[
    {
        "title": "Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis",
        "authors": "Basile Van HoorickRundi WuEge OzgurogluKyle SargentRuoshi LiuPavel TokmakovAchal DaveChangxi ZhengCarl Vondrick",
        "links": "http://arxiv.org/abs/2405.14868v1",
        "entry_id": "http://arxiv.org/abs/2405.14868v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14868v1",
        "summary": "Accurate reconstruction of complex dynamic scenes from just a single\nviewpoint continues to be a challenging task in computer vision. Current\ndynamic novel view synthesis methods typically require videos from many\ndifferent camera viewpoints, necessitating careful recording setups, and\nsignificantly restricting their utility in the wild as well as in terms of\nembodied AI applications. In this paper, we propose $\\textbf{GCD}$, a\ncontrollable monocular dynamic view synthesis pipeline that leverages\nlarge-scale diffusion priors to, given a video of any scene, generate a\nsynchronous video from any other chosen perspective, conditioned on a set of\nrelative camera pose parameters. Our model does not require depth as input, and\ndoes not explicitly model 3D scene geometry, instead performing end-to-end\nvideo-to-video translation in order to achieve its goal efficiently. Despite\nbeing trained on synthetic multi-view video data only, zero-shot real-world\ngeneralization experiments show promising results in multiple domains,\nincluding robotics, object permanence, and driving environments. We believe our\nframework can potentially unlock powerful applications in rich dynamic scene\nunderstanding, perception for robotics, and interactive 3D video viewing\nexperiences for virtual reality.",
        "updated": "2024-05-23 17:59:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14868v1"
    },
    {
        "title": "A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns",
        "authors": "Asaf YehudaiTaelin KaridiGabriel StanovskyAriel GoldsteinOmri Abend",
        "links": "http://arxiv.org/abs/2405.14863v1",
        "entry_id": "http://arxiv.org/abs/2405.14863v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14863v1",
        "summary": "Cross-domain alignment refers to the task of mapping a concept from one\ndomain to another. For example, ``If a \\textit{doctor} were a \\textit{color},\nwhat color would it be?''. This seemingly peculiar task is designed to\ninvestigate how people represent concrete and abstract concepts through their\nmappings between categories and their reasoning processes over those mappings.\nIn this paper, we adapt this task from cognitive science to evaluate the\nconceptualization and reasoning abilities of large language models (LLMs)\nthrough a behavioral study. We examine several LLMs by prompting them with a\ncross-domain mapping task and analyzing their responses at both the population\nand individual levels. Additionally, we assess the models' ability to reason\nabout their predictions by analyzing and categorizing their explanations for\nthese mappings. The results reveal several similarities between humans' and\nmodels' mappings and explanations, suggesting that models represent concepts\nsimilarly to humans. This similarity is evident not only in the model\nrepresentation but also in their behavior. Furthermore, the models mostly\nprovide valid explanations and deploy reasoning paths that are similar to those\nof humans.",
        "updated": "2024-05-23 17:59:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14863v1"
    },
    {
        "title": "Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models",
        "authors": "Gen LiYuling Yan",
        "links": "http://arxiv.org/abs/2405.14861v1",
        "entry_id": "http://arxiv.org/abs/2405.14861v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14861v1",
        "summary": "This paper investigates score-based diffusion models when the underlying\ntarget distribution is concentrated on or near low-dimensional manifolds within\nthe higher-dimensional space in which they formally reside, a common\ncharacteristic of natural image distributions. Despite previous efforts to\nunderstand the data generation process of diffusion models, existing\ntheoretical support remains highly suboptimal in the presence of\nlow-dimensional structure, which we strengthen in this paper. For the popular\nDenoising Diffusion Probabilistic Model (DDPM), we find that the dependency of\nthe error incurred within each denoising step on the ambient dimension $d$ is\nin general unavoidable. We further identify a unique design of coefficients\nthat yields a converges rate at the order of $O(k^{2}/\\sqrt{T})$ (up to log\nfactors), where $k$ is the intrinsic dimension of the target distribution and\n$T$ is the number of steps. This represents the first theoretical demonstration\nthat the DDPM sampler can adapt to unknown low-dimensional structures in the\ntarget distribution, highlighting the critical importance of coefficient\ndesign. All of this is achieved by a novel set of analysis tools that\ncharacterize the algorithmic dynamics in a more deterministic manner.",
        "updated": "2024-05-23 17:59:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14861v1"
    },
    {
        "title": "Not All Language Model Features Are Linear",
        "authors": "Joshua EngelsIsaac LiaoEric J. MichaudWes GurneeMax Tegmark",
        "links": "http://arxiv.org/abs/2405.14860v1",
        "entry_id": "http://arxiv.org/abs/2405.14860v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14860v1",
        "summary": "Recent work has proposed the linear representation hypothesis: that language\nmodels perform computation by manipulating one-dimensional representations of\nconcepts (\"features\") in activation space. In contrast, we explore whether some\nlanguage model representations may be inherently multi-dimensional. We begin by\ndeveloping a rigorous definition of irreducible multi-dimensional features\nbased on whether they can be decomposed into either independent or\nnon-co-occurring lower-dimensional features. Motivated by these definitions, we\ndesign a scalable method that uses sparse autoencoders to automatically find\nmulti-dimensional features in GPT-2 and Mistral 7B. These auto-discovered\nfeatures include strikingly interpretable examples, e.g. circular features\nrepresenting days of the week and months of the year. We identify tasks where\nthese exact circles are used to solve computational problems involving modular\narithmetic in days of the week and months of the year. Finally, we provide\nevidence that these circular features are indeed the fundamental unit of\ncomputation in these tasks with intervention experiments on Mistral 7B and\nLlama 3 8B, and we find further circular representations by breaking down the\nhidden states for these tasks into interpretable components.",
        "updated": "2024-05-23 17:59:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14860v1"
    },
    {
        "title": "Semantica: An Adaptable Image-Conditioned Diffusion Model",
        "authors": "Manoj KumarNeil HoulsbyEmiel Hoogeboom",
        "links": "http://arxiv.org/abs/2405.14857v1",
        "entry_id": "http://arxiv.org/abs/2405.14857v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14857v1",
        "summary": "We investigate the task of adapting image generative models to different\ndatasets without finetuneing. To this end, we introduce Semantica, an\nimage-conditioned diffusion model capable of generating images based on the\nsemantics of a conditioning image. Semantica is trained exclusively on\nweb-scale image pairs, that is it receives a random image from a webpage as\nconditional input and models another random image from the same webpage. Our\nexperiments highlight the expressivity of pretrained image encoders and\nnecessity of semantic-based data filtering in achieving high-quality image\ngeneration. Once trained, it can adaptively generate new images from a dataset\nby simply using images from that dataset as input. We study the transfer\nproperties of Semantica on ImageNet, LSUN Churches, LSUN Bedroom and SUN397.",
        "updated": "2024-05-23 17:58:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14857v1"
    }
]