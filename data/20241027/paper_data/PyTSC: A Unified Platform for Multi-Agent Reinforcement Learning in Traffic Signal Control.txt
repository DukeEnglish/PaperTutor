PyTSC: A Unified Platform for Multi-Agent Reinforcement
ffi
Learning in Tra c Signal Control
Rohit Bokade1 and Xiaoning Jin1
1Department of Mechanical and Industrial Engineering, Northeastern University,
Boston, MA 02115, USA
October 25, 2024
Abstract
Multi-AgentReinforcementLearning(MARL)presentsapromisingapproachforaddressingthecom-
plexity of Traffic Signal Control (TSC) in urban environments. However, existing platforms for MARL-
basedTSCresearchfacechallengessuchasslowsimulationspeedsandconvoluted,difficult-to-maintain
codebases. Toaddresstheselimitations, weintroducePyTSC,arobustandflexiblesimulationenviron-
mentthatfacilitatesthetrainingandevaluationofMARLalgorithmsforTSC.PyTSCintegratesmultiple
simulators,suchasSUMOandCityFlow,andoffersastreamlinedAPI,empoweringresearcherstoexplore
abroadspectrumofMARLapproachesefficiently. PyTSCacceleratesexperimentationandprovidesnew
opportunitiesforadvancingintelligenttrafficmanagementsystemsinreal-worldapplications.
1 Introduction
EffectiveTrafficSignalControl(TSC)isfundamentaltourbantrafficmanagement,responsibleforguiding
themovementofvehiclesthroughintersectionsbycontrollingtrafficlights. TheprimarygoalsofTSCare
tominimizetrafficcongestion,enhancetrafficflow,andimprovesafetyforbothvehiclesandpedestrians.
PoorTSCoptimizationleadstoincreasedcongestion,fuelconsumption,andpollution. Longerwaittimes
at signals lead to increased fuel consumption, which not only exacerbates environmental issues through
higher emissions but also results in economic losses due to delays. Moreover, inefficient TSC negatively
impactsthequalityoflifeinurbanareas,contributingtoincreasednoiseandairpollution.
Multi-AgentReinforcementLearning(MARL)offersapromisingapproachtotacklingtheseTSCchal-
lenges by allowing multiple agents to collaborate within a shared environment. In fully cooperative set-
tings,agentsworktowardacommongoalbyinteractingwiththeirenvironmentandwithoneanotherand
refinetheiractionsbasedonthefeedbackfromtheenvironment. MARL’sversatilityisdemonstratedbyits
successfulapplicationinvariousdomains[1]. Forinstance,inrobotics,MARLhasbeenusedtocoordinate
multiple robots in tasks such as search and rescue operations [2, 3]. These successes highlight MARL’s
potential to solve complex, multi-faceted problems, making it an ideal candidate for optimizing TSC in
dynamicandunpredictableurbanenvironments.
1.1 ChallengesinCurrentMARLResearchforTSC
TheapplicationofMARLtoTSChasseennotableadvancements[4,5,6,7]. Twosimulators,SUMO[8]and
CityFlow [9], are widely recognized in this domain, and several open-source tools have been developed
to leverage these platforms [10, 11, 12]. Recent efforts have aimed at merging the TSC environments of
bothsimulatorsandunifyingdomainmetrics,standardizingevaluationcriteriaandprovidingaconsistent
framework for problem formulation in TSC research [12]. Benchmarks tailored for specific datasets in
SUMOhavealsobeendeveloped,supportingadiverserangeofMARLalgorithms[11].
1
4202
tcO
32
]AM.sc[
1v20281.0142:viXraDespite progress in applying Multi-Agent Reinforcement Learning (MARL) to Traffic Signal Control
(TSC),theresearchcommunitystilllacksaunified,modular,andextensibleplatformthatmeetstheneeds
of modern MARL algorithms. Most existing TSC simulators are tightly coupled to their frameworks and
arenotdesignedtosupporttheflexibleintegrationofadvancedMARLmethodologies,particularlyframe-
workslikeCentralizedTrainingDecentralizedExecution(CTDE),whichhavegainedsignificanttractionin
recentyears.
WhilesimulatorssuchasSUMOandCityFlowarewidelyused,theirrespectiveTSClibrariesareneither
optimizedforCTDE-basedarchitecturesnorcompatiblewithpopularMARLlibrarieslikeEPyMARL[13]
and MARLLib [14]. This lack of compatibility limits experimentation and the exploration of powerful
frameworksthatcanbalancecentralizedlearningwithdecentralizedexecution,whichiscrucialforefficient
andscalabletrafficmanagementinreal-worldsystems.
Furthermore,theabsenceofastreamlinedandmodulardesigninexistingtoolsmakesthemchallenging
toextendandadaptfornewresearchdirections. Researchersoftenspendconsiderabletimegrapplingwith
integration and code maintenance, rather than focusing on the development and testing of novel MARL
algorithms. This inefficiency delays progress and discourages the widespread adoption of cutting-edge
MARLtechniquesinTSC.
To address these gaps, we propose PyTSC, a library specifically designed to overcome these limita-
tions. PyTSC offers a clean, modular, and extensible environment that seamlessly integrates with CTDE
frameworkslikeEPyMARLandMARLLib, enablingresearcherstoquicklyprototype, train, andevaluate
MARL algorithms in a traffic control context. By providing a robust and flexible platform, PyTSC em-
powerstheresearchcommunitytoexplorenovelTSCsolutions,leadingtofasterexperimentation,greater
reproducibility,andultimately,moreeffectivetrafficsignalcontrolstrategies.
1.2 Contributions
This work introduces PyTSC, a flexible and efficient simulation environment designed to address these
challengesintheMARL-TSCresearchdomain. PyTSCfillsacrucialgapintheTSCresearchecosystemby
providingaplatformthatsimplifiesintegration,supportscross-simulatorcomparisons,andoffersaclean
interfacefordeployingadvancedMARLmethodslikeCTDE.Thekeycontributionsofthisresearchare:
1. Compatibility with Multiple Simulators: PyTSC supports both SUMO and CityFlow simulators,
offeringaconsistentAPI.Thisdesignfacilitatestheintegrationofadditionalsimulatorsinthefuture.
2. OptimizedforSpeed:TheRetrievermoduleinPyTSCefficientlygathersrequiredinformationfrom
thesimulatoraftereachtimestep,minimizingsimulatorqueriesandenhancingsimulationspeeds1.
3. LeveragingGraphicalMARLTechniques: TheNetworkParsermoduleprocessesnetworkfiles,ex-
tracting data crucial for graphical methods MARL algorithm development (e.g. adjacency matrix,
centralitymeasures,etc.),facilitatingtheuseofadvancedgraphneuralnetworksinTSC.
4. Dataset Aggregation: PyTSC aggregates commonly used datasets in MARL-TSC. The environment
alsofeaturesmoduleslikeGridGeneratorandTripGeneratorforsyntheticnetworktestingandtrip
generation,respectively.
5. UnifiedMARLFormulationforTSC:WhilewerecognizethatwedidnotdeveloptheDec-POMDP
andNetworkedMMDPformulations,weadvocatefortheiruseinTSCresearch. Theseformulations,
which allow for decentralized control schemes, are comprehensive and well-suited for deep MARL
techniquesinTSC.Bypromotingtheseformulations,weaimtostandardizenomenclatureandprob-
lem formulations in the TSC field, facilitating clearer communication and collaboration among re-
searchers.
6. Experiments with CTDE MARL Frameworks: As demo, we present a experiments with several of
state-of-the-art MARL techniques, which follow Centralized Training and Decentralized Execution
(CTDE)paradigm,usingtheEPymarllibrary[13].
1https://sumo.dlr.de/docs/FAQ.html#traci
2In summary, PyTSC is not merely a tool but a significant advancement in TSC research. By integrating
MARL into a well-structured environment, PyTSC has the potential to redefine Traffic Signal Control re-
search,propellingbothacademicinquiryandpracticalapplications.
2 The PyTSC Framework
Figure1: OverviewofPyTSCArchitecture
The PyTSC Framework stands as a meticulously designed structure, bridging the gap between traffic
simulationsandMulti-AgentReinforcementLearning(MARL).Thelibraryisavailableathttps://github.
com/rbokade/pytsc.This strategic design ensures that researchers can delve into algorithmic intricacies
withouttheoverheadofintegrationcomplexities. Theframework’skeyattributesinclude:
SupportforDiverseSimulatorBackends: PyTSCintegratesaconsistentAPIfortworenownedsimulator
backends: SUMO[8]andCityFlow[9]. SimulatorspecificclasseslikeConfigParser,Retriever,Simula-
tor,TrafficSignalallowforprocessingtheinputfromthesimulatorsintoacommonformatwhichcan
thenbeusedintheTrafficSignalNetworkenvironmentclass. Thisuniforminterfacenotonlymaintains
consistencyacrosssimulatorsbutalsooffersafoundationforresearcherstoincorporateadditionalsimula-
torbackendsasneeded.
Customizable: ThemodularframeworkofPyTSCservesasacomprehensivetestbedforexperimenting.
Researcherscanexperimentwithvarioustrafficsignalnetworksettingsbychoosingfromexistingmodules
orextendthemtosuittheirownneeds. Forexample,theTLSFreePhaseSelectLogicandTLSRoundRobin-
PhaseSelectLogicallowuserstoselecteitheradaptivephaseselectionorfixittoaroundrobinstrategy.
3Figure2: 2×2GridSUMO(left)CityFlow(right)
UserscanalsomodifytheinformationrequiredbytheMARLalgorithmbysimplyextendingBaseObser-
vationSpace,BaseActionSpace,BaseRewardFunctionaccordingtotheirneeds.
OptimizedPerformance: Theframeworkisoptimizedtogatheressentialmetricsfromthebackendsim-
ulator in a single query after each simulation step. This streamlined approach minimizes redundant
queries,leadingtofastersimulationprocesses. ForSUMOsimulatorbackends,itusessubscriptionshttps:
//sumo.dlr.de/docs/FAQ.html#tracitofurtherspeedupsimulations.
IntegrationofStaticNetworkFeatures: Beforesimulationcommencement,theNetworkParsermodule
parsesallassociatednetworkfilesofthechosensimulator. Thisprovidesresearcherswithaddednetwork
insights,suchascentralitymetricsoradjacencymatrices,whichcanbepivotalforenhancingMARLalgo-
rithmperformanceinTrafficSignalControl.
CompatibilitywithMARLTrainingFrameworks: PyTSCintroducesawell-definedAPIunderthemod-
ule TrafficSignalNetwork that integrates seamlessly with established MARL libraries, such as rllib [15]
andpymarl[16],facilitatingtheirapplicationinTSC.
3 Experiments
3.1 TrafficSignalNetworkScenarios
We have curated 10 open source scenarios most commonly used by researchers while applying MARL
techniquestoTSC.Thesescenarios,widelyadoptedbyresearchersinthefield, encompassbothsynthetic
andreal-worldtrafficnetworksandarecompatiblewithbothCityFlowandSUMOsimulators. Adetailed
overviewofthesescenariosispresentedinTable1.
ThescenariosinTable1offeramixofsyntheticgridnetworksandreal-worldtrafficsettings. Synthetic
grids, from 2×2 to 3×3, provide a controlled environment with homogeneous agents for testing MARL
techniques. Incontrast,real-worldscenariosfromcitieslikeCologne,Ingolstadt,andMonacopresentur-
bancomplexitieswithheterogeneousagents,rangingfrom3to16. Thisdiversityensuresthoroughtesting
of MARL across various scales. Additionally, the scenarios’ compatibility with both SUMO and CityFlow
allows researchers flexibility in simulation choices. Overall, these scenarios form a robust benchmarking
platformforMARLinTSC,coveringdiversenetworktypesandcomplexities.
https://github.com/cts198859/deeprl_network/
https://github.com/LucasAlegre/sumo-rl
https://github.com/traffic-signal-control/sample-code/
https://github.com/Pi-Star-Lab/RESCO/
4Figure3: 3×3GridSUMO(left)CityFlow(right)
(a)Cologne(3trafficsignals) (b)Ingolstadt
(c)Pasubio (d)Cologne(8trafficsignals)
Figure4: Real-worldenvironmentsforSUMO
3.2 TrafficSignalsasAgents
InMARLunderfully-cooperativesettings,agentslearntoachieveacommongoalormaximizetheirindi-
vidual rewards through interaction with the environment and each other. In the context of TSC, MARL
providesaframeworkfordevelopingtrafficsignalcontrolstrategiesthatcanadapttochangingtrafficpat-
terns and optimize flow. Traffic signals are modeled as agents whose goal is to choose control the traffic
lightstominimizecongestionthroughoutthetrafficsignalnetwork.
3.2.1 DecentralizedPartiallyObservableMarkovDecisionProcesses(Dec-POMDPs)
Dec-POMDPsmodelmulti-agentsystems[17]whereagentsinteractinadecentralizedwayunderlimited
visibility. Thisispertinentforanalyzingtrafficsignalcontrol.
5(a)Jinan3×4 (b)Hangzhou4×4
Figure5: Real-worldenvironmentsforCityFlow
Simulator Scenario NetworkType AgentType Totalagents
2×2grid Synthetic Homogeneous 4
3×3grid Synthetic Homogeneous 9
Cologne3 Real-world Heterogeneous 3
SUMO Ingolstadt7 Real-world Heterogeneous 7
Cologne8 Real-world Heterogeneous 8
Pasubio Real-world Heterogeneous 8
2×2grid Synthetic Homogeneous 4
3×3grid Synthetic Homogeneous 9
CityFlow
Jinan(3×4grid) Real-world Homogeneous 12
Hangzhou(4×4grid) Real-world Homogeneous 16
Table1: ScenariosincludedinPyTSC
DefinitionADec-POMDPisdefinedasatuple⟨N,S,{A },{O },T,{Ω },R⟩,where:
i i i
• N: Afinitesetofnagents,N ≡{1,...,n}.
• S: Afinitesetofstatesthatdescribetheglobalstateoftheenvironment.
• {A }: Afinitesetofactionsforeachagenti,withthejointactionspaceA≡{A ×...×A }.
i 1 n
• {O }: Afinitesetofobservationsforeachagenti,withthejointobservationspaceO≡{O ×...×O }.
i 1 n
• T :S×A(cid:55)→∆(S): Astatetransitionfunctionthatmapsthecurrentstateandjointactiontoaproba-
bilitydistributionovernextstates.
• {Ω : S×A (cid:55)→ ∆(O )}: An observation function for each agent, mapping the current state and joint
i i
actiontoaprobabilitydistributionoverindividualobservations.
• R:S×A(cid:55)→R: Arewardfunctionthatmapsaglobalstateandjointactiontoareal-valuedreward.
By capturing the decentralized nature and partial observability inherent in urban traffic systems, Dec-
POMDPsofferafoundationfordesigningMARLframeworksthatcanleadtomoreresponsiveandefficient
trafficsignalcontrol.
3.2.2 Observationrepresentation
Eachtrafficsignalhasalimitedrangeofvisionof50meters,withinwhichitcanobtaininformationrelated
tothetrafficflow.Thisisequivalenttothesensoryinformationthatcanbeobtainedfrompracticalcommon
sensors. The observation for each traffic signal consists of: the number of vehicles {n }Li , the average
l l=1
normalized speed of the vehicles {s }Li , the number of halted vehicles (queue lengths) {q }Li , and the
l l=1 l l=1
currentphaseIDofthetrafficsignal,whereL ∈Laretheincominglanesforatrafficsignali andLisaset
i
ofallthelanesinthenetwork.
63.2.3 ActionRepresentation
Foreachtrafficsignali,wedefineitsactiona aschoosingonegreenphasefromalistofavailablephases. A
i
trafficsignalcanselectanygreenphasefromitslistorkeepitscurrentone,butitmustthenfollowthenext
yellow phase, which is enforced by the environment. The action selection interval and the yellow phases
arefixedforadurationof5simulationseconds.
3.2.4 Reward
Variousmetricsareusedforrewardsintrafficsignalcontrolsettings. Inourstudy,wechosequeuelength
q astheperformancemetricofthetrafficsignalcontrollerduetoitssimplisticnatureanditspropertyof
l
representinganinstantaneousfeedbacksignal. Wedefinetheobjectivefunctionasminimizingthenumber
ofvehiclesstoppedthroughoutthenetwork
wherer ∈Ristheglobalrewardandl∈Lrepresentsthelanesinthenetwork.
t
3.3 MARLFrameworks
For benchmarking CTDE algorithms in TSC, we employ EPymarl, an extension of the widely recognized
Pymarl library. EPymarl encompasses a broad spectrum of algorithms under the reinforcement learning
paradigms of Q-learning, actor-critic, and policy gradient methods. Our selection focuses on the most
prevalentMARLframeworks,asdetailedinTable2.
Algorithm Centralizedtraining Off-/On-policy Value-based Policy-based
IQL ✗ ✗ ✓ ✗
IA2C ✗ ✓ ✓ ✓
VDN ✓ ✗ ✓ ✗
QMIX ✓ ✗ ✓ ✗
MAA2C ✓ ✓ ✓ ✓
Table2: MARLAlgorithmsforBenchmarking
AnalyzingthealgorithmspresentedinTable2,weobserveadiverserangeofMARLtechniquestailored
fordifferentproblemsettings. IQL,forinstance,isadecentralized,value-basedmethodthatoperatesoff-
policy. Incontrast, IA2Cisbothvalueandpolicy-based, functioningon-policywithoutcentralizedtrain-
ing. VDNandQMIX,whilebothbeingvalue-based, differintheirapproachtocentralizedtraining, with
QMIXemployingit. MAA2Cstandsoutasaversatilealgorithm,incorporatingbothvalueandpolicy-based
methods, operating on-policy, and utilizing centralized training. This selection ensures a comprehensive
evaluationofMARLtechniquesacrossvarioustrainingparadigms,policyorientations,andvaluedetermi-
nations. Bybenchmarkingthesealgorithms,weaimtoprovideinsightsintotheirapplicability,strengths,
andlimitationswithinthecontextofTSC.
3.4 EvaluationProtocols
The performance of the Multi-Agent Reinforcement Learning (MARL) algorithms was evaluated through
a carefully designed training and testing process. Each episode during training was constrained to 360
simulationseconds,whichcorrespondsto72timesteps. Thistimeframewasselectedtoensureabalance
between simulation length and computational efficiency. Therefore, one simulation hour consisted of 10
episodes, which allowed the MARL algorithms to interact with the environment multiple times within a
relativelyshortperiod(seeTable3foradetailedbreakdownoftimestepsandsimulationperiods).
https://github.com/uoe-agents/epymarl/
https://github.com/oxwhirl/pymarl
7Metric Timestep Simulationseconds Simulationhours
Step 1 5 0.083
Episodelimit 72 360 0.10
Training(length) 4.32M 21.6M 6000
Test(interval) 14400 7200 2
Test(length) 720 3600 1
Table3: BreakdownofHyperparametersUsedforBenchmarking
Intotal,thealgorithmsweretrainedfor4.32milliontimesteps,whichcorrespondsto36,000episodes.
Thisextensivetrainingschedule,equivalentto6,000hoursofsimulatedtraffic,providedampleopportu-
nity for the agents to learn optimal strategies for traffic signal control. To assess the generalization capa-
bilities of the trained models, evaluation was performed every 200 episodes. For each evaluation cycle,
themodelsweretestedover10episodestoensurethatperformancewasnotmerelyduetooverfittingbut
couldbereplicatedundervariousconditions(seeTable3fordetailsontestingintervalsandlength).
To optimize the MARL algorithms, hyperparameter tuning was conducted on smaller synthetic grid
networks,suchas2×2and3×3grids. Thesesimplerenvironmentsallowedformoreefficientexplorationof
differenthyperparametercombinations,ensuringthatthebestconfigurationswerechosenbeforeapplying
thealgorithmstolargerandmorecomplexnetworks. Thechosenhyperparametersforbenchmarkingare
showninTable4.
Hyperparameter Value
Buffersize(episodes) 5000
Hiddendimension 64
Learningrate 0.0005
Evaluationepsilon 0.0
Epsilonanneal(steps) 50000/100000
Targetupdate(episodes) 200
Entropycoeff. 0.01
Table4: Hyperparameters
Inadditiontotheselearningmetrics,severalTSC-specificmetricswereemployedtocapturethebroader
impactofthetrafficsignalcontrolsystem. Theseincludedthetotalnumberofvehiclesqueuedacrossthe
network,theaveragetraveltime,averageoccupancy,averagespeed,averagedelay,andaveragewaittime.
All experiments were conducted on Northeastern University’s High-Performance Computing (HPC)
Discovery cluster. Each experiment utilized 8 single-core CPUs, with 4 parallel environments running
simultaneouslytogatherdataefficiently. Thissetupallowedforsignificantcomputationalpowerandpar-
allelization, enabling the MARL algorithms to process multiple simulations concurrently and reduce the
overalltimerequiredfortrainingandevaluation.
4 Results
The performance of various MARL algorithms was evaluated across different environments using SUMO
andCityFlowsimulators. Theseenvironmentsrangedfromsimplesyntheticgridnetworkstomorecom-
plex real-world networks, such as Jinan, Hangzhou, Pasubio, and Cologne. The results highlight several
keyfactorsthataffectalgorithmicperformance,includingnetworktopologyandthesimulationplatform.
4.1 PerformanceonSyntheticGridNetworks
In synthetic grid networks (2x2 and 3x3), centralized algorithms like QMIX and MAA2C outperform de-
centralizedapproaches,particularlyintheSUMOenvironment. AsshowninFigure4,MAA2CandQMIX
exhibithigherrewardsovertime,indicatingtheirabilitytoeffectivelymanagetrafficincomplexscenarios
8where dynamic routing and multiple traffic flows are present. SUMO’s dynamic routing features allow
centralized algorithms to optimize traffic signal timings more effectively, leading to reduced delays and
shorterqueuelengths.
Conversely,inCityFlow,wherevehicledynamicsaresimplerandthereisnodynamicrouting,theper-
formancegapbetweencentralizedanddecentralizedmethodsnarrows. Allalgorithmsperformsimilarly,
reflecting the reduced need for complex coordination in this simulation environment. This suggests that
CityFlow, while computationally efficient, may not capture the same level of traffic dynamics that allow
centralizedalgorithmstoexcel.
Table5: MeanandStandardErrorofMetricsforVariousControllersAcrossScenarios
MARLControllers Rule-basedControllers
Metric
IQL IA2C VDN QMIX MAA2C Fixed Greedy MaxPres. SOTL
2×2SUMO
Queue 486.47 588.11 475.32 276.69 333.48 464.87 556.88 556.88 556.88
Delay 0.583 0.586 0.586 0.579 0.564 0.59 0.67 0.67 0.67
TravelTime 280.34 329.45 274.92 188.78 239.00 325.02 261.45 261.45 261.45
3×3SUMO
Queue 500.98 411.47 520.54 361.57 449.05 560.08 656.85 656.85 656.85
Delay 0.585 0.556 0.588 0.534 0.554 0.61 0.62 0.62 0.62
TravelTime 140.31 139.92 137.19 146.76 143.27 180.52 166.68 166.68 166.68
2×2CityFlow
Queue 222.72 201.71 239.34 224.97 205.05 314.08 281.75 261.41 377.43
Delay 0.606 0.600 0.611 0.605 0.598 0.6603 0.6466 0.6362 0.6993
TravelTime 223.13 191.88 239.19 227.97 209.88 325.02 219.48 203.31 437.33
3×3CityFlow
Queue 445.10 396.93 520.17 484.57 404.01 621.36 557.96 458.11 738.95
Delay 0.65 0.63 0.67 0.68 0.64 0.69 0.66 0.64 0.74
TravelTime 285.17 249.42 312.03 290.67 288.64 389.21 277.8 246.52 498.33
4.2 ImpactofReal-WorldTopologyonAlgorithmPerformance
The evaluation on real-world networks reveals important insights into how network topology influences
algorithmperformance.
Jinan and Hangzhou: In these larger, more congested networks, centralized algorithms like QMIX and
MAA2CoutperformdecentralizedapproachessuchasIQLandIA2C.Theresultshighlighttheimportance
of centralized training across traffic signals is critical for managing complex flows of vehicles in dense
urban environments. The superior performance of centralized methods in these scenarios reflects their
abilitytoadapttrafficsignalsinacoordinatedmanner,optimizingroutesandreducingoveralldelay.
9Table6: MeanandStandardErrorofMetricsforVariousControllersAcrossScenarios
MARLControllers Rule-basedControllers
Metric
IQL IA2C VDN QMIX MAA2C Fixed Greedy MaxPres. SOTL
Jinan
Queue 278.55 248.49 269.14 231.56 221.79 413.55 210.17 228.2 663.39
Delay 0.479 0.467 0.476 0.469 0.470 0.54 0.47 0.49 0.53
TravelTime 320.51 311.91 323.85 308.67 307.00 354.96 287.33 294.97 425.01
Hangzhou
Queue 286.11 203.24 234.48 208.95 211.18 301.93 171.16 177.93 354.57
Delay 0.585 0.548 0.565 0.554 0.559 0.63 0.56 0.58 0.61
TravelTime 344.72 315.13 327.71 319.03 319.11 356.65 292.77 296.73 364.87
Cologne (3 and 8 Traffic Signals): The performance in the Cologne networks shows the influence of
topology on algorithm effectiveness. In the simpler, 3-signal Cologne network (Figure ??), decentralized
algorithmsperformcompetitivelywithcentralizedmethods. Thelinearstructureandreducedcomplexity
of the network limit the need for extensive coordination, allowing decentralized approaches to function
well. However,inthemorecomplex8-signalColognenetwork(Figure??),centralizedmethodslikeQMIX
andMAA2Cshowclearadvantages,managingtrafficacrossthewidergridmoreeffectivelyandleadingto
higherrewardsandlowerdelays.
IngolstadtandPasubio: Intheseirregularandsprawlingnetworks,centralizedmethodsoutperformde-
centralized ones. The elongated structure of Ingolstadt (Figure ??) and the spread-out intersections in
Pasubio(Figure??)introducechallengesfortrafficmanagement,suchasbottlenecksanduneventrafficdis-
tribution. Centralizedalgorithms, withtheirabilitytocoordinateacrosssignalsandoptimizetrafficflow
holistically,significantlyreducequeuesanddelaysintheseenvironments. Incontrast,decentralizedmeth-
ods struggle to maintain consistent performance in such irregular topologies, resulting in higher travel
timesanddelays.
10Table7: MeanandStandardErrorofMetricsforVariousControllersAcrossScenarios
MARLControllers Rule-basedControllers
Metric
IQL IA2C VDN QMIX MAA2C Fixed Greedy MaxPres. SOTL
Cologne3
Queue 23.46 18.67 19.55 20.49 18.80 51.52 53.29 53.29 53.29
Delay 0.334 0.300 0.316 0.319 0.301 0.5 0.54 0.54 0.54
TravelTime 227.11 227.23 230.06 227.46 230.87 220.7 210.54 210.54 210.54
Cologne8
Queue 19.95 18.32 20.77 17.35 17.39 41.71 73.87 73.87 73.87
Delay 0.190 0.185 0.184 0.171 0.183 0.26 0.3 0.3 0.3
TravelTime 356.59 356.23 356.08 356.96 356.52 358.14 339.59 339.59 339.59
Ingolstadt7
Queue 18.45 17.46 20.35 17.38 19.19 107.06 51.8 50.56 44.16
Delay 0.184 0.169 0.190 0.173 0.177 0.42 0.37 0.36 0.33
TravelTime 192.82 193.35 193.04 193.03 192.74 174.66 183.37 184.47 186.09
Pasubio
Queue 335.29 340.11 307.60 297.79 322.94 304.82 330.26 330.26 330.26
Delay 0.35 0.33 0.30 0.29 0.30 0.34 0.39 0.39 0.39
TravelTime 303.67 310.88 322.29 321.03 327.31 326.0 292.09 292.09 292.09
4.3 InsightsfromPerformanceMetrics
Table 7 summarizes key performance metrics, such as queue lengths, delays, and travel times, across the
evaluatednetworks. Theresultsrevealseveralkeytrends:
• QueueLength: Centralizedalgorithmsgenerallyachieveshorterqueuelengths,particularlyinmore
complexnetworkslikePasubioandCologne8,wherecoordinationacrossintersectionsiscriticalfor
maintainingtrafficflow.
• Delays: Across all scenarios, centralized approaches reduce delays more effectively than decentral-
izedones. ThedifferenceisespeciallynotableinSUMOenvironments,wheredynamicroutingallows
centralizedalgorithmstoadapttoreal-timetrafficconditionsmoreeffectively.
• Travel Time: In networks with higher complexity, such as Jinan and Hangzhou, centralized ap-
proaches minimize travel time more effectively than decentralized methods. However, in simpler
networkslikeCityFlow’s2x2grid, thetraveltimesacrossallalgorithmsarecomparable, suggesting
thatcentralizedcoordinationoffersdiminishingreturnsinlesscomplexenvironments.
4.4 Topology-DependentPerformance
The topology of the traffic network plays a crucial role in determining the success of different MARL al-
gorithms. Insimpler,grid-likenetworks,suchasthe3-signalColognesetup,decentralizedalgorithmscan
perform on par with centralized methods. However, as network complexity increases, the advantages of
centralizedcoordinationbecomemorepronounced. InnetworkslikePasubioandIngolstadt,whichfeature
irregularlayoutsandcomplextrafficflows,centralizedapproacheslikeQMIXandMAA2Coutperformde-
centralizedmethodsbyasignificantmargin.
This suggests that the choice of algorithm should be informed by the specific characteristics of the
trafficnetwork. Centralizedalgorithmsaremoresuitableforcomplex,irregularnetworkswithhightraffic
density,whiledecentralizedapproachesmaysufficeinsimpler,moreuniformnetworks.
5 Conclusion
In this work, we introduced PyTSC, a versatile and extensible library designed to address the significant
gapsinMARL-basedTrafficSignalControl(TSC)research. Byenablingcompatibilitywithmultiplesimu-
11lators,suchasSUMOandCityFlow,PyTSCprovidesaunifiedAPIthatsimplifiesthedevelopment,testing,
and benchmarking of Multi-Agent Reinforcement Learning (MARL) algorithms for TSC. Additionally, its
optimized architecture facilitates faster simulation speeds, allowing researchers to focus on algorithmic
innovationsratherthantechnicalintegration.
PyTSC’s integration with modern CTDE (Centralized Training Decentralized Execution) frameworks,
suchasEPyMARLandMARLLib,allowsresearcherstoprototypeandevaluateadvancedMARLtechniques
withinatrafficcontrolsetting. Thisfillsacriticalgapintheexistingresearchecosystem, wheretoolsare
eithertoodomain-specificorlacktheflexibilityrequiredforseamlessexperimentation.
With its modular and extensible design, PyTSC establishes a foundation for more consistent, repro-
ducible, and scalable MARL research in the realm of traffic signal control. This contributes directly to
advancingsmarter,moreadaptivetrafficmanagementsolutions. Theperformanceevaluationsacrossboth
syntheticandreal-worldtrafficnetworksdemonstratethelibrary’seffectivenessandversatility,underscor-
ingitspotentialtodriveinnovationinTSCsystems.
6 Future Work
Lookingahead,PyTSCopensseveralavenuesforfuturedevelopmentandexploration:
• Incorporation of Additional MARL Algorithms: Future iterations of PyTSC will include policy-
basedMARLalgorithmssuchasMADDPG,IPPO,andMAPPO,expandingitscapabilitiesformore
complextrafficcontrolstrategies.
• DiverseTrafficFlowGeneration: Weaimtointroducemorediversetrafficflowgenerationmodels,
includingbothsyntheticandreal-worldflowpatterns,tobettersimulatethevarietyoftrafficscenar-
iosseeninurbanenvironments.
• Synthetic Network Generation Modules: Expanding the tools for generating synthetic traffic sig-
nalnetworkswillenableresearcherstotestMARLalgorithmsinevenmorecontrolledandcomplex
environments,beyondtheexistingbenchmarks.
• TailoredNeuralNetworkArchitectures:WhilethecurrentversionofPyTSCreliesonout-of-the-box
neuralarchitectures,futureupdateswillexploretheintegrationofspecializedmodels,suchasGraph
Neural Networks (GNNs), that can leverage the graphical structure of traffic networks to optimize
decision-making.
• ExtendingSimulatorCompatibility: Wealsoplantointegrateadditionaltrafficsimulatorsintothe
PyTSC framework, ensuring that the platform remains adaptable to emerging technologies and re-
searchneedsinthefieldofintelligenttransportationsystems.
By continuously evolving PyTSC, we aim to provide a robust and dynamic platform that will foster in-
novation in MARL-based traffic signal control and further enhance the real-world applicability of these
technologies.
12References
[1] W. Du and S. Ding, “A survey on multi-agent deep reinforcement learning: from the perspective of
challengesandapplications,”ArtificialIntelligenceReview,vol.54,pp.3215–3238,2021.
[2] T.T.Nguyen,N.D.Nguyen,andS.Nahavandi,“Deepreinforcementlearningformultiagentsystems:
A review of challenges, solutions, and applications,” IEEE transactions on cybernetics, vol. 50, no. 9,
pp.3826–3839,2020.
[3] L.Canese,G.C.Cardarilli,L.DiNunzio,R.Fazzolari,D.Giardino,M.Re,andS.Spano`,“Multi-agent
reinforcement learning: A review of challenges and applications,” Applied Sciences, vol. 11, no. 11,
p.4948,2021.
[4] M. Noaeen, A. Naik, L. Goodman, J. Crebo, T. Abrar, Z. S. H. Abad, A. L. Bazzan, and B. Far, “Re-
inforcement learning in urban network traffic signal control: A systematic literature review,” Expert
SystemswithApplications,vol.199,p.116830,2022.
[5] R. Chen, F. Fang, and N. Sadeh, “The real deal: A review of challenges and opportunities in
moving reinforcement learning-based traffic signal control systems towards reality,” arXiv preprint
arXiv:2206.11996,2022.
[6] H. Wei, G. Zheng, V. Gayah, and Z. Li, “A survey on traffic signal control methods,” arXiv preprint
arXiv:1904.08117,2019.
[7] A. Haydari and Y. Yılmaz, “Deep reinforcement learning for intelligent transportation systems: A
survey,”IEEETransactionsonIntelligentTransportationSystems,vol.23,no.1,pp.11–32,2020.
[8] P.A.Lopez,M.Behrisch,L.Bieker-Walz,J.Erdmann,Y.-P.Flo¨ttero¨d,R.Hilbrich,L.Lu¨cken,J.Rum-
mel,P.Wagner,andE.Wießner,“Microscopictrafficsimulationusingsumo,”inThe21stIEEEInter-
nationalConferenceonIntelligentTransportationSystems,IEEE,2018.
[9] H. Zhang, S. Feng, C. Liu, Y. Ding, Y. Zhu, Z. Zhou, W. Zhang, Y. Yu, H. Jin, and Z. Li, “Cityflow:
A multi-agent reinforcement learning environment for large scale city traffic scenario,” in The world
widewebconference,pp.3620–3624,2019.
[10] L.N.Alegre,“SUMO-RL.”https://github.com/LucasAlegre/sumo-rl,2019.
[11] J.AultandG.Sharon, “Reinforcementlearningbenchmarksfortrafficsignalcontrol,” inThirty-fifth
ConferenceonNeuralInformationProcessingSystemsDatasetsandBenchmarksTrack(Round1),2021.
[12] H.Mei,X.Lei,L.Da,B.Shi,andH.Wei,“Libsignal: Anopenlibraryfortrafficsignalcontrol,”arXiv
preprintarXiv:2211.10649,2022.
[13] G. Papoudakis, F. Christianos, L. Scha¨fer, and S. V. Albrecht, “Benchmarking multi-agent deep rein-
forcementlearningalgorithmsincooperativetasks,”arXivpreprintarXiv:2006.07869,2020.
[14] S.Hu,Y.Zhong,M.Gao,W.Wang,H.Dong,Z.Li,X.Liang,Y.Yang,andX.Chang,“Marllib: Extend-
ingrllibformulti-agentreinforcementlearning,”2022.
[15] E.Liang,R.Liaw,R.Nishihara,P.Moritz,R.Fox,K.Goldberg,J.E.Gonzalez,M.I.Jordan,andI.Stoica,
“RLlib: Abstractions for distributed reinforcement learning,” in International Conference on Machine
Learning(ICML),2018.
[16] M.Samvelyan,T.Rashid,C.S.DeWitt,G.Farquhar,N.Nardelli,T.G.Rudner,C.-M.Hung,P.H.Torr,
J. Foerster, and S. Whiteson, “The starcraft multi-agent challenge,” arXiv preprint arXiv:1902.04043,
2019.
[17] F.A.OliehoekandC.Amato, AconciseintroductiontodecentralizedPOMDPs. SpringerInternational
Publishing,Cham,2016.
13