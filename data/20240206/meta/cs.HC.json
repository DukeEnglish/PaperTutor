[
    {
        "title": "SLYKLatent, a Learning Framework for Facial Features Estimation",
        "authors": "Samuel AdebayoJoost C. DessingSeán McLoone",
        "links": "http://arxiv.org/abs/2402.01555v1",
        "entry_id": "http://arxiv.org/abs/2402.01555v1",
        "pdf_url": "http://arxiv.org/pdf/2402.01555v1",
        "summary": "In this research, we present SLYKLatent, a novel approach for enhancing gaze\nestimation by addressing appearance instability challenges in datasets due to\naleatoric uncertainties, covariant shifts, and test domain generalization.\nSLYKLatent utilizes Self-Supervised Learning for initial training with facial\nexpression datasets, followed by refinement with a patch-based tri-branch\nnetwork and an inverse explained variance-weighted training loss function. Our\nevaluation on benchmark datasets achieves an 8.7% improvement on Gaze360,\nrivals top MPIIFaceGaze results, and leads on a subset of ETH-XGaze by 13%,\nsurpassing existing methods by significant margins. Adaptability tests on\nRAF-DB and Affectnet show 86.4% and 60.9% accuracies, respectively. Ablation\nstudies confirm the effectiveness of SLYKLatent's novel components. This\napproach has strong potential in human-robot interaction.",
        "updated": "2024-02-02 16:47:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.01555v1"
    },
    {
        "title": "Homogenization Effects of Large Language Models on Human Creative Ideation",
        "authors": "Barrett R. AndersonJash Hemant ShahMax Kreminski",
        "links": "http://arxiv.org/abs/2402.01536v1",
        "entry_id": "http://arxiv.org/abs/2402.01536v1",
        "pdf_url": "http://arxiv.org/pdf/2402.01536v1",
        "summary": "Large language models (LLMs) are now being used in a wide variety of\ncontexts, including as creativity support tools (CSTs) intended to help their\nusers come up with new ideas. But do LLMs actually support user creativity? We\nhypothesized that the use of an LLM as a CST might make the LLM's users feel\nmore creative, and even broaden the range of ideas suggested by each individual\nuser, but also homogenize the ideas suggested by different users. We conducted\na 36-participant comparative user study and found, in accordance with the\nhomogenization hypothesis, that different users tended to produce less\nsemantically distinct ideas with ChatGPT than with an alternative CST.\nAdditionally, ChatGPT users generated a greater number of more detailed ideas,\nbut felt less responsible for the ideas they generated. We discuss potential\nimplications of these findings for users, designers, and developers of\nLLM-based CSTs.",
        "updated": "2024-02-02 16:27:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.01536v1"
    },
    {
        "title": "Towards the new XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence",
        "authors": "Thao LeTim MillerRonal SinghLiz Sonenberg",
        "links": "http://arxiv.org/abs/2402.01292v1",
        "entry_id": "http://arxiv.org/abs/2402.01292v1",
        "pdf_url": "http://arxiv.org/pdf/2402.01292v1",
        "summary": "Prior research on AI-assisted human decision-making has explored several\ndifferent explainable AI (XAI) approaches. A recent paper has proposed a\nparadigm shift calling for hypothesis-driven XAI through a conceptual framework\ncalled evaluative AI that gives people evidence that supports or refutes\nhypotheses without necessarily giving a decision-aid recommendation. In this\npaper we describe and evaluate an approach for hypothesis-driven XAI based on\nthe Weight of Evidence (WoE) framework, which generates both positive and\nnegative evidence for a given hypothesis. Through human behavioural\nexperiments, we show that our hypothesis-driven approach increases decision\naccuracy, reduces reliance compared to a recommendation-driven approach and an\nAI-explanation-only baseline, but with a small increase in under-reliance\ncompared to the recommendation-driven approach. Further, we show that\nparticipants used our hypothesis-driven approach in a materially different way\nto the two baselines.",
        "updated": "2024-02-02 10:28:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.01292v1"
    },
    {
        "title": "STAA-Net: A Sparse and Transferable Adversarial Attack for Speech Emotion Recognition",
        "authors": "Yi ChangZhao RenZixing ZhangXin JingKun QianXi ShaoBin HuTanja SchultzBjörn W. Schuller",
        "links": "http://arxiv.org/abs/2402.01227v1",
        "entry_id": "http://arxiv.org/abs/2402.01227v1",
        "pdf_url": "http://arxiv.org/pdf/2402.01227v1",
        "summary": "Speech contains rich information on the emotions of humans, and Speech\nEmotion Recognition (SER) has been an important topic in the area of\nhuman-computer interaction. The robustness of SER models is crucial,\nparticularly in privacy-sensitive and reliability-demanding domains like\nprivate healthcare. Recently, the vulnerability of deep neural networks in the\naudio domain to adversarial attacks has become a popular area of research.\nHowever, prior works on adversarial attacks in the audio domain primarily rely\non iterative gradient-based techniques, which are time-consuming and prone to\noverfitting the specific threat model. Furthermore, the exploration of sparse\nperturbations, which have the potential for better stealthiness, remains\nlimited in the audio domain. To address these challenges, we propose a\ngenerator-based attack method to generate sparse and transferable adversarial\nexamples to deceive SER models in an end-to-end and efficient manner. We\nevaluate our method on two widely-used SER datasets, Database of Elicited Mood\nin Speech (DEMoS) and Interactive Emotional dyadic MOtion CAPture (IEMOCAP),\nand demonstrate its ability to generate successful sparse adversarial examples\nin an efficient manner. Moreover, our generated adversarial examples exhibit\nmodel-agnostic transferability, enabling effective adversarial attacks on\nadvanced victim models.",
        "updated": "2024-02-02 08:46:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.01227v1"
    },
    {
        "title": "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models",
        "authors": "Mohammadreza PourrezaDavood Rafiei",
        "links": "http://arxiv.org/abs/2402.01117v1",
        "entry_id": "http://arxiv.org/abs/2402.01117v1",
        "pdf_url": "http://arxiv.org/pdf/2402.01117v1",
        "summary": "Leading models for the text-to-SQL task heavily rely on proprietary Large\nLanguage Models (LLMs), posing concerns over data privacy. Closing the\nperformance gap between small open-source models and large proprietary models\nis crucial to mitigate this reliance. To this end, we introduce a novel\ntwo-stage fine-tuning approach that decomposes the task into two simpler tasks.\nThrough comprehensive evaluation on two large cross-domain datasets and two\nsmall LLMs, we show that this approach improves execution accuracy by 3 to 7\npercent, effectively aligning the performance of open-source models with their\nproprietary counterparts.",
        "updated": "2024-02-02 03:21:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.01117v1"
    }
]