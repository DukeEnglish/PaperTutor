Hyperparameter tuning via trajectory predictions:
Stochastic prox-linear methods in matrix sensing
MengqiLou⋆ ,KabirAladinVerchand⋆,‡,AshwinPananjady⋆,†
Schoolsof⋆IndustrialandSystemsEngineeringand†ElectricalandComputerEngineering,
GeorgiaInstituteofTechnology
‡StatisticalLaboratory,UniversityofCambridge
February5,2024
Abstract
Motivatedbythedesiretounderstandstochasticalgorithmsfornonconvexoptimizationthatare
robusttotheirhyperparameterchoices,weanalyzeamini-batchedprox-lineariterativealgorithmfor
theproblemofrecoveringanunknownrank-1matrixfromrank-1Gaussianmeasurementscorrupted
bynoise. Wederiveadeterministicrecursionthatpredictstheerrorofthismethodandshow,using
anon-asymptoticframework,thatthispredictionisaccurateforanybatch-sizeandalargerangeof
step-sizes. Inparticular,ouranalysisrevealsthatthismethod,thoughstochastic,convergeslinearly
fromalocalinitializationwithafixedstep-sizetoastatisticalerrorfloor. Ouranalysisalsoexposes
how the batch-size, step-size, and noise level affect the (linear) convergence rate and the eventual
statisticalestimationerror,andwedemonstratehowtouseourdeterministicpredictionstoperform
hyperparameter tuning (e.g. step-size and batch-size selection) without ever running the method.
Onatechnicallevel,ouranalysisisenabledinpartbyshowingthatthefluctuationsoftheempirical
iteratesaroundourdeterministicpredictionsscalewiththeerrorofthepreviousiterate.
1 Introduction
Weconsiderestimatingarankonematrixµ⋆ν
⋆⊤
Rd ×dfromonline,i.i.d.observations(y i,x i,z i)drawn
∈
accordingtothestatisticalmodel
y
i
= x i,µ⋆ z i,ν⋆ +ϵ i. (1)
⟨ ⟩·⟨ ⟩
Here x Rd and z Rd are sensing vectors, typically drawn i.i.d. from some distribution, and ϵ
i i i
∈ ∈
denoteszero-meannoiseinthemeasurements.Thismodelfindsapplicationsindiverseareasofscience
andengineering,includingastronomy,medicalimaging,andcommunications(JefferiesandChristou,
1993; Wang and Poor, 1998; Campisi and Egiazarian, 2017). For instance, it forms an example of the
blind deconvolution problem in statistical signal processing (see, e.g., Recht et al. (2010); Ahmed et al.
(2013)andthereferencesthereinforseveralapplicationsofthisproblem).
We are interested in the model-fitting problem, and the natural least squares population objective
L : Rd Rd R (corresponding to the scaled negative log-likelihood of our observations under
× →
Gaussiannoise)canbewrittenas
L(µ,ν)
=E(cid:8)(cid:0)
y x,µ z,ν
(cid:1)2(cid:9)
, (2)
−⟨ ⟩·⟨ ⟩
wheretheconditionaldistributionofygivenx,zisasspecifiedbythemodel(1). NotethatLisajointly
nonconvex function in the parameters (µ,ν). With the goal of minimizing the population loss L, we
consideronlinealgorithmswhichoperateonamini-batchofsizemwith1 m dforwhichwedraw
≤ ≤
afresh1setofobservations y,x,z m ateachiterationandformtheaveragedloss
{ i i i }i=1
L (µ,ν) =
1 ∑m (cid:0)
y x,µ z,ν
(cid:1)2
. (3)
m i i i
m −⟨ ⟩·⟨ ⟩
i=1
1Althoughourindexingofobservationsdoesnotreflectthis,eachmini-batchisdrawnindependentlyofallotherobservations.
1
4202
beF
2
]CO.htam[
1v99510.2042:viXraOurparticularfocusisonanonline,stochasticcompositeoptimizationmethod,whichisamember
of the aProx family (Asi and Duchi, 2019b, Eq. (4)). To elucidate the connection, we write the loss
functionL inEq.(3)asacompositionoftwofunctions
m
L m(µ,ν) = m1(cid:13) (cid:13)F m(µ,ν)(cid:13) (cid:13)2 2, where F m(µ,ν) = y −(Xµ) ⊙(Zν), (4)
where denotestheHadamardproduct,andwecollectresponsesintoavectory = [y y ] as
1 m ⊤
wellas⊙ thesensingvectorsintodatamatricesX = [x x ] Rm d andZ = [z | ··· | z ]
1 m ⊤ × 1 m ⊤
Rm d. Thentheprox-linearupdateforeachiterationt| =· 0·· ,1| ,...,T∈ 1isgivenby | ··· | ∈
×
−
(cid:20) (cid:21) (cid:13) (cid:20) (cid:21)(cid:13)2 (cid:13)(cid:20) (cid:21)(cid:13)2
µ
ν
tt ++ 11 =a µr ,g νm Ri dn m1(cid:13) (cid:13) (cid:13)F m(µ t,ν t)+ ∇F m(µ t,ν t) µ ν− −µ
ν
tt (cid:13) (cid:13)
(cid:13)
2+λ ·(cid:13) (cid:13)
(cid:13)
µ ν− −µ
ν
tt (cid:13) (cid:13)
(cid:13)
2, (5)
∈
where F Rm 2d denotes the Jacobian of F . Here, λ > 0 is a hyperparameter that can be inter-
m × m
∇ ∈
pretedasaninversestep-size. Notethattheprox-linearupdatein(5)encompassescomplexmethods,
e.g.,itisequivalenttotheGauss–Newtonmethodwhenλ =0.
Tosetthestageforouranalysistofollow,wewritetheupdatein(5)inclosedform. Tothisend,we
(cid:2) (cid:3)
denote G
i
= x i⊤µ t,G(cid:101)i = z i⊤ν
t
and a
i⊤
= G(cid:101)ix
i⊤
G iz
i⊤
foreach1
≤
i
≤
m; definethepairofdiagonal
matrices W = diag(Xµ t), W(cid:102) = diag(Zν t) and collect the vectors a
i
into a concatenated data matrix
A = [a
1
a
2
... a m]
⊤
= (cid:2) W(cid:102)X WZ(cid:3) Rm ×2d. Armedwiththisnotation,weexplicitlysolvethe
| | | | ∈
quadraticprogramdefiningtheprox-lineariteratesin(5)toobtain
(cid:20) µ
ν
tt ++ 11 (cid:21) = (cid:0) A⊤A+λmI(cid:1) −1 ·(cid:16) A⊤(cid:0) y+diag(WW(cid:102))(cid:1) +λm ·(cid:20) µ
ν
tt (cid:21)(cid:17) =: Gm,λ(cid:0) [µ
t |
ν t](cid:1) , (6)
wherewehavedefineda(random)updatefunction
m,λ
:R2d R2dforconvenience. NotethatW,W(cid:102)
G →
arediagonalmatrices,andconsequentlydiag(WW(cid:102))isavectorinRm.
1.1 Motivationandmaincontributions
Ourgoalistosharplycharacterizehowtheproblemparametersincludingbatch-size m, inversestep-
sizeλ,andnoiselevelσaffecttheconvergencebehavioroftheprox-linearupdateinEq.(6). Webegin
bysituatingourresultsinthecontextofamotivatingnumericalexperiment.
Motivation#1: Fine-grainedconvergencephenomena. Setthedimensiontod = 200andnoiselevel
toσ =0.01. Weinitializethealgorithmlocallyaroundthegroundtruthparameters,settingbothµ and
0
ν
0
suchthat ∥µ
0
−µ⋆ ∥2
2
= ∥ν
0
−ν⋆ ∥2
2
= 0.02. Subsequently,forafixedbatch-sizem,inversestep-size
λ and number of iterations T, we run the stochastic prox-linear method in (5). At each iteration, we
sample independent data (x,z )m i.i.d. N(0,I ) and noise (ϵ)m i.i.d. N(0,σ2) to form the responses
i i i=1 ∼ d i i=1 ∼
(y )m accordingtothemodel(1).
i i=1
Weisolatetheeffectofbatch-sizeandinversestep-sizebyconsideringtwoexperiments. Inthefirst,
wevarythebatch-sizem =8,16,32. Foreachbatch-size,wesetλ =100foreachiterationt 1500and
≤
subsequentlyincreasetheinversestep-sizeasλ =100+tfort >1500. Increasingtheinversestep-size
inthismannercorrespondstoalinearlydecayingstep-size. Wethenplot,inFigure1a,theestimation
error2Err overiterations.Inoursecondexperiment,wefixthebatch-sizetom =32andsetthreeinitial
t
inversestep-sizesλ = 1,10,100. Foreachinitialinversestep-sizeλ ,wethenfixtheinversestep-size
0 0
λ = λ +t 1 t > 1500 . Thatis,asbefore,wedecaythestep-sizelinearlyafteraconstantnumberof
t 0
· { }
iterations. WeplottheestimationerrorErr overiterationsinFigure1b.
t
In both of the experiments, the method appears to display three distinct phases in its iterations.
In the first phase, the error decays linearly to a point of stagnation. Crucially, both the linear rate of
convergenceaswellaserrorfloorreachedafterthisrapiddecayappeartodependonboththebatch-
sizeaswellasthestep-size. Inthesecondphase, theiteratesstagnateuntilthestep-sizeisdecreased.
Finally,inthethirdphase,theerrordecreasesatasub-linearratewhenthestep-sizeisdecreased.
2ThemetricErr tisequivalenttotheFrobeniusnormerror ∥µtν t⊤−µ⋆ν⋆⊤∥2 Fuptoamultiplicative,universalconstantfactor.
2m = 8 λ = 1
0
10 −2 m = 16 10 −2 λ 0 = 10
m = 32 λ = 100
0
10 3 10 3
− −
10 4 10 4
− −
10 5 10 5
− −
10 6 10 6
− 0 750 1,500 2,250 3,000 − 0 750 1,500 2,250 3,000
Iteration Iteration
(a)σ=10−2, d=200. (b)σ=10−2, d=200.
Figure1. Panel(a)demonstratestheconvergencebehaviorofdifferentbatch-sizesm = 8,16,32. Panel(b)
demonstratestheconvergencebehaviorofdifferentinitialinversestep-sizesλ = 1,10,100. Eachexper-
0
iment consists of 30 independent trials and shaded envelopes denote the interquartile range over the 30
independenttrials.SolidlinesdenotethemedianofErr tovertheindependenttrialsanddashlines(barely
visible)denotethedeterministicpredictederrorErrseq
(seeSection2.3foritsdefinition).
t
Whileseveralrecentresults(see,e.g., DavisandDrusvyatskiy,2019;Chadhaetal.,2022;Asietal.,
2020)havecharacterizedthethirdphaseofsub-linearconvergence,severalquestionsremainregarding
thefirsttwophases. Forinstance,theonlylinearratesofconvergenceforstochasticprox-lineariterates
that we are aware of require either (i.) noiseless observations in which σ = 0 (Asi and Duchi, 2019a;
Chadhaetal.,2022)or(ii.) sharpgrowth(Davisetal.,2023,Eq. (2.4)). Wenotethatneitherdoestheloss
in(4)enjoysharpgrowtharounditsminimizers,norisσ =0intheexperimentsshowninFigure1.
Motivatedbytheseobservations,wefocusontheinitialphaseandcharacterizethedependenceof
boththelinearrateofconvergenceaswellastheinitialnoiseflooronthebatch-sizem,theinitialinverse
step-sizeλ,andthelevelofnoiseσ.
Motivation #2: Efficient hyperparameter tuning. The experiment results in Figure 1 demonstrates
the trade-offs for the choice of batch-size m and inverse step-size λ 1. For example, for larger m, the
−
methodenjoysafasterconvergenceratebutalsoincursalargercomputationalcostateachiteration;on
theotherhand,forsmallerλ,themethodenjoysafasterconvergenceratebutstagnatesatalargererror
floor. In order to achieve both computational efficiency and estimation accuracy, a practitioner needs
to jointly tune the batch-size m and inverse step-size λ 1. One approach is via hyperparameter tuning
−
whichconsistsofselectingasequenceofcombinationsofmandλ,subsequentlyrunningtheupdate(6)
for each choice of m and λ, and selecting the m and λ whose empirical performance is the best. The
aforementionedapproachcanbecomputationallyexpensiveifwewanttotestmanychoicesofmand
λ for a high-dimensional problem. Motivated by this, we develop a low-dimensional, deterministic
trajectory prediction that can be run efficiently and without using any data. The produced trajectory
predictionscanthenbeusedtotunethehyperparametersinanofflinefashion.
Main Contributions. In order to describe our main contributions, we first require some definitions
andassumptions. Recallthatourgoalistoestimatetheground-truthpair (µ⋆,ν⋆). Toassessthecon-
vergenceoftheprox-lineariterationstothispair,weconsiderafour-dimensionalstateα : Rd R,β :
→
Rd R, (cid:101)α :Rd R,andβ(cid:101):Rd R,whosecomponentswedefineas
→ → →
α(µ) := ⟨µ,µ⋆ ⟩, β(µ) := ∥P µ⊥ ⋆µ ∥2, (cid:101)α(ν) := ⟨ν,ν⋆ ⟩, β(cid:101)(ν) := ∥P ν⊥ ⋆ν ∥2. (7)
Usingthis,wedefineourstateattimetasthequadrupleconsistingofcomponents
α
t
= α(µ t), β
t
= β(µ t), (cid:101)α
t
= (cid:101)α(ν t), β(cid:101)t = β(cid:101)(ν t). (8)
3
rrE
t
rrE
tThroughout,wemakethefollowingassumptions.
Assumption1. Thecoefficientvectorsµ⋆,ν⋆ satisfy µ⋆
2
= ν⋆
2
=1.
∥ ∥ ∥ ∥
Assumption2. Thesensingvectorsaredrawnas x,z m
i.i.d.
N(0,I ) N(0,I )andthenoiseas ϵ m
i.i.d.
{ i i }i=1 ∼ d ⊗ d { i }i=1 ∼
N(0,σ2),independentlyofthesensingvectors.
Equippedwiththisnotation, weturnnowtodescriptionsofourmainresults. Inshort, theychar-
acterize how the stochastic prox-linear iterates behave as a function of the batch-size m, the inverse
step-sizeλ,andthenoiselevelσ.
1. Sharp, deterministic predictions which adapt to problem error. Consider running one-step
of the prox-linear update specified by the function
m,λ
(6) starting from a pair (µ♯,ν♯) and let
G
[µ
⊤+
ν +⊤]
⊤
= m,λ([µ♯ ν♯]). For all minibatch-sizes 1 m d and a large range of step-size
| G | ≤ ≤
λ≳(1+σ)d/m,wederiveexplicitdeterministicpredictions(αd +et,βd +et, (cid:101)αd +et,β(cid:101)d +et)(seeSection3.2
fortheirpreciseforms)thatcloselytracktheirempiricalcounterparts. Furthermore,inTheorem1
tofollow,weshowthatwithhighprobability,
max(cid:110)(cid:12) (cid:12)α(µ+) αd +et(cid:12) (cid:12),(cid:12) (cid:12)β(µ+) βd +et(cid:12) (cid:12),(cid:12) (cid:12)(cid:101)α(ν+) (cid:101)αd +et(cid:12) (cid:12),(cid:12) (cid:12)β(cid:101)(ν+) β(cid:101)d +et(cid:12) (cid:12)(cid:111) ≲ ∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥F+σ ,
− − − − λ√m
≲
where hidespolylogarithmicfactorsind. Notethatthisguaranteeisfullynon-asymptotic,and
provides bounds on the deviation which scale with the estimation error ∥µ♯ν
♯⊤
−µ⋆ν
⋆⊤
∥F. This,
inturn,enablesatransparentconvergenceanalysisoftheiterationsforallnoiselevelsσ 0. See
≥
Section2.1foradetaileddiscussion.
2. Fine-grained convergence analysis. We use our deterministic predictions to execute an iterate-
by-iterateanalysisofthestochasticprox-linearalgorithmfromalocalinitialization. Thisanalysis
revealsseveralfine-grainedpropertiesoftheconvergencebehavior.Inparticular,forthestep-size
choiceλ 1 m/(d(1+σ2))andbatch-sizem≳polylog(d),weshowthatittakes
−
≍
(cid:16)d(1+σ2) (cid:16) 1 (cid:17)(cid:17)
τ = Θ m ·log σ2 iterationstoguarantee ∥µ τν τ⊤ −µ⋆ν ⋆⊤ ∥2 F ≲ σ2.
Thisrevealsalinearspeed-upinthebatch-sizemforallnoiselevelsσ 0. Asaconsequence,the
≥
totalsamplecomplexityforreachingestimationerrorσ2isO(d(1+σ2)log(1/σ2)). Moreover,for
otherstep-sizechoicesλ 1 ≲ m/(d(1+σ2)),ittakes
−
(cid:16) (cid:16)λm(cid:17)(cid:17) σ2d
τ = Θ λ ·log dσ2 iterationstoguarantee ∥µ τν τ⊤ −µ⋆ν ⋆⊤ ∥2 F ≲ λm,
which in turn quantifies the dependence of the convergence behavior on the step-size λ 1. In
−
particular,bydecreasingthestep-size λ 1,theiterationcomplexityincreaseswhiletheeventual
−
estimationerrordecreases. Weemphasizethatourguaranteesoniterationcomplexityaresharp
in the sense that our bounds provide both upper and lower bounds on the rate of convergence.
SeeTheorem2foraprecisestatementandSection2.2foradetaileddiscussion.
1.2 Relatedwork
We situate our results within the broader literature on stochastic aProx methods as well as learning
dynamics,beginningwithstochasticaProxmethods.
Stochastic aProx methods Several recent works have focused on convergence guarantees for aProx
methods.DuchiandRuan(2018)provedthatthesemethodsconvergetofirst-orderstationarypointsfor
weaklyconvexfunctions.AsiandDuchi(2019a)showedthesemethodsexhibitrobustnesstoproblem
familiesandalgorithmicparameters. DavisandDrusvyatskiy(2019)establishedthesublinearconver-
gencerateO(T 1/4)forweaklyconvexfunctions,whereTisthenumberofiterations. Inturn,Asiand
−
Duchi(2019b)identifiedtheclassofinterpolationproblems—forwhicheachcomponentfunctioninthe
empirical3 loss (3) shares a minimizer—as a benign class under which stochastic prox-linear methods
3Some of these papers define a stronger interpolation condition that depends on the population loss (2), but in both the
empiricalandpopulationdefinitions,theinterpolationconditionisonlysatisfiedinourproblemwhenσ=0.
4enjoy linear convergence under expected strong growth conditions on the stochastic objective. Note
thatinoursetting,anyinterpolationproblemisnoiseless,withσ =0.Asietal.(2020)andChadhaetal.
(2022) extended these methods to accommodate mini-batches of size m and established the sublinear
convergence rate O((Tm) 1/2) for convex functions, as well as a linear convergence rate for interpo-
−
lationproblemsunderaso-called γ-growthcondition(Chadhaetal.,2022, Ass. 4).Davisetal.(2023)
proved that these methods with geometric step decay enjoy local linear rate of convergence for non-
convexproblemsthatsatisfythesharpgrowthcondition. Wealsomentionthat—undertheassumption
that the component functions are strongly convex and smooth—Vaswani et al. (2022) established an
initial linear convergence rate of SGD (not the prox-linear method) under a step-size schedule which
isbothnoiseadaptiveandproblemparameteradaptive. Theaforementionedresultsareallgeometric
in nature and are not comparable with our own, which are based on a statistical model that does not
alwayssatisfytheirconditions.Ontheonehand,ourresultsareprovedforacanonicalstatisticalmodel
that possessesits own problem-specific, geometric structure. Onthe other hand, they aremuch more
fine-grainedandsharp,andexposeseveralphenomenainadditiontothosementionedabove.Wedefer
adetailedcomparisontothediscussionfollowingTheorem2inSection2.2.
Learning dynamics and trajectory analyses Another line of relevant literature focuses on deriving
learningdynamicsforiterativealgorithms. Inparticular,onelineofworkcharacterizedthedynamics
ofSGDforleastsquaresproblems(Paquetteetal.,2021;PaquetteandPaquette,2021;Balasubramanian
et al., 2023) and for non-convex problems (Collins-Woodfin et al., 2023; Ben Arous et al., 2021; Arous
etal.,2023).Althoughthesepreviousworksprovidepowerfulmachinery,theydonotstraightforwardly
applytocomplexalgorithmssuchastheprox-linearmethod.Toseethismoreclearly,notethattheSGD
updatewithstep-sizeγforourlossL (µ,ν)(4)canbewrittenas
m
(cid:20) (cid:21) (cid:20) (cid:21)
µ t+1 = µ t γ L (µ ,ν).
ν t+1 ν t − ·∇ m t t
SincetheSGDupdateprovidesasimplerelationshipbetweenthenextiterate(µ t+1,ν t+1)andthepre-
viousiterate(µ ,ν),onecandirectlyapplyaTaylorexpansiontorelatethestatisticsofthetwoiterates,
t t
which forms an important step in the works Collins-Woodfin et al. (2023); Arous et al. (2023). How-
ever, the prox-linear update (6) is more complicated than SGD, e.g., there is a complicated random
matrixinverse(A A+λmI) 1,whenceitbecomesdifficulttoapplytheTaylorexpansiontricktode-
⊤ −
rivelearningdynamicsfortheprox-linearupdate. Anotherlineofworkcharacterizedtheasymptotic
behaviorof“generalized”first-ordermethods(Celentanoetal.,2020,2021)usingtechniquesfromthe
literatureofapproximatemessagepassingorAMP(Donohoetal.,2009;BayatiandMontanari,2011)in
theasymptoticregimewherem,d +∞andm/d δ (0,+∞). Theseanalysesofferthedistinctad-
→ → ∈
vantagethatthemethodneednotbeonline,andsamplesmaybere-used. However,theydonotapply
directlytohigher-ordermethodslikethemethodconsideredinthispaper. Moreover,weareinterested
inthenon-asymptoticregimeinwhich1 m danddisfinite. Ournon-asymptoticanalysisallows
≤ ≤
ustobypasstheso-called“extensive”batch-sizeassumptioninwhichthebatch-size m scaleslinearly
withthedimension d (see, e.g.,Gerbelotetal.,2022). Themostrelatedrecentworkisthesequenceof
papers (Chandrasekher et al., 2022, 2023) in which the authors derived deterministic predictions be-
yondfirst-ordermethods. However,thesepredictionsrequirethebatch-sizem dandthuscannotbe
≥
directlyappliedtoanalyzemini-batchedalgorithms. Additionally,thesepredictionsareonlyaccurate
uptofluctuationsoforderm 1/2,whichmeansthatthepredictionsbecomemeaninglesswhentheer-
−
rorofinterestfallsbelowthelevelm 1/2. Thisbecomesespeciallyproblematicforanalyzingiterative
−
algorithmsforlownoiseproblems(σ 0)andforsmallbatch-sizesm.
↓
1.3 Notationandorganization
Welet[d]denotethesetofnaturalnumberslessthanorequaltod,let1 denotetheindicatorfunction
andlet d 1 = v Rd v = 1 . Fortwosequencesofnon-nega{ t· i} vereals f and g ,
− 2 n n 1 n n 1
S ≲ { ∈ | ∥ ∥ } { } ≥ { } ≥
weuse f g toindicatethatthereisauniversalpositiveconstantCsuchthat f Cg foralln 1.
n n n n
≳ ≲ ≤≲ ≳≥
The relation f g indicates that g f , and we say that f g if both f g and f g
n n n n n n n n n n
hold simultaneously. We also use standard order notation f = ≍ (g ) to indicate that f ≲ g and
n n n n
O
f
n
= (cid:101)(g n)toindicatethat f
n
≲ g nlogcn,forauniversalconstantc >0. Wesaythat f
n
= Ω(g n)(resp.
O
5f n = Ω (cid:101)(g n))ifg n = (f n)(resp. g n = (cid:101)(f n)). Thenotation f n = o(g n)isusedwhenlim n ∞ f n/g n =
0, and f = ω(g ) wO hen g = o(f ). TO hroughout, we use c,C to denote universal positiv→ e constants,
n n n n
andtheirvaluesmaychangefromlinetoline. WedenotebyN(µ,Σ)anormaldistributionwithmean
µ and covariance matrix Σ. We say that X
( =d)
Y for two random variables X and Y that are equal in
distribution.
Theremainderofthepaperisorganizedasfollows.WeprovideourmainresultsinSection2.InSec-
tion2.1,weprovideourone-stepdeterministicpredictionsfortheprox-linearupdate(seeTheorem1);
inSection2.2,weuseourone-stepupdatestoproveasharplinearconvergenceresultfortheprox-linear
updatefromalocalinitialization(seeTheorem2);andinSection2.3,wepresentnumericalexperiments
whichdemonstratehowourdeterministicpredictionscanbeusedtotunethehyperparameterswithout
runningtheprox-linearupdate.InSection3,weprovideaheuristiccalculationtodemonstratethetech-
niquesforderivingthedeterministicpredictionsandprovidetheexplicitformulasofthedeterministic
predictions. WeproveTheorem1andTheorem2inSections4and5, respectively. Proofsoftechnical
lemmasarepostponedtotheappendices.
2 Main Results
Inthissection,weprovideourmainresultsonthestochasticprox-linearmethodin(6). InSection2.1,
weprovideanon-asymptotic,one-stepguarantee. Then,inSection2.2,weleveragethisone-stepguar-
anteetoproveatwo-sidedconvergenceguaranteefortheprox-linearmethod.
2.1 Deterministicone-steppredictions
Considerapair (µ♯,ν♯) andlet (α♯,β♯, (cid:101)α♯,β(cid:101)♯) denoteitscorrespondingstateasdefinedinEq.(7). The
deterministicpredictions—startingfromthepair(µ♯,ν♯)—arespecifiedas
αd +et = F m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯), (βd +et)2 = (cid:0) H m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯)(cid:1)2+S m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯), (9a)
(cid:101)αd +et = F(cid:101)m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯), (β(cid:101)d +et)2 = (cid:0) H(cid:101)m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯)(cid:1)2+S(cid:101)m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯), (9b)
where F m,d,σ,λ, F(cid:101)m,d,σ,λ, H m,d,σ,λ, H(cid:101)m,d,σ,λ, S m,d,σ,λ, S(cid:101)m,d,σ,λ : R4
→
R are functions of the states
(α♯,β♯, (cid:101)α♯,β(cid:101)♯), which are also parameterized by the tuple of problem-specific parameters (m,d,σ,λ).
TheirexplicitexpressionsareprovidedinSection3.2.
Westateourone-stepguaranteeintermsofthequantityErr ♯,definedas
Err ♯ = (α♯(cid:101)α♯ −1)2+β2 ♯+β(cid:101)2 ♯. (10)
Wenote(seeLemma19)thatifβ♯,β(cid:101)♯ 0.1and0.3 µ♯ 2, ν♯
2
1.7,then
≤ ≤ ∥ ∥ ∥ ∥ ≤
1
5 ·∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F ≤Err ♯ ≤12.5 ·∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F, (11)
sothatthereadershouldthinkofErr ♯ asequivalentto ∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F uptoauniversalconstant. We
arenowpoisedtostateourmainresultforthissection,whichshowsthatthetupleofrandomvariables
(α(µ+),β(µ+),α(ν+),β(ν+))iscloselytrackedbythedeterministicpredictionsinEq.(9).
Theorem 1. Suppose data are drawn from the model (1) and let Assumptions 1 and 2 hold. Let µ♯,ν♯ Rd
∈
satisfy K
1
µ♯ 2, ν♯
2
K
2
for a pair of universal, positive constants K
1
K 2. Consider the updates
≤ ∥ ∥ ∥ ∥ ≤ (cid:0) (cid:1) ≤
specifiedbythefunction
m,λ
(6)andlet[µ+ ν+]
⊤
=
m,λ
[µ♯ ν♯] . Usetheshorthand(α+,β+,α+,β(cid:101)+) =
G | G |
(α(µ+),β(µ+),α(ν+),β(ν+)) (7) and let the deterministic predictions (αd +et,βd +et, (cid:101)αd +et,β(cid:101)d +et) be as in Eq. (9).
Then,thereexistpositiveconstantsd ,C ,C ,dependingonlyonK andK ,suchthatfor
0 1 2 1 2
(1+σ)d
1 m d, λ C , and d d ,
1 0
≤ ≤ ≥ m ≥
thefollowingholdwithprobabilityatleast1 d 20.
−
−
6(a) Theparallelcomponentssatisfy
(cid:12)
(cid:12)α+
−αd +et(cid:12)
(cid:12)
∨(cid:12)
(cid:12)(cid:101)α+
−(cid:101)αd +et(cid:12)
(cid:12) ≤C
2max(cid:26)(cid:112) Er λr ♯+σ
·
lo √g6 m(d)
,
d−30(cid:27)
. (12a)
(b) Theperpendicularcomponentssatisfy
(cid:12) (cid:12)β2 + −(βd +et)2(cid:12) (cid:12) ∨(cid:12) (cid:12)β(cid:101)2 + −(β(cid:101)d +et)2(cid:12) (cid:12) ≤C 2max(cid:26)Err ♯ λ+σ2
·
lo √g6 m(d) , d−30(cid:27) . (12b)
WeprovidetheproofofTheorem1inSection4. Notethatwehavemadenoattempttooptimizethe
logfactorsineitherdeviationcomponent,andthesecanlikelybemadesmaller. Somediscussionofthe
result appears below; we defer commentary on the proof technique to Section 3.1 in which a detailed
overviewisprovided.
First,wenotethatourresultholdsforanybatch-sizem 1,2,...,d .Thisbridgesthegapbetween
∈ { }
deterministicpredictionsforsinglesampleandconstantbatch-sizemethodswhichrelyoncontrolling
stochastic processes (Tan and Vershynin, 2023; Ben Arous et al., 2021) or equivalent differential equa-
tions(Paquetteetal.,2021)andtheextensivebatch-sizesettinginwhichm d(Gerbelotetal.,2022).
≍
WhiletheseworksallstudythedynamicsofSGDorrelatedfirst-ordermethods,itisinstructivetomake
aqualitativecomparisoneventhoughourresultholdsforthe(significantlymorecomplex)prox-linear
iterations.
To illustrate, consider two cases. Recalling that our inverse step-size λ may scale as λ d/m,
≍
considerabatch-sizeofm =1toobtain
(cid:12) (cid:12)α+ −αd +et(cid:12) (cid:12) ∨(cid:12) (cid:12)(cid:101)α+ −(cid:101)αd +et(cid:12) (cid:12) ≤C 2max(cid:26)(cid:112) (1E +rr ♯ σ+ )dσ ·log6(d), d−30(cid:27) ,
andsimilarlyfortheperpendicularcomponentβ.Bycontrast,ifweconsideralargebatch-sizeofm d,
≍
ourboundsreadas
(cid:12)
(cid:12)α+
−αd +et(cid:12)
(cid:12)
∨(cid:12)
(cid:12)(cid:101)α+
−(cid:101)αd +et(cid:12)
(cid:12) ≤C
2max(cid:26)(cid:112) E 1r +r ♯ σ+σ
·
log √6 d(d)
,
d−30(cid:27)
.
That is, for constant batch-size, the fluctuations scale as 1/d, whereas for batch-sizes of commen-
≍
surate order with the dimension, our fluctuations are larger and scale as 1/√d. As we will see in
≍
thesequel,thisdistinctioninbehaviorofthefluctuationreflectstherelativetime-scalesonwhichthese
boundsarerequiredtoholdtoensureconvergence.
Second,recallthatErr ♯ ≲ ∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F (11)toaiddiscussion. Theorem1showsthatthedevia-
tionofthecomponentsα+andβ+aroundtheirdeterministicpredictionsscaleswithboththeestimation
error ∥µ♯ν
♯⊤
−µ⋆ν
⋆⊤
∥Faswellasthenoiselevelσ.Letusnowcomparethisguaranteeexplicitlywiththe
previousresultsChandrasekheretal.(2023,Theorem1)andChandrasekheretal.(2022,Theorem1),set-
tingσ =0andm dtotransparentlyfacilitatethecomparison.TheguaranteesinChandrasekheretal.
≍
(2023,Theorem1)andChandrasekheretal.(2022,Theorem1)scaleas1/d1/4 and1/√d,respectively,
sothatthefluctuationboundsdominatetheerrorachievedbythealgorithmassoonastheerrorissmall
(cid:112)
enough. Bycontrast,ourguaranteescalesas Err ♯/d,whichisalwaysoflowerorderascomparedto
(cid:112)
Err ♯. Thisensuresthataswerunthealgorithm,thefluctuationsoftheempiricalstatesaroundtheir
deterministiccounterpartswilldecreaseatthesamerateastheestimationerrorofthemethod,which
inturnfacilitatesourconvergenceanalysisoftheprox-linearupdateinthelownoiseregime.
Finally, we note that the deterministic predictions in Eq. (9) can be computed efficiently since we
onlyrequiresolutionstotwo-dimensionalfixedpointequationsandsomescalarcalculations(seeSec-
tion3.2fortheexplicitformulas). Later,inSection2.3,weusetheseone-stepdeterministicpredictions
toobtainafulltrajectoryprediction.
2.2 Convergenceresult
Inordertostateourconvergenceguarantee,wedefinetheempiricalerroras
Err
t
= (α t(cid:101)α
t
−1)2+β2
t
+β(cid:101)2 t, forall 0
≤
t
≤
T. (13)
Wealsorequireanassumptionontheinitialization.
7Assumption3(Initialization). Theinitializationµ ,ν satisfiesboth
0 0
Err K and 0.5 µ , ν 1.5, (14)
0 0 0 2 0 2
≤ ≤ ∥ ∥ ∥ ∥ ≤
forK asmallenough,universal,positiveconstant.
0
Equippedwiththisassumption,westateourmainconvergenceresult.
Theorem2. SupposeAssumptions1–3holdandconsidertheobservationmodel(1)andmini-batchedprox-linear
updatesin(6)runforTiterations. Thereexistsatupleofuniversal,positiveconstants(d ,c ,c ,C,C ,C )such
0 1 2 1 2
thatthefollowingstatementholdswithprobabilityatleast1 (T+1)d 18: Iftheinversestep-sizeλ,thebatch-
−
−
sizem,dimensiond,andnumberofiterationsTsatisfy
C(1+σ2)d
λ , C(1+σ4)log12(d) m d, (15a)
≥ m ≤ ≤
λ (cid:16) (cid:16)λm √m (cid:17)(cid:17)
d d , 0 T log min , , (15b)
≥ 0 ≤ ≤ c
1
σ2d σ2log6(d)
thenwehaveforall0 t T,
≤ ≤
(cid:16) c (cid:17) C σ2d C log6(d)σ2 (cid:16) c (cid:17) C σ2d C log6(d)σ2
1
−
λ2 ·Err t+ λ2
2m −
1
λ√m
≤Err t+1
≤
1
−
λ1 ·Err t+ λ1
2m
+ 1
λ√m
. (16)
Asbefore,wehavenotoptimizedconstantorpolylogarithmicfactors,whichcanlikelybeimproved.
Toaiddiscussion,recallthatinequality(11)holdsforalliterations,sothatthereadershouldthinkthat
Err
t
isequivalent(uptoaconstant)totheerror ∥µ tν
t⊤
−µ⋆ν
⋆⊤
∥2 F. Afewremarksfollow.
First, we explain the conditions required by Theorem 2. Note that condition (14) is equivalent to
a local initialization requirement, i.e., the initial estimation error Err is smaller than a universal con-
0
stant and the initial estimators µ ,ν are of constant norm. Such an assumption is typically required
0 0
for non-convex problems to guarantee linear convergence (see, e.g., Chi et al., 2019, as an example).
Eq.(15a)specifiesaconditionontheinversestep-sizeλandbatch-sizem. Notethatwhileourone-step
predictions(Theorem1)holdforanybatch-size1 m d,ourconvergenceguaranteesinTheorem1
≤ ≤
requirebatch-sizeswhichscalepolylogarithmicallyind,andthusTheorem1doesnotcoverthepurely
stochasticcasem =1. Condition(15b)specifiesanupperboundofthenumberofiterationsT,whichis
largeenoughtoguaranteethattheiteratesconvergetoanoisefloor.
Second, we simplify the convergence guarantee for the noiseless case. By setting σ = 0 and λ =
Cd/m,Eq.(16)simplifiesto
(cid:16) c m(cid:17) (cid:16) c m(cid:17)
1 2 Err t Err t+1 1 1 Err t. (17)
− Cd · ≤ ≤ − Cd ·
Thisestablishesalinearconvergenceguaranteeandshowsthattheerrordecreasesatafasterrateasthe
batch-sizemincreases. TheupperboundinEq.(17)recoverstheguaranteesofAsiandDuchi(2019b);
Asietal.(2020);Chadhaetal.(2022)fortheinterpolationversionofourproblem,whilealsoproviding
amatchinglowerboundontheconvergencerate.
Third,weturntoageneralnoiselevelσ > 0. Theorem2impliesthattheprox-linearupdateadapts
to problem difficulty in terms of the rate at which it converges (Chandrasekher et al., 2022; Agarwal
etal.,2012)andenjoysalinearspeed-upinbatch-size(Asietal.,2020;Chadhaetal.,2022).Inparticular,
bysettingλ =Cd(1+σ2)/mand(1+σ4)log12(d) m d,inequality(16)implies
≪ ≤
(cid:16) c m (cid:17) C σ2d (cid:16) c m (cid:17) 2C σ2d
1
−
C(1+2
σ2)d
·Err t+ 2λ2
2m
≤Err t+1
≤
1
−
C(1+1
σ2)d
·Err t+ λ1
2m
. (18)
Consequently,startingfromalocalinitializationsatisfyinginequality(14)andrunningtheprox-linear
updatefor
(cid:16)(1+σ2)d (cid:16)Err (cid:17)(cid:17)
τ = Θ log 0 iterations, weobtain Err ≲ σ2. (19)
m σ2 τ
8Thesandwichrelations(18)and(19)establishsharpupperandlowerboundsbothontheconvergence
rateanditerationcomplexityoftheprox-linearupdate. Notetheexplicitdependenceontheproblem
parameters,includingnoise-dependentconvergencerates. Weillustratethisdifferenceinconvergence
behavior in Figure 2 where we consider m = 4,8,16,32 and λ = (1+σ2)d/m, noting the monotone
relationship(inm)inthespeedofconvergence.
Fourth,Theorem2revealstherobustnessofchoicesofλ(AsiandDuchi,2019a)andhowitaffects
theconvergencebehavior. Inparticular,aslongaswechooseλ C(1+σ2)d/m,inequality(16)holds,
≥
sothatstartingbysatisfyinginequality(14)andrunningtheprox-linearupdatefor
(cid:18) (cid:18) (cid:26) λm √m (cid:27)(cid:19)(cid:19) σ2d log6(d)σ2
τ = Θ λlog Err min , iterations,wehaveErr ≲ + . (20)
0 · σ2d σ2log6(d) τ λm √m
Inequality(20)revealsatensionbetweenthenoisefloorreachedandthespeedofconvergencegoverned
bytheinversestep-sizeλ.Inparticular,asλincreases(i.e.,step-sizedecreases),theiterationcomplexity
increaseswhiletheeventualerrorErr decreases. Weillustratethisdifferenceinconvergencebehavior
τ
inFigure3whereweconsiderλ = 1,10,100,200andm = 32,notingthemonotonerelationship(inλ)
inthespeedofconvergenceandalsointheeventualerrorfloor.
Finally, let us concretely situate our contribution in relation to recent works studying aProx meth-
ods(AsiandDuchi,2019b,Eq. (4)). Aspreviouslymentioned,forinterpolationproblems(correspond-
ingtoσ =0inourcase),Chadhaetal.(2022,Proposition1)andAsietal.(2020,Theorem2)provethat
aProxmethodsenjoylinearconvergenceandenjoyalinearspeedupinthebatch-sizem. Wenotethat
theseresultsholdinamoregeneralsetting,whereasoursarespecifictotheproblemathand. Specializ-
ingtoprox-linearmethodsforrank-onematrixsensing,wecomplementandimprovetheirguarantees
along two axes. First, our result shows there is a linear speed up for all noise levels σ 0. Sec-
≥
ond,weproveamethod-specificmatchinglowerboundontheiterationcomplexity,showingthatthe
speed-upbyincreasingbatch-sizecanbenobetterthanlinear. Inacomplementarylineofwork,Davis
andDrusvyatskiy(2019,Theorem4.1)showsthatthepopulationlossfunctionvalueoftheaverageof
prox-linear iterates converges to its minimal value at a sublinear rateO(T 1/2). Our result improves
−
theirguaranteeinthesensethattheiteratesexhibitlinearconvergencetoanoise-dominatedneighbor
of the ground truth (µ⋆,ν⋆), and characterizes the size of this neighborhood. Asi and Duchi (2019b,
Proposition5)alsoobtainedasimilarlinearconvergenceguaranteeforstrongly-convexstochasticloss
functionswhileourstochasticlossL isnon-convex.Davisetal.(2023)provedthataProxmethodswith
m
geometricstepdecayenjoyalocallinearrateofconvergencefornon-convexproblemsthatsatisfythe
sharpgrowthcondition,butourpopulationlossLdoesnotsatisfythesharpgrowthconditioninDavis
etal.(2023,Eq. (2.4)).
WeprovidetheproofsofTheorem2andtheconsequentinequalities(18),(19)and(20)inSection5.
Ourprooftechniqueproceedsintwoconceptuallysimplebutanalyticallyinvolvedsteps. First,weap-
plytheone-stepupdatesfromTheorem1toreducethecomplexityfromstudyingahigh-dimensional,
random iteration to studying a four-dimensional, deterministic recursion. Second, we show that con-
vergence properties suggested by the deterministic updates (9) are not affected by the fluctuations of
theempiricalstatesaroundtheirpredictionswhenthebatch-sizemislargeenough.
2.3 Trajectorypredictionsandapplicationtohyperparametertuning
In Theorem 1, we derived one-step, deterministic predictions of the update and in turn used these
predictions to obtain concrete convergence guarantees in Theorem 2. In this section, we demonstrate
howtoobtainafulltrajectorypredictionandusethistotunethepairofhyperparameters(m,λ).
2.3.1 Obtainingatrajectoryprediction
Consider an initialization (µ 0,ν 0) Rd Rd and use this to construct an initial state (α 0,β 0, (cid:101)α 0,β(cid:101)0).
∈ ×
Then, giventhetupleofparameters (m,d,σ,λ), werecalltheexplicitformulaeofthepredictionfunc-
tionsF m,d,σ,λ,F(cid:101)m,d,σ,λ,H m,d,σ,λ,H(cid:101)m,d,σ,λ,S m,d,σ,λ,S(cid:101)m,d,σ,λ :R4 →RinSection3.2andusethesetodefinea
deterministicmap :R4 R4,definedas
Tm,d,σ,λ
→
Tm,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1) = (cid:0) αdet ,βdet , (cid:101)αdet ,β(cid:101)det(cid:1) . (21)
9Above,wehaveadditionallyusedthequantities
αdet = F m,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1) , βdet = (cid:16) H m,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1)2+S m,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1)(cid:17) −1/2 ,
(cid:101)αdet = F(cid:101)m,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1) , β(cid:101)det = (cid:16) H(cid:101)m,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1)2+S(cid:101)m,d,σ,λ(cid:0) α,β, (cid:101)α,β(cid:101)(cid:1)(cid:17) −1/2 .
Equipped with the map in (21), we generate a deterministic prediction of the state at iterate t by
T
(cid:8) seq seq seq seq(cid:9)T
iteratingthismapttimes. Thatis,wegenerateadeterministicsequence α
t
,β
t
, (cid:101)α
t
,β(cid:101)
t t=0
with
(cid:0) seq seq seq seq(cid:1)
α
0
,β
0
, (cid:101)α
0
,β(cid:101)
0
= (α 0,β 0, (cid:101)α 0,β(cid:101)0)as
(cid:0) αs teq ,βs teq , (cid:101)αs teq ,β(cid:101)s teq(cid:1) = Tm,d,σ,λ(cid:0) αs teq 1,βs teq 1, (cid:101)αs teq 1,β(cid:101)s teq 1(cid:1) = Tmt ,d,σ,λ(cid:0) αs 0eq ,βs 0eq , (cid:101)αs 0eq ,β(cid:101)s 0eq(cid:1) . (22)
− − − −
Wethendefinethepredictederrorsequence Errseq T as
{ t }t=1
Errs teq
=
(cid:0) αs teq (cid:101)αs teq −1(cid:1)2+(cid:0) βs teq(cid:1)2+(cid:0) β(cid:101)s teq(cid:1)2
. (23)
seq
Note that the sequence Err is the deterministic analog of the empirical error sequence Err de-
{ t } { t }
finedinEq.(13). Wenowusethesetrajectorypredictionstoperformhyperparametertuning.
2.3.2 Hyperparametertuning
Thetrajectorypredictionin(22)anditsassociatederror(23)requireknowledgeofthetupleofparam-
eters (m,d,σ,λ). Given this tuple of parameters, the key advantage of our trajectory prediction lies
in its efficiency: a single trajectory over T = 1000 iterations takes less than 0.25 seconds to generate
foralltheillustratedvaluesofdimension. Ofthisquadrupleofparameters, theuserclearlyhasexact
knowledge of the dimension d, and an estimate of the noise standard deviation σ may be previously
available or estimated via bootstrapping. We would like to use the predictions to tune the batch-size
m and inverse step-size λ in order to ensure rapid convergence to a reasonable error floor—we now
considertwofamiliesofexperimentsthatisolatetheeffectsoftheseparameters.
10 −1
m = 4
10 −1.3
m = 4
m = 8 m = 8
10 −3 m = 16 m = 16
m = 32 m = 32
10 5
−
10 7
− 10 2
−
10 9
−
10 −11 0 1,000 2,000 3,000 4,000 10 −2.4 0 200 400 600 800 1,000
Iteration Iteration
(a)σ=10−5, d=200. (b)σ=0.1, d=200.
Figure2.Lownoise(panel(a))andhighnoise(panel(b))behavioroftheprox-linearmethodforbatch-sizes
m=4,8,16,32andinversestep-sizechoiceλ=(1+σ2)d/m.Eachexperimentstartsfromaninitialization
satisfyingα
0
= (cid:101)α
0
= 0.99and ∥µ
0∥2
= ∥ν
0∥2
= 1andrunstoconvergence. Inpanel(a),eachexperiment
consists of 10 independent trials and the shaded envelopes (m = 4) denote the range over the 10 trials.
In panel (b), each experiment consists of 30 independent trials and the shaded envelopes denote the in-
terquartilerangeoverthe30trials. SolidlinesdenotethemedianoftheempiricalerrorErr t (13)overthe
independenttrialsanddashedlines(barelyvisible)denotethepredictederrorErrseq
(23).
t
1
First,weconsiderafixedinversestep-sizechoiceλ(m) = (1+σ2)d/mandstudytheeffectofvary-
ing the batch-size. To this end, recall from Eq. (19) that this choice of step-size implies an iteration
10
rrE t rrE tcomplexityofΘ (cid:101)((1+σ2)d/m)toreachaparameter-independenterrorfloorofsizeO(cid:101)(σ2). Thatis,the
iteration complexity monotonically decreases as the batch-size increases and there is no tradeoff with
the eventual error floor which is reached. Equipped with a tight characterization of the per iteration
complexity of the method, the user can then compute the iteration complexity for each batch-size m
from our trajectory prediction and use the combination of this information to inform their batch-size
selection. We illustrate this in Figure 2, noting that the user may elect to take a batch-size of m = 16
upon noticing the diminishing gains in iteration complexity purely from observing the deterministic
trajectory. As is clear from the figure, the deterministic and empirical trajectories are nearly indistin-
guishable,sothisdesignchoiceisalsoagoodone(withhighprobability)fortherandomiteratesthat
onewouldobtainbyrunningthealgorithm.
Next,weturntofixingthebatch-sizemandvaryingtheinversestep-sizeλ. RecallfromTheorem2
that,unlikethepreviouscase,thereexistsatension—inducedbytheinversestep-sizeλ—betweenthe
rate of convergence and the size of the noise-dominated neighborhood to which the iterates linearly
converge. Inparticular,largerλyieldsslowerconvergencetoasmallerneighborhood,whereassmaller
λ yields faster convergence albeit to a larger neighborhood. Faced with this, the user may—without
ever running the data—plot several deterministic trajectories, varying λ in each, to determine their
desired trade-off. In Figure 3, we vary λ 1,10,100,200 for a fixed batch-size of m = 32 and in
∈ { }
dimension d = 200. We plot both deterministic trajectories and 30 independent trials of empirical
trajectories,notingthatthedifferenceisbarelyvisible. ZoomingintoFigure3(a),theusermayelectto
pick λ = 10asforlarger λ, theiterationcomplexityincreasesbyanorderofmagnitude, buttheuser
may be satisfied with the eventual error on the order of 10 10. By contrast, in Figure 3(b), the user
−
mayelecttopick λ = 200asthedifferenceiniterationcomplexityismuchsmaller, butthedifference
between 10 2 and 10 3 in eventual error may be non-negligible. Both of these design choices can be
− −
madepurelyfromobservingthedeterministictrajectory,butasguaranteedbyourtheory,theywillbe
suitablefortherandomiterationswithhighprobability.
10 1
−
λ = 1 10 1 λ = 1
10 3 λ = 10 − λ = 10
− λ = 100 λ = 100
λ = 200 λ = 200
10 5
−
10 2 −
10 7
−
10 9
− 10 3
−
10 11
−
10 12
− 0 1,000 2,000 3,000 0 200 400 600 800 1,000
Iteration Iteration
(a)σ=10−5, d=200, m=32. (b)σ=0.1, d=200, m=32.
Figure3.Lownoise(panel(a))andhighnoise(panel(b))behavioroftheprox-linearmethodforbatch-size
m = 32andinversestep-sizeselections λ = 1,10,100,200. Eachexperimentstartsfromaninitialization
satisfyingα
0
= (cid:101)α
0
= 0.99and ∥µ
0∥2
= ∥ν
0∥2
= 1andrunstoconvergence. Inpanel(a),eachexperiment
consistsof10independenttrialsandshadedenvelopes(λ = 200)denotetherangeoverthe10trials. In
panel(b),eachexperimentconsistsof30independenttrialsandshadedenvelopesdenotetheinterquartile
rangeoverthe30trials. SolidlinesdenotethemedianofErr t (13)overtheindependenttrialsanddashed
lines(barelyvisible)denotethepredictederrorErrseq
(23).
t
1
3 A heuristic derivation and explicit formulas
In this section, we first present a heuristic derivation of the deterministic prediction of the parallel
component. Thenwegivethedeferredexplicitformulasofthepredictionfunctions.
11
rrE t rrE t3.1 Aheuristicderivationofthepredictionfortheparallelcomponent
Inthissection,wegiveahigh-leveloverviewofthetechniquesthatweusetoderivethedeterministic
predictions,focusingontheparallelcomponentsα+ and (cid:101)α+. Throughout,weusetheshorthand
L2
♯
= α2
♯
+β2
♯
and (cid:101)L2
♯
= (cid:101)α2
♯
+β(cid:101)2 ♯. (24)
Step 1: Decomposition. Since our updates are online and the data is Gaussian, the current iterate
µ+ is correlated with the past iterates only through the subspace span(µ♯,µ⋆) (and similarly for ν+).
We thus decompose the pair of parallel components (α+, (cid:101)α+) on this subspace using Gram–Schmidt
orthonormalization. Inparticular,considerthefourunitvectors
u =
µ♯
, u =
P µ⊥ ♯µ⋆
, v =
ν♯
and v =
P ν⊥ ♯ν⋆
, (25)
1 2 1 2
∥µ♯
∥2
∥P µ⊥♯µ⋆
∥2
∥ν♯
∥2
∥P ν⊥♯ν⋆
∥2
whereP denotestheprojectionmatrixontotheorthogonalcomplementofone-dimensionalsubspace
µ⊥
♯
spannedbyµ♯(andsimilarlyforP
ν⊥
♯).Wethendecomposeα+and (cid:101)α+onthetwo-dimensionalsubspace
spannedbyu andu as
1 2
α♯ β♯ (cid:101)α♯ β(cid:101)♯
α+ = µ+,u
1
+ µ+,u
2
and (cid:101)α+ = ν+,v
1
+ ν+,v
2
. (26)
L ♯ ·⟨ ⟩ L ♯ ·⟨ ⟩ (cid:101)L ♯ ·⟨ ⟩ (cid:101)L ♯ ·⟨ ⟩
Then, with θ(u i) := ⟨u i,µ+
⟩
(and similarly for θ(cid:101)(v i)), we define deterministic counterparts θ 1det, θ 2det
sothatαd +et = (α♯/L ♯) ·θ 1det+(β♯/L ♯) ·θ 2det (seeSection4.1forexplicitexpressions). Thus,inorderto
boundtheerror α+ αd +et ,itsufficestoboundthedecomposition
| − |
(cid:12) (cid:12)θ(u 1) −θ 1det(cid:12) (cid:12)
≤
(cid:12) (cid:12)θ(u 1) −E[θ(u 1)](cid:12) (cid:12)+(cid:12) (cid:12)E[θ(u 1)] −θ 1det(cid:12) (cid:12),
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Stochasticerror Bias
andsimilarlyforθ(u 2),θ(cid:101)(v 1),θ(cid:101)(v 2).
Step2a: Controllingthestochasticerrorviaaleave-one-sampleoutargument Weviewtherandom
variableθ(u )asafunctionofthedata x ,z ,ϵ m . Indeed,definethefunction f :R(2d+1) m R
1 { k k k }k=1 u1 × →
as f
u1
= ⟨µ+,u
1
⟩. It suffices to show that f
u1
concentrates around its expectation. We then study
the bounded difference property of f using the leave-one-sample out technique and then employ
u1
Warnke’s typical bounded difference inequality (Warnke, 2016, Theorem 2) to facilitate our analysis.
SeeSection4.1.1fordetails.
Step2b: Controllingthebiasviaaleave-one-directionoutargument Inordertocontrolthebias,we
employaleave-one-outtechniquethatissimilarinspirittothatofElKarouietal.(2013).
Let u and u be defined as in Step 1 and let u ,u ,...,u Rd Rd ... Rd denote an or-
1 2 1 2 d
thonormalcompletionofabasisofRd. Define v{ ,v ,...,v }R∈ d R× d ..× . R× d similarly. Wewill
1 2 d
{ } ∈ × × ×
analyzetheeffectofcomputingtheiteratesin(6)uponleavingoutoneof u ,u (aswellas v ,v ). To
1 2 1 2
this end, we define orthogonal leave-one-out matrices O ,O Rd (d 1) whose columns consist of
ui vi
∈
× −
u j j=i and v j j=i respectively. LetW = diag(Xµ♯)andW(cid:102) = diag(Zν♯)anddefinetheleaveoneout
{ }̸ {(cid:104)}̸ (cid:105)
data A
ui,vi
= W(cid:102)XO
ui
WZO
vi
,notingthattheGaussianityof X impliesthat XO
ui
isindependentof
Xu (and similarly for ZO ,Zv). The update in (6) can then be written in terms of the “projection”
i vi i
matrix4
P
ui,vi
:= I −A ui,vi(A⊤ui,viA
ui,vi
+λmI) −1A⊤ui,vi. (27)
4Letusemphasizethatthisisonlyaprojectionmatrixwhenλ = 0, otherwiseitcanbeunderstoodasthecorresponding
quantityinridge-regularizedleastsquaresregression.
12Equippedwiththesepreliminarynotions,wemayutilizetheKKTconditionswhichspecifytheupdates
in(6)(seeSection4.1.2fordetails)toobtainthefollowingapproximations
(cid:16) (cid:17)
E[θ(u 1)]
≈
L
♯+E(cid:40) λLL
2
♯♯
(cid:101)L2
♯α +L♯(cid:101)α
2
♯♯
M−
1((cid:101)L L2
♯
2
♯
+M
(cid:101)L1
2
♯)(cid:41)
and E[θ(u 2)]
≈
(cid:101)(cid:101) Lα 2♯
♯
β
L
♯♯
·E(cid:40)
MM 111 +1
λ(cid:41)
, (28)
wheretherandomvariables M and M aredefinedas
11 1
M =
⟨Xu 2,W(cid:102)P u2,v2W(cid:102)Xu
2 ⟩ and M =
⟨diag(WW(cid:102)),P u1,v1diag(WW(cid:102))
⟩.
11 1
m m
With the closed-form expression in Eq. (28), it suffices to study the concentration of the random vari-
ables M and M .
11 1
Step3:ConcentrationoftheconstituentcomponentsM andM . Wenowderivethetypicalvalues
11 1
around which M and M concentrate. Substituting M and M in Eq. (28) by their typical values
11 1 11 1
yields the formulas of θ 1det and θ 2det and subsequently yields the formula of αd +et as αd +et = (α♯/L ♯)
·
θ 1det+(β♯/L ♯) ·θ 2det.
Recallthatbyourconstructionofu
2
andv 2,itholds u 2,µ♯ = v 2,ν♯ = 0,whencesince X and Z
⟨ ⟩ ⟨ ⟩
areGaussian, thetuplesofrandomvariables {Xu 2, Zv
2
}
and {P u2,v2,W,W(cid:102)
}
areindependentofeach
other. Wethusdeducethefollowingsequenceofapproximations(seeSectionA.4fordetails)
M
11
( ≈i) m1 tr(cid:0) W(cid:102)P u2,v2W(cid:102)(cid:1) = m1 ∑m W(cid:102)(i,i)2P u2,v2(i,i)( =ii) m1 ∑m
1+a (∑
(z ai⊤ aν♯)2
+λmI) 1a
, (29)
i=1 i=1 i⊤ j=i j ⊤j − i
̸
where the approximation (i) follows from the Hanson–Wright inequality (Vershynin, 2018, Theorem
6.2.1)andtheequivalence(ii)followsuponapplyingtheSherman–Morrisonrankoneupdateformula
(cid:104) (cid:105)
tocomputeP u2,v2(i,i),additionallyusingthenotationW(cid:102)(i,i) = z i⊤ν♯anda ⊤j = z ⊤j ν♯ ·x ⊤j O u2 x ⊤j µ♯ ·z ⊤j O u2
∈
R2(d 1)isthejthrowofA . Continuing,weexpressthequantity∑ a a +λmIasablockmatrix,
− u2,v2 j=i j ⊤j
̸
writing
(cid:20) (cid:21)
∑ B C
a ja⊤j +λmI =
C D
, where (30a)
j=i ⊤
̸
m
B = ∑ (z⊤j ν♯)2O u⊤ 2x j(O u⊤ 2x j) ⊤+λmI, C = ∑ (x⊤j µ♯)(z⊤j ν♯)O u⊤ 2x j(O v⊤ 2z j) ⊤, (30b)
j=i j=i
̸ ̸
D = ∑ (x⊤j µ♯)2O v⊤ 2z j(O v⊤ 2z j) ⊤+λmI. (30c)
j=i
̸
Thus,byblockmatrixinversion,
(cid:18) ∑ a ja⊤j +λmI(cid:19) −1 = (cid:20) (D(B C−C BD − 1C1C )⊤ 1) C−1
B 1
−(B (− DCD C−1 BC ⊤ 1) C− )1C 1D −1 (cid:21) . (30d)
j=i − − ⊤ − − ⊤ − − ⊤ − −
̸
Since,byconstruction, a isindependentofeachofthematrices B,C,and D,wededucethefollowing
i
sequenceofapproximations(seeSectionA.4fordetails)
a i⊤(cid:18) ∑ a ja⊤j +λmI(cid:19) −1 a
i
( ≈i) (z i⊤ν♯)2 ·x i⊤(B −CD−1C⊤) −1x i+(x i⊤µ♯)2 ·z i⊤(D −C⊤B−1C) −1z
i
j=i
̸
( ≈ii) (z i⊤ν♯)2 ·tr(cid:0) (B −CD−1C⊤) −1(cid:1) +(x i⊤µ♯)2 ·tr(cid:0) (D −C⊤B−1C) −1(cid:1) ,
where step (i) follows as the quadratic forms involving each of the off-diagonal blocks is zero-mean
and step (ii) follows upon applying the Hanson–Wright inequality. The most technical step, then, is
13to approximately compute the inverse trace quantities in the preceding display. Indeed, in Section D,
weapplythemethodoftypicalboundeddifferences(Warnke,2016)todeducethat,withprobabilityat
least1 Ce
cdt2
,
−
−
(cid:12) (cid:12)tr(cid:0) (B −CD−1C⊤) −1(cid:1) −r 1−1(cid:12) (cid:12)
≤
t and (cid:12) (cid:12)tr(cid:0) (D −C⊤B−1C) −1(cid:1) −r 2−1(cid:12) (cid:12)
≤
t, (31)
wherer ,r arescalarswhichsatisfyasystemoftwoequations,statedexplicitlyinSection3.2tofollow.
1 2
WeshowinLemma19thataslongas ∥µ♯ ∥2, ∥ν♯
∥2
≤
λ,wehavethesandwichrelation λ dm
≤
r 1,r
2
≤
2λm,sothatthequantitiesr andr scalelinearlyin λm.
d 1 2 d
Now,combiningtheapproximations(29)and(31),andapplyingBernstein’sinequality(Vershynin,
2018,Theorem2.8.1)weobtain
M
1 ∑m (z i⊤ν♯)2 E(cid:26) r 1r 2G 22 (cid:27)
,
11 ≈ m i=11+(z i⊤ν♯)2 ·r 1−1+(x i⊤µ♯)2 ·r 2−1 ≈ r 1r 2+r 2G 22+r 1G 12
where in the last step we have let G
1
∼
N(0,L2 ♯) and G
2
∼
N(0,(cid:101)L2 ♯) be two independent random
variables. Proceedingsimilarlyyieldstheapproximation(seeSectionA.4fordetails)
(cid:26) r r G2G2 (cid:27)
M E 1 2 1 2 .
1 ≈ r r +r G2+r G2
1 2 2 2 1 1
Now,substitutingtheapproximationsof M and M intoEq.(28)yieldstheformulasofθdetandθdet.
11 1 1 2
3.2 Explicitformulasofthedeterministicpredictions
Armed with the intuition of the previous section, we now provide explicit expressions for the func-
tions F m,d,σ,λ, F(cid:101)m,d,σ,λ, H m,d,σ,λ, H(cid:101)m,d,σ,λ, S m,d,σ,λ, S(cid:101)m,d,σ,λ : R4
→
R used to define our deterministic
predictions.
(cid:113)
(cid:112)
For inputs (α,β, (cid:101)α,β(cid:101)), we use the shorthand L = α2+β2 and (cid:101)L = (cid:101)α2+β(cid:101)2 and let G 1,G
2
be
twoindependentrandomvariablessuchthat G
1
N(0,L2)and G
2
N(0,(cid:101)L2). Recallthat Λ = m/d.
∼ ∼
The scalars r ,r 0 considered in the previous section are defined to be the unique5 solution to the
1 2
≥
followingfixedpointequations
(cid:26) r r G2 (cid:27) r (cid:26) r r G2 (cid:27) r
λ+E 1 2 2 = 1 and λ+E 1 2 1 = 2 . (32)
r r +r G2+r G2 Λ r r +r G2+r G2 Λ
1 2 1 1 2 2 1 2 1 1 2 2
Wefurtherdefinethedeterministicquantities(V,V ,V )asfollowing
1 2
(cid:26) r r G2G2 (cid:27) (cid:26) r r G2 (cid:27) (cid:26) r r G2 (cid:27)
V =E 1 2 1 2 , V =E 1 2 2 , V =E 1 2 1 . (33)
r r +r G2+r G2 1 r r +r G2+r G2 2 r r +r G2+r G2
1 2 1 1 2 2 1 2 1 1 2 2 1 2 1 1 2 2
Withthesedefinitionsinhand,wedefine
V(cid:0)α(cid:101)α +L2(cid:1)
+λL2(cid:101)L2 V β2
F m,d,σ,λ(α,β, (cid:101)α,β(cid:101)) = V(LL2
2+(cid:101)L2)+λL2(cid:101)L2
·α+ L2(cid:101)L2(1
V 1+λ)
·(cid:101)α (34a)
F(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)) =
V V(cid:0) (Lα (cid:101)L(cid:101)α
2
2++ (cid:101)(cid:101) LL 22 )(cid:1) ++ λλ LL 22 (cid:101)L(cid:101)L 22
·(cid:101)α+
L2(cid:101)L2V
(2
Vβ(cid:101) 22
+λ)
·α (34b)
V(cid:0)α(cid:101)α +L2(cid:1)
+λL2(cid:101)L2
αα V
H m,d,σ,λ(α,β, (cid:101)α,β(cid:101)) = V(LL2
2+(cid:101)L2)+λL2(cid:101)L2
·β
−
L2(cid:101)
(cid:101)L2 · V
1+1
λ
·β (34c)
V(cid:0)α(cid:101)α +(cid:101)L2(cid:1)
+λL2(cid:101)L2
αα V
H(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)) = V(L(cid:101)L2
2+(cid:101)L2)+λL2(cid:101)L2
·β(cid:101)
−
L2(cid:101)
(cid:101)L2 · V
2+2
λ
·β(cid:101). (34d)
5SeeLemma19foraproofofuniqueness
14Continuing,wedefinetwodeterministicquantitiesV andV as
3 4
(cid:16) (cid:17)2
V = (cid:16) σ2+ β2β(cid:101)2(cid:17) E(cid:26) r 22G 22 (cid:27) + λ2 Lα 2(cid:101) (cid:101)α L2 −1 E(cid:26) r 22G 12G 24 (cid:27)
3 L2(cid:101)L2 (r 1r 2+r 1G 12+r 2G 22)2 (cid:0) λ+V(L −2+(cid:101)L −2)(cid:1)2 (r 1r 2+r 1G 12+r 2G 22)2
+
(λ (cid:101)αβ)2 E(cid:26) r 22G 24 (cid:27)
+
(λαβ(cid:101))2 E(cid:26) r 22G 12G 22 (cid:27)
. (35)
(λ+V 1)2(cid:101)L4L2 (r 1r 2+r 1G 12+r 2G 22)2 (λ+V 2)2L4(cid:101)L2 (r 1r 2+r 1G 12+r 2G 22)2
(cid:16) (cid:17)2
V = (cid:16) σ2+ β2β(cid:101)2(cid:17) E(cid:26) r 12G 12 (cid:27) + λ2 · Lα 2(cid:101) (cid:101)α L2 −1 E(cid:26) r 12G 14G 22 (cid:27)
4 L2(cid:101)L2 (r 1r 2+r 1G 12+r 2G 22)2 (cid:0) λ+V(L −2+(cid:101)L −2)(cid:1)2 (r 1r 2+r 1G 12+r 2G 22)2
+
(λαβ(cid:101))2 E(cid:26) r 12G 14 (cid:27)
+
(λ (cid:101)αβ)2 E(cid:26) r 12G 12G 22 (cid:27)
. (36)
(λ+V 2)2(cid:101)L2L3 (r 1r 2+r 1G 12+r 2G 22)2 (λ+V 1)2L2(cid:101)L4 (r 1r 2+r 1G 12+r 2G 22)2
Now,letη,η 0bethesolutionofthefollowingfixedpointequations
(cid:101)
≥
(d 2)m(cid:18) (cid:26) r2G4 (cid:27) (cid:26) r2G2G2 (cid:27) (cid:19)
η2 = − η2 E 2 2 +η2 E 2 1 2 +V , (37a)
d2 · (r r +r G2+r G2)2 (cid:101) · (r r +r G2+r G2)2 3
1 2 1 1 2 2 1 2 1 1 2 2
(d 2)m(cid:18) (cid:26) r2G4 (cid:27) (cid:26) r2G2G2 (cid:27) (cid:19)
η2 = − η2 E 1 1 +η2 E 1 1 2 +V . (37b)
(cid:101) d2 (cid:101) · (r r +r G2+r G2)2 · (r r +r G2+r G2)2 4
1 2 1 1 2 2 1 2 1 1 2 2
Now,wedefine
S m,d,σ,λ(α,β, (cid:101)α,β(cid:101)) = η2 and S(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)) = η (cid:101)2. (38)
Weshow(seeLemma19)thatEq.(37a)andEq.(37b)haveauniquenon-negativesolution,sothatthe
functionsS
m,d,σ,λ
andS(cid:101)m,d,σ,λ arewelldefined.
4 Proof of Theorem 1: One-step predictions
Weprovetheparallelcomponentandtheperpendicularcomponentseparately.
4.1 Parallelcomponent: ProofofTheorem1(a)
WeproceedbyexecutingthestepsoutlinedinSection3.1. Inparticular,recallthetupleofunitvectors
(u 1,u 2,v 1,v 2)fromEq.(25)anddecomposeα+ and (cid:101)α+ asinEq.(26)andrecallthat
α♯ β♯ (cid:101)α♯ β(cid:101)♯
α+ = θ(u 1)+ θ(u 2) and (cid:101)α+ = θ(cid:101)(v 1)+ θ(cid:101)(v 2),
L ♯ · L ♯ · (cid:101)L ♯ · (cid:101)L ♯ ·
wherewedefinedθ(u i) = u i,µ+ andθ(v i) = v i,ν+ .Consequently,itsufficestounderstandthecon-
⟨ ⟩ ⟨ ⟩
centrationpropertiesoftherandomvariablesθ(u 1),θ(u 2),θ(cid:101)(v 1),andθ(cid:101)(v 2)aroundtheirtypicalvalues
(cid:0)α♯(cid:101)α♯ (cid:101)L2(cid:1)
V
θ 1det = L ♯+L ♯
· λL2
♯(cid:101)LL
2
♯2 ♯ +− V(L♯
2
♯·
+(cid:101)L2
♯), θ 2det = (cid:101)(cid:101) Lα 2♯ ♯β L♯
♯
· V
1V +1 λ, (39a)
(cid:0)α♯(cid:101)α♯ L2(cid:1)
V
θ(cid:101) 1det =(cid:101)L ♯+(cid:101)L ♯
· λL2
♯(cid:101)L(cid:101)L
2
♯2 ♯ +− V(L♯
2
♯·
+(cid:101)L2
♯), θ(cid:101) 2det = Lα 2♯ ♯β (cid:101)(cid:101) L♯
♯
· V
2V +2 λ, (39b)
respectively, where the tuple of scalars (V,V ,V ) as defined in Eq. (33). The deterministic prediction
1 2
canthenbewrittenasαdet = α♯ θdet+ β♯ θdet. Thus,bythetriangleinequality,
+ L♯ · 1 L♯ · 2
|α+ −αd +et
| ≤
α L♯
♯
·(cid:0) |θ(u 1) −θ 1det |(cid:1) + β
L
♯♯ ·(cid:0) |θ(u 2) −θ 2det |(cid:1) . (40a)
15Applyingthetriangleinequalityoncemoreyieldsthedecomposition:
(cid:12) (cid:12)θ(u i) −θ idet(cid:12) (cid:12)
≤
(cid:12) (cid:12)θ(u i) −E {θ(u i) }(cid:12) (cid:12)+(cid:12) (cid:12)E {θ(u i) }−θ idet(cid:12) (cid:12), fori =1,2. (40b)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Stochasticerror Bias
Weclaimthefollowingpairofbounds
(cid:12) (cid:12)θ(u 1) −E {θ(u 1) }(cid:12) (cid:12)
∨
(cid:12) (cid:12)θ(u 2) −E {θ(u 2) }(cid:12) (cid:12)≲
max(cid:26) log3(d) λ((cid:112) √E mrr ♯+σ) ,d−50(cid:27)
(41a)
(cid:12) (cid:12)E {θ(u 1) }−θ 1det(cid:12) (cid:12) ∨(cid:12) (cid:12)E {θ(u 2) }−θ 2det(cid:12) (cid:12)≲ (cid:112) E λrr ♯ ·(cid:18) log √6 d(d) + log √2.5 m(m)(cid:19) , (41b)
where the bound (41a) holds with probability at least 1 2d 110. We provide the proof of inequali-
−
−
ties(41a)and(41b)inSections4.1.1and4.1.2, respectively. Noting that α♯/L ♯,β♯/L ♯ 1, andsubsti-
≤
tuting the above bounds into the pair of inequalities (40) yields the result. It remains to establish the
bounds(41).
4.1.1 Boundingthestochasticerror(41a)
This section is devoted to establishing the following stronger bound, which holds with probability at
least1 d 110foranyu S2d 1:
− −
− ∈
(cid:12) (cid:12) (cid:12)(cid:68) u,(cid:20) µ+ (cid:21)(cid:69) E(cid:26)(cid:68) u,(cid:20) µ+ (cid:21)(cid:69)(cid:27)(cid:12) (cid:12)
(cid:12)
max(cid:26)C 3log3(d)((cid:112) Err ♯+σ) ,d−50(cid:27)
, (42)
(cid:12) ν+ − ν+ (cid:12) ≤ λ√m
sincetheinequality(41a)thenfollowsuponlettingu = [u 0 ] andu = [u 0 ] . Weturnnow
1⊤
|
⊤ ⊤ 2⊤
|
⊤ ⊤
totheproofoftheinequality(42).
Note that we require fine-grained control on the deviations since the guarantee (42) depends on
Err ♯. In order to facilitate these fine-grained deviation bounds, we employ Warnke’s typical bounded
differencesinequality(Warnke,2016,Theorem2). Inparticular,considerthefunction f : R(2d+1) m
×
R,definedas →
f u(cid:0) {x k,z k,ϵ
k
}m k=1(cid:1) := (cid:10) u,[µ⊤+
|
ν +⊤] ⊤(cid:11) , (43)
andnotethatitsufficestoshowthat f (cid:0) x ,z ,ϵ m (cid:1) concentratesarounditsexpectationwithdevia-
(cid:0) (cid:112) u (cid:1){ k k k }k=1
tionswhichareO ( Err ♯+σ)/(λ√m) . Inordertoapplythetypicalboundeddifferencesinequality,
wemustconstructaregularityset onwhich(i.) thedata x ,z ,ϵ m lieswithhighprobabilityand
S { k k k }k=1
(ii.) thefunction f enjoystheboundeddifferencesproperty.
u
Towardsconstructingtheregularityset ,wedefinethepairofestimators
S
(cid:20) µ
ν
−− (( ii )) (cid:21) =a µr ,g νm Ri dn k∑ =i(cid:0) y k+G kG(cid:101)k −G(cid:101)kx⊤k µ −G kz⊤k ν(cid:1)2+λm(cid:13) (cid:13) (cid:13) (cid:13)(cid:20) µ ν− −µ ν♯♯(cid:21)(cid:13) (cid:13) (cid:13) (cid:13)2 2, (44a)
∈ ̸
(cid:20) µ
ν
−− (( ii ,, jj )) (cid:21) =a µr ,g νm Ri dn k∑ =i,j(cid:0) y k+G kG(cid:101)k −G(cid:101)kx⊤k µ −G kz⊤k ν(cid:1)2+λm(cid:13) (cid:13) (cid:13) (cid:13)(cid:20) µ ν− −µ ν♯♯(cid:21)(cid:13) (cid:13) (cid:13) (cid:13)2 2, (44b)
∈ ̸
whereweform[µ (i) ν (i)]byleavingoutthesample(x,z,y )andsimilarly,weform[µ (i,j) ν (i,j)]
− − i i i − −
| |
by leaving out the two samples {x k,z k,y
k
}k=i,j. We recall (see the discussion following Eq. (6)) the
shorthand G
i
= x i⊤µ♯, G(cid:101)i = z i⊤ν♯ and a
i⊤
= [G(cid:101)ix
i⊤
|
G iz i⊤]. We further use the shorthand µ
⊥
=
P µ⊥⋆µ♯/β♯,ν
⊥
= P ν⊥⋆ν♯/β(cid:101)♯ todescribethenormalizedorthogonalcomponentsofµ♯ andν♯,respectively,
aswellasthematrixΣ = ∑m a a +λmI anditsleave-one-outandleave-two-outanalogues
k=1 k ⊤k
Σ
i
= ∑ a ka⊤k +λmI, and Σ
i,j
= ∑ a ka⊤k +λmI, fori,j
∈
[m].
k=i k=i,j
̸ ̸
16Theregularityset R(2d+1) m isthendefinedasthesubsetstableuponleavingoneortwosamples
×
S ⊆
out. Inparticular, let R(2d+1) m denotetheeventthat—forafixedunitvector u—thevectors a
1 × i
anda areapproximatS ely⊆ orthogonaltotheleaveoneoutmatricesΣ,Σ :
j i i,j
(cid:110) Clogd(cid:111)
S1
:= {x i,z i,ϵ
i
}im
=1
∈R(2d+1) ×m : ∀i,j
∈
[m], |u⊤Σ i−1a
i
|, |u⊤Σ i−,j1a
j | ≤ λm
.
Wethenlettheset R(2d+1) mdenotetheeventthatthenoiseisboundedaboveby(cid:112) logd,thedata
2 ×
S ⊆
x i,z
i
areboundedinnormby√dandareapproximatelyorthogonaltoµ⋆,µ
⊥
andν⋆,ν ⊥,respectively:
S2
:= (cid:110) {x i,z i,ϵ
i
}im
=1
∈R(2d+1) ×m : ∀i
∈
[m], |x i⊤µ⋆ |, |x i⊤µ⊥ |, |z i⊤ν⋆ |, |z i⊤ν⊥
|
≤C(cid:112) logd,
(cid:112) (cid:111)
x , z C√d, and ϵ Cσ logd .
i 2 i 2 i
∥ ∥ ∥ ∥ ≤ ≤
Finally,werequirethatx i,z iareapproximatelyorthogonaltothedifferencesµ♯ µ −(i)andν♯ ν −(i)(and
− −
similarlyfortheleavetwooutquantities):
S3
:= (cid:26) {x i,z i,ϵ
i
}im
=1
∈R(2d+1) ×m : |x ∥i⊤ µ( ♯µ −♯ −
µ
−µ (− i)( ∥i) 2) | ≤C(cid:112) logd, |x ∥i⊤ µ( ♯µ −♯ −
µ
−µ (− i,j( )i, ∥j) 2) | ≤C(cid:112) logd,
|z i⊤(ν♯ −ν −(i))
|
C(cid:112)
logd,
|z i⊤(ν♯ −ν −(i,j))
|
C(cid:112)
logd, i,j
[m](cid:27)
,
∥ν♯ −ν −(i)
∥2
≤ ∥ν♯ −ν −(i,j)
∥2
≤ ∀ ∈
whereineachoftheabovethreesets, C isalarge, positiveuniversalconstant. Theregularityset is
S
thendefinedtobetheintersectionoftheabovethreesets:
= . (45)
1 2 3
S S ∩S ∩S
Let us now outline the properties that the regularity set enjoys. First, define the Hamming metric
S
ρ :R(2d+1) m R(2d+1) m Z as
× × 0
× → ≥
m
ρ(cid:0) {x k,z k,ϵ k }n k=1, {x′k,z′k,ϵ k′ }n k=1(cid:1) = ∑ 1(cid:8) (x k,z k,ϵ k) ̸= (x′k,z′k,ϵ k′)(cid:9) , (46)
k=1
andlet M := x,z,ϵ m and M := x,z,ϵ m . Thefollowinglemmademonstratesthatthefunc-
{ i i i }i=1 ′ { i′ i′ i′ }i=1
tion f enjoys the bounded difference property on the regularity set ; we provide its proof in Sec-
u
S
tionA.1.
Lemma1. Consider f in(43)andtheregularityset in(45). Thefollowinghold.
u
S
(a) Thereexistsauniversal,positiveconstantC suchthatifλm C d(1+σ),then f (M) d, M .
′ ′ u
≥ | | ≤ ∀ ∈ S
(b) Thereexistsauniversal,positiveconstantC suchthatforall M,M whichsatisfyρ(M,M ) 2,
0 ′ ′
∈ S ≤
f u(M) f u(M′) ∆ where ∆ =
C
0log3(d)((cid:112)
Err ♯+σ)
.
| − | ≤ λm
Havingshownthat f
u
enjoystheboundeddifferencespropertyon ,weextendittoafunction f u↓,
S
whichenjoystheboundeddifferencespropertywhenonlyoneofitsargumentsliesin viatruncation.
S
In particular, let D = d and note that Lemma 1(a) implies D sup f (M) as long as λm
≥ M | u | ≥
C ′d(1+σ). Wedefinetheextension f u↓ :R(2d+1) ×m Ras ∈S
→
f u↓(M) = inf (cid:110) f u(cid:0) M′(cid:1) +∆ ρ(cid:0) M,M′(cid:1) +2D 1(cid:8) ρ(cid:0) M,M′(cid:1) >1(cid:9)(cid:111) , (47)
M · ·
′∈S
where ∆ is as in Lemma 1(b). Consequently, by Lemmas 1 and 18, we deduce for all M and
∈ S
M R(2d+1) m whichsatisfyρ(M,M ) 1,bothofthefollowingpropertieshold
′ × ′
∈ ≤
f u↓(M) = f u(M), and f u↓(M) f u↓(M′) ∆. (48)
| − | ≤
The following lemma establishes the desideratum that the data lies in with high probability and
S
demonstrates that concentration of the truncated function f u↓ suffices to establish the concentration of
theoriginalfunction f . WeprovideitsproofinSectionA.2.
u
17Lemma2. Suppose x,z m
i.i.d.
N(0,I ), ϵ m
i.i.d.
N(0,σ2). ThereexistsuniversalconstantsC,d such
{ i i }i=1 ∼ d { i }i=1 ∼ 0
thatford d ,1 m d,λm C(1+σ)dandt d 80,wehave
0 −
≥ ≤ ≤ ≥ ≥
(a.) Pr(cid:8) {x i,z i,ϵ
i
}im
=1
∈/ S(cid:9)
≤
d−180, (b.) sup (cid:12) (cid:12)f u↓( {x i,z i,ϵ
i
}im =1)(cid:12) (cid:12)≲ d,
{xi,zi,ϵi}im =1∈R(2d+1) ×m
and (c.) Pr(cid:8) f u E f u t(cid:9) Pr(cid:8) f u↓ E f u↓ t/2(cid:9) +d−180.
| − { }| ≥ ≤ | − { }| ≥
ItremainstocontrolthequantityPr f u↓ E f u↓ t/2 .Combininginequality(48)andLemma2(b.)
{| − { }| ≥ }
yields(forρ(M,M ) 1)
′
≤ (cid:12) (cid:12) (cid:26) ∆, if M ,
(cid:12)f u↓(M)
−
f u↓(M′)(cid:12)
≤
Cd,other∈ wiS
se.
Then, weset c = ∆,d = Cd and γ (0,1] foreach k [n] andapplyWarnke(2016, Theorem2)to
k k k
∈ ∈
deducethatforallt >0
Pr(cid:110)
|f u↓(M) −E {f u↓(M)
}| ≥
t(cid:111) ≤2exp(cid:110)
− 4∑m
(ct 22 +γ2d2)(cid:111)
+
∑m
γ k−1 ·Pr {M ∈/ S}.
k=1 k k k k=1
Settingγ = d 60 foreachk [m]andapplyingLemma2(a.),weobtainthatwithprobabilityatleast
k −
∈
1 d 115,
−
−
|f u↓(M) −E {f u↓(M)
}|
≤C(cid:113) log(d)max(cid:110)(cid:16) ∑m
c2
k(cid:17)1/2 ,(cid:16) ∑m
γ k2d2
k(cid:17)1/2(cid:111)
k=1 k=1
C(cid:113) log(d)max(cid:8) √m∆,d−52(cid:9) max(cid:110)C
′log3.5(d)((cid:112)
Err ♯+σ) ,d−50(cid:111)
.
≤ ≤ λ√m
Finally,applyingLemma2(c.),weobtainthatwithprobabilityatleast1 d 110,
−
−
f
u
E f
u
max(cid:110)C
′log3.5(d)((cid:112)
Err ♯+σ) ,d−50(cid:111)
,
| − { }| ≤ λ√m
whichconcludestheproofofinequality(42).
4.1.2 Boundingthebias(41b)
Ourboundsonthebiastermfollowstep2bofthestrategyoutlinedinSection3.1. Webeginwithsome
notation. For any directions u,v Sd −1, we let θ(u) = u,µ+ and θ(cid:101)(v) = v,ν+ . Additionally,
∈ ⟨ ⟩ ⟨ ⟩
we let O Rd (d 1) and O Rd (d 1) consist of columns which form orthonormal bases of the
u × − v × −
∈ ∈
d 1 dimensional subspaces orthogonal to u and v, respectively. Recalling that W = diag(Xµ♯) and
−
W(cid:102) = diag(Zν♯), we then let A
u,v
= [W(cid:102)XO
u
|
WZO v] and P
u,v
= I −A u,v(cid:0) A ⊤u,vA u,v+λmI(cid:1) −1 A
⊤u,v
denoteleave-one-outvariantsofthedata Aandthe“projection”matrixPwhichdonotdependonthe
directionsuandv. Thefollowinglemma,whoseproofwedefertoSectionA.3,characterizesθ(u)and
θ(cid:101)(v)assolutionstoalinearsystem.
Lemma3. Letµ+,ν+,µ♯,ν♯ beasinTheorem1andconsideru,v Sd −1. Thefollowingholds.
∈
(cid:18) m1 (cid:20) ( (W W(cid:102)X Zvu )) ⊤⊤(cid:21) P u,v(cid:2) W(cid:102)Xu |WZv(cid:3) +λI(cid:19)(cid:20) θ θ(cid:101)( (u v) )(cid:21) = λ(cid:20) ⟨ ⟨µ ν♯♯ ,, vu ⟩⟩(cid:21) (49)
(cid:20) (cid:21) (cid:20) (cid:21) (cid:20) (cid:21)
+ m1 ( (W W(cid:102)X Zvu )) ⊤⊤ P u,v(cid:0) y+diag(WW(cid:102))(cid:1) −λ ( (W W(cid:102)X Zvu )) ⊤⊤ A u,v(cid:0) A⊤u,vA u,v+λmI(cid:1) −1 O Ou⊤ v⊤µ ν♯♯ .
Wenextstateexplicitexpressionsforthecomponents θ(u 1),θ(cid:101)(v 1),θ(u 2),and θ(cid:101)(v 2). Theproofsofthe
validity of these expressions rely on Lemma 3, and we provide them at the end of the section. The
18expressionsforθ(u 1)andθ(cid:101)(v 1)arestatedintermsoftherandomvariables M 1and M 2,definedas
1
M
1
= mdiag(WW(cid:102)) ⊤P u1,v1diag(WW(cid:102)),
1 (cid:16)α♯β(cid:101)♯ (cid:101)α♯β♯ β♯β(cid:101)♯ (cid:17)
M
2
= mdiag(WW(cid:102)) ⊤P
u1,v1
L2 ♯(cid:101)L
♯WZv 2+
(cid:101)L2 ♯L
♯W(cid:102)Xu 2+
L ♯(cid:101)L
♯Xu
2
⊙Zv 2+ϵ , (50)
Wethenhave
L ♯(cid:0)α L♯(cid:101)α 2♯ −(cid:101)L2 ♯(cid:1) M 1+L ♯(cid:101)L2 ♯M
2
θ(u 1) = L ♯+ λL♯
2 ♯(cid:101)L2
♯
+M 1(L2
♯
+(cid:101)L2 ♯)
, and (51a)
θ(cid:101)(v 1) =(cid:101)L ♯+
(cid:101)L ♯(cid:0) λα
(cid:101)
LL♯(cid:101)α
2 ♯
2
♯♯
(cid:101)L−
2
♯
+L2
♯
M(cid:1) M
1(1
L+
2
♯
+L2
♯
(cid:101)L(cid:101)L
2
♯♯
)M
2 . (51b)
Wewilllateralsorequiretherandomvariable M
3
= m1 diag(WW(cid:102)) ⊤P u1,v1Xu
2
⊙Zv 2. Theexpressions
for θ(u 2) and θ(cid:101)(v 2), further rely on the random variables M 11,M 12,M 22, as well as E 1,E
2
and F 1,F 2,
whichwedefinepresently.
1 1
M
11
= m(W(cid:102)Xu 2) ⊤P u2,v2W(cid:102)Xu 2, M
12
= m(W(cid:102)Xu 2) ⊤P u2,v2WZv 2,
1
and M
22
= m(WZv 2) ⊤P u2,v2WZv 2. (52)
The key properties of the random variables M ,M ,M ,M ,M , and M are summarized in the
1 2 3 11 12 22
followinglemma,whoseproofwedefertoSectionA.4.
Lemma4. Recallthetupleofdeterministicquantities(V,V ,V )inEq.(33)andthetupleofrandomvariables
1 2
(M ,M ,M ,M ,M ) in Eq. (50) and Eq. (52), and consider the assumptions in Theorem 1. Then, the
11 12 22 1 3
followingfourpropertieshold.
(a.) E(cid:8) M V (cid:9) E(cid:8) M V (cid:9)≲ log1.5(d) + 1 , (b.) E(cid:8) M2 (cid:9)≲ 1 ,
| 11 − 1 | ∨ | 22 − 2 | √d √m 12 m
(c.)
E(cid:8)
M V
(cid:9)≲ log6(d)
+
log2.5(m)
and (d.)
E(cid:8)
M
(cid:9)≲ log6(d)
+
1
.
| 1 − | √d √m | 3 | √d √m
TherandomvariablesE andE dependonthenoiseϵandaredefinedas
1 2
1 (cid:18)(cid:16) α♯ (cid:101)α♯(cid:17) α♯ β(cid:101)♯ β♯β(cid:101)♯ (cid:19)
E
1
= m(W(cid:102)Xu 2) ⊤P
u2,v2
1+
L2
♯
(cid:101)L2
♯
·diag(WW(cid:102))+
L2
♯
(cid:101)L
♯
·WZv 2+
L ♯(cid:101)L
♯
·Xu
2
⊙Zv 2+ϵ ,
1 (cid:18)(cid:16) α♯ (cid:101)α♯(cid:17) (cid:101)α♯ β♯ β♯β(cid:101)♯ (cid:19)
E
2
= m(WZv 2) ⊤P
u2,v2
1+
L2 ♯ (cid:101)L2 ♯
·diag(WW(cid:102))+
(cid:101)L2 ♯ L ♯
·W(cid:102)Xu 2+
L ♯(cid:101)L ♯
·Xu
2
⊙Zv 2+ϵ ,.
Finally,wedefinetherandomvariablesF andF as
1 2
(cid:20) (cid:21)
F 1 = λ(W(cid:102)Xu 2) ⊤A u2,v2(cid:0) A⊤u2,v2A u2,v2 +λmI(cid:1) −1 O Ou⊤ v⊤2 2µ ν♯♯ and
(cid:20) (cid:21)
F 2 = λ(WZv 2) ⊤A u2,v2(cid:0) A⊤u2,v2A u2,v2 +λmI(cid:1) −1 O Ou⊤ v⊤2 2µ ν♯♯ . (53)
19Equippedwiththesedefinitions,wehavethefollowingexpressionsforθ(u 2)andθ(cid:101)(v 2)
(M
+λ)(cid:0)(cid:101)α♯ β♯
M +E F
(cid:1)
M
(cid:0)α♯ β(cid:101)♯
M +E F
(cid:1)
θ(u ) =
22 (cid:101)L2
♯
L♯ · 11 1 − 1 − 12 L2
♯
(cid:101)L♯ · 22 2 − 2
, (54a)
2 (M +λ)(M +λ) M2
11 22 − 12
(M
+λ)(cid:0)α♯ β(cid:101)♯
M +E F
(cid:1)
M
(cid:0)(cid:101)α♯ β♯
M +E F
(cid:1)
θ(cid:101)(v 2) =
11 L2
♯
(cid:101)L♯ · (M22 +λ2 )− (M2 +− λ)12 M(cid:101)L2
♯
2L♯ · 11 1 − 1
. (54b)
11 22 − 12
Taking these expressions for granted, we claim the following expressions characterize E θ(u ) and
1
E θ(u ) . Wedeferitsprooftotheendofthesection. { }
2
{ }
(cid:40)L ♯(α L♯(cid:101)α 2♯ −(cid:101)L2 ♯)M 1+(cid:101)L ♯β♯β(cid:101)♯M 3(cid:41)
E {θ(u 1)
}
= L ♯+E λ♯
L2 ♯(cid:101)L2
♯
+M 1(L2
♯
+(cid:101)L2 ♯)
, and
(cid:40)(cid:101)α♯ β♯M (cid:101)α♯ β♯ M 12
2 (cid:41)
E θ(u ) =E
(cid:101)L2
♯
L♯ 11 − (cid:101)L2
♯
L♯ M22+λ
. (55)
{ 2 } M2
(M +λ) 12
11 − M22+λ
Weturn nowtobounding E θ(u ) θdet . Tothis end, wecombinethe claim(55)with theexplicit
| { 1 }− 1 |
expressionθdetin(39a)andapplythetriangleinequalitytoobtainthedecomposition
1
(cid:12) (cid:12)E {θ(u 1) }−θ 1det(cid:12) (cid:12)
≤
(cid:12) (cid:12)L ♯(cid:0)α L♯(cid:101)α 2♯ −(cid:101)L2 ♯(cid:1)(cid:12) (cid:12) ·T 1+(cid:101)L ♯β♯β(cid:101)♯ ·T 2,
♯
(cid:12) (cid:110) (cid:111) (cid:12) (cid:12) (cid:110) (cid:111)(cid:12)
whereT = (cid:12)E M1 V (cid:12)andT = (cid:12)E M3 (cid:12).NotethatM ,M ,M
1 (cid:12) λL2 ♯(cid:101)L2 ♯+M1(L2 ♯+(cid:101)L2 ♯) −λL2 ♯(cid:101)L2 ♯+V(L2 ♯+(cid:101)L2 ♯)(cid:12) 2 (cid:12) λL2 ♯(cid:101)L2 ♯+M1(L2 ♯+(cid:101)L2 ♯) (cid:12) 1 11 22 ≥
0since P 0fori = 1,2. Moreover, bydefinition, V,V 0(33). Consequently, applyingthetri-
angleineu qi, uvi
al⪰ ityyieldsthepairofboundsT 2 E(cid:8)
M1
≥ V (cid:9) andT 1 E(cid:8) M (cid:9) . Then,
1 ≤ λL2 ♯(cid:101)L2
♯
· | 1 − | 2 ≤ λL2 ♯(cid:101)L2
♯
· | 3 |
applyingLemma4(c.),(d.) yieldsthepairofinequalities
1 (cid:18) log6(d) log2.5(m)(cid:19) 1 (cid:18) log6(d) 1 (cid:19)
T ≲ + , and T ≲ + .
1 λL2(cid:101)L2 √d √m 2 λL2(cid:101)L2 √d √m
♯ ♯ ♯ ♯
CombiningtheprevioustwodisplaysandusingtheassumptionthatL ♯,(cid:101)L ♯ 1yieldstheinequality
≍
(cid:12) (cid:12)
(cid:12) (cid:12)E {θ(u 1) }−θ 1det(cid:12) (cid:12)≲ (cid:12)α♯(cid:101)α♯ −L2 ♯(cid:101)L λ2 ♯(cid:12)+β♯+β(cid:101)♯ ·(cid:18) log √6 d(d) + log √2.5 m(m)(cid:19) . (56)
Wenextturntobounding(cid:12) (cid:12)E {θ(u 2) }−θ 2det(cid:12) (cid:12). Proceedingsimilarly,wedecompose(cid:12) (cid:12)E {θ(u 2) }−θ 2det(cid:12) (cid:12)
≤
(cid:12) (cid:110) (cid:111) (cid:12) (cid:12) (cid:110) M 12 2 (cid:111)(cid:12)
(cid:101)α♯ β♯ (T +T ), where T = (cid:12)E M11 V1 (cid:12) and T = (cid:12)E M22+λ (cid:12). Towards
(cid:101)L2
♯
L♯ · 3 4 3 (cid:12)
(M11+λ)
−MM 2212
+2
λ
− V1+λ(cid:12) 4 (cid:12)
(M11+λ)
−MM 2212
+2
λ
(cid:12)
boundingT ,wenotethat
3
1 (cid:16) (cid:17)2 1 (cid:68) 1 1 (cid:69)2
M 12
2
=
m2
(W(cid:102)Xu 2) ⊤P u2,v2WZv
2
=
n2
P u2 2,v2W(cid:102)Xu 2, P u2 2,v2WZv
2
≤
m1 2(cid:13) (cid:13)P u1 2 2,v2W(cid:102)Xu 2(cid:13) (cid:13)2 2·(cid:13) (cid:13)P u1 2 2,v2WZv 2(cid:13) (cid:13)2
2
= M
11
·M 22,
where the inequality follows from the Cauchy–Schwarz inequality. We thus deduce the inequalities
M M2 /M M2 /(λ+M ). Consequently,
11 ≥ 12 22 ≥ 12 22
T 3 = (cid:12) (cid:12) (cid:12) (cid:12)E(cid:26) (cid:16) λ(M 11 −V M1) 2+ (cid:17)MV1 2M 2+12 2 λ (cid:27)(cid:12) (cid:12) (cid:12)
(cid:12) ≤
E(cid:8) |M 1 λ1 −V 1 |(cid:9) + E(cid:8) λM 212 2(cid:9) , (57)
λ+M 12 (λ+V )
11 − M22+λ 1
20andT E M2 /λ2. CombiningwithLemma4(a.),(b.) yieldstheboundT +T ≲ 1(cid:16) log6(d) + 1 (cid:17) ,
4 ≤ { 12} 3 4 λ √d √m
whichinturnimpliesthebound
(cid:12) (cid:12)
(cid:12) (cid:12)E(cid:8) θ(u 2)(cid:9) −θ 2det(cid:12) (cid:12)≲ (cid:12)α♯(cid:101)α♯ −L2 ♯(cid:101)L λ2 ♯(cid:12)+β♯+β(cid:101)♯ ·(cid:18) log √6 d(d) + log √2.5 m(m)(cid:19) . (58)
Thedesiredinequality(41b)followsdirectlybynoting
(cid:12) (cid:12)α♯(cid:101)α♯ −L2 ♯(cid:101)L2 ♯(cid:12) (cid:12)+β♯+β(cid:101)♯ = (cid:12) (cid:12)α♯(cid:101)α♯(1 −α♯(cid:101)α♯) −α2 ♯β(cid:101)2 ♯−(cid:101)α2 ♯β2 ♯−β2 ♯β(cid:101)2 ♯(cid:12) (cid:12)+β♯+β(cid:101)♯
(cid:113)
≲ 1 α♯(cid:101)α♯ +β♯+β(cid:101)♯ ≲ Err ♯,
| − |
andcombiningwith theinequalities(56)and (58). It remainstoprovethe characterizations (51),(54),
and(55).
Proofofthecharacterizations(51). Bydefinitionofu 1andv 1(24),weobtainthatO
u⊤
1µ♯ =O
v⊤
1ν♯ =0,
µ♯,u 1 = µ♯ 2 = L ♯ and ν♯,v 1 = ν♯ 2 = (cid:101)L ♯. Further,sincediag(Xu 1) = W/L ♯ anddiag(Zv 1) =
⟨ ⟩ ∥ ∥ ⟨ ⟩ ∥ ∥
W(cid:102)/(cid:101)L ♯,wenote
M M
(W(cid:102)Xu 1) ⊤P u1,v1W(cid:102)Xu
1
=
L2
♯1 , (WZv 1) ⊤P u1,v1WZv
1
=
(cid:101)L2
♯1 ,
M
and(W(cid:102)Xu 1) ⊤P u1,v1WZv
1
=
L
♯(cid:101)L1 ♯.
Consequently,Eq.(49)becomes
  M L2 ♯ L1
M
♯+
(cid:101)L1
♯λ
M
(cid:101)L2
♯L 1M ♯ +(cid:101)L1 ♯
λ
 (cid:20) θ θ(cid:101)( (u
v
11 )) (cid:21) = (cid:20) λ λ(cid:101)L L♯
♯
(cid:21) + m1 ·(cid:20) ( (W(cid:102) WX Zvu 11 )) ⊤⊤ (cid:21) P u1,v1(y+diag(WW(cid:102))). (59)
Continuing,recallthedefinitionofu ,v inEq.(25)andnotethat
2 2
(cid:16)α♯ β♯ (cid:17) (cid:16) (cid:101)α♯ β(cid:101)♯ (cid:17)
y = Xµ⋆ Zν⋆+ϵ = Xu 1+ Xu
2
Zv 1+ Zv
2
+ϵ. (60)
⊙ L ♯ L ♯ ⊙ (cid:101)L ♯ (cid:101)L ♯
Consequently,usingdiag(Xu 1) =W/L ♯ anddiag(Zv 1) =W(cid:102)/(cid:101)L ♯,wededucethat
1 1 (cid:16) α♯(cid:101)α♯ (cid:17) 1
m(W(cid:102)Xu 1) ⊤P u1,v1(y+diag(WW(cid:102))) =
L
♯
1+
L2(cid:101)L2
M 1+
L
♯M
2
and
♯ ♯
1 1 (cid:16) α♯(cid:101)α♯ (cid:17) 1
m(WZv 1) ⊤P u1,v1(y+diag(WW(cid:102))) =
(cid:101)L
♯
1+
L2 ♯(cid:101)L2
♯
M 1+
(cid:101)L
♯M 2.
SubstitutingtheequationinthepreviousdisplayintoEq.(59)yields
  M L2 ♯ L1 M ♯+ (cid:101)L1 ♯λ M
(cid:101)L2
♯L 1M ♯ +(cid:101)L1 ♯ λ  (cid:20) θ θ(cid:101)( (u v 11 )) (cid:21) =    λλ (cid:101)L L♯ ♯+ + (cid:101)L L11 ♯ ♯(cid:16) (cid:16)1 1+ + L Lα α2 2♯ ♯♯ ♯(cid:101) (cid:101)(cid:101) (cid:101)α αL L♯ ♯2 2♯ ♯(cid:17) (cid:17)M M1 1+ + (cid:101)L L1 1 ♯♯M M2
2
  .
21Notethattheequationinthedisplayaboveadmitsauniquesolutionas M 0. Solvingtheequation
1
≥
yields
(cid:16) (cid:16) (cid:17) (cid:17) (cid:16) (cid:16) (cid:17) (cid:17)
θ(u ) =
(λ+ M
(cid:101)L2
♯1) λL ♯+ L1
♯
1+ Lα
2
♯♯(cid:101) (cid:101)α L♯
2 ♯
M 1+ L1 ♯M
2 −
LM ♯(cid:101)L1
♯
λ(cid:101)L ♯+ (cid:101)L1
♯
1+ Lα
2
♯♯(cid:101) (cid:101)α L♯
2 ♯
M 1+ (cid:101)L1 ♯M
2
1 (λ+ M1)(λ+ M1) M 12
L2
♯
(cid:101)L2
♯
− L2 ♯(cid:101)L2
♯
(cid:16) (cid:17)
=
λL ♯+ L1
♯
1+ Lα
2
♯♯(cid:101) (cid:101)α L♯
2
♯
M 1+ L1 ♯M 2+ M (cid:101)L1
2
♯L♯
−
M L♯1
λ+M 1(L−♯ 2+(cid:101)L−♯ 2)
(cid:16) (cid:17) (cid:16) (cid:17)
= L ♯+
L1
♯
Lα
2
♯♯(cid:101) (cid:101)α L♯
2
♯
−1 M 1+ L1 ♯M
2
= L ♯+
L
♯
α L♯(cid:101)α
2
♯♯ −(cid:101)L2
♯
M 1+L ♯(cid:101)L2 ♯M
2
.
λ+M 1(L−♯ 2+(cid:101)L−♯ 2) λL2 ♯(cid:101)L2
♯
+M 1(L2
♯
+(cid:101)L2 ♯)
Thisprovestheequationforθ(u 1). Proceedingsimilarlyprovestheequationforθ(cid:101)(v 1).
Proof of the characterizations (54). By definition of (u ,v ) (25), µ u = ν v = 0. Now, setting
2 2 ⊤♯ 2 ♯⊤ 2
u = u andv = v inEq.(49)yields
2 2
(cid:20) M M11 1+
2
λ MM 221 +2
λ
(cid:21)(cid:20) θ θ(cid:101)( (u
v
22 )) (cid:21) = m1 ·(cid:20) ( (W(cid:102) WX Zvu 22 )) ⊤⊤ (cid:21) P u2,v2(y+diag(WW(cid:102))) −(cid:20) F F1
2
(cid:21) .
Then,usingthedecompositionofy(60),weobtain
1 (cid:101)α♯β♯ 1
m(W(cid:102)Xu 2) ⊤P u2,v2(y+diag(WW(cid:102))) =
(cid:101)L2 ♯L
♯
m(W(cid:102)Xu 2) ⊤P u2,v2(W(cid:102)Xu 2)+
1 (cid:16) α♯(cid:101)α♯ α♯β(cid:101)♯ β♯β(cid:101)♯ (cid:17) (cid:101)α♯β♯
m(W(cid:102)Xu 2) ⊤P
u2,v2
(1+
L2 ♯(cid:101)L2
♯)diag(WW(cid:102))+
L2 ♯(cid:101)L
♯WZv 2+
L ♯(cid:101)L
♯Xu
2
⊙Zv 2+ϵ =
(cid:101)L2 ♯L
♯M 11+E 1,
wherethelaststepfollowsbydefinitionof M andE . Similarly,weobtain
11 1
1 α♯β(cid:101)♯
m(WZv 2) ⊤P u2,v2(y+diag(WW(cid:102))) =
L2 ♯(cid:101)L
♯M 22+E 2.
Puttingthethreepiecestogetheryields
(cid:20) M 11+λ M
12
(cid:21)(cid:20) θ(u 2) (cid:21)
=


(cid:101)(cid:101) Lα 2♯ ♯β L♯ ♯M 11+E 1 −F 1 
.
M
12
M 22+λ θ(cid:101)(v 2)  α♯β(cid:101)♯M
+E F

L2 ♯(cid:101)L♯ 22 2 − 2
Notethattheequationinthedisplayaboveadmitsauniquesolutionsince(M +λ)(M +λ) M2 >
11 22 − 12
M M M2 0. Solvingthe2 2equationinthedisplayyieldsthedesiredresult.
11 22 − 12 ≥ ×
Proofoftherelation(55). StartingwithE θ(u ) ,itsufficestoshowthat
1
{ }
E(cid:26) (cid:101)L ♯β♯β(cid:101)♯M 3 (cid:27) =E(cid:26) L ♯(cid:101)L2 ♯M 2 (cid:27)
,
λL2 ♯(cid:101)L2
♯
+M 1(L2
♯
+(cid:101)L2 ♯) λL2 ♯(cid:101)L2
♯
+M 1(L2
♯
+(cid:101)L2 ♯)
whichuponexpandingintermsof M and M ,furtherreducestoprovingthatE R =0,where
2 3
{ }
R :=
L♯ m(cid:101)L2 ♯ ·diag(WW(cid:102)) ⊤P u1,v1(cid:16) Lα 2♯ ♯β (cid:101)(cid:101) L♯ ♯WZv 2+ (cid:101)(cid:101) Lα 2♯ ♯β L♯ ♯W(cid:102)Xu 2+ϵ(cid:17)
.
λL2 ♯(cid:101)L2
♯
+M 1(L2
♯
+(cid:101)L2 ♯)
22By our construction of (u ,v ) (25) and using the Gaussianity of X,Z, we deduce that the tuples of
1 1
random variables (W,W(cid:102),ϵ) and (XO u1,ZO v1) are independent of each other. Moreover, note that
conditionallyon (XO u1,ZO v1), M
1
isaneven functionof (W,W(cid:102),ϵ), whencethe denominatorof R is
an even function of (W,W(cid:102),ϵ). We also note that conditionally on (XO u1,ZO v1), the numerator of R
isanoddfunctionof(W,W(cid:102),ϵ). Consequently,weobtainthat R
|
(XO u1,ZO v1)isanoddfunctionof
(W,W(cid:102),ϵ). Sincethedistributionof(W,W(cid:102),ϵ)issymmetricaroundzero,weobtainthat
E R =E(cid:8)E(cid:8) R (XO ,ZO )(cid:9)(cid:9) =0.
{ } |
u1 v1
InordertoestablishE θ(u ) ,itsufficestoshowthat
2
{ }
E(cid:40)
E 1 −F 1 −
M12( Lα 2 ♯♯ (cid:101)β L(cid:101) M♯♯ · 2M 2+22 λ+E2−F2) (cid:41) =E(cid:40) −(cid:101)(cid:101) Lα 2♯ ♯β L♯
♯ ·
MM 2212 +2
λ
(cid:41)
. (61)
M2 M2
M +λ 12 M +λ 12
11 − M22+λ 11 − M22+λ
BydefinitionofE and M ,E = R +
(cid:101)α♯ β♯
M ,where
2 12 2 ′ (cid:101)L2
♯
L♯ · 12
(cid:18) (cid:19)
1 (cid:0) α♯ (cid:101)α♯(cid:1) β♯β(cid:101)♯
R′ = m(WZv 2) ⊤P
u2,v2
1+
L2
♯
· (cid:101)L2
♯
·diag(WW(cid:102))+
L ♯(cid:101)L
♯
·Xu
2
⊙Zv 2+ϵ .
SubstitutingthisexpressionforE intoEq.(61)impliestheequivalenceofEq.(61)and
2
(cid:40)
E F
M12(cid:0) Lα
2
♯♯ (cid:101)β L(cid:101) ♯♯ ·M22+R′−F2(cid:1)
(cid:41)
E 1 − 1 − M22+λ =0.
M2
M +λ 12
11 − M22+λ
Byourconstruction, µ♯,u
2
= ν♯,v
2
= 0,whencesinceX andZareGaussian,thetuplesofrandom
⟨ ⟩ ⟨ ⟩
variables (W,W(cid:102),P u2,v2,A u2,v2), (Xu 2) and (Zv 2) are independent of each other. Thus, conditionally
on (W,W(cid:102),P u2,v2,A u2,v2), E
1
is a summation of several random variables each of which is either an
odd function of Xu or an odd function of Zv , and F is an odd function of Xu . Further note that,
2 2 1 2
conditionally on the tuple (W,W(cid:102),P u2,v2,A u2,v2), M 11,M 22,M 12
2
are even functions of the inputs Xu
2
and Zv 2. Thus, conditioning on (W,W(cid:102),P u2,v2,A u2,v2) and taking expectation over Xu
2
and Zv 2, we
obtainthat
(cid:40) (cid:41) (cid:40) (cid:40) (cid:12) (cid:41)(cid:41)
E E 1 −F 1
M2
=E E E 1 −F 1
M2
(cid:12) (cid:12)
(cid:12)
(W,W(cid:102),P u2,v2,A u2,v2) =0.
M +λ 12 M +λ 12
11 − M22+λ 11 − M22+λ
Similarly,conditionon(W,W(cid:102),P u2,v2,A u2,v2),M
12
·M 22,M
12
·R ′andM
12
·F 2areoddfunctionsofinput
(Xu ,Zv ). Consequently,weobtainthat
2 2
(cid:40)M12( Lα
2
tt ·(cid:101)β L(cid:101) tt ·M22+R′−F2)
(cid:12) (cid:41)
E M22+λ
M2
(cid:12) (cid:12)
(cid:12)
(W,W(cid:102),P u2,v2,A u2,v2) =0.
M +λ 12
11 − M22+λ
Puttingthepiecestogetheryieldsthedesiredresult.
4.2 Orthogonalcomponent: ProofofTheorem1(b)
Wewillfocusonbounding(cid:12) (cid:12)(β+)2 (βd +et)2(cid:12) (cid:12)sincetheproofforbounding(cid:12) (cid:12)(β(cid:101)+)2 (β(cid:101)d +et)2(cid:12) (cid:12)isidentical.
− −
Webeginbydecomposingtheperpendicularcomponentintoanintermediatecomponent—contained
23inspan µ⋆,µ♯ —andafullyorthogonalcomponent,setting
{ }
ι+ = (cid:10) µ+,(cid:13) (cid:13)PP µ⊥µ⊥ ⋆⋆ µµ ♯♯ (cid:13)
(cid:13)
2(cid:11) , η +2 = (cid:13) (cid:13)P s⊥pan {µ⋆,µ♯}µ+(cid:13) (cid:13)2
2
(cid:101)ι+ = ⟨ν+,(cid:13) (cid:13)PP ν⊥ν⊥ ⋆⋆ νν ♯♯ (cid:13)
(cid:13)
2⟩, η (cid:101)+2 = (cid:13) (cid:13)P s⊥pan {ν⋆,ν♯}ν+(cid:13) (cid:13)2 2. (62)
We then use the functions H m,d,σ,λ, H(cid:101)m,d,σ,λ, S m,d,σ,λ, S(cid:101)m,d,σ,λ in Eq. (34) and Eq. (38) to define the
correspondingdeterministicpredictionsas
ιd +et = H m,d,σ,λ(cid:0) α♯,β♯, (cid:101)α♯,β(cid:101)♯(cid:1) , (η +det)2 = S m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯)
(cid:101)ιd +et = H(cid:101)m,d,σ,λ(cid:0) α♯,β♯, (cid:101)α♯,β(cid:101)♯(cid:1) , (η (cid:101)+det)2 = S(cid:101)m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯), (63)
Thus, by the definition of β+ (7) and βd +et (9), we see that both (βd +et)2 = (ιd +et)2+(η +det)2 as well as
β2
+
= ∥P µ⊥⋆µ+ ∥2
2
= ι2 ++η +2. Applyingthetriangleinequalityyields
(cid:12) (cid:12)β2 + (βd +et)2(cid:12) (cid:12) (cid:12) (cid:12)ι2 + (ιd +et)2(cid:12) (cid:12)+(cid:12) (cid:12)η +2 (η +det)2(cid:12) (cid:12). (64)
− ≤ − −
We claim the following bounds on the error of the intermediate prediction and the error of the fully
orthogonalprediction,respectively.
(cid:12) (cid:12)ι2
+
(ιd +et)2(cid:12) (cid:12)≲
max(cid:26)(Err ♯+σ2)log6(d) ,d−30(cid:27)
, withprobability 1 d−25, (65a)
− λ√m ≥ −
(cid:12) (cid:12)η +2 (η +det)2(cid:12) (cid:12)≲
max(cid:26)(Err ♯+σ2)log6(d) ,d−30(cid:27)
, withprobability 1 d−22. (65b)
− λ√m ≥ −
Theresultfollowsuponcombiningthepreviousthreeinequalities.Itremainstoproveinequalities(65a)
and(65b).
Boundingtheerroroftheintermediateprediction: Proofofinequality(65a). Theproofofthiscom-
ponent largely follows the strategy of Section 4.1. Recall the pair of unit vectors (u ,u ) in Eq. (25)
1 2
and note that (cid:13) (cid:13)PP µ⊥µ⊥ ⋆⋆ µµ ♯♯ (cid:13)
(cid:13)
2
= β L♯♯ ·u 1
−
α L♯
♯
·u 2. Consequently, ι+ = β L♯♯ ·θ(u 1)
−
α L♯
♯
·θ(u 2). Then, us-
ing the definition of θdet and θdet in Eq. (39a), write the corresponding deterministic prediction as
1 2
ιdet = β♯ θdet α♯ θdet. Thus,bythetriangleinequality,
+ L♯ · 1 − L♯ · 2
(cid:12) (cid:12)ι+ −ιd +et(cid:12) (cid:12)
≤
β
L
♯♯ ·(cid:12) (cid:12)θ(u 1) −θ 1det(cid:12) (cid:12)+ α L♯
♯
·(cid:12) (cid:12)θ(u 2) −θ 2det(cid:12) (cid:12).
Notingthatα♯/L ♯,β♯/L ♯ 1andapplyingthepairofinequalities(41)yields
≤
ι+ ιd +et ≲
max(cid:110)((cid:112) Err ♯+σ)log6(d) ,d−30(cid:111)
, withprobability 1 d−25. (66)
| − | λ√m ≥ −
Theinequality(65a)thenfollowsuponbounding ι++ιd +et . Tothisend,wenotethatbythedefinitions
| |
ofιdetandH (34),weobtain
+ m,d,σ,λ
V(cid:0)α♯(cid:101)α♯ +L2(cid:1)
+λL2(cid:101)L2
|ιd +et
|
= (cid:12) (cid:12)H m,d,σ,λ(α♯,β♯, (cid:101)α♯,β(cid:101)♯)(cid:12) (cid:12)
≤
V(LL2 ♯
2
♯
+(cid:101)L2
♯♯
)+λL2
♯♯
(cid:101)L2
♯♯ ·β♯+ Lα
2
♯♯(cid:101) (cid:101)α L♯
2
♯
V
1V +1
λ
·β♯ ≲ β♯,
≲
whereinthelaststepweuseL ♯,(cid:101)L ♯ 1,V 1 0andV 1(33). Wecompletetheproofuponbounding
≍ ≥
ι+,forwhichweconsidertwocases.
24Case1: ((cid:112) Err ♯+σ)log6(d)/(λ√m) d −30. Working on the event in which the deviation bound (66)
≥
holds,weapplythetriangleinequalitytoobtain
ι+ ιd +et + ι+ ιd +et ≲ β♯+
((cid:112) Err ♯+σ)log6(d) ≲(cid:113)
Err ♯+σ,
| | ≤ | | | − | λ√m
whereinthelaststepweusedthebounds β♯ (cid:112) Err ♯ aswellaslog6(d)/(λ√m) ≲ 1,wherethelatter
≤
holdsbyassumption,sincem dandλm d. Puttingthepiecestogetheryields
≤ ≥
(cid:12) (cid:12)ι2 + (ιd +et)2(cid:12) (cid:12) ( ι+ + ιd +et ) ι+ ιd +et ≲
((cid:112) Err ♯+σ)2log6(d)
− ≤ | | | | ·| − | λ√m
≲
max(cid:110)(Err ♯+σ2)log6(d) ,d−30(cid:111)
,
λ√m
whichconcludesthefirstcase.
Case2: ((cid:112) Err ♯+σ)log6(d)/(λ√m) d −30.Inthiscase, ι+ ≲ β♯+d −30. Thus,
≤ | |
(cid:12) (cid:12)ι2 + (ιd +et)2(cid:12) (cid:12) ( ι+ + ιd +et ) ι+ ιd +et ≲(β♯+d−30)d−30 ≲ d−30
− ≤ | | | | ·| − |
≲
max(cid:110)(Err ♯+σ2)log6(d) ,d−30(cid:111)
,
λ√m
whichconcludesthesecondcase. Combiningthetwocasesyieldsthedesiredresult.
Boundingtheerrorofthefullyorthogonalprediction: Proofofinequality(65b). Asintheproofof
Theorem1(a), wedecomposetheerrorintothesumofabiastermandafluctuationtermandcontrol
eachseparately:
(cid:12) (cid:12)η +2 (η +det)2(cid:12) (cid:12) (cid:12) (cid:12)η +2 E η +2 (cid:12) (cid:12)+(cid:12) (cid:12)E η +2 (η +det)2(cid:12) (cid:12). (67)
− ≤ − { } { }−
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Stochasticerror Bias
Thefollowingpairoflemmascontrolseachofthetwoerrors,respectively.
Lemma5(Stochasticerrorofthefullyorthogonalcomponent). ConsidertheassumptionsofTheorem1and
let η+ and η +det beasin(62)and(63). Thereexistsapositiveconstant C 3, dependingonlyon K 1,K
2
suchthat
withprobabilityatleast1 d 22,
−
−
(cid:12) (cid:12)η +2 −E {η +2 }(cid:12) (cid:12)
∨
(cid:12) (cid:12)η (cid:101)+2 −E {η (cid:101)+2 }(cid:12) (cid:12) ≤C
3max(cid:26) log5.5(d λ)(cid:0) √E mrr ♯+σ2(cid:1) ,d−30(cid:27)
. (68)
TheproofofLemma5followsthestrategyappliedinSection4.1.1,sowedeferittoSectionB.1.
Lemma6(Biasofthefullyorthogonalcomponent). ConsidertheassumptionsofTheorem1andletη+ and
ηdetbeasin(62)and(63). ThereexistsapositiveconstantC ,dependingonlyonK ,K suchthat
+ 4 1 2
(cid:12) (cid:12)E {η +2 }−(η +det)2(cid:12) (cid:12)
∨
(cid:12) (cid:12)E {η (cid:101)+2 }−(η (cid:101)+det)2(cid:12) (cid:12) ≤C
4max(cid:26) log6(d) λ(cid:0) √Er mr ♯+σ2(cid:1) ,d−30(cid:27)
. (69)
WeprovidetheproofofLemma6inSection4.2.1. Notethatthedesiredboundfollowsimmediately
uponapplyingLemmas5and6.
4.2.1 ProofofLemma6
Let {u
i
}id =3and {v
i
}id =3beanorthonormalbasisofthecomplementarysubspacesorthogonaltospan {µ⋆,µ♯
}
and span {ν⋆,ν♯
}
respectively. Recall G
i
= x i⊤µ♯,G(cid:101)i = z i⊤ν♯ and O
ui
∈
Rd ×(d −1) whose columns are
25{u j }j ̸=i (similardefineO vi). Foreach3 ≤i
≤
d,let
(cid:20) µ ν uu ii ,, vv ii (cid:21) = µa ,r νg ∈m Rdi −n 1k∑ =m 1(cid:0) y k+G kG(cid:101)k −G(cid:101)k ·x i⊤O uiµ −G k ·z⊤k O viν(cid:1)2+λm ·(cid:13) (cid:13) (cid:13) (cid:13)(cid:20) µ ν− −O Ou⊤ v⊤i iµ ν♯♯(cid:21)(cid:13) (cid:13) (cid:13) (cid:13)2
2
= (cid:16) A⊤ui,viA ui,vi +λmI(cid:17) −1(cid:16) A⊤ui,vi(cid:0) y+diag(WW(cid:102))(cid:1) +λm(cid:20) O Ou⊤ v⊤i iµ ν♯♯ (cid:21)(cid:17) . (70)
ApplyingLemma3yieldstheclosed-formexpressionfor3 i d,
≤ ≤
(cid:20) (cid:21)(cid:20) (cid:21) (cid:20) (cid:21)
M 11+λ M
12
⟨µ+, u
i ⟩ =
1 (W(cid:102)Xu i) ⊤R
ui,vi , where
M 12 M 22+λ ⟨ν+, v i ⟩ m (WZv i) ⊤R ui,vi
R
ui,vi
= y+diag(WW(cid:102)) −A
ui,vi(cid:20) µ
ν
uu ii ,, vv ii
(cid:21)
, M
11
=
(W(cid:102)Xu i) ⊤P mui,vi(W(cid:102)Xu i)
,
M =
(W(cid:102)Xu i) ⊤P ui,vi(WZv i)
and M =
(WZv i) ⊤P ui,vi(WZv i)
. (71)
12 22
m m
Solvingtheequationinthedisplayaboveyields
⟨µ+,u
i
⟩
=
m1(W(cid:102)Xu i) ⊤R
ui,vi −
MM 221 +2
λ
Mm1 2(WZv i) ⊤R
ui,vi . (72)
M +λ 12
11 − M22+λ
Notethatsince {⟨µ+, u
i
⟩}id =3areidenticallydistributed,weobtain
(cid:110) d (cid:111) (cid:110) (cid:111)
E η +2 =E ∑ µ+, u
k
2 = (d 2) E µ+, u
3
2 . (73)
{ } ⟨ ⟩ − · ⟨ ⟩
k=3
Fortheremainderoftheproof,weomittheindexandletu = u andv = v . Werequirethefollowing
3 3
sequence of lemmas to characterize E µ+, u 2 . The first, whose proof we provide in Section B.2,
{⟨ ⟩ }
relatesittotheexpectationof ∥W(cid:102)R
u,v
∥2 2.
Lemma 7. Consider the assumptions of Theorem 1. Let u = u
3
denote a unit norm vector orthogonal to µ⋆
and µ♯, v denoteaunitnormvectororthogonalto ν⋆ and ν♯, andlet R
u,v
beasin(71). Thereexistsapositive
constantC ,dependingonlyonK andK ,suchthatthefollowingholds.
5 1 2
(cid:12) (cid:12) (cid:12)E {⟨µ+,u ⟩2
}−
E m(cid:8) 2∥ (W(cid:102) λ+R u V,v ∥ )2 2 2(cid:9) (cid:12) (cid:12)
(cid:12)
≤C
5
·(cid:104)σ2+ λmErr ♯
·
lo λg √3( md)(cid:105) . (74)
1
Expanding,weseethatE(cid:8) ∥W(cid:102)R
u,v
∥2 2(cid:9) = mE {G(cid:101) i2R2 i},where
R
i
= y i+G iG(cid:101)i −G(cid:101)ix i⊤O uµ
u,v
−G iz i⊤O vν u,v.
Notethattheestimator(µ ,ν )dependsonthedata(x,z,y ),whichprecludesdirectcomputation
u,v u,v i i i
ofE {G(cid:101) i2R2 i}. Wethusconsiderthefollowingestimatorobtainedbyleavingoutthedatax i,z i,y
i
(cid:34) (i) (cid:35) (cid:13)(cid:20) (cid:21)(cid:13)2
µ
ν
u−−u ,, v(v
i)
= µa ,r νg ∈m Rdi −n 1∑
j
̸=i(cid:0) y j+G jG(cid:101)j −G(cid:101)jx⊤j O uµ −G jz⊤j O vν(cid:1)2+λm ·(cid:13) (cid:13)
(cid:13)
µ ν− −O Ou⊤ v⊤µ ν♯♯ (cid:13) (cid:13)
(cid:13)
2. (75)
Weemphasizethattheestimatorinthepreviousdisplayisobtainedbyleavingbothadirection(u,v)
outaswellasasample(x i,z i,y i)out. Leta
i⊤
= [G(cid:101)ix i⊤O
u
G iz i⊤O v]andΣ
i
= ∑ j=ia ja
⊤j
+λmI foreach
̸
i [m]. Weclaimthat
∈
R
i
=
1+a
i⊤τ i
Σ i−1a
i, where τ
i
= y i+G iG(cid:101)i −G(cid:101)ix i⊤O uµ−u,v(i) −G iz i⊤O vν u−,v(i) , (76)
deferringitsprooftotheend. Thenextlemmarelatestheexpectationof ∥W(cid:102)R
u,v
∥2 2tothescalarsr 1and
r , whicharesolutionstothefixedpointequationsin(32)andthequantity τ definedintheprevious
2 i
display. WeprovideitsproofinSectionB.3.
26Lemma8. ConsidertheassumptionsofLemma7. ThereexistsapositiveconstantC > 0,dependingonlyon
6
K andK ,suchthat
1 2
(cid:12) (cid:12) (cid:12) (cid:12)E m(cid:8) 2(cid:13) (cid:13) (W(cid:102) λ+R u V,v 1(cid:13) (cid:13) )2 2 2(cid:9) − m(λ+1 V 1)2E(cid:26) (cid:0) 1+G(cid:101) i2rG 1−(cid:101) 1i2τ +i2 G i2r 2−1(cid:1)2(cid:27)(cid:12) (cid:12) (cid:12) (cid:12) ≤C 6 ·(cid:0) σ2+Err ♯(cid:1)l √og d1 m.5( λd 2) . (77)
Thefinallemmaremovesthedependenceonτ (76)fromthepreviouslemma. Weprovideitsproof
i
inSectionB.4.
Lemma9. ConsidertheassumptionsofLemma6andletV beasin(35). Let
3
(cid:26) r2r2G(cid:101)4 (cid:27) (cid:26) r2r2G2G(cid:101)2 (cid:27)
ψ(r ,r ,V ) =V r2+E η2 E 1 2 i +E η2 E 1 2 i i .
1 2 3 3 1 { + }· (r 1r 2+r 1G i2+r 2G(cid:101) i2)2 {(cid:101)+ }· (r 1r 2+r 1G i2+r 2G(cid:101) i2)2
Then,thereexistsapositiveconstantC ,whichdependsonlyonK andK ,suchthat
7 1 2
(cid:12) (cid:12)
(cid:12)
(cid:12)E(cid:26)
(cid:0) 1+G(cid:101)
i2rG 1−(cid:101) 1i2τ +i2
G i2r
2−1(cid:1)2(cid:27)
−ψ(r 1,r 2,V
3)(cid:12) (cid:12)
(cid:12) (cid:12) ≤C 7
·max(cid:26) C(σ2+
λ
Err ♯)lo √g6 m(d) ,d−50(cid:27)
. (78)
ApplyingthetriangleinequalityandLemmas7,8,and9insequenceyieldstheinequality
(cid:12) (cid:12) (cid:12) (cid:12)E {⟨µ+,u ⟩2
}−
m(λ+1
V
)2ψ(r 1,r 2,V 3)(cid:12) (cid:12) (cid:12) (cid:12)≲ λ1 mmax(cid:26)(σ2+ λErr ♯)lo √g6 m(d) ,d−50(cid:27) ,
1
where ψ(r ,r ,V ) is as in Lemma 9. Now, applying the relation (73) in conjunction with the relation
1 2 3
λ+V =r d/m,whichholdsbydefinition(32),wededucetheinequality
1 1
(cid:12) (cid:12) (cid:12) (cid:12)E {η +2
}−
(d − d22)mψ(r 1, rr 22,V 3)(cid:12) (cid:12) (cid:12) (cid:12)≲ max(cid:26)(σ2+ λErr ♯)lo √g6 m(d) ,d−50(cid:27) .
1
ArguinginaparallelfashionestablishestheanalogousboundonE η2 . Re-arrangingthenyieldsthe
(cid:101)+
{ }
pairofupperbounds
(cid:12) (d 2)m (cid:12)
(cid:12)c E η2 c E η2 − V (cid:12) ∆ (79a)
(cid:12) 1 · { + }− 2 · {(cid:101)+ }− d2 · 3(cid:12) ≤
(cid:12) (d 2)m (cid:12)
(cid:12)c E η2 c E η2 − V (cid:12) ∆, (79b)
(cid:12) 3 · {(cid:101)+ }− 4 · { + }− d2 · 4(cid:12) ≤
(cid:26) (cid:0) (cid:1) (cid:27)
where∆ =C max
log6(d) Err ♯+σ2
,d 50 and
2 λ√m −
(d 2)m (cid:26) r2G4 (cid:27) (d 2)m (cid:26) r2G2G2 (cid:27)
c =1 − E 2 2 , c = − E 2 1 2 ,
1 − d2 (r r +r G2+r G2)2 2 d2 (r r +r G2+r G2)2
1 2 1 1 2 2 1 2 1 1 2 2
(d 2)m (cid:26) r2G4 (cid:27) (d 2)m (cid:26) r2G2G2 (cid:27)
c =1 − E 1 1 , c = − E 1 1 2 .
3 − d2 (r r +r G2+r G2)2 4 d2 (r r +r G2+r G2)2
1 2 1 1 2 2 1 2 1 1 2 2
Moreover,bydefinitionsofηdetandηdetin(37)and(63),wehavethefollowingrelations
+ (cid:101)+
(d 2)m (d 2)m
c (ηdet)2 c (ηdet)2 = − V , and c (ηdet)2 c (ηdet)2 = − V .
1 · + − 2 · (cid:101)+ d2 · 3 3 · (cid:101)+ − 4 · + d2 · 4
Combingtherelationsinthepreviousdisplaywiththepairofinequalities(79)yields
(cid:12) (cid:16) (cid:17)(cid:12)
(cid:12)c E η2 c E η2 c (ηdet)2 c (ηdet)2 (cid:12) ∆
(cid:12) 1 + 2 (cid:101)+ 1 + 2 (cid:101)+ (cid:12)
{ }− { }− − ≤
(cid:12) (cid:16) (cid:17)(cid:12)
(cid:12)c E η2 c E η2 c (ηdet)2 c (ηdet)2 (cid:12) ∆.
(cid:12) 3 (cid:101)+ 4 + 3 (cid:101)+ 4 + (cid:12)
{ }− { }− − ≤
27Then,uponre-arrangingtermsandapplyingthetriangleinequality,wefindthat
(cid:12) (cid:12) (cid:12) (cid:12)
c (cid:12)E η2 (ηdet)2(cid:12) c (cid:12)E η2 (ηdet)2(cid:12)+∆ and
1 (cid:12) + + (cid:12) 2 (cid:12) (cid:101)+ (cid:101)+ (cid:12)
| |· { }− ≤ | |· { }−
(cid:12) (cid:12) (cid:12) (cid:12)
c (cid:12)E η2 (ηdet)2(cid:12) c (cid:12)E η2 (ηdet)2(cid:12)+∆.
3 (cid:12) (cid:101)+ (cid:101)+ (cid:12) 4 (cid:12) + + (cid:12)
| |· { }− ≤ | |· { }−
Combiningthetwoinequalitiesinthepreviousdisplayyields
(cid:12) (cid:12)
( c c c / c ) (cid:12)E η2 (ηdet)2(cid:12) (1+ c / c ) ∆.
|
1
|−|
2
||
4
| |
3
|
·(cid:12)
{
t+1}− t+1 (cid:12)
≤ |
2
| |
3
| ·
Notethat
(d 2)mE G4 (i) (d 2)m E G4 (ii)
c 1 − { 2} 1 − { 2} 0.5,
1 ≥ − d2 r2 ≥ − d2 (λm/d)2 ≥
1
where step (i) follows from r λm/d (see item 1 in Lemma 19), and step (ii) follows as λm Cd
1
for some constant C large enou≥ gh and (d 2)mE G4 /d2 ≲ 1. Similarly, we see that c 0.5≥ and
− { 2} 3 ≥
c , c 0.1. Puttingtogetherthepiecesyields
2 4
| | | | ≤
(cid:12)
(cid:12) (cid:12)E {η +2 }−(η
+det)2(cid:12)
(cid:12)
(cid:12)
≤10∆≲
max(cid:26) log6(d) λ(cid:0) √Er mr ♯+σ2(cid:1) ,d−50(cid:27)
,
asdesired. Itremainstoestablishtheclaim(76).
Proofoftheclaim(76). Leta
⊤j
= [G(cid:101)jx
⊤j
O
u
G jz
⊤j
O v]foreachj
∈
[n]. KKTconditionof(µ u,v,ν u,v)(70)
and(µ
u−,v(i)
,ν
u−,v(i)
)(75)yields
j∑ [n](cid:16) y j+G jG(cid:101)j −a⊤j (cid:20) µ ν uu ,, vv (cid:21)(cid:17) a j = λm(cid:20) µ νu u, ,v v− −O Ou v⊤ ⊤µ ν♯♯ (cid:21) (80a)
∈
(cid:34) (cid:35) (cid:34) (cid:35)
∑
j
̸=i(cid:16) y j+G jG(cid:101)j −a⊤j µ
ν
u−−u ,, v(v( ii )) (cid:17) a j = λm µ
ν
u−u −,, vv( (i i) )− −O Ou⊤ v⊤µ ν♯♯ . (80b)
Subtractingoneinequalitybytheotherinequalityinthedisplayaboveyields
(cid:20) µ
ν
uu ,, vv (cid:21) −(cid:34) µ
ν
u−−u ,, v(v( ii )) (cid:35) = (cid:16) ∑ j=ia ja⊤j +λmI(cid:17) −1 R ia
i
= Σ i−1R ia i.
̸
(cid:18)(cid:20) (cid:21) (cid:34) (i) (cid:35)(cid:19)
Note that, by definition of R and τ, τ R = a µ u,v µ u−,v . Putting the two pieces
i i i − i i⊤ ν u,v − ν u−,v(i)
togetheryieldsτ
i
−R
i
= a i⊤Σ i−1a
i
·R i. Arrangingthetermsyieldsthedesiredresult.
5 Proof of Theorem 2: Convergence guarantees
Our convergence result reposes on the following lemma, which provides a two-sided, one-step im-
provementbound. Weprovideitsproof—whichreliesonpropertiesofthedeterministicpredictions—
inSection5.1.
Lemma 10. Consider (µ♯,ν♯) Rd and let Err ♯,L ♯, and (cid:101)L ♯ be as in (10) and (24). There exists a tuple of
∈
universal,positiveconstants(c,c ,c ,C,C ,C )suchthatif
1 2 1 2
Err
t
c, λm C(1+σ), 0.2 L t,(cid:101)L
t
3 and m Clog12(d),
≤ ≥ ≤ ≤ ≥
28thenwithprobabilityatleast1 d 18,bothofthefollowinghold.
−
−
(cid:16) c (cid:17) C σ2d C log6(d)σ2
1
−
λ2 ·Err t+ λ2
2m −
1
λ√m
≤Err t+1
(cid:16) c (cid:17) (cid:16) σ2d log6(d)σ2(cid:17)
1 1 Err +C + , (81a)
≤ − λ · t 1 λ2m λ√m
and
C √Err C log6(d)σ
|α t+1 −α t |, |(cid:101)α t+1 −(cid:101)α t
| ≤
1
λ
t + 1
λ√m
. (81b)
(cid:16) (cid:110) (cid:111)(cid:17)
Equippedwiththislemma,weproveTheorem2byinductiononT.LetT⋆ = cλ
1
log min σλ 2m d, log√ 6(m
d)σ2
.
Wefirststateourinductionhypothesisfor0 T T⋆.
≤ ≤
InductionHypothesis: Withprobabilityatleast1 (T+1)d 18,theiterates(µ ,ν)T definedin(5)
− − t t t=0
satisfythesandwichrelation(81a)aswellasthebound(81b). Further,Err
t
c,0.3 L t,(cid:101)L
t
1.7forall
≤ ≤ ≤
0 t T,wherecisthesameconstantasinLemma10.
≤ ≤
Base case: T = 0. Note Err
0
K
0
c as long as K
0
c and 0.5 L 0,(cid:101)L
0
1.5 by assumption.
≤ ≤ ≤ ≤ ≤
ThenapplyingLemma10weobtainthatwithprobabilityatleast1 d 18,bothinequalities(81a)and
−
−
inequality(81b)hold,whichconcludesthebasecase.
Induction step: Suppose the induction hypothesis holds for some T T⋆ 1. That is, inequali-
≤ −
ties(81a)and(81b)holdsforall0 t T withprobabilityatleast1 (T+1)d 18. Weneedtoshow
−
≤ ≤ −
theinductionhypothesisholdsatiterateT+1. Applyinginequality(81a)recursivelyforall0 t T
≤ ≤
yields
Err t+1
≤
ρ 1t+1Err 0+
∑t
ρ 1k ·C
1(cid:16) λσ 22 md
+
log λ6 √(d m)σ2(cid:17)
≤
ρ 1t+1Err 0+
C c1(cid:16)σ λ2 md
+
log √6( md)σ2(cid:17)
, (82)
k=0 1
whereρ =1 c1 andinthelaststepweusedthebound∑t ρk λ/c . Consequently,
1 − λ k=0 1 ≤ 1
C (cid:16)σ2d log6(d)σ2(cid:17)
Err T+1 ≤Err 0+ c1
λm
+
√m ≤
c, (83)
1
where the final step follows since Err K , λm C(1+σ2)d and m C(1+σ4)log12(d) and by
0 0
≤ ≥ ≥
taking K smallenoughandC largeenough. Continuing,applyinginequality(81b)recursivelyforall
0
0 t Tyields
≤ ≤
|α T+1 −α 0
| ≤
∑T
|α t+1 −α t
| ≤
C
λ1
∑T
√Err t+
C 1(T+ λ1 √)l mog6(d)σ
.
t=0 t=0
Then,usinginequality(82)toupperbooundErr yields
t
|α T+1 −α 0
| ≤
C λ1 ∑T ρ 1t/2(cid:112) K 0+ C λ1 √ √C c1(cid:16)σ λ2 md + log √6( md)σ2(cid:17)1/2 (T+1)+ C 1(T+ λ1 √)l mog6(d)σ
t=0 1
≤
2 cC 1(cid:112)
K 0+
λC √11. c5 (cid:16)σ λ2 md
+
log √6( md)σ2(cid:17)1/2
T⋆+
C 1T⋆ λl √og m6(d)σ
,
1 1
(cid:16) (cid:17)t
where in the last step we use T+1
≤
T⋆ and ∑ tT =0ρ 1t/2
≤
∑ tT
=0
1
−
2c λ1
≤
2 cλ 1. Thus, using the
numericinequality√a+b √a+√bforall a,b > 0andsubstitutingthedefinitionof T⋆,weobtain
≤
theinequality
C1.5 (cid:16)σ2d log6(d)σ2(cid:17)1/2 C1.5(cid:18)(cid:114) σ2d (cid:16)λm(cid:17) (cid:115) log6(d)σ2 (cid:16) √m (cid:17)(cid:19)
1 + T⋆ 1 log + log .
λ√c
1
λm √m ≤ c1 1.5 λm σ2d √m σ2log6(d)
29Continuing,sinceλm C(1+σ2)dandm C(1+σ4)log12(d)then
≥ ≥
σ2d 1 log6(d)σ2 1
, , and √xlog(1/x) 0asx 0.
λm ≤ C √m ≤ √C → →
Thus,ifweletCbealargeenoughconstant,weobtaintheestimate
(cid:114) (cid:115)
σ2d (cid:16)λm(cid:17) log6(d)σ2 (cid:16) √m (cid:17) c1.5
log + log 0.01 1 .
λm σ2d √m σ2log6(d) ≤ C1.5
1
Similarly,
C 1T⋆log6(d)σ C 1log6(d)σ (cid:16) √m (cid:17)
log 0.01.
λ√m ≤ c
1
√m log6(d)σ2 ≤
Puttingallthepiecestogetheryields
α T+1 α 0
2C 1(cid:112)
K 0+0.02 0.03,
| − | ≤ c ≤
1
wherethelaststepwetakeK smallenough. Byassumption,wehaveα L 1.5and β Err =
0 0 0 0 0
≤ ≤ ≤
K 0.01 so that α L β 0.5 0.01 0.4. Combining this bound with the inequality in
0 0 0 0
≤ ≥ − ≥ − ≥
the display above, we deduce that α T+1 1.5+0.03 1.6 and α T+1 0.4 0.03 0.3. Further,
≤ ≤ ≥ − ≥
by inequality (83), we obtain that β T+1 √Err T+1 √c 0.1. Putting the pieces together yields
≤ ≤ ≤
L T+1 α T+1 0.3 and L T+1 α T+1+β T+1 1.7. Proceeding similarly yields 0.3 (cid:101)L T+1 1.7.
≥ ≥ ≤ ≤ ≤ ≤
Summarizing,wehaveshownthatatiterationT+1,bothofthefollowinghold
Err T+1 c and 0.3 L T+1,(cid:101)L T+1 1.7.
≤ ≤ ≤
ThenapplyingLemma10,weobtainthatinequality(81a)andinequality(81b)holdsfort = T+1with
probabilityatleast1 d 18.Combiningwiththeinductionhypothesis,weobtainthatfor0 t T+1,
−
− ≤ ≤
inequality(81a)andinequality(81b)holdswithprobabilityatleast1 (T+2)d 18,whichestablishes
−
−
theinductivestep.
Theorem2directlyfollowsfrominequality(81a). Thisconcludestheproof.
WenextjustifyseveralconsequencesofTheorem2,i.e.,inequalities(18),(19)and(20).
Proofofinequality(18): Notethatbysettingλ =C(1+σ2)d/mandm log12(d)(1+σ4),weobtain
≫
that
log6(d)σ2 σ2 Cσ2d
= .
λ√m ≪ λ(1+σ2) λ2m
It means that in inequality (16), the term
log6(d)σ2
is a small order term compared with the term
σ2d.
λ√m λ2m
Consequently, the desired result follows immediately from inequality (16) by letting in λ = C(1+
σ2)d/m.
Proof of inequality (19): To reduce the notational burden, we use the shorthand ρ = 1 c1m ,
1 − C(1+σ2)d
ρ
2
= 1
−
C(1c +2m σ2)d, and T⋆ = cλ
1
log(cid:16) min(cid:110)
σλ 2m d, σ2l√ ogm
6(d)(cid:111)(cid:17)
= cλ
1
log(cid:16)
C0(1 σ+
2σ2)(cid:17)
. Applying inequal-
ity(18)recursivelyyields,forall1 t T⋆,
≤ ≤
ρt Err
+t ∑−1
ρk
C 2σ2
Err ρt Err
+t ∑−1
ρk
2C 1σ2
.
2· 0 2· 2λ2m ≤ t ≤ 1· 0 1· λ2m
k=0 k=0
Consequently,fort λ log(Err /σ2) = C(1+σ2)d log(Err /σ2),weobtain
≥ c1 0 c1m 0
(cid:110) c m (cid:111) 2C σ2
Err exp 1 t Err + 1 ≲ σ2 (84)
t ≤ − C (1+σ2d) · · 0 c λm
0 1
30whereinthefirststep,weusedthebounds
ρt =
(cid:16)
1
c 1m (cid:17)t exp(cid:110) c 1m t(cid:111)
, and
t ∑−1
ρk
+ ∑∞
ρk =
C(1+σ2)d
=
λ
,
1 − C(1+σ2)d ≤ − C(1+σ2)d · 1 ≤ 1 c m c
k=0 k=0 1 1
and in the second step, we use the setting λ = C(1+σ2)d/m. Continuing, we obtain that for t
≤
0.5 λ log(Err /σ2) = 0.5C(1+σ2)d log(Err /σ2),
· c2 0 c2m 0
Err ρt Err
+t ∑−1
ρk
C 2σ2
ρt Err
(i) exp(cid:110)
2
c 2m t(cid:111)
σ2, (85)
t ≥ 2· 0 2· 2λ2m ≥ 2· 0 ≥ − C(1+σ2)d · ≥
k=0
whereinstep(i)weusedthenumericalinequality1 x exp 2x for0 x 1/2sothat
− ≥ {− } ≤ ≤
(cid:16) c m (cid:17)t (cid:110) c m (cid:111)
ρt = 1 2 exp 2 2 t .
2 − C(1+σ2)d ≥ − C(1+σ2)d ·
Now,puttingtogetherinequalities(84),(85)together,weseethatittakes
(cid:16) (cid:16)Err (cid:17)(cid:17) (cid:16)d(1+σ2) (cid:16)Err (cid:17)(cid:17)
τ = Θ λlog 0 = Θ log 0 iterationstoguarantee Err ≲ σ2.
σ2 m σ2 τ
Proof of inequality (20): We first prove the upper bound of the iteration complexity. Applying in-
equality(16)recursivelyyields
Err
(cid:16)
1
c 1(cid:17)t
Err
+t ∑−1(cid:16)
1
c 1(cid:17)k (cid:16)C 1σ2d
+
C 1log6(d)σ2(cid:17)
t ≤ − λ · 0 − λ · λ2m λ√m
k=0
≲ e−c λ1t ·Err 0+ d λσ m2 + log √6( md)σ2 ,
whereinthelaststepweused∑t k−=1 0(1 −c 1/λ)k ≲ λ. Consequently,weobtain
dσ2 log6(d)σ2 λ (cid:16) (cid:110)λm √m (cid:111)(cid:17)
Err ≲ + fort log Err min , . (86)
t λm √m ≥ c
1
0 · dσ2 log6(d)σ2
Wethenprovethelowerboundofiterationcomplexity. Applyinginequality(16)recursivelyyields
Err
(cid:16)
1
c 2(cid:17)t
Err
+t ∑−1(cid:16)
1
c 2(cid:17)k (cid:16)C 2σ2d C 1log6(d)σ2(cid:17)
t ≥ − λ · 0 − λ · λ2m − λ√m
k=0
≥
e−2c λ2t
·Err
0
−
C 1l cog √6( md)σ2
,
2
where in the last step we used the numerical inequality 1 x exp 2x for 0 x 1/2 so that
− ≥ {− } ≤ ≤
(cid:16) 1
−
c λ2(cid:17)t
≥
e −2c λ2t ,and∑t k−=1 0(cid:16) 1
−
c λ2(cid:17)k
≤
cλ 2. Consequently,weobtain
C (cid:16)σ2d σ2log6(d)(cid:17) 0.5λ(cid:18) (cid:18) (cid:26) λm √m (cid:27)(cid:19) (cid:16)2C (cid:17)(cid:19)
Err 1 + , fort log Err min , log 1 .
t ≥ 2c
2
λm √m ≤ c
2
0 · dσ2 log6(d)σ2 − c
2
Combining the inequality in the display above with inequality (86) together yields the desired result.
315.1 ProofofLemma10
Ourproofreliescruciallyonpropertiesofthedeterministicpredictions, summarizedinthefollowing
lemma,whoseproofweprovideinSectionC.
Lemma11. Letthefunctions F m,d,σ,λ,F(cid:101)m,d,σ,λ,H m,d,σ,λ,H(cid:101)m,d,σ,λ,S m,d,σ,λ,S(cid:101)m,d,σ,λ : R4
→
Rbeasdefinedin
Section3.2. Givenα, (cid:101)α,β,β(cid:101) R,let
∈
αdet = F m,d,σ,λ(α,β, (cid:101)α,β(cid:101)), (βdet)2 = (cid:0) H m,d,σ,λ(α,β, (cid:101)α,β(cid:101))(cid:1)2+S m,d,σ,λ(α,β, (cid:101)α,β(cid:101)),
(cid:101)αdet = F(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)), (β(cid:101)det)2 = (cid:0) H(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101))(cid:1)2+S(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)),
Err = (α (cid:101)α 1)2+β2+β(cid:101)2, Errdet = (αdet (cid:101)αdet 1)2+(βdet)2+(β(cid:101)det)2.
− −
There exists a tuple of universal, positive constants (c,c ,c ,C ,C ) such that if Err c and 0.2 (α2+
1 2 1 2
≤ ≤
β2)21 ,( (cid:101)α2+β(cid:101)2)21 3thenthefollowinghold.
≤
(cid:16) c (cid:17) C σ2d (cid:16) c (cid:17) C σ2d
1 2 Err+ 2 Errdet 1 1 Err+ 1 , (87a)
− λ · λ2m ≤ ≤ − λ · λ2m
(αdet αdet 1)2+(ιdet)2+(ιdet)2 C Err, αdet , αdet 4 (87b)
(cid:101) (cid:101) 1 (cid:101)
− ≤ | | | | ≤
C √Err
and αdet α , αdet α 1 . (87c)
(cid:101) (cid:101)
| − | | − | ≤ λ
WenowmakeuseofLemma11toproveLemma10. Wenowproveinequalities(81a)and(81b)inturn,
startingwithinequality(81a).
Proofofinequality(81a): Westartwithbounding(α t+1(cid:101)α t+1 1)2.Recallthedeterministicpredictions
−
αd t+et
1
= F m,d,σ,λ(α t,β t, (cid:101)α t,β(cid:101)t)and (cid:101)αd t+et
1
= F(cid:101)m,d,σ,λ(α t,β t, (cid:101)α t,β(cid:101)t). ApplyingTheorem1,weobtainthatwith
probabilityatleast1 d 20
−
−
|α t+1 −αd t+et 1|, |(cid:101)α t+1 −(cid:101)αd t+et 1| ≤C′log6(d)(cid:0) √Err t+σ(cid:1) /(λ√m), (88)
where C is some universal constant. Using inequality (87b) in Lemma 11 yields αdet , αdet 4.
′ | t+1| |(cid:101)t+1| ≤
Puttingthetwopiecestogetheryieldsthepairofupperbounds
(i)
|α t+1
| ≤
|αd t+et 1|+C′log6(d)(cid:0) √Err t+σ(cid:1) /(λ√m) ≤5 and |(cid:101)α t+1
|
≤5, (89)
wherestep(i)followssincem Clog12(d),λ C(1+σ)d/mandErr c.Then,weapplythetriangle
t
≥ ≥ ≤
inequalitytoobtain
(cid:12) (cid:12) |α t+1(cid:101)α t+1 −1 |−|αd t+et 1(cid:101)αd t+et 1−1 |(cid:12) (cid:12) ≤ |(cid:101)α t+1 |·|α t+1 −αd t+et 1|+ |αd t+et 1|·|(cid:101)α t+1 −(cid:101)αd t+et 1|
10C′log6(d)(cid:0)
√Err
t+σ(cid:1)
/(λ√m),
≤
wherethelaststepfollowsuponinvokinginequalities(88)and(89).Usinginequality(87b)inLemma11
yields αdetαdet 1 ≲√Err . Consequently,weobtain
|
t+1(cid:101)t+1−
|
t
|α t+1(cid:101)α′t+1−1
| ≤
|αd t+et 1(cid:101)αd t+et 1−1 |+10C′log6(d)(cid:0) √Err t+σ(cid:1) /(λ√m)≲√Err t+σ, (90)
wherethelastinequalityfollowsasm Clog12(d)andλ C(1+σ)d/m C. Puttingallthepieces
≥ ≥ ≥
togetheryields
(cid:16) (cid:17)
|(α t+1(cid:101)α t+1 −1)2 −(αd t+et 1(cid:101)αd t+et 1−1)2 | ≤ |α t+1(cid:101)α t+1 −1 |+ |αd t+et 1(cid:101)αd t+et 1−1 | ·|α t+1(cid:101)α t+1 −αd t+et 1(cid:101)αd t+et 1|
≲(cid:0) √Err +σ(cid:1) log6(d)(cid:0) √Err +σ(cid:1) /(λ√m)≲ log6(d)(Err +σ2)/(λ√m). (91)
t t t
·
32Wethenturntobound(β t+1)2+(β(cid:101)t+1)2. Welet
(βd t+et 1)2 = (cid:0) H m,d,σ,λ(α t,β t, (cid:101)α t,β(cid:101)t)(cid:1)2+S m,d,σ,λ(α t,β t, (cid:101)α t,β(cid:101)t)2,
(β(cid:101)d t+et 1)2 = (cid:0) H(cid:101)m,d,σ,λ(α t,β t, (cid:101)α t,β(cid:101)t)(cid:1)2+S(cid:101)m,d,σ,λ(α t,β t, (cid:101)α t,β(cid:101)t)2.
ApplyingTheorem1,weobtainthatwithprobabilityatleast1 d 20,
−
−
(cid:12) (cid:12)(βd t+et 1)2+(β(cid:101)t+1)2 −(cid:0) (βd t+et 1)2+(β(cid:101)d t+et 1)2(cid:1)(cid:12) (cid:12)≲ log6(d)(Err t+σ2)/(λ√m). (92)
LetErrd t+et
1
= (αd t+et 1(cid:101)αd t+et 1−1)2+(βd t+et 1)2+(β(cid:101)d t+et 1)2. Combiningtheinequalities(91)and(92)yields
|Err t+1 −Errd t+et 1| ≤C′log6(d)(Err t+σ2)/(λ√m), (93)
whereC isauniversalconstant. Consequently,weobtainthat
′
C log6(d)(Err +σ2) (cid:16) c (cid:17) C σ2d C log6(d)(Err +σ2)
Err t+1 ≤Errd t+et 1+ ′
λ√m
t
≤
1
−
λ1 Err t+ λ1
2m
+ ′
λ√m
t
(cid:16) c (cid:17) C σ2d C log6(d)σ2
1 1 Err + 1 + ′ ,
≤ − 2λ t λ2m λ√m
wherethesecondinequalityfollowsbyinvoking(87a)toupperboundErrdet
andthelaststepfollows
t+1
asm Clog12(d),sothatbylettingClargeenough,
≥
C ′log6(d)Err t C ′Err t c 1′Err t
.
λ√m ≤ λ√C ≤ 2λ
ThisprovesthedesiredupperboundofErr t+1 ininquality(81a)bynotingc 1,C 1 andC ′ areuniversal,
positiveconstants. TurningtothelowerboundofErr t+1,usinginequalities(87a),(93)andlettingm
≥
Clog12(d)forClargeenoughyields
(cid:16) 2c (cid:17) C σ2d C log6(d)σ2
Err t+1
≥
1
−
λ2 Err t+ λ2
2m −
′
λ√m
.
ThisprovesthedesiredlowerboundofErr t+1ininquality(81a)uponadjustingconstants.
Proofofinequality(81b): Applyinginequality(87c),weobtainthat
|αd t+et 1−α
t
| ∨
|(cid:101)αd t+et 1−(cid:101)α
t
|
≤C 1′√Err t/λ.
Combiningtheinequalityinthedisplayabovewithinequality(88),weobtain
|α t+1 −α t
| ≤
|α t+1 −αd t+et 1|+ |αd t+et 1−α t
| ≤
C ′log6(d λ) √(cid:0) √ mErr t+σ(cid:1)
+
C 1′√ λErr
t
C log6(d)σ C √Err
1 + 1 t ,
≤ λ√m λ
where the last step follows from the assumption m Clog12(d). This proves the desired inequal-
≥
ity(81b).Proceedinginidenticalfashionyieldstheboundon (cid:101)α t+1 (cid:101)α t ,whichcompletestheproof.
| − |
6 Discussion
In this paper, we derived deterministic trajectory predictions for the stochastic prox-linear method
whenappliedtorankonematrixsensingwithGaussiandata. Wethenusedthesepredictionstoderive
concrete,two-sidedconvergenceguaranteeselucidatingthetrade-offbetweenbatch-sizeandstep-size
33as well as the sensitivity of the convergence guarantees to the inherent noise in the problem. Several
interestingopenquestionsremainandwedetailafewhere.
While our one-step guarantees in Theorem 1 hold for all batch-sizes 1 m d, our convergence
≤ ≤
guaranteesinTheorem2requirebatch-sizeswhichscalepoly-logarithmicallyinthedimensiond. This
deficiency stems from bounds on the deviation around the deterministic predictions which incur a
polylog(d) factor. Removing these logarithmic factors in Theorem 1 would immediately extend our
convergenceguaranteestoconstantbatch-sizesettings. Inasimilarspirit,whileourdeterministictra-
jectorypredictions—whichweillustrateinSection2.3—demonstrateexcellentadherencetotheempir-
icaltrajectory,ourresultsonlyshowthattheempiricaltrajectoryanddeterministictrajectoryenjoythe
sameconvergencerate. Itwouldbeinterestingtoshowexactconvergenceoftheempiricaltrajectoryto
thedeterministictrajectory,forinstanceviaaso-calledenvelopeguarantee(Chandrasekheretal.,2023,
Theorem3(b)).
Morebroadly,ourguaranteesrequiredthemini-batchestobeobtainedinanonlinefashion. While
thisincursanearlyoptimalsamplecomplexityofO(d(1+σ2)log(1/σ2))toreacherrorσ2,itdoesnot
allowforsamplestobere-used. Aninterestingopenquestioninthisdirectionwouldbetounderstand
theeffectofsamplere-useanddeveloptrajectorypredictionsinthissetting.
Acknowledgments
ThisworkwassupportedinpartbytheNSFundergrantsCCF-2107455andDMS-2210734,byresearch
awards/gifts from Adobe, Amazon, and Mathworks, and by European Research Council Advanced
Grant101019498.KAVwouldliketothankAaronMishkinandKaranChadhaforhelpfulconversations
andusefulpointerstotheliterature.
References
A. Agarwal, S. Negahban, and M. J. Wainwright. Fast global convergence of gradient methods for
high-dimensionalstatisticalrecovery. TheAnnalsofStatistics,40(5):2452–2482,2012.
A.Ahmed,B.Recht,andJ.Romberg. Blinddeconvolutionusingconvexprogramming. IEEETransac-
tionsonInformationTheory,60(3):1711–1732,2013.
G. B. Arous, R. Gheissari, and A. Jagannath. High-dimensional limit theorems for SGD: Effective dy-
namicsandcriticalscaling. CommunicationsonPureandAppliedMathematics,2023.
H.AsiandJ.C.Duchi. Theimportanceofbettermodelsinstochasticoptimization. Proceedingsofthe
NationalAcademyofSciences,116(46):22924–22930,2019a.
H. Asi and J. C. Duchi. Stochastic (approximate) proximal point methods: Convergence, optimality,
andadaptivity. SIAMJournalonOptimization,29(3):2257–2290,2019b.
H.Asi,K.Chadha,G.Cheng,andJ.C.Duchi. Minibatchstochasticapproximateproximalpointmeth-
ods. Advancesinneuralinformationprocessingsystems,33:21958–21968,2020.
K.Balasubramanian,P.Ghosal,andY.He. High-dimensionalscalinglimitsandfluctuationsofonline
least-squaresSGDwithsmoothcovariance. arXivpreprintarXiv:2304.00707,2023.
M.BayatiandA.Montanari. TheLASSOriskforGaussianmatrices. IEEETransactionsonInformation
Theory,58(4):1997–2017,2011.
G.BenArous,R.Gheissari,andA.Jagannath. Onlinestochasticgradientdescentonnon-convexlosses
fromhigh-dimensionalinference. TheJournalofMachineLearningResearch,22(1):4788–4838,2021.
P.CampisiandK.Egiazarian. Blindimagedeconvolution: theoryandapplications. CRCpress,2017.
M.Celentano,A.Montanari,andY.Wu. Theestimationerrorofgeneralfirstordermethods. InConfer-
enceonLearningTheory,pages1078–1141,2020.
34M.Celentano,C.Cheng,andA.Montanari. Thehigh-dimensionalasymptoticsoffirstordermethods
withrandomdata. arXivpreprintarXiv:2112.07572,2021.
K. Chadha, G. Cheng, and J. Duchi. Accelerated, optimal and parallel: Some results on model-based
stochasticoptimization. InInternationalConferenceonMachineLearning,pages2811–2827,2022.
K. A. Chandrasekher, M. Lou, and A. Pananjady. Alternating minimization for generalized rank one
matrixsensing: Sharppredictionsfromarandominitialization. arXivpreprintarXiv:2207.09660,2022.
K. A. Chandrasekher, A. Pananjady, and C. Thrampoulidis. Sharp global convergence guarantees for
iterativenonconvexoptimizationwithrandomdata. TheAnnalsofStatistics,51(1):179–210,2023.
Y. Chi, Y. M. Lu, and Y. Chen. Nonconvex optimization meets low-rank matrix factorization: An
overview. IEEETransactionsonSignalProcessing,67(20):5239–5269,2019.
E.Collins-Woodfin,C.Paquette,E.Paquette,andI.Seroussi. HittingtheHigh-DimensionalNotes: An
ODEforSGDlearningdynamicsonGLMsandmulti-indexmodels. arXivpreprintarXiv:2308.08977,
2023.
D.DavisandD.Drusvyatskiy.Stochasticmodel-basedminimizationofweaklyconvexfunctions.SIAM
JournalonOptimization,29(1):207–239,2019.
D. Davis, D. Drusvyatskiy, and V. Charisopoulos. Stochastic algorithms with geometric step decay
convergelinearlyonsharpfunctions. MathematicalProgramming,pages1–46,2023.
D. L. Donoho, A. Maleki, and A. Montanari. Message-passing algorithms for compressed sensing.
ProceedingsoftheNationalAcademyofSciences,106(45):18914–18919,2009.
J.C.DuchiandF.Ruan. Stochasticmethodsforcompositeandweaklyconvexoptimizationproblems.
SIAMJournalonOptimization,28(4):3229–3259,2018.
N. El Karoui, D. Bean, P. J. Bickel, C. Lim, and B. Yu. On robust regression with high-dimensional
predictors. ProceedingsoftheNationalAcademyofSciences,110(36):14557–14562,2013.
C. Gerbelot, E. Troiani, F. Mignacco, F. Krzakala, and L. Zdeborova´. Rigorous dynamical mean field
theoryforstochasticgradientdescentmethods. arXivpreprintarXiv:2210.06591,2022.
S.M.JefferiesandJ.C.Christou. Restorationofastronomicalimagesbyiterativeblinddeconvolution.
TheAstrophysicalJournal,415:862,1993.
C. Paquette and E. Paquette. Dynamics of stochastic momentum methods on large-scale, quadratic
models. InAdvancesinNeuralInformationProcessingSystems,volume34,pages9229–9240,2021.
C.Paquette,K.Lee,F.Pedregosa,andE.Paquette.SGDinthelarge:Average-caseanalysis,asymptotics,
andstepsizecriticality. InConferenceonLearningTheory,pages3548–3626,2021.
B. Recht, M. Fazel, and P. A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations
vianuclearnormminimization. SIAMreview,52(3):471–501,2010.
Y. S. Tan and R. Vershynin. Online Stochastic Gradient Descent with Arbitrary Initialization Solves
Non-smooth,Non-convexPhaseRetrieval. JournalofMachineLearningResearch,24(58):1–47,2023.
S.Vaswani,B.Dubois-Taine,andR.Babanezhad. Towardsnoise-adaptive,problem-adaptive(acceler-
ated)stochasticgradientdescent. InInternationalConferenceonMachineLearning,pages22015–22059,
2022.
R. Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47.
Cambridgeuniversitypress,2018.
X. Wang and H. V. Poor. Blind equalization and multiuser detection in dispersive CDMA channels.
IEEETransactionsonCommunications,46(1):91–103,1998.
L.Warnke. Onthemethodoftypicalboundeddifferences. Combinatorics,ProbabilityandComputing,25
(2):269–299,2016.
35A Deferred proofs for the parallel component
This appendixis organizedas follows. Sections A.1and A.2 arededicated tothe proofs ofLemmas 1
and2, respectively, eachofwhichisrequiredtoboundthestochasticerroroftheparallelcomponent.
Then,inSectionsA.3andA.4,weprovidetheproofsofLemmas3and4,respectively,eachofwhichis
requiredtoboundthebiasoftheparallelcomponent.
A.1 ProofofLemma1
Weproveeachpartinturn,startingwithpart(a).
(cid:12) (cid:12)
ProofofLemma1(a): Bydefinitionof f u (43)andtheassumption u 2 = 1,webound f u as(cid:12)f u(cid:12)
(cid:13)
(cid:13)[µ ⊤+
|
µ
⊤+](cid:13)
(cid:13) 2.
Bythedefinitionof(µ+,ν+)(6)andΣ,weconsiderthe∥ e∥ quivalentcharacter| iza|
tion
≤
(cid:20) µ ν++(cid:21) = Σ −1(cid:18) k∑ =n 1(y k+G kG(cid:101)k) ·a k+λm(cid:20) µ ν♯♯(cid:21)(cid:19) . (94)
Applyingthetriangleinequalityandusingthethreebounds Σ −1 op (λm) −1,(cid:12) (cid:12)y k+G kG(cid:101)k(cid:12) (cid:12) C(σ+
∥ ∥ ≤ ≤
1)log(d),and x , z ≲√d,weobtainthebound
k 2 k 2
∥ ∥ ∥ ∥
(cid:13) (cid:13)
(cid:13)
(cid:13)(cid:20) µ ν++(cid:21)(cid:13) (cid:13)
(cid:13)
(cid:13) ≤
C(σ+1) λlo mg2(d)√dm
+L ♯+(cid:101)L ♯
≤
d,
2
whereinthelaststepweinvokedtheassumptions λm C d(1+σ) and m d. Weturnnowtothe
0
≥ ≤
proofofpart(b).
ProofofLemma1(b): Sinceρ(cid:0) x ,z ,ϵ n , x ,z ,ϵ n (cid:1) 2,withoutlossofgenerality,wesup-
{ k k k }k=1 { ′k ′k k′ }k=1 ≤
pose(x ,z ,ϵ ) = (x ,z ,ϵ )forallk [m] i,j .Webeginbyclaimingthefollowingpairofstructural
k k k ′k ′k k′
∈ \{ }
relations
(cid:20) µ ν++(cid:21) = (cid:20) µ
ν
−− (( ii ))(cid:21) + y i+G iG(cid:101)i − 1G(cid:101) +ix ai⊤ i⊤µ Σ− i−(i 1) a−
i
G iz i⊤ν −(i) ·Σ i−1a i, (95a)
(cid:20) µ
ν
−−
(( ii ))(cid:21)
=
(cid:20) µ
ν
−−
(( ii ,, jj ))(cid:21)
+
y j+G jG(cid:101)j
−
1G(cid:101) +jx ⊤j aµ
⊤j
− Σ( i−i ,, jj 1)
a−
j
G jz ⊤j ν −(i,j)
·Σ i−,j1a j, (95b)
deferring their proofs to the end. Taking these relations as given, and noting that Σ i−1,Σ i−,j1
⪰
0, we
deducetheinequality
(cid:12) (cid:12) (cid:12) (cid:12)f u(cid:0) {x k,z k,ϵ k }m k=1(cid:1) −(cid:68) u,(cid:20) µ ν− (( ii ,, jj ))(cid:21)(cid:69)(cid:12) (cid:12) (cid:12)
(cid:12) ≤
(cid:12) (cid:12)y i+G iG(cid:101)i −G(cid:101)ix i⊤µ−(i) −G iz i⊤ν−(i)(cid:12) (cid:12) ·(cid:12) (cid:12)u⊤Σ i−1a i(cid:12) (cid:12)
−
+(cid:12) (cid:12)y j+G jG(cid:101)j −G(cid:101)jx⊤j µ−(i,j) −G jz⊤j ν−(i,j)(cid:12) (cid:12) ·(cid:12) (cid:12)u⊤Σ i−,j1a j(cid:12) (cid:12).
Recallingthaty
i
= x i⊤µ⋆ ·z i⊤ν⋆+ϵ
i
andapplyingtriangleinequalityyields
(cid:12) (cid:12)y i+G iG(cid:101)i −G(cid:101)ix i⊤µ−(i) −G iz i⊤ν−(i)(cid:12) (cid:12)
≤
|ϵ i |+(cid:12) (cid:12)x i⊤µ⋆ ·z i⊤ν⋆ −x i⊤µ♯ ·z i⊤ν♯(cid:12) (cid:12)
+(cid:12) (cid:12)x i⊤(µ♯ −µ−(i)) ·z i⊤ν♯(cid:12) (cid:12)+(cid:12) (cid:12)x i⊤µ♯ ·z i⊤(ν♯ −ν−(i))(cid:12) (cid:12). (96)
Wethendecomposeµ♯ intotwoorthogonaldirectionsµ⋆,µ ⊥(similarlyforν♯)tobound
(cid:12) (cid:12)
(cid:12)x i⊤µ⋆z i⊤ν⋆ −x i⊤µ♯z i⊤ν♯(cid:12)
(cid:12) (cid:12)
= (cid:12)(α♯(cid:101)α♯ −1)x i⊤µ⋆ ·z i⊤ν⋆ −β♯(cid:101)α♯x i⊤µ⊥z i⊤ν⋆ −β(cid:101)♯α♯x i⊤µ⋆z i⊤ν⊥ −β♯β(cid:101)♯x i⊤µ⊥z i⊤ν⊥(cid:12)
≲(cid:0)(cid:12)
(cid:12)α♯(cid:101)α♯
1(cid:12) (cid:12)+β♯+β(cid:101)♯(cid:1)
log(d), (97)
− ·
36whereinthelaststepweused {x i,z i,ϵ i }im =1 ∈ S and L ♯,(cid:101)L ♯ ≲ 1. Proceedingsimilarlyyieldsthepairof
upperbounds
(cid:12) (cid:12)x i⊤(µ♯ −µ−(i)) ·z i⊤ν♯(cid:12) (cid:12)≲ log(d)(cid:13) (cid:13)µ♯ −µ−(i)(cid:13) (cid:13) 2, and
(cid:12) (cid:12)x i⊤µ♯ ·z i⊤(ν♯ −ν−(i))(cid:12) (cid:12)≲ log(d)(cid:13) (cid:13)ν♯ −ν−(i)(cid:13) (cid:13) 2.
Then,usingthedefinitionof(µ (i),ν (i))asminimizersof(44a),weobtaintheinequality
− −
∑(cid:0) y k+G kG(cid:101)k −G(cid:101)kx⊤k µ−(i) −G kz⊤k ν−(i)(cid:1)2+λm ·(cid:0)(cid:13) (cid:13)µ−(i) −µ♯(cid:13) (cid:13)2 2+(cid:13) (cid:13)ν−(i) −ν♯(cid:13) (cid:13)2 2(cid:1)
k=i
̸
≤
∑(cid:0)
y k+G kG(cid:101)k −G(cid:101)kx⊤k µ♯ −G kz⊤k
ν♯(cid:1)2
=
∑(cid:0)
y
k
−x⊤k µ♯ ·z⊤k
ν♯(cid:1)2
.
k=i k=i
̸ ̸
Re-arrangingyields
(cid:13) (cid:13)µ−(i) −µ♯(cid:13) (cid:13)2 2+(cid:13) (cid:13)ν−(i) −ν♯(cid:13) (cid:13)2
2 ≤
λ1
m
∑(cid:0)
y
k
−x⊤k µ♯ ·z⊤k
ν♯(cid:1)2
k=i
̸
≤
λ2
m
∑
ϵ
k2+(cid:0)
x⊤k µ⋆ ·z⊤k ν⋆ −x⊤k µ♯ ·z⊤k
ν♯(cid:1)2
.
k=i
̸
Then, applyingtheinequality(97)inconjunctionwiththebound ϵ ≲ σlog(d), wefurtherobtainthe
k
bound
(cid:13) (cid:13)µ−(i) −µ♯(cid:13) (cid:13)2 2+(cid:13) (cid:13)ν−(i) −ν♯(cid:13) (cid:13)2
2
≲ mlo λg m2(d) (cid:0) σ2+(α♯(cid:101)α♯ −1)2+β2 ♯+β(cid:101)2 ♯. (98)
Puttingthetwopiecestogetherandinvokingtheassumptionλm d myieldsthebound
≥ ≥
(cid:12) (cid:12)x i⊤(µ♯ −µ−(i)) ·z i⊤ν♯(cid:12) (cid:12)+(cid:12) (cid:12)x i⊤µ♯ ·z i⊤(ν♯ −ν−(i))(cid:12) (cid:12)≲ log2(d)(cid:0) σ+(cid:12) (cid:12)α♯(cid:101)α♯ −1(cid:12) (cid:12)+β♯+β(cid:101)♯(cid:1) . (99)
Substitutinginequalities(97)and(99)intoinequality(96)yields
(cid:12) (cid:12)y i+G iG(cid:101)i −G(cid:101)ix i⊤µ−(i) −G iz i⊤ν−(i)(cid:12) (cid:12)≲ log2(d)(cid:0) σ+(cid:12) (cid:12)α♯(cid:101)α♯ −1(cid:12) (cid:12)+β♯+β(cid:101)♯(cid:1) . (100)
Followingidenticalsteps,weobtaintheinequality
(cid:12) (cid:12)y j+G jG(cid:101)j −G(cid:101)jx⊤j µ−(i,j) −G jz⊤j ν−(i,j)(cid:12) (cid:12)≲ log2(d)(cid:0) σ+(cid:12) (cid:12)α♯(cid:101)α♯ −1(cid:12) (cid:12)+β♯+β(cid:101)♯(cid:1) .
Further,notethatsince {x k,z k,ϵ
k
}n
k=1 ∈
S,wehavethebounds |u ⊤Σ i−1a
i
|, |u ⊤Σ i−,j1a
j |
≲ log(d)/(λm).
Puttingthepiecestogetheryields
(cid:12) (cid:12) (cid:12) (cid:12)f u(cid:0) {x k,z k,ϵ k }n k=1(cid:1) −(cid:68) u,(cid:20) µ ν− (( ii ,, jj ))(cid:21)(cid:69)(cid:12) (cid:12) (cid:12) (cid:12)≲ log λ3 m(d) ·(cid:0) σ+(cid:12) (cid:12)α♯(cid:101)α♯ −1(cid:12) (cid:12)+β♯+β(cid:101)♯(cid:1) . (101)
−
Procedingsimilarly,since x ,z ,ϵ n ,weobtainthat
{ ′k ′k k′ }k=1 ∈ S
(cid:12) (cid:12) (cid:12) (cid:12)f u(cid:0) {x′k,z′k,ϵ k′ }n k=1(cid:1) −(cid:68) u,(cid:20) µ ν− (( ii ,, jj ))(cid:21)(cid:69)(cid:12) (cid:12) (cid:12) (cid:12)≲ log λ3 n(d) ·(cid:0) σ+(cid:12) (cid:12)α♯(cid:101)α♯ −1(cid:12) (cid:12)+β♯+β(cid:101)♯(cid:1) . (102)
−
Puttinginequalities(101)and(102)togetherandnoting α♯(cid:101)α♯ 1 +β♯+β(cid:101)♯
≲(cid:112)
Err ♯yieldsthedesired
| − |
result. Itremainstoestablishtheclaim(95).
Proofofthestructuralrelations(95):Bythedefinitionof[µ+ ν+]
⊤
= m,λ([µ♯ ν♯])(6),weobtainthat
| G |
(cid:20) (cid:21) (cid:18) (cid:20) (cid:21)(cid:19)
µ ν++ = Σ −1 k∑ =i(y k+G kG(cid:101)k) ·a k+λm µ ν♯♯ +(cid:0) y i+G iG(cid:101)i(cid:1) ·Σ −1a i.
̸
37ApplyingtheSherman–Morrisonformulayields Σ −1 = Σ i−1 −Σ i−1a ia i⊤Σ i−1/(1+a i⊤Σ i−1a i). Wesub-
stitutethisexpressionintotheprecedingdisplaytoobtain
(cid:20) µ ν++(cid:21) = (cid:18) Σ i−1
−
Σ 1i− +1 aa i⊤ia Σi⊤ i−Σ 1i− a1 i(cid:19)(cid:18) k∑ =i(y k+G kG(cid:101)k) ·a k+λn(cid:20) µ ν♯♯(cid:21)(cid:19) + (cid:0) y 1i+ +G ai i⊤G(cid:101) Σi(cid:1) i−Σ 1i− a1 ia i . (103)
̸
Bythedefinitionof(µ (i),ν (i))(44a),weobtainthat
− −
(cid:20) µ
ν
−− (( ii ))(cid:21) = Σ i−1(cid:18) k∑ =i(y k+G kG(cid:101)k) ·a k+λn(cid:20) µ ν♯♯(cid:21)(cid:19) .
̸
Substitutingthisintoequation(103)yields
(cid:20)
µ
(i)(cid:21)
Σ 1a a −
(cid:20) µ t+1(cid:21) = (cid:20) µ −(i)(cid:21) i− i i⊤ ν −(i) + (y i+G iG(cid:101)i)Σ i−1a i
ν t+1 ν −(i) − 1+a i⊤Σ i−1a
i
1+a i⊤Σ i−1a
i
(cid:16) (cid:17)
=
(cid:20)
µ
−(i)(cid:21)
+
y i+G iG(cid:101)i −G(cid:101)ix i⊤µ −(i) −G iz i⊤ν −(i) Σ i−1a
i
,
ν −(i) 1+a i⊤Σ i−1a
i
(cid:2) (cid:3)
whereinthelaststepwere-arrangedtermsandusedthenotationa
i⊤
= G(cid:101)ix
i⊤
G iz
i⊤
. Thisprovesthe
relation(95a). Identicalstepsyieldtheclaim(95b).
A.2 ProofofLemma2
Weproveeachpartinturn,beginningwithpart(a).
Proof of Lemma 2(a): Note that several of the defining constraints of the regularity set in (45) are
S
standard(e.g. thehighprobabilitybound x ≲ √d). Wethusonlyprovideprobabilityboundsfor
i 2
∥ ∥
thenon-standardconstraints.
Let w 1,w
2
∈
Rd such that Σ i−1u = [w
1⊤
|
w 2⊤] ⊤. Note that (x i,z i) are independent of (w 1,w 2)
andu ⊤Σ i−1a
i
= G(cid:101)ix i⊤w 1+G iz i⊤w 2.ApplyingHoeffding’sinequality(Vershynin,2018,Theorem2.2.6)
yieldsthatwithprobabilityatleast1 d 200,allthreeofthefollowinginequalitieshold
−
−
(cid:113) (cid:113) (cid:113)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)G i(cid:12),(cid:12)G(cid:101)i(cid:12) ≤C log(d), (cid:12)x i⊤w 1(cid:12) ≤C log(d) ∥w 1 ∥2, and (cid:12)z i⊤w 2(cid:12) ≤C log(d) ∥w 2 ∥2.
Consequently,withprobabilityatleast1 d 200,
−
−
(cid:12) (cid:12)u⊤Σ i−1a i(cid:12) (cid:12)≲ log(d) ·( ∥w 1 ∥2+ ∥w 2 ∥2)≲ log(d) ·(cid:13) (cid:13)Σ i−1u(cid:13) (cid:13) 2 ≤ lo λg m(d) ,
w loh we ir ne gth the efi in da el ni tn ice aq lu sa tl ei pty yf io el ll do sw as nfr io dm ent th ice alp bai or uo nf db fo ou rn td hs e(cid:13) (cid:13) pΣ roi− b1 a(cid:13) (cid:13) b2 il≤ ity( oλ fm t) h− e1 ea vn ed nt∥(cid:8)u (cid:12) (cid:12)∥ u2 ⊤= Σ i−,j1 1. a j(cid:12) (cid:12)Fo ≥l-
Clog(d)/(λm)(cid:9) . Next,notingthatx
i
isindependentofµ♯ µ −(i) andapplyingHoeffding’sinequality
−
yieldstheprobabilisticinequality
Pr(cid:110)(cid:12) (cid:12)x i⊤(µ♯ −µ−(i))(cid:12) (cid:12) ≥C(cid:113) log(d) ·(cid:13) (cid:13)µ♯ −µ−(i)(cid:13) (cid:13) 2(cid:111) ≤2d−200.
I
(cid:13)
(cid:13)d
µ
(cid:9)e ♯n −tic µa −l (s i,t je )p
(cid:13)
(cid:13)
2s (cid:9)y .ie Pl ud tta ins gim thil ear pb ieo cu en sd too gn ett hh ee rp ar no dba ab pi pli lt yy ino gft th he ee uv ne in ot n(cid:8) b(cid:12) (cid:12) ox ui⊤ n( dµ♯
y−
ielµ d− s( Pi,j r)) (cid:8)(cid:12) (cid:12)
{≥
x
i,C
z
i(cid:112) ,ϵl io }g
in
=( 1d)
∈/·
d 180,asdesired.
−
S ≤
38Proof of Lemmas 2(b) and (c): Next we reduce a tail bound on f to a tail bound on the truncated
u
function f u↓. Recalltheshorthand M = {x i,z i,ϵ
i
}im =1and M
′
= {x i′,z i′,ϵ
i′
}im =1. Notethat
Pr(cid:110)(cid:12) (cid:12)f u E f u (cid:12) (cid:12) t(cid:111) Pr(cid:110)(cid:12) (cid:12)f u(M) E f u(M) (cid:12) (cid:12) t,M (cid:111) +Pr(cid:110) M / (cid:111)
− { } ≥ ≤ − { } ≥ ∈ S ∈ S
(i) Pr(cid:110)(cid:12) (cid:12)f u↓(M) E f u(M) (cid:12) (cid:12) t,M (cid:111) +d−180
≤ − { } ≥ ∈ S
Pr(cid:110)(cid:12) (cid:12)f u↓(M) E f u(M) (cid:12) (cid:12) t(cid:111) +d−180 (104)
≤ − { } ≥
where step (i) follows by combining Eq. (48)—which ensures that f u(M) = f u↓(M) for M —and
Lemma2(a). Wenextturntobound(cid:12) (cid:12)E f u E f u↓ (cid:12) (cid:12). Notethatsince f u and f u↓ agreeon ,∈ S
{ }− { } S
(cid:12) (cid:12)E f u E f u↓ (cid:12) (cid:12) = (cid:12) (cid:12)E(cid:8) f u(M) 1 M / (cid:9) E(cid:8) f u↓(M) 1 M / (cid:9)(cid:12) (cid:12)
{ }− { } · { ∈ S} − · { ∈ S}
(cid:12) (cid:12)E(cid:8) f u(M) 1 M / (cid:9)(cid:12) (cid:12)+(cid:12) (cid:12)E(cid:8) f u↓(M) 1 M / (cid:9)(cid:12) (cid:12). (105)
≤ · { ∈ S} · { ∈ S}
WenextboundthetwotermsintheRHSoftheinequalityinthedisplayabove. Bydefinitionof f u↓(47),
weobtainthatforany M R(2d+1) m and M
′ ×
∈ ∈ S
(i)
f u↓(M′) f u(M)+∆ ρ(M,M′)+2D f u(M)+m∆+2d ≲ d,
≤ · ≤
where step (i) follows from Lemma 1(a). Applying Lemma 1(a) once more additionally yields the
lowerbound f u↓(M ′) inf M f u(M) d. Consequently,weobtainthat f u↓ ≲ d,whichcompletes
≥ ∈S ≥ − | |
theproofofpart(b). Thisadditionallyimpliesthat
(cid:12) (cid:12)E(cid:8) f u↓(M) 1 M / (cid:9)(cid:12) (cid:12)≲ d Pr(cid:8) M / (cid:9) d−160. (106)
· { ∈ S} · ∈ S ≤
N (cid:13) (cid:13)νe +x (cid:13) (cid:13)t 2w .e Ustu inr gn tt ho eb eo xu pn red ss(cid:12) (cid:12) iE o(cid:8) nf ou f( (M µ+) ,· ν1 +{ )M (5)∈/ anS d} t(cid:9) h(cid:12) (cid:12) e. bB oy ud ndefi ∥n Σit −io 1n ∥2o ≤f f (u λ, mw )e −1n ,o wte et oh ba tt ai| nf u t| he≤ in(cid:13) (cid:13) eµ q+ u(cid:13) (cid:13) a2 lit+
y
(cid:13) (cid:13)µ+(cid:13) (cid:13) 2+(cid:13) (cid:13)ν+(cid:13) (cid:13)
2
≲ λ1 m(cid:13) (cid:13) (cid:13)
(cid:13)
∑m (cid:0) y k+G kG(cid:101)k(cid:1) ·a k(cid:13) (cid:13) (cid:13)
(cid:13)
+L ♯+(cid:101)L ♯.
k=1 2
Puttingthepiecestogetheryieldsthebound
(cid:12) (cid:12)E(cid:8) f u(M) ·1 {M ∈/ S}(cid:9)(cid:12) (cid:12)
≤
λ1 mE(cid:26)(cid:13) (cid:13) (cid:13)
(cid:13)
∑m (y k+G kG(cid:101)k) ·a k(cid:13) (cid:13) (cid:13)
(cid:13)
·1(cid:8) M ∈/ S(cid:9)(cid:27) +CPr(cid:8) M ∈/ S(cid:9) .
k=1 2
(cid:124) (cid:123)(cid:122) (cid:125)
T
Then,weapplytheCauchy–Schwartzinequalitytoobtainthebound
(cid:26)(cid:13) m (cid:13)2(cid:27)1/2 (cid:113)
T E (cid:13) (cid:13) ∑ (cid:0) y k+G kG(cid:101)k(cid:1) a k(cid:13) (cid:13) Pr(cid:8) M / (cid:9)≲ md(1+σ) d−90.
≤ (cid:13) · (cid:13) · ∈ S ·
k=1 2
Puttingthepiecestogetheryields
(cid:12) (cid:12)E(cid:8) f u(M) 1 M / (cid:9)(cid:12) (cid:12)≲ md(1+σ) d−90+d−180 2d−85, (107)
· { ∈ S} λm ≤
where the last step follows from the assumptions λm Cd(1+σ) and m d. Substituing inequali-
ties(106)and(107)intoinequality(105)yields(cid:12) (cid:12)E f u ≥ E f u↓ (cid:12) (cid:12)≲ d −81. Con≤ sequently,
{ }− { }
Pr(cid:110)(cid:12) (cid:12)f u↓ E f u (cid:12) (cid:12) t(cid:111) Pr(cid:110)(cid:12) (cid:12)f u↓ E f u↓ (cid:12) (cid:12) t/2(cid:111) +Pr(cid:110)(cid:12) (cid:12)E f u↓ E f u (cid:12) (cid:12) t/2(cid:111)
− { } ≥ ≤ − { } ≥ { }− { } ≥
Pr(cid:110)(cid:12) (cid:12)f u↓ E f u↓ (cid:12) (cid:12) t/2(cid:111) ,
≤ − { } ≥
where the last step follows by setting t > d 80. Combining the inequality in the display above with
−
inequality(104)yieldsthedesiredresult.
39A.3 ProofofLemma3
WewillusetheshorthandG
i
= x i⊤µ♯ andG(cid:101)i = z i⊤ν♯ fori
∈
[m]. NotethatEq.(6)isequivalentto
(cid:0) µ+, ν+(cid:1) =argmin m1 ∑m (cid:0) y i+G iG(cid:101)i −G(cid:101)ix i⊤µ −G iz i⊤ν(cid:1)2+λ(cid:13) (cid:13)µ −µ t(cid:13) (cid:13)2 2+λ(cid:13) (cid:13)ν −ν t(cid:13) (cid:13)2 2.
µ,ν Rd i=1
∈
TheoptimizationprobleminthedisplayadmitstheKKTcondition
1 ∑m (cid:0) (cid:1) (cid:0) (cid:1)
m
G(cid:101)i ·x i⊤µ++G
i
·z i⊤ν+ −y
i
−G iG(cid:101)i G(cid:101)ix i+λ µ+ −µ♯ =0, (108a)
i=1
1 ∑m (cid:0) (cid:1) (cid:0) (cid:1)
m
G(cid:101)i ·x i⊤µ++G
i
·z i⊤ν+ −y
i
−G iG(cid:101)i G iz i+λ ν+ −ν♯ =0. (108b)
i=1
Bydefinition,wedecomposeµ+ = θ(u) ·u+O uO u⊤µ+, ν+ = θ(cid:101)(v) ·v+O vO v⊤ν+. Consequently,
x i⊤µ+ = θ(u) ·x i⊤u+x i⊤O uO u⊤µ+, and z i⊤ν+ = θ(cid:101)(v) ·z i⊤v+z i⊤O vO v⊤ν+. (109)
TakingtheinnerproductbetweenuandbothsidesofEq.(108a),usingthedecompositioninthedisplay
aboveandrearrangingthetermsyields
(cid:16) m1 ∑m
G(cid:101) i2(x
i⊤u)2+λ(cid:17) ·θ(u)+(cid:16) m1 ∑m
G iG(cid:101)i(x i⊤u)(z
i⊤v)(cid:17)
·θ(cid:101)(v)+
m1 ∑m
G(cid:101) i2(x i⊤u)(x i⊤O uO u⊤µ+)
i=1 i=1 i=1
1 ∑m 1 ∑m
+
m
G iG(cid:101)i(z i⊤u)(z i⊤O vO v⊤ν+) = λu⊤µ♯+
m
(y i+G iG(cid:101)i)G(cid:101)i(x i⊤u).
i=1 i=1
Nowwritingtheequationinthedisplayaboveinmatrixformyields
(cid:16)1 (cid:17) 1 1
m∥W(cid:102)Xu ∥2 2+λ ·θ(u)+ m⟨W(cid:102)Xu,WZv ⟩·θ(cid:101)(v)+ m⟨W(cid:102)Xu,W(cid:102)XO uO u⊤µ+
⟩
1 1
+ m⟨W(cid:102)Xu,WZO vO v⊤ν+
⟩
= λ ⟨u,µ♯ ⟩+ m⟨y+diag(WW(cid:102)),W(cid:102)Xu ⟩. (110)
Similarly,takingtheinnerproductbetweenvandbothsidesofEq.(108b)yields
(cid:16)1 (cid:17) 1 1
m∥WZv ∥2 2+λ ·θ(cid:101)(v)+ m⟨W(cid:102)Xu,WZv ⟩·θ(u)+ m⟨WZv,W(cid:102)XO uO u⊤µ+
⟩
1 1
+ m⟨WZv,WZO vO v⊤ν+
⟩
= λ ⟨v,ν♯ ⟩+ m⟨y+diag(WW(cid:102)),WZv ⟩. (111)
RecallthenotationA
u,v
= [W(cid:102)XO
u
WZO v],wecollectEq.(110)andEq.(111)intothefollowingsystem
(cid:18) m1 (cid:20) ( (W W(cid:102)X Zvu )) ⊤⊤(cid:21)(cid:104) W(cid:102)XuWZv(cid:105) +λI(cid:19)(cid:20) θ θ(cid:101)( (u v) )(cid:21) + m1 (cid:20) ( (W W(cid:102)X Zvu )) ⊤⊤(cid:21) A u,v(cid:20) O Ou⊤ v⊤µ ν++ (cid:21)
= λ
(cid:20) ⟨µ♯,u ⟩(cid:21)
+
1 (cid:20) (W(cid:102)Xu) ⊤(cid:21)(cid:16) y+diag(WW(cid:102))(cid:17)
. (112)
· ⟨ν♯,v
⟩
m (WZv)
⊤
Likewise,wemultiplyO onbothsidesof(108a).Asbefore,usingthedecomposition(109)andwriting
u⊤
theresultinmatrixformyields
θ(u) (cid:18) 1 (cid:19) θ(cid:101)(v)
m
(W(cid:102)XO u) ⊤(W(cid:102)Xu)+ m(W(cid:102)XO u) ⊤(W(cid:102)XO u)+λI O u⊤µ++
m
(W(cid:102)XO u) ⊤(WZv)
1 1
+ m(W(cid:102)XO u) ⊤(WZO v)O v⊤ν+ = m(W(cid:102)XO u) ⊤(y+diag(WW(cid:102)))+λO u⊤µ♯.
40Similarly,multiplyingO onbothsidesof(108b)andwritingtheresultinmatrixformyields
v⊤
θ(u) 1 θ(cid:101)(v)
m
(WZO v) ⊤(W(cid:102)Xu)+ m(WZO v) ⊤(W(cid:102)XO u)O u⊤µ++
m
(WZO v) ⊤(WZv)
(cid:18) (cid:19)
1 1
+ m(WZO v) ⊤(WZO v)+λI O v⊤ν+ = m(WZO v) ⊤(y+diag(WW(cid:102)))+λO v⊤ν♯.
Combiningtheprevioustwodisplaysyields
(cid:16) m1 A⊤u,vA u,v+λI(cid:17)(cid:20) O Ou⊤ v⊤µ ν++ (cid:21) + m1 A⊤u,v(cid:104) W(cid:102)XuWZv (cid:105)(cid:20) θ θ(cid:101)( (u v)
)
(cid:21)
(cid:20) (cid:21)
= m1 A⊤u,v(y+diag(WW(cid:102)))+λ O Ou⊤ v⊤µ ν♯♯ ,
andre-arrangingyields
(cid:20) O Ou⊤ v⊤µ ν++ (cid:21) = (cid:16) A⊤u,vA u,v+λmI(cid:17) −1
·(cid:18) A⊤u,v(y+diag(WW(cid:102)))+λm(cid:20) O Ou⊤ v⊤µ ν♯♯ (cid:21) −A⊤u,v(cid:104)
W(cid:102)XuWZv
(cid:105)(cid:20) θ θ(cid:101)( (u v)
)
(cid:21)(cid:19)
Now, substituing the equation in the display above into Eq. (112), re-arranging the terms and using
(cid:16) (cid:17) 1
P = I A A A +λmI − A yieldsthedesiredresult.
u,v
−
u,v ⊤u,v u,v ⊤u,v
A.4 ProofofLemma4
InSectionA.4.1,weprovidetheproofofLemma4(a),inSectionA.4.2,weprovidetheproofofLemma4(b),
inSectionA.4.3,weprovidetheproofofLemma4(c),andfinally,inSectionA.4.4,weprovidetheproof
ofLemma4(d).
A.4.1 ProofofLemma4(a)
WeboundE(cid:8)(cid:12)
(cid:12)M
11
V
1(cid:12) (cid:12)(cid:9) ,notingthatidenticalstepsyieldthesameboundonE(cid:8)(cid:12)
(cid:12)M
22
V
2(cid:12) (cid:12)(cid:9)
.
− −
Consider the shorthand G
i
= x i⊤µ♯ and G(cid:101)i = z i⊤ν♯ for all i
∈
[m]. We then apply the triangle
inequalitytodecompose M V as
11 1
| −
M V T +T +T ,
11 1 1 2 3
| − | ≤
where
T 1 = (cid:12) (cid:12) (cid:12) (cid:12)M 11 − tr(P u2 m,v2W(cid:102)2)(cid:12) (cid:12) (cid:12) (cid:12), T 2 = (cid:12) (cid:12) (cid:12) (cid:12)tr(P u2 m,v2W(cid:102)2) − m1 i∑ =m
11+
G(cid:101)G(cid:101) i2i2
+
G i2 (cid:12) (cid:12) (cid:12) (cid:12)
r1 r2
and T 3 =
(cid:12) (cid:12)
(cid:12)
(cid:12)m1 i∑ =m
11+
G(cid:101)G(cid:101) i2i2
+
G i2 −V
1(cid:12) (cid:12)
(cid:12) (cid:12).
r1 r2
WeboundeachofT ,T ,andT insequence.
1 2 3
BoundingT 1: Since Xu
2
is gaussian and independent of W(cid:102) and P u2,v2, applying the Hanson–Wright
inequality(Vershynin,2018,Theorem6.2.1)yieldsthatforallt 0
≥
(cid:8) (cid:12) (cid:9) (cid:26) (cid:18) m2t2 mt (cid:19)(cid:27)
Pr T 1
≥
t (cid:12) P u2,v2,W(cid:102) ≤2exp −cmin
∥W(cid:102)2 ∥2
F,
∥W(cid:102)2
∥2
,
41whereweusedthepairofbounds(cid:13)
(cid:13)W(cid:102)P
u2,v2W(cid:102)(cid:13) (cid:13)2
F ≤
(cid:13) (cid:13)W(cid:102)2(cid:13) (cid:13)2 Fand(cid:13)
(cid:13)W(cid:102)P
u2,v2W(cid:102)(cid:13)
(cid:13)
2 ≤
(cid:13) (cid:13)W(cid:102)2(cid:13)
(cid:13) 2,eachofwhich
holdssince0 P I. Consequently,sinceT 0,weintegratethetailtoobtain
⪯
u2,v2
⪯
1
≥
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
E(cid:8) T 1 (cid:12) (cid:12) P u2,v2,W(cid:102)(cid:9) =
(cid:90) 0∞
Pr(cid:8) T 1
≥
t (cid:12) (cid:12) P u2,v2,W(cid:102)(cid:9) dt≲
(cid:13)W(cid:102) m2(cid:13)
F +
(cid:13)W(cid:102) m2(cid:13)
2 ≲
(cid:13)W(cid:102) m2(cid:13)
F
Consequently,
E(cid:8) T 1(cid:9) =E(cid:8)E(cid:8) T 1 (cid:12) (cid:12) P u2,v2,W(cid:102)(cid:9)(cid:9)≲ m1 E(cid:8)(cid:13) (cid:13)W(cid:102)2(cid:13) (cid:13) F(cid:9)
≤
m1 E(cid:110)(cid:13) (cid:13)W(cid:102)2(cid:13) (cid:13)2 F(cid:111)1/2 ≲ √1 m. (113)
(cid:2) (cid:3)
BoundingT 2:Weusetheshorthand x¯
i
= O
u⊤
2x
i
and z¯
i
= O
v⊤
2z i. Welet a
i⊤
= G(cid:101)i ·x¯
i⊤
|
G
i
·z¯
i⊤
. Note
that a is the i-th row of A . Moreover, we let Σ = ∑m a a +λmI and Σ = ∑ a a +λmI.
i⊤ u2,v2 j=1 j ⊤j i j=i j ⊤j
̸
ApplyingtheSherman–Morrisonformula,wethenre-write
tr(cid:0) W(cid:102)P u2,v2W(cid:102)(cid:1) = i∑ =m 1G(cid:101) i2P u2,v2(i,i) = i∑ =m 1G(cid:101) i2(cid:0) 1 −a i⊤Σ −1a i(cid:1) = i∑ =m 11+aG i⊤(cid:101) i2
Σ i−1a
i.
Consequently,weboundE T as
2
{ }
E(cid:8)
T
2(cid:9) =E(cid:26)(cid:12) (cid:12)
(cid:12)
(cid:12)m1 i∑ =m 1(cid:18) 1+aG i⊤(cid:101) i2
Σ i−1a
i
−
1+
G(cid:101)G(cid:101) i2i2
+
G i2
(cid:19)(cid:12) (cid:12)
(cid:12)
(cid:12)(cid:27)
r1 r2
≤E(cid:110)(cid:12) (cid:12) (cid:12)G(cid:101) i2(cid:0) a i⊤Σ i−1a
i
−G(cid:101) i2/r
1
−G i2/r 2(cid:1)(cid:12) (cid:12) (cid:12)(cid:111) . (114)
UsingthedefinitionofB,C,DandtheblockmatrixinverseformulainEq.(30),weobtainthata i⊤Σ i−1a
i
=
G(cid:101) i2H 1+G i2H
2
−2G iG(cid:101)iH 3,wherewesetH
1
= x¯ i⊤(cid:0) B −CD −1C ⊤(cid:1) −1 x¯ i,H
2
= z¯ i⊤(cid:0) D −C ⊤B −1C(cid:1) −1 z¯
i
and
H
3
= x¯ i⊤(cid:0) B −CD −1C ⊤(cid:1) −1 CD −1z¯ i. Applyingthetriangleinequalityyields
(cid:12) (cid:12) (cid:12)a i⊤Σ i−1a i −(G(cid:101) i2/r 1+G i2/r 2)(cid:12) (cid:12) (cid:12)
≤
G(cid:101) i2 ·(cid:12) (cid:12)H 1 −r 1−1(cid:12) (cid:12)+G i2 ·(cid:12) (cid:12)H 2 −r 2−1(cid:12) (cid:12)+2(cid:12) (cid:12)G iG(cid:101)i(cid:12) (cid:12) ·(cid:12) (cid:12)H 3(cid:12) (cid:12). (115)
Combininginequalities(114)and(115)thenyields
E(cid:8) T 2(cid:9) ≤E(cid:8) G(cid:101) i4 ·(cid:12) (cid:12)H 1 −r 1−1(cid:12) (cid:12)(cid:9) +E(cid:8) G i2G(cid:101) i2 ·(cid:12) (cid:12)H 2 −r 2−1(cid:12) (cid:12)(cid:9) +2E(cid:8)(cid:12) (cid:12)G iG(cid:101) i3(cid:12) (cid:12) ·(cid:12) (cid:12)H 3(cid:12) (cid:12)(cid:9) . (116)
We then bound each term in the RHS of the inequality in the display above. We will make use of the
shorthand
P
11
= (cid:0) B CD−1C⊤(cid:1) −1 , P
12
= (cid:0) B CD−1C⊤(cid:1) −1 CD−1, P
22
= (cid:0) D C⊤B−1C(cid:1) −1 .
− − − −
ApplyingHanson-WrightInequalityyields
Pr(cid:110)(cid:12) (cid:12)H 1 tr(cid:0) P 11(cid:1)(cid:12) (cid:12) t(cid:111)(i) 2exp(cid:110) cmin(cid:110)(λm)2t2 ,λmt(cid:111)(cid:111)(ii) 2exp(cid:8) cdmin t2,t (cid:9) ,
− ≥ ≤ − d ≤ − { }
w anh der se tes pte (p ii)(i f) of lo loll wow
s
s byfr io nm vot kh ie ngbo tu hn ed as(cid:13) (cid:13) sP u1 m1(cid:13) (cid:13) p2 tio≤ n(cid:13) (cid:13) λΣ mi−1(cid:13) (cid:13) 2 d≤
.
A(λ ppm l) y− in1 gsi Ln ec me mP 1 a1 1is 3a yis eu lb dm
s
ta htr ai tx fo of rΣ ti− ≳1
≥
log1.5(d)/√d,
Pr(cid:110)(cid:12) (cid:12)tr(cid:0) P 11(cid:1) −r 1−1(cid:12) (cid:12)
≥
t(cid:111) ≤2exp(cid:26) m− loc gd 22 (t2 d)(cid:27) +d−15.
Combiningthetwopiecesyieldsthatfort≳ log1.5(d)/√d,
Pr(cid:110)(cid:12) (cid:12)H 1 −r 1−1(cid:12) (cid:12)
≥
t(cid:111) ≤4exp(cid:8) −cdlog−2(d)min {t2,t }(cid:9) +d−15. (117)
42Consequently,weobtainthat
E(cid:110)(cid:0)
H 1 −r
1−1(cid:1)2(cid:111)
≤
Clog d3(d) +E(cid:110)(cid:0)
H 1 −r
1−1(cid:1)2 ·1(cid:8)(cid:12)
(cid:12)H 1 −r
1−1(cid:12)
(cid:12)
≥Clog1.5(d)/√d(cid:9)(cid:111)
≤
Clog d3(d) +E(cid:110)(cid:12)
(cid:12)H 1 −r
1−1(cid:12) (cid:12)4(cid:111)1/2 ·Pr(cid:110)(cid:12)
(cid:12)H 1 −r
1−1(cid:12)
(cid:12)
≥Clog1.5(d)/√d(cid:111)1/2
≤
Clog d3(d) +E(cid:110)(cid:12) (cid:12)H
1
−r 1−1(cid:12) (cid:12)4(cid:111)1/2 ·d−7
wherethesecondstepfollowsfromtheCauchy–Schwarzinequality. Continuing,weobtainthat
E(cid:110)(cid:12) (cid:12)H
1
−r 1−1(cid:12) (cid:12)4(cid:111) ≲E(cid:8) H 14(cid:9) +r 1−4 ≲ 1,
whereweuser λm/d 1bydefinitionofr (32)andλm d,and
1 1
≥ ≥ ≥
E(cid:8)(cid:12) (cid:12)H 1(cid:12) (cid:12)4(cid:9) =E(cid:110)(cid:0) x¯ i⊤(cid:0) B −CD−1C⊤(cid:1) −1 x¯ i(cid:1)4(cid:111)
≤
E(cid:110) (λ(cid:13)
(cid:13) mx¯ i
)(cid:13)
(cid:13)
48 2(cid:111)
≲ 1.
Consequently, we obtain that E(cid:8) (H
1
−r 1−1)2(cid:9) ≲ log3(d)/d. Thus, applying the Cauchy–Schwarz in-
equalityoncemoreyields
E(cid:110) G(cid:101) i4 ·(cid:12) (cid:12)H
1
−r 1−1(cid:12) (cid:12)(cid:111) ≤E(cid:110) G(cid:101) i8(cid:111)1/2 ·E(cid:110)(cid:0) H
1
−r 1−1(cid:1)2(cid:111)1/2 ≲ log1.5(d)/√d. (118)
Followingtheidenticalsteps,weobtain
E(cid:110) G i2G(cid:101) i2 ·(cid:12) (cid:12)H
2
−r 2−1(cid:12) (cid:12)(cid:111) ≤E(cid:110) G i4G(cid:101) i4(cid:111)1/2 ·E(cid:110)(cid:0) H
2
−r 2−1(cid:1)2(cid:111)1/2 ≲ log1.5(d)/√d. (119)
WeturnnowtoboundingH . WefirstapplyHoeffding’sinequalitytoobtain,forallt 0,
3
≥
(cid:8)(cid:12) (cid:12) (cid:12) (cid:9)
(cid:26) t2 (cid:27) (cid:26) t2 (cid:27) (cid:26) (λm)2t2(cid:27)
Pr (cid:12)H 3(cid:12) ≥ t (cid:12) P 12,z¯ i ≤2exp 2 P− z¯ 2 ≤2exp 2 P − 2 z¯ 2 ≤2exp − 2 z¯ 2 ,
∥ 12 i ∥2 ∥ 12 ∥2∥ i ∥2 ∥ i ∥2
wherethelaststepfollowsfromthebound(cid:13) (cid:13)P 12(cid:13) (cid:13)
2 ≤
(cid:13) (cid:13)Σ i−1(cid:13) (cid:13)
2 ≤
(λm) −1. Integratingthetailyieldsthe
bound
E(cid:8) H 32 (cid:12) (cid:12) P 12,z¯ i(cid:9)
≤
(cid:90) 0∞ Pr(cid:110) H 32
≥
t
|
P 12,z¯ i(cid:111) dt
≤
(cid:90) 0∞ 2exp(cid:26) − 2(
(cid:13)
(cid:13)λ z¯m
i(cid:13)
(cid:13))
2
22t(cid:27) dt≲ ((cid:13) (cid:13) λz¯ mi(cid:13) (cid:13) )2 2 2.
Thus,
E(cid:8) H 32(cid:9) ≤E(cid:8)E(cid:8) H 32 (cid:12) (cid:12) P 12,z¯ i(cid:9)(cid:9)≲ (λm1 )2E(cid:110)(cid:13) (cid:13)z¯ i(cid:13) (cid:13)2 2(cid:111)
≤
(λmd
)2
≤1/d,
wherethelaststepfollowsbyinvokingtheassumptionλm d. Consequently,applyingtheCauchy–
≥
Schwarzinequalityyields
E(cid:8)(cid:12) (cid:12)G iG(cid:101)i(cid:12) (cid:12) ·(cid:12) (cid:12)H 3(cid:12) (cid:12)(cid:9) ≤E(cid:8) G i2G(cid:101) i2(cid:9)1/2 ·E(cid:8) H 32(cid:9)1/2 ≲ 1/√d. (120)
Substitutinginequalities(118), (119)and(120)intotheRHSofinequality(116)yields
E(cid:8) T (cid:9)≲ log1.5(d)/√d, (121)
2
whichcompletestheboundonT .
2
BoundingT 3: Note that (cid:8) G(cid:101) i2/(cid:0) 1+G(cid:101) i2/r 1+G i2/r 2(cid:1)(cid:9) im
=1
form a collection of i.i.d. sub-exponential ran-
dom variables whose expectations are V (33). Integrating the tail and applying Bernstein’s inequal-
1
ity(Vershynin,2018,Theorem2.8.2)thusyieldstheinequality
E(cid:8) T (cid:9) (cid:90) ∞ Pr(cid:8) T t(cid:9) dt (cid:90) ∞ 2exp(cid:8) cmmin t2,t (cid:9) dt≲ 1 . (122)
3 ≤ 0 3 ≥ ≤ 0 − { } √m
43Puttingthepiecestogether:Combininginequalities(113), (121)and(122)yields
E(cid:8)(cid:12) (cid:12)M
11
−V 1(cid:12) (cid:12)(cid:9)≲ m1 + log √1.5 d(d) + √1
m
≲ log √1.5 d(d) + √1 m. (123)
where the last step follows from the assumption m d. This yields the desired bound on
E(cid:8)(cid:12)
(cid:12)M
11
(cid:12)(cid:9) ≤ −
V 1(cid:12) . Turningto M 22 V 2 ,wenotethat
| − |
(cid:12)
(cid:12)M 22 −V
2(cid:12)
(cid:12) ≤
(cid:12) (cid:12)
(cid:12) (cid:12)M 22 −
tr(cid:0) P u2 m,v2W2(cid:1)(cid:12) (cid:12)
(cid:12)
(cid:12)+(cid:12) (cid:12)
(cid:12)
(cid:12)tr(cid:0) P u2 m,v2W2(cid:1)
−
m1 i∑ =m
11+
G(cid:101)G i2i2
+
G i2
(cid:12) (cid:12)
(cid:12) (cid:12)
r1 r2
+(cid:12) (cid:12)
(cid:12)
(cid:12)m1 i∑ =m
11+
G(cid:101)G i2i2
+
G i2
−V
2(cid:12) (cid:12)
(cid:12) (cid:12).
r1 r2
TherestoftheproofisidenticaltotheboundonE(cid:8)(cid:12)
(cid:12)M
11
V
1(cid:12) (cid:12)(cid:9)
andisomittedforbrevity.
−
A.4.2 ProofofLemma4(b.)
(cid:0) (cid:1)
Notethat,byconstruction,Xu
2
isindependentofthetupleofrandomvariables W(cid:102),W,P u2,v2,Zv
2
by
definition. Consequently,applyingHoeffding’sinequalityyields
E(cid:8) M 12 2(cid:9) =E(cid:110) E(cid:110) M 12
2 |
(cid:0) W(cid:102),W,P u2,v2,Zv 2(cid:1)(cid:111)(cid:111) ≲ m1 2E(cid:110)(cid:13) (cid:13)W(cid:102)P u2,v2WZv 2(cid:13) (cid:13)2 2(cid:111)
= m1 2E(cid:110)(cid:13) (cid:13)W(cid:102)P u2,v2W(cid:13) (cid:13)2 F(cid:111) = m1 2E(cid:110) tr(cid:0) WP u2,v2W(cid:102)2P u2,v2W(cid:1)(cid:111)
1 E(cid:110) tr(cid:0) WW(cid:102)2W(cid:1)(cid:111) ≲ 1
,
≤ m2 m
asdesired.
A.4.3 ProofofLemma4(c)
Recall the shorthand G
i
= x i⊤µ♯, G(cid:101)i = z i⊤ν♯, x¯
i
= O
u⊤
1x i, z¯
i
= O
v⊤
1z i, a
i⊤
= (cid:2) G(cid:101)ix¯
i⊤
|
G iz¯ i⊤(cid:3) and Σ =
∑n a a +λmI.Notinga isthei-throwof A andexpanding M yields
i=1 i i⊤ i⊤ u1,v1 1
M
1
= m1 ∑m G i2G(cid:101) i2(cid:0) 1 −a i⊤Σ −1a i(cid:1)
−
m1 ∑ G iG jG(cid:101)iG(cid:101)ja i⊤Σ −1a
j
i=1 i=j
̸
= m1 i∑ =m 11+G
a
i⊤i2G Σ(cid:101) i2
i−1a
i
−
m1 i∑ =jG iG jG(cid:101)iG(cid:101)ja i⊤Σ −1a j,
̸
wherethelaststepfollowsbynoting Σ = Σ a a andapplyingtheSherman–Morrisonformulato
i
−
i i⊤
Σ 1. Applyingthetriangleinequality,weobtainthedecomposition
−
(cid:12) (cid:12)
(cid:12)M
1
V(cid:12) T 1+T 2+T 3, (124)
− ≤
where
T 1 =
(cid:12) (cid:12)
(cid:12)
(cid:12)m1 i∑ =m 11+G
a
i⊤i2G Σ(cid:101) i2
i−1a
i
−
m1 i∑ =n 11+G Gi2 i2G(cid:101) +i2
G(cid:101) i2
(cid:12) (cid:12)
(cid:12) (cid:12), T 2 =
(cid:12) (cid:12)
(cid:12)
(cid:12)m1 i∑ =n 11+G Gi2 i2G(cid:101) +i2
G(cid:101) i2
−V(cid:12) (cid:12)
(cid:12) (cid:12)
r1 r2 r1 r2
(cid:12) (cid:12)
and T 3 = (cid:12) (cid:12) (cid:12)m1 ∑ G iG jG(cid:101)iG(cid:101)ja i⊤Σ −1a j(cid:12) (cid:12) (cid:12).
i=j
̸
44Notethatproceedingsimilarlyintheproofof(cid:12) (cid:12)M
11
V 1(cid:12) (cid:12)yieldstheboundE(cid:8) T 1+T 2(cid:9)≲ log1.5(d)/√d+
log3(m)/√m soweomitthedetailsofbounding T− and T . InordertoboundE(cid:8) T (cid:9) ≲ log6(d)/√d,
1 2 3
weapplythemethodoftypicalboundeddifferenceswithregularityset R2d m definedas
×
S ⊆
(cid:26) (cid:113)
S
= {x k,z
k
}m
k=1
: |G
i
|, |G(cid:101)i
|
≤C log(d), ∥x
i
∥2, ∥z
i ∥2
≤C√d, ∀i
∈
[m],
(cid:12) (cid:12) (cid:12) (cid:12) Clog2(d)√d
(cid:12) (cid:12)a i⊤Σ i−1a j(cid:12) (cid:12),(cid:12) (cid:12)a⊤k Σ i−j1a j(cid:12)
(cid:12) ≤ λm
, ∀i ̸= j ̸= k
∈
[m], (125)
(cid:12)
(cid:12) (cid:12)a i⊤Σ i−1 ∑ G kG(cid:101)ka
k(cid:12)
(cid:12)
(cid:12),(cid:12)
(cid:12) (cid:12)a⊤j Σ i−j1 ∑ G kG(cid:101)ka
k(cid:12)
(cid:12)
(cid:12)
≤
Clog2. λ5( md)√md
, ∀i ̸= j
∈
[m].(cid:27)
,
k=i k=i,j
̸ ̸
whereΣ = ∑ a a +λmI andΣ = ∑ a a +λmI foreachi,j [m]. Asthetypicalbounded
differenci esargk u̸= mi ek nt⊤k hasbeencarriei dj throk u̸= gi h,j ak ts⊤k everalpointsinthem∈
anuscript,weomitthedetails
forbrevity.
A.4.4 ProofofLemma4(d)
Bydefinitionof M (55),weexpandanddecompose M as
3 3
1 (cid:0) (cid:1)
M
3
= mdiag WW(cid:102) ⊤P u1,v1Xu
2
⊙Zv
2
= T
1
−T
2
−T 3,
where
T
1
= m1 diag(cid:0) WW(cid:102)(cid:1) ⊤Xu
2
⊙Zv 2, T
2
= m1 ∑m G iG(cid:101)ix i⊤u 2z i⊤v 2a i⊤Σ −1a
i
i=1
and T
3
= m1 ∑ G iG(cid:101)ix⊤j u 2z⊤j v 2a i⊤Σ −1a j.
i=j
̸
The proof consists of bounding each of the absolute first moments E T ,E T , and E T in
1 2 3
{| |} {| |} {| |}
turn.
BoundingE T : Notethat, byconstruction, Xu isindependentofthetupleofrandomvariables
1 2
(cid:0) (cid:1){| |}
W,W(cid:102),Zv
2
. Wethuscompute
E(cid:8)(cid:12) (cid:12)T 1(cid:12) (cid:12)(cid:9) =E(cid:110) E(cid:110)(cid:12) (cid:12)T 1(cid:12) (cid:12) |W,W(cid:102),Zv 2(cid:111)(cid:111) ≲ m1 E(cid:110)(cid:13) (cid:13)WW(cid:102)Zv 2(cid:13) (cid:13) 2(cid:111)
≤
m1 E(cid:110)(cid:13)
(cid:13)WW(cid:102)Zv
2(cid:13) (cid:13)2 2(cid:111)1/2
≤
√1
m. (126)
BoundingE T : Applyingtherank-oneupdateformulatocomputeΣ 1,were-write
2 −
{| |}
T = 1 ∑m G iG(cid:101)ix i⊤u 2z i⊤v 2 ·a i⊤Σ i−1a i .
2 m
i=1
1+a i⊤Σ i−1a
i
Wethenapplythetriangleinequalitytobound T as
2
| |
|T 2
| ≤
(cid:12) (cid:12)
(cid:12)
(cid:12)m1 i∑ =m
1
G iG(cid:101)ix i⊤ 1u +2z ai⊤ i⊤v Σ2
i−·
1a ai⊤ iΣ i−1a i
−
G iG(cid:101) 1ix +i⊤ Gu i2 2z /i⊤
r
2v +2(cid:0) GG (cid:101)r(cid:101) 1i2 i2/+
r
1G r2i2(cid:1)(cid:12) (cid:12)
(cid:12)
(cid:12)
+(cid:12) (cid:12) (cid:12)1 ∑m G iG(cid:101)ix i⊤u 2z i⊤v 2(cid:0)G r2i2 + G r(cid:101) 1i2(cid:1)(cid:12) (cid:12)
(cid:12)
(cid:12)n
i=1
1+G i2/r 2+G(cid:101) i2/r
1
(cid:12)
≤
m1 ∑m (cid:12) (cid:12)G iG(cid:101)ix i⊤u 2z i⊤v 2(cid:12) (cid:12) ·(cid:12) (cid:12) (cid:12)a i⊤Σ i−1a i −G(cid:101) i2/r 1 −G i2/r 2)(cid:12) (cid:12) (cid:12)+(cid:12) (cid:12) (cid:12)m1 ∑m x i⊤u 2δ i(cid:12) (cid:12) (cid:12),
i=1 i=1
45(cid:0) (cid:1) (cid:0) (cid:1)
where δ
i
= G iG(cid:101)iz i⊤v
2
G i2/r 2+G(cid:101) i2/r
1
/ 1+G i2/r 2+G(cid:101) i2/r
1
. Takingexpectationonbothsidesofthe
inequalityinthedisplayaboveyields
E(cid:8)(cid:12) (cid:12)T 2(cid:12) (cid:12)(cid:9) ≤E(cid:110)(cid:12) (cid:12)G iG(cid:101)ix i⊤u 2z i⊤v 2(cid:12) (cid:12) ·(cid:12) (cid:12) (cid:12)a i⊤Σ i−1a i −G i2/r 2 −G(cid:101) i2/r 1)(cid:12) (cid:12) (cid:12)(cid:111) +E(cid:110)(cid:12) (cid:12) (cid:12)m1 ∑m x i⊤u 2δ i(cid:12) (cid:12) (cid:12)(cid:111) .
(cid:124) (cid:123)(cid:122) (cid:125) i=1
(cid:124) (cid:123)(cid:122) (cid:125)
T 2′ T 2′′
Followingtheidenticalstepsofproofofinequality(121)yieldstheboundT ≲ log1.5(d)/√d. Notethat
2′
δ n isindependentof x u n . Consequently,applyingHoeffding’sinequalityyields
{ i }i=1 { i⊤ 2 }i=1
T 2′′
=E(cid:26) E(cid:26)(cid:12)
(cid:12)
(cid:12)m1 ∑m
x i⊤u 2δ i
(cid:12)
(cid:12) (cid:12) {δ i }im
=1(cid:27)(cid:27) ≲E(cid:26) m1(cid:16) ∑m
δ
i2(cid:17)1/2(cid:27)
≤
m1 E(cid:26) ∑m
δ
i2(cid:27)1/2
≲
√1
m,
i=1 i=1 i=1
wherethelaststepfollowsfromE(cid:8) δ2(cid:9)≲
1. Puttingthepiecestogether,weobtainthebound
i
E(cid:8)(cid:12)
(cid:12)T
2(cid:12) (cid:12)(cid:9)≲ log √1.5 d(d)
+
√1
m. (127)
Bounding E T : Proceeding in a parallel fashion to the proof of the step (125) yields the bound
3
{| |}
E T ≲ log6(d)/√d.
3
{| |}
Puttingthepiecestogether:
Applyinginequalities(126),(127)andtheboundofE(cid:8)(cid:12)
(cid:12)T
3(cid:12) (cid:12)(cid:9) yieldsE(cid:8)(cid:12)
(cid:12)M
3(cid:12) (cid:12)(cid:9)≲
log6(d)/√d+1/√m.
B Deferred proofs for the orthogonal component
This section is organized as follows. In Section B.1, we provide the proof of Lemma 5. Then, in Sec-
tionB.2,weprovidetheproofofLemma7. InSectionB.3,weprovidetheproofofLemma8. Finally,in
SectionB.4,weprovidetheproofofLemma9.
B.1 ProofofLemma5
Weonlyprovetheconcentrationofη2 sincetheproofforη2 isidentical.Theproofemploysthemethod
+ (cid:101)+
oftypicalboundeddifferenceswiththefunction f :R(2d+1) m Ras
×
→
f(cid:0) {x i,z i,ϵ i }im =1(cid:1) = η +2 = (cid:13) (cid:13)P s⊥pan {µ⋆,µ♯}µ+(cid:13) (cid:13)2 2, (128)
andtheregularityset R(2d+1) m definedas
×
S ⊆
(cid:26)
S
= {x i,z i,ϵ
i
}im
=1
∈R(2d+1) ×m : ∀i,j
∈
[m],
(cid:112) (cid:112)
∥x
i
∥2, ∥z
i ∥2
≤C√d, |x i⊤µ⋆ |, |x i⊤µ⊥ |, |z i⊤ν⋆ |, |z i⊤ν⊥
|
≤C logd, |ϵ
i
|
≤Cσ logd,
|x i⊤(µ♯ −µ−(i))
|
≤C(cid:112) logd ·∥µ♯ −µ−(i) ∥2, |x i⊤(µ♯ −µ−(i,j))
|
≤C(cid:112) logd ·∥µ♯ −µ−(i,j) ∥2,
|z i⊤(ν♯ −ν−(i))
|
≤C(cid:112) logd ·∥ν♯ −ν−(i) ∥2, |z i⊤(ν♯ −ν−(i,j))
|
≤C(cid:112) logd ·∥ν♯ −ν−(i,j) ∥2,
(cid:12)(cid:68) (cid:20) µ (i)(cid:21)(cid:69)(cid:12) Clog(d)(cid:13) (cid:20) µ (i)(cid:21)(cid:13)
(cid:12) (cid:12) Σ i−1a i,P V⊥ ν −− (i) (cid:12) (cid:12) ≤ λm (cid:13) (cid:13)P V⊥ ν −− (i) (cid:13) (cid:13) 2 and (129)
(cid:12)(cid:68) (cid:20) µ (i,j)(cid:21)(cid:69)(cid:12) Clog(d)(cid:13) (cid:20) µ (i,j)(cid:21)(cid:13) (cid:27)
(cid:12) (cid:12) Σ i−j1a j,P V⊥ ν −− (i,j) (cid:12) (cid:12) ≤ λm (cid:13) (cid:13)P V⊥ ν −− (i,j) (cid:13) (cid:13) 2 for V =span(µ⋆,µ♯) ×Rd ,
whereCdenotesalargeenoughpositiveuniversalconstant.Theremainderoftheprooffollowssimilar
stepstoSection4.1.1,whenceweomitthedetails.
46B.2 ProofofLemma7
WefirstrecallthedefinitionofV
1
asinEq(33)aswellasthecharacterizationof µ+,u asin(72)and
⟨ ⟩
applythetriangleinequalitytoobtainthedecomposition
(cid:12)
(cid:12) (cid:12)E {⟨µ+,u ⟩2
}−
E m(cid:8)
2∥
(W(cid:102) λ+R
u V,v ∥
)2
2
2(cid:9) (cid:12)
(cid:12)
(cid:12)
≤
T 1+T 2+T 3, where
1
T
=E(cid:40) 2(cid:12) (cid:12)(W(cid:102)Xu) ⊤R
u,v
·
MM 221 +2 λ(WZv) ⊤R u,v(cid:12) (cid:12)(cid:41)
, T
=E(cid:40) (M2M 2+12 2 λ)2(cid:16) (WZv) ⊤R u,v(cid:17)2 (cid:41)
1 (cid:16) M2 (cid:17)2 2 (cid:16) M2 (cid:17)2
m2 M +λ 12 m2 M +λ 12
11 − M22+λ 11 − M22+λ
(cid:16) (cid:17)2
and T =
(cid:12) (cid:12) (cid:12)E(cid:40) (W(cid:102)Xu) ⊤R u,v (cid:41) E(cid:8) ∥W(cid:102)R
u,v
∥2 2(cid:9)(cid:12) (cid:12)
(cid:12).
3 (cid:12) (cid:12) m2(cid:16) M +λ M 12 2 (cid:17)2 − m2(λ+V 1)2 (cid:12) (cid:12)
11 − M22+λ
Themainbulkoftheproofconsistsofestablishingeachofthefollowingthreeinequalities
(cid:16) (cid:17)
σ2+Err
♯
log2(m)
T , (130a)
1 ≤ (λm) λ√m
·
(cid:0) σ2+Err ♯(cid:1) log3(m)
T , and (130b)
2 ≤ (λm)2
σ2+Err
♯
(cid:16)log(m) (cid:16)log(m) log1.5(d)(cid:17) log3(m)(cid:17)
T max , + (130c)
3 ≤ λm · λ √m √d λm
Combining these three inequalities with the decomposition at the beginning of the section yields the
bound
(cid:12) (cid:12) (cid:12)E {⟨µ+,u ⟩2
}−
E m(cid:8) 2∥ (W(cid:102) λ+R u V,v ∥ )2 2 2(cid:9) (cid:12) (cid:12) (cid:12)≲ σ2+ λmErr ♯
·
lo λg √3( md) , (131)
1
asdesired. Weturnnowtoestablishingeachofthethreeinequalities(130).
Proofoftheinequality(130a): Recallthequantities M ,M ,and M asdefinedin(52)andapply
11 22 12
the Cauchy–Schwarz inequality to obtain the bound M M M2 . Consequently, since λ 0,
11 · 22 ≥ 12 ≥
M M2 /(λ+M ). NotefurtherthatsinceP 0,wehavethelowerbound M 0. Wethus
11 ≥ 12 22 u,v ⪰ 22 ≥
upperboundT as
1
2 (cid:110)(cid:12) (cid:12)(cid:111)
T
1
≤
(λn)3E (cid:12) (cid:12)(W(cid:102)Xu) ⊤P u,vWZv ·(W(cid:102)Xu) ⊤R u,v(WZv) ⊤R u,v(cid:12)
(cid:12)
2 (cid:110)(cid:16) (cid:17)2(cid:111)1/2 (cid:110)(cid:16) (cid:17)2(cid:111)1/2
≤
(λn)3E (W(cid:102)Xu) ⊤P u,vWZv ·E (W(cid:102)Xu) ⊤R u,v(WZv) ⊤R
u,v
, (132)
wherethelaststepfollowsfromtheCauchy–Schwarzinequality. Continuing,weobtainthebound
E(cid:8)(cid:0) (W(cid:102)Xu) ⊤P u,vWZv(cid:1)2(cid:9)( =i) E(cid:8)(cid:13) (cid:13)W(cid:102)P u,vW(cid:13) (cid:13)2 F(cid:9)≲ mE(cid:110) m
i
[a mx ]G i2 ·m
i
[a mx ]G(cid:101) i2(cid:111) (133)
∈ ∈
mlog2(m), (134)
≤
wherestep(i)followssince(Xu,Zv)isindependentof(W(cid:102),P u,v,W)(asu,vareorthogonaltospan(µ⋆,µ t),span(ν⋆,ν t),
respectively), and in the last step follows from the i.i.d. Gaussian nature of the random variables
{G i,G(cid:101)i
}i
∈[m]. Next,exploitingtheindependencebetween(Xu,Zv)and(W,W(cid:102),R u,v),wededuce
E(cid:8)(cid:0) (W(cid:102)Xu) ⊤R u,v(WZv) ⊤R u,v(cid:1)2(cid:9) =E(cid:8)(cid:13) (cid:13)W(cid:102)R u,v(cid:13) (cid:13)2 2·(cid:13) (cid:13)WR u,v(cid:13) (cid:13)2 2(cid:9)
≤E(cid:110) m
i
[a mx ]G i2 ·m
i
[a mx ]G(cid:101) i2 ·(cid:13) (cid:13)R u,v(cid:13) (cid:13)4 2(cid:111) .
∈ ∈
47Wethenclaimthefollowinginequality,
m
(cid:13) (cid:13)R u,v(cid:13) (cid:13)2
2 ≤
(cid:13) (cid:13)y −Xµ
t
⊙Zν t(cid:13) (cid:13)2
2
= ∑ (y
i
−G iG(cid:101)i)2. (135)
i=1
Takingthisasgiven—andprovidingitsproofattheend—weputthepiecestogetherandusetheshort-
handa =max iG i2andb =max iG(cid:101) i2toobtainthebound
E(cid:110) m
i
∈[a mx ]G i2 ·m
i
∈[a mx ]G(cid:101) i2 ·(cid:13) (cid:13)R u,v(cid:13) (cid:13)4 2(cid:111) ≤E(cid:110) ab(cid:16) i∑ =m 1(y
i
−G iG(cid:101)i)2(cid:17)2(cid:111) ≲ m2E(cid:8) ab(y
i
−G iG(cid:101)i)4(cid:9) .
WefurtherboundtheRHSbyapplyingtheCauchy–Schwarzinequalitytoobtain
E(cid:8) ab(y
i
−G iG(cid:101)i)4(cid:9) ≤E {a2b2 }1/2 ·E {(y
i
−G iG(cid:101)i)8 }1/2 ≲ log2(m) ·(cid:0) Err2
♯
+σ4(cid:1) ,
where in the last step we use the same decomposition as in Eq. (97). Assembling the various bounds
yields
E(cid:8)(cid:0) (W(cid:102)Xu) ⊤R u,v(WZv) ⊤R u,v(cid:1)2(cid:9)≲(cid:0) σ4+Err2 ♯(cid:1) m2log2(m). (136)
Finally,wecombineinequalities(132),(133)and(136)toobtain
(cid:16) (cid:17)
T ≲
σ2+Err
♯ log(m)√m mlog(m)
σ2+Err
♯
log2(m)
, (137)
1 (λm)3 · · ≤ (λm) λ√m
·
asdesired. BeforeturningtoboundingT ,weprovidetheproofoftheremaininginequality(135).
2
Proofoftheinequality(135):BythedefinitionofR (71),were-write
u,v
m
∥R
u,v
∥2
2
= ∑(cid:0) y i+G iG(cid:101)i −G(cid:101)ix i⊤O uµ
u,v
−G iz i⊤ν u,v(cid:1)2 .
i=1
Wethensubstitutethedefinitionsof(µ ,ν )asin (70)toobtainthebound
u,v u,v
m m
∥R
u,v
∥2
2 ≤
∑(cid:0) y i+G iG(cid:101)i −G(cid:101)ix i⊤O uO u⊤µ♯ −G iz i⊤O vO v⊤ν♯(cid:1)2 = ∑(cid:0) y
i
−G iG(cid:101)i(cid:1)2 ,
i=1 i=1
whereinthelaststepweusedthefactsthatO uO u⊤µ♯ = µ♯,O vO v⊤ν♯ = ν♯,G
i
= x i⊤µ♯,andG(cid:101)i = z i⊤ν♯.
Proofoftheinequality(130b): ApplyingthepairofboundsM M2 /(λ+M )andM 0. we
11 ≥ 12 22 22 ≥
obtainthebound
1 (cid:110)(cid:16) (cid:17)2(cid:16) (cid:17)2(cid:111)
T
2
≤
(λm)4E (W(cid:102)Xu) ⊤P u,vWZv (WZv) ⊤R
u,v
≤
(λm1 )4E(cid:110)(cid:13) (cid:13)W(cid:102)P u,vWZv(cid:13) (cid:13)4 2(cid:111)1/2 ·E(cid:110)(cid:16) (WZv) ⊤R u,v(cid:17)4(cid:111)1/2 ,
whereinthefinalinequalitywehavefirsttakentheexpectationoverXuandsubsequentlyappliedthe
Cauchy–Schwarzinequality. Wethenapplythefollowingpairofinequalities
E(cid:110)(cid:13) (cid:13)W(cid:102)P u,vWZv(cid:13) (cid:13)4 2(cid:111) ≲ m2log4(m) and
E(cid:110)(cid:16) (WZv) ⊤R u,v(cid:17)4(cid:111) ≲E(cid:110)(cid:13) (cid:13)WR u,v(cid:13) (cid:13)4 2(cid:111) ≲(cid:0) σ4+Err2 ♯(cid:1) m2log2(m),
todeducetheultimatebound
≲
(cid:0) σ2+Err ♯(cid:1) log3(m)
T , (138)
2 (λm)2
asdesired.
48Proofoftheinequality(130c): NotethatE(cid:8)(cid:0) (W(cid:102)Xu) ⊤R u,v(cid:1)2(cid:9) =E(cid:8)(cid:13) (cid:13)W(cid:102)R u,v(cid:13) (cid:13)2 2(cid:9) and
(cid:12)(cid:16) (cid:17) 2 (cid:12) (cid:16) (cid:17)
(cid:12)
(cid:12)
λ+M
11
−M 12 2/(M 22+λ) − −(λ+V 1) −2(cid:12)
(cid:12)
≤
λ−2 |V
1
−M
11
|+M 12 2/λ .
Consequently,weupperboundT as
3
E(cid:110)(cid:0)
(W(cid:102)Xu) ⊤R
u,v(cid:1)2
V
1
M
11
(cid:111) E(cid:110)(cid:0)
(W(cid:102)Xu) ⊤R
u,v(cid:1)2 (cid:0)
(W(cid:102)Xu) ⊤P
u,vWZv(cid:1)2(cid:111)
T ·| − | + · .
3 ≤ (λm)2 (λm)2λm2
ApplyingtheCauchy–Schwarzinequalitythenyields
E(cid:110)(cid:0)
(W(cid:102)Xu) ⊤R
u,v(cid:1)2
V
1
M
11
(cid:111) E(cid:110)(cid:0)
(W(cid:102)Xu) ⊤R
u,v(cid:1)4(cid:111)1/2 E(cid:110)
V
1
M
11
2(cid:111)1/2
.
·| − | ≤ · | − |
≲(cid:0) σ2+Err2(cid:1)
mlog(m)(cid:16)log(m)
+
log1.5(d)(cid:17)
,
♯ √m √d
Next,weproceedsimilarlytotheproofsof(130a)and(123)toobtainthepairofinequalities
E(cid:110)(cid:0) (W(cid:102)Xu) ⊤R u,v(cid:1)4(cid:111) ≲(cid:0) σ4+Err2 ♯(cid:1) m2log2(m), and
log2(m) log3(d)
E M V 2 ≲ + ,
11 1
{| − | } m d
sothat
E(cid:110)(cid:0) (W(cid:102)Xu) ⊤R u,v(cid:1)2 ·|V
1
−M
11
|(cid:111) ≲(cid:0) σ2+Err2 ♯(cid:1) mlog(m)(cid:16)lo √g( mm) + log √1.5 d(d)(cid:17) .
Wethenmimicthestepstoprovetheinequality(130b)todeducethebound
E(cid:8)(cid:0) (W(cid:102)Xu) ⊤R u,v(cid:1)2 (cid:0) (W(cid:102)Xu) ⊤P u,vWZv(cid:1)2(cid:9)≲(cid:0) σ2+Err ♯(cid:1) m2log3(m).
·
Puttingthepiecestogetheryields
E T ≲
σ2+Err
♯
(cid:16)log(m) max(cid:16)log(m) ,log1.5(d)(cid:17)
+
log3(m)(cid:17)
, (139)
{ 3 } λm · λ √m √d λm
asdesired.
B.3 ProofofLemma8
FollowingthediscussionprecedingthestatementofLemma8,wededucethat
E(cid:8) ∥W(cid:102)R
u,v
∥2 2(cid:9) = n ·E(cid:26)
(cid:0)
1+aG(cid:101) i⊤i2 Στ i i2
−1a
i(cid:1)2(cid:27) . (140)
Wenowreplacethedenominator1+a i⊤Σ i−1a iby1+G(cid:101) i2r 1−1+G i2r 2−1.Tothisend,weapplythetriangle
inequalityandusethethreeboundsΣ i−1 ⪰0andr 1,r
2
≥0(32)toobtaintheinequality
(cid:12) (cid:12) (cid:12) (cid:12)E(cid:26) (cid:0) 1+aG(cid:101) i⊤i2 Στ i i2 −1a i(cid:1)2(cid:27) −E(cid:26) (cid:0) 1+G(cid:101) i2rG 1−(cid:101) 1i2τ +i2 G i2r 2−1(cid:1)2(cid:27)(cid:12) (cid:12) (cid:12) (cid:12) ≤E(cid:110) G(cid:101) i2τ i2(cid:12) (cid:12)a i⊤Σ i−1a i −G(cid:101) i2r 1−1 −G i2r 2−1(cid:12) (cid:12)(cid:111)
≤E {τ i4 }1/2 ·E(cid:110) G(cid:101) i4(cid:0) a i⊤Σ i−1a
i
−G(cid:101) i2r 1−1 −G i2r 2−1(cid:1)2(cid:111)1/2 (141)
Proceedinginanidenticalfashiontotheargumentbetweeninequality(115)toinequality(121)yields
thebound
E(cid:110) G(cid:101) i4(cid:0) a i⊤Σ i−1a
i
−G(cid:101) i2r 1−1 −G i2r 2−1(cid:1)2(cid:111) ≲ log3(d)/d.
49TowardsboundingE τ4 ,wenotethatbytriangleinequality
{ i }
|τ
i
| ≤
|y
i
−G iG(cid:101)i
|+(cid:12)
(cid:12)G
i
·z
i⊤(cid:0)
ν
t
−O vν
u−,v(i)(cid:1)(cid:12) (cid:12)+(cid:12)
(cid:12)G(cid:101)i ·x
i⊤(cid:0)
µ
t
−O
uµ−u,v(i)(cid:1)(cid:12)
(cid:12).
Consequently,weobtainthat
E {τ i4 }≲E(cid:8) (y
i
−G iG(cid:101)i)4(cid:9) +E(cid:8)(cid:12) (cid:12)G
i
·z i⊤(cid:0) ν
t
−O vν u−,v(i)(cid:1)(cid:12) (cid:12)4(cid:9) +E(cid:8)(cid:12) (cid:12)G(cid:101)i ·x i⊤(cid:0) µ
t
−O uµ−u,v(i)(cid:1)(cid:12) (cid:12)4(cid:9)
≲E(cid:8) (y
i
−G iG(cid:101)i)4(cid:9) +E(cid:8)(cid:13) (cid:13)ν
t
−O vν u−,v(i)(cid:13) (cid:13)4 2(cid:9) +E(cid:8)(cid:13) (cid:13)µ
t
−O uµ−u,v(i)(cid:13) (cid:13)4 2(cid:9) , (142)
wherethelaststepfollowssince(µ−u,v(i)
,ν
u−,v(i)
)isindependentof(x i,z i).
Continuing,since(µ−u,v(i)
,ν
u−,v(i)
)
istheminimizerof(75),weobtainthat
λm ·( ∥µ−u,v(i) −O u⊤µ♯ ∥2 2+ ∥ν u−,v(i) −O v⊤ν♯ ∥2 2)
≤
∑(cid:0) y
j
−G jG(cid:101)j(cid:1)2 .
j=i
̸
Theinequalityinthedisplayabovefurtherimplies
∥µ−u,v(i) −O u⊤µ♯ ∥2 2+ ∥ν u−,v(i) −O v⊤ν♯ ∥2
2 ≤
λ1
m
∑(cid:0) y
j
−G jG(cid:101)j(cid:1)2 . (143)
j=i
̸
Takingthesquareandexpectationinsequenceofbothsidesoftheinequalityinthedisplayaboveyields
E(cid:8) ∥µ−u,v(i) −O u⊤µ♯ ∥4 2(cid:9) +E(cid:8) ∥ν u−,v(i) −O v⊤ν♯ ∥4 2(cid:9)≲ (λm m2 )2E(cid:8)(cid:0) y
j
−G jG(cid:101)j(cid:1)4(cid:9) .
Combiningtheinequalityinthedisplayabovewithinequality(142)andinvokingtheassumptionλm
≥
d m,weobtainthebound
≥
E {τ i4 }≲E(cid:8)(cid:0) y
j
−G jG(cid:101)j(cid:1)4(cid:9)≲ σ4+Err2 ♯, (144)
where in the final inequality, we used the decomposition (97). Substituting these bounds into the in-
equality(141)yields
(cid:12) (cid:12) (cid:12) (cid:12)E(cid:26)
(cid:0)
1+aG(cid:101) i⊤i2 Στ i i2
−1a
i(cid:1)2(cid:27) −E(cid:26)
(cid:0) 1+G(cid:101)
i2rG 1−(cid:101) 1i2τ +i2
G i2r
2−1(cid:1)2(cid:27)(cid:12) (cid:12) (cid:12) (cid:12)≲(cid:0) σ2+Err ♯(cid:1)log √1.5 d(d) .
Puttingtogethertheinequalityinthedisplayaboveandinequality(140)yields
(cid:26) (cid:27)
E G(cid:101) i2τ i2
(cid:12) (cid:12) (cid:12) (cid:12)E m(cid:8) 2(cid:13) (cid:13) (W(cid:102) λ+R u V,v 1(cid:13) (cid:13) )2 2 2(cid:9)
−
(cid:0) 1 m+G ((cid:101) λi2r 1− +1+ VG 1i2 )r 22−1(cid:1)2 (cid:12) (cid:12) (cid:12) (cid:12)≲(cid:0) σ2+Err ♯(cid:1)l √og d1 m.5( λd 2) , (145)
asdesired.
B.4 ProofofLemma9
Recallthedefinitionof(u 1,u 2,v 1,v 2)(25)andletS
♯
=span(µ⋆,µ♯)andS(cid:101)♯ =span(ν⋆,ν♯).Decomposing
byGram—Schmidtyields
O
uµ−u,v(i)
= ⟨O
uµ−u,v(i)
,u 1 ⟩u 1+ ⟨O
uµ−u,v(i)
,u 2 ⟩u 2+P S⊥ ♯O
uµ−u,v(i)
, and
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
ϑ 1−i ϑ 2−i ω −i
O vν
u−,v(i)
=
⟨
(cid:124)O vν u− (cid:123),
(cid:122)v(i)
,v 1 (cid:125)⟩v 1+
⟨
(cid:124)O vν u− (cid:123),
(cid:122)v(i)
,v 2 (cid:125)⟩v 2+P S(cid:101)⊥ ♯O vν
u−,v(i)
.
ϑ(cid:101) 1−i ϑ(cid:101) 2−i (cid:124) ω(cid:101)(cid:123) −(cid:122) i (cid:125)
50Wefurtherdefine g
i
= x i⊤u 2, g
i⊥
= x i⊤ω −i, g
(cid:101)i
= z i⊤v
2
and g
(cid:101)i⊥
= z i⊤ω (cid:101)−i. Bydefinition, G
i
= L ♯x i⊤u
1
andG(cid:101)i =(cid:101)L ♯z i⊤v 1. Consequently,G i,g i,g i⊥,G(cid:101)i,g (cid:101)i,g (cid:101)i⊥areindependentsinceu 1,u 2,ω −iareorthogonalto
eachother(similarlyforv ,v ,ω i ),and(ω i,ω i)areindependentof(x,z ). Usingtheorthogonal
1 2 (cid:101)− − (cid:101)− i i
decompositionabove,wethuswrite
x i⊤O uµ−u,v(i) = ϑ 1− Li ♯G i +ϑ 2−ig i+g i⊥ and z i⊤O vν u−,v(i) = ϑ(cid:101) 1− (cid:101)Li ♯G(cid:101)i +ϑ(cid:101) 2−ig (cid:101)i+g (cid:101)i⊥.
(cid:16) (cid:17)(cid:16) (cid:17)
Combiningthiswiththerepresentationy
i
= ϵ i+ Lα 2♯ ♯G i+ β L♯♯g
i
(cid:101)(cid:101) Lα 2♯ ♯G(cid:101)i+ (cid:101)β L(cid:101) ♯♯g
(cid:101)i
,wededucethat
τ
i
= ϵ
i+(cid:16)α♯(cid:101)α♯
+1
ϑ 1−i ϑ(cid:101) 1−i(cid:17)
G iG(cid:101)i
L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯
+(cid:16) Lα 2♯ ♯β (cid:101)(cid:101) L♯
♯
−ϑ(cid:101)
2−i(cid:17)
G ig
(cid:101)i+(cid:16) (cid:101)(cid:101) Lα 2♯ ♯β L♯
♯
−ϑ
2−i(cid:17)
G(cid:101)ig i+
β
L
♯♯ (cid:101)β L(cid:101) ♯♯
g ig (cid:101)i −G(cid:101)ig i⊥ −G ig (cid:101)i⊥.
Then,exploitingthefactthat G i,g i,g i⊥,G(cid:101)i,g (cid:101)i,g
(cid:101)i⊥
areindependentandzero-mean,aswelltherelations
E g2 =E g2 =1, E (g )2 =E ω i 2 , E (g )2 =E ω i 2 ,weobtainthedecomposition
{ i} {(cid:101)i} { i⊥ } {∥ − ∥2} { (cid:101)i⊥ } {∥(cid:101)− ∥2}
E(cid:26) G(cid:101) i2τ i2 (cid:27) =E(cid:26)
(cid:16)
σ2+
Lβ2
2 ♯♯
(cid:101)β L(cid:101)2
2
♯♯(cid:17)
G(cid:101) i2 (cid:27) +E(cid:26)E {∥ω −i ∥2 2}G(cid:101) i4+E {∥ω (cid:101)−i ∥2 2}G i2G(cid:101) i2(cid:27)
(cid:0) 1+G(cid:101) i2r 1−1+G i2r 2−1(cid:1)2 (cid:0) 1+G(cid:101) i2r 1−1+G i2r 2−1(cid:1)2 (cid:0) 1+G(cid:101) i2r 1−1+G i2r 2−1(cid:1)2
+E(cid:26)(cid:16)α♯(cid:101)α♯
+1
ϑ 1−i ϑ(cid:101) 1−i(cid:17)2(cid:27) E(cid:26) G i2G(cid:101) i4 (cid:27)
(146)
L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯ (cid:0) 1+G(cid:101) i2r 1−1+G i2r 2−1(cid:1)2
+E(cid:26)(cid:16) Lα 2♯ ♯β (cid:101)(cid:101) L♯
♯
−ϑ(cid:101)
2−i(cid:17)2(cid:27) E(cid:26)
(cid:0)
1+G(cid:101)
i2rG 1−(cid:101) i2 1G +i2
G i2r
2−1(cid:1)2(cid:27) +E(cid:26)(cid:16) (cid:101)(cid:101) Lα 2♯ ♯β L♯
♯
−ϑ
2−i(cid:17)2(cid:27) E(cid:26)
(cid:0)
1+G(cid:101) i2r
1−G 1(cid:101) i4
+G i2r
2−1(cid:1)2(cid:27)
Wewillusethefollowingauxiliarylemmatoapproximatelycomputesometermsoftheequationinthe
displayabove.
Lemma12. Recallthedefinitionofθdet,θdet(39a)andθ(cid:101)det,θ(cid:101)det(39b). ThereexistsauniversalconstantC >0
1 2 1 2
(cid:26) (cid:27)
suchthatforδ =max
C(σ2+Err ♯)log6(d)
,d 50 ,eachofthefollowinghold.
λ √d −
(a.) (cid:12) (cid:12)E(cid:8) η +2(cid:9) −E(cid:8) ∥ω−i ∥2 2(cid:9)(cid:12) (cid:12) ∨(cid:12) (cid:12)E(cid:8) η (cid:101)+2(cid:9) −E(cid:8) ∥ω (cid:101)−i ∥2 2(cid:9)(cid:12) (cid:12)
≤
C(σ λ2 √+ mErr ♯)
, (147a)
(b.)
(cid:12) (cid:12) (cid:12)E(cid:26)(cid:16)α♯(cid:101)α♯
+1
ϑ 1−i ϑ(cid:101) 1−i(cid:17)2(cid:27) (cid:16)α♯(cid:101)α♯
+1
θ 1det θ(cid:101) 1det(cid:17)2(cid:12) (cid:12)
(cid:12) δ, (147b)
(cid:12) L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯ − L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯ (cid:12) ≤
(c.)
(cid:12) (cid:12)
(cid:12)
(cid:12)E(cid:26)(cid:16) Lα 2♯ ♯β (cid:101)(cid:101) L♯
♯
−ϑ(cid:101)
2−i(cid:17)2(cid:27) −(cid:16) Lα 2♯ ♯β (cid:101)(cid:101) L♯
♯
−θ(cid:101)
2det(cid:17)2(cid:12) (cid:12)
(cid:12)
(cid:12)∨(cid:12) (cid:12)
(cid:12)
(cid:12)E(cid:26)(cid:16) (cid:101)(cid:101) Lα 2♯ ♯β L♯
♯
−ϑ
2−i(cid:17)2(cid:27) −(cid:16) (cid:101)(cid:101) Lα 2♯ ♯β L♯
♯
−θ
2det(cid:17)2(cid:12) (cid:12)
(cid:12)
(cid:12) ≤
δ. (147c)
WeprovidetheproofofLemma12inSectionB.4.1.Continuing,notethatbydefinitionofθdet,θdet(39a)
1 2
andθ(cid:101)det,θ(cid:101)det(39b),wehave
1 2
(cid:16)α♯(cid:101)α♯
+1
θ 1det θ(cid:101) ♯det (cid:17)2
=
λ2(α♯(cid:101)α♯/(L2 ♯(cid:101)L2 ♯) −1)2
,
(cid:16)α♯β(cid:101)♯ θ(cid:101)det(cid:17)2
=
(cid:16)α♯β(cid:101)♯ λ (cid:17)2
,
L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯ (cid:0) λ+V(L−♯ 2+(cid:101)L−♯ 2)(cid:1)2 L2 ♯(cid:101)L ♯ − 2 L2 ♯(cid:101)L ♯ λ+V 2
and
(cid:16) (cid:101)α♯β♯ θdet(cid:17)2
=
(cid:16) (cid:101)α♯β♯ λ (cid:17)2
.
(cid:101)L2 ♯L ♯ − 2 (cid:101)L2 ♯L ♯ λ+V 1
51SubstitutingtheapproximationsinLemma12intoEq.(146)andrecallingthedefinitionofV (35)yields
3
thebound
(cid:12) (cid:12) (cid:12) (cid:12)E(cid:26)
(cid:0) 1+G(cid:101)
i2rG 1−(cid:101) 1i2τ +i2
G i2r
2−1(cid:1)2(cid:27) −(cid:18) V 3r 12+E {η +2 }·E(cid:26)
(r 1r
2+r r12 1r G22 i2G(cid:101) +i4
r 2G(cid:101)
i2)2(cid:27)
+E η (cid:101)+2 E(cid:26) r 12r 22G i2G(cid:101) i2 (cid:27)(cid:19)(cid:12) (cid:12) (cid:12)≲ max(cid:26) C(σ2+Err ♯)log6(d) ,d−50(cid:27) , (148)
{ }· (r 1r 2+r 1G i2+r 2G(cid:101) i2)2 (cid:12) λ √m
asdesired.
B.4.1 ProofofLemma12
Weproveeachpartinturn.
Proof of Lemma 12(a.): Let a
⊤j
= [G(cid:101)j
|
x
⊤j
G jz
⊤j
] and recall τ
j
as defined in Eq. (76). We claim the
followinghold
(cid:20) µ ν++(cid:21) −(cid:34) O Ou vµ
ν
u−−u ,, v(v( ii ))(cid:35) = Σ i−1(cid:18) ∑ j=iτ j(cid:34) G G(cid:101)j jx x⊤ ⊤j
j
u vu v(cid:35) +(cid:16) y i+G iG(cid:101)i −a i⊤(cid:20) µ ν++(cid:21)(cid:17) a i(cid:19) =: b, (149)
̸
where Σ i = λmI +∑ j ̸=ia ja ⊤j . Define the linear subspace V = S ♯ ×Rd. Multiplying both sides of
Eq.(149)byP andtakingthenormyields
V⊥
(cid:34) (cid:35)
∥P S⊥ ♯µ+ ∥2 2 = ∥P S⊥ ♯O uµ u−,v(i) ∥2 2+ ∥P V⊥b ∥2 2+2(cid:68) P V⊥ O Ou vµ
ν
u−u− ,, v(v( ii )) ,P V⊥b(cid:69) .
Notethatη +2 = ∥P
S⊥
♯µ+ ∥2 2andω −i = P
S⊥
♯O uµ−u,v(i) bydefinition. Consequently,weobtain
(cid:12) (cid:12)E(cid:8) η +2(cid:9) −E(cid:8) ∥ω−i ∥2 2(cid:9)(cid:12) (cid:12) ≤E(cid:8) ∥P V⊥b ∥2 2(cid:9) +2E(cid:8) ∥P S⊥ ♯O uµ−u,v(i) ∥2 2(cid:9)1/2 ·E(cid:8) ∥P V⊥b ∥2 2(cid:9)1/2 . (150)
ApplyingthetriangleinequalityandusingΣ i−1
⪯
(λn) −1I,weobtainthebound
E(cid:8) ∥P V⊥b ∥2 2(cid:9)≲ E(cid:110)(cid:16) ∑ j ̸=iτ jG(cid:101)jx ⊤j u ((cid:17) λ2 m+ )2(cid:16) ∑ j ̸=iτ jG(cid:101)jx ⊤j u(cid:17)2(cid:111) + E(cid:110)(cid:16) y i+G iG(cid:101)i − (λa mi⊤ )2(cid:20) µ ν++(cid:21)(cid:17)2 ∥a i ∥2 2(cid:111) .
Notethatx
⊤j
uisindependentofτ
j
(76)asu ⊤µ⋆ = u ⊤µ
t
=0. Consequently,weobtainthat
E(cid:110)(cid:16) ∑ τ jG(cid:101)jx⊤j u(cid:17)2(cid:111) = (m −1)E(cid:8) G(cid:101)2 jτ j2(cid:9)
≤
mE {G(cid:101)4 j}1/2 ·E {τ j4 }1/2 ≲ m(cid:0) σ2+Err ♯(cid:1) , (151)
j=i
̸
where the last step follows from the inequality (144). Applying the Cauchy–Schwarz inequality then
yields
E(cid:110)(cid:16) y i+G iG(cid:101)i −a i⊤(cid:20) µ ν++(cid:21)(cid:17)2 ∥a
i
∥2 2(cid:111) ≲E(cid:110)(cid:16) y i+G iG(cid:101)i −a i⊤(cid:20) µ ν++(cid:21)(cid:17)4(cid:111)1 2E(cid:8) ∥a
i
∥4 2(cid:9)1 2
≲ d(cid:0) σ2+Err ♯(cid:1) , (152)
where to obtain the last inequality, we used the same bound as inequality (100). Putting the pieces
together and invoking the assumption λm
≥
d
≥
m yields E(cid:8) ∥P V⊥b ∥2 2(cid:9) ≲ (σ2+Err ♯)/(λm). Then,
sinceP
S⊥
♯µ♯ =0,wededucetheinequality
∥P S⊥ ♯O uµ−u,v(i) ∥2 2 = ∥P S⊥ ♯O uµ−u,v(i) −P S⊥ ♯µ♯ ∥2 2 ≤ ∥µ−u,v(i) −O u⊤µ♯ ∥2 2 ≤ λ1 m ∑(cid:0) y j −G jG(cid:101)j(cid:1)2 ,
j=i
̸
52wherethelaststepfollowsfromtheinequality(143). Consequently,weobtainthebound
(cid:110) (cid:111)
E ∥P S⊥ ♯O uµ−u,v(i) ∥2 2 ≤E {(y j −G jG(cid:101)j)2 }/λ ≤ (σ2+Err ♯)/λ.
A (σs 2se +m Eb rl ri ♯n )g /(th λe √b mou ).n Pd rs oa cn eed ds iu nb gs sti it mu it li an rg lyth ye im eldin st to heth ae ni an le oq gu oa ul sit by o( u15 n0 d)y (cid:12) (cid:12)Eie (cid:8)ld
η
(cid:101)s +2(cid:12) (cid:12) (cid:9)E −(cid:8) η E+2 (cid:8)(cid:9) ∥−
ω
(cid:101)−E i(cid:8) ∥∥
2
2(cid:9)ω (cid:12) (cid:12)− ≲i ∥2 2 (σ(cid:9) 2(cid:12) (cid:12) +≲
Err ♯)/(λ√m). This concludes the proof of inequality (147a). Before proceeding to the proofs of parts
(b.) and(c.),wefirstprovidetheproofofthedeferredclaim(149).
Proofoftheclaim(149):TheKKTconditionsoftheoptimizationproblemsdefining[µ+,ν+] = G([µ♯ ν♯])(6)
|
and(µ
u−,v(i)
,ν
u−,v(i)
)(75)yield
λm(cid:20) µ ν+ +− −µ ν♯♯(cid:21) = ∑ j=i(cid:16) y j+G jG(cid:101)j −a⊤j (cid:20) µ ν++(cid:21)(cid:17) a j+(cid:16) y i+G iG(cid:101)i −a i⊤(cid:20) µ ν++(cid:21)(cid:17) a i (153a)
̸
(cid:34) (cid:35) (cid:34) (cid:35) (cid:34) (cid:35)
λm µ
ν
u−u −,, vv( (i i) )− −O Ou⊤ v⊤µ ν♯♯ = ∑
j
̸=i(cid:16) y j+G jG(cid:101)j −a⊤j O Ou vµ
ν
u−−u ,, v(v( ii )) (cid:17) G G(cid:101)j jO Ou v⊤ ⊤zx jj . (153b)
MultiplyingO uorO vonbothsidesofEq.(153b)andusingthefactsthatO uO u⊤µ♯ = µ♯andO vO v⊤ν♯ =
ν♯ thenyields
(cid:34) (cid:35) (cid:34) (cid:35) (cid:34) (cid:35)
λm O Ou vµ
ν
u−u −,, vv( (i i) )−µ ν♯♯ = ∑ j=i(cid:16) y j+G jG(cid:101)j −a⊤j O Ou vµ
ν
u−−u ,, v(v( ii )) (cid:17) G G(cid:101)j jO Ou vO Ou v⊤ ⊤zx jj
− ̸
(cid:34) (cid:35) (cid:34) (cid:35)
= ∑ j=i(cid:16) y j+G jG(cid:101)j −a⊤j O Ou vµ
ν
u−−u ,, v(v( ii )) (cid:17)(cid:16) a
j
−
G G(cid:101)j jzx ⊤⊤ jj vu vu (cid:17) ,
̸
wherethelaststepfollowsbyO O = I uu andO O = I vv . Subtractingtheequationinthe
u u⊤
−
⊤ v v⊤
−
⊤
precedingdisplayfromEq.(153a)andre-arrangingthetermsyieldsthedesiredresult.
ProofofLemma12(b.),(c.): Wefirstclaimthatwith∆ :=max(cid:8)σ+Err ♯log6(d) ,d 50(cid:9) ,
λ √d −
E {(ϑ 1−i −θ 1det)2 },E {(ϑ 2−i −θ 2det)2 },E {(ϑ(cid:101) 1−i −θ(cid:101) 1det)2 },E {(ϑ(cid:101) 2−i −θ(cid:101) 2det)2 }≲∆2. (154)
Wetakethisinequalityasgivenfornow,deferringitsprooftotheend. Wethenhave
E e2 f2 E (e+ f)(e f) =E (e f +2f)(e f) E e f 2 +2 f E e f ,
| { }− | ≤ {| − |} {| − − |} ≤ {| − | } | |· {| − |}
with e =
α♯(cid:101)α♯
+1
ϑ 1−i ϑ(cid:101) 1−i
, and f =
α♯(cid:101)α♯
+1
θ 1det θ(cid:101) 1det
.
L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯ L2 ♯(cid:101)L2 ♯ − L ♯ − (cid:101)L ♯
Wenextapplytheinequalities(154)toobtainthebound
E {|e
−
f |2 }≲E {(ϑ 1−i −θ 1det)2 }+E {(ϑ(cid:101) 1−i −θ(cid:101) 1det)2 }≲∆2,
which,uponapplyingJensen’sinequality,yieldsthefurtherboundE e f E e f 2 1/2 ≲ ∆.
{| − |} ≤ {| − | }
Notethatbydefinitionofθdet(39a)andθ(cid:101)det(39b),weobtain
1 1
f =
λ |α♯(cid:101)α♯ −L2 ♯(cid:101)L2
♯| ≲ α♯(cid:101)α♯ 1 +β♯+β(cid:101)♯
≲(cid:113)
Err ♯.
| | λL2(cid:101)L2+V(L2+(cid:101)L2) | − |
♯ ♯ ♯ ♯
Puttingtogetherthepiecesyieldstheinequality
E e2 f2
≲∆2+(cid:113)
Err ♯∆≲
max(cid:26)(σ2+Err ♯)log6(d) ,d−50(cid:27)
.
| { }− | λ √d
53Thisprovesinequality(147b). Proceedingsimilarlyprovesinequality(147c). Itremainstoestablishthe
deferredinequalities(154).
ProofofClaim(154): Recall that θ(u 1) = ⟨u 1,µ+
⟩
and ϑ 1−i = ⟨u 1,O uµ u−,v(i) ⟩. Applying the triangle in-
equalityyieldsthebound
E(cid:8)(cid:0) ϑ 1−i −θ 1det(cid:1)2(cid:9) ≤2E(cid:8)(cid:0) ϑ 1−i −θ(u 1)(cid:1)2(cid:9) +2E(cid:8)(cid:0) θ(u 1) −θ 1det(cid:1)2(cid:9) . (155)
We proceed to bound each term on the RHS of the preceding display. Invoking the relation (149), we
obtain
|ϑ 1−i −θ(u 1) |2 ≲(cid:68)(cid:20) u 01(cid:21) ,Σ i−1∑ j=iτ j(cid:34) G G(cid:101)j jzx ⊤⊤ jj vu vu(cid:35) (cid:69)2 +(cid:16) y i+G iG(cid:101)i −a i⊤(cid:20) µ ν++(cid:21)(cid:17)2(cid:68) a i,Σ i−1(cid:20) u 01(cid:21)(cid:69)2 .
̸ (cid:124) (cid:123)(cid:122) (cid:125)
(cid:124) (cid:123) T(cid:122)
1
(cid:125) T2
Then, applying the Cauchy–Schwarz inequality and the inequality Σ i−1
⪯
(λm) −1I, we upper bound
theexpectationofT as
1
E {T
1
} ≤
(λm1 )2(cid:18) E(cid:110)(cid:16) ∑ τ jG(cid:101)jx⊤j u(cid:17)2(cid:111) +E(cid:110)(cid:16) ∑ τ jG jz⊤j v(cid:17)2(cid:111)(cid:19) ≲ σ2 λ+ 2mErr ♯ ,
j=i j=i
̸ ̸
(cid:20) (cid:21) (cid:20) (cid:21)
u e
where the last step follows from the inequality (151). Let e, f
∈
Rd such that Σ i−1 01 =
f
. Since
bothe, f areindependentofa,wecompute
i
E(cid:26)(cid:68)
a i,Σ
i−1(cid:20) u 01(cid:21)(cid:69)4(cid:27) =E(cid:110)(cid:0)
G(cid:101)ix i⊤e+G iz
i⊤f(cid:1)4(cid:111) ≲E(cid:110)(cid:0)
∥e ∥2+ ∥f
∥2(cid:1)4(cid:111)
≤
(λm1
)4,
where in the last step we used the inequality e + f (λm) 1 u = (λm) 1. Consequently,
2 2 − 1 2 −
∥ ∥ ∥ ∥ ≤ ∥ ∥
applyingtheCauchy–Schwarzinequalityinconjunctionwithinequality(152),weobtainthebound
E(cid:26)(cid:16) y i+G iG(cid:101)i −a i⊤(cid:20) µ ν++(cid:21)(cid:17)2(cid:68) a i,Σ i−1(cid:20) u 01(cid:21)(cid:69)2(cid:27)
≤
σ2 (λ+ mE )r 2r ♯ .
Puttingthepiecestogetherthenyields
E(cid:8) |ϑ 1−i −θ(u 1) |2(cid:9)≲(σ2+Err ♯)/(λ2m). (156)
WenowturntoboundE θ(u ) θdet 2 . Applyinginequalities(41a)and(41b)yields
{| 1 − 1 | }
Pr(cid:8) |θ(u 1) −θ 1det
| ≥
∆(cid:9) ≤2d−110 and ∆
=max(cid:26)C(σ+ λ(cid:112) Err ♯)log √6 d(d) ,d−50(cid:27)
.
Consequently,weobtainthat
E θ(u ) θdet 2 ∆2+E(cid:8) θ(u ) θdet 2 1(cid:8) θ(u ) θdet ∆(cid:9)(cid:9)
{| 1 − 1 | } ≤ | 1 − 1 | · | 1 − 1 | ≥
∆2+E(cid:8) θ(u ) θdet 4(cid:9)1/2 Pr(cid:8) θ(u ) θdet ∆(cid:9)1/2
≤ | 1 − 1 | · | 1 − 1 | ≥
(i)
∆2+(σ2+1)d2 √2d−55 ≲∆2,
≤ ·
wherestep(i)followssinceE(cid:8) |θ(u 1) −θ 1det |4(cid:9)≲E {∥µ+ ∥4 2}+C
≤
(σ4+1)d4.Combiningtheinequal-
ityinthedisplayabovewithinequalities(155)and(156)yieldstheboundE(cid:8)(cid:0) ϑ 1−i −θ 1det(cid:1)2(cid:9)
≤
∆2. The
boundsontheremainingtermsfollowidentically,henceweomitthemhere.
C Deterministic convergence: Proof of Lemma 11
Note that Errdet = (cid:0) αdet (cid:101)αdet 1(cid:1)2+(βdet)2+(β(cid:101)det)2. We control each of these three terms in turn.
− (cid:113)
(cid:112)
Throughout,weusetheshorthandL = α2+β2and(cid:101)L = (cid:101)α2+β(cid:101)2.
54Controlling(αdet (cid:101)αdet −1)2: RecalltheF m,d,σ,λandF(cid:101)m,d,σ,λ—whichcharacterizeαdetand (cid:101)αdet,respectively—
asdefinedinEq.(34). WeusetheshorthandD = V(L2+(cid:101)L2)+λL2(cid:101)L2,whereV asdefinedinEq(33).
Expanding,wedecompose
αdet = α+
V(α (cid:101)α −L2(cid:101)L2)
α+
V
1
(cid:101)αβ2
L2D λ+V
1
L2(cid:101)L2
= α+
Vα2 (cid:101)α(1 −α (cid:101)α)
+
Vα(β2 (cid:101)α2+β(cid:101)2α2+β2β(cid:101)2)
+
V
1
(cid:101)αβ2
,
L2D − L2D λ+V
1
L2(cid:101)L2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T1 T2
whereinthelaststepweusedtherelationα (cid:101)α L2(cid:101)L2 = α (cid:101)α(1 α (cid:101)α) (α2β(cid:101)2+ (cid:101)α2β2+β2β(cid:101)2).Wesimilarly
− − −
decompose
αdet = α+
V (cid:101)α2α(1 −α (cid:101)α)
+
V (cid:101)α(β2 (cid:101)α2+β(cid:101)2α2+β2β(cid:101)2)
+
V
2
αβ(cid:101)2
.
(cid:101) (cid:101) (cid:101)L2D − (cid:101)L2D λ+V
2
L2(cid:101)L2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T3 T4
Beforecontinuing,weclaimthefollowingbounds
(i.) 0.9 α (cid:101)α 1.1, (ii.) √0.03 α , (cid:101)α 3, (iii.) β,β(cid:101) 0.1,
≤ ≤ ≤ | | | | ≤ ≤
(iv.) V,V ,V 1, and (v.) D λ, (157)
1 2
≍ ≍
deferringitsprooftotheend. Combiningthedecompositionsofαdetandαdetwiththeboundsin(157),
(cid:101)
weobtain
αdet
α ,
αdet
α
≲√Err/λ,
(cid:101) (cid:101)
| − | | − |
whichprovesinequality(87c). Consequently,weobtainthat
αdet α +C √Err/λ 3+C √c/C 4,
1 1
| | ≤ | | ≤ ≤
whereweinvokedtheassumptions α 3,Err candλ C. Similarly, αdet 4. Thisprovesthe
(cid:101)
| | ≤ ≤ ≥ | | ≤
secondpartofinequality(87b). Continuing,were-write
(αdet αdet 1)2 = (cid:0) (T +T )(T +T ) 1(cid:1)2 = (T T 1+T T +T T +T T )2
(cid:101) 1 2 3 4 1 3 1 4 2 3 2 4
− − −
= (T T 1)2+2(T T 1)(T T +T T +T T )+(T T +T T +T T )2. (158)
1 3 1 3 1 4 2 3 2 4 1 4 2 3 2 4
− −
Wefirstbound(T T 1)2. Straightforwardcalculationyields
1 3
−
(cid:18) Vα2α2 V2α3α3(αα 1)(cid:19)
T 1T
3
−1= (α (cid:101)α −1) 1
−
D(cid:101) (L−2+(cid:101)L−2)+ L(cid:101) 2(cid:101)L2D(cid:101) 2−
Then,bytheclaim(157),thereexistuniversal,positiveconstantsc ,c suchthatboth
1 2
c Vα2α2 c V2 α3α3(αα 1) c
1 (cid:101) (L−2+(cid:101)L−2) 2 and | (cid:101) (cid:101) − | 2 .
λ ≤ D ≤ λ L2(cid:101)L2D2 ≤ λ2
Bylettingλ C(1+σ)d/m Csothat c2 c1,weobtain
≥ ≥ λ2 ≤ 2λ
(cid:16) 2c (cid:17)2 (cid:16) c (cid:17)2
(αα 1)2 1 2 (T T 1)2 (αα 1)2 1 1 .
(cid:101) 1 3 (cid:101)
− · − λ ≤ − ≤ − · − 2λ
Since λ C for a large enough C, we note that (1 2c /λ)2 1 4c /λ and (1 c /(2λ))2
2 2 1
≥ − ≥ − − ≤
1 c /(4λ). Puttingthepiecestogetheryields
1
−
(cid:16) 4c (cid:17) (cid:16) c (cid:17)
(αα 1)2 1 2 (T T 1)2 (αα 1)2 1 1 . (159)
(cid:101) 1 3 (cid:101)
− · − λ ≤ − ≤ − · − 4λ
55Next,weapplytheclaim(157)toobtainthepairofbounds
T
1
, T
3
≲
1 and T
2
T
4
≲(β2+β(cid:101)2)/λ.
| | | | | | ∨ | |
Combiningwiththeinequality(159),weconcludethatboth
2 T T 1 T T +T T +T T
C
′
|α (cid:101)α −1 |·(β2+β(cid:101)2)
, and
1 3 1 4 2 3 2 4
| − |·| | ≤ λ
(T T +T T +T T )2
C ′(β2+β(cid:101)2)2
.
1 4 2 3 2 4 ≤ λ2
Combiningtheinequalitiesintheprecedingdisplaywiththeinequality(159)andEq.(158),weobtain
(cid:0) αdet αdet 1(cid:1)2 (αα 1)2 (cid:16) 1 c 1 (cid:17) + C ′ |α (cid:101)α −1 |·(β2+β(cid:101)2) + C ′(β2+β(cid:101)2)2 , (160a)
(cid:101) − ≤ (cid:101) − · − 4λ λ λ2
(cid:0) αdet αdet 1(cid:1)2 (αα 1)2 (cid:16) 1 2c 2(cid:17) C ′ |α (cid:101)α −1 |·(β2+β(cid:101)2) C ′(β2+β(cid:101)2)2 . (160b)
(cid:101) − ≥ (cid:101) − · − λ − λ − λ2
Beforeturningtocontroltheorthogonalcomponent,weestablishthedeferredclaims(157).
Proofoftheclaims(157):UsingErr c, weobtainthat (αα 1)2 c. When c 0.01, weobtainthat
(cid:101)
≤ − ≤ ≤
0.9 αα 1.1,whichestablishespart(i.).
(cid:101)
≤ ≤
By L,(cid:101)L [0.2,3], we obtain α L 3 and (cid:101)α (cid:101)L 3. Continuing, since Err c, we obtain
∈ | | ≤ ≤ | | ≤ ≤ ≤
β2+β(cid:101)2 0.01for c 0.01. Then, α2 = L2 β2 0.04 0.01 = 0.03andsimilarly (cid:101)α2 0.03. Sowe
≤ ≤ − ≥ − ≥
concludethat α , (cid:101)α 1andβ,β(cid:101) 0.1,whichestablishesparts(ii.) and(iii.).
| | | | ≍ ≤
Continuing,bydefinitionofV,V ,V inEq(33),wefindthat
1 2
V ≤E {G 12G 22
}
= L2 (cid:101)L2 ≲ 1, V
1
≤E {G 22
}
=(cid:101)L2 ≲ 1, and V
2
≤E {G 12
}
= L2 ≲ 1.
TowardslowerboundingeachofthequantitiesV,V ,V ,wenotethat,bydefinition,
1 2
(cid:26) G2G2 (cid:27) (cid:26) G2 (cid:27) (cid:26) G2 (cid:27)
V =E 1 2 , V =E 2 andV =E 1 .
1+G2/r +G2/r 1 1+G2/r +G2/r 2 1+G2/r +G2/r
1 2 2 1 1 2 2 1 1 2 2 1
Further, by Eq. (32), we obtain r ,r λΛ = λm/d C, where in the last step we have applied the
1 2
≥ ≥
assumptionλm Cd. Puttingthetwopiecestogetheryieldsthelowerbound
≥
(cid:26) G2G2 (cid:27)
V E 1 2 ≳ 1,
≥ 1+G2/C+G2/C
1 2
where the last step follows since G
1
N(0,L2), G
2
N(0,(cid:101)L2) and C > 0 is a universal constant.
≳ ∼ ∼
Similarly,weobtainV ,V 1. Consequently,weobtainV,V ,V 1,whichestablishespart(iv.).
1 2 1 2
≍
TowardsboundingD,by0.2 L,(cid:101)L 3,weobtainD=V(L2+(cid:101)L2)+λL2(cid:101)L2 0.24 λ.ByV L2(cid:101)L2,
≤ ≤ ≥ · ≤
we obtain D (L2+(cid:101)L2+λ)L2(cid:101)L2 (λ+18) 34 2 34 λ, where the last step holds for λ 18.
≤ ≤ · ≤ · · ≥
Consequently,D λ,establishingpart(v.). Thisconcludestheproofoftheclaimsin(157).
≍
Controlling(βdet)2+(β(cid:101)det)2. LetthefunctionsH m,d,σ,λ,H(cid:101)m,d,σ,λ,S m,d,σ,λ,S(cid:101)m,d,σ,λ—whichcharacterize
theorthogonalcomponentsβdetandβ(cid:101)det—beasdefinedinequations(34),(38)andfurtherlet
ιdet = H m,d,σ,λ(α,β, (cid:101)α,β(cid:101)), (ηdet)2 = S m,d,σ,λ(α,β, (cid:101)α,β(cid:101)),
(cid:101)ιdet = H(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)), (η (cid:101)det)2 = S(cid:101)m,d,σ,λ(α,β, (cid:101)α,β(cid:101)).
Notethatbydefinition,wehavethedecompositions(βdet)2 = (ιdet)2+(ηdet)2and(β(cid:101)det)2 = ( (cid:101)ιdet)2+
(ηdet)2. Wefirstbound(ιdet)2+(ιdet)2 andthenturntobound(ηdet)2+(ηdet)2. Recalltheshorthand
(cid:101) (cid:101) (cid:101)
D=V(L2+(cid:101)L2)+λL2(cid:101)L2. Then,weexpandιdetaccordingitsdefinitiontoobtain
ιdet =
(cid:18)
1+
V(α (cid:101)α −L2(cid:101)L2) α (cid:101)α V
1
(cid:19)
β.
DL2 − L2(cid:101)L2 λ+V
1
·
56Recallthat α (cid:101)α 1.1, α , (cid:101)α 3bytheclaim(157),and α (cid:101)α 1 √Err √c,β2+β(cid:101)2 Err cby
| | ≤ | | | | ≤ | − | ≤ ≤ ≤ ≤
assumption. Thus,applyingthetriangleinequality,weobtain
α (cid:101)α L2 (cid:101)L2 = α (cid:101)α(1 α (cid:101)α) (α2β(cid:101)2+ (cid:101)α2β2+β2β(cid:101)2) 1.1√c+10c.
| − | | − − | ≤
Combiningthiswiththeclaim(157),wefindthatthereexistsuniversalconstantsc ,c andc suchthat
1′ 2′ 3′
both
(cid:12)
(cid:12) (cid:12)V(α (cid:101)α
−L2(cid:101)L2)(cid:12)
(cid:12) (cid:12) c 1′ (√c+c) and c 2′ α (cid:101)α V 1 c 3′ .
(cid:12) DL2 (cid:12) ≤ λ λ ≤ L2(cid:101)L2 λ+V
1
≤ λ
Consequently,
(cid:18) (cid:19) (cid:18) (cid:19)
c c c
ιdet 1+ 1′ (√c+c) 2′ β 1 2′ β,
≤ λ − λ ≤ − 2λ
wherethelaststepfollowsbyletting c beasmallenoughconstanttoensurethebound c (√c+c)
1′
≤
c /2. Similarly,aslongasc 0.01,welowerboundιdetas
2′
≤
(cid:18) c c (cid:19) (cid:18) c +c (cid:19)
ιdet 1 1′ (√c+c) 3′ β 1 1′ 3′ β.
≥ − λ − λ ≥ − λ
Puttingtheupperandlowerboundtogetherandproceedingsimilarlyforιdet,weobtain—forλ C—
(cid:101)
≥
thepairofinequalities
(cid:18) 2(c +c )(cid:19) (cid:18) c (cid:19)
1 1′ 3′ β2 (ιdet)2 1 2′ β2, and
− λ ≤ ≤ − 2λ
(cid:18) 2(c +c )(cid:19) (cid:18) c (cid:19)
1 1′ 3′ β(cid:101)2 ( (cid:101)ιdet)2 1 2′ β(cid:101)2. (161)
− λ ≤ ≤ − 2λ
We next turn to bound (ηdet)2+(ηdet)2. Recall the quantities V and V as defined in Eq. (35) and
(cid:101) 3 4
Eq.(36). Wemakethefollowingclaim
C σ2d2 C (Err+σ2)d2
2 V ,V 1 , (162)
(λm)2 ≤ 3 4 ≤ (λm)2
postponingitsproofuntiltheend. TakingtheinequalitiesaboveasgivenandfurtherusingEqs.(37a)
and(37b),weobtainthelowerbounds
m m C σ2d2 C dσ2 C dσ2
(ηdet)2
V
2 2
andsimilarly
(ηdet)2 2
. (163)
≥ 2d 3 ≥ 2d (λm)2 ≥ 2λ2m (cid:101) ≥ 2λ2m
Turningtoupperboundsonηdetandηdet,weapplyEqs.(37a)and(37b)toobtaintheinequality
(cid:101)
(ηdet)2
m(cid:16)(ηdet)2E {G 24
} +
(η (cid:101)det)2E {G 12G 22
} +V
(cid:17)
≤ d r2 r2 3
1 1
C d (cid:16) (cid:17)
′ (ηdet)2+(ηdet)2+Err+σ2
, (164)
≤ λ2m (cid:101)
wherethelaststepfollowsfromtheboundr λΛ = λm/d(seeLemma19),theupperboundofV in
1 3
claim(162)andbytakingC largeenoughtoen≥ sureC ,E G4 ,E G2G2 C . NotethatC d/(λ2m)
′ 1 { 2} { 1 2} ≤ ′ ′ ≤
C m/(C2d) 1/2 since λm Cd and C is a large enough constant. Consequently, rearranging the
′
≤ ≥
termsofinequality(164),wededuce
2C d(cid:16) (cid:17)
(ηdet)2 ′ (ηdet)2+Err+σ2
. (165)
≤ λ2m (cid:101)
Identicalstepsyieldtheanalogousbound
2C d(cid:16) (cid:17)
(ηdet)2 ′ (ηdet)2+Err+σ2
. (166)
(cid:101) ≤ λ2m
57Combininginequalities(165)and(166)yields
10C d
(ηdet)2,(ηdet)2 ′ (Err+σ2). (167)
(cid:101) ≤ λ2m
This concludes the proof for ηdet and ηdet. Before concluding, we provide the proof of the deferred
(cid:101)
claim(162).
ProofofClaim(162):StartingwiththelowerboundforV ,byEq.(35),weobtainthat
3
σ2 (cid:26) G2 (cid:27)(i) σ2 σ2d2
V E 2 ≳ ≳ ,
3 ≥ r2 (1+G2/r +G2/r )2 r2 (λm)2
1 1 2 2 1 1
whereinstep(i)weuser ,r λm/d C(seeLemma19)sothat
1 2
≥ ≥
(cid:26) G2 (cid:27) (cid:26) G2 (cid:27)
E 2 E 2 ≳ 1,
(1+G2/r +G2/r )2 ≥ (1+G2/C+G2/C)2
1 2 2 1 1 2
andinthelaststepweuser 2λm/d(seeLemma19). TurningtotheupperboundforV ,byEq.(35)
1 3
≤
and0.2 L,(cid:101)L 3,weobtainthat
≤ ≤
(σ2+Err)d2
V
3
≲(σ2+β2β(cid:101)2)r 2−2+(α (cid:101)α −L2 (cid:101)L2)2r 2−2+β(cid:101)2r 2−2+β(cid:101)2r 2−2 ≲
(λm)2
,
wherethelaststepfollowssincer
2
λm/d(seeLemma19)and β2β(cid:101)2,β2,β(cid:101)2,(α (cid:101)α L2(cid:101)L2)2 ≲ Err. The
≥ −
proofforboundingV isidenticalsoweomitithere.
4
Puttingtogetherthepieces: Combininginequalities(160a),(161)and(167),weobtainthat
Errdet = (αdet αdet 1)2+(ιdet)2+(ιdet)2+(ηdet)2+(ηdet)2
(cid:101) (cid:101) (cid:101)
−
(cid:16)
1
c
1
(cid:17)
(αα 1)2+
C
′
|α (cid:101)α −1 |·(β2+β(cid:101)2)
+
C ′(β2+β(cid:101)2)2
≤ − 4λ (cid:101) − λ λ2
+(cid:16)
1
c
2′
(cid:17)
(β2+β(cid:101)2)+
10C ′d(Err+σ2)
.
− 2λ λ2m
Then,using α (cid:101)α 1 √Err √candβ2+β(cid:101)2 Err c,weupperboundthedeterministicerroras
| − | ≤ ≤ ≤ ≤
Errdet
(cid:16)
1
min(c 1/4,c 2′/2)
+
C ′√c
+
C
′
·c
+
10C ′d(cid:17)
Err+
10C ′dσ2
≤ − λ λ λ2 λ2m · λ2m
(cid:16)
1
min(c 1/4,c 2′/2)(cid:17)
Err+
10C ′dσ2
,
≤ − 2λ λ2m
wherethelaststepfollowsbytakingcsmallenoughandλ Cd/mwithClargeenoughtoensure
≥
C ′√c
+
C
′
·c
+
10C ′d C ′√c
+
C
′
·c
+
10C
′
min(c 1/4,c 2′/2)
.
λ λ2 λ2m ≤ λ λ2 λC ≤ 2λ
Towardslowerboundingthedeterministicerror,wecombinetheinequalities(160b),(161)and(163)to
obtain
Errdet (αα 1)2
(cid:16)
1
2c 2(cid:17) C
′
|α (cid:101)α −1 |·(β2+β(cid:101)2) C ′(β2+β(cid:101)2)2
≥ (cid:101) − · − λ − λ − λ2
+(cid:18) 1 2(c 1′ +c 3′)(cid:19) (β2+β(cid:101)2)+ C 2dσ2
− λ 2λ2n
(cid:16) 1 2(c 1′ +c 3′ +c 2)+C ′(√c+c)(cid:17) Err+ C 2dσ2 .
≥ − λ 2λ2n
Thelowerboundfollowsupontakingc 0.01.Thisprovesinequality(87a)bynotingthatc ,c ,c ,c ,c ,C ,C
≤
1 2 1′ 2′ 3′ ′ 2
areuniversal,positiveconstants. Puttingtogetherinequalities(160a)and(161)provesthefirstpartof
inequality(87b). ThisconcludestheproofofLemma11.
58D Concentration of the trace inverse
This section is dedicated to the following lemma—which establishes the concentration properties al-
ludedtobyEq.(31)—aswellasitsproof.
Lemma 13. Consider u,v Sd 1 and let the columns of O ,O Rd (d 1) form orthonormal bases of the
− u v × −
∈ ∈
subspacesorthogonaltou,v,respectively. Suppose x,z m i.i.d. N(0,I ). Further,let
{ i i }i=1 ∼ d
m
G
i
= x i⊤µ♯,G(cid:101)i = z i⊤ν♯ ∀i
∈
[m], B = i∑ =1G(cid:101) i2O u⊤x i(O u⊤x i) ⊤+λm ·I
d
−1,
m m
C = i∑ =1G iG(cid:101)i ·O u⊤x i(O v⊤z i) ⊤, D = i∑ =1G i2O v⊤z i(O v⊤z i) ⊤+λm ·I
d
−1, (168)
and let r 1,r
2
be the solution of the fixed point equation (32). Suppose L ♯,(cid:101)L
♯
C for some universal constant
≤
K > 0. Then,thereexistuniversalconstantsd ,c ,C > 0dependingonlyonKsuchthatfor1 m d,d
0 1 1
≤ ≤ ≥
d ,λm C dandt
C1log1.5(d)
,thefollowinghold
0 ≥ 1 ≥ √d
Pr(cid:8)(cid:12) (cid:12)tr(cid:0) (B −CD−1C⊤) −1(cid:1) −r 1−1(cid:12) (cid:12)
≥
t(cid:9) ≤2exp(cid:26) m− lc o1 gd 22 (t d2 )(cid:27) +d−15,
Pr(cid:8)(cid:12) (cid:12)tr(cid:0) (D −C⊤B−1C) −1(cid:1) −r 2−1(cid:12) (cid:12)
≥
t(cid:9) ≤2exp(cid:26) m− lc o1 gd 22 (t d2 )(cid:27) +d−15.
Proof. Weneedthefollowingtwoauxiliarylemmas. WeprovidetheproofofLemma14inSectionD.1
andtheproofofLemma15inSectionD.2.
Lemma14. UnderthesettingofLemma13,thereexistpositiveconstantsd ,c ,C > 0,dependingonlyonK,
0 1 1
suchthatforany1 m d,d d ,λm C dandt 2d 24thefollowinghold
0 1 −
≤ ≤ ≥ ≥ ≥
Pr(cid:8)(cid:12) (cid:12)tr(cid:0) (B CD−1C⊤) −1(cid:1) E(cid:8) tr(cid:0) (B CD−1C⊤) −1(cid:1)(cid:9)(cid:12) (cid:12) t(cid:9) 2exp(cid:26) −c 1d2t2 (cid:27) +d−20,
− − − ≥ ≤ mlog2(d)
Pr(cid:8)(cid:12) (cid:12)tr(cid:0) (D C⊤B−1C) −1(cid:1) E(cid:8) tr(cid:0) (D C⊤B−1C) −1(cid:1)(cid:9)(cid:12) (cid:12) t(cid:9) 2exp(cid:26) −c 1d2t2 (cid:27) +d−20.
− − − ≥ ≤ mlog2(d)
Lemma15. UnderthesettingofLemma13,thereexistpositiveconstantsd ,C ,C >0,dependingonlyonK,
0 1 2
suchthatfor1 m d,d d ,λm C dthefollowinghold
0 1
≤ ≤ ≥ ≥
(cid:12) (cid:12) (cid:12)E(cid:8) tr(cid:0) (B −CD−1C⊤) −1(cid:1)(cid:9) −r 1−1(cid:12) (cid:12)
(cid:12)
∨(cid:12) (cid:12) (cid:12)E(cid:8) tr(cid:0) (D −C⊤B−1C) −1(cid:1)(cid:9) −r 2−1(cid:12) (cid:12)
(cid:12)
≤
C 2lo √g1 d.5(d) .
Thedesiredresultfollowsimmediatelyupondecomposing
(cid:12) (cid:12)tr(cid:0) (B −CD−1C⊤) −1(cid:1) −r 1−1(cid:1)(cid:9)(cid:12) (cid:12)
≤
(cid:12) (cid:12)tr(cid:0) (B −CD−1C⊤) −1(cid:1) −E(cid:8) tr(cid:0) (B −CD−1C⊤) −1(cid:1)(cid:9)(cid:12) (cid:12)
+(cid:12) (cid:12)E(cid:8) tr(cid:0) (B −CD−1C⊤) −1(cid:1)(cid:9) −r 1−1(cid:12) (cid:12),
andsubsequentlyapplyingLemma14tocontrolthefirsttermintheRHSandapplyingLemma15to
controlthesecondterm.
D.1 ProofofLemma14
WefollowthestrategyconsideredinSection4.1.1. Tothisend,definethefunction f : R2d m Rand
×
→
theHammingmetricρas
f(cid:0) {x i,z
i
}im =1(cid:1) =tr(cid:0) (B −CD−1C⊤) −1(cid:1) , (169)
where the matrices B,C and D are as in (168), and consider the Hamming metric ρ : R2d m R as
×
ρ(cid:0) x,z m , x,z m (cid:1) = ∑m 1(cid:8) (x,z ) = (x,z )(cid:9) . As in Section 4.1.1, the proof consists→ of three
{ i i }i=1 { i′ i′ }i=1 i=1 i i ̸ i′ i′
steps:First,wedefinearegularityset onwhichtheboundeddifferencepropertyholds,thenweapply
S
atruncationargumenttorestrictourselvestotheregularityset ,andfinallyweconcludebyapplying
S
thetypicalboundeddifferencesinequality. Wenowexecuteeachofthesestepsinsequence.
59Step1: Constructingtheregularityset . Define R2d m as
×
S S ⊆
S
= (cid:110) {x (cid:101)i,z
(cid:101)i
}im
=1
∈R2d ×m : m
i
[a mx ](cid:0) ∥x
(cid:101)i
∥2 2+ ∥z
(cid:101)i
∥2 2(cid:1) ≤Cd
∈
(cid:112) (cid:111)
, m
i
[a mx ]|x (cid:101)i⊤µ♯ |,m
i
[a mx ]|z (cid:101)i⊤ν♯
|
≤C logd , (170)
∈ ∈
whereCisalargeenoughuniversalconstant. Throughout,wewillusetheshorthand M = x,z m
{ i i }i=1
and M = x,z m . Thenextlemma,whoseproofwedefertoSectionD.1.1,establishesthebounded
′ { i′ i′ }i=1
differencespropertyontheregularityset .
S
Lemma16. Consider f (169)and (170). Thefollowingholds.
S
(a) 0 f(M) d , M R2d n.
≤ ≤ λm ∀ ∈ ×
(b) Thereexistsauniversal,positiveconstantC suchthatifλm d,then
0
≥
(cid:12) (cid:12)f(M) f(M′)(cid:12) (cid:12) C 0 log(d)/(λm) := ∆, for M,M′ suchthatρ(M,M′) 2.
− ≤ · ∈ S ≤
Step2:Truncation. LetD =1andnotethatbyLemma16(a),thissettingensuresD sup f(M)
≥ M | |
aslongasλm d. Wethendefinethefunction f :R2d m Ras ∈S
↓ ×
≥ →
(cid:110) (cid:111)
f↓(M) = inf f(M′)+∆ ρ(M,M′)+2D 1 ρ(M,M′) >1 , (172)
M · · { }
′∈S
where ∆ is as defined in Lemma 16. Applying Lemma 16 in conjunction with Lemma 18, we deduce
thatboth
f↓(M) = f(M), and f(M) f(M′) 2∆, (173)
| − | ≤
forall M , M R2d m whichsatisfyρ(M,M ) 1. Weemphasizethat M neednotbecontained
′ × ′ ′
∈ S ∈ ≤
intheregularityset forthistohold. Thefollowinglemmaestablishesthatwithhighprobability, M
is contained in the rS egularity set, and further, that to bound f(M) Ef(M) , it suffices to establish
| − |
deviationboundson f . WeprovidetheproofofLemma17inSectionD.1.2.
↓
Lemma17. ConsiderthesettingofLemma14andlet M = x,z m . Then,forallt 2d 24,thefollowing
{ i i }i=1 ≥ −
hold.
(a.) Pr M 1 d 25,and
−
{ ∈ S} ≥ −
(b.) Pr f(M) Ef(M) t Pr f (M) Ef (M) t/2 +d 25.
↓ ↓ −
{| − | ≥ } ≤ {| − | ≥ }
Step3: Puttingtogetherthepieces. Bydefinitionof f ,forany M R2d m and M ,
↓ × ′
∈ ∈ S
f↓(M) f(M′)+∆ρ(M,M′)+2D f(M′)+m∆+2≲ logd,
≤ ≤
wherethelaststepfollowsfrompartLemma16(a),whichensuresthat f(P ) 1since,byassumption,
′
λm dand(m+1)∆ ≲ mlogd/d logd. Then,forρ(M,M ) 1,weinvo≤ ketheinequality(173),to
′
≥ ≤ ≤
obtain
(cid:12) (cid:12) (cid:26) 2∆, if M ,
(cid:12)f↓(M)
−
f↓(M′)(cid:12)
≤
Clog(d),oth∈ erwS
ise.
Next,wesetγ = d 1,c = 2∆,d = Clog(d)foreachk [m],andapplyWarnke(2016,Theorem2)to
k − k k
∈
obtainthebound
Pr(cid:110)(cid:12) (cid:12)f↓(M) Ef↓(M)(cid:12) (cid:12) t/2(cid:111) 2exp(cid:26) −cd2t2 (cid:27) +2d−23.
− ≥ ≤ mlog2(d)
Combining the inequality in the display with Lemma 17 yields the first of the desired inequalities in
Lemma14. Proceedinginanidenticalfashionyieldsthesecond.
60D.1.1 ProofofLemma16
Weproveeachpartinturn.
Proofofpart(a): BytheblockmatrixinverseEq.(30),wenotethat
(cid:13) (cid:13)(cid:0) B −CD−1C⊤(cid:1) −1(cid:13) (cid:13) op ≤ (cid:13) (cid:13) (cid:13)(cid:16) i∑ =m 1a ia i⊤+λmI(cid:17) −1(cid:13) (cid:13) (cid:13) op ≤ (λm) −1.
Thedesiredresultimmediatelyfollowsbythedefinitionof f.
Proofofpart(b): Bythetriangleinequality,itsufficestoprove
f(M) f(M′) ∆/2 forall M,M′ suchthatρ(M,M′) 1. (174)
| − | ≤ ∈ S ≤
Towards establishing the above inequality, since ρ(M,M ) 1, we assume, without loss of general-
′
≤
ity, that (x i,z i) = (x i′,z i′) for 2
≤
i
≤
m. Continuing, let G
1′
= ⟨x 1′,µ♯ ⟩, G(cid:101)
1′
= ⟨z 1′ν♯
⟩
and (a 1′)
⊤
=
[G(cid:101) 1′(x 1′) ⊤O
u
|
G 1′(z 1′) ⊤O v]. Similarly, let (a i)
⊤
= [G(cid:101)i(x i) ⊤O
u
|
G i(z 1) ⊤O v] for i
∈
[m], and let
Σ = ∑m a a +λmI andΣ = Σ a a . WethenconsidermatricesB ,C ,andD whicharepertur-
i=1 i i⊤ 1 − 1 1⊤ 1 1 1
bationsofB,C,andD,definedas
B
1
= B −G(cid:101) 12O u⊤x 1(O u⊤x 1) ⊤, C
1
=C −G 1G(cid:101)1 ·O u⊤x 1(O v⊤z 1) ⊤, and
D
1
= D −G 12O v⊤z 1(O v⊤z 1) ⊤. (175)
Weadditionallyrecallthat,bytherelation(30d),
(cid:20) (B CD 1C ) 1 (B CD 1C ) 1CD 1(cid:21)
Σ −1 =
(D
C−
B
− 1C)⊤ 1C−
B 1
− (−
D
C− B⊤ 1C−
) 1
− .
⊤ − − ⊤ − ⊤ − −
− − −
Moreover, by the Sherman–Morrison formula, Σ −1 = Σ 1−1
−
Σ 11− +1 aa 1⊤1a Σ1⊤ 1−Σ 1a1− 11 . Combining this with the
previousdisplayandonlyusingthed dsubmatrixintheupperleftcorneryields
×
(B −CD−1C⊤) −1 = ( (cid:124)B 1 −C 1 (cid:123)D (cid:122)1−1C 1⊤) − (cid:125)1 −(cid:2)Σ 1−1(cid:3) [d 1],[2 +d] aa 1⊤1a Σ1⊤ 1−(cid:2) 1Σ a1− 11(cid:3) ⊤ [d],[2d] ,
P11
where(cid:2)Σ 1−1(cid:3)
[d],[2d] ∈
Rd ×2d isthesubmatrixofΣ 1−1 whichconsistsofthefirstdrows. Takingthetrace
ofbothsidesoftheequationinthedisplayaboveyields
f(M) =tr(P 11)
−
(cid:13) (cid:13)(cid:2) 1Σ +1−1 a(cid:3) [ 1⊤d] Σ,[2 1−d 1]a a1 1(cid:13) (cid:13)2 2 , and f(M′) =tr(P 11)
−
(cid:13) (cid:13) 1(cid:2) +Σ 1− (1 a(cid:3) 1′[d )] ⊤,[2 Σd 1−]a 11′ a(cid:13) (cid:13) 1′2 2 .
Thus,sinceΣ 0,wefindthat
1
⪰
(cid:12) (cid:12)f(M)
−
f(M′)(cid:12) (cid:12)
≤
(cid:13) (cid:13) (cid:13)(cid:2)Σ 1−1(cid:3) [d],[2d]a 1(cid:13) (cid:13) (cid:13)2 2+(cid:13) (cid:13) (cid:13)(cid:2)Σ 1−1(cid:3) [d],[2d]a 1′(cid:13) (cid:13) (cid:13)2 2.
Moreover,since ∥(cid:2)Σ 1−1(cid:3)
[d],[2d]∥2
≤
∥Σ 1−1
∥2
≤
(λm) −1,weobtaintheinequality
(cid:13) (cid:13) (cid:13)(cid:2)Σ 1−1(cid:3) [d],[2d]a 1(cid:13) (cid:13) (cid:13)2
2 ≤
G(cid:101) 12 ∥x 1 ∥ (2 2 λ+ m)G 212 ∥z 1 ∥2 2
≤
C ′l λo mg(d) ,
wherethelaststepfollowssinceM
∈ S
andλm
≥
d,sothat |G
1
|, |G(cid:101)1 |≲(cid:112) logd, ∥x
1
∥2 2,and ∥z
1
∥2
2
≲ d.
Similarly, since M
′ ∈
S, we obtain the bound (cid:13) (cid:13)(cid:2)Σ 1−1(cid:3) [d],[2d]a 1′(cid:13) (cid:13)2
2
≲ log(d)/(λm). Putting the pieces
togetheryields f(M) f(M ) ≲ log(d)/(λm),whichconcludestheproof.
′
| − |
61D.1.2 ProofofLemma17
Weproveeachpartinturn,beginningwithpart(a).
ProofofLemma17(a): WeinvokeVershynin(2018, Theorem3.1.1)toobtainthefollowingfourcon-
centrationinequalitiesforeachi [m],
∈
Pr(cid:8) ∥x
i
∥2
2
≥Cd(cid:9) ≤2d−30, Pr(cid:8) ∥z
i
∥2
2
≥Cd(cid:9) ≤2d−30, Pr(cid:8) |G
i |
≥C(cid:112) logd(cid:9) ≤2d−30
and Pr(cid:8) G(cid:101)i C(cid:112) logd(cid:9) 2d−30. (176)
| | ≥ ≤
Theconclusionfollowsuponapplyingtheunionbound.
ProofofLemma17(b): TheproofofthispartissimilartoSectionA.2. Wethusomitthestepswhich
areidentical,andrestrictourselvestothedifferences.
Itsufficestobound E f E f . Tothisend, bydefinitionofthefunction f , wefindthatfor
↓ ↓
any M R2d m and M| { } ,t− hefo{ llo} w| inginequalityholds
× ′
∈ ∈ S
f↓(M) f(M′)+∆ρ(M,M′)+2D f(M′)+m∆+2≲ logd.
≤ ≤
Above, the final inequality follows since by Lemma 16, f(M ) 1, as long as λm d and m∆ ≲
′
≤ ≥
mlogd/d logd. Consequently,webounditsexpectationas
≤
E f↓ =E f↓(M) 1 M +E f↓ 1 M /
{ } { · { ∈ S}} { · { ∈ S}}
(i)
E f(M) 1 M +Clog(d) E 1 M / E f(M) +d−24,
≤ { · { ∈ S}} · { { ∈ S}} ≤ { }
wherestep(i)followsfromtheinequality(173)aswellassince f and f agreeon . Similarly,
↓
S
E f =E f(M) 1 M +E f(M) 1 M /
{ } { · { ∈ S}} { · { ∈ S}}
(i)
E f↓(M) +E 1 M / E f↓ +d−25,
≤ { } { { ∈ S}} ≤ { }
wherestep(i)followssince f and f agreeon ,andas f 1byLemma16(a)forλm d. Puttingthe
↓
piecestogetheryields(cid:12) (cid:12)E f E f ↓ (cid:12) (cid:12) d −24.S Thedesired≤ resultthenfollowsbyproce≥ edingsimilarly
{ }− { } ≤
asinSectionA.2.
D.2 ProofofLemma15
Consider B 1,C 1,D
1
as defined in (175) and recall the shorthand G
i
= x i⊤µ♯ and G(cid:101)i = z i⊤ν♯. Further
define the leave one out quantities x¯
i
= O u⊤x i, z¯
i
= O v⊤z
i
and a
i⊤
= [G(cid:101)ix¯ i⊤G iz¯ i⊤]. A straightforward
calculationyields
I
2d −2
=E(cid:8)Σ −1Σ(cid:9) =E(cid:110) Σ −1(cid:16) i∑ =m 1a ia i⊤+λmI
2d
−2(cid:17)(cid:111) = m ·E(cid:8)Σ −1a 1a 1⊤(cid:9) +λm ·E(cid:8)Σ −1(cid:9)
= m ·E(cid:26) 1+Σ 1− a1 1⊤a Σ1a 1−1⊤
1a
1(cid:27) +λm ·E(cid:8)Σ −1(cid:9) , (177)
wherethelaststepfollowsfromtheSherman–Morrisonformula. Next,definethethreematricesP =
11
(B
1
−C 1D 1−1C 1⊤) −1, P
12
= −P 11C 1D 1−1, and P
22
= (D
1
−C 1⊤B 1−1C 1) −1 and apply the block matrix
inversionformulatoobtain
(cid:20) (cid:21) 1 (cid:20) (cid:21)
Σ 1−1 = CB 1 DC 1 − = P P11 P P12 . (178)
1⊤ 1 1⊤2 22
62CombiningEqs.(177)and(178)yieldsthepairofrelations
I
d −1
= m ·E(cid:26) G(cid:101) 12P 11x¯ 11x¯ +1⊤ a+ 1⊤G Σ1 1−G(cid:101) 1a1P 112z¯ 1x¯ 1⊤(cid:27) +λm ·E(cid:8) (B −CD−1C⊤) −1(cid:9)
I
d −1
= m ·E(cid:26) G 12P 22z¯ 11z¯ +1⊤ a+ 1⊤G Σ1 1−G(cid:101) 1a1P 11⊤2x¯ 1z¯ 1⊤(cid:27) +λm ·E(cid:8) (D −C⊤B−1C) −1(cid:9) .
Takingthetraceofbothsidesofeachrelationaboveyields
d − m1 =E(cid:26) G(cid:101) 12x¯ 1⊤P 1 11 +x¯ 1 a+ 1⊤G Σ1 1−G(cid:101) 1a1x 1¯ 1⊤P 12z¯ 1(cid:27) +λ ·E(cid:8) tr(cid:0) (B −CD−1C⊤) −1(cid:1)(cid:9) , (179a)
(cid:124) (cid:123)(cid:122) (cid:125)
Ω
1
d − m1 =E(cid:26) G 12z¯ 1⊤P 2 12 +z¯ 1 a+ 1⊤G Σ1 1−G(cid:101) 1a1z 1¯ 1⊤P 1⊤2x¯ 1(cid:27) +λ ·E(cid:8)(cid:0) tr(D −C⊤B−1C) −1(cid:1)(cid:9) . (179b)
(cid:124) (cid:123)(cid:122) (cid:125)
Ω
2
Wethendefineτ andτ(cid:101)asτ =
E(cid:8) tr(cid:0)
(B CD −1C ⊤)
−1(cid:1)(cid:9)
andτ(cid:101)=
E(cid:8)(cid:0)
tr(D C ⊤B −1C)
−1(cid:1)(cid:9)
,respec-
− −
tively,andusethesetodefinethescalars
Ω
=E(cid:110) G(cid:101) 12τ (cid:111)
and Ω
=E(cid:110) G 12τ(cid:101) (cid:111)
.
1 2
1+G(cid:101) 12τ+G 12τ(cid:101) 1+G(cid:101) 12τ+G 12τ(cid:101)
We next make the following claim—deferring its proof to the end—which shows that Ω Ω and
1 1
Ω Ω ≈
2 2
≈
(cid:12) (cid:12)Ω 1 −Ω 1(cid:12) (cid:12)
∨
(cid:12) (cid:12)Ω 2 −Ω 2(cid:12) (cid:12)≲ log √1.5 d(d) . (180)
Wethendefinethescalarsω andω as
1 2
ω
=E(cid:26) G(cid:101) 12r 1−1 (cid:27)
and ω
=E(cid:26) G 12r 2−1 (cid:27)
,
1 1+G 12r 2−1+G(cid:101) 12r 1−1 2 1+G 12r 2−1+G(cid:101) 12r 1−1
andcomparethefixedpointequation(32)withequation(179),toobtainthepair
1 1
m
+Ω 1+λ ·τ = ω 1+λ ·r 1−1 and
m
+Ω 2+λ ·τ(cid:101)= ω 2+λ ·r 2−1.
Combiningthepairofequationsintheprecedingdisplaywiththeinequality(180)yields
(cid:12) (cid:12)ω 1+λ ·r 1−1 −(cid:0)Ω 1+λ ·τ(cid:1)(cid:12) (cid:12)
∨
(cid:12) (cid:12)ω 2+λ ·r 2−1 −(cid:0)Ω 2+λ ·τ(cid:101)(cid:1)(cid:12) (cid:12)≲ log √1.5 d(d) + m1 . (181)
Then,bythetriangleinequality,
(cid:12) (cid:12)ω 1 −Ω 1(cid:12) (cid:12)
∨
(cid:12) (cid:12)ω 2 −Ω 2(cid:12) (cid:12) ≤C ·|τ −r 1−1 |+C ·|τ(cid:101) −r 2−1
|
Applyingthetriangleinequalityinconjunctionwiththeinequalityinthedisplayaboveyieldsboth
(cid:12) (cid:12)ω 1+λ ·r 1−1 −(cid:0)Ω 1+λ ·τ(cid:1)(cid:12) (cid:12)
≥
(λ −C) ·|τ −r 1−1 |−C ·|τ(cid:101) −r 2−1 |, and
(cid:12) (cid:12)ω 2+λ ·r 2−1 −(cid:0)Ω 2+λ ·τ(cid:101)(cid:1)(cid:12) (cid:12)
≥
(λ −C) ·|τ(cid:101) −r 2−1 |−C ·|τ −r 1−1 |.
Wenextcombinethispairofinequalitieswiththeinequality(181)toobtain
log1.5(d) 1
(λ −C) ·|τ −r 1−1 |−C ·|τ(cid:101) −r 2−1
| ∨
(λ −C) ·|τ(cid:101) −r 2−1 |−C ·|τ −r 1−1 |≲
√d
+ m.
Consequently,aslongasλ 10Cd/m 10C,weconcludethat
≥ ≥
log1.5(d)
|τ −r 1−1 |, |τ(cid:101) −r 2−1 |≲ log1.5(d)(λ√d)+(λm) −1 ≲
√d
,
asdesired. Itremainstoprovetheinequality(180).
63Proofoftheinequality(180): WefirstexpandΣ 1−1toobtaintheexpression
a 1⊤Σ 1−1a
1
= G(cid:101) 12x¯ 1⊤P 11x¯ 1+G 12z¯ 1⊤P 22z¯ 1+2G 1G(cid:101)1x¯ 1⊤P 12z¯ 1.
Then,applyingthetriangleyieldsthebound
(cid:12) (cid:12)
(cid:12)
(cid:12)E(cid:26) G(cid:101) 12x¯ 1⊤P 1 11 +x¯ 1 a+ 1⊤G Σ1 1−G(cid:101) 1a1x 1¯ 1⊤P 12z¯ 1(cid:27) −E(cid:26)
1+G(cid:101) 12x¯
1⊤G(cid:101) P12 1x 1¯ 1 x¯⊤ 1P +11 Gx¯ 1
12z¯ 1⊤P 22z¯
1(cid:27)(cid:12) (cid:12)
(cid:12)
(cid:12)
≤3E(cid:8)(cid:12)
(cid:12)G 1G(cid:101)1x¯ 1⊤P 12z¯
1(cid:12) (cid:12)(cid:9)
,
therighthandsideofwhichwefurtherboundbyapplyingtheCauchy-Schwarzinequalitytoobtain
(cid:113) (cid:113)
E(cid:8)(cid:12) (cid:12)G 1G(cid:101)1x¯ 1⊤P 12z¯ 1(cid:12) (cid:12)(cid:9)
≤
E {G 12G(cid:101) 12
}·
E {(x¯ 1⊤P 12z¯ 1)2 }.
ExplicitevaluationthenyieldstheupperboundE G2G(cid:101)2 ≲ 1. Moreover,
{ 1 1}
(i) (ii)
E {(x¯ 1⊤P 12z¯ 1)2
}
=E {∥P 12z¯
1
∥2
2}
≤E {∥P
12
∥2 2}·E {∥z¯
1
∥2
2} ≤
d/(λm)2
where step (i) follows by exploiting the independence between P and z¯ and step (ii) follows from
12 1
thepairofinequalities ∥P
12 ∥2 ≤
∥Σ 1−1
∥2
≤1/(λm)andE {∥z¯
1
∥2
2} ≤
d. Puttingthepiecestogetherand
invokingtheassumptionλm dyields
≥
(cid:12) (cid:12) (cid:12)E(cid:26) G(cid:101) 12x¯ 1⊤P 11x¯ 1+G 1G(cid:101)1x¯ 1⊤P 12z¯ 1(cid:27) E(cid:26) G(cid:101) 12x¯ 1⊤P 11x¯ 1 (cid:27)(cid:12) (cid:12) (cid:12)≲ 1
. (182)
(cid:12) 1+a 1⊤Σ 1−1a
1
− 1+G(cid:101) 12x¯ 1⊤P 11x¯ 1+G 12z¯ 1⊤P 22z¯
1
(cid:12) √d
Wethenclaimthefollowingpairofinequalities,postponingtheirprooftotheendofthesection
3 3
E {|x¯ 1⊤P 11x¯
1
−τ |}≲ log √2 d(d) and E {|z¯ 1⊤P 22z¯
1
−τ(cid:101) |}≲ log √2 d(d) . (183)
Combiningtheinequalities(182),(183)andthetriangleinequalityfinallyyieldsthebound
(cid:12) (cid:12) (cid:12)E(cid:26) G(cid:101) 12x¯ 1⊤P 11x¯ 1+G 1G(cid:101)1x¯ 1⊤P 12z¯ 1(cid:27) E(cid:26) G(cid:101) 12τ (cid:27)(cid:12) (cid:12) (cid:12)≲ log3 2(d)
,
(cid:12) 1+a 1⊤Σ 1−1a
1
− 1+G(cid:101) 12τ+G 12τ(cid:101) (cid:12) √d
whichprovesoneofthepairofinequalitiesin(180).Theremaininginequalityadmitsanidenticalproof.
Weturnnowtoestablishingtheinequality(183)
Proofofinequality(183):Weusetheshorthandτ
1
=E(cid:8) tr(cid:0) (B
1
−C 1D 1−1C 1⊤) −1(cid:1)(cid:9) andτ(cid:101)1 =E(cid:8) tr(cid:0) (D
1
−
C 1⊤B 1−1C 1) −1(cid:1)(cid:9) . Wethenapplythetriangleinequalitytoobtainthedecomposition
(cid:12) (cid:12)
|x 1⊤P 11x
1
−τ
| ≤
(cid:12)x 1⊤P 11x
1
−tr(P 11)(cid:12)+ |tr(P 11) −τ
1
|+ |τ
1
−τ |,
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T1 T2 T3
and proceed to bound the expectation ofeach of T ,T , and T inturn, startingwith E T . Towards
1 2 3 1
{ }
boundingT ,wenotethat P 2 d 1 and P 1 .Then,weapplytheHanson–Wright
1 ∥ 11 ∥F ≤ (λm)2 ≤ λm ∥ 11 ∥op ≤ λm
inequality to obtain the inequality Pr T t 2exp cλmmin(t2,t) for all t 0. Consequently,
1
weintegratethetailtoobtaintheexpe{ ctat≥ ion} bo≤ undE { T− ≲(λm) 1/2 } d 1/2. ≥
1 − −
{ } ≤
TurningtoboundingE T ,wetakeCtodenotealargeenoughconstantandsetδ =Clog3/2(d)d 1/2.
2 −
We then consider the deco{ mp} osition E T = E T 1 T δ +E T 1 T > δ , noting that
2 2 2 2 2
E T 1 T δ δ. On the other h{ and} , an a{ ppli· cat{ ion o≤ f th} e} Cauc{ hy–· Sch{ warz in} e} quality yields
2 2
E{ (cid:8) T · 1{ T ≤ > δ} (cid:9)} ≤ (cid:113) E T2 (cid:112)E 1 T > δ . Then, using the inequality P (λm) 1, we
2 · { 2 } ≤ { 2}· { { 2 }} ∥ 11 ∥op ≤ −
obtainthebound
(cid:16) d (cid:17)2
E T2 E tr(P )2 1,
{ 2} ≤ { 11 } ≤ λm ≤
64wherethefinalinequalityfollowsbyassumption. Moreover,byLemma14,Notethat
E 1 T
2
> δ Pr trP
11
E trP
11
δ d−18,
{ { }} ≤ {| − { }| ≥ } ≤
AssemblingthepiecesyieldstheultimateboundE T ≲ log3/2(d)/√d.
2
{ }
TowardsboundingT ,weapplytheSherman–Morrisonformulatoobtain
3
Σ −1 = (cid:0) a 1a 1⊤+Σ 1−1(cid:1) −1 = Σ 1−1
−
Σ 11− +1 aa 1⊤1a Σ1⊤ 1−Σ 11−
a
11 .
Focusingonthe d d submatricesintheupperleftofbothsidesoftheprecedingequationyieldsthe
×
relation
(cid:0) (cid:1)(cid:0) (cid:1)
(cid:0) B −CD−1C⊤(cid:1) −1 = (cid:0) B
1
−C 1D 1−1C 1⊤(cid:1) −1
−
G(cid:101)1P 11x¯ 1+G 1P 112 +z¯ 1
a
1⊤ΣG(cid:101) 1−1P 11 a1 1x¯ 1+G 1P 12z¯ 1 ⊤
Wethentakethetraceofbothsidesandre-arrangetermstoobtainthebound
(cid:12) (cid:12) (cid:12)tr(cid:0)(cid:0) B −CD−1C⊤(cid:1) −1(cid:1) −tr(cid:0)(cid:0) B
1
−C 1D 1−1C 1⊤(cid:1) −1(cid:1)(cid:12) (cid:12)
(cid:12)
≤
(cid:13) (cid:13)G(cid:101)1P 11x¯ 1+G 1P 12z¯ 1(cid:13) (cid:13)2 2,
wherewehaveadditionallyusedthefactthatΣ 0. Consequently,wededucethebound
1
⪰
E {T
3 }
≤E(cid:8)(cid:13) (cid:13)G(cid:101)1P 11x¯ 1+G 1P 12z¯ 1(cid:13) (cid:13)2 2(cid:9)≲ (λmd
)2 ≤
d−1/2,
where in the last step we have used the bounds P , P (λm) 1. Collecting the bounds on
11 2 12 2 −
ET ,ET ,andET yields ∥ ∥ ∥ ∥ ≤
1 2 3
3
E(cid:8)
|x¯ 1⊤P 11x¯ −τ
|(cid:9)≲ log √2 d(d)
.
Theproofofthesecondinequalityisidenticalandwethusomitit.
E Auxiliary lemmas
Lemma18. Let f : Rd m R. DefinetheHammingmetric ρ : Rd m Rd m [m] suchthatif M,M
× × × ′
differinexactlykcolumnsth→ enρ(M,M ) = k. Let Rd m andsuppo× sethereex→ istssome∆ 0suchthat
′ ×
S ⊆ ≥
forall M,M whichsatisfyρ(M,M ) 2
′ ′
∈ S ≤
f(M) f(M′) ∆. (184)
| − | ≤
LetD RsuchthatD sup f(M) anddefine f :Rd m Ras
∈ ≥ M | | ↓ × →
∈S
(cid:110) (cid:111)
f↓(M) = inf f(M′)+∆ ρ(M,M′)+2D 1 ρ(M,M′) >1 . (185)
M · · { }
′∈S
Then,forany M and M Rd m suchthatρ(M,M ) 1,both
′ × ′
∈ S ∈ ≤
f↓(M) = f(M) and f↓(M) f↓(M′) ∆.
| − | ≤
Proof. First note that, by definition, f (M) f(M) for M . For any M , by the assump-
↓ ′′
≤ ∈ S ∈ S
tion(184)andthedefinitionofD,wenotetheinequality
f(M′′)+∆ ρ(M,M′′)+2D 1 ρ(M,M′′) >1 f(M).
· · { ≥
Consequently,weobtainthat f (M) f(M)for M bythedefinitionof f . Wethusconcludethat
↓ ↓
≥ ∈ S
f(M) = f (M)for M .
↓
∈ S
65Next,let M Rd m,M andρ(M,M ) 1. If M ,thenweinvoketheassumption(184)to
′ × ′ ′
∈ ∈ S ≤ ∈ S
obtainthebound
f↓(M) f↓(M′) = f(M) f(M′) ∆.
| − | | − | ≤
Now,consider M / . Notethatbythedefinitionof f ,
′ ↓
∈ S
f↓(M′) f(M)+∆ = f↓(M)+∆. (186)
≤
Weclaimthat f (M ) f (M). Toseethis,notethatforany M ,ρ(M ,M ) 1since M / . If
↓ ′ ↓ ′′ ′ ′′ ′
≥ ∈ S ≥ ∈ S
ρ(M ,M ) >1then
′ ′′
f(M′′)+∆ ρ(M′,M′′)+2D 1 ρ(M′,M′′) >1 f(M′′)+2D f(M) = f↓(M).
· · { } ≥ ≥
Otherwiseρ(M ,M ) =1. Consequently,
′ ′′
(i)
f(M′′)+∆ ρ(M′,M′′)+2D 1 ρ(M′,M′′) >1 = f(M′′)+∆ f(M) = f↓(M),
· · { } ≥
wherestep(i)followsfromassumption(184)andthefactthatρ(M,M ) ρ(M,M )+ρ(M ,M ) 2.
′′ ′ ′ ′′
≤ ≤
Consequently,puttingthetwocasestogetheryields
(cid:110) (cid:111)
f↓(M′) = inf f(M′′)+∆ ρ(M′,M′′)+2D 1 ρ(M′,M′′) >1 f↓(M),
M · · { } ≥
′′∈S
asdesired. Combiningthebound f (M ) f (M)withtheinequality(186)yields
↓ ′ ↓
≥
f↓(M) f↓(M′) ∆ for ρ(M,M′) 1and M ,
| − | ≤ ≤ ∈ S
asdesired.
Lemma 19. Recall the definitions of fixed point equations (32), (37a) and (37b), and G N(0,L2), G
1 2
∼ ∼
N(0,(cid:101)L2) areindependent. ThereexistsauniversalpositiveconstantC suchthatif λ Cmax 1,L4,(cid:101)L4 d/m
≥ { }
thenthefollowingholds.
(a.) Fixed point equation (32) has a unique positive solution (r ,r ), and r ,r λm/d. Moreover, if λ
1 2 1 2
≥ ≥
max 1,L2,(cid:101)L2 thenr 1,r
2
2λm/d.
{ } ≤
(b.) Fixedpointequations(37a)and(37b)haveaunique,nonnegativesolution.
(c.) RecallthatErr ♯ = (α♯(cid:101)α♯ −1)2+β2 ♯+β(cid:101)2 ♯. Ifβ♯,β(cid:101)♯ ≤0.1and0.3
≤
∥µ♯ ∥2, ∥ν♯ ∥2 ≤1.7,thenwehave
1
5 ·∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F ≤Err ♯ ≤12.5 ·∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F.
Proof. Weproveeachiteminturn.
Proof of Lemma 19(a.): We first show that fixed point equation (32) has a unique solution in the set
= (r ,r ) :r ,r λm/d . Tothisend,wereformulateequation(32)as
1 2 1 2
S { ≥ }
 
(cid:20) (cid:21) E(cid:8) r1r2G 22 (cid:9) +λ
r 1 = g(r ,r ), where g(r ,r ) = Λ  r1r2+r1G 12+r2G 22  (187)
r
2
1 2 1 2 · E(cid:8) r1r2G 12 (cid:9)
+λ

r1r2+r1G 12+r2G 22
Bythecontractionmappingtheorem,itsufficestoshow:
(a) Set = (r ,r ) :r ,r λm/d isaclosedset;
1 2 1 2
S { ≥ }
(b) Forall(r ,r ) ,wehaveg(r ,r ) ;
1 2 1 2
∈ S ∈ S
(c) Thereexistsq <1suchthattheJacobiansatisfies g(r ,r ) qforall(r ,r ) .
1 2 1 1 2
∥∇ ∥ ≤ ∈ S
66Notethat thefirst pointis true. For thesecondpoint, if r ,r 0, then clearly g(r ,r ) sincethe
1 2 1 2
≥ ∈ S
expectationsinEq.(187)arenon-negative. Wenextverifythethirdpoint. ComputingtheJacobianofg
yields
 
E(cid:8) r 22G 24 (cid:9) E(cid:8) r1r2G 12G 22 (cid:9)
g(r ,r ) = Λ  (r1r2+r1G 12+r2G 22)2 (r1r2+r1G 12+r2G 22)2 .
∇ 1 2 · E(cid:8) r1r2G 12G 22 (cid:9) E(cid:8) r 12G 14 (cid:9) 
(r1r2+r1G 12+r2G 22)2 (r1r2+r1G 12+r2G 22)2
Wethuscompute
(cid:26) r2G4+2r r G2G2+r2G4(cid:27)
g(r ,r ) = Λ E 2 2 1 2 1 2 1 1
∥∇ 1 2 ∥1 · (r r +r G2+r G2)2
1 2 1 1 2 2
Λ
r 22E {G 24 }+2r 1r 2E {G 12 }E {G 22 }+r 12E {G 14
}
(i) 3(cid:101)L4+2L2(cid:101)L2+3L4
<0.5,
≤ · (r r )2 ≤ λ2Λ
1 2
where step (i) follows from the bounds r ,r λm/d = λΛ, and the facts that G N(0,L2) and
1 2 1
≥ ∼
G
2
N(0,(cid:101)L2); and last step follows from the bound λ Cmax L4,(cid:101)L4 Λ with C a large enough
∼ ≥ { }
constant. Takingstock,wehaveshowedthatfixedpointequation(32)hasauniquesolutionintheset
= (r ,r ) :r ,r λm/d .
1 2 1 2
S { ≥ }
Next, if fixed point equation (32) admits a non-negative solution r ,r 0, then since the expec-
1 2
tations in Eq. (32) are non-negative, we obtain that r ,r λΛ = λm/d, s≥ o that r ,r must be in .
1 2 1 2
≥ S
Therefore,weconcludethatfixedpointequation(32)hasaunique,non-negativesolutionr ,r 0.
1 2
≥
Finally,notethat
(cid:110) r r G2 (cid:111) (cid:110) r r G2 (cid:111)
E 1 2 2 E G2 =(cid:101)L2 and E 1 2 1 L2.
r r +r G2+r G2 ≤ { 2} r r +r G2+r G2 ≤
1 2 1 1 2 2 1 2 1 1 2 2
Consequently,ifλ max L2,(cid:101)L2 ,thenfromEq.(187),weobtainthatr
1
Λ(λ+(cid:101)L2) 2λΛ =2λm/d
≥ { } ≤ ≤
andsimilarlyr 2λm/d,whichconcludestheproofofpart(a).
2
≤
ProofofLemma19(b.): Toreducethenotationalburden,weusetheshorthand
(cid:110) (d −2)m r2G4 (cid:111) (cid:110) (d −2)m r2G2G2 (cid:111)
a =1 E d2 2 2 , a =E − d2 2 1 2 ,
− (r r +r G2+r G2)2 2 (r r +r G2+r G2)2
1 2 1 1 2 2 1 2 1 1 2 2
(cid:110) (d −2)m r2G2G2 (cid:111) (cid:110) (d −2)m r2G4 (cid:111)
a =E − d2 1 1 2 , and a =1 E d2 1 1 .
3 (r r +r G2+r G2)2 4 − (r r +r G2+r G2)2
1 2 1 1 2 2 1 2 1 1 2 2
Equippedwiththisnotation,werecallV (35)andV (36),andre-writethefixedpointequations(37a)
3 4
and(37b)as
(cid:20) a a (cid:21)(cid:20) η2 (cid:21) (d 2)m (cid:20) V (cid:21)
1 2 = − 3 .
a
3
a
4
η (cid:101)2 d2 V
4
The linear equation in the preceding display admits a unique solution if and only if the determinant
a a a a =0. Notethat
1 4 2 3
− ̸
mE G4 3(cid:101)L4 mL2(cid:101)L2 L2(cid:101)L2
a 1 { 2} 1 0.9 and a 0.1,
1 ≥ − d r2 ≥ − λ2m/d ≥ | 2 | ≤ d r2 ≤ λ2m/d ≤
1 1
since r 1,r
2
λm/d and λ Cmax 1,L4,(cid:101)L4 d/m. Similarly, we find that a
4
0.9 and a
3
0.1.
≥ ≥ { } ≥ | | ≤
Consequently,a a a a 0.92 0.12 >0,sothatthesolutionofequations(37a)and(37b)isunique.
1 4 2 3
− ≥ −
Moreover,solvingthelinearequationyields
(d 2)ma V a V (d 2)ma V a V
η2 = − 4 3 − 2 4 and η2 = − 1 3 − 3 4 .
d2 a a a a (cid:101) d2 a a a a
1 4 2 3 1 4 2 3
− −
Sincea ,a 0.9,a ,a 0andV ,V 0,weobtainthatthesolutionisnon-negative.
1 4 2 3 3 4
≥ ≤ ≥
67ProofofLemma19(c.): Bydefinitionwehave
∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F = ∥µ♯ν ♯⊤ ∥2 F−2 ⟨µ♯ν ♯⊤,µ⋆ν ⋆⊤ ⟩+ ∥µ⋆ν ⋆⊤ ∥2 F = (α♯(cid:101)α♯ −1)2+α2 ♯β(cid:101)2 ♯+ (cid:101)α2 ♯β2 ♯+β2 ♯β(cid:101)2 ♯.
Usingβ♯ 0.1, α♯ µ♯
2
1.7and (cid:101)α♯ ν♯
2
1.7,weobtainthat
≤ | | ≤ ∥ ∥ ≤ | | ≤ ∥ ∥ ≤
∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F ≤ (1.72+0.1) ·(cid:2) (α♯(cid:101)α♯ −1)2+β2 ♯+β(cid:101)2 ♯(cid:3) ≤5 ·Err ♯.
Continuing,notethatα2
♯
= ∥µ♯ ∥2 2−β2
♯
≥0.32 −0.12 =0.08andsimilarly (cid:101)α2
♯
≥0.08. Thus,
∥µ♯ν ♯⊤ −µ⋆ν ⋆⊤ ∥2 F ≥0.08(cid:2) (α♯(cid:101)α♯ −1)2+β2 ♯+β(cid:101)2 ♯(cid:3) ≥0.08Err ♯.
Puttingthepiecestogetheryieldsthedesiredresult.
68