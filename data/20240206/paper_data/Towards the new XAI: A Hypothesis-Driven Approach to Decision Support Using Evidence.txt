TowardsthenewXAI:AHypothesis-DrivenApproachtoDecisionSupportUsing
Evidence
THAOLE,SchoolofComputingandInformationSystems,TheUniversityofMelbourne,Australia
TIMMILLER,SchoolofElectricalEngineeringandComputerScience,TheUniversityofQueensland,Australia
RONALSINGH,CSIRO’sData61,Australia
LIZSONENBERG,SchoolofComputingandInformationSystems,TheUniversityofMelbourne,Australia
PriorresearchonAI-assistedhumandecision-makinghasexploredseveraldifferentexplainableAI(XAI)approaches.Arecentpaper
hasproposedaparadigmshiftcallingforhypothesis-drivenXAIthroughaconceptualframeworkcalledevaluativeAIthatgivespeople
evidencethatsupportsorrefuteshypotheseswithoutnecessarilygivingadecision-aidrecommendation.Inthispaperwedescribeand
evaluateanapproachforhypothesis-drivenXAIbasedontheWeightofEvidence(WoE)framework,whichgeneratesbothpositive
andnegativeevidenceforagivenhypothesis.Throughhumanbehaviouralexperiments,weshowthatourhypothesis-drivenapproach
increasesdecisionaccuracy,reducesreliancecomparedtoarecommendation-drivenapproachandanAI-explanation-onlybaseline,
butwithasmallincreaseinunder-reliancecomparedtotherecommendation-drivenapproach.Further,weshowthatparticipants
usedourhypothesis-drivenapproachinamateriallydifferentwaytothetwobaselines.
CCSConcepts:•Computingmethodologies→Artificialintelligence;•Human-centeredcomputing→HCItheory,concepts
andmodels.
AdditionalKeyWordsandPhrases:XAI,decision-making,hypothesis-driven,evidence,evaluativeAI
1 INTRODUCTION
ResearchhasshownthatAIrecommendations,evenwhenaccompaniedwithexplanations,arenotalwayshelpfulin
supportingdecision-making[4,6,15,36].Thedirectcausesofthisareunder-relianceandover-reliance[35].Withunder-
reliance,decision-makersrejectAIrecommendations,evenwhentheymaybecorrect.Alternatively,decision-makers
mayoverlyrelyonAIrecommendations,hencebeledtoerrorswhentheAIisincorrect.Ineithercase,theytendto
fixateonaparticularhypothesiswithoutsufficientlyconsideringothers[25].Approachessuchascognitiveforcing,
basedonideasfromhumanpsychology,havebeenproposedtoaddresslimitationsoftheAIrecommendationapproach
[6],withrecentworkindictingthatwithholdingAImodeltherecommendations,atleastforashorttime,whilestill
providingtheuserwithanexplanationofthatrecommendation,canbehelpful[15].Recently,Miller[25]proposeda
so-scalledhypothesis-drivendecision-makingparadigmcalledevaluativeAI.Themainaimofthisparadigmisto
focusthedecisionlooponthehumandecisionmaker,providingthemwiththerightevidencetosupporttheirown
intuitions,ratherthanfocusingthedecisionlooponmachinerecommendations.Thisparadigmoffersapromising
directioninbuildingbetterdecisionsupportinexplainableAI(XAI)researchbyfocusingonhumandecisionmakers
consideringmultiplepossiblehypotheses.
Inthispaper,wedescribeandevaluateanapproachforbuildingahypothesis-drivendecision-makingmodelthat
usestheWeightofEvidence(WoE)framework[2].Ourcontributionsare:
• TheEvidence-InformedHypothesis-DrivenDecisionMakingmodel,buildingontheWeightofEvidence(WoE)
frameworktothehypothesis-drivenapproach.
• Asetofhumanbehaviouralexperimentscomparingourhypothesis-drivenapproachwithtwocommondecision-
aidapproaches:(1)thestandardmodelrecommendationwithexplanation;and(2)adesignusingaformof
cognitiveforcingbyprovidingonlyAIexplanations[15].Theresultsshowthathypothesis-drivenapproach
1
4202
beF
2
]IA.sc[
1v29210.2042:viXraLe,etal.
significantlyreducesover-reliancecomparedtostandardrecommendation-drivenapproaches,atthecostof
aslightincreaseinunder-reliance.Furthermore,thehypothesis-drivenreducesunder-reliancesignificantly
comparedtotheAI-explanation-only.Moreover,ourqualitativeanalysisidentifiessomelimitationsandchal-
lengesinthethreedecision-makingapproaches,butalsoshowsthatparticipantsusedthehypothesis-driven
approachinamateriallydifferentwaythantherecommendation-drivenorAI-explanation-onlyconditions,
withparticipantsfocusingmoreontheevidencethanontheirownbackgroundknowledge.
2 BACKGROUNDANDRELATEDWORK
Inthissection,wegiveabriefoverviewofrelatedworkoncommonAI-assisteddecision-makingparadigms.Furthermore,
wehighlightkeyliteratureaboutapplyingexplainableAIinsupportingdecision-making.
2.1 AI-AssistedDecisionMakingParadigms
Intheliterature,therearetwoworkflowsthatareoftenusedinAI-assisteddecision-making:(1)AI-firstdecision-making;
and(2)human-firstdecision-making.AI-firstworkflowprovidestheAIrecommendationfirstandthenhumansdecide
iftheywanttoacceptornottherecommendation,whereashuman-firstdecision-makingrequireshumanstomakea
provisionaldecisionbeforetheyareprovidedwithanyAIrecommendations.
2.1.1 AI-firstWorkflow. IntheAI-firstdecision-makingworkflow,ithasbeendemonstratedthatparticipantsfeel
moreconfidentandarealsofasterindecision-making[13].TheseparticipantsalsoratedAIasmorepractical.In
termsoflimitations,theanchoringeffectisreportedtooccurmoreoftenintheAI-firstworkflow[6,13,27]inwhich
peopleoverlyrelyontheAIrecommendation(alsocalledover-reliance).Anchoringeffect[32]referstogivingstronger
preferencetotheearlierknowledgeratherthandoingafullrevisionandconsideringthelatestevidence.Bycontrast,
Fogliatoetal.[14]didnotfindanysignificantdifferenceintheparticipants’performance,whichismeasuredby
accuracybetweenthetwoworkflows(AI-firstandhuman-first).However,theyalsofoundthatparticipantsare65%
morelikelytorevisetheiranswersinthehuman-firstsettingthanthoseintheAI-firstsetting.
2.1.2 Human-firstWorkflow. Human-firstdecisionworkflowhasbeenshowntohelpreducetherelianceonerroneous
AIrecommendations[6,13].However,expertsmayinteractwithdecision-makingsystemsdifferentlyfromlaypeople
(crowdworkers).Forexample,Fogliatoetal.[13],Gaubeetal.[16]ranstudieswithradiologistswhoweretheexperts.
Theirtaskistoreviewpatients’X-rayimages.Thestudiesconcludethatinhuman-firstworkflowwithexpertparticipants,
theyarelesslikelytoleverageAIadviceeventhoughtheAIismoreaccurate.Infact,thisisreferredtoalgorithm
aversion[12]orunder-reliance.
Ahuman-firstparadigmcalledcognitiveforcing,basedonearlierideasinpsychologyforinterventionsthatelicit
humanthinkingatdecision-makingtime[22],hasbeenproposedasawaytoimproveusers’engagementandalso
increasetheirlearningwheninteractingwiththeAI[6,15].Fourcognitiveforcingdesignshavebeenintroduced:(1)
Ondemand:ParticipantscanonlyseetheAIrecommendationwhentheyrequestit;(2)Update:Participantsfirstmade
adecisionwithoutseeingtheAIrecommendation.Then,theywereshowntheAIpredictionandcouldupdatetheir
decisionlater;(3)Wait:Participantshadtowaitfor30secondsbeforetheAIdecisionwasshown;and(4)OnlyAI
explanation:ProvidingjusttheAIexplanationandnoAIrecommendation,onthebasisthatthismayhelppeopleprocess
theAIexplanationmorecarefullyandtherefore,improvetheirknowledgeandmakebetterdecisions[15].Importantly,
cognitiveforcinghasbeenshowntoreduceover-reliancecomparedtothestandardAIsuggestionapproach,although
APreprint 2TowardsthenewXAI:AHypothesis-drivenApproach
thatstudyhadalimitationinthattheAIpredictionwasalwayscorrect.Therearealsosomerecognisedtrade-offsof
cognitiveforcingdesigns:moretime-consuming[15],andlesstrust[6].
2.1.3 EvaluativeAI(Hypothesis-driven)Paradigm. Miller[25]arguesthatAI-assisteddecisionsupportisonthecuspof
aparadigmshift.Thisshiftisawayfromtheideaofhuman-firstorAI-first,andintoaframeworkhecallsevaluative
AI.ThekeyinsightofevaluativeAIistonotnecessarilyprovidearecommendation,andinsteadtosupportthehuman
cognitivedecision-makingprocessbyprovidingevidencethatsupportsoragainsttheparticularhypothesisthata
humandecisionmakerisconsidering.Millerarguesthatthiswouldhelptopreventover-andunder-reliance,andwould
helpthedecisionmakertoretaintheirinternallocusoncontrol[29].
2.2 ExplainableAI(XAI)inSupportingDecisionMaking
Inthissection,wereviewsomeAI-firstexplainableAIapproachesthathavebeenusedtoprovideexplanationsfor
theAIrecommendationbasedonfeatureanalysis.Ourdecision-makingmodelwillapplytheWeightofEvidence
framework,whichhassimilaritieswithotherfeature-basedexplanations.Therefore,wewilldiscusssomepopular
evidence-basedexplanationsthathavebeenusedinsupportingdecision-making.
2.2.1 Humandecision-makingrelianceonAIsupport. Thereisnostraightforwardpositionregardingwhenhumans
arewellcalibratedtoacceptAI-generatedadvice[35].Overall,studyparticipantsappearmorelikelytoacceptanAI’s
recommendationwhenprovidedwithexplanations,regardlessofthemodel’scorrectness[4,18,33].Explanations
canincreasetheaccuracyofthehuman-AIteamwhentheAIiscorrect,butdecreaseitwhenitiswrong,resultingin
over-relianceontheAI’srecommendations.Arguably,thisisbecausethecurrentexplanationstylesdonotprovide
detailsoftheunderlyingrationaleoftheAImodelbehaviour[33].Wethereforeshouldbecarefulwhenselectingthe
explanationtypeasitcanhaveasignificanteffectonwhetherusersdecidetorelyonthem[7,23].
2.2.2 Evidence-basedExplanations. Inthispaper,wewillgenerateevidence-basedexplanations,whicharesimilar
tofeatureimportanceexplanations.ThemaindifferenceisthatWeightofEvidenceusesloglikelihoodsandlogodds
ratiostogenerateexplanations,whereasLIME[28]andSHAP[24]findfeatureimportancebymodifyingthepredictive
posteriorprobabilityinvariousways.
Evidence-basedexplanationshavebeenappliedtosupportdecision-makinganddebugmodelsinseveralprior
research [19, 20, 26] other than from Alvarez Melis et al. [2]. A closely related work to Alvarez Melis et al. [2]
isfromPoulinetal.[26].Poulinetal.[26]proposeaframeworkcalledExplainD thatusesadditiveevidence.The
frameworkalsomeasurestheweightofevidenceusingaNaiveBayesclassifieralongwithhighlightingthenegativeand
positiveevidenceforadecision.However,theproblembeingconsideredisabinaryclassification.Furthermore,thereis
stillroomforimprovementbyconductingexperimentstoevaluatetheframework.Kuleszaetal.[19,20]introduce
EluciDebuginemailclassificationusingMultinomialNaiveBayesclassifier(MNB).TheEluciDebugprototypeprovides
aninterfacethatincludesimportantwordsandthefoldersizethatbothcontributetotheemailclassification.However,
theprototypedidnotspecificallygivepositiveandnegativeevidenceindecision-makingsituations.
3 EVIDENCE-INFORMEDHYPOTHESIS-DRIVENDECISIONMAKINGMODEL
Wedefinetheevidence-informedhypothesis-drivendecision-makingmodelbyimplementingtheevaluateAI (hypothesis-
driven)paradigm[25]usingtheWoEmodel.Specifically,givenaclassificationproblem,decisionmakersexplore
APreprint 3Le,etal.
evidenceforandagainsteachhypothesis(i.e.anoutputclass).Weallowdecision-makerstointeractwiththemodelby
repeatedlyselectingahypothesisforwhichtheycanthenseethepositive(ornegative)evidence.
3.1 EvidenceGeneration
Inaclassificationproblem,ahypothesisℎ ∈ 𝑌,where𝑌 = {ℎ,ℎ 1,ℎ 2,...,ℎ 𝑛}includesallpossiblehypotheses,asan
outputclass.Then,ℎ¯=𝑌\{ℎ}referstoallhypothesesotherthanℎ.Forexample,ifadoctorassertsasetofhypotheses
𝑌 ={ℎ 1,ℎ 2,ℎ 3}whereℎ 1=thepatienthasCovid,ℎ 2=thepatienthasInfluenzaandℎ 3=thepatienthaspneumonia,then
ℎ¯ 1=thepatientdoesnothaveCovidwhichincludesallpossiblehypothesesexcepthavingCovid,thatisℎ¯ 1={ℎ 2,ℎ 3}.
WegeneratetheweightofevidenceforpossiblehypothesesusingWeightofevidence(WoE),whichisaprobabilistic
approachforanalysingvariableimportance,introducedinthecontextofexplainabilitybyAlvarezMelisetal.[2]
buildingonGood[17].Itprovidesaquantitativeresponsetothequestionofwhyamodelpredictedoutputℎfora
particularinput𝑥intermsofhowmucheachinputfeature𝑥
𝑖
providesinfavourof,oragainst,ℎ,relativetoalternatives.
ThroughBayesrule,WoEcanbeunderstoodasanadjustmenttothepriorlogoddscausedbyobservingtheevidence.
Forhypothesisℎandinputfeature𝑥 𝑖,weightofevidence,woe,isdefinedasfollows:
𝑃(𝑥 𝑖 |ℎ) 𝑃(ℎ |𝑥 𝑖) 𝑃(ℎ)
woe(ℎ |𝑥 𝑖)=log =log −log (1)
𝑃(𝑥 𝑖 |ℎ¯) 𝑃(ℎ¯|𝑥 𝑖) 𝑃(ℎ¯)
Basedontheweightofevidence,wesaytheevidencesupportsorrefutesahypothesis:
• Ifwoe(ℎ |𝑥 𝑖) >0,evidence𝑥 𝑖 supportshypothesisℎ
• Ifwoe(ℎ |𝑥 𝑖) <0,evidence𝑥 𝑖 refuteshypothesisℎ
• Ifwoe(ℎ |𝑥 𝑖)=0,evidence𝑥 𝑖 neithersupportsorrefuteshypothesisℎ
3.2 Howdecision-aidmodelscanuseWoEtomakeadecision
Usingtheweightofevidenceforeachfeature𝑥 𝑖 asinEquation1,adecision-aidmodelcanmakeapredictionbasedon
thetotalweightofevidenceofahypothesisℎbysumminguptheweightofevidenceofthishypothesisbasedoneach
feature𝑥 𝑖.Thetotalweightofevidenceisdefinedasfollows.
𝑛
∑︁
woe(ℎ)= woe(ℎ |𝑥 𝑖) (2)
𝑖=1
where𝑛isthenumberoffeatures.
Thedecision-aidmodelwillselectthebesthypothesisbasedonthemaximumposterior,thatis,𝑦=argmaxℎ∈𝑌𝑃(ℎ |
𝑋).Ifwehavethesamepriorforallhypotheses,wecanalsousethetotalweightofevidenceasanotherwaytofindthe
besthypothesisusingEquation1.Therefore,adecision-aidmodelcanselectthehypothesiswiththemaximumtotal
weightofevidenceasitspredictionasfollows(onlyapplytouniformpriors).
𝑦=argmaxwoe(ℎ) (3)
ℎ∈𝑌
3.3 HowWoEcanincorporateahumanapproachtomakingadecision
Toassistuserswithinterpretability,AlvarezMelisetal.[2]complementthedisplayofthemagnitudeoftheweight
oftheevidencewithanotionofsignificanceleveloftheevidence,usingascaleofsevencategories:decisive-against,
strong-against,substantial-against,not-significant,substantial-in-favor,strong-in-favor,decisive-in-favor.Thedetailscan
befoundintherule-of-thumbguidelineshere[3].
APreprint 4TowardsthenewXAI:AHypothesis-drivenApproach
Inadditiontotheweightofevidenceofafeature,wesuggestitisusefultodistinguishtheimportanceofafeature–
withimportancebeingdomainspecificanddeterminedbythedomainexpertusingthemodel.Specifically,ifafeature
hassignificantweightofevidenceaccordingtotheWoEmodel,butthatfeatureisnotseenasimportantbythehuman
decisionmaker,thenitisreasonabletoanticipatetheimpactofthatevidenceonthedecisionwouldbereducedbythe
decisionmaker.Forexample,ifaclinicianlooksataskincancerimageandalsoisawareofsomeirrelevantbuthigh
weightofevidencefeaturesuchasdensehair,theyshouldignorethatevidenceinmakingaprediction.
Formally,byconsideringtheimportanceoftheevidence,were-definethetotalweightofevidencefromahuman
decisionmakingperspectiveasfollows:
𝑛
∑︁
woe(ℎ)= 𝛾 𝑖 ×woe(ℎ |𝑥 𝑖) (4)
𝑖=1
where𝛾 𝑖 isaparameteroffeature𝑥 𝑖 thatadjuststheweightofevidencebasedonimportance,i.e.,𝛾 𝑖 >𝛾 𝑗 represents
thatfeature𝑥 𝑖 ismoreimportantthanfeature𝑥 𝑗.
Then,fortheskincancerexamplejustmentioned,ineffectinEquation4,theclinicianhasset𝛾 =0forthatfeature.
4 EXPERIMENTDESIGN
Inthissection,wedescribethetaskimplementedinthehumanbehaviourexperimentandtheexperimentdesign.In
selectingadecision-makingtask,weidentifiedrequirementssimilartothoseusedinotherstudiesofhowexplanations
canassisthumandecisionmakersinteractingwithAIdecisionsupport,e.g.Vasconcelosetal.[34]:thetaskshouldnot
betooeasyforhumanstocompletewithoutadecisionaid,butalso,aswewereusinglaysubjectsfromProlificforthis
particularstudy,thetaskcannotrequirespecialistknowledge.
WechoseaversionofthehousingpricepredictiontaskstudiedpreviouslyinanXAIcontext[1,10].Inthistask,par-
ticipantsareprovidedwithinformationabouthousefeaturesandwithotherinformationwhichvariesbyexperimental
condition,andareaskedtochoosewhetherthegivenhousewouldhaveasalepriceoflow,mediumorhigh.Asnoted
byothers[10],realestatevaluationisadomainwhereMLmodelshavebeendevelopedtohelppeoplemakebetter
decisions,predictinghousepricesisataskthatlaypeoplemayneedtodoinreallife,soitisnotunrealistictoexpect
theyhavesufficientday-to-dayknowledgetomakepredictionsanddecidewhetherornottorelyonanAImodel.
Experimentingwiththistask,wecomparedthehypothesis-drivenapproachwithtwostate-of-the-artdecision-making
approachesusingquantitativemeasuresforefficiency,performanceandrelianceandaqualitativeanalysisofinformation
use.IntheterminologyofarecentreviewofXAIevaluation[21],thefirsttwopointsofcomparisonareaformof
evaluationwithrespecttothedecisiontask,andthelattertwofocusonusers’perceptionanduseoftheAIsystemitself.
4.1 DatasetandModelImplementation
Tobuildourmodel,weusedtheAmesHousingDataset[11]andtheopensourcecodeonGitHub[31]fordatapre-
processing.Thedataafterpre-processinghasatotalof2616instancesand28features.Weprocessedthedatasetfurther
byconvertingthehousepriceintothreeoutputclasses(lowprice,mediumpriceandhighprice).Wealsobalancedthe
datasettoensurethatthethreeclasseshadthesamenumberofinstancesbyusingNear-MissUndersampling.Finally,
wehadatotalof1920instanceswith640instancesforeachclass.
Weselectedsixfeaturesforthehumanexperimentinthehouse-pricedecisionmakingtaskbyapplyingGradient
BoostingClassificationmodeloverthedata.Consideringdomainspecificdecisionmakingabouthouseprices,we
proposetheretobethreeimportantfeatures(qualityofconstruction,houseageandlocation)andthreeunimportant
APreprint 5Le,etal.
features(fireplaces,kitchenqualityandcentralairconditioning).Wedividedthedatasetinto80%forthetrainingsetand
20%forthetestset.FollowingAlvarezMelisetal.[2],weuseaGaussianNaïveBayes(GNB)classifiertoobtain𝑃(𝑥
𝑖
|ℎ).
Thisassumesthatfeaturesareindependent,butthemodelandimplementationworkforanyprobabilisticclassifier.
Wechosethismodelbecauseitisasimplediscriminativeclassifierthatalignswithpreviousworkonevidence-based
explanations[19,26].
4.2 ExperimentalConditions
Allparticipants1weregiventhesixhousefeaturevaluesplusotherinformation,whichvariedbyconditionassetout
below.Participantsthenchosewhetherthegivenhousewouldhaveapriceoflow,mediumorhigh.
Usingabetween-subjectdesign,participantswererandomlyassignedtooneofthreeconditions:
• (C1)Recommendation-driven:ParticipantsseetheAIprediction(i.e.,eitherlowormediumorhigh)andalsothe
weightofevidenceforthatprediction;
• (C2)AI-explanation-only:ParticipantsseetheweightofevidenceassociatedwiththeAIprediction,buttheAI
predictionitselfishidden;
• (C3)Hypothesis-driven:Participantsseetheweightofevidenceforallhypotheses(low,mediumandhigh),but
theAIpredictionitselfishidden.
AlthoughparticipantsintheExplanation-onlyandHypothesis-drivenconditionsdidnotseearecommendation,it
wasexpectedthatthedisplayedinformationfromtheWoEframeworkwouldprovideinsightthatparticipantscould
usetosupporttheirdecisionmaking.WenoteasimilarExplanation-onlyapproachhasbeenexploredpreviously[15].
4.3 ResearchQuestionsandHypotheses
Ouroverarchingresearchquestionswereasfollows:
• RQ1:(Efficiency)WhatformofAIassistancehelpsparticipantsmakefasterdecisions?
• RQ2:(Performance)WhatformofAIassistancehelpsparticipantsmakebetterdecisions?
• RQ3:(Reliance)WhatformofAIassistancehelpsreduceover-relianceandunder-reliance?
• RQ4:(Informationuse)Howdopeoplemakedecisionsdifferentlyinrecommendation-driven,AI-explanation-only
andhypothesis-drivenparadigm?
ForRQ1,weevaluatedtheparticipants’speedinmakingadecision.Weusethemostcommonmetric-completion
timetomeasurethetimetakenonthetask.Thecorrespondinghypothesesforthisquestionare:
• H1a/b:(C3)Hypothesis-drivenparadigmwillcostlesstimetofinishthetaskthan(C1)Recommendation-driven
and(C2)AI-explanation-only.
ForRQ2,weevaluatedthequalityofthedecision.Inthetask,weaskedtheparticipantstoassignthelikelihoodfor
eachpricerange(low/medium/high)where100isthemostlikelyand0istheleastlikely.Thesumofthreelikelihoods
mustbeequalto100.Weexpecttheparticipantstobeconfidentwhentheymakeacorrectprediction,andnotbe
confidentwhentheymakeawrongdecision.WeapplyBrierscoreasexplainedbelowtomeasurethetaskperformance.
Thehypothesesforthisquestionare:
• H2a/b:(C3)Hypothesis-drivenparadigmwillhelpparticipantsmakebetterdecisionsthan(C1)Recommendation-
drivenand(C2)AI-explanation-only.
1Wereceivedethicsapprovalfromourinstitutionbeforeconductingthehumanexperiment.
APreprint 6TowardsthenewXAI:AHypothesis-drivenApproach
ForRQ3,weinvestigatedtheparticipants’capabilityofappropriatelycalibratingtheirdecision.Participantsshould
followthemodel’spredictionwhenitiscorrectandshouldnotusethemodel’spredictionwhenitiswrong.Weapplied
twomeasuresover-relianceandunder-relianceasshownbelowwiththefollowinghypotheses:
• H3a:(C3)Hypothesis-drivencanreduceover-reliancecomparedto(C1)Recommendation-driven.
• H3b:(C3)Hypothesis-drivencanreduceunder-reliancecomparedto(C2)AI-explanation-only.
ForRQ4,welookedintothetextwrittenbyparticipantswhentheyexplainedwhytheyselectedanoptionaftereach
questiontoknowhowtheyusedtheprovidedinformationineachdecision-makingparadigmtomaketheirdecisions.
Therefore,wecanidentifythelimitationsofeachparadigmandthegeneratedevidencethatleadtheparticipantsto
makeawrongdecision.
4.4 Measures
Wetookthefollowingmeasures:
(1) TaskEfficiency(Completiontime):Thetimeparticipantstaketocompletethetask.
(2) TaskPerformance(Brierscore):Thismetricquantifiestheeffectivenessoftaskperformance.ThebestBrier
score(i.e.equalsto0)iswhenyouanswerthequestioncorrectlywith100%likelihood,andalsowhenyouhave
awronganswerbutwith0%likelihoood.Therefore,aparticipanthasbettertaskperformancewhentheyhave
alowerBrierscore.Theformulais:
BS𝑝,𝑖 =(𝐶 𝑝,𝑖 −𝐴 𝑝,𝑖)2 (5)
where:𝐶 𝑝,𝑖 isthelikelihoodlevelofparticipant𝑝inquestion𝑖,rangingfrom0to1;𝐴 𝑝,𝑖 istheanswerscoreof
participant𝑝inquestion𝑖,either0(wronganswer)or1(rightanswer).
Wethenmeasuretheover-relianceandunder-reliance[36].SincestudyparticipantscanonlyseetheAIrecommen-
dationinC1(Recommendation-driven),wemeasurewhetherparticipantshavethesamepredictionordifferfromthe
model’spredictionintheothertwoconditions.
(3) Over-reliance:thefractionoftaskswhereparticipantshavethesamedecisionasamodel’spredictionwhen
itwaswrong:Σ 𝑖(𝐴 𝑝,𝑖 =𝑀 𝑖 =0)/Σ 𝑖(1−𝑀 𝑖),where𝐴 𝑝,𝑖 isasaboveand𝑀 𝑖 =1ifthemodeliscorrectand0
otherwise.
(4) Under-reliance:thefractionoftaskswhereparticipantshaveadifferentdecisionfromamodel’sprediction
whenitwascorrect:Σ 𝑖(𝐴 𝑝,𝑖 ≠𝑀 𝑖 =1)/Σ 𝑖𝑀 𝑖.
4.5 Conduct
Weconductedtwoseparatehumanexperimentsinwhichparticipantsweregiventhesametaskintheformofaquestion
set,withtheonlydifferencebeingthewaytheyansweredthequestion.
• Inexperiment1,participantswereaskedtomakeadecisionabouttherelativelikelihoodforeachpricerange
(low/medium/high)ofgivenhouseinstances.WeanswerRQ1,RQ2andRQ3byanalysingtheresultsoffour
measuresmentionedabove(completiontime,Brierscore,over-relianceandunder-reliance).
• Inexperiment2,werecruitedanewandsmallercohortandaskedthemtodothesametasksasinexperiment
1,butinaddition,weaskedparticipantstoexplaintheirdecisionsusingfreetext.Weconductthisexperiment
separatelyfromthequantitativedatainexperiment1becauseaskingparticipantstoexplaintheirreasoning
cognitivelyforcesthemtoengagewiththeinstance,interferingwiththeirnaturaldecision-makingprocess,
APreprint 7Le,etal.
andthereforepotentiallyaffectingthequantitativeresults.Wethenperformedadeductivethematicanalysisof
theirexplanationstoanswerRQ4.
TheexperimentwasdesignedasaQualtrics2surveyandparticipantsaccessedthesurveythroughProlific3.The
experimentrequiredamaximumof25minutestofinish.Therewere12houseinstancesgiven,equivalentto12questions.
These12questionswereevenlydistributedintofourquestioncategories:(1)wherethemodelgivescorrectpredictions
withhighuncertainty,(2)wherethemodelgivescorrectpredictionswithlowuncertainty,(3)wherethemodelgives
wrongpredictionswithhighuncertaintyand(4)wherethemodelgiveswrongpredictionswithlowuncertainty.Thus,
therearethreequestionsineachcategory.
Theuncertaintyismeasuredbythecrossentropyasfollows.
∑︁
𝑢(ℎ)=− 𝑝(ℎ)log𝑝(ℎ) (6)
ℎ∈𝐻
where𝑢(ℎ)istheuncertaintylevelofhypothesisℎgiventheprobabilisticoutputis𝑝(ℎ).Weselectinstanceswith
lowuncertaintybychoosinginstancesentropylessthan0.3.Forhighuncertainty,wechooseinstanceswithentropy
greaterthan0.7.Participantsdidnotknowhowmanytestinstanceswerecorrect/incorrect.Eachparticipantwaspaida
minimumof4GBPfortheirtime,plusabonusof2GBPiftheycouldansweratleast9outof12questionscorrectly.
Participantswerealsogivenaplainlanguagestatement,andconsentformanddidatrainingphasewith3example
questionsbeforeansweringthe12testquestions.
• Inexperiment1,participantswereaskedtomakeadecisionabouttherelativelikelihoodforeachpricerange
(low/medium/high)ofgivenhouseinstances.WeanswerRQ1,RQ2andRQ3byanalysingtheresultsoffour
measuresmentionedabove(completiontime,Brierscore,over-relianceandunder-reliance).
• Inexperiment2,participantswereaskedtoexplaintheirdecisionsusingfreetextandweundertookadeductive
analysisoftheirexplanationstoanswerRQ4.
ForRQ4thetextisaresponseto“Canyoupleaseexplainwhyyouselectedthisoption?".Weanalysedatotalof
12(questions)×95(participants)=1140responses.Thefinalanalysisincludes1,031responsesafterremoving109
responsesduetopoorquality.Eachresponseisassignedtoatleastonecategory(orcode):UsingfeaturevaluesorUsing
evidence.Wethenperformadeductivethematicanalysisbyreadingeachresponseandassigntherelevantcodes.We
explaineachcodeasfollows.
• UsingFeatureValues:Participantsrelyonthefeaturevaluesandtheirbackgroundknowledgetomakethefinal
decisionwithoutusingthemodelevidence.Forexample,inFigure9,featurevaluesarethesixhousefeatures
onthetop.
• UsingEvidence:Participantsrelyontheevidenceprovidedbythemodelandpossiblytheirbackgroundknowledge
tomakethefinaldecision.Forexample,inFigure9,theevidenceistheWeightofEvidencechartoftheprediction.
Wechosethesetwocodesbasedontheideaofmachineexplanationandhumanintuition[8,9].Specifically,using
evidencereferstousingthemachineexplanationandtherefore,makinguseofthemodelevidencetosupportdecision-
making.Ontheotherhand,usingfeaturevaluesisrelevanttousingpeople’sintuitionsofthetaskbasedontheinput
featurevalues.Therefore,usingthequalitativeanalysis,weexplorehowpeopleusethemodelevidenceandtheir
intuitionsinthethreedecision-makingparadigms.
2https://www.qualtrics.com
3https://www.prolific.com
APreprint 8TowardsthenewXAI:AHypothesis-drivenApproach
Fig.1. Completiontimeinseconds.Lowerisbetter.Meansrepre-
sentedasdots. Fig.2. Brierscore.Lowerisbetter.Meansrepresentedasdots.
4.6 Participants
4.6.1 Participantsinexperiment1. UsingthepoweranalysisforF-testforonefactorANOVAandassumingthepower
of0.8andsignificantalphaof0.05,wefoundthatasamplesizeof300participantsinthreegroupsguaranteesasmall
effectsizeof0.2.Intotal,werecruited𝑁 =302participantsonProlific,distributedintothreeconditions:102participants
inC1,99participantsinC2and101participantsinC3.ParticipantsareselectedfromtheUnitedStates,UnitedKingdom,
andAustraliaandmustbefluentinEnglish.Gender-wise,192werewomen,103weremen,4self-specifiedtheirgender
and3declinedtostatetheirgender.Age-wise,94participantswerebetweenAges18and29,91werebetweenAges30
and39,44werebetweenAges40and49,and73wereoverAge50.
4.6.2 Participantsinexperiment2. Werecruited𝑁 =95participantsonProlific,distributedintothreeconditions:30
participantsinC1,34participantsinC2and31participantsinC3.ParticipantsareselectedfromtheUnitedStates,
UnitedKingdom,andAustraliaandmustbefluentinEnglish.Gender-wise,52werewomen,41weremen,and2
declinedtostatethegender.Age-wise,38participantswerebetweenAges18and29,37werebetweenAges30and39,
10werebetweenAges40and49,and10wereoverAge50.
5 EXPERIMENTRESULTS
Inthissection,weshowtheresultsoftwoexperiments.Inthefirstexperiment,weexplorewhetherhypothesis-drivencan
improvetaskefficiency,taskperformanceandreducereliancecomparedtorecommendation-drivenandAIexplanation
only.Inthesecondexperiment,weunderstandhowparticipantsusedourhypothesis-drivenapproachdifferently
comparedtotheothertwobaselines.
5.1 Experiment1:QuantitativeResults
WeperformedaShapiro-Wilkstesttocheckthedatanormalityandwefoundthatourdatawasnotnormallydistributed
(𝑝 <0.05).Therefore,weapplynon-parametricKruskal-Wallistest.Wethenperformpost-hocMann-WitneyUtestto
dopairwisecomparisons.TheresultsarevisualisedinFigure1andFigure2.Thesignificantdifferencesbetweentwo
conditionsarehighlightedinitalicredinthefigureswhere𝑝 <0.05.
APreprint 9Le,etal.
Fig.3. Over-reliance.Lowerisbetter.Meansrepresentedasdots.Fig.4. Under-reliance.Lowerisbetter.Meansrepresentedasdots.
5.1.1 Taskefficiency. Figure1showsthecompletiontimeinthreeconditions.Thereisnostatisticallysignificant
differenceamongthesethreeconditions(𝑝 ≈0.9).WerejectH1a/b.Thisshowsthathypothesis-drivenisnotmore
mentallydemandingthanrecommendation-drivenandAI-explanation-only.
5.1.2 Taskperformance. Weevaluateparticipants’decision-makingperformancebyusingtheBrierscore.ABrier
scoreofzeroindicatesthatparticipantsscoredperfectlywellinthetask.AsseeninFigure2,participantsinthe
hypothesis-drivencondition(𝑀 =0.267,𝑆𝐷 =0.063)performsignificantlybetterthantheothertwoapproaches
(C1:(𝑀 = 0.290,𝑆𝐷 = 0.071),C2:(𝑀 = 0.295,𝑆𝐷 = 0.073)).WeacceptH2a/b.Therefore,hypothesis-drivenhelps
participantsbeconfidentwhentheymakeacorrectdecision,andbelessconfidentwhentheymakeawrongdecision.
5.1.3 Over-reliance. InFigure3,hypothesis-driven(𝑀 =53.30,𝑆𝐷 =22.73)reducedover-reliancesignificantly
comparedtorecommendation-driven(𝑀 =73.86,𝑆𝐷 =20.91)(𝑝 =1.5×10−8,𝑟 =0.449).WeacceptH3a.Moreover,
AI-explanation-only (𝑀 = 54.21,𝑆𝐷 = 22.51)alsoreducesover-reliancecomparedtotherecommendation-driven
approach(𝑝 =1.6×10−8,𝑟 =0.450).
5.1.4 Under-reliance. InFigure4,hypothesis-driven(𝑀 =24.42,𝑆𝐷 =18.19)significantlyreducedunder-reliance
comparedtoAI-explanation-only(𝑀 =41.25,𝑆𝐷 =27.18)(𝑝 =1.09×10−6,𝑟 =0.387),WeacceptH3b.Thisisnot
surprisingbecauseweexpectthatparticipantsintheAI-explanation-onlyconditionarethemostlikelytounder-rely
ontheAIrecommendationastheywerenotgiventheAIrecommendationexplicitly(onlygiventheAIexplanation).
Recommendation-driven(𝑀 =17.81,𝑆𝐷 =20.35)hastheleastunder-reliancevaluebecauseparticipantsweregivenAI
recommendations.
5.2 Experiment2:QualitativeResults
InFigure5aand5b,weillustratethenumberoftimesthatparticipantsusedfeaturevaluesandevidencetomaketheir
decisionsbasedonthetextanalysis.
Fortherecommendation-drivenparadigm,participantsusethefeaturevaluestoconfirmwhetherthe
decisionaid’spredictionandexplanationarereliableornot.Ifparticipantsthinkthefeaturevaluesdonotmatch
theevidenceexplanation,theywillgowiththefeaturevaluestomakethefinaldecision.Someexamplesthatthestudy
participantsintherecommendation-drivenconditiongoagainstthedecisionaid’sprediction:
APreprint 10TowardsthenewXAI:AHypothesis-drivenApproach
(a)Numberoftimesthatparticipantsusedevidencetomakeadecision.
(b)Numberoftimesthatparticipantsusedfeaturevaluestomakeadecision.
Fig.5. Qualitativefindings
“Here,Ibelievethedecisionaidismistaken.Myratingwouldbemediumbecausethehouseisveryold
whichisoverlookedbythemodel.Otherfeaturesarealldecentorabovedecentbutthehouseageisan
importantfeature.”–Q11
“ThelocationofthepropertyislowsoIthoughtthatwouldbringdowntheprice”–Q7
Ignoringevidenceis,ofcourse,agoodstrategyifthedecisionmakerbelievesthattheevidenceiswrong.However,
recommendation-driven does not help participants to be aware of the high uncertainty among multiple
predictions.Thislimitationismitigatedbythehypothesis-drivenparadigm.
FortheAIexplanationonlyparadigm,participantsoftenrelyonthefeaturevaluesandnotontheevidence
explanationtomakeadecision.Thisisnotsurprisingbecauseparticipantscanfinditdifficulttointerprettheevidence
withoutseeingthelabelthattheevidenceisreferredto.Weattributethistothecognitiveefforttolinkevidenceto
hypotheses,leadingtoparticipantsignoringevidenceandrelyingoninputfeaturevaluestomaketheirdecisions.This
APreprint 11Le,etal.
Fig.6. Anexampleofuncertaintyawarenessinhypothesis-driven(Q6).
isanoteworthylimitationofAI-explanation-onlyasitmakespeopleoverlooktheexplanationifthelinktotheevidence
isunclear.InthestudybyGajosandMamykina[15],thelinkfromfeatureattributionstothetasksolutionismore
straightforwardthaninourstudy,whichmayexplainthedivergenceofresults.
Participantsmoreoftenusetheevidenceexplanationtomakeadecisioninthehypothesis-driventhanin
recommendation-drivenorAIexplanationonly.Thisisimportantbecausepeoplecantakeadvantageofthemodel
evidence.Inthetwobaselineconditions,participantstendedtoignoreevidenceseeminglyduetotheinabilityto
interpretit,whichmeanstheywillfailtotakeadvantageoftheunderlyingmodel.InFigure5a,thereareonlytwo
exceptionsatQ6andQ11wheretheevidenceisnotthemostusedinthehypothesis-drivencondition.
Wefoundthatinhypothesis-driven,participantsreportedthatitwasdifficulttomakedecisionsfortwomainreasons:
• Uncertaintyawareness:Thisiswheretherearemultiplehypotheseswithsimilarstrengthevidence.Participants
areawareoftheuncertaintyinthemodelsolelybasedonthepositiveandnegativeevidenceprovidedforall
hypotheses.Inthiscase,participantsusetheinputfeaturevaluesorchoosethehypothesisthattheythinkis
slightlybetterthantheotherswhenmakingthefinaldecision.Figure6showsanexamplewheretwohypotheses
lowandmediumbothhaveapositiveandnegativeweightofevidence,especiallyinthetopthreeimportant
features.Forinstance,someparticipantsexplicitlyexplaintheiruncertaintyinthetextasfollows.
“I was choosing between high and medium. Quality of construction, age and location are the most
importantfeatures.Whenitwasathigh,thesewereallpositive.Kitchenqualityandfireplaceswere
negative,butthesearenotasimportant.”–Q0
“Theamountofnegativeorpositiveevidenceforlowormediumisthesame,includingthethreemore
importantfactors.Bothmediumorlowcouldbeviablebutmediumhaslessvarianceandisoverallmore
balanced.”–Q6
APreprint 12TowardsthenewXAI:AHypothesis-drivenApproach
Fig.7. Anexampleofdeceptiveevidenceinhypothesis-driven(Q9).
“Thehouseisclearlynotinahighbracket,butitissomewhatdifficulttodecidebetweenlowandmedium.
Therearestrongerindicatorsinlow,goingbothways,whilemediumhaslargelyinsignificantindicators.
Lowhasasignificantnegativeweightingforhouseageandthispushedmetowardsmedium.”–Q6
• Deceptiveevidence:Whentheevidencewasstrongestforanincorrectoption.Inthiscase,manyparticipants
justfollowtheevidenceandmakethewrongdecision.Figure7illustratesanexampleofQ9wherewehave
allpositiveevidenceinhypothesismedium,butstrongnegativeevidenceinhypothesishigh.Therefore,all
participantschoosehypothesismedium,buthypothesishighisthegroundtruth.Futureworkwillneedto
addressthechallengeofbuildingtrustworthyevidence.
In summary, the qualitative analysis showed that participants took advantage of the decision aid more in the
hypothesis-drivenconditionthaninrecommendation-drivenandexplanation-onlyconditions.Further,wealsofound
thatparticipantsrecognisedmodeluncertaintyinthehypothesis-drivencondition.However,therestillremainsalimit
ofhavingdeceptiveevidence.
6 DISCUSSIONSANDCONCLUSIONS
Inthissection,wewilldiscussourfindingsaboutthehypothesis-drivenapproach.
6.1 Strengthsandweaknessesofourhypothesis-drivenapproach
First,participantsusingthehypothesis-drivenapproachrequiredasimilartimetocompletethetaskcomparedtothe
recommendation-drivenapproach.Participantsinthehypothesis-drivenconditionalsomadehigherqualitydecisions
APreprint 13Le,etal.
thanrecommendation-drivenandAIexplanationonlybasedontheBrierscore.Theresultsindicatedthatthehypothesis-
drivengavestudyparticipantsamorecompletepictureoftheunderlyingdecisionaidthantheothertwoapproaches,
helpingthemtomakeuseoftheAImodelswhentheyareright,andbelessconfidentwhenthemodelsarewrong.
Moreover,hypothesis-drivenreducedover-reliancesignificantlycomparedtothestandardAIrecommendation.
Similarly,hypothesis-drivenalsoreducedunder-reliancecomparedtoAIexplanationonly.Importantly,thepositive
resultforunder-relianceusingrecommendation-drivenisnotcancelledoutbythepoorover-relianceresult,compared
tohypothesis-driven.Theprimaryaimindicatingpotentialfortheuseofuncertainty/confidence[5]andconformal
prediction[30]todirectdecisionmakers’attentiontowardsasetofhypothesesthatitisconfidentabout.
Usingthequalitativeanalysis,hypothesis-drivenhelpedparticipantstakeadvantageofthedecisionsupporttool’s
evidence,andalsorecognisetheuncertaintyunderlyingthemodel.Usingthestrengthofevidence,participantsare
awareoftheuncertaintybetweenmultiplehypotheses.Therefore,theymadeanattempttogaugethemodeluncertainty
bycalibratingtheweightofevidencedependingonwhetherthefeatureisimportantornot.Also,theycouldmakeuse
oftheinputfeaturevaluesandchoosethehypothesisthattheyperceivemostlikelymatcheswiththosevalues.
Ontheotherhand,recommendation-drivenandAIexplanationonlydonotsupportthis.Wefoundthatinrecommendation-
driven,peoplecouldusefeaturevaluestoconfirmthevalidityofthedecisionaid’sprediction.However,theyarenot
awareoftheuncertaintyamongdifferenthypotheses.InAIexplanationonly,peopleoftenignoreusingtheevidence
andsolelyfocusonusingthefeaturevaluestomakeadecisionbecauseinterpretingtheevidencewiththisapproach
canbealotmorementallydemanding.
6.2 Studylimitations
Therearealsosomelimitationswiththestudy.First,werantheexperimentononedataset(AmesHousing),whichlimits
generalisability.Inaddition,asthereisnogroundtruthforthepriceofahouse,theexperimentalparticipants’tasks
aresomewhatsubjective.Further,thistaskhasonlythreeoutputclasses,soonlythreehypotheses,andweanticipate
theresultswouldbemoreinterestingwhenweconsidermorehypotheses.Finally,thehumanexperimentiscurrently
conductedwithlaypeoplewhileexpertslikelyinteractwiththedecision-aidingtooldifferentlyfromlaypeople[13].
6.3 Conclusions
Inthispaper,weshowthatthehypothesis-drivenapproachusingWeightofEvidence(WoE)cansignificantlyreducere-
liance,improvedecision-makingqualitycomparedtotwootherprevalentdecision-makingapproaches(recommendation-
drivenandAIexplanationonly).Furthermore,hypothesis-drivenhelpsparticipantstobeawareoftheuncertainty
amongmultipleoptions.Nevertheless,therestillremainsachallengeofstudyparticipantsrelyingonthewrong(or
misleading)evidence.Therefore,futureworkcanaddressthischallengebyexploringdifferentapproachesforpresenting
trustworthyevidence.Moregenerally,potentialfutureworkistoconsidertheuncertaintyinthegeneratedevidence.
ACKNOWLEDGMENTS
ThisresearchwassupportedbytheUniversityofMelbourneResearchScholarship(MRS)andpartlyfundedbyAustralian
ResearchCouncilDiscoveryGrantDP190103414.
REFERENCES
[1] AshrafAbdul,ChristianvonderWeth,MohanKankanhalli,andBrianYLim.2020.COGAM:measuringandmoderatingcognitiveloadinmachine
learningmodelexplanations.InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems.1–14.
APreprint 14TowardsthenewXAI:AHypothesis-drivenApproach
[2] DavidAlvarezMelis,HarmanpreetKaur,HalDauméIII,HannaWallach,andJenniferWortmanVaughan.2021.FromHumanExplanationtoModel
Interpretability:AFrameworkBasedonWeightofEvidence.ProceedingsoftheAAAIConferenceonHumanComputationandCrowdsourcing9,1
(2021),35–47.
[3] DavidAlvarezMelis,HarmanpreetKaur,HalDauméIII,HannaWallach,andJenniferWortmanVaughan.2021.UserStudyonInterpretability-
Tutorial.https://github.com/dmelis/interpretwoe/blob/master/notebooks/WoE_UserStudy_Tutorial.ipynb. Accessed:2023-05-30.
[4] GaganBansal,TongshuangWu,JoyceZhou,RaymondFok,BesmiraNushi,EceKamar,MarcoTulioRibeiro,andDanielWeld.2021.Doesthe
WholeExceedItsParts?TheEffectofAIExplanationsonComplementaryTeamPerformance.InProceedingsoftheCHIConferenceonHuman
FactorsinComputingSystems.
[5] UmangBhatt,JavierAntorán,YunfengZhang,Q.VeraLiao,PrasannaSattigeri,RiccardoFogliato,GabrielleMelançon,RanganathKrishnan,Jason
Stanley,OmeshTickoo,LamaNachman,RumiChunara,MadhulikaSrikumar,AdrianWeller,andAliceXiang.2021.UncertaintyasaFormof
Transparency:Measuring,Communicating,andUsingUncertainty.InProceedingsoftheAAAI/ACMConferenceonAI,Ethics,andSociety.401–413.
[6] ZanaBuçinca,MajaBarbaraMalaya,andKrzysztofZ.Gajos.2021.ToTrustortoThink:CognitiveForcingFunctionsCanReduceOverrelianceon
AIinAI-AssistedDecision-Making.Proc.ACMHum.-Comput.Interact.5,CSCW1(2021).
[7] RichCaruana,YinLou,JohannesGehrke,PaulKoch,MarcSturm,andNoemieElhadad.2015. IntelligibleModelsforHealthCare:Predicting
PneumoniaRiskandHospital30-DayReadmission.InProceedingsofthe21thACMSIGKDDInternationalConferenceonKnowledgeDiscoveryand
DataMining.1721–1730.
[8] ChachaChen,ShiFeng,AmitSharma,andChenhaoTan.2023.MachineExplanationsandHumanUnderstanding.InProceedingsofthe2023ACM
ConferenceonFairness,Accountability,andTransparency(Chicago,IL,USA)(FAccT’23).AssociationforComputingMachinery,NewYork,NY,USA,
1.
[9] ValerieChen,Q.VeraLiao,JenniferWortmanVaughan,andGaganBansal.2023. UnderstandingtheRoleofHumanIntuitiononReliancein
Human-AIDecision-MakingwithExplanations.Proc.ACMHum.-Comput.Interact.7,CSCW2(2023).
[10] Chun-WeiChiangandMingYin.2022.ExploringtheEffectsofMachineLearningLiteracyInterventionsonLaypeople’sRelianceonMachine
LearningModels.In27thInternationalConferenceonIntelligentUserInterfaces(Helsinki,Finland)(IUI’22).AssociationforComputingMachinery,
NewYork,NY,USA,148–161.
[11] DeanDeCock.2011.Ames,Iowa:AlternativetotheBostonhousingdataasanendofsemesterregressionproject.JournalofStatisticsEducation19,
3(2011).
[12] BerkeleyJDietvorst,JosephPSimmons,andCadeMassey.2015.Algorithmaversion:peopleerroneouslyavoidalgorithmsafterseeingthemerr.
JournalofExperimentalPsychology:General144,1(2015).
[13] RiccardoFogliato,ShreyaChappidi,MatthewLungren,PaulFisher,DianeWilson,MichaelFitzke,MarkParkinson,EricHorvitz,KoriInkpen,and
BesmiraNushi.2022.WhoGoesFirst?InfluencesofHuman-AIWorkflowonDecisionMakinginClinicalImaging.InProceedingsofthe2022ACM
ConferenceonFairness,Accountability,andTransparency(Seoul,RepublicofKorea)(FAccT’22).AssociationforComputingMachinery,NewYork,
NY,USA,1362–1374.
[14] RiccardoFogliato,AlexandraChouldechova,andZacharyLipton.2021.TheImpactofAlgorithmicRiskAssessmentsonHumanPredictionsandIts
AnalysisviaCrowdsourcingStudies.Proc.ACMHum.-Comput.Interact.5,CSCW2(2021).
[15] KrzysztofZ.GajosandLenaMamykina.2022.DoPeopleEngageCognitivelywithAI?ImpactofAIAssistanceonIncidentalLearning.In27th
InternationalConferenceonIntelligentUserInterfaces.794–806.
[16] SusanneGaube,HariniSuresh,MartinaRaue,AlexanderMerritt,SethJ.Berkowitz,EvaLermer,JosephF.Coughlin,JohnV.Guttag,ErrolColak,
andMarzyehGhassemi.2021.DoasAIsay:susceptibilityindeploymentofclinicaldecision-aids.npjDigitalMedicine4,1(2021).
[17] IJGood.1985.Weightofevidence:Abriefsurvey.InBayesianstatistics,J.M.Bernardo,M.H.DeGroot,D.V.Lindley,andSmithA.F,M(Eds.).Vol.2.
Elsevier,249–270.
[18] MaiaJacobs,MelanieF.Pradier,ThomasH.McCoy,RoyH.Perlis,FinaleDoshi-Velez,andKrzysztofZ.Gajos.2021. Howmachine-learning
recommendationsinfluencecliniciantreatmentselections:theexampleofantidepressantselection.TranslationalPsychiatry11,1(2021).
[19] ToddKulesza,MargaretBurnett,Weng-KeenWong,andSimoneStumpf.2015.PrinciplesofExplanatoryDebuggingtoPersonalizeInteractive
MachineLearning.InProceedingsofthe20thInternationalConferenceonIntelligentUserInterfaces(Atlanta,Georgia,USA)(IUI’15).Associationfor
ComputingMachinery,126–137.
[20] ToddKulesza,SimoneStumpf,Weng-KeenWong,MargaretM.Burnett,StephenPerona,AmyJ.Ko,andIanOberst.2011.Why-OrientedEnd-User
DebuggingofNaiveBayesTextClassification.ACMTrans.Interact.Intell.Syst.1,1(2011).
[21] VivianLai,ChachaChen,AlisonSmith-Renner,Q.VeraLiao,andChenhaoTan.2023.TowardsaScienceofHuman-AIDecisionMaking:AnOverview
ofDesignSpaceinEmpiricalHuman-SubjectStudies.InProceedingsofthe2023ACMConferenceonFairness,Accountability,andTransparency
(Chicago,IL,USA)(FAccT’23).AssociationforComputingMachinery,NewYork,NY,USA,1369–1385.
[22] KathrynAnnLambe,GaryO’Reilly,BrendanDKelly,andSarahCurristan.2016. Dual-processcognitiveinterventionstoenhancediagnostic
reasoning:asystematicreview.BMJQuality&Safety25,10(2016),808–820.
[23] TaniaLombrozo.2007.Simplicityandprobabilityincausalexplanation.CognitivePsychology55,3(2007),232–257.
[24] ScottM.LundbergandSu-InLee.2017.AUnifiedApproachtoInterpretingModelPredictions.InProceedingsofthe31stInternationalConferenceon
NeuralInformationProcessingSystems.4768–4777.
APreprint 15Le,etal.
[25] TimMiller.2023.ExplainableAIisDead,LongLiveExplainableAI!Hypothesis-drivenDecisionSupportusingEvaluativeAI.InProceedingsofthe
2023ACMConferenceonFairness,Accountability,andTransparency(Chicago,IL,USA)(FAccT’23).AssociationforComputingMachinery,NewYork,
NY,USA,333–342.
[26] BrettPoulin,RomanEisner,DuaneSzafron,PaulLu,RussGreiner,D.S.Wishart,AlonaFyshe,BrandonPearcy,CamMacDonell,andJohnAnvik.
2006.VisualExplanationofEvidenceinAdditiveClassifiers.InProceedingsofthe18thConferenceonInnovativeApplicationsofArtificialIntelligence-
Volume2.1822–1829.
[27] CharviRastogi,YunfengZhang,DennisWei,KushR.Varshney,AmitDhurandhar,andRichardTomsett.2022.DecidingFastandSlow:TheRoleof
CognitiveBiasesinAI-AssistedDecision-Making.Proc.ACMHum.-Comput.Interact.6,CSCW1(2022).
[28] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2016. "WhyShouldITrustYou?":ExplainingthePredictionsofAnyClassifier.In
Proceedingsofthe22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining.1135–1144.
[29] BenShneiderman,CatherinePlaisant,MaxineCohen,StevenJacobs,NiklasElmqvist,andNicholasDiakopoulos.2016.DesigningtheUserInterface:
StrategiesforEffectiveHuman-ComputerInteraction(6thed.).Pearson.
[30] EleniStraitouri,LequnWang,NastaranOkati,andManuelGomezRodriguez.2023.ImprovingExpertPredictionswithConformalPrediction.In
Proceedingsofthe40thInternationalConferenceonMachineLearning(ProceedingsofMachineLearningResearch,Vol.202),AndreasKrause,Emma
Brunskill,KyunghyunCho,BarbaraEngelhardt,SivanSabato,andJonathanScarlett(Eds.).PMLR,32633–32653.
[31] AlvinT.Tan.2021.CrackingtheAmesHousingDatasetwithLinearRegression.https://github.com/at-tan/Cracking_Ames_Housing_OLS.Accessed:
2023-05-30.
[32] AmosTverskyandDanielKahneman.1974.JudgmentunderUncertainty:HeuristicsandBiases.Science185,4157(1974),1124–1131.
[33] JaspervanderWaa,ElisabethNieuwburg,AnitaCremers,andMarkNeerincx.2021.EvaluatingXAI:Acomparisonofrule-basedandexample-based
explanations.ArtificialIntelligence291(2021).
[34] HelenaVasconcelos,MatthewJörke,MadeleineGrunde-McLaughlin,TobiasGerstenberg,MichaelSBernstein,andRanjayKrishna.2023.Explana-
tionsCanReduceOverrelianceonAISystemsDuringDecision-Making.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),
1–38.
[35] MorVered,TaliLivni,PiersDouglasLionelHowe,TimMiller,andLizSonenberg.2023.TheEffectsofExplanationsonAutomationBias.Artificial
Intelligence(2023),103952.
[36] XinruWangandMingYin.2022.EffectsofExplanationsinAI-AssistedDecisionMaking:PrinciplesandComparisons.ACMTrans.Interact.Intell.
Syst.(2022).
APreprint 16TowardsthenewXAI:AHypothesis-drivenApproach
A STATISTICSOFEXPERIMENT1
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 1075.186 560.534 306.000 689.500 946.000 1307.500 4021.000
(C2)AIExplanationOnly 99.000 1117.162 675.505 210.000 742.500 928.000 1345.000 5559.000
(C3)Hypothesis-driven 101.000 1085.228 555.319 358.000 711.000 944.000 1287.000 3350.000
Table1. Statisticsofcompletiontimepercondition.
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 0.290 0.071 0.183 0.239 0.277 0.333 0.484
(C2)AIExplanationOnly 99.000 0.295 0.073 0.140 0.242 0.281 0.337 0.594
(C3)Hypothesis-driven 101.000 0.267 0.063 0.154 0.228 0.252 0.304 0.474
Table2. StatisticsofBrierscore percondition.
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 73.856 20.913 33.333 66.667 66.667 100.000 100.000
(C2)AIExplanationOnly 99.000 54.209 22.505 0.000 41.667 50.000 66.667 100.000
(C3)Hypothesis-driven 101.000 53.300 22.733 16.667 33.333 66.667 66.667 100.000
Table3. Statisticsofover-reliancepercondition.
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 17.810 20.346 0.000 0.000 16.667 33.333 100.000
(C2)AIExplanationOnly 99.000 41.246 27.183 0.000 16.667 33.333 50.000 100.000
(C3)Hypothesis-driven 101.000 24.422 18.191 0.000 16.667 16.667 33.333 100.000
Table4. Statisticsofunder-reliancepercondition.
B SUBJECTIVEQUESTIONSINEXPERIMENT1
Afterdoingtheexperiment1,participantswereaskedtoanswer12subjectivequestionsasfollows.
(1) Incontrol:Ifeelincontrolofthedecision-makingprocesswhenusingthisdecisionaid.(0=Disagreestrongly;
10=Agreestrongly)
(2) Preference:Iwouldliketousethisdecisionaidfrequently.(0=Disagreestrongly;10=Agreestrongly)
(3) Mentaldemand:Ifoundthistaskdifficult.(0=Disagreestrongly;10=Agreestrongly)
APreprint 17Le,etal.
(4) Systemcomplexity:Thedecisionaidwascomplex.(0=Disagreestrongly;10=Agreestrongly)
(5) Trust:Iamconfidentinthedecisionaid.Ifeelthatitworkswell.(0=Disagreestrongly;10=Agreestrongly)
(6) Trust:Thedecisionaidisverypredictable.(0=Disagreestrongly;10=Agreestrongly)
(7) Trust:Thedecisionaidisveryreliable.Icancountonittobecorrectallthetime.(0=Disagreestrongly;10=
Agreestrongly)
(8) Trust:IfeelsafethatwhenIrelyonthedecisionaidIwillgettherightanswers.(0=Disagreestrongly;10=
Agreestrongly)
(9) Trust:Thedecisionaidisefficientinthatitworksveryquickly.(0=Disagreestrongly;10=Agreestrongly)
(10) Trust:Iamwaryofthedecisionaid.(0=Disagreestrongly;10=Agreestrongly)
(11) Trust:Thedecisionaidcanperformthetaskbetterthananovicehumanuser.(0=Disagreestrongly;10=
Agreestrongly)
(12) Trust:Ilikeusingthedecisionaidfordecisionmaking.(0=Disagreestrongly;10=Agreestrongly)
We evaluate Q1-4 separately to measure 4 measures (In control, Preference, Mental demand and System
complexity).WeaggregateQ5-12tomeasureTrust.
InFigure8,AI-explanation-onlyissignificantlyworsethantheotherconditionsinallfacets.Moreover,recommendation-
drivenandhypothesis-drivenarequitesimilarandthereisnostatisticaldifferencebetweenthesetwoconditions.The
reasonisthatweconductbetween-subjectexperimentssoeachparticipanthasaccesstoonlyoneconditionandtheydo
nothaveanotherconditiontocompareto.Ifwerunwithin-subjectexperimentstomeasuresubjectivequestionsinthe
future,participantscancomparedifferentdecision-makingapproachesandevaluatewhichonetheypreferthemost.
C EXAMPLEQUESTIONSINHUMANEXPERIMENT
ExamplequestionsareshowninFigure9andFigure10.
APreprint 18TowardsthenewXAI:AHypothesis-drivenApproach
(a)Incontrol(Higherisbetter) (b)Preference(Higherisbetter)
(c)Mentaldemand(Lowerisbetter) (d)Systemcomplexity(Lowerisbetter)
(e)Trust(Higherisbetter)
Fig.8. SubjectiveMeasuresinExperiment1.Meansrepresentedasdots.
APreprint 19Le,etal.
(a)(C1)Recommendation-driven (b)(C2)AIexplanationonly
Fig.9. AnexamplequestioninC1andC2.TheonlydifferenceisthatinC1,participantscanseetheAIprediction(i.e.lowpricein
thiscase)andtheweightofevidence(theexplanation)forthatprediction.InC2,theAIpredictionishidden.Therefore,eventhough
theparticipantscanseetheexplanation,theydonotknowwhichclass(low/medium/high)theevidencerefersto.
APreprint 20TowardsthenewXAI:AHypothesis-drivenApproach
Fig.10. AnexamplequestioninC3.ThehousefeaturesselectedaresimilartotheexamplequestioninFigure9.Weshowparticipants
theevidenceforallhypotheses(low,mediumandhigh),andthehousefeaturesbeforetheevidenceasshowninFigure9.Wedo
notgivethemtheAIprediction.Specifically,wehavesupportiveevidenceinmostfeaturesforhypothesislow.Bycontrast,strongly
negativeevidencerefutehypothesishigh.Thecorrectanswerhereislow.
APreprint 21