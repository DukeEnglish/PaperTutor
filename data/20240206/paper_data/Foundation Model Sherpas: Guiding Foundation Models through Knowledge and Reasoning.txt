Foundation Model Sherpas:
Guiding Foundation Models through Knowledge and Reasoning
DebarunBhattacharjya, JunkyuLee, DonJovenAgravante, BalajiGanesan and Radu
Marinescu
IBMResearch
debarunb@us.ibm.com,{Junkyu.Lee,Don.Joven.R.Agravante}@ibm.com,
bganesa1@in.ibm.com,radu.marinescu@ie.ibm.com
Abstract withusers’preferencesfortheoutput,intermsofthetaskat
hand.Arecentposterchildforthisgeneraldirectionisthere-
Foundation models (FMs) such as large language
inforcementlearningwithhumanfeedback(RLHF)paradigm
modelshaverevolutionizedthefieldofAIbyshow-
ofChatGPT,wherehumanfeedbackisfirstusedtolearnre-
ingremarkableperformanceinvarioustasks.How-
wardmodelsofthegeneratedoutputandsubsequentlylever-
ever,theyexhibitnumerouslimitationsthatprevent
agedforgeneratingfutureoutput[Stiennonetal.,2020].
theirbroaderadoptioninmanyreal-worldsystems,
There are however numerous challenges that must be ad-
which often require a higher bar for trustworthi-
dressed for FMs to be effectively aligned in many practical
nessandusability.SinceFMsaretrainedusingloss
systems. Firstly, there may be multiple users and user per-
functions aimed at reconstructing the training cor-
sonasthatinteractwithsuchsystems,andeachuser(oruser
pusinaself-supervisedmanner,thereisnoguaran-
type)mayhavedifferentobjectivesandpreferences. Further-
teethatthemodel’soutputalignswithusers’pref-
more,datasetsthatareleveragedforpre-trainingmaybeout-
erences for a specific task at hand. In this survey
dated or generally problematic without additional guardrails
paper,weproposeaconceptualframeworkthaten-
due to concerns such as around bias and privacy. This is
capsulates different modes by which agents could
important in business problems or domains such as health-
interactwithFMsandguidethemsuitablyforaset
carewhereincorporatingdomain-specificknowledgeinvar-
of tasks, particularly through knowledge augmen-
ious forms is essential. Another issue is that of robustness;
tation and reasoning. Our framework elucidates
practical systems may need to deal with shifting data distri-
agent role categories such as updating the under-
butions, and perhaps changing external factors such as reg-
lying FM, assisting with prompting the FM, and
ulations. FMs such as LLMs are essentially token genera-
evaluatingtheFMoutput. Wealsocategorizesev-
tors,andchangingthenatureofgenerationbytrial-and-error
eral state-of-the-art approaches into agent interac-
approaches through prompt engineering or updating the FM
tionprotocols,highlightingthenatureandextentof
through simple human feedback alone is unlikely to yield
involvement of the various agent roles. The pro-
long-lastingperformanceandbuildtrust.
posed framework provides guidance for future di-
Inthissurveypaper,weintroduceaconceptualframework
rectionstofurtherrealizethepowerofFMsinprac-
whereagents/modulesthatinteractwithFMsbehaveassher-
ticalAIsystems.
pas,inthesenseofguidingFMstotackleuser-specifiedtasks.
Weemphasizehowsuchagentscanleverageknowledgeand
1 Introduction reasoning in particular. While there are several recent sur-
FoundationModels(FMs)andinparticularLargeLanguage vey papers on related subjects, such as prompt engineering
Models (LLMs) have revolutionized AI [Bommasani et al., in FMs [Liu et al., 2021; Dong et al., 2023], knowledge en-
2021;Hanetal.,2021]. Theyarecurrentlyatthecoreofsev- ablement in FMs [Wei et al., 2021; Zhen et al., 2022; Pan
eralproductsthattouchmillionsofusersonanalmostdaily et al., 2023], reasoning in FMs [Huang and Chang, 2023;
basis. However,inspiteofalltheirpromise,FMs/LLMsare Qiaoetal.,2023],andinstancesofaugmentationofFMs[Mi-
knowntosufferfromimportantlimitationsthatpreventtheir alonetal.,2023],ourframeworkdiffersinthatitemphasizes
broaderadoption,includinglackoftraceability,interpretabil- therolesplayedbyvariousagentsastheyinteractwithFMs
ity, formal reasoning, ability to easily incorporate domain to pursue user-specified tasks. Emphasizing an agent’s role
knowledge,andgeneralizabilitytonewenvironments. helpsindefiningitsmotivatingobjectivesandgoals.
Toalleviatesomeofthewell-knownissueswithFMs,there Intheremainderofthispaper:
hasbeenatrendtowardstryingtoensurealignmentofFMs– • We distinguish the scope of our ideas from some ongoing
atermborrowedfromtheAIsafetyliterature[Amodeietal., effortsthatincorporateagentsintosystemswithFMs.
2016]. SinceFMsaretrainedthroughlossfunctionsthatare • Weintroducethesherpasframework,whichcategorizesthe
intended to generate the training corpus in a self-supervised purpose of various agents, going well beyond the generic
manner, there is no guarantee that the model’s output aligns roleof‘augmentation’. Wedescribehowthespecificroles
4202
beF
2
]IA.sc[
1v20610.2042:viXraintheframeworkconnecttoselectedrecentwork;thisdis- output (completion), which may be subsequently evaluated
tinguishes our survey from other related surveys, which orotherwiseprocessed. Solvingataskmayrequiremultiple
typically focus solely on either a specific role (such as in- FMcalls,andtheremaybeanopportunitytoleverageexter-
volving prompting), or technical approach for augmenta- nalknowledgeand/orreasoningviaoneormoresherpas. In
tion(suchasthedeploymentofknowledgegraphs). the remainder of this section, we categorize sherpa roles in
• We show how selected state-of-the-art approaches invoke thetask-solvingprocessandprovidesomepointerstorelated
a combination of some of the agent roles from the frame- work. Sherpasmaybehumansormachinesorinvolvesome
work, through a categorization based on the extent of for- combinationthereof.
mal reasoning involved. We also highlight further oppor- Intheremainderofthissection,wedescribethepurposeof
tunities for new types of interaction and collaboration be- eachsherpacategoryandprovideacoarsesub-categorization;
tweenagents,withorwithouthumaninvolvement. these are intended to be sufficiently illustrative but not fully
• Webrieflymotivateavisionforafuturewheretheproposed comprehensive, given the space limitations and rapidly ex-
guidingagentsaretrulyautonomousagentsratherthansys- panding literature on foundation models. Note that in most
temmodules,inthattheyexhibitkeybehaviorsuchasbe- currentwork,manyofthesefunctionsareperformedbymod-
ingproactive,reactive,interactive,andcollaborative. ulesofsystems.Figure2providesasummarydepictionofthe
While our exposition hinges primarily around LLMs, the high-leveltaxonomy,alongwithsomeexamplereferences.
ideas apply generally to all FMs. This includes models
3.1 FMUpdaters
trainedonotherdatamodalitiesbeyondtext,suchasimages,
video, audio, code, tabulardata, knowledgegraphs, timese- FM Updatersaresherpasthatmodifytheunderlyingtrans-
riesdata,spatiotemporaldata,andevenmulti-modaldata. former or how the FM generates tokens by using external
memory or models, to improve performance or better align-
2 AgentsandFoundationModels mentwithuserpreferencesforaspecifictask. Weprovidea
fewillustrativeexamplesfromthefollowingfourbroadcate-
There is an increasing interest in work at the intersection of gories.
agent-basedperspectivesandsystemsincorporatingFMs.For
ModifiedPre-training
instance,anapproachinspiredbyMinsky’s‘societyofminds’
Various approaches modify the manner in which an FM is
leveragesmultiplelanguagemodelinstances(oragents)that
pre-trained. An important family of these agents performs
individually propose and jointly debate their responses and
knowledge infusion into an FM, which has been shown to
reasoningprocessestoarriveatananswer[Duetal.,2023].
help in downstream tasks. For instance, additional pre-
Another approach pursues a communicative agent frame-
training of a flan-T5 model on sentences generated from
work called “role playing” that utilizes inception prompting
Wikidatatriples[Agarwaletal.,2021]orusingthetriplesdi-
toguidechatagentsintaskcompletion,generatingconversa-
rectly[Moiseevetal.,2022]helpedwithquestion-answering.
tionaldataforstudyingmulti-agentcooperativebehaviors[Li
etal.,2023a]. Fine/Instruction-tuning
Recentstrideshavealsobeenmadeinorchestrationframe- Perhaps the most common approach is through fine-tuning
works, which seamlessly integrate FMs into various appli- a pre-trained FM with labeled data. An important sub-class
cations and workflows. An example is Langchain [Chase, ofsuchagentsperformsfine-tuningusingdatathatisgener-
2022], which enables systems that couple LLMs with tools ated from intelligent prompt choices. For instance, a series
and APIs such as code execution and knowledge retrieval. of work uses intermediate verbal reasoning (‘rationales’) in
Another recent software framework effort that complements prompts to improve task performance [Rajani et al., 2019;
our own vision is AutoGen [Wu et al., 2023] – a program- Cobbe et al., 2021; Zelikman et al., 2022]. An approach
maticorchestrationlayerthatallowsdeveloperstobuildFM- popularizedbyChatGPTleveragesreinforcementlearningto
based applications using a collection of ‘agents’ to solve learnapolicynetworkforoutputgenerationwithrewardsig-
tasks more effectively. These agents can operate in various nalscollectedfromfeedbacks [Stiennonetal.,2020;Baiet
modes and involve combinations of several different LLMs, al.,2022;Geetal.,2023]. Wenotethatsuchapproachesalso
human input, as well as employ tools and APIs (similar to involvePrompt Assistantsherpas.
Langchain). Our perspective here is consistent with these
Augmented/EditedModels
frameworks but also emphasizes agent roles beyond that of
A broad category of agents modifies generation through ar-
orchestration. Furthermore,westresstheautonomyofagents
chitectural augmentation or proxies during inference, or by
andwhatweconsidertobedesirableagent-likebehavior;we
directly editing the model weights. For instance, adapters
do not regard tools/APIs to be agents in that sense, unlike
have been proposed to achieve similar effects as compared
theseotherframeworks.
to knowledge infusion, using parameter efficient fine-tuning
ratherthanadditionalpre-training[Wangetal.,2021;Diaoet
3 AgentRolesintheSherpasFramework
al.,2023].Analternateapproachisknowledgeediting,which
Figure 1 depicts components of the sherpas framework, dis- involves modifying the weights of the original model to in-
tinguishingbetweenvarioustypesofagentsinhowtheyguide corporate any changed facts [De Cao et al., 2021; Mitchell
anFMasitaddressesasetoftasks. Ingeneral,ataskisex- etal.,2022a]. Proxytuning[Liuetal.,2024]isanapproach
ecuted as follows: an input (prompt) such as a sequence of thatemulatesablack-boxLLMwithoutchangingthemodel’s
wordsisprovidedtoanFM,whichisinvokedtogeneratean weights.Figure1: ThesherpasframeworkforguidingFMs,showingvariousagentcategorieswithrespecttotheirtypicalpointsofinteractionwith
theFMasitexecutesorassistscompletionofasetoftasks.
ControlledGeneration amplescontainapatternoftheimplicitinstructionthatFMs
Some agents perform controlled generation by modifying must follow. This is often referred to as in-context learning
the manner in which tokens are generated without neces- andithasspurredalotofresearch[Minetal.,2022a,b;Ru-
sarily changing the underlying FM. For instance, Zhong et bin et al., 2022]. In tasks where a small dataset or some la-
al.[2023]proposeanalternateapproachwhichdoesnotup- beledexamplesareavailable,thesecanbedirectlyusedinthe
date the LLM but instead generates a tentative response and prompt as a source of knowledge. Chain-of-thought (CoT)
checks if the output contradicts updated facts in external prompting[Weietal.,2021;Kojimaetal.,2022]isanimpor-
memory. tant part of in-context learning prompts, where the research
focus has been on elicitive prompts that guide FMs by de-
3.2 PromptAssistantsandSequencers composingataskintosmallertasks.
Prompting is the primary mode of interacting with FMs,
DecomposedPrompts
and Prompt Assistants help with the process of
prompt engineering. We refer to these agents as Prompt ExtendingtheCoTidea,Prompt Sequencersareframe-
Sequencers when multiple calls are made to an FM for worksthatsequentiallycallFMstosolvesub-tasks. Thede-
a task, requiring several prompts to be composed and se- composition itself can also be done by FMs [Zhou et al.,
quenced. Empirical studies have shown that good prompts 2023; Khot et al., 2023]. Taking this idea even further, the
offer FMs highly informative content and specific seman- sub-taskdecompositioncanbeturnedintographicalmodels,
tic meanings in pre-defined templates. Two broad cate- linkingthislineofresearchtoformalreasoningmethods. For
gories of basic prompting have emerged: instruction-based example,languagemodelcascades[Dohanetal.,2022]pro-
andexample-based. Wealsohighlightdecomposedprompts poses a probabilistic programming language paradigm that
asanimportantevolutionofinstruction-basedprompts. treats question-answering tasks as a graphical model over
string-valued random variables for prompt inputs and LLM
Instruction-basedPrompts outputs,therebyunifyingvariousprompt-basedreasoningap-
These prompts contain explicit directions for what the user proaches[Weietal.,2022;Creswelletal.,2022].
feels the FM should do. This is very intuitive and the main Prompt Assistants typically combine different
mode of using FMs. It is perhaps also the main reason for strategies because empirically they often synergize. In the
the widespread use of LLMs, because of how easy it is to broaderpicture,promptsarealsotheprimarywaytoconnect
write instructions in natural language. Prompt instructions withotheragents;thisfeaturesmoreheavilyinSection4.
canbefurthersubdividedintotwosub-classes: task-prompts
and system-prompts. Task-prompts are those which contain 3.3 AssessorsandExplainers
direct instructions about a task to accomplish (e.g. “write a
Assessors evaluate output generated from an FM along
poem”). On the other hand, system-prompts offer broader
oneormoreattributesforatask,includingbutnotlimitedto
guidelines or style (e.g. “pretend you are a fantasy novel
measures of quality of generation, such as fluency, or those
writer”). ConstitutionalprinciplesinBaietal.[2022]arean-
fortrustworthiness,suchasharmfulness,factuality,etc. Such
otherexampleofsystemprompts. Prompt Assistants
attributes should ideally have the following properties: 1)
oftenusebothofthesesub-classestogetherforbettereffect.
they should be pertinent to the users’ values for the task(s),
In-contextLearningPrompts 2)theyshouldbeclearlydefined,and3)theyshouldbemea-
Thesecondmajorcategoryofpromptingusesexamplesofthe surable. Human feedback is of course a valuable source for
taskintheprompt. Insteadofexplicitinstructions,theseex- evaluating such attributes, but there is also a recent trend ofFigure2:Arelativelyhigh-leveltaxonomyoffourmajorsherpacategories,alongwithsomeillustrativeexamplereferences.
leveragingothermodels(sometimesotherFMs)asassessors. amethodforprobingLLMswithknowledgegraphsformea-
Wedistinguishbetweenselectedpriorworkbasedontheat- suringandimprovingthefactualityofLLMs.
tributebeingassessed.
Consistency. ConCORD [Mitchell et al., 2022b] is an ex-
GenerationQuality/PerformanceRelated ample of an approach that evaluates the consistency of FM
generated output. It formulates a self-consistency measure
There are several well-known attributes and associated met-
as a compatibility score in a probabilistic model over the
ricsthatareintendedtoassessvariousfacetsofthequalityof
candidate question-answer pairs queried from LLMs. Note
anFM’sgeneratedoutput.ForLLMs,theseincludeattributes
thatconsistencyandfactualityarecloselyrelated,asconsis-
of the generated language, such as fluency (as measured by
tencyasksforinvariantoutputsrelativetosemanticallysim-
perplexity),coherence(asmeasuredbyBLEU/ROUGE),rel-
ilarrephrasedinputs,whilefactualityrequiresconsistentbe-
evanceorcontextawareness(asmeasuredbytheBERTscore
haviorrelativetogroundtruthoutputs[Elazaretal.,2021].
or mutual information), or the ambiguity of the output (as
measuredbyaccuracy). Someassessorstrytoevaluatemet- Uncertainty/Confidence. An important class of
ricsthatarepertinenttotheperformanceofthetaskathand. Assessors performs uncertainty quantification to es-
For instance, they may assess whether or not FM generated timate measures such as the variability or confidence of
codewillexecuteorfail[Prasadetal.,2023],ormeasurethe the FM output [Lin et al., 2022; Kuhn et al., 2022]. These
progressmadebythecurrentstatefromasequenceofgener- have been further categorized as verbalized, where the FM
atedFMoutputwithregardtowhetherithasthepotentialto providesconfidencescoresdirectly,ornon-verbalized,where
answertheuser’squery[Yaoetal.,2023a]. confidence is inferred by other means such as gauging the
consistencyoftheoutputafterparaphrasingtheinputprompt.
TrustworthinessRelated
Hallucination. FMs are widely known to generate output
Thefollowingattributesarepertinenttohelpgaugethetrust-
thatareconsideredhallucinations(orconfabulations). Huang
worthinessofthegeneratedoutput:
et al. [2023] categorizes them as either input-conflicting,
Harmfulness/Toxicity. FMs such as LLMs are known to where the output deviates from user-provided source input,
occasionally generate content that may be deemed toxic context-conflicting, where the output conflicts with previ-
or harmful by users. The RLAIF approach [Bai et al., ously generated information by itself, and fact-conflicting,
2022] extends reinforcement learning from human feedback where the output is not faithful to established world knowl-
(RLHF) by generating harmful datasets through chain-of- edge. Notethatfact-conflictinghallucinationcanbeassessed
thought prompting using a pre-defined collection of critique byfactualitymeasures,asdescribedpreviously.
rules;theintentionistogenerateoutputthatisdeemedtobe
Bias. SinceanFM’strainingdataoftenreflectsstereotypes
helpfulyetharmless.Inthiswork,theassessedscoreisbased
anddiscriminatorybeliefsaboutgender,race,andothersoci-
oncrowdworkerpreference.
etalfactors,assessingsuchbiasescouldbeusefulindeploy-
Factuality/Faithfulness. Generating output that is factual mentssuchaschatbots[Zhaoetal.,2023b].
orfaithfulrelativetosomeknowledgereferenceisoftenben- Explainers are an important class of agents related to
eficialinpractice. Forlarge-scalerepetitiveevaluationofFM Assessors, and help provide explanations about the out-
outputs, leveraging external knowledge such as knowledge put of FMs; we refer the reader to a complementary survey
graphscanbefruitful,sincetheyoffereasilyinterpretableand paper which reviews relevant advances [Zhao et al., 2023a].
structuredinformation.LAMA[Petronietal.,2019]presents Explainability has another connection to assessment of FMoutput–criticalapplicationssometimesneedanexplanation LLMtogenerateverbalreasoningtracesandactionspertain-
fortheevaluation,notjusttheevaluationitself. Forinstance, ingtoaspecifictaskinaninterleavedmannerwhilealsoal-
ausermayappreciatereceivingrecordsinaknowledgebase lowing for interactions with specific environments that may
thatprovideevidenceforafactualityassessment. be subsequently incorporated into reasoning. We also in-
clude systems such as BINDER [Cheng et al., 2023] and
3.4 KnowledgeCurators ChatDB [Hu et al., 2023] that interact with a Python inter-
Many AI systems that incorporate FMs require access to preterforcodeexecutionoranSQLengineforretrieval.
sourcesofknowledge,suchasstructuredinformationinare-
FlexibleVerbalReasoning
lationaldatabaseoranunstructuredcorpusofdomainknowl-
Analternatelineofworkexploresorchestrationthatincorpo-
edge. Thisnecessitatestheinvolvementofanoftenneglected
ratesmoreflexibilityintoverbalreasoning,possiblybymim-
categoryofagents,whichcurateknowledgefromappropriate
icking formal reasoning. Several state-of-the-art approaches
sources with the intent of supporting the FM towards han-
use a branching structure in decomposed prompts to guide
dlingthetask(s)ofinterest.
the FM. The ADaPT system [Prasad et al., 2023] allows in
Knowledge Curators play a particularly important
additionfortaskdecomposition(orplanning)totacklemore
rolethroughtheirinteractionwithotherguidingagents. For
complextasks. Suchabranchingstructurecanappearindif-
instance,theyareneededforAssessorsthatrelyonexter-
ferent forms, such as simple decomposition [Radhakrishnan
nalknowledgetoprovideareferenceforfactuality[Petroniet
et al., 2023], tree-structures with search [Yao et al., 2023a],
al., 2019]. They are also crucial for many FM Updaters.
orfullgraphs[Bestaetal.,2023].
Forinstance,theyareneededbyretrieval-augmentedgenera-
tive models [Lewis et al., 2020], which combine pre-trained FormalReasoning
language models with a non-parametric memory (such as a An upcoming class of approaches uses an FM to support a
densevectorindexofWikipedia). symbolic reasoner to solve a set of tasks. Some examples
We also include in this broader category agents that are includeLMcascades[Dohanetal.,2022]andPLoT[Wong
able to suitably extract information from FMs, whenever it et al., 2023], which both integrate FMs into a probabilistic
is beneficial for the application. Since FMs memorize a lot programminglanguageparadigm. Theseframeworksarede-
of facts, this class of Knowledge Curators helps ac- scribedinmoredetailinalatersection.
quire and maintain an FM’s inherently stored knowledge in We anticipate that all these research avenues will
more structured forms. Due to the prevalence and simplic- flourish in the future, with a growing interest in au-
ityofknowledgegraphs,therehavebeennumerouseffortsto tonomous Orchestrators of various types, including
extract them from LLMs [Bosselut et al., 2019; West et al., work that leverages other kinds of formal reasoning (such
2022;Haoetal.,2023b]. Thereisalsoupcomingresearchon as logical or decision-theoretic) for orchestration. Since
acquiringotherrepresentationsofknowledge,suchasfinite- OrchestratorsplayaspecialroleinFM-guidedAIsys-
state automata [Yang et al., 2023] and causal models [Ar- tems, we rely on them heavily for the categorization in the
senyanandShahnazaryan,2023;Kıcımanetal.,2023;Long nextsection.
etal.,2023;Shietal.,2023]. Knowledge Curatorsof
thistypecanaidanAIsystembybeingsuitablyleveragedin 4 AgentInteractionProtocols
futurerelevanttasks.
Inthissection,wecategorizeexistingframeworksthatguide
3.5 Orchestrators FMsbasedoninteractionprotocolsthatweclassifyintofour
categories: Update FM with External Knowledge, Access
Real-worldAIsystemsoftenrelyonOrchestrators(or
Tools for Information Retrieval, Explore Dynamic Prompts,
Controllers)tomanagepotentiallycomplexworkflows. Cur-
andIntegrateExternalReasoners. Thesecategorieshighlight
rent approaches in the literature highlight interactions with
commonscenariosthatspanmostcurrentapproaches.
externaldatasources,toolsandapplicationsinparticular. We
have previously described the burgeoning interest in frame-
4.1 UpdateFMwithExternalKnowledge
works to manage such workflows, including Langchain and
AutoGen. Weclassifytheseintothreehigh-levelcategories, The simplest interaction protocol can be seen in frame-
primarily based on the manner in which formal reasoning is works for updating foundation models with external knowl-
mimickedorleveragedfortheprocessoforchestration.
edgefromKnowledge Curatororfeedbackfromusers.
RLHF [Stiennon et al., 2020] uses human Assessors
ToolingInteractionFocused for the output of FMs, incorporating the feedback as a re-
AnimportantlineofresearchstudiestheuseofLLMstodi- ward model for fine-tuning. RLAIF [Bai et al., 2022] ex-
rectly generate domain-specific actions or plans in interac- tends RLHF by revising harmful responses from red team-
tiveenvironments. Manyoftheseeffortsattempttocombine ing prompts through a nuanced self-assessment of harm-
‘verbal reasoning’ and ‘acting’ for solving diverse language lessness based on user-provided constitutional principles
reasoninganddecisionmakingtasks;sincetheyputmoreof with Prompt Assistant that utilizes in-context learn-
theonusontheLLMformanagingworkflows,thisreduces ing. Since fine-tuning a large FM is costly, more recent
theloadoftheOrchestrator,whichistypicallyonlyleft work proposes augmenting smaller external models without
with executing actions such as calling tools/APIs. For in- modifying the underlying FM [Liu et al., 2024; Wang et
stance,theReActframework[Yaoetal.,2023b]promptsan al., 2021; Diao et al., 2023]. In this category, we observePaper FMUpdater PromptAssistant Assessor KnowledgeCurator Orchestrator
RLHF[Stiennonetal.,2020] Fine-tuning Instruction-based BinaryReward(Human) - -
RLAIF[Baietal.,2022] Fine-tuning In-contextlearning Harmfulness(Human) - -
KGInfusion[Agarwaletal.,2021] ModifiedPre-training - - Knowledgegraphs -
K-ADAPTER[Wangetal.,2021] AugmentedModels - - Wikipedia -
MixDA[Diaoetal.,2023] AugmentedModels - - Domainknowledge -
RAG[Lewisetal.,2020] ControlledGeneration - - Wikipedia -
IRCoT[Khotetal.,2023] - In-contextLearning - Wikipedia/Corpus -
ReAct[Yaoetal.,2023b] OptionalFine-tuning In-contextLearning Factuality(Verbal) Webdocuments APICalls
LLMAugmenter[Pengetal.,2023] ControlledGeneration Instruction-based Factuality(Human) Webdocuments APICalls
ChemCrow[Branetal.,2023] - In-contextLearning Factuality(Human) Chemistryexpertknowledge APICalls
BINDER[Chengetal.,2023] - In-contextLearning Executeorfail(Formal) - APICalls
ToT[Yaoetal.,2023a] - DecomposedPrompts Progress(Verbal) - Comb.search
GoT[Bestaetal.,2023] - DecomposedPrompts Progress(Verbal) - Comb.search
ADaPT[Prasadetal.,2023] - DecomposedPrompts Executeorfail(Verbal) - Comb.search
RAP[Haoetal.,2023a] - DecomposedPrompts Progress(Verbal) - Comb.search
Reflexion[Shinnetal.,2023] - DecomposedPrompts Progress(Verbal) - RL
LMCascade[Dohanetal.,2022] - In-contextLearning Factuality(Formal) - Prob.reasoning
CONCORD[Mitchelletal.,2022b] - Instruction-based Consistency(Formal) OtherLMs -
PLoT[Wongetal.,2023] - Instruction-based Factuality(Formal) - Prob.reasoning
LARK[ChoudharyandReddy,2023] - Decomposedprompts - Knowledgegraphs KGreasoning
CoK[Lietal.,2023b] - Instruction-based Factuality(Formal) Externalknowledge Querylanguages
Table 1: Illustrative frameworks for four categories of agent interaction protocols are shown in the rows. Values in the columns for five
categoriesofsherpasarechosenasfollows. ForFMUpdaterandPromptAssistant,categoriesareshown. ForAssessor,theattributebeing
assessedisshown,alongwiththesourceofassessment(Humanreferstohumanfeedback,VerbalreferstodirectassessmentfromanFM,
andFormalreferstotheuseofformalreasoning).ForKnowledgeCurator,thesourceoftheknowledgeisshown.ForOrchestrator,themain
role/approachtakenisshown.
that Orchestrator plays no significant role since inter- the input. Searching for better combinations of inter-
action is a simple pre-defined workflow from Knowledge mediate thoughts, Orchestrator coordinates Prompt
CuratororAssessortoFM Updater. Assistant/Sequencer to decompose the prompts and
combine thoughts as a new input prompt for querying the
4.2 AccessToolsforInformationRetrieval FM, essentially implementing a combinatorial search over
thespaceofallpossiblecombinationsofgeneratedthoughts
For open-domain questions, FMs often show poor perfor-
[Yao et al., 2023a; Besta et al., 2023]. In addition to com-
mance since it may be not possible to generate the desired
posingthoughts, Haoetal.[2023a]andPrasadetal.[2023]
answersolelyfromtheinputprompt. Manypracticalframe-
showhowtodefineprompttemplatesforgeneratingthestate
works enable retrieving relevant information from web doc-
information in planning problems given a problem descrip-
umentsorotherapplicationspecificdatathroughpre-defined
tionwiththeinitialstate,goalstates,andsetofactions.
APIcalls[Lewisetal.,2020;Chase,2022].Theoverallagent
interaction can be programmed in advance and Prompt Compared with the frameworks that access tools with a
Assistantequippedwithstaticprompttemplatescankeep pre-defined interaction programmed as a chain of static API
interactingwithKnowledge Curatorandstoreretrieved calls, the frameworks in this category exhibit more dynamic
and complex interaction behavior. Many of the frameworks
informationinexternalmemorytogeneratethefinalanswer.
inthiscategoryhaveseveralprompttemplatesthatareasso-
The API calls can also be controlled by checking the factu-
ality of the results, and Orchestrator can repeat the in- ciated with a component of search procedure such as node
teraction based on pre-defined programs. Peng et al. [2023] generation, node evaluation, or node selection. A template
of prompts is grounded to a fully instantiated prompt dur-
propose a control flow similar to a reinforcement learning
ing search. A particularly popular interaction protocol is
agent that generates a feedback reward from a model-based
Assessorthatevaluatesfactualityoftheoutcome. Branet
thatPrompt Assistantgeneratessuccessorstatesinthe
al.[2023]exploreorganicsynthesis,drugdiscovery,andma-
statespace,Assessorevaluatesthequalityofthestategen-
erated by the FM, and Orchestrator controls a search
terialdesignbycombiningdomainexpertisewithFMs.User-
strategy such as Monte carlo tree search, local search, or a
specifiedscientifictasksaretackledbyprovidingasequence
reinforcementlearningcontrolloop.
of prompts in a simple reasoning-based format to GPT-4,
where one of 17 tools can be called upon; these could be as
basicaswebsearch,butalsoincludeAssessorsforcheck- 4.4 IntegrateExternalReasoners
ingwhetheramoleculehasbeenpatented.
All the previous categories primarily rely on the reasoning
capability of an FM, aiming to address tasks by infusing
4.3 ExploreDynamicPrompts
additional domain knowledge, accessing external tools, or
In many few shot in-context learning prompting ap- composing prompts to explore a suitable search space. The
proaches, an FM generates intermediate thoughts that lastcategoryfollowsanalternateapproachthatintegratesex-
lead to the answer following static examples provided in ternal reasoning engines into Assessor or performs sym-
MFetadpU
slooTsseccA
stpmorP.nyD
renosaeR.txEbolicinferencetoextendKnowledge Curatorgoingbe- • Multi-objective and Joint Optimization Paradigms. Many
yondinformationretrieval. Forinstance,Dohanetal.[2022] interaction protocols are aimed at improving performance
proposeslanguagemodelcascades, aprobabilisticprogram- measures such as accuracy, but it may be desirable to op-
ming language paradigm that formulates natural language timizeoverabroadersuiteofobjectives, suchasrun-time
question-answering tasks as a graphical model over string- costs,levelofharmfulness,orsocialbias,usingquantified
valued random variables associated with prompt inputs and measures from Assessors. Also, it may be prudent to
FM outputs, thereby unifying various prompt-based reason- jointlyoptimizeovermultiplesherpas; forexample,ifhu-
ing approaches. Mitchell et al. [2022b] also formulates a man feedback is limited, there is a question around which
consistency Assessor as probabilistic inference. PLoT sherpathatfeedbackmayassistmostmeaningfully.
[Wong et al., 2023] integrates verbal reasoning by an FM • Broader Role for Automated Assessors. The interaction
with symbolic reasoning by translating the natural language protocolsforaccessingtoolsorexploringdynamicprompts
input as code using Prompt Assistant and solving an heavily rely on human feedback or verbal reasoning by
inferencetaskusingaprobabilisticprogrammingframework FMs. FormalAssessorscouldsavethecostofcollect-
–Church[Goodmanetal.,2008]. Thereareframeworksthat ing user feedback or replace less credible verbal reason-
integratereasoningsystemsotherthanprobabilisticprogram- ingAssessors. Furthermore,FM Updaterscoulddi-
ming,suchasprogramminglanguages[Chengetal.,2023]or rectly query formal assessors and go beyond information
knowledgegraphreasoning[ChoudharyandReddy,2023]. retrievaltocontrolgenerationofmoretrustworthyoutputs
duringruntime. Similarly,Prompt Assistantscould
5 DiscussionandFutureDirections dynamically generate optimized prompts by incorporating
feedbackfromAssessorsinanautomatedmanner.
WediscussavisionwhereFMguidingsherpashavemoreau-
• UncertaintyQuantificationAssessors. Whileexploringthe
tonomy,andhighlightvarioustopicareasforfutureresearch.
search space of dynamic prompts, there is potential in us-
5.1 AgentBehaviorsforIntelligentFMSherpas ing uncertainty quantification Assessors for informing
search, so as to evaluate the predicted outcome or even
Much has been written about the properties of agents and
prunethesearchspacewithoutwastingvaluableresources
their categorization, as well as behaviors they need to ex-
byaccessingFMs.
hibittobedeemedautonomous,smart,orintelligent. Atypi-
• Formal Reasoning Orchestration. There is scope for in-
caldefinitionforanintelligentagentis: “acomputersystem
tegrating formal reasoners directly into dynamic Prompt
situated in some environment and that is capable of flexible
Assistantstoprovidemoreaccurateanddiversefeed-
autonomous action in this environment in order to meet its
backtoFMs.
design objectives” [Jennings and Wooldridge, 1998]. Con-
• NovelModesofKnowledgeEnablement. Agentsshouldbe
sideringaweaknotionofagency[WooldridgeandJennings,
abletoinfuseknowledgefromtext,tabulardataandgraphs
1995], we envision agents exhibiting autonomy (operating
more seamlessly. Effective use of knowledge through FM
withoutthedirectinterventionofhumansorotheragents),in-
Updaters and Knowledge Curators is still cur-
teractivity (interacting with other agents including humans),
rentlyunderexplored,inourview.
reactivity (responding to perceived changes in the environ-
• Humans in the Loop. The current literature merely
ment), and pro-activity (taking the initiative based on their
scratches the surface of human involvement, such as for
motivations).Wealsoregardcollaboration(workingtogether
Knowledge CuratorsorAssessors.Thereisroom
towardscommongoals)asasuitableendeavor.
formoresophisticatedpreferenceelicitationschemesfrom
WhilestrongernotionsofagencymaybedesirableforFM
users that go beyond the ‘thumbs up/down’ feedback ap-
sherpas in the future, we believe that even weak agent be-
proach of RLHF. Interaction of FM sherpas with humans
havior is beneficial for practical systems. For instance, au-
tonomy is a useful feature for an Assessor, enabling it throughactivelearningwillbeafruitfulpursuit.
• Benchmarks. There is a need for newer benchmarks that
to operate continuously without direct human intervention.
AnOrchestratormustinteractwithvariousotheragents, emphasizethebreadthofasystem’sabilitiesasopposedto
task-specificperformance[Geetal.,2023;Yuetal.,2023],
including humans, since practical problems may need plan-
whichwillundoubtedlyresultinsignificantinnovationsin
ning adjustments based on clarifications or requested feed-
back. Reactivity may also be key; consider an Assessor sherpasandhighlighttheirpower.
thatneedstoleveragechangesinusersoruserpersonas. An-
other example is a pro-active Knowledge Curator that 6 Conclusions
actively seeks out and reports appropriate knowledge in an Inthispaper,wesurveyedrepresentativeapproachesforguid-
enterprise,suchasthepossibilityofregulatorychanges. ing FMs with knowledge and reasoning using a conceptual
frameworkthatelucidatestheroleofguidingagents. Wecat-
5.2 FutureDirections
egorizedinteractionprotocolsintofourmajorgroups,empha-
Althoughtherehavebeensignificantrecentadvancesaround
sizingtheimportanceandopportunitiesaroundcollaboration
guidingFMs,numerousopenproblemsandopportunitiesre-
of agents with different roles. Systems that can smartly and
main. Ourproposedagentinteractioncategoriescanhelpin-
jointly leverage such guiding agents would go a long way
form future protocols with more complex and nuanced in-
towards ensuring long-term usability and trustworthiness in
teractions, including through sherpas that are equipped with
real-worldapplications.
strongeragency. Somepotentialdirectionsfollow:References YingqiangGe,WenyueHua,KaiMei,etal. OpenAGI:WhenLLM
meetsdomainexperts. arXiv:2304.04370,2023.
Oshin Agarwal, Heming Ge, Siamak Shakeri, et al. Knowledge
graphbasedsyntheticcorpusgenerationforknowledge-enhanced Noah D. Goodman, Vikash K. Mansinghka, Daniel Roy, et al.
languagemodelpre-training. InProceedingsoftheConference Church: a language for generative models. In Proceedings of
oftheNorthAmericanChapteroftheAssociationforComputa- theConferenceonUncertaintyinArtificialIntelligence,2008.
tionalLinguistics:HumanLanguageTechnologies,2021.
Xu Han, Zhengyan Zhang, Ning Ding, et al. Pre-trained models:
DarioAmodei,ChrisOlah,JacobSteinhardt,etal. Concreteprob- Past,presentandfuture. AIOpen,2021.
lemsinAIsafety. arXiv:1606.06565,2016.
ShiboHao,YiGu,HaodiMa,etal.Reasoningwithlanguagemodel
Vahan Arsenyan and Davit Shahnazaryan. Large language mod- isplanningwithworldmodel. InProceedingsoftheConference
elsforbiomedicalcausalgraphconstruction. arXiv:2301.12473, onEmpiricalMethodsinNaturalLanguageProcessing,2023.
2023.
ShiboHao, BowenTan, KaiwenTang, etal. BertNet: Harvesting
YuntaoBai,SauravKadavath,SandipanKundu,etal.Constitutional knowledge graphs with arbitrary relations from pretrained lan-
AI:HarmlessnessfromAIfeedback. arXiv:2212.08073,2022. guagemodels. arXiv:2206.14268,2023.
Maciej Besta, Nils Blach, Ales Kubicek, et al. Graph of Chenxu Hu, Jie Fu, Chenzhuang Du, et al. Chatdb: Aug-
thoughts: Solvingelaborateproblemswithlargelanguagemod- menting llms with databases as their symbolic memory.
els. arXiv:2308.09687,2023. arXiv:2306.03901,2023.
Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, et al. On the Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in
opportunitiesandrisksoffoundationmodels.arXiv:2108.07258, largelanguagemodels: Asurvey. InFindingsofAssociationfor
2021. ComputationalLinguistics,2023.
AntoineBosselut, HannahRashkin, MaartenSap, etal. COMET: LeiHuang,WeijiangYu,WeitaoMa,etal.Asurveyonhallucination
Commonsensetransformersforautomaticknowledgegraphcon- inlargelanguagemodels: Principles,taxonomy,challenges,and
struction. InProceedingsoftheAnnualMeetingoftheAssocia- openquestions. arXiv:2311.05232,2023.
tionforComputationalLinguistics,2019.
Nicholas R. Jennings and Michael J. Wooldridge, editors. Agent
Andres M Bran, Sam Cox, Andrew D White, and Philippe Technology:Foundations,Applications,andMarkets. 1998.
Schwaller. Chemcrow: Augmentinglarge-languagemodelswith
TusharKhot,HarshTrivedi,MatthewFinlayson,etal.Decomposed
chemistrytools. arXiv:2304.05376,2023.
prompting: A modular approach for solving complex tasks. In
Harrison Chase. Langchain. https://github.com/langchain-ai/ InternationalConferenceonLearningRepresentations,2023.
langchain,October2022.
Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, et al. Large
Zhoujun Cheng, Tianbao Xie, Peng Shi, et al. Binding language languagemodelsarezero-shotreasoners. InAdvancesinNeural
models in symbolic languages. In International Conference on InformationProcessingSystems,2022.
LearningRepresentations,2023.
LorenzKuhn,YarinGal,andSebastianFarquhar. Semanticuncer-
Nurendra Choudhary and Chandan K Reddy. Complex logical tainty: Linguisticinvariancesforuncertaintyestimationinnatu-
reasoning over knowledge graphs using large language models. rallanguagegeneration.InInternationalConferenceonLearning
arXiv:2305.01157,2023. Representations,2022.
KarlCobbe,VineetKosaraju,MohammadBavarian,etal. Training Emre Kıcıman, Robert Ness, Amit Sharma, and Chenhao Tan.
verifierstosolvemathwordproblems. arXiv:2110.14168,2021. Causal reasoning and large language models: Opening a new
frontierforcausality. arXiv:2305.00050,2023.
AntoniaCreswell,MurrayShanahan,andIrinaHiggins. Selection-
inference:Exploitinglargelanguagemodelsforinterpretablelog- Patrick Lewis, Ethan Perez, Aleksandra Piktus, et al. Retrieval-
icalreasoning. arXiv:2205.09712,2022. augmentedgenerationforknowledge-intensiveNLPtasks.InAd-
vancesinNeuralInformationProcessingSystems,2020.
NicolaDeCao,WilkerAziz,andIvanTitov. Editingfactualknowl-
edgeinlanguagemodels. InEmpiricalMethodsinNaturalLan- Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, et al.
guageProcessing,2021. Camel: Communicative agents for” mind” exploration of large
scalelanguagemodelsociety. arXiv:2303.17760,2023.
Shizhe Diao, Tianyang Xu, Ruijia Xu, et al. Mixture-of-domain-
adapters: Decoupling and injecting domain knowledge to pre- XingxuanLi,RuochenZhao,YewKenChia,etal. Chainofknowl-
trainedlanguagemodelsmemories. arXiv:2306.05406,2023. edge: A framework for grounding large language models with
structuredknowledgebases. arXiv:2305.13269,2023.
DavidDohan,WinnieXu,AitorLewkowycz,etal.Languagemodel
cascades. InWorkshopBeyondBayes: PathsTowardUniversal Stephanie Lin, Jacob Hilton, and Owain Evans. Teaching models
ReasoningSystems,2022. toexpresstheiruncertaintyinwords. TransactionsonMachine
LearningResearch,2022.
Qingxiu Dong, Lei Li, Damai Dai, et al. A survey on in-context
learning. arXiv:2301.00234,2023. PengfeiLiu,WeizheYuan,JinlanFu,etal. Pre-train,prompt,and
predict: A systematic survey of prompting methods in natural
Yilun Du, Shuang Li, Antonio Torralba, et al. Improving factual-
languageprocessing. arXiv:2107.13586,2021.
ityandreasoninginlanguagemodelsthroughmultiagentdebate.
arXiv:2305.14325,2023. AlisaLiu,XiaochuangHan,YizhongWang,etal. Tuninglanguage
modelsbyproxy. arXiv:2401.08565,2024.
YanaiElazar,NoraKassner,ShauliRavfogel,etal. Measuringand
improvingconsistencyinpretrainedlanguagemodels. Transac- Stephanie Long, Tibor Schuster, and Alexandre Piche´. Can large
tionsoftheAssociationforComputationalLinguistics,2021. languagemodelsbuildcausalgraphs? arXiv:2303.05279,2023.Gre´goireMialon,RobertoDess`ı,MariaLomeli,etal. Augmented Xiaokai Wei, Shen Wang, Dejiao Zhang, et al. Knowledge en-
languagemodels:Asurvey. arXiv:1606.06565,2023. hanced pretrained language models: A compreshensive survey.
arXiv:2110.08455,2021.
Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettle-
moyer. Noisy channel language model prompting for few-shot JasonWei,XuezhiWang,DaleSchuurmans,etal.Chain-of-thought
textclassification. InProceedingsoftheAssociationforCompu- prompting elicits reasoning in large language models. In Ad-
tationalLinguistics,2022. vancesinNeuralInformationProcessingSystems,2022.
Sewon Min, Xinxi Lyu, Ari Holtzman, et al. Rethinking the role Peter West, Chandra Bhagavatula, Jack Hessel, et al. Symbolic
of demonstrations: What makes in-context learning work? In knowledge distillation: From general language models to com-
ProceedingsoftheConferenceonEmpiricalMethodsinNatural monsensemodels.InNorthAmericanChapteroftheAssociation
LanguageProcessing,2022. forComputationalLinguistics: HumanLanguageTechnologies,
EricMitchell,CharlesLin,AntoineBosselut,etal. Memory-based 2022.
modeleditingatscale. InInternationalConferenceonMachine LionelWong,GabrielGrand,AlexanderKLew,etal. Fromword
Learning,2022. modelstoworldmodels:Translatingfromnaturallanguagetothe
Eric Mitchell, Joseph Noh, Siyan Li, et al. Enhancing self- probabilisticlanguageofthought. arXiv:2306.12672,2023.
consistency and performance of pre-trained language models MichaelWooldridgeandNicholasR.Jennings. Intelligentagents:
throughnaturallanguageinference.InEmpiricalMethodsinNat- Theoryandpractice. TheKnowledgeEngineeringReview,1995.
uralLanguageProcessing,2022.
QingyunWu,GaganBansal,JieyuZhang,etal. Autogen:Enabling
Fedor Moiseev, Zhe Dong, Enrique Alfonseca, and Martin Jaggi. next-gen llm applications via multi-agent conversation frame-
SKILL:Structuredknowledgeinfusionforlargelanguagemod- work. arXiv:2308.08155,2023.
els. InNorthAmericanChapteroftheAssociationforComputa-
Yunhao Yang, Jean-Raphae¨l Gaglione, Cyrus Neary, and Ufuk
tionalLinguistics:HumanLanguageTechnologies,2022.
Topcu.Automaton-basedrepresentationsoftaskknowledgefrom
ShiruiPan,LinhaoLuo,YufeiWang,etal. Unifyinglargelanguage generativelanguagemodels. arXiv:2212.01944,2023.
modelsandknowledgegraphs: Aroadmap. arXiv:2306.08302,
Shunyu Yao, Dian Yu, Jeffrey Zhao, et al. Tree of thoughts:
2023.
Deliberate problem solving with large language models.
BaolinPeng,MichelGalley,PengchengHe,etal. Checkyourfacts arXiv:2305.10601,2023.
and try again: Improving large language models with external
knowledgeandautomatedfeedback. arXiv:2302.12813,2023. ShunyuYao,JeffreyZhao,DianYu,etal. React: Synergizingrea-
soningandactinginlanguagemodels. InInternationalConfer-
FabioPetroni,TimRockta¨schel,SebastianRiedel,etal. Language
enceonLearningRepresentations,2023.
modelsasknowledgebases? InEmpiricalMethodsinNatural
LanguageProcessingandtheInternationalJointConferenceon Jifan Yu, Xiaozhi Wang, Shangqing Tu, et al. KoLA: Care-
NaturalLanguageProcessing,2019. fullybenchmarkingworldknowledgeoflargelanguagemodels.
arXiv:2306.09296,2023.
ArchikiPrasad,AlexanderKoller,MareikeHartmann,etal. Adapt:
As-needed decomposition and planning with language models. Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. Star:
arXiv:2311.05772,2023. Bootstrappingreasoningwithreasoning. AdvancesinNeuralIn-
formationProcessingSystems,2022.
ShuofeiQiao,YixinOu,NingyuZhang,etal. Reasoningwithlan-
guagemodelprompting:Asurvey. arXiv:2212.09597,2023. HaiyanZhao,HanjieChen,FanYang,etal. Explainabilityforlarge
language models: A survey. ACM Transactions on Intelligent
AnshRadhakrishnan,KarinaNguyen,AnnaChen,etal. Question
SystemsandTechnology,2023.
decompositionimprovesthefaithfulnessofmodel-generatedrea-
soning. arXiv:2307.11768,2023. Jiaxu Zhao, Meng Fang, Shirui Pan, et al. GPTBIAS: A compre-
hensiveframeworkforevaluatingbiasinlargelanguagemodels.
Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and
arXiv:2312.06315,2023.
RichardSocher. Explainyourself! leveraginglanguagemodels
forcommonsensereasoning. InAnnualMeetingoftheAssocia- Chaoqi Zhen, Yanlei Shang, Xiangyu Liu, et al. A sur-
tionforComputationalLinguistics,2019. vey on knowledge-enhanced pre-trained language models.
arXiv:2212.13428,2022.
OhadRubin,JonathanHerzig,andJonathanBerant. Learningtore-
trievepromptsforin-contextlearning. InNorthAmericanChap- Zexuan Zhong, Zhengxuan Wu, Christopher D Manning, et al.
ter of the Association for Computational Linguistics: Human MQuAKE:Assessingknowledgeeditinginlanguagemodelsvia
LanguageTechnologies,2022. multi-hopquestions. arXiv:2305.14795,2023.
XiaomingShi,SiqiaoXue,KangruiWang,etal. Languagemodels Denny Zhou, Nathanael Scha¨rli, Le Hou, et al. Least-to-most
can improve event prediction by few-shot abductive reasoning. promptingenablescomplexreasoninginlargelanguagemodels.
arXiv:2305.16646,2023. InInternationalConferenceonLearningRepresentations,2023.
NoahShinn,FedericoCassano,AshwinGopinath,etal. Reflexion:
Languageagentswithverbalreinforcementlearning.InAdvances
inNeuralInformationProcessingSystems,2023.
NisanStiennon,LongOuyang,JeffWu,etal. Learningtosumma-
rize from human feedback. In Advances in Neural Information
ProcessingSystems,2020.
Ruize Wang, Duyu Tang, Nan Duan, et al. K-adapter: Infusing
knowledge into pre-trained models with adapters. In Findings
oftheAssociationforComputationalLinguistics,2021.