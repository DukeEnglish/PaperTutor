Supporting Anticipatory Governance usingLLMs:Evaluating and Aligning
LargeLanguage Modelswiththe NewsMediatoAnticipate the Negative
Impacts of AI
MOWAFAKALLAHAM,NorthwesternUniversity,USA
NICHOLASDIAKOPOULOS,NorthwesternUniversity,USA
AnticipatingthenegativeimpactsofemergingArtificialIntelligence(AI)technologiesisachallenge,especiallyintheearlystagesof
development.AnunderstudiedapproachtosuchanticipationistheuseofLargeLanguageModels(LLMs)toenhanceandguidethis
process.DespiteadvancementsinLLMsandevaluationmetricstoaccountforbiasesingeneratedtext,itisunclearhowwellthese
modelsperforminanticipatorytasks.Specifically,theuseofLLMstoanticipateAIimpactsraisesquestionsaboutthequalityand
rangeofcategoriesofnegativeimpactsthesemodelsarecapableofgenerating.Inthispaperweleveragenewsmedia,adiversedata
sourcethatisrichwithnormativeassessmentsofemergingtechnologies,toformulateataxonomyofimpactstoactasabaseline
forcomparingagainst.Bycomputationallyanalyzingthousandsofnewsarticlespublishedbyhundredsofonlinenewsdomains
aroundtheworld,wedevelopataxonomyconsistingoftencategoriesofAIimpacts.Wethenevaluatebothinstruction-based(GPT-4
andMistral-7B-Instruct)andfine-tunedcompletionmodels(Mistral-7BandGPT-3)usingasamplefromthisbaseline.Weexamine
thegeneratedimpactsforcoherence,structure,relevance,andplausibilityandfindthatthegeneratedimpactsusingMistral-7B,a
smallopen-sourcemodelfine-tunedonimpactsfromthenewsmedia,tendtobequalitativelyonparwithimpactsgeneratedusing
amorecapableandlargerscalemodelsuchasGPT-4.Moreover,wefindthattheseLLMsgenerateimpactsthatlargelyreflectthe
taxonomyofnegativeimpactsidentifiedinthenewsmedia,howevertheimpactsproducedbyinstruction-basedmodelshadgaps
intheproductionofcertaincategoriesofimpactsincomparisontofine-tunedmodels.Thisresearchhighlightsapotentialbiasin
state-of-the-artLLMswhenusedforanticipatingimpactsanddemonstratestheadvantagesofaligningsmallerLLMswithadiverse
rangeofimpacts,suchasthosereflectedinthenewsmedia,tobetterreflectsuchimpactsduringanticipatoryexercises.
ACMReferenceFormat:
MowafakAllahamandNicholasDiakopoulos.2024.SupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLarge
LanguageModelswiththeNewsMediatoAnticipatetheNegativeImpactsofAI.1,1(February2024),23pages.https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION
EmergingArtificialIntelligence(AI)technologiescanhaveadetrimentalimpactonindividualsandsociety[50],though
negativeimpactscansometimesbemitigatediftakenintoaccountearlyinthedesignprocess[5,43].Onewaytodo
soisthroughanticipatoryapproaches[8]whichseektoenumeratearangeofplausiblerisksandconsequencesofa
technologyandhowitmayimpactsociety,andthenorientstakeholderstotakeresponsibilityforavertingpotential
bad outcomes [14, 30, 48]. Anticipating the negative impacts of a fast-moving emerging technology such as AI is
difficultforavarietyofreasonsincludingthedeepentanglements andinteractioneffectswiththesocialworldsof
Authors’addresses:MowafakAllaham,mowafakallaham2021@u.northwestern.edu,NorthwesternUniversity,P.O.Box1212,Evanston,Illinois,USA,
43017-6221;NicholasDiakopoulos,nad@northwestern.edu,NorthwesternUniversity,P.O.Box1212,Evanston,Illinois,USA,43017-6221.
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents
ofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton
serversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ManuscriptsubmittedtoACM
ManuscriptsubmittedtoACM 1
4202
naJ
13
]LC.sc[
1v82081.1042:viXra2 MowafakAllahamandNicholasDiakopoulos
human behavior and policy.Doing iteffectively requiresa deepunderstanding ofanAIsystem’s development life
cycleincludingdesign,training,anddeployment[40].Italsodemandsarobustmechanismtoforeseeawiderange
ofplausibleimpactsandminimizetheuncertaintyaroundtheunintendedconsequencesofAIsystemsonpeopleand
institutions[29,39].
Recent efforts towardsanticipating the potential risks and harms ofAI systems have overwhelmingly relied on
experts’perspectives[5,32,38,51].Yetexpertbiasesmayinfluencetheforesightprocessandcanleadtoadistorted
viewofthefuture[6].LargeLanguageModels(LLMs)havealsorecentlybeenexploredfortheirpotentialabilityto
expandtherangeofnegativeimpactsconsideredbyAIresearchersanddevelopers[10],thoughtheyalsosufferfrom
concernsaboutthenatureandextentofthebiasesthatmaybecapturedbytheirtrainingdataandsoreflectedinthe
generatedtext[33,42].Therefore,theuseofLLMstohelpanticipatenegativeimpactsofAIraisesquestionsaround
theoverallqualityofthegeneratedimpacts,whatcategoriesofnegativeimpactsdifferentlargelanguagemodelsare
capableofgenerating,andhowgeneratedimpactsaredistributedwithrespecttothoseimpactcategories.
Inthisworkwe addressthesequestionsbyexploring and evaluating in greater depththepotentialofLLMs for
anticipatingthenegative impactsofAI.First,weuseGPT-3.5-turbo-16Ktodefineabaseline taxonomyofnegative
impactsthatcouldbecausedbyAIsystemsbyleveraging alargeanddiversecorpusofdescriptionsofAIimpacts
drawnfromthenews media. Althoughnews mediareflects itsown set ofnormative biases aboutwhatisselected
forcoverage and howAIiscovered, weuseitasabaseline thatcapturesabroadrangeofsocietalconcernsabout
AItechnologies.Inaddition,thiscorpusprovidesareadysourceofmaterialthatcanbeusedforevaluationpurposes
in termsofwhether certainimpactscan beanticipated basedonthe technical and contextualdescription ofan AI
systempresentedinanewsarticle.Wethenevaluatethecapabilitiesofseveralmodelsforanticipatingimpactswith
respecttothisbaseline,examiningbothzero-shotpromptingandfine-tuningtoassesshowdifferentapproachesand
models may shape the categories and distribution of impacts generated. More specifically, this research addresses
questions about the quality and categories of impacts generated by LLMs by qualitatively evaluating the negative
impactsgeneratedbyclosed-source(e.g.GPT-4)andopen-source(e.g.Mistral-7B-Instruct)instruction-basedmodels
withrespecttothecategoriesofimpactspresent inthenewsmediacoverageofAI.Wealsoextendthisevaluation
toassesswhethercompletionmodels(Mistral-7BandGPT-3)fine-tunedonnegativeimpactsfromnewscoverageof
AIacross266onlinenewsdomainsin30countriescancaptureamorecomprehensiverangeofcategoriesofnegative
impactswhencomparedtoimpactsgeneratedusinginstruction-basedmodels.
Basedonouranalysis,wemakethreemaincontributions.First,wecontributeataxonomyofAIimpactsidentified
fromthenews media. A diversely sampled set ofnews mediaoffers abroadnormative baseline fortheevaluation
of AI impacts identified in society, enabling researchers and practitioners to consider a range of AI impacts. This
taxonomyincludes10categoriesofimpacts:SocialandEthicalImpacts,EconomicImpacts,Privacy,Safety,Potential
HarmsofAI,AIGovernance,AccuracyandReliability,AI-generatedContent,Security,andMiscellaneousRisksand
ImpactsofAI.Thistaxonomyisthenusedasabaselinetocompareandevaluatethegeneratednegativeimpactsfrom
variousmodelstothoseinthenewsmedia.Second,wehighlightapotentialbiasinstate-of-the-artLLMswhenusedfor
anticipatingimpacts.Specifically,bothclosed-sourceandopen-sourceinstruction-basedmodelstendtomisscategories
ofnegativeimpactscoveredinthenewsmediacomparedtoLLMsfine-tunedonnegativeimpactsfromthenewsmedia.
Inaddition,qualitativeassessmentofgeneratedimpactsacrossthefourdimensionsofcoherence,structure,relevance,
andplausibilityshowsthatsmalleropen-sourcemodelssuchasMistral-7Bfine-tunedonnegativeimpactsfromnews
media tend to generate negative impacts that are qualitatively comparableto those generated using a larger scale
modelsuch asGPT-4. Third,our findings suggest that fine-tuning smaller open-sourceLLMs like Mistral-7B,with
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 3
verylimitedcomputeresources,onadiversedatasourcesuchasthenewsmediacancoverarangeofcategoriesof
negativeimpactsrelevanttoAItechnologiesbeyondtheonesanticipatedusingamuchlargerandcapableLLMsuch
asGPT-4.Thesefindings contributetoresearch onanticipatoryethics[31] bypaving thewaytobroadenaccess to
toolsthatcouldbeusedinsupportingtheanticipationofnegativeimpactsofAIinsociety.Moreover,thequantitative
metricsof qualityand thebenchmarks ofperformanceacross different modelsthat we present may help to orient
futuredevelopmentofsuchtools.
2 RELATEDWORK
2.1 AnticipatingImpacts
Anticipating AI impacts helps practitioners and domain experts articulate, and potentially mitigate, the social and
ethicalimplicationsofemergingtechnologiesbasedontheircontextualuseandfunctionalcapabilitiesandaffordances
[29, 31]. While it is difficultto consider all potential impactsof new technologies due to uncertainty [31], various
methodologicalapproacheshavebeenproposedtoenablepractitionerstoanticipateandforeseefailuresandpotential
impactsoftechnologiesthathavenotyetbeenobservedorthatmayoccurinnewcontexts.
Expertinvolvementintheanticipatoryprocesshasbeenconsideredtobeessentialinsomeanticipatorymethods
[4,40].Forinstance, researchers proposedco-designing achecklist withpractitionerstohelpidentify andmitigate
againstpotentialissuesofthesystemsthatareunderdevelopment[27].However,suchchecklistshavebeencriticized
forbeingbroadandfailingtoconsiderdifferencesbetweentechnologies,applications,andstakeholdersaspartofthe
evaluationprocess[25].Expertpeerreview isanother approachthathasbeenexploredbygrant-awarding entities
[3]andacademicconferencessuchasNeurIPs[32]requestingresearchers toincludeanimpactassessment oftheir
workorwriteaboutthepotentialimpactsofthetechnologiestheyareresearching.Someresearcharguesthatsuch
initiativesmaynotbethemosteffectivewaytoassesstheimpactofAIsystems[20]becausetheymaysufferfrom
inadvertentexpertbias,demographicallyskewedbackgrounds,andhomogenousexperiencesofexperts[7,12].
Morerecenteffortsinparticipatoryethicshaveleveragedthecognitivediversityofthecrowdsrecruitedthrough
AmazonMechanicalTurkinanticipatingthesocialimpactsofautomatedandalgorithmicdecision-makingsystems
[2].However,researchhasfoundthattheperceptionandunderstandingofAI,aswellasthesocialimpactsaroundits
use,tendtobemarkedlydifferentacrossgeographicalsettings[16,23].Accordingly,whileparticipatoryapproaches
involvingcrowdsourcingimpactsprovideamorediversealternativetoexpertopinionsinanticipatingimpacts,they
stilloverlooktheculturalandsocio-technicalfactorsofthecrowdswhicharelikelytoreflectonlythetypesofimpacts
deemedrelevantandimportanttothecultureandcountrythecrowdsbelongto.Despitetheefficacyofthegrowing
methodsinanticipatoryandparticipatoryforesightinAIethics,manyofthesemethods,suchastheonesdescribed
earlier,donotassistAIsystemsdesignersanddevelopersinforeseeingtheimpactsofAItechnologiesearlierinthe
developmentlifecycleandbeforethedeploymentofthesetechnologies.
Inresponsetosomeofthesechallenges,researchershavebeguntoexploretheuseofLargeLanguageModelsinthe
anticipatoryprocess.Forinstance,AHA!(AnticipatingHarmsofAI)isagenerativeframeworkthatleveragesGPT-3
toautomatethegenerationofvignettestoelicitexamplesofthepotentialharmsofAIonstakeholdersbasedonthe
descriptionandsetofproblematicbehaviorsprovidedbyusers[10].Ingeneral,ifsuchapproachesaretobeviableand
gainuseinanticipatorygovernanceapproaches,moreevaluationisneededtoassesstheoverallqualityoftheresults.
Inthiswork,basedonpriorevaluationstudiesofgeneratedtextandofqualitycriteriaappliedinotheranticipatory
approaches[14,21,41,46]wedevelopasetofqualitativecriteriarelatedtoimpactcoherence,structure,relevance,and
ManuscriptsubmittedtoACM4 MowafakAllahamandNicholasDiakopoulos
plausibilitythathelptoevaluateandarticulateefficacy.Moreover,LLMshavebiasesbasedonpotentialunbalanced
andselectionbiasesthatexistinthedatasetstheyaretrainedon[33,42]whichcouldpotentiallyinfluencethescope
of impactsthey generate. Accordingly, it is crucial toassess the categories ofimpacts these modelsare capable of
generatingwithrespecttoabaselinetaxonomyofimpactstodeterminetheefficacyofLLMsforsupportingadiverse
setofanticipations.Inthenextsection,weprovideanoverviewofexistingresearchcontributingtothedevelopment
oftaxonomiesofimpactsusingvariousdatasources.
2.2 TaxonomiesofAIImpacts
TaxonomiesofimpactsprovideasystematicwaytoaidtheassessmentofAIandalgorithmicsystemsfromasocio-
technicalperspective,particularlywithrespecttowhoandwhatthesetechnologicalaffordancesmayimpact[1,39].
Theabsenceoftaxonomiesofimpactsinevaluationguidelinespresentschallengesforpractitionersinformulatinga
comprehensiveassessmentofanAIsystem[36,39],especiallythosethathavemultiplemodalitiesandcanperform
differenttasksacrossmanyusecasessuchasgenerativeAI.
ExpertshaveproducedtaxonomiesoftherisksandharmsofAIsystemsbasedontheirunderstandingofthefunc-
tionalcapabilitiesofthesesystems[5,43],theirdomainofuse[2,24],therealizedimpactsofthesetechnologies[32,40],
andthesocio-technicalevaluationofthesesystems[5,37,39,50].Someresearchershaveturnedtothenewsmediato
assesstherisksandbenefitsofAIbyanalyzingthenewscoverageofAIintheU.S[11].Otherinitiatives,suchastheAI
IncidentsDatabase,sourceharmeventsfrompublicdocumentsincludingmanynewsarticlestodevelopataxonomy
ofAIharms[19].Thesevariouseffortsreflectdifferenttypologiesofhigh-levelcategoriesofimpactsthataremostly
basedonexistingrisksandharms,thoughsome[51]differentiateobservedvs.anticipatedrisks.
Inthisworkweleanintothepotentialofferedbydevelopingataxonomyofimpactsbasedonthenewsmedia.Wedo
thisforafewreasons.Firstly,newsmediareflectstheapplicationofasetofprofessionalnewsvaluesthatareusedby
practitionersinmakingjudgementsaboutwhateventsintheworldwarrantdevelopmentintonewsitems[17].These
newsvaluesreflectnormsamongstprofessionalsaboutwhatkindsofoutcomesorbehaviorsofAImaybedetrimental
andthereforewarrantpublicscrutinyandattention.Inshort,theeditorialdecisionsofnewsmediacontributetothe
co-constructionofAIimpactsinsociety[29].Secondly,newsmediaprovidesacontinuouslyupdatingsourceofdata
reflectingsociety’sevolvingnormswithrespecttowhatconstitutesAIimpact.Thus,weexpectthattaxonomiesbuilt
onnewsmediashouldbemoreadaptiveovertimeincomparisontoexpertlyproducedtaxonomies.Finally,it’sworth
notingthatnewsmedia,likeanyotherbasisforcreatingataxonomy,reflectsitsownbiasesgroundedinthevarious
personal,organizational,andinstitutionalforcesshapingthemedia.Wedonotclaimthatataxonomybuiltfromnews
mediaistheonlyorbesttaxonomy,onlythatitwarrantsattentionandhasbeneficialpropertieswhenbuiltfroma
broadsample,andwhenconsideredovertime.ThepresentresearchfocusesondescribingataxonomyofAIimpacts
inthenewsmediaand usestheidentifiedcategoriesofimpactstoevaluateandfine-tuneLLMsinanticipating the
negativeimpactsofAI.
3 DATACOLLECTIONANDPROCESSING
3.1 CuratingAI-relevantkeywordsfromnewsmedia
ToconstructourdatasetofnewsarticlescoveringAIanditsnegativeimpacts,wefirstdevelopedalistofkeywords
relevanttoAItechnologiesandapplicationstohelpfocusoursearch.WestartedbyusingtheNewYorkTimes(NYT)
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 5
developersearchandarchiveAPIendpoints1,toretrieve612articlesonAIpublishedbytheNYTbetweenJanuary2017
andMay2023,inclusive,basedontwobroadseedsearchwords("A.I.",and"ArtificialIntelligence").Wethenscraped
thetextforeachitemandextractedalistofn-grams(uni-gram,bi-gram,andtri-gram)whichindicatecommonlyused
wordsforcoveringAItechnologiesintheNYT.Bymanuallyselectingthen-gramsrelevanttoAIandAItechnologies,
weidentifiedalistof31relevantkeywordsspanningnumeroustopicsrelevanttoAI.Tofurtherexpandthecompre-
hensivenessofthecuratedlistofAI-relevantkeywords,wealsoscrapedthefulltextof2,724articlesassociatedwith
529incidentsbetweenJanuary2017andJune2023thatarerelevanttoAIfromtheAIIncidentDatabase,whichcurates
newsitemsandotherreportsindicatingAIfailuresintherealworld2[28].Usingthesamen-gramextractionmethod
mentionedearlier,weidentifiedninenewkeywordsthatdidn’toverlapwiththe31alreadyfound.Thisbroughtthe
totalnumberofthecuratedkeywordsupto40.Afulllistofthekeywordsisprovidedintheappendix10.1.Next,we
describehowthesekeywordswereusedtoscrapenewsarticlesrelevanttoAI.
3.2 Scraping&FilteringNewsArticles
WeusedGoogleNewstosearchandretrieveallarticlesbasedonthecuratedsetofAI-relevantkeywords.Foreach
keyword inthecuratedlist,wesent asearchrequesttoGoogleNews viaclientURL (cURL)containing thesearch
keywordanddaterange(betweenJanuary1st,2020untilJune1st,2023)topullarticlesfrom.Usingthismethodwe
retrievedtheURL,title,anddomainforeachnewsarticle.ThetotalnumberofretrievedarticlesfromGoogleNews
basedonthecuratedlistofkeywordsis665,965articles.Wesuccessfullyscrapedfull-textcontentfor89.4%(595,371)
outof665,965retrievedarticles.Outofthose,240,850(approximately40.45%)articlesfrom11,980domainshadatleast
oneexactmatchtoourlistofkeywords.Wefurtherfocusthisdatasetonthetop5%(402)ofdomainsinoursample
thatpublishedatleast100articlesormore.Weobservedthatnotall402domainsarefromnewsmedia.Therefore,we
excludedfromourdatasetallnon-mediadomainssuchasgovernmentagencies,academicinstitutions,orenterprise
blogs.Asaresult,thefinaldatasetconsistsof91,930articlesthatwerepublishedonAIby266domainsfrom30countries
aroundtheworldbetweenJanuary1,2020andJune1st2023,inclusive.
4 METHODS
This section describes the methodologyfor developing a taxonomy of AI impacts as well as anticipating negative
impactsusingLLMsandqualitativelyevaluatingthem.TodevelopataxonomyofnegativeimpactsofAIcoveredin
thenewsmedia,wefirstextractedtheimpactsofAIfromournewsarticlesdatasetusinganLLMandclusteredthem
intooverarchinggroups.Weappliedsentimentanalysisonthecentroidsentenceofeachclustertoidentifytheclusters
withnegativeimpactsandfilteroutclusterswithpositivesentiment.Theremainingcentroidsentences,representing
clustersofnegativeimpactsofAI,werethenusedtocreateataxonomyofnegativeimpactsofAIascoveredinthenews
mediabyusingtopicmodeling.Finally,wemapthetopicassignedtoeachclustertothesetofsentencesrepresenting
eachclustertoanalyzethetypesandprevalenceofnegativeimpactsinthenewsmedia.Next,wedescribeeachstep
indetail.
1https://developer.nytimes.com/docs
2https://incidentdatabase.ai
ManuscriptsubmittedtoACM6 MowafakAllahamandNicholasDiakopoulos
4.1 DevelopingaTaxonomyofNegativeImpactsfromNewsMedia
WechoseGPT-3.5-16K-turbo3toextractthenegativeimpactsofAIthatareexplicitlymentionedinthearticles.Our
choicewasdrivenbythelackofclassifierstrainedtodiscernimpactdescriptionsofAImentionedinnewsarticlesand
thepossibilityofhavingmultipleimpactsdescribedineacharticle.Also,themodel’slargecontextwindowenabled
ustoembedthefullarticletextinthepromptcontext.
AsshowninpromptP1,inTableS1,themodelwillindicateifanarticledoesnotstateordiscussnegativeimpactsin
itstext.Articleswithnonegativeimpactsextractedwereexcludedfromfurtheranalysisasourresearchquestionsare
orientedtowardsthenegativeimpactsofAItechnologiescoveredinthenewsmedia.Thisleftuswith17,590articles.
Insomecases,multipleimpactdescriptionsareextractedfromasinglearticleandeachimpactdescriptionreceives
anentryinourdatasetlinking ittothearticleitwasextractedfrom.Intotal45,949impactdescriptionswerethus
extractedfromthenewsarticles.
Tofurtherrefinethedatatowardsnegativeimpacts,wefilteroutclustersofimpactdescriptionsthattendtobeposi-
tive.Todothisweidentifyclustersofimpactdescriptionthataresimilartoeachotherandthenanalyzethesentiment
ofthecentroidsentencerepresentingeachclusterwhichweuseasaproxymeasureforfiltering.Tocluster,weusedthe
fast-clusteringalgorithmfromthesentence-transformerslibrary4,aclusteringalgorithmtunedforlargedatasetsthat
usesdistance-basedmetricssuchascosine-similaritytoestablishlocalcommunitiesofhighlysimilarsentences.The
twoconfigurablehyperparametersforthisalgorithmareminimumcommunitysizeandsentencesimilaritythreshold.
We configured these valuesto5 and 0.7,respectively so that lessprominent negative impactsin thenews are still
representedinoursampleandwepreservethelongtail(andthusdiversity)ofimpactdescriptionsinthedata.The
45,949impactdescriptionswereclusteredinto3,782clusters.
Todeterminewhichclusterscontainnegativeimpactdescriptions,wecalculatedthesentimentscoreforeachcen-
troidsentencecorrespondingtoeachclusterusingSiEBERT[18].Weselectedallclusterswithcentroidsentencesthat
hadanegative sentiment scoreofatleast0.9,tocapturearangeofnegative impactsthatarereportedinthenews
mediawhilestillfocusingtowardsdescriptionsthathaveahighlynegativetendency.Usingthismethodwefiltered
out774clustersrepresenting8,260impactdescriptions,leavinguswith37,689impactdescriptionsfrom17,590articles
groupedinto3008clusters.
TomakesenseoftheclustersatscaleweuseBERTopic[15],atopicmodelingtechniquethatleveragestransformers
tocreateeasilyinterpretabletopicsdescribingthemajorthemesofnegativeimpactscoveredinoursample.Weapply
BERTopiconthegroupofcentroidsentencesrepresentingthe3008clusters.
TorunBERTopiconthecentroidsentences,weconfiguredthemin_topic_sizeandzero_shot_min_similarityto10
and0.9,respectivelytokeepthethenumberoftopicslowandhaveahigherconfidencescoreinassigningatopicto
sentences.Theresultingsetoftentopicswerethenmanuallylabeledbasedonthekeywordspertopicandthreerep-
resentativeexamplesfromeachtopicthatareprovidedbyBERTopicfromthecentroidsentences.Finally,wemapped
themanuallylabeledtopicsbacktothe37,689negativeimpactdescriptionsrepresentingthe3008clusters.
4.2 AnticipatingNegativeImpactsofAI
WetransformourdatasettoalsoincludedescriptionsofthefunctionalcapabilitiesandcontextualuseofAItechnolo-
giesdescribedinthenews.Thisallowsustobuildadatasetthatconnectsthesefunctionaldescriptionstotheimpact
descriptionsandfacilitateslaterfine-tuning.Thisapproachalsoprovidesanopportunitytotranslatedocumentsfrom
3https://platform.openai.com/docs/models
4www.sbert.net
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 7
othersourcesintothisintermediaterepresentationbeforeinferencingnegativeimpacts,thusfacilitatingawiderarray
ofpotentialdownstreamdeploymentcontexts.Wesplitthenewsarticledatasetintotraining,validation,andtesting
subsetsforfine-tuningandzero-shotgenerationofnegativeimpacts.Thesubsequentsectionsprovideanelaboration
ofthesesteps.
Weextractedthefunctionalcapabilitiesandcontextualuseofthetechnologiesmentionedineacharticlediscussing
negativeimpactsofAI.Similartothemethodologyfollowedinsection4.1toextractnegativeimpactsofAItechnologies
inthenewsmedia,weemployGPT-3.5-turbo-16Ktopromptitfortheextractionofthefunctionalcapabilitiesofthe
technologyasmentionedineacharticle,aswellascontextualaspectsofthetechnology’sdomainofuse,stakeholders
involved,andpotentialusersofthetechnologywhomightbenegativelyimpactedbythetechnology(seeAppendix
10.3forexamples).ToimprovethequalityofthegeneratedtextbytheLLMandreducehallucinations,wesetthemodel
temperatureto0.1tobemoredeterministicandalsoinstructedthemodeltodosomereasoningbeforegeneratinga
responsebythinkingstep-by-stepfollowingtheproposedChainofThought(CoT)promptstructure[26].Thefinal
prompttemplateasshowninP2inTableS1wasusedtopromptthemodeltoextractfunctionalcapabilitiesandthe
contextualuseofAItechnologies.
Afterextractingandsynthesizingthedescriptionsofthetechnologiesandtheircontextualuseasmentionedineach
article,weorganizedthedatasetsothateachdescriptionofatechnologyispairedwitheachnegativeimpactforthat
technologythatisidentifiedinthesamearticle.Curatingthedatasetinthisformatenablesustofine-tunemodelsto
generateasingleimpactdescriptionbasedonafunctionaldescriptionofanAItechnology.Thefinaldatasetincludes
37,689pairsofdescriptionsandnegativeimpactofAItechnologiesfrom17,590articles.Thiscurateddatasetwassplit
intotraining(N=32,035),validation(N=5,140),andtestingdatasets(N=514).Thetrainingandvalidationdatasetswere
usedforfine-tuningandthetestingdatasetwasusedtoevaluatethefine-tunedmodelsinanimpactgenerationtask.
Wedecidedtokeepthetrainingsamplelargeinordertonotintroduceadditionalbiasesintheselectionofimpactsused
forfine-tuningandtopreservethediversityofimpactsreflectedbythenewsmedia.Also,wechoseasmalltesting
sampletomakethequalitativeassessmentofthegeneratednegativeimpactsbythefine-tunedandinstruction-based
modelsmorefeasible.
ToassesstheproficiencyofLargeLanguageModels(LLMs)ingeneratingnegativeimpacts,wepromptedclosed-
source(GPT-4)andopen-source(Mistral-7B-Instruct)instructionmodelsusingzero-shotpromptingtogenerateneg-
ativeimpactsbasedonthedescriptionsofAItechnologiesinthetestdataset.WeselectedtheMistral-7B[22]model
foritssmallparameterscaleandstrongperformancethatmatchestheperformanceofmuchlargermodelssuchas
LLaMa-13B[45]onMTbenchmarkandLLaMa-34BonseveralNLPtasks.Moreover,itispossibletoruninferenceon
Mistral-7B-InstructwithlimitedcomputingresourcessuchasGoogleColab.Moreover,wefine-tunedtwocompletion
models(OpenAIGPT-3andMistral7B)onthetrainingdatasettofurthergaugethecapabilityofLLMsingenerating
negativeimpactdescriptionwithouttheneedforpromptengineering.TheselectionofGPT-3andMistral-7Bcomple-
tionmodelsforfine-tuning wasalsoduetothelackofinstructiondatasets[49]focusedonnegative impactsofAI
technologies.Inaddition,curatingarepresentative datasetforinstruction-tuningsimilartotheAlpacadataset[44]
butfornegativeimpactsofAIfallsoutofthescopeofthisresearchasitrequirescrowdsourcingandvalidatingrep-
resentativeseedquestionsfromexpertsandpractitionersthataredeemedessentialintheanticipatoryprocessofAI
impacts.
Togenerateanegativeimpactusinginstruction-basedmodels,weusedazero-shotpromptingtechnique[9]–atype
ofpromptingthatdoesnotnecessitatetheinclusionofexamplesoftasksintheprompt’scontext.TouseOpenAI’s
GPT-4modelforgeneratinganegativeimpact,weformulatedthepromptforthistaskasshowninP3,inTableS1,to
ManuscriptsubmittedtoACM8 MowafakAllahamandNicholasDiakopoulos
includeadescriptionofthefunctionalcapabilityandcontextualuseofatechnologyandaninstructiontogeneratea
singlenegativeimpactofthistechnologybasedontheprovideddescriptions.Besideslimitingthemaximumnumber
ofgeneratedtokensbyGPT-4andMistral-7B-Instructthroughsettingthemax_tokensparameterintheOpenAIAPI
andmax_lengthinthetextgenerationfunctioninHuggingFaceto25,wealsospecifiedforthemodelintheprompt
torestrictthegeneratednegativeimpacttoasinglesentenceforevaluationpurposesacrossmodelsandtomatchthe
structureofthecurateddataset.5 To generate thenegative impactsusingMistra-7B-InstructweusedHuggingFace
text-generationpipelinesandranthemodelforinferenceonanA-100GPUnotebookinstanceonGoogleColabPro+.
Forfine-tuning,wepreparedthetrainingandtestingdatasettofine-tuneGPT-3.Thedatahastobeformattedina
prompt-completionformatfollowingOpenAI’slegacyfine-tuningguide6.EachdescriptionofanAItechnologywas
usedasapromptandthenegativeimpactcorrespondingtothedescriptionsofAItechnologiesasthecompletion.Addi-
tionally,functionaldescriptionsandnegativeimpactdescriptionsinthedatasetswereappendedwith"\n\n###\n\n"
and"END"toinformthemodelwherethepromptandcompletionend,respectively.UsingOpenAIAPI,GPT-3was
fine-tunedusingOpenAI’sauto-allocatedhyperparametersasrecommendedbyOpenAI’sfine-tuningguide.Themodel
wastrainedfor2epochs,onabatchsizeof38,andlearnermultiplierisequalto2.
Tofine-tunetheMistal-7Bmodel,wehadtoreformatthedatatofitMistral’sprompt-completionformat.Descrip-
tionsofAItechnologiesandtheircorrespondingnegativeimpactswerepre-appendedby"##Input:",and"##Response:",
respectively.Weattemptedtomatchthefine-tuninghyperparametersofMistral-7BtomatchGPT-3inordertohavea
faircomparisonoftheoutputofbothmodels.Accordingly,wefine-tunedMistral-7BthroughQLoRA[13]for2epochs,
withalearningrateequalto2e-5,andatrainingbatchsizeof327.Fine-tuning ofMistralwasdoneinPythonona
GoogleColabPro+usinganA100GPUandtookapproximately4hours.
4.3 EvaluatingtheanticipatednegativeimpactsfromLLMs
Arubricwasdevelopedtoqualitativelyassess(1)whetherthegeneratednegativeimpactsbythelanguagemodelsare
actuallynegativeimpactsand(2)thequalityofthegeneratedimpactbasedonfourdimensions:coherence,structure,
relevance, and plausibility. Coherence is used to capture the comprehensibility of a generated impact in terms of
completesentencesandthementionofasingleimpactintheanticipatedimpactusingLLMs.Structuredescribesthe
extenttowhichthegeneratedimpactsaresufficientlydescriptive.Relevanceisdefinedintermsoftherelevanceofthe
negativeimpactdescriptiontothefunctionalcapabilitiesofanAItechnologyandtheentitiesinvolvedinusingit.The
plausibility[47]dimensionevaluatesthereasonablenesstoconcludethatthegenerativeimpactcouldhappengiven
whatisknownaboutthesocio-technicalworld.TheevaluationquestionsandrubricareoutlinedinAppendix10.2.In
theresultssection,wequalitativelyevaluatetheanticipatednegativeimpactsbycomparingtheirqualityacrossmodels
usingthesecriteria.Moreover,wequalitativelydescribeandcompareusingexamplesfromthegeneratedimpactshow
thecategoriesoftheanticipatedimpactsusingLLMsrelatetothebaselinetaxonomyofnegativeimpactsdeveloped
fromnewsmedia.
5Were-formattedtheprompttomatchtheexpectedformattingofMistral-7B-Instructpriortogeneratingtheimpacts.Eachfunctionaldescriptionwas
pre-appendedby<s>[INST]andpostappendedby[/INST](checkpromptP4inTableS1).Thesesequencesinformthemodelswheretheinstruction
promptstartsandwhereitends.
6https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model
7ThebitsandbyteslibrarywasusedforquantizationandPEFTforparameterefficientfine-tuning
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 9
Prompt Description
P1 Summarizethenegativeimpactsexplicitlymentionedinthefollow- PrompttoextractthenegativeimpactsofAIthatareexplicitlymen-
ingarticle.Ifnoimpactsarementionedtypeonly:##NoImpacts##. tionedinthenewsarticlesusingGPT-3.5-turbo-16K
###Article###:{Article}
P2 Inasingleparagraph,explainthefunctionalcapabilitiesofthetech- Prompttoextractfunctionalcapabilitiesandthecontextualuseof
nologydescribedinthearticle,domainofuse,stakeholders,and AItechnologiesusingGPT-3.5-turbo-16K
userswithoutmentioninganynegativeaspectsorconcerns.Focus
solelyonthetechnology’sfeaturesanditsrelevancetostakeholders
andusers.Beaccurate.Donotmakeupinformationnotdescribed
inthearticle.Let’sthinkstepbystep.###Article###:{Article}
P3 You are given a functional description of a technology delim- Promptforzero-shotgenerationofnegativeimpactsusingGPT-4.
ited by ##Description. ##Description: {functional_ and _contex- Thepromptisformulatedtoincludethefunctionalandcontextual
tual_description}.Writeasinglenegativeimpactofthistechnology descriptionsofanAItechnologyandaninstructiontogeneratea
basedontheprovidedfunctionaldescription.Limityouranswerto singlenegativeimpactofthistechnologybasedontheprovidedde-
onesentence. scriptions.
P4 <s>[INST]Describeasinglenegativeimpactofthetechnologyde- Promptforzero-shotgenerationofnegativeimpactsusingMistral-
scribedbelowanddelimitedby##Description:##Description{func- 7B-Instruct.Thepromptisformulatedtoincludethefunctionaland
tional_description}Writeasinglenegativeimpactofthistechnology contextualdescriptionsofanAItechnologyandaninstructionto
basedontheprovidedfunctionaldescription.Limityouranswerto generateasinglenegativeimpactofthistechnologybasedonthe
onesentence.[/INST]</s> provideddescriptions.
TableS1. Promptstemplatesusedtoa)extractthefunctionalandcontextualdescriptionsofAItechnologiesandtheirnegative
impactsfromthenewsmediaandb)assesstheproficiencyofGPT-4andMistral-7B-Instructinstruction-basedmodelsingenerating
negativeimpactsusingzero-shotpromptingbasedonthedescriptionsofAItechnologiesinthetestdataset.Note:Textsurrounded
bycurlybracketsisaplaceholdertextthatwasreplacedbythetextcollectedfromthenewsmedia.
5 RESULTS
Inthissection,wedescribethetaxonomyofimpactsdevelopedfromthenewsmediaandelaborateonourfindings
fromleveragingthistaxonomyasabaselineforcomparingtheanticipatedimpactsofAIusingLLMs.
5.1 TaxonomyofAIimpactsinthenewsmedia
NewsarticlesinoursamplewerepublishedbetweenJanuary2020andMay2023by266onlinenewsdomainsspanning
manyregionsandnationsaroundtheworld.Wefoundthat84%ofthe91,930newsarticlescoveringAIinoursample
werepublishedby10countries:US(37,056),India(22,104),UK(8,543),Canada(2,480),China(1,815),Australia(1,541),
UAE(1,186), Israel (1,095),Germany (770),and Turkey (668).Also,aspart ofdeveloping thetaxonomyofnegative
impactsofAIfromnewsmedia(describedinsection4.1),wefoundthat19.1%(17,590)outof91,930articlescovering
AIinoursamplediscussormentionnegativeimpactsofAI.Thisisinlinewithpreviousworkshowingthatthebenefits
ofartificialintelligencearediscussedmorefrequentlyinnewsmediathanitsrisks[11].
As outlined in section 4.1, we developed a taxonomy of negative impacts by mapping the topics generated by
BERTopicbacktothe37,689negativeimpactstatementsinoursample.Theemergingtaxonomyfromthesenegative
impactstatementsincludes10categoriesofnegativeimpactsrelatingto:SocialandEthicalImpacts,EconomicImpacts,
Privacy,MiscellaneousRisksandImpactsofAITechnologies,Safety,PotentialHarmsofAI,AIGovernance,Accuracy
andReliability,AI-generatedContent,andSafety.WefoundSocialandEthicalimpactstobethemostprevalentcat-
egoryofnegativeimpactinnewsmediaconstituting44.67%ofthe37,689statements,followedbyEconomicImpacts
(10.84%),Privacy(9.77%),MiscellaneousRisksandImpacts(8.49%),Safety(6.25%),PotentialHarmsofAI(6.21%),AI
Governance (4.62%), Accuracy and Reliability (3.20%), AI-generated Content (3.10%), and Security (2.84%). The top
threecategoriesofnegativeimpactsaccountfor65.28%ofthenegativeimpactsreportedinthenewscoverageofAI.
Next,wedescribeeachcategoryindetailasrepresentedinthenewsmediaandincludeexamplesofeachcategoryof
impact.
SocialandEthicalImpacts–Thiscategoryhighlightsarangeofnegativesocialandethicalimpactswithrespect
toAI. Forinstance, someimpactsin thiscategorydescribe thepotentialimplicationsofmisusing AI formalicious
ManuscriptsubmittedtoACM10 MowafakAllahamandNicholasDiakopoulos
purposessuchas“spread[ing]falseinformation”or“overhlem[ing]thedemocraticprocessthroughthemassivespread
ofplausiblemisinformationthroughAIsystems”.
EconomicImpacts–ThiscategorydescribesthepotentialandrealizedimpactsofusingordeployingAIacrossindus-
tries.ImpactsinthiscategorydiscussedthepotentialofAItoreplace“whitecollarjobs,includingwriters,researchers,
editors,customerserviceprofessionals”resultinginjoblossacrosstheseprofessions.Furthermore,theimpactsofAI
onjobsindevelopingcountriescouldleadtomorejoblossin“exportorientedmanufacturingandhindergrowthin
servicesectors”.
Privacy–Thiscategoryfocusesontheprivacyviolationsresultingfromusing,adopting,ordeployingAIsystems.In
particular,thiscategoryispredominantlycenteredarounddescribingtheimpactsoffacialrecognitiontechnologieson
privacysuchastheimpactsofusingfacialrecognitionin“videosurveillancesystemswithAI[to]trackandmonitor
individuals”whichcould“undermineprivacyandfreespeech”.
MiscellaneousImpactsofAI –Thiscatch-allgroupingincludesallremainingnegativeimpactsthatraiseotherim-
portantnegativeconsequencesofAI,butwerenotprominentenoughtoberepresentedastheirowncategories.This
includedimpactssuchascostimpactsoftrainingAImodelslikeLLMs“thecostoftrainingAImodelsonlargedatasets
isexpensive”orenvironmentalimpactsbecause"datacenterssupportingAImodelscontributetocarbonemissions".
Also,negativeimpactsofAIoncognitionsuchas"informationoverload"dueto"GPT’sabilitytogeneratelotoftext
whichmakesitdifficulttodistinguishbetweenfactandfiction"orimpactsofAIchatbotsonemotionssuchas"in-
spire[ing]falsefeelingsofrequitedloveinvulnerableindividuals".
Safety – Thiscategoryfocusespredominantly onthenegative implicationsofself-driving carsand autonomous
vehiclesonsafety.Anexampleoftheseimpactsincludethepotentialofautonomousvehiclestocause“conflictsand
potentialaccidentswhensharingtheroadwithhumans”.
PotentialHarmsofAI–ThiscategoryencompassespotentialdigitalandphysicalharmscausedbyAI.Digitalharms
reflectthetypesofharmsresultingfromthecloudoronlinedeploymentofAIsystemsortechnologiessuchaschatbots
"engaged[ing]insexuallyexplicitconversationswithpayingsubscribers"or,inthecontextoffacialrecognitionsys-
tems,the“wrongconvictionofblackmenduetoincorrectfacialrecognitionmatches.”.Incontrast,existentialthreats
andtheimpactsofAIinwarfarefocusonphysicalharms.Somearticlesfocusedonthepotentialexistentialthreatsof
AIsuchasthe“potentialthreatofAItohumanlifeandsocialstability”.
AIGovernance–describestheimportanceandneedforsettinguparegulatoryframeworktogovernthedevelopment
anddeploymentofresponsibleAI.ThiscategoryalsoincludeschallengesinAIgovernancethatareoftenframedas
due tothe “black box problem, where it is unclear how AI [worksor] makes decisions”. For instance, the“lack of
interpretability in AImodels”and “lackof dataand knowledge aboutthe technology makes it difficult toregulate
effectively”.Additionalchallengesincludethe“vaguenessinAIregulations[which]makeitdifficultforcompaniesto
complyandunderstandwhatisrequired”fortheresponsibledevelopmentandadoptionofAI.
Accuracy andReliability – Thisdescribes theconcerns pertaining tothe reliability ofAIsuchas “overtrust[ing]
robots and technology, leading to automation bias” or its “tendency to hallucinate information and generate false
statements”.Moreover,AImodels“lack[ing]comprehensiontowhattheyreadorwriteashumansdo”raisedconcerns
abouttheirpotentialto“makeelementarymistakesandeven makethingsup”whichdeemthemas“unreliablefor
highstakestaskslikemedicaltranslationorcontentmoderation”.
AI-generatedContent –Thecategoryportraysthechallengesindetectingthedifferentmodalities(images,audio,
andtext)ofAIgeneratedcontentandthepotentialimpactsofsuchcontent.Thisincludes“difficultyindistinguishing
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 11
fakeimages”,problemsin“distinguishrealfromanAI-generatedvoices”,andtheimpactsof“AIgeneratedtext[that]
maynotbedetectablebyexistingplagiarismsoftware”on“academicintegrity”.
Security – This describes the consequences of exploiting security vulnerability of AI technologies for malicious
purposes.Forinstance,cybercriminalscould“easilylaunchcyberattacksusingchatGPT”through“promptinjection
attacks”that“trickchatbotsintobypassing guardrailsand revealing hiddeninstructions,potentiallycompromising
securityandcontentmoderationmeasures.”.
Inthenextsection,wedescribehowthetaxonomyofimpactsdescribedinthissectionwasleveragedasabaseline
forcomparingtheanticipatedimpactsofAIusinginstruction-basedandfine-tunedLLMs.
5.2 EvaluatingtheuseofLLMsforanticipatingimpactsofAI
ThetaxonomyofnegativeimpactsofAIpresentedinsection5.1providesabaselineagainstwhichtoassesswhether
thegeneratednegativeimpactsbyLLMsarealignedwiththenewsmedia.Inthissection,weelaborateourassessment
of four models including two instruction-based models (GPT-4 and Mistral-7B Instruct), as well as two fine-tuned
completionmodels(Mistral-7BandGPT-3).Westartbydescribingthefindingsfromourqualitativeevaluationofthe
generatednegativeimpactsaccordingtotheestablishedcriteriainsection4.3,namelycoherence,structure,relevance,
andplausibility.Wethenmovetoassesstheperformanceofthesemodelswithrespecttothetaxonomyofnegative
impactsinthenewsmediaestablishedinsection5.1.Allfindingsandevaluationsarebasedonusingthefunctional
andcontextualdescriptionsoftechnologiesinthetestingdatasettogeneratenegativeimpactsofthesetechnologies.
5.2.1 QualitativeEvaluationofAnticipatedImpacts. Alloftheimpactsgenerated bythemodelsweevaluatedwere
firstassessedastowhetherthegeneratedtextwasindeedanegativeimpact(seeAppendix10.2).Impactstatements
generatedbyinstruction-basedLLMswereallnegativeandthemajorityofthegeneratedimpactstatementsbythe
fine-tunedmodelswerealsodeemednegative(seeTableS2)aspertheevaluationrubric.Accordingly,theremaining
evaluationcriteriawereappliedonlytothesetofnegativeimpactstatementsgeneratedbyeachmodel.
Next, wequalitativelydescribeourfindings by analyzing thegenerated negative impactsintermsofcoherence,
structure,relevance,andplausibility.
Intermsofcoherence,themajorityofthegeneratedimpactsusinginstruction-basedandfine-tunedmodelswere
completesentences butasmallpercentageofthegenerated negative impactsbyeachLLM hadmorethanasingle
negativeimpactinthegeneratedtext(seeTableS2).Asforstructure,theanticipatednegativeimpactswereevaluated
tobeslightlyabstractandcouldbeelaboratedonfurther.Forinstance,forthisgeneratedimpactusingGPT-3"theuseof
AItomanipulateandpersuadevoterscanleadtoalossoftrustinpoliticsanddemocracy",amorecompletegenerated
impact would elaborate further on how the use of AI would manipulate the voters and influence the voters’ trust
inpoliticsanddemocracysimilartotheimpactgeneratedbyGPT-4:"AIcouldunderminethedemocraticprocessby
manipulatingvoters’choicesbasedontargetedandpotentiallymisleadinginformation".Fortherelevancecriterion,the
generatedtextwaspredominantlyevaluatedtoberelevanttothefunctionalandcontextualdescriptionsofAI.Lastly,
bothinstruction-basedandfine-tunedmodelswereabletogeneratesomewhatorveryplausiblenegativeimpacts.For
example,usingafunctionalandcontextualdescriptionsourcedfromthenewsmediaofNeuraLinkTechnologyaiming
toimplantachipintheskulltoallowindividualswithdisabilitiestoregaintheabilitytowalk,see,andcommunicate,
Mistral-7B generated a somewhat plausible negative impact on "the potential for misuse of Neuralink technology
formindcontrol".Incomparison,GPT-4generatedaveryplausiblenegativeimpactpertainingto"theriskofprivacy
violations,aspersonalthoughtsandexperiencescouldpotentiallybeaccessedandmisusedifthetechnologyishacked".
ManuscriptsubmittedtoACM12 MowafakAllahamandNicholasDiakopoulos
Thequalitativeevaluationofthegenerated negative impactsoncoherence, structure,relevance, and plausibility
demonstratesthepotentialofsmallerandopen-sourceLLMs,suchasMistral-7B,togeneratenegativeimpactsthat
arerelativelysimilarinqualitytonegativeimpactsgeneratedbylargerscaleLLMssuchasGPT-4(seeTableS2).In
thenextsection,wedelvedeeperintotheanalysistoevaluatehowtheseanticipatednegativeimpactsalignwiththe
negativeimpactscoveredinthenewsmedia.
Criterion Description QualitativeRubric GPT-4 Mistral-7B-Instruct GPT-3 Mistral-7B
Validation Isthegeneratedtextanegativeimpact? No 0(0%) 0(0%) 75(14.59%) 47(9.14%)
Yes 514(100%) 514(100%) 439(85.40%) 467(90.85%)
Coherence Isthegeneratedimpactacompletesentence? No 0(0.00%) 36(7.00%) 27(6.15%) 21(4.49%)
Yes 514(100%) 478(93.00%) 412(93.84%) 446(95.50%)
Coherence Doesthegeneratedimpactincludemorethan No 497(96.69%) 462(89.88%) 395(89.97%) 436(93.36%)
oneimpact?
Yes 17(3.30%) 52(10.11%) 44(10.02%) 31(6.63%)
Structure Howelaborativeisthegeneratedimpact? Tooconcise 0(0%) 1(0.19%) 4(0.911%) 7(1.49%)
Couldexplainmore 407(79.18%) 320(62.25%) 378(86.10%) 381(81.58%)
Sufficient 107(20.81%) 193(37.54%) 57(12.98%) 79(16.91%)
Relevance Howrelevantistheimpacttostakeholders? Irrelevant 2(0.39%) 24(4.66%) 4(0.91%) 11(2.35%)
SomewhatRelevant 29(5.64%) 74(14.39%) 59(13.43%) 20(4.2%)
VeryRelevant 483(93.96%) 416(80.93%) 376(85.65%) 436(93.36%)
Relevance Howrelevantistheimpacttothefunctionalca- Irrelevant 13(2.53%) 22(4.28%) 12(2.73%) 19(4.06%)
pabilitiesofthetechnology?
SomewhatRelevant 114(22.17%) 83(16.14%) 53(12.07%) 37(7.92%)
VeryRelevant 387(75.29%) 409(79.57%) 374(85.19%) 411(88.00%)
Plausibility Howplausibleisthegeneratedimpact? NotPlausible 0(0.00%) 0(0.00%) 0(0.00%) 0(0.00%)
SomewhatPlausible 3(0.58%) 10(1.94%) 38(8.65%) 20(4.28%)
VeryPlausible 511(99.41%) 504(98.05%) 401(91.34%) 447(95.71%)
TableS2. ResultsofthequalitativeevaluationofthegeneratedimpactstatementsonCoherence,Structure,Relevance,andPlausi-
bilityusinginstruction-based(GPT-4andMistral-7B-Instruct)andfine-tuned(GPT-3andMistral-7B)LargeLanguageModels.The
percentagesdenotetheproportionofnegativeimpactssatisfyingeachratingoftheevaluationdimensionstothetotalnumberof
negativeimpactsgeneratedbyeachrespectivemodel.
5.2.2 Evaluatingtheanticipatedimpactswithrespecttothenewsmedia. Asdescribedinsection4.2,allnegativeimpacts
were generated once using LLMs for each functional and contextual descriptionof atechnology.Accordingly, this
sectiondescribesresultsfromouranalysisofwhetherthenegativeimpactsgeneratedbyLLMsbasedonthefunctional
andcontextualdescriptionsinthehold-out(i.e.testing)datasetarealignedwiththecategoriesofimpactscoveredin
thenewsmedia.Bycategorizingthegeneratednegativeimpactsbasedonthetaxonomyofnegativeimpactsdeveloped
insection5.1,weprovideanoverviewofthealignmentbetweenthecategoriesofnegativeimpactsgeneratedusing
theLLMsandthosefoundinoursampleofarticlesfromthenewsmedia.
Wefound that thegenerated negative impactsusing instruction-based and fine-tuned modelslargelyreflect the
taxonomyofnegativeimpactsinthenewsmediapreviouslydescribedinsection5.1,thoughwithsomegapsinthe
productionofcertain categories by the instruction-based models.Overall, the generated negative impacts by both
fine-tunedmodels(Mistral-7BandGPT-3)coveredall10categoriesofnegativeimpactsdescribedbyourtaxonomy,
whereas the GPT-4 model did not produce any impacts in the AI-generated Content or Safety categories and the
Mistral-7B-InstructmodeldidnotproduceanyimpactsintheAIGovernanceorAI-generatedContentcategories(see
Appendix10.4forsomeexamples).ThetwocategoriesofnegativeimpactsthatGPT-4missed(AI-generatedContent
andSafety)accountforapproximately3.84%and3.4%ofthetotalgeneratednegativeimpactsbyMistral-7BandGPT-
3,respectively.Moreover,thecategoryofimpactspertainingtoAIGovernancethatismissedbyMistral-7B-Instruct
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 13
ImpactCategory Hold-outdataset GPT-4 Mistral-7B-Instruct GPT-3 Mistral-7B
SocialandEthicalImpacts 42.02% 26.65% 25.29% 35.99% 41.75%
Privacy 16.53% 23.73% 16.92% 12.98% 9.85%
EconomicImpacts 9.92% 24.51% 33.46% 8.88% 13.91%
AccuracyandReliability 7.19% 9.33% 7.00% 11.16% 8.77%
AIGovernance 7.19% 0.77% 0.00% 9.11% 6.42%
MiscellaneousRisksandImpacts 6.42% 3.69% 8.36% 9.56% 7.70%
PotentialHarmsofAI 5.25% 7.78% 4.66% 4.10% 7.06%
Security 2.33% 3.50% 3.50% 4.78% 0.64%
AI-generatedContent 1.94% 0.00% 0.00% 1.13% 0.85%
Safety 1.16% 0.00% 0.77% 2.27% 2.99%
TableS3. Prevalenceofthecategoriesofnegativeimpactsforourimpacttaxonomy(seeSection5.1)thatarepresentinthehold-out
datasetandgeneratedusinginstruction-based(GPT-4andMistral-7B-Instruct)andfine-tuned(GPT-3andMistral-7B)completion
models.Generatedimpactsarebasedonthefunctionalandcontextualdescriptionsoftechnologiesinthehold-outdataset.The
percentagesdenotetheproportionofnegativeimpactsineachcategorytothetotalnumberofnegativeimpactsgeneratedbyeach
respectivemodel.ThecellshighlightedingrayindicatethecategoriesofimpactsmissedbyGPT-4andMistral-7B-Instruct.
accountedfor6.42%and9.11%ofthetotalgeneratednegativeimpactsbyMistral-7BandGPT-3,respectively.These
findingsdemonstratethecapabilityofLLMsfine-tunedonnewsmediatoanticipatearangeofnegativeimpactsthat
gobeyondthezero-shotimpactsgeneratedusinglarger-scaleandinstruction-basedLLMs.
Drillingfurtherintothesedisparities,wefindahigher degreeofconcentrationintheimpacttypesproducedby
instruction-basedincomparisontofine-tunedmodels.Tosupportourobservation,wecalculatetheGinicoefficient
basedonthenumberofnegativeimpactsgeneratedusingeachLLMandpresentinthehold-outdataset.Bycalculating
theGinicoefficient,weareabletostatisticallycomparehowconcentratedtheunequaldistributionsofnegativeimpacts
are,withrespecttocategoriesofimpacts,acrossmodelsandcomparethesedistributionstothedistributionofimpacts
presentinthehold-outdataset.AmodelthathasahighGinicoefficient(moreunequal)hasahigherconcentrationof
impactsinsomecategories.Incontrast,modelswithlowerGinicoefficient(moreequal)haveamoreeven(i.e.,spread
out)distributionofnegativeimpactsacrossthecategoriesofimpacts.Despitetheminordifferencesinthecoefficients
calculatedforeachmodel,wefindthatMistral-7B(0.50)andGPT-3(0.44)tendtohaveamoreeven distributionof
negative impactsacrosscategories,and arecloselyaligned withthedistributionofimpactsinthehold-outdataset
(0.51),comparedtoGPT-4(0.55)andMistral-7B-Instruct(0.58)whichareslightlymoreuneven andconcentratedin
termsofthecategoriesofimpactsgenerated.
6 DISCUSSION
Thisresearch presents an evaluation ofLLMs for the task ofanticipating the negative impacts ofAI. To do so we
first develop a taxonomy of AI impacts from the news media and then use it as a baseline to compare the range
ofimpactsgeneratedbybothinstruction-basedandfine-tunedmodelsonasamplefromthatbaseline.Ourfindings
highlightapotentialbiasinstate-of-the-artLLMswhenusedforanticipatingimpactsanddemonstratetheadvantages
ofaligning smaller LLMswithadiverse range ofimpacts,asreflected in thenews media,tocapturesuchimpacts
duringanticipatoryexercises.
With respect to prior taxonomiesof impacts, thetaxonomy we present captures many ofthe impact categories
outlinedbyrecentresearchontheharms,aswellassocialandethicalimpactsofAI[39,40].However,itappearsthat
impactsrelevanttoalienationandlossofagencythatarereportedintheliterature[39,50]aremissingfromthenews
media,atleastatthelevel ofdetailconsidered inthiswork.Futureworkmaybewarrantedtodrillintosub-types
ofimpactinthenewsmediatofurtherassesspatternsinmediacoverageofAI,suchasbiasesinframingthatcould
ManuscriptsubmittedtoACM14 MowafakAllahamandNicholasDiakopoulos
lead tomissing outonsuchlonger-termthematic treatmentsofimpacts,ortobetterunderstand theprevalence of
presumptivelydominantnarratives.Forinstance,readingintothePotentialHarmsofAI categoryofimpactsinour
samplewenoticedveryfewinstancesofimpactsdiscussingexistentialthreatsofAI,providinglittleevidencethatthat
newsmediahassuccumbedtotherhetoricofadoomsdayscenarioofAI.Therefore,futureworkfocusingoncreating
typologiesofimpactsonthesub-categorylevelmayprovidemoregranularinsightsandpotentialforanalysisofthe
natureofimpactsconstitutingeachofthecategoriesofimpactsfoundinourtaxonomy.
It’simportanttobeclearagain,thatanytaxonomywillreflectbiasesbasedonthesourcesofdatausedtobuildit
andfutureworkisstillneededtoparsethepotentialsourcesofbiasinanews-basedtaxonomy,suchasnewsoutlet
credibility(i.e.,lowvs.highcrediblenewssources),politicalbias,temporalbiases,geographicbiases,andeventhetype
ofnewsarticle(i.e.hardnewsvs.opinion).Whileourresearchfallsshortofaccountingforthesebiases,wesuggest
thatfutureresearchshouldaccountforthemandevaluatethelevelofinfluencethesebiaseshaveonthecategoriesof
impactsprevalentinthenewsmediaandsubsequentlyontherangeandqualityofimpactsthatmightbegenerated
usingLLMsfine-tunedonthatdata.Onebenefitoftaxonomiesthatleveragenewsmediaisthattheyhavethepotential
tocontinuouslyadaptandevolveasrapiddevelopmentsofAIarereportedonbythemedia.Pairedwithanapproach
basedonfine-tuning,thiscouldhelpLLMsusedforanticipatingimpactsstaymorecloselyalignedwithhowthesociety
(asreflectedinnewsmedia)evaluatesthetechnology.
OurfindingsfromevaluatingtheperformanceofLLMsforanticipatingtheimpactsofemergingtechnologies,as
describedinourmethods,demonstrateoverallhighlevelsofperformanceacrossmetricsofcoherence,structure,rel-
evance, and plausibility with relatively minor variations in performance across different models. The open-source
Mistral-7B-InstructmodelshowedserviceableperformanceincomparisontothemuchlargerandproprietaryGPT-4,
andwhenfine-tuning thecompletionmodelofMistral-7B,itexhibited amorealigneddistributionofimpactswith
respecttothenewsmedia,demonstratingthepotentialvalueoffine-tuningforthistask.Thesefindingsalsosuggest
thatthesemodelsarealreadyperformantenoughtobeutilizedbyvariousstakeholdersseekingtoleverageLLMsto
supportanticipatorythinkingabouttheimpactsofAI.Forexample,fine-tunedmodelsondescriptionsofimpactscould
beintegratedintothescientificprocesstohelpresearchersthinkcreativelyaboutthebroaderimpactsoftheirresearch
[32](seealsoourethicsstatementforthispaperwhichwasenhancedusingthetechniquespresentedinthispaper).
Furthermore,technologycompaniescouldpotentiallydeploythesemodelsasatoolforinferencethataugmentsdevel-
opers’abilitiestoanticipateandthinkbroadlyaboutthenegativeandunintendedimpactsofthetechnologiestheyare
creatingearlyoninthedevelopmentlifecycle,perhapsaspartofinternalauditingandevaluationprocesses[35].Also,
modelsfine-tunedondescriptionsofimpactshavethepotentialtobeintegratedwithuser-friendlyinterfacestoenable
domainexpertswithminimaltechnicalexperience,suchasjournalistsandpolicymakers,toalsothinkabouttheneg-
ativeimpactsofemergingtechnologies,potentiallysupportingcreativeidentificationofanglesforfurtherreporting
[34].
7 CONCLUSION
Overall,thisresearchoffersasteptowardsdemocratizingtheprocessofanticipatingtheimpactsofemerging tech-
nologiesby usingLLMs and leveraging moreaccessibleand diverse assessments ofemerging technologiessuchas
thosepresentinthenewsmedia.Morespecifically,weevaluatedthepotentialofLLMsforanticipatingthenegative
impactsofAIusingnewsmediaasabaseline.Toestablishthisbaseline,wedevelopedataxonomyofnegativeimpacts
byleveragingalargeanddiversecorpusofdescriptionsofAIimpactsdrawnfromthenewsmediaandshowedthat
thiscapturesabroadrangeofsocietalconcernsaboutAItechnologies.Ourfindingsfromevaluatingthecategories
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 15
ofnegativeimpactsgeneratedusinginstruction-based(GPT-4andMistral-7B-Instruct)andfine-tunedmodels(GPT-3
andMistral-7B),withrespecttothisbaseline,suggestthatfine-tuningsmalleropen-sourceLLMslikeMistral-7B,with
verylimitedcomputeresources,onadiversedatasourcesuchasthenewsmediacancoverarangeofcategoriesof
negativeimpactsrelevanttoAItechnologiesbeyondtheonesanticipatedusingamuchlargerandcapableLLMsuch
asGPT-4.Inaddition,qualitativeassessmentofgeneratedimpactsacrossthefourdimensionsofcoherence,structure,
relevance,andplausibilityshowsthatsmalleropen-sourcemodelssuchasMistral-7Bfine-tunedonnegativeimpacts
fromnewsmediatendtogeneratenegativeimpactsthatarequalitativelycomparabletothosegeneratedusingalarger
scalemodelsuchasGPT-4.Ourresearchhighlightsapotentialbiasinstate-of-the-artLLMswhenusedforanticipat-
ingimpactsanddemonstratestheadvantagesofaligningsmallerLLMswithadiverserangeofimpacts,suchasthose
reflectedinthenewsmedia,tobetterreflectsuchimpactsduringanticipatoryexercises.
8 ACKNOWLEDGEMENTS
ThisworkissupportedbytheNationalScienceFoundationviaawardIIS-1845460.
ManuscriptsubmittedtoACM16 MowafakAllahamandNicholasDiakopoulos
9 RESEARCHETHICSANDSOCIALIMPACT
Thisworkpavesthewayforfutureresearchtobuildanticipatorytoolstoguidepractitionersandresearchersinthe
processofanticipatingthenegativeimpactsofAItechnologies.Dependingonthecontextofthedeployment,arange
ofunintendedconsequencescouldinfluenceusers’trustandrelianceontheseanticipatorytools.Forinstance,over-
relyingonourfine-tunedmodels,ifdeployedasaninferencetool,hastheriskofdiminishingcriticalthinkingandthe
anticipationofnegativeimpactsiftheoutputsofthemodelsareperceivedordeemedtobeconclusiveorinclusiveof
allplausibleandpossiblescenariosinwhichanAItechnologycouldbeused.Accordingly,weviewthedevelopment
ofanticipatorytoolsassupportingmethods(butnotsubstitutions)inthecreativeprocessofanticipatingthenegative
impactsofAI.
Concerningouruseofnewsmediaasadatasource,werecognizeandacknowledgethesensitivitysurroundingthe
onlinescrapingofarticlestotrainLargeLanguageModels,includingquestionscurrentlybeforecourtsrelatedtothe
fair-usedoctrine.Asaresult,wedonotcurrentlyplantoshareorre-distributethenewsarticledatasetcollectedor
themodelsfine-tunedforthepurposeofthisresearchforanycommercialpurposes.
Toextendthescopeofimpactsbeyondtheoneswehaveconsideredorthoughtof,weleveragedGPT-4andMistral-
7Bfine-tunedonimpactsfromthenewsmediatoassistuswithcapturingtherangeofpotentialunintendedconse-
quencesofusingLLMsforanticipatingimpactsasdescribedinthecontextofthisresearch.BypromptingGPT-4with
theabstracttothispaperandpromptP28,weextractedthefunctionalandcontextualdescriptions9 ofLLMsforan-
ticipatingnegativeimpacts.ThenweincludedthesedescriptionsaspartofthecontextofpromptP3andgenerated
fivenegativeimpactspermodel.AlthoughGPT-4anticipatedimpactsthatwerecoveredinourresearch,suchasme-
diabias10 andover-reliance11 onLLMsforimpactassessment, italsoextended thescopeofimpactstoincludethe
potentialimplicationsoffocusingonexistingnewsmediaonthelackofforesightofnovelorunforeseenimpactsof
AItechnologies12.Also,itgeneratedanimpactrelatedtothepotentialofLLMstoinadvertentlyamplifysensationalist
orexaggeratedviewpoints,suchasthehypearoundAI,prevalentinsomenewsmediawhichcouldresultinaskewed
understandingofthereal-worldimplicationsofAI13.Similarly,Mistral-7Bcontributedanovelimpactbeyondwhat
wehadconsidered,havingtodowiththepotentialofanticipatorytoolstoreducethepowerofregulatoryinstitutions
thataremeanttoconductimpactassessmentsofemergingtechnologies14.Thislastpointraisesacrucialpoliticalpoint
abouttheuseofsuchanticipatorytechnologiesandhowthatcoulderodetheroleofotherstakeholdersinanticipatory
processes.
8SeeTableS1
9ThearticleexplorestheuseofLargeLanguageModels(LLMs)toanalyzetheimpactsofemergingAItechnologies,leveragingavastarrayofnews
mediasources.ItdescribesthedevelopmentofataxonomyofAIimpactsthroughcomputationalanalysisofnewsarticles.Thestudycomparesthe
performanceofdifferentLLMs,includinginstruction-basedmodelslikeGPT-4andMistral-7B-Instruct,andfine-tunedmodelssuchasMistral-7Band
GPT-3,ingeneratingcoherentandplausibleAIimpacts.ThefindingshighlightthecapabilityofLLMs,evensmallermodels,toeffectivelyreflectthe
diverseimplicationsofAI,providingvaluableinsightsforstakeholdersandusersinvariousdomains.
10ApotentialnegativeimpactofthistechnologyisthattheLLMs,inanalyzingAIimpactsthroughnewsmediadata,mightinheritbiasespresentinthe
media,leadingtoskewedorpartialrepresentationsofAI’simplications.
11Anothernegativeimpactcouldbethepotentialforover-relianceonLLM-generatedassessments,whichmightleadtooverlookingnuancedoremerging
aspectsofAIimpactsnotadequatelycoveredinnewsmediasources.
12TheLLMs’focusonexistingnewsmediacontentcouldresultinalackofforesightregardingunforeseenornovelnegativeimpactsofAItechnologies.
13TheuseofLLMsforanalyzingAIimpactsmayinadvertentlyamplifysensationalistorexaggeratedviewpointsprevalentinsomenewsmedia,poten-
tiallyskewingtheunderstandingofAI’sreal-worldimplications.
14LossofinfluenceindecisionmakingbetweenhumanlawmakerinstitutionsresponsibleforregulatingAIinnovationprograms.
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 17
REFERENCES
[1] JackBandy.2021.ProblematicMachineBehavior:ASystematicLiteratureReviewofAlgorithmAudits.Proc.ACMHum.-Comput.Interact.CSCW1
5,Article74(2021),1–34. https://doi.org/10.1145/3449148
[2] JuliaBarnettandNicholasDiakopoulos.2022. CrowdsourcingImpacts:ExploringtheUtilityofCrowdsforAnticipatingSocietalImpactsof
AlgorithmicDecisionMaking.InProceedingsofthe2022AAAI/ACMConferenceonAI,Ethics,andSociety.ACM,OxfordUnitedKingdom,56–67.
https://doi.org/10.1145/3514094.3534145
[3] Michael S. Bernstein, Margaret Levi, David Magnus, Betsy A. Rajala, Debra Satz, and Charla Waeiss. 2021. Ethics and society review:
Ethics reflection as a precondition to research funding. Proceedings of the National Academy of Sciences 118, 52 (2021), e2117261118.
https://doi.org/10.1073/pnas.2117261118
[4] FergusBolgerandGeorgeWright.2017.Useofexpertknowledgetoanticipatethefuture:Issues,analysisanddirections.,230–243pages.
[5] RishiBommasani,DrewA.Hudson,EhsanAdeli,RussB.Altman,SimranArora,SydneyvonArx,MichaelS.Bernstein,JeannetteBohg,Antoine
Bosselut,EmmaBrunskill,ErikBrynjolfsson,ShyamalBuch,DallasCard,RodrigoCastellon,NiladriS.Chatterji,AnnieS.Chen,KathleenCreel,
JaredQuincyDavis,DorottyaDemszky,ChrisDonahue,MoussaDoumbouya,EsinDurmus,StefanoErmon,JohnEtchemendy,KawinEthayarajh,
LiFei-Fei,ChelseaFinn,TrevorGale,LaurenGillespie,KaranGoel,NoahD.Goodman,ShelbyGrossman,NeelGuha,TatsunoriHashimoto,Peter
Henderson,JohnHewitt,DanielE.Ho,JennyHong,KyleHsu,JingHuang,ThomasIcard,SaahilJain,DanJurafsky,PratyushaKalluri,Siddharth
Karamcheti,GeoffKeeling,FereshteKhani,OmarKhattab,PangWeiKoh,MarkS.Krass,RanjayKrishna,RohithKuditipudi,andetal.2021. On
theOpportunitiesandRisksofFoundationModels.CoRRabs/2108.07258(2021).arXiv:2108.07258 https://arxiv.org/abs/2108.07258
[6] AndreaBonaccorsi,RiccardoApreda,andGualtieroFantoni.2020. Expertbiasesintechnologyforesight.Whytheyareaproblemandhowto
mitigatethem.TechnologicalForecastingandSocialChange151(Feb.2020),119855. https://doi.org/10.1016/j.techfore.2019.119855
[7] AndreaBonaccorsi,RiccardoApreda,andGualtieroFantoni.2020. Expertbiasesintechnologyforesight.Whytheyareaproblemandhowto
mitigatethem.TechnologicalForecastingandSocialChange151(2020),119855.
[8] PhilipAEBrey.2012.AnticipatoryEthicsforEmergingTechnologies.NanoEthics6,1(042012),1–13. https://doi.org/10.1007/s11569-012-0141-7
[9] TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,
AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,Jeffrey
Wu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,Sam
McCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.LanguageModelsareFew-ShotLearners. arXiv:2005.14165[cs.CL]
[10] ZanaBuçinca,ChauMinhPham,MauriceJakesch,MarcoTulioRibeiro,AlexandraOlteanu,andSaleemaAmershi.2023. AHA!:FacilitatingAI
ImpactAssessmentbyGeneratingExamplesofHarms. http://arxiv.org/abs/2306.03280arXiv:2306.03280[cs].
[11] Ching-HuaChuan,Wan-HsiuSunnyTsai,andSuYeonCho.2019. FramingArtificialIntelligenceinAmericanNewspapers.InProceedingsofthe
2019AAAI/ACMConferenceonAI,Ethics,andSociety(Honolulu,HI,USA)(AIES’19).AssociationforComputingMachinery,NewYork,NY,USA,
339–344. https://doi.org/10.1145/3306618.3314285
[12] KateCrawford.2016.Artificialintelligence’swhiteguyproblem.TheNewYorkTimes25,06(2016),5.
[13] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023. QLoRA: Efficient Finetuning of Quantized LLMs.
arXiv:2305.14314[cs.LG]
[14] NicholasDiakopoulosandDeborahJohnson.2021. Anticipatingandaddressingtheethicalimplicationsofdeepfakesinthecontextofelections.
NewMedia&Society23,7(2021),2072–2098. https://doi.org/10.1177/1461444820925811
[15] MaartenGrootendorst.2022.BERTopic:Neuraltopicmodelingwithaclass-basedTF-IDFprocedure.arXivpreprintarXiv:2203.05794(2022).
[16] AlexaHagertyandIgorRubinov.2019. GlobalAIEthics:AReviewoftheSocialImpactsandEthicalImplicationsofArtificialIntelligence.
http://arxiv.org/abs/1907.07892arXiv:1907.07892[cs].
[17] Tony Harcup and Deirdre O’Neill. 2016. What is news? News values revisited (again). Journalism Studies 23, 1 (03 2016), 1 – 19.
https://doi.org/10.1080/1461670x.2016.1150193
[18] JochenHartmann,MarkHeitmann,ChristianSiebert,andChristinaSchamp.2023. MorethanaFeeling:AccuracyandApplicationofSentiment
Analysis.InternationalJournalofResearchinMarketing40,1(March2023),75–87. https://doi.org/10.1016/j.ijresmar.2022.05.005
[19] MiaHoffmannandHeatherFrase.2023.AddingStructuretoAIHarm:AnIntroductiontoCSET’sAIHarmFramework.TechnicalReport.Centerfor
SecurityandEmergingTechnology. file:///Users/nad/Downloads/20230022-Adding-structure-to-AI-Harm-FINAL%20(1).pdf
[20] JBrittHolbrookandRobertFrodeman.2011.Peerreviewandtheexanteassessmentofsocietalimpacts.ResearchEvaluation20,3(2011),239–246.
[21] DavidMHowcroft,AnyaBelz,MirunaClinciu,DimitraGkatzia,SadidAHasan,SaadMahamood,SimonMille,EmielVanMiltenburg,Sashank
Santhanam,andVerenaRieser.2020.Twentyyearsofconfusioninhumanevaluation:NLGneedsevaluationsheetsandstandardiseddefinitions.
In13thInternationalConferenceonNaturalLanguageGeneration2020.AssociationforComputationalLinguistics,169–182.
[22] AlbertQ.Jiang,AlexandreSablayrolles,ArthurMensch,ChrisBamford,DevendraSinghChaplot,DiegodelasCasas,FlorianBressand,Gianna
Lengyel,GuillaumeLample,LucileSaulnier,LélioRenardLavaud,Marie-AnneLachaux,PierreStock,TevenLeScao,ThibautLavril,ThomasWang,
TimothéeLacroix,andWilliamElSayed.2023.Mistral7B. arXiv:2310.06825[cs.CL]
[23] AnnaJobin,MarcelloIenca,andEffyVayena.2019. ThegloballandscapeofAIethicsguidelines. NatureMachineIntelligence1,9(Sept.2019),
389–399. https://doi.org/10.1038/s42256-019-0088-2
ManuscriptsubmittedtoACM18 MowafakAllahamandNicholasDiakopoulos
[24] HishamO.KhogaliandSamirMekid.2023. TheblendedfutureofautomationandAI:Examiningsomelong-termsocietalandethicalimpact
features.TechnologyinSociety73(May2023),102232. https://doi.org/10.1016/j.techsoc.2023.102232
[25] AsleHKiran,NellyOudshoorn,andPeter-PaulVerbeek.2015.Beyondchecklists:towardanethical-constructivetechnologyassessment.Journal
ofresponsibleinnovation2,1(2015),5–19.
[26] TakeshiKojima,ShixiangShaneGu,MachelReid,YutakaMatsuo,andYusukeIwasawa.2023. LargeLanguageModelsareZero-ShotReasoners.
arXiv:2205.11916[cs.CL]
[27] MichaelA.Madaio,LukeStark,JenniferWortmanVaughan,andHannaWallach.2020. Co-DesigningCheckliststoUnderstandOrganizational
ChallengesandOpportunitiesaroundFairnessinAI.InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,
HI,USA)(CHI’20).AssociationforComputingMachinery,NewYork,NY,USA,1–14. https://doi.org/10.1145/3313831.3376445
[28] Sean McGregor. 2020. Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incident Database.
http://arxiv.org/abs/2011.08512arXiv:2011.08512[cs].
[29] JacobMetcalf,EmanuelMoss,ElizabethAnneWatkins,RanjitSingh,andMadeleineClareElish.2021. AlgorithmicImpactAssessmentsand
Accountability:TheCo-constructionofImpacts.InProceedingsofthe2021ACMConferenceonFairness,Accountability,andTransparency.ACM,
VirtualEventCanada,735–746. https://doi.org/10.1145/3442188.3445935
[30] BrentDanielMittelstadt,BerndCarstenStahl,andNBenFairweather.2015. Howtoshapeabetterfuture?Epistemicdifficultiesforethical
assessmentandanticipatorygovernanceofemergingtechnologies.EthicalTheoryandMoralPractice18(2015),1027–1047.
[31] PriyankaNanayakkara,NicholasDiakopoulos,andJessicaHullman.2020.AnticipatoryEthicsandtheRoleofUncertainty.CoRRabs/2011.13170
(2020).arXiv:2011.13170 https://arxiv.org/abs/2011.13170
[32] Priyanka Nanayakkara, Jessica Hullman, and Nicholas Diakopoulos. 2021. Unpacking the Expressed Consequences of AI Research in
BroaderImpactStatements. InProceedings ofthe2021AAAI/ACMConferenceonAI,Ethics,andSociety. ACM,VirtualEventUSA, 795–806.
https://doi.org/10.1145/3461702.3462608
[33] RobertoNavigli,SimoneConia,andBjörnRoss.2023.BiasesinLargeLanguageModels:Origins,Inventory,andDiscussion.J.DataandInformation
Quality15,2,Article10(jun2023),21pages. https://doi.org/10.1145/3597307
[34] SavvasPetridis.[n.d.].AngleKindling:SupportingJournalisticAngleIdeationwithLargeLanguageModels.([n.d.]).
[35] InioluwaDeborahRaji,AndrewSmart,RebeccaNWhite,MargaretMitchell,TimnitGebru,BenHutchinson,JamilaSmith-Loud,DanielTheron,
andParkerBarnes.2020. ClosingtheAIaccountabilitygap:defininganend-to-endframeworkforinternalalgorithmicauditing. Proceedingsof
the2020ConferenceonFairness,Accountability,andTransparency(2020),33–44. https://doi.org/10.1145/3351095.3372873
[36] Brianna Richardson, JeanGarcia-Gathright,SamuelF. Way,Jennifer Thom, and Henriette Cramer.2021. Towards Fairnessin Practice: A
Practitioner-OrientedRubricforEvaluatingFairMLToolkits.InProceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems
(<conf-loc>,<city>Yokohama</city>,<country>Japan</country>,</conf-loc>)(CHI’21).AssociationforComputingMachinery,NewYork,NY,
USA,Article236,13pages. https://doi.org/10.1145/3411764.3445604
[37] JohannesSchneider.2022.Foundationmodelsinbrief:Ahistorical,socio-technicalfocus. http://arxiv.org/abs/2212.08967arXiv:2212.08967[cs].
[38] JonasSchuett,NoemiDreksler,MarkusAnderljung,DavidMcCaffary,LennartHeim,EmmaBluemke,andBenGarfinkel.2023. Towardsbest
practicesinAGIsafetyandgovernance:Asurveyofexpertopinion. http://arxiv.org/abs/2305.07153arXiv:2305.07153[cs].
[39] Renee Shelby, Shalaleh Rismani, Kathryn Henne, AJung Moon, Negar Rostamzadeh, Paul Nicholas, N’Mah Yilla, Jess Gallegos, Andrew
Smart, Emilio Garcia,and Gurleen Virk. 2023. Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction.
http://arxiv.org/abs/2210.05791arXiv:2210.05791[cs].
[40] IreneSolaiman,ZeerakTalat,WilliamAgnew,LamaAhmad,DylanBaker,SuLinBlodgett,HalDauméIII,JesseDodge,EllieEvans,SaraHooker,
YacineJernite,AlexandraSashaLuccioni,AlbertoLusoli,MargaretMitchell,JessicaNewman,Marie-TheresePng,AndrewStrait,andApostol
Vassilev.2023.EvaluatingtheSocialImpactofGenerativeAISystemsinSystemsandSociety. http://arxiv.org/abs/2306.05949arXiv:2306.05949
[cs].
[41] Ruixiao Sun, Jie Yang, and Mehrdad Yousefzadeh. 2020. Improving Language Generation with Sentence Coherence Objective.
arXiv:2009.06358[cs.CL]
[42] ZeerakTalat,AurélieNévéol,StellaBiderman,MirunaClinciu,MananDey,ShayneLongpre,SashaLuccioni,MaraimMasoud,MargaretMitchell,
DragomirRadev,ShanyaSharma,ArjunSubramonian,JaesungTae,SamsonTan,DeepakTunuguntla,andOskarVanDerWal.2022. Youreap
whatyousow:OntheChallengesofBiasEvaluationUnderMultilingualSettings.InProceedingsofBigScienceEpisode#5–WorkshoponChallenges
&PerspectivesinCreatingLargeLanguageModels,AngelaFan,SuzanaIlic,ThomasWolf,andMatthiasGallé(Eds.).AssociationforComputational
Linguistics,virtual+Dublin,26–41. https://doi.org/10.18653/v1/2022.bigscience-1.3
[43] AlexTamkin,MilesBrundage,JackClark,andDeepGanguli.2021. UnderstandingtheCapabilities,Limitations,andSocietalImpactofLarge
LanguageModels. http://arxiv.org/abs/2102.02503arXiv:2102.02503[cs].
[44] RohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,andTatsunoriB.Hashimoto.2023.Stanford
Alpaca:AnInstruction-followingLLaMAmodel.https://github.com/tatsu-lab/stanford_alpaca.
[45] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,NikolayBashlykov,SoumyaBatra,PrajjwalBhargava,
ShrutiBhosale,DanBikel,LukasBlecher,CristianCantonFerrer,MoyaChen,GuillemCucurull,DavidEsiobu,JudeFernandes,JeremyFu,Wenyin
Fu,BrianFuller,CynthiaGao,VedanujGoswami,NamanGoyal,AnthonyHartshorn,SagharHosseini,RuiHou,HakanInan,MarcinKardas,Viktor
Kerkez,MadianKhabsa,IsabelKloumann,ArtemKorenev,PunitSinghKoura,Marie-AnneLachaux,ThibautLavril,JenyaLee,DianaLiskovich,
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 19
YinghaiLu,YuningMao,XavierMartinet,TodorMihaylov,PushkarMishra,IgorMolybog,YixinNie,AndrewPoulton,JeremyReizenstein,Rashi
Rungta,KalyanSaladi,AlanSchelten,RuanSilva,EricMichaelSmith,RanjanSubramanian,XiaoqingEllenTan,BinhTang,RossTaylor,Adina
Williams,JianXiangKuan,PuxinXu,ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,MelanieKambadur,SharanNarang,AurelienRodriguez,
RobertStojnic,SergeyEdunov,andThomasScialom.2023.Llama2:OpenFoundationandFine-TunedChatModels. arXiv:2307.09288[cs.CL]
[46] SergioUrueña.2019.Understanding“plausibility”:Arelationalapproachtotheanticipatoryheuristicsoffuturescenarios.Futures111(2019),15
–25. https://doi.org/10.1016/j.futures.2019.05.002
[47] SergioUrueña.2019. Understanding“plausibility”:Arelationalapproachtotheanticipatoryheuristicsoffuturescenarios. Futures111(2019),
15–25. https://doi.org/10.1016/j.futures.2019.05.002
[48] LuciaVesnic-Alujevic,SusanaNascimento,andAlexandrePólvora.2020. Societalandethicalimpactsofartificialintelligence:Criticalnoteson
Europeanpolicyframeworks.TelecommunicationsPolicy44,6(July2020),101961. https://doi.org/10.1016/j.telpol.2020.101961
[49] YizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,NoahA.Smith,DanielKhashabi,andHannanehHajishirzi.2023.Self-Instruct:Aligning
LanguageModelswithSelf-GeneratedInstructions. arXiv:2212.10560[cs.CL]
[50] LauraWeidinger,MaribethRauh,NahemaMarchal,AriannaManzini,LisaAnneHendricks,JuanMateos-Garcia,StevieBergman,JackieKay,
ConorGriffin,BenBariach,IasonGabriel,VerenaRieser,andWilliamIsaac.2023. SociotechnicalSafetyEvaluationofGenerativeAISystems.
arXiv:2310.11986[cs.AI]
[51] LauraWeidinger,JonathanUesato,MaribethRauh,ConorGriffin,Po-SenHuang,JohnMellor,AmeliaGlaese,MyraCheng,BorjaBalle,Atoosa
Kasirzadeh,CourtneyBiles,SashaBrown,ZacKenton,WillHawkins,TomStepleton,AbebaBirhane,LisaAnneHendricks,LauraRimell,William
Isaac,JuliaHaas,SeanLegassick,GeoffreyIrving,andIasonGabriel.2022.TaxonomyofRisksposedbyLanguageModels.In2022ACMConference
onFairness,Accountability,andTransparency.ACM,SeoulRepublicofKorea,214–229. https://doi.org/10.1145/3531146.3533088
ManuscriptsubmittedtoACM20 MowafakAllahamandNicholasDiakopoulos
10 APPENDIX
10.1 AI-relevantKeywords
ThesetofkeywordsusedtoprobethenewsmediaforarticlesonAI:
A.I.,ArtificialIntelligence,AutomatedDecisionMaking,AutomatedSystem,AutonomousDrivingSystem,Autonomous
Vehicles,AutonomousWeapon,ChatBot,Chatbot,ChatGPT,ComputerVision,DeepLearning,Deepfake,Driverless
Car,FacialRecognition,GeneralArtificialIntelligence,GenerativeAI,GPT,ImageGenerator,IntelligenceSoftware,In-
telligentMachine,IntelligentSystem,LanguageModel,LargeLanguageModel,LLMs,MachineIntelligence,Machine
Learning, Machine Translation,Natural Language API, Natural Language Processing, Neural Net, Neural Network,
PredictivePolicing,ReinforcementLearning,Self-DrivingCar,SpeechRecognition,StableDiffusion,SyntheticMedia,
VirtualReality,WeaponsSystem.
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 21
10.2 QualitativeEvaluationRubric
Criterion Description EvaluationScale
Validation Evaluateswhetherthegeneratedtextisanimpact Doesthegeneratedtextstateordescribeanegativeimpact
ofatechnology?
0-Thegeneratedtextisageneralstatementorapositive
impact
1-Yes,thegeneratedtextdescribes/statesanegativeimpact
ofatechnology
RelevancetoStakeholders Definedastherelevanceofthenegativeimpacttotheenti- Howrelevantisthe negativeimpactto the entities men-
tiesandstakeholdersofatechnology tionedinthefunctionaldescription?
1-Irrelevant:thenegativeimpactisirrelevanttotheentities
describedinthefunctionaldescription
2-Somewhatrelevant:thenegativeimpactcouldberelevant
totheentitiesdescribedinthefunctionaldescription
3-Highlyrelevant:thenegativeimpactisrelevanttotheen-
titiesofthetechnologydescribedinthefunctionaldescrip-
tion
RelevancetoCoreFunctionalities Definedastherelevanceofthenegativeimpacttothefunc- Howrelevantisthenegativeimpacttothecorefunctional-
tionalitiesofatechnology ityofthetechnologyasmentionedinthefunctionaldescrip-
tion?
1-Irrelevant:thenegativeimpactisirrelevanttothecore
functionalitydescribedinthefunctionaldescription
2-Somewhatrelevant:thenegativeimpactcouldberelevant
tothecorefunctionalityofthetechnologydescribedinthe
functionaldescription
3-Highlyrelevant:thenegativeimpactisrelevanttothe
corefunctionalityofthetechnologydescribedinthefunc-
tionaldescription.
Coherence(Comprehensibility) Definedintermsofcomprehensibilityofthegeneratedneg- Isthegeneratedimpactacompletesentence?
ativeimpact 0:No
1:Yes
Coherence(NumberofImpacts) Definedintermsofthenumberofgeneratednegativeim- Doesthegeneratedimpactmentionmorethanoneimpact
pacts inanimpactstatement?
0:No
1:Yes
Structure Definedintermsofthelevelofdescriptionofthegenerated Howelaborativeisthegeneratedimpact?
impact 1:Tooconcise(e.g.,asingleword)
2:Couldexplainmore(i.e.,negativeimpactisslightlyde-
scriptiveandcanbeelaboratedon)
3:Sufficient(i.e.,negativeimpactissufficientlydescriptive)
Plausibility Assessesthereasonablenessthatanegativeimpactcould Howreasonableisittoconcludethatthegeneratednegative
happen impactcouldhappen?
1-Notplausible
2-Somewhatplausible
3-Veryplausible
TableS4. Evaluationrubricofthegeneratedtextusinginstruction-basedandfine-tunedmodelsoncoherence,relevance,structure,
andplausibility.
10.3 FunctionalandcontextualdescriptionsusedforanticipatingimpactsusingLLMs
10.3.1 C6:"driverless carsarecapableofoperatingwithoutahumandriver and arecurrentlybeingtestedincities
likeSanFrancisco,Phoenix,Austin,andLosAngeles.stakeholdersinvolvedinthistechnologyincludeGeneral
ManuscriptsubmittedtoACM22 MowafakAllahamandNicholasDiakopoulos
MotorscruiseandGooglesiblingWaymo.thetechnology’sfunctionalcapabilitiesincludeobeyingtrafficrules
anddrivingatthespeed.usersofthistechnologyarethegeneral publicwhosharetheroadswithdriverless
cars.".
10.3.2 C7:"artificialintelligence(AI).ithasthefunctionalcapabilitiestogenerateplausibleresponsestopromptsfrom
users invariousformats,suchas poems,academic essays, and softwarecoding. it can alsoproducerealistic
images, like the pope wearing a puffer jacket. the relevance of AI to stakeholders, such as Google’s parent
companyalphabet,isevidentastheyownanAIcompanycalleddeepmindandhavelaunchedanAI-powered
chatbotcalledbard.usersofAItechnology,includingradiologists,writers,accountants,architects,andsoftware
engineers,canbenefitfromitscapabilitiesinassistingwithtasksandprioritizingcases"
10.3.3 C8:"generativeAItools,specificallyOpenAI’slatestproductcalledChatGPT.Thislargelanguagemodel(LLM)
hasthecapabilitytogeneratecoherentparagraphsoftextandcanbeinstructedtowriteaboutvarioustopics,
includingscience.thestakeholdersinvolvedinthistechnologyareacademicjournalpublishers,suchasScience
andSpringerNature,whohaveintroducednewrulesaddressingtheuseofgenerativeAItoolsintheireditorial
policies.theusersofthistechnologyareresearchersandacademicswhoutilizeChatGPTtoassistinwriting
theirresearchpapers.therelevanceofthistechnologytostakeholdersandusersliesinitsabilitytogenerate
textandaidinthewritingprocess,potentiallyimprovingefficiencyandproductivityinacademicresearch."
10.4 ExamplesofinstancesmissedbyLLMs
(1) TheAI-generatedContentcategoryportraysthechallengesindetectingthedifferentmodalitiesofAIgenerated
content and the potential impacts of such content. For example, by prompting our fine-tuned GPT-3 model
withthefunctionaland contextualdescriptionofChatGPT fromthenews media10.3.3themodelgenerated
animpactrelatedtotheAI-generatedcontentandthe"integrity"ofacademicresearch. Similarly,Mistral-7B,
generatedanegativeimpactpertainingto"concernsabouttheauthenticityoftheAIgeneratedcontent"when
usedinacademicresearch.Incontrast,usingthesamefunctionalandcontextualdescription,GPT-4generateda
negativeimpactrelevanttothecognitiveimpactsresultingfromthe"relianceonChatGPTforacademicwriting
[which]couldleadtoadecreaseincriticalthinking"withoutmentioninganypotentialimpactsofAI-generated
content. Likewise, the impact generated by Mistral-7B-Instruct focused on the over-reliance on ChatGPT in
academicresearchwhichmayleadto"adecreaseinthequalityofresearchpapers,assomeresearchersmay
relytooheavilyonthetool"whenconductingresearch.Additionalnegativeimpactsinthiscategorythatwere
generated by Mistral-7B and GPT-3 include: how AI generated content is becoming "indistinguishable from
humanwriting,makingitdifficulttodetect"andhow"AIgeneratedtextcanmimicthestyleandstructureof
academicwriting".Additionalimpactsincludetheuseof"ai-generatedcontent..tospreadmisinformationand
propaganda"andthechallengesofAI-generatedartwork"rais[ing]questionsabouttheboundariesbetween
ai-generatedartandoriginalartwork".
(2) WithrespecttotheSafetycategory,whenpromptingthemodelstogenerate anegative impactofdriverless
cars10.3.1Mistral-7B-InstructgeneratedanegativeimpactsimilarincontexttotheimpactgeneratedbyGPT-4
in termsofthepotential"lossofjobsforprofessional drivers, suchastaxiand truckdrivers, asthedemand
forhuman-operatedvehiclesdecreases",whereasfine-tunedMistral-7Bgeneratedanimpactpertainingtothe
safetyofdriverlesscars:"driverlesscarsmaynotbeascautiousashumandrivers,leadingtomoreaccidents".
ManuscriptsubmittedtoACMSupportingAnticipatoryGovernanceusingLLMs:EvaluatingandAligningLargeLanguageModelswiththeNews
MediatoAnticipatetheNegativeImpactsofAI 23
(3) FortheAIGovernancecategory,Mistral-7Bgeneratedanimpactaboutthe"needforaglobalregulatoryframe-
workforAItoensuresafetyandaddressesconcernsregardingthepotentialforAItobeusedformaliciouspur-
posessuchascreatingfakenewsandspreadingmisinformation"whenpromptedaboutAI10.3.2.Incontrast,
using thesamefunctionaland contextualdescriptionsofAI,GPT-4generated animpactaboutthepotential
misuseof"AI’sabilitytogenerateplausibleresponsesandproducerealisticimages[that]couldpotentiallylead
tothecreationandspread ofmisinformationorfakenews". Mistral-7B-Instructalsohadasimilargenerated
impactfocusingonAI’scapabilitytogeneraterealisticvideosthat"appearaccuratebutareactuallyfabricated".
OthergeneratedimpactsbyMistral-7Bincludetheimpactsof"thelackofregulationandoversightintheAI
industry[which]hasledtothedevelopment ofchatbotsthatcanspreadmisinformationandengage inhate
speech"and"theneedforinternationalregulationsandagreementstoensurethesafeandresponsibleuseof
AIand autonomousweapons" inthe military.In addition,Mistral-7B generated impactsthatare focusedon
theneedforregulatingAIinspecificindustriessuchashealthcareandlaw.Forinstance,Mistral-7Bgenerated
animpactasaresultof"thelackofregulationandoversight intheuseofAIinhealthcare"thatcanleadto
"unintendedconsequencesandpotentialharmtopatients"andhowthereisa"needformoretransparencyand
accountabilityinthedevelopmentanddeploymentofAIsystems".Inthelegalpractice,Mistral-7Bgenerated
about"theneedforregulationandoversighttoensurethefairandethicaluseofAIinthelegalsystem"and
avoidpotentialbiasandinaccuraciesinlegaldecisions.OtherimpactsgeneratedbyGPT-3inthiscategoryalso
includehow"thedevelopmentofAIhasoutpacedregulation,leadingtoagapbetweentechnologicaladvance-
mentandgovernance"whichmayhaveimplicationsforthepotentialmisuseofAI.
ManuscriptsubmittedtoACM