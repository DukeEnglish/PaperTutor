Distributed fixed-point algorithms for dynamic
convex optimization over decentralized and
unbalanced wireless networks
Navneet Agrawal1, Renato L. G. Cavalcante2, Sławomir Stan´czak1,2
1Technische Universita¨t Berlin, 2Fraunhofer Heinrich-Hertz-Institute
Abstract—We consider problems where agents in a network of these steps for different applications and/or system re-
seek a common quantity, measured independently and periodi- quirements [3]–[8] (also see [1], [9] and references therein).
callybyeachagentthroughalocaltime-varyingprocess.Numer-
However, some advanced techniques in machine learning and
oussolversaddressingsuchproblemshavebeendevelopedinthe
wireless communication that are known to be better suited
past, featuring various adaptations of the local processing and
the consensus step. However, existing solvers still lack support for many current and envisioned applications are still not
for advanced techniques, such as superiorization and over-the- supported by the aforementioned studies. Among these, two
air function computation (OTA-C). To address this limitation, notable techniques are: Superiorization,1 an efficient method
we introduce a comprehensive framework for the analysis of to construct heuristics for constrained optimization problems
distributed algorithms by characterizing them using the quasi-
[10]–[12]; and over-the-airfunctioncomputation(OTA-C),2 a
Feje´r type algorithms and an extensive communication model.
Under weak assumptions, we prove almost sure convergence of scalable solution for distributed function computation over
thealgorithmtoacommonestimateforallagents.Moreover,we wireless networks [13], [14]. In [15], we propose a class
develop a specific class of algorithms within this framework to of distributed algorithms based on the adaptive projected
tackle distributed optimization problems with time-varying ob-
subgradient method (APSM) [16] supporting both of these
jectives,and,assumingthatatime-invariantsolutionexists,prove
technologies.However,theirapplicationiscurrentlylimitedto
itsconvergencetoasolution.WealsopresentanovelOTA-Cpro-
tocolforconsensusstepinlargedecentralizednetworks,reducing the networks with symmetric (undirected) graph topologies.
communication overhead and enhancing network autonomy as In this paper, we overcome these limitations by making
compared to the existing protocols. The effectiveness of the three key contributions. First, we introduce a comprehensive
algorithm,featuringsuperiorizationandOTA-C,isdemonstrated
framework of distributed algorithms that accommodates a
inareal-worldapplicationofdistributedsupervisedlearningover
broader range of optimization techniques and communication
time-varying wireless networks, highlighting its low-latency and
energy-efficiency compared to standard approaches. protocols. We achieve this by characterizing the local pro-
Index Terms—Distributed optimization, quasi-Feje´r mono- cessing step using operators generating quasi-Feje´r monotone
tonicity, superiorization, over-the-air consensus, directed graphs sequences, described later in Definition 1. In the consensus
step,weemployanabstractcommunicationmodelthatextends
[15] tosupportrandomdirectedgraphs.Second,undercertain
I. INTRODUCTION
practicalassumptions, we provideguaranteesfor convergence
We consider distributed optimization problems in multia-
of the proposed algorithms in Theorem 1. Our proofs utilize
gent systems, where the underlying network is decentralized
time-varying quadratic Lyapunov functions [7], [17], making
and time-varying, with possibly random and non-symmetric
the analysis considerably more involved than the undirected
(directed) graph topologies. The objective is for agents to
case in [15]. We also present a specific algorithm based on
reachagreementontheestimateofacommonquantity,whose
thesuperiorizedAPSM (sAPSM)to tacklea classofdynamic
measurements are acquired by each agent independently and
convex optimization problems, and, in Theorem 2, prove its
periodicallyvia some localtime-varyingprocess.Problemsof
convergence to a unique solution. Third, in Section III, we
this type have wide-ranging applications, including, adaptive
propose a novel OTA-C protocol that reduces the commu-
control [1], [2] and distributed learning [3].
nication overhead and grants more autonomy to the agents,
In general, solvers addressing such problems follow a two-
compared to previous studies [3], [5], [18] that require some
stepiterativeapproach:thelocalprocessingstep,whereagents
prior coordination and additional overhead to ensure that the
independently process their acquired measurements, followed
by the consensus step, where they communicate over the net-
1Superiorization [10] is a technique where a sequence of specifically
worktoseekagreement.Overthepastfourdecades,numerous
designedperturbations areaddedtoaniterative algorithm tosteeritsiterates
algorithms have been developed featuring various adaptations towards vectors that are “superior” in terms ofsomedesirable properties. A
superiorizableorboundedperturbationresilientalgorithmenjoysconvergence
Theauthorsacknowledgethesupportofjointproject6G-RIC,projectiden- guarantees oftheoriginal iterative algorithm.
tificationnumbers:16KISK020Kand16KISK030,andtheGermanResearch 2In OTA-C [13], the additive structure of the wireless multiple access
Foundation (DFG) within their priority program SPP 1914 “Cyber-Physical channels (WMAC)is exploited tocompute certain functions, like consensus
Networking”. protocol, efficiently overlargeanddensewireless networks.
4202
naJ
13
]CO.htam[
1v03081.1042:viXraunderlying graph remains balanced or undirected. In Section forthe exchangeofλλλ overa finite-capacitycommunication
k,i
IV, the proposed algorithm, featuring sAPSM and OTA-C, system. We characterize the sequence of operators (T k,i) i∈N
is applied to a distributed supervised learning problem, and explicitly later in Section II-B.
shown to outperform the standard approaches. Intheconsensusstep(1b),agentk incorporatesinformation
Notation:Thespaceofcomplex,real,nonnegativereal,and receivedfromitsneighborsoverthenetwork.Theinformation
naturalnumbers(includingzero)aregivenbyC,R, R ,and exchangeoverthenetworkismodeledbytherandommapping
≥0
N, respectively. Symbols 111 M, I M and denote the vector K k,i which, for almost every (a.e.) ω Ω, takes the form:
of M ones, the M M identity matrix⊗ , and the Kronecker ( i N)( k )(ψψψ RMN) ∈
× ∀ ∈ ∀ ∈A ∈
product, respectively. Any M-dimensional real-valued vector
belongs to the Hilbert space (RM, , ) with inner-product K k,i(ω,ψψψ)=P k,i(ω)ψψψ+nnn k,i(ω), (2)
( vvv,yyy RM) vvv,yyy :=vvvTyyy andinduh c· e· di norm vvv :=√vvvTvvv.
W∀
e
de∈
note
byh ℓ+i
the space of all
nonnegatk ivek
sequences
whereP
k,i
isarandommatrixtakingvaluesinRM×MN,and
of real numbers,1 such that for any sequence (ξ i) i∈N ∈ ℓ+ 1 ψn ψn ψn k ., Ni i os tea tr ha an td to hm e mve oc dt eo lr ii nn (R 2)M coth va et rsm aa ly ard ge epe cn lad sson ofth we iri en lp eu sst
we have ξ < . The underlying probability space is
(Ω, ,P), ai n∈ dN ai rand∞ om variable is a measurable map from protocols with digital and analog transmissions, including the
F P novel OTA-C protocol proposed in Section III.
Ω to some real vector space. Given random variables xxx and
The network is represented by the directed graph :=
yyy, the conditional expectation of yyy w.r.t. the sigma algebra i
generated byxxx is denoted by E[yyy xxx]. ( , i) at any time i N, where i is theG set of
|
dA irecE
ted edges
betwee∈
n the
agents.E Le∈
t
AP×ARMN×MN
be
i
II. GENERALCLASS OF DISTRIBUTED ALGORITHMS the matrix formed by stacking P k,i for all k∈ . Assuming
that each coordinate of vector λλλ RM is ∈ exA changed over
In this paper, we study the general class of distributed k,i
∈
a separate i.i.d. realization of the random graph ,4 the
algorithms that follows an adapt-then-combine [19] strategy. i
expectation of the random matrix P takes the formGP :=
Solvers of this type employ a two-step iterative approach: i i
E[P ] = A I , where A RN×N and, for any
a local optimization step, often implementing a fixed-point (p,qi ) i ⊗ , thM e scalar [A ]i ∈ repr≥ e0 sents the expected
algorithm[4],[8],[20]–[22],followedbyaconsensusstepthat i (p,q)
∈ A×A
edge-weight of the edge from agent q to p in the graph .
fosters agreement among agents using networking protocols i
G
such as broadcast or gossip protocols in wireless networks We make the following assumptions on the sequence of
[1], [3], [5], [18], [23]. In this section, we formulate these graphs ( i) i∈N and corresponding matrices (A i) i∈N.
G
twostepstoaccommodatediverseoptimizationandcommuni- Assumption 1 (Network assumptions). For all i N:
cation techniques, establishing a unified framework for repre- (i) The matrix A is stochastic,5 and it is com∈ pliant with
i
sentingandanalyzingabroadclassofdistributedoptimization the graph , i.e., [A ] >0 if and only if (l,k) .
i i (k,l) i
algorithms, including those employed in the aforementioned G ∈E
(ii)Thereexistsǫ>0suchthat[A ] ǫforallk ,
studies. Later in Section II-C, we also develop a particular and [A ] ǫ for all (l,k) . i (k,k) ≥ ∈A
algorithmunderthisframeworkthataddressesaclassoftime- i (k,l) ≥ ∈Ei
(iii) The graph is strongly connected in expectation,i.e.,
varying distributed optimization problems, and strengthen the there exist n>0,G ni N, such that (A )n >0.
convergence results presented in this section. ∈ i
(iv) E[nnn ψψψ ]=000, P-a.s.
i i
|
A. System description and agent dynamics E[(v P)
Tnnn
E[ k ψψψP ]T i <P i k2 ,] P< -a∞ .s., E[ knnn i k2 |ψψψ i]< ∞, and
Weconsideramultiagentsystemconsistingofanetworkof k i i k| i ∞
N agents,whereeachagentk := 1,...,N implements Remark 1. Assumptions 1(i) and 1(iii) are standard in lit-
the following two-step dynam∈ icsA at ev{ ery time s} tep i N: erature [6]–[8] and 1(ii) facilitates analysis of systems over
∈
directed graphs [7], [17]. Moreover, Assumptions 1(iv) and
λλλ =P (T (ψψψ )) (1a)
k,i X k,i k,i 1(v)areweakerthantheircounterpartsin [15], andhence,the
ψψψ =(1 β )λλλ +β K (λλλ ), (1b)
k,i+1 i k,i i k,i i model in (2) under Assumption 1 is more general.
−
where,startingwithanarbitraryinitializationψψψ ,thecurrent
estimate of agent k at time i is ψψψ RMk, .0 The vector B. Quasi-Feje´rian characterization of (T k,i) i∈N and analysis
k,i
∈
λλλ i is formed by stacking λλλ k,i for all agents k , and the Most fixed-point algorithms (e.g., those with nonexpansive
∈A
sequence (β i) i∈N is a design parameter with the properties: operators) and their variants (e.g., superiorized APSM [12])
( ∀i ∈N) β i
∈
[0,1], and the series i∈Nβ i is divergent, generate quasi-Feje´r monotone sequences (QFMS) of type-III
while i∈Nβ i2 < ∞. In the local Pprocessing step (1a), [24], [25]. Hence, we characterize the sequence of operators
oth pe erc au tor
P
rre Tnt est :im Ra Mte ψψψ k,i RMis fi thr as tt eu mpd ba et de sd lob cy alap inp fl oy ri mng atit oh ne (T k,i) i∈N, for every k ∈A, as generators of QFMS in the
k,i
→
only available to agent k at time i via, for instance, some 3InHilbertspaceH,projectionofyyy∈HontoaclosedconvexsetX ⊂H
m pre oa jesu ctr se 3m ae nn ytp vro ec ce tos rs. iI ntis Rf Mollo ow nte odb ay ct lh oe sem dap ap ni dng cP onX vew xhi sc eh
t
is 4th Ineu an ri aq nu de oP mX g( ryyy ap) h∈ ,tX hes wat ei is gf hy ti sng ovxxxm
e∈
ri Xn itk syyy ed− gexxx sk aH re= rak nyy dy o− mP vX ari( ayyy b) lk esH ..
RM The mapping P X enforces a technical requirement 5AmatrixA∈RN×N iscalledstochastic ifA≥0,andA111N =111N.
X ⊂sense ofDefinition 1 below.In Theorem1, we establish suffi- where, for all k , the cost function Θ : RM R
k,i ≥0
∈A →
cient conditions for almost sure convergenceof the algorithm is convex and possibly nonsmooth with min Θ (xxx) =
xxx∈X k,i
based on these operators to a common point for all agents. 0.6 Define (i) := , := hhh Θ (hhh) =
Q
k∈AQk,i Qk,i
{ ∈ X |
k,i
Definition 1 ((T( iQ)) i∈N : Quasi-Feje´r monotone sequence 0 o} b, jeca tn ivd eas os fum age enth tsa Tt isQ t⋆
o
: fi=
nd
ai∈N soQ lu( ti i) on6= to∅. alI lde ia nl fily n, itt eh lye
( cQ alF leM dS a) Qg Fe Mne Sra gt eo nr) e. raT th oe rwse .rq .tu .e an nc oe no ef mo pp tyer sa et tors (T i( RQ M)) i i∈ f,N fois
r
many problems (P i) i∈N, assumiT ng that such a solution exists.
Tth (e Qs )e (q xxxu )e ,nc xxxe(xxx i) i∈ RN Mof ,v ae nct dor fs og ren ae nr yate xxxdvia( ∀Q i ,∈⊂ thN er) exxx i e+ x1 is=
ts
H suo cw he ave pr, od inu te it sos py rs at ce tm icac la lyus ia nl fit ey asa in bd lel .im Ini ste ted am d,em weory re, lfi an xdi tn hg e
(ǫi i) i∈Ni ∈ℓ+ 10 su∈ ch that: ∈ Q p fir no itb el le ym mt ao nyfin pd ri on bg lea mspo (i Pn it
)
ii ∈n Nt ,h te has tet iso [f 3]s ,o [lu 1t 5i ]o ,n [s 16to ]:all but
( i N) xxx xxx 2 xxx xxx 2+ǫ . (3)
i+1 i i
∀ ∈ k − k ≤k − k Findhhh⋆ ˜ :=liminf (i) = (i) ⋆ = , (5)
Theorem 1. Suppose that Assumption 1 holds in a system ∈Q i→∞ Q Q ⊃Q 6 ∅
where each agent k implements the scheme in (1), n [∈Ni \≥n
(w Th ( ke Q ,r ie k)K ) i∈k, Ni is isgi aven QFb My∈ S(A 2) g, ea nn ed ra, tf oo rr a wl .l r.tk . ∈ seA t, Q(T kk,i ⊂) i∈N RM≡ wh Te hre eC Ad Pe Sn Motes geth ne erc al to essur ae so ef qt uh ee ncse et oC f.
estimates that are
as defined in Definition 1. Moreover, assume that the set known to converge in ˜ [3], [16]. Moreover, the APSM is
⋆ := RM is nonempty. Then, each of Q
Q
k∈AQk
∩ X ⊂
superiorizable, i.e., it is resilient to bounded perturbations.
the following statements holds:
In the following, we first define the sAPSM operators in
(i) (AT lmost sure convergence): Let ψψψ RMN be the
vector formed by stacking ψψψ RM fori all∈ k . For any Definition 2 below, and then, in Theorem 2, prove that the
k,i ∈ ∈A sAPSM based scheme (1) solves (5). Note that the sequence
ψψ aPψ n-⋆ a a.∈ s c. c, uQ a mn⋆ ud, lahth te ie n oc ns ee p,q otu h ine e tn sc Pee -q au( .k se .ψψψ nci e− (ψψψ111 iN ) i∈⊗ Nψψψ is⋆ k b2 o) ui n∈ dN edco an nv der hg ae ss g(T enk(Θ e,i rk a) t) oi∈ rN w.rg .e t.n se er tat Qed kb =y ∩th i∈e
N
QsA kP ,iS [M 12]o .perators is a QFMS
tha( ti :i) ((S (pu ,b qse )quence co )n (s iens N˜us )): There exists N˜ ⊂ N, such qD ue efi nn ci etio gen ne2 ra( t( oT r)( i .Θ) G) i i∈ veN n: aS su ep qe ur eio nr ci eze od fA coP nS vM ex( cs oA stPS fuM nc) tis oe n-
∀ ∈A×A ∈
lim ψψψ ψψψ =0, P-a.s. (Θ i) i∈N, where each Θ i : RM R ≥0 and min xxx∈X Θ i(xxx) =
p,i q,i →
i→∞k − k 0,thesequenceofmappings(T( iΘ)) i∈N generating(xxx i) i∈Nvia:
(iii) (Characterization of accumulation points): If, in addi-
tion,theset ⋆ hasanonemptyinterior,i.e.,forsomeinterior ( i N) xxx =T(Θ) (xxx ):=xxx Φ (xxx )+ζzzz , (6)
point uuu˜ Q ⋆, ̺ > 0 such that uuu RM uuu uuu˜ ∀ ∈ i+1 i i i − i i i i
∈ Q ∃ { ∈ | k − k ≤
(̺ ψψψ} k⊂ ,i)Q i∈⋆ Nis con no vn ee rm gep sty t, oth then e, sf ao mra ell pa og ine tn it nsk X∈
,
PA -, at .sh .esequence Ri ss
e
Mqc ua el il sne cd
de
ea
fio
nfs eA
b
dP
ou
aS snM
:d
(es de iq pu ee
r
Nn tuc )re
(b
xxxag te ion
n
Re sr Ma 7t
i
)o nr, Rw Mh ,er ae nd(ζ Φizzz ii) :i∈ RN Mis →a
Proof. Proof given in the Appendix A.
∀ ∈ ∈
Remark 2. The condition in (3), known as quasi-Feje´r mono- Φ (xxx):=(µ Θ (xxx)/ Θ′(xxx) 2) Θ′(xxx), (7)
i i i k i k i
tonicity (QFM), holds for several fixed-point algorithms, and
it has proven to be an efficient tool for their analysis [24], if kΘ′ i(xxx)
k
6= 0, otherwise Φ i(xxx) = 0, where µ i
∈
(0,2) is a
[26]. However, the analysis of distributed algorithms based design parameter, and Θ′ i(xxx) ∈∂Θ i(xxx).8
on the QMF condition is a novel contribution of this paper.
Wefurthermaketwostandardtechnicalassumptions[3],[16].
Note thatTheorem1 falls shortofan explicitcharacterization
of the point of convergence, for instance, to the set ⋆. In Assumption 2 (Problem-specific assumptions). A time-
Q
Section II-C, we develop a variant of the QFMS generator, invariant solution to all problems in (P i) i∈N exists, i.e.,
for which the point of convergence of the scheme (1) can Q⋆ 6= ∅,and,forallk ∈A,(Θ′ k,i(ψψψ k,i)) i∈N isboundedP-a.s.
be characterized as a time-invariant solution of an infinite
Theorem 2. Suppose that Assumptions 1 and 2 hold in a
sequence of time-varying convex optimization problems.
system where, given Θ
k
:= (Θ k,i) i∈N, each agent k
C. Dynamic distributed convex optimization via sAPSM implements the scheme in (1) where K is given by (2) ∈ anA d,
k,i
In this section, we develop algorithms to solve a class of for all k ∈A, (T k,i) i∈N
≡
(T k(Θ ,ik)) i∈N is a sAPSM sequence
distributed convex optimization problems with time-varying generator as defined in Definition 2. Then, in addition to
objectives. The proposed algorithm is a variation of (1) with the results already established in Theorem 1, the following
a specific QFMS generator based on the superiorized APSM statements hold:
(sAPSM) (see Definition 2). We consider the following prob-
lem P
i
at any time i N: 6Thisisacommonassumptioninsubgradientliterature[3],[5],[12],[16].
P i : ψψψ1∈m Xin ,.i .m .,ψψψiz Ne ∈X∈ k∈AΘ k,i(ψψψ k), s.t. ψψψ 1 = ···=ψψψ N, tio 87 n GA s ii vs f ee ( nq ζu i ae )n cic ∈ oe nN v( e∈ζ xizzz ℓ f+ 1i u) n,i c∈ a tinN od nin ( Θ∃R r :M > RMi 0s )c ( →a ∀l ile R∈d aNa t)s xxxe kq ∈zzzu ie Rkn Mc ≤e ,o r wf . ebo du en fid ne ed ∂p Θer (t xxxu )rb :a =-
X (4) {hhh∈RM |(yyy−xxx)Thhh+Θ(xxx)≤Θ(yyy), ∀yyy∈RM}.(i) The sequence (ψψψ k,i) i∈N asymptotically minimize the where ξ kr and w r are complex-valued random variables rep-
local cost functions, i.e., resentingthefadingchannelbetweenk andr,andthereceiver
noise.
( k ) lim Θ (ψψψ )=0, P-a.s.
k,i k,i
∀ ∈A i→∞ Assumption 3 (WMAC assumptions). For all agents (r,t)
∈
(ii) For an interior point uuu˜ ⋆, let us define sets , and their (inward) neighbors (k,l) r t, the
:= i N min ∈ Q ψψψ xxx > ϑ ,9 and fA ol× lowA ing properties hold: ∈ A ×A
ASS 21 ssu:= mp{{ ti io∈∈ nsN 1|| aP ndkk ∈∈ 2,AA sk uuuu˜ pp− oxxx sψ∈ ψψ el ke tv , hi≤ k a0 tΘ ≤ :k (, rik } ϑ, >Pk, -i 0a− ,.s. rIk n >a 0d ,d} i ξtio >n 0to ) ( (i i) i)C Nh oa in sen :el E: [E w[ r|ξ ]k =r |2 0] ,< E[∞ w, rE 2][ | <ξ kr |2 ,|ξ Elt [|2 w] r< 2∞ w t. 2]< .
P ∀ ∀ ∃ (iii)Therandomvariables| ξ | and∞ w in| the| W| MA| Cm∞ odel
rk r
(9) are independent, and their statistics remains the same for
inf Θ k,i(ψψψ k,i) ξ, P-a.s. (8) the duration of (MB+B′) symbols.
i∈S1∩S2 ≥
k∈A
X Inresponse,atanyiterationi N ofthescheme,agentr
Then, for all k , the sequence of estimates (ψψψ k,i) i∈N receives MB +B′ symbols,∈ where each received symbo∈ l
generated by (1)∈ coA nverges to a solution of (5) P-a.s. A takestheformgivenin(9).GivennoisevarianceE[w 2]and
r
| |
(δ ,δ ), agent r uses the B′ symbols to evaluate: y′ :=
max min r
Proof. Proof given in the Appendix B. 1 B′ q′(b)2 ∆ E[w′ 2], where ∆ := δ δ .
B′ b=1| r | − | r| max − min
Then, for the M sets of B symbols, for each m=1,...,M,
Remark 3. Theorem 2 not only guarantees asymptotic con-
P
agent r evaluates:
vergence to a point that minimizes the cost Θ for each
k,i
agent k , but also characterizes the point of convergence B
explicitly∈ aA s a solution of Problem (5). Note that the point y(m) := ∆ q(m)(b)2 ∆ E[w 2]+δ y′. (10)
of convergencein Theorem 2 is a ˜-valued random variable. r B b=1| r | − | r | min r
Q X
Hence, although the problem itself is deterministic, different
runs of (1) may lead to different estimates in ˜. It can be verified (see [18, Lemma 1]) that y r(m) and y r′ takes
Q the following form:
III. OTA-CFORDECENTRALIZEDCONSENSUS y(m) = ν(m)λ +η(m), y′ = ν′ +η′, (11)
r jr j r r jr r
In this section, we present a novel OTA-C protocol that j X∈Ar j X∈Ar
extends our prior work [15], [18] with some notable dif-
where,forallj ,wedefineν(m) := Pj B ξ(m)(b)2,
ferences, as mentioned in Remark 4. First, we provide a ∈Ar jr B b=1| jr |
brief overview of the OTA-C protocol for implementing the and ν′ := Pj B′ ξ′ (b′)2. It turns out that the random
jr B′ b′=1| jr | P
consensus protocol (1b) over a random directed graph (the variables η(m) and η′ are zero-mean, and with Assumption
r P r
protocol is given later in (12)). Then, in Proposition 1, we 3(iii), we have also E[ν(m)]=E[ν′ ] for all m.
jr jr
prove that the sufficient conditions in Theorem 1 and 2 are
The consensus protocol implemented by each r using
satisfied for the proposed OTA-C protocol based consensus. information (y(m)) and y′ obtained as above is: ( ∈ i A N)
Consider agent r and its (inward) neighbors in r r ∀ ∈
rth eme as ie nt
sA
thr
e
: s= ame{k
fo∈
r∈
evA
eA
ry|
i( tk er, ar t)
ion∈
iE}N. ,A ws eth oe mp itro it no dc eo xl ψψψ r,i+1 =(I M −β i Diag(yyy′ r,i)) λλλ k,i+β i yyy r,i, (12)
i
g
kri an phth ,e rfof gro el
m
nlo ew ra∈i tn eg sM. aFo
s:=
er qe u{v e1e nr
,
cy
.
e.m
. o,
ft Mh Br }e
,
ca ol ai mnz∈ ya pt li
t
eo
r
xn
a -n
vo
s
amf luit th
et
de
ing
rr aa nn
a
dd
g
oo
en
mm
t
Rw prMh ae c,r te
ica
eyyy
n
,r
d
E=
γ [yr
r′γ ]r
∈
c[ ay n(r( 01)
,
b,
(
e. E.
[
e.
y
s,
r′
ty
i]
m)r(M
− a1
t) e)]T di,
s
fyyy ro′ r
a
m=
de
psγ air
sg
tn[y itpr′ e,
a
r. ara. tim. o, ney str′
e
.] rT
.
ThI∈
n
e
nu∈ mbA ers (s (1),...,s (B)) as follows: for all b = 1,...,B following proposition ensures that the sufficient conditions
k k
and k , s (b) := g (λ )U (b), where λ := λλλ(m) required by Theorem 1 and Theorem 2 are satisfied by the
∈A k k k k k k,i proposed OTA-C protocol based consensus step in (12).
denotes the mth element of λλλ , function g (x) := P (x
k,i k k
p −
δ min)/(δ max δ min), (δ max,δ min) := (max ,min ), and Proposition 1. Consider a system where agents exchange
− X X
U k isani.i.d.complex-valuedrandomvariablewith U k(b) = information using the proposed OTA-C protocol, where the
1, and E[U k] = 0. In addition, once every i N| , age| nts conditions in Assumption 3 and Assumption 1(iii) are valid.
∈
transmitB′ randomnumbers(s′ k(1),...,s′ k(B′)), encodedas Then, for every agent implementing the consensus step (12)
above with a constant value ( k ) λ k =δ max. The signal in Scheme (1), the resulting communication model takes the
∀ ∈A
receivedbyanyagentr overWMACduetosimultaneous form in (2), and the conditions in Assumption 1(i), 1(ii), and
∈A
transmissions by all r is modeled as [13]: ( b=1,...,B) 1(iv) are satisfied.
A ∀
q r(b)= ξ kr(b)s k(b)+w r(b), (9) Proof. Proof given in the Appendix C.
k X∈Ar
Remark 4. Note that B′ can be chosen independently, which
9Given a convex function Θ : RM → R ≥0 and c ≥ 0, we define results in a reduced communication overhead compared to
lev≤cΘ:={hhh∈RM |Θ(hhh)≤c}. [18], where B′ = MB. In addition, the requirement in [15,Def.3.1]thateveryrealizationofgraph mustproducearow- We simulate a time-varying network of N =100 agents as
i
G
stochastic weight matrix is relaxed in this paper, leading to a geometric graph based on the locations sampled uniformly
fewer constraints on the WMAC model. Moreover, we allow randomly from the dataset at random intervals. The transmit
agents to independently select their transmit powers, which power P is sampled independently and randomly for each
k
was previously unsupported in [15], [18] as the graph was agent k such that the resulting directed graph is strongly
∈A
required to be undirected. connectedinexpectation.Thechannels( (k,r) )ξ and
i kr
∀ ∈E
noise ( r ) w are modeled as a circularly-symmetric
r
IV. DISTRIBUTED MACHINE LEARNING APPLICATION zero-me∀ an∈ coA mplex Gaussian random variables, with vari-
We simulate the task of supervised learning of a nonlinear ance of the channel proportional to the inverse of squared
function using data distributed over a decentralized network. distance (path loss), and variance of noise fixed to 9dBm
−
The data10 consists of locations xxx := [0,1000]3 and for all agents. Agents randomly choose to either transmit
corresponding measurements f(xxx) ∈ [0,D 1]. At random times or receive at any iteration i N (half-duplex system). Other
(l i) i∈N N, agents move to a ne∈ w location and obtain a design variables are set to t∈ he following values: M = 50,
zn eo ri osy -mm ea⊂ e nasu Gr ae um sse in at nyˆ rk a,l ni d= omf n(xxx uk m,l bi) er+ we ik th,li v, aw rih ae nr ce ee 0k ., 0li 9.is Aa t B 10−= 6(2 i0 /, 10B 0′ += 12 )−B 1, ,( a∀ ni d∈ (N i) β Ni )(:= k( ⌊i/5 )0 µ⌋) k− ,i0 =.51 0, .ζ 5i . :=
⌊ ⌋ ∀ ∈ ∀ ∈A
every i N, each agent implements (1) using the sAPSM We implement two schemes based on the proposed OTA-
generato∈ r sequence (T k(Θ ,ik)) i∈N in (1a) (as in Theorem 2), C protocols, and three standard communication protocols:
(OTAC-S):sparsity-promoting,overdirectedgraphs;(OTAC):
and the OTA-C based consensus step (12). The sequence
without sparsity, over directed graphs; (BDC): digital broad-
of bounded perturbations (ζ izzz k,i) i∈N is designed to promote
cast, where we assume Rayleigh fading channels with outage
sparsityinvectorλλλ which,asdescribedlaterinthissection,
k,i
probabilityof20%atdistance500mfromtransmitter;(NOC):
saves energy in communication using the proposed OTA-C
no information sharing; and (CEN): perfect (centralized and
protocol.Weonlyprovideabriefdescriptionoftheapplication
noiseless) information sharing. Note that except OTAC, and
here and refer the readers to [15] for more details.
BDCschemes,allotherschemesintroducesparsity-promoting
The cost functions (Θ k,i) i∈N, for all k , are designed
∈A perturbations.
such that they satisfy the conditions in Assumption 2, and
a solution of (5) gives a reasonable estimate of the function
to be learned. We use the multi-kernel approach [28] with 0 OTACS
random Fourier features (RFF) approximations [29] to model OTAC
thenonlinearfunctionf asfollows[30]:letfˆ(xxx):=hhhT ϑϑϑ(xxx), BDC
where, for a design parameter M > 0,M N, the vector NOC
hhh RM is to be learned, and ϑϑϑ : R∈ M is the vector −5 CEN
∈ D →
of RFF functions, fixed and known to all agents. The cost
function Θ is defined as: ( i N)( k ) Θ (xxx) :=
k,i k,i
xxx P (xxx) ψψψ P (ψψψ )∀ w∈ hereψψψ∀ ∈ isA theestimateof
k,i k,i k,i k,i k,i
k age− ntk at timkk e i, a− nd P is thk e projectiononto := hhh: −10
k,i k,i
hhhTϑϑϑ(xxx ) yˆ κ , where l N´, κ 0Q is a des{ ign
|
k,li
−
k,li|≤ k
}
i
∈
k
≥
parameterandxxx isthelocationofagentkattimei.In
set , the
park a, mli
e∈ teD r κ is chosen such that Assumption 2
k,i k
Q −15
is satisfied with highprobability.Theexpressionof projection
0 0.2 0.4 0.6 0.8 1
mapping P onto set can be found in [28].
k,i k,i
We assume that theQ set of optimal solutions is contained Iteration i ·104
in := [δ ,δ ]M where δ = 1 and δ = 0
X min max max min Fig.1. EstimationerrorintermsofNMSE
for the sparsity-promoting scheme, otherwise δ = 1.
min
To get δ = 0, model fˆ is modified by introduc− ing
min The performance is compared in Figure 1 using a separate
another copy of the RFFs from the original model with a
test dataset = (xxx,f(xxx)) over the run of 10000 iterations
negative sign. For the sparsity-promoting scheme, we design R { }
in time. The metric used for comparison is the normalized
zzz as: ( k )( i N) zzz := ζ−1 (W (yyy ) yyy ),
wk h,i ere yyy ∀ :=∈A ψψψ ∀ ∈Φ (ψψψk,i ) andi W :k R,i Mk,i −RMk,i is mean square error (NMSE), given by
k,i k,i k,i k,i k,i
defined element-wise− , for each m=1,...,M, as W→ ( km ,i)(x):=
e(i)=
1 1 |fˆ(hhh k,i;xxx) −f(xxx) |2
,
sign(x) x ζ (yyy [m] +ς )−1 , where ς > 0 is a N f(xxx)2
designpar| am| e− teri ,s| igk n, (i− a)1 :=| a/ai ,and+
[a] :=max(a,0).In
|R| (xxx,f X(xxx))∈R k X∈A | |
+
(cid:2) | | (cid:3)
essence, using the prescribed design, (ζ izzz k,i) i∈N reduces the where each result is averaged over 100 independent runs. As
reweighted ℓ -norm [31] of yyy :=ψψψ Φ (ψψψ ), which expected,the bestandworstperformingscheme are CEN and
1 k,i k,i k,i k,i
−
leads to a sparse λλλ . NOC, respectively. All three proposed OTA-C based schemes
k,i
performbetter than the BDC scheme, exhibitingthe merits of
10Theoriginal dataset[27]islinearly scaled, anddistances areinmeters. OTA-C over the standard channel separation based strategy.
)Bd(ESMNThe OTAC scheme (without sparsity) gives the best results [13] Mario Goldenbaum and Slawomir Stanczak, “Robust analog function
in the long run, whereas sparsity-promoting scheme OTAC-S computationviawirelessmultiple-access channels,” IEEETransactions
onCommunications, vol.61,no.9,pp.3863–3877, 2013.
showsfasterconvergenceinitially.Oneplausiblereasoningfor
[14] Navneet Agrawal, Matthias Frey, and Sławomir Stan´czak, “A scalable
this phenomenon is that proximity of the optimal estimate to max-consensusprotocolfornoisyultra-densenetworks,” in2019IEEE
the set of sparse vectors enables faster convergence in the 20thInternationalWorkshoponSignalProcessingAdvancesinWireless
Communications (SPAWC).IEEE,2019,pp.1–5.
beginning, but reaches an error floor as more information
[15] Navneet Agrawal, Renato L. G. Cavalcante, and Sławomir Stan´czak,
arrives.Itisworthnotingthatthesparsity-promotingschemes, “Dynamic distributed convex optimization ”over-the-air” in decentral-
i.e., OTAC-S, NOC and CEN, lead to sparse vectors λλλ ized wireless networks,” in ICASSP 2023 - 2023 IEEE International
k,i
ConferenceonAcoustics,SpeechandSignalProcessing(ICASSP),2023,
with less than 10% nonzero entries, i.e., more than 80%
pp.1–5.
energy-savingincommunicationcomparedtoOTACandBDC [16] Isao Yamada and Nobuhiko Ogura, “Adaptive projected subgradient
schemes. methodforasymptoticminimizationofsequenceofnonnegativeconvex
functions,” Numerical Functional Analysis and Optimization, vol. 25,
no.7-8,pp.593–617,2005.
V. CONCLUSION
[17] Behrouz Touri and Angelia Nedic´, “Product of random stochastic
The paper introduces a unified framework for the devel- matrices,” IEEE Transactions on Automatic Control, vol. 59, no. 2,
pp.437–448, 2013.
opment and analysis of distributed algorithms, showcasing
[18] Navneet Agrawal, Renato LG Cavalcante, Masahiro Yukawa, and Sla-
their adaptability to various optimization and communication womir Stanczak, “Distributed convex optimization” over-the-air” in
technologies,bothcurrentandprospective.Ourfutureresearch dynamicenvironments,” arXivpreprintarXiv:2307.04913, 2023.
[19] AliHSayed, “Diffusionadaptation overnetworks,” inAcademicPress
will focus on deriving theoretical bounds on the convergence
LibraryinSignalProcessing,vol.3,pp.323–453.Elsevier, 2014.
rate, with a goal towards faster solutions. Additionally, we [20] Dimitri P Bertsekas, “Distributed asynchronous computation of fixed
aim to harness cutting-edge technologies like multi-antenna points,” MathematicalProgramming,vol.27,no.1,pp.107–120,1983.
[21] Daniel Fullmer, Ji Liu, and A Stephen Morse, “An asynchronous
systemsandlowresolutionADC/DACtofurtheroptimizeand
distributed algorithm forcomputing a commonfixed point ofafamily
accelerateouralgorithmsinpractice.Theseexcitingprospects of paracontractions,” in 2016 IEEE 55th Conference on Decision and
promise to drive advancements in the field of distributed Control(CDC).IEEE,2016,pp.2620–2625.
[22] Ji Liu, Daniel Fullmer, Angelia Nedic´, Tamer Bas¸ar, and A Stephen
optimization and push the boundaries of what is achievable
Morse, “A distributed algorithm for computing a common fixed point
in dynamical systems. of a family of strongly quasi-nonexpansive maps,” in 2017 American
ControlConference (ACC).IEEE,2017,pp.686–690.
REFERENCES [23] Angelia Nedic, Asuman Ozdaglar, and Pablo A Parrilo, “Constrained
consensusandoptimizationinmulti-agentnetworks,”IEEETransactions
[1] AngeliaNedic´andJiLiu,“Distributedoptimizationforcontrol,”Annual onAutomaticControl,vol.55,no.4,pp.922–938, 2010.
Review ofControl, Robotics, andAutonomous Systems, vol.1,pp.77– [24] Patrick L Combettes, “Quasi-feje´rian analysis of some optimization
103,2018. algorithms,” inStudiesinComputationalMathematics,vol.8,pp.115–
[2] Kai Yang, Tao Jiang, Yuanming Shi, and Zhi Ding, “Federated 152.Elsevier, 2001.
learning via over-the-air computation,” IEEETransactions onWireless [25] Heinz H. Bauschke and Patrick L. Combettes, Convex Analysis and
Communications, vol.19,no.3,pp.2022–2035, 2020. Monotone Operator Theory in Hilbert Spaces, Springer International
[3] Renato L. G. Cavalcante and Sławomir Stan´czak, “A distributed Publishing, secondedition, 2017.
subgradient method for dynamic convex optimization problems under [26] Patrick L Combettes and Jean-Christophe Pesquet, “Stochastic quasi-
noisyinformationexchange,” IEEEJournalofSelectedTopicsinSignal feje´r block-coordinate fixed point iterations with random sweeping,”
Processing,vol.7,no.2,pp.243–256, 2013. SIAMJournal onOptimization, vol.25,no.2,pp.1221–1248, 2015.
[4] John Tsitsiklis, Dimitri Bertsekas, and Michael Athans, “Distributed [27] Dan Seidov, Alexey V. Mishonov, Tim P. Boyer, Olga K.
asynchronous deterministic and stochastic gradient optimization algo- Baranova, Ebenezer Nyadjro, Scott L. Cross, Arthur R. Par-
rithms,” IEEE transactions on automatic control, vol. 31, no. 9, pp. sons, and Katharine A. Weathers, “Gulf of mexico regional
803–812, 1986. climatology version 2 (NCEI accession 0222571) [t13mn10],”
[5] AngeliaNedicandAsumanOzdaglar, “Distributedsubgradientmethods https://doi.org/10.25921/4sxe-ay54,2020, Accessed[08
formulti-agentoptimization,” IEEETransactionsonAutomaticControl, Aug2022].
vol.54,no.1,pp.48–61,2009. [28] MasahiroYukawa, “Multikernel adaptive filtering,” IEEETransactions
[6] AngeliaNedic´andAlexOlshevsky,“Distributedoptimizationovertime- onSignalProcessing,vol.60,no.9,pp.4672–4682, 2012.
varyingdirectedgraphs,” IEEETransactionsonAutomaticControl,vol. [29] Ali Rahimi and Benjamin Recht, “Random features for large-scale
60,no.3,pp.601–615,2014. kernel machines,” in Advances in Neural Information Processing
[7] AngeliaNedic´ andJiLiu, “Onconvergencerateofweighted-averaging Systems,J.Platt,D.Koller,Y.Singer,andS.Roweis,Eds.2007,vol.20,
dynamics for consensus problems,” IEEE Transactions on Automatic CurranAssociates, Inc.
Control, vol.62,no.2,pp.766–781,2016. [30] Minglin Shen, Kui Xiong, and Shiyuan Wang, “Multikernel adaptive
[8] XiuxianLiandLihuaXie,“Distributedalgorithmsforcomputingafixed filtering based on random features approximation,” Signal Processing,
pointofmulti-agentnonexpansiveoperators,” Automatica,vol.122,pp. vol.176,pp.107712,2020.
109286,Dec.2020. [31] EmmanuelJCandes,MichaelBWakin,andStephenPBoyd, “Enhanc-
[9] Tao Yang, Xinlei Yi, Junfeng Wu, Ye Yuan, Di Wu, Ziyang Meng, ingsparsitybyreweightedℓ1minimization,”JournalofFourieranalysis
Yiguang Hong, Hong Wang, Zongli Lin, and Karl H Johansson, “A andapplications, vol.14,no.5,pp.877–905, 2008.
surveyofdistributedoptimization,” AnnualReviewsinControl,vol.47, [32] H.RobbinsandD.Siegmund,“Aconvergencetheoremfornonnegative
pp.278–305, 2019. almostsupermartingales andsomeapplications**research supportedby
[10] YairCensor,RanDavidi,andGaborTHerman, “Perturbationresilience nih grant 5-r01-gm-16895-03 and onr grant n00014-67-a-0108-0018.,”
and superiorization of iterative algorithms,” Inverse problems, vol. 26, in Optimizing Methods in Statistics, Jagdish S. Rustagi, Ed., pp. 233–
no.6,pp.065008,2010. 257.Academic Press,1971.
[11] Jochen Fink, “Fixed point algorithms and superiorization in commu- [33] YuriErmoliev, “stochastic quasigradient methods and their application
nication systems,” Ph.D. dissertation, Technische Universia¨t Berlin, tosystemoptimization,” Stochastics, vol.9,no.1-2,pp.1–36,1983.
Germany,2022. [34] Renato L.G.Cavalcante, AlexRogers,Nicholas R.Jennings, andIsao
[12] JochenFink,Renato LGCavalcante, andSławomir Stan´czak, “Superi- Yamada, “Distributed asymptoticminimization ofsequences ofconvex
orizedadaptiveprojectedsubgradientmethodwithapplicationtoMIMO functionsbyabroadcastadaptivesubgradientmethod,”IEEEJournalof
detection,” IEEETransactions onSignalProcessing,2023. Selected TopicsinSignalProcessing,vol.5,no.4,pp.739–753, 2011.APPENDIX D i.Forasequenceofdeterministicmatrices,strongaperiodic-
Webeginbyreproducingawell-knownresultinthefollow- ity simply meansthat thereexists γ >0 such that[D i] (p,p)
ing, which we will use extensively in our proofs. γ for all p and i N [17]. As [A i] (p,p) ǫ > 0, b≥ y
definition,
w∈
e
A
have
[D∈
] (1 β )+β
ǫ≥
> min(ǫ,1)
P prr oo bp ao bs ii lt ii to yn sp2 a. ce(
,
a[3 n2 d, Theorem 1]) .L .e .t b( eΩ, aF s, eP q) ueb ne ceth oe
f
sinceβ i ∈(0,1).Hencei ,( (p D,p) i) i≥ ∈N sa− tisfiei sstroni gaperiodicity.
1 2 Let beanontrivialsubsetofagentindices,i.e., but
sub-σ-algebras of .
FoF
r
ea⊂ chF
n
⊂N,
let z n, β n, ξ n, and ζ n = S or = ,anddefine c := ascompleS me⊂ ntA of .
F ∈
be nonnegative n-measurable random variables such that S Th6 enA , sincS e 6 eac∅ h A is comS pliant A wi\ thS a strongly connectS ed
F i
E[z ] z (1+β ) ζ +ξ . (13) graph by Assumption 1(i) and 1(iii), there are edges with
n+1 n n n n n
|F ≤ − nonzero weights from a node in to c and vice versa. It
If, in addition, the series n∈Nβ n and n∈Nξ n converges follows that, for all i N, there exS ists aS α>0 such that:
P-a.s., then, the limit lim z exists and finite, and the ∈
n→∞ n
series n∈Nζ n convergesP . P [A i] (p,q) ≥α [A i] (q,p). (16)
p∈Sq∈Sc p∈Sq∈Sc
A. ProPof of Theorem 1 X X X X
We begin by concatenating the consensus step (1b) for all Multiplying both sides of (16) by β i > 0, we get the same
agents in the network as follows: ( i N) inequality for all D i, since [D i] (p,q) =β i[A i] (p,q) for p=q.
ψψψ =((1 β )I
A
+β P )λλλ
+∀ β∈
nnn =:Gλλλ +eee ,
Hence, (D i) i∈N is cut-balanced with coefficient α>0. 6
i+1 i MN i i i i i i i i
−
(14)
Motivated by [7], [17], our proof uses a quadratic time-
where, ψψψ , nnn , and P are obtained by stacking ψψψ , nnn , varying Lyapunov function V(i,yyy), defined as: ( i N)(yyy
and P i colui mn-wisei for all agents k , respectivk e,i ly, ak n,i d RM) ∀ ∈ ∈
k,i
recall that I is an identity matrix o∈ f sA ize MN. Here and
MN
henceforth, we define the following shorthand notations for V(i,yyy):= π k,i ψψψ k,i yyy 2, (17)
k − k
convenience: ( i N) k∈A
∀ ∈ X
G i :=E[G i], G i :=(1 −β i)I MN +β iP i, where π i ∈RM >0 is as specified in Lemma 1.
eee i :=β i(P˜ iλλλ i+nnn i), P˜ i :=P i −P i, P i :=E[P i] denIn oteth te hefo cll oo nw di in tig o, naw le exu ps ee ctt ah te ionsh Eor [than ψψψd ]n .o Wta etio pn roE cei e[ d·] bto
y
G i =D i ⊗I M, D i :=(1 −β i)I N +β iA i, verifyingtheconditionsrequiredforap· p| licai tionofProposition
where, in the last definition, we use the fact that P i = 2 to the sequence (V(i,yyy)) i∈N for someyyy ∈Q⋆. To this end,
A I (see discussion following equation (2)). The matrix in the following, we first establish an inequality similar to
i M
G k,⊗
i
RM×MN is formed by taking k rows of the matrix (13) byboundingE i[V(i+1,yyy)]. Incorporatingthe definition
G co∈ rrespondingto the kth agent, i.e., rows(k 1)m+1 to of V, we have:
i
km of the matrix G . −
We will use the qi uadratic time-varying Lyapunov function E i[V(i+1,yyy)]= π k,i+1E i ψψψ k,i+1 yyy 2 .
k − k
(described in the next paragraph) for our proofs. In the k∈A
X (cid:2) (cid:3)
subsequentdiscussion, thefollowingresultfrom[7], [17] will
The term E ψψψ yyy 2 in the sum above can be fur-
be helpful. i k k,i+1 − k
ther expanded by using (1b) to replace ψψψ , as follows:
k,i+1
Lemma 1. Suppose that the sequence of matrices (A i) i∈N ( k ) (cid:2) (cid:3)
∀ ∈A
satisfies the conditions in Assumption 1(i)-(iii). Then, for the
s βe iq )Iu Nen +ce βo iAf m i,a tt hr eice fos ll( oD wii n) i g∈N ho, lw dsh :ere ( ∀i ∈N) D i = (1 − E i (cid:2)=kψψψ Ek i,i+ k1 G− k,y iyy λλλk i2 −(cid:3)=
yyy
kE 2i (cid:2)+kG Ek i,i kλλλ eeei k+
,i
keee 2k,i +− 2yyy Ek i2
(cid:3)eeeT k,i(G k,iλλλ
i
−yyy)
( ∀i ∈N) π iT =π iT +1D i, (15) =E i(cid:2) kG k,iλλλ i −yyy k2 (cid:3)+E i(cid:2) keee k,i k2 (cid:3), (cid:2) (18) (cid:3)
where eachvectorπ i ∈RM ≥0 is stochastic,i.e., sum upto one, where th(cid:2)e last expression(cid:3) follow(cid:2)s from:(cid:3)
and there exists some δ >0 such that π δ for all k
k,i
and i ∈N, where π k,i is the kth coordinate≥ of π i. ∈A E i eeeT k,i(G k,iλλλ i −yyy)
T
Proof. The proof essentially follows from [17, Lemma 9] (cid:2)=β E (P˜ λλλ +(cid:3) nnn ) (G λλλ yyy)
by establishing that the sequence (D ) satisfies the strong i i k,i i k,i k,i i −
i
aperiodicity and cut-balancedness properties, and that each =β i(E[hP˜ k,i]λλλ i+E[nnn k,ii])T(G k,iλλλ i yyy)
−
D i is a stochastic matrix. Then, by the definition of the class =0,
⋆ of sequence of matrices or chains (cf. [17, Def. 3]), the
P
results of this Lemma follow immediately. where we use the properties that λλλ is a (deterministic)
i
Since A is stochastic for all i N (Assumption 1(i)), the function of ψψψ , E[P˜ ] is zero by definition of P˜ , and
i i k,i k,i
property that D is stochastic foll∈ ows from the definition of E[nnn ] is zero by Assumption 1(iv).
i k,iBefore we proceed, we reproduce the following identity In lightof the discussion above,(18) leadsto the following
from [7, Lemma 5]. For all xxx,yyy in RN, and scalar c R, expression for E [V(i+1,yyy)]:
i
∈
where xxx =1, the following holds:
n n E [V(i+1,yyy)]= π λλλ yyy 2 a +˜b , (20)
i k,i k,i i i
P N 1 N k∈A k − k −
(xxxTyyy c)2 = xxx (yyy c)2 xxx xxx (yyy yyy )2. X
n n n n′ n n′
− − − 2 − where we define
n=1 n,n′=1
X X
(19) 1
a := π [D ] [D ] λλλ λλλ 2,
i
2
k,i+1 i (k,p) i (k,p′)
k
p,i
−
p′,i
k
In the following, using the identity (19), we would like to k∈A p∈Ap′∈A
e thx epa en xd prt eh se sie ox npr oe fss thio en normk∈A Gπ k,i+ λλλ1 kG yyyk, 2iλλλ ii n− (yyy 18k )2 ,. dE ex fip na en ddi fn og
r
˜b i := X π k,i+1E iX keee k,X i k2 .
k,i i
vectors in RM, we obtP ain: k − k k X∈A (cid:2) (cid:3)
Next, we replace λλλ using (1a), and using the definition
k,i
M
of QFMS generator sequences in Definition 1, it yields:
G λλλ yyy 2 = (([G ] )Tλλλ yyy(m))2,
k
k,i i
− k
i (fkm,:) i
−
m=1 λλλ yyy 2 = T(Qk)(ψψψ ) yyy 2
X k k,i − k k k,i k,i − k (21)
w 1)h Mere +w me rd oe wfin oe
f
G[G i .] (fkm,:) ∈ RMN as the f km := (k − ≤kψψψ k,i −yyy k2+ǫ k,i, P-a.s.
i
In the following, we consider any mth summand Therefore,bydefiningb i :=˜b i+ k∈Aπ k,i+1ǫ k,i,equation
(([G ] )Tλλλ yyy(m))2intheaboveexpression,andexpand (20) becomes:
i (fkm,:) i − P
it as follows: E [V(i+1,yyy)] V(i,yyy) a +b P-a.s. (22)
i i i
≤ −
π (([G ] )Tλλλ yyy(m))2
k,i+1 i (fkm,:) i − Note that a i and b i are nonnegative random variables. More-
k∈A
X over, b is convergentdue to the following:
i∈N i
=
k
X∈Aπ k,i+1
" p X∈Aq
X∈M[G i] (fkm,fpq)(λλλ i(fpq) −yyy(m))2
E
i(a k) nnnP kE
,i
ki
2
(cid:2)keee +k, 2i Ek2
i(cid:3)
kP˜≤
T k,innn
k,β
i
ki2 k( λE
λλ
i[ kkP˜ )T k ,, wiP˜ hk e, ri ek2 E] [E ki
P˜ (cid:2)T
kk ,λλλ iPi ˜k k2
,(cid:3)i
k2+
],
−
1
2
p,q
p′,q′[G i] (fkm,fpq)[G i] (fkm,f p′q′)(λλλ( ifpq) −λλλ( if p′q′) )2
#
AE i ss(cid:2) (cid:2)uk mnnn k p, ti ik o2 n(cid:3) (cid:3), 1(a ivn )d
,
ahE ni dhEkP i˜T k, λλi λnnn ik, 2i k iisia br oe unb do eu dnd (Ped -a.( sP .)-a b. es c.) aub sy
e
XX k k
λλλ is a vector in the compact set (see (1a)), and
k,i
=(a) k∈Aπ
k,i+1
"
p∈A[D i] (k,p)(λλλ( pm ,i) −yyy(m))2 con(b v) ert gh ee ntse br yie ds
efini i∈ tiN
onǫ .k,(cid:2) i, for a(cid:3) llX k ∈A, and i∈Nβ i2 are
X
1
X ApplyingPropP
osition2
onsequences(V(i,yyy))P
i∈N, (a i) i∈N,
− 2
p∈Ap′∈A[D i] (k,p)[D i] (k,p′)(λλλ( pm ,i) −λλλ( pm ′,i))2 #, ia nn gd r( eb si u) li t∈ sN :, along with the inequality (22), yields the follow-
X X
where, for convenience, we define := 1,...,M . Since (*) The sequence (V(i,yyy)) i∈N is convergent,P-a.s., and
matrix G i = D
⊗
I, the elementM [G i] (fk{ m,fpq) is } nonzero T(* h* e) rt eh se us lter (i *e )s givi e∈ sN ta hi atc to hn eve sr eg qe us e, nP c- ea. (s.
π ψψψ
[o Gnly ] when (p =,k) [D∈ ] Ei ,an id .e.,m the= vaq l, uean isd ti hn e t sh ais meca fs oe r, yyy 2) i∈N convergesP .Moreover,from the fact thk∈ atA (βk i),i ik ∈Nk c,i on− -
i (fkm,fpq) i (k,p) vek rgestozero,weknowthatD I,andhP ence,π 1111 .
all m . Therefore, by removing the zero elements in i → i → N N
the sum [∈ DmM a ]tion
.
Fp o∈ rA theq v∈ eM ct[ oG ri λλλ] (f ,km th,f epq e), lew me enr ted fuced i nt ot wo 11I 1tfol yyylow 2)s i∈th Nat ct oh ne vs ee rgq eu sen (c Pe -a( .s.)k .∈A Ak nψψψ d,k, si i− ncyyy ek y2 yy) i b∈ eN lo= ng( skψψψ toi − a
corp r∈ eA sponi d( sk, tp o) P the eleP ment f ,i since q = m, ( wpq h) ich in bo⊗ undk ed set , the sequenceP (ψψψ i) i∈N is bounded, and hence,
(pm) X
P hasan accumulationpoint.This provespart(i) of Theorem1.
turn correspond to the mth element ofλλλ . This leads to the
p,i
From result (**), again using the fact that π is bounded
expression (a) above. k,i
below by δ >0 forall i N and k , we can lowerbound
In the first expression in the right-hand side of (a) above,
let w :=(λλλ y)2, where we suppressed the dependence a i as a i (δ/2)h i for al∈ l i N, wh∈ erA e h i is given by:
p,i p,i ≤ ∈
−
on m for convenience, and, with a slight abuse of notation, h := [D ] [D ] λλλ λλλ 2,
define y :=yyy(m). By defining www as the vector stacking w i i (k,p) i (k,p′) k p,i − p′,i k
for all p , we can write:
i p,i (k,p X,p′)∈A3
∈A =2 β (1 β )[A ] λλλ λλλ 2
i i i (p,p′) p,i p′,i
− k − k
π [D ] (λλλ(m) yyy(m))2 =πT Dwww . p,p X′,p6=p′
k,i+1  i (k,p) p,i −  i+1 i i +2 β2[A ] [A ] λλλ λλλ 2
k X∈A p X∈A i i (p,p) i (p,p′) k p,i − p′,i k
Using
Lemm
a 1 above, we know that
 p,p X′,p6=p′
+ β2[A ] [A ] λλλ λλλ 2.
π iT +1D i =π iT. k,p,p′ X,k6=p6=p′ i i (k,p) i (k,p′) k p,i − p′,i kThus,iftheseries a converges,thentheseries h every δ > 0 there exists N N such that for all i N ,
em au cs ht sc uo mnv mer ag ne da is nw tP he eli l∈ . abAN on vdi ef eo xr pt rh ee sss ie or nie os fh ii∈ mN uh si tt co oc nPo vn ei v r∈ geN erg .e Ii t, we Ch oa mve b2 i| n( iG ng( pm , (i a) )− anG d( pm ′ (, bi) )) ,T wλλλ2 i e|∈ h< avδ e2.
the following
resul≥
t,
tha2
t
P
can be verified that the second and third summands converge holds for each m= 1,...,M and all (p,p′) 2: for every
d ou f Ue λλλ spt io , ni gt ah n te d hac [ to An fi av ] ce ( tpr ,g p te h′)n ac tfe o fr oo raf l als le ( lr pi (,e pps ,′ q) P )∈i∈ AN 2β ,ai2 n thdan eid c∈ ob ro N ru e.n spd oe nd dn ie ns gs δ i3 ≥> N0 3,th we ere he ax vi est |s ψψψN ( pm ,i3 +) 1= −m ψψψa ( px m ′,( i) +N 11 |,N <2) δ 3s .u∈ c IthA ft oh la lot wf sor tha al tl
i lim ψψψ ψψψ = 0. Hence, part (ii) of Theorem 1 is
component of A is bounded below∈ byE ǫ, i.e., [A ] ǫ i→∞ k p,i − p′,i k
i i (p,q) proved.
≥
(see Assumption 1), the first summand can be lower bounded
The proof of part 1(iii) follows the proof of [33, Theorem
byǫ β (1 β ) λλλ λλλ 2P-a.s.Moreover,since
(p,p′)∈Ei i − i k p,i − p′,i k 1(c)]. By Theorem 1(i), we have that, the set of accumulation
the s Peries i∈N(1 −β i)β i diverges, we can conclude that: points of (ψψψ k,i) i∈N is nonempty, P-a.s., for every k .
∈A
However, if ⋆ lies in a hyperplane, then there can be
li iP m →∞inf kλλλ p,i −λλλ p′,i k2 =0, P-a.s. (23) two accumulaQ tion points ψψψ′
k,i
and ψψψ′ k′
,i
equidistant from the
(p, Xp′)∈Ei hyperplanein which ⋆ lies. In fact, any two pointsψψψ′ and
Q k,i
This guarantees the existence of a subsequence N˜ N such ψψψ′ k′ ,i, with the property that kψψψ′ k,i −ψψψ⋆ k = kψψψ′ k′ ,i −ψψψ⋆ k for
Pth -a at .sf .or Bl y∈ AN˜ ssuw me ph ta iov nel 1im (i)l→ an∞
d
(ii( ip ), ,p′ i) .∈ e.E ,lk sλ tλλ rp o, nl g− cλλλ op⊂ n′, nl k e2 ct= ivit0 y, ta hn ey ac dh do ii tc ioe no af lψ cψψ o⋆ n∈ ditQ io⋆ n, ss pa eti cs if fiy edth ie nr Tes hu el ot ri en m1( 1i () i. iiH ),o ww eev ee nr s, ub ry e
P that ⋆ does notlie in a hyperplane,i.e., there exists a u>0
of graphs ( Gl) l∈N˜, we have that the limit must converge to suchQ that, for any sss ⋆, the set hhh RM hhh sss u
zero for every pair of agents in the network. More precisely, ∈ Q { ∈ | k − k ≤ }
( (p,q) )(l N˜ N) lim λλλ λλλ 2 = 0, is nonempty.Therefore,no two pointsψψψ′ k,i andψψψ′ k′ ,i can exist
P∀
-a.s.
∈ A×A ∈ ⊂ l→∞ k p,l − q,l k that satisfy the property kψψψ′
k,i
−ψψψ⋆
k
= kψψψ′ k′
,i
−ψψψ⋆
k
for all
ψψψ⋆ ⋆. Hence, the accumulation point must be unique for
Inthefollowing,weshowthatliminf i→∞ kλλλ p,i −λλλ p′,i k=0 ever∈ ykQ
.Bytheresult1(ii),wecanalsoguaranteethatthis
implies liminf i→∞ ψψψ p,i ψψψ p′,i =0. Consider the sequence ∈A
( |ψψψ p(m ,i) −ψψψ p(m ′,i) |) i∈Nk , whe− re ψψψ(mk ) denotes the mth coordinate u Pn -aiq .su ..e Hac ec nu cm e,u Tla ht eio on rempoi 1n (t iii is
)
it she prs oa vm ede .for all agents k ∈A,
of ψψψ RM for m = 1,...,M. The consensus step (1b) B. Proof of Theorem 2
∈
corresponding to the mth coordinate is given by:
Following the proof of Theorem 1 above, we start analysis
ψψψ(m) ψψψ(m) = (G(m) G(m) )Tλλλ +eee(m) eee(m) from (21):
| p,i+1− p′,i+1| | p,i − p′,i i p,i − p′,i|
≤|(G p(m ,i) −G( pm ′,i) )Tλλλ i |+ |eee( pm ,i) −eee( pm ′,i) |. kλλλ k,i −yyy k2 = kP X(ψψψ k,i −Φ k,i(ψψψ k,i)+ζ izzz k,i) −yyy k2,
The following statements hold for each m=1,...,M, the (a) ψψψ Φ (ψψψ )+ζzzz yyy 2,
k,i k,i k,i i k,i
subsequence N˜, and all (p,p′) 2. Note that the sequence =≤k ψψψ − yyy 2+ Φ (ψψψ ) 2− k 2(ψψψ yyy)TΦ (ψψψ )
∈ A k,i k,i k,i k,i k,i k,i
of time indices i in the following discussion belongto the set k − k k k − −
N˜, and hence, expressions like lim
i→∞
must be read as the +ζ i2 kzzz k,i k2+2ζ izzzT k,i(ψψψ k,i −Φ k,i(ψψψ k,i) −yyy).
(24)
limit over the sequence of indices in the set N˜.
where (a) follows from the property of orthogonalprojection
the(a s) eS qi un ec ne ce(β (i eee) i ∈ )N˜ co N˜n ,ve wrg he es reto eeezero =, e βve (r Py ˜co λλλord +ina nnnte o )f
,
operators, namely, ( ∀xxx
∈
RM, ∀yyy
∈
X) kP X(xxx) −yyy k2
≤
convergesto
zerk o,i Pi -a∈
.s.
Consequentk ly,i
,for
evi eryk, δi i
>0
thk e,i
re
kxxx −yyy k2.
1 Using the definition of Φ in (7), and method of proof
exists N N such that for all i N , we have eee(m) k,i
1 ∈ ≥ 1 | p,i − in [16, Theorem 2(a)], the following relation immediately
eee( pm ′,i) |<δ 1 (P-a.s.). follows:
(b)FromthedefinitionofG ,i.e.,G :=I +β (P I),
i i MN i i
andthefactthatlim i→∞β i =0,thelimitlim i→∞G i =I− MN Φ k,i(ψψψ k,i) 2 2(ψψψ k,i yyy)TΦ k,i(ψψψ k,i)
e cx oi ns vts e. rgT eh si ts oi tm hepl vie es ctt oh ra uuut pt ,h me se uuuq pu ′,e mn ,ce wh(G ere( pm , uui u) p− ,mG( p Rm ′,i M) ) i N∈ isN˜ a k ≤−µk k,i(− 2 −µ k,i)− (Θ Θk ′,i (( ψψ ψψ ψψ k,i )))2 2. (25)
vectorofallzerosexceptone− atcoordinate(p 1)∈ M+m.As- k k,i k,i k
−
sume thatλλλ⋆ isa convergencepointofthe sequence(λλλ )
p,i i Using (25) in (24), we obtain the same expression for
N˜. Since ( λλλ p,i λλλ p′,i ) i N˜ converges to zero for a∈ ll E [V(i+1,yyy)] as in (22), but with different definitions for
(p,p′),anyk conver− gencepk oint∈ λλλ⋆hasthepropertythat(uuu i
p,m a and b , given by:
uuu p′,m)Tλλλ⋆ =0, i.e., (p 1)M+m and (p′ 1)M+m coo− r- i i
− −
dinates ofλλλ⋆ are the same for all (p,p′) and all m. Using the 1
a := π [D ] [D ] λλλ λλλ 2
propertythat, if limits of the series lim i→∞a i and lim i→∞b i i 2 k,i+1 i (k,p) i (k,p′) k p,i − p′,i k
exists, then lim i→∞(a ib i) = (lim i→∞a i)(lim i→∞b i), we k X∈A p X∈Ap X′∈A
d Ge
(
pd
m
′u ,i)c )e Tt )h (a lit m: l ii →m ∞i→ λλλ∞ i)(G =( pm u, uui
T
p) ,− mλλλG ⋆( p −m ′,i) uuu)λλ
T
pλ ′i ,m= λλλ⋆(li =m i 0→ .∞ H( eG nc( p em , ,i) fo−
r
+
k
X∈Aπ k,i+1µ k,i(2 −µ k,i) k(Θ Θk ′ k, ,i i(( ψψ ψψ ψψ kk ,, ii )) k)2 2,b := π E eee 2 +ζ2 π E zzz 2 andη(m) := 1 B w(m)(b)2 E[w(m) 2]+κ (b) ,and
i k,i+1 i k k,i k i k,i+1 i k k,i k r B b=1 | r | − | r | r
+k X∈ 2A
ζ
i
π
k,i+(cid:2)
1E
i
zzzT
k(cid:3)
,i(ψψψ
k,ik X −∈A
Φ k,i(ψψψ
k,i)(cid:2)
−yyy) .
(cid:3) it
w
sh he
e
ore bex tp awr ine es es di oo mn
sii
mtPo
te
if
ld
aκ rr
m
ly(b (cid:0))
bfo
yis
r
rg
s
ei
i
pv
m
le apn
cli
ica nit gtyt .h λe
Th
,b eo ft ot
e
ro xm
p ar
leo lsf
s
kit oh nis (cid:1) op fa ,g
η
ie nr′,
Itcanbevek X r∈ ifiA edthata ia(cid:2) ndb iarenonnegativeforall(cid:3) i ∈N. vη ar(m ri) abe lx ep sre cs (msi )on a. nI dn ca ′dd hit aio vn e, fif no ir tea mll ek ak n∈ anA dr v, at rh iae n∈ r ca eA n ,d ao nm
d
eF th so e tr ac bp o lr ino sv hv e ein r dgg e innth c ta het eot f ph re s oes ore i fer oi se fs
TP hk∈
ei oA∈ rN eπ mb ki
,i
1+co
1
an E bv oie vr
k
eg .eeee
k
Ws ,,
i
hkfi a2r tst ri esn mo at ale r ie nt a sh da iy st vth ae riara nn cd e.om Fk ur v ra thr eia rb ml oes rk er η ,r( tm he) rean ed xiη str′ sa sr oe mz eer do- <mean a sun cd hfi tn hi ate
t
to provethatthesecondanP dthirdtermsin(cid:2) the righ(cid:3) t-hand-side E[ξ kr 2 e r] d for all r and k r. ∞
| | ≤ ∈A ∈A
expression of b are convergent. In this direction, note that
i Proof. Using definitions of the correspondingsymbols, equa-
ζ is convergentandthereexistssomeκ< such that
E i [∈N zzz i ] κ for all i N and k (P-a.s.) b∞ y definition tion (26) can be verified using elementary algebraic manip-
i k,i ulations of the equation (10). Finite mean and variance of
P k k ≤ ∈ ∈A
(cf. Definition 2). By Cauchy-Schwartz inequality, we have c(m) andc′ followsfromAssumption3, whereitisassumed
zzzT (ψψψ Φ (ψψψ ) yyy) zzz ψψψ Φ (ψψψ ) yyy . kr kr
k,i k,i − k,i k,i − ≤k k,i kk k,i − k,i k,i − k that ξ kr has finite second and fourth moments. The noise
yyH ye an nc de, ψψψby A bs esu lom np gti to on 2 )a ,n td heb ro eun exd ie sd tsne ss os mo ef s ϕet <X (vec st uo cr hs terms η r(m) and η r′ are zero-mean because e r(b) has a mean
t khat E
i
,[ Pkk zzz -, aki
., si .k
.kψψψ
k,i
−ΦX k,i(ψψψ k,i) −yyy k] ≤ϕ for all i ∈∞N and z i.e i.r do .. TT hh eis fif no itl elow vas rif ar no cm
e
oth fe
η
r(f mac )t at nh dat ηU r′,k agis aiz ne ,r fo o- lm loe wan fra on md
∈ ThA erefore,asintheproofofTheorem1above,applyingthe Assumption3,where,inadditiontoξ kr,itisassumedthatw r
alsohasfinitesecondandfourthmoments.Similarly,finiteness
Proposition 2, in addition to the already established results in
of E[ξ 2 e ] follows from finiteness of second and fourth
Theorem 1, we obtain the following result: | kr | r
moments of ξ and w .
kr r
(Θ (ψψψ ))2
( k ) lim k,i k,i =0, P-a.s., Using expressions for y and y′ from (26), the terms in
∀ ∈A i→∞ kΘ′ k,i(ψψψ k,i) k2
agent k consensus
pror
tocol
(1r
2) can be rearranged and
∈A
wherewe usedthe convergenceof series(a i) i∈N, andthe fact stacked for all agents to obtain:
that π µ (2 µ )> 0 for all i N and k . Since
lk
(i
iΘ
m
)
′ k oi→, fi(k
∞
Tψψψ, hi k+
Θ
e,1 i ok) r,k eik
(
m, i ψψψi s
k
2b
,
.io− )u =ndk e 0,i d fob ry aA lls ksu ∈mp Ati ,o Pn∈ -a2 ., sw ..e Thm isus∈ pt rh oA vav ee spth aa rtt
w 1,h .e .r .e ,MP i
)isψψψ di e+ fi1 ne= d( a1 s− foβ lli o) wλλλ i s:+
(
∀β (i p(P ,qi )λλλ i ∈+ Annn ×i),
A)( ∀m,n =
Part(ii)ofTheorem2canbeprovedbyfollowingtheproof
of [34, Theorem 2(e)] line-by-line. γ p,ic( qm p), if (p,q) i,m=n,
∈E
[P ] = 1 γ c′ , if p=q,m=n,
C. Proof of Proposition 1 i (fpm,fqn)  − p,i k∈Ap qp
NotethattheconditionsinAssumption1(i)-(iii)aresatisfied
0,
P
otherwise
by design. An overview of the steps of proof is as follows: (28)

First, we express the random variables y r(m) and y r′ in (10) where f
pm
= (p 1)M +m; and elements of nnn
i
are given
in terms of inputs λ k from agents in r. Then, we transform by: ( p )( m− =1,...,M)
(12) to the structure in (1b) and obtaA in expressions for P ∀ ∈A ∀
k,i
andnnn k,i.Usingtheseexpressions,weverifythatP
k,i
andnnn
k,i
nnn i(fpm) :=γ p,i(η p(m) −η r′λλλ( pm ,i)). (29)
satisfy conditions in Assumption 1.
It only remains to prove that P and nnn defined above,
i i
Lemma2. BasedontheOTC-protocolproposedinSectionIII, satisfythe conditionsinAssumption1(iv).Tothisend,noting
the random variables y r(m) and y r′ in (10) take the following that P
i
and nnn
i
are functions of (c( km r),c′ kr) and (η r(m),η r′),
form: ( r )( m=1,...,M) respectively, the conditions in Assumption 1 follows from
∀ ∈A ∀
Lemma 2.
y(m) := c(m)λ +η(m), y′ := c′ +η′, (26)
r kr k r r kr r
k X∈Ar k X∈Ar
where, we define
B B′
P P
c(m) := k ξ(m)(b)2, c′ := k ξ′ (b)2, (27)
kr B | kr | kr B | kr |
b=1 b=1
X X
κ (b):= δ P ξ′ 2 ξ 2 + ξ (b)ξ∗(b)U (b)U∗(b) g (λ )g (λ ) +w∗(b)(ξ (b)s (b)) .
r  min k | kr| −| kr |  kr lr k l k k l l  r kr k 
k X∈Ar
(cid:0) (cid:1)
Xk6=l
p
   This figure "cons_results.png" is available in "png"(cid:10) format from:
http://arxiv.org/ps/2401.18030v1This figure "nmse_results.png" is available in "png"(cid:10) format from:
http://arxiv.org/ps/2401.18030v1