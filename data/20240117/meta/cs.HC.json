[
    {
        "title": "Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT",
        "authors": "Mohammad Ronagh NikghalbJinghui Cheng",
        "links": "http://arxiv.org/abs/2401.08405v1",
        "entry_id": "http://arxiv.org/abs/2401.08405v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08405v1",
        "summary": "In an era of AI's growing capabilities and influences, recent advancements\nare reshaping HCI and CSCW's view of AI as mere tools. Playful interactions\nwith AI systems naturally emerged as a way for users to make sense of the\never-changing technology. However, these emergent and playful interactions are\nunderexamined. We target this gap by investigating playful interactions\nexhibited by users of a recently trending powerful AI technology, ChatGPT.\nThrough a thematic analysis of 372 user-generated posts on the ChatGPT\nsubreddit, we found that a substantial portion of user discourse revolves\naround playful interactions. The analysis further allowed us to construct a\npreliminary taxonomy to describe these interactions, categorizing them into six\ntypes: reflecting, jesting, imitating, challenging, tricking, and contriving;\neach included sub-categories. Overall, this study contributes to the field of\nHCI and CSCW by illuminating the multifaceted nature of playful interactions\nwith AI, underlining their significance in shaping the human-AI relationship.",
        "updated": "2024-01-16 14:44:13 UTC",
        "id": 1
    },
    {
        "title": "Understanding User Experience in Large Language Model Interactions",
        "authors": "Jiayin WangWeizhi MaPeijie SunMin ZhangJian-Yun Nie",
        "links": "http://arxiv.org/abs/2401.08329v1",
        "entry_id": "http://arxiv.org/abs/2401.08329v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08329v1",
        "summary": "In the rapidly evolving landscape of large language models (LLMs), most\nresearch has primarily viewed them as independent individuals, focusing on\nassessing their capabilities through standardized benchmarks and enhancing\ntheir general intelligence. This perspective, however, tends to overlook the\nvital role of LLMs as user-centric services in human-AI collaboration. This gap\nin research becomes increasingly critical as LLMs become more integrated into\npeople's everyday and professional interactions. This study addresses the\nimportant need to understand user satisfaction with LLMs by exploring four key\naspects: comprehending user intents, scrutinizing user experiences, addressing\nmajor user concerns about current LLM services, and charting future research\npaths to bolster human-AI collaborations. Our study develops a taxonomy of 7\nuser intents in LLM interactions, grounded in analysis of real-world user\ninteraction logs and human verification. Subsequently, we conduct a user survey\nto gauge their satisfaction with LLM services, encompassing usage frequency,\nexperiences across intents, and predominant concerns. This survey, compiling\n411 anonymous responses, uncovers 11 first-hand insights into the current state\nof user engagement with LLMs. Based on this empirical analysis, we pinpoint 6\nfuture research directions prioritizing the user perspective in LLM\ndevelopments. This user-centered approach is essential for crafting LLMs that\nare not just technologically advanced but also resonate with the intricate\nrealities of human interactions and real-world applications.",
        "updated": "2024-01-16 12:49:00 UTC",
        "id": 2
    },
    {
        "title": "Adapt/Exchange decisions or generic choices: Does framing influence how people integrate qualitatively different risks?",
        "authors": "Romy MÃ¼llerAlexander Blunk",
        "links": "http://arxiv.org/abs/2401.08241v1",
        "entry_id": "http://arxiv.org/abs/2401.08241v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08241v1",
        "summary": "In complex systems, decision makers often have to consider qualitatively\ndifferent risks when choosing between options. Do their strategies of\nintegrating these risks depend on the framing of problem contents? In the\npresent study, participants were either instructed that they were choosing\nbetween two ways of solving a complex problem, or between two generic options.\nThe former was framed as a modular plant scenario that required choices between\nmodifying parameter settings in a current module (Adapt) and replacing the\nmodule by another one (Exchange). The risk was higher for Adapt to harm the\nproduct and for Exchange to harm the plant. These risks were presented as\nprobabilities, and participants were either told that the consequences of both\nrisks were equally severe (content-same group), or that harming the plant was\nmuch worse (content-different group). A third group made decisions based on the\nsame probabilities, but received a generic task framing (no-content group). We\nexpected framing to affect risk integration, leading the content-same group to\nmake different choices than the no-content group. Contrary to this hypothesis,\nthese two groups were strikingly similar in their decision outcomes and\nstrategies, but clearly differed from the content-different group. These\nfindings question whether ecological validity can be enhanced merely by framing\na task in terms of real-world problem contents.",
        "updated": "2024-01-16 09:53:39 UTC",
        "id": 3
    },
    {
        "title": "EEG-based Cognitive Load Estimation of Acoustic Parameters for Data Sonification",
        "authors": "Gulshan SharmaSurbhi MadanManeesh BilalpurAbhinav DhallRamanathan Subramanian",
        "links": "http://arxiv.org/abs/2401.08164v1",
        "entry_id": "http://arxiv.org/abs/2401.08164v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08164v1",
        "summary": "Sonification is a data visualization technique which expresses data\nattributes via psychoacoustic parameters, which are non-speech audio signals\nused to convey information. This paper investigates the binary estimation of\ncognitive load induced by psychoacoustic parameters conveying the focus level\nof an astronomical image via Electroencephalogram (EEG) embeddings. Employing\nmachine learning and deep learning methodologies, we demonstrate that EEG\nsignals are reliable for (a) binary estimation of cognitive load, (b) isolating\neasy vs difficult visual-to-auditory perceptual mappings, and (c) capturing\nperceptual similarities among psychoacoustic parameters. Our key findings\nreveal that (1) EEG embeddings can reliably measure cognitive load, achieving a\npeak F1-score of 0.98; (2) Extreme focus levels are easier to detect via\nauditory mappings than intermediate ones, and (3) psychoacoustic parameters\ninducing comparable cognitive load levels tend to generate similar EEG\nencodings.",
        "updated": "2024-01-16 07:11:14 UTC",
        "id": 4
    },
    {
        "title": "'One Style Does Not Regulate All': Moderation Practices in Public and Private WhatsApp Groups",
        "authors": "Farhana ShahidDhruv AgarwalAditya Vashistha",
        "links": "http://arxiv.org/abs/2401.08091v1",
        "entry_id": "http://arxiv.org/abs/2401.08091v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08091v1",
        "summary": "WhatsApp is the largest social media platform in the Global South and is a\nvirulent force in global misinformation and political propaganda. Due to\nend-to-end encryption WhatsApp can barely review any content and this often\npushes the responsibility of moderation towards group admins. Yet, little is\nknown about how WhatsApp group admins manage their groups, what factors and\nvalues influence moderation decisions, and what challenges they face in\nmoderating their groups. To fill this gap, we interviewed admins of 32 diverse\ngroups and reviewed content from 30 public groups in India and Bangladesh. We\nobserved notable differences in the formation, members' behavior, and\nmoderation of public versus private groups, as well as in how WhatsApp admins\noperate compared to those on other platforms. We used Baumrind's typology of\n'parenting styles' as a lens to explore moderation practices in WhatsApp groups\nand identified four moderation styles based on how responsive and controlling\nthe admins were and discuss design recommendations to help them better manage\nproblematic content in WhatsApp groups.",
        "updated": "2024-01-16 03:32:15 UTC",
        "id": 5
    }
]