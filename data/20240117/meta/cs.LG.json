[
    {
        "title": "Faster ISNet for Background Bias Mitigation on Deep Neural Networks",
        "authors": "Pedro R. A. S. BassiSergio DecherchiAndrea Cavalli",
        "links": "http://arxiv.org/abs/2401.08409v1",
        "entry_id": "http://arxiv.org/abs/2401.08409v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08409v1",
        "summary": "Image background features can constitute background bias (spurious\ncorrelations) and impact deep classifiers decisions, causing shortcut learning\n(Clever Hans effect) and reducing the generalization skill on real-world data.\nThe concept of optimizing Layer-wise Relevance Propagation (LRP) heatmaps, to\nimprove classifier behavior, was recently introduced by a neural network\narchitecture named ISNet. It minimizes background relevance in LRP maps, to\nmitigate the influence of image background features on deep classifiers\ndecisions, hindering shortcut learning and improving generalization. For each\ntraining image, the original ISNet produces one heatmap per possible class in\nthe classification task, hence, its training time scales linearly with the\nnumber of classes. Here, we introduce reformulated architectures that allow the\ntraining time to become independent from this number, rendering the\noptimization process much faster. We challenged the enhanced models utilizing\nthe MNIST dataset with synthetic background bias, and COVID-19 detection in\nchest X-rays, an application that is prone to shortcut learning due to\nbackground bias. The trained models minimized background attention and hindered\nshortcut learning, while retaining high accuracy. Considering external\n(out-of-distribution) test datasets, they consistently proved more accurate\nthan multiple state-of-the-art deep neural network architectures, including a\ndedicated image semantic segmenter followed by a classifier. The architectures\npresented here represent a potentially massive improvement in training speed\nover the original ISNet, thus introducing LRP optimization into a gamut of\napplications that could not be feasibly handled by the original model.",
        "updated": "2024-01-16 14:49:26 UTC",
        "id": 1
    },
    {
        "title": "RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture",
        "authors": "Aman GuptaAnup ShirgaonkarAngels de Luis BalaguerBruno SilvaDaniel HolsteinDawei LiJennifer MarsmanLeonardo O. NunesMahsa RouzbahmanMorris SharpNick MecklenburgRafael PadilhaRanveer ChandraRenato Luiz de Freitas CunhaRoberto de M. Estev√£o FilhoRyan TsangSara MalvarSwati SharmaTodd HendryVijay AskiVijetha VijayendranVinamra Benara",
        "links": "http://arxiv.org/abs/2401.08406v1",
        "entry_id": "http://arxiv.org/abs/2401.08406v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08406v1",
        "summary": "There are two common ways in which developers are incorporating proprietary\nand domain-specific data when building applications of Large Language Models\n(LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the\nprompt with the external data, while fine-Tuning incorporates the additional\nknowledge into the model itself. However, the pros and cons of both approaches\nare not well understood. In this paper, we propose a pipeline for fine-tuning\nand RAG, and present the tradeoffs of both for multiple popular LLMs, including\nLlama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages,\nincluding extracting information from PDFs, generating questions and answers,\nusing them for fine-tuning, and leveraging GPT-4 for evaluating the results. We\npropose metrics to assess the performance of different stages of the RAG and\nfine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset.\nAgriculture as an industry has not seen much penetration of AI, and we study a\npotentially disruptive application - what if we could provide location-specific\ninsights to a farmer? Our results show the effectiveness of our dataset\ngeneration pipeline in capturing geographic-specific knowledge, and the\nquantitative and qualitative benefits of RAG and fine-tuning. We see an\naccuracy increase of over 6 p.p. when fine-tuning the model and this is\ncumulative with RAG, which increases accuracy by 5 p.p. further. In one\nparticular experiment, we also demonstrate that the fine-tuned model leverages\ninformation from across geographies to answer specific questions, increasing\nanswer similarity from 47% to 72%. Overall, the results point to how systems\nbuilt using LLMs can be adapted to respond and incorporate knowledge across a\ndimension that is critical for a specific industry, paving the way for further\napplications of LLMs in other industrial domains.",
        "updated": "2024-01-16 14:44:47 UTC",
        "id": 2
    },
    {
        "title": "Training and Comparison of nnU-Net and DeepMedic Methods for Autosegmentation of Pediatric Brain Tumors",
        "authors": "Arastoo VossoughNastaran KhaliliAriana M. FamiliarDeep GandhiKarthik ViswanathanWenxin TuDebanjan HaldarSina BagheriHannah AndersonShuvanjan HaldarPhillip B. StormAdam ResnickJeffrey B. WareAli NabavizadehAnahita Fathi Kazerooni",
        "links": "http://arxiv.org/abs/2401.08404v1",
        "entry_id": "http://arxiv.org/abs/2401.08404v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08404v1",
        "summary": "Brain tumors are the most common solid tumors and the leading cause of\ncancer-related death among children. Tumor segmentation is essential in\nsurgical and treatment planning, and response assessment and monitoring.\nHowever, manual segmentation is time-consuming and has high inter-operator\nvariability, underscoring the need for more efficient methods. We compared two\ndeep learning-based 3D segmentation models, DeepMedic and nnU-Net, after\ntraining with pediatric-specific multi-institutional brain tumor data using\nbased on multi-parametric MRI scans.Multi-parametric preoperative MRI scans of\n339 pediatric patients (n=293 internal and n=46 external cohorts) with a\nvariety of tumor subtypes, were preprocessed and manually segmented into four\ntumor subregions, i.e., enhancing tumor (ET), non-enhancing tumor (NET), cystic\ncomponents (CC), and peritumoral edema (ED). After training, performance of the\ntwo models on internal and external test sets was evaluated using Dice scores,\nsensitivity, and Hausdorff distance with reference to ground truth manual\nsegmentations. Dice score for nnU-Net internal test sets was (mean +/- SD\n(median)) 0.9+/-0.07 (0.94) for WT, 0.77+/-0.29 for ET, 0.66+/-0.32 for NET,\n0.71+/-0.33 for CC, and 0.71+/-0.40 for ED, respectively. For DeepMedic the\nDice scores were 0.82+/-0.16 for WT, 0.66+/-0.32 for ET, 0.48+/-0.27, for NET,\n0.48+/-0.36 for CC, and 0.19+/-0.33 for ED, respectively. Dice scores were\nsignificantly higher for nnU-Net (p<=0.01). External validation of the trained\nnnU-Net model on the multi-institutional BraTS-PEDs 2023 dataset revealed high\ngeneralization capability in segmentation of whole tumor and tumor core with\nDice scores of 0.87+/-0.13 (0.91) and 0.83+/-0.18 (0.89), respectively.\nPediatric-specific data trained nnU-Net model is superior to DeepMedic for\nwhole tumor and subregion segmentation of pediatric brain tumors.",
        "updated": "2024-01-16 14:44:06 UTC",
        "id": 3
    },
    {
        "title": "Deep Learning-based Group Causal Inference in Multivariate Time-series",
        "authors": "Wasim AhmadMaha ShadaydehJoachim Denzler",
        "links": "http://arxiv.org/abs/2401.08386v1",
        "entry_id": "http://arxiv.org/abs/2401.08386v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08386v1",
        "summary": "Causal inference in a nonlinear system of multivariate timeseries is\ninstrumental in disentangling the intricate web of relationships among\nvariables, enabling us to make more accurate predictions and gain deeper\ninsights into real-world complex systems. Causality methods typically identify\nthe causal structure of a multivariate system by considering the cause-effect\nrelationship of each pair of variables while ignoring the collective effect of\na group of variables or interactions involving more than two-time series\nvariables. In this work, we test model invariance by group-level interventions\non the trained deep networks to infer causal direction in groups of variables,\nsuch as climate and ecosystem, brain networks, etc. Extensive testing with\nsynthetic and real-world time series data shows a significant improvement of\nour method over other applied group causality methods and provides us insights\ninto real-world time series. The code for our method can be found\nat:https://github.com/wasimahmadpk/gCause.",
        "updated": "2024-01-16 14:19:28 UTC",
        "id": 4
    },
    {
        "title": "Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference",
        "authors": "Jinghan YaoQuentin AnthonyAamir ShafiHari SubramoniDhabaleswar K.Panda",
        "links": "http://arxiv.org/abs/2401.08383v1",
        "entry_id": "http://arxiv.org/abs/2401.08383v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08383v1",
        "summary": "In large language models like the Generative Pre-trained Transformer, the\nMixture of Experts paradigm has emerged as a powerful technique for enhancing\nmodel expressiveness and accuracy. However, deploying GPT MoE models for\nparallel inference on distributed systems presents significant challenges,\nprimarily due to the extensive Alltoall communication required for expert\nrouting and aggregation. This communication bottleneck exacerbates the already\ncomplex computational landscape, hindering the efficient utilization of\nhigh-performance computing resources. In this paper, we propose a lightweight\noptimization technique called ExFlow, to largely accelerate the inference of\nthese MoE models. We take a new perspective on alleviating the communication\noverhead by exploiting the inter-layer expert affinity. Unlike previous\nmethods, our solution can be directly applied to pre-trained MoE models without\nany fine-tuning or accuracy degradation. By proposing a context-coherent expert\nparallelism on distributed systems, our design only uses one Alltoall\ncommunication to deliver the same functionality while previous methods all\nrequire two Alltoalls. By carefully examining the conditional probability in\ntokens' routing across multiple layers, we proved that pre-trained GPT MoE\nmodels implicitly exhibit a strong inter-layer expert affinity. We then design\nan efficient integer programming model to capture such features and show that\nby properly placing the experts on corresponding GPUs, we can reduce up to 67%\ncross-GPU routing latency. Our solution beats the cutting-edge MoE\nimplementations with experts from 8 to 64, with up to 2.2x improvement in\ninference throughput. We further provide a detailed study of how the model\nimplicitly acquires this expert affinity at the very early training stage and\nhow this affinity evolves and stabilizes during training.",
        "updated": "2024-01-16 14:16:47 UTC",
        "id": 5
    }
]