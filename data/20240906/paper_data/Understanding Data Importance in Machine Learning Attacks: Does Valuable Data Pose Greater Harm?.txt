ToAppearinNetworkandDistributedSystemSecurity(NDSS)Symposium2025
Understanding Data Importance in Machine Learning Attacks:
Does Valuable Data Pose Greater Harm?
RuiWen MichaelBackes YangZhang*
CISPAHelmholtzCenterforInformationSecurity
Abstract proving machine learning explainability, offering new in-
sights into model behavior, and enhancing interpretabil-
Machine learning has revolutionized numerous domains,
ity [27,37,46,47]. Second, this knowledge can guide data
playingacrucialroleindrivingadvancementsandenabling
trading practices, where the importance of data is a signifi-
data-centric processes. The significance of data in training
cantfactor[4,16].
modelsandshapingtheirperformancecannotbeoverstated.
However, the influence of such diverse data on model
Recentresearchhashighlightedtheheterogeneousimpactof
leakage and security remains largely unexplored. Existing
individualdatasamples,particularlythepresenceofvaluable
research predominantly concentrates on the models them-
datathatsignificantlycontributestotheutilityandeffective-
selves; for example, studies [35,50] suggest that overfit-
ness of machine learning models. However, a critical ques-
tedmodelsaremorepronetomembershipinferenceattacks.
tion remains unanswered: are these valuable data samples
Nevertheless,evenwithinthesamemodel,distinctdatasam-
more vulnerable to machine learning attacks? In this work,
plesexhibitvaryingvulnerabilitiestoattacks.Thispromptsa
weinvestigatetherelationshipbetweendataimportanceand
crucialquestion: dothesevaluabledatasamplesalsoexhibit
machine learning attacks by analyzing five distinct attack
an increased vulnerability to a spectrum of machine learn-
types. Ourfindingsrevealnotableinsights. Forexample,we
ing attacks? Understanding the differential vulnerability of
observethathighimportancedatasamplesexhibitincreased
datasampleshas significantpracticalimplications. Inmed-
vulnerability in certain attacks, such as membership infer-
ical diagnostics, for example, patient records with rare but
enceandmodelstealing. Byanalyzingthelinkagebetween
highlyindicativesymptomsareconsideredhighimportance
membershipinferencevulnerabilityanddataimportance,we
samples. Assessingwhethertheserecordsaremoreproneto
demonstratethatsamplecharacteristicscanbeintegratedinto
attacks is crucial, as breaches could lead to discrimination,
membershipmetricsbyintroducingsample-specificcriteria,
higher insurance premiums, or other serious consequences
thereforeenhancingthemembershipinferenceperformance.
forindividuals.
Thesefindingsemphasizetheurgentneedforinnovativede-
Inthispaper,ourfocusliesininvestigatingtherelationship
fensemechanismsthatstrikeabalancebetweenmaximizing
betweendataimportanceandmachinelearningattacks. Our
utility and safeguarding valuable data against potential ex-
primaryobjectiveistothoroughlyinvestigatewhethervalu-
ploitation.
abledatasamples,whichcontributesignificantlytotheutility
ofmachinelearningmodels,areexposedtoanelevatedrisk
1 Introduction
ofexploitationbymaliciousactors.
Toachieveourobjectives, wefocusonfivedistincttypes
Machine learning has emerged as an indispensable tool
ofattacks,encompassingbothtraining-timeandtesting-time
across numerous domains, revolutionizing industries and
attacks. The training-time attack we consider is the back-
empoweringdata-drivendecision-makingprocesses. Central
doorattack[17,32,49],whilethetesting-timeattacksconsist
totheessenceofmachinelearningisthepivotalroleplayed
of membership inference attack [12,31,34,50,55], model
by data, serving as the bedrock for training models and ex-
stealingattack[52,62,63],attributeinferenceattack[39,57],
ertingaprofoundinfluenceontheirperformanceandpredic-
anddatareconstructionattack[14,72,75]. Foreachofthese
tiveaccuracy. Concurrently,thecrucialroleofdatainmodel
attacks, we thoroughly analyze the behavior and impact on
trainingalsoexposesitasanoteworthysourceofvulnerabil-
bothhighimportanceandlowimportancedatasamples,aim-
ities.
ingtouncoveranydiscernibledifferences.
Recent research has shed light on the heterogeneous im-
pact of individual data samples, highlighting the presence Main Findings: Our research has yielded significant find-
of certain data that exhibit a heightened influence on the ings that shed light on the heightened vulnerability of valu-
utility and overall effectiveness of machine learning mod- able data samples to privacy attacks. Specifically, our key
els [16,24,25,27,28]. Understanding this variability is im- findingsareasfollows:
portant for two main reasons. First, knowing how individ-
• Membership Inference Attack: High importance data
ual data samples affect model performance is key to im-
samples exhibit a higher vulnerability compared to
*Correspondingauthor low importance samples, particularly in the low false-
1
4202
peS
5
]GL.sc[
1v14730.9042:viXrapositive rate region. For instance, in the CIFAR10 2 Background
dataset, at a false positive rate (FPR) of 1%, the true
2.1 MachineLearningModels
positive rate (TPR) of high importance data is 10.2
×
greaterthanthatoflowimportancesamples. Machinelearningalgorithmsaimtoconstructmodelsthatef-
fectivelypredictoutputsbasedongiveninputs. Thesemod-
• PrivacyOnionEffect: Theconceptoftheprivacyonion
elsaretypicallyrepresentedbyaparameterizedfunctionde-
effect[9]canbeextendedtothedistributionofdataim-
noted as f :X Y, where X represents the input space
portance. Specifically, previouslyconsideredunimpor- θ →
and Y represents the output space encompassing all possi-
tantsamplesgainsignificancewhenthedatasetremoves
blepredictions. Theprocessofdeterminingoptimalparame-
theimportantsamples.
tervaluesθinvolvesminimizinganobjectivefunctionusing
• Model Stealing Attack: High importance samples gradient descent. Specifically, the objective is to minimize
demonstrategreaterefficiencyinstealingmodelswhen theclassificationloss
the target model is trained on the same distribution as
thequerydistribution.However,weempiricallydemon- E [L(f θ(x),y)]
stratethattheimportancedoesnottransferbetweendif-
(x,y)
ferenttasks.
where (x,y) X Y denotes samples from the training
∈ ×
• Backdoor Attack: Poisoning high importance data en- dataset used to train the target model. This optimization
hancestheefficiencyofthepoisoningprocess,particu- processguidesthemodeltowardsachievingoptimalperfor-
larlywhenthesizeofthepoisonissmall. Ontheother mancebyiterativelyadjustingtheparameters.
hand, the influence on clean accuracy does not yield a
definitiveconclusion, poisoningeithertypeofdatahas 2.2 DataImportance
alimitedimpactoncleanaccuracy.
Theinvestigationofindividualtrainingsampleimportancein
• Attribute Inference and Data Reconstruction Attacks: machinelearning(ML)isafundamentalandintricateprob-
Weobservenosignificantdistinctionbetweenhighand lem with broad implications, especially in data valuation.
lowimportancedataintheseattacks. Understanding the importance of a single training sample
within a learning task profoundly impacts data assessment,
Our research provides empirical evidence establishing
allocationofresources,andthequalityofMLmodels.
a correlation between data importance and vulnerabilities
Leave-one-out (LOO) method has long been regarded as
across diverse attack scenarios. This introduces a novel
an intuitive approach for assessing the importance of data
perspectiveforanalyzingsample-specificvulnerabilities,en-
samples. Formally, let D and D represent the training set
val
richingourunderstandingofthesecurityimplicationswithin
andthevalidationset, andA denotethelearningalgorithm.
therealmofmachinelearning.
U denotesthevalidationaccuracyofthemodeltrained
Beyondtheoreticalinsights,ourstudyshowcasespractical
A,Dval
on D using A. The importance of a target sample z can be
applications of these findings, illustrating how they can be
quantified as the difference in utility before and after incor-
utilized to devise more potent attacks. On one hand, these
poratingthetargetsampleintothetrainingset,expressedas:
findings can be utilized in a passive manner. For example,
we empirically demonstrate that membership inference at-
tackscanbeimprovedbyintroducingsample-specificcrite- v loo(z)∝U A,Dval(D) −U A,Dval(D \{z })
riabasedonsampleimportance. Additionally,adjustingthe
poisoningstrategyaccordingtosampleimportanceprovesto Nevertheless, evaluating the importance of all N samples
enhancetheefficacyofbackdoorattacks,particularlywitha inthetrainingsetnecessitatesretrainingthemodelN times,
reducedpoisoningrate. resultingincomputationalheaviness. Toaddressthislimita-
Moreinterestingly,wecanactivelymodifysamplestoal- tion,KohandLiang[27]proposedinfluencefunctionsasan
ter their importance, which subsequently impacts both at- approximation method, significantly reducing the computa-
tack and defense performance. For example, recognizing tionalcostfromO(Np2+p3)toO(Np),where prepresents
that high importance samples are more vulnerable to mem- thenumberofmodelparameters.
bershipinferenceattacks,attackerscouldincreasetheimpor- DespitetheeffectivenessofLOO,GhorbaniandZou[16]
tanceoftargetedsamplestoheightentheirvulnerability.This have raised concerns about its ability to capture complex
approachfollowsexactlythesameideaastheattackaccepted interactions between subsets of data. They argue that the
atCCS’22[61],effectivelydemonstratinghowwecan“rein- Shapley value provides a more comprehensive framework
vent”state-of-the-artattacksguidedbyfindingsinourwork. for measuring data importance. The Shapley value, origi-
Insummary,ourworkrepresentsapioneeringstepinsys- nallyproposedbyShapley[54],assignsanimportancevalue
tematicallyunderstandingthevulnerabilitiesofthemachine to each sample z in the training set using the following for-
learningecosystemthroughthelensofdata. Thesefindings mulation:
serve as a resounding call to action, urging researchers and
practitionerstodevelopinnovativedefensesthatstrikeadel-
icate balance between maximizing utility and safeguarding ν shap(z)∝ N1 ∑ (cid:0)N1 1(cid:1)(cid:2) U A,Dval(S ∪{z }) −U A,Dval(S)(cid:3)
valuabledataagainstmaliciousexploitation. S D z −S
⊆ \{} | |
2To simplify the interpretation of the Shapley value as- Jiaetal.’swork[25], theauthorsprovidearuntimedemon-
signedtoeachsample,onecanconceptualizeitasthecontri- stration (Figure 21 for ease reference) showing that exist-
butiontoaccuracyintypicalscenarios. ingmeasurementmethods,exceptforKNN-Shapley,donot
Forinstance,inahypotheticalscenariowith100samples scaleefficientlytolargedatasets,evenasCIFAR10.
andamodelachieving90%accuracy,avaluablesamplemay Furthermore,thecomprehensiveevaluationsconductedby
contribute 2% accuracy, while a less valuable sample may prior studies [25] consistently underscore the effectiveness
only contribute 0.1%. Consequently, the importance value andaccuracyofKNN-Shapley. Therefore,consideringboth
assigned to a valuable sample is 0.02, whereas for a less utilityandscalability,KNN-Shapleyemergesasthesolefea-
valuable sample, it is 0.001. Samples with an importance siblemethodforconductingexperiments.
of 0 signify no contribution to the model’s accuracy, while Datasets: Our evaluation encompasses three widely-used
valuesbelow0suggestadetrimentalimpact,possiblydueto benchmark datasets, namely CIFAR10 [1], CelebA [36],
incorrectlabelsorsampleslyingoutsidethedistribution. and TinyImageNet [2]. CIFAR10 comprises a collection of
TheShapleyvaluetakesintoaccountthecontributionsof 60,000coloredimagesevenlydistributedacrosstenclasses,
allpossiblesubsetsofthetrainingset,offeringamoreholis- representing common objects encountered in everyday life,
tic assessment of data importance. However, the accurate includingairplanes,birds,anddogs. CelebAisalarge-scale
computation of the Shapley value based on the defined for- face dataset that encompasses over 40 annotated binary at-
mula necessitates training O(2N) machine learning models, tributes. Toensurebalanceinouranalysis,wefollowprevi-
renderingitimpracticalforcomplexdatasets.Asaresult,ex- ousworks[35,43,49,76]thatselectthethreemostbalanced
isting methods employ approximate algorithms to estimate attributes(HeavyMakeup, MouthSlightlyOpen, andSmil-
the Shapley value. For instance, Ghorbani and Zou [16] ing)tocreatean8-class(23)classificationtask.Notethatour
introduced two Monte Carlo-based approaches for Shapley findingsarenotdependentonthisspecificattributeselection,
valueapproximation.Toexpediteevaluationtimeandenable asvalidatedinAppendixA. Additionally,ourevaluationin-
analysisoflargedatasets,Jiaetal.[24]utilizedtheK-nearest corporates TinyImageNet, which constitutes a subset of the
neighbors(KNN)algorithmtoapproximatethetargetlearn- ImageNetdataset.Itencompasses200distinctobjectclasses,
ingalgorithm,reducingthetimecomplexitytoO(NlogN). eachwith500trainingimages. Wefurthervalidatethegen-
eralizability of our conclusions across different modalities,
withdetailedinformationdeferredtoSection9.
3 EvaluationSetup
Inthiswork,wedeployKNN-Shapley[24]toassesstheim- 3.1 LearningCharacteristic
portanceofsamplesinthetrainingset,whichtakesadataset
In order to gain a deep understanding of the disparities be-
as input and assigns an importance value to each sample in
tweenhighandlowimportancedata,wedelveintothelearn-
thedataset. Thisdecisionisjustifiedbytwomainconsidera-
ing characteristics, such as loss, associated with these sam-
tions.
ples. To the best of our knowledge, our study represents
Firstly, from the perspective of utility, traditional data at- thefirstendeavortoinvestigatethelearningcharacteristicsof
tributionmethodsstruggletoaccountforthecomplexinter- sampleswithvaryingdegreesofimportance,divergingfrom
actionswithindatasubsets. Previousresearch, asdiscussed theconventionalfocussolelyontheircontributiontothefinal
by Gupta and Zou [16], highlights this limitation. Con- performance.
sequently, we adopt Shapley value-based approaches for a Toquantifytheselearningcharacteristics,weinitiallytrain
moreaccurateassessmentofdataimportance.Wefurtherex- a model using the complete dataset, comprising both high
amine the efficacy of two non-Shapley-based measurement andlowimportancedata. Subsequently,wecomputetheloss
techniques: Leave-one-out(LOO)andtheadvanceddataat- foreachindividualdatapointandexplorethecorrelationbe-
tribution method, Trak1 [46]. As evidenced in Figure 20, tweenthelossanditscorrespondingimportancevalue.
when comparing the performance of models trained with
InFigure1a,wepresentavisualrepresentationofthere-
5000samplesofvaryingsignificance, theaccuracydiscrep-
lationship between loss and importance value. The x-axis
ancyislessthan7%forthesemethods.Incontrast,theKNN-
represents the importance order of a sample in the dataset,
Shapleymethodidentifiessamplesthatyieldanaccuracydif-
with1denotingthelowestimportanceand50000represent-
ference exceeding 20%, thereby demonstrating its superior
ingthemostvaluabledata. Initially,itmayseemthatthereis
capabilityinaccuratelyquantifyingimportance,wedeferthe
nodiscerniblepatternbetweenlossandimportancevalue,as
detailstoAppendixD.
bothlowandhighimportancesamplescanexhibiteitherlow
Secondly, regarding scalability, most measurement meth- orhighloss. However,uponfurtheranalysis,westatistically
odsarehighlycomputationallyinefficient. Forinstance,em- observethathigherimportancesamplestendtodemonstrate
ployingLeave-one-outtocalculateimportancevaluesforCI- lowerloss,asdepictedinFigure1b,Figure1c,andFigure1d.
FAR10necessitatesover80hourson8 A100GPUs. Shap- Toarriveatthisconclusion,wedividethesamplesinto200
×
ley value-based methods are generally more demanding. In binsbasedontheirimportancevalue. Forinstance,thelow-
est1to250samplesarecategorizedintobinone,251to500
1Trakquantifiestheinfluenceofeachsampleonspecifictestsampleswithin
areallocatedtobintwo,andsoforth. Foreachbin,wecal-
adataset. Toadheretotheestablisheddefinitionofdataimportance,we
culatethesumofthelossesandplotthese200datapointsto
calculatetheaverageinfluenceexertedbyeachsampleacrosstheentire
testdatasetastheimportanceofeachsample. generatethefinalcurve. Despitesomefluctuationsobserved
30.7 60 12
0.6 1.0 50 10
0.5 0.8 40 8
0.4
0.6 30
0.3 6
0.2 0.4 20
4
0.1 0.2 10
0.0 0 2
0 1000020000300004000050000 0 1000020000300004000050000 0 1000020000300004000050000 0 20000400006000080000100000
ImportanceOrder ImportanceOrder ImportanceOrder ImportanceOrder
(a)LossDistribution (b)CIFAR10 (c)CelebA (d)TinyImageNet
Figure1:Relationshipbetweenlossandimportancevalue.Lowimportancesamplesstatisticallyhavehigherlosses.
in the curve, it is evident that valuable samples tend to ex- sampleashadowdatasetfromthesameorasimilardistribu-
hibitlowerloss. Thisfindingalignswithourexpectations,as tion,whichisacommonassumptionintheexistingliterature.
lowerlosssignifiesgreaterrepresentativeness,therebyfacili- Theattackaccuracyfortheadversaryisdefinedasfollows:
tatingeasierlearningandenhancingtheircontributiontothe
Acc= Pr
[AD,f(x,y)=b].
overallutilityofthemodel.
x,y,f,b
Havingestablishedtheeffectivenessofimportanceassign-
To assess the privacy leakage caused by membership infer-
mentandgainedpreliminaryinsightsintothelearningchar-
enceattacks(MIAs),weemploytwometricscommonlyused
acteristics, we proceed to conduct representative machine
in prior research, focusing on both worst-case and average-
learningattackstoinvestigatetheimpactofdataimportance
caseperformance:
in such attacks. Our experimental investigations are carried
out using the ResNet18 architecture, and in Section 9, we 1. (Log-scale) ROC Analysis [7], which focuses on the
demonstratethegeneralizabilityofourconclusionstodiffer- true-positiverateatlowfalse-positiverates, effectively
entarchitectures. capturing the worst-case privacy vulnerabilities of ma-
chinelearningmodels.
4 MembershipInferenceAttack
2. MembershipAdvantage[59,71],definedas
Membership Inference Attack (MIA) [12,31,34,50,55,70]
Adv=2 (Acc 0.5).
isaprominentprivacyattackutilizedtodeterminewhethera × −
specificdatasamplebelongstoatrainingdataset.Thisattack This metric represents the advantage over random
iswidelyemployedtoassesstheprivacyoftrainingdatadue guessing, multiplied by 2, providing an average-case
toitssimplicityandbroadapplicability. measuretogainanoverviewoftheattack’sefficacy.
Intheattackscenario,theadversaryA isgrantedaccessto
Inthiswork, weinvestigatefourspecificmembershipin-
a target model and is tasked with determining the member-
ferenceattacks. FortheCIFAR10andCelebAtasks,atrain-
shipstatusofagivendatasample(x,y). Formally,themem-
ingsetof50,000samplesisemployed,whilefortheTinyIm-
bership inference attack can be defined as a security game,
ageNet task, we utilize a training set of 100,000 samples to
referred to as Membership Inference Security Game, which
constructthetargetmodel.
isdescribedasfollows:
Toassessthemembershipstatusofsamples,wefirstadopt
Definition 4.1 (Membership Inference Security Game [7]). amethodologybasedonpreviousresearch[12,31]thatcon-
ThegameproceedsbetweenachallengerC andanadversary sidersthedistancetothedecisionboundaryasareflectionof
A: membershipstatus. Specifically,theyclaimthatsampleslo-
catednearthedecisionboundaryaremorelikelytobenon-
1. The challenger samples a training dataset D D and
← members, whereas samples positioned in the central region
trainsamodel f T(D)onthedatasetD.
θ ← ofthedecisionareaaremorelikelytobemembers.
2. The challenger flips a bit b, and if b = 0, samples a Wecalculatethedistancetothedecisionboundaryforall
fresh challenge point from the distribution (x,y) D samples in the training dataset. Specifically, for each sam-
(suchthat(x,y) /D). Otherwise,thechallengerse← lects ple, we iteratively perturb it using Projected Gradient De-
∈ $ scent (PGD) with a small step size until it is classified into
apointfromthetrainingset(x,y) D.
← adifferentclass. Subsequently,wecomputethedistancebe-
3. Thechallengersends(x,y)totheadversary. tween the perturbed sample and its original counterpart. In
thisanalysis,thedistanceismeasuredusingtheℓ norm,and
∞
4. The adversary gets query access to the distribution D, we find consistent results across different norms such as ℓ
andtothemodel f θ,andoutputsabitbˆ ←AD,f(x,y). andℓ 2,asevidencedbythecorrespondingfindingspresented1
5. Output1ifbˆ =b,and0otherwise. inAppendixE.
Our initial visualization focuses on examining the dis-
The adversary A is provided with auxiliary information tances of samples with different importance values. Simi-
about the data distribution D. This allows the adversary to lartotheobservationmaderegardingthedistributionofloss
4
ssoL ssoL ssoL ssoL0.040 0.00625
0.035 0.008 0.0016 0.00600
0.030 0.00575
0.025 0.007 0.0014 0.00550
0.020 0.006 0.00525
0.015 0.005 0.0012 0.00500
0.010
0.005 0.004 0.0010 0.00475
0.00450
0.000
0 1000020000300004000050000 0 1000020000300004000050000 0 1000020000300004000050000 0 20000400006000080000100000
ImportanceOrder ImportanceOrder ImportanceOrder ImportanceOrder
(a)DistanceDistribution (b)CIFAR10 (c)CelebA (d)TinyImageNet
Figure2: Relationshipbetweendistancetothedecisionboundaryandimportancevalue. Lowimportancesamplesarestatistically
closertothedecisionboundary.ThedistancemeasuredwithdifferentnormscanbefoundinAppendixE.
100 100 100
High
Low
10−1 10−1 10−1
10−2 10−2 10−2
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
FalsePositiveRate FalsePositiveRate FalsePositiveRate
(a)CIFAR10 (b)CelebA (c)TinyImageNet
Figure 3: Log-scale ROC curve: membership inference attack based on the distance to the decision boundary. High importance
samples exhibited substantially higher true-positive rates, particularly in the low false-positive rate region. Results with different
normscanbefoundinAppendixE.
valuesinSection3.1,nodirectrelationshipisdiscerniblebe- idence supporting the notion that high importance samples
tweentheimportancevalueandthedistancetothedecision are considerably more vulnerable to membership inference
boundary. Notably, samples with similar importance values attacks, which satisfies our expectation as the importance
may exhibit substantial differences in their distances to the of data samples can be regarded as the proxy of memoriza-
decision boundary. In contrast, we further analyze the sta- tion [13]. These findings thus pose a significant and tangi-
tisticalcharacteristicsofthesesamples,asperformedinSec- ble threat to the safeguarding of high importance data pri-
tion3.1andpresentthe“groupdistance”inFigure2b, Fig- vacy. On the other hand, these findings may also prompt
ure 2c, and Figure 2d. The results reveal that low impor- researcherstoconsideradoptingstrategicsamplingmethods
tance samples are statistically closer to the decision bound- formoreeffectiveprivacyauditing[22,41].
ary, which aligns with the previous conclusion that low im- We further validate the generalizability of this finding
portancesamplestendtohavehigherlosscomparedtohigh across various attack methodologies by conducting exper-
importancesamples. iments with three additional metric-based attacks: pre-
We follow the same procedure to derive the distance for diction confidence-based attack [59,71], entropy-based at-
samples in the testing dataset and launch the membership tack [50, 55], and modified prediction entropy-based at-
inference attack based on the distance. We identify 10,000 tack[58]. Thefirsttwoattackswereenhancedbyintroduc-
sampleswiththehighestimportancevalueasthehighgroup, ingclass-dependentthresholds,asdemonstratedbySongand
and an equivalent number of samples with the lowest value Mittal[58].
asthelowgroup.TheresultingROCcurves,depictedinFig- Bygroupingthesamplesbasedontheirimportancevalues
ure 3, are presented on a logarithmic scale to compare the in intervals of 10,000 samples (equivalent to the size of the
performancebetweenthesetwogroups. testingdataset),weconductedtheaforementionedattackson
From the figures, we observe significant differences in thesesubsets. Themembershipadvantageachievedforeach
the behavior of high importance samples and low impor- subsetisillustratedinFigure4. Notably, aclearmonotonic
tancesamples,particularlyinthelowfalse-positiveratearea. increase in attack advantage is observed as the importance
Specifically,fortheCIFAR10dataset,highimportancesam- value increases, establishing a positive correlation between
ples demonstrate a true-positive rate (TPR) 10.2 higher the importance value and the susceptibility of membership
×
than low importance samples at a low false-positive rate of inference.
1%. For the TinyImageNet dataset, the difference is even Thisempiricaltrendalignswithourexpectations. Asevi-
more pronounced, with high importance samples exhibiting dencedbythemetricsinFigure1andFigure2,sampleswith
aTPRthatis27.9 higherthanthatoflowimportancesam- lower importance inherently present greater learning chal-
×
plesatthesamefalse-positiverate. lenges compared to their higher-importance counterparts.
Theseobservationsprovidecompellingandempiricalev- Evenpost-learning,thesesamplesexhibitworsemembership
5
mron-
‘ ∞
etaRevitisoPeurT
mron-
‘ ∞
etaRevitisoPeurT
mron-
‘ ∞
etaRevitisoPeurT
mron-
‘ ∞0.22 Confidence 0.30 0.70
Entropy 0.25
0.20 0.68
ModifiedEntropy 0.20
0.18 0.15 0.66
0.16 0.10 0.64
0.14 0.05
0.00 0.62
10000 20000 30000 40000 50000 10000 20000 30000 40000 50000 10000 30000 50000 70000 90000
ImportanceOrder ImportanceOrder ImportanceOrder
(a)CIFAR10 (b)CelebA (c)TinyImageNet
Figure4: Membershipadvantage: membershipinferenceattackbasedonthreemetrics. Attackadvantagesteadilyescalatesasthe
importancevalueofthesamplesincreases.
Asaproofofconcept,weempiricallydeterminethehyper-
0.25 Original parameter k in an exploratory manner, adjusting its magni-
Calibrated tudeuntiloptimalperformanceisattained. Theexperimental
0.20
outcomes,depictedinFigure5,illustratethattheincorpora-
0.15
tionofimportancecalibrationnotablyenhancestheefficacy
0.10 of metric-based attacks. Nevertheless, it is pertinent to ac-
knowledge that identifying the optimal hyperparameter and
0.05
devising more refined methods for integrating importance
0.00 valueswarrantfurtherinvestigation.
Confidence Entropy ModifiedEntropy
AttackMethod Wealsoemphasizethatthisimprovementdoesnotneces-
sitateadditionalrequirementscomparedtostandardattacks;
Figure 5: Incorporation of importance values in calibrat- specifically, the adversary does not need full access to the
ing membership inference metrics improves the attack per-
training dataset to obtain importance values. Although im-
formance, demonstrating the strength of employing sample-
portancevaluescannotbecalculatedforsinglesamples,most
specificmembershipcriteria.
membership inference attacks assume access to a shadow
dataset. We validate the feasibility of our approach using a
metrics compared to those of higher importance. This cir- shadowdataset. Specifically,werandomlyselect1,000sam-
cumstancerendersthemchallengingtodistinguishfromnon- plesfromtheCIFAR10datasettocalculatetheirimportance
membersamples,especiallywhencertainnon-membersam- value, we first calculate the importance value for all sam-
plesmanifestalowerlearningdifficultyandconsequentlyex- ples using the whole CIFAR10 dataset as the ground truth.
hibitbettermetricscomparedtothemorechallengingmem- Then we assume the adversary can only access a shadow
bersamples. datasetcontaining10,000samples,andcalculatetheimpor-
Drawing from this insight, one potential strategy to en- tance value for each sample using only the shadow dataset.
hance the efficiency of membership inference attacks is to We found a correlation coefficient of 0.957 between these
compare each sample with others of comparable difficulty. values, indicating that using the shadow dataset could pro-
A pragmatic approach to actualize this entails introduc- videagoodapproximation.
ing sample-specific criteria. Rather than employing a uni-
formthresholdacrosstheentiretestingdataset,suchcriteria 4.1 PrivacyOnionEffect
shouldintricatelycorrelatewiththesample’scharacteristics,
Carlinietal.[9]haveidentifiedtheonioneffectofmemoriza-
with their designated importance level serving as a robust
tion,whichreferstothephenomenonwherein“removingthe
quantitativeindextoreflectthisalignment.
layerofoutlierpointsthataremostvulnerabletoaprivacy
Inthisstudy,weinitiateanexplorationintothefeasibility
attack exposes a new layer of previously-safe points to the
ofsuchanapproach.Toseamlesslyintegrateourmethodinto
sameattack.” Theirresearchdemonstratesthiseffectbyre-
theexistingmetric-basedframework,weintroduceasample-
movingsamplesthatareatthehighestriskofbeingcompro-
specificthresholdinaconsistentmanner: whilemaintaining
mised through membership inference, resulting in formerly
auniformthresholdforthedataset,wemodifythemember-
safesamplesbecomingvulnerabletotheattack.
shipmetricsbyincorporatinganimportance-relatedterm:
Building upon the insights from the preceding section,
our empirical findings confirm a positive correlation be-
CaliMem(x)=OriMem(x)+k Shapley(x)
× tween membership inference vulnerability and data impor-
Here,OriMem(x)denotestheconventionalmembershipmet- tance. Thispromptsanintriguingquestion: Doesthiseffect
ric, including elements such as confidence, entropy, and reflectintheimportancevaluesassignedtothedata?Putdif-
modified entropy. The term Shapley(x) signifies the im- ferently, when high importance samples are removed from
portance value attributed to the specific sample x, and adataset,dopreviouslydesignatedlowimportancesamples
CaliMem(x)representstherecalibratedmembershipmetric. gainsignificance?
6
egatnavdAkcattA
egatnavdAkcattA egatnavdAkcattA egatnavdAkcattA×104 7×103 ×103 3.5×103
1.4 Original 6 RemoveLowest 5 3.0
1.2 AfterRemoval 5 RemoveHighest 4 2.5
1.0
0.8 Cutoff 4 3 2.0
0.6 3 2 1.5
0.4 2 1.0
1
0.2 1 0.5
0.0 0 0 0.0
5 4 3 2 1 0 1 2 1 0 1 2 3 1.5 1.0 0.50.0 0.5 1.0 1.5 2.0 2.5 4 2 0 2 4 6 8
− − −Sh−apley−Value ×10−4 −ShapleyValueDifference ×10−4 − −Sha−pleyValueDifference ×10−4 − Sh−apleyValueDifference ×10−5
(a)DistributionShift (b)CIFAR10 (c)Celeba (d)TinyImageNet
Figure 6: The privacy onion effect can be extended to the importance distribution. For Figure 6a, we remove all examples with
importancevalueslargerthantheredline. Samplesthatremainafterremovalhavetheirimportancevalueincreasepasttheredline.
Subsequentfiguresconfirmthatremovinghighlyimportantsampleselevatesthesignificanceoftheremainingset,whiletheremoval
oflesssignificantsampleshasnosucheffect,rulingoutdatasetsizeinfluence.
Toavoidambiguity,itisimperativetounderstandthatthe ×10−1
term“importance”inthiscontextisnotsubjectiveorrelative. Unaltered
1.0
Theremovalofhighimportancedatapointsdoesnotinher- Augmented
ently increase the importance of those initially deemed low 0.8
importance. Furthermore, it is conceivable for a dataset to 0.6
exclusivelyconsistoflowimportancesamples. Thisclarifi-
0.4
cationisindispensable;otherwise,thestudiedquestionmay
seemtrivial. 0.2
Our results indicate that removing important samples in-
0.0
deedmakessamplespreviouslyconsideredunimportantgain 20 0 20 40 60 80 100 120 140
−
importance. Specifically,uponremoving10,000datapoints ShapleyValueAmplification(%)
with the highest importance scores, we recalculated the im-
Figure7: Impactofsampleduplicationonimportancevalues.
portance for the remaining samples. As depicted in Fig-
Followingtheduplicationprocess(16duplicationspersample),
ure6a,thisremovalledtoanoticeableredistributionindata
45outof50targetsamplesshowedamarkedincreaseinimpor-
pointimportance,withpreviouslylowimportantdatapoints
tance,averaginga53.02%rise,whiletheimportanceofcontrol
nowbeingassignedgreatersignificance.
samples(unduplicated)remainedrelativelystable.
However, a note of caution is warranted in interpreting
this result. The removal of a substantial number of sam-
ples(10,000inthiscontext)mightintroduceabaselinedrift. tion.
Therefore,attributingtheobservedimportanceaugmentation
solelytotheexclusionofimportantsamplesmightbeprema-
4.2 ActivelyModifySampleImportance
ture. Tofurthervalidateourfindings,weexecutedcontrolled
experiments wherein we systematically excluded either the Asdiscussedintheprevioussection,alteringthedatasetcan
mostorleastsignificantdatapoints. Thisapproachmitigates influence the importance of samples. Given the observed
potential biases stemming from dataset size discrepancies. linkage between membership vulnerability and importance
To emphasize the impact of these exclusions, we quantified value,aninterestingquestionarises: canweactivelyuseour
theimportancevaluediscrepanciesfordatapointsrankedbe- findings to design more advanced attacks by modifying the
tween10,000and20,000indescendingorderofimportance importanceoftargetsamples?
in the original dataset, as they remained for both removal However,directlyalteringsampleimportanceischalleng-
procedures. ing due to the absence of a standardized method or frame-
Ourresults,asvisualizedinFigure6b, Figure6c,andFig- work. Inthissection,weexploreanad-hocapproachaimed
ure6d,underscorethepronounceddisparitiesinhowtheex- atincreasingtheimportanceoftargetsamples. Specifically,
clusionofhighimportanceversuslowimportancedatasam- weselectasetoftargetsamplesandduplicateeachonemul-
ples influences the remaining dataset’s importance distribu- tiple times with consistently incorrect labels. This strategy
tion. Using CIFAR10 as an illustrative case, removing the intuitivelyheightenstheinfluenceofthesesamplesbycaus-
mostsignificantdatapointscaused99.14%oftheremaining ingthemodeltoconsiderthemas“outliers”duetothepreva-
datapointstobereevaluatedasmoreimportant. Incontrast, lenceofincorrectduplicates.Wetestedthisideabyduplicat-
removing the least significant data points led to a 45.88% ing 50 target samples 16 times and reassessing their impor-
decrease in importance for the affected data points. These tancevalues. Asshownin Figure7,theduplicatedsamples
findingsrobustlysupportourhypothesisthatdatapointspre- generally exhibited an increase in importance. Specifically,
viously deemed of lesser importance assume greater signif- 45ofthe50targetsamplesexperiencedanincreaseinimpor-
icance when high importance data points are excluded, and tance,withanaverageincreaseof53.02%,whiletheimpor-
such a conclusion cannot be attributed to dataset size varia- tanceoftheunalteredsamplesremainednearlyconstant.
7
tnuoC tnuoC tnuoC
ytisneD
tnuoC×105 2.00×105 ×105 ×105
2.0 TargetDiff 1.75 2.0 1.75
1.5 RemainedDiff 11 .. 25 50 1.5 11 .. 25 50
1.0 1.00 1.0 1.00
0.75 0.75
0.5 0.50 0.5 0.50
0.25 0.25
0.0 0.00 0.0 0.00
1.5 1.0 0.5 0.0 0.5 1.0 1.5 1.0 0.5 0.0 0.5 1.0 1.5 1.0 0.5 0.0 0.5 1.0 2.0 1.5 1.0 0.5 0.0 0.5 1.0
− −Shapl−eyValueDifference ×10−4 − S−hapley−ValueDifference ×10−4 − Sh−apley−ValueDifference ×10−4 − −Shapl−eyVa−lueDifference ×10−4
(a)ColorJitter (b)GrayScale (c)HorizontalFlip (d)VerticalFlip
Figure8:Comparisonofimportancevaluesbeforeandafterreplacing1,000sampleswiththeiraugmentedversionsusingColorJitter,
Grayscale,HorizontalFlip,andVerticalFliptechniques.Theplotillustratesthataugmentationcausedvariablechangesinimportance,
withsomesamplesgainingandotherslosingimportance.
2.00×105
TargetDiff
2.00×105 ×105 1.75×105
1.75 1.75 2.0 1.50
1.50 RemainedDiff 1.50 1.25
1.25 1.25 1.5 1.00
1.00 1.00 1.0 0.75
0.75 0.75
0.50 0.50 0.5 0.50
0.25 0.25 0.25
0.00 0.00 0.0 0.00
1.5 1.0 0.5 0.0 0.5 1.0 1.5 1.0 0.5 0.0 0.5 1.0 1.5 1.0 0.5 0.0 0.5 1.0 2.0 1.5 1.0 0.5 0.0 0.5 1.0
− −Shapl−eyValueDifference ×10−4 − S−hapley−ValueDifference ×10−4 − Sh−apley−ValueDifference ×10−4 − −Shapl−eyVa−lueDifference ×10−4
(a)ColorJitter (b)GrayScale (c)HorizontalFlip (d)VerticalFlip
Figure9: Analysisoftheimpactonimportancevalueswhen1,000augmentedsamplesareaddedtotheoriginaldataset, compared
to a baseline scenario where the same 1,000 samples were duplicated. The figure demonstrates that the presence of both original
andaugmentedsampleshadminimaleffectontheimportanceoftheoriginalsamples,showingnosignificantdifferencesfromsimple
duplication.
This approach is exactly the membership poisoning at- ableeffectsonimportance: somesamplesgainedhigherim-
tackproposedbyTramèretal.[61],wheretheycomprehen- portance, while others lost it. Overall, a slight majority of
sively demonstrated the method’s efficiency. This indicates thesamplesexperiencedadecreaseinimportancefollowing
that increasing the importance of samples can be a practi- augmentation. However, theaugmentedsampleshadaneg-
cal approach to enhance their vulnerability. By revisiting ligibleimpactontheremainingnon-augmentedsamples.
theirtechniquefromadataimportanceperspective,wehigh-
Original and Augmented Versions: In this scenario, we
light that actively modifying sample importance could be a
examined the effect of having both augmented and original
promisingstrategyfordevelopingsophisticatedattacktech- versions of certain samples in the dataset. We added 1,000
niquesorformulatingrobustdefenses.
augmented samples to the original dataset and recalculated
the importance values for the original samples. To control
4.3 DataAugmentation
for dataset size, we also considered a baseline case where
Inpreviousdiscussions,ithasbeendemonstratedthatmanip- the same 1,000 samples were duplicated. As shown in Fig-
ulating data samples can alter their importance values and, ure9, thepresenceofbothoriginalandaugmentedsamples
consequently,theirsusceptibilitytoattacks. Giventhatdata had minimal impact on the importance of the original sam-
augmentation is the most widely used method for data ma- ples,withnosignificantdifferencescomparedtosimpledu-
nipulation,itwouldbeinterestingtoask: doesdataaugmen- plication.
tationaffecttheimportanceofasample? We acknowledge that more complex augmentation tech-
Inourstudy,weexaminedtheimpactoffourdataaugmen- niques,suchasthoseusinggenerativemodels,mayhavedif-
tation techniques—ColorJitter, Grayscale, HorizontalFlip, ferent effects. The exploration of these complex augmenta-
andVerticalFlip—undertwospecificscenarios. Inbothsce- tiontechniquesremainsanavenueforfutureresearch.
narios, we selected 1,000 samples for augmentation while Takeaways: Ourfindingshighlightthevulnerabilityofhigh
leavingtherestofthedatasetunaltered:
importance samples to membership inference attacks. Sig-
Augmented Versions Only: In this scenario, we aimed to nificantdifferenceswereobservedinthebehaviorofhighim-
investigate how data augmentation impacts the importance portanceandlowimportancesamples,particularlyinthelow
of the augmented samples and the unaltered samples in the false-positive rate region, where high importance samples
dataset. Specifically, we replaced 1,000 samples with their exhibited substantially higher true-positive rates. This em-
augmented versions, recalculated their importance values, phasizesthenecessityofaddressingtheprivacyrisksassoci-
and compared these values to the original. As illustrated atedwithhighimportancesamplesandimplementingeffec-
inFigure8,wefoundthattheaugmentedversionshadvari- tivesafeguards. Simultaneously,itencouragesresearchersto
8
tnuoC
tnuoC
tnuoC
tnuoC
tnuoC
tnuoC
tnuoC
tnuoCexplorestrategicsamplingmethodstoenhancetheeffective- from the same or a similar distribution. This scenario has
nessofprivacyaudits. practicalapplications,suchascreatingasurrogatemodelto
Theobservationalsosuggestsapotentialenhancementto facilitatefurtherattacksortosaveonlabelingcosts.Welimit
membership inference attacks through the introduction of ourdiscussiontothisprimaryscenarioanddonotdelveinto
sample-specific criteria. We empirically validate the prac- more advanced model stealing techniques that focus on re-
ticality of using importance values to calibrate membership ducing the dataset assumption, as our interest lies in under-
metrics,therebyenhancingattackefficiency. standinghowdifferentdatainteractwiththemodelstealing
Moreover, our findings reveal the “privacy onion effect” process.
withinthesampleimportancedistribution,wherepreviously Ourgoalistoinvestigatewhetherquerysampleswithdif-
overlooked samples gain importance when key samples are ferent importance values exhibit varying efficiency in steal-
removed. Furthermore, by revisiting an advanced member- ing models. We explore two settings in our experiments.
ship poisoning attack from the perspective of data impor- First, we launch the attack using query data from the same
tance, we suggest that actively manipulating sample impor- distribution as the target model trained on. For example,
tance can be a potent strategy for developing sophisticated if the target model is trained on CIFAR10, we employ CI-
cybersecurity measures, both offensive and defensive, but FAR10 data to query the model. The second scenario in-
finding general manipulating methods needs further inves- volves using data from different distributions, specifically
tigation. CelebA and TinyImageNet, to query the CIFAR10 model.
Wechooseaccuracyandquerybudgetasthemetricstoeval-
5 ModelStealing uate the success of the attack, using less query budget to
achievehigheraccuracydenotesbetterattackperformance.
Model stealing attack [8,21,52,62,63] differs from mem-
bership inference attack as it aims to compromise the con-
5.1 SameDistributionQuery
fidentialityofthemodelitselfratherthanexploitingprivacy
informationabouttrainingsamples. Thistypeofattackdoes Three target models were trained using a standard training
nothaveinformationaboutthetargetmodel’sarchitectureor procedure, resultingintestingaccuraciesof95.15%forCI-
parameters but seeks to create a surrogate model that emu- FAR10,79.05%forCelebA,and65.01%forTinyImageNet.
latesthefunctionalityofthetargetmodel. Suchattackscan After training the target models, our attack solely interacts
be employed by adversaries for various purposes, including withthetargetmodelsthroughtheiroutputswithoutaccess-
monetary gains or as a preliminary step for subsequent at- ingorreadingtheirparameters.
tacks[45]. Toinitiatetheattack,weestablishaquerybudgetranging
The workflow of a model stealing attack is visualized from100to10,000.Oncethequerybudgetisdetermined,we
inFigure10.Theadversarysamplesdatafromaspecificdis- prioritizecollectinghighimportancedatauntilthebudgetis
tributionDandsimultaneouslyqueriesthetargetandsurro- exhausted,andthesameprincipleappliestothecollectionof
gatemodels. Toensuresimilaritybetweenthesurrogateand lowimportancedata.
target models, the adversary optimizes the surrogate model The attack results are illustrated in Figure 11, highlight-
to produce similar outputs S(x) as the target outputs T(x). ingthesuperiorefficiencyofhighimportancesamplesinthe
Whiletheattackapproachisstraightforward,selectinganap- modelstealingprocess. Forinstance,whenthequerybudget
propriate query data distribution poses a challenge, as it di- issetto1000,highimportancedatastealaCIFAR10model
rectlyimpactsthestolenaccuracyandqueryefficiency. Re- with53.77%accuracy,whichis1.6 higherthanthemodel
×
cent research has explored efficient and data-free methods stolen by low importance data (33.29%). This trend holds
for launching these attacks [26,44,52], yet the question of truefortheothertwodatasetsaswell. TakingTinyImageNet
selectinghigh-qualitysampleswhenthetargettaskisknown asanexample, whenthequerybudgetis1000, highimpor-
remainsintriguing. tance data yield a model accuracy of 19.25%, whereas low
Inthiswork,wefocusontheprimaryscenariowherethe importance data only result in a model accuracy of 9.25%,
adversarycanquerythetargetmodeltoobtaincorresponding exhibitinganotable2.1-folddisparity.
posteriors,whilehavingknowledgeofthetargettask.Specif- One plausible explanation for this difference may arise
ically, the adversary could query the model with a dataset fromvariationsinclassbalance,giventhatthequerysetsare
chosen based on sample importance. It is conceivable that
thelowimportancequerysetmaylacksamplesfromcertain
classes, thereby resulting in suboptimal performance. Prior
research has suggested that a more balanced data distribu-
tion could potentially improve model stealing performance
[33,52]. However, uponexaminingthedatadistributionfor
bothhighandlowsignificancesamples,weobservednosig-
nificantdisparities.Forexample,inthecaseofCIFAR10,the
entropy values for the top-10,000 high importance and low
importancedistributionswere3.282and3.245,respectively.
Figure10:Theworkflowofmodelstealingattack,theadversary Evenwhenconsidering1000samples,thecorrespondingen-
leveragesthetargetmodeltoguidethesurrogatemodel. tropy values were 3.161 (high importance) and 3.229 (low
990
80 High 70 50
60
70 Low 40
50
60
40 30
50
40 30 20
30 20 10
20 10
0
0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000
QueryBudget QueryBudget QueryBudget
(a)CIFAR10 (b)CelebA (c)TinyImageNet
Figure11:Modelstealingattackthatqueriedwithdatafromthesamedistribution.Highimportancesamplesexhibitgreaterefficiency
instealingmodelswhenthetargetmodelistrainedonthesamedistributionasthequerydistribution.
70 90 querydistribution.Importantly,thisenhancedefficiencycan-
60 High 80 notbesolelyattributedtodistributionbias.Thissuggeststhat
Low 70
50 60 adversaries,whenawareofthetargettask,canemployhigh
40 50 importance samples to optimize attack performance with a
30 40
reduced query budget. However, this conclusion does not
20 30
10 20 hold when the target task differs from the query distribu-
0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000 tion. Consequently, this implies that selecting a group of
QueryBudget QueryBudget
high importance samples as a “universal” query set for ef-
(a)CelebA (b)TinyImageNet
ficientmodelstealingattacks,regardlessofthetargettask,is
notfeasible.
Figure 12: Model stealing attack that queried with data from
differentdistributions. ThetargetmodelistrainedontheCI-
FAR10 task. Results show that importance does not transfer 6 BackdoorAttack
betweendifferenttasks.
Backdoorattack[17,32,49]isatraining-timeattackthatin-
volves actively interfering with the training process to ma-
importance). For context, a perfectly uniform distribution nipulate the resulting model. Its primary objective is to in-
has an entropy of 3.322. This indicates that both the high troducemaliciousbehaviorintothemodel,makingitbehave
and low importance subsets closely approximate a uniform likeabenignmodelfornormalinputs.However,whenaspe-
distribution. Such findings reinforce our assertion that high cifictriggerisdetected, thebackdooredmodelintentionally
importance data can indeed augment model stealing perfor- misclassifiestheinputtoapredeterminedclass. Thistypeof
mance,mitigatingconcernsrelatedtodistributionalbiases. attackcanhavesevereconsequences,suchascompromising
theintegrityandreliabilityofthemodel,leadingtopotential
5.2 DifferentDistributionQuery securitybreaches,datamanipulation,orunauthorizedaccess
tosensitiveinformation.
Theprevioussectionhighlightedtheenhancedefficiencyof
Despite the severe consequences that a backdoor attack
high importance samples in stealing models trained on the
may cause, the attack itself is relatively easy to achieve
same task. However, it remains uncertain whether this effi-
by poisoning the training dataset, thereby posing an even
ciencypersistswhenthetargetmodelistrainedusingadif-
stronger threat. For instance, a straightforward attack ap-
ferentdatasetortask,andwhetherimportancevaluescanbe
proachcalledBadNets[17]addsafixedtriggertoaportion
transferredacrosstasks.
ofthetrainingdataset,resultinginaperfectattackwhereal-
Toinvestigate,weconductedexperimentsinvolvingquery
most all triggered samples are misclassified into the target
datathatdifferedfromthedistributionusedtotrainthetarget
class,whiletheaccuracyontheoriginaltaskremainslargely
model. Specifically, weemployedaCIFAR10modelasthe
unaffected.
target model and queried it with the CelebA and TinyIma-
In the context of backdoor attacks, the poison rate plays
geNetdatasets.
a critical role as it directly influences the effectiveness and
Interestingly, as depicted in Figure 12, we observed that
concealmentoftheattack. Ahigherpoisonratecanleadto
theadvantageofhighimportancesamplesdisappearedinthis
anincreasedattacksuccessrate,butitalsoraisestheriskof
cross-taskscenario. Whenthequerybudgetwasconsistent,
detection since a large number of samples need to be mod-
the stolen accuracy for both high and low importance sam-
ified. Conversely, a lower poison rate may offer better con-
ples was comparable. This suggests that samples deemed
cealment,butitmaynotachieveoptimalattackperformance.
important for one task may not transfer effectively to arbi-
Additionally, there are situations where the adversary can
trarytasks.
only control a small set of samples, making it impossible
Takeaways: Ourfindingsdemonstratethathighimportance to poison a large number of samples to achieve the attack.
samples exhibit greater efficiency in stealing models when Consequently, the problem of backdooring a model with a
the target model is trained on the same distribution as the limited poison rate becomes an interesting and challenging
10
ycaruccA
ycaruccA
ycaruccA
ycaruccA ycaruccA100 80 100
70
80 60 80
50 60
60
40
40 30 40
High 20 20
20 Low 10
0
0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000
NumberofPoisons NumberofPoisons NumberofPoisons
(a)CIFAR10 (b)CelebA (c)TinyImageNet
Figure 13: Relationship between attack success rate and the poisoning rate, high importance samples enhance the efficiency of the
poisoningprocess,particularlywhenthepoisoningrateissmall.
researchquestion. However, we also find that when the poisoning rate is
Inthissection,weconductempiricalinvestigationstoex- large, the difference is not significant. We believe this is
plore whether poisoning samples with different importance due to the trade-off between the importance advantage and
levelsinfluencestheattackperformanceunderthesamepoi- theattackupperbound. Asthenumberofpoisonsincreases,
sonrate. Weutilizetwometricstoevaluatetheattackperfor- the advantage of using high importance data becomes more
mance: evident. However, achievingtheoptimalASRfortheback-
door attack does not require a large amount of data. Gen-
1. Accuracy. This metric assesses the deviation of the
erally, poisoning approximately 10% of the dataset is suf-
backdoored model from the clean model. We measure
ficient. Therefore, as the number of poisons increases, the
theperformanceofthebackdooredmodelontheclean
gap between high importance and low importance samples
dataset, and a successful attack should result in accu-
is reduced. Nevertheless, it is still observed that poisoning
racyclosetothatofthecleanmodel,makingitdifficult
high importance samples requires poisoning fewer samples
todetect.
toachieveitsoptimalASR.
2. AttackSuccessRate(ASR).Thismetricevaluatesthe Inscenarioswhereadversarieshavelimitedaccesstodata,
functionalityofthebackdooredmodelandismeasured determining the true importance of samples can be chal-
onthetriggereddataset. Adesirablebackdooredmodel lenging, whichimpactsthefeasibilityofselectivelypoison-
shouldexhibitahighASR,indicatingitsabilitytomis- ing high importance samples. In this case, we empirically
classifyalltriggeredsamplesintothetargetlabel. demonstratethatcalculatingtheimportancevalueusingjust
a fraction of the training set can provide a good approxi-
Byanalyzingthesemetrics,weaimtogaininsightsintothe
mation of the true importance. For example, with just 2%
influence ofdata importance on theattack performance and
of the CIFAR10 data available, the computed importance
further understand the trade-offs between attack effective-
values correlate strongly with those derived from the entire
nessandconcealmentinthecontextofbackdoorattacks.
dataset,achievingacorrelationcoefficientof0.811 0.016.
In this part, we adopt the same approach as BadNets ±
The accuracy of these approximations improves with more
to backdoor the model, with hyperparameter details pro-
data: with5%ofthedata,thecorrelationcoefficientrisesto
vided in Appendix G. Additionally, we validate the gen-
0.899 0.006, and with 20% of the data, it exceeds 0.96.
eralizability of our conclusion across five other backdoor ±
These results demonstrate that even with limited data ac-
attacks—Blend [11], SSBA [30], LF [73], SIG [6], and
cess,itisfeasibletocloselyestimatetheimportanceofsam-
CTRL [29]—which utilize various trigger patterns or target
ples,facilitatingeffectiveattackplanningunderrealisticcon-
differentlearningparadigms,asdiscussedinAppendixI.
straints.
WepresentthevisualizedattacksuccessrateinFigure13.
Additionally,ourinvestigationintotheimpactoncleanac-
Asdepictedinthefigure,thereisanoticeableincreaseinthe
curacyrevealsnosignificanttrendssuggestingthatpoisoning
attacksuccessrateasthenumberofpoisonsincreases. Con-
samplesofdifferingimportancelevelsaffectscleanaccuracy.
currently,weobservesignificantdifferencesbetweenpoison-
In both scenarios, the influence on clean accuracy remains
ing high importance samples and low importance samples.
below 2%, indicating the concealment of the backdoor at-
Specifically, poisoninganequalnumberofhighimportance
tack. Due to space constraints, detailed results are deferred
samplesprovestobemoreeffectiveinincreasingtheattack
toAppendixH.
successratecomparedtopoisoninglowimportancesamples.
Thisphenomenonbecomesmorepronouncedwhenthepoi- Takeaways: Ourexperimentalresultsdemonstratethatpoi-
soning rate is small. For instance, in the case of CIFAR10, soning high importance samples enhances the efficiency of
withapoisoningsizeof50,poisoninghighimportancedata the poisoning process, particularly when the poisoning rate
resultsinamodelwithanASRof54.42%,whereaspoison- is small. This insight offers valuable guidance for develop-
inglowimportancedataonlyachieves37.74%,indicatinga ingattackstrategiesaimedatcompromisingmodelswithre-
1.44 advantage. Similartrendscanbeobservedacrossthe stricted data accessibility. Beyond refining trigger patterns
×
othertwodatasets. foreffectiveinjections,prioritizingthepoisoningofhighim-
11
etaRsseccuSkcattA etaRsseccuSkcattA etaRsseccuSkcattA40 [0,10000]
[10000,20000]
30 [20000,30000]
[30000,40000]
20
[40000,50000]
10
0
Eyebrows Makeup Cheekbones Male Mouth Smiling Hair Lipstick
InferredAttribute
Figure14:Attributeinferenceattackperformanceondifferentattributes,nosignificantcorrelationbetweenattributeinferenceattacks
anddataimportanceisobserved.Theseconfirmourhypothesisthattheimportanceofdatasamplesiscontext-dependentandcanvary
basedonthespecifictaskathand.
portancesamplesemergesasapromisingapproach. Onthe model, which is then utilized to infer the sensitive attribute
otherhand,theinfluenceoncleanaccuracydoesnotyielda fromtheembeddings.
definitive conclusion, as poisoning either type of data has a Toevaluatetheattackperformance,weutilizerelativeac-
limitedimpactoncleanaccuracy. curacy as the metric, comparing the accuracy against a ran-
domguessingbaselinethatvariesfordifferentattributesdue
7 AttributeInferenceAttack totheunevendistributionoftheCelebAdataset.
The experimental results, as shown in Figure 14, reveal
Attributeinferenceattackisaprivacyattackthataimstoin- no significant connection between data importance and the
fersensitiveattributesthatarenotdirectlyrelatedtotheorig- success of attribute inference attacks. For instance, the
inaltaskofamachinelearningmodel. Forinstance,amodel “Arched Eyebrows” attribute is easily inferred for high im-
trained to predict age from profile photos may unintention- portance samples, while only low importance samples can
ally learn to predict race as well [39,56,57]. This type of be inferred for the “High Cheekbones” attribute. Further-
attack has significant implications for privacy and fairness, more,thevulnerabilitytoattributeinferenceforthe“Mouth
as the inadvertent leakage of sensitive attributes can have Slightly Open” attribute is most prominent among samples
far-reachingconsequences,includingtheviolationofprivacy with middle importance values. These results demonstrate
rights,potentialdiscrimination,andtheunderminingoftrust that there is no significant correlation between attribute in-
inmachinelearningsystems. ferenceattacksanddataimportance.
In this work, we focus on a commonly considered attack
One possible explanation for these results is that the im-
scenario as depicted in Figure 15, where the adversary ex-
portance value of data samples may vary depending on the
ploits the embeddings of a target sample obtained from the
prediction task. In other words, the significance of certain
target model to predict its sensitive attributes 2 To perform
features or attributes may differ across different prediction
attributeinference,theadversaryassumesauxiliaryinforma-
tasks. Forexample,whilewhiskersmaybeanimportantfea-
tionaboutthetrainingdatasetandcollectsashadowdataset
tureforpredictinggender,itmayholdlessimportancewhen
from similar distributions. They train a shadow model to
predictingincome. Wefurthervalidateourconjecturebyvi-
mimic the behavior of the target model and use the embed-
sualizing the correlation among importance values assigned
dingsandsensitiveattributestotrainanattackclassifier.
todifferentattributesinAppendixF. Itindicatesthatasam-
In this section, we investigate the impact of data im- ple’selevatedimportanceononeattributemaynotalignwith
portance on the CelebA dataset, which contains several at- itsimportanceonanotherattribute.
tributesthatcanbeinferred. Wecategorizethesamplesinto
Takeaways:Ourfindingsindicatethatthereisnotastraight-
fivegroups,eachcomprising10,000samples,basedontheir
forwardcorrelationbetweenthesignificanceofdatasamples
importancevaluesrangingfromlowtohigh. Followingthis
and the performance of an attack, aligning with our initial
categorization, we train five models using these groups as
targetmodels.
To perform the attack, we utilize 10,000 samples, dis-
joint from the 50,000 training samples, to train a shadow
model. Thisshadowmodelisemployedtogeneratedatasets
for training the attack model, where the inputs are embed-
dings,andtheassociatedsensitiveattributesserveaslabels.
We train a two-layer fully connected network as the attack
2Weacknowledgethatthereexistsaseparatelineofresearchonattribute
inferenceattackstargetingtabulardata[15,23,38],whichprimarilyaims Figure 15: The attack scenario for attribute inference attack.
toreconstructmissingattributevaluesinoriginalrecords.Giventhatthese
Theadversarycangettheembeddingsandaimstoinfersensi-
attacksemploydifferenttechnicalmethodologiesandpursuedistinctob-
tiveattributesbasedontheinformationencodedinembeddings.
jectives,ourconclusionsmaynotnecessarilyapplytosuchwork.
12
ycaruccA400 400 400
350 350 350
300 300 300
250 250 250
200 200 200
150 DeepInversion 150 150
100 Revealer 100 100
50 50 50
10000 20000 30000 40000 50000 10000 20000 30000 40000 50000 10000 30000 50000 70000 90000
ImportanceOrder ImportanceOrder ImportanceOrder
(a)CIFAR10 (b)CelebA (c)TinyImageNet
Figure16: Relationshipbetweenreconstructionqualityanddataimportance,reconstructionperformanceremainssteadyregardless
oftheimportancelevelofthedatasamples.
hypothesis. Apivotalinsightfromthissectiondemonstrates Toinvestigatetheimpactofdataimportanceontheperfor-
thattheimportanceofdatasamplesiscontext-dependentand mance of data reconstruction attacks, we partition the sam-
canvarybasedonthespecifictaskathand,whichresonates plesintogroupsof10,000basedontheirimportancevalues,
withourearlierdiscoveryinSection5.2. ranging from low importance to high importance. Subse-
quently, we train one target model for each sample group,
resultinginatotaloffivemodelsforCIFAR10andCelebA
8 DataReconstructionAttack
datasets, and ten models for TinyImageNet. We then ap-
Data reconstruction attack [14,48,69,72,75] refers to re- ply two reconstruction attacks on each of them. We lever-
covering the target dataset with limited access to the target ageFréchetInceptionDistance(FID)tomeasurethesimilar-
model,withtheaidofadditionalknowledgepossessedbythe itybetweenreconstructedsamplesandthetrainingsamples,
adversary. While data reconstruction attack shares similari- given its established utility in evaluating the quality of gen-
ties with membership inference attack, there are significant erateddistributions[60,72,75]. AsmallerFIDdenotesbet-
differences that make data reconstruction a stronger attack. terreconstructionquality. Foreachtargetmodel, wegener-
Specifically, membership inference operates at the sample ate10,000reconstructions,matchingthesizeofthetraining
level,determiningthemembershipstatusofindividualsam- dataset. Subsequently, we calculate the FID score, quanti-
ples. Incontrast,datareconstructionisadataset-levelattack fying the discrepancy between the reconstructions and the
aimed at extracting the entire training dataset. This distinc- correspondingtrainingdataset.
tion necessitates different technical approaches for data re- ThefindingspresentedinFigure16suggestthatthereisno
construction. significantdistinctionbetweenhighandlowimportancedata
In this work, we employ two data reconstruction attacks, samplesintermsofdatareconstruction. TakingCIFAR10as
namelyDeepInversion[72]andRevealer[75],toinvestigate anexample,DeepInversionexhibitsamaximumdeviationof
the influence of data importance on the reconstruction pro- only13.02%comparedtothemeanvalue,indicatingacon-
cess. These attacks are based on the optimization of input sistent performance. Similar results are observed with Re-
samples, as illustrated in Figure 17. Specifically, given a vealer,wherethemaximumdeviationismerely5.35%com-
target class y, both methods initialize a sample x and itera- pared to the mean value. Moreover, this consistent perfor-
tivelyupdateittomaximizethelikelihoodorprobabilityof manceextendstomorecomplexdatasets.Forinstance,inthe
belonging to that class while keeping the model parameters caseofCelebAdataset, themaximumdeviationislessthan
fixed. This optimization process is guided by the following 8.27%, while for TinyImageNet, the deviation is less than
lossfunction: 4.01%. These findings suggest that the reconstruction per-
minL(f (x),y) formance remains steady regardless of the importance level
θ
x
ofthedatasamples.
DeepInversion leverages statistical information encoded in
thebatchnormalizationlayertoenhancethequalityofrecon-
9 TransferabilityStudy
structions,whileRevealeremploysaGenerativeAdversarial
Network(GAN)togeneratehigh-qualityreconstructions. Inordertofortifythegeneralizabilityofourconclusions,this
sectioninvestigatesthetransferabilityofourfindingsacross
various model architectures and data modalities. For the
vision modality, we conducted experiments employing two
distinctmodelarchitectures, namelyMobileNetV2[51]and
ResNet50[19].
To evaluate the transferability to diverse data modalities,
we introduced the tabular dataset Purchase-100 [3], con-
Figure17: Theworkflowofabasicdatareconstructionattack, sisting of 600 binary features for classifying 100 classes.
theadversaryoptimizestheinputtomaximizethelikelihoodof We focus on the tabular modality considering that existing
thetargetclass. Shapley methods predominantly support vision and tabular
13
erocSDIF erocSDIF erocSDIF0.26 0.58
0.22 Confidence 0.18 0.24 0.56
Entropy 0.22 0.54
0.20 0.16
ModifiedEntropy 0.20 0.52
0.18 0.14 0.18 0.50
0.16
0.16 0.12 0.48
0.14
0.14 0.10 0.12 0.46
0.44
10000 20000 30000 40000 50000 10000 20000 30000 40000 50000 10000 20000 30000 40000 50000 4000 8000 12000 16000 20000
ImportanceOrder ImportanceOrder ImportanceOrder ImportanceOrder
(a)ResNet18(CIFAR10) (b)MobileNetV2(CIFAR10) (c)ResNet50(CIFAR10) (d)MLP(Purchase)
Figure18: Relationshipbetweenmembershipinferenceattackadvantageanddataimportance. Resultsshowthatourconclusioncan
begeneralizedtodifferentmodelarchitecturesanddatamodalities.
modalities. We utilize a Multilayer Perceptron (MLP) emergentcharacteristicswhenscaledbeyondcertainthresh-
to process the Purchase task, aligning with established olds. Additionally,theconsiderablylargerdatasetstypicalof
practicesinpriorresearch[50,55]. LLMs further complicate the feasibility of extending these
Ourexperimentalresultsconsistentlysupportourconclu- methods.
sions,irrespectiveofthemodelarchitectureanddatamodal- Furthermore, our research does not examine more com-
ity. For example, in Figure 18, the three left figures depict plex augmentation techniques, such as those utilizing gen-
aconsistentrelationshipbetweentheadvantageofmember- erative models. Future work should investigate whether
ship inference attacks and the importance of data across all these advanced techniques affect data importance and vul-
three model architectures. This trend is also evident when nerability differently. Additionally, exploring whether there
performing the attack based on the distance to the bound- exists a generalizable method to manipulate data impor-
ary (see results in Appendix J). Additionally, Figure 18d tance across various augmentation techniques would be in-
illustratesthatthisconclusionholdsforthetabularmodality. valuable. To foster further research and collaboration,
Although slight fluctuations are observed in the low impor- we have open-sourced our evaluation framework, available
tancearea,theoverallpicturedemonstratesaconsistentrela- at https://github.com/TrustAIRLab/importance-in-
tionshipbetweenimportanceandmembershipvulnerability, mlattacks. This will enable other researchers to examine
aligningwiththeconclusionsdrawnfromthevisionmodal- whethertheobserveddatadiscrepanciesholdfornewtypes
ity. ofattacks,therebybenefitingthebroadercommunity.
Furthermore,thisconclusionextendstootherattacktypes,
such as model stealing and backdoor attacks. Due to space 11 Conclusion
constraints, we defer the results to Appendix J. These find-
In this paper, our research systematically studies the vul-
ingsreaffirmtheconsistentimpactofdataimportanceacross
nerability of heterogeneous data when confronted with ma-
different attack scenarios, underscoring the generalizability
chine learning attacks. Our findings underscore a height-
ofourobservations.
ened susceptibility of high importance data samples to pri-
vacy attacks, including membership inference attacks and
10 LimitationsandFutureWork model stealing attacks. Our findings also carry practical
implications, inspiring researchers to design more efficient
While our research provides valuable insights into the rela-
attacks. For example, we empirically showcase the poten-
tionship between data importance and vulnerability to spe-
tial enhancement of membership inference attacks through
cificattacks,severallimitationsexistthatwarrantfurtherin-
theincorporationofsample-specificcriteriabasedonimpor-
vestigation. Our study focuses on a specific set of attacks.
tancevalues. Additionally,wedemonstratethatourfindings
Althoughtheseareimportant,theymaynotcovertheentire
can bestrategically employed toguide the creationof more
spectrum of potential threats. Other types of attacks could
advancedattacksthroughtheactivemanipulationofsample
exhibit different relationships between data importance and
importance.
vulnerability, and understanding how these various attacks
interact with data importance remains an open area for ex-
Acknowledgements
ploration.
Extending our findings to Large Language Models We thank all anonymous reviewers for their constructive
(LLMs)presentssubstantialchallengesdespitetheirpromis- comments. This work is partially funded by the European
ing advancements. The primary obstacle is the computa- Health and Digital Executive Agency (HADEA) within the
tionalcostassociatedwithcalculatingimportancevalues. To project “Understanding the individual host response against
manage this burden, current methods often resort to com- HepatitisDVirustodevelopapersonalizedapproachforthe
putationally lighter algorithms like KNN for classification managementofhepatitisD”(DSolve,grantagreementnum-
tasks. However, it is unclear whether similar computation- ber101057917)andtheBMBFwiththeproject“Repräsen-
allyefficientapproachescanbeadaptedtoapproximateauto- tative, synthetische Gesundheitsdaten mit starken Privat-
regression models, especially since LLMs exhibit unique sphärengarantien”(PriSyn,16KISAO29K).
14
egatnavdAkcattA egatnavdAkcattA egatnavdAkcattA egatnavdAkcattAReferences [14] MattFredrikson,SomeshJha, andThomasRistenpart.
ModelInversionAttacksthatExploitConfidenceInfor-
[1] https://www.cs.toronto.edu/~kriz/cifar.
mation and Basic Countermeasures. In ACM SIGSAC
html. 3
Conference on Computer and Communications Secu-
[2] https://www.kaggle.com/c/tiny-imagenet. 3 rity(CCS),pages1322–1333.ACM,2015. 1,13,21
[15] Matt Fredrikson, Eric Lantz, Somesh Jha, Simon Lin,
[3] https://www.kaggle.com/c/acquire-valued-
David Page, and Thomas Ristenpart. Privacy in Phar-
shoppers-challenge/data. 13
macogenetics: AnEnd-to-EndCaseStudyofPersonal-
[4] AnishAgarwal,MuntherA.Dahleh,andTuhinSarkar. izedWarfarinDosing. InUSENIXSecuritySymposium
AMarketplaceforData: AnAlgorithmicSolution. In (USENIXSecurity),pages17–32.USENIX,2014. 12
EntertainmentComputing(EC),pages701–726.ACM,
[16] Amirata Ghorbani and James Y. Zou. Data Shap-
2019. 1
ley: Equitable Valuation of Data for Machine Learn-
[5] Eugene Bagdasaryan and Vitaly Shmatikov. Blind ing. InInternationalConferenceonMachineLearning
BackdoorsinDeepLearningModels.InUSENIXSecu- (ICML),pages2242–2251.PMLR,2019. 1,2,3
ritySymposium(USENIXSecurity),pages1505–1521.
[17] TianyuGu,BrendanDolan-Gavitt,andSiddharthGrag.
USENIX,2021. 21
Badnets: Identifying Vulnerabilities in the Machine
LearningModelSupplyChain. CoRRabs/1708.06733,
[6] MauroBarni,KassemKallas,andBenedettaTondi. A
2017. 1,10,21
New Backdoor Attack in CNNS by Training Set Cor-
ruption Without Label Poisoning. In IEEE Interna- [18] Niv Haim, Gal Vardi, Gilad Yehudai, Ohad Shamir,
tional Conference on Image Processing (ICIP), pages and Michal Irani. Reconstructing Training Data from
101–105.IEEE,2019. 11,19,23 Trained Neural Networks. In Annual Conference
on Neural Information Processing Systems (NeurIPS).
[7] Nicholas Carlini, Steve Chien, Milad Nasr, Shuang
NeurIPS,2022. 21,22
Song,AndreasTerzis,andFlorianTramèr.Membership
InferenceAttacksFromFirstPrinciples. InIEEESym- [19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
posium on Security and Privacy (S&P), pages 1897– Sun. Deep Residual Learning for Image Recognition.
1914.IEEE,2022. 4,20 In IEEE Conference on Computer Vision and Pattern
Recognition(CVPR),pages770–778.IEEE,2016. 13
[8] NicholasCarlini,MatthewJagielski,andIlyaMironov.
Cryptanalytic Extraction of Neural Network Mod- [20] Xinlei He, Rui Wen, Yixin Wu, Michael Backes, Yun
els. In Annual International Cryptology Conference Shen,andYangZhang.Node-LevelMembershipInfer-
(CRYPTO),pages189–218.Springer,2020. 9 ence Attacks Against Graph Neural Networks. CoRR
abs/2102.05429,2021. 20
[9] Nicholas Carlini, Matthew Jagielski, Chiyuan Zhang,
[21] Matthew Jagielski, Nicholas Carlini, David Berthelot,
NicolasPapernot,AndreasTerzis,andFlorianTramèr.
Alex Kurakin, and Nicolas Papernot. High Accu-
ThePrivacyOnionEffect:MemorizationisRelative.In
racyandHighFidelityExtractionofNeuralNetworks.
Annual Conference on Neural Information Processing
In USENIX Security Symposium (USENIX Security),
Systems(NeurIPS).NeurIPS,2022. 2,6
pages1345–1362.USENIX,2020. 9
[10] Si Chen, Mostafa Kahla, Ruoxi Jia, and Guo-Jun Qi.
[22] MatthewJagielski,JonathanUllman,andAlinaOprea.
Knowledge-Enriched Distributional Model Inversion
Auditing Differentially Private Machine Learning:
Attacks. In IEEE International Conference on Com-
How Private is Private SGD? In Annual Conference
puterVision(ICCV),pages16158–16167.IEEE,2021.
on Neural Information Processing Systems (NeurIPS).
21
NeurIPS,2020. 5
[11] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and
[23] BargavJayaramanandDavidEvans. AreAttributeIn-
Dawn Song. Targeted Backdoor Attacks on Deep
ference Attacks Just Imputation? In ACM SIGSAC
Learning Systems Using Data Poisoning. CoRR
Conference on Computer and Communications Secu-
abs/1712.05526,2017. 11,19,23
rity(CCS),pages1569–1582.ACM,2022. 12
[12] Christopher A. Choquette Choo, Florian Tramèr, [24] Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hu-
Nicholas Carlini, and Nicolas Papernot. Label-Only bis, Nezihe Merve Gürel, Bo Li, Ce Zhang, Costas J.
Membership Inference Attacks. In International Con- Spanos, andDawnSong. EfficientTask-SpecificData
ference on Machine Learning (ICML), pages 1964– Valuation for Nearest Neighbor Algorithms. Proceed-
1974.PMLR,2021. 1,4,20 ingsoftheVLDBEndowment,2019. 1,3,18
[13] Vasisht Duddu, Sebastian Szyller, and N. Asokan. [25] Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David
SHAPr: An Efficient and Versatile Membership Pri- Dao, Bhavya Kailkhura, Ce Zhang, Bo Li, and Dawn
vacy Risk Metric for Machine Learning. CoRR Song. Scalabilityvs.Utility: DoWeHaveToSacrifice
abs/2112.02230,2021. 5 One for the Other in Data Importance Quantification?
15In IEEE Conference on Computer Vision and Pattern InIEEEInternationalConferenceonComputerVision
Recognition(CVPR),pages8239–8247.IEEE,2021.1, (ICCV),pages3730–3738.IEEE,2015. 3
3,19
[37] Scott M. Lundberg and Su-In Lee. A Unified Ap-
[26] Sanjay Kariyappa, Atul Prakash, and Moinuddin K. proach to Interpreting Model Predictions. In Annual
Qureshi. MAZE:Data-FreeModelStealingAttackUs- ConferenceonNeuralInformationProcessingSystems
ing Zeroth-Order Gradient Estimation. In IEEE Con- (NeurIPS),pages4765–4774.NIPS,2017. 1
ference on Computer Vision and Pattern Recognition
[38] Shagufta Mehnaz, Sayanton V. Dibbo, Ehsanul Kabir,
(CVPR),pages13814–13823.IEEE,2021. 9,20,21
NinghuiLi,andElisaBertino. AreYourSensitiveAt-
[27] PangWeiKohandPercyLiang. UnderstandingBlack- tributes Private? Novel Model Inversion Attribute In-
box Predictions via Influence Functions. In Interna- ference Attacks on Classification Models. In USENIX
tionalConferenceonMachineLearning(ICML),pages Security Symposium (USENIX Security), pages 4579–
1885–1894.PMLR,2017. 1,2 4596.USENIX,2022. 12
[28] Yongchan Kwon and James Zou. Beta Shapley: a [39] LucaMelis,CongzhengSong,EmilianoDeCristofaro,
UnifiedandNoise-reducedDataValuationFramework and Vitaly Shmatikov. Exploiting Unintended Feature
forMachineLearning. InInternationalConferenceon Leakage in Collaborative Learning. In IEEE Sympo-
Artificial Intelligence and Statistics (AISTATS), pages sium on Security and Privacy (S&P), pages 497–512.
8780–8802.JMLR,2022. 1 IEEE,2019. 1,12
[29] Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, [40] Luis Muñoz-González, Battista Biggio, Ambra De-
Shouling Ji, Yuan Yao, and Ting Wang. An Embar- montis,AndreaPaudice,VasinWongrassamee,EmilC.
rassingly Simple Backdoor Attack on Self-supervised Lupu, and Fabio Roli. Towards Poisoning of Deep
Learning. In IEEE International Conference on Com- LearningAlgorithmswithBack-gradientOptimization.
puter Vision (ICCV), pages 4344–4355. IEEE, 2023. In Workshop on Security and Artificial Intelligence
11,19,21,23 (AISec),pages27–38.ACM,2017. 21
[30] Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, [41] MiladNasr,ShuangSong,AbhradeepThakurta,Nico-
Ran He, and Siwei Lyu. Invisible Backdoor Attack lasPapernot,andNicholasCarlini. AdversaryInstanti-
with Sample-Specific Triggers. In IEEE International ation:LowerBoundsforDifferentiallyPrivateMachine
ConferenceonComputerVision(ICCV),pages16443– Learning. InIEEESymposiumonSecurityandPrivacy
16452.IEEE,2021. 11,19,23 (S&P).IEEE,2021. 5
[31] Zheng Li and Yang Zhang. Membership Leakage in [42] Tuan Anh Nguyen and Anh Tran. Input-Aware Dy-
Label-OnlyExposures.InACMSIGSACConferenceon namic Backdoor Attack. In Annual Conference on
ComputerandCommunicationsSecurity(CCS),pages Neural Information Processing Systems (NeurIPS).
880–895.ACM,2021. 1,4,20 NeurIPS,2020. 21
[32] Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan [43] TuanAnhNguyenandAnhTuanTran.WaNet-Imper-
Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. ceptible Warping-based Backdoor Attack. In Interna-
TrojaningAttackonNeuralNetworks. InNetworkand tionalConferenceonLearningRepresentations(ICLR),
DistributedSystemSecuritySymposium(NDSS).Inter- 2021. 3,18
netSociety,2018. 1,10,21
[44] Tribhuvanesh Orekondy, Bernt Schiele, and Mario
[33] Yiyong Liu, Rui Wen, Michael Backes, and Yang Fritz. KnockoffNets: StealingFunctionalityofBlack-
Zhang. EfficientData-FreeModelStealingwithLabel BoxModels. InIEEEConferenceonComputerVision
Diversity. CoRRabs/2404.00108,2024. 9,20 and Pattern Recognition (CVPR), pages 4954–4963.
IEEE,2019. 9,20,21
[34] YiyongLiu,ZhengyuZhao,MichaelBackes,andYang
Zhang. Membership Inference Attacks by Exploit- [45] Nicolas Papernot, Patrick D. McDaniel, Ian Goodfel-
ing Loss Trajectory. In ACM SIGSAC Conference on low, Somesh Jha, Z. Berkay Celik, and Ananthram
ComputerandCommunicationsSecurity(CCS),pages Swami. PracticalBlack-BoxAttacksAgainstMachine
2085–2098.ACM,2022. 1,4,20 Learning. In ACM Asia Conference on Computer and
CommunicationsSecurity(ASIACCS),pages506–519.
[35] Yugeng Liu, Rui Wen, Xinlei He, Ahmed Salem,
ACM,2017. 9
Zhikun Zhang, Michael Backes, Emiliano De Cristo-
faro,MarioFritz,andYangZhang. ML-Doctor: Holis- [46] Sung Min Park, Kristian Georgiev, Andrew Ilyas,
ticRiskAssessmentofInferenceAttacksAgainstMa- Guillaume Leclerc, and Aleksander Madry. TRAK:
chine Learning Models. In USENIX Security Sympo- Attributing Model Behavior at Scale. In Interna-
sium (USENIX Security), pages 4525–4542. USENIX, tionalConferenceonMachineLearning(ICML),pages
2022. 1,3,18 27074–27113.PMLR,2023. 1,3
[36] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou [47] Marco Túlio Ribeiro, Sameer Singh, and Carlos
Tang. Deep Learning Face Attributes in the Wild. Guestrin. Why Should I Trust You?: Explaining the
16Predictions of Any Classifier. In ACM Conference on [59] LiweiSong, RezaShokri, andPrateekMittal. Privacy
KnowledgeDiscoveryandDataMining(KDD),pages Risks of Securing Machine Learning Models against
1135–1144.ACM,2016. 1 AdversarialExamples.InACMSIGSACConferenceon
ComputerandCommunicationsSecurity(CCS),pages
[48] AhmedSalem,ApratimBhattacharya,MichaelBackes,
241–257.ACM,2019. 4,5
MarioFritz,andYangZhang. Updates-Leak: DataSet
InferenceandReconstructionAttacksinOnlineLearn- [60] Lukas Struppek, Dominik Hintersdorf, Antonio
ing. In USENIX Security Symposium (USENIX Secu- De Almeida Correia, Antonia Adler, and Kristian
rity),pages1291–1308.USENIX,2020. 13,21 Kersting. Plug & Play Attacks: Towards Robust and
Flexible Model Inversion Attacks. In International
[49] AhmedSalem,RuiWen,MichaelBackes,ShiqingMa,
Conference on Machine Learning (ICML), pages
andYangZhang. DynamicBackdoorAttacksAgainst
20522–20545.PMLR,2022. 13,21
MachineLearningModels. InIEEEEuropeanSympo-
[61] Florian Tramèr, Reza Shokri, Ayrton San Joaquin,
siumonSecurityandPrivacy(EuroS&P),pages703–
Hoang Le, Matthew Jagielski, Sanghyun Hong, and
718.IEEE,2022. 1,3,10,18,21
Nicholas Carlini. Truth Serum: Poisoning Machine
[50] Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal Learning Models to Reveal Their Secrets. In ACM
Berrang,MarioFritz,andMichaelBackes. ML-Leaks: SIGSAC Conference on Computer and Communica-
Model and Data Independent Membership Inference tionsSecurity(CCS).ACM,2022. 2,8,20
AttacksandDefensesonMachineLearningModels. In
[62] FlorianTramèr, FanZhang, AriJuels, MichaelK.Re-
Network and Distributed System Security Symposium
iter, andThomasRistenpart. StealingMachineLearn-
(NDSS).InternetSociety,2019. 1,4,5,14,20
ing Models via Prediction APIs. In USENIX Secu-
[51] Mark Sandler, Andrew G. Howard, Menglong Zhu, rity Symposium (USENIX Security), pages 601–618.
Andrey Zhmoginov, and Liang-Chieh Chen. Mo- USENIX,2016. 1,9,20,21
bileNetV2: InvertedResidualsandLinearBottlenecks.
[63] Jean-BaptisteTruong,PratyushMaini,RobertJ.Walls,
In IEEE Conference on Computer Vision and Pattern
and Nicolas Papernot. Data-Free Model Extraction.
Recognition (CVPR), pages 4510–4520. IEEE, 2018.
In IEEE Conference on Computer Vision and Pattern
13
Recognition(CVPR),pages4771–4780.IEEE,2021.1,
[52] Sunandini Sanyal, Sravanti Addepalli, and 9,20,21
R.VenkateshBabu.TowardsData-FreeModelStealing
[64] Kuan-Chieh Wang, Yan Fu, Ke Li, Ashish Khisti,
inaHardLabelSetting. CoRRabs/2204.11022,2022.
Richard S. Zemel, and Alireza Makhzani. Varia-
1,9,21 tionalModelInversionAttacks. InAnnualConference
on Neural Information Processing Systems (NeurIPS),
[53] Ali Shafahi, W Ronny Huang, Mahyar Najibi, Octa-
pages9706–9719.NeurIPS,2021. 21
vianSuciu,ChristophStuder,TudorDumitras,andTom
Goldstein.PoisonFrogs!TargetedClean-LabelPoison- [65] Rui Wen, Zheng Li, Michael Backes, and Yang
ingAttacksonNeuralNetworks.InAnnualConference Zhang. Membership Inference Attacks Against In-
on Neural Information Processing Systems (NeurIPS), Context Learning. In ACM SIGSAC Conference on
pages6103–6113.NeurIPS,2018. 21 ComputerandCommunicationsSecurity(CCS).ACM,
2024. 20
[54] LloydSShapley. AValueforn-personGames. Contri-
butionstotheTheoryofGames,1953. 2 [66] RuiWen,TianhaoWang,MichaelBackes,YangZhang,
and Ahmed Salem. Last One Standing: A Com-
[55] RezaShokri,MarcoStronati,CongzhengSong,andVi-
parative Analysis of Security and Privacy of Soft
talyShmatikov.MembershipInferenceAttacksAgainst
PromptTuning,LoRA,andIn-ContextLearning.CoRR
MachineLearningModels. InIEEESymposiumonSe-
abs/2310.11397,2023. 20
curityandPrivacy(S&P),pages3–18.IEEE,2017. 1,
4,5,14,20 [67] Rui Wen, Zhengyu Zhao, Zhuoran Liu, Michael
Backes,TianhaoWang,andYangZhang. IsAdversar-
[56] Congzheng Song and Ananth Raghunathan. Informa-
ial Training Really a Silver Bullet for Mitigating Data
tionLeakageinEmbeddingModels. InACMSIGSAC
Poisoning? In International Conference on Learning
Conference on Computer and Communications Secu-
Representations(ICLR),2023. 21
rity(CCS),pages377–390.ACM,2020. 12
[68] Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao
[57] Congzheng Song and Vitaly Shmatikov. Overlearning Zhu,ShaokuiWei,DanniYuan,andChaoShen. Back-
Reveals Sensitive Attributes. In International Confer- doorBench:AComprehensiveBenchmarkofBackdoor
enceonLearningRepresentations(ICLR),2020. 1,12 Learning.InAnnualConferenceonNeuralInformation
ProcessingSystems(NeurIPS).NeurIPS,2022. 20
[58] Liwei Song and Prateek Mittal. Systematic Evalua-
tion of Privacy Risks of Machine Learning Models. [69] Ziqi Yang, Jiyi Zhang, Ee-Chien Chang, and Zhenkai
In USENIX Security Symposium (USENIX Security). Liang. Neural Network Inversion in Adversarial Set-
USENIX,2021. 5 ting via Background Knowledge Alignment. In ACM
17SIGSAC Conference on Computer and Communica- To validate that our findings are not dependent on this
tions Security (CCS), page 225–240. ACM, 2019. 13, specific attribute selection, we conducted the same experi-
21 mentsusinganotherrandomlyselectedsetofattributes(High
Cheekbones,ArchedEyebrows,andWearingLipstick). We
[70] Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda,
evaluatedtheperformanceonmembershipinferenceattacks,
Vincent Bindschaedler, and Reza Shokri. Enhanced
model stealing, and backdoor attacks. The results are de-
MembershipInferenceAttacksagainstMachineLearn-
pictedinFigure19,confirmingthatourfindingsareconsis-
ingModels. InACMSIGSACConferenceonComputer
tent across these different attribute sets. For example, Fig-
and Communications Security (CCS), pages 3093–
ure 19a demonstrate that samples with higher importance
3106.ACM,2022. 4
aremorevulnerabletomembershipinferenceattack; italso
[71] SamuelYeom,IreneGiacomelli,MattFredrikson,and reflects on the worst-case evaluation as illustrated in Fig-
Somesh Jha. Privacy Risk in Machine Learning: An- ure 19b. The conclusion holds for backdoor and model
alyzing the Connection to Overfitting. In IEEE Com- stealing attack, specifically, with a 1500 query budget, high
puter Security Foundations Symposium (CSF), pages importance samples can steal a surrogate model with 48%
268–282.IEEE,2018. 4,5 higheraccuracythanthatstolenbylowimportancesamples.
[72] Hongxu Yin, Pavlo Molchanov, Jose M. Alvarez,
ZhizhongLi,ArunMallya,DerekHoiem,NirajK.Jha, B MeasurementHyperparameter
andJanKautz. DreamingtoDistill: Data-FreeKnowl-
edgeTransferviaDeepInversion. InIEEEConference In implementing the KNN-Shapley method, we set the hy-
on Computer Vision and Pattern Recognition (CVPR), perparameterk=6,followingthesuggestionintheoriginal
pages8712–8721.IEEE,2020. 1,13 paper [24]. Further experimentation with k=7 and k=8
indicatedthatperformanceremainslargelyconsistentacross
[73] Yi Zeng, Won Park, Z. Morley Mao, and Ruoxi Jia.
these settings. Specifically, the correlation between impor-
Rethinking the Backdoor Attacks’ Triggers: A Fre-
tancevaluescalculatedwithk=6andk=7is0.9988, and
quency Perspective. In IEEE International Confer-
betweenk=6andk=8, it’s0.9972, demonstratingthero-
enceonComputerVision(ICCV),pages16453–16461.
bustnessofourresultswithrespecttothishyperparameter.
IEEE,2021. 11,19,23
[74] Minxing Zhang, Ning Yu, Rui Wen, Michael Backes,
C ImportanceDistribution
andYangZhang. GeneratedDistributionsAreAllYou
NeedforMembershipInferenceAttacksAgainstGen- Figure22showstheimportancedistributionsfortheCelebA
erativeModels. InWinterConferenceonApplications andTinyImageNetdataset.
ofComputerVision(WACV),pages4827–4837.IEEE,
2024. 20
D EffectivenessofKNN-Shapley
[75] Yuheng Zhang, Ruoxi Jia, Hengzhi Pei, Wenxiao
WevalidatetheefficacyoftheKNN-Shapleymethodtoen-
Wang, Bo Li, and Dawn Song. The Secret Re-
sureitsaccurateassignmentofimportancevaluetoindivid-
vealer: Generative Model-Inversion Attacks Against
ualsamples.
DeepNeuralNetworks. InIEEEConferenceonCom-
puter Vision and Pattern Recognition (CVPR), pages We apply the KNN-Shapley approach to three distinct
250–258.IEEE,2020. 1,13,21 datasetsandcomputetheimportancevalueforeachsample.
To gain insight into the contribution of different samples to
[76] NanZhong, ZhenxingQian, andXinpengZhang. Im-
the model’s utility, we visualize the distribution of impor-
perceptibleBackdoorAttack:FromInputSpacetoFea-
tancevaluesfortheCIFAR10datasetinFigure23a.
tureRepresentation.InInternationalJointConferences
The observed distribution aligns with our expectations,
onArtificalIntelligence(IJCAI),pages1736–1742.IJ-
as most samples exhibit similar contributions, while certain
CAI,2022. 3,18
samples significantly influence the model’s behavior. We
[77] Chen Zhu, W Ronny Huang, Hengduo Li, Gavin Tay- corroborate this finding with the other two datasets, and in-
lor, Christoph Studer, and Tom Goldstein. Transfer- cludethecorrespondingvisualizationsinAppendixC.
able Clean-label Poisoning Attacks on Deep Neural Subsequently, we empirically validate whether samples
Nets. In International Conference on Machine Learn- withhighimportancevaluesandthosewithlowimportance
ing(ICML),pages7614–7623.JMLR,2019. 21 valuesdemonstratedistincttrainingperformance.Toachieve
this, we sort the samples based on their importance values
andformtwosets: onecomprisingsampleswiththehighest
A CelebAAttributeSelection
values and the other consisting of samples with the lowest
The CelebA dataset contains 40 binary attributes, which is values. Weemploythesetwosetstotraintwoseparatemod-
notsuitableformulti-classclassification. Therefore,wefol- elsandevaluatetheirperformanceonthetestingdataset. We
lowpreviousworks[35,43,49,76]thatselectthethreemost varythesizeofthesetwosetsfrom50to5000andplotthe
balanced attributes (Heavy Makeup, Mouth Slightly Open, corresponding testing accuracy in Figure 23b, Figure 23c,
andSmiling)tocreatean8-class(23)classificationtask. andFigure23d.
180.40 100 80 60
0.35 Confidence High 70 High High
0.30 Entropy Low 60 Low 50 Low
0.25 ModifiedEntropy
10−1
50 40
0.20 40
0.15 10−2 30 30
0.10 20 20
0.05
0.00
10000 20000 30000 40000 50000
10−13
0−3 10−2 10−1 100
10
0 25050075010001250150017502000
10
0 2000 4000 6000 8000 10000
ImportanceOrder FalsePositiveRate NumberofPoisons QueryBudget
(a)MIA(metric-based) (b)MIA(log-scale) (c)BackdoorASR (d)ModelStealing
Figure19:Attackperformanceonsampleswithhighandlowimportance.Theresultsdemonstratethatourconclusionsareconsistent
acrossdifferentsetsofselectedattributes.
70 60 E MembershipInferenceAttack
High
60 Low 50 Figure 24 depicts the distance to the boundary for samples
50 40
withdifferentimportancevalues,measuredbytwodifferent
40 30 norms.
30
20 Figure25representsthelog-scaleROCcurvesforattacks
20
10 conductedbasedonthedistancetotheboundary.
0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000
NumberofTrainingSamples NumberofTrainingSamples
(a)LOO (b)Trak F CorrelationBetweenDifferentAttributes
Figure20: LOOandTrakfailtocapturethecomplexinterac- We visualize the correlation among importance values as-
tions between subsets of data, resulting in suboptimal sample signedtodifferentattributesinFigure26.
importanceidentificationperformance.
G HyperparametersforBackdoorAttacks
Runtime Comparison
Object Classification For the three datasets evaluated in our study—CIFAR10,
ResNet18 Classifier
104 CelebA, and TinyImagenet—a consistent modification was
appliedtoeachimage: ablacksquarewaspositionedatthe
103 bottomleftcorner.
The dimension of this black square, or backdoor trigger,
102 variedaccordingtotheimagesizesoftherespectivedatasets
TMC-Shapley to maintain proportional consistency. Specifically, for the
G-Shapley
101 Leave-One-Out CIFAR10 dataset, with an image resolution of 32 32, the
KNN-Shapley ×
triggerwassizedat2 2. InthecaseofCelebA,whichfea-
101 102 103
Number of training data points in log scale tures larger images w× ith dimensions of 178 218, the trig-
×
ger’s size was increased to 8 8. Lastly, for images from
Figure 21: A runtime comparison of current measurement ×
TinyImagenet,whichare64 64pixels,a5 5squarewas
methods reveals their significant computational inefficiency. × ×
usedasthetrigger.
(FigureadaptedfromFigure1in[25])
H CleanAccuracyPerformance
Theeffectofpoisoninghighandlowimportancesampleson
cleanaccuracyisdepictedin Figure26.
Thefiguresclearlydemonstratethatsampleswithvarying
importance values exhibit significant differences in training
I MoreBackdoorAttacks
performance. Specifically,consideringtheCIFAR10dataset
trainedwith2000samples, themodeltrainedwithhighim- Toassesswhethertheobservationthatpoisoninghighimpor-
portance samples achieves a testing accuracy that is 1.6 tance data samples enhances backdoor attack effectiveness
×
higher compared to the model trained with low importance is applicable to various trigger patterns, we broadened our
samples. Moreover, in the case of TinyImageNet, the dis- study to include three additional backdoor methods. These
parityisevenmorepronounced. Whenthetrainingsetcom- methods comprise Blend [11], which incorporates triggers
prises 5000 samples, the model trained with valuable data coveringtheentiretyoftheinput; SSBA[30],characterized
attainsatestingaccuracythatis4.4 higherthanthatofthe bysample-specificandinvisibletriggers;LF[73],whichuti-
×
model trained with low importance samples. These exper- lizes triggers of low frequency; SIG [6], a method without
imental findings provide strong evidence supporting the ef- label poisoning; and CTRL [29], which targets contrastive
fectivenessofKNN-Shapley. learning.
19
ycaruccA
egatnavdAkcattA
)s(
elacs
gol
ni
emit
gninnuR
ycaruccA
etaRevitisoPeurT
etaRsseccuSkcattA
ycaruccA1.6×104 ×104 7×103
3.0
1.4 6
1.2 2.5
5
1.0 2.0
4
0.8 1.5
3
0.6
0.4 1.0 2
0.2 0.5 1
0.0 0.0 0
5 4 3 2 1 0 1 2 3 1.0 0.5 0.0 0.5 1.0 5 4 3 2 1 0 1 2 3
− − − S−haple−yValue ×10−4 − − ShapleyValue ×10−4 − − − S−haple−yValue ×10−4
(a)CelebA (b)TinyImagenet (c)Purchase
Figure22:ImportancedistributionforCelebA,TinyImagenet,Purchase.
1.4×104
60 High
60
25
11 .. 02 50 Low 45 00 20
0.8 40 15
30
0.6 30 10
20
0.4
20 5
0.2 10
0.0 10 0
5 4 3 2 1 0 1 2 0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000
− − − Sh−apley−Value ×10−4 NumberofTrainingSamples NumberofTrainingSamples NumberofTrainingSamples
(a)ShapleyDistribution (b)CIFAR10 (c)CelebA (d)TinyImageNet
Figure23:Distributionofimportancevalueandlearningcharacteristicsfordatawithdifferentimportance.Highimportancesamples
contributetobettermodelutilitywhenthedatasethasthesamesize. ImportancedistributionforCelebAandTinyImageNetcanbe
foundinAppendixC.
We utilized the BackdoorBench tool [68] to conduct our ple was part of the training dataset or not, thereby directly
experiments,adheringtoalldefaultimplementationsettings breachingprivacy.
withthesolemodificationbeingtheselectionprocessforpoi- The seminal work by Shokri et al. [55] introduced MIA
soningsamples. against machine learning models, wherein multiple shadow
The results, depicted in Figure 28, consistently demon- models were trained to mimic the behavior of the target
stratethatthepoisoningof highimportancesamplessignif- model.Thisattackoriginallyrequiredaccesstodatafromthe
icantlyimprovestheefficacyofthebackdoorattacksacross samedistributionasthetrainingdataset. However,Salemet
morecomplextriggerpatterns,thusunderscoringtherobust al.[50]relaxedthisassumptionbydemonstratingtheeffec-
generalizabilityofourconclusions. tiveness of using only a single shadow model, substantially
reducingthecomputationalcostinvolved.
Subsequentresearch[12,31]hasexploredmorechalleng-
J TransferabilityStudy
ing settings for MIA. In these scenarios, the adversary only
Figure 29 and Figure 30 demonstrate the transferability on has access to hard-label predictions from the target model.
modelstealingandbackdoorattack. LiandZhang[31]proposedamethodthatapproximatesthe
Figure31showcasesLog-scaleROCcurvesforthreedis- distancebetweenthetargetsampleanditsdecisionboundary
tinctarchitecturesutilizingthreedifferentnorms. Theexper- usingadversarialexamples,enablingtheattackertomakede-
imentsareconductedontheCIFAR10targetdataset. cisionsbasedonthisdistance.
Recent advancements in MIA have focused on enhanc-
ing attack performance. Carlini et al. [7] leveraged the dis-
K RelatedWork
crepancy between models trained with and without the tar-
In addition to the attack approach investigated in our work, get sample to improve attack effectiveness. Liu et al. [34]
severalmethodsexistforprivacyandsecurityattacksagainst demonstrated the utility of loss trajectory analysis in MIA.
machinelearningmodels. Inthefollowingsection, wepro- Furthermore, Tramèr et al. [61] highlighted the potential of
videabriefoverviewoftheseapproaches. data poisoning, showing that even with access to a small
fractionofthetrainingdataset,theattackercansignificantly
K.1 MembershipInferenceAttack boosttheperformanceofmembershipinferenceattacks.
MembershipInferenceAttacks(MIA)[20,31,50,55,65,74]
K.2 ModelStealingAttack
haveemergedasasignificantthreattoprivacyinthecontext
ofmachinelearningmodels. Theseattacksaimtorevealthe Model stealing attacks [26,33,44,62,63,66] aim to extract
membershipstatusofatargetsample,i.e.,whetherthesam- information from a victim model and construct a local sur-
20
tnuoC
tnuoC
ycaruccA
tnuoC
ycaruccA
tnuoC
ycaruccA60
3.6
16 58
3.4
56
14 3.2
54
3.0
52
12 2.8
50
2.6
10 48
2.4
46
8 2.2 44
0 1000020000300004000050000 0 1000020000300004000050000 0 20000400006000080000100000
ImportanceOrder ImportanceOrder ImportanceOrder
(a)CIFAR10 (b)CelebA (c)TinyImageNet
0.350 0.075 0.58
0.325 0.070 0.56
0.300 0.065 0.54
0.275 0.52
0.060
0.250 0.50
0.225 0.055 0.48
0.200 0.050 0.46
0.175 0.045 0.44
0.150 0.42
0 1000020000300004000050000 0 1000020000300004000050000 0 20000400006000080000100000
ImportanceOrder ImportanceOrder ImportanceOrder
(d)CIFAR10 (e)CelebA (f)TinyImageNet
Figure24:Relationshipbetweendistancetothedecisionboundaryandimportancevalue.
rogatemodel. ThisattackwasinitiallyproposedbyTramèr injecting static triggers, making them susceptible to detec-
et al. [62], assuming that the adversary has access to a sur- tion.
rogate dataset for stealing the model. Orekondy et al. fur- Salemetal.[49]integratedgenerativemodelstoperform
ther advanced this approach by developing a reinforcement dynamicbackdoorattacks,wherethetriggerisnotfixedthus
learning-basedframeworkthatoptimizesquerytimeandef- increasingthedifficultyofdetection. NguyenandTran[42]
fectiveness[44]. furtherextendedthisconcepttodesignaninput-awareattack.
Recent research has focused on the more stringent data- Mostexistingattacksinthisdomainarebasedonpoisoning
free setting, where adversaries lack access to any data. In attacks[40,53,67,77],whichinvolvepoisoningthetraining
this context, Kariyappa et al. [26] propose MAZE, which dataset. Incontrast,BagdasaryanandShmatikov[5]propose
employsagenerativemodeltogeneratesyntheticdatasam- adistinctattacktargetinthescenariowherethelearningal-
ples for launching the attack. The generator is trained to gorithmitselfispoisoned,presentinganalternativeapproach
maximize disagreement between the victim model and the inthisfieldofstudy.
clonemodel,requiringthegradientsfromthevictimmodel.
Toapproximatethesegradientswithonlyblack-boxaccess, K.4 DataReconstructionAttack
zeroth-ordergradientestimationtechniquesareadopted.
Datareconstructionattacks[14,18,48,69]aimtorecoverthe
Truong et al. [63] present a similar approach, where they
target dataset with limited access to the target model, with
replacethelossfunctionfromKullback-Leibler(KL)diver-
theaidofadditionalknowledgepossessedbytheadversary.
gencetoℓ normlossfortrainingthestudentmodel. Incon-
1 In the realm of data reconstruction attacks, existing
trasttothepreviousattacksthatgenerate“hard”queriesthat
approaches can be broadly classified into three cate-
differ in predictions between the victim and clone models,
gories: optimization-based attacks, training-based attacks,
Sanyaletal.[52]adoptadifferentstrategybygenerating"di-
andanalysis-basedattacks.
verse"queriestoincreasepredictionsbelongingtodifferent
Optimization-basedattacks,firstintroducedbyFredrikson
classes.
et al. [14], represent the majority of existing reconstruction
attacks. Theseattacksemployaniterativeoptimizationpro-
K.3 BackdoorAttack
cess to reconstruct the training dataset, with the objective
Backdoorattacks[5,17,29,32,49]aretraining-timeattacks of obtaining a high likelihood score for the desired class.
that introduce malicious behavior into the model, making Notably, the integration of generative models by Zhang et
it behave like a benign model for normal inputs, while in- al. [75] has contributed to improving the quality of recon-
tentionallymisclassifyingtheinputtoapredeterminedclass struction. Building on this line of research, several stud-
whenthetriggerappears. ies have explored diverse architectural choices [10,64] and
TheseminalworkbyGuetal.[17]introducedtheconcept lossfunctions[60]tofurtherenhancereconstructionperfor-
ofthebackdoorattackonmachinelearningmodels.Building mance.
uponthis,Liuetal.[32]proposedanadvancedbackdooring Conversely, training-based attacks [69] regard the target
technique that incorporates enhanced triggers and relies on modelasanencoderandtrainacorrespondingdecodernet-
fewer assumptions. However, these attacks were limited to worktoreconstructinputsbasedonthemodel’soutputs. Re-
21
mron-1‘
mron-2‘
mron-1‘
mron-2‘
mron-1‘
mron-2‘100 100 100
High
Low
10−1 10−1 10−1
10−2 10−2 10−2
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
FalsePositiveRate FalsePositiveRate FalsePositiveRate
(a)CIFAR10 (b)CelebA (c)TinyImageNet
100 100 100
High
Low
10−1 10−1 10−1
10−2 10−2 10−2
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
FalsePositiveRate FalsePositiveRate FalsePositiveRate
(d)CIFAR10 (e)CelebA (f)TinyImageNet
Figure25:Log-scaleROCcurve:membershipinferenceattackbasedonthedistancetothedecisionboundary.Thefirstrowisresults
generatedusingℓ normwhilethesecondrowisusingℓ norm.
1 2
1.0
Combined 1.00 0.12 0.36 0.35 0.07 0.58 0.54 0.00 0.17
Eyebrows 0.12 1.00 0.28 0.10 0.12 0.03 0.04 0.03 0.20
0.8
Makeup 0.36 0.28 1.00 0.09 0.18-0.000.02 0.05 0.48
Cheekbones 0.35 0.10 0.09 1.00 0.08 0.31 0.59-0.030.08 0.6
Male 0.07 0.12 0.18 0.08 1.00 0.01 0.02 0.00 0.48
0.4
Mouth 0.58 0.03-0.000.31 0.01 1.00 0.46-0.02-0.01
Smiling 0.54 0.04 0.02 0.59 0.02 0.46 1.00-0.020.01
0.2
Hair 0.00 0.03 0.05-0.030.00-0.02-0.021.00 0.03
Lipstick 0.17 0.20 0.48 0.08 0.48-0.010.01 0.03 1.00
0.0
Figure26: Theheatmapdepictsthecorrelationamongimpor-
tance values assigned to different attributes. It indicates that
asample’selevatedimportanceononeattributemaynotalign
withitsimportanceonanotherattribute.
cently, Haim et al. [18] presented a theoretical demonstra-
tionthat,underspecificassumptions,thetrainingdatacanbe
completelyrecovered,leadingtoanewattackapproach.
22
etaRevitisoPeurT
etaRevitisoPeurT
denibmoC sworbeyE puekaM senobkeehC elaM htuoM gnilimS riaH
etaRevitisoPeurT
etaRevitisoPeurT
kcitspiL
etaRevitisoPeurT
etaRevitisoPeurT96 80.0 68
95 79.5 67
79.0
94 66
78.5
93 78.0 65
92 77.5 64
High
77.0
91 Low 76.5 63
90 76.0 62
0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000
NumberofPoisons NumberofPoisons NumberofPoisons
(a)CIFAR10 (b)CelebA (c)TinyImageNet
Figure27:Relationshipbetweenaccuracyandthepoisoningrate,poisoningsampleswithdifferentimportancedoesnothaveasignifi-
cantdifference.
1.0 1.0 1.0 1.0
0.9 0.8 0.8 0.9 0.9
0.8
0.7 0.6 0.6 0.8 0.8
00 .. 56 High 0.4 0.4 00 .. 67 00 .. 67
0.4 Low 0.2 0.2 0.5 0.5
0 500 1000 1500 2000 0 500 1000 1500 2000 0 500 1000 1500 2000 0 100 200 300 400 500 1030507090110130150170190
NumberofPoisons NumberofPoisons NumberofPoisons NumberofPoisons NumberofPoisons
(a)Blend[11] (b)SSBA[30] (c)LF[73] (d)SIG[6] (e)CTRL[29]
Figure28: Relationshipbetweenattacksuccessrateandthepoisoningrateondifferentbackdoorattacks, theconclusionthathigh
importancesamplesenhancetheefficiencyofthepoisoningprocessholdsforotherbackdoorattackswithdifferentbackdoorpatterns
andlearningparadigms.
90 80
80 High 80 80 70
70 Low 70 70
60 60 60 60
50 50 50 50
40 40 40 40
30 30 30 30
20 20 20 20
0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000 200 400 600 800100012001400
QueryBudget QueryBudget QueryBudget QueryBudget
(a)ResNet18(CIFAR10) (b)MobileNetV2(CIFAR10) (c)ResNet50(CIFAR10) (d)MLP(Purchase)
Figure29:Relationshipbetweenmodelstealingaccuracyandthequerybudget.
100 100 100
80
80 80 80
60
60 60 60
40
40 40 40
High 20
20 Low 20 20
0
0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000
NumberofPoisons NumberofPoisons NumberofPoisons NumberofPoisons
(a)ResNet18(CIFAR10) (b)MobileNetV2(CIFAR10) (c)ResNet50(CIFAR10) (d)MLP(Purchase)
Figure30:Relationshipbetweenbackdoorattacksuccessrateandthepoisoningrate.
23
ycaruccA
etaRsseccuSkcattA
etaRsseccuSkcattA
ycaruccAnaelC
etaRsseccuSkcattA
ycaruccA
etaRsseccuSkcattA
ycaruccAnaelC
etaRsseccuSkcattA
ycaruccA
etaRsseccuSkcattA
etaRsseccuSkcattA
ycaruccAnaelC
ycaruccA
etaRsseccuSkcattA
etaRsseccuSkcattA100 100 100
High High High
Low Low Low
10−1 10−1 10−1
10−2 10−2 10−2
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
FalsePositiveRate FalsePositiveRate FalsePositiveRate
(a)ResNet18 (b)MobileNetV2 (c)ResNet50
100 100 100
High High High
Low Low Low
10−1 10−1 10−1
10−2 10−2 10−2
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
FalsePositiveRate FalsePositiveRate FalsePositiveRate
(d)ResNet18 (e)MobileNetV2 (f)ResNet50
100 100 100
High High High
Low Low Low
10−1 10−1 10−1
10−2 10−2 10−2
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
10−13
0−3 10−2 10−1 100
FalsePositiveRate FalsePositiveRate FalsePositiveRate
(g)ResNet18 (h)MobileNetV2 (i)ResNet50
Figure31:Log-scaleROCcurve:membershipinferenceattackbasedonthedistancetothedecisionboundary.Thefirstrowisresults
generatedusingℓ norm,thesecondrowisusingℓ norm,andthethirdrowisusingℓ norm.
1 2 ∞
24
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT
etaRevitisoPeurT