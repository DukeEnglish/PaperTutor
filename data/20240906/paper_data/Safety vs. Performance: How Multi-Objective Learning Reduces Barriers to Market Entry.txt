Safety vs. Performance: How Multi-Objective Learning Reduces
Barriers to Market Entry
Meena Jagadeesan, Michael I. Jordan, and Jacob Steinhardt
University of California, Berkeley
September 6, 2024
Abstract
Emerging marketplaces for large language models and other large-scale machine learning
(ML) models appear to exhibit market concentration, which has raised concerns about whether
there are insurmountable barriers to entry in such markets. In this work, we study this issue
from both an economic and an algorithmic point of view, focusing on a phenomenon that reduces
barriers to entry. Specifically, an incumbent company risks reputational damage unless its model
is sufficiently aligned with safety objectives, whereas a new company can more easily avoid
reputational damage. To study this issue formally, we define a multi-objective high-dimensional
regression framework that captures reputational damage, and we characterize the number of
data points that a new company needs to enter the market. Our results demonstrate how
multi-objective considerations can fundamentally reduce barriers to entry—the required number
of data points can be significantly smaller than the incumbent company’s dataset size. En
route to proving these results, we develop scaling laws for high-dimensional linear regression in
multi-objective environments, showing that the scaling rate becomes slower when the dataset
size is large, which could be of independent interest.
1 Introduction
Large language models and other large-scale machine learning (ML) models have led to an important
shift in the information technology landscape, one which has significant economic consequences.
Whereas earlier generations of ML models provided the underpinnings for platforms and services,
new models—such as language models—are themselves the service. This has led to new markets
where companies offer language models as their service and compete for user usage. As in other
markets, it is important to reason about market competitiveness: in particular, to what extent there
are barriers to entry for new companies.
A widespread concern about these markets is that new companies face insurmountable barriers
to entry that drive market concentration [Vipra and Korinek, 2023]. The typical argument is that
incumbent companies with high market share can purchase or capture significant amounts of data
and compute,1 and then invest these resources into the training of models that achieve even higher
performance [Kaplan et al., 2020]. This suggests that the company’s market share would further
increase, and that the scale and scope of this phenomenon would place incumbent companies beyond
the reach of new companies trying to enter the market. The scale is in fact massive—language
1Largecompaniescanaffordtheseresourcessincethemarketplaceisaneconomyofscale(i.e.,fixedcostsoftraining
significantly exceed per-query inference costs). They also generate high volumes of data from user interactions.
1
4202
peS
5
]GL.sc[
1v43730.9042:viXraassistants such as ChatGPT and Gemini each have hundreds of millions of users [Cook, 2024]. In
light of the concerns raised by policymakers [Vipra and Korinek, 2023] and regulators [The White
House, 2023, European Union, 2022b] regarding market concentration, it is important to investigate
the underlying economic and algorithmic mechanisms at play.
While standard arguments assume that market share is determined by model performance, the
reality is that the incumbent company risks reputational damage if their model violates safety-
oriented objectives. For example, incumbent companies face public and regulatory scrutiny for their
model’s safety violations—such as threatening behavior [Perrigo, 2023], jailbreaks [Wei et al., 2023],
and releasing dangerous information [The White House, 2023]—even when the model performs well
in terms of helpfulness and usefulness to users. In contrast, new companies face less regulatory
scrutiny since compliance requirements often prioritize models trained with more resources [The
White House, 2023, California Legislature, 2024], and new companies also may face less public
scrutiny given their smaller user bases.
In this work, we use a multi-objective learning framework to show that the threat of reputational
damage faced by the incumbent company can reduce barriers to entry. For the incumbent, the
possibility of reputational damage creates pressure to align with safety objectives in addition to
optimizing for performance. Safety and performance are not fully aligned, so improving safety can
reduce performance as a side effect. Meanwhile, the new company faces less of a risk of reputational
damage from safety violations. The new company can thus enter the marketplace with significantly
less data than the incumbent company, a phenomenon that our model and results formalize.
Model and results. We analyze a stylized marketplace based on multi-objective linear regression
(Section 2). The performance-optimal output and the safety-optimal output are specified by two
different linear functions of the input x. The marketplace consists of two companies: an incumbent
company and a new company attempting to enter the market. Each company receives their own
unlabelled training dataset, decides what fraction of training data points to label according to the
performance-optimal vs. safety-optimal outputs, and then runs ridge regression. The new company
requires a less stringent level of safety to avoid reputational damage than the incumbent company.
We characterize the market-entry threshold N∗ (Definition 1) which captures how much data the
E
new company needs to outperform the incumbent company.
First, as a warmup, we characterize N∗ when the new company faces no safety constraint and
E
the incumbent company has infinitely many data points (Section 3). Our key finding is that the new
company can enter the market with finite data, even when the incumbent company has infinite data
(Theorem 1; Figure 1). Specifically, we show that the threshold N∗ is finite; moreover, it is increasing
E
in the correlation (i.e., the alignment) between performance and safety, and it is decreasing in a
problem-specific scaling law exponent.
Next, we turn to more general environments where the incumbent has finite data N < ∞
I
(Section 4.2). We find that the threshold N∗ scales sublinearly with the incumbent’s dataset size N ,
E I
as long as N is sufficiently large. In fact, the threshold N∗ scales at a slower rate as N increases:
I E I
that is, N∗ = Θ(Nc) where the exponent c is decreasing in N (Theorem 4; Figure 3). For example,
E I I
for concrete parameter settings motivated by language models [Hoffmann et al., 2022], the exponent
c decreases from 1 to 0.75 to 0 as N increases. In general, the exponent c takes on up to three
I
different values depending on N , and is strictly smaller than 1 as long as N is sufficiently large.
I I
Finally, we turn to environments where the new company also faces a nontrivial safety constraint,
assuming for simplicity that the incumbent company again has infinite data (Section 4.3). We find
that N∗ is finite as long as the new company faces a strictly weaker safety constraint than the
E
incumbent. When the two safety thresholds are closer together, the new company needs more data
and in fact needs to scale up their dataset size at a faster rate: that is, N∗ = Θ(D−c), where D
E
2measures the difference between the safety thresholds and where the exponent c increases as D
decreases (Theorem 5; Figure 4). For the parameter settings in [Hoffmann et al., 2022], the exponent
c changes from −2.94 to −3.94 to an even larger value as D decreases. In general, the exponent c
takes on up to three different values.
Technical tool: Scaling laws. To prove our results, we derive scaling laws for multi-objective
high-dimensional linear regression, which could be of independent interest (Section 4.1; Figure 2).
We study optimally-regularized ridge regression where some of the training data is labelled according
to the primary linear objective (capturing performance) and the rest is labelled according to an
alternate linear objective (capturing safety).
We characterize data-scaling laws for both the loss along the primary objective and the excess
loss along the primary objective relative to an infinite-data ridgeless regression. Our scaling laws
quantify the rate at which the loss (Theorem 2; Figure 2a) and the excess loss (Theorem 3; Figure
2b) decay with the dataset size N, and how this rate is affected by the fraction of data labelled
according to each objective and other problem-specific quantities. Our analysis improves upon recent
works on scaling in multi-objective environments [e.g., Jain et al., 2024, Song et al., 2024] by allowing
for non-identity covariances and problem-specific regularization, which leads to new insights about
scaling laws as we describe below.
Our results reveal that the scaling rate becomes slower as the dataset size increases, illustrating
that multi-objective scaling laws behave qualitatively differently from classical single-objective
environments. While a typical scaling exponent in a single-objective environment takes on a single
value across all settings of N, the scaling exponent for multi-objective environments decreases as N
increases. In particular, the scaling exponent takes on three different values depending on the size of
N relative to problem-specific parameters. The intuition is that the regularizer must be carefully
tuned to N in order to avoid overfitting to training data labelled according to the alternate objective,
which in turn results in the scaling exponent being dependent on N (Section 5).
Discussion. Altogether, our work highlights the importance of looking beyond model performance
when evaluating market entry in machine learning marketplaces. Our results highlight a disconnect
between market entry in single-objective environments versus more realistic multi-objective envi-
ronments. More broadly, a company’s susceptibility to reputational damage affects how they train
their model to balance between different objectives. As we discuss in Section 6, these insights have
nuanced implications for regulators who wish to promote both market competitiveness and safety
compliance, and also generalize beyond language models to online platforms.
1.1 Related work
Our work connects to research threads on competition between model providers as well as scaling
laws and high-dimensional linear regression.
Competition between model providers. Our work contributes to an emerging line of work
studying how competing model providers strategically design their machine learning pipelines to
attract users. Model-provider actions range from choosing a function from a model class [Ben-Porat
and Tennenholtz, 2017, 2019, Jagadeesan et al., 2023b], to selecting a regularization parameter [Iyer
and Ke, 2022], to choosing an error distribution over user losses [Feng et al., 2019], to making data
purchasedecisions[Dongetal.,2019,Kwonetal.,2022], todecidingwhethertosharedata[Gradwohl
and Tennenholtz, 2023], to selecting a bandit algorithm [Aridor et al., 2020, Jagadeesan et al., 2023a].
While these works assume that model providers win users solely by maximizing (individual-level or
population-level) accuracy, our framework incorporates the role of safety violations in impacting
user retention implicitly via reputational damage. Moreover, our focus is on quantifying the barriers
3to market entry, rather than analyzing user welfare or the equilibrium decisions of model providers.
Other related work includes the study of competition between algorithms [Immorlica et al., 2011,
Kleinberg and Raghavan, 2021], retraining dynamics under user participation decisions [Hashimoto
et al., 2018, Ginart et al., 2021, Dean et al., 2022, Shekhtman and Dean, 2024, Su and Dean, 2024],
the bargaining game between a foundation model company and a specialist [Laufer et al., 2024], and
the market power of an algorithmic platform to shape user populations [Perdomo et al., 2020, Hardt
et al., 2022, Mendler-Dünner et al., 2024].
Our work also relates to platform competition [Jullien and Sand-Zantman, 2021, Calvano and
Polo, 2021], the emerging area of competition policy and regulation of digital marketplaces [Stigler
Committee, 2019, Vipra and Korinek, 2023, Cen et al., 2023, Competition and Markets Authority,
2024], the study of how antitrust policy impacts innovation in classical markets [Baker, 2007,
Segal and Whinston, 2007], and industrial organization more broadly [Tirole, 1988]. For example,
recent work examines how increased public scrutiny from inclusion in the S&P 500 can harm firm
performance [Bennett et al., 2023], how privacy regulation impacts firm competition [Gal and
Aviv, 2020, Fallah et al., 2024], how regulatory inspections affect incentives to comply with safety
constraints [Harrington, 1988, Fallah and Jordan, 2023], and how data-driven network effects can
reduce innovation [Prüfer and Schottmüller, 2021].
Scaling laws and high-dimensional linear regression. Ourworkalsocontributestoanemerging
line of work on scaling laws which study how model performance changes with training resources.
Empiricalstudieshavedemonstratedthatincreasestoscaleoftenreliablyimprovemodelperformance
[e.g., Kaplan et al., 2020, Hernandez et al., 2021, Hoffmann et al., 2022], but have also identified
settings where scaling behavior is more nuanced [e.g., Muennighoff et al., 2023, Gao et al., 2023].
We build on a recent mathematical characterization of scaling laws based on high-dimensional linear
regression [e.g., Hastie et al., 2019, Bordelon et al., 2020, Bahri et al., 2021, Cui et al., 2021,
Wei et al., 2022, Bach, 2023, Wei, 2024, Patil et al., 2024, Bordelon et al., 2024, Mallinar et al.,
2024, Lin et al., 2024, Atanasov et al., 2024]. However, while these works focus on single-objective
environments where all of the training data is labelled with outputs from a single predictor, we
consider multi-objective environments where some fraction of the training data is labelled according
to an alternate predictor.
We note that a handful of recent works similarly move beyond single-objective environments
and study scaling laws where the training data comes a mixture of different data sources. Jain
et al. [2024], Song et al. [2024] study high-dimensional ridge regression in a similar multi-objective
environment to our setup. However, these results assume an identity covariance and focus on fixed
regularization or no regularization. In contrast, we allow for richer covariance matrices that satisfy
natural power scaling (Section 2.3), and we analyze optimally tuned regularization. Our analysis
of these problem settings yields new insights about scaling behavior: for example, the scaling rate
becomes slower with dataset size (Theorems 2-3). Other related works study scaling laws under
mixtures of covariate distributions [Hashimoto, 2021], under data-quality heterogeneity [Goyal et al.,
2024], under data addition [Shen et al., 2024], under mixtures of AI-generated data and real data
[Dohmatob et al., 2024, Gerstgrasser et al., 2024], and with respect to the contribution of individual
data points [Covert et al., 2024].
More broadly, our work relates to collaborative learning [Blum et al., 2017, Mohri et al., 2019,
Sagawa et al., 2020, Haghtalab et al., 2022], federated learning [see Yang et al., 2019, for a survey],
optimizing data mixtures [e.g., Rolf et al., 2021, Xie et al., 2023], and adversarial robustness [e.g.,
Raghunathan et al., 2020]. Finally, our work relates to non-monotone scaling laws in strategic
environments [Jagadeesan et al., 2023a, Handina and Mazumdar, 2024], where increases to scale can
worsen equilibrium social welfare.
42 Model
We define our linear-regression-based marketplace (Section 2.1), justify the design choices of our
model (Section 2.2), and then delineate our statistical assumptions (Section 2.3).
2.1 Linear regression-based marketplace
We consider a marketplace where two companies fit linear regression models in a multi-objective
environment.
Linear regression model. To formalize each company’s machine learning pipeline, we consider
the multi-objective, high-dimensional linear regression model described below. This multi-objective
environment aims to capture how ML models are often trained to balance multiple objectives which
areintensionwitheachother, andweconsiderlinearregressionsinceithasoftenaccuratelypredicted
scaling trends of large-scale machine learning models (see Section 2.2 for additional discussion).
More concretely, given an input x ∈ RP, let ⟨β ,x⟩ be the output that targets performance
1
maximization,andlet⟨β ,x⟩betheoutputthattargetssafetymaximization. Givenalinearpredictor
2
β, the performance loss is evaluated via a population loss, L (β) = E [(⟨β ,x⟩−⟨β,x⟩)2], and
1 x∼DF 1
the safety violation is captured by a loss L (β) = E [(⟨β ,x⟩−⟨β,x⟩)2], where D is the input
2 x∼DF 2 F
distribution.
The model provider implicitly determines how to balance β and β when determining how to
1 2
label their training dataset. In particular, each model provider is given an unlabelled training dataset
X ∈ RN×P with N inputs drawn from D . To generate labels, they select the fraction α ∈ [0,1] of
F
training data to label according to each objective. They then sample a fraction α of the training data
uniformlyfromX andlabelitasY = ⟨β ,X ⟩;theremaining1−αfractionislabelledasY = ⟨β ,X ⟩.
i 1 i i 2 i
The model provider fits a ridge regression on the labelled training dataset with least-squares loss
(cid:16) (cid:17)
ℓ(y,y′) = (y−y′)2, and thus solves: βˆ(α,λ,X) = argmin 1 (cid:80)N (Y −⟨β,X ⟩)2+λ||β||2 .
β N i=1 i i 2
Marketplace. The marketplace contains two companies, an incumbent company I already in the
market and a new (entrant) company E trying to enter the market. At a high level, each company
C ∈ {I,E} faces reputational damage if their safety violation exceeds their safety constraint τ .
C
Each company company C is given N unlabelled data points sampled from D , and selects a
C F
mixture parameter α and regularizer λ to maximizetheir performance giventheir safety constraint
C C
τ . We assume that the incumbent company I faces a stricter safety constraint, τ < τ , due to
C I E
increased public or regulatory scrutiny (see Section 2.2 for additional discussion).
When formalizing how the model providers choose hyperparameters, we make the following
simplications. First, rather than work directly with the performance and safety losses of the ridge
regression estimator, we assume for analytic tractability that they approximate these losses by
L∗ := L∗(β ,β ,D ,λ,N,α) and L∗ := L∗(β ,β ,D ,α) defined as follows.
1 1 1 2 F 2 2 1 2 F
• Performance: WedefineL∗ tobeadeterministic equivalent Ldet(β ,β ,Σ,λ,N,α)whichwederive
1 1 1 2
in Lemma 6. The deterministic equivalent [cf. Hachem et al., 2007] is a tool from random matrix
theory that is closely linked to the Marčenko-Pastur law [Marčenko and Pastur, 1967]. Under
standard random matrix assumptions (Assumption 1), the deterministic equivalent asymptotically
approximates the loss L (βˆ(α,λ,X)) when X is constructed from N i.i.d. samples from D (see
1 F
Appendix D for additional discussion).
• Safety: Foranalyticsimplicity,inthemainbodyofthepaper,wedefineL∗ tobethesafetyviolation
2
of the infinite-data ridgeless regression estimator with mixture parameter α.2 In Appendix E, we
2Theinfinite-dataridgelessregressionestimatorisargmin (cid:0) α·E [⟨β−β ,x⟩2]+(1−α)·E [⟨β−β ,x⟩2](cid:1) .
β x∼DF 1 x∼DF 2
For this specification, the dataset size N and the regularization parameter λ only affect L∗ and not L∗, which
1 2
5instead define L∗ analogously to L∗—i.e., as a deterministic equivalent Ldet(β ,β ,D ,λ,N,α)—
2 1 2 1 2 F
and extend our model and results to this more complex setting.3
Second, we assume that (β ,β ) ∼ D for some joint distribution D and that the model providers
1 2 W W
take expectations when choosing hyperparameters, since it will be easier to specify assumptions in
Section 4.3 over distributions of predictors.
Within this setup, a company C faces reputational damage if the safety violation exceeds a
certain threshold:
E [L∗(β ,β ,D ,α )] > τ .
(β1,β2)∼DW 2 1 2 F C C
We assume that the safety thresholds for the two companies satisfy the following inequalities:
τ > τ ≥ E [L∗(β ,β ,D ,0.5)]. (1)
E (A) I (B) (β1,β2)∼DW 2 1 2 F
Here, inequality (A) captures the notion that the incumbent needs to achieve higher safety to avoid
reputational damage. Inequality (B) guarantees that both companies, C ∈ {I,E}, can set the
mixture parameter α ≥ 0.5 without facing reputational damage, and thus ensures that the safety
C
constraint does not dominate the company’s optimization task.4
The company selects α ∈ [0.5,1] and λ ∈ (0,1) to maximize their performance subject to their
safety constraint, as formalized by the following optimization program:5
(α ,λ ) = argmin E [L∗(β ,β ,D ,λ,N ,α)] s.t. E [L∗(β ,β ,D ,α)] ≤ τ .
C C α∈[0.5,1],λ∈(0,1) DW 1 1 2 F C DW 2 1 2 F C
Market-entry threshold. We define the market-entry threshold to capture the minimum number
of data points N that the new company needs to collect to achieve better performance than the
E
incumbent company while avoiding reputational damage.
Definition 1. The market-entry threshold N∗(N ,τ ,τ ,D ,D ) is the minimum value of N ∈
E I I E W F E
Z such that E [L∗(β ,β ,D ,λ ,N ,α )] ≤ E [L∗(β ,β ,D ,λ ,N ,α )].
≥1 DW 1 1 2 F E E E DW 1 1 2 F I I I
The goal of our work is to analyze the function N∗(N ,τ ,τ ,D ,D ).
E I I E W F
2.2 Model discussion
Now that we have formalized our statistical model, we discuss and justify our design choices in
greater detail. We defer a discussion of limitations to Section 6.
Presence of competing objectives. Our multi-objective formulation is motivated by how ML
models are often trained to balance multiple objectives which are in tension with each other. In
some cases, the pretraining objective is in tension with the finetuning objective [Wei et al., 2023].
For example, the fine-tuning of a language model to be more aligned with user intent can degrade
performance—e.g., because the model hedges too much—which creates an “alignment tax” [Ouyang
et al., 2022]. In other cases, fine-tuning approaches themselves balance multiple objectives such
as helpfulness (which can be mapped to performance in our model) and harmlessness (which can
be mapped to safety in our model) [Bai et al., 2022]. These objectives can be in tension with one
another, for example if the user asks for dangerous information.
simplifies our analysis in Sections 3-4 and enables us to obtain tight characterizations.
3We directly extend our results in Section 3, and we also show relaxed versions of our results in Section 4.
4More specifically, inequality (B) ensures that the safety constraint still allows both companies to label 50% of
their training data according to the performance-optimal outputs.
5Technically, the optimum might be achieved at λ=0 or λ=1, and the min should be replaced by a inf.
6High-dimensional linear regression as a statistical model. We focus on high-dimensional
linear regression due to its ability to capture scaling trends observed in large-scale machine learning
models such as language models, while still retaining analytic tractability. In particular, in single-
objective environments, scaling trends for high-dimensional linear regression recover the empirically
observed power-law scaling of the loss with respect to the dataset size [Kaplan et al., 2020, Cui
et al., 2021, Wei et al., 2022]. Moreover, from an analytic perspective, the structural properties of
high-dimensional linear regression make it possible to characterize the loss using random matrix
machinery (see Appendix D).
Impact of market position on model provider constraint τ. Our assumption that τ > τ
E I
(inequality (A) in (1)) is motivated by how large companies face greater reputational damage from
safety violations than smaller companies. One driver of this unevenness in reputational damage is
regulation: for example, recent regulation and policy [The White House, 2023, California Legislature,
2024] places stricter requirements on companies that use significant amounts of compute during
training. In particular, these companies face more stringent compliance requirements in terms of
safety assessments and post-deployment monitoring. Another driver of uneven reputational damage
is public perception: we expect that the public is more likely to uncover safety violations for large
companies, due to the large volume of user queries to the model. In contrast, for small companies,
safety violations may be undetected or subject to less public scrutiny.
2.3 Assumptions on linear regression problem
To simplify our characterization of scaling trends, we follow prior work on high-dimensional linear
regression [see, e.g., Cui et al., 2021, Wei et al., 2022] and make the following empirically motivated
power-law assumptions. Let Σ = E [xxT] be the covariance matrix, and let λ and v be the
x∼DF i i
eigenvalues and eigenvectors, respectively. We require the eigenvalues to decay with scaling exponent
γ > 0 according to λ = i−1−γ for 1 ≤ i ≤ P. For the alignment coefficients ⟨β ,v ⟩, it is cleaner to
i j i
enforce power scaling assumptions in expectation, so that we can more easily define a correlation
parameter. We require that for some δ > 0, the alignment coefficients satisfy E [⟨β ,v ⟩2] = i−δ,
DW j i
where v is the ith eigenvector of Σ, for j ∈ {1,2} and 1 ≤ i ≤ P. We also introduce a similar
i
condition on the joint alignment coefficients, requiring that for some ρ ∈ [0,1), it holds that
E [⟨β ,v ⟩⟨β ,v ⟩] = ρ·i−δ. Finally, we assume an overparameterized limit where the number
DW 1 i 2 i
of parameters P → ∞ approaches infinity. Below, we provide an example which satisfies these
assumptions.
Example 1. Suppose that the covariance Σ is a diagonal matrix with diagonal given by λ = i−1−γ.
i
Let the joint distribution over β and β be a multivariate Gaussian such that:
1 2

0 if 1 ≤ j ,j ≤ 2,1 ≤ i ̸= i ≤ P
 1 2 1 2

E [(β ) (β ) ] = i−δ if 1 ≤ j = j ≤ 2,1 ≤ i = i ≤ P
DW j1 i1 j2 i2 1 1 2 1 2

ρ·i−δ if 1 ≤ j ̸= j ≤ 2,1 ≤ i = i ≤ P.
1 1 2 1 2
This implies that E [⟨β ,v ⟩2] = i−δ and E [⟨β ,v ⟩⟨β ,v ⟩] = ρ·i−δ.
DW j i DW 1 i 2 i
We adopt the random matrix theory assumptions on the covariance matrix and linear predictors
from Bach [2023] (see Assumption 1 in Appendix D), which guarantee that the Marčenko-Pastur
law holds [Marčenko and Pastur, 1967]. That is, the covariance (Σˆ +λI)−1 of the samples can be
approximated by a deterministic quantity (see Appendix D.1 for a more detailed discussion). We
leverage this Marčenko-Pastur law to derive a deterministic equivalent Ldet for the performance loss
1
L (βˆ(α,λ,X)) of the ridge regression estimator (Lemma 6).
1
7Figure 1: Market-entry threshold N∗ as a function of the incumbent’s safety constraint τ , when
E I
the incumbent has infinite data and entrant has no safety constraint (Theorem 1). The plots show
varying values of the scaling exponent ν where the correlation parameter ρ = 0.5 is held fixed (left)
and varying values of ρ where ν = 0.34 is held fixed (right). The market-entry threshold N∗ is finite.
E
It is also higher when the constraint τ is weaker, when the correlation ρ is stronger, and when the
I
scaling exponent ν is lower.
3 Warm Up: Infinite-Data Incumbent and Unconstrained Entrant
As a warmup, we analyze the market entry N∗ threshold in a simplified environment where the
E
incumbent has infinite data and the new company faces no safety constraint. In this result, we place
standard power-law scaling assumptions on the covariance and alignment coefficients (Section 2.3)
and we characterize the threshold N∗ up to constants (Theorem 1; Figure 1).
E
Theorem 1. Suppose that power-law scaling holds for the eigenvalues and alignment coefficients,
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞.
Suppose that the incumbent company has infinite data (i.e., N = ∞), and that the entrant faces no
I
constraint on their safety (i.e., τ = ∞). Suppose that the safety constraint τ satisfies (1). Then, it
E I
holds that:6
(cid:18) (cid:19)
(cid:16)(cid:112) (cid:112) (cid:17)−2/ν
N∗(∞,τ ,∞,D ,D ) = Θ L∗(ρ)− min(τ ,L∗(ρ)) ,
E I W F I
where L∗(ρ) = E [(β −β )TΣ(β −β )] = Θ(1−ρ), and where ν := min(2(1+γ),δ+γ).
DW 1 2 1 2
The intuition is as follows. The safety constraint τ forces the incumbent company to partially
I
align their predictor with the safety objective β . Since β and β point in different directions, this
2 1 2
reduces the performance of the incumbent along β as a side effect, resulting in strictly positive loss
1
with respect to performance. On the other hand, since the new company faces no safety constraint,
the new company can optimize entirely for performance along β . This means that the new company
1
can enter the market as long as their finite data error is bounded by the incumbent’s performance
loss. We formalize this intuition in the following proof sketch.
Proof sketch of Theorem 1. The incumbent chooses the infinite-data ridgeless estimator β(α,0)
with mixture parameter α ∈ [0,1] tuned so the safety violation is τ (Lemma 11). The resulting
I
performancelossis(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ)). Sincethenewcompanyhasnosafetyconstraint, they
I
choose the single-objective ridge regression estimator where α = 1 and where λ is chosen optimally.7
Theorem 2 (or alternatively, existing analyses of high-dimensional linear regression [e.g., Cui et al.,
2021, Wei et al., 2022]) demonstrate the loss follows a scaling law of the form inf L (βˆ(1,λ,X)) =
λ>0 1
Θ(N−ν) where ν := min(2(1+γ),δ+γ). The full proof is in Appendix A.
6Throughout the paper, we allow Θ() and O() to hide implicit constant which depends on the scaling exponents
γ,δ.
7We formally rule out the possibility that α̸=1 using our multi-objective scaling law in Theorem 2.
8Theorem 1 reveals that the market-entry threshold is finite as long as (1) the safety constraint
τ places nontrivial restrictions on the incumbent company and (2) the safety and performance
I
objectives are not perfectly correlated. This result captures the notion that the new company can
enter the market even after the incumbent company has accumulated an infinite amount of data.
Theorem 1 further illustrates how the market-entry threshold changes with other parameters
(Figure 1). When safety and performance objectives are more correlated (i.e., when ρ is higher), the
market-entry threshold increases, which increases barriers to entry. When the safety constraint for
the incumbent is weaker (i.e., when τ is higher), the market-entry threshold also increases. Finally,
I
when the power scaling parameters of the covariance and alignment coefficients increase, which
increases the scaling law exponent ν, the market-entry threshold decreases.
4 Generalized Analysis of the Market-entry Threshold
To obtain a more fine-grained characterization of the market-entry threshold, we now consider
more general environments. Our key technical tool is multi-objective scaling laws, which capture
the performance of ridge regression in high-dimensional, multi-objective environments with finite
data (Section 4.1). Using these scaling laws, we characterize the market-entry threshold when the
incumbent has finite data (Section 4.2) and when the new company has a safety constraint (Section
4.3).
Our results in this section uncover the following conceptual insights about market entry. First,
our main finding from Section 3—that the new company can enter the market with significantly less
datathantheincumbent—appliestothesegeneralizedenvironments. Moreover, ourcharacterizations
of N∗ exhibit a power-law-like dependence with respect to the incumbent’s dataset size (Theorem
E
4) and the difference in safety requirement for the two companies (Theorem 5). Interestingly, the
scaling exponent c is not a constant across the full regime and instead takes on up to three different
values. As a consequence, the new company can afford to scale up their dataset at a slower rate as
the incumbent’s dataset size increases, but needs to scale up their dataset at a faster rate as the two
safety constraints become closer together. Proofs are deferred to Appendix B.
4.1 Technical tool: Scaling laws in multi-objective environments
In this section, we give an overview of multi-objective scaling laws (see Section 5 for a more formal
treatment and derivations). Our scaling laws capture how the ridge regression loss L (βˆ(α,λ,X))
1
along the primary objective β scales with the dataset size N, when the regularizer λ is optimally
1
tuned to both N and problem-specified parameters. We show scaling laws for both the loss
inf E[L (βˆ(α,λ,X))] and the excess loss inf (E[L (βˆ(α,λ,X)) − L (β(α,0))]) where
λ∈(0,1) 1 λ∈(0,1) 1 1
β(α,0) is the infinite-data ridgeless regression estimator.
Scaling law for the loss. Wefirstdescribethescalinglawforinf E[L (βˆ(α,λ,X))](Theorem
λ∈(0,1) 1
2; Figure 2a).
Theorem 2 (Informal Version of Corollary 8). Suppose that the power-law scaling assumptions
from Section 2.3 hold with exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1). Suppose also
that P = ∞ and α ≥ 0.5. Then, a deterministic equivalent for the expected loss under optimal
regularization inf E[L (βˆ(α,λ,X))] scales according to N−ν∗, where the scaling exponent ν∗ is
λ∈(0,1) 1
9(a) Scaling law for loss (up to constants) (b) Scaling law for excess loss (up to constants)
Figure 2: Data scaling laws for multi-objective environments where a fraction α = 0.9 of the data is
labelled according to the primary objective and a fraction 1−α = 0.1 is labelled according to the
secondary objective. The plots show, up to constants, the loss Θ(inf E[L (βˆ(α,λ,X))]) (left,
λ∈(0,1) 1
Theorem 2) and excess loss Θ(inf (E[L (βˆ(α,λ,X))−L (β(α,0))])) (right, Theorem 3) as a
λ∈(0,1) 1 1
function of the total number of training data points N. The loss and excess loss both take the form
N−c, but where the scaling exponent c takes on multiple (two or three) different values depending
on the size of N relative to other parameters. The scaling exponent is smaller when N is larger,
thus demonstrating that the scaling rate becomes slower as the dataset size N increases.
defined to be:
 ν if N ≤ (1−α)− ν1 (1−ρ)− ν1

ν∗ = ν if (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)−2+ νν (1−ρ)− ν1
ν+1
 0 if N ≥ (1−α)−2+ νν (1−ρ)− ν1 ,
for ν := min(2(1+γ),δ+γ).
Theorem 2 (Figure 2a) illustrates that the scaling rate becomes slower as the dataset size N
increases. In particular, while the scaling exponent in single-objective environments is captured by
a single value, Theorem 2 illustrates that the scaling exponent ν∗ in multi-objective environments
takes on three different values, depending on the size of N relative to other parameters. When N
is small (the first regime), the scaling exponent ν∗ = ν is identical to that of the single-objective
environment given by β . When N is a bit larger (the second regime), the scaling exponent reduces
1
to ν∗ = ν/(ν +1) < ν. To make this concrete, if we take ν = 0.34 to be an empirically estimated
scaling law exponent for language models [Hoffmann et al., 2022], this would mean that ν∗ ≈ 0.34 in
the first regime and ν∗ ≈ 0.25 in the second regime. Finally, when N is sufficiently large (the third
regime), the scaling exponent reduces all the way to ν∗ = 0 and the only benefit of additional data
is to improve constants on the loss.
Scaling law for the excess loss. We next turn to the excess loss, inf (E[L (βˆ(α,λ,X))−
λ∈(0,1) 1
L (β(α,0))]), which is normalized by the loss of the infinite-data ridgeless predictor β(α,0). We
1
show that the excess loss exhibits the same scaling behavior as the loss when N is sufficiently small,
but exhibits different behavior when N is sufficiently large (Theorem 3; Figure 2b).
Theorem 3 (Informal Version of Corollary 10). Suppose that the power-law scaling assumptions
from Section 2.3 hold with exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1). Suppose also
that P = ∞ and α ≥ 0.75. Then, a deterministic equivalent for the expected loss under optimal
regularization inf (E[L (βˆ(α,λ,X))−L (β(α,0))]) scales according to N−ν∗, where the scaling
λ∈(0,1) 1 1
10exponent ν∗ is defined to be:
 ν if N ≤ (1−α)− ν1 (1−ρ)− ν1

ν∗ =  ν if (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′
ν+1
   ν′ if N ≥ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′,
ν′+1
for ν := min(2(1+γ),δ+γ) and ν′ := min(1+γ,δ+γ).
Theorem 3 (Figure 2b) again shows that the scaling rate can become slower as the dataset size
N increases, and again reveals three regimes of scaling behavior. While the first two regimes of
Theorem 3 resemble the first two regimes of Theorem 2, the third regime of Theorem 3 (where
N ≥ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′) behaves differently. In this regime, the scaling exponent for the
excess loss is ν′ , rather than zero—this captures the fact that additional data can nontrivially
ν′+1
improve the excess loss even in this regime, even though it only improves the loss up to constants. In
terms of the magnitude of the scaling exponent ν′ , it is strictly smaller than the scaling exponent
ν′+1
ν when δ > 1 and equal to the scaling exponent ν when δ ≤ 1.
ν+1 ν+1
4.2 Finite data for the incumbent
We compute N∗ when the incumbent has finite data and the new company has no safety constraint
E
(Theorem 4; Figure 3). The market-entry threshold N∗ depends on the incumbent’s dataset size
E
N , the incumbent’s performance loss G if they were to have infinite data but face the same safety
I I
constraint, the scaling exponents γ,δ, and the correlation coefficient ρ.
Theorem 4. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞.
Assume that τ = ∞. Suppose that the safety constraint τ satisfies (1). Then we have that
E I
N∗ = N∗(N ,τ ,∞,D ,D ) satisfies:
E E I I W F

  Θ(cid:0) N I(cid:1) if N I ≤ G− I 21 ν(1−ρ)− 21 ν
 (cid:18) (cid:19)
N E∗ :=   Θ N Iν+1 1 ·G− I 2(ν1 +1)(1−ρ)− 2(ν1 +1) if G− I 21 ν(1−ρ)− 21 ν ≤ N I ≤ G− I 1 2− ν1 (1−ρ)1 2
 (cid:18) (cid:19)
    Θ G− I ν1 if N I ≥ G− I 1 2− ν1 (1−ρ)1 2,
where L∗(ρ) = E [(β −β )TΣ(β −β )] = Θ(1−ρ), where G := ((cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ)))2,
DW 1 2 1 2 I I
and where ν = min(2(1+γ),δ+γ).
The market-entry threshold in Theorem 4 exhibits three regimes of behavior depending on N .
I
In particular, the market-entry threshold takes the form N∗ = Θ(Nc) where c decreases from 1 (in
E I
the first regime) to 1 (in the second regime) to 0 (in the third regime) as N increases. To connect
ν+1 I
this to large-language-model marketplaces, we directly set ν = 0.34 to be the empirically estimated
scaling law exponent for language models [Hoffmann et al., 2022]; in this case, the scaling exponent c
ranges from 1 to 0.75 to 0. The fact that there are three regimes come from the scaling law derived
in Theorem 2, as the following proof sketch illustrates.
Proof sketch. The key technical tool is the scaling law for the loss inf E[L (βˆ(α,λ,X))] (The-
λ∈(0,1) 1
orem 2), which has three regimes of scaling behavior for different values of N. We apply the scaling
law to analyze the performance of the incumbent, who faces a safety constraint and has finite
11Figure 3: The market-entry threshold N∗ as a function of the incumbent dataset size N , when the
E I
new company has no safety constraint (Theorem 4). The plots show varying values of the scaling
exponent ν where the correlation parameter ρ = 0.5 is held fixed (left) and varying values of ρ
where ν = 0.34 is held fixed (right). When N is sufficiently large, the market-entry threshold N∗ is
I E
asymptotically less than N (i.e., below the dotted black line). Each curve is the union of three line
I
segments with slope decreasing in N , demonstrating that the new company can afford to scale up
I
their dataset at a slower rate as N increases.
I
data. Analyzing the performance of the new company—who faces no safety constraint—is more
straightforward, given that the new company can set α = 1. We compute N∗ as the number
E E
of data points needed to match the incumbent’s performance level. The full proof is deferred to
Appendix B.1.
Theorem 4 reveals that the new company can enter the market with N∗ = o(N ) data, as long
E I
as the incumbent’s dataset is sufficiently large (i.e., N
I
≥ G−
I
21 ν(1−ρ)− 21 ν). The intuition is when
there is sufficient data, the multi-objective scaling exponent is worse than the single-objective scaling
exponent (Theorem 2). The incumbent thus faces a worse scaling exponent than the new company,
so the new company can enter the market with asymptotically less data.
The three regimes in Theorem 4 further reveal that the market-entry threshold N∗ scales at
E
a slower rate as the incumbent’s dataset size N increases (Figure 3). The intuition is that the
I
multi-objective scaling exponent ν∗ faced by the incumbent decreases as dataset size increases, while
the single-objective scaling exponent faced by the new company is constant in dataset size (Theorem
2). The incumbent thus becomes less efficient at using additional data to improve performance,
while the new company’s efficiency in using additional data remains unchanged.
Theorem 4 also offers finer-grained insight into the market-entry threshold in each regime. In
the first regime, where the incumbent’s dataset is small, the threshold N∗ matches the incumbent
E
dataset size—the new company does not benefit from having a less stringent safety constraint. In
the second (intermediate) regime, the new company can enter with a dataset size proportional
to N1/(ν+1). This polynomial speedup illustrates that the new company can more efficiently use
I
additional data to improve performance than the incumbent company. A caveat is that this regime
is somewhat restricted in that the ratio of the upper and lower boundaries is bounded. In the third
regime, where the incumbent’s dataset size is large, the market-entry threshold N∗ matches the
E
market-entry threshold from Theorem 1 where the incumbent has infinite data.
4.3 Safety constraint for the new company
We compute N∗ when the new company has a nontrivial safety constraint and the incumbent has
E
infinite data. For this result, we strengthen the conditions on τ and τ from (1), instead requiring:
E I
τ > τ ≥ E [L∗(β ,β ,D ,0.75)], (2)
E (A) I (B) (β1,β2)∼DW 2 1 2 F
12Figure 4: The market-entry threshold N∗ as a function of the difference D between the infinite-data
E
performancelossoftheincumbentandnewcompany, whentheincumbenthasinfinitedata(Theorem
5). The plots show varying values of the scaling exponent δ where the correlation parameter ρ = 0.49
is held fixed (left) and varying values of ρ where δ = 2.5 is held fixed (right). The plots are shown
in log space. The market-entry threshold is finite in all cases. Each curve is the union of multiple
line segments with slope increasing in magnitude as logD decreases, demonstrating that the new
company needs to scale up their dataset at a faster rate as D decreases.
where (2) replaces the 0.5 with a 0.75 in the right-most quantity.8
We state the result below (Theorem 5; Figure 4). The market-entry threshold N∗ depends on
E
the incumbent’s safety constraint τ , the performance loss G (resp. G ) if the incumbent (resp.
I I E
new company) had infinite data and faced the same safety constraint, the difference D = G −G in
I E
infinite-data performance loss achievable by the incumbent and new company, the scaling exponents
γ,δ, and the correlation coefficient ρ.
Theorem 5. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
withscalingexponentsγ,δ > 0andcorrelationcoefficientρ ∈ [0,1), andsupposethatP = ∞. Suppose
that the safety constraints τ and τ satisfy (2). Then it holds that N∗ = N∗(∞,τ ,τ ,D ,D )
I E E E I E W F
satisfies:

  Θ(D− ν1 ) if D ≥ G E1 2(1−ρ)1 2
N E∗ :=
   Θ(cid:18) D−ν+ ν1
G
E1 2(1−ρ)1 2(cid:19)
if G
E2(ν−ν ν′)(1−ρ)2(ν−ν
ν′) ≤ D ≤ G
E21 (1−ρ)1
2
     Θ(cid:18) (cid:0) D·G E− 21 (1−ρ)−1 2(cid:1)−ν′ ν+ ′1(cid:19) if D ≤ G E2(ν−ν ν′)(1−ρ)2(ν−ν ν′),
where L∗(ρ) = E [(β −β )TΣ(β −β)] = Θ(1−ρ), where ν = min(2(1+γ),δ+γ) and ν′ = min(1+
DW 1 2 1
(cid:16)(cid:112) (cid:112) (cid:17)2 (cid:16)(cid:112) (cid:112) (cid:17)2
γ,δ+γ), where G := L∗(ρ)− min(τ ,L∗(ρ)) and G := L∗(ρ)− min(τ ,L∗(ρ)) ,
I I E E
and where D := G −G .
I E
The market-entry threshold in Theorem 5 also exhibits three regimes of behavior depending
on the difference D in the infinite-data performance loss achievable by the incumbent and new
company. In particular, the market-entry threshold takes the form N∗ = Θ(D−c) where c increases
E
from 1 to ν+1 to ν′+1 as D decreases. (The third regime only exists when δ > 1.) To connect this
ν ν ν′
to large-language-model marketplaces, if we take ν = 0.34 to be the empirically estimated scaling
law exponent for language models [Hoffmann et al., 2022], then c would range from 2.94 to 3.94 to
8Inequality (B) in (2) requires that the safety constraint still allows both company to label 75% of their training
data according to performance-optimal outputs. We make this modification, since our analysis of multi-objective
scaling laws for the excess loss assumes α≥0.75 (see Section 5.3).
13potentially even larger. The fact that there are three regimes come from the scaling law derived in
Theorem 3, as the following proof sketch illustrates.
Proof sketch. Thekeytechnicaltoolisthescalinglawfortheexcess loss inf (E[L (βˆ(α,λ,X))−
λ∈(0,1) 1
L (β(α,0))]) (Theorem 3), which has three regimes of scaling behavior for different values of N. We
1
apply the scaling law to analyze the performance of the new company, who faces a safety constraint
and has finite data. Analyzing the performance of the incumbent—who has infinite data—is more
straightforward, and the incumbent’s performance loss is G = D+G . We compute the number
I E
of data points N∗ needed for the new company to achieve an excess loss of D. The full proof is
E
deferred to Appendix B.2.
Theorem 5 illustrates that the new company can enter the market with finite data N∗, as long
E
as the safety constraint τ placed on the new company is strictly weaker than the constraint τ
E I
placed on the incumbent company (inequality (A) in (2)). This translates to the difference D being
strictly positive. The intuition is that when the new company faces a weaker safety constraint, it can
train on a greater number of data points labelled with the performance objective β , which improves
1
performance.
The three regimes in Theorem 5 further reveal that the market-entry threshold N∗ scales at a
E
faster rate as the difference D between the two safety constraints decreases (Figure 3). The intuition
is since the new company needs to achieve an excess loss of at most D, the new company faces a
smaller multi-objective scaling exponent ν∗ as D decreases (Theorem 3). The new company thus
becomes less efficient at using additional data to improve performance.
5 Deriving Scaling Laws for Multi-Objective Environments
We formalize and derive our multi-objective scaling laws for the loss (Theorem 2) and excess loss
(Theorem 3). Recall that the problem setting is high-dimensional ridge regression when a fraction α
of the training data is labelled according to β and the rest is labelled according to an alternate
1
objective β . First, following the style of analysis of single-objective ridge regression [e.g., Cui et al.,
2
2021, Wei et al., 2022], we first compute a deterministic equivalent of the loss (Section 5.1). Then
we derive the scaling law under the power scaling assumptions on the eigenvalues and alignment
coefficients in Section 2.3, both for the loss (Section 5.2) and for the excess loss (Section 5.3). Proofs
are deferred to Appendix C.
5.1 Deterministic equivalent
We show that the loss of the ridge regression estimator can be approximated as a deterministic
quantity. This analysis builds on the random matrix tools in Bach [2023] (see Appendix D). Note
that our derivation of the deterministic equivalent does not place the power scaling assumptions
on the eigenvalues or alignment coefficients; in fact, it holds for any linear regression setup which
satisfies a standard random matrix theory assumption (Assumption 1).
We compute the following deterministic equivalent (proof deferred to Appendix C.5).9
Lemma 6. Suppose that N ≥ 1, P ≥ 1, D , β , and β satisfy Assumption 1. Let Σ be the
F 1 2
covariance matrix of D , and let α ∈ [0,1] and λ ∈ (0,1) be general parameters. Let Σ = (Σ+cI)
F c
9FollowingBach[2023],theasymptoticequivalencenotationu∼v meansthatu/v tendsto1asN andP goto∞.
14for c ≥ 0, let Bsn = β βT, let Bdf = (β − β )(β − β )T, and let Bmx = (β − β )βT. Let
1 1 1 2 1 2 1 2 1
κ = κ(λ,N,Σ) from Definition 2. Then, it holds that
T +T +T +T +T
L (βˆ(α,λ,X)) ∼ Ldet(β ,β ,D ,λ,N,α) =: 1 2 3 4 5 ,
1 1 1 2 F Q
where:
T := κ2·Tr(ΣΣ−2Bsn), T := (1−α)2(cid:0) Tr(cid:0) Σ−2Σ3Bdf(cid:1)(cid:1)
1 κ 2 κ
T :=
2(1−α)κ·Tr(cid:0) Σ−2Σ2Bmx(cid:1)
, T := −2(1−α)κ
1 Tr(Σ2Σ−2)·Tr(cid:0) Σ−1ΣBmx(cid:1)
,
3 κ 4 N κ κ
T := (1−α) 1 Tr(Σ2Σ−2)·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2(1−α)Tr(cid:0) Σ−1Σ2Bdf(cid:1)(cid:1) , Q := 1− 1 Tr(Σ2Σ−2).
5 N κ κ N κ
Lemma6showsthatthelosscanbeapproximatedbyadeterministicquantityLdet(β ,β ,D ,λ,N,α)
1 1 2 F
which is sum of five terms, normalized by the standard degrees of freedom correction Q−1 [Bach,
2023]. The sum T +T +T is the loss of infinite-data ridge regression with regularizer κ. Terms T
1 2 3 4
and T capture additional error terms.
5
In more detail, term T /Q captures the standard single-objective environment error for N data
1
points [Bach, 2023]: i.e., the population error of the single-objective linear regression problem with
regularizer λ where all of the N training data points are labelled with β . Term T is similar to
i 2
the infinite-data ridgeless regression error but is slightly smaller due to regularization. Term T is
3
a cross term which is upper bounded by the geometric mean of term T and term T . Term T is
1 2 4
another cross term which is subsumed by the other terms. Term T captures an overfitting error
5
which increases with the regularizer κ and decreases with the amount of data N.
From deterministic equivalents to scaling laws. In the following two subsections, using the
deterministic equivalent from Lemma 6, we derive scaling laws. We make use of the the power
scaling assumptions on the covariance and alignment coefficients described in Section 5.2, under
which the deterministic equivalent takes a cleaner form (Lemma 26 in Appendix C). We note that
strictly speaking, deriving scaling laws requires controlling the error of the deterministic equivalent
relative to the actual loss; for simplicity, we do not control errors and instead directly analyze the
deterministic equivalent.
5.2 Scaling law for the loss
We derive scaling laws for the loss Ldet := Ldet(β ,β ,D ,λ,N,α). We first prove the following
1 1 1 2 F
scaling law for a general regularizer λ (proof deferred to Appendix C.7).
Theorem 7. Suppose that the power-law scaling assumption holds for the eigenvalues and alignment
coefficients with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞.
Assume that α ≥ 0.5 and λ ∈ (0,1). Let Ldet := Ldet(β ,β ,D ,λ,N,α) be the deterministic
1 1 1 2 F
equivalent from Lemma 6. Let ν := min(2(1+γ),δ+γ). Then, the expected loss satisfies:
 
 (cid:32) − 1 (cid:33) 
E DW[Ld 1et] = Θ  max(λ1+ν γ,N−ν)+(1−α)2·(1−ρ)+(1−α) min(λ N1+γ,N) (1−ρ)  .
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
 
finite data error mixture error (cid:124) (cid:123)(cid:122) (cid:125)
overfitting error
15Theorem 7 illustrates that the loss is the sum of a finite data error, an overfitting error, and a
mixture error. The finite data error for Ldet matches the loss in the single-objective environment
1
for N data points labelled with objective β . The mixture error equals the loss of the infinite-data
1
ridgeless regression predictor β(α,0). The overfitting error for Ldet equals the error incurred when
1
the regularizer λ is too small. This term is always at most (1−α)−1 times larger than the mixture
error, and it is smaller than the mixture error when λ is sufficiently large relative to N.
Due to the overfitting error, the optimal loss is not necessarily achieved by taking λ → 0 for
multi-objective linear regression. In fact, if the regularizer decays too quickly as a function of
N (i.e., if λ = O(N−1−γ)), then the error would converge to (1−α)(1−ρ), which is a factor of
(1−α)−1 higher than the error of the infinite-data ridgeless predictor β(α,0). The fact that λ → 0
is suboptimal reveals a sharp disconnect between the multi-objective setting and the single-objective
setting where no explicit regularization is necessary to achieve the optimal loss [see, e.g., Cui et al.,
2021, Wei et al., 2022].10
In the next result, we compute the optimal regularizer and derive a scaling law under optimal
regularization as a corollary of Theorem 7.
Corollary 8 (Formal version of Theorem 2). Consider the setup of Theorem 7. Then, the loss under
optimal regularization can be expressed as:

Θ(N−ν) if N ≤ (1−α)− ν1 (1−ρ)− ν1

  (cid:18) (cid:16) (cid:17)− ν (cid:19)
inf E DW[Ld 1et] = Θ (1−αN
)(1−ρ)
ν+1 if (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)−2+ νν (1−ρ)− ν1
λ∈(0,1) 

 Θ((1−α)2(1−ρ)) if N ≥ (1−α)−2+ νν (1−ρ)− ν1 ,
where ν := min(2(1+γ),δ+γ).
The scaling law exponent ν∗ ranges from ν, to ν/(ν+1), to 0 (Figure 2a). To better understand
each regime, we provide intuition for when error term from Theorem 7 dominates, the form of the
optimal regularizer, and the behavior of the loss.
• Regime 1: N ≤ (1−α)− ν1 (1−ρ)− ν1 . Since N is small, the finite data error dominates regardless of
λ. As a result, like in a single-objective environment, taking λ = O(N−1−γ) recovers the optimal
loss up to constants. Note that the loss thus behaves as if all N data points were labelled according
to β : the learner benefits from all of the data, not just the data is labelled according to β .
i i
• Regime 2: (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)−2+ νν (1−ρ)− ν1 . In this regime, the finite error term
(cid:18)
(cid:16)
(cid:17)1+γ(cid:19)
and overfitting error dominate. Taking λ = Θ (1−α)(1−ρ) ν+1 , which equalizes the two error
N
terms, recovers the optimal loss up to constants. The loss in this regime improves with N, but at
a slower rate than in a single-objective environment.
• Regime 3: N ≥ (1−α)−2+ νν (1−ρ)− ν1 . Since N is large, the mixture and the overfitting error
terms dominate. Taking λ = Θ((N(1−α))−1−γ), which equalizes the two error terms, recovers
the optimal loss up to constants. The loss behaves (up to the constants) as if there were infinitely
many data points from the mixture distribution with weight α. This is the minimal possible loss
and there is thus no additional benefit for data beyond improving constants.
The full proof of Corollary 8 is deferred to Appendix C.8.
10Temperedoverfitting[Mallinaretal.,2022]cansimilarlyoccurinsingle-objectivesettingswithnoisy observations.
In this sense, labelling some of the data with the alternate objective β behaves qualitatively similarly to noisy
2
observations.
165.3 Scaling law for the excess loss
Now, we turn to scaling laws for the excess loss E [Ldet(β ,β ,D ,λ,N,α)−L (β(α,0))], , which
DW 1 1 2 F 1
is normalized by the loss of the infinite-data ridgeless predictor β(α,0). We first prove the following
scaling law for a general regularizer λ, assuming that α ≥ 0.75 (proof deferred to Appendix C.9).11
Theorem 9. Suppose that the power-law scaling assumption holds for the eigenvalues and alignment
coefficients with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞.
Assume that α ≥ 0.75 and λ ∈ (0,1). Let Ldet := Ldet(β ,β ,D ,λ,N,α) be the deterministic
1 1 1 2 F
equivalent from Lemma 6. Let ν := min(2(1+γ),δ+γ) and let ν′ = min(1+γ,δ+γ) Then, the
expected loss satisfies:
E [Ldet−L (β(α,0))]
DW 1 1
 
 (cid:32) − 1 (cid:33) 
=
Θ max(λ1+ν γ,N−ν)+(1−ρ)(1−α)max(λ1ν +′ γ,N−ν′
)+(1−α)
min(λ 1+γ,N) (1−ρ)
.
 N 
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
 
finite data error mixture finite data error (cid:124) (cid:123)(cid:122) (cid:125)
overfitting error
Theorem 9 illustrates that the loss is the sum of a finite data error, an overfitting error, and a
mixture finite data error. In comparison with Theorem 7, the difference is that the mixture error
is replaced by the mixture finite data error. Interestingly, the mixture finite data error exhibits a
different asymptotic dependence with respect to λ and N than the finite data error: the asymptotic
rate of decay scales with ν′ rather than ν. In fact, the rate is slower for the mixture finite data error
than the finite data error as long as δ > 1 (since this means that ν′ < ν).
Since the optimal excess loss is also not necessarily achieved by taking λ → 0, we compute the
optimal regularizer for the excess loss and derive a scaling law under optimal regularization as a
corollary of Theorem 9.
Corollary 10 (Formal version of Theorem 3). Consider the setup of Theorem 9. The excess loss
under optimal regularization can be expressed as:
inf (E [Ldet−L (β(α,0))])
DW 1 1
λ∈(0,1)
 Θ(N−ν) if N ≤ (1−α)− ν1 (1−ρ)− ν1
=
    Θ(cid:18) (cid:16) (1−αN )(1−ρ)(cid:17)− ν+ν 1(cid:19) if (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′
 

(cid:18)
−
ν′ (cid:19) −ν′+1 −ν′+1
 Θ (1−α)(1−ρ)N ν′+1 if N ≥ (1−α) ν−ν′(1−ρ) ν−ν′,
where ν := min(2(1+γ),δ+γ) and ν′ = min(1+γ,δ+γ).
The scaling law exponent ν∗ ranges from ν, to ν/(ν +1), to ν′/(ν′+1) (Figure 2b). The first
two regimes behave similarly to Corollary 8, and the key difference arises in the third regime (when
N is large). In the third regime (N ≥ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′), the mixture finite data error and
the overfitting error terms dominate. Taking λ = Θ(cid:16) N− ν1 ′+ +γ 1(cid:17) —which equalizes these two error
terms—recovers the optimal loss up to constants. The resulting scaling behavior captures that in
this regime, additional data meaningfully improves the excess loss, even though additional data only
improves the loss in terms of constants. The full proof of Corollary 10 is deferred to Appendix C.10.
11The assumption that α≥0.75 simplifies the closed-form expression for the deterministic equivalent of the excess
loss in Lemma 26. We defer a broader characterization of scaling laws for the excess loss to future work.
176 Discussion
Westudiedmarketentryinmarketplacesformachinelearningmodels,showingthatpressuretosatisfy
safety constraints can reduce barriers to entry for new companies. We modelled the marketplace
using a high-dimensional multi-objective linear regression model. Our key finding was that a new
company can consistently enter the marketplace with significantly less data than the incumbent. En
route to proving these results, we derive scaling laws for multi-objective regression, showing that the
scaling rate becomes slower when the dataset size is large.
Potential implications for regulation. Our results have nuanced design consequences for
regulators, who implicitly influence the level of safety that each company needs to achieve to avoid
reputational damage. On one hand, our results suggest that placing greater scrutiny on dominant
companiescanencouragemarketentryandcreateamorecompetitivemarketplaceofmodelproviders.
On the other hand, market entry does come at a cost to the safety objective: the smaller companies
exploit that they can incur more safety violations while maintaining their reputation, which leads to
a race to the bottom for safety. Examining the tradeoffs between market competitiveness and safety
compliance is an important direction for future work.
Barriers to market entry for online platforms. While we focused on language models, we
expect that our conceptual findings about market entry also extend to recommendation and social
media platforms.
In particular, our motivation and modeling assumptions capture key aspects of these online
platforms. Policymakershaveraisedconcernshavebeenraisedaboutbarrierstoentryforsocialmedia
platforms [Stigler Committee, 2019], motivated by the fact that social media platforms such as X and
Facebook each have over a half billion users [Statista, 2024, Ingram, 2024]. Incumbent companies
risk reputational damage if their model violates safety-oriented objectives—many recommendation
platforms have faced scrutiny for promoting hate speech [European Union, 2022a], divisive content
[Rathje et al., 2021], and excessive use by users [Hasan et al., 2018], even when recommendations
perform well in terms of generating user engagement. This means that incumbent platforms must
balance optimizing engagement with controlling negative societal impacts [Bengani et al., 2022].
Moreover, new companies face less regulatory scrutiny, given that some regulations explicitly place
more stringent requirements on companies with large user bases: for example the Digital Services
Act [European Union, 2022a] places a greater responsibility on Very Large Online Platforms (with
over 45 million users per month) to identify and remove illegal or harmful content.
Given that incumbent platforms similarly face more pressure to satisfy safety-oriented objectives,
our results suggest that multi-objective learning can also reduce barriers to entry for new online
platforms.
Limitations. Our model for interactions between companies and users makes several simplifying
assumptions. Forexample, wefocusedentirelywhetherthenewcompanycanenterthemarket, which
leaves open the question of whether the new company can survive in the long run. Moreover, we
assumedthatalluserschoosethemodelwiththehighestoverallperformance. However,differentusers
often care about performance on different queries; this could create an incentive for specialization,
which could also reduce barriers to entry and market concentration. Finally, we focused on direct
interactions between model providers and users, but in reality, downstream providers sometimes
build services on top of a foundation model. Understanding how these market complexities affect
market entry as well as long-term concentration is an interesting direction for future work.
Furthermore, our model also made the simplifying assumption that performance and safety trade
off according to a multi-objective regression problem. However, not all safety objectives fit the
18mold of linear coefficients within linear regression. For some safety objectives such as privacy, we
still expect that placing greater scrutiny on dominant companies could similarly reduce barriers to
entry. Nonetheless, for other safety or societal considerations, we do expect that the implications for
market entry might be fundamentally different. For example, if the safety objective is a multi-group
performance criteria, and there is a single predictor that achieves zero accuracy on all distributions,
then a dominant company with infinite data would be able to retain all users even if the company
faces greater scrutiny. Extending our model to capture a broader scope of safety objectives is a
natural direction for future work.
7 Acknowledgments
We thank Alireza Fallah, Jiahai Feng, Nika Haghtalab, Andy Haupt, Erik Jones, Jon Kleinberg, Ben
Laufer, Neil Mallinar, Judy Shen, Alex Wei, Xuelin Yang, and Eric Zhao for useful feedback on this
project. This work was partially supported by an Open Philanthropy AI fellowship and partially
supported by the European Union (ERC-2022-SYG-OCEAN-101071601).
References
Guy Aridor, Yishay Mansour, Aleksandrs Slivkins, and Zhiwei Steven Wu. Competing bandits: The
perils of exploration under competition. CoRR, abs/2007.10144, 2020.
Alexander B. Atanasov, Jacob A. Zavatone-Veth, and Cengiz Pehlevan. Scaling and renormalization
in high-dimensional regression. CoRR, abs/2405.00592, 2024.
Francis R. Bach. High-dimensional analysis of double descent for linear regression with random
projections. CoRR, abs/2303.01372, 2023.
Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, and Utkarsh Sharma. Explaining neural
scaling laws. CoRR, abs/2102.06701, 2021.
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn
Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson
Kernion, Tom Conerly, Sheer El Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez,
Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson,
Dario Amodei, Tom B. Brown, Jack Clark, Sam McCandlish, Chris Olah, Benjamin Mann, and
Jared Kaplan. Training a helpful and harmless assistant with reinforcement learning from human
feedback. CoRR, abs/2204.05862, 2022.
Jonathan B. Baker. Beyond Schumpeter vs. Arrow: How antitrust fosters innovation. Antitrust Law
Journal, 74(3):575–602, 2007.
OmerBen-PoratandMosheTennenholtz.Bestresponseregression.InAdvancesinNeuralInformation
Processing Systems 30: Annual Conference on Neural Information Processing Systems (NIPS),
pages 1499–1508, 2017.
Omer Ben-Porat and Moshe Tennenholtz. Regression equilibrium. In Proceedings of the 2019 ACM
Conference on Economics and Computation (EC), pages 173–191. ACM, 2019.
19Priyanjana Bengani, Jonathan Stray, and Luke Thorburn. What’s right
and what’s wrong with optimizing for engagement. Understanding Recom-
menders, Apr 2022. URL https://medium.com/understanding-recommenders/
whats-right-and-what-s-wrong-with-optimizing-for-engagement-5abaac021851.
Benjamin Bennett, Rene M. Stulz, and Zexi Wang. Does greater public scrutiny hurt a firm’s
performance? Available at SSRN: https://ssrn.com/abstract=4321191, 2023.
Avrim Blum, Nika Haghtalab, Ariel D. Procaccia, and Mingda Qiao. Collaborative PAC learning. In
Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information
Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 2392–2401, 2017.
Blake Bordelon, Abdulkadir Canatar, and Cengiz Pehlevan. Spectrum dependent learning curves in
kernel regression and wide neural networks. In Proceedings of the 37th International Conference
on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of
Machine Learning Research, pages 1024–1034. PMLR, 2020.
Blake Bordelon, Alexander B. Atanasov, and Cengiz Pehlevan. A dynamical model of neural scaling
laws. CoRR, abs/2402.01092, 2024.
California Legislature. California senate bill no. 1047 (2023-2024). https://leginfo.legislature.
ca.gov/faces/billTextClient.xhtml?bill_id=202320240SB1047, 2024.
Emilio Calvano and Michele Polo. Market power, competition and innovation in digital markets: A
survey. Information Economics and Policy, 54:100853, 2021.
Sarah Huiyi Cen, Aspen Hopkins, Andrew Ilyas, Aleksander Madry, Isabella Struckman, and Luis
Videgaray Caso. AI supply chains. Available at SSRN: https://ssrn.com/abstract=4789403, 2023.
Competition and Markets Authority. AI foundation models: Technical update report. Technical
report, UK Government, 2024. URL https://assets.publishing.service.gov.uk/media/
661e5a4c7469198185bd3d62/AI_Foundation_Models_technical_update_report.pdf.
Jodie Cook. ChatGPT, Claude, Gemini or another: The AI tool entrepreneurs
prefer. Forbes, 2024. URL https://www.forbes.com/sites/jodiecook/2024/05/07/
chatgpt-claude-gemini-or-another-the-ai-tool-entrepreneurs-prefer/.
IanCovert, WenlongJi, TatsunoriHashimoto, andJamesZou. Scalinglawsforthevalueofindividual
data points in machine learning. CoRR, abs/2405.20456, 2024.
Hugo Cui, Bruno Loureiro, Florent Krzakala, and Lenka Zdeborová. Generalization error rates
in kernel regression: The crossover from the noiseless to noisy regime. In Advances in Neural
Information Processing Systems 34: Annual Conference on Neural Information Processing Systems
2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 10131–10143, 2021.
Sarah Dean, Mihaela Curmei, Lillian J. Ratliff, Jamie Morgenstern, and Maryam Fazel. Multi-learner
risk reduction under endogenous participation dynamics. CoRR, abs/2206.02667, 2022.
Elvis Dohmatob, Yunzhen Feng, Pu Yang, François Charton, and Julia Kempe. A tale of tails:
Model collapse as a change of scaling laws. CoRR, abs/2402.07043, 2024.
20JinshuoDong,HadiElzayn,ShahinJabbari,MichaelJ.Kearns,andZacharySchutzman. Equilibrium
characterization for data acquisition games. In Sarit Kraus, editor, Proceedings of the Twenty-
Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China,
August 10-16, 2019, pages 252–258. ijcai.org, 2019.
European Union. Regulation (EU) 2022/2065 of the European Parliament and of the Council of 19
October 2022 on a single market for digital services and Amending Directive 2000/31/EC (Digital
Services Act). Official Journal of the European Union, 2022a. URL https://eur-lex.europa.
eu/legal-content/EN/TXT/?uri=celex%3A32022R2065.
European Union. Regulation (EU) 2022/1925 of the European parliament and of the Council
of 14 September 2022 on contestable and fair markets in the digital sector and Amending
Directives (EU) 2019/1937 and (EU) 2020/1828 (Digital Markets Act), 2022b. URL https:
//eur-lex.europa.eu/eli/reg/2022/1925/oj.
AlirezaFallahandMichaelI.Jordan. Contractdesignwithsafetyinspections. CoRR,abs/2311.02537,
2023.
Alireza Fallah, Michael I. Jordan, Ali Makhdoumi, and Azarakhsh Malekian. On three-layer data
markets. CoRR, abs/2402.09697, 2024.
Yiding Feng, Ronen Gradwohl, Jason D. Hartline, Aleck C. Johnsen, and Denis Nekipelov. Bias-
variance games. CoRR, abs/1909.03618, 2019.
Michal S Gal and Oshrit Aviv. The competitive effects of the gdpr. Journal of Competition Law &
Economics, 16(3):349–391, 05 2020.
Leo Gao, John Schulman, and Jacob Hilton. Scaling laws for reward model overoptimization. In
International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii,
USA, volume 202 of Proceedings of Machine Learning Research, pages 10835–10866. PMLR, 2023.
Matthias Gerstgrasser, Rylan Schaeffer, Apratim Dey, Rafael Rafailov, Henry Sleight, John Hughes,
Tomasz Korbak, Rajashree Agrawal, Dhruv Pai, Andrey Gromov, Daniel A. Roberts, Diyi Yang,
David L. Donoho, and Sanmi Koyejo. Is model collapse inevitable? breaking the curse of recursion
by accumulating real and synthetic data. CoRR, abs/2404.01413, 2024.
Tony Ginart, Eva Zhang, Yongchan Kwon, and James Zou. Competing AI: how does competition
feedback affect machine learning? In Arindam Banerjee and Kenji Fukumizu, editors, The
24th International Conference on Artificial Intelligence and Statistics (AISTATS), volume 130 of
Proceedings of Machine Learning Research, pages 1693–1701, 2021.
Sachin Goyal, Pratyush Maini, Zachary C. Lipton, Aditi Raghunathan, and J. Zico Kolter. Scaling
laws for data filtering—Data curation cannot be compute agnostic. CoRR, abs/2404.07177, 2024.
Ronen Gradwohl and Moshe Tennenholtz. Coopetition against an Amazon. J. Artif. Intell. Res., 76:
1077–1116, 2023.
WalidHachem,PhilippeLoubaton,andJamalNajim. Deterministicequivalentsforcertainfunctionals
of large random matrices. The Annals of Applied Probability, 17(3):875 – 930, 2007.
Nika Haghtalab, Michael I. Jordan, and Eric Zhao. On-demand sampling: Learning optimally
from multiple distributions. In Advances in Neural Information Processing Systems 35: Annual
21Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA,
USA, November 28 - December 9, 2022, 2022.
Tinashe Handina and Eric Mazumdar. Rethinking scaling laws for learning in strategic environments.
CoRR, abs/2402.07588, 2024.
MoritzHardt,MeenaJagadeesan,andCelestineMendler-Dünner. Performativepower. InAdvancesin
Neural Information Processing Systems 35: Annual Conference on Neural Information Processing
Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022.
WinstonHarrington.Enforcementleveragewhenpenaltiesarerestricted.JournalofPublicEconomics,
37(1):29–53, 1988. ISSN 0047-2727.
Md Rajibul Hasan, Ashish Kumar Jha, and Yi Liu. Excessive use of online video streaming services:
Impact of recommender system use, psychological factors, and motives. Computers in Human
Behavior, 80:220–228, 2018.
Tatsunori Hashimoto. Model performance scaling with multiple data sources. In Proceedings of the
38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event,
volume 139 of Proceedings of Machine Learning Research, pages 4107–4116. PMLR, 2021.
Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness without
demographics in repeated loss minimization. In Jennifer Dy and Andreas Krause, editors, Pro-
ceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of
Machine Learning Research, pages 1929–1938. PMLR, 10–15 Jul 2018.
Trevor Hastie, Andrea Montanari, Saharon Rosset, and Ryan J. Tibshirani. Surprises in high-
dimensional ridgeless least squares interpolation. CoRR, abs/1903.08560, 2019.
Danny Hernandez, Jared Kaplan, Tom Henighan, and Sam McCandlish. Scaling laws for transfer.
arXiv preprint arXiv:2102.01293, 2021.
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza
Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom
Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy,
Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre.
Training compute-optimal large language models. CoRR, abs/2203.15556, 2022.
Nicole Immorlica, Adam Tauman Kalai, Brendan Lucier, Ankur Moitra, Andrew Postlewaite, and
Moshe Tennenholtz. Dueling algorithms. In Proceedings of the 43rd ACM Symposium on Theory
of Computing (STOC), pages 215–224, 2011.
David Ingram. Fewer people using Elon Musk’s X as platform struggles to keep
users. NBC News, 2024. URL https://www.nbcnews.com/tech/tech-news/
fewer-people-using-elon-musks-x-struggles-keep-users-rcna144115.
Ganesh Iyer and T. Tony Ke. Competitive algorithmic targeting and model selection. Available at
SSRN: https://ssrn.com/abstract=4214973, 2022.
Meena Jagadeesan, Michael I. Jordan, and Nika Haghtalab. Competition, alignment, and equilibria
in digital marketplaces. In Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI
2023, Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence, IAAI 2023,
22Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023, Washington,
DC, USA, February 7-14, 2023, pages 5689–5696. AAAI Press, 2023a.
Meena Jagadeesan, Michael I. Jordan, Jacob Steinhardt, and Nika Haghtalab. Improved Bayes risk
can yield reduced social welfare under competition. In Advances in Neural Information Processing
Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023,
New Orleans, LA, USA, December 10 - 16, 2023, 2023b.
Ayush Jain, Andrea Montanari, and Eren Sasoglu. Scaling laws for learning with real and surrogate
data. CoRR, abs/2402.04376, 2024.
Bruno Jullien and Wilfried Sand-Zantman. The economics of platforms: A theory guide for
competition policy. Information Economics and Policy, 54:100880, 2021.
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,
Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models.
CoRR, abs/2001.08361, 2020.
Jon M. Kleinberg and Manish Raghavan. Algorithmic monoculture and social welfare. Proc. Natl.
Acad. Sci. USA, 118(22):e2018340118, 2021.
Yongchan Kwon, Tony Ginart, and James Zou. Competition over data: how does data purchase
affect users? Trans. Mach. Learn. Res., 2022.
Benjamin Laufer, Jon M. Kleinberg, and Hoda Heidari. Fine-tuning games: Bargaining and
adaptation for general-purpose models. In Proceedings of the ACM on Web Conference 2024,
WWW 2024, Singapore, May 13-17, 2024, pages 66–76. ACM, 2024.
Licong Lin, Jingfeng Wu, Sham M. Kakade, Peter L. Bartlett, and Jason D. Lee. Scaling laws in
linear regression: Compute, parameters, and data. CoRR, abs/2406.08466, 2024.
Neil Mallinar, James B. Simon, Amirhesam Abedsoltan, Parthe Pandit, Misha Belkin, and Preetum
Nakkiran. Benign, tempered, or catastrophic: Toward a refined taxonomy of overfitting. In Sanmi
Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in
Neural Information Processing Systems 35: Annual Conference on Neural Information Processing
Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022.
Neil Mallinar, Austin Zane, Spencer Frei, and Bin Yu. Minimum-norm interpolation under covariate
shift. CoRR, abs/2404.00522, 2024.
V A Marčenko and L A Pastur. Distribution of eigenvalues for some sets of random matrices.
Mathematics of the USSR-Sbornik, 1(4):457, apr 1967.
CelestineMendler-Dünner,GabrieleCarovano,andMoritzHardt. Anenginenotacamera: Measuring
performative power of online search. CoRR, abs/2405.19073, 2024.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In
Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June
2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research,
pages 4615–4625. PMLR, 2019.
23Niklas Muennighoff, Alexander M. Rush, Boaz Barak, Teven Le Scao, Nouamane Tazi, Aleksandra
Piktus, Sampo Pyysalo, Thomas Wolf, and Colin A. Raffel. Scaling data-constrained language
models. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural
Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16,
2023, 2023.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong
Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton,
Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and
Ryan Lowe. Training language models to follow instructions with human feedback. In Advances in
Neural Information Processing Systems 35: Annual Conference on Neural Information Processing
Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022.
PratikPatil,Jin-HongDu,andRyanJ.Tibshirani.Optimalridgeregularizationforout-of-distribution
prediction. CoRR, abs/2404.01233, 2024.
Juan C. Perdomo, Tijana Zrnic, Celestine Mendler-Dünner, and Moritz Hardt. Performative
prediction. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020,
13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages
7599–7609. PMLR, 2020.
Billy Perrigo. The new AI-powered Bing is threatening users. that’s no laughing matter. Time
Magazine, 2023. URL https://time.com/6256529/bing-openai-chatgpt-danger-alignment/.
Jens Prüfer and Christoph Schottmüller. Competing with big data. The Journal of Industrial
Economics, 69(4):967–1008, 2021.
Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John C. Duchi, and Percy Liang. Understanding
and mitigating the tradeoff between robustness and accuracy. In Proceedings of the 37th Interna-
tional Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119
of Proceedings of Machine Learning Research, pages 7909–7919. PMLR, 2020.
Steve Rathje, Jay J. Van Bavel, and Sander van der Linden. Out-group animosity drives engagement
on social media. Proceedings of the National Academy of Sciences, 118(26):e2024292118, 2021.
Esther Rolf, Theodora T. Worledge, Benjamin Recht, and Michael I. Jordan. Representation matters:
Assessing the importance of subgroup allocations in training data. In Marina Meila and Tong
Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, ICML
2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research,
pages 9040–9051. PMLR, 2021.
Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generalization.
In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia,
April 26-30, 2020. OpenReview.net, 2020.
Ilya Segal and Michael D. Whinston. Antitrust in innovative industries. American Economic Review,
97(5):1703–1730, December 2007.
Eliot Shekhtman and Sarah Dean. Strategic usage in a multi-learner setting. In International
Conference on Artificial Intelligence and Statistics, 2-4 May 2024, Palau de Congressos, Valencia,
Spain, volume 238 of Proceedings of Machine Learning Research, pages 2665–2673. PMLR, 2024.
24Judy Hanwen Shen, Inioluwa Deborah Raji, and Irene Y Chen. The data addition dilemma. arXiv
preprint arXiv:2408.04154, 2024.
Yanke Song, Sohom Bhattacharya, and Pragya Sur. Generalization error of min-norm interpolators
in transfer learning. CoRR, abs/2406.13944, 2024.
Statista. Leading countries based on facebook audience size as of jan-
uary 2024, 2024. URL https://www.statista.com/statistics/268136/
top-15-countries-based-on-number-of-facebook-users/#:~:text=With%20around%202.
9%20billion%20monthly,most%20popular%20social%20media%20worldwide.
Stigler Committee. Final report: Stigler committee on digital platforms.
available at https://www.chicagobooth.edu/-/media/research/stigler/pdfs/
digital-platforms---committee-report---stigler-center.pdf,, September 2019.
Jinyan Su and Sarah Dean. Learning from streaming data when users choose. CoRR, abs/2406.01481,
2024.
The White House. Executive order on the safe, secure, and trustworthy development and use of
Artificial Intelligence, 2023.
Jean Tirole. The Theory of Industrial Organization, volume 1 of MIT Press Books. The MIT Press,
December 1988.
Jai Vipra and Anton Korinek. Market concentration implications of foundation models. CoRR,
abs/2311.01550, 2023.
Alexander Wei. Learning and Decision-Making in Complex Environments. PhD thesis, EECS
Department, University of California, Berkeley, May 2024.
Alexander Wei, Wei Hu, and Jacob Steinhardt. More than a toy: Random matrix models predict how
real-world neural representations generalize. In International Conference on Machine Learning,
ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine
Learning Research, pages 23549–23588. PMLR, 2022.
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. Jailbroken: How does LLM safety training
fail? In Advances in Neural Information Processing Systems 36: Annual Conference on Neural
Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16,
2023, 2023.
Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V.
Le, Tengyu Ma, and Adams Wei Yu. Doremi: Optimizing data mixtures speeds up language model
pretraining. In Advances in Neural Information Processing Systems 36: Annual Conference on
Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December
10 - 16, 2023, 2023.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept
and applications. ACM Trans. Intell. Syst. Technol., 10(2):12:1–12:19, 2019.
25A Proofs for Section 3
In this section, we prove Theorem 1. First, we state relevant facts (Appendix A.1) and prove
intermediate lemmas (Appendix A.2), and then we use these ingredients to prove Theorem 1
(Appendix A.3). Throughout this section, we let
L∗(ρ) = E [(β −β )Σ(β −β )T].
DW 1 2 1 2
Moreover, let
β(α,λ) = argmin (cid:0) α·E [(⟨β−β ,X⟩)2]+(1−α)·E [(⟨β−β ,X⟩)2]+λ∥β∥2(cid:1)
β X∼DF 1 X∼DF 2 2
be the infinite-data ridge regression predictor.
A.1 Facts
We can explicitly solve for the infinite-data ridge regression predictor
β(α,λ) = argmin (cid:0) α·E [⟨β −β ,x⟩2]+(1−α)·E [⟨β −β ,x⟩2]+λ||β||2(cid:1)
β x∼DF 1 x∼DF 2 2
= Σ(Σ+λI)−1(αβ +(1−α)β ).
1 2
A simple calculation shows that E [L (β(α,0))] = (1−α)2L∗(ρ) and E [L (β(α,0))] = α2L∗(ρ).
DW 1 DW 2
Thus, it holds that:
αE [L (β(α,0))]+(1−α)E [L (β(α,0))] = α(1−α)L∗(ρ).
DW 1 DW 2
Moreover, by the definition of the ridge regression objective, we see that:
αE [L (β(α,λ))]+(1−α)E [L (β(α,λ))] ≥ αE [L (β(α,0))]+(1−α)E [L (β(α,0))].
DW 1 DW 2 DW 1 DW 2
A.2 Lemmas
The first lemma upper bounds the performance loss when there is regularization.
Lemma 11. Suppose that power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1) and suppose that P = ∞. Let
L∗(ρ) = (β −β )TΣ(β −β )T. Let
1 2 1 2
β(α,λ) = argmin (cid:0) α·E [(⟨β−β ,X⟩)2]+(1−α)·E [(⟨β−β ,X⟩)2]+λ∥β∥2(cid:1)
β X∼DF 1 X∼DF 2 2
be the infinite-data ridge regression predictor. Assume that α ≥ 1/2. Then it holds that
E [L (β(α,λ))] ≥ (1−α)2L∗(ρ)
DW 1
and
E [L (β(α,λ))] (1−α)2
DW 1
≥ .
E [L (β(α,λ))] α2
DW 2
26Proof. We define the quantities:
P
A := λ2(cid:88) λ i i−δ
(λ +λ)2
i
i=1
(cid:88)P λ3
B := (1−α)2(1−ρ)2 i i−δ
(λ +λ)2
i
i=1
(cid:88)P λ2
C := λ(1−ρ) i i−δ.
(λ +λ)2
i
i=1
We compute the performance loss as follows:
E [L (β(α,λ))]
DW 1
= E [Tr(Σ(β −β(α,λ))(β −β(α,λ))T)]
DW 1 1
(cid:104) (cid:16) (cid:17)(cid:105)
= E Tr (Σ+λI)−2Σ(λβ +Σ·(1−α)(β −β ))(λβ +Σ·(1−α)(β −β ))T
DW 1 1 2 1 1 2
(cid:104) (cid:16) (cid:17)(cid:105)
= E Tr (Σ+λI)−2Σ·(λβ +Σ·(1−α)(β −β ))(λβ +Σ·(1−α)(β −β ))T
DW 1 1 2 1 1 2
= λ2E (cid:2) Tr(cid:0) (Σ+λI)−2Σ·β βT(cid:1)(cid:3) +(1−α)2E (cid:2) Tr(cid:0) (Σ+λI)−2Σ3·(β −β )(β −β )T(cid:1)(cid:3)
DW 1 1 DW 1 2 1 2
+λ(1−α)E (cid:2) Tr(cid:0) (Σ+λI)−2Σ2·β (β −β )T(cid:1)(cid:3)
DW 1 1 2
=
λ2(cid:88)P λ
i E [⟨β ,v
⟩2]+(1−α)2(cid:88)P λ3
i E [⟨β −β ,v ⟩2]
(λ +λ)2 DW 1 i (λ +λ)2 DW 1 2 i
i i
i=1 i=1
(cid:88)P λ2
+λ(1−α) i E [⟨β ,v ⟩⟨β −β ,v ⟩]
(λ +λ)2 DW 1 i 1 2 i
i
i=1
=
λ2(cid:88)P λ
i i−δ
+(1−α)2(1−ρ)2(cid:88)P λ3
i i−δ
+λ(1−α)(1−ρ)(cid:88)P λ2
i i−δ
(λ +λ)2 (λ +λ)2 (λ +λ)2
i i i
i=1 i=1 i=1
= A+(1−α)2B+(1−α)C.
An analogous calculation shows that the safety violation can be written as:
E [L (β(α,λ))] = A+α2B+αC
DW 2
Since α ≥ 1/2, then it holds that:
E [L (β(α,λ))] A+(1−α)2B+(1−α)C (1−α)2
DW 1
= ≥ .
E [L (β(α,λ))] A+αB+αC α2
DW 2
Combining this with the facts from Appendix A.1—which imply that αE [L (β(α,λ))]+(1−
DW 1
α)E [L (β(α,λ))] ≥ α(1−α)L∗(ρ)—wehavethatE [L (β(α,λ))] ≥ (1−α)2L∗(ρ)asdesired.
DW 2 DW 1
The following lemma computes the optimal values of α and λ for the incumbent.
Lemma 12. Suppose that power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1) and suppose that P = ∞. Let
L∗(ρ) = E [(β −β )TΣ(β −β )T]. Suppose that N = ∞, and suppose that the safety constraint
DW 1 2 1 2
(cid:113)
I
τ satisfies (1). Then it holds that α = min(τI,L∗(ρ)) , and λ = 0 is optimal for the incumbent.
I I L∗(ρ) I
Moreover, it holds that:
(cid:112) (cid:112)
E [L∗(β ,β ,D ,λ ,∞,α )] = ( L∗(ρ)− min(τ ,L∗(ρ))2.
DW 1 1 2 F I O I
27Proof. First, we apply Lemma 26 with N = ∞ to see that:
E [L∗(β ,β ,D ,λ,∞,α)] = E [L (β(α,λ))]
DW 1 1 2 F DW 1
and apply the definition of L∗ to see that:
2
E [L∗(β ,β ,D ,α)] = E [L (β(α,0))].
DW 2 1 2 F DW 2
(cid:113)
Let α∗ = min(τI,L∗(ρ)). By the assumption in the lemma statement, we know that:
L∗(ρ)
(cid:115)
E [L∗(β ,β ,D ,0.5)]
α∗ ≥ DW 2 1 2 F = 0.5.
L∗(ρ)
We show that (α ,λ ) = (α∗,0). Assume for sake of contradiction that (α,λ) ̸= (α∗,0) satisfies
I I
the safety constraint E [L∗(β ,β ,D ,α)] ≤ τ and achieves strictly better performance loss:
DW 2 1 2 F I
E [L∗(β ,β ,D ,λ,∞,α)] < E [L∗(β ,β ,D ,0,∞,α∗)].
DW 1 1 2 F DW 1 1 2 F
We split into two cases: α∗ = α,λ ̸= 0 and α∗ ̸= α.
Case 1: α∗ = α, λ ̸= 0. By Lemma 11, we know that
E[L∗(β ,β ,D ,λ,∞,α∗)] = E [L (β(α∗,λ))] ≥ (1−α∗)2L∗(ρ).
1 1 2 F DW 1
Equality is obtained at λ = 0, which is a contradiction.
Case 2: α ̸= α∗. By Lemma 11, it must hold that α > α∗ in order for the performance to beat that
of (α∗,0). However, this means that the safety constraint
E [L∗(β ,β ,D ,α)] = α2L∗(ρ) > (α∗)2L∗(ρ) = τ
DW 2 1 2 F I
is violated, which is a contradiction.
Concluding the statement. This means that(α ,λ ) = (α∗,0), which also means that:
I I
E [L∗(β ,β ,D ,λ ,∞,α )] = E [L (β(α ,λ ))]
DW 1 1 2 F I I DW 1 I I
= (1−α )2E [(β −β )TΣ(β −β )]
I DW 1 2 1 2
(cid:16)(cid:112) (cid:112) (cid:17)2
= L∗(ρ)− min(τ ,L∗(ρ) .
I
The following claim calculates E [(β −β )TΣ(β −β )].
DW 1 2 1 2
Claim 13. Suppose that the power-law scaling assumption holds for the eigenvalues and alignment
coefficients with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞.
Then it holds that:
(cid:32) P (cid:33)
(cid:88)
E [(β −β )TΣ(β −β )] = 2(1−ρ) i−δ−1−γ = Θ(1−ρ).
DW 1 2 1 2
i=1
28Proof. Let Σ = VΛVT be the eigendecomposition of Σ, where Λ is a diagonal matrix consisting of
the eigenvalues. We observe that
E [⟨β −β ,v ⟩2] = E [⟨β ,v ⟩2]+E [⟨β ,v ⟩2]−2E [⟨β ,v ⟩⟨β ,v ⟩] = i−δ+i−δ−2ρi−δ = 2(1−ρ)i−δ.
DW 1 2 i DW 1 i DW 2 i DW 1 i 2 i
This means that:
E [(β −β )TΣ(β −β )] = Tr(ΣE [(β −β )(β −β )T])
DW 1 2 1 2 DW 1 2 1 2
= Tr(ΛE [VT(β −β )(β −β )TV])
DW 1 2 1 2
P
(cid:88)
= i−1−γE [⟨β −β ,v ⟩2]
DW 1 2 i
i=1
P
(cid:88)
= 2(1−ρ) i−δ−1−γ
i=1
= Θ(1−ρ).
A.3 Proof of Theorem 1
We prove Theorem 1 using the above lemmas along with Corollary 8 (the proof of which we defer to
Appendix C).
Proof of Theorem 1. We analyze (α ,λ ) first for the incumbent C = I and then for the entrant
C C
C = E.
Analysis of the incumbent C = I. To compute α and λ , we apply Lemma 12. By Lemma 12,
I I
we see that:
(cid:16)(cid:112) (cid:112) (cid:17)2
E [L∗(β ,β ,D ,λ ,∞,α )] = L∗(ρ)− min(τ ,L∗(ρ) .
DW 1 1 2 F I I I
Analysis of the entrant C = E. Since the entrant faces no safety constraint, the entrant can
choose any α ∈ [0.5,1]. We apply Corollary 8 to see that:
E [L∗(β ,β ,D ,λ ,N,α )] = inf inf E [L∗(β ,β ,D ,λ,N,α)] = Θ(cid:0) N−ν(cid:1) ,
DW 1 1 2 F E E
α∈[0.5,1]λ>0
DW 1 1 2 F
which means that:
(cid:18) (cid:19)
(cid:16)(cid:112) (cid:112) (cid:17)−2/ν
N∗(∞,τ ,∞,D ,D ) = Θ L∗(ρ)− min(τ ,L∗(ρ)
E I W F I
as desired. We can further apply Claim 13 to see that L∗(ρ) = Θ(1−ρ).
B Proofs for Section 4
B.1 Proofs for Section 4.2
We prove Theorem 4. The main technical tool is Theorem 7, the proof of which we defer to Appendix
C.
29Proof of Theorem 4. We analyze (α ,λ ) first for the incumbent C = I and then for the entrant
C C
C = E. Like in the theorem statement, let L∗(ρ) = E [(β −β )TΣ(β −β )] = Θ(1−ρ) (Claim
13) and G := ((cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ)))2, and ν
=DW min(1 2(1+2 γ),δ+1
γ).
2
I I
Analysis of the incumbent C = I. Recall from the facts in Appendix A.1 that:
L∗(β ,β ,D ,α) = α2L∗(ρ).
1 1 2 F
(cid:113)
This means that the safety constraint is satisfied if and only if α ≤ min(τI,L∗(ρ)) =: α∗. The bound
I L∗(ρ)
in Corollary 8 implies that:
E [L∗(β ,β ,D ,λ ,N ,α )]
DW 1 1 2 F I I I
= inf inf E [L∗(β ,β ,D ,λ,N ,α)]
α∈[0.5,α∗]λ>0
DW 1 1 2 F I
(cid:18) (cid:19)
= Θ inf E [L∗(β ,β ,Σ,λ,N ,α∗)]
λ>0
DW 1 1 2 I
  Θ(cid:0) N I−ν(cid:1) if N I ≤ (1−α∗)− ν1 (1−ρ)− ν1
  (cid:18) (cid:16) (cid:17)− ν (cid:19)
= Θ (1−αN ∗)I
(1−ρ)
ν+1 if (1−α∗)− ν1 (1−ρ)− ν1 ≤ N
I
≤ (1−α∗)−2+ νν (1−ρ)− ν1


 Θ((1−α∗)2(1−ρ)) if N
I
≥ (1−α∗)−2+ νν (1−ρ)− ν1 ,

  Θ(cid:0) N I−ν(cid:1) if N I ≤ G− I 21 ν(1−ρ)− 21 ν
=   Θ(cid:18) N I− ν+ν 1 ·G I2(νν +1)(1−ρ)2(νν +1)(cid:19) if G− I 21 ν(1−ρ)− 21 ν ≤ N I ≤ G− I 1 2− ν1 (1−ρ)1 2 .


  Θ(G I) if N I ≥ G− I 1 2− ν1 (1−ρ)1 2
Analysis of the entrant C = E. Since the entrant faces no safety constraint, the entrant can
choose any α ∈ [0.5,1]. We apply Corollary 7 to see that:
E [L∗(β ,β ,D ,λ ,N,α )] = inf inf E [L∗(β ,β ,D ,λ,N,α)] = Θ(cid:0) N−ν(cid:1) ,
DW 1 1 2 F E E
α∈[0.5,1]λ>0
DW 1 1 2 F
which means that:

  Θ(N I) if N I ≤ G− I 21 ν(1−ρ)− 21 ν
 (cid:18) (cid:19)
N E∗(N I,τ I,∞,D W,D F) =   Θ N Iν+1 1 ·G− I 2(ν1 +1)(1−ρ)− 2(ν1 +1) if G− I 21 ν(1−ρ)− 21 ν ≤ N I ≤ G− I 21− ν1 (1−ρ)1 2
 (cid:18) (cid:19)
    Θ G− I ν1 if N I ≥ G− I 1 2− ν1 (1−ρ)1 2.
as desired.
B.2 Proofs for Section 4.3
We prove Theorem 5. When the the safety constraints of the two firms are sufficiently close, it no
longer suffices to analyze the loss up to constants for the entrant, and we require a more fine-grained
analysis of the error terms than is provided in the scaling laws in Corollary 8. In this case, we turn
to scaling laws for the excess loss as given by Corollary 10.
30Proof of Theorem 5. We analyze (α ,λ ) first for the incumbent C = I and then for the entrant
C C
C = E. Like in the theorem statement, let L∗(ρ) = E [(β −β )TΣ(β −β )] = Θ(1−ρ) (Claim
13), G = ((cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ)))2, G = ((cid:112) L∗D (ρW )−(cid:112)1 min2 (τ ,L∗1 (ρ)))2 2, D = G −G , and
I I E E I E
ν = min(2(1+γ),δ+γ).
Analysis of the incumbent C = I. Since the incumbent has infinite data, we apply Lemma 12 to
see that:
(cid:16)(cid:112) (cid:112) (cid:17)2
E [L∗(β ,β ,D ,λ ,∞,α )] = L∗(ρ)− min(τ ,L∗(ρ))
DW 1 1 2 F I I I
= D+G .
E
Analysis of the entrant C = E. Recall from the facts in Appendix A.1 that:
L∗(β ,β ,D ,α) = α2L∗(ρ).
1 1 2 F
(cid:113)
This means that the safety constraint is satisfied if and only if α ≤ min(τE,L∗(ρ)) =: α∗. The
E L∗(ρ)
bound in Corollary 10 implies that:
E [L∗(β ,β ,D ,λ ,N,α )]
DW 1 1 2 F E E
= inf inf E [L∗(β ,β ,D ,λ,N,α)]
α∈[0.5,α∗]λ>0
DW 1 1 2 F
(cid:18) (cid:19)
= inf inf (E [L∗(β ,β ,D ,λ,N,α)−L (β(α,0))])+E [L (β(α,0))]
α∈[0.5,α∗] λ>0
DW 1 1 2 F 1 DW 1
(cid:18) (cid:19)
= inf inf (E [L∗(β ,β ,D ,λ,N,α)−L (β(α,0))])+(1−α)2L∗(ρ)
α∈[0.5,α∗] λ>0
DW 1 1 2 F 1
(cid:18) (cid:19)
= Θ inf (E [L∗(β ,β ,D ,λ,N,α)−L (β(α∗,0))]) +(1−α∗)2L∗(ρ)
λ>0
DW 1 1 2 F 1
 (1−α∗)2L∗(ρ)+Θ(N−ν) if N ≤ (1−α∗)− ν1 (1−ρ)− ν1
=
    (1−α∗)2L∗(ρ)+Θ(cid:18) (cid:16) (1−α∗N )(1−ρ)(cid:17)− ν+ν 1(cid:19) if (1−α∗)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α∗)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′
    (1−α∗)2L∗(ρ)+Θ(cid:18) (1−α∗)(1−ρ)N− ν′ν +′ 1(cid:19) if N ≥ (1−α∗)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′,
 G
E
+Θ(N−ν) if N ≤ (1−α∗)− ν1 (1−ρ)− ν1
=
    G
E
+Θ(cid:18) (cid:16) (1−α∗N )(1−ρ)(cid:17)− ν+ν 1(cid:19) if (1−α∗)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α∗)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′
.
    G
E
+Θ(cid:18) (1−α∗)(1−ρ)N− ν′ν +′ 1(cid:19) if N ≥ (1−α∗)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′,
31Using this, we can compute the market-entry threshold as follows:
N∗(∞,τ ,τ ,D ,D )
E I E W F
 Θ(D− ν1 ) if D ≥ (1−α∗)(1−ρ)
   Θ(cid:16) D−ν+ ν1 (1−α∗)(1−ρ)(cid:17) if (1−α∗)ν−ν ν′(1−ρ)ν−ν ν′ ≤ D ≤ (1−α∗)(1−ρ)
=
  

Θ(cid:32) (cid:16) (1−α∗D )(1−ρ)(cid:17)−ν′ ν+ ′1(cid:33) if D ≤ (1−α∗)ν−ν ν′(1−ρ)ν−ν ν′

  Θ(D− ν1 ) if D ≥ G E1 2(1−ρ)1 2
     Θ(cid:18) D−ν+ ν1 G E1 2(1−ρ)1 2(cid:19) if G E2(ν−ν ν′)(1−ρ)2(ν−ν ν′) ≤ D ≤ G E1 2(1−ρ)1 2
=
   
Θ (cid:32)
D
(cid:33)−ν′ ν+ ′1
 if D ≤ G2(ν−ν ν′)(1−ρ)2(ν−ν ν′)
 
 

G
E1 2(1−ρ)1
2
 E
C Proofs for Section 5
In this section, we derive a deterministic equivalent and scaling laws for high-dimensional multi-
objective linear regression. Before diving into this, we introduce notation, derive a basic decomposi-
tion, and give an outline for the remainder of the section.
Notation. Recall that (X ,Y ) denotes the labelled training dataset. Let the sample covariance be:
i i
N
1 (cid:88)
Σˆ = X XT.
N i i
i=1
We also consider the following reparameterization where we group together inputs according to how
they are labelled. For j ∈ {1,2}, we let X ,...,X be the inputs labelled by β . We let
1,j Nj,j j
1
(cid:88)N1
Σˆ = X XT
1 N i,1 i,1
1
i=1
1
(cid:88)N2
Σˆ = X XT .
2 N i,2 i,2
2
i=1
It is easy to see that Σ = αΣˆ +(1−α)Σˆ . Moreover, E[Σˆ] = E[Σˆ ] = E[Σˆ ] = Σ. Furthermore, Σˆ
1 2 1 2 1
and Σˆ are fully independent. We let ∼ denote asymptotic equivalence following Bach [2023].
2
Basic decomposition. A simple calculation shows that the solution and population-level loss of
ridge regression takes the following form.
Claim 14. Assume the notation above. Let Bsn = β βT, let Bdf = (β −β )(β −β )T, and let
1 1 1 2 1 2
Bmx = (β −β )βT. The learned predictor takes the form:
1 2 1
βˆ(α,λ,X) = (Σˆ +λI)−1(αΣˆ β +(1−α)Σˆ β ).
1 1 2 2
32Moreover, it holds that:
L (βˆ(α,λ,X)) = λ2Tr((Σˆ +λI)−1Σ(Σˆ +λI)−1Bsn)+(1−α)2Tr(Σˆ (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bdf)
1 2 2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(T1) (T2)
+2λ(1−α)·Tr((Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bmx).
2
(cid:124) (cid:123)(cid:122) (cid:125)
(T3)
Proof. For 1 ≤ i ≤ N, let Y be the label for input X in the training dataset. For i ∈ {1,2} and
i i
1 ≤ i ≤ N , let Y := ⟨β ,X ⟩ be the label for the input X according to β .
i i,j i i,j i,j i
For the first part, it follows from standard analyses of ridge regression that the learned predictor
takes the form:
(cid:32) N (cid:33)
1 (cid:88)
βˆ(α,λ,X) = (Σˆ +λI)−1 X Y
i i
N
i=1
(cid:32) N N (cid:33)
1 (cid:88) 1 (cid:88)
= (Σˆ +λI)−1 X Y + X Y
i,1 i,1 i,2 i,2
N N
i=1 i=1
(cid:16) (cid:17)
= (Σˆ +λI)−1 αΣˆ β +(1−α)Σˆ β
1 1 2 2
as desired.
For the second part, we first observe that the difference β −βˆ(α,λ,X) takes the form:
1
(cid:16) (cid:17)
β −βˆ(α,λ,X) = β −(Σˆ +λI)−1 αΣˆ β +(1−α)Σˆ β
1 1 1 1 2 2
(cid:16) (cid:17)
= (Σˆ +λI)−1 λβ +(1−α)Σˆ (β −β ) .
1 2 1 2
This means that:
L (βˆ(α,λ,X))
1
= (β −βˆ(α,λ,X)TΣ(β −βˆ(α,λ,X)
1 1
(cid:16) (cid:17)T (cid:16) (cid:17)
= λβ +(1−α)Σˆ (β −β ) (Σˆ +λI)−1Σ(Σˆ +λI)−1 λβ +(1−α)Σˆ (β −β )
1 2 1 2 1 2 1 2
= λ2·βTΣˆ +λI)−1Σ(Σˆ +λI)−1β +(1−α)2·(β −β )TΣˆ Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ (β −β )
1 1 1 2 2 2 1 2
+2λ(1−α)·βTΣˆ +λI)−1Σ(Σˆ +λI)−1Σˆ (β −β )
1 2 1 2
= λ2Tr((Σˆ +λI)−1Σ(Σˆ +λI)−1Bsn)+(1−α)2Tr(Σˆ (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bdf)
2 2
+2λ(1−α)·Tr((Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bmx).
2
as desired.
Outline for the rest of this Appendix. The bulk of our analysis in this section boils down to
analyzing Term 1 (T1), Term 2 (T2), and Term 3 (T3) in Claim 14. Our main technical tool is the
random matrix machinery from Appendix D. In Appendix C.1, we provide useful sublemmas about
intermediate deterministic equivalents that we apply to analyze Terms 2 and 3. We then analyze
Term 1 (Appendix C.2), Term 2 (Appendix C.3), and Term 3 (Appendix C.4), and use this to prove
Lemma 6 (Appendix C.5).
We apply the power scaling assumptions to derive a simpler expression for the deterministic
equivalent (Lemma 26 in Appendix C.6). We then apply Lemma 26 to prove Theorem 7 (Appendix
33C.7), and we prove Corollary 8 (Appendix C.8). We also apply Lemma 26 to prove Theorem 9
(Appendix C.9), and we prove Corollary 10 (Appendix C.10). We defer auxiliary calculations to
Appendix C.11.
C.1 Useful lemmas about intermediate deterministic equivalents
The results in this section consider Z := α Σˆ + λ I, which we introduce when conditioning on
1 1−α 1 1−α
the randomness of Σˆ when analyzing (T2) and (T3). We derive several properties of Z and the
1 1
effective regularizer κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ) below.
1 1 1
The first set of lemmas relate the trace of various matrices involving κ and Z to deterministic
1 1
quantities. A subtlety is that κ and Z are correlated, so we cannot directly apply Marčenko-Pastur,
1 1
and instead we must indirectly analyze this quantity.
Lemma 15. Consider the setup of Lemma 6, and assume the notation above. Assume α < 1.
Let Z = α Σˆ + λ I, and let κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ). Suppose that B has bounded
1 1−α 1 1−α 1 1 1
operator norm.
κ
Tr(cid:0)
(Σ+κ Z
)−1B(cid:1)
∼
(1−α)κ Tr(cid:0) (Σ+κI)−1B(cid:1)
1 1 1
λ
Proof. By Claim 19, we know that:
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
(1−α)Tr Σˆ +λI B = Tr Σˆ +Z B
2 1
(cid:16) (cid:17)
∼ κ Tr (Σ+κ I)−1B .
(A) 1 1
where (A) applies Lemma 36 and Claim 20.
Furthermore, by Lemma 36, it holds that:
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)
λTr Σˆ +λI B ∼ κTr (Σ+κI)−1B .
Putting this all together yields the desired result.
Lemma 16. Consider the setup of Lemma 6, and assume the notation above. Assume α < 1. Let
Z = α Σˆ + λ I, and let κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ). Suppose that A and B have bounded
1 1−α 1 1−α 1 1 1
operator norm. Then it holds that:
(cid:16) (cid:16) (cid:17) (cid:17) (1−α)2κ2 (cid:16) (cid:16) (cid:17) (cid:17)
(κ )2 Tr (Σ+κ Z )−1A(Σ+κ Z )−1B +E ∼ Tr (Σ+κI)−1A(Σ+λI)−1B +E
1 1 1 1 1 1 λ2 2
where
κ = κ(λ,N,Σ)
1 Tr(A(Σ+κ Z )−1Σ(Σ+κ Z )−1)
E = N(1−α) 1 1 1 1 ·Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1B(cid:1)
1 1− 1 Tr((Σ+κ Z )−1)Σ(Σ+κ Z )−1Σ 1 1 1 1
N(1−α) 1 1 1 1
1 Tr(AΣ(Σ+κI)−2)
E = N ·Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1B(cid:1)
2 1− 1 Tr(Σ2(Σ+κI)−2)
N
34Proof. By Claim 19, we know that:
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1 (cid:16) (cid:17)−1 (cid:16) (cid:17)−1
(1−α)2Tr Σˆ +λI A Σˆ +λI B = Tr Σˆ +Z A Σˆ +Z B
2 1 2 1
(cid:16) (cid:16) (cid:17) (cid:17)
∼ κ2 Tr (Σ+κ Z )−1A(Σ+κ Z )−1B +E .
(A) 1 1 1 1 1 1
where (A) applies Lemma 36 and Claim 20.
Furthermore, by Lemma 36, it holds that:
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1 (cid:16) (cid:16) (cid:17) (cid:17)
λ2Tr Σˆ +λI A Σˆ +λI B ∼ κ2 Tr (Σ+κI)−1A(Σ+κI)−1B +E .
2
Putting this all together yields the desired result.
Lemma 17. Consider the setup of Lemma 6, and assume the notation above. Assume α < 1. Let
Z = α Σˆ + λ I, and let κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ). Then it holds that:
1 1−α 1 1−α 1 1 1
Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) (1−α)2κ2 Tr(Σ2(Σ+κI)−2)
κ2 1 1 1 1 ∼
1 1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) λ2 1− 1 Tr(Σ2(Σ+κI)−2)
N(1−α) 1 1 1 1 N
Proof. By Claim 19, we know that:
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
(1−α)2Tr Σˆ +λI Σ Σˆ +λI Σ
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
= Tr Σˆ +Z Σ Σˆ +Z Σ
2 1 2 1
∼
κ2(cid:32)
1+
N(11
−α)
Tr((Σ+κ 1Z 1)−1Σ(Σ+κ 1Z 1)−1Σ) (cid:33) Tr(cid:16)
(Σ+κ Z )−1Σ(Σ+κ Z
)−1Σ(cid:17)
(A) 1 1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1 1 1
N(1−α) 1 1 1 1
Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
= κ2 1 1 1 1
1 1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
where (A) applies Lemma 36 and Claim 20.
Furthermore, by Lemma 36, it holds that:
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
λ2Tr Σˆ +λI Σ Σˆ +λI Σ
(cid:32) (cid:33)
1 Tr(Σ2(Σ+κI)−2) (cid:16) (cid:17)
∼ κ2 1+ N Tr (Σ+κI)−1Σ(Σ+κI)−1Σ
(A) 1− 1 Tr(Σ2(Σ+κI)−2
N
 (cid:16) (cid:17) 
Tr Σ2(Σ+κI)−2
= κ2  .
1− 1 Tr(Σ2(Σ+κI)−2
N
where (A) applies Lemma 36.
Putting this all together yields the desired result.
Next, we relate the random effective regularizer κ to the deterministic effective regularizer
1
κ(λ,N,Σ).
35Lemma 18. Consider the setup of Lemma 6, and assume the notation above. Assume α < 1. Let
Z = α Σˆ + λ I, and let κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ). Let κ = κ(λ,N,Σ). Then, it holds
1 1−α 1 1−α 1 1 1
that λκ ∼ κ.
1
Proof. Recall that κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ) is the unique value such that:
1 1 1
1 1
+
Tr((Z−1/2 ΣZ−1/2
+κ
I)−1Z−1/2 ΣZ−1/2
) = 1.
κ N(1−α) 1 1 1 1 1
1
We can write this as:
κ
1+ 1 Tr((Σ+κ Z )−1Σ) = κ .
1 1 1
N(1−α)
Now we apply Lemma 15 to see that:
κ 1 (1−α)κ
κ = 1+ 1 Tr((Σ+κ Z )−1Σ) ∼ 1+ Tr((Σ+κI)−1Σ).
1 1 1
N(1−α) N(1−α) λ
We can write this to see that:
(cid:18) (cid:19)
κ λ 1 κ
κ ∼ + Tr((Σ+κI)−1Σ) = .
1
λ κ N λ
This implies that λκ ∼ κ as desired.
1
The proofs of these results relied on the following facts.
Claim 19. Consider the setup of Lemma 6, and assume the notation above. Assume α < 1. Let
Z = α Σˆ + λ I. Then it holds that:
1 1−α 1 1−α
(Σˆ +λI)−1 = (1−α)−1(Σˆ +Z )−1.
2 1
Proof. We observe that:
(1−α)(Σˆ +λI)−1 = (1−α)(αΣˆ +(1−α)Σˆ +λI)−1
1 2
(cid:18)
α λ
(cid:19)−1
= (1−α)(1−α)−1 Σˆ + Σˆ + I
2 1
1−α 1−α
(cid:16) (cid:17)−1
= Σˆ +Z ,
2 1
where Z = α Σˆ + λ I.
1 1−α 1 1−α
Claim 20. Consider the setup of Lemma 6, and assume the notation above. Assume α < 1. Let
Z = α Σˆ + λ I. Then it holds that Z and Z−1 both have bounded operator norm.
1 1−α 1 1−α 1 1
Proof. Since Σˆ is PSD, we observe that:
1
α λ
∥Z ∥ = ∥Σˆ ∥ + .
1 op 1 op
1−α 1−α
The fact that ∥Σˆ ∥ is bounded follows from the boundedness requirements from Assumption 1.
1 op
This proves that ∥Z ∥ is bounded.
1 op
To see that ∥Z−1∥ is also bounded, note that:
1
1−α
∥Z−1∥ ≥
1 op λ
36C.2 Analysis of Term 1 (T1)
We show the following deterministic equivalent for term 1. This analysis is identical to the analysis
of the deterministic equivalent for single-objective linear regression [Bach, 2023, Wei et al., 2022],
and we include it for completeness.
Lemma 21. Consider the setup of Lemma 6, and assume the notation above. Then it holds that:
κ2
λ2Tr((Σˆ +λI)−1Σ(Σˆ +λI)−1Bsn) ∼ ·Tr(Σ(Σ+κI)−2Bsn)
1− 1 Tr(Σ2(Σ+κI)−2)
N
Proof. We apply Lemma 36 to see that:
λ2Tr((Σˆ +λI)−1Σ(Σˆ +λI)−1Bsn)
1 Tr(Σ2(Σ+κI)−2)
∼ κ2Tr((Σ+κI)−1Σ(Σ+κI)−1Bsn)+ N
1− 1 Tr(Σ2(Σ+κI)−2)
N
κ2
= ·Tr(Σ(Σ+κI)−2Bsn),
1− 1 Tr(Σ2(Σ+κI)−2)
N
as desired.
C.3 Analysis of Term 2 (T2)
We show the following deterministic equivalent for term 2.
Lemma 22. Consider the setup of Lemma 6, and assume the notation above. Then it holds that:
(cid:16) (cid:17)
(1−α)2Tr Σˆ (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bdf
2 2
(1−α)2 (cid:16) (cid:16) (cid:17)(cid:17)
∼ Tr (Σ+κI)−1Σ(Σ+κI)−1ΣBdfΣ
1− 1 Tr(Σ2(Σ+κI)−2)
N
(1−α)1 Tr(Σ2(Σ+κI)−2)
+ N ·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2(1−α)Tr(cid:0) (Σ+κI)−1ΣBdfΣ(cid:1)(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
The key idea of the proof is to unwrap the randomness in layers. First, we condition on Σˆ and
1
replace the randomness Σˆ with a deterministic equivalent where the effective regularizer κ depends
2 1
on Σˆ (Lemma 23). At this stage, we unfortunately cannot directly deal with the randomness Σˆ
1 1
with deterministic equivalence due to the presence of terms κ which depend on Σˆ , and we instead
1 1
apply the sublemmas from the previous section.
The following lemma replaces the randomness Σˆ with a deterministic equivalent.
2
Lemma 23. Consider the setup of Lemma 6, and assume the notation above. Assume that α < 1.
Let Z = α Σˆ + λ I, and let κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ). Then it holds that:
1 1−α 1 1−α 1 1 1
(cid:16) (cid:17)
(1−α)2Tr Σˆ (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bdf
2 2
(cid:16) (cid:17)
Tr (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ
1 1 1 1
∼
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
+
N(1−α) 1 1 1 1 ·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2Tr(cid:0)
Σ(Σ+κ Z
)−1ΣBdf(cid:1)(cid:1)
.
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1
N(1−α) 1 1 1 1
37Proof. By Claim 19 we have that:
(cid:18) (cid:19)
(cid:16) (cid:17) (cid:16) (cid:17)−1 (cid:16) (cid:17)−1
(1−α)2Tr Σˆ (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bdf = Tr Σˆ Σˆ +Z Σ Σˆ +Z Σˆ Bdf
2 2 2 2 1 2 1 2
∼ Tr(cid:0) Σ(Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdf(cid:1) +E
(A) 1 1 1 1
= Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ(cid:1) +E
1 1 1 1
where (A) follows from Lemma 39 and Claim 20, and E is defined such that
E :=
N(11
−α)
Tr((Σ+κ 1Z 1)−1Σ(Σ+κ 1Z 1)−1Σ)
·(κ
)2Tr(cid:16)
Z (Σ+κ Z )−1Σ(Σ+κ Z )−1Z
Bdf(cid:17)
.
1− 1 Tr(Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1 1 1 1 1 1
N(1−α) 1 1 1 1
and κ = κ(λ,N(1−α),Z−1/2 ΣZ−1/2 ).
1 1 1
Note that:
(cid:16) (cid:17)
(κ )2Tr Z (Σ+κ Z )−1Σ(Σ+κ Z )−1Z Bdf
1 1 1 1 1 1 1
(cid:16) (cid:17)
= Tr (κ Z )(Σ+κ Z )−1Σ(Σ+κ Z )−1(κ Z )Bdf
1 1 1 1 1 1 1 1
(cid:16) (cid:17)
= Tr (cid:0) I −Σ(Σ+κ Z )−1(cid:1) Σ(cid:0) I −Σ(Σ+κ Z )−1(cid:1)T Bdf
1 1 1 1
= Tr(cid:0) ΣBdf(cid:1) −2Tr(cid:0) (Σ+κ Z )−1ΣBdfΣ(cid:1) +Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ(cid:1) .
1 1 1 1 1 1
Note that:
Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ(cid:1)
1 1 1 1
1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
+Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ(cid:1) · N(1−α) 1 1 1 1
1 1 1 1 1− 1 Tr(Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ(cid:1)
1 1 1 1
=
1− 1 Tr(Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
Now we are ready to prove Lemma 22.
38Proof of Lemma 22. The statement follows trivially if α = 1. By Lemma 23, it holds that:
(cid:16) (cid:17)
(1−α)2Tr Σˆ (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bdf
2 2
(cid:16) (cid:17)
Tr (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBdfΣ
1 1 1 1
∼
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
+
N(1−α) 1 1 1 1 ·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2Tr(cid:0)
(Σ+κ Z
)−1ΣBdfΣ(cid:1)(cid:1)
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1
N(1−α) 1 1 1 1
(cid:16) (cid:16) (cid:17)(cid:17)
∼ (1−α)2 Tr (Σ+κI)−1Σ(Σ+κI)−1ΣBdfΣ
(A)
1 Tr(Σ2(Σ+κI)−2)
+ N ·(1−α)2·Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1ΣBdfΣ(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
+
N(1−α) 1 1 1 1 ·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2(1−α)Tr(cid:0) (Σ+κI)−1ΣBdfΣ(cid:1)(cid:1)
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
(1−α)2 (cid:16) (cid:16) (cid:17)(cid:17)
= Tr (Σ+κI)−1Σ(Σ+κI)−1ΣBdfΣ
1− 1 Tr(Σ2(Σ+κI)−2)
N
1 Tr(Σ2(Σ+κ Z )−2)
+
N(1−α) 1 1 ·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2(1−α)Tr(cid:0) (Σ+κI)−1ΣBdfΣ(cid:1)(cid:1)
1− 1 Tr(Σ2(Σ+κ Z )−2)
N(1−α) 1 1
(1−α)2 (cid:16) (cid:16) (cid:17)(cid:17)
∼ Tr (Σ+κI)−1Σ(Σ+κI)−1ΣBdfΣ
(B) 1− 1 Tr(Σ2(Σ+κI)−2)
N
1 Tr(Σ2(Σ+κI)−2)
+(1−α) N ·(cid:0) Tr(cid:0) ΣBdf(cid:1) −2(1−α)Tr(cid:0) (Σ+κI)−1ΣBdfΣ(cid:1)(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
where (A) applies Lemma 16, Lemma 15, and (B) uses Lemma 17 and Lemma 18.
C.4 Analysis of Term 3 (T3)
We show the following deterministic equivalent for term 3.
Lemma 24. Consider the setup of Lemma 6 and assume the notation above. Let Bmx = (β −β )βT,
1 2 1
and let κ = κ(λ,N,Σ). Then it holds that:
(cid:16) (cid:17)
2λ(1−α)Tr (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bmx
2
∼
2(1−α)κ Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
(1−α)1 Tr(Σ2(Σ+κI)−2)
−2 N ·κTr(cid:0) (Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
Theanalysisfollowsasimilarstructuretotheanalysisof(T2);wesimilarlyunwraptherandomness
in layers.
39Lemma 25. Consider the setup of Lemma 6 and assume the notation above. Assume α < 1. Let
Z = α Σˆ + λ I, and let κ = κ(1,N(1−α),Z−1/2 ΣZ−1/2 ). Then it holds that:
1 1−α 1 1−α 1 1 1
(cid:16) (cid:17)
2λ(1−α)2Tr (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bmx
2
λκ Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1)
1 1 1 1 1
∼ 2
(1−α)1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
−2
λκ 1
·
N(11 −α) Tr(Σ2(Σ+κ 1Z 1)−2) ·Tr(cid:0)
Σ(Σ+κ Z
)−1ΣBmx(cid:1)
.
(1−α) 1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1
N(1−α) 1 1 1 1
Proof. By Claim 19 we have that:
(cid:18) (cid:19)
(cid:16) (cid:17) λ (cid:16) (cid:17)−1 (cid:16) (cid:17)−1
2λ(1−α)Tr (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bmx = 2 Tr Σˆ +Z Σ Σˆ +Z Σˆ Bmx
2 2 1 2 1 2
(1−α)
∼ 2 λ (cid:0) κ Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1) −E(cid:1)
(A) (1−α) 1 1 1 1 1
where (A) follows from Lemma 40 and Claim 20, and E is defined such that
E :=
N(11
−α)
Tr((Σ+κ 1Z 1)−1Σ(Σ+κ 1Z 1)−1Σ)
·(κ
)2Tr(cid:16)
(Σ+κ Z )−1Σ(Σ+κ Z )−1Z
Bmx(cid:17)
.
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1 1 1 1 1
N(1−α) 1 1 1 1
and κ = κ(λ,N(1−α),Z−1/2 ΣZ−1/2 ).
1 1 1
Note that:
(cid:16) (cid:17)
(κ )2Tr (Σ+κ Z )−1Σ(Σ+κ Z )−1Z Bmx
1 1 1 1 1 1
(cid:16) (cid:17)
= κ Tr (Σ+κ Z )−1Σ(Σ+κ Z )−1(κ Z )Bmx
1 1 1 1 1 1 1
= κ
Tr(cid:0)
(Σ+κ Z
)−1Σ(cid:0)
I −(Σ+κ Z
)−1Σ(cid:1) Bmx(cid:1)
1 1 1 1 1
= κ Tr(cid:0) (Σ+κ Z )−1ΣBmx(cid:1) −κ Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1)
1 1 1 1 1 1 1 1
Moreover, note that:
2 λκ 1 Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1)
1 1 1 1
(1−α)
+2 λ · N(11 −α) Tr((Σ+κ 1Z 1)−1Σ(Σ+κ 1Z 1)−1Σ) ·κ Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1)
(1−α) 1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1 1 1 1 1
N(1−α) 1 1 1 1
λ Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1)
1 1 1 1
= 2 ·κ .
(1−α)1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) 1
N(1−α) 1 1 1 1
Now we are ready to prove Lemma 22.
40Proof of Lemma 22. The statement follows trivially if α = 1. By Lemma 23, it holds that:
(cid:16) (cid:17)
2λ(1−α)2Tr (Σˆ +λI)−1Σ(Σˆ +λI)−1Σˆ Bmx
2
λκ Tr(cid:0) (Σ+κ Z )−1Σ(Σ+κ Z )−1ΣBmx(cid:1)
1 1 1 1 1
∼ 2
(1−α)1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
−
N(11 −α) Tr((Σ+κ 1Z 1)−1Σ(Σ+κ 1Z 1)−1Σ)
·2
λκ 1 Tr(cid:0)
(Σ+κ Z
)−1ΣBmx(cid:1)
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ) (1−α) 1 1
N(1−α) 1 1 1 1
∼
2(1−α)κTr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1ΣBmx(cid:1)
(A)
1 Tr(Σ2(Σ+κI)−2)
+2(1−α)κ N Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
−2
N(1−α) 1 1 1 1 ·κTr(cid:0) (Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
= 2
(1−α)κ Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
−2
N(1−α) 1 1 1 1 ·κTr(cid:0) (Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr((Σ+κ Z )−1Σ(Σ+κ Z )−1Σ)
N(1−α) 1 1 1 1
∼ 2
(1−α)κ Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1ΣBmx(cid:1)
(B) 1− 1 Tr(Σ2(Σ+κI)−2)
N
1 Tr(Σ2(Σ+κI)−2)
−2(1−α) N ·κTr(cid:0) (Σ+κI)−1ΣBmx(cid:1)
1− 1 Tr(Σ2(Σ+κI)−2)
N
where (A) applies Lemma 16, Lemma 15, and Lemma 18, and (B) uses Lemma 17 and Lemma 18.
C.5 Proof of Lemma 6
Lemma 6 follows from the sublemmas in this section.
Proof. We apply Claim 14 to decompose the error in terms (T1), (T2), and (T3). We replace these
terms with deterministic equivalents using Lemma 21, Lemma 22, and Lemma 24. The statement
follows from adding these terms.
C.6 Reformulation of Lemma 6 using assumptions from Section 2.3
Under the assumptions from Section 2.3, we show the following:
Lemma 26. Suppose that power scaling holds for the eigenvalues and alignment coefficients with
scaling γ,δ > 0 and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞. Suppose that
λ ∈ (0,1), and N ≥ 1. Let Ldet := Ldet(β ,β ,D ,λ,N,α) be the deterministic equivalent from
1 1 1 2 F
Lemma 6. Let κ = κ(λ,N,Σ) from Definition 2. Let L∗(ρ) = E [(β −β )TΣ(β −β )]. Then it
DW 1 2 1 2
41holds that:
(cid:88)P i−δ−1−γ
Q·E [Ldet] = κ2(1−2(1−α)2(1−ρ)) +(1−α)2L∗(ρ)
DW 1 (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+2(1−α)(1−ρ) ·(1−2(1−α)) ,
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
where Q = 1− 1 (cid:80)P i−2−2γ .
N i=1 (i−1−γ+κ)2
Before proving Lemma 26, we prove a number of sublemmas where we analyze each of the terms
in Lemma 6 using the assumptions from Section 2.3. In the proofs in this section, we use the
notation F ≈ F′ to denote that F = Θ(F′) where the Θ is allowed to hide dependence on the scaling
exponents γ and δ. Moreover let Σ = VΛVT be the eigendecomposition of Σ, where Λ is a diagonal
matrix consisting of the eigenvalues.
Lemma 27. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6. Let ν = min(2(1+γ),γ +δ). Then it holds that:
(cid:88)P i−δ−1−γ
E [T ] := κ2·Tr(ΣΣ−2E [Bsn]) = κ2 .
DW 1 κ DW (i−1−γ +κ)2
i=1
Proof. Observe that:
Tr(ΣΣ−2E [Bsn]) = Tr(Λ(Λ+κI)−2E [VTβ βTV])
κ DW DW 1 1
(cid:88)P i−1−γ
= ·E [⟨β ,v ⟩2]
(i−1−γ +κ)2 DW 1 i
i=1
(cid:88)P i−δ−1−γ
=
(i−1−γ +κ)2
i=1
Lemma 28. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6. Then it holds that:
E [T ] := (1−α)2(cid:0) Tr(cid:0) Σ−2Σ3E [Bdf](cid:1)(cid:1) =
2(1−α)2(1−ρ)(cid:88)P i−δ−3(1+γ)
.
DW 2 κ DW (i−1−γ +κ)2
i=1
Proof. First, we observe that
E [⟨β −β ,v ⟩2] = E [⟨β ,v ⟩2]+E [⟨β ,v ⟩2]−2E [⟨β ,v ⟩⟨β ,v ⟩] = i−δ+i−δ−2ρi−δ = 2(1−ρ)i−δ.
DW 1 2 i DW 1 i DW 2 i DW 1 i 2 i
42It is easy to see that:
Tr(cid:0) Σ−2Σ3E [Bdf](cid:1) = Tr(Λ3(Λ+κI)−2E [VT(β −β )(β −β )TV])
κ DW DW 1 2 1 2
(cid:88)P i−3(1+γ)
= ·E [⟨β −β ,v ⟩2]
(i−1−γ +κ)2 DW 1 2 i
i=1
(cid:88)P i−δ−3(1+γ)
= 2(1−ρ) .
(i−1−γ +κ)2
i=1
Lemma 29. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6. Then it holds that:
E [T ] := 2(1−α)κ·Tr(cid:0) Σ−2Σ2Bmx(cid:1) =
2(1−α)κ(1−ρ)(cid:88)P i−δ−2−2γ
.
DW 3 κ (i−1−γ +κ)2
i=1
Proof. First, we observe that
E [⟨β −β ,v ⟩⟨β ,v ⟩] = E [⟨β ,v ⟩2]−E [⟨β ,v ⟩⟨β ,v ⟩] = i−δ −ρi−δ = (1−ρ)i−δ.
DW 1 2 i 1 i DW 1 i DW 1 i 2 i
Observe that:
Tr(cid:0) Σ−2Σ2Bmx(cid:1) = Tr(Λ2(Λ+κI)−2E [VT(β −β )βTV])
κ DW 1 2 1
(cid:88)P i−2(1+γ)
= ·E [⟨β −β ,v ⟩⟨β ,v ⟩]
(i−1−γ +κ)2 DW 1 2 i 1 i
i=1
(cid:88)P i−δ−2−2γ
= (1−ρ) .
(i−1−γ +κ)2
i=1
This means that:
(cid:88)P i−δ−2−2γ
E [T ] = 2(1−α)κ(1−ρ) .
DW 3 (i−1−γ +κ)2
i=1
Lemma 30. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6. Then it holds that:
|E [T ]| := 2κ(1−α) 1 Tr(Σ2Σ−2)·Tr(cid:0) Σ−1ΣE [Bmx](cid:1)
DW 4 N κ κ DW
1 (cid:32) (cid:88)P i−2−2γ (cid:33)(cid:32) (cid:88)P i−δ−1−γ (cid:33)
= 2κ(1−α)(1−ρ)
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
43Proof. First, we observe that
E [⟨β −β ,v ⟩⟨β ,v ⟩] = E [⟨β ,v ⟩2]−E [⟨β ,v ⟩⟨β ,v ⟩] = i−δ +−ρi−δ = (1−ρ)i−δ.
DW 1 2 i 1 i DW 1 i DW 1 i 2 i
Observe that:
Tr(cid:0) Σ−1ΣE [Bmx](cid:1) = Tr(Λ(Λ+κI)−1E [VT(β −β )βTV])
κ DW DW 1 2 1
(cid:88)P i−1−γ
= ·E [⟨β −β ,v ⟩⟨β ,v ⟩]
i−1−γ +κ DW 1 2 i 1 i
i=1
(cid:88)P i−δ−1−γ
= (1−ρ) .
i−1−γ +κ
i=1
Now, apply Lemma 32, we see that:
|E [T ]| := 2κ(1−α) 1 Tr(Σ2Σ−2)·Tr(cid:0) Σ−1ΣBmx(cid:1)
DW 4 N κ κ
1 (cid:32) (cid:88)P i−2−2γ (cid:33)(cid:32) (cid:88)P i−δ−1−γ (cid:33)
= 2κ(1−α)(1−ρ)
(A) N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
where (A) follows from Lemma 32.
Lemma 31. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6, and similarly let
E [T ] := (1−α) 1 Tr(Σ2Σ−2)·(cid:0) Tr(cid:0) ΣE [Bdf](cid:1) −2(1−α)Tr(cid:0) Σ−1Σ2E [Bdf](cid:1)(cid:1)
DW 5 N κ DW κ DW
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
= 2(1−α)(1−ρ) · i−δ−1−γ −2(1−α)· .
N (i−1−γ +κ)2 (i−1−γ +κ)
i=1 i=1 i=1
Proof. First, we observe that
E [⟨β −β ,v ⟩2] = E [⟨β ,v ⟩2]+E [⟨β ,v ⟩2]−2E [⟨β ,v ⟩⟨β ,v ⟩] = i−δ+i−δ−2ρi−δ = 2(1−ρ)i−δ.
DW 1 2 i DW 1 i DW 2 i DW 1 i 2 i
Now, observe that:
E [T ] := (1−α) 1 Tr(Σ2Σ−2)·(cid:0) Tr(cid:0) ΣE [Bdf](cid:1) −2(1−α)Tr(cid:0) Σ−1Σ2E [Bdf](cid:1)(cid:1)
DW 5 N κ DW κ DW
= (1−α) 1 Tr(Σ2Σ−2)·(cid:0) Tr(cid:0) ΛE [VT(β −β )(β −β )TV](cid:1)(cid:1)
N κ DW 1 2 1 2
−(1−α) 1 Tr(Σ2Σ−2)·(cid:0) 2(1−α)Tr(cid:0) (Λ+κI)−1Λ2E [VT(β −β )(β −β )TV](cid:1)(cid:1)
N κ DW 1 2 1 2
1 (cid:32) (cid:88)P (cid:88)P i−2−2γ (cid:33)
= (1−α) Tr(Σ2Σ−2)· i−1−γ⟨β −β ,v ⟩2−2(1−α)· ⟨β −β ,v ⟩2
N κ 1 2 i (i−1−γ +κ) 1 2 i
i=1 i=1
1 (cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
= 2(1−α)(1−ρ) Tr(Σ2Σ−2)· i−δ−1−γ −2(1−α)·
N κ (i−1−γ +κ)
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
= 2(1−α)(1−ρ) · i−δ−1−γ −2(1−α)· .
(A) N (i−1−γ +κ)2 (i−1−γ +κ)
i=1 i=1 i=1
where (A) uses Lemma 32.
44The proofs of these sublemmas use the following fact.
Lemma 32. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6. Then it holds that:
Tr(cid:0) Σ2(Σ+κI)−2(cid:1)
=
(cid:88)P i−2−2γ
.
(i−1−γ +κ)2
i=1
Proof. We see that:
1 1
(1−α) Tr(Σ2Σ−2) = (1−α) Tr(VΛ2(Λ+κI)−2VT)
N κ N
1
= (1−α) Tr(Λ2(Λ+κI)−2)
N
(cid:88)P i−2−2γ
= .
(i−1−γ +κ)2
i=1
Now, we are ready to prove Lemma 26.
Proof of Lemma 26. By Lemma 32, we know:
1 1 (cid:88)P i−2−2γ
Q = 1− Tr(Σ2(Σ+κI)−2) = 1− .
N N (i−1−γ +κ)2
i=1
Moreover, we have that:
Q·E [Ldet] = E [T +T +T +T +T ]
DW 1 (A) DW 1 2 3 4 5
(cid:88)P i−δ−1−γ (cid:88)P i−δ−3(1+γ)
= κ2 +2(1−α)2(1−ρ)
(B) (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)(1−α)
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33)(cid:32) (cid:88)P i−δ−1−γ (cid:33)
−2κ(1−ρ)(1−α)
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
+2(1−α)(1−ρ) · i−δ−1−γ −2(1−α)· .
N (i−1−γ +κ)2 (i−1−γ +κ)
i=1 i=1 i=1
where (A) follows from Lemma 6, and (B) follows from Lemmas 27-31.
By Claim 13, we know that:
(cid:88)P (cid:88)P i−δ−3(1+γ)
L∗(ρ) = 2(1−ρ) i−δ−1−γ = 2(1−ρ) .
(i−1−γ)2
i=1 i=1
45This means that:
(cid:88)P i−δ−3(1+γ)
L∗(ρ)−2(1−ρ)
(i−1−γ +κ)2
i=1
(cid:88)P (cid:32) i−δ−3(1+γ) i−δ−3(1+γ) (cid:33)
= 2(1−ρ) −
(i−1−γ)2 (i−1−γ +κ)2
i=1
(cid:88)P (cid:32) i−δ−3(1+γ)·((i−1−γ +κ)2−(i−1−γ)2)(cid:33)
= 2(1−ρ)
(i−1−γ)2·(i−1−γ +κ)2
i=1
(cid:88)P (cid:32) i−δ−3(1+γ) (cid:33) (cid:88)P (cid:32) i−δ−3(1+γ)·i−1−γ (cid:33)
= 2κ2(1−ρ) +4κ(1−ρ)
(i−1−γ)2·(i−1−γ +κ)2 (i−1−γ)2·(i−1−γ +κ)2
i=1 i=1
(cid:88)P (cid:18) i−δ−1−γ (cid:19) (cid:88)P (cid:32) i−δ−2(1+γ) (cid:33)
= 2κ2(1−ρ) +4κ(1−ρ)
(i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
Applying this and some other algebraic manipulations, we obtain that:
(cid:88)P i−δ−1−γ
Q·Ldet = κ2(1−2(1−α)2(1−ρ)) +(1−α)2L∗(ρ)
1 (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33)(cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
−2(1−α)(1−ρ) i−δ−1−γ −
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
+2(1−α)(1−ρ) · i−δ−1−γ −2(1−α)·
N (i−1−γ +κ)2 (i−1−γ +κ)
i=1 i=1 i=1
(cid:88)P i−δ−γ
= κ2(1−2(1−α)2(1−ρ)) +(1−α)2L∗(ρ)
(i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+2(1−α)(1−ρ) ·(1−2(1−α)) .
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
C.7 Proof of Theorem 7
We now prove Theorem 7. In the proof, we again use the notation F ≈ F′ to denote F = Θ(F′).
The main ingredient is Lemma 26, coupled with the auxiliary calculations in Appendix C.11.
Proof. The proof boils down to three steps: (1) obtaining an exact expression, (2) obtaining an
up-to-constants asymptotic expression in terms of κ and Q, and (3) substituting in κ and Q.
46Step 1: Exact expression. We apply Lemma 26 to see that:
(cid:88)P i−δ−1−γ
Q·Ldet = κ2(1−2(1−α)2(1−ρ)) +(1−α)2L∗(ρ)
1 (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+2(1−α)(1−ρ) ·(1−2(1−α)) ,
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
where Q = 1 − 1 (cid:80)P i−2−2γ , where L∗(ρ) = E [(β − β )TΣ(β − β )], and where κ =
N i=1 (i−1−γ+κ)2 DW 1 2 1 2
κ(Σ,N,λ) as defined in Definition 2.
Step 2: Asymptotic expression in terms of κ and Q. We show that
− 1
Q·Ldet ≈ κ1+ν γ +(1−α)2(1−ρ)+(1−α)(1−ρ)κ 1+γ .
1 N
We analyze this expression term-by-term and repeatedly apply Lemma 33. We see that:
κ2(1−2(1−α)2(1−ρ))(cid:88)P (i−i 1− −δ γ−1 +−γ
κ)2
≈
(A)
κ1+ν γ(1−2(1−α)2(1−ρ)) ≈
(B)
κ1+ν γ,
i=1
where (A) uses Lemma 33 and (B) uses that α ≥ 0.5. Moreover, we observe that:
(1−α)2L∗(ρ) ≈ (1−α)2(1−ρ),
(C)
where (C) uses Claim 13. Moreover, we see that:
(cid:88)P i−δ−2(1+γ) (cid:16) δ+γ(cid:17)
2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
≈
(D)
(1−α)(1−ρ)(1−2(1−α))max κ,κ1+γ
i=1
(cid:18) (cid:18) (cid:19)(cid:19)
(cid:112) δ+γ
= O (1−α) 1−ρmax κ,κ2(1+γ)
(E)
(cid:18)(cid:113) (cid:19)
min(2(1+γ),γ+δ)
= O (1−α)2(1−ρ)·κ 1+γ
(cid:18) (cid:19)
min(2(1+γ),γ+δ)
= (F) O κ 1+γ +(1−α)2(1−ρ)
=
O(cid:16) κ1+ν
γ
+(1−α)2(1−ρ)(cid:17)
where (D) uses Lemma 33, (E) uses that 1−ρ ≤ 1 and that κ = O(1) (which follows from Lemma
35 and the assumption that λ ∈ (0,1)) and (F) follows from AM-GM. Finally, observe that:
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
2(1−α)(1−ρ) ·(1−2(1−α))
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
≈ (1−2(1−α))·(1−α)(1−ρ)
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
− 1
κ 1+γ
≈ (1−2(1−α))·(1−α)(1−ρ)
(G) N
47where (G) uses Lemma 33 twice.
Putting this all together, we see that:
− 1
Q·Ldet ≈ κ1+ν γ +(1−α)2(1−ρ)+(1−2(1−α))·(1−α)(1−ρ)κ 1+γ .
1 N
We split into two cases based on α. When α ≥ 0.75, we observe that
− 1 − 1
κ 1+γ κ 1+γ
(1−2(1−α))·(1−α)(1−ρ) ≈ (1−α)(1−ρ) ,
N N
and when α ∈ [0.5,0.75], we observe that
− 1 (cid:32) − 1 (cid:33)
κ 1+γ κ 1+γ
(1−2(1−α))·(1−α)(1−ρ) = O (1−α)(1−ρ)
N N
and
− 1
κ 1+γ
(1−α)2(1−ρ) ≈ (1−α)(1−ρ)
(H) N
where (H) follows from the fact that κ = Ω(N−1−γ) by Lemma 35. Altogether, this implies that:
− 1
Q·Ldet ≈ κ1+ν γ +(1−α)2(1−ρ)+(1−α)(1−ρ)κ 1+γ ,
1 N
as desired.
Step 2: Substitute in κ and Q. Finally, we apply Lemma 34 to see that:
(cid:32) 1 (cid:88)P i−2−2γ (cid:33)−1
Q−1 = 1− = Θ(1).
N (i−1−γ +κ)2
i=1
We apply Lemma 35 to see that
κ = κ(Σ,N,Σ) = max(N−1−γ,λ).
Plugging this into the expression derived in Step 2, we obtain the desired expression.
C.8 Proof of Corollary 8
We prove Corollary 8 using Theorem 7.
Proof. We apply Theorem 7 to see that:
 
 (cid:32) − 1 (cid:33) 
E DW[Ld 1et] = Θ  max(λ1+ν γ,N−ν)+(1−α)2·(1−ρ)+(1−α) min(λ N1+γ,N) (1−ρ)  .
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
 
finitedataerror mixtureerror (cid:124) (cid:123)(cid:122) (cid:125)
overfittingerror
We split into three cases: N ≤ (1−α)− ν1 (1−ρ)− ν1, (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)−2+ νν (1−ρ)− ν1,
and N ≥ (1−α)−2+ νν (1−ρ)− ν1.
48Case 1: N ≤ (1−α)− ν1 (1−ρ)− ν1 . We observe that the finite data error dominates regardless of λ.
This is because the condition implies that
max(λ1+ν γ,N−ν) ≥ (1−α)(1−ρ),
which dominates both the mixture error and the overfitting error.
Case 2: (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)−2+ νν (1−ρ)− ν1 . We show that the finite error term and
overfitting error dominate. Let N˜ = min(λ− 1+1 γ,N). We can bound the sum of the finite data error
and the overfitting error as:
max(λ1+ν
γ,N−ν)+(1−α)(cid:32) min(λ− 1+1 γ,N)(cid:33)
(1−ρ) = N˜−ν
+(1−α)(1−ρ)N˜
.
N N
Taking a derivative (and verifying the second order condition), we see that this expression is
minimized when:
(1−α)(1−ρ)
ν ·N˜−ν−1 =
N
which solves to:
N˜ =
Θ(cid:32) (cid:18) (1−α)(1−ρ)(cid:19)− 1+1 ν(cid:33)
.
N
The lower bound on N guarantees that:
N˜ =
Θ(cid:32) (cid:18) (1−α)(1−ρ)(cid:19)− 1+1 ν(cid:33)
=
O(cid:18) (cid:16)
(1−α)1+ ν1 (1−ρ)1+
ν1(cid:17)− 1+1 ν(cid:19)
=
O(cid:16)
(1−α)− ν1 (1−ρ)−
ν1(cid:17)
= O(N)
N
which ensures that N˜ can be achieved by some choice of λ. In particular, we can take λ =
(cid:18)
(cid:16)
(cid:17)1+γ(cid:19)
Θ (1−α)(1−ρ) ν+1 .
N
The resulting sum of the finite error and the overfitting error is:
(cid:32) − 1 (cid:33) (cid:32) (cid:18) (cid:19) ν (cid:33)
max(λ1+ν γ,N−ν)+(1−α) min(λ 1+γ,N) = Θ (1−α)(1−ρ) ν+1 .
N N
The upper bound on N guarantees that this dominates the mixture error:
Θ(cid:32) (cid:18) (1−α)(1−ρ)(cid:19) ν+ν 1(cid:33)
=
Ω(cid:18) (cid:16)
(1−α)1+2+ νν (1−ρ)1+
ν1(cid:17) ν+ν 1(cid:19)
= Ω((1−α)2(1−ρ))
N
as desired.
Case 3: N ≥ (1−α)−2+ νν (1−ρ)− ν1 . We show that the mixture and the overfitting error terms
dominate. First, we observe that the sum of the mixture error and the finite data error is:
(cid:32) − 1 (cid:33) (cid:32) (cid:32) − 1 (cid:33)(cid:33)
min(λ 1+γ,N) min(λ 1+γ,N)
(1−α)2(1−ρ)+(1−α) (1−ρ) = Θ (1−α)(1−ρ) 1−α+ .
N N
This is minimized by taking λ = Θ((N(1−α))−1−γ), which yields Θ((1−α)2(1−ρ)).
The upper bound on N and the setting of λ guarantees that this term dominates the finite data
error:
max(λ1+ν γ,N−ν) = O((N(1−α))−ν) ≤ O(cid:0) (1−α)−ν(1−α)2+ν(1−ρ)(cid:1) = O((1−α)2(1−ρ),
as desired.
49C.9 Proof of Theorem 9
We prove Theorem 9.
Proof of Theorem 9. Like the proof of Theorem 7, the proof boils down to three steps: (1) obtaining
an exact expression, (2) obtaining an up-to-constants asymptotic expression in terms of κ, and (3)
substituting in κ.
Step 1: Exact expression. We first apply Lemma 26 to obtain the precise loss:
(cid:88)P i−δ−1−γ
Q·E [L∗(β ,β ,D ,λ ,N,α )] = κ2(1−2(1−α)2(1−ρ)) +(1−α)2L∗(ρ)
DW 1 1 2 F E E (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+2(1−α)(1−ρ) ·(1−2(1−α)) ,
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
where Q = 1− 1 (cid:80)P i−2−2γ and where κ = κ(Σ,N,λ) as defined in Definition 2. This can be
N i=1 (i−1−γ+κ)2
written as:
E [L∗(β ,β ,D ,λ ,N,α )]−(1−α)2L∗(ρ)
DW 1 1 2 F E E
(cid:88)P i−δ−1−γ
= Q−1·κ2(1−2(1−α)2(1−ρ))
(i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+Q−1·2κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−1·2(1−α)(1−ρ) ·(1−2(1−α))
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
1−Q
+ (1−α)2L∗(ρ).
Q
Step 2: Asymptotic expression in terms of κ. We use the notation F ≈ F′ to denote that
50F = Θ(F′). We obtain:
E [L∗(β ,β ,D ,λ ,N,α )]−(1−α)2L∗(ρ)
DW 1 1 2 F E E
(cid:88)P i−δ−1−γ
≈ κ2(1−2(1−α)2(1−ρ))
(A) (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+κ(1−ρ)(1−α)(1−2(1−α))
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+(1−α)(1−ρ) ·(1−2(1−α))
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
+(1−Q)(1−α)2L∗(ρ)
(cid:88)P i−δ−1−γ (cid:88)P i−δ−2(1+γ)
≈ κ2 +κ(1−ρ)(1−α)
(B) (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+(1−α)(1−ρ)
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33)
+(1−α)2L∗(ρ)· .
N (i−1−γ +κ)2
i=1
where (A) uses that Q−1 is a constant by Lemma 34 and (B) uses that α ≥ 0.75 and the definition
of Q. Now, using the bounds from Lemma 33, and the bound from Claim 13, we obtain:
E [L∗(β ,β ,D ,λ ,N,α )]−(1−α)2L∗(ρ)
DW 1 1 2 F E E
min(2(1+γ),γ+δ) (cid:16) γ+δ(cid:17) κ− 1+1 γ κ− 1+1 γ
≈ κ 1+γ +(1−ρ)(1−α)max κ,κ1+γ +(1−α)(1−ρ) + (1−α)2(1−ρ)
N N
− 1
ν ν′ κ 1+γ
≈ κ1+γ +(1−ρ)(1−α)κ1+γ +(1−α)(1−ρ) .
N
Step 3: Substituting in κ. Finally, we apply Lemma 35 to see that
κ = κ(Σ,N,Σ) = max(N−1−γ,λ).
Plugging this into the expression derived in Step 2, we obtain the desired expression.
C.10 Proof of Corollary 10
We prove Corollary 10 using Theorem 9.
Proof. We apply Theorem 7 to see that:
E [Ldet−L (β(α,0))]
DW 1 1
 
 (cid:32) − 1 (cid:33) 
=
Θ max(λ1+ν γ,N−ν)+(1−ρ)(1−α)max(λ1ν +′ γ,N−ν′
)+(1−α)
min(λ 1+γ,N) (1−ρ)
.
 N 
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
 
finitedataerror mixturefinitedataerror (cid:124) (cid:123)(cid:122) (cid:125)
overfittingerror
51We split into three cases: N ≤ (1−α)− ν1 (1−ρ)− ν1, (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)− νν −′+ ν1 ′(1−
ρ)− νν −′+ ν1 ′, and N ≥ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′.
Case 1: N ≤ (1−α)− ν1 (1−ρ)− ν1 . We observe that the finite data error dominates regardless of λ.
This is because the condition implies that
max(λ1+ν γ,N−ν) ≥ (1−α)(1−ρ),
which dominates both the mixture finite data error and the overfitting error.
Case 2: (1−α)− ν1 (1−ρ)− ν1 ≤ N ≤ (1−α)− νν −′+ ν1 ′(1−ρ)− νν −′+ ν1 ′. We show that the finite error term
and overfitting error dominate. Let N˜ = min(λ− 1+1 γ,N). We can bound the sum of the finite data
error and the overfitting error as:
max(λ1+ν
γ,N−ν)+(1−α)(cid:32) min(λ− 1+1 γ,N)(cid:33)
(1−ρ) = N˜−ν
+(1−α)(1−ρ)N˜
.
N N
Taking a derivative (and verifying the second order condition), we see that this expression is
minimized when:
(1−α)(1−ρ)
ν ·N˜−ν−1 =
N
which solves to:
N˜ =
Θ(cid:32) (cid:18) (1−α)(1−ρ)(cid:19)− 1+1 ν(cid:33)
.
N
The lower bound on N guarantees that:
N˜ =
Θ(cid:32) (cid:18) (1−α)(1−ρ)(cid:19)− 1+1 ν(cid:33)
=
O(cid:18) (cid:16)
(1−α)1+ ν1 (1−ρ)1+
ν1(cid:17)− 1+1 ν(cid:19)
=
O(cid:16)
(1−α)− ν1 (1−ρ)−
ν1(cid:17)
= O(N)
N
which ensures that N˜ can be achieved by some choice of λ. In particular, we can take λ =
(cid:18)
(cid:16)
(cid:17)1+γ(cid:19)
Θ (1−α)(1−ρ) ν+1 .
N
The resulting sum of the finite error and the overfitting error is:
(cid:32) − 1 (cid:33) (cid:32) (cid:18) (cid:19) ν (cid:33)
max(λ1+ν γ,N−ν)+(1−α) min(λ 1+γ,N) = Θ (1−α)(1−ρ) ν+1 .
N N
The upper bound on N and the choice of λ guarantees that this dominates the mixture finite
52data error, as shown below:
(1−ρ)(1−α)max(λ1ν +′ γ,N−ν′
)
 
(cid:18) (cid:19)
ν′
(1−α)(1−ρ) ν+1
= Θ(1−ρ)(1−α) 
N

(cid:18) (cid:19) ν (cid:18)
(cid:19)ν′−ν
(1−α)(1−ρ) ν+1 (1−α)(1−ρ) ν+1
= Θ (1−α)(1−ρ) 
N N
(cid:32) (cid:18) (cid:19) ν (cid:33)
(1−α)(1−ρ) ν+1 ν′+1 ν′+1 ν−ν′
= Θ (1−α)ν+1 (1−ρ)ν+1 N ν+1
N
(cid:32) (cid:18) (cid:19) ν (cid:33)
= O
(1−α)(1−ρ) ν+1 (1−α)ν ν′ ++ 11 (1−ρ)ν ν′ ++ 11 (1−α)−ν ν′ ++ 11 (1−ρ)−ν ν′ ++ 11
N
(cid:32) (cid:18) (cid:19) ν (cid:33)
(1−α)(1−ρ) ν+1
= O
N
as desired.
Case 3: N ≥ (1 − α)− νν −′+ ν1 ′(1 − ρ)− νν −′+ ν1 ′. We show that the mixture finite data error and the
overfitting error terms dominate. First, we observe that the sum of the mixture error and the finite
data error is:
(cid:32) − 1 (cid:33)
(1−ρ)(1−α)max(λ1ν +′ γ,N−ν′
)+(1−α)
min(λ 1+γ,N)
(1−ρ)
N
(cid:32) (cid:32) − 1 (cid:33)(cid:33)
ν′ min(λ 1+γ,N)
= Θ (1−α)(1−ρ) λ1+γ +
N
This is minimized by taking λ = Θ(N− ν1 ′+ +γ 1), which yields Θ((1−α)(1−ρ)N− ν′ν +′ 1).
The upper bound on N and the setting of λ guarantees that this term dominates the finite data
error:
max(λ1+ν γ,N−ν) = Θ(N− ν′ν +1)
(cid:18) (cid:19)
≤ Θ
(1−α)(1−ρ)N− ν′ν +′ 1(1−α)−1(1−ρ)−1N−ν ν− ′+ν 1′
(cid:18) (cid:19)
= O (1−α)(1−ρ)N− ν′ν +′ 1(1−α)−1(1−ρ)−1(1−α)(1−ρ)
(cid:18) (cid:19)
−
ν′
= O (1−α)(1−ρ)N ν′+1
as desired.
C.11 Auxiliary calculations under power scaling assumptions
We show the following auxiliary calculations which we use when analyzing the terms in Lemma 6
under the power scaling assumptions. Throughout this section, we again use the notation F ≈ F′ to
denote that F = Θ(F′).
53Lemma 33. Suppose that power-law scaling holds for eigenvalues and alignment coefficients with
scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞. Let
κ = κ(λ,N,Σ) be defined according to Definition 2. Then the following holds:
(cid:88)P i−δ−1−γ
min(2(1+γ),γ+δ)
≈ κ−2κ 1+γ
(i−1−γ +κ)2
i=1
(cid:88)P i−δ−3(1+γ)
≈ 1
(i−1−γ +κ)2
i=1
(cid:88)P i−δ−2−2γ
≈ 1
i−1−γ +κ
i=1
(cid:88)P i−δ−2(1+γ)
δ−1
≈ max(1,κ1+γ)
(i−1−γ +κ)2
i=1
(cid:88)P i−δ−1−γ
δ−1
≈ max(1,κ1+γ)
i−1−γ +κ
i=1
(cid:88)P i−2−2γ
− 1
≈ κ 1+γ
(i−1−γ +κ)2
i=1
(cid:88)P i−1−γ
− 1
≈ κ 1+γ
i−1−γ +κ
i=1
(cid:88)P i−1−γ
γ
≈ κ−2κ1+γ
(i−1−γ +κ)2
i=1
Proof. To prove the first statement, observe that:
(cid:88)P i−δ−1−γ
(cid:88)
i−δ−1−γ
(cid:88)
i−δ−1−γ
= +
(i−1−γ +κ)2 (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i≤κ−1+1
γ
i≥κ−1+1
γ
(cid:88) (cid:88)
≈ i1+γ−δ +κ−2 i−δ−1−γ
i≤κ−1+1
γ
i≥κ−1+1
γ
≈
max(1,κ−2+ 1+γ− γδ )+κ−2κ1δ+ +γ
γ
γ+δ δ+γ
= κ−2max(κ2,κ1+γ)+κ−2κ1+γ
γ+δ
≈ κ−2max(κ2,κ1+γ)
min(2(1+γ),γ+δ)
≈ κ−2κ 1+γ .
To prove the second statement, we use Lemma 35 and the assumption that λ ∈ (0,1) to see
κ = Θ(max(λ,N−1−γ)) = O(1). This means that
(cid:88)P i−δ−3(1+γ) (cid:32) (cid:88)P (cid:33)
= Ω i−δ−3(1+γ) = Ω(1).
(i−1−γ +κ)2
i=1 i=1
54Moreover, we see that:
(cid:88)P i−δ−3(1+γ) (cid:32) (cid:88)P i−δ−3(1+γ)(cid:33) (cid:32) (cid:88)P (cid:33)
= O = O i−δ−1−γ) = Ω(1).
(i−1−γ +κ)2 (i−1−γ)2
i=1 i=1 i=1
To prove the third statement, we use Lemma 35 and the assumption that λ ∈ (0,1) to see
κ = Θ(max(λ,N−1−γ)) = O(1). This means that
(cid:88)P i−δ−2−2γ (cid:32) (cid:88)P (cid:33)
= Ω i−δ−2(1+γ) = Ω(1).
i−1−γ +κ
i=1 i=1
Moreover, we see that:
(cid:88)P i−δ−2(1+γ) (cid:32) (cid:88)P i−δ−2(1+γ)(cid:33) (cid:32) (cid:88)P (cid:33)
= O = O i−δ−1−γ = O(1).
i−1−γ +κ i−1−γ
i=1 i=1 i=1
To prove the fourth statement, observe that:
(cid:88)P i−δ−2−2γ
(cid:88)
i−δ−2−2γ
(cid:88)
i−δ−2−2γ
≈ +
(i−1−γ +κ)2 (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i≤κ−1+1
γ
i≥κ−1+1
γ
(cid:88) (cid:88)
≈ i−δ +κ−2 i−δ−2−2γ
i≤κ−1+1
γ
i≥κ−1+1
γ
≈
max(1,κ− 11 +− γδ )+κ−2κδ+ 11 ++ γ2γ
δ−1
≈ max(1,κ1+γ).
To prove the fifth statement, observe that:
(cid:88)P i−δ−1−γ
(cid:88)
i−δ−1−γ
(cid:88)
i−δ−1−γ
= +
i−1−γ +κ i−1−γ +κ i−1−γ +κ
i=1 i≤κ−1+1
γ
i≥κ−1+1
γ
(cid:88) (cid:88)
≈ i−δ +κ−1 i−δ−1−γ
i≤κ−1+1
γ
i≥κ−1+1
γ
≈
max(1,κ− 11 +− γδ )+κ−1κ1δ+ +γ
γ
δ−1
≈ max(1,κ1+γ).
To prove the sixth statement, observe that:
(cid:88)P i−2−2γ
(cid:88)
i−2−2γ
(cid:88)
i−2−2γ
= +
(i−1−γ +κ)2 (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i≤κ−1+1
γ
i≥κ−1+1
γ
(cid:88) (cid:88)
≈ 1+κ−2 i−2−2γ
i≤κ−1+1
γ
i≥κ−1+1
γ
≈
κ− 1+1
γ
+κ−2κ1 1+ +2 γγ
− 1
≈ κ 1+γ.
55To prove the seventh statement, observe that:
(cid:88)P i−1−γ
(cid:88)
i−1−γ
(cid:88)
i−1−γ
= +
i−1−γ +κ i−1−γ +κ i−1−γ +κ
i=1 i≤κ−1+1
γ
i≥κ−1+1
γ
(cid:88) (cid:88)
≈ 1+κ−1 i−1−γ
i≤κ−1+1
γ
i≥κ−1+1
γ
≈
κ− 1+1
γ
+κ−1κ1+γ
γ
− 1
≈ κ 1+γ.
To prove the eighth statement, observe that:
(cid:88)P i−1−γ
(cid:88)
i−1−γ
(cid:88)
i−δ−1−γ
= +
(i−1−γ +κ)2 (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i≤κ−1+1
γ
i≥κ−1+1
γ
(cid:88) (cid:88)
≈ i1+γ +κ−2 i−1−γ
i≤κ−1+1
γ
i≥κ−1+1
γ
≈
max(1,κ−2 1+ +γ γ)+κ−2κ1+γ
γ
γ γ
= κ−2max(κ2,κ1+γ)+κ−2κ1+γ
γ
≈ κ−2max(κ2,κ1+γ)
γ
≈ κ−2κ1+γ
Lemma 34. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), suppose that P = ∞. Assume
the notation from Lemma 6, and similarly let
1
Q := 1− Tr(Σ2Σ−2).
N κ
Then it holds that Q−1 = Θ(1).
Proof. Let Σ = VΛVT be the eigendecomposition of Σ, where Λ is a diagonal matrix consisting of
the eigenvalues. By Definition 2, we see that:
λ 1
+ Tr(ΣΣ−1) = 1.
κ N κ
This implies that:
Q = 1− 1 Tr(ΣΣ−1)+ 1 (cid:0) Tr(ΣΣ−1)−Tr(Σ2Σ−2)(cid:1)
N κ N κ κ
=
λ
+
1 (cid:0) Tr(ΣΣ−1)−Tr(Σ2Σ−2)(cid:1)
.
κ N κ κ
56Observe that:
Tr(ΣΣ−1)−Tr(Σ2Σ−2) = Tr(Λ(Λ+κI)−1)−Tr(Λ2(Λ+κI)−2)
κ κ
(cid:88)P (cid:18) i−1−γ i−2−γ (cid:19)
= −
i−1−γ +κ (i−1−γ +κ)2
i=1
(cid:88)P i−1−γ
= κ .
(i−1−γ +κ)2
i=1
This means that:
λ κ (cid:88)P i−1−γ
Q = +
κ N (i−1−γ +κ)2
i=1
λ (cid:16) κ γ (cid:17)
≈
(A) κ
+Θ( Nκ−2κ1+γ )
(cid:32) − 1 (cid:33)
λ κ 1+γ
= +Θ .
κ N
where (A) uses Lemma 33.
Case 1: κ = Θ(λ). In this case, we see that
(cid:32) − 1 (cid:33)
λ κ 1+γ
Q = +Θ = Θ(1).
κ N
This means that Q−1 = Θ(1).
Case 2: κ = Θ(N−1−γ). In this case, we see that
(cid:32) − 1 (cid:33) (cid:32) − 1 (cid:33)
λ κ 1+γ κ 1+γ
Q = +Θ = Ω = Ω(1).
κ N N
This means that Q−1 = Θ(1).
Lemma 35. Suppose that power-law scaling holds for the eigenvalues with scaling exponent γ, and
suppose that P = ∞. Then it holds that κ(λ,M,Σ) = Θ(max(λ,M−1−γ)).
Proof. Let Σ = VΛVT be the eigendecomposition of Σ, where Λ is a diagonal matrix consisting of
the eigenvalues. Observe that:
Tr((Σ+κI)−1Σ) = Tr(Λ(Λ+κI)−1)
(cid:88)P i−1−γ
=
i−1−γ +κ
i=1
− 1
≈
(A)
κ 1+γ.
where (A) follows from Lemma 33. Using Definition 2, we see that for κ = κ(λ,M,Σ), it holds that:
λ 1
+ Θ(κ−1−γ) = 1.
κ M
This implies that κ = Θ(max(λ,M−1−γ)) as desired.
57D Machinery from random matrix theory
In this section, we introduce machinery from random matrix theory that serves as the backbone
for our analysis of multi-objective scaling laws in Appendix C. In Appendix D.1, we give a recap
of known Marčenko-Pastur properties. In Appendix D.2, we use these known properties to derive
random matrix theory results which are tailored to our analysis.
D.1 Recap of Marčenko-Pastur properties
We introduce Marčenko-Pastur properties, following the treatment in Bach [2023]. Informally
speaking, Marčenko-Pastur laws show that a random matrix (Σˆ + λI)−1 (where Σˆ is a sample
covariance) behaves similarly to a deterministic matrix of the form (Σˆ+κI)−1, where κ = κ(λ,M,Σ)
is an effective regularizer.
Deriving this formally requires placing several structural assumptions on number of data points
N ≥ 1, the number of parameters P ≥ 1, the distribution D , and the vectors β and β . We adopt
F 1 2
assumptions from Bach [2023] which guarantee that a Marčenko-Pastur law holds for Σ, and we
further introduce a boundedness assumption for technical reasons.
Assumption 1. We assume that: (1) X ∼ D takes the form X = ZΣ1/2 where Z has bounded
F
subgaussian i.i.d components with mean zero and unit variance, (2) N and P approach ∞ with P
N
tending to γ > 0, (3) the spectral measure 1 (cid:80)P δ of Σ converges to a probability measure with
P i=1 λi
compact support, and Σ is invertible and bounded in operator norm, and (4) for j ∈ {1,2}, the
measure (cid:80)P ⟨v ,β ⟩2 converges to a measure with bounded mass, and β has bounded ℓ norm.
i=1 i j j 2
The effective regularizer κ(λ,M,Σ) is defined as follows.
Definition 2 (Effective regularizer). For λ ≥ 0, M ≥ 1, and a P-dimensional positive semidefinite
matrix Σ with eigenvalues λ for 1 ≤ i ≤ P, the value κ(λ,M,Σ) is the unique value κ ≥ 0 such that:
i
P
λ 1 (cid:88) λ i
+ = 1.
κ N λ +κ
i
i=1
We are now ready to state the key random matrix theory results proven in Bach [2023]. Following
Bach [2023], the asymptotic equivalence notation u ∼ v means that u/v tends to 1 as N and P go
to ∞.
Lemma 36 (Restatement of Proposition 1 in Bach [2023]). Let Σˆ = 1 (cid:80)M X XT be the sample
M i=1 i i
covariance matrix from M i.i.d. samples from X ,...,X ∼ D . Let κ = κ(λ,N,Σ). Suppose that
1 M F
A and B have bounded operator norm. Then it holds that:
(cid:16) (cid:17)
Tr (Σˆ +λI)−1A ∼ κTr(cid:0) (Σ+κI)−1A(cid:1)
(cid:16) (cid:17)
κ2Tr (Σˆ +λI)−1A(Σˆ +λI)−1B ∼ Tr(cid:0) (Σ+κI)−1A(Σ+κI)−1B(cid:1)
1 Tr(cid:0) AΣ(Σ+κI)−2(cid:1)
+κ2 N Tr(cid:0) (Σ+κI)−1Σ(Σ+κI)−1B(cid:1) .
1− 1 Tr(Σ2(Σ+κI)−2)
N
We note that the requirement that B has bounded operator norm in Lemma 36 is what forces us
to require that ∥β ∥ and ∥β ∥ are bounded. However, Wei et al. [2022] showed that the norm can be
1 2
unbounded in several real-world settings, and thus instead opt to assume a local Marčenko-Pastur
law and derive scaling laws based on this assumption. We suspect it may be possible to derive our
58scaling law with an appropriate analogue of the local Marčenko-Pastur law, which would also have
the added benefit of allowing one to relax other requirements in Assumption 1 such as gaussianity.
We view such an extension as an interesting direction for future work.
D.2 Useful random matrix theory facts
We derive several corollaries of Lemma 36 tailored to random matrices that arise in our analysis of
multi-objective scaling laws.
Lemma 37. Assume that D satisfies the Marčenko-Pastur property (Assumption 1). Let Z be a
F
positive definite matrix such that Z−1 has bounded operator norm, and let A be a matrix with bounded
operator norm. Let Σˆ = 1 (cid:80)M X XT be the sample covariance matrix from M i.i.d. samples from
M i=1 i i
X ,...,X ∼ D . Then it holds that:
1 M F
λ·Tr((Σˆ +λZ)−1A) ∼ κ·Tr((Σ+κZ)−1A). (3)
If A also has bounded trace and Z has bounded operator norm, then it holds that:
Tr(Σˆ(Σˆ +λZ)−1A) ∼ Tr(Σ·(Σ+κZ)−1A) (4)
where κ = κ(λ,M,Z−1/2ΣZ−1/2).
Proof. For (3), observe that:
λ·Tr((Σˆ +λZ)−1A) = λ·Tr(Z−1/2(Z−1/2ΣˆZ−1/2+λI)−1Z−1/2A)
= λ·Tr((Z−1/2ΣˆZ−1/2+λI)−1Z−1/2AZ−1/2)
∼ κ·Tr((Z−1/2ΣZ−1/2+κI)−1Z−1/2AZ−1/2)
(A)
= κ·Tr(Z−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2A)
= κ·Tr((Σ+κZ)−1A).
where (A) applies Lemma 36 (using the fact that since A and Z−1 have bounded operator norm, it
holds that Z−1/2AZ−1/2 has bounded operator norm).
For (4), observe that:
(cid:18)(cid:18) (cid:19) (cid:19)
(cid:16) (cid:17)−1
Tr(Σˆ(Σˆ +λZ)−1A) = Tr I −λZ1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2 A
(A)
(cid:18) (cid:19)
(cid:16) (cid:17)−1
= Tr(A)−λ·Tr Z−1/2ΣˆZ−1/2+λI Z−1/2AZ1/2
(B)
(cid:18) (cid:19)
(cid:16) (cid:17)−1
∼ Tr(A)−κ·Tr Z−1/2ΣZ−1/2+κI Z−1/2AZ1/2
(C)
(cid:18)(cid:18) (cid:19) (cid:19)
(cid:16) (cid:17)−1
= Tr I −κZ1/2 Z−1/2ΣZ−1/2+κI Z−1/2 A
(D)
= Tr(Σ(Σ+κZ)−1A)
(E)
where (A) and (E) follows from Claim 41, (B) and (D) use the fact that Tr(A) is bounded, and (C)
follows from Lemma 36 (using the fact that since A, Z, and Z−1 have bounded operator norm, it
holds that Z−1/2AZ1/2 has bounded operator norm).
59Lemma 38. Assume that D satisfies the Marčenko-Pastur property (Assumption 1). Let Z be
F
any positive definite matrix such that Z and Z−1 have bounded operator norm, and let A and B
have bounded operator norm. Let Σˆ = 1 (cid:80)M X XT be the sample covariance matrix from M i.i.d.
M i=1 i i
samples from X ,...,X ∼ D . Then it holds that:
1 M F
λ2Tr((Σˆ +λZ)−1A(Σˆ +λZ)−1B)
= λ2Tr(Z−1/2(Z−1/2ΣˆZ−1/2+λI)−1Z−1/2AZ−1/2(Z−1/2ΣˆZ−1/2+λI)−1B)
∼ κ2Tr((Σ+κZ)−1A(Σ+κZ)−1B)
1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1A)
+κ2 M Tr((Σ+κZ)−1Σ(Σ+κZ)−1B)
1− 1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1Σ)
M
where κ = κ(λ,M,Z−1/2ΣZ−1/2).
Proof. Let q =
M1 Tr(Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−2Z−1/2AZ−1/2)
.
1− 1 Tr(Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−2Z−1/2ΣZ−1/2)
Observe that: M
λ2Tr((Σˆ +λZ)−1A(Σˆ +λZ)−1B)
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
λ2Tr Z−1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2AZ−1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2B
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
= λ2Tr Z−1/2ΣˆZ−1/2+λI Z−1/2AZ−1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2BZ−1/2
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
∼ κ2Tr Z−1/2ΣZ−1/2+κI Z−1/2AZ−1/2 Z−1/2ΣZ−1/2+κI Z−1/2BZ−1/2
(A)
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
+κ2qTr Z−1/2ΣZ−1/2+κI Z−1/2ΣZ−1/2 Z−1/2ΣZ−1/2+κI Z−1/2BZ−1/2
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
= κ2Tr Z−1/2 Z−1/2ΣZ−1/2+κI Z−1/2AZ−1/2 Z−1/2ΣZ−1/2+κI Z−1/2B
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
+κ2qTr Z−1/2 Z−1/2ΣZ−1/2+κI Z−1/2ΣZ−1/2 Z−1/2ΣZ−1/2+κI Z−1/2B
(cid:16) (cid:17) (cid:16) (cid:17)
= κ2Tr (Σ+κZ)−1A(Σ+κZ)−1B +qκ2Tr (Σ+κZ)−1Σ(Σ+κZ)−1B ,
where(A)followsfromLemma36(usingthefactthatsinceA, B, Z, andZ−1 haveboundedoperator
norm, it holds that Z−1/2AZ1/2, Σ, and Z−1/2BZ1/2 have bounded operator norm).
We can simplify q as follows:
1 Tr(Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−2Z−1/2AZ−1/2)
q = M
1− 1 Tr(Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−2Z−1/2ΣZ−1/2)
M
1 Tr((Z−1/2ΣZ−1/2+κI)−1Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2AZ−1/2)
= M
1− 1 Tr((Z−1/2ΣZ−1/2+κI)−1Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2ΣZ−1/2)
M
1 Tr(Z−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2A)
= M
1− 1 Tr(Z−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2ΣZ−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2Σ)
M
1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1A)
= M .
1− 1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1Σ)
M
60Lemma 39. Assume that D satisfies the Marčenko-Pastur property (Assumption 1). Let Z be
F
any positive definite matrix such that Z and Z−1 have bounded operator norm. Let A and B have
bounded operator norm, and suppose also that Tr(AB) is bounded. Let Σˆ = 1 (cid:80)M X XT be the
M i=1 i i
sample covariance matrix from M i.i.d. samples from X ,...,X ∼ D . Then it holds that:
1 M F
Tr(Σˆ(Σˆ +λZ)−1A(Σˆ +λZ)−1ΣˆB) ∼ Tr(Σ(Σ+κZ)−1A(Σ+κZ)−1ΣB)+E, (5)
where:
1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1A) (cid:16) (cid:17)
E := M ·κ2Tr (Σ+κZ)−1Σ(Σ+κZ)−1ZBZ ,
1− 1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1Σ)
M
and κ = κ(λ,M,Z−1/2ΣZ−1/2).
Proof. Observe that:
Tr(Σˆ(Σˆ +λZ)−1A(Σˆ +λZ)−1ΣˆB)
(cid:16) (cid:17)T
= Tr(Σˆ(Σˆ +λZ)−1A Σˆ(Σˆ +λZ)−1 B)
(cid:32) (cid:33)
(cid:18)
(cid:16) (cid:17)−1
(cid:19) (cid:18)
(cid:16) (cid:17)−1
(cid:19)T
= Tr I −λZ1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2 A I −λZ1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2 B
(A)
(cid:32) (cid:33)
(cid:18)
(cid:16) (cid:17)−1
(cid:19)T
= Tr(AB)−λTr A Z1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2 B
(B)
(cid:18) (cid:19)
(cid:16) (cid:17)−1
−λTr Z1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2AB
(cid:32) (cid:33)
(cid:16) (cid:17)−1
(cid:18)
(cid:16) (cid:17)−1
(cid:19)T
+λ2Tr Z1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2A Z1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2 B
(cid:18) (cid:19)
(cid:16) (cid:17)−1
= Tr(AB)−λTr AZ−1/2 Z−1/2ΣˆZ−1/2+λI Z1/2B
(cid:18) (cid:19)
(cid:16) (cid:17)−1
−λTr Z1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2AB
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
+λ2Tr Z1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2AZ−1/2 Z−1/2ΣˆZ−1/2+λI Z1/2B
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
= Tr(AB)−λTr Σˆ +λZ ZBA −λTr Σˆ +λZ ABZ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(1) (2)
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
+λ2Tr Σˆ +λZ A Σˆ +λZ ZBZ
(cid:124) (cid:123)(cid:122) (cid:125)
(3)
where (A) follows from Claim 41, (B) uses that Tr(AB) is bounded,
For term (1) and term (2), we apply Lemma 37 to see that:
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)
λTr Σˆ +λZ ZBA ∼ κλTr (Σ+κZ)−1ZBA
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)
λTr Σˆ +λZ ABZ ∼ κTr (Σ+κZ)−1ABZ .
61For term (3), we apply Lemma 38 to see that
(cid:18) (cid:19)
(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
λ2Tr Σˆ +λZ A Σˆ +λZ ZBZ
(cid:16) (cid:17)
∼ κ2Tr (Σ+κZ)−1A(Σ+κZ)−1ZBZ
1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1A)
+κ2 M Tr(cid:0) (Σ+κZ)−1Σ(Σ+κZ)−1ZBZ(cid:1)
1− 1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1Σ)
M
(cid:16) (cid:17)
∼ κ2Tr (Σ+κZ)−1A(Σ+κZ)−1ZBZ +E
This means that:
(cid:16) (cid:17) (cid:16) (cid:17) (cid:16) (cid:17)
Tr Σˆ(Σˆ +λZ)−1A(Σˆ +λZ)−1Σˆ ∼ Tr(AB)−κTr (Σ+κZ)−1ZBA −κTr (Σ+κZ)−1ABZ
(cid:16) (cid:17)
+κ2Tr (Σ+κZ)−1A(Σ+κZ)−1ZBZ +E
= Tr(Σ(Σ+κZ)−1A(Σ+κZ)−1ΣB)+E,
(C)
where (C) uses an analogous analysis to the beginning of the proof.
Lemma 40. Assume that D satisfies the Marčenko-Pastur property (Assumption 1). Let Z be
F
any positive definite matrix such that Z and Z−1 have bounded operator norm, and let A and B
have bounded operator norm. Let Σˆ = 1 (cid:80)M X XT be the sample covariance matrix from M i.i.d.
M i=1 i i
samples from X ,...,X ∼ D . Then it holds that:
1 M F
(cid:16) (cid:17)
λTr (Σˆ +λZ)−1A(Σˆ +λZ)−1ΣˆB ∼ κTr(cid:0) (Σ+κZ)−1A(Σ+κZ)−1ΣB(cid:1) −E, (6)
where:
1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1A) (cid:16) (cid:17)
E := M ·κ2Tr (Σ+κZ)−1Σ(Σ+κZ)−1ZB
1− 1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1Σ)
M
and κ = κ(λ,N,Z−1/2ΣZ−1/2).
Proof. Observe that:
(cid:16) (cid:17)
λTr (Σˆ +λZ)−1A(Σˆ +λZ)−1ΣˆB
(cid:18) (cid:18) (cid:19) (cid:19)
(cid:16) (cid:17)−1
= λTr Z−1/2(Z−1/2ΣˆZ−1/2+λI)−1Z−1/2A I −λZ−1/2 Z−1/2ΣˆZ−1/2+λI Z1/2 B
(A)
(cid:16) (cid:17)
= λTr Z−1/2(Z−1/2ΣˆZ−1/2+λI)−1Z−1/2AB
(cid:18) (cid:19)
(cid:16) (cid:17)−1
−λ2Tr Z−1/2 Z−1/2ΣˆZ−1/2+λI Z−1/2AZ−1/2(Z−1/2ΣˆZ−1/2+λI)−1Z1/2B
(cid:18) (cid:19)
(cid:16) (cid:17) (cid:16) (cid:17)−1
= λTr (Σˆ +λZ)−1AB −λ2Tr Σˆ +λZ A(Σˆ +λZ)−1ZB
(cid:124) (cid:123)(cid:122) (cid:125)
(cid:124) (cid:123)(cid:122) (cid:125)
(1)
(2)
where (A) follows from Claim 41.
62For term (1), we apply Lemma 37 see that:
(cid:16) (cid:17)
λTr (Σˆ +λZ)−1AB ∼ κTr(cid:0) (Σ+κZ)−1AB(cid:1) .
For term (2), we apply Lemma 38 to see that
(cid:18) (cid:19)
(cid:16) (cid:17)−1
λ2Tr Σˆ +λZ A(Σˆ +λZ)−1ZB
(cid:16) (cid:17)
∼ κ2Tr (Σ+κZ)−1A(Σ+κZ)−1ZB
1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1A)
+κ2 M Tr(cid:0) (Σ+κZ)−1Σ(Σ+κZ)−1ZB(cid:1)
1− 1 Tr((Σ+κZ)−1Σ(Σ+κZ)−1Σ)
M
(cid:16) (cid:17)
∼ κ2Tr (Σ+κZ)−1A(Σ+κZ)−1ZB +E.
This means that:
(cid:16) (cid:17)
λTr (Σˆ +λZ)−1A(Σˆ +λZ)−1ΣˆB
(cid:16) (cid:17)
∼ κTr(cid:0) (Σ+κZ)−1AB(cid:1) +κ2Tr (Σ+κZ)−1A(Σ+κZ)−1ZB −E
(cid:18) (cid:18) (cid:19) (cid:19)
(cid:16) (cid:17)−1
= κTr Z−1/2(Z−1/2ΣZ−1/2+κI)−1Z−1/2A I −κZ1/2 Z−1/2ΣZ−1/2+κI Z−1/2 B −E
=
κTr(cid:0) (Σ+κZ)−1A(Σ+κZ)−1ΣB(cid:1)
−E,
(A)
where (A) uses an analogous analysis to the beginning of the proof.
The proofs of these results relied on the following basic matrix fact.
Claim 41. Let A be any matrix and let B be any symmetric positive definite matrix. Then it holds
that:
(cid:16) (cid:17)−1
A(A+λB)−1 = I −λB1/2 B−1/2AB−1/2+λI B−1/2.
Proof. Observe that:
A(A+λB)−1
(cid:16) (cid:17)−1
= AB−1/2 B−1/2AB−1/2+λI B−1/2
(cid:16) (cid:17)(cid:16) (cid:17)−1
= B1/2 B−1/2AB−1/2 B−1/2AB−1/2+λI B−1/2
(cid:16) (cid:17)(cid:16) (cid:17)−1 (cid:16) (cid:17)−1
= B1/2 B−1/2AB−1/2+λI B−1/2AB−1/2+λI B−1/2−B1/2λ B−1/2AB−1/2+λI B−1/2
(cid:16) (cid:17)−1
= I −λB1/2 B−1/2AB−1/2+λI B−1/2.
E Extension: Market-entry threshold with richer form for L∗
2
In this section, we modify the safety requirement to take into account the impact of dataset size N
and regularization parameter λ, and we extend our model and analysis of the market-entry threshold
63accordingly. We show that the characterization in Theorem 1 directly applies to this setting, and
we also show relaxed versions of Theorem 4 and Theorem 5. Altogether, these extended results
illustrate that our qualitative insights from Sections 3-4 hold more generally.
We define a modified approximation of the safety violation L˜ (β ,β ,D ,λ,N,α). This modified
2 1 2 F
approximation is defined analogously to L∗(β ,β ,D ,λ,N,α). To formalize this, we define a
1 1 2 F
deterministic equivalent Ldet for the safety violation to be
2
Ldet(β ,β ,D ,λ,N,α) := Ldet(β ,β ,D ,λ,N,1−α). (7)
2 1 2 F 1 2 1 F
It follows from Lemma 6 that L (βˆ(α,λ,X)) ∼ Ldet(β ,β ,D ,λ,N,α): here, we use the fact
2 2 1 2 F
that L (βˆ(α,λ,X)) is distributed identically to L (βˆ(1−α,λ,X)). Now, using this deterministic
2 1
equivalent, we define L˜ (β ,β ,D ,λ,N,α) = Ldet(β ,β ,D ,λ,N,α).
2 1 2 F 2 1 2 F
Using this formulation of L˜ , we define a modified market entry threshold where we replace
2
all instances of original approximation L∗ with the modified approximation L˜ . In particular, a
2 2
company C faces reputational damage if:
E L˜ (β ,β ,D ,α ) ≥ τ .
(β1,β2)∼DW 2 1 2 F C C
The company selects α ∈ [0.5,1] and λ ∈ (0,1) to maximize their performance subject to their safety
constraint, as formalized by the following optimization program:12
(α˜ ,λ˜ ) = argmin E [L∗(β ,β ,D ,λ,N ,α)] s.t. E [L˜ (β ,β ,D ,α)] ≤ τ .
C C α∈[0.5,1],λ∈(0,1) DW 1 1 2 F C DW 2 1 2 F C
We define the modified market-entry threshold as follows.
Definition 3. The modified market-entry threshold N˜∗(N ,τ ,τ ,D ,D ) is the minimum value
E I I E W F
of N ∈ Z such that E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≤ E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )].
E ≥1 DW 1 1 2 F E E E DW 1 1 2 F I I I
Inthissection,weanalyzethemodifiedmarketentrythresholdN˜∗(N ,τ ,τ ,D ,D ). Weshow
E I I E W F
an extension of Theorem 1 (Appendix E.1). We then derive a simplified version of the deterministic
equivalent Ldet (Appendix E.2). Finally, we show a weakened extension of Theorem 4 (Appendix
2
E.3) and a weakened extension of Theorem 5 (Appendix E.4). These weakened extensions derive
upper bounds (rather than tight bounds) on the modified market entry threshold, and also assume
that δ ≤ 1.
E.1 Extension of Theorem 1
We study the market entry N˜∗ threshold in the environment of Theorem 1 where the incumbent has
E
infinite data and the new company faces no safety constraint. We show that the modified market
entry threshold takes the same form as the market entry threshold in Theorem 1.
Theorem 42 (Extension of Theorem 1). Suppose that power-law scaling holds for the eigenvalues
and alignment coefficients, with scaling exponents γ,δ > 0 and correlation coefficient ρ ∈ [0,1), and
suppose that P = ∞. Suppose that the incumbent company has infinite data (i.e., N = ∞), and
I
that the entrant faces no constraint on their safety (i.e., τ = ∞). Suppose that the safety constraint
E
τ satisfies (1). Then, it holds that:
I
(cid:18) (cid:19)
N˜∗(∞,τ ,∞,D ,D ) = Θ (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)−2/ν ,
E I W F I
where L∗(ρ) = E [(β −β )TΣ(β −β )] = Θ(1−ρ), and where ν := min(2(1+γ),δ+γ).
DW 1 2 1 2
12Unlike in Section 2, there might not exist α∈[0.5,1] and λ∈(0,1) which satisfy the safety constraint, if N is
C
too small.
64Theorem42showsthatthequalitativeinsightsfromTheorem1—includingthatthenewcompany
can enter with finite data—readily extend to this setting.
To prove Theorem 42, we build on the notation and analysis from Appendix A. It suffices to
show that each company C will select α = α˜ and λ = λ˜ . This follows trivially for the entrant
C C C C
C = E since they face no safety constraint, and there is no different between the two settings. The
key ingredient of the proof is to compute α˜ and λ˜ for the incumbent (i.e., an analogue of Lemma
I I
12 in Appendix A).
To do this, we first upper bound the following function of the safety loss and performance loss
for general parameters λ and α.
Lemma 43. For any α and λ, it holds that:
(cid:113) (cid:113) (cid:113)
E [L (β(α,λ))]+ E [L (β(α,λ))] ≥ E [(β −β )TΣ(β −β )T].
DW 1 DW 2 DW 1 2 1 2
Proof. Note that:
(cid:113) (cid:113)
T := E [L (β(α,λ))]+ E [L (β(α,λ))]
DW 1 DW 2
(cid:113) (cid:113)
= (β −β(α,λ))TΣ(β −β(α,λ))+ (β −β(α,λ))TΣ(β −β(α,λ))
1 1 2 2
(cid:113)
= (λβ +(1−α)Σ(β −β ))TΣ(Σ+λI)−2(λβ +(1−α)Σ(β −β ))
1 1 2 1 1 2
(cid:113)
+ (λβ +αΣ(β −β ))TΣ(Σ+λI)−2(λβ +αΣ(β −β ))
2 2 1 2 2 1
(cid:113)
= (λβ +(1−α)Σ(β −β ))TΣ(Σ+λI)−2(λβ +(1−α)Σ(β −β ))
1 1 2 1 1 2
(cid:113)
+ (−λβ +αΣ(β −β ))TΣ(Σ+λI)−2(−λβ +αΣ(β −β )).
2 1 2 2 1 2
Now note that for any PSD matrix Σ′ and any distribution, note that the following triangle inequality
holds:
(cid:113) (cid:113) (cid:113)
E[(X +X )TΣ′(X +X )] ≤ E[XTΣ′X ]+ E[XTΣ′X ].
1 2 1 2 1 1 2 2
We apply this for X = λβ +(1−α)Σ(β −β ), X = −λβ +αΣ(β −β ), and distribution D .
1 1 1 2 2 2 1 2 W
This means that we can lower bound:
(cid:113)
T ≥ E [((Σ+λI)(β −β ))TΣ(Σ+λI)−2((Σ+λI)(β −β ))]
DW 1 2 1 2
(cid:113)
= E [(β −β ))TΣ(β −β ))]
DW 1 2 1 2
as desired.
Now, we are ready to compute α˜ and λ˜ for the incumbent.
I I
Lemma 44. Let L∗(ρ) = E [(β −β )TΣ(β −β )T]. Suppose that N = ∞, and suppose that the
DW 1 2 1 2
(cid:113)
I
safety constraint τ satisfies (1). Then it holds that α = min(τI,L∗(ρ)) , and λ = 0 is optimal for
I I L∗(ρ) I
the incumbent. Moreover, it holds that:
E [L∗(β ,β ,D ,λ˜ ,∞,α˜ )] = (cid:16)(cid:112) L∗(ρ)−(cid:112) min(L∗(ρ),τ )(cid:17)2 .
DW 1 1 2 F I I I
65Proof. First, we apply Lemma 46 with N = ∞ to see that:
E [L∗(β ,β ,D ,λ,∞,α)] = E [L (β(α,λ))]
DW 1 1 2 F DW 1
and
E [L∗(β ,β ,D ,λ,∞,α)] = E [L (β(α,λ))].
DW 2 1 2 F DW 2
(cid:113)
Let α∗ = min(τI,L∗(ρ)). By the assumption in the lemma statement, we know that:
L∗(ρ)
(cid:115)
E [L∗(β ,β ,D ,0.5)]
α∗ ≥ DW 2 1 2 F = 0.5.
L∗(ρ)
Observe that:
(cid:113)
(cid:112)
E [L (β(α∗,0))]+ min(τ ,L∗(ρ))
DW 1 I
(cid:113) (cid:113)
= E [L (β(α∗,0))]+ E [L (β(α∗,0))]
DW 1 DW 2
(cid:113) (cid:113)
= (1−α∗)2E [(β −β )TΣ(β −β )T]+ (α∗)2E [(β −β )TΣ(β −β )T]
DW 1 2 1 2 DW 1 2 1 2
(cid:113)
= E [(β −β )TΣ(β −β )T]
DW 1 2 1 2
Weshowthat(α˜ ,λ˜ ) = (α∗,0). Assumeforsakeofcontradictionthat(α,λ) ̸= (α∗,0)satisfiesthe
I I
safety constraint E [L˜ (β ,β ,D ,α)] ≤ min(τ ,L∗(ρ)) and achieves strictly better performance
DW 2 1 2 F I
loss:
E [L∗(β ,β ,D ,λ,∞,α)] < E [L∗(β ,β ,D ,0,∞,α∗)].
DW 1 1 2 F DW 1 1 2 F
Then it would hold that:
(cid:113) (cid:113) (cid:113)
(cid:112)
E [L (β(α,λ))]+ E [L (β(α,λ))] < E [L (β(α∗,0))]+ min(τ ,L∗(ρ))
DW 1 DW 2 DW 1 I
(cid:113)
= E [(β −β )TΣ(β −β )T],
DW 1 2 1 2
which contradicts Lemma 43.
To analyze the loss, note that:
E [L∗(β ,β ,D ,λ˜ ,∞,α˜ )]
DW 1 1 2 F I I
= E [L (β(α˜ ,λ˜ ))]
DW 1 I I
= (1−α˜ )2L∗(ρ)
I
(cid:112) (cid:112)
= ( L∗(ρ)− min(L∗(ρ),τ ))2
I
We now prove Theorem 42.
Proof of Theorem 42. We analyze (α˜ ,λ˜ ) first for the incumbent C = I and then for the entrant
C C
C = E.
Analysis of the incumbent C = I. By Lemma 44, we see that:
E [L∗(β ,β ,D ,λ˜ ,∞,α˜ )] = (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)2 .
DW 1 1 2 F I I I
66Analysis of the entrant C = E. This analysis follows identically to the analogous case in the
proof of Theorem 1, and we repeat the proof for completeness. Since the entrant faces no safety
constraint, the entrant can choose any α ∈ [0.5,1]. We apply Corollary 8 to see that:
E [L∗(β ,β ,D ,λ ,N,α )] = inf inf E [L∗(β ,β ,D ,λ,N,α)] = Θ(cid:0) N−ν(cid:1) ,
DW 1 1 2 F E E
α∈[0.5,1]λ>0
DW 1 1 2 F
which means that:
(cid:18) (cid:19)
(cid:16)(cid:112) (cid:112) (cid:17)−2/ν
N∗(∞,τ ,∞,D ,D ) = Θ L∗(ρ)− min(τ ,L∗(ρ)
E I W F I
as desired. We can further apply Claim 13 to see that L∗(ρ) = Θ(1−ρ).
E.2 Bounds on the excess loss for safety
We bound the excess loss α2L∗(ρ)−E [Ldet]. We assume that α ≥ 0.5 and we further assume
DW 2
that δ ≤ 1.
Lemma 45. Suppose that power scaling holds for the eigenvalues and alignment coefficients with
scaling γ > 0 and δ ∈ (0,1], and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞. Suppose
that α ≥ 0.5, λ ∈ (0,1), and N ≥ 1. Let Ldet := Ldet(β ,β ,D ,λ,N,α) be defined according to
2 2 1 2 F
(7). Let L∗(ρ) = E [(β −β )TΣ(β −β )]. Then it holds that:
DW 1 2 1 2
α2L∗(ρ)−E DW[Ld 2et] = O(cid:16) max(λ1+ν γ,N−ν)(cid:17)
and
(cid:32) − 1 (cid:33)
E DW[Ld 2et]−α2L∗(ρ) = O max(λ1+ν γ,N−ν)+(1−α)(1−ρ)min(λ N1+γ,N) ,
where ν = min(2(1+γ),δ+γ) = δ+γ.
To prove Lemma 45, we first simplify the deterministic equivalent Ldet(β ,β ,D ,λ,N,α) using
2 1 2 F
the assumptions from Section 2.3.
Lemma 46. Suppose that power scaling holds for the eigenvalues and alignment coefficients with
scaling γ,δ > 0 and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞. Suppose that λ ∈ (0,1),
and N ≥ 1. Let Ldet := Ldet(β ,β ,D ,λ,N,α) be defined according to (7). Let κ = κ(λ,N,Σ)
2 2 1 2 F
from Definition 2. Let L∗(ρ) = E [(β −β )TΣ(β −β )]. Then it holds that:
DW 1 2 1 2
(cid:88)P i−δ−1−γ (cid:88)P i−δ−2(1+γ)
E [Ldet]−L∗(ρ) = Q−1·κ2 +Q−12κα(1−α)(1−ρ)
DW 2 (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−12α(1−α)(1−ρ) ·
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
(cid:88)P i−δ−1−γ
−2α2κ(1−ρ) ,
i−1−γ +κ
i=1
where Q = 1− 1 (cid:80)P i−2−2γ .
N i=1 (i−1−γ+κ)2
67Proof. First,weapplyLemma26,coupledwiththefactthatLdet(β ,β ,D ,λ,N,α) := Ldet(β ,β ,D ,λ,N,1−
2 1 2 F 1 2 1 F
α), to see that:
(cid:88)P i−δ−1−γ
Q·E [Ldet] = κ2(1−2α2(1−ρ)) +α2L∗(ρ)
DW 2 (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+2κ(1−ρ)α(1−2α)
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+2α(1−ρ) ·(1−2α) ,
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
(cid:16) (cid:17)
whereQ = 1− 1 (cid:80)P i−2−2γ . Usingthat(Q−1−1)α2L∗(ρ) = Q−1 1 (cid:80)P i−2−2γ 2α2(1−
N i=1 (i−1−γ+κ)2 N i=1 (i−1−γ+κ)2
(cid:16) (cid:17)
ρ) (cid:80)P i−δ−1−γ , this means that:
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:32) (cid:88)P (cid:33)
E [Ldet]−α2L∗(ρ) = Q−1 2α2(1−ρ) i−δ−1−γ
DW 2 N (i−1−γ +κ)2
i=1 i=1
(cid:88)P i−δ−1−γ
+Q−1·κ2(1−2α2(1−ρ))
(i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+Q−12κ(1−ρ)α(1−2α)
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−12α(1−ρ) ·(1−2α)
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
By expanding some of these terms, we see that:
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P
E [Ldet]−α2L∗(ρ) = Q−12α2(1−ρ) · i−δ−1−γ
DW 2 N (i−1−γ +κ)2
i=1 i=1
(cid:88)P i−δ−1−γ (cid:88)P i−δ−1−γ
+Q−1·κ2 −Q−12α2(1−ρ)·κ2
(i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
(cid:88)P i−δ−2(1+γ) (cid:88)P i−δ−2(1+γ)
+Q−12κ(1−ρ)α(1−α) −Q−12κ(1−ρ)α2
(i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−12α(1−α)(1−ρ) ·
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
−Q−12α2(1−ρ) · .
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
68When we collect terms, we obtain:
(cid:88)P i−δ−1−γ (cid:88)P i−δ−2(1+γ)
E [Ldet]−α2L∗(ρ) = Q−1·κ2 +Q−12κ(1−ρ)α(1−α)
DW 2 (i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−12α(1−α)(1−ρ) ·
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
(cid:32) (cid:88)P i−δ−2(1+γ) (cid:88)P κ·i−δ−1−γ (cid:33)
−Q−12κ(1−ρ)α2 +
(i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:32) (cid:88)P (cid:88)P i−δ−2−2γ (cid:33)
+Q−12α2(1−ρ) · i−δ−1−γ −
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1 i=1
(cid:88)P i−δ−1−γ (cid:88)P i−δ−2(1+γ)
= Q−1·κ2 +Q−12κ(1−ρ)α(1−α)
(i−1−γ +κ)2 (i−1−γ +κ)2
i=1 i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−12α(1−α)(1−ρ) ·
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
(cid:32) (cid:88)P i−δ−1−γ (cid:33)
−Q−12κ(1−ρ)α2
(i−1−γ +κ)
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) i−δ−1−γ
+Q−12κα2(1−ρ) · .
N (i−1−γ +κ)2 i−1−γ +κ
i=1
Combining the last two terms gives us the desired statement.
Now, we are ready to prove Lemma 45.
Proof. For the first bound, we observe that:
α2L∗(ρ)−E [Ldet]
DW 2
(cid:88)P i−δ−1−γ
≤ 2α2κ(1−ρ)
(A) i−1−γ +κ
i=1
(cid:18) (cid:19)
min(1+γ,δ+γ)
= (B) O α2(1−ρ)κ 1+γ
(cid:16) ν (cid:17)
=
(C)
O κ1+γ
=
(D)
O(cid:16) max(λ1+ν γ,N−ν)(cid:17)
where (A) uses Lemma 46, (B) uses Lemma 33, (C) uses that δ ≤ 1 and ρ ∈ [0,1), and (D) uses
Lemma 35.
69For the second bound, we observe that:
E [Ldet]−α2L∗(ρ)
DW 2
(cid:88)P i−δ−1−γ
≤ Q−1·κ2
(A) (i−1−γ +κ)2
i=1
(cid:88)P i−δ−2(1+γ)
+Q−12κα(1−α)(1−ρ)
(i−1−γ +κ)2
i=1
1 (cid:32) (cid:88)P i−2−2γ (cid:33) (cid:88)P i−δ−2−2γ
+Q−12α(1−α)(1−ρ) ·
N (i−1−γ +κ)2 i−1−γ +κ
i=1 i=1
(cid:32) − 1 (cid:33)
min(2(1+γ),γ+δ) min(1+γ,γ+δ) κ 1+γ
= (B) O κ 1+γ +α(1−α)(1−ρ)κ 1+γ +α(1−α)(1−ρ) N
(cid:32) − 1 (cid:33)
γ+δ γ+δ κ 1+γ
=
(C)
O κ1+γ +(1−α)(1−ρ)κ1+γ +(1−α)(1−ρ)
N
(cid:32) − 1 (cid:33)
γ+δ κ 1+γ
= O κ1+γ +(1−α)(1−ρ)
N
(cid:32) − 1 (cid:33)
=
(D)
O
max(λ1+ν γ,N−ν)+(1−α)(1−ρ)min(λ N1+γ,N)
where (A) uses Lemma 46, (B) uses Lemma 33 and Lemma 34, (C) uses that δ ≤ 1 and α ≥ 0.5,
and (D) uses Lemma 35.
E.3 Extension of Theorem 4
We next study the market entry N˜∗ threshold in the environment of Theorem 4 where the incumbent
E
has finite data and the new company faces no safety constraint. We place the further assumption
that δ ≤ 1. We compute the following upper bound on the modified market entry threshold.
Theorem 47 (Extension of Theorem 4). Suppose that the power-law scaling holds for the eigenvalues
and alignment coefficients with scaling exponents γ > 0,δ ∈ (0,1] and correlation coefficient ρ ∈ [0,1),
and suppose that P = ∞. Assume that τ = ∞. Suppose that the safety constraint τ satisfies (1).
E I
Then we have that N˜∗ = N˜∗(N ,τ ,∞,D ,D ) satisfies:
E E I I W F

  O(N I) if N I ≤ G˜− I 21 ν(1−ρ)− 21 ν
 (cid:18) (cid:19)
N˜ E∗ :=   O N Iν+1 1 ·G˜− I 2(ν1 +1)(1−ρ)− 2(ν1 +1) if G˜ I− 21 ν(1−ρ)− 21 ν ≤ N I ≤ G˜− I 1 2− ν1 (1−ρ)1 2
 (cid:18) (cid:19)
    O G˜ I− ν1 if N I ≥ G˜− I 1 2− ν1 (1−ρ)1 2,
(cid:113)
where L∗(ρ) = E [(β − β )TΣ(β − β )] = Θ(1 − ρ), where α∗ = min(τI,L∗(ρ)) , where α˜ :=
DW 1 2 1 2 L∗(ρ)
(cid:112) (1−α∗)+(α∗)2, where G˜ = (1−α˜)2(1−ρ), and where ν = min(2(1+γ),γ +δ) = γ +δ.
I
Theorem 47 shows that the key qualitative finding from Theorem 4—that the new company can
enter with N = o(N ) data as long as the incumbent’s dataset size is sufficiently large—readily
E I
70extends to this setting. We note that the bound in Theorem 47 and the bound in Theorem 4 take
slightly different forms: the term G = ((cid:112) L∗(ρ)−(cid:112) min(L∗(ρ),τ ))2 = Θ((1 −α∗)2(1−ρ)) is
I I
replaced by G˜ = (1−α˜)2(1−ρ). We expect some of these differences arise because the bound in
I
Theorem 47 is not tight, rather than fundamental distinctions between the two settings. Proving a
tight bound on the modified market entry threshold is an interesting direction for future work.
To prove this, we compute a lower bound on the incumbent’s loss E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )].
DW 1 1 2 F I I I
Lemma 48. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ > 0,δ ∈ (0,1] and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞.
Assume that τ = ∞. Suppose that the safety constraint τ satisfies (1). Then we have that:
E I
E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )]
DW 1 1 2 F I I I

=      ΩΩ (cid:18)(cid:0) N NI− I−ν ν(cid:1) +ν 1 ·G˜ I2(νν +1)(1−ρ)2(νν +1)(cid:19) i if f GN ˜− II 2≤ 1 ν(G 1˜− I −21 ν ρ( )1 −− 21 ν ρ ≤)− N21 ν I ≤ G˜− I 1 2− ν1 (1−ρ)1 2

   Ω(cid:16) G˜ I(cid:17) if N
I
≥ G˜−
I
1 2− ν1 (1−ρ)1 2.
(cid:113)
where L∗(ρ) = E [(β − β )TΣ(β − β )] = Θ(1 − ρ), where α∗ = min(τI,L∗(ρ)) , where α˜ :=
DW 1 2 1 2 L∗(ρ)
(cid:112) (1−α∗)+(α∗)2, where G˜ = (1−α˜)2(1−ρ) and where ν = min(2(1+γ),γ +δ) = γ +δ.
I
Proof. By Corollary 8 and Lemma 35, we know that:
E DW[L∗ 1(β 1,β 2,D F,λ˜ I,N I,α˜ I)] = Ω(κ1+ν γ) = Ω(max(λ1+ν γ,N I−ν)).
Let C be an implicit constant13 such that:
δ,γ
E DW[L∗ 1(β 1,β 2,D F,λ˜ I,N I,α˜ I)] ≥ C δ,γmax(λ1+ν γ,N I−ν) (8)
By Lemma 45, there also exists an implicit constant C′ such that:
δ,γ
α2L∗(ρ)−E DW[Ld 2et(β 1,β 2,D F,λ,N I,α)] ≤ C δ′ ,γmax(λ1+ν γ,N I−ν). (9)
We now split into two cases: (1) C δ′ ,γE [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≥ (1−α∗)L∗(ρ), and (2)
C
δ,γ
DW 1 1 2 F I I I
C δ′ ,γE [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≤ (1−α∗)L∗(ρ).
C
δ,γ
DW 1 1 2 F I I I
Case 1: C δ′ ,γE [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≥ (1−α∗)L∗(ρ). It follows from (8) that:
C
δ,γ
DW 1 1 2 F I I I
E DW[L∗ 1(β 1,β 2,D F,λ˜ I,N I,α˜ I)] ≥ C δ,γmax(λ1+ν γ,N I−ν) ≥ C δ,γN I−ν.
Using the condition for this case, this implies that:
N ≤
(cid:18)
1
E [L∗(β ,β ,D ,λ˜ ,N ,α˜
)](cid:19)− ν1
I C DW 1 1 2 F I I I
δ,γ
(cid:32) (cid:33)−1
1 ν
≤ (1−α∗)L∗(ρ)
C′
δ,γ
(cid:16) (cid:17)
= O ((1−α˜)(1−ρ))− ν1
(cid:18) (cid:19)
= O G˜− 21 ν(1−ρ)− 21 ν .
I
13We need to introduce an implicit constant because of O() is permitted to hide constants that depend on δ and γ.
71This proves that N is up to constants within the first branch of the expression in the lemma
I
statement. Since the bound in the lemma statement only changes by constants (that depend on δ
and γ) between the first branch and second branch, this proves the desired expression for this case.
Case 2: C δ′ ,γE [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≤ (1−α∗)L∗(ρ). Note that α∗ = (cid:113) min(τI,L∗(ρ)) is the
C
δ,γ
DW 1 1 2 F I I I L∗(ρ)
mixture parameter that achieves the safety constraint in the infinite-data ridgeless setting. The
incumbent’s safety constraint means that:
E [Ldet(β ,β ,D ,λ˜ ,N ,α˜ )] ≤ (α∗)2L∗(ρ).
DW 2 1 2 F I I I
By (9), this implies that
(α˜ I)2L∗(ρ) ≤ C δ′
,γ
·max(λ1δ+ +γ γ,N I−δ−γ)+(α∗)2L∗(ρ).
Now, applying (8) and the assumption for this case, we see that:
C′
(α˜ )2L∗(ρ) ≤ δ,γ ·E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )]+(α∗)2L∗(ρ)
I C DW 1 1 2 F I I I
δ,γ
≤ (1−α∗)L∗(ρ)+(α∗)2L∗(ρ).
This implies that:
(cid:112)
α˜ ≤ (1−α∗)+(α∗)2.
I
Let α˜ := (cid:112) (1−α∗)+(α∗)2. Plugging this into Corollary 8, we see that:
E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )]
DW 1 1 2 F I I I
≥ inf inf E [L∗(β ,β ,D ,λ,N ,α)]
α∈[0.5,α˜]λ>0
DW 1 1 2 F I
(cid:18) (cid:19)
= Θ inf E [L∗(β ,β ,Σ,λ,N ,α˜)]
λ>0
DW 1 1 2 I
  Θ(cid:0) N I−ν(cid:1) if N I ≤ (1−α˜)− ν1 (1−ρ)− ν1
  (cid:18) (cid:16) (cid:17)− ν (cid:19)
= Θ (1−α˜N )(I
1−ρ)
ν+1 if (1−α˜)− ν1 (1−ρ)− ν1 ≤ N
I
≤ (1−α˜)−2+ νν (1−ρ)− ν1


 Θ((1−α˜)2(1−ρ)) if N
I
≥ (1−α˜)−2+ νν (1−ρ)− ν1 ,

=     Θ Θ(cid:0) (cid:18)N NI− I−ν ν(cid:1) +ν 1 ·G˜ I2(νν +1)(1−ρ)2(νν +1)(cid:19) i if f N G˜− II 2≤ 1 ν(G 1˜− I −21 ν ρ( )1 −− 21 ν ρ ≤)− N21 ν I ≤ G˜− I 1 2− ν1 (1−ρ)1 2

   Θ(cid:16) G˜ I(cid:17) if N
I
≥ G˜−
I
1 2− ν1 (1−ρ)1 2.
The statement follows in this case.
We are now ready to prove Theorem 47.
Proof of Theorem 47. We analyze (α˜ ,λ˜ ) first for the incumbent C = I and then for the entrant
C C
C = E. Like in the theorem statement, let L∗(ρ) = E [(β −β )TΣ(β −β )] = Θ(1−ρ) (Claim
13) and G := ((cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ)))2, and ν
=DW min(1 2(1+2 γ),δ+1
γ).
2
I I
72Analysis of the incumbent C = I. We apply Lemma 48 to see that:
E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )]
DW 1 1 2 F I I I

=     Ω Ω(cid:0) (cid:18)N NI− I−ν ν(cid:1) +ν 1 ·G˜ I2(νν +1)(1−ρ)2(νν +1)(cid:19) i if f N G˜− II 2≤ 1 ν(G 1˜− I −21 ν ρ( )1 −− 21 ν ρ ≤)− N21 ν I ≤ G˜− I 21− ν1 (1−ρ)1 2 .

   Ω(cid:16) G˜ I(cid:17) if N
I
≥ G˜−
I
1 2− ν1 (1−ρ)1 2.
Analysis of the entrant C = E. Since the entrant faces no safety constraint, the entrant can
choose any α ∈ [0.5,1]. We apply Corollary 7 to see that:
E [L∗(β ,β ,D ,λ˜ ,N,α˜ )] = inf inf E [L∗(β ,β ,D ,λ,N,α)] = Θ(cid:0) N−ν(cid:1) ,
DW 1 1 2 F E E
α∈[0.5,1]λ>0
DW 1 1 2 F
which means that:

  O(N I) if N I ≤ G˜− I 21 ν(1−ρ)− 21 ν
 (cid:18) (cid:19)
N E∗(N I,τ I,∞,D W,D F) =   O N Iν+1 1 ·G˜− I 2(ν1 +1)(1−ρ)− 2(ν1 +1) if G˜− I 21 ν(1−ρ)− 21 ν ≤ N I ≤ G˜− I 1 2− ν1 (1−ρ)1 2
 (cid:18) (cid:19)
    O G˜− I ν1 if N I ≥ G˜− I 1 2− ν1 (1−ρ)1 2
as desired.
E.4 Extension of Theorem 5
We next study the market entry N˜∗ threshold in the environment of Theorem 5 where the incumbent
E
has infinite data and the new company faces a nontrivial safety constraint. We place the further
assumption that δ ≤ 1. We compute the following upper bound on the modified market entry
threshold.
Theorem 49 (Extension of Theorem 5). Suppose that the power-law scaling holds for the eigenvalues
and alignment coefficients with scaling exponents γ > 0, δ ∈ (0,1], and correlation coefficient
ρ ∈ [0,1), and suppose that P = ∞. Suppose that the safety constraints τ and τ satisfy (2). Then
I E
it holds that N˜∗ = N˜∗(∞,τ ,τ ,D ,D ) satisfies:
E E I E W F
(cid:18) (cid:18) (cid:18) (cid:19)(cid:19)(cid:19)
N˜ E∗ := O max D˜− ν1 ,D˜−ν+ ν1 G E1 2(1−ρ)1 2 + 1 2G I − 1 2G E ,
where L∗(ρ) = E [(β −β )TΣ(β −β)] = Θ(1−ρ), where ν = min(2(1+γ),δ+γ) = δ+γ, where
DW 1 2 1
(cid:16)(cid:112) (cid:112) (cid:17)2 (cid:16)(cid:112) (cid:112) (cid:17)2
G := L∗(ρ)− min(τ ,L∗(ρ)) and G := L∗(ρ)− min(τ ,L∗(ρ)) , and where:
I I E E
(G −G )2
D˜ := α∗ ·(G −G )− I E .
E I E 4·L∗(ρ)
Theorem 49 shows that the key qualitative finding from Theorem 5—that the new company can
enter with finite data, as long as they face a strictly weaker safety constraint than the incumbent
company—readily extends to this setting. We note that the bound in Theorem 49 and the bound in
73Theorem 5 take slightly different forms. Some of these differences are superficial: while the bound
in Theorem 49 contains two—rather than three—regimes, the third regime in Theorem 5 does not
exist in the case where δ ≤ 1. Other differences are more substantial: for example, the bound in
Theorem 49 scales with D˜ while the bound in Theorem 5 scales with D. However, we expect some
of this difference arises because the bound in Theorem 49 is not tight, rather than fundamental
distinctions between the two settings. Proving a tight bound on the modified market entry threshold
is an interesting direction for future work.
We compute an upper bound on the number of data points N that the new company needs to
E
achieve at most loss (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)2 on performance.
I
Lemma 50. Suppose that the power-law scaling holds for the eigenvalues and alignment coefficients
with scaling exponents γ > 0,δ ∈ (0,1] and correlation coefficient ρ ∈ [0,1), and suppose that P = ∞.
Suppose that the safety constraints τ and τ satisfy (1). For sufficiently large constant C , if
I E δ,γ
(cid:18) (cid:18) (cid:19)(cid:19)
N E ≥ C δ,γ ·max D˜− ν1 ,D˜−ν+ ν1 G E21 (1−ρ)1 2 + 21 G I − 1 2G E ,
then it holds that:
E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≤ G ,
DW 1 1 2 F E E E I
where L∗(ρ) = E [(β −β )TΣ(β −β)] = Θ(1−ρ), where ν = min(2(1+γ),δ+γ) = δ+γ, where
DW 1 2 1
(cid:16)(cid:112) (cid:112) (cid:17)2 (cid:16)(cid:112) (cid:112) (cid:17)2
G := L∗(ρ)− min(τ ,L∗(ρ)) and G := L∗(ρ)− min(τ ,L∗(ρ)) , and where:
I I E E
(G −G )2
D˜ := α∗ ·(G −G )− I E .
E I E 4·L∗(ρ)
Proof. It suffices to construct α˜ and λ˜ such that
E [L˜ (β ,β ,D ,λ˜,N ,α˜)] ≤ τ
DW 2 1 2 F E E
and
E [L∗(β ,β ,D ,λ˜,N ,α˜)] ≤ G
DW 1 1 2 F E I
(cid:18) (cid:18) (cid:18) (cid:19)(cid:19)(cid:19)
for N E = Ω max D˜− ν1 ,D˜−ν+ ν1 G E1 2(1−ρ)1 2 + 21G I − 1 2G E .
To define α˜ and λ˜, it is inconvenient to work with the following intermediate quantities. Let
α∗ = (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)2 and let α∗ = (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)2 . We define an
E E I I
error function:
− 1
f(N E,α,λ) :=
max(λ1+ν
γ,N
E−ν)+(1−α)(1−ρ)min(λ N1+γ,N E)
E
We define:
1 1 α∗ −α∗
α˜ := α∗ + (1−α∗)2− (1−α∗)2 = α∗+ E I.
E 2 E 2 I I 2
and
λ˜ := inf f(N ,α˜,λ).
E
λ∈(0,1)
74At these values of α˜ and λ˜ and under the condition on N , observe that:
E
f(N ,α˜,λ˜) =
Θ(cid:32) max(cid:32) N−ν,(cid:18)
N
E
(cid:19)− ν+ν 1(cid:33)(cid:33)
E E (1−α˜)(1−ρ)
   − ν 
ν+1
N
= ΘmaxN−ν, E  
  E G E1 2(1−ρ)1 2 + 1 2G I + 1 2G E 
(cid:16) (cid:17)
= O D˜ ,
where the implicit constant can be reduced by increasing the implicit constant on N .
E
The remainder of the analysis boils down to showing that E [L˜ (β ,β ,D ,λ˜,N ,α˜)] ≤ τ
DW 2 1 2 F E E
and E [L∗(β ,β ,D ,λ˜,N ,α˜)] ≤ G . To show this, we first derive an error function and bound
DW 1 1 2 F E I
these losses in terms of the error function.
Bounding E [L˜ (β ,β ,D ,λ˜,N ,α˜)] ≤ τ . Observe that:
DW 2 1 2 F E E
E [L˜ (β ,β ,D ,λ˜,N ,α˜)]
DW 2 1 2 F E
(cid:32) − 1 (cid:33)
=
(A)
α˜2L∗(ρ)+O max(λ1+ν γ,N E−ν)+(1−α)(1−ρ)min(λ N1+γ,N E)
E
1 1
= (α∗ + (1−α∗)2− (1−α∗)2)L∗(ρ)+O(f(N ,α˜))
E 2 E 2 I E
(cid:18) ((1−α∗)2−(1−α∗)2)2 (cid:19)
≤ (α∗)2L∗(ρ)+ I E −α∗((1−α∗)2−(1−α∗)2) L∗(ρ)+D˜
E 4 E I E
(G −G )2 (G −G )2
= τ + I E −α∗(G −G )α∗ ·(G −G )− I E
E 4·L∗(ρ) E I E E I E 4·L∗(ρ)
= τ
E
where (A) follows from Lemma 45. This gives us the desired bound.
Bounding E [L∗(β ,β ,D ,λ˜,N ,α˜)]. Observe that:
DW 1 1 2 F E
E [L∗(β ,β ,D ,λ˜,N ,α˜)]
DW 1 1 2 F E
(cid:32) − 1 (cid:33)
=
(A)
(1−α˜)2L∗(ρ)+O max(λ1+ν γ,N E−ν)+(1−α)(1−ρ)min(λ N1+γ,N E)
E
1 1
≤ (1−α∗ − (1−α∗)2+ (1−α∗)2)2L∗(ρ)+O(f(N ,α˜))
E 2 E 2 I E
(cid:18) ((1−α∗)2−(1−α∗)2)2 (cid:19)
≤ (1−α∗)2+ I E −(1−α∗)((1−α∗)2−(1−α∗)2) L∗(ρ)+D˜
E 4 E I E
(G −G )2 (G −G )2
≤ G +(G −G )(1−α∗)+ I E +α∗ ·(G −G )− I E
E I E E 4L∗(ρ) E I E 4·L∗(ρ)
= G .
I
where (A) uses Theorem 9, coupled with the fact that δ ≤ 1 (which means that ν′ = ν, so the
mixture finite data error is subsumed by the finite data error) and coupled with Lemma 35. This
gives us the desired bound.
75We are now ready to prove Theorem 49.
Proof of Theorem 49. We analyze (α˜ ,λ˜ ) first for the incumbent C = I and then for the entrant
C C
C = E. Like in the theorem statement, let L∗(ρ) = E [(β − β )TΣ(β − β)] = Θ(1 − ρ),
DW 1 2 1
let ν = min(2(1 + γ),δ + γ) = δ + γ, let G := (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)2 and G :=
I I E
(cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ))(cid:17)2 , and let:
E
(G −G )2
D˜ := α∗ ·(G −G )− I E .
E I E 4·L∗(ρ)
Analysis of the incumbent C = I. To compute α˜ and λ˜ , we apply Lemma 44. The assumption
I I
τ ≥ E [L (β ,β ,Σ,0.5)] in the lemma statement can be rewritten as τ ≥ 0.25L∗(ρ), which
I DW 2 1 2 I
guarantees the assumptions in Lemma 44 are satisfied. By Lemma 44, we see that:
E [L∗(β ,β ,D ,λ˜ ,∞,α˜ )] = (cid:16)(cid:112) L∗(ρ)−(cid:112) min(τ ,L∗(ρ)(cid:17)2 = G .
DW 1 1 2 F I I I I
Analysis of the entrant C = E. We apply Lemma 50 to see for sufficiently large constant C , if
δ,γ
(cid:18) (cid:18) (cid:19)(cid:19)
N E ≥ C δ,γ ·max D˜− ν1 ,D˜−ν+ ν1 G E21 (1−ρ)1 2 + 21 G I − 1 2G E ,
then it holds that:
E [L∗(β ,β ,D ,λ˜ ,N ,α˜ )] ≤ G = E [L∗(β ,β ,D ,λ˜ ,∞,α˜ )].
DW 1 1 2 F E E E I DW 1 1 2 F I I
This means that:
(cid:18) (cid:18) (cid:18) (cid:19)(cid:19)(cid:19)
N˜ E∗ = O max D˜− ν1 ,D˜−ν+ ν1 G E1 2(1−ρ)1 2 + 1 2G I − 1 2G E
as desired.
76