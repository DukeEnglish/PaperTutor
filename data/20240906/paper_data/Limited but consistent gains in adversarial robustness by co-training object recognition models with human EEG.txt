Limited but consistent gains in adversarial
robustness by co-training object recognition
models with human EEG
Manshan Guo1,2,4 , Bhavin Choksi1,2 , Sari Sadiya1,2,3 ,
Alessandro T. Gifford4 , Martina G. Vilas1,2,5 ,
Radoslaw M. Cichy4⋆ , and Gemma Roig1,2,⋆
1 DepartmentofComputerScience,GoetheUniversity,FrankfurtamMain,Germany
{m.guo,choksi,Saba-Sadiya,roignoguera}@em.uni-frankfurt.de
2 The Hessian Center for Artificial Intelligence (hessian.AI), Darmstadt, Germany
3 Frankfurt Institute for Advanced Studies (FIAS), Frankfurt, Germany
4 Department of Education and Psychology, Freie Universität Berlin, Berlin,
Germany
{nikiguo93,rmcichy}@zedat.fu-berlin.de,alessandro.gifford@gmail.com
5 Ernst Strüngmann Institute for Neuroscience, Frankfurt am Main, Germany
martina.vilas@esi-frankfurt.de
Abstract. Incontrasttohumanvision,artificialneuralnetworks(ANNs)
remainrelativelysusceptibletoadversarialattacks.Toaddressthisvul-
nerability,effortshavebeenmadetotransferinductivebiasfromhuman
brains to ANNs, often by training the ANN representations to match
their biological counterparts. Previous works relied on brain data ac-
quired in rodents or primates using invasive techniques, from specific
regions of the brain, under non-natural conditions (anesthetized ani-
mals), and with stimulus datasets lacking diversity and naturalness. In
thiswork,weexploredwhetheraligningmodelrepresentationstohuman
EEGresponsestoarichsetofreal-worldimagesincreasesrobustnessto
ANNs.Specifically,wetrainedResNet50-backbonemodelsonadualtask
of classification and EEG prediction; and evaluated their EEG predic-
tionaccuracyandrobustnesstoadversarialattacks.Weobservedsignif-
icant correlation between the networks’ EEG prediction accuracy, often
highest around 100 ms post stimulus onset, and their gains in adversar-
ial robustness. Although effect size was limited, effects were consistent
across different random initializations and robust for architectural vari-
ants.WefurtherteasedapartthedatafromindividualEEGchannelsand
observed strongest contribution from electrodes in the parieto-occipital
regions. The demonstrated utility of human EEG for such tasks opens
up avenues for future efforts that scale to larger datasets under diverse
stimuli conditions with the promise of stronger effects.
Keywords: HumanEEG·Adversarialrobustness·Biologicallyinspired
robustness
⋆ jointly directed work
4202
peS
5
]GL.sc[
1v64630.9042:viXra2 Guo et al.
1 Introduction
Despite the remarkable performance of artificial neural networks (ANNs) in ob-
ject recognition [15,22,34], ANNs are sensitive to small so-called adversarial
perturbations in the inputs [37]. Since the initial discovery of this vulnerabil-
ity, the field has moved rapidly to devise various adversarial defenses against
it [7,27,40].
Incontrast,humanperceptionisrobusttoadversarialattacksthataredetri-
mentalforANNs[10,41].Thisinspirestheideathataddingmorebio-inspiredele-
mentsintoANNsmighthelpalleviatetheirsensitivitytoadversarialattacksand
makethemmorerobust.Thesebiologicalinductivebiasesoftenarearchitecture-
based,optimization-basedorboth[4,9,17,20,26].Studieshavealsodirectlycon-
strainedtheANNrepresentationswiththeirbiologicalcounterparts,oftenusing
neuraldatafromrodentsornon-humanprimatesundernon-ecologicalconditions
as regularizers [8,11,24,25,28,29,32,35]. These attempts have led to promising,
but modest gains in the robustness of the resulting ANNs [11,29,32]. Yet, the
cost and the practical challenges associated with acquiring such data also limits
the diversity of stimuli used, often restricting the images from small datasets
like CIFAR in grayscale, even for approaches relying on fMRI brain data [30].
Thus, in this work, we used a large-scale EEG dataset collected on diverse
real-world images with the aim to improve ANNs robustness to adversarial at-
tacks. Specifically, we experimented with the EEG dataset collected by [14] on
participants viewing imagesfrom theTHINGSdataset [16].We reportimprove-
ments against adversarial attacks which, though modest, were observed consis-
tently across different random initializations of various architectural variants.
These robustness gains were positively correlated with the ability of the mod-
els to predict EEG at early time points. Interestingly, as already observed in
previous work, we also report similar robustness gains when using shuffled ver-
sionsoftheEEGdata.Whileourresultsdonotgivestate-of-the-artrobustness,
theyprovideimportantpointersguidingfutureresearch.Wefurtheranalyzethe
EEG dataset across individual channels to investigate any channel-specific ef-
fects. We observe that mid-level channels (PO7, PO3, POz, PO4, PO8), though
notaswell-predictedbytheANNsastheearlychannels(Oz,O1,O2),arebetter
(positively) correlated with the gains in robustness. To further facilitate investi-
gationsintothesemethods,wepubliclyprovidethecodetothebroaderscientific
community6.
2 Related work
Various efforts have aimed to imbue deep neural networks (ANNs) with human-
like cognitive abilities by training them using brain data. Khosla et al. [19]
showcased that ANNs optimized to predict fMRI activity in the fusiform face
area (FFA) and extrastriate body area (EBA) could detect ‘faces’ and ‘bodies’,
6 Code available at: https://github.com/cvai-roig-lab/eeg_cotraining_
robustnessAdversarial Robustness Gains via EEG Co-Training 3
despite lacking direct exposure to such images during training. Fu et al. [13] il-
lustratedthataligningCNNrepresentationswithhumanfMRIdatacanimprove
model’s performance in video emotion recognition tasks.
Among these, some studies have focused specifically on improving the ad-
versarial robustness of object recognition models using brain data. Li et al. [24]
recorded mice’s neural response in primary visual cortex (V1) with photon-
scans and then, along with classification, use it to penalize the representations
ofResNet18[21],resultinginreducedvulnerabilitytowhite-boxadversarialper-
turbations and gaussian noise.
Federer et al. [11] used publicly available recordings from V1 in monkeys
using micro-electrode arrays [6] and similarly penalized representations of VGG
with RSA, observing a brain-like response to white-box adversarial noise and
label corruption. In a similar fashion, Safarani et al. [32] first jointly trained
VGG19 for classification and predicting neural data collected in monkeys’ V1,
enhancing the models’ robustness against 14 image distortions. Besides, they
showed that their co-trained models were sensitive to salient regions of objects,
reminiscent of V1’s role in detecting object borders and bottom-up map.
Pirlot et al. [29] argued that the concurrent methods used for penalizing the
representationscouldbelimited,andinsteadproposedaDeepCanonicalCorre-
lation Analysis (DCCA)-based regularization, observing a reduction of vulner-
ability against adversarial noise. Dapello et al. [8] employed Centered Kernel
Alignments (CKA) to penalize representations, leveraging monkeys’ data in In-
feriortemporalcortex(IT)toimproverobustnessagainstwhite-boxattacksand
align with human behavior error patterns. Based on the findings from Stringer
etal[36]that,regardlessoftheinput,theeigenspectrumofcovariancematrixof
the neural code (in mice’s visual cortex) followed a power law, Nassar et al. [28]
inquired whether a similar constraint on the ANN representations might help
in enhancing their robustness. They found that, when implemented on smaller
convolutional neural networks, their proposed spectral regularization improved
robustness against L -FGSM and Projected Gradient Descent attacks [27].
∞
Unlike ours, most studies have restricted themselves to using brain data
collectedfromnon-humananimalsusingcostlyinvasivetechniques.Wenotethat
a contemporary study took a similar rationale to ours and introduced a multi-
layeralignmentframeworktoalignANNrepresentationswithhumanEEG[25].
Using the same EEG dataset, they trained an additional multi-layer module to
predict image categories and human EEG from CORnet-S features (pretrained
on ImageNet). While they tested their networks on FGSM attacks, which are
known to be quite weak and prone to gradient-masking [38], their main focus
was to demonstrate the utility of the learned representations for neuroscience—
to better explain fMRI and behavioral data.
3 Methods
Dataset We used a publicly available dataset containing images and corre-
sponding EEG recordings from 10 subjects viewing images from the THINGS4 Guo et al.
Fig.1: Paradigm for improving adversarial robustness via co-training with
human EEG: We first trained dual-task learning (DTL) models with original and
shuffled EEG data and then evaluated their robustness against various adversarial
attacks. We trained four clusters of ResNet50 backbone models, each incorporating a
differentindependentEEGpredictor:DenseLayers(CNN),RecurrentNeuralNetworks
(RNN), Transformer, and Attention layers. Finally, we measured the relationship be-
tween adversarial robustness gain and EEG prediction accuracy.
database [14,16]. The training set included 16,540 natural images across 1,654
object categories, with each category containing 10 images presented in 4 sep-
arate runs. We split the training set into 9:1 split for training and validation,
allocating 9 images per category for training (14,886 images total) and 1 im-
age per category for validation (1,654 images total). The raw EEG signals were
epoched from 200ms before to 800ms after stimulus onset and down-sampled to
100Hz. Seventeen channels were selected, including ‘Pz’, ‘P3’, ‘P7’, ‘O1’, ‘Oz’,
‘O2’, ‘P4’, ‘P8’, ‘P1’, ‘P5’, ‘PO7’, ‘PO3’, ‘POz’, ‘PO4’, ‘PO8’, ‘P6’, and ‘P2’,
which record signals from the occipital and parietal cortex where the visual sig-
nals are the strongest. Further details on EEG-image pair preprocessing are in
Appendix A.1.
Architectures and training The DTL networks consisted of an image classi-
fication branch (a ResNet50 backbone) and an EEG prediction branch. Along
with certain layers that were shared from the classification branch, the EEG
prediction branch comprised of an independent component of either dense lin-
ear layers (CNN), recurrent layers (RNN), Transformer, or attention layers that
were appended to the ResNet backbone. Overall 24 models (see Appendix A.2
for additional details) were trained for two objectives—classification and EEG
prediction. For the classification branch, 1654 object-categories were used. For
EEG prediction, MSE loss was applied to predict the EEG data consisting of
100timepoints(outputofsize1image 17channels 100tps).Tobalancethe
× ×
lossesbetweenthesetasks,weappliedthefollowingtotallossfunctionfrom[18]:
1 1
L(W,δ ,δ )= L (W)+ L (W)+logδ +logδ . (1)
1 2 2δ2 1 2δ2 2 1 2
1 2Adversarial Robustness Gains via EEG Co-Training 5
Here,L andL representtheEEGpredictionandimageclassificationlosses,
1 2
respectively, with 1 and 1 as loss coefficients. These parameters, along with
2δ2 2δ2
1 1
the model weights W were updated using the Adam optimizer with a learning
rate of 5e-6 and a weight decay of 0.0. The image classification branch was
pre-trained on ImageNet, and the EEG prediction branch was initialized with
three different training seeds (0, 17, and 337). Each model was trained for 200
epochs with a batch size of 64. As control experiments, we also trained the
networks on three simulated EEG datasets obtained by shuffling the original,
and randomly drawing from a geometrical or normal distribution. The models
trained with such data are labeled as DTL-shuffled, DTL-random, and DTL-
random-normal and were contrasted with those trained on original EEG data
(DTL-real).Additionaldetailsregardingallthearchitecturesandmodeltraining
can be found in Appendix A.2.
EEG prediction evaluation Following[14],weevaluatedtheEEGprediction
results by measuring Pearson correlation between the predicted and the actual
EEG. A PCC matrix (of shape 17 100) was constructed where each element
×
represented the linear correlation between the predicted and actual EEG. We
then averaged across the channel dimension to get a global value. Results were
averaged across the 10 subjects and models initialized with three random seeds.
Further details are available in Appendix A.3.
Adversarial robustness evaluation and Robustness gain Adversarial per-
turbations are image transformations capable of fooling ANNs while remaining
imperceptible for humans. To assess the adversarial robustness of our models,
we employed Foolbox [31] to create adversarial versions of the 1654 original
validation images under different attack strengths ϵ. In particular, 1654 adver-
sarial examples with each ϵ value were fed into each DTL model to obtain the
the top-1 classification accuracy, denoted as acc (ϵ). Similarly, we obtained
DTL
acc (ϵ) for the baseline model–the ResNet50 model trained for classifica-
baseline
tion. The adversarial robustness gain was defined as Gain (ϵ)=acc (ϵ)
DTL DTL
−
acc (ϵ). We applied L - and L -norm bounded untargeted projected gra-
baseline 2 ∞
dient descent (PGD) [27], and L Carlini & Wagner (C&W) attack [3], as de-
2
scribed in Appendix A.3.
Correlation between adversarial robustness gain and EEG prediction
We co-trained 24 architectures on EEG from 10 subjects using 3 training seeds,
resulting in a total of 24 10 3 = 720 samples for correlation analysis. The
× ×
mean adversarial robustness gain Avg_Gain was computed by averaging
DTL
Gainn (ϵ) across subjects and training seeds (0 n 720) as well as attack
DTL ≤ ≤
strength ϵ. To identify significant time points (tps) contributing to robustness
gain, we averaged PCC(ci,tps) across all channels (ci, channel index) and time
points(tps)withinanoptimalslidingwindowsize,resultinginAvg_PCC_tps,
which denotes mean prediction accuracy of all channels within the window. The
slidingwindowsize wasoptimized toencompassas manysignificanttimepoints
as possible, further details of which are provided in Appendix A.4.6 Guo et al.
A EEG contributors to robustness gain B Best contributor to robustness gain: EEG within 0.09s to 0.14s timeframe
across time points
C Standard evaluation of EEG prediction D Adversarial Robustness Gain v.s. Attack strength (Best Model)
Fig.2: Adversarial robustness gain was correlated with EEG prediction(A)
correlationvaluebetweenmeanadversarialrobustnessgain(Avg_Gain )andmean
DTL
EEGpredictionaccuracy(Avg_PCC_tps)peakedat0.09s(B)Adversarialrobustness
gainsacrossallthethreeattacksweresignificantlycorrelatedwithpredictionaccuracy
of EEG from 0.09s to 0.14s. The correlation values R2 correspond to the peak R2 in
(A). Colors denote architecture type and markers denote if the features used for EEG
prediction were from only the 4th block, both the 3rd and 4th block (via concatenat-
ing/averaging of features from 3rd and 4th block, all 4 blocks, the last 3 blocks...),
or other blocks excluding the 4th. Blue squares represent integrating 3rd and 4th
block features for EEG prediction, which generally achieved higher Avg_Gain
DTL
andAvg_PCC_tps.(C)EEGpredictionofourmostrobustmodel(shownredarrow
in B) using Pearson correlation coefficients. The correlation around 100ms is signifi-
cant(p<0.05,Bonferronicorrected).(D)Adversarialrobustnessgain(Gain (ϵ))of
DTL
themodeldenotedin(B)alongwiththecontrolsco-trainedonshuffledandrandomly
generated EEG. Shaded regions represent the standard error over training seeds and
subjects. ).
Afteridentifyingthesesignificanttimepoints,weinvestigatedkeyelectrodes
bysimilarlymeasuringcorrelationbetweenrobustnessgainandmeanprediction
accuracy per channel across critical time points.
4 Results
Adversarial robustness gains were positively correlated with the mod-
els’ EEG prediction We first investigated if there is a relationship between
the model’s EEG prediction ability and its gains in adversarial robustness. For
this, we measured the correlation between the gains in adversarial robustness
(Gain (ϵ)) of the 720 models considered here and their EEG prediction
DTL
(AVG_PCC_tps); see Figure 2A. We observed significant positive correlation
values (between 0.53-0.61, p-values < 1e-6) implying that the robustness of the
models scaled with the ability of the networks to better capture the statisticsAdversarial Robustness Gains via EEG Co-Training 7
A B C
0.7 Noise Ceiling Lower 0.8 NZ Nose 0.6 L L2 in f P PG GD D L2 C&W
Noise Ceiling Upper F9 AF7 AF Fp 31 AFp FZ Z F Ap F2 4 AF8 F10 FT9 FT7F7 FC5F5 FCF 33 FF C1 1FF Cz ZFF c2 2FF C4 4F F6 C6F F8 C8 FC10
T9 T7 C5 C3 C1 Cz C2 C4 C6 T8 T10
TP9 P9TP7 P7CP P5 P O5 7CP P3 P3 O3C PP 11 PC P OP z zZ PC 2 PP O2 4P4CP P4 OP 86CP P6 8CP8 P10CP10
0.0 PzP3P7 O1OzO2P4P8P1P5 PO7 PO3 POz PO4 PO8P6P2 0.08 O1 O IZZ O2 0.0 PzP3P7 O1OzO2P4P8P1P5 PO7 PO3 POz PO4 PO8P6P2
EEG Channels EEG Channels
Fig.3:ContributionofindividualEEGelectrodesinnetworkrobustness(A)
The PCC values across channels, calculated as the correlation between the predicted
andtherealEEGfrom0.09sto0.14s.Theloweranduppernoiseceilingsarecalculated
asper[14]andaredenotedinblackandredlinesrespectively.(B)A64-channelEEG
top down brain view with the 17 electrodes covering occipital and parietal cortex
colored with the PCC values obtained (from (A)) for each electrode. (C) Correlation
values between the robustness gains (for each attack) and PCC values for each EEG
channel
fromtheneuraldata.Wenotethatsimilarresultswereobtainedby[9]albeitfor
neural data from individual neurons in the macaque brain. Concerning the role
of architecture, we observed that evaluations that combined the features from
boththe3rdand4thblockobtainedgoodresultsforbothadversarialrobustness
and EEG prediction.
We further illustrate the robustness gains of our most robust model (in Fig-
ure2BandD).Thisnetwork(shownwitharedarrowinFigure2B)concatenated
the features from both the 3rd and 4th block. We observed highest correlations
of 0.32 around 100 ms post-stimulus onset (Figure 2C), that is at the time
of highest discriminability in the EEG data [14]. In Figure 2D, we show the
robustness of this model against all the attacks used in our analysis. We also
include the robustness gains obtained after training the model with the control
(shuffled and random) versions of EEG . While these also showed some gains in
robustness (as also reported in previous works), the model trained with the real
EEG showed the highest robustness gains. While the gains are modest—a clear
limitation of our results and similar to those reported in earlier studies—they
arenonethelesssurprisinggiventhehighstrengthsoftheattacks(epsilonbudget
of 1. in L2 norm). Moreover, they demonstrate the potential for the utility of
human EEG for rendering robustness.
Electrodes from mid-level EEG channels contribute most strongly to
robustness Tofindout which EEG channels mostly contributed to robustness,
we first determined the EEG channels that were best predicted after our dual-
task training. We measured the correlation between the original and predicted
EEG,andobservedthatthemodelsbestpredictedthedatafromearlyoccipital
slennahc ssorca
CCP
CCP noitalerroC8 Guo et al.
channels (Oz, O1, O2) with the group of parieto-occipital channels (PO7, PO3,
PO4, PO8, POz) being second best (Figure 3A). These EEG channels overlay
the visual cortex (see Figure 3B), consistent with the origin of the observed
signals [14].
Butdothesechannelsactuallycontributetotherobustnessofthenetworks?
Toascertainthat,wemeasuredthecorrelationsbetweentherobustnessgainsfor
each attack and the PCC values for each individual channel (Figure 3C). While
the channels in the early visual areas seemed to be best predicted, those in the
parieto-occipital region (from electrodes PO7, PO3, PO4, PO8, POz) showed
the highest correlation values, indicating that it were the statistics from these
channels that particularly aided in enhancing the robustness of the networks.
This suggests that brain signal from the later visual processing stages in the
human brain contribute more to the robustness than earlier processing stages.
5 Discussion and Conclusion
In this study, we explored the effectiveness of human EEG to render robustness
to ANNs. Specifically, we co-trained the ANNs to predict human EEG signals
in addition to image classification, and tested their robustness to adversarial
perturbations. We observed consistent robustness gains across different variants
of the networks. Our investigations revealed a positive correlation between a
model’s robustness and its ability to predict the EEG. We further teased apart
the contribution from individual EEG channels, and observed that though the
channels overlaying the early visual cortex were best predicted (with Oz even
reaching the upper estimates of the noise ceilings), the ones in the parieto-
occipital region correlated better with the gains in adversarial robustness.
OurworkvalidatestheuseofhumanEEGdataforenhancingtherobustness
of ANNs which, compared to intracranial recordings that were often used pre-
viously, is cheaper and easier to collect. Given that there is an ongoing trend in
NeuroAI[1,2,5,23]tocollectmassivedatasets,ourmethodscouldnotonlyben-
efitfromthenewdatasets,butalsoinformfuturedatacollectionprocess.Future
works could investigate if larger EEG datasets, collected with different stimulus
conditions, say from the auditory domain, can similarly help in improving the
robustness of artificial neural networks.
As reported in previous works, the robustness gain was consistent, yet mod-
est. This could be because of the exact methods that we used to regularize our
networks, as also suggested by [29], or could be the inherent limitations of this
approach in itself. Like earlier works, we found that the control (shuffled and
random) versions of the EEG, and thus the mere statistics of the signal, also
helped in rendering robustness to the ANNs. Indeed, this consistent observa-
tion,nowobservedacrossintra-andextracranialneuralactivity,deservesfuture
scientificinquiryinitsownright.Exactlywhat(statistical)elementsoftheneu-
ral activity are the networks utilizing to improve their robustness? Can we use
these over conventional initialization methods to improve robustness of ANNs?
These questions raise the need and guide future research efforts.Adversarial Robustness Gains via EEG Co-Training 9
Acknowledgements
This project was funded by the German Research Foundation (DFG) - DFG
Research Unit FOR 5368 (GR) awarded to Gemma Roig, Deutsche Forschungs-
gemeinschaft(DFG;CI241/1-1,CI241/3-1,andCI241/7-1)awardedtoRadoslaw
Cichy,andaEuropeanResearchCouncil(ERC)startinggrant(ERC-2018-STG
803370) awarded to Radoslaw Cichy. We are grateful for access to the comput-
ing facilities of the Center for Scientific Computing at Goethe University and
Freie universität Berlin. M. Guo is supported by a PhD stipend from the China
Scholarship Council (CSC).
References
1. Cneuromod. https://www.cneuromod.ca, accessed: 2024-07-19
2. Allen,E.J.,St-Yves,G.,Wu,Y.,Breedlove,J.L.,Prince,J.S.,Dowdle,L.T.,Nau,
M., Caron, B., Pestilli, F., Charest, I., et al.: A massive 7t fmri dataset to bridge
cognitive neuroscience and artificial intelligence. Nature neuroscience 25(1), 116–
126 (2022)
3. Carlini, N., Wagner, D.: Towards evaluating the robustness of neural networks
(2017)
4. Choksi, B., Mozafari, M., Biggs O’May, C., Ador, B., Alamia, A., VanRullen, R.:
Predify: Augmenting deep neural networks with brain-inspired predictive coding
dynamics. Advances in Neural Information Processing Systems 34, 14069–14083
(2021)
5. Cichy, R.M., Roig, G., Andonian, A., Dwivedi, K., Lahner, B., Lascelles, A.,
Mohsenzadeh, Y., Ramakrishnan, K., Oliva, A.: The algonauts project: A plat-
form for communication between the sciences of biological and artificial intelli-
gence. arXiv preprint arXiv:1905.05675 (2019)
6. Coen-Cagli,R.,Kohn,A.,Schwartz,O.:Flexiblegatingofcontextualinfluencesin
natural vision. Nature neuroscience 18(11), 1648–1655 (2015)
7. Cohen, J., Rosenfeld, E., Kolter, Z.: Certified adversarial robustness via random-
ized smoothing. In: international conference on machine learning. pp. 1310–1320.
PMLR (2019)
8. Dapello, J., Kar, K., Schrimpf, M., Geary, R., Ferguson, M., Cox, D.D., DiCarlo,
J.:Aligningmodelandmacaqueinferiortemporalcortexrepresentationsimproves
model-to-human behavioral alignment and adversarial robustness. bioRxiv pp.
2022–07 (2022)
9. Dapello,J.,Marques,T.,Schrimpf,M.,Geiger,F.,Cox,D.,DiCarlo,J.J.:Simulat-
ingaprimaryvisualcortexatthefrontofcnnsimprovesrobustnesstoimageper-
turbations. Advances in Neural Information Processing Systems 33, 13073–13087
(2020)
10. Elsayed, G., Shankar, S., Cheung, B., Papernot, N., Kurakin, A., Goodfellow, I.,
Sohl-Dickstein,J.:Adversarialexamplesthatfoolbothcomputervisionandtime-
limited humans. Advances in neural information processing systems 31 (2018)
11. Federer, C., Xu, H., Fyshe, A., Zylberberg, J.: Improved object recognition using
neuralnetworkstrainedtomimicthebrain’sstatisticalproperties.NeuralNetworks
131, 103–114 (2020)10 Guo et al.
12. Fu, J., Liu, J., Jiang, J., Li, Y., Bao, Y., Lu, H.: Scene segmentation with dual
relation-aware attention network. IEEE Transactions on Neural Networks and
Learning Systems 32(6), 2547–2560 (2020)
13. Fu, K., Du, C., Wang, S., He, H.: Improved video emotion recognition with align-
ment of cnn and human brain representations. IEEE Transactions on Affective
Computing pp. 1–15 (2023). https://doi.org/10.1109/TAFFC.2023.3316173
14. Gifford,A.T.,Dwivedi,K.,Roig,G.,Cichy,R.M.:Alargeandricheegdatasetfor
modeling human visual object recognition. NeuroImage 264, 119754 (2022)
15. He,K.,Zhang,X.,Ren,S.,Sun,J.:Deepresiduallearningforimagerecognition.In:
Proceedings of the IEEE conference on computer vision and pattern recognition.
pp. 770–778 (2016)
16. Hebart,M.N.,Dickter,A.H.,Kidder,A.,Kwok,W.Y.,Corriveau,A.,VanWicklin,
C.,Baker,C.I.:Things:Adatabaseof1,854objectconceptsandmorethan26,000
naturalistic object images. PloS one 14(10), e0223792 (2019)
17. Huang,Y.,Dai,S.,Nguyen,T.,Bao,P.,Tsao,D.Y.,Baraniuk,R.G.,Anandkumar,
A.:Brain-inspiredrobustvisionusingconvolutionalneuralnetworkswithfeedback.
In:RealNeurons{\&}HiddenUnits:Futuredirectionsattheintersectionofneu-
roscience and artificial intelligence@ NeurIPS 2019 (2019)
18. Kendall, A., Gal, Y., Cipolla, R.: Multi-task learning using uncertainty to weigh
losses for scene geometry and semantics. In: Proceedings of the IEEE conference
on computer vision and pattern recognition. pp. 7482–7491 (2018)
19. Khosla,M.,Wehbe,L.:High-levelvisualareasactlikedomain-generalfilterswith
strong selectivity and functional specialization. bioRxiv pp. 2022–03 (2022)
20. Konkle, T., Alvarez, G.A.: Cognitive steering in deep neural networks via long-
range modulatory feedback connections. In: Thirty-seventh Conference on Neural
Information Processing Systems (2023)
21. Kriegeskorte, N., Mur, M., Bandettini, P.A.: Representational similarity analysis-
connectingthebranchesofsystemsneuroscience.Frontiersinsystemsneuroscience
p. 4 (2008)
22. Krizhevsky,A.,Sutskever,I.,Hinton,G.E.:Imagenetclassificationwithdeepcon-
volutional neural networks. In: Pereira, F., Burges, C., Bottou, L., Weinberger,
K. (eds.) Advances in Neural Information Processing Systems. vol. 25. Curran
Associates, Inc. (2012), https://proceedings.neurips.cc/paper_files/paper/
2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
23. Lahner,B.,Dwivedi,K.,Iamshchinina,P.,Graumann,M.,Lascelles,A.,Roig,G.,
Gifford,A.T.,Pan,B.,Jin,S.,RatanMurty,N.A.,etal.:Boldmoments:modeling
shortvisualeventsthroughavideofmridatasetandmetadata.bioRxivpp.2023–
03 (2023)
24. Li,Z.,Brendel,W.,Walker,E.,Cobos,E.,Muhammad,T.,Reimer,J.,Bethge,M.,
Sinz, F., Pitkow, Z., Tolias, A.: Learning from brains how to regularize machines.
Advances in neural information processing systems 32 (2019)
25. Lu, Z., Wang, Y., Golomb, J.: Realnet: Achieving more human brain-like vision
viahumanneuralrepresentationalalignment.In:ICLR2024WorkshoponRepre-
sentational Alignment (2024), https://openreview.net/forum?id=BN9WE9pOSD
26. Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q.: Foveation-based mechanisms
alleviate adversarial examples. arXiv preprint arXiv:1511.06292 (2015)
27. Madry,A.,Makelov,A.,Schmidt,L.,Tsipras,D.,Vladu,A.:Towardsdeeplearning
models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 (2017)
28. Nassar, J., Sokol, P., Chung, S., Harris, K.D., Park, I.M.: On 1/n neural repre-
sentationandrobustness.AdvancesinNeuralInformationProcessingSystems33,
6211–6222 (2020)Adversarial Robustness Gains via EEG Co-Training 11
29. Pirlot, C., Gerum, R.C., Efird, C., Zylberberg, J., Fyshe, A.: Improving the accu-
racyandrobustnessofcnnsusingadeepccaneuraldataregularizer.arXivpreprint
arXiv:2209.02582 (2022)
30. Rakhimberdina,Z.,Liu,X.,Murata,T.:Strengtheningrobustnessunderadversar-
ial attacks using brain visual codes. IEEE Access 10, 96149–96158 (2022)
31. Rauber,J.,Brendel,W.,Bethge,M.:Foolbox:Apythontoolboxtobenchmarkthe
robustness of machine learning models. arXiv preprint arXiv:1707.04131 (2017)
32. Safarani, S., Nix, A., Willeke, K.F., Cadena, S.A., Restivo, K., Denfield, G., To-
lias, A.S., Sinz, F.H.: Towards robust vision by multi-task learning on monkey
visual cortex. In: Beygelzimer, A., Dauphin, Y., Liang, P., Vaughan, J.W. (eds.)
AdvancesinNeuralInformationProcessingSystems(2021),https://openreview.
net/forum?id=3KhhJxaufVF
33. Schwartz, D., Toneva, M., Wehbe, L.: Inducing brain-relevant bias in natural lan-
guage processing models. Advances in neural information processing systems 32
(2019)
34. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
image recognition. arXiv preprint arXiv:1409.1556 (2014)
35. Sinz, F.H., Pitkow, X., Reimer, J., Bethge, M., Tolias, A.S.: Engineering a less
artificial intelligence. Neuron 103, 967–979 (2019)
36. Stringer, C., Pachitariu, M., Steinmetz, N., Carandini, M., Harris, K.D.: High-
dimensionalgeometryofpopulationresponsesinvisualcortex.Nature571(7765),
361–365 (2019)
37. Szegedy,C.,Zaremba,W.,Sutskever,I.,Bruna,J.,Erhan,D.,Goodfellow,I.,Fer-
gus, R.: Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199
(2013)
38. Tramer,F.,Carlini,N.,Brendel,W.,Madry,A.:Onadaptiveattackstoadversarial
example defenses. Advances in neural information processing systems 33, 1633–
1645 (2020)
39. Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,L.,Gomez,A.N.,Kaiser,
Ł., Polosukhin, I.: Attention is all you need. Advances in neural information pro-
cessing systems 30 (2017)
40. Wang, Y., Sun, T., Li, S., Yuan, X., Ni, W., Hossain, E., Poor, H.V.: Adversarial
attacks and defenses in machine learning-empowered communication systems and
networks: A contemporary survey. IEEE Communications Surveys & Tutorials
(2023)
41. Zhou,Z.,Firestone,C.:Humanscandecipheradversarialimages.Naturecommu-
nications 10(1), 1334 (2019)12 Guo et al.
A Appendix
A.1 EEG-Images pairs
EEG-Image pre-processing The raw EEG signals were first epoched into tri-
als ranging from 200ms before the stimulus onset (denoted as -0.2s) to 800ms
after the stimulus onset (denoted as 0.8s) and later down-sampled to 100Hz.
17 channels overlying occipital and parietal cortex where the visual signals
are strongest were finally selected. Consequently, our EEG data matrix for
model training is of shape (14,886 images 4 trials 17 EEG channels
× × ×
100EEGtps(timepoints)) and our EEG data matrix for model validation is of
shape (1654 images 4 trails 17 EEG channels 100 EEG tps). As EEG
× × ×
signals are noisy, we averaged EEG data across the trial dimension and normal-
ized it across the temporal dimension with Z-score. All the image stimuli were
normalized and resized to 3 224 224pixels.
× ×
A.2 Dual task learning (DTL)
Architecture InCNNcluster,weconcatenatedoraveragedoutputfromdifferent
ResNet50-blocks in the shared net and then used fully connected layers to map
from image features to EEG signals directly. In RNN cluster, shallow RNNs
where feedback were realized with Resnet-like skip connections, or Long short-
term memory (LSTM) units were integrated with the shared net, as recurrence
is capable of capturing temporal dynamics and patterns in time-series data.
In Transformer cluster, 6 layers of transformer encoders with 32 multi-heads,
dropout value of 0.5 and embedding dimension of 256 were combined with the
shared net, as transformer architectures have been shown to be beneficial for
fMRIandMEGprediction[33].InAttentionlayercluster,2self-attentionlayers
were considered. One is a self-attention layer in [39]. We used 4 multi-heads and
anembeddingdimensionof256afteroptimizationexperiments.Anotherutilized
the position attention modules (PAM) and channel attention modules (CAM)
used in [12]. We followed the default settings. All the 24 architectures from the
4 clusters are included in Table 1. Some architectures from the 4 clusters are
depicted in Figure 5, Figure 4 and Figure 6.Adversarial Robustness Gains via EEG Co-Training 13
+ +
256 3r2 d56 Bloc×k6 (Laye10 r2 34 ) 1024 512 512 4thBloc×k3 (Layer42 )048 2048 Avgpool L 1*a 1b 6e 5l 4
+ +
Co64nv1 1stBl6 o4 c×6 k43 (L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4 (La5 y12 er2) 55612
FC
1*256 L 1*S 5T 1M 2 FC
EEG
1*1700
(a) RNN cluster with long-short-term-memory (LSTM) units. We labeled it with
RNN (LSTM)_Bk2.Afully-connectedlayerwasusedtotransformthe2rdResNet50
Blockoutputintoavectorof1×256,afterwhichaLSTMunitwasutilizedtomapfrom
imagefeaturestoEEG.
+ +
256 3r2 d56 Blo28 c×k6(Laye10 r2 34
)
218024 512 512 4thBloc×k3(Layer42 )048 2048
Avgpool
L1*a1b6e5l4
+ +
Co64nv1 1stBl6 o4 c×6 k43(L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4(La5 y12 er2) 512
+ +
256 256 1024 1024 512 512 2048 Av2 g0 p48
ool
E1*E1G700
(b) RNNclusterwithResNet-likefeedbackconnection.WelabeleditwithRNN_Bk2.
TheinputtotheRNNwasthe2rdResNet50Blockoutput.
Convolutional layer + Skip connection Fully-connected layer
Batch normalization layer Pooling layer Resnet block & Feature integration
(c) Legend.
Fig.4: 2 architectures in RNN cluster14 Guo et al.
EEG
1*1700
+ + + +
Co64nv1 1stBl6 o4 c×6 k43 (L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4 (La5 y12 er2) 512
256 3r2 d56 Bloc×k6 (Laye10 r2 34
)
1024 512 512 4thBloc×k3 (Layer42 )048 2048
Avgpool
Label
1*1654
(a) Architecture of CNN_Bk4 in CNN cluster. The input to the fully-connected layer
wasthe4thResNet50Blockoutput.
Label
1*1654
Avgpool
+ + + +
256 3r2 d56 Bloc×k6 (Laye10 r2 34
)
1024 512 512 4thBloc×k3 (Layer42 )048 2048
Co64nv1 1stBl6 o4 c×6 k43 (L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4 (La5 y12 er2) 512
coF nea catFu tC er ne ation E 1*E 1G 700
(b) Architecture of CNN_Bk3,4 in CNN cluster. It first extracted the 3rd and 4th
Blockfeaturesandused2fully-connectedlayerstotransformthesefeaturesdimensionto
be 1×256, respectively. The input to the last fully-connected layer for EEG prediction
wasobtainedbyconcatenatingthetwotransformedfeatures(ofdimension:1×512)and
theoutputdimensionofthelastfully-connectedlayeris1×1700(EEGdimension).
L1*a1b6e5l4
Avgpool
+ + + +
Co64nv1 1stBl6 o4 c×6 k43(L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4(La5 y12 er2) 512
256 3r2 d56 Bloc×k6(Laye10 r2 34
)
1024 512 512 4thBloc×k3(Layer42 )048 2048
FAfC evaetruargees
E1*E1G700
(c)OnearchitecturesimilartoCNN_Bk3,4butaveragingthe3rdand4thblockfeatures
forEEGprediction.WelabeleditasCNN(avg)_Bk3,4.Itfirstextractedthe3rdand
4thBlockfeaturesandused2fully-connectedlayerstotransformthesefeaturesdimension
to be 1×256, respectively. The input to the last fully-connected layer was obtained by
averagingthetwotransformedfeatures(ofdimension:1×256)andoutputdimensionof
thelastfully-connectedlayeris1×1700(EEGdimension).
Fig.5: 3 architectures in CNN cluster.Adversarial Robustness Gains via EEG Co-Training 15
E1*E1G700
+ + + +
Co64nv1 1stBl6 o4 c×6 k43(L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4(La5 y12 er2)512
256 3r2 d56 Bloc×k6(Laye10 r2 34
)
1024 512 512 4thBloc×k3(Layer42 )048 2048
Avgpool
conF 1ce *aa 4tt 0eu 9nr 6ae tion
L1*a1b6e5l4
(a) One architecture in Attention layer cluster using position attention module (PAM)
and channel attention module (CAM) in the dual attention network. Features extracted
fromthesharednet(lastpoolinglayerinResNet50)werefedintoPAMandCAMmodules
respectively. The input dimension was 1×2048 and the output from CAM or PAM was
1×2048.Thesefeatureswerethenconcatenated(ofdimension:1×4096)andfedintoa
denselayerforEEGprediction(ofdimension:1×1700).WelabeleditasAtt_Bk4.The
inputtoindependentEEGpredictionnetwasthe4thResNet50Blockoutput.
Label
1*1654
Avgpool
+ + + +
256 3r2 d56 Bloc×k6 (Laye10 r2 34
)
1024 512 512 4thBloc×k3 (Layer42 )048 2048
Co64nv1 1stBl6 o4 c×6 k43 (L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4 (La5 y12 er2) 512
coF nea catFu tC er ne ation M 1H *u e 5al 1t d 2i- E 1*E 1G 700
(b) Another architecture in Attention layer cluster using a multi-head layer to predict
EEG. We labeled it with Att(concat)_Bk3,4. The input to the multi-head layer was
obtainedbyconcatenatingthe3rdand4thBlock(ofdimension:1×512).
Label
+ + + + Avgpool 1*1654
256 3r2 d56 Bloc×k6 (Laye10 r2 34
)
1024 512 512 4thBloc×k3 (Layer42 )048 2048
Co64nv1 1stBl6 o4 c×6 k43 (L2 a5 y6 er1)256 2n1 d28 B12 l8 oc×k4 (La5 y12 er2) 55612
FC
EEG
1*1700
(c) OnearchitectureinTransformerclusterusingTransformerencoderswith6layers,32
multi-heads,embeddingdimensionof256andoutputdimensionof1700.Welabeleditas
Trans_Bk4.TheinputtotheTransformerencoderwas4thBlockoutput.
Fig.6: 2 architectures in Attention layer cluster and 1 architecture in Transformer.16 Guo et al.
Model training [18] used the total loss function in EquationEquation (2) to
balance the loss updating during dual task learning.
1 1
L(W,δ ,δ )= L (W)+ L (W)+logδ +logδ (2)
1 2 2δ2 1 2δ2 2 1 2
1 2
Where L and L were EEG prediction and image classification loss, respec-
1 2
tively. 1 and 1 werelosscoefficients. 1 , 1 ,L andL wereupdatedusing
2δ2 2δ2 2δ2 2δ2 1 2
1 1 1 1
Adam optimizer, with a learning rate of 5e-6 and a weight decay of 0.0. The
learning rate and weight decay values were optimized with cross validation. W
denoted weights of model. The image classification branch was pre-trained on
Imagenet and the independent net of EEG prediction branch were initialized
with 3 different pre-chosen training seeds (0, 17 and 337).
A.3 Evaluation of EEG prediction and adversarial robustness
EEG prediction evaluation Giventhehierarchicalvisualprocessinginthebrain,
EEG signals at different time points may capture activities in different regions.
WeusedPearsoncorrelationanalysistoevaluateEEGpredictionsatvarioustime
pointsusing1654imagesfromthevalidationset.ThePearsoncorrelationcoeffi-
cient(PCC)ateachtimepointwascomputedasfollows:(1)Byloopingthrough
the channel and temporal dimension, we measured the PCC between predicted
EEG and biological EEG at different channel index (ci) and time points. Con-
sequently, we obtained a PCC array of size 17 100, denoted as PCC(ci,tps).
×
(2) We averaged the PCC(ci,tps) across the channel dimension and obtained
PCC(pts), which denoted linear relationship between predicted and biological
EEG at different time points. Here, pts [ 0.02s, 0.01s,...,0.07s,0.08s]. The
∈ − −
formula for PCC was given as follows: PCC = cov(signal_1,signal_2) , where
σ1,σ2
cov denoted the covariance while σ and σ denoted the standard deviation of
1 2
signal_1 and signal_2.
AdversarialexamplesgeneratedwithPGD ProjectedGradientDescent,orPGD,
iteratively constructs adversarial examples as follows :
xt+1 =Proj (xt+αsgn( L(θ,xt,y))) (3)
x+S x
∇
where θ is the parameters of models, xt is the input and y is the associated
label.L(θ,xt,y)isthelossofmodeltrainingand L(θ,xt,y)isthegradientof
x
∇
lossLwithrespecttoinputx.αisthegradientstepsize.tisthenumberofsteps
foriteration.xtandxt+1areadversarialexamplesbeforeandafternextiteration,
respectively.TheProjisanoperatortoconstructxt+1withinspacex+S,suchas
l ball or l norm ball around x. In our setting, t was 50 and 40 for l -bounded
∞ 2 2
PGD and l -bounded PGD, respectively. In l -constrained PGD, the attack
∞ ∞
strengthϵ [1e−5,2e−5,3e−5,4e−5,5e−5,6e−5,7e−5,8e−5,1e−4,3e−4,5e−4,7e−4,8e−4
∈
,1e−3,8e−3,1e−2]andthestepsizerelativetoϵwas0.01/0.3.Inthel -constrained
2
PGD,theattackstrengthϵ [1e−3,5e−3,7e−3,1e−2,2e−2,3e−2,5e−2,7e−2,1e−1
∈
,2e−1,3e−1,5e−1,7e−1,1.0] and the step size relative to ϵ was set to 0.025.Adversarial Robustness Gains via EEG Co-Training 17
AdversarialexamplesgeneratedwithCarlini&Wagner(C&W)attack C&W at-
tack formulates the generation of adversarial examples as an optimization prob-
lem, finding the smallest perturbations to the input data that causes misclassi-
fication of the target model. C&W attack defines the objective function J(x′)
as follows:
′ ′ ′
J(x )=α dist(x,x )+β loss(f(x ),y) (4)
· ·
Wherexistheoriginalimage;x′ istheperturbedimage;InthecaseofL2C&W
attack, dist(x,x′) measures the perturbation using the l norm. loss(f(x′),y)
2
represents the misclassification loss of target model f on the perturbed input
with respect to the target class y. α and β are weights to balance the dist(x,x′)
and loss(f(x′),y). The C&W attack iteratively adjusts the perturbations to
improve the chances of misclassification while keeping the perturbations imper-
ceptible.Thusthetermdist(x,x′)isminimizedandloss(f(x′),y)ismaximized.
Gradient descent is used for optimization. The perturbation is updated until it
convergedtowardsanexamplesx′ =x′ η ′J(x′),whereηisthestepsize.The
− ·∇x
attack strength ϵ [1e−5,7e−5,1e−4,7e−4,1e−3,1e−2,1e−1,3e−1,5e−1,7e−1,
∈
9e−1,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0] and the step size relative to ϵ
was 0.01.
A.4 Mean adversarial robustness gain and mean EEG prediction
accuracy
MeanadversarialrobustnessgainandmeanEEGpredictionaccuracywereused
to measure the relationship between adversarial robustness gain and EEG pre-
diction accuracy. We trained 24 architectures from all 4 clusters on EEG of 10
subjects with 3 training seeds. As a result, we had totally 24 10 3 = 720
× ×
sample models for analysis.
Mean adversarial robustness gain Avg_Gain For each sample model n
DTL
(0 n 720), we first computed Avg_Gainn which was the averaged value
≤ ≤ DTL
of Gainn (ϵ) across selected attack strength. In C&W, Gain (ϵ) used for
DTL DTL
Avg_Gainn calculation included those obtained under attack strength ϵ
DTL ∈
[5e−1,7e−1,9e−1,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0].Inl -constrained
∞
PGD, Gain (ϵ) used for Avg_Gainn calculation included those obtained
DTL DTL
under attack strength ϵ [8e−5,1e−4,3e−4,5e−4,7e−4,8e−4,1e−3,8e−3,1e−2
∈
,1e−1].Inl -constrainedPGD,weconsideredtheattackstrengthϵ [7e−2,1e−1
2
∈
,2e−1,3e−1,5e−1,7e−1,1.0]. We selected high ϵ values because under high at-
tack strength, robust models would perform much better than fragile ones in
classifying adversarial examples, which enabled us to better quantify relation-
ship between EEG prediction accuracy and robustness gain. We finally had
720 Avg_Gainn values and the Avg_Gain was computed by averaged
DTL DTL
Avg_Gainn across 3 training seeds and 10 subjects.
DTL
Mean EEG prediction accuracy Avg_PCC_tps and optimal sliding window se-
lection Based on our initial experimentation, we posited that higher prediction18 Guo et al.
accuracy of EEG signals around 100ms might result in increased gains in adver-
sarialrobustness.Torigorouslyinvestigatethisassociation,weinitiallydeployed
threeslidingwindowscoveringthevicinityof100ms:0.10sto0.12s,0.09sto0.14s,
and 0.05s to 0.3s, respectively. Within these windows, for each model iteration
(n), we computed Pearson correlation coefficient (PCC) values (PCCn(pts)) as
described in Appendix A.3, subsequently averaging these values (Avg_PCCn)
across all time points within the sliding window. By averaging Avg_PCCn val-
ues across 10 subjects and 3 training seeds, we derived the Avg_PCC_tps.
AssessingthecorrelationbetweenAvg_Gain anddifferentAvg_PCC_tps
DTL
obtained with the three window sizes, we identified an optimal window size
of 0.06s, resulting in the highest correlation value between Avg_Gain and
DTL
Avg_PCC_tpsaround100ms.Subsequently,weproceededtoidentifythemost
informativeEEGsignalscrucialforrobustnessgainbymovingthisoptimalslid-
ing window across all time points, with a step size of 0.01s, and measuring the
correlation values between Avg_Gain and Avg_PCC_tps across all time
DTL
points. In total, we obtained 100 correlation values, which represent the corre-
lation between Avg_Gain and Avg_PCC_tps when the optimal sliding
DTL
windowarrivesatdifferenttimepoints.Similarly,todiscernthemostsignificant
channels for enhancing the robustness gain, after identifying these significant
time points, we averaged PCC(ci,tps) across critical time points, yielding the
averaged prediction accuracy across critical time points for each channel.Adversarial Robustness Gains via EEG Co-Training 19
B Additional results
B.1 Relationship between Avg_Gain and Avg_PCC_tps
DTL
within different sliding windows
InFigure7(A),thecorrelationvaluesbetweenAvg_Gain andAvg_PCC_tps
DTL
withintwospecificslidingwindows,onerangingfrom0.05sto0.3sandtheother
from 0.10s to 0.12s, were inferior to those in Figure 2 (B), which suggested that
using a sliding window size of 0.06s allowed us to capture more significant EEG
signals around 100ms for adversarial robustness improvements. Using this op-
timal window size, Figure 2 rigorously examines the correlation between EEG
prediction accuracy and adversarial robustness gain.
(A) Mean Adversarial Robustness Gain v.s. Mean EEG prediction accuracy (B) Correlation values
across time points (tps) within different sliding windows across time points (tps) within different sliding windows
Fig.7: Correlation between Avg_Gain and Avg_PCC_tps across various slid-
DTL
ing windows. (A) shows how Avg_Gain varies with Avg_PCC_tps within two
DTL
specific sliding windows: one ranging from 0.05s to 0.3s, and the other from 0.10s to
0.12s. The correlation values observed within these windows are lower compared to
those depicted in Figure 2 (B). Here, (B) presents the R2 values for several sliding
windows, indicating that the window ranging from 0.09s to 0.14s achieves the highest
R2 value. This sliding window is also identified as optimal in Figure 2 (B).20 Guo et al.
Table 1: All architectures.
Model Cluster Name (Avg_PCC_tps, Avg_Gain)
L PGD L PGD L Carlini
2 ∞ 2
0 CNN CNN_Bk4 (0.264,0.019) (0.264,0.012) (0.264,0.013)
1 CNN CNN(concat)_Bk12 (0.267,0.028) (0.267,0.017) (0.267,0.027)
2 CNN CNN(concat)_Bk1234 (0.290,0.05) (0.290,0.027) (0.290,0.05)
1
3 CNN CNN(avg)_Bk1234 2 (0.292,0.04) (0.292,0.024) (0.292,0.04)
4 CNN CNN(concat)_Bk34 (0.296,0.08) (0.296,0.044) (0.296,0.076)
5 CNN CNN(avg)_Bk34 (0.293,0.06) (0.293,0.033) (0.293,0.059)
6 CNN CNN(concat)_Bk234 (0.299,0.060) (0.299,0.031) (0.299,0.063)
7 CNN CNN(avg)_Bk234 (0.296,0.047) (0.296,0.02) (0.296,0.049)
8 RNN RNN(concat)_Bk34 (0.30,0.06) (0.30,0.033) (0.30,0.066)
9 RNN RNN(avg)_Bk34 (0.302,0.051) (0.302,0.029) (0.302,0.04)
10 RNN RNN(LSTM)_Bk2 3 (0.27,0.025) (0.27,0.014) (0.27,0.027)
11 RNN RNN(LSTM)_Bk1 (0.267,0.026) (0.267,0.013) (0.267,0.029)
12 RNN RNN_Bk4 (0.271,0.025) (0.271,0.011) (0.271,0.027)
13 RNN RNN_Bk2 (0.279,0.032) (0.279,0.018) (0.279,0.032)
14 RNN RNN_Bk3 (0.258,0.028) (0.258,0.014) (0.258,0.026)
15 Transformer Trans_Bk4 (0.291,0.029) (0.291,0.014) (0.291,0.021)
16 Transformer Trans_Bk1 (0.289,0.051) (0.289,0.025) (0.289,0.053)
17 Transformer Trans_Bk2 (0.297,0.055) (0.297,0.029) (0.297,0.052)
18 Transformer Trans_Bk3 (0.309,0.053) (0.309,0.03) (0.309,0.051)
19 Attention layer Att(concat)_Bk34 (0.278,0.046) (0.278,0.024) (0.278,0.05)
20 Attention layer Att(concat)_Bk12 (0.271,0.039) (0.271,0.019) (0.271,0.037)
21 Attention layer Att_Bk4 (0.265,0.029) (0.265,0.013) (0.265,0.028)
22 Attention layer Att_Bk3 (0.283,0.045) (0.283,0.026) (0.283,0.042)
23 Attention layer Att_Bk2 (0.264,0.037) (0.264,0.02) (0.264,0.039)
1RepresentsarchitectureinCNNclusterthatconcatenatestheoutputfromBlocks
1,2,3,and4ofResNet50forEEGprediction.Model2andmodel5exhibitedsimilar
Avg_PCC_tps and L Carlini & Wagner Avg_Gain . In the third subplot of
2 DTL
Figure 2 B, two blue squares representing these two models overlapped.
2Represents architecture that averages the output from Blocks 1, 2, 3, and 4 of
ResNet50 for EEG prediction.
3Represents architecture that predicts EEG from Block 2 features using LSTM
units.