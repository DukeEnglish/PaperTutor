Accelerating materials discovery for polymer
solar cells: Data-driven insights enabled by
natural language processing
Pranav Shetty,† Aishat Adeboye,‡ Sonakshi Gupta,¶ Chao Zhang,† and Rampi
Ramprasad∗,¶
†School of Computational Science & Engineering
‡School of Chemical & Biomolecular Engineering
¶School of Materials Science and Engineering, Georgia Institute of Technology, 771 Ferst
Drive NW, Atlanta, Georgia 30332, USA
E-mail: rampi.ramprasad@mse.gatech.edu
Abstract
We present a natural language processing pipeline that was used to extract poly-
mer solar cell property data from the literature and simulate various active learning
strategies. Whiledata-drivenmethodshavebeenwellestablishedtodiscovernovelma-
terials faster than Edisonian trial-and-error approaches, their benefits have not been
quantified. Our approach demonstrates a potential reduction in discovery time by ap-
proximately 75 %, equivalent to a 15 year acceleration in material innovation. Our
pipeline enables us to extract data from greater than 3300 papers which is ∼5 times
largerthansimilardatasetsreportedbyothers. Wealsotrainedmachinelearningmod-
els to predict the power conversion efficiency and used our model to identify promising
donor-acceptor combinations that are as yet unreported. We thus demonstrate a work-
flow that goes from published literature to extracted material property data which in
1
4202
beF
92
]ics-lrtm.tam-dnoc[
1v26491.2042:viXraturn is used to obtain data-driven insights. Our insights include active learning strate-
gies that can simultaneously optimize the material system and train strong predictive
models of material properties. This work provides a valuable framework for research
in material science.
Introduction
Machine learning (ML) methods have become ubiquitous in materials science. Indeed, data-
driven methods have enabled the discovery of new materials for applications such as high-
breakdownstrengthdielectricpolymers,1–3 heussleralloys,4,5 organicphotovoltaicswithhigh
power conversion efficiency6,7 and gas separation membranes with high selective permeabil-
ity.8 Active learning is a technique that is used to drive this improvement. It leverages
trained models of material properties to identify promising candidate materials and then
augment the training set once the candidate material is “measured”, to improve the predic-
tive performance of the ML models. Active learning methods have been used to discover
high hole mobility thin films,9 alloys for gas turbine engine blades,10 and high glass tran-
sition temperature polymers.11 Recent work has benchmarked the performance of various
active learning strategies on problems such as electrocatalysis,12 magnetic properties,13 and
band gap.14 However, no study has compared the time taken to experimentally determine an
optimal material system with desirable properties through trial and error against the time
taken to discover the same material system using machine learning methods. Polymer solar
cells offer a promising playground for us to quantify the time savings offered by the use of
machine learning methods in materials science using historical data.
Traditionally solar cells are inorganic and are made out of either crystalline silicon or
amorphous silicon. The principle of operation of this device is that light incident on a
surface produces electron-hole pairs which produces a potential that can drive an external
load. Due to the use of an inorganic material like silicon, the cost of manufacturing such
cells is increased due to the high temperatures required to process silicon. Polymer solar
2cells, on the other hand, are made of organic materials and can thus be processed at much
lower temperatures. The most common configuration of a polymer solar cell is as a bulk
hetero-junction blend of two materials known as the donor and acceptor. Finding optimal
donor/acceptorcombinationsthatleadtohighpowerconversionefficiency(PCE)isanactive
area of research. Historically, the acceptor was based on fullerenes, typically [6,6] phenyl-
C61-butyric acid methyl ester (PCBM). In recent years, though non-fullerene acceptors have
gained traction and have led to solar cell configurations with much higher efficiency.15
The chemical space for donors and acceptors is vast, making machine learning methods
a promising avenue for narrowing down the chemical space for testing candidate materi-
als. Past work has developed machine learning models for polymer solar cells to identify
promising donors for fullerene systems16 as well as promising non-fullerene acceptors.17 Ref.
7 uses trained ML models of PCE to find promising candidate materials and then tests cells
fabricated using the predicted candidate systems to discover new viable candidates. The
number of experimental papers published in this space is quite large however and covers
a wide chemical space. In this work, we found over ∼ 3300 papers in this area using our
pipeline. The papers that have typically applied ML methods to polymer solar cells relied
on data that was manually collected and covered about 500 papers on average. A summary
of publicly available polymer solar cell data sets is provided in Table 1. Thus, due to the
manual nature of data collection, nearly five-sixth of relevant papers typically cannot be
parsed for data extraction due to time constraints. The use of natural language processing
(NLP) offers a potential solution to the problem of material property data collection at scale.
Table 1: Comparing public data sets of polymer solar cell device characteristics
Type of data Number of data points Number of papers Reference
Fullerenes only 1200 500 16
Non-fullerenes only 1001 - 18
Non-fullerenes only 1318 558 6,17
Fullerenes only 350 - 19
Fullerenes and non- 1543 3307 This work
fullerenes
3NLP is a way to get computers to understand human text. NLP has been used in
materials science to obtain insights from inorganic literature as well as polymer literature
by extracting structured material property data or synthesis data from a large number of
papers. We used NLP methods to extract device characteristics of polymer solar cells from
the abstracts of materials science literature. A data extraction pipeline was developed as
part of a previous work,20–22 that recognized the categories of words in text using machine
learning models and used heuristic rules to link them into a material property record. Using
this pipeline, we obtained a data set of donors and acceptors and their corresponding device
characteristics such as PCE. We curated a subset of the NLP extracted data to record the
structure of the donor and acceptor as a SMILES string.
Using the data curated by us, we trained machine learning models that take the donor
and acceptor as input and predicted the PCE (overall workflow shown in Figure 1). We used
this trained model to predict the PCE for all donor/acceptor combinations not found in our
curated data set to identify promising candidates with high PCE and obtain some unique
insights. This training methodology was also used in the simulation of an active learning
loop. Comparing this against the time trend of PCE in the literature enables us to estimate
the time that would have been saved, had data-driven methods been used from the start to
drive materials discovery. The fundamental premise of using machine learning in materials
scienceisthatwecandiscovernewmaterialssystemsfasterthanwouldotherwisebepossible.
We provide the first quantitative evidence for this by comparing the paths obtained using
active learning to the actual evolution of power conversion efficiency for polymer solar cells
reported in the literature. We thus make a stronger policy case for wider systemic adoption
of machine learning for the discovery of new materials.
4Figure 1: Pipeline used for extracting polymer solar cell PCE data from published literature
which is then used in two ways 1) To train ML models of PCE and predict high-performing
donor/acceptor pairs not reported in the literature and 2) To simulate an active learning
loop through which donor/acceptor pairs are ‘discovered’ sequentially. (J71, Y6) referenced
in the figure is a donor/acceptor pair.
5Methods
Data extraction pipeline from literature
We created a corpus of 2.4 million materials science journal articles by web scraping and
by downloading from publisher-specific APIs. Elsevier, Wiley, Royal Society of Chemistry,
American Chemical Society, Springer Nature, Taylor & Francis, and the American Insti-
tute of Physics are the publishers included in our corpus.20 These papers span the years
2000 to 2022. A subset of 750 abstracts was annotated using an ontology specific to the
materials science domain consisting of the entity types POLYMER, POLYMER CLASS,
PROPERTY VALUE, PROPERTY NAME, MONOMER, ORGANIC MATERIAL, INOR-
GANIC MATERIAL, and MATERIAL AMOUNT. A Named Entity Recognition (NER)
model was trained using the annotated data set. The trained NER model along with heuris-
tic rules for entity linking was used to extract material property data from the abstracts of
all papers in our corpus that were polymer-relevant. This extracted data set represents all
material property data reported in the abstracts of our corpus of papers. A subset of this
material property data corresponds to polymer solar cells and the selection and curation of
this subset is described next. Refer to Ref.22 for further details.
Creating the polymer solar cells data set
Polymer solar cells was the domain with the largest number of papers in our corpus. It
is also conventional for scientists to record information such as the donor/acceptor system
developed in the paper as well as its key device characteristics in the abstract of the paper.
Moreover, this field has for the most part developed over the ∼20 year time span between
2000 and 2022 which overlaps well with the time frame of our corpus of papers. Most of the
research in this field has also focused on developing a donor/acceptor that improves one key
property namely the power conversion efficiency of the resulting cell. This makes it an ideal
playground for our active learning experiments.
6We picked the subset of abstracts (from which we extracted all material property data),
thatcontainedthekeyword“solarcell”andcontainedreportedvaluesforPSCdevicecharac-
teristics. We also excluded keywords such as “perovskite”, “dye-sensitized”, “tandem solar
cell”, “quantum dot”, “hybrid solar cell”, “silicon solar cell” and “ternary solar cell”. In
practice, it is common for authors working in polymer solar cells to report the character-
istics associated with the most important donor-acceptor combinations tested in the paper
in the abstract. Most papers report innovations in the materials used in the cell and its
corresponding performance which are typically the most important results reported in the
paper and are hence mentioned in the abstract. Since the ontology used in Ref. 22 was not
specific to polymer solar cells, it was necessary to distinguish donor and acceptor labels for
material entities reported in the abstract. We labeled material entities as donors or acceptors
based on the following hierarchy of rules:
1. Donors and acceptors are often separated by a “/” or a “:” such as “P3HT/PCBM”
or “P3HT:PCBM” wherein the first entry is the donor and the second entry is the
acceptor. Material entities mentioned in this manner were marked as donors and
acceptors respectively
2. POLYMER or ORGANIC entities that co-occur with the word donor or acceptor were
counted as the donor and acceptor respectively.
3. If PCBM or any coreferent of a fullerene is mentioned in the text, then it was marked
as it was labeled as the acceptor.
4. If an ORGANIC entity is present in the list of materials for a material property record,
then it was treated as the acceptor, and the POLYMER entity in that material list
was treated as the donor.
Anything that fell outside the above set of rules was marked as being ambiguous and
required manual curation.
7It is common for donor polymers to be referred to by generic identifiers such as P1 or P2
and for the corresponding structure to be provided in the paper. In such cases we change
the name of the entity to P1 DOI where DOI is the digital object identifier of the paper.
This helps distinguish this case from other papers where similar identifiers were used.
Data curation
To use the above data set to train machine learning models, we curated the NLP extracted
data further to 1) fix any mistakes made by the NLP pipeline and 2) collect SMILES strings
fordonorsandacceptorswhichcanbeusedtogenerateastructuralfingerprintofthematerial
entity for training models.
The curation was done by annotators labeling donors, acceptors, and their corresponding
SMILES strings. We were only interested in properties reported for bulk heterojunction
polymer solar cells. Thus the donor in each data point is a polymer and papers dealing with
ternary systems, i.e., with multiple donors or multiple acceptors were excluded. We also
excluded papers reporting properties computed through simulations or materials that were
discovered using data-driven methods such as Ref. 7. The device characteristics reported in
the data set include power conversion efficiency, fill factor, open circuit voltage, and short
circuit current.
Whileintheanalysisthatfollows, weonlymakeuseofthepowerconversionefficiency, the
complete data set is released as part of this work. Note that all property values curated were
mentioned in the abstract. There were cases where only donor or acceptor was mentioned in
the abstract while the other had to be located in the body of the paper. In such cases, the
material entity not found in the abstract is provided in single quotes to distinguish it from
cases where the material entity is provided in the abstract. The SMILES strings for the most
common donors and acceptors found in our corpus were first created and then pre-populated
inthecorrespondingcolumntoavoidrepeatingtheeffortofrecreatingthoseSMILESstrings.
For every other case, the SMILES string was constructed by looking for the structure among
8the figures in the paper and using the draw tool found in polymergenome.org to construct
the SMILES string. In cases where the structure was not found in the paper, the annotators
would look for supporting references that contained the structure. The SMILES string is a
stringrepresentationofthestructureofamolecule. Notethatweusedthepsmilesconvention
as defined in Ref. 23 for polymer SMILES strings. Creating the SMILES strings was the
most time-consuming aspect of data curation. The SMILES strings were canonicalized using
the package described in Ref. 23 and the canonicalized SMILES strings were used to identify
unique donor-acceptor pairs.
Machine learning prediction of power conversion efficiency
We used the curated data set to build machine learning models of the power conversion
efficiency (PCE) of a polymer solar cell. We modeled the PCE as being dependent on only
the donor and acceptor. In practice, the PCE depends on factors like the weight fractions
of the donor and acceptor and other device fabrication parameters.24 We however assumed
that the property values reported in the abstract are for systems in which other factors
have been optimized. Our problem formulation is more general than several others reported
in the literature which only use the structure of the donor and assume that the acceptor
is a fullerene16 or do not consider the effect of the acceptor.7 Due to the recent rise of
non-fullerenes, it is necessary to include acceptors in the problem formulation.15 For donor-
acceptor pairs for which multiple power conversion efficiencies are available, we took the
median of all available values. The values may differ due to differences in the electron or
holetransportlayer,additivesusedduringthesynthesisoftheactivelayer,orthemorphology
of the active layer. Taking the median “averages” out these factors.
Weusedhand-craftedfingerprintsdescribedinearlierwork25 tofingerprintthedonorand
acceptor. While other fingerprints have been developed for featurizing polymers using ideas
such as graph neural networks26 and BERT-based fingerprinting,23 we used handcrafted
fingerprints for this work as they can be used to fingerprint polymers as well as organic
9molecules. Moreover, each fingerprint component corresponds to a pre-defined chemical
feature which enables us to “peer” into the model and determine why certain predictions
were made by the model. In cases where the donor or acceptor is a copolymer, we take
the average fingerprint of all components of the copolymer, in keeping with past work on
copolymers.27 Min-max scaling is performed on all fingerprint components to ensure that
they are each between 0 and 1. The vector fingerprints for the donor and acceptor were
then concatenated and input to a Gaussian Process Regression (GPR) model to predict
the power conversion efficiency. The fingerprint dimension is 745 while the number of data
points is 835. Neural networks tend to overfit when the number of data points is close to
the dimension of the feature space while GPR models generalize much better in this regime
making it a natural choice for our problem.28 We used the python package scikit-learn29
to train GPR models. We used a Matern kernel.30 The curated data is split into 85 % for
training and 15 % for testing. We used root mean squared error (RMSE) and the coefficient
of determination (r) as the metric for assessing model performance.
Data selection methods for simulating active learning of polymer
solar cells
We used the curated polymer solar cell data set to pick a sequence of donor/acceptor pairs.
This process is continued till the data point with the highest PCE in our data set was
discovered. This in effect, simulates an active learning generated path of how the field of
polymer solar cells may have developed and can be used to compare against how the field
developed. We employed several different methods to pick the next data point to test,
described below. Let ypred be the predicted value of the GPR model for the ith test point
i
and σ be the corresponding uncertainty of the GPR model evaluated at that point where
i
i ∈ {1,..,N} where N is the number of test points at a given step in the active learning
loop. Suppose the current step in the active learning cycle is T. Let Y represent the random
i
variable corresponding to the measurement of the ith test point. If GPR is used to model
10Y , then it is known that Y is Gaussian distributed with mean ypred and standard deviation
i i i
σ . The first four methods described below require a model to be trained at each step of the
i
active learning loop while linear bandits do not train a predictive model.
1. Gaussian Process-Upper Confidence Bound (GP-UCB): This uses the pre-
dicted value along with its uncertainty to pick points, i.e., ypred+βσ . The parameter
i i
β controls thetrade-off of exploration versus exploitation. A higher value ofβ indicates
a belief that higher value points are likely to be found in regions of uncertainty while
a lower value of beta indicates a belief that the model predictions should be exploited
as is. We used a value of β = 1 in this work.
2. Gaussian Process-Probability Improvement (GP-PI): Intuitively, this strategy
looks for points that have the highest probability of being greater than some threshold
θ. P(Y > θ) = 1 − Φ(θ−y ipred ) = Φ(y ipred−θ ). Here Φ(.) is the cumulative probability
i σi σi
distribution function for a standard Gaussian. In practice, the threshold is selected to
be the value of the highest y sampled until that point multiplied by some improvement
fractionν, i.e., θ = max y (1+ν). Wepickavalueofν = 0.01. Aftercomputing
t∈{1,...,T} t
the probability of improvement for all test points, we pick the point with the greatest
value.
3. Gaussian Process-Expected Improvement (GP-EI): In contrast to the previous
strategy where we compute the probability of improvement over some threshold, in
this strategy we look at the expected value of the difference between the value and
the threshold. Thus we compute the quantity E[Y − θ] = (cid:82)∞ (y − θ)p(y )dy . This
i −∞ i i i
evaluates to E[Y −θ] = (ypred −θ)Φ(y ipred )+σ ϕ(y ipred ), where ϕ(.) is the probability
i i σi i σi
distribution function of the standard gaussian. The threshold is computed the same
way as GP-PI. After computing this quantity for all test points, we pick the point with
the largest expected improvement.
4. Greedy acquisition: This strategy simply looks at the highest predicted values ypred.
i
11This is equivalent to using β = 0 in GP-UCB.
5. Gaussian Process-Thompson Sampling (GP-TS): For each material system, we
sample the value of the power conversion efficiency from a Gaussian distribution with
mean ypred and standard deviation σ . We pick the material system with the highest
i i
sampled property value.
6. Linear contextual bandits: In a multi-arm bandit setting, an agent interacts with
an environment over several rounds. In contrast to the methods described above, we do
not train an ML model at each round. During each round, the agent selects an action
from a set of available actions (also known as “arms” in the multi-arm bandit setting)
where each action is represented by a d-dimensional feature vector (the “context”). In
our case, the set of actions is the available set of donor/acceptor systems. After taking
an action, the agent receives a reward, which in our case is the value of the PCE
“measured” for a donor/acceptor system. The goal is to learn a policy (a mapping
from context to action) that maximizes the expected cumulative reward over time. In
linear contextual bandits, the reward function is assumed to be a linear function of the
action. The agent’s goal is to estimate the parameters of the linear model based on
observed data and use it to make action selections that maximize expected rewards.
We implemented Thompson Sampling for linear contextual bandits.31 While training
GPR models, the focus is on optimizing prediction accuracy, while in linear contextual
bandits, the focus is on maximizing cumulative rewards. Instead of having a fixed
data set used for training, contextual bandits involve online learning where the agent
interacts with the environment and adapts its policy over time. Further mathematical
details are provided in Supplemental Information Section 1.
In each of the above methods, we can pick a batch b of any size but in practice we use
b = 1 since the cost of fabricating a cell with a given material system and measuring the
PCE is much larger than the computational cost of the active learning loop.
12Results and discussion
Analysis of NLP extracted data
There are 3307 documents in the NLP extracted data set out of which 861 (∼ 26 %) have
been curated (detailed breakdown in Table 2). The number of unique data points in the
full data set is estimated based on the normalized names of the donors and acceptors and is
an approximation. The donors are always polymers and hence can be normalized using the
normalization workflow described in earlier work.21 The acceptors on the other hand can be
polymers or organic molecules. For polymer acceptors, we use our polymer normalization
workflow. For fullerene acceptors, given that only about four such acceptors are commonly
used (PC61BM, PC71BM, C60, ICBA), we manually constructed a list of named entity
variants for each of these. For other non-fullerene acceptors, we constructed an on-the-fly
normalization data set using the coreferents for all non-fullerene acceptors mentioned among
the curated papers. The number of total data points is greater than the number of unique
data points as there are several systems for which a value has been reported in multiple
papers, often differing in cell fabrication conditions. For the curated data set, the number
of data points was computed using the canonical SMILES string of the donor and acceptor.
The SMILES strings were canonicalized using the psmiles package described in Ref. 23.
We can see from the heatmap in Figure 2 that only a small fraction (0.70 %) of the
donor/acceptor space has been explored experimentally. The donors and acceptors are not
labeled as they are far too numerous. The donors on the heat map which are reported
against the most acceptors correspond to P3HT (40), PTB7-Th (40), and PBDB-T (37).
The material system with the highest reported PCE for a bulk heterojunction polymer solar
cellinourdatasetisPBDS-TasdonorandBTP-ec9asacceptorwithareportedPCEof16.4
% 32. We built a prediction pipeline that can fill in the blanks in this figure and used that to
discern patterns as well as find optimal donor/acceptor combinations that would otherwise
require expensive experimental measurements. A machine learning model that takes both
13the donor structure as well as the acceptor structure as input should in principle be able
to learn correlations between the two which can be used to predict novel combinations of
donors and acceptors.
Table 2: Detailed composition of the NLP extracted polymer solar cell data and the curated
subset
Type of data Full data set Curated data set
Number of papers 3307 861
Unique donor-fullerene pairs 1160 607
Total donor-fullerene data points 2107 903
Unique donor- non-fullerene pairs 1425 261
Total donor-non-fullerene data 1934 284
points
Number of unique donors 1910 628
Number of unique acceptors 650 190
Maximumreportedpowerconver- - 16.4 %
sion efficiency
Figure 2: Entire donor/acceptor space at a glance. The donors and acceptors that are most
frequently reported are shown along the axes.
In Table 3 we compare the ground truth versus the extracted data to measure the fidelity
with which the NLP system can extract the relevant polymer solar cell data.
We measured the fidelity of extraction using k-tuple metrics where 2 ≤ k ≤ 4. For a 4-
tuple comparison, we looked at the tuple (donor, acceptor, property name, property value).
We compared the ground truth tuples against the NLP extracted tuples for each abstract
14to check if there is any NLP extracted tuple for which all 4 entries are identical and that is
marked as a true positive (TP). If no such ground truth tuple is found then we have a false
negative (FN). We similarly compared the NLP extracted tuples against the ground truth
tuples for each abstract to check if a match is found and if not then a false positive (FP) is
recorded. As the 4-tuple metric is strict, we computed 3-tuple and 2-tuple metrics as well
wherein the 4-tuple is split into 3 and 6 tuples respectively for each 4-tuple, in each abstract.
This allows us to see if at least some subsets of the 4-tuple are extracted correctly. This is
consistent with how extraction fidelity has been measured in the literature in cases involving
multiple entities in a tuple.33 Precision, Recall, and F1 score are then calculated as below:
TP
Precision =
TP +FP
TP
Recall = (1)
TP +FN
2×Precision×Recall
F1 =
Precision+Recall
Each of the above metrics is reported as a % value.
Table 3: Comparing fidelity of NLP extracted data to ground truth data
Metric Precision Recall F1
4-tuple 46.03 40.25 42.95
3-tuple 61.34 55.09 58.05
2-tuple 72.87 66.18 69.37
Predicting power conversion efficiency
The RMSE of property prediction is 2.07 % for the model using donors as well as acceptors
as seen in the parity plot in Figure 3. Figure 3 compares a machine learning model trained
using the donor alone and using the donor as well as the acceptor. The donor-only data set
was constructed by removing the acceptors from each data point in the donor/acceptor data
set thus ensuring a fair comparison. There are thus data points that have the same donor but
15(a) (b)
Figure 3: Parity plot for a machine learning model trained to predict power conversion
efficiency. a) Model trained using only donors as input b) Model trained using donors and
acceptors as input to the model
different values of power conversion efficiency which is due to the acceptors being different.
Having additional information on the acceptor improves the prediction performance of the
model by 0.22 % as measured by the RMSE. Note that the train-test split is identical for
both Figure 3a and Figure 3b. Figure 4 shows the predicted power conversion efficiencies
for all donor/acceptor pairs in our data set. A trend we observe from the figure is that
the use of certain acceptors can improve the power conversion efficiency significantly. The
bright red horizontal line at the bottom corresponds to the acceptor BTIC-2Br-m which is
a Y6-based acceptor. Similarly, some of the other high-performance acceptors in Figure 4
are also based on Y634 such as BTP-4Cl and BTP-ec9. The observations we make from this
figure match well with the strategy recently employed in the polymer solar cell community
of using acceptors based on Y6 and testing it with various donors.
The highest donor/acceptor pairs predicted from our model are listed in Table 5 along
with the corresponding power conversion efficiency. All the acceptors are based on Y6 and
the corresponding donors are then recommendations for promising combinations. Due to the
16sparsity of the underlying data set, however, this extrapolation must be viewed with caution.
It is possible that the acceptors with the highest recorded PCE have an undue influence on
the predictions and that donor/acceptor interactions are unable to be fully captured due to
the sparsity of the underlying data. The vast majority of donors are reported with just a
single acceptor and likewise, most acceptors are tested with just a single donor, thus making
it difficult for a model to learn the correlations effectively. To examine this possibility more
closely, we looked at the top donors and acceptors from Figure 4 by computing the average
PCE over donors for each acceptor and likewise for donors. The top five results are shown in
Table 4. The top pairs reported in Table 5 are not simply formed by matching the top donors
with the top acceptors in Table 4 but are non-trivial combinations of donors and acceptors,
suggesting that the model may well be learning meaningful donor/acceptor co-relations. The
acceptors used in the top reported pairs match closely with the top acceptors overall and
furthermore, the average PCE for the top acceptors is higher than that for the top donors
suggesting that acceptors do indeed play a more important role than donors in determining
the power conversion efficiency in the high PCE regime.
Thus, we have demonstrated the end-to-end use of NLP to facilitate the creation of
a data set which is then used for building machine learning models and predicting new
donor/acceptor combinations for polymer solar cells. This also validates our modeling ap-
proach for simulated active learning discussed in the next section.
Table 4: Top donors and acceptors from Figure 4
Top Donors Average PCE (%) Top acceptors Average PCE
(%)
PTzBI-Si35 8.87 BTIC-2Br-m36 12.42
L237 8.68 BTP-4Cl38 11.19
PTQ1039 8.46 BTP-ec9 11.07
PM740 8.44 TPIC-4Cl41 10.42
F1342 7.98 Y6 9.37
17Figure 4: Predicted power conversion efficiency value for the entire donor/acceptor space.
The donors and acceptors with the highest average PCE are shown along the axes.
Table 5: donor/acceptor pairs with highest predicted power conversion efficiency
Donor Acceptor Predicted power True PCE (if re-
conversion effi- ported in litera-
ciency ture)
PBDB-TF BTIC-2Br-m 14.34 % 16.1 %36
PM6 BTIC-2Br-m 14.33 % -
PFBDB-T43 BTIC-2Br-m 14.33 % -
PM7 BTP-ec9 14.31 % -
PM7 BTP-4Cl 14.30 % -
PM7 TPIC-4Cl 14.25 % 15.1 %41
PDBT-F44 BTIC-2Br-m 14.20 % -
L2 BTP-ec9 14.17 % -
L2 BTP-4Cl 14.16 % -
PBDT(T)[2F]T45 BTIC-2Br-m 14.07 % -
Simulating the ‘discovery’ of new donor/acceptor combinations
The green line in Figure 5 shows how the power conversion efficiency of polymer solar cell
systems reported in the literature has changed over time. Each data point corresponds
to a single donor/acceptor system. In cases where a donor/acceptor system is reported
multiple times in the literature, we take the median value and the timestamp for the paper
corresponding to the median value (in cases where the number of data points n is even, we
use the PCE at index n after the PCE values are sorted). Observe that the value of PCE
2
shows an upward trend till 2022 where a peak of 16.4 % was obtained which is the highest
18value in our data set. Thus this plot captures a near complete picture of the evolution of the
field of polymer solar cells. The discovery of new material systems has proceeded through
trial and error which is why the PCE does not increase monotonically but fluctuates in
value. The number of PCE values reported that under-perform the then-state-of-the-art
is likely underestimated on this plot given that only material systems that are considered
improvements end up getting published resulting in a bias in the available data.46
(a) (b) (c)
(d) (e) (f)
Figure 5: Comparing the simulated path of material systems generated by data selection
methods against the evolution of power conversion efficiency in the experimental literature.
a) Both fullerene and non-fullerene acceptors included among candidate material systems b)
fullerene acceptor only c) non-fullerene acceptors only. Fig. d-f shows the range of values
obtained over 5 active learning cycles with different starting material systems for each data
selection method tested in the row above.
We consider the question of how this field may have evolved had it relied completely on
data-driven methods to pick the next donor/acceptor combinations to evaluate rather than
19relying on trial and error. This allows us to empirically estimate how much faster we may
have reached the end-point shown in Figure 5.
The iterative process we used for material selection is shown in Figure 1. The initial
donor/acceptorsystemweusedwasOC C -PPV/PC BM47 whichwastheearliestreported
1 10 61
material system in our data set. At each step, we trained a GPR model using all available
data at that point and used that to make predictions on our curated list of donor/acceptor
materials. We picked one donor/acceptor system that was the most “promising” according
to a few different possible strategies. We “measured” the true power conversion efficiency
by looking up the value from our curated data set of known PCE values. This new data
point was then used to augment the training data set to train a new model and repeat the
above cycle. The iterations were terminated when the material system with the highest value
in our data set was identified. This is identical to active learning with the key difference
being that we can compare active learning generated paths against how the field evolved to
compare various data selection methods and estimate their respective speedups. We make
two key assumptions in this analysis:
1. The list of donor/acceptor systems used as candidate material systems is the full list
of all material systems reported in our curated data set. While we do not assume fore-
knowledge of the actual value of PCE, coming up with viable new material systems was
part of the evolution of this field which we are unable to realistically simulate. A fairer
analysis would assume a much larger candidate list of donor/acceptor systems which
would be created without bias. There would however be no way to “measure” the
value of PCE for such these material systems with the same fidelity as experimentally
reported values.
2. The timestamp associated with each new donor/acceptor system that is picked is the
same as the timestamp for an entry of the corresponding index in the ground truth
data. As the experimentally reported results are by many different research groups,
this assumption is reasonable if we assume that many different research groups are
20involved in this data-driven workflow. It may even be possible for funding agencies to
allocate resources more efficiently if the iterative methodology described in this section
were to be followed.
As we see in Figure 5a-c, all data selection methods used in this work outperform trial
and error. We compared different methods using the discovery time speedup factor (DTSF)
which is defined below:
texp −t
DTSF = max 0 (2)
tsim −t
max 0
where t is the timestamp associated with the earliest data point in our data set, texp is
0 max
the timestamp for the paper when the highest experimental PCE was reported in our data
set, tsim is the timestamp corresponding to the index at which the simulated path reaches
max
the same maximum PCE. The timestamp here is the date converted to a rational number
wherein the fractional part is the day and month converted to a fraction of a full year and
the integer part is the year.
Intuitively this gives a sense of how much faster can machine learning methods reach the
same end-point as trial and error methods. When fullerenes as well as non-fullerenes are
used as acceptors, we obtain the greatest speedup of a factor of about 4 while the speedup
factor is lower when only one of fullerenes or non-fullerenes are used as acceptors reducing
to a factor of 2. In the context of polymer solar cell donor/acceptor discovery, this translates
to a time saving of ∼15 years. This is one of the first quantitative estimates of the time
saved by using machine learning for materials discovery that we are aware of. Figure 5a-
c assume a fixed starting donor/acceptor system, namely OC C -PPV/PC BM. For all
1 10 61
methods tested except GP-TS and linear contextual bandits, a fixed starting point would
result in a fixed path of donor/acceptor pairs being selected as a GPR model will always
generate the same predictions given fixed training data and fixed hyperparameters. In the
case of GP-TS and linear contextual bandits, however, there is a sampling step involved
21in picking a new material which inherently introduces randomness. To estimate the range
of speedups obtained for each method, we used the first five donor/acceptor pairs reported
in our curated data set. These five donor/acceptor systems belong to the same generation
of polymer solar cells and are listed in Supplemental Information Section 2. When error
bars are accounted for, we notice, from Figure 5d-f that there is no statistically significant
differencebetweenthedifferentmethodsthatwetested. GP-EIhasahighervalueonaverage
and so we plot the path generated by GP-EI in Figure 5a-c. It is worth noting that linear
contextual bandits which is a linear method and therefore much faster than non-parametric
methods like GPR, has a similar speedup factor as GPR-based methods. This indicates that
the predictive capabilities of a model have little to do with how quickly it can identify the
best-performing material system. We shall explore this more fully in the next section.
Analyzing the predictions from data selection methods
In this section, we take a closer look at the predictions made by the various methods we
tested and examine the path of donor/acceptor pairs predicted to understand why certain
predictions were made by the model. We projected the vector representations of the con-
catenated donor/acceptor material fingerprint to two dimensions using Uniform Manifold
Approximation and Projection (UMAP).48 We considered fullerene as well as non-fullerene
acceptors. This projection results in four clusters being formed which are shown in Figure 6.
The leftmost cluster corresponds to non-fullerene small molecule acceptors which is what we
need for this discussion and the remaining clusters are described in the caption. The paths
shown in Figure 6 were generated using OC C -PPV/PC BM as the initial donor/acceptor
1 10 61
pair. Note from Figure 6b and e that both greedy and GP-EI jump to the non-fullerene small
molecule space after the first iteration and stays there during all subsequent iterations. This
is the space that is known to contain the candidates most likely to have high power conver-
sion efficiency. This is likely why greedy and GP-EI have higher average speedups compared
to other methods as seen in Figure 5a and c. All other methods spend at least one or more
22iterations in exploring other parts of the donor/acceptor space. Observe also that greedy
and GP-EI when applied to non-fullerene acceptors and both fullerene and non-fullerene
acceptors differ in the first material system only. All subsequent iterations for both cases are
restricted to the space of non-fullerenes. Yet, there is a statistically significant difference in
the time taken to find the optimal material system in both cases (refer Figure 5) with the
non-fullerene only case taking significantly longer. We posit that the initial inclusion of the
fullerene acceptor or more generally the inclusion of some initial material system that is dif-
ferent from the space where the optimal material system is expected to lie, would accelerate
convergence to the optimal material system. This could be because the initial diversity helps
give the model a better “view” of the overall material space compared to if the candidates
were less diverse which can at best present the model with a very local region of the material
spacerequiringthemodeltothereforespendmoreiterationstounderstandthebestdirection
to traverse in material space.
At each iteration, we measure the predictive performance of the trained GPR model by
comparingitspredictionsagainstallpointsnotyetaddedtothetestset(Figure7). Thedata
points used for measuring test performance are reduced by one point at every iteration and
have some points that are different for each selection method. However, the number of points
selected during a typical active learning run (10-15) is small compared to the total number
of data points (835) which makes this a reasonable approach to infer the general trend in
the predictive capabilities of the models being trained. Note that there is no improvement
in the predictive performance of the models being trained as the number of data points
in the training set increases, for most of the selection methods we test. This is consistent
with results reported in Ref. 14. The notable exception to this however is GP-TS in which
successive models have improved predictive performance. This intuitively makes sense as
all other methods pick material systems by directly optimizing for high power conversion
efficiency and therefore bias the model that is trained using the picked data points. GP-
TS on the other hand picks material systems by maximizing over PCEs sampled from the
23(a) (b) (c)
(d) (e) (f)
Figure 6: The simulated path of material systems for each data selection method with the
material system vectors being embedded in two dimensions using UMAP. The left most
cluster in each figure corresponds to non-fullerene small molecule acceptors. The middle
two clusters correspond to fullerene acceptors within which the top cluster corresponds to
donors with fused aromatic rings and the bottom cluster corresponds to all other donors.
The rightmost cluster consists of polymer acceptors. The plots correspond to a) GP-TS b)
Greedy c) GP-UCB d) GP-PI e) GP-EI f) Linear contextual bandits
predicted distribution for each material system and thus samples a more diverse set of data
points as seen in Figure 6a. By design, GP-TS reaches the optimal material state quickly
and in parallel trains models with strong predictive performance and is the only method out
of the methods we test that achieves this balance. The trend observed in Figure 7 is reported
for both types of acceptors. We report the corresponding plots for iterations performed over
fullerene acceptors and non-fullerene acceptors only in Supplemental Information Section 3,
which demonstrates the same trend.
24(a) (b) (c)
(d) (e)
Figure 7: Evolution of the predictive performance of the models trained using different data
selection methods using OC C -PPV/PC BM as the initial donor/acceptor pair. The data
1 10 61
selection methods compared are a) GP-TS b) Greedy c) GP-UCB d) GP-PI e) GP-EI
Summary and Outlook
A pipeline that extracts material property data from published literature which is then used
for training property prediction models and in turn generates novel insights was built in
this work. By training models to predict power conversion efficiency, we found promising
donor/acceptor combinations that have not yet been reported in the literature. We used the
timestamp associated with our literature-extracted data set to demonstrate that data-driven
methodsalonewouldhavediscoveredthemostpromisingdonor/acceptorsysteminonlyone-
fourth of the time it took through trial and error. This allows for a stronger case to be made
to policymakers to encourage further use of ML methods for materials discovery. We also
discover that Gaussian Process-Thompson Sampling as an active learning strategy discovers
the optimal donor/acceptor system as quickly as any of the other strategies tested but also
simultaneously results in training a strong property predictor, unlike other strategies. There
25are some key limitations of our study that we highlight below.
1. The list of candidate material systems we pick from, is the set of all donor/acceptor
systems which have been tested in the literature. The structures that were tested much
later in the literature could only be discovered due to the experimental trial and error
that preceded it.
2. We assume that the time intervals of measurement in the data-driven view are identi-
cal to the trial and error approach, i.e., new materials through data-driven approaches
can be discovered at the same rate at which experimental papers containing new
donor/acceptor systems were published.
One of the bottlenecks when going from NLP-extracted data to a data set usable for
training ML models is obtaining SMILES strings for the donor and acceptor. This had to
be done manually during data curation. There are computer vision tools available that can
convert structures to SMILES strings such as MolScribe49 and OSRA.50 However, donor
or acceptor structures found in the literature are typically part of a larger figure such as a
reaction scheme. Robust segmentation of relevant structures combined with conversion of
structures to SMILES strings is necessary to bridge the gap between NLP extracted data and
trained property predictors. Furthermore, the conversion of polymer structures to SMILES
strings is not possible through these tools and is still an open question.
This study views active learning as a sequential process whereby a material is “chosen”
by the model and tested by the scientist. The only input from the scientist is the list of
materials provided initially. The difficulty of coming up with a perfect initial list ensures
however, that scientists and machines would need to co-ordinate more closely in practice.
The insights generated by the selection process can guide scientific intuition to continuously
update the list of materials. An example of this is provided in Supplemental Information
Section 4.
We also limited our focus to optimizing a single material property, namely the PCE. In
26practice, however, materials scientists are often interested in optimizing multiple properties
simultaneously which may be inversely co-related. In Ref. 10, for instance, the authors
find optimal multi-principal element alloys while optimizing two ductility indicators (Pugh’s
Ratio and Cauchy pressure). Multi-objective Bayesian approaches using hypervolume indi-
cators are a promising approach for solving such problems.51,52 In organic photovoltaics, a
possible direction of inquiry would be a simultaneous optimization of the efficiency, flexibil-
ity, and stability of the solar cell. PSCs need to be stable and retain their power conversion
efficiency with usage. This is typically inversely co-related with PCE. Higher flexibility PSCs
usually have weaker mechanical properties and therefore lower PCE.53–55
The ability to scale up the pipeline we have built to other properties and materials classes
will significantly speed up the development and deployment of new materials. This in turn
will accelerate scientific discovery across many critical applications such as clean energy,
healthcare, and devices.
Acknowledgements
This work was also supported by the Office of Naval Research through grants N00014-19-1-
2103 and N00014-20-1-2175. Pranav Shetty was funded by a fellowship by JPMorgan Chase
& Co. that helped to support this research. Any views or opinions expressed herein are
solely those of the authors listed, and may differ from the views and opinions expressed by
JPMorgan Chase & Co. or its affiliates.
Data and software availability
All code and data needed to reproduce the results in this paper can be found at https:
//github.com/pranav-s/PolymerSolarCellsML
27References
(1) Mannodi-Kanakkithodi, A.; Chandrasekaran, A.; Kim, C.; Huan, T. D.; Pilania, G.;
Botu,V.; Ramprasad,R.Scopingthepolymergenome: Aroadmapforrationalpolymer
dielectrics design and beyond. Materials Today 2018, 21, 785–796.
(2) Ma, R.; Sharma, V.; Baldwin, A. F.; Tefferi, M.; Offenbach, I.; Cakmak, M.; Weiss, R.;
Cao, Y.; Ramprasad, R.; Sotzing, G. A. Rational design and synthesis of polythioureas
as capacitor dielectrics. Journal of Materials Chemistry A 2015, 3, 14845–14852.
(3) Wu, C.; Chen, L.; Deshmukh, A.; Kamal, D.; Li, Z.; Shetty, P.; Zhou, J.; Sahu, H.;
Tran, H.; Sotzing, G.; others Dielectric polymers tolerant to electric field and tempera-
tureextremes: Integrationofphenomenology, informatics, andexperimentalvalidation.
ACS Applied Materials & Interfaces 2021, 13, 53416–53424.
(4) He, J.; Rabe, K. M.; Wolverton, C. Computationally accelerated discovery of functional
and structural Heusler materials. MRS Bulletin 2022, 47, 559–572.
(5) Jia, X.; Deng, Y.; Bao, X.; Yao, H.; Li, S.; Li, Z.; Chen, C.; Wang, X.; Mao, J.;
Cao, F.; others Unsupervised machine learning for discovery of promising half-Heusler
thermoelectric materials. npj Computational Materials 2022, 8, 34.
(6) Kranthiraja, K.; Saeki, A. Machine Learning-Assisted Polymer Design for Improving
the Performance of Non-Fullerene Organic Solar Cells. ACS Applied Materials & Inter-
faces 2022, 14, 28936–28944.
(7) Sun, W.; Zheng, Y.; Yang, K.; Zhang, Q.; Shah, A. A.; Wu, Z.; Sun, Y.; Feng, L.;
Chen, D.; Xiao, Z.; others Machine learning–assisted molecular design and efficiency
predictionforhigh-performanceorganicphotovoltaicmaterials.Science advances 2019,
5, eaay4275.
28(8) Yang, J.; Tao, L.; He, J.; McCutcheon, J. R.; Li, Y. Machine learning enables in-
terpretable discovery of innovative polymers for gas separation membranes. Science
Advances 2022, 8, eabn9545.
(9) MacLeod, B. P.; Parlane, F. G.; Morrissey, T. D.; Ha¨se, F.; Roch, L. M.; Dettel-
bach, K. E.; Moreira, R.; Yunker, L. P.; Rooney, M. B.; Deeth, J. R.; others Self-driving
laboratory for accelerated discovery of thin-film materials. Science Advances 2020, 6,
eaaz8867.
(10) Khatamsaz, D.; Vela, B.; Singh, P.; Johnson, D. D.; Allaire, D.; Arro´yave, R. Multi-
objective materials bayesian optimization with active learning of design constraints:
Design of ductile refractory multi-principal-element alloys. Acta Materialia 2022, 236,
118133.
(11) Kim, C.; Chandrasekaran, A.; Jha, A.; Ramprasad, R. Active-learning and materials
design: the example of high glass transition temperature polymers. Mrs Communica-
tions 2019, 9, 860–866.
(12) Rohr, B.; Stein, H. S.; Guevarra, D.; Wang, Y.; Haber, J. A.; Aykol, M.; Suram, S. K.;
Gregoire, J. M. Benchmarking the acceleration of materials discovery by sequential
learning. Chemical science 2020, 11, 2696–2706.
(13) Wang, A.; Liang, H.; McDannald, A.; Takeuchi, I.; Kusne, A. G. Benchmarking active
learning strategies for materials optimization and discovery. Oxford Open Materials
Science 2022, 2, itac006.
(14) Borg, C. K.; Muckley, E. S.; Nyby, C.; Saal, J. E.; Ward, L.; Mehta, A.; Meredig, B.
Quantifying the performance of machine learning models in materials discovery. Digital
Discovery 2023, 2, 327–338.
(15) Fu, H.; Wang, Z.; Sun, Y. Polymer donors for high-performance non-fullerene organic
solar cells. Angew. Chem. Int 2019, 58, 4442–4453.
29(16) Nagasawa, S.; Al-Naamani, E.; Saeki, A. Computer-aided screening of conjugated poly-
mers for organic solar cell: classification by random forest. J. Phys. Chem 2018, 9,
2639–2646.
(17) Miyake, Y.; Saeki, A. Machine learning-assisted development of organic solar cell mate-
rials: issues, analyses, and outlooks. The Journal of Physical Chemistry Letters 2021,
12, 12391–12401.
(18) Greenstein, B. L.; Hutchison, G. R. Screening Efficient Tandem Organic Solar Cells
with Machine Learning and Genetic Algorithms. The Journal of Physical Chemistry C
2023, 127, 6179–6191.
(19) Lopez, S. A.; Pyzer-Knapp, E. O.; Simm, G. N.; Lutzow, T.; Li, K.; Seress, L. R.;
Hachmann, J.; Aspuru-Guzik, A. The Harvard organic photovoltaic dataset. Scientific
data 2016, 3, 1–7.
(20) Shetty, P.; Ramprasad, R. Automated knowledge extraction from polymer literature
using natural language processing. iScience 2020, 24, 101922.
(21) Shetty, P.; Ramprasad, R. Machine-Guided Polymer Knowledge Extraction Using Nat-
ural Language Processing: The Example of Named Entity Normalization. Journal of
Chemical Information and Modeling 2021, 61, 5377–5385.
(22) Shetty, P.; Rajan, A. C.; Kuenneth, C.; Gupta, S.; Panchumarti, L. P.; Holm, L.;
Zhang,C.; Ramprasad,R.Ageneral-purposematerialpropertydataextractionpipeline
from large polymer corpora using natural language processing. npj Computational Ma-
terials 2023, 9, 52.
(23) Kuenneth, C.; Ramprasad, R. polyBERT: a chemical language model to enable fully
machine-driven ultrafast polymer informatics. Nature Communications 2023, 14, 4099.
30(24) Zhao, J.; Yao, C.; Ali, M. U.; Miao, J.; Meng, H. Recent advances in high-performance
organic solar cells enabled by acceptor–donor–acceptor–donor–acceptor (A–DA’ D–A)
type acceptors. Materials Chemistry Frontiers 2020, 4, 3487–3504.
(25) Doan Tran, H.; Kim, C.; Chen, L.; Chandrasekaran, A.; Batra, R.; Venkatram, S.; Ka-
mal, D.; Lightstone, J. P.; Gurnani, R.; Shetty, P.; others Machine-learning predictions
of polymer properties with Polymer Genome. J. Appl. Phys. 2020, 128, 171104.
(26) Gurnani, R.; Kuenneth, C.; Toland, A.; Ramprasad, R. Polymer Informatics at Scale
with Multitask Graph Neural Networks. Chemistry of Materials 2023, 35, 1560–1567.
(27) Kuenneth, C.; Schertzer, W.; Ramprasad, R. Copolymer informatics with multitask
deep neural networks. Macromolecules 2021, 54, 5957–5961.
(28) Kamath, A.; Vargas-Herna´ndez, R. A.; Krems, R. V.; Carrington, T.; Manzhos, S. Neu-
ral networks vs Gaussian process regression for representing potential energy surfaces:
A comparative study of fit quality and vibrational spectrum accuracy. The Journal of
chemical physics 2018, 148.
(29) Pedregosa, F. et al. Scikit-learn: Machine Learning in Python. Journal of Machine
Learning Research 2011, 12, 2825–2830.
(30) Williams, C. K.; Rasmussen, C. E. Gaussian processes for machine learning; MIT press
Cambridge, MA, 2006; Vol. 2.
(31) Agrawal, S.; Goyal, N. Thompson sampling for contextual bandits with linear payoffs.
International conference on machine learning. 2013; pp 127–135.
(32) Bin, H.; van der Pol, T. P.; Li, J.; van Gorkom, B. T.; Wienk, M. M.; Janssen, R. A. Ef-
ficient organic solar cells with small energy losses based on a wide-bandgap trialkylsilyl-
substituted donor polymer and a non-fullerene acceptor. Chemical Engineering Journal
2022, 435, 134878.
31(33) Jain, S.; van Zuylen, M.; Hajishirzi, H.; Beltagy, I. SciREX: A challenge dataset for
document-level information extraction. arXiv preprint arXiv:2005.00512 2020,
(34) Song, C. E.; Ham, H.; Noh, J.; Lee, S. K.; Kang, I.-N. Efficiency enhancement of a
fluorinated wide-bandgap polymer for ternary nonfullerene organic solar cells. Polymer
2020, 188, 122131.
(35) Zhu, L.; Zhong, W.; Qiu, C.; Lyu, B.; Zhou, Z.; Zhang, M.; Song, J.; Xu, J.; Wang, J.;
Ali, J.; others Aggregation-induced multilength scaled morphology enabling 11.76%
efficiencyinall-polymersolarcellsusingprintingfabrication.Advanced Materials 2019,
31, 1902899.
(36) Wang, H.; Liu, T.; Zhou, J.; Mo, D.; Han, L.; Lai, H.; Chen, H.; Zheng, N.; Zhu, Y.;
Xie, Z.; others Bromination: an alternative strategy for non-fullerene small molecule
acceptors. Advanced Science 2020, 7, 1903784.
(37) Li, X.; Weng, K.; Ryu, H. S.; Guo, J.; Zhang, X.; Xia, T.; Fu, H.; Wei, D.; Min, J.;
Zhang, Y.; others Non-Fullerene Organic Solar Cells Based on Benzo [1, 2-b: 4, 5-b’]
difuran-ConjugatedPolymerwith14%Efficiency.Advanced Functional Materials 2020,
30, 1906809.
(38) Ma, L.; Zhang, S.; Yao, H.; Xu, Y.; Wang, J.; Zu, Y.; Hou, J. High-efficiency non-
fullerene organic solar cells enabled by 1000 nm thick active layers with a low trap-state
density. ACS applied materials & interfaces 2020, 12, 18777–18784.
(39) Sun, C.; Pan, F.; Chen, S.; Wang, R.; Sun, R.; Shang, Z.; Qiu, B.; Min, J.; Lv, M.;
Meng, L.; others Achieving fast charge separation and low nonradiative recombination
loss by rational fluorination for high-efficiency polymer solar cells. Advanced Materials
2019, 31, 1905480.
(40) Zhang, C.; Song, X.; Liu, K.-K.; Zhang, M.; Qu, J.; Yang, C.; Yuan, G.-Z.; Mah-
mood, A.; Liu, F.; He, F.; others Electron-Deficient and Quinoid Central Unit Engi-
32neering for Unfused Ring-Based A1–D–A2–D–A1-Type Acceptor Enables High Perfor-
mance Nonfullerene Polymer Solar Cells with High Voc and PCE Simultaneously. Small
2020, 16, 1907681.
(41) Li, G.; Cheng, H.; Zhang, Y.; Yang, T.; Liu, Y. Higher open circuit voltage caused by
chlorinated polymers endows improved efficiency of binary organic solar cell. Organic
Electronics 2020, 83, 105776.
(42) He, E.; Zheng, Z.; Lu, Y.; Guo, F.; Gao, S.; Pang, X.; Mola, G. T.; Zhao, L.; Zhang, Y.
Highly efficient non-fullerene polymer solar cells from a benzo [1, 2-b: 4, 5-b’] difuran-
based conjugated polymer with improved stabilities. Journal of Materials Chemistry A
2020, 8, 11381–11390.
(43) He, Q.; Shahid, M.; Wu, J.; Jiao, X.; Eisner, F. D.; Hodsden, T.; Fei, Z.; Anthopou-
los, T. D.; McNeill, C. R.; Durrant, J. R.; others Fused cyclopentadithienothiophene
acceptor enables ultrahigh short-circuit current and high efficiency¿ 11% in as-cast
organic solar cells. Advanced Functional Materials 2019, 29, 1904956.
(44) Huang, J.; Peng, R.; Xie, L.; Song, W.; Hong, L.; Chen, S.; Wei, Q.; Ge, Z. A novel
polymer donor based on dithieno [2, 3-d: 2’, 3’-d”] benzo [1, 2-b: 4, 5-b’] dithiophene
for highly efficient polymer solar cells. Journal of Materials Chemistry A 2019, 7,
2646–2652.
(45) Firdaus, Y.; Maffei, L. P.; Cruciani, F.; Mu¨ller, M. A.; Liu, S.; Lopatin, S.; Wehbe, N.;
Ndjawa, G. O. N.; Amassian, A.; Laquai, F.; others Polymer Main-Chain Substitution
Effects on the Efficiency of Nonfullerene BHJ Solar Cells. Advanced Energy Materials
2017, 7, 1700834.
(46) Fujinuma, N.; DeCost, B.; Hattrick-Simpers, J.; Lofland, S. E. Why big data and com-
pute are not necessarily the path to big materials science. Communications Materials
2022, 3, 59.
33(47) Dyakonov, V. Electrical aspects of operation of polymer–fullerene solar cells. Thin Solid
Films 2004, 451, 493–497.
(48) McInnes, L.; Healy, J.; Melville, J. Umap: Uniform manifold approximation and pro-
jection for dimension reduction. arXiv preprint arXiv:1802.03426 2018,
(49) Qian, Y.; Guo, J.; Tu, Z.; Li, Z.; Coley, C. W.; Barzilay, R. MolScribe: Robust Molec-
ular Structure Recognition with Image-to-Graph Generation. Journal of Chemical In-
formation and Modeling 2023, 63, 1925–1934.
(50) Filippov, I. V.; Nicklaus, M. C. Optical structure recognition software to recover chem-
ical information: OSRA, an open source solution. 2009.
(51) Yang, Q.; Ding, S. Novel algorithm to calculate hypervolume indicator of Pareto ap-
proximation set. International Conference on Intelligent Computing. 2007; pp 235–244.
(52) Emmerich, M. T.; Deutz, A. H.; Klinkenberg, J. W. Hypervolume-based expected im-
provement: Monotonicity properties and exact computation. 2011 IEEE Congress of
Evolutionary Computation (CEC). 2011; pp 2147–2154.
(53) Xu, X.; Fukuda, K.; Karki, A.; Park, S.; Kimura, H.; Jinno, H.; Watanabe, N.; Ya-
mamoto, S.; Shimomura, S.; Kitazawa, D.; others Thermally stable, highly efficient,
ultraflexible organic photovoltaics. Proceedings of the National Academy of Sciences
2018, 115, 4589–4594.
(54) Gevorgyan, S. A.; Heckler, I. M.; Bundgaard, E.; Corazza, M.; H¨osel, M.;
Søndergaard, R. R.; dos Reis Benatto, G. A.; Jørgensen, M.; Krebs, F. C. Improving,
characterizing and predicting the lifetime of organic photovoltaics. Journal of Physics
D: Applied Physics 2017, 50, 103001.
(55) Rafique, S.; Abdullah, S. M.; Sulaiman, K.; Iwamoto, M. Fundamentals of bulk hetero-
34junction organic solar cells: An overview of stability/degradation issues and strategies
for improvement. Renewable and Sustainable Energy Reviews 2018, 84, 43–53.
35