CAPTURE-24: A large dataset of wrist-worn activity
tracker data collected in the wild for human activity
recognition
Shing Chan1,2, Hang Yuan1,2, Catherine Tong3, Aidan Acquah1,2,4, Abram Schonfeldt1,2,
Jonathan Gershuny5, and Aiden Doherty1,2*
1BigDataInstitute,UniversityofOxford,Oxford,UK
2NuffieldDepartmentofPopulationHealth,UniversityofOxford,Oxford,UK
3DepartmentofComputerScience,UniversityofOxford,Oxford,UK
4DepartmentofEngineeringScience,UniversityofOxford,Oxford,UK
5SocialResearchInstitute,UniversityCollegeLondon,London,UK
*correspondingauthor: AidenDoherty(aiden.doherty@ndph.ox.ac.uk)
ABSTRACT
Existingactivitytrackerdatasetsforhumanactivityrecognitionaretypicallyobtainedbyhavingparticipantsperformpredefined
activitiesinanenclosedenvironmentundersupervision. Thisresultsinsmalldatasetswithalimitednumberofactivitiesand
heterogeneity,lackingthemixedandnuancedmovementsnormallyfoundinfree-livingscenarios. Assuch,modelstrainedon
laboratory-styledatasetsmaynotgeneraliseoutofsample. Toaddressthisproblem,weintroduceanewdatasetinvolving
wrist-wornaccelerometers,wearablecameras,andsleepdiaries,enablingdatacollectionforover24hoursinafree-living
setting. TheresultisCAPTURE-24,alargeactivitytrackerdatasetcollectedinthewildfrom151participants,amountingto
3883hoursofaccelerometerdata,ofwhich2562hoursareannotated. CAPTURE-24istwotothreeordersofmagnitude
largerthanexistingpubliclyavailabledatasets,whichiscriticaltodevelopingaccuratehumanactivityrecognitionmodels.
Background & Summary
WiththeincreasingadoptionofactivitytrackerssuchasFitbitandAppleWatch,theabilitytoextractobjectivehealth-related
behaviouralinsightsatanunprecedentedscalepromptsnewopportunitiesinmedicine. Aparticularlypromisingdirectionis
theuseofaccelerometer-basedactivityrecognitioninhealthcare,whereitisstillcommontouserecalldiariesortimeand
labour-intensive methods such as clinical fitness tests. These approaches suffer from objectivity and/or scalability issues.
Wrist-worn accelerometers, being low-cost, low-powered and convenient, allow us to efficiently obtain an objective and
high-resolutionpictureofauser’sdailyactivities,whichbringsnewopportunitiesforreal-timeprecisionmedicine,digital
phenotypingforroutinecareandclinicaltrials1–3,andlarge-scalepopulationandepidemiologicalstudies4–6. Thesuccess
oftheseapplicationsdependsonareliableactivityrecognitionmodel,whichrequiresasizeableandrepresentativelabelled
dataset.
However,existingopenaccelerometerdatasetshavemanyshortcomingsduetothedatacollectionprotocolcommonly
employed, whereby participants are invited to an enclosed environment to engage in a set of activities pre-defined by the
experimenters,ofteninagivensequenceandundersomeformofsupervision. Thislaboratory-stylesetupcausesthefollowing
limitations: 1)theamountofdatacollectedisusuallysmallasthisisalabour-intensiveapproach;2)itoftendoesnotallow
formixedactivities; 3)evenwhenmixedactivitiesareallowed,thenatureofthestudy(instructionprompting,supervised
performance,enclosedenvironment)encourageshomogeneousprototypicalmovementpatternsasparticipantsaresubject
toacquiescencebias;4)thesequenceofactivitiesisartificial. Thelattermeansthatsuchdatacannotbeusedforsequence
modelling(e.g. hiddenMarkovmodels,recurrentneuralnetworks)–forexample,ifthestudywereconductedinawaythatthe
sequenceofactivitieswasfixed,sequencemodellingwouldbehighlyoverfittedtothissequence(thetransitionmatrixwouldbe
sparseandclosetoidentity),showinghighin-datasettestaccuracybutfailingtogeneraliseoutsidethedataset(notethatsimply
randomisingthesequencedoesnotfixtheproblem). Theendresultofalltheselimitationsisamodelthatseemstoperform
wellinthestudyevenwithpropervalidationandtestingbutunderperformsintherealworld.
Inthiswork,weaddresstheseissuesbyreleasingtheCAPTURE-24dataset–alarge,in-the-wilddatasetofannotated
wrist-wornaccelerometerreadings,whichwasfirstdesignedtotesttime-usediaryagainstdevicemeasurements7. CAPTURE-
24includesannotatedaccelerometerdatafrom151participants,eachwitharound24hoursofweartime,makingitseveral
4202
beF
92
]CH.sc[
1v92291.2042:viXraTable1. Publiclyavailablewrist-wornaccelerometerdatasets. hrs: hours;ppl: people;mins: minutes.
Dataset Size Annotations† Domain Free-living Year
CAPTURE-24 2562hrs(151ppl×24hrs)‡ >200 Leisure,Sports,Occupation ✓ 2024
Clemson8 120hrs(30pplx240mins) Steps Leisure ✗ 2017
WISDM9 43hrs(51ppl×54mins) 18 Leisure ✗ 2019
REALDISP10 39.8hrs(17pplx140.5mins) 33 Sports ✗ 2012
OxWalk11 39hrs(39pplx60mins) Steps Leisure ✓ 2023
Hang-Time12 37.8hrs(24pplx94.4mins) 11 Sports ✓ 2023
LeisureActivities13 27.7hrs(6pplx277mins) 6 Leisure ✓ 2012
WetLab14 21.0hrs(22pplx57.2mins) 8 Occupation ✗ 2015
Realworld15 18hrs(15ppl×70mins) 8 Leisure ✗ 2016
SmartwatchSwimming16 17hrs(40pplx25.5mins) 5 Sports ✗ 2019
WEAR17 15hrs(18pplx50mins) 18 Sports ✓ 2023
TNDA-HAR18 5.7hrs(23pplx14.6mins) 8 Leisure ✗ 2021
Opportunity++19 5.3hrs(4ppl×80mins) >24,000 Leisure,Gestures ✗ 2021
Opportunity20 5.3hrs(4ppl×80mins) 13 Leisure,Gestures ✗ 2010
UCBerkleyWARD21 5hrs(20pplx15mins) 13 Leisure ✗ 2009
PAMAP222 4.5hrs(9pplx30mins) 18 Leisure ✗ 2012
CMU-MMAC23 3.6hrs(43ppl×5mins) 5 Cooking ✗ 2008
Skoda24 3hrs(1pplx180mins) 10 Occupation ✗ 2008
ADL25 2.7hrs(16pplx10mins) 14 Leisure ✗ 2014
MHEALTH26 2.5hrs(10pplx15mins) 12 Leisure ✗ 2014
UTD-MHAD27 1.4hrs(8pplx10.8mins) 27 Gestures ✗ 2015
UCBerkleyHMAD28 1.3hrs(12pplx6.3mins) 11 Leisure,Gestures ✗ 2013
DailyandSportsActivities29 0.7hrs(8pplx5mins) 19 Leisure,Sports ✗ 2010
UTD-MHADKinectV230 0.4hrs(6pplx4.3mins) 10 Gestures ✗ 2015
†Fordatasetswithannotationsatdifferentlevelsofgranuality,thelargestnumberofannotationsatagivenlevelofgranularitywaschosen.
‡Wereleased3883hoursoftotalrecording,ofwhich2562hoursarelabelled.
ordersofmagnitudelargerthanexistingdatasets(Table1). WeanticipatetheCAPTURE-24datasettobeavaluableresourcein
wearablesensor-basedhumanactivityrecognition,especiallyforresearchindata-hungrymethodssuchasdeeplearning. We
illustratethisinourbenchmarks,whichincludecommonlyusedmethodssuchasrandomforest,XGBoost,hiddenMarkov
models,anddeeplearningmethods.
Methods
DataAcquisition
TheCAPTURE-24studywasthefirstsizeableattempttotesttraditionalself-reporttime-usediariesagainstreal-timepassive
sensinginstruments,namely,wearablecamerasandactivitytrackers7. Datacollectedfromthisstudy(carriedoutin2014-2015)
forms the majority of our CAPTURE-24 dataset – the data being released includes additional data collected since then.
Additionalprocessing,labellingforactivityrecognition,andanonymizationwereconductedtopermititsopenrelease. An
overviewoftheprocedurescarriedoutisdepictedinFigure1.
ThedesignandassociatedoperatingproceduresoftheCAPTURE-24studywerebasedonthefindingsofapilotstudy
(n=14)31. Members of the public from Oxfordshire, United Kingdom, were recruited as study participants following
advertisements with a £20 voucher for taking part. A member of the research team met with participants to explain the
projectpurpose,gainwritteninformedconsent,completeashortdemographicquestionnaire(includinggender,age,heightand
weight)anddelivertheinstruments. Duringthedesignateddatacollectionday,participantswereaskedtowearawrist-worn
accelerometercontinuouslyandawearablecamerawhileawake. Forsleepmonitoring,participantswereaskedtocompletea
simplesleepdiaryconsistingoftwoquestions: “whattimedidyoufirstfallasleeplastnight?” and“whattimedidyouwakeup
today(eyesopen,readytogetup)?”. ParticipantswerealsoaskedtokeepaharmonisedEuropeantime-usesurvey32,from
whichsleepinformationwasextractedwhendatawasmissingfromthesimplesleepdiary. Aninitial166participantswere
recruited,ofwhich151remainedafterdisregardingparticipantswithincomplete,corruptedand/orbadqualitydata.
Accelerometer ParticipantswereaskedtowearanAxivityAX3wrist-worntri-axialaccelerometerontheirdominanthand.
Theaccelerometerwassettocapturetri-axialaccelerationdataat100Hzwithadynamicrangeof±8g. Axivitydevicehas
2/17I. Recruitment of 151 IV. Data
III. Data collection in the wild
subjects processing
Annotators’ training
CPA Code
Annotations
II. Passive sensors Data extraction and
synchronization
De-identification
0am 8am 4pm
Mon
Feb. 8
Label scheme
Tue
Feb. 9 definitions
Annotation Example
Home activity; leisure; activities for maintenance of a household; miscellaneous; 9100 Ethics Approval for
Accelerometer Camera retreat/family reunion activities involving sitting eating relaxing talking with more than one Open Release
person; MET 1.8
Figure1. OverviewofthecreationoftheCAPTURE-24Dataset. Recruitedsubjectsworeanactivitytrackerforroughly
24hours. Theyalsoworeacameraduringdaytimeandusedadiarytoregistertheirsleeptimesduringnighttime. Thecollected
datawasprocessedandharmonisedtoobtainaccelerationtime-seriesdataannotatedwiththeactivitiesperformed. CPA:
CompendiumofPhysicalActivities;MET:metabolicequivalent. Notethatthecameraimagesarenotpartofthedatasetrelease.
beenvalidatedforestimatingenergyexpenditureinafree-livingenvironment33. Thisdevicehasalsodemonstratedequivalent
signalvectormagnitudeoutputonmulti-axisshakingtestswithothercommonly-usedaccelerometers34.
Wearable Camera Wearable cameras were used to collect ground truths of the participants’ activities while wearing
the accelerometers. Participants were given an OMG Life Autographer, a wearable camera worn around the neck which
automaticallytakesphotographsevery20-40secondsandhasupto16hoursbatterylifeandstoragecapacityforoverone
week’sworthofimages35. Whenworn,thecameraisreasonablyclosetothewearer’seyelineandhasawide-anglelensto
CAPTUREthewearer’sview36. Previously,annotationsfromwearablecamerashavebeenfoundtohavestrongagreement
withthemoreexpensivedirectobservationmethodstoclassifyactivitytypes(inter-raterreliabilityviaCohen’sκ of0.92)31.
Recently,thecameraimageshavealsobeenfoundtocorrectlyidentify85%+ofsittingtimeagainstdirectobservations37.
SomesampleimagescapturedbythewearablecameracanbeseeninFigure1.
Duetotheintrusivenatureofwearablecameras,weabidebytheethicalframeworkestablishedbyKellyandcolleagues
throughdatacollectionandprocessing;thisincludedschedulingareviewingsessionwithparticipantswhorevisitedtheirown
cameradatatoremoveanyunwantedorsensitiveimages38. ThepublicCAPTURE-24datasetalsoexcludesimagedatafrom
thewearablecameras–onlytextannotationsoftheimagesareprovided.
DataAnnotation Wereliedonthetime-stampedwearablecameraimagestoannotatetheaccelerometerdataduringwake
time, and sleep diaries during sleep time. To standardize the annotation taxonomy, we employed activity codes from the
CompendiumofPhysicalActivities(CPA)39.Thisdescribesactivitiesandtheircontextsinahierarchicalfashionwithan
associated Metabolic Equivalent of Task (MET) score to represent the mass-specific energy expenditure of activities. An
examplefoundinCAPTURE-24is“occupation; interruption; 11795 walking on job and carrying
light objects such as boxes or pushing trolleys; MET 3.5”. Toensurethereliabilityoftheannota-
tionprocess,allannotatorshadtocompleteashorttrainingcourse. Thiscoveredethicstrainingforhandlingimagedata,usage
ofaspecifically-developedimagebrowsingsoftware40,annotationtraining,andfinallypassingannotationqualitychecksona
held-outgold-standarddataset,whereannotatorshavetoachievean(Cohen’s)inter-rateragreementscoreofκ >0.8.
3/17DataProcessing
DataExtraction TheAxivityOmguisoftware1distributedbytheaccelerometermanufacturerswasusedforinitialization
ofthemeasurements,synchronization,anddownloadingbinaryaccelerometryfilesrecordedonthedevices. Ontopofthis,
weappliedsamplingratecorrectionbynearest-neighborinterpolationtofixanyirregularsamplingthatmayhappendueto
machineerror. Tocorrectforanyaccelerometermiscalibrationandmeasurementdrifts,gravityautocalibration41wasappliedto
reducediscrepanciesacrossdevices.
De-identification Toprotectparticipantprivacy,weselectedasubsetofthecollecteddataforpublicrelease–theaccelerometer
data,thetextannotations,andtheparticipants’genderandage. Imagedataisnotincludedintherelease. Participantages
werebinnedinto4similarly-sizedgroups{“18-29”,“30-37”,“38-52”and“53orabove”}. Forfurtherde-identification,actual
dates were randomized and timestamps were shifted by a small random amount. We also reconsidered the acquired CPA
codeannotationscontainingsensitiveorrareactivities,judgingonacase-by-casebasiswhethertosimplifytheannotationto
ensureanonymization. Ahypotheticalexampleisacodecontainingthedescription“skiing, cross country, >8.0
mph, elite skier, racing; MET 15”whichcomesfromonlyoneparticipantinthedataset(aprofessionalskier),
theannotationwillbere-labeledas“sports; MET 15”. Theinclusionoftheoriginallabel’sMETensuresthattheactivity
intensityisstillretainedintheannotation,butonlyincaseswhereitsinclusiondoesnotpermittheactivitytobeuniquely
identifiedindependentlyfromtheCPA,inwhichcasetheMETvalueisroundedtothenearest,mostcommonlyoccuringMET
valueseeninCAPTURE-24.
Benchmarks
Weconsideredtwoactivityrecognitiontasks:onetoclassifyintensitylevelsofphysicalactivity,andanothertoclassifyactivities
ofdailyliving. Forthese,were-workedtheCPAcodesaccordingly,simplifyingandmappingthemtotwosetsoflabels5,6. The
labelsforintensitiesofphysicalactivityare{“sleep”,“sedentary”,“lightphysicalactivity”,“moderate-to-vigorousphysical
activity”},andthelabelsforactivitiesofdailylivingare{“sleep”,“sitting”,“standing”,“household-chores”,“manual-work”,
“walking”,“mixed-activity”,“vehicle”,“sports”,“bicycling”}.
Datapreprocessingforactivityrecognition
We followed the common practice of sliding-window segmentation42 to extract fixed-size, non-overlapping windows of
ten seconds. This resulted in a dataset of n=922,199 windows in total, each with dimension (3, 1000) (10 sec, 100 Hz,
tri-axial). Datafrom100participants(P001-P100,with618,129windows)wereusedformodelderivation,whiletherest
(P101-P151,with304,070windows)wassetasideformodelevaluation;werefertotheseastheDerivationSetandTestSet
respectively. Theclassdistributioninbothsetsremainedsimilar(seeFigure5intheAppendix).
Models
Weconsiderthefollowingcommonlyusedmethodsintheactivityrecognitionliterature:
• Randomforest(RF) Weusedabalancedrandomforest43with3000trees. Thenumberoftreeswerechosentobeas
largeaspossible. Themodelwasveryrobusttotheremaininghyperparameterchoices,soweusedtherecommended
defaultvalues.
• XGBoost WeusedXGBoost44andBayesianoptimization45totunethehyperparameters(numberofestimators,max
depth,gamma,regularizationcoefficients)with100iterations,althoughwefoundthatitdidnotsignificantlyimprove
uponthedefaulthyperparameters.
• Convolutionalneuralnetwork(CNN) Weuse1Dconvolutions,residualblocks46,andanti-aliaseddownsampling47.
Wetunedthekernelsizes,numberofblocks,andnumberoffiltersusinggridsearchandtheASHAscheduler48. See
AppendixBforfurtherdetails.
• Recurrentneuralnetwork(RNN) ThebackboneofthearchitectureistheCNNmentionedabove,withthesecondlast
layer(originallyafully-connectedlayer)replacedbyabidirectionalLongShort-TermMemorymodule49. Thismodel
cantakeasequenceofwindowstomodeltemporaldependencies. Amaximumsequencelengthof8(80sec)isused. See
AppendixBforfurtherdetails.
• HiddenMarkovmodels(HMM)Additionally,weconsidertheapplicationofhiddenMarkovmodelsontopofall
aforementionedmodelstomodelthetemporaldependenciesbetweenwindows. TheHMMisappliedpost-hoctothe
finalsequenceofoutputsfromthebasemodels. NotethatwhileRNNisalreadyatemporalmodel,wefoundfurther
improvementswhenapplyingHMMontop.
1https://github.com/digitalinteraction/openmovement/wiki/AX3-GUI
4/17Table2. DemographicinformationforCAPTURE-24participants
All DerivationSet TestSet
n(%) n(%) n(%)
Gender
Male 52(34.4) 36(36.0) 16(31.4)
Female 99(65.6) 64(64.0) 35(68.6)
Age
18-29 43(28.5) 27(27.0) 17(33.3)
30-37 37(24.5) 26(26.0) 14(27.5)
38-52 37(24.5) 24(24.0) 10(19.6)
≥53 34(22.5) 23(23.0) 10(19.6)
ForRFandXGBoost,weextractedtime-seriesfeaturesfromtheaccelerometrythatarecommonlyusedintheliterature50
includingtimeandfrequencydomainfeatures,angularandpeakfeatures,resultinginatotalof40featuresperwindow. See
AppendixAforthefulllistoffeatures.
Metrics
Thedistributionofactivitieswashighlyimbalancedreflectingthatthefree-livingnatureofthecollecteddata(“sleeping”,
“sitting”and“standing”makeupmorethan60%ofactivities). Asaresult,wereportedourevaluationsusingmetricswhichare
moreappropriateforthissuchasmacro-averagedF1-score,Cohen’sκ,andPearson-Yule’sφ coefficient51,52(alsoknownas
theMatthewscorrelationcoefficient)onthetestset. weusebootstrapping(n=100)toestimate95%confidenceintervals53on
allreportedmetrics.
Trainingdetails
Inthedeeplearningexperiments,wefurthersplitthederivationsetof100usersinto80users(503,880windows)fortraining
and20users(125,970windows)forvalidationandearlystopping. Abatchsizeof512wasusedthroughoutexceptfortheRNN
modelwhereitwasreducedto64inresponsetoincreasedcomputationalburdenduetothesequencelengthof8. Stochastic
gradientdescentwithrestarts54,55wasusedforoptimization. Fourdataaugmentationmethodswereexplored56: jittering,time
warping,magnitudewarping,andshifting. SeeAppendixBforfurtherdetails.
Data Records
OurdatasetishostedattheOxfordUniversityResearchArchiveundertheCreativeCommons“Attribution4.0International
(CC BY 4.0)” License, at https://doi.org/10.5287/bodleian:NGx0JOMP5. The raw accelerometry data has
beenprocessedandstoredascompressedCSVfilesusingthebiobankAccelerometerAnalysistool. Foreachparticipant,the
rawaccelerometryfilecontainsthefollowingcolumns:
• Time: thetimestampforeachaccelerometryreadinginmilliseconds;
• X,Y,Z:therawaccelerometryalongeachoftheaxesing;
• Annotation: theactivityannotationusingacategoryfromtheCompendiumofPhysicalActivities.
Inaddition,wealsoprovidedthe“annotation-label-dictionary.CSV”toprovidetheannotationmappingfromfine-grained
activitytohigh-levelclassesthatbeformachinelearning,geneticsandpopulationhealthstudies5,57,58. Finally,agegroupand
sexinformationforeachparticipantarestoredin“metadata.CSV”.
Technical Validation
Initially,166participantswererecruited. Afterdiscardingincomplete,corruptedand/orbadqualitydata,151participants
remainedamountingtoatotalof3883hoursofdata. Thedifferentdatasources(activitytracker,camera,sleepdiary)werethen
harmonisedandprocessed,resultingin2562hoursofannotateddata. ParticipantdemographicsaresummarisedinTable2.
Themajorityofparticipantswerewomen(66%). Differentagegroupswererelativelywell-represented,whichisimportantfor
developingmodelsthatgeneralizewellforchangesinmovementpatternsduetoaging(e.g. walkingpace).
5/17Table3. Annotationexamples
Mostfrequent
7030sleeping;MET0.95
occupation;officeandadministrativesupport;11580office/computerworkgeneral;MET1.5
homeactivity;householdchores;preparingmeals/cooking/washingdishes;5035kitchenactivity;MET3.3
homeactivity;miscellaneous;sitting;9060sitting/lyingreadingwithoutobservableactivities;MET1.3
occupation;officeandadministrativesupport;11580officewok/computerworkgeneral;MET1.5
Leastfrequent
homeactivity;householdchores;5140sweepinggaragesidewalkoroutsideofhouse;MET4.0
carryingheavyloads;MET8.0
occupation;interruption;walking;17070walkingdownstairs;MET3.5
leisure;miscellaneous;walking;17070descendingstairs;MET3.5
occupation;interruption;walking;17133walkingupstairs;MET4.0
leisure;miscellaneous;21070(generic)walking/standingcombinationindoor;MET3.0
Table4. LabelsforclassificationtasksonCAPTURE-24usedinpreviousstudiesandtheirintendedobjectives.
Reference Studyobjective Labels
Willettsetal.5 Activityrecognition bicycling,sports,vehicle,
mixed,walking,manual-work,
household-chores,standing,sitting,sleep
Willettsetal.5 Activityrecognition bicycling,sit/stand,walking,
vehicle,mixedactivity,sleep
Dohertyetal.57 Genomicdiscovery sleep,sedentary,walking,
moderatephysicalactivity
Walmsleyetal.6 Epidemiology sleep,sedentarybehaviour,
lightphysicalactivity,
moderate-to-vigorousphysicalactivity
Atotalof206uniqueCPAcodeswereidentified.TheCPAcodesfollowedalong-taildistribution(AppendixC),dominated
bythe“sleeping”activitywhichconstitutemorethanathirdofactivities. ThemostandleastfrequentCPAcodesareshown
inTable3. Asthe206codescanbeoverlydetailed,wedevisedsixschema(includedinthedatarelease)formappingthe
fine-grainedcodesintosetsofsimplifiedlabels.
Eachschemehasanintendeduseaccordingtoaresearchquestion. Forexample,foraepidemiologicalstudyfocusing
onphysicalactivitylevels,itmaybeconvenienttosummarisethecodesinto4classes: “sleep”,“sedentaryactivity”,“light
physicalactivity”,“moderate-to-vigorousphysicalactivity”. Forageneralactivityrecognitionstudy,wemayinsteadconsider
activitiessuchas“walking”,“standing”,“bicycling”. Table4showsthreeschemausedinpreviousworkstoanswerdifferent
researchquestions5,6,57.
Benchmarks
ResultsforthedifferentmodelsaresummarisedinTable5. Scoresfortheclassificationofphysicalactivitylevelsareshown
inTable5a,andthosefortheclassificationofdaily-livingactivitiesareshowninTable5b. Ineachsubtable,tophalfshows
scoresforthebasemodels,andbottomhalfshowsscoresforthemodelsenhancedwithHMMsmoothing. WeseethatHMM
consistentlyachievesbigimprovementsacrosstasks,modelsandmetrics,highlightingtheimportanceofmodellingtemporal
dependencies. Further,wefoundthatRF+HMMandXGBoost+HMMarealreadycompetitive,bothperformingonparor
betterthanthemoreexpensivemodelswithoutHMM.Theimportanceoftemporalmodellingwasalsoseenwithinthemodels
withoutHMM,whereRNNexcelledasithadthecontextofupto8consecutivewindowstomakepredictions. Notably,we
foundthatHMMfurtherimproveduponRNN,suggestingthatlongersequencemodellingwouldbefruitful. Interestingly,we
foundCNN+HMMtobethebestperformingmodeloveralleventhoughRNNperformedbetterinthenon-HMMcases.
ChallengesinActivityRecognitionintheWild Wefoundthatscoresfortheclassificationofdaily-livingactivitieswere
consistentlylowerthanthosefortheclassificationofphysicalactivitylevels. Moregranularclassificationisgenerallyharder
6/17Table5. PerformanceforactivityrecognitionontheCAPTURE-24Dataset. 95%confidenceintervalsareshownin
brackets.
(a)Classifyingphysicalactivitylevels
Model F1-score Cohen’sκ Pearson-Yule’sφ
RF .711(.710,.713) .665(.664,.667) .666(.664,.668)
XGBoost .693(.691,.695) .666(.664,.668) .667(.665,.669)
CNN .716(.714,.718) .704(.703,.706) .704(.702,.705)
RNN .776(.774,.778) .790(.788,.791) .790(.789,.792)
RF+HMM .789(.788,.791) .772(.771,.774) .773(.771,.774)
XGBoost+HMM .783(.781,.785) .772(.771,.774) .773(.771,.774)
CNN+HMM .800(.798,.802) .814(.812,.816) .815(.813,.816)
RNN+HMM .787(.785,.789) .800(.798,.801) .801(.799,.802)
(b)Classifyingactivitiesofdailyliving
Model F1-score Cohen’sκ Pearson-Yule’sφ
RF .388(.386,.390) .514(.512,.516) .519(.518,.521)
XGBoost .399(.396,.401) .576(.574,.577) .580(.579,.582)
CNN .485(.482,.488) .626(.624,.627) .627(.625,.629)
RNN .534(.530,.536) .697(.695,.698) .698(.696,.700)
RF+HMM .486(.484,.489) .637(.636,.639) .641(.639,.643)
XGBoost+HMM .483(.480,.486) .682(.680,.684) .686(.684,.688)
CNN+HMM .576(.574,.580) .735(.733,.736) .737(.736,.739)
RNN+HMM .537(.535,.540) .714(.713,.716) .716(.715,.718)
sleep
sedentary
light
moderate-vigorous
sleep
.98slee .p 01sitti .n 0g 0stan .d 0in 0g hous .0eh 0ol md a- nc .u 0h ao l 0r - we ws alor k .ik 0n 0g mix .e 0d- 0a vc eti hv ii .ct 0ly e 0spor .t 0s 0bicycling
g .08 .78 .06 .04 .03 .00 .00 .01 .00 .00
n
sleep .95 .05 .00 .00
sitt di
ing .01 .28 .30 .19 .13 .05 .01 .03 .00 .00
n
sta
hores .00 .04 .03 .62 .24 .02 .00 .05 .00 .00
sedentary .05 .82 .13 .01 house mh aol nd u- a wlc - alw kio nrk
g
. .0 00
0
. .0 01
5
. .0 03
5
. .6 39
1
. .1 21
1
. .0 25
7
. .0 00
9
. .0 00
1
. .0 01
0
. .0 09
0
light .00 .13 .74 .13
mixed-a vc
eti
hivi clt ey . .0 00
0
. .0 06
7
. .1 00
4
. .2 00
8
. .1 06
2
. .3 01
3
. .1 03
1
. .0 72
5
. .0 01
0
. .0 02
0
moderate-vigorous .00 .03 predicted.27 .70
bics
yp clo ir nts
g
. .0 00
0
. .0 08
0
. .0 02
2
. .0 01
7
p. .0
0
re6
7
dic.
.
t1
0
e5
4
d
. .0 00
0
. .0 08
3
. .3 07
0
. .2 73
7
(a)Classifyingphysicalactivitylevels (b)Classifyingactivitiesofdailyliving
Figure2. Confusionmatrixforrandomforest+HiddenMarkovModel
foralltypesoftasks,butitisespeciallysowithourdatasetduetotheambiguityofmanyfree-livinghumanactivities. Figure2
showstheconfusionmatricesusingtheRF+HMMmodel. Foractivitiesofdailyliving,mostoftheconfusionhappensbetween
7/17
eurt eurtBase models Base models + HMM
0.80
0.75
0.70
0.65
RF RF+HMM
XGBoost XGBoost+HMM
CNN CNN+HMM
0.60
RNN RNN+HMM
20 40 60 80 100 20 40 60 80 100
dataset size (number of subjects) dataset size (number of subjects)
Figure3. F1-scoreasafunctionofdatasetsizeforphysicalactivityclassification
theactivities“household-chores”,“standing”,“walking”,“manual-work”and“mixed-activity”. Thisisexpectedgiventhat,in
free-livingsettings,theseactivitiesarenaturallyintertwined(e.g. thehouseholdchore“cleaning,sweepingcarpetorfloor”
inevitablyinvolvessomedegreeof“walking”and“standing”),asopposedtodatacollectedinlaboratorysettingswherethe
scriptedactivitiestendtobeclearlysegmentedandthemovementpatternsshowlessheterogeneity. Regardingclassificationof
physicalactivityintensitylevels,theirdefinitionsfromreal-worldhumanactivitiestendtobelessambiguous,thereforewe
observedlessconfusionforthisclassificationtask.
PerformanceagainstDatasetSize Wehighlightedtheimportanceofhavinglargedatasetsfordata-intensivedeeplearning
methods. Weassessedtheperformanceasafunctionofdatasetsizebyrunningthebenchmarksonvaryingnumberofsubjects
includedinthederivationset(thetestsetof51subjectsisunchanged). FromFigure3,weobservedthatinthesmall-data
regimetheoutperformanceofdeeplearningmodelsisnotsoclear. Inparticular,ifweconsideronlynon-temporalmodels
(RF,XGBoostandCNN),wecouldseethatCNNonlystartstooutperformafteraround40subjects(≈650person-hours).
Similarlyforthetemporalmodels(RNNand∗-HMM),theclearadvantageofCNN-HMMbecameapparentonlyafteraround
30subjects(≈500person-hours).
Usage Notes
WepresentedtheCAPTURE-24datasettoaddressshortcomingsofexistingactivityrecognitiondatasets–namely,limited
dataset sizes and unrepresentativeness due to intrusive data collection methods resulting in short time spans, limited and
scriptedactivities,lowpatternheterogeneity,andmanufacturedactivitysequences. WedescribedindetailhowCAPTURE-24
addressedtheseissueswithanovelcollectionprotocolinvolvingindirectmeasurementsusingwearablecamerasandsleep
diaries,allowingforlongtimespans(24hoursormore)inreal-worldsettingswhilealsobeinglesslabour-intensiveandmore
scalable. Wealsodescribedprocedurestakentocomplywithprivacyandethicsstandardstopermitthepublicreleaseofthe
dataset. With2562hoursofannotateddata(and3883hoursoverall),thereleaseddatasetis2to3ordersofmagnitudelarger
thanexistingpublicaccelerometerdatasets.
We presented benchmarks for activity recognition on this dataset with commonly used methods in the literature and
discussedchallengesforactivityrecognitioninthewild. Inparticular,wehighlightedchallengesinactivityrecognitionin
thewildasmanyactivitiesintherealworldareintertwined, incontrasttothosecollectedinlaboratorysettings. Wealso
highlightedtheimportanceofhavinglargeHARdatasetsfordeeplearningresearch,suggestingthatexistingdatasetsizesare
insufficienttoachievethefullpotentialoftheirmethods,renderinganymodelcomparisonunreliable.
Limitations. TheCAPTURE-24onlycontainsaconveniencesampleofparticipantsinOxford. Therefore,largerdatasets
usingmorediversepopulationsareneeded. Forexample,asimilardatasetwascollectedinChinaforhumanactivityrecognition
aspartoftheChinaKadoorieBiobankwearablestudy59. Aswearablesensingtechnologiesimprove,multi-modalmonitoring
forhumanactivityrecognitionovertimehasbecomefeasible,improvingthepredictivepowerforlabour-intensiveactivitywith
littlewristmovementandtheclassificationofthesleepstages.
Furthermore,Cameradatamaysometimesbeuninformativeforannotationduetoobstruction,poorlightingconditions
and blurriness. Since the cameras record data at a frame rate (≈0.03Hz) – much lower than that of the accelerometers
(100Hz)–activitiescouldhavebeenmissed. Asaresult,itispossiblethattheannotatorsmayassignCPAcodesthrough
8/17
erocs-1Fguessworkdespiteourbesteffortsincoveringuncertainscenariosintheannotatortraining. AfurtherlimitationwithCPA
codesisthattheywereoriginallydevelopedforuseinepidemiologicalstudiestostandardisetheassignmentofMETvalues
in physical activity questionnaires, thus some codes place more emphasis on distinguishing energy intensities rather than
behaviours. ThisresultsinsomeCPAcodesbeingambiguousforretrospectiveinterpretingandre-labelling. Forexample,the
code“home activity; miscellaneous; standing; 9050 standing talking in person/ on the
phone/ computer (skype chatting) or using a mobile phone/ smartphone/ tablet; MET 1.8”
precludesdistinguishingwhethertheparticipantwasspeakingtosomeoneinpersonorthroughaspecificdevice,whichmight
havebeenusefulinstudieslookingtounderstandpeople’sscreen-timeorsocialbehaviours. Ourexistingbenchmarkincorpo-
ratescommonmethodsusedforHAR,futureworkcouldalsobenefitfromleveragingmorerecentmodelingtechniquesusing
DeepConvLSTM60,61,transformers62,andself-supervisedlearning63–66.
Researchdirections. Althoughthefeasibilityofactivityrecognitionsolelyfromaccelerometerdatahasbeendebatedin
recentwork67,aproperinvestigationhasbeenlackingduetothelackofrealisticdatasets. Asmentioned,currentdatasets
havelimitedandhomogeneousactivitieswhichoptimisticallybiasanyassessment. TheCAPTURE-24couldbeusefulfor
suchinvestigation. TheproblemofopensetrecognitionisanotherinterestingdirectioninHARastherearepracticallyinfinite
numberofactivitiesthatonecouldconsider. Thefine-grainedandhierarchicalannotationsinCAPTURE-24canbeleveraged
tostudythisproblemwithintheframeworkofzero-shotandfew-shotlearning. Finally,wesawthattemporalmodellingusing
hiddenMarkovmodelsconsistentlyimprovedperformance,butothertime-seriesmethods60,62 couldbeinvestigatedleveraging
theuniquelong-spanaspectofourdataset.
Code availability
Allthecodeassociatedwiththisprojectcanbeusedfreeofchargefornon-commercialpurposes.Theannotationtoolusedcanbe
accessedviatheOxfordWearableCameraBrowser: https://github.com/OxWearables/oxford-wearable-\
camera-browser. The data analytics script can be accessed via biobankAccelerometerAnalysis repository: https:
//github.com/OxWearables/biobankAccelerometerAnalysis. Finally, the machine learning benchmarks
canbeaccessedvia: https://github.com/activityMonitoring/capture24.
Acknowledgements
ThisworkissupportedbyNovoNordisk(HY,SC,AD);theWellcomeTrust[223100/Z/21/Z](AD);GlaxoSmithKline(AA);
theBritishHeartFoundationCentreofResearchExcellence[RE/18/3/34214](AD);theNationalInstituteforHealthResearch
(NIHR)OxfordBiomedicalResearchCentre(AD);andHealthDataResearchUK(RW,AD),aninitiativefundedbyUK
ResearchandInnovation,DepartmentofHealthandSocialCare(England)andthedevolvedadministrations,andleading
medicalresearchcharities. ItisalsosupportedbytheUK’sEngineeringandPhysicalSciencesResearchCouncil(EPSRC)
withgrantsEP/S001530/1(theMOAproject)andEP/R018677/1(theOPERAproject)andtheEuropeanResearchCouncil
(ERC)viatheREDIALproject(GrantAgreementID:805194),andindustrialfundingfromSamsungAI.Thedatacollection
wascarriedoutusingfunding(JG)fromtheUKEconomicandSocialResearchCouncil(grantnumberES/L011662/1)andthe
EuropeanResearchCouncilAdvancedGrant(Grantnumber339703). Finally,wewouldliketothankRosemaryWalmsleyfor
hercontributionsinthedatasetcurationandanalysis.
Forthepurposeofopenaccess,theauthorhasappliedaCC-BYpubliccopyrightlicencetoanyauthoracceptedmanuscript
versionarisingfromthissubmission.
Author contributions statement
SC,HY,CT,andADconceivedtheexperiments. SC,HY,CT,AD,ASconductedtheexperiments. SC,HY,CT,AD,AA,and
ASanalysedtheresults. HY,SCwrotethefirstdraftofthemanuscript. Allauthorsreviewedthemanuscript.
Competing interests
Theauthorsdeclarenocompetinginterests.
9/17References
1. Creagh, A.P.etal. Digitalhealthtechnologiesandmachinelearningaugmentpatientreportedoutcomestoremotely
characteriserheumatoidarthritis. MedRxiv2022–11(2022).
2. Schalkamp, A.-K., Peall, K.J., Harrison, N.A.&Sandor, C. Wearablemovement-trackingdataidentifyparkinson’s
diseaseyearsbeforeclinicaldiagnosis. Nat.Medicine1–9(2023).
3. Gupta,A.S.,Patel,S.,Premasiri,A.&Vieira,F. At-homewearablesandmachinelearningsensitivelycapturedisease
progressioninamyotrophiclateralsclerosis. Nat.Commun.14,5080(2023).
4. Master,H.etal. Associationofstepcountsovertimewiththeriskofchronicdiseaseintheallofusresearchprogram. Nat.
medicine28,2301–2308(2022).
5. Willetts,M.,Hollowell,S.,Aslett,L.,Holmes,C.&Doherty,A. Statisticalmachinelearningofsleepandphysicalactivity
phenotypesfromsensordatain96,220ukbiobankparticipants. Sci.reports8,1–10(2018).
6. Walmsley, R. et al. Reallocating time from machine-learned sleep, sedentary behaviour or light physical activity to
moderate-to-vigorousphysicalactivityisassociatedwithlowercardiovasculardiseaserisk. medRxiv(2020).
7. Gershuny,J.etal. Testingself-reporttime-usediariesagainstobjectiveinstrumentsinrealtime. Sociol.Methodol.50,
318–349(2020).
8. Mattfeld,R.,Jesch,E.&Hoover,A. Anewdatasetforevaluatingpedometerperformance. In2017IEEEInternational
ConferenceonBioinformaticsandBiomedicine(BIBM),865–869,10.1109/BIBM.2017.8217769(IEEE,KansasCity,MO,
2017).
9. Weiss,G.M.,Yoneda,K.&Hayajneh,T. SmartphoneandSmartwatch-BasedBiometricsUsingActivitiesofDailyLiving.
IEEEAccess7,133190–133202,10.1109/ACCESS.2019.2940729(2019).
10. Baños,O.etal. Abenchmarkdatasettoevaluatesensordisplacementinactivityrecognition. InProceedingsofthe2012
ACM Conference on Ubiquitous Computing, 1026–1035, 10.1145/2370216.2370437 (ACM, Pittsburgh Pennsylvania,
2012).
11. Small, S. R. et al. Development and Validation of a Machine Learning Wrist-worn Step Detection Algorithm with
DeploymentintheUKBiobank. Preprint,PublicandGlobalHealth(2023). 10.1101/2023.02.20.23285750.
12. Hoelzemann, A., Romero, J. L., Bock, M., Laerhoven, K. V. & Lv, Q. Hang-Time HAR: A Benchmark Dataset for
BasketballActivityRecognitionUsingWrist-WornInertialSensors. Sensors23,10.3390/s23135879(2023).
13. Berlin,E.&VanLaerhoven,K. Detectingleisureactivitieswithdensemotifdiscovery. InProceedingsofthe2012ACM
ConferenceonUbiquitousComputing,250–259,10.1145/2370216.2370257(ACM,PittsburghPennsylvania,2012).
14. Scholl,P.M.,Wille,M.&VanLaerhoven,K. Wearablesinthewetlab: Alaboratorysystemforcapturingandguiding
experiments. InProceedingsofthe2015ACMInternationalJointConferenceonPervasiveandUbiquitousComputing,
589–599,10.1145/2750858.2807547(ACM,OsakaJapan,2015).
15. Sztyler,T.&Stuckenschmidt,H. On-bodylocalizationofwearabledevices: Aninvestigationofposition-awareactivity
recognition. In 2016 IEEE International Conference on Pervasive Computing and Communications (PerCom), 1–9,
10.1109/PERCOM.2016.7456521(IEEE,Sydney,Australia,2016).
16. Brunner, G., Melnyk, D., Sigfússon, B. & Wattenhofer, R. Swimming style recognition and lap counting using a
smartwatch and deep learning. In Proceedings of the 23rd International Symposium on Wearable Computers, 23–31,
10.1145/3341163.3347719(ACM,LondonUnitedKingdom,2019).
17. Bock,M.,Kuehne,H.,VanLaerhoven,K.&Moeller,M. WEAR:AnOutdoorSportsDatasetforWearableandEgocentric
ActivityRecognition,10.48550/ARXIV.2304.05088(2023).
18. Yan,Y.etal. TopologicalNonlinearAnalysisofDynamicalSystemsinWearableSensor-BasedHumanPhysicalActivity
Inference. IEEETransactionsonHuman-MachineSyst.53,792–801,10.1109/THMS.2023.3275774(2023).
19. Ciliberto, M., Fortes Rey, V., Calatroni, A., Lukowicz, P. & Roggen, D. Opportunity++: A Multimodal Dataset for
Video-andWearable,ObjectandAmbientSensors-BasedHumanActivityRecognition. Front.Comput.Sci.3,792065,
10.3389/fcomp.2021.792065(2021).
20. Roggen,D.etal. Collectingcomplexactivitydatasetsinhighlyrichnetworkedsensorenvironments. In2010Seventh
InternationalConferenceonNetworkedSensingSystems(INSS),233–240,10.1109/INSS.2010.5573462(IEEE,Kassel,
Germany,2010).
21. Yang,A.Y.,Kuryloski,P.&Bajcsy,R. WARD:AWearableActionRecognitionDatabase(2009).
10/1722. Reiss,A.&Stricker,D. IntroducingaNewBenchmarkedDatasetforActivityMonitoring. In201216thInternational
SymposiumonWearableComputers,108–109,10.1109/ISWC.2012.13(IEEE,Newcastle,UnitedKingdom,2012).
23. Frade,F.D.l.T.etal. GuidetotheCarnegieMellonUniversityMultimodalActivity(CMU-MMAC)Database. Tech.Rep.
CMU-RI-TR-08-22,CarnegieMellonUniversity,Pittsburgh,PA(2008).
24. Zappi,P.etal. ActivityRecognitionfromOn-BodySensors: Accuracy-PowerTrade-OffbyDynamicSensorSelection. In
Verdone,R.(ed.)WirelessSensorNetworks,vol.4913,17–33,10.1007/978-3-540-77690-1_2(SpringerBerlinHeidelberg,
Berlin,Heidelberg,2008).
25. Bruno, B., Mastrogiovanni, F., Sgorbissa, A., Vernazza, T. & Zaccaria, R. Analysis of human behavior recognition
algorithmsbasedonaccelerationdata. In2013IEEEInternationalConferenceonRoboticsandAutomation,1602–1607,
10.1109/ICRA.2013.6630784(IEEE,Karlsruhe,Germany,2013).
26. Banos, O. et al. mHealthDroid: A Novel Framework for Agile Development of Mobile Health Applications. In
Pecchia,L.,Chen,L.L.,Nugent,C.&Bravo,J.(eds.)AmbientAssistedLivingandDailyActivities,vol.8868,91–98,
10.1007/978-3-319-13105-4_14(SpringerInternationalPublishing,Cham,2014).
27. Chen,C.,Jafari,R.&Kehtarnavaz,N. UTD-MHAD:Amultimodaldatasetforhumanactionrecognitionutilizingadepth
cameraandawearableinertialsensor. In2015IEEEInternationalConferenceonImageProcessing(ICIP),168–172,
10.1109/ICIP.2015.7350781(IEEE,QuebecCity,QC,Canada,2015).
28. Ofli,F.,Chaudhry,R.,Kurillo,G.,Vidal,R.&Bajcsy,R. BerkeleyMHAD:AcomprehensiveMultimodalHumanAction
Database. In2013IEEEWorkshoponApplicationsofComputerVision(WACV),53–60,10.1109/WACV.2013.6474999
(IEEE,ClearwaterBeach,FL,USA,2013).
29. Altun,K.,Barshan,B.&Tunçel,O.Comparativestudyonclassifyinghumanactivitieswithminiatureinertialandmagnetic
sensors. PatternRecognit.43,3605–3620,10.1016/j.patcog.2010.04.019(2010).
30. Chen,C.,Jafari,R.&Kehtarnavaz,N. UTDMultimodalHumanActionDataset(UTD-MHAD)KinectV2(2015).
31. Kelly,P.etal. Developingamethodtotestthevalidityof24hourtimeusediariesusingwearablecameras: afeasibility
pilot. PLoSOne10,e0142198(2015).
32. oftheEuropeanCommission,S.O.etal. Harmonisedeuropeantimeusesurveys,2008guidelines. Off.forOff.Publ.Eur.
Communities(2009).
33. White,T.etal. Estimatingenergyexpenditurefromwristandthighaccelerometryinfree-livingadults: adoublylabelled
waterstudy. Int.journalobesity43,2333–2342(2019).
34. Ladha,C.,Ladha,K.,Jackson,D.&Olivier,P. Shakertablevalidationofopenmovementax3accelerometer. InAhmerst
(ICAMPAM 2013 AMHERST): In 3rd International Conference on Ambulatory Monitoring of Physical Activity and
Movement,69–70(2013).
35. Doherty, A.R.etal. Wearablecamerasinhealth: thestateoftheartandfuturepossibilities. Am.journalpreventive
medicine44,320–323(2013).
36. Hodges,S.etal. Sensecam: Aretrospectivememoryaid. InInternationalConferenceonUbiquitousComputing,177–193
(Springer,2006).
37. Martinez,J.etal. Validationofwearablecamerastillimagestoassesspostureinfree-livingconditions. J.formeasurement
physicalbehaviour4,47–52(2021).
38. Kelly,P.etal. Ethicsofusingwearablecamerasdevicesinhealthbehaviourresearch. AmJPrevMed44,314–319(2013).
39. Ainsworth,B.E.etal. 2011compendiumofphysicalactivities: asecondupdateofcodesandmetvalues. MedSciSports
Exerc.43,1575–1581(2011).
40. Doherty,A.R.,Moulin,C.J.&Smeaton,A.F. Automaticallyassistinghumanmemory: Asensecambrowser. Memory19,
785–795(2011).
41. VanHees,V.T.etal. Autocalibrationofaccelerometerdataforfree-livingphysicalactivityassessmentusinglocalgravity
andtemperature: anevaluationonfourcontinents. J.appliedphysiology117,738–744(2014).
42. Bulling,A.,Blanke,U.&Schiele,B. Atutorialonhumanactivityrecognitionusingbody-worninertialsensors. ACM
Comput.Surv.(CSUR)46,1–33(2014).
43. Chen,C.,Liaw,A.&Breiman,L. Usingrandomforesttolearnimbalanceddata. Tech.Rep.666,UniversityofCalifornia,
Berkeley(2004).
11/1744. Chen,T.&Guestrin,C. Xgboost: Ascalabletreeboostingsystem. InProceedingsofthe22ndacmsigkddinternational
conferenceonknowledgediscoveryanddatamining,785–794(2016).
45. Bergstra, J., Yamins, D. & Cox, D. Making a science of model search: Hyperparameter optimization in hundreds of
dimensionsforvisionarchitectures. InInternationalconferenceonmachinelearning,115–123(PMLR,2013).
46. He,K.,Zhang,X.,Ren,S.&Sun,J. Identitymappingsindeepresidualnetworks. InECCV,630–645(Springer,2016).
47. Zhang, R. Making convolutional networks shift-invariant again. In International conference on machine learning,
7324–7334(PMLR,2019).
48. Li,L.etal. Asystemformassivelyparallelhyperparametertuning. arXivpreprintarXiv:1810.05934(2018).
49. Hochreiter,S.&Schmidhuber,J. Longshort-termmemory. Neuralcomputation9,1735–1780(1997).
50. Twomey, N. et al. A comprehensive study of activity recognition using accelerometers. In Informatics, vol. 5, 27
(MultidisciplinaryDigitalPublishingInstitute,2018).
51. Yule,G.U. Onthemethodsofmeasuringassociationbetweentwoattributes. J.RoyalStat.Soc.75,579–652(1912).
52. Cramér,H. MathematicalMethodsofStatistics(PMS-9),Volume9(Princetonuniversitypress,2016).
53. Efron,B. Thejackknife,thebootstrapandotherresamplingplans(SIAM,1982).
54. Loshchilov,I.&Hutter,F. Sgdr: Stochasticgradientdescentwithwarmrestarts. arXivpreprintarXiv:1608.03983(2016).
55. Smith,L.N. Cyclicallearningratesfortrainingneuralnetworks. In2017IEEEwinterconferenceonapplicationsof
computervision(WACV),464–472(IEEE,2017).
56. Um,T.T.etal. Dataaugmentationofwearablesensordataforparkinson’sdiseasemonitoringusingconvolutionalneural
networks. InProceedingsofthe19thACMInternationalConferenceonMultimodalInteraction,216–220(2017).
57. Doherty,A.etal. Gwasidentifies14locifordevice-measuredphysicalactivityandsleepduration. Nat.communications9,
1–8(2018).
58. Walmsley,R.etal.Reallocationoftimebetweendevice-measuredmovementbehavioursandriskofincidentcardiovascular
disease. Br.journalsportsmedicine(2021).
59. Chen,Y.etal. Device-measuredmovementbehavioursinover20,000chinakadooriebiobankparticipants. Int.J.Behav.
Nutr.Phys.Activity20,138(2023).
60. Ordóñez,F.J.&Roggen,D. Deepconvolutionalandlstmrecurrentneuralnetworksformultimodalwearableactivity
recognition. Sensors16,115(2016).
61. Yuan,H.etal. Self-supervisedlearningofaccelerometerdataprovidesnewinsightsforsleepanditsassociationwith
mortality. medRxiv(2023).
62. Haresamudram,H.etal. Maskedreconstructionbasedself-supervisionforhumanactivityrecognition. InProceedingsof
the2020ACMInternationalSymposiumonWearableComputers,45–49(2020).
63. Saeed,A.,Ozcelebi,T.&Lukkien,J. Multi-taskself-supervisedlearningforhumanactivitydetection. Proc.ACMon
Interactive,Mobile,WearableUbiquitousTechnol.3,1–30(2019).
64. Haresamudram,H.,Essa,I.&Plötz,T. Assessingthestateofself-supervisedhumanactivityrecognitionusingwearables.
Proc.ACMonInteractive,Mobile,WearableUbiquitousTechnol.6,1–47(2022).
65. Jain,Y.,Tang,C.I.,Min,C.,Kawsar,F.&Mathur,A. Collossl: Collaborativeself-supervisedlearningforhumanactivity
recognition. Proc.ACMonInteractive,Mobile,WearableUbiquitousTechnol.6,1–28(2022).
66. Yuan,H.etal. Self-supervisedlearningforhumanactivityrecognitionusing700,000person-daysofwearabledata. arXiv
preprintarXiv:2206.02909(2022).
67. Tong,C.,Tailor,S.A.&Lane,N.D. Areaccelerometersforactivityrecognitionadead-end? InProceedingsofthe21st
InternationalWorkshoponMobileComputingSystemsandApplications,39–44(2020).
68. Srivastava,N.,Hinton,G.,Krizhevsky,A.,Sutskever,I.&Salakhutdinov,R. Dropout: asimplewaytopreventneural
networksfromoverfitting. Thejournalmachinelearningresearch15,1929–1958(2014).
69. Ioffe,S.&Szegedy,C. Batchnormalization: Acceleratingdeepnetworktrainingbyreducinginternalcovariateshift. In
Internationalconferenceonmachinelearning,448–456(PMLR,2015).
70. Fukushima,K.&Miyake,S. Neocognitron: Aself-organizingneuralnetworkmodelforamechanismofvisualpattern
recognition. InCompetitionandcooperationinneuralnets,267–285(Springer,1982).
12/1771. Liaw,R.etal. Tune: Aresearchplatformfordistributedmodelselectionandtraining. arXivpreprintarXiv:1807.05118
(2018).
72. Kingma,D.P.&Ba,J. Adam: Amethodforstochasticoptimization. arXivpreprintarXiv:1412.6980(2014).
73. Weiss,G.M.,Yoneda,K.&Hayajneh,T. Smartphoneandsmartwatch-basedbiometricsusingactivitiesofdailyliving.
IEEEAccess7,133190–133202(2019).
74. Bruno, B., Mastrogiovanni, F., Sgorbissa, A., Vernazza, T. & Zaccaria, R. Analysis of human behavior recognition
algorithmsbasedonaccelerationdata. In2013IEEEInternationalConferenceonRoboticsandAutomation,1602–1607
(IEEE,2013).
75. Reiss, A. & Stricker, D. Introducing a new benchmarked dataset for activity monitoring. In 2012 16th international
symposiumonwearablecomputers,108–109(IEEE,2012).
76. Sztyler,T.&Stuckenschmidt,H. On-bodylocalizationofwearabledevices: Aninvestigationofposition-awareactivity
recognition. In2016IEEEInternationalConferenceonPervasiveComputingandCommunications(PerCom),1–9(IEEE,
2016).
13/17A List of hand-crafted features
Thefollowingcommonlyusedfeatures50 (40intotal)areextractedfromtherawaccelerometryfortherandomforestand
XGBoostmodels:
• QuantilesMinimum,maximum,median,25thand75thpercentilesofaccelerationforeachofthethreeaxisstreamsas
wellasthemagnitudestream.
• CorrelationsCorrelationbetweenaxesand1-sec-lagautocorrelationofthemagnitudestream.
• SpectralfeaturesFirstandseconddominantfrequenciesandtheirpowers,andspectralentropy.
• PeakcharacteristicsNumberofpeaksandmedianprominenceofthepeaks.
• AngularfeaturesEstimateddynamicroll,pitchandyaw(meanandstandarddeviation),andgravityroll,pitchandyaw
(mean).
B Hyperparameter tuning details
B.1 Baselinearchitecture
The final architecture is described in Table 6. Here, Conv(k,n) means a 1D convolution with n filters of kernel size k,
m×ResBlock(k,n)meansmresidualblocksofsizemwithnfiltersandkernelsizek46, Drop(p)isdropout68 withrate p,
FC(n)isafullyconnectedlayerwithoutputsizen, BiLSTM(n)isabidirectionalLSTM49 withoutputsizen, andfinally,
Linear(n)isalinearlayerwithoutputsizen. Asusual, batchnormalization69 andrectifiedlinearunits70 followtheConv
layers. RectifiedlinearunitsalsofollowtheFClayer. Allconvolutionsuseastrideandcircularpaddingof1. Downsamplingis
performedwithanti-aliasingasdescribedin47.
Table6. Networkarchitecturesforconvolutionneuralnetwork(CNN)andrecurrentneuralnetwork(RNN)
Statesize Layer
(*,3,1000) Conv(3,128)/2
(*,128,500) Conv(3,128),3xResBlock(3,128)/2
(*,128,250) Conv(3,256),3xResBlock(3,256)/2
(*,256,125) Conv(3,256),3xResBlock(3,256)/5
(*,256,25) Conv(3,512),3xResBlock(3,512)/5
(*,512,5) Conv(3,512),3xResBlock(3,512)/5
(*,512,1) Drop(0.5),FC(1024)orBiLSTM(512(x2))
(*,1024) Linear(6)
FortheRNNmodel,BiLSTMisusedinplaceofFCinordertoingestsequencesofwindows–welimitthemaximum
sequencelengthto8.
We tried k∈{3,5} for the kernel sizes and m∈{0,1,2,3} for number of residual blocks (constrained to be the same
throughout),aninitialconfigurationoffiltersn=64→64→128→128→256→256→512,andawideronen=128→
128→256→256→512→512→1024. WeusedASHA48asimplementedinRayTune71.
B.2 Dataaugmentation
Wetriedfourdataaugmentationtechniques56: jittering,timewarping,magnitudewarping,andshifting. Forjittering,wetried
standarddeviationσ ∈{0,.01,.05,.1}. Fortimeandmagnitudewarping,σ ∈{0,.01,.05,.1}andknots∈{2,4}. Forshifting,
shift∈{0sec,1sec,2sec,5sec}. Toreducecomputationalcost,eachaugmentationtechniqueistriedindependentlyandthe
bestparametersarethencombined. Eachtrialisrununtilearly-stoppedwithpatienceof5. Table7reportsthebestparameters
found. Noteinparticularthatwedidnotfindjitteringtoimproveperformance. Fortheothertechniques,wefoundslightto
moderateimprovements.
B.3 Optimization
Initially,wetunedthearchitectureanddataaugmentationparametersusingAdam72 withlearningrateη =3×10−3. After
tuningwasdone,weretrainedtheoptimalmodelusingstochasticgradientdescentwithrestarts54,55andtriedinitiallearning
ratesη ∈{.1,.15,.2,.25,.3,.35,.4,.45}. Thetrialswererununtilearly-stoppedwithpatienceof5. TheCNNmodelconverged
inaround30epochswhiletheRNNmodelinaround40epochs.
14/17Table7. Dataaugmentationparameters
Technique Parameters
Jittering σ=0
Timewarping σ=.05,knots=4
Magnitudewarping σ=.05,knots=2
Shifting shift=2sec
7030 sleeping;MET 0.95
occupation;office and administrative support;11580 office/computer work general;MET 1.5
home activity;household chores;preparing meals/cooking/washing dishes;5035 kitchen activity general cooking/washing/dishes/cleaning up;MET 3.3
home activity;miscellaneous;sitting;9060 sitting/lying reading or without observable/identifiable activities;MET 1.3
occupation;office and administrative support;11580 office wok/computer work general;MET 1.5
home activity;miscellaneous;walking;17150 walking household without observable loads;MET 2.0
home activity;miscellaneous;sitting;11580 office/computer work general;MET 1.5
transportation;private transportation;16010 driving automobile or light truck (not a semi);MET 2.5
home activity;miscellaneous;sitting;7010 sitting/lying and watching television with TV on as the primary activity;MET 1.0
home activity;miscellaneous;sitting;9055 sitting/lying talking in person/using a mobile phone/smartphone/tablet or talking on the phone/computer (skype chatting);MET 1.5
all other annotations
0 200000
No. of 10s windows
Figure4. Top10mostfrequentCompendiumofPhysicalActivitiescodeannotationsfoundinCapture-24
B.4 Computationalresources
ModelsweretrainedusingaV100GPUwith32GBofRAM.Trainingtimevariesbymodelandtask,butcanallbecompleted
within12h.
C Annotations
Figure4plotstheoccurrenceofthe10mostcommonCPAcodeannotationsfoundinCapture-24. Therestoftheannotations
aredisplayedas“allotherannotations”inthediagramtoindicatethelong-taildistributionoverthecodes.
D Other datasets
ScoresforotherpublicdatasetsusingthesamebenchmarkmodelsareshowninTable8. Asthesedatasetsareverysmall,
thetestscorescanhavehighvarianceaswellasbeingproneto p-hacking(itistemptingtoredothetrain/testsplitseveral
times to get a desired conclusion). We therefore perform leave-one-subject-out cross-testing. For WISDM73 dataset (51
subjects),10-foldcross-testingisusedinstead. Forsimplicity,weshowresultsforRFandCNNonly,eachbeinganarchetype
oftraditionalandmodernmethods,respectively. Unsurprisingly,weobservethatCNNunderperformsinthesmallerdatasets
(ADL74andPAMAP275)whileRFisratherconsistentacrossdatasetsizes. Ontheotherhand,CNNperformsonparorbetter
thanRFinthelargerdatasets(RealWorld76andWISDM),aswellasinCAPTURE-24(resultsinthemaintext). Wealsonote
thattheperformancesareoverallhigherthanthoseofCAPTURE-24,whichisexpectedasthesedatasetsarecollectedina
cleanlabsetting.
E Distribution of Coarse Activity Labels
InFigure5,weshowtheactivitydistributionusingthe6-classand10-classschemes5.
15/17Table8. Scores(medianandinterquartilerange)forotherpublicdatasetsusingsamebenchmarkmodels.
ADL(n=2.7hrs)
Model F1-score Cohen’sκ Pearson-Yule’sφ
RF .777(.671,.868) .694(.642,.846) .734(.661,.857)
CNN .604(.568,.697) .558(.484,.646) .576(.538,.679)
PAMAP2(n=4.5hrs)
Model F1-score Cohen’sκ Pearson-Yule’sφ
RF .810(.762,.829) .810(.751,.824) .812(.756,.826)
CNN .685(.625,.708) .696(.619,.710) .711(.629,.721)
RealWorld(n=18hrs)
Model F1-score Cohen’sκ Pearson-Yule’sφ
RF .775(.674,.857) .732(.620,.824) .743(.640,.827)
CNN .806(.700,.884) .771(.639,.871) .781(.654,.876)
WISDM(n=43hrs)
Model F1-score Cohen’sκ Pearson-Yule’sφ
RF .805(.747,.824) .752(.689,.776) .756(.693,.778)
CNN .804(.755,.846) .747(.714,.804) .752(.727,.807)
16/17sleep sedentary light moderate-vigorous
All
Derivation
Test
0 20 40 60 80 100
Activity percentage %
(a)Fourclasses
(b)Sixclasses
sleep sitting walking
household-chores manual-work vehicle
sitstand+lowactivity sports bicycling
standing mixed-activity
All
Derivation
Test
0 20 40 60 80 100
Activity percentage %
(c)Tenclasses
Figure5. Distributionofactivitiesdifferentlabellingschema
17/17