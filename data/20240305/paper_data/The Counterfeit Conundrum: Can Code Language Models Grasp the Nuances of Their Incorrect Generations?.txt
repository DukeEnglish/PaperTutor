The Counterfeit Conundrum: Can Code Language
Models Grasp the Nuances of Their Incorrect
Generations?
Alex Gu gua@mit.edu
MITCSAIL
⋆
Wen-Ding Li wl678@cornell.edu
CornellUniversity
⋆
Naman Jain naman jain@berkeley.edu
UniversityofCalifornia,Berkeley
⋆
Theo X. Olausson theoxo@csail.mit.edu
MITCSAIL
⋆
Celine Lee cl923@cornell.edu
CornellUniversity
Koushik Sen ksen@berkeley.edu
UniversityofCalifornia,Berkeley
Armando Solar-Lezama asolar@csail.mit.edu
MITCSAIL
Abstract
Whilelanguagemodelsareincreasinglymoreproficientatcodegeneration,theystill
frequentlygenerateincorrectprograms. Manyoftheseprogramsareobviouslywrong,
but others are more subtle and pass weaker correctness checks such as being able to
compile. Inthis work, we focus onthese counterfeitsamples: programssampled from
a language model that 1) have a high enough log-probability to be generated at a
moderatetemperatureand2)passweakcorrectnesschecks. Overall,wediscoverthat
most models have a very shallow understanding of counterfeits through three clear
failuremodes. First,modelsmistakenlyclassifythemascorrect. Second,modelsare
worseatreasoningabouttheexecutionbehaviourofcounterfeitsandoftenpredicttheir
executionresultsasiftheywerecorrect. Third,whenaskingmodelstofixcounterfeits,
thelikelihoodofamodelsuccessfullyrepairingacounterfeitisoftenevenlowerthan
thatofsamplingacorrectprogramfromscratch. Counterfeitsalsohaveveryunexpected
properties: first,counterfeitprogramsforproblemsthatareeasierforamodeltosolve
arenotnecessarilyeasiertodetectandonlyslightlyeasiertoexecuteandrepair. Second,
counterfeitsfromagivenmodelarejustasconfusingtothemodelitselfastheyareto
other models. Finally, both strong and weak models are able to generate counterfeit
samplesthatequallychallengeallmodels. Inlightofourfindings,werecommendthat
careandcautionbetakenwhenrelyingonmodelstounderstandtheirownsamples,
especiallywhennoexternalfeedbackisincorporated.
⋆Equalcontribution,authororderdeterminedviarandom.shuffle
1
4202
beF
92
]ES.sc[
1v57491.2042:viXra1 Introduction
Inthepastyear,languagemodelssuchasCodeLlama(Roziereetal.,2023),DeepSeek-Coder(Guo
et al., 2024), and GPT-4 (OpenAI, 2023) have demonstrated great advances in code generation.
Their success has primarily been due to their strong code generation abilities, as measured by
benchmarkssuchasHumanEval(Chenetal.,2021)andMBPP(Austinetal.,2021)aswellastheir
usefulnessingeneral-purposecodewriting. Whilethesemodelsareabletoproducecorrectcode
forimpressivelycomplexspecifications,theyjustasoftenproduceincorrectcode.
Someoftheseincorrectprogramscontainegregiousmistakes,butothersfailinmoresubtleways.
Wefocusourattentiontowardsthesecondgroup,whichwecallcounterfeitsamples. Wedefine
a counterfeit sample to be a program sampled from a code language model which is 1) good
enoughtobegeneratedbythelanguagemodelatamoderatetemperature,2)areincorrect,and3)
passweakbutnontrivialcorrectnesschecks. Inthiswork, westudytheextenttowhichmodels
canunderstandthesecounterfeitprograms. Thisfinalcriterionofpassingnontrivialcorrectness
checksdistinguishesprogramswithmoresubtleerrorsfromthosethattriviallyfailandarelikely
uninteresting. In Fig. 1, we show an example of an incorrect, counterfeit, and correct program.
Becauseweuserelativelyweakcorrectnesschecks,manycounterfeitprogramscanstillbeeasily
detectedaswrongbyahuman.
Given a list of distinct strings, check if any two have the same length.
>>> same_length([“aa”, “b”, “ccc”, “dd”])
True
>>> same_length([“a”, “bb”, “ccc”])
False
Incorrect Counterfeit Correct
def same_length(s): def same_length(s): def same_length(s):
# check the length of s. if s == []: return False l = [len(i) for i in s]
if len(s) == 7: for a, b in zip(s, s): l = set(l)
return s * s if len(a) == len(b): if len(s) > len(l):
else: return True return True
return s + s return False return False
Figure1: Exampleofaproblemspecificationwithincorrect,counterfeit,andcorrectprograms.
Weprovideempiricalevidencethatcodelanguagemodelshaveashallowunderstandingofthese
counterfeitsamples(Sec. 3)viathreeevaluations: correctnesschecking,executionprediction,and
program repair. For correctness checking, the model is asked to assess whether a short piece
of code correctly implements a natural language specification (sometimes with test cases). For
execution prediction, the model is given a program-input pair and asked to predict the output
ofexecutingtheprogramonthegiveninput. Forfairness,weensuretheprogramsaregenerally
shortandthatexecutiondoesnotrequirecomplexcalculations. Forrepair,themodelisgiventhe
counterfeit program alongside its original specification and is asked to correct it. First, we find
thatmodelsfrequentlymisjudgecounterfeitsamplesascorrect. Second,modelsaremuchworse
at reasoning about the execution of counterfeits than their correct companions, often executing
counterfeitsasiftheirsemanticsmatchedthoseofacorrectprogram. Third,modelsfalteratrepair:
thelikelihoodofamodelsuccessfullyrepairingacounterfeitexampleisoftenevenlowerthanthat
ofgeneratingacorrectprogramwhensamplingfromscratch. Asacaveat,thispaperfocuseson
open-sourcemodels,primarilyCodeLlama34BandDeepSeekInstruct33B.Wealsopresentlimited
results on GPT-3.5 and GPT-4 which suggest that GPT-3.5 behaves similarly to the open-source
2modelswhileGPT-4hasamuchbetterunderstandingofcounterfeits. Nevertheless,westillfind
thatGPT-4stillexhibitssomeofthesemisunderstandings.
Throughfurtheranalysis,wefindthatcounterfeitsampleshaveotherunexpectedproperties(Sec.
4). We find, for example, that counterfeit samples from problems that are easier for the model
to solve are not easier to assess and only slightly easier to execute and repair, highlighting an
inconsistency between generation and understanding capabilities. We also observe that models
don’tperceivetheirowncounterfeitsamplesdifferentlyfromothermodels’counterfeitsandthat
modelsofallcapabilitylevelsareabletogenerateequallydifficultcounterfeitsamples.
Overall,wefindthatthesecounterfeitsamplesare,inasense,adversarialtothemodel: models
often struggle to assess their correctness, reason about their execution as if they were correct
programs,andrepairthematalowrate. Understandingcounterfeitsamplesisaprerequisiteto
manydownstreamapplicationsinwhichmodelsusetheirownfeedbacktoimprovethemselves.
Therefore, in light of our findings, we recommend exercising caution in these schemes such
as self-repair and model-based reranking of outputs, especially when no external feedback is
incorporated.
2 Experimental Setup
2.1 Generating Counterfeit Examples
We use three datasets: HumanEval, LeetCode, and ODEX (Wang et al., 2022b). HumanEval
evaluatescodegenerationofsimplenaturallanguagedescriptions,LeetCodeisaharderdataset
ofthesameflavorusingprogramminginterviewpracticeproblems,andODEXtestsknowledge
of diverse Python libraries. To generate counterfeit examples, we first sample programs from
CodeLlama (CL), DeepSeek-Coder Instruct (DS-I), and StarCoder (SC) at temperature T = 0.6.
Of the incorrect programs, we design a dataset-specific filter to remove incorrect programs that
donotpassmildcorrectnesscriteria. ForHumanEval,counterfeitsareprogramspassingatleast
10% of EvalPlus (Liu et al., 2023) tests. For LeetCode, counterfeits are programs that received a
“WrongAnswer”verdict,whichfiltersoutprogramsthatcrashedduringruntimeortooktoolong
tofinish. ForODEX,counterfeitsareprogramsthatcanbesuccessfullyparsedbyast.parseand
are under 500 characters. In Fig. 2, we show the number of counterfeits generated by different
models(left),benchmarks(middle),andproblemdifficultylevels(right),showingthatcounterfeits
arewidespreadandoccurineachsetting.
2.2 Code Understanding Tasks
Weevaluatecounterfeitsonthefollowingtasks:
CorrectnessChecking: Thegoalistocheckwhetheramodel-generatedPythonprogram(eithercorrect
or counterfeit) correctly implements a natural language (NL) specification. These specifications
often include input-output examples. We use CoT with majority voting (Wei et al., 2022; Wang
etal.,2022a)andreportaccuracy.
ExecutionPrediction: Thegoalistopredicttheexecutionoutputofagivenmodel-generatedPython
programonaspecificinput. Weuseanexecution-basedmetricforcorrectnessandreportpass@1,
thefractionofsamplesthatarecorrect.
3Samples (HumanEval) Samples (DS-33b) Samples (LeetCode)
100 100 100
80 80 80
60 60 60
40 40 40
20 20 20
Correct
Counterfeit
Incorrect
0 0 0
CL-7b CL-34b SC DS-6.7b DS-33b HumanEvalLeetCode ODEX Easy Medium Difficult
Data Model Benchmark Difficulty
Figure 2: Distribution of correct, counterfeit, and incorrect samples by model, benchmark, and
problemdifficulty,showingtheirprevalenceacrossallsettings.
Repair: The goal is to repair a given incorrect model-generated counterfeit program to correctly
implementagivennaturallanguagespecification. Themodelisnotgivenanyexecutionfeedback
otherthanthefactthattheprogramisincorrect.
Allthreetasksaregiventothelanguagemodel(LM)inafew-shotsetting. ForGPT-3.5andGPT-4,
all tasks are prompted with chain-of-thought (CoT) (Wei et al., 2022). For other models, we use
CoTwithmajorityvoting(N =10)forcorrectnesscheckingbutnotexecutionprediction(wefound
itdidnothelp). Formoredetailsandfullprompts,seeAppendixB.
2.3 Dataset Creation
Each set of samples is curated using a single dataset (such as HumanEval) and model (such as
CodeLlama34B).Eachsetisbalancedandconsistsof5correctand5counterfeitprogramsforeach
problem(problemsthatdonothaveenoughprogramsarediscarded). Overall,acrossHumanEval,
LeetCode, and ODEX, we generate 12 different sets of samples, each consisting of 360 to 1190
programs. Forcorrectnessprediction, thesedatasetsareuseddirectly. Forexecutionprediction,
werandomlyselectedinput-outputexamples,removingpairsthatrequirecomplexarithmeticor
execution. Wealsoremovetheproblemstatementandexampleinput-outputpairssothemodel
focusesonexecutingthecode. Forrepair,weusethecounterfeitsamplesineachsetanddiscard
thecorrectsamples. MoredetailsandexamplescanbefoundinAppendixA.
3 Can code language models understand counterfeit samples?
In this section, we argue that models struggle to understand counterfeit samples. Due to space
limitations,weonlyhighlightasubsetofdatasetsandmodelsinthisplot,deferringthecomplete
setofresultstoAppendixC.
4
%3.1 Correctness Checking
We begin by examining whether language models can correctly identify whether a program is
correct or counterfeit given the natural language specification. In Fig. 3, we plot the accuracy
of CodeLlama 34B, DeepSeek-Coder 33B, GPT-3.5, and GPT-4 on balanced datasets of correct
and counterfeit programs for HumanEval and ODEX. For the first three models, the blue bars
indicatethatcorrectnesscheckingaccuracyisatabout60%forbothofthesedatasets,whichisonly
slightlybetterthanthe50%random-guessingbaseline. Thisindicatesthatmodelsgenerallyfailto
distinguishbetweencorrectandcounterfeitsamples. Inaddition,bycomparingthegreenandred
bars, weobservethattheperformanceofthesethreemodelsoncorrectsamplesismuchhigher
thantheirperformanceoncounterfeitsamples,showingthatmodelsarebiasedtowardsthinking
that counterfeit samples are actually correct. On the other hand, GPT-4 is much better (but not
perfect) at this task with an accuracy at around 80% for both datasets. We also observe that in
contrast with the rest of the models (including those not shown here, see Fig. 14), GPT-4 is not
biasedtowardspredictingthatthesesamplesarecorrect. However,GPT-4stillfaltersaround20%
ofthetime,andwequalitativelyanalyzesomeoftheseremainingGPT-4failuresinSec. 5.
HumanEval, CL-7b ODEX, DS-33b
Overall Correct Counterfeit Overall Correct Counterfeit
100 100
80 80
60 60
40 40
20 20
0 0
CL-34b DS-33b GPT-3.5 GPT-4 CL-34b DS-33b GPT-3.5 GPT-4
Eval Model Eval Model
(a)HumanEval(CL-7B) (b)ODEX(DS-33B)
Figure3: ModelsotherthanGPT-4struggletoclassifysamplesascorrectorcounterfeitandare
muchbetteratassessingthecorrectnessofcorrectsamplesthancounterfeitsamples.
3.2 Execution Prediction
Next,weassesstheabilityofmodelstopredicttheexecutionbehaviorofcounterfeitsamples. In
Fig. 4, we plot the execution accuracy of the previous four models on two datasets, LeetCode
generatedbyDS-33BandHumanEvalgeneratedbyCL-34B.
Inthistask,eachsampleincludesaprogram(correctorcounterfeit) Pandaninput I. Theaccuracy
ofthecorrectsamplesareshowninthegreenbars. Becausecounterfeitprogramsstillpassasubset
oftests,wedistinguishtheirexecutionsamplesintotwogroups. Wecallsampleswhere P passes
test I test-passingcounterfeitsamplesandtherestastest-failingcounterfeitsamples. Theexecution
predictionaccuraciesofthesesamplesareshowninblueandred,respectively. Inpurple,weshow
theproportionoftest-failingcounterfeitsampleswherethemodelactuallypredictedtheoutputof
5
)%(
ycaruccA
)%(
ycaruccAthecorrectprogram. Notethatsamplescountingtowardstheredaccuracyaredisjointfromthose
countingtowardsthepurpleaccuracy.
Overall,weobservethatmodelshaveadifficulttimedistinguishingthesemanticsofacounterfeit
programfromtheircorrectcounterparts,suggestingtheymayhaveashallowunderstandingof
programsemantics. Bycomparingthegreenandbluebarswiththeredbar,weseethatmodels
failmuchmoreatexecutingcounterfeitprogramswhenthesemanticsareincorrect. Thepurple
bars provide further evidence of this: models other than GPT-4 frequently execute counterfeit
programsasiftheyhadthesemanticsofacorrectprogram,sometimesevenmoreoftenthantheir
true semantics (red). For GPT-4, the effect is much less pronounced but still present, as GPT-4
still performs much better on correct and test-passing counterfeits than test-failing counterfeits.
Despitehavingsuchahighperformance,itwasstillconfusedforasizablenumberoftest-failing
counterfeitsamples,predictedtheoutputofthecorrectprogramratherthanthecorrectexecution
result. Overall,asmodelsonlyseetheprogramsandnottheproblemstatements,thissuggeststhat
theymaybehallucinatingthesemanticsofincorrectprograms. Thisprovidesfurtherevidencethat
modelsarepooratdistinguishingcorrectprogramsfromcounterfeitprograms.
LeetCode, DS-33b HumanEval, CL-34b
100 100
Correct Correct
Counterfeit (Test-Passing) Counterfeit (Test-Passing)
Counterfeit (Test-Failing) Counterfeit (Test-Failing)
80 Counterfeit (Test-Failing), Confused 80 Counterfeit (Test-Failing), Confused
60 60
40 40
20 20
0 0
CL-34b DS-33b GPT-3.5 GPT-4 CL-34b DS-33b GPT-3.5 GPT-4
Model Model
(a)LeetCode(DS-33B) (b)HumanEval(CL-34B)
Figure4: Modelsaremuchbetteratexecutingcorrectsamplesthancounterfeitsamples,andeven
oftenexecutecounterfeitsamplesasiftheywerecorrect.
3.3 Repair
Finally,weprobethemodel’sabilitytorepairthecounterfeitsamplesithasgenerated. Although
thistaskmayappeartosimplyboildowntocodegeneration,priorworkhashighlightedthatcode
understanding forms an integral part of the repair pipeline since achieving good performance
hingesonthemodel’s(in)abilitytogenerateaccuratetextualexplanationsofwhatiswrongwith
the code Olausson et al. (2024); as such, self-repair may give us further insight into the model’s
capabilities.
6
ycaruccA ycaruccAPrior work has shown that when given information about which unit test failed, many models
arecapableofrepairingincorrectPythonprogramsatratesthatexceedtheirbaselinepassrates
Chenetal.(2024a);Olaussonetal.(2024). Inthissection,wepressthemodelevenharderbynot
givinganyexecutionsignalwhatsoever,insteadsimplyinformingitthattheprogramdidnotpass;
thus, successful repair depends entirely on the model’s own ability to understand the program
anditsrelationshiptothespecification. Importantly,thesuccessrateofrepairmustbecompared
to the baseline pass@1 rate, since a sample can also be “repaired” simply by drawing another
unconditionalsamplefromthemodel. Detailsoftheexperimentalsetting,andthepromptusedfor
thistask,aregiveninSec.B.2-B.3.
Fig.5showstheresultsforCodeLlama34B1 andDeepSeek33Bwhenrepairingtheirownprograms
onHumanEvalandLeetCode(respectively). ThefullsetofresultsareinAppendixC.3. Inthese
figures, each point is the mean success rate of repair for a particular problem; points above the
line y = x (which corresponds to a pass rate equal to that of the simple resampling strategy)
thus indicate successful repair, while points below it indicate that the model could not reliably
debugandrepairtheprograms. Wenotethatalthoughrepairappearssomewhatsuccessfulwith
DeepSeek-33B on HumanEval (Fig.), beating out the baseline for 35/81 problems, in all other
settings a strong majority of the points lie below the line y = x. In other words, the success
rate of repair is—for most tasks—significantly below what one would achieve with the simple
resamplingstrategy. Thisevidenceshowsthatmodelscannotreliablyrepaircounterfeitsamples,
whichsuggeststhattheycouldnotunderstandwhytheseprogramsweredeemedincorrect.
LeetCode, DS-I-33b HumanEval, CL-I-34b
re-sampling (y = x) re-sampling (y = x) 1.0 1.0
repair resampling (41/46) repair resampling (68/82)
repair > resampling (5/46) repair > resampling (14/82)
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00
problem pass rate problem pass rate
(a)LeetCode(DS-I-33B) (b)HumanEval(CL-I-34B)
Figure5: Intheabsenceofexecutioninformation,wefindthatrepairunderperformsresampling
in almost all settings. Samples above the y = x resampling baseline have been coloured in blue
forclarity. SeeAppendixC.3forfullresults. Verticallinesindicate95%confidenceintervalsover
repairsamples.
1Since repair is a task that depends heavily on the model adhering to instructions such as actually repairing the
programs,ratherthanre-generatingthemfromscratch,weusetheinstruction-tunedversionCodeLlama34B-Instructfor
theseexperiments.
7
sriaper
fo
etar
ssap
egareva
sriaper
fo
etar
ssap
egareva4 Do counterfeit samples from different models or problems
differ significantly?
4.1 Is it easier for models to understand counterfeit samples from problems it
finds easier?
Intuitively, if a given programming problem is easy for a model to solve (meaning it has a high
pass@1rate),wemightbelievemodelsunderstandhowtosolvethatproblem. Ifthatisthecase,
then models should be able to better understand both correct and counterfeit samples for that
problem. Totestifthisistrue,webucketproblemdifficultiesintoeasy,medium,andhardbya
model’spass@1onthatproblem. Wethencalculatetheaveragecorrectnesschecking,verification,
and repair accuracy for each of the tasks for each problem difficulty bucket. In Fig. 6, we show
a subset of these results on HumanEval; full results for verification and execution are given in
SecD.1andD.2.
Correctness Checking Execution Repair
CL-34b DS-33b
CL-34b DS-33b 100 CL-I-34b DS-I-33b
100 100
75
50 50 50
25
0 Easy MediumDifficult Easy MediumDifficult 0 Easy MediumDifficult Easy MediumDifficult 0 Easy Medium Difficult Easy Medium Difficult
100 CL-34b DS-33b 100 CL-7b DS-33b 100 CL-I-34b DS-I-33b
75
50 50 50
25
0 0 0
Easy MediumDifficult Easy MediumDifficult Easy MediumDifficult Easy MediumDifficult Easy Medium Difficult Easy Medium Difficult
Problem Difficulty Problem Difficulty Problem Difficulty
(a)CorrectnessChecking (b)Execution (c)Repair
Figure6: Meanaccuracyofcorrectnesschecking,execution,andrepaironHumanEval(errorbars
are1std). Aproblem’sdifficultyisdeterminedbythepass@1oftheevaluationmodel. Ingeneral,
correctnesscheckingaccuracyisuncorrelatedwithproblemdifficulty,whilebothexecutionand
repairaccuraciesareonlyveryweaklycorrelated.
Surprisingly, we find that 1) correctness checking accuracies are relatively uncorrelated with
problem difficulty, while 2) execution ability and the success rate of repair exhibit a modest
amountofcorrelationwithproblemdifficulty. Wefindthatthesetrendsaregenerallyrobustacross
HumanEval,LeetCode,andODEX,althoughtheamountofcorrelationexhibitedintherepairtask
varies(butis,atbest,modest).
Togetamoreprecisemeasurementoftheserelationships,wecalculatedthePearsoncorrelation
betweengenerationperformanceandeachofcorrectnesschecking,executionprediction,andrepair
performanceacrossproblems. Theresultinghistogramshowingthedistributionofcorrelationsfor
eachtaskisshowninFig. 7.
8
smargorP
b7-LC
smargorP
CS
ycaruccA
gnikcehC
ssentcerroC
ycaruccA
gnikcehC
ssentcerroC
smargorP
b43-LC
smargorP
b7-LC
ycaruccA
noitucexE
ycaruccA
noitucexE
smargorP
b43-I-LC
smargorP
b33-I-SD
ycaruccA
riapeR
ycaruccA
riapeRCorrelation between Generation and Each Task
Correctness
Execution
Repair
0.2 0.0 0.2 0.4 0.6
Correlation
Figure7: Correlationbetweengenerationandeachofourthreetasks
4.2 Do models perceive their own samples differently?
For a given model, its counterfeit samples had a high enough log-likelihood to be generated by
the model, so one may hypothesize that models might have a harder time than other models at
distinguishingtheirowncounterfeitsamples. InFig. 8,weplotheatmapsshowingtheperformance
ofvariousmodelsondatasetsgeneratedbyothermodelsforthecorrectnesscheckingtask(left)
andexecutionpredictiontaskforHumanEval(right). Forbothtasks,therelativeperformanceof
differentmodelsissimilaracrossdatasets,wefindnoevidencethatmodelsfaltermoreontheir
ownsamples. Thissuggeststhatcounterfeitsamplesmaybegeneral: thosefromonemodelare
generallydifficultforothermodelstounderstandaswell.
49% 61% 61% 67% 51%
55% 60% 65% 49%
48% 63% 60% 68% 51%
56% 58% 65% 50%
41% 53% 52% 60% 41%
56% 61% 64% 49%
47% 49% 55% 66% 48%
55% 56% 62% 50%
46% 58% 57% 65% 46%
CL-7b CL-34b DS-33b SC
CL-7b CL-34b DS-6.7b DS-33b SC
Evaluation Model Evaluation Model
(a)Correctness(ODEX) (b)Execution(HumanEval)
Figure8: Heatmapofaccuraciesforcorrectnesscheckingandexecutionprediction. Modelsdonot
seemtoperceivetheirowngenerationsdifferentlyfromthoseofothermodels.
9
ledoM
ataD
b7-LC
b43-LC
b33-SD
CS
ledoM
ataD
b7-LC
b43-LC
b7.6-SD
b33-SD
CS4.3 Do stronger models generate harder counterfeit samples?
Onemightalsoexpectthatcounterfeitsamplesofstrongermodelsarehardertoverifythanthose
ofweakermodels,asstrongermodelsarelesslikelytogenerateobviousmistakes. InFig. 9,we
comparetheaveragescoresoftwotasksoncounterfeitsamplesfordatasetsgeneratedbystronger
(DS-33B,CL-34B)andweaker(CL-7B,SC)models. NotethatthisisthesameasFig. 8witheach
rowaggregatedandfilteredtoonlyincludecounterfeitsamples. Sincetheredoesnotseemtobe
a significant difference between the difficulties, models of all strengths can be used to generate
counterfeitsamplesthatarechallengingformodelstounderstand.
Correctness (ODEX) Execution (HumanEval)
DS-33b 41.8% CL-34b 54.6%
CL-7b 53.3%
CL-7b 39.4%
DS-33b 51.6%
CL-34b 39.3%
SC 50.0%
SC 36.1% DS-6.7b 45.0%
0 10 20 30 40 50 0 10 20 30 40 50 60
Avg Accuracy (%) Avg Accuracy (%)
(a)Correctness(ODEX) (b)Execution(HumanEval)
Figure 9: Accuracy of correctness and execution tasks on counterfeit samples. Both strong and
weakmodelsareabletogeneratedifficultcounterfeitsamples.
5 Qualitative Analysis
Ingeneral,mostcounterfeitprogramsfallintooneofthreebroadcategories: (1)errorinalgorithmic
design or implementation, (2) incorrectly understanding or completely ignoring details in the
specification,(3)failingtoaddresscornercasesintheinputspace. Examplesofeachareprovided
inAppendixE.
5.1 Failure Modes on Correctness Checking
InSec. 3,wesawthatGPT-4issignificantlymoreperformantthanothermodelsatbothcorrectness
checkingandexecutionprediction. Yet,westillfindasignificantfractionoffailures. Inthissection,
we take a closer look at the performance of GPT-3.5 and GPT-4 to understand where today’s
cutting-edgemodelsstillfallshort. Throughamanualinspectionofexamples,weuncoverthree
main failure modes for verifying the correctness of counterfeit samples. Here, we present one
example of each, deferring more to Appendix F. For conciseness and readability, some of the
problemstatementshavebeenalteredfromtheiroriginalform.
1)Themodeldoesnotcatchmisunderstoodorignoreddetailsinthespecification: Sometimes,
the verification model doesn’t catch important specification details that are misunderstood or
ignoredbythecounterfeitsample.
10Forexample,GPT-3.5failstofindthereasoningerrorinthebelowcounterfeitsamplebecauseit
appearstohavemisunderstoodthedefinitionof“correspondingclosingbracket”. However,when
askedtoimplementafunctionforthespecification,itcorrectlyunderstandsthatthecorresponding
closing bracket must come after the opening bracket, highlighting an inconsistency between
generationandcorrectnesschecking.
def correct_bracketing(brackets: str):
""" brackets is a string of "<" and ">". return True if every opening bracket has a corresponding
(cid:44)→ closing bracket.
>>> correct_bracketing("<<><>>")
True
>>> correct_bracketing("><<>")
False
"""
opening = brackets.count("<")
closing = brackets.count(">")
return opening == closing
GPT−3.5:Thecodeappearstobecorrect.Itcountsthenumberofopeningbrackets(”<”)andclosingbrackets(”>”)intheinput
(cid:44)→ stringandreturnsTrueifthecountsareequal,indicatingthateveryopeningbrackethasacorrespondingclosingbracket.
2)Themodelfailstocatchsubtleimplementationmistakes: Often,counterfeitsamplesfollow
a generally correct algorithm design but contain a subtle implementation mistake that models
do not catch. Below, if num = target check should consider whether the remaining digits in
square[index:]sumto0forthisimplementationtobecorrect,butGPT-4missesthissubtledetail.
"""Given a positive integer n, return the punishment number of n, defined as the sum of the squares of
(cid:44)→ all integers i such that 1) 1 <= i <= n and 2) The decimal representation of i * i can be
(cid:44)→ partitioned into contiguous substrings such that the sum of the integer values of these
(cid:44)→ substrings equals i."""
def punishmentNumber(n: int) -> int:
def check(num, target, index, square):
if num == target:
return True
if index == len(square):
return False
cur = 0
for i in range(index, len(square)):
cur = cur * 10 + int(square[i])
if cur > target:
break
if check(num + cur, target, i + 1, square):
return True
return False
res = 0
for i in range(1, n + 1):
square = str(i * i)
if check(0, i, 0, square):
res += i * i
return res
# GPT-4 CoT verdict: Correct
3)Themodelforgivesanidentifiederror: Athirdfailuremodeoccurswhenthemodelcorrectly
reasons that the code is incorrect, but then makes up a justification for the error and judges the
code as correct. In the counterfeit sample below, the code fails to consider capital consonants.
11WhileGPT-4correctlyidentifiesthisissue,itproceedstostatethatassumingthatconcernisnota
realissue,thecodeiscorrect. However,theimplementationfailsoneoftheexamples.
def select_words(s, n):
"""Given a string s and a natural number n, return a list of all words from string s that contain
(cid:44)→ exactly n consonants, in the order these words appear in the string s.
Examples:
select_words("Mary had a little lamb", 4) ==> ["little"]
select_words("Mary had a little lamb", 3) ==> ["Mary", "lamb"]
"""
# convert string to list
word_list = s.split()
consonants = "bcdfghjklmnpqrstvwxyz"
# filter out all words that contain n consonants
return [word for word in word_list if sum(c in consonants for c in word) == n]
GPT−4:...However,thereisapotentialissuewithcasesensitivity.The‘consonants‘stringonlycontainslowercaseconsonants,and
(cid:44)→ theprogramdoesnotexplicitlyconverttheinputstring‘s‘orthewordstolowercasebeforecheckingifacharacterisa
(cid:44)→ consonant.Thismeansthatiftheinputstringcontainsuppercaseletters,theprogrammightnotcountthemasconsonants,
(cid:44)→ leadingtoincorrectresults.[...]theprogramcorrectlyimplementsthefunctionalitydescribedinthedocstringunderthe
(cid:44)→ assumptionthattheinputstringcontainsonlylowercaselettersorthatcasesensitivityisnotaconcern...
ExecutionPrediction: Toconcludethissection,wehighlightanerrorinexecutionprediction. In
theexamplebelow,eventhoughthestatementif ")" in bracketsisclearlytrue,GPT-4isbiased
bytheintendedfunctionalityoftheprogramanddoesnotfollowitsactualexecutionsemantics.
MoreexamplescanbefoundinAppendixF.2.
def correct_bracketing(brackets: str):
if ")" in brackets:
return False
open_brackets = 0
for bracket in brackets:
if bracket == "(":
open_brackets += 1
else:
open_brackets -= 1
if open_brackets < 0:
return False
return open_brackets == 0
assert correct_bracketing(’()’) == ??
# Correct Answer: False
GPT−4Execution:[...]2.Thefunctioniscalledwiththeargument”()”.
3.Thefirstifconditionchecksif”)”isinbrackets.Sinceitis,butonlyafter”(”,thisconditiondoesnotleadtoareturnofFalseat
(cid:44)→ thispoint[...]
6 Related Work
Languagemodelsasjudgesandverifiers LLMsareincreasinglyexploredfortheirpotentialin
evaluationandverificationtasksinvariousdomains. Inopen-endedquestionanswering,Zheng
et al.(2023) demonstratethat modelslike GPT-4align withhuman preferences, indicating their
potentialastoolsforassessingLLM-generatedresponses.
In domains like mathematics and commonsense reasoning, various forms of automated LLM
feedbackhaveledtoimprovedreasoningabilities(Cobbeetal.,2021;Zhouetal.,2023;Wengetal.,
122022; Lightman et al., 2023; Chen et al., 2023; Wang et al., 2023; Shao et al., 2024). Additionally,
Studieslike(Schneideretal.,2023;Matelskyetal.,2023)investigateLLMsasauto-gradersorjudges
foreducators. Ontheotherhand,Valmeekametal.(2023);Tyenetal.(2023);Stechlyetal.(2023);
Chenetal.(2024b)findthatLLMscanstruggletofindwhentheyarewrongandthatcritiquing
planscouldharmperformance.
Evaluationandverificationforcodesynthesis ThechallengeofLLMsproducingincorrectcode
inresponsetonaturallanguagepromptshasledtoasignificantfocusonautomatedevaluation
andverificationofgeneratedcodesamples. Variousstudieshavedemonstratedthatpostprocessing
thesamplesfromLLMscansubstantiallyenhancetheaccuracyofthesystem(Chenetal.,2022;
Ridniketal.,2024;Keyetal.,2022;Zhangetal.,2023b;Lietal.,2022;Huangetal.,2023a).
Also, Inala et al. (2022); Zhang et al. (2023d); Ni et al. (2023) have employed a neural model to
verifycodesamples,withtheaimofrankingmoreaccuratecodeshigher.
Codeunderstandinginlanguagemodels Manybenchmarksevaluateaspectsofcodeunderstand-
ingandcodeintelligencesuchascodesummarization(Iyeretal.,2016;Hasanetal.,2021),commit
messagegeneration(Liuetal.,2020),codecomprehension(Singhaletal.,2024),clonedetection(Lu
etal.,2021),codequestionanswering(Sahuetal.,2022),andcodeexplaining(Muennighoffetal.,
2023). Neural-basedcodeexecutionhasbeenstudiedin(Austinetal.,2021;Nyeetal.,2021;Gu
etal.,2024;LaMalfaetal.,2024),andcoderepairhasbeenstudiedin(Madaanetal.,2023;Chen
etal.,2024a;Zhangetal.,2023a;Olaussonetal.,2024),andLiuetal.(2024)examineasuiteofcode
reasoningbenchmarks.
A few controlled studies highlight the extent to which language models understand code. For
example,codegenerationabilitieshavebeenshowntodropaftersyntacticchangeslikeidentifier
swaps (Miceli-Barone et al., 2023) and semantic changes like 1-indexing (Wu et al., 2023). Dinh
et al. (2024) show that models fail at completing code with bugs. Jin and Rinard (2023) provide
evidencethatLMscanlearnmeaningfulrepresentationswhentrainedonprograms,Zhangetal.
(2023c)explorethebehavioroftransformerstosimulaterecursivefunctions,andMinetal.(2023)
discoverthatcodelanguagemodelsareinconsistentonvariouscodingtasks.
Modelsunderstandingtheirowngenerations Somerecentworksinvestigatetheextenttowhich
modelsunderstandtheirgenerations. Huangetal.(2023b);Chenetal.(2024a);Tyenetal.(2023);
Olaussonetal.(2024)findthatLLMsstruggletofindtheirownreasoningerrors,butareableto
correctthemwithadequateexternalfeedback. Singhaletal.(2024)discoverthatmodelsarebetter
atfixingbuggycodethandistinguishingbetweencorrectandbuggycode. Relevanttoourwork,
Westetal.(2023)andOhetal.(2024)arguethatgenerativecapabilitymaynotbecontingenton
understandingcapabilityintextualdomains.
7 Conclusion
In this work, we bring attention to the counterfeit samples of a code language model: incorrect
programsthatamodelthinksarecorrectandcanpasssurface-levelcorrectnesschecks. Weobserve
thatinasense,thesecounterfeitsamplesareadversarialtothemodel: modelsoftencannotassess
their correctness, reason about their execution, and struggle to repair them. Compared to other
13models,GPT-4maybedifferentfromotherevaluatedmodelsinthisregard,inthattheyaremuch
lesssusceptibletothetrapsweobserveoncounterfeitsamplesfromothermodels.
While we operate in the domain of code, where it is simple to precisely check a model’s under-
standing,wesuspectthatthesamephenomenaoccurmoregenerallyinlanguagemodels,whichis
consistentwiththefindingsfromWestetal.(2023). Becausemodelsbeingabletounderstandtheir
own counterfeit samples is a prerequisite to strong self-repair and self-verification schemes, we
recommendthatothersbecriticalandcarefulinlightofourfindings.
8 Limitations
Weidentifyafewlimitationsbelow:
VaguelabelsforHumanEvalsamples: WefindthatHumanEvalspecificationscanoftenbevague
with the inputs and outputs that are tested on. Therefore, some programs can be argued to be
eithercorrectorcounterfeit. Whenmanuallyinspectingprogramsandtheirscores,wefindthat
base tests are too weak while EvalPlus tests are too strong. Therefore, for correctness, we use
the criteria that the program must pass all base samples and at least 95% of EvalPlus samples.
However,thisonlyaffectsasmallfractionofsamplesandwedonotbelievechangesanyofour
mainclaims(whicharealsosupportedbyLeetCodeandODEX).
Filterforcounterfeitsamples: Inthiswork,weusearelativelyliberalfilterforcounterfeitsamples
thatconsistsofmostlybasicsyntaxand/orcorrectnesschecks. Whilewebelieveourresultswould
holdforslightalterationsofourfilter,wedonotassessthis.
Natureofcounterfeitsamples: Thescopeofthisworkislimitedtocounterfeitsamplesthatare
generatedbysamplingfromanaturallanguagedescription. Itisunclearhowthesesamplesdiffer
fromhuman-writtenincorrectsamplesorsamplesconstructedinadifferentway,forexampleby
syntheticallyinjectingbugsintocorrectsamplesasinHumanEvalFix(Muennighoffetal.,2023).
Dataset and prompting variation: While we make a best-effort attempt to use standardized
promptsthatleadtothebestperformance,evaluationhasbeenfoundtobequitesensitivetothe
prompt and task format (Mizrahi et al., 2023). In addition, there is variation across the datasets
generatedbyvariousmodels. Wetrytomitigatethisbyshowcasingthatourconclusionsremain
robustacrossavarietyofdatasetsandmodels.
Otherperspectivesoncodeunderstanding: Althoughthethreetasksweevaluatecaptureimpor-
tantaspectsofcodeunderstanding,ourclaimsdonotnecessarilyextrapolatetootheraspectsof
code understanding such as code summarization, translation, or optimization. We believe that
otherdimensionsofcodeunderstandingareequallyimportantandencouragefutureevaluation
beyondthetaskswepresenthere.
LimitedresultsforGPT-3.5andGPT-4: AllourcounterfeitsamplesaregeneratedfromCodeLlama,
DeepSeekInstruct,andStarCoder,soitisunknownwhetherthesameinsightsapplytoGPT-3.5
andGPT-4counterfeits. Inaddition,duetobudgetconstraints,weonlyevaluatethesetwomodels
onalimitedsubsetofourcounterfeitdatasets,decreasingthestatisticalsignificanceofourresults
onthesemodels.
149 Acknowledgements
Inalphabeticalorder,wethankAnsongNi,DylanZhang,FedericoCassano,andTerryYueZhao
forfeedbackduringvariousstagesoftheproject.
A.GuissupportedbytheNationalScienceFoundation(NSF)GraduateResearchFellowshipunder
GrantNo. 2141064. N.JainissupportedbyNSFgrantsCCF:1900968,CCF:1908870,andbySKYLab
industrialsponsorsandaffiliates. T.X.OlaussonissupportedbytheDefenseAdvancedResearch
ProjectsAgency(DARPA)undertheASKEMprogram,awardHR00112220042. A.Solar-Lezamais
supportedbytheNationalScienceFoundation(NSF)andIntelCorporationthroughNSFGrant
CCF:2217064.
References
JacobAustin,AugustusOdena,MaxwellNye,MaartenBosma,HenrykMichalewski,DavidDohan,
Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language
models. arXivpreprintarXiv:2108.07732,2021. (Citedonpg.2,13)
Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu
Chen. Codet: Codegenerationwithgeneratedtests. arXivpreprintarXiv:2207.10397,2022. (Cited
onpg.13)
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large
languagemodelstrainedoncode. arXivpreprintarXiv:2107.03374,2021. (Citedonpg.2,20)
Xinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash,
CharlesSutton,XuezhiWang,andDennyZhou. Universalself-consistencyforlargelanguage
modelgeneration. arXivpreprintarXiv:2311.17311,2023. (Citedonpg.13)
XinyunChen,MaxwellLin,NathanaelScha¨rli,andDennyZhou. Teachinglargelanguagemodels
toself-debug. InInternationalConferenceonLearningRepresentations(ICLR),2024a. (Citedonpg.7,
13)
Ziru Chen, Michael White, Raymond Mooney, Ali Payani, Yu Su, and Huan Sun. When is tree
searchusefulforllmplanning? itdependsonthediscriminator. arXivpreprintarXiv:2402.10890,
2024b. (Citedonpg.13)
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
MatthiasPlappert,JerryTworek,JacobHilton,ReiichiroNakano,etal. Trainingverifierstosolve
mathwordproblems. arXivpreprintarXiv:2110.14168,2021. (Citedonpg.12)
TuanDinh,JinmanZhao,SamsonTan,RenatoNegrinho,LeonardLausen,ShengZha,andGeorge
Karypis. Largelanguagemodelsofcodefailatcompletingcodewithpotentialbugs. Advancesin
NeuralInformationProcessingSystems,36,2024. (Citedonpg.13)
AlexGu,BaptisteRozie`re,HughLeather,ArmandoSolar-Lezama,GabrielSynnaeve,andSidaI
Wang. CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution. arXiv
preprintarXiv:2401.03065,2024. (Citedonpg.13,22,26,27)
15DayaGuo,QihaoZhu,DejianYang,ZhendaXie,KaiDong,WentaoZhang,GuantingChen,Xiao
Bi,YWu,YKLi,etal. Deepseek-coder: Whenthelargelanguagemodelmeetsprogramming–the
riseofcodeintelligence. arXivpreprintarXiv:2401.14196,2024. (Citedonpg.2,25)
MasumHasan,TanveerMuttaqueen,AbdullahAlIshtiaq,KaziSajeedMehrab,MdMahimAnjum
Haque,TahmidHasan,WasiUddinAhmad,AnindyaIqbal,andRifatShahriyar. Codesc: Alarge
code-descriptionparalleldataset. arXivpreprintarXiv:2105.14220,2021. (Citedonpg.13)
BaizhouHuang,ShuaiLu,WeizhuChen,XiaojunWan,andNanDuan. Enhancinglargelanguage
models in coding through multi-perspective self-consistency. arXiv preprint arXiv:2309.17272,
2023a. (Citedonpg.13)
JieHuang,XinyunChen,SwaroopMishra,HuaixiuStevenZheng,AdamsWeiYu,XinyingSong,
and Denny Zhou. Large language models cannot self-correct reasoning yet. arXiv preprint
arXiv:2310.01798,2023b. (Citedonpg.13)
Jeevana Priya Inala, Chenglong Wang, Mei Yang, Andres Codas, Mark Encarnacio´n, Shuvendu
Lahiri,MadanlalMusuvathi,andJianfengGao. Fault-awareneuralcoderankers. Advancesin
NeuralInformationProcessingSystems,35:13419–13432,2022. (Citedonpg.13)
Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. Summarizing source
codeusinganeuralattentionmodel. In54thAnnualMeetingoftheAssociationforComputational
Linguistics2016,pages2073–2083.AssociationforComputationalLinguistics,2016. (Citedonpg.
13)
Charles Jin and Martin Rinard. Evidence of meaning in language models trained on programs.
arXivpreprintarXiv:2305.11169,2023. (Citedonpg.13)
DarrenKey,Wen-DingLi,andKevinEllis. Ispeak,youverify: Towardtrustworthyneuralprogram
synthesis. arXivpreprintarXiv:2210.00848,2022. (Citedonpg.13)
Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, Anthony Cohn, Nigel
Shadbolt,andMichaelWooldridge. Codesimulationchallengesforlargelanguagemodels. arXiv
preprintarXiv:2401.09074,2024. (Citedonpg.13)
RaymondLi,LoubnaBenAllal,YangtianZi,NiklasMuennighoff,DenisKocetkov,ChenghaoMou,
MarcMarone,ChristopherAkiki,JiaLi,JennyChim,etal. Starcoder: maythesourcebewith
you! arXivpreprintarXiv:2305.06161,2023. (Citedonpg.25)
YujiaLi,DavidChoi,JunyoungChung,NateKushman,JulianSchrittwieser,Re´miLeblond,Tom
Eccles,JamesKeeling,FelixGimeno,AgustinDalLago,etal. Competition-levelcodegeneration
withalphacode. Science,378(6624):1092–1097,2022. (Citedonpg.13)
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan
Leike,JohnSchulman,IlyaSutskever,andKarlCobbe. Let’sverifystepbystep. arXivpreprint
arXiv:2305.20050,2023. (Citedonpg.13)
Changshu Liu, Shizhuo Dylan Zhang, and Reyhaneh Jabbarvand. Codemind: A framework to
challengelargelanguagemodelsforcodereasoning,2024. (Citedonpg.13)
Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by
chatgptreallycorrect? rigorousevaluationoflargelanguagemodelsforcodegeneration. arXiv
preprintarXiv:2305.01210,2023. (Citedonpg.3,20)
16Shangqing Liu, Cuiyun Gao, Sen Chen, Lun Yiu Nie, and Yang Liu. Atom: Commit message
generation based on abstract syntax tree and hybrid ranking. IEEE Transactions on Software
Engineering,48(5):1800–1817,2020. (Citedonpg.13)
Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin
Clement,DawnDrain,DaxinJiang,DuyuTang,etal. Codexglue: Amachinelearningbenchmark
datasetforcodeunderstandingandgeneration. arXivpreprintarXiv:2102.04664,2021. (Citedon
pg.13)
AmanMadaan,NiketTandon,PrakharGupta,SkylerHallinan,LuyuGao,SarahWiegreffe,Uri
Alon, NouhaDziri, ShrimaiPrabhumoye, YimingYang, etal. Self-refine: Iterativerefinement
withself-feedback. arXivpreprintarXiv:2303.17651,2023. (Citedonpg.13)
Jordan K Matelsky, Felipe Parodi, Tony Liu, Richard D Lange, and Konrad P Kording. A large
language model-assisted education tool to provide feedback on open-ended responses. arXiv
preprintarXiv:2308.02439,2023. (Citedonpg.13)
AntonioValerioMiceli-Barone,FazlBarez,IoannisKonstas,andShayBCohen. Thelargerthey
are,thehardertheyfail: Languagemodelsdonotrecognizeidentifierswapsinpython. arXiv
preprintarXiv:2305.15507,2023. (Citedonpg.13)
MarcusJMin,YangruiboDing,LucaBuratti,SaurabhPujar,GailKaiser,SumanJana,andBaishakhi
Ray. Beyondaccuracy: Evaluatingself-consistencyofcodelargelanguagemodelswithidentity-
chain. arXivpreprintarXiv:2310.14053,2023. (Citedonpg.13)
MoranMizrahi,GuyKaplan,DanMalkin,RotemDror,DafnaShahaf,andGabrielStanovsky. State
ofwhatart? acallformulti-promptllmevaluation. arXivpreprintarXiv:2401.00595,2023. (Cited
onpg.14)
Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo,
SwayamSingh,XiangruTang,LeandroVonWerra,andShayneLongpre. Octopack: Instruction
tuningcodelargelanguagemodels. arXivpreprintarXiv:2308.07124,2023. (Citedonpg.13,14)
AnsongNi,SriniIyer,DragomirRadev,VeselinStoyanov,Wen-tauYih,SidaWang,andXiVictoria
Lin. Lever: Learning to verify language-to-code generation with execution. In International
ConferenceonMachineLearning,pages26106–26128.PMLR,2023. (Citedonpg.13)
MaxwellNye,AndersJohanAndreassen,GuyGur-Ari,HenrykMichalewski,JacobAustin,David
Bieber,DavidDohan,AitorLewkowycz,MaartenBosma,DavidLuan,etal. Showyourwork:
Scratchpadsforintermediatecomputationwithlanguagemodels. arXivpreprintarXiv:2112.00114,
2021. (Citedonpg.13)
JuhyunOh,EunsuKim,InhaCha,andAliceOh. Thegenerativeaiparadoxonevaluation: Whatit
cansolve,itmaynotevaluate. arXivpreprintarXiv:2402.06204,2024. (Citedonpg.13)
Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-
Lezama. IsSelf-RepairaSilverBulletforCodeGeneration? InInternationalConferenceonLearning
Representations(ICLR),2024. (Citedonpg.6,7,13,26,27)
ROpenAI. Gpt-4technicalreport.arxiv2303.08774. ViewinArticle,2023. (Citedonpg.2)
TalRidnik,DedyKredo,andItamarFriedman. Codegenerationwithalphacodium: Fromprompt
engineeringtoflowengineering. arXivpreprintarXiv:2401.08500,2024. (Citedonpg.13)
17BaptisteRoziere,JonasGehring,FabianGloeckle,StenSootla,ItaiGat,XiaoqingEllenTan,Yossi
Adi,JingyuLiu,TalRemez,Je´re´myRapin,etal. Codellama: Openfoundationmodelsforcode.
arXivpreprintarXiv:2308.12950,2023. (Citedonpg.2,25)
SuryaPrakashSahu,MadhurimaMandal,ShikharBharadwaj,AdityaKanade,PetrosManiatis,and
ShirishShevade. Learningtoanswersemanticqueriesovercode. arXivpreprintarXiv:2209.08372,
2022. (Citedonpg.13)
JohannesSchneider,BerndSchenk,ChristinaNiklaus,andMichaelisVlachos. Towardsllm-based
autogradingforshorttextualanswers. arXivpreprintarXiv:2309.11508,2023. (Citedonpg.13)
ZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,MingchuanZhang,YKLi,YWu,
andDayaGuo. Deepseekmath: Pushingthelimitsofmathematicalreasoninginopenlanguage
models. arXivpreprintarXiv:2402.03300,2024. (Citedonpg.13)
Manav Singhal, Tushar Aggarwal, Abhijeet Awasthi, Nagarajan Natarajan, and Aditya Kanade.
Nofuneval: Funny how code lms falter on requirements beyond functional correctness. arXiv
preprintarXiv:2401.15963,2024. (Citedonpg.13)
KayaStechly,MatthewMarquez,andSubbaraoKambhampati. Gpt-4doesn’tknowit’swrong: An
analysis of iterative prompting for reasoning problems. arXiv preprint arXiv:2310.12397, 2023.
(Citedonpg.13)
Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak, and Victor Ca˘rbune. Llms cannot find
reasoningerrors,butcancorrectthem! arXivpreprintarXiv:2311.08516,2023. (Citedonpg.13)
KarthikValmeekam,MatthewMarquez,andSubbaraoKambhampati. Canlargelanguagemodels
reallyimprovebyself-critiquingtheirownplans? arXivpreprintarXiv:2310.08118,2023. (Cited
onpg.13)
Peiyi Wang, Lei Li, Zhihong Shao, RX Xu, Damai Dai, Yifei Li, Deli Chen, Y Wu, and Zhifang
Sui. Math-shepherd: Verifyandreinforcellmsstep-by-stepwithouthumanannotations. CoRR,
abs/2312.08935,2023. (Citedonpg.13)
XuezhiWang,JasonWei,DaleSchuurmans,QuocLe,EdChi,SharanNarang,AakankshaChowdh-
ery,andDennyZhou. Self-consistencyimproveschainofthoughtreasoninginlanguagemodels.
arXivpreprintarXiv:2203.11171,2022a. (Citedonpg.3,25)
ZhiruoWang,ShuyanZhou,DanielFried,andGrahamNeubig. Execution-basedevaluationfor
open-domaincodegeneration. arXivpreprintarXiv:2212.10481,2022b. (Citedonpg.3,20)
JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,Denny
Zhou,etal. Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. Advancesin
NeuralInformationProcessingSystems,35:24824–24837,2022. (Citedonpg.3,4,25)
Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao. Large language models are
reasonerswithself-verification. arXivpreprintarXiv:2212.09561,2022. (Citedonpg.12)
PeterWest,XimingLu,NouhaDziri,FaezeBrahman,LinjieLi,JenaDHwang,LiweiJiang,Jillian
Fisher,AbhilashaRavichander,KhyathiChandu,etal. Thegenerativeaiparadox:”whatitcan
create,itmaynotunderstand”. arXivpreprintarXiv:2311.00059,2023. (Citedonpg.13,14)
ZhaofengWu,LinluQiu,AlexisRoss,EkinAkyu¨rek,BoyuanChen,BailinWang,NajoungKim,
JacobAndreas,andYoonKim. Reasoningorreciting? exploringthecapabilitiesandlimitations
oflanguagemodelsthroughcounterfactualtasks. arXivpreprintarXiv:2307.02477,2023. (Cited
onpg.13)
18KechiZhang,ZhuoLi,JiaLi,GeLi,andZhiJin. Self-edit: Fault-awarecodeeditorforcodegenera-
tion. InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume
1: Long Papers), pages 769–787, Toronto, Canada, July 2023a. Association for Computational
Linguistics. (Citedonpg.13)
Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, and Lei Li. Algo: Synthesizing
algorithmic programs with generated oracle verifiers. arXiv preprint arXiv:2305.14591, 2023b.
(Citedonpg.13)
Shizhuo Dylan Zhang, Curt Tigges, Stella Biderman, Maxim Raginsky, and Talia Ringer. Can
transformerslearntosolveproblemsrecursively? arXivpreprintarXiv:2305.14699,2023c. (Cited
onpg.13)
Tianyi Zhang, Tao Yu, Tatsunori Hashimoto, Mike Lewis, Wen-tau Yih, Daniel Fried, and Sida
Wang. Coder reviewer reranking for code generation. In International Conference on Machine
Learning,pages41832–41846.PMLR,2023d. (Citedonpg.13)
LianminZheng,Wei-LinChiang,YingSheng,SiyuanZhuang,ZhanghaoWu,YonghaoZhuang,
Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and
chatbotarena. arXivpreprintarXiv:2306.05685,2023. (Citedonpg.12)
AojunZhou,KeWang,ZimuLu,WeikangShi,SichunLuo,ZipengQin,ShaoqingLu,AnyaJia,
Linqi Song, Mingjie Zhan, et al. Solving challenging math word problems using gpt-4 code
interpreterwithcode-basedself-verification. arXivpreprintarXiv:2308.07921,2023. (Citedonpg.
12)
19A Detailed Experimental Setup
A.1 Correct and Counterfeit Data Generation for Correctness Checking
In Table 1, we show statistics about the datasets used for correctness checking. Recall that each
dataset consists of 5 correct and 5 counterfeit samples per problem. We also show the average
pass@1 score of problems in the dataset at T = 0.6. A few examples of correct and counterfeit
samplesareshowninListings1,2,and3.
Table1: CorrectnessCheckingDatasetSizes
Dataset Model Pass@1 Size
CL-34b 42.0 850
CL-7b 36.9 870
HumanEval DS-I-33B 45.1 830
StarCoder 32.9 660
DS-I-6.7B 56.7 810
DS-I-33B 49.4 460
LeetCode
DS-I-6.7B 37.3 360
CL-34B 49.2 1070
CL-7B 52.2 1190
ODEX DS-I-33B 44.3 520
StarCoder 46.2 1060
CL-13B 50.1 1090
HumanEval: HumanEval(Chenetal.,2021)isadatasetof164relativelysimplenaturallanguage
to programming problems in Python. We sample 200 generations at T = 0.6. We use both the
originalHumanEvaltestsandEvalPlustests,whicharemorecomprehensive(Liuetal.,2023). In
order to filter out trivial solutions and keep the task interesting, we only consider a counterfeit
sample to be a program with an EvalPlus score of over 10% and manually inspect the resulting
dataset. Onmanualinspection,wefoundthatEvalPlustestscansometimesbetoostrongandfilter
outcorrectsolutionsduetoverysubtleerrorslikeprecisionandfloatingpointissues,weconsider
asolutionascorrectifitpassesallthebasetestsandatleast95%ofEvalPlustests. Ourmanual
inspectionshowsthatthisisafairercriteriaforassessingprogramcorrectness.
LeetCode: LeetCodeisadatasetof130LeetCodeproblemsusedforprogramminginterviews. We
sample200generationsat T =0.6. UnlikeinHumanEval,run-timeandcomputationalcomplexity
is an important consideration for many LeetCode problems. However, determining whether
a program can finish within the time limit can be difficult. Therefore, we consider counterfeit
programstobethosethatresultedina“Correct”or“WrongAnswer”verdict,andremoveprograms
thatreceiveda“RuntimeError”and“TimeLimitExceeded”.
ODEX: ODEX (Wang et al., 2022b) is an open-domain, multilingual, execution-based natural
languagetocodegenerationbenchmark. WeonlyusetheEnglishsubsetof479problems. Unlike
HumanEval and LeetCode, ODEX contains problems using a wide variety of Python library
functionssuchasnumpy,os,andpandas. Wesample50generationsat T =0.6. AsODEXdoesnot
comewithcleanlyseparatedtestcases,weconsideraprogramascounterfeitifitcanbeparsed
20successfully by ast.parse and have a length of under 500 characters. From manual inspection,
someoftheproblemsinODEXcanbequitevague,makingitdifficulttodiscernifasolutionis
correctorcounterfeitwithoutseeingtheinput-outputformat. Tomitigatethis,forODEXonly,we
include both the generated program and the assertions that is checked. This leads to a slightly easier
settingthantheprevioustwotasks,butwefindthatitstillposesasignificantchallengeformodels.
Listing1: ExampleofcounterfeitsampleforHumanEval,generatedbyCL-34B
def sort_even(l: list):
"""This function takes a list l and returns a list l’ such that
l’ is identical to l in the odd indicies, while its values at the even indicies are equal
to the values of the even indicies of l, but sorted.
>>> sort_even([1, 2, 3])
[1, 2, 3]
>>> sort_even([5, 6, 3, 4])
[3, 6, 5, 4]
"""
even_nums = l[::2]
even_nums.sort()
odd_nums = l[1::2]
ans = []
for i in range(len(even_nums)):
ans.append(even_nums[i])
ans.append(odd_nums[i])
return ans
Listing2: ExampleofcorrectsampleforLeetCode,generatedbyDS-I-33B
"""
You are given a 0-indexed permutation of n integers nums.
A permutation is called semi-ordered if the first number equals 1 and the last number equals n. You
(cid:44)→ can perform the below operation as many times as you want until you make nums a semi-ordered
(cid:44)→ permutation:
Pick two adjacent elements in nums, then swap them.
Return the minimum number of operations to make nums a semi-ordered permutation.
A permutation is a sequence of integers from 1 to n of length n containing each number exactly once.
Example 1:
Input: nums = [2,1,4,3]
Output: 2
Explanation: We can make the permutation semi-ordered using these sequence of operations:
1 - swap i = 0 and j = 1. The permutation becomes [1,2,4,3].
2 - swap i = 2 and j = 3. The permutation becomes [1,2,3,4].
It can be proved that there is no sequence of less than two operations that make nums a semi-ordered
(cid:44)→ permutation.
Example 2:
Input: nums = [2,4,1,3]
Output: 3
Explanation: We can make the permutation semi-ordered using these sequence of operations:
1 - swap i = 1 and j = 2. The permutation becomes [2,1,4,3].
2 - swap i = 0 and j = 1. The permutation becomes [1,2,4,3].
3 - swap i = 2 and j = 3. The permutation becomes [1,2,3,4].
It can be proved that there is no sequence of less than three operations that make nums a semi-ordered
(cid:44)→ permutation.
Example 3:
21Input: nums = [1,3,4,2,5]
Output: 0
Explanation: The permutation is already a semi-ordered permutation.
Constraints:
2 <= nums.length == n <= 50
1 <= nums[i] <= 50
nums is a permutation.
"""
def semiOrderedPermutation(nums: List[int]) -> int:
n = len(nums)
min_idx = nums.index(1)
max_idx = nums.index(n)
if min_idx < max_idx:
return min_idx + n - 1 - max_idx
else:
return min_idx + n - 2 - max_idx
Listing3: ExampleofcounterfeitsampleforODEX,generatedbyDS-I-33B
def f_41861705(split_df, csv_df):
"""Create new DataFrame object by merging columns "key" of dataframes ‘split_df‘ and ‘csv_df‘ and
(cid:44)→ rename the columns from dataframes ‘split_df‘ and ‘csv_df‘ with suffix ‘_left‘ and ‘_right‘
(cid:44)→ respectively
"""
return split_df.merge(csv_df, how=’left’, left_on=’key’, right_on=’key’, suffixes=(’_left’, ’
(cid:44)→ _right’))
import pandas as pd
def check(candidate):
split_df = pd.DataFrame({’key’: [’foo’, ’bar’], ’value’: [1, 2]})
csv_df = pd.DataFrame({’key’: [’foo’, ’baz’], ’value’: [3, 4]})
result = pd.DataFrame({’key’: [’foo’], ’value_left’: [1],’value_right’: [3]})
assert all(candidate(csv_df, split_df) == result)
check(f_41861705)
A.2 Data Generation for Execution Prediction
WeperformcodeexecutionexperimentsonHumanEvalandLeetCodeprograms. Theinputsand
outputs for these datasets are primitive Python objects (mostly int, str, bool, list). While it
is possible, we do not evaluate execution for ODEX because many of the programs involve file
modifications and cannot easily be represented. For each dataset and data-generating model,
we use the same set of programs used in the correctness checking experiment for consistency.
As of today, we cannot expect a language model to follow the execution of arbitrary Python
programs. Therefore,weensurethattheexecutionsamplesinourbenchmarkarereasonableby
applying a filter following the setup in (Gu et al., 2024). One key difference from their work is
that instead of using arbitrary programs, the programs we use here are seeded from a natural
language specification and are semantically meaningful. This allows us to analyze how models
behavedifferentlywhenaskedtoreasonaboutcorrectandcounterfeitprograms.
22Wecreateourdatasetofsamplestoevaluatecodeexecutionasfollows: first,wetaketheprograms
generatedforthecorrectnesscheckingdataset. Thedocstringcontainingtheproblemstatement
is stripped away to force the model to use the provided code. Second, we run the program on
the tests provided in the original problem statement and examples, which are generally simple
and concise to create a large set of model-generated programs, inputs, and outputs. Third, we
apply a compile-time and runtime based filter using Python bytecode to remove programs that
are too long, require complex arithmetic/floating point operations, and have too many steps in
theexecution. Thefinalstepisamanualinspectionofprograms,inputs,andoutputspassingthe
filtertoensurethattheyseemreasonable. TheresultingdatasetsizesareshowninTable2, and
examplesareshowninListings4,5.
Table2: ExecutionDatasetSizes
Dataset Model DatasetSize
CL-34B 1406
CL-7B 1528
HumanEval DS-I-33B 1964
StarCoder 1622
DS-I-6.7B 1917
DS-I-33B 845
LeetCode
DS-I-6.7B 694
Listing4: ExampleofHumanEvalexecutionpredictionexample,generatedbyStarCoder
from typing import List
def string_xor(a: str, b: str) -> str:
assert len(a) == len(b)
res = ""
for i in range(len(a)):
if a[i] == b[i]:
res += "0"
else:
res += "1"
return res
assert string_xor(’1’, ’1’) == ??
# Answer: ’0’
Listing5: ExampleofLeetCodeexecutionpredictionexample,generatedbyDS-I-6.7B
def relocateMarbles(nums: List[int], moveFrom: List[int], moveTo: List[int]) -> List[int]:
# Create a dictionary to store the number of marbles at each position
marbles = {}
for num in nums:
marbles[num] = marbles.get(num, 0) + 1
# Apply the moves
for f, t in zip(moveFrom, moveTo):
# Remove the marbles at the source position
count = marbles.pop(f)
# Add the marbles at the target position
marbles[t] = marbles.get(t, 0) + count
23# Return the sorted keys of the dictionary
return sorted(marbles.keys())
assert relocateMarbles(nums = [1, 6, 7, 8], moveFrom = [1, 7, 2], moveTo = [2, 9, 5]) == ??
# Answer: [5, 6, 8, 9]
24B Models, Task Evaluation, and Prompts
B.1 Models
WeuseDeepSeek(Guoetal.,2024),CodeLlama(Roziereetal.,2023),andStarCoder(Lietal.,2023)
models. TheHuggingFaceURLsarelistedinTable3. ExperimentswererunonA100(80GB)and
A6000(40GB)machines.
Table3: ModelLinks
ModelName HuggingFaceURL
DeepSeekInstruct(6.7B) https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct
DeepSeekInstruct(33B) https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct
StarCoder(15.5B) https://huggingface.co/bigcode/starcoder
CodeLlama(7B) https://huggingface.co/codellama/CodeLlama-7b-hf
CodeLlama(13B) https://huggingface.co/codellama/CodeLlama-13b-hf
CodeLlama(34B) https://huggingface.co/codellama/CodeLlama-34b-hf
CodeLlamaInstruct(34B) https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf
B.2 Task Evaluation
Correctness Checking: For this task, we use an autoregressive-style CoT prompt from Listing 7.
We perform majority voting on the binary label (correct/incorrect) with N = 10 samples and
temperature T =0.2andreportaccuracyontheselabels. Wedothisbecausegreedydecodingcan
benoisyforchain-of-thoughtpromptingandmajorityvotinghasbeenshowntohelp(Weietal.,
2022;Wangetal.,2022a).
We also compared this with an autoregressive-style prompt without CoT, where the model is
simplyaskedtopredictCorrect/Incorrect. Inthiscase,wehavethedirectlog-probabilitiesofeach
outcome p and p = 1−p , sothepredictedlabel istakentobe p ≥ 0.5. In
correct incorrect correct correct
Fig. 10,weobservethatforamajorityofsettingsandsamples,CoThelpstheaccuracyofthistask,
motivatingouruseofCoT.
25Impact of CoT on Correctness Checking
CL-34b DS-6.7b
CL-7b SC
DS-33b CL-13b
65
60
55
50
HHuummaannEEvvaall
OODDEEXX
LLeeeettCCooddee
50 55 60 65
Accuracy without CoT
Figure10: ModelsareslightlybetterwhenusingCoTthanwithout
Execution Prediction: For this task, we use the same prompt format as in (Gu et al., 2024) with
modified few-shot examples to better resemble our dataset format. We tested both CoT and
non-CoTprompts,discoveringthatCoTdidnothelpmodelsotherthanGPT-3.5andGPT-4. Thisis
relativelyconsistentwiththeresultsfromGuetal.(2024)2,whichonlysawa1.2%improvementfor
CodeLlama34BandnoimprovementforCodeLlama13B.Therefore,weuseCoTforGPTmodels,
andnon-CoTpromptsfortheothers. Theaccuracyiscalculatedusingpass@1with N =10,T =0.2.
Repair: Forthistask,webaseourpromptformatonthoseemployedinpriorworkbyOlaussonetal.
(2024). This prompt format is reminiscent of Chain-of-Thought in that it instructs the model to
generateatextualexplanationofwhatiswrongwiththecode,beforegeneratingthefixedversion
oftheprogram. Notethatinourversionofthispromptformat,themodelisnotgivenanydetails
astowhattesttesttheprogramfailed,andsohastorelatetheprogramtothenaturallanguage
specificationtodebugit. Unliketheothertasks,thepromptformatweuseforrepairiszero-shot.
Preliminaryexperimentsindicatedthatthisledtobetterresults,particularlyforsmallermodels
whichshowedatendencytodebugtheexampleprograminsteadofthetarget. Fortheexperiments
withDeepSeek-basedmodels,wereplacedtheHTML-styletagswithMarkdown-styletags(e.g.,
[PYTHON]→```python). Sincerepairrequiresgeneratingaratherlonganswer,withbothatextual
explanationandafixedversionoftheprogram,variancecanbehigherthanintheothersettings
we consider. To reduce this variance, we generate a large amount (R = 50) of repair candidates
foreachcounterfeitsample,usingatemperatureof T =0.6. Wethenaverageoverall5·50=250
samplestocomputethemeansuccessrateforeachtask,andalsoshowa95%confidenceinterval
onthemean.3 Notethatduetothisincreasedcomputationalburden,wedonotcarryoutrepair
experimentsforthefullCartesianproductofmodelsconsideredbefore,insteadfocusingonthose
open-sourcemodelsthatperformedbestoneachdataset.
2Seetheirleaderboard
3Recallthatourcurateddatasetscontain5counterfeitsamplesperproblem.
26
ToC
htiw
ycaruccAB.3 Prompts
Inthissection,welisttheHumanEvalprompts. Thepromptsforothertaskscanbefoundinour
codebase4. Listings6,7showthecorrectnesscheckingpromptwithoutandwithCoT,andListings
8,9showtheexecutionpredictionprompts. WegivecredittoGuetal.(2024)andOlaussonetal.
(2024)fortheirexecutionpredictionandrepairprompts.
Listing6: Promptforcorrectnesschecking(HumanEval)
You will be given a Python coding problem with its specification and input/output examples in
(cid:44)→ docstrings.
Your goal is to determine whether the program exactly matches the specification.
A correct program must be correct for all inputs, including hidden test cases not listed in the
(cid:44)→ docstring.
In [ANSWER] and [/ANSWER] tags, write "Correct" if the program is correct, and "Incorrect" otherwise.
[PYTHON]
from typing import List
def is_at_least_zero(numbers: List[int]) -> bool:
""" For a given list of numbers, checks if their sum is at least 0.
>>> is_at_least_zero([1, -2, 3])
True
>>> is_at_least_zero([-1, -2, 2])
False
"""
return sum(numbers) >= 0
[/PYTHON]
[ANSWER]
Correct
[/ANSWER]
[PYTHON]
from typing import List
def identical_length(s: List[str]) -> bool:
""" Check if in given list of strings, there exist two different
strings with the same length.
>>> identical_length(["abc", "def", "ghi"])
True
>>> identical_length(["abc", "gh"])
False
"""
for i in range(len(s)):
for j in range(len(s)):
if len(s[i]) == len(s[j]):
return True
return False
[/PYTHON]
[ANSWER]
Incorrect
[/ANSWER]
Listing7: Promptforcorrectnesschecking,CoT(HumanEval)
You will be given a Python coding problem with its specification and input/output examples in
(cid:44)→ docstrings.
4https://github.com/update-after-deanonymization
27Your goal is to judge whether the program exactly matches the behavior specified in the docstring.
A correct program must be correct for all inputs, including hidden test cases not listed in the
(cid:44)→ docstring.
First, think step by step about the program in [THOUGHT] and [/THOUGHT] tags.
In [ANSWER] and [/ANSWER] tags, write "Correct" if the program is correct, and "Incorrect" otherwise.
[PYTHON]
from typing import List
def is_at_least_zero(numbers: List[int]) -> bool:
""" For a given list of numbers, checks if their sum is at least 0.
>>> is_at_least_zero([1, -2, 3])
True
>>> is_at_least_zero([-1, -2, 2])
False
"""
return sum(numbers) >= 0
[/PYTHON]
[THOUGHT]
The function calculates the sum of a list of integers and checks if the sum is at least 0. The
(cid:44)→ implementation uses Python’s built-in sum function to calculate the total sum of the list and
(cid:44)→ compares it with 0 using the >= operator. This approach should work correctly for any list of
(cid:44)→ integers, including empty lists, where the sum would be 0, thus meeting the specification for
(cid:44)→ all possible inputs.
[/THOUGHT]
[ANSWER]
Correct
[/ANSWER]
[PYTHON]
from typing import List
def identical_length(s: List[str]) -> bool:
""" Check if in given list of strings, there exist two different
strings with the same length.
>>> identical_length(["abc", "def", "ghi"])
True
>>> identical_length(["abc", "gh"])
False
"""
for i in range(len(s)):
for j in range(len(s)):
if len(s[i]) == len(s[j]):
return True
return False
[/PYTHON]
[THOUGHT]
The program checks if any two strings in the list have the same length. However, it also compares each
(cid:44)→ string with itself due to the loops’ range, which means it will always find two strings (the
(cid:44)→ same string compared with itself) with identical length, returning True incorrectly for any
(cid:44)→ non-empty list. The correct approach should exclude the case where i equals j.
[/THOUGHT]
[ANSWER]
Incorrect
[/ANSWER]
Listing8: Promptforexecutionprediction(HumanEval)
You are given a Python function and an assertion containing an input to the function.
28Complete the assertion with a literal (no unsimplified expressions, no function calls) containing the
(cid:44)→ output when executing the provided code on the given input.
Even if the function is incorrect or incomplete, give the output when executing the Python code as
(cid:44)→ provided.
Assume all required imports have been included.
Do NOT output any extra information. Provide the full assertion with the correct output in [ANSWER]
(cid:44)→ and [/ANSWER] tags, following the examples.
[PYTHON]
def add_one(number : int) -> int:
return number + 2
assert add_one(17) == ??
[/PYTHON]
[ANSWER]
assert add_one(17) == 19
[/ANSWER]
[PYTHON]
def add_character_a(string : str) -> str:
return string + "a"
assert add_character_a("x9j") == ??
[/PYTHON]
[ANSWER]
assert add_character_a("x9j") == "x9ja"
[/ANSWER]
[PYTHON]
{solution}
assert {input} == ??
[/PYTHON]
[ANSWER]
Listing9: Promptforexecutionprediction,CoT(HumanEval)
You are given a Python function and an assertion containing an input to the function.
Complete the assertion with a literal (no unsimplified expressions, no function calls) containing the
(cid:44)→ output when executing the provided code on the given input.
Even if the function is incorrect or incomplete, give the output when executing the Python code as
(cid:44)→ provided.
Assume all required imports have been included. Think through the execution of the program in [THOUGHT
(cid:44)→ ] and [/THOUGHT] tags.
Provide the full assertion with the correct output in [ANSWER] and [/ANSWER] tags, following the
(cid:44)→ examples.
[PYTHON]
def performOperation(s : str) -> str:
s = s + s
return "b" + s + "a"
assert performOperation("hi") == ??
[/PYTHON]
[THOUGHT]
Let’s execute the code step by step:
1. The function performOperation is defined, which takes a single argument s.
2. The function is called with the argument "hi", so within the function, s is initially "hi".
3. Inside the function, s is concatenated with itself, so s becomes "hihi".
4. The function then returns a new string that starts with "b", followed by the value of s (which is
(cid:44)→ now "hihi"), and ends with "a".
5. The return value of the function is therefore "bhihia".
[/THOUGHT]
[ANSWER]
assert performOperation("hi") == "bhihia"
29[/ANSWER]
[PYTHON]
{solution}
assert {input} == ??
[/PYTHON]
[THOUGHT]
Listing10: Promptfor(self-)repair(HumanEval)
=== system prompt ===
You are a helpful programming assistant and an expert Python programmer.
You are helping a user write a program.
The user has been given a function signature, along with a doc-string explaining its specification,
(cid:44)→ and has then written an attempted implementation of the function.
Unfortunately, their code has some bugs and is not passing all of the hidden unit tests.
You will help the user by first giving a concise textual explanation of what is wrong with the code.
After you have pointed out what is wrong with the code, you will then generate a fixed version of the
(cid:44)→ program.
Put your fixed program within code delimiters, for example:
[PYTHON]
# YOUR CODE HERE
[/PYTHON]
Do not change the function signature or doc-string in any way: they must be exactly as given by the
(cid:44)→ user.
=== user prompt ===
### INCORRECT CODE
[PYTHON]
{code}
[/PYTHON]
The program does not pass all of the hidden test cases. Please fix it.
30C Accuracy Results for All Tasks
C.1 Correctness Checking
Fig. 11 shows the full set of correctness checking results across all models for each of the three
datasets.
Correctness Checking (HumanEval) Correctness Checking (LeetCode)
90 90
SC CL-34b SC DS-6.7b
CL-13b DS-33b CL-7b GPT-3.5
CL-7b GPT-3.5 CL-13b DS-33b
80 DS-6.7b GPT-4 80 CL-34b GPT-4
70 70
60 60
50 50
CL-34b CL-7b DS-6.7b DS-33b SC DS-33b DS-6.7b
Model Generating Programs Model Generating Programs
(a) (b)
Correctness Checking (ODEX)
90
SC CL-34b
DS-6.7b DS-33b
CL-13b GPT-3.5
80 CL-7b GPT-4
70
60
50
CL-34b CL-7b DS-33b SC
Model Generating Programs
(c)
Figure11: Correctnesscheckingresultsacrossallmodelsanddatasets
31
)%(
ycaruccA
)%(
ycaruccA
)%(
ycaruccATheseresultsareshowninheatmapforminFig. 12.
51% 57% 53% 62% 51% 55% 60% 65% 49%
51% 55%
50% 55% 52% 57% 48%
56% 58% 65% 50%
49% 51% 50% 57% 49%
56% 61% 64% 49%
51% 55%
51% 56% 51% 59% 51%
55% 56% 62% 50%
53% 57% 52% 63% 51%
DS-6.7b DS-33b
CL-7b CL-34b DS-33b SC
CL-7b CL-34b DS-6.7b DS-33b SC Evaluation Model
Evaluation Model Evaluation Model
(a)Correctness(HumanEval) (b)Correctness(ODEX) (c)Correctness(LeetCode)
Figure12: Heatmapofaccuraciesforcorrectnesschecking.
InFig. 13,weshowtheconfusionmatricesofpredictedandcorrectlabels,whichhighlightsthe
predictionbiasesofvariousmodels.
Confusion Matrices for Verification
CL-7b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
I 114 231 I 160 185 I 21 324 I 103 242 I 64 281 I 110 235 I 281 64
C 107 238 C 112 233 C 3 342 C 19 326 C 58 287 C 34 311 C 46 299
I C I C I C I C I C I C I C
Predicted
CL-7b CL-34b DS-6.7b DS-33b SC
I 86 244 I 137 193 I 11 319 I 65 265 I 79 251
C 87 243 C 101 229 C 0 330 C 18 312 C 89 241
I C I C I C I C I C
Predicted
CL-7b CL-34b DS-6.7b DS-33b SC
I 101 219 I 107 213 I 3 317 I 59 261 I 66 254
C 106 214 C 102 218 C 0 320 C 15 305 C 70 250
I C I C I C I C I C
Predicted
CL-7b CL-34b DS-6.7b DS-33b SC
I 101 194 I 104 191 I 8 287 I 73 222 I 80 215
C 93 202 C 68 227 C 0 295 C 17 278 C 74 221
I C I C I C I C I C
Predicted
CL-7b CL-34b DS-6.7b DS-33b SC
I 83 182 I 115 150 I 13 252 I 71 194 I 43 222
C 65 200 C 78 187 C 1 264 C 1 264 C 37 228
I C I C I C I C I C
Predicted
(a)HumanEval
32
ledoM
ataD
b7-LC
b43-LC
b7.6-SD
b33-SD
CS
smargorP
b7-LC
smargorP
b43-LC
smargorP
b7.6-SD
smargorP
b33-SD
smargorP
CS
eurT
eurT
eurT
eurT
eurT
ledoM
ataD
b7-LC
b43-LC
b33-SD
CS
ledoM
ataD
b7.6-SD
b33-SDConfusion Matrices for Verification
CL-7b CL-34b DS-6.7b DS-33b SC
I 0 180 I 1 179 I 7 173 I 39 141 I 54 126
C 1 179 C 2 178 C 5 175 C 22 158 C 56 124
I C I C I C I C I C
Predicted
CL-7b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
I 0 230 I 4 226 I 17 213 I 52 178 I 72 158 I 19 211 I 194 36
C 0 230 C 2 228 C 12 218 C 29 201 C 78 152 C 9 221 C 79 151
I C I C I C I C I C I C I C
Predicted
(b)LeetCode
Confusion Matrices for Verification
CL-7b CL-34b DS-33b SC
I 273 322 I 185 410 I 221 374 I 259 336
C 213 382 C 70 525 C 45 550 C 265 330
I C I C I C I C
Predicted
CL-7b CL-34b DS-33b SC
I 262 273 I 145 390 I 199 336 I 235 300
C 203 332 C 64 471 C 37 498 C 239 296
I C I C I C I C
Predicted
CL-7b CL-34b DS-33b SC GPT-3.5 GPT-4
I 140 120 I 83 177 I 94 166 I 118 142 I 112 148 I 228 32
C 110 150 C 24 236 C 22 238 C 122 138 C 53 207 C 77 183
I C I C I C I C I C I C
Predicted
CL-7b CL-34b DS-33b SC
I 248 282 I 136 394 I 175 355 I 207 323
C 196 334 C 74 456 C 44 486 C 207 323
I C I C I C I C
Predicted
(c)ODEX
Figure13: Confusionmatricesofpredictionsvs. labels
33
smargorP
b7.6-SD
smargorP
b33-SD
eurT
eurT
smargorP
b7-LC
smargorP
b43-LC
smargorP
b33-SD
smargorP
CS
eurT
eurT
eurT
eurTInFig. 14,wealsoshowafewmoreplotshighlightingthatmodelsoftenmispredictcounterfeit
samplesascorrect.
HumanEval, CL-7b HumanEval, CL-34b
100 Overall Correct Counterfeit 100 Overall Correct Counterfeit
80 80
60 60
40 40
20 20
0 0
CL-7b CL-13b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4 CL-7b CL-13b CL-34b DS-6.7b DS-33b SC
Eval Model Eval Model
(a)HumanEval(CL-7B) (b)HumanEval(CL-34B)
LeetCode, DS-6.7b LeetCode, DS-33b
100 Overall Correct Counterfeit 100 Overall Correct Counterfeit
80 80
60 60
40 40
20 20
0 0
CL-7b CL-13b CL-34b DS-6.7b DS-33b SC CL-7b CL-13b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
Eval Model Eval Model
(c)LeetCode(DS-6.7B) (d)LeetCode(DS-33B)
ODEX, SC ODEX, DS-33b
100 Overall Correct Counterfeit 100 Overall Correct Counterfeit
80 80
60 60
40 40
20 20
0 0
CL-7b CL-13b CL-34b DS-6.7b DS-33b SC CL-7b CL-13b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
Eval Model Eval Model
(e)ODEX(StarCoder) (f)ODEX(DS-33B)
Figure14: Modelsaremuchbetteratassessingthecorrectnessofcorrectsamplesthancounterfeit
samples.
34
)%(
ycaruccA
)%(
ycaruccA
)%(
ycaruccA
)%(
ycaruccA
)%(
ycaruccA
)%(
ycaruccAC.2 Execution Prediction
Fig. 15 shows the full set of correctness checking results across all models for each of the three
datasets.
Execution (HumanEval) Execution (LeetCode)
100 100
CL-7b CL-34b CL-13b DS-33b
SC DS-33b CL-34b DS-6.7b
CL-13b GPT-3.5 CL-7b GPT-3.5
80 DS-6.7b GPT-4 80 SC GPT-4
60 60
40 40
20 20
0 0
CL-34b CL-7b DS-6.7b DS-33b SC DS-33b DS-6.7b
Model Generating Programs Model Generating Programs
(a) (b)
Figure15: Executionpredictionresultsacrossallmodelsanddatasets
TheseresultsareshowninheatmapforminFig. 16.
49% 61% 61% 67% 51%
34% 38%
48% 63% 60% 68% 51%
41% 53% 52% 60% 41%
33% 33%
47% 49% 55% 66% 48%
46% 58% 57% 65% 46%
DS-6.7b DS-33b
CL-7b CL-34b DS-6.7b DS-33b SC Evaluation Model
Evaluation Model
(a)Execution(HumanEval) (b)Execution(LeetCode)
Figure16: Heatmapofaccuraciesforcorrectnesschecking.
35
)%(
ycaruccA
ledoM
ataD
b7-LC
b43-LC
b7.6-SD
b33-SD
CS
ledoM
ataD
b7.6-SD
b33-SD
)%(
ycaruccAInFig. 17,weshowthatonotherdatasetsandmodels,modelsaregenerallybetteratexecuting
correct samples than counterfeit samples with outputs that don’t match those of the correct
samples, and that models often predict the output of the correct sample when asked to execute
thesecounterfeitsamples.
HumanEval, CL-34b
100 HumanEval, CL-7b 100 Correct
Correct Counterfeit (Test-Passing)
Counterfeit (Test-Passing) Counterfeit (Test-Failing)
Counterfeit (Test-Failing) 80 Counterfeit (Test-Failing), Confused
80 Counterfeit (Test-Failing), Confused
60
60
40
40
20 20
0 0
CL-7b CL-13b CL-34b DS-6.7b DS-33b SC CL-7b CL-13b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
Model Model
(a)HumanEval(CL-7B) (b)HumanEval(CL-34B)
HumanEval, DS-33b HumanEval, SC
100 100
Correct Correct
Counterfeit (Test-Passing) Counterfeit (Test-Passing)
Counterfeit (Test-Failing) Counterfeit (Test-Failing)
80 Counterfeit (Test-Failing), Confused 80 Counterfeit (Test-Failing), Confused
60 60
40 40
20 20
0 0
CL-7b CL-13b CL-34b DS-6.7b DS-33b SC CL-7b CL-13b CL-34b DS-6.7b DS-33b SC
Model Model
(c)HumanEval(DS-33B) (d)HumanEval(StarCoder)
100 Correct LeetCode, DS-6.7b 100 Correct LeetCode, DS-33b
Counterfeit (Test-Passing) Counterfeit (Test-Passing)
Counterfeit (Test-Failing) Counterfeit (Test-Failing)
80 Counterfeit (Test-Failing), Confused 80 Counterfeit (Test-Failing), Confused
60 60
40 40
20 20
0 0
CL-7b CL-13b CL-34b DS-6.7b DS-33b SC CL-7b CL-13b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
Model Model
(e)LeetCode(DS-6.7B) (f)LeetCode(DS-33B)
Figure17: Modelsaremuchbetteratexecutingcorrectsamplesthancounterfeitsamples,andeven
oftenexecutecounterfeitsamplesasiftheywerecorrect.
36
ycaruccA
ycaruccA
ycaruccA
ycaruccA
ycaruccA
ycaruccAC.3 Repair
Figures18-20showthefullsetofscatterplotsfortherepairexperimentsinSec.3.3. Intheseplots,
thesamemodelisusedforbothrepairandtheinitialcodegeneration,sothattheresamplingstrategycan
berepresentedbytheline y = x (simplifyingexposition). Notethateveninthemostsuccessful
setting,DS-I-33bonHumanEval,thenumberofproblemsforwhichrepairismoresuccessfulthan
simplyresamplingisstillintheminority(35/81).
Figures21-22alsoshowstheabsolutemeansuccessrateofrepairacrosstasksforeachmodeland
dataset, similarly to how was done in the previous sections. Note that these absolute numbers
shouldnotbepaidtomuchattentionto,sincerepairmustalwaysbecomparedtotheaccuracyof
thesimpleresamplingstrategy;however,theydoshowthatmodelsdonotappeartobebetterat
repairingtheirowncounterfeitsamplesthanthosegeneratedbyothermodels.
HumanEval, CL-I-34b HumanEval, DS-I-33b
1.0 re-sampling (y = x) 1.0 re-sampling (y = x)
repair resampling (68/82) repair resampling (46/81)
repair > resampling (14/82) repair > resampling (35/81)
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00
problem pass rate problem pass rate
(a)CL-I-34b (b)DS-I-33b
Figure18: Repairsuccessvs. baselinepass@1onHumanEval.
LeetCode, DS-I-6.7b LeetCode, DS-I-33b
1.0 re-sampling (y = x) 1.0 re-sampling (y = x)
repair resampling (32/36) repair resampling (41/46)
repair > resampling (4/36) repair > resampling (5/46)
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00
problem pass rate problem pass rate
(a)DS-I-6.7b (b)DS-I-33b
Figure19: Repairsuccessvs. baselinepass@1onLeetCode.
37
sriaper
fo
etar
ssap
egareva
sriaper
fo
etar
ssap
egareva
sriaper
fo
etar
ssap
egareva
sriaper
fo
etar
ssap
egarevaODEX, CL-I-34b ODEX, DS-I-33b
1.0 re-sampling (y = x) 1.0 re-sampling (y = x)
repair resampling (93/107) repair resampling (40/52)
repair > resampling (14/107) repair > resampling (12/52)
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00
problem pass rate problem pass rate
(a)CL-I-34b (b)DS-I-33b
Figure20: Repairsuccessvs. baselinepass@1onODEX.
Repair (HumanEval) Repair (LeetCode) Repair (ODEX)
100 100 100
cl34 ds33 ds33 ds6.7 cl34 ds33
80 80 80
60 60 60
40 40 40
20 20 20
0 0 0
cl34 ds33 ds33 ds6.7 cl34 ds33
Model Generating Programs Model Generating Programs Model Generating Programs
(a)HumanEval (b)LeetCode (c)ODEX
Figure21: Averagerepairaccuracyacrossallmodelsanddatasets.
21% 51% 19% 12% 20% 33%
16% 41% 27% 11% 19% 29%
cl34 ds33 ds33 ds6.7 cl34 ds33
Evaluation Model Evaluation Model Evaluation Model
(a)HumanEval (b)LeetCode (c)ODEX
Figure22: Heatmapsofaveragerepairaccuracyacrossallmodelsanddatasets.
38
)%(
ycaruccA
ledoM
ataD
43lc
33sd
sriaper
fo
etar
ssap
egareva
)%(
ycaruccA
ledoM
ataD
33sd
7.6sd
sriaper
fo
etar
ssap
egareva
)%(
ycaruccA
ledoM
ataD
43lc
33sdD Correlations by Problem Difficulty
D.1 Problem Difficulty vs. Correctness Checking
In Fig. 23, we show the accuracy of HumanEval (top), LeetCode (middle), and ODEX (bottom)
acrossdifferentmodels. Weseeanabsenceofcorrelationacrosstheboard.
Correctness Checking vs. Generation (HumanEval)
CL-7b CL-34b DS-6.7b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-6.7b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-6.7b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-6.7b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-6.7b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
Problem Difficulty to Model (Based on Pass@1)
39
smargorP
b7-LC
smargorP
b43-LC
smargorP
b7.6-SD
smargorP
b33-SD
smargorP
CS
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevACorrectness Checking vs. Generation (LeetCode)
DS-6.7b DS-33b
100
50
0
Easy Medium Difficult Easy Medium Difficult
DS-6.7b DS-33b
100
50
0
Easy Medium Difficult Easy Medium Difficult
Problem Difficulty to Model (Based on Pass@1)
Correctness Checking vs. Generation (ODEX)
CL-7b CL-34b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
Problem Difficulty to Model (Based on Pass@1)
Figure23: Accuraciesforcorrectnesscheckingtaskbucketedbydifficulty.
40
smargorP
b7-LC
smargorP
b43-LC
smargorP
b33-SD
smargorP
CS
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevA
smargorP
b7.6-SD
smargorP
b33-SD
ycaruccA
gnikcehC
ssentcerroC
egarevA
ycaruccA
gnikcehC
ssentcerroC
egarevAD.2 Problem Difficulty vs. Execution
InFig. 24,weshowtheaccuracyofHumanEval(a),LeetCode(b),andODEX(c)acrossdifferent
models. We see a slight correlation, where programs for more difficult problems are harder to
execute.
Execution vs. Generation (HumanEval)
CL-7b CL-34b DS-33b DS-6.7b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b DS-6.7b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b DS-6.7b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b DS-6.7b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
CL-7b CL-34b DS-33b DS-6.7b SC
100
50
0
Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult Easy Medium Difficult
Problem Difficulty to Model (Based on Pass@1)
(a)HumanEval
41
smargorP
b7-LC
smargorP
b43-LC
smargorP
b33-SD
smargorP
b7.6-SD
smargorP
CS
ycaruccA
noitucexE
egarevA
ycaruccA
noitucexE
egarevA
ycaruccA
noitucexE
egarevA
ycaruccA
noitucexE
egarevA
ycaruccA
noitucexE
egarevAExecution vs. Generation (LeetCode)
DS-33b DS-6.7b
100
50
0
Easy Medium Difficult Easy Medium Difficult
DS-33b DS-6.7b
100
50
0
Easy Medium Difficult Easy Medium Difficult
Problem Difficulty to Model (Based on Pass@1)
(b)LeetCode
Figure24: Accuraciesforexecutiontaskbucketedbydifficulty.
42
smargorP
b33-SD
smargorP
b7.6-SD
ycaruccA
noitucexE
egarevA
ycaruccA
noitucexE
egarevAD.3 HumanEval Pass Rate vs. Correctness Prediction
In Fig. 25, we investigate the correlation between a program’s pass rate on HumanEval (using
EvalPlus tests) and its prediction. Since a problem’s pass rate is indicative of how close it is to
correct, we might expect that programs with a higher pass rate have a higher chance of being
predicted as correct. For most models, this does not seem ot be the case, though we do see this
trendforGPT-4.
Pass Rate vs. Correctness (HumanEval)
CL-7b CL-34b DS-6.7b DS-33b SC GPT-3.5 GPT-4
1 107 69 1 70 78 1 140 9 1 91 42 1 134 46 1 86 44 1 17 146
0 45 124 0 82 115 0 12 184 0 61 151 0 18 147 0 66 149 0 135 47
<0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5
EvalPlus PR
CL-7b CL-34b DS-6.7b DS-33b SC
1 101 55 1 77 82 1 128 7 1 92 25 1 99 46
0 31 143 0 55 116 0 4 191 0 40 173 0 33 152
<0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5
EvalPlus PR
CL-7b CL-34b DS-6.7b DS-33b SC
1 72 64 1 69 67 1 106 0 1 91 41 1 89 46
0 37 147 0 40 144 0 3 211 0 18 170 0 20 165
<0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5
EvalPlus PR
CL-7b CL-34b DS-6.7b DS-33b SC
1 50 73 1 44 70 1 71 1 1 53 48 1 65 67
0 28 144 0 34 147 0 7 216 0 25 169 0 13 150
<0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5
EvalPlus PR
CL-7b CL-34b DS-6.7b DS-33b SC
1 74 48 1 55 61 1 99 3 1 61 23 1 85 19
0 35 108 0 54 95 0 10 153 0 48 133 0 24 137
<0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5 <0.5 >0.5
EvalPlus PR
Figure25: ModelsotherthanGPT-4showalackofcorrelationbetweenaproblem’spassrateand
itscorrectnessprediction.
43
ataD
b7-LC
ataD
b43-LC
ataD
b7.6-SD
ataD
b33-SD
ataD
CS
derP
derP
derP
derP
derPE Examples of Counterfeits
E.1 Counterfeits with Algorithmic Errors
def multiply(a, b):
"""Complete the function that takes two integers and returns
the product of their unit digits.
Assume the input is always valid.
Examples:
multiply(148, 412) should return 16.
multiply(19, 28) should return 72.
multiply(2020, 1851) should return 0.
multiply(14,-15) should return 20.
"""
return a % 10 * b % 10
def sort_numbers(numbers: str) -> str:
""" Input is a space-delimited string of numberals from ’zero’ to ’nine’.
Valid choices are ’zero’, ’one’, ’two’, ’three’, ’four’, ’five’, ’six’, ’seven’, ’eight’ and ’nine
(cid:44)→ ’.
Return the string with numbers sorted from smallest to largest
>>> sort_numbers(’three one five’)
’one three five’
"""
return ’ ’.join(sorted(numbers.split()))
def eat(number, need, remaining):
"""
You’re a hungry rabbit, and you already have eaten a certain number of carrots,
but now you need to eat more carrots to complete the day’s meals.
you should return an array of [ total number of eaten carrots after your meals,
the number of carrots left after your meals ]
if there are not enough remaining carrots, you will eat all remaining carrots, but will still be
(cid:44)→ hungry.
Example:
* eat(5, 6, 10) -> [11, 4]
* eat(4, 8, 9) -> [12, 1]
* eat(1, 10, 10) -> [11, 0]
* eat(2, 11, 5) -> [7, 0]
Variables:
@number : integer
the number of carrots that you have eaten.
@need : integer
the number of carrots that you need to eat.
@remaining : integer
the number of remaining carrots thet exist in stock
Constrain:
* 0 <= number <= 1000
* 0 <= need <= 1000
* 0 <= remaining <= 1000
Have fun :)
"""
return [number + need, remaining - need] if remaining - need >= 0 else [remaining, 0]
44E.2 Counterfeits ignoring aspects of the specification
def specialFilter(nums):
"""Write a function that takes an array of numbers as input and returns
the number of elements in the array that are greater than 10 and both
first and last digits of a number are odd (1, 3, 5, 7, 9).
For example:
specialFilter([15, -73, 14, -15]) => 1
specialFilter([33, -2, -3, 45, 21, 109]) => 2
"""
# Define a function that checks if the first and last digit of a number is odd
def isSpecial(n):
if n < 0: n = -n # make sure n is positive
return n % 10 in [1, 3, 5, 7, 9] and n//10 % 10 in [1, 3, 5, 7, 9]
# Use a list comprehension to filter the numbers and count the results
return sum(1 for num in nums if num > 10 and isSpecial(num))
def common(l1: list, l2: list):
"""Return sorted unique common elements for two lists.
>>> common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])
[1, 5, 653]
>>> common([5, 3, 2, 8], [3, 2])
[2, 3]
"""
return list(set(l1) & set(l2))
def find_max(words):
"""Write a function that accepts a list of strings.
The list contains different words. Return the word with maximum number
of unique characters. If multiple strings have maximum number of unique
characters, return the one which comes first in lexicographical order.
find_max(["name", "of", "string"]) == "string"
find_max(["name", "enam", "game"]) == "enam"
find_max(["aaaaaaa", "bb" ,"cc"]) == ""aaaaaaa"
"""
max_word = ""
max_len = 0
for word in words:
word_len = len(set(word))
if word_len > max_len:
max_len = word_len
max_word = word
return max_word
def double_the_difference(lst):
’’’
Given a list of numbers, return the sum of squares of the numbers
in the list that are odd. Ignore numbers that are negative or not integers.
double_the_difference([1, 3, 2, 0]) == 1 + 9 + 0 + 0 = 10
double_the_difference([-1, -2, 0]) == 0
double_the_difference([9, -2]) == 81
double_the_difference([0]) == 0
If the input list is empty, return 0.
’’’
return sum(elem**2 for elem in lst if elem%2!=0)
45E.3 Counterfeits that fail to handle important edge cases
def intersperse(numbers: List[int], delimeter: int) -> List[int]:
""" Insert a number ’delimeter’ between every two consecutive elements of input list ‘numbers’
>>> intersperse([], 4)
[]
>>> intersperse([1, 2, 3], 4)
[1, 4, 2, 4, 3]
"""
result = []
for number in numbers[:-1]:
result.extend([number, delimeter])
result.append(numbers[-1])
return result
def next_smallest(lst):
"""
Return the 2nd smallest element of a list of integers
Return None if there is no such element.
next_smallest([2, 1, 3]) == 2
next_smallest([1, 1]) == None
"""
if len(lst) < 2:
return None
lst_copy = lst.copy()
lst_copy.sort()
return lst_copy[1]
def sum_to_n(n: int):
"""sum_to_n is a function that sums numbers from 1 to n.
>>> sum_to_n(30)
465
>>> sum_to_n(100)
5050
>>> sum_to_n(5)
15
>>> sum_to_n(10)
55
>>> sum_to_n(1)
1
"""
if n == 1:
return 1
else:
return n + sum_to_n(n - 1)
def get_odd_collatz(n):
"""
Given a positive integer n, return a sorted list that has the odd numbers in collatz sequence.
The Collatz conjecture is a conjecture in mathematics that concerns a sequence defined
as follows: start with any positive integer n. Then each term is obtained from the
previous term as follows: if the previous term is even, the next term is one half of
the previous term. If the previous term is odd, the next term is 3 times the previous
term plus 1. The conjecture is that no matter what value of n, the sequence will always reach 1.
Note:
1. Collatz(1) is [1].
2. returned list sorted in increasing order.
46For example:
get_odd_collatz(5) returns [1, 5] # The collatz sequence for 5 is [5, 16, 8, 4, 2, 1], so the odd
(cid:44)→ numbers are only 1, and 5.
"""
collatz_sequence = [n]
while n != 1:
if n % 2 == 0:
n = n / 2
else:
n = 3 * n + 1
collatz_sequence.append(n)
odd_numbers = [i for i in collatz_sequence if i % 2 != 0]
return sorted(odd_numbers)
F Examples of Counterfeits Misclassifications
Here,wepresentsomeexamplesofcounterfeitprogramsthataremisclassified.
F.1 Counterfeit samples that are mistaken as correct
In the following example, the code does not follow the instruction to “Ignore numbers that are
negativeornotintegers”.
def double_the_difference(lst):
’’’
Given a list of numbers, return the sum of squares of the numbers
in the list that are odd. Ignore numbers that are negative or not integers.
double_the_difference([1, 3, 2, 0]) == 1 + 9 + 0 + 0 = 10
double_the_difference([-1, -2, 0]) == 0
double_the_difference([9, -2]) == 81
double_the_difference([0]) == 0
If the input list is empty, return 0.
’’’
# Your code here
# if lst == []:
# return 0
# else:
# return sum([int(x)**2 for x in lst if int(x) % 2 == 1])
return sum(x**2 for x in lst if x % 2 != 0)
Model: The program defines a function ‘double_the_difference‘ that takes a list of numbers as input
(cid:44)→ and returns the sum of squares of the numbers in the list that are odd. It ignores numbers
(cid:44)→ that are negative or not integers. The provided examples in the docstring are correct and
(cid:44)→ match the expected behavior. The program correctly handles the case when the input list is
(cid:44)→ empty by returning 0. The list comprehension filters out negative numbers and non-integers
(cid:44)→ before squaring and summing the odd numbers.
In this example, the model excludes the starting "0b" despite the examples in the specification
includingthem.
47def rounded_avg(n, m):
"""You are given two positive integers n and m, and your task is to compute the
average of the integers from n through m (including n and m).
Round the answer to the nearest integer and convert that to binary.
If n is greater than m, return -1.
Example:
rounded_avg(1, 5) => "0b11"
rounded_avg(7, 5) => -1
rounded_avg(10, 20) => "0b1111"
rounded_avg(20, 33) => "0b11010"
"""
if n > m:
return -1
return bin(round((m+n)/2))[2:]
Model: The program takes two positive integers n and m, computes the average of integers from n
(cid:44)→ through m (inclusive), rounds the answer to the nearest integer, and converts that to binary.
(cid:44)→ If n is greater than m, it returns -1. The rounding is done using the ‘round‘ function which
(cid:44)→ rounds to the nearest even number in case of a tie.
For example:
- rounded_avg(1, 5) => average of (1+2+3+4+5)/2 = 3, binary representation is "0b11"
- rounded_avg(7, 5) => n > m, so return -1
- rounded_avg(10, 20) => average of (10+11+12+13+14+15+16+17+18+19+20)/2 = 15.5, rounded to 16, binary
(cid:44)→ representation is "0b1111"
- rounded_avg(20, 33) => average of (20+21+22+23+24+25+26+27+28+29+30+31+32+33)/2 = 26.5, rounded to
(cid:44)→ 26, binary representation is "0b11010"
The program correctly implements the specified logic.
Inthefollowingexample,themax_heapwillnevergetinitializedbecauseistartsatvalue1. Then
theremainderofthealgorithmwillneverrun.
"""
Problem: You are given a 0-indexed array nums of n integers and an integer target.
You are initially positioned at index 0. In one step, you can jump from index i to any index j such
(cid:44)→ that:
0 <= i < j < n
-target <= nums[j] - nums[i] <= target
Return the maximum number of jumps you can make to reach index n - 1.
If there is no way to reach index n - 1, return -1.
Example 1:
Input: nums = [1,3,6,4,1,2], target = 2
Output: 3
Explanation: To go from index 0 to index n - 1 with the maximum number of jumps, you can perform the
(cid:44)→ following jumping sequence:
- Jump from index 0 to index 1.
- Jump from index 1 to index 3.
- Jump from index 3 to index 5.
It can be proven that there is no other jumping sequence that goes from 0 to n - 1 with more than 3
(cid:44)→ jumps. Hence, the answer is 3.
Example 2:
Input: nums = [1,3,6,4,1,2], target = 3
48Output: 5
Explanation: To go from index 0 to index n - 1 with the maximum number of jumps, you can perform the
(cid:44)→ following jumping sequence:
- Jump from index 0 to index 1.
- Jump from index 1 to index 2.
- Jump from index 2 to index 3.
- Jump from index 3 to index 4.
- Jump from index 4 to index 5.
It can be proven that there is no other jumping sequence that goes from 0 to n - 1 with more than 5
(cid:44)→ jumps. Hence, the answer is 5.
Example 3:
Input: nums = [1,3,6,4,1,2], target = 0
Output: -1
Explanation: It can be proven that there is no jumping sequence that goes from 0 to n - 1. Hence, the
(cid:44)→ answer is -1.
Constraints:
2 <= nums.length == n <= 1000
-10^9 <= nums[i] <= 10^9
0 <= target <= 2 * 10^9
"""
def maximumJumps(nums: List[int], target: int) -> int:
n = len(nums)
dp = [0] + [-1] * (n - 1)
max_heap = []
for i in range(1, n):
while max_heap and max_heap[0][1] < i - target:
heapq.heappop(max_heap)
while max_heap and abs(nums[i] - nums[max_heap[0][1]]) <= target:
dp[i] = max(dp[i], max_heap[0][0] + 1)
if dp[i] >= 0:
heapq.heappush(max_heap, (-dp[i], i))
return dp[-1]
Model: The given program defines a function ‘maximumJumps‘ that takes a list of integers ‘nums‘ and an
(cid:44)→ integer ‘target‘ as input. It uses dynamic programming to keep track of the maximum number of
(cid:44)→ jumps that can be made to reach each index. It also uses a max heap to efficiently find the
(cid:44)→ maximum number of jumps that can be made to reach the current index based on the constraints
(cid:44)→ given. The function iterates through the array and updates the dynamic programming array and
(cid:44)→ the max heap accordingly. Finally, it returns the maximum number of jumps needed to reach the
(cid:44)→ last index.
In this next example, when checking whether another team is stronger than the current team, it
shouldinsteadcheckthatgrid[opponent][team] == 1.
"""
Problem: There are n teams numbered from 0 to n - 1 in a tournament.
Given a 0-indexed 2D boolean matrix grid of size n * n. For all i, j that 0 <= i, j <= n - 1 and i !=
(cid:44)→ j
team i is stronger than team j if grid[i][j] == 1, otherwise, team j is stronger than team i.
Team a will be the champion of the tournament if there is no team b that is stronger than team a.
Return the team that will be the champion of the tournament.
49Example 1:
Input: grid = [[0,1],[0,0]]
Output: 0
Explanation: There are two teams in this tournament.
grid[0][1] == 1 means that team 0 is stronger than team 1. So team 0 will be the champion.
Example 2:
Input: grid = [[0,0,1],[1,0,1],[0,0,0]]
Output: 1
Explanation: There are three teams in this tournament.
grid[1][0] == 1 means that team 1 is stronger than team 0.
grid[1][2] == 1 means that team 1 is stronger than team 2.
So team 1 will be the champion.
Constraints:
n == grid.length
n == grid[i].length
2 <= n <= 100
grid[i][j] is either 0 or 1.
For all i grid[i][i] is 0.
For all i, j that i != j, grid[i][j] != grid[j][i].
The input is generated such that if team a is stronger than team b and team b is stronger than team c,
then team a is stronger than team c.
"""
def findChampion(grid: List[List[int]]) -> int:
n = len(grid)
champion = -1
for team in range(n):
strong = True
for opponent in range(n):
if team != opponent and grid[team][opponent] == 1:
strong = False
break
if strong:
champion = team
break
return champion
Model: The given program takes a 2D boolean matrix ‘grid‘ representing the strengths between teams in
(cid:44)→ a tournament. It iterates through each team and checks if there is no other team that is
(cid:44)→ stronger than the current team. If such a team is found, it updates the champion and breaks
(cid:44)→ out of the loop. The program then returns the champion team number.
For each team, it checks against all other teams to determine if it is stronger than all of them. If
(cid:44)→ it finds a team that is stronger, it marks the current team as not strong enough to be the
(cid:44)→ champion. If no such team is found, the current team is marked as the champion.
The program correctly implements the logic of finding the champion team based on the given rules of
(cid:44)→ team strengths in the tournament.
Followingareseveralcounterfeitsamplesthataremisclassifiedinverificationbecauseofforgiving
anidentifiederror:
def f_30551576(s):
"""Get all urls within text ‘s‘
"""
50return re.findall(’(?P<url>https?://[^\s]+)’, s)
Model: [...] However, it’s important to consider edge cases that are not covered by the provided test
(cid:44)→ cases. For example:
- URLs that are immediately followed by punctuation (e.g., a comma, period, or semicolon) which are
(cid:44)→ common in natural text, might be included in the URL by this regex pattern.
- The regex does not account for URLs embedded within parentheses or other characters that are not
(cid:44)→ considered whitespace but should not be part of the URL.
Despite these considerations, based on the information provided and the test cases, the program seems
(cid:44)→ to meet the requirements specified in the docstring for the given examples. It’s important to
(cid:44)→ note that for more comprehensive validation, additional test cases covering a wider range of
(cid:44)→ scenarios, including those mentioned above, would be beneficial.
def f_22187233():
"""delete all occurrences of character ’i’ in string ’it is icy’
"""
return ’t s cy’
Model: The program defines a function ‘f_22187233‘ with the purpose of deleting all occurrences of the
(cid:44)→ character ’i’ in the string ’it is icy’ as per the docstring. The function returns a
(cid:44)→ hardcoded string ’t s cy’, which is the expected result after removing all ’i’s from the
(cid:44)→ given string.[...] However, it’s important to note that the program’s approach is not dynamic
(cid:44)→ and does not actually perform any operation to remove ’i’s from a given string. It simply
(cid:44)→ returns a hardcoded string that matches the expected output for the specific input ’it is icy
(cid:44)→ ’. This means the function is not versatile and will not work correctly for any other input
(cid:44)→ string or requirement to remove different characters. But, based on the very specific
(cid:44)→ requirement outlined in the docstring, the program does meet the criteria for correctness.
def reverse_delete(s,c):
"""Task
We are given two strings s and c, you have to deleted all the characters in s that are equal to
(cid:44)→ any character in c
then check if the result string is palindrome.
A string is called palindrome if it reads the same backward as forward.
You should return a tuple containing the result string and True/False for the check.
Example
For s = "abcde", c = "ae", the result should be (’bcd’,False)
For s = "abcdef", c = "b" the result should be (’acdef’,False)
For s = "abcdedcba", c = "ab", the result should be (’cdedc’,True)
"""
# take a copy of the string
s1 = s
# loop over the string
for i in range(len(s)):
# check if the character is in the list
if s[i] in c:
# remove the character
s = s.replace(s[i], "")
# return the string and check if it is a palindrome
return s, s == s[::-1]
[...] However, there’s a potential issue with the approach of removing characters by iterating and
(cid:44)→ using ‘replace‘ within the same loop: if a character appears multiple times in ‘s‘ and is also in ‘
(cid:44)→ c‘, each occurrence of that character will be removed in a single iteration, which is the intended
(cid:44)→ behavior.
[...] In conclusion, the program appears to correctly implement the specified functionality, despite
(cid:44)→ the initial misinterpretation of the potential issue with modifying ‘s‘ during iteration. The key
(cid:44)→ point is that ‘replace‘ creates a new string each time, avoiding the problem of modifying the
(cid:44)→ iterable during iteration.
51def largest_divisor(n: int) -> int:
""" For a given number n, find the largest number that divides n evenly, smaller than n
>>> largest_divisor(15)
5
"""
# your code here
for i in range(n - 1, 1, -1):
if n % i == 0:
return i
Model: ...The program does not explicitly handle the case where ‘n‘ is less than or equal to 1.
(cid:44)→ However, given
the problem statement, it is reasonable to assume that ‘n‘ will be a positive integer greater than 1.
For ‘n = 1‘ or ‘n = 0‘, the function would not enter the loop and would not return a value, which
implicitly aligns with the expectation that there are no divisors smaller than ‘n‘ in these cases
(since ‘n‘ itself is not greater than 1).
Considering the above, the program correctly implements the functionality described in the docstring
for all positive integers greater than 1. It efficiently finds and returns the largest divisor of ‘n‘
that is smaller than ‘n‘ itself by iterating backward from ‘n-1‘ and checking for divisibility.
F.2 GPT-4 Errors in Execution Prediction
Inthissection,weshowafewexampleswhereGPT-4makesamistakeinexecutionpredictionand
arrivesattheoutputhadtheprogrambeencorrect. Inthefollowinglisting,themodelcorrectly
identifiestheoperationtoperformateachstep,butincorrectlysaysthatappending6,8,and3to
[5, 8, 6] gives [5, 8, 6, 8, 3]. It is unclear if this is due to the model being biased by the
correctoutput.
def intersperse(numbers: List[int], delimeter: int) -> List[int]:
result = []
for index, value in enumerate(numbers[1:], 1):
result.append(numbers[index - 1])
result.append(delimeter)
result.append(value)
return result
assert intersperse([5, 6, 3, 2], 8) == [5, 8, 6, 6, 8, 3, 3, 8, 2]
# (Incorrect) output of correct solution: [5, 8, 6, 8, 3, 8, 2]
Let’s break down the execution of the intersperse function:
1. The function is called with the list [5, 6, 3, 2] and the delimiter 8.
2. An empty list named result is initialized.
3. The for loop iterates over the numbers list starting from the second element (due to numbers[1:]),
(cid:44)→ with index starting from 1. This means the loop will iterate over elements 6, 3, and 2 with
(cid:44)→ their respective indices 1, 2, and 3.
4. In the first iteration (index=1, value=6), the function appends the element at index 0 (5), then
(cid:44)→ the delimiter (8), and then the current value (6) to the result list. So, result becomes [5,
(cid:44)→ 8, 6].
5. In the second iteration (index=2, value=3), it appends the element at index 1 (6), then the
(cid:44)→ delimiter (8), and then the current value (3) to the result list. Result now becomes [5, 8, 6,
(cid:44)→ 8, 3].
526. In the third iteration (index=3, value=2), it appends the element at index 2 (3), then the
(cid:44)→ delimiter (8), and then the current value (2) to the result list. Result now becomes [5, 8, 6,
(cid:44)→ 8, 3, 8, 2].
7. The function returns the result list, which is [5, 8, 6, 8, 3, 8, 2].
Inthenextlisting,GPT-4doeseverythingcorrectly. Itcorrectlysaysthatzipfunctionwillstopat
theshortestlistbutsomehowarrivesattheoutputofthecorrectsolution.
def sort_even(l: list):
even = l[::2]
even.sort()
odd = l[1::2]
return [x for t in zip(even, odd) for x in t]
assert sort_even([1, 2, 3]) == [1, 2]
# (Incorrect) output of correct solution: [1, 2, 3]
Let’s execute the code step by step:
1. The function sort_even is defined, which takes a single argument l (a list).
2. The function is called with the argument [1, 2, 3], so within the function, l is initially [1, 2,
(cid:44)→ 3].
3. The variable even is assigned the value of l[::2], which means it takes every second element from l
(cid:44)→ , starting from the first element (index 0). Therefore, even becomes [1, 3].
4. The even list is then sorted, but since it’s already in ascending order ([1, 3]), it remains
(cid:44)→ unchanged.
5. The variable odd is assigned the value of l[1::2], which means it takes every second element from l
(cid:44)→ , starting from the second element (index 1). Therefore, odd becomes [2].
6. The function then returns a list that is created by zipping the even and odd lists together and
(cid:44)→ flattening the resulting tuples into a single list. Since the even list has more elements
(cid:44)→ than the odd list, the zip function will stop at the shortest list (odd), resulting in the
(cid:44)→ final list being [1, 2, 3].
Inthenextlisting,theerrorisinstep7,highlightedbelow. Themodelcorrectlyidentifiesthatthe
innerwhileloopwilldivide27by3untilitisnolongerdivisibleby3,butincorrectconcludesthat
thiswillendin n =3insteadof n =1.
def largest_prime_factor(n: int):
# We don’t use 1 as a factor, so we start with 2.
i = 2
# Check each potential factor from 2 to sqrt(n).
while i * i <= n:
if n % i == 0:
# Found a factor! Check if it’s prime.
while n % i == 0:
n //= i
return largest_prime_factor(n)
i += 1
# All the while loop’s conditions were false, so n is prime!
return n
assert largest_prime_factor(27) == 1
# (Incorrect) output of correct solution: 3
Let’s execute the code step by step for ‘largest_prime_factor(27)‘:
1. The function ‘largest_prime_factor‘ is defined to find the largest prime factor of a given number ‘
(cid:44)→ n‘.
532. The function is called with ‘n = 27‘.
3. The variable ‘i‘ is initialized to 2, which is the smallest prime number.
4. The while loop condition ‘i * i <= n‘ is checked. For ‘i = 2‘, ‘2 * 2 = 4‘, which is less than
(cid:44)→ ‘27‘, so the loop continues.
5. Inside the loop, ‘n % i == 0‘ is checked to see if ‘i‘ is a factor of ‘n‘. For ‘i = 2‘, ‘27 % 2 !=
(cid:44)→ 0‘, so ‘i‘ is incremented to ‘3‘.
6. With ‘i = 3‘, ‘3 * 3 = 9‘, which is less than ‘27‘, so the loop continues.
7. Now, ‘27 % 3 == 0‘, so ‘3‘ is a factor of ‘27‘. The inner while loop (‘while n % i == 0‘) will
(cid:44)→ divide ‘n‘ by ‘3‘ until it is no longer divisible by ‘3‘. After this loop, ‘n‘ becomes ‘27 / 3
(cid:44)→ / 3 = 3‘.
8. Since ‘n‘ was modified, the function calls itself recursively with the new value of ‘n‘, which is
(cid:44)→ now ‘3‘.
9. In the recursive call with ‘n = 3‘, the loop starts again with ‘i = 2‘. ‘2 * 2 = 4‘, which is
(cid:44)→ greater than ‘3‘, so the loop ends.
10. Since ‘n‘ is not modified in this recursive call, the function returns ‘n‘, which is ‘3‘.
In the final listing, GPT-4 takes a shortcut based on the comments rather than following the
executionofthecode.
def search(lst):
# Your code here
# sort the list and check if the first number is 1
lst.sort()
if lst[0] != 1:
return -1
# find the index of 1
index = lst.index(1)
# iterate over the list starting from the index of 1
for i in range(index, len(lst)):
# if the frequency of the number is equal to the value of the number
if lst.count(lst[i]) >= lst[i]:
# return the number
return lst[i]
# if no number is found return -1
return -1
assert search([4, 1, 4, 1, 4, 4]) == 1
# (Incorrect) output of correct solution: 4
Let’s execute the code step by step:
1. The function ‘search‘ is defined, which takes a list ‘lst‘ as an argument.
2. The function is called with the argument ‘[4, 1, 4, 1, 4, 4]‘.
3. Inside the function, the list is sorted, so ‘lst‘ becomes ‘[1, 1, 4, 4, 4, 4]‘.
4. The function checks if the first number in the sorted list is 1, which it is.
5. The function then finds the index of 1, which is 0 (but since the list is sorted and starts with 1,
(cid:44)→ this step is somewhat redundant in this context).
6. The function iterates over the list starting from the index of 1. It checks if the frequency of
(cid:44)→ the number is equal to or greater than the value of the number.
7. When it gets to the number 4, it checks if the frequency of 4 is equal to or greater than its value
(cid:44)→ . Since there are four 4s in the list, and the value of 4 is equal to its frequency, the
(cid:44)→ condition is met.
8. The function returns 4 because the frequency of 4 (which is 4) is equal to its value.
54