Training Dynamics of Multi-Head Softmax Attention
for In-Context Learning: Emergence, Convergence,
and Optimality
Siyu Chen Heejune Sheen Tianhao Wang Zhuoran Yang
Department of Statistics and Data Science, Yale University
{siyu.chen.sc3226, heejune.sheen, tianhao.wang, zhuoran.yang}@yale.edu
Abstract
We study the dynamics of gradient flow for training a multi-head softmax attention model for
in-context learning of multi-task linear regression. We establish the global convergence of gradi-
ent flow under suitable choices of initialization. In addition, we prove that an interesting “task
allocation” phenomenon emerges during the gradient flow dynamics, where each attention head
focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient
flow dynamics can be split into three phases — a warm-up phase where the loss decreases rather
slowly and the attention heads gradually build up their inclination towards individual tasks, an
emergence phase where each head selects a single task and the loss rapidly decreases, and a con-
vergence phase where the attention parameters converge to a limit. Furthermore, we prove the
optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par
with the best possible multi-head softmax attention model up to a constant factor. Our analysis
also delineates a strict separation in terms of the prediction accuracy of ICL between single-head
and multi-head attention models. The key technique for our convergence analysis is to map the
gradient flow dynamics in the parameter space to a set of ordinary differential equations in the
spectraldomain,wheretherelativemagnitudesofthesemi-singularvaluesoftheattentionweights
determines task allocation. To our best knowledge, our work provides the first convergence result
for the multi-head softmax attention model.
1 Introduction
The transformer architecture (Vaswani et al., 2017) is the backbone of many foundational models
in artificial intelligence (AI), demonstrating striking empirical success in domains including natural
language processing (Devlin et al., 2018), computer vision (Dosovitskiy et al., 2020), and rein-
forcement learning (Chen et al., 2021). At a high level, a transformer is a sequence-to-sequence
model that processes an input sequence of tokens and produces an output sequence of tokens. An
autoregressive transformer generates the output in an autoregressive manner, i.e., each new token
is generated by taking all previously generated tokens as the input of the transformer model. Au-
toregressive transformer architecture has emerged as the mainstream paradigm of large language
models (LLMs), with examples such as GPT (Radford et al., 2019; Brown et al., 2020; Achiam
et al., 2023), Claude (Anthropic, 2023), and Gemini (Team et al., 2023).
These LLMs are trained on internet-scale data across a wide range of topics and languages.
A distinguishing feature of these models is their ability to learn from a few demonstrations of
1
4202
beF
92
]GL.sc[
1v24491.2042:viXraa new task that does appear in the training data, a phenomenon known as In-Context Learning
(ICL)(Brownetal.,2020). Thatis,withoutupdatingthemodelparameters,byfeedingafewinput-
output examples of a task and querying a new input, LLMs are able to give the correct output.
The ICL ability serves as the foundation for building more sophisticated prompting methods that
uses LLMs for solving complicated problems (Huang and Chang, 2022).
While the ICL capability of transformers has been empirically demonstrated and applied, the-
oretical understanding of this phenomenon is still in its infancy. In particular, we lack a compre-
hensive understanding of a key component of the transformer architecture, the attention mecha-
nism (Vaswani et al., 2017), and how it is related to the ICL ability. In the attention mechanism,
multiple attention heads attend to tokens in the input sequence by assigning attention weights
and aggregates the values according to the weights from all tokens to form the output features.
These attention weights are probabilities given by a softmax function and thus the resulting model
is referred to as Multi-head Softmax Attention (MS-Attn). Existing works have investigated how
single-head attention-based models can be trained for ICL (Zhang et al., 2023a; Huang et al., 2023;
KimandSuzuki,2024), butthemulti-headcaseisstillunder-explored, thoughithasbeenobserved
that multi-head attention outperforms single-head attention for ICL (Cui et al., 2024; Xing et al.,
2024).
In this work, we aim to make a step towards understanding the role MS-Attn played in the
emergence of ICL ability. To this end, we focus on a simple but fundamental setting where trans-
former is a one-layer multi-head softmax attention model trained for the ICL task of multi-task
linear regression. In particular, the MS-Attn model is asked to see L covariate-response examples,
{x ,y } , sampled from a randomly sampled noisy multi-task linear regression problem, i.e.,
l l l∈[L]
y = G⊤x +ε , and predict the regression target G⊤q of a new covariate q, referred to as a query.
l l l
Here, G ∈ Rdy×d is a random matrix sampled randomly from a distribution and ε is a random
l
noise. Moreover, we further assume that G admits a multi-task structure in the sense that it can
be transformed by two fixed orthogonal matrices Φ and Ψ into a block diagonal matrix, where each
block corresponds to the signal of an individual task. In other words, upon orthogonal transfor-
mations, the multi-task linear regression is reduced to a set of independent linear models. We are
considering sufficiently large L and d while the dimension-to-sequence length ratio d/L = Θ(1).
To perform ICL, the MS-Attn model is first trained on a variety of randomly sampled instances of
multi-task ICL data and then evaluated on a random new instance.
To understand how the attention mechanism enables the ICL ability, we delve into the gradient
flow dynamics of training the MS-Attn model at a population level. This corresponds to the setting
where the number of instances of multi-task task linear regression goes to infinity. Under such a
setting, we aim to address the following questions:
(a) Does gradient flow dynamics of ICL on multi-task linear data converge to a limit?
(b) Does the learned MS-Attn model exhibit ICL ability with high prediction accuracy?
(c) Does the multi-head structure offer any advantage over the single-head version?
We provide affirmative answers to all these three questions. In particular, using a symmetric
initializationschemewherethekeyandqueryweightsarethesame, weprovethatthegradientflow
with respect to the population loss converges to a limit. In addition, we characterize the prediction
error of the limiting MS-Attn model explicitly in terms of the signal-to-noise ratio of the linear
model and the the ratio d/L under certain condition, e.g., both d and L are large. Moreover, such
2an error decays to zero when d/L decreases. We also characterize the minimal error attained by the
class of MS-Attn models and prove that the model founded by gradient flow is on par with the best
model up to a constant factor. Finally, we demonstrate the superiority of multi-head structure in
two aspects. First, the multi-head structure exhibits a “task allocation” phenomenon, where each
attention head focuses on solving an individual and non-overlapping task. Second, there exists a
strict separation between single-head and multi-head models. In particular, the minimal prediction
error achieved by the best single-head model is strictly larger than that of the MS-Attn model
learned by gradient flow by a factor of H, where H represents the number of heads.
Main Contributions. Our main contributions are summarized as follows:
1. First, we establish the convergence of gradient flow for a one-layer multi-head softmax atten-
tion model for ICL (Theorem 3.3). A key technical ingredient is to reduce the gradient flow
dynamics in the parameter space to the corresponding spectral dynamics in the eigenspace of
the data features, which allows a more tractable analysis (Lemma 3.2). Our analysis captures
also fine-grained properties of the dynamics like the phase transition behavior that leads to
the sudden emergence of ICL ability.
2. We prove that the convergence point of gradient flow admits the following properties: each
attention head focuses on solving an individual task without cross-head interference and acts
as the optimal single-head attention model for that task (Lemma 4.1 and Theorem 4.2). In
addition, we show that the model found by gradient flow achieves minimal ICL loss up to a
constant factor when the number of heads matches the number of tasks (Theorem 4.4).
3. We show that the multi-head model strictly outperforms the single-head model by a factor
of H when the number of tasks matches the number of heads. This is demonstrated by
comparing the multi-head model found by the gradient flow to the optimal single-head model
in terms of the ICL loss.
4. As a byproduct, we identify an interesting “attention allocation” phenomenon for a single-
headsoftmaxattentionheadtooptimallysolvemultipletasks(Theorem4.2). Asanextension,
we make a comparison between linear and softmax attention in Section 5. Moreover, we show
thatthemodellearnedbygradientflowgeneralizestonewdatawithsequencelengthsdiffering
from the training data, while we also characterize its limitation in solving nonlinear tasks.
To our best knowledge, our work is the first to provide a comprehensive analysis of the training
dynamics of a single-layer multi-head softmax attention model and the properties of the model
trainedbygradientflow. Ouranalysischaracterizes, inaunifiedmanner, therichinterplaybetween
different design aspects of the attention mechanism and ICL task-specific properties.
1.1 Our Approach: Tracking the Spectral Dynamics
The analysis of the dynamics is challenging due to the symmetries of the loss landscape (see related
discussion in §1.2), as well as the nonlinearity introduced by the softmax operation.
1. We address the first challenge by properly aligning the eigenspaces of the weight matrices
with those of the context data features under the condition of Decomposable Weights (Def-
inition 3.1). This gives rise to a crucial simplification that allows us to track the spectral
dynamics of the attention weights and output weights during the training process.
3Figure 1: Illustration of the training loss and dynamics of the weights of the MS-Attn. The
dynamics undergo three phases: warm-up, emergence, and convergence. Here, we set H = 3
heads, I = 3 homogeneous tasks with signal strength λ = 1 and no noise, dimension d = 30
and context sequence length L = 100. The top two plots show the dynamics of the eigenvalues
of two combined weight matrices, ω(h) for W(h) and µ(h) for U(h) for all h ∈ [H]. The third
X Y
(h)
plot shows the training loss and the last plot shows the value of ω upon convergence. Here,
i
the optimal head for task i is h⋆ = i for i ∈ [I] by initialization.
i
2. To address the second challenge, we perform careful moment analyses on the attention prob-
ability vectors produced by the softmax operation. Based on this, we control the nonlinear
effects and prune higher-order terms to extract the key factors driving the learning process.
This is essential for both the dynamic analysis and the establishment of optimality bounds.
Combining these two ingredients paves the way for understanding the attention layer’s behavior
both during the training process and at the convergence point. The following informal theorem
summarizes our main result on the dynamics of the multi-head attention model.
Theorem 1.1 (Gradient flow for MS-Attn, informal). Under proper initialization of the gradient
flow, assume that the number of heads is larger than the number of tasks, then the following holds:
(i) (Warm-up) There exists a threshold time T > 0, before which the loss value decreases slowly,
0
and each attention head gradually adjusts its weights to select one individual task.
(ii) (Emergence) For a brief period around T , the loss undergoes a sudden decrease, each atten-
0
tion head rapidly becomes focused on a single task, and cross-head interference vanishes.
4(iii) (Convergence) Finally, gradient flow converges to a point where each task is predominantly
handled by a single attention head, in the sense that the output from this head dominates the
output of the entire model for this task.
In complement to the dynamics analysis, we further study the optimality property of the con-
vergence point of gradient flow.
(i) We first consider using a single-head softmax attention model to optimally solve multi-task
linear regression. We show the lower bound of the optimal ICL loss and construct a group of
attention weights to achieve the lower bound. When specialized to a single task, we directly
conclude that the optimal attention weights are indeed the same as the convergence point
of the gradient flow dynamics. The challenge here is the nonconvexity of the landscape
induced by the softmax function, and our main approach is to find the optimal working
regime of the softmax attention and derive a good nonlinear approximation to the attention’s
behavior in this regime. As a byproduct, we also show that the optimal attention weights are
decomposable in the sense of Definition 3.1, which justifies our simplification of the gradient
flow dynamics to the spectral dynamics.
(ii) For the multi-head case, we consider a subclass of the MS-Attn model bearing a certain
symmetricstructurecalledtheequiangularweights(Definition4.3). Undertaskhomogeneity,
i.e., all tasks having the same Signal-to-Noise Ratio (SNR) and dimension, we show using a
similar technique that the convergence point of the gradient flow is indeed optimal. The
analysis demonstrates an additional characterization of the cross-head interference compared
with the single-head case.
Organization of the paper. The rest of the paper is organized as follows: We finish the intro-
duction by discussing related works. In Section 2, we introduce the one-layer multi-head softmax
attention model and the ICL setting of multi-task linear regression. In Section 3, we present gra-
dient flow dynamics and characterize the emergence and convergence behavior of the attention
weights during the training process. In Section 4, we investigate the optimality of the trained
model. In Section 5, we discuss extensions of our main results. Detailed proofs and auxiliary
results are deferred to the appendix.
1.2 Related Work
We briefly review additional related work on ICL and learning properties of transformers in other
settings. First, as suggested by empirical evidence, various explicit weight constructions have been
proposed to show that transformers can do ICL by emulating specific algorithms such as gradient
descent and its variants (Akyu¨rek et al., 2023; Von Oswald et al., 2023; Bai et al., 2023; Fu et al.,
2023). Itisfurthertheoreticallyverifiedvialandscapeanalysisthattheglobalminimizer(orcertain
critical points) of the ICL loss corresponds to a certain adaptive version of gradient descent (Ahn
et al., 2023; Mahankali et al., 2023). Moreover, convergence analyses have also been proposed by
Zhang et al. (2023a); Huang et al. (2023); Kim and Suzuki (2024); Nichani et al. (2024) under
different models and data assumptions. Nonetheless, these convergence analyses are tailored to
single-head attention models and require simplifications of the model such as combining the key
and query matrices into a single weight matrix. Though not changing the model’s expressiveness,
such simplifications make the loss landscape more amenable to analysis by removing the rotational
5symmetry of the attention weights1. Also, note that the permutation symmetry between multiple
heads further complicates the loss landscape, and so far there is no convergence analysis for multi-
head attention models for ICL.
The statistical complexity of transformers for ICL of linear functions has been characterized
by Wu et al. (2023), and Cheng et al. (2023); Guo et al. (2023); Collins et al. (2024) investigated
ICL beyond the simple linear functions. In particular, Collins et al. (2024); Edelman et al. (2024);
Makkuva et al. (2024) studied the ICL capability of transformers when data is drawn from Markov
chains. There are also works explaining how transformers perform in-context learning from the
Bayesian perspective (Xie et al., 2021; Mu¨ller et al., 2021; Zhang et al., 2022, 2023b; Ahuja et al.,
2023; Jeon et al., 2024). Transformers’ capability of in-context decision making has been explored
by Lin et al. (2023); Sinii et al. (2023). See also Li et al. (2023a); Dai et al. (2022); Ravent´os
et al. (2023) for other related results on ICL. Existing works have also studied the use of multiple
attention heads from different perspectives (An et al., 2020; Mahdavi et al., 2023). Beyond the case
of ICL, there have been recent advances in understanding the learning properties of transformers
in other settings (Edelman et al., 2022; Li et al., 2023b; Jelassi et al., 2022; Sanford et al., 2023;
Giannou et al., 2023; Liu et al., 2022; Tarzanagh et al., 2023a,b; Tian et al., 2023b,a; Song and
Zhong, 2023; Deora et al., 2023; Chen and Li, 2024). We do not discuss these works in detail here
since they are out of the scope of the current paper.
2 Preliminaries
We first introduce the notation conventions used throughout the paper. We use uppercase letters
like A and B to denote matrices and lowercase letters like u and v for column vectors. For any
positive integer n, we denote [n] := {1,...,n}. We denote by span(M) the column space of matrix
M. For two matrices A and B (not necessarily squared), we write A ≃ B if they share the same
singular vector spaces, i.e., A = UΣV⊤ and B = UΛV⊤ for some orthogonal matrices U and
V and diagonal matrices Σ and Λ. For any vector v ∈ Rd, we define the softmax operation as
softmax(v) := (ev1/(cid:80)d evi,...,ev d/(cid:80)d evi)⊤. We denote by ⊙ the element-wise Hadamard
i=1 i=1
product. Let N be the set of non-negative integers.
Next, we introduce the one-layer multi-head softmax attention model in Section 2.1 and the
multi-task linear regression problem for ICL in Section 2.2.
2.1 One-Layer Multi-Head Softmax Attention Model
We consider a MS-Attn model with H attention heads and context length L, defined as follows:
Let D be the input dimension, d be the output dimension, and d be the embedding dimension.
y e
Throughout the paper, we assume d ≥ d, where d = D−d . For each attention head h ∈ [H], let
e y
O(h) ∈ Rdy×de andV(h),K(h),Q(h) ∈ Rde×D betheoutputprojection,value,key,andqueryweights,
respectively. We let Θ = {O(h),V(h),K(h),Q(h)} denote the parameters of the MS-Attn model.
h∈[H]
Then given an input matrix Z ∈ RD×L and a query vector z ∈ RD, the output yp of MS-Attn is
q q
yp = MS-Attn(Z,z ;Θ) :=
(cid:88)H
O(h)V(h)Z
·softmax(cid:32) Z⊤K( √h)⊤ Q(h)z q(cid:33)
∈ Rdy. (2.1)
q q
d
e
h=1
1Here we are referring to the fact that K⊤Q=(OK)⊤(OQ) for any orthogonal matrix O.
6Following from (2.1), given the parameter Θ, for each head h ∈ [H], we define the attention score
vector s(h) ∈ RL and the corresponding attention probability vector p(h) ∈ RL as
Z⊤K(h)⊤ Q(h)z
s(h) = √ q ∈ RL, p(h) = softmax(s(h)) ∈ RL. (2.2)
d
e
Intuitively, s(h) measures the similarity between the query vector and each column of Z, and p(h) is
the probability distribution over [L] that is induced by s(h). Such a distribution is used to weight
the value head V(h)Z ∈ Rde×L to get a vector V(h)Zp(h) that lies in the embedded space Rde. The
output yp
q
is obtained by mapping such an embedding to the output space Rdy by a linear map
O(h). That is, we can equivalently write (2.1) as yp = (cid:80)H O(h)V(h)Zp(h). To further simplify the
q h=1
notation, we define the combined output weight U(h) ∈ Rdy×D and attention weight W(h) ∈ RD×D:
K(h)⊤Q(h)
U(h) := O(h)V(h), W(h) := √ for each h ∈ [H]. (2.3)
d
e
Throughout the paper, we will consider the query vector z with the last d coordinates being
q y
zero, i.e., z = [q⊤,0,...,0]⊤ where q ∈ Rd. The output yp can be viewed as the lower right d ×1
q q y
block of the output of the standard multi-head softmax attention architecture with input matrix
[Z,z ] ∈ RD×(L+1). We remark that the residual connection is omitted in (2.1) since it does not
q
affect the output, and we do not consider any attention mask as there is only one single layer.
2.2 In-Context Learning of Multi-Task Linear Regression
We consider a data structure where each input token comprises a covariate with dimension d and
a label with dimension d such that D = d+d . The inputted Z and z can be decomposed as
y y q
(cid:20) (cid:21) (cid:20) (cid:21)
x x x q
1 2 L
Z = , z = .
y y y q 0
1 2 L
Such input format is standard in recent literature about Transformers and ICL (Garg et al., 2022;
Akyu¨rek et al., 2023; Von Oswald et al., 2023; Ahn et al., 2023; Zhang et al., 2023a), but we remark
that here we allow d > 1, in contrast to the single-task case where d = 1 considered in previous
y y
works. In the sequel, we denote by X = [x 1,...,x L] ∈ Rd×L and Y = [y 1,...,y L] ∈ Rdy×L. For the
ICL, we consider a multi-task linear regression task described by the following data assumption.
Assumption2.1(Multi-TaskICLData). Everyin-contextsample(Z,z )isindependentlysampled
q
according to the distribution described as follows: First, we assume the covariate vectors and the
i.i.d.
query vector to be distributed as x ,...,x ∼ N(0,I ) and q ∼ N(0,I ). Next, for a random
1 L d d
coefficient matrix G ∈ Rd×dy, each response vector is given by y = G⊤x +ε for l ∈ [L] where
l l l
the noise ε ,...,ε i. ∼i.d. N(0,σ2I ). Note that the coefficient matrix G is shared within the context
1 L dy
sequence Z. Then the goal is to predict the true response vector y = G⊤q given the context Z and
q
the query z . To this end, we assume G to be independent of both the covariate vectors {x }L and
q l l=1
the noise {ε }L , and moreover, we assume that G admits a multi-task structure:
l l=1
 
g 0 ··· 0
1
 0 g 2 ··· 0 
G = d−1/2·Φ· 

. .
.
. .
.
... . .
.
  ·Ψ⊤, (2.4)
0 0 ··· g
I
7where Φ ∈ Rd×d and Ψ ∈ Rdy×dy are two fixed orthogonal matrices, and corresponding to each task
i ∈ [I], the random vector g
i
∈ Rdi with dimension d
i
satisfies E[g i] = 0 and Cov[g i] = λ iI
di
with λ
i
being the signal strength for each task i ∈ [I]. Here, we restrict I = d for simplicity. In addition,
y
d−1/2 is the normalization factor which ensures that E[∥y ∥2] = 1.
q 2
The above decomposition of G breaks down the ICL problem into I components, and inferring
the correct response requires simultaneously estimating all I tasks. Note that we allow G to be
supported within some subspace. Here we only consider cross-task differences while assuming
homogeneous signal strength within each task for ease of analysis. We define the single sample
Signal-to-Noise Ratio (SNR) for task i as SNR :=λ d /(dσ2), and also ϕ := 1 + SNR−1. We
i i i i i
define J = {d +···+d +1,··· ,d +···+d } as the set of indices for task i. Then {J }
i 1 i−1 1 i i i∈[I]
forms a partition of [d]. Throughout the paper, we consider sufficiently large context length L and
dimension d, and we assume that the ratios d/L = Θ(1) and d /d = Θ(1) for all i ∈ [I].
i
Assumption 2.2. For a constant C > 0, it holds that d/L ∈ (C,1/C) and d /d > C for all i ∈ [I].
i
Before we proceed, we first introduce V(h) ,K(h) ,Q(h) ∈ Rde×d and V(h) ,K(h) ,Q(h) ∈ Rde×dy as
X X X Y Y Y
the splits of V(h),K(h),Q(h) with respect to the X and Y parts as shown in Figure 2. We split the
combined output weights by writing
U(h)
=
O(h)V(h)
as the left d ×d block and
U(h)
=
O(h)V(h)
X X y Y Y
as the right d ×d block of U(h), respectively. We also split the combined attention weights by
y y
(h) (h)⊤ (h) √ (h) (h)⊤ (h) √
packing W = K Q / d as the top left d × d block and W = K Q / d as the
X X X e Y Y X e
bottom left d ×d block of W(h).
y
(cid:34) (cid:35)
(cid:104) (cid:105) W(h) ⋆
U(h) = U(h) U(h) , W(h) = X . (2.5)
X Y W(h) ⋆
Y
The splitting described above is visualized in Figure 2.
Gradient Flow. We consider a pretraining process with gradient flow on the parameters Θ =
{O(h),V(h),K(h),Q(h)} to minimize the following population mean-squared error:
h∈[H]
L(Θ) = E[ℓ(yp ,y )], where ℓ(yp ,y ) = ∥yp −y ∥2/2, (2.6)
q q q q q q 2
and the expectation is taken over the distribution over (Z,z ) in Assumption 2.1. With the pa-
q
rameterization of the MS-Attn in (2.1) and the loss function in (2.6), one can derive the gradient
flow dynamics for parameters Θ = {O(h),V(h),K(h),Q(h)} by moving Θ along the direction of
h∈[H]
the negative gradient of the mean squared loss, i.e., ∂ Θ = −∇ L(Θ). By a direct calculation, we
t Θ
have the following dynamics2:
∂ O(h) = −B(h)V(h)⊤ , ∂ V(h) = −O(h)⊤ B(h),
t t
(2.7)
∂ K(h) = −d−1/2Q(h)A(h)⊤ , ∂ Q(h) = −d−1/2K(h)A(h),
t e t e
where A(h) ∈ RD×D and B(h) ∈ Rdy×D are defined respectively as
(cid:20) (cid:18) H (cid:19) (cid:21)
A(h) = E ZP(h)⊤ Z⊤U(h)⊤ (cid:88) U(h′)Zp(h′)−y z⊤ , (2.8)
q q
h′=1
(cid:20)(cid:18) (cid:19) (cid:21)
B(h) = E (cid:88)H U(h′)Zp(h′)−y p(h)⊤ Z⊤ , (2.9)
q
h′=1
2Here we omit the time dependence of the weights for simplicity.
8Figure 2: Illustration of the MS-Attn with H heads, embedding dimension d , and sequence
e
length L. Weights (V(h),K(h),Q(h)) can be split into the X and Y parts. The combined
weights (U(h),W(h)) are also split into (U(h) ,U(h) ) and (W(h) ,W(h) ). Under the decompos-
X Y X Y
(h) (h)
ability assumption (W = 0, U = 0), the attention scores only depend on the X part, and
Y X
the output is an aggregation of the Y part. Although we introduce the concept of combined
weights, it is important to note that the gradient flow operates on the individual weights.
where we have an L×L matrix (P(h)) = ∂p(h) /∂s(h) and in the case of softmax attention, it
l,m l m
takes the form of P(h) = diag(p(h))−p(h)p(h)⊤ .
3 Dynamics of Gradient Flow: Emergence and Convergence
In this section, we present our main results on the gradient flow dynamics, stated previously in
the informal Theorem 1.1. We first introduce in Section 3.1 the specific set of weights that we will
consider. Then we describe the analysis and state the full results in Section 3.2.
3.1 Decomposable Weights
We introduce the concept of decomposable weights, a key property that will be preserved along
gradient flow and will be used for analyzing the induced dynamics in the eigenvalue space.
Definition 3.1 (Decomposable Weights). For orthogonal matrices Φ ∈ Rd×d and Ψ ∈ Rdy×dy,
we say the weights of the MS-Attn are decomposable with respect to (Φ,Ψ) if for all h ∈ [H], the
following three conditions hold:
(i) (Orthogonality) For the matrices U(h) and W(h) defined in (2.5), we have U(h) = W(h) = 0.
X Y
Moreover, the column subspaces (of Rde) spanned by K(h) and K(h) are orthogonal, and the
X Y
(h) (h) (h) (h)
column spaces spanned by V and V are orthogonal. That is, span(K ) ⊥ span(K ),
X Y X Y
(h) (h)
and span(V ) ⊥ span(V ).
X Y
(h) (h)
(ii) (SimultaneousDiagonolizability)WehaveK ≃ Q withthesamerighteigenvectormatrix
X X
Φ and V(h) ≃ O(h)⊤ with the same right eigenvector matrix Ψ. That is, there exists an
Y
orthogonal matrix M ∈ Rde×de such that
M⊤K(h)
Φ =
diag(cid:0) σ(K(h) )(cid:1)
,
M⊤Q(h)
Φ =
diag(cid:0) σ(Q(h) )(cid:1)
.
X X X X
9Here σ(K(h) ),σ(Q(h) ) ∈ Rd are the d semi-singular values3 of K(h) and Q(h) respectively, and
X X X X
we let diag(σ(K(h) )) to denote the diagonal matrix in Rde×d whose (j,j)-th entry is given by
X
(h) (h) (h)
σ(K ) , the j-th entry of σ(K ), ∀j ∈ [d]. We define diag(σ(Q )) similarly. Besides,
X j X X
there exists an orthogonal matrix N ∈ Rde×de such that
N⊤V(h)
Ψ =
diag(cid:0) σ(V(h) )(cid:1)
,
N⊤O(h)⊤
Ψ =
diag(cid:0) σ(O(h))(cid:1)
,
Y Y
where σ(V Y(h) ),σ(O(h)) ∈ Rdy are the d
y
semi-singular values of V Y(h) and O(h) respectively.
Here diag(σ(V(h) )) and diag(σ(O(h))) are diagonal matrices in Rde×dy defined similarly.
Y
(iii) (Task-wise Homogeneity) Note that σ(K(h) ) and σ(Q(h) ) are vectors in Rd and that [d] is
X X
partitioned into I disjoint sets J ,...,J . We require that the semi-singular values are the
1 I
same within each task. That is, if j,j′ ∈ J for a same task i, then we have
i
(h) (h) (h) (h)
σ(Q ) = σ(Q ) , σ(K ) = σ(K ) .
X j X j′ X j X j′
(h) (h)
Definition 3.1(i) asserts that U and W are zero. By (2.1) and (2.2), since the attention
X Y
scores are computed by X⊤W q and the output is given by U Yq, this condition implies that the
X Y
attention probability is only a function of the covariate and the query, and the output is just an
aggregation of Y. This property further implies that the attention probability is independent of
the noise ϵ and the coefficient G, which enables us to simplify gradient flow dynamics. Moreover,
(h) (h)
Definition 3.1(i) requires that the column spaces spanned by K and K are orthogonal. Similar
X Y
(h) (h)
property holds for V and V . As we will see in Appendix C.3, orthogonality of these subspaces
X Y
(h) (h)
ensures that U and W remains zero through the course of gradient flow dynamics.
X Y
In addition, Definition 3.1(ii) suggests that the split weight matrices are simultaneously diago-
nalizable and that the right eigenvectors are aligned with task-specific directions given by (Φ,Ψ).
In particular, let
ω(h) = σ(K(h) )⊙σ(Q(h) ), µ(h) = σ(O(h))⊙σ(V(h) ), (3.1)
X X Y
which are vectors in Rd and Rdy respectively. Then we have W(h) = Φdiag(ω(h))Φ⊤ and U(h) =
X Y
Ψdiag(µ(h))Ψ⊤. That is, W(h) and U(h) are symmetric matrices and can be diagonalized by Φ and
X Y
Ψ respectively , and the eigenvalues are given by ω(h) and µ(h) respectively.
Furthermore, Definition 3.1(iii) is a natural assumption given that within task i’s support J ,
i
both g and X are isotropic random vectors under our data model. That is, the mean is zero and
i (i)
covariance is proportional to the identity matrix. This condition implies that ω(h) defined in (3.1)
should also satisfy the same structure. Here, X is the submatrix of X containing only the rows
(i)
corresponding to task i’s support J .
i
Finally,weremarkthatthefamilyofdecomposableweightsseemsabitrestrictive. Nevertheless,
we will justify this restriction by showing that the minimal ICL loss is approximately attained
by decomposable weights in Section 4 (see the discussion below Theorem 4.2). Notably, letting
Q(h) ,K(h) ,V(h) ,O(h) be diagonal matrices (but not necessarily squared) yields a special case of
X X Y
decomposable weights, and any decomposable weights can be transformed to this special case
3Thedifferencebetweensemi-singularvaluesandstandardsingularvaluesisthatweallowsemi-singularvaluesto
be negative.
10by rotation. Another key feature of decomposable weights is that, when the initial weights are
decomposable, such a structure is preserved through the course of gradient flow dynamics. This is
shown in the lemma below.
Lemma 3.2 (Preservation of Decomposibility along Gradient Flow). Under Assumption 2.1, sup-
pose the initialization of gradient flow is decomposable with respect to (Φ,Ψ) in the sense of Defi-
nition 3.1. Then the decomposability is preserved along the gradient flow trajectory. Moreover, the
semi-singular values of the weight matrices
O(h),V(h) ,K(h) ,Q(h)
for h ∈ [H] satisfy
Y X X
∂
σ(K(h)
) =
−d−1/2σ(Q(h) )⊙σ(A(h)⊤
), ∂
σ(Q(h)
) =
−d−1/2σ(K(h) )⊙σ(A(h)
),
t X e X XX t X e X XX
∂ σ(O(h)) = −σ(B(h) )⊙σ(V(h)⊤ ), ∂ σ(V(h) ) = −σ(O(h)⊤ )⊙σ(B(h) ),
t Y Y t Y Y
where A(h) is the top left d×d block of A(h) and B(h) is the right d ×d block of B(h).
XX Y y y
Whentheweightsareinitializedtobedecomposable,thegradientflowdynamicsbecomesimpler
as described in Lemma 3.2. In particular, this lemma shows that the weight matrices remains
decomposable with the same orthogonal matrices (Φ,Ψ). As a result, we only need to track the
evolution os the semi-singular values of the weight matrices, which enables us to focus on the
gradient flow dynamics in the spectral domain.
3.2 Analysis of Gradient Flow Dynamics
We proceed to give a high-level overview of our analysis of the gradient flow dynamics. Here we
focus on the dominant part of the gradient flow dynamics to illustrate the main idea, and the
complete analysis involving the higher order terms is given in Appendix C.2 and Appendix D.
When Definition 3.1 is satisfied, we define ω(h) ∈ RI to be the vector where each ω(h) is the
i
average value of the entries of ω(h) ∈ Rd corresponding to the i-th task in the decomposition of G.
(h) (h)
That is, ω is equal to any ω with j ∈ J . If the weights are decomposable, then the output is
i j i
only a function of the data, ω := {ω(h)} , and µ := {µ(h)} . Recall that d = I and thus
h∈[H] h∈[H] y
µ(h) ∈ Rdy is also a vector in RI. By Definition 3.1(iii) and Lemma 3.2, it suffices to focus on ω(h)
and µ(h) when the weights are initialized to be decomposable.
√
We assume that at initialization, σ(Q(h) ) = σ(K(h) ) = ω 1 ,σ(O(h)) = σ(V(h) ) = (µ(h) )−1/2,
X X 0 d Y 0
(h)
where ω > 0 is a sufficiently small constant and µ is a vector of positive and sufficiently
0 0
small entries. We thoroughly analyze the signal and interference components of the gradient flow
dynamics and observe three phases: warm-up, emergence, and convergence. Specifically, for each
task i, we analyze the dynamics of the parameters of the optimal head, (ω⋆,µ⋆), as well as those
i i
of the non-optimal heads (ω(h) ,µ(h) ) for h ̸= h⋆. Here the optimal head for task i is defined as
i i i
h⋆
i
= argmax h∈[H]µ( ih) and we have the abbreviations ω i⋆ ≜ ω i(h⋆ i) and µ⋆
i
≜ µ(h⋆ i). Notice that h⋆
i
is
actually a function of time t. As we will state in Theorem 3.3, in initialization, h⋆ is determined
i
by the initial values of {µ(h)} , and the choice of µ(h) ensures that h⋆ is unique for each task
h∈[H] 0 i
i. Then, as we will see below h⋆ remains the same throughout the dynamics. That is, the optimal
i
head for each task is fixed during gradient flow and only determined in initialization.
In the following, we characterize the three phases of gradient flow dynamics in the spectral
domain. For ease of exposition, we rescale the time by letting t ← 2dt in the following discussion.
11Phase I: Warm-up. During the warm-up phase, the optimal heads gradually dominate the non-
optimal heads. Recall that ϕ = 1+SNR−1 = 1+σ2d/(λ d ) where λ is the signal strength for
i i i i i
(h) (h)
task i. We can prove that the dynamics of ω and µ are approximately given by
i i
∂
logω(h)
≈
λ
√iµ( ih)
, ∂
logµ(h)
≈ d λ
ω(h)
−
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
d λ ϕ
µ(h′)
, (3.2)
t i d t i i i i L i i i i
e h′=1
(cid:124) (cid:123)(cid:122) (cid:125)
Cross-head interference
(h)
wherethesecondterminthedynamicsofµ isthecross-headinterferencetermbecauseitcontains
i
the contribution of µ(h′) for h′ ̸= h. When t is small, ω(h) is not far from the initial value ω ·1 for
i 0 d
all h ∈ [H]. Thus exp(⟨ω(h),ω(h′)⟩) in (3.2) is roughly of the same order for all h,h′. As a result,
the cross-head interference term is almost the same for all heads as long as ω(h) is small enough at
initialization. Then, by comparing heads h with h⋆, we eliminate the interference term and get
i
(cid:18) µ⋆ (cid:19) (cid:18) ω⋆ (cid:19) λ
∂ log i ≈ λ d (ω⋆−ω(h) ), ∂ log i ≈ √i (µ⋆−µ(h) ). (3.3)
t µ(h) i i i i t ω(h) d
e
i i
i i
Note that µ⋆ is the largest among µ(h) for all h ∈ [H]. The second equation in (3.3) ensures that
i i
ω⋆/ω(h) increases in times. Since they are initialized with the same value ω , (3.3) implies that ω⋆
i i 0 i
will grow faster than ω(h) for all i ∈ I, i.e., ω⋆ = max ω(h) . By examining the two equations in
i i i∈[I] i
(3.3), we see that the dominance of µ⋆ over each other µ(h) will induce the dominance of ω⋆ over
i i
each other ω(h) through the second equation, which then in-turn reinforces the dominance of µ⋆
i i
via the first equation.
In summary, during the warm up stage, both µ⋆ and ω⋆ will increase quickly and keep their
i i
dominating role over other heads in terms of solving task i. This phase terminates when there
exists an i ∈ [I] such that ω⋆ is sufficiently large such that the interference terms in the dynamics
i
(h)
of µ cannot be canceled out across different heads.
i
Phase II: Emergence. After the warm-up phase, the optimal head parameters µ⋆ and ω⋆ un-
i i
dergo a rapid and substantial increase for each task i. As the optimal head h⋆ becomes increasingly
i
dominant, {µ(h) ,ω(h) } for i ̸= h⋆ will remain small. As a result, we can only focus on the
i i h̸=h∗ i i
optimal head parameters and neglect the non-optimal head parameters, which yields the following
simplified dynamics:
(cid:16) (cid:17)
∂ µ⋆ ≈ λ d · −exp(d (ω⋆)2)·L−1ϕ µ⋆2+(1−ω⋆µ⋆)ω⋆µ⋆ ,
t i i i i i i i i i i i
(3.4)
(cid:16) (cid:17)
∂ ω⋆ ≈ 1−(cid:0) 1+exp(d (ω⋆)2(cid:1) ·L−1·d ϕ )·µ⋆ω⋆ ·d−1/2λ ω⋆µ⋆.
t i i i i i i i e i i i
To see that the dynamics in (3.4) captures the gradient flow dynamics, we plot the dynamics of µ⋆
i
in Figure 3-(a) for ϕ = λ = 1, d = 10, d = 30, and L = 100. The curve aligns well with the
i i i e
gradient flow dynamics in the simulation experiments, which is plotted in Figure 1.
To analyze this dynamics, we first note that because the first equation in (3.4) has a factor d
i
while the second equation is multiplied by d−1/2 , we can conclude that µ⋆ changes much faster than
e i
ω⋆. As a result, we leverage a two-timescale analysis by first pushing µ⋆ to its limit and write the
i i
12limiting value as a function of ω⋆. Then we can only focus on the dynamics of ω⋆ and analyze its
i i
behavior. In particular, setting the right-hand side of the first equation in (3.4) to zero, we have
ω⋆
µ⋆ ≈ i . (3.5)
i ω⋆2+ϕ exp(cid:0) d (ω⋆)2(cid:1) L−1
i i i i
Then, plugging (3.5) into the dynamics of ω⋆, we have
i
(cid:0)
1−d
(ω⋆)2(cid:1) ·d−1/2
λ
∂ ω⋆ ≈ i i e i . (3.6)
t i 2+ϕ exp(d (ω⋆)2)/(L(ω⋆)2)+L(ω⋆)2/(ϕ exp(d (ω⋆)2))
i i i i i i i i
Setting the right-hand side of (3.6) to zero yields a critical point ω⋆ = d−1/2 . Thus, when ω⋆ <
i i i
d−1/2 , the right-hand side of (3.6) is positive, which indicates the growth of ω⋆ before its value
i i
reaches d−1/2 . To further understand the dynamics of ω⋆, it suffices to consider the behavior of the
i i
denominator:
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)
L(ω⋆)2
2+ i i i + i
L(ω⋆)2 ϕ exp(d (ω⋆)2)
i i i i
For small ω⋆, the second term is large and dominates, thus resulting in the slow growth of ω⋆
i i
at the beginning. However, as ω⋆ grows larger (but still much less than d−1/2 ), the value of the
i i
denominatorquicklydecreases,makingthegrowthofω⋆ fastandgivingrisetotheemergencephase.
i
We also plot the dynamics of ω⋆ according to the apprximated dynamics in (3.6) in Figure 3-(b).
i
The curve aligns well Figure 1, which justifies the validity of the approximation.
Phase III: Convergence. Asω⋆ approachesd−1/2 ,weseefrom(3.6)thatthegrowthofω⋆ slows
i i i
down, and eventually ω⋆ converges to d−1/2 . By also invoking (3.5), we can show that eventually
i i
√
1 d
ω⋆ → √ , µ⋆ → i .
i d i 1+ed ϕ L−1
i i i
(h) (h)
While for each non-optimal head, ω does not change much from the initialization and µ
i i
converges to 0.
Collecting all the above components, we arrive at the main result on gradient flow dynamics
presented in Theorem 3.3. For a rigorous analysis, we pick constants c and ϵ such that
(cid:112) 1 1 3
3 ≤ c = o( logL), > ϵ ≥ + . (3.7)
(cid:112)
2 c 1+ 1+c2/2
Picking ϵ = 1/4 suffices, and a smaller value of ϵ requires larger L.
Theorem 3.3 (Convergence of gradient flow for MS-Attn). Under Assumption 2.1 and Assump-
tion 2.2, let L be sufficiently large such that (3.7) holds. Let d ≥ d. Suppose the initialization is
e
decomposable in the sense of Definition 3.1 and moreover,
√ (cid:113)
σ(Q(h) ) = σ(K(h) ) = ω 1 , σ(O(h)) = σ(V(h) ) = µ(h) ,
X X 0 d Y 0
where ω
0
and µ( 0h) ∈ Rdy are positive and sufficiently small in the sense of Assumption D.1. Suppose
H ≥ I and that at initialization, there exists a unique optimal head h⋆ for each task i such that
i
(µ⋆(0)−µ(h) (0))/µ⋆(0) ≥ c ,∀h ̸= h⋆,∀i ∈ [I], where c > 0 is a positive constant. Let µ⋆ and ω⋆
i i i 1 i 1 i i
(h⋆) (h⋆)
be abbreviations of µ i , ω i , respectively. We rescale t ← 2dt. Then the following holds:
i i
13(a) Dynamics of µ⋆ in (3.4) (b) Dynamics of ω⋆ in (3.6) (c) ∂ ω⋆ as a function of ω⋆
i i t i i
Figure 3: Approximated dynamics of the gradient flow with d = 10, d = 30, L = 100,
i e
ϕ = 1 and λ = 1. In (a) we plot the dynamics of µ⋆ in (3.4), starting from t = 4 and
i i i
(ω⋆,µ⋆) = (0.01,1). In (b) we plot the dynamics of ω⋆ in (3.6), starting from t = 4 and
i i i
ω⋆ = 0.01. We note that the approximated dynamics given by (3.4) and (3.6) are consistent
i
with the numerical simulations in Figure 1 based on data. In (c) we plot ∂ ω⋆ as a function of
t i
ω⋆ with the same setup. When ω⋆ is small (left), the growth of ∂ ω⋆ is slow. When ω⋆ reaches
i i t i i
the middle region, the growth of ω⋆ accelerates. When ω⋆ grows to the right end, it converges
i i
−1/2
to d .
i
(i) (Optimal Head Takes All) For each task i ∈ [I], the optimal head h⋆ determined by initializa-
i
tion will remain optimal during the training process in the sense that µ⋆ > µ(h) and ω⋆ > ω(h)
i i i √ i
for all h ̸= h⋆. In particular, for any non-optimal head h ̸= h⋆, we have µ(h) ≤ µ⋆exp(−Ω( d ))
i i i i e
(h)
and ω ≤ O(ω ) upon convergence for all i ∈ [I].
i 0
√
(ii) (Emergence) Fix a small constant α = Θ(1) < 1 and let T = d ϕ /(λLω ) be the threshold
0,i e i 0
time for task i to emerge. For time t ≤ (1−α)T , we have ω⋆(t) ≤ α−1ω , which means ω⋆(t)
0,i i 0 i
is “fixed” around initialization and the loss for task i is larger than Ω(λ d /d), where λ d /d
i i i i
is the value of the ICL loss if the attention output is 0 for task i. If t ≥ (1 + α)T , then
0,i
(cid:113)
ω⋆(t) ≥ αd−1 and the loss for task i is at most O(eα/α) times the optimal loss for task i in
i i
the single-head case given later by (4.4):
λ d ed ϕ L−1
L⋆:= i i · i i .
i d 1+ed ϕ L−1
i i
(iii) (Convergence) Consider the optimal head for task i. Let δ ∈ (0,1). With training time
√ √
(cid:18) (cid:19)
d eϕ i d e 4 (cid:112)
Ω max + √ log ≤ T ≤ exp(O( d )),
e
i∈[I] λ iLω 0 λ i d i δ
it holds that
sup(cid:12) (cid:12) (cid:12)ω i⋆(T) −1(cid:12) (cid:12)
(cid:12) ≤ δ, and
sup(cid:12) (cid:12)
(cid:12)√
µ⋆ i(T) −1(cid:12) (cid:12)
(cid:12) ≤ O(δ), (3.8)
i∈[I](cid:12)d i−1/2 (cid:12) i∈[I](cid:12) d i/(1+ed iϕ iL−1) (cid:12)
which is the same as the global optimal solution for a single-head softmax attention trained only
for task i (see (4.3)).
14The upper bound of the convergence time is due to technical reasons where we need to control
thecumulativeeffectoftheapproximationerrorinthegradientflow. Wecompareourresultstothe
existing literature regarding the training dynamics of attention-based models. Zhang et al. (2023a)
proved the convergence of gradient flow for one-layer single-head linear attention, while our results
areformulti-headsoftmaxattentionandwedonotcombinethekeyandqueryweightmatricesinto
a single matrix. Our results further provide a full characterization of the training dynamics from
small initialization to convergence and demonstrate a phase transition in the emergence of the ICL
capacity. Huang et al. (2023) was the first to study the training dynamics of softmax attention, but
their analysis is limited to the single-head case with context features coming from an orthogonal
dictionary. Moreover, the convergence point derived in Huang et al. (2023) is in sharp contrast to
ours. As we will show in the following section, we have E[∥p∥2] = O(L−1) upon convergence, while
2
the convergence point in Huang et al. (2023) has E[∥p∥2] = Ω(1) as the tokens that are the same
2
as the query will have dominating attention weights. The difference is due to the orthogonality
between token features and not taking into account the effect of noise in their analysis. Indeed,
we will show in the following section (Theorem 4.2) that having a dominating attention weight is
suboptimal in the presence of noise. Finally, Deora et al. (2023) also considered training a multi-
head softmax attention model, but they focused on the classification setting and their analysis is
limited to the regime of neural tangent kernel (Jacot et al., 2018) where the parameters do not
evolve much during training.
We conclude this section with a discussion of the convergence point of the gradient flow.
Each Optimal Head Aligns with the Task’s Subspace. ByTheorem3.3(iii), fortheoptimal
head h⋆ corresponding to task i, the attention score is computed as s = ω⋆(ΦX)⊤ (Φq) , where
i i (i) (i)
we use subscript “(i)” to denote the slice of a vector (matrix) corresponding to task i’s indices J .
i
Intuitively, the attention score is obtained by (i) rotating the key and query vectors to align with
the task’s eigenvectors and (ii) computing the inner product between the aligned key and query
vectors after projected onto the task’s subspace.
What is the Model learned by Gradient Flow? In addition, it was previously found by
Ahn et al. (2023); Mahankali et al. (2023) that the optimal weights of a one-layer linear attention
model correspond to one step of preconditioned gradient descent. While in our case, the model
in Theorem 4.2 found by gradient flow is analogous to emulating certain kernel regression where
the softmax attention aggregates similarity scores between the query and the keys across all tasks.
Note that if (ΦX) and (Φq) are of the same 2-norm, then the attention probability is given by
(i) (i)
p ∝ exp(−1ω⋆∥(Φx ) −(Φq) ∥2), and the output for task i, yp = µ⋆Yp, is the same as that of
l 2 i l (i) (i) 2 i i
the kernel smoothing method based on the radial basis function kernel with bandwidth (ω⋆)−1/2.
i
4 Optimality of Convergence Point of Gradient Flow
Next, we discuss the optimality (in terms of the ICL loss value) of the model trained by gradient
flow. The main result is summarized in the following lemma. Let us first understand the ICL loss
for this solution.
15Lemma 4.1 (ICLLossforMS-Attn). Under the setting of Theorem 3.3, the ICL loss value achieved
by the convergence point of gradient flow is upper bounded by
(cid:88)I λ id
i
·(cid:18) ed iϕ iL−1 +O(L−(1−ϵ)/2+δ+ω2d)(cid:19)
, (4.1, GF-ICL)
d 1+ed ϕ L−1 0
i i
i=1
where ϵ is defined in (3.7) and δ is the error for the convergence point in (3.8).
WedeferreaderstoLemmaE.9anditsfollow-upproofforthedetailedderivation. Forsequence
lengthL, theICLlossscaleswithO(d/L)andissimplyasummationofindividuallossacrosstasks,
which matches our observation that each task i ∈ [I] is completed by an individual head without
cross-head interference. Naturally, one may ask:
1. Giventhefactthateachtaskishandledbyauniquehead,doesthisdominatinghead’sbehavior
endure similarity to a single-head softmax attention? Does it achieve the optimal ICL loss on
that individual task?
2. Does this model achieve the optimal ICL loss within the class of MS-Attn?
In pursuit of answers to the above question, we continue to study the optimality properties for
both single-head softmax attention and MS-Attn. In §4.1, we investigate what are the optimal
attention weights and loss value for a single-head softmax attention dealing with multiple tasks. In
§4.2, we study lower bound of the optimal ICL loss within the class of equiangular weights under
homogeneity assumption on the tasks, and show that the convergence point of the gradient flow
matches the lower bound. In §4.3, we give a proof sketch to these optimality results with more
insights into the softmax attention.
4.1 The Single-Head Case: Allocation of Attention Budget
We first consider the single-head case where H = 1, and the goal here is to characterize the
minimalvalueoftheICLloss,assummarizedinthefollowingtheorem. Herewerecallthedefinition
ϕ = 1+σ2d/(λ d ).
i i i
Theorem 4.2 (Optimal Loss for Single-Head Softmax Attention). Suppose Assumption 2.1 holds
with Φ and Ψ being identity matrices (which is without loss of generality). Under Assumption 2.2,
supposeLissufficientlylargesuchthat (3.7)holdswithconstantsϵandc. Forasingle-headsoftmax
attention, assume that W = 0. Consider constant noise level σ2 = Θ(1). Suppose for each task
Y
i ∈ [I], the signal strength satisfies either λ = Θ(1) or λ = 0 for any i ∈ [I]. The model with the
i i
weights
(cid:112) b⋆/d ·I 0 ··· 0   0 0 
1 i d1
(cid:112)
W⋆ =    
 
0 0. . . b⋆ 2/ 0d . . .i·I d2 · ·..· ·.·
· (cid:112) b⋆
I/d0 . . .
I ·I dI
⋆   

, U⋆ =    

0 u 0 .
.
.⋆ 1 u0 .
.
.⋆ 2 ·· ..·· .·· 00 .
. .
   
 
0 ⋆ 0 0 ··· u⋆
I
approximately achieves the optimal loss in the sense that
L(U⋆,W⋆) ≤ inf L(U,W)+O(L−(1−ϵ)/2).
U,W:WY=0
16Moreover, B⋆ and b⋆ = (b⋆) are obtained by solving the following optimization problem:
i i∈[I]
I (cid:18) (cid:19)
min L
(B,b):=(cid:88) λ id i
1−
b i
, (4.2, OptS-ICL)
c−22logL≥B≥0,b∈RI,1⊤b=B sim d b i+d iϕ i·exp(B)·L−1
+ i=1
and u⋆ = (cid:112) b⋆d /(b⋆+d ϕ exp(B⋆)/L). In addition, |L(U⋆,W⋆)−L (B⋆,b⋆)| = O(L−(1−ϵ)/2).
i i i i i i sim
See §4.3 for a proof sketch and §E.1 for a detailed proof. In a nutshell, Theorem 4.2 shows that
the optimal ICL loss and the corresponding weights for a single-head softmax attention are related
to the optimal value and solutions to an optimization problem. Our proof is based on first lower
bounding the ICL loss for any weights by the optimal value of (4.2, OptS-ICL) and then show the
constructed optimal solution achieves the lower bound. Note that the softmax operation induces
nonlinearity, and our proof technique is to identify the operating regimes of the softmax attention
(Figure 6 in §4.3) and decide the optimal operating regime for the ICL task. After that, we isolate
the higher order nonlinear terms and approximate the lower order nonlinear term in the system
to make rigorous nonlinear analysis tractable. We also remark that setting W = 0 is a standard
Y
practice for analyzing attention-based models for ICL and similar assumptions are also employed
in Zhang et al. (2023a); Von Oswald et al. (2023); Ahn et al. (2023); Huang et al. (2023).
Below we provide discussion on the insights and implications of Theorem 4.2.
OptimalSolutionisDecomposable. ForgeneralorthogonalmatricesΦandΨ,thecorrespond-
ing optimal weights can be constructed by applying the rotation to W⋆ and U⋆ while keeping the
X Y
Ă r
remaining entries zero, i.e., the optimal weights W⋆ and U⋆ are given by
WĂ⋆ = Φ⊤W⋆Φ, WĂ⋆ = 0, Ur⋆ = Ψ⊤U⋆Ψ, Ur = 0.
X X Y Y Y X
To see the equivalence, one can view the rotated data Xr = Φ⊤X, εr= Ψ⊤ε and qr= Φ⊤q as the
new input, and the loss value is preserved due to the rotational invariance of the input distribution
(See (E.1)). More importantly, we remark that the optimal weights are decomposable since W⋆
X
and U⋆ are diagonal, and one can always construct the corresponding Q⋆ , K⋆ , V⋆ and O⋆ (also
Y X X Y
subject to rotation for general Φ and Ψ) that share common eigenvector spaces to get the same
model. Moreover, it is clear that the optimal weights also have homogeneous entries within each
task. These facts justify the decomposability condition in Definition 3.1.
Allocation of Attention Budget. We interpret the sum of the squared eigenvalues, ∥ω∥2 =
2
∥W ∥2, as the total attention budget. Correspondingly, one can intuitively understand the sum of
X F
the squared eigenvalues within task i’s support, (cid:80) ω2, as the allocation of attention budget for
j∈Ji j
task i. Then in (4.2, OptS-ICL), B and b = {b } are the attention budget and the allocation
i i∈[I]
vector of the budget, respectively. Fixing the attention budget B, the inner optimization problem
over b is simply trying to optimally allocate the budget according to the signal-to-noise ratios
{SNR } and the task dimensions {d } , which is a convex optimization problem.
i i∈[I] i i∈[I]
Softmax Attention Works in the Exponential Regime. Note that the optimal attention
budgetscalesasB⋆ = o(logL)(seethejustificationofthisinLemmaE.6). Aswewillillustratelater
in§4.3, suchanattentionbudgetcorrespondstotheexponential regime4 ofsoftmaxattention. This
4See Figure 6 for a graphic illustration of the “exponential” behavior of the softmax attention in this regime
17is a consequence of the fact that the exp(B) in the denominator of (4.2, OptS-ICL) penalizes the
attention budget. In contrast, in the saturation regime where the attention budget B = Ω(logL),
the attention probability vector concentrates on a few tokens, which is suboptimal in the presence
of noise (Lemma E.4 and Lemma E.5).
GiventhattheattentionbudgetB = o(logL), theattentionprobabilityvectorisdelocalized5 so
that the attention is spread out to capture the information from similar tokens in regression tasks
and average out the noise. This is in sharp contrast to the solution found by Huang et al. (2023)
where the attention probability is concentrated on the tokens that are the same as the query, which
is because their context features are from an orthogonal dictionary and the data is noiseless.
MS-Attn Acts as Multiple Optimal Single-Head Softmax Attention. Supposeanattention
head focuses on a single task, say task i, and treats the other tasks as with zero signal strength,
i.e. λ = 0 for any j ̸= i. We apply Theorem 4.2 to this head, and the optimal eigenvalues are
j
√
1 d
i
ω = √ , µ = , ,ω = µ = 0, ∀j ∈ [I]\{i}. (4.3)
i d i 1+ed ϕ L−1 j j
i i i
Thisisobtainedbylettingb = B fortheinneroptimizationin(4.2, OptS-ICL)anddirectlysolving
i
the outer optimization problem which gives optimal solution at B⋆ = 1. The optimal loss value
(up to O(L−(1−ϵ)/2) error) for task i is then given by
λ d ed ϕ L−1 (cid:18) d(cid:19)
L⋆:= i i · i i = O , (4.4)
i d 1+ed ϕ L−1 L
i i
Comparing this to the multi-head model trained by gradient flow in Theorem 3.3, we discover that
attheconvergencepoint, theoptimalheadisactingasanoptimalsingle-headsoftmaxattentionfor
each task. Is this optimal within the class of MS-Attn? We will next investigate this question over
a class of equiangular weights, which is a natural class to consider when the tasks are homogeneous
in the sense that they share the same dimension and signal strength.
4.2 The Multi-Head: Equiangular Lower Bound and Bayesian Risk
We start by introducing the following class of weights, which we call equiangular weights.
Definition4.3(EquiangularWeights). ForweightsofaMS-Attnthataredecomposableinthesense
of Definition 3.1, we say the corresponding task-aggregated eigenvalues {ω(h)} are equiangular
h∈[H]
ifthereexistconstantsa,b ∈ Rsuchthat∥ω(h)∥2 = aand⟨ω(h),ω(h′)⟩ = bforalldistincth,h′ ∈ [H].
2
Theequiangularpropertyensuresthecosinesimilaritybetweenanytwotask-aggregatedweights
to be the same, which reduces the degree of freedom in the system and it suffices to optimize over
a and b. We remark that the equiangular weights are a reasonable class to consider under the task
homogeneity assumption that all tasks have the same dimension and signal strength. The following
theorem addresses the optimality among the class of MS-Attn with equiangular weights.
Theorem 4.4 (LowerBoundofMS-AttnwithinEquiangularWeights). Under Assumption 2.1 and
Assumption 2.2, suppose H ≥ 2 and I tasks are homogeneous such that d = d/I = d and λ = λ
i i
5This is a direct result of Lemma B.3 applied to a single head which says E[∥p∥2]≈exp(∥ω∥2)/L=o(1)
2 2
18i.i.d.
for all i ∈ [I]. Suppose task coefficient g ∼ N(0,λ/d · I ) for all i ∈ [I]. Let c and ϵ satisfy
i d
(cid:112)
(3.7), and consider the regime where ∥ω(h)∥ ≤ 2logL/3dc2,∥µ(h)∥ ≤ L3/4−ϵ/2 for all h ∈ [H].
∞ ∞
Then for any MS-Attn with equiangular weights in the sense of Definition 4.3, the ICL loss is lower
bounded by
(cid:26) (cid:27)
λ
max +O(L−ϵ/2), R , (4.5)
ϕ−1d−1L·(H −1)+1 Bayes
(cid:124) (cid:123)(cid:122) (cid:125)
LB-ICL
i.i.d.
where R is the Bayesian risk for this ICL task with prior g ∼ N(0,λ/d·I ) for all i ∈ [I].
Bayes i d
Moreover, by decomposing R := Variance+Bias, the two terms are given asymptotically by
Bayes
(cid:112)
br+(1+r)− (br−1+r)2+4b
Variance = Iσ2· ,
(cid:112)
2 (br−1+r)2+4b
(cid:18) br(1+r)+(1−r)2−|1−r|(cid:112) (br−1+r)2+4br (cid:18) 1(cid:19) (cid:19)
Bias = λ· + 1− 1(r > 1) ,
(cid:112)
2 (br−1+r)2+4b r
where b = σ2/λ and r = d/L.
See§4.3foraproofsketchand§E.2foradetailedproof. Weremarkthenormconstraintsonthe
weights are without much loss of generality since the optimal weights for the single-head softmax
√
attention satisfy ω = O(d−1/2) and µ = O( d) as we have shown in Theorem 4.2, which means the
attention is working in the exponential regime as we will discuss in §4.3. As a corollary, we give an
affirmative answer to the question of the optimality of the model found by gradient flow.
Corollary 4.5. Under the setting of Theorem 4.4, let H = I. The ICL loss of the model in
Theorem 3.3 achieves the lower bound of the ICL loss given by Theorem 4.4 up to a constant
multiplicative factor.
Lower Bound is Achieved by the Convergence Point. Now we compare the upper bound
of the ICL loss with the lower bound in (4.5) under different settings. For simplicity, we consider
the asymptotic regime (d,L → ∞ and d/L = Θ(1)) where we neglect the error term that only
depends on L and consider a small constant d/L. The Bayesian risk (or Minimum Mean Square
Error (MMSE)) when ignoring higher order terms of d/L is given by
σ2
MMSE = . (4.6, MMSE)
d−1L+I−1(SNR−1−1)
We consider four cases stratified by the relationship between H and I, and compare in each case
the lower bound and the upper bound on the ICL loss. The result is summarized in Table 1 and
visualized in Figure 5.
(i) If H = I, then the ICL loss at the convergence point achieves the lower bound up to a
constant factor e, where we are exploiting the full power of the MS-Attn to solve the tasks.
(ii) If H ≥ I, in general the GF-ICL is suboptimal compared with the Bayesian risk. However,
in the low SNR regime, i.e., SNR = λ/(Iσ2) = o(1), the ICL loss of the trained model also
reaches the Bayesian risk up to a constant factor e. This is in fact not surprising and is due
to the softmax-induced regularization. We will further illustrate this in Section 4.3.
19Case Lower Bound Upper Bound Matched?
H = I LB-ICL = λ GF-ICL = λ ✓
(H−1)ϕ−1d−1L+1 He−1ϕ−1d−1L+1
H > I MMSE = σ2 GF-ICL = σ2·(1+SNR) ✓(low SNR)
d−1L+I−1(SNR−1−1) e−1d−1L+I−1(1+SNR−1)
H < I LB-ICL = λ Const-ICL = λ ✓(I = kH)
(H−1)ϕ−1d−1L+1 H·e−1ϕ−1d−1L+1
H = 1 OptS-ICL = λ same as the lower bound ✓
e−1ϕ−1d−1L+1
Table 1: Summary of lower bounds and upper bounds for different cases. Here, LB-ICL is the
lower bound given by (4.5), GF-ICL is the ICL loss of the convergence point of the dynamics in
(4.1, GF-ICL) which serves as an upper bound, MMSE is the Bayesian risk, OptS-ICL is given
by the optimal value to (4.2, OptS-ICL) that is the optimal ICL loss for a single-head softmax
attention. For the H > I case, we rewrite the GF-ICL in terms of the SNR for better comparison.
The term “Const-ICL” refers to the ICL loss for the constructed solution under the condition
I = kH where each head handles k different tasks optimally and treats other tasks as with zero
signal in the sense of Theorem 4.2.
(iii) We do not consider the gradient flow for H < I. However, it is not hard to construct a
solution when I = kH for some positive integer k. In this case, we just let each head handle
k different tasks while treating the remaining as with zero signal, and the optimal weights
are given by Theorem 4.2 and the ICL loss is given by Const-ICL shown in Table 1. Clearly,
the construction achieves the lower bound up to a constant factor e.
(iv) When comparing the ICL loss upper bound of the MS-Attn with H heads (Case (i)∼(iii)) to
the optimal ICL loss for the single-head case (OptS-ICL by Theorem 4.2), we clearly see that
the MS-Attn is at least H ∧I times more efficient than the single-head softmax attention in
terms of the ICL loss.
Insummary,wehaveshownbycasesthetightnessofthelowerboundinTheorem4.4. Inparticular,
the Bayesian risk lower bound is achieved by the convergence point of the MS-Attn for H ≥ I in
the lower SNR regime.
4.3 Softmax-Induced Regularization and Proof Sketch for the Optimality Re-
sults
Before presenting our proof sketch for the optimality results, let us first understand the loss de-
composition of a single softmax transformer head.
4.3.1 Loss Decomposition and Softmax-Induced Regularization
We treat W and U as the combined weights of the single-head attention. For ease of presentation,
we only consider one task here while the multi-task case is deferred to the complete proof in §E.
Hence, d = 1 with U being just a scalar, G = g ∈ Rd×1 and we have E[GG⊤] = λd−1I . Suppose
y Y 1 d
20(a) Visualization of the lower bound in The-
orem 4.4 and the Bayesian risk (MMSE). As
further illustrated on the right, for H < I,
LB-ICL serves as the effective lower bound and (b) Comparison of LB-ICL and
for roughly H > I, the Bayesian risk serves as MMSE over (i) d/L for different H
the effective lower bound. and (i) H for d/L=0.01.
Figure 4: Comparison between the lower bound LB-ICL and the Bayesian risk (MMSE) for
different H and d/L with I = 10, λ = σ2 = 1. Here, d = d/I.
W = 0, then the ICL loss defined in (2.6) can be decomposed into
Y
L(U,W) = E(cid:2)(cid:13) (cid:13)G⊤q−U YG⊤Xp(cid:13) (cid:13)2 2(cid:3) +E(cid:2)(cid:13) (cid:13)U XXp(cid:13) (cid:13)2 2(cid:3) + E(cid:2)(cid:13) (cid:13)U Yεp(cid:13) (cid:13)2 2(cid:3) .
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Signal-induced error Extra error Noise-induced variance
Note that the extra error term vanishes when setting U = 0, and the remaining terms are not
X
affected, thus justifying Definition 3.1(i). Expanding the signal-induced error, we have
E(cid:2)(cid:13) (cid:13)G⊤q−U YG⊤Xp(cid:13) (cid:13)2 2(cid:3) = λd−1·E(cid:2) d−2U
Y
Tr(Xpq⊤)+U Y2 Tr(Xpp⊤X⊤)(cid:3) .
Applying the Stein’s lemma for the expectation term (Lemma C.4) yields
E[Xp|q] = W q(1−E[∥p∥2|q]),
X 2
(4.7)
E[Xpp⊤X⊤|q] = W qq⊤W⊤E[1−∥p∥2−6∥p∥3+6∥p∥4|q]+I E[∥p∥2|q].
X X 2 3 2 d 2
When W has bounded operator norm (which will be justified later), it holds with high proba-
X
bility that ∥W q∥2 ≤ O(2logL), and then we can ignore the higher order terms in the expecta-
X 2
tion (Lemma B.4). Consequently, we have E[Xp|q] ≈ W q and E[Xpp⊤X⊤|q] ≈ W qq⊤W⊤ +
X X X
I E[∥p∥2|q] up to O(L−1) error. Applying these to simplify the signal-induced error term, we
d 2
obtain
L(U,W) ≈ λd−1·E(cid:2) ∥q−U W q∥2(cid:3) + (λ+σ2)U2 ·E[∥p∥2] . (4.8)
Y X 2 Y 2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Linearized bias Softmax-induced regularization
21Figure 5: Comparison of the ICL loss between (i) ridge regression with regularization param-
eter penalty = 0.05 and penalty = 5; (ii) the Bayesian risk, i.e., MMSE; (iii) the ICL loss for
the convergence point of the gradient flow (4.1, GF-ICL) with H ≥ I; (iv) the ICL loss of the
optimal single head attention (4.2, OptS-ICL). Here, d = d/I. For large d/L, the GF-ICL
loss behaves similarly to ridge regression with large penalty = 5 and does not have the double
descent phenomenon that is observed with insufficient regularization penalty = 0.05. This is
due to the softmax-induced regularization as we will further illustrate in §4.3. For small d/L,
we see that MS-Attn (GF-ICL) has an H∧I = 10 improvement over the single-head attention
(OptS-ICL). We refer readers to §E.3 for more details.
Here, the first term is the linearized bias, where we get rid of the nonlinearity in the attention
probability. In particular, this term measures how close U W is to the identity. The second
Y X
term is a softmax-induced regularization induced by the concentration of the attention probability.
With ∥p∥2 becoming larger, the attention probability becomes more concentrated on a few input
2
tokens, leading to a larger variance in the output. In particular, when compared to standard linear
regression’s loss decomposition, a key difference is that the softmax-induced regularization term
alsodependsonthesignalstrengthλwhilethestandardlinearregression’sregularizationtermonly
depends on the noise level σ2. Such a fact answers the question of why the MS-Attn’s performance
matches the MMSE only under the low SNR regime as shown Table 1. The key to our analysis is
understanding the softmax-induced regularization term.
4.3.2 Exponential and Saturation Regime of Softmax Attention
We characterize the behavior of the softmax-induced regularization in two regimes, which we call
the exponential regime and the saturation regime, stratified by the scale of the attention budget
∥W ∥2 = E[∥W q∥2]. In the sequel, we denote by E[∥p∥2|r] = E[∥p∥2|∥W q∥ = r]. Since r is a
X F X 2 2 2 X 2
random variable with r2 concentrated around ∥W ∥2, we also characterize the two regimes by the
X F
scale of r. Figure 6 illustrates the behavior of the softmax-induced regularization term E[∥p∥2|r]
2
as a function of r.
√
Exponential Region (r = o( 2logL), Lemma B.2). We name this regime the exponential
regime since in this regime, the softmax-induced regularization term in (4.8) is approximately an
exponential function of the attention budget. This is also the regime where the optimal ICL rate
is achieved (Theorem 4.2). To derive the approximation form, we introduce an index t ∈ [0,1] and
22Figure 6: The behavior of E[∥p∥2|r] as a function of r for L = 104. The left figure shows the
2 √
behavior of E[∥p∥2|r] and min{exp(r2)/L,1} is a good approximation when r = o( 2logL)
2
(Lemma B.2) in the exponential regime. The right figure shows that 1−E[∥p∥2|r] for r ≫
√ 2
2logL is upper bounded by O(r−1+ϵ) in the saturation regime(Lemma B.5).
consider function f(t,q) = E[∥softmax(tX⊤W q)∥2|q]. We then take the derivative ∂f to obtain
X 2 ∂t
∂f
= E[∥p(t)∥2−4∥p(t)∥3+3∥p(t)∥4|q]·∥W q∥2,
∂t 2 3 2 X 2
where p(t) = softmax(tX⊤W q). This calculation follows from the Stein’s lemma. By analyzing
X
the tail of max p (t), we can control the higher order moments of p(t) and get
l∈[L] l
∂f
≈ E[∥p(t)∥2|q]·∥W q∥2 = f(t,q)·∥W q∥2.
∂t 2 X 2 X 2
Integrating this with respect to t from 0 to 1 and by a careful analysis of the error along the
integrating path, we conclude that E[∥softmax(tX⊤W q)∥2|q] = f(1,q) ≈ exp(∥W q∥2)/L. The
X 2 X 2
analysis can also be extended to the multi-head case and the results are also useful for simplifying
the dynamics in §C.2.2.
√
Saturation Regime (r ≫ 2logL, Lemma B.5). The above approximation breaks down for
large r. However, in this case we can utilize the fact that the attention probability is concentrated.
Note that E[∥p∥2|r] = E[∥softmax(rz)∥2], where z ∼ N(0,I ). It can be shown that
2 2 d
(cid:20) L (cid:21)
(cid:88)
1−E[∥p∥2|r] ≤ 2E[p +p +···+p |r] ≤ 2E exp(−r(z −z )) , (4.9)
2 2 3 L 1 l
l=2
where p ,p ,...,p and z ,z ,...,z are the (descending) order statistics of p and z respectively.
1 2 L 1 2 L
The approach for dealing with (4.9) is to properly choose a threshold θ = log(Lrα)/r for some
α > 1/2 and then split the sum into two parts based on whether z −z > θ or z −z ≤ θ. For
1 l 1 l
the first part, we utilize the gap θ to upper bound the sum by Lexp(−rθ) = r−α. For the second
part, we directly upper bound each term by exp(−r(z −z )) while controlling the total number
1 2
of terms N. This is essentially equivalent to bounding the tail of a binomial distribution with L
√
trials and success probability roughly P ( 2logL−v ≤ θ). Finally, combining the moment
v∼N(0,1)
generating function for z −z and also the tail bound for N, we can choose α to be some 1−ϵ
1 2
constant and obtain the desired result.
23The Saturation Regime is Suboptimal for ICL with noise. Huang et al. (2023) studied
the setting where the context features come from an orthogonal basis and the data is noiseless.
Their trained model assigns Ω(1) probability to some tokens and falls into the saturation regime.
However, in the presence of noise, our analysis clearly shows the suboptimality of the saturation
regime for ICL (Lemma E.4 and Lemma E.5). The proof is a combination of understanding the
nonlinear ICL loss for different regions of the attention budget. Notably, the proof of Lemma E.4
for the very extreme case of the attention budget is given by relating the lower bound of the ICL
loss to a group of attention weights operating with normalized query on the sphere.
4.3.3 Proof Sketch for the Optimality Results
Now we are ready to sketch the proof for the optimality results.
The Single-Head Case. Recall from (4.8) and we consider the attention to operate in the
exponential regime:
exp(∥W ∥2)
L(U,W) ≈ λd−1·E(cid:2) ∥I −U W ∥2(cid:3) + (λ+σ2)·U2 · X F . (4.10)
Y X F Y L
(cid:124) (cid:123)(cid:122) (cid:125)
(cid:124) (cid:123)(cid:122) (cid:125)
Linearized bias
Softmax-induced regularization
The softmax-induced regularization puts a quadratic penalty on the output projection weights
U and an exponential penalty on the attention budget ∥W ∥2. In (4.10), it is not hard to see
Y X F
that all attention budget should be concentrated only on the diagonal entries of W to minimize
X
the loss. For multi-task case, the same argument still holds but needs a more refined analysis,
especially for dealing with nonlinearity that is hidden in (4.10) for ease of presentation. By treating
(cid:112)
W = B/d·I and first optimizing over U , we arrive at the an optimization problem over B:
X d Y
λ
min ,
0≤B≤O(logL)
d−1Lϕ−1exp(−B)B+1
where ϕ = 1+SNR−1 = 1+σ2/λ. The optimal is achieved at B⋆ = 1 which gives the optimal
loss value λ/(e−1ϕ−1d−1L+1) and also the optimal solution. The results for the multi-task setting
follow from similar ideas.
The Multi-Head Case. Here we need a more refined loss decomposition that isolates task-wise
performance as follows:
I
λ (cid:88)
L(µ,ω) = L (µ,ω)+O(L−ϵ/2), where L (µ,ω):=1−2µ⊤ω +µ⊤(ω ω⊤+B)µ ,
I i i i i i i i i
i=1
ϕ exp(d⟨ω(h),ω(h′)⟩)
ω = (ω(1) ,...,ω(H) )⊤, µ = (µ(1) ,...,µ(H) )⊤, B ∈ RH×H with(B ) := i .
i i i i i i i hh′ L
Note that by the equiangular property, we can also decompose B into the diagonal part and the
off-diagonal part
B =
(ra−r
b)I
+r
bE,
where E is the matrix with all entries being 1 and
ra,r
b are the diagonal and off-diagonal entries
of B respectively. Motivated by the structure of B, we can also project ω into the parallel and
i
orthogonal components with respect to 1 . By doing quadratic minimization over µ , and a
H i
nonlinear minimization over
ra,r
b, we arrive at the lower bound for the equiangular weights.
245 Extensions
Inthissection, wediscusssomeextensionsofthemainresults. Letusfirstgainmoreunderstanding
of the relationship between softmax attention and linear attention.
5.1 Similarity between Softmax Attention and Linear Attention
Here we consider the optimal single-head attention head and consider the regime L ≫ d. Consider
a query q such that ∥W q∥2 = O(1) and we ignore the noise term. We invoke (4.7) and also the
X 2
approximation in the exponential regime (Lemma B.2, which applies regardless of the relative scale
of d and L when ∥W q∥2 = O(1)) to get
X 2
1
Xp ≈ E[Xp|q] = W q(1−E[∥p∥2|q]) ≈ W q ≈ XX⊤W q.
X 2 X L X
Here the first approximation is due to the fact that the second moment is small by (4.7), i.e.,
Tr(E[(Xp−E[Xp|q])(Xp−E[Xp|q])⊤|q]) = d·E[∥p∥2|q]+O(L−1) = O(d/L).
2
Therefore, it follows that
1 1
yp = U G⊤Xp ≈ U YX⊤W q = UZZ⊤Wz , (5.1)
q Y Y X q
L L
which is equivalent to the linear attention model (Zhang et al., 2022) but with a different scaling
of the attention weights. However, such approximation requires a large L. For the setting of our
main results where d/L = Θ(1), the approximation is not valid and the analysis has to go beyond
the linear case.
5.2 Length Generalization
WealsoconsiderapplyingthetrainedmodelinTheorem3.3withtrainingdataoflengthLtoasame
r
ICL tasks with a new sequence of length L, and study the ICL loss for the new tasks. Specifically,
the softmax attention model is trained in the same way as in (2.7), but when computing the ICL
loss, we use a sequence of length Lr . That is, in (2.6), yp is computed according to (2.1) but
q
r
with Z consisting of L covariate-response pairs from the multi-task linear model introduced in
Assumption 2.1. We have the following upper bound on the ICL loss.
Proposition 5.1 (Length Generalization for MS-Attn). For the convergence point of the dynamics
described in Theorem 3.3, consider applying the trained model to a new ICL learning task with the
r
same data structure under Assumption 2.1 but a new sequence length L. Then the corresponding
loss value is upper bounded by
(cid:88)I λ id
i
·(cid:18) ed iϕ iL−1
+O(L−(1−ϵ)/2+ω2d+δ)+O(ϕ d
|L−1−Lr−1|)2(cid:19)
. (5.2)
d 1+ed ϕ L−1 0 i i
i i
i=1
See §F.1 for a proof. Proposition 5.1 shows that the ICL loss scales with O(d/Lr )+O((d/(L∧
r
L)2)). Herein(5.2), thefirsttermistheintrinsiclossandthethirdtermcharacterizestheerrordue
to the mismatch in sequence length. Notably, since ω⋆ is independent of the sequence length, we
i
25have the mismatch term coming only from the suboptimality of µ⋆, which is actually a higher order
i
term (for more details, see the quadratic error term in Lemma E.7). Thus, we conclude that the
model trained by gradient flow also generalizes well to new sequence length. We also remark that
such a nice property is due to the normalization of the softmax function, and the linear attention
model does not have such a property as indicated by (5.1) where the weights should directly scale
with 1/L.
5.3 Linear-to-Nonlinear Transfer
We consider first training the model on linear tasks and then applying the trained model to a
nonlinear task. We only consider the single-head case for simplicity. Consider replacing Y =
G⊤X+εwithY = f(X)+εwheref isanonlinearfunctioninthedownstreamICLtask(thetraining
dataisstilllinear). Supposef hasdegreeatmostD inthesensethatf isalinearcombinationofd-
dimensional multivariate Hermite polynomials up to degree D, {He |α ∈ Nd, |α|:=(cid:80)d α ≤ D}.
α i=1 i
f(x) = (cid:88) fp He (x), where fp ∈ R.
α α α
|α|≤D
Lemma 5.2 (Generalization of Single-Head Softmax Attention to Nonlinear Tasks). Let L be
sufficiently large such that (3.7) holds for constants ϵ and c. Consider Assumption 2.1 on the data
but with a nonlinear task Y = f(X)+ε where f has degree at most D = O(1). Consider only a
single head whose weights are given by the optimal single-head softmax attention trained for this
linear task, i.e.,
√
d
W = d−1/2·I , U = µ = . (5.3)
X d Y 1+edϕL−1
Then with probability at least 1−exp(−(c−2logL−1)2∧d/2), the average output of the model for
a fixed query q satisfies
(cid:12) (cid:12)
(cid:12) (cid:12)E[yp q|q]−µ· (cid:88) fp αd−|α|/2·qα(cid:12) (cid:12) ≤ O(L−2(1−ϵ)), (5.4)
(cid:12) (cid:12)
α:|α|≤D
where we define qα = (cid:81)d qαi.
i=1 i
See §F.2 for a proof. Lemma 5.2 indicates that the optimal single-head softmax attention
trained for a linear task does not generalize well to a nonlinear task. On one hand, the coefficient
is not well preserved due to the additional factor d−|α|/2, especially for high degree terms. On the
other hand,
qα =
(cid:89)d (cid:18)⌊α (cid:88)i/2⌋
He αi−2ki(q i)
(cid:19)
= He (q)+
(cid:88) He α−2k(q)
,
k i!2ki(α i−2k i)! α k!2k(α−2k)!
i=1 ki=0 k∈Nd,|k|≥1
ki≤⌊αi/2⌋,∀i∈[d]
where k! = (cid:81)d i=1k i! and 2k = (cid:81)d i=12ki. Such a fact indicates a “leakage” of the high degree terms
p
to the low degree terms. Notably, when α = 0, we have output µf , where we see that the current
√ 0
attention scales up the constant term up by µ = Ω( d). However, this can be remedied by also
26includingabiastermtotheoutputlayer, i.e., yp = U Yp+bandalsobeforeinputtingthesequence
q Y
to the attention layer, i.e., Y = Y −b′.
At a high level, the failure of capturing higher order nonlinear effect is because the model (5.3)
trained on linear tasks only achieves the optimal variance and bias tradeoff for linear tasks, as
√
W = d−1/2I “downscales” the attention score to have unit variance and U ≈ d “upscales” the
X d Y
aggregatedoutputbacktoitsoriginalscale. The“downscaling”seemstobetoomuchfornonlinear
tasks with higher degree terms.
6 Conclusion and Future Work
In this paper, we study the training dynamics of a single-layer multi-head softmax attention model
for the in-context learning problem of multi-task linear regression. By deriving the spectral dy-
namics of the attention weights induced by gradient flow, we provide a complete characterization
of the training dynamics in terms of three phases: warm-up, emergence, and convergence.
(i) The warm-up phase shows that the optimal attention head for each task, which by initial-
ization has small advantage, gradually wins the competition among heads under a strong
cross-head interference.
(ii) The emergence phase demonstrates the sudden emergence of the ICL capability with a quick
drop in the ICL loss.
(iii) The convergence phase highlights a linear convergence rate to the optimal solution: each task
is assigned a unique attention head which operates as the optimal single-head attention for
that task.
Wealsocharacterizetheoptimalityoftheconvergencepointofgradientflow. Throughouttheanal-
ysis, we identify two working regions of the softmax attention model and prove that for noisy tasks,
the optimal weights lie in the exponential region which demonstrates a unique tradeoff between
bias and variance for the softmax attention model.
We also show that the optimal solution for a linear task trained with a fixed context sequence
length generalizes well to different sequence length but poorly to nonlinear tasks. For future
work, we believe it is important to further incorporate into the analysis other design factors in
transformers, such as multi-layers, layer normalization, and positional encodings, etc. It is also
an interesting future direction to understand how softmax attention deals with nonlinear tasks,
especially for the multi-head attention model.
References
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D.,
Altenschmidt, J., Altman, S., Anadkat, S. et al. (2023). Gpt-4 technical report. arXiv preprint
arXiv:2303.08774.
Ahn, K., Cheng, X., Daneshmand, H. and Sra, S. (2023). Transformers learn to implement precon-
ditioned gradient descent for in-context learning. arXiv preprint arXiv:2306.00297.
Ahuja, K., Panwar, M. and Goyal, N. (2023). In-context learning through the bayesian prism.
arXiv preprint arXiv:2306.04891.
27Akyu¨rek, E.,Schuurmans, D.,Andreas, J.,Ma, T.andZhou, D.(2023).Whatlearningalgorithmis
in-contextlearning? investigationswithlinearmodels. InThe Eleventh International Conference
on Learning Representations.
An, B., Lyu, J., Wang, Z., Li, C., Hu, C., Tan, F., Zhang, R., Hu, Y. and Chen, C. (2020). Repul-
sive attention: Rethinking multi-head attention as bayesian inference. In Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP).
Anthropic (2023). Model card and evaluations for claude models.
Bai, Y., Chen, F., Wang, H., Xiong, C. and Mei, S. (2023). Transformers as statisticians: Provable
in-context learning with in-context algorithm selection. arXiv preprint arXiv:2306.04637.
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A.,
Shyam, P., Sastry, G., Askell, A. et al. (2020). Language models are few-shot learners. Advances
in neural information processing systems, 33 1877–1901.
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A. and
Mordatch, I. (2021). Decision transformer: Reinforcement learning via sequence modeling. Ad-
vances in neural information processing systems, 34 15084–15097.
Chen, S. and Li, Y. (2024). Provably learning a multi-head attention layer. arXiv preprint
arXiv:2402.04084.
Cheng, X., Chen, Y. and Sra, S. (2023). Transformers implement functional gradient descent to
learn non-linear functions in context. arXiv preprint arXiv:2312.06528.
Collins, L., Parulekar, A., Mokhtari, A., Sanghavi, S. and Shakkottai, S. (2024). In-context learn-
ing with transformers: Softmax attention adapts to function lipschitzness. arXiv preprint
arXiv:2402.11639.
Cui, Y., Ren, J., He, P., Tang, J. and Xing, Y. (2024). Superiority of multi-head attention in in-
context linear regression. arXiv preprint arXiv:2401.17426.
Dai, D., Sun, Y., Dong, L., Hao, Y., Sui, Z. and Wei, F. (2022). Why can gpt learn in-
context? language models secretly perform gradient descent as meta optimizers. arXiv preprint
arXiv:2212.10559.
Deora, P., Ghaderi, R., Taheri, H. and Thrampoulidis, C. (2023). On the optimization and gener-
alization of multi-head attention. arXiv preprint arXiv:2310.12680.
Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K. (2018). Bert: Pre-training of deep bidirec-
tional transformers for language understanding. arXiv preprint arXiv:1810.04805.
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T.,
Dehghani, M., Minderer, M., Heigold, G., Gelly, S. et al. (2020). An image is worth 16x16
words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.
Edelman, B. L., Edelman, E., Goel, S., Malach, E. and Tsilivis, N. (2024). The evolution of statis-
tical induction heads: In-context learning markov chains. arXiv preprint arXiv:2402.11004.
28Edelman, B. L., Goel, S., Kakade, S. and Zhang, C. (2022). Inductive biases and variable creation
in self-attention mechanisms. In International Conference on Machine Learning. PMLR.
Fu, D., Chen, T.-Q., Jia, R. and Sharan, V. (2023). Transformers learn higher-order optimization
methods for in-context learning: A study with linear models. arXiv preprint arXiv:2310.17086.
Garg, S., Tsipras, D., Liang, P. S.andValiant, G.(2022). Whatcantransformerslearnin-context?
a case study of simple function classes. Advances in Neural Information Processing Systems, 35
30583–30598.
Giannou, A., Rajput, S., Sohn, J.-Y., Lee, K., Lee, J. D. and Papailiopoulos, D. (2023). Looped
transformers as programmable computers. In Proceedings of the 40th International Conference
on Machine Learning (A.Krause, E.Brunskill, K.Cho, B.Engelhardt, S.SabatoandJ.Scarlett,
eds.), vol. 202 of Proceedings of Machine Learning Research. PMLR.
Guo, T., Hu, W., Mei, S., Wang, H., Xiong, C., Savarese, S. and Bai, Y. (2023). How do trans-
formers learn in-context beyond simple functions? a case study on learning with representations.
arXiv preprint arXiv:2310.10616.
Huang, J. and Chang, K. C.-C. (2022). Towards reasoning in large language models: A survey.
arXiv preprint arXiv:2212.10403.
Huang, Y., Cheng, Y.andLiang, Y.(2023). In-contextconvergenceoftransformers. arXiv preprint
arXiv:2310.05249.
Jacot, A., Gabriel, F. and Hongler, C. (2018). Neural tangent kernel: Convergence and generaliza-
tion in neural networks. Advances in neural information processing systems, 31.
Jelassi, S., Sander, M. and Li, Y. (2022). Vision transformers provably learn spatial structure.
Advances in Neural Information Processing Systems, 35 37822–37836.
Jeon, H. J., Lee, J. D., Lei, Q. and Van Roy, B. (2024). An information-theoretic analysis of in-
context learning. arXiv preprint arXiv:2401.15530.
Kim, J. and Suzuki, T. (2024). Transformers learn nonlinear features in context: Nonconvex mean-
field dynamics on the attention landscape. arXiv preprint arXiv:2402.01258.
Laurent, B. and Massart, P. (2000). Adaptive estimation of a quadratic functional by model selec-
tion. Annals of statistics 1302–1338.
Li, Y.,Ildiz, M. E.,Papailiopoulos, D.andOymak, S.(2023a). Transformersasalgorithms: Gener-
alization and stability in in-context learning. In International Conference on Machine Learning.
PMLR.
Li, Y., Li, Y.-F. and Risteski, A. (2023b). How do transformers learn topic structure: Towards a
mechanistic understanding. arXiv preprint arXiv:2303.04245.
Lin, L., Bai, Y. and Mei, S. (2023). Transformers as decision makers: Provable in-context rein-
forcement learning via supervised pretraining. arXiv preprint arXiv:2310.08566.
29Liu, B., Ash, J. T., Goel, S., Krishnamurthy, A. and Zhang, C. (2022). Transformers learn short-
cuts to automata. arXiv preprint arXiv:2210.10749.
Mahankali, A., Hashimoto, T. B. and Ma, T. (2023). One step of gradient descent is prov-
ably the optimal in-context learner with one layer of linear self-attention. arXiv preprint
arXiv:2307.03576.
Mahdavi, S., Liao, R. and Thrampoulidis, C. (2023). Memorization capacity of multi-head atten-
tion in transformers. arXiv preprint arXiv:2306.02010.
Makkuva, A. V., Bondaschi, M., Girish, A., Nagle, A., Jaggi, M., Kim, H.andGastpar, M.(2024).
Attention with markov: A framework for principled analysis of transformers via markov chains.
arXiv preprint arXiv:2402.04161.
Marchenko, V. A. and Pastur, L. A. (1967). Distribution of eigenvalues for some sets of random
matrices. Matematicheskii Sbornik, 114 507–536.
Mu¨ller, S., Hollmann, N., Arango, S. P., Grabocka, J. and Hutter, F. (2021). Transformers can do
bayesian inference. arXiv preprint arXiv:2112.10510.
Nichani, E., Damian, A. and Lee, J. D. (2024). How transformers learn causal structure with gra-
dient descent. arXiv preprint arXiv:2402.14735.
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.et al.(2019). Languagemodels
are unsupervised multitask learners. OpenAI blog, 1 9.
Ravent´os, A., Paul, M., Chen, F. and Ganguli, S. (2023). Pretraining task diversity and the emer-
gence of non-bayesian in-context learning for regression. arXiv preprint arXiv:2306.15063.
Sanford, C., Hsu, D.andTelgarsky, M.(2023). Representationalstrengthsandlimitationsoftrans-
formers. arXiv preprint arXiv:2306.02896.
Sinii, V.,Nikulin, A.,Kurenkov, V.,Zisman, I.andKolesnikov, S.(2023). In-contextreinforcement
learning for variable action spaces. arXiv preprint arXiv:2312.13327.
Song, J. and Zhong, Y. (2023). Uncovering hidden geometry in transformers via disentangling
position and context. arXiv preprint arXiv:2310.04861.
Tarzanagh, D. A., Li, Y., Thrampoulidis, C. and Oymak, S. (2023a). Transformers as support
vector machines. arXiv preprint arXiv:2308.16898.
Tarzanagh, D. A., Li, Y., Zhang, X. and Oymak, S. (2023b). Max-margin token selection in atten-
tion mechanism. arXiv preprint arXiv:2306.13596.
Team, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J.,
Dai, A. M., Hauth, A. et al. (2023). Gemini: a family of highly capable multimodal models.
arXiv preprint arXiv:2312.11805.
Tian, Y.,Wang, Y.,Chen, B.andDu, S.(2023a). Scanandsnap: Understandingtrainingdynamics
and token composition in 1-layer transformer. arXiv preprint arXiv:2305.16380.
30Tian, Y.,Wang, Y.,Zhang, Z.,Chen, B.andDu, S.(2023b). Joma: Demystifyingmultilayertrans-
formers via joint dynamics of mlp and attention. arXiv preprint arXiv:2310.00535.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L(cid:32) . and
Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing
systems, 30.
Von Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A.and
Vladymyrov, M. (2023). Transformers learn in-context by gradient descent. In International
Conference on Machine Learning. PMLR.
Wu, J., Zou, D., Chen, Z., Braverman, V., Gu, Q. and Bartlett, P. L. (2023). How many pretrain-
ingtasksareneededforin-contextlearningoflinearregression? arXivpreprintarXiv:2310.08391.
Xie, S. M., Raghunathan, A., Liang, P. and Ma, T. (2021). An explanation of in-context learning
as implicit bayesian inference. arXiv preprint arXiv:2111.02080.
Xing, Y., Lin, X., Suh, N., Song, Q. and Cheng, G. (2024). Benefits of transformer: In-context
learning in linear regression tasks with unstructured data. arXiv preprint arXiv:2402.00743.
Zhang, R.,Frei, S.andBartlett, P. L.(2023a). Trainedtransformerslearnlinearmodelsin-context.
arXiv preprint arXiv:2306.09927.
Zhang, Y., Liu, B., Cai, Q., Wang, L. and Wang, Z. (2022). An analysis of attention via the lens
of exchangeability and latent variable models. arXiv preprint arXiv:2212.14852.
Zhang, Y., Zhang, F., Yang, Z. and Wang, Z. (2023b). What and how does in-context learn-
ing learn? bayesian model averaging, parameterization, and generalization. arXiv preprint
arXiv:2305.19420.
31Contents
1 Introduction 1
1.1 Our Approach: Tracking the Spectral Dynamics. . . . . . . . . . . . . . . . . . . . . 3
1.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2 Preliminaries 6
2.1 One-Layer Multi-Head Softmax Attention Model . . . . . . . . . . . . . . . . . . . . 6
2.2 In-Context Learning of Multi-Task Linear Regression . . . . . . . . . . . . . . . . . . 7
3 Dynamics of Gradient Flow: Emergence and Convergence 9
3.1 Decomposable Weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.2 Analysis of Gradient Flow Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
4 Optimality of Convergence Point of Gradient Flow 15
4.1 The Single-Head Case: Allocation of Attention Budget . . . . . . . . . . . . . . . . . 16
4.2 The Multi-Head: Equiangular Lower Bound and Bayesian Risk . . . . . . . . . . . . 18
4.3 Softmax-Induced Regularization and Proof Sketch for the Optimality Results . . . . 20
4.3.1 Loss Decomposition and Softmax-Induced Regularization . . . . . . . . . . . 20
4.3.2 Exponential and Saturation Regime of Softmax Attention . . . . . . . . . . . 22
4.3.3 Proof Sketch for the Optimality Results . . . . . . . . . . . . . . . . . . . . . 24
5 Extensions 25
5.1 Similarity between Softmax Attention and Linear Attention . . . . . . . . . . . . . . 25
5.2 Length Generalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
5.3 Linear-to-Nonlinear Transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
6 Conclusion and Future Work 27
A Additional Notations and Organization of the Appendices 33
B Characterizing the Moments of the Attention Probability 35
B.1 Monotonicity of E[∥p∥2|∥Wq∥ = r] with respect to r . . . . . . . . . . . . . . . . . 35
2 2
B.2 Approximating E[p⊤pr|q] for small ∥Wq∥ . . . . . . . . . . . . . . . . . . . . . . . . 36
2
B.3 Controlling the Higher Order Moments. . . . . . . . . . . . . . . . . . . . . . . . . . 41
B.4 Understanding E[∥p∥2|q] for large ∥Wq∥ . . . . . . . . . . . . . . . . . . . . . . . . 41
2 2
C Simplification and Approximation of the Gradient Flow Dynamics 48
C.1 Simplification Induced by the Decomposability Condition . . . . . . . . . . . . . . . 48
C.1.1 Simplification of A(h) and B(h) under the Decomposability Condition . . . . . 48
(h) (h)
C.1.2 Simplification of A and B with Gaussian Covariate . . . . . . . . . . . 51
XX Y
C.2 Approximation of the Spectral Dynamics . . . . . . . . . . . . . . . . . . . . . . . . 57
C.2.1 Low-Effective Order Approximation to the Derivatives of Softmax Attention
Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
(h) (h)
C.2.2 Error Analysis for the Approximation of A and B . . . . . . . . . . . . 64
XX Y
C.2.3 Further Approximation for Symmetric Weights . . . . . . . . . . . . . . . . . 66
C.3 Preservation of The Decomposability Condition along Gradient Flow . . . . . . . . . 68
32D Analysis of the Spectral Gradient Flow 71
D.1 Warm-up Stage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
D.1.1 Step 1: Growth of ρ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
i
D.1.2 Step 2: Growth of
ω⋆/ω(h)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
i i
D.1.3 Step 3: Growth of
µ⋆/µ(h)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
i i
D.1.4 Step 4: Growth of ρ⋆ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
i
D.1.5 Step 5: Lottery Winner Dominates . . . . . . . . . . . . . . . . . . . . . . . . 91
D.2 Growing Stage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
D.2.1 Coupled Growth of µ⋆ and ω⋆. . . . . . . . . . . . . . . . . . . . . . . . . . . 103
i i
D.2.2 Duration of the Growing Stage. . . . . . . . . . . . . . . . . . . . . . . . . . . 105
D.2.3 Verifying the Conditions for the Growing Stage. . . . . . . . . . . . . . . . . 106
D.2.4 Emergence and Convergence of the Growing Stage . . . . . . . . . . . . . . . 109
D.3 Dynamics Path . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
E Optimality 114
E.1 Optimality of Single-Head Attention . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
E.1.1 Rewriting and Lower Bounding the Loss Function . . . . . . . . . . . . . . . 115
E.1.2 Approximations of Nonlinear Functions f and f . . . . . . . . . . . . . . . . 117
1 2
E.1.3 The Optimal Attention Budget is Bounded . . . . . . . . . . . . . . . . . . . 118
E.1.4 Perturbation Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
E.1.5 Proof of The Main Theorem and Its Consequences . . . . . . . . . . . . . . . 124
E.2 Lower Bound for Multi-Head Attention . . . . . . . . . . . . . . . . . . . . . . . . . 128
E.3 Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
F Generalization 136
F.1 Length Generalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
F.2 Generalization to Nonlinear Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
G Auxiliary Results 139
G.1 Proof of Auxiliary Results in §C.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
G.1.1 Proof of Lemma C.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
G.1.2 Proof of Lemma C.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
G.2 Proof of Auxiliary Results in §C.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
G.2.1 Proof of Lemma C.13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
G.2.2 Proof of Lemma C.15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
A Additional Notations and Organization of the Appendices
Addition Notations for Proofs. For a polynomial f(x ,...,x ) = (cid:81)n xai of n variables
1 n i=1 i
x ,...,x where a ,...,a are positive integers, we say that f is even if all a ’s are even. For any
1 n 1 n i
dimension d, we denote by 1 the d-dimensional all-one vector. We denote by Diag(M) the column
d
vector created from the diagonal entries of M and diag(v) the diagonal matrix created from the
vector v. We denote by u⊗v the outer product of vectors u and v, and denote by A⊗ B the
K
Kronecker product of matrices A and B. Following the convention for tensor inner product, we
(cid:80) .
denote by A·B the inner product of tensors A and B such that A·B = A B , A.B the
k :,k k,:
33. (cid:80)
double inner product of tensors A and B such that A.B = A B . Here, the “:” in A
kl :,k,l l,k,: :,k
hides the indices of A except for the last dimension(s).
Roadmap of the Appendices. The remainder of the appendices is organized as follows:
1. AppendixBcontainsresultsonthe(conditional)momentsoftheattentionprobabilityvector.
2. Section C contains the simplification and approximation of the gradient flow dynamics under
the Decomposability Condition. In particular
(a) Appendix C.1 provides simplifications of the gradient flow dynamics induced by the
Decomposability Condition.
(b) AppendixC.2containstheapproximationofspectraldynamicsinducedbygradientflow.
(c) Appendix C.3 provides the proof of Lemma 3.2, the preservation of the Decomposability
Condition along gradient flow.
3. Appendix D contains the analyses for the dynamics.
4. Appendix E presents the optimality analysis of the convergence point of gradient flow.
5. Appendix F contains the proofs for the generalization results.
6. Appendix G collects the proofs of auxiliary results used in the analysis.
34B Characterizing the Moments of the Attention Probability
Notations. Inthissection,wecharacterizethecorrelationoftheattentionprobabilityE[(ph)⊤ph′|q]
by providing an upper and lower bound for this quantity. The idea is to construct a gradient flow
dynamics starting from zero for the attention weight Wh and Wh′ and bounding the terms in the
gradient flow dynamics. In the sequel, we denote by p and prtwo attention probability vectors, and
Ă
by W and W the corresponding weight matrices, and they are related by
p = softmax(X⊤Wq), pr= softmax(X⊤WĂ q), where
X = (cid:2) x ,...,x (cid:3) ∈ Rd×L, x i. ∼i.d. N(0,I ),∀l ∈ [L].
1 L l d
Here, q ∈ Rd is the query vector and we have q ∼ N(0,I ). In addition, we define the kernel
d
matrices P ∈ RL×L and Pr ∈ RL×L as
P = diag(p)−pp⊤, Pr = diag(pr)−prpr⊤.
B.1 Monotonicity of E[∥p∥2|∥Wq∥ = r] with respect to r
2 2
Let r = ∥Wq∥ . Note that E[∥p∥2|q] is just a function of r as we have shown in the previous
2 2
section. Thus, we also abbreviate E[∥p∥2|q] into E[∥p∥2|∥Wq∥ = r]. Note the there is still a gap
√ √ 2 2 2
for r ∈ (c−1 2logL,O( 2logL3 ). To fully understand the behavior of the transformer so as to
give the optimality result, we need to show that E[∥p∥2|∥Wq∥ = r] is a growing function of r,
2 2
which is presented in the following lemma.
Lemma B.1. Under the softmax attention structure and let p be the attention probability vector.
Suppose attention score is calculated by s = x⊤Wq. Then E[∥p∥2|∥Wq∥ = r] is a monotone
i i 2
function of r.
Proof of Lemma B.1. We let w = x⊤Wq/∥Wq∥ and the attention score is just given by s = w r.
l l 2 l i
We directly take the derivative of ∥p∥2 with respect to r and obtain that
2
L (cid:32) (cid:33)2
d
∥p∥2 =
d (cid:88) exp(rw i)
dr 2 dr (cid:80)L exp(rw )
i=1 j=1 j
(cid:80) (cid:80)
2w exp(2rw ) exp(rw )−exp(2rw )2 exp(rw )x
(cid:88) i i j=1 j i j j j
=
(cid:16) (cid:17)3
(cid:80)
i jexp(rw j)
(cid:80) (cid:80) (cid:80) (cid:80)
w exp(2rw ) exp(rw )− exp(2rw ) exp(rw )w
i i i j=1 j i i j j j
= 2· .
(cid:16) (cid:17)3
(cid:80)
exp(rw )
j j
We denote by v = exp(rw ). The numerator can be rewritten as
i i
(cid:88) (cid:88) (cid:88) 1 (cid:88) 1 (cid:88)
w v2v − w v2v = (w −w )v2v = (w −w )v2v + (w −w )v2v
i i j j i j i j i j 2 i j i j 2 j i j i
ij ij ij ij ij
1 (cid:88)
= (w −w )(v −v )v v ≥ 0.
i j i j i j
2
ij
Note that since v is a monotone function of w , and by nonnegativity of v , we have the above term
i i i
to be nonnegative. Therefore, we claim that ∥p∥2 is a monotonically increasing function of r, and
2
hence does E[∥p∥2|∥Wq∥ = r].
2 2
35B.2 Approximating E[p⊤pr|q] for small ∥Wq∥
2
Ă
Construct Pseudo Dynamics. We consider a constant-speed gradient flow on W(t) and W(t)
Ă
within time interval t ∈ [0,1] with initial condition W(0) = W(0) = 0 and terminal condition
W(1) = W and WĂ (1) = WĂ . The gradient flow for E[p⊤pr|q] is given by
∂ tE[p⊤pr|q] = (cid:88) E(cid:2) ∂ tp lpr
l
+p l∂ tpr l(cid:12) (cid:12)q(cid:3)
l
= (cid:88) E(cid:104) P lmpr
l
·x⊤ m∂ tWq+p lPr lm·x⊤ m∂ tWĂ q(cid:12) (cid:12)q(cid:105)
lm
= (cid:88) E(cid:104) ∇⊤ xm(P lmpr l)∂ tWq+∇⊤ xm(Pr lmp l)∂ tWĂ q(cid:12) (cid:12)q(cid:105) . // Stein’s Lemma
lm
Here, we use the Stein’s Lemma to derive the last equality. Next, we expand the gradient and
obtain
∂ tE[p⊤pr|q] = (cid:88) E(cid:104) P lm(1−2p m)pr
l
·q⊤W⊤∂ tWq+P lmPr lmq⊤WĂ⊤∂ tWq(cid:12) (cid:12)q(cid:105)
lm
+(cid:88) E(cid:104) Pr lmP lmq⊤W⊤∂ tWĂ q+Pr lm(1−2pr m)p
l
·q⊤WĂ⊤∂ tWĂ q(cid:12) (cid:12)q(cid:105)
lm
= E(cid:104) −2(cid:16) pr⊤p⊙2−∥p∥2 2p⊤pr(cid:17) ·q⊤W⊤∂ tWq−2(cid:16) p⊤pr⊙2−∥pr∥2 2p⊤pr(cid:17) ·q⊤WĂ⊤∂ tWĂ q(cid:12) (cid:12)q(cid:105)
+E(cid:104)(cid:16) p⊤pr−p⊤pr⊙2−pr⊤p⊙2+(p⊤pr)2(cid:17) q⊤(WĂ⊤∂
tW +∂
tWĂ⊤W)q(cid:12) (cid:12)q(cid:105)
= E(cid:104) −(cid:16) pr⊤p⊙2−∥p∥2 2p⊤pr(cid:17) ·q⊤∂ t(W⊤W)q−(cid:16) p⊤pr⊙2−∥pr∥2 2p⊤pr(cid:17) ·q⊤∂ t(WĂ⊤WĂ )q(cid:12) (cid:12)q(cid:105)
+E(cid:104)(cid:16) p⊤pr−p⊤pr⊙2−pr⊤p⊙2+(p⊤pr)2(cid:17) q⊤∂ t(WĂ⊤W)q(cid:12) (cid:12)q(cid:105) (B.1)
Our next goal is to show that p⊤pris the dominating term. A naive lower bound for p⊤pris given
by p⊤pr≥ L−1. So the claim holds if we could show that the remaining terms are of higher order
o(L−1).
Eliminate the Higher Order Terms. In the following, we consider bounding the higher order
terms in (B.1). We employ notations p ,pr,W ,WĂ to denote the attention probability vectors
t t t t
and weight matrices at time t We have p = pr = 0,W = WĂ = 0 at initialization and p =
0 0 0 0 1
p,pr = pr,W = W,WĂ = WĂ at terminal time. We work in the region τ2:=max{∥Wq∥2,∥WĂ q∥2} ≤
1 1 1 2 2
c−2 ·2logL for some absolute constant c. The result for representing the pseudo dynamics with
only the dominating term is given by the following lemma.
Lemma B.2. Fix constant ϵ ∈ (0,1) and let c > 0 be the solution to the fixed-point equation
1 3
+ = ϵ.
(cid:112)
c 1+ 1+c2/2
If τ2:=max{∥Wq∥2,∥WĂ q∥2} ≤ c−2·2logL holds, we have for E[p⊤pr|q] that
2 2
(cid:12)
(cid:12)
exp(cid:0) q⊤WĂ ⊤Wq(cid:1)(cid:12)
(cid:12)
ξ :=(cid:12)E[p⊤pr| q]− (cid:12) = O(L−2(1−ϵ)).
L (cid:12) L (cid:12)
(cid:12) (cid:12)
36Also, for the higher order terms, we also have
(cid:110) (cid:111)
max E[p⊤pr⊙2|q], E[pr⊤p⊙2|q], E[∥p ∥2p⊤pr |q], E[∥pr∥2p⊤pr |q], E[(p⊤pr)2|q]
t t t t t 2 t t t 2 t t t t
≤ O(L−2(1−ϵ)).
Proof of Lemma B.2. The first step is to put an upper bound for the maximum of the softmax
probability p . It suffices to look at the attention scores s = x⊤Wq, which are i.i.d.distributed
l l l
as N(0,∥Wq∥2), and the variance is bounded by ∥Wq∥2 ≤ τ2. Using the Gaussian tail bound, we
2 2
have
(cid:18) (cid:19)
P maxs > τσ·(cid:112) 2logL ≤ L−σ2+1, ∀σ > 1.
l
l∈[L]
Also, we are able to bound the number of negative attention scores by invoking the Hoeffding’s
inequality that
(cid:32) (cid:33)
(cid:88) L
(cid:18) 2(L/4)2(cid:19) (cid:18) L(cid:19)
P 1(s ≥ 0) < ≤ exp − = exp − .
m
4 L 8
m
We define the event E (W) for the softmax probability p(t) over time t ∈ [0,1] as
1
  √
  exp(τσ 2logL)
E 1(W) = max p l(t) < ζ(τ,σ;L) , where ζ(τ,σ;L) = ≤
4L2 cσ−1.
(B.2)
l∈[L],  L/4
t∈[0,1]
Ă
The event E(W) is defined similarly. One can bound the probability of Ec as
1
 √ (cid:12)  (cid:32) (cid:33)
P(E 1c) ≤ P m l∈[a Lx
],
p l(t) > exp(τσ L/42logL) (cid:12) (cid:12)
(cid:12)
(cid:88) 1(s m ≥ 0) ≥ L 4+P (cid:88) 1(s m ≥ 0) < L
4
t∈[0,1] m m
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:112) L
≤ P maxs > τσ 2logL +exp −
l
l∈[L] 8
(cid:18) (cid:19)
L
≤
L−σ2+1+exp
− ,
8
where the second inequality holds since (cid:80) exp(s ) ≥ (cid:80) 1(s > 0) ≥ L/4 for the normalization
m m m m
Ă Ă
of p. As a result, we consider two disjoint events E (W)∩E (W), Ec(W)∪Ec(W) and obtain that
1 1 1 1
(cid:110) (cid:111)
max E[p⊤pr⊙2|q], E[pr⊤p⊙2|q], E[∥p ∥2p⊤pr |q], E[∥pr∥2p⊤pr |q], E[(p⊤pr)2|q]
t t t t t 2 t t t 2 t t t t
≤
L·ζ(τ,σ;L)3+P(Ec(W)∪Ec(WĂ
))
1 1
≤
64L6 cσ−2+2L−σ2+1+2exp(−L/8).
(B.3)
Here, the first inequality holds by noting that p ,pr ≤ ζ(τ,σ;L) element-wise on E (W)∩E (WĂ )
l l 1 1
and that each term in the maximum is bounded by 1. Now, we select out the dominating term p⊤pr
in (B.1) and with a little abuse of notation, denote the remaining terms as err (t;q) given by
>1
err (t;q) = ∂ E[p⊤pr |q]−E[p⊤pr |q]q⊤∂ (WĂ⊤W )q.
>1 t t t t t t t t
37Then, (B.3) implies that
(cid:12) (cid:12) (cid:16) (cid:17)
(cid:12) (cid:12)err (t;q)(cid:12)
(cid:12)
≤ 64L6 cσ−2+2L−σ2+1+2exp(−L/8)
>1
·(cid:16)(cid:12) (cid:12)q⊤(cid:16) ∂ (W⊤W )+∂ (WĂ⊤WĂ )(cid:17) q(cid:12) (cid:12)+2(cid:12) (cid:12)q⊤∂ (WĂ⊤W )q(cid:12) (cid:12)(cid:17)
(cid:12) t t t t t t (cid:12) (cid:12) t t t (cid:12)
(cid:16) (cid:17)
≤ 4 64L6 cσ−2+2L−σ2+1+2exp(−L/8) τ2,
where the last inequality holds since we have constant speed. From the dynamics (B.1), we have
∂ (cid:16) exp(cid:0) −q⊤WĂ⊤W q(cid:1) ·E[p⊤pr |q](cid:17) = exp(cid:0) −q⊤WĂ⊤W q(cid:1) ·err(t;q).
t t t t t t t
By integrating the above equation from t = 0 to t = 1, we have
(cid:12)
(cid:12)
exp(cid:0) q⊤WĂ ⊤Wq(cid:1)(cid:12)
(cid:12)
(cid:12)E[p⊤pr| q]− (cid:12)
(cid:12) L (cid:12)
(cid:12) (cid:12)
(cid:12)(cid:90) 1 (cid:12)
= (cid:12) (cid:12) exp(cid:0) −q⊤WĂ t⊤W tq(cid:1) ·err(t;q)dt(cid:12) (cid:12)·exp(cid:0) q⊤WĂ⊤Wq(cid:1)
(cid:12) (cid:12)
0
(cid:16) (cid:17)
exp(cid:0) q⊤WĂ ⊤Wq(cid:1)
−1
≤ 4 64L6 cσ−2+2L−σ2+1+2exp(−L/8) τ2·
Ă
q⊤W⊤Wq
(cid:16) (cid:17)
≤ 4
64L6 cσ−2+2L−σ2+1+2exp(−L/8) ·exp(cid:0) τ2(cid:1)
. (B.4)
We invoke the upper bound for τ2 to obtain the final result,
(cid:12)
(cid:12)
exp(cid:0) q⊤WĂ ⊤Wq(cid:1)(cid:12)
(cid:12) (cid:16) (cid:17)
(cid:12)E[p⊤pr| q]− (cid:12) ≤ 4 64L2c−2+6σc−1−2+2L−σ2+1+2c−2 +2L2c−2−L(logL)−1/8 .
(cid:12) L (cid:12)
(cid:12) (cid:12)
(cid:112)
Here, we plug in σ = c·(1+ 1+c2/3)−1 which make the first and second terms equal in order.
We also note that the third term is of higher order. Hence, for each fixed constant ϵ ∈ (0,1), we
can always find c > 0 satisfying the fixed-point condition
1 3
+ = ϵ,
(cid:112)
c 1+ 1+c2/2
Ă
such that for all τ2:=max{∥Wq∥2,∥Wq∥2} ≤ c−2·2logL:
2 2
(cid:12)
(cid:12)
exp(cid:0) q⊤WĂ ⊤Wq(cid:1)(cid:12)
(cid:12)
√
(cid:12)E[p⊤pr| q]− (cid:12) ≤ O(L2(c−2−1)+6·(1+ 1+c2/2)−1 ) = O(L−2(1−ϵ)).
(cid:12) L (cid:12)
(cid:12) (cid:12)
Notably, the error term in (B.3) is strictly less than the error term in (B.4). Hence for the higher
order terms, we also have
(cid:110) (cid:111)
max E[p⊤pr⊙2|q], E[pr⊤p⊙2|q], E[∥p ∥2p⊤pr |q], E[∥pr∥2p⊤pr |q], E[(p⊤pr)2|q]
t t t t t 2 t t t 2 t t t t
≤ O(L−2(1−ϵ)).
Hence, the proof is complete.
38Concentration in q. Next, we take expectation with respect to q ∼ N (0,I ). It suffices to
D
consider the expectation
E(cid:2) exp(q⊤WĂ ⊤Wq)(cid:3)
according to Lemma B.2. The following lemma char-
acterizes the expectation term.
LemmaB.3. ConsiderthatW ∈ RD×D andWĂ ∈ RD×D sharethesamelefteigenvectorsw ,...,w
1 D
and also the same right eigenvectors u ,...,u , i.e., W = (cid:80)d ω w u⊤ and WĂ = (cid:80)d ωr w u⊤.
1 D k=1 k k k k=1 k k k
Ă
Here, d is the effective rank for W and W. Suppose
2logL
max{∥ωr∥ ,∥ω∥ } ≤ L−1/4·(logL)−1/2, max{∥ω∥2,∥ωr∥2} ≤ ,
∞ ∞ 2 2 3c2
max{∥ω∥4,∥ωr∥4} ≤ L−(1−ϵ0)·(logL)−1
4 4
where c > 0 is a constant depending on a given constant ϵ ∈ (0,1) via the fixed-point equation
1 3
+ = ϵ,
(cid:112)
c 1+ 1+c2/2
and ϵ ∈ (0,1) is a constant whose purpose is to make sure ω = d−1/21 satisfies the forth moment
0
condition and could also be chosen to be the same as ϵ. It then holds that
  (cid:16) Ă (cid:17)2
exp Tr[W⊤W]
E E[p⊤pr|q]−   ≤ O(L−(3−ϵ0)).
 L 
Ă
Proof of Lemma B.3. UndertheconditionthatW andW havethesameleftandrighteigenvectors,
itsufficestostudythequantityE(cid:2) exp((cid:80)d ω ωr v2)(cid:3) wherev i. ∼i.d. N(0,1). Here,disthemaximal
k=1 k k k k
rank of W and WĂ , and ω and ωr are the eigenvalues of W and WĂ within the effective dimensions,
k k
respectively. We also denote by ω and ωr the vector of eigenvalues for W and WĂ when there is no
ambiguity. Note that v2 is a chi-square random variable. We invoke the following tail bound for
k
chi-square distribution, which is given by Lemma 1 in Laurent and Massart (2000).
(cid:32) (cid:88)d (cid:88)d √ (cid:33)
P ω ωr v2− ω ωr ≥ 2∥ω⊙ωr∥ x+2∥ω⊙ωr∥ x ≤ exp(−x), (B.5)
k k k k k 2 ∞
k=1 k=1
(cid:32) (cid:88)d (cid:88)d √ (cid:33)
P ω ωr v2− ω ωr ≤ −2∥ω⊙ωr∥ x ≤ exp(−x).
k k k k k 2
k=1 k=1
For our purpose, we take x = 4logL, which gives
(cid:32)(cid:12) d d (cid:12) (cid:33)
(cid:12)(cid:88) (cid:88) (cid:12) (cid:112) 2
P (cid:12) ω ωr v2− ω ωr (cid:12) ≥ 2∥ω⊙ωr∥ 4logL+8∥ω⊙ωr∥ logL ≤ . (B.6)
(cid:12) k k k k k(cid:12) 2 ∞ L4
(cid:12) (cid:12)
k=1 k=1
Ă
Define the above event as Ec(W,W). Before we proceed, one must be aware that to use Lemma B.2
2
for approximating E(cid:2) p⊤pr|q(cid:3) with exp(q⊤WĂ ⊤Wq), we need to show that event
E (W):=(cid:8) ∥Wq∥2 ≤ c−2·2logL(cid:9)
3 2
39also holds with high probability. To show this point, we have by (B.5) where ωr is replaced by ω
and x = 4logL that
P(cid:16) ∥Wq∥2 ≥ ∥ω∥2+4∥ω∥2(cid:112) logL+8∥ω∥2 logL(cid:17) ≤ L−4. (B.7)
2 2 4 ∞
Note that under the conditions
logL 2logL 1
max{∥ω∥4,∥ωr∥4} ≤ , max{∥ω∥2,∥ωr∥2} ≤ , max{∥ω∥ ,∥ωr∥ } ≤ √ , (B.8)
4 4 36c4 2 2 3c2 ∞ ∞ 12c
itfollowsthatP(Ec(W)) = P(cid:0) ∥Wq∥2 ≥ c−2·2logL(cid:1) ≤ L−4, andthesameholdsforEc(WĂ ). Hence,
3 2 3
we are able to control the difference between E[p⊤pr] and exp(ω⊤ωr)/L by
 
(cid:32) exp(cid:0) ω⊤ωr(cid:1)(cid:33)2
E

E[p⊤pr|q]−

L
 
≤ E
(cid:32)
E[p⊤pr|q]−
exp(cid:0) ω⊤ωr(cid:1)(cid:33)2
·1(cid:104) E 2(W,WĂ )∩E 3(W)∩E 3(WĂ )(cid:105) 
L
+(cid:16) P(cid:0) Ec(W,WĂ )(cid:1) +P(cid:0) Ec(W)(cid:1) +P(cid:0) Ec(WĂ )(cid:1)(cid:17)
·2(cid:32)
1+
2exp(cid:0) ω⊤ωr(cid:1)(cid:33)
2 3 3 L2
exp(cid:0) 2ω⊤ωr(cid:1)
(cid:16) (cid:16) (cid:112) (cid:17) (cid:17)2
≤ 2· · exp 2∥ω⊙ωr∥ 4logL+8∥ω⊙ωr∥ logL −1 +ξ2
L2 2 ∞ L
6
(cid:32) exp(cid:0) 2ω⊤ωr(cid:1)(cid:33)
+ · 1+ ,
L4 L2
where the second inequality holds by using the approximation result in Lemma B.2 with ξ =
L
O(L−2(1−ϵ)), and the last inequality holds by plugging in (B.6). Under the condition
max{∥ωr∥ ,∥ω∥ } ≤ L−1/4·(logL)−1/2, max{∥ω∥4,∥ωr∥4} ≤ L−(1−ϵ0)·(logL)−1,
∞ ∞ 4 4
it is easy to show that
(cid:16) (cid:112) (cid:17)
exp 2∥ω⊙ωr∥ 2logL+4∥ω⊙ωr∥ logL −1 ≤ O(L−(1−ϵ0)/2),
2 ∞
6
(cid:32) exp(cid:0) 2ω⊤ωr(cid:1)(cid:33)
· 1+ = O(L−4), ξ = O(L−2(1−ϵ)).
L4 L2 L
As a result, we conclude that
 
(cid:32) exp(cid:0) ω⊤ωr(cid:1)(cid:33)2
E  E[p⊤pr|q]−  ≤ O(L−(3−ϵ0)),
L
which completes the proof.
40B.3 Controlling the Higher Order Moments.
Lemma B.4. Under Definition C.9, consider a G-induced polynomial f (p,pr) = (cid:81) (cid:0) pavprbv(cid:1) ·
G v∈V v v
(cid:81) δ and let Ord(G)=∆ (cid:80) (a +b )−|CC (G)| be the effective order of G. Here, p and
(v,v′)∈E vv′ v∈V v v ≥1
pr are the attention probability vectors for W and WĂ , respectively. Suppose Ord(G) ≥ κ = 2. Fix
√
2Deg(G) 2κ+1 (cid:80)
any ϵ ∈ (0,1) and let c ≥ where Deg(G) = (a +b ). If
ϵκ v∈V v v
logL 2logL 1
max{∥ω∥4,∥ωr∥4} ≤ , max{∥ω∥2,∥ωr∥2} ≤ , max{∥ω∥ ,∥ωr∥ } ≤ √
4 4 36c4 2 2 3c2 ∞ ∞ 12c
holds, we have
E(cid:2) f (p,pr)2(cid:3) ≤ O(L−4(1−ϵ)).
G
Proof of Lemma B.4. Let n = |CC (G)| and Deg(G) =
(cid:80)n
(a +b ). The argument is a com-
≥1 v∈V v v
bination of the general ideas in Lemma B.2 and Lemma B.3. Let us first fix a query q. On the
Ă
success of the event E (W)∩E (W) defined in (B.2), one has by definition that
1 1
(cid:16) (cid:17)2m
f G(p,pr)2 ≤ 4L2 cσ−1 ·L2n = 16Deg(G)·L4 cσDeg(G)·L−2Ord(G),
The failure probability for this joint event is at most 2(cid:0) L−σ2+1 + L− 8loL gL(cid:1) as we have shown
Ă
in the proof of Lemma B.2 if E (W) ∩ E (W) holds. Here, E (W) is defined by the success of
3 3 3
∥Wq∥2 ≤ c−2·2logL. Notethat|f (p,pr)| ≤ 1. Therefore, wehaveonthesuccessofE (W)∩E (WĂ )
2 G 3 3
that
E(cid:2) f(p,pr)2|q(cid:3)
≤
16Deg(G)·L4 cσDeg(G)·L−2κ+2(cid:16) L−σ2+1+L− 8loL gL(cid:17)
.
√
Wetakeσ = 2κ+1. Bychoosingaconstantc = (2σDeg(G))/(ϵ·κ)accordingtoϵ,thetotaldegree
Deg(G), and κ, we obtain that E(cid:2) f(p,pr)2|q(cid:3) ≤ O(L−2κ·(1−ϵ)) on the success of E (W)∩E (WĂ ).
3 3
Ă
Following the conditions in (B.8) on the failure probability of E (W)∩E (W), we have
3 3
E(cid:2) f(p,pr)2(cid:3)
=
E(cid:2)E[f(p,pr)2|q](cid:3)
≤
E(cid:104) E[f(p,pr)2|q]·1(cid:104)
E (W)∩E
(WĂ )(cid:105)(cid:105) +P(Ec(W))+P(Ec(WĂ
))
3 3 3 3
≤ O(L−2κ·(1−ϵ))+O(L−4) ≤ O(L−4(1−ϵ)),
where in the first inequality we use the fact that |f (p,pr)| ≤ 1 and in the last inequality we use the
G
same conditions as (B.8) in order to invoke (B.7). Thus, we complete the proof.
B.4 Understanding E[∥p∥2|q] for large ∥Wq∥
2 2
Previously, we have a thorough understanding of the behavior of E[∥p∥2] as ∥Wq∥2 ≤ c−2·2logL.
2 2
We are still lacking understanding of what happens if ∥Wq∥2 ≫ c−2 · 2logL. In this section,
2
we give a characterization of the behavior of E[∥p∥2|q]. Note that ∥p∥2 ≤ 1. When ∥Wq∥
2 2 2
gets large, we anticipate ∥p∥2 to get closer to 1. Hence, we instead understand the behavior of
2
h(r) = 1−E[∥p∥2|q], where r = ∥Wq∥ . In the following, we provide an upper bound for h(r).
2 2
41Lemma B.5. Define h(r) = 1 − E[∥p∥2|∥Wq∥ = r]. Take a small constant ϵ ∈ (0,1). For
√ 2 2
3/ϵ
r ≥ O( 2logL ), it holds that
h(r) = E[1−∥p∥2] ≤ O(r−(1−ϵ)).
2
Proof of Lemma B.5. Let p ,...,p be the elements of p in the descending order. In the follow-
1 L
ing , we consider r to be fixed and the expectation is taken only with respect to the context
X (or equivalently, attention probability p). We let s ,...,s be the attention score calculated
1 L
by x⊤Wq,...,x⊤Wq, also in the same descending order and let z ,...,z be the projection of
1 L 1 L
x ,...,x onto the direction of Wq. We have
1 L
h(r) ≤ E[1−p2] = E[(1−p )(1+p )] ≤ 2E[1−p ] = 2·E[p +···+p ].
1 1 1 1 2 L
Also we note that
p
1
= exp(s −s ) = exp(r(z −z )) ⇒ p ≤ p exp(−r(z −z )) ≤ exp(−r(z −z )).
1 l 1 l l 1 1 l 1 l
p
l
Hence,
(cid:34) L (cid:35)
(cid:88)
h(r) ≤ 2E exp(−r(z −z )) .
1 l
l=2
We split the summation into two parts depending on whether z −z ≤ log(Lrα)/r, where α > 1/2
1 j
is a constant to be determined later. Thereby,
(cid:20) (cid:21)
(cid:88)
h(r) ≤ 2E exp(−r(z −z ))+ exp(−r(z −z ))+Lexp(−r·log(Lrα)/r)
1 2 1 j
j≥3:z1−zj≤log(Lrα)/r
2
≤ 2E[(N +1)exp(−r(z −z ))]+ ,
1 2 rα
where N is the size of {j ∈ {3,...,L} : z −z ≤ log(Lrα)/r} and is also a random variable. Here,
1 j
we remark that in the second inequality, we just lower bound z −z by the minimum z −z . We
1 j 1 2
pick some small constant a ∈ (0,1) and note that
2E[(N +1)exp(−r(z −z ))]
1 2
(cid:104) (cid:112) (cid:105) (cid:104) (cid:112) (cid:105)
= 2E (N +1)exp(−r(z −z ))1(z > 2alogL) +2E (N +1)exp(−r(z −z ))1(z ≤ 2alogL)
1 2 1 1 2 1
(cid:104) (cid:112) (cid:105) (cid:112)
≤ 2E (N +1)exp(−r(z −z ))1(z > 2alogL) +2LP(z ≤ 2alogL)
1 2 1 1
(cid:32) (cid:32) (cid:33) (cid:33)
1 1 1
≤ 2E[(N 1+1)exp(−r(z 1−z 2))]+2Lexp −√
2π
· √
2alogL
− √
2alogL3
L1−a , (B.9)
√
where we define N as the size of the class {j ∈ {3,...,L} : 2alogL−z ≤ log(Lrα)/r} and it is
1 √ j
obvious that N ≤ N under the condition z > 2alogL. Here, in the first inequality, we upper
1 1
bound N by L and in the second inequality, we invoke the following fact:
42Lemma B.6 (GaussianFirstOrderStatistics). Let v be the first order statistics of L i.i.d.standard
Gaussian random variables. For any a > 0:
(cid:32) (cid:32) (cid:33) (cid:33)
(cid:112) 1 1 1
P(v ≤ 2alogL) ≤ exp √ · √ − √ L1−a
2π 2alogL 2alogL3
We take a = 1−ϵ, and to make the second term in (B.9) smaller than O(r−α), we just need
√
log(cid:0) 4πlogLlog(Lrα)(cid:1)
log(logLlogr)
ϵ ≥ → = o(1),
logL logL
where the right hand side is o(1) as long as r = o(exp(L)). To this end, we just set the first
inequality to be equality for ϵ. Now, for the first term, we have
2E[(N +1)exp(−r(z −z ))]
1 1 2
(cid:20) (cid:26) (cid:18)
(cid:112)
log(Lrα) (cid:19)
(cid:112)
(cid:27) (cid:21)
= 2E ♯ j = 2,...,L : z ≥ (1−ϵ)− √ · 2logL exp(−r(z −z )
j 1 2
r 2logL
(cid:20) (cid:26) (cid:18)
(cid:112)
log(Lrα) (cid:19)
(cid:112)
(cid:27) (cid:21)
≤ 2E ♯ j ∈ [L] : z ≥ (1−ϵ)− √ · 2logL exp(−r(z −z )
j 1 2
r 2logL
= 2E[N exp(−r(z −z )],
2 1 2
where we define
(cid:26) (cid:18)
(cid:112)
log(Lrα) (cid:19)
(cid:112)
(cid:27)
N :=♯ j ∈ [L] : z ≥ (1−ϵ)− √ · 2logL
2 j
r 2logL
We note that for a standard Gaussian random variable z,
(cid:18) (cid:18)
(cid:112)
log(Lrα) (cid:19)
(cid:112)
(cid:19)
P z ≥ (1−ϵ)− √ · 2logL
r 2logL
(cid:32) (cid:33)
1 (cid:18) (cid:112) log(Lrα) (cid:19)2 1
≤ √ exp − (1−ϵ)− √ ·logL · √
2π r 2logL logL
≤ √
1 L−1+ϵ+2 rl √og 2( lL ogrα L)
=
L−1·Llog(√ 4πlo log gL Llog(Lrα)) +2 rl √og 2( lL ogrα L)−log√ lo2 gπ LlogL
.
2πlogL
whereweinvoketheupperboundP(z ≥ a) ≤ f(z)/awithf(·)beingthedensityofz. Forsimplicity,
we consider function
√ √
log(cid:0) 4πlogLlog(Lrα)(cid:1)
2log(Lrα) log 2πlogL
φ(r) ≥ + √ − ,
logL r 2logL logL
where we note that r ≪ exp(L/α) (the upper bound is because the first term in φ(r) cannot
be too large). To this end, we invoke the tail bound for binomial distribution that if N follows
2
Binom(L,q), then
P(N ≥ m) ≤ exp(−LD(m/L∥q)),
2
43where D(q ∥q ) is the KL divergence between Bern(q ) and Bern(q ). We plug in the expression
1 2 1 2
for q = Lφ(r)−1 and obtain that
(cid:18) (cid:18) (cid:18) (cid:19)(cid:19)(cid:19)
m m (cid:16) m(cid:17) m/L−q
P(N ≥ m) ≤ exp −2L log + 1− log 1+
2
L Lφ(r) L 1−m/L
(cid:16) (cid:16) m (cid:17)(cid:17)
≤ exp −2 mlog +m−Lφ(r) ,
Lφ(r)
where in the second inequality we invoke the fact that log(1+x) ≤ x. We pick m = Lφ(r)+ξ(r),
where ξ(r) > 0 is a constant depending on r to be determined later, and obtain
(cid:16) (cid:17)
P(N ≥ Lφ(r)+ξ(r)) ≤ exp −2Lφ(r)+ξ(r)·(1+ξ(r)logL)+2Lφ(r) ≤ L−2Lφ(r)+ξ(r)·ξ(r),
2
Here, the first and the third terms cancel and the second term gives the final upper bound. To this
end, we have for 2E[N exp(−r(z −z ))] that
2 1 2
2E[N exp(−r(z −z ))] ≤ 2E[N exp(−r(z −z ))1(N < Lφ(r)+ξ(r))]
2 1 2 2 1 2 2
+2E[N exp(−r(z −z ))1(N ≥ Lφ(r)+ξ(r))]
2 1 2 2
≤ 2Lφ(r)+ξ(r)E[exp(−r(z −z ))]+2L·L−2Lφ(r)+ξ(r)ξ(r).
1 2
Note that to make the second term less than O(r−α), a sufficient condition we need is
log(ξ(r)−1) αlogr
φ(r)+ξ(r)− ≥ .
logL (logL)2
Therefore,allweneedtodoiscontrollingtheMomentGeneratingFunction(MGF)forthedifference
between the Gaussian’s first and second order statistics. Let u,v be the second and the first order
statistics of z ,...,z . The joint distribution of u,v is then given by
1 L
L(L−1)
(cid:18) u2+v2(cid:19)
f(u,g) = exp − Φ(u)n−21(u ≤ v),
2π 2
where Φ is the standard Gaussian Cumulative Distribution Function (CDF). The MGF is then
given by
(cid:90) +∞(cid:90) +∞ L(L−1) (cid:18) u2+v2(cid:19)
M(r) = exp − Φ(u)n−21(u ≤ v)exp(−r(v−u))dudv
2π 2
−∞ −∞
(cid:90) +∞ L(L−1) (cid:18) u2(cid:19) (cid:90) +∞ 1 (cid:18) v2 (cid:19)
= √ exp − Φ(u)n−2exp(ru)· √ exp − −rv dv·du
2π 2 2π 2
−∞ u
(cid:90) +∞ L(L−1) (cid:18) u2(cid:19) (cid:18) r2 (cid:19)
= √ exp − Φ(u)n−2exp +ru ·(1−Φ(u+r))·du.
2π 2 2
−∞
We note that the marginal for u is (we just need to plug r = 0 into the above equation, and after
marginalizing v the remaining expression is just f(u))
L(L−1)
(cid:18) u2(cid:19)
f(u) = √ exp − Φ(u)n−2·(1−Φ(u)).
2π 2
44Notably,intheabovecalculationwefixuandonlymarginalizev. Thus,abyproductisthefollowing
fact:
(cid:18) r2 (cid:19) P(z ≥ u+r)
E[exp(−r(v−u)) |u] = exp +ru · ≤ 1.
2 P(z ≥ u)
Therefore, the MGF can also be rewritten as
(cid:20) (cid:18) r2 (cid:19) P(z ≥ u+r)(cid:21)
M(r) = E exp +ru ·
u 2 P(z ≥ u)
(cid:20) (cid:18) r2 (cid:19) P(z ≥ u+r) (cid:16) (cid:112) (cid:112) (cid:17)(cid:21)
= E exp +ru 1 u ∈ ( 2(1−rϵ)logL, 2(1+b)logL)
2 P(z ≥ u)
(cid:20) (cid:18) r2 (cid:19) P(z ≥ u+r) (cid:16) (cid:112) (cid:112) (cid:17)(cid:21)
+E exp +ru 1 u ∈/ ( 2(1−rϵ)logL, 2(1+b)logL)
2 P(z ≥ u)
(cid:20) (cid:18) r2 (cid:19) P(z ≥ u+r) (cid:16) (cid:112) (cid:112) (cid:17)(cid:21)
= E exp +ru 1 u ∈ ( 2(1−rϵ)logL, 2(1+b)logL)
2 P(z ≥ u)
(cid:16) (cid:112) (cid:112) (cid:17)
+P u ∈/ ( 2(1−rϵ)logL, 2(1+b)logL)
where we pick b ∈ (0,1) andrϵ ∈ (O((logL)−1),1) as small constant to be determined later. For the
second order statistics of L i.i.d.Gaussian random variables, we have
Fact B.7 (Gaussian Second Order Statistics). Let v,u be the first and the second order statistics
of L i.i.d.standard Gaussian random variables. Also, let z be another standard Gaussian random
variable. Then for any ϵ ∈ (O((logL)−1),1):
(cid:112) (cid:112)
P(u ≥ 2(1+ϵ)logL) ≤ P(v ≥ 2(1+ϵ)L) ≤ L−ϵ,
and
(cid:18) (cid:19)
(cid:112) (cid:112) (cid:112) L
P(u ≤ 2(1−ϵ)logL) = P(z ≤ 2(1−ϵ)logL)L−1·P(z ≥ 2(1−ϵ)logL)·
1
(cid:112)
+P(z ≤ 2(1−ϵ)logL)L
(cid:112)
≤ (L+1)·P(z ≥ 2(1−ϵ)logL)L−1
(cid:32) (cid:32) (cid:33)(cid:33)
(L−1)ϵ 1 1
≤ (L+1)·exp − √ · −
2π (cid:112) 2(1−ϵ)logL (cid:112) 2(1−ϵ)logL3
(cid:18) (L−1)ϵ (cid:19)
≤ (L+1)·exp −√ ,
4πlogL
where the last inequality holds if ϵ ≥ O(1/2logL).
Using the above fact, we deduce that
(cid:18) (L−1)ϵ (cid:19) (cid:18) r2 (cid:19) P(z ≥ u+r)
M(r) ≤ L−b+(L+1)·exp −√ + max exp +ru · ,
4πlogL u∈U(rϵ,b) 2 P(z ≥ u)
45where for our convenience, we define U(rϵ,b) = ((cid:112) 2(1−rϵ)logL,(cid:112) 2(1+b)logL). Now, we invoke
the tail bound for Gaussian distribution and obtain that
(cid:18) r2 (cid:19) P(z ≥ u+r) (cid:18) r2 (cid:19) f(u+r) (u+r)−1 u 1
exp +ru · ≤ exp +ru · · = · .
2 P(z ≥ u) 2 f(u) u−1−u−3 u+r 1−u−2
(B.10)
As the last piece of the jigsaw, we conclude that
2E[N exp(−r(z −z ))]
2 1 2
≤ 2Lφ(r)+ξ(r)E[exp(−r(z −z ))]+2L·L−2Lφ(r)+ξ(r)ξ(r)
1 2
(cid:18) (cid:18) (L−1)ϵ (cid:19) u 1 (cid:19)
≤ 2Lφ(r)+ξ(r)· L−b+(L+1)·exp −√ + max ·
4πlogL u∈U(rϵ,b) u+r 1−u−2
+2L·L−2Lφ(r)+ξ(r)ξ(r).
Now, we pick β > 0 and let
(cid:18) (L−1)rϵ (cid:19)
L−b = (L+1)·exp −√ = r−β,
4πlogL
which implies
√
βlogr log(cid:0) log L+1 · 4πlogL(cid:1)
b = , rϵ = rβ = o(1),
logL log(L−1)
where the solution also satisfies the contraint rϵ > O((logL)−1) so long as r ≪ (L+1)β−1 and we
have
u 1
max ·
u∈U(rϵ,b) u+r 1−u−2
1 1 1+O((logL)−2)
≤ · = .
1+r/(cid:112)
2(1+b)logL
1−(2(1−rϵ)logL)−2 1+r/(cid:112)
2(logL+βlogr)
Therefore, we have
2E[N exp(−r(z −z ))]
2 1 2
(cid:32) (cid:33)
2 1+O((logL)−2)
≤ 2Lφ(r)+ξ(r)· + +2L1−2Lφ(r)+ξ(r)ξ(r). (B.11)
rβ 1+r/(cid:112) 2(logL+βlogr)
To this end, it is clear that the right choice of β should be 1. Here, we recall the definition for φ(r)
that √ √
log(cid:0) 4πlogLlog(Lrα)(cid:1)
2log(Lrα) log 2πlogL
φ(r) ≥ + √ − ,
logL r 2logL logL
and the condition for picking ξ(r) is
log(ξ(r)−1) αlogr
φ(r)+ξ(r)− ≥ .
logL (logL)2
46We redefine φr(r) = logL/logr·φ(r) and ξr (r) = logL/logr·ξ(r). Then we conclude that
√ √ √
log(cid:0) 4πlogLlog(Lrα)(cid:1)
log(Lrα) 2logL log 2πlogL
φr(r) ≥ + − ,
logr rlogr logr
r
φr(r)+ξr
(r)−
log(ξ(r)−1·logL/logr)
≥
α
logr logL
To make the third term in (B.11) L1−2Lφ(r)+ξ(r)ξ(r) also less than O(r−α), a sufficient condition is
that
logL −2rφr(r)+ξr (r)ξr
(r) ≤ −α
logr
Tothisend,
wecanseedirectlythatbychoosingφr(r)andξr
(r)tobesmallconstant, sayϵ/3, allthe
√
inequalities are satisfied for r ≥ O((logL)3/2) (in order to make log(Lrα) 2logL of the scale o(1)).
rlogr
In order to make (B.11) of order O(r−α) with α = 1−ϵ, we note that the second term dominates
and we just need to ensure that
(cid:112) (cid:112) 3/ϵ
r−1+2ϵ/3 2logL ≤ r−1+ϵ ⇒ r ≥ 2logL
√
3/ϵ
and α = 1−ϵ. Therefore, we wrap our proof by concluding that for r ≥ O( 2logL ),
h(r) = E[1−∥p∥2] ≤ O(r−(1−ϵ)).
2
47C Simplification and Approximation of the Gradient Flow Dy-
namics
In this section, we first simplify the gradient flow dynamics of the MS-Attn to the eigenvalue
space under the Decomposability Condition introduced in Definition 3.1. Then we approximate
the spectral gradient flow dynamics using the results from Appendix B. As a byproduct of the
simplification of the gradient flow dynamics, we further prove that the Decomposability Condition
is preserved along the gradient flow.
C.1 Simplification Induced by the Decomposability Condition
In this section, we aim to show that the gradient flow dynamics in (2.7) admit a simplified form
under the Decomposability Condition introduced in Definition 3.1.
Recall that given the parameters Θ = {O(h),V(h),K(h),Q(h)} , the output of the the
h∈[H]
MS-Attn function, is given by (2.1). The gradient flow for minimizing the mean-squared loss L(Θ)
in (2.6) is introduced in (2.7), which involves matrices A(h) ∈ RD×D and B(h) ∈ Rdy×D defined
in (2.8) and (2.9), respectively. Here D = d+d where d and the d are the dimensions of the
y y
covariate and output, respectively. Note that these matrices depends on the attention score s(h)
and attention probability p(h) defined in (2.2), and output weight matrix U(h) given in (2.3). Thus,
both A(h) and B(h) are (perhaps complicated) functions of the parameter Θ. In the following, we
aim to prove that when Θ satisfies the Decomposability Condition, A(h) and B(h) can be diagonal-
ized using the orthogonal matrices specified by the Decomposability Condition. The main result
can be summarized in the following proposition.
Proposition C.1 (Simplification of A(h) and B(h)). Let Θ = {O(h),V(h),K(h),Q(h)} be a
h∈[H]
set of parameters and let A(h) and B(h) be functions of Θ defined according to (2.8) and (2.9),
respectively. We use subscripts X and Y to indicate the indices that corresponds to the covariate
or the response, i.e., X indicate {1,...,d} and Y indicates {d+1,...,D}. Then, when Θ satisfy
the Decomposability Condition in Definition 3.1, A(h) and B(h) can be written as
(cid:34) (cid:35) (cid:34) (cid:35)
A(h) A(h) A(h) 0 (cid:104) (cid:105) (cid:104) (cid:105)
A(h) = XX XY = XX , B(h) = B(h) B(h) = 0 B(h) . (C.1)
A(h) A(h) 0 0 X Y Y
YX YX
That is, only the top-left block of A(h) and the right block of B(h) are non-zero. Moreover, these two
nonzero blocks can be diagonalized by orthogonal matrices Φ and Ψ, respectively, where Φ and Ψ are
introduced by the Decomposability Condition in Definition 3.1. That is,
Φ⊤A(h)
Φ and
Ψ⊤B(h)
Ψ
XX Y
are diagonal matrices.
In the rest of this section, we provide a proof of Proposition C.1. Our proof is split into two
parts. First, we use the Decomposability Condition to prove the results in (C.1). Then we use
the fact that the covariates are Gaussian distributed to show that the non-zero blocks can be
diagonalized by the orthogonal matrices Φ and Ψ.
C.1.1 Simplification of A(h) and B(h) under the Decomposability Condition
Proof. (Proof of Equation (C.1) in Proposition C.1) We first simplify the expression for A(h) and
B(h) in (2.8) and (2.9) under the Decomposability Condition introduced in Definition 3.1, which
gives us (C.1).
48Simplification of A(h). By the definition of A(h) in (2.8), we have
H
A(h) = −E(cid:104) ZP(h)⊤ Z⊤U(h)⊤ y z⊤(cid:105) + (cid:88) E(cid:104) ZP(h)⊤ Z⊤U(h)⊤ U(h′)Zp(h′)z⊤(cid:105) . (C.2)
q q q
(cid:124) (cid:123)(cid:122) (cid:125) h′=1(cid:124) (cid:123)(cid:122) (cid:125)
=∆ A(h,0) =∆ A(h,h′)
Recall that s(h) and p(h) in (2.2) are the attention score and probability vectors, and P(h) =
diag(p(h))−p(h)p(h)⊤ . Also recall the definition of U(h) and W(h) in (2.3). By Definition 3.1(i), we
have W(h) = 0, where W(h) is the bottom left block of W(h). As a result, since the last d indices
Y Y y
of z is zero, we have s(h) = Z⊤W(h)z = X⊤W(h) q. This implies that p(h) depends only on the
q q X
covariates X and the query q, and thus ph,G,ε are independent of each other.
Now we write Y = G⊤X +ε where ε ∈ Rdy×L stands for the noise terms in Y. Hence, we can
write Z as in the following form:
(cid:20) (cid:21) (cid:20) (cid:21) (cid:20) (cid:21)
X I 0
d
Z = = X + . (C.3)
Y G⊤ ε
Substituting Z using (C.3) into (C.2), we can write A(h,0) as
(cid:20)(cid:18)(cid:20) (cid:21) (cid:20) (cid:21)(cid:19) (cid:21)
A(h,0) = −E I d X + 0 P(h)⊤(cid:16) X⊤(cid:2) I G(cid:3) +(cid:2) 0 ε⊤(cid:3)(cid:17) U(h)⊤ G⊤qz⊤
G⊤ ε d q
 E(cid:104) XP(h)⊤ X⊤GU Y(h)⊤ G⊤qq⊤(cid:105) 0 (cid:34) −E(cid:104) XP(h)⊤ X⊤GU(h)⊤ G⊤qq⊤(cid:105) 0(cid:35)
= − E(cid:104) G⊤XP(h)⊤ X⊤U(h)⊤ G⊤qq⊤(cid:105) 0 =
0
Y
0
.
X
whereinthesecondequality, weusethefactthatGandεareindependentandmeanzero, andthus
only the terms with second-order moments of G and ε are p. Moreover, in the last inequality, we
note that submatrix U(h) is zero by Definition 3.1(i). Thus, we show that A(h,0) is a block-diagonal
X
matrix with only the top left block being nonzero. The derivation of such simplification is based on
(i) the independence between p(h), G and ε and (ii) the fact that U(h) is zero by Definition 3.1(i).
X
(h)
Here (i) is implied by the fact that W = 0, given also by Definition 3.1(i). We will use the same
Y
argument to simplify A(h,h′) in (C.2) and B(h) in (2.9).
For A(h,h′), by direct calculation, we have
(cid:34) (cid:35)
(cid:18)(cid:20) (cid:21) (cid:20) (cid:21)(cid:19) (cid:18)(cid:20) (cid:21) (cid:20) (cid:21)(cid:19)⊤ (cid:18)(cid:20) (cid:21) (cid:20) (cid:21)(cid:19)
A(h,h′) = E I d X + 0 P(h)⊤ I d X + 0 U(h)⊤ U(h′) I d X + 0 p(h′)z⊤
G⊤ ε G⊤ ε G⊤ ε q
 E(cid:104) XP(h)⊤ X⊤U(h)⊤ U(h′) Xp(h′)z⊤+XP(h)⊤ X⊤GU(h)⊤ U(h′) G⊤Xp(h′)z⊤(cid:105) 
X X q Y Y q
=  E(cid:104) G⊤XP(h)⊤ X⊤GU(h)⊤ U(h′) Xp(h′)z⊤+G⊤XP(h)⊤ X⊤U(h)⊤ U(h′) G⊤Xp(h′)z⊤(cid:105)
Y X q X Y q
 E(cid:104) XP(h)⊤ ε⊤U(h)⊤ U(h′) εp(h′)z⊤(cid:105) 
Y Y q
+
E(cid:104) εP(h)⊤ ε⊤U(h)⊤ U(h′) Xp(h′)z⊤+εP(h)⊤ X⊤U(h)⊤ U(h′)
εp(h′)z⊤(cid:105).
Y X q X Y q
Then, using the fact that p(h), G, and ε are independent, we have
(cid:34) E(cid:104) XP(h)⊤ X⊤GU(h)⊤ U(h′) G⊤Xp(h′)q⊤+XP(h)⊤ ε⊤U(h)⊤ U(h′) εp(h′)q⊤(cid:105) 0(cid:35)
A(h,h′) = Y Y Y Y .
0 0
49(h) (h,h′) (h,h′)
Furthermore, we define matrices A , A , and A as follows:
Signal Intf Noise
A(h) =∆ −E(cid:104) XP(h)⊤ X⊤GU(h)⊤ G⊤qq⊤(cid:105) , (C.4)
Signal Y
A(h,h′)
=∆
E(cid:104) XP(h)⊤ X⊤GU(h)⊤ U(h′) G⊤Xp(h′)q⊤(cid:105)
, (C.5)
Intf Y Y
A(h,h′)
=∆
E(cid:104) XP(h)⊤ ε⊤U(h)⊤ U(h′) εp(h′)q⊤(cid:105)
. (C.6)
Noise Y Y
(h)
Here A is the signal part, which has a negative sign and leads the gradient flow dynamics to
Signal
(h,h′)
a desired solution. Moreover, A represents the cross-head interference as it involves both h-th
Intf
and h′-th head, and A(h,h′) is the noise part as it involves ε.
Noise
Therefore, we prove that only the top left block A(h) of A(h) is nonzero, and A(h) can be
XX XX
written as
H H
(h) (h) (cid:88) (h,h′) (cid:88) (h,h′)
A = A + A + A . (C.7)
XX Signal Intf Noise
h′=1 h′=1
Simplification of B(h). By the definition of B(h) in (2.9), we can write B(h) as
(cid:34) H (cid:35)
B(h) =E (cid:88) U(h′)Zp(h′)p(h)⊤ Z⊤ −E(cid:104) y p(h)⊤ Z⊤(cid:105) .
q
h′=1
Note that y = G⊤q and Y = G⊤X +ε. Writing in a block matrix form, we have
q
Bh =
(cid:88)H
(cid:104)
U(h′)
U(h′)(cid:105)
·(cid:34) E(cid:2) Xp(h′)p(h)⊤ X⊤(cid:3) E(cid:2) Xp(h′)p(h)⊤ (X⊤G+ε⊤)(cid:3) (cid:35)
X Y E(cid:2) (G⊤X +ε)p(h′)p(h)⊤ X⊤(cid:3) E(cid:2) (G⊤X +ε)p(h′)p(h)⊤ (X⊤G+ε⊤)(cid:3)
h′=1
−E(cid:104) G⊤qp(h)⊤(cid:2) X⊤ X⊤G+ε⊤(cid:3)(cid:105) .
Then using the independence between ε, p(h), and G implied by Definition 3.1(i) and the fact that
U(h′) = 0 for all h′ ∈ [H], we further have
X
H
B(h) = (cid:88) (cid:104) 0 E(cid:104) U(h′) G⊤Xp(h′)p(h)⊤ X⊤G+U(h′) εp(h′)p(h)⊤ ε⊤(cid:105)(cid:105) −(cid:104) 0 E(cid:104) G⊤qp(h)⊤ X⊤G(cid:105)(cid:105) .
Y Y
h′=1
(h) (h,h′) (h,h′)
Now we define matrices B , B , and B as follows:
Signal Intf Noise
B(h) =∆ −E(cid:104) G⊤qp(h)⊤ X⊤G(cid:105) , B(h,h′) =∆ E(cid:104) U(h′) G⊤Xp(h′)p(h)⊤ X⊤G(cid:105) , (C.8)
Signal Intf Y
B(h,h′)
=∆
E(cid:104) U(h′) εp(h′)p(h)⊤ ε⊤(cid:105)
, (C.9)
Noise Y
and B(h) only has the right block (Y part) being nonzero, which is given by
H H
(h) (h) (cid:88) (h,h′) (cid:88) (h,h′)
B = B + B + B . (C.10)
Y Signal Intf Noise
h′=1 h′=1
In conclusion, we have proved (C.1) in Proposition C.1, and the nonzero blocks of A(h) and B(h)
are given by (C.4)–(C.6), (C.8), and (C.9), respectively.
50(h) (h)
C.1.2 Simplification of A and B with Gaussian Covariate
XX Y
It remains to prove that the nonzero blocks of A(h) and B(h) can be diagonalized by the orthogonal
matrices Φ and Ψ introduced by the Decomposability Condition in Definition 3.1. We will prove
this fact leveraging the fact that the covariate distribution is Gaussian. In the following, for ease
of presentation, we introduce some additional notation that will only be used inside this section.
Additional Notation. Consider two heads h,h′ ∈ [H], We locally drop the superscript (h),(h′)
and write (·)(h) as (·) and (·)(h′) as (Ă ·). For example, under this notation, we write A(h) as A and
A(h′) as Ar . Similarly, the attention scores s(h) and s(h′) are written as s and sr, respectively. Since
W and WĂ are zero matrices, we have s = X⊤W q and sr= X⊤WĂ q. Note that s,sr∈ RL and we
Y Y X X
let s and sr denote the l-th entry of s and sr, respectively. That is, s = x⊤W q and sr = x⊤WĂ q.
l l l l X l l X
For any l ∈ [L], we define an operator T as follows:
l
(cid:18) (cid:19)
∂ Ă ∂ ∂f Ă ∂f
T ◦f=∆ W q· +W q· ◦f = W q· +W q· , (C.11)
l X ∂s X ∂sr X ∂s X ∂sr
l l l l
where f is any real-valued function of the l-th attention scores s and sr. In particular, W ∈ Rd×d,
l l X
q ∈ Rd, and ∂f/∂s ∈ R. Note that after applying the operator to f, the output is a d-dimensional
l
vector-valued function of s and sr. The intuition of the operator T is as follows. When f is a
l l l
function of the attention scores s and sr, it is a function of X, i.e., {x } . For any fixed l, x
l l∈[L] l
appears in s and sronly through s and sr. We can prove that ∇ f = T ◦f by using the chain rule.
l l x l l
Furthermore, for regularity, we assume that f is arbitrary-order differentiable and the derivatives
i.i.d.
have bounded expectations with respect to x ∼ N(0,I ). When it is clear from the context, we
l d
r
write the partial derivatives ∂/∂ s l and ∂/∂ sr l as ∂ l and ∂ l, respectively.
Additionally, we will encounter the composition of operators {T }. To this end, we extend the
l
definition in (C.11) to vector-valued functions. Specifically, let F = {F } : RL×RL → Rm be
i i∈[m]
a mapping that maps s and srto Rm. Then we define T ◦F as a matrix in Rd×m where the i-th
l
row is given by T ◦F . Then the composition (T ◦(T ◦f)) can be viewed as a matrix-valued
l i l m
function taking values in Rd×d, and (T ◦(T ◦(T ◦f))) can be viewed as a function taking values
l m n
in third-order tensor space Rd×d×d. To simplify the notation, we denote them by (T ⊗T )◦f and
l m
(T ⊗T ⊗T )◦f, respectively.
l m n
Meanwhile, note that when the parameter Θ satisfies the Decomposability Condition, W and
X
WĂ can be diagonalized by Φ. That is, we have WĂ = Φdiag(ωr)Φ⊤ and W = Φdiag(ω)Φ⊤. We
X X X
let q = Φ⊤q denote the rotated query vector and define a operator T by letting
l
T ◦f=∆
(cid:16)
diag(ω)·∂
+diag(ωr)·∂r(cid:17)
◦f = diag(ω)·∂ f
+diag(ωr)·∂r
f, (C.12)
l l l l l
for any function f of (s,sr). It is clear that T ◦f gives a diagonal matrix as diag(ω) is a diagonal
l
matrix and ∂ f is a scalar. Moreover, T and T are connected via the property that
l l l
T ◦f = Φdiag(ω)Φ⊤q·∂ f +Φdiag(ωr)Φ⊤q·∂r f = Φ(T ◦f)q. (C.13)
l l l l
We will also encounter the compositions of operators {T }, which takes a rather simple form.
l
Specifically, we have
(T ◦(T ◦f)) = (T ◦(T ◦f))
l m m l
= diag(ω⊙2)·∂ ∂ f +diag(ωr⊙2)·∂r ∂r f +diag(ω⊙ωr)·(∂ ∂r f +∂r ∂ f).
l m l m l m l m
51Note that (T ◦(T ◦f)) is a diagonal matrix.
l m
In addition, in the following, to simplify A(h) and B(h) using the Gaussian variate distribution,
we will recursively apply the Stein’s Lemma, will yields expectations of tensor-valued random
variables. For ease of presentation, we introduce the following notation for handling third-order
tensors. In particular, suppose f = {f } is a third-order tensor-value function of (s,sr)
lmn l,m,n∈[L]
indexed by (l,m,n) ∈ [L]×[L]×[L], we define
(cid:88)
f =∆ E[f |q], (C.14)
lmn l′m′n′
(cid:74) (cid:75)
l′,m′,n′∈[L]
where the expectation is taken with respect to the randomness of covariate X. That is, f
lmn
(cid:74) (cid:75)
denotes the sum of entries of the expectation of the tensor {f }. Here we hide the dependency on
lmn
q for simplicity. Note that the conditional expectation in (C.14) takes the same value if we instead
conditiononq. Besides,wecansimilarlydefine f and f forsecond-ordertensor-valuefunction
lm l
and vector-value function of (s,sr), respectively(cid:74) . Fu(cid:75) rther(cid:74) mo(cid:75) re, for a third-order tensor M, we let
M⊤(i1i2i3) denote the (i 1,i 2,i 3) transpose of M. For instance, M⊤(132) represents the transpose of
M by swapping the second and the third dimension.
Gaussian Moments. A nice property of the Gaussian distribution is the Stein’s Lemma, which
states that E[xg(x)] = E[∇g(x)] for any function g under some regularity condition. Here the
(h) (h)
expectation is taken with respect to x ∼ N(0,I ). Note that A and B are functions X. We
d XX Y
(h)
will leverage the Stein’s Lemma to explicitly compute the expectations with respect to X in A
XX
(h)
and B . In particular, we will resort to the following lemma.
Y
Lemma C.2. Suppose for any l ∈ [L], the l-th covariate x in the ICL context Z is drawn from a
l
i.i.d.
standard normal distribution, i.e., x ∼ N(0,I ). In addition, let {f } be a third-order
l d lmn l,m,n∈[L]
tensor-value function of (s,sr) indexed by (l,m,n) ∈ [L]×[L]×[L]. Similarly, let {f } be
lm l,m∈[L]
a second-order tensor-value function of (s,sr) indexed by (l,m) ∈ [L]×[L], and let {f } be a
l l∈[L]
vector-value function of (s,sr) indexed by l ∈ [L]. Then, we have the following results.
(i) f ·x ⊗x ⊗x = T ◦(f )⊗I + I ⊗T ◦(f )
lmn l m n l lmm d d l mml
(cid:74) (cid:75) (cid:74) (cid:75) (cid:74) (cid:75)
+ I ⊗T ◦(f ) ⊤(132)+ (T ⊗T ⊗T )◦(f ) .
d l mlm l m n lmn
(cid:74) (cid:75) (cid:74) (cid:75)
(ii) f ·x ⊗x = (T ⊗T )◦f + f ·I .
lm l m l m lm ll d
(cid:74) (cid:75) (cid:74) (cid:75) (cid:74) (cid:75)
(iii) f x = T ◦f .
l l l l
(cid:74) (cid:75) (cid:74) (cid:75)
Proof. (Proof of Lemma C.2) See §G.1.1 for a detailed proof.
Now we are ready to simplify A(h) and B(h) by showing that the nonzero blocks of A(h) and
B(h) can be diagonalized by the orthogonal matrices Φ and Ψ, respectively.
52(h)
Simplification of A with Gaussian Covariate
XX
(h) (h)
Recall that we show in (C.7) that A is equal to a sum of three terms. We first consider A
XX Signal
defined in (C.4). By the second identity of Lemma C.2, we have
(cid:104) (cid:105)
A(h) = −E XP⊤X⊤GU⊤G⊤qq⊤
Signal Y
(cid:104) (cid:105)
= −E ( (T ⊗T )◦P + P ·I )GU⊤G⊤qq⊤ , // Lemma C.2
l m ml ll d Y
(cid:74) (cid:75) (cid:74) (cid:75)
where the expectation in the second equality is taken with respect to the randomness of G and q.
Here we omit the superscript (h) for simplicity. Besides, we write
(cid:88) (cid:88)
(T ⊗T )◦P = E[(T ⊗T )◦P |q], P ·I = E[P ·I |q].
l m ml l m ml ll d ll d
(cid:74) (cid:75) (cid:74) (cid:75)
l,m l
By the definition of T in (C.11) and noticing that P is a function of s only, we have
l ml
(T ⊗T )◦P = W qq⊤W⊤·∂ ∂ P = Φdiag(ω)Φ⊤qq⊤Φdiag(ω)Φ⊤·∂ ∂ P
l m ml X X l m ml l m ml
= Φdiag(ω)qq⊤diag(ω)Φ⊤·∂ ∂ P
l m ml
= Φ(cid:0) T ◦(qq⊤T ◦P ))Φ⊤:=Φ(T qq⊤T )◦P Φ⊤,
l m ml l m ml
where in the first equality we use the fact that ∂r P = 0 since P does not depend on sr. In the
l ml ml
third equality, we use the fact that q = Φ⊤q. In the fourth equality we apply the definitions of T
l
and T . Moreover, we let (T qq⊤T )◦f denote the operator composition T ◦(qq⊤T ◦f) for any
m l m l m
function f.
Furthermore, notice that both (T ⊗T )◦P and P ·I are functions of q only, and thus
l m ml ll d
areindependentofG. Thus, wecan(cid:74) alsotakecondit(cid:75) ionale(cid:74) xpecta(cid:75) tionofGU⊤G⊤ givenq inA(h) .
Y Signal
We introduce the following lemma that computes such an expectation.
√
Lemma C.3. Consider G = 1/ d·ΦGΨ⊤ with Φ ∈ Od, Ψ ∈ Ody, and G is a random matrix in
Rd×dy. Let M ∈ Rdy×dy and N ∈ Rd×d be two fixed matrices. Suppose the d×d
y
random matrix
G has independent entries with E[G] = 0 and E[G⊙2] = Λ. It then holds that
E[GMG⊤] = 1/d·Φdiag(cid:0) ΛDiag(Ψ⊤MΨ)(cid:1) Φ⊤, E[G⊤NG] = 1/d·Ψdiag(cid:0) Λ⊤Diag(Φ⊤NΦ)(cid:1) Ψ⊤.
Here Diag(·) denotes the vector that consists the digonal entries of a matrix, and diag(·) denotes
the diagonal matrix created from a vector.
Thislemmacanbecomputedbydirectcomputationandweomittheproofforbrevity. Besides,
to simplify the notation, we define
A◦M =∆
1/d·diag(cid:0) ΛDiag(Ψ⊤MΨ)(cid:1)
, B◦N =∆
1/d·diag(cid:0) Λ⊤Diag(Φ⊤NΦ)(cid:1)
.
asoperatorsthatmapamatrixM ∈ Rdy×dy orN ∈ Rd×d toanotherdiagonalmatrix. Inparticular,
if M = ΨMΨ takes Ψ as its eigenvector matrix and M as a diagonal matrix, then A ◦ M =
diag(Λvec(M))/d. By this lemma, we have E[GU⊤G⊤|q] = A◦U⊤. Thus, we further have
Y Y
(cid:104)(cid:16) (cid:17) (cid:105)
A(h) = −E Φ (cid:114)(T qq⊤T )◦P (cid:122)Φ⊤+ P ·I Φ(cid:0) A◦U⊤(cid:1) Φ⊤qq⊤
Signal l m ml ll d Y
(cid:74) (cid:75)
(cid:104) (cid:105)
= −ΦE (cid:0) (cid:113)(T lqqT m)◦P ml(cid:121)+ P
ll
·I
d
(cid:1) (A◦U Y⊤)qq⊤ Φ⊤. (C.15)
(cid:74) (cid:75)
53Note that (T qqT )◦P , P ·I , and A◦U⊤ are all diagonal matrices. Hence, Φ⊤A(h) Φ is
l m ml ll d Y Signal
equal to the expectation of the product of a diagonal matrix and a rank-one matrix qq⊤, where
the diagonal matrix is a function of q.
We now introduce a key observation, which is a direct result of the inner product structure of
the attention scores and the rotation invariance of the distribution of the covariate x .
l
Lemma C.4. Consider g(s,sr) as an arbitrary function of the attention scores s and sr. Then,
E[g(s,sr)|q], viewed as a function of q, is a function of only ⟨ω⊙2,q⊙2⟩, ⟨ωr⊙2,q⊙2⟩, and ⟨ω⊙ωr,q⊙2⟩.
Here ω and ωr are the eigenvalues of W and WĂ , respectively. Here ω⊙2 denotes the elementwise
X X
square of ω, i.e., ω⊙2 is a vector in Rd with the i-th entry being ω2.
i
Proof. (Proof of Lemma C.4) See §G.1.2 for a detailed proof.
We remark that Lemma C.4 shows that when f is a function that simultaneously depends on
two attention scores s and sr, the conditional expectation E[f(s,sr)|q] is a function of only the
second-order moments of q, i.e., {q2} . This fact is a result of the rotational invariance of the
j j∈[d]
covariate distribution. This lemma directly implies that
Φ⊤A(h)
Φ is a diagonal matrix, which is
Signal
shown in the following lemma.
Lemma C.5. Let g(q) = (cid:81)d qci be a polynomial of q with c ∈ N. Then, if (cid:80)d c is odd, we
i=1 i i i=1 i
have E[g(q)|q⊙2] = 0. In particular, E[qq⊤|q⊙2] is a diagonal matrix.
Proof. (Proof of Lemma C.5) Note that when conditioned on q⊙2, each entries of q are i.i.d.and
takes values −|q | and |q | with equal probability. Hence, by symmetry, we have E[g(q)|q⊙2] = 0 if
i i
(cid:80)d
c is odd. Therefore, we prove this lemma.
i=1 i
(h)
Applying (C.15) and Lemma C.5 to A , we have
Signal
(cid:104)(cid:16) (cid:17) (cid:105)
A(h) = −ΦE (cid:114)(T qq⊤T )◦P (cid:122)+ P ·I (A◦U⊤)qq⊤ Φ⊤
Signal l m ml ll d Y
(cid:74) (cid:75)
(cid:104) (cid:104) (cid:12) (cid:105)(cid:105)
= −ΦE E (cid:114)(T qq⊤T )◦P ·(A◦U⊤)qq⊤(cid:122)+ P ·I (A◦U⊤)qq⊤(cid:12)q⊙2 Φ⊤.
l m ml Y ll d Y (cid:12)
(cid:74) (cid:75)
Note that the second term is a diagonal matrix by directly applying Lemma C.5. We note that the
first term is also a diagonal matrix since q⊤T ◦P (A◦U⊤)q = ⟨Diag(T⊤◦P (A◦U⊤)),q⊙2⟩ is a
m ml Y m ml Y
real number and only depends on q⊙2. The remaining term E[qq⊤|q⊙2] clearly gives us a diagonal
(h)
matrix. Hence, we claim that A is diagonal. We will leverage the same technique to simplify
Signal
(h,h′) (h,h′)
A and A , respectively.
Intf Noise
(h,h′)
For A , by the first identity of Lemma C.2, we have
Intf
A(h,h′)
=
E(cid:104) XP(h)⊤ X⊤GU(h)⊤ U(h′) G⊤Xp(h′)q⊤(cid:105)
Intf Y Y
(cid:104)(cid:16)
= E (cid:0) T ◦(P pr ) ⊗I +I ⊗ T ◦(P pr) +(I ⊗ T ◦(P pr ) )⊤(132)
l ml m d d l mm l d l lm m
(cid:74) (cid:75) (cid:74) (cid:75) (cid:74) (cid:75)
+ (T ⊗T ⊗T )◦(P pr ) (cid:1). .(cid:0) GUr⊤U G⊤(cid:1)(cid:17) ⊗q(cid:105) .
l m n ml n Y Y
(cid:74) (cid:75)
.
Recallthat“.”denotesthedoubleinnerproductoftwotensors. Inparticular, wehavethefollowing
relationships for the double inner product.
54Lemma C.6. Let N,M ∈ Rd×d be two matrices and u,v,w,x ∈ Rd be four vectors. Then we have
v⊗N . .M ⊗u = vu⊤·Tr(NM), (I ⊗v). .M = (v⊤M)⊤,
d
(I ⊗v)⊤(132). .M = Mv, u⊗v⊗w. .M ⊗x = (w⊤Mv)ux⊤.
d
(h,h′)
Combining the first identity in Lemma C.6 and Lemma C.3 to the expression of A , we have
Intf
E(cid:2) T ◦(P pr ) ⊗I . .(cid:0) GUr⊤U G⊤(cid:1) ⊗q(cid:3)
l ml m d Y Y
(cid:74) (cid:75)
= E(cid:2) T ◦(P pr ) q⊤·Tr(cid:0) ΦA◦(Ur⊤U )Φ⊤(cid:1)(cid:3)
l ml m Y Y
(cid:74) (cid:75)
= ΦE(cid:2) (cid:113)T
l
◦(P mlpr m)(cid:121) qq⊤Tr(cid:0) A◦(Ur Y⊤U Y)(cid:1)(cid:3) Φ⊤, (C.16)
where q = Φ⊤q. Besides, using the second identity in Lemma C.6 and Lemma C.3, we have
E(cid:2) I ⊗ T ◦(P pr) . .(cid:0) GUr⊤U G⊤(cid:1) ⊗q(cid:3)
d l mm l Y Y
(cid:74) (cid:75)
= E(cid:2) ΦA◦(Ur⊤U )Φ⊤ T ◦(P pr) q⊤(cid:3)
Y Y l mm l
(cid:74) (cid:75)
= ΦE(cid:2) A◦(Ur Y⊤U Y)(cid:113)T
l
◦(P mmpr l)(cid:121)qq⊤(cid:3) Φ, (C.17)
where the second equality follows from (C.13). Note that T ◦(P pr) is a vector in Rd and
l mm l
A ◦ (Ur ⊤U ) is a diagonal matrix in Rd×d. Moreover, by th(cid:74) e third iden(cid:75) tity in Lemma C.6 and
Y Y
Lemma C.3, we have
E(cid:2) I ⊗ T ◦(P pr ) ⊤(132). .(cid:0) GUr⊤U G⊤(cid:1) ⊗q(cid:3)
d l lm m Y Y
(cid:74) (cid:75)
= E(cid:2) ΦA◦(Ur⊤U )Φ⊤ T ◦(P pr ) q⊤(cid:3)
Y Y l lm m
(cid:74) (cid:75)
= ΦE(cid:2) A◦(Ur Y⊤U Y)(cid:113)T
l
◦(P lmpr m)(cid:121)qq⊤(cid:3) Φ, (C.18)
where the second equality follows from (C.13). Finally, note that by the definition of T in (C.11),
l
T ⊗T ⊗T ◦(P pr ) is a rank-one third-order tensor. By Lemma C.3 and the last identity in
l m n ml n
Lemma C.6, we have
E(cid:2) T ⊗T ⊗T ◦(P pr ) . .(cid:0) GUr⊤U G⊤(cid:1) ⊗q(cid:3)
l m n ml n Y Y
(cid:74)
=
E(cid:104)
(cid:114)(cid:0) T T⊤(cid:0)
A◦(Ur⊤(cid:75)
U )(cid:1) T (cid:1) ◦(P pr
)(cid:122)q⊤(cid:105)
l n Y Y m ml n
= ΦE(cid:104) (cid:114)(cid:0) T qq⊤T (cid:0) A◦(Ur⊤U )(cid:1) T (cid:1) ◦(P pr )(cid:122)qq⊤(cid:105) Φ, (C.19)
l n Y Y m ml n
where the second equality is obtained by applying (C.13) for three times.
(h,h′)
Thus, combining (C.16)–(C.19), we have for A that
Intf
A( Ih n, th f′) = ΦE(cid:104) (cid:113)T
l
◦(P mlpr m)(cid:121) qq⊤Tr(cid:0) A◦(Ur Y⊤U Y)(cid:1) +A◦(Ur Y⊤U Y)(cid:113)T
l
◦(P mmpr l)(cid:121) qq⊤
+A◦(Ur Y⊤U Y)(cid:113)T
l
◦(P lmpr m)(cid:121)qq⊤+(cid:114)(cid:0) T lqq⊤T n(cid:0) A◦(Ur Y⊤U Y)(cid:1) T m(cid:1) ◦(P mlpr n)(cid:122)qq⊤(cid:105) Φ⊤.
r
Here, we treat each T as a vector and T as a diagonal matrix. Note that A◦(U⊤U ) is a diagonal
l l Y Y
matrix. Thus, the terms with · in (C.16), (C.17), and (C.18) are all diagonal matrices. Moreover,
they are functions of s and
sr.(cid:74) (cid:75)
Thus, for these three terms, by Lemma C.4 and Lemma C.5, we
can first take a conditional expectation with respect to q⊙2 and prove that they are all diagonal
55matrices. Moreover, in(C.19), thetermT (cid:0) A◦(Ur ⊤U )(cid:1) T isadiagonalmatrixasitistheproduct
n Y Y m
ofthreediagonalmatrices. Asaresult,(cid:114)(T qq⊤T (A◦(Ur ⊤U ))T )◦(P pr )(cid:122)qq⊤ involvesfourth-
l n Y Y m ml n
order moments of q. By applying Lemma C.4 and Lemma C.5, and taking conditional expectation
given q⊙2, we can similarly argue that this term is a diagonal matrix. Therefore, we conclude that
(h,h′)
A is a diagonal matrix.
Intf
(h,h′)
Finally, for A , by the last identity of Lemma C.2 and the first identity of Lemma C.6, we
Noise
have
A(h,h′) = E(cid:104) XP⊤ε⊤U⊤Ur εprq⊤(cid:105) = E(cid:104)(cid:16) x ⊗ε ⊗ε ·(P pr ) . .Ur U⊤(cid:17) q⊤(cid:105)
Noise Y Y l m n ml n Y Y
(cid:74) (cid:75)
= σ2E(cid:104) Tr(cid:0) Ur U⊤(cid:1) · (P pr )·x ·q⊤(cid:105) = σ2E(cid:104) Tr(cid:0) Ur U⊤(cid:1) · T ◦(P pr ) q⊤(cid:105)
Y Y ml m l Y Y l ml m
(cid:74) (cid:75) (cid:74) (cid:75)
= σ2·ΦE(cid:104) Tr(Ur YU Y⊤)·(cid:113)T
l
◦(P mlpr m)(cid:121) qq⊤(cid:105) Φ⊤,
where the second equality follows from direct computation; in the third equality, we use the fact
thatε i. ∼i.d. N(0,σ2I )andthefactthatI. .M = Tr(M);inthefourthequalityweapplyLemmaC.2;
l dy
thelastequalityfollowsfrom(C.13). Similarly, applyingLemmaC.4andandLemmaC.5, weprove
(h,h′)
that A is a diagonal matrix.
Noise
(h)
In summary, we have for A that
XX
(cid:104)(cid:16) (cid:17) (cid:105)
Φ⊤A(h) Φ = −E (cid:114)(T qq⊤T⊤)◦P (cid:122)+ P I (A◦U⊤)qq⊤
XX l m ml ll d Y
(cid:74) (cid:75)
(cid:124) (cid:123)(cid:122) (cid:125)
Signal
H
+ (cid:88) σ2E(cid:104) Tr(Ur YU Y⊤)(cid:113)T
l
◦(P mlpr m)(cid:121)qq⊤(cid:105)
h′=1
(cid:124) (cid:123)(cid:122) (cid:125)
Noise
H
+ (cid:88) E(cid:104) (cid:113)T
l
◦(P mlpr m)(cid:121) qq⊤Tr(cid:0) A◦(Ur Y⊤U Y)(cid:1) +A◦(Ur Y⊤U Y)(cid:113)T
l
◦(P mmpr l)(cid:121) qq⊤
h′=1
+A◦(Ur Y⊤U Y)(cid:113)T
l
◦(P lmpr m)(cid:121)qq⊤+(cid:114)(cid:0) T lqq⊤T n⊤(cid:0) A◦(Ur Y⊤U Y)(cid:1) T m(cid:1) ◦(P mlpr n)(cid:122)qq⊤(cid:105) .
(cid:124) (cid:123)(cid:122) (cid:125)
Interference
We prove that, when Θ satisfies Decomposability Condition, only the top left block of A(h), A(h) ,
XX
is non-zero. Moreover,
Φ⊤A(h)
Φ is a diagonal matrix.
XX
(h)
Simplification of B with Gaussian Covariate.
Y
(h) (h) (h,h′)
Recall that in (C.10) we show that B can be decomposed into three terms: B , B , and
Y Signal Intf
(h,h′)
B , which are defined in (C.8) and (C.8). In the following, we prove that each term can be
Noise
diagonalized by Ψ.
56(h)
For B , by the last identity of Lemma C.2 and Lemma C.3, we have
Signal
(cid:104) (cid:105) (cid:104) (cid:16) (cid:17)(cid:105)
B(h) = −E G⊤qp⊤X⊤G = −ΨE B◦ q T ◦p ⊤ Ψ⊤
Signal l l
(cid:74) (cid:75)
(cid:104) (cid:16) (cid:17)(cid:105)
= −ΨE B◦ Φqq⊤ (cid:113)T
l
◦p l(cid:121)⊤ Φ⊤ Ψ⊤.
where the last equality holds by (C.13) and the definition q = Φ⊤q. Note that the operator B
always produces a diagonal matrix, we prove that
Ψ⊤B(h)
Ψ is a diagonal matrix. For
B(h,h′)
,
Signal Intf
by the second identity of Lemma C.2 and Lemma C.3, we have
B(h,h′)
=
E(cid:104) Ur G⊤Xprp⊤X⊤G(cid:105)
Intf Y
(cid:104) (cid:16) (cid:17)(cid:105)
= ΨE diag(µr)B◦ (cid:114)(T T⊤)◦(prp )(cid:122)+ prp ·I Ψ⊤ // Lemma C.2
l m l m l l d
(cid:74) (cid:75)
(cid:104) (cid:16) (cid:16) (cid:17) (cid:17)(cid:105)
= ΨE diag(µr)B◦ Φ (cid:114)(T qq⊤T )◦(prp )(cid:122)+ prp ·I Φ⊤ Ψ⊤.
l m l m l l d
(cid:74) (cid:75)
Here, the second equality also holds by Definition 3.1(ii) that Ur = Ψdiag(µr)Ψ⊤ and the last
Y
equality follows from (C.13). Similarly, thanks to the operator B,
Ψ⊤B(h,h′)
Ψ is a diagonal matrix.
Intf
(h,h′)
Finally, for B , we have
Noise
B N(h oi,h s′ e) = E(cid:104) Ur Yεprp⊤ε⊤(cid:105) = σ2·E(cid:104) Ur
Y
(cid:113)I
dy
·pr lp l(cid:121)(cid:105) = σ2ΨE[diag(µr) pr lp
l
]Ψ⊤,
(cid:74) (cid:75)
where we use the fact that ε i. ∼i.d. N(0,σ2I ). This matrix is also digonalizable by Ψ as prp is a
l dy l l
(cid:74) (cid:75)
scalar.
(h)
In summary, we have for B that
Y
H
Ψ⊤B Y(h) Ψ = −E(cid:104) B◦(cid:16) Φqq⊤ (cid:113)T
l
◦p l(cid:121)⊤ Φ⊤(cid:17)(cid:105) + (cid:88) σ2E[diag(µr) pr lp
l
]
(cid:74) (cid:75)
(cid:124) (cid:123)(cid:122) (cid:125) h′=1
Signal (cid:124) (cid:123)(cid:122) (cid:125)
Noise
H
(cid:88) (cid:104) (cid:16) (cid:16) (cid:17) (cid:17)(cid:105)
+ E diag(µr)B◦ Φ (cid:114)(T qq⊤T⊤)◦(prp )(cid:122)+ prp ·I Φ⊤ .
l m l m l l d
(cid:74) (cid:75)
h′=1
(cid:124) (cid:123)(cid:122) (cid:125)
Interference
We prove that, when Θ satisfies Decomposability Condition, only the right block of B(h), B(h) , is
Y
non-zero. Moreover,
Ψ⊤B(h)
Ψ is a diagonal matrix. Therefore, we conclude the proof of Proposi-
Y
tion C.1.
C.2 Approximation of the Spectral Dynamics
Additional Notations. We follow the same notations as in Section C.1.2. Besides, we denote
by δ the Kronecker delta function such that δ = 1 if i = j and 0 otherwise. Furthermore, we will
ij ij
also encounter graph-theoretic notions. For a graph G, we denote by CC(G) the set of connected
components of G. We denote by R(v) the set of nodes that are reachable from node v in G. Note
that R(v) is also the element of CC(G) that contains v.
57C.2.1 Low-Effective Order Approximation to the Derivatives of Softmax Attention
Probability
(h) (h)
In order to give a rigorous calculation of A and B , we need to compute the derivatives of
XX Y
the attention probability p and pr with respect to the attention scores s and sras implied by the
l l
operator T that
l
T ◦f=∆
(cid:16)
diag(ω)∂
+diag(ωr)∂r(cid:17)
◦f.
l l l
For simplicity, we replace diag(ω) and diag(ωr) with w and wr as placeholders, respectively. With
such a replacement, we have T ◦f = (w∂
+wr∂r
)f. Also, when considering T ◦f, we just need
l l l l
to replace w and wr with Wq and WĂ q by multiplying back the rotation matrix Φ and q = Φ⊤q
according to (C.13).
Note that P = diag(p)−pp⊤ for softmax attention probability p, which is a symmetric matrix.
(h)
For calculation of A , we need to compute the following derivatives:
XX
(cid:113)w⊗2∂ l∂ mP ml(cid:121), (cid:114)(w∂
l
+wr∂r l)P mmpr l(cid:122), (cid:114)(w∂
l
+wr∂r l)P lmpr m(cid:122),
(cid:114)(w∂ +wr∂r )⊗(w∂ +wr∂r )⊗(w∂ +wr∂r )P pr (cid:122).
l l m m n n ml n
(h)
For B , we need to compute the following derivatives:
Y
w∂ p , (cid:114)(w∂ +wr∂r )⊗(w∂ +wr∂r )prp (cid:122).
l l l l m m l m
(cid:74) (cid:75)
We have the following fact about the derivatives of the attention probabilities.
Lemma C.7. We have the following identities involving partial derivatives of the attention proba-
bility p with respect to the attention scores s:
(i) ∂ p = P = δ p −p p ;
l m ml lm l l m
(ii) ∂2 p = ∂ P = δ p −δ p p −δ p p −δ p p +2p p p ;
lm n l nm lmn l mn l m nl m n lm n l l m n
(iii) (cid:80) ∂ P = (cid:80) ∂ P = (cid:80) 2p p2−2p2δ = 2p (∥p∥2−p );
l l nl l n ll l n l n ln n 2 n
(iv) (cid:80) ∂ P = ∂ ((cid:80) ∂ P ) = 2(−2p2δ +p p2δ +2p p2δ +2p2p δ −3p p p2);
l lm nl m l l nl n lmn n l mn n l lm n m ln m n l
(h) (h)
Calculations for B . We give a rigorous calculation of the terms for B in the following. By
Y Y
Lemma C.7(i), we have
∂ p = P = 1−∥p∥2.
l l ll 2
(cid:74) (cid:75) (cid:74) (cid:75)
Furthermore, by Lemma C.7(ii), we have
(cid:113)(w∂ l +wr∂r l)⊗(w∂ m+wr∂r m)pr lp m(cid:121)
= (cid:114)w⊗2pr(δ p −p p −2δ p2 +2p p2 )+wr⊗2p (δ pr −prpr −2δ pr2 +2prpr2 )
l lm m l m lm m l m l lm m l m lm m l m
+wr⊗w(p −p2 )(pr −pr2)+w⊗wr(δ p −p p )(δ pr −prpr )(cid:122)
m m l l lm l l m lm l l m
(cid:104)
= E 2w⊗2(−pr⊤p⊙2+pr⊤p∥p∥2)+2wr⊗2(−p⊤pr⊙2+p⊤pr∥pr∥2)
2 2
+wr⊗w(1−∥p∥2)(1−∥pr∥2)+w⊗wr(p⊤pr−p⊤pr⊙2−pr⊤p⊙2+(pr⊤p)2)(cid:12) (cid:12)q(cid:105)
.
2 2
58The following fact summarizes the above calculations in the original matrix form (substituting the
placeholders w and wr with Wq and WĂ q, respectively).
Ă
Lemma C.8. Suppose q is the query vector and W,W are two attention weight matrices such that
p = softmax(X⊤Wq) and pr = softmax(X⊤WĂ q). Suppose that each column of X is i.i.d.drawn
from N(0,I ). Then we have by Lemma C.2 that
dx
E[Xp|q] = T ◦p = Wq·E(cid:2) (1−∥p∥2)|q(cid:3) ,
l l 2
(cid:74) (cid:75)
E[XpprX⊤|q] = p pr ·I + (T ⊗T )◦(p pr )
l l dx l m l m
= E[p⊤pr|q]·I (cid:74) +E(cid:104) 2W(cid:75) qq⊤(cid:74) W⊤(−pr⊤p⊙2+pr⊤p(cid:75) ∥p∥2)+2WĂ qq⊤WĂ⊤(−p⊤pr⊙2+p⊤pr∥pr∥2)
dx 2 2
+WĂ qq⊤W⊤(1−∥p∥2)(1−∥pr∥2)+Wqq⊤WĂ⊤(p⊤pr−p⊤pr⊙2−pr⊤p⊙2+(pr⊤p)2)(cid:12) (cid:12)q(cid:105)
.
2 2 (cid:12)
Ă
In particular, if W = W, then we have a simpler form:
E[XppX⊤|q] = E[Wqq⊤W⊤(1−∥p∥2−6∥p∥3+6∥p∥4)]+I E[∥p∥2].
2 3 2 dx 2
(h) (h)
Calculations for A . For A , expanding all these derivatives is tedious and unnecessary.
XX XX
We only need to keep track of those terms that contribute significantly to the final results and
view the rest as higher-order noise. This necessitates developing a systematic way to evaluate the
importance of each term in the expansion. To this end, in the following, we relate the expansion
of partial derivates of a polynomial function of attention probabilities p and prto a graph structure
where the nodes are in V = [L] and the edges are in E = [L]×[L]. We introduce the notion of
graph-induced polynomials and effective order as follows.
Definition C.9 (Graph-Induced Polynomial and Effective Order). Consider a weighted graph
G = (V,E,a,b) where V = [L] is a set of vertices, E = [L] × [L] is a set of undirected edges
(we allow self-loop), and a = {a } ,b = {b } with (a ,b ) ∈ N are the nonnegative integer
v v∈V v v∈V v v
weights. For any subgraph G′ of G, define the total weights of G′ as W(G′)=∆ (cid:80) (a +b ). We
v∈V′ v v
have the following definitions:
(i) The polynomial induced by graph G with variables p = {p } , pr = {pr } is defined as
v v∈V v v∈V
f G(p,pr) = (cid:81) v∈V(cid:0) pa vvpr vbv(cid:1) ·(cid:81)
(v,v′)∈E
δ vv′.
(ii) Let CC (G)=∆{c ∈ CC(G)|W(c) ≥ n} be the set of connected components of G with total
≥n
weights no less than n.
(iii) We define the effective order of G as Ord(G)=∆ (cid:80) (a +b )−|CC (G)|.
v∈V v v ≥1
(iv) We say that two graphs G and G′ are equivalent if V = V′, a = a′, b = b′ and CC (G) =
≥1
CC (G′).
≥1
Definition C.9 draws a parallel between the weighted graph structure to polynomials of this
form (cid:81) v∈V(cid:0) pa vvprb vv(cid:1) ·(cid:81)
(v,v′)∈E
δ vv′. We remark that the effective order is critical for our analysis
since terms with higher effective order turn out to be higher-ordered smaller in scale. The following
fact shows that the polynomial and the underlying graph structure are isomorphic up to the class
of equivalent graphs.
59Lemma C.10. For any two graphs G and G′, f (p,pr) = f (p,pr) if and only if G and G′ are
G G′
equivalent. Moreover, any two equivalent graphs have the same effective order.
Proof. (Proof Sketch of Lemma C.10) It is easy to check that f (p,pr) = f (p,pr) if and only if G
G G′
and G′ have the same set of vertices, same weights on the vertices, and the same set of connected
components, which is exactly what it means by saying that G and G′ are equivalent. The second
claim on the effective order follows directly from the definition that the effective order is only a
function of the weights on the vertices and the set of connected components.
To this end, we can also define the effective order of a polynomial as the effective order of any
graph that induces this polynomial. We next introduce a partial derivative operator on both the
graph and the polynomial.
DefinitionC.11(DerivativeOperator). Considerapolynomialf G(p,pr) = (cid:81) v∈V(cid:0) pa vvprb vv(cid:1) ·(cid:81)
(v,v′)∈E
δ vv′.
Define partial derivative operator ∂ for any u ∈ V as
u
∂ f (p,pr)=∆ (cid:88) a pas−1(δ p −p p )prbs · (cid:89) (cid:0) pavprbv(cid:1) · (cid:89) δ
u G s s us s s u s v v vv′
s∈V v∈V\{s} (v,v′)∈E
(cid:32) (cid:33)
=
(cid:88)
a δ ·
(cid:89)(cid:0) pavprbv(cid:1)
·
(cid:89)
δ −
(cid:88)
a ·p ·
(cid:89)(cid:0) pavprbv(cid:1)
·
(cid:89)
δ . (C.20)
s us v v vv′ s u v v vv′
s∈V v∈V (v,v′)∈E s∈V v∈V (v,v′)∈E
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Adding an edge (u,s) Increasing a by 1
u
r
Moreover, ∂ is defined similarly.
u
Note that the definition of the partial derivative operator is consistent with the definition of
the derivative of the attention probability p in Lemma C.7. When combined with the underlying
graph structure, we have an intuitive interpretation of the partial derivative operator. The partial
derivative operator ∂ produces at most |V|+1 terms in the summation, where each of the first |V|
u
term adds a new edge (u,s) for some s ∈ V to the graph G and the last term adds 1 to weight a
u
of vertex u in G. The following fact comes directly from the observation that both adding a new
edge or adding 1 to the weight does not decrease the effective order.
Lemma C.12. Consider a G-induced polynomial f G(p,pr) = (cid:81) v∈V(cid:0) pa vvprb vv(cid:1) ·(cid:81)
(v,v′)∈E
δ vv′. Applying
r
∂ or∂ yieldsinasummationofpolynomialswhereeachhasaneffectiveordernolessthanOrd(G).
v v
Proof. (Proof Sketch of Lemma C.12) The proof follows directly from the definition of the partial
derivative operator in Definition C.11 and that adding a new edge or increasing the weight of a
vertex does not decrease the effective order.
Therefore, when applying a sequence of partial derivative operators and want to keep track of
only the low-effective-order terms, we can safely ignore higher-order terms after each application
of the partial derivative operator. To this end, we use notation (cid:80) f (p,pr)= (cid:80) f (p,pr) to
i Gi ⩽k j G j′
denote the low-effective-order equivalence between two expressions if (cid:80) f (p,pr)1(Ord(G ) ≤ k) =
(cid:80) f (p,pr)1(Ord(G′) ≤ k). The following fact helps us simplify the i caG lci ulation underi this low-
j G′ j
j
effective-order equivalence.
60Lemma C.13. We denote by R(v) the set of nodes that are reachable from node v in G. Consider
a G-induced polynomial f G(p,pr) = (cid:81) v∈V(cid:0) pa vvprb vv(cid:1) · (cid:81)
(v,v′)∈E
δ vv′. Let k be the effective order of
f (p,pr). Consider two cases: (i) if W(R(u)) = 0, we have
G
(cid:32) (cid:33)
∂ f (p,pr)= (cid:88) a δ · (cid:89)(cid:0) pavprbv(cid:1) · (cid:89) δ − (cid:88) a ·p · (cid:89)(cid:0) pavprbv(cid:1) · (cid:89) δ ,
u G ⩽k s us v v vv′ s u v v vv′
s∈V v∈V (v,v′)∈E s∈V v∈V (v,v′)∈E
and (ii) if W(R(u)) ≥ 1, we only need to keep
 
∂ uf G(p,pr)= ⩽k (cid:88) a s· (cid:89)(cid:0) pa vvprb vv(cid:1) · (cid:89) δ vv′, (C.21)
s∈R(u) v∈V (v,v′)∈E
where δ is not needed since s ∈ R(u) and deleting the edge (u,s) will not change the connected
us
component structure. Similar result holds for ∂r f (p,pr).
u G
Proof. (Proof of Lemma C.13) See Appendix G.2.1 for a detailed proof.
(h)
We now characterize each term in the decomposition of A . By Lemma C.7(iv), we have
XX
(cid:113)w⊗2∂ l∂ mP ml(cid:121) = 2w⊗2 (cid:113)−2p2 mδ lm+2p mp2 lδ lm+2p3 mδ lm+p mp2
l
−3p2 mp2 l(cid:121)
=
2w⊗2E(cid:2) −∥p∥2+4∥p∥3−3∥p∥4(cid:12) (cid:12)q(cid:3)
.
2 3 2
For (cid:113)(w∂
l
+wr∂r l)P mmpr l(cid:121), we have by Lemma C.7(iii) and Lemma C.7(i) that
(cid:113)(w∂ l +wr∂r l)P mmpr l(cid:121) = w(cid:113)(−2p2 lδ lm+2p lp2 m)pr l(cid:121)+wr (cid:113)(p m−p2 m)(pr l −pr2 l)(cid:121)
=
wE(cid:2) pr⊤(cid:0) −2p⊙2+2p∥p∥2(cid:1) |q(cid:3) +wrE(cid:2) (1−∥p∥2)(1−∥pr∥2)|q(cid:3)
,
2 2 2
where the last equality holds by noting that (cid:80) lδ lmpr
l
−pr lpr
m
= 0. For (cid:113)(w∂
l
+wr∂r l)P lmpr m(cid:121), we
have also by Lemma C.7(iii) and Lemma C.7(i) that
(cid:113)(w∂ l +wr∂r l)P lmpr m(cid:121) = w(cid:113)(2p mp2 l −2p2 mδ lm)pr m(cid:121)+wr (δ lmp l −p lp m)(δ lmpr l −pr lpr m)
(cid:74) (cid:75)
=
wE(cid:2) pr⊤(cid:0) −2p⊙2+2p∥p∥2(cid:1) |q(cid:3) +wrE(cid:2) pr⊤p−p⊤pr⊙2−pr⊤p⊙2+(pr⊤p)2|q(cid:3)
.
2
Lastly, we have
(cid:114)(w∂ +wr∂r )⊗(w∂ +wr∂r )⊗(w∂ +wr∂r )P pr (cid:122)
l l m m n n ml n
= (cid:114)(w∂ +wr∂r )⊗(w∂ +wr∂r )⊗(cid:16) w(cid:0) 2p p2−2p2 δ (cid:1) pr +wrP Pr (cid:17) (cid:122)⊤(312)
m m n n m l m lm n ml nl
// Lemma C.7(iii)
= (cid:114)(w∂ +wr∂r )⊗(w∂ +wr∂r )⊗(cid:0) w(cid:0) 2p p2−2p2 δ (cid:1) pr +wr(δ p −p p )(δ pr −prpr )(cid:1)(cid:122)⊤(3 .12)
m m n n m l m lm n lm l l m ln l l n
Note that all the terms in (cid:0) w(cid:0) 2p p2−2p2 δ (cid:1) pr +wr(δ p −p p )(δ pr −prpr )(cid:1) are of effective
m l m lm n lm l l m ln l l n
order 1. Now, we apply (w∂
+wr∂r
) to these terms and only keep track of those terms of effective
m m
61order 1. Using Lemma C.13, we have
(cid:114)(w∂ +wr∂r )(cid:0) w(cid:0) 2p p2pr −2p2 pr δ (cid:1) +wr(δ p pr −δ p prpr −δ p p pr +p p prpr )(cid:1)(cid:122)⊤
m m m l n m n lm lmn l l lm l l n ln l m l l m l n
= (cid:114)w⊗2(2p p2pr −4p2 pr δ )+wr⊗w(δ p pr −δ p prpr −δ p p pr +p p prpr )
⩽1 m l n m n lm lmn l l lm l l n ln l m l l m l n
+wr⊗2(δ p pr −δ p prpr )(cid:122).
lmn l l lm l l n
In the above calculation, we note that W(R(m)) ≥ 1 holds for all terms. Hence, we apply (C.21)
to these terms for both ∂ and ∂r . For (cid:0) 2p p2pr −2p2 pr δ (cid:1) , only terms with ∂ survives since
m m m l n m n lm m
b = 0 for pr. For (δ p pr −δ p prpr −δ p p pr +p p prpr ), when applying ∂ , all the terms
m lmn l l lm l l n ln l m l l m l n m
remain unchanged since the (cid:80) a = 1 and when applying ∂r , we have ∂r (−δ p p pr +
s∈R(m) s m m ln l m l
p p prpr ) = 0. Next, we apply (w∂ +wr∂r ) to the above expressions,
l m l n n n
(cid:114)(w∂ +wr∂r )(cid:16) w⊗2(2p p2pr −4p2 pr δ )+wr⊗w(δ p pr −δ p prpr −δ p p pr +p p prpr )
n n m l n m n lm lmn l l lm l l n ln l m l l m l n
(cid:17) ⊤(231)
+wr⊗2(δ p pr −δ p prpr ) (cid:122)
lmn l l lm l l n
= (cid:114)w⊗2⊗wr(2p p2pr −4p2 pr δ )+wr⊗w⊗wr(δ p pr −δ p prpr −δ p p pr +p p prpr )
⩽1 m l n m n lm lmn l l lm l l n ln l m l l m l n
+wr⊗w⊗2(δ p pr −δ p p pr)+wr⊗3(δ p pr −δ p prpr )+wr⊗2⊗wδ p pr(cid:122)
lmn l l ln l m l lmn l l lm l l n lmn l l
= (cid:113)w⊗2⊗wr(2p mp2 lpr n−4p2 mpr nδ lm)+wr⊗2⊗wδ lmnp lpr l(cid:121)
=
E(cid:2) −2w⊗2⊗wr∥p∥2+wr⊗2⊗wp⊤pr|q(cid:3)
.
2
Inthefirstequality,weagainhaveW(R(n)) ≥ 1foralltermsandweonlyuse(C.21)forcalculation.
This time, applying ∂ to (2p p2pr − 4p2 pr δ ) gives 0 since (cid:80) a = 0. Applying ∂r to
n m l n m n lm s∈R(n) s n
the second part (δ p pr − δ p prpr − δ p p pr + p p prpr ) does not change the form since
lmn l l lm l l n ln l m l l m l n
(cid:80) b = 1. Applying ∂ to (δ p pr −δ p prpr −δ p p pr +p p prpr ) only gives us the
s∈R(n) s n lmn l l lm l l n ln l m l l m l n
first and the third terms. Applying ∂r to (δ p pr −δ p prpr ) does not change the form since
n lmn l l lm l l n
(cid:80) b = 1 and applying ∂ to (δ p pr − δ p prpr ) gives us δ p pr. Moreover, for the
s∈R(n) s n lmn l l lm l l n lmn l l
(cid:80)
second equality, we have the 2nd-4th terms zero by noting that p = 1 by the normalization of
l l
the attention probability.
(cid:80)
Wesummarizetheaboveresultsintothefollowingtable,wherethehighestdegree( a +b )
v∈V v v
is upper bounded by counting the total number of p, pr and T in the expression. Here, P =
lm
δ p −p p is counted as 2 and each T raises the degree at most 1 by Lemma C.13.
lm l l m
(h) (h) (h) (h) (h) (h)
Inthesequel,wedenotebyα ,α ,α thevectorofeigenvaluesofA ,A ,A
Signal Noise Intf Signal Noise Intf
(h) (h) (h) (h) (h) (h)
respectively, andβ ,β ,β the vector of eigenvalues ofB ,B ,B respectively.
Signal Noise Intf Signal Noise Intf
Combining the above results with the fact that
Φ⊤A(h)
Φ is diagonal in Proposition C.1, we have
XX
for each terms in
Φ⊤A(h)
Φ that
XX
α(h) = − 1 E(cid:104) (cid:0) −2∥p(h)∥2+err (cid:1) ·(cid:10) ω(h)⊙(Λµ(h)),q⊙2(cid:11) ·ω(h)⊙q⊙2(cid:105)
Signal d 2 >1
x
−
1 E(cid:104) (cid:0) 1−∥p(h)∥2(cid:1) ·(Λµ(h))⊙q⊙2(cid:105)
,
d 2
x
62Objects Expressions Degree
(cid:113)T l ◦p l(cid:121) = E(cid:2) w·(1−∥p∥2 2)|q(cid:3) 2
(cid:113)(T
l
⊗T m)◦(pr lp m)(cid:121) = ⩽1E(cid:2) wr⊗w·(1−∥p∥2 2−∥pr∥2 2)+w⊗wr·p⊤pr|q(cid:3) 4
(cid:113)(T l ⊗T m)◦P ml(cid:121) = E(cid:2) w⊗2·2(−∥p∥2 2+4∥p∥3 3−3∥p∥4 2)|q(cid:3) 4
(cid:113)T
l
◦(P mmpr l)(cid:121) = E(cid:2) w·2pr⊤(cid:0) −p⊙2+p∥p∥2 2(cid:1) +wr·(1−∥p∥2 2)(1−∥pr∥2 2)|q(cid:3) 4
(cid:113)T
l
◦(P lmpr m)(cid:121) = ⩽1E(cid:2) w·2pr⊤(cid:0) −p⊙2+p∥p∥2 2(cid:1) +wr·pr⊤p|q(cid:3) 4
(cid:113)(T
l
⊗T m⊗T n)◦(P mlpr n)(cid:121) = ⩽1E(cid:2) w⊗2⊗wr·(−2∥p∥2 2)+wr⊗2⊗w·p⊤pr|q(cid:3) 6
(h) (h)
Table 2: Expressions for Terms in the Decomposition of A and B and Their Highest Degrees.
XX Y
H
α(h)
=
(cid:88) σ2E(cid:104) (cid:10) µ(h),µ(h′)(cid:11) ·(cid:16)
err
·ω(h)+(cid:0) p(h)⊤ p(h′)+err (cid:1) ·ω(h′)(cid:17) ⊙q⊙2(cid:105)
,
Noise >1 >1
h′=1
H
α(h)
=
(cid:88) 1 E(cid:104) Λ(cid:0) µ(h)⊙µ(h′)(cid:1) ⊙(cid:16)
err
ω(h)+(cid:0)
1+err
(cid:1) ω(h′)(cid:17) ⊙q⊙2(cid:105)
Intf d >1 >0
x
h′=1
H
+
(cid:88) 1 E(cid:104)(cid:16) 1⊤Λ(cid:0) µ(h)⊙µ(h′)(cid:1)
1
+Λ(cid:0) µ(h)⊙µ(h′)(cid:1)(cid:17) ⊙(cid:16)
err
·ω(h)+(cid:0) p(h)⊤ p(h′)+err (cid:1) ·ω(h′)(cid:17) ⊙q⊙2(cid:105)
d dx dx >1 >1
x
h′=1
H
+ (cid:88) 1 E(cid:104) (cid:0) −2∥p(h)∥2+err (cid:1) ·(cid:10) Λ(cid:0) µ(h)⊙µ(h′)(cid:1) ⊙ω(h)⊙ω(h′),q⊙2(cid:11) ·ω(h)⊙q⊙2(cid:105)
d 2 >1
x
h′=1
H
+
(cid:88) 1 E(cid:104) (cid:0) p(h)⊤ p(h′)+err (cid:1) ·(cid:10) Λ(cid:0) µ(h)⊙µ(h′)(cid:1) ⊙ω(h)⊙ω(h′),q⊙2(cid:11) ·ω(h′)⊙q⊙2(cid:105)
d >1
x
h′=1
H
+
(cid:88) (cid:88) 1 E(cid:104)
err
·(cid:10) Λ(cid:0) µ(h)⊙µ(h′)(cid:1)
⊙ω ⊙ω
,q⊙2(cid:11)
·ω
⊙q⊙2(cid:105)
,
1 2 3
d >1
x
(ω1,ω2,ω3)∈Ωh′=1
where we use err to hide terms that are functions of (p(h),p(h′)) and are of effective order higher
>k
than k. In addition, we denote by Ω = {ω(h),ω(h′)}3\{(ω(h),ω(h′),ω(h)),(ω(h),ω(h′),ω(h′))}. Here,
wealsousethefactthatA◦(Ur ⊤U ) = diag(Λ(µr⊙µ))andA◦(U⊤) = diag(Λµ)duetothefactthat
Y Y Y
Ur
and U are simultaneously diagonalizable by Ψ. Similarly, we have for each terms in
Ψ⊤B(h)
Ψ
Y Y Y
that
H
β(h) = − 1 E(cid:104) (cid:0) 1−∥p(h)∥2(cid:1) ·Λ⊤(ω(h)⊙q⊙2)(cid:105) + (cid:88) σ2E(cid:104) p(h)⊤ p(h′)·µ(h′)(cid:105)
d 2
x
h′=1
H
+
(cid:88) 1 E(cid:104) µ(h′)⊙Λ⊤(cid:16)(cid:16) ω(h′)⊙ω(h)(1+err )+ω(h)⊙2
err
+ω(h′)⊙2
err
(cid:17) ⊙q⊙2(cid:17)(cid:105)
d >0 >1 >1
x
h′=1
H
+ (cid:88) 1 E(cid:104) p(h)⊤ p(h′)·µ(h′)⊙(cid:0) Λ⊤1 (cid:1)(cid:105) .
d
dy
x
h′=1
63(h) (h)
C.2.2 Error Analysis for the Approximation of A and B
XX Y
In order to derive an approximation of A(h) and B(h) , we propose the following conditions on µ(h)
XX Y
and ω(h).
Condition C.14. For fixed ϵ ∈ (0,1) and ϵ ∈ (0,1), we consider the following regime for
0
{ω(h)} :
h∈[H]
2logL
∥ω(h)∥ ≤ L−1/4·(logL)−1/2, ∥ω(h)∥2 ≤ , ∥ω(h)∥4 ≤ L−(1−ϵ0)·(logL)−1,
∞ 2 3c2 4
where c ∈ R is the minimal constant satisfying
+
(cid:40) √ (cid:41)
1 3 12 5
max + , ≤ ϵ.
(cid:112)
c 1+ 1+c2/2 2c
We also consider the following regime for {µ(h)} :
h∈[H]
H (cid:113)
µ( ih′) ω i(h′) ≥ 0, (cid:88) µ( ih′) ω i(h′) ≤ O(1), (cid:12) (cid:12)µ( ih)(cid:12) (cid:12) ≤ 2Lϕ−
i
1, ∀i ∈ [d y],h ∈ [H],
h′=1
where ϕ = 1+SNR−1 = 1+(σ2d)/(d λ ).
i i i i
The above conditions on ω(h) is motivated by Lemma B.3 and Lemma B.4 where in Lemma B.4
√
2Deg(G) 2κ+1
we plug in Deg(G) ≤ 6 and κ = 2 in the condition ≤ c. The fact Deg(G) ≤ 6 is
ϵκ
according to the highest degree in Table 2. Under Condition C.14, we conclude from Lemma B.3
that
 
(cid:32) exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)(cid:33)2
E  E[p(h)⊤ p(h′)|q]−  ≤ O(L−(3−ϵ0)). (C.22)
L
And if Ord(G) ≥ 2 and Deg(G) ≤ 6 for some graph G, then the G-induced polynomial f (p(h),p(h′))
G
satisfies
(cid:104) (cid:105)
E f (p(h),p(h′))2 ≤ O(L−4·(1−ϵ)) (C.23)
G
by Lemma B.4.
To use the previous results, we need to decouple the randomness in f (p(h),p(h′)) and some
G
polynomials of q.
Notations. In the sequel, we use f to denote terms with effective order equal to 1 and f
=1 >1
to denote terms with effective order greater than or equal to 2 where we hide the dependence on
(p(h),p(h′)) in the notation. For our need, we consider two kinds of polynomials in q: (i) g(q) = q⊙2
and (ii) g(q) = ⟨v,q⊙2⟩·q⊙2 where v ∈ Rd is a constant vector. We abbreviate g(q) as g in the
+
sequel. We drop the superscript (·)(h) and replace (·)(h′) by (Ă ·) for simplicity. We denote by v the
i
i-th entry of v and v the vector obtained from v with the i-th entry removed.
−i
64Lemma C.15. Suppose v ∈ Rd or v ∈ Rd. Under Condition C.14, we have
+ −
(cid:40)(cid:12) (cid:12) E(cid:2) (p⊤pr+f )·⟨v,q⊙2⟩·q2(cid:3) (cid:12) (cid:12) (cid:12) (cid:12)E(cid:2) (p⊤pr+f )·q2(cid:3) (cid:12) (cid:12)(cid:41)
max (cid:12) >1 i −1(cid:12), (cid:12) >1 i −1(cid:12) ≤ O(L−(1−ϵ0)/2),
(cid:12) exp(cid:0)(cid:10) ω,ωr(cid:11)(cid:1) ·L−1·(⟨v⟩+2v ) (cid:12) (cid:12) exp(cid:0)(cid:10) ω,ωr(cid:11)(cid:1) ·L−1 (cid:12)
(cid:12) i (cid:12) (cid:12) (cid:12)
(cid:40)(cid:12) (cid:12)E(cid:2)
f
·⟨v,q⊙2⟩·q2(cid:3)(cid:12)
(cid:12)
(cid:41)
max (cid:12)
(cid:12)
> (1
⟨v⟩+2v )
i (cid:12) (cid:12), (cid:12) (cid:12)E(cid:2) f >1·q i2(cid:3)(cid:12) (cid:12) ≤ O(L−2(1−ϵ)).
(cid:12) i (cid:12)
Proof. (Proof of Lemma C.15) See Appendix G.2.2 for a detailed proof.
Notations. Recall that
(cid:0) (cid:1)
Λ = diag λ 1 ,...,λ 1 ,0 ,...,0 ,
1 d1 I dI dI+1 d
dy
where 1 is a d -dimensional all-one vector. For the eigenvalues µ(h) and ω(h), we denote by µ(h)
di i i
the i-th entry of µ(h), and ω(h) the average of the i-th block of ω(h), where the blocks are defined
i
by the row partition of Λ for i ∈ [d ]. Moreover, if I < d , we assign nominal tasks indexed by
y y
j = I +1,...,d with λ = 0, dimension d such that
(cid:80)dy
d =
d−(cid:80)I
d , and define
µ(h)
y j j j=I+1 j i=1 i j
(h)
and ω for j ∈ {I + 1,...,d } accordingly. We let d = (d ,...,d ) be the vector containing
j y 1 dy
the dimensions for each corpus. We denote by α(h) the average of α(h) within the ith block and
i
α = (α ,...,α ) the vector containing the averages for each corpus. Equipped with Lemma C.15,
1 dy
we have for each terms in
Φ⊤A(h)
Φ that
XX
H
dα(h)
=
(cid:88) λ⊙µ(h)⊙µ(h′)⊙ω(h′)⊙(cid:0) 1±L−1(cid:1)
(C.24)
Intf
h′=1
H
+
(cid:88) λ⊙µ(h)⊙µ(h′)⊙ω(h)⊙(cid:16) ±L−2(1−ϵ)(cid:17)
(C.25)
h′=1
+
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
(cid:10) d⊙λ,µ(h)⊙µ(h′)(cid:11) ω(h′)⊙(cid:16) 1±(d−1 +L−1− 2ϵ0 )(cid:17) (C.26)
L min
h′=1
H
+
(cid:88)(cid:10) d⊙λ,µ(h)⊙µ(h′)(cid:11) ω(h)⊙(cid:16) ±L−2(1−ϵ)(cid:17)
(C.27)
h′=1
−
(cid:88)H 2exp(cid:0)(cid:10) ω(h),ω(h)(cid:11)(cid:1)
(cid:10) d⊙λ,ω(h)⊙ω(h′)⊙µ(h)⊙µ(h′)(cid:11) ω(h)⊙(cid:16) 1±(cid:0) d−1 +L−1− 2ϵ0(cid:1)(cid:17) (C.28)
L min
h′=1
+
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
(cid:10) d⊙λ,ω(h)⊙ω(h′)⊙µ(h)⊙µ(h′)(cid:11) ω(h′)⊙(cid:16) 1±(cid:0) d−1 +L−1− 2ϵ0(cid:1)(cid:17) (C.29)
L min
h′=1
H
+
(cid:88) (cid:88)(cid:10) d⊙λ,(cid:12)
(cid:12)ω 1⊙ω
2⊙µ(h)⊙µ(h′)(cid:12) (cid:12)(cid:11)
ω
3⊙(cid:16) ±L−2(1−ϵ)(cid:17)
, (C.30)
(ω1,ω2,ω3)∈Ωh′=1
65dα S(h i)
gnal
= 2exp(cid:0)(cid:10) ω( Lh),ω(h)(cid:11)(cid:1) (cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ω(h)⊙(cid:16) 1±(d− m1 in+L−1− 2ϵ0 )(cid:17) −λ⊙µ(h)⊙(1±L−1),
dα
N(h o)
ise
=
(cid:88)H σ2dexp(cid:0)(cid:10) ω(h L),ω(h′)(cid:11)(cid:1) (cid:10) µ(h),µ(h′)(cid:11) ω(h′)⊙(cid:16) 1±L−1− 2ϵ0(cid:17)
h′=1
H
+
(cid:88) σ2d(cid:10) µ(h),µ(h′)(cid:11) ω(h)⊙(cid:16) ±L−2(1−ϵ)(cid:17)
,
h′=1
where we have
(cid:16) (cid:17)
Ω =
{ω(h),ω(h′)}⊗2\{(ω(h),ω(h′))} ⊗{ω(h),ω(h′)},
as all the possible combinations of (ω(h),ω(h′)) except for the combinations that already appear in
(C.28) and (C.29). Here, we define d = min d and the additional error d−1 comes from
min i∈[I] i min
the approximation of ⟨v⟩+2v in Lemma C.15 with ⟨v⟩ since there are at least d terms equal
i min
to v in the summation ⟨v⟩ and each coordinate of v is either non-negative or non-positive. Here,
i
x = a ± b means that the upper bound for x is a + O(b) and the lower bound is a − O(b). In
(h)
addition, we are able to invoke Lemma C.15 for (C.28), (C.29) and the first term in dα since
σ
ω(h) ⊙ ω(h′) ⊙ µ(h) ⊙ µ(h′) and µ(h) ⊙ ω(h) have non-negative entries according to the condition
(h) (h)
µ ω ≥ 0 in Condition C.14. Due to the same reason, we include an absolute value in (C.30) to
i i
ensure that the entries of ω ⊙ω ⊙µ(h) ⊙µ(h′) are non-negative in order to invoke Lemma C.15,
1 2
where we treat (C.30) as an error term. Similarly, for
Ψ⊤B(h)
Ψ we have
Y
dβ(h) = −d⊙λ⊙ω(h)⊙(cid:0) 1±L−1(cid:1) +
(cid:88)H σ2dexp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
µ(h′)⊙(cid:16) 1±L−1− 2ϵ0(cid:17) (C.31)
L
h′=1
H
+
(cid:88) d⊙λ⊙ω(h)⊙ω(h′)⊙µ(h′)⊙(cid:0) 1±L−1(cid:1)
(C.32)
h′=1
H
+
(cid:88) d⊙λ⊙(cid:16) ω(h)⊙2 +ω(h′)⊙2(cid:17) ⊙µ(h′)⊙(cid:16) ±L−2(1−ϵ)(cid:17)
(C.33)
h′=1
+
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
d⊙λ⊙µ(h′)⊙(cid:16) 1±L−1− 2ϵ0(cid:17)
, (C.34)
L
h′=1
C.2.3 Further Approximation for Symmetric Weights
(h) (h)
In this part, we consider the case where both W and U are Positive Semi-definite (PSD)
X Y
(h) (h)
matrices, which means that µ ≥ 0 and ω ≥ 0 for all i ∈ [d ] and h ∈ [H]. We first simplify
i i y
α(h) . We consider the second order terms which scales as L−2(1−ϵ). For (C.30), we note that the
Intf
possible combinations for (ω ,ω ) are (ω(h),ω(h)), (ω(h′),ω(h′)), and (ω(h′),ω(h)) while ω can be
1 2 3
either ω(h) or ω(h′). If (ω ,ω ) = (ω(h′),ω(h)), we can get rid of the absolute value in (C.30). To
1 2
this end, we notice that the form of this term is then no different from either (C.28) or (C.29)
depending on the choice of ω , while both (C.28) and (C.29) can only be larger than L−1. Hence,
3
we can add an additional error term L−(1−2ϵ) to both (C.28) and (C.29) and remove the case
(ω ,ω ) = (ω(h′),ω(h)) from (C.30).
1 2
66We further simplify (C.30) if both µ and ω are non-negative. For the remaining cases, we note
that ω = ω and ω⊙2 has each element of order o(1) according to Condition C.14. If ω = ω(h), we
1 2 1 3
have (C.30) bounded by (C.27) element-wise and if ω = ω(h′), we have (C.30) bounded by (C.26)
3
times L−(1−2ϵ) element-wise. For the second term (C.25), we also have by the non-negativity of µ
that it is bounded by (C.27) element-wise. Hence, we conclude that only (C.27) survives as the
(h)
second order term in α if both µ and ω are non-negative.
Intf
Next, we consider the first order terms which scales as L−1. By noting that µ(h′)⊙ω(h′) < O(1)
element-wise according to Condition C.14, we have that (C.28) is upper bounded by the first
term in dα S(h i)
gnal
up to some constant. By noting that ∥ω(h)∥
∞
< O(L−(1−ϵ0)/4) according to
Condition C.14, we have that (C.29) is upper bounded by (C.26) times L−(1−ϵ0)/2. In summary,
we have for α(h) that
H
dα(h) = −(cid:0) 1±L−1(cid:1) ⊙λ⊙µ(h)+ (cid:88) (cid:0) 1±L−1(cid:1) ⊙λ⊙µ(h)⊙µ(h′)⊙ω(h′) (C.35)
h′=1
+
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ω(h′)⊙(cid:16) 1±(d−1 +L−1− 2ϵ0 +L−(1−2ϵ))(cid:17)
L min
h′=1
+
exp(cid:0)(cid:10) ω(h),ω(h)(cid:11)(cid:1)
(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ω(h)⊙(±1)+
(cid:88)H
(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11)
ω(h)⊙(cid:16) ±L−2(1−ϵ)(cid:17)
.
L
h′=1
Forβ(h),wenotethatthesecondterm(C.33)isoforderL−2(1−ϵ). Notethat∥ω(h)∥
∞
≤ O(L−(1−ϵ0)/4)
according to Condition C.14. Hence, we have (C.34) bounded by (C.34) times L−(1−ϵ0)/2. In sum-
mary, we have for β(h) that
H
dβ(h) = −(cid:0) 1±L−1(cid:1) ⊙d⊙λ⊙ω(h)+ (cid:88) (cid:0) 1±L−1(cid:1) ⊙d⊙λ⊙ω(h)⊙ω(h′)⊙µ(h′)
h′=1
+
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
d⊙λ⊙ϕ⊙µ(h′)⊙(cid:16) 1±L−1− 2ϵ0(cid:17)
. (C.36)
L
h′=1
67C.3 Preservation of The Decomposability Condition along Gradient Flow
In the previous section, we have shown that the decomposability of the weights implies that both
A(h) and B(h) have only one nonzero block, and these submatrices can be diagonalized by Φ and Ψ.
In the following, we prove that the Decomposability Condition is preserved during the dynamics,
given that the initialization of gradient flow satisfies the Decomposability Condition.
Proof. (Proof of Lemma 3.2) Below we verify the preservation of the conditions in Definition 3.1
one by one.
(h) (h)
Preservation of U = 0 and W = 0. We first show the easy part in Definition 3.1(i) that
X Y
U(h) = 0 and W(h) = 0 during the dynamics. Recall from Appendix C.1 that A(h) only has the
X Y
left-top block A(h) ∈ Rd×d being non-zero. Therefore, the time-derivative of W(h) = K(h)⊤ Q(h)
XX Y Y X
satisfies
(h) (h)⊤ (h) (h)⊤ (h)
∂ W = ∂ K Q +K ∂ Q
t Y t Y X Y t X
(cid:34) (cid:35)
= −d−1/2(cid:18) (cid:104) A(h) A(h)(cid:105) Q(h)⊤ Q(h) +K(h)⊤ K(h) A( Xh X) (cid:19)
e YX YY X Y A(h)
YX
=
−d−1/2K(h)⊤ K(h) A(h)
= 0,
e Y X XX
(h) (h)
where the last equality holds by Definition 3.1(i) that span(K ) ⊥ span(K ). Also, we note
X Y
that B(h) only has the right block B(h) ∈ Rdy×dy being non-zero. Thus the time-derivative of
Y
U(h)
=
O(h)V(h)
satisfies
X X
∂ U(h) = ∂ O(h)V(h) +O(h)∂ V(h)
t X t X t X
= −(cid:104) B(h) B(h)(cid:105) V(h)⊤ V(h) −O(h)O(h)⊤ B(h)
X Y X X
(h) (h)⊤ (h)
= −B V V = 0,
Y Y X
(h) (h)
wherethelastequalityholdsbyDefinition3.1(i)thatspan(V ) ⊥ span(V ). Hence,weconclude
X Y
(h) (h)
that U ≡ 0 and W ≡ 0 along the gradient flow trajectory if they are initialized to be zero.
X Y
Preservation of Subspace Orthogonality. We next show that Definition 3.1(i) is preserved,
(h)⊤ (h) (h)⊤ (h)
for which it suffices to show that ∂ (K K ) ≡ 0 and ∂ (V V ) ≡ 0. The time derivatives
t Y X t X Y
(h) (h)
of K and K are given by
X Y
   
(h)⊤ (h)⊤
∂ tK X(h) = −d− e1/2Q(h) A X (hX )⊤ = −d e−1/2Q( Xh) A( Xh X)⊤ , ∂ tK Y(h) = −d e−1/2Q(h) A Y (hX )⊤ = 0.
A A
XY YY
These further imply
∂
(K(h)⊤ K(h)
) =
K(h)⊤
∂
K(h)
=
−d−1/2K(h)⊤ Q(h) A(h)⊤
=
−d−1/2W(h) A(h)⊤
= 0.
t Y X Y t X e Y X XX e Y XX
68Similarly, we have ∂
V(h)
=
−O(h)⊤ B(h)
= 0,∂
V(h)
=
−O(h)⊤ B(h)
, and thus
t X X t Y Y
∂
(V(h)⊤ V(h)
) =
V(h)⊤
∂
V(h)
=
−V(h)⊤ O(h)⊤ B(h)
=
−U(h)⊤ B(h)
= 0.
t X Y X t Y X Y X Y
(h) (h)
In the above two derivations, we have used Definition 3.1(i) that U = 0 and W = 0.
X Y
Preservation of Definition 3.1(ii) via diagonality of
Φ⊤A(h)
Φ and
Ψ⊤B(h)
Ψ. Under the
XX Y
(cid:104) (cid:105)
common singular vector space condition in Definition 3.1(ii), let Υ(h) = υ(h) ,...,υ(h) ∈ Rde×d
1 d
and Φ(h) ∈ Rd×d be the common left- and right-singular vector matrix for both Q(h) and K(h) , and
X X
(cid:104) (cid:105)
Θ(h) = θ(h) ,...,θ(h) ∈ Rde×dy and Ψ(h) ∈ Rdy×dy be the common left- and right-singular vector
1 dy
matrix for both V(h) and O(h)⊤ . Simply put, we can decompose Q(h) ,Kh,V(h) and O(h) into
Y X X Y
Q(h) = Υ(h)diag(σ(Q(h) ))Φ⊤, K(h) = Υ(h)diag(σ(K(h) ))Φ⊤,
X X X X
V(h) = Θ(h)diag(σ(V(h) ))Ψ⊤, O(h) = Ψdiag(σ(O(h)))Θ(h),
Y Y
where (σ(Q(h) ),σ(K(h) )) ∈ Rd and (σ(V(h) ),σ(O(h))) ∈ Rdy are the semi-singular values6. Note
X X Y
that we also have σ(Q(h) )⊙σ(K(h) ) = ω(h) and σ(V(h) )⊙σ(O(h)) = µ(h). Our goal is to show that
X X Y
the singular vector spaces remain unchanged for all these four matrices during the dynamics. With
(h) (h)
the observations that only A and B are non-zero, we have the following dynamics as we have
XX Y
derived in the previous step:
∂ K(h) = −d−1/2Q(h) A(h)⊤ = −d−1/2Υ(h)diag(σ(Q(h) ))(cid:0) Φ⊤A(h) Φ(cid:1)⊤ Φ⊤,
t X e X XX e X XX
∂ Q(h) = −d−1/2K(h) A(h) = −d−1/2Υ(h)diag(σ(K(h) ))(cid:0) Φ⊤A(h) Φ(cid:1) Φ⊤,
t X e X XX e X XX
∂ O(h) = −B(h) V(h)⊤ = −Ψ(cid:0) Ψ⊤B(h) Ψ(cid:1) diag(σ(V(h) ))Θ(h)⊤ ,
t Y Y Y Y
∂ V(h) = −O(h)⊤ B(h) = −Θ(h)diag(σ(O(h)))(cid:0) Ψ⊤B(h) Ψ(cid:1) Ψ⊤.
t Y Y Y
To this end, it suffices to verify that both
Φ⊤A(h)
Φ and
Ψ⊤B(h)
Ψ are diagonal matrices in order to
XX Y
showthatthesingularvectorspacesremainunchanged.
ThediagonalityofΨ⊤B(h)
Ψ
andΦ⊤A(h)
Φ
Y XX
is shown by Proposition C.1. Hence, we conclude that the singular vector spaces remain unchanged
during the dynamics.
Preservation of Definition 3.1(iii). Note that the previously, Definition 3.1(i) and Defini-
tion 3.1(ii) are self-preserved during the dynamics. We next show that Definition 3.1(iii) is also
preservedduringthedynamicsifthecurrentstatesatisfiesthiscondition. LetJ betheindexsetof
i
(h) (h)
thesupportofthei-thtaskaswehavedefinedinthemaintext. Giventhatσ(Q ) = σ(Q ) for
X m X n
any m,n ∈ J , and the same for
K(h)
, it suffices to check that the diagonal entries of
Φ⊤A(h)
Φ are
i X XX
the same for any m,n ∈ J . We say a Rd×⋆ matrix (or vector) is Within-Task Homogeneous (wth)
i
if the m-th and the n-th rows (or entries) are always the same. Note that operators T (by the wth
l
6We use the phrase “semi-singular” since σ(Q(h)),σ(K(h)),σ(V(h)) and σ(O(h)) are not necessarily non-negative.
X X Y
69of ω(h)) and A (by the wth property of Λ = E[G⊙2]) are both wth. Therefore, it suffices to check
that both
(cid:20) (cid:21)
(cid:88)
E[f(s,sr)qq⊤], E f(s,sr) q2qq⊤
j
j∈Ji
have wth diagonal entries for any function f that only depends on s and sr and any j ∈ [d].
These formulas capture all the terms in the decomposition of
Φ⊤A(h)
Φ. The first term captures
XX
the signal term, the noise term, and the first three interference terms in the decomposition of
Φ⊤A(h)
Φ. The last term captures the last interference term in the decomposition of
Φ⊤A(h)
Φ.
XX XX
Notably, by Lemma C.4, f(s,sr) is a function of only ⟨ω⊙2,q⊙2⟩, ⟨ωr⊙2,q⊙2⟩, and ⟨ω⊙ωr,q⊙2⟩. For
now, we can rewrite ⟨ω⊙2,q⊙2⟩ = (cid:80)I d−1(cid:80) ω2 ·(cid:80) q2 and the same for the remaining
i=1 i k∈Ji k m∈Ji m
terms by the wth property of ω or ωr. Let q be the slice of q that contains only the entries in J .
(i) i
Hence, f(s,sr) is just a function of {∥q ∥ } . Given the 2-norm of q , the posterior distribution
(i) 2 i∈[I] (i)
of q is shuffling-invariant. Therefore, for the first term, we directly conclude that E[f(s,sr)qq⊤]
(i)
has wth diagonal entries. For the second term, we combine f(s,sr) and (cid:80) q2qq⊤ to form a new
j∈Ji(cid:104) j
(cid:105)
function that only depends on {∥q ∥ } . Thus, we also conclude that E f(s,sr)(cid:80) q2qq⊤
(i) 2 i∈[I] j∈Ji j
has wth diagonal entries. Thus, we conclude that Definition 3.1(iii) is also self-preserved during
the dynamics.
70D Analysis of the Spectral Gradient Flow
In this section, we analyze the dynamics and convergence of gradient flow. For the analysis we
separate the dynamics into two stages: the warm-up stage and the growth stage. The warm-up
stage is further divided into five steps, with each step being studied and summarized afterward.
The growth stage consists of the emergence and convergence phases. The dynamics paths are
summarized in Appendix D.3, while the observations regarding emergence and convergence in the
growth stage are summarized in Appendix D.2.4.
Upon success of Lemma 3.2, we have
(h) (cid:112) −1 (h) (h) ⊤ (h) (cid:112) −1 (h) (h)
∂ σ(K ) = − d σ(Q )⊙σ(A ), ∂ σ(Q ) = − d σ(K )⊙σ(A ),
t X e X XX t X e X XX
∂ σ(O(h)) = −σ(B(h) )⊙σ(V(h)⊤ ), ∂ σ(V(h) ) = −σ(O(h)⊤ )⊙σ(B(h) ),
t Y Y t Y Y
(h)
Under the Symmetric Weights (Symmetric Weights) initialization, we always have σ(Q ) =
√ X
σ(K(h) ) = ω(h) and σ(O(h)) = σ(V(h) ) = (cid:112) µ(h). Thus, we can further reduce the dynamics
X Y
to the combined dynamics of µ(h) and ω(h):
∂ ω(h) = −(cid:112) d −1(cid:16) σ(Q(h) )⊙2+σ(K(h) )⊙2(cid:17) ⊙σ(A(h) ) = −2(cid:112) d −1 ω(h)⊙α(h),
t e X X XX e
(cid:16) (cid:17)
∂ µ(h) = − σ(O(h))⊙2+σ(V(h) )⊙2 ⊙σ(B(h) ) = −2µ(h)⊙β(h).
t Y Y
In the following, we rescale the time as t ← 2dt. Note that ω(h) ∈ Rdy is just a collection of
the unique task-wise values in ω(h). Recall the simplification of α(h) and β(h) in (C.35) and (C.36),
which gives
H
(cid:112) d ∂ ω(h) = (cid:0) 1±L−1(cid:1) ⊙λ⊙µ(h)⊙ω(h)− (cid:88) (cid:0) 1±L−1(cid:1) ⊙λ⊙µ(h)⊙µ(h′)⊙ω(h′)⊙ω(h)
e t
h′=1
−
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ω(h′)⊙ω(h)⊙(cid:16) 1±(d−1 +L−1− 2ϵ0 +L−(1−2ϵ))(cid:17)
L min
h′=1
exp(cid:0)(cid:10) ω(h),ω(h)(cid:11)(cid:1)
− (cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) (ω(h))⊙2⊙(±1)
L
H
−
(cid:88)(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) (ω(h))⊙2⊙(cid:16) ±L−2(1−ϵ)(cid:17)
. (D.1)
h′=1
Here, we denote by d the vector of task dimensions, i.e., d = (d ,...,d )⊤. Also, we have
1 I
H
∂ µ(h) = (cid:0) 1±L−1(cid:1) ⊙d⊙λ⊙ω(h)⊙µ(h)− (cid:88) (cid:0) 1±L−1(cid:1) ⊙d⊙λ⊙ω(h)⊙ω(h′)⊙µ(h′)⊙µ(h)
t
h′=1
−
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
d⊙λ⊙ϕ⊙µ(h′)⊙µ(h)⊙(cid:16) 1±L−1− 2ϵ0(cid:17)
. (D.2)
L
h′=1
For simplicity, we let
ξ ≜ L−1, ζ ≜ d−1 +L−1− 2ϵ0 +L−(1−2ϵ), η ≜ L−2(1−ϵ).
min
71We consider I to be the set of tasks with λ = Θ(1) and I to be the set of tasks with λ = 0,
i c i
which we call the effective and nominal tasks, respectively. This is a generalization of the setting in
Theorem 3.3where all tasks are effective. We will study the more general setting in the dynamics’
analysis.
In the following, we will study the behavior of the dynamics in (D.1) and (D.2). We assume
ω(h) to have the same initialization for each coordinate and have ω(h) (0) = ω for each h ∈ [H] and
i 0
i ∈ I. For µ(h), we don’t restrict all eigenvalues to be the same. The following is the assumption
for the initialization of µ(h). We also let
σ2d
ϕ = 1+ = 1+SNR−1,
i d λ i
i i
where SNR = d λ /(σ2d) is the signal-to-noise ratio for the i-th task.
i i i
Assumption D.1 (Initialization). We assume ω(h) to have the same initialization for each coor-
dinate with ω(h) = ω where max{ω2d,HLω2} ≪ 1 for all i ∈ [d ]. For each task i ∈ I, we assume
i 0 0 0 y
there exist a unique “optimal head” h⋆ such that for any h ̸= h⋆, µ(h) (0) < µ(h⋆ i) (0), and a minimal
i i i i
marginal difference ϵ ∈ (0,1) such that
(h⋆) (h)
µ i (0)−µ (0)
i i ≥ ϵ = Θ(1), ∀h ̸= h⋆, ∀i ∈ I.
(h⋆) i
µ i (0)
i
We consider h⋆ ̸= h⋆ for i ̸= j, which means that each task has a unique optimal head and no two
i j
tasks share the same optimal head. We assume that the initialization µ⋆(0) satisfies the following
i
condition,
⟨d,λ⊙ϕ⟩λ−1·50HLω3ϵ−1 ≪ µ⋆(0) ≪ Lω /(2Hϕ ), ∀i ∈ I.
i 0 i 0 i
For the nominal task, we assume µ(h) (0) ≪ min (Lϕ−1 ∧d )(cid:112) |I |H−1 ·ω , µ(h) (0)2 ≪ SNR ·
j i∈I i i c 0 j i
(1∧L/(d ϕ ))/(H|I |ζ) for all h ∈ [H] and j ∈ I . Moreover, we assume that ω satisfies
i i c c 0
λ
i
ω ≪ max .
0
i∈I ϕ i⟨d,λ⊙ϕ⟩ζ
2C (cid:18) ⟨d,λ⊙ϕ⟩ (cid:19) λ ϕ−1
· ξ+80HLω2+ ·100H2ω2ϕ ≪ i i .
ϵ 0 λ i 0 i max k∈Iλ kϕ− k1
When it is clear from the context, we use µ⋆ ≡ µ(h⋆ i) and ω⋆ ≡ ω(h⋆ i) . During our analysis, we
i i i i
keep track of the following quantities,
(h) H
ρ(h) ≜ µ i , ρ ≜ (cid:88) ρ(h) .
i Lω⋆ i i
i h=1
We denote by ρ⋆ ≡ ρ(h⋆ i) . The dynamics of ρ(h) is given by
i i i
∂ µ(h) −∂ ω⋆/ω⋆·µ(h) ∂ logµ(h) −∂ logω⋆
∂ ρ(h) = t i t i i i = t i t i ·µ(h) . (D.3)
t i Lω⋆ Lω⋆ i
i i
72D.1 Warm-up Stage
We first give a rigorous definition of the warm-up stage.
Definition D.2 (Warm-up Stage). Let c > 1 be a constant. Let T be the first time that at
warmup
least one of the following conditions is violated:
(A1) (µ⋆−µ(h) )/µ⋆ ≥ ϵ/c holds for all h ̸= h∗ and i ∈ I.
i i i i
(h)
(A2) ω ≤ 4ω holds for all h ∈ [H] and k ∈ [d ].
k 0 y
(h) (h) (h)
(A3) µ ≤ 5Lω holds for all h ∈ [H] and i ∈ I. µ ≤ µ (0) holds for all h ∈ [H] and j ∈ I .
i 0 j j c
(A4) ω⋆/ω(h) ≥ 1 holds for all h ̸= h∗ and i ∈ I.
i i i
(A5) ω⋆/µ⋆ ≤ ω /µ⋆(0) and i ∈ I.
i i 0 i
(A6) µ⋆/ω⋆ ≤ 2Lϕ−1 and i ∈ I.
i i i
(h)
By definition, the warm-up stage corresponds to the stage where ω is within constant factors
k
of ω for all k ∈ [d ] and h ∈ [H]. Note that Condition (A2) and Condition (A3) already implies
0 y
all the conditions in Condition C.14. Thus, we can further simplify the dynamics based on (D.1)
and (D.2) in the warm-up stage. To further decouple the dynamics for each task, we invoke the
following definition.
Definition D.3 (Task-interference-free Dynamics for the Warm-up Stage). Fix a effective or nom-
inal task i ∈ [d ]. We say that a dynamics on µ (t) and ω (t) is a Task-Interference-Free dynamics
y i i
for task i (TIF-i dynamics for short) in the warm-up stage if:
(i) The dynamics for µ (t) and ω (t) are given by (D.2) and (D.1) respectively.
i i
(ii) The initializations of µ (0) and ω (0) satisfy the conditions in Assumption D.1.
i i
(iii) For any other task k ∈ [d ]\{i}, µ (t) and ω (t) satisfy Condition (A1)-Condition (A6) for
y k k
task k at any time.
We define Ti be the smallest time that the TIF-i dynamics violate at least one of the Condition
warmup
(A1)-Condition (A6) for task i.
Equipped with the conditions in Definition D.2 and the definition of the TIF-i dynamics for the
(h) (h)
warm-up stage, we can first simplify the dynamics of ω and µ . When not specified, we use i
i i
to denote an effective task and j to denote a nominal task in the sequel.
(h) (h) (h)
Simplification of ∂ µ and ∂ µ . Recall by (D.2), we have for the TIF-i dynamics of µ
t i t j i
that
H
(h) (h) (h) (cid:88) (h) (h′) (h′) (h)
∂ µ = (1±ξ)d λ ω µ − (1±ξ)d λ ω ω µ µ
t i i i i i i i i i i i
h′=1
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
(h′) (h)
− d λ ϕ µ µ (1±ζ). (D.4)
L i i i i i
h′=1
73where the ratio between the second and first terms is bounded by
(cid:80)H
h′=1(1±ξ)d iλ iω
i(h)
ω
i(h′) µ( ih′) µ( ih)
≤ 2
(cid:88)H
ω(h′) µ(h′) ≤ 40Hω2L,
(h) (h) i i 0
(1±ξ)d λ ω µ
i i i i h′=1
(h′) (h′)
whereCondition(A2)andCondition(A3)areusedforupperboundingω µ inthelastinequal-
i i
ity. Also for the third term, we have exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1) ≤ exp(16dω2) ≤ 1+16edω2 by Condition
0 0
r r
(A2) and exp(x) ≤ 1+ex for x ≤ 1. Based on these observations, we define quantities ξ and ζ as
ξr = ξ+80HLω2 ≪ 1, ζr = ζ +32eω2d ≪ 1,
0 0
(h)
and we can simplify the dynamics of µ as
i
(cid:32) H (cid:33)
(h) (h) r (cid:88) ϕ i (h′) r (h)
∂ µ = λ d µ −(1±ζ)· µ +(1±ξ)·ω .
t i i i i L i i
h′=1
As a result, we also have for ∂
(logµ⋆−logµ(h)
) that
t i i
(cid:32) H (h′)(cid:33)
∂
(cid:16) logµ⋆−logµ(h)(cid:17)
= λ d
(1±ξr )ω⋆−(1±ζr
)ϕ
(cid:88) µ
i
t i i i i i i L
h′=1
(cid:32) H (h′)(cid:33)
−λ d (1±ξr )ω(h) −(1±ζr )ϕ (cid:88) µ i
i i i i L
h=1
(cid:32) H (h′)(cid:33)
= λ d ω⋆−ω(h) ±ξr(cid:16) ω⋆+ω(h)(cid:17) ±2ζr ϕ (cid:88) µ i .
i i i i i i i L
h′=1
(h)
For the nominal task j ∈ I , we have for ∂ µ that
c t j
(h) r
(cid:88)H σ2d
(h′) (h)
∂ µ = −(1±ζ)· ·µ µ . (D.5)
t j L j j
h′=1
Note that this dynamics holds at any time since we are just using λ = 0 for nominal tasks.
j
(h) (h) (h)
Simplification of ∂ ω and ∂ ω . Recall by (D.1), we have for the dynamics of ω that
t i t j i
√
d ·∂
ω(h)
= −(1±ζ)·
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
·(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·ω(h′) ω(h)
e t i L i i
h′=1
H
(cid:88) (h′) (h) (h′) (h) (h) (h)
−(1±ξ)λ · µ µ ω ω +(1±ξ)λ ·µ ω
i i i i i i i i
h′=1
exp(cid:0)(cid:10) ω(h),ω(h)(cid:11)(cid:1)
(±1)· ·(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ·(ω(h) )2
L i
H
(±η)· (cid:88)(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·(ω(h) )2.
i
h′=1
74Here, we can upper bound the inner product
(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11)
and
(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11)
using
Condition (A2) and Condition (A3) as
(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ≤ ⟨d,λ⊙ϕ⟩25L2ω2,
0
(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ≤ ⟨d,λ⟩20Lω2.
0
r r (h)
Thus, following the definition of ζ and ξ, we have for the dynamics of ω that
i
√ d ·∂ ω(h) = −(cid:16) 1±ζr ±HLη±L−1(cid:17) ·⟨d,λ⊙ϕ⟩25Lω2 (cid:88)H ω(h′) ω(h)
e t i 0 i i
h′=1
r (h) (h)
+(1±ξ)λ µ ω
i i i
= ±⟨d,λ⊙ϕ⟩ ·(cid:16) 1±ζr ±HLη±L−1(cid:17) ·25HLω2·λ ω⋆ω(h)
λ 0 i i i
i
r (h) (h)
+(1±ξ)λ µ ω
i i i
= ±⟨d,λ⊙ϕ⟩ ·50HLω2·λ ω⋆ω(h) +(1±ξr )λ µ(h) ω(h) . (D.6)
λ 0 i i i i i i
i
where we use Condition (A4) that ω(h′) ≤ ω⋆ in the second equality and incorporate the fact that
i i
r
1+ζ +HLη+L−1 ≤ 2 in the last inequality. Note that it is unclear which term dominates in
(D.6) since the ratio µ(h) /ω⋆ is unknown. However, for h = h∗, we have a clear picture that
i i i
(cid:112) d ·∂ ω⋆ =
(cid:18)
1±ξr ± ⟨d,λ⊙ϕ⟩ ·50HLω2· ω
i⋆(cid:19)
·λ µ⋆ω⋆
e t i λ 0 µ⋆ i i i
i i
= (cid:16) 1±ξq (t)(cid:17) ·λ µ⋆ω⋆,
i i i i
q
where we define ξ (t) as
i
ξq i(t) = ξr + ⟨d,λ λ⊙ϕ⟩ ·50HLω 02· ω µi ⋆⋆ (cid:12) (cid:12) (cid:12)
(cid:12)
≤ ξr + ⟨d,λ λ⊙ϕ⟩ · 50 µH ⋆(L 0ω )03 =∆ ξq i(0) ≪ 1.
i i t i i
Here, the upper bound is given by Condition (A5) that ω⋆/µ⋆ ≤ ω /µ⋆(0). Similarly, we study the
i i 0 i
dynamics of logω⋆−logω(h) for h ̸= h∗ as
i i i
(cid:112)
d ·∂
(cid:16) logω⋆−logω(h)(cid:17)
e t i i
= ±⟨d,λ⊙ϕ⟩ ·50HLω2·λ ω⋆+(1±ξr )λ µ⋆
λ 0 i i i i
i
± ⟨d,λ⊙ϕ⟩ ·50HLω2·λ ω⋆−(1±ξr )λ µ(h) (D.7)
λ 0 i i i i
i
(cid:32) (cid:33)
= 1± ⟨d,λ⊙ϕ⟩ ·100HLω2· ω i⋆ · µ⋆ i ±ξr · µ⋆ i +µ( ih)
λ
i
0 µ⋆
i
µ⋆−µ(h) µ⋆−µ(h)
i i i i
(cid:16) (cid:17)
·λ ·
µ⋆−µ(h)
i i i
=
(cid:16) 1±ξp (t)(cid:17)
·λ
(cid:16) µ⋆−µ(h)(cid:17)
,
i i i i
75p
where we define ξ (t) as
i
ξp
(t) =
2µ⋆
i
ξq
(t) ≤
2cϵ−1ξq
(t) ≤
2cϵ−1ξq
(0)=∆
ξp
(0) ≪ 1.
i i i i i
µ⋆−µ(h)
i i
Here, we incorporate Condition (A1) to upper bound µ⋆/(µ⋆−µ(h) ) by cϵ−1. We are also interested
i i i
in the dynamics of ω⋆−ω(h) for h ̸= h∗, which can be lower bounded as
i i i
(cid:112) d ·∂ (cid:16) ω⋆−ω(h)(cid:17) = ±⟨d,λ⊙ϕ⟩ ·50HLω2·λ (ω⋆)2+(1±ξr )λ µ⋆ω⋆
e t i i λ 0 i i i i i
i
± ⟨d,λ⊙ϕ⟩ ·50HLω2·λ ω⋆ω(h) −(1±ξr )λ µ(h) ω(h)
λ 0 i i i i i i
i
≥ −⟨d,λ⊙ϕ⟩ ·50HLω2·λ (ω⋆)2+(1−ξr )λ µ⋆ω⋆
λ 0 i i i i i
i
− ⟨d,λ⊙ϕ⟩ ·50HLω2·λ ω⋆ω⋆−(1+ξr )λ µ(h) ω⋆
λ 0 i i i i i i
i
=
(cid:16) 1−ξp (t)(cid:17)
λ
ω⋆(cid:16) µ⋆−µ(h)(cid:17)
,
i i i i i
where the inequality holds by invoking Condition (A4) that ω⋆ ≥ ω(h) and the last equality is given
i i
by a simple comparison to the form of (D.7).
(h)
For the nominal task j ∈ I , we have for ∂ ω that
c t j
(cid:112) d ∂ ω(h) ≤ (±1)·
exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1)
·(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ·(ω(h) )2
e t j L j
H
+(±η)· (cid:88)(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·(ω(h) )2
j
h′=1
≤ (cid:0) CL−1⟨d,λ⟩20Lω2+C⟨d,λ⊙ϕ⟩25L2ω2η(cid:1) ·(ω(h) )2
0 0 j
≤ C(20+25Lζ)·⟨d,λ⊙ϕ⟩·ω2·(ω(h) )2
0 j
≤ 26CLζ ·⟨d,λ⊙ϕ⟩·ω2·(ω(h) )2,
0 j
(cid:124) (cid:123)(cid:122) (cid:125)
≪ 1
where in the last second inequality, we use the fact that ζ ≥ Lη ≥ L−1.
Simplification of ∂ ρ⋆ and ∂ ρ . Recall from (D.3) that the dynamics of ρ⋆ satisfy
t i t i i
∂ logµ⋆−∂ logω⋆
∂ ρ⋆ = t i t i ·µ⋆
t i Lω⋆ i
i
λ d (cid:16) −(1±ζr )·(cid:80)H ϕiµ(h′) +(1±ξr )·ω⋆(cid:17) −(1±ξq (t))·√ d −1 λ µ⋆
i i h′=1 L i i i e i i
= ·µ⋆
Lω⋆ i
i
(cid:32) q (cid:33)
=
λ id iµ⋆
i ·
−(1±ζr
)·ϕ ρ
+(1±ξr
)−
(1 √±ξ i(t))
·
µ⋆
i .
L i i d d ω⋆
e i i
76Here, we invoke the ratio argument in Condition (A6) that µ⋆/ω⋆ ≤ 2Lϕ−1 and ξq (t) ≤ ξq (0) ≪ 1
√ i i i i i
to upper bound the last term by ς =∆ L/( d d ϕ ) ≪ 1. Hence, we have for the dynamics of ρ⋆ that
i e i i i
∂ ρ⋆ = L−1λ d µ⋆·(cid:16) −(1±ζr )·ϕ ρ +(1±ξr ±4ς )(cid:17) .
t i i i i i i i
Similarly, we have for the dynamics of ρ that
i
H λ d (cid:16) −(1±ζr )·(cid:80)H ϕiµ(h′) +(1±ξr )·ω(h)(cid:17) −(1±ξq (t))·√ d −1 λ µ⋆
(cid:88) i i h′=1 L i i i e i i (h)
∂ ρ = ·µ
t i Lω⋆ i
h=1 i
≤ λ d
(cid:32)
−(1±ζr
)·ϕ
ω⋆ρ2+(1±ξr
)·
(cid:80)H
h=1ω
i(h) µ( ih)(cid:33)
i i i i i Lω⋆
i
≤ λ d ρ
ω⋆(cid:16) −(1±ζr
)·ϕ ρ
+(1±ξr )(cid:17)
.
i i i i i i
where in the second inequality, we invoke Condition (A4) that ω(h) ≤ ω⋆.
i i
As a summary, we have the following dynamics for the warm-up stage:
Terms Simplified Dynamics without Cross-task Interference
∂
µ(h)
λ d
µ(h)(cid:0) −(1±ζr
)·ϕ
L−1(cid:80)H µ(h′) +(1±ξr )·ω(h)(cid:1)
t i i i i √ i h′=1 i i
∂ ω⋆ (1±ξq (t))· d −1 λ µ⋆ω⋆
t i i e i i i
∂
(logµ⋆−logµ(h)
) λ d
(cid:0) ω⋆−ω(h) ±ξr(cid:0) ω⋆+ω(h)(cid:1) ±2ζr
ϕ
(cid:80)H µ( ih′)(cid:1)
t i i i i i √i i i i h′=1 L
∂
(logω⋆−logω(h)
)
(1±ξp
(t))· d
−1
λ
(cid:0) µ⋆−µ(h)(cid:1)
t i i i √e i i i
∂
(ω⋆−ω(h)
) ≥
(1−ξp
(t))· d
−1
λ
ω⋆(cid:0) µ⋆−µ(h)(cid:1)
t i i i e i i i i
∂ ρ⋆ L−1λ d µ⋆·(cid:0) −(1±ζr )·ϕ ρ +(1±ξr ±4ς )(cid:1)
t i i i i i i i
(cid:16) r r(cid:17)
∂ ρ ≤ λ d ρ ω⋆ −(1±ζ)·ϕ ρ +(1±ξ)
t i i i i i i i
∂
µ(h)
,j ∈ I
−µ(h) (1±ζr )·(cid:80)H σ2ddy ·µ(h′)
t j c j √ h′=1 L j
∂ ω(h) ,j ∈ I ≤ 26CLζ d −1 ·⟨d,λ⊙ϕ⟩·ω2
t j c e 0
Table 3: Simplified TIF-i Dynamics for the Warm-up Stage before Ti
warmup
UnderthesimplifieddynamicsinTable3, onecouldnoticethattasksaredecoupledinthesense
that the above dynamics are “independent” for each task i ∈ I while only cross-head interference
exists. Based on this observation, we can further split the dynamics for each task into 4 stages.
Definition D.4 (SplitoftheEffectiveTIF-iDynamicsfortheWarm-upStage). Consider a specific
task i ∈ I with the corresponding TIF-i dynamics. Define ϑ=∆
mini∈Iϕiλ−
i
1
≤ 1 as the ratio between
maxj∈Iϕjλ− j1
the smallest and largest ϕ λ−1 within the effective task set I. Let α ,β , and γ be three small
i i i i i
77constants for each i ∈ I such that satisfy
(cid:40) (cid:18) (cid:18) (cid:19) (cid:19) r r (cid:18) (cid:19)(cid:41)
ς i 2Lω 0 r r 18e(ξ+ζ) 2CLω 0
max log ∨H ,ξ+2ζ +4ς , ·log ≪ α ≪ 1,
ϑ ϕ µ⋆(0) i (1−c−1)ϵ ϕ µ⋆(0) i
i i i i
(cid:40) r r r r (cid:41)
cH(ζ +ξ) c(ζ +ξ)2H
max , ≪ β ≪ 1,
ϵϑ (1−c−1)ϵ2ς i
i
(cid:40) (cid:41)
(cid:18) ϵϑ2 (cid:19) Hλ ϕ−1
H ·exp − ≪ γ ≪ min α , i i ,
64cHς i i i max k∈Iλ kϕ− k1
We say that the TIF-i dynamics with i ∈ I fall into one of the following five steps if both (i)
Condition (A1)-Condition (A6) for task i and (ii) additional condition(s) for that corresponding
step listed in the following are satisfied:
Step 1. ρ ϕ ≤ 1−α .
i i i
Step 2. The following conditions hold:
(a) ρ⋆ϕ ≥ (1−α )/H and the dynamics have been through Step 1.
i i i
(b) There exists at least one h ∈ [H]\{h∗} such that (ω⋆−ω(h) )/ω⋆ < (3ζr +2ξr )β−1.
i i i i i
Step 3. The following conditions hold:
(a) (ω⋆−ω(h) )/ω⋆ ≥ (3ζr +2ξr )β−1 for any h ∈ [H]\{h∗}.
i i i i i
(b) There exists at least one h ∈ [H]\{h∗} such that µ⋆/µ(h) < (H −1)/γ .
i i i i
Step 4. the following conditions hold:
(a) µ⋆/µ(h) ≥ (H −1)/γ for all h ∈ [H]\{h∗}.
i i i i
(b) ρ⋆ϕ < 1−α .
i i i
Step 5. ρ⋆ϕ ≥ 1−α .
i i i
We observe that there is no overlap between these five steps by definition.
Under the simplified dynamics, one can notice that the conditions in Definition D.2 are related
in the sense that some of these conditions are critical while others are just a byproduct of the
dynamics. In the following proposition, we present such relations and show how the “critical”
conditions imply the others.
Lemma D.5 (Critical Conditions). For any t ∈ (0,∞), we have the following facts for the TIF-i
dynamics where i ∈ I:
(i) If Condition (A1)-Condition (A6) hold for τ ∈ [0,t), then Condition (A4)-Condition (A6)
always hold with some marginal gap in the inequalities at time t.;
(ii) If Condition (A2) holds with some marginal gap at t and Condition (A1) also holds at t, then
Condition (A2) and Condition (A3) hold with some marginal gap in the inequalities for any
τ ∈ (0,t];
78r r
In particular, by scrutinizing the simplified dynamics in Table 3, we have ρ ϕ ≤ 1+ξ +2ζ and
i i
that both ω⋆ and ω⋆/ω(h) are increasing for any h ∈ [H]\{h∗}. For the nominal task j ∈ I , we
i i i i c
(h)
have µ nonincreasing for any h ∈ [H], which holds not only for the warm-up stage but also for
j
the entire training process.
q
Proof. It is obvious that ω⋆ is increasing by just the dynamics in Table 3: ∂ ω⋆ = (1 ± ξ (t)) ·
√ i t i i
d −1 λ µ⋆ω⋆ > 0. It is also direct that µ(h) is nonincreasing for any h ∈ [H] by the dynamics in
e i i i j
Table 3 for the nominal task j ∈ I . For Condition (A4), Condition (A5) and Condition (A6), we
c
aim to show that the dynamics for 0 < τ < t already implies some marginal gap in these conditions
for time t.
For Condition (A4), we have for 0 < τ < t that
∂ t(logω i⋆−logω i(h) )(cid:12) (cid:12)
τ
= (cid:16) 1±ξp i(τ)(cid:17) ·λ i(cid:16) µ⋆
i
−µ( ih)(cid:17) (cid:12) (cid:12)
τ
> (cid:16) 1±ξp (0)(cid:17) ·λ ϵc−1µ⋆(τ) > 0, // by Condition (A1)
i i i
we directly conclude that ω⋆(t) > ω(h) (t) holds for all h ̸= h∗ by integrating the above inequality
i i i
from 0 to t and noting that ω⋆(0) = ω(h) (0) = ω . This also verifies the claim that ω⋆/ω(h) is
i i 0 i i
increasing for any h ̸= h∗.
i
For Condition (A5), recall that we have for ∂ ρ⋆ that
t i
∂ ρ⋆ = L−1λ d µ⋆·(cid:16) −(1±ζr )·ϕ ρ +(1±ξr ±4ς )(cid:17)
t i i i i i i i
≥ L−1λ d µ⋆·(cid:16) −(1±ζr )·ϕ Hρ⋆+(1±ξr ±4ς )(cid:17) // Condition (A1)
i i i i i i
≥ (1+ζr )−1L−1λ d µ⋆·(cid:16) −ϕ Hρ⋆+(cid:0) 1−(ξr +4ς +2ζr )(cid:1)(cid:17) .
i i i i i i
(cid:124) (cid:123)(cid:122) (cid:125)
≪ α
i
As long as ρ⋆ < (1 − α )ϕ−1H−1, we have ∂ ρ⋆ ≥ 0, which can also be translated as whenever
i i i t i
µ⋆/ω⋆ < (1−α )ϕ−1H−1L, we will have the ratio µ⋆/ω⋆ increasing. Note that at initialization, we
i i i i i i
have µ⋆(0)/ω⋆(0) = µ⋆(0)ω−1 ≤ L/(2Hϕ ) < (1−α )ϕ−1H−1L by Assumption D.1. Hence, the
i i i 0 i i i
ratio µ⋆/ω⋆ will keep increasing until it reaches (1−α )ϕ−1H−1L, and then remains above this
i i i i
threshold. Hence, we have for any t ∈ (0,Ti ] that
warmup
µ⋆(t) (cid:26) µ⋆(t) (cid:27)
i ≥ min i ,(1−α )ϕ−1H−1L
ω⋆(t) ω⋆(t) i i
i i
(cid:40)µ⋆ i(t) before µ⋆ i(t) reaches (1−α )ϕ−1H−1L,
= ω i⋆(t) ω i⋆(t) i i
(1−α )ϕ−1H−1L otherwise.
i i
µ⋆(t) µ⋆(0)
In both case, we have i > i holding strictly, which verifies Condition (A5).
ω⋆(t) ω⋆(0)
i i
Next, for Condition (A6), we upper bound the gradient for ρ as
i
∂ ρ ≤ L−1λ d µ⋆·(cid:16) −(1±ζr )·ϕ ρ +(1±ξr )(cid:17)
t i i i i i i
≤ (1+ζr )L−1λ d µ⋆·(cid:16) −ϕ ρ +(1+ξr +2ζr )(cid:17) .
i i i i i
79r r
Thus, we conclude that if we initialize with ρ ϕ < 1, ρ ϕ will not exceed 1+ξ +2ζ during the
i i i i
warm-up stage. As a result, we will always have µ⋆ ≤ ρ Lω⋆ ≤ (1+ξr +2ζr )Lω⋆ϕ−1 < 2Lω⋆ϕ−1 for
i i i i i i i
t ∈ (0,Ti ], which directly justifies that Condition (A6) holds with some marginal gap.
warmup
Lastly,forshowingthatCondition(A1)andCondition(A2)attimetimpliesCondition(A3)and
r r
Condition(A2)foranyτ ∈ (0,t], wejustinvokethepreviousboundµ⋆/ω⋆ ≤ (1+ξ+2ζ)L < 1.25L.
i i
Thus, if ω⋆(t) < 4ω strictly holds under Condition (A2), we have that
i 0
µ⋆(τ) < 1.25Lω⋆(τ) ≤ 1.25Lω⋆(t) ≤ 5Lω , ∀τ ∈ (0,t].
i i i 0
Here the second inequality holds by the monotonicity of ω⋆. As a result, we conclude that
i
µ(h) (τ) ≤ µ⋆(τ) < 5Lω , ω(h) (τ) ≤ ω⋆(τ) < ω⋆(t) < 4ω , ∀τ ∈ (0,t],h ∈ [H],
i i 0 i i i 0
whereforthenon-optimalheads,wejustinvokeCondition(A1)tohaveµ(h) ≤ µ⋆ andtheincreasing
i i
in
ω⋆/ω(h)
that
ω⋆/ω(h)
| ≥
ω⋆/ω(h)
| = 1.
i i i i τ i i 0
ThemessageofLemmaD.5isthatwecanjustfocusonverifyingCondition(A1)andCondition
(A2) at one time stamp t as the critical conditions for the warm-up stage to hold for any τ ∈ (0,t].
Inotherwords, ifalltheconditionsinDefinitionD.2aresatisfiedfortimeτ ∈ (0,t), andthecritical
conditions Condition (A1) and Condition (A2) are still satisfied with some marginal gap at time
t, then all the conditions in Definition D.2 are also satisfied at time t with some marginal gap,
which implies that for a sufficiently small time interval ∆t, we are still in the warm-up stage during
[t,t+∆t). Next, we study each of the 5 steps in Definition D.4 for an effective task i ∈ I.
D.1.1 Step 1: Growth of ρ
i
In the first step of the warm-up stage, we show that ρ ϕ increases to 1−α .
i i i
Dynamics enter Step 1 at the beginning of the Warm-up Stage. We first show that the
warm-up stage starts with Step 1, i.e., at initialization, all the conditions in Definition D.2 for task
i are satisfied. We have by Assumption D.1 that (µ⋆−µ(h) )/µ⋆ ≥ ϵ > ϵ/c for all h ̸= h∗, which
i i i i
implies that Condition (A1) holds. Condition (A3), Condition (A6) and Cond of Step 1 also hold
by condition µ(h) (0) ≤ µ⋆(0) ≤ Lω /(2Hϕ ) in Assumption D.1. The remaining conditions are
i i 0 i
(h)
automatically satisfied by the initialization of ω = ω .
i 0
Upper Bounding the Duration of Step 1. Let ti denote the time when the dynamics for task
1
i exits Step 1. Using the dynamics for µ⋆ and ω⋆ in Table 3, we have for t ∈ (0,ti) that
i i 1
λ d
µ⋆·(cid:18)
ω⋆(1±ξr )−(1±ζr )·(cid:80)H
ϕ
µ(
ih′)(cid:19)
∂ µ⋆ i i i i h′=1 i L
∂ tt ω ii ⋆ = √ d e−1 λ iµ⋆ iω i⋆·(cid:16) 1±ξq i(0)(cid:17)
√ (cid:16) r r (cid:17) √
d d · (1±ξ)−(1±ζ)·ϕ ρ r r
i e i i d d ·(α −ξ−ζ)
i e i
= ≥ , (D.8)
1±ξq (0) 2
i
80where in the last inequality we use the fact that ρ ϕ ≤ 1−α by Cond of Step 1 and the small
i i i
q
error condition ξ (0) ≪ 1. Thus, we have for ti that
i 1
√
r r H
(ω⋆(ti)−ω )· d i d e·(α i−ξ−ζ) ≤ µ⋆(ti)−µ⋆(0) ≤ (cid:88) µ(h′) (ti) ≤ Lϕ−1ω⋆,
i 1 0 2 i 1 i i 1 i i
h′=1
where the last inequality holds by using Cond of Step 1. Defining αr = α −ξr −ζr and rearranging
i i
the above inequality, we have
(cid:32)
2L
(cid:33)−1
(cid:18)
2ς
(cid:19)−1
ω i⋆(ti 1) ≤ ω 0· 1−
d
i√
d eϕ i(α
i−ξr −ζr
)
= ω 0· 1−
αr
ii = (1+o(1))ω 0. (D.9)
r r
For this upper bound to make sense, we require that α ≫ ξ +ζ +2ς . Consequently, we have for
i i
µ⋆(ti) that
i 1
µ⋆(ti) ≤
(cid:88)H
µ(h′) (ti) ≤ Lρ (ti)ω⋆(ti) ≤ Lϕ−1ω
·(cid:18)
1− 2ς
i(cid:19)−1
. (D.10)
i 1 i 1 i 1 i 1 i 0 αr
i
h′=1
We can then upper bound the duration of Step 1 by studying the dynamics for ω⋆ as
i
∂ logµ⋆ = λ d ω⋆·(cid:16) −(1±ζr )·ϕ ρ +(1±ξr )(cid:17) ≥ λ d ω αr ,
t i i i i i i i i 0 i
where in the last inequality, we use the fact that ∂ ω⋆ > 0 to establish the monotonicity of ω⋆
t i i
r r
and lower bound ω⋆ by its initialization value ω . Moreover, the α−ξ −ζ term comes from the
i 0
same argument as in (D.8). As a result, we have for t ∈ (0,ti] that µ⋆(t)/µ⋆(0) ≥ exp(λ d ω αr t).
1 i i i i 0 i
Combining this lower bound with the upper bound in (D.10), we have for t ∈ (0,ti] that
1
exp(cid:0) λ d ω αr ti(cid:1) ≤ µ⋆ i(ti 1) ≤ Lϕ− i 1ω 0 ·(cid:18) 1− 2ς i(cid:19)−1 ,
i i 0 i 1 µ⋆(0) µ⋆(0) αr
i i i
which implies the upper bound for ti as
1
(cid:32) (cid:33)
1 Lϕ−1ω
ti ≤ ·log i 0
1 λ id iω 0αr i µ⋆ i(0)(cid:0) 1−2ς iαr i−1(cid:1)
(cid:18) (cid:19)
1 2Lω
≤ ·log 0 =∆ ti .
λ d ω αr ϕ µ⋆(0) 1+
i i 0 i i i
Only Cond of Step 1 is violated at ti. Here, we aim to show that for a sufficiently small
1
time beyond ti, only Cond of Step 1 is violated. To do so, it suffices to show that the remaining
1
conditions in Definition D.2 are satisfied for t ∈ (0,ti] and also has some marginal at time ti such
1 1
that they will not be violated even if we go beyond ti for a sufficiently small amount of time. In
1
particular,whenappealingtoLemmaD.5,weonlyneedtoshowthatCondition(A1)andCondition
(A2) are satisfied for t ∈ (0,ti] and also have some marginal gap at ti.
1 1
Using the upper bound for ω⋆ (D.9) and the fact that ω⋆ monotonically increases, we have
i i
Condition (A2) satisfied with sufficient marginal gap for t ∈ (0,ti]. The last thing to verify is
1
Condition (A1). As we do not have the property that this ratio is monotonically increasing, we
need to invoke the upper bound on the duration of Step 1 to show that this ratio must not decrease
too much. The following proposition rigorously shows this fact.
81Lemma D.6 (Lower Bounding the Separation for Condition (A1)). Let
ϵ
T =∆ .
U thres r r
18e(ξ+ζ)λ d ω
i i 0
For any t ∈ [0,T ∧Ti ], we have for the TIF-i dynamics that
U thres warmup
µ⋆(t)−µ(h)
(t)
(cid:18)
t
(cid:19)
i i ≥ ϵ· 1− .
µ⋆(t) T
i U thres
In particular, if t ≪ (1−c−1)T , we have Condition (A1) strictly satisfied.
U thres
Proof. To provide a lower bound for the separation (µ⋆ −µ(h) )/µ⋆, we first derive a lower bound
i i i
for ∂ logµ⋆−∂ logµ(h) at any τ ∈ (0,t) as
t i t i
∂ (cid:32) log µ⋆ i (cid:33)(cid:12) (cid:12) (cid:12) = λ d (cid:32) ω⋆−ω(h) ±ξr(cid:16) ω⋆+ω(h)(cid:17) ±2ζr ϕ (cid:88)H µ( ih′)(cid:33)(cid:12) (cid:12) (cid:12)
t (h) (cid:12) i i i i i i i L (cid:12)
µ (cid:12) (cid:12)
i τ h′′=1 τ
≥
−ξr
λ d
(cid:16) ω⋆+ω(h)(cid:17) −2ζr
λ d ϕ ρ
ω⋆(cid:12)
(cid:12)
i i i i i i i i i(cid:12)
τ
(cid:12)
≥ −2(ξr +ζr )λ d ·ω⋆(1+ϕ ρ )(cid:12) ,
i i i i i (cid:12)
τ
where the first and the second inequality hold by Condition (A4) that ω⋆ ≥ ω(h) . Using the upper
i i
r r
bound ϕ ρ ≤ 1+ξ +2ζ < 1.25 from Lemma D.5 together with the upper bound ω⋆ ≤ 4ω by
i i i 0
Condition (A2), we conclude that
(cid:32) (cid:33)(cid:12)
µ⋆ (cid:12)
r r
∂ log i (cid:12) ≥ −18(ξ+ζ)λ d ω ,
t (h) (cid:12) i i 0
µ (cid:12)
i τ
Thus, for all t ∈ (0,T ∧Ti ], we integrate the above inequality from 0 to t to obtain
U thres warmup
(cid:32) (cid:33) (cid:32) (cid:33)
µ⋆(t) µ⋆(0)
r r
log i −log i ≥ −18(ξ+ζ)λ d ω ·t ≥ −1,
i i 0
(h) (h)
µ (t) µ (0)
i i
where the last inequality holds by definition of T . Given the initial condition µ(h) (0)/µ⋆(0) ≤
U thres i i
(1−ϵ), we have for t ∈ (0,T ∧Ti ] that
U thres warmup
(h) (h)
µ (t) µ (0) (cid:16) r r (cid:17)
i ≤ i ·exp 18(ξ+ζ)λ d ω ·t
µ⋆(t) µ⋆(0) i i 0
i i
(cid:16) r r (cid:17)
≤ (1−ϵ)· 1+18e(ξ+ζ)λ d ω ·t
i i 0
≤
1−ϵ·(cid:16) 1−18e(ξr +ζr
)λ d ω
·tϵ−1(cid:17)
,
i i 0
which implies the result
µ⋆ i(t)−µ( ih) (t)
≥
ϵ·(cid:16) 1−18e(ξr +ζr
)λ d ω
·tϵ−1(cid:17)
=
ϵ·(cid:18)
1−
t (cid:19)
.
µ⋆(t) i i 0 T
i U thres
as we claimed in Lemma D.6.
82Note that ti ≤ Ti and the upper bound ti satisfies
1 warmup 1+
1 (cid:18) 2Lω (cid:19) ϵ(1−c−1)
ti = ·log 0 ≪ = (1−c−1)T .
1+ λ id iω 0αr i ϕ iµ⋆ i(0) 18e(ξr +ζr )λ id iω 0 U thres
r r (cid:16) (cid:17)
given that α ≫ 18e(ξ+ζ) ·log 2CLω0 . Hence, we conclude from Lemma D.6 that for t ∈ (0,ti],
i (1−c−1)ϵ ϕiµ⋆ i(0) 1
Condition (A1) holds with sufficient margin gap. The following table summarizes the dynamics for
µ⋆ and ω⋆ in Step 1 of the warm-up stage.
i i
Properties Typical Values
(cid:16) (cid:17)
Duration ti ≤ ti = 1 ·log 2Lω0
1 1+ λidiω0αr i ϕiµ⋆ i(0)
(cid:16) (cid:17)−1
µ⋆ ↗ µ⋆(0) ≤ µ⋆(t) ≤ Lϕ−1ω · 1− 2ςi
i i i i 0 αr
i
(cid:16) (cid:17)−1
ω⋆ ↗ ω ≤ ω⋆(t) ≤ ω · 1− 2ςi
i 0 i 0 αr
i
(cid:16) r r (cid:16) (cid:17)(cid:17)
(µ⋆−µ(h) )/µ⋆ lower bounded by ϵ· 1− 4e(ξ+ζ) ·log 2CLω0
i i i ϵαr i ϕiµ⋆ i(0)
Table 4: Summary of Step 1 of the Warm-up Stage
Analysis of ρ⋆ and ρ after Step 1. Before we dive into the analysis of Step 2, we first
i i
r r
understand two key features of the dynamics: (i) ρ⋆ϕ ≥ (1 − α )/H; (ii) ρ ϕ ≤ 1 + ξ + 2ζ.
i i i i i
These properties will preserve in the following steps and will be frequently used for our analysis
throughout the warm-up stage. Recall that we have for ∂ ρ⋆ that
t i
∂ ρ⋆ ≥ (1+ζr )−1L−1λ d µ⋆·(cid:16) −ϕ Hρ⋆+(cid:0) 1−(ξr +4ς +2ζr )(cid:1)(cid:17) , (D.11)
t i i i i i i i
(cid:124) (cid:123)(cid:122) (cid:125)
≪ α
i
as we have shown in the proof of Lemma D.5. At time ti, we already have ρ⋆(ti)ϕ ≤ (1−α )/H,
1 i 1 i i
r r
and we have ρ⋆ still growing for a while after ti by (D.11) since ξ+4ς +2ζ ≪ α . That is, as long
i 1 i i
r r
as ρ⋆ϕ lies between (1−α )/H and (1−ξ −4ς −2ζ)/H, we will have ∂ ρ⋆ > 0. Therefore, the
i i i i t i
first condition ρ⋆ϕ ≥ (1−α )/H is preserved in the following steps for t ∈ [ti,Ti ]. A direct
i i i 1 warmup
conclusion from this property is that
ξq i(t)| t≥ti 1 = ξr + ⟨d,λ λ⊙ i ϕ⟩ ·50HLω 02· ω µi ⋆ i⋆ (cid:12) (cid:12) (cid:12) (cid:12) t≥ti
1
= ξr + ⟨d,λ⊙ϕ⟩ ·50HLω2ϕ ·L−1(ρ⋆(t)| )−1ϕ−1
λ i 0 i i t≥ti 1 i
≤ ξr + ⟨d,λ⊙ϕ⟩ ·50H2ω2ϕ (1−α )−1
λ 0 i i
i
≤ ξr + ⟨d,λ⊙ϕ⟩ ·100H2ω2ϕ =∆ ξq′. (D.12)
λ 0 i i
i
And also we have new upper bound
ξp (t) ≤ 2cξq (t)ϵ−1 ≤ 2cϵ−1ξq′=∆ ξp′. (D.13)
i i i i
q p
for t ∈ [ti,Ti ]. Using these ξ′ and ξ′, we have the following upper bound for ω⋆.
1 warmup i i i
83Lemma D.7. For any (t ,t) ∈ [ti,Ti ]2 such that t < t, we have the following upper bounds
0 1 warmup 0
for ω⋆ in the TIF-i dynamics as
i
q r r
1 (1+ξ′ +ξ+2ζ)Lλ
ω⋆(t) ≤ , where σi =∆ i√ i .
i ω⋆(t )−1−σi(t−t ) 3 d ϕ
i 0 3 0 e i
Moreover, we have ρ⋆ϕ ≥ (1−α )/H for any t ∈ [ti,Ti ], which implies a lower bound for ω⋆
i i i 1 warmup i
as
q
1 (1−α −ξ′)·Lλ
ω⋆(t) ≥ , where σi =∆ i √i i .
i ω⋆(t )−1−σi(t−t ) 2 Hϕ d
i 0 2 0 i e
Proof. we write down the dynamics for ω⋆ as
i
∂ ω⋆ =
(1±ξq′)·(cid:112)
d
−1
λ µ⋆ω⋆ // (D.12)
t i i e i i i
≤
(1+ξq′)·(cid:112)
d
−1
λ Lρ (ω⋆)2 // µ⋆ ≤ Lρ ω⋆ by definition
i e i i i i i i
q r r
(1+ξ′ +ξ+2ζ)Lλ
≤ i√ i ·(ω⋆)2. // Lemma D.5
i
d ϕ
e i
(cid:124) (cid:123)(cid:122) (cid:125)
σi
3
Since ω⋆ is monotonically increasing, we have that
i
1
ω⋆(t +∆t) ≤
i 0 ω⋆(t )−1−σi∆t
i 0 3
as we claimed. The second condition ρ⋆ϕ ≥ (1−α )/H is just a direct conclusion of (D.11) and
i i i
using the fact that ρ⋆ϕ already reaches (1−α )/H at ti. For the lower bound, using the gradient
i i i 1
of ω⋆, we have
i
∂ ω⋆ = (1±ξq′)·(cid:112) d −1 λ µ⋆ω⋆ // (D.12) for ξq (t)
t i i e i i i i
=
(1±ξq′)·L(cid:112)
d
−1
λ ρ⋆(ω⋆)2
i e i i i
q
(1−α −ξ′)·Lλ
≥ i √i i ·(ω⋆)2, // lower bound for ρ⋆
Hϕ d i i
i e
(cid:124) (cid:123)(cid:122) (cid:125)
=∆ σi
2
which implies that
1
ω⋆(t +∆t) ≥ .
i 0 ω⋆(t )−1−σi∆t
i 0 2
We complete the proof.
D.1.2 Step 2: Growth of
ω⋆/ω(h)
i i
In Step 2 of the warm-up stage, we aim to show the Growth of marginal difference (ω⋆−ω(h) )/ω⋆
i i i
for all h ̸= h∗.
i
84Dynamics Either Enter or Skip Step 2 at ti. Using the inequality
1
ρ⋆(ti)ϕ ≤ H−1·ρ (ti)ϕ ≤ (1−α )/H,
i 1 i i 1 i i
where the first inequality holds since Condition (A1) holds at t = ti and the second inequality
1
holds by Cond of Step 1, we have (a) satisfied. If there exists at least one h ∈ [H]\{h∗} such that
i
(ω⋆ −ω(h) )/ω⋆| < (3ζr +2ξr )β−1, the dynamics will enter Step 2 at ti. Otherwise, the dynamics
i i i ti i 1
1
skip Step 2 and we have ti = ti. Next, we consider the case where the dynamics enter Step 2 at ti.
2 1 1
Upper Bounding the Duration of Step 2. We study the following quantity for h ̸= h∗:
i
∂ t(logω i⋆−logω i(h) )
=
(1±ξp i(t))·√ d e− √1 λ i(cid:16) µ⋆ i −µ( ih)(cid:17)
∂ tlogω i⋆ (1±ξq i(t))· d e−1 λ iµ⋆
i
(1±ξp (t))·(cid:16) µ⋆−µ(h)(cid:17)
=
i i i
≥
(1−ξp′ −ξq′)c−1ϵ,
(D.14)
q i i
(1±ξ (t))·µ⋆
i i
p q
where the last inequality holds by Condition (A1) and (D.12) for both ξ (t) and ξ (t). Note that for
i i
any t ∈ [ti,ti], there always exists a h ∈ [H]\{h∗} such that (ω⋆ −ω(h) )/ω⋆| < (3ζr +2ξr )β−1 by
1 2 i i i i t i
(b), which implies that ω⋆/ω(h) | ≤ (1−(3ζr +2ξr )β−1)−1. Consequently, we have by the gradient
i i t i
ratio argument in (D.14) that for this pair of (t,h),
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:18) ω⋆(t) (cid:19) log ωω (i h⋆ )( (t)
t)
−log ωω (i h⋆ )( (ti 1 ti)
)
−log(cid:16) 1−(3ζr +2ξr )β i−1(cid:17)
log i ≤ i i 1 ≤
ω⋆(ti) (1−ξp ′ −ξq ′)c−1ϵ (1−ξp ′ −ξq ′)c−1ϵ
i 1 i i i i
(cid:32) (3ζr +2ξr )β−1 (cid:33) (cid:32) 2c(3ζr +2ξr )(cid:33)
≤ −log 1− i ≤ −log 1− , (D.15)
(1−ξp ′ −ξq ′)c−1ϵ β iϵ
i i
where the second inequality comes from the fact that ω⋆ ≥ ω(h) for all h ̸= h∗ by Condition (A4),
i i i
with which we drop the second term in the numerator. Here, the third inequality holds by noting
that klog(1−x) ≥ log(1−kx) for k > 1 and 0 < kx < 1. We can also lower bound the gradient of
ω⋆ as
i
∂ logω⋆ = (1±ξq (t))·(cid:112) d −1 λ µ⋆
t i i e i i
≥
(1−ξq′)·(cid:112)
d
−1
λ Lρ⋆ω⋆
i e i i i
≥ (1−ξq′ −α )·H−1L(cid:112) d −1 λ ϕ−1ω ,
i i e i i 0
whereinthelastinequalityweusethefactthatρ⋆ϕ ≥ (1−α )/H byLemmaD.7andthatω⋆ ≥ ω
i i i i 0
by the monotonicity of ω⋆ according to Lemma D.5. It follows that
i
log(cid:18) ω i⋆(t) (cid:19) ≥ (1−ξq′ −α )·H−1L(cid:112) d −1 λ ϕ−1ω ·(t−ti). (D.16)
ω⋆(ti) i i e i i 0 1
i 1
85Combining the lower (D.16) and upper (D.15) bounds with t = ti, we have
2
−log(cid:16)
1−
2c(3ζr +2ξr )(cid:17) H√
d ϕ r r
√
ti −ti ≤ βiϵ e i ≤ 4c(3ζ +2ξ)·H d eϕ i =∆ ∆ti ,
2 1 (1−ξq i′ −α i)·Lλ iω 0 β iϵLλ iω 0 2+
r r q
whereinthelastinequalityweusethescaleβ ≫ cϵ−1log(2c(3ζ+2ξ)−1)andthefactthatξ′+α ≪
i i i
1.
Only (b) is violated at ti. Here, we use the same argument as in the analysis of Step 1 to
2
show that only (b) is violated at ti. Note that (a) is already justified by (D.11). To show that the
2
critical condition Condition (A2) holds for t ∈ (ti,ti] with some marginal gap, we first note that
1 2
ω⋆ is monotonically increasing. We next calculate the upper bound for ω⋆(ti). Invoking (D.15), we
i i 2
have
(cid:32) (cid:32) r r (cid:33)(cid:33)
2c(3ζ +2ξ)
ω⋆(ti) ≤ ω⋆(ti)·exp −log 1−
i 2 i 1 β ϵ
i
(cid:18)
2ς
(cid:19)−1 (cid:32) 2c(3ζr +2ξr )(cid:33)−1
i
≤ ω · 1− · 1− = (1+o(1))ω ,
0 αr β ϵ 0
i i
where the second inequality holds by the upper bound for ω⋆(ti) in (D.9) from step 1 and the fact
i 1
r r
that 2c(3ζ +2ξ)ϵ−1 ≪ β . Hence, Condition (A2) holds for t ∈ (ti,ti] with sufficient margin gap.
i 1 2
The next thing is to show that the other one Condition (A1) holds with some marginal gap. In
order to invoke Lemma D.6 again, we check the condition that
√
r r
4c(3ζ +2ξ)·H d ϕ ϵ(1−c−1)
∆ti ≤ e i ≪ = (1−c−1)T ,
2 β iϵLλ iω 0 18e(ξr +ζr )λ id iω 0 U thres
c(ζr +ξr )2H
which holds by noting that β ≫ in Definition D.4. Together with the previous verified
i (1−c−1)ϵ2ςi
condition ti ≪ (1−c−1)T , we conclude that Condition (A1) holds with sufficient margin gap
1 U thres
for t = ti. To summarize, we have the following table for the dynamics in Step 2.
2
Properties Typical Values
r r √
Duration ∆ti ≤ ∆ti = 4c(3ζ+2ξ)·H deϕi
µ⋆ ↗
µ⋆(2
ti) ≤
L2+ ϕ−1(1+β ξriϵ +Lλ 2i ζω r )0
ω⋆(ti)
i i 2 i i 2
(cid:16) (cid:17)−1 (cid:16) r r (cid:17)−1
ω⋆ ↗ ω⋆(ti) ≤ ω · 1− 2ςi · 1− 2c(3ζ+2ξ)
i i 2 0 αr i βiϵ
(µ⋆−µ(h) )/µ⋆ lower bounded by ϵ·(cid:0) 1−(ti +∆ti )/T (cid:1)
i i i 1+ 2+ U thres
Table 5: Summary of Step 2 of the Warm-up Stage
Growth of
µ⋆/µ(h)
is guaranteed after Step 2. As long as the dynamics exist Step 2, we
i i
will have for any h ∈ [H]\{h∗} that (ω⋆ −ω(h) )/ω(h) ≥ (3ζr +2ξr )β−1. Integrating with the fact
i i i i i
that
ω⋆/ω(h)
is monotonically increasing by Lemma D.5, the very same condition will always hold
i i
thereafter. We have the following fact for the growth of
µ⋆/µ(h)
.
i i
86Lemma D.8. Suppose that (ω⋆ −ω(h) )/ω(h) ≥ (3ζr +2ξr )β−1 holds for any h ∈ [H]\{h∗} at some
i i i i i
τ. Then, we have for t ∈ [τ,Ti ] that µ⋆(τ)/µ(h) (τ) is monotonically increasing for any h ∈
warmup i i
[H]\{h∗}.
i
Proof. We thus have for the gradient of
logµ⋆−logµ(h)
that
i i
∂
(logµ⋆−logµ(h)
)
t i i
(cid:32) H (h′)(cid:33)
= λ d ω⋆−ω(h) ±ξr(cid:16) ω⋆+ω(h)(cid:17) ±2ζr ϕ (cid:88) µ i
i i i i i i i L
h′=1
(cid:32) (cid:33)
= λ d
(cid:16) ω⋆−ω(h)(cid:17) 1±ξr
·
ω i⋆+ω i(h) ±2ζr
ϕ ρ ·
ω i⋆
i i i i ω⋆−ω(h) i i ω⋆−ω(h)
i i i i
(cid:16) (cid:17)
= (1±β )λ d
ω⋆−ω(h)
, (D.17)
i i i i i
ω⋆+ω(h) ω⋆ r r
where the last equality holds by using the fact that i i ≤ 2 i ≤ 2β /(3ζ +2ξ) and that
ω⋆−ω(h) ω⋆−ω(h) i
i i i i
ϕ ρ ≤ (1+ξr +2ζr ) ≤ 1.5 by Lemma D.5. It is then obvious from (D.17) that logµ⋆ −logµ(h) is
i i i i
monotonically increasing for t ∈ [τ,Ti ] given that β ≪ 1 and ω⋆ ≥ ω(h) for all h ̸= h∗ under
warmup i i i i
Condition (A4).
D.1.3 Step 3: Growth of
µ⋆/µ(h)
i i
In this step, we aim to show the Growth of marginal difference µ⋆/µ(h) to (H−1)/γ for all h ̸= h∗.
i i i i
Dynamics Either Enter or Skip Step 3 at ti. After Step 2, we have and (a) satisfied. If
2
there exists at least one h ∈ [H]\{h∗} such that µ⋆/µ(h) | < (H −1)γ−1, the dynamics will enter
i i i ti i
2
Step 3 at ti. Otherwise the dynamics skip Step 3 and we have ti = ti. Next, we consider the case
2 3 2
where the dynamics enter Step 3 at ti.
2
Upper Bounding the Duration of Step 3. Suppose the dynamics enter Step 3 at ti. In the
2
previous steps, we establish the upper bounds by controlling the maximal value of ω⋆. In this step,
i
we will establish the upper bound in a more direct way—by lower bounding the growth of
µ⋆/µ(h)
.
i i
We first derive a tighter lower bound for ω⋆ by incorporating Lemma D.7 with t replaced by
i 0
ti.
2
q
1 (1−α −ξ′)·Lλ
ω⋆(ti +∆t) ≥ , where σi =∆ i √i i .
i 2 ω⋆(ti)−1−σi∆t 2 Hϕ d
i 2 2 i e
87On the other hand, we have for the gradient of
ω⋆−ω(h)
that
i i
∂
(cid:16) ω⋆−ω(h)(cid:17)
≥
(1−ξp′)·(cid:112)
d
−1
λ
ω⋆(cid:16) µ⋆−µ(h)(cid:17)
// (D.13) for
ξp
(t)
t i i i e i i i i i
≥
(1−ξp′)·(cid:112)
d
−1
λ ω⋆·
ϵ
·µ⋆ // Condition (A1)
i e i i c i
p
(1−ξ′ −α )·Lλ ϵ
≥ i √i i · ·(ω⋆)2. // Lemma D.7
Hϕ d c i
i e
(cid:124) (cid:123)(cid:122) (cid:125)
=∆ σi
1
We plug in the lower bound for ω⋆ and conclude that ∂ (ω⋆ −ω(h) ) ≥ σi ·(cid:0) ω⋆(ti)−1−σi∆t(cid:1)−2 .
i t i i 1 i 2 2
Integrating the above inequality, we have
(ω⋆−ω(h) )(cid:12)
(cid:12) ≥
σ 1i ·ω i⋆(ti 2)·∆t +(ω⋆−ω(h) )(cid:12)
(cid:12) ≥
σ 1i ·ω i⋆(ti 2)·∆t
.
i i ti+∆t ω⋆(ti)−1−σi∆t i i ti ω⋆(ti)−1−σi∆t
2 i 2 2 2 i 2 2
where the last inequality holds by Condition (A4) that ω⋆(ti) ≥ ω(h) (ti). Moreover, we have for
i 2 i 2
the gradient of
logµ⋆−logµ(h)
following (D.17) that
i i
(cid:16) (cid:17)
∂
(logµ⋆−logµ(h)
) = (1±β )λ d
ω⋆−ω(h)
,
t i i i i i i i
Now, we plug in the lower bound for
ω⋆−ω(h)
and obtain
i i
∂ t(logµ⋆
i
−logµ( ih) )(cid:12) (cid:12)
ti+∆t
≥ (1−β i)λ id i· ωσ ⋆1i (t· iω )−i⋆( 1t −i 2) σ·∆ i∆t t.
2 i 2 2
Integrating both sides with respect to ∆t, we have
(cid:12) (cid:12) (cid:40)
µ⋆
i
(cid:12)
(cid:12) ≥
µ⋆
i
(cid:12)
(cid:12) ·exp (1−β )λ d ω⋆(cid:0) ti(cid:1)
(h)(cid:12) (h)(cid:12) i i i i 2
µ (cid:12) µ (cid:12)
i ti+∆t i ti
2 2
(cid:32) (cid:33)(cid:41)
·
−σ 1i∆t
−
σ 1i log(cid:0) 1−σiω⋆∗(cid:0) ti(cid:1) ∆t(cid:1)
σi (σi)2ω⋆(cid:0) ti(cid:1) 2 i 2
2 2 i 2
(cid:12)
≥
µ⋆
i
(cid:12)
(cid:12)
·exp(cid:16)
(1−β )λ d σi ·(cid:0) ω⋆(ti)∆t(cid:1)2
/2(cid:17)
(D.18)
(h)(cid:12) i i i 1 i 2
µ (cid:12)
i ti
2
(cid:16) (cid:17)
≥ exp (1−β )λ d σi ·(cid:0) ω⋆(ti)∆t(cid:1)2 /2 ,
i i i 1 i 2
where in the second inequality, we use the fact that log(1−x) ≥ −x−x2/2 for x ∈ [0,1/2] by
Taylor expansion and in the last inequality we use the fact that
µ⋆/µ(h)
≥ 1 by Condition (A1).
i i
For any t ∈ [ti,ti], there always exists a h ∈ [H]\{h∗} such that µ⋆/µ(h) | < (H −1)γ−1 by (b).
2 3 i i i t i
Let ∆t = t−ti. For this pair of (∆t,h), we incorporate the lower and upper bounds and obtain
2
(cid:16) (cid:17)
(H −1)γ−1 ≥ exp (1−β)λ d σi ·(cid:0) ω⋆(ti)∆t(cid:1)2 /2 .
i i i 1 i 2
We can solve for the maximal ∆t and obtain
(cid:115) (cid:115) √
2log(cid:0)
(H
−1)γ−1(cid:1) 4clog(cid:0)
(H
−1)γ−1(cid:1)
·Hϕ d
∆t ≤ i ≤ i i e =∆ ∆ti ,
(1−β )λ d σiω⋆(ti)2 Lλ2d ω2·ϵ 3+
i i i 1 i 2 i i 0
where the inequality holds by the monotonicity of ω⋆.
i
88Only (b) is violated at ti. Note that we no longer need to check Condition (A1) as we have
3
explicitlycharacterizethegrowthofµ⋆/µ(h)
in(D.18).
Thegrowthofω⋆/ω(h)
isalreadyestablished
i i i i
byLemmaD.5, whichimpliesthat(a)issatisfiedwithsomemarginalgap. Therefore, weonlyneed
to verify that Condition (A2) holds for t = ti with some marginal gap according to Lemma D.5.
3
To control the upper bound for ω⋆(ti), we invoke Lemma D.7 that for any ti ≤ t < t ≤ Ti ,
i 3 1 0 warmup
it holds that
q r r
1 (1+ξ′ +ξ+2ζ)Lλ
ω⋆(t +∆t) ≤ , where σi =∆ i√ i .
i 0 ω⋆(t )−1−σi∆t 3 d ϕ
i 0 3 e i
Here, we just take t = ti and ∆t = ti −ti ≤ ∆ti and obtain
0 2 3 2 3+
1
ω⋆(ti) ≤
i 3 (cid:114) √
ω−1·(cid:16)
1−
2ςi(cid:17) ·(cid:16)
1−
2c(3ζr +2ξr )(cid:17)
−
(1+ξq i′ √+ξr +2ζr )Lλi 4clog((H−1)γ i−1)·Hϕi de
0 αr i βiϵ deϕi Lλ2 idiω 02·ϵ
1
≤
(cid:18) (cid:113) (cid:19)
ω−1·
(cid:16)
1−
2ςi(cid:17) ·(cid:16)
1−
2c(3ζr +2ξr )(cid:17)
−
16clog((H−1)γ i−1)·Hςi
0 αr i βiϵ ϵ
1
≤ = (1+o(1))ω ,
(cid:18) (cid:113) (cid:19) 0
ω−1·(cid:16)
1−
2ςi(cid:17) ·(cid:16)
1−
2c(3ζr +2ξr )(cid:17)
· 1−
32clog((H−1)γ i−1)·Hςi
0 αr i βiϵ ϵ
(cid:16) (cid:17)
wherethelastinequalityholdsbytheconditionthatγ ≫ (H−1)−1exp − ϵ inDefinitionD.4.
i 32cHςi
Hence, we verify Condition (A2) as well. The following table summarizes the dynamics in Step 3.
Properties Typical Values
(cid:114) √
Duration ∆ti ≤ ∆ti = 4clog((H−1)γ i−1)·Hϕi de
3 3+ Lλ2 idiω 02·ϵ
µ⋆ µ⋆(ti) ≤
Lϕ−1(1+ξr +2ζr
)ω⋆(ti)
i i 3 i i 3
(cid:16) (cid:17)−1 (cid:16) r r (cid:17)−1
ω⋆ ↗ ω⋆(ti) ≤ ω · 1− 2ςi · 1− 2c(3ζ+2ξ) ·
i i 3 0 αr i βiϵ
(cid:18) (cid:113) (cid:19)−1
1−
32clog((H−1)γ i−1)·Hςi
ϵ
(µ⋆−µ(h) )/µ⋆ ↗ (1−γ /(H −1))
i i i i
Table 6: Summary of Step 3 of the Warm-up Stage
D.1.4 Step 4: Growth of ρ⋆
i
The moment the dynamics exist Step 3, we have (a) satisfied. Suppose that at ti, we already have
3
ρ⋆ ≥ (1−α )/ϕ . Then, we just set ti = ti and skip Step 4. Next, we consider the case where the
i i i 4 3
dynamics enter Step 4 at ti.
3
Upper Bounding the Duration of Step 4. Using (a), we have for t > ti that ρ⋆ < ρ ≤
3 i i
(1+γ )ρ⋆. Therefore, we have for the gradient of ρ⋆ that
i i i
∂ ρ⋆ = L−1λ d µ⋆·(cid:16) −(1±ζr ±2γ )ϕ ρ⋆+(1±ξr ±4ς )(cid:17) .
t i i i i i i i i
89We plug in the upper bound ρ⋆ ≤ (1−α )ϕ−1 in (b) and obtain
i i i
∂ ρ⋆ ≥ L−1λ d µ⋆·(cid:16) −(1±ζr ±2γ )(1−α )+(1±ξr ±4ς )(cid:17)
t i i i i i i i
≥ L−1λ d µ⋆·(α −ξr −4ς −2γ −ζr ).
i i i i i i
By looking at the ratio between ∂ ρ⋆ and ∂ logω⋆, we have
t i t i
r r
∂ ρ⋆ L−1λ d µ⋆·(α −ξ−4ς −2γ −ζ)
t i ≥ i i i i √ i i
∂ tlogω i⋆ (1±ξq i′)· d e−1 λ iµ⋆
i
r r
(α −ξ−4ς −2γ −ζ) α
i i i i
≥ ≥ ,
(1+ξq i′)ς iϕ i 2ς iϕ i
where the last inequality holds by the condition that γ ≪ α . The maximal increment of ρ⋆ is
i i i
boundedbythemaximalvalue(1−α )/ϕ . Asaresult, themaximalincrementoflogω⋆ isbounded
i i i
by (1−αi)2ςi ≤ 2ςi. Hence, we have
αi αi
ω⋆(ti) (cid:18) 2ς (cid:19) 2eς
i 4 ≤ exp i ≤ 1+ i = 1+o(1), (D.19)
ω⋆(ti) α α
i 3 i i
where the last inequality holds by the condition α ≫ ς in Definition D.4. To find a lower bound
i
for ω⋆(ti), we invoke Lemma D.7 with t replaced by ti and obtain
i 4 0 3
q
1 (1−α −ξ′)·Lλ
ω⋆(ti) ≥ , where σi =∆ i √i i , ∆ti =∆ ti −ti.
i 4 ω⋆(ti)−1−σi∆ti 2 Hϕ d 4 4 3
i 3 2 4 i e
Comparing the upper and lower bounds, we have
2eH 4eH
∆ti ≤ ≤ =∆ ∆ti .
4 (1−α i−ξq i′)·d iλ iα i·ω i⋆(ti 3) d iλ iα iω 0 4+
As discussed previously in Lemma D.8, we have the ratio λ∗/λh monotonically increasing after
U U
Step 2. Thus there is no need to check Condition (A1) again. Also, we have from (D.19) that
ω⋆(ti) = (1+o(1))ω⋆(ti) < 2ω L,whichimpliesthatCondition(A2)issatisfiedwithsomemarginal
i 4 i 3 0
gap. In the following table, we summarize the dynamics in Step 4.
Properties Typical Values
Duration ∆ti ≤ ∆ti = 4eH
µ⋆
µ⋆(4
ti) ≤
L4+ ϕ−1(d 1iλ +iα ξriω +0 2ζr
)ω⋆(ti)
i i 4 i i 4
(cid:16) (cid:17)−1 (cid:16) r r (cid:17)−1
ω⋆ ↗ ω⋆(ti) ≤ ω · 1− 2ςi · 1− 2c(3ζ+2ξ) ·
i i 4 0 αr i βiϵ
(cid:18) 1−(cid:113)
32clog((H−1)γ
i−1)·Hςi(cid:19)−1
·(cid:16)
1+
2eςi(cid:17)
ϵ αi
Table 7: Summary of Step 4 of the Warm-up Stage
90D.1.5 Step 5: Lottery Winner Dominates
Afterstep4,wesummarizeallthegoodpropertieswehaveestablishedsofarforanyt ∈ [ti,Ti ]:
4 warmup
(5-1) µ⋆/µ(h) ≥ (H −1)/γ for all h ∈ [H]\{h∗}.
i i i i
(5-2) (ω⋆−ω(h) )/ω⋆ ≥ (3ζr +2ξr )β−1 for any h ∈ [H]\{h∗}.
i i i i i
r r
(5-3) 1−α ≤ ρ⋆ϕ < ρ ϕ ≤ 1+ξ+2ζ.
i i i i i
(5-4) ω⋆, ω⋆/ω(h) and µ⋆/µ(h) are monotonically increasing for any h ∈ [H]\{h∗}.
i i i i i i
In the sequel, we will appeal to these facts and refrain from checking them again.
Lower Bounding the Duration of Step 5. We first understand what’s happening in Step 5.
We have for ω⋆ that
i
∂ ω⋆ = (1±ξq′)·(cid:112) d −1 λ µ⋆ω⋆ // (D.12) for ξq (t)
t i i e i i i i
=
(1±ξq′)·L(cid:112)
d
−1
λ ρ⋆(ω⋆)2
i e i i i
= (1±ξq′ ±2α )·L(cid:112) d −1 λ ϕ−1(ω⋆)2, // Fact (5-3)
i i e i i i
r r
where in the last equality we also invoke the fact that α ≫ ζ+ξ when comparing the lower bound
with the upper bound. As a result, we have for t = ti +∆t that
4
q
1 (1±ξ′ ±2α )·Lλ
ω⋆±(t) = , where σi± =∆ i√ i i , (D.20)
i ω i⋆(ti 4)−1−σ 4i± ∆t 4 d eϕ i
where“+”and“−”correspondtotheupperandlowerbounds,respectively. Therefore,theduration
of Step 5 is given by
∆ti = ω i⋆(ti 4)−1−ω i⋆(ti 5)−1 = ω i⋆ω (0 ti 4) −1/4 = (cid:18) 3 ±o(1)(cid:19) √ d eϕ i ,
5 σ 4i± ω 0σ 4i± 4 ω 0Lλ i
where in the last inequality we use the fact that ω⋆(ti) = (1+o(1))ω .
i 4 0
Growth of
ω⋆/ω(h)
and
µ⋆/µ(h)
. On the other hand, we have for the gradient of
ω⋆−ω(h)
that
i i i i i i
∂
(cid:16) ω⋆−ω(h)(cid:17)
=
(1±ξp′)·(cid:112)
d
−1
λ
ω⋆(cid:16) µ⋆−µ(h)(cid:17)
// (D.13) for
ξp
(t)
t i i i e i i i i i
(cid:18) (cid:19)
≥ (1−ξp′)·(cid:112) d −1 λ ω⋆· 1− γ i ·µ⋆ // Fact (5-1)
i e i i H −1 i
(cid:16) 1−ξp ′ −α − γi (cid:17) ·Lλ
i i H−1 i
≥ √ ·(ω⋆)2. // Fact (5-3)
i
ϕ d
i e
(cid:124) (cid:123)(cid:122) (cid:125)
=∆ σi
5
91Integrating the above inequality, with the lower bound for ω⋆, we conclude that
i
(cid:16) (cid:17)(cid:12) (cid:90) ∆t 1 (cid:16) (cid:17)(cid:12)
ω⋆−ω(h) (cid:12) ≥ σi dτ + ω⋆−ω(h) (cid:12)
i i (cid:12)
t
5
0
(cid:16)
ω⋆(ti)−1−σi−
τ(cid:17)2 i i (cid:12)
ti 4
i 4 4
ω⋆(ti)·σi∆t
≥ i 4 5 ,
ω⋆(ti)−1−σi−
∆t
i 4 4
where the last inequality holds by noting that ω⋆(ti) ≥ ω(h) (ti). Now, similar to the analysis in
i 4 i 4
Step 3, with ti replaced by ti, σi replaced by σi, and σi replaced by σi− , we adapt (D.18) to have
2 5 1 5 2 4
that
(cid:12) (cid:12)
µ⋆
i
(cid:12)
(cid:12) ≥
µ⋆
i
(cid:12)
(cid:12)
·exp(cid:16)
(1−β)λ d σi ·(cid:0) ω⋆(ti)∆t(cid:1)2
/2(cid:17)
(h)(cid:12) (h)(cid:12) i i 5 i 4
µ (cid:12) µ (cid:12)
i t i ti
4
 
(cid:32) (cid:33)2
H −1 1 1−ω⋆(ti)/ω⋆(t)
≥
γ
i
·exp
2
·(1−β)λ id iσ 5i · i σi4
+
i 
4
(cid:32) (cid:33)
H −1 σi(1−β)λ d (1−κ (t))2
= ·exp 5 i i i .
γ i 2(σi+ )2
4
where the second inequality holds by the upper bound for ω⋆ in (D.20), and in the last inequality
i
we define κ (t)=∆ ω⋆(ti)/ω⋆(t). Not that κ (t) > 1/4+o(1) still makes the dynamics satisfying the
i i 4 i i
condition ω⋆(ti) ≤ 4ω given that ω⋆(ti) = (1+o(1))ω . By Lemma D.5 and the monotonicity
i 5 0 i 4 0
of
µ⋆/µ(h)
, we can guarantee that we are still within the warm-up stage for the TIF-i dynamics.
i i
Furthermore, by plugging in the definition of σi and ω+, we have
5 4
σ 5i
=
(cid:16) 1−ξp i′ −α i− Hγ −i 1(cid:17) ·√ d eϕ i
=
(cid:18) 1−ξp′
−4α −
γ i −2ξq′(cid:19)
·
√ d eϕ i
≥
√ d eϕ i
.
(ω 4+)2 (1+ξq i′ +2α i)2·Lλ i i i H −1 i Lλ i 2Lλ i
In conclusion, we have
(cid:12)
µ⋆ (cid:12) H −1 (cid:18) (1−β)(1−κ (t))2(cid:19) H −1 (cid:18) (1−κ (t))2(cid:19)
i (cid:12) ≥ ·exp i ≥ ·exp i . (D.21)
(h)(cid:12) γ 4ς γ 8ς
µ (cid:12) i i i i
i t
√ √
Wecanroughlyestimatethescaleofς = L/( d d ϕ ) ≈ L/L1.5 = 1/ Lgiventhatbothd = O(L)
i e i i e
and d = O(L). As a result, we have the ratio growing exponentially large, which means those non-
i
optimal head will decay exponentially fast. Similar idea also applies to the ratio
ω⋆/ω(h)
where we
i i
(h)
do not wish ω for the nonoptimal head to grow large. For our purpose, we just compare the ratio
i
between ∂ (logω⋆−logω(h) ) and ∂ (logω⋆) as
t i i t i
∂ t(logω i⋆−logω i(h) )
=
(1±ξp i′)·√ d e−1 √λ i(cid:16) µ⋆ i −µ( ih)(cid:17)
∂ t(logω i⋆) (1±ξq i(t))· d e−1 λ iµ⋆
i
p
(1±ξ′)·(1±γ /(H −1))
= i i // Fact (5-1)
q
(1±ξ (t))
i
=
1±ξp′
±2γ /(H
−1)±2ξq′.
i i i
92The message is that the growth of ω⋆/ω(h) is roughly the same as ω⋆. As a result, we conclude that
i i i
for any t ∈ [ti,ti], it holds that
4 5
(cid:32) (cid:33)
log
ω i(h) (t)
=
±(cid:16) ξp′
+2γ /(H
−1)+2ξq′(cid:17) ·log(cid:18) ω i⋆(t) (cid:19)
. (D.22)
ω i(h) (ti 4) i i i ω i⋆(ti 4)
(h)
Therefore,ω isalmost“fixed”atinitialization. Inthefollowingtable,wesummarizethedynamics
i
in Step 5.
Properties Typical Values
√
Duration ∆ti ≥ deϕi
µ⋆ µ⋆5 ≤ (14ω +0L ξrλ +i 2ζr )Lϕ−1ω⋆
i i i i
ω⋆ ω⋆(ti) = 4ω
i i 5 0
(cid:18) (cid:19)
ω⋆/ω(h) log ω i(h)(ti 5) = ±(cid:16) ξp ′ +2γ /(H −1)+2ξq ′(cid:17) ·log(cid:16) ω i⋆(ti 5)(cid:17)
i i ω i(h)(ti 4)
(cid:16)
i
(cid:17)
i i ω i⋆(ti 4)
µ⋆/µ(h) ≥ H−1 ·exp (1−κi(t))2
i i γi 8ςi
Table 8: Summary of Step 5 of the Warm-up Stage
The Last Step Takes Much Longer. We first summarize the durations for each of the five
steps in the warm-up stage in the following table. We calculate the ratio between the duration of
Step Duration
(cid:16) (cid:17)
Step 1 ti ≤ ti = 1 ·log 2Lω0
1 1+ λidiω0αr i
r r
√ϕiµ⋆ i(0)
Step 2 ∆ti ≤ ∆ti = 4c(3ζ+2ξ)·H deϕi
2 2+
(cid:114)
βiϵLλiω0
√
Step 3 ∆ti ≤ ∆ti = 4clog((H−1)γ i−1)·Hϕi de
3 3+ Lλ2 idiω 02·ϵ
Step 4 ∆ti ≤ ∆ti = 4eH
4 √4+ diλiαiω0
Step 5 ∆ti ≥ deϕi
5 4ω0Lλi
Table 9: Summary of the Durations for Each Step in the Warm-up Stage
the first four steps against the last step as
ti 8ς (cid:18) 2Lω (cid:19) ∆ti 16cH(3ζr +2ξr )
1+ ≤ i ·log 0 , 2+ ≤ ,
∆ti α ϕ µ⋆(0) ∆ti β ϵ
5− i i i 5− i
(cid:115)
∆ti 64clog(cid:0) (H −1)γ−1(cid:1) ·ς H ∆ti 16eς H
3+ ≤ i i , 4+ ≤ i .
∆ti ϵ ∆ti α
5− 5− i
By our conditions for α , β , γ , we can ensure that all these ratios are o(1). To ensure o(1), we
i i i
need
(cid:18) (cid:18) (cid:19) (cid:19) r r (cid:18) (cid:19)
2Lω 16cH(3ζ +2ξ) ϵ
0
α ≫ ς · log ∨H , β ≫ , γ ≫ H ·exp − .
i i ϕ µ⋆(0) i ϵ i 64cς H
i i i
93End of the Warm-up Stage. Let us first deal with the nominal task. Our goal is to show that
Condition (A2) and Condition (A3) for the nominal task will not be violated even for the upper
√
bound of the duration of the warm-up stage, which is given by min Ti ≤ min deϕi. By
i∈I warmup i∈I ω0Lλi
(h) (h)
the gradient of ∂ µ of a nominal task j ∈ I , we directly conclude that µ cannot increase,
t j c j
which verifies Condition (A3). For the ω(h) ’s side, we have by the gradient ∂ ω(h) ≤ ν·(ω(h) )2 that
j t j j
1
(h)
ω
i
≤ ω−1−26CLζ√
d −1 ·⟨d,λ⊙ϕ⟩·ω2·min
√
deϕi
= ω 0(1+o(1)),
0 e 0 i∈I ω0Lλi
where the last equality holds by our conditions for ω that ω ≪ max λi . Hence, we also
0 0 i∈I ϕi⟨d,λ⊙ϕ⟩ζ
have Condition (A2) satisfied for the nominal task.
Previously, we have shown that the TIF-i dynamics for i ∈ I in the warm-up stage can be
divided into five steps for individual task i. However, the real dynamics does not necessarily roll
out in this way, since if one of these tasks finishes the warm-up stage, at least one of the conditions
Condition (A1)-Condition (A6) will be violated. In particular, the violated condition will be one of
the critical conditions—Condition (A2) for a certain effective task since the other critical condition
Condition (A1) will not be violated by the monotonicity of
µ⋆/µ(h)
.
i i
We have T = min Ti = min Ti . Let i∗ be the task that finishes the warm-
warmup i∈[dy] warmup i∈I warmup
up stage first. We first argue that at T , the other TIF-j dynamics are all in Step 5 for any
warmup
j ∈ I\{i∗}.
Lemma D.9. All TIF-j dynamics are in Step 5 at T for any j ∈ I\{i∗}. In particular, we
warmup
have
maxtj /∆tj ≪ ϑ.
4+ 5−
j∈I
Proof. We just need to check that T = Ti∗ ≥ tj for any j ∈ I\{i∗}. By the fact
warmup warmup 4
that ∆tj ≪ ∆tj for any l ∈ {1,2,3,4}, it suffices to show that 4max ∆tj /∆tj ≤
l+ 5− l∈{1,2,3,4} l+ 5−
∆ti∗ /∆tj . The left hand side is bounded by
5− 5−
4∆tj (cid:40)
64eς
(cid:32) (cid:32)
2Lω
(cid:33) (cid:33) 64cH(3ζr +2ξr
)
max l+ ≤ max j · log 0 ∨H , ,
l∈{1,2,3,4} ∆tj
5−
j∈I α j ϕ jµ⋆ j(0) β jϵ
(cid:114) (cid:41)
(cid:16) (cid:17) ς H
32 clog (H −1)γ−1 · j , ,
j ϵ
while the right hand side is lower bounded by
∆ti∗ ϕ λ−1 min ϕ λ−1
5− = i∗ i∗ ≥ i∈I i i =∆ ϑ.
∆tj ϕ λ−1 max ϕ λ−1
5− j j j∈I j j
4∆tj
Hence it suffices to have ϑ ≫ max l+, which is already guaranteed by our conditions
l∈{1,2,3,4} ∆tj
5−
for α , β , γ in Definition D.4.
j j j
94Since all the TIF-j dynamics are in Step 5, we can easily conclude from (D.22) that for any
i ∈ I and h ∈ [H]\{h∗}, it holds that
i
ω(h)
(T ) =
ω(h) (ti)·exp(cid:18) ±(cid:16) ξp′
+2γ /(H
−1)+2ξq′(cid:17) ·log(cid:18) ω i⋆(t) (cid:19)(cid:19)
i warmup i 4 i i i ω⋆(ti)
i 4
(cid:18) (cid:18) (cid:19) (cid:19)
≤ ω⋆(ti)· 1+ ξp′ + 2γ i +2ξq′ ·elog4 = (1+o(1))ω ,
i 4 i H −1 i 0
where the inquality holds by the fact that ω⋆(ti) ≤ 4ω and ω⋆(ti) = (1 + o(1))ω . Therefore,
i 5 0 i 4 0
ω(h) (T ) is “fixed” at initialization as ω⋆(ti) = (1+o(1))ω . Meanwhile, we have from (D.20)
i warmup i 4 0
for ω⋆(T ) that
i warmup
1
ω⋆(T ) ≥
i warmup ω⋆(ti)−1− (1−ξq i′ √−2αi)·Lλi∆ti∗
i 4 deϕi 5−
(cid:32) (1−ξq ′ −2α )(3/4−o(1)) λ ϕ−1 (cid:33)−1
≥ ω⋆(ti)−1− i i · i i
i 4 ω 0 max k∈Iλ kϕ− k1
(cid:32) (cid:33)−1
λ ϕ−1
≥ ω⋆(ti)· 1− i i .
i 4 1.5·max λ ϕ−1
k∈I k k
Thus, we conclude that
(cid:12)
ω⋆−ω(h)(cid:12)
i i (cid:12)
ω⋆ (cid:12)
i (cid:12)
Twarmup
(cid:32) (cid:33)
≥ 1−(cid:18) 1+(cid:18) ξp′ + 2γ i +2ξq′(cid:19) ·elog4(cid:19) · 1− λ iϕ− i 1
i H −1 i 1.5·max λ ϕ−1
k∈I k k
≥ λ iϕ− i 1 −(cid:18) ξp′ + 2γ i +2ξq′(cid:19) ·elog4 ≥ λ iϕ− i 1 .
1.5·max λ ϕ−1 i H −1 i 2·max λ ϕ−1
k∈I k k k∈I k k
Under the condition that λiϕ− i 1 ≫ max{ξp ′,γ /H,ξq ′}, At the same time, we have for µ(h)
max λ ϕ−1 i i i i
k∈I k k
with h ∈ [H]\{h∗} that
i
(cid:12)
µ(h)(cid:12)
γ
(cid:18)
(1−κ (T
))2(cid:19)
i (cid:12) ≤ i ·exp − i warmup . (D.23)
µ⋆ (cid:12) H −1 8ς
i (cid:12) i
Twarmup
Given that κ (t) < 1, it suffices to upper bound κ (T ) for upper bounding the ratio. Recall
i i warmup
by definition,
ω⋆(ti) (cid:16) (cid:17)
κ (T ) = i 4 ≤ ω⋆(ti)· ω⋆(ti)−1−σi− (T −ti)
i warmup ω⋆(T ) i 4 i 4 4 warmup 4
i warmup
≤ 1−ω ·σi− (∆ti∗ −ti ),
0 4 5− 4+
where in the first inequality we invoke (D.20) and in the second inequality we invoke the lower
bound for T since T = Ti∗ ≥ ∆ti∗ and lower bound ω⋆(ti) by its initial value ω . To
warmup warmup warmup 5− i 4 0
95further lower bound ∆ti∗ −ti , we invoke Lemma D.9 that max tj /∆tj ≪ ϑ and conclude
5− 4+ j∈I 4+ 5−
that
(cid:18) ti ∆ti (cid:19) (cid:18) ti (cid:19) ∆ti∗
∆ti∗ −ti = ∆ti∗ · 1− 4+ · 5− ≥ ∆ti∗ · 1− 4+ ·ϑ−1 ≥ √5−.
5− 4+ 5− ∆ti ∆ti∗ 5− ∆ti 2
5− 5− 5−
Therefore, we have for (D.23) that
 (cid:16) (cid:17)2
µ( ih)(cid:12) (cid:12) (cid:12) ≤ γ i ·exp− ω 0·σ 4i− ∆ti 5∗ − 
µ⋆ (cid:12) H −1  16ς 
i (cid:12) i
Twarmup
≤
γ
i
·exp

−(cid:18) ω 0· (1−ξq i′ √− d2 eα ϕi i)·Lλi · 4√ ωd 0e Lϕ λi i∗ ∗(cid:19)2


H −1  16ς 
 i 
≤
γ
i
·exp(cid:32) −(cid:0) λ− i∗1ϕ i∗/(λ−
i
1ϕ i)(cid:1)2(cid:33)
≤
γ
i
·exp(cid:18)
−
ϑ2 (cid:19)
=∆ ϱ ≪ 1. (D.24)
i
H −1 256ς H −1 256ς
i i
In conclusion, as long as ς ≪ ϑ2, we have the ratio µ(h) /µ⋆ being exponentially small. In the
i i i
following table, we summarize the dynamics at T .
warmup
Properties Typical Values
Duration T = min Ti
warmup i∈[dy] warmup
µ⋆ (1−α )ϕ−1Lω⋆ ≤ µ⋆ ≤ (1+ξr +2ζr )Lϕ−1ω⋆
i i i i i i i
ω⋆ ω⋆ ≤ 4ω with ω⋆ = 4ω
i i 0 i∗ 0
(cid:18) (cid:19)
ω⋆/ω(h) log ω i(h)(Twarmup) = ±(cid:16) ξp ′ +2γ /(H −1)+2ξq ′(cid:17) ·log(cid:16) ω i⋆(Twarmup)(cid:17)
i i
(cid:12)
ω i(h)(ti 4) i i i ω i⋆(ti 4)
µ⋆ i/µ( ih) µ µi(h ⋆ i)(cid:12) (cid:12)
(cid:12)
Twarmup
≤ ϱ i ≪ 1
Table 10: Summary of the Dynamics at T
warmup
D.2 Growing Stage
We give the following definition for the growing stage of the dynamics.
Definition D.10 (Growing Stage). We say that the dynamics is in the growing stage if all the
conditions in Condition C.14 and the following conditions hold:
√
(i) µ⋆ ≥ Lϕ−1ω / 2 for all i ∈ I.
i i 0
(ii) ω⋆ > ω(h) , ω⋆/ω(h) ≥ ω⋆/ω(h)(cid:12) (cid:12) and µ⋆/µ(h) ≥ µ⋆/µ(h)(cid:12) (cid:12) for any (i,h) ∈ (I ⊗
i i i i i i Twarmup i i i i Twarmup
[H])\{(i,h∗)|i ∈ I}.
i
√
(iii) ω(h) ≤ 2ω for all (i,h) ∈ ([d ]⊗[H])\{(i,h∗)|i ∈ I}.
i 0 y i
√
(iv) (cid:0) d ∧Le−1ϕ−1(cid:1) /4 ≤ µ⋆/ω⋆ ≤ 2Lϕ−1 for all i ∈ I.
i i i i i
96(v) µ⋆ω⋆ ≤ 2 for all i ∈ I.
i i 1+diϕiL−1
Based on these conditions, we can simplify the dynamics based on (D.1) and (D.2) in the
growing stage as follows. For completeness, we copy (D.1) here:
(cid:112)
d ·∂
ω(h)
= −(1±ζ)·
(cid:88)H exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1)
·(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·ω(h′) ω(h)
(D.25)
e t i L i i
h′=1
H
(cid:88) (h′) (h) (h′) (h) (h) (h)
−(1±ξ)λ · µ µ ω ω +(1±ξ)λ ·µ ω (D.26)
i i i i i i i i
h′=1
exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1)
(±1)· ·(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ·(ω(h) )2 (D.27)
L i
H
(±η)· (cid:88)(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·(ω(h) )2. (D.28)
i
h′=1
Wenoticethatthecross-taskinterferencehappenswhendealingwith⟨ω(h),ω(h′)⟩, ⟨d⊙λ⊙ϕ,µ(h)⊙
µ(h′)⟩ and ⟨d⊙λ,ω(h)⊙µ(h)⟩. For the first term, we have
dy
⟨ω(h),ω(h′)⟩
=
(cid:88) ω(h) ω(h′)
d
i i i
i=1
( ≤a) (cid:88)dy
d
·(cid:16)
ω⋆χ(h)
+√
2ω
(cid:17) ·(cid:16)
ω⋆χ(h′)
+√
2ω
(cid:17)
i i i 0 i i 0
i=1
( =b) d i∗
h
·(ω i⋆ ∗ h)2·1(h = h′ ∈ B)+2ω 0(cid:16)(cid:113) d i∗
h′
1(h′ ∈ B)+(cid:113) d i∗ h1(h ∈ B)(cid:17) +2ω 02d
(cid:16) √ (cid:17)
≤ d i∗ ·(ω i⋆ ∗)2·1(h = h′ ∈ B)+ 4ω 0 d+2ω 02d ≤ 1+o(1). (D.29)
h h
(cid:124) (cid:123)(cid:122) (cid:125)
≪ 1
(h)
where we define χ as an indicator function for which takes value 1 if h is the unique optimal
i
head for task i ∈ I and 0 otherwise (also 0 if i ∈ I belongs to the nominal tasks), and B = {h ∈
c
[H]|∃i ∈ I s.t. h = h∗} as the set for the heads that are optimal for some tasks, 1(·) as the
i
indicator function, and i∗ as the unique task that takes head h as the optimal head if h ∈ B.
h √
Here, (a) holds by noting that each task i has a unique optimal head h∗ and ω(h) ≤ 2ω for
i i 0
all nonoptimal head h ∈ [H]\{h∗} according to (iii). (b) holds by noting that χ(h) χ(h′) = 1(h =
i i i
(cid:113) (cid:113)
h∗ i ∈ B) by the uniqueness of the optimal head and d i∗ h′ and d i∗ h comes from the upper bound
(cid:113)
ω(h) ≤ 2d−1 according to Condition C.14. The last inequality holds by invoking the upper bound
i i
for ω⋆ in Condition C.14. A naive lower bound for ⟨ω(h),ω(h′)⟩ is
i
⟨ω(h),ω(h′)⟩ ≥ d i∗ ·(ω i⋆ ∗)2·1(h = h′ ∈ B)
h h
(h) (h′)
by the nonnegativity of ω and ω .
i i
97For the second term ⟨d⊙λ⊙ϕ,µ(h)⊙µ(h′)⟩, we have
⟨d⊙λ⊙ϕ,µ(h)⊙µ(h′)⟩
=
(cid:88)
d λ ϕ
µ(h) µ(h′)
+
(cid:88) σ2dµ(h) µ(h′)
i i i i i j j
i∈I j∈Ic
( ≤a) (cid:88)
d λ ϕ
(µ⋆)2·(cid:16) χ(h)
+ϱ
(cid:17) ·(cid:16) χ(h′)
+ϱ
(cid:17)
+
(cid:88) σ2dµ(h) (0)µ(h′)
(0)
i i i i i i i i j j
i∈I j∈Ic
= E i∗(µ⋆ i∗)2·1(h = h′ ∈ B)+E i∗ϱ i∗(µ⋆ i∗)2·1(h ∈ B)
h h h h h
(cid:88)
+E i∗ h′ϱ i∗ h′(µ⋆ i∗ h′)2·1(h′ ∈ B)+ E i(µ⋆ i)2(ϱ i)2
i∈I
 2
(h)
σ2d|I | µ (0)
+E i∗ h(µ⋆ i∗ h′)2· i∈I,jm ∈Ia cx
,h∈[H] E i
c ·
1
4
(cid:16)
d
ij
∧ eL
ϕi(cid:17)
ω
0 ,
(cid:124) (cid:123)(cid:122) (cid:125)
=∆ ν ≪ 1
1
where we define E = d λ ϕ = (d λ /(d)+σ2)·d as the rescaled total energy for task i. Here, the
i i i i i i
first term in (a) holds by noting that µ(h) /µ⋆ ≤ ϱ for all nonoptimal head h ∈ [H]\{h∗} and i ∈ I
i i i i
according to (D.24) and (ii) which says that
µ⋆/µ(h)
≥ ϱ . The second term in (a) holds by noting
i i i
(cid:113) √
that µ(h) is non-increasing for all j ∈ I . Next, we invoke the upper bound µ(h) ≤ 2Lϕ−1 ≤ 2L
j c i i
in Condition C.14 to get
⟨d⊙λ⊙ϕ,µ(h)⊙µ(h′)⟩ ≤ E i∗(µ⋆ i∗)21(h = h′ ∈ B)+(4+2|I|ϱs)Es ϱsL+σ2d|I c|µs2,
h h
⟨d⊙λ⊙ϕ,µ(h)⊙µ(h′)⟩ ≤ E i∗ ·(µ⋆ i∗)2·(1(h = h′ ∈ B)+ν 1)+(4+2|I|ϱs)Es ϱsL, (D.30)
h h
wherewedefineEs = max E , ϱs= max ϱ , andµs=∆ max µ(h) (0). Anaivelowerbound
i∈I i i∈I i h∈[H],j∈Ic j
for ⟨d⊙λ⊙ϕ,µ(h)⊙µ(h′)⟩ is
⟨d⊙λ⊙ϕ,µ(h)⊙µ(h′)⟩ ≥ E i∗ ·(µ⋆ i∗)2·1(h = h′ ∈ B). (D.31)
h h
Lastly, for ⟨d⊙λ,ω(h)⊙µ(h)⟩, we have
⟨d⊙λ,ω(h)⊙µ(h)⟩ = (cid:88) d λ µ(h) ω(h)
i i i i
i∈I
≤
(cid:88)
d λ
µ⋆·(cid:16) χ(h)
+ϱ
(χ(h) )c(cid:17) ·(cid:16) λr∗ [i]χ(h) +√
2ω
(χ(h) )c(cid:17)
i i i i i i W i 0 i
i∈I
√
≤ d i∗λ i∗µ⋆ i∗ω i⋆
∗
1(h ∈ B)+2ω 0|I|Es Lϱs, (D.32)
h h h h
where we additionally define (χ(h) )c = 1−χ(h) as the complement of χ(h) . Here, the first inequality
i i i
holds for the same argument as before, and the second inequality holds by invoking the upper
bound for µ⋆ in Condition C.14.
i
Now, we are ready to simplify the dynamics in the growing stage. Consider i ∈ I as a specific
98effective task. For (D.25) with h = h∗, we have the following ratio bound:
i
(cid:80)H exp(cid:0) ⟨ω⋆,ω(h′)⟩(cid:1) L−1·(cid:10) d⊙λ⊙ϕ,λ∗ ⊙µ(h′)(cid:11) ·ω(h′) ω⋆
h′=1 U i i
(cid:0) (cid:1)
exp ⟨ω⋆,ω⋆⟩ L−1E (µ⋆)2·(ω⋆)2
i i i
(cid:88)H (cid:16) (cid:16) √ (cid:17) (cid:17)
≤ exp ⟨ω⋆,ω⋆⟩·1(h′ = h∗)+ 4ω d+2ω2d ·1(h′ ̸= h∗)−⟨ω⋆,ω⋆⟩
i 0 0 i
h′=1
·ω(h′)E i·(µ⋆ i)2·(1(h′ = h∗ i)+ν 1)+(4+2|I|ϱs)Es ϱsL
// (D.29) and (D.30)
i E (µ⋆)2ω⋆
i i i
4eH(4+2|I|ϱs)Es ϱsL
≤ 1+eHν +max = =∆ 1+ν = 1+o(1), (D.33)
1
i∈I E
(cid:0)
Lω
ϕ−1(cid:1)2 2
i 0 i
(cid:124) (cid:123)(cid:122) (cid:125)
=∆ ν
2
where the second inequality holds by also noting that ω(h′) /ω⋆ ≤ 1 for all i ∈ I and h′ ∈ [H]\{h∗}
i i i
according to (ii), and we also invoke the following lower bound on µ⋆ for all i ∈ I by (i):
i
Lω
µ⋆ ≥ (1−α )ϕ−1Lω ≥ √ 0 (D.34)
i i i 0
2ϕ
i
The message from (D.33) is that exp(cid:0) ⟨ω⋆,ω⋆⟩(cid:1) L−1E (µ⋆)2 ·(ω⋆)2 is the dominant term in (D.25)
i i i
for any i ∈ I. Again, we need to deal with the error terms (D.27) and (D.28). For (D.27), we
observe for any h ∈ B that
(±1)·exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1) L−1·(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ·(ω(h) )2
i
exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1) L−1·(cid:10) d⊙λ⊙ϕ,(µ(h))⊙2(cid:11) ·(ω(h) )2
i
√ √
( ≤a)
C ·
d i∗ hλ i∗ hµ⋆ i∗ hω i⋆ ∗ h1(h ∈ B)+ 2ω 0|I|Es 2Lϱs
(cid:32) ω i⋆
∗
2ωE 0i |∗ h I· |ϱs( Eµ s⋆ i √∗ h) L2 (cid:33)·1(h ∈ B)
= C · h +
(b)
(cid:40)µ⋆ i∗
h
(cid:18)
E i∗
h
·( eµ ϕ⋆ i∗ h) (cid:19)2
12Cω
|I|ϱsEs√ L(cid:41)
≤ max 4C d−1∨ k + 0 =∆ ν ≪ 1, (D.35)
i∈I k L E ·(cid:0) ϕ−1Lω (cid:1)2 3
k k 0
where in (a) we use the upper bound and lower bound in (D.32) and (D.31) respectively, and in
(b) we invoke the lower bound for µ⋆/ω⋆ in (iv) and also the lower bound for µ⋆ in (D.34). The
i i i
message conveyed here is that (D.27) is negligible compared to (D.25) for any i ∈ I and h ∈ B.
On the other hand, when h ∈/ B, we have following the upper bounds for the above ratio following
from (D.29) and (D.32) that
√
(±1)·
exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1)
·(cid:10) d⊙λ,ω(h)⊙µ(h)(cid:11) ·(ω(h) )2 ≤
2Ce1.1ω 0|I|Es Lϱs
·(ω(h) )2. (D.36)
L i L i
99Similarly, we have for the error term (D.28) that when h ∈ B,
(±η)·(cid:80)H (cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·(ω(h) )2
h′=1 i
exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1) L−1·(cid:10) d⊙λ⊙ϕ,(µ(h))⊙2(cid:11) ·(ω(h) )2
i
(cid:80)H (cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11)
≤
h′=1
·CLη
(cid:10) (cid:11)
d⊙λ⊙ϕ,(µ(h))⊙2
≤
E i∗
h
·(µ⋆ i∗ h)2·(1(h ∈ B)+Hν 1)+H(4+2|I|ϱs)Es ϱsL
·CLη // (D.30) & (D.31)
E i∗
h
·(µ⋆ i∗ h)2·1(h ∈ B)
(cid:18) 4H(4+2|I|ϱs)Es ϱsL(cid:19)
≤ (1+Hν )+ ·Cζ ≤ 2Cζ ≪ 1, (D.37)
1 (cid:16) (cid:17)2
E i∗
h
· ϕ− i∗ h1Lω 0
(cid:124) (cid:123)(cid:122) (cid:125)
≪ 1
where the last inequality holds by (D.34) on the lower bound for µ⋆ and by condition ζ ≥ Lη.
i∗
h
When h ∈/ B,
H
(cid:88)(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·(ω(h) )2·η
i
h′=1
≤ (cid:0) (4+2|I|ϱs)Es ϱsL+σ2dH|I |µs2(cid:1) ·Cζ ·(ω(h) )2. (D.38)
c i
Lastly, for the first term in (D.26), we have for any i ∈ I that
(cid:80)H µ(h′) µ(h) ω(h′) ω(h)
(cid:88)
µ(h′) ω(h′)
h′=1 i i i i = 1+ i i ≤ 1+Hϱs, (D.39)
µ( ih) ω i(h) µ⋆ iω i⋆
h′̸=h∗
µ⋆ iω i⋆
i
where we invoke the upper bound µ(h) /µ⋆ ≤ ϱsby (ii).
i i
(h)
Simplifying ∂ ω in the Growing Stage. We have by (D.1) that when h ∈ B and i ∈ I,
t i
(cid:112)
d ·∂
ω(h)
= −(1±ζ)·
(cid:88)H exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1)
·(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·ω(h′) ω(h)
e t i L i i
h′=1
−(1±2ξ±Hϱs)·λ µ⋆ω⋆µ(h) ω(h) +(1±ξ)·λ µ(h) ω(h) // (D.39) & i ∈ I
i i i i i i i i
exp(cid:0) ⟨ω(h),ω(h)⟩(cid:1)
(±(ν +2Cζ))· ·(cid:10) d⊙λ⊙ϕ,(µ(h))⊙2(cid:11) ·(ω(h) )2
3 L i
// (D.35) & (D.37) & h ∈ B
= −(1±(2ζ +ν +2Cζ))·
(cid:88)H exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1)
·(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11)
3
L
h′=1
·ω(h′) ω(h) +λ µ(h) ω(h) (−µ⋆ω⋆+(1±(4ξ+2Hϱs+ξ))),
i i i i i i i
where in the last equality we merge the error terms into the first term and invoke (v) on the upper
bound of µ⋆ω⋆ ≤ 2 to get the error term 4ξ+2Hϱs+ξ out in the last line. Define ξr = 4ξ+2Hϱs+ξ.
i i 1
100For the case i ∈ I with h ∈ B\{h∗}, we have a naive upper bound for this gradient
i
∂
ω(h)
≤
(cid:112)
d
−1
λ
µ(h) ω(h)(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17)
t i e i i i i i 1
≤
ϱs(cid:112)
d
−1
λ
µ⋆ω(h)(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17)
e i i i i i 1
≤
ϱs(cid:112)
d
−1
λ
(cid:113) 2Lϕ−1ω(h)(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17)
, (D.40)
e i i i i i 1
where the second inequality holds by invoking the upper bound µ(h) /µ⋆ ≤ ϱs by (ii) and the last
i i
inequality holds by invoking Condition C.14. For ω⋆ where i ∈ I, we can further simplify the
i
dynamics as
(cid:112)
−1exp(cid:0) ⟨ω⋆,ω⋆⟩(cid:1)
∂ ω⋆ = −(1±(2ζ +ν +2Cζ +2ν ))· d E (µ⋆)2·(ω⋆)2 // (D.33)
t i 3 2 e L i i i
(cid:124) (cid:123)(cid:122) (cid:125)
r
=∆ ζ
1
+(cid:112)
d
−1
λ
µ⋆ω⋆(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17)
e i i i i i 1
=
(cid:32) 1−(cid:32)
1+(1±ζr )·
exp(cid:0) ⟨ω⋆,ω⋆⟩(cid:1)
d ϕ
(cid:33) µ⋆ω⋆±ξr(cid:33)
(cid:112) d −1 λ ω⋆µ⋆
1 L i i i i 1 e i i i
=
(cid:32) 1−(cid:32)
1+
exp(cid:0)
d i(ω
i⋆)2(cid:1)
d ϕ
(cid:33)
µ⋆ω⋆±τ
(cid:33)
(cid:112)
d
−1
λ ω⋆µ⋆, (D.41)
L i i i i 1 e i i i
where we define τ ≜ ξr +2eζr +e1.12ω2d = 4(C +1)eζ +4eν +2eν +5ξ+2Hϱs+2e1.1ω2d ≪ 1.
1 1 1 0 2 3 0
The scale of τ comes from the upper bound for ω⋆µ⋆ ≤ 2/(1+d ϕ L−1) in (v) and also the upper
1 i i i i
bound ⟨ω(h∗ i),ω(h∗ i)⟩−d i(ω i⋆)2 ≤ 2ω 02d by (iii). For ω j(h) where h ∈ B and j ∈ I c, we have
∂
logω(h)
=
−1
√±ζr
1
·
(cid:88)H exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1)
·(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·ω(h′)
< 0, (D.42)
t j d L j
e h′=1
r
since λ = 0 and we can also combine (D.27) and (D.28) into (D.25) with error ζ since h ∈ B.
j 1
(h) (h)
Therefore, these ω monotonically decrease. For h ∈ B and k ∈ [d ], we can upper bound ω as
j c y k
√
∂ logω(h) ≤ 21(k ∈ I)(cid:112) d −1 λ
(cid:113)
Lϕ−1ϱs+
2Ce1.1ω √0|I|Es Lϱs
·ω(h)
t k e k k L d i
e
+(cid:0) (4+2|I|ϱs)Es ϱsL+σ2dH|I |µs2(cid:1) ·(cid:112) d −1 Cζ ·ω(h) , (D.43)
c e i
√
wherewedefineµs=∆ max µ(h) (0). Here,thefirsttermcomesfromupperbounding d −1 λ µ(h) ω(h)
h∈[H],j∈Ic j e i i i
(h)
by the upper bound for µ in Condition C.14, the second and the third term come from the upper
i
bounds in (D.36) and (D.38) respectively.
101(h) (h)
Simplification of ∂ µ . We copy the dynamics for µ as
t i i
(h)
(cid:88)H exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1)
(h′) (h)
∂ µ = −λ d ϕ (1±ζ)· ·µ µ
t i i i i L i i
h′=1
H
(cid:88) (h′) (h) (h′) (h) (h) (h)
−λ d (1±ξ)· ω ω µ µ +λ d (1±ξ)·ω µ .
i i i i i i i i i i
h′=1
For the first term, we have for i ∈ I that
λ id iϕ
i·(cid:80)H h′=1exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1) L−1·µ( ih′) µ( ih)
≤ 1+
e1.1(cid:80)
h′̸=h∗
i
µ( ih′)
≤ 1+e1.1Hϱs= 1+o(1).
λ id iϕ i·exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1) L−1·µ⋆ iµ( ih) µ⋆ i
(h)
As a result, for logµ with i ∈ I, it holds that
i
∂
logµ(h)
= λ d
(cid:18)
−(1±(2ζ
+e1.1Hϱs))exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1)
ϕ
µ⋆+(cid:16) 1−ω⋆µ⋆±ξr(cid:17)
ω(h)(cid:19)
. (D.44)
t i i i L i i i i 1 i
In particular, for h = h∗, we have
i
∂ logµ⋆ = λ d
(cid:18)
−(1±(2ζ
+e1.1Hϱs))exp(cid:0) ⟨ω(h∗ i),ω(h∗ i)⟩(cid:1)
ϕ
µ⋆+(cid:16) 1−ω⋆µ⋆±ξr(cid:17)
ω⋆(cid:19)
t i i i L i i i i 1 i
(cid:18) exp(cid:0) d (ω⋆)2(cid:1) (cid:16) (cid:17) (cid:19)
= λ d − i i ϕ µ⋆+ 1−ω⋆µ⋆±τ ω⋆ ,
i i L i i i i 2 i
where we define τ ≜ ξr +2e1.1(2ω2d+2ζ +e1.1Hϱs) = 5ξ+2Hϱs+2e1.1(2ω2d+2ζ +e1.1Hϱs) ≪ 1
2 1 0 0
and the scale of τ comes from the upper bound µ⋆/ω⋆ ≤ 2Lϕ−1 in (iv) together with the upper
2 i i i
bound ⟨ω(h∗ i),ω(h∗ i)⟩−d i(ω i⋆)2 ≤ 2ω 02d by (iii). For j ∈ I c, we simply have
∂ logµ(h) = −σ2d(1±ζ)·
(cid:88)H exp(cid:0) ⟨ω(h),ω(h′)⟩(cid:1)
·µ(h′) ≤ −σ2d(1−ζ)L−1
(cid:88)H
µ(h′) .
t j L i j
h′=1 h′=1
Another gradient we keep track of is logµ⋆−logµ(h) with i ∈ I and h ̸= h∗, which satisfies
i i i
(cid:32) (cid:33)
∂ log µ⋆ i = λ d (cid:16) (cid:0) 1−ω⋆µ⋆(cid:1) ·(cid:0) ω⋆−ω(h)(cid:1) ±ξr(cid:0) 1+ω⋆µ⋆(cid:1) ·(cid:0) ω⋆+ω(h)(cid:1)(cid:17)
t (h) i i i i i i 1 i i i i
µ
i
(cid:16) (cid:17)
+λ id iL−1ϕ iµ⋆
i
exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1) −exp(cid:0) ⟨ω(h∗ i),ω(h∗ i)⟩(cid:1)
(cid:16) (cid:17)
±(2ζ +e1.1Hϱs)λ id iL−1ϕ iµ⋆
i
exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1) +exp(cid:0) ⟨ω(h∗ i),ω(h∗ i)⟩(cid:1) .
Here, for the second terms, we follow a similar argument as in the warm-up stage and obtain
λ d
ξr(cid:0) 1+ω⋆µ⋆(cid:1) ·(cid:0) ω⋆+ω(h)(cid:1)
≤ 2λ d
ξr ·(cid:0) ω⋆−ω(h)(cid:1)
·
ω i⋆
i i 1 i i i i i i 1 i i ω⋆−ω(h)
i i
≤ 4λ d
ξr ·(cid:0) ω⋆−ω(h)(cid:1)
·
max k∈Iλ kϕ− k1
,
i i 1 i i λ ϕ−1
i i
102where in the last inequality we invoke (ii) for the upper bound of ω(h) /ω⋆ by its corresponding
i i
value at the end of the warm-up stage. For the third term, we observe that
(cid:16) (cid:17)
λ id iL−1ϕ iµ⋆
i
exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1) −exp(cid:0) ⟨ω(h∗ i),ω(h∗ i)⟩(cid:1)
≥ λ d L−1ϕ µ⋆(cid:0) 1−exp(cid:0) d (ω⋆)2+2ω2d(cid:1)(cid:1)
i i i i i i 0
≥ −e1.1λ d L−1ϕ µ⋆(cid:0) d (ω⋆)2+2ω2d(cid:1) .
i i i i i i 0
Combining the third and the fourth term, we have
(cid:16) (cid:17)
λ id iL−1ϕ iµ⋆
i
exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1) −exp(cid:0) ⟨ω(h∗ i),ω(h∗ i)⟩(cid:1)
(cid:16) (cid:17)
±(2ζ +e1.1Hϱs)λ id iL−1ϕ iµ⋆
i
exp(cid:0) ⟨ω(h),ω(h∗ i)⟩(cid:1) +exp(cid:0) ⟨ω(h∗ i),ω(h∗ i)⟩(cid:1)
≥ −λ d L−1ϕ µ⋆(cid:0) d (ω⋆)2+2ω2d+4ζ +2e1.1Hϱs(cid:1)
i i i i i i 0
≥ −λ d L−1ϕ (cid:0) d (ω⋆)2+2ω2d+4ζ +2e1.1Hϱs(cid:1) · µ⋆ i · ω i⋆ ·(cid:16) ω⋆−ω(h)(cid:17) .
i i i i i 0 ω i⋆ ω⋆−ω(h) i i
i i
Using the upper bound µ⋆/ω⋆ ≤ 2Lϕ−1 in (v) and the upper bound for ω(h) /ω⋆ by (ii), we have
i i i i i
for logµ⋆−logµ(h) with i ∈ I and h ̸= h∗ that
i i i
(cid:32) (cid:33) (cid:32)
∂ log µ⋆ i ≥ λ d −4(cid:16) ξr +d (ω⋆)2+2ω2d+4ζ +2e1.1Hϱs(cid:17) max k∈Iλ kϕ− k1
t µ( ih) i i 1 i i 0 λ iϕ−
i
1
+1−ω⋆µ⋆)·(cid:0) ω⋆−ω(h)(cid:1)
i i i i
≥ λ d
(cid:0) 1−ω⋆µ⋆−4(cid:0)
τ +d
(ω⋆)2(cid:1) Φ−1(cid:1) ·(cid:0) ω⋆−ω(h)(cid:1)
, (D.45)
i i i i 2 i i i i i
where we define Φ = λ ϕ−1/(max λ ϕ−1).
i i i k∈I k k
D.2.1 Coupled Growth of µ⋆ and ω⋆.
i i
We aim to show that µ⋆ is roughly a function of ω⋆ during the growing stage. To this end, we
i i
define the following quantity
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)
π ≜ µ⋆· ω⋆+ i i i . (D.46)
i i i Lω⋆
i
We always have nonnegative π . In the following, we only consider π ∈ [1/2,2]. We characterize
i i
the dynamics for logπ as
i
∂
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)
∂ logπ = ∂ logµ⋆+ ω⋆+ i i i ·∂ ω⋆.
t i t i ∂ω⋆ i Lω⋆ t i
i i
For the second part in the derivative, we have
∂
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)
ω⋆+ i i i
∂ω⋆ i Lω⋆
i i
µ⋆ (cid:32) ϕ exp(cid:0) d (ω⋆)2(cid:1) (cid:18) 1 (cid:19)(cid:33)
= i · 1+ i i i − +2d
π L (ω⋆)2 i
i i
103Let us look at the scale of the following expression.
(µ⋆)2 (cid:12) (cid:12) ϕ exp(cid:0) d (ω⋆)2(cid:1) (cid:18) 1 (cid:19)(cid:12) (cid:12)
i (cid:12)1+ i i i − +2d (cid:12)
d (cid:12) L (ω⋆)2 i (cid:12)
i (cid:12) i (cid:12)
(µ⋆)2 ϕ exp(cid:0) d (ω⋆)2(cid:1) (cid:18) (µ⋆)2 (cid:19) (cid:18) L (cid:19)
≤ i + i i i i +2d (µ⋆)2 ≤ 4e1.1 +1 ,
d Ld (ω⋆)2 i i ϕ d
i i i i i
√
where we invoke the upper bound µ⋆/ω⋆ ≤ 2Lϕ−1 by (iv) and the upper bound (µ⋆)2 ≤ 2Lϕ−1
i i i i i
by Condition C.14. We can also rewrite ∂ logµ⋆ and ∂ ω⋆ in terms of π as
t i t i i
∂ logµ⋆ = λ d ω⋆(1−π ±τ ),
t i i i i i 2
∂ ω⋆ = (cid:112) d −1 λ
ω⋆µ⋆(cid:32)
1−π +
exp(cid:0)
d i(ω
i⋆)2(cid:1)
ϕ i · µ⋆ i ·(cid:0) 1−d (ω⋆)2(cid:1) ±τ
(cid:33)
. (D.47)
t i e i i i i L ω⋆ i i 1
i
Here, for ∂ ω⋆ we also have the following upper bound
t i
λ ω⋆µ⋆ (cid:16) √ (cid:17)
|∂ ω⋆| ≤ i √i i · |1−π |+ 2e1.1+τ ,
t i i 1
d
e
√
where we invoke the upper bound µ⋆/ω⋆ ≤ 2Lϕ−1 by (iv). Therefore, we have for ∂ logπ that
i i i t i
(cid:18) 1 (cid:16) √ (cid:17) (cid:18) L (cid:19)(cid:19)
∂ logπ = λ d ω⋆ 1−π ±τ ± √ · |1−π |+ 2e1.1+τ ·4e1.1 +1
t i i i i i 2 d π i 1 ϕ d
e i i i
(cid:16) (cid:112) −1 (cid:17)
= λ d ω⋆ 1−π ±(τ +120ς +120 d ) .
i i i i 2 i e
(cid:124) (cid:123)(cid:122) (cid:125)
≤ ι
i
√
Define ι =∆ max{τ + 120ς + 120 d −1 ,α + 17d ω2 + 32Lω2ϕ−1}, we automatically have from
i 2 i e i i 0 0 i
r r
1−α ≤ ρ∗ϕ ≤ 1+ξ +2ζ that at the start of the growing phase, π satisfies the following upper
i i i
bound
(cid:12) (cid:12)
(cid:12) (cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33) (cid:12)
(cid:12)
(cid:12)
|π i(T warmup)−1| = (cid:12) (cid:12) (cid:12)Lρ∗
i
· (ω i⋆)2+ i Li i −1(cid:12)
(cid:12)
(cid:12) (cid:12)
(cid:12)
(cid:12)
(cid:12) Twarmup(cid:12)
≤ (1+α )·(1+d 16ω2)−1+32Lω2ϕ−1
i i 0 0 i
≤ α +17d ω2+32Lω2ϕ−1.
i i 0 0 i
As a result, during the growing stage, we always have π ∈ [1−ι ,1+ι ] ⊂ [0.5,1.5].
i i i
104D.2.2 Duration of the Growing Stage.
(cid:18) (cid:0) (cid:1)(cid:19)
Under the definition π = µ⋆· ω⋆+
ϕiexp di(ω i⋆)2
and condition π ∈ [1−ι ,1+ι ], we have for
i i i Lω⋆ i i i
i
∂ ω⋆ following (D.47) that
t i
(cid:32) (cid:32) (cid:33)(cid:33)
L(ω⋆)2
(cid:112) −1
∂ ω⋆ = 1−d (ω⋆)2+(1−π ) i +d (ω⋆)2 π d λ
t i i i i
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1) i i i e i
i i i
(cid:32)
L(ω⋆)2
(cid:33)−1 (cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)−1
· 1+ i · 1+ i i i
ϕ exp(cid:0) d (ω⋆)2(cid:1) L(ω⋆)2
i i i i
= (cid:0) 1−d (ω⋆)2±2ι (cid:0) Ld−1ϕ−1+1(cid:1)(cid:1) ·(1±ι )(cid:112) d −1 λ
i i i i i i e i
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)
L(ω⋆)2
(cid:33)−1
· 2+ i i i + i , (D.48)
L(ω⋆)2 ϕ exp(cid:0) d (ω⋆)2(cid:1)
i i i i
where in the second equality we also invoke the upper bound (ω⋆)2 ≤ 2d−1 by Condition C.14
i i
to simplify the numerator. Define rι = 2ι (Ld−1ϕ−1 + 1) ≪ 1 and consider the regime where
i i i i
d (ω⋆)2 ≤ 1−2rι . Equivalently, we have
i i i
(cid:0) (cid:1)
2+
ϕiexp di(ω i⋆)2
+
L (cid:0)(ω i⋆)2
(cid:1)
dt
=
L(ω i⋆)2 ϕiexp √di(ω i⋆)2
. (D.49)
d(ω i⋆) (1−d i(ω i⋆)2±rι i)·(1±ι i) d e−1 λ
i
We first pick υ < 1−2rι such that 1−υ ≥ 3rι and consider the regime where d (ω⋆)2 ≤ υ. In this
i i i i
regime, we can upper bound the above expression by
d(d ωt
i⋆)
≤ (1+2rι i)· 2 (+ 1−Lϕ (ωi υe i⋆ )υ )2 √+
d
e−L( 1ω ϕ λii⋆ i)2 = (1 (+ 12 −rι i υ) )· λ√ id e · d(d
ω i⋆)
(cid:18) 2(ω i⋆)− Lϕ (i ωe iυ
⋆)
+ L( 3ω ϕi⋆ i)3(cid:19) .
Therefore, the duration of this regime ∆ti where d (ω⋆)2 is raised from the value at the end of
6+ i i
the warm-up stage to υ is upper bounded by
√
√
∆ti ≤ (1+2rι i)· d e (cid:18) 2(ω⋆)− ϕ ieυ + L(ω i⋆)3(cid:19)(cid:12) (cid:12) (cid:12) υ/di
6 (1−υ)λ i L(ω⋆) 3ϕ (cid:12)
i i i ω0
√ (cid:32) (cid:33)
(1+2rι i)· d e (cid:112) ϕ ieυ Lυ3/2
≤ 2 υd + + . (D.50)
i
(1−υ)λ Lω 3/2
i 0 3ϕ d
i i
One should notice that the second term in the above expression dominates as ω is small in the
√ 0
sense that ω ≪ (ϕ L−1 d −1 )∧(ϕ2L−2d3/2 ). For the other regime where υ ≤ d (ω⋆)2 ≤ 1−2rι ,
0 i i i i i i i
we have
dt (cid:32) (cid:40) ϕ exp(cid:0) d x2(cid:1) Lx2 (cid:41)(cid:33) √ d λ−1
d(ω⋆)
≤ 2+ √max√ i Lx2i +
ϕ exp(cid:0) d x2(cid:1)
·
(1−rι −d
(e ω⋆i
)2)(1−ι
).
i x∈{ υ/di, 1/di} i i i i i i
(cid:124) (cid:123)(cid:122) (cid:125)
=∆ Γ
i
(D.51)
105Here, a typical choice of υ is 1/2 for the definition of Γ . By integrating the above expression for
i
ω⋆ between the above mentioned range, we have
i
√ (cid:32) (cid:32)(cid:115) (cid:33) (cid:33) √
Γ d λ−1 1−2rι (cid:18)(cid:114) υ (cid:19) Γ d λ−1 1 4
∆ti ≤ i e i · tanh−1 i −tanh−1 ≤ i e i · log ,
7 (cid:112) d i(1−rι i)3 1−rι i 1−rι i (cid:112) d i(1−rι i)3 2 rι i
where the last inequality follows from upper bounding the positive term in the inverse hyperbolic
tangent function.
D.2.3 Verifying the Conditions for the Growing Stage.
√
Verification for (i). We first verify that µ⋆ ≥ Lϕ−1ω / 2 in (i) for i ∈ I during the growing
i i 0
stage. Using the fact that π ∈ [1−ι ,1+ι ], we have
i i i
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)−1
µ⋆ ≥ (ω⋆)+ i i i ·(1−ι ).
i i L(ω⋆) i
i
√
It remains to check that (ω⋆) ≥ ω . Invoking (D.48), we can easily observe that for (ω⋆) < 1/ 2d ,
i 0 i i
we have ∂ (ω⋆) > 0. Since at the end of the warm-up stage, we already have (ω⋆) ≥ ω , we can
t i i 0
conclude that (ω⋆) ≥ ω for all i ∈ I during the growing stage.
i 0
Verification for (ii). We next check the conditions in (ii). We first show that (ω⋆) ≥ ω(h) and
i i
(ω⋆)/ω(h) ≥ (ω⋆)/ω(h)(cid:12) (cid:12) hold for all i ∈ I and h ∈ B\{h∗}. Invoking (D.40) and (D.41), we
i i i i Twarmup i
have for ∂
(log(ω⋆)−logω(h)
) that
t i i
∂
(cid:32)
log
(ω
i⋆)(cid:33)
≥
(cid:32) 1−(cid:32)
1+
exp(cid:0)
d i(ω
i⋆)2(cid:1)
d ϕ
(cid:33)
µ⋆(ω⋆)±τ
(cid:33)
(cid:112)
d
−1
λ µ⋆
t (h) L i i i i 1 e i i
ω
i
−(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17)(cid:112)
d
−1
λ
µ(h)
.
i i 1 e i i
We split the discussion into two cases based on whether (ω⋆)µ⋆ < 1/(1+2e1.1d ϕ L−1) or not. If
i i i i
(cid:113)
the condition holds, we have following the upper bound (ω⋆) ≤ (1+o(1)) d−1 by Condition C.14
i i
that
(cid:32) (cid:33)
∂ log
(ω i⋆)
≥
(cid:18) e1.1d iϕ iL−1
−τ
(cid:19) (cid:112)
d
−1
λ
µ⋆−(1+ξr )(cid:112)
d
−1
λ
µ(h)
.
t (h) 1+2e1.1d ϕ L−1 1 e i i 1 e i i
ω i i
i
At this point, we invoke the ratio argument µ⋆/µ(h) ≥ µ⋆/µ(h)(cid:12) (cid:12) ≥ ϱs−1 for any i ∈ I in (ii)
i i i i Twarmup
that
(cid:32) (cid:33)
∂ log
(ω i⋆)
≥
(cid:18) e1.1d iϕ iL−1
−τ
−2ϱs(cid:19) (cid:112)
d
−1
λ µ⋆ > 0,
t (h) 1+2e1.1d ϕ L−1 1 e i i
ω i i
i
where we invoke the relationship min{e1.1d ϕ L−1,1} ≫ τ ∨ ϱs. Therefore, we have (ω⋆)/ω(h)
i i 1 i i
growing throughout the first case (Also, note that (ω⋆) is also growing under this condition).
i
106Hence, both conditions are satisfied for the first case. For the other case, since we already have
(ω⋆)µ⋆ ≥ 1/(1+2e1.1d ϕ L−1), by incorporating the relationship between (ω⋆) and µ⋆ in (D.46) we
i i i i i i
conclude that (ω⋆) ≥ (cid:112) 1/2d . Therefore, we just need to check that ω(h) is still somewhere near
i i i
the initialization. To do so, we incorporate the upper bound for the duration of the growing stage
(cid:32) √ √ (cid:33)
(1+2rι )· d ϕ eυ Γ d λ−1 1 4
∆ti +∆ti ≤ max 2 k e · k + k e k · log ,
6 7 k∈I (1−υ)λ k Lω 0 (cid:112) d k(1−rι k)3 2 rι k
where υ ∈ (0,1) is a absolute constant and rι ≪ 1 is a chosen small constant. We can now upper
i
bound the maximal value of ω(h) for i ∈ I and h ̸= h∗ during the growing stage as
i i
log ω i(h) ≤ ϱsλ (cid:113) 2Lϕ−1(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17)
(h) i i i i 1
ω (T )
i warmup
(cid:32) (cid:33)
(1+2rι ) ϕ eυ Γ λ−1 1 4
·max 2 k · k + k k · log = o(1). (D.52)
k∈I (1−υ)λ k Lω 0 (cid:112) d k(1−rι k)3 2 rι k
As we have ω ≫ ϱspoly(L) thanks to the exponential decay in ϱs, the above expression is o(1)
0
for the scale of rι that rι ≥ ς . Therefore, for the second case, we still have (ω⋆) > ω(h) and
i i i i i
(ω⋆)/ω(h) ≥ (ω⋆)/ω(h)(cid:12) (cid:12) for all i ∈ I and h ̸= h∗ during the growing stage.
i i i i Twarmup i
For the case h ∈ B , we have the upper bound for ∂ logω(h) in (D.43). Note that for (ω⋆)µ⋆ <
c t i i i
1/(1+2e1.1d ϕ L−1), we have
i i
∂ log(ω⋆) ≥
(cid:18) e1.1d iϕ iL−1
−τ
(cid:19) (cid:112)
d
−1
λ µ⋆.
t i 1+2e1.1d ϕ L−1 1 e i i
i i
For the terms in (D.43) with ϱs, the above expression automatically dominates thanks to the expo-
√
nentially small scale of ϱsand the fact that ω(h) ≤ 2ω when (iii) holds. The only term we need
√ i 0 √ √
to consider is σ2dH|I |µs2· d −1 Cζ·ω(h) ≤ σ2dH|I |µs2· d −1 Cζ· 2ω . Therefore, we have for
c e i c e 0
the time-derivative of
log((ω⋆)/ω(h)
) that
i i
√
(ω⋆) (cid:18) e1.1d ϕ L−1 (cid:19) λ µ⋆ σ2dH|I |µs2·Cζ · 2ω
∂ log i ≥ i i −τ −ϱspoly(L) √i i − c √ 0
t ω(h) 1+2e1.1d iϕ iL−1 1 d
e
d
e
i
(cid:18) d ϕ (cid:18) e1.1 2CH|I |µs2ζ(cid:19) (cid:19) λ µ⋆
≥ i i · − c −τ −ϱspoly(L) √i i .
L 1+2e1.1d ϕ L−1 SNR[i] 1 d
i i e
By our initialization condition that µs2 ≪ SNR[i] · (1 ∧ L/(d ϕ ))/(H|I |ζ), we have the above
i i c
expression being positive. On the other hand, as (ω⋆)µ⋆ ≥ 1/(1+2e1.1d ϕ L−1), we have (ω⋆) ≥
i i i i i
(cid:112) (h)
1/2d . Similar to the previous case for h ∈ B, we can upper bound the total drift of logω for
i i
h ∈ B as
c
ω(h) √
log i ≤ ( 2σ2dH|I |µs2·Cζ +ϱspoly(L)ω−1)
(h) c 0
ω (T )
i warmup
(cid:32) (cid:33)
(1+2rι ) ϕ eυ Γ λ−1ω 1 4
·max 2 k · k + k k 0 · log .
k∈I (1−υ)λ k L (cid:112) d k(1−rι k)3 2 rι k
107Note that the above terms are o(1) given the scale of ζµs2d ≪ 1 and rι ≥ ς .
i i
Next, we have the argument for
µ⋆/µ(h)
that the ratio is non-decreasing. Recall the lower
i i
bound for ∂ log(µ⋆/µ(h) ) in (D.45). Before (ω⋆) reaches 10ω , we have obviously that the gradient
t i i i 0
is non-negative for log(µ⋆/µ(h) ). On the other hand, after (ω⋆) reaches 10ω , we have following
i i i 0
from (D.44) and the definition of π that
i
∂ logµ(h) ≤ λ d
(cid:16)
−(1−(2ζ +e1.1Hϱs))ϕ
L−1µ⋆+(cid:16) 1−(ω⋆)µ⋆+ξr(cid:17) ω(h)(cid:17)
t i i i i i i i 1 i
(cid:32)
(h)
≤ λ d (ω⋆) (1−(ω⋆)µ⋆+ξr )ω i
i i i i i 1 (ω⋆)
i
(cid:33)
−(1−(2ζ +e1.1Hϱs))(π −µ⋆(ω⋆))exp(−d (ω⋆)2)
i i i i i
≤ −λ d (ω⋆)(1−(2ζ +e1.1Hϱs))exp(−d (ω⋆)2)
i i i i i
(cid:18) (cid:19)
·(1−µ⋆(ω⋆)−2ι −2ξr )· 1−e1.1(1+4ζ +e1.1Hϱs)1+o(1) .
i i i 1 10
We note that
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)−1
1−µ⋆(ω⋆) = 1−π−1 1+ i i i
i i i L(ω⋆)2
i
ϕ exp(cid:0) d (ω⋆)2(cid:1) /(L(ω⋆)2)
≥ i i i i −ι
1+ϕ exp(cid:0) d (ω⋆)2(cid:1) /(L(ω⋆)2) i
i i i i
(cid:40) 1 ϕ exp(cid:0) d (ω⋆)2(cid:1)(cid:41) (cid:26) 1 d ϕ e(cid:27)
≥ min , i i i −ι ≥ min , i i −ι .
2 2L(ω⋆)2 i 2 2L i
i
Under the condition that min{1,d ϕ /L} ≫ 3ι +2ξr , we have that ∂ logµ(h) ≤ 0. As µ⋆ is no
i i i 1 t i i
smaller than the corresponding value when (ω⋆) = 10ω , the ratio µ⋆/µ(h) is no smaller than 1/ϱs.
i 0 i i
Verification for (iii). We next check the conditions in (iii). In the previous paragraph, we
have already verified that ω(h) ≤ (1+o(1))ω for all i ∈ I and h ̸= h∗ during the growing stage.
i 0 i
It remains to characterize the condition for other j ∈ I . However, this is trivial as we have
c
(h)
∂ logω ≤ 0 for all j ∈ I due to (D.42).
t j c
Verification for (iv). We just use the fact that π ∈ [1 − ι ,1 + ι ] to conclude for the ratio
i i i
µ⋆/(ω⋆) that
i i
µ⋆ π
i = i .
(ω⋆) (ω⋆)2+ϕ exp(cid:0) d (ω⋆)2(cid:1) L−1
i i i i i
An upper bound is given by
µ⋆ 1+ι √
i ≤ i ≤ 2Lϕ−1,
(ω⋆) ϕ L−1 i
i i
108and an lower bound is given by
µ⋆ 1−ι d ∧Le−1ϕ−1
i ≥ i ≥ i i ,
(ω⋆) 2d +ϕ e1.1L−1 4
i i i
where we invoke the upper bound for (ω⋆) in Condition C.14 to simplify the denominator.
i
Verification for (v). Following the definition of π in (D.46), we have
i
π 1+ι 2
µ⋆(ω⋆) = i ≤ i ≤ ,
i i 1+ϕ exp(cid:0) d (ω⋆)2(cid:1) L−1/(ω⋆)2 1+ϕ L−1d /2 1+d ϕ L−1
i i i i i i i i
where the last inequality holds as we have Lϕ−1d−1 ≫ ι .
i i i
D.2.4 Emergence and Convergence of the Growing Stage
Recall that we rescale the time as t ← 2dt.
Convergence We first check if the dynamics converge or not after the growing stage. By (D.48),
after d ω⋆2 ≥ 1−2rι , we still have for d ω⋆2 around 1 that
i i i i i
∂ ω⋆ = (cid:0) 1−d (ω⋆)2±2ι (cid:0) Ld−1ϕ−1+1(cid:1)(cid:1) ·(1±ι )(cid:112) d −1 λ
t i i i i i i i e i
(cid:32)
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)
L(ω⋆)2
(cid:33)−1
· 2+ i i i + i .
L(ω⋆)2 ϕ exp(cid:0) d (ω⋆)2(cid:1)
i i i i
Notably, if d ω⋆2 grows larger than 1+2rι , the dynamics will “draw” the values back. Thus, we
i i i
prove that d ω⋆ will be roughly 1±2rι , which shows the convergence for ω⋆. Since π is “fixed”
i i i i i
around 1±ι , we also have µ⋆ “fixed” around
i i
1±ι 1±ι
i i
= .
1+ϕ exp(cid:0) d (ω⋆)2(cid:1) L−1/(ω⋆)2 1+d ϕ eL−1(1±rι )
i i i i i i i
For other nonoptimal head, we have following the same argument as (D.52) that
log ω i(h) (t) ≤ ϱsλ (cid:113) 2Lϕ−1(cid:16) −µ⋆ω⋆+(1±ξr )(cid:17) ·T = o(1)
(h) i i i i 1
ω (T )
i warmup
√ √
thanks to the scale ϱs = max (H −1)−1γ exp(−ϑ2/(256ς )) where ς = L/( d d ϕ ) ≈ 1/ d
√ i∈[I] i i i e i i e
as long as T ≪ exp(O( d )). This is a fairly long time given that d ≥ d. Moreover, as we have
e e
(h) (h)
discussed, for the nonoptimal head, µ dies down as ∂ logµ < 0. Thus, we have shown the
i t i
convergence.
(cid:112) (cid:112)
Convergence Rate. We integrate (D.51) for ω⋆ between υ/d and (1−δ)/d where δ ∈
i i i
(2rι ,1−υ) can be arbitrarily picked, we have the following upper bound on the required t to raise
i
(cid:112) (cid:112)
ω⋆ from υ/d to (1−δ)/d :
i i i
Γ
√
d λ−1
(cid:32) (cid:32)(cid:114) 1−δ(cid:33)
(cid:18)(cid:114) υ
(cid:19)(cid:33)
Γ
√
d λ−1 1 4
t ≤ i e i · tanh−1 −tanh−1 ≤ i e i · log ,
(cid:112) d i(1−rι i)3 1−rι i 1−rι i (cid:112) d i(1−rι i)3 2 δ
This clearly shows the convergence rate.
109Emergence. The next theorem characterizes the emergence behavior of the dynamics.
Theorem D.11 (Emergence Behavior). Define
√
ϕ d
i e
T = 2d· .
0
λ Lω
i 0
Pick an absolute constant υ ∈ (0,1/4). Then, the following holds:
• For the total time less than (1−υ−o(1))T , we must have ω⋆ ≤ υ−1ω . The loss for task i
0 i 0
is a least
(cid:18) (cid:19)
λ d
i i
Ω .
d
• For the total time larger than (1+eυ)T , we must have d (ω⋆)2 ≥ υ. The loss for task i is at
0 i i
most
(cid:18) (cid:18) (cid:19)(cid:19)
λ d 1
i i
O · 1− .
d 1+(d ω⋆2)−1exp(d ω⋆2)ϕ d L−1
i i i i i i
Proof. (Proof of Theorem D.11) In the following discussion, we also rescale the time by
t ← 2dt. At the end of the warm-up phase, we just have by (D.20) in the fifth step of the warm-up
phase that
1±o(1)
ω⋆(T ) = ≤ 4ω , (D.53)
i warmup ω−1− √Lλi (T −ti) 0
0 deϕi warmup 4
giventhatω⋆ = (1+o(1))ω aswehaveshownfortheendof the step4ofthewarm-upstage. Here,
i 0
ti is the ending time of step 4 of the warm-up stage for task i. Here, the 4ω is ensured by the
4 0
definition of the warm-up stage. Consider a fixed small constant υ ∈ (0,1/4). Consider the regime
when ω⋆ is raised from the value at the end of the warm-up stage to υ−1ω . Recall the derivative
i 0
of time with respect to ω⋆ in (D.49) that
i
(cid:0) (cid:1)
dt
=
2+ ϕiex Lp (ωd i⋆i( )ω 2i⋆)2 + ϕiexL p(cid:0)( √ω di⋆ i() ω2 i⋆)2(cid:1)
≥
2+
L
√(ωϕi
i⋆)2
+ L( ϕω ii⋆ e)2
d(ω i⋆) √(1−d i(ω i⋆)2±rι i)·(1±ι i) d e−1 λ
i
d e−1 λ
i
d d
(cid:18)
ϕ
Lω⋆3(cid:19)
= e · 2ω⋆− i + i .
λ dω⋆ i Lω⋆ 3ϕ e
i i i i
Itisclearthatthetimeusedforω⋆ toberaisedtoυ−1ω , whichwedefineas∆T , islowerbounded
i 0 1
by
√ √
∆T 1 ≥ λd e (cid:18) 2(ω i⋆)− L(ϕ ωi ⋆) + L 3( ϕω i⋆ e)3(cid:19)(cid:12) (cid:12) (cid:12) (cid:12)υ−1ω0 ≥ ϕ λi Ld e (cid:0) ω i⋆(T warmup)−1−υω 0−1(cid:1) .
i i i ω i⋆(Twarmup) i
Using the result in (D.53), we also have
(cid:18) (cid:19)
Lλ
ω⋆(T )−1 = ω−1− √ i (T −ti) ·(1±o(1)). (D.54)
i warmup 0 d ϕ warmup 4
e i
110Plugging (D.54) into the lower bound for ∆T , we conclude that
1
√
(cid:18)(cid:18) (cid:19) (cid:19)
ϕ d Lλ
∆T ≥ i e ω−1− √ i (T −ti) ·(1−o(1))−υω−1 ,
1 λ L 0 d ϕ warmup 4 0
i e i
which shows that
√
ϕ d
∆T +(1−o(1))(T −ti) ≥ i e ·(1−o(1)−υ)ω−1.
1 warmup 4 λ L 0
i
Note that ti is much smaller than T as we have discussed previously. Define
4 warmup
√
ϕ d
i e
T = .
0
λ Lω
i 0
Asaresult,weconcludethatforthetotaltimelessthanT ·(1−υ−o(1)),wemusthaveω⋆ ≤ υ−1ω .
0 i 0
For the other side T (1+υ), we have by (D.50) that the time to raise d (ω⋆)2 from the value at the
0 i i
end of the warm-up stage to υ, which we define as T , is upper bounded by
2
√ (cid:32) (cid:33)
(1+2rι i)· d e (cid:112) ϕ ieυ Lυ3/2
T ≤ 2 υd + + .
2 i
(1−υ)λ Lω 3/2
i 0 3ϕ d
i i
Note that the second term dominates as we discussed before. Thus, T is no larger than (1 +
2
o(1))eυ/(1−υ)T ≤ (1+eυ)T .
0 0
For the loss before (1 − υ − o(1))T , we have by noting that both µ and ω are small that
0 i i
the output for position i is much smaller in scale compared to (y ) . Hence, the loss is at least
q 0
(cid:16) (cid:17)
Ω λidi . Lastly, for the training loss at T , we notice that µ⋆ is around the optimal value for the
d 2 i
corresponding ω⋆ as we have
i
(cid:32)
ϕ d
exp(cid:0)
d
(ω⋆)2(cid:1)(cid:33)
π = µ⋆ω⋆· 1+ i i i i = 1±o(1),
i i L(d ω⋆2)
i i
compared to the optimality condition in (E.19) of Lemma E.7 with b replaced by d ω⋆2. Therefore,
i i i
giventhatthetaskisonlycarriedoutbyitsoptimalhead,thelossforeachtaskiswellapproximated
by
(cid:18) (cid:19)
λ d 1
i i
· 1− .
d 1+(d ω⋆2)−1exp(d ω⋆2)ϕ d L−1
i i i i i i
Plugging in the value of ω⋆, we have the desired result.
i
D.3 Dynamics Path
We give a simplified version of the dynamics path for ease of understanding what’s happening
during each phase. We remind the readers that the following is not rigorous proof. The Gradient
Flow (Gradient Flow) dynamics of ω(h) is approximated by
√
d ·∂
ω(h)
= −
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
·(cid:10) d⊙λ⊙ϕ,µ(h)⊙µ(h′)(cid:11) ·ω(h′) ω(h)
e t i L i i
h′=1
H
(cid:88) (h′) (h) (h′) (h) (h) (h)
−λ · µ µ ω ω +λ ·µ ω ,
i i i i i i i i
h′=1
111and the GF dynamics of µ(h) is approximated by
(h)
(cid:88)H exp(cid:0)(cid:10) ω(h),ω(h′)(cid:11)(cid:1)
(h′) (h)
(cid:88)H
(h) (h′) (h′) (h) (h) (h)
∂ µ = − d λ ϕ µ µ − d λ ω ω µ µ +d λ ω µ .
t i L i i i i i i i i i i i i i i i
h′=1 h′=1
(h)
Dynamics Path for the Warm-up Phase. Note that during the warmup phase ω ≈ ω .
i 0
Hence, any term of 2 or higher order in ω is ignorable. Hence, we have only the signal term for
∂ ω(h):
t
√
(h) (h) (h)
d ·∂ ω ≈ λ ·µ ω ,
e t i i i i
and the last signal term and the first interference term for ∂ µ(h), where it is more clear to write in
t
the logarithm form:
H
∂ logµ(h) ≈ d λ ω(h) − (cid:88) L−1d λ ϕ µ(h′) ·(cid:16) 1+⟨ω(h),ω(h′)⟩(cid:17) . (D.55)
t i i i i i i i i
h′=1
Mean-Field Interference Makes the Optimal Head Dominate: To understand how the
optimal head gradually dominates the other heads, we consider the time-derivative of the ratios:
(cid:32) (cid:33) (cid:32) (cid:33)
µ⋆ (cid:16) (cid:17) ω⋆
∂ log i ≈ λ d ω⋆−ω(h) , ∂ log i ≈ λ (µ⋆−µ(h) )
t (h) i i i i t (h) i i i
µ ω
i i
where we actually cancel out the interference term since the interference term is almost the same
for all heads as long as ω(h) is small enough! This is the underlying reason why the optimal head
can gradually dominates the other heads using the advantage of initialization. In particular, the
advantage in µ⋆ will be converted to the advantage in ω⋆ through the second equation and then
i i
back to the further advantage in µ⋆.
i
For more insight, note that the dynamics of µ(h) runs much faster than ω(h) in scale. Therefore,
the first step should be µ(h) trying to reaching the equilibrium given by (D.55):
H
(cid:88) (h′) (h)
ϕ µ ≈ Lω . (D.56)
i i i
h′=1
However, the left-hand side of (D.56) is independent of h but the right-hand side is not. Notably,
(cid:80) (h) (h)
ϕ µ should be larger than the smallest Lω while it should be smaller than the largest
h∈[H] i i i
(h) (h)
Lω , since otherwise we can always find all {µ } to simultaneously increase or decrease
i i h∈[H]
according to (D.55). As a result, we will have a clear separation between heads: For heads with
(h) (cid:80) (h′) (h)
Lω larger than the interference level ϕ µ , the corresponding µ will increase, and
i h′∈[H] i i i
vice versa. Only the optimal head will keep going all the time.
Dynamics Path for the Emergence and Convergence Phase (Growing Phase). As the
optimal head takes over the other heads, the dynamics of ω(h) and µ(h) can be simplified to only
112the optimal one and neglect the interference terms, which gives us
(cid:18) exp(cid:0) d (ω⋆)2(cid:1) (cid:16) (cid:17) (cid:19)
∂ logµ⋆ ≈ λ d − i i ϕ µ⋆+ 1−ω⋆µ⋆ ω⋆ ,
t i i i L i i i i i
∂ ω⋆ ≈
(cid:32) 1−(cid:32)
1+
exp(cid:0)
d i(ω
i⋆)2(cid:1)
d ϕ
(cid:33)
µ⋆ω⋆±τ
(cid:33)
(cid:112)
d
−1
λ ω⋆µ⋆.
t i L i i i i 1 e i i i
The equilibrium of µ(h) is given by
ω⋆
µ⋆ ≈ i .
i ω⋆2+ϕ exp(cid:0) d (ω⋆)2(cid:1) L−1
i i i i
Plugging this into the dynamics of ω⋆, we have
i
∂ ω⋆ ≈ (cid:0) 1−d (ω⋆)2(cid:1) ·(cid:112) d −1 λ
·(cid:32)
2+ ϕ
iexp(cid:0)
d i(ω
i⋆)2(cid:1)
+ L(ω i⋆)2
(cid:33)−1
.
t i i i e i L(ω⋆)2 ϕ exp(cid:0) d (ω⋆)2(cid:1)
i i i i
It is clear that the stationary point is given by d (ω⋆)2 = 1 and before that, ω⋆ will keep increasing.
i i i
To understand the sudden emergence, we just look at the
ϕ
exp(cid:0)
d
(ω⋆)2(cid:1)
L(ω⋆)2
2+ i i i + i
L(ω⋆)2 ϕ exp(cid:0) d (ω⋆)2(cid:1)
i i i i
term. For small ω⋆, the second term dominates and we have a super large denominator, thus
i
making the growth of ω⋆ slow. However, as ω⋆ goes somewhere near the valley of the function (not
i i
(cid:112)
necessarily achieving the minimum) while still remaining away from 1/d , the value of this term
i
suddenly decreases and makes the growth of ω⋆ fast. This is the reason why we have the sudden
i
emergence. After d (ω⋆)2 reaches 1, we have the convergence result. To characterize the emergence
i i
and convergence behavior, we also consider time t as a function of ω⋆:
i
(cid:0) (cid:1)
2+
ϕiexp di(ω i⋆)2
+
L (cid:0)(ω i⋆)2
(cid:1)
dt
=
L(ω i⋆)2 √ϕiexp di(ω i⋆)2
.
d(ω i⋆) (1−d i(ω i⋆)2)· d e−1 λ
i
By integrating this function with respect to ω⋆, we obtain some hyperbolic function for the time
i
function upon convergence.
113E Optimality
In this section, we provide optimality results for both the single-head case and the convergence
point of the multi-head attention’s training dynamics by providing a lower bound.
Notations. We denote by [A;B] the concatenation of two matrices A and B along the row
direction.
E.1 Optimality of Single-Head Attention
Inthissection, weprovideacharacterizationoftheglobaloptimalityofthesingle-headcase. Under
the condition W = 0, we have the training loss given by
Y
L(U,W)=∆ E(cid:104)(cid:13) (cid:13)G⊤q−(U XX +U Y(G⊤X +ε))p(cid:13) (cid:13)2 2(cid:105) , where p = softmax(X⊤W Xq).
Here, G ∈ Rd×dy is the random coefficient matrix. Recall that G = d−1/2Φdiag(g 1,...,g I)Ψ⊤.
Define G′ = diag(g ,...,g ). Since X, ε and q are rotationally invariant in distribution, one can
1 I
equivalently consider the rotated input X′ = Φ⊤X, ε′ = Ψ⊤ε and q′ = Φ⊤q, and also rotate the
weights by
W′ = Φ⊤W Φ, U′ = Ψ⊤U Ψ, U′ = Ψ⊤U Φ.
X X Y Y X X
Using the rotated input and weights, we have
p = softmax(X′⊤W′ q′), y = G⊤q = ΨG′⊤ q′,
X q
yp q = (U XX +U Y(G⊤X +ε))p = Ψ(U X′ X′+U Y′ (G′⊤X′+ε′))p, (E.1)
L(U′,W′) = E(cid:104)(cid:13) (cid:13)G′⊤ q′−(U′ X′+U′ (G′⊤X′+ε′))p(cid:13) (cid:13)2(cid:105) .
X Y 2
Therefore, it suffices to consider the case where Φ and Ψ are identity matrices. We aim to prove
the following theorem.
Theorem E.1 (Approximate Optimality of Single-Head Attention). For ssa! (ssa!) with I tasks,
assume that W = 0, and the noise level σ > 0 is a constant independent of d and L. Suppose
Y
L = o(exp(d)), then for some b⋆ = (b⋆) and u⋆ = (u⋆) , the following solution
i i∈[I] i i∈[I]
(cid:112) b⋆/d ·I 0 ··· 0   0 0 
1 i d1
(cid:112)
W⋆ =    
 
0 0. . . b⋆ 2/ 0d . . .i·I d2 · ·..· ·.·
· (cid:112) b⋆
I/d0 . . .
I ·I dI
⋆   

, U⋆ =    

0 u 0 .
.
.⋆ 1 u0 .
.
.⋆ 2 ·· ..·· .·· 00 .
. .
   
 
0 ⋆ 0 0 ··· u⋆
I
approximately achieves the minimal loss value in the sense that for any other (W,U) such that
W = 0, we have
Y
I
L(U⋆,W⋆) ≤ L(U,W)+(cid:88) λ id i ·O(L−(1−ϵ)/2+L−1+2(c−2∨ϵ)),
d
i=1
114where ϵ is a small constant. In particular, b⋆ and u⋆ can be obtained by first finding the solution
(B⋆,b⋆) to the following optimization problem for an absolute constant C ∈ (0,1):
b⋆ = argmin
(cid:88)I d iλ
i
(cid:18)
1−
b
i
(cid:19)
, and u⋆ =
(cid:112) b⋆ id
i .
d b +d ϕ exp(B)/L i b⋆+d ϕ exp(B⋆)/L
C·logL≥B≥0, i=1 i i i i i i
b∈RI +,1⊤b=B
Before we prove Theorem E.1, we first rewrite the loss function in a more convenient form and
discuss some related properties.
E.1.1 Rewriting and Lower Bounding the Loss Function
Note that p is only a function of (X,q) by W = 0. We use the mutual independence between
Y
(X,q), G and ε to rewrite the loss function as follows:
L(U,W) = E(cid:13) (cid:13)G⊤q−U YG⊤Xp(cid:13) (cid:13)2 2+E(cid:13) (cid:13)U XXp(cid:13) (cid:13)2 2+E(cid:13) (cid:13)U Yεp(cid:13) (cid:13)2
2
= E(cid:2) Tr(GG⊤)−2Tr(U G⊤Xpq⊤G)
Y
+Tr(U Xpp⊤X⊤U⊤+U G⊤Xpp⊤X⊤GU⊤+U εpp⊤ε⊤U⊤)(cid:3)
X X Y Y Y Y
≥ E(cid:2) Tr(GG⊤)−2Tr(U G⊤Xpq⊤G)+Tr(U (G⊤Xpp⊤X⊤G+εpp⊤ε⊤)U⊤)(cid:3) . (E.2)
Y Y Y
Here, the inequality follows from the fact that the trace of a positive semi-definite matrix is non-
negative and by setting U = 0, the inequality becomes an equality. Thus, it is sufficient to
X
consider the case U = 0 for optimality. Note that (E.2) is a quadratic function in terms of U .
X Y
By optimizing over U , we obtain L(W) as a lower bound of the loss value:
Y
L(W):=ETr(GG⊤)−Tr(cid:0)E[G⊤qp⊤X⊤G]·E[G⊤Xpp⊤X⊤G+εpp⊤ε⊤]−1·E[G⊤Xpq⊤G](cid:1)
. (E.3)
Here, the optimal U is given by
Y
U⋆(W) = E[G⊤qp⊤X⊤G]·E[G⊤Xpp⊤X⊤G+εpp⊤ε⊤]−1. (E.4)
Y
When plugging in the concrete form of G, we notice that E[G⊤MG] always gives a diagonal matrix
for any conformable matrix M. In particular,
 
(cid:88) (cid:88)
E[G⊤MG] = d−1·diagλ
1
M ii,...,λ
I
M ii.
i∈J1 i∈JI
(cid:80)
In the sequel, we denote by Tr (M) = M the sliced trace of the i-th block of M. Note that
i j∈Ji jj
E[εpp⊤ε⊤] = σ2I E[∥p∥2] is also a diagonal matrix. Consequently, (E.3) can be rewritten as
dy 2
L(W) =
(cid:88)I λ id
i
(cid:32)
1−
d−
i
1(cid:0)ETr i(E[Xp|q]q⊤)(cid:1)2 (cid:33)
. (E.5)
d ETr (E[Xpp⊤X⊤|q])+σ2dλ−1E[∥p∥2]
i=1 i i 2
Moreover, U⋆(W) is also a diagonal matrix:
Y
ETr (E[Xp|q]q⊤)
U⋆(W) = diag(u⋆(W),...,u⋆(W)), u⋆(W):= i . (E.6)
Y 1 I i ETr (E[Xpp⊤X⊤|q])+σ2dλ−1E[∥p∥2]
i i 2
115To lower bound (E.5), we invoke inequality (ETr (MN))2 ≤ ETr (MM⊤)·ETr (N⊤N) for any
i i i
two conformable random matrices M and N to obtain
L(W) ≥
(cid:88)I λ id
i
(cid:18)
1−
d−
i
1·E[Tr i(E[Xp|q]E[Xp|q]⊤)]·E[Tr i(qq⊤)](cid:19)
d ETr (E[Xpp⊤X⊤|q])+σ2dλ−1E[∥p∥2]
i=1 i i 2
(cid:88)I λ id
i
(cid:18) E[Tr i(E[Xp|q]E[Xp|q]⊤)] (cid:19)
= 1− . (E.7)
d ETr (E[Xpp⊤X⊤|q])+σ2dλ−1E[∥p∥2]
i=1 i i 2
We apply Stein’s lemma to deal with the expectation terms with respect to X and p. The result is
summarized by Lemma C.8 to and we defer readers to , we conclude that
E[Xp|q] = W q(1−f (∥W q∥2)),
X 1 X 2
(E.8)
E[Xpp⊤X⊤|q] = W qq⊤W⊤f (∥W q∥2)+I f (∥W q∥2),
X X 2 X 2 d 1 X 2
where
f (∥W q∥2) = E[∥p∥2|q], f (∥W q∥2) = E[1−∥p∥2−6∥p∥3+6∥p∥4|q].
1 X 2 2 2 X 2 2 3 2
We remark that both f and f are just functions of ∥W q∥2 as we have proved in Lemma C.4. In
1 2 X 2
the sequel, we drop the dependence of f ,f on ∥W q∥2 for simplicity. Plugging (E.8) into (E.5),
1 2 X 2
we obtain
L(W) =
(cid:88)I λ id
i
(cid:32)
1−
d−
i
1(cid:0)E[Tr i(W Xqq⊤(1−f 1))](cid:1)2(cid:33)
, (E.9)
d E[Tr (W qq⊤W⊤f )+d ϕ f ]
i=1 i X X 2 i i 1
where we follow the convention to denote ϕ = 1+SNR−1 = 1+σ2dλ−1d−1. Also, U⋆(W) has
i i i i Y
diagonal entries given by plugging (E.8) into (E.6):
E[Tr (W qq⊤(1−f ))]
u⋆(W) = i X 1 . (E.10)
i E[Tr (W qq⊤W⊤f )+d ϕ f ]
i X X 2 i i 1
Plugging (E.8) into (E.7), we obtain
L(W) ≥
(cid:88)I λ id
i
(cid:18)
1−
E[Tr i(W Xqq⊤W X⊤)(1−f 1)] (cid:19)
. (E.11)
d E[Tr (W qq⊤W⊤f )+d ϕ f ]
i=1 i X X 2 i i 1
We remind the readers that we do not make any change to the denominator of (E.11), which is
still equal to ETr (E[Xpp⊤X⊤|q])+σ2dλ−1E[∥p∥2] > 0. Invoking the fact that both f and f
i i 2 1 2
are just functions of ∥W q∥2 = Tr(W qq⊤W⊤), and that E[f(x)]/E[g(x)] ≤ sup f(x)/g(x) for
X 2 X X x
non-negative function g, we have (E.11) further lower bounded by
L(W) ≥ inf L (B,b), where L
(B,b):=(cid:88)I d iλ
i
(cid:18)
1−
b i(1−f 1(B))2 (cid:19)
. (E.12)
lb lb
B≥0,b≥0 d b if 2(B)+d iϕ if 1(B)
1⊤b=B i=1
Comparing (E.12) to (E.11), we are just replacing the sliced trace by b and the full trace by B
i
and imposing the constraint 1⊤b = B. We give a physical interpretation of (E.12). If we view B
as the “attention budget” and b as the “attention allocation for task i”, then (E.12) is a bilevel
i
optimization problem where:
116• The lower-level problem is to find the optimal allocation of the attention budget to each task
for a given attention budget B.
• The upper-level problem is then to decide the optimal attention budget B.
As a concluding remark for this lower bound, we have the following lemma that shows the achiev-
ability of the lower bound.
E.1.2 Approximations of Nonlinear Functions f and f
1 2
The next thing is to understand the behavior of f and f . Note that as we have characterized in
1 2
Appendix B, we have under bounded parameter norm condition that
exp(B)
f (B) = E[∥p∥2|∥W q∥2 = B] ≈ , f (B) = E[1−∥p∥2−6∥p∥3+6∥p∥4|∥W q∥2 = B] ≈ 1.
1 2 X 2 L 2 2 3 2 X 2
Therefore, it suffices to characterize the following dominant part of the loss’s lower bound
I (cid:18) (cid:19)
L
(B,b):=(cid:88) d iλ i
1−
b i
.
sim d b +d ϕ ·exp(B)·L−1
i i i
i=1
The following lemma gives an approximation of L with L when B is bounded from above.
lb sim
√ √
Lemma E.2 (Simple Approximation of L ). For any ϵ > 0, suppose B ≤ c−1 2logL, where c
lb
satisfies
1 3
+ ≤ ϵ.
(cid:112)
c 1+ 1+c2/2
Then for any b with non-negative elements such that 1⊤b = B, it holds that
I
|L (B,b)−L (B,b)| ≤
(cid:88) d iλ i ·O(L−1+2(c−2∨ϵ)).
lb sim
d
i=1
√ √
Proof. (Proof of Lemma E.2) Note that for B ≤ c−1 2logL, where by our choice c satisfies the
conditions in Lemma B.2, we have
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)f 1(B)− exp L(B)(cid:12) (cid:12)
(cid:12)
= (cid:12) (cid:12) (cid:12)E[∥p∥2 2|∥W Xq∥2
2
= B]− exp L(B)(cid:12) (cid:12)
(cid:12)
≤ O(L−2(1−ϵ)).
In additions, Lemma B.2 also implies that
|f 2(B)−1| = (cid:12) (cid:12)E[−∥p∥2 2−6∥p∥3 3+6∥p∥4 2|∥W Xq∥2
2
= B](cid:12) (cid:12) ≤ exp L(B) +O(L−2(1−ϵ)) ≤ O(L−1+2c−2 ).
Therefore, we have for the target function in (E.12) that
(cid:88)I d iλ
i
(cid:32) b i·(1±O(L−1+2c−2))2 (cid:33)
L (B,b) = 1−
lb d b ·(1±O(L−1+2c−2))+d ϕ ·exp(B)·L−1·(1±O(L−1+2ϵ))
i i i
i=1
I (cid:18) (cid:19)
=
(cid:88) d iλ i
1−
b i ·(cid:16) 1±O(L−1+2(c−2∨ϵ))(cid:17)
d b +d ϕ ·exp(B)·L−1
i i i
i=1
I (cid:18) (cid:19) I
=
(cid:88) d iλ i
1−
b i ±(cid:88) d iλ i ·O(L−1+2(c−2∨ϵ)),
d b +d ϕ ·exp(B)·L−1 d
i i i
i=1 i=1
where the last equality is due to the fact that bi ≤ 1.
bi+diϕi·exp(B)·L−1
117E.1.3 The Optimal Attention Budget is Bounded
Following the result of Lemma E.2, we are able to characterize L in order to understand the
sim
behavior of L with bounded attention budget B. We first give a naive upper bound of L by
lb lb
plugging in b = Bd /d for all i ∈ [I] and B = 1.
i i
Lemma E.3 (Upper Bound of L ). For L (B,b), we have upper bound on the minimal value as
lb lb
inf L (B,b) ≤
(cid:88)I (d iλ i+σ2d)e·L−1 +(cid:88)I d iλ
i ·O(L−1+2(c−2∨ϵ))
= O(d/L).
B≥0,b≥0, lb 1+dϕ ie·L−1 d
1⊤b=B i=1 i=1
Proof of Lemma E.3. We choose B = 1 and plug b = Bd /d into L (B,b) and have
i i sim
(cid:12)
L (B,b)| =
(cid:88)I
d iλ
i
(cid:18)
1−
1
(cid:19)(cid:12)
(cid:12)
sim B=1,bi=Bdi/d d 1+dϕ exp(B)B−1·L−1 (cid:12)
i (cid:12)
i=1 B=1
(cid:88)I d iλ
i
dϕ ie·L−1 (cid:88)I (d iλ i+σ2d)e·L−1
= · = ,
d 1+dϕ e·L−1 1+dϕ e·L−1
i i
i=1 i=1
which is clearly of the order O(d/L). In addition, we note that B = 1 ≤ c−2·2logL for sufficiently
large L and any choice of ϵ ∈ (0,1) and corresponding c. Hence, the condition in Lemma E.2 is
satisfied for this choice of B,b. Therefore, we conclude the proof by also including the error of
approximating L with L in Lemma E.2.
lb sim
GiventheupperboundoftheoptimalvalueofL ,wenextshowthatitsufficestooptimizeover
lb
B in a small range, i.e., 0 ≤ B ≤ c−22logL for some small constant c. We first consider the large
√
scale regime, i.e., B ≥ O(d1−ϵ) with a constant scale of noise σ2 = Ω(1). For our convenience, we
define a normalized version of the query token as
 qr 
(1)
.
qr=   . .  , where qr (i) = d i∥q (i)∥− 21·q (i).
qr
(I)
Here, we let q be the i-th block of q corresponding to task i’s position J . Notably, each qr is
(i) √ i (i)
uniformly distributed on the d i-sphere in Rdi. Under this model with normalized query token,
we have the optimal U still given by (E.6) and this time each diagonal element is given by
Y
E[Tr (W qrqr⊤(1−f ))]
ur⋆(W):= i X 1 . (E.13)
i E[Tr (W qrqr⊤W⊤f )+d ϕ f ]
i X X 2 i i 1
In addition, we define the corresponding loss function as
Lr (W):=(cid:88)I λ id i (cid:32) 1− d− i 1(cid:0)E[Tr i(W Xqrqr⊤(1−f 1))](cid:1)2(cid:33) , (E.14)
d E[Tr (W qrqr⊤W⊤f )+d ϕ f ]
i=1 i X X 2 i i 1
Lemma E.4. (Large B is suboptimal for constant noise level) Suppose B = Ω(d2−2ϵ) for some
small ϵ ∈ (0,1), the noise level σ2 = Ω(1), and L = o(exp(d)). Then for any b with non-negative
elements such that 1⊤b = B,
(cid:88)I d iλ
i
σ2/λ i(1−O(d−(1−2ϵ)))
L (B,b) ≥ = Ω(1).
lb d 1+σ2/λ (1−O(d−(1−2ϵ)))
i
i=1
118Proof of Lemma E.4. NotethatundertheconditionB ≥ Ω(d2−2ϵ), itfollowsfromLemmaB.5that
√
f (B) = E[∥p∥2|∥W q∥2 = B] ≥ 1−O( B−(1−ϵ) ) ≥ 1−O(d−(1−2ϵ)), (E.15)
1 2 X 2
which means that the attention probability vector is approximately one-hot. Our goal is thus using
this “almost deterministic” property to show that as long as we have a constant level of noise, the
ICL rate is suboptimal. Our proof is constructive in nature, i.e., relating the loss L (B,b) to the
lb
ICL rate of another model with a constructed attention weights. Consider the following choice of
weights:
(cid:112) 
b /d ·I ··· 0
1 1 d1
 . .
.
... . .
.
⋆
W =  . (E.16)
 (cid:112) 
 0 ··· b I/d I ·I dI 
0 ⋆
Recall the definition of L (B,b) in (E.12) that
lb
(cid:88)I d iλ
i
(cid:18) b i(1−f 1(B))2 (cid:19)
L (B,b) = 1− .
lb
d b f (B)+d ϕ f (B)
i 2 i i 1
i=1
Note that the denominator b f (B)+d ϕ f (B) is always positive. In the sequel, we aim to lower
i 2 i i 1
bound the value of L (B,b), thus equivalent to lower bounding the denominator. We have
lb
b f (B)+d ϕ f (B) = Tr (cid:0) W qrqr⊤W ·f (∥W qr∥2)(cid:1) +d ϕ f (∥W qr∥2)
i 2 i i 1 i X X 2 X 2 i i 1 X 2
= Tr (cid:0) W qrqr⊤W ·f (∥W qr∥2)+I f (∥W qr∥2)(cid:1) +σ2dλ−1f (B)
i X X 2 X 2 d 1 X 2 i 1
= Tr (cid:0)E[Xpp⊤X⊤|qr](cid:1) +σ2dλ−1f (B).
i i 1
Here, qrcan be any normalized query token. The first equality holds by noting that ∥W qr∥2 ≡ B
X 2
and Tr (W qrqr⊤W⊤) ≡ b by our construction. The second equality holds by definition ϕ =
i X X i i
1+dσ2/(λ d ). The last equality holds by (E.8) where p = softmax(X⊤W qr). Meanwhile, we also
i i X
have for the numerator that
b (1−f (B))2 = Tr (cid:0) W qrqr⊤W⊤(1−f (B))2(cid:1) = Tr (cid:0)E[Xp|qr]E[Xp|qr]⊤(cid:1) .
i 1 i X X 1 i
For L (B,b), we thus have
lb
(cid:88)I
d iλ
i
(cid:32)
Tr
i(cid:0)E[Xp|qr]E[Xp|qr]⊤(cid:1) (cid:33)
L (B,b) = 1−
lb d Tr (cid:0)E[Xpp⊤X⊤|qr](cid:1) +σ2dλ−1f (B)
i=1 i i 1
≥
(cid:88)I d iλ
i ·
σ2dλ−
i
1f 1(B)
d Tr (cid:0)E[Xp|qr]E[Xp|qr]⊤(cid:1) +σ2dλ−1f (B)
i=1 i i 1
≥
(cid:88)I d iλ
i ·
σ2λ−
i
1f 1(B)
i=1
d d−1·(cid:13) (cid:13)E[Xp|qr](cid:13) (cid:13)2 2+σ2λ−
i
1f 1(B)
Here, the first inequality is Cauchy-Schwarz. Therefore, it suffices to upper bound the term
(cid:13) (cid:13)E[Xp|qr](cid:13) (cid:13)2 2. Consider v = W Xqr/∥W Xqr∥
2
as the direction of the attention. For each x l, we decom-
pose it into the part that is parallel to v and the part that is orthogonal to v, i.e., x = z v +x⊥
l l l
119where in distribution z i. ∼i.d. N(0,1) and are independent of x⊥. Define z = (z ,...,z )⊤ and
l l 1 L
X⊥ = (x⊥,...,x⊥). By the definition of the softmax probability, we have
1 L
√
p = softmax(x⊤W qr) = softmax( Bz),
l X
which is just a function of z. Therefore, in expectation, we have
E[Xp|qr] = E[X⊥p+v·zp|qr] = v·E[zp|qr]
√
⇒ (cid:13) (cid:13)E[Xp|qr](cid:13) (cid:13)2
2
= E[zp|qr]2 = E[zsoftmax( Bz)]2 ≤ (cid:0)Emax{z 1,...,z L}(cid:1)2 = O(2logL).
Here we use the fact that hard max is larger than softmax. Therefore, we have for L (B,b) that
lb
L (B,b) ≥
(cid:88)I d iλ
i ·
σ2λ−
i
1f 1(B)
lb
i=1
d d−1·(cid:13) (cid:13)E[Xp|qr](cid:13) (cid:13)2 2+σ2λ−
i
1f 1(B)
≥
(cid:88)I d iλ
i ·
σ2λ−
i
1(1−O(d−(1−2ϵ)))
.
d O(2d−1logL)+σ2λ−1(1−O(d−(1−2ϵ)))
i=1 i
Hence, for L = o(exp(d)), we always have L (B,b) = Ω(1) with constant noise level.
lb
√
Thus, it suffices to focus on the case 0 ≤ B ≤ O(d1−ϵ) for some small ϵ ∈ (0,1) when doing
the optimization of the target function in (E.12). The next lemma further shows we can further
restrict the attention budget to a much smaller range 0 ≤ B ≤ O(logL).
√
Lemma E.5. Consider 0 ≤ B ≤ O(d1−ϵ) for some small ϵ ∈ (0,1) when doing the optimization
of the target function in (E.12). Let c be a constant satisfying
1 3
+ ≤ ϵ.
(cid:112)
c 1+ 1+c2/2
In addition, we take sufficiently large L such that c−2·2logL = Ω(1). We have for any b ≥ 0 such
that 1⊤b = B,
I
L (B,b) ≥ min L
(B,b)−(cid:88) d iλ i ·O(L−1+2(c−2∨ϵ)).
lb sim
c−22logL≥B≥0 d
1⊤b=B,b≥0 i=1
Proof of Lemma E.5. We discuss the behavior of L in three cases.
lb
√ √
Case 1. For the case 0 ≤ B ≤ c−1 2logL, we have following Lemma E.2 that L (B,b) is well
lb
approximated by L (B,b). Combining the discussion in Lemma E.2 and also the upper bound in
sim
Lemma E.3, we have
I
min L (B,b) = min L
(B,b)±(cid:88) d iλ i ·O(L−1+2(c−2∨ϵ))
≤ O(d/L).
lb sim
c−22logL≥B≥0 c−22logL≥B≥0 d
1⊤b=B,b≥0 1⊤b=B,b≥0 i=1
The remaining thing is to show for the other case the optimal value of L is much larger than
lb
O(d/L).
120√ √
Case 2. For O(d1−ϵ) ≥ B ≥ Ω( 2logL3/ϵ ), we have f (b) = E[∥p∥2|∥W q∥2 = B] ≥ 1 −
√ 1 2 X 2
−1+ϵ
O( B ) for some small ϵ by Lemma B.5. Therefore,
(cid:88)I d iλ
i
(cid:18) b i(1−f 1(B))2 (cid:19)
L (B,b) = 1−
lb
d b f (B)+d ϕ f (B)
i 2 i i 1
i=1
(cid:88)I d iλ i(cid:18) b i·O(B−1+ϵ) (cid:19)
≥ 1− √ √
d −1+ϵ −1+ϵ
−O( B )·b +d ϕ ·(1−O( B ))
i=1 i i i
√
I (cid:18) 2ϵ (cid:19) I
(cid:88) d iλ i O( B ) (cid:88) d iλ i
≥ 1− √ √ = (1−o(1)).
d 1+ϵ −1+ϵ d
−O( B )+d ϕ ·(1−O( B ))
i=1 i i i=1
Here, in the first inequality, we have f (B) lower bounded as
2
f (B) = E[1−∥p∥2−6∥p∥3+6∥p∥4|∥W q∥2 = B] ≥ −6E[∥p∥3−∥p∥4|∥W q∥2 = B]
2 2 3 2 X 2 3 2 X 2
L L
(cid:88) (cid:88)
= − 6E[p2(p −∥p ∥2)|∥W q∥2 = B] ≥ − 6E[p2(∥p ∥ −∥p ∥2)|∥W q∥2 = B]
l l l 2 X 2 l l 2 l 2 X 2
l=1 l=1
= −6E[∥p∥3(1−∥p∥ )|∥W q∥2 = B] ≥ −3E[∥p∥2(1+∥p∥ )(1−∥p∥ )|∥W q∥2 = B]
2 2 X 2 2 2 2 X 2
√
= −3E[1−∥p∥2|∥W q∥2 = B] ≥ −O( B−1+ϵ ).
2 X 2
The second inequality follows by 0 ≤ b ≤ B. And for the last inequality, we notice that
i
√ √ √
d ϕ (1−O(
B−1+ϵ
)) = O(d), O(
B1+ϵ
) ≤
O(d1−ϵ2
) = o(d), O(
B2ϵ
) = o(d).
i i
Hence, there is no effective ICL learning for this case.
√ √ √
Case 3. For the last case, i.e., c−1 2logL ≤ B ≤ O( 2logL3/ϵ ), we apply the monotonicity
of E[∥p∥2|∥W q∥2 = B] with respect to B as is shown in Lemma B.1, which gives us f (B) ≥
2 X 2 1
f (c−22logL) = exp(c−22logL)/L−O(L−2(1−ϵ)) ≥ O(L2c−2−1). Therefore, it follows that
1
I (cid:18) (cid:19)
(cid:88) d iλ i b i
L (B,b) ≥ 1− ,
lb d −6b +d ϕ L2c−2−1
i i i
i=1
√
3/ϵ
where we use the fact that f (B) ≥ −6. Note that d /L = Θ(1) and b ≤ B ≤ O( 2logL ) ≪
2 i i
d L2c−2−1. Thus,weconcludethattheabovetermislowerboundedbyL (B,b) ≥ (cid:80)I diλi (1−o(1)).
i lb i=1 d
Combining the above results, we conclude that the optimality could only be achieved in the first
√ √
case, i.e., 0 ≤ B ≤ c−1 2logL.
Let (B⋆,b⋆) be the solution to the following optimization problem:
I (cid:18) (cid:19)
(cid:88) d iλ i b i
min L (B,b) = 1− . (E.17)
c−22logL≥B≥0,b≥0, sim d b i+d iϕ i·exp(B)·L−1
1⊤b=B i=1
By Lemma E.5, it suffices to consider the range 0 ≤ B ≤ c−22logL for some constant c. However,
for our purpose, we need a more refined characterization of the optimal attention budget B. The
following result shows that the optimal B should be of order o(logL).
121Lemma E.6. Let (B⋆,b⋆) be any optimal solution to (E.17). Then it holds that B⋆ = o(logL).
Proof of Lemma E.6. Suppose B∗ = βlogL for some constant β such that c−2 ≥ β > 0 and we
have exp(B)/L = L−1+β. As a result, the value to the optimization target of (E.17) is lower
bounded by
I (cid:18) (cid:19) I
(cid:88) d iλ i βlogL (cid:88) d iλ i
1− = (1−o(1)),
d βlogL+d ϕ ·L−1+β d
i i
i=1 i=1
which, given d /L = Θ(1), is clearly suboptimal.
i
E.1.4 Perturbation Analysis
In this part, we understand the effect of perturbation of the optimal weights on the ICL rate.
Consider the following weights:
(cid:112) b /d ·I 0 ··· 0   0 0 
1 i d1
(cid:112)
W =

  


0
0. . .
b 2/ 0d
. .
.i·I d2 · ·..· ·.·
·
(cid:112)
b
I/d0
. . .
I ·I dI
⋆
  

, U =

  

0
u
0 .
.
.1 u0
.
.
.2
·· ..·· .·· 00
.
.
.

  

. (E.18)
0 ⋆ 0 0 ··· u I
We have the following result for the above weights.
(cid:112)
Lemma E.7 (Perturbation of attention weights). We define ω = b /d and u⋆(b) as
i i i i
√
b d
u⋆(b) = i i , (E.19)
i b +d ϕ exp(B)/L
i i i
and consider u to be the perturbation of u⋆(b). We consider bounded attention budget 0 ≤ B =
i i
o(logL) and bounded perturbation such that
0 < ω u = O(1), u2 = O(d ). (E.20)
i i i i
Suppose d/L = Θ(1) and d /d = Θ(1). It then holds that
i
L(U,W) = L
(B,b)+(cid:88)I
d
i
·(cid:18)(cid:18)
λ b +
(d iλ
i+σ2d)eB(cid:19)
d−1·(u −u⋆(b))2±λ
·O(L−(1−ϵ)/2)(cid:19)
.
sim d i i L i i i i
i=1
If in addition, we have |B−B⋆| = o(B⋆), then we have
L(U,W) = L
(B⋆,b⋆)+(cid:88)I
λ
i
·(cid:18)(cid:18)
b⋆+
d iϕ
ieB⋆(cid:19)
·(u
−u⋆)2(cid:19)
sim d i L i i
i=1
I (cid:18) (cid:19)
+(cid:88) λ id i ·O u |ω −ω⋆|+ ϕ i |B−B⋆|+ξ .
d i i i L
i=1
122Proof of Lemma E.7. By our previous discussion in Lemma E.6, we restrict our attention budget
to the range 0 ≤ B = o(logL). Our goal is to understand the ICL loss
L(U,W) = E(cid:104)(cid:13) (cid:13)G⊤q−U Y(G⊤X +ε)p(cid:13) (cid:13)2 2(cid:105)
= E(cid:2) Tr(GG⊤)−2Tr(U G⊤Xpq⊤G)+Tr(U (G⊤Xpp⊤X⊤G+εpp⊤ε⊤)U⊤)(cid:3)
Y Y Y
I
= (cid:88) λ id i ·(cid:16) 1−2u d−1ETr (Xpq⊤)+u2d−1(cid:0)ETr (Xpp⊤X⊤)+dσ2λ−1E[∥p∥2](cid:1)(cid:17) .
d i i i i i i i 2
i=1
Using (E.8), we have
I
L(U,W) = (cid:88) λ id i ·(cid:16) 1−u d−1E(cid:2) Tr (W qq⊤)(1−f )(cid:3) +u2d−1E(cid:2) Tr (W qq⊤W⊤f )+d ϕ f (cid:3)(cid:17) .
d i i i X 1 i i i X X 2 i i 1
i=1
With 0 ≤ B = o(logL), and noting that b ≤ B, we have that all the conditions in Lemma B.3 on
i
the eigenvalues ω of W are satisfied given that d/L = Θ(1) and d /d = Θ(1), i.e.,
X i
2logL
∥ω∥ ≤ L−1/4·(logL)−1/2, ∥ω∥2 ≤ , ∥ω∥4 ≤ L−(1−ϵ)·(logL)−1.
∞ 2 3c2 4
We thus conclude that
(cid:34) (cid:35)
(cid:18) exp(B)(cid:19)2
E f (∥W q∥2)− ≤ O(L−(3−ϵ)).
1 X 2 L
This together with the fact that ∥p∥3 ≤ ∥p∥2 and ∥p∥4 ≤ ∥p∥2 implies that
3 2 2 2
(cid:104) (cid:105)
E (cid:0) f (∥W q∥2)−1(cid:1)2 ≤ O(cid:0)E[f (∥W q∥2)2](cid:1) ≤ O(L−2(1−ϵ)).
2 X 2 1 X 2
Here, the last inequality holds since B ≤ ϵlogL for fixed small constant ϵ > 0. Therefore, we have
each term in the ICL loss to be
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)E[Tr (W qq⊤)(1−f )]−ω d (cid:12) = (cid:12)E[Tr (W qq⊤)(1−f )]−E[Tr (W qq⊤)](cid:12)
(cid:12) i X 1 i i(cid:12) (cid:12) i X 1 i X (cid:12)
(cid:12) (cid:18)(cid:113) (cid:19)(cid:12)
≤ (cid:12) (cid:12) (cid:12)Tr i E[diag(W Xqq⊤)⊙2]E[f 12] (cid:12) (cid:12)
(cid:12)
(cid:113)
= ω d E[χ4]E[f2] = ω d ·O(L−(1−ϵ)).
i i 1 i i
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)ETr (W qq⊤W⊤f )−ω2d (cid:12) = (cid:12)ETr (W qq⊤W⊤f )−ETr (W qq⊤W⊤)(cid:12)
(cid:12) i X X 2 i i(cid:12) (cid:12) i X X 2 i X X (cid:12)
(cid:12) (cid:18)(cid:113) (cid:19)(cid:12)
≤ (cid:12) (cid:12) (cid:12)Tr i E[diag(W Xqq⊤W X⊤)⊙2]E[(f 2−1)2] (cid:12) (cid:12)
(cid:12)
(cid:112)
= ω2d E[χ4]E[(f −1)2] = ω2d ·O(L−(1−ϵ)).
i i 2 i i
(cid:118)
(cid:12)
(cid:12) (cid:12)E[f 1]−
exp(B)(cid:12)
(cid:12) (cid:12) ≤
(cid:117)
(cid:117)
(cid:116)E(cid:34) (cid:18)
f 1−
exp(B)(cid:19)2(cid:35)
≤ O(L−(3−ϵ)/2) ≤ exp(B) ·O(L−(1−ϵ)/2).
(cid:12) L (cid:12) L L
123Therefore, the ICL loss can be controlled as
L(U,W) = (cid:88)I λ id i (cid:18) 1−2u ω (1±ξ2)+u2(cid:0) ω2(1±ξ2)+ ϕ ieB (1±ξ)(cid:1)(cid:19)
d i i i i L
i=1
= (cid:88)I λ id i (cid:18) 1−2u ω +u2(cid:0) ω2+ ϕ ieB (cid:1)(cid:19) ±(cid:88)I λ id i ·(cid:0) ξ2(2u ω +u2ω2)+ξu2ϕ eB/L(cid:1)
d i i i i L d i i i i i i
i=1 i=1
(cid:88)I λ id
i
d iϕ ieB/L (cid:88)I λ id
i
(cid:32) (cid:18) d iϕ ieB(cid:19) (cid:18) u
i
√ b
i
(cid:19)2 (cid:33)
= · + · b + · √ − ±O(ξ) ,
i=1
d b i+d iϕ ieB/L
i=1
d i L d
i
b i+d iϕ ieB/L
where ξ = O(L−(1−ϵ)/2). Here, the last upper and lower bound follows from (E.20). Moreover, if
we also consider the perturbation of ω from the optimal value, we have with |B−B⋆| = o(B⋆) that
L(U,W) =
(cid:88)I
λ id
i
·(cid:18)
1−2u ω⋆+(u
)2(cid:18)
(ω⋆)2+
ϕ
ieB⋆(cid:19) ±O(cid:18)
u |ω −ω⋆|+
ϕ
i
|B⋆−B|(cid:19)(cid:19)
d i i i i L i i i L
i=1
I
(cid:88) λ id i
± ·O(ξ)
d
i=1
=
(cid:88)I λ id
i ·
d iϕ ieB⋆/L +(cid:88)I λ
i
·(cid:18)(cid:18)
b⋆+
d iϕ ieB⋆(cid:19)
·(u
−u⋆)2(cid:19)
d b +d ϕ eB⋆/L d i L i i
i i i
i=1 i=1
I (cid:18) (cid:19)
+(cid:88) λ id i ·O u |ω −ω⋆|+ ϕ i |B−B⋆|+ξ .
d i i i L
i=1
Hence, we prove the desired result.
E.1.5 Proof of The Main Theorem and Its Consequences
Now we are ready to present the proof of Theorem E.1.
Proof of Theorem E.1. Now, we construct our W⋆ and U⋆ matrix for an upper bound:
(cid:112) b⋆/d ·I 0 ··· 0   0 0 
1 i d1
(cid:112)
W⋆ =    
 
0 0. . . b⋆ 2/ 0d . . .i·I d2 · ·..· ·.·
· (cid:112) b⋆
I/d0 . . .
I ·I dI
⋆   

, U⋆ =    

0 u 0 .
.
.⋆ 1 u0 .
.
.⋆ 2 ·· ..·· .·· 00 .
. .
   

, (E.21)
0 ⋆ 0 0 ··· u⋆
I
where B⋆ and b⋆ = (b⋆,...,b⋆) are the optimal solution to (E.17) and each u⋆ is given by
1 I i
(cid:112) b⋆d
u⋆ = i i
i b⋆+d ϕ exp(B⋆)/L
i i i
124according to (E.19). Combining our previous discussions, we already have any group of weights
W,U such that W = 0 satisfying the lower bound
Y
inf L(U,W) ≥ inf L (B,b) // (E.12)
lb
U,W B≥0
WY=0 1⊤b=B,b≥0
≥ min L (B,b) // Lemma E.4
lb
O(d2−2ϵ)≥B≥0
1⊤b=B,b≥0
I
≥ min L
(B,b)−(cid:88) d iλ i ·O(L−1+2(c−2∨ϵ)).
// Lemma E.5
sim
c−22logL≥B≥0 d
1⊤b=B,b≥0 i=1
WealsonotethatB⋆ = o(logL)byLemmaE.6. Inaddition, (E.20)issatisfiedbyourconstruction.
Hence, it holds by Lemma E.7 that
I
L(U⋆,W⋆) ≤ min L (B,b)+(cid:88) d iλ i ·O(L−(1−ϵ)/2).
sim
c−22logL≥B≥0 d
1⊤b=B,b≥0 i=1
Hence, we conclude that
I
L(U⋆,W⋆) ≤ inf L(U,W)+(cid:88) λ id i ·O(L−(1−ϵ)/2+L−1+2(c−2∨ϵ)),
U,W d
WY=0 i=1
which completes our proof of Theorem E.1.
In the following, we consider a special case where we have only one task i having nonzero signal
strength λ = Θ(1).
i
Lemma E.8. Suppose that we have only one task i with signal strength λ = Θ(1) and λ = 0 for
i j
j ̸= i. Then
√
(i) The solution to (E.17) is given by B⋆ = b⋆ = 1 (which implies ω⋆ = d −1 and ω⋆ = 0 for
i √ i i j
j ̸= i). In addition, we have optimal value u⋆ = d /(1+d ϕ eL−1) and u⋆ = 0 for j ̸= i.
i i i i j
Let U, W be constructed as in (E.21) with b⋆ and u⋆ given as above. This gives the optimal
ICL loss in the sense that
d λ d λ
L(U⋆,W⋆) = L (B⋆,b⋆)± i i ·O(L−(1−ϵ)/2) ≤ inf L(U,W)+ i i ·O(L−(1−ϵ)/2),
sim
d U,W d
WY=0
where L (B⋆,b⋆) is given by L (B⋆,b⋆) = ediϕi/L .
sim sim 1+ediϕi/L
(ii) Let ω⋆ and u⋆ be defined as in (i). Suppose we have a construction of ω and u such that
i i
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)ω i (cid:12) (cid:12)u i (cid:12)
(cid:12)
(cid:12)ω⋆
−1(cid:12)
(cid:12)
≤ δ ω, (cid:12)
(cid:12)u⋆
−1(cid:12)
(cid:12)
≤ δ u, |ω j| ≤ ξ ω, |u j| ≤ ξ u, ∀j ∈ [I]\{i}, (E.22)
i i
where δ = o(1),δ = o(1), ξ = o(d−1/2) and ξ = o(d1/2). Then the ICL loss for such a
ω u ω u
construction is upper bounded by
L(U,W) ≤ L (B⋆,b⋆)+
λ id
i ·O(δ
+ξ2d+δ2)+(cid:88)I d kλ
k ·O(L−(1−ϵ)/2)+
σ2I
·O(ξ2).
sim d ω ω u d L u
k=1
125Proof of Lemma E.8. The first argument is straightforward by noting that the inner problem of
(E.17) is convex with fixed total attention budget B, and we have monotonicity that the more
attention budget is allocated to a task, the smaller the loss for that task is. With λ = 0, the
j
nominal task j has no effect on the ICL loss and thus all attention budget should be allocated to
the only task i, which gives the simplified loss
d λ 1
i i
min L (B,b) = · .
b:1⊤b=B sim d Be−B ·d−1ϕ−1L+1
i i
Obviously, B = 1 is the optimal solution to the above problem since xe−x is maximized at x = 1
for x ≥ 0. The optimal u⋆ is given by (E.19). Invoking Lemma E.7, we have the desired result for
i
the first argument.
For the second argument, we define b = ω2d and B = (cid:80)I b . Under the perturbation of ω,
i i i i=1 i
we have for task i that
(cid:12) (cid:12) (cid:12) (cid:12)b +d iϕ die ϕB e/ BL /L − b⋆d +iϕ die ϕB e⋆ B/L ⋆/L(cid:12) (cid:12) (cid:12) (cid:12) ≤ b⋆d +iϕ die ϕB e⋆ B/L ⋆/L ·(cid:12) (cid:12) (cid:12) (cid:12)b⋆ ieB b−B⋆ −1(cid:12) (cid:12) (cid:12) (cid:12) ≤ b⋆d +iϕ die ϕB e⋆ B/L ⋆/L ·O(δ ω +ξ ω2d).
i i i i i i i i i i i i i
and for task j ̸= i that
λ d d ϕ eB/L λ d
j j j j j j
0 ≤ · ≤ = 0.
d b +d ϕ eB/L d
j j j
In addition, we have
(cid:12) (cid:12) √ b d (cid:112) b⋆d (cid:12) (cid:12)
|u⋆(b)−u⋆| = (cid:12) i i − i i (cid:12)
i i (cid:12)b +d ϕ eB/L b⋆+d ϕ eB⋆/L(cid:12)
(cid:12) i i i i i i (cid:12)
(cid:12) (cid:12)√
b
(cid:0)(cid:112) b⋆−√
b +d ϕ
L−1·(cid:0) eB⋆/(cid:112) b⋆−eB/√
b
(cid:1)(cid:1)(cid:12)
(cid:12)
≤ u⋆·(cid:12) i i i i i i i (cid:12) ≤ u⋆·O(δ +ξ2d).
i (cid:12) b +d ϕ eB/L (cid:12) i ω ω
(cid:12) i i i (cid:12)
For the perturbation of u, we have for task i that
|u −u⋆(b)| ≤ |u −u⋆|+|u⋆(b)−u⋆| ≤ u⋆·O(δ +δ +ξ2d),
i i i i i i i ω u ω
and for task j ̸= i that
(cid:112)
b d
(cid:12) (cid:12)u j −u⋆ j(b)(cid:12) (cid:12) ≤ ξ u∨ b +d ϕj ej B/L = ξ u∨0 = ξ u.
j j j
Plugging these error terms into Lemma E.7, we have
L(U,W) ≤ L (B⋆,b⋆)+
λ id
i ·
d iϕ ieB⋆/L
·O(δ
+ξ2d)+(cid:88)I d kλ
k ·O(L−(1−ϵ)/2)
sim d b⋆+d ϕ eB⋆/L ω ω d
i i i k=1
+(cid:18)
λ b +
(d iλ i+σ2d)eB(cid:19)
d−1(u⋆)2·O(δ2 +δ2
+ξ4d2)+(cid:88) σ2eB
ξ2
i i L i ω u ω L u
j̸=i
≤ L (B⋆,b⋆)+
λ id
i ·O(δ
+ξ2d+δ2)+(cid:88)I d kλ
k ·O(L−(1−ϵ)/2)+
σ2I
·O(ξ2).
sim d ω ω u d L u
k=1
This completes the proof.
126Lemma E.9 (Restatement of Lemma 4.1). The ICL loss under the convergence point described for
the MS-Attn in Theorem 3.3, which we define as L , is upper bounded by
Conv
L ≤
(cid:88)I λ id
i
·(cid:18) ed iϕ iL−1 +O(L−(1−ϵ)/2+ω2d+δ)(cid:19)
.
Conv d 1+ed ϕ L−1 0
i i
i=1
Proof of Lemma E.9. Same as before, we consider Φ and Ψ to be identity matrices. Define
G = diag(0, ..., 0, g , 0, ..., 0)
i i
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
i−1 I−i
as the coefficient matrix with only the i-th block of G. Note that for Decomposable weights we
always have U(h) and W(h) satisfying the form in (E.18) with
 ω(h) ·I 0 ··· 0   0 0 
1 d1
 0 ω(h) ·I ··· 0   µ(h) 0 ··· 0 
 2 d2 ⋆  1 
W(h) =   
 
0. . . 0. . . ·.. ·.
· ω
I(h). . .
·I dI
  

, U(h) =   

0 0 .
. .
µ( 2 .
.
.h) · ..· .· 0 .
. .
  

.
0 ⋆ 0 0 ··· µ(h)
I
(h) (h)
With W = 0 and U = 0, the ICL loss for MS-Attn is given by
Y X
(cid:13) (cid:13)2
H
L({U(h),W(h)} h∈[H]) = E (cid:13) (cid:13) (cid:13)G⊤q−(cid:88) U Y(h) (G⊤X +ε⊤)p(h)(cid:13) (cid:13) (cid:13) 
(cid:13) (cid:13)
h=1 2
 2
I
= (cid:88) E g i⊤q−µ⋆ i(g i⊤X (i)+ε⊤ i )p⋆ i + (cid:88) µ( ih) (g i⊤X (i)+ε⊤ i )p(h)  
i=1 h̸=h⋆
i
I (cid:18) (cid:113) (cid:19)
≤
(cid:88) L(1)
+2
L(1) ·I2L(2) +I2L(2)
i i i i
i=1
(1) (2)
Here, we have kinds of errors L and L in the above loss and the last inequality is due to the
i i
Cauchy-Schwarz inequality. The first is the error of the optimal head on each task, which is given
by
(cid:20) (cid:21)
(cid:16) (cid:17)2
L(1) :=E g⊤q −µ⋆(g⊤X +ε⊤)p⋆ .
i i (i) i i (i) i i
In this case, we can think as having only one head and with only one nonzero task i. In addition,
we have u = 0 for j ̸= i for this only head. Invoking the second argument in Lemma E.8 with
j
δ = δ = O(δ) (convergence of the optimal heads), ξ = 0 (u = 0), and ξ = O(ω ) (nonoptimal
ω u u j ω 0
head h ̸= h⋆ has ω(h) fixed at initialization), we have that the error for each task is upper bounded
i i
by
λ d (cid:18) ed ϕ L−1 (cid:19)
L(1) ≤ i i · i i +O(δ+ω2d+L−(1−ϵ)/2) ≤ O(1). (E.23)
i d 1+ed ϕ L−1 0
i i
127The second kind of error is the error coming from the “leakage” of the nonoptimal heads, which is
given by
(cid:20) (cid:21)
(cid:16) (cid:17)2
L(2) :=maxL(2,h) , where L(2,h) :=E µ(h) (g⊤X +ε⊤)p(h) .
i h̸=h⋆ i i i i (i) i
i
We can upper bound this error for each h ̸= h⋆ by
i
L(2,h) = (µ(h) )2·(cid:16) λ d−1Tr(E[X p(h)p(h)⊤ X⊤])+σ2E[∥p(h)∥2](cid:17)
i i i (i) (i) 2
(cid:104) (cid:105)
≤ (µ(h) )2·E λ d−1∥W(h) q∥2f (∥W(h) q∥2)+σ2f (∥W(h) q∥2)
i i X 2 2 X 2 1 X 2
(cid:16) (cid:17)
≤ (µ(h) )2· λ d−1·O(1)+σ2·O(L−(1−ϵ)) ,
i i
where in the second inequality we replace the trace on the i-th block to the trace on the whole
(h) (h)⊤
matrixasanupperbound,andinthelastinequality,weusethefactthatTr(W W ) = 1+o(1)
X X
at the convergence point. Combining the above results, we conclude that
I (cid:18) (cid:113) (cid:19)
L({U(h),W(h)} ) ≤ (cid:88) L(1) +2 L(1) ·I2L(2) +I2L(2)
h∈[H] i i i i
i=1
≤
(cid:88)I λ id
i
·(cid:18) ed iϕ iL−1 +O(δ+ω2d+L−(1−ϵ)/2)(cid:19)
d 1+ed ϕ L−1 0
i i
i=1
(cid:113)
+O(I2)· max µ(h) · λ d−1·O(1)+σ2·O(L−(1−ϵ)).
i,h̸=h⋆ i i
i
√
Note that µ(h) = µ⋆exp(−O( dd ϕ L−1)), which is sufficiently small in scale. Hence, we just need
i i i i
to consider the first term, which gives the desired result.
E.2 Lower Bound for Multi-Head Attention
In this section, we aim to prove the following optimality result for multihead attention within the
(h)
class of equiangular weights. We consider MS-Attn with H heads and I tasks. Let ω = {ω }
i h∈[H]
(h)
and µ = {µ } , and the loss is defined as
i h∈[H]
(cid:13) (cid:13)2
H
L(µ,ω) = E (cid:13) (cid:13) (cid:13)G⊤q−(cid:88) U Y(h) (G⊤X +ε)p(h)(cid:13) (cid:13)
(cid:13)
, where p(h) = softmax(cid:16) X⊤W X(h) q(cid:17) .
(cid:13) (cid:13)
h=1 2
Theorem E.10 (Optimality of Multi-Head Attention). Suppose we have H ≥ 2 heads and I tasks
and consider MS-Attn with equiangular weights. Assume that all the tasks are homogeneous, i.e.,
d = d:=d/H and λ = λ for all i ∈ [H]. Consider the regime where
i i
(cid:112)
∥ω(h)∥ ≤ 2logL/3dc2, ∥µ(h)∥ ≤ L3/4−ϵ/2 ∀h ∈ [H],
∞ ∞
where c is a constant satisfying
1 3
+ ≤ ϵ.
(cid:112)
c 1+ 1+c2/2
128The ICL loss for MS-Attn is lower bounded by the maximum of
λ
−O(L−ϵ/2),
ϕ−1d−1L·(H −1)+1
and the Bayesian risk
Bayesian Risk = Variance+Bias, where
(cid:112)
br+(1+r)− (br−1+r)2+4b
Variance = Iσ2· ,
(cid:112)
2 (br−1+r)2+4b
(cid:32) br(1+r)+(1−r)2−|1−r|(cid:112) (br−1+r)2+4br (cid:18) 1(cid:19) (cid:33)
Bias = λ· + 1− 1(r > 1) .
(cid:112)
2 (br−1+r)2+4b r
Proof of Theorem E.10. Under the decomposability assumption, we have the loss function as

L(µ,ω) = E q⊤GG⊤q−2q⊤G (cid:88) U(h) (G⊤X +ε)p(h)
Y
h∈[H]

+ (cid:88) p(h)⊤ (X⊤G+ε⊤)U(h)⊤ U(h′) (G⊤X +ε)p(h′) 
Y Y
h,h′∈[H]
2λ (cid:88) (cid:16) (cid:17)
= λ− Tr (diag(µ(h))⊗ I )E[Xp(h)q⊤]
d K d
h∈[H]
+
λ (cid:88) Tr(cid:16) (diag(µ(h)⊙µ(h′))⊗
I
)E[Xp(h)p(h′)⊤ X⊤](cid:17)
d K d
h,h′∈[H]
+
(cid:88) σ2⟨µ(h),µ(h′)⟩E[p(h)⊤ p(h′)]
h,h′∈[H]
= λ−
2λ (cid:88) E(cid:104) ⟨µ(h),ω(h)⊙v2⟩(1−f(h,h) )(cid:105)
I 3
h∈[H]
+
λ (cid:88) E(cid:104) (cid:10) µ(h)⊙µ(h′),ω(h)⊙ω(h)⊙v2f(h,h′) +ω(h′)⊙ω(h′)⊙v2f(h′,h)(cid:11)(cid:105)
I 1 1
h,h′∈[H]
+
λ (cid:88)
E(cid:20)
(cid:10) µ(h)⊙µ(h′),ω(h)⊙ω(h′)⊙v2f(h,h′)(cid:11)
+(cid:18)
1+
σ2I(cid:19) ⟨µ(h),µ(h′)⟩f(h,h′)(cid:21)
I 2 λ 3
h,h′∈[H]
where ⊗ denotes the Kronecker product, and ⊙ denotes the element-wise product. Here, we
K
denote by v2 a d-dimensional random vector where each entry is drawn i.i.d.from the chi-square
distribution with degree 1. We use the following definition for the last equality,
(cid:104) (cid:105)
f(h,h′) :=E (p(h′))⊤(p(h))⊙2−(p(h′))⊤p(h)∥p(h)∥2|q
1 2
f(h,h′) :=E(cid:104) (1−∥p(h′)∥2)(1−∥p(h)∥2)+(p(h))⊤p(h′)−(p(h′))⊤(p(h))⊙2−(p(h′))⊤(p(h))⊙2+(p(h)⊤ p(h′))2|q(cid:105)
2 2 2
(cid:104) (cid:105)
f(h,h′) :=E (p(h))⊤p(h′) ,
3
129wheretherelationshipbetweenthesetermstoE[Xp]andE[Xp(h)p(h′)⊤ X⊤]isgivenbyLemmaC.8.
(h,h′)
As a matter of fact, both f and f are functions of q. Note that f is actually a higher order
1 2 1
(cid:112)
term, and according to our regime where ∥ω(h)∥ ≤ 2logL/3dc2, we have all the conditions in
∞
Lemma B.4 and Lemma B.3 satisfied and thus
(cid:113)
|E[v2·f(h,h′) ]| ≤ E[v4]·E[(f(h,h′) )2] = O(L−2(1−ϵ)),
i 1 i 1
(cid:113)
|E[v2·f(h,h′) ]−1| ≤ E[v4]·E[(f(h,h′) −1)2] = O(L−1),
i 2 i 2
(cid:118)
(cid:12) (cid:12) (cid:12)E[f(h,h′) ]− exp(d⟨ω(h),ω(h′)⟩)(cid:12) (cid:12) (cid:12) ≤ (cid:117) (cid:117) (cid:116)E(cid:34) (cid:18) f(h,h′) − exp(d⟨ω(h),ω(h′)⟩)(cid:19)2(cid:35) = O(L−(3−ϵ)/2).
(cid:12) 3 L (cid:12) 3 L
(cid:12) (cid:12)
Note that it is hard to optimize for µ for each individual head. However, we note that by the
Decomposability Condition, we can instead optimize for each task separately. In particular, the
individual loss of task i is given by
L (µ,ω):=1−2µ⊤ω +µ⊤(ω ω⊤+B)µ .
i i i i i i i
The B ∈ RH×H matrix in the above equation is given element-wise by
(B ) :=ϕ L−1exp(d⟨ω(h),ω(h′)⟩).
i hh′ i
(h) (h)
Here, we denote by µ = (µ ) and ω = (ω ) the eigenvalues of the attention weights
i i h∈[H] i i h∈[H]
for task i. Here, we drop the energy term λ/I in the definition. Note that we also ignore the higher
order terms by suffering from an error of O(L−ϵ/2) given the scale of µ and ω. As a result, the
relationship between L and L is given by
i
I
λ (cid:88)
L(µ,ω) = L (µ,ω)+O(L−ϵ/2).
i
I
i=1
Lower Bound for the ICL Loss. We define an operator R that applies the following element-
wise transformation to a matrix A:
(R◦A) = ϕ L−1exp(dA ).
mn i mn
Let M = (ω(1),...,ω(H)) ∈ RI×H. To this end, we can rewrite B as
B = R◦(M⊤M).
Solving for this quadratic problem, we obtain
µ⋆ = (ω ω⊤+B)−1ω , (E.24)
i i i i
and the corresponding loss
L (ω):=1−ω⊤(ω ω⊤+B)−1ω .
i i i i i
130Note that although we restrict ∥µ(h)∥ ≤ L3/4−ϵ/2, the optimal µ⋆ in (E.24) can be much larger
∞ i
than L3/4−ϵ/2, which may lead to a looser lower bound. However, as we will show later, this
only leads to an additional constant multiplicative factor in the lower bound. By property of the
equiangular weights, M⊤M has the same value for the diagonal elements, which we denote by a,
andalsothesamevalueforoff-diagonalelements, whichwedenotebyb. ThesamealsoholdsforB,
and we denote the value for the diagonal elements by ra and the value for the off-diagonal elements
r
by b. The quadratic term can be simplified as
A :=ω
ω⊤+(ra−r
b)I
+r
bE.
i i i
We note that
(cid:18) 1 1⊤ω (cid:19)
Υ = √H , ω − H i ·1 , ...
i i H
H H
√ √
forms an orthogonal basis. Let q = 1⊤ω / H be the inner product of 1 / H and ω and
√ i H i H i
ωr = ω − q · 1 / H be the orthogonal projection of ω onto the orthogonal complement of
i √ i i H i
1 / H. We thus have
H
 q2+ra+(H −1)r b q ∥ωr ∥ 0 
i i i 2
Υ⊤A Υ =  q ∥ωr ∥ ∥ωr ∥2+ra−r b 0 .
i i i  i i 2 i 2 
0 0
(ra−r
b)I
H−2
The inverse of the above matrix is given by
 ∥ωr i∥2 2+ar−r b −qi∥ωr i∥2
0

∆ ∆
(Υ i⊤A iΥ i)−1 =   −qi∥ ∆ωr i∥2 q i2+ar+ ∆(H−1)r b 0   .
0 0
IH−1
ar−r
b
where
∆ = (q2+ra+(H −1)r b)(∥ωr ∥2+ra−r b)−q2∥ωr ∥2
i i 2 i i 2
= (ra+(H −1)r b)∥ωr ∥2+q2(ra−r b)+(ra+(H −1)r b)(ra−r b)
i 2 i
is the determinant of top left 2×2 submatrix of Υ⊤A Υ . Therefore,
i i i
ω⊤A−1ω = (Υ⊤ω )⊤(Υ⊤A Υ )−1(Υ⊤ω )
i i i i i i i i i i
 ∥ωr i∥2 2+ar−r b −qi∥ωr i∥2 0   q 
∆ ∆ i
= (cid:2) q i ∥ωr i∥ 2 0(cid:3) · −qi∥ωr i∥2 q i2+ar+(H−1)r b 0  ·∥ωr i∥ 2
 ∆ ∆ 
0 0
IH−1 0
ar−r
b
q2(∥ωr ∥2+ra−r b)+∥ωr ∥2(q2+ra+(H −1)r b)−2q2∥ωr ∥2
= i i 2 i 2 i i i 2
∆
(ra−r b)(ra+(H −1)r b)
= 1− .
∆
131As a result, we have
I
1 (cid:88)
L (ω)
i
I
i=1
1 (cid:88)I (ra−r b)(ra+(H −1)r b)
=
I (ra+(H −1)r b)∥ωr ∥2+q2(ra−r b)+(ra+(H −1)r b)(ra−r b)
i=1 i 2 i
(ra−r b)(ra+(H −1)r b)
≥ (E.25)
(ra+(H −1)r b)· 1 (cid:80)I ∥ωr ∥2+ 1 (cid:80)I q2(ra−r b)+(ra+(H −1)r b)(ra−r b)
I i=1 i 2 I i=1 i
(ra−r b)(ra+(H −1)r b)
= ,
(ra+(H −1)r b)·I−1(H −1)(a−b)+I−1(a+(H −1)b)(ra−r b)+(ra+(H −1)r b)(ra−r b)
where in the inequality we use the Jensen’s inequality for the convex function x (cid:55)→ 1/(1+x). In
the last equality, we note that
I I I √
(cid:88) (cid:88) (cid:88)
∥ω ∥2 = Tr(M⊤M) = Ha, q2 = ∥1⊤ω / H∥2 = H−1Tr(EM⊤M) = a+(H −1)b.
i 2 i H i 2
i=1 i=1 i=1
As a result, I−1(cid:80)I ∥ωr ∥2 = I−1(cid:80)I ∥ω ∥2−I−1(cid:80)I q2 = I−1(H−1)(a−b) and I−1(cid:80)I q2 =
i=1 i 2 i=1 i 2 i=1 i i=1 i
I−1(a+(H −1)b). By a direction calculation, we also have
I
1 (cid:88) 1
L (ω) ≥
i
I (H−1)(a−b) + a+(H−1)b +1
i=1 I(ar−r b) I(ar+(H−1)r b)
1
= .
r b−1· (H−1)(a−b) +r b−1· a+(H−1)b +1
I(ar/r
b−1)
I(ar/r
b+(H−1))
Now, we plug in the definition ra = ϕL−1exp(da) andr b = ϕL−1exp(db), and we have
I
1 (cid:88) 1
L (ω) ≥ .
i (cid:16) (cid:17)
I I−1ϕ−1Lexp(−db)· (H−1)(a−b) + a+(H−1)b +1
i=1
exp(d(a−b))−1 exp(d(a−b))+H−1
To this end, we define x = d(a−b) and y = db. Our target is thus to optimize:
(cid:18) (cid:19)
(H −1)x x+Hy
maxg(x,y):=exp(−y)· + .
x,y exp(x)−1 exp(x)+H −1
However, there are constraints we need to consider, given the nonnegativity of the energy:
I
(cid:88)
∥ωr ∥2 = (H −1)(a−b) ≥ 0 ⇒ x ≥ 0.
i 2
i=1
I
(cid:88)
q2 = a+(H −1)b ≥ 0 ⇒ x+Hy ≥ 0.
i
i=1
132We first optimize y given x. The partial derivative of g(x,y) with respect to y is given by
∂g(x,y)
= C(x,y)·(1+(H −2)x−yex(x+y−1)),
∂y
where C : R×R (cid:55)→ R is a positive function. Let
+
ex(x−1)+1+(H −2)x
y = − .
0 ex−1
Note that the above function increases when y ≤ y and decreases when y ≥ y . Our constraint
0 0
also requires that y ≥ −x/H. We just need to decide which one is larger between −x/H and y .
0
Suppose y > −x/H. With a little bit of algebra, we have this condition equivalent to
0
(cid:18) (cid:19)
H H
> 1+ x
H −1 ex−1
given the nonnegativity of x. Note that the left hand side decreases to 1 as H increases, and the
right hand side increases. Thus, we just need to check the case when H = 2, and we consider
another function
2x
g (x) = x+ −2.
1 ex−1
Notably, this function is increasing as x ≥ 0, and the minimal value is achieved at x = 0 which
gives g (0) = 0. Thus, we have y > −x/H impossible for H ≥ 2. As a result, we conclude that
1 0
the optimal y should always be y⋆(x):=−x. The remaining is just a simple plug in, which gives
H
(cid:16) x (cid:17) (H −1)x
g(x,y⋆) = exp · ,
H exp(x)−1
where the optimal x is given by finding the maximum of the above function when x ≥ 0. Let the
optimal x be x⋆. Clearly 0 < x⋆ ≤ 1 as for x = 0, exp(x/H)x has a faster growing rate than exp(x)
in a sufficiently small region. For the other side, it is not hard to see that function decreases for
x ≥ 1. We have the loss lower bounded by
I
λ (cid:88)
L(µ,ω) ≥ L (µ,ω)−O(L−ϵ/2)
i
I
i=1
λ
≥ −O(L−ϵ/2)
I−1ϕ−1d−1
L·max
exp(x/H)(H−1)x
+1
x≥0 exp(x)−1
λ
= −O(L−ϵ/2). (E.26)
ϕ−1d−1L·max exp(x/H)(H−1)x +1
x≥0 exp(x)−1
Note that the loss in (E.26) cannot be better than the loss achieved by the Bayesian posterior mean
estimator. Let b = σ2/λ. The Bayesian risk in our case is just the MMSE. Asymptotically, i.e.,
d → ∞ and L → ∞ with d/L → r, the MMSE is given by
Bayesian Risk = Variance+Bias, where
(cid:112)
br+(1+r)− (br−1+r)2+4br
Variance = Iσ2· ,
(cid:112)
2 (br−1+r)2+4br
(cid:32) br(1+r)+(1−r)2−|1−r|(cid:112) (br−1+r)2+4br (cid:18) 1(cid:19) (cid:33)
Bias = λ· + 1− 1(r > 1) .
(cid:112)
2 (br−1+r)2+4br r
(E.27, MMSE & Ridge)
133where r = d/L = d/(IL). Here, characterizing the asymptotical behavior of the MMSE is just a
matter of calculating the following variance and bias term in the limit d/L → r:
I (cid:20) (cid:18) (cid:19)(cid:21)
(cid:88) (cid:16) (cid:17)−1 (cid:16) (cid:17)−1
Variance:= σ2E Tr X X⊤ +bdI X X⊤ X X⊤ +bdI ,
(i) (i) d (i) (i) (i) (i) d
i=1
(cid:88)I
λ
(cid:34) (cid:32) (cid:18)
(cid:16) (cid:17)−1
(cid:19)(cid:18)
(cid:16) (cid:17)−1
(cid:19)⊤(cid:33)(cid:35)
Bias:= ·E Tr X X⊤ +bdI X −I X X⊤ +bdI X −I .
d (i) (i) d (i) d (i) (i) d (i) d
i=1
Let ν be the Marchenko-Pastur distribution (Marchenko and Pastur, 1967) for the eigenvalues
of X X⊤/L, which is the same for different i since we assume the homogeneity of the tasks.
(i) (i)
Therefore, we have
(cid:20) Ls (cid:21) (cid:20) (bd)2 (cid:21)
Variance = σ2d·E ,Bias = λ·E ,
s∼ν (Ls+bd)2 s∼ν (Ls+bd)2
whichgivestheresultin(E.27, MMSE & Ridge). Inparticular,ifr → 0,i.e.,largesequencelength,
the MMSE is approximately given by This completes the proof.
Discussion of the ICL Loss Lower Bound. Note that throughout the proof of the lower
bound, the first inequality we are using is (E.25), where equality holds if
∥ωr ∥2 = ∥ωr ∥2 for all i,j ∈ [I] and q2 = q2 for all i,j ∈ [I],
i 2 j 2 i j
and the second optimality condition is y⋆ = −x⋆/H with x⋆ solved by argmax exp(x/H)(H−1)x .
x≥0 exp(x)−1
Note that x+Hy = 0 ⇒ a+(H −1)b = 0 ⇒ (cid:80)I q2 = 0, which means that the projection of ω
√ i=1 i i
onto 1 / H is zero for all i ∈ [I]. Therefore, we just need to ensure ∥ω ∥2 = ∥ω ∥2 for all i,j ∈ [I].
H i 2 j 2
Consider matrix M = (ω(1),...,ω(H)) ∈ RI×H. Our condition is just saying that
(i) the row sum of M is 0.
(ii) the row norm of M is the same for all rows.
(iii) the columns of M form an equiangular system.
(iv) Tr(M⊤M) = (H −1)x⋆.
However, observant readers might have noticed that the optimal x⋆ is always 0 for H ≥ 2. This is
not realistic as Tr(M⊤M) = 0 just means W = 0, which is not learning anything. We remark that
this issue is due to our approximation of the loss function’s landscape and allowing violation of the
∥µ(h)∥ ≤ L3/4−ϵ/2 condition in (E.24). However, we remark that (E.26) still gives us a correct
∞
lower bound on the ICL rate, where the difference between letting x → 0 and x = Θ(1) is just a
loss of a constant multiplicative factor as we can clearly see from (E.26). Although condition (iv)
is not realistic, the remaining conditions are indeed realistic and achievable by the gradient flow of
the MS-Attn as we will show in the experiment.
134E.3 Comparison
In the following discussion, we neglect some error terms for simplicity and only consider the regime
where L/d beats the SNR, i.e., r = d/L = o(λ/σ2). Note that when we are having a single head to
solve the multitask problem, the optimal rate given by Theorem E.1 is
λ d
≈ e(λ+σ2I)· , (E.28, OptS-ICL)
e−1ϕ−1d−1L+1 L
while the lower bound in (E.26) is given by
λ d
≈ (H −1)−1·(λ+σ2I)· . (E.29, LB-ICL)
ϕ−1d−1L·(H −1)+1 L
The ICL loss achieved by the convergence point of the gradient flow of the MS-Attn with H ≥ I
characterized by Lemma 4.1,
λ d
≈ eI−1·(λ+σ2I)· . (E.30, GF-ICL)
Ie−1ϕ−1d−1L+1 L
Moreover, the Bayesian risk is given by (E.27, MMSE & Ridge), which for r = d/L ≤ 1 is approx-
imately given by the variance term
Iσ2r Iσ2 d
= ≈ σ2· . (MMSE)
1+(b−1)r I ·d−1L+σ2/λ−1 L
In addition, when using a ridge regression with regularization parameter bd for each task, i.e.,
(cid:13) (cid:13)2
gp = argmin(cid:13)Y −g⊤X (cid:13) +bd·∥g∥2,
i (cid:13) i (i)(cid:13) 2
g∈Rd 2
andusetheminimizerastheestimatorforthequery,westillhavetherategivenby(E.27, MMSE & Ridge)
(b functions as the regularization parameter). Notably, as the number of tasks I increases, the ICL
loss achieved by the gradient flow of the MS-Attn is getting closer to the MMSE but only with a
constant multiplicative factor gap. There is clear gap between the single head and the multihead
ICL loss.
Figure 7: Comparison of loss functions
135F Generalization
Inthissection, weprovidegeneralizationresultsbothtoanewsequencelengthandnonlineartasks.
Before we proceed, we first introduce the basic definition of multivariate Hermite polynomials and
some additional notations.
F.1 Length Generalization
We first consider generalization of the optimal single-head softmax attention to a new sequence
r
length L.
Proof of Proposition 5.1. The proof is a combination of Lemma E.8 and the proof of Lemma E.9.
r
Note that for a new sequence length L, the optimal W remains unchanged. Also, we can equiv-
X
r
alently view U as a perturbation of the optimal U under L. Let ω⋆ and µ⋆ be the optimal
Y Y i i
(h⋆) (h⋆) r
(nonzero) eigenvalues for W i and U i at task i’s position under the new sequence length L.
X Y
(h) (h)
Let ω and ω be the eigenvalues at the convergence point of the gradient flow trained under
i i
the original sequence length L. In particular,
√ (cid:12) (h⋆) (cid:12) (cid:12) (h⋆) (cid:12)
d (cid:12)ω i (cid:12) (cid:12) µ i (cid:12)
ω⋆ = d−1/2 , µ⋆ = i , (cid:12) i −1(cid:12) ≤ O(δ), (cid:12)√ i −1(cid:12) ≤ O(δ).
i i i 1+eϕ id i/Lr √(cid:12) (cid:12)d−
i
1/2 (cid:12) (cid:12) (cid:12) (cid:12) d i/(1+eϕ id iL−1) (cid:12) (cid:12)
d √
ω(h) = O(ω ), µ(h) = i ·exp(−O( dd ϕ L−1)), ∀h ∈ [H]\{h⋆}.
i 0 i 1+eϕ d L−1 i i i
i i
Therefore, we have for the convergence point of the gradient flow,
(cid:12) (cid:12) (cid:12)ω i(h⋆ i) −1(cid:12) (cid:12)
(cid:12) ≤ O(δ),
(cid:12) (cid:12) (cid:12)µ( ih⋆ i) −1(cid:12) (cid:12)
(cid:12) ≤ O(δ)·
1+eϕ id iL−1
+eϕ d
|L−1−Lr−1|.
(cid:12) (cid:12) ω i⋆ (cid:12) (cid:12) (cid:12) (cid:12) µ⋆ i (cid:12) (cid:12) 1+eϕ id iLr −1 i i
(h⋆)
We observe that the only difference from the previous proof is the last error in µ i . Therefore,
i
the only difference is in the first kind of error concerning the optimal head previously described by
(E.23). In this case, we have following Lemma E.8 to get (E.23) replaced by
(cid:32) r (cid:33)
L(1) ≤ λ id i · ed iϕ iL−1 +O(δ+ω2d+L−(1−ϵ)/2)+O(eϕ d |L−1−Lr−1|)2 ≤ O(1).
i d 1+ed ϕ Lr −1 0 i i
i i
Therefore, we have the result in Lemma E.9 replaced by
L ≤
(cid:88)I λ id
i
·(cid:18) ed iϕ iL−1
+O(L−(1−ϵ)/2+ω2d+δ)+O(ϕ d
|L−1−Lr−1|)2(cid:19)
.
Conv d 1+ed ϕ L−1 0 i i
i i
i=1
Hence, we have the result in Proposition 5.1.
F.2 Generalization to Nonlinear Task
In this section, we provide proof for the nonlinear generalization of the optimal single-head softmax
attention for a single task.
136Proof of Lemma 5.2. Since at the convergence point of the gradient flow, each optimal head is
handling a unique task as the optimal single-head softmax attention, the generalization for the
multi-headcaseisconsequentlyimpliedbythesingle-headcase. Tothisend,weconsideranonlinear
task y = f(x), where f is a nonlinear function. Suppose f has degree at most D in the sense that
f is a linear combination of d-dimensional multivariate Hermite polynomials {He |α ∈ Nd, |α| =
α
(cid:80)d
α ≤ D} as
i=1 i
f(x) = (cid:88) fp He (x), where fp ∈ R.
α α α
|α|≤D
We consider only the bias for the softmax attention and it suffices to only consider
(cid:34) L (cid:35)
(cid:88) (cid:12)
E f(x )p (cid:12)q , where p = softmax(s), s = x⊤W q.
l l(cid:12) l l X
l=1
We consider each term in the decomposition of f(x) separately. For degree α, we have
E(cid:34) (cid:88)L
He α(x l)p
l(s)(cid:12)
(cid:12)
(cid:12)q(cid:35)
=
(cid:88)L E(cid:34)
(−1)|α|e∥x l∥2 2/2
∂∂ x|α α|
e−∥x l∥2 2/2·p
l(s)(cid:35)
l=1 l=1
= (cid:88)L (cid:90) (−1)|α| ∂∂ x|α α| e− √∥x l∥2 2 d/2 ·p l(s)dx
l
l=1 x l l 2π
=
(cid:88)L E(cid:34) ∂|α|
p
(s)(cid:12) (cid:12)q(cid:35)
=
(cid:89)d
(ωq )αi
·(cid:88)L E(cid:34) ∂|α|p l(s) (cid:12) (cid:12)q(cid:35)
∂xα l (cid:12) i |α| (cid:12)
l=1 l i=1 l=1 ∂s l
where the last equality is by integrate by parts. The derivative of the softmax probability with
respecttotheattentionscorewillyieldapolynomialofpaswellsince∂p /∂s = p (1−p ). Notethat
l l l l
sincetheoptimalattentionworksinthelinearoperatingregionandwehavelowdegree|α| ≤ D, we
can safely apply the low-effective-order (Definition C.9) approximation since the coefficient before
each term is constant and we have at most D terms ∂|α|p /∂s|α| . Note that p has effective order
l l l
0, p −p2 also has lowest effective order 0 and low effective order approximation p −p2= p . As
l l l l ⩽0 l
a matter of fact, by Lemma C.12 and (C.21) in Lemma C.13, we can always ensures that
∂|α|
p = p .
∂s|α| l ⩽0 l
l
We have by the tail bound of chi-square distribution (by (B.5)) that for any δ ∈ (0,1),
(cid:16) (cid:112) (cid:17)
P ∥W q∥2 ≥ ∥W ∥2 +2∥W ∥2 logδ−1+2∥W ∥2 logδ−1 ≤ δ. (F.1)
X 2 X F X F X op
Since W = d−1/2I , to ensure ∥W q∥2 ≤ c−2·2logL for some constant c such that
X d X 2
1 3
+ = ϵ
(cid:112)
c 1+ 1+c2/2
holds for some small constant ϵ, we just need to set
δ =
exp(cid:0) −(c−2logL−1)2(cid:1)
∨exp(−d/2).
137Notably,wehavealltermswithhighereffectiveorderupperboundedbytheonlytermwitheffective
order 1, i.e., ∥p∥2, since p ≤ 1 for all l ∈ [L]. Thus, by Lemma B.2, we have with probability at
2 l
least 1−δ that the terms effective order higher than 0 in p (e.g., E[∥p∥2|q],E[∥p∥3|q]) is upper
2 3
bounded by O(L−2(1−ϵ)) given that D is constant. Thus, conditioned on the success of the event
in (F.1), we have
(cid:88)L E(cid:34) ∂|α|p l(s) (cid:12) (cid:12)q(cid:35)
= E[∥p∥ |q]±O(L−2(1−ϵ)) = 1±O(L−2(1−ϵ)).
|α| (cid:12) 1
∂s
l=1 l
Thus, we conclude that
(cid:32) (cid:12) (cid:34) L (cid:35) d (cid:12) (cid:33)
(cid:12) (cid:88) (cid:12) (cid:89) (cid:12)
P ∀|α| ≤ D, (cid:12)E He (x )p (s)(cid:12)q − (ωq )αi(cid:12) ≥ O(L−2(1−ϵ))
(cid:12) α l l (cid:12) i (cid:12)
(cid:12) (cid:12)
l=1 i=1
≤
exp(cid:0) −(c−2logL−1)2(cid:1)
∨exp(−d/2).
Therefore,
(cid:12) (cid:12) 
P
(cid:12)
(cid:12) (cid:12) (cid:12)E[µYp|q]−µ· (cid:88) fp
αω|α|·qα(cid:12)
(cid:12) (cid:12)
(cid:12)
≥ O(L−2(1−ϵ)) ≤
exp(cid:32) −(cid:18)
lo cg 2L
−1(cid:19)2
∧ d
2(cid:33)
,
(cid:12) α:|α|≤D (cid:12)
where we define qα = (cid:81)d qαi. Thus, we conclude the result in Lemma 5.2.
i=1 i
138G Auxiliary Results
We collect the proofs of the auxiliary results used before.
G.1 Proof of Auxiliary Results in §C.1
G.1.1 Proof of Lemma C.2
Proof. We give a proof for the first equality in Lemma C.2 and the remaining two can be calculated
usingasimilarargument. TheproofisbasedontheStein’sLemma,whichstatesthatforaGaussian
random variable x ∼ N(0,I ) and a differentiable function g: Rd → R with E[∥∇g(x)∥ ] finite, we
d 2
have
E[x·g(x)] = E[∇g(X)].
We apply the Stein’s Lemma to the function f recursively for three times. Note that f is a
lmn lmn
function of the attention scores s and sr, and thus is a function of the covariate sequence {x }
l l l l∈[L]
in the ICL. By chain rule, we have
E[f ·x ⊗x ⊗x ] = E[∇ ⊗(f ·x ⊗x )]
lmn l m n x l lmn m n
(cid:104) (cid:105)
= E ∇ f ⊗x ⊗x +δ f ·I ⊗x +δ f ·(I ⊗x )⊤(132) .
x l lmn m n lm lmn d n ln lmn d m
Here the first equality is due to the Stein’s lemma, and the second equality is due to the chain
rule, where we use the fact that ∇ (x ) = δ I . Moreover, applying the Stein’s Lemma again,
x l m lm d
we have
E[∇ f ⊗x ⊗x ] = E[(∇ ⊗∇ )f ⊗x +δ ∇ f ⊗I ]
x l lmn m n x l xm lmn n mn x l lmn d
= E[(∇ ⊗∇ ⊗∇ )f +δ ∇ f ⊗I ],
x l xm xn lmn mn x l lmn d
E[δ f ·I ⊗x ] = E[δ ·I ⊗∇ f ],
lm lmn d n lm d xn lmn
(cid:104) (cid:105) (cid:104) (cid:105)
E δ f ·(I ⊗x )⊤(132) = E δ f ·(I ⊗∇ f )⊤(132) ,
ln lmn d m ln lmn d xm lmn
where we apply the Stein’s Lemma twice in the first equation. Therefore, we have
E[f ·x ⊗x ⊗x ] = E[(∇ ⊗∇ ⊗∇ )f +δ ∇ f ⊗I ]
lmn l m n x l xm xn lmn mn x l lmn d
(cid:104) (cid:105)
+E δ ·I ⊗∇ f +δ f ·(I ⊗∇ f )⊤(132) .
lm d xn lmn ln lmn d xm lmn
Notice that x only appears in the attention scores s and sr. This is because s = x⊤W q and
l l l l l X
sr = x⊤WĂ q. As a result, we can write ∇ = (W q∂ +WĂ q∂r ). Plugging in the definition of T
l l X x l X l X l l
in (C.11), we obtain that ∇ f = T ◦f , i.e., we can replace ∇ by the operator T in the
x l lmn l lmn x l l
above equation. Finally, taking the summation over l,m,n ∈ [H], we obtain the desired result.
For the second equality, consider the second-order tensor {f } . By applying the Stein’s
lm l,m∈[L]
Lemma twice, we have
E[f ·x ⊗x ] = E[∇ f ⊗x +δ f ·I ] = E[(∇ ⊗∇ )f +δ f ·I ].
lm l m x l lm m lm lm d x l xm lm lm lm d
Then replacing ∇ by T and taking the summation over l,m ∈ [H], we obtain the desired result.
x l l
Finally, the last equality can be proved by directly applying the Stein’s Lemma to the function
f , i.e.,
l
E[f ·x ] = E[∇ f ].
l l x l l
Therefore, we conclude the proof.
139G.1.2 Proof of Lemma C.4
Proof. We define ν = diag(ω)q and νr = diag(ωr)q. Note that the joint distribution of (s,sr)|q can
be factorized as a tensor product of the distribution of each individual (s ,sr )|q since {x } are
1 1 l l∈[L]
independently sampled. It suffices to show that the distribution of (s ,sr )|q is fully determined by
1 1
∥ν∥ , ∥νr∥ and ⟨ν,νr⟩. For fixed ∥ν∥ , ∥νr∥ and ⟨ν,νr⟩, there exist constants c and c that depend
2 2 2 2 1 2
on ∥ν∥ , ∥νr∥ and ⟨ν,νr⟩ such that we can rewrite νr as νr= c ν +c ν , where ν = ν/∥ν∥ and ν
2 2 1 // 2 ⊥ // 2 ⊥
is orthogonal to ν . By definition, we have
//
s = x⊤diag(ω)q = ⟨x ,ν⟩ = ∥ν∥ ·⟨x ,ν ⟩,
1 1 1 2 1 //
sr = x⊤diag(ωr)q = ⟨x ,νr⟩ = c ·⟨x ,ν ⟩+c ·⟨x ,ν ⟩,
1 1 1 1 1 // 2 1 ⊥
where x = Φ⊤x is the rotated covariate of the first context token, whose distribution is also
1 1
rotationally invariant. Therefore, the joint distribution of ⟨x ,ν ⟩ and ⟨x ,ν ⟩ does not depend on
1 // 1 ⊥
the specific choice of ν and ν . Thus, the joint distribution of (s ,sr )|q is fully determined by
// ⊥ 1 1
(∥ν∥ ,c ,c ), and thus by (∥ν∥ ,∥νr∥ ,⟨ν,νr⟩). Thus, we conclude the proof.
2 1 2 2 2
G.2 Proof of Auxiliary Results in §C.2
G.2.1 Proof of Lemma C.13
Proof. For the last term in (C.20), if W(R(u)) ≥ 1, then adding 1 to a will not change CC (G)
u ≥1
and only increase the effective order by 1. If W(R(u)) = 0, then adding 1 to a will also include
u
R(u) in CC (G) and increase the cardinality of CC (G) by 1, which offsets the effect of the
≥1 ≥1
increase in a . Therefore, the conditions for keeping effective order k is W(R(u)) = 0 for the last
u
term.
We next consider the first |V| terms in the summation, where each term only adds a new edge
(u,s) for some s ∈ V to the graph G. The requirement a ≥ 1 is obvious, which also suggests
s
that R(s) ∈ CC (G). To this end, it suffices to see under what conditions will adding an edge
≥1
(u,s) to the graph G not affect |CC (G)|. If s ∈ R(u), then adding an edge (u,s) within the same
≥1
connected component will not change anything. If s ∈/ R(u), consider two cases: (i) W(R(u)) = 0
and (ii) W(R(u)) ≥ 1. If W(R(u)) = 0, then R(u) ∈/ CC (G) and adding an edge (u,s) only
≥1
replaces R(s) with R(s)∪R(u) in CC (G), which does not change the cardinality of CC (G).
≥1 ≥1
If W(R(u)) ≥ 1, then R(u) ∈ CC (G) and adding an edge (u,s) will merge R(u) and R(s) into
≥1
a single connected component, which decreases the cardinality of CC (G) by 1. Therefore, the
≥1
conditions for keeping effective order k is s ∈ R(u)∨W(R(u)) = 0.
G.2.2 Proof of Lemma C.15
Proof. We denote by f the terms p⊤pr and f the terms of higher effective order. Let f =
=1 >1
f +f . We denote by f∗ = L−1 ·exp(cid:0)(cid:10) ω,ωr(cid:11)(cid:1) as the approximation of f. Invoking (C.22) and
=1 >1
(C.23), we have
(cid:112)E[(f −f∗)2] (cid:112) 2E[(f )2]+2E[(f −f∗)2]
≤ >1 =1 ≤ O(L−(1−ϵ0)/2).
f∗
L−1·exp(cid:0)(cid:10) ω,ωr(cid:11)(cid:1)
140For the first case, we denote by g = ⟨v,q⊙2⟩·q2 and g∗ = E[g] = ⟨v⟩+2v . For the second case, we
i i
denote by g = q2 and g∗ = E[g] = 1. We use the following error decomposition
i
(cid:12) (cid:12)E[fg] (cid:12)
(cid:12)
|E[(f −f∗)(g−g∗)]|+|E[(f −f∗)g∗]|+|f∗E[(g−g∗)]|
(cid:12) −1(cid:12) ≤
(cid:12) f∗g∗ (cid:12) |f∗g∗|
(cid:112)E[(f −f∗)2]·E[(g−g∗)2] (cid:112)E[(f −f∗)2]
≤ +
|f∗g∗| |f∗|
(cid:32) (cid:112)E[(g−g∗)2](cid:33)
≤ 2+ ·O(L−(1−ϵ0)/2).
|g∗|
whereinthesecondinequality,weusetheCauchy-SchwarzinequalityandthefactthatE[(g−g∗)] =
0. It suffices to verify that
(cid:112)E[(g−g∗)2]/|g∗|
= O(1) for both cases. For the first case, we have
the following calculation:
E[(g−g∗)2] = Var[g] = Var[⟨v ,q⊙2⟩q2+v q4] ≤ 2Var[⟨v ,q⊙2⟩q2]+2Var[v q4]
−i −i i i i −i −i i i i
= 2(cid:0)E[⟨v ,q⊙2⟩2]·E[q4]−E[⟨v ,q⊙2⟩]2·E[q2]2(cid:1) +2Var[v q4]
−i −i i −i −i i i i
(cid:16) (cid:17)
= 2 3v⊤(11⊤+2I )v −⟨v ⟩2 +192v2 = 4⟨v ⟩2+12⟨v⊙2⟩+192v2.
−i d−1 −i −i i −i −i i
Therefore,
(cid:113) √
(cid:112)E[(g−g∗)2] 4⟨v −i⟩2+12⟨v −⊙ i2⟩+192v i2
4⟨v −i⟩+ 192v
i
≤ ≤ ≤ O(1),
|g∗| |⟨v⟩+2v | ⟨v⟩+2v
i i
where we use the fact that ⟨v⊙2⟩ ≤ ⟨v ⟩2 and |⟨v ⟩| ≤ |⟨v⟩| if v ∈ Rd or v ∈ Rd. For the second
−i −i −i + √−
case, we have E[(g−g∗)2] = Var[g] = Var[q2] = 2 and hence (cid:112)E[(g−g∗)2]/g∗ = 2 = O(1). Next,
i
we consider only having terms with higher effective order. Using the same definition for g and g∗,
it holds that
(cid:12) (cid:12)E[f >1g](cid:12) (cid:12) (cid:12) (cid:12)E[f >1(g−g∗)]+E[f >1g∗](cid:12) (cid:12) (cid:112)E[(f >1)2]·E[(g−g∗)2]+g∗E[f >1]
(cid:12) (cid:12) ≤ (cid:12) (cid:12) ≤
(cid:12) g∗ (cid:12) (cid:12) g∗ (cid:12) |g∗|
(cid:32) (cid:112)E[(g−g∗)2](cid:33)
(cid:112)
≤ 1+ · E[(f )2] = O(L−2(1−ϵ)),
|g∗| >1
where in the last inequality, we have already proved that
(cid:112)E[(g−g∗)2]/g∗
= O(1) for both cases.
We also invoke (C.23) to conclude that
(cid:112)E[(f
)2] = O(L−2(1−ϵ)).
>1
141