[
    {
        "title": "A Novel Context driven Critical Integrative Levels (CIL) Approach: Advancing Human-Centric and Integrative Lighting Asset Management in Public Libraries with Practical Thresholds",
        "authors": "Jing LinNina MyllyPer Olof HedekvistJingchun Shen",
        "links": "http://arxiv.org/abs/2404.17554v1",
        "entry_id": "http://arxiv.org/abs/2404.17554v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17554v1",
        "summary": "This paper proposes the context driven Critical Integrative Levels (CIL), a\nnovel approach to lighting asset management in public libraries that aligns\nwith the transformative vision of human-centric and integrative lighting. This\napproach encompasses not only the visual aspects of lighting performance but\nalso prioritizes the physiological and psychological well-being of library\nusers. Incorporating a newly defined metric, Mean Time of Exposure (MTOE), the\napproach quantifies user-light interaction, enabling tailored lighting\nstrategies that respond to diverse activities and needs in library spaces. Case\nstudies demonstrate how the CIL matrix can be practically applied, offering\nsignificant improvements over conventional methods by focusing on optimized\nuser experiences from both visual impacts and non-visual effects.",
        "updated": "2024-04-26 17:33:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17554v1"
    },
    {
        "title": "\"ChatGPT Is Here to Help, Not to Replace Anybody\" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses",
        "authors": "Bruno Pereira CiprianoPedro Alves",
        "links": "http://arxiv.org/abs/2404.17443v1",
        "entry_id": "http://arxiv.org/abs/2404.17443v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17443v1",
        "summary": "Large Language Models (LLMs) like GPT and Bard are capable of producing code\nbased on textual descriptions, with remarkable efficacy. Such technology will\nhave profound implications for computing education, raising concerns about\ncheating, excessive dependence, and a decline in computational thinking skills,\namong others. There has been extensive research on how teachers should handle\nthis challenge but it is also important to understand how students feel about\nthis paradigm shift. In this research, 52 first-year CS students were surveyed\nin order to assess their views on technologies with code-generation\ncapabilities, both from academic and professional perspectives. Our findings\nindicate that while students generally favor the academic use of GPT, they\ndon't over rely on it, only mildly asking for its help. Although most students\nbenefit from GPT, some struggle to use it effectively, urging the need for\nspecific GPT training. Opinions on GPT's impact on their professional lives\nvary, but there is a consensus on its importance in academic practice.",
        "updated": "2024-04-26 14:29:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17443v1"
    },
    {
        "title": "Child Speech Recognition in Human-Robot Interaction: Problem Solved?",
        "authors": "Ruben JanssensEva VerhelstGiulio Antonio AbboQiaoqiao RenMaria Jose Pinto BernalTony Belpaeme",
        "links": "http://arxiv.org/abs/2404.17394v1",
        "entry_id": "http://arxiv.org/abs/2404.17394v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17394v1",
        "summary": "Automated Speech Recognition shows superhuman performance for adult English\nspeech on a range of benchmarks, but disappoints when fed children's speech.\nThis has long sat in the way of child-robot interaction. Recent evolutions in\ndata-driven speech recognition, including the availability of Transformer\narchitectures and unprecedented volumes of training data, might mean a\nbreakthrough for child speech recognition and social robot applications aimed\nat children. We revisit a study on child speech recognition from 2017 and show\nthat indeed performance has increased, with newcomer OpenAI Whisper doing\nmarkedly better than leading commercial cloud services. While transcription is\nnot perfect yet, the best model recognises 60.3% of sentences correctly barring\nsmall grammatical differences, with sub-second transcription time running on a\nlocal GPU, showing potential for usable autonomous child-robot speech\ninteractions.",
        "updated": "2024-04-26 13:14:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17394v1"
    },
    {
        "title": "M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training",
        "authors": "Lakmal MeegahapolaHamza HassouneDaniel Gatica-Perez",
        "links": "http://dx.doi.org/10.1145/3659591",
        "entry_id": "http://arxiv.org/abs/2404.17391v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17391v1",
        "summary": "Over the years, multimodal mobile sensing has been used extensively for\ninferences regarding health and well being, behavior, and context. However, a\nsignificant challenge hindering the widespread deployment of such models in\nreal world scenarios is the issue of distribution shift. This is the phenomenon\nwhere the distribution of data in the training set differs from the\ndistribution of data in the real world, the deployment environment. While\nextensively explored in computer vision and natural language processing, and\nwhile prior research in mobile sensing briefly addresses this concern, current\nwork primarily focuses on models dealing with a single modality of data, such\nas audio or accelerometer readings, and consequently, there is little research\non unsupervised domain adaptation when dealing with multimodal sensor data. To\naddress this gap, we did extensive experiments with domain adversarial neural\nnetworks (DANN) showing that they can effectively handle distribution shifts in\nmultimodal sensor data. Moreover, we proposed a novel improvement over DANN,\ncalled M3BAT, unsupervised domain adaptation for multimodal mobile sensing with\nmulti-branch adversarial training, to account for the multimodality of sensor\ndata during domain adaptation with multiple branches. Through extensive\nexperiments conducted on two multimodal mobile sensing datasets, three\ninference tasks, and 14 source-target domain pairs, including both regression\nand classification, we demonstrate that our approach performs effectively on\nunseen domains. Compared to directly deploying a model trained in the source\ndomain to the target domain, the model shows performance increases up to 12%\nAUC (area under the receiver operating characteristics curves) on\nclassification tasks, and up to 0.13 MAE (mean absolute error) on regression\ntasks.",
        "updated": "2024-04-26 13:09:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17391v1"
    },
    {
        "title": "How Could AI Support Design Education? A Study Across Fields Fuels Situating Analytics",
        "authors": "Ajit JainAndruid KerneHannah FowlerJinsil SeoGalen NewmanNic LupferAaron Perrine",
        "links": "http://arxiv.org/abs/2404.17390v1",
        "entry_id": "http://arxiv.org/abs/2404.17390v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17390v1",
        "summary": "We use the process and findings from a case study of design educators'\npractices of assessment and feedback to fuel theorizing about how to make AI\nuseful in service of human experience. We build on Suchman's theory of situated\nactions. We perform a qualitative study of 11 educators in 5 fields, who teach\ndesign processes situated in project-based learning contexts. Through\nqualitative data gathering and analysis, we derive codes: design process;\nassessment and feedback challenges; and computational support.\n  We twice invoke creative cognition's family resemblance principle. First, to\nexplain how design instructors already use assessment rubrics and second, to\nexplain the analogous role for design creativity analytics: no particular trait\nis necessary or sufficient; each only tends to indicate good design work. Human\nteachers remain essential. We develop a set of situated design creativity\nanalytics--Fluency, Flexibility, Visual Consistency, Multiscale Organization,\nand Legible Contrast--to support instructors' efforts, by providing on-demand,\nlearning objectives-based assessment and feedback to students.\n  We theorize a methodology, which we call situating analytics, firstly because\nmaking AI support living human activity depends on aligning what analytics\nmeasure with situated practices. Further, we realize that analytics can become\nmost significant to users by situating them through interfaces that integrate\nthem into the material contexts of their use. Here, this means situating design\ncreativity analytics into actual design environments. Through the case study,\nwe identify situating analytics as a methodology for explaining analytics to\nusers, because the iterative process of alignment with practice has the\npotential to enable data scientists to derive analytics that make sense as part\nof and support situated human experiences.",
        "updated": "2024-04-26 13:06:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17390v1"
    }
]