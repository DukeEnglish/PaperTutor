[
    {
        "title": "An exactly solvable model for emergence and scaling laws",
        "authors": "Yoonsoo NamNayara FonsecaSeok Hyeong LeeArd Louis",
        "links": "http://arxiv.org/abs/2404.17563v1",
        "entry_id": "http://arxiv.org/abs/2404.17563v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17563v1",
        "summary": "Deep learning models can exhibit what appears to be a sudden ability to solve\na new problem as training time ($T$), training data ($D$), or model size ($N$)\nincreases, a phenomenon known as emergence. In this paper, we present a\nframework where each new ability (a skill) is represented as a basis function.\nWe solve a simple multi-linear model in this skill-basis, finding analytic\nexpressions for the emergence of new skills, as well as for scaling laws of the\nloss with training time, data size, model size, and optimal compute ($C$). We\ncompare our detailed calculations to direct simulations of a two-layer neural\nnetwork trained on multitask sparse parity, where the tasks in the dataset are\ndistributed according to a power-law. Our simple model captures, using a single\nfit parameter, the sigmoidal emergence of multiple new skills as training time,\ndata size or model size increases in the neural network.",
        "updated": "2024-04-26 17:45:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17563v1"
    },
    {
        "title": "Structured Conformal Inference for Matrix Completion with Applications to Group Recommender Systems",
        "authors": "Ziyi LiangTianmin XieXin TongMatteo Sesia",
        "links": "http://arxiv.org/abs/2404.17561v1",
        "entry_id": "http://arxiv.org/abs/2404.17561v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17561v1",
        "summary": "We develop a conformal inference method to construct joint confidence regions\nfor structured groups of missing entries within a sparsely observed matrix.\nThis method is useful to provide reliable uncertainty estimation for\ngroup-level collaborative filtering; for example, it can be applied to help\nsuggest a movie for a group of friends to watch together. Unlike standard\nconformal techniques, which make inferences for one individual at a time, our\nmethod achieves stronger group-level guarantees by carefully assembling a\nstructured calibration data set mimicking the patterns expected among the test\ngroup of interest. We propose a generalized weighted conformalization framework\nto deal with the lack of exchangeability arising from such structured\ncalibration, and in this process we introduce several innovations to overcome\ncomputational challenges. The practicality and effectiveness of our method are\ndemonstrated through extensive numerical experiments and an analysis of the\nMovieLens 100K data set.",
        "updated": "2024-04-26 17:42:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17561v1"
    },
    {
        "title": "Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation",
        "authors": "Wei CuiRasa HosseinzadehJunwei MaTongzi WuYi SuiKeyvan Golestan",
        "links": "http://arxiv.org/abs/2404.17489v1",
        "entry_id": "http://arxiv.org/abs/2404.17489v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17489v1",
        "summary": "Contrastive learning is a model pre-training technique by first creating\nsimilar views of the original data, and then encouraging the data and its\ncorresponding views to be close in the embedding space. Contrastive learning\nhas witnessed success in image and natural language data, thanks to the\ndomain-specific augmentation techniques that are both intuitive and effective.\nNonetheless, in tabular domain, the predominant augmentation technique for\ncreating views is through corrupting tabular entries via swapping values, which\nis not as sound or effective. We propose a simple yet powerful improvement to\nthis augmentation technique: corrupting tabular data conditioned on class\nidentity. Specifically, when corrupting a specific tabular entry from an anchor\nrow, instead of randomly sampling a value in the same feature column from the\nentire table uniformly, we only sample from rows that are identified to be\nwithin the same class as the anchor row. We assume the semi-supervised learning\nsetting, and adopt the pseudo labeling technique for obtaining class identities\nover all table rows. We also explore the novel idea of selecting features to be\ncorrupted based on feature correlation structures. Extensive experiments show\nthat the proposed approach consistently outperforms the conventional corruption\nmethod for tabular data classification tasks. Our code is available at\nhttps://github.com/willtop/Tabular-Class-Conditioned-SSL.",
        "updated": "2024-04-26 15:43:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17489v1"
    },
    {
        "title": "Conformal Prediction with Learned Features",
        "authors": "Shayan KiyaniGeorge PappasHamed Hassani",
        "links": "http://arxiv.org/abs/2404.17487v1",
        "entry_id": "http://arxiv.org/abs/2404.17487v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17487v1",
        "summary": "In this paper, we focus on the problem of conformal prediction with\nconditional guarantees. Prior work has shown that it is impossible to construct\nnontrivial prediction sets with full conditional coverage guarantees. A wealth\nof research has considered relaxations of full conditional guarantees, relying\non some predefined uncertainty structures. Departing from this line of\nthinking, we propose Partition Learning Conformal Prediction (PLCP), a\nframework to improve conditional validity of prediction sets through learning\nuncertainty-guided features from the calibration data. We implement PLCP\nefficiently with alternating gradient descent, utilizing off-the-shelf machine\nlearning models. We further analyze PLCP theoretically and provide conditional\nguarantees for infinite and finite sample sizes. Finally, our experimental\nresults over four real-world and synthetic datasets show the superior\nperformance of PLCP compared to state-of-the-art methods in terms of coverage\nand length in both classification and regression scenarios.",
        "updated": "2024-04-26 15:43:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17487v1"
    },
    {
        "title": "Differentiable Pareto-Smoothed Weighting for High-Dimensional Heterogeneous Treatment Effect Estimation",
        "authors": "Yoichi ChikaharaKansei Ushiyama",
        "links": "http://arxiv.org/abs/2404.17483v1",
        "entry_id": "http://arxiv.org/abs/2404.17483v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17483v1",
        "summary": "There is a growing interest in estimating heterogeneous treatment effects\nacross individuals using their high-dimensional feature attributes. Achieving\nhigh performance in such high-dimensional heterogeneous treatment effect\nestimation is challenging because in this setup, it is usual that some features\ninduce sample selection bias while others do not but are predictive of\npotential outcomes. To avoid losing such predictive feature information,\nexisting methods learn separate feature representations using the inverse of\nprobability weighting (IPW). However, due to the numerically unstable IPW\nweights, they suffer from estimation bias under a finite sample setup. To\ndevelop a numerically robust estimator via weighted representation learning, we\npropose a differentiable Pareto-smoothed weighting framework that replaces\nextreme weight values in an end-to-end fashion. Experimental results show that\nby effectively correcting the weight values, our method outperforms the\nexisting ones, including traditional weighting schemes.",
        "updated": "2024-04-26 15:34:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17483v1"
    }
]