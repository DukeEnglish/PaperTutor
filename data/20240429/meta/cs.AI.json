[
    {
        "title": "Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo",
        "authors": "Stephen ZhaoRob BrekelmansAlireza MakhzaniRoger Grosse",
        "links": "http://arxiv.org/abs/2404.17546v1",
        "entry_id": "http://arxiv.org/abs/2404.17546v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17546v1",
        "summary": "Numerous capability and safety techniques of Large Language Models (LLMs),\nincluding RLHF, automated red-teaming, prompt engineering, and infilling, can\nbe cast as sampling from an unnormalized target distribution defined by a given\nreward or potential function over the full sequence. In this work, we leverage\nthe rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic\ninference problems. In particular, we use learned twist functions to estimate\nthe expected future value of the potential at each timestep, which enables us\nto focus inference-time computation on promising partial sequences. We propose\na novel contrastive method for learning the twist functions, and establish\nconnections with the rich literature of soft reinforcement learning. As a\ncomplementary application of our twisted SMC framework, we present methods for\nevaluating the accuracy of language model inference techniques using novel\nbidirectional SMC bounds on the log partition function. These bounds can be\nused to estimate the KL divergence between the inference and target\ndistributions in both directions. We apply our inference evaluation techniques\nto show that twisted SMC is effective for sampling undesirable outputs from a\npretrained model (a useful component of harmlessness training and automated\nred-teaming), generating reviews with varied sentiment, and performing\ninfilling tasks.",
        "updated": "2024-04-26 17:18:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17546v1"
    },
    {
        "title": "Using Neural Implicit Flow To Represent Latent Dynamics Of Canonical Systems",
        "authors": "Imran NasimJoaõ Lucas de Sousa Almeida",
        "links": "http://arxiv.org/abs/2404.17535v1",
        "entry_id": "http://arxiv.org/abs/2404.17535v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17535v1",
        "summary": "The recently introduced class of architectures known as Neural Operators has\nemerged as highly versatile tools applicable to a wide range of tasks in the\nfield of Scientific Machine Learning (SciML), including data representation and\nforecasting. In this study, we investigate the capabilities of Neural Implicit\nFlow (NIF), a recently developed mesh-agnostic neural operator, for\nrepresenting the latent dynamics of canonical systems such as the\nKuramoto-Sivashinsky (KS), forced Korteweg-de Vries (fKdV), and Sine-Gordon\n(SG) equations, as well as for extracting dynamically relevant information from\nthem. Finally we assess the applicability of NIF as a dimensionality reduction\nalgorithm and conduct a comparative analysis with another widely recognized\nfamily of neural operators, known as Deep Operator Networks (DeepONets).",
        "updated": "2024-04-26 17:01:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17535v1"
    },
    {
        "title": "Large Language Model Agent as a Mechanical Designer",
        "authors": "Yayati JadhavAmir Barati Farimani",
        "links": "http://arxiv.org/abs/2404.17525v1",
        "entry_id": "http://arxiv.org/abs/2404.17525v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17525v1",
        "summary": "Conventional mechanical design paradigms rely on experts systematically\nrefining concepts through experience-guided modification and FEA to meet\nspecific requirements. However, this approach can be time-consuming and heavily\ndependent on prior knowledge and experience. While numerous machine learning\nmodels have been developed to streamline this intensive and expert-driven\niterative process, these methods typically demand extensive training data and\nconsiderable computational resources. Furthermore, methods based on deep\nlearning are usually restricted to the specific domains and tasks for which\nthey were trained, limiting their applicability across different tasks. This\ncreates a trade-off between the efficiency of automation and the demand for\nresources. In this study, we present a novel approach that integrates\npre-trained LLMs with a FEM module. The FEM module evaluates each design and\nprovides essential feedback, guiding the LLMs to continuously learn, plan,\ngenerate, and optimize designs without the need for domain-specific training.\nWe demonstrate the effectiveness of our proposed framework in managing the\niterative optimization of truss structures, showcasing its capability to reason\nabout and refine designs according to structured feedback and criteria. Our\nresults reveal that these LLM-based agents can successfully generate truss\ndesigns that comply with natural language specifications with a success rate of\nup to 90%, which varies according to the applied constraints. By employing\nprompt-based optimization techniques we show that LLM based agents exhibit\noptimization behavior when provided with solution-score pairs to iteratively\nrefine designs to meet specifications. This ability of LLM agents to produce\nviable designs and optimize them based on their inherent reasoning capabilities\nhighlights their potential to develop and implement effective design strategies\nautonomously.",
        "updated": "2024-04-26 16:41:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17525v1"
    },
    {
        "title": "On the Use of Large Language Models to Generate Capability Ontologies",
        "authors": "Luis Miguel Vieira da SilvaAljosha KöcherFelix GehlhoffAlexander Fay",
        "links": "http://arxiv.org/abs/2404.17524v1",
        "entry_id": "http://arxiv.org/abs/2404.17524v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17524v1",
        "summary": "Capability ontologies are increasingly used to model functionalities of\nsystems or machines. The creation of such ontological models with all\nproperties and constraints of capabilities is very complex and can only be done\nby ontology experts. However, Large Language Models (LLMs) have shown that they\ncan generate machine-interpretable models from natural language text input and\nthus support engineers / ontology experts. Therefore, this paper investigates\nhow LLMs can be used to create capability ontologies. We present a study with a\nseries of experiments in which capabilities with varying complexities are\ngenerated using different prompting techniques and with different LLMs. Errors\nin the generated ontologies are recorded and compared. To analyze the quality\nof the generated ontologies, a semi-automated approach based on RDF syntax\nchecking, OWL reasoning, and SHACL constraints is used. The results of this\nstudy are very promising because even for complex capabilities, the generated\nontologies are almost free of errors.",
        "updated": "2024-04-26 16:41:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17524v1"
    },
    {
        "title": "Enhancing Legal Compliance and Regulation Analysis with Large Language Models",
        "authors": "Shabnam Hassani",
        "links": "http://arxiv.org/abs/2404.17522v1",
        "entry_id": "http://arxiv.org/abs/2404.17522v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17522v1",
        "summary": "This research explores the application of Large Language Models (LLMs) for\nautomating the extraction of requirement-related legal content in the food\nsafety domain and checking legal compliance of regulatory artifacts. With\nIndustry 4.0 revolutionizing the food industry and with the General Data\nProtection Regulation (GDPR) reshaping privacy policies and data processing\nagreements, there is a growing gap between regulatory analysis and recent\ntechnological advancements. This study aims to bridge this gap by leveraging\nLLMs, namely BERT and GPT models, to accurately classify legal provisions and\nautomate compliance checks. Our findings demonstrate promising results,\nindicating LLMs' significant potential to enhance legal compliance and\nregulatory analysis efficiency, notably by reducing manual workload and\nimproving accuracy within reasonable time and financial constraints.",
        "updated": "2024-04-26 16:40:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17522v1"
    }
]