[
    {
        "title": "A multi-agent model of hierarchical decision dynamics",
        "authors": "Paul Kinsler",
        "links": "http://arxiv.org/abs/2404.17477v1",
        "entry_id": "http://arxiv.org/abs/2404.17477v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17477v1",
        "summary": "Decision making can be difficult when there are many actors (or agents) who\nmay be coordinating or competing to achieve their various ideas of the optimum\noutcome. Here I present a simple decision making model with an explicitly\nhierarchical binary-tree structure, and evaluate how this might cooperate to\ntake actions that match its various evaluations of the uncertain state of the\nworld. Key features of agent behaviour are (a) the separation of its decision\nmaking process into three distinct steps: observation, judgement, and action;\nand (b) the evolution of coordination by the sharing of judgements.",
        "updated": "2024-04-26 15:26:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17477v1"
    },
    {
        "title": "Real-World Deployment of a Hierarchical Uncertainty-Aware Collaborative Multiagent Planning System",
        "authors": "Martina Stadler KurtzSamuel PrenticeYasmin VeysLong QuangCarlos Nieto-GrandaMichael NovitzkyEthan StumpNicholas Roy",
        "links": "http://arxiv.org/abs/2404.17438v1",
        "entry_id": "http://arxiv.org/abs/2404.17438v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17438v1",
        "summary": "We would like to enable a collaborative multiagent team to navigate at long\nlength scales and under uncertainty in real-world environments. In practice,\nplanning complexity scales with the number of agents in the team, with the\nlength scale of the environment, and with environmental uncertainty. Enabling\ntractable planning requires developing abstract models that can represent\ncomplex, high-quality plans. However, such models often abstract away\ninformation needed to generate directly-executable plans for real-world agents\nin real-world environments, as planning in such detail, especially in the\npresence of real-world uncertainty, would be computationally intractable. In\nthis paper, we describe the deployment of a planning system that used a\nhierarchy of planners to execute collaborative multiagent navigation tasks in\nreal-world, unknown environments. By developing a planning system that was\nrobust to failures at every level of the planning hierarchy, we enabled the\nteam to complete collaborative navigation tasks, even in the presence of\nimperfect planning abstractions and real-world uncertainty. We deployed our\napproach on a Clearpath Husky-Jackal team navigating in a structured outdoor\nenvironment, and demonstrated that the system enabled the agents to\nsuccessfully execute collaborative plans.",
        "updated": "2024-04-26 14:22:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17438v1"
    },
    {
        "title": "On the Road to Clarity: Exploring Explainable AI for World Models in a Driver Assistance System",
        "authors": "Mohamed RoshdiJulian PetzoldMostafa WahbyHussein EbrahimMladen BerekovicHeiko Hamann",
        "links": "http://arxiv.org/abs/2404.17350v1",
        "entry_id": "http://arxiv.org/abs/2404.17350v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17350v1",
        "summary": "In Autonomous Driving (AD) transparency and safety are paramount, as mistakes\nare costly. However, neural networks used in AD systems are generally\nconsidered black boxes. As a countermeasure, we have methods of explainable AI\n(XAI), such as feature relevance estimation and dimensionality reduction.\nCoarse graining techniques can also help reduce dimensionality and find\ninterpretable global patterns. A specific coarse graining method is\nRenormalization Groups from statistical physics. It has previously been applied\nto Restricted Boltzmann Machines (RBMs) to interpret unsupervised learning. We\nrefine this technique by building a transparent backbone model for\nconvolutional variational autoencoders (VAE) that allows mapping latent values\nto input features and has performance comparable to trained black box VAEs.\nMoreover, we propose a custom feature map visualization technique to analyze\nthe internal convolutional layers in the VAE to explain internal causes of poor\nreconstruction that may lead to dangerous traffic scenarios in AD applications.\nIn a second key contribution, we propose explanation and evaluation techniques\nfor the internal dynamics and feature relevance of prediction networks. We test\na long short-term memory (LSTM) network in the computer vision domain to\nevaluate the predictability and in future applications potentially safety of\nprediction models. We showcase our methods by analyzing a VAE-LSTM world model\nthat predicts pedestrian perception in an urban traffic situation.",
        "updated": "2024-04-26 11:57:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17350v1"
    },
    {
        "title": "Agentive Permissions in Multiagent Systems",
        "authors": "Qi Shi",
        "links": "http://arxiv.org/abs/2404.17053v1",
        "entry_id": "http://arxiv.org/abs/2404.17053v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17053v1",
        "summary": "This paper proposes to distinguish four forms of agentive permissions in\nmultiagent settings. The main technical results are the complexity analysis of\nmodel checking, the semantic undefinability of modalities that capture these\nforms of permissions through each other, and a complete logical system\ncapturing the interplay between these modalities.",
        "updated": "2024-04-25 21:27:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17053v1"
    },
    {
        "title": "AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks",
        "authors": "Jeremy Harper",
        "links": "http://arxiv.org/abs/2404.17017v1",
        "entry_id": "http://arxiv.org/abs/2404.17017v1",
        "pdf_url": "http://arxiv.org/pdf/2404.17017v1",
        "summary": "The proliferation of large language models (LLMs) and their integration into\nmulti-agent systems has paved the way for sophisticated automation in various\ndomains. This paper introduces AutoGenesisAgent, a multi-agent system that\nautonomously designs and deploys other multi-agent systems tailored for\nspecific tasks. AutoGenesisAgent comprises several specialized agents including\nSystem Understanding, System Design, Agent Generator, and several others that\ncollectively manage the lifecycle of creating functional multi-agent systems\nfrom initial concept to deployment. Each agent in AutoGenesisAgent has distinct\nresponsibilities ranging from interpreting input prompts to optimizing system\nperformance, culminating, in the deployment of a ready-to-use system. This\nproof-of-concept study discusses the design, implementation, and lessons\nlearned from developing AutoGenesisAgent, highlighting its capability to\ngenerate and refine multi-agent systems autonomously, thereby reducing the need\nfor extensive human oversight in the initial stages of system design. Keywords:\nmulti-agent systems, large language models, system design automation, agent\narchitecture, autonomous systems, software deployment",
        "updated": "2024-04-25 20:20:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.17017v1"
    }
]