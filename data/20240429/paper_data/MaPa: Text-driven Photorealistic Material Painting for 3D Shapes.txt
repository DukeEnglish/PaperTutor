MaPa: Text-driven Photorealistic Material Painting for 3D Shapes
ShangzhanZhang1,2 SidaPeng1 TaoXu1 YuanboYang1 TianrunChen1
NanXue2 YujunShen2 HujunBao1 RuizhenHu3 XiaoweiZhou1
1ZhejiangUniversity 2AntGroup 3ShenzhenUniversity
Figure1:ExamplesfromMaPaGallery,whichfacilitatesphoto-realistic3Drenderingbygeneratingmaterialsfordailyobjects.
ABSTRACT 1 INTRODUCTION
Thispaperaimstogeneratematerialsfor3Dmeshesfromtext 3Dcontentgenerationhasattractedincreasingattentiondueto
descriptions.Unlikeexistingmethodsthatsynthesizetexturemaps, its wide applications in video games, movies and VR/AR. With
weproposetogeneratesegment-wiseproceduralmaterialgraphsas theintegrationofdiffusionmodels[Hoetal.2020;Rombachetal.
theappearancerepresentation,whichsupportshigh-qualityrender- 2022;Songetal.2020]into3Dgeneration[Chengetal.2023;Liu
ingandprovidessubstantialflexibilityinediting.Insteadofrelying etal.2023;Pooleetal.2022],thisfieldhaswitnessedremarkable
onextensivepaireddata,i.e.,3Dmesheswithmaterialgraphsand advancementsandimpressiveresults.Manyworksfocusongen-
correspondingtextdescriptions,totrainamaterialgraphgener- erating3Dobjects[Linetal.2023;Liuetal.2023;Longetal.2023;
ativemodel,weproposetoleveragethepre-trained2Ddiffusion Pooleetal.2022]fromtextpromptsorasingleimage.Inadditionto
modelasabridgetoconnectthetextandmaterialgraphs.Specif- 3Dshapegeneration,generatingappearanceforexistingmeshesis
ically,ourapproachdecomposesashapeintoasetofsegments alsoanimportantproblem.Theconventionalprocessofdesigning
anddesignsasegment-controlleddiffusionmodeltosynthesize2D appearancesformeshesinvolvesextensiveandlaboriousmanual
imagesthatarealignedwithmeshparts.Basedongeneratedim- work,creatingapressingneedwithinthecommunityforamore
ages,weinitializeparametersofmaterialgraphsandfine-tunethem efficientapproachtoproducingmeshappearance.Many3Dtexture
throughthedifferentiablerenderingmoduletoproducematerials synthesismethods[Caoetal.2023;Chenetal.2023b,2022;Metzer
inaccordancewiththetextualdescription.Extensiveexperiments etal.2022;Richardsonetal.2023;Yehetal.2024;Yuetal.2023]
demonstratethesuperiorperformanceofourframeworkinphoto- havebeenproposedtosolvethisproblem,whichcancreatediverse
realism,resolution,andeditabilityoverexistingmethods.Project 3Dtexturesformeshesaccordingtothetextinputbyusers.
page:https://zhanghe3z.github.io/MaPa/. However,creatingtexturesalonedoesn’tfullymeettheneedsof
downstreamapplications,asweoftenrendermeshesundervari-
ouslightingconditions.Forexample,invideogames,choosingthe
CCSCONCEPTS
rightmaterialsforrenderingmeshesinasceneiscritical,asthis
•Computingmethodologies→Appearanceandtexturerepresen-
impactshowthemeshinteractswiththelightaroundit,whichin
tations.
turnaffectsitsappearanceandrealism.Therefore,designingan
algorithmforpaintingmaterialsonmeshesisimportant.Despite
KEYWORDS theremarkablesuccessintexturegeneration,thereisalackofre-
materialpainting,3Dassetcreation,generativemodeling searchfocusingongeneratinghigh-qualitymaterialsfor3Dobjects.
4202
rpA
62
]VC.sc[
1v96571.4042:viXraSIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA Zhang,S.etal
Recently,Fantasia3D[Chenetal.2023a]triestogenerate3Dobjects baselinesinthetaskoftext-drivenappearancemodeling,interms
withmaterialsbydistillingtheappearancepriorfrom2Dgener- ofFIDandKIDmetrics,aswellasinuserstudyevaluation.We
ativemodels.However,thisapproachfacessubstantialobstacles also provide qualitative comparisons to the baselines, showcas-
duetooptimizationinstabilityandoftenfailstoyieldhigh-quality ingoursuperiorphotorealisticvisualquality.Userscaneasilyuse
materials.Moreover,itmodelstheobjectmaterialasaper-point ourmethodtogeneratehigh-qualitymaterialsforinputmeshes
representation,whichcouldbeinconvenientfordownstreamuser throughtextandeditthemconveniently.Meanwhile,sincewecan
modifications. generatearbitrary-resolutionandtileablematerialmaps,wecan
Inthispaper,ourgoalistogeneratephotorealisticandhigh- renderfinematerialdetailsathighresolution.
resolutionmaterialsformeshesfromtextualdescriptions,which
canbeconvenientlyeditedbyusers.Weobservethatthematerials 2 RELATEDWORKS
ofnewlymanufacturedobjectsinreallifeoftenexhibitconsistency
2Ddiffusionmodels. Recently,diffusionmodels[Hoetal.2020;
withinspecificareasduetothenatureofthemanufacturingpro-
Nicholetal.2021;Rombachetal.2022;Songetal.2020]havebeen
cesses.Motivatedbythis,wehopethatourgenerationprocesscan
dominatingthefieldofimagegenerationandediting.Theseworks
mimicthischaracteristic,whichhastheadvantageofleadingto
cangenerateimagesfromtextprompts,achievingimpressivere-
moreorganizedresultsandallowinguserstoeffortlesslyswapthe
sults. Among them, Stable Diffusion [Rombach et al. 2022] is a
materialofaspecificareainmodelingsoftware,withouttheneed
large-scalediffusionmodelthatiswidelyused.ControlNet[Zhang
torecreatetheentirematerialmap.However,itisstillanunsolved
etal.2023]introducesspatialconditioningcontrols(e.g.,inpaint-
problemtoseparatelygeneratematerialsforeachpartofthemesh
ingmasks,Cannyedges[Canny1986],depthmaps)topretrained
andensuretheconsistencyofmaterialswithinthelocalregion.
text-to-imagediffusionmodels.Thesesignalsprovidemoreprecise
Tothisend,weproposeanovelframework,namedMaPa,togen-
controloverthediffusionprocess.Anotherlineofworkfocuses
eratematerialsforagivenmeshbasedontextprompts.Ourkeyidea
oncontrollingdiffusionmodelswithexemplarimages.TextualIn-
istointroduceasegment-wiseproceduralmaterialgraphsrepre-
version[Galetal.2022]representstheexemplarimagesaslearned
sentationfortext-drivenmaterialpaintingandleverage2Dimages
tokensintextualspace.DreamBooth[Ruizetal.2023]finetunes
asabridgetoconnectthetextandmaterials.Proceduralmaterial
thediffusionmodelandusesseveraltrickstopreventoverfitting.
graphs[Huetal.2022a;Lietal.2023;Shietal.2020],astapleinthe
IP-Adapter[Yeetal.2023]trainsasmalladapternetworktomap
computergraphicsindustry,consistofarangeofsimpleimagepro-
theexemplarimagetothelatentspaceofthediffusionmodel.
cessingoperationswithasetofparameters.Theyarerenownedfor
theirhigh-qualityoutputandresolutionindependence,andprovide Appearancemodeling. Withtheemergenceofdiffusionmodels,
substantialflexibilityinediting.Thesegment-wiserepresentation someworksbegintousediffusionmodelstogeneratetexturesfor
mimicstheconsistencyofmaterialsintherealworld,makingthe 3Dobjects.Latent-nerf[Metzeretal.2022]extendsDreamFusion
resultslookmorerealisticandclean.However,totrainagenera- tooptimizethetexturemapforagiven3Dobject.However,Latent-
tivemodelthatdirectlycreatesmaterialgraphsforaninputmesh, nerfrequiresalongtrainingtimeandproduceslow-qualitytexture
extensivedataforpairsoftextsandmesheswithmaterialgraphs maps.TEXTure[Richardsonetal.2023]andText2tex[Chenetal.
needtobecollected.Instead,weleveragethepre-trained2Ddiffu- 2023b]utilizeapretraineddepth-to-imagediffusionmodeltoitera-
sionmodelasanintermediatebridgetoguidetheoptimizationof tivelypainta3Dmodelfromdifferentviewpoints.TexFusion[Cao
proceduralmaterialgraphsandproducediversematerialforgiven etal.2023]introducesaniterativeaggregationschemefromdiffer-
meshesaccordingtotextualdescriptions. entviewpointsduringthedenoisingprocess.Theseworksgreatly
Specifically,ourmethodcontainstwomaincomponents:segment- improvethequalityofthegeneratedtexturemapandspeedupthe
controlledimagegenerationandmaterialgraphoptimization.Given texturegenerationprocess.However,theseworkscanonlygenerate
amesh,itisfirstlysegmentedintoseveralsegmentsandprojected texturemaps,notrealisticmaterials.Materialmodeling[Guarnera
ontoaparticularviewpointtoproducea2Dsegmentationimage. etal.2016]haslongbeenaproblemofinterestincomputergraphics
Then,wedesignasegment-controlleddiffusionmodeltogenerate andvision.PhotoShape[Parketal.2018]usesshapecollections,
anRGBimagefromthe2Dsegmentation.Incontrasttoholisti- materialcollections,andimagecollectionstolearnmaterialassign-
callysynthesizingimages[Richardsonetal.2023],conditioning mentto3Dshapesbasedongivenimages,wheretheshapeand
the diffusion model on the projections of 3D segments can cre- imagesneedtobepreciselyaligned.TMT[Huetal.2022b]addresses
ate2Dimagesthatmoreaccuratelyalignwithpartsofthemesh, thelimitationsofdataconstraintsinPhotoShapebyallowingdif-
thereby enhancing the stability of the subsequent optimization ferentshapestructures.However,itssuccessfulimplementation
process.Subsequently,weproducetheobjectmaterialbyestimat- necessitatesasubstantialquantityof3Ddatawithpartsegmenta-
ingsegment-wisematerialgraphsfromthegeneratedimage.The tion[Moetal.2019]fortraining,whichmakesitcanonlywork
materialgraphsareinitializedbyretrievingthemostsimilarones onafewcategoriesofobjects.Moreover,bothofthoseworkstreat
fromourcollectedmaterialgraphlibrary,andthentheirparameters materialmodelingasaclassificationproblemandcanonlyusema-
areoptimizedtofittheimagethroughadifferentiablerendering terialsfromthepre-collecteddataset,whichoftenleadstoincorrect
module.Thegeneratedmaterialscanthenbeimportedintoexisting materialpredictionunderchallenginglightinganddissimilarmate-
commercialsoftwareforuserstoeditandgeneratevariousmaterial rialassignmentduetotherestrictionofdataset.MATch[Shietal.
variantsconveniently. 2020]anditsextension[Lietal.2023]introduceadifferentiable
Weextensivelyvalidatetheeffectivenessofourmethodondif- proceduralmaterialgraphs.Proceduralmaterialgraphsarepopular
ferentcategoriesofobjects.Ourresultsoutperformthreestrong inthegraphicsindustry,whichcangenerateresolution-invariant,MaPa:Text-drivenPhotorealisticMaterialPaintingfor3DShapes SIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA
Material Graph Selection DiffMat UV Map
Material
A
a
c lu es athi ho en r co hn airMesh 2D segments Material Classification Material Group Optimization
Roughness Albedo Normal
(c) Material Graph Selection and Optimization (Sec 3.3)
Repeat (b) (c)
Segment-conditioned
ControlNet Generated Image Albedo Diffusion Albedo Image Final Result Segment-conditioned Inpainted Image
Inpainting Network
(a) Segment-controlled Image Generation (Sec 3.1) (b) Material Grouping (Sec 3.2) (d) Iterative Material Recovery (Sec 3.4)
Figure2:Illustrationofourpipeline.Ourpipelineprimarilyconsistsoffoursteps:a)Segment-controlledimagegeneration.
First,wedecomposetheinputmeshintovarioussegments,projectthesesegmentsonto2Dimages,andthengeneratethe
correspondingimagesusingthesegment-controlledControlNet.b)Materialgrouping.Wegroupsegmentsthatsharethesame
materialandhavesimilarappearanceintoamaterialgroup.c)Materialgraphselectionandoptimization.Foreachmaterial
group,weselectanappropriatematerialgraphbasedongeneratedimagesandthenoptimizethismaterialgraph.d)Iterative
materialrecovery.Werenderadditionalviewsoftheinputmeshwiththeoptimizedmaterialgraphs,inpaintthemissing
regionsintheserenderedimages,andrepeatstepsb)andc)untilallsegmentsareassignedwithmaterialgraphs.
tileable,andphotorealisticmaterials.PhotoScene[Yehetal.2022] TheoverviewoftheproposedmodelisillustratedinFigure2.Sec-
andPSDR-Room[Yanetal.2023]producethematerialsofindoor tion 3.1 first describes our proposed segment-controlled image
scenesfromsingleimagesusingdifferentiableproceduralmaterial generation.Theimage-basedmaterialoptimizationisdividedinto
graphs.Differentfromtheseworks,wefocusonassigningrealistic threecomponents:materialgrouping,materialgraphselectionand
materialstoagivenobject.TheclosestworkisFantasia3D[Chen optimization,anditerativematerialrecovery.Section3.2provides
etal.2023a],whichfollowsDreamFusionandincorporatesaspa- detailsonusingthegeneratedimageformaterialgrouping.Sec-
tiallyvaryingbidirectionalreflectancedistributionfunction(BRDF) tion3.3introduceshowtoselectinitialmaterialgraphsfromthe
tolearnthesurfacematerialsforgenerated3Dobjects.However, materialgraphlibraryandoptimizetheparametersofprocedural
theprocessofdistilling3Dmaterialsfroma2Dpretraineddiffusion nodegraphsaccordingtothegeneratedimage.Then,wedesign
modelisnotstable,andoftenfailstogeneratereasonablemate- aniterativeapproachtogeneratematerialsforsegmentsofthe
rials.Moreover,thematerialsgeneratedbyFantasia3Dareoften meshthathavenotbeenassignedmaterialsinSection3.4.Finally,
cartoonishandunrealistic. weintroduceadownstreameditingmoduleinSection3.5toallow
userstoeditthegeneratedmaterialsconveniently.
Materialandtextureperception. Materialperceptionandtexture
recognitionarelong-standingproblems.Aconsiderableamount 3.1 Segment-controlledimagegeneration
ofearlierresearchonmaterialrecognitionhasconcentratedon Givenamesh,wefirstoversegmentitintoaseriesofsegments
addressingtheclassificationproblem[Belletal.2015;Cimpoietal. {si} 𝑖𝑁 =1.Duringthemodelingprocess,designersoftencreatein-
2014;Huetal.2011;Liuetal.2010].Otherworks[Sharmaetal. dividualparts,whicharelaterassembledintoacompletemodel.
2023;UpchurchandNiu2022;Zhengetal.2023]attempttosolve Hence,ourmethodcanseparatethesecomponentsbygrouping
materialsegmentationproblem.Asfortextureperception,anum- theconnectedcomponents.Ifthemeshisscannedorwatertight,
beroftraditionalapproachestreattextureasasetofhandcrafted wecanalsouseexistingtechniques[KatzandTal2003]todecom-
features[Caputoetal.2005;Guoetal.2010;Lazebniketal.2005]. poseitintoaseriesofsegments.Motivatedbytheprogressof2D
Recently,deeplearningmethods[BrunaandMallat2013;Chenetal. generativemodels[Hoetal.2020;Rombachetal.2022;Zhangetal.
2021;Cimpoietal.2015;Fujiedaetal.2017]havebeenintroducedto 2023],weopttoprojectthesesegmentstoaviewpointtogenerate
addresstheproblemoftextureperception.Ourworkbenefitsfrom 2Dsegmentationmasksandperformsubsequentconditionalgen-
theseworks,andweempiricallyfindthatGPT-4v[OpenAI2023] erationin2Dspace.Forthegoodperformanceofconditional2D
canbeappliedtomaterialclassificationandtexturedescription generation,wecarefullyselectaviewpointtoensureagoodinitial
tasksinazero-shotmanner. result.Specifically,asetofviewpointsareuniformlysampledwith
a360-degreeazimuthrange,aconstant25-degreeelevationangle,
andafixedradiusof2unitsfromthemesh.Weprojectthe3D
3 METHOD segmentsontotheseviewpointsandchoosetheonewiththehigh-
Givenameshandatextualprompt,ourmethodaimstoproduce estnumberof2Dsegmentsasourstartingviewpoint.Ifmultiple
suitablematerialstocreatephotorealisticandrelightable3Dshapes. viewpointshavethesamenumberof2Dsegments,weempiricallySIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA Zhang,S.etal
choosetheviewpointwiththelargestprojectedareaofthemesh, group,weretrievethemostsimilarmaterialgraphfromthemate-
asitismorelikelytocontainmoredetails.The2Dsegmentsare rialgraphlibrary.Then,weoptimizethematerialgraphtoobtain
sortedbyareasizeandnumberedfromlargetosmalltoformthe thefinalmaterialgraph.
2Dsegmentationmask.
Fromthisviewpoint,the2Dsegmentationmaskisusedtoguide Materialgraphselection. Webuildamaterialgraphlibraryinad-
vance,whichcontainsavarietyofmaterialcategories.Thumbnails
thegenerationofthecorrespondingRGBimage,whichthenfa-
ofmaterialgraphsarerenderedusingeightdifferentenvironment
cilitatestheprocessofmaterialpredictionthatfollows.Notethat
mapstoenhancetherobustnessoftheretrievalprocess.Follow-
previousworks[Caoetal.2023;Chenetal.2023b;Richardsonetal.
ing PSDR-Room [Yan et al. 2023], we adopt CLIP for zero-shot
2023]usuallyusedepth-to-imagediffusionmodeltogenerateim-
retrievalofmaterialgraphs.Wecropthematerialgroupregion
ageconditionedonmeshes,whichmayresultinmultiplecolor
fromthegeneratedimageandcomputeitscosinesimilaritywith
blockswithinasegmentandleadtounstablematerialoptimization,
same-classmaterialgraphsinourlibrarythroughCLIPmodel.The
thuswechooseControlNetwithSAMmask[Kirillovetal.2023]
materialgraphwiththehighestsimilarityisselected.Similarto
ascondition[Gaoetal.2023]foroursegment-controlledimage
PhotoScene[Yehetal.2022],weapplyhomogeneousmaterials
generation.Thisprocessisdefinedas:
tomaterialgroupswithanareasmallerthan1000pixels,asitis
challengingtodiscernspatialvariationsinsuchsmallarea.
{sˆi 𝑧} t𝑖𝑀 −=1 1= =𝝐P 𝜃( ({ 𝑧s ti ,} 𝒕𝑖𝑁 ,= {1 sˆ) i, } 𝑖𝑀 =1), (1) graM phat ce lr oia sl eg tora tp hh eo gp et nim eri az ta et dio in m. aT go e,m wa ek oe pt th ime ir ze etr ti he eve pd arm amat ee tr ei ra sl
ofthematerialgraphusingourdifferentiablerenderingmodule.
wherePistheprojectionfunction,and𝝐𝜃 isthepre-trainedCon-
Thedifferentiablerenderingmodulecontainsadifferentiableren-
trolNet.𝑧t is the noised latent at time step𝑡, 𝒕 is the time step, dererandDiffMatv2[Lietal.2023].DiffMatv2[Lietal.2023]
and{sˆi} 𝑖𝑀 =1isthe2Dsegments.WefinetunetheSAM-conditioned
isaframeworkthatdifferentiablyconvertsmaterialgraphsinto
ControlNet[Gaoetal.2023]onourowncollecteddatasettoobtain
asegment-conditionedControlNet.Theimplementationdetailsof
texture-space maps, such as albedo map Auv, normal map Nuv,
segment-conditionedControlNetandthecomparisontodepth-to-
roughnessmapRuv,etc.WeutilizeUVmapsgeneratedbyBlender
tosampleper-pixelmaterialmapsA,N′,R.ThenormalsN′should
imagediffusionmodelarepresentedinthesupplementarymaterial.
berotatedtoalignwiththelocalshadingframetoobtainthefinal
normalmapN.Weusephysically-basedmicrofacetBRDF[Karis
3.2 Materialgrouping 2013]asourmaterialmodel.Ourlightingmodelis2Dspatially-
Tosavetheoptimizationtimeandobtainvisuallymorecoherentre- varyingincominglighting[Lietal.2020].Theincominglightingis
sults,wefirstmergesegmentswithsimilarappearanceintogroups storedinatwo-dimensionalgridthatvariesspatially.Usingthis
andgenerateonematerialgraphpergroup,insteadofdirectlyopti- lightingmodelsignificantlyenhancestheefficiencyofourrender-
mizingthematerialforeachsegment.Specifically,webuildagraph ing process, which eliminates the need to trace additional rays.
witheachsegmentasanode,andconnecttwosegmentsifthey InvRenderNet[Lietal.2020]isanetworkthatcanpredictthe2D
havethesamematerialclassandsimilarcolors.Then,weextract spatially-varyinglightingfromasingleimage.Weusethepredic-
allconnectedcomponentsfromthegraphasthegroupingresults. tionofInvRenderNetasourinitiallightingLinit.Duringtraining,
Inmoredetails,formaterialclassification,weuseGPT-4v[Ope- weoptimizethelightingLbyaddingresiduallighting (cid:101)LtoLinit.
nAI2023]duetoitsstrongvisualperceptioncapabilitiesandconve- Theinformationof (cid:101)Lisstoredina2Dhashgrid[Mülleretal.2022].
nientin-contextlearningabilities.WeempiricallyfindthatGPT-4v Foreachpixel,wequerythecorrespondingfeaturefromthehash
workswellwithimagescreatedbyadiffusionmodel.Thedetails gridanduseashallowMLPtoconvertitintoaresiduallighting.We
ofthepromptarepresentedinthesupplementarymaterial.Forthe settheinitialvalueof (cid:101)Lto0,andusetheReLUactivationfunction
colorsimilarity,wetrainanalbedoestimationnetworktoremove topreventthevalueofLfrombeingnegative.Thedifferentiable
effectscausedbytheshadowsandstronglightinginthegenerated renderingmoduleisdescribedas:
images.Wefine-tuneStableDiffusionconditionedonCLIPimage
Auv,Nuv,Ruv=DiffMat(G),
embeddingsontheABOmaterialdataset[Collinsetal.2022],with
aRGBimageastheinputandthecorrespondingalbedoimageas
A,R=S(Auv,Ruv),
(2)
theoutput.Theimplementationdetailsofalbedoestimationnet- N=Rot(S(Nuv)),
workarepresentedinthesupplementarymaterial.Ifthedistance I𝑟𝑒𝑛𝑑 =R(A,N,R,L),
betweenthemediancoloroftwosegmentsinthealbedoimagein
theCIEcolorspace[Sharmaetal.2005]islessthanathreshold𝜆,
whereGistheproceduralmaterialgraph,SistheUVsampling
thesetwosegmentsareconsideredtobesimilar.Weempirically
function,RotistherotationfunctionthatrotatesthenormalsN′,
andRisthedifferentiablerendereradoptedfromInvRenderNet[Li
set𝜆to2,whichmeansthedifferenceisperceptiblethroughclose
et al. 2020]. We can render a 2D image using the differentiable
observation[Minakeretal.2021].
renderingmodule,andthenoptimizetheparametersofthema-
terialgraphbymakingtherenderedimageassimilaraspossible
3.3 Materialgraphselectionandoptimization tothegeneratedimage.However,imagesgeneratedbythediffu-
Inthissection,wedescribehowtorecovertheparametersofpro- sionmodeltypicallyhavestronglightingandshadows.Toavoid
ceduralnodegraphsfromthegeneratedimages.Foreachmaterial overfitting,weintroducearegularizationtermthatconstrainstheMaPa:Text-drivenPhotorealisticMaterialPaintingfor3DShapes SIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA
graphdirectlyinSubstanceDesigner[Adobe2021].Forexample,
Add a pattern that gives
a sense of luxury theycanchangethenoisethataffectsthebasecolortochangethe
texture,oraddsomenodesthataffecttheroughnesstoadddetails
suchasscratchesandothersurfaceimperfections.
However,itisdifficultformostuserstooperatetheunderlying
Retrieve API
noisenodeswhicharecomplexandintertwined.Inspiredbythe
Retrieve Pattern
workofVISPROG[GuptaandKembhavi2023],weprovideusers
withsomehigh-leveloperations,allowingthemtoeasilymodifythe
materialthroughtextualinstructions.Forexample,whenusersin-
puttherequirement“addapatternthatgivesasenseofluxury”,our
methodwillfindageometricseamlesspatternmaskthatmatches
Figure3:Downstreamediting.Weperformmaterialediting thedescriptionandgeneratethecorrespondingpythoncommand
ongeneratedmaterial.Theusercaneditthematerialusing toaddsuchpatternsothattheusercanrunthiscommandlocally
textualpromptsthroughtheGPT-4andasetofpredifined toobtainthedesiredmaterialmodification.Oneexampleresultof
APIs. addingtextureisshowninFigure3.Moredetailsaboutthisfunction
canbefoundinthesupplementarymaterial.
renderingresultofthealbedomapAofthematerialgraphtobeas
similaraspossibletothealbedoimagepredictedbythenetwork 4 EXPERIMENTS
mentionedinSection3.2.Additionally,differentiableprocedural
4.1 Implementationdetails
material graphs highly constrain the optimization space of the
OurmaterialgraphoptimizationinthreestagesusesAdam[Kingma
materialmodel,whichcanalsoalleviatetheinstabilityduringthe
andBa2014]astheoptimizer.Weperformatotalof300iterations
trainingprocessduetothepresenceofstronglightingandshadows.
foroptimization.Ingeneral,theentireprocessofourmethodcanbe
Thelossfunctionsandmoretechnicaldetailsarepresentedinthe
completedinlessthan10minutesonanA6000,whichisfasterthan
supplementarymaterial.
Text2tex[Chenetal.2023b](15minutes)andFantasia3D[Chen
etal.2023a](25minutes).Wecollect8materialcategories,including
3.4 Iterativematerialrecovery
wood,metal,plastic,leather,fabric,stone,ceramic,andrubber.The
Theaforementionedprocesscanonlygeneratematerialsforone
numberofeachcategoryisgiveninthesupplementarymaterial.
viewpointofthemesh.Forareaswithoutmaterial,weadoptedan
Sincetheeightmaterialsmentionedabovealreadycoverthevast
iterativeapproachtoinpaintthem.Amongalltheviewpointsgen-
majorityofman-madeobjects,wedidnotcollectadditionaltypes
eratedinSection3.1,weselecttheviewpointadjacenttotheinitial
ofmaterialgraphs.
oneforthenextiteration.Duringthisiteration,itisnecessaryto
determinewhichsegmentsrequirematerialassignment.Asegment
isconsideredinneedofmaterialifithasnotyetbeenassigned 4.2 Comparisontobaselines
one,orifitsprojectedareainthepreviousviewpointislessthana Baselines. Wecompareourmethodwiththreestrongbaselines
quarterofitsprojectedareainthecurrentviewpoint. ontext-drivenappearancemodeling.TEXTure[Richardsonetal.
Toensuretheconsistencyoftheinpaintingresults,weadopta 2023]introducesaniterativetexturepaintingschemetogenerate
commondesign[Dihlmannetal.2024;Zeng2023]inthecommu- texturemapsfor3Dobjects.Text2tex[Chenetal.2023b]usesa
nity.Werenderthemeshwithpartiallyassignedmaterialsboth similarschemetoTEXTure.Additionally,itcreatesanautomated
fromthepreviousiterationviewpointsandthecurrentiteration strategyforselectingviewpointsduringtheiterativeprocess.Fan-
viewpointusingBlenderCyclesRenderer.Then,thepreviousitera- tasia3D[Chenetal.2023a]separatesthemodelingofgeometry
tionviewpointimagesandthecurrentiterationviewpointimage andappearance,adoptinganMLPtomodelthesurfacematerial
areconcatenatedastheinputoftheinpaintingnetwork.Onlythe propertiesofa3Dobject.Forthefollowingexperiments,weemploy
segments that need material assignment are inpainted, and the anenvironmentalmaptogenerateoutcomesforourmethodand
inpaintingmaskofotherregionsissetto0.TheSAM-conditioned Fantasia3D.TheresultsforTEXTureandText2texarederivedfrom
inpaintingnetwork[Gaoetal.2023]isadoptedasourinpainting theirdiffusecolorpassinBlender.
network.WeemploytheprocessdescribedinSection3.3againto
generatematerialsforthesesegments.Ifsegmentsrequiringmate- Quantitativecomparison. Ourgoalistoobtainhighrendering
rialassignmentandthosealreadyassignedmaterialaregrouped qualitythatisascloseaspossibletotherealimage,sowemeasure
intothesamematerialgroup,wedirectlycopytheexistingmaterial thedistributiondistancebetweentherenderedimageandthereal
graphtothesegmentsrequiringmaterial.Abovestepsarerepeated image using FID [Heusel et al. 2017] and KID [Binkowski et al.
untilallregionsareassignedmaterials. 2018].Weselect300chairsfromTMT[Huetal.2022b]and30
randomobjectsfromABOdataset[Collinsetal.2022]astestdata.
3.5 Downstreamediting 10viewsareuniformlysampledforeachchairwitha360-degree
Differentfrompreviouswork[Caoetal.2023;Chenetal.2023b,a; azimuthrange,aconstant45-degreeelevationangle,andafixed
Richardsonetal.2023],ourmethodcangenerateeditablematerial radiusof1.5units.Thepromptintheexperimentisextractedfrom
graphs,whichisparamountforusers.Userscaneditthematerial therenderingoforiginalobjectsusingBLIP[Lietal.2022].EachSIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA Zhang,S.etal
Table1:Comparisonresults.Wecompareourmethodwith
threestrongbaselines.Ourapproachyieldssuperiorquanti-
tativeresultsandattainsthehighestratingsinuserstudies.
Dataset Methods FID↓ KID↓ Overallquality↑ Fidelity↑
TEXTure 94.6 0.044 2.43 2.41
Wooden
Text2tex 102.1 0.048 2.35 2.51 Nightstand
Chair
Fantasia3D 113.7 0.055 1.98 2.08
Ours 88.3 0.037 4.33 3.35
TEXTure 118.0 0.027 2.65 2.41
Text2tex 109.8 0.020 3.10 2.94
ABO
Fantasia3D 138.1 0.034 1.51 1.80
Ours 87.3 0.014 4.10 3.22
Toy
baselineusesthesameprompts.Thesegmentationoftheeachinput Rocket
shapeisobtainedbyfindingconnectedcomponents.
Moreover,wealsoconductedauserstudytoassesstherendering
results.Eachrespondentwasaskedtoevaluatetheresultsbasedon
twoaspects:overallqualityandfidelitytothetextprompt,using
ascaleof1to5.Overallqualityreferstothevisualqualityofthe
renderingresults,whilefidelitytothetextpromptindicateshow
closelytheseresultsalignwiththegiventextprompt.Therewere
Brand-new
40usersparticipatedinthestudy,including16professionalartists
Sword
and24membersofthegeneralpublic.Wegathered60responses
MaPa (Ours) TEXTure Text2tex Fantasia3D
fromeachparticipant,andthefinalscorerepresentstheaverageof
Figure4:Qualitativecomparisons.Theresultsgeneratedby
alltheseresponses.AsshowninTable1,ourmethodachievesthe
ourmethodandallthebaselinesarerenderedinthesame
bestquantitativeresultsandthehighestuserstudyscores.
CGenvironmentforcomparison.Thepromptsforthethree
Qualitativecomparison. Wecollectseveralhigh-quality3Dmod- objectsare:"aphotoofawoodenbedsidetable,""aphotoof
elsfromSketchfab[SketchFab2012]andusethesedataforqualita- atoyrocket,"and"aphotoofabrand-newsword."
tiveexperiments.AsshowninFigure4,ourmethodcanachieve
morerealisticrenderingresultsthanthebaselines.TEXTureand
Text2texarepronetoproduceinconsistenttextures,whichmakes
theirresultslookdirty.Fantasia3D’sresultsfrequentlyexhibitover-
saturationorfaildirectly.
4.3 Morequalitativeresults
Diversityofresults. 2Ddiffusionmodelcangeneratedifferent
imageswithdifferentseeds,whichnaturallybringsdiversitytoour
frameworkwhenoptimizingmaterialaccordingtothegenerated
images.WeshowanexampleshapewithdiverseresultsinFigure5.
Notehowthepaintedmaterialschangewhendifferentimagesof
thesameobjectaregenerated. Figure5:Diversityofourgeneratedmaterial.Weshowthe
diversityofresultssynthesizedbyourframeworkwiththe
Appearancetransferfromimageprompt. Wecanusetheimage
sameprompt:“Aphotoofatoyairplane”.Imagesinthefirst
encoderintroducedinIP-Adapter[Yeetal.2023]tobecompatible
rowaregeneratedbydiffusionmodels,andmodelsinthe
withimageprompt.AsshowninFigure6,ourmethodcantransfer
secondrowareourpaintedmeshes.
theappearancefromthereferenceimagetotheinputobjectsby
firstgeneratingthecorrespondingimageofthegivenobjectwith
similarappearanceandthenoptimizingthematerialsusingour Downstreameditingresults. Ourmethodcaneditmaterialsbased
framework. onuser-providedprompts,andweshowseveraleditingresultsona
baginFigure7.Wecanseethatweareabletoadddifferentpatterns
Results on watertight meshes. Although we mainly focus on
tothebagaccordingtotheprompts.
meshesthatcanbesegmentedbygroupingconnectedcomponents,
ourmethodcanalsohandlewatertightmeshes.InFigure9,wealso
showtheresultsofpaintedwatertightmeshes.Weusethegraph 4.4 Ablationstudies
cutalgorithm[KatzandTal2003]tosegmentthewatertightmesh, Thesignificanceofalbedoestimationnetwork. Tojustifytheusage
andthenwegeneratematerialsforeachsegment. ofouralbedoestimationnetwork,wecomparewiththesettingMaPa:Text-drivenPhotorealisticMaterialPaintingfor3DShapes SIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA
Original Image Transform into a texture with a maze-like style
Reference Images Input Meshes Our Results Generated Images
Figure 6: Appearance transfer. Our method can also take
imagepromptasinput,transferringtheappearanceofrefer-
enceimagestoinputobjects.
“w/oAlbedo”,whereweremovethismodulefromourmethodand
usethegeneratedimagedirectly.AsillustratedinFigure10,the
baseline“w/oAlbedo”failstomergethesegmentswiththesimilar
Turn into a floral and ornate pattern Change into a texture featuring the natural
color,hinderedbytheimpactsofshadowandlighting.Additionally, curve of tree branches
anoticeablecolordisparityexistsbetweentherenderingresultof
“w/oAlbedo”andthegeneratedimage. Figure7:Resultsofdownstreamediting.Weperformtext-
driveneditingongeneratedmaterialthroughtheGPT-4and
Robustness analysis of grouping results. Our method can also
asetofpredifinedAPIs.
workwithoutmaterialgrouping.Weshowtheresultsofourmethod
withoutmaterialgroupinginFigure10,referredas“w/oGrouping”.
Theresultsof“w/oGrouping”arenotsignificantlydifferentfrom toguidethepredictionofthisrepresentation.Ourresultsyield
ourresults.However,theoptimizationtimewillbemuchlonger photorealistic renderings that are also conveniently flexible for
withoutgrouping.Wefindourmethodtakes7minutesonaverage editing.Itisworthexploringwaystotrainanamortizedinference
tofinishthealloptimizationprocesspershape.Ifweremovethe networkthatcandirectlypredicttheparametersofthematerial
materialgrouping,theoptimizationtimeonaveragewillincrease graphfromtheinputimagetohighlyimprovetheefficiency.Our
to33minutes. limitationsareasfollows:
Thesignificanceofmaterialgraphoptimization. Wealsoshow Domaingapofgeneratedimages. Ourmethodsometimesfails
somerepresentativevisualcomparisonswiththesetting“w/oOpt”, togeneraterenderingresultsthatmatchthegeneratedimage,as
wherethematerialgraphisselectedwithoutfurtheroptimizationin showninFigure8,mainlyduetothedifferentdomainofthedif-
Figure11.Wecanclearlyseethattheoptimizationhighlyincreases fusionmodelandouralbedoestimationnetwork.Thisisbecause
theappearancesimilaritytothegeneratedimagesandisnotlimited thediffusionmodelistrainedonnaturalimages,whileouralbedo
bythesmallmaterialgraphdataset.Generatedimages(a),(b),and estimationnetworkistrainedonsyntheticimages.Wesuggestthat
(c) are generated under the same pose. The retrieval results of fine-tuningthediffusionmodelonsyntheticimagescouldmitigate
thewoodmaterialgraphinthethreeimagesarethesameshown thisissue.Alternatively,employingamoreadvancedalbedoesti-
as “w/o Opt”. This proves that even if our material graph data mationnetworkcouldpotentiallyserveasareplacementforour
setissmall,ourmethodcanstillproducediversetextureresults. currentalbedoestimationnetwork.Moreover,wecurrentlyuse
We also conduct an ablation study on effectiveness of residual GPT-4vformaterialclassificationaswefoundthatitsperformance
lighting,refereedas“w/oRes”.Comparedtoourresult(a),“w/o isbetterthanotherpriorworks,anditwouldbeeasytobereplaced
Res”producestexturesthatareinconsistentwiththegenerated ifmorepowerfulmethodsformaterialclassificationcomeout.
images.Thisisbecausetheinitial2Dspatially-varyinglightingis
notveryaccurate,whichiscausedbythedomaingapbetweenthe Complexobjectswithunobvioussegments. Forcomplexobjects
withunobvioussegments,wetendtoover-segmenttheshapeand
trainingdataofInvRenderNetandtheimagesgeneratedbythe
thengroupthesegmentswithsimilarmaterialsaccordingtothe
diffusionmodel.
generatedimage.Finalresultswilldependonover-segmentations
andthesegment-conditionedControlNetmayfailtoproducerea-
5 CONCLUSIONS
sonableguidanceforgroupingduetothelackoftrainingdataof
In this paper, we propose a novel method for generating high-
suchcomplexobjects.
qualitymaterialmapforinput3Dmeshes.Weintroducesegment-
wiseproceduralmaterialgraphsrepresentationforthischallenging Expressivenessofthematerialgraph. Thematerialcanbeopti-
taskandadoptapre-trained2Ddiffusionmodelasanintermediary mizedtoproducespatiallyvaryingappearanceonlyifthematerialSIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA Zhang,S.etal
JasmineCollins,ShubhamGoel,KenanDeng,AchleshwarLuthra,LeonXu,Erhan
Gundogdu,XiZhang,TomasFYagoVicente,ThomasDideriksen,HimanshuArora,
MatthieuGuillaumin,andJitendraMalik.2022.ABO:DatasetandBenchmarksfor
Real-World3DObjectUnderstanding.CVPR(2022).
Jan-NiklasDihlmann,AndreasEngelhardt,andHendrikLensch.2024.SIGNeRF:Scene
IntegratedGenerationforNeuralRadianceFields.arXivpreprintarXiv:2401.01647
Generated Image Albedo Image Result (2024).
ShinFujieda,KoheiTakayama,andToshiyaHachisuka.2017.Waveletconvolutional
Figure8:Failurecase.Becauseoftheunusuallighteffects
neuralnetworksfortextureclassification.arXivpreprintarXiv:1707.07394(2017).
generatedbydiffusion(silvermetallicwithyellowlight),the RinonGal,YuvalAlaluf,YuvalAtzmon,OrPatashnik,AmitH.Bermano,GalChechik,
albedoestimationnetworkfailstoaccuratelyestimatethe andDanielCohen-Or.2022.AnImageisWorthOneWord:PersonalizingText-to-
ImageGenerationusingTextualInversion. https://doi.org/10.48550/ARXIV.2208.
albedo,leadingtodissimilarmaterialprediction. 01618
ShanghuaGao,ZhijieLin,XingyuXie,PanZhou,Ming-MingCheng,andShuicheng
graphcontainssomecorrespondingnodesforoptimization,asthe Yan.2023.EditAnything:EmpoweringUnparalleledFlexibilityinImageEditingand
woodmaterialshowninFigure11.Currently,mostoftheother Generation.InProceedingsofthe31stACMInternationalConferenceonMultimedia,
Demotrack.ACM,Ottawa,ON,Canada.
materialsweusedlacksuchnodes,andthecomplexlookinFig- DaryaGuarnera,GiuseppeClaudioGuarnera,AbhijeetGhosh,CorneliaDenk,and
ure 7indeedcomes fromthe downstream editingbyretrieving MashhudaGlencross.2016. BRDFrepresentationandacquisition.InComputer
predefinedpatterns.Weechothatthemethodcouldhandlemore
GraphicsForum,Vol.35.WileyOnlineLibrary,625–650.
ZhenhuaGuo,LeiZhang,andDavidZhang.2010.Acompletedmodelingoflocalbinary
complextargetsifwehavealargercollectionofgraphswithmore patternoperatorfortextureclassification.IEEEtransactionsonimageprocessing19,
expressiveness. 6(2010),1657–1663.
TanmayGuptaandAniruddhaKembhavi.2023.Visualprogramming:Compositional
visualreasoningwithouttraining.InProceedingsoftheIEEE/CVFConferenceon
ACKNOWLEDGMENTS ComputerVisionandPatternRecognition.14953–14962.
MartinHeusel,HubertRamsauer,ThomasUnterthiner,BernhardNessler,andSepp
WewouldliketothankXiangyuSuforhisvaluablecontributions
Hochreiter.2017.Ganstrainedbyatwotime-scaleupdateruleconvergetoalocal
toourdiscussions.ThisworkwaspartiallysupportedbyNSFC(No. nashequilibrium.Advancesinneuralinformationprocessingsystems30(2017).
62172364andNo.62322207),AntGroupandInformationTechnol- JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilistic
models.Advancesinneuralinformationprocessingsystems33(2020),6840–6851.
ogyCenterandStateKeyLabofCAD&CG,ZhejiangUniversity. DianeHu,LiefengBo,andXiaofengRen.2011.TowardRobustMaterialRecognition
forEverydayObjects..InBMVC,Vol.2.Citeseer,6.
RuizhenHu,XiangyuSu,XiangkaiChen,OliverVanKaick,andHuiHuang.2022b.
REFERENCES
Photo-to-shapematerialtransferfordiversestructures. ACMTransactionson
Adobe.2021.3Ddesignsoftwareforauthoring-AdobeSubstance3D—adobe.com. Graphics(TOG)41,4(2022),1–14.
https://www.adobe.com/products/substance3d-designer.html. YiweiHu,ChenganHe,ValentinDeschaintre,JulieDorsey,andHollyRushmeier.2022a.
SeanBell,PaulUpchurch,NoahSnavely,andKavitaBala.2015.Materialrecognitionin Aninverseproceduralmodelingpipelineforsvbrdfmaps.ACMTransactionson
thewildwiththematerialsincontextdatabase.InProceedingsoftheIEEEconference Graphics(TOG)41,2(2022),1–17.
oncomputervisionandpatternrecognition.IEEEComputerSociety,Boston,MA, BrianKaris.2013. Realshadinginunrealengine4. Proc.PhysicallyBasedShading
USA,3479–3487. TheoryPractice4,3(2013),1.
MikolajBinkowski,DanicaJ.Sutherland,MichaelArbel,andArthurGretton.2018. SagiKatzandAyelletTal.2003.Hierarchicalmeshdecompositionusingfuzzyclustering
DemystifyingMMDGANs.InInternationalConferenceonLearningRepresentations. andcuts.ACMtransactionsongraphics(TOG)22,3(2003),954–961.
OpenReview.net,Vancouver,BC,Canada,pp. DiederikPKingmaandJimmyBa.2014.Adam:Amethodforstochasticoptimization.
JoanBrunaandStéphaneMallat.2013.Invariantscatteringconvolutionnetworks.IEEE arXivpreprintarXiv:1412.6980(2014).
transactionsonpatternanalysisandmachineintelligence35,8(2013),1872–1886. AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,Laura
JohnCanny.1986.Acomputationalapproachtoedgedetection.IEEETransactionson Gustafson,TeteXiao,SpencerWhitehead,AlexanderCBerg,Wan-YenLo,etal.
patternanalysisandmachineintelligence8,6(1986),679–698. 2023.Segmentanything.arXivpreprintarXiv:2304.02643(2023).
TianshiCao,KarstenKreis,SanjaFidler,NicholasSharp,andKangxueYin.2023. SvetlanaLazebnik,CordeliaSchmid,andJeanPonce.2005.Asparsetexturerepresen-
Texfusion:Synthesizing3dtextureswithtext-guidedimagediffusionmodels.In tationusinglocalaffineregions.IEEEtransactionsonpatternanalysisandmachine
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.IEEE, intelligence27,8(2005),1265–1278.
Paris,France,4169–4181. BeichenLi,LiangShi,andWojciechMatusik.2023. End-to-EndProceduralMate-
BarbaraCaputo,EricHayman,andPMallikarjuna.2005. Class-specificmaterial rialCapturewithProxy-FreeMixed-IntegerOptimization.ACMTransactionson
categorisation.InTenthIEEEInternationalConferenceonComputerVision(ICCV’05) Graphics(TOG)42,4(2023),1–15.
Volume1,Vol.2.IEEE,1597–1604. JunnanLi,DongxuLi,CaimingXiong,andStevenHoi.2022. Blip:Bootstrapping
DaveZhenyuChen,YawarSiddiqui,Hsin-YingLee,SergeyTulyakov,andMatthias language-imagepre-trainingforunifiedvision-languageunderstandingandgener-
Nießner.2023b.Text2tex:Text-driventexturesynthesisviadiffusionmodels.arXiv ation.InInternationalConferenceonMachineLearning.PMLR,12888–12900.
preprintarXiv:2303.11396(2023). ZhengqinLi,MohammadShafiei,RaviRamamoorthi,KalyanSunkavalli,andMan-
RuiChen,YongweiChen,NingxinJiao,andKuiJia.2023a. Fantasia3D:Disentan- mohanChandraker.2020. Inverserenderingforcomplexindoorscenes:Shape,
glingGeometryandAppearanceforHigh-qualityText-to-3DContentCreation.In spatially-varyinglightingandsvbrdffromasingleimage.InProceedingsofthe
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision(ICCV). IEEE/CVFConferenceonComputerVisionandPatternRecognition.2475–2484.
YongweiChen,RuiChen,JiabaoLei,YabinZhang,andKuiJia.2022.TANGO:Text- Chen-HsuanLin,JunGao,LumingTang,TowakiTakikawa,XiaohuiZeng,XunHuang,
drivenPhotorealisticandRobust3DStylizationviaLightingDecomposition.InAd- KarstenKreis,SanjaFidler,Ming-YuLiu,andTsung-YiLin.2023.Magic3D:High-
vancesinNeuralInformationProcessingSystems,S.Koyejo,S.Mohamed,A.Agarwal, ResolutionText-to-3DContentCreation.InIEEEConferenceonComputerVision
D.Belgrave,K.Cho,andA.Oh(Eds.),Vol.35.CurranAssociates,Inc.,30923–30936. andPatternRecognition(CVPR).
ZhileChen,FengLi,YuhuiQuan,YongXu,andHuiJi.2021.Deeptexturerecognition CeLiu,LavanyaSharan,EdwardHAdelson,andRuthRosenholtz.2010.Exploring
viaexploitingcross-layerstatisticalself-similarity.InProceedingsoftheIEEE/CVF featuresinabayesianframeworkformaterialrecognition.In2010ieeecomputer
conferenceonComputerVisionandPatternRecognition.5231–5240. societyconferenceoncomputervisionandpatternrecognition.IEEE,239–246.
Yen-ChiCheng,Hsin-YingLee,SergeyTulyakov,AlexanderGSchwing,andLiang- Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tokmakov, Sergey Zakharov,
YanGui.2023. Sdfusion:Multimodal3dshapecompletion,reconstruction,and and Carl Vondrick. 2023. Zero-1-to-3: Zero-shot One Image to 3D Object.
generation.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand arXiv:2303.11328[cs.CV]
PatternRecognition.4456–4465. XiaoxiaoLong,Yuan-ChenGuo,ChengLin,YuanLiu,ZhiyangDou,LingjieLiu,Yuexin
MirceaCimpoi,SubhransuMaji,andAndreaVedaldi.2014.Deepconvolutionalfilter Ma,Song-HaiZhang,MarcHabermann,ChristianTheobalt,etal.2023.Wonder3d:
banksfortexturerecognitionandsegmentation. arXivpreprintarXiv:1411.6836 Singleimageto3dusingcross-domaindiffusion.arXivpreprintarXiv:2310.15008
(2014). (2023).
MirceaCimpoi,SubhransuMaji,andAndreaVedaldi.2015. Deepfilterbanksfor GalMetzer,EladRichardson,OrPatashnik,RajaGiryes,andDanielCohen-Or.2022.
texturerecognitionandsegmentation.InProceedingsoftheIEEEconferenceon Latent-NeRFforShape-GuidedGenerationof3DShapesandTextures. arXiv
computervisionandpatternrecognition.3828–3836. preprintarXiv:2211.07600(2022).MaPa:Text-drivenPhotorealisticMaterialPaintingfor3DShapes SIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA
SamuelAMinaker,RyanHMason,andDavidRChow.2021. OptimizingColor
PerformanceoftheNgenuity3-DimensionalVisualizationSystem.Ophthalmology
Science1,3(2021),100054.
KaichunMo,ShilinZhu,AngelXChang,LiYi,SubarnaTripathi,LeonidasJGuibas,and
HaoSu.2019.Partnet:Alarge-scalebenchmarkforfine-grainedandhierarchical
part-level3dobjectunderstanding.InProceedingsoftheIEEE/CVFconferenceon
computervisionandpatternrecognition.909–918.
ThomasMüller,AlexEvans,ChristophSchied,andAlexanderKeller.2022. Instant
NeuralGraphicsPrimitiveswithaMultiresolutionHashEncoding. ACMTrans.
Graph.41,4,Article102(July2022),15pages. https://doi.org/10.1145/3528223.
3530127
AlexNichol,PrafullaDhariwal,AdityaRamesh,PranavShyam,PamelaMishkin,Bob
McGrew,IlyaSutskever,andMarkChen.2021. Glide:Towardsphotorealistic
imagegenerationandeditingwithtext-guideddiffusionmodels. arXivpreprint
arXiv:2112.10741(2021).
ROpenAI.2023.GPT-4technicalreport.arXiv(2023),2303–08774.
KeunhongPark,KonstantinosRematas,AliFarhadi,andStevenMSeitz.2018.Pho-
toshape:Photorealisticmaterialsforlarge-scaleshapecollections.arXivpreprint
arXiv:1809.09761(2018).
BenPoole,AjayJain,JonathanT.Barron,andBenMildenhall.2022. DreamFusion:
Text-to-3Dusing2DDiffusion.arXiv(2022).
EladRichardson,GalMetzer,YuvalAlaluf,RajaGiryes,andDanielCohen-Or.2023.
Texture:Text-guidedtexturingof3dshapes.arXivpreprintarXiv:2302.01721(2023).
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjörnOmmer.
2022.High-resolutionimagesynthesiswithlatentdiffusionmodels.InProceedings
oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.10684–10695.
NatanielRuiz,YuanzhenLi,VarunJampani,YaelPritch,MichaelRubinstein,and
KfirAberman.2023.Dreambooth:Finetuningtext-to-imagediffusionmodelsfor
subject-drivengeneration.InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition.
GauravSharma,WenchengWu,andEdulNDalal.2005. TheCIEDE2000color-
differenceformula:Implementationnotes,supplementarytestdata,andmath-
ematicalobservations.ColorResearch&Application:EndorsedbyInter-SocietyColor
Council,TheColourGroup(GreatBritain),CanadianSocietyforColor,ColorScience
AssociationofJapan,DutchSocietyfortheStudyofColor,TheSwedishColourCentre
Foundation,ColourSocietyofAustralia,CentreFrançaisdelaCouleur30,1(2005),
21–30.
PrafullSharma,JulienPhilip,MichaëlGharbi,BillFreeman,FredoDurand,andValentin
Deschaintre.2023. Materialistic:Selectingsimilarmaterialsinimages. ACM
TransactionsonGraphics(TOG)42,4(2023),1–14.
LiangShi,BeichenLi,MilošHašan,KalyanSunkavalli,TamyBoubekeur,Radomir
Mech,andWojciechMatusik.2020. Match:Differentiablematerialgraphsfor
proceduralmaterialcapture. ACMTransactionsonGraphics(TOG)39,6(2020),
1–15.
SketchFab2012.Sketchfab-Thebest3Dviewerontheweb—sketchfab.com.https:
//sketchfab.com/.
JiamingSong,ChenlinMeng,andStefanoErmon.2020.Denoisingdiffusionimplicit
models.arXivpreprintarXiv:2010.02502(2020).
PaulUpchurchandRansenNiu.2022. Adensematerialsegmentationdatasetfor
indoorandoutdoorsceneparsing.InEuropeanConferenceonComputerVision.
Springer,450–466.
KaiYan,FujunLuan,MilošHašan,ThibaultGroueix,ValentinDeschaintre,andShuang
Zhao.2023.PSDR-Room:SinglePhototoSceneusingDifferentiableRendering.In
SIGGRAPHAsia2023ConferencePapers.1–11.
HuYe,JunZhang,SiboLiu,XiaoHan,andWeiYang.2023.IP-Adapter:TextCompatible
ImagePromptAdapterforText-to-ImageDiffusionModels.(2023).
Yu-YingYeh,Jia-BinHuang,ChangilKim,LeiXiao,ThuNguyen-Phuoc,NumairKhan,
ChengZhang,ManmohanChandraker,CarlMarshall,ZhaoDong,andZhengqinLi.
2024.TextureDreamer:Image-guidedTextureSynthesisthroughGeometry-aware
Diffusion.ArXivabs/2401.09416(2024).
Yu-YingYeh,ZhengqinLi,YannickHold-Geoffroy,RuiZhu,ZexiangXu,MilošHašan,
KalyanSunkavalli,andManmohanChandraker.2022.Photoscene:Photorealistic
materialandlightingtransferforindoorscenes.InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition.18562–18571.
XinYu,PengDai,WenboLi,LanMa,ZhengzheLiu,andXiaojuanQi.2023.Texture
Generationon3DMesheswithPoint-UVDiffusion.InProceedingsoftheIEEE/CVF
InternationalConferenceonComputerVision.4206–4216.
XianfangZeng.2023.Paint3D:PaintAnything3DwithLighting-LessTextureDiffusion
Models.arXivpreprintarXiv:2312.13913(2023).
LvminZhang,AnyiRao,andManeeshAgrawala.2023.AddingConditionalControl
toText-to-ImageDiffusionModels.
JunweiZheng,JiamingZhang,KailunYang,KunyuPeng,andRainerStiefelhagen.
2023. MATERobot:MaterialRecognitioninWearableRoboticsforPeoplewith
VisualImpairments.arXivpreprintarXiv:2302.14595(2023).SIGGRAPHConferencePapers’24,July27-August1,2024,Denver,CO,USA Zhang,S.etal
Generated Image Albedo Segments Material Groups Results
Figure9:Resultsonwatertightmeshes.Wedecomposethemeshintoseveralsegmentsusingthegraphcutalgorithmand
generatematerialsforeachsegment.Thetextpromptsforthosetwoexamplesare“Aphotoofamodernchairwithbrownlegs”
and"Ablackandwhiteeyeglass",respectively.
Generated Image Input Segments Material Groups Material Groups
(Ours) (w/o Albedo)
Albedo Image Rendering Results Rendering Results Rendering Results
(Ours) (w/o Grouping) (w/o Albedo)
Figure10:Ablationstudyof“w/oAlbedo”and“w/oGrouping”.Examplewithtextprompt“Adarkbrownleathersofa”.“w/o
Albedo”exhibitscolordisparitybetweentherenderingresultandgeneratedimage,andfailstomergesegmentswithsimilar
color.“w/oGrouping”hassimilarrenderingresultstoourmethod.
Generated Image (a) Our Result (a) w/o Opt w/o Res
Generated Image (b) Our Result (b) Generated Image (c) Our Result (c)
Figure11:Ablationstudyofourmaterialgraphoptimization.Weshowtheablationstudyofourmaterialgraphoptimization
andtheeffectivenessofresiduallight.Thebaseline“w/oOpt”and“w/oRes”areoptimizedtominimizethelossofthegenerated
image(a)andtherenderedimage.Thegeneratedimage(b)and(c)areusedtoprovethatourmethodcanyielddiverseresults
evenwithasmallmaterialgraphdataset.