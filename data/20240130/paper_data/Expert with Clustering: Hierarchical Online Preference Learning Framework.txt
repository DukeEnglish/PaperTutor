ProceedingsofMachineLearningResearchvolvvv:1–12,2024
Expert with Clustering: Hierarchical Online Preference Learning
Framework
TianyueZhou ZHOUTY1@SHANGHAITECH.EDU.CN
ShanghaiTechUniversity
Jung-HoonCho JHOONCHO@MIT.EDU
MassachusettsInstituteofTechnology
BabakRahimiArdabili BRAHIMIA@CHARLOTTE.EDU
HamedTabkhi HTABKHIV@CHARLOTTE.EDU
UniversityofNorthCarolinaatCharlotte
CathyWu CATHYWU@MIT.EDU
MassachusettsInstituteofTechnology
Abstract
Emerging mobility systems are increasingly capable of recommending options to mobility
users,toguidethemtowardspersonalizedyetsustainablesystemoutcomes. Evenmoresothanthe
typicalrecommendationsystem,itiscrucialtominimizeregret,because1)themobilityoptions
directly affect the lives of the users, and 2) the system sustainability relies on sufficient user
participation. Inthisstudy,wethusconsideracceleratinguserpreferencelearningbyexploitinga
low-dimensionallatentspacethatcapturesthemobilitypreferencesofuserswithinapopulation. We
thereforeintroduceahierarchicalcontextualbanditframeworknamedExpertwithClustering(EWC),
whichintegratesclusteringtechniquesandpredictionwithexpertadvice. EWCefficientlyutilizes
hierarchicaluserinformationandincorporatesanovelLoss-guidedDistancemetric. Thismetricis
instrumentalingeneratingmorerepresentativeclustercentroids,therebyenhancingtheperformance
ofrecommendationsystems. InarecommendationscenariowithN users,T roundsperuser,and
√
K options,ouralgorithmachievesaregretboundofO(N T logK+NT). Thisboundconsists
oftwoparts: thefirsttermistheregretfromtheHedgealgorithm,andthesecondtermdepends
ontheaveragelossfromclustering. Thealgorithmperformswithlowregret,especiallywhena
latenthierarchicalstructureexistsamongusers. Thisregretboundunderscoresthetheoreticaland
experimentalefficacyofEWC,particularlyinscenariosthatdemandrapidlearningandadaptation.
Experimental results highlight that EWC can substantially reduce regret by 27.57% compared
totheLinUCBbaseline. Ourworkoffersadata-efficientapproachtocapturingbothindividual
andcollectivebehaviors,makingithighlyapplicabletocontextswithhierarchicalstructures. We
expectthealgorithmtobeapplicabletoothersettingswithlayerednuancesofuserpreferencesand
information.
Keywords:Onlinepreferencelearning,Contextualbandit,Clustering,Eco-drivingrecommendation,
Expertadvice
1. Introduction
Emerging mobility systems are increasingly pivotal in designing efficient and sustainable transit
networks. Thesesystemswithadvancedtechnologieshavethepotentialtorevolutionizehowwenav-
igateurbanenvironments,therebyenhancingtheoverallefficiencyoftransportationsystems. Recent
workaimstominimizeemissionsthrougheco-drivingrecommendationsystems,thuscontributingto
environmentalsustainability(Tuetal.(2022);Chadaetal.(2023)).
Thechallengeliesinthecomplexnatureofdrivers’preferences,whichareshapedbyvarious
factors such as personal schedules, environmental concerns, and the unpredictability of human
©2024T.Zhou,J.-H.Cho,B.R.Ardabili,H.Tabkhi&C.Wu.
4202
naJ
62
]GL.sc[
1v26051.1042:viXraZHOUCHOARDABILITABKHIWU
Figure1: IllustrativefigureforExpertwithClusteringalgorithm.
behavior. To tackle this, we advocate for the contextual bandit algorithm, a framework adept at
learning from and adapting to the driver’s unique context. This algorithm is poised to accurately
capture the subtle preferences of drivers, offering nuanced insights into their decision-making
processesinever-changingenvironments.
Ourproblemdeviatesfromaclassicalcontextualbanditscenario. Itresemblessupervisedonline
learning,asthedriver’schoiceisknownafterthesystemprovidesrecommendations. However,this
choicemaybeinfluencedbytherecommendationitself,leadingtovaryingobservedrewards. This
variationcloselymirrorsthestructureofabanditproblem,whereactionsinfluenceobservedoutcomes.
Thus, our problem can be considered a specialized variant of the bandit problem, incorporating
elementsofbothsupervisedlearningandadaptivedecision-makingtypicalofbanditscenarios.
Our research focuses on refining online learning algorithms tailored to the contextual bandit
framework,enhancingtheirabilitytodiscerntravelerpreferencesandpredictresponsestorouting
andtransitmoderecommendations. Inthispaper, weproposetheExpertwithClustering(EWC)
framework, a novel approach that synergizes clustering and prediction with expert advice. The
fundamentalconceptinvolvesusingclusteringtodiscernhierarchicalinformationamongusers,with
eachclusteractingasan‘expert’representingcommonuserpreferences. Thisapproachtransforms
theonlinepreferencelearningproblemintooneofpredictionwithexpertadvice. Foreachuser,an
expertisselectedtoapproximatetheirpreferences,enablingaccuraterecommendations.
1.1. RelatedWorks
Preferencelearningfordrivers. Thefieldofpreferencelearningfordrivershasfocusedonadaptive
modelsthatcatertoindividualdrivingbehaviorsanddecision-makingprocesses. Jalotaetal.(2022)
contributetothisdomainwiththeonlinelearningapproach,adjustingtraffictollsbasedonaggregate
flows to influence drivers towards more efficient routes, thus minimizing the need for detailed
personaltravelinformation. ThismethodresonateswiththeutilitarianperspectiveofChorusetal.
(2009), delving into how drivers’ preference with advice is shaped by their personal preferences
and perceptions of travel time uncertainty. Sadigh et al. (2017) explore the learning of human
preferencesfromcomparativechoicesbetweentrajectories,eschewingtheneedfordirectreward
signals. Collectively,theseworkshighlightatrendtowardmachinelearningthatisnotjustreactive
butanticipatoryandadaptabletothenuancedspectrumofhumandrivingpreferences.
Contextualbandits. Thecontextualbanditsframeworkhasemergedasanefficientapproachfor
recommendation systems. Originally introduced by Auer (2002), this framework delved into the
utilizationofconfidenceboundswithintheexploration-exploitationtrade-off,specificallyfocusing
2EXPERTWITHCLUSTERING: HIERARCHICALONLINEPREFERENCELEARNINGFRAMEWORK
on contextual bandits with linear value functions. Building upon this foundation, Li et al. (2010)
expanded the application of this concept to personalized news recommendations and proposed
LinUCBalgorithmwhichhassincebecomeabenchmarkinthefield.
Expertalgorithm. Thepredictionwithexpertadviceisafundamentalprobleminonlinelearning.
TheHedgealgorithm,alsorecognizedastheWeightedMajorityAlgorithmandinitiallyintroduced
byLittlestoneandWarmuth(1994),presentsanefficientapproachtoaddressingthischallenge. The
insightsofferedbytheHedgealgorithmhavesignificantlyinformedourdevelopmentoftheExpert
withClustering(EWC)framework. Intermsoftheoreticalperformance,FreundandSchapire(1997)
√
hasestablishedthattheHedgealgorithm’sregretboundisO( T logK). Thisregretboundprovides
afoundationfortheoreticalanalysingtheEWCframework.
Contextualbanditswithclustering. K-Meansclustering,aclassicunsupervisedlearningalgorithm,
wasfirstintroducedbyLloyd(1982). Withtheevolutionofbothcontextualbanditsandclustering
techniques,theconceptofclusteringuserswithincontextualbanditswasproposedbyGentileetal.
(2014), utilizing a graph to represent user similarities. To enhance the utilization of similarity
information,Lietal.(2016)combinedcollaborativefilteringwithcontextualbanditstoclusterboth
usersanditems. Furthermore,Gentileetal.(2017)introducedcontext-awareclustering,whereeach
itemcouldclusterusers.
Existingworksincontextualbanditstypicallyoverlookuserchoiceduetotheirclassicalframe-
work. Incontrast,ouruniqueproblemstructureincorporatesuserchoice,offeringinsightsintothe
comparativeutilityofdifferentoptions. Thisdistinctapproachallowsforacceleratingthepreference
learningwithinlimiteddata.
1.2. Contributions
Theprimarycontributionsofthisworkareoutlinedasfollows:
1. We introduce the novel hierarchical contextual bandit framework, Expert with Clustering
(EWC),whichintegratesclusteringandpredictionwithexpertadvicetoaddresstheonline
preferencelearningproblem. Thisframeworkeffectivelyutilizeshierarchicaluserinformation,
enablingrapidandaccuratelearningofuserpreferences.
2. We propose a new distance metric, Loss-guided Distance, which enhances the representa-
tivenessofcentroids. ThisadvancementsignificantlyimprovestheperformanceoftheEWC
framework,demonstratingitspracticaleffectiveness.
3. WeestablishtheregretboundofEWCasasumoftwocomponents: theregretfromtheHedge
algorithm and the bias introduced by representing users with centroids, indicating superior
theoretical performance in the short term and enhanced overall experimental performance
comparedtotheLinUCBalgorithm(Lietal.(2010)).
2. ProblemFormulation
ConsiderthescenariowhereasocialplanneristaskedwithrecommendingmobilityoptionsR,where
A := |R|,toapopulationofdrivers. Eachmobilityoptionisparameterizedbyatravelinformation
vectorx ∈ Rd,whichspecifiesrelevanttravelmetrics. Forsimplicity,weconsidertwomobility
i,t
options (A = 2), each with two relevant travel metrics (d = 2), although the framework extends
gracefullytomoreoptionsandmetrics. Thus,ateachdecisionpointforauser,thesocialplanner
facesachoicebetweentworouteoptions: route1,thestandardroutewithregulartraveltimeand
emissions,androute2,aneco-friendlyalternativethat,whileofferingreducedemissions,comeswith
3ZHOUCHOARDABILITABKHIWU
anincreasedtraveltime. Intuitively,inthissimplifiedexample,thesocialplannerseekstoquickly
identify users who prefer travel time or environmental impact while ensuring user participation,
inordertobestachievethesystemsustainability. Inthefuture,considerationsofmultiplesystem
objectivesandincentivestoshapeuserchoicescanbeincluded.
Foreachdecisionroundt,theusericomparetworoutesintermsoftheirrelativetraveltimeand
emissions. Let’sdenotethetraveltimeandemissionsforroute2relativetoroute1asτ ande ,
i,t i,t
respectively. Forexample,[τ ,e ] = [1.2,0.9]means120%oftraveltimeand90%ofemission.
i,t i,t
Travelinformationvectorforthisdecisionround,x ,isdefinedwithtwocomponentsfortworoutes:
i,t
x (1) = [1,1] and x (2) = [τ ,e ]. Based on this information, we issue a recommendation
i,t i,t i,t i,t
Rec ∈ {1,2},whereuponwereceivefeedbackintheformoftheuser’schoicey ∈ {1,2}. The
i,t i,t
objective of our system is to minimize the total regret: min (cid:80)N (cid:80)T |Rec −y |2,
Reci,t,∀i,t i=1 t=1 i,t i,t
whereN representthenumberofusersandT denotethetotalnumberofdecisionrounds.
3. ExpertwithClustering(EWC)
3.1. GeneralFramework
WeintroducetheExpertwithClustering(EWC)algorithm,anovelhierarchicalcontextualbandit
approach. EWCtransformsanonlinepreferencelearningproblemintoanexpertproblemandutilizes
theHedgealgorithmtoidentifythemosteffectiveexpert.
Prediction with expert advice is a classic online learning problem introduced by Littlestone
and Warmuth (1994). Consider a scenario where a decision-maker has access to the advice of
K experts. At each decision round t, advice from these K experts is available, and the decision
makerselectsanexpertbasedonaprobabilitydistributionp andfollowshisadvice. Subsequently,
t
the decision maker observes the loss of each expert, denoted as l ∈ [0,1]K. The primary goal
t
is to identify the best expert in hindsight, which essentially translates to minimizing the regret:
min (cid:80)T < p ,l > −(cid:80)T l (k∗),wherek∗ isthebestexpertthroughoutthetime.
pt,∀t t=1 t t t=1 t
We cast the online preference learning problem into the framework of prediction with expert
adviceinthefollowingway. Assumethateachuserhasafixedbutunknownpreferenceparameter
θ ∈ Rd. Given θ , we can make predictions using a known function yˆ(θ ,x ). The EWC
i i i i,t
algorithmoperatesundertheassumptionofaclusterstructurewithintheusers’preferenceparameters
{θ } . UtilizingasetofofflinetrainingdataD = {{x } ,{y } }where
i i∈[N] i,t i∈[N′],t∈[T′] i,t i∈[N′],t∈[T′]
N′ andT′ arenumberofusersanddecisionroundsintrainingdata,weinitiallyemployalearning
framework(suchasSVMornonlinearregression)todetermineeachuser’sθ . Despitedifferences
i
between training and testing data, both are sampled from the same distribution. This allows for
anapproximatedeterminationofθ ,providinginsightsintothehierarchicalstructureamongusers,
i
albeitwithsomedegreeofapproximation. Subsequently,aclusteringmethodisappliedtoidentify
centroids {c } . Each centroid is considered as an expert. Using the Hedge algorithm, we
k k∈[K]
initialize their weights and, at every online decision round, select an expert E ∈ [K]. The
i,t
recommendationRec = yˆ(c ,x )isthenformulated. Uponreceivingtheuser’schosenoption
i,t Ei,t i,t
y ,wecalculatethelossforeachexpertl andupdatetheweightsinHedgebasedonthisloss. The
i,t i,t
lossforeachexpertk isdeterminedbyaknownlossfunctionl (k) = l(yˆ(c ,x ),y ) ∈ R,e.g.,
i,t k i,t i,t
l(yˆ(c ,x ),y ) = 1 . ThedetailsofthisprocessareencapsulatedinAlgorithm1.
k i,t i,t yˆ(c k,xi,t)̸=yi,t
4EXPERTWITHCLUSTERING: HIERARCHICALONLINEPREFERENCELEARNINGFRAMEWORK
Algorithm1ExpertWithCluster
Require: NumberofclustersK,offlinetrainingdataD,learningrateη
TrainwithdataD,receive{θ }
i i∈[N′]
Applyclusteringon{θ } ,receivecentroids{c }
i i∈[N′] k k∈[K]
Initializeweightp (k) ← 1 foralli ∈ [N],k ∈ [K]
i,1 K
fort = 1,...,T do
fori = 1,...,N do
Receivex
i,t
SampleE ∼ p ,submitRec = yˆ(c ,x ),
i,t i,t i,t Ei,t i,t
Receivey ,computelossl (k) = l(yˆ(c ,x ),y )forallk ∈ [K]
i,t i,t k i,t i,t
p (k) ←
pi,t(k)e−ηli,t(k)
forallk ∈ [K]
i,t+1 (cid:80) k′∈[K]pi,t(k′)e−ηli,t(k′)
endfor
endfor
3.2. EWCforOnlinePreferenceLearning
WeimplementtheEWCalgorithmforonlinepreferencelearninginadrivingcontext. Foreachuser
i,alineardecisionboundaryisposited,characterizedbyparametersθ = [b ,s ,o ]. Here,b ands
i i i i i i
denotethebiasandslopeoftheline,ando denotestheorientationofthedecisionboundarythat
i
differentiatestheaffiliationofuser’schoice. θ classifiesthedatapoints[τ ,e ]intotwocategories:
i i,t i,t
optingfortheregularroute(y = 1)ortheeco-friendlyroute(y = 2).
i,t i,t
In the offline training phase, using the dataset D, a linear Support Vector Machine (SVM) is
initiallyemployedtodifferentiatethetwoclassesofdatapointsforeachuseri. Thisprocessyields
theparameters{θ } . Subsequently,K-Meansclusteringisappliedtoascertainthecentroids
i i∈[N′]
{c } oftheset{θ } ,whereeachcentroidisrepresentedasc = [b ,s ,o ].
k k∈[K] i i∈[N′] k k k k
Intheonlinelearningstage,first,theweightp(k)isinitializedforeachexpert. Foreverydecision
instancetpertainingtouseri,wecollectactiondatax . UtilizingtheHedgeAlgorithm,anexpert
i,t
E isselected,TherecommendationisthenformulatedasRec = yˆ(c ,x ),withyˆ(c ,x ) =
i,t i,t Ei,t i,t k i,t
1 Uponobtainingtheuser’schoicey ,thelossl (k) = |yˆ(c ,x )−y |2 is
o k(τi,t−s kei,t−b k)>0 i,t i,t k i,t i,t
computed,leadingtoanadjustmentofeachexpert’sweightaccordingly.
3.3. ClusteringwithLoss-guidedDistance
The core parameter influencing the regret in our model is the set of centroids {c } . An
k k∈[K]
accuratelyrepresentativesetofcentroidscansignificantlyreflectusers’behaviors,whereaspoorly
chosencentroidsmayleadtosuboptimalperformance. Inoursimulations,weobservedlimitations
with centroids generated by the standard K-Means algorithm. For instance, 1) a centroid c that
k
differs slightly from θ in the bias term but exceeds the decision boundary can misclassify many
i
points,resultinginhigherregret. 2)Incaseswherethereisahighfrequencyofy = 1,variationsin
i,t
slopeandbiasdonotsubstantiallyaffecttheregretaslongastheyaredistancedfromthey = 1
i,t
points. This implies that centroids with similar θ values do not necessarily yield comparable
i
performances,whiledistinctθ valuescansometimesachievesimilaroutcomes.
i
To address this issue, we introduce a novel distance metric for clustering guided by the loss
function. Ourobjectiveistoensurethatθ valueswithinthesameclusterexhibitsimilarperformance.
i
5ZHOUCHOARDABILITABKHIWU
Thus,wereplacethetraditionalL normdistancewiththepredictionlossincurredwhenassigningc
2 k
touseri. Here,wedefine: x = [x ,x ,...,x ] ∈ RT′×A×dandy = [y ,y ,...,y ] ∈ RT′ ,
i i,1 i,2 i,T′ i i,1 i,2 i,T′
while yˆ(c ,x ) = [yˆ(c ,x ),yˆ(c ,x ),...,yˆ(c ,x )] ∈ RT′ . The Loss-guided Distance is
k i k i,1 k i,2 k i,T′
definedasdist(i,c ) = ||yˆ(c ,x )−y ||2. ThedetailedclusteringispresentedinAlgorithm2.
k k i i
Algorithm2K-MeanswithLoss-guidedDistance
Require: {θ }
i i∈[N′]
Randomlyinitializecentroids{c }
k k∈[K]
while{c } notconvergeddo
k k∈[K]
dist(i,c ) ← ||yˆ(c ,x )−y ||2 foralli ∈ [N′],k ∈ [K]
k k i i
r ← 1 foralli ∈ [N′],k ∈ [K]
i,k k=argmin k′dist(i,c k′)
c ←
(cid:80)N i=1r i,kθi
forallk ∈ [K]
k (cid:80)N r
i=1 i,k
endwhile
return {c }
k k∈[K]
4. Regretanalysis
4.1. RegretBoundofEWC
Beforedescribingourtheoreticalfindings,wefirstintroducesomebackgroundanddefinitions. In
theexpertproblem,spanningT totalroundswithK experts,wedenotethebestexpertthroughout
thedurationask∗. Theregretbound,asestablishedbyFreundandSchapire(1997),isexpressedas:
T
(cid:88) (cid:112)
R = (⟨p ,l ⟩−l (k∗)) ≤ 2 T logK (1)
Hedge t t t
t=1
ThelossofK-MeansalgorithmisdefineasL = (cid:80)N ||c −θ ||2,wherek(i)isthecluster
i=1 k(i) i
centroid assigned to θ . Consider {c } be any set of centroids, P as any distribution on Rd
i k k∈[K]
withmeanµ = E [θ ]andvarianceσ2 = E [||θ −µ||2]. AssumingfiniteKurtosis(4th moment)
P i P i
Mˆ < ∞ and given ϵ ∈ (0,1), δ ∈ (0,1) and a sample size m from P, we establish that for
4
m ≥
12800(8+Mˆ 4) (cid:0)
3+30K(d+4)log6K +log
1(cid:1)
,theUniformdeviationboundofK-Means,as
ϵ2δ δ
provenbyBachemetal.(2017),holdswithatleast1−δ probability:
ϵ ϵ
|L−E [L]| ≤ σ2+ E [L] (2)
P P
2 2
WedefinetheregretofEWCastheperformancedifferencebetweenEWCandOracleθ :
i
N T
R =
(cid:88)(cid:88)(cid:0)
⟨p ,l ⟩−|yˆ(θ ,x )−y
|2(cid:1)
(3)
EWC i,t i,t i i,t i,t
i=1 t=1
Whatfollowsisourmaintheoreticalresult. Hereweslightlyabusethenotationyˆ(θ ,x ) ∈ RT and
i i
y ∈ RT tobethepredictionanduser’schoicevectorintestingdata.
i
6EXPERTWITHCLUSTERING: HIERARCHICALONLINEPREFERENCELEARNINGFRAMEWORK
Theorem4.1(RegretBoundofEWC) Let P be any distribution of θ ∈ Rd with µ = E [θ ],
i P i
σ2 = E [||θ − µ||2], and finite Kurtosis. Let {c } be any set of centroids, k∗(i) be the
P i k k∈[K]
best expert for user i, L = (cid:80)N ||c −θ ||2 be the total squared distance of clustering, and
i=1 k∗(i) i
yˆ(θ ,x ) ∈ RT bethepredictionfunction. Ifyˆ(·,x )isLipschitzcontinuousforallx withLipschitz
i i i i
constantL,L normdistance,anddimensionnormalization,thenwithprobabilityatleast1−δ,the
2
regretofEWCisboundedby:
(cid:112) (cid:16)ϵ ϵ (cid:17)
R ≤ R = 2N T logK +TL σ2+( +1)E [L] (4)
EWC EWC P
2 2
Proof
N T
R
=(cid:88)(cid:88)(cid:0)
⟨p ,l ⟩−|yˆ(θ ,x )−y
|2(cid:1)
EWC i,t i,t i i,t i,t
i=1 t=1
N T
=(cid:88)(cid:88)(cid:0)
⟨p ,l ⟩−|yˆ(c ,x )−y
|2(cid:1)
i,t i,t k∗(i) i,t i,t
i=1 t=1
N T
+(cid:88)(cid:88)(cid:0) |yˆ(c ,x )−y |2−|yˆ(θ ,x )−y |2(cid:1)
k∗(i) i,t i,t i i,t i,t
i=1 t=1
N T N
=(cid:88)(cid:88) (⟨p ,l ⟩−l (k∗(i)))+(cid:88)(cid:0) ||yˆ(c ,x )−y ||2−||yˆ(θ ,x )−y ||2(cid:1)
i,t i,t t k∗(i) i i i i i
i=1 t=1 i=1
N
(cid:112) (cid:88)
≤2N T logK + ||yˆ(c ,x )−yˆ(θ ,x )||2
k∗(i) i i i
i=1
(5)
Since∃Ls.t. ∀i,∀θ ,θ , 1||yˆ(θ ,x )−yˆ(θ ,x )||2 ≤ L||θ −θ ||2
1 2 T 1 i 2 i 1 2
N N
(cid:88) (cid:88)
||yˆ(c ,x )−yˆ(θ ,x )||2 ≤ TL ||c −θ ||2
k∗(i) i i i k∗(i) i
(6)
i=1 i=1
= TLL ≤ TL(|L−E[L]|+E[L])
Byinequation2,withprobabilityatleast1−δ,
N
(cid:88) (cid:16)ϵ ϵ (cid:17)
||yˆ(c ,x )−yˆ(θ ,x )||2 ≤ TL σ2+( +1)E[L] (7)
k∗(i) i i i
2 2
i=1
(cid:112) (cid:16)ϵ ϵ (cid:17)
R ≤ 2N T logK +TL σ2+( +1)E[L] (8)
EWC
2 2
Corollary4.1.1 IfP isaGaussianMixtureModel(GMM)withKGaussiandistributions,eachof
whichhasweightπ ,meanµ ,andcovarianceΣ ,andtheclusteringoutputstheoptimalcentroids
k k k
where c = µ . Define l = L ϵ σ2 +L(ϵ +1)(cid:80)K π trace(Σ ) be the average loss
k k centroids 2N 2 k=1 k k
causedbycentroids. Withprobabilityatleast1−δ,theregretofEWCisboundedby
(cid:112)
R ≤ R = 2N T logK +TNl (9)
EWC EWC centroids
Proof Since c = µ , and P = (cid:80)K π N(µ ,Σ ), the expected squared distance is E[||θ −
k k k=1 k k k i
c ||2] = (cid:80)K π trace(Σ ). So,E[L] = NE[||θ −c ||2] = N (cid:80)K π trace(Σ ).
k(i) k=1 k k i k(i) k=1 k k
7ZHOUCHOARDABILITABKHIWU
4.2. Comparison
WecomparetheregretboundoftheEWCalgorithmwithLinUCBandoracleFollow-the-Leader
(oracleFTL).Follow-the-Leader(FTL)isastraightforwardmethodthatselectstheoptionwiththe
besthistoricalperformancek = argmin (cid:80)T l (k′). TheoracleFTLisanoraclemethodthatlets
k′ t=1 t
usknowthisbestoptioninhindsightandalwayschoosesitatdecisionrounds. Lemma4.2.1isthe
regretboundofSupLinUCB(avarientofLinUCB)whichhasbeenprovedbyLietal.(2010),and
lemma4.2.2istheregretboundoforacleFTL.Corollary4.2.1comparesEWCwithbothLinUCB
andOracleFTL.
Lemma4.2.1(RegretBoundofSupLinUCB) Assume ∀i,t,∃θ∗ ∈ Rd, s.t. E[l (a)|x (a)] =
i i,t i,t
(cid:16) (cid:17)
x (a)⊺ θ∗. DefineR = (cid:80)N (cid:80)T l (a )−l (a∗ ) wherea∗ = argmax x (a)⊺ θ∗.
i,t i LinUCB i=1 t=1 i,t i,t i,t i,t i,t a i,t
(cid:113)
IfSupLinUCBrunswithα = 1 ln 2TK,withprobabilityatleast1−δ,R < R =
2 δ LinUCB LinUCB
(cid:18) (cid:113) (cid:19)
O N Tdln3(KT lnT/δ) .
Lemma4.2.2(RegretBoundofOracleFTL) DefinetheregretoforacleFTLbeR =
OracleFTL
(cid:80)N (cid:80)T
l . Letp betheproportionofchoosingoption1foreachuseri. Theregretoforacle
i=1 t=1 i,t i
FTLisR =
(cid:80)N
T min{p ,1−p } = O(TN).
OracleFTL i=1 i i
Proof Sincewealwayschoosethebestoneofoptions{1,2}foreachuser,thenumberofwrong
predictionshouldbeT min{p ,1−p }. Sothetotalregretisthesummationofallusers.
i i
(cid:113)
Corollary4.2.1(AdvantageofEWC) 1) Assume R = CN Tdln3(KT lnT/δ), then
LinUCB
when T < ( C−2 )2, R < R . 2) When l < 1 (cid:80)N min{p ,1 − p } −
l EWC LinUCB centroids N i=1 i i
(cid:112) centroids
2 log(K)/T,R < R
EWC OracleFTL
√
Proof 1) Since R = 2N T logK + TNl , R < R is equivalent to
EWC centroids EWC LinUCB
√ (cid:113) √ √
Tl < c dln3(KT lnT/δ)−2 logK. So when Tl < c−2, the condition
centroids centroids
√
aboveissatisfied. 2)Dividing2N T logK +TNl
and(cid:80)N
T min{p ,1−p }byNT,
centroids i=1 i i
wecangetthesecondresult.
AshighlightedinCorollary4.2.1,EWCdemonstratessuperiortheoreticalperformancecompared
to LinUCB when T is relatively small. This advantage is contingent upon l which is
centroids
the average loss incurred when using the centroids c as representations of the users’ preference
k
parametersθ . EWCoutperformstheoracleFollow-the-Leader(FTL)whenthelossduetoemploying
i
(cid:112)
centroidsislessthanthelossfromconsistentlyselectingthefixedbestarm. Theterm2 log(K)/T
representstheaveragelossassociatedwiththeprocessofidentifyingthebestexpert. Thislossis
negligiblesinceitdecreasesrapidlyasT increases.
5. Experiments
In this section, we have established empirical analyses to evaluate the application of the Expert
withClustering (EWC)algorithm througha comprehensive setof experiments. The experiments
aredesignedtoassesstheperformanceoftheEWCalgorithminlearningdriverpreferencesinan
online setting, especially focusing on its ability to adapt to new data and to make accurate route
recommendationsbasedoneco-drivingconsiderations.
8EXPERTWITHCLUSTERING: HIERARCHICALONLINEPREFERENCELEARNINGFRAMEWORK
5.1. ExperimentalSetup
Communitysurvey. ThisstudyinvolvedacommunitysurveyconductedinJuly2023ontheUniver-
sityofNorthCarolinaatCharlottecampus,andatotalof43individualsparticipated. Participants
providedthedrivingchoicepreferencesaswellasdemographicdatacoveringage,gender,ethnicity,
andeducationallevel. Thesurvey’smaincomponentinvolvedaseriesofquestionsassessingwilling-
nesstoadheretorouterecommendationsundervaryingscenarioswithdistincttraveltimesandcarbon
dioxideemissionlevels. Participantsratedtheirlikelihoodoffollowingtheserecommendationsin
theLikertscale,offeringinsightintotheirdecision-makingcriteria. Forexample,participantswere
askedontheirlikelihoodtooptforaneco-friendlyrouteofferinga10%reductioninCO emissions
2
inexchangefora5–15%increaseintraveltime.
Mobility user simulation. We broadened the dataset to simulate a broader driving population,
extrapolatingfromthesurveyresponsestogenerateadiverserangeofusercontexts. Togeneratethe
largerpopulationhavingdifferentusercontexts,weusetheBayesianinferencemodelthatresembles
theoriginaldistributionfromthesurveydata(Andrieuetal.(2003)). Werefinedthisapproachby
implementingdistinctutilityfunctionsfordemographicsegmentsdifferentiatedbygender,age,and
householdcarownership. Drawingsamplesfromtheposteriordistributionofmodelparameters,we
populatedthedatasetwithindividualsexhibitingarangeoffeaturesandcompliancebehavior. This
methodologyallowedustoproduce2000individualuserchoicerecordsforthesyntheticdataset,
with parameters set at N = 800, N′ = 1200, T = T′ = 40, and K = 6. The optimal K was
selected based on regret minimization. The synthetic dataset features a mix of route choices that
reflect various driving preferences and behaviors, providing a rich foundation for evaluating our
EWCalgorithm.
Baselines. Ourapproachisbenchmarkedagainstaselectionofwell-establishedbaselinealgorithms.
Follow-the-Leader(FTL)predictsthefutureactionsbasedonhistoricallyrewardingchoices. The
LinearUpperConfidenceBound(LinUCB)algorithmadaptstheupperconfidenceboundmethod
for linear payoffs, optimizing the trade-off between exploring new actions and exploiting known
ones. Oracle Follow-the-Leader (Oracle FTL) always chooses the historically optimal option.
TheOracleCluster algorithmmakespredictionsusingpreciseclusterassignmentstoincorporate
collective behaviors within a user’s group for decision-making. Lastly, Oracle θ leverages a
i
perfect understanding of user preferences and behaviors to anticipate the most likely user action.
Thesebaselinesrangefromsimplehistoricalaction-basedstrategiestocomplexmodelsthatassume
completeknowledgeofuserbehaviorsorpreferences.
5.2. Results
Figure2comparestheregretofvariousonlinelearningalgorithmsonasynthesizeddatasetbased
on driving preferences and eco-driving recommendations. Regret measures how much worse an
algorithm performs compared to the best possible action over time. Oracle θ shows the lowest
i
regret, indicating it almost perfectly predicts the best action due to itsassumption of perfect user
preference information. Oracle Cluster also performs well, benefiting from knowledge of user
clusters. Oracle FTL exhibits a high slope value comparable to that of standard FTL. LinUCB
andstandardFollow-the-Leader(FTL)algorithmsexperiencehigherregret. FTL,relyingsolelyon
historicalactionfrequency,performsworstamongbaselines. LinUCB’sexpressivenessislimited,
whichleadstoasimilarperformancewithFTL.Intheearlyrounds,LinUCBandtheEWCalgorithm
startwithsimilarlevelsofregret,suggestingthatinitially,bothalgorithmsperformcomparablyin
predicting the best action. This could be because, in the initial stages, there’s less historical data
9ZHOUCHOARDABILITABKHIWU
Figure2: Comparativeregretanalysisofonlinelearningalgorithms: ExpertwithClustering(EWC,
Ours)showslowerregretthanthebaselinealgorithms(Follow-the-Leader,LinUCB,OracleFTL)
andapproachestheconsistencyoftheOraclemethods.
todifferentiatethepredictivepowerofthealgorithms,orthecorrectactionismoreobvious. EWC
surpassesnon-oraclemethods,showingclustering’seffectivenessincapturinguserpreferences. Its
long-term regret slope mirrors that of Oracle Cluster, suggesting rapid identification of optimal
usergroupaffiliations. TheEWCalgorithm’sperformancegraduallyimproves,indicatingthatitis
increasinglypredictingtheoptimalactions, reducingregretby27.57%comparedtotheLinUCB
atthefinalrounds. Thiscouldbeduetotheinherentadvantagesofitsclustering-basedpredictive
model,which,despitelackingperfectforesight,benefitsfrominsightsthatapproachtheprescience
oftheOraclemethods.
6. Conclusion
Inthispaper,weintroduceExpertwithClustering(EWC),anovelhierarchicalcontextualbandits
algorithmdesignedtoaddresstheonlinelearningchallengesfordrivers’preferences. EWCuniquely
combinesclusteringtechniqueswithpredictionbasedonexpertadvice,effectivelyachievinglow
regret in online learning scenarios. A key innovation of our approach is the adoption of a new
metric, the Loss-guided Distance, which facilitates the generation of more representative cluster
centroids, thereby enhancing the recommendation performance. Furthermore, EWC offers an
efficientmethodforextractinginsightsintobothpopulation-wideandindividual-specificbehaviors,
proving particularly effective in contextualized settings that exhibit hierarchical structures. In
future work, we plan to refine EWC by incorporating more user-specific preference learning and
investigatingthepreferenceforincentives,therebyenhancingthepersonalizationandeffectiveness
ofourrecommendations.
10EXPERTWITHCLUSTERING: HIERARCHICALONLINEPREFERENCELEARNINGFRAMEWORK
Acknowledgments
ThisworkwaspartiallysupportedbytheNationalScienceFoundation(NSF)undergrantnumber
2149511andtheKwanjeongscholarship. TheauthorswouldliketothankProf. ChristosCassandras,
Prof. AndreasMalikopoulos,andProf. RoyDongfortheinsightfuldiscussion.
References
ChristopheAndrieu,NandodeFreitas,ArnaudDoucet,andMichaelI.Jordan. AnIntroductionto
MCMCforMachineLearning. MachineLearning,50:5–43,January2003.
PeterAuer. Usingconfidenceboundsforexploitation-explorationtrade-offs. JournalofMachine
LearningResearch,3(Nov):397–422,2002.
OlivierBachem,MarioLucic,S.HamedHassani,andAndreasKrause. Uniformdeviationbounds
forunboundedlossfunctionslikek-means,2017.
SaiKrishnaChada,DanielGörges,AchimEbert,RomanTeutsch,andShreevatsaPuttigeSubramanya.
Evaluationofthedrivingperformanceanduseracceptanceofapredictiveeco-drivingassistance
system for electric vehicles. Transportation Research Part C: Emerging Technologies, 153:
104193,August2023. ISSN0968-090X. doi: 10.1016/j.trc.2023.104193. URLhttps://www.
sciencedirect.com/science/article/pii/S0968090X23001821.
CasparG.Chorus,TheoA.Arentze,andHarryJ.P.Timmermans. Travelercompliancewithadvice:
ABayesianutilitarianperspective. TransportationResearchPartE:LogisticsandTransportation
Review, 45(3):486–500, May 2009. ISSN 13665545. doi: 10.1016/j.tre.2008.10.004. URL
https://linkinghub.elsevier.com/retrieve/pii/S1366554508001336.
YoavFreundandRobertESchapire.Adecision-theoreticgeneralizationofon-linelearningandanap-
plicationtoboosting. JournalofComputerandSystemSciences,55(1):119–139,1997. ISSN0022-
0000. doi: https://doi.org/10.1006/jcss.1997.1504. URLhttps://www.sciencedirect.
com/science/article/pii/S002200009791504X.
Claudio Gentile, Shuai Li, and Giovanni Zappella. Online clustering of bandits. In Eric P. Xing
andTonyJebara,editors,Proceedingsofthe31stInternationalConferenceonMachineLearning,
volume32ofProceedingsofMachineLearningResearch,pages757–765,Bejing,China,22–24
Jun2014.PMLR. URLhttps://proceedings.mlr.press/v32/gentile14.html.
ClaudioGentile,ShuaiLi,PurushottamKar,AlexandrosKaratzoglou,GiovanniZappella,andEvans
Etrue. On context-dependent clustering of bandits. In International Conference on machine
learning,pages1253–1262.PMLR,2017.
DevanshJalota,KarthikGopalakrishnan,NavidAzizan,RameshJohari,andMarcoPavone. Online
LearningforTrafficRoutingunderUnknownPreferences,March2022. URLhttp://arxiv.
org/abs/2203.17150. arXiv:2203.17150[cs,math].
Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A Contextual-Bandit Approach to
PersonalizedNewsArticleRecommendation. InProceedingsofthe19thinternationalconference
onWorldwideweb,pages661–670,April2010. doi: 10.1145/1772690.1772758. URLhttp:
//arxiv.org/abs/1003.0146. arXiv:1003.0146[cs].
11ZHOUCHOARDABILITABKHIWU
ShuaiLi,AlexandrosKaratzoglou,andClaudioGentile. Collaborativefilteringbandits,2016.
N. Littlestone and M.K. Warmuth. The weighted majority algorithm. Information and
Computation, 108(2):212–261, 1994. ISSN 0890-5401. doi: https://doi.org/10.1006/inco.
1994.1009. URL https://www.sciencedirect.com/science/article/pii/
S0890540184710091.
StuartLloyd. Leastsquaresquantizationinpcm. IEEEtransactionsoninformationtheory,28(2):
129–137,1982.
DorsaSadigh,AncaDragan,ShankarSastry,andSanjitSeshia. ActivePreference-BasedLearning
of Reward Functions. In Robotics: Science and Systems XIII. Robotics: Science and Systems
Foundation, July 2017. ISBN 978-0-9923747-3-0. doi: 10.15607/RSS.2017.XIII.053. URL
http://www.roboticsproceedings.org/rss13/p53.pdf.
RanTu,JunshiXu,TiezhuLi,andHaiboChen. EffectiveandAcceptableEco-DrivingGuidance
forHuman-DrivingVehicles: AReview. InternationalJournalofEnvironmentalResearchand
PublicHealth,19(12):7310,June2022. ISSN1660-4601. doi: 10.3390/ijerph19127310. URL
https://www.mdpi.com/1660-4601/19/12/7310.
12