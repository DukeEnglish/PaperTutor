Health Text Simplification: An Annotated Corpus for Digestive
Cancer Education and Novel Strategies for Reinforcement Learning
Md Mushfiqur Rahman*, Mohammad Sabik Irbaz*, Kai North, Michelle S. Williams
Marcos Zampieri, Kevin Lybarger
George Mason University
Abstract
Objective: The reading level of health educational materials significantly influences information
understandability and accessibility, particularly for minoritized populations. Many patient edu-
cational resources surpass the reading level and complexity of widely accepted standards. There
is a critical need for high-performing text simplification models in health information to enhance
dissemination and literacy. This need is particularly acute in cancer education, where effective
prevention and screening education can substantially reduce morbidity and mortality.
Methods: WeintroduceSimplified Digestive Cancer (SimpleDC),aparallelcorpusofcancered-
ucation materials tailored for health text simplification research. Utilizing SimpleDC alongside the
existingMed-EASicorpus,weexploreLargeLanguageModel(LLM)-basedsimplificationmethods,
including fine-tuning, reinforcement learning (RL), reinforcement learning with human feedback
(RLHF), domain adaptation, and prompt-based approaches. Our experimentation encompasses
Llama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a lightweight model
adept at distinguishing between original and simplified texts, thereby enhancing the model’s effec-
tiveness with unlabeled data.
Results: Fine-tuned Llama 2 models demonstrated high performance across various metrics.
Our innovative RLHF reward function surpassed existing RL text simplification reward functions
ineffectiveness. TheresultsunderscorethatRL/RLHFcanaugmentfine-tuning,facilitatingmodel
training on unlabeled text and improving performance. Additionally, these methods effectively
adapt out-of-domain text simplification models to targeted domains.
Conclusion: The newly developed SimpleDC corpus will serve as a valuable asset to the re-
search community, particularly in patient education simplification. The RL/RLHF methodologies
presented herein enable effective training of simplification models on unlabeled text and the uti-
lization of out-of-domain simplification corpora.
*Authors contributed equally to this paper.
1. Introduction
Accessibility and comprehensibility of patient medical educational materials are critical to im-
proving health literacy and patient health. Patient educational materials, including those related
to cancer, are fundamental in providing patients with the information necessary to make informed
healthcare decisions. Health literacy is strongly influenced by the clarity and understandability of
Preprint submitted to Elsevier January 29, 2024
4202
naJ
62
]LC.sc[
1v34051.1042:viXrasuch materials and plays a key role in health outcomes [1]. It affects various aspects of patient
health, including reducing risk factors, encouraging timely screening, and facilitating proactive
health management. Despite the importance of these educational materials, there exists a signif-
icant gap in their readability. The American Medical Association (AMA) and National Institutes
of Health (NIH) recommend a reading at or below the sixth grade reading level for patient edu-
cational materials to ensure comprehensibility for a broad audience [2, 3]. However, the materials
from key information sources are often presented at a high school or college reading level [4]. This
highreadinglevelposesabarrier, particularlyforindividualswithlowerliteracyorlimiteddomain
knowledge,preventingpatientsfromfullyunderstandingandtakingactiononessentialhealthinfor-
mation. The accessibility and comprehensibility of educational materials are of particular concern
incancerinformationdissemination,whereclearandunderstandableguidanceiscrucialforeffective
patienteducationanddecision-making[5,6]. Ourfocusontext-basededucationalmaterialsrelated
to cancer in this document is based on their critical role in patient education and the urgent need
to improve their accessibility to a wider audience.
Natural Language Processing (NLP) and recent advances in Large Language Models (LLMs)
hold substantial promise to bridge the gap between the complexity of existing medical education
materials and the need for large-scale simplification of educational information to improve public
health literacy [7]. LLMs enable new possibilities to automatically generate high-quality text sim-
plificationsandhaveshownremarkableproficiencyinreducinglinguisticcomplexityandpreserving
medical precision and meaning [8]. This capability is vital in the domain of health information,
where accuracy and accessibility of information are critical. Finding the optimum balance of sim-
plification and information retention is challenging, and the stakes of miscommunication are high
[9]. Developing and evaluating data-driven text simplification models requires parallel corpora of
originalandsimplifiedtext, andcreatingtheseparallelcorporaislabor-intensiveandcostly. Inthe
health domain, these challenges are exacerbated by the need for domain-specific medical expertise
and the consequences of inaccurate simplifications. To address these challenges, robust methods
are needed for creating high-performing simplification models with minimal training data.
This paper makes significant contributions to the field of health information simplification and
text simplification more broadly. In this paper, we focus on patient educational materials related
to digestive cancer, given the prevalence and mortality of these cancers [10, 11]. We introduce
Simplified Digestive Cancer (SimpleDC), a novel text simplification corpus consisting of patient
educational materials from three prominent sources of health information, including the National
Cancer Institute (NCI), American Cancer Society (ACS), and Centers for Disease Control (CDC).
SimpleDCisuniqueinitsconcentrationondigestivecancersandcomprisesparallelsentences(origi-
nalandsimplifiedversions),wheresimplificationsweregeneratedbyateamofnurseoncologistsand
anursepractitionerwithmedicalandpatienteducationbackgrounds. WeexploreSimpleDCusing:
1) Llama 2 [12] with supervised fine-tuning (SFT), reinforcement learning (RL), and reinforce-
ment learning with human feedback (RLHF) approaches and 2) GPT-4 [13, 14] with prompt-based
methods. We introduce a novel RLHF reward function for text simplification, which combines a
heuristic scoring function for reading level and a data-driven classifier for distinguishing between
originalandsimplifiedtexts. WedemonstratethatthisRLHFrewardfunctionoutperformsexisting
text simplification reward functions, complements SFT, and can facilitate domain adaptation. In
our prompt-based exploration of GPT-4, we introduce a novel self-correction strategy. Our find-
ings advance the simplification of health text and enable the automatic creation of more accessible
healthinformation,ultimatelycontributingtobetterhealthliteracy. Weprovidethenewannotated
2corpus, SimpleDC, LLM-based simplification models, and code to the research community.1
2. Related Work
Textsimplification,afieldthathasevolvedsignificantlyoverthepastdecade,involvesthetrans-
formationoftextsintomorecomprehensibleversionstoimproveaccessibilityfordiverseaudiences.
This process is particularly relevant for sources such as news articles, literature, and scientific ar-
ticles, where complex ideas must be communicated in a clear and concise manner [15–19]. In the
health domain, text simplification takes on unique dimensions, including tasks such as converting
denseclinicalnotesintopatient-friendlysummaries[20–22],makingbiomedicalliteratureaccessible
to laypeople, and simplifying educational materials for patients [7, 23–27]. Unlike general domain
text simplification, which can prioritize readability or stylistic adjustments, health text simplifi-
cation demands meticulous care to preserve the integrity and accuracy of information due to the
potentiallysevereconsequencesofmisinterpretation,suchashealthrisksorethicalconcerns[7,28].
This challenge is compounded by the need to accommodate a wide range of patients, including
those with varying literacy levels, non-native speakers, and individuals with reading disabilities,
necessitating a nuanced approach to ensure both clarity and correctness in communication.
Text simplification can be subdivided into three distinct tasks: lexical simplification, sentence-
level simplification, and paragraph/document-level simplification [29, 30]. Within the health sim-
plification domain, these tasks address distinct challenges inherent in medical texts, such as dense
jargon, complex sentence structures, and lengthy explanations. This domain-specific focus requires
tailored methods and approaches that consider not only linguistic complexity but also the critical
needtopreservetheaccuracyandnuancesofmedicalinformation. Lexicalsimplificationcommonly
involvesthesubstitutionofwordsorphrases,wheredifficultmedicaltermsarereplacedwithsimpler
wordsorphrases[28,31–34]. Lexicalsimplificationmayuseknowledgebasestoaddexplanationsfor
improvedreadability[35]. However,theword-/phrase-levelfocusoflexicalsimplificationinherently
limits its scope, as it does not facilitate the rephrasing or restructuring of sentences or paragraphs.
This constraint may result in inadequate handling of the broader contextual and structural com-
plexities of health communications, beyond surface-level linguistic complexities. Sentence- and
document-levelsimplificationenablestextrestructuringtoenhanceoverallclarityandaccessibility.
Sentence- and document-level simplification methods typically require parallel text corpora
(complex and simplified text) for model training and evaluation. Due to the labor-intensive nature
of annotation, there are limited health-focused text simplification corpora, which we highlight here
[8, 25, 36, 37]. The Medical dataset for Elaborative and Abstractive Simplification (Med-EASi)
dataset consists of medical text from SIMPWIKI that was simplified by a team of medical experts
andlaypersoncrowdworkersatthesentence-level[36]. TheAutocompleteforMedicalTextSimpli-
fication (AutoMeTS) dataset is a medical text simplification corpus consisting of aligned sentences
from English Wikipedia and Simple English Wikipedia [25]. Devaraj et al. provided a manually
annotated parallel corpus of biomedical literature with simplified text created by domain experts
[8]. Weintroduceanewhealthtextsimplificationcorpus,SimpleDC,whichisbasedoneducational
patient materials from prominent information sources and explicitly focuses on the cancer domain.
Sentence-level simplification focuses on modifying the structure and phrasing of individual sen-
tences to enhance clarity and understanding. Early work used heuristics and traditional machine
1Alinkwillbeprovideduponacceptance.
3learning techniques, like pruning or pattern-based paraphrasing [38, 39]; however, contemporary
approaches treat text simplification as a machine translation task, where each inputted sentence
is transformed by a neural language model to create a simplified version [7, 40]. Document-level
simplification is generally also pursued as a machine translation task. Some studies have used
Neural Style Transfer (NST) [15], which allows transforming input text without the requirement
for parallel corpora. Essentially, all state-of-the-art text simplification models are based on LLMs,
including: i) encoder-decoder architectures, like Text-to-Text Transfer Transformer (T5) [41] and
Fine-tuned LAnguage Net on T5 (FlanT5) [42] and ii) decoder-only models such as Large Lan-
guage Model Analysis (Llama) variants [12, 43] and Generative Pre-trained Transformer (GPT)
[14]variants,likeGPT-4[44]. LLM-basedsimplificationmodelsarepredominantlycreatedthrough
SFT;however,therehasbeensomelimitedexplorationofprompt-basedmethodsandreinforcement
learning. Although these models have been explored in general domain simplification tasks, there
is comparatively little research exploring LLMs for health simplification, and there are many open
research questions.
ManyLLMsareinstruction-tunedtolearntofollownaturallanguageinstructions,whichenables
prompt-based approaches, including in-context learning, chain-of-thought (CoT) learning [45, 46],
and self-correction (SC) [47, 48]. These methods rely on the inherent language understanding
and reasoning capabilities of LLMs [45]. CoT learning enables models to articulate step-by-step
reasoning, akin to human problem-solving, enhancing response accuracy and interpretability [45,
46]. SC allows models to iteratively refine their outputs, improving the precision and reliability of
their responses [48]. We present novel approaches for adapting these techniques to our exploration
of SimpleDC.
Inrecentyears,reinforcementlearning(RL)hasemergedasapromisingapproachinthedomain
of textsimplification, with several studiesdemonstrating its effectiveness [37,49, 50]. Zhanget al’s
work on sentence simplification with RL underscored the potential of RL in the text simplification
domain [51]. TESLEA [37] is one of the pivotal works in the health text simplification space. They
applied an RL-based method for simplification and used automatic metrics for evaluation. Their
methodcloselyalignswithourproposedwork. Nakamachietal. exploredtheuseofgrammaticality,
meaning preservation, and simplicity in a novel RL reward function for their text simplification
model[49]. Similarly, Yanamotoetal. introducedanRLapproachbasedonthedifferencebetween
estimated and target difficulty levels, using a novel reward calculation method [50]. Alkaldi et al
presented an RL paradigm that refines reading levels in a controlled and iterative process [52].
3. Materials and Methods
3.1. Data
3.1.1. SimpleDC
We introduce the SimpleDC dataset, which is a meticulously curated parallel corpus, specifi-
cally designed for text simplification research within the medical domain. It comprises educational
information for patients from three reputable institutions: the American Cancer Society (ACS),
the Centers for Disease Control and Prevention (CDC), and the National Cancer Institute (NCI).
Theseorganizationswerechosenduetotheirexpertiseandcomprehensivecoverageofhealth-related
topics. There are many different types of cancer, each with its own characteristics, and primary
sources (ACS, CDC, and NCI) include comprehensive information on these cancers, far exceeding
the available annotation budget. SimpleDC is focused on the subset of cancers associated with the
digestive system to create a corpus that spans many cancer types that share similar terminology
4and topics (e.g. anatomy or symptoms). The focus on digestive cancers is also motivated by the
prevalence and mortality of these cancers and the role that prevention and screening play in the
outcomes. SimpleDCrespondstotheurgentneedtomakemedicalinformationmoreaccessibleand
comprehensible to a broader audience, especially traditionally under-resourced populations.
Source Original Text Simplified Text Orig. Simp.
FKGL FKGL
ACS Theanusistheopeningatthelower Theanusistheopeningwherebowel 4.4 3.6
end of the intestines. movements come out of your body.
CDC Screening can find precancerous Screening can help find growths in 10.7 5.2
polyps—abnormal growths in the your colon or rectum called precan-
colon or rectum—that can be re- cerouspolyps. Theycanberemoved
movedbeforetheyturnintocancer. before they turn into cancer.
NCI Primary liver cancer is a disease in A cancer that starts in your liver is 10.3 6.8
which malignant (cancer) cells form called primary liver cancer.
in the tissues of the liver.
Table1: AnnotationexamplesandFlesch-KincaidGrade-Level(FKGL)scores
WescrapedtheACS,CDC,andNCIwebpagescontainingpatienteducationalcontentrelatedto
eightdigestivecancers: anal,bileduct,colorectal,gastrointestinal,liver,pancreatic,smallintestine,
and stomach. For these cancer types, we collected the text from web pages that present the
most introductory cancer information (e.g. About, Prevention, Screening). The collected text
was cleaned, including the removal of white spaces, adjusting punctuation, and removing rich-text
formatting, and split into sentences. We developed annotation guidelines for the simplification
task and trained a team of subject matter experts (SMEs) with expertise in both cancer and
patient education, including two nurse oncologists and a nurse practitioner. For each web page,
wecreatedanannotationdocumentwithatwo-columnformat, wheretheleft-handandright-hand
sides contained the original text with each sentence on its own line. The annotators modified the
sentences in the right column in place based on the annotation guidelines. This approach allowed
the annotators to focus on sentence-level simplification while considering the entire web page for
context. Table 1 presents annotation examples for each source, together with the Flesch-Kincaid
Grade Level (FKGL) [53] scores.
In the initial training round, two annotators independently generated simplifications for the
same web page. To assess the quality of the annotation, the third annotator reviewed the simplifi-
cations relative to the original text and indicated their preferred simplification as A is better; B
is better; Both are good; or None is good (simplification order shuffled). In the evaluation phase,
the distribution of the third annotator’s preferences was as follows: 34% of the samples favored the
first annotator’s version, 32% favored the second annotator’s version, 26% were considered equally
effective from both annotators, and 8% were found inadequate by the third annotator, meaning
neither version met the simplification criteria. SimpleDC consists of 29 annotated web pages (14
train, 5 development, and 10 test). It includes 1,183 annotated sentence pairs (361 train, 294 de-
velopment,and528test). Thedevelopmentandtestsetsweredoublyannotatedbytwoannotators
and adjudicated by the third annotator to create a robust evaluation set. The training set was
singly annotated by the domain experts. Figure 1 presents the distribution of the reading level.
As part of the data collection and exploration process, we collected an additional 1,395 web
5Figure 1: Boxplot representing the FKGL scores of Expert and Simple Text of the SimpDC dataset (grouped by
source)
pages from ACS, CDC, and NCI related to digestive cancer that were not annotated/simplified.
Werandomlysampled1,000oftheseunannotatedwebpagesforuseintheRLproceduresdescribed
in Section .
3.1.2. Med-EASi
Med-EASi dataset [54] is distinctively crowdsourced and features fine-grained annotations for
supervised text simplification, addressing the challenge of making complex medical information
more accessible to a general audience. The textual transformations in Med-EASi are classified
into four types: elaboration, replacement, deletion, and insertion. The study employs the T5-
large [55] model, fine-tuned with different styles of input-output combinations. They experiment
with two control-free and two controllable versions of the model, enabling varying degrees of text
simplification. A novel aspect of this study is its annotation approach, which combines the efforts
of medical experts, layman crowd-workers, and AI algorithms, ensuring both the accuracy and
readability of simplified texts. The dataset includes 1,979 expert-simple text pairs, covering a wide
range of medical topics and complexities. The average FKGL of the expert samples is around 13th
grade and the average readability of the layman samples is around 10th grade.
3.2. Simplification Models
Our text simplification exploration with SimpleDC and Med-EASi focuses on state-of-the-art
encoder-only LLMs, including Llama 2[12] and GPT-4[44]. Using Llama 2, we explore zero-shot
and SFT approaches to establish performance baselines and introduce a novel RL approach for
simplification. Using GPT-4, we explore different prompt-based strategies and present a novel
self-correction strategy for simplification.
63.2.1. Supervised fine-tuning (SFT)
Llama 2 was trained on input-output pairs consisting of the original text and simplified text
usingSFTwithstandardcross-entropyloss. OurSFTexperimentationincludedboththeSimpleDC
and Med-EASi data sets.
Figure2: ReinforcementLearningwithHumanFeedbackforMedicalTextSimplification
3.2.2. Reinforcement Learning
We explored RL strategies to incorporate unlabeled, in-domain text into simplification model
training. Using Proximal Policy Optimization (PPO) [56], we investigated RL reward functions
based on individual metrics related to reading level assessment (FKGL), semantic similarity (rel-
evance), and likelihood of original vs. simplified. Our exploration of RL includes Reinforcement
Learning with Human Feedback (RLHF)[57]. Figure 2 presents an overview of the RL pipeline.
Each of these reward metrics is described below. In RL frameworks, it is common for the reward
values to be in the range [0, 1], where higher values indicate more desirable outcomes and lower
values indicate less desirable outcomes. For each reward metric presented, individual rewards and
composite rewards are scaled to fall in this range.
3.2.3. Reward Models
Readability Reward: FKGL is a heuristic function to assess the reading level of text based
onwordandsentencelength. Althoughitisanimperfectmetric,FKGLprovidesanautomaticway
to assess the reading level of the generated text. In the TESLEA approach [37], the FKGL score
7is essentially normalized to the [-1,1] range based on the target reading level. To map the FKGL
scores to the [0, 1] range for RL, we took inspiration from the TESLEA approach. The reading
level reward, R , was calculated by normalizing the FKGL score by the reading level target
FKGL
and applying a sigmoid function:
(cid:18) (cid:19)
6.5−FKGL(generated)
R =sigmoid
FKGL 6.5
The normalized reading score (fraction within the sigmoid) generally falls in the range [-1, 1] for
our data, where positive values indicate simpler text (more desirable) and negative values indicate
more complex text (less desirable). The sigmoid function maps the normalized reading scores to
the range [0, 1], where higher values still indicate lower reading levels.
Relevance Reward: The relevance reward, R , is intended to quantify the semantic rela-
Rel
tionship between the simplified text and the original text, where a higher reward indicates greater
semanticsimilarity. WefollowtheTESLEAapproach[37]forrelevancescoring: 1)theoriginaltext
andthesimplifiedtextaremappedtoseparatevectorrepresentationsusinganencodermodeland2)
semanticsimilarityisassessedbasedonthecosinesimilaritybetweenthesetwovectors. BioSentVec
[58] was selected as the encoder, which has been extensively trained in biomedical literature. Co-
sinesimilarityfallsintherange[0,1],wherehighervaluesindicatehighersemanticcorrespondence.
Therelevancerewardincentivizesthepreservationofsemanticrelatednessbetweentheoriginaland
simplified text. The R reward does not include any information or representation from the
Rel
annotated corpus, SimpleDC.
Originalvs. Simplified(OvS)Reward: WeintroduceanewRLreward,R ,basedonthe
OvS
likelihoodthatatextsamplehasbeensimplified. UsingSimpleDCtrainingdata,wetrainedabinary
classifier to label samples as original or simplified using BioMed-RoBERTa base [59]. This reward
function captures some aspects of the annotator’s (human) preferences and is considered human
feedbackforRL.TheOvSclassificationmodelachievedanaccuracyof 75.1% on the SimpleDC
dev dataset. This accuracy indicates a robust ability to discern the complexity of the language
and the specialized nature of the content. The reward value, R , is the predicted probability
OvS
thatthetextissimplified(P(simplified))providingacontinuousrewardsignalrangingfrom[0,1],
wherehighervaluessuggestbettersimplification. Ourintuitionbehindthisrewardfunctionisthat
it provides a mechanism for learning features of the original and simplified text and propagating
this learning to unlabeled samples during RL.
Reward Aggregation: We calculated aggregated reward values from the individual metrics
using the harmonic mean, H, to balance the contribution from each metric, as
1
H(x ,x )=
1 2 1 + 1
x1 x2
. We developed two aggregated reward functions:
• R : Wecombinedthereadinglevelreward,R ,andtherelevancereward,R ,
FKGL+Rel FKGL Rel
to create an aggregated reward, R = H(R ,R ). This aggregated reward is
FKGL+Rel FKGL Rel
intended to capture both text complexity and semantic similarity to yield text that is at the
desired reading level, while preserving the original meaning. This reward function does not
incorporate any learning from SimpleDC and is therefore considered RL.
• R : We also combined the reading level reward, R , and the Original vs.
FKGL+OvS FKGL
Simplified reward, R , to create an aggregated reward, R = H(R ,R ).
Rel FKGL+OvS FKGL OvS
8Thisaggregatedrewardisintendedtoassesstextcomplexity(R )andidentifylinguistic
FKGL
featuresthatdifferentiatetheoriginalandsimplifiedtext(R )toproducetextthatisatthe
Rel
desiredreadinglevelandemulatesthesimplificationoftheSimpleDC.Asthisrewardfunction
incorporatesatrainingsignalderivedfromtheSimpleDCannotations,itisconsideredRLHF.
3.2.4. Fine-tuning With Reward Models
We explored different pipelines for incorporating RL/RLHF, including only using RL/RLHF,
combining SFT and RL/RLHF, and using RL/RLHF for domain adaptation:
• RL/RLHF only: Apre-trainedLLMwastrainedusingRL/RLHFusingunlabeledin-domain
data (digestive cancer text) to learn the text simplification task and text-domain without
any SFT of the LLM on in-domain data (SimpleDC). The goal of this exploration was to
understand the achievable performance without any SFT.
• In-domain SFT + RL/RLHF - A pre-trained LLM was first trained through SFT on labeled
in-domain data (SimpleDC train set), followed by continued training through RL/RLHF on
unlabeledin-domaindata(digestivecancertext). Thisexperimentationwasintendedtoassess
whether RL/RLHF can continue to improve the model even after in-domain SFT.
• Out-domainSFT+RL/RLHF -Apre-trainedLLMwasfirsttrainedthroughSFTonlabeled
out-of-domain data (Med-EASi train set), followed by continued training through RL/RLHF
unlabeled in-domain data (digestive cancers text).
Intheexperimentationdescribedabove,theunlabeledin-domaindataconsistedof1,000webpages
fromACS,CDC,andNCIrelatedtodigestivecancerthatwerenotannotatedandnotincorporated
into SimpleDC (no overlap with SimpleDC).
InallRLexperiments,thetrainingusedProximalPolicyOptimization(PPO),whereaKullback-
Leibler (KL) divergence constraint (1975)[60] was implemented to limit the excessive deviation of
the LLM trained with RL from the original LLM. This divergence acted as a regulatory mecha-
nism, ensuringthattheLLMmaintainedlinguisticcoherenceandavoidedoverfittingtopotentially
incorrect or excessive scores from the reward model. Such a constraint was crucial, considering the
reward model’s inherent limitations in comprehending the extensive range of potential responses.
This approach effectively mitigated bias toward outlier responses that may not represent genuine
quality in text simplification.
3.2.5. Prompt-based models
Given our focus on developing simplification models with limited training data and the success
of GPT-4 in many tasks, we present prompt-based approaches for text simplification with GPT-4
[13], including in-context learning, CoT, and self-correction.
Zero-shot: In the zero-shot approach, GPT-4 was prompted to simplify the text to an ele-
mentary reading level, serving as a baseline to evaluate the efficacy of more complex prompting
strategies in text simplification. The specific simplification prompt is included in the Baseline
module in Figure 3.
In-context Learning: The in-context variant used the same initial prompt as the zero-shot
approach, but was augmented with three representative examples from the SimpleDC training set.
Theseexamplesweremanuallyselectedtoillustratethedesiredsimplificationstyleandcomplexity,
providing GPT-4 with contextual clues to guide its simplification process.
FKGL-Enhanced Prompt: Building on the initial prompt, we added a detailed description
of the FKGL heuristic, indicating that lower reading levels are associated with shorter words and
9sentences, and provided the FKGL formula for calculating the grade level from word and sentence
lengths.
Figure3: Chain-of-Thought(CoT)promptingalongwithBaselineandIn-context
Chain-of-Thought (CoT): Our CoT approach builds on the FKGL-Enhanced Prompt ap-
proach by providing the model with additional sample-specific context, including the average word
length,averagesentencelength,andalistoflongerwordswords(≥3syllables). Thismodelaimsto
provide explicit guidance for the simplification process and anchor the simplification in commonly
used readability standards. Figure 3 illustrates the CoT approach.
Self-Correction (SC): Inspired by recent work on self-correction [47, 48], we created a self-
correction approach for simple text identification. Figure 4 presents the proposed self-correction
approach, which incorporates external assessments of the generated text to guide the refinement of
thesimplification. TheintentwastobothexploitthereasoningcapabilitiesoftheLLMandincorpo-
rate additional external training signals to iteratively refine output. Each generated simplification
was scored for reading level using FKGL and semantic fidelity using BERTScore. Acceptance
criteria include: 1) FKGL score ≤ 6 or FKGL reduced by 3 grade levels from the original text
and 2) BERTScore between the generated and original texts ≥ 0.95. If the simplification met the
acceptance criteria, it was accepted; otherwise, the simplification was fed back into GPT-4 with
instructions for improving the simplification. Each sample was processed iteratively at most 3
times.
10Figure4: DiagramofSelf-correctionPrompting
3.2.6. Experimental Paradigm
OurexperimentalpipelinesutilizedPyTorch[61]andHuggingFace’sTransformers[62]package.
WeusedtwoLlama2variants: Llama-2-7b-chat-hf2 andLlama-2-7B-32K-Instruct3. Trainingand
evaluation utilized A100 GPUs. We also used Weights and Biases [63] for tracking training and
performance.
For SFT, we utilized LORA [64] utilities from the Parameter-Efficient Fine-Tuning (PEFT)
package [65, 66], to reduce the time and space complexity of model training. Hyperparameters
were selected based on computational constraints and performance optimization. We selected a
batch size of 8 to balance memory usage and model updating. The learning rate was set at 2e-4,
followingpreliminaryexperimentstofindabalancebetweencatastrophicforgettingandsuboptimal
convergence. Additional hyperparameters, such as weight decay (0.001) and maximum gradient
norm (0.3), were included to prevent overfitting and maintain the stability of the training process.
For RLHF, we specified a range of hyperparameters, including a learning rate of 1.41e-5 and PPO
epochs of 2, reflecting a conservative approach to incremental learning. Our choice of batch and
mini-batch sizes, set to 4, was influenced by the need to manage the computational load effectively
while still capturing the nuances of gradient updates during the training process.
3.3. Evaluation
We utilized widely accepted evaluation metrics, each addressing specific aspects of text simpli-
fication quality. These include System output Against References and against the Input sentence
2https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
3https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct
11(SARI) [67], which evaluates the quality of sentence simplification by considering additions, dele-
tions,andsubstitutions;BilingualEvaluationUnderstudy(BLEU)[68,69],evaluatingtheprecision
ofthegeneratedtextagainstreferencetranslations; BERTScore[70], whichquantifiesthesemantic
similarity between the simplified text and reference using contextual embeddings; Recall-Oriented
Understudy for Gisting Evaluation (ROUGE) [71], focusing on recall by comparing the overlap of
n-grams between the output and reference texts; and Flesch-Kincaid Grade Level (FKGL) [53],
measuring the readability of the text based on sentence and word length.
4. Results
Variant SARI BLEU BERTScore ROUGE FKGL
Llama-2-7b- Zero-shot 30.75 0.19 0.91 0.49 8.64
chat-hf SFT 69.74 0.67 0.97 0.83 7.55
Llama-2-7B- Zero-shot 27.84 0.10 0.87 0.29 8.59
32K-Instruct SFT 70.39 0.69 0.97 0.83 7.59
RL (R ) 33.23 0.26 0.90 0.49 8.25
Llama-2-7b- FKGL+Rel
RLHF (R ) 30.95 0.27 0.91 0.53 8.57
chat-hf OvS
RLHF (R ) 34.28 0.31 0.91 0.56 8.16
FKGL+OvS
SFT+RLHF (R ) 73.50 0.71 0.97 0.85 7.85
FKGL+OvS
RL (R ) 44.48 0.52 0.92 0.64 6.92
Llama-2-7B- FKGL+Rel
RLHF (R ) 42.49 0.43 0.93 0.61 8.26
32K-Instruct OvS
RLHF (R ) 50.54 0.57 0.95 0.76 7.84
FKGL+OvS
SFT+RLHF (R ) 58.97 0.69 0.96 0.85 7.63
FKGL+OvS
Zero-shot 26.07 0.17 0.92 0.46 6.12
In-context 26.23 0.17 0.92 0.46 6.10
GPT4 Turbo Instruct 26.70 0.28 0.94 0.54 5.89
Chain-of-Thought 25.33 0.22 0.93 0.49 5.35
Self-Correction 27.55 0.17 0.92 0.45 5.59
Table2: ResultsofPrompt-based,SFT,andRLHFexperimentationonSimpDCdataset
4.1. Text Simplification
Table 2 presents the performance on the SimpleDC withheld test set, including three LLMs:
Llama-2-7b-chat-hf, Llama-2-7b-32K-Instruct, and GPT4 Turbo. In the zero-shot setting, Llama-
2-7b-chat-hf achieved the highest SARI performance, although GPT-4 achieved the lowest FKGL.
ForbothLlama2models,SFTdrasticallyincreasedtheperformanceofSARI,BLEU,BERTScore,
and ROUGE and reduced FKGL by approximately one grade level. Even with the relatively small
SimpleDCtrainingset, SFTallowstheLlama2modelstolearnanunderstandingoftheSimpleDC
annotation approach and voice of the annotators. SFT performance for the two Llama 2 variants
is similar across all metrics, including SARI (69.74 vs. 70.39). The success of the RL/RLHF varies
byLlama2variantandrewardstrategy. IntheRL/RLHF-onlyexperimentation, Llama-2-7b-32K-
Instruct consistently outperforms Llama-2-7b-chat-hf across metrics, including higher SARI and
lower FKGL. Our proposed reward function, R , outperforms the baseline, R ,
FKGL+OvS FKGL+Rel
12approach for SARI, BLEU, BERTScore, and ROUGE. For Llama-2-7b-32K-Instruct, the proposed
RLHF,R ,increasesperformancefromthezero-shotapproachfrom27.84to50.54SARI.
FKGL+OvS
For Llama-2-7b-chat-hf, combining SFT and RLHF yields the best-performing system in terms of
SARI (73.50), BLEU (0.71), BERTScore (0.97), and ROUGE (0.85). For this configuration, the
FKGLmetricsuggeststhatthisapproachyieldstextatarelativelylowreadinglevelof7.85. These
results demonstrate that RL/RLHF can be effectively used to improve text simplification perfor-
mance both with and without prior SFT on labeled data. Additionally, these results demonstrate
theimportanceofincorporatinghumanfeedbackthroughRLHFoverRLwithouthumanfeedback.
Conversely, the GPT4 Turbo model exhibited lower scores across all adequacy metrics (SARI,
BLEU,BERTScore,andROUGE)comparedtotheLlama2modelsbutachievedlowerFKGL.The
lowerperformancedoesnotnecessarilyindicateGPT-4generatedlow-qualitysimplifications. Based
on our preliminary qualitative review, GPT-4 edited the original text more completely, resulting in
alargerdivergencebetweentheoriginalandsimplifiedtext. Additionally,thevoiceorwritingstyle
of GPT-4 appears to differ from that of our annotators, contributing to the lower performance for
adequacymetrics. Thebestpromptingperformancewasachievedusingtheproposedself-correction
technique, which increased the SARI to 27.55 and lowered the FKGL to 5.59.
4.2. Domain Adaptation
Model Name RLHF Reward SARI BLEU BERTScore ROUGE FKGL
none 44.90 0.58 0.95 0.70 8.19
Llama-2-7b-
R +R 70.54 0.68 0.97 0.85 7.71
chat-hf FKGL Rel
R +R 44.21 0.59 0.95 0.73 7.05
FKGL OvS
none 38.97 0.54 0.94 0.67 7.96
Llama-2-7B-
R +R 57.57 0.66 0.96 0.77 7.54
32K-Instruct FKGL Rel
R +R 49.99 0.59 0.96 0.78 7.33
FKGL OvS
Table3: ResultsofdomainadaptationexperimentationonSimpDCdataset
WeexploredthepotentialforRL/RLHFtoadaptanout-of-domaintextsimplificationmodelto
a target domain, specifically the adaptation of a text simplification model trained on Med-EASi to
our SimpleDC corpus. Table 3 presents our domain adaptation results, where all models were first
trained through SFT on the Med-EASi training set [54]. The models were subsequently adapted
through RL/RLHF using unlabeled texts related to digestive cancer that are not contained in
SimpleDC. This experimentation was intended to assess the potential for leveraging external out-
of-domaincorporatoimprovein-domainperformance. Theperformancegainsassociatedwithusing
RL/RLHF for domain adaptation vary by Llama 2 variant and the specific reward function. For
Llama-2-7b-chat-hf, RL with the R reward led to an increase across all adequacy met-
FKGL+Rel
rics, including increased SARI from 44.90 to 70.54, BLEUScore from 0.58 to 0.68, ROUGE 0.70 to
0.85. Simultaneously, the FKGL decreased from 8.19 to 7.71, indicating more extreme simplifica-
tion, which is desired for this task. Similarly, the Llama-2-7B-32K-Instruct model demonstrated
improvements with RL/RLHF, with the largest gains associated with the R reward. In
FKGL+Rel
thisconfiguration, RLincreasedtheSARIscorefrom38.97to57.57andtheBLEUscore from 0.54
to0.66. Furthermore,theR rewardalsoresultedinimprovements,buttoalesserextent
FKGL+OvS
compared to the R reward. In all of the experiments, the FKGL score decreases when
FKGL+Rel
13RL/RLHF is combined with SFT. The most prominent finding in the domain adaptation experi-
mentationisthatthebest-performingdomain-adaptedLLM(Llama-2-7b-chat-hfwithR
FKGL+Rel
reward in Table 3) achieves very similar performance to the best performing in-domain models
trained with SFT on SimpleDC (Llama-2-7b-chat-hf and Llama-2-7b-32K-Instruct with SFT in
Table 2). These findings underscore the potential of combining SFT with targeted RL/RLHF to
improve the performance of NLP models in domain-specific tasks. This will also pave the way to-
wardloweringannotationquantityandcostswheretheannotationiscostlyandrequiresaspecialist,
like the medical domain.
5. Conclusions
In this paper, we present SimpleDC, a carefully curated human-annotated text simplification
corpus for digestive cancer education. The rich annotations of the dataset have been instrumental
in training effective simplification models. We explore a range of learning approaches, including
supervised fine-tuning, RL, RLHF, and prompt-based approaches. We introduced a new RLHF
reward function, R , which outperforms an existing RL reward function for text simpli-
FKGL+Rel
fication. In terms of model performance, we observed that Llama 2 models, being supervised and
data-dependent, outperformed GPT models in our experiments. This highlights the significant im-
pact of high-quality domain-specific data in improving model performance. The addition of such
data to Llama 2 models led to a substantial improvement in simplification quality, achieving a bal-
ancebetweencomprehensibilityandclinicalaccuracy. OurresultsalsodemonstratethatRL/RLHF
can be used to incorporate unlabeled text into training to improve simplification performance: i)
as a standalone training step, ii) in conjunction with supervised fine-tuning, and iii) as a domain
adaptation technique. Although this represents a significant advancement, our findings also under-
score the vast potential for future research in this area. Our work provides a robust foundation
for further explorations, aiming to refine and expand the capabilities of NLP models to simplify
complex medical information for enhanced patient understanding.
References
[1] Cline RJW, Haynes KM. Consumer health information seeking on the Internet: the state of
theart. HealthEducationResearch.200112;16(6):671-92. Availablefrom: https://doi.org/
10.1093/her/16.6.671.
[2] Friedman DB, Hoffman-Goetz L. A Systematic Review of Readability and Comprehension
Instruments Used for Print and Web-Based Cancer Information. Health Education & Be-
havior. 2006;33(3):352-73. PMID: 16699125. Available from: https://doi.org/10.1177/
1090198105277329.
[3] Hansberry DR, John A, John E, Agarwal N, Gonzales SF, Baker SR. A Critical Review of
the Readability of Online Patient Education Resources From RadiologyInfo.Org. American
Journal of Roentgenology. 2014;202(3):566-75. PMID: 24555593. Available from: https:
//doi.org/10.2214/AJR.13.11223.
[4] Jindal P, MacDermid JC. Assessing reading levels of health information: uses and limitations
of flesch formula. Education for Health: Change in Learning & Practice. 2017;30(1).
14[5] Rimer B, Jones WL, Keintz MK, Catalano RB, Engstrom PF. Informed consent: a crucial
step in cancer patient education. Health Education Quarterly. 1984:30-42.
[6] MillsME,SullivanK. Theimportanceofinformationgivingforpatientsnewlydiagnosedwith
cancer: a review of the literature. Journal of clinical nursing. 1999;8(6):631-42.
[7] van den Bercken L, Sips RJ, Lofi C. Evaluating Neural Text Simplification in the Medical
Domain. In: The World Wide Web Conference. WWW ’19. New York, NY, USA: Association
for Computing Machinery; 2019. p. 3286–3292. Available from: https://doi.org/10.1145/
3308558.3313630.
[8] Devaraj A, Marshall I, Wallace B, Li JJ. Paragraph-level Simplification of Medical Texts.
In: Toutanova K, Rumshisky A, Zettlemoyer L, Hakkani-Tur D, Beltagy I, Bethard S, et al.,
editors.Proceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociation
for Computational Linguistics: Human Language Technologies. Online: Association for Com-
putational Linguistics; 2021. p. 4972-84. Available from: https://aclanthology.org/2021.
naacl-main.395.
[9] McCabe R, Healey PG. Miscommunication in doctor–patient communication. Topics in cog-
nitive science. 2018;10(2):409-24.
[10] Rawla P, Sunkara T, Barsouk A. Epidemiology of colorectal cancer: incidence, mortality,
survival, and risk factors. Gastroenterology Review. 2019;14(2):89-103.
[11] TegliaF,BoffettaP. Associationbetweentrendsofmortalityandincidence,survivalandstage
at diagnosis for six digestive and respiratory cancers in United States (2009–2013). European
Journal of Cancer Prevention. 2023;32(2):195-202.
[12] Touvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y, et al. Llama 2: Open
foundationandfine-tunedchatmodels. arXivpreprintarXiv:230709288.2023. Availablefrom:
https://arxiv.org/abs/2307.09288.
[13] Achiam OJ, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. GPT-4 Technical
Report; 2023. Available from: https://api.semanticscholar.org/CorpusID:257532815.
[14] Brown T, Mann B, Ryder N, et al. Language Models are Few-Shot Learn-
ers. Advances in Neural Information Processing Systems;33:1877-901. Avail-
able from: https://proceedings.neurips.cc/paper_files/paper/2020/file/
1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.
[15] Cao Y, Shui R, Pan L, Kan MY, Liu Z, Chua TS. Expertise Style Transfer: A New Task To-
wards Better Communication between Experts and Laymen. In: Jurafsky D, Chai J, Schluter
N, Tetreault J, editors. Proceedings of the 58th Annual Meeting of the Association for Com-
putational Linguistics. Online: Association for Computational Linguistics; 2020. p. 1061-71.
Available from: https://aclanthology.org/2020.acl-main.100.
[16] Nisioi S, Sˇtajner S, Ponzetto SP, Dinu LP. Exploring Neural Text Simplification Models. In:
Barzilay R, Kan MY, editors. Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers). Vancouver, Canada: Association
for Computational Linguistics; 2017. p. 85-91. Available from: https://aclanthology.org/
P17-2014.
15[17] Maddela M, Alva-Manchego F, Xu W. Controllable Text Simplification with Explicit Para-
phrasing. In: Toutanova K, Rumshisky A, Zettlemoyer L, Hakkani-Tur D, Beltagy I,
Bethard S, et al., editors. Proceedings of the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics: Human Language Technologies. On-
line: Association for Computational Linguistics; 2021. p. 3536-53. Available from: https:
//aclanthology.org/2021.naacl-main.277.
[18] North K, Zampieri M, Shardlow M. Lexical Complexity Prediction: An Overview. ACM
Computing Surveys. 2022;55(9).
[19] Shardlow M, Cooper M, Zampieri M. CompLex — A New Corpus for Lexical Complexity
Prediction from Likert Scale Data. In: Proceedings of READI; 2020. .
[20] Liang J, Tsou CH, Poddar A. A Novel System for Extractive Clinical Note Summariza-
tion using EHR Data. In: Rumshisky A, Roberts K, Bethard S, Naumann T, editors.
Proceedings of the 2nd Clinical Natural Language Processing Workshop. Minneapolis, Min-
nesota, USA: Association for Computational Linguistics; 2019. p. 46-54. Available from:
https://aclanthology.org/W19-1906.
[21] KanwalN,RizzoG.Attention-BasedClinicalNoteSummarization.In: Proceedingsofthe37th
ACM/SIGAPPSymposiumonAppliedComputing.SAC’22.NewYork,NY,USA:Association
for Computing Machinery; 2022. p. 813–820. Available from: https://doi.org/10.1145/
3477314.3507256.
[22] Feblowitz JC, Wright A, Singh H, Samal L, Sittig DF. Summarization of clinical information:
A conceptual model. Journal of Biomedical Informatics. 2011;44(4):688-99. Available from:
https://www.sciencedirect.com/science/article/pii/S1532046411000591.
[23] Guo Y, Qiu W, Wang Y, Cohen T. Automated Lay Language Summarization of Biomedi-
cal Scientific Reviews. Proceedings of the AAAI Conference on Artificial Intelligence. 2021
May;35(1):160-8. Available from: https://ojs.aaai.org/index.php/AAAI/article/view/
16089.
[24] Abrahamsson E, Forni T, Skeppstedt M, Kvist M. Medical text simplification using syn-
onym replacement: Adapting assessment of word difficulty to a compounding language. In:
Williams S, Siddharthan A, Nenkova A, editors. Proceedings of the 3rd Workshop on Pre-
dicting and Improving Text Readability for Target Reader Populations (PITR). Gothen-
burg, Sweden: Association for Computational Linguistics; 2014. p. 57-65. Available from:
https://aclanthology.org/W14-1207.
[25] Van H, Kauchak D, Leroy G. AutoMeTS: The Autocomplete for Medical Text Simplifica-
tion. In: Scott D, Bel N, Zong C, editors. Proceedings of the 28th International Conference
on Computational Linguistics. Barcelona, Spain (Online): International Committee on Com-
putational Linguistics; 2020. p. 1424-34. Available from: https://aclanthology.org/2020.
coling-main.122.
[26] Cardon R, Grabar N. Parallel Sentence Retrieval From Comparable Corpora for Biomedical
Text Simplification. In: Mitkov R, Angelova G, editors. Proceedings of the International Con-
ferenceonRecentAdvancesinNaturalLanguageProcessing(RANLP2019).Varna, Bulgaria:
INCOMA Ltd.; 2019. p. 168-77. Available from: https://aclanthology.org/R19-1020.
16[27] Sakakini T, Lee JY, Duri A, Azevedo RFL, Sadauskas V, Gu K, et al. Context-Aware
Automatic Text Simplification of Health Materials in Low-Resource Domains. In: Hold-
erness E, Jimeno Yepes A, Lavelli A, Minard AL, Pustejovsky J, Rinaldi F, editors. Pro-
ceedings of the 11th International Workshop on Health Text Mining and Information Anal-
ysis. Online: Association for Computational Linguistics; 2020. p. 115-26. Available from:
https://aclanthology.org/2020.louhi-1.13.
[28] Kandula S, Curtis D, Zeng-Treitler Q. A semantic and syntactic text simplification tool for
health content. In: AMIA annual symposium proceedings. vol. 2010. American Medical In-
formatics Association; 2010. p. 366. Available from: https://www.ncbi.nlm.nih.gov/pmc/
articles/PMC3041424/.
[29] GrabarN,SaggionH. EvaluationofAutomaticTextSimplification: Wherearewenow,where
should we go from here. In: Est`eve Y, Jim´enez T, Parcollet T, Zanon Boito M, editors.
Actes de la 29e Conf´erence sur le Traitement Automatique des Langues Naturelles. Volume 1
: conf´erence principale. Avignon, France: ATALA; 2022. p. 453-63. Available from: https:
//aclanthology.org/2022.jeptalnrecital-taln.47.
[30] Shardlow M. A survey of automated text simplification. International Journal of Advanced
Computer Science and Applications. 2014;4(1):58-70.
[31] RamadierL,LafourcadeM. RadiologicalTextSimplificationUsingaGeneralKnowledgeBase.
In: Gelbukh A, editor. Computational Linguistics and Intelligent Text Processing. Cham:
Springer International Publishing; 2018. p. 617-27.
[32] Zilio L, Paraguassu LB, Hercules LAL, Ponomarekano GL, Berwanger LP, Finatto MJB. A
Lexical Simplification Tool for Promoting Health Literacy; 2020.
[33] Qenam B, Kim TY, Carroll MJ, Hogarth M. Text Simplification Using Consumer Health
Vocabulary to Generate Patient-Centered Radiology Reporting: Translation and Evaluation.
J Med Internet Res. 2017 Dec;19(12):e417. Available from: http://www.jmir.org/2017/12/
e417/.
[34] Leroy G, Endicott JE, Kauchak D, Mouradi O, Just M, et al. User evaluation of the effects of
a text simplification algorithm using term familiarity on perception, understanding, learning,
and information retention. Journal of medical Internet research. 2013;15(7):e2569. Available
from: https://www.jmir.org/2013/7/e144.
[35] Kloehn N, Leroy G, Kauchak D, Gu Y, Colina S, Yuan NP, et al. Improving Consumer
UnderstandingofMedicalText: DevelopmentandValidationofaNewSubSimplifyAlgorithm
to Automatically Generate Term Explanations in English and Spanish. J Med Internet Res.
2018 Aug;20(8):e10779. Available from: http://www.jmir.org/2018/8/e10779/.
[36] Basu C, Vasu R, Yasunaga M, Yang Q. Med-EASi: Finely Annotated Dataset and Models
for Controllable Simplification of Medical Texts. In: Proceedings of the Thirty-Seventh AAAI
Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications
of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial
Intelligence. AAAI’23/IAAI’23/EAAI’23. AAAI Press; 2023. Available from: https://doi.
org/10.1609/aaai.v37i12.26649.
17[37] Phatak A, Savage DW, Ohle R, Smith J, Mago V. Medical Text Simplification Using Rein-
forcement Learning (TESLEA): Deep Learning–Based Text Simplification Approach. JMIR
Med Inform. 2022 Nov;10(11):e38095. Available from: https://medinform.jmir.org/2022/
11/e38095.
[38] FilippovaK,StrubeM. DependencyTreeBasedSentenceCompression. In: WhiteM,Nakatsu
C, McDonald D, editors. Proceedings of the Fifth International Natural Language Generation
Conference. Salt Fork, Ohio, USA: Association for Computational Linguistics; 2008. p. 25-32.
Available from: https://aclanthology.org/W08-1105.
[39] Filippova K, Strube M. Sentence Fusion via Dependency Graph Compression. In: Lapata
M, Ng HT, editors. Proceedings of the 2008 Conference on Empirical Methods in Natural
Language Processing. Honolulu, Hawaii: Association for Computational Linguistics; 2008. p.
177-85. Available from: https://aclanthology.org/D08-1019.
[40] Shardlow M, Nawaz R. Neural Text Simplification of Clinical Letters with a Domain Specific
PhraseTable. In: KorhonenA,TraumD,M`arquezL,editors.Proceedingsofthe57thAnnual
Meeting of the Association for Computational Linguistics. Florence, Italy: Association for
Computational Linguistics; 2019. p. 380-9. Available from: https://aclanthology.org/
P19-1037.
[41] Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, et al. Exploring the Limits of
TransferLearningwithaUnifiedText-to-TextTransformer. JMachLearnRes.2020jan;21(1).
[42] ChungHW,HouL,LongpreS,ZophB,TayY,FedusW,etal..ScalingInstruction-Finetuned
Language Models. arXiv; 2022. Available from: https://arxiv.org/abs/2210.11416.
[43] TouvronH,LavrilT,IzacardG,MartinetX,LachauxMA,LacroixT,etal. Llama: Openand
efficient foundation language models. arXiv preprint arXiv:230213971. 2023. Available from:
https://doi.org/10.48550/arXiv.2302.13971.
[44] OpenAI. GPT-4 Technical Report; 2023.
[45] Wei J, Wang X, Schuurmans D, Bosma M, ichter b, Xia F, et al. Chain-of-
Thought Prompting Elicits Reasoning in Large Language Models. In: Koyejo S,
Mohamed S, Agarwal A, Belgrave D, Cho K, Oh A, editors. Advances in Neu-
ral Information Processing Systems. vol. 35. Curran Associates, Inc.; 2022. p. 24824-
37. Available from: https://proceedings.neurips.cc/paper_files/paper/2022/file/
9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf.
[46] Wang J, Li J, Zhao H. Self-prompted Chain-of-Thought on Large Language Models for Open-
domain Multi-hop Reasoning. In: Bouamor H, Pino J, Bali K, editors. Findings of the As-
sociation for Computational Linguistics: EMNLP 2023. Singapore: Association for Compu-
tational Linguistics; 2023. p. 2717-31. Available from: https://aclanthology.org/2023.
findings-emnlp.179.
[47] WuTH,LianL,GonzalezJE,LiB,DarrellT.Self-correctingLLM-controlledDiffusionModels.
arXiv preprint arXiv:231116090. 2023.
18[48] Pan L, Saxon M, Xu W, Nathani D, Wang X, Wang WY. Automatically correcting large
language models: Surveying the landscape of diverse self-correction strategies. arXiv preprint
arXiv:230803188. 2023.
[49] Nakamachi A, Kajiwara T, Arase Y. Text Simplification with Reinforcement Learning Using
Supervised Rewards on Grammaticality, Meaning Preservation, and Simplicity. In: Shmueli
B, Huang YJ, editors. Proceedings of the 1st Conference of the Asia-Pacific Chapter of the
Association for Computational Linguistics and the 10th International Joint Conference on
Natural Language Processing: Student Research Workshop. Suzhou, China: Association for
Computational Linguistics; 2020. p. 153-9. Available from: https://aclanthology.org/
2020.aacl-srw.22.
[50] Yanamoto D, Ikawa T, Kajiwara T, Ninomiya T, Uchida S, Arase Y. Controllable Text Sim-
plificationwithDeepReinforcementLearning. In: HeY,JiH,LiS,LiuY,ChangCH,editors.
Proceedingsofthe2ndConferenceoftheAsia-PacificChapteroftheAssociationforComputa-
tionalLinguisticsandthe12thInternationalJointConferenceonNaturalLanguageProcessing
(Volume 2: Short Papers). Online only: Association for Computational Linguistics; 2022. p.
398-404. Available from: https://aclanthology.org/2022.aacl-short.49.
[51] Zhang X, Lapata M. Sentence Simplification with Deep Reinforcement Learning. In: Palmer
M,HwaR,RiedelS,editors.Proceedingsofthe2017ConferenceonEmpiricalMethodsinNat-
uralLanguageProcessing.Copenhagen,Denmark: AssociationforComputationalLinguistics;
2017. p. 584-94. Available from: https://aclanthology.org/D17-1062.
[52] Alkaldi W, Inkpen D. Text Simplification to Specific Readability Levels. Mathematics.
2023;11(9):2063.
[53] Kincaid JP, Fishburne Jr RP, Rogers RL, Chissom BS. Derivation of new readability formulas
(automated readability index, fog count and flesch reading ease formula) for navy enlisted
personnel. Institute for Simulation and Training, University of Central Florida; 1975.
[54] Basu C, Vasu R, Yasunaga M, Yang Q. Med-easi: Finely annotated dataset and models for
controllable simplification of medical texts. arXiv preprint arXiv:230209155. 2023.
[55] Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, et al. Exploring the limits of
transfer learning with a unified text-to-text transformer. The Journal of Machine Learning
Research. 2020;21(1):5485-551.
[56] Schulman J, Wolski F, Dhariwal P, Radford A, Klimov O. Proximal policy optimization
algorithms. arXiv preprint arXiv:170706347. 2017.
[57] Christiano PF, Leike J, Brown T, Martic M, Legg S, Amodei D. Deep reinforcement learning
from human preferences. Advances in neural information processing systems. 2017;30.
[58] Chen Q, Peng Y, Lu Z. BioSentVec: creating sentence embeddings for biomedical texts. In:
2019 IEEE International Conference on Healthcare Informatics (ICHI). IEEE; 2019. p. 1-5.
[59] Gururangan S, Marasovi´c A, Swayamdipta S, Lo K, Beltagy I, Downey D, et al. Don’t Stop
Pretraining: Adapt Language Models to Domains and Tasks. In: Proceedings of ACL; 2020. .
19[60] Csisz´ar I. I-divergence geometry of probability distributions and minimization problems. The
annals of probability. 1975:146-58.
[61] Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, et al. Pytorch: An impera-
tive style, high-performance deep learning library. Advances in neural information processing
systems. 2019;32.
[62] WolfT,DebutL,SanhV,ChaumondJ,DelangueC,MoiA,etal. Huggingface’stransformers:
State-of-the-art natural language processing. arXiv preprint arXiv:191003771. 2019.
[63] Biewald L. Experiment Tracking with Weights and Biases; 2020. Software available from
wandb.com. Available from: https://www.wandb.com/.
[64] Hu EJ, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, et al. Lora: Low-rank adaptation of
large language models. arXiv preprint arXiv:210609685. 2021.
[65] Xu L, Xie H, Qin SZJ, Tao X, Wang FL. Parameter-Efficient Fine-Tuning Methods for Pre-
trainedLanguageModels: ACriticalReviewandAssessment. arXivpreprintarXiv:231212148.
2023.
[66] Mangrulkar S, Gugger S, Debut L, Belkada Y, Paul S, Bossan B. PEFT: State-of-the-art
Parameter-Efficient Fine-Tuning methods; 2022. https://github.com/huggingface/peft.
[67] Optimizing Statistical Machine Translation for Text Simplification. vol. 4; 2016. p. 401-15.
Available from: https://www.aclweb.org/anthology/Q16-1029.
[68] Papineni K, Roukos S, Ward T, jing Zhu W. BLEU: a Method for Automatic Evaluation of
Machine Translation; 2002. p. 311-8.
[69] Lin CY, Och FJ. ORANGE: a Method for Evaluating Automatic Evaluation Metrics for
MachineTranslation. In: COLING2004: Proceedingsofthe20thInternationalConferenceon
Computational Linguistics. Geneva, Switzerland: COLING; 2004. p. 501-7. Available from:
https://www.aclweb.org/anthology/C04-1072.
[70] Zhang*T,Kishore*V,Wu*F,WeinbergerKQ,ArtziY. BERTScore: EvaluatingTextGener-
ation with BERT. In: International Conference on Learning Representations; 2020. Available
from: https://openreview.net/forum?id=SkeHuCVFDr.
[71] LinCY. ROUGE:APackageforAutomaticEvaluationofSummaries. In: TextSummarization
Branches Out. Barcelona, Spain: Association for Computational Linguistics; 2004. p. 74-81.
Available from: https://www.aclweb.org/anthology/W04-1013.
20