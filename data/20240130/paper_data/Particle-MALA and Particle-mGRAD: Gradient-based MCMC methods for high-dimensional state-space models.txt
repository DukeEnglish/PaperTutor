Particle-MALA and Particle-mGRAD:
Gradient-based MCMC methods for high-dimensional
state-space models
1 2
Adrien Corenflos and Axel Finke
1
Department of Electrical Engineering and Automation,
Aalto University, Finland
adrien.corenflos@aalto.fi
2Department of Mathematical Sciences,
Loughborough University, UK
a.finke@lboro.ac.uk
January 29, 2024
State-of-the-art methods for Bayesian inference in state-space models are (a) con-
ditional sequential Monte Carlo (CSMC) algorithms; (b) sophisticated ‘classical’
MCMC algorithms like MALA, or mGRAD from Titsias and Papaspiliopoulos
(2018). The former propose N particles at each time step to exploit the model’s
‘decorrelation-over-time’ property and thus scale favourably with the time horizon,
T, but break down if the dimension of the latent states, D, is large. The latter
leverage gradient-/prior-informed local proposals to scale favourably with D but
exhibit sub-optimal scalability with T due to a lack of model-structure exploita-
tion. We introduce methods which combine the strengths of both approaches. The
first, Particle-MALA,spreadsN particleslocallyaroundthecurrentstateusinggra-
dient information, thus extending MALA to T > 1 time steps and N > 1 proposals.
The second, Particle-mGRAD, additionally incorporates (conditionally) Gaussian
prior dynamics into the proposal, thus extending the mGRAD algorithm to T > 1
time steps and N > 1 proposals. We prove that Particle-mGRAD interpolates
between CSMC and Particle-MALA, resolving the ‘tuning problem’ of choosing be-
tween CSMC (superior for highly informative prior dynamics) and Particle-MALA
(superior for weakly informative prior dynamics). We similarly extend other ‘classi-
cal’ MCMC approaches like auxiliary MALA, aGRAD, and preconditioned Crank–
Nicolson–Langevin (PCNL) to T > 1 time steps and N > 1 proposals. In ex-
periments, for both highly and weakly informative prior dynamics, our methods
substantially improve upon both CSMC and sophisticated ‘classical’ MCMC ap-
proaches.
1
4202
naJ
62
]OC.tats[
1v86841.1042:viXra1 Introduction
1.1 Feynman–Kac models
The aim of this work is to construct efficient Markov chain Monte Carlo (MCMC) updates for
sampling from a continuous joint smoothing distribution π (x ) on XT, where X := RD and
T 1:T
where for any t ≤ T, we have defined the following distributions (termed filters):
t
π (x ) ∝ Y Q (x ). (1)
t 1:t s s−1:s
s=1
Here, Q (x ) > 0 is differentiable and can be evaluated point-wise. Throughout this work,
t t−1:t
we use the convention that quantities with ‘time’ subscripts t ≤ 0 or t > T should be ignored,
so that, e.g., Q (x ) ≡ Q (x ) and Q (x ) ≡ 1. We will frequently work with some
1 0:1 1 1 T+1 T:T+1
decomposition
Q (x ) = M (x |x )G (x ),
t t−1:t t t t−1 t t−1:t
such that
• M (·|x )isadensity(w.r.t.asuitableversionoftheLebesguemeasure)andalsodefines
t t−1
a Markov transition kernel called mutation kernel;
• G (x ) > 0 is called potential function.
t t−1:t
We assume that these densities and potential functions are differentiable and that they (as well
as their gradients) can be evaluated point-wise. Motivated by the following example, we will
sometimes refer to M (x ) := QT M (x |x ) as the prior dynamics of the latent states
1:T 1:T t=1 t t t−1
x and G (x ) := QT G (x ) as the likelihood.
1:T 1:T 1:T t=1 t t−1:t
Example 1 (state-space model). One important special case of Feynman–Kac models are
state-space models. A state-space model is a bivariate Markov chain (x ,y ) on X×Y, where
t t t≥1
X := RD and Y := RD′, with initial density p(x ,y ) = f (x )g (y |x ) and transition densities
1 1 1 1 1 1 1
p(x ,y |x ) = f (x |x )g (y |x ) (w.r.t. a suitable version of the Lebesgue measure). State-
t t t−1 t t t−1 t t t
space models assume that only the measurements y can be observed whilst the Markov chain
1:T
(x ) (often representing the evolution of the phenomenon of interest) is latent. The joint
t t≥1
smoothing distribution then encodes our knowledge of the latent states x given the available
1:T
data y :
1:T
T
π (x ) := p(x |y ) ∝ Y f (x |x )g (y |x ).
T 1:T 1:T 1:T t t t−1 t t t
t=1
One possible way of casting such a state-space model as a Feynman–Kac model (there are
others) is then to take M (x |x ) = f (x |x ) and G (x ) = g (y |x ). In this case,
t t t−1 t t t−1 t t−1:t t t t
M (x ) = p(x ), G (x ) = p(y |x ), and π (x ) = p(x |y ), for t ≤ T.
1:T 1:T 1:T 1:T 1:T 1:T 1:T t 1:t 1:t 1:t
1.2 Sampling the latent states
Performing inference about the latent states x requires calculating expectations of the form
1:T
E [φ(x )], for some integrable test function φ: XT → R. Unfortunately, such expecta-
x1:T∼πT 1:T
tionsdonotadmitclosed-formexpressionsinmostrealisticproblemsandmustbeapproximated
by some Monte Carlo estimate 1 PI φ(x [i]) using samples (x [i])I (approximately) dis-
I i=1 1:T 1:T i=1
tributed according to π . These often come from some MCMC algorithm targeting π .
T T
2‘Classical’ MCMC methods. Unfortunately, simple MCMC approaches like the indepen-
dent Metropolis–Hastings (IMH) algorithm (Hastings, 1970) perform poorly if the problem size:
D ×T, is large due the difficulty of constructing efficient global (a.k.a. independent) proposal
distributions in high dimensions. To circumvent this difficulty, MCMC algorithms with local
moves like the random-walk Metropolis (RWM) algorithm (Metropolis et al., 1953), propose a
new state of the Markov chain near the current state. By decreasing the proposal scale at a
suitable rate with the problem size, the RWM algorithm can circumvent this curse of dimension
(Roberts et al., 1997). Further improved performance can be achieved by exploiting
• gradient information, i.e. by including gradients of the log-likelihood or log-target density
into the proposal as in the Metropolis-adjusted Langevin algorithm (MALA) from Besag
(1994) and in the auxiliary MALA (aMALA) from Titsias and Papaspiliopoulos (2018);
and additionally
• prior information, i.e. by explicitly incorporating the prior dependence structure into the
proposal as in the preconditioned Crank–Nicolson–Langevin (PCNL) and related algo-
rithms (see, e.g., Cotter et al., 2013, and references therein) or in the marginal gradient
(mGRAD) and auxiliary gradient (aGRAD)1 algorithms from Titsias (2011); Titsias and
Papaspiliopoulos (2018).
Figure 1a illustrates that ‘classical’ MCMC algorithms can scale favourably with D.
However, ‘classical’ MCMC algorithms are agnostic to the ‘decorrelation-over-time’ structure
of the target distribution π (x ), i.e., to the fact that, for suitably regular models, the correla-
T 1:T
tion of x and x under π(x ) decays with |t−s|. For example, for the simple RWM algorithm
s t 1:T
andMALA,thestep size δ > 0(i.e., proposalvariance)wouldneedtodecreaseatasuitablerate
with T (δ ∈ O((DT)−1) and δ ∈ O((DT)−1/3), respectively) even if the model was completely
independent across time steps (Roberts and Rosenthal, 2001). Therefore, it stands to reason
that the scaling of ‘classical’ MCMC methods like MALA, PCNL or mGRAD/aGRAD with
the time horizon T could be improved by empowering them to exploit this model structure.
CSMC methods. Another popular π -invariant MCMC-kernel, P , is induced by run-
T CSMC
ning the CSMC algorithm proposed in the seminal work Andrieu et al. (2010); Whiteley (2010).
Given the current state x ∈ XT of the Markov chain (then called the reference path) this
1:T
algorithm generates x˜ ∼ P (·|x ) as follows, where we write [n] := {1,...,n} and
1:T CSMC 1:T
[n] := [n]∪{0}:
0
1. For t = 1,...,T, sample some index k
t
from a uniform distribution on [N] 0; set x tkt :=
x and sample the remaining particles x−kt := (x0,...,xkt−1 ,xkt+1 ,...,xN) conditionally
t t t t t t
independently such that for n ̸= k ,
t
xn ∼ M
(·|xan
t−1), (2)
t t t−1
for ancestor indices an ∈ [N] whose rôle is explained later.
t−1 0
2. Return x˜
1:T
:= (x 1l1,...,x tlT), for indices l 1,...,l
T
∈ [N]
0
sampled from an appropriate
distribution.
1Throughout this work, ‘aGRAD’ refers more specifically to the ‘aGrad-z’ algorithm from Titsias and Pa-
paspiliopoulos (2018).
3CSMC
5 Particle-RWM
Particle-aMALA
15
4 Particle-MALA
Particle-aMALA+
Particle-aGRAD
10 3
Particle-mGRAD
TwistedParticle-aGRAD
2
IMH
5
RWM
1
aMALA
MALA
0 0
aGRAD
10 20 30 40 50 60 70 80 90 100 250 500 750 1000
Dimension, D Time horizon, T
(a) EmpiricalscalingwithDforfixed (b) Empirical scaling with T for fixed
time horizon T = 25. state dimension D = 10.
Figure 1: Toy linear-Gaussian state-space model with M (x |x ) = N(x ;x ,λI) and
t t t−1 t t−1
G (x ) = N(y ;x ,I), where I is the (D × D)-identity matrix and λ = 1. For
t t−1:t t t
a fair comparison, all methods use N +1 = 32 particles. The step sizes are: (TD)−1
for (multi-proposal) RWM, D−1 for Particle-RWM, (TD)−1/3 for (multi-proposal)
aMALA/MALA/aGRAD, and D−1/3 for the remaining (i.e., new) methods. Panel a
illustrates that as D increases, some ‘classical’ MCMC algorithms (RWM, MALA,
aMALA and aGRAD) are stable but the CSMC algorithm breaks down. Conversely,
PanelbillustratesthatasT increases, theCSMCalgorithmisstableinT butall‘clas-
sical’ MCMC algorithms (IMH, RWM, MALA, aMALA and aGRAD) break down.
Informally, the CSMC algorithm can be interpreted as employing T separate accept–reject
steps (one at each time point) which allows it to exploit the ‘decorrelation-over-time’ property
of π (x ) (akin to a ‘classical’ MCMC algorithm with blocking in the ‘time’ direction as noted
T 1:T
by Singh et al. 2017). For suitably regular problems, the CSMC algorithm therefore scales more
favourably with T than ‘classical’ MCMC approaches as illustrated in Figure 1b.
Unfortunately, as shown in Finke and Thiery (2023), the CSMC algorithm suffers from a
curse of dimension in the state dimension D: as D increases, it becomes increasingly likely that
x˜ coincides exactly with x , i.e., the induced MCMC chain gets stuck. This is unsurprising
1:T 1:T
because the CSMC algorithm generalises the IMH algorithm to T > 1 time steps and N > 1
proposals. Indeed, note that (2) is again an independent (i.e. global) proposal in the sense that
it does not depend on the time-t component of the current state of the Markov chain, x ; and
t
suchproposalsareknowntoscalepoorlywithdimension(duetothedifficultyoffindingefficient
global proposals in high dimensions). The only potential remedy: increasing N exponentially
with D, is prohibitively costly.
Existing combinations of ‘classical’ MCMC and CSMC. To circumvent this problem,
Finke and Thiery (2023) introduced the Particle-RWM2 algorithm which scatters the particles
locallyaroundthereferencepath(seealsoShestopaloffandNeal,2018;Malory,2021, forrelated
2Referred to as ‘random-walk CSMC’ therein.
4
ecnatsid
gnipmuj
derauqs
naeMapproaches). That is, conditional on the reference path x 1:T, the remaining particles x t−kt are
proposed from a joint distribution under which
xn ∼ N(x ,δ I),
t t t
for n ̸= k , where I is the (D ×D)-identity matrix. As noted in Tjelmeland (2004), sampling
t
from this joint proposal distribution can be achieved by first sampling an auxiliary variable
u ∼ N(x , δtI) and then xn ∼ N(u , δtI), for n ̸= k . Finke and Thiery (2023) also showed that
t t 2 t t 2 t
scaling the step size as δ ∈ O(D−1) (independently of T) guarantees stability in high dimen-
t
sions. This is again unsurprising because the Particle-RWM algorithm generalises the RWM
algorithm with Gaussian proposals (and proposal variance δ ) to T > 1 time steps and N > 1
1
proposals. Recently, Corenflos and Särkkä (2023) showed that the Particle-RWM algorithm can
be viewed as a Gibbs-sampling step for the auxiliary variables u followed by a CSMC update
t
which targets a modified Feynman–Kac model which depends on u , allowing for greater flex-
1:T
ibility in the choice proposals. Including related ‘pseudo observations’ u into CSMC updates
t
had previously been suggested by Murray et al. (2013); Fearnhead and Meligkotsidou (2016);
Karppinen and Vihola (2021) but primarily aimed at overcoming the problem that the CSMC
algorithm mixes poorly if the initial distribution M (x ) is diffuse (and potentially also for
1 1
improving mixing in the presence of ‘static’ model parameters).
1.3 Contributions
Recall that in the ‘classical’ MCMC setting, improved performance can often be achieved by
enhancing the proposal distribution using gradient or prior information. Thus, in this work,
we introduce a methodology which combines the strength of CSMC methods (i.e., exploita-
tion of the ‘decorrelation-over-time’ property of the target distribution) with the strengths of
sophisticated ‘classical’ MCMC approaches (i.e., gradient-enhanced local proposals).
Intheremainderofthissection, wedetailthecontributionsofthispaper(Table1summarises
our proposed methodology).
In Section 3, we introduce the following CSMC type methods which propose particles locally
around the reference path guided by gradient information:
• Particle-aMALA.InSection3.1, weextendtheParticle-RWMalgorithmtoincorporate
gradient information into the proposals. That is, conditional on the reference path x ,
1:T
the remaining particles x−kt are proposed from a joint distribution under which
t
x tn ∼ N(x
t
+ δ 2t∇ xtlogπ t(x 1:T),δ tI), (3)
for n ̸= k . Sampling from this joint proposal can be achieved by first sampling an
t
auxiliary variable u
t
∼ N(x
t
+κδ 2t∇ xtlogπ t(x 1:t), δ 2tI) and then x tn ∼ N(u t, δ 2tI), for n ̸=
k . We call this method Particle-aMALA because the auxiliary variables u are explicitly
t t
included in the space, i.e. they appear in the particle weights, and because the algorithm
generalises a version of auxiliary MALA (aMALA) from Titsias and Papaspiliopoulos
(2018) to T > 1 time steps and N > 1 proposals.
• Particle-MALA. In Section 3.2, we improve Particle-aMALA by marginalising out the
auxiliary variables u . We call the resulting method Particle-MALA because it generalises
t
MALA (Besag, 1994) to T > 1 time steps and N > 1 proposals.
• Particle-aMALA+. In Section 3.3, we improve Particle-aMALA differently by replac-
ingthe‘filter’gradient∇ logπ (x )in(3)withthe‘smoothing’gradient∇ logπ (x )
xt t 1:t xt T 1:T
5which is beneficial when future observations are informative about the current state. We
call the resulting method Particle-aMALA+.
In Section 4, we consider the special case that the Feynman–Kac model has conditionally Gaus-
sian mutation kernels: M (x |x ) = N(x ;m (x ),C (x )). In this setting, we introduce
t t t−1 t t t−1 t t−1
the following methods which propose particles locally around the reference path guided by both
gradient information and prior information:
• Particle-aGRAD. In Section 4.1, we propose an algorithm which, conditional on the
reference path x 1:T, proposes the remaining particles x t−kt from a joint distribution under
which
x tn ∼ N(cid:16) (I−A t(x ta −n t− 11))m t(x ta −n t− 11)+A t(x ta −n t− 11)[x
t
+ δ 2t∇ xtlogG t(x t−1:t)],B t(x ta −n t− 11)(cid:17) ,(4)
for n ̸= k , where A (x) := (C (x)+ δtI)−1C (x) and B (x) := δtA (x)2 +A (x). Sam-
t t t 2 t t 2 t t
pling from this joint proposal can be achieved by first sampling an auxiliary variable
u
t
∼ N(x
t
+ δ 2t∇ xtlogG t(x t−1:t), δ 2tI) and then x tn ∼ M t′(x t|x ta −n t− 11;u t), for n ̸= k t, where
M′(x |x ;u ) = p(x |x ,u ) is the fully-adapted auxiliary particle-filter proposal for
t t t−1 t t t−1 t
the state-space model with Gaussian transitions x |x ∼ M (x |x ) and pseudo ob-
t t−1 t t t−1
servations u |x ∼ N(u ;x ; δtI). We call this the Particle-aGRAD algorithm because the
t t t t 2
auxiliary variables u again appear in the particle weights, and because it generalises the
t
powerful aGRAD algorithm from Titsias and Papaspiliopoulos (2018) to T > 1 time steps
and N > 1 proposals.
• Particle-mGRAD. In Section 4.2, under the assumption that C (x ) = C and in
t t−1 t
analogy to Section 3.2, we improve Particle-aGRAD by marginalising out the auxiliary
variables u . We call the resulting method Particle-mGRAD because it generalises the
t
powerful mGRAD algorithm from Titsias and Papaspiliopoulos (2018) to T > 1 time
steps and N > 1 proposals.
• Particle-aGRAD+. In Section 4.3, in analogy to Section 3.3, we improve Particle-
aGRADbyreplacingthe‘filter-potential’gradients∇ logG (x )in(4)with‘smoothing-
xt t t−1:t
potential’ gradients ∇ logG (x ) which may be beneficial if G (x ) varies signifi-
xt 1:T 1:T t t−1:t
cantly in x . We call this method Particle-aGRAD+.
t−1
• Twisted Particle-aGRAD(+). In Section 4.4, under the assumption that m (x ) =
t t−1
F x + b and C (x ) = C , we improve Particle-aGRAD and Particle-aGRAD+
t t−1 t t t−1 t
by instead using all future auxiliary variables u to propose xn ∼ M′(x
|xan
t−1;u ),
t:T t t t t−1 t:T
for n ̸= k , where M′(x |x ;u ) = p(x |x ,u ) is the fully twisted particle filter
t t t t−1 t:T t t−1 t:T
proposal for the state-space model with Gaussian transitions and pseudo observations u
t
mentioned above. We call the resulting methods twisted Particle-aGRAD and twisted
Particle-aGRAD+.
In Section 4.6, we prove that Particle-aGRAD and Particle-mGRAD (and their smoothing-
gradient/twisted variants) solve the ‘tuning’ problem of having to choose between:
1. the CSMC algorithm (which proposes particles solely based on the prior dynamics);
2. theParticle-aMALA,Particle-MALAorParticle-aMALA+(whichproposeparticlessolely
locally around the reference path).
62.0
CSMC
Particle-aMALA
1.5
Particle-MALA
Particle-aMALA+
1.0
Particle-aGRAD
Particle-mGRAD
0.5
TwistedParticle-aGRAD
0.0
0.01 0.1 1 10
Prior variance, λ
Figure 2: Empirical illustration of the ‘interpolation’ from Propositions 8 and 9 in the toy
linear-Gaussian state-space model from Figure 1 (with D = T = 10).
This choice is not always clear: on the one hand, Choice 2 can exhibit superior performance in
high dimensions. On the other hand, if the prior dynamics are highly informative then Choice 1
can outperform Choice 2. Specifically, we prove that the following results hold in stationarity
and under the simplifying assumption that the model factorises over time, i.e., if G , m , C
t t t
(and hence A and B in (4)) do not depend on the state at time t−1:
t t
• Proposition 8. Particle-aGRAD and Particle-mGRAD reduce to the CSMC algorithm
as prior dynamics become more informative. Informally, we then have A ≈ 0 and
t
B ≈ C so that (4) reduces to (2).
t t
• Proposition 9. Particle-aGRAD and Particle-mGRAD reduce to Particle-aMALA and
Particle-MALA, respectively, as prior dynamics become less informative. Informally, we
then have A ≈ I and B ≈ δ I so that (4) reduces to (3).
t t t
Propositions 8 and 9 are illustrated in Figure 2 for a model in which the independence across
time-steps is not verified. As a by-product, these propositions show that the aGRAD/mGRAD
algorithms from Titsias and Papaspiliopoulos (2018) can be viewed as automatically interpo-
lating between the IMH algorithm and aMALA/MALA, depending on the ‘informativeness’
of the prior. To our knowledge, this has not been pointed out in the literature. As another
by-product, the methodology presented in this section also addresses the ‘tuning problem’ of
having to choose whether to sample the initial latent state x within the CSMC scheme (which
1
is preferable if the prior on the initial state is informative) or to treat it as a ‘static’ parameter
to be sampled separately (which is preferable if this prior is diffuse, see Murray et al., 2013;
Fearnhead and Meligkotsidou, 2016; Karppinen and Vihola, 2021).
In Section 5, we demonstrate the performance of our methodology on a high-dimensional
multivariate stochastic volatility model, often used as a benchmark in the particle filtering
literature. The different methods proposed in this article dramatically improve on existing
CSMC and related methods and also on ‘classical’ MCMC methods in terms of effective sample
size for different levels of prior informativeness.
All proofs (e.g., of the fact that the proposed methods leave π (x ) invariant) are deferred
T 1:T
to the appendix. Additionally, in Appendix A, we introduce Particle-PCNL methods which
generalise the preconditioned Crank–Nicolson–Langevin (PCNL) algorithm from Cotter et al.
(2013) to T > 1 time steps and N > 1 proposals. The methods proposed in this work and their
7
ecnatsid
gnipmuj
derauqs
naeM
)DARGm-elcitraP
ot
evitaler(Table 1: The methods mentioned in this work (new methods are in italic).
Special case
Method Section
if N = T = 1
CSMC† 2.1 IMH
Particle-RWM 2.2 RWM
Particle-aMALA 3.1 aMALA
Particle-MALA 3.2 MALA
Particle-aMALA+ 3.3 aMALA
Particle-aGRAD 4.1 aGRAD
Particle-mGRAD 4.2 mGRAD
Particle-aGRAD+ 4.3 aGRAD
Twisted Particle-aGRAD(+) 4.4 aGRAD
Particle-PCNL & more‡ Appendix A PCNL
† In our taxonomy, CSMC could be called ‘Particle-IMH’. However,
the latter already refers to an entirely different algorithm in Andrieu
et al. (2010).
‡ We again also describe auxiliary-variable, smoothing-gradient (‘+’)
and twisted versions.
special cases if N = T = 1 are summarised in Table 1. Note that for T = 1 but N > 1, our
work implies novel multi-proposal versions of ‘classical’ MCMC kernels like MALA, aMALA,
mGRAD, aGRAD and PCNL. These may be of independent interest because they can exploit
parallel computing architectures for inference in non-dynamic models.
Importantly, and in keeping with existing CSMC methodology, the computational cost of all
our proposed algorithms is linear in both T and N, in time and memory.
Finally, the Python code for reproducing our experiments is publicly available at https:
//github.com/AdrienCorenflos/particle_mala. It was written as a library and can be
extended to accommodate other models than the ones considered here.
2 Existing methodology
2.1 CSMC (particle extension of IMH)
2.1.1 Algorithm
Assume that we can generate independent and identically distributed (IID) samples from
the mutation kernels M (x |x ). A method for constructing a π -invariant MCMC kernel
t t t−1 T
P (x˜ |x ) is then given by the CSMC algorithm from Andrieu et al. (2010) which pro-
CSMC 1:T 1:T
poses N particles at each time step to build up an efficient proposal. Algorithm 1 summarises
the scheme, where ‘w.p.’ is short for ‘with probabilitity’. We also recursively define the nth
surviving particle lineage at time t as
x(n) := (x(an t−1) ,xn).
1:t 1:t−1 t
In particular, therefore, x(n) = (xan t−1,xn).
t−1:t t−1 t
8Algorithm 1 (CSMC). Given x ∈ XT:
1:T
1. for t = 1,...,T,
a) sample k
t
from a uniform distribution on [N]
0
and set x tkt := x t,
b) if t > 1, set ak t−t 1 := k t−1 and sample an t−1 = i w.p. W ti −1, for n ∈ [N] 0 \{k t},
c) sample xn ∼ M
(·|xan
t−1) for n ∈ [N] \{k },
t t t−1 0 t
d) for n ∈ [N] , set wn ∝ G (x(n) ).
0 t t t−1:t
e) for n ∈ [N] , set Wn := wn/PN wm;
0 t t m=0 t
Wi 1−WkT
2. sample i ∈ [N] \ {k } w.p. T ; set l := i w.p. 1∧ T ; otherwise, set
0 T 1−WkT T 1−Wi
T T
l := k ;
T T
WiQ (xi,xlt+1)
3. for t = T −1,...,1, sample l = i ∈ [N] w.p. t t+1 t t+1 ;
t 0 PN WnQ (xn,xlt+1)
n=0 t t+1 t t+1
4. return x˜
1:T
:= (x 1l1,...,x tlT).
Algorithm 1 includes two extensions to the original presentation of the CSMC algorithm in
Andrieu et al. (2010):
• Step 2 uses the so-called forced-move extension for CSMC algorithms which was proposed
in Chopin and Singh (2013) (see also Liu, 1996). The algorithm would still be valid if we
instead sampled l = i ∈ [N] with probability Wi.
T 0 T
• Step 3 is the backward-sampling extension from Whiteley (2010). The algorithm would
still be valid if we instead set l = alt+1 (but typically much less efficient, especially if T
t t
is large).
Importantly, sampling x˜ given x as described in Algorithm 1 induces a Markov kernel
1:T 1:T
P (x˜ |x ) which leaves π invariant. For sufficiently ergodic models, this MCMC kernel
CSMC 1:T 1:T T
can yield highly efficient updates of the sequence of latent states, even if the time horizon T is
large (Lee et al., 2020; Karjalainen et al., 2023).
2.1.2 Relationship with ‘classical’ MCMC algorithms
Interestingly, the CSMC algorithm generalises the classical IMH algorithm (Hastings, 1970) in
the sense that the former reduces to the latter if T = N = 1. This can be seen as follows,
where we suppress the ‘time’ subscript t = 1 everywhere to simplify the notation. Given that
the current state of the Markov chain is x = x0 (we can assume that k = 0 without loss of
generality), Step 1c of Algorithm 1 proposes x1 ∼ M. The remaining steps return x˜ := x1 as
the new state with acceptance probability 1∧α (x0,x1), where
IMH
1−W0 G(x1) π(x1)M(x0)
α (x0 ,x1) := = = .
IMH 1−W1 G(x0) π(x0)M(x1)
Otherwise, the old state x˜ := x0 = x is returned as the new state.
92.1.3 Breakdown in high dimensions
Unfortunately, as shown in Finke and Thiery (2023), Algorithm 1 suffers from a curse of di-
mension if D is large (unless the number of proposed particles, N, grows exponentially in D
but that is prohibitive). This is not surprising since the IMH algorithm is known to break down
in high dimensions (due to the difficulty of finding an efficient global proposal distribution M
in high dimensions).
2.2 Particle-RWM
2.2.1 Algorithm
To circumvent the curse of dimension, Finke and Thiery (2023) (see also Shestopaloff and
Neal, 2018; Malory, 2021, for related methods) developed the particle random-walk Metropolis
(Particle-RWM) algorithm which scatters the proposed particles locally around the reference
path using Gaussian perturbations as outlined in Algorithm 2.
Algorithm 2 (Particle-RWM). Implement Algorithm 1 but replace the particle proposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x t, δ 2tI), and x tn ∼ N(u t, δ 2tI), for n ∈ [N]
0
\{k t},
1d. for n ∈ [N] , set wn ∝ Q (x(n) ).
0 t t t−1:t
Notably, Step 1c marginally samples xn ∼ N(x ,δ I), for n ̸= k .
t t t t
2.2.2 Interpretation as a CSMC update on an extended space
Corenflos and Särkkä (2023) showed that Algorithm 2 can be derived by including the auxiliary
variables u into the space and thus considering the extended distribution
t
T
π T′ (x 1:T,u 1:T) := π T(x 1:T)YN(u t;x t, δ 2tI),
t=1
which admits π (x ) as a marginal and which can be targeted by alternating the following
T 1:T
two steps. Given x ∈ XT,
1:T
1. sample u ∼ N(x , δtI), for t = 1,...,T;
t t 2
2. run the CSMC algorithm (Algorithm 1) but with M (x |x ), G (x ), and Q (x )
t t t−1 t t−1:t t t−1:t
replaced by M t′(x t|x t−1;u t) := N(x t;u t, δ 2tI), G′ t(x t−1:t) := Q t(x t−1:t) and Q′ t(x t−1:t;u t) :=
M′(x |x ;u )G′(x ).
t t t−1 t t t−1:t
In particular, this shows that sampling x˜ given x via Algorithm 2 induces a Markov kernel
1:T 1:T
P (x˜ |x ) which leaves π invariant.
Particle-RWM 1:T 1:T T
2.2.3 Relationship with ‘classical’ MCMC algorithms
TheParticle-RWMalgorithmgeneralisestheclassical(Gaussian)RWMalgorithmofMetropolis
et al. (1953) in the sense that the former reduces to the latter if T = N = 1. This can be
seen as follows, where we again suppress the ‘time’ subscript t = 1 everywhere to simplify the
notation. Given that the current state of the Markov chain is x = x0 (we can again assume
10that k = 0 without loss of generality), Step 1c of Algorithm 2 proposes x1 ∼ N(x0,δI). The
remaining steps return x˜ := x1 as the new state with acceptance probability 1∧α (x0,x1),
RWM
where
1−W0 π(x1)
α (x0 ,x1) := = .
RWM 1−W1 π(x0)
Otherwise, the old state x˜ := x0 = x is returned as the new state.
2.2.4 Stability in high dimensions
Finke and Thiery (2023) proved that the Particle-RWM algorithm circumvents the curse of
dimensionality if the proposal variance is scaled as δ ∈ O(D−1) (see also Malory, 2021, for a
t
proof for non-Gaussian exchangeable proposals but in the case where the model factorises over
time). However, from the literature on classical MCMC algorithms, it is well known that faster
convergence rates can be achieved by incorporating gradient information into the proposal
(Roberts and Rosenthal, 1998). Thus, in the next section, we extend the Particle-RWM to
allow for gradient-informed proposals.
3 Particle extensions of MALA and aMALA
3.1 Particle-aMALA
We now propose Particle-aMALA, a method which extends the Particle-RWM algorithm from
Finke and Thiery (2023) by allowing for the use of gradient information in the proposal. For the
moment, gradients are taken w.r.t. the filtering densities and we employ an indicator κ ∈ {0,1}
to permit switching off the use of gradient information.
We now write
M t′(x t|x t−1;u t) := N(x t;u t, δ 2tI), (5)
G′(x ;u ) := Q (x
)N(u t;x
t
+κδ 2t∇ xtlogπ t(x 1:t), δ 2tI)
, (6)
t t−1:t t t t−1:t N(u ;x , δtI)
t t 2
as well as Q′(x ;u ) := M′(x |x ;u )G′(x ;u ), where we note that
t t−1:t t t t t−1 t t t−1:t t
∇ logπ (x ) = ∇ logQ (x ).
xt t 1:t xt t t−1:t
A single iteration of the Particle-aMALA is then as follows.
Algorithm 3 (Particle-aMALA). Implement Algorithm 1 but replace the particle proposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x
t
+κδ 2t∇ xtlogπ t(x 1:t), δ 2tI), and x tn ∼ N(u t, δ 2tI), for n ∈ [N]
0
\{k t},
1d. for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−1:t t
and also replace Q (·) in the backward kernel in Step 3 by Q′ (·;u ).
t+1 t+1 t+1
Step 1c marginally samples x tn ∼ N(x
t
+κδ 2t∇ xtlogπ t(x 1:t),δ tI), for n ̸= k t. This follows
from Lemma 3 in Appendix C.
Proposition 1 (validity of Particle-aMALA). Sampling x˜ given x via Algorithm 3
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-aMALA 1:T 1:T T
113.2 Particle-MALA
In this section, we analytically integrate out the auxiliary variables u appearing in the weights
t
of the Particle-aMALA. A single iteration of the resulting methodology – which we term the
Particle-MALA – is as follows, where we write
1
logH (x,x¯) := h 2ϕT(x¯ −x)− N ϕT ϕi . (7)
t,ϕ δ N+1
t
Algorithm 4 (Particle-MALA). Implement Algorithm 1 but replace the particle proposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x
t
+κδ 2t∇ xtlogπ t(x 1:t), δ 2tI), and x tn ∼ N(u t, δ 2tI), for n ∈ [N]
0
\{k t},
1d. set x¯ := 1 PN xn and, for n ∈ [N] ,
t N+1 n=0 t 0
wn ∝ Q (x(n) )H (xn,x¯ ).
t t t−1:t t,κδ 2t∇ xn
t
logQt(x t( −n) 1:t) t t
Step 1d pre-computes x¯ to ensure that the algorithm can still be implemented in O(N)
t
operations even though the weight of the nth particle now depends on the values of all N +1
particles. However, note that the auxiliary variables u no longer appear in the weights.
t
Remark 1 (Particle-aMALA ‘exactly approximates’ Particle-MALA). Note that the
Particle-aMALA differs from the Particle-MALA only in the definition of the weights (and the
backward-sampling weights). This allows us to interpret the former as a ‘noisy’ version of the
latter. Indeed, write the unnormalised weight of the nth particle at time-t in the Particle-
aMALA as wn(u ), whilst wn denotes the corresponding weight under the Particle-MALA
t t t
(which does not depend on the auxiliary variable u ). Then we have
t
wn(u ) wn q−n(u |x−n,xn;H )
t t = t × t t t t t−1 ,
w tkt(u t) w tkt q t−kt(u t|x t−kt,x tkt;H t−1)
where q t−n(u t|x t−n,x tn;H t−1) = N(u t;x¯
t
+κ 2(Nδt +1)∇
x
tnlogQ t(x t( −n) 1:t), 2(Nδt +1)I) is the conditional
distribution of u under the joint distribution of all random variables generated by Algorithm 3
t
up to (and including) time t assuming the reference particle at time t is placed in position n
(and H denotes the history of the particle system, i.e. all particles and ancestor indices up to
t−1
time t−1). This conditional distribution follows from Lemma 3 in Appendix C. In particular,
we therefore have
" wn(u )# wn
E t t = t ,
wkt(u ) wkt
t t t
where the expectation is taken w.r.t. q t−kt(u t|x t−kt,x tkt;H t−1). Interestingly, for the Particle-
RWM algorithm (recovered by setting κ = 0), the ‘auxiliary’ and ‘marginal’ variants are sta-
tistically equivalent.
Proposition 2 (validity of Particle-MALA). Sampling x˜ given x via Algorithm 4
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-MALA 1:T 1:T T
123.3 Particle-aMALA+
In this section, we extend the Particle-aMALA in a different manner: we now modify the
algorithm so that the proposal distributions incorporate gradients w.r.t. the joint smoothing
distribution π rather than w.r.t. the filters, π . This can be beneficial if there is a significant
T t
discrepancy between the marginal distribution of x under the former and the latter as is
t
typically the case if D is large. Indeed, this discrepancy is likely the reason for the decay in
performance of Particle-aMALA and Particle-MALA for very large D visible in Figure 1a.
For M′(x |x ;u ) and G′(x ;u ) still defined as in the Particle-aMALA algorithm (i.e.,
t t t−1 t t t−1:t t
as in (5) and (6)), we now write
N(u ;x +κδt−1∇ logπ (x ), δt−1I)
G′(x ;u ) := G′(x ;u ) t−1 t−1 2 xt−1 T 1:T 2 ,
t t−2:t t−1:t t t−1:t t N(u ;x +κδt−1∇ logπ (x ), δt−1I)
t−1 t−1 2 xt−1 t−1 1:t−1 2
as well as Q′(x ;u ) := M′(x |x ;u )G′(x ;u ), where we note that
t t−2:t t−1:t t t t−1 t t t−2:t t−1:t
∇ logπ (x ) = ∇ [logQ (x )+logQ (x )].
xt T 1:T xt t t−1:t t+1 t:t+1
A single iteration of the resulting ‘smoothing-gradient’ methodology – which we term the
Particle-aMALA+ – is then as follows.
Algorithm 5 (Particle-aMALA+). Implement Algorithm 1 but replace the particle pro-
posal (Step 1c), the weight calculation (Step 1d), and backward sampling (Step 3) by
1c. sample u
t
∼ N(x
t
+κδ 2t∇ xtlogπ T(x 1:T), δ 2tI), and x tn ∼ N(u t, δ 2tI), for n ∈ [N]
0
\{k t},
1d. for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−2:t t−1:t
3. for t = T −1,...,1, sample l = i ∈ [N] w.p.
t 0
WiQ′ ((x(i) ,xlt+1);u )Q′ ((xi,xlt+1,xlt+2);u )
t t+1 t−1:t t+1 t:t+1 t+2 t t+1 t+2 t+1:t+2 .
PN WnQ′ ((x(n) ,xlt+1);u )Q′ ((xn,xlt+1,xlt+2);u )
n=0 t t+1 t−1:t t+1 t:t+1 t+2 t t+1 t+2 t+1:t+2
In Step 3, we recall the convention that any quantity with ‘time’ index t > T should be
ignored, so that Q′ ≡ 1. Some comments about Algorithm 5 are in order.
T+1
• Step 1c marginally samples x tn ∼ N(x
t
+κδ 2t∇ xtlogπ T(x 1:T),δ tI), for n ̸= k t. This is in
contrast to the Particle-aMALA and Particle-MALA, whose (marginal) proposal distri-
bution is centred around x
t
+κδ 2t∇ xtlogπ t(x 1:t).
• Steps 1d and 3 are similar to the weight-calculation and backward-sampling steps in the
previous algorithms. The only difference here is that the model is now no longer (first-
order) Markov in the sense that the (incremental) weights at time t now also depend on
the state at time t−2.
Proposition 3 (validity of Particle-aMALA+). Sampling x˜ given x via Algorithm 5
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-MALA 1:T 1:T T
3.4 Relationship with other methods
We end this section by relating the proposed algorithms to existing methodologies.
131. Generalisation of Particle-RWM and RWM. If κ = 0, then the algorithms intro-
duced in this section (Particle-aMALA, Particle-MALA and Particle-aMALA+) do not
make use of any gradient information and reduce to the Particle-RWM algorithm. In
particular, if T = N = 1, they thus reduce to the RWM algorithm.
2. Generalisation of aMALA. For κ = 1, the Particle-aMALA (and similarly the
Particle-aMALA+) algorithm generalise the auxiliary MALA (aMALA) from Titsias and
Papaspiliopoulos (2018) in the sense that the former reduces to the latter if T = N = 1.
Thiscanbeseenasfollows,whereweagainsuppressthe‘time’subscriptt = 1everywhere.
Given that the current state of the Markov chain is x = x0 (we can assume that k = 0
without loss of generality), Step 1c of Algorithm 3 first refreshes the auxiliary variable by
sampling u ∼ N(x0 + δ∇logπ(x0), δI) and then proposes x1 ∼ N(u, δI). The remaining
2 2 2
steps return x˜ := x1 as the new state with acceptance probability 1∧α (x0,x1;u),
aMALA
where
1−W0 π(x1)N(u;x1 + δ∇logπ(x1), δI)N(x0;u, δI)
α (x0 ,x1;u) := = 2 2 2 .
aMALA 1−W1 π(x0)N(u;x0 + δ∇logπ(x0), δI)N(x1;u, δI)
2 2 2
Otherwise, the old state x˜ := x0 = x is returned as the new state. This induces the
same Markov chain on X as the aMALA from Titsias and Papaspiliopoulos (2018) (the
only difference relates to a re-centring of the auxiliary variables u previously discussed
in Corenflos and Särkkä (2023) but this does not change the law of the Markov chain on
the marginal space which does not include the auxiliary variable).
3. Generalisation of MALA. Still taking κ = 1, the Particle-MALA generalises the
Metropolis-adjusted Langevin algorithm (MALA) (Besag, 1994) in the sense that the for-
mer reduces to the latter if T = N = 1. This can be seen as follows, where use the same
notational conventions as in the case of aMALA above. Step 1c of Algorithm 4 then
marginally proposes x1 ∼ N(x0 + δ∇logπ(x0),δI). The remaining steps return x˜ := x1
2
as the new state with acceptance probability 1∧α (x0,x1), where
MALA
1−W0 π(x1)N(x0;x1 + δ∇logπ(x1),δI)
α (x0 ,x1) := = 2 .
MALA 1−W1 π(x0)N(x1;x0 + δ∇logπ(x0),δI)
2
Otherwise, the old state x˜ := x0 = x is returned as the new state.
In particular, Remark 1 shows that we can view the aMALA as a ‘noisy’ version of MALA
(as already mentioned in Titsias and Papaspiliopoulos, 2018) because, dropping the time
subscript again, by Lemma 3:
N(u;x¯ + δ∇logπ(x1), δI)
α (x0 ,x1;u) = α (x0 ,x1) 4 4 ,
aMALA MALA N(u;x¯ + δ∇logπ(x0), δI)
4 4
where x¯ = (x0 +x1)/2, and hence
E[α (x0 ,x1;u)] = α (x0 ,x1),
aMALA MALA
where the expectation is w.r.t. the conditional distribution of u under the joint distri-
bution of the random variables sampled in Step 1c of the Particle-aMALA, i.e. w.r.t.
N(x¯+δ∇logπ(x0), δI). In other words, this algorithm is the same as MALA except that
4 4
the acceptance ratio is ‘randomised’ in the sense that it is multiplied by a non-negative
random variable whose expectation is 1. Other examples of such algorithms can be found
in Ceperley and Dewing (1999); Nicholls et al. (2012); see also Finke (2015, Section 3.3.3)
for a discussion as well as Andrieu and Vihola (2016, page 2669) for a simple argument
showing that the asymptotic variance of aMALA cannot be smaller than that of MALA.
144 Particle extensions of mGRAD and aGRAD
4.1 Particle-aGRAD
Thegradient-informedalgorithms(Particle-MALA,etc)developedinSection3canbeexpected
to improve upon the Particle-RWM algorithm in the same way that aMALA/MALA improve
upontheRWMalgorithm. However, theymayunderperformcomparedtotheCSMCalgorithm
when the prior dynamics of the latent states are highly informative in the same way that MALA
can underperform relative to the IMH algorithm (with prior as proposal) if the prior is highly
informative. Additionally, note that the algorithms from Section 3 employ proposals that
are separable in the sense that, given the reference path, the marginal proposal distribution
of xn does not depend on the ancestor particle
xan
t−1 (that is, separability implies that the
t t−1
weight-calculation and resampling steps could be postponed until after all particles have been
proposed); such separable proposals can be expected to perform poorly if the latent states are
highly correlated across time.
In this section, we further incorporate (conditionally) Gaussian prior dynamics into the par-
ticle proposals and thus interpolate between the CSMC algorithm and the gradient-informed
algorithms of Section 3. Our construction generalises the aGRAD and mGRAD algorithms of
Titsias and Papaspiliopoulos (2018). In particular, the algorithms introduced in this section
do not imply separable proposals, i.e., the proposal kernel for particle xn will generally depend
on its ancestor particle
xan
t−1.
t
t−1
Specifically, in this section, we consider the special case of the generic Feynman–Kac model
from (1) in which we can find a decomposition Q (x ) = M (x |x )G (x ), such that
t t−1:t t t t−1 t t−1:t
M (x |x ) = N(x ;m (x ),C (x )), (8)
t t t−1 t t t−1 t t−1
is a Gaussian transition density whose mean m (x ) and non-singular covariance matrix
t t−1
C (x ) may depend on the previous state x , for t > 1; and that M (x ) = N(x ;m ,C ).
t t−1 t−1 1 1 1 1 1
Example 2 (state-space model, continued). The methods proposed in this section imme-
diately apply with M (x |x ) := f (x |x ) if the state-space model has conditionally Gaus-
t t t−1 t t t−1
sian dynamics, i.e. if f (x |x ) = N(x ;m (x ),C (x )), by taking G (x ) = g (y |x ).
t t t−1 t t t−1 t t−1 t t−1:t t t t
However, they may often still apply to state-space models with non-Gaussian dynamics via a
change of measure, i.e., by taking M (x |x ) := N(x ;m (x ),C (x )) and G (x ) =
t t t−1 t t t−1 t t−1 t t−1:t
f (x |x )g (y |x )/N(x ;m (x ),C (x )), or through a suitable transformation.
t t t−1 t t t t t t−1 t t−1
The first method proposed in this section is termed Particle-aGRAD. Conditional on the
auxiliary variables u , it can be viewed as a CSMC algorithm whose proposal kernels are
1:T
those of the fully-adapted auxiliary particle filter for the state-space model defined by the
Gaussian transitions p(x |x ) = N(x ;m (x ),C (x )) from (8) and ‘pseudo observations’
t t−1 t t t−1 t t−1
u with p(u |x ) = N(u ;x , δtI). We now write
t t t t t 2
M′(x |x ;u ) := p(x |x ,u )
t t t−1 t t t−1 t
∝ N(x t;m t(x t−1),C t(x t−1))N(u t;x t, δ 2tI)
∝ N(x ;m′(x ,u ),C′(x )), (9)
t t t−1 t t t−1
with
m′(x,u) := m (x)+A (x)[u−m (x)], (10)
t t t t
C′(x) := (I−A (x))C (x) = δtA (x), (11)
t t t 2 t
A (x) := (C (x)+ δtI)−1 C (x),
t t 2 t
15as well as
G′(x ;u ) := Q (x
)N(u t;x
t
+κδ 2t∇ xtlogG t(x t−1:t), δ 2tI)
, (12)
t t−1:t t t t−1:t M′(x |x ;u )
t t t−1 t
and Q′(x ;u ) := M′(x |x ;u )G′(x ;u ). A single iteration of the Particle-aGRAD
t t−1:t t t t t−1 t t t−1:t t
algorithm is as follows.
Algorithm 6 (Particle-aGRAD). Implement Algorithm 1 but replace the particle proposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x
t
+κδ 2t∇ xtlogG t(x t−1:t), δ 2tI), and x tn ∼ M t′(·|x ta −n t− 11;u t), for n ∈ [N]
0
\
{k },
t
1d. for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−1:t t
and also replace Q (·) in the backward kernel in Step 3 by Q′ (·;u ).
t+1 t+1 t
Proposition 4 (validity of Particle-aGRAD). Sampling x˜ given x via Algorithm 6
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-aGRAD 1:T 1:T T
4.2 Particle-mGRAD
In this section, we analytically integrate out the auxiliary variables u which appeared in the
t
weights of the Particle-aGRAD algorithm. Here we consider the case when the covariance
matrices appearing in the conditionally Gaussian mutation kernel (8) do not depend on the
previous state, i.e.,
C (x ) = C , (13)
t t−1 t
which then also implies that A (x ) = A . A single iteration of the resulting methodology –
t t−1 t
which we term the Particle-mGRAD algorithm – is as follows, where we write
logH (x,v,x¯,v¯) = 1(x−v)T((δtA )−1 +G )(x−v)
t,ϕ 2 2 t t
−[1 N(x+ϕ)T A +(x−v)T]G (x+ϕ)
2 t t
+(N +1)(x¯ −v¯)T G (v+ϕ),
t
for G := 2(I+NA )−1.
t δt t
Algorithm 7 (Particle-mGRAD). ImplementAlgorithm1butreplacetheparticleproposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x
t
+κδ 2t∇ xtlogG t(x t−1:t), δ 2tI) and x tn ∼ M t′(·|x ta −n t− 11;u t), for n ∈ [N]
0
\
{k },
t
1d. set x¯ := 1 PN xn, vn := (I−A )m (xan t−1), v¯ := 1 PN vn, and, for n ∈ [N] ,
t N+1 n=0 t t t t t−1 t N+1 n=0 t 0
wn ∝ Q (x(n) )H (xn,vn,x¯ ,v¯ ). (14)
t t t−1:t t,κδ 2t∇ xn
t
logGt(x t( −n) 1:t) t t t t
16Remark 2 (Particle-aGRAD ‘exactly approximates’ Particle-mGRAD). Inanalogue
totherelationshipbetweenParticle-aMALAandParticle-MALAdiscussedinRemark1,Particle-
aGRAD is a noisy version of Particle-mGRAD. That is, letting wn(u ) and wn be the unnor-
t t t
malised weights under Particle-aGRAD and Particle-mGRAD, respectively, we have
" wn(u )# wn
E t t = t ,
wkt(u ) wkt
t t t
where the expectation is taken with respect to the conditional distribution of u under the joint
t
distribution of all random variables generated by Algorithm 6 up to (and including) time t.
Proposition 5 (validity of Particle-mGRAD). Sampling x˜ given x via Algorithm 7
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-aGRAD 1:T 1:T T
4.3 Particle-aGRAD+
While the algorithm of Section 6 incorporates information from the smoothing distribution by
meritofnotmodifyingthelatentdynamics, itmayhappenthatthepotentialG (x )strongly
t t−1:t
depends on x . In this case, considering the ‘myopic’ gradient information ∇ logG (x )
t−1 xt t t−1:t
may not suffice to improve the mixing of the algorithm and information from x may then be
t−1
beneficial. Similarly to Section 3.3, in this section, we extend the Particle-aGRAD algorithm
to incorporate gradients w.r.t. the ‘smoothing potential’ G (x ) = QT G (x ) rather
1:T 1:T t=1 t t−1:t
than w.r.t. the ‘filtering potential’ Qt G (x ).
s=1 s s−1:s
For M′(x |x ;u ) and G′(x ;u ) still defined as in the Particle-aGRAD algorithm (i.e.,
t t t−1 t t t−1:t t
as in (9) and (12)), we now write
N(u ;x +κδt−1∇ logG (x ), δt−1I)
G′(x ;u ) := G′(x ;u ) t−1 t−1 2 xt−1 1:T 1:T 2 ,
t t−2:t t−1:t t t−1:t t N(u ;x +κδt−1∇ logG (x ), δt−1I)
t−1 t−1 2 xt−1 t−1 t−2:t−1 2
as well as Q′(x ;u ) := M′(x |x ;u )G′(x ;u ), where we note that
t t−2:t t−1:t t t t−1 t t t−2:t t−1:t
∇ logG (x ) = ∇ log[G (x )+logG (x )].
xt 1:T 1:T xt t t−1:t t+1 t:t+1
A single iteration of the resulting ‘smoothing-gradient’ methodology – which we term the
Particle-aGRAD+ algorithm – is as follows.
Algorithm 8 (Particle-aGRAD+). Implement Algorithm 1 but replace the particle pro-
posal (Step 1c), the weight calculation (Step 1d), and backward sampling (Step 3) by
1c. sample u
t
∼ N(x
t
+κδ 2t∇ xtlogG 1:T(x 1:T), δ 2tI), and x tn ∼ M t′(x t|x t−1;u t), for n ∈ [N]
0
\
{k },
t
1d. for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−2:t t−1:t
3. for t = T −1,...,1, sample l = i ∈ [N] w.p.
t 0
WiQ′ ((x(i) ,xlt+1);u )Q′ ((xi,xlt+1,xlt+2);u )
t t+1 t−1:t t+1 t:t+1 t+2 t t+1 t+2 t+1:t+2 .
PN WnQ′ ((x(n) ,xlt+1);u )Q′ ((xn,xlt+1,xlt+2);u )
n=0 t t+1 t−1:t t+1 t:t+1 t+2 t t+1 t+2 t+1:t+2
Note that if G (x ) = G (x ) does not depend on x , then the Particle-aGRAD+ algo-
t t−1:t t t t−1
rithm coincides with the Particle-aGRAD algorithm. However, when G (x ) varies highly
t t−1:t
in x , their behaviours may differ substantially.
t−1
Proposition 6 (validity of Particle-aGRAD+). Sampling x˜ given x via Algorithm 8
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-aGRAD+ 1:T 1:T T
174.4 Twisted Particle-aGRAD(+)
Recall that, conditionally on the auxiliary variables u , the Particle-aGRAD algorithm could
1:T
be viewed as a CSMC algorithm whose proposal kernels M′(x |x ;u ) = p(x |x ,u ) are
t t t−1 t t t−1 t
those of the fully-adapted auxiliary particle filter for the state-space model which is defined
by the Gaussian transitions p(x |x ) = N(x ;m (x ),C (x )) from (8) and observation
t t−1 t t t−1 t t−1
densities p(u |x ) = N(u ;x , δtI).
t t t t 2
In this section (and in this section only), we make the more restrictive assumption that the
transition kernel from (8) is not only Gaussian but also affine, i.e.,
m (x ) = F x +b , and C (x ) = C , (15)
t t−1 t t−1 t t t−1 t
for some F ∈ RD×D, b ∈ RD, and some covariance matrix C ∈ RD×D. Under (15), we
t t t
can then go one step further and implement the fully twisted particle filter (Whiteley and Lee,
2014; Guarniero et al., 2017; Heng et al., 2020) proposal which conditions on all future pseudo
observations u . That is, we now write
t:T
M′(x |x ;u ) := p(x |x ,u )
t t t−1 t:T t t−1 t:T
Z " T #
∝ YN(x s;F sx
s−1
+b s,C s)N(u s;x s, δ 2sI) dx
t+1:T
XT−t s=t
∝ N(x ;F′x +b′,C′), (16)
t t t−1 t t
G′(x ;u ) := Q (x
)N(u t;x
t
+κδ 2t∇ xtlogG t(x t−1:t), δ 2tI)
,
t t−1:t t:T t t−1:t M′(x |x ;u )
t t t−1 t:T
as well as Q′(x ;u ) := M′(x |x ;u )G′(x ;u ). Here, b′ ∈ RD and F′,C′ ∈ RD×D
t t−1:t t:T t t t−1 t:T t t−1:t t:T t t t
can be obtained via Kalman-filtering recursions as explained in Appendix B.
A single iteration of the resulting methodology – which we term the twisted Particle-aGRAD
algorithm – is then exactly as the Particle-aGRAD (Algorithm 6), except that M′(·|·;u ),
t t
G′(·;u )andQ′(·;u )fromSection4.1arereplacedbyM′(·|·;u ),G′(·;u )andQ′(·;u )
t t t t t t:T t t:T t t:T
from this section. When the potential functions G (x ) vary in x , then we can further
t t−1:t t−1
construct a twisted Particle-aGRAD+ algorithm by replacing M′(x |x ,u ) in Algorithm 8
t t t−1 t
and in the denominator of G′(x ;u ) by M′(x |x ,u ).
t t−2:t t−1:t t t t−1 t:T
Proposition 7 (validity of the twisted Particle-aGRAD/Particle-aGRAD+). Sampling
x˜ given x via the twisted Particle-aGRAD or twisted Particle-aGRAD+ algorithm induces
1:T 1:T
a Markov kernel which leaves π invariant.
T
4.5 Relationship with other methods
The algorithms proposed above relate to existing methods as follows.
1. Generalisation of aGRAD. For κ = 1, the Particle-aGRAD algorithm (and similarly
the Particle-aGRAD+ algorithm as well as the twisted versions of either) generalises the
auxiliary gradient (aGRAD) algorithm from Titsias and Papaspiliopoulos (2018, called
‘aGrad-z’ therein) in the sense that the former reduces to the latter if T = N = 1. This
can be seen as follows, where we again suppress the ‘time’ subscript t = 1 everywhere so
that π(x) ∝ M(x)G(x), where M(x) = N(x;m,C). Given that the current state of the
Markov chain is x = x0 (we can assume that k = 0 without loss of generality), Step 1c of
Algorithm6firstrefreshestheauxiliaryvariablebysamplingu ∼ N(x0+δ∇logG(x0), δI)
2 2
18and then proposes x1 ∼ N((I−A)m+Au, δA), for A = (C+ δI)−1C. The remaining
2 2
steps return x˜ := x1 as the new state with acceptance probability 1∧α (x0,x1;u),
aGRAD
where
1−W0
α (x0 ,x1;u) :=
aGRAD 1−W1
π(x1)N(u;x1 + δ∇logG(x1), δI)N(x0;(I−A)m+Au, δA)
= 2 2 2 .
π(x0)N(u;x0 + δ∇logG(x0), δI)N(x1;(I−A)m+Au, δA)
2 2 2
Otherwise, the old state x˜ := x0 = x is returned as the new state.
2. Generalisation of mGRAD. Still taking κ = 1, the Particle-mGRAD algorithm gen-
eralises the marginal gradient (mGRAD) algorithm from Titsias and Papaspiliopoulos
(2018) in the sense that the former reduces to the latter if T = N = 1. This can be
seen as follows, where we use the same notational conventions as in the case of aGRAD
above. Step 1c of Algorithm 7 then marginally proposes x1 ∼ N((I − A)m + A[x0 +
δ∇logG(x0)],B), where B := δA2 +A. The remaining steps return x˜ := x1 as the new
2 2
state with acceptance probability 1∧α (x0,x1), where
mGRAD
1−W0 π(x1)N((I−A)m+A[x1 + δ∇logG(x1)],B)
α (x0 ,x1) := = 2 .
mGRAD 1−W1 π(x0)N((I−A)m+A[x0 + δ∇logG(x0)],B)
2
Otherwise, the old state x˜ := x0 = x is returned as the new state. In particular, by
Remark 2, in analogue to Section 3.4, we can again interpret aGRAD as a version of
mGRAD with ‘randomised’ acceptance ratio.
3. Generalisation of a ‘preconditioned’ Particle-RWM algorithm. If κ = 0, then the
Particle-aGRADandParticle-aGRAD+algorithmsreducetoamethodrecentlyproposed
in Corenflos and Särkkä (2023, Section 4.3), which can be seen as a ‘preconditioned’
version of the Particle-RWM algorithm.
4.6 Interpolation between CSMC and
Particle-MALA/Particle-aMALA
The Particle-MALA (and related methods) proposed in Section 3 may be outperformed by the
CSMC algorithm in the case when the prior dynamics are highly informative – in the same way
that MALA may be outperformed by the IMH algorithm (with prior as proposal) if the prior
dominates the posterior. For instance, in the extreme case that all the potential functions are
constant, the CSMC algorithm proposes N trajectories (in addition to the reference path) that
are IID samples from π (assuming an adaptive or low-variance conditional resampling scheme
T
is used) while the N trajectories proposed by Particle-MALA are still highly correlated with
the reference path.
Put differently, the user is faced with the ‘tuning problem’ of having to decide between
the CSMC algorithm on the one hand and the Particle-MALA (and related methods) on the
other hand. In this section, we show that the Particle-mGRAD algorithm resolves this tuning
problem in the sense that it can be viewed as interpolating between CSMC and Particle-MALA.
Specifically, Proposition 8 shows that Particle-mGRAD reduces to the CSMC algorithm if the
prior dynamics are highly informative. Conversely, Proposition 9 shows that Particle-mGRAD
reduces to the Particle-MALA if the prior dynamics are uninformative. The same results hold
for the auxiliary-variable versions: Particle-aMALA and Particle-aGRAD.
We make the following assumptions (assumed to hold for all t ∈ [T]):
19A1 For any x ∈ X, m (x ) = m , C (x ) = C and G (x ) = G (x ) are constant in
t t t−1 t t t−1 t t t−1:t t t
x , with G uniformly bounded on X and C invertible.
t−1 t t
A2 There exist C ,C ≥ 0 such that κ∥∇logG (x )∥ ≤ C +C ∥x ∥ .
0 1 t t 2 0 1 t 2
A3 max R x2 G (x )dx < ∞, where x is the dth component of x .
d∈[D] X t,d t t t t,d t
Whenever T > 1, Assumption A1 is strong because it requires the Feynman–Kac model to
factorise over time. However, we expect that it could be relaxed at the cost of greatly com-
plicating the arguments. Indeed, note that the model used in Figure 2 does not satisfy this
assumption. Assumption A2 is rather mild, e.g. it holds in a state-space model with Gaussian
measurement errors.
In the following, for each t ∈ [T], we will consider a sequence of prior covariance matrices
(C ) . We will therefore add the subscript k to any quantity which depends on C . We
t,k k≥1 t,k
also let λ(A) denote the set of eigenvalues of some matrix A. The following propositions are
proved in Appendix E.
Proposition 8. For some D,T,N ≥ 1, assume A1–A2, and assume that there exists a se-
quence (λ ) in (0,∞) with max{λ(C ),...,λ(C )} ≤ λ → 0 as k → ∞. Then for any
k k≥1 1,k T,k k
ε > 0, there exists a sequence (F ) of subsets of XT with lim π (F ) = 1 such that
T,k k≥1 k→∞ T,k T,k
1. sup ∥P (·|x )−P (·|x )∥ ∈ O(λ(1−ε)/4);
x1:T∈F T,k Particle-mGRAD,k 1:T CSMC,k 1:T tv k
2. sup ∥P (·|x )−P (·|x )∥ ∈ O(λ(1−ε)/4).
x1:T∈F T,k Particle-aGRAD,k 1:T CSMC,k 1:T tv k
Proposition 9. For some D,T,N ≥ 1, assume A1–A3, and assume that there exists a se-
quence (λ ) in (0,∞) with min{λ(C ),...,λ(C )} ≥ λ → ∞ as k → ∞. Then for any
k k≥1 1,k T,k k
ε > 0, there exists a sequence (F ) of subsets of XT with lim π (F ) = 1 such that
T,k k≥1 k→∞ T,k T,k
1. sup ∥P (·|x )−P (·|x)∥ ∈ O(λ−(1−ε)/4);
x1:T∈F T,k Particle-mGRAD,k 1:T Particle-MALA,k tv k
2. sup ∥P (·|x )−P (·|x)∥ ∈ O(λ−(1−ε)/4).
x1:T∈F T,k Particle-aGRAD,k 1:T Particle-aMALA,k tv k
As per Sections 2.1.2, 3.4 and 4.5, taking T = N = 1 in Propositions 8 and 9 immediately imply
that the aGRAD/mGRAD algorithm can be viewed as automatically interpolating between the
IMH algorithm with prior as proposal (if the prior is highly informative) and aMALA/MALA
(if the prior is highly diffuse). To our knowledge, this interpretation has not been pointed out in
the literature. It provides new intuition for the noteworthy performance of aGRAD/mGRAD
in Titsias and Papaspiliopoulos (2018).
4.7 Complexity
An iteration of Particle-aGRAD or Particle-aGRAD+ requires computing T(N +1) gain ma-
trices A
(xan
t−1) ∈ RD×D; and all of these, in general, have a cubic cost in the latent-state
t t−1
dimension D. While this may be reasonable for small enough systems and will be helpful
for informative likelihoods, the computational quickly outweighs the statistical benefits of the
method. However, when the dynamics have additive noise (13), A does not depend on x .
t t−1
In this case, only T gain matrices are needed and these can be pre-computed, only paying the
cubic cost in the dimension upfront rather than at each iteration.
The same applies for the Particle-mGRAD algorithm for which we always require (13) to
hold (the auxiliary variables could still be integrated out if (13) is relaxed, but only at the cost
of a cubic computational complexity in the number of particles).
20However, as for the Particle-RWM algorithm and Particle-MALA-type methods, we need to
calibrate the step-size parameters δ which changes the gain matrices (so that pre-computation
t
is not possible during the calibration stage). Thankfully, because A and C have the same
t t
eigenvectors no matter what δ is, it is possible to use similar spectral methods as in Titsias
t
and Papaspiliopoulos (2018) to reduce the complexity of changing δ to quadratic.
t
At first sight, the complexity of the twisted Particle-aGRAD seems quadratic in T as the
proposal kernel M′(x |x ,u ) = N(x ;F′x + b′,C′) requires processing T − t auxiliary
t t t−1 t:T t t t−1 t t
variables for each time t. However, in Appendix B, we show how F′, b′ and C′ can all be pre-
t t t
computed based on standard Kalman filter recursions (Kalman, 1960), preserving the linear
cost in T and N.
5 Experimental validation and comparison
5.1 Multivariate stochastic volatility model
In this section, we illustrate the efficiency of our methods on a multivariate stochastic volatility
model often used as a benchmark for high-dimensional sequential Monte Carlo methodology
(see, e.g., Guarniero et al., 2017). This model is a state-space model with a non-linear obser-
vation equation:
g (y |x ) = N(y ;0,diag(expx )),
t t t t t
where exp is applied element-wise and where 0 is a D-dimensional vector of zeros. The prior
on the latent variables is defined through auto-regressive Gaussian dynamics, i.e. for t > 1:
f (x |x ) = N(x ;m (x ),C ) (17)
t t t−1 t t t−1 t
where m (x ) := φx and C ∈ RD×D has diagonal entries τ and off-diagonal entries
t t−1 t−1 t
τρ. The initial distribution f (x ) = N(x ;m ,C ) is the stationary distribution under the
1 1 1 1 1
dynamics (17), i.e., m := 0 and C := C /(1−φ2). Here, φ ∈ (−1,1) is some autocorrelation
1 1 t
coefficient, ρ ∈ (−1,1) is some intra-asset correlation coefficient and τ > 0.
Throughout our experiments, we take φ = 0.9, ρ = 0.25, and τ ∈ {0.1,0.5,1,2}. The
eigenvalues of C are then proportional to τ, i.e., a small value of τ corresponds to highly
t
informative prior dynamics (as in Proposition 8) while a large value of τ corresponds to weakly
informative prior dynamics (as in Proposition 9). To make our observations robust to the
choice of data set, for each τ, we simulated M = 5 independent sets of T = 128 observations
from the multivariate stochastic volatility model with D = 30, i.e., each state x takes values
t
in X = R30. To make results more easily comparable, experiments for different values of τ use
the same random number generator seed.
5.2 Simulation study setup
In addition to the methods proposed in Sections 3 and 4 – potentially without the use of
gradient information by taking κ = 0 – we consider the following benchmark methods:
1. CSMC. The CSMC algorithm with bootstrap proposals (Algorithm 1).
2. Particle-RWM. The Particle-RWM algorithm (Algorithm 2) from Finke and Thiery
(2023) (the special case of Particle-aMALA/Particle-MALA/Particle-aMALA+ if κ = 0).
213. MALA and aMALA. The N-proposal MALA and aMALA which correspond to the
Particle-aMALA and Particle-MALA proposed in this work with a single time step (ap-
plied to the path-space representation of the Feynman–Kac model, i.e. with a single
(D×T)-dimensional state).
4. aGRAD. The N-proposal aGRAD algorithm, which corresponds to the Particle-aGRAD
proposed in this work with a single time step (again on the path space). We note that
we implemented aGRAD using the auxiliary Kalman perspective of Corenflos and Särkkä
(2023), making the method complexity scale linearly with T rather than quadratically
with T as in the original version of Titsias and Papaspiliopoulos (2018). We do not
compare to mGRAD because computing its particle weights (and hence acceptance ratio)
has quadratic complexity in T.
All algorithms use N +1 = 32 particles, and those employing resampling use the conditional
’killing’ resampling method (Karppinen et al., 2023), more stable than multinomial resampling,
especially with highly informative priors. In each of M = 5 independent experiments, algo-
rithms start from the same trajectory generated by a bootstrap particle filter using 32 particles.
The samplers run for 10000 steps to calibrate step-size parameters δ , detailed below (note that
t
calibration stabilises much faster). For CSMC, which requires no calibration, the initial 10000
steps are discarded as warm-up. After calibration, J = 4 independent chains start at the final
calibration sample, running for K = 50000 iterations, with the first 5000 discarded as burn-in
to decorrelate the chains. Reported statistics are based on these J independent chains.
The step-size parameters δ are calibrated for a 75% acceptance rate, as explained in Ap-
t
pendixF.Thisslightlyexceedsrecommendationsby, e.g., RobertsandRosenthal(2001);Titsias
and Papaspiliopoulos (2018). This is because we use multiple proposals and the optimal accep-
tance rate is expected to increase accordingly. Here, ’acceptance rate at time t’ refers to the
relative frequency of with which the state x is updated. Figure 7 in Appendix G.1 shows stable
t
acceptance rates around 75% for all methods except CSMC across all time steps. Figure 6 in
Appendix G.1 displays calibrated δ values.
t
Experiments ran on a shared computational cluster with identical configurations (32 GB
RAM, four processor cores, on shared machines with 2 × 64-core AMD EPYC 7713 CPUs,
clock speed 2.0 GHz). Nonetheless, cluster idiosyncrasies may be present, potentially impacting
slower methods like Particle-aMALA+ and Particle-mGRAD.
5.3 Breakdown of CSMC, aMALA and MALA
Our results indicate that CSMC, aMALA, and MALA failed to explore the right regions of the
space for all of our chosen levels of informativeness of the latent dynamics (τ ∈ {0.1,0.5,1,2}).
Specifically, Figures 8 and 9 in Appendix G.2 show that both the estimated marginal posterior
means and also the energy traces of CSMC, aMALA and MALA differ substantially from
those of all the other algorithms. Here, ‘energy trace’ refers to logπ (x )+const computed
T 1:T
on the sampled trajectories throughout the sampling procedure. Since CSMC, aMALA and
MALA thus do not produce reliable approximations of the distribution of interest, we omit
these methods from our discussions in the sequel.
Intheremainderofthissection, wecomparetheremainingalgorithmsintermsoftheeffective
sample size (ESS) computed using the method of Vehtari et al. (2021) with J = 4 independent
chains. We also compare the algorithms in terms of ESS per second (ESS/s). The latter
corresponds to the time it would take to obtain a ‘perfect’ sample using the Markov chain. In
the main manuscript, we only show results for the median ESS and averaged over all T time
22steps. Appendix G.3 shows detailed results for the minimum and maximum ESS and ESS/s
(which are qualitatively similar to the median case) separately for each time step t = 1,...,T.
5.4 Benefits of exploiting gradient information
Figure 3 compares the median ESS (‘unnormalised’) and median ESS/s (‘per second’) of
Particle-aMALA, Particle-MALA and Particle-aMALA+, i.e., for those methods which do not
make any Gaussian assumption about the prior dynamics. Recall that these differ from the
baseline: the Particle-RWM algorithm, only in the use of gradient information. Thus, the left
panel in Figure 3 illustrates the benefits (in terms of ESS) of exploiting gradient information.
Notably:
• the improvement of Particle-MALA over Particle-aMALA is marginal at best. Possi-
bly, the difference between both algorithms decreases with N but this calls for further
investigation;
• the ‘smoothing-gradient’ variant Particle-aMALA+ dominates all other alternatives for
all values of τ, with up to three times the performance of Particle-RWM and twice that
of the ‘filter-gradient’ variants Particle-aMALA and Particle-MALA;
• theperformanceofallshownmethodsimprovesasτ increases: thisisbecausetheposterior
distribution then decorrelates in time, and, therefore, the fact that they all use proposals
which are separable (in the sense discussed in Section 4) stops being penalising.
The right panel in Figure 3 shows that the use of gradient information is still beneficial even
when accounting for the cost of gradient calculation. However, the relative performance of the
gradient-based methods is now less clear: whilst Particle-aMALA+ has the highest sampling
efficiency, it incurs additional overheads due to computing twice as many gradients as Particle-
aMALA and Particle-MALA and due to dealing with non-Markovian potentials.
5.5 Benefits of exploiting Gaussian prior dynamics
In this section, we demonstrate that exploiting the latent (conditionally) Gaussian dynamics of
the model (as done by Particle-aGRAD, Particle-mGRAD and twisted Particle-aGRAD) can
improve the sampling efficiency.
First, in Figure 4, we illustrate the performance of those methods which require (at most)
conditionally Gaussian prior dynamics as in (8), i.e., of Particle-aGRAD and Particle-mGRAD
(note that the later also requires C (x ) = C (13) to retain linear computational complexity
t t−1 t
in N). In terms of ESS, these methods improve upon the ‘filter-gradient’ methods Particle-
aMALA and Particle-MALA but they are still dominated by the ‘smoothing-gradient’ method
Particle-aMALA+. However, the picture is less clear when accounting for computation time.
Second, in Figure 5, we illustrate the performance of the twisted Particle-aGRAD which
requires unconditionally Gaussian prior dynamics as in (15). As a baseline, we use the aGRAD
algorithm from Titsias and Papaspiliopoulos (2018) as it makes the same assumption. The
twisted Particle-aGRAD strongly outperforms this baseline and also all the other algorithms.
Furthermore, thedominanceofthetwistedParticle-aGRADalgorithmdoesnotdisappearwhen
accounting for the computation time. This is because, in contrast to Particle-aMALA+, its
modified model is still Markovian and because it only requires the computation of a single
gradient per particle and time step.
23Unnormalised Persecond
1600
0.8
1200
0.6
Particle-RWM
Particle-aMALA
800
0.4 Particle-MALA
Particle-aMALA+
400 0.2
0 0.0
0.1 0.5 1 2 0.1 0.5 1 2
Prior variance, τ
Figure 3: Performance of those proposed methods which do not require (conditionally or un-
conditionally) Gaussian prior dynamics compared with the existing Particle-RWM
algorithm as a baseline.
Unnormalised Persecond
1600
0.8
Particle-RWM
1200
Particle-aMALA
0.6
Particle-MALA
Particle-aMALA+
800
0.4 Particle-aGRAD
Particle-mGRAD
Particle-aGRAD(κ=0)
400 0.2
Particle-mGRAD(κ=0)
0 0.0
0.1 0.5 1 2 0.1 0.5 1 2
Prior variance, τ
Figure 4: Performanceoftheproposedmethodswhichrequireonlyconditionally Gaussianprior
dynamics (8), i.e., M (x |x ) = N(x ;m (x ),C (x )). The Particle-mGRAD
t t t−1 t t t−1 t t−1
algorithm (with any κ ∈ {0,1}) also requires that C (x ) = C is constant to avoid
t t−1 t
superlinear computational complexity in N. Results that were already shown in the
previous figure are greyed out.
24
SSE
naideM
SSE
naideMUnnormalised Persecond
Particle-RWM
4
4000 Particle-aMALA
Particle-MALA
3 Particle-aMALA+
3000
Particle-aGRAD
Particle-mGRAD
2
2000 TwistedParticle-aGRAD
aGRAD
Particle-aGRAD(κ=0)
1000 1
Particle-mGRAD(κ=0)
TwistedParticle-aGRAD(κ=0)
0 0
0.1 0.5 1 2 0.1 0.5 1 2
Prior variance, τ
Figure 5: Performance of the proposed methods which require unconditionally Gaussian prior
dynamics (15), i.e., M (x |x ) = N(x ;F x + b ,C ), compared with aGRAD
t t t−1 t t t−1 t t
(whichalsorequires(15))asbaseline. Resultsthatwerealreadyshownintheprevious
two figures are greyed out. The abnormally large computation time of the twisted
Particle-aGRAD for κ = τ = 1 was likely caused by some computational-cluster
idiosyncrasies.
6 Conclusion
6.1 Summary
We have proposed a methodology for Bayesian inference about the latent states in high-
dimensional state-space models and beyond. Our methodology combines the CSMC algorithm
(Andrieu et al., 2010) with sophisticated ‘classical’ MCMC algorithms like MALA (Besag,
1994), aMALA (Titsias and Papaspiliopoulos, 2018), aGRAD/mGRAD (Titsias, 2011; Titsias
and Papaspiliopoulos, 2018) or PCNL (Cotter et al., 2013) to retain the best of both worlds:
• fromtheCSMCalgorithm,ourmethodsretaintheabilitytoexploitthemodel’s‘decorrelation-
over-time’ structure which permits favourable scaling with the number of time steps, T;
• from‘classical’MCMCalgorithms,ourmethodsretaintheabilitytousegradient-informed,
local proposals which permits favourable scaling with the dimension of the states, D.
Mostofourproposedalgorithms(exceptthe‘marginal’ones)leverageanauxiliary-variableper-
spective recently proposed in Corenflos and Särkkä (2023). We name our algorithms Particle-
aMALA, Particle-MALA, Particle-aGRAD, Particle-mGRAD and Particle-PCNL. This is mo-
tivated by the fact that if T = N = 1 (where N ∈ N is the number of particles), they reduce to
the ‘classical’ MCMC algorithms: aMALA, MALA, PCNL, aGRAD and mGRAD, respectively.
Furthermore, if T = 1 but N > 1, our methods constitute novel multi-proposal versions of such
‘classical’ MCMC algorithms which may themselves be of interest with a view to exploiting
parallelisation.
25
SSE
naideMThe generalisation of such ‘classical’ MCMC algorithms to T > 1 time steps is, however, not
unique. And so we have presented additional variants named Particle-aMALA+ and Particle-
aGRAD+andtwisted Particle-aGRAD/Particle-aGRAD+. Thesecanbeviewedas‘lookahead’
methods because their proposals employ ‘smoothing’ rather than ‘filter’ gradients or utilise in-
formation contained in future auxiliary variables. Notably, if N = 1 but T > 1, then the IMH,
RWM, aMALA and aGRAD algorithm can still be recovered as a special case of slightly mod-
ified versions of the CSMC, Particle-RWM, Particle-aMALA+, and twisted Particle-aGRAD+
algorithms (and also of the twisted Particle-aGRAD algorithm if G (x ) is constant in x ).
t t−1:t t−1
Specifically, this modification would entail that the latter use no resampling (i.e., they instead
set an = n for all n ∈ [N] and all t ∈ [T − 1]), use ancestral tracing instead of backward
t 0
sampling (i.e., they instead set l = alt+1 for all t ∈ [T −1]) and use δ = ... = δ .
t t 1 T
We have further proved that the Particle-aGRAD/Particle-mGRAD algorithms have the
desirable property that they naturally recover (a) the CSMC algorithm if the prior dynamics
are highly informative (i.e., if the target posterior distribution is dominated by the prior); (b)
theParticle-aMALA/Particle-MALAifthepriordynamicsarecompletelyuninformative(i.e., if
the target posterior distribution is dominated by the likelihood). This property independently
helps explain the impressive performance of aGRAD and mGRAD reported in Titsias and
Papaspiliopoulos (2018).
Our methods have enabled Bayesian inference in a multivariate stochastic volatility model
with D = 30 assets and T = 128 observations (3840 unknowns in total) in which neither
CSMC nor aMALA/MALA gave reliable estimates. In particular, in this application, our
twisted Particle-aGRAD algorithm strongly outperformed the existing sophisticated aGRAD
algorithm – even when accounting for computation time.
6.2 Limitations
The main limitations of our methods are the same as in all gradient-based ‘classical’ MCMC
algorithms. First, they require continuously differentiable target densities (more precisely, the
densities Q (x ) need to be computable and differentiable pointwise). This requirement is
t t−1:t
slightly softened for the methods of Section 4 where only the likelihood G (x ) is required
t t−1:t
to be differentiable, at the cost of needing (at least conditionally) Gaussian prior dynamics
M (x |x ). ThefavourablescalingwiththedimensionDalsotypicallyrequirestargetdensities
t t t−1
to be sufficiently smooth (see, e.g., Vogrinc and Kendall, 2021, for counterexamples). Second,
while it improves mixing properties, locality in MCMC is often detrimental when exploring
multi-modal posteriors. This is inherited by our methods which, too, explore the space by local
moves.
6.3 Extensions
Our work opens up multiple avenues for further research.
• The algorithms proposed in this work can be extended to more general graphical models,
i.e., they can be combined with suitably ‘conditional’ versions of the divide-&-conquer
sequential Monte Carlo algorithm from Lindsten et al. (2017). For instance, for a par-
ticular graphical model, such a ‘conditional’ scheme was recently described in Corenflos
et al. (2022, Section 3).
• Particle-aMALAcanbeincorporatedstraightforwardlyintothemethodologyfromCoren-
flos et al. (2022) to reduce the computation time per MCMC update from O(T) to
26O(log T) (for some fixed dimension D) on parallel architectures. While less directly ob-
2
vious (because of the non-Markovianity of the auxiliary target), the smoothing-gradient
version Particle-aMALA+ is likely parallelisable, too, by simply extending the framework
to compute weight functions over three time steps rather than two. It is however less
clear that Particle-MALA is parallelisable, as the marginalisation has to be done across
two time steps rather than one as presented in Section 3.2.
• All our algorithms can be straightforwardly extended to use other resampling schemes
than conditional multinomial resampling, e.g., conditional systematic resampling. In fact,
in our experiments, we used the conditional killing resampling which is stable under low-
informative likelihoods (Karppinen et al., 2023), a regime that may happen in our case
when δ takes very small values at calibration time.
t
• In this work, we have left aside the question of choosing δ and have elected to take it to
t
correspondtoa75%acceptanceratethroughout. Itishoweverclearthatitsoptimalvalue
(and the optimal value of the acceptance rate) depends on the number of proposals N
and on the dimension D. An optimal-scaling analysis (see Roberts and Rosenthal, 2001,
and references therein) of the methods proposed in this work is therefore needed. An
optimal-scaling analysis for a related algorithm without backward sampling and without
gradient or prior-informed proposals can be found in Malory (2021).
• In Section 4 (in which we propose Particle-aGRAD and variations thereof), we have
assumed that the covariance matrices C (x ) (or C ) are non-singular. However, it is
t t−1 t
worth noting that proposal kernels used by the methods from Section 4 remain valid if
the covariance matrices are singular, in the sense that they are still absolutely continuous
w.r.t. the true dynamics. However, the use of backward sampling is no longer possible
for such degenerate dynamics. Instead, one must resort to ancestral tracing, i.e., taking
l := alt+1, for t = T−1,...,1. However, in this case, N needs to grow with T at a suitable
t t
rate which depends on the stability properties of the model, but at least linearly (Andrieu
et al., 2018; Lindsten et al., 2015). An alternative is to fix N but decrease the step sizes
δ with t (which would automatically occur when using adaptation based on acceptance
t
rates as considered in work), as considered in Malory (2021) for a related method.
• Our proposed algorithms consider solely first-order gradient information. A natural ex-
tension would therefore be to incorporate second-order expansions or preconditioned and
adaptive versions of the Particle-MALA variants. Another obvious direction of study is to
extend our methodology to other MCMC kernels, such as the recently proposed Barker’s
robust proposal (Livingstone and Zanella, 2022), or non-reversible discrete-time kernels
such as the discrete bouncy particle sampler Sherlock and Thiery (2022). Other natu-
ral extensions would consist of adapting the methodology to non-continuous spaces, e.g.,
using methods from Zanella (2020); Rhodes and Gutmann (2022), or constrained spaces.
Author contributions
A.C. and A.F. jointly developed the methodology, writing was primarily done by A.F., A.C. im-
plemented and conducted the experiments, after which both A.C. and A.F. edited and reviewed
the final manuscript.
27References
Andrieu, C., Doucet, A., and Holenstein, R. (2010). Particle Markov chain Monte Carlo methods. Journal of
the Royal Statistical Society: Series B (Statistical Methodology), 72(3):269–342. With discussion.
Andrieu,C.,Lee,A.,andVihola,M.(2018). UniformergodicityoftheiteratedconditionalSMCandgeometric
ergodicity of particle Gibbs samplers. Bernoulli, 24(2):842–872.
Andrieu,C.andVihola, M.(2016). EstablishingsomeorderamongstexactapproximationsofMCMCs. Annals
of Applied Probability, 26(5):2661–2696.
Besag, J. E. (1994). Contribution to the discussion on ‘Representations of knowledge in complex systems’ by
Grenander, U and Miller, M. I.. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
56(4):549–581.
Ceperley, D. M. and Dewing, M. (1999). The penalty method for random walks with uncertain energies. The
Journal of Chemical Physics, 110(20):9812–9820.
Chopin, N. and Singh, S. S. (2013). On particle Gibbs sampling. arXiv e-prints, arXiv:1304.1887v1.
Corenflos, A., Chopin, N., and Särkkä, S. (2022). De-sequentialized Monte Carlo: A parallel-in-time particle
smoother. Journal of Machine Learning Research, 23(283):1–39.
Corenflos, A. and Särkkä, S. (2023). Auxiliary MCMC and particle Gibbs samplers for parallelisable inference
in latent dynamical systems. arXiv preprint arXiv:2303.00301.
Cotter, S. L., Roberts, G. O., Stuart, A. M., and White, D. (2013). MCMC methods for functions: Modifying
old algorithms to make them faster. Statistical Science, 28(3):424–446.
Fearnhead, P. and Meligkotsidou, L. (2016). Augmentation schemes for particle MCMC. Statistics and Com-
puting, 26:1293–1306.
Finke, A. (2015). On Extended State-Space Constructions for Monte Carlo Methods. PhD thesis, Department
of Statistics, University of Warwick, UK.
Finke, A., Doucet, A., and Johansen, A. M. (2016). On embedded hidden Markov models and particle Markov
chain Monte Carlo methods. arXiv e-prints, arXiv:1610.08962.
Finke, A. and Thiery, A. H. (2023). Conditional sequential Monte Carlo in high dimensions. The Annals of
Statistics, 51(2):437–463.
Guarniero, P., Johansen, A. M., and Lee, A. (2017). The iterated auxiliary particle filter. Journal of the
American Statistical Association, 112(520):1636–1647.
Hastings,W.K.(1970).MonteCarlosamplingmethodsusingMarkovchainsandtheirapplications. Biometrika,
57(1):97–109.
Henderson, H. V. and Searle, S. R. (1981). On deriving the inverse of a sum of matrices. SIAM Review,
23(1):53–60.
Heng, J., Bishop, A. N., Deligiannidis, G., and Doucet, A. (2020). Controlled sequential Monte Carlo. The
Annals of Statistics, 48(5):2904 – 2929.
Kalman,R.E.(1960). Anewapproachtolinearfilteringandpredictionproblems. JournalofBasicEngineering,
82:35–45.
Karjalainen,J.,Lee,A.,Singh,S.S.,andVihola,M.(2023). Mixingtimeoftheconditionalbackwardsampling
particle filter. arXiv e-prints, arXiv:2312.17572.
Karppinen, S., Singh, S. S., and Vihola, M. (2023). Conditional particle filters with bridge backward sampling.
Journal of Computational and Graphical Statistics, 0(0):1–15.
Karppinen, S. and Vihola, M. (2021). Conditional particle filters with diffuse initial distributions. Statistics
and Computing, 31:1–14.
Lee, A., Singh, S. S., and Vihola, M. (2020). Coupled conditional backward sampling particle filter. Annals of
Statistics, 48(5):3066–3089.
Lindsten,F.,Douc,R.,andMoulines,E.(2015). UniformergodicityoftheparticleGibbssampler. Scandinavian
Journal of Statistics, 42(3):775–797.
Lindsten, F., Johansen, A. M., Naesseth, C. A., Kirkpatrick, B., Schön, T. B., Aston, J. A., and Bouchard-
Côté, A. (2017). Divide-and-conquer with sequential Monte Carlo. Journal of Computational and Graphical
Statistics, 26(2):445–458.
28Lindsten, F., Jordan, M. I., and Schön, T. B. (2012). Ancestor sampling for particle Gibbs. In Proceedings of
the 2012 Conference on Neural Information Processing Systems, Lake Tahoe, NV.
Liu, J. S. (1996). Peskun’s theorem and a modified discrete-state Gibbs sampler. Biometrika, 83(3):681–682.
Livingstone, S. and Zanella, G. (2022). The Barker proposal: Combining robustness and efficiency in gradient-
based MCMC. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 84(2):496–523.
Malory, S. (2021). Bayesian inference for stochastic processes. PhD thesis, Lancaster University.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E. (1953). Equation of state
calculations by fast computing machines. Journal of Chemical Physics, 21(6):1087–1092.
Murray, L. M., Jones, E. M., and Parslow, J. (2013). On disturbance state-space models and the particle
marginal Metropolis–Hastings sampler. SIAM/ASA Journal on Uncertainty Quantification, 1(1):494–521.
Nicholls,G.K.,Fox,C.,andMuirWatt,A.(2012). CoupledMCMCwitharandomizedacceptanceprobability.
arXiv e-prints, arXiv:1205.6857.
Rhodes, B. and Gutmann, M. (2022). Enhanced gradient-based MCMC in discrete spaces. arXiv e-prints,
arXiv:2208.00040.
Roberts, G. O., Gelman, A., and Gilks, W. R. (1997). Weak convergence and optimal scaling of random walk
Metropolis algorithms. The Annals of Applied Probability, 7(1):110–120.
Roberts, G. O. and Rosenthal, J. S. (1998). Optimal scaling of discrete approximations to Langevin diffusions.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 60(1):255–268.
Roberts, G. O. and Rosenthal, J. S. (2001). Optimal scaling for various Metropolis–Hastings algorithms.
Statistical Science, 16(4):351–367.
Särkkä, S. and Svensson, L. (2023). Bayesian filtering and smoothing, volume 17. Cambridge University Press.
Sherlock, C. and Thiery, A. H. (2022). A discrete bouncy particle sampler. Biometrika, 109(2):335–349.
Shestopaloff, A. Y. and Neal, R. M. (2018). Sampling latent states for high-dimensional non-linear state space
models with the embedded HMM method. Bayesian Analysis, 13(3):797–822.
Singh,S.S.,Lindsten,F.,andMoulines,E.(2017). BlockingstrategiesandstabilityofparticleGibbssamplers.
Biometrika, 104(4):953–969.
Titsias, M. K. (2011). Contribution to the discussion on ‘Riemann manifold Langevin and Hamiltonian Monte
Carlo methods’ by Girolami, M., and Calderhead, b. Journal of the Royal Statistical Society Series B:
Statistical Methodology, 73(2):123–214.
Titsias, M. K. and Papaspiliopoulos, O. (2018). Auxiliary gradient-based sampling algorithms. Journal of the
Royal Statistical Society: Series B (Statistical Methodology), 80(4):749–767.
Tjelmeland, H. (2004). Using all Metropolis–Hastings proposals to estimate mean values. preprint 4/2004,
Norwegian University of Science and Technology, Trondheim, Norway.
Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., and Bürkner, P.-C. (2021). Rank-normalization, folding,
and localization: An improved Rb for assessing convergence of MCMC (with discussion). Bayesian Analysis,
16(2):667–718.
Vogrinc,J.andKendall,W.S.(2021). CounterexamplesforoptimalscalingofMetropolis–Hastingschainswith
rough target densities. The Annals of Applied Probability, 31(2):972–1019.
Whiteley, N. (2010). Contribution to the discussion on ‘Particle Markov chain Monte Carlo methods’ by
Andrieu, C., Doucet, A., and Holenstein, R. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 72(3):306–307.
Whiteley, N. and Lee, A. (2014). Twisted particle filters. The Annals of Statistics, 42(1):115–141.
Zanella, G. (2020). Informed proposals for local MCMC in discrete spaces. Journal of the American Statistical
Association, 115(530):852–865.
29A Particle extensions of PCN(L)
A.1 Particle-aPCNL
In this section, we extend the preconditioned Crank–Nicolson–Langevin (PCNL) algorithm (and
also the preconditioned Crank–Nicolson (PCN) algorithm recovered by setting κ = 0) (Cotter
et al., 2013) to T > 1 time steps and N > 1. As a by-product, we derive an ‘auxiliary-variable’
versionofPCNLwhichwasmentioned,butnotexplicitlystated,inTitsiasandPapaspiliopoulos
(2018). Throughout this section, we assume the prior dynamics are conditionally Gaussian,
M (x |x ) = N(x ;m (x ),C (x )) as in (8).
t t t−1 t t t−1 t t−1
Throughout this section, we use the parametrisation of the PCNL algorithm from Titsias
and Papaspiliopoulos (2018)3, i.e., we set
2
β := ∈ (0,1),
t 2+δ
t
where δ > 0 is again the step size at time t. Note that this implies that 1−βt = δt.
The fit rst method proposed in this section is termed Particle-aPCNL.β Ct ondi2 tional on the
auxiliary variables u , it can be viewed as a CSMC algorithm whose proposal kernels are
1:T
those of the fully-adapted auxiliary particle filter for the state-space model defined by the
Gaussian transitions p(x |x ) = N(x ;m (x ),C (x )) from (8) and ‘pseudo observations’
t t−1 t t t−1 t t−1
u
t
with p(u t|x t) = N(u t;x t, δ 2tC t(x t−1)). We now write
M′(x |x ,u ) := p(x |x ,u )
t t t−1 t t t−1 t
∝ M t(x t|x t−1)N(u t;x t, δ 2tC t(x t−1))
∝ N(x ;m′(x ,u ),C′(x )), (18)
t t t−1 t t t−1
with
m′(x ,u ) := β u +(1−β )m (x ), (19)
t t−1 t t t t t t−1
C′(x ) := (1−β )C (x ), (20)
t t−1 t t t−1
as well as
G′(x ;u ) := Q (x
)N(u t;x
t
+κδ 2tCe t(x t−1)∇ xtlogG t(x t−1:t), δ 2tC t(x t−1))
, (21)
t t−1:t t t t−1:t M′(x |x ,u )
t t t−1 t
and Q′ t(x t−1:t;u t) := M t′(x t|x t−1;u t)G′ t(x t−1:t;u t). Here, Ce t(x t−1) ∈ RD×D is some precondi-
tioning matrix whose choice is discussed in Section A.5 below.
A single iteration of the Particle-aPCNL algorithm is then as follows.
Algorithm 9 (Particle-aPCNL). Implement Algorithm 1 but replace the particle proposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x
t
+κδ 2tCe t(x t−1)∇ xtlogG t(x t−1:t), δ 2tC t(x t−1)), and x tn ∼ M t′(·|x ta −n t− 11;u t),
for n ∈ [N] \{k },
0 t
1d. for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−1:t t
and also replace Q (·) in the backward kernel in Step 3 by Q′ (·;u ).
t+1 t+1 t
Proposition 10 (validity of Particle-aPCNL). Sampling x˜ given x via Algorithm 9
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-aPCNL 1:T 1:T T
3In the parametrisation from Cotter et al. (2013), we would have δ t ∈[0,2] β t = 2 2− +δδ tt
30A.2 Particle-PCNL
In this section, in analogy to the Particle-MALA and Particle-mGRAD algorithms from the
main manuscript, we analytically integrate out the auxiliary variables u which appeared in the
t
weights of the Particle-aPCNL algorithm. As in the case of the Particle-mGRAD algorithm, we
assume that the covariance matrices appearing in the conditionally Gaussian mutation kernel
(8) do not depend on the previous state, i.e., C (x ) = C (13).
t t−1 t
Asingleiterationoftheresultingmethodology–whichwetermtheParticle-PCNLalgorithm
– is as follows, where we write
logH (x,v,x¯,v¯) = 1(β−1 +N +1)(x−v)T G (x−v)
t,ϕ 2 t t
− 1 Nβ (x+ϕ)T G (x+ϕ)
2 t t
+(N +1)(x¯ −v¯)T G (v+ϕ)
t
−(x−v)T G (x+ϕ),
t
for
β 2(δ +2)
G := t C−1 = t C−1 . (22)
t (1−β )(1+Nβ ) t δ (δ +2+N) t
t t t t
Algorithm 10 (Particle-PCNL). Implement Algorithm 1 but replace the particle proposal
(Step 1c) and the weight calculation (Step 1d) by
1c. sample u
t
∼ N(x
t
+κδ 2tCe t(x t−1)∇ xtlogG t(x t−1:t), δ 2tC t), and x tn ∼ M t′(·|x ta −n t− 11;u t), for
n ∈ [N] \{k },
0 t
1d. set x¯ := 1 PN xn, vn := (1−β )m (xan t−1), v¯ := 1 PN vn, and, for n ∈ [N] ,
t N+1 n=0 t t t t t−1 t N+1 n=0 t 0
wn ∝ Q (x(n) )H (xn,vn,x¯ ,v¯ ).
t t t−1:t t,κδ 2tCet(x ta −n t− 11)∇ xn
t
logGt(x t( −n) 1:t) t t t t
In the same way as outlined in Remarks 1 and 2, the Particle-aPCNL algorithm can be
viewed as an ‘exact approximation’ of the Particle-PCNL algorithm.
Proposition 11 (validity of Particle-PCNL). Sampling x˜ given x via Algorithm 10
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-PCNL 1:T 1:T T
A.3 Particle-aPCNL+
In this section, similar to the Particle-aMALA+ and Particle-aGRAD+ algorithms from the
main manuscript, we extend the Particle-aPCNL algorithm to incorporate gradients w.r.t. the
‘smoothing’ potential G (x ) = QT G (x ) rather than w.r.t. the ‘filtering’ potential
1:T 1:T t=1 t t−1:t
Qt G (x ).
s=1 s s−1:s
For M′(x |x ;u ) and G′(x ,u ) still defined as in the Particle-aPCNL algorithm (i.e.,
t t t−1 t t t−1:t t
as in (18) and (21)), we now write
G′(x ,u )
t t−2:t 1:T
:= G′(x ,u )
N(u t−1;x
t−1
+κδt 2−1Ce t−1(x t−2)∇ xt−1logG 1:T(x 1:T), δt 2−1C t−1(x t−2))
,
t t−1:t t N(u t−1;x
t−1
+κδt 2−1Ce t−1(x t−2)∇ xt−1logG t−1(x t−2:t−1), δt 2−1C t−1(x t−2))
31as well as Q′(x ;u ) := M′(x |x ;u )G′(x ;u ), where we note that
t t−2:t t−1:t t t t−1 t t t−2:t t−1:t
∇ logG (x ) = ∇ [logG (x )+logG (x )].
xt 1:T 1:T xt t t−1:t t+1 t:t+1
Asingleiterationoftheresultingmethodology–whichwetermtheParticle-aPCNL+algorithm
– is as follows.
Algorithm 11 (Particle-aPCNL+). Implement Algorithm 1 but replace the particle pro-
posal (Step 1c), the weight calculation (Step 1d), and backward sampling (Step 3) by
1c. sample u
t
∼ N(x
t
+κδ 2tCe t(x t−1)∇ xtlogG T(x 1:T), δ 2tC t(x t−1)), and x tn ∼ M t′(·|x ta −n t− 11;u t),
for n ∈ [N] \{k },
0 t
1d. for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−2:t t−1:t
3. for t = T −1,...,1, sample l = i ∈ [N] w.p.
t 0
WiQ′ ((x(i) ,xlt+1);u )Q′ ((xi,xlt+1,xlt+2);u )
t t+1 t−1:t t+1 t:t+1 t+2 t t+1 t+2 t+1:t+2 .
PN WnQ′ ((x(n) ,xlt+1);u )Q′ ((xn,xlt+1,xlt+2);u )
n=0 t t+1 t−1:t t+1 t:t+1 t+2 t t+1 t+2 t+1:t+2
Note that if G (x ) = G (x ) does not depend on x , then the Particle-aPCNL+ algo-
t t−1:t t t t−1
rithm coincides with the Particle-aPCNL algorithm. However, when G (x ) varies highly in
t t−1:t
x , their behaviours may differ substantially.
t−1
Proposition 12 (validity of Particle-aPCNL+). Samplingx˜ givenx viaAlgorithm11
1:T 1:T
induces a Markov kernel P (x˜ |x ) which leaves π invariant.
Particle-aPCNL+ 1:T 1:T T
A.4 Twisted Particle-aPCNL(+)
In analogue to the twisted Particle-aGRAD and twisted Particle-aGRAD+ algorithms, we can
again construct ‘twisted’ versions of the Particle-aPCNL and Particle-aPCNL+ algorithms,
under the assumption that M (x |x ) = N(x ;F x +b ,C ), i.e., (15).
t t t−1 t t t−1 t t
We start with the twisted Particle-aPCNL algorithm. We now write
M′(x |x ;u ) := p(x |x ,u )
t t t−1 t:T t t−1 t:T
Z " T #
∝ YN(x s;F sx
s−1
+b s,C s)N(u s;x s, δ 2sC t) dx
t+1:T
XT−t s=t
∝ N(x ;F′x +b′,C′), (23)
t t t−1 t t
G′(x ;u ) := Q (x
)N(u t;x
t
+κδ 2tCe t(x t−1)∇ xtlogG t(x t−1:t), δ 2tC t)
,
t t−1:t t:T t t−1:t M′(x |x ,u )
t t t−1 t:T
as well as Q′(x ;u ) := M′(x |x ;u )G′(x ;u ). Here, b′ ∈ RD and F′,C′ ∈ RD×D
t t−1:t t:T t t t−1 t:T t t−1:t t:T t t t
can again be obtained via the Kalman-filtering recursions given in Appendix B.
A single iteration of the resulting methodology – which we term the twisted Particle-aPCNL
algorithm – is then exactly as the Particle-aPCNL algorithm (Algorithm 9), except that
M′(·|·;u ), G′(·;u ) and Q′(·;u ) from Section A.1 are replaced by M′(·|·;u ), G′(·;u )
t t t t t t t t:T t t:T
and Q′(·;u ) from this section. When the potential functions G (x ) vary in x , then
t t:T t t−1:t t−1
we can further construct a twisted Particle-aGRAD+ algorithm by replacing M′(x |x ,u ) in
t t t−1 t
Algorithm 11 and in the denominator of G′(x ;u ) by M′(x |x ,u ).
t t−2:t t−1:t t t t−1 t:T
Proposition 13 (validity of the twisted Particle-aPCNL/Particle-aPCNL+). Sampling
x˜ given x via the twisted Particle-aPCNL or twisted Particle-aPCNL+ algorithm induces
1:T 1:T
a Markov kernel which leaves π invariant.
T
32A.5 Choice of preconditioning matrix
There is some degree of freedom in choosing the preconditioning matrices Ce t(x t−1) ∈ RD×D in
the algorithms presented above.
1. A simple option which does not require further assumptions is to take
Ce t(x t−1) := C t(x t−1).
2. Ifwemakethestrongermodelassumptionthatm (x ) = F x +b andC (x ) = C
t t−1 t t−1 t t t−1 t
(15)(whichisassumedtoholdforthetwistedversionsoftheParticle-aPCNLandParticle-
aPCNL+ algorithms anyway), then we could alternatively set
T
Ce t(x t−1) = Ce
t
:= X Σ s,t, (24)
s=1
where Σ ∈ RD×D is the block (s,t) in the covariance matrix Σ ∈ RTD×TD of the prior
s,t
dynamics M (x ), i.e.,
1:T 1:T
 F Σ , if s > t,
 s s−1,t
Σ = ΣT , if s < t,
s,t t,s
Σ
, if s = t,
t
where Σ can be found via the recursion from Step 1 of Algorithm 12 from Appendix B.
t
As discussed below, this specification has the potentially useful implication that the al-
gorithm reduces to an ‘auxiliary-variable’ version of the PCNL algorithm on the path
space in the absence of resampling and backward sampling. Unfortunately, evaluating
the preconditioning matrices Ce is likely to incur a quadratic computational complexity
t
in T which we prefer to avoid.
3. A compromise (which retains linear computational complexity in T) may be to truncate
the above sum by setting
(t+L)∧T
Ce := X Σ ,
t s,t
s=(t−L)∨1
for some L ∈ [T] (note that this still requires the model assumption (15)).
0
A.6 Relationship with other methods
The algorithms proposed above relate to existing methods as follows.
1. Generalisation of aPCNL. For κ = 1, the Particle-aPCNL algorithm (and similarly
the Particle-aPCNL+ algorithm as well as the twisted versions of either) generalises an
auxiliary preconditioned Crank–Nicolson–Langevin (aPCNL) algorithm (which was men-
tioned but not explicitly derived in Titsias and Papaspiliopoulos (2018)) in the sense that
the former reduces to the latter if T = N = 1. This can be seen as follows, where we
again suppress the ‘time’ subscript t = 1 everywhere so that π(x) ∝ M(x)G(x), where
M(x) = N(x;m,C). We also take Ce := C. Given that the current state of the Markov
33chain is x = x0 (we can assume that k = 0 without loss of generality), Step 1c of Algo-
rithm 9 first refreshes the auxiliary variable by sampling u ∼ N(x0+ δC∇logG(x0), δC)
2 2
and then proposes x1 ∼ N((1−β)m+βu,(1−β)C). The remaining steps return x˜ := x1
as the new state with acceptance probability 1∧α (x0,x1;u), where
aPCNL
α
(x0 ,x1;u)
aPCNL
1−W0
:=
1−W1
π(x1)N(u;x1 + δC∇logG(x1), δC)N(x0;(1−β)m+βu,(1−β)C)
= 2 2 .
π(x0)N(u;x0 + δC∇logG(x0), δC)N(x1;(1−β)m+βu,(1−β)C)
2 2
Otherwise, the old state x˜ := x0 = x is returned as the new state. If N = 1 and κ = 1 but
T > 1 then the aPCNL algorithm could still be recovered as a special case of (a slightly
modified version of) the twisted Particle-aPCNL+ algorithm (and also of the twisted
Particle-aPCNL algorithm if the potential functions G (x ) do not depend on x ) if
t t−1:t t−1
the latter uses no resampling and ancestral tracing instead of backward sampling, and if
δ = ... = δ and if the preconditioning matrices are specified via (24). However, we do
1 T
not recommend this choice of preconditioning matrix as it leads to squared computational
complexity in T (also incurred by aPCNL).
2. Generalisation of PCNL. Still taking κ = 1, the Particle-PCNL algorithm generalises
the preconditioned Crank–Nicolson–Langevin (PCNL) algorithm (Cotter et al., 2013) in
the sense that the former reduces to the latter if T = N = 1. This can be seen as follows,
where we use the same notational conventions as in the case of aPCNL above. Step 1c of
Algorithm 10 then marginally proposes x1 ∼ N((1−β)m+β[x0 + δC∇logG(x0)],(1−
2
β2)C). The remaining steps return x˜ := x1 as the new state with acceptance probability
1∧α (x0,x1), where
PCNL
1−W0
α (x0 ,x1) :=
PCNL 1−W1
π(x1)N((1−β)m+β[x1 + δ∇logG(x1)],(1−β2)C)
= 2 .
π(x0)N((1−β)m+β[x0 + δ∇logG(x0)],(1−β2)C)
2
Otherwise, the old state x˜ := x0 = x is returned as the new state. In particular, in
analogue to Section 3.4, we can again interpret aPCNL as a version of PCNL with ‘ran-
domised’ acceptance ratio.
B Twisted proposals
In this section, we detail the mutation kernel M′(x |x ;u ) used by the twisted Particle-
t t t−1 t:T
aGRAD/Particle-aGRAD+(16)andtwistedParticle-aPCNL/Particle-aPCNL+(23)algorithms.
This mutation kernel can be thought of as the fully-twisted particle-filter proposal for the
state-space model which is defined by the Gaussian transitions p(x |x ) = M (x |x ) =
t t−1 t t t−1
N(x t;F tx t−1+b t,C t) from (15) and observation densities p(u t|x t) = N(u t;x t, δ 2tV t), where we
take V := I in the case of the twisted Particle-aGRAD or twisted Particle-aGRAD+ algorithm
t
andV := C inthe caseof thetwistedParticle-aPCNLortwistedParticle-aPCNL+algorithm:
t t
M′(x |x ;u ) = p(x |x ,u ) = N(x ;F′x +b′,C′).
t t t−1 t:T t t−1 1:T t t t−1 t t
34General algorithm. Algorithm 12 explains how the twisted-proposal parameters b′ ∈ RD
t
and F′,C′ ∈ RD×D can be calculated at linear complexity in T, independently of the total
t t
number of particles, N. Notably, Algorithm 12 does not require C to be invertible.
t
Algorithm 12 (twisted-proposal parameters). At the start of an iteration of the twisted
Particle-aGRAD, Particle-aGRAD+, Particle-aPCNL or Particle-aPCNL+ algorithm (after
having sampled all the auxiliary variables u upfront – e.g., as in Algorithm 14 from Ap-
1:T
pendix D.1 – which is possible because these only depend on the reference path),
1. recursively compute the moments of p(x ) = N(x ;µ ,Σ ), for t = 1,...,T, as
t t t t
µ := F µ +b ,
t t t−1 t
Σ := F Σ FT +C ,
t t t−1 t t
if t > 1, and with initial condition µ = b and Σ = C ,
1 1 1 1
2. recursivelycomputethemomentsofthetime-reversedstatetransitionkernelsp(x |x ) =
t t+1
N(x ;F←x +b←,C←), for t = T −1,...,1, as
t t t+1 t t
F← := F Σ Σ−1 ,
t t+1 t t+1
b← := µ −F←µ ,
t t t t+1
C← := Σ −F←Σ FT .
t t t t t+1
3. run the Kalman filtering recursion for the time-reversed state-space model (i.e., with
observation densities p(u |x ) = N(u ;x , δtV ), initial distribution p(x ) and time-
t t t t 2 t t
reversed state transitions p(x |x ) found in Steps 1 and 2) to compute the moments
t t+1
of p(x |u ) = N(x ;µ←,Σ←), for t = T,...,1,
t t:T t t|t t|t
4. set F′ := 0 , b′ := µ← as well as C′ := Σ←, and, for t = 2,...,T,
1 D×D 1 1|1 1 1|1
F′ := Σ←F← (C← +F← Σ←{F← }T)−1 ,
t t|t t−1 t−1 t−1 t|t t−1
b′ := µ← −F′(F← µ← +b← ),
t t|t t t−1 t|t t−1
C′ := (I−F′F← )Σ←.
t t t−1 t|t
Algorithm 12 is justified by the decomposition
M′(x |x ;u ) ∝ p(x |u )
t t t−1 t:T t−1:t t:T
= p(x |x )p(x |u )
t−1 t t t:T
= N(x ;F←x +b←,C←)N(x ;µ←,Σ←) (25)
t t t+1 t t t t|t t|t
∝ N(x ;F′x +b′,C′), (26)
t t t−1 t t
where, as described in Algorithm 12, p(x |u ) = N(x ;µ←,Σ←) is the time-t filter for the
t t:T t t|t t|t
time-reversed state-space model with the same observation densities p(u |x ) = N(u ;x , δtV )
t t t t 2 t
as before but with initial distribution p(x ) = N(x ;µ ,Σ ) and time-reversed state transitions
t t T T
p(x |x ) = N(x ;F←x +b←,C←). Thus, in Algorithm 12:
t t+1 t t t+1 t t
• Step 1 calculates the marginal prior distributions of the states. To see this, note that
this step is effectively the Kalman-filter recursion without observations. Note that if the
35prior dynamics are stationary with stationary distribution N(µ,Σ), then Step 1 can be
skipped (because then µ = µ and Σ = Σ, for any t ∈ [T]).
t t
• Step 2 computes the parameters of the time-reversed transition kernels and follows from
standard Gaussian algebra (see, e.g., Särkkä and Svensson, 2023, Section A.1) by noting
that
" # " # " #!
x µ Σ F Σ
t ∼ N t , t t+1 t .
x µ Σ FT Σ
t+1 t+1 t t+1 t+1
• Step 4 derives (26) from (25) and corresponds to a single update step of a Kalman filter
(Särkkä and Svensson, 2023, Chapter 6, Equation 6.21), where x plays the rôle of an
t−1
observation.
Alternative algorithm for invertible covariance matrices. If C is invertible for all
t
t ∈ [T], then the twisted-proposal parameters can be alternatively computed via Algorithm 13
which may be slightly simpler to implement for some users and which may provide additional
numerical advantages in the case of explosive prior dynamics.
Algorithm 13 (twisted-proposal parameters: alternative). At the start of an iteration
of the twisted Particle-aGRAD, Particle-aGRAD+, Particle-aPCNL or Particle-aPCNL+ algo-
rithm (after having sampled all the auxiliary variables u upfront – e.g., as in Algorithm 14
1:T
from Appendix D.1 – which is possible because these only depend on the reference path),
1. run the Kalman filtering recursion to compute the moments of p(x |u ) =
t 1:t−1
N(x ;µ ,Σ ), for t = 1,...,T,
t t|t−1 t|t−1
2. runtheKalmansmoothing(a.k.a.Rauch–Tung–Striebelsmoothing)recursiontocompute
the moments of p(x |u ) = N(x ;µ ,Σ ), for t = T,T −1,...,1,
t 1:T t t|T t|T
3. for t ∈ [T], set
C′ := [C−1 +Σ−1 −Σ−1 ]−1 ,
t t t|T t|t−1
F′ := C′[C−1 b +Σ−1 µ −Σ−1 µ ],
t t t t t|T t|T t|t−1 t|t−1
b′ := C′C−1 F .
t t t t
Algorithm 13 is justified by the decomposition
p(x |x ,u ) ∝ p(x ,u )
t t−1 1:T t−1:t 1:T
= p(x |x ,u )p(x |u )
t−1 t 1:T t 1:T
p(x |x )
∝ t t−1 p(x |u )
p(x |u ) t 1:T
t 1:t−1
N(x ;F x +b ,C )
= t t t−1 t t N(x ;µ ,Σ )
N(x ;µ ,Σ ) t t|T t|T
t t|t−1 t|t−1
∝ N(x ;F′x +b′,C′).
t t t−1 t t
C Integrating out the auxiliary variables
In this section, we prove a few lemmata which are used in subsequent sections.
36• Lemmata 1 and 2. Lemmata 1 and 2 derive the determinant and inverse of a certain
simple block matrix which appears repeatedly in the remainder of this section and also
in Appendix E.
• Lemma 3. Lemma3willallowustoderivemarginalproposaldistributionsofthevarious
algorithms, i.e., the distribution of x−kt = (x0,...,xkt−1 ,xkt+1 ,...,xN) conditional on k ,
t t t t t t
xkt = x and all the particles and ancestor indices with time indices s < t, but with the
t t
auxiliary variables u integrated out.
1:T
• Lemma 4. Lemma 4 will allow us to evaluate the particle weights used in the ‘marginal’
algorithms (Particle-MALA, Particle-mGRAD and Particle-PCNL) at linear complexity
in N although the weight of the nth particle depends on the values of all other particles.
C.1 Properties of a particular block matrix
Let I denote the (M × M) identity matrix. When M = D we continue to leave out the
M
subscript. Furthermore, let 1 ∈ {1}M×N and denote a matrix in which every element is 1.
M×N
For matrices A,B ∈ RD×D, define the block matrix
 A+B B ... B 
  B A+B ... . . .  
M N(A,B) := I N ⊗A+1 N×N ⊗B =  

. .
.
... ...
B
 

∈ R(DN)×(DN) . (27)
 
B ... B A+B
Lemma 1. For N,D ∈ N, let A,B ∈ RD×D. Then,
det(M (A,B)) = det(A)N−1det(A+NB).
N
Proof. Subtracting the last row of M (A,B) from all other rows and then adding the sum
N
of the first N −1 columns to the last column gives the upper-triangular block matrix
 
A 0 ... 0
 B ... ... . . .  
 

. .
.
...
A 0
  .
 
B ... B A+NB
This proves the result.
(cid:50)
Lemma 2. For N,D ∈ N, let A,B ∈ RD×D, such that A and (A+NB) are invertible. Then
M (A,B)−1 = M (A−1 ,−(A+NB)−1 BA−1).
N N
Proof. We must have M (A,B)M (F,G) = I and hence
N N DN
(A+B)(F+G)+(N −1)BG = I,
B(F+G)+(A+B)G+(N −2)BG = 0.
This implies F = A−1 and G = −(A+NB)−1BA−1.
(cid:50)
37C.2 Conditional and marginal proposal distributions
In this section, for any tuple (z ,...,z ) of values in X := RD and any n ∈ [N] , we write
0 N 0
z := (z ,...,z ,z ,...,z ). Given some N ∈ N, n ∈ [N] , x ,ϕ ∈ X, we consider the
−n 0 n−1 n+1 N 0 n n
following joint distribution on XN+1:
N
q (u,x |x ) := N(u;x +ϕ ,E)YN(x ;v +H u,D ), (28)
−n −n n n n m m m m
m=0
m̸=n
where, for any m ∈ [N] , v ∈ X and H ∈ RD×D, and D ,E ∈ RD×D are positive definite
0 m m m
and symmetric.
Tosimplifythepresentation–andwithsomeabuseofnotationsinceweusethesamesymbols
for tuples and their vectorised versions – we write
       
x v H D
0 0 0 0
. . . .
 .   .   .   . 
 .   .   .   . 
       
x  v  H  D 
x −n :=    xn
n
.− +1 1   , v −n :=    vn
n
.− +1 1   , H −n :=    Hn
n
.− +11   , D −n := diag      D nn .+− 11      ,
 .   .   .   . 
 .   .   .   . 
       
x v H D
n n n n
where, in the last expression, diag induces a block-diagonal matrix. With this notation, we can
formulate (28) equivalently as
q (u,x |x ) = N(u;x +ϕ ,E)N(x ;v +H u,D ). (29)
−n −n n n n −n −n −n −n
Lemma 3. For any n ∈ [N] and x ∈ X,
0 n
1. the marginal distribution of x given x under (29) is
−n n
q (x |x ) = N(x ;µ ,Σ ),
−n −n n −n −n −n
where
µ := v +H (x +ϕ ),
−n −n −n n n
Σ := D +H EHT ;
−n −n −n −n
2. the conditional distribution of u given x and x under (29) is
−n n
q (u|x ,x ) = N(u;x +ϕ +K[x −v −H (x +ϕ )],(I−KH )E),
−n −n n n n −n −n −n n n −n
where K := EHT (D +H EHT )−1.
−n −n −n −n
Proof. This follows by simple algebra (see, e.g., Särkkä and Svensson, 2023, Appendix A.1).
(cid:50)
Lemma 4. Assume now that H = H and D = D, for any m ∈ [N] . Then, with the
m m 0
notation from Lemma 3,
q (x |x ) ∝ H (x ,v ,x¯,v¯)I((x −v )N ),
−n −n n ϕn n n m m m=0
where
381. z 7→ I(z ) is invariant under any permutation of its arguments;
0:N 0:N
2. x¯ := 1 PN x , and v¯ := 1 PN v , and
N+1 m=0 n N+1 m=0 n
logH (x,v,x¯,v¯)
ϕ
= 1(x−v)T(D−1 +G)(x−v)
2
− 1 N(x+ϕ)T HT(D−1 −NG)H(x+ϕ)
2
−(N +1)(x¯ −v¯)T[G(x−v)−(D−1 −NG)H(x+ϕ)]
−(x−v)T(D−1 −NG)H(x+ϕ),
whose evaluation complexity does not depend on N. Here,
G := (D+NHEHT)−1 HEHT D−1 (30)
= D−1 HE(E+NEHT D−1 HE)−1 EHT D−1 . (31)
Proof. The equivalence of (30) and (31) follows from the push-through identity (Henderson
and Searle, 1981). By assumption, Σ = M (D,HEHT). Thus, Lemma 2 gives
−n N
Σ−1 = M (D−1 ,−G).
−n N
In particular, letting ⊗ be the Kronecker product, this implies that
Σ−1 H = 1 ⊗[(D−1 −NG)H],
−n −n N×1
HT Σ−1 H = NHT(D−1 −NG)H.
−n −n −n
Therefore, defining
   
x v
0 0
. .
x :=   . .  , v :=   . .  , Σ := M N+1(D−1 ,−G)−1 ,
   
x v
N N
39we have
q (x |x )
−n −n n
∝ exp(cid:16) −1h (x −v −H (x +ϕ ))T Σ−1(x −v −H (x +ϕ ))i(cid:17)
2 −n −n −n n n −n −n −n −n n n
= exp(cid:16) −1h (x −v )T Σ−1(x −v )
2 −n −n −n −n −n
+(x +ϕ )T HT Σ−1 H (x +ϕ )
n n −n −n −n n n
−2(x −v )T Σ−1 H (x +ϕ )i(cid:17)
−n −n −n −n n n
= exp(cid:16) −1h (x−v)T Σ−1(x−v)
2
−(x −v )T(D−1 −G)(x −v )
n n n n
+2(x −v )T[1 ⊗G](x −v )
−n −n N×1 n n
+N(x +ϕ )T HT(D−1 −NG)H(x +ϕ )
n n n n
−2(x −v )T Σ−1 H (x +ϕ )i(cid:17)
−n −n −n −n n n
= exp(cid:16) −1h (x−v)T Σ−1(x−v)
2
−(x −v )T(D−1 −G)(x −v )
n n n n
+N(x +ϕ )T HT(D−1 −NG)H(x +ϕ )
n n n n
+2(x−v)Tn 1 ⊗[G(x −v )−(D−1 −NG)H(x +ϕ )]o
(N+1)×1 n n n n
−2(x −v )T[G(x −v )−(D−1 −NG)H(x +ϕ )]i(cid:17)
n n n n n n
= H (x ,v ,x¯,v¯)I((x −v )N ),
ϕn n n m m m=0
with
I((x −v )N ) ∝ exp(−1(x−v)T Σ−1(x−v)).
m m m=0 2
This completes the proof.
(cid:50)
D Generic algorithms and proof of Propositions 1–13
In this section, we prove that the algorithms proposed in this work leave π invariant. To this
T
end, we first prove the validity of two generic algorithms.
• Generic auxiliary algorithm. The first generic algorithm includes auxiliary variables
u in the space and admits the ‘auxiliary-variable’ based algorithms: Particle-aMALA,
t
Particle-aGRAD, Particle-aPCNL as well as their smoothing-gradient (‘+’) and twisted
versions, as special cases. Its proof extends the auxiliary-variable interpretation of the
Particle-RWM algorithm which was given in Corenflos and Särkkä (2023).
• Generic marginal algorithm. The second generic algorithm integrates out the auxil-
iary variables and admits the ‘marginal’ algorithms from the main manuscript (Particle-
MALA, Particle-mGRAD, Particle-PCNL). Its proof relies on an argument previously
given in Finke et al. (2016).
40D.1 Generic auxiliary algorithm
Define an extended target distribution
T
π′ (x ,u ) := π (x )YN(u ;x +Φ (x ),E (x )), (32)
T 1:T 1:T T 1:T t t t 1:T t t−1:t
t=1
where, for any t ∈ [T], Φ : XT → X is a function satisfying
t

Φ (x ) =
ϕ T(x t−T:T), if t = T,
t 1:T ϕ t(x t−1:t)+ψ t(x t:t+1), otherwise,
and E (x ) ∈ RD×D is some positive-definite symmetric matrix. Additionally, let
t t−1:t
Q′(x ;u ) = M′(x |x ;u )G′(x ;u ),
t t−2:t 1:T t t t−1 1:T t t−2:t 1:T
for some mutation kernel M′(x |x ;u ) and some potential function G′(x ;u ) (both
t t t−1 1:T t t−2:t 1:T
of which may depend on some or all of u ,...,u ) such that
1 t
T
π′ (x |u ) ∝ Y Q′(x ;u ).
T 1:T 1:T t t−2:t 1:T
t=1
Algorithm 14 (generic auxiliary algorithm). Given x ∈ XT, sample
1:T
u ∼ N(x +Φ (x ),E (x )),
t t t 1:T t t−1:t
for any t = 1,...,T and then
1. for t = 1,...,T,
a) sample k
t
from a uniform distribution on [N]
0
and set x tkt := x t,
b) if t > 1, set ak t−t 1 := k t−1 and sample an t−1 = i w.p. W ti −1, for n ∈ [N] 0 \{k t},
c) sample xn ∼
M′(·|xan
t−1;u ) for n ∈ [N] \{k },
t t t−1 1:T 0 t
d) for n ∈ [N] , set wn ∝ G′(x(n) ;u ),
0 t t t−2:t 1:T
e) for n ∈ [N] , set Wn := wn/PN wm;
0 t t m=0 t
Wi 1−WkT
2. samplei ∈ [N] \{k }w.p. T ; setl := iw.p.1∧ T ; otherwise, setl := k ;
0 T 1−WkT T 1−Wi T T
T T
3. for t = T −1,...,1, sample l = i ∈ [N] w.p.
t 0
WiQ′ ((x(i) ,xlt+1);u )Q′ ((xi,xlt+1,xlt+2);u )
t t+1 t−1:t t+1 1:T t+2 t t+1 t+2 1:T ;
PN WnQ′ ((x(n) ,xlt+1);u )Q′ ((xn,xlt+1,xlt+2);u )
n=0 t t+1 t−1:t t+1 1:T t+2 t t+1 t+2 1:T
4. return x˜
1:T
:= (x 1l1,...,x tlT).
Proposition 14 (validity of the generic auxiliary algorithm). Sampling x˜ given x
1:T 1:T
via Algorithm 14 induces a Markov kernel P(x˜ |x ) which leaves π invariant.
1:T 1:T T
41Proof (of Proposition 14). Theextendeddistributionfrom(32)admitsπ (x )asamarginal.
T 1:T
Therefore, a valid MCMC update for sampling from this extended distribution is given by al-
ternating the following two steps. Given x ∈ XT,
1:T
1. sample u ∼ N(x +Φ (x ),E (x )), for t = 1,...,T;
t t t 1:T t t−1:t
2. run a standard CSMC algorithm with backward sampling (as in Algorithm 1) targeting
π′ (x |u )butwithM (x |x ),G (x ),andQ (x )replacedbyM′(x |x ;u ),
T 1:T 1:T t t t−1 t t−1:t t t−1:t t t t−1 1:T
G′(x ;u ) and Q′(x ;u ), and with appropriate adjustments (e.g., of the back-
t t−2:t 1:T t t−2:t 1:T
ward kernels) to account for the possibility that the model may only be second-order
Markov.
These to steps are equivalent to Algorithm 14.
(cid:50)
D.2 Generic marginal algorithm
Consider the same setting as above but now assume that for any t ∈ [T], ψ ≡ 0, so that
t
Φ (x ) = ϕ (x ) as well as that E (x ) = E is independent of x .
t 1:T t t−1:t t t−1:t t t−1:t
Furthermore, assume that M′(x |x ;u ) = M′(x |x ;u ) only depends on the tth aux-
t t t−1 1:T t t t−1 t
iliary variable u and, specifically, is a Gaussian distribution of the following form:
t
M′(x |x ;u ) := N(x ;v (x )+H u ,D ),
t t t−1 t t t t−1 t t t
where v (x) ∈ X whilst H ,D ∈ RD×D do not depend on x and define
t t t t−1
N
q−n(x−n,u |xn;H ) := N(u ;xn +ϕ (x(n) ),E )Y M′(xm|xam t−1;u ),
t t t t t−1 t t t t−1:t t t t t−1 t
m=0
m̸=n
where H is the history of the particle system up to time t−1, i.e., all particles and ancestor
t−1
indices with ‘time’ subscript s ≤ t−1. By Lemma 3 from Appendix C, we obtain a closed-form
expression for
Z
q−n(x−n|xn;H ) := q−n(x−n,u |xn;H )du .
t t t t−1 t t t t t−1 t
X
42Algorithm 15 (generic marginal algorithm). Given x ∈ XT:
1:T
1. for t = 1,...,T,
a) sample k
t
from a uniform distribution on [N]
0
and set x tkt := x t,
b) if t > 1, set ak t−t 1 := k t−1 and sample an t−1 = i w.p. W ti −1, for n ∈ [N] 0 \{k t},
c) sample x t−kt ∼ q t−kt(x t−kt|x tkt;H t−1)
(e.g. by sampling u ∼ N(x +ϕ (x ),E ) and then xn ∼
M′(·|xan
t−1;u ) for n ∈
t t t t−1:t t t t t−1 t
[N] \{k }),
0 t
d) for n ∈ [N] , set wn ∝ Q (x(n) )q−n(x−n|xn;H ),
0 t t t−1:t t t t t−1
e) for n ∈ [N] , set Wn := wn/PN wm;
0 t t m=0 t
Wi 1−WkT
2. samplei ∈ [N] \{k }w.p. T ; setl := iw.p.1∧ T ; otherwise, setl := k ;
0 T 1−WkT T 1−Wi T T
T T
WiQ (xi,xlt+1)
3. for t = T −1,...,1, sample l = i ∈ [N] w.p. t t+1 t t+1 ;
t 0 PN WnQ (xn,xlt+1)
n=0 t t+1 t t+1
4. return x˜
1:T
:= (x 1l1,...,x tlT).
Algorithm 15 can be implemented in O(N) operations because Lemma 3 from Appendix C
allows us to write the weight in Step 1d as
wn ∝ Q (x(n) )q−n(x−n|xn;H )
t t t−1:t t t t t−1
∝ Q (x(n) )H (xn,vn,x¯ ,v¯ ),
t t−1:t t,ϕt(x t( −n) 1:t) t t t t
where vn := v (xan t−1), x¯ := 1 PN xm, v¯ := 1 PN vm and
t t t−1 t N+1 m=0 t t N+1 m=0 t
logH (x,v,x¯,v¯) = 1(x−v)T(D−1 +G )(x−v)
t,ϕ 2 t t
− 1 N(x+ϕ)T HT(D−1 −NG )H (x+ϕ)
2 t t t t
−(N +1)(x¯ −v¯)T[G (x−v)−(D−1 −NG )H (x+ϕ)]
t t t t
−(x−v)T(D−1 −NG )H (x+ϕ),
t t t
with G := (D+NH E HT)−1H E HTD−1 (see (31) for an alternative expression).
t t t t t t t t
Proposition 15 (validity of the generic marginal algorithm). Sampling x˜ given x
1:T 1:T
via Algorithm 15 induces a Markov kernel P(x˜ |x ) which leaves π invariant.
1:T 1:T T
Proof (of Proposition 15). We begin with a few observations.
1. Since the unnormalised weights satisfy
wn ∝ Q (x(n) )q−n(x−n|xn;H ), (33)
t t t−1:t t t t t−1
we have that
wkt Q (x(lt) )
q t−kt(x t−kt|x tkt;H t−1) = wt
lt
Qt (xt (− kt1 ):t )q t−lt(x t−lt|x tlt;H t−1).
t t t−1:t
432. For a given set of final-time weights {Wn} , let R (·|·;H ) be the PN Wnδ -
T n∈[N] 0 T T n=0 T n
invariantMarkovkernelusedinStep2ofAlgorithm15. Thatis,samplingl ∼ R (·|k ;H )
T T T T
could be the forced-move update; or, in the more common specification of CSMC algo-
rithms (Andrieu et al., 2010), i.e. without the forced-move update, we would simply have
R (l |k ;H ) = WlT. In either case, it can then be verified that
T T T T T
WkTR (l |k ;H ) = WlTR (k |l ;H ),
T T T T T T T T T T
for any k ,l ∈ [N] .
T T 0
3. Under Algorithm 15, we have the following identities (with probability 1): x = xkt and
t t
x t′ = x tlt, for 1 ≤ t ≤ T, as well as ak t−t
1
= k t−1, for any 1 < t ≤ T.
Putting these observations together then shows that the Algorithm 15 targets the following
extended distribution (i.e., this is the distribution of all random variables obtained if we first
sampled x ∼ π and then ran Algorithm 15):
1:T T
(π NT( +x 1 1:T )T) δ x1:T(x 1k :1 T:T)" YT q t−kt(x t−kt|x tkt;H t−1)#" YT δ kt−1(ak t−t 1)YN W ta −n t− 11#
t=1 t=2 n=0
n̸=kt
×R (l |k ;H
)"T Y−1 w tltQ t+1(x tlt,x tlt ++ 11) #
δ (x˜ )
T T T T
t=1
PN m=0w tmQ t+1(x tm,x tlt ++ 11) x 1l1 :T:T 1:T
π (x˜ ) " T #
= (NT +1 1:T )Tδ x˜ 1:T(x 1l1 :: TT) Y q t−lt(x t−lt|x tlt;H t−1)
t=1
×" YT w ta −l tt − 11Q t(x ta −l tt − 11,x tlt+1) YN Wan t−1#
PN wm Q (xm ,xlt) t−1
t=2 m=0 t−1 t t−1 t n=0
n̸=lt
"T−1 #
×R (k |l ;H ) Y δ (k ) δ (x ),
T T T T akt t−1 xk1:T 1:T
t=1 t−1 1:T
where the r.h.s. is the distribution obtained if we first sampled x˜ ∼ π and then ran Al-
1:T T
gorithm 15 algorithm but with ancestor sampling (Lindsten et al., 2012) instead of backward
sampling. This is a modified version of the proof technique from Finke et al. (2016). In other
words, if x ∼ π and if x˜ is sampled via Algorithm 15, then x˜ ∼ π . This completes
1:T T 1:T 1:T T
the proof.
(cid:50)
D.3 Invariance of the algorithms
We can now easily verify the validity of the ‘auxiliary’ algorithms (Particle-aMALA, Particle-
aMALA+,Particle-aGRAD,Particle-aGRAD+,Particle-aPCNL,Particle-aPCNL+,andtwisted
Particle-aGRAD/Particle-aGRAD+/Particle-aPCNL/Particle-aPCNL+) by noting that these
arespecialcasesofAlgorithm14, andthevalidityofthe‘marginal’algorithms(Particle-MALA,
Particle-mGRAD, Particle-PCNL) by noting that these are special cases of Algorithm 15.
Proof (of Proposition 1). This follows by taking ϕ t(x t−1:t) := κδ 2t∇ xtlogQ t(x t−1:t), ψ
t
≡ 0,
M t′(x t|x t−1;u 1:T) = N(x t;u t, δ 2tI) and E
t
≡ δ 2tI in Proposition 14.
Proof (of Proposition 2). This follows from Proposition 15 with the same setting as i(cid:50)n
Proposition 1. In particular, in this case, v ≡ 0, H = I, D = E = δtI. Consequently,
t t t t 2
(33) then simplifies to (7), where we have used that G = [δt(N +1)]−1I = D−1 /(N +1) and
t 2 t
D−1 −NG = G .
t t t
(cid:50)
44Proof (of Proposition 3). This follows in the same way as the proof of Proposition 1 except
that now ψ t(x t:t+1) = κδ 2t∇ xtlogQ t+1(x t:t+1).
(cid:50)
Proof (of Proposition 4). This follows in the same way as the proof of Proposition 1 except
thatnowϕ t(x t−1:t) := κδ 2t∇ xtlogG t(x t−1:t),andM t′(x t|x t−1;u 1:T) = N(x t;m t′(x t−1,u t),C′ t(x t−1)),
where m′(x ,u ) and C′(x ) are defined in (10) and (11).
t t−1 t t t−1
(cid:50)
Proof (of Proposition 5). This follows from Proposition 15 with the same setting as in
Proposition 4. In particular, in this case, H = A := (C + 2 I)−1C , D = δtA and E = δtI.
Consequently, (33) then simplifies to
(14),t whert
e we
ht aveδtused tht
at
At is2 syt mmetrit
c,
th2
at
t
HTD−1 = D−1 H = 2 I and hence
t t t t δt
D−1 −NG = A−1 G = G A−1 .
t t t t t t
This completes the proof.
(cid:50)
Proof (of Proposition 6). This follows in the same way as the proof of Proposition 4 except
that now ψ t(x t:t+1) = κδ 2t∇ xtlogG t+1(x t:t+1).
(cid:50)
Proof (of Proposition 7). This follows in the same way as the proof of Propositions 4 and
6, respectively, but with M′(x |x ;u ) = N(x ;F′x +b′,C′).
t t t−1 1:T t t t−1 t t
(cid:50)
Proof (of Proposition 10). ThisfollowsinthesamewayastheproofofProposition1except
thatnowϕ t(x t−1:t) := κδ 2tCe t(x t−1)∇ xtlogG t(x t−1:t),E t(x t−1:t) := δ 2tC t(x t−1)andM t′(x t|x t−1;u 1:T) =
N(x ;m′(x ,u ),C′(x )), where m′(x ,u ) and C′(x ) are defined in (19) and (20).
t t t−1 t t t−1 t t−1 t t t−1
(cid:50)
Proof (of Proposition 11). This follows from Proposition 15 with the same setting as in
Proposition 10. In particular, in this case, H = β I, D = (1 − β )C and E = δtC .
t t t t t t 2 t
Consequently, (33) then simplifies to (22), where we have used that EHTD−1 = D−1 H E = I
t t t t
and hence
D−1 +G = (β−1 +N +1)G ,
t t t t
D−1 −NG = β−1 G .
t t t t
This completes the proof.
(cid:50)
Proof (of Proposition 12). This follows in the same way as the proof of Proposition 10
except that now ψ t(x t:t+1) = κδ 2tCe t(x t)∇ xtlogG t+1(x t:t+1).
(cid:50)
Proof (of Proposition 13). This follows in the same way as the proof of Propositions 10 and
12, respectively, but with M′(x |x ;u ) = N(x ;F′x +b′,C′).
t t t−1 1:T t t t−1 t t
(cid:50)
E Proof of Propositions 8 and 9
E.1 Preliminaries
For some given N ∈ N, let Ψn denote either the Boltzmann selection function (with the con-
vention h0 := 0):
exp(hn)
Ψn(h1:N) := ,
1+PN exp(hm)
m=0
45or the Rosenbluth–Teller selection function:
 exp(hn)
Ψn(h1:N) :=
1+PN m=1exp(hm)−1∧exp(hn), if n > 0,
N
1−XΨl(h1:N), if n = 0.
l=1
In either case, Ψn is Lipschitz continuous with constant denoted [Ψn] .
lip
E.2 Marginal MCMC kernels in the special case: T = 1
For the moment, we assume that T = 1. To simplify the notation, we drop the ‘time’ subscripts
t = 1. With this convention, for some bounded and differentiable G : RD → (0,∞), define
π(x) ∝ N(x;m,C)G(x).
The π-invariant Markov kernels induced by the (non-auxiliary variable based) algorithms dis-
cussed in this work can then be written as
N Z
P (dx˜|x) = X δ (dx0)q−0(dx−0 |x0)Ψl({hn(x0:N)}N )δ (dx˜),
a x a a n=1 xl
l=0 XN+2
where have appealed to symmetry to always place the reference ‘path’ in position 0, and with
hn(x0:N) := logq−n(x−n|xn)−logq−0(x−0 |x0),
a a a
q−n(x−n|xn) = N(x−n;m (xn),C ),
a a a
where m (xn) ∈ RND is a suitable mean vector (which may depend on xn ∈ RD), C ∈
a a
R(ND)×(ND) a suitable variance, and where we again slightly abuse notation to let x−n represent
both the tuple (x0,...,xn−1,xn+1,...,xN) and its vectorised form
 x0 
.
 . 
 . 
 
xn−1
x−n := vec(x−n) =   xn+1 

∈ RND.
 . 
 . 
 . 
 
xN
Additionally, ‘a’ is a placeholder for ‘CSMC’, ‘Particle-MALA’, or ‘Particle-mGRAD’. Specif-
ically, by the developments from Section C (Lemma 3 and its proof), and recalling that the
block matrix operator M was defined in (27),
N
m (xn) = 1 ⊗[m+A(xn +ϕ(xn)−m)],
Particle-mGRAD N×1
C = δM (A,A2) = δ[I ⊗A+1 ⊗A2],
Particle-mGRAD 2 N 2 N N×N
m (xn) = 1 ⊗m,
CSMC N×1
C = M (C,0 ) = I ⊗C,
CSMC N D×D N
m (xn) = 1 ⊗[xn +ϕ(xn)+φ(xn)],
Particle-MALA N×1
C = δM (I,I) = δ[I +1 ⊗I],
Particle-MALA 2 N 2 ND N×N
46where ϕ(x) := κδ∇logG(x) and φ(x) := κδ∇logM(x) and with A := (δC−1 + I)−1 =
2 2 2
C(C+ δI)−1 = (C+ δI)−1C.
2 2
Key to our proofs will be the following bound which follows from the triangle inequality and
a telescoping-sum decomposition (here: a and b are again placeholders which take values in
{CSMC,Particle-MALA,Particle-mGRAD}):
∥P (·|x)−P (·|x)∥
a b tv
≤
∥q−0(·|x)−q−0(·|x)∥
a b tv
N Z
+X δ (dx0)q−0(dx−0 |x0)|Ψl({hn(x0:N)}N )−Ψl({hn(x0:N)}N )|
x a a n=1 b n=1
l=0 XN+1
q
≤
KL(q−0(·|x)∥q−0(·|x))
a b
N Z N
+X[Ψl]
δ
(dx0)q−0(dx−0 |x0)X |hn(x0:N)−hn(x0:N)|
lip x a a b
l=0 XN+1 n=1
≤
C(cid:20)q
D0 (x)+
XN
Dn
(x)(cid:21)
. (34)
a,b a,b
n=0
Here, the penultimate line follows from Pinsker’s inequality and the Lipschitz continuity of the
selection function; C ≥ 0 is some constant which may depend on these Lipschitz constants and
N and D; for the last inequality, we have defined
Z
Dn (x) := δ (dx0)q−0(dx−0 |x0)|logq−n(x−n|xn)−logq−n(x−n|xn)|. (35)
a,b x a a b
XN+1
E.3 Proofs of Part 1
Proof (of Part 1 of Proposition 8). By Assumption A1, the model factorises over time
and so do the CSMC and Particle-mGRAD algorithms. Hence, without loss of generality, we
prove the result in the case that T = 1 (and we drop the ‘time’ subscript t = 1 hereafter).
Throughout the proof, we will also make repeated use of the fact that the eigenvalues of A
k
are given by (2λ )/(2λ +δ), for d ∈ [D].
k,d k,d
For ε ≥ 1 the result is trivially true but meaningless. Fix ε ∈ (0,1).
F :=
n
x ∈
RD(cid:12)
(cid:12)∥x−m∥ ≤
λ(1−ε)/2o
,
k (cid:12) 2 k
denote a ball of radius λ(1−ε)/2 around m, for any k ≥ 1. We then have π (F ) = (1+H )−1,
k k k k
where, letting Fc := X \F :
k k
R G(x)N(dx;m,C )
H := F kc k
k R G(x)N(dx;m,C )
F k
k
≤
sup
x∈X
G(x)R
F
kcN(dx;m,C k)
inf G(x)R N(dx;m,C )
x∈F k F k k
sup G(x)R N(dx;0,I)I{∥x∥ > λ−ε/2 }
≤ x∈X X 2 k
inf x∈F k G(x)R X N(dx;0,I)I{∥x∥ 2 ≤ λ− kε/2 }
→ 0,
as k → ∞, where we have used that G is bounded and that (inf G(x)) is an increasing
x∈F k≥1
k
sequence in (0,∞) (since (F ) is decreasing and F is compact).
k k≥1 1
47By the decomposition from (34), all that remains is to control the terms
sup Dn (x0),
CSMC,Particle-mGRAD,k
x0∈F
k
for arbitrary n ∈ [N] .
0
Firstly, by Lemma 1 from Appendix C, letting λ(C ) = {λ ,...,λ } denote the eigenval-
k k,1 k,D
ues of C and noting that A is simultaneously diagonalisable with A2:
k k k
|log(det(C ))−log(det(C ))|
CSMC,k Particle-mGRAD,k
(cid:12) D (cid:18) δλ (cid:19) δλ 2δNλ2 !(cid:12)
= (cid:12) (cid:12) (cid:12)X N logλ k,d −(N −1)log 2λ k +,d δ −log 2λ k +,d δ + (2λ +k, δd )2 (cid:12) (cid:12) (cid:12)
d=1 k,d k,d k,d
(cid:12) D (cid:18)2λ +δ(cid:19) (cid:18) δλ (cid:19) δλ 2δNλ2 !(cid:12)
= (cid:12) (cid:12)X N log k,d +log k,d −log k,d + k,d (cid:12) (cid:12)
(cid:12) δ 2λ +δ 2λ +δ (2λ +δ)2 (cid:12)
d=1 k,d k,d k,d
(cid:12) D (cid:18)2λ +δ(cid:19) (cid:18) 2λ +δ (cid:19)(cid:12)
= (cid:12) (cid:12) (cid:12)X N log k, δd +log
2λ
(Nk,d
+1)+δ
(cid:12) (cid:12)
(cid:12)
∈ O(λ k). (36)
d=1 k,d
Secondly, by Lemma 2 from Appendix C,
2
C−1 = M (A−1 ,−(I+NA )−1),
Particle-mGRAD,k δ N k k
and with the conventions that the sum symbol P is shorthand for P , that P is
i i∈[N] 0\{n} j
shorthand for P , that P is shorthand for P , and again writing ϕ(x) =
j∈[N] 0\{n} i̸=j j∈[N] 0\{n,i}
48κδ∇logG(x) we obtain:
2
(cid:12)
(cid:12)(x−n −m (xn))T C−1 (x−n −m (xn))
(cid:12) CSMC CSMC,k CSMC
(cid:12)
−(x−n −m (xn))T C−1 (x−n −m (xn))(cid:12)
Particle-mGRAD,k Particle-mGRAD,k Particle-mGRAD,k (cid:12)
(cid:12)
= (cid:12) (cid:12)X(xi −m)T C−1(xi −m)
(cid:12) k
i
2
− X(xi −ϕ(xn)−m)T A−1(xi −ϕ(xn)−m)
δ k
i
2 (cid:12)
+ XX(xi −ϕ(xn)−m)T(I+NA k)−1(xj −ϕ(xn)−m)(cid:12)
(cid:12)
δ (cid:12)
i j
(cid:12)2
= (cid:12)
(cid:12)
XX(xi −m)T(I+NA k)−1(xj −m)
(cid:12)δ
i j
2 (cid:18)δ (cid:19)
+ X(xi −m)T C−1 −A−1 (xi −m)
δ 2 k k
i
2 (cid:20) (cid:18)4(N −1) (cid:19) (cid:21)
+ X(xi −m)T I+ −1 (I+NA )−1 A (xn −ϕ(xn)−m)
k k
δ δ
i
(cid:20) (cid:18)2(N −1) (cid:19) (cid:21) (cid:12)
+N(xn −ϕ(xn)−m)T A k + −1 A k(I+NA k)−1 A k (xn −ϕ(xn)−m)(cid:12) (cid:12)
δ (cid:12)
2
≤ XX ∥xi −m∥ ∥xj −m∥ ∥(I+NA )−1 ∥
2 2 k 2,2
δ
i j
2 (cid:13)δ (cid:13)
+
δ
X
i
∥xi −m∥ 2∥xi −m∥ 2(cid:13) (cid:13) (cid:13)2C− k1 −A− k1(cid:13) (cid:13)
(cid:13)2,2
2 (cid:13) (cid:18)4(N −1) (cid:19) (cid:13)
+ X ∥xi −m∥ 2∥xn −ϕ(xn)−m∥ 2(cid:13) (cid:13)I+ −1 (I+NA k)−1 A k(cid:13) (cid:13)
δ
i
(cid:13) δ (cid:13)2,2
(cid:13) (cid:18)2(N −1) (cid:19) (cid:13)
+N∥xn −ϕ(xn)−m∥2 2(cid:13) (cid:13)A k + −1 A k(I+NA k)−1 A k(cid:13) (cid:13)
(cid:13) δ (cid:13)2,2
(cid:20)
≤ C XX ∥xi −m∥ ∥xj −m∥
2 2
i j
+(1+∥xn −m∥ )X ∥xi −m∥
2 2
i
(cid:21)
+λ (1+∥xn −m∥ )2 , (37)
k 2
for some constant C ≥ 0 which only depends on N, δ and m. Here, we have used that all
the matrices inside the operator norms are simultaneously diagonalisable with C (so that the
k
operator norms can be bounded above by some function of λ ):
k
∥(I+NA )−1 ∥ ≤ 1,
k 2,2
(cid:13)δ (cid:13)
(cid:13)
(cid:13)
C−1 −A−1(cid:13)
(cid:13)
= 1,
(cid:13)2 k k (cid:13)2,2
(cid:13) (cid:18)2(N −1) (cid:19) (cid:13) 2λ 2
(cid:13) (cid:13) (cid:13)A k + δ −1 A k(I+NA k)−1 A k(cid:13) (cid:13) (cid:13)2,2 ≤ C′ 2λ
k
+k δ ≤ C′ δλ k,
(cid:13) (cid:18)4(N −1) (cid:19) (cid:13)
(cid:13) (cid:13)I+ −1 (I+NA k)−1 A k(cid:13) (cid:13) ≤ C′′,
(cid:13) δ (cid:13)2,2
49for other constants C′,C′′ ≥ 0.
Furthermore, by definition of (F ) ,
k k≥1
sup∥x−m∥ ∈ O(λ(1−ε)/2).
2 k
x∈F
k
Consequently, for i,j ∈ [N] :
0
Z
sup N(dx−0;m ,C )∥xi −m∥ ∥xj −m∥
CSMC CSMC,k 2 2
x0∈F XN
k
O(λ(1−ε)), if i = j = 0,
∈
 O(λk
(2−ε)/2), if either i = 0 or j = 0, (38)
k
O(λ
), if neither i = 0 nor j = 0,
k
as λ → 0, and where the last two cases follow from the Cauchy–Schwarz inequality. Similarly,
k
for i ∈ [N] ,
0
Z  O(λ(1−ε)/2), if i = 0,
sup N(dx−0;m ,C )∥xi −m∥ ∈ k (39)
x0∈F
k
XN CSMC CSMC,k 2 O(λ k1/2), if i ̸= 0,
as λ → 0. Combining the bounds from (36)–(39) then shows that
k
sup Dn (x0) ∈ O(λ(1−ε)/2),
CSMC,Particle-mGRAD,k k
x0∈F
k
for any n ∈ [N] . Plugging these bounds into (34) completes the proof.
0
(cid:50)
Proof (of Part 1 of Proposition 9). By Assumption A1, the model factorises over time
and so do the Particle-MALA and Particle-mGRAD algorithms. Hence, without loss of gen-
erality, we again only prove the result in the case that T = 1 (and we again drop the ‘time’
subscript t = 1 hereafter).
For ε ≥ 1 the result is trivially true but meaningless. Fix ε ∈ (0,1). Since G is integrable
(by Assumption A3) and since π is invariant to scaling of G by a positive constant factor, we
k
assume that R G(x)dx = 1, without loss of generality, so that G can be viewed as a density
X
(and we will also use the symbol G to denote the corresponding distribution). Let m and C
G G
be mean and variance of G (which exist by Assumption A3) and define
F := n x ∈ X (cid:12) (cid:12)∥x−m∥ ∨q (x−m )TC−1(x−m ) < λε/2o .
k (cid:12) 2 G G G k
50We then have π (F ) = (1+H )−1, where, letting Y ∼ G and letting Fc := X \F :
k k k k k
R G(x)N(dx;m,C )
H := F kc k
k R G(x)N(dx;m,C )
F k
k
R G(x)dx
Fc
≤ k
inf exp(−1 ∥x−m∥2λ−1)R G(x)dx
x∈F k 2 2 k F k
R G(x)dx
≤
F kc exp(1 λε−1)
R G(x)dx 2 k
F
k
exp(1 λε−1)
= P(Y ∈ Fc) 2 k
k R G(x)dx
F
k
≤
P(cid:16)q
(Y−m )TC−1(Y−m ) ≥
λε/2(cid:17)exp(1 2λε k−1)
G G G k R G(x)dx
F
k
D
exp(1 λε−1)
≤ 2 k
λε R G(x)dx
k F
k
→ 0.
The penultimate line follows from the (multidimensional) Chebyshev’s inequality and the last
line uses that F → X as k → ∞.
k
By the decomposition from (34), all that remains is to control the terms
sup Dn (x0),
Particle-MALA,Particle-mGRAD,k
x0∈F
k
for arbitrary n ∈ [N]
0
Firstly, by Lemma 1 from Appendix C, letting λ(C ) = {λ ,...,λ } denote the eigenval-
k k,1 k,D
ues of C and noting that A is simultaneously diagonalisable with A2:
k k k
|log(det(C ))−log(det(C ))|
Particle-MALA Particle-mGRAD,k
(cid:12) D (cid:18)2λ +δ(cid:19) (cid:18) 2λ +δ (cid:19)(cid:12)
= (cid:12) (cid:12)X N log k,d +log k,d (cid:12) (cid:12) ∈ O(λ−1). (40)
(cid:12) 2λ 2λ +δ/(N +1) (cid:12) k
d=1 k,d k,d
Secondly, by Lemma 2 from Appendix C, and again with the conventions that P is shorthand
i
for P , that P is shorthand for P , that P is shorthand for P ,
i∈[N] 0\{n} j j∈[N] 0\{n} i̸=j j∈[N] 0\{n,i}
and writing ϕ(x) := κδ∇logG(x) as well as φ (x) := κδ∇logM (x) = κδC−1(m − x), so
2 k 2 k 2 k
that ϕ(x)+φ (x) = κδ∇logπ (x):
k 2 k
(cid:12)
(cid:12)(x−n −m (xn))T C−1 (x−n −m (xn)
(cid:12) Particle-MALA,k Particle-MALA Particle-MALA,k
(cid:12)
−(x−n −m (xn))T C−1 (x−n −m (xn))(cid:12)
Particle-mGRAD,k Particle-mGRAD,k Particle-mGRAD,k (cid:12)
(cid:20) N (cid:21)
≤ Cλ−1 XX ∥xi −m∥ ∥xj −m∥ +(1+∥xn −m∥ )X ∥xi −m∥ , (41)
k 2 2 2 2
i j i=0
for some constant C ≥ 0 which only depends on N, δ and m. Here, we have followed the same
steps as for (37) and used that all the matrices inside the operator norms are simultaneously
diagonalisable with C (so that the operator norms can be bounded above by some function of
k
λ−1).
k
51Furthermore, by definition of F , we have
k
sup∥x−m∥ ∈ O(λε/2),
2 k
x∈F
k
as λ → ∞. Consequently, for i,j ∈ [N] , by the Cauchy–Schwarz inequality:
k 0
Z
sup N(dx−0;m ,C )∥xi −m∥ ∥xj −m∥
Particle-MALA,k Particle-MALA 2 2
x0∈F XN
k
O(λε), if i = j = 0,
∈
 O(λεk
/2), if either i = 0 or j = 0, (42)
k
O(1),
if neither i = 0 nor j = 0,
as λ → ∞. Similarly, for i ∈ [N] ,
k 0
Z  O(λε/2), if i = 0,
sup N(dx−0;m ,C )∥xi −m∥ ∈ k (43)
x0∈F XN
Particle-MALA,k Particle-MALA 2
O(1), if i ̸= 0,
k
as λ → ∞. Combining the bounds from (40)–(43) then shows that
k
sup Dn (x0) ∈ O(λ−(1−ε)/2),
Particle-MALA,Particle-mGRAD,k k
x0∈F
k
for any n ∈ [N] . Plugging these bounds into (34) completes the proof.
0
(cid:50)
E.4 Auxiliary MCMC kernels in the special case: T = 1
The π-invariant Markov kernels induced by the auxiliary-variable based algorithms discussed
in this work can then be written as
N Z
P (dx˜|x) = X δ (dx0)q−0(dx−0 ×du|x−0 ,x0)Ψl({hn(x0:N,u)}N )δ (dx˜),
a x a a n=1 xl
l=0 XN+3
where have appealed to symmetry to always place the reference ‘path’ in position 0, where ‘a’
is now a placeholder for ‘Particle-aGRAD’, ‘Particle-aMALA’, or ‘CSMC’ and with
q−n(x−n,u|xn) = q−n(x−n|xn)q−n(u|x−n,xn),
a a a
hn(x0:N,u) := logq−n(x−n|xn)−logq−0(x−0 |x0)
a a a
+I{a ̸= CSMC}[logq−n(u|x−n,xn)−logq−0(u|x−0 ,x0)],
a a
q−n(x−n|xn) = N(x−n;m (xn),C ),
a a a
q−n(u|x−n,xn) = N(u;ν (x−n,xn),Υ ),
a a a
where again m (xn) ∈ RND and ν (x−n,xn) ∈ RD are suitable mean vector, and C ∈
a a a
R(ND)×(ND), Υ ∈ RD×D are suitable covariance variance matrices, and we again write x−n :=
a
vec(x−n). Specifically,
m (xn) = m (xn)
Particle-aGRAD Particle-mGRAD
C = C ,
Particle-aGRAD Particle-mGRAD
ν (x−n,xn) = (I+NA)−1[(N +1)x¯ +ϕ(xn)+N(A−I)m],
Particle-aGRAD
Υ = δ(I+NA)−1 ,
Particle-aGRAD 2
m (xn) = m (xn),
Particle-aMALA Particle-aMALA
C = C ,
Particle-MALA Particle-MALA
ν (x−n,xn) = x¯ + 1 ϕ(xn),
Particle-aMALA N+1
Υ = δ I,
Particle-aMALA 2(N+1)
52byPart2ofLemma3andLemma2fromAppendixC.Ofcourse, thestandardCSMCalgorithm
does not make use of the auxiliary variable u, so we extend the space to include u with
ν (x−n,xn) = ν (x−n,xn), (44)
CSMC Particle-aGRAD
Υ = Υ . (45)
CSMC Particle-aGRAD
Key to our proofs will be the following bound which follows by the triangle inequality
and a telescoping-sum decomposition (here: a is again a placeholder which takes values in
{CSMC,Particle-MALA} whilst we will always set b = Particle-aGRAD and q−m(·|x); and,
a
unless otherwise stated, q−m(·|x) denote the joint distributions on the space that includes the
b
auxiliary variable u):
∥P (·|x)−P (·|x)∥
a b tv
≤
∥q−0(·|x)−q−0(·|x)∥
a b tv
N Z
+X
δ
(dx0)q−0(dx−0 ×du|x0)
x a
l=0 X ×N |+ Ψ2 l({hn(x0:N,u)}N )−Ψl({hn(x0:N,u)}N )|
a n=1 b n=1
q
≤
KL(q−0(·|x)∥q−0(·|x))
a b
N Z N
+X[Ψl]
δ
(dx0)q−0(dx−0 ×du|x0)X |hn(x0:N,u)−hn(x0:N,u)|
lip x a a b
l=0 XN+2 n=1
≤
C(cid:20)q
D0 (x)+E0 (x)+
XN
Dn (x)+Een
(x)(cid:21)
.
a,b a,b a,b a,b
n=0
Here, the penultimate line follows from Pinsker’s inequality and the Lipschitz continuity of the
selection function; C ≥ 0 is some constant which may depend on these Lipschitz constants and
on N and D; Dn (x) is defined exactly as in the marginal case (35). Furthermore, we have
a,b
defined
Z
En (x) := δ (dx0)q−0(dx−0 ×du|x0)|logq−n(u|x−n,xn)−logq−n(u|x−n,xn)|. (46)
a,b x a a b
XN+1
Finally, if a ̸= CSMC and b ̸= CSMC, we we have defined
EePn article-aMALA,Particle-aGRAD(x) := E Pn article-aMALA,Particle-aGRAD(x),
whilst
EeCn SMC,Particle-aGRAD(x)
Z
:= δ (dx0)q−0 (dx−0 ×du|x0)
x CSMC
XN+2
×|logq−n (u|x−n,xn)−logq−0 (u|x−0 ,x0)|.
Particle-aGRAD Particle-aGRAD
E.5 Proofs of Part 2
Proof (of Part 2 of Proposition 8). Assume the same setting as in the proof of Part 1 of
Proposition 8 with the same definition of F .
k
Weproceedbycontrollingthetermsin(46). NotethatDn = Dn .
CSMC,Particle-aGRAD,k CSMC,Particle-mGRAD,k
Hence, by the arguments from the proof of Part 1 of Proposition 8,
sup Dn (x) ∈ O(λ(1−ε)/2).
CSMC,Particle-aGRAD,k k
x∈F
k
53Additionally, due to (44)–(45), En (x) = 0. Finally, using similar arguments as
CSMC,Particle-aGRAD
in the proofs for the ‘marginal’ algorithm, we can verify that
sup EeCn SMC,Particle-aGRAD,k(x) ∈ O(λ( k1−ε)/2).
x∈F
k
This completes the proof.
(cid:50)
Proof (of Part 2 of Proposition 9). Assume the same setting as in the proof ofPart 1 of
Proposition 9 with the same definition of F .
k
We proceed by controlling the terms in (46). Note that Dn =
Particle-aMALA,Particle-aGRAD,k
Dn . Hence, by the arguments from the proof Part 1 of Proposition 9,
Particle-MALA,Particle-mGRAD,k
sup Dn (x) ∈ O(λ−(1−ε)/2).
Particle-aMALA,Particle-aGRAD,k k
x∈F
k
Additionally, using similar arguments as in the proofs for the ‘marginal’ algorithm, we can
verify that
sup En (x) ∈ O(λ−(1−ε)).
Particle-aMALA,Particle-aGRAD,k k
x∈F
k
This completes the proof.
(cid:50)
F Step-size adaptation
All our algorithms involve the calibration of several step sizes δ , one for each time step. To
t
calibrate these, we implement a routine that recursively increases or decreases δ if the running
t
average of the acceptance rate α (i.e., the relative frequency with which x is updated) is
t t
respectively above or below a pre-specified target acceptance rate (in our experiments, we
picked this to be α∗ = 75%). The only exception to this lies in the twisted algorithms of
Section 4.4 which we calibrate using a single step-size δ (so that δ = δ = ... = δ ), and
1 T
for which the target relates to the overall acceptance rate averaged across time steps. The
reason for this difference stems from the fact that the twisting causes the acceptance rate at
time s additionally depend on future auxiliary variables u , and therefore the future step-size
t
parameters δ (for t > s), thereby making the behaviour per time-step harder to control. In
t
practice, our calibration of the twisted Particle-aGRAD is therefore more similar to that of
aGRAD than that of our other algorithms. The adaptation procedure is summarised in the
following algorithm.
54Algorithm 16 (step-size adaptation).
1. Initialise the trajectory x [0], the initial step sizes δ [0] (for t ∈ [T]), the initial learning
1:T t
rate ρ[0] = 1.
2
2. Initialise the history of accepted time steps A := (A ) ∈ {0,1}W×T, with 0 everywhere.
w,t
3. For k = 1,...,K,
a) samplex [k] ∼ P(·|x [k−1]), whereP denotestheMarkovkernelinducedbyone
1:T 1:T
of the algorithms discussed in this work with step sizes δ set equal to δ [k −1],
1:T 1:T
b) roll the array A by one: set A := A , and A = I{x [k] =
2:min{W,k},t 1:min{W−1,k−1},t 1,t t
x [k −1]}, for t ∈ [T],
t
c) compute α = 1 Pmin{W,k}A , for t ∈ [T],
t min{W,k} w=1 w,t
d) if |α −α∗| < σ then keep δ [k] = δ [k −1] unchanged;
t t t
otherwise, set
δ [k] := δ [k −1]+max{kγρ,ρ }(α −α)/α∗.
t t min t
In our experiments, we took σ = 5%, K = 10000, δ [0] = 10−2, W = 100, ρ = 1, ρ = 10−3,
t 2 min
γ = −1.
2
G Additional experimental results
In this section, we provide additional simulation results for the multivariate stochastic volatility
model experiments from Section 5.
G.1 Calibrated step sizes and acceptance rates
Recall that the step sizes δ were calibrated to achieve an acceptance rate of 75%. Here, the
t
‘acceptance rate’ at time t refers to the relative frequency with which the state x is updated.
t
The calibrated step sizes are shown in Figure 6; and the corresponding acceptance rates are
shown in Figure 7.
The results are averaged over the four chains and five simulated data sets. We do not report
CSMC as it does not require calibration. All methods consistently resulted in acceptance rates
close to the target 75%. Only the twisted Particle-aGRAD algorithm showed more instability
as the informativeness of the prior decreased: this is because, contrary to the methods, only
a single step-size is used for all time steps, so calibrating for the informativeness of individual
observations is not feasible. This seems to hint to the fact that the twisted Particle-aGRAD,
under our proposed calibration, is less robust than alternatives to heterogeneous levels of infor-
mativeness.
G.2 Breakdown of CSMC, aMALA and MALA
In this section, we illustrate the breakdown of CSMC, aMALA and MALA.
Firstly, Figure 8 illustrates that the estimates of the marginal posterior means of x (the
t,15
15th component of the state at time t) produced by CSMC, aMALA and MALA differ substan-
55τ =0.1 τ =0.5 τ =1 τ =2
1.00 Particle-RWM
Particle-aMALA
Particle-MALA
Particle-aMALA+
Particle-aGRAD
Particle-mGRAD
0.10
TwistedParticle-aGRAD
aMALA
MALA
aGRAD
Particle-aGRAD(κ=0)
0.01
Particle-mGRAD(κ=0)
TwistedParticle-aGRAD(κ=0)
0 50 100 0 50 100 0 50 100 0 50 100
Time, t
Figure 6: Adaptation of the step-size parameters δ , averaged across all four chains and all five
t
simulated data sets (per value of τ) in the multivariate stochastic volatility model.
τ =0.1 τ =0.5 τ =1 τ =2 CSMC
1.00
Particle-RWM
Particle-aMALA
Particle-MALA
0.75
Particle-aMALA+
Particle-aGRAD
Particle-mGRAD
0.50
TwistedParticle-aGRAD
aMALA
MALA
0.25
aGRAD
Particle-aGRAD(κ=0)
Particle-mGRAD(κ=0)
0.00
0 50 100 0 50 100 0 50 100 0 50 100 TwistedParticle-aGRAD(κ=0)
Time, t
Figure 7: Acceptance rates (i.e., relative frequencies with which states are updated), averaged
across all four chains and all five simulated data sets (per value of τ) in the multi-
variate stochastic volatility model.
56
δ
etar
ecnatpeccA
tτ =0.1 τ =0.5 τ =1 τ =2 CSMC
4
2 Particle-RWM
0
Particle-aMALA
-2
4 Particle-MALA
2
0 Particle-aMALA+
-2
Particle-aGRAD
5.0
2.5 Particle-mGRAD
0.0
TwistedParticle-aGRAD
-2.5
4 aMALA
2
0 MALA
-2
aGRAD
2 Particle-aGRAD(κ=0)
0
-2 Particle-mGRAD(κ=0)
0 50 100 0 50 100 0 50 100 0 50 100 TwistedParticle-aGRAD(κ=0)
Time, t
Figure 8: Estimated posterior mean of x minus the estimated posterior mean of x under
t,15 t,15
the aGRAD algorithm, averaged across all four chains for each of the five simulated
data sets (per value of τ) in the multivariate stochastic volatility model. The figure
shows that the estimated posterior means of CSMC, aMALA and MALA differ sub-
stantially from those of all the other algorithms.
tially from those produced by all the other algorithms. We emphasise that the 15th component
was arbitrarily chosen as an example and is representative of the other components.
Secondly, Figure 9 illustrates that the energy traces of CSMC, aMALA and MALA differ
substantiallyfromthoseofalltheotheralgorithms. Here,theenergyisdefinedaslogπ (x [i]),
T 1:T
where x [i] is the sample from the ith iteration after burn-in. Such energy traces serve as a
1:T
visual illustration of both stationarity and mixing speed: if the energy trace of a sampler differs
too much from the others, or is not consistent across the independent Markov chains we used,
the sampler is unlikely to perform correctly.
G.3 Effective sample sizes
In this section, in Figures 10–12 report the minimum, median and maximum ESS and ESS per
second (averaged across all four chains and all five simulated data sets) individually for each
time step t = 1,...,T.
G.4 Autocorrelation
Figure 13 shows the autocorrelation (corrected using Vehtari et al., 2021) of the energy from
Figure 9. This serves as a visual confirmation of the statistical performance of the differ-
ent algorithms considered under several prior dispersion regimes: as expected, the twisted
Particle-aGRAD dominates all other alternatives, while Particle-aMALA+ dominates other al-
ternatives, including aGRAD as soon as the prior variance is large enough, followed by Particle-
aGRAD/Particle-aGRAD, and then by Particle-aMALA/Particle-MALA, with Particle-RWM
being the least efficient.
57
x
fo
naem
eht
ni
ecnereffiD
51,t
Data1
Data2
Data3
Data4
Data5τ =0.1 τ =0.5 τ =1 τ =2 CSMC
0
Particle-RWM
-5000
-10000 Particle-aMALA
0 Particle-MALA
-5000 Particle-aMALA+
-10000
Particle-aGRAD
0
Particle-mGRAD
-5000
-10000 TwistedParticle-aGRAD
0 aMALA
-5000 MALA
-10000
aGRAD
0
Particle-aGRAD(κ=0)
-5000
-10000 Particle-mGRAD(κ=0)
0 20 40 0 20 40 0 20 40 0 20 40 TwistedParticle-aGRAD(κ=0)
Iteration (after burn-in) [ 1000]
×
Figure 9: Energy (i.e., logπ (x [i])+const, where x [i] is the sample from the ith iteration
T 1:T 1:T
after burn-in) minus the energy under the aGRAD algorithm, averaged across all
four chains for each of the five simulated data sets (per value of τ) in the multivariate
stochasticvolatilitymodel. ThefigureshowsthattheenergytracesofCSMC,aMALA
and MALA differ substantially from those of all the other algorithms.
τ =0.1 τ =0.5 τ =1 τ =2
3000
Particle-RWM
1000
Particle-aMALA
300
Particle-MALA
100
Particle-aMALA+
30 Particle-aGRAD
Particle-mGRAD
TwistedParticle-aGRAD
1.00
aGRAD
Particle-aGRAD(κ=0)
0.10
Particle-mGRAD(κ=0)
TwistedParticle-aGRAD(κ=0)
0.01
0 50 100 0 50 100 0 50 100 0 50 100
Time, t
Figure 10: Minimum ESS and ESS per second averaged across all four chains and all five sim-
ulated data sets (per value of τ) in the multivariate stochastic volatility model.
58
ygrene
ni
ecnereffiD
SSE
muminiM
Data1
Data2
Data3
Data4
Data5
Unnormalised
Persecondτ =0.1 τ =0.5 τ =1 τ =2
3000
Particle-RWM
1000 Particle-aMALA
Particle-MALA
300
Particle-aMALA+
100
Particle-aGRAD
30 Particle-mGRAD
3.00
TwistedParticle-aGRAD
1.00
aGRAD
0.30 Particle-aGRAD(κ=0)
0.10 Particle-mGRAD(κ=0)
TwistedParticle-aGRAD(κ=0)
0.03
0 50 100 0 50 100 0 50 100 0 50 100
Time, t
Figure 11: Medium ESS and ESS per second averaged across all four chains and all five simu-
lated data sets (per value of τ) in the multivariate stochastic volatility model.
τ =0.1 τ =0.5 τ =1 τ =2
10000
Particle-RWM
Particle-aMALA
1000
Particle-MALA
Particle-aMALA+
100 Particle-aGRAD
Particle-mGRAD
10.0
TwistedParticle-aGRAD
aGRAD
1.0
Particle-aGRAD(κ=0)
Particle-mGRAD(κ=0)
0.1
TwistedParticle-aGRAD(κ=0)
0 50 100 0 50 100 0 50 100 0 50 100
Time, t
Figure 12: Maximum ESS and ESS per second averaged across all four chains and all five
simulated data sets (per value of τ) in the multivariate stochastic volatility model.
59
SSE
naideM
SSE
mumixaM
Unnormalised
Persecond
Unnormalised
Persecondτ =0.1 τ =0.5 τ =1 τ =2
1.00
Particle-RWM
Particle-aMALA
0.75 Particle-MALA
Particle-aMALA+
Particle-aGRAD
0.50 Particle-mGRAD
TwistedParticle-aGRAD
aGRAD
0.25 Particle-aGRAD(κ=0)
Particle-mGRAD(κ=0)
TwistedParticle-aGRAD(κ=0)
0.00
0 100 200 0 100 200 0 100 200 0 100 200
Lag
Figure 13: Autocorrelation of the energy from Figure 9 in the multivariate stochastic volatility
model.
60
noitalerrocotua
ygrenE