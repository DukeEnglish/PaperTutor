ON THE GENERALIZATION CAPACITY OF NEURAL NET-
WORKS DURING GENERIC MULTIMODAL REASONING
TakuyaIto,SohamDan,MattiaRigotti,JamesKozloski,&MurrayCampbell
T.J.WatsonResearchCenter,IBMResearch
{takuya.ito,soham.dan}@ibm.com,mrg@zurich.ibm.com
{kozloski,mcam}@us.ibm.com
ABSTRACT
TheadventoftheTransformerhasledtothedevelopmentoflargelanguagemod-
els (LLM), which appear to demonstrate human-like capabilities. To assess the
generality of this class of models and a variety of other base neural network ar-
chitecturestomultimodaldomains,weevaluatedandcomparedtheircapacityfor
multimodal generalization. We introduce a multimodal question-answer bench-
marktoevaluatethreespecifictypesofout-of-distribution(OOD)generalization
performance: distractorgeneralization(generalizationinthepresenceofdistrac-
tors), systematic compositional generalization (generalization to new task per-
mutations), and productive compositional generalization (generalization to more
complextasksstructures). Wefoundthatacrossmodelarchitectures(e.g.,RNNs,
Transformers, Perceivers, etc.), models with multiple attention layers, or mod-
elsthatleveragedcross-attentionmechanismsbetweeninputdomains, faredbet-
ter. Ourpositiveresultsdemonstratethatformultimodaldistractorandsystematic
generalization, either cross-modal attention or models with deeper attention lay-
ersarekeyarchitecturalfeaturesrequiredtointegratemultimodalinputs. Onthe
otherhand,neitherofthesearchitecturalfeaturesledtoproductivegeneralization,
suggesting fundamental limitations of existing architectures for specific types of
multimodal generalization. These results demonstrate the strengths and limita-
tions of specific architectural components underlying modern neural models for
multimodalreasoning. Finally,weprovideGenericCOG(gCOG),aconfigurable
benchmarkwithseveralmultimodalgeneralizationsplits,forfuturestudiestoex-
plore.
1 INTRODUCTION
RecentLLMsappeartoexhibitremarkablecognitiveabilities.Onthesurface,thesemodelsperform
exceptionally well on cognitive tasks, such as language comprehension, mathematical reasoning,
and coding (Bubeck et al., 2023; Webb et al., 2023). However, many of these demonstrations are
limitedtoasinglemodality(e.g.,language).Moreover,themechanismsdrivingperformanceamong
these models are opaque. Even when both the model and dataset are publicly available, the sheer
scale of the model and training data make it difficult to isolate which architectural mechanisms
influencegeneralizationbehavior,inpartduetothedifficultyincontrollingforconfoundingfactors
inlargepretrainingdatasets(Kimetal.,2022).Toquantifytherelationshipbetweenmechanismand
generalization on multimodal cognitive tasks, we sought to evaluate a set of base neural network
architectures(RNN,GRU,Transformer,Perceiver)onacarefullycontrolledmultimodaltask.
RecentstudieshavesuggestedthattheimpressivebehaviorsexhibitedbyLLMsareduetosuperficial
data interpolation, rather than “emergent cognition” (Schaeffer et al., 2023; Kim et al., 2022; Wu
etal.,2023). Oneapproachtoadjudicatebetweenpossibilitiesistofirstcuratecarefullycontrolled
training and test sets generated from compositional task experiments (Keysers et al., 2020; Dziri
etal.,2023;Bahdanauetal.,2020;Ontan˜o´netal.,2022;Csorda´setal.,2022;Hupkesetal.,2020;
Lake&Baroni,2018;Yangetal.,2018;Kimetal.,2022). Bydesign, compositionaltasksenable
experimenters to measure OOD generalization – the ability to perform tasks beyond the training
distribution–byprogrammaticallycomposingatestsetusingnoveltaskcomponents. Indeed,when
controllingforconfoundingfactorsinatrainingset,studieshaveshownthatneuralmodelscannot
1
4202
naJ
62
]GL.sc[
1v03051.1042:viXrageneralize OOD (Kim et al., 2022; Dziri et al., 2023). However, most prior demonstrations have
beenlimitedtoevaluatingtaskswithinasinglemodality(e.g.,naturallanguage). Thus,itremains
uncleartowhatextentpreviousunimodalmodelsgeneralizetomultimodalreasoningtasks.
Given recent studies demonstrating that pretraining can actually degrade downstream systematic
generalization (Kim et al., 2022), and that OOD generalization performance can inversely scale
with model size (McKenzie et al., 2023), we focused on training models from scratch rather than
fine-tuning large pretrained models. This ensured full experimental control over training data and
architecturalchoices.WeintroduceGenericCOG(gCOG),ataskabstractedfromthepreviousCOG
task (Yang et al., 2018). Our variant employs generic feature sets that are not tied to any specific
modality,andrelaxespreviousexperimentalconstraintstobroadenitscapacitytotestcompositional
generalization splits (Fig. 1). This design allowed us to comprehensively evaluate a variety of
modelarchitecturesontasksthattestforthreedifferentformsofOODgeneralization: 1)Distractor
generalization(generalizationinthepresenceofadifferentnoisedistribution),2)Systematiccom-
positionalgeneralization(generalizationtonewpermutationsoftaskstructures,i.e.,combinatorial
generalization),and3)Productivecompositionalgeneralization(generalizationtotaskstructuresof
greatercomplexity). Wefindthatmodelsthatintegratemultimodalinputswitheitherdeeperatten-
tionlayersorcross-attentionmechanisms(suchasPerceiver-likemodels)performedbest,andwere
capableofexcellentdistractorgeneralization,reasonablygoodsystematiccompositionalgeneraliza-
tion,yet(aswithallmodelstested)noproductivecompositionalgeneralization.Ourresultsillustrate
thesuccessesandfundamentallimitationsofmodernneuralarchitectures’nascentmultimodalrea-
soningabilities,andweprovideaconfigurablemultimodalreasoningbenchmarkforfuturestudies
tobuildupon.
A Task Operators
Get Get Get Sum Sum Product Product
Exist
Location Shape Color Even Odd Even Odd
B C
Example task, depth 3
Example task, depth 1 Stimulus, 5 distractors Stimulus, 30 distractors
Instruction
Exist
pink “t”
Instruction
Exist
orange “t” If-Then-Else
then else
Get Location Get Shape
blue “z” green object
If a pink “t” exists
Does an orange “t” exist? Answer: “True” Then get the location of the blue “z”. Answer: Location:
Else, get the shape of the green object. (8,8)
Figure1: gCOGtask. Weadaptedthepreviously-developedCOGtask(Yangetal.,2018). Ourmodifications
toCOGincludeddifferenttaskoperators,theabilitytousecategoricaltokenstoallowforgenerictestingof
multimodalreasoning,andtheabilitytoallowforarbitrarilylongtaskinstructionstoallowfortheevaluation
ofcompositionalproductivity. A)TaskoperatorsandobjectsserveasthecoreunitsofthegCOGtask. Atask
operator(e.g.,“Exist”)ispairedwithaspecificfeaturecombination(e.g.,orange+“t”). Inourinterpretation,
featurecategoriescorrespondtoshape(i.e.,letters“a”through“z”)andcolor(i.e.,10discretelycodedcolors).
B) At minimum, a task must comprise of one specific task operator (e.g., Exist) and a feature combination
(e.g., orange“t”). Anarbitrarynumberofstimuli(e.g., images)canbeconstructedon-the-flytosatisfythis
task instruction (i.e., produce a TRUE or FALSE response). C) Tasks can be combined with a conditional
operator(e.g.,anIF-THEN-ELSEconditional)toincreasethetaskcomplexity. Thisenablestheconstruction
ofarbitrarilycomplextasks. WhiletheoriginalCOGtaskexploredonlytasktreesofdepth3(i.e., asingle
conditional),werelaxedthisconstrainttoallowforarbitrarilylongtasktrees.
1.1 RELATEDWORK
A number of recent studies have evaluated the compositional generalization properties of LLMs,
documenting several of their generalization shortcomings (Dziri et al., 2023; Keysers et al., 2020;
Kim et al., 2022; Wu et al., 2023). However, evaluations were limited to massive pretrained lan-
2guage models, making it difficult (if not impossible) to assess the interplay between training data,
architecture,andgeneralization,asnotedbyKimetal.(2022). Smallerscalestudiesdemonstrated
thelimitationsofmodernneuralnetworkarchitectures(e.g.,Transformers,RNNs)oncompositional
tasks, buthavebeenfocusedprimarilyonasinglemodality(e.g., language)(Csorda´setal.,2022;
Ontan˜o´n et al., 2022; Hupkes et al., 2020; Lake & Baroni, 2018; Andreas, 2019; Bahdanau et al.,
2019; Furrer et al., 2021). Other neural models trained on multimodal question-answer datasets
likeCLEVR(Johnsonetal.,2017)alsofailedtogeneralizesystematicallywhenpropertrainingand
testsplitswerecurated(e.g., CLOSURE)(Bahdanauetal.,2020). Relatedhybridneuro-symbolic
approaches have demonstrated great success at compositional generalization tasks (Klinger et al.,
2023;Nyeetal.,2020;Bahdanauetal.,2019;Shawetal.,2021),althoughtheseapproachesrequire
customizedsymbolicarchitectures,possiblyrenderingthemdifficulttoscale. Extendingthesestud-
ies,ouraimistoevaluatetheperformanceofbaseneuralmodelsongenericmultimodalreasoning.
OurapproachtoconstructingarbitrarilycomplexcompositionsofsimpletasksissimilartogSCAN
(Ruis et al., 2020). However, it differs in three key ways. First, we focus on question-answer
tasks (which require encoder-only architectures), rather than sequence-to-sequence learning tasks
(which require decoder architectures, e.g., Qiu et al. (2021)). Sequence decoding tasks introduce
the added complexity of requiring autoregressive responses, which are susceptible to fundamental
statistical challenges, such as exposure bias (Wang & Sennrich, 2020). Second, gCOG includes a
distractorgeneralizationsplit,inadditiontosystematicandproductivecompositionalgeneralization
splits. Finally,wemethodicallycharacterizedifferentformsofgeneralizationusingsimplerunder-
lying abstractions (i.e., without the explicit use of image pixels). Indeed, the experimental design
ismostsimilartotheoriginalCOG(Yangetal.,2018),SQOOP(Bahdanauetal.,2019)andCLO-
SURE(Bahdanauetal.,2020)inthatitismultimodalandcangeneratesynthetictrialson-the-fly.
However,thoseprevioustasksdidnotincludeproductivecompositionalgeneralizationbenchmarks
(i.e., evaluation of arbitrarily complex task commands), systematic compositional generalization
benchmarksondeepertasktrees(e.g.,tasktreesofdepth3),andexplicitsplitsforOODdistractor
generalization. IngCOG,weuniquelydesignedsplitsthattargetthesethreedistinctformsofOOD
generalization. gCOG therefore provides a scalable design (e.g., more than two modalities can be
straightforwardlyaccommodated)tobroadlyevaluatemultimodalgeneralization(Fig. 1).
1.2 CONTRIBUTIONS
SpecificcontributionscenteraroundtheconfigurabilityandflexibilityofgCOGforthreeformsof
OOD generalization, as well as the comprehensive evaluation of a variety of base neural network
architectures. Wehighlightthreeprincipalcontributionsofthisstudy:
1. A configurable dataset that complements and extends prior tasks (i.e., gSCAN, SQOOP,
COG)onmultimodalcompositionalgeneralizationtoincludeproductivitysplits, system-
aticitysplitsondeepertasktrees,andOODdistractorgeneralizationsplits.
2. Acomprehensiveevaluationofcommonly-usedbaseneuralmodels(RNNs,GRUs,Trans-
formers,Perceivers)ondistractor,systematic,andproductivegeneralizationsplits.Wefind
that for distractor and systematic generalization, including a cross-attention mechanism
acrossinputmodalitiesisimportant. However,allmodelsfailontheproductivitysplit.
3. A comprehensive evaluation of how scaling standard encoder-only Transformer models
improvesdistractorandsystematicgeneralization,butnotproductivegeneralization.
Finally,weincludeanalysisofinternalmodelrepresentationsinAppendixA.1,revealingtheinflu-
enceofbaseneuralarchitectureoninternalmodelrepresentations.
2 EXPERIMENTAL DESIGN
2.1 GCOGFORMULTIMODALANDCOMPOSITIONALEVALUATION
gCOGisaconfigurablequestion-answerdataset,originallyinspiredfromCOG(Yangetal.,2018),
that programmatically composes task instructions, and then generates synthetic stimuli to satisfy
thoseinstructionson-the-fly(Fig. 1). TheprimarymodificationsingCOGare1)differencesinthe
set of task operators, 2) the ability to use categorical tokens to allow for generic testing of multi-
3modalreasoning,and3)theabilitytoallowforarbitrarilylongtasktreestoassessproductivecom-
positionalgeneralization,inadditiontodistractorandsystematicgeneralization(e.g.,seeAppendix
Fig. 8). Importantly, theoriginalCOGtaskdidnotallowfortaskswithmorethanasinglecondi-
tionalstatement,e.g.,atasktreeofdepth3,makingitdifficiulttoevaluateproductivecompositional
generalization. The use of categorical stimulus tokens and instruction tokens generically tests the
capacityofneuralarchitecturestomaintain,manipulate,andgeneralizenovelcompositions. Impor-
tantly,ifmodelsareunabletogeneralizeusingsimplecategoricalencodings,thenitisunlikelythat
thesemodelswillgeneralizewhenpresentedwiththesametaskinamodality-specificdomain. The
totalnumberofuniqueindividualtasks(i.e., tasktreesofdepth1)is8operators∗26shapes∗10
colors=2080uniqueindividualtaskcommands,butcanbestraightforwardlyextendedwithmodi-
ficationstotheconfigurationfile. Thenumberoftotaluniquetaskstructuresexplodesexponentially
when task trees exceed depth 1 (e.g., 5,624,320,000 unique task structures for task trees of depth
3). Weadditionallyprovidefunctionalityinthedatasetthatallowsthechoicetogeneratesamples
using either categorical task encodings, or task encodings with image pixels and natural language
instructions. (Allevaluationsperformedinthispaperareusingcategoricaltaskencodings.)
The original COG dataset formulated tasks as directed acyclic graphs (DAGs). To simplify this
representation (andto ensurea unique, topologically sortedsolution of operators), we constrained
taskstobinarytrees. Unlessotherwisestated, stimuliweremappedfroma10x10spatialgridtoa
sequence of 100 binary tokens, where each token represented a specific location in the grid. If a
location contained an object, the embedding was encoded as the specific attributes of that object.
AlltaskruletokenswereappendedwithanEOSstatement,whichwaspreviouslydemonstratedto
improvegeneralization(Csorda´setal.,2022). (SeeAppendixforadditionaldetailsonexperimental
designA.2,andhowthetaskinputswereconfiguredformodeltrainingandinferenceA.3.)
2.2 MODELARCHITECTURES
Weevaluatedperformanceofsixencoder-onlymodelarchitectures(Fig.2).Allmodelsweretrained
toperformclassificationinasupervisedmanner. Outputswereprojectedtoavectorwith138ele-
ments,witheachelementinthevectorrepresentingaTrue/Falsebooleanorafeaturelabel(e.g.,the
color“Red”,letter“a”,orthespatiallocation(2,1)). ModelsthatincludedaTransformercompo-
nent in the main figures used absolute positional encoding (Vaswani et al., 2017), though we also
reportresultsintheAppendixwithTransformersthatusedrelativepositionalencoding(Shawetal.,
2018; Huang et al., 2018) (Appendix Fig. 9 and Fig. 10). Importantly, there were no discernible
differencesbetweenthesechoicesofpositionalencoding. Finally,wereportadditionalevaluations
ondeeperandlargerSSTfmrmodels(i.e.,BERT-stylemodels)inFig. 6forallgeneralizationsplits.
Thoseresultsdemonstratethatimproveddistractorandsystematicgeneralizationperformancecan
beachievedbyscalingmodels(i.e.,increasingencoderdepthandattentionheads),butnotproduc-
tivecompositionalgeneralization.
RNNs and GRUs. We trained both RNNs and GRUs with 512 units on gCOG (Fig. 2a). Task
trees(i.e.,instructions)werepresentedasasequenceoftokenembeddings,oneforeachnodeinthe
binary tree. The end of the rule sequence was marked with an EOS token. Stimuli were flattened
froma10×10×D matrixtoa100×D matrix(whereD istheembeddingdimension,andwere
presentedsimultaneously(i.e.,nottokenized).
Single stream Transformer (SSTfmr). We trained a single stream Transformer, where the task
instructions and stimuli were concatenated into a single matrix (with zero-padding), then passed
througha sharedEncoderblock(Vaswani etal.,2017)(Fig. 2b). Thus, intheTransformer block,
self-attentionwasappliedonbothruleandstimulusembeddingssimultaneously. Theoutputofthe
Transformerwasthenprocessedthrougha2-layerMLPbeforeprojectiontotheoutputlayer.
Dual stream Transformer (DSTfmr). We used a Transformer-based model to process task in-
structions and stimuli separately through modality-specific parallel Transformer blocks (Fig. 2c).
OutputsfromtheTransformersweresubsequentlyprocessedthroughasharedMLP.
TransformerswithCrossAttention(CrossAttn).LiketheDSTfmr,thisTransformer-basedmodel
processed task instructions and stimuli separately through modality-specific Transformers. How-
ever,theoutputsoftheparallelTransformerswereintegratedthroughacross-attentionmechanism
(Fig. 2d). Specifically, cross-attention was estimated by computing the query from the output of
4A RNN / GRU B Single Stream Transformer C Dual Stream Transformer
Task vector Stimulus vector Task vector Stimulus vector Task vector Stimulus vector
Transformer Transformer Transformer
512 Encoder Block Encoder Block Encoder Block
units
MLP MLP MLP
Output vector Output vector LayerNorm + MLP
D E
Transformers with Cross Attn Perceiver
Output vector
Task vector Stimulus vector Task vector Stimulus vector
F
Transformer Transformer Transformer Transformer
Encoder Block Encoder Block Encoder Block Encoder Block
Query Key Value Key Value Key Value
Query Query
Latent Transformer
CrossAttn+
LayerNorm
Latent Transformer
MLP
Output vector
Output vector
Figure2: Modelarchitectures. Weevaluatedgeneralizationacrosssixbaseneuralnetworkarchitectures. A)
RNNsandGRUswith512hiddenunits. B)SingleStreamTransformer(SSTfmr),whichprocessestaskrules
andstimuliinasingleTransformer,applyingself-attentionintheTransformerblock. C)DualStreamTrans-
former(DSTfmr). IncontrasttotheSSTfmr,twoparallelTransformerblocksprocessruleandimagetokens
separately,andthenprocessthemtogetherinasharedMLP.D)Transformerswithcross-attention(CrossAttn).
TheoutputsoftwoparallelTransformerblocksareprocessedwithacross-attentionmechanism,wheretheout-
putofthetaskruleTransformerproducesaquery,andthenthestimulusTransformerblockproducesakeyand
valuematrix.E)APerceiver-likearchitecture,whichintegratesbothtaskandstimulusoutputinformationina
latentTransformerthroughcross-attention(Jaegleetal.,2021).F)Thenumberofparametersforeachmodel.
the task rule Transformer, and the key and value matrix computed from the stimulus Transformer
output. Thecross-attentionoutputwasprocessedthroughaLayerNorm,andthenanMLP.
Perceiver-likearchitecture(Perceiver). Finally,weincludedaPerceiver-likemodel(Jaegleetal.,
2021), anarchitecturedesignedtogenericallyprocessmultimodalinputs(Fig. 2e). ThePerceiver
architecturecontainedalatentTransformer,whichusescross-attentiontoprocessinformationfrom
inputmodalities. Specifically,thelatentTransformerproducesaqueryforeachmodality. Theout-
puts of each modality-specific Transformer produced keys and values, which were subsequently
processed through cross-attention with the latent Transformer. The latent Transformer also con-
tainedastandardself-attentionTransformerblock,followedbyanMLP.
3 RESULTS
3.1 DISTRACTORGENERALIZATION
Experimentalsetup.Distractorgeneralizationevaluatesthedegreetowhichamodelcangeneralize
atasktoastimulusorenvironmentwithmoredistractorsthanitwastrainedon. Forexample,good
distractorgeneralizationrequiresthatamodelcancorrectlydiscernifa“reda”exists,independent
of the number or configuration of distractors presented. We evaluated distractor generalization on
an independent and identically distributed (IID) split and an OOD split. The IID split tests for
generalizationtostimuliwiththesamenumberofdistractorsthatthemodelwastrainedon,butwith
a different configuration. The OOD split evaluates generalization to stimuli with more distractors
thanobservedduringtraining. Modelsweretrainedonindividualtaskoperatorsforsimplicity(i.e.,
tasktreesofdepth1). Stimuliinthetrainingsetwererandomlygeneratedwithaminimumofone
5distractorandamaximumoffivedistractors. Modelsweretrainedonthesamenumberoftraining
steps(AppendixA.3). Allmodelsconvergedtogreaterthan94%trainingsetaccuracy(Fig. 3a-c).
A Train set (up to 5 distractors) Test set (10, 20, 30, 40 distractors) B
5 distractors 20 distractors 40 distractors
generalize
C D E
Figure3:Distractorgeneralization.A)Experimentalevaluationfordistractorgeneralization.Wetrainedmod-
elsonindividualtaskoperators(e.g.,“Existredd”)onstimulithatincluded1to5distractors,andthenevalu-
atedOODgeneralizationperformanceonstimuliwith10,20,30,and40distractors. B)LossandC)accuracy
trajectoriesduringtrainingforallmodels. Allmodelsconvergedtogreaterthan94%accuracy. D)Distrac-
torgeneralizationperformanceforeachmodel. WeassessedIIDdistractorgeneralization(novelstimuli,but
with1or5distractors),andOODdistractorgeneralization(10,20,30,or40distractors). Formostmodels,
performancereducedasthenumberofdistractorsincreased. E)WedirectlycomparedIIDvs. OODdistrac-
torgeneralizationbyaveragingperformanceforIIDandOODsplits. Modelsincorporatingacross-attention
mechanism–CrossAttnandPerceiver–clearlyexhibitedthebestperformance.
Generalizationperformance.WhileallbasemodelsperformedIIDgeneralizationwell,onlymod-
elsthatcontainedcross-attentionmechanisms(CrossAttnandPerceivermodels)exhibitedexcellent
OOD distractor generalization (Fig. 3e). A related result was also reported in Qiu et al. (2021)
usingcross-modalself-attention. ThoughtheGRU,SSTfmr,andDSTfmrmodelswereabletoper-
formsomedegreeofOODgeneralization(e.g.,generalizationon10distractors),performancewas
markedlyreducedasthenumberofdistractorsincreasedfrom10to20(Fig. 3d).
3.2 SYSTEMATICCOMPOSITIONALGENERALIZATION
The evaluation of Transformer models on systematic generalization problems has been of recent
interest(Ontan˜o´netal.,2022;Csorda´setal.,2022;Hupkesetal.,2020;Keysersetal.,2020;Dziri
etal.,2023). However,mostevaluationshavebeenlimitedtosequence-to-sequencetasksinasin-
gle modality (e.g., natural language). Here we extend prior work, and provide an evaluation of
systematicgeneralizationinthegCOGtaskusingencoder-onlyarchitectures.
Experimentalsetup. Evaluatingsystematiccompositionalgeneralizationrequiresatestsetthatis
anovelrecombinationofpreviouslyseentasks. IngCOG,thistrain/testsplitcanmanifestinseveral
ways.Thesimplestsplitistoevaluategeneralizationonindividualtaskoperators(e.g.,“exist”)with
objects(e.g.,“redb”)thatithasnotbeenpairedwithbefore. Forexample,ifthemodelwastrained
on“Existbluea”and“GetLocationredb”,itwouldhavetosystematicallycombinethenotionof
“redb”withthe“Exist”operator–aconfigurationnotseeninthetrainingset(Fig. 4a).
Additionally,amorechallengingtestofsystematicityistoevaluategeneralizationperformanceon
more complex task tree structures. Prior question-answer benchmarks that evaluated systematic
generalizationtypicallywerelimitedtoassessingsystematicityonindividualtaskoperations,rather
6A Systematicity on B C
Individual operator generalization
individual operators
train set test set
Exist Exist
A B
Get Location Get Location
B A
generalize
Systematicity on
D E F
depth 3 tasks
Depth 3 task generalization
train set
test set
Figure4:A)Systematicityonindividualtaskoperators,wherespecificobjects(e.g.,ablue“a”)aretrainedon
asubsetofoperators,andthentestedondistinctsetofoperators. Thisevaluatesifthemodelcangeneralize
to new operator and object combinations. B) Training trajectories. C) CrossAttn and Perceiver-like models
exhibitexcellentsystematicitygeneralization,whileothermodelsperformedatreducedrates. D)Anothertest
ofsystematicityistotrainontasktreesofdepth3,andthentestonnovelcombinationsoftasktreesofdepth3.
E)Trainingtrajectories.Allmodelswereabletoefficientlylearnthistaskvariant.(Notethatperiodicspikesin
thelossfunctionareduetoaresamplingofthetrainingdatasetduetomodelcheckpointingand/ordisruption
toacomputejob.) F)Whileoverallgeneralizationperformanceislower(evenonIIDgeneralization),cross-
attentionmodelsstillperformsystematiccompositionalgeneralizationwellabovechance.
than on task trees with greater dependencies (e.g., COG, SQOOP; Yang et al. (2018); Bahdanau
etal.(2019;2020). Here,wetrainedonasubsetoftasktreesofdepth1and3,andthenevaluated
performance on an a novel combination of task structures of depth 3 (Fig. 4d). In this particular
train/testsplit,weensuredthateveryindividualtaskoperatorwaspreviouslytrainedon,butthata
specificcombinationoftaskoperatorsinatasktreewasnovel.
Generalizationperformance. Onthesystematicitytestwithindividualtaskoperators(Fig. 4a),all
modelsconvergedonthetrainingsetwithgreaterthan92%performance(Fig. 4b). Allmodelsex-
hibitedreasonablygoodperformance(>78%;chance=33.10%)onOODsystematicgeneralization
(Fig. 4c). (Note that chance was determined as the average probability of each output classifica-
tiongiventhedistributionofthetrainingset.) Acrossallmodels,modelscontainingcross-attention
mechanismsperformedthehighestonsystematicgeneralization,withtheCrossAttnandPerceiver
architecturesexhibitingthehighestOODgeneralizationperformance(>97%;Fig. 4c).
Onsystematicgeneralizationondepth3tasks(Fig. 4d),IIDgeneralizationwasmarkedlyreduced
acrosstheboard,despiteconvergenceonthetrainingsetforallmodels(allmodelsachieved>98%
accuracy on the training set) (Fig. 4e,f). (Note, however, that increasing depth (encoder layers)
to Transformers improves IID generalization on these splits; Fig. 6.) However, the Perceiver
model outperformed all other models, exhibiting 75.4% IID systematic generalization, and 65.7%
OODgeneralization. Thenextbestperformingmodelshad59.2%IIDgeneralizationperformance
(CrossAttnmodel),and54.1%OODgeneralizationperformance(RNN).Theseresultssuggestthat
thePerceiverwasbestsuitedforsystematicmultimodalgeneralization, indicatingitspromiseasa
generic,amodalarchitectureformultimodalsystematicgeneralization.
3.3 PRODUCTIVECOMPOSITIONALGENERALIZATION
Experimental setup. Productive compositional generalization involves generalizing to tasks of
greatercomplexity(e.g., atasktreeofdepth3toatasktreeofdepth5). Weevaluatedproductive
7
ezilareneggeneralizationinthecontextofgCOG.Wetrainedallmodelsontasktreesofdepth1anddepth3,
andthenevaluatedgeneralizationperformancetotasktreesofdepth5anddepth7(Fig. 5a). (We
alsoshowinAppendixFig. 11howmodelstrainedonlyontasktressofdepth1failtogeneralizeto
tasktreesofdepth3,5,and7.)
A Productive compositional generalization
depth 3
depth 1
TEST SET
generalize depth 7
TRAIN SET
depth 5
B C D
Figure 5: Productive compositional generalization performance. A) OOD productivity performance of all
modelstonoveltasksofgreatercomplexity(i.e.,deepertasktrees). Wetrainedmodelsontasktreesofdepth
1 and depth3, andthen tested generalization to tasktrees of depth 5 and 7. While the B)training loss and
C)trainingaccuracyconvergedforallmodels,D)allmodelsfailedtoperformOODproductivecompositional
generalizationtomorecomplextasktrees.(Notethatperiodicspikesinthelossfunctionareduetoaresampling
ofthetrainingdatasetduetomodelcheckpointingand/ordisruptiontoacomputejob.)
Generalizationperformance. Thoughallmodelsconvergedonthetrainingdataset(Fig5b,c),all
modelscompletelyfailedtoOODgeneralizetotasktreesof5and7(Fig. 5d)(performancewasat
orbelowchanceforallOODsplits). PriorworkhasshownthatTransformer-basedmodelsexhibit
improvedproductivitygeneralizationwhenusingarelativepositionalencoding(Csorda´setal.,2022;
Ontan˜o´n et al., 2022). Though we used absolute positional encodings in our Transformer-based
models in Fig. 5, we found that using relative positional encodings did not improve productive
generalizationperformanceongCOG(AppendixFig.10).Onepossibleexplanationforthedisparity
betweensystematicandproductivegeneralizationinneuralmodelsisthatsystematicityrequiresthe
ability to exchange semantics (or tokens) from a known syntactic structure (e.g., a tree of certain
depth). In contrast, productive generalization requires generalizing to an entirely new syntactic
structure (e.g., a task tree of different size or depth). This requires understanding the syntax –
howtopiecetogethersyntacticstructureson-the-fly–requiringanotherlevelofabstraction. Toour
knowledge,thereisnomechanisminmodernTransformersthatwouldenablethis.Thus,productive
compositionalgeneralizationremainsadifficultcapabilityforpurelyneuralmodelstoachieve.
3.4 IMPACTOFLAYERDEPTHANDATTENTIONHEADSONGENERALIZATION
Our previous experiments evaluated the performance of base neural network models on gCOG.
However, these “base” models did not assess the impact of model scale (e.g., depth) on perfor-
mance. Tocomplementthosepreviousexperiments, weevaluatedtheimpactofscale(layerdepth
andattentionheads)ofastandardTransformerencodermodel(e.g.,BERT-style,andsimilarinbase
architecture to the SSTfmr; Devlin et al. (2019)) on generalization. We assessed the influence of
encoder layers (1, 2, 3, and 4 layers), and the number of attention heads per encoder layer (1, 4,
and 8 heads). We found that increasing encoder layers improves generalization across distractor
(Fig. 6a,b)andsystematicgeneralization(Fig. 6d,e,g,h). Increasingattentionheadsperlayeralso
8marginallyimproveddistractorandsystematicgeneralization,buttoalesserextentthanaddinglay-
ers (Fig. 6c,f,i). Importantly, the largest model we tested (a BERT-small-sized model; 4 layers
and 8 attention heads) demonstrated excellent systematic and distractor generalization. However,
model scale failed to illustrate any improvement on productive generalization (Fig. 6j,k). These
results demonstrate that increasing scale of standard Transformer architectures may be sufficient
fordistractorandsystematicgeneralization,butthatproductivegeneralizationremainsasignificant
challenge.
A B C
D E F
G H I
J K L
Figure6: EvaluatinggeneralizationsplitsonBERT-likesingle-streamtransformermodelswithvaryinglayers
(L)andattentionheads(A).Overall,increasinglayersandattentionheadscanimprovegeneralizationacross
distractorandsystematicgeneralization,butnotproductivegeneralization. A)Evaluationondistractorgener-
alizationacrossallmodelparameters. B)Theeffectofaddingadditionalencoderlayersondistractorgeneral-
izationperformance(averagedacrossallattentionheadconfigurations).C)Theeffectofaddingattentionheads
ondistractorgeneralizationperformance(averagedacrossalllayerdepthconfigurations). D-F)Evaluationon
systematicityfordepth1tasks(generalizationsplitinFig. 4a). G-I)Evaluationonsystematicityfordepth3
tasks(generalizationsplitinFig.4d).J-L)Evaluationonproductivitysplit(generalizationsplitinFig.5a).
4 CONCLUSION
IdentifyingneuralarchitecturesthatcanrobustlygeneralizeOODisacentralgoalinartificialintel-
ligence. Compositionalgeneralizationbenchmarks,whichexplicitlyevaluateforOODgeneraliza-
tion,provideagoodtestbedformeasuringthesecapabilities. However,themostsuccessfulmodels
for multimodal compositional generalization tend to be hybrid neuro-symbolic models rather than
purely neural models (Bahdanau et al., 2020). While useful for some applications, current neuro-
symbolicmodelsrequireaprioriknowledgeofwhatrulesandoperationstoinclude,makingthem
difficult to train end-to-end, and limiting their broader use and overall scalability. In this study,
we sought to evaluate how different architectural mechanisms in purely neural models influence
OODmultimodalgeneralization. WeintroducedgCOG,whichprovidesexplicitOODgeneraliza-
tionsplitsforgenericmultimodalreasoningthatcanbeextendedinfuturestudies.Ourexperimental
resultsdemonstratethatwhilecurrentneuralmodelsfallshortofexhibitinganyproductivecompo-
sitionalgeneralization,increasinglayerdepthsand/ortargetedcrossattentionmechanismsbetween
multiple domains provide paths towards improving systematic and distractor OOD generalization
onmultimodaltasks. Thus,wehopethisstudyinspiresfutureworktowardsidentifyingtheneural
architecturescapableofperformingmultimodalOODgeneralization,withthegoalofadvancingthe
broaderreasoningcapacitiesofmodernAIsystems.
9REPRODUCIBILITYSTATEMENT
Upon publication, we will publicly release the code (along with documentation) for the task and
models. AdditionaldetailsregardingtheexperimentaldesigncanbefoundinAppendixA.2. Addi-
tionaldetailsregardingthemodelarchitecturesandtrainingcanbefoundinAppendixA.3. Addi-
tionaldetailsregardingrepresentationanalysiscanbefoundinAppendixA.1.
REFERENCES
JacobAndreas. MeasuringCompositionalityinRepresentationLearning,April2019. URLhttp:
//arxiv.org/abs/1902.07181. arXiv:1902.07181[cs,stat].
DzmitryBahdanau,ShikharMurty,MichaelNoukhovitch,ThienHuuNguyen,HarmdeVries,and
Aaron Courville. Systematic Generalization: What Is Required and Can It Be Learned?, April
2019. URLhttp://arxiv.org/abs/1811.12889. arXiv:1811.12889[cs].
Dzmitry Bahdanau, Harm de Vries, Timothy J. O’Donnell, Shikhar Murty, Philippe Beau-
doin, Yoshua Bengio, and Aaron Courville. CLOSURE: Assessing Systematic Generaliza-
tion of CLEVR Models, October 2020. URL http://arxiv.org/abs/1912.05783.
arXiv:1912.05783[cs].
Se´bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece
Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi,
MarcoTulioRibeiro,andYiZhang. SparksofArtificialGeneralIntelligence: Earlyexperiments
withGPT-4,April2023. URLhttp://arxiv.org/abs/2303.12712. arXiv:2303.12712
[cs].
Ro´bert Csorda´s, Kazuki Irie, and Ju¨rgen Schmidhuber. The Devil is in the Detail: Simple Tricks
Improve Systematic Generalization of Transformers, February 2022. URL http://arxiv.
org/abs/2108.12284. arXiv:2108.12284[cs].
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. BERT:Pre-trainingofDeep
Bidirectional Transformers for Language Understanding, May 2019. URL http://arxiv.
org/abs/1810.04805. arXiv:1810.04805[cs].
Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Peter
West, Chandra Bhagavatula, Ronan Le Bras, Jena D. Hwang, Soumya Sanyal, Sean Welleck,
XiangRen,AllysonEttinger,ZaidHarchaoui,andYejinChoi. FaithandFate: LimitsofTrans-
formers on Compositionality, June 2023. URL http://arxiv.org/abs/2305.18654.
arXiv:2305.18654[cs].
DanielFurrer,MarcvanZee,NathanScales,andNathanaelScha¨rli. CompositionalGeneralization
inSemanticParsing: Pre-trainingvs.SpecializedArchitectures, September2021. URLhttp:
//arxiv.org/abs/2007.08970. arXiv:2007.08970[cs].
Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Cur-
tis Hawthorne, Andrew M. Dai, Matthew D. Hoffman, Monica Dinculescu, and Douglas
Eck. MusicTransformer,December2018. URLhttp://arxiv.org/abs/1809.04281.
arXiv:1809.04281[cs,eess,stat].
Dieuwke Hupkes, Verna Dankers, Mathijs Mul, and Elia Bruni. Compositionality Decomposed:
How do Neural Networks Generalise? Journal of Artificial Intelligence Research, 67:757–795,
April 2020. ISSN 1076-9757. doi: 10.1613/jair.1.11674. URL https://www.jair.org/
index.php/jair/article/view/11674.
Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and Joao Car-
reira. Perceiver: General Perception with Iterative Attention. In Proceedings of the 38th In-
ternationalConferenceonMachineLearning,pp.4651–4664.PMLR,July2021. URLhttps:
//proceedings.mlr.press/v139/jaegle21a.html. ISSN:2640-3498.
10JustinJohnson, BharathHariharan, LaurensvanderMaaten, LiFei-Fei, C.LawrenceZitnick, and
RossGirshick. CLEVR:ADiagnosticDatasetforCompositionalLanguageandElementaryVi-
sualReasoning. In2017IEEEConferenceonComputerVisionandPatternRecognition(CVPR),
pp.1988–1997,Honolulu,HI,July2017.IEEE. ISBN978-1-5386-0457-1. doi: 10.1109/CVPR.
2017.215. URLhttps://ieeexplore.ieee.org/document/8099698/.
DanielKeysers,NathanaelScha¨rli,NathanScales,HylkeBuisman,DanielFurrer,SergiiKashubin,
Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao
Wang,MarcvanZee,andOlivierBousquet. MeasuringCompositionalGeneralization: ACom-
prehensive Method on Realistic Data, June 2020. URL http://arxiv.org/abs/1912.
09713. arXiv:1912.09713[cs,stat].
NajoungKim, TalLinzen, andPaulSmolensky. UncontrolledLexicalExposureLeadstoOveres-
timation of Compositional Generalization in Pretrained Models, December 2022. URL http:
//arxiv.org/abs/2212.10769. arXiv:2212.10769[cs].
Max Klabunde, Tobias Schumacher, Markus Strohmaier, and Florian Lemmerich. Similarity of
Neural Network Models: A Survey of Functional and Representational Measures, May 2023.
URLhttp://arxiv.org/abs/2305.06329. arXiv:2305.06329[cs].
Tim Klinger, Qi Liu, Maxwell Crouse, Soham Dan, Parikshit Ram, and Alexander G. Gray.
Compositional Program Generation for Systematic Generalization. June 2023. URL https:
//openreview.net/forum?id=Wxj9U0ySU-s.
Nikolaus Kriegeskorte, Marieke Mur, and Peter Bandettini. Representational similarity analy-
sis - connecting the branches of systems neuroscience. Frontiers in systems neuroscience, 2
(November):4,2008. ISSN1662-5137. doi: 10.3389/neuro.06.004.2008.
Brenden Lake and Marco Baroni. Generalization without Systematicity: On the Compositional
Skills of Sequence-to-Sequence Recurrent Networks. In International Conference on Machine
Learning, pp. 2873–2882. PMLR, July 2018. URL http://proceedings.mlr.press/
v80/lake18a.html. ISSN:2640-3498.
Ilya Loshchilov and Frank Hutter. Decoupled Weight Decay Regularization, January 2019. URL
http://arxiv.org/abs/1711.05101. arXiv:1711.05101[cs,math].
IanR.McKenzie,AlexanderLyzhov,MichaelPieler,AliciaParrish,AaronMueller,AmeyaPrabhu,
Euan McLean, Aaron Kirtland, Alexis Ross, Alisa Liu, Andrew Gritsevskiy, Daniel Wurgaft,
Derik Kauffman, Gabriel Recchia, Jiacheng Liu, Joe Cavanagh, Max Weiss, Sicong Huang,
TheFloatingDroid,TomTseng,TomaszKorbak,XudongShen,YuhuiZhang,ZhengpingZhou,
NajoungKim,SamuelR.Bowman,andEthanPerez. InverseScaling: WhenBiggerIsn’tBetter,
June2023. URLhttp://arxiv.org/abs/2306.09479. arXiv:2306.09479[cs].
MaxwellI.Nye,ArmandoSolar-Lezama,JoshuaB.Tenenbaum,andBrendenM.Lake. Learning
CompositionalRulesviaNeuralProgramSynthesis. arXiv:2003.05562[cs],March2020. URL
http://arxiv.org/abs/2003.05562. arXiv: 2003.05562.
Santiago Ontan˜o´n, Joshua Ainslie, Vaclav Cvicek, and Zachary Fisher. Making Transformers
Solve Compositional Tasks, March 2022. URL http://arxiv.org/abs/2108.04378.
arXiv:2108.04378[cs].
Linlu Qiu, Hexiang Hu, Bowen Zhang, Peter Shaw, and Fei Sha. Systematic Generalization on
gSCAN:WhatisNearlySolvedandWhatisNext? InMarie-FrancineMoens,XuanjingHuang,
Lucia Specia, and Scott Wen-tau Yih (eds.), Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing, pp. 2180–2188, Online and Punta Cana, Dominican
Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.
emnlp-main.166. URLhttps://aclanthology.org/2021.emnlp-main.166.
Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, and Brenden M Lake. A
Benchmark for Systematic Generalization in Grounded Language Understanding. In Ad-
vances in Neural Information Processing Systems, volume 33, pp. 19861–19872. Curran As-
sociates,Inc.,2020. URLhttps://proceedings.neurips.cc/paper/2020/hash/
e5a90182cc81e12ab5e72d66e0b46fe3-Abstract.html.
11Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. Are Emergent Abilities of Large Lan-
guage Models a Mirage?, May 2023. URL http://arxiv.org/abs/2304.15004.
arXiv:2304.15004[cs].
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-Attention with Relative Position Repre-
sentations, April 2018. URL http://arxiv.org/abs/1803.02155. arXiv:1803.02155
[cs].
Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova. Compositional Gener-
alization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both? In
Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (eds.), Proceedings of the 59th An-
nual Meeting of the Association for Computational Linguistics and the 11th International Joint
ConferenceonNaturalLanguageProcessing(Volume1:LongPapers),pp.922–938,Online,Au-
gust2021.AssociationforComputationalLinguistics. doi: 10.18653/v1/2021.acl-long.75. URL
https://aclanthology.org/2021.acl-long.75.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N
Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is All you Need. In Ad-
vances in Neural Information Processing Systems, volume 30. Curran Associates,
Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/hash/
3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.
Chaojun Wang and Rico Sennrich. On Exposure Bias, Hallucination and Domain Shift in
Neural Machine Translation, May 2020. URL http://arxiv.org/abs/2005.03642.
arXiv:2005.03642[cs].
Taylor Webb, Keith J. Holyoak, and Hongjing Lu. Emergent analogical reasoning in large
language models. Nature Human Behaviour, pp. 1–16, July 2023. ISSN 2397-3374.
doi: 10.1038/s41562-023-01659-w. URL https://www.nature.com/articles/
s41562-023-01659-w. Publisher: NaturePublishingGroup.
Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyu¨rek, Boyuan Chen, Bailin Wang, Najoung
Kim, Jacob Andreas, and Yoon Kim. Reasoning or Reciting? Exploring the Capabilities and
Limitations of Language Models Through Counterfactual Tasks, August 2023. URL http:
//arxiv.org/abs/2307.02477. arXiv:2307.02477[cs].
Guangyu Robert Yang, Igor Ganichev, Xiao-Jing Wang, Jonathon Shlens, and David Sus-
sillo. A Dataset and Architecture for Visual Reasoning with a Working Memory. pp. 714–
731,2018. URLhttps://openaccess.thecvf.com/content_ECCV_2018/html/
Guangyu_Robert_Yang_A_dataset_and_ECCV_2018_paper.html.
12A APPENDIX
A.1 REPRESENTATIONANALYSISOFMODELARCHITECTURES
We performed representation analysis to identify the relationship between how a model’s archi-
tecture constrains its internal representations, and in turn, its generalization behavior. Originally
developed to analyze and interpret neuroscience data, representational similarity analysis (RSA)
facilitates the interpretability of a model’s internal activation patterns (Kriegeskorte et al., 2008;
Klabundeetal.,2023). Inbrief,RSAsummarizesthegeometryofrepresentationsinaneuralnet-
work layer (or layers) by measuring the similarities (or distances) between the activation vectors
during the presentation of different inputs. This explicitly measures the relations between input
samples,facilitatinginsightintohowthisneuralnetworklayerprocessesdifferentsamples. More-
over, transforming individual representations into a sample-by-sample matrix of representational
similarities enables direct comparison between neural network layers both within and across net-
works,sincethematrixdimensionscanbemadeequal. (Incontrast,layeractivationsacrossmodels
or even within models are hard to compare, due to the lack of a 1-to-1 mapping of units.) In our
specific case, we evaluated how different task features (stimulus input and target representaions)
emerge in the penultimate layer of neural network models. This was done by computing the sim-
ilaritiesofstimuli(thevectorizedstimulusencoding)andtargetresponses(one-hotcodesforeach
targetresponse),andthencomputingthedistanceofthesesimilaritymatricestotherepresentational
similaritymatricesofthemodel’spenultimatelayer.
Inouranalysis,wesoughttounderstandwhymodelswithdifferentarchitectures(e.g.,thepresence
of a cross-attention mechanism) better performed OOD distractor generalization. We focused our
analysistothedistractorgeneralizationbenchmark,sinceweobservedthestrongestdiscrepancyin
OOD generalization performance across models. To evaluate what task information was retained
withintherepresentationsofeachmodelduringOODdistractorgeneralization,werandomlysam-
pled 800 task samples with 40 to 50 distractors and quantified the vectorized cosine similarities
betweeneverypairoftaskstimuli(intheinputspace)(Fig. 7a). (Note,however,thatotherdistance
metricscanalsobeusedKlabundeetal.(2023).) Thisresultedinastimulussimilaritymatrix,from
whichwecoulddirectlycompareamodel’sinternalrepresentationalsimilaritiesusingthesame800
samples.Next,wemeasuredeachmodel’srepresentationalsimilaritymatrixtothesamesetofstim-
uli using activations in the models’ penultimate layer (Fig. 7a). To measure how much stimulus
informationtheneuralnetwork’slayerretained,wecomputedtheL2normbetweenmatricesafter
aligningthetwomatricesthroughtheorthogonalProcrustestransform. (Thesameprocedurecould
beappliedtomeasuretherepresentationalalignmenttotargetresposneinformation(Fig. 7c).) The
orthogonalProcrustestransformbetweentherepresentationalsimilaritymatrix,X,andstimulus(or
target)matrixY,wascomputedbysolvingfortheorthogonaltransformation
Q∗ =arg min ||XQ−Y||
F
Q∈O(D)
whereQ∗ isthebestorthogonaltransformationtoalignX andY,O(D)isthegroupoforthogonal
transformations,and||·|| denotestheFrobeniusnorm. Then,tocomputethealignmentAbetween
F
matricesX andY,wecompute
A=||XQ∗−Y||
F
Weusedthisdistancemetricasithasbeenpreviouslyshowntobeaproperdistancemetric(i.e.,it
obeysthetriangleinequality;Klabundeetal.(2023). However,thismeasurealonedoesnotcontrol
forpotentialbiasesinrepresentationaldistancesduetoarchitecture.Thus,tocontrolforthepotential
confound that some model architectures have different innate distances, we computed the relative
alignmentbycomputingthedifferenceofAbeforeandaftertrainingthemodel.Importantly,relative
alignmentcanbenegative, sinceitprovidesametricofhowtherepresentationschangerelativeto
therandomlyinitializedmodelarchitecture. Weusethismeasureofrelativealignmenttomeasure
how much stimulus or target response information each model architecture retained in Figure 7.
We found that the best performing models (CrossAttn and Perceiver models) on OOD distractor
generalization,hadthehighestalignmenttothestimuli,whilethelowestperformingmodels(e.g.,
RNNsandGRUs), wereleastalignedtostimulusinformation(Fig. 7b). Wefoundasimilartrend
whenestimatingthemodel’salignmenttothecorrectresponse(i.e.,target)(Fig. 7c). Thus,thebest
OODdistractorgeneralizationmodelswereabletoretainbothstimulusandresponseinformationin
thepenultimateinternalrepresentations.
13A B C
stim 1
less alignment
stim k
compute
L2 norm
sample m
sample n
greater alignment
Figure7:Representationanalysisacrossmodelarchitectures.A)Tomeasuretaskinformationineachmodel’s
internalrepresentations,wemeasuredtherepresentationalsimilaritymatricesofthestimulus(ortarget)sam-
ples,andcomparedthosetothemodels’representationalsimilaritymatricesduringthosesamesamples. Re-
tainmentofstimulus(ortarget)informationinthemodel’srepresentationscouldthenbemeasuredastheL2
normbetweenmodelandthetaskstimulus(ortarget)matrices. B)Modelalignmenttostimulusinformation.
Modelswithcross-attentionmechanismsbestretainedstimulusinformationinthepenultimatelayer.C)Model
alignmenttotarget(response)information.
A.2 ADDITIONALDETAILSONTASKDESIGN
gCOGwasmodifiedfromtheoriginalCOGtasktoenablethemeasurementofvariousOODbench-
marks(Yangetal.,2018). Whileweemployedsomesimilartaskoperations(e.g.,theExistopera-
tor),wealsoimplementedanumberofnewtaskoperatorsthatwerenotintheoriginaldataset. We
alsoliftedtheconstraintofmaximallyincludingonlyasingleconditional(i.e.,anIF-THEN-ELSE
statement,originallyreferredtoasa“Switch”clauseinCOG),allowingustoflexiblyevaluatepro-
ductivecompositionalgeneralization. AfewexamplequeriesfromtheoriginalCOGtaskinclude:
“Whatisthecolorofthelatesttriangle? Pointtothelatestredobject. Ifasquareexists,thenpoint
tothecurrentx,otherwisepointtothelastb.”
Construction of task samples was algorithmically consistent with how samples were constructed
in COG and CLEVR (Johnson et al., 2017). Construction of a task sample (i.e., task instructions,
stimuli,andtarget)beganbyfirstconstructingthetaskinstruction,andthendeterminingthespecific
taskpath(i.e.,whichoperatorswillbeencounteredinthetasktree). Dependingonwhatthetarget
response is, a backward pass is taken through the task path (i.e., bottom-up). Objects are then
incrementallyaddedtothestimulustosatisfyalltasknodesfromthebottom-up. Thisensuresthat
the stimulus will necessarily satisfy the chosen task path while guaranteeing a unique solution for
eachtasknode. Morespecifically,therewillalwaysbeauniqueobjectorobjectfeaturetosatisfya
taskoperator. (IfthetaskoperatoristoGettheColorofthe“a”,thetaskalgorithmguaranteesthat
there will only be a single “a” in the image. If the task operator is Does the red “a” exist?, there
isguaranteedtobeamaximumofonered“a”.) Additionalalgorithmicdetailsontaskconstruction
can be found in Yang et al. (2018) and Johnson et al. (2017), and the task code will be publicly
released. Wewilladditionallyreleasespecificbenchmarksthatwereusedinthisstudy.
NotethatintheIIDsplitforeachtest,itistheoreticallypossiblethatthemodelwillbetestedona
samplethatitwastrainedonduetorandomsampling,thoughthisishighlyunlikely:theprobability
that two identical stimuli are presented is less than 10−14 due to the total number of distractor
combinations.
A.2.1 TASKOPERATORS
Exist. TheExistoperatorispairedwithanobject(i.e., colorandshapefeaturecombination), and
asks whether that object exists in the stimulus. The correct response returns a boolean (True or
False). Example: Doesthered“a”exist?
GetColor. TheGetColoroperatorispairedwithashapefeature,andaskstoreturnthecolorofthat
shape. Thecorrectresponseisacolorfeature(1outof10possiblecolorfeatures). Example: Get
thecolorofthe“a”. (Inthetaskconstruction,thereisguaranteedtobeauniquesolution(i.e.,one
“a”)intheimage.
14
enisocGetShape.TheGetShapeoperatorispairedwithacolorfeature,andaskstoreturntheshapeofthe
objectwiththatcolor. Thecorrectresponseisashapefeature(1outof26possibleshapeattributes).
Example: Gettheshapeoftheredobject. (Intheexample,therewillalwaysbeasingleredobject.)
GetLocation. TheGetLocationoperatorispairedwithanobject, andaskstoreturnitslocation.
Thecorrectresponseisthe(x,y)coordinatesofthatobject(1outof100possiblelocationsina10
by10grid). Example: Getthelocationofthered“a”.
SumEven. TheSumEvenoperatorispairedwithanobject,andaskswhetherthesumofitsxand
ycoordinatelocationiseven. ThecorrectresponseisaTrue/Falseboolean. Example: Isthesumof
thexandycoordinatevaluesofthered“a”even?
SumOdd. TheSumOddoperatorispairedwithanobject,andaskswhetherthesumofitsxand
ycoordinatelocationisodd. ThecorrectresponseisaTrue/Falseboolean. Example: Isthesumof
thexandycoordinatevaluesofthered“a”odd?
ProductEven. TheProductEvenoperatorispairedwithanobject,andaskswhethertheproductof
itsxandycoordinatelocationiseven. ThecorrectresponseisaTrue/Falseboolean. Example: Is
theproductofthexandycoordinatevaluesofthered“a”even?
ProductOdd. TheProductOddoperatorispairedwithanobject,andaskswhethertheproductof
itsxandycoordinatelocationisodd. ThecorrectresponseisaTrue/Falseboolean. Example:Isthe
productofthexandycoordinatevaluesofthered“a”odd?
Note that some of these operators can be used as terminals, i.e., task tree leaves with no children.
This includes all task operators that do not return a boolean response (Get Color, Get Shape, and
GetLocation). Thisisbecauseabooleanresponseisrequiredtobeinputtoanif-then-elseclause.
A.3 ADDITIONALDETAILSONMODELARCHITECTURESANDTRAINING
Upon publication, all code associated with model architectures will be publicly released. Models
were constructed using PyTorch version 2.0.0+cu118. All models could be trained in under three
daysonanNVIDIAK80GPU,andweretrainedonIBM’sCognitiveComputeCluster.
For a specific evaluation benchmark (e.g., distractor generalization), all models were trained on
exactly the same number of samples (and training steps). This made it possible to fairly evaluate
and compare performance of different models. For distractor generalization (Fig. 3), all models
were trained on 53,980,000 samples. For systematic generalization on individual operators (Fig.
4a),allmodelsweretrainedon47,980,000samples. Forsystematicgeneralizationondepth3tasks
(Fig. 4d), allmodelsweretrainedon53,980,000samples. Forproductivegeneralization(training
ontaskswithdepth1and3;Fig. 5),allmodelsweretrainedon59,980,000samples.
All models were trained using the AdamW optimizer with a learning rate of 0.0001, and the loss
wascomputedastheCrossEntropybetweenthetargetclassandoutputvector.
A.3.1 MODELARCHITECTURES
The inputs to the models comprised of rule tokens (i.e., task instructions) and stimulus. For
Transformer-based models (SSTfmr, DSTfmr, CrossAttn, and Perceiver) the 10x10 stimulus grid
waspresentedasasequenceof100tokenswithabsolutepositionalencoding. Eachstimulustoken
hadanembeddingdimensionalityof37(26letters+10colors+1EOSsymbol).ForRNNandGRU
models,stimuliwereflattenedintoanarray(100×37). Ruletokenshadanembeddingdimension
of84,whichcomprisedofone-hotencodingsoftaskoperator,objectfeatures(i.e.,whichobjector
featuretoselectfor),andEOSsymbol. Allmodelsencodedruletokensasasequence.
RNN.InputstotheRNNwereasequenceofruletokensandaflattenedstimulusvector,whichwere
projectedto512hiddenunits. Hiddenunitactivity,h wasdeterminedbytheequation
t
h =tanh((x WT +b )+(x WT +b )+h WT +b
t r,t r,h r,h s,t s,h s,h t−1 hh hh
where x , WT , and b represented the rule inputs, weights, and biases respectively, and x ,
r,t r,h r,h s,t
WT , and b the stimulus inputs, weights, and biases. The stimulus vector was presented every
s,h s,h
timearuletokenwasprocessed. ThisavoidedtheneedfortheRNNto“remember”thestimulus.
15Example of task trees of varying depth
Depth 1 Depth 5
Depth 3
Depth 7
Figure8:Exampletasktreesofdepth1,3,5,and7.Inthecurrentdesign,thereare8taskoperatorsthatcanbe
pairedwithupto260uniqueobjects(26letters*10colors).However,someoperatorscanonlybeusedastree
leaves(i.e.,theyhavenochildreninthetasktree).TheseincludeGetColor,GetShape,andGetLocation.This
isbecauseifataskoperatorhasachildwhichisanif-else-thenclause,thetaskoperatorisrequiredtoreturna
boolean.
Hidden units were initialized as a vector of zeros prior to each trial. The RNN hidden activation
patternswereprocessedthroughaLayerNormaftereveryiteration,andthensubsequentlyprojected
to the output layer (with 138 units) for classification. A Softmax was applied prior to supervised
trainingoftheoutputs. ModeltrainingwasperformedwiththeAdamWoptimizeratalearningrate
of 0.0001 (Loshchilov & Hutter, 2019), and the loss was computed as the Cross Entropy between
thetargetclassandtheoutputvector.
GRU.Architecturally,theGRUwasstructuredidenticallytotheRNN.Inputandoutputswerefor-
mattedandprojectedidentically,andtheplacementofLayerNormsremainedthesame.Theprimary
distinctionwasthegenerationofthehiddenunitactivityh ,whichwasdeterminedbytheequation
t
h =(1−z )⊙n +z ⊙h
t t t t t−1
wheren ,z ,andr correspondtothenew,update,andresetgates,respectively,andaredefinedby
t t t
theequations
n =tanh(W x +b +r ⊙(W h +b ))
t in t in t hn t−1 hn
z =σ(W x +b +W h +b ))
t iz t iz hz t−1 hz
r =σ(W x +b +W h +b ))
t ir t ir hr t−1 hr
16where σ is the sigmoid function, and ⊙ is the Hadamard product. As in the case of the RNN, the
GRUmodelwastrainedwiththeAdamWoptimizerwithalearningrateof0.0001,andthelosswas
computedastheCrossEntropybetweenthetargetclassandtheoutputvector.
SSTfmr. Rule inputs the the SSTfmr were identical to the RNN, i.e., a sequence of rule tokens.
Stimulus input was represented as a sequence of tokens. Specifically, each location of the stim-
ulus(i.e., each(x,y)coordinate)correspondedtoasingletoken. Sincetherewere10rowsand10
columns,therewereatotalof100tokens.Wezero-paddedconcatenatedboththeruletokensandthe
stimulustokensintoasinglecontextwindowwithzero-padding. Thus,thetotalnumberofinputto-
kenscorrespondedtothesumofruleandstimulustokens. ThearchitectureoftheSSTfmrfollowed
astandardbidirectionalEncoder-onlyTransformer, andisarchitecturallysimilartoBERT(Devlin
etal.,2019)(withoutmasking).Sincemultimodalinputswereconcatenatedbeforebeingfedintothe
SSTfmr,self-attentionwastechnicallycross-modal. Note,however,thatcross-modalself-attention
is distinct from cross-attention, since self-attention always produces a square (quadratic) attention
matrix, while cross-attention can produce a square matrix, depending on the number of tokens in
thequerymatrixandthenumberoftokensinthekeyandvaluematrices. Inputtokenswerelinearly
embedded into a vector size of 256. For simplicity, we only included a single Transformer layer,
andeachlayeronlyincludedasingleattentionhead,thoughwedoamoreextensiveevaluationof
this type of architecture in Figure 6. We evaluated models with both absolute positional encoding
(following Vaswani et al. (2017)) and relative positional encoding (following Shaw et al. (2018)).
Theposition-wiseMLPportionoftheTransformerblockwasa2-layerMLPwith512unitsineach
layer. TheoutputoftheTransformerblockwassubsequentlyprocessedthrougha3-layerfeedfor-
ward MLP (512, 1024, and 512 units per layer). We applied a LayerNorm prior to projecting the
activity to the output layer for classification. Model training was performed with the AdamW op-
timizer at a learning rate of 0.0001, and the loss was computed as the Cross Entropy between the
targetclassandtheoutputvector.
DSTfmr. The DSTfmr was architecturally similar to the SSTfmr, except rule and stimulus to-
kens were processed independently in separate (and in parallel) encoder-only Transformer blocks,
followed by separate 3-layer MLPs. (No zero-padded concatenation was applied to the rule and
stimulustokens.) TheoutputoftheparallelMLPs(Fig. 2c)werethensummedtogether,processed
throughaLayerNorm,andthenpassedthrougha3-layerMLP(512,1024,and512unitsperlayer).
ModeltrainingwasperformedwiththeAdamWoptimizeratalearningrateof0.0001,andtheloss
wascomputedastheCrossEntropybetweenthetargetclassandtheoutputvector.
CrossAttn. InputstotheCrossAttnmodelwereprocessedidenticallytotheDSTfmrmodel,i.e.,in
dualstreamencoder-onlyTransformerblocks. Cross-attentionwasthencomputedfromtheoutputs
of the two Transformer blocks. Specifically, the query was computed from the output of the rule
Transformerblock,andthekeysandvalueswerecomputedfromtheoutputofthestimulusTrans-
formerblock(Fig. 2d). Thecross-attentionoutputwasthenprocessedthroughaLayerNorm(witha
skipconnectionfromtheruleTransformerblockoutput),anda2-layerMLP(bothwith512units).
After a final LayerNorm, the activations were linearly projected to the classification layer. Model
training was performed with the AdamW optimizer at a learning rate of 0.0001, and the loss was
computedastheCrossEntropybetweenthetargetclassandtheoutputvector.
Perceiver. InputstothePerceiver-likemodelwereprocessedidenticallytotheDSTfmrmodel,i.e.,
in dual stream encoder-only Transformer blocks. Outputs of the dual-stream Transformer blocks
wereprocessedthroughseparatecross-attentionmechanismswiththelatentTransformer(Fig. 2e).
The processing of inputs to the latent Transformer followed the structure of the Perceiver model
(Jaegle et al., 2021). In our specific case, the latent Transformer contained 256 latent units, and
was initialized to zero at the start of every trial. We computed cross-attention between the latent
Transformer and the output of the rule Transformer first, and then between the latent Transformer
andtheoutputofthestimulusTransformer. Cross-attentioninvolvedcomputingthequeryfromthe
latent units, and the keys and values from the modality-specific Transformers. LayerNorms and
residual connections were computed after every cross-attention computation, followed by a self-
attention computation. After self-attention was computed after integrating information, the latent
activationswereprojectedtotheoutputlayerforclassification.
BERT-like SSTfmr. To assess the role of Transformer depth and attention head number in gen-
eralization splits. we performed additional experiments on a range of BERT-like SSTfmr models
(Fig. 6). ThisincludedsystematicallyvaryingnumberofTransformerlayers(1,2,3,and4layers),
17and attention heads per layer (1, 4, and 8 attention heads). The model with 4 encoder layers and
8 attention heads was architecturally identical to BERT-small, with the exception that the embed-
dingdimensionalitywaslimitedto256(ratherthan512). Moreover,unliketheSSTfmrusedinthe
main manuscript (described above), we removed the additional MLP that was included on top of
theTransformer’sencoderlayer. Theoutputsofthefinalencoderlayerwereprojectedtotheouput
layer for classification (using just a linear layer with a Softmax). For the experiments included in
Fig. 6,allmodelsusedrelativepositionalencoding(Shawetal.,2018). BERT-likeSSTfmrmodels
weretrainedonatotalof11,980,000samplesbeforetestsetevaluation.
A.4 SUPPLEMENTARYRESULTS
Systematicity on
A B C
depth 3 tasks
Depth 3 task generalization
train set
test set
Figure9:Systematiccompositionalgeneralizationperformanceusingrelativepositionalencoding(Shawetal.,
2018;Huangetal.,2018)A)Systematicityevaluationontasktreesofdepth3. B)Trainingtrajectories. C)
Whileweobserveoverallsimilargeneralizationperformancepatternsasobservedusingabsolutepositionalen-
coding,weseesomereductioninperformanceinthecross-attentionmodelsusingrelativepositionalencoding.
A Productive compositional generalization
depth 3
depth 1
TEST SET
generalize depth 7
TRAIN SET
depth 5
B C D
Figure10:Productivecompositionalgeneralizationperformanceusingrelativepositionalencoding(Shawetal.,
2018;Huangetal.,2018)A)OODproductivityperformanceofallmodelstonoveltasksofgreatercomplexity
(i.e.,deepertasktrees). Wetrainedmodelsontasktreesofdepth1anddepth3,andthentestedgeneralization
totasktressofdepth5and7. WhiletheB)traininglossandC)trainingaccuracyconvergedforallmodels,
D)allmodelsfailedtoperformOODproductivecompositionalgeneralizationtomorecomplextasktrees.The
resultswithrelativepositionalencodingareoverallsimilartotheresultswithabsolutepositionalencoding(Fig.
5).
18
ezilarenegA Productive compositional generalization
depth 3
depth 1
TEST SET
generalize depth 7
depth 5
TRAIN SET
B C D
Figure 11: Productive compositional generalization performance, training ontask trees of depth1 (absolute
positional encoding), and testing on task trees of depth 3, 5, and 7. A) In contrast to Figures 5 and 10, we
exclusivelytrainontasktreesofdepth1,andthenassessgeneralizationtotasktressofdepth3,5,and7(i.e.,
deepertasktrees). Evaluationontasktreesof3,5,and7arethereforeOOD.WhiletheB)traininglossand
C)trainingaccuracyconvergedforallmodels(> 94%),D)allmodelsperformedpoorlyonOODproductive
compositionalgeneralization.
19