[
    {
        "title": "EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty",
        "authors": "Yuhui LiFangyun WeiChao ZhangHongyang Zhang",
        "links": "http://arxiv.org/abs/2401.15077v1",
        "entry_id": "http://arxiv.org/abs/2401.15077v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15077v1",
        "summary": "Auto-regressive decoding makes the inference of Large Language Models (LLMs)\ntime-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm\nfor Greater Language-model Efficiency), for lossless acceleration. Unlike\ntraditional speculative sampling methods, EAGLE operates the drafting process\nauto-regressively at the more regular (second-top-layer) feature level and\naddresses the sampling uncertainty issues in the next-feature prediction\nproblems by integrating tokens from one time step ahead. The acceleration\nprovided by EAGLE is lossless: it involves no fine-tuning of the target LLM,\nand the generated text maintains the same distribution as that of vanilla\nauto-regressive decoding. As of the submission of this paper, EAGLE is the\nfastest known framework within the speculative sampling family. On MT-bench,\nEAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x\nfaster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with\nLLaMA2-Chat 13B on a single RTX 3090 GPU, compared to 24 tokens/s of\nHuggingface's implementations.",
        "updated": "2024-01-26 18:59:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15077v1"
    },
    {
        "title": "Expert with Clustering: Hierarchical Online Preference Learning Framework",
        "authors": "Tianyue ZhouJung-Hoon ChoBabak Rahimi ArdabiliHamed TabkhiCathy Wu",
        "links": "http://arxiv.org/abs/2401.15062v1",
        "entry_id": "http://arxiv.org/abs/2401.15062v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15062v1",
        "summary": "Emerging mobility systems are increasingly capable of recommending options to\nmobility users, to guide them towards personalized yet sustainable system\noutcomes. Even more so than the typical recommendation system, it is crucial to\nminimize regret, because 1) the mobility options directly affect the lives of\nthe users, and 2) the system sustainability relies on sufficient user\nparticipation. In this study, we consider accelerating user preference learning\nby exploiting a low-dimensional latent space that captures the mobility\npreferences of users. We introduce a hierarchical contextual bandit framework\nnamed Expert with Clustering (EWC), which integrates clustering techniques and\nprediction with expert advice. EWC efficiently utilizes hierarchical user\ninformation and incorporates a novel Loss-guided Distance metric. This metric\nis instrumental in generating more representative cluster centroids. In a\nrecommendation scenario with $N$ users, $T$ rounds per user, and $K$ options,\nour algorithm achieves a regret bound of $O(N\\sqrt{T\\log K} + NT)$. This bound\nconsists of two parts: the first term is the regret from the Hedge algorithm,\nand the second term depends on the average loss from clustering. The algorithm\nperforms with low regret, especially when a latent hierarchical structure\nexists among users. This regret bound underscores the theoretical and\nexperimental efficacy of EWC, particularly in scenarios that demand rapid\nlearning and adaptation. Experimental results highlight that EWC can\nsubstantially reduce regret by 27.57% compared to the LinUCB baseline. Our work\noffers a data-efficient approach to capturing both individual and collective\nbehaviors, making it highly applicable to contexts with hierarchical\nstructures. We expect the algorithm to be applicable to other settings with\nlayered nuances of user preferences and information.",
        "updated": "2024-01-26 18:44:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15062v1"
    },
    {
        "title": "Fully Independent Communication in Multi-Agent Reinforcement Learning",
        "authors": "Rafael PinaVaruna De SilvaCorentin ArtaudXiaolan Liu",
        "links": "http://arxiv.org/abs/2401.15059v1",
        "entry_id": "http://arxiv.org/abs/2401.15059v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15059v1",
        "summary": "Multi-Agent Reinforcement Learning (MARL) comprises a broad area of research\nwithin the field of multi-agent systems. Several recent works have focused\nspecifically on the study of communication approaches in MARL. While multiple\ncommunication methods have been proposed, these might still be too complex and\nnot easily transferable to more practical contexts. One of the reasons for that\nis due to the use of the famous parameter sharing trick. In this paper, we\ninvestigate how independent learners in MARL that do not share parameters can\ncommunicate. We demonstrate that this setting might incur into some problems,\nto which we propose a new learning scheme as a solution. Our results show that,\ndespite the challenges, independent agents can still learn communication\nstrategies following our method. Additionally, we use this method to\ninvestigate how communication in MARL is affected by different network\ncapacities, both for sharing and not sharing parameters. We observe that\ncommunication may not always be needed and that the chosen agent network sizes\nneed to be considered when used together with communication in order to achieve\nefficient learning.",
        "updated": "2024-01-26 18:42:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15059v1"
    },
    {
        "title": "Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning",
        "authors": "Md Mushfiqur RahmanMohammad Sabik IrbazKai NorthMichelle S. WilliamsMarcos ZampieriKevin Lybarger",
        "links": "http://arxiv.org/abs/2401.15043v1",
        "entry_id": "http://arxiv.org/abs/2401.15043v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15043v1",
        "summary": "Objective: The reading level of health educational materials significantly\ninfluences information understandability and accessibility, particularly for\nminoritized populations. Many patient educational resources surpass the reading\nlevel and complexity of widely accepted standards. There is a critical need for\nhigh-performing text simplification models in health information to enhance\ndissemination and literacy. This need is particularly acute in cancer\neducation, where effective prevention and screening education can substantially\nreduce morbidity and mortality.\n  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel\ncorpus of cancer education materials tailored for health text simplification\nresearch. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore\nLarge Language Model (LLM)-based simplification methods, including fine-tuning,\nreinforcement learning (RL), reinforcement learning with human feedback (RLHF),\ndomain adaptation, and prompt-based approaches. Our experimentation encompasses\nLlama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a\nlightweight model adept at distinguishing between original and simplified\ntexts, thereby enhancing the model's effectiveness with unlabeled data.\n  Results: Fine-tuned Llama 2 models demonstrated high performance across\nvarious metrics. Our innovative RLHF reward function surpassed existing RL text\nsimplification reward functions in effectiveness. The results underscore that\nRL/RLHF can augment fine-tuning, facilitating model training on unlabeled text\nand improving performance. Additionally, these methods effectively adapt\nout-of-domain text simplification models to targeted domains.",
        "updated": "2024-01-26 18:13:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15043v1"
    },
    {
        "title": "On the generalization capacity of neural networks during generic multimodal reasoning",
        "authors": "Takuya ItoSoham DanMattia RigottiJames KozloskiMurray Campbell",
        "links": "http://arxiv.org/abs/2401.15030v1",
        "entry_id": "http://arxiv.org/abs/2401.15030v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15030v1",
        "summary": "The advent of the Transformer has led to the development of large language\nmodels (LLM), which appear to demonstrate human-like capabilities. To assess\nthe generality of this class of models and a variety of other base neural\nnetwork architectures to multimodal domains, we evaluated and compared their\ncapacity for multimodal generalization. We introduce a multimodal\nquestion-answer benchmark to evaluate three specific types of\nout-of-distribution (OOD) generalization performance: distractor generalization\n(generalization in the presence of distractors), systematic compositional\ngeneralization (generalization to new task permutations), and productive\ncompositional generalization (generalization to more complex tasks structures).\nWe found that across model architectures (e.g., RNNs, Transformers, Perceivers,\netc.), models with multiple attention layers, or models that leveraged\ncross-attention mechanisms between input domains, fared better. Our positive\nresults demonstrate that for multimodal distractor and systematic\ngeneralization, either cross-modal attention or models with deeper attention\nlayers are key architectural features required to integrate multimodal inputs.\nOn the other hand, neither of these architectural features led to productive\ngeneralization, suggesting fundamental limitations of existing architectures\nfor specific types of multimodal generalization. These results demonstrate the\nstrengths and limitations of specific architectural components underlying\nmodern neural models for multimodal reasoning. Finally, we provide Generic COG\n(gCOG), a configurable benchmark with several multimodal generalization splits,\nfor future studies to explore.",
        "updated": "2024-01-26 17:42:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15030v1"
    }
]