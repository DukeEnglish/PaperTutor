[
    {
        "title": "Mapping-to-Parameter Nonlinear Functional Regression with Novel B-spline Free Knot Placement Algorithm",
        "authors": "Chengdong ShiChing-Hsun TsengWei ZhaoXiao-Jun Zeng",
        "links": "http://arxiv.org/abs/2401.14989v1",
        "entry_id": "http://arxiv.org/abs/2401.14989v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14989v1",
        "summary": "We propose a novel approach to nonlinear functional regression, called the\nMapping-to-Parameter function model, which addresses complex and nonlinear\nfunctional regression problems in parameter space by employing any supervised\nlearning technique. Central to this model is the mapping of function data from\nan infinite-dimensional function space to a finite-dimensional parameter space.\nThis is accomplished by concurrently approximating multiple functions with a\ncommon set of B-spline basis functions by any chosen order, with their knot\ndistribution determined by the Iterative Local Placement Algorithm, a newly\nproposed free knot placement algorithm. In contrast to the conventional\nequidistant knot placement strategy that uniformly distributes knot locations\nbased on a predefined number of knots, our proposed algorithms determine knot\nlocation according to the local complexity of the input or output functions.\nThe performance of our knot placement algorithms is shown to be robust in both\nsingle-function approximation and multiple-function approximation contexts.\nFurthermore, the effectiveness and advantage of the proposed prediction model\nin handling both function-on-scalar regression and function-on-function\nregression problems are demonstrated through several real data applications, in\ncomparison with four groups of state-of-the-art methods.",
        "updated": "2024-01-26 16:35:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14989v1"
    },
    {
        "title": "Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models",
        "authors": "Michael WojnowiczPreetish RathEric MillerJeffrey MillerClifford HancockMeghan O'DonovanSeth Elkin-FrankstonThaddeus BrunyeMichael C. Hughes",
        "links": "http://arxiv.org/abs/2401.14973v1",
        "entry_id": "http://arxiv.org/abs/2401.14973v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14973v1",
        "summary": "We seek to model a collection of time series arising from multiple entities\ninteracting over the same time period. Recent work focused on modeling\nindividual time series is inadequate for our intended applications, where\ncollective system-level behavior influences the trajectories of individual\nentities. To address such problems, we present a new hierarchical\nswitching-state model that can be trained in an unsupervised fashion to\nsimultaneously explain both system-level and individual-level dynamics. We\nemploy a latent system-level discrete state Markov chain that drives latent\nentity-level chains which in turn govern the dynamics of each observed time\nseries. Feedback from the observations to the chains at both the entity and\nsystem levels improves flexibility via context-dependent state transitions. Our\nhierarchical switching recurrent dynamical models can be learned via\nclosed-form variational coordinate ascent updates to all latent chains that\nscale linearly in the number of individual time series. This is asymptotically\nno more costly than fitting separate models for each entity. Experiments on\nsynthetic and real datasets show that our model can produce better forecasts of\nfuture entity behavior than existing methods. Moreover, the availability of\nlatent state chains at both the entity and system level enables interpretation\nof group dynamics.",
        "updated": "2024-01-26 16:06:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14973v1"
    },
    {
        "title": "A structured regression approach for evaluating model performance across intersectional subgroups",
        "authors": "Christine HerlihyKimberly TruongAlexandra ChouldechovaMiroslav Dudik",
        "links": "http://arxiv.org/abs/2401.14893v1",
        "entry_id": "http://arxiv.org/abs/2401.14893v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14893v1",
        "summary": "Disaggregated evaluation is a central task in AI fairness assessment, with\nthe goal to measure an AI system's performance across different subgroups\ndefined by combinations of demographic or other sensitive attributes. The\nstandard approach is to stratify the evaluation data across subgroups and\ncompute performance metrics separately for each group. However, even for\nmoderately-sized evaluation datasets, sample sizes quickly get small once\nconsidering intersectional subgroups, which greatly limits the extent to which\nintersectional groups are considered in many disaggregated evaluations. In this\nwork, we introduce a structured regression approach to disaggregated evaluation\nthat we demonstrate can yield reliable system performance estimates even for\nvery small subgroups. We also provide corresponding inference strategies for\nconstructing confidence intervals and explore how goodness-of-fit testing can\nyield insight into the structure of fairness-related harms experienced by\nintersectional groups. We evaluate our approach on two publicly available\ndatasets, and several variants of semi-synthetic data. The results show that\nour method is considerably more accurate than the standard approach, especially\nfor small subgroups, and goodness-of-fit testing helps identify the key factors\nthat drive differences in performance.",
        "updated": "2024-01-26 14:21:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14893v1"
    },
    {
        "title": "P3LS: Partial Least Squares under Privacy Preservation",
        "authors": "Du Nguyen DuyRamin Nikzad-Langerodi",
        "links": "http://arxiv.org/abs/2401.14884v1",
        "entry_id": "http://arxiv.org/abs/2401.14884v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14884v1",
        "summary": "Modern manufacturing value chains require intelligent orchestration of\nprocesses across company borders in order to maximize profits while fostering\nsocial and environmental sustainability. However, the implementation of\nintegrated, systems-level approaches for data-informed decision-making along\nvalue chains is currently hampered by privacy concerns associated with\ncross-organizational data exchange and integration. We here propose\nPrivacy-Preserving Partial Least Squares (P3LS) regression, a novel federated\nlearning technique that enables cross-organizational data integration and\nprocess modeling with privacy guarantees. P3LS involves a singular value\ndecomposition (SVD) based PLS algorithm and employs removable, random masks\ngenerated by a trusted authority in order to protect the privacy of the data\ncontributed by each data holder. We demonstrate the capability of P3LS to\nvertically integrate process data along a hypothetical value chain consisting\nof three parties and to improve the prediction performance on several\nprocess-related key performance indicators. Furthermore, we show the numerical\nequivalence of P3LS and PLS model components on simulated data and provide a\nthorough privacy analysis of the former. Moreover, we propose a mechanism for\ndetermining the relevance of the contributed data to the problem being\naddressed, thus creating a basis for quantifying the contribution of\nparticipants.",
        "updated": "2024-01-26 14:08:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14884v1"
    },
    {
        "title": "Particle-MALA and Particle-mGRAD: Gradient-based MCMC methods for high-dimensional state-space models",
        "authors": "Adrien CorenflosAxel Finke",
        "links": "http://arxiv.org/abs/2401.14868v1",
        "entry_id": "http://arxiv.org/abs/2401.14868v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14868v1",
        "summary": "State-of-the-art methods for Bayesian inference in state-space models are (a)\nconditional sequential Monte Carlo (CSMC) algorithms; (b) sophisticated\n'classical' MCMC algorithms like MALA, or mGRAD from Titsias and\nPapaspiliopoulos (2018, arXiv:1610.09641v3 [stat.ML]). The former propose $N$\nparticles at each time step to exploit the model's 'decorrelation-over-time'\nproperty and thus scale favourably with the time horizon, $T$ , but break down\nif the dimension of the latent states, $D$, is large. The latter leverage\ngradient-/prior-informed local proposals to scale favourably with $D$ but\nexhibit sub-optimal scalability with $T$ due to a lack of model-structure\nexploitation. We introduce methods which combine the strengths of both\napproaches. The first, Particle-MALA, spreads $N$ particles locally around the\ncurrent state using gradient information, thus extending MALA to $T > 1$ time\nsteps and $N > 1$ proposals. The second, Particle-mGRAD, additionally\nincorporates (conditionally) Gaussian prior dynamics into the proposal, thus\nextending the mGRAD algorithm to $T > 1$ time steps and $N > 1$ proposals. We\nprove that Particle-mGRAD interpolates between CSMC and Particle-MALA,\nresolving the 'tuning problem' of choosing between CSMC (superior for highly\ninformative prior dynamics) and Particle-MALA (superior for weakly informative\nprior dynamics). We similarly extend other 'classical' MCMC approaches like\nauxiliary MALA, aGRAD, and preconditioned Crank-Nicolson-Langevin (PCNL) to $T\n> 1$ time steps and $N > 1$ proposals. In experiments, for both highly and\nweakly informative prior dynamics, our methods substantially improve upon both\nCSMC and sophisticated 'classical' MCMC approaches.",
        "updated": "2024-01-26 13:52:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14868v1"
    }
]