[
    {
        "title": "Annotated Hands for Generative Models",
        "authors": "Yue YangAtith N GandhiGreg Turk",
        "links": "http://arxiv.org/abs/2401.15075v1",
        "entry_id": "http://arxiv.org/abs/2401.15075v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15075v1",
        "summary": "Generative models such as GANs and diffusion models have demonstrated\nimpressive image generation capabilities. Despite these successes, these\nsystems are surprisingly poor at creating images with hands. We propose a novel\ntraining framework for generative models that substantially improves the\nability of such systems to create hand images. Our approach is to augment the\ntraining images with three additional channels that provide annotations to\nhands in the image. These annotations provide additional structure that coax\nthe generative model to produce higher quality hand images. We demonstrate this\napproach on two different generative models: a generative adversarial network\nand a diffusion model. We demonstrate our method both on a new synthetic\ndataset of hand images and also on real photographs that contain hands. We\nmeasure the improved quality of the generated hands through higher confidence\nin finger joint identification using an off-the-shelf hand detector.",
        "updated": "2024-01-26 18:57:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15075v1"
    },
    {
        "title": "Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning",
        "authors": "Md Mushfiqur RahmanMohammad Sabik IrbazKai NorthMichelle S. WilliamsMarcos ZampieriKevin Lybarger",
        "links": "http://arxiv.org/abs/2401.15043v1",
        "entry_id": "http://arxiv.org/abs/2401.15043v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15043v1",
        "summary": "Objective: The reading level of health educational materials significantly\ninfluences information understandability and accessibility, particularly for\nminoritized populations. Many patient educational resources surpass the reading\nlevel and complexity of widely accepted standards. There is a critical need for\nhigh-performing text simplification models in health information to enhance\ndissemination and literacy. This need is particularly acute in cancer\neducation, where effective prevention and screening education can substantially\nreduce morbidity and mortality.\n  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel\ncorpus of cancer education materials tailored for health text simplification\nresearch. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore\nLarge Language Model (LLM)-based simplification methods, including fine-tuning,\nreinforcement learning (RL), reinforcement learning with human feedback (RLHF),\ndomain adaptation, and prompt-based approaches. Our experimentation encompasses\nLlama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a\nlightweight model adept at distinguishing between original and simplified\ntexts, thereby enhancing the model's effectiveness with unlabeled data.\n  Results: Fine-tuned Llama 2 models demonstrated high performance across\nvarious metrics. Our innovative RLHF reward function surpassed existing RL text\nsimplification reward functions in effectiveness. The results underscore that\nRL/RLHF can augment fine-tuning, facilitating model training on unlabeled text\nand improving performance. Additionally, these methods effectively adapt\nout-of-domain text simplification models to targeted domains.",
        "updated": "2024-01-26 18:13:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15043v1"
    },
    {
        "title": "PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models",
        "authors": "Haochen TanZhijiang GuoZhan ShiLu XuZhili LiuXiaoguang LiYasheng WangLifeng ShangQun LiuLinqi Song",
        "links": "http://arxiv.org/abs/2401.15042v1",
        "entry_id": "http://arxiv.org/abs/2401.15042v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15042v1",
        "summary": "Large Language Models (LLMs) have exhibited remarkable success in long-form\ncontext comprehension tasks. However, their capacity to generate long contents,\nsuch as reports and articles, remains insufficiently explored. Current\nbenchmarks do not adequately assess LLMs' ability to produce informative and\ncomprehensive content, necessitating a more rigorous evaluation approach. In\nthis study, we introduce \\textsc{ProxyQA}, a framework for evaluating long-form\ntext generation, comprising in-depth human-curated \\textit{meta-questions}\nspanning various domains. Each meta-question contains corresponding\n\\textit{proxy-questions} with annotated answers. LLMs are prompted to generate\nextensive content in response to these meta-questions. Utilizing an evaluator\nand incorporating generated content as background context, \\textsc{ProxyQA}\nevaluates the quality of generated content based on the evaluator's performance\nin answering the \\textit{proxy-questions}. We examine multiple LLMs,\nemphasizing \\textsc{ProxyQA}'s demanding nature as a high-quality assessment\ntool. Human evaluation demonstrates that evaluating through\n\\textit{proxy-questions} is a highly self-consistent and\nhuman-criteria-correlated validation method. The dataset and leaderboard will\nbe available at \\url{https://github.com/Namco0816/ProxyQA}.",
        "updated": "2024-01-26 18:12:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15042v1"
    },
    {
        "title": "Airavata: Introducing Hindi Instruction-tuned LLM",
        "authors": "Jay GalaThanmay JayakumarJaavid Aktar HusainAswanth Kumar MMohammed Safi Ur Rahman KhanDiptesh KanojiaRatish PuduppullyMitesh M. KhapraRaj DabreRudra MurthyAnoop Kunchukuttan",
        "links": "http://arxiv.org/abs/2401.15006v1",
        "entry_id": "http://arxiv.org/abs/2401.15006v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15006v1",
        "summary": "We announce the initial release of \"Airavata,\" an instruction-tuned LLM for\nHindi. Airavata was created by fine-tuning OpenHathi with diverse,\ninstruction-tuning Hindi datasets to make it better suited for assistive tasks.\nAlong with the model, we also share the IndicInstruct dataset, which is a\ncollection of diverse instruction-tuning datasets to enable further research\nfor Indic LLMs. Additionally, we present evaluation benchmarks and a framework\nfor assessing LLM performance across tasks in Hindi. Currently, Airavata\nsupports Hindi, but we plan to expand this to all 22 scheduled Indic languages.\nYou can access all artifacts at https://ai4bharat.github.io/airavata.",
        "updated": "2024-01-26 17:07:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15006v1"
    },
    {
        "title": "Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing",
        "authors": "Guadalupe OrtizMeftah ZouaiOkba KazarAlfonso Garcia-de-PradoJuan Boubeta-Puig",
        "links": "http://dx.doi.org/10.1016/j.csi.2021.103550",
        "entry_id": "http://arxiv.org/abs/2401.14968v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14968v1",
        "summary": "The Internet of Things (IoT) has grown significantly in popularity,\naccompanied by increased capacity and lower cost of communications, and\noverwhelming development of technologies. At the same time, big data and\nreal-time data analysis have taken on great importance and have been\naccompanied by unprecedented interest in sharing data among citizens, public\nadministrations and other organisms, giving rise to what is known as the\nCollaborative Internet of Things. This growth in data and infrastructure must\nbe accompanied by a software architecture that allows its exploitation.\nAlthough there are various proposals focused on the exploitation of the IoT at\nedge, fog and/or cloud levels, it is not easy to find a software solution that\nexploits the three tiers together, taking maximum advantage not only of the\nanalysis of contextual and situational data at each tier, but also of two-way\ncommunications between adjacent ones. In this paper, we propose an architecture\nthat solves these deficiencies by proposing novel technologies which are\nappropriate for managing the resources of each tier: edge, fog and cloud. In\naddition, the fact that two-way communications along the three tiers of the\narchitecture is allowed considerably enriches the contextual and situational\ninformation in each layer, and substantially assists decision making in real\ntime. The paper illustrates the proposed software architecture through a case\nstudy of respiratory disease surveillance in hospitals. As a result, the\nproposed architecture permits efficient communications between the different\ntiers responding to the needs of these types of IoT scenarios.",
        "updated": "2024-01-26 16:01:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14968v1"
    }
]