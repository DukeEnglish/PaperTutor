[
    {
        "title": "EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty",
        "authors": "Yuhui LiFangyun WeiChao ZhangHongyang Zhang",
        "links": "http://arxiv.org/abs/2401.15077v1",
        "entry_id": "http://arxiv.org/abs/2401.15077v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15077v1",
        "summary": "Auto-regressive decoding makes the inference of Large Language Models (LLMs)\ntime-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm\nfor Greater Language-model Efficiency), for lossless acceleration. Unlike\ntraditional speculative sampling methods, EAGLE operates the drafting process\nauto-regressively at the more regular (second-top-layer) feature level and\naddresses the sampling uncertainty issues in the next-feature prediction\nproblems by integrating tokens from one time step ahead. The acceleration\nprovided by EAGLE is lossless: it involves no fine-tuning of the target LLM,\nand the generated text maintains the same distribution as that of vanilla\nauto-regressive decoding. As of the submission of this paper, EAGLE is the\nfastest known framework within the speculative sampling family. On MT-bench,\nEAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x\nfaster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with\nLLaMA2-Chat 13B on a single RTX 3090 GPU, compared to 24 tokens/s of\nHuggingface's implementations.",
        "updated": "2024-01-26 18:59:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15077v1"
    },
    {
        "title": "Pairing Orthographically Variant Literary Words to Standard Equivalents Using Neural Edit Distance Models",
        "authors": "Craig MessnerTom Lippincott",
        "links": "http://arxiv.org/abs/2401.15068v1",
        "entry_id": "http://arxiv.org/abs/2401.15068v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15068v1",
        "summary": "We present a novel corpus consisting of orthographically variant words found\nin works of 19th century U.S. literature annotated with their corresponding\n\"standard\" word pair. We train a set of neural edit distance models to pair\nthese variants with their standard forms, and compare the performance of these\nmodels to the performance of a set of neural edit distance models trained on a\ncorpus of orthographic errors made by L2 English learners. Finally, we analyze\nthe relative performance of these models in the light of different negative\ntraining sample generation strategies, and offer concluding remarks on the\nunique challenge literary orthographic variation poses to string pairing\nmethodologies.",
        "updated": "2024-01-26 18:49:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15068v1"
    },
    {
        "title": "Deep learning-based approach for tomato classification in complex scenes",
        "authors": "Mikael A. MousseBethel C. A. R. K. AtohounCina Motamed",
        "links": "http://arxiv.org/abs/2401.15055v1",
        "entry_id": "http://arxiv.org/abs/2401.15055v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15055v1",
        "summary": "Tracking ripening tomatoes is time consuming and labor intensive. Artificial\nintelligence technologies combined with those of computer vision can help users\noptimize the process of monitoring the ripening status of plants. To this end,\nwe have proposed a tomato ripening monitoring approach based on deep learning\nin complex scenes. The objective is to detect mature tomatoes and harvest them\nin a timely manner. The proposed approach is declined in two parts. Firstly,\nthe images of the scene are transmitted to the pre-processing layer. This\nprocess allows the detection of areas of interest (area of the image containing\ntomatoes). Then, these images are used as input to the maturity detection\nlayer. This layer, based on a deep neural network learning algorithm,\nclassifies the tomato thumbnails provided to it in one of the following five\ncategories: green, brittle, pink, pale red, mature red. The experiments are\nbased on images collected from the internet gathered through searches using\ntomato state across diverse languages including English, German, French, and\nSpanish. The experimental results of the maturity detection layer on a dataset\ncomposed of images of tomatoes taken under the extreme conditions, gave a good\nclassification rate.",
        "updated": "2024-01-26 18:33:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15055v1"
    },
    {
        "title": "LongFin: A Multimodal Document Understanding Model for Long Financial Domain Documents",
        "authors": "Ahmed MasryAmir Hajian",
        "links": "http://arxiv.org/abs/2401.15050v1",
        "entry_id": "http://arxiv.org/abs/2401.15050v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15050v1",
        "summary": "Document AI is a growing research field that focuses on the comprehension and\nextraction of information from scanned and digital documents to make everyday\nbusiness operations more efficient. Numerous downstream tasks and datasets have\nbeen introduced to facilitate the training of AI models capable of parsing and\nextracting information from various document types such as receipts and scanned\nforms. Despite these advancements, both existing datasets and models fail to\naddress critical challenges that arise in industrial contexts. Existing\ndatasets primarily comprise short documents consisting of a single page, while\nexisting models are constrained by a limited maximum length, often set at 512\ntokens. Consequently, the practical application of these methods in financial\nservices, where documents can span multiple pages, is severely impeded. To\novercome these challenges, we introduce LongFin, a multimodal document AI model\ncapable of encoding up to 4K tokens. We also propose the LongForms dataset, a\ncomprehensive financial dataset that encapsulates several industrial challenges\nin financial documents. Through an extensive evaluation, we demonstrate the\neffectiveness of the LongFin model on the LongForms dataset, surpassing the\nperformance of existing public models while maintaining comparable results on\nexisting single-page benchmarks.",
        "updated": "2024-01-26 18:23:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15050v1"
    },
    {
        "title": "Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning",
        "authors": "Md Mushfiqur RahmanMohammad Sabik IrbazKai NorthMichelle S. WilliamsMarcos ZampieriKevin Lybarger",
        "links": "http://arxiv.org/abs/2401.15043v1",
        "entry_id": "http://arxiv.org/abs/2401.15043v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15043v1",
        "summary": "Objective: The reading level of health educational materials significantly\ninfluences information understandability and accessibility, particularly for\nminoritized populations. Many patient educational resources surpass the reading\nlevel and complexity of widely accepted standards. There is a critical need for\nhigh-performing text simplification models in health information to enhance\ndissemination and literacy. This need is particularly acute in cancer\neducation, where effective prevention and screening education can substantially\nreduce morbidity and mortality.\n  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel\ncorpus of cancer education materials tailored for health text simplification\nresearch. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore\nLarge Language Model (LLM)-based simplification methods, including fine-tuning,\nreinforcement learning (RL), reinforcement learning with human feedback (RLHF),\ndomain adaptation, and prompt-based approaches. Our experimentation encompasses\nLlama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a\nlightweight model adept at distinguishing between original and simplified\ntexts, thereby enhancing the model's effectiveness with unlabeled data.\n  Results: Fine-tuned Llama 2 models demonstrated high performance across\nvarious metrics. Our innovative RLHF reward function surpassed existing RL text\nsimplification reward functions in effectiveness. The results underscore that\nRL/RLHF can augment fine-tuning, facilitating model training on unlabeled text\nand improving performance. Additionally, these methods effectively adapt\nout-of-domain text simplification models to targeted domains.",
        "updated": "2024-01-26 18:13:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15043v1"
    }
]