[
    {
        "title": "Color Maker: a Mixed-Initiative Approach to Creating Accessible Color Maps",
        "authors": "Amey SalviKecheng LuMichael E. PapkaYunhai WangKhairi Reda",
        "links": "http://dx.doi.org/10.1145/3613904.3642265",
        "entry_id": "http://arxiv.org/abs/2401.15032v1",
        "pdf_url": "http://arxiv.org/pdf/2401.15032v1",
        "summary": "Quantitative data is frequently represented using color, yet designing\neffective color mappings is a challenging task, requiring one to balance\nperceptual standards with personal color preference. Current design tools\neither overwhelm novices with complexity or offer limited customization\noptions. We present ColorMaker, a mixed-initiative approach for creating\ncolormaps. ColorMaker combines fluid user interaction with real-time\noptimization to generate smooth, continuous color ramps. Users specify their\nloose color preferences while leaving the algorithm to generate precise color\nsequences, meeting both designer needs and established guidelines. ColorMaker\ncan create new colormaps, including designs accessible for people with\ncolor-vision deficiencies, starting from scratch or with only partial input,\nthus supporting ideation and iterative refinement. We show that our approach\ncan generate designs with similar or superior perceptual characteristics to\nstandard colormaps. A user study demonstrates how designers of varying skill\nlevels can use this tool to create custom, high-quality colormaps. ColorMaker\nis available at https://colormaker.org",
        "updated": "2024-01-26 17:48:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.15032v1"
    },
    {
        "title": "Robust Dual-Modal Speech Keyword Spotting for XR Headsets",
        "authors": "Zhuojiang CaiYuhan MaFeng Lu",
        "links": "http://arxiv.org/abs/2401.14978v1",
        "entry_id": "http://arxiv.org/abs/2401.14978v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14978v1",
        "summary": "While speech interaction finds widespread utility within the Extended Reality\n(XR) domain, conventional vocal speech keyword spotting systems continue to\ngrapple with formidable challenges, including suboptimal performance in noisy\nenvironments, impracticality in situations requiring silence, and\nsusceptibility to inadvertent activations when others speak nearby. These\nchallenges, however, can potentially be surmounted through the cost-effective\nfusion of voice and lip movement information. Consequently, we propose a novel\nvocal-echoic dual-modal keyword spotting system designed for XR headsets. We\ndevise two different modal fusion approches and conduct experiments to test the\nsystem's performance across diverse scenarios. The results show that our\ndual-modal system not only consistently outperforms its single-modal\ncounterparts, demonstrating higher precision in both typical and noisy\nenvironments, but also excels in accurately identifying silent utterances.\nFurthermore, we have successfully applied the system in real-time\ndemonstrations, achieving promising results. The code is available at\nhttps://github.com/caizhuojiang/VE-KWS.",
        "updated": "2024-01-26 16:09:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14978v1"
    },
    {
        "title": "\"It's Sink or Swim'': Exploring Patients' Challenges and Tool Needs for Self-Management of Postoperative Acute Pain",
        "authors": "Souleima ZghabGabrielle PagéMélanie LussierSylvain BédardJinghui Cheng",
        "links": "http://dx.doi.org/10.1145/3613904.3642916",
        "entry_id": "http://arxiv.org/abs/2401.14972v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14972v1",
        "summary": "Poorly managed postoperative acute pain can have long-lasting negative\nimpacts and pose a major healthcare issue. There is limited investigation to\nunderstand and address the unique needs of patients experiencing acute pain. In\nthis paper, we tackle this gap through an interview study with 14 patients who\nrecently underwent postoperative acute pain to understand their challenges in\npain self-management and their need for supportive tools. Our analysis\nidentified various factors associated with the major aspects of acute pain\nself-management. Together, our findings indicated that tools for supporting\nthese patients need to carefully consider information and support delivery to\nadapt to rapid changes in pain experiences, offer personalized and dynamic\nassistance that adapts to individual situations in context, and monitor emotion\nwhen promoting motivation. Overall, our work provided valuable knowledge to\naddress the less-investigated but highly-needed problem of designing technology\nfor the self-management of acute pain and similar health conditions.",
        "updated": "2024-01-26 16:05:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14972v1"
    },
    {
        "title": "Reassessing Java Code Readability Models with a Human-Centered Approach",
        "authors": "Agnia SergeyukOlga LvovaSergey TitovAnastasiia SerovaFarid BagirovEvgeniia KirillovaTimofey Bryksin",
        "links": "http://arxiv.org/abs/2401.14936v1",
        "entry_id": "http://arxiv.org/abs/2401.14936v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14936v1",
        "summary": "To ensure that Large Language Models (LLMs) effectively support user\nproductivity, they need to be adjusted. Existing Code Readability (CR) models\ncan guide this alignment. However, there are concerns about their relevance in\nmodern software engineering since they often miss the developers' notion of\nreadability and rely on outdated code. This research assesses existing Java CR\nmodels for LLM adjustments, measuring the correlation between their and\ndevelopers' evaluations of AI-generated Java code. Using the Repertory Grid\nTechnique with 15 developers, we identified 12 key code aspects influencing CR\nthat were consequently assessed by 390 programmers when labeling 120\nAI-generated snippets. Our findings indicate that when AI generates concise and\nexecutable code, it is often considered readable by CR models and developers.\nHowever, a limited correlation between these evaluations underscores the\nimportance of future research on learning objectives for adjusting LLMs and on\nthe aspects influencing CR evaluations included in predictive models.",
        "updated": "2024-01-26 15:18:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14936v1"
    },
    {
        "title": "Appropriateness of LLM-equipped Robotic Well-being Coach Language in the Workplace: A Qualitative Evaluation",
        "authors": "Micol SpitaleMinja AxelssonHatice Gunes",
        "links": "http://arxiv.org/abs/2401.14935v1",
        "entry_id": "http://arxiv.org/abs/2401.14935v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14935v1",
        "summary": "Robotic coaches have been recently investigated to promote mental well-being\nin various contexts such as workplaces and homes. With the widespread use of\nLarge Language Models (LLMs), HRI researchers are called to consider language\nappropriateness when using such generated language for robotic mental\nwell-being coaches in the real world. Therefore, this paper presents the first\nwork that investigated the language appropriateness of robot mental well-being\ncoach in the workplace. To this end, we conducted an empirical study that\ninvolved 17 employees who interacted over 4 weeks with a robotic mental\nwell-being coach equipped with LLM-based capabilities. After the study, we\nindividually interviewed them and we conducted a focus group of 1.5 hours with\n11 of them. The focus group consisted of: i) an ice-breaking activity, ii)\nevaluation of robotic coach language appropriateness in various scenarios, and\niii) listing shoulds and shouldn'ts for designing appropriate robotic coach\nlanguage for mental well-being. From our qualitative evaluation, we found that\na language-appropriate robotic coach should (1) ask deep questions which\nexplore feelings of the coachees, rather than superficial questions, (2)\nexpress and show emotional and empathic understanding of the context, and (3)\nnot make any assumptions without clarifying with follow-up questions to avoid\nbias and stereotyping. These results can inform the design of\nlanguage-appropriate robotic coach to promote mental well-being in real-world\ncontexts.",
        "updated": "2024-01-26 15:17:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14935v1"
    }
]