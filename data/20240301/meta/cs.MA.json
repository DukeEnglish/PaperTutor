[
    {
        "title": "Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning",
        "authors": "Zeyang LiuLipeng WanXinrui YangZhuoran ChenXingyu ChenXuguang Lan",
        "links": "http://arxiv.org/abs/2402.17978v1",
        "entry_id": "http://arxiv.org/abs/2402.17978v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17978v1",
        "summary": "Effective exploration is crucial to discovering optimal strategies for\nmulti-agent reinforcement learning (MARL) in complex coordination tasks.\nExisting methods mainly utilize intrinsic rewards to enable committed\nexploration or use role-based learning for decomposing joint action spaces\ninstead of directly conducting a collective search in the entire\naction-observation space. However, they often face challenges obtaining\nspecific joint action sequences to reach successful states in long-horizon\ntasks. To address this limitation, we propose Imagine, Initialize, and Explore\n(IIE), a novel method that offers a promising solution for efficient\nmulti-agent exploration in complex scenarios. IIE employs a transformer model\nto imagine how the agents reach a critical state that can influence each\nother's transition functions. Then, we initialize the environment at this state\nusing a simulator before the exploration phase. We formulate the imagination as\na sequence modeling problem, where the states, observations, prompts, actions,\nand rewards are predicted autoregressively. The prompt consists of\ntimestep-to-go, return-to-go, influence value, and one-shot demonstration,\nspecifying the desired state and trajectory as well as guiding the action\ngeneration. By initializing agents at the critical states, IIE significantly\nincreases the likelihood of discovering potentially important under-explored\nregions. Despite its simplicity, empirical results demonstrate that our method\noutperforms multi-agent exploration baselines on the StarCraft Multi-Agent\nChallenge (SMAC) and SMACv2 environments. Particularly, IIE shows improved\nperformance in the sparse-reward SMAC tasks and produces more effective\ncurricula over the initialized states than other generative methods, such as\nCVAE-GAN and diffusion models.",
        "updated": "2024-02-28 01:45:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17978v1"
    },
    {
        "title": "A Heterogeneous Agent Model of Mortgage Servicing: An Income-based Relief Analysis",
        "authors": "Deepeka GargBenjamin Patrick EvansLeo ArdonAnnapoorani Lakshmi NarayananJared VannUdari MadhushaniMakada Henry-NickieSumitra Ganesh",
        "links": "http://arxiv.org/abs/2402.17932v2",
        "entry_id": "http://arxiv.org/abs/2402.17932v2",
        "pdf_url": "http://arxiv.org/pdf/2402.17932v2",
        "summary": "Mortgages account for the largest portion of household debt in the United\nStates, totaling around \\$12 trillion nationwide. In times of financial\nhardship, alleviating mortgage burdens is essential for supporting affected\nhouseholds. The mortgage servicing industry plays a vital role in offering this\nassistance, yet there has been limited research modelling the complex\nrelationship between households and servicers. To bridge this gap, we developed\nan agent-based model that explores household behavior and the effectiveness of\nrelief measures during financial distress. Our model represents households as\nadaptive learning agents with realistic financial attributes. These households\nexperience exogenous income shocks, which may influence their ability to make\nmortgage payments. Mortgage servicers provide relief options to these\nhouseholds, who then choose the most suitable relief based on their unique\nfinancial circumstances and individual preferences. We analyze the impact of\nvarious external shocks and the success of different mortgage relief strategies\non specific borrower subgroups. Through this analysis, we show that our model\ncan not only replicate real-world mortgage studies but also act as a tool for\nconducting a broad range of what-if scenario analyses. Our approach offers\nfine-grained insights that can inform the development of more effective and\ninclusive mortgage relief solutions.",
        "updated": "2024-02-29 14:21:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17932v2"
    },
    {
        "title": "Independent Learning in Constrained Markov Potential Games",
        "authors": "Philip JordanAnas BarakatNiao He",
        "links": "http://arxiv.org/abs/2402.17885v1",
        "entry_id": "http://arxiv.org/abs/2402.17885v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17885v1",
        "summary": "Constrained Markov games offer a formal mathematical framework for modeling\nmulti-agent reinforcement learning problems where the behavior of the agents is\nsubject to constraints. In this work, we focus on the recently introduced class\nof constrained Markov Potential Games. While centralized algorithms have been\nproposed for solving such constrained games, the design of converging\nindependent learning algorithms tailored for the constrained setting remains an\nopen question. We propose an independent policy gradient algorithm for learning\napproximate constrained Nash equilibria: Each agent observes their own actions\nand rewards, along with a shared state. Inspired by the optimization\nliterature, our algorithm performs proximal-point-like updates augmented with a\nregularized constraint set. Each proximal step is solved inexactly using a\nstochastic switching gradient algorithm. Notably, our algorithm can be\nimplemented independently without a centralized coordination mechanism\nrequiring turn-based agent updates. Under some technical constraint\nqualification conditions, we establish convergence guarantees towards\nconstrained approximate Nash equilibria. We perform simulations to illustrate\nour results.",
        "updated": "2024-02-27 20:57:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17885v1"
    },
    {
        "title": "A Multi-Agent Model for Opinion Evolution under Cognitive Biases",
        "authors": "Mário S. AlvimArtur Gaspar da SilvaSophia KnightFrank Valencia",
        "links": "http://arxiv.org/abs/2402.17615v1",
        "entry_id": "http://arxiv.org/abs/2402.17615v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17615v1",
        "summary": "We generalize the DeGroot model for opinion dynamics to better capture\nrealistic social scenarios. We introduce a model where each agent has their own\nindividual cognitive biases. Society is represented as a directed graph whose\nedges indicate how much agents influence one another. Biases are represented as\nthe functions in the square region $[-1,1]^2$ and categorized into four\nsub-regions based on the potential reactions they may elicit in an agent during\ninstances of opinion disagreement. Under the assumption that each bias of every\nagent is a continuous function within the region of receptive but resistant\nreactions ($\\mathbf{R}$), we show that the society converges to a consensus if\nthe graph is strongly connected. Under the same assumption, we also establish\nthat the entire society converges to a unanimous opinion if and only if the\nsource components of the graph-namely, strongly connected components with no\nexternal influence-converge to that opinion. We illustrate that convergence is\nnot guaranteed for strongly connected graphs when biases are either\ndiscontinuous functions in $\\mathbf{R}$ or not included in $\\mathbf{R}$. We\nshowcase our model through a series of examples and simulations, offering\ninsights into how opinions form in social networks under cognitive biases.",
        "updated": "2024-02-27 15:44:12 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17615v1"
    },
    {
        "title": "Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas",
        "authors": "Hao GuoChunjiang MuYang ChenChen ShenShuyue HuZhen Wang",
        "links": "http://arxiv.org/abs/2402.17270v1",
        "entry_id": "http://arxiv.org/abs/2402.17270v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17270v1",
        "summary": "The study of cooperation within social dilemmas has long been a fundamental\ntopic across various disciplines, including computer science and social\nscience. Recent advancements in Artificial Intelligence (AI) have significantly\nreshaped this field, offering fresh insights into understanding and enhancing\ncooperation. This survey examines three key areas at the intersection of AI and\ncooperation in social dilemmas. First, focusing on multi-agent cooperation, we\nreview the intrinsic and external motivations that support cooperation among\nrational agents, and the methods employed to develop effective strategies\nagainst diverse opponents. Second, looking into human-agent cooperation, we\ndiscuss the current AI algorithms for cooperating with humans and the human\nbiases towards AI agents. Third, we review the emergent field of leveraging AI\nagents to enhance cooperation among humans. We conclude by discussing future\nresearch avenues, such as using large language models, establishing unified\ntheoretical frameworks, revisiting existing theories of human cooperation, and\nexploring multiple real-world applications.",
        "updated": "2024-02-27 07:31:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17270v1"
    }
]