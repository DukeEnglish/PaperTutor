[
    {
        "title": "Mental Models of Meeting Goals: Supporting Intentionality in Meeting Technologies",
        "authors": "Ava Elizabeth ScottLev TankelevitchSean Rintel",
        "links": "http://arxiv.org/abs/2402.18526v1",
        "entry_id": "http://arxiv.org/abs/2402.18526v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18526v1",
        "summary": "Ineffective meetings due to unclear goals are major obstacles to\nproductivity, yet support for intentionality is surprisingly scant in our\nmeeting and allied workflow technologies. To design for intentionality, we need\nto understand workers' attitudes and practices around goals. We interviewed 21\nemployees of a global technology company and identified contrasting mental\nmodels of meeting goals: meetings as a means to an end, and meetings as an end\nin themselves. We explore how these mental models impact how meeting goals\narise, goal prioritization, obstacles to considering goals, and how lack of\nalignment around goals may create tension between organizers and attendees. We\nhighlight the challenges in balancing preparation, constraining scope, and\nclear outcomes, with the need for intentional adaptability and discovery in\nmeetings. Our findings have implications for designing systems which increase\neffectiveness in meetings by catalyzing intentionality and reducing tension in\nthe organisation of meetings.",
        "updated": "2024-02-28 18:06:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18526v1"
    },
    {
        "title": "Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration",
        "authors": "Crystal QianJames Wexler",
        "links": "http://arxiv.org/abs/2402.18498v1",
        "entry_id": "http://arxiv.org/abs/2402.18498v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18498v1",
        "summary": "Although recent developments in generative AI have greatly enhanced the\ncapabilities of conversational agents such as Google's Bard or OpenAI's\nChatGPT, it's unclear whether the usage of these agents aids users across\nvarious contexts. To better understand how access to conversational AI affects\nproductivity and trust, we conducted a mixed-methods, task-based user study,\nobserving 76 software engineers (N=76) as they completed a programming exam\nwith and without access to Bard. Effects on performance, efficiency,\nsatisfaction, and trust vary depending on user expertise, question type\n(open-ended \"solve\" questions vs. definitive \"search\" questions), and\nmeasurement type (demonstrated vs. self-reported). Our findings include\nevidence of automation complacency, increased reliance on the AI over the\ncourse of the task, and increased performance for novices on \"solve\"-type\nquestions when using the AI. We discuss common behaviors, design\nrecommendations, and impact considerations to improve collaborations with\nconversational AI.",
        "updated": "2024-02-28 17:26:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18498v1"
    },
    {
        "title": "Human-Centric Aware UAV Trajectory Planning in Search and Rescue Missions Employing Multi-Objective Reinforcement Learning with AHP and Similarity-Based Experience Replay",
        "authors": "Mahya RamezaniJose Luis Sanchez-Lopez",
        "links": "http://arxiv.org/abs/2402.18487v1",
        "entry_id": "http://arxiv.org/abs/2402.18487v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18487v1",
        "summary": "The integration of Unmanned Aerial Vehicles (UAVs) into Search and Rescue\n(SAR) missions presents a promising avenue for enhancing operational efficiency\nand effectiveness. However, the success of these missions is not solely\ndependent on the technical capabilities of the drones but also on their\nacceptance and interaction with humans on the ground. This paper explores the\neffect of human-centric factor in UAV trajectory planning for SAR missions. We\nintroduce a novel approach based on the reinforcement learning augmented with\nAnalytic Hierarchy Process and novel similarity-based experience replay to\noptimize UAV trajectories, balancing operational objectives with human comfort\nand safety considerations. Additionally, through a comprehensive survey, we\ninvestigate the impact of gender cues and anthropomorphism in UAV design on\npublic acceptance and trust, revealing significant implications for drone\ninteraction strategies in SAR. Our contributions include (1) a reinforcement\nlearning framework for UAV trajectory planning that dynamically integrates\nmulti-objective considerations, (2) an analysis of human perceptions towards\ngendered and anthropomorphized drones in SAR contexts, and (3) the application\nof similarity-based experience replay for enhanced learning efficiency in\ncomplex SAR scenarios. The findings offer valuable insights into designing UAV\nsystems that are not only technically proficient but also aligned with\nhuman-centric values.",
        "updated": "2024-02-28 17:10:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18487v1"
    },
    {
        "title": "Robotising Psychometrics: Validating Wellbeing Assessment Tools in Child-Robot Interactions",
        "authors": "Nida Itrat AbbasiGuy LabanTamsin FordPeter B JonesHatice Gunes",
        "links": "http://arxiv.org/abs/2402.18325v1",
        "entry_id": "http://arxiv.org/abs/2402.18325v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18325v1",
        "summary": "The interdisciplinary nature of Child-Robot Interaction (CRI) fosters\nincorporating measures and methodologies from many established domains.\nHowever, when employing CRI approaches to sensitive avenues of health and\nwellbeing, caution is critical in adapting metrics to retain their safety\nstandards and ensure accurate utilisation. In this work, we conducted a\nsecondary analysis to previous empirical work, investigating the reliability\nand construct validity of established psychological questionnaires such as the\nShort Moods and Feelings Questionnaire (SMFQ) and three subscales (generalised\nanxiety, panic and low mood) of the Revised Child Anxiety and Depression Scale\n(RCADS) within a CRI setting for the assessment of mental wellbeing. Through\nconfirmatory principal component analysis, we have observed that these measures\nare reliable and valid in the context of CRI. Furthermore, our analysis\nrevealed that scales communicated by a robot demonstrated a better fit than\nwhen self-reported, underscoring the efficiency and effectiveness of\nrobot-mediated psychological assessments in these settings. Nevertheless, we\nhave also observed variations in item contributions to the main factor,\nsuggesting potential areas of examination and revision (e.g., relating to\nphysiological changes, inactivity and cognitive demands) when used in CRI.\nFindings from this work highlight the importance of verifying the reliability\nand validity of standardised metrics and assessment tools when employed in CRI\nsettings, thus, aiming to avoid any misinterpretations and misrepresentations.",
        "updated": "2024-02-28 13:42:12 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18325v1"
    },
    {
        "title": "Affective State Detection using fNIRs and Machine Learning",
        "authors": "Ritam Ghosh",
        "links": "http://arxiv.org/abs/2402.18241v1",
        "entry_id": "http://arxiv.org/abs/2402.18241v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18241v1",
        "summary": "Affective states regulate our day to day to function and has a tremendous\neffect on mental and physical health. Detection of affective states is of\nutmost importance for mental health monitoring, smart entertainment selection\nand dynamic workload management. In this paper, we discussed relevant\nliterature on affective state detection using physiology data, the benefits and\nlimitations of different sensors and methods used for collecting physiology\ndata, and our rationale for selecting functional near-infrared spectroscopy. We\npresent the design of an experiment involving nine subjects to evoke the\naffective states of meditation, amusement and cognitive load and the results of\nthe attempt to classify using machine learning. A mean accuracy of 83.04% was\nachieved in three class classification with an individual model; 84.39%\naccuracy was achieved for a group model and 60.57% accuracy was achieved for\nsubject independent model using leave one out cross validation. It was found\nthat prediction accuracy for cognitive load was higher (evoked using a pen and\npaper task) than the other two classes (evoked using computer bases tasks). To\nverify that this discrepancy was not due to motor skills involved in the pen\nand paper task, a second experiment was conducted using four participants and\nthe results of that experiment has also been presented in the paper.",
        "updated": "2024-02-28 11:12:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18241v1"
    }
]