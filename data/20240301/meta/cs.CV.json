[
    {
        "title": "UniMODE: Unified Monocular 3D Object Detection",
        "authors": "Zhuoling LiXiaogang XuSerNam LimHengshuang Zhao",
        "links": "http://arxiv.org/abs/2402.18573v1",
        "entry_id": "http://arxiv.org/abs/2402.18573v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18573v1",
        "summary": "Realizing unified monocular 3D object detection, including both indoor and\noutdoor scenes, holds great importance in applications like robot navigation.\nHowever, involving various scenarios of data to train models poses challenges\ndue to their significantly different characteristics, e.g., diverse geometry\nproperties and heterogeneous domain distributions. To address these challenges,\nwe build a detector based on the bird's-eye-view (BEV) detection paradigm,\nwhere the explicit feature projection is beneficial to addressing the geometry\nlearning ambiguity when employing multiple scenarios of data to train\ndetectors. Then, we split the classical BEV detection architecture into two\nstages and propose an uneven BEV grid design to handle the convergence\ninstability caused by the aforementioned challenges. Moreover, we develop a\nsparse BEV feature projection strategy to reduce computational cost and a\nunified domain alignment method to handle heterogeneous domains. Combining\nthese techniques, a unified detector UniMODE is derived, which surpasses the\nprevious state-of-the-art on the challenging Omni3D dataset (a large-scale\ndataset including both indoor and outdoor scenes) by 4.9% AP_3D, revealing the\nfirst successful generalization of a BEV detector to unified 3D object\ndetection.",
        "updated": "2024-02-28 18:59:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18573v1"
    },
    {
        "title": "Selection of appropriate multispectral camera exposure settings and radiometric calibration methods for applications in phenotyping and precision agriculture",
        "authors": "Vaishali SwaminathanJ. Alex ThomassonRobert G. HardinNithya Rajan",
        "links": "http://arxiv.org/abs/2402.18553v1",
        "entry_id": "http://arxiv.org/abs/2402.18553v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18553v1",
        "summary": "Radiometric accuracy of data is crucial in quantitative precision\nagriculture, to produce reliable and repeatable data for modeling and decision\nmaking. The effect of exposure time and gain settings on the radiometric\naccuracy of multispectral images was not explored enough. The goal of this\nstudy was to determine if having a fixed exposure (FE) time during image\nacquisition improved radiometric accuracy of images, compared to the default\nauto-exposure (AE) settings. This involved quantifying the errors from\nauto-exposure and determining ideal exposure values within which radiometric\nmean absolute percentage error (MAPE) were minimal (< 5%). The results showed\nthat FE orthomosaic was closer to ground-truth (higher R2 and lower MAPE) than\nAE orthomosaic. An ideal exposure range was determined for capturing canopy and\nsoil objects, without loss of information from under-exposure or saturation\nfrom over-exposure. A simulation of errors from AE showed that MAPE < 5% for\nthe blue, green, red, and NIR bands and < 7% for the red edge band for exposure\nsettings within the determined ideal ranges and increased exponentially beyond\nthe ideal exposure upper limit. Further, prediction of total plant nitrogen\nuptake (g/plant) using vegetation indices (VIs) from two different growing\nseasons were closer to the ground truth (mostly, R2 > 0.40, and MAPE = 12 to\n14%, p < 0.05) when FE was used, compared to the prediction from AE images\n(mostly, R2 < 0.13, MAPE = 15 to 18%, p >= 0.05).",
        "updated": "2024-02-28 18:35:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18553v1"
    },
    {
        "title": "Gradient Reweighting: Towards Imbalanced Class-Incremental Learning",
        "authors": "Jiangpeng HeFengqing Zhu",
        "links": "http://arxiv.org/abs/2402.18528v1",
        "entry_id": "http://arxiv.org/abs/2402.18528v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18528v1",
        "summary": "Class-Incremental Learning (CIL) trains a model to continually recognize new\nclasses from non-stationary data while retaining learned knowledge. A major\nchallenge of CIL arises when applying to real-world data characterized by\nnon-uniform distribution, which introduces a dual imbalance problem involving\n(i) disparities between stored exemplars of old tasks and new class data\n(inter-phase imbalance), and (ii) severe class imbalances within each\nindividual task (intra-phase imbalance). We show that this dual imbalance issue\ncauses skewed gradient updates with biased weights in FC layers, thus inducing\nover/under-fitting and catastrophic forgetting in CIL. Our method addresses it\nby reweighting the gradients towards balanced optimization and unbiased\nclassifier learning. Additionally, we observe imbalanced forgetting where\nparadoxically the instance-rich classes suffer higher performance degradation\nduring CIL due to a larger amount of training data becoming unavailable in\nsubsequent learning phases. To tackle this, we further introduce a\ndistribution-aware knowledge distillation loss to mitigate forgetting by\naligning output logits proportionally with the distribution of lost training\ndata. We validate our method on CIFAR-100, ImageNetSubset, and Food101 across\nvarious evaluation protocols and demonstrate consistent improvements compared\nto existing works, showing great potential to apply CIL in real-world scenarios\nwith enhanced robustness and effectiveness.",
        "updated": "2024-02-28 18:08:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18528v1"
    },
    {
        "title": "Defect Detection in Tire X-Ray Images: Conventional Methods Meet Deep Structures",
        "authors": "Andrei CozmaLandon HarrisHairong QiPing JiWenpeng GuoSong Yuan",
        "links": "http://arxiv.org/abs/2402.18527v1",
        "entry_id": "http://arxiv.org/abs/2402.18527v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18527v1",
        "summary": "This paper introduces a robust approach for automated defect detection in\ntire X-ray images by harnessing traditional feature extraction methods such as\nLocal Binary Pattern (LBP) and Gray Level Co-Occurrence Matrix (GLCM) features,\nas well as Fourier and Wavelet-based features, complemented by advanced machine\nlearning techniques. Recognizing the challenges inherent in the complex\npatterns and textures of tire X-ray images, the study emphasizes the\nsignificance of feature engineering to enhance the performance of defect\ndetection systems. By meticulously integrating combinations of these features\nwith a Random Forest (RF) classifier and comparing them against advanced models\nlike YOLOv8, the research not only benchmarks the performance of traditional\nfeatures in defect detection but also explores the synergy between classical\nand modern approaches. The experimental results demonstrate that these\ntraditional features, when fine-tuned and combined with machine learning\nmodels, can significantly improve the accuracy and reliability of tire defect\ndetection, aiming to set a new standard in automated quality assurance in tire\nmanufacturing.",
        "updated": "2024-02-28 18:07:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18527v1"
    },
    {
        "title": "Multimodal Learning To Improve Cardiac Late Mechanical Activation Detection From Cine MR Images",
        "authors": "Jiarui XingNian WuKenneth BilchickFrederick EpsteinMiaomiao Zhang",
        "links": "http://arxiv.org/abs/2402.18507v1",
        "entry_id": "http://arxiv.org/abs/2402.18507v1",
        "pdf_url": "http://arxiv.org/pdf/2402.18507v1",
        "summary": "This paper presents a multimodal deep learning framework that utilizes\nadvanced image techniques to improve the performance of clinical analysis\nheavily dependent on routinely acquired standard images. More specifically, we\ndevelop a joint learning network that for the first time leverages the accuracy\nand reproducibility of myocardial strains obtained from Displacement Encoding\nwith Stimulated Echo (DENSE) to guide the analysis of cine cardiac magnetic\nresonance (CMR) imaging in late mechanical activation (LMA) detection. An image\nregistration network is utilized to acquire the knowledge of cardiac motions,\nan important feature estimator of strain values, from standard cine CMRs. Our\nframework consists of two major components: (i) a DENSE-supervised strain\nnetwork leveraging latent motion features learned from a registration network\nto predict myocardial strains; and (ii) a LMA network taking advantage of the\npredicted strain for effective LMA detection. Experimental results show that\nour proposed work substantially improves the performance of strain analysis and\nLMA detection from cine CMR images, aligning more closely with the achievements\nof DENSE.",
        "updated": "2024-02-28 17:34:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.18507v1"
    }
]