GENERALIZABILITY UNDER SENSOR FAILURE:
TOKENIZATION + TRANSFORMERS ENABLE MORE
ROBUST LATENT SPACES
GeelingChau∗,YujinAn∗,AhamedRaffeyIqbal∗,Soon-JoChung,YisongYue,SaberaTalukder
CaliforniaInstituteofTechnology,Pasadena,CA
{gchau,yan2,raffey,sjchung,yyue,sabera}@caltech.edu
ABSTRACT
Amajorgoalinneuroscienceistodiscoverneuraldatarepresentationsthatgen-
eralize. Thisgoalischallengedbyvariabilityalongrecordingsessions(e.g. envi-
ronment),subjects(e.g.varyingneuralstructures),andsensors(e.g.sensornoise),
among others. Recent work has begun to address generalization across sessions
andsubjects,butfewstudyrobustnesstosensorfailurewhichishighlyprevalent
inneuroscienceexperiments.Inordertoaddressthesegeneralizabilitydimensions
wefirstcollectourownelectroencephalographydatasetwithnumeroussessions,
subjects,andsensors,thenstudytwotimeseriesmodels:EEGNet(Lawhernetal.,
2018)andTOTEM(Talukderetal.,2024).EEGNetisawidelyusedconvolutional
neuralnetwork,whileTOTEMisadiscretetimeseriestokenizerandtransformer
model. WefindthatTOTEMoutperformsormatchesEEGNetacrossallgeneral-
izabilitycases. FinallythroughanalysisofTOTEM’slatentcodebookweobserve
thattokenizationenablesgeneralization.
1 INTRODUCTION
Neuroscienceexperimentsvaryacrossnumerousdimensionsincludingsessions,subjectsandsenors
(Gonschoreketal.,2021;Saha&Baumert,2020;Parvizi&Kastner,2018).Giventhisinherentvari-
ability,modelswithstronggeneralizationpropertiesaredesirable. Modelgeneralizabilityrefersto
a model’s zero shot capabilities, or the model’s ability to operate on test datasets unseen at train-
ing time. Prior work studies generalizability along the datasets’ session and subject dimensions
(Petersonetal.,2021;Talukderetal.,2022;Krumpeetal.,2017), butfewstudymodelgeneraliz-
ability under sensor variability. Sensors vary primarily because of sensor failure and sensor count
differences across recording sessions. Common practice is to reduce the train and test sets to the
intersectionofcleanandavailablesensorsthentrainmodels. However, thisthrowsawaydifficult-
to-obtainneuraldata. Itisthereforevaluabletobuildmodelsthatcantrainonallavailabledataand
inferunderanytypeofsensorvariability.
Toprobegeneralizabilityacrosssessions,subjects,andsensors,wesystematicallystudytwo
timeseriesmodels: EEGNet(Lawhernetal.,2018)andTOTEM(Talukderetal.,2024). EEGNetis
apopularconvolutionalneuralnetworkuponwhichmanyothermodelsarebuiltorcomparedagainst
(Petersonetal.,2021;Xuetal.,2021). EEGNetintakesaSensorxTimearrayandappliesconvo-
lutionalkernelsalongthetemporalandspatialdimensions,acommonapproachinspiredbyFilter-
BankCommonSpatialPatterns(FBCSP)Angetal.(2012). TOTEMfirstlearnsasensor-agnostic
setofdiscretetokensviaaself-supervisedvectorquantizedvariationalautoencoder,thenusesthese
pretrainedtokensastheinputtoatransformerclassifier. TOTEMexhibitsstronggeneralizationon
numeroustimeseriesdatasets(Talukderetal.,2024). Tostudythesemodels’generalizabilityacross
experimentalconditionswecreateataxonomyofgeneralizationcasesthatencompasssession,sub-
ject,andsensorvariability. Wecollectarichelectroencephalographydatasetthatpermitstestingof
these generalization cases. See Figure 1 for a visualization of cross subject generalizability under
sensorfailure.FinallyweexploreTOTEM’slatentdiscretecodebooks,asTOTEMdemonstratesthe
bestperformanceacrossexperimentsinourgeneralizationtaxonomy.
∗EqualContribution
1
4202
beF
92
]GL.sc[
2v64581.2042:viXraFigure 1: Overview. TOTEM and EEGNet train on data from subject A1, which has no failed
sensors. Both TOTEM and EEGNet are then tested on subject B2 with artificially failed sensors.
Thisisanexampleofcrosssubjectgeneralizabilityundersensorfailure.
2 METHOLODOLOGY
2.1 EXPERIMENTALDESIGN
We first define a taxonomy of a baseline and generalization cases, the cases are as follows:
BaselineCase: Within Session - train and test on the same session. GeneralizationCases: (1)
CrossSession-trainononesession,andtestonaseparatesessionfromthesamesubject. (2)Cross
Subject-trainononesubject,andtestonaseparatesubject. (3)SensorFailure-randomlyfailX%
of sensors, X ∈ {0,10,20,...,100}. Notably the within session, cross session, and cross subject
casescanbecombinedwiththesensorfailurecondition,e.g. onecanstudycrosssubjectgeneraliz-
abilityundersensorfailure(Figure1). Foravisualizationofthebaselineandgeneralizabilitycases
seeFigure2(a).
We then design and collect an electroencepholography (EEG) dataset featuring high sensor
count(128electrodes)andhightrialcount(600trials/session)acrosstwohumansubjects. Intotal
this leads to four sub-datasets across subjects A,B and sessions 1,2: A1, A2, B1, B2. Our 128
sensorsetupintroducesrelativelylargedatasetsaspreviouspubliclyavailableEEGdatasetsrarely
exceed64sensors(Stiegeretal.,2021;Kayaetal.,2018;Tangermannetal.,2012). Additionally,
muchpriorworkwithmorethan64channelscollects<200trialspersession(Gwonetal.,2023;Xu
etal.,2020)wecollect150trialsperdirection(600trialspersession).Designingourexperimentsto
generaterelativelylargedatasetsenablesourstudyofgeneralizationacrossnumerousexperimental
conditions.
Foreachsessionasubjectsatinfrontofamonitorandfixatedonacenterpointthatrandomly
changedto◀,▶,▲,and▼;◀islefthandmovement(HM),▶isrightHM,▲isbothHM,and▼is
bothfeetmovement. Ineachsessiontherewere150trialsforeachdirection,lasting3secondseach.
Afterdatacollectionweperformedminimaldataprocessingby(1)downsamplingfrom4096Hzto
2048Hz, (2) high-pass filtering at 0.5Hz, (3) average referencing, and (4) standardizing across the
entirerecording.
We chose to use EEG due to its high variance along these generalization cases, allowing us
tostudygeneralizabilityinoneofthemostdifficultdatamodalities. However,challengesregarding
sensor variation are highly prominent in larger signal-to-noise ratio recording modalities such as
electrocorticographyormulti-unitprobes(Neuropixels,Utaharrays,DBSprobes). Inthefuturewe
aimtoreplicateourEEGexperimentswithotherneuraldatarecordingmodalities,seeSection4for
furtherdiscussion.
2.2 MODELS
EEGNet from Lawhern et al. (2018) is a popularly used convolutional neural network (CNN) for
EEG decoding. It consists of temporal and spatial CNNs that learn kernels swept across these
dimensions. ItsdesignmimicsaperformantEEGprocessingpipeline,FBCSP(Angetal.(2012)),
2(a) (b)
Figure 2: (a) Visualization of baseline (within session) and generalizability cases (cross subject,
crosssession,sensorfailure)illustrated. (b)Experimentalsetup. Weteston2humansubjectseach
with128electrodesgenerating600trialspersession. AdaptedfromGarc´ıa-Murilloetal.(2023)
learningtemporalkernelsthatextractfrequencyfeatureswhichthengetweightedbylearnedspatial
filters(Figure3). EEGNettakesafixed[SensorsxTime]matrixasinput.
Figure3: EEGNetarchitecture. AdaptedfromLawhernetal.(2018)
TOTEM from Talukder et al. (2024) consists of a sensor-agnostic tokenizer which uses a
learned latent codebook, followed by a time-length flexible and sensor-count flexible transformer
classifier(Figure4). TOTEMfirstlearnsthelatentcodebookviaself-supervisiononthetimeseries
signals(Figure4(a)).Itsgoalistolearnasetofsmalltimetokensthathelpreconstructthetimeseries
signalswithlowestMSE.Thiscanbeseenaslearningadiscretetemporal“vocabulary”thatcanbe
usedto expressthedata modality’sdistributionof temporal activity. Thistokeniationtechnique is
inspiredbytheVQ-VAE(Aaronetal.(2017))whichhasbeenstudiedtobebeneficialinhelping(1)
reducenoiseinsequentialrepresentationsand(2)allowtransformerstooperateonameaningfuland
definedvocabularyset(Talukderetal.,2024). Afterthecodebooktraininghasconverged,itisthen
frozenandusedtotranslatethetimeseriesinputsintotokenizedinputsforthedownstreamtemporal
andspatialtransformers(Figure4(b)). Thesetransformersareabletooperateondifferentsequence
lengths (Vaswani et al. (2017)), providing benefits for modeling trials with different lengths and
sensoravailabilities. Wehereonlystudythecasewheretheinputsizesarenotchangedinorderto
beabletocomparewithEEGNet.
2.3 TRAINING
The600trialsineachsessionarebrokendownintofixedtraining(80%),validation(10%),andtest
(10%)sets,withineachofwhicharethenbrokendowninto250mslongindividualmini-trials. We
trainandtestonthesemini-trials. Inthebaselinewithinsessioncase,wetrain,val,andtestonthe
same session. In generalization cross session and subject cases, we train and validate on the first
3Figure4:TOTEMarchitectureandtraining. (a)Learnlatentcodebokviaself-supervision. (b)Train
transformersontokenizeddatacreatedfromfrozencodebook. AdaptedfromTalukderetal.(2024)
session,thentestonthesecondsession. Insensorfailurecases,wetrainandvalidateontheoriginal
sensorsandtestonasetwithartificiallyfailedsensors.
Sensor Failure: We simulate failure by randomly zeroing-out X% of test set sensors, where
X∈ {0,10,20,...,100}(11cases). WecannotremovesensorsasEEGNetrequiresfixedinputsize,
sowezero-outsensorsforbothmodels. Forfaircomparison,weensurebothmodelshavethesame
failedsensorsforeachrandomseed.Westudytheeffectonclassificationperformanceacrosswithin
sessionandgeneralizabilitycases.
Hyperparameterselection: Foreachmodel,weselectedasetofhyperparametersthatallowed
themodelstoconvergeandperformoptimallyonwithinsessionperformance. Wefixedthesehy-
perparametersandranallourmodelingexperimentswiththesameparametersacrossdatasets.
3 RESULTS & DISCUSSION
Wereportdecodingaccuracyacrossallgeneralizationcases(Figure5)andanalyzeTOTEM’slatent
spacestounderstandhowitsrepresentationsgeneralize(Figure6).
3.1 DECODINGACCURACYCOMPARISON
To evaluate the robustness of the latent spaces learned by each of the models, we tested their per-
formanceonthebaselinecase(withinsession)andzero-shottogeneralizationcases(crosssession,
crosssubject,andacrosssensorfailurelevels).
When analyzing the 0% sensor failure generalizability cases, we see TOTEM outperforms
EEGNetoncrosssessionandsubjectcases,andmatchEEGNetonwithinsessionperformance. On
acasebycasebasis,weseethatTOTEMbeatsEEGNetonallcrosssessionmodelingexperiments,
and beats in 4/8 cross subject modeling experiments. The within session experiments all cluster
aroundtheequalperformanceline,whichmeansthatTOTEMisabletodojustaswellasEEGNet
when evaluated at the baseline case. The difference in generalizability performance between the
twomodelswhilewithinsessiondecodingisfairlyconsistentshowsthatitisimportanttoevaluate
modelsalonggeneralizationdimensionswhenselectingformodels.
When analyzing the 10%, 30%, and 70% generalizability cases, we see that for nearly all
modeling experiments, the same generalizbility results we saw hold, with TOTEM’s performance
becomingrelativelybetterthanEEGNet’sasmoresensorsarefailed. Thiscanbeobservedbythe
dots shifting leftward and more into the green regions as more sensors are failed (Figure 5). The
withinsessiondecodingaccuraciesalsofavorTOTEMasmoresensorsarefailed,whichisbeneficial
formodelingwithinsessiondatasetswheresensorfailuremayappearrandomlywithinasession.
4Figure5: Classifierperformanceunderallgeneralizabilitycases. (a)TOTEMvsEEGNetaccuracy
forallwithinsession(black),crosssession(red),crosssubject(blue)casesacrossseveralamounts
ofsensorfailure(0%,10%,30%,70%). Ovalsin0%failurecaserepresentstandarderrorofmean
(SEM)across5modelrandomseeds. Ovalsin10%,30%,70%sensorfailureplotsrepresentSEM
across3sensorfailurerandomseeds. (b)DecodingaccuracyofTOTEM(solidline)andEEGNet
(dashedline)whentrainedonB1,andtestedagainstwithinsession(black),crosssession(red),and
crosssubject(blue)casesacross0-100%sensorfailurepercentages. Additionalperformancescan
befoundinAppendix5.1.
Whenanalyzingthetrendsofeachmodelagainstafinerresolutionofsensorfailurepercent-
ages, we see that TOTEM maintains a higher decoding accuracy for longer, while EEGNet has a
morelineardecliningperformancewithadditionalsensorsremoved(Figure5(b)). Thisisobserved
even when both models start with the same decoding accuracy, so it is not due to TOTEM simply
generalizingbetterincrosssessionandcrosssubjectcases. Additionalresultstrainedoneachofour
4sessionscanbefoundinAppendix5.1.
These results suggest that (1) TOTEM’s tokenization + transformers approach create more
generalizablerepresentationswhencomparedtoEEGNet’sCNNkernels,and(2)studyinggeneral-
izationhighlightsmodelperformancedifferencesasthewithinsessionconclusionsdifferfromthe
generalizabilityconclusions.
3.2 LATENTCODEBOOKANALYSIS
To better understand TOTEM’s generalization capabilities, we investigate its learned latent code-
bookacrosssessions, subjects, andsensoravailability. Ifthecodebookslearnedaregeneralizable,
we would expect that the codewords have corresponding matches to the codewords in the other
codebooks,allowinganewrecordingsessiontobereconstructedandrepresentedwithhighfidelity.
Indeed, when we plot the MSE between codewords across different codebooks (Figure 6(a) Cross
Subject),wefindthatthecodebooksimilaritymatricesarequalitativelycomparabletowithincode-
book(Figure6(a),WithinSession),especiallywhenwematcheachcodewordfromthenewcode-
book(A2)withitsminimumMSEcodewordintheoriginalcodebook(B1).Thematchedcodewords
alsolookhighlysimilaracrosscodebooks(Figure6(b))andarequantitativelylowinMSE.Across
thewholecodebook,theaverageMSEofmatchedcodewordsisnearzeroandamajorityofcode-
wordsareusedwhenmatching(Table1),suggestinghighoverlapbetweencodebookslearnedacross
generalizability cases. All generalization cases studied here learn similar codebooks according to
these qualitative and quantitative metrics (additional visualizations in Appendix 5.2). This shows
thatTOTEM’slearnedtokenizationspacemaybeabletolearnageneralizedcodebookforourtime
seriesdatamodalityofinterest,potentiallyallowingformasstrainingofthedownstreamtransformer
encodersusingthesametokenizedlatentspace.
4 CONCLUSION + LIMITATIONS + FUTURE WORK
We find that tokenization + transformers are a promising approach to modeling time series neu-
ral data which have high variability in datasets and recordings. Specifically, we demonstrate that
compared with one of the most performant and popular CNN models, tokenization+transformers
outperforminnumerousgeneralizationcases. Thesemodelsarealsoripeforinterpretabilityanal-
ysis which can uncover new findings about time series neural data. Our study further shows how
importantitistoconsidergeneralizabilitycaseswhenselectingmodels.
5Figure6: Codebooksimilaritymatricesandvisualizationofcodewordswithincodebooks. (a)Ma-
tricesofMSEbetweenmatchingcodewordsinthetwolabeledcodebooks. Codewordsareordered
roughlybywithinsessionmeanMSE.Coloredarrowsalongaxisdenotevisualizedcodewordshigh-
lighted in (b). (b) All codewords in each codebook. Highlighted are three examples of matched
codewords between codebooks. MSE values between codewords are: purple=0.065, pink=0.018,
orange=0.013.
AverageMSE Num. SubselectedCodewords
BaselineCase
WithinSession: B1→B1 0.0 256
GeneralizationCases
CrossSession: B1 →B2 0.06 163
sub
CrossSubject: B1 →A2 0.05 188
sub
10%sensors: B1 →B110% 0.04 194
sub
Table1: AverageMSEofmatchedcodewordsinbaselinecaseandgeneralizationcases. Numberof
SubselectedCodewordsdenotethenumberofcodewordsfromtheoriginalcodebook(B1)thatwere
matchedtothegeneralizationcodebook.
Currentlyweonlymodelsensorfailureaszeroingoutdata. Thismaskingtechniqueiswidely
used machine learning, but does not cover all sensor failure cases. Creating more sensor failure
modes is a meaningful direction for future work. Extending our interpretability analysis to the
downstreamtransformerisanothervaluablefuturedirection. Wewouldalsoliketoadapttheframe-
worktoworkwithmoretypesofneuraltimeseriesdatasuchassparselysampledneuraltimeseries
data such as LFP from neuropixels, Utah Arrays, and stereoencepholography (sEEG) recordings,
andmorevariedlayoutmodalitiessuchaselectrocortiography(ECoG).Thisworkcouldenableau-
tomatic noisy sensor detection, interesting interpretations of temporal and spatial dimensions, and
buildingoffoundationmodelsforneuraltimeseries.
6REFERENCES
Aaron,OriolVinyals,andKorayKavukcuoglu. Neuraldiscreterepresentationlearning,2017. URL
https://arxiv.org/abs/1711.00937v2.
Kai Keng Ang, Zheng Yang Chin, Chuanchu Wang, Cuntai Guan, and Haihong Zhang.
Filter bank common spatial pattern algorithm on bci competition iv datasets 2a and
2b. Frontiers in Neuroscience, 6, Jan 2012. doi: https://doi.org/10.3389/fnins.
2012.00039. URL https://www.frontiersin.org/journals/neuroscience/
articles/10.3389/fnins.2012.00039/full.
Daniel Guillermo Garc´ıa-Murillo, Andre´s Marino A´lvarez Meza, and Cesar German Castellanos-
Dominguez. Kcs-fcnet: Kernelcross-spectralfunctionalconnectivitynetworkforeeg-basedmo-
tor imagery classification. Diagnostics, 13(6):1122–1122, Mar 2023. doi: https://doi.org/10.
3390/diagnostics13061122. URLhttps://www.mdpi.com/2075-4418/13/6/1122.
Dominic Gonschorek, Larissa Ho¨fling, Klaudia P Szatko, Katrin Franke, Timm Schu-
bert, Benjamin Dunn, Philipp Berens, David Klindt, and Thomas Euler. Remov-
ing inter-experimental variability from functional data in systems neuroscience. Ad-
vances in Neural Information Processing Systems, 34:3706–3719, Dec 2021. URL
https://proceedings.neurips.cc/paper_files/paper/2021/hash/
1e5eeb40a3fce716b244599862fd2200-Abstract.html.
Daeun Gwon, Kyungho Won, Minseok Song, Chang S Nam, Sung Chan Jun, and Minkyu
Ahn. Review of public motor imagery and execution datasets in brain-computer inter-
faces. Frontiers in Human Neuroscience, 17, Mar 2023. doi: https://doi.org/10.3389/
fnhum.2023.1134869. URL https://www.frontiersin.org/articles/10.3389/
fnhum.2023.1134869/full#B76.
Murat Kaya, Mustafa Kemal Binli, Erkan Ozbay, Hilmi Yanar, and Yuriy Mishchenko. A large
electroencephalographic motor imagery dataset for electroencephalographic brain computer in-
terfaces. Scientific Data, 5(1), Oct 2018. doi: https://doi.org/10.1038/sdata.2018.211. URL
https://www.nature.com/articles/sdata2018211.
T Krumpe, K Baumga¨rtner, W Rosenstiel, and M Spu¨ler. Non-stationarity and inter-subject vari-
ability of eeg characteristics in the context of bci development. 7th Graz Brain-Computer In-
terface Conference 2017, Graz, Austria, 2017. doi: http://hdl.handle.net/10900/83769. URL
https://tobias-lib.ub.uni-tuebingen.de/xmlui/handle/10900/83769.
VernonJLawhern,AmeliaJSolon,NicholasRWaytowich,StephenMGordon,ChouPHung,and
Brent J Lance. Eegnet: a compact convolutional neural network for eeg-based brain–computer
interfaces. Journal of Neural Engineering, 15(5):056013, jul 2018. doi: 10.1088/1741-2552/
aace8c. URLhttps://dx.doi.org/10.1088/1741-2552/aace8c.
Josef Parvizi and Sabine Kastner. Promises and limitations of human intracranial elec-
troencephalography. Nature Neuroscience, 21(4):474–483, Mar 2018. doi: https:
//doi.org/10.1038/s41593-018-0108-2. URL https://www.nature.com/articles/
s41593-018-0108-2.
Steven M Peterson, Zoe Steine-Hanson, Nathan Davis, Rajesh P N Rao, and Bingni W Brunton.
Generalized neural decoders for transfer learning across participants and recording modalities.
JournalofNeuralEngineering,18(2):026014,mar2021. doi: 10.1088/1741-2552/abda0b. URL
https://dx.doi.org/10.1088/1741-2552/abda0b.
SimantoSahaandMathiasBaumert. Intra-andinter-subjectvariabilityineeg-basedsensorimotor
brain computer interface: A review. Frontiers in Computational Neuroscience, 13, Jan 2020.
doi: https://doi.org/10.3389/fncom.2019.00087. URLhttps://www.frontiersin.org/
articles/10.3389/fncom.2019.00087/full.
James R Stieger, Stephen A Engel, and Bin He. Continuous sensorimotor rhythm based brain
computer interface learning in a large population. Scientific Data, 8(1), Apr 2021. doi: https:
//doi.org/10.1038/s41597-021-00883-1. URL https://www.nature.com/articles/
s41597-021-00883-1.
7Sabera Talukder, Jennifer J. Sun, Matthew Leonard, Bingni W. Brunton, and Yisong Yue. Deep
neuralimputation:Aframeworkforrecoveringincompletebrainrecordings,2022.URLhttps:
//doi.org/10.48550/arXiv.2206.08094.
SaberaTalukder,YisongYue,andGeorgiaGkioxari. Totem: Tokenizedtimeseriesembeddingsfor
generaltimeseriesanalysis,2024. URLhttps://arxiv.org/abs/2402.16412v1.
Michael Tangermann, Klaus Robert Mu¨ller, Ad Aertsen, Niels Birbaumer, Christoph Braun,
Clemens Brunner, Robert Leeb, Carsten Mehring, Kai J Miller, Gernot R Mu¨ller-Putz,
Guido Nolte, Gert Pfurtscheller, Hubert Preissl, Gerwin Schalk, Alois Schlo¨gl, Carmen
Vidaurre, Stephan Waldert, and Benjamin Blankertz. Review of the bci competition iv.
Frontiers in Neuroscience, 6, Jan 2012. doi: https://doi.org/10.3389/fnins.2012.00055. URL
https://www.frontiersin.org/journals/neuroscience/articles/10.
3389/fnins.2012.00055/full?ref=https%3A%2F%2Fgithubhelp.com.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
LukaszKaiser,andIlliaPolosukhin. Attentionisallyouneed,2017. URLhttps://arxiv.
org/abs/1706.03762.
LichaoXu,MinpengXu,YufengKe,XingweiAn,ShuangLiu,andDongMing. Cross-datasetvari-
abilityproblemineegdecodingwithdeeplearning. FrontiersinHumanNeuroscience,14, Apr
2020. doi: https://doi.org/10.3389/fnhum.2020.00103. URLhttps://www.frontiersin.
org/articles/10.3389/fnhum.2020.00103/full.
Lichao Xu, Minpeng Xu, Zheng Ma, Kun Wang, Tzyy-Ping Jung, and Dong Ming. Enhanc-
ing transfer performance across datasets for brain-computer interfaces using a combination of
alignment strategies and adaptive batch normalization. Journal of Neural Engineering, 18(4):
0460e5–0460e5, Aug 2021. doi: https://doi.org/10.1088/1741-2552/ac1ed2. URL https:
//iopscience.iop.org/article/10.1088/1741-2552/ac1ed2.
5 APPENDIX
5.1 SENSORFAILUREPERFORMANCEACROSSSUBJECTS
Figure 7: Classifier performance under sensor failure. A) Classifier accuracy across variable sen-
sor failure %s. Each column represents models trained on the dataset in the title. Error bars rep-
resent SEM of 5 random seeds which randomly select the failed sensors. wSes=Within Session,
xSes=Cross Session, xSub=Cross Subject. B) TOTEM & EEGNet accuracy difference with mean
ofdifferencesinred. Ifapointliesabove0,TOTEMdecodesbetter.
85.2 LATENTCODEBOOKGENERALIZABILITYACROSSALLCASES
(a)WithinSessionCodebookMSEMatrices
(b) Matrices of MSE between matching codewords in the two labeled codebooks. Codewords are ordered
roughlybywithinsessionmeanMSE.Coloredarrowsalongaxisdenotehighlightedcodewordsin(c).
(c)Allcodewordsineachcodebook.Highlightedarethreeexamplesofmatchedcodewordsbetweencodebooks
Figure8: Additionallatentcodebookvisualizations
9