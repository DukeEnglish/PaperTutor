LLM Internal States Reveal Hallucination Risk Faced With a Query
ZiweiJi,DelongChen,EtsukoIshii,SamuelCahyawijaya,
YejinBang,BryanWilie,PascaleFung
CenterforArtificialIntelligenceResearch(CAiRE)
HongKongUniversityofScienceandTechnology
zjiad@connect.ust.hk, pascale@ece.ust.hk
Abstract
ThehallucinationproblemofLargeLanguage
Models(LLMs)significantlylimitstheirrelia-
bilityandtrustworthiness. Humanshaveaself-
awarenessprocessthatallowsustorecognize
whatwedon’tknowwhenfacedwithqueries.
Inspiredbythis,ourpaperinvestigateswhether
LLMscanestimatetheirownhallucinationrisk
before response generation. We analyze the
internalmechanismsofLLMsbroadlybothin
terms of training data sources and across 15
diverse Natural Language Generation (NLG)
tasks,spanningover700datasets. Ourempiri- Figure1: Humanshaveself-awarenessandrecognize
calanalysisrevealstwokeyinsights: (1)LLM uncertaintieswhenconfrontedwithunknownquestions.
internalstatesindicatewhethertheyhaveseen LLMinternalstatesrevealuncertaintyevenbeforere-
thequeryintrainingdataornot;and(2)LLM sponding. Pinkdots aretheinternalLLMstatesasso-
internal states show they are likely to hallu-
ciatedwithhallucinatedresponses,whereas Bluedots
cinate or not regarding the query. Our study
arethoseoffaithfulresponses. Thequeriesleadingto
exploresparticularneurons,activationlayers,
thoseLLMresponsesarecoloredaccordingly.
andtokensthatplayacrucialroleintheLLM
perceptionofuncertaintyandhallucinationrisk.
Byaprobingestimator,weleverageLLMself- Previous research (Bricken et al., 2023; Tem-
assessment,achievinganaveragehallucination pleton et al., 2024; Bills et al., 2023; Wu et al.,
estimationaccuracyof84.32%atruntime.
2024)haveexploredtheinternalstatesoflanguage
modelsthatcapturecontextualandsemanticinfor-
1 Introduction
mationlearnedfromtrainingdata(Liuetal.,2023;
Humanshaveanawarenessofthescopeandlimit Chen et al., 2024; Gurnee and Tegmark, 2023).
oftheirownknowledge(FlemingandDolan,2012; Nevertheless, internal states of language models
Koriat, 1997; Hart, 1965), as illustrated in Fig. 1. sometimesexhibitlimitedgeneralizationonunseen
This cognitive self-awareness ability in humans dataandtheirrepresentationeffectivenesscanbe
introduces hesitation in us before we respond underminedbyflawedtrainingdataormodelingis-
to queries or make decisions in scenarios where sues(Wangetal.,2022a;BelinkovandGlass,2019;
we know we don’t know (Yeung and Summer- Meng et al., 2021; Xie et al., 2022; Carlini et al.,
field, 2012; Nelson, 1990; Bland and Schaefer, 2021; Yin et al., 2023a). Notably, recent works
2012). However,LLM-basedAIassistantslackthis haveshownthattheLLM’sinternalstatescanpo-
cognitive uncertainty estimation. Consequently, tentiallydetecthallucinationsintexts(Azariaand
they tend to be overconfident and may produce Mitchell,2023;Chenetal.,2024;Suetal.,2024).
plausible-sounding but unfaithful or nonsensical However, these works examine texts not exclu-
contentscalledhallucinationorconfabulation(Ji sivelyproducedbythesameLLMswhoseinternal
et al., 2022; Xiao and Wang, 2021; Bang et al., statesareanalyzed,highlightingthenecessityfor
2023;Xiongetal.,2023). Thisproblemlimitstheir furtherinvestigationintotheLLMself-awareness
applicationsinnumerousreal-worldscenariosand and how their internal states correlate with their
underminesusertrustworthiness. uncertaintyandownhallucinationoccurrence.
4202
luJ
3
]LC.sc[
1v28230.7042:viXraOur work takes a step further by investigating However,inthereal-worldscenario,it’simprac-
whether LLM internal states have some indi- ticaltodefinitivelycategorizedataasentirelyseen
cation of hallucination risk given queries and or unseen due to the inability to access the vast
whether it can be reliably estimated even be- training data of LLM. Thus, we expand the pre-
foretheactualresponsegeneration(Fig.1). We liminary insights and further investigate LLMs’
conductacomprehensiveanalysisoftheLLMsin- self-awarenessofrecognizingwhethermodelsare
ternal mechanisms both in terms of training data likely to hallucinate regarding the query. It’s
sourcesandacross15diverseNLGtasks,spanning importanttonotethatthehallucinationsaresource-
over700datasetsthroughanin-depthanalysis. We agnostic,meaningtheycanresultfrombothunseen
exploreparticularneurons,differentactivationlay- andseendata. Thelattercanstilltriggerhallucina-
ers,andtokensthatplayacrucialroleintheLLM tionsduetodeficienciesinmodeling. Tofacilitate
perception of uncertainty and hallucination risk. analysis, we construct data by using LLM to di-
Employing a probing estimator (Belinkov, 2022) rectlygenerateresponsestoqueriesacrossdiverse
on the internal states associated with the queries, NLGtasksandthenlabelthehallucinationlevelin
wevalidatetheirself-awarenessandabilitytoindi- theresponses.
cateuncertaintyintwoaspects: (1)Whetherthey
haveseenthequeryintrainingdata,achievingan 3 Methodology
accuracy of 80.28%. (2) Whether they are likely
Thissectionbeginswithanintroductiontotheprob-
to hallucinate regarding the query, achieving an
lem formulation of uncertainty estimation faced
averageestimationaccuracyof84.32%across15
withqueriesin§3.1. Weconstructdatasetsin§3.2
NLGtasks. Weproposethatunderstandingthese
focusing on two dimensions: (1) the distinction
representations could offer a proactive approach
between queries seen and unseen in the training
toestimatinguncertainty,potentiallyservingasan
data;(2)thelikelihoodofhallucinationriskfaced
earlyindicatorforthenecessityofretrievalaugmen-
withthequeries. Tovalidatetheefficacyofinternal
tation (Wang et al., 2023) or as an early warning
staterepresentationinhallucinationestimation,we
system.
visualizetheneuronsforperceptionextractedfrom
aspecifiedLLMlayer(§3.3)andthenleveragethe
2 HallucinationandTrainingData
probing classifier technique (Belinkov, 2022) on
ThesourcesofhallucinationinLLMscanbetraced topofinternalstatesassociatedwiththelasttoken
back to data and modeling (Ji et al., 2022). Fac- ofqueries(§3.4).
tors tied to data encompass unseen knowledge,
3.1 ProblemFormulation
task-specificinnatedivergence,noisytrainingdata,
etc. Fromthemodelingperspective,hallucinations Suppose we have an LLM f parameterized by
canbetracedtothemodelarchitecture,alignment θ. It is able to gain internal states I and gen-
tax,teacher-forcedmaximumlikelihoodestimation erate response r given user query q represented
(MLE)training,etc. as I,r = f (q). We aim to investigate the self-
θ
Acommonsituationwherehallucinationsfrom awarenessofLLM,specificallyhowtheirinternal
data occur is when LLMs attempt to provide in- states I relate to their level of hallucination risk
formationonunseenqueriesthatarenotincluded h when faced with a query q. This correlation
in their training set, rather than refusing to reply. is formulated by u = E(I ), where E signifies
θ,q
Previousworks(Kadavathetal.,2022;Rajpurkar anestimatorfunction. Thecombinationofmodel-
et al., 2018; Onoe et al., 2022; Yin et al., 2023b) specific attribute via f , and query-only attribute
θ
explore to identify the unseen data based on var- via q, allows it to accurately capture the charac-
ious indicators such as text similarity, perplexity. teristics of individual LLMs and fosters a more
WeinvestigatethecapabilityofLLMstorecognize efficientpredictionmechanismthatmirrorshuman
whether they have seen the query in training cognitiveprocesses.
datavianovelanalysisoftheirinternalstates. To We employ a dataset D = {⟨Itrain,htrain⟩}N
θ θ,q,i i i=1
facilitateanalysis,wecrafttwosetsofqueriesby consisting of N query-label pairs. These pairs
collectingnewsfromperiodsbeforeandafterthe serve to represent the behavior of f Here, htrain
θ i
releaseoftheLLMweanalyzetorepresentunseen denotes the hallucination risk label, which is de-
andseendata,respectively. terminedbasedon(1)thequery’spresenceintheFigure2: VisualizationoftheNeuronsforHallucinationPerceptioninvariousNLGtasks. Pinkdots represent
UnknownQueriestriggeringhallucinationsand Bluedots representKnownQueries.
trainingdataor(2)thedegreeofhallucinationin in real-world applications. This generation pro-
theresponser toq. Thus,ourobjectiveismathe- cesscanalsobeinothersettings,suchasretrieval-
maticallyexpressedas: augmentedgeneration,toexplorewhethertheinter-
h = E(I ;D ) (1) nalstatescanestimatehallucinationriskorother
θ,q θ
aspects’performanceinthesesettings.
3.2 DataConstruction
Toevaluatethegeneratedresponses,weimple-
Asintroducedin§1and 2,weinvestigateLLMin-
mentamulti-facetedevaluationapproach. Weem-
ternalstates’self-awarenessandabilitytoindicate
ploy classical Rouge-L (Lin, 2004), which com-
uncertaintyintwoaspects: (1)whethertheyhave
pares the generated response with gold-standard
seen the query in training data; and (2) whether
reference. To measure hallucination level, we
theyarelikelytohallucinatewhenfacedwiththe
alsoutilizeNaturalLanguageInference(NLI)2
query.
and Questeval (Scialom et al., 2021). NLI is a
(1)Seen/UnseenQueryinTrainingData The common metric for hallucination evaluation (Ji
unseenquerieswilltriggerhallucinationsduetothe etal.,2023a,b)whichassessesthelogicalconsis-
lackofinformationwithinthemodel’strainingdata tency/entailment of generated text with the pro-
whenthemodeldoesn’trefusetorespond. Inother vided context or the reference. QuestEval is a
words,hallucinationstriggeredbyunseenqueries QA-basedmetricforevaluatingthefaithfulnessof
aredata-related. Toinvestigatethedistinguishabil- theoutputingenerationtasks. Thisworkadoptsits
itybetweenseenandunseenqueries,weconstruct reference-dependentmodedependingbothonthe
acompactdatasetconsistingoftwodistinctsetsof inputsourceandgoldenreference.
queries. Fortheseengroup, wecollecthistorical
Tomakeupfordeficienciesofsingleautomatic
BBCnewsin 2020likelyexposedduring LLM’s
metrics, weintegratethesethreemetricscompre-
training. For the unseen group, we collect recent
hensively. If NLI predicts entailment and both
BBC news in 2024 after the release of the LLM
Rouge-LandQuestevalexceedtheirrespectiveme-
we analyze. To ensure comparability, we ensure
dianvalues,weassignalabelof1. Conversely,if
thesetwosetssharesimilarlengthdistributionsand
semanticinformationviasentenceembeddings1. NLIpredictscontradictionorneutrality,andboth
Rouge-L and Questeval fall below their median
(2) Hallucination Risk faced with the Query values,weassignalabelof0. Thislabelingstrat-
WefirstconstructdatausingLLMtodirectlygen- egynotonlyprovidesabinaryqualityassessment
erate responses to queries in diverse NLG tasks. butalsoreflectsamulti-dimensionalevaluationof
Subsequently,forlabelingtheresponsesandcorre- the text, capturing the hallucination level of the
spondingqueries,acomprehensiveintegrationof generatedresponses.
NLG metrics assesses the levels of hallucination.
This generation only uses the parametric knowl-
edge of LLM which is a proxy of performance
1https://huggingface.co/ 2https://huggingface.co/MoritzLaurer/
sentence-transformers/all-mpnet-base-v2 mDeBERTa-v3-base-xnli-multilingual-nli-2mil73.3 PreliminaryAnalysis: Neuronsfor
HallucinationPerceptionfromInternal
States
Internalstatesplayacrucialroleinlanguagemod-
els,encapsulatingrichcontextualandsemanticin-
formationlearnedfrompredictingtokens. Theyare
adeptatrecognizingcomplexpatternsandrelation-
shipspertinenttovariousNLPtasks, whichposi-
tionsthemaspotentiallypowerfultoolsforestimat-
ingtheriskofhallucinations(AzariaandMitchell,
2023; Liu et al., 2023; Chen et al., 2024). To an-
alyze the self-assess sense of internal states and
theroleofspecificneuronsintheuncertaintyand
hallucinationestimation,weemployafeatureselec-
tionmethodbasedonMutualInformation(Kraskov
etal.,2004). Thistechniquemeasurestherelevance
ofdifferentfeaturesfordistinguishingbetweenthe
categoriesinadataset.
InthecontextofNLGtasksincludingdialogue,
Figure3: Automaticevaluationresultsforourmethod
QA,andtranslation,weselecttheeightmostsig-
and baselines including Perplexity (PPL), Zero-shot
nificantneuronsfromthelastactivationlayerand
Prompt,andInContextLearning(ICL)Prompt.
visualize them in Fig. 2. We observe that these
neuronsexhibitsensitivitytouncertainty,allowing structurehandlesthecomplexityofhallucination
them to distinguish between different hallucina- riskestimationinNLGtasks.
tionlevelsgivenknownandunknownqueries. In
otherwords,thereexistindividualneuronswithin 4 Experiments
LLMthatcanfairlyperceiveuncertaintyandpre-
4.1 Dataset
dictfuturehallucinations. Thisapproachnotonly
enhances our understanding of the neural corre- (1)Seen/UnseenQueryinTrainingData Lat-
lates of hallucinations but also paves the way for estEval(Lietal.,2024)isabenchmarkdesignedto
developingtargetedinterventionsthatmitigatethe tackledatacontaminationinevaluationthroughdy-
effectsofhallucinations. namicandtime-sensitiveconstruction. Itincludes
data from various time periods. In our study, we
3.4 InternalState-basedEstimator
utilizeBBCnewscollectedinJan. 2020and2024,
Based on the above preliminary analysis, we use which correspond to periods before and after the
internal states corresponding to the last token of releaseoftheLLM.Theselecteddatasetincludes
queries, denoted as x . These representations, 2.8k samples allowing us to represent both seen
q
takenfromaspecifiedlayerwithintheLLM,serve andunseendatainouranalysis.
as the input to our estimation model. The acces-
(2) Hallucination Risk faced with the Query
sibility and ease of obtaining these states further
Super-Natural Instructions (Wang et al., 2022b)
underscoretheirpracticalityforsuchapplications.
isalargeanddiversebenchmarkincluding1,616
For the architecture of our estimator, we em-
diverse NLP datasets and their expert-written in-
ployavariantofthemultilayerperceptron(MLP)
structions. Among this benchmark, we select 15
adaptedfromtheLlama(Touvronetal.,2023). The
NLGtaskcategoriesincludingQA,Summarization,
estimatorismathematicallyformulatedas:
Translation, etc consisting of over 700 datasets.
H = down(up(x )×SiLU(gate(x ))) (2) PleasefindthefulllistofNLGtaskcategoriesin
q q
Fig.3or4andthefulllistoftasksinTab.A2in§A.
whereSiLUistheactivationfunction. down,up, WealsoleverageANAH(Jietal.,2024)totestour
andgatearelinearlayersfordown-projection,up- estimator’sperformanceinthehallucinationaspect
projection,andgatemechanisms,respectively. The anditsgeneralization. ANAHisabilingualdataset
combinationofinternalstatesandtheLlamaMLP thatoffersanalyticalannotationofHallucinationsin LLMs within Generative QA. Our work uses
Englishsamplesandtreatsthehallucinationtype
asthelabelinthetestingstage.
4.2 LLM
Inthiswork,weprimarilyuseLlama2-7B(Touvron
et al., 2023) as our generative model and delve
intoitsinternalstatestoaccesshallucinationrisk
estimation. Inaddition,weexploretheimpactof
different internal states in the Mistral-7B (Jiang
etal.,2023)in§5.
4.3 Baselines
Toexplorequery-onlyuncertaintyestimation,we
involvestraightforwardprompt-basedapproaches
asbaselines.
Zero-shot Prompt We directly ask the LLM
whetheritcanaccuratelyrespondtothequeryvia
thefollowingprompt: "Query: {Query}\n\nAre
you capable of providing an accurate
Figure 4: F1 scores of Internal-State from Different
response to the query given above?
LayersforHallucinationEstimation.
Respond only to this question with ’yes’
or ’no’ and do not address the content of
TrainingTask TestingTask F1 ACC
the query itself."
UnseenQA 64.79 73.32
QA
Translation 51.34 65.10
In-Context-Learning (ICL) Prompt We ask
UnseenTranslation 74.03 73.81
the LLM whether it can accurately respond to Translation
QA 20.45 37.50
the query and give some examples: "Are you
capable of providing an accurate response
Table1: Zero-ShotAutomaticEvaluationResultsinthe
to the following query? Respond only SameTaskandacrossDifferentTasks.
to this question with ’yes’ or ’no’
and do not address the content of
trainingdataset. Thisoptimalthresholdisthenap-
the query itself.\n\nQuery: {Example
plied to the test dataset to gauge the accuracy of
Query 0}\nAnswer: no\n\nQuery: {Example
ourhallucinationriskestimationmethod.
Query 1}\nAnswer: yes...\n\nQuery:
{Query}\nAnswer:"
4.4 EstimatorEvaluationProtocols
Perplexity(PPL) Consideringtheprompt-based For the classification task with the discrete type
methods only use the model’s inner knowledge, predicted,weutilizeF1andAccuracytomeasure
wealsoincorporatethedistributionofthetraining thequalityofpredictedcategorization.
datasetandemployaPerplexity(PPL)-basedbase-
line. AssumeLLMsaretrainedonahypothetical 5 ResultsandAnalysis
large dataset that perfectly contains every possi-
5.1 ResultsforInternalState-basedEstimator
ble query-response pair, where the responses are
guaranteedtobefaithful. Then,thehallucination (1) Seen/Unseen Query in Training Data We
estimationcanbesimplydonebycheckingwhether evaluateourinternalstate-basedestimatortrained
thegivenqueryappearsinthetrainingcorpus(Lee todistinguishunseenandseenquestions. TheF1
et al., 2021; Kandpal et al., 2023). To determine and accuracy scores reach 80.28% and 80.24%
thisthreshold,wefirstcalculatethePPLforeach Thesehighresultsshedlightontheeffectivenessof
query. Subsequently,weidentifytheoptimalPPL ourinternalstate-basedmethodinidentifyingun-
thresholdthatyieldsthemaximumaccuracyonour seenqueries. ThisphenomenonisalignedwiththeTask InternalState F1 ACC
Llama2 74.33 74.22
Dialogue
Mistral 72.39 72.55
Llama2 82.37 82.55
QA
Mistral 80.46 81.00
Llama2 88.08 88.95
Summarization
Mistral 83.63 85.42
Figure5: Inferencetimeofvariousestimationmethods.
Llama2 76.90 76.90
Translation
Mistral 73.10 73.14
bestinrecognizinglying.
Table2:AutomaticEvaluationResultsofInternalStates ConsistencyofInternalStatesacrossDifferent
fromDifferentModels. LLMs ToevaluatetheimpactoftheLLM’sIn-
ternalState, weuseMistral-7B’sinternalstateto
previousworks(Kadavathetal.,2022;Yinetal.,
assess Llama2’s hallucination risk. As shown in
2023b) which find the model can distinguish an-
Tab.2,theresultsforfourcommonNLGtasksex-
swerableandunanswerablequestionsthatinclude
hibitadecreasecomparedtoLlama2’sowninternal
futureinformation.
states. SincedifferentLLMsshareasimilarityin
(2) Hallucination Risk faced with the Query modelarchitectureanddata,thereisapotentialfor
For estimating hallucination risk, as depicted in zero-shottransfer. Nonetheless,themosteffective
Fig.3,ourmethodsexhibitsuperiorperformance predictorofLLM’sgenerativeperformanceisstill
inbothF1andACC.Notably,itsperformancere- itsowninternalstate,whichunderscorestheimpor-
mains stable across different tasks. It performs tance of considering model-specific assessments
lesseffectivelyinthetranslationtask(F1andACC ratherthanuniversalones.
76.90%)whileexcellingintheNumberConversion
InternalStatesShareFeaturesinner-taskbutdo
task(F194.04%,ACC96.00%). Zero-shotprompt
not Cross-task. As shown in Tab. 1, we evalu-
andICLyieldsimilarresults,withICLslightlyout-
atethegeneralizationacrossdifferentNLGtasks
performingzero-shotprompt. Bothmethodstend
and within the same NLG task. Specifically, we
tobeoverconfidentandpredictLLMcanaccurately
examinezero-shotperformanceinQAandtransla-
respondtothequery(Recall99%),whichisaligned
tion. Whilethezero-shotperformancewithinthese
withtheobservationof(Xiongetal.,2023). PPL
individualtasksisacceptable,thecross-taskgener-
is better than the prompt methods while exhibit-
alizationremainsrelativelyweak,alignedwiththe
ingvaryingperformanceacrosstasks. Itperforms
findingsreportedbyKadavathetal.(2022). Inad-
poorly in the translation task (F1 33.73%, ACC
dition,weevaluateourestimatortrainedinQAon
50.36%) but achieves its best performance in the
theout-of-domainhallucinationQAdatasetANAH.
data-to-texttask(F188.28%,ACC92.08%).
TheF1scorereaches78.56%andtheaccuracyis
78.83%. Theserelativelyhighresultsshedlighton
5.2 Analysis
theeffectivenessofourinternalstateestimatorin
LayerDepthPositivelyCorrelateswithitsPre-
handlinghallucinationchallengesandfurthershow
dictionPerformance. Wesystematicallydissect
ourgeneralizationcapabilities. Therefore,thefea-
thecontributionofeachlayertotheoverallhallu-
tures in internal states are shared with OOD data
cinationriskestimation. Wehypothesizethatcer-
withinthesametaskbutnotsharedacrosstasks.
tainlayersmaybemoreindicativeofhallucinatory
propensitiesthanothers,andouranalysisseeksto InternalStateasanEfficientHallucinationEs-
validatethishypothesis. AsshowninFig.4,early timator Our estimator has three linear layers
Layers perform poorly since they often capture which requires minimal computing power. As
basic syntactic information. Intermediate layers shown in Fig. 5, our estimator demonstrates im-
performbettersincetheselayerstypicallyencode pressiveefficiency. Specifically,likelihood-based
more complex semantic relationships. Deep lay- costs1.36spersample,whileinternal-state-based
ers perform best and learn hallucination patterns costsonly0.05spersample. Thisrapidinference
with high-level presentation. This observation is speedisessentialforreal-worldapplications. The
different from Azaria and Mitchell (2023) where generationtime,withamaximumtokenlengthof
middle-layerhiddenstatesofstatementsperform 50andabatchsizeof1,is3.37seconds. Notably,Figure6: HallucinationRateforeachNLGTask.
Questevalcoststhemosttime10.25sintotal.
HallucinationRate Duringthelabelingprocess
mentioned in § 3.2, we obtain the hallucination
rateintheresponsesofeachtask. Asillustratedin Figure7: VisualizationofTokenContributionstohallu-
Fig.6,thehallucinationratefluctuatessignificantly cinationsinunknownqueriesforQA(top)andtransla-
acrossNLGtasks. Amongthem,TitleGeneration tion(bottom)tasks. Deeper backgroundcolormeans
highercontributionsandthehallucinatedcontentinthe
exhibitsthehighestratesinceitsdivergentnature
generatedreplyismarkedin pink.
and there is no unique and standard answer. In
contrast,NumberConversiongainsthelowestrate
example,theestimatorpredictsthatLLMcancor-
sincethetaskisrelativelyeasyandtheansweris
rectlyanswerthequery“Whatisthetermfortough,
fixedleavinglessroomforhallucination.
flexibleconnectivetissuethatcontainstheprotein
Visualizing Tokens Triggering Hallucination collagen?” ButLLMreplies“ligaments”instead
Tofurtherunderstandthemechanismsbehindhal- of“cartilage”,whichishallucinated. theestimator
lucination, we dissect the process of the queries predictsthatLLMwillhallucinatewhenfacedwith
triggering hallucinations at a fine-grain level. In- “whatappropriatelynicknamedpacificlocation?”
spiredbytheGradient-weightedClassActivation ButLLMreplieswithouthallucination.
Mapping(Grad-CAM)technique(Selvarajuetal., More analysis is described in Appendix B in-
2017), we quantify the average gradients of in- cludingtreatingseparatemetricsascontinuousre-
put embedding associated with each token in the gressionlabelsanddifferentestimatorbackbones.
jointoperationoftheLLMandestimator. Specifi-
cally,wefocusedonhowthesetokensinfluencethe 6 RelatedWork
LLM’sinternalstateandthesubsequentestimation
KnowledgeBoundary Researchersinvestigate
ofhallucinationsbasedonthisinternalstate.
the boundary of parametric knowledge in LLMs
Fig.7indicatesthattokenswithinanunknown
whichaimtouncoverwhatmodelsknowandwhere
query contribute unequally to the occurrence of
their capabilities end. Current research on the
hallucinations. Weobservethatthetokensthatare
knowledgeboundarypredominantlynarrowsdown
partofunfamiliarnamedentitiesorcarrycritical
this investigation to specialized tasks, charting a
informationexhibitahigherimpact. Forinstance,
mapofknownsandunknownswithinthesedefined
“amniotes”intheQAtaskand“麻雀”inthetrans-
borders. IntherepresentativeQAfield,Rajpurkar
lationtaskgainhighergradientsandsignificantly
etal.(2018)andYinetal.(2023b)collectdatasets
impact hallucination estimation. This could be
containingknownandunknownquestionsandde-
attributedtothesystem’sattemptstogenerateflu-
velopclassifierstodifferentiatethem. Theconcept
entresponsesdespitegapsinitsunderstandingor
ofunanswerabilityintheseworksisuniversaland
knowledgeabouttheseentities.
model-agnostic, such as philosophical questions
ErrorAnalysis Althoughourmethodperforms and unsolved mysteries. In contrast, Kadavath
betterthanthebaselinesintheestimationtask, it etal.(2022)focusesonmodel-specificprediction
stillgeneratesafewcasesoffailure. Togainmore ofwhichquestionsthemodelwillbeabletoanswer
insightintoourmodel,wepresentafailureexam- correctly. Thisapproachrequiresdirectfine-tuning
ple in Tab. 3 and conduct an error analysis. For of the LLM to make it a classifier in a few-shotGenerated Golden Trainig Predicted
Query
Reply Answer Label Label
Givenascientificquestion,gen- Ligaments are fibrous connec- cartilage hallucinated faithful
erateacorrectanswertoit. What tivetissuestructuresthatconnect
isthetermfortough,flexiblecon- bonestootherbonesandprovide
nective tissue that contains the supportandstabilitytothejoint...
proteincollagen?
Givenascientificquestion,gen- Since1900,fourofthefiveearth- ringoffire faithful hallucinated
erateacorrectanswertoit. Since quakesofthegreatestmagnitude
1900,fourofthefiveearthquakes haveoccurrednearthePacificlo-
of the greatest magnitude oc- cation of the Ring of Fire. The
curred near what appropriately RingofFireisanareaof...
nicknamedpacificlocation?
Table3: NegativeSamples. Thehallucinatedcontextismarkedin pink.
setting. Out-of-domainorout-of-distributiondetec- 7 Conclusion
tion(Zhouetal.,2023;Ryuetal.,2018;Tanetal.,
Inspired by human self-awareness, this work
2019; Yang et al., 2021; Zheng et al., 2020) are
demonstratesthelatentcapacityofLLMstoself-
alsorelevantareasdealingwiththedifferentiation
assessandestimatehallucinationriskspriortore-
ofunknown/unseenfromtrainingdata,withmain
sponse generation. We conduct a comprehensive
focus on classification tasks. Our method is ver-
analysisoftheinternalstatesofLLMsbothinterms
satileacrossvariousNLGtaskswithoutrequiring
oftrainingdatasourcesandacross15NLGtasks
fine-tuningofLLMs.
with over 700 datasets. Employing a probing es-
timator on the internal states associated with the
Hallucination Detection The phenomenon of
queries,weassesstheirself-awarenessandability
hallucination in NLG encourages a variety of de-
to indicate uncertainty in two aspects: (1) recog-
tection methods (Min et al., 2023; Ji et al., 2024;
nizingwhethertheyhaveseenthequeryintraining
Li et al., 2023; Scialom et al., 2021). Some of
data,achievinganaccuracyof80.28%3. (2)recog-
thesemethodsdelveintotheinternalstatesforde-
nizingwhethertheyarelikelytohallucinatewhen
tection. AzariaandMitchell(2023),forexample,
facedwiththequery. Theresultsdemonstratethat
collectatrue-falsestatementdatasetwithartificial
internal state-based self-assessment outperforms
guidanceandtheclassificationresultsindicatethat
PPL-basedandprompting-basedbaselines,withan
the LLMs’ internal state can reveal the truthful-
averageestimationaccuracyof84.32%acrossall
ness of statements. INSIDE (Chen et al., 2024)
tested datasets. In addition, we explore the role
alsoleveragesLLMs’internalstatesandproposes
ofparticularneuronsinuncertaintyandhallucina-
EigenScoreforevaluatingtheself-consistencyof
tion perception and reveal a positive correlation
responses, therebyservingasaproxyforhalluci-
betweenthedepthofactivationlayersinanLLM
nationlevels. MIND(Suetal.,2024),anunsuper-
and its predictive accuracy. The consistency of
visedtrainingapproach,distinguishesthehalluci-
internal states across different models suggests a
natedcontinuationtextfromtheoriginalWikipedia
potentialforzero-shottransfer,butmodel-specific
contentbasedoninternalstates. Ontheotherhand,
estimation is the optimal strategy. Challenges of
XiaoandWang(2021)showsevidencethathigher
generalizing these findings across different tasks
uncertaintycorrespondstoahigherhallucination
arenoted,despiteobservingpromisinggeneraliza-
probability. Uncertaintyestimationmethods,such
tionswithinthesameNLGtasks.
as (Xiaoetal.,2022;Xiongetal.,2023;Kadavath
Forfuturework,weaimtorefineourmethodol-
etal.,2022),predictthereliabilityoftheirnatural
ogytoenhancetherobustnessandgeneralization
language outputs and can also serve as a tool for
acrossvariousNLGtasksinthefieldofhallucina-
hallucination detection. Previous works leverage
tionriskassessment. Inaddition,wewillinvolvea
the LLM’s internal states for the text to be mea-
broaderspectrumofLLMstoextendtheapplica-
suredwhichisnotnecessaryfromthesameLLM.
bilityofourfindings.
Differently, this work focuses on self-awareness
correspondingtothequeries. 3Pleaserefertothefirstpartsof§3.2,§4.1,and§5.1.8 Limitation References
Amos Azaria and Tom Mitchell. 2023. The internal
ModelCoverage Thisworkprimarilyinvestigate
stateofanllmknowswhenit’slying. InFindings
the widely used LLM, Llama2, due to its preva-
of the Association for Computational Linguistics:
lence in current NLG applications. However, it EMNLP2023,pages967–976.
does not encompass other LLMs. In the future,
YejinBang,SamuelCahyawijaya,NayeonLee,Wen-
wewillextendthescopeofLLMstoenhancethe
liangDai,DanSu,BryanWilie,HolyLovenia,Ziwei
robustnessandapplicabilityofourresults. Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan
Xu,andPascaleFung.2023. Amultitask,multilin-
HumanEvaluationinDataConstruction Hu- gual,multimodalevaluationofchatgptonreasoning,
manjudgmentisextremelyresource-intensivefor hallucination,andinteractivity. AACL.
hallucinationjudgment. Theextensivetimecom-
YonatanBelinkov.2022. Probingclassifiers: Promises,
mitmentandfinancialexpenditurerequiredarebe- shortcomings,andadvances. ComputationalLinguis-
yondthescopeofthisstudy,particularlygiventhe tics,48(1):207–219.
large scale of the datasets. Consequently, this re-
Yonatan Belinkov and James Glass. 2019. Analysis
searchdidnotincludehumanevaluationinthedata
methods in neural language processing: A survey.
labelingprocessin§3.2. TransactionsoftheAssociationforComputational
Linguistics,7:49–72.
Comparative Performance Our method pre-
Steven Bills, Nick Cammarata, Dan Moss-
dictstheriskinadvanceofgenerationanddepends
ing, Henk Tillman, Leo Gao, Gabriel Goh,
solelyonthequery. Itmayleadtoatrade-offinper- Ilya Sutskever, Jan Leike, Jeff Wu, and
formance compared to other existing approaches William Saunders. 2023. Language mod-
thatconsiderboththequeryandtheresponse. els can explain neurons in language models.
https://openaipublic.blob.core.windows.
net/neuron-explainer/paper/index.html.
9 EthicalConsiderations
AmyRBlandandAlexandreSchaefer.2012. Different
In our experiments, we utilized datasets that are varieties of uncertainty in human decision-making.
either publicly accessible or synthetically gener- Frontiersinneuroscience,6:85.
ated,therebycircumventinganypotentialadverse
Trenton Bricken, Adly Templeton, Joshua Batson,
effectsonindividualsorcommunities. Thedatasets Brian Chen, Adam Jermyn, Tom Conerly, Nick
employedinthisinvestigationweremeticulously Turner,CemAnil,CarsonDenison,AmandaAskell,
curatedandprocessedtoupholdtheprinciplesof RobertLasenby,YifanWu,ShaunaKravec,Nicholas
Schiefer, Tim Maxwell, Nicholas Joseph, Zac
privacy and confidentiality. We ensured the ex-
Hatfield-Dodds, Alex Tamkin, Karina Nguyen,
clusionofanypersonallyidentifiableinformation, Brayden McLean, Josiah E Burke, Tristan Hume,
withalldataundergoinganonymizationbeforeany Shan Carter, Tom Henighan, and Christopher
analysiswasconducted. Olah. 2023. Towards monosemanticity: Decom-
posing language models with dictionary learning.
Whencontemplatingthedeploymentofourre-
Transformer Circuits Thread. Https://transformer-
searchoutcomes,werecognizetheinherentrisks circuits.pub/2023/monosemantic-
and ethical dilemmas involved. The tendency of features/index.html.
LLMstoproducehallucinationscoulddispropor-
Nicholas Carlini, Florian Tramer, Eric Wallace,
tionatelyaffectvariousdemographicgroups,acon-
Matthew Jagielski, Ariel Herbert-Voss, Katherine
sequence of the inherent biases in the training Lee,AdamRoberts,TomBrown,DawnSong,Ulfar
datasets. We are committed to the identification Erlingsson,etal.2021. Extractingtrainingdatafrom
large language models. In 30th USENIX Security
andrectificationofsuchbiasestoforestallthecon-
Symposium(USENIXSecurity21),pages2633–2650.
tinuationofstereotypesortheinequitabletreatment
ofanydemographic. Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu,
Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024.
Byadheringtotheseethicalconsiderations,we
INSIDE:LLMs’internalstatesretainthepowerof
aim to contribute positively to the field of NLP
hallucinationdetection. InTheTwelfthInternational
andensurethatadvancementsinunderstandingand ConferenceonLearningRepresentations.
mitigating hallucinations in LLMs are achieved
StephenMFlemingandRaymondJDolan.2012. The
responsiblyandwithconsiderationforthebroader
neural basis of metacognitive ability. Philosophi-
societalimpact.
calTransactionsoftheRoyalSocietyB:Biological
Sciences,367(1594):1338–1349.WesGurneeandMaxTegmark.2023. Languagemod- JunyiLi,XiaoxueCheng,WayneXinZhao,Jian-Yun
elsrepresentspaceandtime. InTheTwelfthInterna- Nie, and Ji-Rong Wen. 2023. Halueval: A large-
tionalConferenceonLearningRepresentations. scalehallucination evaluationbenchmark forlarge
languagemodels. InProceedingsofthe2023Con-
Julian T Hart. 1965. Memory and the feeling-of- ferenceonEmpiricalMethodsinNaturalLanguage
knowing experience. Journal of educational psy- Processing,pages6449–6464.
chology,56(4):208.
Yucheng Li, Frank Guerin, and Chenghua Lin. 2024.
Ziwei Ji, Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Latesteval: Addressing data contamination in lan-
Dahua Lin, and Kai Chen. 2024. Anah: Analyti- guagemodelevaluationthroughdynamicandtime-
cal annotation of hallucinations in large language sensitive test construction. In Proceedings of the
models. InACL. AAAI Conference on Artificial Intelligence, vol-
ume38,pages18600–18607.
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu,
DanSu,YanXu,EtsukoIshii,YejinBang,Andrea Chin-YewLin.2004. Rouge: Apackageforautomatic
Madotto,andPascaleFung.2022. Surveyofhalluci- evaluation of summaries. In Text summarization
nationinnaturallanguagegeneration. ACMComput- branchesout,pages74–81.
ingSurveys.
KevinLiu,StephenCasper,DylanHadfield-Menell,and
ZiweiJi,ZihanLiu,NayeonLee,TiezhengYu,Bryan JacobAndreas.2023. Cognitivedissonance: Whydo
Wilie, Min Zeng, and Pascale Fung. 2023a. RHO: languagemodeloutputsdisagreewithinternalrep-
Reducing hallucination in open-domain dialogues resentationsoftruthfulness? InProceedingsofthe
with knowledge grounding. In Findings of the As- 2023ConferenceonEmpiricalMethodsinNatural
sociationforComputationalLinguistics: ACL2023, LanguageProcessing,pages4791–4797.
pages4504–4522,Toronto,Canada.Associationfor
ComputationalLinguistics. Zhong Meng, Sarangarajan Parthasarathy, Eric Sun,
YasheshGaur,NaoyukiKanda,LiangLu,XieChen,
Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Rui Zhao, Jinyu Li, and Yifan Gong. 2021. Inter-
Ishii, and Pascale Fung. 2023b. Towards mitigat- nallanguagemodelestimationfordomain-adaptive
inghallucinationinlargelanguagemodelsviaself- end-to-endspeechrecognition. In2021IEEESpo-
reflection. EMNLPFindings. ken Language Technology Workshop (SLT), pages
243–250.IEEE.
Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
sch,ChrisBamford,DevendraSinghChaplot,Diego SewonMin,KalpeshKrishna,XinxiLyu,MikeLewis,
delasCasas,FlorianBressand,GiannaLengyel,Guil- Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle-
laumeLample,LucileSaulnier,etal.2023. Mistral moyer, and Hannaneh Hajishirzi. 2023. Factscore:
7b. arXivpreprintarXiv:2310.06825. Fine-grainedatomicevaluationoffactualprecision
inlongformtextgeneration. InProceedingsofthe
SauravKadavath,TomConerly,AmandaAskell,Tom 2023ConferenceonEmpiricalMethodsinNatural
Henighan, Dawn Drain, Ethan Perez, Nicholas LanguageProcessing,pages12076–12100.
Schiefer,ZacHatfield-Dodds,NovaDasSarma,Eli
Tran-Johnson, et al. 2022. Language models Thomas O Nelson. 1990. Metamemory: A theoreti-
(mostly) know what they know. arXiv preprint calframeworkandnewfindings. InPsychologyof
arXiv:2207.05221. learningandmotivation,volume26,pages125–173.
Elsevier.
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric
Wallace, and Colin Raffel. 2023. Large language YasumasaOnoe,MichaelZhang,EunsolChoi,andGreg
modelsstruggletolearnlong-tailknowledge. InIn- Durrett.2022. Entityclozebydate: WhatLMsknow
ternationalConferenceonMachineLearning,pages about unseen entities. In Findings of the Associa-
15696–15707.PMLR. tion for Computational Linguistics: NAACL 2022,
pages693–702,Seattle,UnitedStates.Association
AsherKoriat.1997. Monitoringone’sownknowledge forComputationalLinguistics.
during study: A cue-utilization approach to judg-
mentsoflearning. Journalofexperimentalpsychol- Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
ogy: General,126(4):349. Know what you don’t know: Unanswerable ques-
tionsforsquad. InProceedingsofthe56thAnnual
AlexanderKraskov,HaraldStögbauer,andPeterGrass- Meeting of the Association for Computational Lin-
berger.2004. Estimatingmutualinformation. Physi- guistics(Volume2: ShortPapers).Associationfor
calreviewE,69(6):066138. ComputationalLinguistics.
NayeonLee,YejinBang,AndreaMadotto,andPascale SeonghanRyu,SangjunKoo,HwanjoYu,andGaryGe-
Fung. 2021. Towards few-shot fact-checking via unbaeLee.2018. Out-of-domaindetectionbasedon
perplexity. InProceedingsofthe2021Conference generative adversarial network. In Proceedings of
of the North American Chapter of the Association the2018ConferenceonEmpiricalMethodsinNatu-
for Computational Linguistics: Human Language ralLanguageProcessing,pages714–718,Brussels,
Technologies,pages1971–1981. Belgium.AssociationforComputationalLinguistics.ThomasScialom,Paul-AlexisDray,SylvainLamprier, 2022b. Super-naturalinstructions:generalizationvia
BenjaminPiwowarski,JacopoStaiano,AlexWang, declarativeinstructionson1600+tasks. InEMNLP.
andPatrickGallinari.2021. Questeval: Summariza-
tionasksforfact-basedevaluation. InProceedings Jeffrey Wu, Leo Gao, Tom Dupre la Tour, and
of the 2021 Conference on Empirical Methods in Henk Tillman. 2024. Extracting concepts
NaturalLanguageProcessing,pages6594–6604. from gpt-4. https://openai.com/index/
extracting-concepts-from-gpt-4/.
RamprasaathRSelvaraju,MichaelCogswell,Abhishek
Das, Ramakrishna Vedantam, Devi Parikh, and Yijun Xiao and William Yang Wang. 2021. On hal-
DhruvBatra.2017. Grad-cam: Visualexplanations lucinationandpredictiveuncertaintyinconditional
fromdeepnetworksviagradient-basedlocalization. languagegeneration. InProceedingsofthe16thCon-
InProceedingsoftheIEEEinternationalconference ferenceoftheEuropeanChapteroftheAssociation
oncomputervision,pages618–626. forComputationalLinguistics: MainVolume,pages
2734–2744.
WeihangSu,ChangyueWang,QingyaoAi,YiranHu,
ZhijingWu,YujiaZhou,andYiqunLiu.2024. Unsu- Yuxin Xiao, Paul Pu Liang, Umang Bhatt, Willie
pervisedreal-timehallucinationdetectionbasedon Neiswanger, Ruslan Salakhutdinov, and Louis-
the internal states of large language models. ACL PhilippeMorency.2022. Uncertaintyquantification
2024Findings. withpre-trainedlanguagemodels: Alarge-scaleem-
piricalanalysis. InFindingsoftheAssociationfor
MingTan,YangYu,HaoyuWang,DakuoWang,Saloni
Computational Linguistics: EMNLP 2022, pages
Potdar, Shiyu Chang, and Mo Yu. 2019. Out-of-
7273–7284.
domaindetectionforlow-resourcetextclassification
tasks. In Proceedings of the 2019 Conference on
ShuoXie,JiahaoQiu,AnkitaPasad,LiDu,QingQu,
EmpiricalMethodsinNaturalLanguageProcessing
andHongyuanMei.2022. Hiddenstatevariabilityof
andthe9thInternationalJointConferenceonNatu-
pretrainedlanguagemodelscanguidecomputation
ralLanguageProcessing(EMNLP-IJCNLP),pages
reduction for transfer learning. In Findings of the
3566–3572,HongKong,China.AssociationforCom-
AssociationforComputationalLinguistics: EMNLP
putationalLinguistics.
2022,pages5750–5768.
AdlyTempleton,TomConerly,JonathanMarcus,Jack
MiaoXiong,ZhiyuanHu,XinyangLu,YIFEILI,Jie
Lindsey,TrentonBricken,BrianChen,AdamPearce,
Fu, Junxian He, and Bryan Hooi. 2023. Can llms
CraigCitro,EmmanuelAmeisen,AndyJones,Hoagy
expresstheiruncertainty? anempiricalevaluationof
Cunningham,NicholasLTurner,CallumMcDougall,
confidenceelicitationinllms. InTheTwelfthInter-
MonteMacDiarmid,C.DanielFreeman,TheodoreR.
nationalConferenceonLearningRepresentations.
Sumers,EdwardRees,JoshuaBatson,AdamJermyn,
ShanCarter,ChrisOlah,andTomHenighan.2024.
JingkangYang,KaiyangZhou,YixuanLi,andZiwei
Scaling monosemanticity: Extracting interpretable
Liu.2021. Generalizedout-of-distributiondetection:
featuresfromclaude3sonnet. TransformerCircuits
Asurvey. arXivpreprintarXiv:2110.11334.
Thread.
Nick Yeung and Christopher Summerfield. 2012.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
Metacognition in human decision-making: confi-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
dence and error monitoring. Philosophical Trans-
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
actionsoftheRoyalSocietyB:BiologicalSciences,
Bhosale, et al. 2023. Llama 2: Open founda-
367(1594):1310–1321.
tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288.
XunjianYin,BaizhouHuang,andXiaojunWan.2023a.
Jindong Wang, Cuiling Lan, Chang Liu, Yidong Alcuna: Large language models meet new knowl-
Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wen- edge. In Proceedings of the 2023 Conference on
junZeng,andSYuPhilip.2022a. Generalizingto
EmpiricalMethodsinNaturalLanguageProcessing,
unseendomains: Asurveyondomaingeneralization. pages1397–1414.
IEEEtransactionsonknowledgeanddataengineer-
ing,35(8):8052–8072. Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu,
XipengQiu,andXuanjingHuang.2023b. Dolarge
YileWang,PengLi,MaosongSun,andYangLiu.2023. language models know what they don’t know? In
Self-knowledge guided retrieval augmentation for FindingsoftheAssociationforComputationalLin-
largelanguagemodels. InFindingsoftheAssocia- guistics: ACL 2023, pages 8653–8665, Toronto,
tionforComputationalLinguistics: EMNLP2023, Canada.AssociationforComputationalLinguistics.
pages10303–10315.
YinheZheng,GuanyiChen,andMinlieHuang.2020.
Yizhong Wang, Swaroop Mishra, Pegah Alipoor- Out-of-domain detection for natural language un-
molabashi, Yeganeh Kordi, Amirreza Mirzaei, derstanding in dialog systems. IEEE/ACM Trans-
Anjana Arunkumar, Arjun Ashok, Arut Selvan actionsonAudio,Speech,andLanguageProcessing,
Dhanasekaran, Atharva Naik, David Stap, et al. 28:1198–1209.Yunhua Zhou, Jianqiang Yang, Pengyu Wang, and
XipengQiu.2023. Twobirdsonestone: Dynamic
ensembleforoodintentclassification. InProceed-
ingsofthe61stAnnualMeetingoftheAssociationfor
ComputationalLinguistics(Volume1: LongPapers),
pages10659–10673.A Dataset
ThisworkusesbenchmarkSuper-NaturalInstruc-
tions(Wangetal.,2022b)whichincludes1,616di-
verseNLPdatasetscovering76distincttasktypes.
We select 15 NLG task types and list all datasets
includedineachNLGtaskinTab.A2.
B ResultsandAnalysis
SeparateMetricasContinuousRegressionLa-
bel Inadditiontothecomprehensiveintegration
of all metrics (i.e. NLI, Rouge-L, Questeval) de-
scribedin§3.2,weanalyzeourinternalstate-based
method’sperformanceswhentreatingeachmetric
asthelabel,separately.
We consider three forms of “golden score” for
eachmetric. First,theabsolutevalues,whichserve
asthetargetforregression,withhigherscoresindi-
catingfewerhallucinations. Weconsidertheproba-
bilityofentailmentastheabsolutevalueoftheNLI
metric. Second,westandardizetheseabsoluteval-
uesusingtheminimumandmaximumvaluesfrom
thetrainingdatasettoobtainnormalized“golden
scores”. Third,weusetherelativerankingsofthese
scoreswithinthetrainingdatasetasanalternative
regressiontarget.
For the regression task with continuous score
predicted,weutilizeRootMeanSquaredError FigureA1: RMSEScoresofInternalState-basedEsti-
matorwithLabels: (a)Rouge-L(b)NLI(c)QuestEval
(RMSE) to measure the average difference be-
tween the values predicted by our estimator and
Task InternalState F1 ACC
theactualvalues.
LlamaMLP 74.33 74.22
As shown in Fig. A1, our method’s prediction Dialogue
MLP 70.22 71.12
performancevariesacrosstheformofthe“golden LlamaMLP 82.37 82.55
QA
MLP 81.57 81.84
score”. Foreachmetric,theRMSEisthesmallest
LlamaMLP 88.08 88.95
when predicting absolute value, which indicates Summarization
MLP 87.59 87.59
that the hidden state performs best in predicting LlamaMLP 76.90 76.90
Translation
the absolute value of the metric. Conversely, the MLP 74.23 74.90
highest RMSE occurs when the model attempts
TableA1: AutomaticEvaluationResultsforDifferent
topredicttherelativerankings,implyingthatpre-
ClassifierBackbone
dictingthepreciseorderingofthemetricsismore
challengingforthehiddenstaterepresentation. is10,thebatchsizeis128,thelearningrateis1e-5,
andtheAdamWoptimizerhasalinearscheduler.
EstimatorBackbone InsteadofLlamaMLP,we
Ourmodelistrainedon1NVIDIAA800GPU.
employ a standard MLP as the backbone of the
estimator. TheresultsinTab.A1demonstratethat D AIAssistantsUsing
LlamaMLPoutperformsthestandardMLP.
Inthispaper,weuseChatGPTtoimprovethewrit-
C ImplementationDetails ingatgrammarlevel.
Theinputdimensionofourclassifieris4096and
thehiddendimensionis11008,whicharealigned
with Llama2-7B. We train our classifier with the
followingsettingsandhyper-parameters: theepochTask No. Dataset
Code
to 4 task110 logic2text sentence generation, task129 scan long text generation action command short,
Text task127 scan long text generation action command all, task131 scan long text generation action
commandlong
Data
to 9 task1728webnlgdatatotext,task1598nyclongtextgeneration,task1631openpianswergeneration,
Text task677olliesentenceanswergeneration,task957e2enlgtextgenerationgenerate,task760msrsqa
longtextgeneration,task1407dartquestiongeneration,task102commongensentencegeneration,
task1409darttextgeneration
Dialogue
13 task574airdialoguesentencegeneration,task361spolinyesandpromptresponseclassification,task576
Generation
curiositydialogsanswergeneration,task1603smcalflowsentencegeneration,task1714convai3sen-
tencegeneration,task1730personachatchoosenext,task565circaanswergeneration,task611mutual
multiturndialogue,task1729personachatgeneratenext,task1600smcalflowsentencegeneration,
task639 multi woz user utterance generation, task1590 diplomacy text generation, task360 spolin
yesandresponsegeneration
Explanation 6 task295semeval2020task4commonsensereasoning,task192hotpotqasentencegeneration,task593
sciq explanation generation, task1369 healthfact sentence generation, task223 quartz explanation
generation,task134winowhyreasongeneration
Grammar
Error 2 task1415youtubecaptioncorrectionsgrammarcorrection,task1557jfleganswergeneration
Correction
Number
2 task1703ljspeechtextmodification,task1704ljspeechtextmodification
Conversion
Overlap
2 task039qascfindoverlappingwords,task281pointsofcorrespondence
Extraction
Paraphrasing 12 task776 pawsx japanese text modification, task045 miscellaneous sentence paraphrasing, task770
pawsxenglishtextmodification,task771pawsxkoreantextmodification,task774pawsxgermantext
modification,task177para-nmtparaphrasing,task466parsinluqqptextmodification,task775pawsx
chinesetextmodification,task1614sicktextmodify,task773pawsxspanishtextmodification,task132
daistextmodification,task772pawsxfrenchtextmodification
Program
90 task113countfrequencyofletter,task1151swapmaxmin,task509collateofallalphabeticaland
Execution
numericalelementsinlistseparately,task100concatenateallelementsfromindexitoj,task096conala
listindexsubtraction,task365syntheticremovevowels,task622replacealphabetsinalistbytheir
positioninenglishalphabet,task852syntheticmultiplyodds,task1088arrayofproducts,task1405find
median,task637extractandsortuniquedigitsinalist,task1446farthestintegers,task506positionof
allalphabeticalelementsinlist,task378reversewordsofgivenlength,task093conalanormalizelists,
task1404dateconversion,task097conalaremoveduplicates,task372syntheticpalindromenumbers,
task755findlongestsubstringandreplaceitssortedlowercaseversioninbothlists,task636extract
andsortuniquealphabetsinalist, task267concatenateandreverseallelementsfromindexitoj,
task162countwordsstartingwithletter,task159checkfrequencyofwordsinsentencepair,task208
combinationsoflist,task1316removeduplicatesstring,task504countallalphabeticalelementsinlist,
task079conalaconcatstrings,task158countfrequencyofwords,task507positionofallnumerical
elementsinlist,task374syntheticposornegcalculation,task1087twonumbersum,task163count
wordsendingwithletter,task756findlongertsubstringandreturnalluniquealphabetsinit,task101
reverseandconcatenateallelementsfromindexitoj,task1551everyithelementfromkthelement,
task606sumofallnumbersinlistbetweenpositionsiandj,task368syntheticevenoroddcalculation,
task1150deletemaxmin,task851syntheticmultiplyevens,task377removewordsofgivenlength,
task063firstielements,task064allelementsexceptfirsti,task245checkpresenceinsetintersection,
task161countwordscontainingletter, task605findthelongestcommonsubsequenceintwolists,
task850syntheticlongestpalindrome,task157countvowelsandconsonants,task373syntheticround
tens place, task206 collatz conjecture, task1443 string to number, task123 conala sort dictionary,
task244countelementsinsetunion,task499extractandaddallnumbersfromlist,task124conala
pairaverages,task1444roundpoweroftwo,task099reverseelementsbetweenindexiandj,task1089
checkmonotonicarray,task1188countmaxfreqchar,task125conalapairdifferences,task488extract
allalphabeticalelementsfromlistinorder,task1542everyithelementfromstarting,task1194kth
largestelement,task371syntheticproductoflist,task1406kthsmallestelement,task095conalamax
absolutevalue,task1315findrangearray,task243countelementsinsetintersection,task1331reverse
array,task062bigbenchrepeatcopylogic,task122conalalistindexaddition,task091allelementsfrom
indexitoj,task369syntheticremoveodds,task497extractallnumbersfromlistinorder,task505
countallnumericalelementsinlist,task205removeevenelements,task1189checkcharinstring,
task1445closestintegers,task094conalacalculatemean,task160replaceletterinasentence,task1148
maximumasciivalue,task098conalalistintersection,task078allelementsexceptlasti,task523find
ifnumbersoralphabetsaremoreinlist,task370syntheticremovedivisibleby3,task367synthetic
removefloats,task1190addintegertolist,task376reverseorderofwords,task600findthelongest
commonsubstringintwostrings,task207maxelementlists,task366syntheticreturnprimesTableA1–continuedfrompreviouspage
Task No. Dataset
Question
207 task837viquiquadanswergeneration,task701mmmluanswergenerationhighschoolcomputersci-
Answering
ence,task1399obqaanswergeneration,task075squad1.1answergeneration,task724mmmluanswer
generationmoralscenarios,task666mmmluanswergenerationastronomy,task742lhoestqanswer
generation frequency, task1438 doqa cooking answer generation, task863 asdiv multiop question
answering,task864asdivsingleopquestionanswering,task058multircquestionanswering,task669
ambigqaanswergeneration,task704mmmluanswergenerationhighschoolgovernmentandpolitics,
task728mmmluanswergenerationprofessionalaccounting,task740lhoestqanswergenerationquan-
tity,task1293kilttaskshotpotqaquestionanswering,task849pubmedqaanswergeneration,task1424
mathqaprobability,task1625disflqaasnwergeneration,task858inquisitivespandetection,task723
mmmluanswergenerationmoraldisputes,task083babit1singlesupportingfactanswergeneration,
task118semeval2019task10openvocabularymathematicalanswergeneration,task582naturalques-
tionanswergeneration,task237iircanswerfromsubtextanswergeneration,task714mmmluanswer
generationhumansexuality,task444comqaquestionparaphrasesanswergeneration,task720mmmlu
answergenerationmarketing,task332tellmewhyanswergeneration,task119semeval2019task10geo-
metricmathematicalanswergeneration,task310raceclassification,task1132xcsrurcommonsensemc
classification,task702mmmluanswergenerationhighschooleuropeanhistory,task710mmmluanswer
generationhighschoolstatistics,task870msmarcoanswergeneration,task047miscellaneousanswer-
ingsciencequestions,task711mmmluanswergenerationhighschoolushistory,task1286openbookqa
questionanswering,task598cuadanswergeneration,task685mmmluanswergenerationclinicalknowl-
edge,task084babit1singlesupportingfactidentifyrelevantfact,task1420mathqageneral,task1520
qasrlanswergeneration,task868mawpssingleopquestionanswering,task768qedtextspanselection,
task061ropesanswergeneration,task041qascanswergeneration,task144subjqaquestionanswering,
task1570cmrc2018answergeneration,task1610xquadesanswergeneration,task164mcscriptquestion
answeringtext,task703mmmluanswergenerationhighschoolgeography,task705mmmluanswer
generationhighschoolmacroeconomics,task1131xcsrescommonsensemcclassification,task1130
xcsrvicommonsensemcclassification,task750aquamultiplechoiceanswering,task473parsinlu
mcclassification,task385socialiqaincorrectanswergeneration,task691mmmluanswergeneration
collegephysics,task719mmmluanswergenerationmanagement,task1327qazreanswergeneration
fromquestion,task715mmmluanswergenerationinternationallaw,task737mmmluanswergeneration
worldreligions,task010mctacoanswergenerationeventordering,task741lhoestqanswergeneration
place, task028dropanswergeneration, task730mmmluanswergenerationprofessionalmedicine,
task491mwscanswergeneration,task716mmmluanswergenerationjurisprudence,task732mmmlu
answer generation public relations, task735 mmmlu answer generation us foreign policy, task898
freebaseqaanswergeneration,task887quailanswergeneration,task024cosmosqaanswergeneration,
task1140xcsrplcommonsensemcclassification,task225englishlanguageanswergeneration,task1608
xquadenanswergeneration,task170hotpotqaanswergeneration,task667mmmluanswergeneration
businessethics,task699mmmluanswergenerationhighschoolbiology,task595mochaanswergener-
ation,task751svampsubtractionquestionanswering,task1656gooaqanswergeneration,task1431
headqaanswergeneration,task1296wikihopquestionanswering,task490mwscoptionsgeneration,
task867mawpsmultiopquestionanswering,task865mawpsaddsubquestionanswering,task1133
xcsrnlcommonsensemcclassification,task1422mathqaphysics,task1135xcsrencommonsensemc
classification,task054multircwritecorrectanswer,task1661superglueclassification,task708mmmlu
answergenerationhighschoolphysics,task1726mathqacorrectanswergeneration,task664mmmlu
answergenerationabstractalgebra,task1412webquestionsquestionanswering,task002quorefanswer
generation, task752 svamp multiplication question answering, task1297 qasc question answering,
task692mmmluanswergenerationcomputersecurity,task1136xcsrfrcommonsensemcclassification,
task727mmmluanswergenerationprehistory,task725mmmluanswergenerationnutrition,task104
semeval2019task10closedvocabularymathematicalanswergeneration, task694mmmluanswer
generationeconometrics,task820protoqaanswergeneration,task700mmmluanswergenerationhigh
schoolchemistry,task390torquetextspanselection,task1421mathqaother,task918coqaanswer
generation,task309raceanswergeneration,task247dreamanswergeneration,task695mmmluanswer
generationelectricalengineering,task230iircpassageclassification,task712mmmluanswergenera-
tionhighschoolworldhistory,task731mmmluanswergenerationprofessionalpsychology,task596
mochaquestiongeneration,task698mmmluanswergenerationglobalfacts,task718mmmluanswer
generationmachinelearning,task395persianqaanswergeneration,task597cuadanswergeneration,
task339recordanswergeneration,task835mathdatasetanswergeneration,task238iircanswerfrom
passageanswergeneration,task228arcanswergenerationeasy,task380boolqyesnoquestion,task152
tomqafindlocationeasynoise,task754svampcommon-divisionquestionanswering,task713mmmlu
answergenerationhumanaging,task665mmmluanswergenerationanatomy,task706mmmluanswer
generationhighschoolmathematics,task697mmmluanswergenerationformallogic,task753svamp
additionquestionanswering,task1727wiqawhatistheeffect,task1139xcsrrucommonsensemc
classification,task1134xcsrhicommonsensemcclassification,task344hybridqaanswergeneration,
task165mcscriptquestionansweringcommonsense,task1145xcsrjapcommonsensemcclassification,
task1295 adversarial qa question answering, task239 tweetqa answer generation, task1382 quarel
writecorrectanswer,task866mawpsmultidivquestionanswering,task151tomqafindlocationeasy
clean,task591sciqanswergeneration,task717mmmluanswergenerationlogicalfallacies,task726
mmmluanswergenerationphilosophy,task1419mathqagain,task1423mathqageometry,task231iirc
linkclassification,task049multircquestionsneededtoanswer,task734mmmluanswergeneration
sociology,task580socialiqaanswergeneration,task736mmmluanswergenerationvirology,task729...TableA1–continuedfrompreviouspage
Task No. Dataset
Translation 394 task808 pawsx chinese korean translation, task254 spl translation fi en, task1111 ted translation
he it, task988 pib translation oriya english, task650 opus100 ar en translation, task763 emea es
lt translation, task1648 opus books en-sv translation, task1263 ted translation pl fa, task1020 pib
translationteluguoriya,task913bianettranslation,task1060pibtranslationurdumalayalam,task1676
xquad-catranslation,task1098tedtranslationjafa,task984pibtranslationmarathigujarati,task1086
pibtranslationmarathienglish,task789pawsxfrenchenglishtranslation,task1110tedtranslationhegl,
task1689qedamaratranslation,task787pawsxkoreanchinesetranslation,task1071pibtranslation
malayalam marathi, task548 alt translation en ch, task1373 newscomm translation, task1023 pib
translationenglishhindi, task1271tedtranslationfait, task1274tedtranslationpten, task552alt
translationenbu,task1040pibtranslationpunjabioriya,task1323opensubtitleshientranslation,
task1058pibtranslationurduenglish,task1105tedtranslationargl,task1353hindencorptranslationen
hi,task1085pibtranslationenglishmarathi,task1103tedtranslationesfa,task784pawsxkoreanfrench
translation,task811pawsxchinesegermantranslation,task1365opustedtalkstranslation,task1278
ted translation pt he, task1115 alt ja id translation, task538 alt translation bu en, task786 pawsx
koreangermantranslation,task805pawsxgermanchinesetranslation,task1692qedamaratranslation,
task1690qedamaratranslation,task655bibleenfatranslation,task1256tedtranslationplen,task977
pibtranslationoriyaurdu,task841parapdtdeentranslation,task996pibtranslationenglishbengali,
task531europarlesentranslation,task452opusparacrawlenigtranslation,task1250tedtranslationit
ar,task644refresdtranslation,task1248tedtranslationitja,task1034pibtranslationhindigujarati,
task1225tedtranslationjahe, task997pibtranslationbengalioriya, task1127altjathtranslation,
task783pawsxkoreanenglishtranslation,task1031pibtranslationbengalitelugu,task560alttranslation
enentk,task1000pibtranslationtamilmalayalam,task252spltranslationentr,task1650opusbooks
en-fitranslation,task654biblefaentranslation,task802pawsxgermankoreantranslation,task1025
pibtranslationbengalipunjabi,task262spltranslationjaen,task785pawsxkoreanspanishtranslation,
task530 europarl en es translation, task1232 ted translation ar es, task799 pawsx spanish chinese
translation,task1119altfiljatranslation,task260spltranslationzhen,task1686menyo20ktranslation,
task448opusparacrawlentltranslation,task994pibtranslationtamilhindi,task1065pibtranslation
punjabitelugu,task557alttranslationenba,task1072pibtranslationmarathimalayalam,task535alt
translationchen,task762emeafrsktranslation,task1024pibtranslationhindienglish,task914bianet
translation,task779pawsxenglishspanishtranslation,task547alttranslationentken,task1128altthja
translation,task537alttranslationthen,task1277tedtranslationptar,task1124altjalotranslation,
task1514florestranslationentone,task435altenjatranslation,task425hindienglishcorporaenhi
translation,task1371newscommtranslation,task818pawsxjapanesechinesetranslation,task873opus
xhosanavytranslationxhosaeng,task1240tedtranslationgles,task553alttranslationenma,task1351
opus100translationguen,task999pibtranslationmalayalamtamil,task438enggujparallelcorpus
engutranslation,task541alttranslationkhen,task1329opensubtitlesenhitranslation,task1102ted
translationespl,task661mizanenfatranslation,task1259tedtranslationplar,task424hindienglish
corporahientranslation,task793pawsxfrenchchinesetranslation,task1005pibtranslationmalayalam
punjabi,task1262tedtranslationplit,task1367opustedtalkstranslation,task117spltranslationen
de, task1237 ted translation he ar, task1122 alt khm ja translation, task1230 ted translation ar en,
task790pawsxfrenchkoreantranslation,task433althientranslation,task253spltranslationenzh,
task1037pibtranslationteluguurdu,task840parapdtenestranslation,task982pibtranslationtamil
bengali,task1009pibtranslationbengalihindi,task1062pibtranslationmarathibengali,task1218ted
translationenja,task1113tedtranslationhefa,task1691qedamaratranslation,task1276tedtranslation
ptes,task1108tedtranslationarfa,task1070pibtranslationurdubengali,task1244tedtranslation
glpl, task1239tedtranslationglja, task1055pibtranslationmarathioriya, task794pawsxfrench
japanesetranslation,task1004pibtranslationmalayalambengali,task1049pibtranslationmalayalam
telugu,task989pibtranslationmarathiurdu,task450opusparacrawlsoentranslation,task815pawsx
japanesefrenchtranslation,task1066pibtranslationtelugupunjabi,task777pawsxenglishkorean
translation,task542alttranslationjaen,task830poleval2019mttranslation,task1655mkbtranslation,
task313europarlensvtranslation,task1044pibtranslationpunjabigujarati,task1038pibtranslation
urdutelugu,task1057pibtranslationenglishurdu,task1047pibtranslationenglishtelugu,task1258
tedtranslationples,task1001pibtranslationgujaratiurdu,task1063pibtranslationgujaratitamil,
task1649opusbooksen-notranslation,task1282tedtranslationptfa,task983pibtranslationgujarati
marathi, task261 spl translation es en, task439 eng guj parallel corpus gu en translation, task795
pawsxspanishenglishtranslation,task1046pibtranslationteluguhindi,task1233tedtranslationar
he,task1112tedtranslationhepl,task663globalvoicesenfatranslation,task662globalvoicesfaen
translation,task1376newscommtranslation,task258spltranslationfaen,task1029pibtranslation
marathipunjabi,task986pibtranslationoriyahindi,task1067pibtranslationbengaligujarati,task604
florestranslationentosn, task1224tedtranslationjaar, task250spltranslationenar, task1242ted
translation gl he, task559 alt translation en fi, task1015 pib translation punjabi tamil, task259 spl
translationtren,task1269tedtranslationfahe,task807pawsxchineseenglishtranslation,task809
pawsxchinesefrenchtranslation,task995pibtranslationbengalienglish,task1093tedtranslationen
fa,task174spltranslationenja,task1036pibtranslationurdutamil,task1245tedtranslationglfa,
task1081pibtranslationhindimarathi,task1249tedtranslationites,task842parapdtcsentranslation,
task1006pibtranslationpunjabimalayalam,task1091tedtranslationenit,task1022pibtranslation
malayalamenglish,task656quranenfatranslation,task1435rostsparallellanguagetranslationroto
en,task1219tedtranslationenes,task782pawsxenglishjapanesetranslation,task1054pibtranslation
urduhindi,task1035pibtranslationtamilurdu,task554alttranslationenla,task993pibtranslation
hinditamil,task540alttranslationlaen,task556alttranslationenja,task1324opensubtitlesteen...TableA1–continuedfrompreviouspage
Task No. Dataset
Sentence
1 task1340msrtextcompressioncompression
Compression
Summarization16 task1357xlsumsummarygeneration,task672amazonandyelpsummarizationdatasetsummarization,
task1579gigawordincorrectsummarization,task1658billsumsummarization,task618amazonreview
summarytextgeneration,task522newseditorialsummary,task1355sentcompsummarization,task589
amazonfood summary text generation, task1553 cnn dailymail summarization, task1572 samsum
summary,task1291multinewssummarization,task668extremeabstractsummarization,task1309
amazonreviewsummaryclassification,task1499dstc3summarization,task1290xsumsummarization,
task511reddittifulongtextsummarization
Text
to 12 task210logic2textstructuredtextgeneration,task107splashquestiontosql,task077splashexplanation
Code tosql,task076splashcorrectingsqlmistake,task130scanstructuredtextgenerationcommandaction
long,task869cfqmcd1sqltoexplanation,task212logic2textclassification,task126scanstructured
textgenerationcommandactionall, task211logic2textclassification, task128scanstructuredtext
generationcommandactionshort,task868cfqmcd1explanationtosql,task956leetcode420strong
passwordcheck
Title
19 task1540parsedpdfssummarization,task1561clickbaitnewbgsummarization,task769qedsumma-
Generation
rization,task1342amazonusreviewstitle,task1356xlsumtitlegeneration,task569recipenlgtext
generation,task1161coda19titlegeneration,task220rocstoriestitleclassification,task219rocstories
titleanswergeneration, task1586scifacttitlegeneration, task602wikitext-103answergeneration,
task1358xlsumtitlegeneration,task1659titlegeneration,task418persenttitlegeneration,task743
eurlexsummarization,task288gigawordsummarization,task500scruplesanecdotestitlegeneration,
task619ohsumedabstracttitlegeneration,task510reddittifutitlesummarization
TableA2: DatasetlistforeachNLGtaskfromSuper-NaturalInstructions.