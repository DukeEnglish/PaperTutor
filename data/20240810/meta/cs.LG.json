[
    {
        "title": "Transformer Explainer: Interactive Learning of Text-Generative Models",
        "authors": "Aeree ChoGrace C. KimAlexander KarpekovAlec HelblingZijie J. WangSeongmin LeeBenjamin HooverDuen Horng Chau",
        "links": "http://arxiv.org/abs/2408.04619v1",
        "entry_id": "http://arxiv.org/abs/2408.04619v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04619v1",
        "summary": "Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.",
        "updated": "2024-08-08 17:49:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04619v1"
    },
    {
        "title": "Better Alignment with Instruction Back-and-Forth Translation",
        "authors": "Thao NguyenJeffrey LiSewoong OhLudwig SchmidtJason WestonLuke ZettlemoyerXian Li",
        "links": "http://arxiv.org/abs/2408.04614v1",
        "entry_id": "http://arxiv.org/abs/2408.04614v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04614v1",
        "summary": "We propose a new method, instruction back-and-forth translation, to construct\nhigh-quality synthetic data grounded in world knowledge for aligning large\nlanguage models (LLMs). Given documents from a web corpus, we generate and\ncurate synthetic instructions using the backtranslation approach proposed by Li\net al.(2023a), and rewrite the responses to improve their quality further based\non the initial documents. Fine-tuning with the resulting (backtranslated\ninstruction, rewritten response) pairs yields higher win rates on AlpacaEval\nthan using other common instruction datasets such as Humpback, ShareGPT, Open\nOrca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the\nresponses with an LLM outperforms direct distillation, and the two generated\ntext distributions exhibit significant distinction in embedding space. Further\nanalysis shows that our backtranslated instructions are of higher quality than\nother sources of synthetic instructions, while our responses are more diverse\nand complex than those obtained from distillation. Overall we find that\ninstruction back-and-forth translation combines the best of both worlds --\nmaking use of the information diversity and quantity found on the web, while\nensuring the quality of the responses which is necessary for effective\nalignment.",
        "updated": "2024-08-08 17:42:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04614v1"
    },
    {
        "title": "Risk and cross validation in ridge regression with correlated samples",
        "authors": "Alexander AtanasovJacob A. Zavatone-VethCengiz Pehlevan",
        "links": "http://arxiv.org/abs/2408.04607v1",
        "entry_id": "http://arxiv.org/abs/2408.04607v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04607v1",
        "summary": "Recent years have seen substantial advances in our understanding of\nhigh-dimensional ridge regression, but existing theories assume that training\nexamples are independent. By leveraging recent techniques from random matrix\ntheory and free probability, we provide sharp asymptotics for the in- and\nout-of-sample risks of ridge regression when the data points have arbitrary\ncorrelations. We demonstrate that in this setting, the generalized cross\nvalidation estimator (GCV) fails to correctly predict the out-of-sample risk.\nHowever, in the case where the noise residuals have the same correlations as\nthe data points, one can modify the GCV to yield an efficiently-computable\nunbiased estimator that concentrates in the high-dimensional limit, which we\ndub CorrGCV. We further extend our asymptotic analysis to the case where the\ntest point has nontrivial correlations with the training set, a setting often\nencountered in time series forecasting. Assuming knowledge of the correlation\nstructure of the time series, this again yields an extension of the GCV\nestimator, and sharply characterizes the degree to which such test points yield\nan overly optimistic prediction of long-time risk. We validate the predictions\nof our theory across a variety of high dimensional data.",
        "updated": "2024-08-08 17:27:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04607v1"
    },
    {
        "title": "Inference with the Upper Confidence Bound Algorithm",
        "authors": "Koulik KhamaruCun-Hui Zhang",
        "links": "http://arxiv.org/abs/2408.04595v1",
        "entry_id": "http://arxiv.org/abs/2408.04595v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04595v1",
        "summary": "In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.",
        "updated": "2024-08-08 17:11:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04595v1"
    },
    {
        "title": "Learn To Learn More Precisely",
        "authors": "Runxi ChengYongxian WeiXianglong HeWanyun ZhuSongsong HuangFei Richard YuFei MaChun Yuan",
        "links": "http://arxiv.org/abs/2408.04590v1",
        "entry_id": "http://arxiv.org/abs/2408.04590v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04590v1",
        "summary": "Meta-learning has been extensively applied in the domains of few-shot\nlearning and fast adaptation, achieving remarkable performance. While\nMeta-learning methods like Model-Agnostic Meta-Learning (MAML) and its variants\nprovide a good set of initial parameters for the model, the model still tends\nto learn shortcut features, which leads to poor generalization. In this paper,\nwe propose the formal conception of \"learn to learn more precisely\", which aims\nto make the model learn precise target knowledge from data and reduce the\neffect of noisy knowledge, such as background and noise. To achieve this\ntarget, we proposed a simple and effective meta-learning framework named Meta\nSelf-Distillation(MSD) to maximize the consistency of learned knowledge,\nenhancing the models' ability to learn precise target knowledge. In the inner\nloop, MSD uses different augmented views of the same support data to update the\nmodel respectively. Then in the outer loop, MSD utilizes the same query data to\noptimize the consistency of learned knowledge, enhancing the model's ability to\nlearn more precisely. Our experiment demonstrates that MSD exhibits remarkable\nperformance in few-shot classification tasks in both standard and augmented\nscenarios, effectively boosting the accuracy and consistency of knowledge\nlearned by the model.",
        "updated": "2024-08-08 17:01:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04590v1"
    }
]