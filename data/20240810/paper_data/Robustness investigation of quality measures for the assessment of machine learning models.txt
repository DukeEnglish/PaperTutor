Robustness investigation of quality measures
for the assessment of machine learning
models
Thomas Most Lars Gra¨ning
Ansys Germany GmbH Ansys Germany GmbH
Weimar,Germany Weimar,Germany
Sebastian Wolff
Ansys Austria GmbH
Vienna,Austria
ABSTRACT
In this paper the accuracy and robustness of quality measures for the assessment of machine learning
modelsareinvestigated. Thepredictionqualityofamachinelearningmodelisevaluatedmodel-independent
based on a cross-validation approach, where the approximation error is estimated for unknown data. The
presented measures quantify the amount of explained variation in the model prediction. The reliability of
thesemeasuresisassessedbymeansofseveralnumericalexamples,whereanadditionaldatasetforthever-
ificationoftheestimatedpredictionerrorisavailable. Furthermore,theconfidenceboundsofthepresented
qualitymeasuresareestimatedandlocalqualitymeasuresarederivedfromthepredictionresidualsobtained
bythecross-validationapproach.
1 INTRODUCTION
Nowadays,theapplicationofmathematicalsurrogatemodelsplaysanimportantroleinengineeringdesign.Start-
ingwithclassicalDesignofExperimentschemesandclassicalpolynomialresponsesurfacemodels[1],[2],meanwhile
a wide range of surrogate models has been developed such as Kriging [3], Moving Least Squares [4], Radial Basis
Functions[5]andSupportVectorMachines[6]. Recently,artificialneuralnetworks[7]havebeenextendedtomore
sophisticatedDeepLearningmodels[8]whichcanbeappliedonaverywiderangeofengineeringfields[9]. Agood
overviewofcurrentapplicationsofsurrogatemodelsinglobaloptimizationisgivenin[10]andrecentdevelopments
insurrogate-assistedglobalsensitivityanalysiscanbefoundin[11]. Investigationsontheaccuracyofmachinelearn-
ingmodelsforuncertaintyquantificationarepublishedin[12],[13]. Furtherreviewsonengineeringapplicationsare
availablee.g. in[14],[15]and[16].
Generally,theapplicationofsurrogatemodelswillintroduceadditionalmodelerrorsintheprediction.Dependent
ontheapplication,theapproximationqualityandtheverificationofthesurrogatemodelisverycriticaltoasuccessful
application. Asdiscussedin[17],[18]theassessmentofthepredictionqualityforunknowndataisnecessary. Aquite
common approach for this purpose is the well-known cross validation. Based on this procedure the approximation
errorsofunknowndatapointscanbeestimated.In[19]avarianced-basedqualitymeasure,theCoefficientofPrognosis
(CoP)wasintroducedbasedonthisprinciple.Withhelpofthismeasureamodelindependentassessmentandselection
4202
guA
8
]LM.tats[
1v19340.8042:viXraispossiblewhichwasrealizedintheMetamodelofOptimalPrognosis(MOP)in[19]andextendedfordeep-learning
modelsin[20].
Inthispaper,therobustnessandstabilityofthesequalitymeasuresbyusingdifferentcrossvalidationprocedures
are investigated. Based on the prediction residuals, the confidence bounds of the CoP are estimated and verified by
means of several numerical examples. Additional to the global quality measures, a local model independent error
estimatorisintroduced,whichcanbeutilizedforlocalmodelimprovementbyadditionalsamples. Inthispaper,we
limit the investigation to scalar inputs and outputs of a mathematical surrogate model. An extension to parametric
non-scalarinputsandoutputsisstraightforwardasinvestigatedin[21].
2 QUALITYMEASURESFORTHEMODELASSESSMENT
2.1 Measuringthegoodnessoffit
Let us assume a simulation model with a certain number of scalar outputs. Each of these outputs can be repre-
sentedasablack-boxfunctionofagivennumberofinputs
y(x)=f(x ,x ,...,x ). (1)
1 2 m
Iftheseoutputfunctionsareapproximatedbyamathematicalsurrogatemodel,weobtainanapproximationofthetrue
function
yˆ(x)=fˆ(x ,x ,...,x ). (2)
1 2 m
Iftheapproximationmodelisbuildortrainedbasedonagivennumberofsupportpointsn,wecancalculatethe
residualsforeachofthesupportpointsandestimatedifferenterrormeasurestoquantifythegoodnessoffit
ϵ =y(x )−yˆ(x )=y −yˆ. (3)
i i i i i
Onewellknownmeasureistherootmeansquarederror(RMSE)
(cid:118)
(cid:117) n
(cid:117)1 (cid:88)
RMSE =(cid:116)
n
(y i−yˆ i)2, (4)
i=1
whichhasthesameunitastheoutputitselfandcanbeinterpretedasthestandarddeviationoftheapproximationerror.
Anotherwell-knownmeasureistheunitlessCoefficientofDetermination(CoD)
SS
CoD =1− E, 0≤CoD ≤1, (5)
SS
T
which measures the ratio of the explained vs. the original variation of the investigated response. The sum of total
squares SS is equivalent to the total variation of the response and the sum of squared errors SS quantifies the
T E
unexplainedvariation
n n n
(cid:88) 1 (cid:88) (cid:88)
SS = (y −µ )2, µ = y , SS = (y −yˆ)2. (6)
T i Y Y n i E i i
i=1 i=1 i=1
TheRMSEandtheCoDarebothmeasuresforthegoodnessoffit,whichquantifythedeviationbetweenthesupport
point values used for the training and the approximation values at these points. Unfortunately, this will not give us
anyinformationofthepredictionqualityofthesurrogatemodelforunknowndatapoints. Infigure1aninterpolation
functionofthedistorteddataofaquadraticfunctionisshown. TheCoDwouldindicateaperfectmatchbetweenthe
dataandtheinterpolationmodel,althoughtheoriginalfunctionwasnotrepresentedwell.Fig.1. Interpolationofdistorteddatapointsofanquadraticfunctionwithaninterpolationmodelwithperfectgoodnessoffit
2.2 Measuringtheprognosisquality
Fig.2. Basiccross-validationprocedurebysplittingthedatasetintwosubsets:Usingsetonefortrainingandsettwoforprediction
(left)andsettwofortrainingandsetoneforprediction(right)
Inordertoestimatethepredictionerrorofamathematicalsurrogatemodel,wecansplitthedatasete.g. intwo
datasetsofsamesizeandusesetnumberoneforthetrainingandsetnumbertwofortheestimationoftheprediction
errors. In a second step this procedure is applied by using data set two for the training and data set one for the
estimation. Thisprocedureasshowninfigure2iscalledcross-validationandisexplainedinmoredetailin[18]. More
generally, we can subdivide the original data set in q subsets of almost equal size, where the points in each subset
should be selected in that way that they cover the investigated space of the input variables almost uniformly. Thus,
eachofthensupportpointsaremappedtoonesubset
ζ :{1,...,n}→{1,...,q}. (7)
Once, the q individual cross validation models have been trained, we use the approximation values to evaluate the
predictionresidualsforeachoftheavailabledatapoints
yˆcv(x )=fˆ (x ), (8)
i ∼ζ(i) iwherefˆ (.)istheapproximationmodelbuiltbyusingallcrossvalidationsubsetsexcepttheonesetbelongingto
∼ζ(i)
thesupportpointi. Fromthispredictionthecorrespondingresidualsofthecross-validationpredictionerrorscanbe
estimatedas
ϵcv =y(x )−yˆcv(x )=y −yˆcv. (9)
i i i i i
Theresidualsofthegoodnessoffitinequation3andofthecross-validationresidualscanbedisplayedinaso-called
residualplotasshowninfigure3. Ifalargedeviationoftheresidualsfromthefitandthepredictioncanbeobserved,
wecanassumethattheappliedsurrogatemodeltendstoover-fitting.
Fig.3. Residualplotwiththefittingandpredictionresiduals(left)andsampleCoP,whichquantifiesthecontributionofeachsample
totheCoP(right).Onepossibleoutlierisindicatedinredwhichisoutsidetherangeof±3×RMSEcv.
Basedonthepredictionresidualswecanestimatetherootmeansquarederror
(cid:118)
(cid:117) n
(cid:117)1 (cid:88)
RMSEcv =(cid:116)
n
(y i−yˆ icv)2, (10)
i=1
andtheCoefficientofPrognosis[19]
SScv (cid:88)n
CoP =1− E , SScv = (y −yˆcv)2. (11)
SS E i i
T
i=1
TheestimatedRMSEinequation10canbeusedtoidentifypossibleoutliers. SincetheRMSEcanbeunderstoodas
thestandarddeviationoftheapproximationerror,wecanassumeaboundaryofabout±3×RMSEcv tocheckfor
outliers. Intheresidualplotinfigure3,thisisindicatedasthetworedlines.
Usually,5-10subsetsareusedwithinthecrossvalidationproceduretoobtainstableestimators[18]. Thisproce-
dureisusuallycalledk-foldcrossvalidation.Sincesomemathematicalsurrogatemodelsprovideclosedformsolutions
foran-foldcrossvalidation,whereeachsetbelongsjusttoasinglesample,thisso-calledleave-one-out(LOO)cross
validationis veryattractivefromthe computationalpointof view. However, inourexamples wewillshow, that theLOO cross validation may be to optimistic as an error estimator and the k-fold cross validation gives more reliable
results.
In order to get an estimate, how the residuals of an individual support point x contribute to the CoP, we can
i
furtherformulatethesampleCoPasfollows
(y −yˆcv)2
CoP =1− i i , (12)
xi SS
T
whichisshownadditionallyinfigure3. Thefigureclearlyindicates,thatthesampleCoPmayhelptodetectoutliers
more clearly by using a different scaling. The mean value of all individual sample CoPs is consequently the global
CoPvalueintroducedinequation11.
2.3 Localmeasuresoftheprognosisquality
Fig.4. Estimatedlocalrootmeansquarederror(left)andthelocalCoefficientofPrognosis(right)assubspaceplotina5Dinput
space.
Based on the individual residuals of each support point we can formulate a continuous function of the local
prediction error for an arbitrary point in the input space. By using a local averaging scheme similar to the Moving
LeastSquaresapproximation[4]thelocallyweightedRMSEandthelocalCoPreadasfollows
(cid:115)
(cid:80)n w (x)(y −yˆcv)2
RMSEcv(x)= i=1 i i i , (13)
(cid:80)n
w (x)
i=1 i
(cid:80)n w (x)(y −yˆcv)2 n n·(RMSEcv(x))2
CoP(x)=1− i=1 i i i · =1− , (14)
(cid:80)n
w (x) SS SS
i=1 i T Twherew (x)ischosenasanexponential,isotropicweightingfunction,whichisscaledwithrespecttothenumberof
i
necessaryaveragingpoints. Infigure4theestimatedlocalpredictionerrorsareshownfortheresidualsfromfigure3.
Thefigureindicates,thatintheregionoftheidentifiedoutliertheapproximationqualityisworst.
Thepresentedlocalpredictionerrorscanbeeasilyutilizedinanadaptionschemee.g. fortheexpectedimprove-
ment criterion according to [22]. The advantage of this error estimator is its independence w.r.t. the approximation
model. Thusitcanbeappliedforsimplepolynomialmodelsinthesamemannerasformoresophisticateddeeplearn-
ingnetworks. ThisestimatorhasbeenappliedintheAdaptiveMetamodelofOptimalPrognosis(AMOP)[23]inthe
Ansys optiSLang software package. With help of the local RMSE the prediction uncertainty of an investigated sur-
rogatemodelcanbeinterpretedasanormallydistributedrandomprocess,wherethemeancorrespondstothemodel
approximationitselfandthestandarddeviationtotheestimatedlocalRMSE.
2.4 Quantificationoftheinputsensitivity
Ifweinterpretthescalaroutputofasimulationmodelaswellastheminputparametersastherandomnumbers
Y andX ,thefirstordersensitivityindexcanbeformulatedfortheinputX accordingto[24]asfollows
i i
V (E (Y|X ))
S = Xi X∼i i , (15)
i V(Y)
where V(Y) is the unconditional variance of the model output Y and V (E (Y|X )) is called the variance of
Xi X∼i i
conditional expectation with X denoting the matrix of all inputs without X . Thus, V (E (Y|X )) measures
∼i i Xi X∼i i
the first order effect of X on the model output. The first order sensitivity indices quantify only the contribution
i
of a single input to the output variance, but not the interaction with other inputs. In order to quantify higher order
interactionterms,thetotaleffectsensitivityindiceshavebeenintroducedin[25]asfollows
V (E (Y|X ))
S =1− X∼i Xi ∼i , (16)
Ti V(Y)
where V (E (Y|X )) measures the first order effect of X on the model output which does not contain any
X∼i Xi ∼i ∼i
effectcorrespondingtoX .
i
Inourimplementationweusethefirstorderandtotaleffectindicestoquantifytheimportanceoftheinputswith
respecttotheapproximatedmodeloutputyˆ(x). Sincetheapproximationmodelisnotrepresentingthefullvariance
oftheoriginalresponsey(x),weusetheestimatedCoPtoquantifythisproportion
Sˆcv =CoP ·Sˆ, Sˆcv =CoP ·Sˆ , (17)
i i Ti Ti
where the CoP is estimated using equation 11 and Sˆ and Sˆ are the estimated first order and total effect indices
i Ti
using the surrogate model approximation instead of the original model, whereby the input variables are assumed to
beuniformelydistributedwithinthegivensamplingbounds. Furtherdetailsonthecomputationoftheestimatorsof
Sˆ and Sˆ can be found in [26], [27]. For correlated inputs a modification of the estimators is necessary which is
i Ti
explainedindetailin[26].
2.5 Estimationofconfidenceboundsusingbootstrapping
Oncethecross-validationresidualsandthepredictionqualityestimatorshavebeenevaluated,onemayneedfur-
therinformationontheconfidenceboundsoftheseestimators. Forthispurpose,weapplythebootstrappingmethod
introduced in [28]. In this method the statistical properties of an estimator are obtained by sampling from an ap-
proximate distribution which can be the empirical distribution of the observed data or a parametrized form of this
distribution. Inourstudyweusethemostcommonapproach,thenon-parametricbootstrapping,wherethesampling
is done directly from the empirical distribution of the original observations. This method assumes independent andObservations Bootstrapsetj
ϵcv ϵ∗ = ϵcv
1 1,j 3
ϵcv ϵ∗ = ϵcv
2 2,j 1
ϵcv ϵ∗ = ϵcv
3 3,j 5
ϵcv ϵ∗ = ϵcv
4 4,j 3
ϵcv Randomchoice ϵ∗ = ϵcv
5 withreplacement 5,j 2
Fig.5. Principleofnon-parametricbootstrapmethod:generationofabootstrapsamplesetfromtheoriginalresidualsetbyrandom
choicewithreplacement
identically distributed observations and constructs a number of re-samples from the original samples. In [29] this
procedureisdiscussedindetailfortheestimationofstatisticalmomentsofmaterialproperties.
Inourstudyweassumethecrossvalidationresidualsoftheapproximationfunctioninequation9asindependent
observationsofanunknownrandomnumber.Fromthisoriginalsetofobservationsϵcv,ϵcv,...,ϵcvabootstrapsample
1 2 n
set B = ϵ∗ ,ϵ∗ ,...,ϵ∗ with n samples is chosen by random sampling with replacement from the observation
j 1,j 2,j n,j
datasetasillustratedinfigure5. Inthisseteachobservationϵcv mayappearonce,morethanonceornotatall. This
i
procedure is repeated with a large number of repetitions and the presented quality measures are estimated for each
bootstrapsamplesetB asfollows
j
(cid:118)
RMSE Bj =(cid:117) (cid:117) (cid:116) n1 (cid:88)n (cid:0) ϵ∗ i,j(cid:1)2 , CoP Bj =1− (cid:80)n i= S1 S(cid:0) ϵ∗ i,j(cid:1)2 . (18)
T
i=1
From the individual results of each bootstrap set B , the statistical properties of the RMSE and CoP estimates can
j
be evaluated. In figure 6 the 100 cross validation residuals of the previous example plots are shown. The anthill
plot indicates an almost independent relation between the data values and the residuals. However, the histogram is
non-symmetricandindicatesaskeweddistribution. Fortheseresidualsthebootstrapresamplingisappliedusing105
repetitionsandthestatisticalmeasuresareevaluatedforeachofthebootstrapsamples. Infigure6thehistogramsof
thecorrespondingRMSEandCoPareshownincludingthe99%confidenceintervals,whichcanbedirectlyestimated
fromthebootstrapsamples. ThefigureindicatesanalmostsymmetricdistributionoftheRMSE,whichwouldfitto
anormaldistributionverywell. ThedistributionoftheCoPisnon-symetricandskewed,whichmeansthatthemean
valueandthestandarddeviationmightbenotsufficienttocharacterizetheconfidenceinterval.Therefore,wecalculate
theconfidenceintervalofeachqualitymeasureinthefollowingexamplesdirectlyfromthebootstrapsampleswithout
assuminganydistribution.
Thebenefitinbootstrappingtheresidualsdirectlyinsteadofbuildingupnewsurrogatemodelsforeachbootstrap
setisclearlythereductionofthenumericaleffort. Oncethecrossvalidationresidualsareobtainedforagivensupport
pointset,thebootstrappingandtheevaluationoftheCoPdistributioncanbeperformedverycheap. However,thees-
timatorwillnotcoverthecase,thatthesupportpointsdonothaveasuitabledistribution. Nevertheless,theconfidence
estimatesfromthisprocedurearequitehelpfultoassessthequalityestimatorsasshowninthenumericalexamples.Fig.6. Crossvalidationresidualsof100supportpoints:distributionandhistogram(top)andbootstrappedRMSEandCoP(bottom)
withdeterministicestimates(green)and99%confidenceinterval(red)3 BENCHMARKSANDAPPLICATIONS
3.1 Analyticalbenchmarkfunction
Fig.7. Analyticalbenchmarkfunctionwithcouplingterminx 1-x 2subspaceandonenonlinearterminx 3
Inafirstexample,weinvestigateananalyticalbenchmarkfunctionwith5inputsasshoninfigure7
y(x)=0.5·x +x +0.5·x x +5.0·sin(x )+0.2·x +0.1·x , −π ≤xi≤π. (19)
1 2 1 2 3 4 5
Thisbenchmarkfunctionwasintroducedin[19]andconsistsofadditivelinearandnon-lineartermsandonecoupling
term. Furthermore,theinputsx andx haveminorimportance.
4 5
We investigate this example by generating 50, 100 and 200 support points within the input bounds by using an
improvedLatin-HypercubeSampling(LHS)accordingto[30]. AnisotropicKrigingapproximationmodelaccording
to [18] is trained by using these support points and a k-fold and LOO cross-validation is performed to estimate the
predictionerrors. UnimportantinputsareremovedautomaticallyfromtheapproximationmodelusingtheMetamodel
of Optimal Prognosis approach [19]. 500 additional test samples are generated by an independent LHS and are
evaluatedwiththebenchmarkfunction. Thesesamplesareusedtocomparedtheestimatedpredictionerrorsfromthe
cross-validation procedure with the errors in unknown data. For this purpose the prediction sum of squares SS is
E
evaluatedforthecross-validationresidualsandfortheadditionaltestdataaccordingtoequation11.
Inordertoquantifythestatisticalscatterofthepredictionerrorestimates,wegenerate50independentdatasets
for the support points and perform the model training and error estimation and compare these estimates with the
predictionerrorofafixedtestdataset. SincetheSS itselfvariesforeachsupportpointset,wecomparenotdirectly
T
theestimatedCoPfromthecross-validationwiththeCoDofthetestdata. InsteadwescaletheSScv fromthecross-
E
validationwiththeSS ofthetestdataasfollows
T
1SScv− 1 SStest
∆SScv = n E nt E , (20)
E 1 SStest
nt T
wherethenormalizationwiththenumberofsupportsnandthenumberoftestdatapointsn isnecessaryduetothe
t
differentnumberofsamplesinbothsets. Infigure8and9theobtained∆SScv areshownforthe50investigatedruns
EbyusingLOOaswellask-fold-cross-validationinthepredictionqualityestimation. Thefigureindicates,thatincase
of LOO the number of runs, where the SS is over-estimated, is similar as the number of cases where the SS is
E E
under-estimated. Ifthek-fold-cross-validationisusedwith50supportpoints,theestimatedSS ismostlylargeras
E
verified by the test data, which is indicated by ∆SScv > 0. This means that the CoP estimate is in the most cases
E
moreconservativeanddoesnotover-estimatethepredictionqualityoftheinvestigatedsurrogatemodel. Ifthenumber
ofsupportpointsisincreased,thedeviationbetweentheLOOandk-fold-cross-validationqualityestimatesreduces.
Fig.8. Statisticalevaluationofthepredictionerrorsoftheanalyticaltestfunctionbyusing50supportpointsand500testpointswith
k-fold-cross-validation(left)andLOO-cross-validation(right)
Fig.9. Statisticalevaluationofthepredictionerrorsoftheanalyticaltestfunctionbyusing200supportpointsand500testpointswith
k-fold-cross-validation(left)andLOO-cross-validation(right)
Additionally,weinvestigatetheconfidenceoftheestimatedCoPcomparedtothecorrespondingCoDofthetest
data. TheconfidenceintervaloftheCoPisestimateddirectlyfromthek-foldcrossvalidationresidualsforeachrun
using the bootstrap approach with 105 repetitions. In figure 11 the CoP estimates with 99% confidence bounds are
shown for the 50 investigated runs. The figure indicates, that the confidence interval of the CoP covers the verified
CoDinalmostallcases. Ifonly50supportpointsareused,theCoPestimateisgenerallymoreconservativeasforof200supportpoints. Ifwelookdeeperintotheresults,wecanobserve,thatforseveralrunstheCoPestimateissimilar
but the confidence bounds differ significantly. For the 50 support points this is the case for the sorted run numbers
34 and 35. In figure 10 the residual plots and the histogram of the bootstrapped CoP of both cases are shown. The
figureindicates, thatforrun34withthelargerconfidenceinterval, onesignificantoutliercanbeobservedwhilethe
remainingresidualsaresmaller. Inrunnumber35theresidualsindicatenosignificantoutlierbuthavelargervariation
asinrunnumber34. Thismeans,thatincaseofpossibleoutlierstheconfidenceintervaloftheCoPshouldbelarger
andanarrowestimateoftheCoPisnotpossible.
Fig.10. ResidualplotsandbootstrappedCoP’softheanalyticaltestfunctionofsortedrunnumber34(left)andrunnumber35(right)
byusing50supportpointsFig.11. CoPestimatesandconfidenceboundsoftheanalyticaltestfunctionbyusingk-fold-cross-validationcomparedtotheCoD
ofthetestdatafor50supportpoints(top)and200supportpoints(bottom)3.2 Noisybenchmarkfunction
Inthesecondexampleweextendtheanalyticalfunctionwithadditionallinear,non-linearandanoiseterm. The
functionfor20inputsreads
y(x)=0.5·x +x +0.5·x x +5.0·sin(x )+0.5·x +0.5·x2+0.1·x
1 2 1 2 3 4 4 5
(cid:88)20 (21)
+ 0.01·x +0.5·N(0,1), −π ≤x ≤π,
i i
i=6
whereN(0,1)isastandardnormalnoiseterm.
Wegenerateagain100supportpointsand500additionaltestsamplesbyLatin-HypercubeSampling(LHS)and
applyanisotropicKrigingapproximationmodel.Thescatterofthestatisticalmeasuresisanalyzedagainbyevaluating
50runswithLOOandk-fold-cross-validation.
In figure 12 the calculated errors ∆SScv are compared for both cases. The figure indicates a similar behavior
E
as in the first example, where the k-fold-cross-validation gives more conservative results and thus the CoP does not
over-estimatethepredictionquality.
In figure 13 the estimated confidence intervals are compared to the CoD of the additional test data. As in the
previousexample,theestimatedconfidenceboundsoftheCoPandtheverifiedCoDagreeverywell.
Fig.12. Statisticalevaluationofthepredictionerrorsofthenoisytestfunctionbyusing100supportpointsand500testpointswith
k-fold-cross-validation(left)andLOO-cross-validation(right)Fig.13. CoPestimatesandconfidenceboundsofthenoisytestfunctionbyusingk-fold-cross-validationcomparedtotheCoDofthe
testdatafor100supportpoints
3.3 Frontcrashexample
In the third example we investigate the presented error measures on a highly non-linear application, where the
intrusions and pulses of a truck impact example are analyzed with the LS-Dyna finite element solver as shown in
figure14. Thepulsesareaccelerationrelatedquantitiescomputedovertwo-time-intervalsofthecrashevent. 22input
variableshavebeenconsideredintheanalysiswhichbelongtothemetalsheetthicknessesandthematerialproperties
of specific parts of the car body. Further details on this example can be found in [31]. For this example, different
datasetsof100, 200and400LatinHypercubesampleshavebeenusedforthemodeltrainingandasingletestdata
set of 1200 samples for the validation of the estimated prediction errors. Again we use the Metamodel of Optimal
Prognosis [19] to select the most suitable approximation model for each response automatically. As approximation
modelsweconsiderpolynomialsandMovingLeastSquares,eachwithlinearandquadraticbasis,aswellasisotropic
and anisotropic Kriging. Additionally to the best approximation model, the optimal subspace of important inputs is
detectedbyusingthemaximumCoefficientofPrognosisasselectioncriterion.
Intable1theresultsfortheinvestigatedsixreponsesaregiven. Thetableindicates,thatwithincreasingnumber
ofsupportpoints,thepredictionqualityestimatedwiththeCoPandverifiedwiththetestdatasetincreasesforalmost
alloutputs.Furthermore,theestimatedconfidenceintervaloftheCoPcoverstheverifiedtestCoDverywell.Thetable
further indicates, that with increasing number of supports the number of selected important inputs increases, which
is a typical phenomena in machine learning. In figure 15 the estimated total effect sensitivity indices are shown for
each support point set. Already with 100 support points, the most important inputs could be detected for almost all
outputs. Incontrasttotheotheroutputs,onlytheHeadinjurycriterion(HIC)couldnotberepresentedwellwiththe
investigatedapproximationmodels. TheCoPanditsconfidenceintervalindicateaverylowpredictionquality,which
might be caused by numerical noise in the output or a high-dimensional non-linear relation between the inputs and
theHICvalue. Insuchacase,theestimateoftheinputsensitivitybasedontheapproximationmodelaspresentedin
section 2.4 is not reliable, since a high amount of the output variation can not be represented by the approximation
model.
Infigure16theresidualsandthebootstrappedCoP’sareshownexemplarilyfortheN1 dispresponseobtainedforFig.14. Investigatedfrontcrashexampleaccordingto[31]considering22varyinginputsofspecificpartsofthecarbodyinaLS-
Dynasimulationmodel
Output No.supports SelectedModel No.selectedinputs CoP 99%conf.interval CoDtestdata
100 LinearPolynomial 9 0.747 0.643-0.830 0.759
N1 disp 200 AnisotropicKriging 14 0.803 0.735-0.856 0.809
400 AnisotropicKriging 18 0.835 0.793-0.867 0.836
100 LinearPolynomial 9 0.778 0.676-0.856 0.787
N2 disp 200 AnisotropicKriging 14 0.827 0.762-0.876 0.836
400 AnisotropicKriging 15 0.857 0.823-0.885 0.853
100 AnisotropicKriging 11 0.990 0.986-0.993 0.989
Stage1Pulse 200 AnisotropicKriging 13 0.992 0.989-0.994 0.994
400 AnisotropicKriging 13 0.994 0.992-0.995 0.994
100 LinearPolynomial 20 0.942 0.922-0.961 0.908
Stage2Pulse 200 AnisotropicKriging 18 0.956 0.946-0.965 0.932
400 AnisotropicKriging 19 0.967 0.961-0.973 0.954
100 LinearPolynomial 9 1.000 1.000-1.000 1.000
total mass 200 LinearPolynomial 9 1.000 1.000-1.000 1.000
400 LinearPolynomial 9 1.000 1.000-1.000 1.000
Headinjury 100 AnisotropicKriging 2 0.062 0.000-0.752 0.000
criterion(HIC) 200 AnisotropicKriging 19 0.365 0.000-0.686 0.000
400 AnisotropicKriging 21 0.318 0.000-0.677 0.000
Table 1. Computed quality estimates for the front crash example with 22 inputs and 6 investigated outputs by using k-fold cross
validationandresidualbootstrapping
eachsupportpointset. Forthisoutputaclearimprovementofthepredictionqualitycanbeobservedwithincreasing
number of support points, which is indicated by a narrower confidence interval. In the residual plots no significant
outlier or systematic approximation errors could be recognized. This is not the case for the HIC value residuals
showninfigure17. Hereaclearsystematicapproximationerrorcouldbedetected,whichconfirmstheestimatedpoor
approximationquality. ThecalculatedconfidenceintervalscoveralmostthewholedomainofpossibleCoPvalues.100supportpoints
200supportpoints
400supportpoints
Fig.15. EstimatedCoPsandinputsensitivitiesforthesimulationmodelresponsesofthetruckfrontcrashexamplebyusing100,
200and400supportpoints100supportpoints
200supportpoints
400supportpoints
Fig.16. Residualplots(left)andbootstrappedCoP’s(right)oftheoutputN1dispfromthefrontcrashexample100supportpoints
200supportpoints
400supportpoints
Fig.17. Residualplots(left)andbootstrappedCoP’s(right)oftheHICvaluefromthefrontcrashexample3.4 Cut-Inscenarioexample
Fig.18. SimulatedCut-Scenarioofanautonomousvehicle
Output No.supports SelectedModel No.selectedinputs CoP 99%conf.interval CoDtestdata
Time 280 AnisotropicKriging 7 0.666 0.568-0.750 0.745
Headway 560 AnisotropicKriging 7 0.722 0.659-0.776 0.771
(THW) 1120 AnisotropicKriging 7 0.794 0.756-0.830 0.804
1866 AnisotropicKriging 8 0.824 0.795-0.850 0.841
Timeto 280 AnisotropicKriging 10 0.417 0.112-0.661 0.244
collision 560 AnisotropicKriging 8 0.459 0.281-0.613 0.490
(TTC) 1120 AnisotropicKriging 10 0.506 0.385-0.613 0.549
1866 AnisotropicKriging 9 0.554 0.464-0.634 0.600
280 AnisotropicKriging 5 0.804 0.735-0.863 0.751
Egomax 560 AnisotropicKriging 8 0.792 0.721-0.845 0.785
speed 1120 AnisotropicKriging 9 0.827 0.791-0.858 0.824
1866 AnisotropicKriging 8 0.843 0.812-0.869 0.837
280 AnisotropicKriging 7 0.704 0.583-0.800 0.721
Criticality 560 AnisotropicKriging 8 0.713 0.636-0.782 0.758
1120 AnisotropicKriging 8 0.773 0.722-0.819 0.797
1866 AnisotropicKriging 8 0.808 0.772-0.840 0.830
Table2. ComputedqualityestimatesfortheCut-Inexamplewith10inputsand4investigatedoutputsbyusingk-foldcrossvalidation
andresidualbootstrapping
In the final example, the simulation data of a Cut-In scenario of an autonomous vehicle are analyzed. Further
detailsofthesimulationanalysiscanbefoundin[32]. Inthisexample10inputparametersasegoandcut-invehicle
speeds,leadvehicledistanceandbreakingdecelerationareconsidered. Inthesimulationthetypicalkeyperformance
indicators(KPIs)ascriticaltimeheadway(THW),timetocollision(TTC),collisionspeedandmanyothershavebeen
calculated.Fromtheseoutputsacombinedfailurecriterionwasderivedforeachsimulationrun.Fortheanalysisofthe
machinelearningmodels,differentdatasetsof280,560,1120and1866supportpointshavebeenusedforthetraining
and5600datapointsareconsideredasverificationdata. Similarasinthepreviousexample,differentapproximation
modelshavebeenconsideredintheMOPcompetitionandthemostimportantinputshavebeendetectedautomatically.
In table 2 the estimated CoPs for the training data and the CoDs of the verification data set are given for four
selected outputs including the confidence interval from the bootstrapped residuals. The table shows, that for eachinvestigatedoutput,theestimatedCoPincreaseswithincreasingnumberoftrainingpoints. Furthermore,theCoDof
the verification agrees very well with the CoP estimates and the corresponding confidence bounds. In figure 19 the
approximationmodelforthetime-headwayoutputisshownexemplarilyfor280and1866trainingpoints. Inthefirst
casethemodelalreadyrepresentstheglobalbehaviourbutlocalnonlinearitiesarefiltered. For1866trainingpoints
these local relations can be represented much more accurate. In figure 20 the corresponding residual plots and the
histogramsofthebootstrappedCoPofbothcasesareshown. Thefigureindicates,thatevenwith1866trainingpoints
aperfectapproximationofthesimulatedtimeheadwayisnotpossible. However,theestimatedCoPwasproventobe
anaccurateandreliablemeasureforthemodelpredictionquality.
4 CONCLUSIONS
In this paper, statistical measures for the assessment of the prediction quality of machine learning models are
investigatedregardingtheiraccuracyandrobustness. Basedonacross-validationapproach, theCoefficientofProg-
nosiswasintroducedasamodelindependentqualitymeasure. However, theimplementationofthecross-validation
procedureisveryimportantforastableestimationofthepredictionqualityasshowninthenumericalexamples.From
these findings, we would prefer the k-fold cross-validation towards the Leave-one-out approach since it gives more
conservativeestimatesespeciallyforalimitednumberoftrainingdatapoints. Statisticalconfidenceboundsofthese
global quality measures have been derived by using the bootstrap approach, whereas the resampling was evaluated
directlyonthecross-validationresiduals. Therefore,thisprocedurecanbeappliedwithoutanyadditionalmodeltrain-
ing. Bymeansofseveralnumericalexamples, thevalueoftheestimatedconfidenceboundscouldbedemonstrated.
Thisadditionalinformationhelpstodecide,howreliablethequalityestimatorsare,iffurtherdatapointsarenecessary,
orifthepredictionqualityisaffectedbypossibleoutliers. Additionally,totheglobalqualitymeasures,weintroduced
thelocalRootMeanSquaredError(RMSE)andthelocalCoPaslocalqualitymeasures,whichcanbeevaluatedfor
eachapproximationpoint. Theyoffermodelindependenterrorestimatorsofthelocalmodelprediction,whichcould
beveryvaluablee.g. forDigitalTwinsapplications.
ACKNOWLEDGEMENTS
This article is dedicated to Prof. Christian G. Bucher, former professor at the Bauhaus-University in Weimar,
Germany, and Technical University in Vienna, Austria. Prof. Bucher supported the work of the former Dynardo
GmbH over more than 20 years with his excellent expertise and knowledge. Additionally, we want to thank Dr.
Johannes Will, who is the founder of the former Dynardo GmbH, for his huge commitment to the success of the
MetamodelofOptimalPrognosisapproachwithintheAnsysoptiSLangcommunity.
REFERENCES
[1] Myers,R.H.,andMontgomery,D.C.,2002, Responsesurfacemethodology: processandproductoptimization
usingdesignedexperiments JohnWiley&Sons.
[2] Montgomery,D.C.,andRunger,G.C.,2003, AppliedStatisticsandProbabilityforEngineers,thirded. John
Wiley&Sons.
[3] Krige,D.,1951, “AstatisticalapproachtosomebasicminevaluationproblemsontheWitwatersrand,” Journal
oftheChemical,MetallurgicalandMiningSocietyofSouthAfrica,52,pp.119–139.
[4] Lancaster,P.,andSalkauskas,K.,1981, “Surfacegeneratedbymovingleastsquaresmethods,” Mathematicsof
Computation,37,pp.141–158.
[5] Park,J.,andSandberg,I.,1993, “Approximationandradialbasisfunctionnetworks,” NeuralComputation,5(2),
pp.305–316.
[6] Smola,A.,andScho¨lkopf,B.,2004, “Atutorialonsupportvectorregression,” Statisticsandcomputing,14(3),
pp.199–222.
[7] Hagan,M.T.,Demuth,H.B.,andBeale,M.,1996, NeuralNetworkDesign PWSPublishingCompany.
[8] Goodfellow,I.,Bengio,Y.,andCourville,A.,2016, Deeplearning MITpress.
[9] Herrmann,L.,andKollmannsberger,S.,2024, “Deeplearningincomputationalmechanics: areview,” Compu-
tationalMechanics,74,pp.281––331.[10] Ye, P., 2019, “A review on surrogate-based global optimization methods for computationally expensive func-
tions,” SoftwareEngineering,7(4),pp.68–84.
[11] Cheng, K., Lu, Z., Ling, C., andZhou, S., 2020, “Surrogate-assistedglobalsensitivityanalysis: anoverview,”
StructuralandMultidisciplinaryOptimization,61,pp.1187–1213.
[12] Bucher,C.,andMost,T.,2008, “Acomparisonofapproximateresponsefunctionsinstructuralreliabilityanaly-
sis,” ProbabilisticEngineeringMechanics,23,pp.154–163.
[13] Moustapha, M., Marelli, S., and Sudret, B., 2022, “Active learning for structural reliability: Survey, general
frameworkandbenchmark,” StructuralSafety,96,p.102174.
[14] Yondo, R., Bobrowski, K., Andre´s, E., and Valero, E., 2019, “A review of surrogate modeling techniques
for aerodynamic analysis and optimization: current limitations and future challenges in industry,” Advances
in evolutionary and deterministic methods for design, optimization and control in engineering and sciences,
pp.19–33.
[15] Westermann, P., andEvins, R., 2019, “Surrogatemodellingforsustainablebuildingdesign–areview,” Energy
andBuildings,198,pp.170–186.
[16] Zhang, W., Gu, X., Hong, L., Han, L., and Wang, L., 2023, “Comprehensive review of machine learning in
geotechnicalreliabilityanalysis:Algorithms,applicationsandfurtherchallenges,” AppliedSoftComputing,136,
p.110066.
[17] Queipo, N.V., Haftka, R.T., Shyy, W., Goel, T., Vaidyanathan, R., andTucker, P.K., 2005, “Surrogate-based
analysisandoptimization,” Progressinaerospacesciences,41(1),pp.1–28.
[18] Forrester,A.,Sobester,A.,andKeane,A.,2008, Engineeringdesignviasurrogatemodelling: apracticalguide
JohnWiley&Sons.
[19] Most,T.,andWill,J.,2011, “SensitivityanalysisusingtheMetamodelofOptimalPrognosis,” In8thOptimiza-
tionandStochasticDays,Weimar,Germany,24-25November,2011.
[20] Most,T.,Gra¨ning,L.,Will,J.,andAbdulhkim,A.,2022,“Automatizedmachinelearningapproachforindustrial
application,” InNAFEMSDACHconference,Bamberg,Germany,4-6October2022.
[21] Most,T.,Gra¨ning,L.,Wolff,S.,andCremanns,K.,2024, “AutomatisierteApproximationvonCAE-Signal-und
Feldergebnisgro¨ßenmitMethodendesMaschinellenLernens,” NAFEMSDACHMagazin,70,pp.32–40.
[22] Jones, D. R., Schonlau, M., and Welch, W. J., 1998, “Efficient global optimization of expensive black-box
functions,” JournalofGlobaloptimization,13(4),p.455.
[23] AnsysGermanyGmbH,2023, optiSLangdocumentation: Methodsformulti-disciplinaryoptimizationandro-
bustnessanalysis.
[24] Sobol’, I. M., 1993, “Sensitivity estimates for nonlinear mathematical models,” Mathematical Modelling and
ComputationalExperiment,1,pp.407–414.
[25] Homma, T., and Saltelli, A., 1996, “Importance measures in global sensitivity analysis of nonlinear models,”
ReliabilityEngineeringandSystemSafety,52,pp.1–17.
[26] Most, T., 2012, “Variance-based sensitivity analysis in the presence of correlated input variables,” In 5th In-
ternational Conference on Reliable Engineering Computing (REC), Brno, Czech Republic, 13-15 June, 2012.
pp.335–352.
[27] Saltelli,A.,etal.,2008, GlobalSensitivityAnalysis.ThePrimer JohnWiley&Sons,Ltd,Chichester,England.
[28] Efron,B.,1992,“Bootstrapmethods:anotherlookatthejackknife,”InBreakthroughsinstatistics:Methodology
anddistribution.Springer,pp.569–593.
[29] Most,T.,andKnabe,T.,2010,“Reliabilityanalysisofthebearingfailureproblemconsideringuncertainstochas-
ticparameters,” ComputersandGeotechnics,37,pp.299–310.
[30] Huntington,D.,andLyrintzis,C.,1998, “Improvementstoandlimitationsoflatinhypercubesampling,” Proba-
bilisticengineeringmechanics,13(4),pp.245–253.
[31] Stander,N.,Basudhar,A.,Gandikota,I.,Liebold,K.,Svedin,A.,andKeisser,C.,2021,“LS-OPTstatusupdate,”
InProc.13thEuropeanLS-DYNAConference,Ulm,Germany.
[32] Most, T., Rasch, M., Ubben, P. T., Niemeier, R., and Bayer, V., 2023, “A multimodal importance sampling
approachfortheprobabilisticsafetyassessmentofautomateddriverassistancesystems,” JournalofAutonomous
VehiclesandSystems,3(1),pp.011001–1.Fig.19. Approximationmodelofthetimeheadway(THW)for280trainingpoints(left)and1866trainingpoints(right)inthesubspace
ofthetwomostimportantinputsoftheCut-Inscenarioexample
280supportpoints,CoP=66.6% 1866supportpoints,CoP=82.4%
Fig.20. Residualplots(top)andbootstrappedCoP’s(bottom)ofthetimeheadwayoutputoftheCut-Inscenarioexample