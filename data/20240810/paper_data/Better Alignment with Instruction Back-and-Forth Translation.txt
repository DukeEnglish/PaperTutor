Better Alignment with Instruction Back-and-Forth Translation
ThaoNguyen1,2 JeffreyLi1 SewoongOh1
LudwigSchmidt1 JasonWeston2 LukeZettlemoyer1,2 XianLi2
1UniversityofWashington 2MetaFAIR
{thaottn,jwl2162,sewoong,schmidt}@cs.washington.edu {jase,lsz,xianl}@meta.com
Abstract etal.,2023)orwebcrawls(Lietal.,2023a;Köksal
etal.,2023)toinstruction-responsepairs,and(iii)
We propose a new method, instruction back-
distillingknowledgefromamodel(Chiangetal.,
and-forthtranslation,toconstructhigh-quality
2023;Mukherjeeetal.,2023). synthetic data grounded in world knowledge
for aligning large language models (LLMs). Therearebenefitsanddisadvantagestoeachof
Givendocumentsfromawebcorpus,wegener- theseapproaches. While(i)canofferstrongbase-
ateandcuratesyntheticinstructionsusingthe lines (Zhou et al., 2024; Köpf et al., 2024), the
backtranslationapproachproposedbyLietal.
reliance on human annotations makes scaling up
(2023a),andrewritetheresponsestoimprove
thesedatasetsdifficult. Thesuccessof(i)and(ii)
their quality further based on the initial doc-
isalsomoredependentonhavinganeffectivefilter-
uments. Fine-tuningwiththeresulting(back-
ingmechanismtoremovenoisydatafromhumans
translatedinstruction,rewrittenresponse)pairs
yieldshigherwinratesonAlpacaEvalthanus- andtheweb. Ontheotherhand,(iii)ismorecost-
ing other common instruction datasets such effectiveandscalable;manycurrentstate-of-the-art
asHumpback,ShareGPT,OpenOrca,Alpaca- instructiondatasetsemploydistillation. However,
GPT4andSelf-instruct. Wealsodemonstrate distillation alone has also been claimed to be a
thatrewritingtheresponseswithanLLMout-
“false promise”—Gudibande et al. (2023) shows
performs direct distillation, and the two gen-
that specific capability improvements depend on
eratedtextdistributionsexhibitsignificantdis-
thecoverageofthedistilleddataandthattheper-
tinctioninembeddingspace. Furtheranalysis
formancegainsfromdistillingcanplateauquickly.
showsthatourbacktranslatedinstructionsare
ofhigherqualitythanothersourcesofsynthetic Thesefindingssuggestthatlessnoisyandmoredi-
instructions,whileourresponsesaremoredi- versedataiscrucialforinstruction-tuningtoclose
verse and complex than those obtained from thegapbetweenopenandclosedLLMs.
distillation. Overall we find that instruction
Giventheknowledgebreadththatcanbefound
back-and-forthtranslationcombinesthebestof
on the internet, generating instruction-response
both worlds—making use of the information
data with backtranslation has been shown to be
diversityandquantityfoundontheweb,while
a promising alternative to distillation (Li et al.,
ensuringthequalityoftheresponseswhichis
necessaryforeffectivealignment. 2023a). In particular, the authors parse the
ClueWeb corpus (Overwijk et al., 2022) for self-
1 Introduction
containedtextsegments,trainamodelspecifically
Inrecentyears,itisincreasinglycommonforlarge forinstructiongenerationonOpenAssistantdata
languagemodels(LLMs)tobedeployedthrough (Köpfetal.,2024),andgenerateinstructionstogo
a chat interface to interact with users’ queries. withthetextsegments. However,thisapproachre-
Thiscapabilityisachievedbytakingmodelsthat liesonhigh-qualitytextdataprovidedbyClueWeb,
havebeenpre-trainedonmassiveamountsofweb- apaid-accesscorpuscontainingonlythemostpop-
crawled text and fine-tuning them on a relatively ularwebpagesfromsearchresults,aswellasalist
smallersetofinstruction-responsepairsorprefer- ofmanuallyspecifiedrulesforparsingrawHTML
ences (Ouyang et al., 2022). Popular instruction- filesintostructuredresponses(whicharethenused
tuningcorporaareoftenconstructedby(i)human directlyforfine-tuning).
annotationandcuration(Köpfetal.,2024;Conover Inthiswork,wealsoadopttheinstructionback-
etal.,2023;Zhouetal.,2024),(ii)convertingex- translationtechniquebutmakeitmoreaccessible
isting texts, e.g. from other NLP tasks (Longpre andscalable. Wemakedirectuseofpreprocessed
1
4202
guA
8
]LC.sc[
1v41640.8042:viXraFigure1: Overviewofourproposedpipeline: instructionback-and-forthtranslation. (1)Wefirstfine-tune
abasemodel,e.g. Llama-2,onsomeseedexamplesfromOpenAssistant,forthetaskofinstructiongeneration.
Wethenextractinitialcandidateresponsesfromawebcorpus,e.g. Dolma,andusethefine-tunedmodeltoobtain
syntheticinstructionsthatwouldgowiththecorrespondingresponses; (2)Weseparatelyobtainaninstruction-
followingmodelbyfine-tuningthesamebasemodelontheseedexamples,anduseittoscorethequalityofthe
(syntheticinstruction,web-scrapedresponse)pairs;(3)Withthehighestscoringpairs,weaskanexistingaligned
model(e.g. Llama-2-chat)toimprovetheresponsesfurther,conditionedonthegeneratedinstructionsandtheinitial
webtexts. Steps(1)and(2)followLietal.(2023a)withsomemodifications(i.e. usingpreprocesseddocuments
fromDolmainsteadofparsingrawHTMLsfromClueWeb). Weprovideaspecificdataexampleinthebottomrow.
documentsfromalarge-scaleopen-sourcecorpus structions(Section5.1). Inaddition,weoffersome
likeDolma(Soldainietal.,2024)andgeneratein- insights into how instruction backtranslation and
structionsviabacktranslationaccordingly. Wefind responserewritingaffectthequalityofinstructions
thatthequalityofourinstructionsarecomparable and responses respectively, especially in compar-
tothosebacktranslatedfromClueWeb. Tomakeup ison with existing data generation methods (Sec-
for the lack of manually designed rules for struc- tions5.2and5.3). Overallourresultssuggestthat
turingtheresponse,weexperimentwithusingan back-and-forthtranslationoffersaneffectiveway
LLM to rewrite the response based on the gener- to generate instruction-tuning data enriched with
atedinstructionandtheinitialwebtext. Thisalso diverse information found on the web, while en-
allows us to avoid directly distilling and overfit- suring the quality of the response annotations by
tingtoanLLM’sknowledge. Anoverviewofour havingalignedLLMsintheloop.
pipeline,whichwecallback-and-forthtranslation,
2 Method
canbefoundinFigure1.
Giventhesamedataquantity,fine-tuningLlama- Figure1showsanoverviewofourpipeline. Here
2-70Bontheinstruction-responsepairsfromour wedescribeeachstepinmoredetail.
datagenerationpipelineimprovestheAlpacaEval
2.1 Background: instructionbacktranslation
winrateby3.6%comparedtousingthebacktrans-
lation data from previous work (Li et al., 2023a), Ourworkisinspiredbythebacktranslationmethod
andbyatleast3.2%comparedtousingotherexist- fromLietal.(2023a). Inthispreviouswork, the
ing distillation datasets such as OpenOrca (Lian authorsfine-tuneabaselanguagemodelonsome
et al., 2023), ShareGPT (Chiang et al., 2023), seedinstruction-responsepairs(x ,y )(e.g. from
s s
Alpaca-GPT4(Pengetal.,2023)andSelf-instruct Open Assistant (Köpf et al., 2024)) to obtain a
(Wangetal.,2022a)(Section4). Byaskingamodel backwardmodelM := p(x|y)thatlearnstogen-
yx
torewriteresponsesbasedoninitialtextsextracted erate instructions. The authors then extract can-
fromDolma,weobtainadistributionofresponses didateresponsesy from.warcfilesofawebcor-
i
thatinterpolatesbetweentheoriginalwebtextdis- pus,ClueWeb,usingcarefullyconstructedHTML-
tribution and the distribution of outputs distilled parsingrules,andaugmenttheresponseswithcor-
fromthesamemodel. Fine-tuningontherewritten responding instructions output by the backward
responses in turn outperforms fine-tuning on the model. Thisyieldsasetofcandidate(xˆ ,y )pairs.
i i
distilled responses corresponding to the same in- The authors also separately fine-tune the same
2baselanguagemodelonthesameseeddata(x ,y ) ingbothofferscomplementaryperformancebene-
s s
toobtainaforwardmodelM := p(y|x)thatcan fits. WewillelaborateonthisinSection4.
xy
followinstructions. Thismodelisthenprompted
toscorecandidate(xˆ i,y i)pairsona5-pointscale. 3 Experimentsetup
Thefinalinstruction-tuningdatasetconsistsofonly
score-5 examples. The paper provides ablations
3.1 Trainingdetails
toshowthatthiscurationstepiscriticaltoachiev-
Data. To source the initial web-crawled re-
ingperformancegains,especiallywithincreasing
sponses, we use the Common Crawl subset of
instructiondataquantity.
Dolmav1(Soldainietal.,2024). Thissubsethas
The two steps derived from Li et al. (2023a)
beenpreprocessedwithqualityandcontentfilters,
are denoted as (1) Backtranslation and (2)
in addition to undergoing deduplication. We ad-
FilteringinFigure1.
ditionallyfilter outdocuments whoselengths are
2.2 Therewritingprocess closetoexceedingthecontextlengthofLlama-2;
A major limitation of previous work (Li et al., thisremovesabout25%oftheCommonCrawlsub-
2023a) is the limited availability of high-quality set. Besides,weonlyusedatafromtheheadsplit
candidateresponses. TheauthorsrelyonClueweb (whichconsistsofdocumentswiththebestperplex-
(Overwijketal.,2022)asthesourceforunlabelled ityscores),aspreliminaryexperimentsshowthat
responses{y },usingonlyhighlylinkedwebsites thissplitoffersbettercandidateresponsesthanthe
i
visitedbyasearchengine(e.g. Wikipedia,popular middlesplit(seeTable5inAppendix).
newssites)asthisoffersqualitycontrolovertheex- Fortheseeddatausedtotraintheforwardand
tractedtexts{y }. However,(i)ClueWebrequires backward models, we follow previous work (Li
i
paidaccess, (ii)thetextsegmentswereextracted etal.,2023a)anduse3200examplesfromtheOpen
from raw HTML format, which requires specific Assistantdataset(Köpfetal.,2024),chosenfrom
preprocessingandmaystillresultinsegmentsthat the first turn of each conversation tree. Note that
aresub-optimalasresponses. the seed data only consists of English language
Our work removes the data access restrictions responsesthatareconsideredhigh-quality,based
and preprocessing steps by using cleaned docu- ontheirhumanannotatedrank(rank0).
ments from an open-source corpus, Dolma (Sol-
daini et al., 2024), for the initial web-scraped Model. Wefine-tuneaLlama-2-70Bbasemodel
responses. Since these documents come pre- (Touvron et al., 2023) on the seed data to obtain
extracted(withallHTMLstructuresremoved)and theforwardandbackwardmodelsusedinsteps(1)
were written for various purposes, they may con- and(2)ofourpipeline. Therewritingstepemploys
tainredundantinformationandthecontentpresen- Llama-2-70B-chatbydefault. Wealsoexperiment
tationcouldalsobeimproved(e.g. bybeingsplit withusingasmallermodel(Llama-2-7B-chat)as
into paragraphs). Consequently, we use an LLM wellastheforwardmodelfromstep(2)forrewrit-
toimprovethesedocumentstobetterresemblere- ing,butweobservethattheoutputqualityisworse
sponses from AI Assistants; this step is denoted (AppendixD).Forperformanceevaluation,wefine-
as (3) Rewriting in Figure 1. Conditioned on tune both the 7B and 70B scales of the Llama-2
initial text y from Dolma and the corresponding base model on the resulting instruction-response
i
backtranslatedinstructionxˆ ,wepromptanaligned pairsinasupervisedmanner. Specifichyperparam-
i
LLM,Llama-2-70B-chat,torewritetheresponse eterscanbefoundinAppendixA.
toimproveitsquality(y′). Thefullpromptcanbe
i
foundinAppendixA.2. Evaluation. Givenafine-tunedLlama-2model,
Bydefault,weapplyrewritingto(xˆ ,y )pairs wepromptittorespondto805questionsfromthe
i i
thathavepassedthefilteringstage. However,we AlpacaEvalbenchmark(Lietal.,2023b)andreport
alsoexperimentwithskippingthefilteringstep,i.e. themodel’swinrateovertext-davinci-003aseval-
rewriteresponsesforanypaireveniftheforward uatedbyGPT-4model. Wealsoadoptthelength-
modelfindssomewebresponsesandcorrespond- controlledwinrateevaluationfromAlpacaEval2.0
ing generated instructions not properly aligned. (Dubois et al., 2024), see Appendix E for more
Overallwefindthatstep(3) Rewritingismore details. Performance on other NLP tasks can be
effectivecomparedto(2) Filtering,thoughus- foundinAppendixF.
33.2 Baselines Datasource Datasize Winrate(%)
Dolma+filtering 12.8K 71.70
Theotherfine-tuningdatasourceswecompareto Dolma+rewriting 12.8K 73.44
include: Dolma+filtering+rewriting 12.8K 74.38
ClueWeb+filtering 12.8K 70.77
• OpenOrca(Lianetal.,2023;Mukherjeeetal.,
OpenOrca 12.8K 74.20
2023): containsGPT-4-distilledoutputstoFLAN
ShareGPT 12.8K 72.69
tasks (Longpre et al., 2023), which are con- Alpaca-GPT4 12.8K 71.17
verted from existing NLP datasets using man- Self-instruct 12.8K 65.11
uallycraftedtemplates. Thetaskshavebeenaug- Table 1: Performance of fine-tuning Llama-2-7B.
mented with prompting to elicit some form of Given the same data quantity (12.8K), fine-tuning on
reasoningduringdistillation. theinstruction-responsepairsobtainedfrominstruction
back-and-forthtranslationoutperformsfine-tuningon
• ShareGPT(Chiangetal.,2023): thedatacomes
thebacktranslatedClueWebdatafrompreviouswork
from ShareGPT.com, where users shared their
(Lietal.,2023a),aswellasothercommoninstruction
own conversation logs with ChatGPT. We only datasets. We also find that the rewriting step is more
takethefirstinstructionandfirstresponsefrom effective than the filtering step at improving the data
eachconversationforfine-tuning. quality,andsubsequently,themodelwinrate.
• ClueWeb+filtering(Lietal.,2023a): responses
areparsedfromHTMLfilesintheClueWebcor-
ResultsareshowninTable1. Belowwedescribe
pus (Overwijket al., 2022)and donot undergo
ourdifferentdatavariationsinmoredetail:
rewriting. Instructions are generated with the
backtranslation approach. After preprocessing
• Dolma+filtering: Dataobtainedfromsteps(1)
and two rounds of curation, previous work pro-
and (2) of our pipeline (Figure 1). We gather
duces41.8Kinstruction-responsepairsintotal.
initialresponsesfromtheDolmacorpus,generate
• Self-instruct (Wang et al., 2022a): the instruc- correspondinginstructionswithbacktranslation,
tions,inputsandoutputsaregeneratedbyGPT-3, and filter out instruction-response pairs that do
bootstrappedfromasmallsetofseedtasks. not get a score 5 from our forward model (i.e.
• Alpaca-GPT4(Pengetal.,2023): containsGPT- not well-aligned). Responses do not undergo
4-distilledresponsestoinstructionsfromAlpaca rewritingforthisbaseline.
dataset(Taorietal.,2023). Alpaca’sinstruction • Dolma+rewriting: Dataobtainedfromsteps(1)
generationseekstoimproveovertheSelf-instruct and (3) of our pipeline (Figure 1). We source
frameworkbyusingdifferentpromptsandamore candidate responses from Dolma, generate in-
advancedmodel(text-davinci-003). structions with backtranslation and rewrite the
Wenotethatexceptforthefirsttwo,therestofthe responseswithLlama-2-70B-chat. Nointermedi-
baselines employ synthetic instructions. Besides, atefilteringisdoneinthiscase.
themajorityofthesedatasets(otherthanClueWeb) • Dolma + filtering + rewriting: Data obtained
distillresponsesfromdifferentexistingLLMs. We fromgoingthroughallthestepsofourpipeline
usetheseGPT-distilleddatasetsforresearch-only, (Figure1)asdescribedinSection2.
non-commercialpurposes(i.e. toserveascompeti-
tivebaselinestocompareourmethodagainst). We find that at this scale, our filtered backtrans-
lation data (Dolma + filtering) outperforms simi-
4 Fine-tuningresults larlyconstructeddatafrompreviouswork(Lietal.,
2023a)(ClueWeb+filtering). Ourbestdatasetthat
Wevalidatetheeffectivenessofourdatageneration
undergoesbothfilteringandrewritingyieldsbetter
method,byexaminingtheAlpacaEvalperformance
winratethanallotherbaselines. Itisworthnoting
ofLlama-2modelsfine-tunedonourdataversuson
thatfine-tuningonrewrittenresponsesfromunfil-
otherdatasets,giventhesameinstructionquantity. teredinstruction-responsepairs(Dolma+rewrit-
ing)outperformsfine-tuningoninitialweb-scraped
4.1 7Bscale
responses that have passed the filtering stage but
Wefixthenumberofsamplestobe12.8Kandcom- havenotbeenrewritten(Dolma+filtering). This
pare fine-tuning Llama-2-7B base model on our signalsthattherewritingstepismoreeffectivethan
backtranslationandrewrittendatatofine-tuningon filtering at improving the quality of instruction-
othercommonbaselinesdescribedinSection3.2. tuningdata.
4Datasource Datasize Winrate(%) Textdistributions MAUVEscore
Dolma+filtering 51.2K 87.42 Distilledresponsesvs. 0.960±0.002
Dolma+rewriting 51.2K 90.52 Distilledresponses
Dolma+filtering+rewriting 51.2K 91.74 Distilledresponsesvs. 0.340±0.009
ClueWeb+filtering 41.8K 88.18 Rewrittenresponses
OpenOrca 51.2K 87.31 Distilledresponsesvs. 0.0338±0.0007
ShareGPT 51.2K 88.56 Initialwebresponses
Alpaca-GPT4 51.2K 86.18 Table 3: Rewritten responses interpolate between
Self-instruct 51.2K 78.48 theinitialweb-scrapedresponsesandthedistillation
Dolma+filtering+rewriting 25.6K 90.22
outputs from the aligned LLM used for rewriting.
Dolma+filtering+distilling 25.6K 87.58
WeuseMAUVEscore(Pillutlaetal.,2021)tomeasure
Table 2: Performance of fine-tuning Llama-2-70B. thedistancesamongthethreetextdistributions: initial
Whilebacktranslationdatafrompreviouswork(Lietal., responsessourcedfromDolma,therewrittenresponses
2023a) is limited by the number of high-quality web and the distilled outputs of Llama-2-70B-chat, all in
pagesinClueweb,ourapproachreliesonDolmatexts responsetothesameinstructionset. Wefindthatthe
andthushasaccesstomanymorecandidateresponses. rewrittenresponsesappearmoresimilartothedistilled
Similar to the 7B scale results, (i) rewriting is more outputscomparedtothewebtexts,thoughtherestillex-
effective at improving data quality than filtering, (ii) istsasubstantialgapbetweenthefirsttwodistributions.
filteringbacktranslatedinstructionsandthenrewriting
theresponsesdoesthebestandoutperformsprevious pipelinecomparedtootherexistingdatasets.
work. WealsoobservethatusinganalignedLLMfor
5.1 RewritingversusDistilling
responserewritingyieldsbetterdata,andsubsequently,
winrate,thanusingthesamemodelfordistillation. AsrewritinginvolvesaskingLlama-2-70B-chatto
improve the response quality, conditioned on an
4.2 70Bscale
initialweb-crawledresponseandabacktranslated
Wealsoexperimentwithfine-tuningtheLlama-2- instruction,afundamentalquestionarises: doesthe
70Bbasemodelondifferentvariantsoftheback- rewritingprocessleverageinformationintheraw
translationdatadescribedintheprevioussection. text or does it simply distill knowledge stored in
Whiletheinstruction-tuningdatageneratedbypre- Llama-2-70B-chat?
vious work (Li et al., 2023a) is limited by the Giventhesamesetofbacktranslatedinstructions,
amountofhigh-qualitytextfromtheinitialwebcor- we use MAUVE score (Pillutla et al., 2021) to
pus(i.e. ClueWeb),ourapproachovercomesthis quantifythedistributionaldifferencesamongthree
limitation with response rewriting. We generate sets of responses: initial web-scraped responses
51.2Kinstruction-responsepairswithourpipeline. (fromDolma),rewrittenresponses,andresponses
In Table 2, we find that by simply doing back- distilled from Llama-2-70B-chat. MAUVE was
translationonDolmatextsandfilteringlikeprevi- originally designed to measure the gap between
ouswork(Dolma+filtering),theresultingmodel machine-andhuman-generatedtexts. Thismetric
slightly lags behind the Humpback model from computes the area under the curve of divergence
(Li et al., 2023a) (ClueWeb + filtering) in terms frontiersinaquantizedspace,afterembeddingtext
ofwinrate. However,afterrewritingresponsesin sampleswithalanguagemodel(bydefault,GPT-2).
thefilteredsubset(Dolma+filtering+rewriting), MAUVEscorerangesbetween0and1;thehigher
wemanagetooutperformpreviousworkby3.6%. itis,themoresimilarthetextdistributionsare. In
Similar to the 7B scale, we also observe at the thefirstrowofTable3,wesampletwodisjointsets
70Bscalethatfine-tuningonrewrittenresponses of10Kdistilledresponsesandfindthattheyexhibit
fromunfilteredinstruction-responsepairs(Dolma highMAUVEscore(0.960)asexpected,sincethey
+rewriting)ismoreeffectivethanfine-tuningon are from the same distribution. Comparing 10K
web-scrapedresponsesthathavepassedthefilter initial responses sourced from Dolma to 10K re-
buthavenotbeenrewritten(Dolma+filtering). sponses distilled from Llama-2-70B-chat, we ob-
servethatthesetwosetsoftextsdiffersignificantly,
5 Understandingrewrittendataquality
eventhoughtheyaresupposedlyresponsestothe
Giventheperformancebenefitsofrewrittendata, same (backtranslated) queries (MAUVE score =
weanalyzehowtheoutputsobtainedfromrewrit- 0.0338). Rewritten responses exhibit some simi-
ing are different from those obtained from dis- laritywithdistilledoutputsbuttherestillexistsa
tillation. We also analyze the characteristics of significant gap between them (MAUVE score =
the instruction-response pairs resulting from our 0.340). Thissuggeststhattherewritingprocessis
512.8K instructions from our backtranslation data
(withandwithoutfiltering)aswellasfromeachof
thebaselinedatasetsdescribedinSection3.2. We
discard allexistinganswers, and feedeach set of
12.8KqueriestoLlama-2-70B-chattoobtaindis-
tilledresponses. Wethenfine-tuneaLlama-2-7B
model on each set of (instruction, new response)
pairsandevaluatetheAlpacaEvalwinrateofthe
resulting model. In Figure 2, we find that (i) fil-
teredbacktranslationinstructions(i.e. fromDolma
orClueWeb)outperformothersyntheticinstruction
generationmethods(i.e. Alpaca(Taorietal.,2023)
and Self-instruct (Wang et al., 2022a)), (ii) how-
Figure2: Qualityofinstructionpromptsfromvari-
ever,syntheticinstructionsstilllagbehindhuman-
ousdatasets,measuredbytheirabilitytodistilluse-
written ones, obtained via user interactions with
ful information from a fixed model. We randomly
achatinterface(ChatGPT),(iii)instructionscon-
sample12.8Kinstructionsfromeachdatasetinourex-
perimentsandinputthemtoLlama-2-70B-chattodistill structedfromtransformingexistingNLPdatasets
itsknowledge. Thequalityoftheinstructionsisthen (i.e. OpenOrca(Lianetal.,2023;Mukherjeeetal.,
measuredbytheperformanceofamodel(Llama-2-7B) 2023))donotyieldhighdistillationperformance,
fine-tunedonthe(instruction,distilledresponse)pairs. possiblyduetolimitedandrepetitivetasktypes.
Wefindthatbacktranslatedinstructionssurpassother
syntheticinstructiongenerationmethods(e.g. Alpaca),
Diversity. As a proxy for diversity, we mea-
whilestillunderperforminghuman-writtenqueries(e.g.
sure the number of unique trigrams across dif-
ShareGPT).Thisgapispartly,butnotentirely,dueto
ferent instruction sets, given the same data quan-
ShareGPThavinglongerinstructions.
tity. In Figure 3 (left), we observe that while
sufficientlydistinctfromdistillation. Weprovide ourinstructionset(backtranslatedfromDolma)is
someexamplesofrewrittenanddistilledresponses morediversethanothersyntheticinstructionsets—
inAppendixC. includingClueWeb,AlpacaandSelf-instruct,there
Wealsocompareempiricalperformanceoffine- isstillasignificantgapindiversitybetweenmodel-
tuningonrewrittendataversusdistilleddata. For generatedinstructionsandmanually-craftedones
the latter, we feed 25.6K instructions randomly (e.g.,OpenOrcaandShareGPT).
sampled from our filtered backtranslated dataset Itisworthnotingthatthehuman-writteninstruc-
to Llama-2-70B-chat and let the model answer tions(e.g. duringtheirinteractionswithChatGPT)
directly. For the former, we use the same set tendtobesubstantiallylongerthansyntheticones,
of 25.6K instructions and prompt Llama-2-70B- see Table 6 in the appendix. We thus conduct an
chattorewritethecorrespondingweb-scrapedre- ablation study to study how much the length fac-
sponses. Fine-tuning a Llama-2-70B model on tor contributes to the quality of instructions. We
thedistilledresponsesyieldslowerwinratecom- filteroutinstructionsinShareGPTthatexceedthe
paredtofine-tuningontherewrittentexts(bottom maximumlengthofourbacktranslatedinstructions
two rows of Table 2). This demonstrates that the (i.e. 514 tokens) and among the remaining dat-
rewritingprocessimprovesthequalityofresponse apoints, randomly sample 12.8K instructions to
data in general, beyond just extracting what an repeat the distillation experiment described ear-
LLMalreadyknows,possiblybecauserewritingin- lier (Figure 2). This yields a shorter version of
corporatestheinformationdiversityfoundinweb- ShareGPT ("ShareGPT (short)") in which the in-
scrapedtexts. structions have about the same average length as
ourbacktranslatedinstructions(i.e. 69tokens). We
5.2 Instructionqualityanalysis
observe that when fixing the output distribution
Measuring instruction quality empirically. tobedistilledresponsesfromLlama-2-70B-chat,
We attempt to isolate the quality of instructions fine-tuningon"ShareGPT(short)"islesseffective
from different datasets by unifying the response thanusingtheoriginalShareGPTinstructions,but
distribution to be outputs distilled from the same stilloutperformsbacktranslatedinstructions(Fig-
model. More specifically, we randomly sample ure 2). This suggests that independent of length,
6Figure3:Diversityofinstructionsandresponsesfromourbacktranslationdataandothercommoninstruction
datasets,asmeasuredbythenumberofuniquetrigrams. Wefindthat(i)whileinstructionsgeneratedinthis
workaremorediversethansyntheticinstructionsfromexistingbaselinesincludingClueWebandAlpaca-GPT4,our
instructiondiversitystilllagsbehindthatofmanually-craftedprompts,(ii)intermsofresponses,usingweb-crawled
textssourcedfromDolmayieldsthemostdiverseresponses;rewritingreducestheresponsediversityslightly,but
stilloffersmuchmoretextdiversitythandistillation.
human-writteninstructionsarestillofhigherqual- Datasource Instruction Response
Dolma+filtering 5.6 8.3
ityoverallcomparedtosyntheticinstructions.
Dolma+rewriting 4.8 6.8
Dolma+filtering+rewriting 5.1 6.6
Complexity. Following the InsTag Complexity
ClueWeb 3.7 6.6
metric employed by Liu et al. (2023), we use
OpenOrca 3.5 4.9
the InsTag public tagger (Lu et al., 2023), which Alpaca-GPT4 3.6 4.4
is a Llama-2-7B model fine-tuned on ChatGPT- Self-instruct 3.1 5.1
generated tags, to automatically tag our text data ShareGPT 6.2 5.2
Table 4: Average number of semantic and inten-
with all detectable semantics and intentions. We
tiontagsuncoveredindifferentinstruction-tuning
usetheaveragenumberofuniquetagsuncoveredin
datasetsbytheInsTagmodel(Luetal.,2023). While
instructions,andseparately,responses,fromeach
our backtranslated instructions yield fewer tags than
datasetasaproxyforcomplexity. InTable4,we
human-written ones (i.e. ShareGPT), they exhibit
observethatourDolma-backtranslatedinstructions highercomplexitythansyntheticinstructionsfromother
offershigherInsTagcomplexitythanmostinstruc- datasets. Besides,wefindthatresponsessourcedfrom
tionsetsfrompreviouswork,includingClueWeb- orarebasedonwebtextsgenerallyhavehigherInsTag
backtranslated data (Li et al., 2023a) and Open complexitythanthoseobtainedviadistillation.
Orca (Lian et al., 2023). Human-written instruc-
analysisdemonstratestheimportanceofincluding
tions, i.e. from user interactions with ChatGPT,
web sources in the data construction process, in
stillyieldthehighestnumberoftagsonaverage.
ordertoencouragemorediverseinstructionsand
5.3 Responsequalityanalysis responses, compared to just distilling knowledge
fromexistingLLMs.
Diversity. Weapplythesamediversityanalysis
as in Section 5.2 to response data. In Figure 3 Complexity. Applying the same analysis as in
(right), we observe that the initial web responses Section5.2,usingtheaveragenumberofsemantic
sourced from Dolma are substantially more di- andintentiontagsuncoveredbyInsTagtagger(Lu
verse than outputs distilled from existing models etal.,2023)asaproxyforcomplexity,wecompare
(e.g. ChatGPT, GPT-4, GPT-3), as well as web theresponsesfromourpipeline(withandwithout
texts from ClueWeb. The rewriting process re- rewriting)toresponsesfromotherbaselinedatasets.
ducesinformationdiversityoftheseweb-scraped InTable4,wefindthattheinitialweb-scrapedre-
responses slightly, but still leads to much more sponsesfromDolmayieldthehighestcomplexity.
diverse responses than distillation. Overall this RewritinggenerallyreducestheInsTagcomplexity
7oftheresponse. However,ourrewrittenresponses (ii)obtainbetterperformancewithmuchfewerdata
arestillsubstantiallymorecomplexthanmostex- (Table5)(iii)generatemoredata(51.2Kcompared
istingresponsedata,whichiscommonlydistilled to12.4K),(iv)offermoreinsightsintothequality
fromhigh-performingLLMs. ofourinstructionsandresponsesincomparisonto
We also provide an analysis of instruction and otherexistingdatasets.
responselengthsasanotherqualitymetric. Refer
Distillation. Perhapsthemostcommonapproach
toAppendixBformoredetails.
in instruction-tuning data generation, distillation
seekstomimicthecapabilitiesofpowerfulLLMs
6 RelatedWork
(e.g. GPT-4)byfeedingqueriestothesemodelsand
We discuss related papers that construct new
using the outputs to fine-tune subsequent LLMs.
instruction-tuningdatasetsorproposemethodsto
DatasetsthatarebuiltthiswayincludeShareGPT
improveexistingones. Morein-depthreviewcan
(Chiang et al., 2023), OpenInstruct (Wang et al.,
befoundinZhangetal.(2023).
2023),Alpaca-GPT4(Pengetal.,2023)andUltra-
Human-crafted data. Open Assistant (Köpf Feedback(Tunstalletal.,2023).
et al., 2024), Dolly (Conover et al., 2023) and Improving instruction-tuning data quality.
Super-NI(Wangetal.,2022b)aresomeexamples Some prior work studies characteristics of high-
ofdatasetsthatcontainsolelyhuman-generatedand qualityinstruction-tuningdata(Liuetal.,2023)and
human-annotatedconversations,coveringarange proposescurationtechniquesaccordingly. LIMA
oftopicsandNLPtasks. Thesedatasetstendtobe (Zhouetal.,2024)carefullycollects1Kfine-tuning
relativelysmallinscaleduetotheexpensivecosts samplesviabothinternetsourcingandhumanan-
ofmanualannotationandverification. notation, and shows that strong performance can
Other papers do not explicitly ask humans to be achieved despite the small data quantity. Sim-
createquestionsandanswerthem, butinsteadre- ilarly, Chen et al. (2023a) demonstrates that per-
purpose existing datasets. For example, FLAN formance gain is possible by fine-tuning on only
(Longpre et al., 2023) and Natural instructions asmallsubsetoftheoriginaldataset(Alpaca),us-
(Mishraetal.,2021)transforminputsandoutputs ing ChatGPT as the quality evaluator. Zhao et al.
ofmorethan60NLPtasksintoinstruction-tuning (2024)findsthatselectingonlythe1Klongestre-
data. Thissuffersfromthesamescalabilityissue sponsesfromexistingdatasetsoffersaverystrong
ashuman-annotateddatasets. baseline, independent of GPT-4’s preference for
longer texts. Evol-Instruct (Xu et al., 2023) and
Syntheticinstructiongeneration. Incontrastto
Orca (Mukherjee et al., 2023) manually prompt
sourcingmanuallywritteninstructions,whichmay
modelstoenhancethecomplexityofinstructions,
beexpensivetoscale,somepapersproposewaysto
andsubsequently,datageneration(e.g. byasking
automaticallygeneratelargequantitiesofinstruc-
forjustification).
tions (Wang et al., 2022a; Taori et al., 2023). In
particular,ourworkisinspiredbythebacktransla-
7 Discussion
tiontechniqueproposedinLietal.(2023a),which
Weproposeinstructionback-and-forthtranslation:
fine-tunes an LLM specifically for the task of in-
combininginstructionbacktranslationmethodfrom
structiongeneration,andthenappliesthemodelto
Lietal.(2023a)withresponserewriting,inorderto
augmenttextsegmentsextractedfromthewebwith
benefitfromboththeinformationdiversityfound
corresponding instructions. The paper suggests
ontheinternetandthequalityofmodelannotations,
thatthisapproachallowstheresultinginstruction-
whileenablingscalabilityowingtothesizeofthe
tuning data to be more diverse especially in the
webcorpuswherewesourceinitialresponsesfrom.
long tail. Another prior work, LongForm (Kök-
saletal.,2023),introducesasimilarapproachfor Future work. Our findings motivate a number
generatinginstructions. ofinterestingfuturedirections. Oneconcreteques-
MostrelatedtoourapproachistheworkbyChen tion is whether applying other existing curation
etal.(2023b),whotrainanLLMtogenerateboth techniques—e.g. quality filters proposed by Liu
instructionsandresponsesfromweb-scrapeddocu- et al. (2023)—to our pool of (synthetic instruc-
ments. Incontrasttotheirmethod,we(i)generate tions,rewrittenresponse)pairswouldleadtofur-
instructions separately with backtranslation and therperformancegains. Inaddition,wealsolook
thenaskanLLMtoimprovetheexistingresponses, forwardtoscalingupourdatagenerationpipeline
8andstudyingtheimplicationoftherewrittendata Stoica, and Eric P. Xing. 2023. Vicuna: An open-
onthepre-trainingprocess,givenconcurrentwork sourcechatbotimpressinggpt-4with90%*chatgpt
quality.
(Mainietal.,2024)thatexploresparaphrasingpre-
training data into the question-answering format.
PeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,
AshishSabharwal,CarissaSchoenick,andOyvind
Tafjord.2018. Thinkyouhavesolvedquestionan-
Limitations. Althoughwetrytocontrolforcon-
swering? tryarc,theai2reasoningchallenge. arXiv
foundingfactors(e.g. dataquantity),ourfindings preprintarXiv:1803.05457.
are only obtained from using one model family,
i.e. Llama-2(Touvronetal.,2023). Besides, our MikeConover,MattHayes,AnkitMathur,JianweiXie,
Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell,
pipelinerevolvesaroundgeneral-purposeEnglish
MateiZaharia,andReynoldXin.2023. Freedolly:
instructions,withlimitedcodingorscience-related
Introducingtheworld’sfirsttrulyopeninstruction-
tasks. Nevertheless, it is possible to extend our tunedllm.
method to more domain-specific data, e.g. by
YannDubois,BalázsGalambosi,PercyLiang,andTat-
crawlingtextsfromStackOverflow,generatingin-
sunori B Hashimoto. 2024. Length-controlled al-
structions and rewriting the responses with Code
pacaeval: Asimplewaytodebiasautomaticevalua-
Llama(Roziereetal.,2023). tors. arXivpreprintarXiv:2404.04475.
Ethicalconsiderations&Potentialrisks. Itis
ArnavGudibande,EricWallace,CharlieSnell,Xinyang
possiblethatsourcingresponsedatafromtheweb Geng,HaoLiu,PieterAbbeel,SergeyLevine,and
couldaffectthefactualityofthefine-tunedmodel Dawn Song. 2023. The false promise of imitating
proprietaryllms. arXivpreprintarXiv:2305.15717.
and/ormakeitmorepronetohallucination. The
samerisksapplytotheresponserewritingprocess.
DanHendrycks,CollinBurns,StevenBasart,AndyZou,
Futureworkcouldincludeadditionalstepstoverify MantasMazeika,DawnSong,andJacobSteinhardt.
thequalityoftheinformationintheresponses,and 2020. Measuringmassivemultitasklanguageunder-
checkwhetheritoverlapswithwhatthemodelal- standing. arXivpreprintarXiv:2009.03300.
readyknows,beforeusingthedataforfine-tuning.
AriHoltzman,JanBuys,LiDu,MaxwellForbes,and
Yejin Choi. 2019. The curious case of neural text
Acknowledgments
degeneration. arXivpreprintarXiv:1904.09751.
We are grateful to Weijia Shi and Mike Lewis
AbdullatifKöksal,TimoSchick,AnnaKorhonen,and
for helpful discussion as well as feedback on the Hinrich Schütze. 2023. Longform: Optimizing in-
manuscript. TNissupportedbytheUW-MetaAI structiontuningforlongtextgenerationwithcorpus
Mentorship Program. This work is supported in extraction. arXivpreprintarXiv:2304.08460.
partbyNSFgrant2019844.
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte,
Sotiris Anagnostidis, Zhi Rui Tam, Keith Stevens,
Abdullah Barhoum, Duc Nguyen, Oliver Stan-
References ley, Richárd Nagyfi, et al. 2024. Openassistant
conversations-democratizinglargelanguagemodel
YonatanBisk,RowanZellers,JianfengGao,YejinChoi,
alignment. AdvancesinNeuralInformationProcess-
et al. 2020. Piqa: Reasoning about physical com-
ingSystems,36.
monsenseinnaturallanguage. InProceedingsofthe
AAAIconferenceonartificialintelligence,volume34,
XianLi,PingYu,ChuntingZhou,TimoSchick,Luke
pages7432–7439.
Zettlemoyer, Omer Levy, Jason Weston, and Mike
Lewis.2023a. Self-alignmentwithinstructionback-
LichangChen,ShiyangLi,JunYan,HaiWang,Kalpa
translation. arXivpreprintarXiv:2308.06259.
Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srini-
vasan,TianyiZhou,HengHuang,etal.2023a. Al-
XuechenLi,TianyiZhang,YannDubois,RohanTaori,
pagasus: Training a better alpaca with fewer data.
IshaanGulrajani,CarlosGuestrin,PercyLiang,and
arXivpreprintarXiv:2307.08701.
Tatsunori B. Hashimoto. 2023b. Alpacaeval: An
YongruiChen,HaiyunJiang,XintingHuang,Shuming automaticevaluatorofinstruction-followingmodels.
Shi,andGuilinQi.2023b. Tegit: Generatinghigh- https://github.com/tatsu-lab/alpaca_eval.
quality instruction-tuning data with text-grounded
taskdesign. arXivpreprintarXiv:2309.05447. WingLian,BleysGoodson,EugenePentland,Austin
Cook, Chanvichet Vong, and "Teknium". 2023.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Openorca: An open dataset of gpt augmented flan
ZhanghaoWu,HaoZhang,LianminZheng,Siyuan reasoningtraces. https://https://huggingface.
Zhuang,YonghaoZhuang,JosephE.Gonzalez,Ion co/Open-Orca/OpenOrca.
9Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and LucaSoldaini,RodneyKinney,AkshitaBhagia,Dustin
Junxian He. 2023. What makes good data for Schwenk,DavidAtkinson,RussellAuthur,BenBo-
alignment? a comprehensive study of automatic gin,KhyathiChandu,JenniferDumas,YanaiElazar,
dataselectionininstructiontuning. arXivpreprint ValentinHofmann,AnanyaHarshJha,SachinKumar,
arXiv:2312.15685. LiLucy,XinxiLyu,NathanLambert,IanMagnusson,
Jacob Morrison, Niklas Muennighoff, Aakanksha
Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Naik, Crystal Nam, Matthew E. Peters, Abhilasha
Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Ravichander,KyleRichardson,ZejiangShen,Emma
Le, Barret Zoph, Jason Wei, et al. 2023. The flan Strubell,NishantSubramani,OyvindTafjord,Pete
collection: Designingdataandmethodsforeffective Walsh,LukeZettlemoyer,NoahA.Smith,Hannaneh
instructiontuning. InInternationalConferenceon Hajishirzi,IzBeltagy,DirkGroeneveld,JesseDodge,
MachineLearning,pages22631–22648.PMLR. and Kyle Lo. 2024. Dolma: An Open Corpus of
ThreeTrillionTokensforLanguageModelPretrain-
KemingLu,HongyiYuan,ZhengYuan,RunjiLin,Jun-
ingResearch. arXivpreprint.
yang Lin, Chuanqi Tan, Chang Zhou, and Jingren
Zhou.2023. #instag: Instructiontaggingforanalyz-
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
ingsupervisedfine-tuningoflargelanguagemodels.
Dubois,XuechenLi,CarlosGuestrin,PercyLiang,
InTheTwelfthInternationalConferenceonLearning
and Tatsunori B Hashimoto. 2023. Alpaca: A
Representations.
strong,replicableinstruction-followingmodel. Stan-
ford Center for Research on Foundation Models.
PratyushMaini,SkylerSeto,HeBai,DavidGrangier,
https://crfm.stanford.edu/2023/03/13/alpaca.html,
YizheZhang,andNavdeepJaitly.2024. Rephrasing
3(6):7.
theweb: Arecipeforcomputeanddata-efficientlan-
guagemodeling. arXivpreprintarXiv:2401.16380.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Hannaneh Hajishirzi. 2021. Cross-task generaliza- Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
tionvianaturallanguagecrowdsourcinginstructions. Bhosale, et al. 2023. Llama 2: Open founda-
arXivpreprintarXiv:2104.08773. tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288.
SubhabrataMukherjee,ArindamMitra,GaneshJawa-
har, Sahaj Agarwal, Hamid Palangi, and Ahmed Lewis Tunstall, Edward Beeching, Nathan Lambert,
Awadallah.2023. Orca: Progressivelearningfrom Nazneen Rajani, Kashif Rasul, Younes Belkada,
complexexplanationtracesofgpt-4. arXivpreprint Shengyi Huang, Leandro von Werra, Clémentine
arXiv:2306.02707. Fourrier,NathanHabib,NathanSarrazin,OmarSan-
seviero,AlexanderM.Rush,andThomasWolf.2023.
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida, Zephyr: Directdistillationoflmalignment. Preprint,
CarrollWainwright,PamelaMishkin,ChongZhang, arXiv:2310.16944.
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
2022. Training languagemodelsto followinstruc- Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack
tionswithhumanfeedback. Advancesinneuralin- Hessel, Tushar Khot, Khyathi Raghavi Chandu,
formationprocessingsystems,35:27730–27744. DavidWadden,KelseyMacMillan,NoahA.Smith,
IzBeltagy,andHannanehHajishirzi.2023. Howfar
Arnold Overwijk, Chenyan Xiong, and Jamie Callan.
cancamelsgo? exploringthestateofinstructiontun-
2022. Clueweb22: 10billionwebdocumentswith
ingonopenresources. Preprint,arXiv:2306.04751.
richinformation. InProceedingsofthe45thInter-
nationalACMSIGIRConferenceonResearchand
YizhongWang, YeganehKordi, SwaroopMishra, Al-
DevelopmentinInformationRetrieval,pages3360–
isaLiu,NoahASmith,DanielKhashabi,andHan-
3362.
nanehHajishirzi.2022a. Self-instruct: Aligninglan-
guagemodelswithself-generatedinstructions. arXiv
BaolinPeng,ChunyuanLi,PengchengHe,MichelGal-
preprintarXiv:2212.10560.
ley,andJianfengGao.2023. Instructiontuningwith
gpt-4. arXivpreprintarXiv:2304.03277.
Yizhong Wang, Swaroop Mishra, Pegah Alipoor-
KrishnaPillutla,SwabhaSwayamdipta,RowanZellers, molabashi, Yeganeh Kordi, Amirreza Mirzaei,
JohnThickstun,SeanWelleck,YejinChoi,andZaid Anjana Arunkumar, Arjun Ashok, Arut Selvan
Harchaoui. 2021. Mauve: Measuring the gap be- Dhanasekaran, Atharva Naik, David Stap, et al.
tweenneuraltextandhumantextusingdivergence 2022b. Super-naturalinstructions: Generalizationvia
frontiers. AdvancesinNeuralInformationProcess- declarative instructions on 1600+ nlp tasks. arXiv
ingSystems,34:4816–4828. preprintarXiv:2204.07705.
BaptisteRoziere,JonasGehring,FabianGloeckle,Sten Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,
Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, PuZhao,JiazhanFeng,ChongyangTao,andDaxin
Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023. Jiang. 2023. Wizardlm: Empowering large lan-
Codellama:Openfoundationmodelsforcode. arXiv guagemodelstofollowcomplexinstructions. arXiv
preprintarXiv:2308.12950. preprintarXiv:2304.12244.
10Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali A Moretrainingdetails
Farhadi, and Yejin Choi. 2019. Hellaswag: Can a
machinereallyfinishyoursentence? arXivpreprint A.1 Webcorpusablation
arXiv:1905.07830.
We randomly sample text segments from differ-
ShengyuZhang,LinfengDong,XiaoyaLi,SenZhang, entCommon-Crawl-derivedcorpora,generatethe
XiaofeiSun,ShuheWang,JiweiLi,RunyiHu,Tian- corresponding instructions with backtranslation,
weiZhang,FeiWu,etal.2023. Instructiontuning
andfilterthecandidatepairstoobtain3200high-
forlargelanguagemodels: Asurvey. arXivpreprint
qualitysamplesforfine-tuningLlama-2-7B.InTa-
arXiv:2308.10792.
ble 5, even though Dolma head split still slightly
HaoZhao,MaksymAndriushchenko,FrancescoCroce, lagsbehindClueWebwhenitcomestoproducing
and Nicolas Flammarion. 2024. Long is more
high-qualityresponsesforfine-tuning,itstillout-
for alignment: A simple but tough-to-beat base-
performs other web data sources such as C4 and
line for instruction fine-tuning. arXiv preprint
arXiv:2402.04833. Dolmamiddlesplit.
ChuntingZhou,PengfeiLiu,PuxinXu,SrinivasanIyer, Datasource Datasize Winrate(%)
JiaoSun,YuningMao,XuezheMa,AviaEfrat,Ping
C4 3.2K 66.83
Yu,LiliYu,etal.2024. Lima: Lessismoreforalign-
Dolma(head) 3.2K 67.92
ment. AdvancesinNeuralInformationProcessing
Dolma(middle) 3.2K 67.21
Systems,36.
ClueWeb 3.2K 68.04
Table 5: Comparison of text quality from various
web-crawled data sources, when used as initial re-
sponsesinourpipeline.
A.2 Datagenerationhyperparameters
By default, we use nucleus sampling (Holtzman
etal.,2019)forourdatageneration.
(1) Backtranslation We prompt the fine-tuned
backward model to generate instruction that
can go with a given web text response, with
T = 1.0,p = 0.9. The prompt follows from
previouswork(Lietal.,2023a):
[INST] Below is a candidate answer
to a question or instruction from an
user. Write the most likely question to
which the text below would be a great
answer.
<response>
Answer in the style of an AI Assistant.
[/INST]
(2)Filtering Wepromptthefine-tunedforward
model to score instruction-response pairs with
T = 1.0,p = 0.9. The prompt for scoring could
be found in Table 19 of previous work (Li et al.,
2023a).
(3) Rewriting Given <response>, which is
a cleaned text document from Dolma, and the
corresponding <instruction> generated by our
11backward model, we ask Llama-2-70B-chat to 70B-scaleruntakes16hourswith64A100GPUs
improve the response with T = 1.0,p = 0.9 and and51.2Kexamples.
thefollowingprompt:
A.4 Evaluationhyperparameters
[INST] Given the draft response to
Similar to Li et al. (2023a), we use nucleus sam-
the provided question below, rewrite the
pling (Holtzman et al., 2019) with temperature
draft to improve it, so it is a high
T = 0.7,p = 0.9 for generation. When evalu-
quality response to the given question.
atingontheAlpacaEvalset(Lietal.,2023b),we
appendthequestionswiththeprompt"Answer in
Draft Response: <response>
the style of an AI Assistant."or"Answer
in the style of an AI Assistant, with
Question: <instruction>
knowledge from web search if needed.", in
accordancewiththetagsusedduringtraining,and
Given the above question, rewrite
pickwhicheverpromptthatleadstohigherwinrate
the draft response to be an improvement
onaverage.
over the draft response. It should be as
similar as possible, copying text where
B Datastatistics
possible, while making the flow more
clear, useful, relevant and providing
Averagelength InTable6,wereporttheaverage
a direct answer to the question. It
length,measuredinnumberoftokens,forinstruc-
should be written to be impeccably
tions and responses from our datasets and other
tailored to the user’s question as if
baselinesdescribedinSection3.2.
written by an AI Assistant, without
extraneous information, reflecting Datasource Instruction Response
length length
expert knowledge, and demonstrating a
Dolma+filtering 69 499
high-quality, engaging, and insightful
Dolma+rewriting 58 449
answer. Try not to add new facts that Dolma+filtering+rewriting 69 468
are not already in the draft response. Dolma+filtering+distilling 69 567
Return the rewritten response between ClueWeb 31 442
OpenOrca 248 181
[RES] and [/RES]. [/INST]
ShareGPT 264 318
Alpaca-GPT4 25 163
A.3 Traininghyperparameters
Self-instruct 38 37
Wefine-tuneLlama-2model(Touvronetal.,2023) OpenAssistant 40 273
with 7B and 70B parameters. By default, we use Table 6: Average token length of instructions and
responsesfromdifferentinstruction-tuningdatasets.
acosinelearningrateschedulewithbatchsize32,
weightdecay0.1anddropout0.1. Forthe7Bscale,
we use learning rate 1e-5. With any dataset size Whenitcomestoinstructions,wefindthatthose
smaller than or equal to 25.6K, we fine-tune for generated by backtranslation tend to be longer
{600,900,1200}stepsandreportthehighestwin than those obtained from other synthetic instruc-
rate. Forthe70Bscale,weuselearningrate5.5e-6 tiongenerationmethods(i.e. Alpaca(Taorietal.,
and fine-tune on all 51.2K-size datasets for 1600 2023)orSelf-instruct(Wangetal.,2022a)). How-
steps,andall25.6K-sizedatasetsfor1200steps. ever,ourbacktranslationinstructionsaresubstan-
Following previous work (Li et al., 2023a), in tially shorter than manually crafted instructions
eachofourfine-tuningexperiments,wecombine (i.e. OpenOrca(Mukherjeeetal.,2023;Lianetal.,
both seed data (3.2K samples from Open Assis- 2023)orShareGPT(Chiangetal.,2023)). Wehy-
tant)andthedatasetofinterest,taggingtheformer pothesizethatthispropertyofourgeneratedinstruc-
distributionwith"Answer in the style of an tionsisinfluencedbythelengthofinstructionsin
AI Assistant."andthelatteronewith"Answer theseeddataset(i.e. OpenAssistant)usedtotrain
with knowledge from web search." to distin- the backward model. Future work could explore
guishthetwodatasources. usingdatasetswithlongerinstructionsfortraining
Each7B-scalefine-tuningruntakes4hourswith the backward model, or enhance the complexity
8 A100 GPUs and 12.8K examples, while each of synthetic instructions further with specifically
12craftedprompts,suchasviathemethodproposed
inEvol-Instruct(Xuetal.,2023).
In terms of responses, those obtained from in-
struction back-and-forth translation are overall
longerthanthosefoundinotherexistingdatasets.
We observe that rewriting reduces the response
length, possibly due to the removal of irrelevant
information in the initial web-crawled responses
(468tokensversus499tokensonaverage). Onthe
otherhand,giventhesamebacktranslatedinstruc-
tions,distillingfromanexistingmodelyieldssig-
nificantlylongerresponsesthantheinitialDolma
texts(567tokensversus468tokensonaverage).
Score distribution In step (2) Filtering of
ourpipeline,weaskthefine-tunedforwardmodel
toscore(backtranslatedinstruction,webresponse
fromDolma)pairs. Weuseasetofregexexpres-
sions to extract the scores from the model’s re-
sponses. Wefindthatthescoreisvalid(i.e. being
intherangeof1to5)88%ofthetime,with5-score
examplesmakingup13.6%ofthedatapool.
C Examplesofourinstruction-tuning
data
RefertoTables7,8and9.
13Backtranslatedinstruction writeapressreleaseforappleannouncingtheacquisitionofshazam
Response(fromDolma) Cupertino,California—AppletodayannouncedithascompleteditsacquisitionofShazam,one
oftheworld’smostpopularandhighly-ratedmusicapps,usedbyhundredsofmillionsofpeople
worldwide.
Rewrittenresponse AppleAcquiresShazam:ANewChapterinMusicRecognitionTechnology
Cupertino, California — Apple is thrilled to announce the completion of its acquisition
ofShazam,theworld-renownedmusicappusedbyhundredsofmillionsofpeopleglobally.
ThisstrategicmovemarksasignificantmilestoneinApples´missiontorevolutionizetheway
peoplediscover,enjoy,andinteractwithmusic.
With Shazam, users can effortlessly identify songs, artists, and albums in a matter of
seconds,makingitanindispensabletoolformusicloverseverywhere.ByintegratingShazams´
innovativetechnologyintoourecosystem,wecanfurtherenhancethemusicexperienceforour
customers,providingthemwithseamlessaccesstothesongsandartiststheylove.
"We are delighted to welcome Shazam to the Apple family," said Tim Cook, CEO of
Apple."Thisacquisitionisatestamenttoourcommitmenttodeliveringthebestpossiblemusic
experiencestoourcustomers.Welookforwardtoexploringtheexcitingpossibilitiesthatthis
partnershippresents,andweareeagertoseewherethisnewchapterwilltakeus."
Shazam has been a game-changer in the music industry since its inception, using audio
fingerprintingtechnologytoquicklyandaccuratelyrecognizesongs.Thiscutting-edgetechhas
madeitpossibleforuserstoidentifymusicplayinginthebackground,whetherinastore,onthe
radio,oreveninamovie.Shazamhasalsoexpandeditsofferingstoincludefeatureslikelyrics,
recommendations,andplaylists,cementingitsplaceasaleaderinthemusicrecognitionspace.
The union between Apple and Shazam is a natural one. Both companies share a pas-
sionfordeliveringexceptionaluserexperiences,andweareconfidentthatthiscollaborationwill
bringevenmorejoyandconveniencetomusicfanseverywhere.
"We are incredibly excited to join forces with Apple, a company that shares our dedi-
cationtodeliveringthebestpossibleuserexperience,"saidRichRiley,CEOofShazam."We
lookforwardtoworkingtogethertocreatenewandinnovativewaysforpeopletoenjoyand
engagewithmusic."
Apple and Shazam share a rich history, dating back to the early days of the App Store.
ShazamwasoneofthefirstappstobefeaturedontheAppStore,anditquicklybecameafan
favorite.Today,thispartnershiprepresentsthenextstepinthatjourney,aswecontinuetopush
theboundariesofwhatispossiblewithmusicrecognitiontechnology.
At Apple, we believe that music has the power to bring people together and enrich
theirlives. WiththeadditionofShazamtoourfamily,weareonestepclosertomakingthat
visionareality.So,letthemusicplay,andlet’sseewherethisjourneytakesusnext.
14Distilledresponse Sure!Here’sapossiblepressreleaseforAppleannouncingtheacquisitionofShazam:
—
AppleAcquiresShazam,BringingMusicRecognitionTechnologyIn-House
Cupertino, California — December 17, 2022 — Apple today announced that it has ac-
quired Shazam, a leading music recognition platform that has been a popular choice for
musicfansaroundtheworld.TheacquisitionbringsShazam’sinnovativeaudiofingerprinting
technologyandextensivemusicdatabaseintotheApplefold,furtherenhancingthecompanys´
capabilitiesinthemusicandaudiospace.
"We´re thrilled to welcome Shazam to the Apple family," said Tim Cook, CEO of Ap-
ple. "Shazam’stechnologyandtalentedteamwillplayakeyroleinoureffortstocontinue
deliveringthebestmusicexperiencestoourcustomers. We’relookingforwardtoexploring
themanywaysthatShazam’saudiofingerprintingtechcanbeintegratedintoourproductsand
services,andwe’reexcitedtoseewhatthefutureholdsforthispartnership."
Shazam’s proprietary audio fingerprinting technology allows users to identify songs
andartistsplayingaroundthemsimplybyholdingtheirdevicenearthesourceofthesound.The
platformhasbecomeago-todestinationformusicdiscoveryandidentification,withover1
billiondownloadsworldwideandcounting.
"We´re proud of the Shazam team for building such a powerful and beloved platform,"
saidOliverSchusser, VicePresidentofAppleMusic. "We’reexcitedtointegrateShazam’s
technologyintoourownproductsandservices,andwe’relookingforwardtoworkingwiththe
Shazamteamtotakemusicrecognitionanddiscoverytothenextlevel."
The acquisition follows Apple’s purchase of Beats Electronics in 2014, which brought
thepopularBeatsheadphonesandstreamingserviceintotheApplefamily.Likethatdeal,the
Shazam acquisition underscores Apple’s commitment to delivering the best possible music
experiencestoitscustomers.
Terms of the deal were not disclosed. Shazam will continue operating independently,
withthesameleadershipandteamthathavedrivenitssuccesstodate.
AboutApple
Apple revolutionized personal technology with the introduction of the Macintosh com-
puterin1984.Today,AppleleadstheworldininnovationwithiPhone,iPad,Mac,AppleWatch,
andAppleTV.Apple’sfoursoftwareplatforms—iOS,macOS,watchOS,andtvOS—provide
seamlessexperiencesacrossallAppledevicesandempowerpeoplewithbreakthroughservices
includingtheAppStore,AppleMusic,ApplePay,andiCloud.Apple’s100,000employeesare
dedicatedtomakingthebestproductsonearth,andtoleavingtheworldbetterthantheyfoundit.
AboutShazam
Shazam is a popular music recognition platform that has been a go-to destination for
musicfansaroundtheworld. Withover1billiondownloadsworldwide, Shazamletsusers
identifysongsandartistsplayingaroundthemsimplybyholdingtheirdevicenearthesourceof
thesound.Shazam’sproprietaryaudiofingerprintingtechnologyhasmadeitaleaderinmusic
recognitionanddiscovery,anditsextensivemusicdatabasehasmadeitavaluableresourcefor
musicfanseverywhere.
Contacts:
AppleMediaRelations:[media.relations@apple.com](mailto:media.relations@apple.com)
ShazamPressOffice:[press@shazam.com](mailto:press@shazam.com)
—
Of course, this is just one possible version of a press release announcing Apple’s ac-
quisitionofShazam.Theactualpressreleasecouldbedifferent,dependingonthespecificsof
thedealandthemessagingthatAppleandShazamwanttoconvey.
Table7: Exampleofascore-5(backtranslatedinstruction,web-scrapedresponse)pair
15Backtranslatedinstruction Whydoesn’tanybodyridethetraininSanJose?
Response(fromDolma) Lessthan1percentofSantaClaraCountyresidentsrideVTAlightrail,andtaxpayerssubsidize
85percentoftheoperatingcosts.
Lightrailrecentlycelebratedits25thanniversaryinSiliconValley,butmostpeopleinthearea
wereprobablytoobusydrivingtocelebrate.MikeRosenbergoftheMercuryNewsreportsthat
thesystem,runbytheValleyTransportationAuthority,isamongthecountry’sworstbyjust
abouteverycommonmetricofsuccess.
Towit:Lessthan1percentofSantaClaraCountyresidentsrideVTAlightrail;theper-passenger
round-tripoperatingcostis$11.74andtaxpayerssubsidize85percentofcosts—thirdand
secondworstinthecountry,respectively.Thereareproblemswithmeasuringcostsperpassenger
mileonlightrail,butouch.
Light-railagenciesinMinneapolis,Houston,Newark,N.J.,andPhoenixeachrunlessservice
thanVTAyetcarrymorepassengersthantheSouthBay’snetwork.Severalcitiesthataremuch
smallerthanSanJose—fromSt. LouistoSaltLakeCitytoPortland,Ore. —alsofeature
light-railsystemswithmoreridersthanVTA.
Sacramento—whichalsoopeneditslight-railnetworkin1987,operateswithapproximately
thesamelevelofserviceandrunsthroughasimilarlysprawled-outregion—carriesnearly40
percentmorepassengersperdaythanVTA.
WhenIfirstencounteredVTAlightrailinSanJose(briefly)in1990. Inotedhowslowlyit
movedthruthedowntownarea,interminglingamongstpedestriantraffic. Ithoughtitthento
beweirdatbestforacitytorunlightrailonasidewalkwherepedestriansnormallyare.Fast
forwardtotoday(afterreturningtoNewJerseythenmovingbacktoCalifornia), evenwith
system-wideexpansiontoMountainView,SouthSanJoseandEastSanJose,anditsstillthe
same,sadslownessIremember.
SiliconValleymustbegettingusedtobadtransitnewsatthispoint.InNovember,Rosenberg
reportedthataVTAplantoextendalightrailline1.6milestoLosGatos,homeofNetflix,will
cost$175millionwhiledrawingonlyabout200newriders.BackinMay,alocalnewsstation
foundacultureoffareevasiononVTAthatgivesthesystemarateof7.2percent—highestin
theregion.
InApril,constructionbeganonanextensionofBARTfromtheBayAreatoSantaClara,ending
attheBerryessastation,whereitwillmeettheVTAlightrailsystem. Amongthatproject’s
shortcomingsarethefactthatthestopfallsshortofdowntownSanJose,andthatBerryessa
seemspoorlysuitedtotransit-orienteddevelopment. AnextensiontoSanJoseisstillinthe
plans,thoughBARTservicetothecitywouldduplicatetheCaltraincommuterrailthatalready
goesthere.
NotthatanyoneinSiliconValleyusesCaltrainanyway.InOctober,StamenDesignsreleased
amapofprivatebuslinesthatservethecampusesofGoogle,Apple,Facebook,andthelike
foremployeeslivingindowntownSanFrancisco.Thesebusesareseenasabetteroptionthan
Caltrain, which runsinfrequentlyand requiresanumber oftransfers fromthecity toreach
SiliconValley...
Rewrittenresponse San Jose’s VTA light rail system has struggled with low ridership, high costs, and poor
performance,raisingthequestionofwhynobodyridesthetraininSanJose.AccordingtoMike
RosenbergoftheMercuryNews,thesystemhassomeoftheworstmetricsinthecountry,with
fewerthan1%ofSantaClaraCountyresidentsusingthetrainandtaxpayerssubsidizing85%of
theoperatingcosts.
One reason for the low ridership may be the limited coverage area, as the system pri-
marilyservesthedowntownareaandnearbyneighborhoods. Additionally, thetrainsmove
slowlythroughthedowntownarea,whichmaynotappealtocommuterslookingforaquickand
efficientride.
Moreover, Silicon Valley’s tech industry leaders seem to prioritize corporate campuses
overaccessiblepublictransportation.PrivatebuslinesforemployeeslivingindowntownSan
FranciscoareviewedasabetteralternativetoCaltrain,whichrunsinfrequentlyandrequires
multipletransferstoreachSiliconValley.
Despite efforts to expand the VTA light rail system, including a planned extension to
LosGatosthatwillcost$175millionanddrawonly200newriders,thesystemstillfallsshort
ofmeetingtheregion’stransportationneeds. TheBerryessastation,wheretheVTAlightrail
systemwillmeettheBART,isnotlocatedindowntownSanJose,andtheextensiontoSanJose
isstillintheplansbutwillduplicatetheCaltraincommuterrailthatalreadyexists.
In conclusion, the low ridership of the VTA light rail system in San Jose can be at-
tributedtoacombinationoffactors,includinglimitedcoverage,slowtraveltimes,andalack
ofinvestmentinaccessiblepublictransportationbythetechindustry.Addressingtheseissues
couldpotentiallyimprovethesystem’sperformanceandencouragemorepeopletousethetrain.
16Distilledresponse TherecouldbeseveralreasonswhypeoplemaynotridethetraininSanJose,California.Here
areafewpossiblereasons:
1.Limitedpublictransportationoptions:SanJoseisasprawlingcitywithacar-centricculture,
andpublictransportationoptionsmaybelimited,especiallyoutsideofdowntownareas.Thiscan
makeitdifficultforpeopletoaccessthetrainorotherformsofpublictransportation,especially
iftheyliveinsuburbanorruralareas.
2. Lackofconvenientroutes: ThetrainroutesinSanJosemaynotbeconvenientformany
residents,especiallyiftheyliveinareasthatarenotservicedbythetrain. Thiscanmakeit
difficultforpeopletousethetrainfortheirdailycommutesorothertrips.
3.Limitedfrequencyofservice:ThefrequencyoftrainserviceinSanJosemaybelimited,with
fewtrainsrunningduringoff-peakhoursoronweekends.Thiscanmakeitdifficultforpeopleto
usethetrainforspontaneoustripsorfortravelingoutsideofpeakcommutetimes.
4.Competitionfromothermodesoftransportation:SanJoseislocatedintheheartofSilicon
Valley,andmanypeoplemayprefertousetheirowncarsorride-hailingserviceslikeUberor
Lyfttogetaround.Thiscanmakeitdifficultforthetraintocompeteforpassengers,especially
inareaswithheavytrafficorlimitedpublictransportationoptions.
5.Lackofawarenessorpromotion:ThetrainserviceinSanJosemaynotbewell-promotedor
well-known,especiallyamongvisitorsornewresidents.Thiscanmakeitdifficultforpeopleto
learnaboutthetrainanditsroutes,schedules,andfares.
6. Affordability: ThecostoftakingthetraininSanJosemaybeprohibitivelyexpensivefor
somepeople,especiallyforthosewhoareusedtocheapertransportationoptionslikedriving
orride-hailingservices. Thiscanmakeitdifficultforthetraintoattractadiverserangeof
passengers.
7. Safetyconcerns: SomepeoplemaybehesitanttoridethetraininSanJoseduetosafety
concerns,suchasconcernsaboutcrimeorsafetyonthetrainsorinthesurroundingareas.
8.Lackofamenities:ThetrainserviceinSanJosemaynotofferthesamelevelofamenitiesas
othermodesoftransportation,suchascomfortableseating,Wi-Fi,orfoodandbeverageoptions.
Table8: Exampleofascore-3(backtranslatedinstruction,web-scrapedresponse)pair
17Backtranslatedinstruction WhenwastheChicagoSymphonyOrchestra’sfirsttourofRussiaandEasternEurope,andwere
anyrecordingsmadeduringthattour?
Response(fromDolma) Youarecurrentlybrowsingthetagarchiveforthe’AndrásSchiff’tag.
CongratulationstoBernardHaitink—theChicagoSymphonyOrchestra’sprincipalconductor
from2006until2010andafrequentguestconductor—therecipientofthisyear’sGramophone
magazineawardforlifetimeachievement!
Congratulations,MaestroHaitink!
HaitinkreturnstoChicagoinApril2016,leadingtheOrchestrainMozart’sPianoConcertono.
22withTillFellnerandStrauss’sAnAlpineSymphony.
SirGeorgSoltiledtheChicagoSymphonyOrchestra’sfirsttriptotheSovietUnionandHungary
inNovember1990,alsoincludingasinglestopinVienna.
Tworecordingsweremadeduringthetour, bothforLondonRecords. Theperformanceof
Bruckner’sEighthSymphonywasrecordedliveinLeningradonNovember22(London’sfirst
recordingventureintheSovietUnion);MichaelHaaswastheproducer,JamesLockandColin
Moorfootweretheengineers,andSallyDrewwasthetapeeditor.Mahler’sFifthSymphonywas
recordedliveinViennaonNovember30,MichaelHaaswastheproducer,StanGoodallwasthe
engineer,andMatthewHutchinsonwasthetapeeditor.
Rewrittenresponse The Chicago Symphony Orchestra’s first tour of Russia and Eastern Europe took place
in November 1990, led by Sir Georg Solti. During this tour, the orchestra made two
recordings for London Records. The first recording was of Bruckner’s Eighth Symphony,
which was recorded live in Leningrad on November 22, with Michael Haas as producer,
James Lock and Colin Moorfoot as engineers, and Sally Drew as tape editor. The sec-
ond recording was of Mahler’s Fifth Symphony, recorded live in Vienna on November 30,
withMichaelHaasasproducer,StanGoodallasengineer,andMatthewHutchinsonastapeeditor.
Congratulations are in order for Bernard Haitink, who will be returning to Chicago in
April 2016 to lead the orchestra in Mozart’s Piano Concerto No. 22 with Till Fellner and
Strauss’sAnAlpineSymphony.Haitink,whoservedastheprincipalconductoroftheChicago
SymphonyOrchestrafrom2006to2010,isthisyear’srecipientofGramophonemagazine’s
lifetimeachievementaward.
Distilledresponse TheChicagoSymphonyOrchestra’sfirsttourofRussiaandEasternEuropetookplacein1971.
Theorchestra,ledbymusicdirectorGeorgSolti,performedinseveralcities,includingMoscow,
Leningrad(nowSt.Petersburg),Warsaw,andPrague.
During the tour, the orchestra made several recordings, including a live recording of
Tchaikovsky’s Symphony No. 6, which was recorded at the Great Hall of the Moscow
Conservatory.ThisrecordingwaslaterreleasedontheRCARedSeallabelandwonaGrammy
AwardforBestClassicalPerformance-Orchestra.
Additionally, the orchestra recorded a live performance of Shostakovich’s Symphony
No.5inLeningrad,whichwasalsoreleasedonRCARedSeal.
These recordings were significant not only for their artistic quality but also for their
historicalsignificance,astheyrepresentedoneofthefirsttimesaWesternorchestrahadtoured
theSovietUnionandEasternEuropesincetheendofWorldWarII.Thetourandrecordings
helpedtoestablishtheChicagoSymphonyOrchestraasoneoftheleadingensemblesinthe
worldandpavedthewayforfutureculturalexchangesbetweentheUnitedStatesandEastern
Europe.
Table9: Exampleofascore-1(backtranslatedinstruction,web-scrapedresponse)pair
18D Rewritingablations models (ChatGPT for ShareGPT and GPT-3 for
Self-instruct).
Besides Llama-2-70B-chat, we also experiment
We do not emphasize AlpacaEval 2.0 results
with rewriting web-crawled responses with: (i) a
in the main text, given that the win rates against
smallerscalemodel, Llama-2-7B-chat, (ii)aless
GPT-4Turboobtainedfromourbaselinesareclose
alignedmodel,Llama-2basefine-tunedonOpen
together within a limited range, leading to their
Assistantseeddata(i.e. theforwardmodelusedin
performancegapsbeingnotsufficientlysignificant.
our filtering step). Ablation results are shown in
WiththecurrentresultsinTable10,wefindthat
Figure4.
similartotheobservationsinTable2: (i)rewriting
In our small-scale experiments fine-tuning a
is more effective at improving data quality than
Llama-2-7B model with 3.2K and 6.4K (instruc-
filtering(lookingatthefirsttworows),and(ii)us-
tion,rewrittenresponse)pairs,wefindthattheAl-
inganalignedLLMforresponserewritingyields
pacaEvalwinrateislowerwhenusingdatarewrit-
betterwinratethanusingthesamemodelfordis-
tenbyLlama-2-7B-chatandOA-finetunedLlama-
tillation (looking at the bottom two rows). How-
2. This suggests that effectively structuring and
ever, with this evaluation, rewriting all candidate
enrichingtheinitialrawtextresponsemayrequire
instruction-responsepairswithoutfiltering(Dolma
asufficientlyalignedmodelthatalsocontainssig-
+rewriting)yieldsthebestperformance,whenall
nificantknowledgeitself.
baselines are fine-tuned with same data quantity
(51.2K).
F OtherNLPevaluations
WealsoevaluatethemodelsdescribedinSection4
onsomecommonNLPbenchmarks:
• HellaSwag (Zellers et al., 2019): consists of
70K multiple-choice questions designed to test
grounded commonsense inference. Each ques-
tion comes from either activitynet or wikihow,
alongwithfouranswerchoicesaboutwhatmight
happen next in the scene. The correct answer
is the actual sentence for the next event, while
the other three are adversarially generated and
Figure 4: Performance of fine-tuning on responses
humanverified.
rewrittenbydifferentmodels. Wefindthatusinga
• ARC(Clarketal.,2018): aimstotestadvanced
smallermodel(i.e. Llama-2-chat-7B)oralessaligned
question-answeringcapabilitieswith7787grade-
model(i.e. Llama-2fine-tunedonOpenAssistant)for
rewritingyieldslowerresponsequality,asreflectedin schoollevel,multiple-choicesciencequestions.
thewinrateofaLlama-2-7Bmodelfine-tunedonthe ThedatasetconsistsofChallengeandEasySets,
resultingresponsedata. with the former containing only questions an-
sweredincorrectlybybotharetrieval-basedalgo-
E AlpacaEval2.0results
rithmandawordco-occurrencealgorithm.
AlpacaEval2.0(Duboisetal.,2024)upgradesthe • PIQA(Bisketal.,2020): anothermultiple-choice
baseline model from text-davinci-003 to GPT-4 dataset, created to test an NLP model’s under-
Turbo,andusesGPT-4Turboastheevaluatorby standingofthephysicsmodeloftheworld. Ques-
default. Theevaluationalsodebiasestherawwin tionsareinspiredbyhow-toinstructionsandthe
rateviaafittedlogisticregressionmodel,inorder modelissupposedtopickthecorrectanswerout
tocontrolforthelengthoftheoutputs. oftwochoices.
AsnotedbytheAlpacateam,length-controlled • MMLU(Hendrycksetal.,2020): covers57sub-
(LC) win rates alleviate length biases of GPT-4, jects across STEM, the humanities, the social
but may favor models fine-tuned on its outputs. sciences,etc. Thequestiondifficultyrangesfrom
Ourbaselinesofchoice(describedinSection3.2) anelementaryleveltoanadvancedprofessional
mostly distill outputs from GPT4 (in the case of level,testingforbothworldknowledgeandprob-
Alpaca-GPT4 and Open Orca) and GPT-related lemsolvingability. Questionsarepresentedina
19Datasource Datasize GPT-4-Turbo GPT-4-Turbo Claude-3-Opus Claude-3-Opus
Winrate-LC(%) Winrate(%) Winrate-LC(%) Winrate(%)
Dolma+filtering 51.2K 16.71 11.90 17.66 9.63
Dolma+rewriting 51.2K 17.44 12.66 21.54 15.34
Dolma+filtering+rewriting 51.2K 16.68 12.07 19.09 12.86
ClueWeb+filtering 41.8K 15.93 11.89 18.39 10.26
OpenOrca 51.2K 16.96 11.82 16.35 9.63
ShareGPT 51.2K 18.42 11.62 19.14 9.81
Alpaca-GPT4 51.2K 17.19 11.48 17.04 8.63
Self-instruct 51.2K 12.20 7.09 13.24 6.58
Dolma+filtering+rewriting 25.6K 17.90 13.05 17.55 11.86
Dolma+filtering+distilling 25.6K 17.80 11.95 17.50 10.50
Table10: WinratesagainstGPT-4-TurboofLlama-2-70Bmodelsfine-tunedondifferentinstructiondatasets,
asevaluatedwithAlpacaEval2.0frameworkusingGPT-4TurboandClaude-3Opusasevaluators.
Datasource Datasize HellaSwag ARC PIQA MMLU
7Bscale
Dolma+filtering 12.8K 60.6 59.1 76.1 35.6
Dolma+rewriting 12.8K 56.4 56.8 74.6 33.8
Dolma+filtering+rewriting 12.8K 56.8 56.7 74.5 36.6
ClueWeb+filtering 12.8K 60.3 57.5 75.7 35.1
OpenOrca 12.8K 57.3 59.1 76.0 45.7
ShareGPT 12.8K 56.3 59.2 75.1 40.4
Alpaca-GPT4 12.8K 57.3 57.7 74.7 35.0
Self-instruct 12.8K 56.7 55.7 74.9 35.2
70Bscale
Dolma+filtering 51.2K 68.1 69.4 81.8 62.8
Dolma+rewriting 51.2K 66.4 69.3 81.2 61.9
Dolma+filtering+rewriting 51.2K 66.8 69.1 81.4 61.4
ClueWeb+filtering 41.8K 68.8 68.4 81.6 63.3
OpenOrca 51.2K 65.8 66.6 78.6 61.8
ShareGPT 51.2K 65.7 68.4 79.7 60.0
Dolma+filtering+rewriting 25.6K 66.8 69.7 82.2 62.7
Dolma+filtering+distilling 25.6K 65.7 70.9 82.0 60.8
Table11: Performanceofourfine-tunedmodelsondifferentNLPtasks.
multiple-choiceformat.
WereporttheresultsonthesetasksinTable1.
20