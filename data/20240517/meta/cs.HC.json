[
    {
        "title": "Societal Adaptation to Advanced AI",
        "authors": "Jamie BernardiGabriel MukobiHilary GreavesLennart HeimMarkus Anderljung",
        "links": "http://arxiv.org/abs/2405.10295v1",
        "entry_id": "http://arxiv.org/abs/2405.10295v1",
        "pdf_url": "http://arxiv.org/pdf/2405.10295v1",
        "summary": "Existing strategies for managing risks from advanced AI systems often focus\non affecting what AI systems are developed and how they diffuse. However, this\napproach becomes less feasible as the number of developers of advanced AI\ngrows, and impedes beneficial use-cases as well as harmful ones. In response,\nwe urge a complementary approach: increasing societal adaptation to advanced\nAI, that is, reducing the expected negative impacts from a given level of\ndiffusion of a given AI capability. We introduce a conceptual framework which\nhelps identify adaptive interventions that avoid, defend against and remedy\npotentially harmful uses of AI systems, illustrated with examples in election\nmanipulation, cyberterrorism, and loss of control to AI decision-makers. We\ndiscuss a three-step cycle that society can implement to adapt to AI.\nIncreasing society's ability to implement this cycle builds its resilience to\nadvanced AI. We conclude with concrete recommendations for governments,\nindustry, and third-parties.",
        "updated": "2024-05-16 17:52:12 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.10295v1"
    },
    {
        "title": "Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers",
        "authors": "Tuo ZhangJinyue YuanSalman Avestimehr",
        "links": "http://arxiv.org/abs/2405.10276v1",
        "entry_id": "http://arxiv.org/abs/2405.10276v1",
        "pdf_url": "http://arxiv.org/pdf/2405.10276v1",
        "summary": "Numerous recent works aim to enhance the efficacy of Large Language Models\n(LLMs) through strategic prompting. In particular, the Optimization by\nPROmpting (OPRO) approach provides state-of-the-art performance by leveraging\nLLMs as optimizers where the optimization task is to find instructions that\nmaximize the task accuracy. In this paper, we revisit OPRO for automated\nprompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral\n7B. Our investigation reveals that OPRO shows limited effectiveness in\nsmall-scale LLMs, with limited inference capabilities constraining optimization\nability. We suggest future automatic prompting engineering to consider both\nmodel capabilities and computational costs. Additionally, for small-scale LLMs,\nwe recommend direct instructions that clearly outline objectives and\nmethodologies as robust prompt baselines, ensuring efficient and effective\nprompt engineering in ongoing research.",
        "updated": "2024-05-16 17:33:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.10276v1"
    },
    {
        "title": "IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers",
        "authors": "Hao YanThomas D. LatozaZiyu Yao",
        "links": "http://arxiv.org/abs/2405.10250v1",
        "entry_id": "http://arxiv.org/abs/2405.10250v1",
        "pdf_url": "http://arxiv.org/pdf/2405.10250v1",
        "summary": "Large language models (LLMs) have exhibited a strong promise in automatically\ngenerating executable code from natural language descriptions, particularly\nwith interactive features that allow users to engage in the code-generation\nprocess by instructing the LLM with iterative feedback. However, existing\ninteraction paradigms often assume that users have expert knowledge to debug\nsource code and are not optimized for non-professional programmers' use. This\nraises challenges in making interactive code generation more accessible for\nindividuals with varying levels of programming expertise. To tackle these\nchallenges, we present IntelliExplain, which offers a novel human-LLM\ninteraction paradigm to enhance non-professional programmers' experience by\nenabling them to interact with source code via natural language explanations.\nUsers interact with IntelliExplain by providing natural language corrective\nfeedback on errors they identify from the explanations. Feedback is used by the\nsystem to revise the code, until the user is satisfied with explanations by the\nsystem of the code. Our user study demonstrates that users with IntelliExplain\nachieve a significantly higher success rate 11.6% and 25.3% better than with\nvanilla GPT-3.5, while also requiring 39.0% and 15.6% less time in Text-to-SQL\nand Python code generation tasks, respectively.",
        "updated": "2024-05-16 16:55:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.10250v1"
    },
    {
        "title": "Co-Matching: Towards Human-Machine Collaborative Legal Case Matching",
        "authors": "Chen HuangXinwei YangYang DengWenqiang LeiJianCheng LvTat-Seng Chua",
        "links": "http://arxiv.org/abs/2405.10248v1",
        "entry_id": "http://arxiv.org/abs/2405.10248v1",
        "pdf_url": "http://arxiv.org/pdf/2405.10248v1",
        "summary": "Recent efforts have aimed to improve AI machines in legal case matching by\nintegrating legal domain knowledge. However, successful legal case matching\nrequires the tacit knowledge of legal practitioners, which is difficult to\nverbalize and encode into machines. This emphasizes the crucial role of\ninvolving legal practitioners in high-stakes legal case matching. To address\nthis, we propose a collaborative matching framework called Co-Matching, which\nencourages both the machine and the legal practitioner to participate in the\nmatching process, integrating tacit knowledge. Unlike existing methods that\nrely solely on the machine, Co-Matching allows both the legal practitioner and\nthe machine to determine key sentences and then combine them probabilistically.\nCo-Matching introduces a method called ProtoEM to estimate human decision\nuncertainty, facilitating the probabilistic combination. Experimental results\ndemonstrate that Co-Matching consistently outperforms existing legal case\nmatching methods, delivering significant performance improvements over human-\nand machine-based matching in isolation (on average, +5.51% and +8.71%,\nrespectively). Further analysis shows that Co-Matching also ensures better\nhuman-machine collaboration effectiveness. Our study represents a pioneering\neffort in human-machine collaboration for the matching task, marking a\nmilestone for future collaborative matching studies.",
        "updated": "2024-05-16 16:50:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.10248v1"
    },
    {
        "title": "A Design Trajectory Map of Human-AI Collaborative Reinforcement Learning Systems: Survey and Taxonomy",
        "authors": "Zhaoxing Li",
        "links": "http://arxiv.org/abs/2405.10214v1",
        "entry_id": "http://arxiv.org/abs/2405.10214v1",
        "pdf_url": "http://arxiv.org/pdf/2405.10214v1",
        "summary": "Driven by the algorithmic advancements in reinforcement learning and the\nincreasing number of implementations of human-AI collaboration, Collaborative\nReinforcement Learning (CRL) has been receiving growing attention. Despite this\nrecent upsurge, this area is still rarely systematically studied. In this\npaper, we provide an extensive survey, investigating CRL methods based on both\ninteractive reinforcement learning algorithms and human-AI collaborative\nframeworks that were proposed in the past decade. We elucidate and discuss via\nsynergistic analysis methods both the growth of the field and the\nstate-of-the-art; we conceptualise the existing frameworks from the\nperspectives of design patterns, collaborative levels, parties and\ncapabilities, and review interactive methods and algorithmic models.\nSpecifically, we create a new Human-AI CRL Design Trajectory Map, as a\nsystematic modelling tool for the selection of existing CRL frameworks, as well\nas a method of designing new CRL systems, and finally of improving future CRL\ndesigns. Furthermore, we elaborate generic Human-AI CRL challenges, providing\nthe research community with a guide towards novel research directions. The aim\nof this paper is to empower researchers with a systematic framework for the\ndesign of efficient and 'natural' human-AI collaborative methods, making it\npossible to work on maximised realisation of humans' and AI's potentials.",
        "updated": "2024-05-16 16:04:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.10214v1"
    }
]