Feature-based Federated Transfer Learning:
Communication Efficiency, Robustness and Privacy
Feng Wang, M. Cenk Gursoy and Senem Velipasalar
Abstract—In this paper, we propose feature-based federated availability of open-source big data repositories and deep
transfer learning as a novel approach to improve communi- learning models [12], [13], transfer learning (TL) has become
cation efficiency by reducing the uplink payload by multiple
an attractive solution for various applications, such as text
orders of magnitude compared to that of existing approaches in
sentiment classification [14]–[16], image classification [17]–
federated learning and federated transfer learning. Specifically,
in the proposed feature-based federated learning, we design [22], human activity classification [23]–[25], software defect
the extracted features and outputs to be uploaded instead of classification [26], [27], and multi-language text classification
parameter updates. For this distributed learning model, we [28]–[30].
determine the required payload and provide comparisons with However, when the clients in FL are mobile devices and
the existing schemes. Subsequently, we analyze the robustness
the training process is performed over a wireless network
of feature-based federated transfer learning against packet loss,
data insufficiency, and quantization. Finally, we address privacy such as a wireless local area network (WLAN) or cellular
considerations by defining and analyzing label privacy leak- system, it is crucial to minimize the data sent during updates
age and feature privacy leakage, and investigating mitigating ofthemodelparameters.Thisisduetothelimitedavailability
approaches. For all aforementioned analyses, we evaluate the
of radio spectrum, and the uncertain nature of the wireless
performanceoftheproposedlearningschemeviaexperimentson
environment caused by factors such as channel fading and
an image classification task and a natural language processing
task to demonstrate its effectiveness. 1 interference [31]. In the context of FL applications on IoT
devices, the added constraints on computation and power
Index Terms—Federated learning, transfer learning, commu-
consumptionforuploadingdatamakeitevenmorechallenging
nication efficiency, robustness, privacy
to perform complex tasks that require deep neural networks
(DNNs) with many layers and a large number of trainable
I. INTRODUCTION
parameters. While many existing FL studies have focused on
Federated learning (FL) is a form of distributed learning in shallowDNNswithafewlayers,state-of-the-artDNNmodels
whichonlymodelparametersareexchangedwhiledatasetsare used in various applications often have dozens of layers and
keptlocalwiththegoaltomaintaindataprivacy[1].Typically, millionsorbillionsoftrainableparametersinordertoachieve
in FL, a central server, known as the parameter server (PS), the highest accuracy in e.g., image segmentation [32], [33],
coordinatesthecollaborativetrainingofadeepneuralnetwork image classification [34], [35], object detection [36], [37],
(DNN) model [2] by aggregating updates on the weights question answering [38], medical image segmentation [39],
and biases from multiple participating devices/clients. The and speech recognition [40].
widespread use of mobile phones and tablets with sufficient
computational power and wireless communication capability
enables FL in a wide range of applications such as speech A. Contributions
recognition and image classification. Internet of Things (IoT)
Inresponsetotheabove-mentionedconstraintsontheuplink
with large number of devices/sensors may generate even
payload budget and limitations on the local computational
larger amount of data while casting further constraints on
power, we develop a novel scheme to perform model-based
the computational power and transmission power [3]. With
transferFLandrefertothisschemeasfeature-basedfederated
these,FLhasgainedwidespreadattentionfrombothacademic
transfer learning (FbFTL). In FbFTL, rather than uploading
and industrial communities, resulting in a rapid increase in
the gradients, the input and output of the subset of DNN to
research on FL techniques, such as federated averaging (Fe-
be trained are uploaded with the goal to reduce the uplink
dAvg) [4], federated transfer learning (FTL) [5], [6], and FL
payload. This is one of the key differences from prior FL and
with differential privacy (DP) [7]. Among them, model-based
FTL strategies. In this paper, after describing the proposed
FTL stands out as a particularly efficient scheme, because it
FbFTL scheme, we analyze its overall uplink payload and
transfers a well-trained source model into the target task of
providecomparisonswithpriorschemestoquantifythegains.
interest where samples may have different input and output
Specifically, we test this approach by transferring the VGG-
spaces, and thus FTL requires fewer training samples and
16 convolutional neural network (CNN) model [41] trained
shortens the training process [8]–[11]. Especially, with the
with ImageNet dataset [42] to CIFAR-10 dataset [43], and
showthatFL,twotypesofFTL,andFbFTLrequireuploading
The authors are with the Department of Electrical Engineering and
Computer Science, Syracuse University, Syracuse, NY, 13244. E-mail: 3216 Tb, 949.5 Tb, 599 Tb, and 6.6 Gb of data, respectively,
fwang26@syr.edu,mcgursoy@syr.edu,svelipas@syr.edu. untilperformanceconvergence.Withthis,wedemonstratethat
The material in this paper has been presented in part at the IEEE Global
the proposed FbFTL outperforms FL and FTL substantially
CommunicationsConference(Globecom),Dec.2022.
1Code implementation available at: https://github.com/wfwf10/Feature- by reducing the upload requirements by at least 5 orders
based-Federated-Transfer-Learning. of magnitude. We note that the ITU standard of 5G uplink
4202
yaM
51
]GL.sc[
1v41090.5042:viXra2
Table I: Notations
user experienced data rate is only 50 Mb/s [44], and even
the 6G uplink user experienced data rate at Gbit/s level may FLParameters: SectionII-A
not sufficiently support such huge uploading requirements U,U Setofclients,Numberofclients
of regular FL. Additionally, to our best knowledge, existing Ku Setoflocaltrainingsamplesatclientu
works on improving FL efficiency (such as FedAvg [4],
Ku Numberoflocaltrainingsamplesatclientu
su,k Thekthsampleatclientu
sparsification [45], [46] and quantization [47], [48] with or xu,k Inputvectorofsu,k withN0 attributes
without error feedback [49], [50], federated distillation [51]– y u,k Outputvectorofsu,k withN attributes(orclasses)
[53], pruning [54], [55] or partially trainable network [56],
f θθθ(x) DNNthatmapstheinputxtoestimatedoutputˆy
θθθ TrainableparametervectorofDNN
[57],andover-the-aircomputation[58]–[60])stillconsiderthe
L(f θθθ|su,k) Lossfunction
transmission of gradient updates and can achieve a relatively g Sumofupdates(orgradients)atclientu
u
limited reduction in payload and experience degradation in α Learningrate
I Numberofcommunicationiterationsduringtrainingprocess
performance. For instance, the payload reduction is of only
(superscriptindicatesmethods)
two orders of magnitude of the original payload on the same C Fractionofclientsselectedineachiteration
CIFAR-10dataset[61],[62].Therefore,FbFTLisstillamore FTLParameters: SectionII-B,III-A,III-B
effective approach in reducing the uplink payload even after M′ Numberoflayerswithouttrainableparameters
M Numberoflayerswithtrainableparameters
theefficiencyofFLhasbeenimprovedviatheaforementioned
mc Index of the layer partitioning DNN into feature extraction
methods. We further show that FbFTL has substantially lower partandtask-specificpart
downlink payload, and requires significantly less computa- f1 Featureextractionsub-modelwithtrainableparametersθθθ1
θθθ1
tional power from the edge devices, and therefore it is much f θθθ2 2 Task-specificsub-modelwithtrainableparametersθθθ2
more friendly in terms of facilitating the training tasks on
zu,k Extractedfeaturesf θθθ1 1(xu,k)
clients with limited power budget.
Tm Numberoftrainableparametersinthemthtrainablelayer
Nm− Numberofinputnodesatthemthtrainablelayer
To validate our approach, wefurther analyze the robustness Nm+ Numberofoutputnodesatthemthtrainablelayer
of FbFTL against FL and FTL. We show significant reduction PerformanceMeasurements: SectionII-A,III-B,,III-C
onpacketlossrate(PLR)withFbFTLwiththesameblockloss d Payloadofeachfloatnumberinbits
P Uplinkpayload(superscriptindicatesmethods)
rate (BLR), and demonstrate the robustness of FbFTL with
D Downlinkpayload(superscriptindicatesmethods)
insufficient training data. While there have been numerous O(X) Computationtimecomplexityfortraining
studies on gradient quantization and sparsification to reduce RobustnessMeasurements: SectionIV
the uplink payload [63], [64], we illustrate that FbFTL also PLR Packetlossrate
BLR Blocklossrate
achieves significant compression rate by quantization while
n b Numberofblocksineachpacket
the validation accuracy is barely affected. Furthermore, we nr Maximumnumberofpacketretransmissionallowed
analyzetheprivacyleakagetoapotentialadversary.Wedefine Sr(·) Sparsificationfunctionkeepingaratioroftheinputelements
the label privacy leakage and feature privacy leakage for
Qq(·) Quantizationfunctionkeepingq bitsoftheinputelements
mu,t Localmemoryvectorforerrorfeedback
bothfeature-basedandgradient-basedframeworks.Toourbest
PrivacyMeasurements: SectionV
knowledge, this is the first work that divides the privacy into H(·) Entropytoquantifytheuncertainty
differentcategories,defineseachtype,andproposesmitigation N Outputdimension(ornumberoflabels)
B Setofpossiblebatches
approaches.Viaexperimentalresults,weshowthatFbFTLhas
|B| Numberofpossiblebatches
betterperformance(e.g.,classificationaccuracy)withthesame
B Unknownbatchtypeofclientuasarandomvariable
level of privacy protection when each client obtains a small Py Distributionoverlabels
set of samples. Py,uni Uniformlabeldistribution
ny Countofoutputlabeltypeainabatchoftypeb
Insummary,ourmaincontributioncanbelistedasfollows: a,b
P Adversary’s presumed probability distribution of batches
B|uni
• We propose the FbFTL scheme that uploads extracted withoutpriorknowledge
features instead of gradients to reduce uplink payload by H(B |Py,uni) Adversary’s uncertainty of a batch without prior knowledge
ofthecontent
five orders of magnitude.
Py,true Truelabeldistribution
• We analyze the robustness of FbFTL, and demonstrate P Adversary’s presumed probability distribution of batches
B|true
that it maintains the payload advantage when strategies giventhetruesampledistribution
suchassparsification,quantizationanderrorfeedbackare H{B |Py,true} Adversary’s uncertainty of a batch given the true sample
deployed. Ll d Li as btr ei lbu Pt ri io vn acP yy L,t eru ae kagewithStatisticalInformation
s
• Westudytheprivacyguaranteesintermsofentropybased c(b) Countforbatchesofdifferenttypesamongshuffledbatches
formulations that quantify the uncertainty and also by CU Numberofeachbatchtypebinshuffledbatchesasasetof
randomvariables
utilizing differential privacy mechanisms.
PB,emp Adversary’spresumedempiricaldistributionofbatchesgiven
• We show that a small batch size is preferred to protect shuffledbatchesCU =cU =[c(1),c(2),...,c(|B|)]
label privacy of shuffled batches, and FbFTL has better H(B|CU =cU) Adversary’suncertaintyofabatchgivenshuffledbatchesCU
performance (such as in terms of accuracy) given the Ll q LabelPrivacyLeakagewithQuery
differentialprivacyconstraintforinputprivacyinasmall Ll t TotalLabelPrivacyLeakage
n AdditiveindependentGaussiannoisetoprotectlocalinstance
batch. privacy,wheren∼N(0,σ2R2std2(g(d1))I)
d Trainingsamplesforonebatch
g(d) Uploadingvectorinonebatch
B. Organization and Notations (ϵ,δ) Differentialprivacylevel
R Maximumrelativedistance
The remainder of the paper is organized as follows. In
Additionally: f in subscript (⋆ f) denotes transfer learning updating full
Section II, we discuss the preliminary concepts regarding model, and c in subscript (⋆c) denotes transfer learning
updatingtask-specificsub-model3
FL and FTL, describe the system design via FedAvg, and 6) Return to step 2) until convergence.
demonstrate their uplink payload. In Section III, we intro- Let us assume that the number of iterations in FL with
duce the proposed FbFTL algorithm, introduce the learning FedAvg is IFL (in the absence of any processing and trans-
structureandsystemdesign,andcompareitspayloadwithFL mission failures). This implies that the total number of times
and FTL. In this section, we also evaluate the performance the clients upload g is IFLUC within the training process.
u
of FbFTL via simulations, and provide comparisons with AssumefurtherthattheDNNincludesM layerswithtrainable
FL and FTL. In Section IV, we illustrate the robustness of parameters (such as convolutional layer and fully connected
FbFTL in the presence of packet loss, data insufficiency, and layer, i.e., dense layer) and M′ layers without trainable pa-
quantization.InSectionV,wedefinethelabelprivacyleakage rameters (such as pooling layer and residue connection). The
and the feature privacy leakage. For label privacy, we discuss mth trainable layer has T trainable parameters. Thus, for
m
the leakage with statistical information and the leakage with each trainable parameter, the client uploads one float number
query, and investigate mitigation approaches to avoid these ofdbitsforthecorrespondingelementintheupdateg during
u
privacy leakages. For feature privacy leakage, we illustrate each iteration. Therefore, the overall uplink payload to train a
the mitigation approach via differential privacy. Finally, we DNN via FL with FedAvg is
conclude the paper in Section VI. The list of all notations in
M
the paper is provided in Table I as a quick reference. (cid:88)
PFL =dIFLUC T bits, (2)
m
II. PRELIMINARIES m=1
and we will set this as a benchmark to compare with three
Inthissection,weintroducepreliminaryconceptsrelatedto
other training methods in the remainder of this paper.
FLandFTL,andanalyzetherequirementsontheirsuccessful
uplink payload.
B. Federated Transfer Learning
A. Federated Learning
TL is an effective learning technique that utilizes knowl-
We address a common FL task in which a PS coordinates a edge from a different domain to enhance the performance in
set U of U clients to cooperatively train a DNN model. Each the target domain. FTL incorporates the privacy-preserving
client u possesses a local dataset K u with K u samples for distributed learning paradigm into conventional TL in order
training.Inthisdataset,thekthsamples u,k ∈K uiscomprised to address the challenges of spectrum limitations in wireless
ofaninputvectorx u,k ∈RN0 andanoutputvectory u,k ∈RN. applications and training data scarcity. In this paper, we
The DNN, represented by the function f θθθ(x), maps the input consider FTL to be performed in the same fashion as in
xtoanoutputˆy(asanestimateofy)withtrainableparameter the previous subsection, where one PS orchestrates U clients.
vectorθθθ. The goal of the FL training process is to update the Based on the difference between the domains, FTL can be
parametervectorθθθ usingthetrainingsamplesfromeachclient divided into three different categories: instance-based FTL,
in order to minimize the expected loss E(L(f θθθ|s test)) on the feature-basedFTL,andmodel-basedFTL[6],[65].Theformer
unseen sample s test with the same distribution as the training two types of FTL assume similarity in the distribution of
samples. For most DNNs with classification tasks, the output the input and output, and hence we in this paper focus on
label y is an axis-aligned unit vector with one element equal the model-based FTL which only assumes similarity in the
to 1 indicating the class of this sample, and all others equal functionality to extract a high-dimensional description from
to 0. In this case, the loss function is typically the categorical the input data.
cross-entropy:
N
(cid:88) Parameter Server Client
L(f |s )=− yyy [n]logf (xxx )[n]. (1)
θθθ u,k u,k θθθ u,k Input Input Input
n=1 Layer 1 Copy Layer 1 Broadcast updated parameters Layer 1
In order to minimize the loss and keep the training samples E Fext ar ta uc rt e s Layer 2 Copy Layer 2 Layer 2 F paix r a/ mup ed tea rt se
local, the authors in [4] proposed an iterative distributed Iterative communication
Layer 3 Copy Layer 3 during training process Layer 3
optimization scheme called FedAvg with the following steps:
1) The PS initiates trainable parameters θθθ, and broadcasts Task- Layer 4 R ina itin ad teomly Layer 4 Upload parameter updates Layer 4 Update
the model structure f with non-trainable parameters to specific Layer 5 R ina itin ad teomly Layer 5 Layer 5 parameters
each client. Output Output Output
2) ThePSchoosesasubsetofUC clients(withC denoting Pre-tra min oe dd e s lource Ne mw o t da erg let Ne mw o t da erg let
thefractionofclientsinthisiteration)andbroadcaststhe Figure 1: Diagram of the iterative training process of model-
trainable parameters θθθ. based federated transfer learning.
3) Each client performs stochastic gradient descent (SGD)
to obtain the parameter update corresponding to each As shown in Fig. 1, we consider FTL with a DNN model
training sample: ∇ θθθL(f θθθ|s u,k). pre-trained with an open-source dataset that corresponds to
4) Each client sends the sum of the updates over all local a similar but not the same task as the source model. The
samples g u
=(cid:80)K
k=u 1∇ θθθL(f θθθ|s u,k) and K u to the PS. goalhereistoreducethenumberofiterationsduringtraining.
5) The PS updates the parameter θθθ with θθθ−(cid:80)U α g ManyDNNscanbepartitionedintotwosections.Thefirstsec-
u=1 Ku u
where α is the learning rate that controls the training tion generates the high-dimensional features from the sample
speed. inputdatawithgeneralinformation.Thesecondsectioncarries4
out operations for a particular task, such as classification, and should be altered less when new data is encountered. In this
is less likely to be transferable to a new task. To move the paper,weconsideradifferentproblem,wherewetransfertoa
knowledgeofthesourcemodelintoanewtaskbeforetraining, single target task from a single source model on another task
the feature extraction section of the source model is directly whose performance is no longer considered. In this problem
transferredtothenewtargetmodel,whilethetask-specificpart setting, there is no clear difference between EWC and plain
is randomly initiated. FTL can be performed by retraining all SGD in [66] in terms of both training performance or training
the parameters with new data. However, there typically exist time, but EWC does introduce extra communication payload
a large number of parameters to train, and in order to reduce and computation cost in FL. On the contrary, FbFTL achieves
the training time and data requirements, a common approach five orders of magnitude payload reduction.
is to perform FTL by fixing the feature extraction part and Split federated learning (SFL) [67] partitions the neural
simply updating the task-specific part. In particular, we select network into two segments: the initial part near the input
one fully connected layer m (which is Layer 4 in Fig. 1), undergoestraininginafederatedlearningmannerusinga“Fed
c
close to the output without a paralleling path (such as residue Server”, and the subsequent part near the output is trained
connection), and randomly initiate all trainable parameters of using split learning with a “Main Server,” which receives the
layers m ,m +1,...,M (which are Layer 4 and Layer 5 smashed data. Compared to FbFTL, the federated learning
c c
in Fig. 1). During the distributed training process, all copied segment utilizing the Fed Server operates in the same way
parameters are fixed, and we only update the parameters of as FL and requires significant uplink and downlink payload.
layers m ,...,M. Hence,thispartaloneistypicallymuchmorecommunication-
c
Similartotheprevioussub-sectiononFL,wedeterminethe expensive compared to FbFTL. The advantage of SFL lies
least requirements on successful uplink payload for FTL until in its similar performance to FL and not needing a pre-
convergence. For FTL that updates all parameters, assuming trainedmodelasitupdatesallparameters.Wewillpresentthe
that FTL with FedAvg is iterated IFTL times, the overall experimental performance comparison in Table III in Section
f
uplink payload required for training is III-D.
Personalizedfederatedlearning(PFL)[68]considersclients
M
PFTL =dIFTLUC (cid:88) T bits. (3) with large number of heterogeneous local samples, enabling
f f m generalization to the heterogeneous local distribution. How-
m=1
ever, we in this paper consider a large number of clients with
On the other hand, assuming FTL with FedAvg that only up-
asmallsetoflocalsamplesfromeach.AsexplainedinSection
datesthetask-specificpartwithIFTL iterationsandassuming
c V-A and Section V-C, such a setting better protects label
that each sum update g consists of
(cid:80)M
T trainable
u m=mc m privacy. Therefore, personalized federated learning focuses
parameters, the overall uplink payload for training is
on a different problem from ours. We cannot apply this
M approach to FbFTL because personalized FbFTL violates the
(cid:88)
PFTL =dIFTLUC T bits. (4) shuffle-batch assumption, unless we train the global model
c c m
m=mc by FbFTL and then retrain locally. Although PFL has better
local performance than FL with large heterogeneous batches,
Typically, training from scratch requires more training sam-
ples, and thus we have IFTLUC ≈ IFTLUC < IFLUC. it requires several independent local batches and significantly
c f more local computation. Furthermore, it does not allow quan-
For most of the models, the majority of the DNN struc-
tization and sparsification since the weights instead of gra-
ture is dedicated to the feature extraction, and obviously
(cid:80)M
T
<(cid:80)M
T . Therefore,
dients are uploaded. Therefore, it is comparatively even less
m=mc m m=1 m communication-efficient when quantization and sparsification
PFTL <PFTL <PFL. (5) are deployed in other methods, as shown in Section IV-C and
c f
Table V.
C. Other Recent Transfer and Federated Learning Schemes
III. FEATURE-BASEDFEDERATEDTRANSFERLEARNING
WhileweinthispaperfocusonFLschemesthatgeneralize
Inthissection,wedescribetheproposedFbFTLframework
to the majority of use cases, there are also recent works that
and demonstrate that it requires a substantially smaller uplink
improve the performance under certain assumptions and can
payload compared to FL and FTL. This efficiency arises from
be used in FL. We list these well-known methods, along with
the fact that the extracted features and outputs are uploaded
FL, FTL, and the proposed FbFTL, in Table II and provide a
rather than the parameter updates.
comparison. Below, we briefly describe the key assumptions
ofthesemethods,andhighlightthedifferencesoftheproposed
A. Learning Structure
FbFTL scheme.
Specifically, elastic weight consolidation (EWC) [66] fo- As depicted in Fig. 2, in FbFTL we consider the model-
cuses on a large number of different tasks simultaneously and based TL on a source DNN model f′ pre-trained on a
the transfer between them by remembering the importance differenttask.Wechooseonefullyconnectedlayerm without
c
of each weight. The performance is typically measured on paralleling path as the cut layer, and divide the new target
all experienced tasks. EWC is inspired by neuroscience and model f ← f′ into two parts. Those layers before layer m
c
Bayesian inference, and it aims to quantify the importance of (which is layer 4 in Fig. 2, i.e., m = 4 ) are regarded as
c
each weight to the tasks the model has previously learned. the feature extraction sub-model f1 , and the parameters θθθ1
θθθ1
Thefundamentalideaisthattheweightscriticaltopriortasks for the new target model f are copied from the pre-trained5
Method Payload Computation Key Assumption
FL iterative gradient-level medium, distributed start with random initialization
FTL iterative gradient-level low, distributed start with source model
FbFTL (ours) one-time feature-level low, mostly centralized start with source model
EWC [66] iterative gradient-level high, distributed evaluating many different tasks
SFL [67] iterative gradient-level medium, hybrid of distributed and centralized two servers needed
PFL [68] iterative gradient-level very high, distributed large and heterogeneous local batch
Table II: Comparison between different federated learning methods
samples are not correlated with the model parameters θθθ2,
Parameter Server Client and therefore they can be used in different training iterations
Input Input Input withoutdownloadingoruploadinganythingagain.Weprovide
Layer 1 Copy Layer 1 Layer 1 the steps of the FbFTL algorithm in Algorithm 1 below.
E Fext ar ta uc rt e s Layer 2 Copy Layer 2 Broadcast fixed parameters Layer 2
Layer 3 Copy Layer 3 One-time communication Layer 3 Algorithm 1 FbFTL
Upload output and
T sa ps ek c- ific L La ay ye er r 4 5 R i R in na ai it tin ina ad dt te eo om ml ly y F te aa rI gtn u ete r tO e r sm u e ute p x bd u t -ri mta at c oe t d io en l intermediate output F te aa rgI tn u et r te O e r s m u e ut xe bp td u -r mi t aa c ote t di o en l mPS odc eo lp ai ne ds rfi ax ne dd oms lu yb- inm ito id ate el sf trθθθ1 a1 inf ar bo lm e sup bre -- mtr oa din ee ld f θθθ2s 2o .urce
Output PS broadcasts f1 to each client u∈U
Pre-trained θθθ1
source model Clients execute:
for client u∈U do
Inte Orm ute pd ui tate Inte Orm ute pd ui tate Inte Orm ute pd ui tate for sample s
u,k
∈K
u
do
Update Update Upload z =f1 (x ) and y to PS
Layer 4 Layer 4 Layer 4 u,k θθθ1 u,k u,k
Layer 5 Update Layer 5 Update Layer 5 end for
end for
Output Output Output
PS executes:
Iterative training process of
task-specific target sub-model
while not converge do
Figure 2: Diagram of the training process of feature-based for mini-batch b of pairs {u,k}∈U ×K u do
federated transfer learning, which reduces to one-time com- θθθ2 ←θθθ2−α(cid:80) {u,k}∈b∇ θθθ2L(f θθθ2|z u,k,y u,k)
munication of the output and the intermediate output (i.e., end for
extracted features). end while
As emphasized above, a key distinction of FbFTL is that
source model f′ and fixed without any further update. The the training samples of task-specific sub-model are uploaded
other layers are regarded as the task-specific sub-model f2 , rather than the direct gradient updates. With this, FbFTL
θθθ2
and all trainable parametersθθθ2 in the new target model f are provides additional important benefits that can lead to fur-
randomlyinitiatedfortrainingwiththeuthclient’skthtraining ther improvements in the training performance and efficient
sample s ={x ,y } for all u and k. management in practice. One of the most important benefits
u,k u,k u,k
The forward pass of the full model f (x ) = is the significant reduction of packet loss rate given the same
θθθ u,k
f2 (f1 (x )) maps the input x to the estimated output batch loss rate since FbFTL has much less data in each batch,
θθθ2 θθθ1 u,k u,k
ˆy , and we note that the output of the feature extraction as we will illustrate in detail in Section IV-A. One other
u,k
sub-model z = f1 (x ) is also the input of the task- benefit is the waiving of the requirement of synchronization
u,k θθθ1 u,k
specific sub-model f2 . Note that we require only the task- betweenclients,sincethereisonlyoneiterationinFbFTL.The
θθθ2
specific sub-model to be trained. In this setting, each client other benefits pertain to hyper-parameter fine-tuning, dataset
generates the features z from input x and sends these balancing, and enabling flexible training batch size selection,
u,k u,k
features to the PS only once. Subsequently, in FbFTL, the as detailed below.
PS performs the gradient back-propagation iteratively without Specifically, one of the most important additional benefit is
sendinganyfeedbacktotheclients.Contrarytothis,inFLand thatFbFTLenablesiterativefine-tuningoftheSGDoptimizer
FTL, the parameter update, which is based on the gradients, hyper-parameters such as the learning rate. To obtain the
highlyreliesontheparametersinthecurrenttrainingiteration, optimized DNN, one needs to find the optimized hyper-
and the same data sample may generate different parameter parameters that provide the best convergence performance. In
updates in different iterations within the training process. FbFTL, the model can be trained from scratch several times
Therefore, in FL and FTL, we either require many more at the PS to identify the best hyper-parameter setting without
training samples, or need to upload updates multiple times additional communication with the clients. On the other hand,
for the same sample. However in FbFTL, each client only in FL and FTL, the entire online training process has to be
needs to upload the intermediate output z and output y run several times, resulting in a much higher cost compared
u,k u,k
once, instead of iteratively uploading the gradients. The PS to the ideal uplink payload P.
may deem these as the input and the output of the training Another benefit of FbFTL is the dataset balancing. If the
sample for the task-specific sub-model f2 . Such pairs of overall dataset is imbalanced and hence the samples with
θθθ26
certain types of output appears much more frequently than of each upload for single sample between FTL and FbFTL is
those of other outputs, it is hard for FL and FTL to dis-
tinguish this via gradient updates, and such imbalanced data
d(cid:80)M
m=mcT m
=
T mc
+(cid:80)M
m=mc+1T m
distribution could significantly degrade FL performance [69], dN− N−
mc mc
[70]. However, FbFTL with direct output information enables N+ (N− +1)+(cid:80)M T (7)
techniques, such as re-sampling specific classes or merging = mc mc m=mc+1 m
near-identical classes, to improve dataset imbalance. N m−
c
>N+ .
One more benefit of FbFTL is to lift the constraint of UC mc
and K u on the training batch size. To avoid over-fitting to Therefore,
the training dataset, one needs to validate the performance
on a separate validation set of data to identify the optimal P cFTL = dI
cFTLUC(cid:80)M
m=mcT m > I cFTLUC N+ . (8)
number of training iterations to stop training and conclude PFbFTL d(cid:80)U K N− (cid:80)U K mc
the final model. It is straightforward for FbFTL to divide the u=1 u mc u=1 u
The number of extracted features for many state-of-the-art
obtaineddatasetintotrainingandvalidationsubsets.However,
modelsislargerthan103,andTLusuallyrequiresarelatively
the gradient-based FL frameworks call for extra effort for the
deeper task-specific sub-model, and therefore N+ can be
communication system to meticulously perform the training mc
large. For the cross-device federated learning, the clients do
process and validation process with the desired order and
number of samples. Additionally for the training process, due not obtain huge local datasets, (cid:80)U u=1K u <I cFTLUC. There-
to the broadcast nature of the downlink in wireless FL and fore, we have PFbFTL ≪ P cFTL. We note that FbFTL and
FTL, all selected clients in the same communication iteration FTL that updates the task-specific sub-model have the same
receive the same parameters. Hence, each SGD mini-batch performance at every iteration because the only difference
has a larger size than (cid:80)UC K , and an overwhelmingly between the two methods is the communication model but
u=1 u
not the numerical process to generate the gradient updates.
large SGD mini-batch size may delay the training process
Combining this observation with the conclusion in (5), we
and require more training iterations. The mini-batches in
have
these gradient-based FL frameworks are also on the order of
PFbFTL ≪PFTL <PFTL <PFL, (9)
given clients’ samples. Therefore, when the clients’ sample c f
distribution is biased, we cannot shuffle the samples between
and therefore we expect extremely smaller uplink payload in
iterationsandhavetoacceptthelossinthefinalperformance.
FbFTL compared to FTL and FL.
However, FbFTL may choose any rational size of SGD mini-
We also note that FbFTL has the smallest downlink broad-
batch without the constraints of the communication system,
cast payload and the least local computation compared to FL
and can reshuffle the data in each training iteration.
and FTL. For FL, FTL that updates all parameters, FTL that
updates the task-specific sub-model, and FbFTL, the overall
downlink broadcast payloads, respectively, are
M
(cid:88)
DFL =dIFL T bits, (10)
m
B. Payload Analysis m=1
M
(cid:88)
DFTL =dIFTL T bits, (11)
NotethatFbFTLhasthemajorbenefitofrequiringone-time f f m
communication between the clients and the PS. In addition m=1
to this, FbFTL has much less data in a single upload batch M
(cid:88)
compared to that of each sample in the upload batch of FL D cFTL =dI cFTL T m bits, (12)
and FTL. Let us assume that in the fully connected layer m=1
m
of
ow ui tt ph utbi na os, det she arn eu dm eb ne or teo df bi ynp Nut −no ad ne ds Nan +d
,
t rh ee spen cu tm ivb ele yr
DFbFTL
=dm (cid:88)c−1
T bits. (13)
m m m
Then, the number of trainable parameters in this layer is
m=1
given by T = N+(N− +1). Compared to the dimension
m m m
of N m− c, the amount of information that we need to represent C. Time Complexity Analysis
y ∈{1,...,N},i.e.,log N bits,isnegligible.Notethatin
u,k 2 We note that FbFTL consumes less computation time and
FbFTL, gradients are computed at the PS. Therefore, FedAvg
power for training in total, and also transfers a proportion of
cannot be applied and each sample is required to be uploaded
computationfromtheclientdevicestothePS.InFLandFTL,
separately. Therefore for FbFTL, the uplink payload for each
eachclientmustcompleteonefullforwardpassandoneback-
sample is dN− , and the overall successful uplink payload
mc propagation of the parameters to be trained for each training
required for training is
sample at each iteration. However, in FbFTL, each sample is
(cid:88)U only processed once by the client, and each client only needs
PFbFTL =d K uN m−
c
bits. (6) to complete the forward pass of feature extraction sub-model,
u=1 while all other computations are completed at the PS. Such
Comparedtotheuplinkpayloadin(4)ofFTLwithFedAvg(in shift of computational load to the PS is particularly beneficial
which only the task-specific sub-model is updated), the ratio if the end users and devices are severely limited in their7
computational capabilities and power resources (for instance,
in IoT networks) and the PS is equipped with advanced
processors and has access to more resources.
In this subsection, we use time complexity to estimate the
computation time and energy consumption. For each fully
connected layer m with N− input nodes and N+ output
nodes, there are T 1 =N+m (N1 − +1) trainable pam r1 ameters,
and each sample rem q1 uires Om (1 N+m (1 N− +1))=O(T ) time
m1 m1 m1 Figure 3: ImageNet samples with labels.
complexity for matrix multiplication during forward pass, and
the same time complexity for matrix multiplication during
back-propagation.Each2-dimensionalconvolutionallayerm
2
with stride 1 in each direction and same padding has the
input shape {a−,b−,c−} where N− = a−b−c−, kernel
shape {c+,a′,b′,c−} where T
=m2
c+(a′b′c− + 1), and
m2
outputshape{a−,b−,c+}whereN+ =a−b−c+.Thus,each
samplerequiresO(c+(a′b′c−+1)a−m b2−)=O(a−b−T
)time
m2
complexity for matrix multiplication during forward pass, and
the same during back-propagation. Comparatively, the time
complexity of activation functions, max-pooling layers and Figure 4: CIFAR-10 samples with labels.
dropout layers is negligible. Therefore, we denote the time
complexity of each trainable layer m for a single training
sample as O(X ), and the overall time complexity required Note that these samples have simple labels and appear more
m
for all clients as O(X). Specifically, the overall time com- blurred compared to those in ImageNet due to their lower
plexities at clients for the methods of FL, FTL that updates resolution/dimension.
all parameters, FTL that updates the task-specific sub-model, In Fig. 5, we depict the structure of VGG-16 used for
and FbFTL, respectively, are trainingonCIFAR-10.ForTL,weconsiderthefirsthalfofthe
(cid:32) M (cid:33) layersmarkedblueasthefeatureextractionsub-modelf θθθ1 1 and
O(XFL)∝O 2IFLUC (cid:88) X , (14) directlytransferthissub-modelfromthattrainedonImageNet.
m
We deem the latter part marked yellow as the task-specific
m=1
sub-modelf2 andrandomlyinitiatethispart.ForFbFTL,the
(cid:32) (cid:88)M (cid:33) dimension oθθθ f2 the intermediate output is N− =4096.
O(XFTL)∝O 2IFTLUC X , (15) mc
f f m TotrainthemodelonCIFAR-10,weutilizeNvidiaGeForce
m=1 GPUwithCUDAtorunthealgorithmswithPyTorch[72].We
(cid:32) m (cid:88)c−1 (cid:88)M (cid:33) assume that there are U =6250 clients in total, each iteration
O(X cFTL)=O U X m+2I cFTLUC X m , takes a fraction C = 1.28 × 10−3 of all clients, and each
m=1 m=mc
(16)
(cid:32) m (cid:88)c−1 (cid:33)
O(XFbFTL)∝O U X m , (17) Input
m=1
Conv 3 - 64 Conv 3 - 512
where ∝ stands for “proportional to”. Typically, we have
Conv 3 - 64 Conv 3 - 512
XFbFTL <XFTL ≪XFTL <XFL.
c f Max-pooling Conv 3 - 512
Max-pooling
Conv 3 - 128
D. Experimental Results
Conv 3 - 128 FC 4096
In this section, we consider the application of FL, FTL Max-pooling FC 4096
and FbFTL to the VGG-16 CNN model [41] and transfer the
knowledge learned from ImageNet dataset [42] to CIFAR-10 Conv 3 - 256 FC 4096
Conv 3 - 256 FC 512
dataset [43].
Conv 3 - 256 FC 10
ImageNet is a vast online database containing over 14
Max-pooling
million images, each with hand-annotated labels describing
Output
the classification types or intended outputs for training. The Conv 3 - 512
pre-trained source model we use for TL was created on the Conv 3 - 512
2012 ImageNet Large Scale Visual Recognition Challenge Conv 3 - 512
(ILSVRC2012, [71]), and the images come from 1000 dif- Max-pooling
ferent categories. As an illustration, we provide 10 samples
with their labels in Fig. 3.
Figure 5: Diagram of the VGG-16 model for training on
CIFAR-10 is a database of 60000 images, each with one
CIFAR-10 dataset. “Conv {receptive field size} - {number
of N = 10 distinct labels. Out of these images, 50000
of output channels}” depicts the convolutional layers. “FC
images are used for training and 10000 images for testing.
{output size}” depicts the fully connected layers.
Fig. 4 showcases the first ten samples with their labels.8
batch contains K = 8 samples. In the two most commonly Furthermore, we note that in transfer learning, there is an
u
used deep learning tools TensorFlow (including Keras) [73] additional trade-off between privacy protection, performance
and PyTorch, the default data type of each number has 32 and payload. When partitioning a model into feature extrac-
bits and therefore d = 32 bits. The learning rate is 10−2, tion sub-model and task-specific sub-model, choosing the cut
the momentum of the optimizer is 0.9, and the L2 penalty is layer closer to the output better preserves data privacy, while
5×10−4. picking a cut layer closer to the input improves the training
performance.Inordertodemonstratesuchatrade-off,wenext
In Table III, we compare the performances of FL, SFL, consider a language model as our application scenario. In FL,
FTL updating the full model (FTL f), FTL updating the task- FTL, and FbFTL on natural language processing tasks, we
specificsub-model(FTL c),andFbFTL.Forincreasedfairness consider tasks where the model and the intermediate features
in the comparison of payloads, we further demonstrate the are not proprietary or private, and thus we assume that the
performances FLlow and FTLl fow, which are the FL and FTL f clients are willing to share them while keeping the local data
algorithms that terminate training process when the validation private As an example, we show the results on a conversation
accuracy reaches those of FTL c and FbFTL (i.e., ≈ 86%). summary task SAMSum [74] with 32128 distinct token types
As we have analyzed, the other algorithms require IUC outof14732trainingdialoguesand819testingdialogues.For
successfully uploaded batches, while FbFTL only requires instance, dialogue ID 13728867 in SAMSum is “Olivia: Who
(cid:80)U
u=1K u batches. Also, FL, SFL, FTL f and FTL c require are you voting for in this election? Oliver: Liberals as always.
uploading d(cid:80)M T bits, d(K N− +(cid:80)M T ) bits, Olivia: Me too!! Oliver: Great”, and ground truth summary is
d(cid:80)M T bim ts= ,1 anm d d(cid:80)M u Tmc bits, rm es= pm ecc tivm ely, for “OliviaandOlivierarevotingforliberalsinthiselection.”For
eachm b= a1 tchm , while FbFTL onm ly= rm ec quim res uploading dN− bits this task, we deploy a language model FLAN-T5-small [75],
for each batch. In the third row of the table, we om bc serve whichisatransformerwith110millionparameters,including
that the FbFTL algorithm significantly reduces the uplink 8 encoders and 8 decoders. This model is pre-trained and the
payload per batch by four orders of magnitude (i.e. a factor dataset is relatively small, so we do not have FL in this case.
of 10−4) compared to the other algorithms for each client. We assume that there are U =7366 clients, each has K u =2
Additionally, in the fourth row, FbFTL leads to a reduction
dialogues,andeachiterationtakesafractionC =5.43×10−4
of five orders of magnitude (i.e. a factor of 10−5) in the of all clients. Our experiment is based on HuggingFace [76]
total uplink payload during training when compared to the with learning rate 2×10−4.
other algorithms. These results demonstrate that FbFTL is In Table IV, we compare the performances of FTL and
apparently the most efficient scheme. FbFTL also results in a FbFTL in terms of ROUGE-1 score, which measures the
substantial decrease in the overall downlink payload. If larger match between the generated text and reference text. A larger
models are trained for more complex tasks or if the size of ROUGE-1 indicates better performance. We note that FTL f
the training dataset is more limited, the difference in payload trains all components including encoders, decoders, embed-
couldbeevengreater.In(14)through(17),wehavedescribed ding and the final linear layer. On the other hand, FTL c and
the overall computation time complexity required for training FbFTL freeze embedding, and may or may not freeze several
at clients as O(X). In the second-to-last row of the table, we encoders close to the input prompts. The number of trained
quantify and provide this time complexity for each method encodersisgiveninthesecondrowofTableIV.Forinstance,
by counting the number of multiplications among floating the performance results in the third and fourth columns are
numbers. We readily observe that FbFTL requires the least forFTL c andFbFTLthathavetrainedallencoders(andhence
computation time and power consumption at the clients, and havenotfrozenanyofthem),whiletheothercolumnsprovide
has two orders of magnitude reduction compared to FL, SFL the performances with 4 or 2 encoders trained (indicating that
and FTL , since it only runs the forward pass over feature 4 or 6 encoders close to the input are frozen). We do not
f
extraction sub-model for each sample one time. We further need to freeze decoders since label privacy leakage converges
note that for FbFTL, the computation complexity at the PS to zero with shuffled batches, as will be shown in Section
is also low with X = 3.00 × 1014. Furthermore, we note V. In Table IV, we observe that FbFTL reduces the uplink
that different number of clients CU in each iteration does not and downlink payload by similar orders of magnitude as in
affecttheperformanceofFbFTL,butalargenumberofclients the VGG-16 experiment. Furthermore, we notice that training
CU reduces the performance of FL and FTL, since it defines less layers or encoders leads to a slight reduction in ROUGE-
the minimum “training batch size” CUK . The performance 1 score but it does not guarantee lower payload. While FTL
u
of FL and FTL will decrease with an overwhelmingly large mayrequiremoreiterationstoarriveconvergence,FbFTLmay
training batch size, which is another benefit of FbFTL. We in need to broadcast a larger feature extraction sub-model.
the experiment pick a small CU = 8 so that the benchmark
schemes(i.e.,FL,FTL ,andFTL )havethebestperformance
f c
(atwhichpointFTL andFbFTLhavethesameperformance).
c
Moreover, we also observe that FTL and FbFTL only update
IV. ROBUSTNESSANALYSIS
c
asmallportionoftheparametersandexhibitaslightdecrease
in validation accuracy, which is the trade-off for the reduced Inthissection,wecomparetheperformanceofFbFTLwith
payload. However, we will show in Section IV and Section thatofFLandFTLunderthesamepacketlossrate(PLR)for
V that under communication efficiency or privacy constraints, each batch being uploaded, and illustrate the robustness of
FbFTL may also prevail in terms of validation accuracy in FbFTL against packet losses, data insufficiency, and compres-
certain situations. sion,includingquantization,sparsificationanderrorfeedback.9
FL SFL FLlow FTLf FTLl fow FTLc FbFTL
numberofuploadbatches 656250 656250 68750 193750 25000 525000 50000
uploadparametersperbatch 153144650 117483328 153144650 153144650 153144650 35665418 4096
uplinkpayloadperbatch 4.9Gb 3.8Gb 4.9Gb 4.9Gb 4.9Gb 1.1Gb 131Kb
totaluplinkpayloadP 3216Tb 2467Tb 337Tb 949Tb 123Tb 599Tb 6.6Gb
totaldownlinkpayloadD 402Tb 308Tb 42Tb 253Tb 15Tb 322Tb 3.8Gb
computationtimecomplexityX 1.63×1017 1.63×1017 1.7×1016 4.80×1016 6.19×1015 1.07×1015 7.74×1014
validationaccuracy 89.42% 89.42% 86.64% 93.75% 86.45% 86.51% 86.51%
TableIII:PerformancecomparisononVGG-16betweenFL,SFL,FTLupdatingfullmodel(FTL ),FTLupdatingtask-specific
f
sub-model (FTL ) and FbFTL. Additionally, we compare with cases in which FL and FTL achieve the same accuracy as
c f
FTL and FbFTL (≈ 86%) by terminating training slightly earlier. Algorithms in these cases are referred to as FLlow and
c
FTLlow.
f
FTL FTL FbFTL FTL FbFTL FTL FbFTL
f c c c
number of trained encoders 8 8 8 4 4 2 2
number of upload batches 132588 36830 7366 88392 7366 103124 7366
upload parameters per batch 109860224 60511616 1024 51070144 1024 46349504 1024
uplink payload per batch 3.5 Gb 1.9 Gb 32.7 Kb 1.6 Gb 32.7 Kb 1.5 Gb 32.7 Kb
total uplink payload P 466.1 Tb 71.3 Tb 241.4 Mb 144.5 Tb 241.4 Mb 152.9 Tb 241.4 Mb
total downlink payload D 116.0 Tb 32.2 Tb 1.58 Gb 77.3 Tb 1.88 Gb 90.2 Tb 2.03 Gb
validation ROUGE-1 45.9249 45.4680 45.4680 45.2827 45.2827 44.9862 44.9862
Table IV: Performance comparison on FLAN-T5-small between FTL updating full model, FTL updating task-specific sub-
f c
model and FbFTL, with different number of encoders trained.
A. Packet Loss retransmissions is
(cid:88)nb
P
(cid:88)nr (cid:88)nr
P(BLR)= (BLR)n =P (BLR)n. (19)
As we have demonstrated in the previous section, gradient-
n
b
based FedAvg FL frameworks including FL and FTL upload n′=1 n=0 n=0
the gradient update g
u
= (cid:80)K k=u 1∇ θθθL(f θθθ|s u,k) iteratively, We note that (cid:80)n nr =1(BLR)n is the expected number of re-
where each batch contains the gradient summation from all transmissions, which is the same for all different learn-
samplesoftheclient.Incontrast,ourproposedFbFTLuploads ing frameworks. If the transmission has a fixed bandwidth,
the data for each sample only once, and each batch contains (cid:80)nr (BLR)n also represents the delay factor of the to-
n=1
extracted features z u,k and output y u,k from one sample. tal transmission. We further note that if BLR = 0, then
FLIn is( m7) u, cw he lah ra gv ee
r
ts hh ao nw en acth ha bt ae ta cc hh fob rat Fc bh Ff To Lr g (bra ydi ae bn ot- ub ta 1s 0ed
4
P P( .B NL oR ti) ce= tP ha. tO thth eer iw nci rs ee a, sP e( iB nL tR h) e= paP yl+ oaP
d
(cid:80)
P
n n(cid:80)r =
n
n1
r
=(B 1(L BR L) Rn )>
n
larger in our experiments), and we assume that the packets to grows with P and n r. Hence, learning frameworks with
transmitbothtypesofbatchesconsistofmultipletransmission higher payload experience a higher increase in payload when
blocksofthesamesize.Forbothtypesofpackets,weconsider retransmissions are introduced.
measuring the robustness of all frameworks against packet
loss caused by block losses due to network congestion or link
outage (e.g., as a result of deep fading in wireless networks).
For each learning framework whose packet consists of n b B. Data Insufficiency
transmission blocks, we consider the same block loss rate
(BLR). The PLR without retransmission is
At the end of Section III-A, we have discussed the ben-
PLR=1−(1−BLR)nb. (18) efit that FbFTL does not require additional online uploads
from the clients to test different sets of hyper-parameters,
Obviously,PLRhighlydependsonthevalueofn .FbFTLhas
b while gradient-based frameworks need to run the entire up-
significantly lower packet size and consequently we expect
loading process multiple times. In practice, in addition to
much lower PLR for the given same BLR. We show the
hyper-parameters, another intangible aspect prior to training
significant performance difference among different learning
is whether there exists a sufficient number of participating
frameworks in our experiments at the end of this section.
clients and training samples. If the planned set of samples
If, on the other hand, we allow at most n retransmis- is insufficient to train the neural network, gradient-based
r
sions for all packets and assume the channel state of each frameworks require rerunning the overall process with more
transmission to be independent and identically distributed clients, which leads to high consumption and potential waste
(i.i.d.), we can lower the PLR and achieve similar packet- of both computational and transmission resources. However,
level reliability. However, this is realized at the cost of higher FbFTL only requires the new clients to compute and upload
totaluplinkpayload.Specificallyforeachlearningframework their batches, and hence there is no waste of transmission
requiring uplink payload P, the expected uplink payload with resources.10
C. Quantization, Sparsification and Error Feedback D. Experimental Results
To further reduce the uplink payload of gradient-based In this section, we numerically demonstrate the aforemen-
frameworks, there have been extensive works on gradient tioned robustness metrics in our experiments with the VGG-
compression, including gradient sparsification [77], [78] and 16 CNN model on transfer learning from ImageNet dataset to
gradient quantization [63], [64], especially signSGD, the ex- CIFAR-10 dataset.
treme case in which each element is reduced to be binary In Fig. 6, we show the PLR (without retransmissions) of
valuedwithoutscaling[79].Severalrecentstudiesutilizeerror different learning frameworks when the block size equals the
feedback(orquantizationandsparsificationwithmemory)that batchsizeofFbFTL(i.e.,theBLRequalsthePLRofFbFTL).
reduces the error in compression at client’s local device to As we have shown in the row of uplink payload per batch
improve the updates in future iterations [49], [50]. of Table III, the batch sizes of other learning frameworks
are about 104 times larger than that of FbFTL. Due to the
For gradient-based frameworks utilizing gradient update g
u huge difference in the batch sizes, the PLR curves of the
with X elements, we denote the sparsification function as
g
S r(·):RXg →RXg,wherer ∈(0,1].Thisfunctionkeepsthe other learning frameworks almost reach 1 when the PLR of
FbFTLislessthan0.001(orequivalentlywhenBLR<0.001).
value of rX elements in the vector with the highest absolute
g
The difference is still substantially high if a few rounds of
values,andsetthevalueofallotherelementsto0.Wedenote
the quantization function as Q q(·) : RXg → RXg where q ∈ retransmissions are allowed in gradient-based frameworks.
Z+, and this function quantizes each element in the vector to Fig. 7 provides the magnified plot of Fig. 6 for BLR<0.001,
and we note that the curve of FL and the curve of FTL that
q bits within the max/min range. Furthermore, we denote the
errormemoryvectorforclientuatiterationtasm
u,t
∼RXg. updates full model overlap since they have the same number
of parameters to update and therefore have the same batch
Therefore, the process of quantization and sparsification with
size. In this figure, we again observe that the PLR curves of
error feedback at iteration t is described as follows:
learning mechanisms other than FbFTL quickly approach 1
g′
u
=Q q(S r(g u+m u,t)), (20) within the considered range of BLR <0.001, while the PLR
of FbFTL (being equal to BLR) stays below 0.001.
m =g +m −g′, (21)
u,t+1 u u,t u
where g′ is uploaded to the PS, and the local error memory
u
vector is updated to m . For initialization, m =0.
u,t+1 u,1
Similarly, for FbFTL utilizing extracted feature z with
u,k
X elements, we may also apply sparsification and quantiza-
z
tion. However, error feedback is not applicable, because there
isonlyoneuploaditerationinFbFTL,andtheextractedfeature
is not additive unlike the gradient. Therefore, the process
of quantization and sparsification for FbFTL is described as
Figure 6: Comparison Figure 7: Magnification of
follows:
z′ =Q (S (z )), (22) of PLR (without Fig. 6 for BLR<0.1%.
u,k q r u,k retransmission) among FL,
where z′ is uploaded to the PS. FTL updating full model,
u,k
Inbothcases,thecompressionrateiscloseto2d/q/r where FTL updating task-specific
d is the number of bits for the representation of the original sub-model, and FbFTL.
datatype.Wenotethatthereisalsoapotentialdrawbackinthe
practical deployment of sparsification and error feedback. On Since FbFTL has significantly lower PLR, we subsequently
the one hand, while all other operations including training, analyze its performance with different amount of data. In Fig.
communication, inference, quantization and error feedback 8, we see that FbFTL has relatively high validation accuracy
have time complexity no more than O(X′) where X′ is the even with only 10% of the samples. Indeed, when we have
total number of parameters in the neural network, we notice only 0.1% of the samples (i.e., the case with 50 samples),
that depending on the sparsification ratio r, sparsification the accuracy is 82.5% even with PLR=0.5. Furthermore, we
requires up to O(X logX ) time complexity for gradient- observe that as PLR increases, the accuracy curves remain
g g
based frameworks and O(X logX ) time complexity for relatively flat, and experience sharp drops only when PLR
z z
FbFTL. Typically, we have O(X ) ≪ O(X ) = O(X′), and approaches1.Therefore,FbFTLisconsiderablyrobustagainst
z g
FbFTLcanachievemoresignificanttimecomplexityreduction data insufficiency and PLR. We note that such robustness
inlocalsparsificationcomputationcomparedtogradient-based requires significantly more training iterations I′ such that
frameworks. On the other hand, by compensating for the IU and I′U′ have the same order of magnitude, where
compression error in future iterations, the error feedback I is the original number of training iterations with all U
significantlyimprovesthetrainingperformancewhenthecom- participatingclients,andI′ isthenumberoftrainingiterations
pression rate is high, i.e., r and q are low. However, the error with limited data from U′ clients. In the case of smaller
feedback requires O(Xg) additional memory throughout the numberofparticipatingclientsU′ ≪U andPLR=0,FbFTL
entire training process and not just during the local training. requires the same level of computational power consumption
Also, we demonstrate below in the experimental results that and more total downlink payload compared to the original
the gradient-based frameworks do not prevail even with error case with U clients. However, there is a huge reduction
feedback. in total uplink payload and total local computational power11
FL r =1 r =0.1 r =0.01 r =0.001
FTL
f
FTL
c
FbFTL
q =32 89.42% 83.96% 59.97% 42.26%
93.75% 93.46% 90.98% 81.98%
86.51% 85.45% 84.49% 82.78%
86.51% 86.47% 82.10% 65.71%
q =8 88.46% 82.34% 57.04% 39.34%
93.36% 93.34% 90.83% 81.91%
Figure8:ValidationaccuracyofFbFTLwithdifferentnumber 86.16% 85.44% 84.41% 82.53%
of participating samples and PLRs. 86.41% 86.39% 81.85% 65.55%
q =2 45.96% 44.67% 33.63% 31.91%
88.20% 88.16% 86.19% 80.15%
81.44% 81.29% 80.91% 78.61%
85.50% 85.48% 80.99% 65.18%
Table V: Validation accuracy comparison between FL, FTL
updatingfullmodel,FTLupdatingtask-specificsub-modeland
FbFTL with quantization to q bits, sparsification ratio r of
elements, and error feedback (except for FbFTL).
instance82%,FbFTLrequiresthesparsificationratiotobeno
lower than r =0.01 (which is 10 times more than that of the
bestgradient-basedframework),butstillmaintainsareduction
Figure 9: ROUGE-1 score of FbFTL with different number
of more than four orders of magnitude (i.e., reduction of
of participating samples and PLRs on FLAN-T5-small with
10−4) in total uplink payload compared to the gradient-based
SAMSum.
algorithmswhileachievingthesamevalidationaccuracy.Such
good performance of FbFTL without error feedback is due
to the robustness of extracted features against noise. If we
consumption, because FbFTL only requires uploading once
consider the error from compression as random noise, the
for each participating client. In comparison, gradient-based
extractedfeaturesfromawell-trainedsourcemodelistypically
frameworks require uploading in every training iteration, and
robusttonoisewhilegradientupdatedoesnotnecessarilyhave
therefore there is no such benefit in terms of reduced uplink
the same level of robustness.
payload and local computations, while they also suffer from
higher downlink payload. Similarly, we have the performance
curves for FLAN-T5-small in Fig. 9.
V. PRIVACYANALYSIS
In Table V, we show the validation accuracy of each In previous sections, we have described the FbFTL frame-
framework with data from all U clients and PLR =0, but for work where each client u with K u samples uploads extracted
different values of quantization size q bits and sparsification features z u,k and output y u,k for k = 1,...,K u instead of
ratio r. In the experiment, we pick the same set of values for the gradient update g =
(cid:80)Ku
∇ L(f |s ) as done in
u k=1 θθθ θθθ u,k
q and r as in [77], [78]. Note that the highest reduction in FL and FTL with FedAvg. In this section, we conduct a
uplink payload is achieved when we set r =0.001 and q =2. privacy analysis by studying privacy leakage to a potential
However, even in this case, the uplink payload of gradient- adversary, and propose protection strategies. In particular, we
basedframeworks(i.e.,FTL,FTL ,FTL )isstillgreaterthan considerleakageduetotheunveilingofinformationregarding
f c
that of FbFTL with r = 1 and q = 32. Moreover, with the outputs/labels {y } (henceforth referred to as label
u,k
such drastic reduction, gradient-based schemes achieve lower privacy leakage) and the unveiling of intermediate features
accuraciescomparedtothatofFbFTLwithr =1andq =32. {z } (henceforth referred to as feature privacy leakage).
u,k
Therefore, even without sparsification and more restrictive For example, during the training process of a classifier to
quantization (e.g., q = 8 or q = 2), FbFTL outperforms distinguish the character in a photo to be a dog or a cat, the
gradient-based frameworks in terms of both accuracy and identity of the character being labeled as a dog is considered
payload reduction. We can further reduce the uplink payload as label privacy, while the feature privacy includes additional
of FbFTL by choosing r < 1 and q < 32. We note that information of the certain photo besides its label privacy such
FbFTL in the extreme case of r = 0.001 only keeps 4 as the color of the fur and the furniture in the background.
elements in the extracted features to distinguish among 10 The label privacy leakage quantifies how much information
classes. In this setting, the information is severely limited aboutthebatchofatargetedclientisrevealedtoanadversary
and is insufficient to make an accurate prediction, resulting through the information on the outputs {y } (or type of
u,k
in accuracy levels of 65% for FbFTL. If, on the other hand, label in classification problems). The information on the
we pick a certain threshold on the validation accuracy, for outputs/labels can be of statistical nature or can be obtained12
via the unveiling of the outputs to the adversary. The former
N labels
considers the information leakage via the knowledge of the
general sample output distribution, while the latter specifies [0, 1, 0, 0, 0] [0, 0, 0, 0, 1] [0, 1, 0, 0, 0]
the leakage when the adversary has access to the output/label [1, 0, 0, 0, 0] [1, 0, 0, 0, 0] [0, 0, 0, 1, 0]
values. We analyze the label privacy leakage via the entropy [0, 0, 0, 1, 0] [0, 0, 1, 0, 0] [0, 0, 0, 1, 0]
K samples : : …… :
and mutual information from the adversary’s perspective and : : :
proposeanuploadingdesignthatrandomlyshufflesallbatches : : :
to conceal the dependency between the client address and the [0, 0, 1, 0, 0] [0, 0, 0, 1, 0] [1, 0, 0, 0, 0]
output data.
Feature privacy leakage describes the amount of informa- U clients with U batches
tion that possibly leaks when the adversary obtains uploaded Figure 10: Diagram of every sample label y ∈ [0,1]N in
contents from clients. We will analyze the feature privacy u,k
batches.
leakage via the differential privacy (DP) framework [7] and
provide comparisons between FbFTL and the gradient-based
frameworks (FL and FTL, in which cases feature privacy
Assuming that the order in the batch does not contain
is leaked when the adversary obtains the gradient updates)
information, we use B to denote the set of possible batches
through experiments and numerical results.
without order from client u, and the privacy information of
the real batch b from client u is the sum vector
(cid:80)K
y =
A. Label Privacy Leakage k=1 u,k
[ny ,ny ,...,ny ], where (cid:80)N ny = K. Subsequently,
First, we analyze the label privacy leakage. While FbFTL 1,b 2,b N,b a=1 a,b
the number of possible batches without order is the combina-
directly uploads the output in each batch for each sample,
tion with the replacement of N items taken K times and is
we note that FL and FTL with FedAvg that update the final
given by
layer also leak the output, and hence label privacy leakage (cid:18) N +K−1(cid:19)
also occurs in these cases. According to [80], the count of |B|= . (23)
K
each output type in a batch can be numerically solved given
theaveragegradient.Adversarieswithcertainpriorknowledge We denote the index of client u’s batch as a random variable
on the training data are able to gain further knowledge and B, and the index of the uploaded batch as B = b ∈ B. We
reconstruct the input from the average gradient, such as deep denotethetypeofthelabely u,k’sdistributionasP y.Typically
leakage [81] or gradient inversion [82], [83]. Although the toachievebetterperformance,inmostofthemachinelearning
following label privacy analysis applies to both feature-based applications we desire a uniform distribution over different
FbFTL and gradient-based FedAvg frameworks, we in label labels, and we denote the uniform distribution over N labels
privacy analysis use the word “batch” to indicate all uploaded as P y,uni =[ N1, N1,..., N1].
information from one client with multiple samples. Compared To evaluate the adversary’s knowledge on one given batch
tothehigh-dimensionalgradientg orfeaturez ,theoutput B = b of a target victim client, we consider the presumed
u u,k
y also potentially reveals clients’ private information but up distribution P B of the batch B from the adversary’s perspec-
to a certain degree. In this setting, we analyze the conditions tivetoquantifytheadversary’suncertaintythroughtheentropy
under which the label privacy leakage (with statistical infor- H(B) of the given batch.
mation) vanishes. We also address the role of shuffling the 1) Label Privacy Leakage with Statistical Information:
output information from all clients as a way of hiding the A weak adversary without any prior knowledge of the sam-
client’s address from uploaded content when adversary has ple distribution may presume the sample distribution to be
access to outputs. uniform, i.e., P y,uni. In this case, the distribution of ordered
To validate these approaches, we analyze the private output batches from the adversary’s perspective is also uniform with
informationleakageofaspecificbatchtoapotentialadversary probability 1/NK. Each batch index b∈B without order cor-
without client addresses. According to [84], the privacy loss respondstoK!/(cid:81)N ny !differentbatchindiceswithorder,
a=1 a,b
of a query can be evaluated as the difference in the privacy and hence the adversary’s presumed probability distribution
before and after the query. In our setting, we determine of batches without order (under the assumption of uniform
the amount of label privacy via the uncertainty from the sample distribution) is P B|uni =[p 0,1,p 0,2,...,p 0,|B|], where
adversary’sperspective,andquantifyitbyutilizingtheentropy
K!
formulation. p = . (24)
0,b NK(cid:81)N ny !
As shown in Fig. 10, we consider a common learning task a=1 a,b
in which the output y∈[0,1]N is an axis-aligned unit vector
Therefore from the weak adversary’s perspective, the uncer-
with one element having a value of 1 indicating the label tainty of the batch from client u with known format and
associated with the given input, and all others equal to 0.
size but without prior knowledge about the content can be
We assume that each sample {x ,z ,y } is independent
u,k u,k u,k quantified by the entropy
and identically distributed (i.i.d.). Each client u∈U transmits
one batch with K
u
=K samples, including the outputs/labels (cid:88)|B|
{y }K . Therefore for this client, there are NK different H(B | P y,uni)=− p 0,blog 2p 0,b (25)
u,k k=1
possible ordered batches of outputs in total (where N is the b=1
numberofpossibledifferentlabelsthatcanbeassociatedwith wheretheconditionintheentropysignifiesthatthisistheen-
the input). tropy under the assumption of uniformly distributed samples.13
On the contrary, a stronger adversary with the ability to among all U batches:
steal and decode a large amount of uploaded data may learn (cid:20) (cid:21)
c(1) c(2) c(|B|)
the structure of the DNN and is able to decode the labels of P ≜P{B | C =c }= , ,..., .
B,emp U U U U U
the K samples in a batch, and hence such an adversary is
(29)
likely to have the prior knowledge of the general distribution
With this empirical distribution based on the shuffled U
of batches from a large number of clients. In the case that the
batches, the adversary’s uncertainty is given by the entropy
truesampledistributionP isknown,wedenotethestrong
y,true
adversary’s presumed distribution of the batch from client u |B|
(cid:88)c(b) c(b)
as H(B | C U =c U)=− U log 2 U . (30)
P B|true =[p 1,p 2,...,p |B|], (26) b=1
and the corresponding uncertainty at the adversary in the In the case in which the adversary has acquired U batches
original setting before query is via the query and knows the distribution P y,true of the sam-
ples, we denote the adversary’s presumed distribution as
|B|
H(B | P )=−(cid:88) p log p . (27) P(B |C U =c U,P y,true),anditsuncertaintyonclientu’sbatch
y,true b 2 b as H(B | C =c ,P ).
U U y,true
b=1
First, we establish the following result.
Bycomparingtheuncertaintybetweentheweakadversaryand
the strong adversary, we give the definition of label privacy Lemma1. Assumethatthetruesampledistributionisknown.
leakage with statistical information. Once U batches are revealed to the adversary, the distribution
ofthebatches(fromtheadversary’sperspective)dependsonly
Definition 1. Label Privacy Leakage with Statistical Infor- on the frequency/count of each batch type in the unveiled U
mation: For an adversary without prior knowledge of the batches and not on the sample distribution, i.e.,
sample distribution (and hence that initially assumes uniform
P(B =b | C =c ,P )=P{B =b|C =c }. (31)
sample distribution), the label privacy leakage is the amount U U y,true U U
of information regarding the target batch B that leaks to the
Proof. We prove this lemma by utilizing the Bayes’ rule
adversary when it obtains the true distribution P . This
y,true and determining the ratio of two conditional probabilities as
privacy leakage can be formulated as follows:
follows:
Ll =H(B | P )−H(B | P ). (28)
s y,uni y,true P(B =b | C =c ,P )=P(C U =c U,B =b|P y,true)
U U y,true P(C =c |P )
U U y,true
Note that H(B | P ) is the uncertainty in B under
y,uni (U−1)!
the assumption that the labels are uniformly distributed. =(c(b)−1)!(cid:81) b′̸=bc(b′)!
H(B | P ) is the remaining uncertainty in B when the U!
true
sampy l, etru de
istribution is learned by the adversary. Hence,
c(b)!(cid:81) b′̸=bc(b′)!
(U−1)!
the difference is the information gained by or equivalently
(c(b)−1)!
=
leaked to the adversary. U!
c(b)!
Machine learning tasks typically require dataset balancing. c(b)
=
If the data collection process is sufficiently well designed so U
that each output type is almost equally likely and we have =P{B =b|C =c }.
U U
P B|true → P B|uni, then the label privacy leakage Ll s → 0. As (32)
wehaveillustratedinsectionIII-A,achievingthisgoalismore
viable in FbFTL.
2) Label Privacy Leakage with Access via Query: Next,
we analyze the label privacy leakage when the adversary has This result indicates that the batch distribution is equal to
access to the shuffled outputs (e.g., via a query). In the worst the empirical distribution in (29). Consequently, we also have
case, the strongest query is the process that the adversary the following characterization for the entropies:
acquires all batches without clients’ addresses. Specifically,
we assume that the adversary has access to randomly shuffled H(B | C U =c U,P y,true)=H(B | C U =c U) (33)
U batches. Recall that there are |B| different types of batches.
Next, we give the definition of the label privacy leakage
Weusec(b)todenotethecountfortypebbatchesamonggiven
with query, and identify a condition under which the privacy
U batches. With this definition, we have (cid:80)| bB =| 1c(b)=U. For leakage vanishes.
different set of U batches, the counts will be different. We
define C as a random vector of counts of different types Definition 2. Label Privacy Leakage with Query: For an
U
of batches among a total of U batches. Hence, for given adversarywithpriorknowledgeofthetruesampledistribution
U batches, the realization of this vector is C = c = P , the label privacy leakage with query is the amount of
U U y,true
[c(1),c(2),...,c(|B|)]. In the absence of any other statistical information regarding the batch of a target client that leaks
information, the adversary can utilize the following empirical to the adversary when it obtains the randomly shuffled set of
distribution of B based on the frequency of each batch type uploaded U batches including the target’s batch. This privacy14
leakage can be formulated as follows: privacy, we denote the training samples for each batch as d
and the function that generates the upload vector as g. More
Ll q =H(B |P y,true)−H(B | P y,true, C U =c U) (34) specifically,d=s u,k andg(d)=z u,k =f θθθ1 1(x u,k)forFbFTL,
=H(B |P )−H(B | C =c ). while d = (cid:83)K s and g(d) = g = (cid:80)K ∇ L(f |s )
y,true U U k=1 u,k u k=1 θθθ θθθ u,k
for gradient-based FedAvg frameworks. Similarly as in [89]–
Lemma 2. Asthenumberofshuffledbatchesgoestoinfinity,
[91], we define the feature privacy through the following
the label privacy leakage with query converges to 0, i.e.,
condition: g satisfies (ϵ,δ)-DP if for any subset of possible
lim Ll =0. (35) outputs G it holds that
q
U→∞
Proof. As U grows without bound, we have lim P = Pr{g(d)∈G}≤eϵPr{g(d′)∈G}+δ, (37)
B,emp
U→∞
P by the law of large numbers, and as a result, we where d and d′ differ in a single sample with the true
B|true
have the characterization that lim H(B | C U = c U) = distribution P y,true.
U→∞
H(B |P ).Hence,thelabelprivacyleakageLq withquery In[92],ithasbeenshownviamomentsaccountantapproach
y,true l that adding Gaussian noise n to g(d) prior to transmission
converges to 0.
maintains an overall privacy loss of (ϵ,δ). Typically, the
Note that if the adversary does not initially know even the variance of the noise depends on the maximum distance
distributionofthesamplesandassumeauniformlydistributed max∥g(d)−g(d′)∥ for any two adjacent inputs d and d′. To
samples,thentotallabelprivacyleakageaftertheunveilingof provide a fair comparison between different learning frame-
the U batches to the adversary can be defined as works, we consider the maximum relative distance R =
max|g(d)−g(d′)|
Ll t =Ll s+Ll q =H(B | P y,uni)−H(B | C U =c U). (36) m d,a d′x Kstd(g(d)) within training set for each framework,
where | · | denotes absolute value and std(·) denotes the
If the shuffled dataset is perfectly balanced and we have
standard deviation. Thus, the additive Gaussian noise to each
P = P , the total label privacy leakage is zero, i.e.,
B,emp B|uni output g(d ) should be n ∼ N(0, σ2R2std2(g(d ))I) to
Ll =Ll +Ll =0. 1 1
t s q mitigate the feature privacy leakage, and the lower bound of
the σ value can be determined via the moments accountant
B. Feature Privacy Leakage approach.
As a result, according to [92, Theorem 1], there exist
In this section, we analyze the privacy leakage on the input
constants c and c such that for any ϵ<c C2I, the training
x via uploaded content. Such privacy leakage includes the 1 2 1
process with g(d)+n is (ϵ,δ)-differentially private for any
information that is not necessarily needed to determine the √
output y, and we will define it as feature privacy. Different
δ >0ifwechooseσ ≥ c2 ϵC −Ilogδ,whereI isthenumber
of iterations (I = 1 for FbFTL), and C is the fraction of
from label privacy where the adversary knows the implication
clients selected in each iteration. When the value of δ and
of each type of output (or the meaning of each label), it
noise factor σR are fixed, ϵ for FedAvg DP decreases as
is hard to define the adversary’s prior knowledge on the
the batch size K grows, but increases as training iterations I
gradients and extracted features, and it is unlikely to cancel
(and potentially, the number of retraining for hyper-parameter
feature privacy leakage via shuffling. Furthermore, it is hard
tuning) increase. However, ϵ for FbFTL DP does not depend
toquantifyandanalyzetheentropyandmutualinformationof
on these factors. Furthermore, the final performance also
gradients and extracted features because of the complexity of
depends on the robustness of each framework against noise.
neural networks. Instead, we will analyze the feature privacy
Therefore, we demonstrate the comparisons via experiments
leakage via differential privacy.
in the following subsection.
For FbFTL, the intermediate output z is also referred to as
the smashed data in split learning [85], [86], and cannot be
directlytransformedbacktotheinputxduetothenonlinearity C. Experimental Results
oftheactivationfunctionsineachlayer.However,itispossible In our experiments, we utilize the dataset CIFAR-10 which
that FbFTL leaks privacy to some extent and partially reveals has N = 10 types of labels, and is well-balanced (i.e.,
theinput.Sincethefeaturebeforeafullyconnectedlayerfrom P = P ). We generate shuffled batches according to
y,true y,uni
a sample can be analytically solved from its gradient [87], the uniform sample distribution P and evaluate the total
y,uni
it is possible that gradient-based frameworks also leak the label privacy leakage in different scenarios in Fig. 11. The
input.ThestrategytoextracttheinputfromFedAvggradients blue curve plots the initial uncertainty H(B | P ) for
y,uni
includes deep leakage [81], [87], [88] and gradient inversion different values of K (where K is the number of samples
[82], [83], and is extensively studied for image recognition. from each client). Each of the other curves shows the uncer-
However, deep leakage highly depends on the dataset and tainty given shuffled data H(B | C = c ) with fixed total
U U
DNN structure. Therefore, an analysis of the privacy leakage amount of samples UK from all clients, and the number of
beyond label privacy is needed to identify what may be clients U is determined by each value of K accordingly. By
partially revealed regarding the input x from the uploaded Definition 1 and Definition 2, the total label privacy leakage
features. given shuffled data is Ll = Ll + Ll and is equal to the
t s q
Differential privacy (DP) provides an upper bound on the difference H(B | P )−H(B | C = c ). We see that
y,uni U U
privacy leakage using a different measuring approach, and H(B | P )≈H(B | C =c ) when K is small, and thus
y,uni U U
we compare the feature privacy preserving performances of the label privacy is well preserved. However, for given value
FbFTLandotherschemesviaDP.IntheDPanalysisoffeature of the product UK, H(B | C =c ) diminishes fast once a
U U15
mitigated via shuffling. In Fig. 12c, we show the comparison
for even larger K =600, where all types of FedAvg perform
better than FbFTL.
(a) K=4. (b) K=100.
Figure 11: Label privacy of each client in bits against the
number of samples K from each client.
certain threshold of K is exceeded. Therefore, we note that
(c) K=600.
the label privacy leakage becomes high when K is large. As
addressed before, the label privacy applies in the same way Figure 12: Comparison of validation accuracy at different K,
to both FbFTL and gradient-based FedAvg frameworks, and ϵ, and δ =10−6 between FL, FTL updating full model, FTL
hence a smaller K might be preferred in order to preserve the updating task-specific sub-model and FbFTL. The accuracy is
label privacy. However, current FL privacy analyses typically marked as 0 if the model fails to converge.
focus on DP that provides a relatively loose upper bound
on the total local privacy. Within the DP setting, studies
Note that it is extremely difficult to analytically evaluate
typically consider a small number of clients and assume that
the volume of feature privacy leakage that can be mitigated
each client obtains hundreds of samples, if not thousands of,
viashuffling.Howeover,wecancomparetheperformancesof
to achieve improved DP performance. However, as we have
FbFTL and FedAvg for a given K via experimental results
observed above, a setting with higher values of K can lead to
as done above. One key conclusion we have is the following.
higherlabelprivacyloss(inadditiontorequiringmoretraining
In terms of privacy preservation, FbFTL is preferred when K
epochs and achieving less validation accuracy). This leads to
is small (i.e., each client obtains a small set of samples), and
the important conclusion that the balance between different
gradient-based FedAvg is preferred when K is large.
types of privacy leakage needs to be considered carefully.
TocomparetheDPperformancesoffeatureprivacyleakage,
we apply different noise levels σ on upload content g(d)
VI. CONCLUSION
of different frameworks to achieve the same level (ϵ,δ) of In this paper, we have presented a novel communication-
privacy, and compare the validation accuracy at convergence efficient federated transfer learning method. In this proposed
with different K in Fig. 12. In our experiments, we imple- feature-basedfederatedtransferlearning(FbFTL),thefeatures
ment the moments accountant via Re´nyi Divergence-based and outputs are uploaded rather than the gradient updates. We
DP accountant to get a tighter bound. With fixed δ = 10−6, haveprovidedathoroughdescriptionofthesystemdesignand
each plot shows the validation accuracy at convergence as a the learning algorithm, and compared its theoretical payload
function of ϵ for given K. We note that higher ϵ indicates withthatoffederatedlearningandfederatedtransferlearning.
weaker DP protection, lower noise level σ, and thus higher Our results demonstrate substantial reductions in both uplink
accuracy (closer to the original performance without noise). and downlink payload when using FbFTL. Via experiments,
As shown in Fig. 11, label privacy is better preserved at we have further shown the effectiveness of the proposed
K = 4, and we show the DP performance within the same FbFTL by showing that FbFTL reduces the uplink payload
setting in Fig. 12a. While gradient-based FedAvg frameworks byuptofiveordersofmagnitudecomparedtothatofexisting
totallyfail,FbFTLhasgoodperformancebecauseithasmuch methods. Subsequently, we have demonstrated that FbFTL
smaller data size |g(d)| and is more robust against noise, as with small batch size has significantly less packet loss rate
it receives constant data instead of varying perturbation in than gradient-based frameworks, and illustrated its robustness
each training iteration and converges to a sub-optimal model. against data insufficiency and quantization. Finally, we have
SuchadvantageofFbFTLremainsuntilK increasesto100as considered different types of privacy leakage, and analyzed
shown in Fig. 12b, where FTL that updates the task-specific mitigation approaches. Specifically, we have first analyzed
sub-modeloutperformsFbFTLatϵ≥4astheyhavethesame label privacy leakage with both statistical knowledge and
data size |g(d)| while the noise level of FedAvg decreases as query (resulting in access to the label outputs). We have
K increases. However, the label privacy completely leaks for identified a condition under which label privacy vanishes.
K ≥16 as we have seen in Fig. 11. FedAvg for K ≥16 only We have also addressed feature privacy and considered a
prevails in protecting the subset of feature privacy that is not DP mechanism for preserving this privacy. We have shown16
that with small K and shuffling that eliminates label privacy [22] D.Han,Q.Liu,andW.Fan,“Anewimageclassificationmethodusing
leakage, FbFTL also attains good differential feature privacy cnntransferlearningandwebdataaugmentation,”ExpertSystemswith
Applications,vol.95,pp.43–56,2018.
protection.ThesecharacterizationsandresultsrenderFbFTLa
[23] M. Harel and S. Mannor, “Learning from multiple outlooks,” arXiv
communication-efficient, robust, and privacy-preserving novel preprintarXiv:1005.0027,2010.
federated transfer learning scheme. [24] J.Park,R.J.Javier,T.Moon,andY.Kim,“Micro-dopplerbasedclassi-
ficationofhumanaquaticactivitiesviatransferlearningofconvolutional
neuralnetworks,”Sensors,vol.16,no.12,p.1990,2016.
[25] N. Agarwal, A. Sondhi, K. Chopra, and G. Singh, “Transfer learning:
REFERENCES
Surveyandclassification,”inSmartInnovationsinCommunicationand
ComputationalSciences. Springer,2021,pp.145–155.
[1] J.Konecˇny`,H.B.McMahan,D.Ramage,andP.Richta´rik,“Federated [26] Y. Ma, G. Luo, X. Zeng, and A. Chen, “Transfer learning for cross-
optimization: Distributed machine learning for on-device intelligence,” company software defect prediction,” Information and Software Tech-
arXivpreprintarXiv:1610.02527,2016. nology,vol.54,no.3,pp.248–256,2012.
[2] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. [27] J.Nam,W.Fu,S.Kim,T.Menzies,andL.Tan,“Heterogeneousdefect
Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings et al., prediction,”IEEETransactionsonSoftwareEngineering,vol.44,no.9,
“Advances and open problems in federated learning,” arXiv preprint pp.874–896,2017.
arXiv:1912.04977,2019. [28] P. Prettenhofer and B. Stein, “Cross-language text classification using
[3] J.Mills,J.Hu,andG.Min,“Communication-efficientfederatedlearning structuralcorrespondencelearning,”inProceedingsofthe48thannual
forwirelessedgeintelligenceiniot,”IEEEInternetofThingsJournal, meetingoftheassociationforcomputationallinguistics,2010,pp.1118–
vol.7,no.7,pp.5986–5994,2019. 1127.
[4] B.McMahan,E.Moore,D.Ramage,S.Hampson,andB.A.yArcas, [29] J.T.Zhou,I.W.Tsang,S.J.Pan,andM.Tan,“Heterogeneousdomain
“Communication-efficientlearningofdeepnetworksfromdecentralized adaptationformultipleclasses,”inArtificialintelligenceandstatistics.
data,”inArtificialintelligenceandstatistics. PMLR,2017,pp.1273– PMLR,2014,pp.1095–1103.
1282. [30] J.T.Zhou,S.J.Pan,I.W.Tsang,andY.Yan,“Hybridheterogeneous
[5] Y. Cheng, J. Lu, D. Niyato, B. Lyu, J. Kang, and S. Zhu, “Federated transferlearningthroughdeeplearning,”inTwenty-eighthAAAIconfer-
transferlearningwithclientselectionforintrusiondetectioninmobile enceonartificialintelligence,2014.
edge computing,” IEEE Communications Letters, vol. 26, no. 3, pp. [31] M.Chen,D.Gu¨ndu¨z,K.Huang,W.Saad,M.Bennis,A.V.Feljan,and
552–556,2022. H.V.Poor,“Distributedlearninginwirelessnetworks:Recentprogress
[6] Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu, “Federated andfuturechallenges,”arXivpreprintarXiv:2104.02151,2021.
learning,” Synthesis Lectures on Artificial Intelligence and Machine [32] Y. Yuan, X. Chen, X. Chen, and J. Wang, “Segmentation transformer:
Learning,vol.13,no.3,pp.1–207,2019. Object-contextual representations for semantic segmentation,” in Euro-
[7] K.Wei,J.Li,M.Ding,C.Ma,H.H.Yang,F.Farokhi,S.Jin,T.Q.Quek, peanConferenceonComputerVision(ECCV),vol.1,2021.
andH.V.Poor,“Federatedlearningwithdifferentialprivacy:Algorithms [33] J. Jain, A. Singh, N. Orlov, Z. Huang, J. Li, S. Walton, and H. Shi,
andperformanceanalysis,”IEEETransactionsonInformationForensics “Semask:Semanticallymaskedtransformersforsemanticsegmentation,”
andSecurity,vol.15,pp.3454–3469,2020. arXivpreprintarXiv:2112.12782,2021.
[8] X.Yin,X.Yu,K.Sohn,X.Liu,andM.Chandraker,“Featuretransfer [34] Z.Dai,H.Liu,Q.V.Le,andM.Tan,“Coatnet:Marryingconvolution
learningforfacerecognitionwithunder-representeddata,”inProceed- andattentionforalldatasizes,”arXivpreprintarXiv:2106.04803,2021.
ings of the IEEE/CVF conference on computer vision and pattern [35] P. Foret, A. Kleiner, H. Mobahi, and B. Neyshabur, “Sharpness-aware
recognition,2019,pp.5704–5713. minimization for efficiently improving generalization,” arXiv preprint
[9] Y.Chen,X.Qin,J.Wang,C.Yu,andW.Gao,“Fedhealth:Afederated arXiv:2010.01412,2020.
transfer learning framework for wearable healthcare,” IEEE Intelligent [36] Z. Liu, H. Hu, Y. Lin, Z. Yao, Z. Xie, Y. Wei, J. Ning, Y. Cao,
Systems,vol.35,no.4,pp.83–93,2020. Z. Zhang, L. Dong et al., “Swin transformer v2: Scaling up capacity
[10] C.Ju,D.Gao,R.Mane,B.Tan,Y.Liu,andC.Guan,“Federatedtransfer andresolution,”arXivpreprintarXiv:2111.09883,2021.
learningforeegsignalclassification,”in202042ndAnnualInternational [37] G.Ghiasi,Y.Cui,A.Srinivas,R.Qian,T.-Y.Lin,E.D.Cubuk,Q.V.Le,
Conference of the IEEE Engineering in Medicine & Biology Society andB.Zoph,“Simplecopy-pasteisastrongdataaugmentationmethod
(EMBC). IEEE,2020,pp.3040–3045. forinstancesegmentation,”inProceedingsoftheIEEE/CVFConference
[11] H.Yang,H.He,W.Zhang,andX.Cao,“Fedsteg:Afederatedtransfer onComputerVisionandPatternRecognition,2021,pp.2918–2928.
learning framework for secure image steganalysis,” IEEE Transactions [38] I. Yamada, A. Asai, H. Shindo, H. Takeda, and Y. Matsumoto,
onNetworkScienceandEngineering,2020. “Luke:deepcontextualizedentityrepresentationswithentity-awareself-
[12] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Trans- attention,”arXivpreprintarXiv:2010.01057,2020.
actionsonknowledgeanddataengineering,vol.22,no.10,pp.1345– [39] A.Srivastava,D.Jha,S.Chanda,U.Pal,H.D.Johansen,D.Johansen,
1359,2009. M.A.Riegler,S.Ali,andP.Halvorsen,“Msrf-net:Amulti-scaleresidual
[13] K. Weiss, T. M. Khoshgoftaar, and D. Wang, “A survey of transfer fusion network for biomedical image segmentation,” arXiv preprint
learning,”JournalofBigdata,vol.3,no.1,pp.1–40,2016. arXiv:2105.07451,2021.
[14] C. Wang and S. Mahadevan, “Heterogeneous domain adaptation using [40] Y. Zhang, J. Qin, D. S. Park, W. Han, C.-C. Chiu, R. Pang, Q. V. Le,
manifoldalignment,”inTwenty-secondinternationaljointconferenceon andY.Wu,“Pushingthelimitsofsemi-supervisedlearningforautomatic
artificialintelligence,2011. speechrecognition,”arXivpreprintarXiv:2010.10504,2020.
[15] M.Kaya,G.Fidan,andI.H.Toroslu,“Transferlearningusingtwitter [41] K.SimonyanandA.Zisserman,“Verydeepconvolutionalnetworksfor
dataforimprovingsentimentclassificationofturkishpoliticalnews,”in large-scaleimagerecognition,”arXivpreprintarXiv:1409.1556,2014.
Informationsciencesandsystems2013. Springer,2013,pp.139–148. [42] J.Deng,W.Dong,R.Socher,L.-J.Li,K.Li,andL.Fei-Fei,“Imagenet:
[16] F.H.Khan,U.Qamar,andS.Bashir,“Enhancedcross-domainsentiment Alarge-scalehierarchicalimagedatabase,”in2009IEEEconferenceon
classification utilizing a multi-source transfer learning approach,” Soft computervisionandpatternrecognition. Ieee,2009,pp.248–255.
Computing,vol.23,no.14,pp.5431–5442,2019. [43] A. Krizhevsky, G. Hinton et al., “Learning multiple layers of features
[17] L. Duan, D. Xu, and I. Tsang, “Learning with augmented features fromtinyimages,”2009,citeseer.
forheterogeneousdomainadaptation,”arXivpreprintarXiv:1206.4660, [44] M.Series,“Minimumrequirementsrelatedtotechnicalperformancefor
2012. imt-2020radiointerface(s),”Report,pp.2410–0,2017.
[18] B. Kulis, K. Saenko, and T. Darrell, “What you saw is not what you [45] H. Sun, S. Li, F. R. Yu, Q. Qi, J. Wang, and J. Liao, “Toward
get:Domainadaptationusingasymmetrickerneltransforms,”inCVPR communication-efficientfederatedlearningintheinternetofthingswith
2011. IEEE,2011,pp.1785–1792. edge computing,” IEEE Internet of Things Journal, vol. 7, no. 11, pp.
[19] Y. Zhu, Y. Chen, Z. Lu, S. J. Pan, G.-R. Xue, Y. Yu, and Q. Yang, 11053–11067,2020.
“Heterogeneous transfer learning for image classification,” in Twenty- [46] E. Ozfatura, K. Ozfatura, and D. Gu¨ndu¨z, “Time-correlated sparsifi-
FifthAAAIConferenceonArtificialIntelligence,2011. cation for communication-efficient federated learning,” in 2021 IEEE
[20] M.ShahaandM.Pawar,“Transferlearningforimageclassification,”in International Symposium on Information Theory (ISIT). IEEE, 2021,
2018 Second International Conference on Electronics, Communication pp.461–466.
andAerospaceTechnology(ICECA). IEEE,2018,pp.656–660. [47] Y. He, H.-P. Wang, and M. Fritz, “Cossgd: Communicationefficient
[21] M.Hussain,J.J.Bird,andD.R.Faria,“Astudyoncnntransferlearning federated learning with a simple cosine-based quantization,” in 1st
forimageclassification,”inUKWorkshoponcomputationalIntelligence. NeurIPS Workshop on New Frontiers in Federated Learning (NFFL),
Springer,2018,pp.191–202. 2021.17
[48] J.Konecˇny`,H.B.McMahan,F.X.Yu,P.Richta´rik,A.T.Suresh,and International Journal of Computer Vision (IJCV), vol. 115, no. 3, pp.
D.Bacon,“Federatedlearning:Strategiesforimprovingcommunication 211–252,2015.
efficiency,”arXivpreprintarXiv:1610.05492,2016. [72] A.Paszke,S.Gross,S.Chintala,G.Chanan,E.Yang,Z.DeVito,Z.Lin,
[49] D. Basu, D. Data, C. Karakus, and S. Diggavi, “Qsparse-local-sgd: A. Desmaison, L. Antiga, and A. Lerer, “Automatic differentiation
Distributedsgdwithquantization,sparsificationandlocalcomputations,” in pytorch,” in NIPS 2017 Workshop on Autodiff, 2017. [Online].
AdvancesinNeuralInformationProcessingSystems,vol.32,2019. Available:https://openreview.net/forum?id=BJJsrmfCZ
[50] P. Richta´rik, I. Sokolov, and I. Fatkhullin, “Ef21: A new, simpler, [73] M.Abadi,A.Agarwal,P.Barham,E.Brevdo,Z.Chen,C.Citro,G.S.
theoretically better, and practically faster error feedback,” Advances in Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow,
NeuralInformationProcessingSystems,vol.34,pp.4384–4396,2021. A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser,
[51] D.LiandJ.Wang,“Fedmd:Heterogenousfederatedlearningviamodel M. Kudlur, J. Levenberg, D. Mane´, R. Monga, S. Moore, D. Murray,
distillation,”arXivpreprintarXiv:1910.03581,2019. C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar,
[52] T. Lin, L. Kong, S. U. Stich, and M. Jaggi, “Ensemble distillation P. Tucker, V. Vanhoucke, V. Vasudevan, F. Vie´gas, O. Vinyals,
for robust model fusion in federated learning,” Advances in Neural P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng,
InformationProcessingSystems,vol.33,pp.2351–2363,2020. “TensorFlow:Large-scalemachinelearningonheterogeneoussystems,”
[53] J.-H.Ahn,O.Simeone,andJ.Kang,“Wirelessfederateddistillationfor 2015, software available from tensorflow.org. [Online]. Available:
distributededgelearningwithheterogeneousdata,”in2019IEEE30th https://www.tensorflow.org/
AnnualInternationalSymposiumonPersonal,IndoorandMobileRadio [74] B. Gliwa, I. Mochol, M. Biesek, and A. Wawer, “SAMSum corpus:
Communications(PIMRC). IEEE,2019,pp.1–6. Ahuman-annotateddialoguedatasetforabstractivesummarization,”in
[54] Y. Jiang, S. Wang, V. Valls, B. J. Ko, W.-H. Lee, K. K. Leung, and Proceedingsofthe2ndWorkshoponNewFrontiersinSummarization.
L.Tassiulas,“Modelpruningenablesefficientfederatedlearningonedge Hong Kong, China: Association for Computational Linguistics, Nov.
devices,”IEEETransactionsonNeuralNetworksandLearningSystems, 2019,pp.70–79.[Online].Available:https://www.aclweb.org/anthology/
2022. D19-5409
[55] J. Liu, S. Tripathi, U. Kurup, and M. Shah, “Pruning algorithms [75] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li,
to accelerate convolutional neural networks for edge applications: A X.Wang,M.Dehghani,S.Brahmaetal.,“Scalinginstruction-finetuned
survey,”arXivpreprintarXiv:2005.04275,2020. languagemodels,”arXivpreprintarXiv:2210.11416,2022.
[76] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi,
[56] H. Sidahmed, Z. Xu, A. Garg, Y. Cao, and M. Chen, “Efficient and
private federated learning with partially trainable networks,” arXiv P. Cistac, T. Rault, R. Louf, M. Funtowicz, J. Davison, S. Shleifer,
preprintarXiv:2110.03450,2021. P.vonPlaten,C.Ma,Y.Jernite,J.Plu,C.Xu,T.L.Scao,S.Gugger,
M. Drame, Q. Lhoest, and A. M. Rush, “Huggingface’s transformers:
[57] T.-J. Yang, D. Guliani, F. Beaufays, and G. Motta, “Partial variable
State-of-the-artnaturallanguageprocessing,”2020.
training for efficient on-device federated learning,” in ICASSP 2022-
[77] D.Alistarh,T.Hoefler,M.Johansson,N.Konstantinov,S.Khirirat,and
2022 IEEE International Conference on Acoustics, Speech and Signal
C.Renggli,“Theconvergenceofsparsifiedgradientmethods,”Advances
Processing(ICASSP). IEEE,2022,pp.4348–4352.
inNeuralInformationProcessingSystems,vol.31,2018.
[58] O. Aygu¨n, M. Kazemi, D. Gu¨ndu¨z, and T. M. Duman, “Hierarchical
[78] S. U. Stich, J.-B. Cordonnier, and M. Jaggi, “Sparsified sgd with
over-the-air federated edge learning,” in ICC 2022-IEEE International
memory,”AdvancesinNeuralInformationProcessingSystems,vol.31,
ConferenceonCommunications. IEEE,2022,pp.3376–3381.
2018.
[59] K. Yang, T. Jiang, Y. Shi, and Z. Ding, “Federated learning via over-
[79] J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar,
the-air computation,” IEEE Transactions on Wireless Communications,
“signsgd:Compressedoptimisationfornon-convexproblems,”inInter-
vol.19,no.3,pp.2022–2035,2020.
nationalConferenceonMachineLearning. PMLR,2018,pp.560–569.
[60] Y. Sun, S. Zhou, Z. Niu, and D. Gu¨ndu¨z, “Time-correlated sparsifica-
[80] A.Wainakh,F.Ventola,T.Mu¨ßig,J.Keim,C.G.Cordero,E.Zimmer,
tion for efficient over-the-air model aggregation in wireless federated
T. Grube, K. Kersting, and M. Mu¨hlha¨user, “User-level label leakage
learning,”arXivpreprintarXiv:2202.08420,2022.
fromgradientsinfederatedlearning,”ProceedingsonPrivacyEnhanc-
[61] O. Shahid, S. Pouriyeh, R. M. Parizi, Q. Z. Sheng, G. Srivastava, and
ingTechnologies,vol.2022,no.2,pp.227–244,2022.
L. Zhao, “Communication efficiency in federated learning: Achieve-
[81] L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” Advances
mentsandchallenges,”arXivpreprintarXiv:2107.10996,2021.
inNeuralInformationProcessingSystems,vol.32,2019.
[62] H. Xu, C.-Y. Ho, A. M. Abdelmoniem, A. Dutta, E. H. Bergou,
[82] J.Jeon,K.Lee,S.Oh,J.Oketal.,“Gradientinversionwithgenerative
K.Karatsenidis,M.Canini,andP.Kalnis,“Compressedcommunication
image prior,” Advances in Neural Information Processing Systems,
fordistributeddeeplearning:Surveyandquantitativeevaluation,”Tech.
vol.34,pp.29898–29908,2021.
Rep.,2020.
[83] Y.Huang,S.Gupta,Z.Song,K.Li,andS.Arora,“Evaluatinggradient
[63] A.Reisizadeh,A.Mokhtari,H.Hassani,A.Jadbabaie,andR.Pedarsani, inversionattacksanddefensesinfederatedlearning,”AdvancesinNeural
“Fedpaq: A communication-efficient federated learning method with InformationProcessingSystems,vol.34,pp.7232–7241,2021.
periodic averaging and quantization,” in International Conference on [84] L. Longpr, V. Kreinovich, and T. Dumrongpokaphan, “Entropy as a
ArtificialIntelligenceandStatistics. PMLR,2020,pp.2021–2031. measureofaveragelossofprivacy,”ThaiJournalofMathematics,pp.
[64] N.Shlezinger,M.Chen,Y.C.Eldar,H.V.Poor,andS.Cui,“Federated 7–15,2017.
learning with quantization constraints,” in ICASSP 2020-2020 IEEE [85] O.GuptaandR.Raskar,“Distributedlearningofdeepneuralnetwork
International Conference on Acoustics, Speech and Signal Processing overmultipleagents,”JournalofNetworkandComputerApplications,
(ICASSP). IEEE,2020,pp.8851–8855. vol.116,pp.1–8,2018.
[65] S.J.Pan,I.W.Tsang,J.T.Kwok,andQ.Yang,“Domainadaptationvia [86] P. Vepakomma, O. Gupta, T. Swedish, and R. Raskar, “Split learning
transfer component analysis,” IEEE Transactions on Neural Networks, forhealth:Distributeddeeplearningwithoutsharingrawpatientdata,”
vol.22,no.2,pp.199–210,2011. arXivpreprintarXiv:1812.00564,2018.
[66] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, [87] J. Geiping, H. Bauermeister, H. Dro¨ge, and M. Moeller, “Inverting
A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska gradients-how easy is it to break privacy in federated learning?” Ad-
et al., “Overcoming catastrophic forgetting in neural networks,” Pro- vancesinNeuralInformationProcessingSystems,vol.33,pp.16937–
ceedings of the national academy of sciences, vol. 114, no. 13, pp. 16947,2020.
3521–3526,2017. [88] B. Zhao, K. R. Mopuri, and H. Bilen, “idlg: Improved deep leakage
[67] C. Thapa, P. C. M. Arachchige, S. Camtepe, and L. Sun, “Splitfed: fromgradients,”arXivpreprintarXiv:2001.02610,2020.
When federated learning meets split learning,” in Proceedings of the [89] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise
AAAI Conference on Artificial Intelligence, vol. 36, no. 8, 2022, pp. to sensitivity in private data analysis,” in Theory of cryptography
8485–8493. conference. Springer,2006,pp.265–284.
[68] A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized federated [90] C. Dwork, “A firm foundation for private data analysis,” Communica-
learning:Ameta-learningapproach,”arXivpreprintarXiv:2002.07948, tionsoftheACM,vol.54,no.1,pp.86–95,2011.
2020. [91] C. Dwork, A. Roth et al., “The algorithmic foundations of differential
[69] Y.Zhao,M.Li,L.Lai,N.Suda,D.Civin,andV.Chandra,“Federated privacy.” Found. Trends Theor. Comput. Sci., vol. 9, no. 3-4, pp. 211–
learningwithnon-iiddata,”arXivpreprintarXiv:1806.00582,2018. 407,2014.
[70] J.Park,S.Samarakoon,M.Bennis,andM.Debbah,“Wirelessnetwork [92] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov,
intelligenceattheedge,”ProceedingsoftheIEEE,vol.107,no.11,pp. K. Talwar, and L. Zhang, “Deep learning with differential privacy,” in
2204–2239,2019. Proceedings of the 2016 ACM SIGSAC conference on computer and
[71] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, communicationssecurity,2016,pp.308–318.
Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and
L. Fei-Fei, “ImageNet Large Scale Visual Recognition Challenge,”