IntelliExplain: Enhancing Interactive Code Generation through
Natural Language Explanations for Non-Professional
Programmers
HaoYan ThomasD.LaToza ZiyuYao
GeorgeMasonUniversity GeorgeMasonUniversity GeorgeMasonUniversity
Fairfax,VA,USA Fairfax,VA,USA Fairfax,VA,USA
hyan5@gmu.edu tlatoza@gmu.edu ziyuyao@gmu.edu
(Task-specific Context)
User seeks What is the area code in which the most voters voted? VOTES:
help for code (Question) vote_id phone_number st (a Dte atac bre aa ste ed Schema)
generation
IntelliExplain (ours) Vanilla GPT-3.5
Here is what I understand based on your question: SELECT state, COUNT(*) as num_votes
System explains
code using In what state did the highest number of voters cast FROM VOTES JOIN AREA_CODE_STATE ON System exposes
understanable their votes? VOTES.state = AREA_CODE_STATE.state source code to
NL explanation If you think that my understanding is correct, please GROUP BY state ORDER BY num_votes users directly
& mark this question as "complete" by clicking "I think DESC LIMIT 1 (Initial Code) &
User identifies you are correct." (Explanation) User has to errors understand
(state --> area What does JOIN operation in the given query technical terms
co and de) Return an area code, not the state. (Feedback) do? (Clarfication Question) and r eit qe ura et siv tely
communicates explanations,
with NL Here is what I understand based on your question: The JOIN operation in the given query combines execution
feedback In which area code did the highest number of voters the VOTES table with the AREA_CODE_STATE results, etc.
vote? table based on condition that the state in VOTES
If you think that my understanding is correct, please matches the state in AREA_CODE_STATE. This
Easy-to-use and mark this question as "complete" by ... (Explanation) allows us to retrieve the area code ... (Response) Hard-to-
enhanced code I think you are correct. understand and
gene nra ot nio -n for Explain how these tables are combined. cof dix e e gr er no ers ra i tn ion
professionals I've finalized the SQL query based on your inputs! for non-
Here is it: professionals
9 More Turns
SELECT area_code FROM AREA_CODE_STATE WHERE state
= (SELECT state FROM VOTES GROUP BY state ORDER BY
COUNT(*) LIMIT 1) I think you are correct.
Figure1:IntelliExplainenablesnon-professionalprogrammerstowritecodeinnaturallanguagewithoutrequiringdirect
interaction with code. The user starts with a question in natural language (NL), accompanied by relevant context (top).
IntelliExplainthengeneratessourcecodeandconfirmsitsunderstandingofthequestionbypresentinganNLexplanation
(in□)totheuser.Whenthisunderstandingisincorrect,theusercanprovidecorrectivefeedbackinNLandinstructthesystem
forerrorcorrection.
ABSTRACT
withiterativefeedback.However,existinginteractionparadigms
Largelanguagemodels(LLMs)haveexhibitedastrongpromisein oftenassumethatusershaveexpertknowledgetodebugsource
automaticallygeneratingexecutablecodefromnaturallanguage codeandarenotoptimizedfornon-professionalprogrammers’use.
descriptions,particularlywithinteractivefeaturesthatallowusers Thisraiseschallengesinmakinginteractivecodegenerationmore
toengageinthecode-generationprocessbyinstructingtheLLM accessibleforindividualswithvaryinglevelsofprogrammingex-
pertise. To tackle these challenges, we present IntelliExplain,
whichoffersanovelhuman-LLMinteractionparadigmtoenhance
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed non-professionalprogrammers’experiencebyenablingthemto
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation interactwithsourcecodevianaturallanguageexplanations.Users
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe
interactwithIntelliExplainbyprovidingnaturallanguagecor-
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission rective feedback on errors they identify from the explanations.
and/orafee.Requestpermissionsfrompermissions@acm.org. Feedbackisusedbythesystemtorevisethecode,untiltheuser
Preprint,Conferenceacronym’XX,2024
issatisfiedwithexplanationsbythesystemofthecode.Ouruser
©2018Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ACMISBN978-1-4503-XXXX-X/18/06
https://doi.org/XXXXXXX.XXXXXXX
4202
yaM
61
]CH.sc[
1v05201.5042:viXraPreprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
studydemonstratesthatuserswithIntelliExplainachieveasig- tocomprehendthemodel-generatedtechnicalcontentanddebug
nificantly higher success rate 11.6% and 25.3% better than with sourcecodethemselves.Inadditiontocodeauto-completion,an
vanillaGPT-3.5,whilealsorequiring39.0%and15.6%lesstimein evenmorestraightforwardinteractionparadigmisforuserstocon-
Text-to-SQLandPythoncodegenerationtasks,respectively. versationallyrequestcodesolutionsfromLLMs.Forexample,auser
cantypicallyinteractwithChatGPT[29]byposingprogramming
CCSCONCEPTS
questionsandoptionallyprovidinginput-outputsamplestospecify
•Human-centeredcomputing→Naturallanguageinterfaces; requirements.Whenerrorsareidentifiedorthegeneratedcodefails
Userinterfacedesign. tomeetthespecifiedcriteria,usersoftenfollowupwithfeedback
promptingChatGPTtorefinethecodesolution.Thisprocesscan
KEYWORDS runiterativelyuntiltheusersobtainadesiredsolution.Despiteits
simplicity,thedifficultyinaccuratelypinpointingandarticulating
InteractiveCodeGeneration,Non-ProfessionalProgrammers,Large
errorsinageneratedcodemakesitchallengingforuserstopro-
LanguageModels,NaturalLanguageExplanations
videmeaningfulcorrectivefeedback.Toaddresstheproblem,prior
ACMReferenceFormat: researchhasconductedextensiveexplorationontheformatsof
HaoYan,ThomasD.LaToza,andZiyuYao.2018.IntelliExplain:Enhanc- userfeedback[6,12,40,41,45],buttherehasnotbeenavalidated
ingInteractiveCodeGenerationthroughNaturalLanguageExplanations solutionparticularlyfornon-professionalprogrammers.
forNon-ProfessionalProgrammers.InProceedingsof (Preprint).ACM,New Inthiswork,wepresentanovelandeffectiveinteractionsys-
York,NY,USA,18pages.https://doi.org/XXXXXXX.XXXXXXX
tem, dubbed IntelliExplain, which is designed to assist non-
professionalprogrammersinwritinganddebuggingcode.Specifi-
1 INTRODUCTION
cally,IntelliExplainisbuiltuponanovelhuman-LLMinteraction
ThefieldofAI-poweredcodegenerationhaswitnessedasignifi- paradigm,wheretheLLMexplainsitsgeneratedsourcecodein
cantparadigmshiftwiththeemergenceofLargeLanguageModels plainlanguage,promptsuserstoidentifyproblemsandprovide
(LLMs)suchasCodex[7],GPT-3.5&4[1,29],CodeLlama[33],Star- NLfeedbackbasedontheexplanation,andthenrefinesthecode
Coder[22],andCodeT5[42].Unlikepriorapproachesthatrequired solution based on the user feedback. As such, non-professional
trainingtask-specificcodegenerationmodelsandofteninvolved programmerscaneasilywritecodeusingNL,withoutneedingpro-
labor-intensivedatacollectionandannotationefforts,LLMscan fessionalknowledgeaboutprogrammingordirectlyinteracting
learndirectlyfromafewshotsoftaskdemonstrationsfedintheir withthesourcecode(Figure1).ThekeyinsightofIntelliExplain
promptcontext(called“few-shot,in-contextlearning”)[25].Ad- liesintheuseofNLexplanationwhichoffersamoreaccessible
ditionally,theyseamlesslyinterpretandgeneratecodebasedon versionofthesourcecode.Itpresentstousersthelogicandthe
contextualdescriptionsprovidedinnaturallanguage(NL),offer- reasoningprocessfortheLLMtosolvethegivenproblem.One
ing the potential for dramatically improving the efficiency and recent work relevant to us is that of Chen et al. [8], which uti-
accessibilityofcodegenerationtasks.Thisproficiencyisfurther lizesNLexplanationsgeneratedbyanLLMto“selfdebug”itscode
amplifiedthroughtheirinstruction-followingfeatures[9,30,36],al- generation.However,theirexplanationsoften1)tendtobeoverly
lowinguserstoactivelyparticipateinthedecision-makingprocess lengthy,potentiallycausingdisinterestamongusers,and2)contain
byprovidingguidanceacrossmultipleturns.Asusersengagein technical terminologies, which are not understandable by non-
themulti-turninteractionwithLLMs,LLMscaniterativelyrefine professionalprogrammers.Toaddresstheseshortcomings,wefirst
thegeneratedcodeandensureitalignsmorecloselywithusers’ designpromptsthatconvertthemodel-generatedcodeintoamore
intentionsandrequirements.Assuch,LLMshaveshownpromise concise,easilyunderstandable,yetlogicallypreciseNLexplanation
inmitigatingthechallengesassociatedwithlearningunfamiliar fornon-professionalprogrammers.Subsequently,wealsodevise
programminglanguages,reducingdevelopmenttime,andoffering promptsforLLMstoeffectivelyrefinetheircodeanswerbasedon
real-timeassistancetoprogrammers. userfeedback.
However,howtoleverageLLMs’interactivefeaturesinassist- Toassesstheeffectivenessof IntelliExplain,weconducted
ing non-professional programmers to write code remains a chal- auserstudyinvolving20non-professionalprogrammers.Partici-
lenge.Non-professionalprogrammersareindividualswhohave pantswereassignedtwocodingtasks:SQLprogramming,based
basicknowledgeofcomputation(e.g.mathematicaloperation,lin- ontheSpiderdataset[49],andPythonprogramming,basedonthe
ear algebra, etc.) but much less than a computer science major MBPPdataset[2].WeevaluatewhetherIntelliExplaincanas-
orprofessionalengineer.Whiletheymaynothaveorhaveonly sistthesenon-professionalprogrammersinwritingcodecorrectly.
limitedintroductoryprogrammingexperience,theyrecognizethe ResultsfromouruserstudyindicatethatparticipantsusingIntel-
potentialofprogrammingtoenhanceproductivityintheirown liExplainachievedsignificantlyhighersuccessratesinwriting
work.Priorworkhasdominantlyfocusedonthehuman-LLMin- correctcodecomparedtothoserelyingonvanillaChatGPT[29].
teractionforexperiencedprogrammers.Barkeetal.[3]categorized ParticipantswhodidnotuseIntelliExplainfacedchallengesin
user interactions with GitHub Copilot [13] into acceleration or effectivelyinteractingwithChatGPTandspentmoretimeonav-
explorationmodesbasedonuserbehaviorsonhowtoseekhelp erageattemptingtocompletethetasks.Evenparticipantswithno
fromCopilot.Vaithilingametal.[38]systematicallyexploredde- priorprogrammingexperiencewereabletowriteanddebugcode
signprinciplesoftheuserinterfaceforinlinecodesuggestions. solelybyrelyingonthedesignedNLexplanation.Tosummarize:
However,theirexplorationsinthisinteractionparadigmpresup-
posethattheuserpossessessufficientprogrammingexperienceIntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
• WeintroduceIntelliExplain,aprogramming-assistivesys- B A
tembasedonanovelinteractionparadigmthatincorporates
NLexplanationandfeedbackforinteractivecodegeneration.
IntelliExplainisparticularlydesignedfornon-professional
programmersandcanbeappliedtodifferentLLMsacross
varyingcodingtasks.
• WedesignaconciseandstraightforwardNLexplanation
forcodegenerationtoaidnon-professionalprogrammersin
understandinganddebuggingsourcecodewithoutdirectly
interactingwiththesourcecode.
• Ouruserstudywith20non-professionalprogrammersdemon- C
stratesthatIntelliExplaincanassistnon-professionalpro-
grammers,eventhosewithnopriorprogrammingexperi-
ence,inmoreeffectivelywritinganddebuggingcode.
• Weincludeanin-depthanalysisoftheuserstudyresults,
particularlydiscussingthepromiseandchallengesforfu-
tureresearcherspursuingtheresearchofinteractivecode
generationfornon-professionalprogrammers.
Thesourcecodeanddataofourprojectwillbereleasedathttps: Figure2:IntelliExplainstartswiththeloginpage(A)and
//hyan5.github.io/IntelliExplain/. shows up two tabs for different coding tasks (B) for user
selection.IntelliExplainprocessestheuser-uploadedSQL
2 MOTIVATINGEXAMPLE fileandgivesanoverviewofalltablesincludingthreesample
recordsforeachtableintheinterface(C).
Amidaheatedelectionseason,thecampaignheadquartersofa
determinedcandidatebuzzedwithactivity.Emily,astrategistwith
noprogrammingbackground,workshardtounderstandtheelec-
tionsituationandplantheirnextsteps.Sherecognizesthecrucial itas“state”.Shethenprovidedfeedback“Returnanareacode,not
importance of securing support from the area with the highest thestate.” Inthesecondround,IntelliExplaintriedtorefineits
numberofvoters.Shewantstoretrievetheinformationfroma answerbasedonthefeedbackfromEmilyandgeneratedadifferent
publicdatabase.However,shedoesnothavepriorexperiencein codeandexplanation.Emilyconfirmedtheunderstandingwascor-
writingSQL.Emilyinitiallyturnstothewidely-usedAI-powered rect.IntelliExplainthenprovidedthesourcecodeforthelatest
codegenerationmodel,GPT-3.5(ChatGPT).Unfortunately,despite oneasoutput.
herefforts,herinteractionswithGPT-3.5didnotyieldthecorrect
answersasthecodereturnednothingbyexecutingit.Withoutthe 3 RELATEDWORK
abilitytounderstandthegeneratedcode,responsesgeneratedby
3.1 AutomaticCodeGeneration
GPT-3.5containtoomanytechnicalterms,whichmakesithardfor
hertofinderrorsinsidethecodeorconfirmthecorrectnessofthe Automaticcodegenerationaimstoautomatetheprocessofcreating
code.Eventhoughsherequestedthemodeltoexplainitscode,the executablecodefromhigh-levelspecifications,naturallanguage
explanationswerelongandnoteasilyunderstandablebyher.In descriptions,input-outputexamples,orpartialimplementations.
themeanwhile,shenoticesIntelliExplainanddecidestouseitto Withinthislandscape,ourinterestliesincodegenerationmodels,
generatetheSQL. particularlythoseharnessingthepowerofLLMs.Thesemodels
WhenEmilyopensIntelliExplain,aloginpageisdisplayed autonomouslygraspprogramconceptsfromvastcoderepositories
to facilitate the storage and retrieval of personal usage history withoutbeingconstrainedbyspecificlanguagesortaskdomains.
(Figure2A).AftersuccessfullogintoIntelliExplain,theuser Recently,theapplicationofLLMsasprogrammingassistantshas
interfaceappearsandcontainstwotabsfordifferentcodegenera- gainedsubstantialinterestinbothNaturalLanguageProcessing
tiontasks(Figure2B).Emilyselectstext-to-SQLasshewantsto (NLP)andHuman-ComputerInteraction(HCI)communities.Mc-
writeanSQLquery.ShedownloadedtheSQLfilefromtheofficial Nuttetal.[27]delvedintotheintegrationofLLM-basedcodeassis-
websiteanduploadedittoIntelliExplain.Shethenenteredthe tantswithinnotebooks,exploringtheiradaptabilityandpotential
question“Whatistheareacodeinwhichthemostvotersvoted?”. impact.Döderleinetal.[10]exploredtheimpactofinputcontent
IntelliExplainprocessestheSQLfileandshowsanoverviewof andmodelparametersontheoverallperformanceofthefinalout-
alltablesandthreesamplerecordsforeachtable(Figure2C).In- putcode.Despitetheirstrongcapabilitiesincodegeneration,these
telliExplain,asshowninFigure3,firstpredictsaninitialcode LLM-poweredapplications[2,34,44]oftenassumeuserspossess
inthebackendandconvertsittoanunderstandableexplanation. specificknowledgeforeffectivecodegeneration,posingchallenges
Afterthat,IntelliExplainpresentstheexplanationtoEmilyinthe fornon-professionalprogrammers.Recognizingtheselimitations,
interfaceandrequestsvalidationonitsunderstandingoftheinput ourworkisdedicatedtodesigninganinteractionparadigmthat
question.Emilycheckedtheexplanationandfoundshewantedthe isnotonlymoreeffectivebutalsoeasiertouse,aimingtobetter
“areacode”butintheexplanation,IntelliExplainunderstands assistnon-professionalprogrammersintheircodingtasks.Preprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
Interaction turn #1
D
Interaction turn #2
D
Interaction turn #3
Figure3:Theconversationbeginswiththeuserposinganinitialquestion,followedbyanexplanationoftheLLM-generated
codeinresponse(turn#1).Inthenextturn,theuserofferscorrectivefeedbacktohelptheLLMfixanyerrorsdetectedinthe
explanation.TheLLMthenexplainstherevisedcodetotheuser(turn#2).Finally,theuserconfirmsthecorrectnessofthecode
explanationandexpressesconfidencethatthequestioncanbeaddressedusingthecurrentcode(turn#3).
3.2 InteractiveCodeGeneration
toselectthecorrectcomponentsasaformoffeedback.Another
Theresearchofinteractivecodegenerationhasbecomeanimpor- approach,proposedbyLietal.[23],identifieduncertaintokensin
tanttopicevenbeforethepopularizationofLLMs[5,12,19,23,28, theuser’sNLcommandsandsoughtuserchoicesforparaphrases
35,37,46,48].Aninteractivecodegenerationsystemtypicallycon- toenhanceclarity.However,thetraditionalmulti-choicefeedback
sistsofthreecomponents:acodegenerationmodel,amechanism paradigm,whileeffectiveinerrorcorrectionfortext-to-SQLgener-
toidentifyandrequestuserfeedbackonerrorsinthepredicted ation,exhibitedlimitationsintermsofuser-friendliness,efficiency,
code,andanerrorcorrectionmodeltorefinethecodebasedonuser andgeneralizabilitytomorecomplexprogramminglanguages.In
feedback.Previousstudieslookedintointeractivecodegeneration particular,userscouldonlypassivelyrespondtosystem-presented
throughamethodcalledprogramming-by-examples(PBE),where choices,posingchallengesinfacilitatingamoredynamicanduser-
usersdefinehowaprogramshouldbehavebygivinginput-output centricinteraction.Toaddressthis,free-formNLfeedbackhasbeen
examples. Zhang et al. [50] offered methods to augment input- introduced[12,19].Elgoharyetal.[12]demonstratedtheeffective-
outputexamplesandhelprefinetheuser’strueintent.Drososet nessandpromiseincorrectingparsingerrorsviaNLfeedbackand
al.[11]proposedWrexwhichcreatesaprogramming-by-example annotatedSPLASHdataset.Chenetal.[6]proposedanalgorithm
environmentwithinacomputationalnotebook.Lahirietal.[20] forimprovingacodegenerationmodelfromNLfeedback.However,
triedtogeneratetestsuggestionsthatalignwithhumanintent. thosemethodsrequiretrainingorfine-tuningadditionalmodels,
However,evenproficientprogrammerscannotproviderepresenta- whichbecomesimpracticalwithLLMshavinganextremelylarge
tiveexamplesthatcoverasmanyaspossiblepracticalsituations. amountofparameters.
Consequently, while the provided or augmented examples may AsLLMsenhancetheirabilitytofollowinstructions,interactive
matchtheexpectedoutput,theymaydeviatefromtheuser’sin- codegenerationhasgainedincreasedattentionandisbeingex-
tendedbehaviorwhensubjectedtounseencases.Inadditionto ploredextensivelyincurrentresearchefforts[3,4,15,17,24,38,39].
interactionthroughexamples,priorworkshaveutilizedmultiple- Despitetheseadvancements,aremainingchallengeishowtoseam-
choicefeedbackmechanisms.StudiesconductedbyGuretal.[14] lesslyintegratecodegenerationmodelsintointerfaces,makethem
andYaoetal.[47]approachedthisbyexplainingcomponentsina understandable,andgiveusersasenseofcontrol.Thischallenge
generatedSQLcode,andifthelogiciswrong,userswereprompted promptstheneedforfurtherexplorationandrefinementtoenhance
theoveralluserexperienceininteractivecodegeneration.Rossetal.IntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
[32]demonstratedtheefficacyofaconversationalprogramming solution,requestsuserfeedbackontheexplanation,andrefinesits
assistantpoweredbyanadvancedLLMinansweringqueries,gen- generationbasedonthefeedback,untiltheuserissatisfiedwith
eratingcontext-specificcode,andfacilitatingfollow-upquestions. thecodesolution.Ourapproachtodesigningsuchaninteraction
Jiangetal.[16]proposedGenLine,anIDE-basedLLM-powered paradigmfornon-professionalprogrammerswasshapedbyseveral
codeassistantforwebdevelopment,leveragingNLandcommand- keydesigngoals.
likehuman-LLMinteraction.However,itisimportanttonotethat (1)Enablenon-professionalprogrammerstounderstand
thesetoolsareprimarilydesignedforexperiencedprogrammers the model-generated code and identify errors without di-
andmayposechallengesfornon-professionalprogrammers,espe- rectlyinteractingwiththecode.Thismeansmakingexplana-
ciallythoseunfamiliarwiththeIDEenvironment.Inourwork,we tionssimple,avoidingtechnicaljargon,andmaintainingclarity
tacklethisissuebyintroducingNLexplanationaimedatprovid- andconciseness.Beyondunderstandingthemodel-generatedcode,
ingasimpleandeasywayfornon-professionalprogrammersto itisessentialthatuserscaneffectivelyprovidefeedbackonany
interactwithcodegenerationmodelspoweredbyLLMs.Thisis errorsidentifiedwithintheexplanation.Thisrequiresthedesignof
astepforwardinclosingthegapfornewprogrammers,making explanationscapableofaccuratelycapturingerrorsinthesource
interactivecodegenerationmoreaccessibleanduser-friendly. code.Toachievethis,theNLexplanationsshouldclarifythecode’s
functionalityandbestructuredlogicallytoguideusersthrough
3.3 LLMInterpretabilityandExplanability thethoughtprocessbehindthegeneratedcode.Bypresentingthe
informationlogically,userscaneasilyunderstandthereasoning
WiththeuseofNLexplanations,ourworkisalsorelatedtoexisting
behindeachcodeelement,therebyboostingtheirconfidenceand
effortsininterpretingandexplainingLLMs.Amongothers,Raietal.
capabilitytoengagewiththesystem.Thisiterativefeedbackloop,
[31]presentedoneofthefirstworksonpost-hocexplanationsof
whereuserscanreadilyidentifyandarticulateissueswithinthe
LLMsforcodegeneration.MacNeiletal.[26]exploredtheintegra-
explanation,iscrucialforrefiningthemodel’soutputandimprov-
tionofcodeexplanationsgeneratedbyLLMsintoaninteractive
ingtheoveralleffectivenessoftheinteractionparadigm.Thisgoal
e-bookonwebsoftwaredevelopmentandassessedstudentengage-
raisestheresearchquestions(RQ):
mentandutilityacrossdifferentexplanationtypes.Sarsaetal.[34]
• RQ1:CanthedesignedNLexplanationaccuratelydescribe
examinedtheabilitiesofLLMsinproducingprogrammingexer-
thesourcecode?
cisesandcodeexplanations,findingthatthemajorityofgenerated
• RQ2:CanusersprovideeffectivefeedbackbasedontheNL
contentisbothnovelandcoherent,withpotentialapplicationsin
explanation?
educationalsettings.Lampinenetal.[21]evaluatedhowdifferent
typesofexplanations,instructions,andcontrolsaffectzero-and (2)Incorporateuserfeedbackforerrorcorrection.Theinter-
few-shotperformanceofLLMs.Weietal.[43]andKojimaetal.[18] actionparadigmmustseamlesslyintegrateuserfeedbacktorefine
demonstratedthatthegenerationofreasoningstepscontributesto thegeneratedcode.Inourdesign,usersinteractwithexplanations
theproductionofaccuratefinalanswers.Chenetal.[8]explored withoutseeingthesourcecode.Thisthusleadstoapotentialdis-
theself-debugabilityofLLMswhenpromptingthemodelstogener- crepancy, i.e., the user feedback targets errors presented in the
ateNLexplanationstotheirownpredictions.However,noneofthe explanation,ratherthandirectlythesourcecode.Itresultsina
priorworksexploredthepossibilityofusingsuccinctexplanations researchquestion:
ininteractivecodegenerationfornon-professionalprogrammers. • RQ3:Canuserfeedbackbasedontheexplanationbesuc-
cessfullyappliedtothesourcecodeforerrorcorrection?
4 INTERACTIVECODEGENERATIONFOR
Intheremainingsection,wewillfirstgivedetailsofourexpla-
NON-PROFESSIONALPROGRAMMERS
nationinSection4.2andthenpresentourdesignedinteraction
BASEDONNLEXPLANATIONS paradigminSection4.3.
4.1 DesignGoals
4.2 NaturalLanguageExplanation
Weaimtodesignaneffectiveandeasy-to-useinteractionparadigm
The most straightforward prompt is to ask the LLM to explain
fornon-professionalprogrammers.Inthispaper,weusetheterm
theirprediction.However,thisvanillaapproachoftenresultsin
non-professionalprogrammerstoencompassbothnoviceandend-
explanationsthatarelengthyandtootechnicaltobereadbynon-
userprogrammers.Noviceprogrammersareindividualswhoare
professionalprogrammers.Toaddressthislimitation,wepropose
newtoprogrammingandhavelimitedexperienceorknowledge
twodistinctstylesforprogramexplanations:
inwritingcode.Incontrast,end-userprogrammersareindivid-
ualswho maynot haveformal trainingin computerscienceor 4.2.1 QuestionRestatementfromSourceCode. Inourpreliminary
softwareengineeringbutuseprogramminginterfacestoautomate experiments, we observed that a significant portion of LLM er-
tasks,developscripts,ormodifyexistingsoftwareapplicationsfor rorsintext-to-SQLstemmedfromamisunderstandingofconcepts
personalorprofessionaluse.Ourconceptofnon-professionalpro- withintheoriginalquestion.However,suchmistakescanhardly
grammersbridgesthesecategories,addressingtheneedsofboth be captured from a vanilla explanation of the SQL code, which
thosenewtoprogrammingandthoseseekingtoutilizeprogram- isoftenfulloftechnicaljargondistractingusersfromidentifying
mingtoolsforspecifictaskswithoutextensiveexpertise.Withthis conceptsinvolvedinthecode(Figure1,right).Observingthischal-
definitioninmind,weproposeanovelinteractionparadigm,where lenge,weinsteadproposetouse“restatedquestion”fromthesource
theLLM-poweredsystemrepeatedlyexplainsitsgeneratedcode codeasanexplanationfortext-to-SQLprogramming(Table1).APreprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
TranslatethefollowingSQLintoquestion.Thequestionshouldbe YouareanexpertPythonprogrammer.Yourtaskistowriteade-
consistentwiththeSQLandfollowasimilarstyleastheoriginal scriptionforthefollowingPythonprogram.Thedescriptionshould
question. beaccurate,concise,andeasilyunderstoodbynon-programmers.
[...tripletsof<SQL,OriginalQuestion,RestatedQuestion>asfew- [...pairsof<PythonProgram,Explanation>asfew-shotdemonstra-
shotdemonstrations...] tions...]
PythonProgram:
SELECT status_code FROM bookings GROUP BY status_code ORDER import math
↩→ BY count(*) DESC LIMIT 1 def is_not_prime(n):
OriginalQuestion:Whatisthemostfrequentstatusofbookings? result = False
for i in range(2,int(math.sqrt(n)) + 1):
Explanation(RestatedQuestion):Whichstatuscodeappearsmost if n % i == 0:
ofteninbookings? result = True
Table 1: Restated Question from Source Code as Explana- return result
tion.Explanationinthisformatseeksadirectandhigh-level
descriptionofthesourcecode.Bycomparingtherestated Explanation(ConciseDescription):Thisprogramchecksifagiven
numberisnotaprimenumber.Itdoesthisbyiteratingthrough
questionwiththeoriginalone,userscaneasilyidentifyany
allnumbersfrom2tothesquarerootofthegivennumberand
conceptmisunderstandingmadebytheLLM,whichiscom-
checkingifanyofthemdividethenumberevenly.Ifadivisoris
monintext-to-SQLprogramming. found,theprogramreturnsTrue,indicatingthatthenumberisnot
prime.Otherwise,itreturnsFalse,indicatingthatthenumberis
prime.
Table2:ConciseDescriptionofSourceCodeasExplanation.A
concisedescriptionincludesmoredetailsaboutthethought
restatedquestionisanNLquestiongeneratedbytheLLMtode-
processbehindthesourcecodeandthusenablesusersto
scribetheintentofamodel-generatedcode.Priorwork[23]found
identifylogicerrorsinit.
that,bypromptinguserstocomparetherestatedquestionwith
theoriginalone,theycaneasilyspotanymismatchedconcepts.To
non-professionalprogrammers,suchexplanationsareveryconcise
anddonotinvolveanytechnicalterminologies,renderingthem
notonlyeffectivebutalsoeasytounderstand.Ourinvestigation Tothisend,wefirstrandomlyselect8examplesandannotateeach
revealedthaterroridentificationismorestraightforwardwhen withahuman-writtendescription.Thisdescriptionconsistsofa
twoNLquestionsshareasimilarlinguisticstructure.Toalignthe briefintroductionsummarizingthepredictedcodeatanabstract
restatedquestionwiththestyleofthesourcequestion,weaddition- level.Followingthisintroductionisadetailedbreakdownofthe
allyincludetheuser’sinitialquestioninthepromptandexplicitly logicbehindthecode,illustratinghowLLMsolvesthequestion.
instructtheLLMtoproducearestatedquestionfollowingasimilar Incontrasttoaline-by-lineexplanation,ourconcisedescription
languagestyle.Together,thesedesignconsiderationsresultinour offersamorereadableandrelativelyshorterpresentationofthe
promptforquestionrestatementfromthesourcecodeinTable1. codewhileensuringtheinclusionofcrucialdetails.Theannotated
Specifically,weprompttheLLMtogeneratetherestatedquestion examples then serve as the few-shot demonstrations when we
giventhesourcecodealongwithtaskinstruction“Translatethe promptanLLMtogeneratetheexplanation.Asamplepromptis
followingSQLintoquestion.Thequestionshouldbeconsistentwith showninTable2.
theSQLandfollowasimilarstyleastheoriginalquestion.”Toprompt
anLLMtogeneraterestatedquestionsfollowingthisdesign,we 4.3 InteractionParadigm
manuallywrote13tripletsof<SQL,OriginalQuestion,Restated
Toutilizeourdesignedexplanationforassistingnon-expertpro-
Question>asfew-shotdemonstrations.TheSQLquerieswerese-
grammersincodingtasks,weintroduceaninteractionparadigmas
lectedtoencompassabroadrangeofsyntaxthatmayappearin
showninFigure4.Weincludedsampleprompttemplatesforeach
thegiven programminglanguage, suchaskeywords “SELECT”,
stageusedinourparadigminAppendixA.
“WHERE”,“DISTINCT”,etc.
4.3.1 CodeGeneration. Theuserfirstasksacodingquestionand
4.2.2 ConciseDescriptionofSourceCode. Inourexploration,we
providesrelatedcontext(e.g.,databaseschemafortext-to-SQLand
observedthatquestionrestatementprovestobemoreeffectivefor
testcasesforPythoncodegeneration)forcodegenerationthrough
shortcodesnippets,likeSQLqueries,andcaneffectivelyaddress
IntelliExplain.ThebackendLLMthentriestogenerateaninitial
conceptualmisunderstandingerrors.However,itcannotcapture
answercode.Thisinitialcodegenerationisachievedviafew-shot
theinnerlogicalerrorsinscenariosinvolvinglengthygenerated
in-contextlearning,wherewefeedtheLLMwithafewexamples
codeandintricatecodingtasks,especiallywhentheLLMmakes
demonstratingthecodegenerationtask.Thespecificpromptswe
aninaccurategenerationdespitecorrectlyunderstandingtheinput
adoptareadaptedfromthatofChenetal.[8]fortext-to-SQLand
question.Thisraisesaneedforamorefine-grainedexplorationof
Austinetal.[2]forPythoncodegeneration.
theinnerlogic.Weachievethisbyproposingaconciseexplanation
ofthesourcecode,strikingabalancebetweenthesuccinctquestion 4.3.2 ExplanationGeneration. Aftertheinitialcodeisgenerated,
restatementandthetechnicalandlengthyline-by-lineexplanation. thebackendLLMthengeneratestheNLexplanationtoexplainIntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
5 USERSTUDY
User Feedback
Request WeevaluateIntelliExplainbyconductingauserstudyinvolving
20participants.Thepurposeofthestudywastogaininsightinto
3 Explanation
1 Question + hownon-professionalprogrammersperceiveandinteractwithan
task-specific content Code 2 Initial Code Explanation NLexplanationofcodeinprogramminganddebuggingtasks.
Generation Generation
5.1 Participants
4 User Feedback Error 5 Corrected Code Torecruitnon-professionalprogrammers,wetargetedundergradu-
Correction
atestudentsfromarangeofmajorsthroughrecruitmentflyersand
advertisingemails.Eachapplicantcompletedademographicsurvey
Initial/Corrected Code + Explanation withitemsontheirprogrammingbackgroundandexperiencelevel.
Wespecificallyselectedparticipantswhowerebeginnersinpro-
Figure4:InteractionParadigm.Ourdesignedinteractionpar-
gramming,suchasfirst-yearcomputersciencestudentswhohad
adigmconsistsof(1)useraskingacodingquestionandpro-
onlycompletedanintroductoryprogrammingcoursewithmini-
vidingthenecessarycontextthatarenecessaryforanswering
malpracticalexperience,aswellasindividualsfromnon-computer
thequestion;(2)LLMpredictinganinitialcodeanswer;(3)
sciencemajors,whohadnopriorprogrammingexperiencebut
LLMgeneratinganNLexplanationfortheinitialcode;(4)
werefamiliarwithbasicmathematicallogicandcouldbenefitfrom
userjudgingtheexplanationanddeterminingwhetherthe
programmingintheirrespectiveworks.
codeiscorrect;ifanyerrorisfoundintheexplanation,user
From50applicants,werecruited22participantsintotal.20partic-
providingNLfeedbackforerrorcorrection;and(5)theLLM
ipantscompletedthestudy.Ofthetwowhodidnot,oneparticipant
refiningitsanswerbasedonuserfeedback.Steps3-5repeat
encountereddifficultiesduringthewarm-uptasks,strugglingto
untiluserscannotfindmoreerrorsintheexplanation.
understandthebasicconceptsdescribedinthematerials.Asare-
sult,theparticipantoptedtowithdrawfromthestudy.Asecond
participantcouldnotunderstandthebasicconceptsofdatabase
thecode.AsintroducedinSection4.2,weadoptquestionrestate-
queryingandonlycompletedthetestquestionsforPythoncode
mentasexplanationsfortext-to-SQLandconcisedescriptionas
generation.Fortheremaining20participantswhocompletedthe
explanationsforPythoncodegeneration.
fulluserstudy,noneofthemhadsignificantexperiencewithboth
programminglanguages.18outof20participantsreportedthat
4.3.3 UserFeedbackRequest. IntelliExplainthenpresentsthe
they did not have any experience in database and SQL queries,
NLexplanationandtheexecutionresultsbyrunningthegenerated
whiletheremaining2tookdatabaseclassesatuniversitybuthad
codetotheuser,andseeksfeedbackonwhethertheirquestion
nopracticalexperience.1outof20participantsreportedthatthey
iscorrectlyaddressed.Weemploydifferentstrategiesfortext-to-
hadnopriorexperienceinPython,whiletheremaining19had
SQLandPythoncodegeneration.Intext-to-SQL,werequestuser
takenanintroductoryPythonclass.Additionally,3outof20partic-
feedbackbyaskingusers“HereiswhatIunderstandbasedonyour
ipantsreportedthattheyhadattemptedtouseChatGPT[29]for
question:[restated_question].Ifyouthinkthatmyunderstandingis
coding.
correct,youcanmarkthisquestionas“complete”.Currentprediction
willbesavedasfinalanswer.” ForPythoncodegeneration,weinte-
grateanexternalPythoncodeinterpretertoevaluatewhetherthe 5.2 Setup
generatedcodepassesalltests.Ifthemodel-generatedcodefails
5.2.1 BackendLLMandTestingQuestionSelection. WeuseGPT-3.5
anytests,userswillbepromptedwith,“ThecodeIgenerateddid
(version:turbo-0613)asourbackendLLMandinclude10questions
notpassalltestcases.Couldyouidentifywhatiswrongwithit?Here
foreachtaskfromtheSpider[49]andtheMBPP[2]dataset,re-
isadescriptionofthecode:[code_description].Theexecutionresults
spectively,whereGPT-3.5demonstratederrorsinitsinitialcode
aredisplayedonthetopright.”Followingtheinstructions,userscan
generation.Fortheuserstudyresultstobereliableacrossprogram-
thenwritetheirfeedbackinNL,pointingouterrorsoridentifying
mingquestionswithvariouscomplexities,wechosethequestions
anymissingrequirementsfoundintheexplanation.
carefullybasedontheirdifficultylevels.Fortext-to-SQL,wefollow
4.3.4 ErrorCorrection. Afterreceivingtheuserfeedback,theback- thesamecriteriaproposedinSpider[49]anddefinethequestion
endLLMperformserrorcorrectionbytakingtheinitialcode,itsNL difficultybasedonthenumberofclausesandconditionsinvolved
explanation,andtheuserfeedbackasinput,andthengeneratinga intheground-truthSQLquery(e.g.,queriesthatcontainmoreSQL
newsourcecodeasthecorrectedsolution.Thiscorrectiontaskis keywordsareconsideredtobeharder).ForPythoncodegenera-
similarlyformulatedasfew-shotin-contextlearning,forwhichwe tion,wedefinethedifficultylevelbythesyntaxcomplexityand
include4human-annotatederrorcorrectionexamplesasdemon- readability(e.g.,alongercodecontainingnestedfunctioncallsis
strationsintheprompttoguidetheLLMonhowtoperformthis consideredharder).Specifically,werandomlysampled20questions
task.Afterthiserrorcorrection,thebackendLLMgeneratesanew for each task, manually assessed their difficulty level, and then
explanationfortherevisedcodesolution.IntelliExplainseeks retained10ofthemthatwereevenlydistributedacrossdifferent
furtheruserfeedback,andrepeatstheprocessuntiltheusercannot difficultylevels.Finally,participantswereprovidedwiththesame
findmoreissueswiththecodesolution. setoftestquestionsforeachtaskforconsistency.Preprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
A A B
C
B
C
D D
Figure5:Theuserinterface(UI)usedinthestudy.Forbothtasks,theUIconsistsof4components:(A)Backgroundcontent
thatcanbeusedtoanswerthequestion(e.g.,sampledatabaserecordsforText-to-SQLandtestcasesandexpectedoutputs
forPythonCodeGeneration);(B)Executionresults,whicharereturnedvaluesbyexecutingthepredictedcodeagainstthe
databaseortestcases;(C)Chatbot,showingtheconversationhistorybetweenuserandtheLLMandincludingatextboxfor
userinput;and(D)Controlpanel,includingthreefunctionalbuttons.
5.2.2 BaselineSystem. Forcomparison,weconsidervanillaGPT- thecorrectanswerafteraseriesofinteractions.InthebaselineUI
3.5asthebaseline.Forafaircomparison,wepromptedthebaseline withvanillaGPT-3.5,executionresultsareomitted.Thisisbecause
systemwiththesamefew-shotexamplesininitialcodegeneration, GPT-3.5doesnotconsistentlyprovidepurecodeasaresponse.As
which resulted in model-generated code containing exactly the aresult,itbecomeschallengingtodistinguishthecodefromits
sameerrorsasIntelliExplain’sinthefirstround.Then,users responsesandexecuteit.
werefreetointeractwithGPT-3.5,andnoadditionalpromptswere Currently,theUIprimarilyservesthepurposeofconducting
employedinthefollowinginteractions.Thebaselinesystemshared userstudies.Toensureconsistencyandcomparabilityacrossall
thesameUIandtestquestionsasIntelliExplain.Theonlydif- participants, users are restricted from posing their own coding
ferenceisthatweremovedtheexecutionresults(componentBin questions.Instead,allquestionsarepredetermined,andusersare
Figure5)fromtheUIofvanillaGPT-3.5sinceitishardtoextract notrequiredtoprovideanyrelevantcontextthemselves.Inpractical
purecodefromitsgeneration.Participantswerethenrandomly use,IntelliExplaincanbeextendedtoacceptarbitraryuserinput
splitintotwogroups(10foreach),interactingwitheitherIntelli- andoffersafunctionbuttonforuserstouploadfilesrelevantto
ExplainorthevanillaGPT-3.5. theirspecificneeds.
5.3 UserInterface
5.4 StudyProcedure
WedesignedaUserInterface(UI)(Figure5)fortheproposedinter-
actionparadigmwithGradio1andusedittoconducttheuserstudy. The user study comprised three phases: warm-up tasks, formal
Intext-to-SQL,theUIincludesadatabase,containingalltables study,andapost-taskinterview.Recognizingthatallparticipants
andtheirattributesalongwiththreesamplerecords;execution enteredthestudywithlimitedexperienceinthespecifiedtasksand
results,showingthereturnvaluesbyrunningthepredictedcode wereunfamiliarwithourUI,weinitiatedthestudywithawarm-up
againstthedatabase;andChatbot,showingtheconversationhis- session.Anexperimenterprovidedanoverviewofthetwotasks
torybetweentheuserandLLM.ForPythoncodegeneration,ourUI andintroducedparticipantstothevariousfunctionalitiesembed-
includesapanelshowingthetestcasesandtheirexpectedoutputs. dedwithinourUI.ParticipantsthenactivelyengagedwiththeUI,
Theexecutionresultsshowthevaluesreturnedbyrunningthe tacklingtwowarm-upquestionsforeachtasktofosterfamiliarity
predictedcodeagainsttheprovidedtestcases.Inbothinterfaces,a andproficiency.Throughoutthiswarm-upsession,participants
textboxisprovidedasanentrypointforuserstointeractwiththe wereencouragedtoposeanyquestionsrelatedtothetasksorcod-
LLM.A“Complete”buttonisprovidediftheuserthinksthecurrent ingprocess,fosteringacollaborativeandinformativeenvironment.
predictioniscorrectandwantstoproceedtothenextquestion.Two Thewarm-upsessionwasessentialforgettingparticipantsfamiliar
“Skip”buttonsareprovidedforcaseswhereparticipantsstruggleto withthetasksandhelpingthembecomecomfortableusingtheUI.
understandthegivenquestionorwhentheLLMfailstogenerate Participantscouldaskquestionsaboutthetasksorcodingduring
thestudy,providingthemwithmoreclarity.Afail-safewasin-
1https://www.gradio.app. cluded,soifparticipantsfoundthetrainingquestionschallengingIntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
orfacedissueswiththeUI,theywereguidedtoendtheirparticipa- SuccessRate(%) Avg.Time/Question(s)
System
tion.Uponsuccessfulcompletionofthewarm-uptasks,qualified Text-to-SQL
participantsthenproceededtotheformalstudy,wheretheywere
IntelliExplain 21.9(𝑆𝐷=0.220) 90.0(𝑆𝐷=35.971)
taskedwithindependentlysolvingasetofchallengingtestques- VanillaGPT-3.5 10.3(𝑆𝐷=0.151) 147.6(𝑆𝐷=57.528)
tions.Duringthisevaluativephase,theexperimenterassumeda
PythonCodeGeneration
passiverole,interveningsolelytoaddressclarificationquestions
orresolveanytechnicalissuesencounteredbytheparticipants.
IntelliExplain 51.7(𝑆𝐷=0.163) 152.8(𝑆𝐷=53.085)
VanillaGPT-3.5 26.4(𝑆𝐷=0.337) 181.2(𝑆𝐷=46.911)
Thisintentionalshiftallowedforanauthenticassessmentofthe
Table3:OverallperformanceontestingquestionsusingIn-
system.Toencourageanefficientcompletionoftheuserstudyand
telliExplainandvanillaGPT-3.5.Wereportedtheaverage
topreventparticipantfatigue,weseta5-minutetimelimitforeach
successrate(inpercentage)andtimespent(inseconds)for
question.Participantswereinstructedtoskipanyquestionthey
eachparticipant.IntelliExplainoutperformsvanillaGPT-
couldnotsolvewithinthistimeframe.Afterthethoroughformal
3.5insuccessrateandtypicallyneedslesstime.
study,participantstookpartinareflectiveinterviewtosharetheir
thoughts.Thisinterviewprovidedtheexperimenterwithachance
toexploreparticipants’experiencesandgatherdetailedfeedback
onusingthesystem.Theinterviewquestionscoveredvariousas- across4distinctquestionswereskippedoutofthe100totalsamples
pects,fromoverallexperiencestospecificcomponentsthatassisted (10participantsby10testquestions).InPythoncodegeneration,15
theminsolvingcodingtasksorchallengestheyencounteredduring samplesacross7distinctquestionswereskippedoutofthe100sam-
theformalstudy,givingparticipantsaplatformtoexpresstheir ples.Forremainingquestions,wekeptthemallinouranalysiseven
thoughtsfully. forthoseskippedquestionsdueto“Cannotgetthecorrectanswer”.
Byemployingthiscarefulthree-phaseapproach,ouruserstudy EvenusersthoughtIntelliExplaincouldnotcorrecttheerrors
aimedtoobjectivelyevaluatetheperformanceof IntelliExplain, basedontheirfeedback,theyidentifiederrorsintheexplanation
collectqualitativeinsightsregardinguserexperiences,andfacilitate andtriedtocorrectthem.
acomprehensiveexplorationofpotentialchallenges. IntelliExplainenablesuserstoachievesuccessrates11.6%and
25.3%higherthanthevanillaGPT-3.5groupintext-to-SQLand
6 RESULTS
Pythoncodegeneration,respectively.Thet-Testshowedthatthe
6.1 Evaluation meansbetweenthetwogroupsarestatisticallysignificantinsuccess
rate(SQL:𝑡 =1.935,𝑝 =0.043;Python:𝑡 =2.361,𝑝 =0.021)and
Forevaluation,wereporttheSuccessRateofwhetherusercan timespentoneachquestionfortext-to-SQL(SQL:𝑡 =−2.611,𝑝 =
obtainthecorrectanswercodeusingeachsystemonbothtasks.For 0.014), but no difference in time spent per question for Python
text-to-SQL,weadopttheofficialexecutionaccuracymetricfrom codegeneration(Python:𝑡 =−1.374,𝑝 =0.101).Thisobservation
Spider[49],whichcomparestheexecutionresultsbetweentheLLM-
couldbeattributedtothemorecomplextaskandmorefine-grained
generatedcodeandtheground-truthcodeagainstthedatabase.For
explanationsinPythoncodegeneration.Participantsfromboth
Pythoncodegeneration,weexecutethegeneratedcodeagainstthe
groupsneededmoretimetonavigateandcomprehendthetask.
giventestcasestoseewhetherthecodecanpassalltests.Inaddition,
Thissubstantialperformanceimprovementservesasaquantita-
wealsoreporttheaveragetimespentperquestion(denotedas
tivevalidationoftheeffectivenessof IntelliExplainandaligns
“Avg.Time/Question”)tomeasurehowefficientofusersusingeach
seamlesslywiththequalitativefeedbackgatheredduringpost-task
systemincodingtasks.Foreachreportedmetric,wereportthe
interviews:“Thissystemprovidedmewithanamazingexperience
meanandthestandarddeviation.Anindependentsamplest-Test
thatIhadneverhadbefore”;“Yoursystemisreallyhelpfulformein
withanalphalevelof0.05wasusedtodeterminewhethertherewas
programming.I’mnotveryskilledatprogramming,butwithyour
statisticalevidencethattheassociatedpopulationmeansbetween
system, I find it easy to understand and write code using natural
thetwoconditionsweresignificantlydifferent.Inthissection,we
language.”;“Yoursystemisparticularlyusefulbecauseofitsnatural
firstpresentanoverviewoftheoverallperformanceachievedusing
languageexplanations,allowingmetounderstandanddebugcode
ourdesignedinteractionparadigmwithdesignedNLexplanation
withoutneedingtoinspectthesourcecodedirectly”,etc.Participants
andfeedbackfromtheuserstudy.Then,welookintoeachpart
consistentlyreportedamoresatisfactoryexperiencewhenusing
morecloselyforadetailedanalysis.
IntelliExplain,highlightingitseffectivenessinenhancingthe
overalluser-LLMinteractionincodegeneration.Moreover,the
6.2 OverallPerformance
advantagesof IntelliExplainextendbeyondmeresuccessrates.
Table3presentstheaveragesuccessrateofourtestingquestions Inadditiontotheimprovedsuccessrate,IntelliExplainalsore-
acrossallparticipantsutilizingtwosystems.Theresults(aswell ducesusers’timeby60secondsperquestionintext-to-SQLand25
asourfollow-upanalysis)haveexcludedtestsampleswherethe secondsperquestioninPythoncodegeneration.Thisadvantage
participantsindicateddifficultyinunderstandingtheinitialques- showsthatourdesignedinteractionparadigmisnotonlyimproving
tionandhenceskippedit(“Cannotunderstandthequestion”).In themodel’sperformancebutisalsomorepracticalandefficient.
text-to-SQL,6suchtestsamplesacross4distinctquestionswere WethenlookintowhatexactlymakesIntelliExplainwork
skipped out of the 100 total samples (10 participants by 10 test betterandquicker.Weattachedoneexamplefromouruserstudy
questions);inPythoncodegeneration,15samplesacross7distinct forPythoncodegenerationinFigure6(anexampleofSQLcode
questionsweresimilarlyskipped.Intext-to-SQL,6testsamples generationhasbeenpresentedinFigure1).Inthisexample,thePreprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
(Question) (Tests)
User seeks Write a python function to find the last digit when factorial of a compute_Last_Digit(2,4) == 2
help for code divides factorial of b. compute_Last_Digit(6,8) == 6
generation compute_Last_Digit(1,2) == 2
IntelliExplain (ours) Vanilla GPT-3.5
I generated a code that cannot pass all test cases. Can you tell
me what is wrong with my code? Here is the description of my Here is the Python function to find the last digit when the factorial
code: of a divides the factorial of b:
This program calculates the last digit of the result when
computing the factorials of two given numbers, 'a' and 'b'. It uses ddeeff ccoommppuuttee__LLaasstt__DDiiggiitt((aa,, bb))::
the math module to calculate the factorials of 'a' and 'b'. Then, it ddeeff ffaaccttoorriiaall((nn))::
finds the last digit of each factorial by taking the modulus of 10. If iiff nn ==== 00 oorr nn ==== 11::
the last digit of 'a' is 0, it returns 0. If the last digit of 'b' is 0, it
rreettuurrnn 11
returns the last digit of 'a'. Otherwise, it returns the last digit of 'a'
modulo the last digit of 'b'. eellssee::
The execution results are shown on the top right. (Explanation) rreettuurrnn nn ** ffaaccttoorriiaall((nn--11))
(Execution Results: 2, 0, 1) ffaaccttoorriiaall__aa == ffaaccttoorriiaall((aa))
ffaaccttoorriiaall__bb == ffaaccttoorriiaall((bb))
Divide factorial of b by factorial of a and find return the last digit.
llaasstt__ddiiggiitt__aa == ffaaccttoorriiaall__aa %% 1100
(Feedback)
llaasstt__ddiiggiitt__bb == ffaaccttoorriiaall__bb %% 1100
iiff llaasstt__ddiiggiitt__aa ==== 00 oorr llaasstt__ddiiggiitt__bb ==== 00::
I generated a code that cannot pass all test cases. Can you tell
me what is wrong with my code? Here is the description of my rreettuurrnn 00
code: iiff llaasstt__ddiiggiitt__aa ==== llaasstt__ddiiggiitt__bb::
This program calculates the last digit of the result when rreettuurrnn llaasstt__ddiiggiitt__aa
computing the factorials of two given numbers, 'a' and 'b'. It uses
rreettuurrnn llaasstt__ddiiggiitt__aa
the math module to calculate the factorials of 'a' and 'b'. Then, it
finds the last digit of each factorial by taking the modulus of 10. If
the last digit of 'a' is 0, it returns 0. If the last digit of 'b' is 0, it
returns the last digit of 'a'. Otherwise, it returns the last digit of 'a' What are the factorials of 8 and 6.
modulo the last digit of 'b'.
The execution results are shown on the top right. (Explanation)
(Execution Results: 2, 0, 1) The factorial of 8 is calculated as 8! = 8 x 7 x 6 x 5 x 4 x 3 x 2 x
1 = 40,320.
Find the last digit of the quotient b factorial divided by a factorial. The factorial of 6 is calculated as 6! = 6 x 5 x 4 x 3 x 2 x 1 = 720.
(Feedback)
What is the output of compute_Last_Digit(2, 5).
I've finalized my answer based on your input and passed all the
tests! Here is it:
The factorial of 8 is 40320 and the factorial of 6 is 720.
import math
The output of compute_Last_Digit(2, 5) is 2.
ddeeff ccoommppuuttee__LLaasstt__DDiiggiitt((aa,, bb))::
ffaaccttoorriiaall__aa == mmaatthh..ffaaccttoorriiaall((aa))
ffaaccttoorriiaall__bb == mmaatthh..ffaaccttoorriiaall((bb))
I asked for the factorials of 5 and 2, not 8 and 6.
qquuoottiieenntt == ffaaccttoorriiaall__bb //// ffaaccttoorriiaall__aa
llaasstt__ddiiggiitt__qquuoottiieenntt == qquuoottiieenntt %% 1100
rreettuurrnn llaasstt__ddiiggiitt__qquuoottiieenntt (Corrected Code) Apologies for the confusion. The factorials of 5 and 2 are: ...
(Execution Results: 2, 6, 2)
6 More Turns
I think you are correct. Successfully I think you are correct. Could not identify
identify errors and errors in the
make corrections source code
Figure6:WithIntelliExplain,userscancomprehendthesourcecodeviaNLexplanation(in□)tomoreeasilyidentify
potentialerrors.IntelliExplainmakescorrectionsbasedonuserfeedback.Incontrast,wheninteractingdirectlywithcode
invanillaGPT-3.5,non-professionalprogrammersmaystruggletounderstandsourcecodeandfailtoidentifyerrors.GPT-3.5
mayalsosometimesgeneratesresponsesthatareirrelevanttotheuserquestion(in□).
participantsuccessfullycomposedthecorrectPythoncodeusing thesecondround,LLMsuccessfullyrefineditsanswerguidedby
just2interactionswithIntelliExplain,whereasusersrelyingon therephrasedfeedback.
thebaselineGPT-3.5requiredsignificantlymoreinteractionsto Furthermore,thepost-taskinterviewallowsustogathermore
understandthegeneratedcodeandvalidatewhetheritiscorrect. comprehensive feedback from our participants, reaffirming the
Finally,participantsusingvanillaGPT-3.5failedtoidentifyerrorsin significantroleourproposedexplanationsplayinassistingpartic-
thegeneratedcode,whichresultedinanincorrectanswerwithout ipantsthroughoutthecodegenerationprocess.Infact,anover-
theuser’sawareness.Moreover,wenoticedthatinthefirstturnof whelmingmajorityofparticipants,anotable9outof10participants
interaction,IntelliExplaindidnotmakecorrectionsaccordingly whoareusingIntelliExplainintheuserstudy,expressedtheir
basedonuserfeedback.Thisrevealsroomforfutureimprovement appreciationfortheexplanations,highlightingthatitsignificantly
ofLLMsinincorporatinghumanfeedbackwithdiversestyles.InIntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
Preciseness Discriminativeness generallyalignpreciselywiththegeneratedcode;however,they
Text-to-SQL 10/10 5/10 donotalwayshelpfindcodeerrors.Thislimitationarisesfromthe
PythonCodeGeneration 10/10 7/10 challengeofencapsulatingintricateinnerlogicintoconciseexpla-
Table4:Statisticsfromtheuserstudyshowingthefrequency nations.Thishighlightsthechallengeofstrikingabalancebetween
whentheNLexplanationofIntelliExplainpreciselyde- presentingconciseandeasy-to-understandNLexplanationsand
scribesthegeneratedcode(Preciseness)andwhencodeerrors presentingmorefine-grainedinnerlogicofthecode.
couldbefoundfromtheexplanation(Discriminativeness). Tobetterunderstandthisphenomenon,weperformedasystem-
aticinvestigationindependentoftheuserstudy.Specifically,we
runGPT-3.5togeneratetheanswercodefortheentireSpider-dev
Question HowmanydifferentwinnersbothparticipatedintheWTA set(1,034testexamples)andtheMBPP-testset(500testexamples).
(Text-to-SQL) Championshipsandwerelefthanded?
Eventually,wecollected214errorpredictionsfortext-to-SQLfrom
Predicted SELECT COUNT(DISTINCT winner_id) FROM matches Spider-devand140errorpredictionsforPythoncodegeneration
Code WHEREtourney_name=’WTAChampionships’ANDwin- fromMBPP-test.Then,wepromptedGPT-3.5togeneratetheexpla-
ner_hand=’L’ANDloser_hand!=’L’
nationforthesepredictionsfollowingourmethodinSection4.2.For
Explanation Whatisthecountofuniquewinnerswhowereleft-handed eachtask,werandomlyselected30casesandmanuallyinspected
andparticipatedintheWTAChampionships,buttheirop- theirquality.Wefoundthatonlyoneexplanationwasinconsistent
ponentswerenotleft-handed?
withthesourcecodeintext-to-SQLandallexplanationsprecisely
Errors Thepredictedcodeincludeadditionalconditionthatisnot describethePythoncode.Amongthosepreciseexplanations,51.7%
mentionedintheoriginalquestion. fortext-to-SQLand66.7%forPythoncodegenerationallowsfor
Question Writeafunctiontofindthekthelementinthegivenarray. easilycapturingcodeerrors.Theresultsthusconfirmedourob-
(PythonCode
servationfromthesmallsamplesintheuserstudy.Weattached
Gen)
oneexampleforeachtasktoshowtheprecisenessofourdesigned
Predicted def kth_element(arr, n, k): explanationinTable5.
Code arr.sort()
Inpractice,participantswereabletorecognizecodeerrorsfrom
return arr[k-1]
theNLexplanationsandhadatleastoneturnofinteractionwith
IntelliExplainfor53%ofthetimeintext-to-SQLand83%ofthe
Explanation Thisprogramfindsthekthsmallestelementinanarray.It
takesanarray,thesizeofthearray(n),andthevalueofkas timeinPythoncodegeneration.Thisindicatesthatparticipants
input.Theprogramfirstsortsthearrayinascendingorder. canunderstandtheexplanationsandpotentiallylocateerrorsin
Then,itreturnstheelementatthek-1indexpositionfrom
theexplanations.Inthepost-taskinterview,wegatheredfeedback
thesortedarray,whichrepresentsthekthsmallestelement.
fromallparticipantsusingIntelliExplainspecificallyfocusing
Errors Thearraydoesnotneedtobesorted. ontheirexperienceswithourdesignedNLexplanation.Fortext-
Table5:Exampleexplanationsthataccuratelydescribethe
to-SQL,allparticipantsthoughtthattheexplanationcouldhelp
sourcecodeandcaptureerrorsexistedinthesourcecode.
themunderstandthemeaningandlogicbehindthesourcecode
ofSQLqueries.Wenoticedtwochallengingquestionsthatmost
oftheparticipantscouldnotrealizeanyerrorsfromtheexplana-
contributestotheirunderstandingofthesourcecode.Thesepartic-
tions.Asubsequentmanualinvestigationpointedtotheinherent
ipantsspecificallynotedapreferenceforexplanationsovertheraw
ambiguitywithintheoriginalquestions,whichwaslikelydueto
codeitself,indicatingtheexplanatorycontent’sperceivedvalue.On
theoriginalquestionsbeingunclearandlackingspecificconditions
theotherhand,oneparticipantofferedfeedbackthat“Occasionally
suchasrequestingsortedorderwithoutspecifyinghowtosortit
theexplanationsfellshort,particularlywhenthelogicwithinthem
(descendingorascending).ForPythoncodegeneration,mostpar-
wasunclear.”Thisfeedbackunderscorestheneedforfutureimprove-
ticipantsappreciatedtheexplanationforaidinginunderstanding
mentinensuringtheclarityandeffectivenessoftheexplanations
anddebuggingthesourcecode.However,oneparticipantreported
andaddressinganypotentialchallengesthatparticipantsmight
theexplanationwaslessusefulandaskedifwecouldprovideboth
encounterincomprehendingthegeneratedcode.Allparticipants
theexplanationandsourcecode.Weinquiredaboutthereasonand
whousedvanillaGPT-3.5expresseduncertaintyaboutdebugging
collected“Theexplanationdoeshelp,butitlacksstep-by-steplogic
thecodethroughtheexplanationgeneratedbyvanillaGPT-3.5.
onhowthesourcecodeperforms.Fromtheexplanation,Ithought
Insubsequentsections,wepresentfurtherinsightssurrounding
thecodewascorrect,butitcouldnotpassalltests.” Thisfeedback
theresearchquestions(RQs)weoutlinedinSection4.1,andthen
suggeststhat,whileourNLexplanationsweregenerallyeffective,
discussacomparisonwiththevanillaGPT-3.5inSection6.6.
thereweresomevariationsinuserpreferencesandtheneedfor
6.3 RQ1:CantheDesignedNLExplanation improvingtheexplanationtoincludemorefine-grainedlogic.This
insightsuggeststhatfutureworkshouldtailortheNLexplanation
AccuratelyDescribetheSourceCode?
tobemore“personalized”formeetingindividualusers’needs.
ToillustratetheeffectivenessofourproposedNLexplanation,de-
terminingitsaccuracyindescribingthemodel-generatedcodeand
itsabilitytocaptureerrorsthatexistinthesourcecode,weman-
uallyexaminedallexplanationsofgeneratedcodeforeverytest
question.AsdepictedinTable4,wefoundthatourexplanationsPreprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
Question Writeapythonfunctiontofindthelastdigitwhenfactorialofadividesfactorialofb.
Explanation Thisprogramcalculatesthelastdigitoftheresultwhencomputingthefactorialsoftwogivennumbers,
‘a’and‘b’.Itusesthemathmoduletocalculatethefactorialsof‘a’and‘b’.Then,itfindsthelastdigitof
eachfactorialbytakingthemodulusof10.Ifthelastdigitof‘a’is0,itreturns0.Ifthelastdigitof‘b’is0,
itreturnsthelastdigitof‘a’.Otherwise,itreturnsthelastdigitof‘a’modulothelastdigitof‘b’.
FeedbackType&Frequency(%) Example
InstructionforErrorCorrection Afterfindingthefactorialsofaandbyoushoulddividethefactorialofbbythefactorialofa.After
(57.5%/71.0%) dividingyoureturnthelastdigitfromtheresult.
QuestionRephrasing YoushouldwriteaPythonfunctionthatdeterminesthelastdigitofthefactorialofnumbera,which
(39.2%/2.1%) dividesthefactorialofanothernumberb?
Step-by-StepInstructions Firstinitializevariablefact_aasthefactorialofnumber‘a’andfact_basthefactorialofnumber‘b’.
(3.3%/26.9%) Thendividefact_bbyfact_aandassignthevaluetovariablequotient.Thentakequotientandreturnthe
remainderwhendividedby10.
Table 6: Types and frequencies (for SQL/Python programming) of feedback provided by users. Errors mentioned in the
explanationaremarkedinred.Diversetypesoffeedbackreceivedfromuserstudydemonstratedtheeffectivenessofour
explanationinaidingnon-professionalprogrammersinbothcodecomprehensionanddebugging.
6.4 RQ2:CanUsersProvideEffectiveFeedback
Thisislikelycausedbyboththedistinctexplanationmethods
basedontheNLExplanation? andthetaskcomplexities.Moreover,userstendedtoprovide
thisfeedbackiftheyfeltconfidentinsolvingthequestion
Throughouttheuserstudy,weobservedavarietyoffeedbackfrom
themselves,particularlyamonguserswhohadtakenintro-
participantsusingIntelliExplain,whichcanbebroadlyclassified
ductoryprogrammingcourses.
intothreecategoriesasshowninTable6:
Overall,regardlessofthedifferenttypesoffeedbackreceived
• Instructions for Error Correction. Users can spot er-
fromtheuserstudy,itisevidentthatparticipantsrecognizeder-
rorsintheexplanationandsuggesthowtofixthem.We
rorsinourexplanationsandtriedtoprovideguidanceforerror
foundthat57.5%oftext-to-SQLusersand71.0%ofPython
correction.Thesubstantialproportionoffeedbackpinpointinger-
code-generation users gave this feedback type. This also
rorsintheexplanationindicatestheprecisenessandutilityofour
impliestheeffectivenessofourexplanationsinaidingnon-
explanationsindescribingthesourcecodeinpracticalscenarios.
professionalprogrammersincodeunderstandinganddebug-
Finally,anintriguingquestionis,whenusersprovidedfeedback,
ging.
didtheybenefitmorefromtheNLexplanationorthecode’sexe-
• QuestionRephrasing.Thistypeoffeedbacksuggeststhat
cutionresults?WiththeinclusionofexecutionresultsinourUI,
usersperceiveerrorsintheexplanation,attributingthem
participantshavetheoptiontoprovidefeedbacknotonlybasedon
totheunderspecifiedintentoftheoriginalquestion.Inour
theexplanationsbutalsoontheactualexecutionresults.Thisin-
observations, participants are more likely (39.2%) to pro-
troducesavaluableavenueforassessingtheeffectivenessofourex-
videthisfeedbacktypeintext-to-SQLcomparedtoPython
planations.Duringthepost-taskinterview,participantsarequeried
codegeneration(2.1%).Thisdiscrepancyisinfluencedby
about the number of instances in which they chose to provide
the distinct explanation methods used in these tasks. In
feedbackprimarilyinfluencedbytheobservedexecutionresults
text-to-SQL,therestatedquestionmotivatedparticipants
ratherthanrelyingsolelyontheexplanations.All10participants
tocomparetheintentspresentedintheirinitialquestionand
saidtheyonlyusetheexplanationstofixerrorsintext-to-SQL.
therestatedone;whentheyidentifiedinconsistency,they
Unliketext-to-SQL,testcasesandexpectedoutputsareprovided
mightnaturallythinkaboutprovidingacompletequestion
inPythoncodegeneration.Thus,7outof10participantsstarted
withclearerintent.Inaddition,therewasnoclearpattern
bylookingattheexecutionresults.Iftheresultswerewrong,they
indicatingwhetherparticipantschosetoprovidethisfeed-
knewtheremightbeerrorsintheexplanation,sotheyspentmore
backbasedontheirexperienceorthequestiondifficulty,as
timecheckingit.Theother3participantsindicatedthattheybegan
mostparticipantslackedexperiencewithSQL,andthisfeed-
byreviewingtheexplanation.Iftheyidentifiederrors,theyimmedi-
backoccurredevenlyacrossalldifficultylevels.Conversely,
atelyprovidedfeedbackwithoutconsideringtheexecutionresults.
inPythoncodegeneration,participantsinteractwithcon-
Thisdemonstratestheindispensableroleofourexplanation.
cisedescriptionsofthesourcecode,whichincludemore
logicbehindthesourcecodeandresultinlesspossibilityof 6.5 RQ3:CanUserFeedbackbasedonthe
rephrasingtheoriginalquestion. ExplanationbeSuccessfullyAppliedtothe
• Step-by-StepInstruction.Usersofferdetailedstep-by-step
SourceCodeforErrorCorrection?
instructionstoguidethemodelinsolvingtheproblembased
ontheirunderstanding.WeobservedthatPythoncodegen- InTable7,thesuccessratesofdifferentfeedbacktypesillustrate
erationparticipants(26.9%)aremoreinclinedtoprovidethis IntelliExplain’sefficacyinintegratinghumanfeedbackforerror
feedbacktypecomparedtotext-to-SQLparticipants(3.3%). correction.Specifically,IntelliExplainachievedasuccessrateofIntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
SuccessRate(%) 6.6 ComparisonwiththeBaselineSystem
FeedbackType
Text-to-SQL PythonCodeGen (VanillaGPT-3.5)
InstructionforErrorCorrection 36.0 65.6 ParticipantsusingthevanillaGPT-3.5withoutourdesignedex-
QuestionRephrasing 25.9 50.0 planations consistently reported frustration since the raw code
Step-by-StepInstruction 0.0 20.0 generatedbythemodelwastoochallengingtounderstand,even
Table7:SuccessrateofIntelliExplainforeachfeedback whenitwasactuallycorrect.Lackingprofessionalprogramming
type.Thepercentagesarecalculatedbydividingthenumber experience,theystruggledtounderstandthelogic,structure,and
ofsuccessfulerrorcorrectionsforeachfeedbacktypebythe meaningbehindthecode.Thishinderedtheirabilitytoidentify
numberoftotalfeedbackofthesametypeperconversation. errorsorprovidemeaningfulfeedbacktothesystem.Asshownin
Figures1and6,participantsusingvanillaGPT-3.5needtounder-
standeachtechnicalfunctioninthesourcecodebeforetheycan
debugit.WhentheypromptedGPT-3.5toexplainitsreasoning
process,thelengthandcomplexityofGPT-3.5’sverbosetechnical
descriptionsposedanimpenetrablebarrier.Participantswereover-
36.0%fortext-to-SQLand65.6%forPythoncodegenerationwhen
whelmedbyunfamiliarterminologiesandconceptsirrelevantto
usersprovidedfeedbackoftype“InstructionsforErrorCorrection”.
comprehendingthecorelogic.Withoutthecapacitytoparsethese
This indicates a reasonable level of success in addressing user-
abstruseexplanations,userscouldneitherefficientlyevaluatethe
providedfeedback,giventhatthistypeoffeedbackwasthemost
model’sthoughtprocessnorsupplyusefuldebuggingfeedback.
commonlyprovidedbyparticipantsinbothtasks.Ontheother
Incontrast,participantshighlightedthattheconciseyetinfor-
hand,itshowcasesthepracticalutilityandresponsivenessofour
mativeNLexplanationsprovidedbyIntelliExplainelucidated
designedNLexplanationandinteractionparadigm.
themodel’scodegenerationreasoningclearlyandinanaccessi-
The25.9%successratein“QuestionRephrasing”feedbackfor
blemanner.Bydistillingcomplextechnicalconceptsintoeasy-to-
text-to-SQLalsodemonstratestheeffectivenessof IntelliExplain
understandlanguage,theexplanationsunlockedcomprehension
inincorporatinghumanfeedback.Peopletypicallyelaboratetheir
anddebugabilityfornon-professionalprogrammers.Additionally,
questionstousemoreprecisewordsandincludealittlemorede-
bypinpointingspecificmisunderstandingsinlocalizedareasofthe
tails.Withtherephrasedquestion,IntelliExplaincangenerate
explanations,userscouldprovidemeaningfulfeedbacktocorrecter-
codethatisbetteralignedwithhumanintent.Thisexposesthe
rors.Overall,participantsstronglyaffirmedthattheNLtranslation
limitationsofLLMinhandlingconfusingoruncertaininputsand
ofcodelogic,coupledwithtargeteddebuggingviatheexplanation-
leavesroomforimprovement.It’sworthnotingthat“Question
and-feedbackloop,enhancedtheirabilitytoachievesuccessfulcode
Rephrasing”feedbackoccurredonlytwiceinPythoncodegenera-
generationdespitelimitedtechnicalskills.
tion,potentiallyexplainingitshighersuccessrate.
InPythoncodegeneration,userfeedbackintheformof“Step- 7 PERFORMANCEOFINTELLIEXPLAINWITH
by-StepInstruction”rankssecond.Weinvestigateduserbehavior
GPT-4ASBACKBONELLM
regardingthistypeoffeedback.Throughpost-taskinterviews,we
foundthatdespiteparticipantshavinglimitedPythonprogram-
mingknowledge,theywereabletolearnfromourexplanations
GPT-4
andincorporatetheirownsolutionsintothefeedback.Thisunder- System
SuccessRate(%) Avg.Time/question(s)
scoresthepotentialutilityofourexplanationsineducatingnovice
programmers,particularlyinintroductoryprogrammingclasses. Text-to-SQL 30.0 107.4
Despitetheachievementinincorporatinghumanfeedbackin PythonCodeGen 50.0 132.3
IntelliExplain,weobservedanotablegapinthesuccessratefrom Table8:OverallperformanceofIntelliExplainwithGPT-4
theuserstudyespeciallyinSQL.Wequeriedeachparticipantabout asbackboneLLM.Theresultwascollectedbasedonapilot
theirexperienceswiththesuccessfulapplicationoftheirfeedback studywithonenon-professionalprogrammerparticipant.
intheerrorcorrectionphase.7outof10participantsusingIntel-
liExplainreportedthattheirfeedback.However,theremaining
participantsnotedinstanceswheretheirfeedbackdidnotyield OurmaininvestigationhasbeenbasedonGPT-3.5,ratherthan
thedesiredresults.Acloserexaminationofthesecasesrevealed thestate-of-the-artGPT-4,asthebackboneLLM.Anaturalquestion
variouscontributingfactors.Firstly,userfeedbackwassometimes hereisthus:fortheeffectivenesswehaveshownwithIntelliEx-
toovagueorabstractandlackedthespecificityneededforprecise plaininthisstudy,aswellasthefindingswehavediscovered,are
corrections.Secondly,misalignedreasoningbetweenparticipants’ theystillapplicablewhenpeopleswitchtothemorepowerfulGPT-
mentalmodelsandthemodel’sthoughtledtosuggestionsbased 4?Limitedbytheavailableresourcesandbudget,itisinfeasible
onflawedassumptions.Lastly,forcomplexcode,smallchangesin tore-conducttheuserstudy.However,togainsomepreliminary
theexplanationmadeitchallengingforuserstotrack,emphasizing insights,westillperformedapilotstudywithoneparticipantwho
theimportanceofhighlightingthosechangesinexplanations.In hadnopriorexperienceinSQLandPythonprogramming.Given
essence,narrowingcommunicationgapsthroughimprovedexplain- GPT-4’s enhanced code generation capabilities, some questions
ability,alignment,andtransparencyisessentialfortheeffective thatweusedinthemainuserstudywerenotsuitableanymore.
applicationofuserfeedback. Specifically,weobservedthat3outof10questionsintext-to-SQLPreprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
Question Writeafunctiontofindthedepthofadictionary.
PreditedCode def dict_depth(dictionary):
depth = 0
if not isinstance(dictionary, dict) or len(dictionary) == 0:
return depth
else:
depth += 1
return depth + max(dict_depth(value) for value in dictionary.values())
GPT-3.5Explanation Thisprogramcalculatesthedepthorlevelofnestinginagivendictionary.Itchecksiftheinputisa
dictionaryandifitisnotempty.Ifitisnotadictionaryorisempty,itreturnsadepthof0.Otherwise,it
recursivelycalculatesthedepthofeachvalueinthedictionaryandreturnsthemaximumdepthfound,
incrementedby1.
GPT-4Explanation Thisprogramcalculatesthedepthofadictionary.Thedepthofadictionaryisthemaximumnumberof
levelsitcontains.Ifthedictionarycontainsotherdictionariesasvalues,thoseareconsideredadditional
levels.Theprogramcheckseachvalueinthedictionary,andifavalueisanotherdictionary,itrecursively
calculatesthedepthofthatdictionary.Thefinaldepthisonemorethanthemaximumdepthofanyvalue.
Ifthedictionaryisempty,itsdepthisconsideredtobezero.
Table 9: Explanations provided by GPT-3.5 and GPT-4 on the same question for the generated code. GPT-4 generates an
explanatorysentenceonhowtosolvetheproblemingeneral(in□).Thisinformationmakestheexplanationgeneratedby
GPT-4morecomprehensiblethanGPT-3.5.
8 DISCUSSION
and2outof10questionsinPythoncodegenerationcouldbeaccu-
ratelyansweredbyGPT-4withoutanyspecificinteractiondesign. OurinnovativeNLexplanationandinteractionparadigmintro-
Consequently,weexcludedthesequestionsandrandomlyselected ducesseveralnoteworthyadvantagesthatsignificantlyenhance
additionalquestionstokeepthesameamountofquestions.There- theuser-friendlynatureofinteractivecodegeneration,particularly
sultsarepresentedinTable8.Theresultsshowanimprovedsuccess fornon-professionalprogrammers.However,somelimitationsexist.
rateintext-to-SQLandacomparablesuccessrateinPythoncode Firstly,theinherentambiguityinhumanlanguagecanresultin
generationcomparedtoGPT-3.5’s(Table3),whichindicatesthata LLMsgeneratingincorrectanswers.Addressingthischallengere-
strongerLLMcouldpotentiallyyieldevenmoreeffectivehuman- quiresenhancingthemodel’sabilitytodistinguishunclearconcepts
LLMinteractionforcodegeneration.Theresultsalsodemonstrate inthequestionandrequestuserclarificationonambiguousterms.
thatourdesignedpromptsandinteractionparadigmcanworkwith Suchimprovementswouldfosteramorenaturalanduser-centric
amorepowerfulLLM. interactionbetweenhumansandLLMs.Inthefuture,researchers
TogaindeeperinsightsintothedifferencesbetweenGPT-4and areencouragedtoextendtheinteractionparadigmwepresented
GPT-3.5,weconductedananalysisfocusingonthequalityoftheir inthisworkwiththisricheruser-systeminteraction.Additionally,
generatedNLexplanations.Asexpected,weobservedthatGPT-4 whendealingwithmoreintricatecode,theexplanationsfellshort
couldproduceexplanationsaspreciseasGPT-3.5’s.Beyondpre- offullycapturingcomplexlogicalerrors.Strikingtheoptimalbal-
ciseness,wefoundthatintwocases,theexplanationsgenerated ancebetweendetailednessandbrevityinexplanationsremains
byGPT-4showevenhigherqualityintermsofcomprehensibility, anongoingchallenge.Whilethesuccessratesaffirmtheeffective-
asexemplifiedinTable9.Thisenhancedcomprehensibilitycould nessofuserfeedbackforerrorcorrection,thereisstillpotential
potentiallyimpacttheuserexperiencebyprovidingclearerinsights forimprovement.Futureeffortsfocusingoncomprehendingand
intothegeneratedcode.However,theobservationthatonlytwo incorporatingdiverseuserinputcouldsignificantlyenhancethe
explanationsrevealthisenhancedcomprehensibilityindicatesthat interactiverefinementprocess.AswediscussedattheendofSec-
thereisstillroomforimprovementevenwithamoreadvancedLLM. tion6.3,userscouldbenefitfrom“personalized”interactivecode
Wehavealsoexaminedwhethertheparticipantcouldprovideeffec- generationsystems,wherethewayhowanLLMexplainsacode
tivefeedbackforerrorcorrection.Inthepilotstudy,theparticipant canbecustomizedtobetterfittheirneedsandpreferences.
mainlyprovidedfeedbackoftype“InstructionforErrorCorrection”,
exceptone“QuestionRephrasing”feedbackfortext-to-SQL.The 9 CONCLUSION
observationreaffirmsthatwithourdesignedexplanations,users
canfinderrorsandprovidefeedbackwithoutdirectlyinteracting Inthiswork,weintroduceanovelhuman-LLMinteractionpara-
withthesourcecode.However,itslowsuccessrateunderscores digmutilizingnaturallanguageexplanationstoenhancetheuser-
theneedforfutureexplorationonthistopic. friendlinessofinteractivecodegenerationfornon-professionalpro-
grammers.Theresultsfromtheuserstudyvalidatetheadvantages
ofourapproach.Resultsshowtheexplanationsaidcomprehen-
sionanddebugging,withusersprovidingmeaningfulcorrective
feedbackfromtheexplanation.TheinteractivefeedbackcyclealsoIntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
successfullyhandlesuserfeedbacktorefinethecode.Togetherthis Proceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.
leadstohighersuccessratesandbetteroverallexperiencethanits 1–19.
[17] MajeedKazemitabaar,JustinChow,CarlKaToMa,BarbaraJEricson,David
counterpartvanillaLLM.
Weintrop,andToviGrossman.2023.StudyingtheeffectofAICodeGenerators
onSupportingNoviceLearnersinIntroductoryProgramming.InProceedingsof
10 ACKNOWLEDGMENTS the2023CHIConferenceonHumanFactorsinComputingSystems.1–23.
[18] TakeshiKojima,ShixiangShaneGu,MachelReid,YutakaMatsuo,andYusuke
Iwasawa.2022. Largelanguagemodelsarezero-shotreasoners. Advancesin
ThisprojectwassponsoredbyNSFSHF2311468,GMUCollege
neuralinformationprocessingsystems35(2022),22199–22213.
ofComputingandEngineering,andGMUDepartmentofCom- [19] IgorLabutov,BishanYang,andTomMitchell.2018.LearningtoLearnSemantic
puterScience.WeappreciatetheOfficeofResearchIntegrityand ParsersfromNaturalLanguageSupervision.InProceedingsofthe2018Conference
onEmpiricalMethodsinNaturalLanguageProcessing,EllenRiloff,DavidChiang,
AssuranceatGMUfortheirworkinreviewingandapprovingour
JuliaHockenmaier,andJun’ichiTsujii(Eds.).AssociationforComputational
InstitutionalReviewBoard(IRB)application.Wealsoappreciate Linguistics,Brussels,Belgium,1676–1690. https://doi.org/10.18653/v1/D18-1195
commentsfromstudentsinGMUNLPandSElabs. [20] ShuvenduKLahiri,AadityaNaik,GeorgiosSakkas,PialiChoudhury,Curtisvon
Veh,MadanlalMusuvathi,JeevanaPriyaInala,ChenglongWang,andJianfeng
Gao.2022.Interactivecodegenerationviatest-drivenuser-intentformalization.
REFERENCES arXivpreprintarXiv:2208.05950(2022).
[21] AndrewLampinen,IshitaDasgupta,StephanieChan,KoryMathewson,Mh
[1] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,Floren- Tessler,AntoniaCreswell,JamesMcClelland,JaneWang,andFelixHill.2022.
ciaLeoniAleman,DiogoAlmeida,JankoAltenschmidt,SamAltman,Shyamal Canlanguagemodelslearnfromexplanationsincontext?.InFindingsofthe
Anadkat,etal.2023. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774 AssociationforComputationalLinguistics:EMNLP2022,YoavGoldberg,Zornitsa
(2023). Kozareva,andYueZhang(Eds.).AssociationforComputationalLinguistics,Abu
[2] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Dhabi,UnitedArabEmirates,537–563.https://doi.org/10.18653/v1/2022.findings-
Michalewski,DavidDohan,EllenJiang,CarrieCai,MichaelTerry,QuocLe, emnlp.38
etal.2021. Programsynthesiswithlargelanguagemodels. arXivpreprint [22] RaymondLi,LoubnaBenAllal,YangtianZi,NiklasMuennighoff,DenisKocetkov,
arXiv:2108.07732(2021). ChenghaoMou,MarcMarone,ChristopherAkiki,JiaLi,JennyChim,etal.2023.
[3] ShraddhaBarke,MichaelBJames,andNadiaPolikarpova.2023. Grounded StarCoder:maythesourcebewithyou!arXivpreprintarXiv:2305.06161(2023).
copilot:Howprogrammersinteractwithcode-generatingmodels.Proceedingsof [23] YuntaoLi,BeiChen,QianLiu,YanGao,Jian-GuangLou,YanZhang,andDongmei
theACMonProgrammingLanguages7,OOPSLA1(2023),85–111. Zhang.2020.“WhatDoYouMeanbyThat?”AParser-IndependentInteractive
[4] StephenBrade,BryanWang,MauricioSousa,SageevOore,andToviGross- ApproachforEnhancingText-to-SQL.InProceedingsofthe2020Conferenceon
man.2023. Promptify:Text-to-imagegenerationthroughinteractiveprompt EmpiricalMethodsinNaturalLanguageProcessing(EMNLP),BonnieWebber,
explorationwithlargelanguagemodels.InProceedingsofthe36thAnnualACM TrevorCohn,YulanHe,andYangLiu(Eds.).AssociationforComputational
SymposiumonUserInterfaceSoftwareandTechnology.1–14. Linguistics,Online,6913–6922. https://doi.org/10.18653/v1/2020.emnlp-main.561
[5] ShobhitChaurasiaandRaymondJ.Mooney.2017.DialogforLanguagetoCode. [24] MichaelXieyangLiu,AdvaitSarkar,CarinaNegreanu,BenjaminZorn,Jack
InProceedingsoftheEighthInternationalJointConferenceonNaturalLanguage Williams,NeilToronto,andAndrewDGordon.2023. “WhatItWantsMeTo
Processing(Volume2:ShortPapers),GregKondrakandTaroWatanabe(Eds.). Say”:BridgingtheAbstractionGapBetweenEnd-UserProgrammersandCode-
AsianFederationofNaturalLanguageProcessing,Taipei,Taiwan,175–180. https: GeneratingLargeLanguageModels.InProceedingsofthe2023CHIConferenceon
//aclanthology.org/I17-2030 HumanFactorsinComputingSystems.1–31.
[6] AngelicaChen,JérémyScheurer,TomaszKorbak,JonAnderCampos,JunShern [25] PengfeiLiu,WeizheYuan,JinlanFu,ZhengbaoJiang,HiroakiHayashi,and
Chan,SamuelRBowman,KyunghyunCho,andEthanPerez.2023.Improving GrahamNeubig.2023.Pre-train,prompt,andpredict:Asystematicsurveyof
codegenerationbytrainingwithnaturallanguagefeedback. arXivpreprint promptingmethodsinnaturallanguageprocessing.Comput.Surveys55,9(2023),
arXiv:2303.16749(2023). 1–35.
[7] MarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveira [26] StephenMacNeil,AndrewTran,ArtoHellas,JoanneKim,SamiSarsa,Paul
Pinto,JaredKaplan,HarriEdwards,YuriBurda,NicholasJoseph,GregBrockman, Denny,SethBernstein,andJuhoLeinonen.2023.Experiencesfromusingcode
etal.2021. Evaluatinglargelanguagemodelstrainedoncode. arXivpreprint explanationsgeneratedbylargelanguagemodelsinawebsoftwaredevelopment
arXiv:2107.03374(2021). e-book.InProceedingsofthe54thACMTechnicalSymposiumonComputerScience
[8] XinyunChen,MaxwellLin,NathanaelSchärli,andDennyZhou.2023.Teaching EducationV.1.931–937.
largelanguagemodelstoself-debug.arXivpreprintarXiv:2304.05128(2023). [27] AndrewMMcNutt,ChenglongWang,RobertADeline,andStevenMDrucker.
[9] PaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDario 2023.Onthedesignofai-poweredcodeassistantsfornotebooks.InProceedings
Amodei.2017.Deepreinforcementlearningfromhumanpreferences.Advances ofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–16.
inneuralinformationprocessingsystems30(2017). [28] LingboMo,AshleyLewis,HuanSun,andMichaelWhite.2022.TowardsTranspar-
[10] Jean-BaptisteDöderlein,MathieuAcher,DjamelEddineKhelladi,andBenoit entInteractiveSemanticParsingviaStep-by-StepCorrection.InFindingsofthe
Combemale.2022.PilotingCopilotandCodex:HotTemperature,ColdPrompts, AssociationforComputationalLinguistics:ACL2022,SmarandaMuresan,Preslav
orBlackMagic?arXivpreprintarXiv:2210.14699(2022). Nakov,andAlineVillavicencio(Eds.).AssociationforComputationalLinguistics,
[11] IanDrosos,TitusBarik,PhilipJGuo,RobertDeLine,andSumitGulwani.2020. Dublin,Ireland,322–342. https://doi.org/10.18653/v1/2022.findings-acl.28
Wrex:Aunifiedprogramming-by-exampleinteractionforsynthesizingreadable [29] OpenAI.2023.ChatGPT.https://openai.com.
codefordatascientists.InProceedingsofthe2020CHIconferenceonhumanfactors [30] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,Pamela
incomputingsystems.1–12. Mishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal.2022.
[12] AhmedElgohary,SagharHosseini,andAhmedHassanAwadallah.2020.Speak Traininglanguagemodelstofollowinstructionswithhumanfeedback.Advances
toyourParser:InteractiveText-to-SQLwithNaturalLanguageFeedback.In inNeuralInformationProcessingSystems35(2022),27730–27744.
Proceedingsofthe58thAnnualMeetingoftheAssociationforComputational [31] DakingRai,YilunZhou,BailinWang,andZiyuYao.2023. Explaininglarge
Linguistics,DanJurafsky,JoyceChai,NatalieSchluter,andJoelTetreault(Eds.). languagemodel-basedneuralsemanticparsers(studentabstract).InProceedings
AssociationforComputationalLinguistics,Online,2065–2077. https://doi.org/ oftheAAAIConferenceonArtificialIntelligence,Vol.37.16308–16309.
10.18653/v1/2020.acl-main.187 [32] StevenIRoss,FernandoMartinez,StephanieHoude,MichaelMuller,andJustinD
[13] GitHub.2021. Copilot. https://github.blog/2021-06-29-introducing-github- Weisz.2023.Theprogrammer’sassistant:Conversationalinteractionwithalarge
copilot-ai-pair-programmer/. languagemodelforsoftwaredevelopment.InProceedingsofthe28thInternational
[14] IzzeddinGur,SemihYavuz,YuSu,andXifengYan.2018. DialSQL:Dialogue ConferenceonIntelligentUserInterfaces.491–514.
BasedStructuredQueryGeneration.InProceedingsofthe56thAnnualMeeting [33] BaptisteRoziere,JonasGehring,FabianGloeckle,StenSootla,ItaiGat,Xiao-
oftheAssociationforComputationalLinguistics(Volume1:LongPapers),Iryna qingEllenTan,YossiAdi,JingyuLiu,TalRemez,JérémyRapin,etal.2023.Code
GurevychandYusukeMiyao(Eds.).AssociationforComputationalLinguistics, llama:Openfoundationmodelsforcode.arXivpreprintarXiv:2308.12950(2023).
Melbourne,Australia,1339–1349. https://doi.org/10.18653/v1/P18-1124 [34] SamiSarsa,PaulDenny,ArtoHellas,andJuhoLeinonen.2022. Automatic
[15] DhanyaJayagopal,JustinLubin,andSarahEChasins.2022. Exploringthe generationofprogrammingexercisesandcodeexplanationsusinglargelanguage
learnabilityofprogramsynthesizersbynoviceprogrammers.InProceedingsof models.InProceedingsofthe2022ACMConferenceonInternationalComputing
the35thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.1–15. EducationResearch-Volume1.27–43.
[16] EllenJiang,EdwinToh,AlejandraMolina,KristenOlson,ClaireKayacik,Aaron [35] MichaelStaniekandStefanRiezler.2021.Error-AwareInteractiveSemanticPars-
Donsbach,CarrieJCai,andMichaelTerry.2022. Discoveringthesyntaxand ingofOpenStreetMap.InProceedingsofSecondInternationalCombinedWorkshop
strategiesofnaturallanguageprogrammingwithgenerativelanguagemodels.In onSpatialLanguageUnderstandingandGroundedCommunicationforRobotics.Preprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
A PROMPTSUSEDININTELLIEXPLAIN
53–59.
[36] NisanStiennon,LongOuyang,JeffreyWu,DanielZiegler,RyanLowe,Chelsea A.1 Few-shotCodeGeneration
Voss,AlecRadford,DarioAmodei,andPaulFChristiano.2020. Learningto
summarizewithhumanfeedback. AdvancesinNeuralInformationProcessing
A.1.1 Text-to-SQL. Sampleprompttemplateoffew-shotcodegen-
Systems33(2020),3008–3021.
[37] YuSu,AhmedHassanAwadallah,MiaosenWang,andRyenWWhite.2018. erationfortext-to-SQL.
Naturallanguageinterfaceswithfine-graineduserinteraction:Acasestudy
onwebapis.InThe41stInternationalACMSIGIRConferenceonResearch&
DevelopmentinInformationRetrieval.855–864.
[38] PriyanVaithilingam,ElenaLGlassman,PeterGroenwegen,SumitGulwani, CREATE TABLE department (
AustinZHenley,RohanMalpani,DavidPugh,ArjunRadhakrishna,Gustavo
department_id number ,
Soares,JoeyWang,etal.2023. TowardsMoreEffectiveAI-AssistedProgram-
ming:ASystematicDesignExplorationtoImproveVisualStudioIntelli-Code’s name text ,
UserExperience.InProceedingsoftheIEEE/ACMInternationalConferenceon creation text ,
SoftwareEngineering:SoftwareEngineeringinPractice(ICSE-SEIP’23).Association
ranking number ,
forComputingMachinery,NewYork,NY,USA.
[39] PriyanVaithilingam,TianyiZhang,andElenaLGlassman.2022.Expectation budget_in_billions number ,
vs.experience:Evaluatingtheusabilityofcodegenerationtoolspoweredby num_employees number ,
largelanguagemodels.InChiconferenceonhumanfactorsincomputingsystems
extendedabstracts.1–7. primary key ( department_id )
[40] XingyaoWang,HaoPeng,ReyhanehJabbarvand,andHengJi.2023.LeTI:Learn- )
ingtoGeneratefromTextualInteractions.arXivpreprintarXiv:2305.10314(2023).
insert into department (department_id, name,
[41] XinWang,YashengWang,YaoWan,FeiMi,YitongLi,PingyiZhou,JinLiu,Hao
Wu,XinJiang,andQunLiu.2022. CompilableNeuralCodeGenerationwith ↩→ creation, ranking, budget_in_billions,
CompilerFeedback.InFindingsoftheAssociationforComputationalLinguistics: ↩→ num_employees) values (1,'State','1789','1'
ACL2022.9–19.
[42] YueWang,WeishiWang,ShafiqJoty,andStevenCHHoi.2021.Codet5:Identifier-
↩→ ,9.9600000000000008526,30265.999999999999999)
awareunifiedpre-trainedencoder-decodermodelsforcodeunderstandingand ↩→ ;
generation.arXivpreprintarXiv:2109.00859(2021).
[43] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,
QuocVLe,DennyZhou,etal.2022.Chain-of-thoughtpromptingelicitsreasoning CREATE TABLE head (
inlargelanguagemodels.AdvancesinNeuralInformationProcessingSystems35 head_id number ,
(2022),24824–24837.
name text ,
[44] FrankFXu,BogdanVasilescu,andGrahamNeubig.2022.In-idecodegeneration
fromnaturallanguage:Promiseandchallenges.ACMTransactionsonSoftware born_state text ,
EngineeringandMethodology(TOSEM)31,2(2022),1–47. age number ,
[45] JohnYang,AksharaPrabhakar,KarthikNarasimhan,andShunyuYao.2023.
primary key ( head_id )
InterCode:StandardizingandBenchmarkingInteractiveCodingwithExecution
Feedback.arXivpreprintarXiv:2306.14898(2023). )
[46] ZiyuYao,XiujunLi,JianfengGao,BrianSadler,andHuanSun.2019.Interactive insert into head (head_id, name, born_state, age)
semanticparsingforif-thenrecipesviahierarchicalreinforcementlearning.In
ProceedingsoftheAAAIConferenceonArtificialIntelligence,Vol.33.2547–2554. ↩→ values (1,'Tiger Woods','Alabama'
[47] ZiyuYao,YuSu,HuanSun,andWen-tauYih.2019. Model-basedInteractive ↩→ ,66.999999999999999998) ;
SemanticParsing:AUnifiedFrameworkandAText-to-SQLCaseStudy.InPro-
ceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguagePro-
cessingandthe9thInternationalJointConferenceonNaturalLanguageProcess- CREATE TABLE management (
ing(EMNLP-IJCNLP),KentaroInui,JingJiang,VincentNg,andXiaojunWan department_id number ,
(Eds.).AssociationforComputationalLinguistics,HongKong,China,5447–5458.
head_id number ,
https://doi.org/10.18653/v1/D19-1547
[48] ZiyuYao,YiqiTang,Wen-tauYih,HuanSun,andYuSu.2020. AnImitation temporary_acting text ,
GameforLearningSemanticParsersfromUserInteraction.InProceedingsofthe primary key ( department_id ) ,
2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),
BonnieWebber,TrevorCohn,YulanHe,andYangLiu(Eds.).Associationfor foreign key ( head_id ) references head ( head_id )
ComputationalLinguistics,Online,6883–6902. https://doi.org/10.18653/v1/2020. ↩→ ,
emnlp-main.559
foreign key ( department_id ) references department
[49] TaoYu,RuiZhang,KaiYang,MichihiroYasunaga,DongxuWang,ZifanLi,
JamesMa,IreneLi,QingningYao,ShanelleRoman,ZilinZhang,andDragomir ↩→ ( department_id )
Radev.2018. Spider:ALarge-ScaleHuman-LabeledDatasetforComplexand )
Cross-DomainSemanticParsingandText-to-SQLTask.InProceedingsofthe2018
insert into management (department_id, head_id,
ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,EllenRiloff,
DavidChiang,JuliaHockenmaier,andJun’ichiTsujii(Eds.).Associationfor ↩→ temporary_acting) values (2,5,'Yes') ;
ComputationalLinguistics,Brussels,Belgium,3911–3921. https://doi.org/10.
18653/v1/D18-1425
[50] TianyiZhang,LondonLowmanstone,XinyuWang,andElenaLGlassman.2020. Translate the following question into SQL.
Interactiveprogramsynthesisbyaugmentedexamples.InProceedingsofthe33rd
AnnualACMSymposiumonUserInterfaceSoftwareandTechnology.627–648.
Question: In which year were most departments
↩→ established?
SQL:
SELECT creation FROM department GROUP BY creation
↩→ ORDER BY COUNT(*) DESC LIMIT 1
[moredemonstrations...]
<inputquestionanddatabaseschema>IntelliExplain:EnhancingInteractiveCodeGenthroughNLExplanationsforNon-ProfessionalProgrammers Preprint,Conferenceacronym’XX,2024
A.1.2 PythonCodeGeneration. Sampleprompttemplateoffew- A.2.2 ExplanationforPythonCodeGeneration. Sampleprompt
shotcodegenerationforPythonCodeGeneration. templateofexplanationgenerationforPythonCode.
YouareanexpertPythonprogrammer,andhereisyour
You are an expert Python programmer. Your task is to
task:
write a description for the following Python program.
The description should be accurate, concise, and easily
Writeapythonfunctiontoidentifynon-primenumbers.
understoodbynon-programmers.
Your code should pass these tests:
assert is_not_prime(2) == False
def similar_elements(test_tup1, test_tup2):
assert is_not_prime(10) == True
res = tuple(set(test_tup1) & set(test_tup2))
assert is_not_prime(35) == True
return (res)
Code:
Explanation:Thisprogramtakestwolistsasinputand
import math
returns a new list containing the common elements
def is_not_prime(n):
betweenthetwoinputlists.
result = False
for i in range(2,int(math.sqrt(n)) + 1):
import math
if n % i == 0:
def is_not_prime(n):
result = True
result = False
return result
for i in range(2,int(math.sqrt(n)) + 1):
[moredemonstrations...] if n % i == 0:
<inputquestionandtests> result = True
return result"
A.2 ExplanationGeneration Explanation:Thisprogramchecksifagivennumberis
notaprimenumber.Itdoesthisbyiteratingthroughall
A.2.1 Explanation for Text-to-SQL. Sample prompt template of
numbersfrom2tothesquarerootofthegivennumber
explanationgenerationfortext-to-SQL.
andcheckingifanyofthemdividethenumberevenly.If
adivisorisfound,theprogramreturnsTrue,indicating
TranslatethefollowingSQLintoquestion.Thequestion thatthenumberisnotprime.Otherwise,itreturnsFalse,
shouldbeconsistentwiththeSQLandfollowasimilar indicatingthatthenumberisprime.
styleastheoriginalquestion.
SQL: select t1.name from person as t1 join def count_ways(n):
↩→ personfriend as t2 on t1.name = t2.name A = [0] * (n + 1)
↩→ where t2.friend in (select name from person B = [0] * (n + 1)
↩→ where age > 40) except select t1.name from A[0] = 1
↩→ person as t1 join personfriend as t2 on t1. A[1] = 0
↩→ name = t2.name where t2.friend in (select B[0] = 0
↩→ name from person where age < 30) B[1] = 1
for i in range(2, n+1):
OriginalQuestion:Findthenameofthepersonwhohas
A[i] = A[i - 2] + 2 * B[i - 1]
friendswithageabove40butnotunderage30?
B[i] = A[i - 1] + B[i - 2]
return A[n]
Explanation: What is the name of the person who has
friendsolderthan40butdoesnothavefriendsyounger Explanation: This program calculates the number
than30? of ways to climb a staircase with n steps using two
SQL: select status_code from bookings group by differenttypesofsteps.Theprogramusesdynamicpro-
↩→ status_code order by count(*) desc limit 1 grammingtostorethenumberofwaysateachstepand
thenreturnsthetotalnumberofwaystoreachthetopstep.
Original Question: What is the most frequent status of
bookings?
[moredemonstrations...]
<inputPythoncode>
Explanation: Which status code appears most often in
bookings?
A.3 Feedback-drivenErrorCorrection
[moredemonstrations...]
<inputSQLqueryandcorrespondingoriginalquestion> A.3.1 Text-to-SQL. Sampleprompttemplateoferrorcorrection
fortext-to-SQL.Preprint,Conferenceacronym’XX,2024 Yan,Latoza,andYao
YouareanexpertPythonprogrammer,andyourtaskis
CREATE TABLE department (
tocorrecttheerrorsintheOriginalPythoncodebasedon
department_id number ,
UserFeedbacktoanswerthequestion.Theuserfeedbackis
name text ,
collectedbasedontheOriginalPythonCodeDescription.
creation text ,
Question:Writeapythonfunctiontomergetheelements
ranking number ,
inthesamecolumnseparatelyinalistoflists.
budget_in_billions number ,
num_employees number ,
primary key ( department_id ) Your code should pass these tests:
) assert merge([['x', 'y'], ['a', 'b'], ['m', 'n']])
insert into department (department_id, name, ↩→ == [['x', 'a', 'm'], ['y', 'b', 'n']]
↩→ creation, ranking, budget_in_billions, assert merge([[1, 2], [3, 4], [5, 6], [7, 8]]) ==
↩→ num_employees) values (1,'State','1789','1' ↩→ [[1, 3, 5, 7], [2, 4, 6, 8]]
↩→ ,9.9600000000000008526,30265.999999999999999) assert merge([['x', 'y','z' ], ['a', 'b','c'], ['m',
↩→ ; ↩→ 'n','o']]) == [['x', 'a', 'm'], ['y', 'b',
↩→ 'n'],['z', 'c','o']]
CREATE TABLE head (
head_id number , def merge(last):
name text , first_elements = [sublist[0] for sublist in last
born_state text , ↩→ ]
age number , last_elements = [sublist[-1] for sublist in last
primary key ( head_id ) ↩→ ]
) merged_list = [first_elements, last_elements]
insert into head (head_id, name, born_state, age) return merged_list
↩→ values (...) ; Description:Thisprogramtakesalistofsublistsasinput
[allremainingdatabaseschemasinthesameformat...] and merges them into a new list. It first extracts the
first elements from each sublist and creates a new list
TranslatethefollowingquestionintoSQL.Foramulti-turn withtheseelements.Then,itextractsthelastelements
scenario,usercanprovidefeedbacktocorrecterrorsin fromeachsublistandaddsthemtothenewlist.Finally,
therestatedquestionwhichisgeneratedfromtheSQL. it returns the merged list containing the first and last
elementsfromeachsublist.
Question: In which year were most departments estab-
lished?" Feedback: You should merge all elements at the same
location.
SELECT Creation, COUNT(*) AS num_departments FROM
RefinedPythonCode:
↩→ department GROUP BY Creation ORDER BY
↩→ num_departments DESC LIMIT 1" def merge(last):
return [list(ele) for ele in list(zip(*lst))]
RestatedQuestion:Inwhichyearwerethemostdepart-
ments established, and how many departments were [moredemonstrations...]
establishedinthatyear? <inputquestion,tests,description,feedback>
Feedback: Do not need to count the number of depart-
ments. Received20February2007;revised12March2009;accepted5June2009
RefinedSQL:
SELECT Creation AS num_departments FROM department
↩→ GROUP BY Creation ORDER BY num_departments
↩→ DESC LIMIT 1
[moredemonstrations...]
<inputquestion,databaseschema,restatedquestion,feed-
back>
A.3.2 PythonCodeGeneration. Sampleprompttemplateoferror
correctionforPythonCode.