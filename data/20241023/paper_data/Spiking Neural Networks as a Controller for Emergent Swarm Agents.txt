Spiking Neural Networks as a Controller for
Emergent Swarm Agents
Kevin Zhu Connor Mattson Shay Snyder Ricardo Vega
George Mason University University of Utah George Mason University George Mason University
Fairfax, USA Salt Lake City, USA Fairfax, USA Fairfax, USA
kzhu4@gmu.edu c.mattson@utah.edu ssnyde9@gmu.edu rvega7@gmu.edu
Daniel S. Brown Maryam Parsa Cameron Nowzari
University of Utah George Mason University George Mason University
Salt Lake City, USA Fairfax, USA Fairfax, USA
daniel.s.brown@utah.edu mparsa@gmu.edu cnowzari@gmu.edu
Abstract—Droneswhichcanswarmandloiterinacertainarea interest to an even more limited sensor suite: a single binary
cost hundreds of dollars, but mosquitos can do the same and sensor which activates if another object passes within its field
are essentially worthless. To control swarms of low-cost robots,
of view. Deceptively simple controllers on binary sensing-to-
researchersmayendupspendingcountlesshoursbrainstorming
actuating robots have been shown to be capable of what were
robot configurations and policies to “organically” create behav-
iorswhichdonotneedexpensivesensorsandperception.Existing previously thought to be complex global behaviors requiring
research explores the possible emergent behaviors in swarms of good sensing and localization capabilities. Take, for instance,
robots with only a binary sensor and a simple but hand-picked a simple binary controller that maps the binary sensor output
controller structure. Even agents in this highly limited sensing,
to one of two constant motor commands. With certain sets of
actuation, and computational capability class can exhibit rela-
motorcommands,swarmsofsimplegroundrobotsarecapable
tivelycomplexglobalbehaviorssuchasaggregation,milling,and
dispersal,butfindingthelocalinteractionrulesthatenablemore of aggregation, dispersion, and milling [2], [3].
collective behaviors remains a significant challenge. This paper This simple binary controller was originally designed by
investigates the feasibility of training spiking neural networks Gaucietal.,andevolutionaryalgorithmswereusedtodiscover
to find those local interaction rules that result in particular
parametersforthecontrollerthatleadtomillingin[2].Despite
emergent behaviors. In this paper, we focus on simulating a
its simplicity, this controller has been shown to be robust to
specific milling behavior already known to be producible using
very simple binary sensing and acting agents. To do this, we use sensing and actuation noise [2], [4].
evolutionary algorithms to evolve not only the parameters (the We propose searching for controller structure and parame-
weights,biases,anddelays)ofaspikingneuralnetwork,butalso ters simultaneously. The architecture of the controller should
its structure. To create a baseline, we also show an evolutionary
lend itself to the learning of essential skills in robotics, such
search strategy over the parameters for the incumbent hand-
as perception, prediction, planning, and action. We look at
picked binary controller structure. Our simulations show that
spikingneuralnetworkscanbeevolvedinbinarysensingagents spikingneuralnetworksasacontrollerforemergentbehaviors
to form a mill. in multi-agent systems. In this paper, we examine searching
Index Terms—Spiking Neural Networks, Evolutionary algo- forcontrollerstructuresthatproduceamillingbehavior,which
rithms, Swarming Behaviors
provides a baseline for future work on more complex behav-
iors.
I. INTRODUCTION
Our contributions are as follows:
Antsappeartobefairlysimplecreaturesonthesurface,but
• We present a framework for training a swarm to ex-
they are capable of many group behaviors, such as bridging,
hibit a specific emergent behavior, milling, with minimal
orperhapsmoreinterestingly,milling,inwhichgroupsofants
intuition and without explicitly defining the controller
march in a circle until they die. Ant mills form circumstan-
structure.
tially,inlargepartduetothepheromonesleftbehindbyother
• We show that an evolutionary algorithm can be used to
ants[1].Thesebehaviorsareemergent,thatis,thebehavioris
train a spiking neural network to produce milling in an
apropertyoftheentireswarm,resultingfromlocalinteraction
agent-based swarm simulator.
rules that do not explicitly define the global swarm state. Ant
milling is an emergent behavior; a tragic consequence of each II. BACKGROUND
ant’s internal interaction policy rather than a behavior learned
A. Spiking Neural Networks for Multi-Agent Systems
through incentives.
To replicate this behavior in a robot swarm, no explicit The third generation of neural networks take further in-
communication or pheromones are required. We restrict our spiration from the human brain [5] to create a more energy
4202
tcO
12
]EN.sc[
1v57161.0142:viXraefficient and noise resilient deep learning system operating on
spikes [6]. More formally known as spiking neural networks
(SNNs), these systems differ from traditional ANNs by prop-
agating spikes through the network rather than floating-point
values. In particular, the Leaky Integrate-and-Fire model of
neuron incorporates neuronal charge, passive leaking of said
charge over time, and variable delay of spike transmission
between neurons [7]. Perhaps the most popular motivation
for studying SNNs is their potential use in size, weight, and
power constrained applications. There is ongoing hardware
development to make this a reality [7], but such systems have
Fig.1. Diagramexplainingsensorvariablesandsensorplacement
not been widely deployed yet. SNNs are also theorized to be
moretoleranttofaultsandnoiseowingtotheirasynchronicity
and parallel processing capabilities [7]. Furthermore, this 1. Comparedtogradientbasedmethods,EAsareextremely
neuromorphic computing framework has lead to entire new flexible as the reward structure can be sparse and non-
areas of computer and neural architecture design for various differentiable.
forms of computation [8] and optimization [9]. 2. EAs have been used to evolve neural network structure
Our primary interest in SNNs lies in their inbuilt notion alongside the typical weights and biases [22].
of time and their intermingled memory owing to the charge In this paper, we use TENNlab’s [23] EONS evolutionary
accumulated on each neuron. Some variants of ANNs, such framework [24] and virtual Caspian SNN processors [25]
as the Long-Short Term Memory (LSTM) architecture, do to exploit Darwin’s Theory of Evolution [26] and design a
have memory capabilities, and have successfully been applied controller that can be homogenously applied to a swarm of
to various problems in robotics, such as path planning [10]. binary sensing agents to achieve a milling behavior. Like
However, the structure of an LSTM cell is complex and [22], EONS is capable of evolving not only the weights and
was painstakingly designed by researchers, and contains no hyperparameters of a network, but also its structure. This
inbuilt notion of time. For example, scheduling an event to techniqueresultsinmodelconfigurationsthatresemblehetero-
occur in the future would require an LSTM to be given an geneous graph structures [27] along with having a multitude
explicittimestampuponeachcycle,orrequireanaccumulator- ofuniqueperformanceattributescomparedtotraditionallayer-
like structure to be learned within the network. Compare based systems [28].
this to SNNs, where a spike can simply be delayed. We Tothebestofourknowledge,thisisthefirstworkapplying
believe that these properties of SNNs lend themselves to SNNs to a binary sensing swarm.
memory, prediction, and pre-acting, which we see as essential
components of complex behaviors. III. PROBLEMFORMULATION
In the scope of robotics, other works show SNN models We consider a swarm of N unicycle-like robots with dis-
matching or out-performing ANNs in single and multi-agent cretized kinematics for the i-th robot with i∈{1,...,N}
scenarios [11] and have also been deployed as a collision
avoidancedecisionmechanismin[12].SNNsareanappealing x i(k+1)=x i(k)+u i,1cosθ i∆t (1)
candidate for autonomous robotics, but training them requires y (k+1)=y (k)+u sinθ ∆t (2)
i i i,1 i
novel methods because their activation function is nonlinear θ (k+1)=θ (k)+u ∆t, (3)
i i i,2
and time-dependent. Training approaches include translating
pre-trained ANNs to SNNs [13], using differentiable surro- where z (k) = (x ,y ,θ ) ∈ SE(2) represent the 2D
i i i i
gatesforgradientdescentlearning [14]–[16]andevolutionary positionandorientationofagenti.Eachrobothastwocontrol
algorithms [17], [18] paired with Bayesian optimization [19], inputs in the form of a forward velocity u = v ∈
i,1 i
[20]. Evolutionary algorithms have also been used to design [−v ,v ] and a turning rate u =ω ∈[−ω ,ω ].
max max i,2 i max max
the architecture and train the weights of an SNN to process We consider a binary sensing model where agent i receives
LIDAR data and control a 4-wheeled robotics platform [21]. the observation h ∈{0,1} given by
i
In [17], a novel genetic algorithm was used to evolve a multi-
(cid:40)
agent system to compete for food. h (z)= 1 if ∃j ̸=i,s.t. z j ∈FOV i, (4)
i
0 otherwise,
B. Evolutionary Optimization for Neuromorphic Systems where the FOV i is the conical area in front of the sensor of
the ith agent with a measured distance and opening angle, as
Evolutionary algorithms (EAs) are good at exploring the shown in Fig. 1.
search space, but tend to be inefficient for exploiting and fine- Sincethegoalofthispaperisnottofindarbitraryemergent
tuning. Despite their inefficiencies, there are several reasons behaviors,buttrainnetworkstooptimizeaparticularemergent
why EAs are suited to our problem. behavior, we must choose a fitness function.In [29], it is suggested that rather than calculating rewards Although we consider an unbounded domain p ∈ R2,
i
from an agent-local perspective, using a globally defined due to practical limitations such as limited sensing range and
metric to evolve the local behaviors can lead to successful collisions, it is sensible to restrict the set of initial conditions.
flocking behaviors. To that end, we use the “circliness” value, Inparticular,weinitializeallagentpositionsp(0)randomlyin
first described in [30]. This is a measure of how perfect of a a square starting area with random heading, θ (0)∼U[0,2π).
i
circle is formed by the agents, which we take to be the fitness
x (0),y (0)∼U[−W/2,W/2] where W ∈R (10)
of a milling swarm. i i
We begin with a “fatness” measure ϕ defined in [30]. Note where W defines the width and height of the starting region.
thatthefollowingequations(5),(6)aredefinedforaparticular Additionally, no agents are overlapping each other i.e. z ∈
0
state and time z(k), which we omit for readability. Letting µ {z |∥p −p ∥>2r} for i,j ∈{1,...,N},j ̸=i
0 i j
be the average position of all agents and p = (x ,y ) ∈ R2
i i i
be the 2D position of the i-th agent, Problem 1 (Optimizing Milling) Given an initial condi-
tionz ∈S,findcontrollersu ,u asfunctionsofthebinary
1 (cid:88)N 0 i,1 i,2
µ= N p i observation of each agent h i to solve
i=1 maximize λ(T),
and r ,r be the minimum and maximum distance to the π1,π2
min max
subject to
z(T)=z(0)+∆t(cid:80)T−1f(z(k),u(k)),
center of the swarm µ, k=0
z(0)=z ,
0
r = min ∥p −µ∥, r = max ∥p −µ∥ u (k)∈[−v ,v ]∀k ∈{1,...,T −1},
min i max i i,1 max max
i∈{1,...,N} i∈{1,...,N} u (k)∈[−ω ,ω ]∀k ∈{1,...,T −1},
i,2 max max
r2 where π 1 :{0,1}∗ →u i,1 and π 2 :{0,1}∗ →u i,2 are control
ϕ=1− min (5) policies driving the forward speeds v and turning rates ω of
r2 i i
max each agent, respectively, where ∗ is the Kleene Star, denoting
As noted in [30], ϕ is a measure of radial variance. ϕ=1 “zero or more repetitions” of items from the set [31]. Thus,
indicatesthattheagentslieperfectlyonacircleattimek,and the policies π and π take as input the history of all binary
1 2
ϕ→0 implies radial scatter. networkinputssincetherobotwasturnedon.Asin[32],[33],
Instantaneous tangentness is taken as: weassumethatthecontrollersπ ,π arehomogeneousacross
1 2
the swarm.
N
1 (cid:88)
τ = |σ |, (6)
N τ
i=1
p −µ p˙
where σ = i · i (7) IV. METHODS
τ ∥p −µ∥ ∥p˙ ∥
i i To evaluate the capabilities of an SNN in creating an
=cos(θ i−∠(p i−µ)) (8) emergent milling behavior, we compare this to a symbolic
controller described in [2]: a direct binary sensing-to-action
Thus, τ = 0 indicates that agent headings are perfectly
controller, which can be formally defined as
perpendiculartothecentroid,implyingtagentnesstothecircle
formed by the agents, and τ = 1 represents all agents are (cid:40)
v , ω if h =1
facing into or away from the centroid µ. Note that instead of u i,2(h i), u i,1(h i)= a a i (11)
v , ω otherwise.
(7) from [30], we use 8 to avoid division by zero; equivalent b b
in all other cases. Whilethiscontrollercanbestatedinapurefashioni.e.u (k)
i,1
It is desired that the agents maintain this formation for depends only on h (k), it is more conducive to simulate it
i
as much of the time as possible, as opposed to a perfect as u (k) = f (h (k−1)). While the controller structure is
i,1 1 i
circle forming for a brief instant and then dissipating. To clearly defined in (11), the parameters v ,v ,ω ,ω must be
a b a b
encourage this, we use the averaged fatness and tangentness chosen to determine the behavior of the swarm. It has been
— ϕ¯(k), τ¯(k) — over the previous T window ticks i.e. over the shown to result in six unique behaviors including milling,
rolling interval [k −T window, k] where k ≥ T window. We can referred to as “circular pursuit” in [3]. To determine a set
then use the circliness metric defined in [30]: of parameters for our baseline, we use genetic algorithms,
particularly CMA-ES, further discussed in Section V-B.
λ(k)=1−max{ϕ¯(k),τ¯(k)} (9)
A controller using an SNN must be described differently:
where λ ∈ [0,1]. λ = 1 corresponds to a swarm of agents
u (k), u (k), S (k)=f (h (k−1), S (k−1)) (12)
travelling on a single circular path, and λ = 0 “represents i,1 i,2 i SNN i i
maximum disorder” as noted in [30]. where s (k) is the state of the network of agent i at time
i
Our goal now is to find controllers u and u to make k. Note that the controller can no longer be stated as a pure
i,1 i,2
circliness λ(T) as close to 1 as possible. We formalize this function; its output depends on the previous state of the SNN,
next. owing to the intermingled computing and memory.neurons have parameters that must be determined. Further-
more, we do not have a fully-connected internal network
structure, thus the network edges and edge parameters must
alsobedetermined.Todothis,weuseTENNlab’s[23]EONS
[24] library which implements genetic algorithms capable of
creatingandevolvingthenetworkstructureandparametersfor
our SNN.
We now describe the search process. First, P networks are
initialized. The two input and four output neurons are created
first. Each network is given n “floating” unconnected
hidden
nodes. Then, n edges are randomly assigned. Each node
Fig. 2. Diagram of encoding process for a single robot. Top: Sensor not edges
activated;robotdoesnot“see”anotheragent.Bottom:Sensoractivated,robot and edge’s parameters are also randomized within limits set
“sees”otheragentinitsFOV. foreachparameter(seeCaspianparametersinTableIII).Each
initial network is likely to be unique to the others in the
population.
The structure and parameters of f must be defined.
SNN We use tournament selection [24], with the n best
best
Furthermore, as the raw inputs and outputs of the spiking
networks being directly copied to the next generation. The
neural network are spikes rather than numerical values, they
parameters of random edges and nodes are mutated, and
must be converted. We detail our methods for both of these
nodes and edges may be added or removed, as described in
problems in this section.
[24]. A certain percentage of the population, determined by
random factor, is replaced with newly initialized networks.
A. Encoder and Decoder
C. Simulation
The binary output of the sensor must be encoded to a
To calculate the fitness of a particular network, a simulator
spike train to be sent to the SNN. To do this, we first
instance is instantiated. The starting positions and headings
convert the binary output of h (k) using one-hot encoding
i
z of the N agents are set from the uniform distribution
(i.e. 0→[1,0]T, 1→[0,1]T). This is a type of “binning” as 0
discussed in the problem formulation, but with a fixed seed,
describedin[34].Eachelementofthevectoristhenconverted
resulting in consistent initial state across all training runs.
to a spike train to be given to its respective input neuron: If
This is done to prevent variations in the circliness λ due to
theneuronistoreceivea1,aspikeisfedtothatinputneuron
differing initial conditions. An increase in the circliness score
on every cycle of the simulated Caspian processor containing
then is purely due to an improvement in behavior, at least
the SNN; See Figure 2 and section IV-D. The processor is
for that particular seed. N simulated Caspian processors are
then run for 3 cycles to account for spike propagation time,
created and loaded with a copy of the network structure. The
and then run for another 10 cycles.
simulatorandsimulatedCaspianSNNprocessorsarethenrun
During these cycles, the spikes are propagated through the
in the observe-act loop for T timesteps, and the static metrics
network, and some spikes will likely be emitted from the
fatness ϕ and tangentness τ are calculated and stored. Finally,
outputneurons.Thearrivaltimeandmagnitudeofthesespikes
the circliness value λ(T) from eq. (9) is used as the reward
are recorded by the decoder. For our decoder, we use a rate-
for that particular run and its associated network.
based encoding. The total number of spikes emitted from
We performed this process in parallel on a multi-core
an output neuron during the last 10 cycles is summed. This
workstation,andeachthreadisassignedthefitnesscalculation
value is then normalized by dividing by 10. As such, each
of a particular network. After each generation, if the fitness
output neuron can output 10 distinct discrete values. We use
of the best network is greater than that of the previous best,
4 output neurons; To represent negative values, we used the
the network is saved. Thus the output of the search is the first
difference in pairs of outputs, i.e. v = o −o , which allows
1 2 network to reach the maximum fitness score, if the maximum
for a maximum of 21 distinct values per pair. As this value is
score is achieved.
normalized,
D. Caspian
o∈{−1,...,0,0.1,...,1} (13)
To process the SNN, we use a simulated TENNlab Caspian
wemultiplythisbythemaximumsafeforwardvelocityv maxof processor [25], which uses a leaky-integrate-and-fire (LIF)
therobottoobtainu i,1(k+1).Anotherpairofoutputneurons
neuron model. Each neuron can take four parameters: leak,
is used for the turning rate ω =o 3−o 4, scaled to the robot’s axonal delay, threshold, and weight. Each synapse (edge) has
maximum angular velocity ω max, thus we have u i,2(k+1). two parameters: weight and synaptic delay. When a neuron
receives a spike, the magnitude of the spike is added to that
B. Evolving the Network
neuron’scharge.Overtimeasspecifiedbytheleakparameter,
As discussed in the previous section, the number of input aneuron’schargewilldecaytozero.Ifthechargereachesthe
and output neurons are fixed at two and four respectively. threshold, the neuron will spike and the charge will be reset
However, these neurons and indeed the remaining internal to resting state. A neuron can fire once per processor tick.TABLEI TABLEII
BASEPARAMETERSFORALLEXPERIMENTS(UNLESSOTHERWISENOTED) EONSPARAMETERSUSED
Variable Value Unit Description Variable Value
ProblemParameters starting nodes 10
starting edges 20
N 10 NumberofAgents
population size P
W 1.2 meters SpawnAreaWidth
crossover rate 0.5
T 1000 ticks Timehorizon
mutation rate 0.9
T window 450 ticks RollingWindowHorizon add node rate∗ 0.55
∆t 1/7.5 s timestep delete node rate∗ 0.45
vmax 0.2 m/s MaxForwardVelocity add edge rate∗ 0.6
ωmax 2.0 rad/s MaxAngularVelocity delete edge rate∗ 0.4
rsense 3.6 meters SensingRange selection type “tournament”
ψ 0.4 rad SensorFOV tournament size factor 0.1
tournament best net factor 0.9
TrainingParameters
random factor 0.10
P 100 PopulationSize
num mutations 3
n epochs 1000 Max#ofEpochs node mutations “Threshold”:1.0
“Weight”:0.65
edge mutations
“Delay”:0.35
num best 4
V. EXPERIMENTALSETUP ∗ Add/delete parameters are relative to each other
We used the parameters in Tables I, II, III for every andsumto1.0.
experiment, except where otherwise noted.
A. RobotSwarmSimulator (RSSim) TABLEIII
RANGEOFCASPIANPARAMETERSTHATEONSWASALLOWEDTO
WeusedaPython-based2Dagentsimulatortotestboththe
GENERATE.
baselinecontrollerandourSNNapproach:RobotSwarmSimu-
lator(RSSim)[35].RSSimusestheagentandsensordynamics Parameter Rangea
Threshold [0,127]
detailedinSectionIIItoupdatethepositionofeachsimulated
LeakTimeConstant None,1,2,4,8,or16
robot each tick based on the control inputs. Collisions are
AxonalDelay 0
resolved inelastically. In the case of the SNN, on each tick SynapticWeight [−127,127]
of RSSim, each robot evaluates its sensor state and sends SynapticDelay [0,255]
CyclesperTickb 13
the binary value through the encoder. An emulated Caspian
a Onlyintegervaluesareallowed.
processor executes the SNN, and its output is decoded, from
b referstothenumberofCaspiancycles
which the agent’s desired position is calculated. In the case correspondingtoasinglesense-act‘tick’inRSSim.
of the symbolic controller, the binary sensor output is used to
choose between the two sets of actuation outputs as shown in
(11), the values of which are determined using CMA-ES.
CMA-ES is configured to output continuous values for
B. CMA-ES each search parameter within the range [0, 1]. To match the
discrete nature of the SNN decoder output, (13), we round
To evolve the symbolic controllers in RSSim, we use
each output to the nearest 0.05, resulting in the discrete set
CovarianceMatrixAdaptation-EvolutionaryStrategy(CMA-
{0.0,0.05,...,0.95,1.0} (21 values). Discretized candidate
ES) [36], [37], a form of evolutionary optimization that
solutions are then mapped back to the appropriate control
samples a population from a multivariate Gaussian distri-
bution, X ∼ N (ϵ, σ2C ), and updates the mean ϵ and signalintheranges[−v max,v max],[−ω max,ω max]toobtainu i,1,
i k k
u respectively, as in (11).
covariance matrix each epoch as a way to optimize a black- i,2
box function f(x ,x ,...,x ) with k parameters. We use
1 2 k
C. EONS
CMA-ES to search for a pair of binary sensing-to-action
controllers (11) that maximizes the fitness function λ(T). For our SNN-based approach, EONS [24] was used with
Specifically, v ,v ,ω ,ω are used as the search parameters bothsimulatorstosearchforacontrollerthatmaximizesλ(T).
a b a b
(k=4), each normalized from the max forward and angular The EONS parameters used are shown in Table II unless
velocity limits to the range [0,1]. We set the initial starting otherwise noted. EONS is restricted to generating networks
mean ϵ =[0.5,0.5,0.5,0.5], and step-size, σ =0.2. During with parameters limited to the parameter space described in
0 0
each epoch, population candidates are simulated in parallel TableIII.Outsideofthis,EONSisnotprocessor-aware;ithas
and the fitness is returned to CMA-ES, which updates the no knowledge of the parameters themselves.
mean, covariance matrix, and step-size for the distribution of We first generate a population of P networks. For each
the subsequent epoch. For a fair comparison, CMA-ES uses node and edge in the network, each parameter is initialized
the same population size, P, and iteration cutoff, n as to a uniform random value within that parameter’s minimum
epochs
SNN evolutionary search. All other hyper-parameters follow and maximum values, shown in Table III. Each network in
the standard CMA-ES defaults [38]. this population is evaluated by running parallel simulationsFig.3. Top:PopulationBestFitnessperEpoch.Forthesymbolic4-parameter Fig. 4. Top: Distribution of fitness scores in the population after each
controller optimized with CMA-ES, a single run was performed, and the epoch.EachdotrepresentsthefitnessofasinglesimulationinRSSimandis
searchwasterminatedatthe263rdepoch.FortheSNNsevolvedwithEONS, transparent(opacity=0.2).ForEONS,onlydatafromthebestrunisshown.
5runswithdifferentevolutionaryseedswereperformed.Theshadedsilhouette Bottom:NumberofneuronsandsynapsesinthebestSNNforeachepochof
boundsthemin/maxfitnessachievedforaparticularepochacrosstheEONS thebestEONSrun.Note:Givenourencoding/decodingscheme,theminimum
runs. The EONS run which achieved the highest final fitness is highlighted. numberofneuronsis6.
Theannotationsindicatewhenthehighestfitnessscorewasfirstachievedin
thebestrun.
Bottom:FocusedviewofTopplot.
where that network is loaded into each robot in the swarm.
The final circliness value, λ(T), is used to compute the
fitness for that network. Neurons and synapses not part of the
input/output path were not explicitly pruned; rather, a penalty
was subtracted from λ(T) based on the number of neurons Fig. 5. Violin plot of circliness in RSSim across 100 seeds for spawn
locations (see (10)). The vertical bar denotes the mean circliness and the
and synapses for that network, following the multi-objective
dotsdenotethebestoverallcirclinessachievedduringtraining.
optimization described by Schuman et al. [24]. EONS then
evolves the population for the next epoch.
troller optimized with CMA-ES: what is likely the best score
D. Training
possible for λ is achieved in the 15th epoch. The CMA-ES
A single CMA-ES training run was conducted. For EONS, run was terminated after 263 epochs because the condition
due to the variability of the training process, five runs were numberofthecovariancematrixhadexceededthetermination
conducted across different seeds for EONS’ random number threshold:1014 inthiscase.FortheSNNcontroller,weseethe
generator. For both EONS and CMA-ES, following each variabilityinthetrainingprocessrepresentedbythesilhouette
epoch, the system time, epoch number, and the circliness val- of minimum and maximum fitnesses. One run surpassed the
ues across the population are recorded. The search processes best overall symbolic circliness score within 100 epochs, but
were performed on the same desktop computer with an AMD this run did not achieve the highest final λ of the five training
Ryzen 9 3900 desktop-class CPU running a Debian-based runs.For4outofthe5runsofEONS,thebestSNNachieved
OS inside a ProxMox virtual machine. No other tasks were a marginally higher score than the best symbolic controller
running during the search process. All evolutionary circliness found with CMA-ES.
evaluation was carried out with 24 threads (i.e. a max of 24 To evaluate and evolve 100 generations, EONS took 144
concurrent simulations). minutes to evaluate the SNNs, and CMA-ES took 2 minutes
longer.
VI. RESULTS
A. Training Fitness B. Behavior Analysis
In Figure 3, we can see that the distribution of circliness We examined the behavior of the evolved controllers by
converges within the first few epochs for the symbolic con- observing the simulation, the live network visualization, andsimulating an SNN is negligible, or at least comparable to the
time added by the CMA-ES statistical operations.
Figure 4 shows the network size changes as a result of
EONS.Wecanseethat,initially,thenetworksizeissettothe
values in Table II, but the number of neurons and synapses
falls drastically within the first 100 epochs. However, around
the 170th epoch, there is a large jump in best network size,
accompanied by a gradual shift in fitness distributions. This
Fig.6. VisualizationofmillinginRSSim.Greenwhiskersindicatethatthe
best net is similar in size to the initial network size set in
sensorisactivated.
Left:SymbolicControllerMill. TableII,suggestingthatthedistributionshiftandperformance
Right:SNNControllerMill. uptick was the result of a randomly initialized network (see
Section IV-B, random factor). The network size falls again
over the next hundred epochs, likely thanks to the multi-
objective optimization described in Section V-C. Conversely,
the growth of the network past the 300th epoch suggests that
theadditionalsynapsesareresponsibleforimprovedcircliness
scores.
In Figure 5, we can see that there is some performance
degradationwhentheinitialpositionsarechanged,suggesting
some slight over-fitting to the fixed initialization position.
However,boththeSNNandSymboliccontrollerperformwell,
with the SNN performing better overall, but with a wider
Fig. 7. Snapshot of live visualization showing simulation with a selected spread compared to that of the Symbolic controller.
robot’svisioncone(green)shown.Theselectedrobot’slivenetworkcharge At one point, a parameter was incorrectly set such that the
states are shown on the right. The neurons at the top of the graph are the
SNN’soutputdecodingwasbinnedintothreepossibleoutputs
input neurons, and the neurons at the bottom are the outputs, labeled with
theircontributiontothatagent’sspeedvi andturningrateωi. per o i, i.e. each agent could only move at −0.2,0,0.2 m/s
and turn with −2,0,2 rad/s. Despite this, it was still able to
mill with a circliness score of over 0.86, which still results in
the control outputs. In Figure 6, we see that the symbolic a milling formation. This may point to SNNs being able to
controller (11) forms a large, slow-moving, evenly spaced use temporal strategies to compensate for a lack of actuation
circle. An even number of robots have their sensors activated, resolution, but further research is needed.
andtheirpolicyisexplicitlyknownandeasytodescribe:Turn
slightly left (counter-clockwise, out of the circle) if another VII. CONCLUSIONS
object comes into view, otherwise turn right (clockwise, into
the circle). The difference in turning rates for h = 0 and Inthispaper,weinvestigateduseofspikingneuralnetworks
i
h =1 is minimal, so as to optimize tangentness, resulting in (SNNs) for use in a swarm of binary sensing agents. By
i
constant flip-flopping of the sensor. evolving an SNN to maximize a “circliness” metric, it is
The behavior for the best evolved SNN controller appears possible to find local interaction rules that lead to a desired
to work in similar fashion, except the mill is moving counter- group behavior, milling in this case, using SNNs without
clockwise. As indicated by the green whiskers, every robot explicitly defining the structure of the controller.
has its sensor activated. The agents follow a similar rule to While this work is limited to simulation, the learned SNN
the symbolic controller, but the speed of each agent fluctuates is small enough to easily be deployed on robots, allowing us
slightly, even if the sensor state does not change. While there to test the sim-to-real transfer [32] of the learned behavior in
may be more properties of the learned SNN controller, a full the future. We hope that this work inspires research on how
analysis is outside the scope of this paper. SNNscanbeusedtoformmorecomplexswarmingbehaviors.
In these experiments, a candidate controller structure (e.g.,
the symbolic binary controller) is already known. We would
C. Discussion
of course like to apply this methodology to more complex
Although the circliness λ (9) converges considerably faster problems. However, to make further progress with complex
for the symbolic controller than for the SNN controller, the problems, the training process must become more efficient.
search and simulation process itself did not take significantly Possibleapproachestothismayincludeback-propagation,but
longerfortheSNNcontroller forthesamenumberofepochs. this presents additional challenges such as how to calculate
ThisisdespitethefactthatsimulatingtheSNNrequiresaddi- local rewards from the global reward. We suggest the milling
tionalCPUtimetosimulatethespikespropagatingthroughthe problemshouldbeusedasabenchmarkasweworktoimprove
network of the simulated spiking processors. This is evidence the learning speed, as it requires emergence but is simple to
that, for small network sizes, the performance overhead of work with and intuitive to understand.REFERENCES [19] M. Parsa, J. P. Mitchell, C. D. Schuman, R. M. Patton, T. E. Potok,
andK.Roy,“Bayesianmulti-objectivehyperparameteroptimizationfor
[1] N. R. Franks, N. Gomez, S. Goss, and J. L. Deneubourg, “The blind accurate,fast,andefficientneuralnetworkacceleratordesign,”Frontiers
leading the blind in army ant raid patterns: Testing a model of self- inneuroscience,vol.14,p.667,2020.
organization (Hymenoptera: Formicidae),” Journal of Insect Behavior, [20] M. Parsa, J. P. Mitchell, C. D. Schuman, R. M. Patton, T. E. Potok,
vol.4,pp.583–607,Sept.1991. and K. Roy, “Bayesian-based hyperparameter optimization for spiking
neuromorphicsystems,”in2019IEEEInternationalConferenceonBig
[2] M. Gauci, J. Chen, T. J. Dodd, and R. Groß, “Evolving Aggregation
Data(BigData),pp.4472–4478,IEEE,2019.
BehaviorsinMulti-RobotSystemswithBinarySensors,”inDistributed
[21] R. Patton, C. Schuman, S. Kulkarni, M. Parsa, J. P. Mitchell, N. Q.
Autonomous Robotic Systems (M. Ani Hsieh and G. Chirikjian, eds.),
Haas, C. Stahl, S. Paulissen, P. Date, T. Potok, et al., “Neuromorphic
Springer Tracts in Advanced Robotics, (Berlin, Heidelberg), pp. 355–
computing for autonomous racing,” in International Conference on
367,Springer,2014.
NeuromorphicSystems2021,pp.1–5,2021.
[3] D. S. Brown, R. Turner, O. Hennigh, and S. Loscalzo, “Discovery
[22] K.O.StanleyandR.Miikkulainen,“Evolvingneuralnetworksthrough
and Exploration of Novel Swarm Behaviors Given Limited Robot
augmenting topologies,” Evolutionary computation, vol. 10, no. 2,
Capabilities,” in Distributed Autonomous Robotic Systems: The 13th
pp.99–127,2002.
InternationalSymposium(R.Groß,A.Kolling,S.Berman,E.Frazzoli,
[23] J.S.Plank,C.D.Schuman,G.Bruer,M.E.Dean,andG.S.Rose,“The
A. Martinoli, F. Matsuno, and M. Gauci, eds.), Springer Proceedings
TENNLab Exploratory Neuromorphic Computing Framework,” IEEE
in Advanced Robotics, pp. 447–460, Cham: Springer International
LettersoftheComputerSociety,vol.1,pp.17–20,July2018.
Publishing,2018.
[24] C.D.Schuman,J.P.Mitchell,R.M.Patton,T.E.Potok,andJ.S.Plank,
[4] J. J. Daymude, N. C. Harasha, A. W. Richa, and R. Yiu, “Deadlock
“EvolutionaryOptimizationforNeuromorphicSystems,”inProceedings
andNoiseinSelf-OrganizedAggregationWithoutComputation,”Aug.
ofthe2020AnnualNeuro-InspiredComputationalElementsWorkshop,
2021.
NICE’20,(NewYork,NY,USA),pp.1–9,AssociationforComputing
[5] W.Maass,“Networksofspikingneurons:Thethirdgenerationofneural
Machinery,June2020.
networkmodels,”NeuralNetworks,vol.10,pp.1659–1671,Dec.1997.
[25] J.P.Mitchell,C.D.Schuman,R.M.Patton,andT.E.Potok,“Caspian:
[6] C. D. Schuman, S. R. Kulkarni, M. Parsa, J. P. Mitchell, P. Date, and
A Neuromorphic Development Platform,” in Proceedings of the 2020
B. Kay, “Opportunities for neuromorphic computing algorithms and
Annual Neuro-Inspired Computational Elements Workshop, NICE ’20,
applications,” Nature Computational Science, vol. 2, no. 1, pp. 10–19,
(NewYork,NY,USA),pp.1–6,AssociationforComputingMachinery,
2022.
June2020.
[7] C.D.Schuman,T.E.Potok,R.M.Patton,J.D.Birdwell,M.E.Dean, [26] C.Darwin,OntheOriginofSpecies. 1859.
G.S.Rose,andJ.S.Plank,“Asurveyofneuromorphiccomputingand [27] J.Zhou,G.Cui,S.Hu,Z.Zhang,C.Yang,Z.Liu,L.Wang,C.Li,and
neuralnetworksinhardware,”CoRR,vol.abs/1705.06963,2017.
M.Sun,“Graphneuralnetworks:Areviewofmethodsandapplications,”
[8] J.B.Aimone,P.Date,G.A.Fonseca-Guerra,K.E.Hamilton,K.Henke, AIopen,vol.1,pp.57–81,2020.
B.Kay,G.T.Kenyon,S.R.Kulkarni,S.M.Mniszewski,M.Parsa,etal., [28] M.-P. Hosseini, S. Lu, K. Kamaraj, A. Slowikowski, and H. C.
“Areviewofnon-cognitiveapplicationsforneuromorphiccomputing,” Venkatesh,“Deeplearningarchitectures,”Deeplearning:conceptsand
Neuromorphic Computing and Engineering, vol. 2, no. 3, p. 032003, architectures,pp.1–24,2020.
2022. [29] R. P. Ramos, S. M. Oliveira, S. M. Vieira, and A. L. Christensen,
[9] S. Snyder, S. R. Risbud, and M. Parsa, “Neuromorphic bayesian opti- “Evolving flocking in embodied agents based on local and global
mizationinlava,”inProceedingsofthe2023InternationalConference applicationofReynolds’rules,”PloSOne,vol.14,no.10,p.e0224376,
onNeuromorphicSystems,ICONS’23,(NewYork,NY,USA),Associ- 2019.
ationforComputingMachinery,2023. [30] C. Taylor and C. Nowzari, “The impact of catastrophic collisions and
[10] F.Nicola,Y.Fujimoto,andR.Oboe,“ALSTMNeuralNetworkapplied collisionavoidanceonaswarmingbehavior,”RoboticsandAutonomous
to Mobile Robots Path Planning,” in 2018 IEEE 16th International Systems,vol.140,p.103754,June2021.
ConferenceonIndustrialInformatics(INDIN),pp.349–354,July2018. [31] Regular Expressions, pp. 28–35. Addison-Wesley Series in Computer
[11] M. Saravanan, P. S. Kumar, K. Dey, S. Gaddamidi, and A. R. Kumar, Science,Reading,Mass:Addison-Wesley,1979.
“Exploring Spiking Neural Networks in Single and Multi-agent RL [32] R. Vega, K. Zhu, S. Luke, M. Parsa, and C. Nowzari, “Simulate less,
Methods,” in 2021 International Conference on Rebooting Computing expectmore:Bringingrobotswarmstolifevialow-fidelitysimulations,”
(ICRC),pp.88–98,Nov.2021. 2023.
[12] F. Zhao, Y. Zeng, B. Han, H. Fang, and Z. Zhao, “Nature-inspired [33] S. Snyder, K. Zhu, R. Vega, C. Nowzari, and M. Parsa, “Zespol: A
self-organizing collision avoidance for drone swarm based on reward- lightweightenvironmentfortrainingswarmingagents,”inProceedings
modulatedspikingneuralnetwork,”Patterns,vol.3,no.11,2022. ofthe2023InternationalConferenceonNeuromorphicSystems,ICONS
[13] Y.Cao,Y.Chen,andD.Khosla,“SpikingDeepConvolutionalNeural ’23, (New York, NY, USA), Association for Computing Machinery,
NetworksforEnergy-EfficientObjectRecognition,”InternationalJour- 2023.
nalofComputerVision,vol.113,pp.54–66,May2015. [34] C. D. Schuman, J. S. Plank, G. Bruer, and J. Anantharaj, “Non-
[14] C. Lee, S. S. Sarwar, P. Panda, G. Srinivasan, and K. Roy, “Enabling Traditional Input Encoding Schemes for Spiking Neuromorphic Sys-
Spike-Based Backpropagation for Training Deep Neural Network Ar- tems,” in 2019 International Joint Conference on Neural Networks
chitectures,”FrontiersinNeuroscience,vol.14,2020. (IJCNN),pp.1–10,July2019.
[15] S. B. Shrestha and G. Orchard, “SLAYER: Spike layer error reassign- [35] C. Mattson and D. S. Brown, “Leveraging human feedback to evolve
ment in time,” in Proceedings of the 32nd International Conference and discover novel emergent behaviors in robot swarms,” Genetic and
on Neural Information Processing Systems, NIPS’18, (Red Hook, NY, EvolutionaryComputationConference(GECCO),2023.
USA),pp.1419–1428,CurranAssociatesInc.,Dec.2018. [36] N. Hansen and A. Ostermeier, “Completely derandomized self-
[16] E. O. Neftci, H. Mostafa, and F. Zenke, “Surrogate Gradient Learning adaptation in evolution strategies,” Evolutionary computation, vol. 9,
in Spiking Neural Networks: Bringing the Power of Gradient-Based no.2,pp.159–195,2001.
Optimization to Spiking Neural Networks,” IEEE Signal Processing [37] N. Hansen, “The cma evolution strategy: A tutorial,” arXiv preprint
Magazine,vol.36,pp.51–63,Nov.2019. arXiv:1604.00772,2016.
[17] S.Das,A.Shankar,andV.Aggarwal,“Trainingspikingneuralnetworks [38] N. Hansen, yoshihikoueno, ARF1, G. Kadlecova´, K. Nozawa, L. Rol-
with a multi-agent evolutionary robotics framework,” in Proceedings shoven, M. Chan, Y. Akimoto, brieglhostis, and D. Brockhoff, “Cma-
of the Genetic and Evolutionary Computation Conference, GECCO es/pycma:r3.3.0,”Jan.2023.
’21, (New York, NY, USA), pp. 858–865, Association for Computing
Machinery,June2021.
[18] C. Schuman, R. Patton, S. Kulkarni, M. Parsa, C. Stahl, N. Q. Haas,
J. P. Mitchell, S. Snyder, A. Nagle, A. Shanafield, and T. Potok,
“Evolutionary vs imitation learning for neuromorphic control at the
edge*,” NeuromorphicComputing andEngineering, vol.2, p.014002,
Mar.2022.