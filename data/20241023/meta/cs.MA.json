[
    {
        "title": "IBGP: Imperfect Byzantine Generals Problem for Zero-Shot Robustness in Communicative Multi-Agent Systems",
        "authors": "Yihuan MaoYipeng KangPeilun LiNing ZhangWei XuChongjie Zhang",
        "links": "http://arxiv.org/abs/2410.16237v1",
        "entry_id": "http://arxiv.org/abs/2410.16237v1",
        "pdf_url": "http://arxiv.org/pdf/2410.16237v1",
        "summary": "As large language model (LLM) agents increasingly integrate into our\ninfrastructure, their robust coordination and message synchronization become\nvital. The Byzantine Generals Problem (BGP) is a critical model for\nconstructing resilient multi-agent systems (MAS) under adversarial attacks. It\ndescribes a scenario where malicious agents with unknown identities exist in\nthe system-situations that, in our context, could result from LLM agents'\nhallucinations or external attacks. In BGP, the objective of the entire system\nis to reach a consensus on the action to be taken. Traditional BGP requires\nglobal consensus among all agents; however, in practical scenarios, global\nconsensus is not always necessary and can even be inefficient. Therefore, there\nis a pressing need to explore a refined version of BGP that aligns with the\nlocal coordination patterns observed in MAS. We refer to this refined version\nas Imperfect BGP (IBGP) in our research, aiming to address this discrepancy. To\ntackle this issue, we propose a framework that leverages consensus protocols\nwithin general MAS settings, providing provable resilience against\ncommunication attacks and adaptability to changing environments, as validated\nby empirical results. Additionally, we present a case study in a sensor network\nenvironment to illustrate the practical application of our protocol.",
        "updated": "2024-10-21 17:41:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.16237v1"
    },
    {
        "title": "LASER: Script Execution by Autonomous Agents for On-demand Traffic Simulation",
        "authors": "Hao GaoJingyue WangWenyang FangJingwei XuYunpeng HuangTaolue ChenXiaoxing Ma",
        "links": "http://arxiv.org/abs/2410.16197v2",
        "entry_id": "http://arxiv.org/abs/2410.16197v2",
        "pdf_url": "http://arxiv.org/pdf/2410.16197v2",
        "summary": "Autonomous Driving Systems (ADS) require diverse and safety-critical traffic\nscenarios for effective training and testing, but the existing data generation\nmethods struggle to provide flexibility and scalability. We propose LASER, a\nnovel frame-work that leverage large language models (LLMs) to conduct traffic\nsimulations based on natural language inputs. The framework operates in two\nstages: it first generates scripts from user-provided descriptions and then\nexecutes them using autonomous agents in real time. Validated in the CARLA\nsimulator, LASER successfully generates complex, on-demand driving scenarios,\nsignificantly improving ADS training and testing data generation.",
        "updated": "2024-10-22 07:14:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.16197v2"
    },
    {
        "title": "Spiking Neural Networks as a Controller for Emergent Swarm Agents",
        "authors": "Kevin ZhuConnor MattsonShay SnyderRicardo VegaDaniel S. BrownMaryam ParsaCameron Nowzari",
        "links": "http://arxiv.org/abs/2410.16175v1",
        "entry_id": "http://arxiv.org/abs/2410.16175v1",
        "pdf_url": "http://arxiv.org/pdf/2410.16175v1",
        "summary": "Drones which can swarm and loiter in a certain area cost hundreds of dollars,\nbut mosquitos can do the same and are essentially worthless. To control swarms\nof low-cost robots, researchers may end up spending countless hours\nbrainstorming robot configurations and policies to ``organically\" create\nbehaviors which do not need expensive sensors and perception. Existing research\nexplores the possible emergent behaviors in swarms of robots with only a binary\nsensor and a simple but hand-picked controller structure. Even agents in this\nhighly limited sensing, actuation, and computational capability class can\nexhibit relatively complex global behaviors such as aggregation, milling, and\ndispersal, but finding the local interaction rules that enable more collective\nbehaviors remains a significant challenge. This paper investigates the\nfeasibility of training spiking neural networks to find those local interaction\nrules that result in particular emergent behaviors. In this paper, we focus on\nsimulating a specific milling behavior already known to be producible using\nvery simple binary sensing and acting agents. To do this, we use evolutionary\nalgorithms to evolve not only the parameters (the weights, biases, and delays)\nof a spiking neural network, but also its structure. To create a baseline, we\nalso show an evolutionary search strategy over the parameters for the incumbent\nhand-picked binary controller structure. Our simulations show that spiking\nneural networks can be evolved in binary sensing agents to form a mill.",
        "updated": "2024-10-21 16:41:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.16175v1"
    },
    {
        "title": "Natural GaLore: Accelerating GaLore for memory-efficient LLM Training and Fine-tuning",
        "authors": "Arijit Das",
        "links": "http://arxiv.org/abs/2410.16029v1",
        "entry_id": "http://arxiv.org/abs/2410.16029v1",
        "pdf_url": "http://arxiv.org/pdf/2410.16029v1",
        "summary": "Training LLMs presents significant memory challenges due to growing size of\ndata, weights, and optimizer states. Techniques such as data and model\nparallelism, gradient checkpointing, and offloading strategies address this\nissue but are often infeasible due to hardware constraints. To mitigate memory\nusage, alternative methods like Parameter-Efficient-Fine-Tuning (PEFT) and\nGaLore approximate weights or optimizer states. PEFT methods, such as LoRA,\nhave gained popularity for fine-tuning LLMs, though they require a full-rank\nwarm start. In contrast, GaLore allows full-parameter learning while being more\nmemory-efficient. This work introduces Natural GaLore, a simple drop in\nreplacement for AdamW, which efficiently applies the inverse Empirical Fisher\nInformation Matrix to low-rank gradients using Woodbury's Identity. We\ndemonstrate that incorporating second-order information speeds up optimization\nsignificantly, especially when the iteration budget is limited. Empirical\npretraining on 60M, 130M, 350M, and 1.1B parameter Llama models on C4 data\ndemonstrate significantly lower perplexity over GaLore without additional\nmemory overhead. By fine-tuning RoBERTa on the GLUE benchmark using Natural\nGaLore, we demonstrate significant reduction in gap 86.05% vs 86.28% for\nfull-finetuning. Furthermore, fine-tuning the TinyLlama 1.1B model for function\ncalling using the TinyAgent framework shows that Natural GaLore achieving\n83.09% accuracy on the TinyAgent dataset, significantly outperforms 16-bit LoRA\nat 80.06% and even surpasses GPT4-Turbo by 4%, all while using 30% less memory.\n  All code to reproduce the results are available at:\nhttps://github.com/selfsupervised-ai/Natural-GaLore.git",
        "updated": "2024-10-21 14:05:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.16029v1"
    },
    {
        "title": "Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations",
        "authors": "Matthias BitzerReinis CimursBenjamin CoorsJohannes GothSebastian ZieschePhilipp GeigerMaximilian Naumann",
        "links": "http://arxiv.org/abs/2410.15987v1",
        "entry_id": "http://arxiv.org/abs/2410.15987v1",
        "pdf_url": "http://arxiv.org/pdf/2410.15987v1",
        "summary": "Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.",
        "updated": "2024-10-21 13:16:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.15987v1"
    }
]