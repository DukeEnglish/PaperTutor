[
    {
        "title": "The State of Reproducibility Stamps for Visualization Research Papers",
        "authors": "Tobias Isenberg",
        "links": "http://arxiv.org/abs/2408.03889v1",
        "entry_id": "http://arxiv.org/abs/2408.03889v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03889v1",
        "summary": "I analyze the evolution of papers certified by the Graphics Replicability\nStamp Initiative (GRSI) to be reproducible, with a specific focus on the subset\nof publications that address visualization-related topics. With this analysis I\nshow that, while the number of papers is increasing overall and within the\nvisualization field, we still have to improve quite a bit to escape the\nreplication crisis. I base my analysis on the data published by the GRSI as\nwell as publication data for the different venues in visualization and lists of\njournal papers that have been presented at visualization-focused conferences. I\nalso analyze the differences between the involved journals as well as the\npercentage of reproducible papers in the different presentation venues.\nFurthermore, I look at the authors of the publications and, in particular,\ntheir affiliation countries to see where most reproducible papers come from.\nFinally, I discuss potential reasons for the low reproducibility numbers and\nsuggest possible ways to overcome these obstacles. This paper is reproducible\nitself, with source code and data available from\ngithub.com/tobiasisenberg/Visualization-Reproducibility as well as a free paper\ncopy and all supplemental materials at osf.io/mvnbj.",
        "updated": "2024-08-07 16:40:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03889v1"
    },
    {
        "title": "From Data to Story: Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems",
        "authors": "Leixian ShenHaotian LiYun WangHuamin Qu",
        "links": "http://arxiv.org/abs/2408.03876v1",
        "entry_id": "http://arxiv.org/abs/2408.03876v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03876v1",
        "summary": "Creating data stories from raw data is challenging due to humans' limited\nattention spans and the need for specialized skills. Recent advancements in\nlarge language models (LLMs) offer great opportunities to develop systems with\nautonomous agents to streamline the data storytelling workflow. Though\nmulti-agent systems have benefits such as fully realizing LLM potentials with\ndecomposed tasks for individual agents, designing such systems also faces\nchallenges in task decomposition, performance optimization for sub-tasks, and\nworkflow design. To better understand these issues, we develop Data Director,\nan LLM-based multi-agent system designed to automate the creation of animated\ndata videos, a representative genre of data stories. Data Director interprets\nraw data, breaks down tasks, designs agent roles to make informed decisions\nautomatically, and seamlessly integrates diverse components of data videos. A\ncase study demonstrates Data Director's effectiveness in generating data\nvideos. Throughout development, we have derived lessons learned from addressing\nchallenges, guiding further advancements in autonomous agents for data\nstorytelling. We also shed light on future directions for global optimization,\nhuman-in-the-loop design, and the application of advanced multi-modal LLMs.",
        "updated": "2024-08-07 16:25:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03876v1"
    },
    {
        "title": "ImageSI: Semantic Interaction for Deep Learning Image Projections",
        "authors": "Jiayue LinRebecca FaustChris North",
        "links": "http://arxiv.org/abs/2408.03845v1",
        "entry_id": "http://arxiv.org/abs/2408.03845v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03845v1",
        "summary": "Semantic interaction (SI) in Dimension Reduction (DR) of images allows users\nto incorporate feedback through direct manipulation of the 2D positions of\nimages. Through interaction, users specify a set of pairwise relationships that\nthe DR should aim to capture. Existing methods for images incorporate feedback\ninto the DR through feature weights on abstract embedding features. However, if\nthe original embedding features do not suitably capture the users' task then\nthe DR cannot either. We propose ImageSI, an SI method for image DR that\nincorporates user feedback directly into the image model to update the\nunderlying embeddings, rather than weighting them. In doing so, ImageSI ensures\nthat the embeddings suitably capture the features necessary for the task so\nthat the DR can subsequently organize images using those features. We present\ntwo variations of ImageSI using different loss functions - ImageSI_MDS_Inverse,\nwhich prioritizes the explicit pairwise relationships from the interaction and\nImageSI_Triplet, which prioritizes clustering, using the interaction to define\ngroups of images. Finally, we present a usage scenario and a simulation based\nevaluation to demonstrate the utility of ImageSI and compare it to current\nmethods.",
        "updated": "2024-08-07 15:40:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03845v1"
    },
    {
        "title": "Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps",
        "authors": "Forough MehralianTitus BarikJeff NicholsAmanda Swearngin",
        "links": "http://arxiv.org/abs/2408.03827v1",
        "entry_id": "http://arxiv.org/abs/2408.03827v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03827v1",
        "summary": "Accessibility is crucial for inclusive app usability, yet developers often\nstruggle to identify and fix app accessibility issues due to a lack of\nawareness, expertise, and inadequate tools. Current accessibility testing tools\ncan identify accessibility issues but may not always provide guidance on how to\naddress them. We introduce FixAlly, an automated tool designed to suggest\nsource code fixes for accessibility issues detected by automated accessibility\nscanners. FixAlly employs a multi-agent LLM architecture to generate fix\nstrategies, localize issues within the source code, and propose code\nmodification suggestions to fix the accessibility issue. Our empirical study\ndemonstrates FixAlly's capability in suggesting fixes that resolve issues found\nby accessibility scanners -- with an effectiveness of 77% in generating\nplausible fix suggestions -- and our survey of 12 iOS developers finds they\nwould be willing to accept 69.4% of evaluated fix suggestions.",
        "updated": "2024-08-07 15:06:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03827v1"
    },
    {
        "title": "Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning",
        "authors": "Simret Araya GebreegziabherKuangshi AiZheng ZhangElena L. GlassmanToby Jia-Jun Li",
        "links": "http://arxiv.org/abs/2408.03819v1",
        "entry_id": "http://arxiv.org/abs/2408.03819v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03819v1",
        "summary": "Active Learning (AL) allows models to learn interactively from user feedback.\nThis paper introduces a counterfactual data augmentation approach to AL,\nparticularly addressing the selection of datapoints for user querying, a\npivotal concern in enhancing data efficiency. Our approach is inspired by\nVariation Theory, a theory of human concept learning that emphasizes the\nessential features of a concept by focusing on what stays the same and what\nchanges. Instead of just querying with existing datapoints, our approach\nsynthesizes artificial datapoints that highlight potential key similarities and\ndifferences among labels using a neuro-symbolic pipeline combining large\nlanguage models (LLMs) and rule-based models. Through an experiment in the\nexample domain of text classification, we show that our approach achieves\nsignificantly higher performance when there are fewer annotated data. As the\nannotated training data gets larger the impact of the generated data starts to\ndiminish showing its capability to address the cold start problem in AL. This\nresearch sheds light on integrating theories of human learning into the\noptimization of AL.",
        "updated": "2024-08-07 14:55:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03819v1"
    }
]