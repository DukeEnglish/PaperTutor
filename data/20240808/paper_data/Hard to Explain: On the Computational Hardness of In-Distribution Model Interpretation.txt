Hard to Explain: On the Computational Hardness
of In-Distribution Model Interpretation
GuyAmira,*,1,ShahafBassana,1 andGuyKatza
aTheHebrewUniversityofJerusalem,Jerusalem,Israel
Abstract. The ability to interpret Machine Learning (ML) mod- Tobridgethisgap,workbyBarceloetal.[12]proposesassessing
elsisbecomingincreasinglyessential.However,despitesignificant theinterpretabilityofanMLmodelbyexaminingthecomputational
progressinthefield,thereremainsalackofrigorouscharacteriza- complexityinvolvedingeneratingvarioustypesofexplanationsforit.
tionregardingtheinnateinterpretabilityofdifferentmodels.Inan TheideaisthatifexplanationscanbeefficientlyobtainedforanML
attempttobridgethisgap,recentworkhasdemonstratedthatitis model,itcanbeconsideredinterpretable.Conversely,ifobtaining
possibletoformallyassessinterpretabilitybystudyingthecomputa- explanations is computationally intractable, the model is deemed
tionalcomplexityofexplainingthedecisionsofvariousmodels.In uninterpretable. For example, while obtaining certain explanation
thissetting,ifexplanationsforaparticularmodelcanbeobtained formsfordecisiontreescanbecomputedinpolynomialorevenlinear
efficiently,themodelisconsideredinterpretable(sinceitcanbeex- time, these same tasks become NP-hard for neural networks [12,
plained“easily”).However,ifgeneratingexplanationsoveranML 47,44].Thisprovidesrigorousmathematicalevidencethatneural
modeliscomputationallyintractable,itisconsidereduninterpretable. networksareindeedlessinterpretablethandecisiontreesinthese
Priorresearchidentifiedtwokeyfactorsthatinfluencethecomplexity contexts.
of interpreting an ML model: (i) the type of the model (e.g., neu- Thecomputationalcomplexityofobtainingexplanationswasstud-
ralnetworks,decisiontrees,etc.);and(ii)theformofexplanation iedinavarietyofdifferentsettings[12,89,15],inwhichthecom-
(e.g.,contrastiveexplanations,Shapleyvalues,etc.).Inthiswork,we putational complexity is typically analyzed along two main axes:
claimthatathird,importantfactormustalsobeconsideredforthis (i)themodeltypeand(ii)theexplanationform.Forexample,comput-
analysis—theunderlyingdistributionoverwhichtheexplanationis ingShapleyvalueexplanationsfordecisiontreescanbeobtainedin
obtained.Consideringtheunderlyingdistributioniskeyinavoiding polynomialtime[8,88],whileobtainingminimumsizecontrastive
explanationsthataresociallymisaligned,i.e.,conveyinformation explanationsforneuralnetworksisNP-complete[12].
thatisbiasedandunhelpfultousers.Wedemonstratethesignificant
TheDistributionComponent.Inmanyexplainabilitymethods,un-
influenceoftheunderlyingdistributionontheresultingoverallinter-
derstanding the rationale behind a specific input prediction often
pretationcomplexity,intwosettings:(i)predictionmodelspairedwith
involvesdefininganexplanationthatsatisfiescertainpropertiesin anexternalout-of-distribution(OOD)detector;and(ii)prediction
inputssimilartotheonebeinginterpreted.Forinstance,inputsthat
modelsdesignedtoinherentlygeneratesociallyalignedexplanations.
areidenticaltotheoriginaloneinmostfeatures,withdifferences
Our findings prove that the expressiveness of the distribution can
inonlyafew.Thisapproachcanbeproblematicbecausethesenew
significantlyinfluencetheoverallcomplexityofinterpretation,and
inputsmightbeout-of-distribution(OOD),andmaydeviatesubstan-
identifyessentialprerequisitesthatamodelmustpossesstogenerate
tiallyfrominputsofinterest.Hence,theOODinputsmayaffectthe
sociallyalignedexplanations.Weregardthisworkasasteptowardsa
explanationinunexpectedways,andconveyunintuitiveinformation
rigorouscharacterizationofthecomplexityofgeneratingexplanations
tousers.Haseetal.[38]refertoexplanationsthatdisregardtheinput
forMLmodels,andtowardsgainingamathematicalunderstanding
distributionassociallymisaligned,i.e.,conveyinformationthatis
oftheirinterpretability.
biasedandunhelpfultousers.
This general OOD phenomenon in explanations is termed “the
1 Introduction OODproblemofexplainability"[38]andisencounteredinnumer-
ousexplanationforms,includingcounterfactualexplanations[74],
EnsuringtheinterpretabilityofMLmodelsisbecomingincreasingly contrastiveexplanations[96,36],sufficientexplanations[38,96,36],
vital,asitenhancestheirtrustworthiness,particularlywhendeployed andShapleyvalues[83].Therefore,manypracticalexplanationtech-
insafety-criticalsystems[43].However,despitesignificantadvance- niquesaimtomitigatetheimpactofOODinstances,makingthisa
mentsinthefield,thereremainsanotablelackofmathematicalrigor crucialaspectofcomputingmorepreciseexplanations[59,20,95,
inunderstandingtheinherentinterpretabilityofvariousMLmodels. 38,85,100,84].
Forinstance,manyfundamentalclaimswithininterpretability,such Inthiswork,wearguethatevaluatingthecomputationalcomplexity
as“decisiontreesaremoreinterpretablethanneuralnetworks",are ofexplainingthedecisionofamodel,shouldnotrelysolelyonthe
oftenregardedasfolkloreandlacksufficientmathematicalrigor. model type and the explanation form, but also on the underlying
distributionoverwhichtheexplanationiscomputed.Thedistribution
∗CorrespondingAuthor.Email:guy.amir2@mail.huji.ac.il. componentiscrucialforensuringthatthecomputedexplanationsare
1Equalcontribution. sociallyalignedandmeaningful.Inthispaper,weillustratetheimpact
4202
guA
7
]GL.sc[
1v51930.8042:viXraof this factor on the overall interpretation complexity, in various taskofobtaininganalignedinterpretationofthemodelmaybesub-
settingsandscenarios. stantiallymorecomplexthanthemisalignedform.
InSec.5westudythespecificcaseofself-alignedexplanations.
A Running Example. Consider the task of classifying low-
Here,ourfocusshiftsfromrelyingonanexternalOOD-detection
dimensional images as either “0" or “1". Due to the simplicity of
modeltothepossibilityofutilizingasinglemodelthatderivesaligned
thistask,letusassumethatitcanbeeffectivelylearnedusingasim-
explanations.Specifically,wefocusonthecaseofefficientlyproduc-
pledecisiontreeclassifier.Givenanimageclassifiedas“0",wecan
ingasinglemodelthatservesbothasaclassifierandasanOOD
interpretthepredictionofthedecisiontreeusingalocal,post-hoc
detector,giventhateachoftheseisrealizedseparatelybythesame
explainabilitymethod.Forinstance,wecanobtainasufficientreason
modelclass.Asweprove,thiscapabilitycorrelatestothedegreeof
S [47,25,13]:asubsetoffeatures(inthiscase,pixels)that,when
expressivenessinherentinvariousMLmodels—whilesomemodel
fixed,ensuretheimageremainsclassifiedas“0”,regardlessofthe
typespossesstherequiredlevelofexpressiveness,othersdonot.We
assignmentoftheadditionalfeaturesS.Fortunately,sincethistask
provetheseinsightsforspecificmodeltypesandshowthat,assuming
waslearnedbyadecisiontreeclassifier,obtainingalocallyminimal
P̸=NP,bothneuralnetworksanddecisiontreeshavethecapabilityto
sufficientreasoncanbeachievedinpolynomialtime[44].
deriveself-alignedexplanations,whilelinearclassifiersdonot.
However,despitetheirappeal,sufficientreasons,similarlytoother
Furthermore,relatedworkiscoveredinSec.6.Weconcludein
explanationforms,sufferfromtheOODproblemofexplainability[38,
Sec.7,anddiscussthelimitationsofourtheoreticalframework,as
96,36].Inthisparticularcase,thesufficientreasonSmaytakeinto
wellaspotentialfutureworkinSec.8.
accountOODassignmentsoverS.Inotherwords,settingthepixels
Duetospacelimitations,weprovideonlyconciseoverviewsofthe
ofStopartialimagesthatareOOD(e.g.,imagesfeaturingunrelated
proofsofourvariousclaims,andreferthereadertotheappendixfor
digits,orcats)mightresultintheimagebeingclassifiedas“1”.This
thecomprehensiveandmoredetailedproofs.
willprecludeSfrombeingasufficientreason—evenifitisonewhen
takingintoaccountonlythecontextofinterest(i.e.,allin-distribution
imagesofthedigits“0”or“1”). 2 Preliminaries
Acommonsolutionforbridgingthisgapistotrainanothermodel
Domain
todetectOODinputs,andthenuseittodismantletheeffectofany
misleadingassignment[59,20,95,38,85,100].However,thetaskof
Weassumeasetofnfeaturesx=(x ,...,x ),wherethedomain
1 n
OODdetectionisconsideredverychallenging,bothintheory[32,73]
ofeachfeatureisx ∈{0,1}.Theentirefeaturespaceisdenotedas
i
andinpractice[41,80,16]—asmodelingthefeaturedistribution F={0,1}n.Weseektolocallyinterpretthepredictionofabinary
isoftenharderthantheoriginalpredictiontask[83].Hence,obtain- classifierf : F → {0,1},i.e.,givenaninputx ∈ F,toexplainthe
inganOODclassifiermayrequiretrainingaveryexpressivemodel,
predictionf(x)oftheclassifieroverthisspecificinput.Wefollow
suchasagenerativemodelthatapproximatesthedomaindistribution
commonpracticeinthefield,andconcentrateonBooleaninputand
p (x).Forourrunningexample,forinstance,learningtodistinguish
ϕ outputvalues,tomakethepresentationclearer[7,89,12].However,
betweenin-distributionimages(“0”or“1”)andOODimages(any
manyofourfindingsarealsoapplicabletoscenariosinvolvingreal-
otherpossibleimage)maybeasubstantiallyhardertaskthanlearning
valueddata.
toclassifyimagesof“0”and“1”.Suchataskmayrequiretheuseof
amuchmoreexpressivemodel,suchasadeepgenerativeneuralnet-
work.ThecomplexityofobtainingasufficientreasonSthatignores ComplexityClassesandSecond-OrderLogic(SOL)
theeffectofanyOODassignmentmaythusbemuchgreaterthanthat
Thepaperassumesbasicfamiliaritywiththecommoncomplexity
ofsimplyexplainingthedecisiontreeclassifier,withoutconsidering
classesofpolynomialtime(PTIME)andnondeterministicpolynomial
thedistribution.Revisitingourrunningexample,thefindingsinthis
time(NP,co-NP).Thesecondorderofpolynomialhierarchy,i.e.,ΣP,
studydemonstratethatperformingthistaskisindeedNP-hard,de- 2
whichisbrieflymentionedinthepaper,isthesetofproblemsthat
spitethefactthatcomputingsuchanexplanationwithoutdistribution
becomemembersofNPgivenanoraclethatsolvesco-NPproblems
alignmentcanbedoneinpolynomialtime.
inO(1).Wealsodiscusstheclass#P,whichcorrespondstothetotal
PaperStructure.InSec.2,westartbycoveringtherelevantback- numberofacceptingpathsofapolynomial-timenondeterministicTur-
groundforthiswork.Next,inSec.3,weexamineawidevarietyof ingmachine.ItiswidelybelievedthatPTIME⊊NP⊊ΣP⊊#P[10].
2
explanationforms,suchassufficiency-based,contrastive-based,and WeusethecommonconventionL ≤ L todenoteapolynomial-
1 p 2
counting-basedexplanations,andstudyhowtheycanbeformalized timereductionfromlanguageL toL ,andL = L toindicate
1 2 1 p 2
tomaintainsocialalignment.Specifically,wedelveintothecommon thatsuchareductionexistsinbothdirections.
scenariowheretheclassificationmodeliscoupledwithanadditional Thepaperalsomakesuseofsecond-orderlogic(SOL)formulas
component—anOODdetector.Thisdetectorplaysacrucialrolein — a generalization of the first-order predicate logic. In both logic
mitigatingtheimpactofOODcounterfactualsinexplanations,and forms,existentialoruniversalquantifiersareappliedtoeachvariable
canbeusedtoalignvariousexplanationformswithadistributionof orsubsetthereof,sothattheformulaevaluatestoeithertrueorfalse.
interest.Weproceedtodemonstratethatdiverseexplanationformscan However,wechoseSOLformulasforourabstractionduetotheirhigh
beunifiedthroughasingleframework,whichcapturestheirshared expressivity(incontrasttofirst-orderlogicqueriessuggestedin[7]),
structure. Given an OOD detector, this framework can be used to astheycanalsoencodeanexplanationsize,whichisinfeasiblewith
preservethealignmentofeachoftheseexplanations;aswellasto FOL.Assuch,SOL-basedqueriesarerigorousenoughtoenablethe
studythecomputationalcomplexityofobtainingthem. formulationofgeneralproofsthatholdforanyexplanationwithin
InSec.4weprovethatforanyexplanationmatchingourabstract this framework. For each SOL formula Q, we define #Q as the
form, the complexity of interpreting a model is dominated by the correspondingcountingproblemoverthatformula—whichcounts
complexity of interpreting an OOD detector for the same type of thenumberofsatisfyingassignmentsforQ.Givenafinitenumber
explanation.SinceOODdetectioniscomputationallyhard[32],the ofinputs,implyingafinitelogic-basedmodel,eachSOLformulaisassociatedwithaspecificcomplexityclasswithinthepolynomial often,andalignswithcommonlyusedexplainabilitytechniques[77].
hierarchy,andwithacorrespondingcountingclass. Formallyput:
∀(z∈F). [f(x S;z S¯)=f(x)] (1)
ExplainabilityQueries
where(x S;z S¯)denotesanassignmentinwhichthevaluesofSare
We follow prior work [12, 15] and define an explainability query, takenfromxand,theremainingvalues(i.e.,fromS),aretakenfrom
denotedQ,whichrepresentssomeformofinterpretation.Qtakes z.
both f and x as inputs, and it outputs information regarding the GivenacontextC,indicatedbyπ,asociallyalignedsufficient
interpretationoff(x).Inlinewithpreviouswork[69,89,7,9,15], reasonisdefinedasfollows[96,36]:
ouremphasisisonexplainabilityqueriesthatoutputananswertoa
decisionproblem—providingadefiniteyes/noansweror,inthecase ∀(z∈F). [π(x S;z S¯)=1→f(x S;z S¯)=f(x)] (2)
ofQbeingacountingproblem,anumericalvalue.Forexample,Q
Awidelyobservedconventionintheliteratureisthatsmallersuf-
canprovideayes/noanswertothequestionisaspecificsubsetof
ficientreasons(relativetothesizeof|S|)aremoremeaningfulthan
featuresasufficientreason?Itcanalsocountthenumberofpossible
largerones[47,12,37].Consequently,itisinterestingtoconsidercar-
assignmentsinwhichthepredictionisaltered,ormaintained.
dinallyminimalsufficientreasons.Clearly,thesecanalsobeobtained
withrespecttoπ.Thisleadsustoourfirstexplainabilityquery:
Models
MSR(MinimumSufficientReason):
Thetechniquespresentedinthisworkareapplicabletoadiversesetof Input:Modelf,inputx,contextindicatorπ,andintegerk.
modelclasses.Still,wefocusourattentiononafewpopularmodels, Output:Yes,ifthereexistsasufficientreasonSforf(x)withrespect
locatedattheextremitiesoftheinterpretabilityspectrum:decision toπsuchthat|S|≤k,andNootherwise.
trees,linearclassifiers,andneuralnetworks.Specifically,weaddress
Wenotethatwecanconsiderthecaseofsociallymisalignedqueries
FreeBinaryDecisionDiagrams(FBDDs),whichserveasanextension
asatrivialcaseofthisdefinition,inwhichthecontextindicatoris
ofdecisiontrees,alongwithPerceptronsandMulti-LayerPerceptrons
the constant function π := 1, indicating the entire input space as
(MLPs)employingReLUactivations.Anexactformalizationofthese
in-distribution.
modelsappearsintheappendix.
Contrastive/Counterfactual-BasedExplanations.Adifferentap-
proachtointerpretingamodelisbyobservingsubsetsoffeatures
3 SociallyAlignedExplainabilityQueries
that, when altered, may cause the classification of the model to
ContextIndicator change[47,12].Thesearereferredtoascontrastiveexplanations
orcontrastivereasons,andthecorrespondingvaluesarereferredtoas
TocopewiththeundesiredeffectsofOODinputassignments,we counterfactualexplanations.WedefineasubsetS ⊆{1,...,n}as
considersomecontext C ⊆ Foverwhichanexplanationistobe contrastiveifalteringitsvaluesmaycausetheoriginalclassification
provided.Intuitively,contextCdenotestheentirepotentialsetof f(x)tochange:
in-distributioninputsthatwetakeintoconsiderationwhenproviding
anexplanation,whiledisregardingtheeffectofanyOODassignment ∃z∈F. [f(x S¯;z S)̸=f(x)] (3)
fromF\C.BecausedescribingthecontextCexplicitlyisclearly
ToavoidcounterfactualOODassignments,acontrastivesubset
non-trivial,inourframework,weinsteadassumetheexistenceofa
contextindicatorπ :F→{0,1}:abinaryclassifieroveraspecific S can be obtained with respect to a context indicator π [96], by
encoding:
contextC,i.e.,π(x)=1 .
{x∈C}
Naturally, assuming the existence of a context indicator π that ∃z∈F. [π(x S¯;z S)=1∧f(x S¯;z S)̸=f(x)] (4)
perfectlycapturesthedesiredcontextCisnon-trivialaswell.For
instance, in our running example, this requires π to identify any Similarly to sufficient reasons, smaller contrastive reasons tend
possibleimageofeither“0”or“1”.Nevertheless,practicaltoolswere tobemoremeaningful.Here,too,itisusuallymoreinformativeto
showntobeabletoapproximatesuchdomains,forexample,byusing focusoncardinallyminimalcontrastivereasons,asexpressedinthe
generative-model-based OOD classifiers, trained to learn the data followingexplainabilityquery:
distributionp (x)[92,63].Intheseparticularscenarios,theindicated
ϕ
Ccanbeseenasamereapproximationofthetrue,intendedcontext. MCR(MinimumChangeRequired):
Input:Modelf,inputx,contextindicatorπ,andintegerk.
Output: Yes, if there exists some contrastive reason S such that
SociallyAligningExplainabilityQueries
|S|≤kforf(x)withrespecttoπ,andNootherwise.
Modelinterpretabilityissubjective,andthishasledtothedesignof
Counting-BasedExplanations.Finally,anothercommonexplainabil-
multipleformsofexplanationsinrecentyears.Wefocushereona
ityformisbasedonexploringthenumberofassignmentcompletions
fewwidelyusedexplanationforms,andanalyzethemrigorously.
formaintaining(oraltering)aspecificclassification[52,28,89].As
Sufficiency-Based Explanations. A common definition of an ex- withpreviousexplanationforms,weredefinetheproblemtoavoid
planationforamodelf’sdecisionwithrespecttoaninputxisthat countingOODcompletions,whichmaycausethesocialmisalignment
ofasufficientreason[47,25,13].Asufficientreasonisasubsetof ofthecorrespondinginterpretation.Inordertodoso,wedefinethe
featuresS ⊆{1,...,n}suchthat,whenfixedtothecorresponding completioncountcofSwithrespecttoπas:
valuesinx,determinethatthepredictionremainsf(x),regardlessof
theotherfeatures’assignments[12,69].Thisnotationisusedquite c(S):=|{z∈{0,1}|S|,π(x S¯;z S)=1,f(x S¯;z S)̸=f(x)}| (5)appendix.Inessence,thisabstractformcapturesvarious(logically
CC(CountCompletions): expressible)explanationformulations,overwhichwecandismantle
Input:Modelf,inputx,contextindicatorπ,andsubsetoffeatures theeffectofOODcounterfactuals.
S. By using this single, broader form of Q, we are able to prove
Output:Thecompletioncountc(S)off(x)withrespecttoπ. generalpropertiesregardingsociallyalignedexplainabilityqueries,
anddeducethecomplexityofinterpretingthesequeriesinvarious
ThewidelyusedShapleyvalues[83],whichserveasacommon
settings.
formofexplanation[64,84],canalsobecharacterizedasatypeof
countingproblem[88,8].
4 TheComplexityofObtainingSociallyAligned
Explanations
AbstractQueryForm
AGeneralFramework
Manyoftheexplanationformsstudiedintheliterature,includingthe
aforementionedones,becomemoremeaningfulwhentheeffectof Toevaluatethecomputationalcomplexityofinterpretingaspecific
OODcounterfactualsarereduced.Foranalyzinghowdistributions classofmodels,denotedasC ,itisusefultodefineQ(C )asthe
M M
affect the complexity of obtaining explanations not only for one computationalproblemrepresentedbyinterpretingasetofmodels
specificexplanation,butforawidearrayofexplanationforms,we withintheclassC withrespecttoanexplainabilityqueryQ[12,
M
proceedtodefineabstractexplainabilityqueries.Wethenprovide 15].Toillustrate,letusconsidertheclassofmulti-layerperceptrons
generalresultsregardingthecomputationalcomplexityofobtaining denotedasC .MSR(C )isthenthecomputationalproblemof
MLP MLP
thisabstractformofexplanation. obtainingcardinallyminimalsufficientreasonsforanMLP,givenan
Thetaskofobtainingeachoftheexplanationtypesdiscussedso inputx.
farcanbeachievedbyinvokingadecisionprocedurefordetermining Whilethisformalizationishelpfulforassessingtheinterpretability
whetherornotf(x S¯;z S)=f(x)(orforsolvingthecorresponding ofaspecificmodeltype,itdoesnotconsidertheunderlyingcontext
countingproblem).Thesedecisionproceduresreceiveapartialas- andthus,itmayproducesociallymisalignedexplanations.
signment(x S¯;z S)ofagiveninputx,whichfixessomefeaturesofx Werevisitourrunningexample,whereourmodelf representsa
whileallowingtheresttochangeaccordingtoanarbitraryz;andtheir decisiontree.Wefurtherassumethatthedecisionofwhetherx∈C
goalistodeterminewhethertheseassignmentspreserve,oralter,the (orequivalently,whetherxisin-distribution)islearnedbyanother
classificationoutcome. model,e.g.,adeepneuralnetwork.Inthisscenario,thecontextindi-
The task of deciding whether or not f(x S¯;z S) = f(x) can, in catorπbelongstoadifferentclassthanf (whichisinC M).Insuch
turn,beformulatedasanSOLformula,SOL ¬f,whichencodesthat acase,weshouldposeadifferenttypeofquestionthatassessesthe
f(x S¯;z S) ̸= f(x) (or, again, the counting problem over that for- computationalcomplexityofprovidingasociallyalignedexplanation
mula).IfSOL ¬f isfalse,thentheanswertotheoriginalproblemis foraninstanceclassifiedbyf.Specifically,weneedtodetermine
affirmative;andotherwise,itisnegative. thecomputationalcomplexityofinterpretingamodelf ∈C while
M
Therelevantformulaisfullyquantified,inamannerthatrepresents ensuringitsalignmentwithacontextindicatorfunctionπ∈C .As
π
aspecificexplanationform.Forexample,contrastivereasonqueries mentionedearlier,inmanyinstances(includingourexample),πcor-
checkwhetherthereexistsanyassignmentleadingtoamisclassifica- respondstoamoreexpressivefunctionthanf,potentiallydominating
tion,whereassufficientreasonqueriesaskwhethertheclassification theoverallcomplexity.Therefore,weintroducethefollowingnotion
stays constant for all possible completions. The goal is to eventu- thatenablesustoassessthecomputationalcomplexityofmodelsin
allydeterminewhethertheformulaistrueornot,andequivalently— C withrespecttoaclassofcontextindicatorsC .
M π
whethertheexplanationiscorrect.
Intheappendix,weshowhoweachofthepredefinedexplainability Definition 3. Given an explainability query Q, a class of predic-
queriescanbeformalizedusingthisnotion,inwhichMSR(Minimum tion models C M, and a class of context indicators C π, we define
SufficientReason)andMCR(MinimumChangeRequired)arepos- Q(C M,C π)asthecomputationalproblemofQdefinedbytheset
siblesolutionstoanunderlyingsatisfiabilityqueryoverSOL ¬f,and offunctionswithinC M,withrespecttothecontextsinducedbythe
CC(CountCompletions)isthecountingsolutionof#SOL ¬f.This functionsofC π.
canalsobeextendedtoadditionalexplanationforms.
Forourrunningexample,Q(C ,C )denotesthecomputational
DT MLP
Definition 1. Let SOL be an SOL formula encoding the query complexityofsomeexplainabilityqueryQ,giventhatourclassifica-
¬f
f(x S¯;z S) ̸= f(x).Wedefineanabstractquery,Q,thatreceivesf tionmodelisadecisiontreeandtheOODdetectorisamulti-layer
andxasinputs,andanswerswhetherSOL istrue.Forthecounting perceptron.Wenotethat,similarlytothepreviouslystudiedevalu-
¬f
case,Qreturnsthecountingof#SOL ¬f. ationofQ(C M)[12],theformalizationofQ(C M,C π)considersa
“worst-case”scenarioofthecorrespondingalignment,andnotany
Next,weadjustthisabstractqueryformtoprovideonlysocially
parameter-specificconfiguration.Thisiscapturedbyassessingthe
aligned explanations. This is performed by incorporating into the
correspondingcomplexitywithrespecttoaclassofpredictionmodels
formulatheadditionalconstraintπ(x S¯;z S)=1,whichguarantees
andaclassofdistributionindicators.
thatanyexplanationthatsatisfiesthequeryisalsoin-distribution.
Definition2. LetSOL beanSOLformulaencodingthequery TheComplexityofQ(C ,C )
¬f,π M π
f(x S¯;z S)̸=f(x)∧π(x S¯;z S)=1.Therespectivealignedquery,Q,
We prove a connection between the complexity of calculating an
receivesasinputsf,x,andπ,andanswerswhetherSOL istrue.
¬f,π
alignedexplanationQ(C ,C ),tothecomplexityofobtainingmis-
Forthecountingcase,Qreturnsthecountingof#SOL . M π
¬f,π
alignedexplanationsofeitherQ(C )orQ(C ).Thisrelationholds
M π
Anyofthealignedqueryformsmentionedintheprevioussection inabroadsense,asweproveitforourabstractqueryformQ,defined
canbedescribedasanabstractnotionofthisqueryasweshowinthe inSec.3.First,clearly,if1 ∈ C (1isatrivialfunctionthatacceptsany whereKisacomplexityclassofthepolynomialhierarchy(orthe
π
possible inputas in-context), then Q(C ,C ) is polynomiallyre- classassociatedwithitscountingproblem),thenQ(C ,C )isalso
M π M π
duciblefromQ(C ).Wenotethat1 ∈ C isatrivialrequestfor K-complete.
M π
anyexpressiveclassofcontextindicators,forexample,assumingthe
existenceofaneuralnetworkthatalwaysoutputs1. The“hardness”partofTheorem3isadirectconsequenceofTheo-
rems1and2.However,whenspecificallyconsideringMLPs,com-
Theorem1. If1∈C πthenQ(C M)≤ p Q(C M,C π). pletenessalsoholds.Theproofofthisclaimisrelegatedtotheap-
pendix, and is a result of the fact that any Boolean circuit can be
This result is, of course, not surprising and a more interesting
polynomiallyreducedtoanMLP[12].Thisrelationimpliesthatthe
connection to explore is the less straightforward relation between
“hardest”possiblecomplexityclassinthepolynomialhierarchyis
Q(C ,C )andQ(C ).Weshowthatasimilarresulttotheformer
M π π alwaysassociatedwiththeoneforinterpretinganMLPoverQ.Fig.1
canbeobtainedinthiscaseaswell,providedthatC issymmetrically
π depictstherelationsamongdifferentcomplexityclasses,asderived
constructible(givensomef ∈C ,wecanconstructinpolynomial
π fromTheorems1,2,and3.
time¬f ∈ C );andthatC isnaivelyconstructible(givensome
π M
x∈F,itholdsthatwecanconstructinpolynomialtime1 ∈C ).
{x} M
Afullformalizationoftheseconditionsisprovidedintheappendix. 𝑸(𝑪 )
𝑴𝑳𝑷
Laterinthissection,wealsodemonstratethattheseconstructions
alsoholdforpopularfunctionclasses,andprovidemodel-specific
𝑪 |𝑪 =𝑪
instantiationsofourframework. 𝑴 π 𝑴𝑳𝑷
Theorem2. IfC MissymmetricallyconstructibleandC πisnaively 𝑸(𝑪 ,𝑪 )
constructible,thenQ(C )≤ Q(C ,C ). 𝑴 π
π p M π
Theorem2indicatesthat,givenbasicassumptionsregardingthe
expressivityofC andC ,itholdsthatthecomplexityofevaluating
M π
Q(C ,C ), i.e., interpreting a model from C with respect to a
M π M
modelfromC ,forsomeexplainabilityqueryQ,isatleastashard
π 𝑸(𝑪 ) 𝑸(𝑪 )
asinterpretingQ(C ),i.e.,interpretingtheOODdetectorπ.Thisis 𝑴 π
π
significant—asinmanycasesC π,theclassassociatedwiththeinput Figure1:AvisualillustrationofTheorems1,2,and3.Dashedlines
distribution,ismuchmoreexpressivethanC ,theclassassociated depictthatbothqueriesareinthesamecomplexityclass,andarehard
M
withthepredictionmodel,andhencemaybemuchhardertointerpret. forthatclass.Arrowsaredirectedfromthequerywiththe“easier”
complexityclasstothequerywiththe“harder”complexityclass.
Proofsketch.ThereductionexploitsthenaiveconstructibilityofC ,
M
withtheaimofrenderingobsoletetheconjunctresponsibleforvali-
InTable1,weexemplifytheaforementionedexplainabilityqueries
datingwhetherasubsetiscontrastive.Thereductiontakesadvantage
(MCR,MSR,andCC)andaspecificscenariowhereC issettoeither
of thefact that π ∈ C is symmetrically constructible inorder to M
π C orC ,whereasthecontextindicatorC issettoC
transformπtovalidatethemodelinsteadoftheindicatedcontext.By FBDD Perceptron π MLP
(thisisthecaseofourrunningexample,inwhichtheOODdetectionis
employingthisapproach,itbecomesfeasibletopolynomiallyreduce
performedusingamoreexpressivemodelthantheoriginalclassifier).
anySOLformularepresentingQ(C )toanequivalentSOLformula
π Hence,Theorem3impliesthatthecomplexityofsolvingthealigned
undertheformulationofQ(C ,C ).Consequently,anydecisionor
M π queryisprimarilydeterminedbythecomplexityinvolvedinusingan
countingsolutionfortheoriginalSOLformulawillbetantamountto
MLP,assummarizedinTable1.
solvinganequivalentSOLformulacorrespondingtoaqueryseeking
sociallyalignedexplanations.
5 “Self-Alignment”:IncorporatingSocial
AlignmentwithinaSingleModel
Model-SpecificFrameworkInstantiations
Untilnow,wefocusedonthegeneralscenarioinwhichf andπare
Next,wepresentspecificresultswhenfocusingonFBDDs,Percep-
chosenfromtwodifferentmodelclasses(forinstancef isadecision
trons,andMLPs.Itisstraightforwardtoshowthattheseclassesof
tree,andπ isaneuralnetwork).However,insomecases,f andπ
modelsmatchourtheoreticalframework,asthefollowingholds(and
canbetwomodelsofthesametype,i.e.,fromthesameclass.Inthis
proveninourappendix):
scenario,givenaclassifierandanOODdetector,bothfromthesame
Proposition1. FBDDs,Perceptrons,andMLPsareallsymmetrically class,practitionersmightdecidetotrainasinglemodelthatlearns
constructibleandnaivelyconstructible. boththepredictiontaskandthealignmenttask.Moreformally,we
saythatasinglemodelclassCis“self-aligned”whenitisexpressive
Dominance of Interpreting MLPs. We prove that when dealing enoughtoincorporatethisdualprocedure.Thisisdemonstratedby
withcomplexityclassesofexplainabilityqueriesthatarefromthe thefactthatgivenamodelf andacontextindicatorπ,anewmodelg
polynomialhierarchy(suchasNP,ΣP,etc.),thecomplexityclass canbeefficientlyconstructedtoshowthealignmentoff withrespect
2
associatedwiththeMLPalwaysdominatestheoverallcomplexity. tothedistributionindicatedbyπ:
Hence,theexactcomplexityclassofQ(C ,C )whenC =C
M π M MLP
Definition4. AclassofmodelsCisself-alignedifforanyf,π∈C,
and/orC =C ,isequivalenttothatofQ(C ).Thisclaimholds
π MLP MLP
and any inputs x and I, there exists a polynomially constructible
foranyclassofpolynomiallycomputablefunctions.
functiong∈C,suchthat:
Theorem3. LetC ,C beclassesofpolynomiallycomputablefunc-
M π
tionssuchthatC =C orC =C .IfQ(C )isK-complete, ⟨f,π,x,I⟩∈Q(C,C) ⇐⇒ ⟨g,x,I⟩∈Q(C) (6)
M MLP π MLP MLPTable1:ThecomputationalcomplexityofQ(C M)andQ(C M,C π)withrespecttovariousexplainabilityqueries.
C =C C =C
M FBDD M Perceptron
Q(C ) Q(C ,C ) Q(C ) Q(C ,C )
M M MLP M M MLP
MCR PTIME NP-complete PTIME NP-complete
MSR NP-complete ΣP-complete PTIME ΣP-complete
2 2
CC PTIME #P-complete #P-complete #P-complete
Intuitively,foranypossibleexplainabilityquerywithinQ(decision BuildinguponProposition4,wecandeducethefollowingcorollary
orcounting),explanationsoff,alignedbyπ,canbeexpressedbya (provedintheappendix):
singleaggregatedfunctiong.Clearly,gmustbeatleastasexpressive
as the original models f and π. This raises the question of how Theorem 5. Assuming that P ̸= NP, the class C Perceptron is not
expressiveaclassofmodelsCshouldbe,forittobeself-aligned. self-aligned.
Theorem4. GivenaclassofmodelsC,ifforanyf 1,f 2 ∈C,wecan Thesefindingsunderscoreacrucialaspectconcerningtheinter-
polynomiallyconstructg:=f 1[op]f 2 ∈C,for[op]∈{∧,→},then pretabilityofPerceptrons.Whileproducingexplanationspertainingto
Cisself-aligned. themcanbeachievedwithlowcomputationalcomplexity(providing
furtherevidenceoftheirinterpretability),theyarenotself-aligned.
Intuitively,classesofmodelsthatarecapableofexpressingthe
Consequently,obtainingalignedexplanationsusingPerceptronsne-
logicaloperators→and∧arecapableof“capturing”thatagivenex-
cessitatestheadoptionofamoresophisticatedmodel,thatisexpres-
planationformisdeterminedbyitsunderlyingdistribution.Theproof
siveenoughtoincorporatesocialalignment—andthis,inturn,can
ofthistheoremisrelegatedtotheappendix,andcanbeobtainedby
significantlyincreasetheoverallcomplexityoftheirinterpretation.
showinganequivalencebetweenthetwounderlyingformalizations.
Ifself-alignmentimpliesthat,givenapredictionmodelf anda
contextindicatorπ,wecanattainasingleaggregatedmodelg—then 6 RelatedWork
clearly the computational complexity of interpreting f ∈ C with
respecttoπ∈C(i.e.,thecomplexityofQ(C,C))iscorrelatedtothe This work continues a line of research that focuses on Formal
complexityofinterpretingg∈C(i.e.,thecomplexityofQ(C)).This XAI [46, 89, 9, 7, 48, 13, 14]. Prior studies have already in-
canbedemonstratedbythesubsequentproposition: vestigated the explanation forms that were analyzed within our
work[7,89,9,7],includingsufficiency-basedexplainabilityqueries
Proposition2. IftheconditionsinTheorem4holdforaclassof
(MSR)[47,69],contrastive/counterfactual-basedqueries(MCR)[81,
modelsC,thenQ(C,C)= Q(C).
P 49],andcounting-basedqueries(CC)[28].Otherwork[36]defined
formalnotionsofsufficientandcontrastivereasonsunderspecific
Model-SpecificResults
contextsandsuggestedwaystocomputethemonawiderangeof
models[96].However,theseexplanationformswerenotanalyzed
Wemoveontoanalyzewhichoftheaforementionedmodelclasses
withrespecttotheiroverarchingcomputationalcomplexity.Closerto
incorporateself-alignment.First,weshowthatbothFBDDsandMLPs
oursistheworkofCooperetal.[21]whichanalyzesdifferentprop-
areself-aligned,whichisaresultoftheircapabilitytopolynomially
erties(includingthecomputationalcomplexity)ofsufficiency-based
express→and∧relationswithintheirclass:
explanationsunderlogicalconstraints.Wealsoacknowledgethework
Proposition3. FBDDsandMLPsareself-aligned,andhence,itfol- ofArenasetal.[7],whichdescribesagenerallogic-basedexplanation
lowsthat:Q(C FBDD,C FBDD)= P Q(C FBDD)andQ(C MLP,C MLP)= P form,similartoourabstractqueryform.Whiletheirworkfocuses
Q(C MLP). onexplanationsoffirst-orderlogicformsfordecisionqueries,our
approachismoreexpressive,encompassingsecond-orderlogicforms
However,incontrasttodecisiontreesandneuralnetworks,linear
thatincorporatebothdecision-basedandcounting-basedexplanations.
classifierslacktheabilitytocapturethenotionofself-alignment.Itis
Anotherlineofresearchexaminesthecomputationalcomplexity
importanttonotethatasinglePerceptroncannotinherentlyrepresent
of obtaining Shapley value-based explanations [8, 88, 72], where
the→and∧relationsovertwootherPerceptrons.Thatsaid,itis
alignmentwithrespecttoagivendistributionisvital[83].Specifically,
worthemphasizingthatthisobservationalonedoesnotconclusively
VandenBroecketal.[88]identifyacomplexitygapininterpreting
establishtheirlackofself-alignment,asthisconditionissufficient
Shapley valueswhen consideringfullyfactorized orNaiveBayes-
butnotnecessary.TorigorouslyprovetheinabilityofPerceptronsto
modeleddistributions.
beself-aligned,weprovethesubsequentproposition:
Insomecases,theterm“sufficientreason”isalsodefinedasan
Proposition 4. While the query MCR(C ) can be solved in abductiveexplanation[47]andcorrelateswiththenotionofaprime
Perceptron
polynomialtime,thequeryMCR(C ,C )isNP-complete. implicantforaBooleanclassifier[28].TheCCqueryisassociated
Perceptron Perceptron
withprobabilisticnotionsofexplainability,bycorrelatingthepre-
Proofsketch.Membershipresultsfromthefactthatwecanguessa cision of the explanation with the number of possible input com-
subsetoffeaturesSandvalidatewhetheritiscontrastiveforf and pletions[77,89].Asimilarnotion,formallyknownasaδ-relevant
whetheritisalsoin-distribution(byfeedingittoπ).Forhardness, set[52,89],focusesonboundingthisspecificportion.
wereducefromSSP(thek-subset-sumproblem),whichisaclassic ThedependencyofexplanationsonOODassignmentshasbeen
NP-completeproblem.ThereductionexploitstherangesofthePer- studiedextensively[97,84,33,39,59,40,95,83].Specifically,many
ceptronsofbothf andπ inordertobindthetargetsumT ofthe heuristic-basedtoolsandframeworkshavebeenproposedfordeal-
subset,bothfromaboveandfrombelow. ingwiththeOODcounterfactualprobleminmodelexplainability.Theseincludemarginalizingthepredictionofthemodeloverpos- sharedcharacteristicsamongdifferenttypesofexplainabilityqueries
siblecounterfactualassignments[100,59,95],samplingpointsin canbeutilizedtooffermoregeneralizedassessments.
theproximityoftheoriginalinput[20,79,77],aswellascounter- Finally, we highlight that our study primarily concentrates on
factualtraining[38,87]—amethodthat,similarlytoadversarial an OOD detector π(x), which classifies each input as either in-
training[99],seekstorobustifymodelstoOODcounterfactuals.Other distributionorOOD,ratherthanontheinputdistributionp (x)itself.
θ
workfocusesonmitigatingtheeffectofOODassignmentsonthe Thisapproachisduetothestrictlyformalnatureoftheexplanations
computationofShapleyvalues[83,56,85].Inspiteofthesenotable we investigate; an explanation is either valid or not, necessitating
accomplishments,thetheoreticalanalysisoftheOODcounterfactual a definitive categorization of the presence or absence of each in-
problemwithrespecttoitscomputationalcomplexityhasyettobe put.Incontrast,probabilisticexplanationforms,suchasδ-relevant
thoroughlyexamined. sets[89,52]orShapleyvalues[64,83],aredefinedinrelationtothe
distributionitselfandcanalsobeassessedbasedonthecomputational
complexityofobtainingthem.Forinstance,arecentstudybyMar-
7 Conclusion
zouketal.[72]exploresthecomputationalcomplexityofcalculating
Computationalcomplexitytheorystandsasapotentialavenuetofor- ShapleyvalueswithinMarkoviandistributions.Futureresearchcan
mallyassesstheinterpretabilityofvariousMLmodels.Priorresearch focusonexpandingthestrictlyformalexplanationframeworkdis-
examinedthisbyconsideringtwomainfactors:themodeltypeandthe cussedheretoincludeprobabilisticexplanationformsaswell,where
explanationform.Weclaimthatathirdandimportantfactorshouldbe complexityassessmentswouldfocusdirectlyontheinputdistribution
takenintoconsideration—theunderlyingdistributionoverwhichthe p θ(x)ratherthanontheOODdetectorπ(x).Other,broaderfuture
explanationiscomputed.Toachievethisgoal,wegeneralizeexisting workcanexploretherelationbetweenthecomputationalcomplexity
explainabilityqueriesandshowhowaunifiedformcandescribethe ofgeneratingexplanations(ourcurrentfocus)andthecomplexityof
desiredsocialalignmentrequirementforanyexplanationformunder theexplanationsthemselves.Thiscanbeachievedusingvarioustools,
oursecond-orderlogicformalization.Moreover,wepresentaframe- suchasKolmogorovcomplexity.Wealsocoveradditionalextensions
workforassessingthecomputationalcomplexityofthesequeriesand ofourframeworkintheappendix.
demonstratethat,forabroadrangeofmodeltypesandqueryforms,
providingsociallyalignedexplanationsisashardasinterpretinga Acknowledgments
modeldesignedtodetectOODinputs.AsOODdetectionisknown
This work was partially funded by the European Union (ERC,
tobesubstantiallydifficult,suchmodelsmayoftenrequiremoreex-
VeriDeL,101112713).Viewsandopinionsexpressedarehowever
pressivecapacitythantheoriginalclassificationmodels,significantly
thoseoftheauthor(s)onlyanddonotnecessarilyreflectthoseofthe
impactingtheoverallcomplexityofmodelinterpretation.Finally,we
EuropeanUnionortheEuropeanResearchCouncilExecutiveAgency.
provideananalysisoftherequiredcapacityofmodelstoinherently
NeithertheEuropeanUnionnorthegrantingauthoritycanbeheld
producealignedexplanationswithoutusinganexternalOODdetector.
responsibleforthem.TheworkofAmirwasfurthersupportedbya
Wehopethatourworkservesasafoundationforadeepermathemat-
scholarshipfromtheCloreIsraelFoundation.
icalunderstandingoftheinterpretabilitypertainingtovariousML
models.
References
8 LimitationsandFutureWork [1] G.Amir,M.Schapira,andG.Katz. TowardsScalableVerification
ofDeepReinforcementLearning.InProc.21stInt.Conf.onFormal
MethodsinComputer-AidedDesign(FMCAD),pages193–203,2021.
Ourframeworkcanbeextendedalongseveraldifferentaxes.Firstand
[2] G.Amir,H.Wu,C.Barrett,andG.Katz.AnSMT-BasedApproachfor
foremost,wenotethatassumingtheexistenceofacontextindicatorπ VerifyingBinarizedNeuralNetworks.InProc.27thInt.Conf.onTools
foridentifyingOODinputsishighlynon-trivial.Previouswork,both andAlgorithmsfortheConstructionandAnalysisofSystems(TACAS),
theoreticalandpractical,hashighlightedthechallengesassociated pages203–222,2021.
[3] G.Amir,T.Zelazny,G.Katz,andM.Schapira. Verification-Aided
withobtainingsuchanOODdetector[32,73,41,80,16].However,
DeepEnsembleSelection.InProc.22ndInt.Conf.onFormalMethods
itisimportanttoemphasizethatourframeworkdoesnotnecessarily inComputer-AidedDesign(FMCAD),pages27–37,2022.
assumethecompleteaccuracyorcorrectnessofsuchaclassifier.In- [4] G.Amir,D.Corsi,R.Yerushalmi,L.Marzari,D.Harel,A.Farinelli,
andG.Katz.VerifyingLearning-BasedRoboticNavigationSystems.
stead,πcanbeviewedasafunctionthatprovidesanapproximation
InProc.29thInt.Conf.onToolsandAlgorithmsfortheConstruction
oftheunderlyingcontextC.Therefore,futureresearchendeavors andAnalysisofSystems(TACAS),pages607–627,2023.
couldcenteraroundevaluatingthecomputationalcomplexityofspe- [5] G.Amir,Z.Freund,G.Katz,E.Mandelbaum,andI.Refaeli.veriFIRE:
cificapproximationstailoredtoparticularcontextsofinterest.While VerifyinganIndustrial,Learning-BasedWildfireDetectionSystem.In
Proc.25thInt.SymposiumonFormalMethods(FM),pages648–656,
theseapproximationsmayonlyofferapartiallyguaranteedsolution
2023.
tothealignmentissue,theymaystillexhibitanimprovedcomplexity [6] G.Amir,O.Maayan,T.Zelazny,G.Katz,andM.Schapira.Verifying
overall. GeneralizationinDeepLearning.InProc.35thInt.Conf.onComputer
AidedVerification(CAV),pages438–455,2023.
Otherlimitationscorrespondtosimilar(non-aligned)approaches
[7] M.Arenas,D.Baez,P.Barceló,J.Pérez,andB.Subercaseaux.Foun-
for analyzing the computational complexity of obtaining explana- dationsofSymbolicLanguagesforModelInterpretability. InProc.
tions[12,89,15].Firstly,ouranalysisconsidersonlyaworst-case 34thInt.Conf.onAdvancesinNeuralInformationProcessingSystems
scenariothatmaychangeundervariousparameter-specificconfigu- (NeurIPS),pages11690–11701,2021.
[8] M.Arenas,P.Barceló,L.Bertossi,andM.Monet.TheTractabilityof
rations.Secondly,thenaturalsubjectivityofinterpretabilitymakesit
SHAP-Score-BasedExplanationsforClassificationoverDeterministic
challengingtoanalyzethecomputationalcomplexityofinterpreting andDecomposableBooleanCircuits. InProc.35thAAAIConf.on
amodelinasingle“correct”way.Toaddressthisissue,theoretical ArtificialIntelligence,pages6670–6678,2021.
frameworksdefinevariousexplainabilityqueriesandevaluatethem [9] M.Arenas,P.Barceló,M.RomeroOrth,andB.Subercaseaux. On
ComputingProbabilisticExplanationsforDecisionTrees. InProc.
separately.Weregardourproofforawiderangeofexplainability
35thInt.Conf.onAdvancesinNeuralInformationProcessingSystems
queriesQ(theabstractqueryform)aspotentialevidencethatthe (NeurIPS),pages28695–28707,2022.[10] S.AroraandB.Barak.ComputationalComplexity:AModernApproach. Perceptron)—aReviewofApplicationsintheAtmosphericSciences.
CambridgeUniversityPress,2009. AtmosphericEnvironment,32(14-15):2627–2636,1998.
[11] G.Audemard,J.Lagniez,P.Marquis,andN.Szczepanski.Computing [35] T.Gehr,M.Mirman,D.Drachsler-Cohen,E.Tsankov,S.Chaudhuri,
AbductiveExplanationsforBoostedTrees.InProc.26thInt.Conf.on andM.Vechev. AI2:SafetyandRobustnessCertificationofNeural
ArtificialIntelligenceandStatistics(AISTATS),2023. NetworkswithAbstractInterpretation.InProc.39thIEEESymposium
[12] P.Barceló,M.Monet,J.Pérez,andB.Subercaseaux. ModelInter- onSecurityandPrivacy(S&P),2018.
pretabilitythroughtheLensofComputationalComplexity. InProc. [36] N.GorjiandS.Rubin. SufficientReasonsforClassifierDecisions
33rdInt.Conf.onAdvancesinNeuralInformationProcessingSystems inthePresenceofDomainConstraints. InProc.36thAAAIConf.on
(NeurIPS),pages15487–15498,2020. ArtificialIntelligence,pages5660–5667,2022.
[13] S.BassanandG.Katz. TowardsFormalApproximatedMinimalEx- [37] J.HalpernandJ.Pearl.CausesandExplanations:AStructural-Model
planationsofNeuralNetworks.InProc.29thInt.Conf.onToolsand Approach.PartI:Causes. TheBritishJournalforthePhilosophyof
AlgorithmsfortheConstructionandAnalysisofSystems(TACAS), Science,2005.
pages187–207,2023. [38] P.Hase,H.Xie,andM.Bansal.TheOut-of-DistributionProbleminEx-
[14] S.Bassan,G.Amir,D.Corsi,I.Refaeli,andG.Katz. FormallyEx- plainabilityandSearchMethodsforFeatureImportanceExplanations.
plainingNeuralNetworkswithinReactiveSystems.InProc.23rdInt. InProc.34thInt.Conf.onAdvancesinNeuralInformationProcessing
Conf.onFormalMethodsinComputer-AidedDesign(FMCAD),pages Systems(NeurIPS),pages3650–3666,2021.
10–22,2023. [39] S.Hooker,D.Erhan,P.Kindermans,andB.Kim. ABenchmarkfor
[15] S.Bassan,G.Amir,andG.Katz.Localvs.GlobalInterpretability:A InterpretabilityMethodsinDeepNeuralNetworks. InProc.32nd
ComputationalComplexityPerspective. InProc.41stInt.Conf.on Int. Conf. on Advances in Neural Information Processing Systems
MachineLearning(ICML),2024. (NeurIPS),2019.
[16] D.Berend,X.Xie,L.Ma,L.Zhou,Y.Liu,C.Xu,andJ.Zhao.Catsare [40] C.Hsieh,C.Yeh,X.Liu,P.Ravikumar,S.Kim,S.Kumar,andC.Hsieh.
notFish:DeepLearningTestingCallsforOut-of-DistributionAware- EvaluationsandMethodsforExplanationthroughRobustnessAnalysis.
ness. In Proc. 35th IEEE/ACM Int. Conf. on Automated Software InProc.9thInt.Conf.onLearningRepresentations(ICLR),2021.
Engineering(ASE),pages1041–1052,2020. [41] Y.Hsu,Y.Shen,H.Jin,andZ.Kira.GeneralizedODIN:DetectingOut-
[17] R.Boumazouza,F.Cheikh-Alili,B.Mazure,andK.Tabia.ASTERYX: of-DistributionImageWithoutLearningFromOut-of-DistributionData.
AModel-AgnosticSAT-BasedApproachforSymbolicandScore-Based InProc.IEEE/CVFConf.onComputerVisionandPatternRecognition
Explanations.InProc.30thACMInt.Conf.onInformation&Knowl- (CVPR),2020.
edgeManagement(CIKM),pages120–129,2021. [42] X.HuangandJ.Marques-Silva.FromRobustnesstoExplainabilityand
[18] R.Bunel,I.Turkaslan,P.Torr,P.Kohli,andP.Mudigonda.AUnified BackAgain,2023.TechnicalReport.https://arxiv.org/abs/2306.03048.
ViewofPiecewiseLinearNeuralNetworkVerification.InProc.32nd [43] X.Huang,D.Kroening,W.Ruan,J.Sharp,Y.Sun,E.Thamo,M.Wu,
Conf.onNeuralInformationProcessingSystems(NeurIPS),pages andX.Yi. ASurveyofSafetyandTrustworthinessofDeepNeural
4795–4804,2018. Networks:Verification,Testing,AdversarialattackandDefence,and
[19] M. Casadio, E. Komendantskaya, M. Daggitt, W. Kokke, G. Katz, Interpretability.ComputerScienceReview,37:100270,2020.
G.Amir,andI.Refaeli. NeuralNetworkRobustnessasaVerifica- [44] X.Huang,Y.Izza,A.Ignatiev,andJ.Marques-Silva. OnEfficiently
tionProperty:APrincipledCaseStudy. InProc.34thInt.Conf.on ExplainingGraph-BasedClassifiers,2021. TechnicalReport.https:
ComputerAidedVerification(CAV),pages219–231,2022. //arxiv.org/abs/2106.01350.
[20] C.Chang,E.Creager,A.Goldenberg,andD.Duvenaud.Explaining [45] X.Huang,M.Cooper,A.Morgado,J.Planes,andJ.Marques-Silva.
ImageClassifiersbyCounterfactualGeneration.InProc.7thInt.Conf. FeatureNecessity&RelevancyinMLClassifierExplanations. In
onLearningRepresentations(ICLR),2019. Proc.29thInt.Conf.onToolsandAlgorithmsfortheConstructionand
[21] M.CooperandL.Amgoud. AbductiveExplanationsofClassifiers AnalysisofSystems(TACAS),pages167–186,2023.
underConstraints:ComplexityandProperties.In26thEuropeanConf. [46] A.Ignatiev.TowardsTrustableExplainableAI.InProc.29thInt.Joint
onArtificialIntelligence(ECAI),2023. Conf.onArtificialIntelligence(IJCAI),pages5154–5158,2020.
[22] D.Corsi,R.Yerushalmi,G.Amir,A.Farinelli,D.Harel,andG.Katz. [47] A.Ignatiev,N.Narodytska,andJ.Marques-Silva. Abduction-Based
ConstrainedReinforcementLearningforRoboticsviaScenario-Based ExplanationsforMachineLearningModels.InProc.33rdAAAIConf.
Programming, 2022. Technical Report. https://arxiv.org/abs/2206. onArtificialIntelligence,pages1511–1519,2019.
09603. [48] A.Ignatiev,N.Narodytska,andJ.Marques-Silva.OnRelatingExplana-
[23] D.Corsi,G.Amir,G.Katz,andA.Farinelli. AnalyzingAdversarial tionsandAdversarialExamples.InProc.32ndInt.Conf.onAdvances
InputsinDeepReinforcementLearning,2024.TechnicalReport.https: inNeuralInformationProcessingSystems(NeurIPS),2019.
//arxiv.org/abs/2402.05284. [49] A.Ignatiev,N.Narodytska,N.Asher,andJ.Marques-Silva. From
[24] D.Corsi,G.Amir,A.Rodríguez,C.Sánchez,G.Katz,andR.Fox. ContrastivetoAbductiveExplanationsandBackAgain.InProc.Int.
Verification-GuidedShieldingforDeepReinforcementLearning. In Conf.ItalianAssociationforArtificialIntelligence,2020.
Proc.1stInt.ReinforcementLearningConf.(RLC),2024. [50] A.Ignatiev,Y.Izza,P.Stuckey,andJ.Marques-Silva.UsingMaxSAT
[25] A.DarwicheandA.Hirth.OntheReasonsBehindDecisions.InProc. forEfficientExplanationsofTreeEnsembles.InProc.36thAAAIConf.
23rdEuropeanConf.onArtificialIntelligence(ECAI),pages712–720, onArtificialIntelligence,pages3776–3785,2022.
2020. [51] Y.IzzaandJ.Marques-Silva. OnExplainingRandomForestswith
[26] A.DarwicheandA.Hirth. Onthe(Complete)ReasonsBehindDe- SAT. InProc.30thInt.JointConf.onArtificialIntelligence(IJCAI),
cisions. JournalofLogic,LanguageandInformation,32(1):63–88, 2021.
2023. [52] Y.Izza,A.Ignatiev,N.Narodytska,M.Cooper,andJ.Marques-Silva.
[27] A.DarwicheandC.Ji.OntheComputationofNecessaryandSufficient EfficientExplanationswithRelevantSets,2021. TechnicalReport.
Explanations.InProc.36thAAAIConf.onArtificialIntelligence,pages https://arxiv.org/abs/2106.00546.
5582–5591,2022. [53] Y.Izza,A.Ignatiev,andJ.Marques-Silva.OnTacklingExplanationRe-
[28] A.DarwicheandP.Marquis.AKnowledgeCompilationMap.Journal dundancyinDecisionTrees.JournalofArtificialIntelligenceResearch
ofArtificialIntelligenceResearch(JAIR),17:229–264,2002. (JAIR),75:261–321,2022.
[29] R.Ehlers. FormalVerificationofPiece-WiseLinearFeed-Forward [54] Y.Izza,X.Huang,A.Morgado,J.Planes,A.Ignatiev,andJ.Marques-
NeuralNetworks.InProc.15thInt.Symp.onAutomatedTechnology Silva. Distance-RestrictedExplanations:TheoreticalUnderpinnings
forVerificationandAnalysis(ATVA),pages269–286,2017. &EfficientImplementation,2024.TechnicalReport.https://arxiv.org/
[30] Y.Elboher,J.Gottschlich,andG.Katz.AnAbstraction-BasedFrame- abs/2405.08297.
workforNeuralNetworkVerification. InProc.32ndInt.Conf.on [55] Y.Jacoby,C.Barrett,andG.Katz. VerifyingRecurrentNeuralNet-
ComputerAidedVerification(CAV),pages43–65,2020. worksusingInvariantInference. InProc.18thInt.Symposiumon
[31] R.Fagin.GeneralizedFirst-OrderSpectraandPolynomial-TimeRec- AutomatedTechnologyforVerificationandAnalysis(ATVA),pages
ognizableSets.ComplexityofComputation,7:43–73,1974. 57–74,2020.
[32] Z.Fang,Y.Li,J.Lu,J.Dong,B.Han,andF.Liu.IsOut-of-Distribution [56] D.Janzing,L.Minorics,andP.Blöbaum.FeatureRelevanceQuantifi-
DetectionLearnable?InProc.36thInt.Conf.onAdvancesinNeural cationinExplainableAI:ACausalProblem.InProc.23rdInt.Conf.
InformationProcessingSystems(NeurIPS),2022. onArtificialIntelligenceandStatistics(AISTATS),pages2907–2916,
[33] R.FongandA.Vedaldi.InterpretableExplanationsofBlackBoxesby 2020.
MeaningfulPerturbation.InProc.IEEEInt.Conf.onComputerVision [57] G.Katz,C.Barrett,D.Dill,K.Julian,andM.Kochenderfer.Reluplex:
(ICCV),pages3429–3437,2017. AnEfficientSMTSolverforVerifyingDeepNeuralNetworks.InProc.
[34] M.GardnerandS.Dorling.ArtificialNeuralNetworks(theMultilayer 29thInt.Conf.onComputerAidedVerification(CAV),pages97–117,2017. [80] J.Serrà,D.Álvarez,V.Gómez,O.Slizovskaia,J.Núñez,andJ.Luque.
[58] G.Katz,D.Huang,D.Ibeling,K.Julian,C.Lazarus,R.Lim,P.Shah, InputComplexityandOut-of-DistributionDetectionwithLikelihood-
S.Thakoor,H.Wu,A.Zeljic´,D.Dill,M.Kochenderfer,andC.Barrett. BasedGenerativeModels.InProc.7thInt.Conf.onLearningRepre-
TheMarabouFrameworkforVerificationandAnalysisofDeepNeural sentations(ICLR),2019.
Networks. InProc.31stInt.Conf.onComputerAidedVerification [81] A.Shih,A.Choi,andA.Darwiche.FormalVerificationofBayesian
(CAV),pages443–452,2019. NetworkClassifiers. InProc.Int.Conf.onProbabilisticGraphical
[59] S.Kim,J.Yi,E.Kim,andS.Yoon. InterpretationofNLPModels Models(PGM),pages427–438,2018.
ThroughInputMarginalization.InProc.Conf.onEmpiricalMethods [82] X.Sun,H.Khedr,andY.Shoukry. FormalVerificationofNeural
inNaturalLanguageProcessing(EMNLP),2020. NetworkControlledAutonomousSystems. InProc.22ndACMInt.
[60] B.Könighofer,F.Lorber,N.Jansen,andR.Bloem.ShieldSynthesis Conf.onHybridSystems:ComputationandControl(HSCC),2019.
forReinforcementLearning.InProc.Int.SymposiumonLeveraging [83] M.SundararajanandA.Najmi.TheManyShapleyValuesforModel
ApplicationsofFormalMethods,VerificationandValidation(ISoLA), Explanation. InProc.37thInt.Conf.onMachineLearning(ICML),
pages290–306,2020. pages9269–9278,2020.
[61] E. La Malfa, A. Zbrzezny, R. Michelmore, N. Paoletti, and [84] M.Sundararajan,A.Taly,andQ.Yan.AxiomaticAttributionforDeep
M.Kwiatkowska. OnGuaranteedOptimalRobustExplanationsfor Networks.InProc.34thInt.Conf.onMachineLearning(ICML),2017.
NLPModels. InProc.30thInt.JointConf.onArtificialIntelligence [85] M.Taufiq,P.Blöbaum,andL.Minorics.ManifoldRestrictedInterven-
(IJCAI),2021. tionalShapleyValues.InProc.26thInt.Conf.onArtificialIntelligence
[62] C. Lee. Representation of Switching Circuits by Binary-Decision andStatistics(AISTATS),2023.
Programs.TheBellSystemTechnicalJournal,38(4):985–999,1959. [86] H.Tran,S.Bak,andT.Johnson. VerificationofDeepConvolutional
[63] C.Liang,P.Huang,W.Lai,andZ.Ruan.GAN-BasedOut-of-Domain NeuralNetworksUsingImageStars.InProc.32ndInt.Conf.onCom-
DetectionUsingBothIn-DomainandOut-of-DomainSamples.InProc. puterAidedVerification(CAV),pages18–42,2020.
IEEEInt.Conf.onAcoustics,SpeechandSignalProcessing(ICASSP), [87] K.Vafa,Y.Deng,D.Blei,andA.Rush. RationalesforSequential
pages7663–7667,2021. Predictions.InProc.Conf.onEmpiricalMethodsinNaturalLanguage
[64] S.LundbergandS.Lee. AUnifiedApproachtoInterpretingModel Processing(EMNLP),2021.
Predictions.InProc.30thInt.Conf.onAdvancesinNeuralInformation [88] G.VandenBroeck,A.Lykov,M.Schleich,andD.Suciu. Onthe
ProcessingSystems(NeurIPS),2017. TractabilityofSHAPExplanations.JournalofArtificialIntelligence
[65] Z.Lyu,C.Ko,Z.Kong,N.Wong,D.Lin,andL.Daniel. Fastened Research(JAIR),74:851–886,2022.
Crown:TightenedNeuralNetworkRobustnessCertificates. InProc. [89] S.Wäldchen,J.Macdonald,S.Hauch,andG.Kutyniok. TheCom-
34thAAAIConf.onArtificialIntelligence(AAAI),pages5037–5044, putationalComplexityofUderstandingBinaryClassifierDecisions.
2020. JournalofArtificialIntelligenceResearch(JAIR),70:351–387,2021.
[66] U.Mandal,G.Amir,H.Wu,I.Daukantas,F.Newell,U.Ravaioli, [90] H.Wu,O.Isac,A.Zeljic´,T.Tagomori,M.Daggitt,W.Kokke,I.Refaeli,
B.Meng,M.Durling,M.Ganai,T.Shim,G.Katz,andC.Barrett. G.Amir,K.Julian,S.Bassan,P.Huang,O.Lahav,M.Wu,M.Zhang,
FormallyVerifyingDeepReinforcementLearningControllerswith E.Komendantskaya,G.Katz,andC.Barrett.Marabou2.0:AVersatile
LyapunovBarrierCertificates. InProc.24thInt.Conf.onFormal FormalAnalyzerofNeuralNetworks. InProc.36thInt.Conf.on
MethodsinComputer-AidedDesign(FMCAD),2024. ComputerAidedVerification(CAV),2024.
[67] U.Mandal,G.Amir,H.Wu,I.Daukantas,F.Newell,U.Ravaioli, [91] M.Wu,H.Wu,andC.Barrett.Verix:TowardsVerifiedExplainability
B.Meng,M.Durling,K.Hobbs,M.Ganai,T.Shim,G.Katz,and ofDeepNeuralNetworks. InProc.36thInt.Conf.onAdvancesin
C.Barrett.SafeandReliableTrainingofLearning-BasedAerospace NeuralInformationProcessingSystems(NeurIPS),2024.
Controllers. InProc.43rdDigitalAvionicsSystemsConf.(DASC), [92] X.Xuan,P.Xizhou,L.Nan,H.Xing,M.Lin,Z.Xiaoguang,and
2024. D.Ning.GAN-BasedAnomalyDetection:AReview.Neurocomputing,
[68] J.Marques-SilvaandA.Ignatiev.DeliveringTrustworthyAIthrough 493,2022.
formalXAI.InProc.36thAAAIConf.onArtificialIntelligence,pages [93] R.Yerushalmi,G.Amir,A.Elyasaf,D.Harel,G.Katz,andA.Mar-
3806–3814,2022. ron.Scenario-AssistedDeepReinforcementLearning.InProc.10th
[69] J.Marques-Silva,T.Gerspacher,M.Cooper,A.Ignatiev,andN.Nar- Int.Conf.onModel-DrivenEngineeringandSoftwareDevelopment
odytska. ExplainingNaiveBayesandOtherLinearClassifierswith (MODELSWARD),pages310–319,2022.
PolynomialTimeandDelay.InProc.33rdInt.Conf.onAdvancesin [94] R.Yerushalmi,G.Amir,A.Elyasaf,D.Harel,G.Katz,andA.Mar-
NeuralInformationProcessingSystems(NeurIPS),pages20590–20600, ron. EnhancingDeepReinforcementLearningwithScenario-Based
2020. Modeling.SNComputerScience,4(2):156,2023.
[70] J.Marques-Silva,T.Gerspacher,M.Cooper,A.Ignatiev,andN.Naro- [95] J.Yi,E.Kim,S.Kim,andS.Yoon. Information-TheoreticVisual
dytska.ExplanationsforMonotonicClassifiers.InProc.38thInt.Conf. ExplanationforBlack-BoxClassifiers,2020.TechnicalReport.https:
onMachineLearning(ICML),2021. //arxiv.org/abs/2009.11150.
[71] L. Marzari, D. Corsi, F. Cicalese, and A. Farinelli. The #DNN- [96] J.Yu,A.Ignatiev,P.Stuckey,N.Narodytska,andJ.Marques-Silva.
Verificationproblem:CountingUnsafeInputsforDeepNeuralNet- EliminatingTheImpossible,WhateverRemainsMustBeTrue,2022.
works.InProc.32ndInt.JointConf.onArtificialIntelligence(IJCAI), TechnicalReport.https://arxiv.org/abs/2206.09551.
2023. [97] O.Zaidan,J.Eisner,andC.Piatko.Using“AnnotatorRationales”toIm-
[72] R. Marzouk and C. de La Higuera. On the Tractability of SHAP proveMachineLearningforTextCategorization.InProc.Conf.North
ExplanationsunderMarkovianDistributions,2024.TechnicalReport. AmericanChapteroftheAssociationforComputationalLinguistics
http://arxiv.org/abs/2405.02936. (NAACL),pages260–267,2007.
[73] P.MortezaandY.Li.ProvableGuaranteesforUnderstandingOut-of- [98] H.Zhang,M.Shinn,A.Gupta,A.Gurfinkel,N.Le,andN.Narodytska.
DistributionDetection.InProc.36thAAAIConf.onArtificialIntelli- VerificationofRecurrentNeuralNetworksforCognitiveTasksvia
gence,pages7831–7840,2022. ReachabilityAnalysis. InProc.24thEuropeanConf.onArtificial
[74] R.Poyiadzi,K.Sokol,R.Santos-Rodriguez,T.DeBie,andP.Flach. Intelligence(ECAI),pages1690–1697,2020.
FACE:FeasibleandActionableCounterfactualExplanations.InProc. [99] W.Zhao,S.Alwidian,andQ.Mahmoud.AdversarialTrainingMethods
AAAI/ACMConf.onAI,Ethics,andSociety(AIES),2020. forDeepLearning:ASystematicReview.Algorithms,15(8):283,2022.
[75] A.Ralston,E.Reilly,andD.Hemmendinger. EncyclopediaofCom- [100] L.Zintgraf,T.Cohen,T.Adel,andM.Welling. VisualizingDeep
puterScience.JohnWileyandSonsLtd.,2003. NeuralNetworkDecisions:PredictionDifferenceAnalysis. InProc.
[76] H.Ramchoun,Y.Ghanou,M.Ettaouil,andM.AmineJanatiIdrissi. 7thInt.Conf.onLearningRepresentations(ICLR),2017.
MultilayerPerceptron:ArchitectureOptimizationandTraining. Int.
JournalofInteractiveMultimediaandArtificialIntelligence,2016.
[77] M.Ribeiro,S.Singh,andC.Guestrin.Anchors:High-PrecisionModel-
AgnosticExplanations.InProc.32ndAAAIConf.onArtificialIntelli-
gence,2018.
[78] A.Rodriguez,G.Amir,D.Corsi,C.Sanchez,andG.Katz. Shield
SynthesisforLTLModuloTheories,2024. TechnicalReport.https:
//arxiv.org/abs/2406.04184.
[79] S.SanyalandX.Ren.DiscretizedIntegratedGradientsforExplaining
LanguageModels. InProc.Conf.onEmpiricalMethodsinNatural
LanguageProcessing(EMNLP),2021.Appendix
(Misaligned)CC(CountCompletions):
Input:Modelf,inputx,andinputI :=⟨S⟩.
Theappendixcontainsdefinitions,formalizations,andproofsthat
Output: The number of assignments of SOL := ∃(z ∈
werementionedthroughoutthepaper: ¬f
F)ψ (x,S,z).
¬f
AppendixAdescribestheabstractqueryform.
AppendixBdescribesthespecificmodeltypes,andtheuniversal Onceagain,itisworthnotingthatintheseparticularscenarios,
modelproperties. the value of S is derived from a subset of the input I for the CC
AppendixCcontainsananalysisofthemodel-specificproperties. query,whileforMCR,itisdefinedwithinSOL ¬f.Now,weproceed
AppendixDincludestheproofsforthetheoremsandpropositions todemonstratehowthesufficiency-basedexplainabilityquery(MSR)
mentionedinthepaper. canalsobeacquired.Inthiscase,SOL ¬f correspondstothenegation
AppendixEincludespossibleextensionsofourtheoreticalframe- ofψ ¬f:
work.
(Misaligned)MSR(MinimumSufficientReason):
Input:Modelf,inputx,andinputI :=⟨k⟩.
A AbstractQueryForm
Output: Yes, if SOL := ∃S ⊆ (1,...,n) ¬∃(z ∈
¬f
WepresentacomprehensiveanalysisoftheabstractqueryformQ F)ψ (x,S¯,z)∧|S|≤kissatisfiable,andNootherwise.
¬f
discussedinourpaper,providingamoredetailedexplanationofour
process. It is straightforward to show that this formalization of MSR is
equivalenttoitspredefinedversions,since:
TheMisalignedCase
∀(z∈F) [f(x S;z S¯)=f(x)] ⇐⇒
(8)
I fn eri rti ia nl gly t, ow the ein at bro std ru acc te qth ue erq yu fe or ry mfo Qrm thf ao tr dth oe es“ nm oi tsa cl oig nn sie dd e” rc tha ese c, or ne-
-
¬∃(z∈F) [f(x S¯;z S)̸=f(x)]
textindicatorπasaninput.Weformulatethisspecificscenarioand Inotherwords,asubsetSissufficienttodetermineaprediction
demonstrateitsapplicabilityingeneralizingthevariousdiscussed f(x)ifandonlyiftheredoesnotexistanyassignmenttothecomple-
explainabilityqueries:MSR,CC,andMCR,allintheirmisaligned
mentaryS¯thatiscontrastive.Thisleadsustothefactthatthereexists
versions.Subsequently,weproceedtooutlinetheconsequentialquery asufficientreasonofsizekifandonlyifthereexistssomesubsetS
forthealignedscenario,whereπistakenintoaccount,dismantling
ofsizeksuchthatnopossibleassignmenttoS¯iscontrastive.
theeffectofanyOODcounterfactual.Wethenreiteratehowtheex- Wenotethatwhenevaluatingthecomplexityofthemisaligned
plainabilityqueriesofMSR,CC,andMCR,whenconsideredintheir abstractexplainabilityqueryQ,weconsideritinrelationtoasingle
alignedforms,areallspecificinstancesoftheabstractqueryQ. classofmodels.Forinstance,Q(C M)describesthecomplexityof
Letψ ¬f(x,S,z)denotethefollowingconjunct: obtaininga(misaligned)explainabilityqueryforamodelf ∈ C C
using the (misaligned) abstract query form Q. Unlike the aligned
ψ ¬f :=[f(x S¯;z S)̸=f(x)] (7) version,wedonotinputtwofamiliesoffunctionssincethecontext
indicatorπisnotincludedaspartoftheinputforthesequeries.
LetSOL denoteanSOLformulathatincludesψ ,wherethe
¬f ¬f
variable f is exclusively present in ψ . In other words, f is not
¬f
foundinanyotherconjunctofSOL ¬f apartfromψ ¬f.Wedenotethe TheAlignedCase
(misaligned)versionofQasanyexplainabilityquerythattakesf,x,
andIasinputs,whereIrepresentsasetofadditionalarbitraryinputs. Wenowproceedtodescribethealignedversionoftheabstractquery
TheoutputofQisasatisfyingsolutiontoSOL ¬f orthecounting form.Inthiscase,weaimtoconstructasimilarabstractqueryform
of#SOL ¬f.Wearenowabletoformulatetheabstract(misaligned) withtheadditionalrequirementofneutralizingtheinfluenceofany
queryformQ: OODcounterfactuals.Thisisobtainedbyaddinganadditionalcon-
straint,namely[π(x S¯;z S)=1].Toformallydefinethis,weintroduce
(Misaligned)Q(AbstractQueryForm): ψ (x,S,z)asfollows:
¬f,π
Input:Modelf,inputx,andinputI.
Output:aYesorNoanswer,towhetherSOL ¬f holds,orthenumber ψ ¬f,π :=[f(x S¯;z S)̸=f(x)]∧[π(x S¯;z S)=1] (9)
ofassignmentsofSOL .
¬f
Similarly,wedefineSOL asanySOLformulathatincludes
¬f,π
ψ ,wheref andπareexclusivelyincludedwithinψ .Inother
ItisimportanttohighlightthatthevaluesofSandzareimplicitly ¬f,π ¬f,π
words,f andπ arenotpresentinanyconjunctofSOL except
presentinψ .Thesevaluescaneitherbeincludedaspartofthe ¬f,π
¬f
forψ .Wedenotethe(aligned)versionofQasanexplainability
inputI,ortheycanbeexplicitlydefinedwithinSOL .Now,we ¬f,π
¬f
query that takes f, x, π, and I as inputs, where I represents an
demonstratehowtheaforementionedexplainabilityqueries(intheir
arbitrarysetofadditionalinputs.TheoutputofQisasolution(either
misalignedform)canbepreciselyformulatedasspecificinstancesof
decisionorcounting),overSOL .Therefore,theabstractquery
Q.Westartbyillustratingthisfortherelativelysimplerscenariosof ¬f,π
form,inthiscase,canbeexpressedasfollows:
MCRandCC:
(Misaligned)MCR(MinimumChangeRequired): Q(AbstractQueryForm):
Input:Modelf,inputx,andinputI :=⟨k⟩. Input:Modelf,inputx,contextindicatorπ,andinputI.
Output:Yes,ifSOL
¬f
:=∃S ⊆(1,...,n) ∃(z∈F)ψ ¬f(x,S,z)∧ Output:aYesorNoanswer,towhetherSOL ¬f,πholds,orthenumber
|S|≤kissatisfiable,andNootherwise. ofassignmentsofSOL ¬f,π.Webrieflyillustratehowthisabstractqueryformencompassesall Multi-LayerPerceptron(MLP).Givenasetoftweightmatrices
thepreviouslydefinedexplainabilityqueries,includingthealigned W(1),...,W(t),tbiasvectorsb(1),...,b(t) andtactivationfunc-
versionsofMSR,MCR,andCC.Onceagain,itisstraightforwardto tionsf(1),...,f(t),aMulti-LayerPerceptron(MLP)[34,76]f,with
showthatMCRandCCareinstancesofthisabstractqueryform(this t−1hiddenlayers(hj forj ∈{1,...,t−1})andasingleoutput
time,inthealignedversion): layer (ht), is recursively defined based on the following series of
functions:
MCR(MinimumChangeRequired):
Input:Modelf,inputx,contextindicatorπ,andinputI :=⟨k⟩.
Output: Yes, if SOL := ∃S ⊆ (1,...,n) ∃(z ∈ h(j) :=σ(j)(h(j−1)W(j)+b(j)) (j ∈{1,...,t}) (11)
¬f,π
F)ψ ¬f,π(x,S,z)∧|S|≤kissatisfiable,andNootherwise. f outputsthevalueofthefunctionf := h(t),andh(0) := x ∈
{0,1}n corresponds to the input of the model. The weight matri-
cesandbiasesaredefinedbyaseriesofpositivevaluesd ,...,d
CC(CountCompletions): 0 t
representingthedimensionsoftheirinputs.Inaddition,weassume
Input:Modelf,inputx,contextindicatorπ,andinputI :=⟨S⟩.
thatalltheweightsandbiases(learnedduringtraining)haveratio-
Output: The number of assignments of SOL := ∃(z ∈
¬f,π nal values, i.e., W(j) ∈ Qdj−1×dj and b(j) ∈ Qdj. Notice that
F)ψ (x,S,z).
¬f,π due to our focus on binary classifiers over {0,1}n, then it holds
that: d = n and d = 1. Furthermore, we consider the popular
Similarly to the misaligned case, the aligned version of the 0 t
ReLU(x) = max(0,x)activationfunction.Thelastactivationof
sufficiency-basedquery(MSR)canbeobtainedasfollows:
MLPsistypicallyasigmoidfunction,butsinceweareonlyinter-
estedinpost-hocinterpretations,wecanequivalently,withoutloss
MSR(MinimumSufficientReason):
ofgenerality,considerthelastactivationtocorrespondtothestep
Input:Modelf,inputx,contextindicatorπ,andinputI :=⟨k⟩.
function:
Output: Yes, if SOL := ∃S ⊆ (1,...,n) ¬∃(z ∈ (cid:40)
¬f,π 1, y>0
F)ψ (x,S¯,z)∧|S|≤kissatisfiable,andNootherwise. step(y)= (12)
¬f,π
0, y≤0
Theequivalencebetweenthesespecificinstancesandthepredefined
Perceptron.APerceptron[75]isanMLPwithasinglelayer(i.e.,
explainabilityqueriesholdsintheseparticularscenarios.Thisisdue
t=1):f(x)=σ(⟨W,x⟩+b),forW ∈Qn×d1 andb∈Q.Hence,
tothefollowing:
withoutlossofgenerality,foraPerceptronf itholdsthat:
∀(z∈F) [π(x S;z S¯)=1→f(x S;z S¯)=f(x)] ⇐⇒
(10)
f(x)=1 ⇐⇒ ⟨W,x⟩+b>0 (13)
¬∃(z∈F) [f(x S¯;z S)̸=f(x)]∧[π(x S¯;z S)=1]
UniversalProperties
RecallthatinthecaseofthealignedversionofQ,theunderlying
computationalcomplexityisevaluatedbyconsideringtwoclasses Next,weprovidethepreciseformalizationfortheuniversalproper-
ofmodels:C fortheclassificationmodelandC forthecontext tiesoverC andC thatwerementionedwithinourstudy.These
M π M π
indicator.Forinstance,Q(C ,C )representsthecomputationalcom- arethatC issymmetricallyconstructible,whereasC isnaively
M π π M
plexityofobtaininganexplainabilityqueryformodelsf ∈C with construcatble.
M
respecttothecontextindicatorsπ∈C andanabstractqueryform
π
Definition1. AclassoffunctionsCissymmetricallyconstructibleif
Q.
givenamodelf ∈C,then¬f ∈Ccanbeconstructedinpolynomial
time.
B ModelTypesandUniversalProperties
Definition2. AclassoffunctionsCisnaivelyconstructibleifforany
ModelTypes
valuex∈F,then1 ∈Ccanbeconstructedinpolynomialtime.
{x}
Next,weprovideafulldescriptionofthemodelsthataretakeninto
accountwithinourwork. C Model-SpecificProperties
BinaryDecisionDiagram(BDD).ABDD[62]isagraphicalrepre-
Asmentionedabove,ourpropositionsandtheoremsarebasedonthe
sentationofaBooleanfunctionf :F→{0,1},realizedbyadirected,
universalpropertiesformulatedinSectionBoftheappendix.These
acyclicgraph,forwhich:(i)eachinternalnodev(i.e.,non-sinknodes)
qualitiesincludesymmetricconstructabilityandnaiveconstructability.
correspondstoasinglefeature(1,...,n);(ii)eachinternalnodev
Inthissection,weillustratehowthesepropertiesindeedholdforthe
has precisely two output edges, representing the values {0,1} as-
particularmodelsdiscussedinourwork,namelyFBDDs,Perceptrons,
signedtov;(iii)eachleafcorrespondstoeitheratrue,orfalse,label;
andMLPs.Weemphasizethattheseareonlyparticularillustrations,
and(iv)eachvariableappearsatmostonce,alonganygivenpathα
andthatthesepropertiescanbeproventoholdforabroaderrangeof
withintheBDD.
hypothesisclasses.First,werecallProposition1:
Hence,everypathαfromtherootnodetoaleaf,correspondsto
aspecificinputassignmentx∈F,withf(x)matchingthevalueof Proposition1. FBDDs,Perceptrons,andMLPsareallsymmetrically
theleafoftherelevantpathα.Followingpreviousconventions[12, constructibleandnaivelyconstructible.
44,45,9],weregardthesize|f|oftheBDDtobethetotalnumber
Tothisend,weprovethefollowinglemmas.
ofedges.Wefocusonthepopularhypothesisclassof“FreeBDDs”
(FBDDs),inwhichdifferentpathsmayhavevariousorderingsofthe Lemma1. TheclassC isnaivelyconstructibleandsymmetrically
FBDD
inputvariables{1,...,n}. constructible.Itisstraightforwardtoshowthisinthefollowingmanner:(i)given
anFBDDf wecanconstruct¬f byduplicatingf andnegatingall
leafnodesvintheduplicateddiagram;and(ii)givenaninputx∈F 1 𝑥
1 𝑤+
wecansimplyconstructanFBDDf withasingleacceptingpathα
matchingtheassignmentofx. 1 𝑥 2 𝑤+
−σ (ℎ1 𝑥)+0.5
𝑤− 1≤𝑖≤𝑛 𝑖 𝑖
Lemma2. TheclassC MLPisnaivelyconstructibleandsymmetrically 0 𝑥
3
𝑠𝑡𝑒𝑝
constructible. 𝑤+
1 𝑥
4 𝑤−
MLPs can also be constructed symmetrically and naively in a
straightforwardmanner.First,westatethatforeveryMLPf,wecan 0 𝑥
5
construct,inlineartime,anequivalentMLPf′,suchthattheweights
andbiasesareintegers(thiscanbeachievedbymultiplyingthevalues
Figure2:AnillustrationofthenaiveconstructabilityofaPerceptron
bythelowestcommondenominator,asdonein[12]).Next,forthe
model,indicatingthevalue[1,1,0,1,0],andw+ =1,w− =(−1).
biasinthelastlayer,wealsoadd−0.5.Thisprocedureguaranteesthat: Thebiastermis[−(cid:80) (h1·x )]+0.5=(−3)+0.5=(−2.5).
(i)foreveryinputx∈{0,1}n,itholdsthatf(x)=f′(x),i.e.,the 1≤i≤n i i
newMLPf′isequivalenttof;and(ii)thereisnobinaryinputxsuch
Theorem1. If1∈C thenQ(C )≤ Q(C ,C ).
thatforf′ =step(h′(t−1)W′(j)+b′(t))itholdsthat(h′(t−1)W′(j)+ π M p M π
b′(t))(x)=0,i.e.,noinputxisexactlyonthedecisionboundaryof Proof. Theproofisstraightforwardsincegivensome⟨f,x,I⟩the
f′(asalllinearcombinationsofintegers—remainintegers,andthe reductioncansimplyencodeandreturn⟨f,x,1,I⟩.Clearly,itholds
singlebiasisnotaninteger).Next,symmetricconstructabilityforf′ that:⟨f,x,I⟩ ∈ Q(C M) ⇐⇒ ⟨f,x,1,I⟩ ∈ Q(C M,C π),which
(andhence,forf)isacquiredasfollows.Wecanconstruct¬f′ by concludesthecorrectnessofthereduction.
negatingtheweightsofthelastlayerh′t(settingh′t =−h′tforall
i)andnegatingthebiasoftheoutputlayerb′t.Sini cethelai
stlayer
Theorem2. IfC MissymmetricallyconstructibleandC πisnaively
constructible,thenQ(C )≤ Q(C ,C ).
containsasinglestepfunction,negatingthecorrespondingweights π p M π
(andbias)willresultinaflippedclassification. Givensome⟨f ,x,I⟩:thereductioncheckswhetherf isavalid
1 1
To show naive constructability, we make use of the following encodingofafunctioninC .Ifnot,itreturnsaninvalidencoding.If
π
Lemma[12]: so,itconstructsthenegationfunction¬f (basedonourassumptions,
1
thiscanbecomputedinpolynomialtime).Then,thereductioncom-
Lemma3. GivenaBooleancircuitB,wecanconstruct,inpolyno-
putesf (x)andconstructs1 ∈C (alsoinpolynomialtime).If
mialtime,anMLPf ,whichinducesanequivalentBooleanfunction 1 {x} M
B f (x)=1,thereductionreturns⟨f =1 ,π =¬f ,x,I⟩,andif
relativetoB. 1 2 {x} 2 1
f (x)=0,itreturns⟨f =1 ,π =f ,x,I⟩.
1 2 {x} 2 1
Hence,asadirectcorollary,itispossibletopolynomiallyconstruct LetQ 1denotetheSOLformulathatcorrespondstothesolutionof
anMLPthatcorrespondstotheBooleancircuitrepresenting:x 1∧ Q(C π)andletQ
2
denotetheSOLformulathatcorrespondstothe
x 2...∧x n. solutionofQ(C M,C π).Letusdenoteψ ¬f1 astheaforementioned
conjunct(seeSec.Aoftheappendix)thatcorrespondstoQ ,andby
1
Lemma4. TheclassC isnaivelyconstructibleandsymmetri-
Perceptron ψ theconjunctthatcorrespondstoQ .
callyconstructible.
¬f2,π 2
Assume⟨f ,x,I⟩∈Q(C ).Sinceinthiscaseitholdsthatf ∈
1 π 1
ThesymmetricconstructionprovedforMLPsalsoholdsdirectly C π,then:
forPerceptrons(bynegatingtheweightsofh1 aswellasthebias
b1).Givenaninputx∈F,naiveconstructabilitycanbeachievedby
ψ
¬f1
=[f 1(x S;z S¯)̸=f 1(x)]
constructingamodelwherethecorrespondingsinglehiddenlayer Forϕ
2
:=[π 2(x S;z S¯)=1]itholdsthat:
h1 isweightedsuchthath1 := w+ forx = 1andh1 := w− for
i i i
x = 0,forsomeuser-definedvaluew.Thesinglebiastermb1 is
i
settob1 := −[(cid:80) 1≤i≤n(h1
i
·x i)]+0.5.Theintuitionbehindthis ψ ¬f2,π =[f 2(x S;z S¯)̸=f 2(x)]∧[π 2(x S;z S¯)=1]
constructionisthatitmaximizesthecontributionoftheparticular =[f 2(x S;z S¯)̸=f 2(x)]∧ϕ 2
inputxwhilerenderingnegativevaluesforanyotherinputinF\x.
=[1 {x}(x S;z S¯)̸=1 {x}(x)]∧ϕ
2
AnillustrationofthisconstructionisprovidedinFig.2.Also,we
observethatthisconstructionclearlyservesasvalidproofforthe
=[1 {x}(x S;z S¯)̸=1]∧ϕ
2
naiveconstructabilityofMLPs,butthiswasalreadytriviallyderived
fromthepropertiesdiscussedintheprevioussection. Assumethatf (x)=1.Inthiscase,thereductionsetsπ to¬f ,
1 2 1
andthus:
D MainTheoremProofs
Inthissection,weproveallthetheoremsandpropositionspresented ϕ
2
=[π 2(x S;z S¯)=1]=[¬f 1(x S;z S¯)=1]=
inthemaintext. [f 1(x S;z S¯)̸=1]=[f 1(x S;z S¯)̸=1]∧[f 1(x)=1]
Wherethelastencodedconjunctf (x) = 1isatautologyunder
TheComplexityofObtainingSociallyAligned 1
thisscenario.Overall,wegetthat:
Explanations
First,weprovidetheproofsforTheorems1and2,asdiscussedinthe
ψ
¬f2,π
=[1 {x}(x S;z S¯)̸=1]∧[f 1(x S;z S¯)̸=1]
maintext.Morespecifically: ∧[f 1(x)=1]=[f 1(x S;z S¯)̸=1]=ψ ¬f1ThismeansthatQ 1andQ 2areequivalentandhenceanysolution RecallthateachqueryQ(C M)isassociatedwithanSOLformula
forSOLor#SOLwillbeequivalenttoQ(C M,C π)andQ(C π).Thus, SOL
¬f
and each aligned query Q(C M,C π) is associated with an
⟨f 1,x,I⟩∈Q(C π) ⇐⇒ ⟨f 2,x,π 2,I⟩∈Q(C M,C π). SOLformulaSOL ¬f,π.Bothoftheseformulascanbewrittenintheir
Assumethatf 1(x) = 0.Inthiscase,thereductionsetsπ 2 tof 1 PrenexNormalFormSOLk ¬f andSOLk ¬f,π.Sincetheprefixesof
andthus: boththeseformulasareequivalent,thenbothofthemareassociated
withsomecomplexityclassK′ inthepolynomialhierarchy(orits
correspondingcountingclass),duetotheextensionofFagin’sTheo-
ϕ 2 =[π 2(x S;z S¯)=1]=[f 1(x S;z S¯)=1] rem,whichasmentioned,holdsforourcase(aswefocusondiscrete
=[f 1(x S;z S¯)̸=0]=[f 1(x S;z S¯)̸=0]∧[f 1(x)=0] inputsofafinitesize).
Clearly,sinceC andC areclassesofpolynomiallycomputable
M π
Overall,weagainobtainthat: functions,thenbydefinitionQ(C ,C ) ∈ K′ andQ(C ) ∈ K′.
M π M
Morespecifically,thismeansthatQ(C ) ∈ K′ aswell.Next,to
MLP
ψ ¬f2,π =[1 {x}(x S;z S¯)̸=1]∧[f 1(x S;z S¯)̸=0] provehardness,wewillmakeuseofLemma3,aswellasKarp’s
∧[f 1(x)=0]=[f 1(x S;z S¯)̸=0]=ψ
¬f1
reduction.
Karp’s reduction implies that any quantified propositional for-
Hence, again it holds that Q 1 and Q 2 are equivalent, and from mula∃X 1∀X 2,...(∃/∀)X k,ψ(X 1,...,X k),foraquantifier-free
the same reason stated above, it thus holds that ⟨f 2,x,π 2,I⟩ ∈ Booleanformulaψ(over(X 1,...,X k))isΣp k-complete.Inaddition,
Q(C M,C π). asLemma3indicatesthatanarbitraryBooleanformulaψ canbe
Now,assume⟨f 1,x,I⟩ ̸∈ Q(C π).Inthiscase,thereductionini- translated to an equivalent MLP in polynomial time, it holds that
tially checks the validity of the encoding, which includes that of Q(C )isK′-hard.AswehavealsoshownthatQ(C )isinK′,
MLP MLP
f ∈ C π.Hence,weareonlylefttocheckthecaseswheref ∈ C π wededucethatQ(C MLP)isK′-complete.
but⟨f,x,π,I⟩̸∈Q(C π).ThisimpliesthattheSOLwasunsatisfiable Overall,wegetthatQ(C MLP)isK-completeforsomeclassinthe
or,ifQisacountingquery,that#SOLreturnedanincorrectcount. polynomialhierarchy,andalsoK′-complete.Eachlanguageiscom-
SincethepreviousresultdemonstratedthatQ 1andQ 2areequivalent pleteonlyforoneclassinthehierarchy(orotherwise,thehierarchy
undertheassumptionthatf ∈C π,anyassignmenttoQ 1willhold collapses),andthusK=K′.
if and only if it holds to Q 2. Consequently, we can conclude that Now, we get that Q(C M,C π) ∈ K′ = K. Since we know that
⟨f 2,x,π 2,I⟩̸∈Q(C M,C π). C
M
=C MLPorC
π
=C MLP,andsinceMLPsarebothsymmetrically
constructibleandnaivelyconstructible(Lemma2)thenasaconse-
Theorem3. LetC ,C beclassesofpolynomiallycomputablefunc-
M π quenceofTheorems1and2wegetthatQ(C ,C )isalsoK-hard.
M π
tionssuchthatC =C orC =C .IfQ(C )isK-complete,
M MLP π MLP MLP WededucethatQ(C ,C )isK-complete.
M π
where K is a complexity class of the polynomial hierarchy (or its
Note.InordertorelyonFagin’sthorem[31],wemustassumea
associatedcountingclass),thenQ(C ,C )isalsoK-complete.
M π finitestructure.Thisholdsinthecaseofdiscreteinputs,butnotfor
anygeneralSOLencoding(whichinfact,mayevenbeundecidable).
Proof.Thecomplexityclasseswithinthepolynomialhierarchyconsist
oftheclassesΣp k andΠp k forallk.TheclassΣp k isdefinedasall “Self-Alignment”:IncorporatingSocialAlignment
languagesLsuchthatthereexistsapolynomialtimeTuringmachine withinaSingleModel
M andpolynomialsq ,...,q suchthat:
1 k
Inthenextsubsection,weelaborateonthegeneral,andmodel-specific,
x∈L ⇐⇒ ∃y ∀y ,...(∃/∀)y ,|y |≤q (|X|) proofsforourfindingsregardingtheself-alignmentpropertyofagiven
1 2 k i i
(14)
∧ M(x,y ,...,y )=1 modelclassC.First,wereiteratethedefinitionofself-alignment:
1 k
Ontheotherhand,Πpisdefinedrespectivelybyalternatingquanti- Definition4. AclassofmodelsCisself-alignedifforanyf,π∈C,
fiers∀∃,...,andhencek Πp ={L|L¯ ∈Σp}.InthecontextofSOL, and any inputs x and I, there exists a polynomially constructible
wedefineSOLkasaformk ulaoftheform:k functiong∈C,suchthat:
⟨f,π,x,I⟩∈Q(C,C) ⇐⇒ ⟨g,x,I⟩∈Q(C) (16)
∃X ∀X ,...(∃/∀)X ,ϕ(X ,...,X ) (15)
1 2 k 1 k
Theorem4. GivenaclassofmodelsC,ifforanyf ,f ∈C,wecan
1 2
whereϕisaquantifier-freeFOLformulaover(X 1,...,X k).Extend- polynomiallyconstructg:=f 1[op]f
2
∈C,for[op]∈{∧,→},then
ingFagin’stheorem[31]showsthatasolutiontoanSOLformula Cisself-aligned.
withkalternatingquantifiers(startingwith∃)isΣp-complete.We
k
notethatthisholdsinthecaseoffinitestructures,whichisoursetting, Proof.BasedontheassumptionsonC,givenanytwomodelsf,π∈
asforanynwehaveafinitenumberofinputs.SinceanySOLformula C,wecanconstruct,inpolynomialtime,afunctiongthatencodes
canbewrittenasanSOLformulaconsistingofalternatingquantifiers alogicalrelationbetweentheoriginalclassifierf andthecontext
∃,∀,...or∀,∃,...,thenbyextendingFagin’stheorem[31],wecan indicatorπ.Wedefineg∈Cbasedontheoriginalclassificationf(x).
concludethateachSOLformulaisassociatedwithaclassinthepoly- Ourreductiondefinesslightlydifferentfunctionsg∈C,depending
nomialhierarchy(thisholdsinthecaseoffinitestructures,whichis onwhethertheoriginalclassificationisf(x)=1orf(x)=0.
indeedourcase,aswefocusondiscreteinputs).Forexample∃∀SOL Inthecaseoff(x)=1,wedefineg∈Casfollows:
isΣp-completeand∀∃SOLisΠp-complete(again,asinourcasethe
form2 ulaincludesmodelsthatare2 restrictedtofiniteinputs).Wenote g:=[f ∨¬π]∈C. (17)
thatforthecountingcase,eachoneofthesecomplexityclasseshasa
Next,wenotethatforthegiveninputxitholdsthat:
correspondingassociatedcountingclass,forexample,thenumberof
satisfyingassignmentsfor∃SOLor∃∀SOL. g(x)=[f ∨¬π](x)=f(x)∨π(x)=1∨¬π(x)=1 (18)Italsoholdsthat: Lemma5. TheclassC isself-aligned.
FBDD
ψ ⇐⇒
¬f,π
Proof.WerelyonProposition4andshowthecorrespondingencodings
[f(x S;z S¯)̸=f(x)=1]∧[π(x S;z S¯)=1] ⇐⇒
of∧and→forC (asufficientconditionfortheself-alignmentof
FBDD
[f(x S;z S¯)=0]∧[π(x S;z S¯)=1] ⇐⇒ theclass).Morespecifically,giventwofunctionsf t,f
s
∈C FBDD,
[¬f(x S;z S¯)=1]∧[π(x S;z S¯)=1] ⇐⇒
(19)
over{0,1}n,wecanpolynomiallyconstructanewfunctionf
k
∈
[(¬f ∧π)(x S;z S¯)=1] ⇐⇒ C FBDD,suchthatf k =f t∧f s.
Asafirststep,weshowhow,givenf andf ,wecanconstruct
[¬(¬f ∧π)(x S;z S¯)=0] ⇐⇒
somegeneraldecisiondiagramf′ :=f
t
→f
os
rf′ :=f ∧f .In
t s t s
[(f ∨¬π)(x S;z S¯)=0] ⇐⇒ thesecondstepofthisprocess,weexplainhowwecanreducef′to
[g(x S;z S¯)=0̸=1=g(x)] ⇐⇒ ψ ¬g somef k ∈C FBDD.
Inthecaseoff(x)=0,wedefineg∈Casfollows: Lemma6. Givensomef t,f
s
∈C FBDD,itispossibletopolynomially
constructtheBooleanfunctionsf′ :=f →f andf′ :=f ∧f .
t s t s
g:=[f ∧π]∈C. (20)
Andhence,iff(x)=1: Proof.Noticethatwedonotrequirethatf′ ∈C FBDD,aswelatershow,
f′ willbeageneralformofadecisiondiagram,andtheencoding
⟨f,x,π,I⟩∈Q(C,C) ⇐⇒ ⟨g,x,I⟩∈Q(C) (21) off′ willbeofsizeO(f ·f ).Forf′ := f ∧f weperformthe
s t s t
followingsteps:
Inthecasethatforthegiveninputxitholdsthat:
g(x)=[f ∧π](x)=f(x)∧π(x)=0∧π(x)=0 (22) 1. Createasinglecopyoff t.
2. Foreachleafnodelabeled“1”inf ,deletetheleafandconnectits
t
Italsoholdsthat: predecessortotherootofacopyoff .
s
3. Wenotethatallleafnodeslabeled“0”inf areleftunchanged.
ψ ⇐⇒ t
¬f,π
[f(x S;z S¯)̸=f(x)=0]∧[π(x S;z S¯)=1] ⇐⇒ Itishencestraightforwardtoshowthat∀z∈F:
[f(x S;z S¯)=1]∧[π(x S;z S¯)=1] ⇐⇒ (23)
[(f ∧π)(x S;z S¯)=1] ⇐⇒
f′(z)=1 ⇐⇒ f (z)=1∧f (z)=1
t s
[g(x S;z S¯)=1̸=0=g(x)] ⇐⇒ ψ
¬g
Next,wedemonstratehow,giventwofunctionsf ,f ∈ C
Hence,forallcases,itholdsthat: t s FBDD
over{0,1}n,wecanpolynomiallyconstructafunctionf′,satisfying
⟨f,x,π,I⟩∈Q(C,C) ⇐⇒ ⟨g,x,I⟩∈Q(C) (24) f k =f t →f s,againusinganencodingofsizeO(f t·f s).
Specifically,ourconstructionincludesthefollowingsteps:
Thus,weconcludethatCisself-aligned,andhenceTheorem4is
proven. 1. Since the class C is symmetrically constructible (Proposi-
FBDD
tion1),wecanpolynomiallyconstructafunctionf′ := ¬f ∈
Proposition2. IftheconditionsinTheorem4holdforaclassof t
C .
modelsC,thenQ(C,C)= Q(C). FBDD
P 2. Weconstructanewfunctionf ∈C bydeletingall“0”leaf
k FBDD
nodesoff′,andaddingedgesbetweenthepredecessorsofthe“0”
Proof.Basedonthepreviousreduction,wecandeducethatifthe
leaves,andtherootofacopyoff .
s
conditions in Theorem 4 hold for a model class C, then C is self-
aligned,i.e.,givenf,π∈Cwecanpolynomiallyconstructafunction Itisnowstraightforwardtoshowthat∀z∈F:
g∈C,suchthat:
f (z)=0 ⇐⇒
⟨f,π,x,I⟩∈Q(C,C) ⇐⇒ ⟨g,x,I⟩∈Q(C) k
¬f (z)=0∧f (z)=0 ⇐⇒
t s
Hence:
f (z)=1∧f (z)=0
t s
Q(C,C)≤ Q(C)
p Hence,f′ = f → f .Fig.3depictsthisconstruction.Weem-
t s
Inaddition,fromTheorems1and2,itholdsthat: phasize that the decision diagram f′ is not necessarily an FBDD.
Thisisbecausethesamevariablescanrepeatthemselvesmorethan
oncewithinf′.Welaterprovehowanyf′canbereducedtosome
Q(C)≤ p Q(C,C) f k ∈C FBDD.
Finally,itisstraightforwardtoconcludethat: Lemma7. Giventheencodingoff′fromLemma6,wecanpolyno-
miallyreducef′tosomef ∈C .
Q(C,C)= Q(C) k FBDD
P
Proposition3. FBDDsandMLPsareself-aligned,andhence,itfol- Proof.Asmentionedearlier,f′isnotnecessarilyanFBDDsinceit
lowsthat:Q(C FBDD,C FBDD)= P Q(C FBDD)andQ(C MLP,C MLP)= P maycontainvariousrepeatedvariableswithinitsdiagram.Wenow
Q(C MLP). showhoweachf′canbereducedtosomef
k
∈C FBDD.𝒇
𝒕
𝒇 →𝒇
𝒕 𝒔ss
𝟏
𝟏 𝟏 𝟏 𝟏 𝒇 𝟏 𝒂 𝒇 𝒔 𝟏 𝒂 𝒇 𝒔
𝒇 𝒔 𝒇 𝒔 𝟏 𝒉 𝒇 𝒔 𝟏 𝒉
𝒇 𝒔 𝟏 𝒂 𝟏 𝒃 𝟏
𝒔 𝟏
𝟏 𝟏 𝒃 𝟏 𝟏 𝒓
𝟏 𝟏 𝟏 𝟏 𝟏 𝟏 𝒓 𝟏 𝟏
𝟏 𝟏 𝟏
𝟏 𝟏
𝟏 𝟏
Figure3:Anillustrationofthepolynomialconstructionf′ :=f
t
→ Figure4:Anillustrationofthepolynomialconstructionoff
k
∈C FBDD,
f ,relyingonf ,f ∈C .Forf andf thedashedlinesrepresent givenf′.Theblueboxesrepresentanareaprunedduringourrecursive
s t s FBDD s t
pathsthatendwitha“0”leafnode,whilesolidlinesrepresentpaths procedure,inordertoconstructavalidFBDD,withoutarepetitionof
thatendwitha“1”leafnode. features.
Wedefineeachpathαasaconcatenationoftwosubpathsα := oftheclass).Westartbyshowinghow,giventwofunctionsf ,f ∈
t s
[α ;α ],eachcorrespondingthetherelevantpathinf (orf )ac- C over{0,1}n,wecanpolynomiallyconstructanewfunction
t s s t MLP
cordingly. Since each node v corresponds to some input feature f ∈C ,suchthatf =f ∨f .Thiswilllaterimplytheexistence
k MLP k t s
i∈(1,...,n),wedenotex (v)asafunctionthatmapsvtoitscor- oftheaforementionedlogicrelations.Moreformally:
v
respondingfeature.Weusethecommonconventionsofparent(v),
Lemma9. Letf ,f ∈ C ,thenf = f ∨f ∈ C canbe
left(v),andright(v). t s MLP k t s MLP
Wenowdescribethefollowingrecursivealgorithmforreducingf′ constructedinpolynomialtime.
tosomef ∈C .
k FBDD
Proof.Weassumethatf consistsofthiddenlayers,whilef consists
t s
1. Wetraverseonallcorrespondingpathsα,startingfromtheroot ofshiddenlayers.WerecallthatourdefinitionofanMLPisdefined
nodeandtraversingdownwards.Thealgorithmdoesnotchangef′ recursively,orinotherwords,f :=h(t)isdefinedas:
t 1
aslongasweareontheα partofthetraversion.
t
2. Reachinganodev ∈α ,ifforallv ∈α itholdsthatx (v )̸=
s s i t v i
x v(v s),thenwerecursivelycontinuetraversingbothleftandright. h 1(j) :=σ 1(j)(h( 1j−1)W 1(j)+b( 1j)) (j ∈{1,...,t}) (25)
Intuitively,thismeansthatthefeaturecorrespondingtov wasnot
partofthedecisionpathofα t.
s andf
s
:=h( 2s)isdefinedas:
3. Otherwise,wereachsomenodev ∈ α suchthatthereexists
s s
av i ∈ α t inwhichx v(v i) = x v(v s).Inthiscase,wedeletev s h(j) :=σ(j)(h(j−1)W(j)+b(j)) (j ∈{1,...,s}) (26)
fromf′.Wenowneedtoconnecttheparentofv witheitherthe 2 2 2 2 2
s
leftorrightchildofv s withinf′.Assumethatforx v(v i+1) = Wenowconstructf :=h(k)wherek:=max(s,t)+1.Forfully
right(x v(v i)),orinotherwordsv ileadstoarightturninthepath formulatingh wenek edtof3 ormulatetheassociatedweightsW(i)
α.Inthiscase,weconnecttheparentofv withtherightchildof 3 3
s andbiastermsb(i) foreachlayeri.Noticethati = 0istheinput
v .Iftheoppositeholds,i.e.,v leadstoaleftturninthepathα, 3
s i layersonocorrespondingbiasorweightisdefinedforthem,andthe
thenweconnecttheparentofv withtheleftchildofv .
s s dimensionsoftheinputlayersofbothh andh areequal(forMLPs
1 2
Intuitively,whentraversingoverthesecondpartofthepathα thatreceiveinputsfromthesamedomain).
s
wecanpotentiallycomeacrosstwoscenarios.Inthefirst,wereach Assuming that s = t, we construct b(i) := b(i) · b(i) for all
3 1 2
afeaturewithinthepaththatdidnotparticipateinα t.Inthiscase, 1 ≤ i ≤ s. In other words, b 3 is a concatenation of b 1 and b 2.
wewanttocontinuetraversingbothpossiblescenarios(leavingthe Notice that given that the dimensions of the hidden layers corre-
corresponding feature in the tree). In the second case, we reach a spondingtoh 1ared1 1,...,ds 1andthecorrespondingdimensionsof
featurethatalreadyparticipatedinα t.Inthisscenario,wedeletethe thehiddenlayerscorrespondingtoh 2 ared1 2,...,ds 2,thenthecor-
correspondingnodefromα sandconnectitinthesamedirectionin respondingdimensionsofthehiddenlayersofh 3 inthiscaseare:
whichthecorrespondingfeatureisconnectedinα s. (d1 1+d1 2),...,(ds 1+ds 2).
Hence, at the end of this recursive process, we are left with an Now,assumingthats ̸= t,withoutlossofgenerality,wecanas-
equivalentdiagramwhereforeachpathα,notwonodesv i,v j ∈α sumethatt > s.Foranylayer1 ≤ i ≤ sweconstructb 3 inthe
exist,suchthatx (v )=x (v ).Figure4depictsanillustrationof sameway,i.e.,b(i) := b(i)·b(i).Foranys < i ≤ tweconstruct:
v i v j 3 1 2
thisrecursiveprocess. b(i) :=b(i)·(0).Inotherwords,weconcatenatethevectorb witha
3 1 1
Thisconcludestheproofthatgiventwofunctionsf t,f s ∈C FBDD singlebiasterm0.Inthisparticularcase,thecorrespondingdimen-
wecanpolynomiallyconstructsomef k ∈C FBDD,whichissufficient sionsofh 3are:(d1 1+d1 2),...,(ds 1+ds 2),(ds 1+1+1),...,(dt 1+1).
toshowthatC FBDDisself-aligned. Finally,weconstructtheweightvectorW 3(i) ∈Qdi 3−1×di 3.Again,
forthecasewheres=t,weconstructitsuchthatforany1≤i≤s:
Lemma8. TheclassC isself-aligned.
MLP
(cid:32) (cid:33)
W(i) 0
Proof.WerelyonProposition4andshowthecorrespondingencodings W(i) = 1 (27)
of∧and→forC
MLP
(asufficientconditionfortheself-alignment 3 0 W 2(i)Assuming,withoutlossofgenerality,thats < t,weconstructit know that MLPs are symmetrically constructible. In other words,
suchthatforany1≤i≤sthenW 3(i)isformalizedasinEquation27 givenf t ∈C MLPwecanpolynomiallyconstructf k :=¬f t ∈C MLP.
andforanys<i≤tthen: Since any logic gate can be encoded using the universal NOR
gate,wecannowpolynomiallyconstructbothf := f → f ∈
k s t
W(i) =(cid:18) W 1(i) 0(cid:19) (28) C MLP andf k := f s∧f t ∈ C MLP.Thiscanbedonebyrecursively
3 0 1 building the corresponding MLPs representing either the f ∨f
s t
or ¬f constructions in a polynomial number of steps. Each one
Intuitively,theconstructionofthebiastermsandtheweightmatrix s
ofthesestepsrunsinpolynomialtimeandoutputsanewMLPof
Wi layerscapturesasituationwherewe“stack”thehiddenlayers
3 size O(f +f ) at each step. Hence, we conclude that MLPs are
of h and h . This is a result of the concatenated bias vectors at s t
1 2 self-aligned.
eachstep,aswellthefactthatwezeroouttheeffectoftheweights
correspondingtoh 1withthoseofh 2,andviceversa. Next,wepresenttheformalizationoftheSubsetSumproblem,used
Now,wedescribetheconstructionforthelastlayerkofh 3(recall forprovingProposition4.
thatk := max(s,t)+1).Sincewefocusonbinaryclassification,
thesingleactivationfunctionσofthelastlayercanbeconsidered, SSP(SubsetSumProblem):
withoutlossofgenerality,asastepfunction.Wealsodefinethebias Input:(z ,z ,...,z )setofpositiveintegers,integerk(suchthat
1 2 n
tobezero,i.e.,bk 3+1 =0.Now,weareleftwithdefiningtheweight k≤n)anda(target)integerT.
matrixofthelastlayer.Formally,wedefineW 3(k) ∈ Qdk 3−1×dk 3−1 , Outp (cid:80)ut:Yes,ifthereexistsasubsetS ⊆(1,2,...,n)ofsizeksuch
whereeachweightinW 3(k)issomestrictlypositiveweightw 3+. that i∈Sz i =T,andNootherwise.
Wenowprovethattheaboveencodingoff satisfiesthatf =
k k
f ∨f foranyvaluez∈F:
t s Proposition 4. While the query MCR(C ) can be solved in
Perceptron
polynomialtime,thequeryMCR(C ,C )isNP-complete.
f (z)=h(k)(z)=0 ⇐⇒ Perceptron Perceptron
k 3
(∗)
step (w+·ReLU(h(t))+w+·ReLU(h(s)))(z)=0 ⇐⇒ Proof.First,webrieflyexplainhowitispossibletocheckwhethera
3 3 1 3 2
(∗∗) subsetoffeaturesiscontrastiveforaPerceptronmodel,withinthe
(w+·ReLU(h(t))+w+·ReLU(h(s)))(z)≤0 ⇐⇒ misalignedconfiguration,inpolynomialtime[12].
3 1 3 2
APerceptronisdefinedbyf = ⟨w,b⟩,wherew istheweight
w+·(ReLU(h(t))+ReLU(h(s)))(z)≤0 ⇐⇒
3 1 2 vectorcorrespondingtotheinputx,andbisthebiasterm.Wecan
(∗∗∗)
(cid:80)
obtaintheexactvalueof x ·w .Then,forthefeaturesinS,
(ReLU(h(t))+ReLU(h(s)))(z)≤0 ⇐⇒ i∈S¯ i i
1 2 itispossibletolinearlyfindtheyassignmentscorrespondingtothe
(ReLU(h( 1t))+ReLU(h( 2s)))(z)=0 ⇐⇒ maximalandminimalvaluesof(cid:80) i∈Sy i·w i.Themaximalvalueis
(∗∗∗∗) obtainedbysettingy :=1whenw ≥0andy :=0whenw =0.
i i i i
ReLU(h(t)(z))=0∧ReLU(h(s)(z))=0 ⇐⇒ Theminimalvalueisobtainedrespectively(settingy := 1when
1 2 i
h(t)(z)≤0∧h(s)(z)≤0 ⇐⇒
w
i
<0andy
i
:=0whenw
i
≥0).Now,wecancalculatetheentire
1 2 rangeofpossiblevaluesthatcanbeobtainedbysettingthevalues
step 1(ht 1−1(z))=0∧step 2(hs 2−1(z))=0 ⇐⇒ ofS¯tox.Iftheminimalpossiblevalueisnegativeandthemaximal
f (z)=0∧f (z)=0 possiblevalueispositivethenitmeansthatSisindeedcontrastive,as
s k
thereexistsasubsetoffeaturesthatcanaltertheclassification.Ifnot,
Where(*)holds,sincef isdirectlyconnectedtotheoutputsof i.e.,theentirerangeiseitherstrictlypositiveornegative,thismeans
k
bothf andf (inwhichtheirstepfunctionwasreplacedbyReLU thatSisnotcontrastive.Moreformally,Siscontrastiveifandonly
s t
activations).Thisisthecasebothforwhens = tor,withoutloss if:
ofgenerality,whens < t,replacingeachcorrespondingweightin
W 1i withasingleneuron.Equivalence(**)holdsdirectlyfromthe (cid:88) x i·w i+max{(cid:88) y i·w i+b|y∈F}>0 ∧
definitionofthestepfunction(seeEquation12),whileequivalence i∈S i∈S¯
(***)holdsfromthefactthatw+ >0.Equivalence(****)follows (cid:88) (cid:88) (29)
3 x ·w +min{ y ·w +b|y∈F}≤0
fromthefactthatReLUisanon-negativefunction. i i i i
WeprovideavisualillustrationofthisconstructioninFig.5.Note
i∈S i∈S¯
thatthefiguredoesnotexplicitlystatetheinnerconnectionsbetween Inotherwords,itholdsthat:
f andf thatarewithzeroweights.Now,basedonLemma2,we
t s (cid:88) (cid:88)
−max{ y ·w +b|y∈F}< x ·w
i i i i
i∈S¯ i∈S
(30)
(cid:88)
≤−min{ y ·w +b|y∈F}
i i
𝒇 𝒕 𝑠𝑡𝑒𝑝1 i∈S¯
𝑅𝑒𝐿𝑈
𝑓 𝑡 𝑤 3+
𝑠𝑡𝑒𝑝3 Membership.Giventheaforementioneddescriptionregardingthe
𝑓
𝑠
𝑅𝑒𝐿𝑈 𝑤 3+ p beo rl sy hn io pm inia Nlv Pa il sid sa trti ao ign ho tff oc ro wn at rr da ,st si iv ne cere oa nso en cs anfo gr uP ee sr sc aep st ur bo sn es t, Sm ae nm d-
𝒇 𝒔 𝑠𝑡𝑒𝑝2 validatewhetheritholdsthat|S|<k,Siscontrastivewithrespect
tof(x),aswellasthefactthatπ(x ;z )=1.Iftheseholdthenwe
S S
knowthat⟨f,π,x,k⟩∈MCR(C ,C ).
Perceptron Perceptron
Figure5:Anillustrationoftheeffectiveconstructionf t∨f
s
∈C MLP,
relyingonf ,f ∈C .
t s MLPHardness.WereduceMCR(C Perceptron,C Perceptron)fromSSP(theSub- min{(cid:88) y ·w2+b |y∈F}=b
setSumproblem),aclassicNP-completeproblem,previouslyformal- i i 2 2 (37)
i∈S
ized.Givensome⟨(z ,z ,...,z ),k,T⟩thereductionfirstchecks
1 2 n
Now,if⟨(z ,z ,...,z ),T⟩∈SSP,thenthereexistsasubsetof
thespecificcasewherek=n.Inthisscenario,wewanttoconstruct 1 2 n
(cid:80)
a“dummy”result.Inotherwords,if(cid:80)n
i=1z
i
=T,wecanconstruct
f ine dat iu care tes sS tha⊆ t:(1,2,...,n)ofsizeksuchthat i∈Sz
i
= T.This
a“dummy”instanceof⟨f ,π := f ,x := (1,1),k := 2⟩.Wede-
1 2
finef := ⟨w1,b ⟩wherew1 := (1,−1)andb := 0.Wedefine
f 2 :=1 ⟨w2,b 2⟩ su1 ch that w1 := (1,1) and b 1 1 := 1. In case that (cid:88) x i·w i1 =−T =−b 1+ 1 4 >−b 1 =
(cid:80)n i=1z
i
̸=T,wecansimplyconstructafalseencoding. i∈S¯
(38)
Ifthisisnotthecase(meaningthatk ̸= n),thereductioncon- −max{(cid:88) y ·w1+b |y∈F}
structs the two following Perceptrons f := ⟨w1,b ⟩ and f := i i 1
1 1 2 i∈S
⟨w2,b ⟩, where w1 := (−z ,−z ,...,−z ), b := T + 1,
2 1 2 n 1 4 aswellas:
w2 := (z ,z ,...,z ),andb := −T.Thereductionconstructs
1 2 n 2
⟨f :=f 1,π :=f 2,x:=1 n,k :=k⟩,and1 ndenotesaunitvector (cid:88) x ·w1 =−T =−b + 1 <−b + 1 <
ofsizen. i i 1 4 1 2
aliF gnir es dt, bn yot fice ifth aa nt dt oh ner lye ie fx :istsacontrastivereasonofsizekforf 1
i∈S¯
−min{(cid:88) y ·w1+b |y∈F} (39)
2 i i 1
i∈S
∃S ∈(1,...n),z∈F. |S|≤k∧
(31) Regardingw2,itholdsthat:
[f 2(x S¯;z S)=1∧f 1(x S¯;z S)̸=f 1(x)]
(cid:88) x ·w2 =T =−b
ThismeansthatthereexistsasubsetSofsizeksuchthat: i i 2
i∈S¯
(40)
[−max{(cid:88) y i·w i1+b 1|y∈F}<(cid:88) x i·w i1 =−min{(cid:88) y i·w i2+b 2|y∈F}
i∈S i∈S¯ i∈S
≤−min{(cid:88) y ·w1+b |y∈F}]∧ andhence:
i i 1 (32)
i∈S
[(cid:88) x ·w2 ≤−min{(cid:88) y ·w2+b |y∈F}] ⟨f,π,x,k⟩∈MCR(C Perceptron,C Perceptron) (41)
i i i i 2
i∈S¯ i∈S Giventhat⟨(z 1,z 2,...,z n),T⟩̸∈SSP,thentheredoesnotexist
(cid:80)
Weassumeavalidencoding(sincethiscantriviallybevalidatedin asubsetoffeaturesS ⊆(1,2,...,n)ofsizeksuchthat i∈Sz i =
polynomialtime).Thefirst“dummy”validationcheckswhetherk= T.Thisisequivalenttosayingthattheredoesnotexistasubsetof
nand(cid:80)n z =T.Insuchacase,itholdsthat⟨(z ,z ),k,T⟩∈ featuresS ⊆(1,2,...,n)ofsizeksuchthat:
i=1 i 1 2
SSP.WealsonotethatS,whichisofsizek =2(theentireinput
domain)isanalignedcontrastivereason.Thisisduetothefactthat ((cid:88) x i·w i1 ≤−T)∧((cid:88) x i·w i2 ≥T) (42)
f ((1,1))=1andf ((0,1))=0.Additionally,itholdsthatforany i∈S¯ i∈S¯
1 1
zitsatisfiesthatf 2(z)=1.Inotherwords: meaningthattheredoesnotexistasubsetSsuchthat:
∃S ∈(1,...n),z∈F. |S|≤k∧ [−max{(cid:88) y ·w1+b|y∈F}<(cid:88) x ·w1]∧
(33) i i i i
[f 2(x S¯;z S)=1∧f 1(x S¯;z S)̸=f 1(x)] i∈S i∈S¯
(43)
Hence⟨f,π,x,k⟩∈MCR(C Perceptron,C Perceptron). [(cid:88) x i·w i2 ≤−min{(cid:88) y i·w i2+b|y∈F}]
Thus,wecannowassumethatk<n.Sinceallvaluesinw1are i∈S¯ i∈S
negative,thenitholdsthatforanysubsetoffeaturesS: andhence:⟨f,π,x,k⟩ ̸∈ MCR(C ,C ),concluding
Perceptron Perceptron
thereduction.
max{(cid:88) y ·w1+b |y∈F}=b (34)
i i 1 1
Theorem 5. Assuming that P ̸= NP, the class C is not
i∈S Perceptron
self-aligned.
ItalsoclearlyholdsthatforanyS:
b ≥min{(cid:88) y ·w1+b |y∈F} (35) Proof. Assume, by negation, that the model class C Perceptron is self-
1 i i 1 aligned. Hence, we deduce that given some f,π ∈ C we
Perceptron
i∈S can polynomially construct a function g such that ⟨f,π,x,I⟩ ∈
Sinceweknowthatk<n,andsincethesearenegativeintegers, Q(C ,C ) if and only if ⟨g,x,I⟩ ∈ Q(C ). As
Perceptron Perceptron Perceptron
thenthereexistsatleastoneintegerinthecomplementarysetS,and weknowfromProposition4thatdecidingQ(C ,C )is
Perceptron Perceptron
henceitalsoholdsthat: NP-hardandthatQ(C )isinPTIME,thefollowingclaimholds
Perceptron
max{(cid:88) y ·w1+b |y∈F}=b > onlyifPTIME=NP.Hence,C Perceptronisnotself-aligned.
i i 1 1
i∈S
(36) E FrameworkExtenstions
min{(cid:88) y ·w1+b |y∈F}+ 1
i i 1 2 Ourframeworkcanbeextendedinmultipleaxes.First,althoughwe
i∈S
followcommonconventions(e.g.,[9,12,89,15])andfocusonbinary
Regardingw2,sinceallofitsvaluesarepositive,thenitholdsthat: inputandoutputdomainstosimplifyourpresentation,someofourfindingsareapplicabletoanydiscreteinputoroutputdomains.Addi-
tionally,ratherthanconsideringindividualfeatures,wecanconsider
“high-level"features,e.g.,bygroupingmultiplefeaturestogether.This
allowsdefiningexplanations,forexample,intermsofsuper-pixels
andalsoRGBimagesinvariouspracticalsettings.
Morebroadly,thetypesofexplanationsanalyzedinthisworkare
explanationswithformalandmathematicalguarantees,commonly
discussedwithinasub-fieldofinterestknownasFormalXAI[68].One
benefitofexplanationswithformalguaranteesisthat,unlikeheuristic-
basedexplanations,theyenableamorerigorousandmathematical
analysis,allowingthestudyofcomputationalcomplexityaspectsof
obtainingexplanations[12,13].
However,thereexistsabodyofworkinFormalXAIthatfocuses
onthepracticalaspectofcomputingexplanationswithformalguaran-
tees[25,69,13,14,47,26,27,44,51].Initialeffortstocomputesuch
explanationsweredemonstratedonsimpleMLmodels,whichallow
tractablecomputationsofexplanations.Thesemodelsincludedecision
trees[53,44],linearmodels[69],monotonicclassifiers[70],andtree
ensembles[50,51,11,17].Morerecently,variousmethodshavebeen
proposedtoobtainexplanationswithformalguaranteesforneural
networks[61,91,14,13,42,54].Thistaskisconsideredacomputa-
tionallychallengingone[12,15].However,thedevelopmentofsuch
methodsisfacilitatedbytherapidadvancementofneuralnetwork
verificationtools[57,58,90,82,65,35,98,55,60,1,22,93,94,4],
whicharebeingdevelopedmorebroadlytoformallycertifyadiverse
setofprovableproperties[23,24,66,67,78,29,18,86,30,19,2,
3,5,6,71].Webelievethatourworkcanserveasasteptowards
developingamorerigorousunderstandingofthepotentialcapabilities
andlimitationsofcomputingexplanationswithformalguarantees
concerningagivendistributionofinterest.