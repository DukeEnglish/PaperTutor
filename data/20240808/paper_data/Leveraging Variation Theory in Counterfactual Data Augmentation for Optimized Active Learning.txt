Leveraging Variation Theory in Counterfactual Data Augmentation for
Optimized Active Learning
SimretArayaGebreegziabher KuangshiAi ZhengZhang
sgebreeg@nd.edu kai@nd.edu zzhang37@nd.edu
UniversityofNotreDame UniversityofNotreDame UniversityofNotreDame
ElenaL.Glassman TobyJia-JunLi
glassman@seas.harvard.edu toby.j.li@nd.edu
HarvardUniversity UniversityofNotreDame
Abstract
ActiveLearning(AL)allowsmodelstolearn
interactivelyfromuserfeedback. Thispaperin-
troduces a counterfactual data augmentation
approach to AL, particularly addressing the
selection of datapoints for user querying, a
pivotal concern in enhancing data efficiency.
OurapproachisinspiredbyVariationTheory,
a theory of human concept learning that em-
phasizes the essential features of a concept
byfocusingonwhatstaysthesameandwhat
changes. Instead of just querying with exist-
ingdatapoints, ourapproachsynthesizesarti-
ficial datapoints that highlight potential key Figure1: InspiredbyVariationTheoryoflearning,our
similarities and differences among labels us- approach combines neuro-symbolic patterns with in-
inganeuro-symbolicpipelinecombininglarge contextlearningtogeneratecounterfactualexamplesfor
languagemodels(LLMs)andrule-basedmod- activelearning. Thesinglearrowindicatesthemodel
els. Through an experiment in the example trainingdatastream,whilethedoublearrowindicates
domainoftextclassification,weshowthatour themodelinferencedatastream.
approachachievessignificantlyhigherperfor-
mancewhentherearefewerannotateddata. As
theannotatedtrainingdatagetslargertheim- strugglestomakeeffectivelearningdecisions,af-
pact of the generated data starts to diminish fecting its early performance (Yuan et al., 2020).
showingitscapabilitytoaddressthecoldstart Previousworkshowedthatcarefulselectionofex-
problem in AL. This research sheds light on amplestobeannotatedisinstrumentaltoachieve
integratingtheoriesofhumanlearningintothe
optimalperformancegain(Becketal.,2013).
optimizationofAL.
Theuseofhumancognitivelearningtheoriesas
inspirationforhowandwhatmodelslearnhasbeen
1 Introduction
shownpromisinginpreviouswork(ZhangandEr,
Active learning (AL) allows users to provide fo- 2016). Followingthisdirection,ourworkexplores
cused annotations to integrate human perception thenoveluseofatheoryofhumanlearning—The
anddomainknowledgeintomachinelearningmod- VariationTheory—tosupporthuman-AIcollabora-
els (Settles, 2009). It relies on a human’s itera- tionininteractivemachinelearning. TheVariation
tive annotations to build and refine model perfor- Theoryoflearning(LingLo,2012;Marton,2014;
mance (Budd et al., 2021), and as a result, the MartonandBooth,1997)statesthathumanlearn-
model’s gain in performance of with each round erscanmoreeffectivelygraspthecriticalaspectsof
ofannotationsreliesonthequalityandquantityof aconceptbyexperiencingvariationalongcritical
annotatedexamples. However,theprocessoflabel- features. Forexample,tocomprehendtheconcept
ingdatapresentsasignificantbottleneckduetothe ofa“ripebanana”,learnersshouldfirstencounter
costandtimeassociatedwithannotation(Fredriks- bananas alongside examples of other fruits, and
son et al., 2020). Additionally, AL faces a cold then encounter various colors of bananas labeled
startproblem,whereinitially,intheabsenceofsuf- asmoreorlessripe,sothattheycanrecognizethe
ficient annotated data, the model is unstable and criticalqualitiesofabanana,e.g. “yellowness”and
4202
guA
7
]GL.sc[
1v91830.8042:viXra“firmness”,ascriticalindicatorsofripeness(Seel, Thispapermakesthefollowingcontributions:
2011). VariationTheoryinvolvestwokeysteps: (1)
identifyingcriticalfeaturesandconceptualbound- EvaluatingtheeffectivenessofVariationTheory
aries,and(2)devisingnewexamplestodelineate inactivelearning: WeassesshowtheVariation
theseconceptualboundaries. Thisworkexplores Theoryofhumanlearningcanenhancetherobust-
the relevance of the Variation Theory of human ness and address the cold-start challenges (Yuan
conceptlearningincontextswhereanAImodelis et al., 2020) in active learning. The results show
activelylearningaconceptfromhuman-provided thatusingcounterfactual-basedexampleselection
annotations; the variations that Variation Theory resultsinhigheraccuracywithfewerannotations
proscribes may assist both the machine and the requiredcomparedtootherexampleselectionmeth-
humaninthiscontext. odsincoldstartscenarios.
Previousresearchshowedthebenefitsofcounter-
Quality of counterfactual examples generated
factualdataaugmentationtoenhancemodelperfor-
using neuro-symbolic approaches: Our ap-
mance(Liuetal.,2021;Yangetal.,2022a;Wang
proachemploysVariationTheorytogeneratecoun-
andCulotta,2020;Reddyetal.,2023). Inthecon-
terfactual data that differ from the original data
text of Variation Theory, synthesized counterfac-
semanticallyoverneuro-symbolicdimensionsbut
tualdatacanbemoreeffectiveincapturingmean-
maintain syntactic similarity with the original la-
ingful variations than real data selected from the
beled data. We assess the quality of generated
dataset. However,thescalablegenerationandse-
counterfactualexamplesusingathree-stagefilter-
lection of augmented data has been a consistent
ingmechanismincludingtherateatwhichthesym-
challenge (Liu et al., 2022; Li et al., 2023a). To
bolicpatternsarekeptconsistentinthegenerated
addressthis,DISCO(Chenetal.,2023)proposed
examples. The results show significant increase
amethodforautomaticallygeneratingcounterfac-
in the Soft Label Flip rate (SLFR)—the rate of
tual data using task-agnostic models. Despite its
removaloforiginallabelsfromcounterfactualex-
robustapproachtoaugmenteddata,DISCO’suse
amples, and a high level of consistency in Label
ofafullyblack-boxpipelinemakesdebuggingand
FlipRate(LFR)—therateofchangingoriginalla-
improvingthemodeldifficultanddoesnotallow
belsintotargetlabelsingeneratedcounterfactual
meaningful presentation of variations that facili-
examples. Byevaluatinghowoftennewexamples
tateseffectivehumanannotationandsensemaking.
meaningfully alter the original label and capture
To address this, we propose a counterfactual
valuablevariations–bykeepingtheoriginalneuro-
generationpipelinethatusesneuro-symbolicpat-
symbolicpattern–wecanassesstheefficacyofthe
terns to identify important features and uses
examplesproduced.
them to guide the LLM’s counterfactual gener-
This paper assesses the impacts of annotation
ation1. Specifically, we use a programming-by-
selection, syntactic diversity, and semantic diver-
example approach (Gulwani, 2011) to generate
sity of generated counterfactuals in active learn-
neuro-symbolic patterns (Gebreegziabher et al.,
ing. We use a classification task to compare the
2023). These patterns capture the syntactic and
performanceofourmethodwithfourbaselinecon-
semantic similarities among similarly labeled ex-
ditions, i.e., random selection and cluster-based
amples. Wethenusethelearnedpatternstoguide
selection,uncertainity-basedselection,andcoun-
the LLM to generate counterfactual examples to
terfactualswithoutVariationTheory. Ourmethod
beusedinconsecutiveroundsofmodelre-training.
uses generated counterfactual data as augmenta-
Thegeneratedcounterfactualexampleschangethe
tion, while the baseline uses existing “real” data
assignedlabelintoadifferentlabelwhilestillkeep-
along with example selection methods to train a
ing the original symbolic pattern in the data. In
multiclassclassificationmodel. Theresultsacross
doingso,thegeneratedexamplesintroducemore
three datasets and two models show that the use
meaningful variability in the data for subsequent
ofcounterfactualgenerateddataresultsinatleast
model training. To further ensure the quality of
twotimeshigherperformancewithfewernumber
thegeneratedcounterfactualexamples,wedesign
ofannotations(<70)comparedtotheothercondi-
athree-stepautomaticfilteringpipeline.
tions. Asthenumberofannotateddataincreases,
theimpactoftheaugmenteddatastartstodiminish
1https://github.com/SimretA/Variation-Theor
y-in-Counterfactual-Data-Augmentation showingtheefficacyoftheapproachincold-startscenarios. eration has been the scalable generation and se-
lection of augmented data (Liu et al., 2022; Li
2 RelatedWork
et al., 2023a). To address this, DISCO (Chen
etal.,2023)introducedamethodforautomatically
2.1 DataGenerationandAugmentation
generatinghigh-qualitycounterfactualdatausing
In domains with scarce annotated data, data aug- task-agnostic “teacher and student” models to al-
mentationmethodsaimtoenhancethequantityand lowclassifiermodelstolearncasualrepresentation.
qualityoftrainingdata(Yangetal.,2022b). Tradi- DISCOusesaneuralsyntacticparsertoselectthe
tionaldataaugmentationtechniques,suchasgeo- spans of the sentence to vary on to generate data
metrictransformationsandcolorspacealterations, usingLargeLanguageModels(LLMs). Although
donotmodifythefundamentalcausalgenerative DISCO provides more robust models trained on
process. Asaresult,theydonotcounteractbiases augmenteddata,theuseofblack-boxapproaches
likespuriouscorrelations(Kaushiketal.,2021). togeneratedatacouldmakemodeldebuggingand
Counterfactual data augmentation has been improvement harder. To address this, we adopt
widely used to counteract spurious correlations a neuro-symbolic approach to define the concept
in data (Denton et al., 2020; Liu et al., 2021; boundaries in user annotations (Gebreegziabher
Yang et al., 2022a; Wang and Culotta, 2020). etal.,2023).
This approach employs counterfactual inference
to control generative factors, facilitating the gen- 2.2 Example-basedLearningviaVariation
eration of samples that can address confound- Theory
ing biases. Many existing strategies use dataset-
BasedonpreviousstudiesonLLMsascounterfac-
specific counterfactual augmentation methods in
tual generators, our work seeks to learn from hu-
specificdomains,suchassentimentanalysis(Yang
mancognitionandexample-basedlearningtobetter
et al., 2022a; Kaushik et al., 2020), named entity
guideLLMstogeneratehigherqualitydata. Will
recognition(Ghaddaretal.,2021),textclassifica-
educational theories that work for human learn-
tion(WangandCulotta,2020),andneuralmachine
ers also work for AI? Decades of research have
translation(Liuetal.,2021). Apopularapproach
demonstrated that using example-based learning
toaddressspuriousdependenceinNLPdatasetsis
constitutesaneffectiveinstructionalstrategyforhu-
tousehuman-guidedcounterfactualaugmentation
manacquiringnewskills(GogandRummel,2010).
throughcrowdsourcing (Kaushiketal.,2021;Joshi
Few-shot learning is an example-based learning
andHe,2022). Thisapproachpresentsindividuals
methodcommonlyusedbyLLMs.
with data and preliminary labels, asking them to
How can we use human learning theories to
modifythedataforanalternatelabelwhileavoid-
support the annotation of data and training of
ingunnecessaryedits(Kaushiketal.,2020). This
LLMclassifiers? VariationTheory(Marton,2014),
methoddependsonhumaneffortsandexpertiseto
rootedinphenomenography,givesusinsightsfrom
overcomethechallengeofautomaticallytranslat-
humanexperience,e.g.,(Cheng,2016). Thecore
ingrawtextintoimportantfeatures.
conceptofthistheoryinvolvespresentingsetsof
LLMshavehavebeenshowntopossessexten-
examplesthatvaryalongspecificdimensions,en-
sivegenerativecapacity,makingthemusefultools
abling learners to identify and conceptualize the
forcounterfactualdatageneration. Lietal.(2023a)
dimensionsasausefulcoordinatespacefordescrib-
introduced a method utilizing LLMs to generate
inginstantiationsoftheunderlyingconcept. This
domain-specific counterfactual samples through
aligns with the foundational principle of counter-
promptdesign,highlightingthealignmentbetween
factualdataaugmentationinmachinelearning.
theefficacyofLLMsindomain-specificcounterfac-
tualgenerationandtheiroverallproficiencyinthat
3 Approach
domain. Althoughin-contextlearninghasbeena
promisingdirectiontogetLLMstoperformdiffer- OurapproachappliestheVariationTheoryofhu-
enttasksMinetal.(2022)foundthatdemonstrating man learning to machine learning in the context
the label space, the distribution of the input text, of active learning (AL). In order to adopt Varia-
andtheoverallformatofthesequenceasimportant tion Theory to AL we propose a new approach
factorsfortheperformanceofin-contextlearning. of counterfactual data generation by combining
A consistent challenge in counterfactual gen- neuro-symbolicmethodsandLLMs. SpecificallyA
Candidate phrases: [‘affordable lobster’, GPT-4o Original text: ‘Cheapest restaurant on the street, but the
‘reasonable price’, ‘budget-friendly menu options’] Gener pa hte ra c sa en sdidate p Or ric ige is n w ae l r le a bto eo l: h pig rih c efo r what you get.’
Pattern: ‘(cheap)+*+NOUN’
Target label: products
B
GPT-4o
Generate
counterfactuals
Candidate 1 : ”\nlabel: Cheapest on the street, but\n\n##\n\n”
Counterfactual Data Regular expression usedL [r’.*label:.*’, r’.\n\n##\n\n$’]
Reject erroneous
g pe ren -e dr ea fiti no en ds sth ea t t o m f ca otc mh m a o n C hC iga hn d inid ca at re b 2 s f o r w: ” hB ae t s yt o l uo b gs et te .”r ever, but the pasta was just too
errors 1 Does not match pattern: [‘(cheap)+*+NOUN’]
Heuristic Filter
Candidate 3 : ”Reasonable price overall, but the pasta prices
Reject generations that do are too high for what you get”
n po at t tk ee rne sp neuro-symbolic 2 Candidate 4 : ”Cheapest on the street, but the service was just
Symbolic Filter too slow for what you get”
tR he aj te : cts counterfactuals LLM-based Discriminator3 C paa sn td ai d wa at se j5 u s t t o : o ” O hif gfe hr i in ng c b aru bd sg fe ot r- f wri he an td yly o um ge en tu .” o ptions, but the
1.Still belong to the original
label
2.Do not belong to the
target label
D Fine-tuned GPT-3.5
Fine-tuning set Fine-tune Counterfactual
Generator
Figure2: Ourpipelinefirstgeneratescandidatephrasesthatmatchthelearnedneuro-symbolicpattern(A).By
usingthegeneratedcandidatephraseswegeneratecounterfactualdatathatincludesoneofthegeneratedcandidate
phrases,therebymatchingthelearnedpatternbutchangestheoriginallabelintothetargetlabel(B).Thegenerated
counterfactualexamplesarefilteredthrough3layers(C)tocreatethefine-tuningdataset. Thefiltereddatawillthen
beusedtofine-tuneaGPT-3.5counterfactualgenerator(D).
weusedomain-specificneuro-symbolicpatternsto 3.1.1 LearningNeuro-symbolicPatterns
learnsyntacticrepresentationofsimilarlylabeled We use a programming-by-example (Lieberman,
data that define a neuro-symbolic model’s learn- 2001)approachtoestablishtheboundariesofcon-
ing space and concept boundaries. We then use cepts defined by data points and their associated
thelearnedpatternstoguidethegenerationofaug- ground truth labels. While our simulation study
menteddatathathelpsaclassificationmodellearn currently relies on ground truth labels, these will
importantnuancesabouteachlabel(Fig.2-A,B). besubstitutedwithhumanannotationsinforthcom-
Through this approach we generate counter- inginteractivesystems. Afterwerandomlyselecta
factual data that are syntactically similar to their fewannotations,weusePaTAT’s(Gebreegziabher
original counterpart but semantically belong to etal.,2023)interactiveprogramsynthesisapproach
a different label. To ensure the quality of the togeneratedomain-specificpatternrulesthatmatch
generatedcounterfactuals,weapplyathree-level theannotatedexamples. Thesepatternrulesrepre-
filteringmechanism(Fig.2-C). sentthelexical,syntactic,andsemanticsimilarities
ofdataunderthesamelabel. PaTAT’spatternlan-
3.1 UsingNeuro-symbolicPatternstoDefine
guageincludesthefollowingcomponents:
ConceptSpace
• Part-of-speech (POS) tags: VERB, PROPN,
VariationTheorysuggeststhathumanslearnacon-
NOUN,ADJ,ADV,AUX,PRON,NUM
ceptmosteffectivelywhentheyareshownexam-
plesthatvaryinonlyonespecificdimensionata • Word stemming: [WORD] (e.g., [have] will
time,whileallotheraspectsstaythesame. There- match all variants of have, such as had, has,
fore,animportantaspectofVariationTheoryisde- andhaving)
terminingwhichfeaturesshouldvarytoemphasize
• Soft match: (word) (e.g., (pricey) will
their effects in the learning process. We achieve
matchsynonymssuchasexpensiveandcostly,
thisbylearningcriticalfeaturesfromlabeleddata
etc.)
by generating neuro-symbolic patterns and make
smallmodificationsontheoriginalsentencewhile • Entitytype: $ENT-TYPE(e.g.,$LOCATIONwill
maintaining consistency along the generated pat- matchphrasesoflocationtype,suchasHous-
tern. ton, TX and California; $DATE will matchdates; $ORG will match names of organiza- 3.2.1 RegexHeuristicFiltering
tions)
We use a heuristic-based filter to identify and re-
• Wildcard: * (will match any sequence of movecounterfactualdatawithcommongeneration
words) flaws. This filter ensures that the generated sen-
tences are coherent and complete. This method
Althoughthefundamentalpatternsaresuitablefor uses regular expressions to detect common gen-
generaldomaintextdata,itisfeasibletoexpandthe eration errors observed during our experimenta-
patternlanguagetoincludespecializedordomain- tion(Fig.2-C1). Wedefinerulestoidentifyerror
specificpatterns. patterns such as repetition of prompt, inaccurate
Thismethodgeneratesacollectionofregex-like formatting,andincompletegeneration,whichwere
patterns(butwithsemantically-enhancedtags)that somecommonpitfallsweobservedduringgenera-
match with the labeled positive examples while tion.
excluding the labeled negative examples. For ex-
ample,iftwodatapointsinthedomainofrestau- 3.2.2 Neuro-symbolicFiltering
rant review “Good food with great variety." and
The neuro-symbolic filter ensures that the gener-
“Thefoodwasamazing."havethesamelabel“prod-
ated counterfactual examples retain the original
ucts", PaTAT learns up to 5 patterns that collec-
learnedpattern. Theoriginalpatternsrepresentfea-
tively match the set of examples annotated with
turesthemodellearnsasusefulconceptualbound-
that label. In this case, two patterns match both
aries. Therefore, keeping them in the counterfac-
sentences,i.e.,“[food]+*+ADJ”,“(amazing)+*”.
tuallygeneratedexampleschallengesthemodel’s
3.1.2 UsingNeuro-symbolicPatternsfor currentboundary. Toachievethisweimplementthe
CounterfactualDataGeneration filterusingexecutableneuro-symbolicpatternsde-
Usingthelearnedneuro-symbolicpatterns,wegen- finedin§3.1. Specifically,wecheckwhethereach
erate counterfactual examples by modifying the generatedcounterfactualexamplematchesitsorig-
originaltexttobeaboutadifferentlabelwhilestill inalcounterpart’sneuro-symbolicpattern(Fig.2-
keeping the original pattern. To ensure minimal C2). Thisfilterexcludesgeneratedcounterfactual
modificationsandtomakesurethereasonforthe examplesthatdonotmatchwiththeprovidedpat-
originallabeliskept,webeginbygeneratingcandi- tern from being used in the consecutive training
datephrasesforsegmentsoftheoriginalsentence pipeline. Toquantifythisoverthegeneratedcoun-
thatmatchedtheneuro-symbolicpattern(Fig.2-A). terfactualexampleswecalculatethepatternkeep-
We use the generated candidate phrases as ingrate(PKR)asdefinedbelow.
a constraints to be included in the generated
sentence. For example in Fig. 2, the pattern 1 (cid:88)N
PKR = 1(pˆ = p )
(cheap)+*+NOUN hascandidatephrases[‘afford- n n
N
ablelobster’,‘reasonableprice’,‘budget-friendly n=1
menu’]. Whengeneratingthecounterfactualexam-
wherep isoriginalpattern,pˆ isthepatterngiven
pleweinstructtheLLMtoalwaysincludeoneof n n
tothecounterfactualdata,andN isthesizeofthe
thosephrasesinthemodifiedsentence. Thiscon-
counterfactualdata.
straint ensures that counterfactual examples that
varyinsemanticcontentremainwithinthesyntac-
3.2.3 LLM-basedDiscriminatorFiltering
ticboundariessetbythepattern,whichdefines,at
least in part, the particular label for which coun- Finally,weapplyafilterusingaGPT-3.5discrimi-
terexamplesarebeinggenerated(Fig.2-B). nator. Thisfilterremovescounterfactualsthatstill
keep their original label and all counterfactuals
3.2 FilteringGeneratedCounterfactualData
that do not belong to the target label (Fig. 2-C3).
The ideal counterfactual examples is a complete Thisfiltermakessurethatthegeneratedcounterfac-
andcoherentsentencethatshouldkeepthepatterns tualexampleshaveenoughsemanticchangesthat
oftheoriginaltext,andsuccessfullyfliptheorigi- changes the original label to the target label. We
nallabeltothetargetlabel. Toensurethequalityof adopttwomatrices(Chenetal.,2023)toquantify
thefine-tuningdatasetweimplementathree-stage this: theLabelFlipRate(LFR),andtheSoftLabel
filteringmechanism: FlipRate(SLFR)asdefinedbelow:• Condition2: Clustering-basedexamplese-
lectionToensuredatabalance,originalexam-
N
LFR = 1 (cid:88) 1(cid:16) ˆl = L (cid:17) ples are initially transformed into word vec-
n n
N tors. Thesevectorsarethengroupedusingk-
n=1
means,andtheinputorderisultimatelygener-
N
1 (cid:88)
SLFR = 1(ˆl ̸= l ) atedbyrotationamongthedifferentclusters.
n n
N
n=1
• Condition 3: Uncertainty-based example
selection We use model confidence on the
whereˆl
isthelabelgivenbyGPT-3.5discrimina-
training set to choose data with the lowest
n
confidence to be labeled. We use verbal un-
tor,L isthetargetlabel,l istheoriginallabel.
n n
certainty(Linetal.,2022)togetmodelcon-
SLFRmeasurestherateatwhichthegenerated
fidence in GPT-3.5 and model logits for the
counterfactualremovetheiroriginallabel,andLFR
BERTmodel.
evaluates how often the counterfactual examples
successfullyadoptthetargetlabel.
• Condition 4: Counterexamples without
3.3 Fine-tuningaSmallerCounterfactual Variation Theory We generate counterex-
Generator amples without using the neuro-symbolic
pipelinedefinedinFig2.
WeusecounterfactualexamplesgeneratedbyGPT-
4otofine-tuneasmallerGPT-3.5model,forcost-
• Condition 5: LLM generated counterfac-
effectiveness and practicality (Fig. 2-D). Specifi-
tualexamplewithfilteringInthiscondition
cally,weusethesetoffiltereddatasetthatsatisfies
eachselectedexampleispairedwithcounter-
allthreestageswefine-tuneaGPT-3.5modelover
factual examples generated by a fine-tuned
5epochstobeusedasacounterfactualgenerator
GPT-3.5 model, and filtered using the three
duringAL.
stepfilteringmethod(see§3.2).
4 Experiments
4.2 Dataset
Weevaluatethegeneratedcounterfactualsintwo Inordertosimulatethesubjectivityinhumandata
phases: anautomatedfilteringmechanismtodetect annotationwechosedatasetsthatexhibithighintra-
the rates at which the generated data changes its coderreliability,butlowinter-coderreliability.
labelusingGPT-4oandfine-tunedGPT-3.5mod-
els,andthroughastandardclassificationtaskusing • YELP:TheYELPdataset(Asghar,2016)con-
twopre-trainedmodels. Wesimulateandevaluate sists of user reviews of different businesses
the effects of five different annotation selection and services. The dataset itself provides 4
techniques in interactive AL: random selection, ground-truthcategories(i.e. service,price,en-
cluster-based selection, uncertainity-based selec- vironmentandproducts),werandomlysam-
tion, counterfactual examples generated without pled495examplesforthisexperiment.
VariationTheory,andourproposedcounterfactual
• MASSIVE:TheMASSIVE(FitzGeraldetal.,
based example selection. We use each dataset’s
2022)virtualassistantutteranceswith18la-
originallabelasgroundtruthanduseGPT-3.5and
beledintentsasground-truth(e.g. audio,cook-
aBERTmodelasthetargetclassificationmodels.
ing, weather, recommendationetc). Forthis
4.1 Conditions experiment we randomly selected 30 exam-
We investigate the implications of counterfactual plesfromeachcategory,makingupatotalof
exampleselectionandotherselectionmethodsin 540examples.
interactiveAL.Specifically,weusefiveconditions:
• Emotions: Includes a collection of English
• Condition 1: Random example selection Twittermessagesannotateswith6emotions:
In this condition random labeled examples anger,fear,joy,love,sadness,andsurprise(El-
are selected for each annotation iteration to giriyewithana,2024). Forthisexperimentwe
train the classification model, serving as the randomly selected 500 examples while bal-
baselinecondition. ancingthenumberoflabels.4.3 CounterfactualEvaluationwithActive PatternKeepingRate
Learning Method YELP MASSIVE Emotions
GPT-4ogeneration 0.96 0.88 0.81
Toevaluatethegeneratedcounterfactualexamples,
Fine-tunedgeneration 0.94 0.93 0.88
weemployasimulatedactivelearningtasktotrain
SoftLabelFlipRate
and evaluate a BERT model (Devlin et al., 2018)
Method YELP MASSIVE Emotions
andGPT-3.5modelforamulti-classclassification
GPT-4ogeneration 0.25 0.71 0.58
task. Weusetheexampleselectionconditionsde- Fine-tunedgeneration 0.51 0.80 0.70
finedin§4.1todefineasubsetof10,15,30,and LabelFlipRate
progressivelyincreasingupto170datapoints(re- Method YELP MASSIVE Emotions
ferredtoas‘shots’),alongsidetheircorresponding GPT-4ogeneration 0.95 0.86 0.86
Fine-tunedgeneration 0.99 0.93 0.92
ground truths. After fine-tuning the model, we
evaluateitagainstahold-offsetofthedataset.
Table1: Generatedcounterfactualdataqualityevalua-
Toaugmentthemodel’strainingwithgenerated
tiononrawGPT-40generationvs. Fine-tunedgenera-
counterfactualexamples,wepaireachoriginaldata tion.
with its generated counterfactual examples and
their assigned target label. This pairing is used
4.4.2 CounterfactualEvaluationonActive
toenrichthedistributionandqualityofthetraining
Learning
data, hypothesizing that the inclusion of counter-
We present our findings on the efficacy of gen-
factuals would enhance the model’s learning and
erated counterfactuals in active learning as de-
predictiveaccuracyinearlystagesofannotationad-
fined in § 4.3. We report the macro F1-scores
dressingthecoldstartproblem(Yuanetal.,2020).
for the three datasets across different shots and
Similarly, the performance of the model, in this
conditions (YELP dataset (Table 2), MASSIVE
casetrainedwithbothoriginalandcounterfactual
dataset(Table3),andemotionsdataset(Table4))
dataset,wasagainevaluatedagainstthesamehold-
usingtwomodels-fewshotGPT-3.5andaBERT
offset. Thiscomparativeanalysisaimedtoquan-
model. We use training shots ranging from 10 to
tifytheimpactofcounterfactualexamplesonthe
120 shots for GPT-3.5 to stay with-in OpenAI’s
model’s ability to generalize and make accurate
tokenlimitand10to170fortheBERTmodel.
predictionsonunseendatainearlyactivelearning
We conducted a pair-wise t-test between the
scenarios.
counterfactualconditionandtheotherbaselinecon-
ditions to understand the impact of the proposed
4.4 Results
approach. Theresultsacrossthethreedatasetshigh-
4.4.1 AutomaticGenerationQuality
lightthestronginitialimpactthatthecounterfactual
Evaluation
conditionhasinaddressingthecoldstartproblem
BuildingontheworkofChenetal.(2023),wemea- in active learning (see Fig. 3). We consistently
sure the efficacy of the generated counterfactual observeastatisticallysignificantadvantageofthe
examples based on three metrics: Pattern Keep- counterfactualconditioninlowershotnumbers(see
ing Rate, Soft Label Flip Rate, and Label Flip Table 2-4). As the number of annotate examples
Rate. These metrics were examined in two con- increases(70shotsandabove),thedifferenceinav-
ditions(see1): usingGPT-4otogeneratecounter- erageF1-scoredecreases,suggestingtheadvantage
factuals and using a fine-tuned GPT-3.5 counter- of the counterfactual condition diminishes when
factual generator as defined in Fig 1. The results moredatabecomeavailable. Similarly,weobserve
showthatforbothdatasets,themulti-filteringand significantimpactsofthecounterfactualcondition
fine-tuning pipeline based on GPT-3.5 maintains whenusingafew-shotapproachwiththeGPT-3.5.
orevenimprovesthequalityofgeneratedcounter- However,wedidnotfindresultsthatconsistently
factualsonallmetrics. ThePatternKeepingRate, indicatedasubstantialdifferencebetweentheran-
Soft Label Flip Rate, and the Label Flip Rate re- dom,cluster,andcounterfactualwithoutvariation
main consistent with the GPT-4o and fine-tuned theoryconditionsafter50shotsofexampleshave
GPT-3.5generationmethods. Theabsolutevalue beenlabeled. Theresultsdemonstratedtheperfor-
of pattern retention is relatively low as we over manceadvantageofourproposedneuro-symbolic
generatecounterfactualsonalltargetlabelswith- variationtheory-basedcounterfactualdataaugmen-
outcheckingwhetherthetaskitselfismeaningful. tationapproachincold-startscenariosforALtasks.GPTresultsonYELP BERTresultsonYELP
0.8 * ++ 0.8
000 ... 246 ** ** * ** ** *** ***** ** *** ** ** *** **** *** ***
** ** **
000 ... 246
** ** ***** *** ***** ** ** *** ** ** ******** ******** ** **
****** ****** ************ **** **** ***
0.0 0.0
10 15 30 50 70 90 120 10 15 30 50 70 90 120 150 170
Shots Shots
GPTresultsonMASSIVE BERTresultsonMASSIVE
0.8 0.8 * +
* * **** +
0.6 0.6 *
0.4 ****** ***
** * *
* 0.4 ***
0.2
*** *** ***
*** ***
***
0.2 ********* *** ********* *** *** ****** *********
********* ********* ********* ********* *********
0.0 0.0
10 15 30 50 70 90 120 10 15 30 50 70 90 120 150 170
Shots Shots
GPTresultsonEmotions BERTresultsonEmotions
0.8 0.8 **** **
******
0.6 0.6
****** ******
**
+
Con cd oi uti no tn
er
0.4 *** *** *** *** *** 0.4 ** * ***** ***** * *** c r u nal n ou n c ns d e Vt oe r Ttmr ainity
0.2 0.2
0.0 0.0
10 15 30 50 70 90 120 10 15 30 50 70 90 120 150 170
Shots Shots
Figure3: Experimentresultsacrossdifferentdatasetsandconditions. Shownstatisticallysignificantdifference
betweenthecounterfactualconditionandtheclustercondition. +indicatesp-value<0.1,*indicatesp-value<0.05,
**indicatesp-value<0.01,and***indicatesp-value<0.0001.
Theproposedapproachistargetedatintroducing theticdataishighlydependentofthedistribution
usefuldatatoaddressthelackoflabeldistribution of the generated data, suggesting that enhancing
andrepresentationincoldstartscenarios. However, datadiversitycouldsignificantlyimprovetheutil-
aswegetmoreannotateddata,weobserveeither ityofsyntheticdata. Ourapproachachievesthisby
minimalimprovementoradeclineinthemodel’s generatingcounterfactualexamplesalongdynamic
performance. Webelievethatthisoccursbecause neuro-symbolicboundariestoallowthesynthetic
afteracertainpoint,thegeneratedcounterfactuals data to represent underlying concepts for better
begintoreplicatepreviouslyobservedpatterns,and generalizability. Thisapproachleveragestherich-
there is a limit to the amount of information that nessofthedata’ssemanticstructure,allowingfora
canbeextractedfromthesepatterns. Wealsosee morerobustlearningprocessduringcounterfactual
similar patterns of model decline in the counter- generationbytheLLM.
factualswithoutVTcondition. Thisultimatelycan
Inourevaluation,wefindthatmodelstrainedon
havethemodeloverlyrelyonthemodel,resulting
counterfactualexampleshaveastatisticallysignifi-
intheperformancenotscaling. Toaddressthis,itis
cantadvantageintheearlystageofactivelearning,
importanttoheuristicallyunderstandtheamountof
wherethereisalimitednumberofannotateddata.
datadistributionthatcanbecapturedbygenerated
When there is only a small amount of annotated
dataandswitchgearsbacktousingrealdatawhen
dataavailable,therepresentationofalabel’sdistri-
needed.
butiondoesnotsufficientlycoverthelatentspace.
5 Discussion Theimprovementinperformancewhenusingcoun-
terfactualdatapointshighlightsthattheintroduc-
Lietal.(2023b)findthattheperformanceofsyn- tionofsystematicallygeneratedcounterfactualdata
erocs−1F
egarevA
erocs−1F
egarevA
erocs−1F
egarevA
erocs−1F
egarevA
erocs−1F
egarevA
erocs−1F
egarevAaddsthenecessaryvariabilityformodeltraining. In domains, they can be augmented by adding any
ourexperiment,boththeGPT-3.5andBERTclassi- speciallexicalrulesasnecessaryforadomain. In
ficationmodelsshowedhigherperformanceunder ourexperiments,weuseaGPT-baseddiscrimina-
thecounterfactualconditionacrossmostdatasets; torto determinethetargetlabelfor eachcounter-
however,theYELPdatasetonGPT-3.5emergedas factual example. Given that our pipeline aims to
anexceptiontothistrend(Table2). enhance human-AI interaction in active learning
Notably,theperformancebenefitofthecounter- environments, future research should investigate
factualconditionbeginstodeclinewhenmorethan howusersengagewiththesegeneratedexamples.
70labeleddatapointsareusedinmodeltraining. Ourfindingsindicatethat,whileourcounterfactual
This reduction in advantage could potentially be example selection proves beneficial in the early
attributed to model collapse. This happens when stages of active learning, designing an adaptive
themodelfailstocapturethefulldiversityofthe pipelinethatswitchesbetweenexampleselection
dataonwhichitistrained(Wangetal.,2023;Su methodsbasedontheavailablelabeleddatacould
etal.,2023). Withtheintroduceddistributionshift, beadvantageous. Furtherstudiescouldexplorethis
afterthe70shotsthreshold,themodelmightover- adaptability.
fit to the specific characteristics of the synthetic
examples it has seen, rather than generalizing to
References
thebroaderrealdatadistribution. Thiscouldlead
toadecreasedabilitytohandleneworslightlydif- NabihaAsghar.2016. Yelpdatasetchallenge: Review
ferentdatatypesintroducedinlaterstagesoftrain- ratingprediction. arXivpreprintarXiv:1605.05362.
ing. Asaresult,theperformancegainsfromusing
DanielBeck,LuciaSpecia,andTrevorCohn.2013. Re-
counterfactualexamplesnolongeraresignificant
ducing annotation effort for quality estimation via
becausethemodel’sadaptabilityiscompromised. activelearning. InProceedingsofthe51stAnnual
Identifying the optimal threshold for introducing Meeting of the Association for Computational Lin-
guistics(Volume2: ShortPapers),pages543–548.
counterfactual examples could be crucial, allow-
ingustostrategicallyadaptourtrainingapproach
SamuelBudd,EmmaCRobinson,andBernhardKainz.
basedonthenumberofannotatedrealdataavail- 2021. A survey on active learning and human-in-
able. Thisapproachcanparticularlybeapplicable the-loop deep learning for medical image analysis.
MedicalImageAnalysis,71:102062.
tohandlecoldstartproblemsinactivelearningwith
datathatrequiredomain-specific,user-specific,or
Zeming Chen, Qiyue Gao, Antoine Bosselut, Ashish
ambiguousannotation. Sabharwal,andKyleRichardson.2023. Disco: Dis-
Activelearningreliesonhuman-annotateddata. tilling counterfactuals with large language models.
In Proceedings of the 61st Annual Meeting of the
Therefore,whenconsideringtheintegrationofsyn-
AssociationforComputationalLinguistics(Volume
theticdata,itisimportanttofactorintheadditional
1: LongPapers),pages5514–5528.
annotationcosts. Inourapproach,weapplyhuman
learning theories to generate counterfactual data Wai Lun Eddie Cheng. 2016. Learning through the
variation theory: A case study. The International
points that could potentially simplify the cogni-
JournalofTeachingandLearninginHigherEduca-
tiveloadofannotation. Specifically,thegenerated
tion,28:283–292.
counterfactualdatapointsarestructurallysimilar
to their original counterpart and only vary along Emily Denton, Ben Hutchinson, Margaret Mitchell,
Timnit Gebru, and Andrew Zaldivar. 2020. Image
distinctdimensions. Infuturework,ouraimisto
counterfactualsensitivityanalysisfordetectingunin-
evaluatethisthroughaninteractiveprocessinvolv-
tendedbias.
inghumans.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
KristinaToutanova.2018. Bert: Pre-trainingofdeep
6 LimitationsandFuturework
bidirectionaltransformersforlanguageunderstand-
ing. arXivpreprintarXiv:1810.04805.
Our neuro-symbolic pipeline facilitates the auto-
matic,real-timecreationofcounterfactualdataus- NidulaElgiriyewithana.2024. EmotionsDataset.
ing a pattern-based program synthesis approach.
Jack FitzGerald, Christopher Hench, Charith Peris,
Thismethoddefinestheconceptspacevarieddur-
ScottMackie,KayRottmann,AnaSanchez,Aaron
ingcounterfactualgeneration. Althoughthecurrent
Nash,LiamUrbach,VisheshKakarala,RichaSingh,
pattern building blocks are designed for general Swetha Ranganath, Laurie Crist, Misha Britan,Wouter Leeuwis, Gokhan Tur, and Prem Natara- AlisaLiu,SwabhaSwayamdipta,NoahA.Smith,and
jan. 2022. Massive: A 1m-example multilin- YejinChoi.2022. WANLI:WorkerandAIcollabora-
gualnaturallanguageunderstandingdatasetwith51 tionfornaturallanguageinferencedatasetcreation.
typologically-diverselanguages. In Findings of the Association for Computational
Linguistics: EMNLP2022,pages6826–6847,Abu
TeodorFredriksson,DavidIssaMattos,JanBosch,and Dhabi,UnitedArabEmirates.AssociationforCom-
HelenaHolmströmOlsson.2020. Datalabeling: An putationalLinguistics.
empiricalinvestigationintoindustrialchallengesand
mitigation strategies. In International Conference QiLiu,MattKusner,andPhilBlunsom.2021. Counter-
onProduct-FocusedSoftwareProcessImprovement, factualdataaugmentationforneuralmachinetrans-
pages202–216.Springer. lation. In Proceedings of the 2021 Conference of
theNorthAmericanChapteroftheAssociationfor
SimretArayaGebreegziabher,ZhengZhang,Xiaohang
ComputationalLinguistics: HumanLanguageTech-
Tang, Yihao Meng, Elena L. Glassman, and Toby
nologies, pages 187–197, Online. Association for
Jia-JunLi.2023. Patat: Human-aicollaborativequal-
ComputationalLinguistics.
itativecodingwithexplainableinteractiverulesyn-
thesis. InProceedingsofthe2023CHIConference FerenceMarton.2014. Necessaryconditionsoflearn-
onHumanFactorsinComputingSystems,CHI’23, ing. Routledge.
New York, NY, USA. Association for Computing
Machinery. FerenceMartonandShirleyABooth.1997. Learning
andawareness. psychologypress.
AbbasGhaddar,PhilippeLanglais,AhmadRashid,and
MehdiRezagholizadeh.2021. Context-awareAdver- SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,
sarialTrainingforNameRegularityBiasinNamed MikeLewis,HannanehHajishirzi,andLukeZettle-
EntityRecognition. TransactionsoftheAssociation moyer.2022. Rethinkingtheroleofdemonstrations:
forComputationalLinguistics,9:586–604. Whatmakesin-contextlearningwork? InProceed-
ingsofthe2022ConferenceonEmpiricalMethodsin
TamaraGogandNikolRummel.2010. Example-based NaturalLanguageProcessing,pages11048–11064,
learning: Integratingcognitiveandsocial-cognitive AbuDhabi,UnitedArabEmirates.Associationfor
researchperspectives. EducationalPsychologyRe- ComputationalLinguistics.
view,22:155–174.
Abbavaram Gowtham Reddy, Saketh Bachu, Saloni
Sumit Gulwani. 2011. Automating string processing
Dash,CharchitSharma,AmitSharma,andVineethN
inspreadsheetsusinginput-outputexamples. ACM
Balasubramanian.2023. Rethinkingcounterfactual
SigplanNotices,46(1):317–330.
dataaugmentationunderconfounding.
NitishJoshiandHeHe.2022. Aninvestigationofthe
NorbertMSeel.2011. EncyclopediaoftheSciencesof
(in)effectivenessofcounterfactuallyaugmenteddata.
Learning. Springer.
DivyanshKaushik,EduardHovy,andZacharyLipton.
BurrSettles.2009. Activelearningliteraturesurvey.
2020. Learning the difference that makes a differ-
encewithcounterfactually-augmenteddata. InInter- YiSu,YixinJi,JuntaoLi,HaiYe,andMinZhang.2023.
nationalConferenceonLearningRepresentations.
Bewareofmodelcollapse! fastandstabletest-time
adaptation for robust question answering. In The
Divyansh Kaushik, Amrith Setlur, Eduard Hovy, and
2023ConferenceonEmpiricalMethodsinNatural
ZacharyC.Lipton.2021. Explainingtheefficacyof
LanguageProcessing.
counterfactuallyaugmenteddata.
Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen,
YongqiLi,MayiXu,XinMiao,ShenZhou,andTieyun
Runkai Zheng, Yidong Wang, Linyi Yang, Hao-
Qian.2023a. Largelanguagemodelsascounterfac-
jun Huang, Wei Ye, Xiubo Geng, et al. 2023.
tualgenerator: Strengthsandweaknesses.
On the robustness of chatgpt: An adversarial
Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming andout-of-distributionperspective. arXivpreprint
Yin. 2023b. Synthetic data generation with large arXiv:2302.12095.
languagemodelsfortextclassification: Potentialand
Zhao Wang and Aron Culotta. 2020. Robustness to
limitations. arXivpreprintarXiv:2310.07849.
spuriouscorrelationsintextclassificationviaauto-
Henry Lieberman. 2001. Your wish is my command: maticallygeneratedcounterfactuals.
Programmingbyexample. MorganKaufmann.
Linyi Yang, Jiazheng Li, Pádraig Cunningham, Yue
StephanieLin,JacobHilton,andOwainEvans.2022. Zhang,BarrySmyth,andRuihaiDong.2022a. Ex-
Teaching models to express their uncertainty in ploringtheefficacyofautomaticallygeneratedcoun-
words. arXivpreprintarXiv:2205.14334. terfactualsforsentimentanalysis.
MunLingLo.2012. Variationtheoryandtheimprove- Suorong Yang, Weikang Xiao, Mengcheng Zhang,
mentofteachingandlearning. Göteborg: ActaUni- SuhanGuo,JianZhao,andFuraoShen.2022b. Im-
versitatisGothoburgensis. agedataaugmentationfordeeplearning: Asurvey.Michelle Yuan, Hsuan-Tien Lin, and Jordan Boyd-
Graber. 2020. Cold-start active learning through
self-supervisedlanguagemodeling. arXivpreprint
arXiv:2010.09535.
Yong Zhang and Meng Joo Er. 2016. Sequential ac-
tivelearningusingmeta-cognitiveextremelearning
machine. Neurocomputing,173:835–844.Make small changes to the conversation to change the topic label, Separate the given multi-labeled sentences into different parts, but not to change the given pattern.
each part corresponds to a label and a pattern.
The patterns can be composed with AND (+) or OR (|) operators
The pattern language consists of the following syntax:
New content should be in the format: 'text' + 'pattern' + 'label';
Part-of-speech (POS) tags: VERB, PROPN, NOUN, ADJ, ADV, AUX, 'text' + 'pattern' + 'label’. PRON, NUM
All the text, patterns and labels are already given as input, if
Word stemming: [WORD] (e.g., [have] will match all variants of
there is no corresponding pattern, just use '' to indicate empty.
have, such as had, has, and having)
Make sure each separated sentence only has a single label but Soft match: (word) (e.g., (pricey) will match synonyms such as
mayrelate to severalpatterns.
expensive and costly, etc.)
Entity type: $ENT-TYPE (e.g., $LOCATION will match phrases of
location type; $ORG will match names of organizations)
Wildcard: * (will match any sequence of words)
Conversation: "Friendly w / great customer service, reasonable
prices, and a chill atmosphere."
Pattern: (customer)+*+[service], (pay)|(sale) Conversation: "Our bill was around $ 400 -it was upsetting that
Label: price, service, environment they decided to be stingy about a $ 8 piece of cake."
Pattern: $MONEY|(price); Original label: price; Target: service
'Friendly w / great customer service, ' + '(customer)+*+[service]'
+ 'service'; ‘reasonable prices, ' + '(pay)|(sale)' + 'price'; 'and a Our bill was around $ 400 -the service was upsetting as they
chill atmosphere.' + '' + 'environment' decided to be stingy about a $ 8 piece of cake.
Step1: separatemulti-labeledtext
Step2: generatepattern-keptcounterfactualtext
Figure4:IllustrationofLLMpromptsusedforpreparingtrainingdatapointsandgeneratingcounterfactualdatapoints
A Appendix • {“role”: “user”,“content”: “Conversation: Greatcus-
tomerservice,reasonableprices,andachillatmosphere.
A.1 GenerationPipeline Pattern:[‘(customer)+*+[service]’,‘(pay)|(sale)’,‘(en-
vironment)’]Label:price,service,environment”}
In this section, we provide the details of all the
promptsandmodelsweusetoconstructthewhole • {“role": “assistant",“content": “‘Greatcustomerser-
vice,’+‘(customer)+*+[service]’+‘service’;‘reason-
counterfactualgenerationpipeline.
able prices, ’ + ‘(pay)|(sale)’ + ‘price’; ‘and a chill
atmosphere.’+‘(environment)’+‘environment’”}
A.1.1 GPT-3.5Multi-labelSeparator
• {“role”:“user”,“content”:“Conversation:{text}Pat-
As shown in Fig. 4 Step-1, we utilize zero-shot
tern:{pattern}Label:{label}”}
GPT-4topreprocesstherawdata,inordertosep-
arate the given multi-labeled sentences into sev- A.1.2 GPT-4oCandidatePhrasesGenerator
eral single-labeled parts. We call GPT-4 through As we are generating counterfactuals that keeps neuro-
symbolic patterns, the first step of this task is to generate
theAPIprovidedbyOpenAI,setthetemperature
candidatephrasesthatkeepthepatternbutvariatesemanti-
parameter to 0 and restrict the maximum token cally,whichmakeupcrucialbranchesofgeneratedcounter-
number to 512, which ensures the reliability of factualvariations.Forthispart,wecallGPT-4othroughthe
APIprovidedbyOpenAI,setthetemperatureparameterto0
the generated results. The prompt used is shown
andrestrictthemaximumtokennumberto256.Theprompt
below: usedisshownbelow:
• {“role”:“system”,“content”:“Theassistantwillcreate
• {“role”: “system”,“content”: “Theassistantwillsep-
alistofphrasesthatmatchthegivendomainspecific
arate the given multi-labeled sentences into different
languagebasedonthegivendefinition.”}
parts,eachcorrespondstoalabelandapattern(ifthe
patternisviable)”}
• {“role”: “user”, “content”: “For the following text
andpattern,generateasmanydiverseexamplephrases
• {“role": “user", “content": “The assistant will make
that match the given pattern and can be part of the
conversations based on the following example. New
giventargetlabel. Trytonotusetheword{label}or
content should be in the format: ‘text’ + ‘pattern’ +
{target_label}inthephrasesyougenerate.Separated
‘label’;‘text’+‘pattern’+‘label’.Allthetext,patterns
youranswerbyacomma”}
and labels are already given as input, if there is no
correspondingpattern,justuse”toindicateempty.”}
• {“role”:“user”,“content”:“text:{matched_phrase},
pattern:{pattern},currentlabel:{label}targetlabel:
• {“role”: “user”,“content”: “Eachseparatedtextmust
{target_label}”}
onlyhaveasinglelabel,butmaycontainseveralpat-
terns. Eachlabelorpatternmustappearatleastonce
• {“role”:“user”,“content”:“Theword‘{match}‘isa
inthecompletion.Thepatternscanbecomposedwith
softmatch,youcanonlyuse{soft-match_words}as
AND(+)orOR(|)operators.”}
itssynonymstoreplaceit.Youcannotuseotherwords
for{match}”}
ksaT
snoitcurtsnI
tupnI
tuptuO
ksaT
noitanalpxE
tpecnoC
tupnI
tuptuOA.1.3 GPT-4oCounterfactualGenerator
TheGPT-4ogeneratorwillfinishthesecondstepofcounter-
factualgeneration,makinguseofcandidatephrasesgenerated
inthefirststepandcombiningthesesemanticpiecesintorea-
sonablesentences.Wesetthetemperatureparameterto0and
restrictthemaximumtokennumberto256.Thepromptused
isshownbelow:
• {“role”:“system”,“content”:“Theassistantwillgener-
ateacounterfactualexampleclosetotheoriginalsen-
tencethatcontainsoneofthegivenphrases.”}
• {“role”:“user”,“content”:“Yourtaskistochangethe
givensentencefromthecurrentlabeltothetarget.
Forexample: ‘Findmeatrainticketnextmondayto
new york city’ with original label “transport” would
beturnedto‘PlaymeasongcalledNewYorkCityby
TaylorSwift’withalabel“audio”.
Youcanusethefollowingphrasestohelpyougenerate
the counterfactuals. Please make the sentence about
{target_label}. Make sure that the new sentence is
not about {label}. You must use one of the follow-
ingphraseswithoutrewordingitinthenewsentence:
{generated_phrases}”}
• {“role”: “user”, “content”: “You must follow three
criteria:
criteria 1: the phrase should change the label from
{label}to{target_label}tothehighestdegree.
criteria2:themodifiedsentencecannotalsobeabout
{label}andmakesuretheword{target_label}isnot
partofthemodifiedsentence.
criteria3: themodifiedsentenceshouldbegrammati-
callycorrect.”}
• {“role”:“user”,“content”:“Ifyoufindthatyoucannot
generatenewsentencethatfulfillalltherequirements
above, justresponse ‘cannotgeneratecounterfactual’
anddon’tfeelbadaboutthis”}
• {“role”:“user”,“content”:“originaltext:{text},origi-
nallabel:{label},modifiedlabel:{target_label},gener-
atedphrases:{generated_phrases},modifiedtext:”}
A.2 ExperimentResults[YELP]MacroF1-scores(GPT-3.5)
No.shots 10 15 30 50 70 90 120
Random 0.38∗∗∗ 0.44∗∗∗ 0.51∗∗∗ 0.61 0.65 0.69+ 0.74
SD 0.05 0.06 0.07 0.05 0.06 0.04 0.04
Cluster 0.41∗∗∗ 0.48∗∗∗ 0.57 0.63 0.68∗ 0.69+ 0.70
SD 0.07 0.04 0.07 0.06 0.03 0.03 0.02
Uncertainity 0.23∗∗∗ 0.21∗∗∗ 0.27∗∗∗ 0.28∗∗∗ 0.29∗∗∗ 0.28∗∗∗ 0.29
SD 0.04 0.05 0.06 0.05 0.04 0.06 0.05
CounterfactualswithoutVT 0.35∗∗∗ 0.46∗ 0.54∗ 0.53∗ 0.39∗∗∗ 0.25∗∗∗ -
SD 0.10 0.13 0.05 0.06 0.08 0.05 -
Counterfactuals 0.53 0.60 0.62 0.61 0.59 0.62 -
SD 0.08 0.07 0.07 0.07 0.10 0.05 -
[YELP]MacroF1-scores(BERT)
No.shots 10 15 30 50 70 90 120 150 170
Random 0.16∗ 0.18∗∗∗ 0.26∗∗∗ 0.33∗∗∗ 0.35∗∗∗ 0.45 0.45 0.48 0.51
SD 0.06 0.05 0.03 0.04 0.06 0.01 0.03 0.04 0.02
Cluster 0.18∗∗∗ 0.19∗∗∗ 0.26∗∗∗ 0.32∗∗∗ 0.34+ 0.46 0.31 0.42 0.45
SD 0.08 0.06 0.07 0.06 0.05 0.03 0.08 0.1 0.1
Uncertainty 0.13 0.14 0.19 0.33 0.41 0.46 0.47 0.53 0.54
SD 0.06 0.04 0.07 0.04 0.06 0.03 0.04 0.04 0.05
CounterfactualswithoutVT 0.20 0.16 0.25 0.29 0.38 0.45 0.49 0.54 0.55
SD 0.06 0.07 0.04 0.04 0.08 0.05 0.04 0.05 0.04
Counterfactuals 0.38 0.39 0.49 0.47 0.51 0.53 0.50 0.52 0.53
SD 0.04 0.07 0.05 0.04 0.04 0.04 0.03 0.02 0.03
Table2: AverageF1-scorewithincreasingnumbersofannotations(shots)andthestandarddeviations(SD)across
8independentexperimentsusingafewshotpromptingwithOpenAI’sGPT-3.5andfine-tunedBERTmodelfor
classificationonYELPdataset. +indicatesp-value<0.1,*indicatesp-value<0.05,**indicatesp-value<0.01,and
***showsp-value<0.0001betweentheconditionandthecounterfactualcondition.[MASSIVE]MacroF1-scores(GPT-3.5)
No.shots 10 15 30 50 70 90 120
Random 0.36∗∗∗ 0.40∗ 0.49 0.51 0.54∗ 0.57∗∗∗ 0.61
SD 0.06 0.05 0.12 0.11 0.10 0.09 0.10
Cluster 0.35∗∗∗ 0.40∗ 0.47 0.49 0.56∗ 0.54∗ 0.55
SD 0.06 0.07 0.08 0.08 0.12 0.12 0.09
Uncertainty 0.22∗∗∗ 0.19∗∗∗ 0.18∗∗∗ 0.13∗∗∗ 0.14∗∗∗ 0.19∗∗∗ 0.20
SD 0.08 0.1 0.07 0.06 0.07 0.09 0.1
CounterfactualswithoutVT 0.28∗∗∗ 0.38∗ 0.43∗ 0.40 0.33 0.27∗ -
SD 0.10 0.07 0.05 0.07 0.10 0.09 -
Counterfactuals 0.48 0.49 0.51 0.47 0.38 0.40 -
SD 0.05 0.11 0.12 0.10 0.10 0.09 -
[MASSIVE]MacroF1-scores(BERT)
No.shots 10 15 30 50 70 90 120 150 170
Random 0.048∗∗∗ 0.052∗∗∗ 0.12∗∗∗ 0.11∗∗∗ 0.19∗∗∗ 0.22∗∗∗ 0.23∗∗∗ 0.24∗∗∗ 0.25*
SD 0.03 0.03 0.04 0.05 0.03 0.02 0.02 0.02 0.02
Cluster 0.046∗∗∗ 0.058∗∗∗ 0.091∗∗∗ 0.13∗∗∗ 0.18∗∗∗ 0.20∗∗∗ 0.23∗∗∗ 0.24∗∗∗ 0.25
SD 0.01 0.04 0.03 0.04 0.04 0.03 0.02 0.02 0.02
Uncertainty 0.029∗∗∗ 0.035∗∗∗ 0.11∗∗∗ 0.14∗∗∗ 0.22∗∗∗ 0.23∗∗∗ 0.24∗∗∗ 0.25∗∗∗ 0.25∗∗∗
SD 0.02 0.02 0.04 0.03 0.02 0.03 0.03 0.03 0.02
CounterfactualswithoutVT 0.09∗∗∗ 0.15∗∗∗ 0.33∗∗∗ 0.50∗ 0.61+ 0.64 0.68∗ 0.68 0.69+
SD 0.08 0.07 0.08 0.07 0.05 0.04 0.04 0.04 0.03
Counterfactuals 0.33 0.40 0.51 0.58 0.56 0.60 0.61 0.66 0.62
SD 0.09 0.07 0.08 0.06 0.05 0.09 0.06 0.05 0.1
Table3: AverageF1-scorewithincreasingnumbersofannotations(shots)andthestandarddeviations(SD)across8
independentexperimentsusingafewshotpromptingwithOpenAI’sGPT-3.5andaBERTmodelforclassification
ontheMASSIVEdataset. +indicatesp-value<0.1,*indicatesp-value<0.05,**indicatesp-value<0.01,and***
showsp-value<0.0001betweentheconditionandthecounterfactualcondition.[Emotions]MacroF1-scores(GPT-3.5)
No.shots 10 15 30 50 70 90 120
Random 0.29 0.32 0.36∗∗∗ 0.39∗∗∗ 0.45∗ 0.45 0.47
SD 0.1 0.1 0.07 0.04 0.04 0.06 0.04
Cluster 0.32 0.38 0.36∗∗∗ 0.39∗∗∗ 0.42∗ 0.42 0.41
SD 0.04 0.04 0.08 0.12 0.09 0.08 0.05
Uncertainty 0.21∗∗∗ 0.19∗∗∗ 0.25∗∗∗ 0.29∗∗∗ 0.28∗∗∗ 0.29 0.33
SD 0.07 0.05 0.05 0.04 0.07 0.06 0.05
CounterfactualswithoutVT 0.28 0.37 0.49 0.51 0.50 - -
SD 0.09 0.13 0.12 0.13 0.12 - -
Counterfactuals 0.34 0.43 0.54 0.51 0.59 - -
SD 0.08 0.1 0.1 0.05 0.1 - -
[Emotions]MacroF1-scores(BERT)
No.shots 10 15 30 50 70 90 120 150 170
Random 0.19∗ 0.20∗∗∗ 0.24∗ 0.31 0.46 0.47 0.53 0.63 0.30
SD 0.04 0.03 0.08 0.12 0.09 0.09 0.14 0.07 0.06
Cluster 0.18∗ 0.21∗ 0.23∗∗∗ 0.28∗ 0.41 0.43 0.48 0.59 0.52
SD 0.02 0.03 0.02 0.03 0.05 0.08 0.06 0.05 0.12
Uncertainty 0.23∗∗∗ 0.23 0.26∗ 0.35 0.38+ 0.57∗∗∗ 0.66∗∗∗ 0.69 0.70∗
SD 0.04 0.05 0.08 0.05 0.04 0.07 0.08 0.07 0.06
CounterfactualswithoutVT 0.18∗ 0.21∗ 0.32 0.36 0.40 0.57∗∗∗ 0.62 0.62 0.72∗
SD 0.05 0.05 0.09 0.12 0.13 0.08 0.1 0.2 0.05
Counterfactuals 0.27 0.26 0.36 0.38 0.49 0.45 0.50 0.63 0.56
SD 0.07 0.09 0.05 0.12 0.05 0.15 0.06 0.06 0.07
Table4: AverageF1-scorewithincreasingnumbersofannotations(shots)andthestandarddeviations(SD)across8
independentexperimentsusingafewshotpromptingwithOpenAI’sGPT-3.5andaBERTmodelforclassification
ontheemotionsdataset. Wearelimitedto90shotsforthefirsttwoconditionsand50shotsforthecounterfactual
condition when using GPT-3.5, due to token limitations. + indicates p-value<0.1, * indicates p-value<0.05, **
indicatesp-value<0.01,and***showsp-value<0.0001betweentheconditionandthecounterfactualcondition.NoofShots 10 15 30 50 70 90 120
NoFilters 0.10 0.12 0.15 0.23 0.23 0.21 0.21
SD
0.03 0.04 0.05 0.04 0.04 0.03 0.03
HerusticFilter 0.15 0.17 0.19 0.28 0.27 0.28 0.28
SD
0.08 0.1 0.1 0.07 0.09 0.1 0.1
Herustic+SymbolicFilters 0.12 0.13 0.13 0.17 0.16 0.18 0.20
SD
0.04 0.03 0.01 0.02 0.03 0.02 0.01
AllFilters 0.38 0.39 0.49 0.47 0.51 0.53 0.50
SD
0.04 0.08 0.06 0.04 0.05 0.05 0.04
Table5: AverageF1-scoreandSDfromanablationstudywiththeYELPdatasetonBERTmodel
A.3 CounterfactualFilteringMethods model.Theablationstudyisconductedusingoneofthethree
datasets,YELP,withtheBERTmodel.Theresultsshowthat
Todeterminethesignificanceofvariouscomponentsinour
the counterfactual examples with all filters have 2X better
pipeline,weperformanablationstudy.Wefollowthesame
performanceindownstreamactivelearningtaskscompared
approachas§4.3whereeachconditionisrunwithdifferent
tomethodsthatdonotemploythefilters(p<0.0001). This
seeds 8-times and we report the average F1-score and the
showsthevalueofcarefullyfilteringthroughLLMgenerated
standarddeviationoftheresultsinTable5.Ourbaselineap-
counterfactulstomakeusabledataformodeltraining.
proachinvolvesgeneratingcounterexampleswithafine-tuned
GPT-3.5modelandapplyingallthreefiltersdefinedin§3.2
beforeusingthedataforactivelearning.Inthisstudy,wevary
thegeneratormodelbetweenthefine-tunedGPT-3.5andthe
off-the-shelfGPT-4omodel,andwealsoevaluatetheimpact
ofincludingorexcludingeachfilterwhenusingtheGPT-3.5