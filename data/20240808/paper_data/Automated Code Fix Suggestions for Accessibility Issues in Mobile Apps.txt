Automated Code Fix Suggestions for
Accessibility Issues in Mobile Apps
Forough Mehralian Titus Barik Jeff Nichols Amanda Swearngin
Apple Apple Apple Apple
Seattle, USA Seattle, USA Seattle, USA Seattle, USA
mehralian@apple.com tbarik@apple.com jwnichols@apple.com aswearngin@apple.com
Abstract—Accessibility is crucial for inclusive app According to documentation, Accessibility Inspector re-
usability, yet developers often struggle to identify and ports 7 categories of issues [10], and these single-purpose
fix app accessibility issues due to a lack of awareness, approaches can fix only a small subset.
expertise, and inadequate tools. Current accessibility To bridge this gap in tooling between single-purpose fix
testing tools can identify accessibility issues but may
approaches and source code, we investigate an automated
not always provide guidance on how to address them.
We introduce FixAlly, an automated tool designed plan-localize-fix technique—implemented as a tool called
to suggest source code fixes for accessibility issues FixAlly—to fix various types of accessibility issues re-
detected by automated accessibility scanners. FixAlly portedbyscannerssuchastheAccessibilityInspector[10].
employsamulti-agentLLMarchitecturetogeneratefix To understand the challenges of fixing issues detected by
strategies, localize issues within the source code, and
accessibility scanners in source code, we first conducted
propose code modification suggestions to fix the acces-
formative interviews with five developers. Our develop-
sibility issue. Our empirical study demonstrates Fix-
Ally’s capability in suggesting fixes that resolve issues ers indicated that: 1) multiple strategies can address a
found by accessibility scanners—with an effectiveness single issue, 2) appropriate fixes must consider not only
of77%ingeneratingplausiblefixsuggestions—andour accessibility guidelines, but also the integrity of the app’s
surveyof12iOSdevelopersfindstheywouldbewilling
design and functionality, 3) implementing a fix frequently
to accept 69.4% of evaluated fix suggestions.
requires modifications beyond the problematic element,
Index Terms—accessibility, automated, repair, mo-
bile, llm and 4) identifying these relevant locations in the code to
apply fixes is the most time-consuming step.
I. Introduction
To address these needs, FixAlly employs a multi-
The increasing reliance on mobile apps for everyday agent LLM architecture capable of proposing plausible fix
tasks underscores the necessity of ensuring accessibility suggestionsforissuesreportedbyanaccessibilityscanner.
for all. Despite the existence of guidelines aimed at as- In this context, a plausible fix is defined as a modification
sisting developers in creating more accessible apps [1]– thatpassestheaccessibilitychecksoftheautomatedscan-
[3], research shows that many apps are still released ner for the target issue without introducing new ones or
withnumerousaccessibilityissues[4]–[7].Developersoften removing functionality. FixAlly analyzes an open-source
struggle with building accessible apps because they lack mobile app to detect various accessibility issues. FixAlly
awareness of accessibility requirements [4] or have limited localizes issues within the source code and proposes fix
knowledge and expertise in effectively addressing accessi- suggestions to resolve the issue using a suggestion genera-
bility issues [8]. tion engine. Each proposed fix suggestion aims to resolve
Existingaccessibilityscanningtools—suchasAccessibil- the targeted accessibility issue without introducing new
ityScanner[9]forAndroidandAccessibilityInspector[10] ones or compromising app functionalities. FixAlly also
for iOS—helpfully verify compliance of each app screen assists the developer in the decision-making process to
withrulesderivedfromaccessibilityguidelines.Inaddition select the strategy that best aligns with the app’s design
to these rule-based techniques, some automated tools dy- and requirements.
namicallyexamineappsusingassistivetechnologiestode- The contributions of this paper are:
tectissuesthatmanifestduringreal-timeinteractions[11], A novel plan-localize-fix technique—operationalized
•
[12]. However, current tools provide insufficient support as an automated tool using a multi-agent LLM
for maintaining app accessibility [8] because fixing the architecture—that generates code suggestions to fix
large number of issues reported by these tools remains accessibility issues in mobile apps.
a significant challenge. While single-issue fix techniques An empirical evaluation on 205 issues from 14 iOS
•
address problems like color issues [13], missing labels [14], apps built using SwiftUI, a declarative framework
text scaling problems [15], and touch target size [16], that allows developers to define the desired UI at-
these single-issue fix techniques have notable limitations. tributes and behavior [17]. Our evaluation demon-
4202
guA
7
]ES.sc[
1v72830.8042:viXrastrategies to address such issues, such as adjusting back-
ground colors, modifying text colors, or increasing font
struct ThemePicker: View {
@Binding var selection: Theme sizes. However, these strategies cannot be applied in the
var body: some View {
Picker("Theme", selection: $selection) { provided code snippet that demonstrates the element’s
ForEach(Theme.allCases) { theme in
ThemeView(theme: theme) implementation. Instead, the appropriate place to adjust
.tag(theme)
} the color for this element is within the ThemeView called
}
.pickerStyle(.navigationLink)
} from the ThemePicker (Figure 2). Locating this correct
}
position necessitates navigating through the UI hierarchy,
Fig.1. ImplementationofadropdownlistinSwiftUI. understanding the semantics of the GUI, and compre-
hending the structure of the source code required for
implementing these elements. This complexity has made
struct ThemeView: View {
let theme: Theme localization a challenging task.
var body: some View {
III. Formative Study
Text(theme.name)
.padding(4)
Internal uTse onoly–do neot ldisitricbutei.ttheprocessdevelopersfollowtofixaccessibility
.frame(maxWidth: .infinity)
.background(theme.mainColor) bugs found by an accessibility scanner in iOS apps, we
.foregroundColor(theme.accentColor) conducted formative interviews with five iOS app devel-
.clipShape(RoundedRectangle(cornerRadius: 4))
} opers in our company. The developers had at least 1 year
} of experience in developing SwiftUI apps and median of
intermediate accessibility familiarity (1 – No Experience
Fig.2. Localizationofthecolorcontrastissueinthesourcecode.
to 5 – Expert). During the study, the developers used
the Accessibility Inspector and Xcode to detect issues in
stratesaneffectivenessof77%of FixAllyinpropos- the Landmarks app1 running on an iOS simulator. We
ing plausible fix suggestions for accessibility issues. asked them to think-aloud while they detected and fixed
A survey of 12 iOS app developers, finding the tool as many issues as they could within 1 hour. At the end,
•
was most helpful for less experienced developers in weaskedthemfollow-upquestionsabouttheirexperiences
allowing them to explore multiple solutions when and their ideas on any tools that could improve their
resolving accessibility bugs. Even experienced devel- process in finding and fixing the accessibility issues. All
opers found it helpful that FixAlly localized the sessionstookplacevirtuallyoverWebex.Somedevelopers
issue in the code. built and tested the app locally while sharing their screen
and some developers remotely controlled the screen of the
II. Background: Comparing Android and iOS
lead researcher who also had the app and simulator built
Many of the existing approaches focus on Android and running in Xcode. A second researcher observed and
applications which require different techniques than iOS tooknotesforfouroutoffivesessions.Werecordedaudio,
applications. Declarative programming languages, such as video, and notes for each session.
SwiftUI, represent a contemporary paradigm for building To analyze the data, we annotated the transcripts and
GUIs in mobile apps by enabling developers to define built an affinity diagram [18] where one paper author led
the desired UI and its behavior using concise syntax. the annotation and initial grouping, and another author
Figure 1 illustrates how a dropdown list is implemented read and also validated the themes.
in SwiftUI. This approach contrasts with traditional im- 1) Accessibility Bug Fixing Phases: We examined the
perative methods, where developers must meticulously developers’ overall process in fixing the accessibility bugs
specifyattributesofeachUIelementandmanageitsstate. with two goals: first, understanding the varied activities
For example, in Android, the UI specification is defined (e.g., localizing an issue, fixing it in the code) within the
using an XML file, with Java classes binding behavior to whole process, and second, understanding inefficiencies
each element. Developers can also modify UI attributes within each of those activities where an automated tool
dynamicallythroughspecifiedbehaviorindeclarativelan- could help. We found that developers accessibility bug
guages. Therefore, properly locating GUI problems in the fixing workflow can be grouped into the following phases:
project cannot be effectively achieved through analysis or hypothesis formation & fix planning, localization, and code
modification of the static GUI specification alone. The editing and validation. We ultimately designed the archi-
dynamicspecificationofUIattributes,whichisthecoreof tecture of FixAlly around these three phases.
declarative programming languages, introduces additional Hypothesisformationandfixplanning: Alldevelopersin
challengesinidentifyingGUIproblems,suchasaccessibil- ourstudyhadatleastintermediateaccessibilityknowledge
ity issues, within the source code. and could understand the issues reported by Accessibility
Consider the color contrast failure issue for the an- Inspector. They were all able to propose hypotheses to
notated dropdown list in Figure 1, as reported by Ac-
cessibility Inspector. Developers typically employ various 1https://github.com/pd95/SwiftUI-Landmarksdiagnose one or more issues, and come up with a high different heuristics to localize the issue, including search-
level plan to fix one or more of them. In some cases, ing for textual elements, mapping their mental model of
developers directly proposed a fix plan for some issues elements in the screenshots to the UI structure in the
because they were already highly familiar with the issue code,lookingforspecificaccessibilityattributestheywere
and could quickly come up with the fix. In other cases, planning to modify, or combinations of these approaches.
developers mentioned multiple hypotheses that the issue Thus a key goal of FixAlly is to automatically localize
could be related to, and validated which to test after potentialfixlocationsincodefordetectedissuestoremove
localizing the impacted UI element in the source code. this inefficiency and also generate fix suggestions in the
Localization: The output of Accessibility Inspector, and form of patches so they can be applied automatically.
typically other accessibility scanners, is a screenshot high- Design Goal 2 – Provide multiple fix suggestions for an
lighting the impacted UI element and the ability to issue: Somedevelopersstruggledtocomeupwithhypoth-
highlight the element with the issue on a live device. esis for fixes, and even if they had a plausible hypothesis,
While these tools provide some metadata and inspectors some did not know how to make the corresponding code
to examine the running app’s hierarchy, they provide changes to test it. Furthermore, some issues often can be
little help with localizing UI elements in code. In our fixed in multiple ways. For example, contrast issues can
study, developers used a variety of methods to localize be fixed by increasing text font size, or changing the color
UI elements in the code including searching for specific of UI elements or background. Developers noted other
text strings found in the interface. Others tried to match considerations and potential side effects in choosing a
the visual hierarchy in the interface with the hierarchy of correctfixincludingconsultingwithdesignteams,support
views in the source files by looking at them one by one. for other languages, and impact on the layout of other
Sometimes they also looked for specific SwiftUI modifiers areas of the screen or the application. Some developers
in the code based on their hypothesis, or examined the also struggled to understand some issues reported by
viewhierarchyintheaccessibilityinspectorforclassnames Accessibility Inspector, and requested better suggestions
ormetadatatheycouldsearchfor.Localizationwaswhere more contextualized and specific to their code. To help
theypredominantlyspentthemosttimeduringthestudy. developers in understanding each suggested fix, FixAlly
Code editing and validation: After fix planning and also includes information about the model’s fix plan and
localization,developersappliedtheirfixtothecode.They reasoning along with each generated fix suggestion.
then re-ran the Accessibility Inspector audit on the same
IV. Approach
screen again to confirm the issue was resolved. If the issue
was not resolved, they could repeat the overall process as Figure 3 shows an overview of FixAlly, with its three
long as time allowed. main modules: Data Processing, Suggestion Generation
Developers did not necessarily complete the bug fixing Engine, and Suggestion Assessment.
phases in the same order. In all cases, developers either FixAlly takes as input an app with GUI tests, each
localized or came up with a hypothesis or fix plan first. designed to navigate to different screens of the app. The
Some developers first attempted to localize a UI element XCTestframework[19],integratedintoXcodeIDE,allows
in the source code before coming up with a hypothesis or iOS developers to create automated test scenarios that
fix plan, while others first described a hypothesis or fix navigate the app to the screens targeted for accessibility
plan before attempting to localize the UI element. Some assessment.Additionally,existingautomatedappcrawlers
developers repeated this process multiple times before canhelpdevelopersgeneratethesetestscenariosautomat-
confirming the fix by validating it no longer appeared in ically. These crawlers either perform random actions on
the Accessibility Inspector. the screen [20] or analyze UI elements to systematically
2) DesignGoals: Attheclosingofthesession,weasked explore all possible actions on those elements [21].
the developers to describe their overall process for fixing Automated testing frameworks recommend that devel-
the accessibility issues, and to provide feedback on any opers use unique identifiers for each element, serving as
tools that could expedite their process. We then formu- a bridge between testing frameworks and apps. To ensure
lated list of design goals that we incorporated into our everyUIelementisassociatedwithanidentifier,theData
system.Thedesigngoalsweremotivatedbythechallenges Processing module statically analyzes the source code, re-
developers faced throughout the accessibility bux fixing stores the UI hierarchy, and instruments the app to insert
process and suggestions they provided to address these a unique accessibility identifier for each UI element [22]
challenges. in the input SwiftUI app. To find accessibility issues,
DesignGoal1–LocalizeimpactedUIelementsinsource, the Data Processing module runs GUI tests to navigate
and automatically apply fix suggestions: Developers strug- to varied screens in the app. It then uses Accessibility
gledthemostduringourinterviewswithfindingimpacted Inspector [10] to obtain a report of accessibility issues on
UI elements in source code, which is often the starting an app screen navigated to by a GUI test. The output
point for making a fix. This added tedious, and unneces- of the scanner includes a description of each issue, the
saryfrictiontotheirbugfixingprocess.Developersutilized identifieroftheimpactedUIelementoritsparentelementsFig.3. FixAlly’sapproach,consistingof1)DataProcessing whichinstrumentstheapplicationandnavigatestovariousscreensviaGUI
tests to capture accessibility scans and screenshots, 2) Suggestion Generation which uses a multi-agent LLM architecture to generate fix
suggestions for each detected issue from the input screenshot, source code, and issue descriptions, and 3) Suggestion Assessment which
capturesanewaccessibilityscanofthepatchedappandGUIscreenandcomparesittothepriorreporttodetermineifthefixsuggestion
resolvedtheissue.
in the UI hierarchy, and a screenshot of the app with
A11y Issue
the location of the problematic element. The Suggestion Modification Plan
GenerationEngineprocessestheinformationforeachissue UI hierarchical Structure
to generate multiple fix suggestions for addressing the
issue, and patched project to verify whether suggestions
resolvetheissue(DetailsinSectionV).InspiredbyDesign
All View files in the project
Goal 1, the Suggestion Generation Engine is capable of
localizing the source of issues among the code for an Static Analysis:
app across multiple files, and generating patches that Parent and Descendants
in UI hierarchy
developers can automatically apply to fix the issue.
To verify that generated fix suggestions can plausibly LLM-based Rating:
fix each issue, FixAlly evaluates each code modification Highly matched
in its Suggestion Assessment module. This module takes Views
themodifiedcodesnippettogenerateapatchedversionof
the project, attempts to build the app, and runs the same LLM-based
Comparison
GUI test to navigate to the target screen where the issue
was detected. It then uses the Accessibility Inspector to
audit the screen and compare the report with the initial
report.
Suggestion Generation Engine fails when the generated Most likely
fixhasbuilderrors,wasnotabletoresolvetheaccessibility code snippet
issue, or introduced new issues. The model may also
Fig. 4. Multi-level, hybrid localization architecture: Static analysis
inadvertently comment out sections of code or remove of the UI hierarchy identifies parent and descendant views. LLM-
necessary screen elements. FixAlly feeds these failure basedratingevaluatesthematchofeachindividualcodesnippetto
thescreenshot.Finally,LLM-basedcomparisonexaminesthehighly
messages back to the Suggestion Generation Engine to
matchedviewstodeterminethemostlikelycodesnippetforapplying
self-reflect and let it revise the modified code snippet. thefix.
This iterative process mirrors a developer’s approach of
assessing and revising modifications in response to issues.
V. Suggestion Generation Engine
In our work, we configure the number of iterations for
this feedback loop, setting it to 3 to allow sufficient The Suggestion Generation Engine (Figure 3.2) is sug-
opportunities for the model to refine its fix suggestions. gests fix strategies for each reported accessibility issue.
Finally, if the fix suggestion successfully resolves the issue Figure 1 shows the Suggestion Generation Engine, illus-
without introducing other issues or removing functional- trating three agents in this module: Planner, Localizer,
ities, the Suggestion Assessment module marks it as a Fixer.Theseagentsareresponsibleforperformingspecific
fix suggestion that can be shown to developers. FixAlly steps that developers take in fixing an accessibility bug,
provides developers with multiple fix suggestions for an as we observed in our Formative Study (Section III).
issue inspired by Design Goal 2. The details of each agent are below. For each agent,Issue: Hit Area is too small Issue: Text Clipped Issue: Contrast nearly passed
plan: Wrap the interactive element with a larger container. plan: Increase font size of Dismiss button
Plan1: Use a flexible stackable layouts
Text("Seasonal Photos:\(seasonalPhoto.raw)")
var body: some View { HStack { .toolbar {
ScrollView { Text("Seasonal Photos:") ToolbarItem(placement: .cancellationAction) {
Button(action: { Spacer() Button(action: {
// Empty action to make it interactive Text(profile.seasonalPhoto.rawValue) isPresentingNewScrumView = false
}) { } }) {
VStack(alignment: .leading, spacing: 10) { .accessibilityElement(children: .combine) Text("Dismiss")
// The rest of elements .font(.system(size: 18)) // Modified font size
} Plan2: Enable word wrapping and hyphenation. }
.padding() Text("Seasonal Photos:\(seasonalPhoto.raw)") }
.frame(minWidth: 44, minHeight: 44) .lineLimit(nil) // Allow unlimited lines ToolbarItem(placement: .confirmationAction) {
} .multilineTextAlignment(.leading) Button(action: {
.buttonStyle(PlainButtonStyle()) // Ensure text wraps correctly scrums.append(newScrum)
} isPresentingNewScrumView = false
} Plan3: Increase row heights }) {
Text("Add")
Text("Seasonal Photos:\(seasonalPhoto.raw)") .font(.system(size: 18))
.padding(.vertical, 20) // Optional: Ensure consistency in font size
// Increased padding to increase height }
(a) (b) (c)
Fig.5. ThreedifferenttypesofissuesthatwerefixedbyFixAlly.(a)Thetooladdressestheissueofsmallhittargetsizebyidentifyinga
groupofsemanticallyrelatedelementsandmergingthemintoaninteractivecontainer.(b)ShowsthreegeneratedfixsuggestionsforText
Clipped issue. The first plan involves replacing a single element with a group of elements while preserving the functionality(c) FixAlly
addressesthecontrastissueofthe“Dismiss”button,whilealsomaintainingdesignintegritybyapplyingthefontchangetoanothersimilar
button.
we currently use GPT-4o [23] for the LLM model. The B. Localizer: Finding the relevant code snippet
specifics of the prompt, along with the source code, are
available in the supplementary material submitted with Localizing an issue involves identifying the precise lo-
the paper. cation in the source code where the fix plan should be
applied. Source code projects often span numerous files
with thousands of lines, potentially exceeding the token
limits that language models can effectively query in one
A. Planner: Suggesting fix plans
request or retain in their context window. To manage this
Eachaccessibilityissuemayberesolvedinvariousways. complexity, we employ a multi-level localization approach
According to our Formative Study III, developers prefer usingstaticcodeanalysisandLLMcodeanalysis.Figure4
solutions that not only fix the issue without introducing illustratesthedifferentlevelsoflocalization,includingone
new issues, but also align with the design decisions of the static code analysis step and two LLM-based steps for
app and work well in different modes, such as dark mode issue-to-code mapping.
or horizontal mode. Providing different options for fixing First, the Localizer identifies all of the View files of the
an issue allows the developer to choose the one that best project, identifiable by the ‘import SwiftUI’ statement
fitstheoveralldesignandfunctionality.ThePlanneragent and structures extendingthe View class.Then, it extracts
facilitates this by generating natural language suggestions candidate code snippets from these view files through
of strategies to fix each issue. For example, agent may static code analysis. The key insight that the Localizer
suggest a plan of “adjust background color for better uses to optimize this process is that the behavior and de-
contrast” to fix a “contrast failed” issue for a UI element. sign of UI elements are predominantly influenced by their
FixAllyprovidesthePlanneragentwithanannotated descendants or ascendants. The Static Analysis module
screenshotoftheappalongwiththeissuedescriptionfrom takestheaccessibilityidentifieroftheproblematicelement
the Accessibility Inspector. Its task is to identify the most and traverses the pre-analyzed UI structure to return all
relevant accessibility guideline related to the reported descendant views and the parent of that element to form
issue and list techniques to resolve it in natural language. a set of candidate code snippets. FixAlly adds these
FixAllyaimstoleveragethelanguagemodel’sknowledge accessibilityidentifierstoeachviewinthecodeintheData
of accessibility fixes across various platforms, such as the Processing phase, where it also captures the UI hierarchy
web,toprovidesuggestionsthatcanbeadaptedformobile (Recall Section IV).
appsonspecificplatformslikeiOS.FixAllyinstructsthe Next, the Localizer generates an LLM-based rating for
agenttoavoidsuggestingsolutionsthatarenotapplicable thecodesnippetsfilteredbythestaticanalysismodule.It
to the source code, filtering out recommendations such as matcheseachsnippettothemodificationplanfortheissue
using third-party tools to test the app. In our evaluation, and the screenshot highlighting the problem. Due to the
FixAlly instructsthePlannertoreturnthreealternative limited context window of LLMs, it may not be feasible
plansforeachissue,thoughthisnumbercanbeconfigured. to consider and compare all candidate snippets simulta-neously to find the correct one to apply the fix. Instead, VI. Evaluation
the Localizer agent first assesses each snippet individually
We evaluated FixAlly through the following research
based on detailed issue information, the screenshot, and
questions:
theproposedfixplantodetermineitssuitability.FixAlly
RQ1. (Effectiveness) How effective is FixAlly in gener-
instructs the agent to map the problematic element and
ating code fixes for accessibility issues detected by
other elements in its vicinity to the source code, consider
an accessibilty scanner?
thefixplan,andratethelikelihoodthatthesnippetisthe
RQ2. (Efficiency) What is the efficiency of FixAlly in
correctlocation.Thisapproachmirrorsvarioustechniques
terms of time, the number of attempts, and the
developers use to localize accessibility issues in the source
cost?
code, as mentioned in Section III. The language model’s
RQ3. (Helpfulness) How helpful are the proposed fixes
codecomprehensioncapabilities,combinedwithitsknowl-
for developers?
edge of accessibility, enable it to rate the alignment of
the code with the highlighted element in the screenshot A. Experimental Setup
and the fix strategy. FixAlly selects the code snippets We evaluated our approach using 14 open-source apps
with the highest match rates for further comparison by sourced from GitHub. Specifically, we randomly selected
the Localizer agent. The Localizer agent ranks the highly apps from two GitHub repositories that catalog open-
rated snippets and selects the one most likely to be the source iOS apps [24], [25], excluding apps not built using
correct location for applying the fix. SwiftUI. For each app, one of the authors attempted to
buildtheappsuccessfullywithina30minutewindow.We
C. Fixer: Modifying the code also excluded apps with build errors due to dependencies,
external packages, or very old iOS versions from the
The goal of the Fixer agent is to apply the fix strategy
dataset. Table I provides a list of the apps included in our
to the selected code snippet. The Fixer agent receives
study. The list of apps with their corresponding GitHub
the issue details, the fix strategy for the issue, and the
linksisalsoavailableinoursupplementarymaterials.Fix-
most relevant code snippet to be modified based on the
Ally’s implementation leverages LLM agents based on
plan. Instead of relying on the agent to generate a diff, we
GPT-4o,whichfeaturesa128Kcontextwindowandhasa
instruct the agent to directly apply the modifications and
knowledgecut-offdateofOctober2023.Weconductedthe
return the updated code. This approach avoids potential
experiments on a MacBook M1 Pro equipped with 32GB
inaccuracies in diff generation by language models, which
of RAM, a typical computer setup for development. We
may struggle with accurately calculating changes across
used Xcode 15.0, the latest available version, to build the
linesofcodeandmanagingtherequirednumberoftokens.
apps, and we installed and tested them on an iPhone 12.
Finally, the Suggestion Generation Engine module applies
the diff and creates a new copy of the project.
B. RQ1. FixAlly’s effectiveness
We assessed the efficacy of FixAlly by evaluating its
D. Output
ability to propose fix suggestions for 204 issues across 22
Italso storesa diffof theupdatedcodeand theoriginal screensofSwiftUIiOSapps.TableIpresentstheoutcomes
buggy code to provide a visualization of the code sugges- of FixAllyingeneratingfixsuggestions.Weusetheterm
tion for developers to examine. Figure 5 shows examples plausible to indicate that the generated fix resolved the
of fix suggestions generated by FixAlly, demonstrating targeted issue while maintaining app functionality and
its ability to address different types of issues and apply without introducing new issues.
differentstrategiestofixanissue.Theoutputof FixAlly FixAlly demonstrated a 77% effectiveness in auto-
iscurrentlyadiffvisualizationofthecodeforeachfixsug- matically generating fix suggestions for accessibility is-
gestionalongwiththefixplanandthemodel’sexplanation sues, where effectiveness means it successfully produced
of the changes. at least one plausible suggestion out of three suggestions
As shown in Figure 5(a), FixAlly correctly identifies a for 157 out of 204 issues. Furthermore, for 129 (63%) of
group of semantically related elements and merges them these issues, FixAlly generated two or three plausible
into an interactive container to address the issue of small fix suggestions, providing developers multiple options to
hit target size. In contrast, Figure 5(b) demonstrates the consider.
capability of FixAlly in splitting a single element into We also assessed the categories of issues that FixAlly
a group of elements to address the Text Clipped issue. cangeneratefixsuggestionsfor.Ourdatasetcontainsnine
Figure 5(c) shows that when fixing the contrast issue of differenttypesofissuesasshowninTableII.Accordingto
the “Dismiss” button, the tool also maintains the app’s the documentation for Accessibility Inspector [26], these
design integrity by applying the proposed fix to a similar issues encompass the categories of Element description,
“Add” button in the toolbar, demonstrating its ability Element detection, Hit region, Contrast, Clipped text,
to fix accessibility issues while maintaining consistency Traits, and Dynamic type. However, our dataset does not
between similar UI elements. contain trait issues: we found that even when modifyingthe proposed plans, related code snippets, and SwiftUI
TABLEI
FixAlly’s effectiveness in generating fixes accessibility attributes generated by the tool can still help
for accessibility issues
developers devise a fix more quickly. Furthermore, some
reported failures were due to false positives from the
App1 Screens n PlausibleFix(PF)
Accessibility Inspector. For instance, after testing the app
ARPlasticOcean 1 5 4
withdifferentfontsizes,wefoundthattheissue”Dynamic
Calculator 1 24 22
DeTeXt 1 1 1 Typefontsizesareunsupported”wasincorrectlyreported
DesignRemakes 1 1 0 in two cases for Landmarks app. Given these factors, the
ExpenseTracker 1 5 4
tool’s effectiveness in practice may be higher than what is
Fingerspelling 1 4 3
Instagram 2 5 3 reflected in our current report.
Landmarks 3 55 48 We also hypothesized that the capabilities of FixAlly
Ratio 1 15 10
extend beyond the issues reported by the Inspector. In
Scrumdinger 2 7 6
GoCycling 4 74 52 one experiment on a reported issue on GitHub for an iOS
DesignCode 1 8 7 app [27], we attempted to fix the “incorrect focus order”
GradeCalc 2 7 3
issue using FixAlly. Due to the lack of accessibility
Sunshine 1 1 1
identifiers and GUI tests, we manually localized the code
Total 22 205 158
snippet and allowed the tool to perform the planning and
1Open-sourceappsfromGitHub.
fixing phases. We provided the screenshot and the title of
the report to the model. Given the related code snippet,
TABLEII themodel’sfirstplanwasto“settheaccessibilityElements
FixAlly’s effectiveness in fixing different types of issues property of the parent view.” The model generated a fix,
adding ‘.accessibilityElement(children:.contain)’
Category Issuetype n PF1
to the parent view, which was very similar to the fix sub-
Clippedtext Textclipped 15 11 mittedbydevelopers.Toensuretherewasnodataleakage
Contrast Contrastfailed 27 21 to the LLM, we confirmed that the commit date for fixing
Contrast Contrastnearlypassed 21 17
that issue was after the knowledge cut-off date of GPT-
Dynamictype DynamicTypefontsizesare 16 11 4. While this experiment demonstrates that FixAlly’s
partiallyunsupported
capabilities can extend beyond the issues reported by the
Dynamictype DynamicTypefontsizesare 58 39
unsupported Accessibility Inspector, further experiments are needed.
Elementdescription Elementhasnodescription 43 38
Elementdescription Labelnothuman-readable 3 3 C. RQ2. FixAlly’s efficiency
Elementdetection Potentiallyinaccessibletext 8 7 In this research question, we assessed FixAlly’s ef-
Hitregion Hitareaistoosmall 21 17 ficiency in terms of the number of attempts, time, and
1Indicatesthenumberofissueswithatleastoneplausiblefix. number of tokens required to fix issues.
In terms of the number of attempts, our experiments
indicatethatoutof363plausiblefixsuggestions,FixAlly
some apps to purposefully contain these issues, Accessi- generated157ofthemonthefirstattempt,whileFixAlly
bility Inspector detected these only on the iOS simulator generated 124 and 82 on the second and third attempts,
and not on the physical device used for our experiments. respectively. For the majority of the plausible fix sugges-
Excluding Traits, FixAlly could successfully resolve at tions (57%), the feedback loop design helped FixAlly
least one issue from each type. resolve the reported failures and generate a plausible fix
To understand the failures of FixAlly, the first author suggestion, positively impacting the model’s effectiveness.
manually inspected a subset of the generated fix sugges- However, this improvement in effectiveness comes at the
tions that did not resolve the accessibility issues. Their cost of efficiency. By making this feedback loop a con-
analysis suggests that these failures may stem from short- figurable parameter, users can adjust it to match their
comingsintheplanning,localization,orfixingphases.For specific resource constraints, thereby balancing efficiency
example, for the issue “Text Clipped” only one of the fix and effectiveness.
suggestions was plausible. Two out of three plans gener- We also evaluated the time required for the tool to
atedbytheplannerwereirrelevant,indicatingthatnotall fix the issues. The mean time to propose alternative fix
issuesmayhavemultipleplausiblesolutions.Additionally, suggestions (averaged across 10 randomly selected issues)
in some cases, the tool may select incorrect code snippets was 54 seconds. Therefore, for a screen with 10 issues,
forfixing.Whenthereisinsufficientinformationaboutthe the tool can provide solutions in less than 10 minutes,
problematic element, the model might fail to identify the demonstrating its practical usability. The breakdown of
relevantcodesnippet,leadingtoineffectivefixsuggestions. this time is as follows:
Even if localization is accurate, the generated code may The time required for the Data Processing module to
contain build errors or be ineffective. Despite these issues, statically analyze the app depends on the project’s com-plexity and the number of views it contains. For the apps
in our test set, it takes an average of 6 ms to extract the
UI hierarchy and instrument the code. Extracting acces-
sibility issues involves building the app, running the GUI
test, and using the Accessibility Inspector to dynamically
assess the app. These steps, performed by both the Data
Processing and Suggestion Assessment modules, take an
average of 130 ms per screen.
FixAlly’s performance is also closely tied to the LLM
responsetime.WeuseapubliclyavailableAPItocommu-
nicate with the agents, and various factors, such as online
traffic and token constraints per minute, can impact the
model’s response time. In our experiments, the average
response times (across 10 randomly sampled issues) for
the Planner, Localizer, and Fixer were 7s, 29.5s, and 8.2s,
respectively.TheLocalizer’slongerresponsetimeisdueto
itsneedtoevaluatemultiplecandidatesnippets,requiring
more than one inquiry to the model.
In addition to time considerations, the cost of using
LLMsiscloselyrelatedtothenumberoftokensprocessed.
The average number of tokens per inquiry to the Planner,
Localizer, and Fixer is 10K, 15K, and 20K, respectively.
The GPT-4o model used in this study costs $5 per 1M
tokens.Forascreenwith about 10issues,thetotalcostof
using the tool is less than $10.
D. RQ3. FixAlly’s helpfulness
To evaluate the helpfulness of FixAlly in assisting
developers with fixing accessibility issues, we conducted
a survey of 12 iOS developers within our company. We
recruited them from a participant pool from prior studies
witharound60candidates.Inthesurvey,developersrated
suggestions produced by FixAlly and gave feedback on
theoverallusefulnessofthetool.Thedevelopersself-rated
their SwiftUI iOS development experience on a scale from
1 (No Experience) to 5 (Expert). The developers’ median
self-rated expertise in SwiftUI app development was 5
( ) and in accessibility testing was 5 ( ). We excluded
developers who self-rated as 1 (No Experience) for either
of these questions from answering the survey.
We randomly selected 9 issues and generated plausible
fixes for them using FixAlly. Figure 6 illustrates one
of these issues with three alternative code suggestions to
fix the issue. For each issue, we showed developers an
annotated screenshot with the issue reported by Acces-
sibility Inspector along with a diff visualization for each
of the three suggestions and the fix plan and explanation
of changes from the LLM.
1) Acceptance of Fix suggestions: Initially, the survey
askedthedeveloperstodescribewhattheissuemeantand
iftheyhadahypothesisandaplanforhowtofixtheissue
Fig. 6. A sample issue with three fix suggestions generated by
before showing them the fix suggestions. The developers FixAlly. The first image shows the ”Contrast Failed” issue and
overall accessibility testing expertise was relatively high. its original code snippet in Ratio app. The following three boxes
represent different plans, each with the modified code snippet and
We presented the developers three fix suggestions from
thecorrespondingscreenshotupdates.
the tool and asked whether they would accept any of
the proposed suggestions. Overall, developers accepted asuggestion as is or with some modifications for 70% of the VII. Threats to Validity
issues.
External Validity: One limitation of FixAlly is that
Developers did not always accept a fix suggestion that
it assesses issues individually, even though many issues
aligned with their initial hypothesis and fix plan. An ac-
maybeinterconnected.Forexample,fixingoneissuemight
cessibility testing expert (also an author) assessed “align-
resolve others, or altering the appearance of one element
ment” of developers’ hypothesis and fix plan matched
might require adjustments to other related elements. To
the corresponding fix suggestion using a scoring rubric of
address this, we have designed the Fixer prompt to cas-
0 – did not match, 1 – matched with some conceptual
cade design changes across elements to maintain design
difference or different level of specificity, and 2 – perfect
integrity.AsFigure5(c)shows,themodelcanconsiderthis
match. The mean score for “alignment” was 1.1 (Med: 1,
aspect in some cases. However, without a clear definition
σ =1.31) and 68% of the accepted fixes at least partially of relevant elements and design integrity, the tool’s limi-
alignedwiththedevelopers’initialfixplanandhypothesis.
tations and capabilities are unknown. Future work could
focus on developing metrics to assess design integrity or
2) Helpfulness: Developersalsoratedhowhelpful(from
grouping related issues to propose unified solutions and
1-leasthelpfulto5-mosthelpful)theywouldfindatool
enhance the performance of the tool.
that proposed suggestions for fixing accessibility issues.
Developers median rating for helpfulness was 3 ( ). Less Additionally, FixAlly focuses on single-view files for
experienced developers in accessibility testing rated the localizing and generating fixes for issues, which means
tool as more helpful. it cannot address problems that require changes across
multiple files. Although the issues in our test set could be
Developers rating the tool a 5 or 4 (6 developers) found
resolved within single files, studying more complex, cross-
it useful the tool gave multiple suggestions, and noted it
file issues—albeit less common—remains a compelling
was especially useful to help less experienced developers
area for future research. This limitation also impacts the
in accessibility testing and implementation to understand
consideration of overall app design integrity beyond a
different fix strategies.
single screen. While providing multiple suggestions allows
While developers who rated the tool a 2 (Slightly Help- developers to choose the most suitable one based on app
ful) or 3 (Moderately Helpful) (6 developers) found the design decisions, incorporating techniques to group issues
FixAlly’s localization of the issue helpful, and liked that across different app screens would enhance the tool.
it provided several options, they critiqued some solutions Lastly, the tool has been implemented and tested on
for not addressing the root of the issue or for being sub- iOSapps.Webelievethatthebenefitsof FixAllycanbe
optimal. All developers rating FixAlly’s helpfulness as generalized to other platforms by using appropriate tools
2 or 3 predominantly focus on accessibility engineering to build, instrument, and audit apps on those platforms.
and testing for their job, while the remaining developers The system definitions for agents can also be adjusted
(rating helpfulness as 4 or 5) primarily focus on software according to the platform, such as specifying expertise in
engineering and occasionally perform accessibility testing. SwiftUI for iOS or in Android development for Android
apps. However, this generalizability needs to be further
The developers’ opinions were also mixed on whether it
evaluated.
wouldbeusefulforthetooltoalsoprovidesub-optimalfix
suggestionsorsuggestionswhichdonotfixtheissue.Some Internal Validity: We implemented FixAlly using
varioustoolsandlibraries,includingXCTest,Accessibility
thought it would be useful to see alternative suggestions
Inspector,andtheTree-sitterlibraryforcodeparsing[28].
to stoke the developer’s imagination for finding the right
These external tools may introduce defects into the sys-
solution(6developers),whilesome(3developers)thought
tem,andtheprototypeitselfmaycontainimplementation
providing these suggestions which were known to not fix
bugs. To mitigate these issues, we tested the tool on a
the issue could be confusing or distracting, especially to
variety of apps at different stages and ensured that we
developers less experienced with accessibility testing.
used the latest updates of the external tools.
3) Plausible fix vs correct fix.: With FixAlly, our goal
was to generate plausible fixes—code modifications that VIII. Related Work
passtheaccessibilitychecksofanautomatedscannerwith-
out introducing new issues or removing any functionality. Our work fits into the space of automated accessibility
Our survey shows that out of 36 developer assessments testing and repair tools, which have advanced the state-
of plausible fix suggestions, only 11 cases did not receive of-the-art for automated detection and reported of acces-
approvalforanyofthesuggestedfixes,resultingina69.4% sibility issue. Our work is among the first to localize and
developer acceptance of fixes. However, further studies suggest fixes in code for these issues. We also review work
are needed to understand the various considerations app LLM-based program repair and fault localization which
development teams take into account when determining a use similar multi-agent architecture, but do not address
correct fix, before automating that process. GUI or accessibility issues.A. Automated accessibility testing and repair techniques into its pipeline for issue detection, and then
rely on the capabilities of its LLM to suggest candidate
Manyautomatedtoolshavebeenreleasedandproposed
solutions.
in research over the years to detect accessibility issues.
Static tools [29] examine code directly to find potential
B. LLM-based program repair and fault localization
issues. One limitation with these tools is that they do not
Recent progress in LLMs have advanced their applica-
have access to the run-time interface that can be created
tioninautomatingprogramrepairtasks.Asystematicsur-
programmatically or injected with data at runtime. Test-
vey on LLMs for automated program repair [37] reviewed
time tools can detect issues from the runtime UI [30]–[32]
127 studies, covering various aspects of this problem, but
butarelimitedbythecoverageoftheinputUItestswhich
none specifically address GUI or accessibility issues.
priorworksuggestsmaynotexistorhaveveryincomplete
The only study focused on GUI issues is ACCESS [38],
coverage over UI states [33]. Accessibility scanners that
which examines LLM capabilities in correcting web acces-
examinearun-timeinterfacecandetectdifferentclassesof
sibility violations by exploring different prompt engineer-
issuesthatsurfaceatrun-time[9],[10],[30]anddonotrely
ing techniques to fix issues reported on specific HTML
on pre-existing UI tests. However, accessibility scanners
tags. This approach is limited to textual data from web
havetwomainlimitations:1)theydonotassistdevelopers
pages and does not address mobile app issues, where it is
in effectively localizing the impacted UI element with an
necessary to identify the location of the problematic GUI
issue,and2)theyprovidedeveloperswithlittleassistance
element in the code.
infixingtheissueotherthansometimesasinglehigh-level
Recently,researchershaveexpandedbeyondprompten-
non-contextualizedfixsuggestion.FixAllytakesasinput
gineering to enhance LLM-based bug repair performance
an issue detected by one of these tools, its description,
forGitHubissues.Theyhaveemployedvarioustechniques,
information about the impacted UI element in the form
includingfine-tuningonspecificdatasets[39]–[43],ormore
of a screenshot (i.e., Accessibility Inspector [10]), and the
advanced strategies such as retrieval-augmented genera-
app source code, and both localizes the UI element and
tion to guide search space [44], agents interacting with
provides multiple relevant fix suggestions.
other tools [45], [46], or multi-agent systems operating in
Some work combines run-time accessibility scanners
different steps [47]–[49].
with app crawlers to detect and report accessibility is-
In these works [48], [49], researchers drew inspiration
sues [12], [34], [35]. While these tools can surface more
fromhumanrolesinreal-worldscenarios,suchasManager
issues to developers, the amount of issues reported by
andDeveloper,todesignLLMagentswithspecificactions.
these tools can be overwhelming [36] especially when even
Tao et al. [48] enforce collaboration between agents to
localizingandfixingoneissueisalreadychallenging.These
localize a file and implement a patch. Chen et al. [49]
toolsarealsonotconnectedtotheunderlyingsourcecode,
proposed four collaborative plans for agents to address
which can often be a reason for developers to ignore the
issues, with the Manager agent selecting a plan from pre-
reported issues from these tools.
defined options. These studies demonstrate how modeling
Another area of work has developed single-purpose,
software engineering processes with agents can enhance
mostly machine-learning based, techniques to detect spe-
issue resolution capabilities. However, these approaches
cific accessibility issues such as color issues [13], touch
only address functional issues reported on GitHub.
target size [16], missing labels [14], and text scaling [15].
In contrast to prior related work, our work targets
These solutions have predominately focused on Android
accessibility issues in mobile apps using a novel multi-
apps, which have very different specification than iOS
agent LLM architecture. It designs agents inspired by
apps and are not implemented in SwiftUI. Zhang et. al [6]
the steps developers take to solve these problems while
detectandrepairUIelementsfortheiOSVoiceOverscreen
also considering their unique characteristics, such as the
readerusinganapproachthatcouldbeplatformagnostic.
diversity of accessibility issues, various fix strategies, and
However,thereremainsahugegapbetweenthesesolutions
the need to analyze GUI images with reported issues. We
and the original source code where the developer must
developedFixAlly,whichanalyzesissuesinmobileapps,
make the fix. Even if the localization issue were solved by
employsaplan-localize-fixprocess,andproducesplausible
these methods, there would still be a need to generate
fixes. Additionally, FixAlly incorporates a feedback loop
alternate fix solutions. As we learned in our formative
that uses natural language error messages to enable the
interviews, fixing one issue may introduce other issues, so
LLM to reflect [50] on and address its own failures.
thereislikelynoone-size-fits-allfixforeachissuecategory.
Developers need to consider many other requirements to
IX. Conclusion
determine the correct fix (e.g., input from design teams,
impact on other areas of the app). In contrast to prior so- Fixingaccessibilityissuesinmobileappsisachallenging
lutions,FixAlly bothlocalizesthecodefortheimpacted taskfordevelopers.Whileautomatedscannerscanidentify
UI element and suggests multiple candidate fixes. Future these issues, they often fall short in guiding developers to
versions of FixAlly can also incorporate some of these the exact location in the code and suggesting appropriatefixes.Towardsaddressingtheseneeds,weproposedaplan-
[15] A.S.Alotaibi,P.T.Chiou,F.M.Tawsif,andW.G.Halfond,
localize-fix technique, operationalized through a multi- “ScaleFix: An Automated Repair of UI Scaling Accessibility
agent LLM architecture called FixAlly. Evaluations on Issues in Android Applications,” in Proceedings of the 39th
IEEE International Conference on Software Maintenance and
FixAlly demonstrate its capabilities in suggesting plau-
Evolution(ICSME),October2023.
sible fix suggestions and highlight how the tool assists the [16] A. S. Alotaibi, P. T. Chiou, and W. G. Halfond, “Automated
developer in the decision-making process for selecting and repairofsize-basedinaccessibilityissuesinmobileapplications,”
in 2021 36th IEEE/ACM International Conference on Auto-
applying accessibility-related fixes. Our results suggest
matedSoftwareEngineering(ASE). IEEE,2021,pp.730–742.
that applying LLMs to fix accessibility issues in source [17] Apple Developer, “Swiftui - build user interfaces for any apple
code is an encouraging direction. device,”https://developer.apple.com/xcode/swiftui/,2024,ac-
cessed:2024-07-20.
References [18] I. D. Foundation, “Affinity diagrams,” Dec 2017. [On-
line].Available:https://www.interaction-design.org/literature/
[1] Android, “Build more accessible apps,” https://developer. topics/affinity-diagrams
android.com/guide/topics/ui/accessibility, Google, 2022, last [19] A. Inc., “Xctest,” Aug 2023. [Online]. Avail-
Accessed:May6,2022. able: https://developer.apple.com/documentation/xctest/
[2] Apple, “Accessibility on ios,” https://developer.apple.com/ user interface tests
accessibility/ios/,Apple,2022,lastAccessed:May6,2021. [20] testableapple, “xcmonkey: Stress testing tool for ios apps,”
[3] W3C,“Wcag2overview,”https://www.w3.org/WAI/standards- 2024, accessed: 2024-07-20. [Online]. Available: https://github.
guidelines/wcag/,W3C,2024,lastAccessed:July18,2024. com/testableapple/xcmonkey
[4] A.Alshayban,I.Ahmed,andS.Malek,“Accessibilityissuesin [21] T. Su, G. Meng, Y. Chen, K. Wu, W. Yang, Y. Yao, G. Pu,
androidapps:stateofaffairs,sentiments,andwaysforward,”in Y.Liu,andZ.Su,“Guided,stochasticmodel-basedguitesting
2020 IEEE/ACM 42nd International Conference on Software ofandroidapps,”inProceedingsofthe201711thjointmeeting
Engineering(ICSE). IEEE,2020,pp.1323–1334. onfoundationsofsoftwareengineering,2017,pp.245–256.
[5] C. Vendome, D. Solano, S. Lin˜´an, and M. Linares-V´asquez, [22] A. Inc., “accessibilityidentifier,” July 2024. [Online].
“Caneveryoneusemyapp?anempiricalstudyonaccessibility Available: https://developer.apple.com/documentation/uikit/
in android apps,” in 2019 IEEE International Conference on uiaccessibilityidentification/1623132-accessibilityidentifier
Software Maintenance and Evolution (ICSME). IEEE, 2019, [23] OpenAI, “Gpt-4,” https://openai.com/index/gpt-4/, 2024, ac-
pp.41–52. cessed:2024-07-20.
[6] X. Zhang, L. de Greef, A. Swearngin, S. White, K. Murray, [24] vsouza, “Awesome ios,” https://github.com/vsouza/
L. Yu, Q. Shan, J. Nichols, J. Wu, C. Fleizach et al., “Screen awesome-ios,Accessed:2024.
recognition:Creatingaccessibilitymetadataformobileapplica- [25] dkhamsing, “Open source ios apps,” https://github.com/
tions from pixels,” in Proceedings of the 2021 CHI Conference dkhamsing/open-source-ios-apps,Accessed:2024.
onHumanFactorsinComputingSystems,2021,pp.1–15. [26] Apple Inc., “Performing accessibility audits
[7] A.S.Ross,X.Zhang,J.Fogarty,andJ.O.Wobbrock,“Exam- for your app,” Apple Developer Documenta-
ining image-based button labeling for accessibility in android tion, July 2024, accessed: 2024-08-01. [On-
apps through large-scale analysis,” in Proceedings of the 20th line]. Available: https://developer.apple.com/documentation/
InternationalACMSIGACCESSConferenceonComputersand accessibility/performing-accessibility-audits-for-your-app
Accessibility,2018,pp.119–130. [27] OrangeOpenSource,“Issue#703:Checkaccessibilityissueson
[8] T.Bi,X.Xia,D.Lo,J.Grundy,T.Zimmermann,andD.Ford, ios17,”GitHub,2023,accessed:2024-08-01.[Online].Available:
“Accessibilityinsoftwarepractice:Apractitioner’sperspective,” https://github.com/Orange-OpenSource/ods-ios/issues/703
ACM Transactions on Software Engineering and Methodology [28] Tree-sitter, “Tree-sitter,” https://tree-sitter.github.io/
(TOSEM),vol.31,no.4,pp.1–26,2022. tree-sitter/, 2024, accessed: 2024-07-24. [Online]. Available:
[9] Google, “Get started with accessibility scanner - android https://tree-sitter.github.io/tree-sitter/
accessibility help,” 2024. [Online]. Available: https://support. [29] Google, “Android lint,” 2022. [Online]. Available: https:
google.com/accessibility/android/answer/6376570 //support.google.com/accessibility/android/answer/6376570
[10] A. Inc., “Accessibility Programming Guide for OS [30] N. Salehnamadi, A. Alshayban, J.-W. Lin, I. Ahmed, S. Bran-
X: Testing for Accessibility on OS X,” March ham,andS.Malek,“Latte:Use-caseandassistive-servicedriven
2022. [Online]. Available: https://developer.apple.com/ automatedaccessibilitytestingframeworkforandroid,”inPro-
library/archive/documentation/Accessibility/Conceptual/ ceedings of the 2021 CHI Conference on Human Factors in
AccessibilityMacOSX/OSXAXTestingApps.html ComputingSystems,2021,pp.1–11.
[11] F. Mehralian, N. Salehnamadi, S. F. Huq, and S. Malek, “Too [31] G. O. S. Framework), “Earl grey: ios ui automation test
muchaccessibilityisharmful!automateddetectionandanalysis framework,” 2022. [Online]. Available: https://github.com/
of overly accessible elements in mobile apps,” in 2022 37th google/EarlGrey
IEEE/ACM International Conference on Automated Software [32] Google, “Espresso,” 2021. [Online]. Available: https:
Engineering, IEEE. Rochester, Michigan, USA: ACM New //developer.android.com/training/testing/espresso
York,NY,USA,2022. [33] M. Padure and C. Pribeanu, “Comparing six free accessibility
[12] N.Salehnamadi,F.Mehralian,andS.Malek,“Groundhog:An evaluation tools,” Informatica Economica, vol. 24, no. 1, pp.
automated accessibility crawler for mobile apps,” in 2022 37th 15–25,2020.
IEEE/ACM International Conference on Automated Software [34] M. M. Eler, J. M. Rojas, Y. Ge, and G. Fraser, “Automated
Engineering, IEEE. Rochester, Michigan, USA: ACM New accessibility testing of mobile apps,” in 2018 IEEE 11th In-
York,NY,USA,2022. ternational Conference on Software Testing, Verification and
[13] Y. Zhang, S. Chen, L. Fan, C. Chen, and X. Li, “Automated Validation(ICST). IEEE,2018,pp.116–126.
andcontext-awarerepairofcolor-relatedaccessibilityissuesfor [35] A. Swearngin, J. Wu, X. Zhang, E. Gomez, J. Coughenour,
androidapps,”inProceedingsofthe31stACMJointEuropean R. Stukenborg, B. Garg, G. Hughes, A. Hilliard, J. P. Bigham
SoftwareEngineeringConferenceandSymposiumontheFoun- et al., “Towards automated accessibility report generation for
dationsofSoftwareEngineering,2023,pp.1255–1267. mobile apps,” ACM Transactions on Computer-Human Inter-
[14] F. Mehralian, N. Salehnamadi, and S. Malek, “Data-driven action.
accessibility repair revisited: on the effectiveness of generating [36] S. F. Huq, A. Alshayban, Z. He, and S. Malek, “# a11ydev:
labelsforiconsinandroidapps,”inProceedingsofthe29thACM Understanding contemporary software accessibility practices
Joint Meeting on European Software Engineering Conference from twitter conversations,” in Proceedings of the 2023 CHI
and Symposium on the Foundations of Software Engineering, ConferenceonHumanFactorsinComputingSystems,2023,pp.
2021,pp.107–118. 1–18.[37] Q.Zhang,C.Fang,Y.Xie,Y.Ma,W.Sun,andY.Y.Z.Chen,
“A systematic literature review on large language models for
automated program repair,” arXiv preprint arXiv:2405.01466,
2024.
[38] C. Huang, A. Ma, S. Vyasamudri, E. Puype, S. Kamal, J. B.
Garcia,S.Cheema,andM.Lutz,“Access:Promptengineering
for automated web accessibility violation corrections,” arXiv
preprintarXiv:2401.16450,2024.
[39] W.Wang,Y.Wang,S.Joty,andS.C.Hoi,“Rap-gen:Retrieval-
augmentedpatchgenerationwithcodet5forautomaticprogram
repair,”inProceedingsofthe31stACMJointEuropeanSoftware
EngineeringConferenceandSymposiumontheFoundationsof
SoftwareEngineering,2023,pp.146–158.
[40] B. Berabi, J. He, V. Raychev, and M. Vechev, “Tfix: Learning
to fix coding errors with a text-to-text transformer,” in Inter-
national Conference on Machine Learning, ser. Proceedings of
MachineLearningResearch,vol.PMLR,2021,pp.780–791.
[41] M. Fu, C. Tantithamthavorn, T. Le, V. Nguyen, and P. Dinh,
“Vulrepair: A t5-based automated software vulnerability re-
pair,” in Proceedings of the ACM Joint European Software
EngineeringConferenceandSymposiumontheFoundationsof
SoftwareEngineering,ser.ESEC/FSE. ACM,2022,pp.935–
947.
[42] E. Mashhadi and H. Hemmati, “Applying codebert for au-
tomated program repair of java simple bugs,” in Proceedings
Companion of the 18th IEEE/ACM International Conference
onMiningSoftwareRepositories(MSR’21),2021,pp.505–509.
[43] M. Lajk´o, V. Csuvik, and L. Vid´acs, “Towards javascript pro-
gram repair with generative pre-trained transformer,” in 2022
IEEE/ACM International Workshop on Automated Program
Repair. IEEE,2022,pp.61–68.
[44] C.E.Jimenez,J.Yang,A.Wettig,S.Yao,K.Pei,O.Press,and
K.Narasimhan,“Swe-bench:Canlanguagemodelsresolvereal-
worldgithubissues?”arXivpreprintarXiv:2310.06770,2023.
[45] J. Yang, C. E. Jimenez, A. Wettig, K. Lieret, S. Yao,
K.Narasimhan,andO.Press,“Swe-agent:Agent-computerin-
terfacesenableautomatedsoftwareengineering,”arXivpreprint
arXiv:2405.15793,2024.
[46] I.Bouzenia,P.Devanbu,andM.Pradel,“Repairagent:Anau-
tonomous,llm-basedagentforprogramrepair,”arXivpreprint
arXiv:2403.17134,2024.
[47] Y. Zhang, H. Ruan, Z. Fan, and A. Roychoudhury,
“Autocoderover: Autonomous program improvement,” arXiv
preprintarXiv:2404.05427,2024.
[48] W. Tao, Y. Zhou, W. Zhang, and Y. Cheng, “Magis: Llm-
basedmulti-agentframeworkforgithubissueresolution,”arXiv
preprintarXiv:2403.17927,2024.
[49] D. Chen, S. Lin, M. Zeng, D. Zan, J.-G. Wang, A. Cheshkov,
J. Sun, H. Yu, G. Dong, A. Aliev et al., “Coder: Issue re-
solving with multi-agent and task graphs,” arXiv preprint
arXiv:2406.01304,2024.
[50] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and
S.Yao,“Reflexion:Languageagentswithverbalreinforcement
learning,”AdvancesinNeuralInformationProcessingSystems,
vol.36,2024.