Recovering the Pre-Fine-Tuning Weights of Generative Models
EliahuHorwitz JonathanKahana YedidHoshen
SchoolofComputerScienceandEngineering
TheHebrewUniversityofJerusalem,Israel
https://vision.huji.ac.il/spectral_detuning/
{eliahu.horwitz, jonathan.kahana, yedid.hoshen}@mail.huji.ac.il
Abstract ispublished,andtherecoveryoftheoriginalPre-FTunsafe
weights,isimplicitlyassumedtobeimpossible. Whilefor
Thedominantparadigmingenerativemodelingconsists existingmodelstherecoveryofthePre-FTweightsposes
of two steps: i) pre-training on a large-scale but unsafe asecurityandsafetyvulnerability; forfuturesuperhuman
dataset,ii)aligningthepre-trainedmodelwithhumanval- models,itmayleadtocatastrophicconsequences.
uesviafine-tuning. Thispracticeisconsideredsafe,asno Motivatedbytheabove,weproposethetaskofPre-Fine-
currentmethodcanrecovertheunsafe,pre-fine-tuningmodel TuningWeightRecovery. Inthispaper,wetacklethistaskin
weights. Inthispaper,wedemonstratethatthisassumption caseswheremultipleLoRAfine-tunedflavorsofthesame
isoftenfalse. Concretely,wepresentSpectralDeTuning,a sourcemodelareavailable. Wepresentanoverviewofour
methodthatcanrecovertheweightsofthepre-fine-tuning settinginFig.1. Thistaskisparticularlytimelyduetotwo
modelusingafewlow-rank(LoRA)fine-tunedmodels. In trends: i)Popularfoundationmodelscomeinmultiplefla-
contrasttopreviousattacksthatattempttorecoverpre-fine- vors. E.g.,LLaMA2,CodeLLaMA,CodeLLaMA-Python,
tuning capabilities, our method aims to recover the exact CodeLLaMA-Instruct. ii)LoRAisbecomingakeycom-
pre-fine-tuningweights. Ourapproachexploitsthisnewvul- ponent for creating SoTA models [26]. These two trends
nerabilityagainstlarge-scalemodelssuchasapersonalized havenotyetmerged,i.e,wearenotawareofmulti-flavored
StableDiffusionandanalignedMistral. foundationalmodelsthatuseLoRAalignmentfine-tuning.
Here,webringtotheattentionofthecommunitytherisks
andperilsinvolvedinmergingthesetrends.
1.Introduction
WepresentSpectralDeTuning,amethodthatrecoversthe
Akeyparadigmindeeplearningistofirstpre-trainafoun- Pre-FTweightswithremarkablyhighprecisionusingitera-
dation model [36, 46] on a large, general-purpose dataset tivelow-rankmatrixfactorization. Toenhanceoptimization
andthenfine-tunethemodelforaspecifictask. Fine-tuning stability and accelerate convergence, we introduce a rank
isusedforcriticalapplicationsincludingmodelsafety[31], schedulerthatprogressivelyincreasestherankofthefactor-
alignmenttohumanpreferencesandvalues[7,30,33],pro- izedmatricesduringoptimization. Akeydistinctionfrom
viding privacy guarantees [56], personalization [37], and priorattacksonmodelalignment[5,51,62]isthatSpectral
more[4,59].Inthispaper,weidentifyavulnerabilityinfine- DeTuningprioritizesrestoringtheexactPre-FTweightsover
tunedmodels,whereinthepre-fine-tuning(Pre-FT)weights, Pre-FTfunctionalities. Italsodoesnotrequirerunninginfer-
i.e.,themodelweightsbeforethefine-tuningstage,canbe encethroughthemodel. Thisisadvantageousasi)itdoes
recovered using a small number of models fine-tuned via notrequiretrainingdataii)itishighlyparallelizable,e.g.,on
low-rankadaptation(LoRA)[19]. aclusterofdesktopGPUssuchasRTX2080ourmethodcan
Toillustrateoursetting,letusconsideraLargeLanguage recoverthePre-FTweightsofaMistral-7Bmodelinunder
Model (LLM). While the pre-trained version of the LLM fiveminutes.
exhibitsadvancedlanguageunderstandingandgeneration Wedemonstratetheeffectivenessofourmethodbyuncov-
capabilities, it is unaligned with human preference and is eringthevulnerabilityofrealandwidelyusedNLPandVi-
oftendeemedunsafe. Theseunsafemodelscanbeusedfor sionmodels.Ourapproachachievesremarkableprecisionon
example to get instructions for building a bomb or other analignedMistralmodel,effectivelyreversingthealignment
maliciousactivities. Toimproveinstructionfollowingand trainingandrestoringtheoriginalmodel(SeeFig.2). Simi-
enhancesafety,modelcreatorsperformanalignmentfine- larly,onStable-Diffusion,werecovertheoriginalmodel’s
tuningstage. Usually,onlythealignedversionoftheLLM weightswithavanishinglysmallerror,showcasingalmost
1
4202
beF
51
]GL.sc[
1v80201.2042:viXra(c) Recovered
(a) Visible to Attacker by Attacker
" " " "
! "# … ! %# … ! $# Spectral !∗
! ! ! DeTuning ! Recovered Pre-
Merged LoRA Merged LoRA Merged LoRA
Fine-Tuning
Weights Weights Weights
Weights
(b) Invisible to Attacker
" " # "
#
# %
! %# ! "
%
LoRA Weights
! ! !
Merged LoRA Pre-Fine-Tuning LoRA
Weights Weights Weights
Figure1.Pre-Fine-TuningWeightRecoveryAttackSetting:WeuncoveravulnerabilityinLoRAfine-tunedmodelswhereinanattackeris
abletoundothefine-tuningprocessandrecovertheweightsoftheoriginalpre-trainedmodel.Thesettingforthevulnerabilityisasfollows:
(a)TheattackeronlyhasaccesstondifferentLoRAfine-tunedmodels. (b)Theattackerassumesthatallnmodelsoriginatedfromthe
samesourcemodel.Note:Theattackerhasnoaccesstothelow-rankdecompositionofthefine-tunedmodels.(c)Usingonlythen
visiblemodels,theattackerattemptstorecovertheoriginalsourcemodel.Ourmethod,SpectralDeTuning,canperformtheattackinan
unsupervisedanddata-freemanneronrealmodelssuchasStableDiffusionandMistral.Forsimplicity,weillustratetheattackonasingle
layer,inreality,theattackiscarriedoutindependentlyonallthefine-tunedlayers.Bestviewedincolor
perfectreconstructionoftheoriginalgenerationcapabilities 50,60]aimtoeconomizeandbroadenaccesstofine-tuning.
(SeeFig.3). Thesemethodsapproximatefullfine-tuningwithfewerpa-
ThisworkaimstostimulateresearchintopreventingPre- rameters. SomerecentworkscombinemultiplePEFTmod-
FTweightleakageandtheassociatedrisksintermsofmodel els[16,20,32,43,54],hopingtoleveragethestrengthsof
safetyandalignment. Tofacilitatethisresearch,weintro- individualmodels. LoRA[19]isperhapsthemostpopular
duceLoWRABench,acomprehensivebenchmarkcompris- PEFTmethodandisknownforitseffectivenessacrossvar-
ingdatasetsandevaluationmetrics,designedforassessing ious tasks and modalities [1, 38, 49, 55], sometimes even
Pre-FTweightrecoverymethods. outperformingfullfine-tuning. Givenitspopularity,inthis
Tosummarize,ourmaincontributionsare: paper, we focus on recovering Pre-FT weights of LoRA
1. IntroducingthetaskofPre-Fine-TuningWeightRecovery, fine-tunedmodels.
anewattackvectoragainstfine-tunedmodels.
2.2.ModelSafetyandSecurity
2. PresentingSpectralDeTuning,ahighlyeffectivemethod
forpre-fine-tuningweightrecoveryattacksagainststate-
Deeplearningmodelshavevarioussafetyandsecurityvul-
of-the-artmodels.
nerabilities. Membershipinferenceattacksaimtodetectif
3. Providing LoWRA Bench, a comprehensive suite of
specificdatasampleswereusedintraining[41,44]. Model
datasetsandmetricsdesignedfortheevaluationofpre-
inversionattemptstogeneratethesamplesusedduringtrain-
fine-tuningweightrecoverymethods.
ing [13, 14]. Machine unlearning protects against attacks
byremovingtheeffectofspecifictrainingsampleswithout
2.RelatedWorks
retrainingtheentiremodel[3]. Modelextraction,ormodel
stealing,involvesstealingatargetmodelhiddenbehindan
2.1.ModelFine-tuning
API by querying it multiple times [42, 47]. In contrast,
Modelfine-tuning,crucialindeeplearningresearch[2,58, Pre-FTweightrecoveryaimstorecovertheexactweights
59], can be resource-intensive. Parameter-Efficient Fine- of the pre-trained model, compromising the entire model
tuning (PEFT) methods [9, 17–19, 21, 22, 24, 25, 27, 28, rather than just a subset of capabilities. Additionally, our
2Do you know why cats always rub up against Please tell me about pearls. Where are they
your legs? found?
LoRA Fine-Tuning LoRA Fine-Tuning
The smell of our legs and feet, as well as the The pearl is a naturally occurring, organic gemstone.
vibrations from the rubbing, are all signals to cats It forms inside a living mollusk as a protective
that they trust and feel safe. ## Why do cats rub mechanism to a small irritant. A pearl is a hardened
their butts on your leg?... mass of calcium carbonate that is produced...
Mean LoRAs Mean LoRAs
The smell of our legs and feet, as well as the
The pearl is a naturally occurring, organic gemstone.
vibrations from the rubbing, are all signals to cats It forms within a living mollusk as a protective
that they trust and feel safe. ## Why do cats rub coating around an irritant, such as a small stone or
their butts on your leg?... parasite. Freshwater pearls are found in...
Spectral DeTuning (Ours) Spectral DeTuning (Ours)
The smell of our legs and feet, for one, is a cat's way The pearl is a gem that has been highly prized since
of identifying us. Also, the oils in our skin are ancient times. In the 19th century, the pearl industry
soothing to a cat. You can see this in action if... was primarily centered in the Persian Gulf, but today,
most pearls are cultured in...
Pre-Fine-Tuning (Ground Truth) Pre-Fine-Tuning (Ground Truth)
The smell of our legs and feet, for one, is a cat's way The pearl is a gem that has been highly prized since
of identifying us. Also, the oils in our skin are ancient times. In the 19th century, the pearl industry
soothing to a cat. You can see this in action if... was primarily centered in the Persian Gulf, but today,
most pearls are cultured in...
Figure2.MistralDPOResults:Ourmethod,SpectralDeTuning,recoversthepre-fine-tuninggenerationcapabilitieswithhighprecision,
essentiallyundoingtheDPOalignmentLoRAfine-tuning. Ingreenexactrecovery,inredunrecoveredwords. Noticethatunlikethe
baselines,ourmethodrecoversthesemanticmeaningevenwhenthegeneratedtextisnotaperfectmatch.Bestviewedincolor
method,SpectralDeTuning,operatesinanunsupervisedand low-rankmatrixtheymultiplytwofull-rankmatriceswith
data-freemanner. suitabledimensions. Thisreparametrizationdrasticallyre-
duces the number of parameters being optimized. Specif-
2.3.ModelRed-TeamingandAdversarialAttacks
ically, for a pre-trained weight matrix W ∈ Rd×k, the
P
One of the primary methods for ensuring model safety update ∆W can be decomposed into a rank r decompo-
involves incorporating human feedback through a reward sition ∆W = BA where B ∈ Rd×r,A ∈ Rr×k and
modeltrained onannotator preferences, followed byrein- r ≪ min(d,k). During fine-tuning, W P is frozen and
forcementlearningtofine-tunethemodel[7,15,31,33,40, onlyAandB arefine-tuned. Thisresultsinthefollowing
45].However,Wolfetal.[52]arguethatthesealignmentpro- forward pass W Px+∆Wx = W Px+BAx, where x is
cessesmayleaveundesiredbehaviorpartiallyintactandare theoutcomeofthepreviouslayer. SinceLoRAislinearby
thusvulnerabletoadversarialpromptingattacks. Thishas design,itispossibletomergethefine-tunedmatricesback
beendemonstratedbyredteaming[15,31]andadversarialat- intotheoriginalmatrix
tacks[5,51,62]approaches. Unliketargetedattacks,Pre-FT
W′ =W +BA (1)
weightrecoverycompromisestheentiremodelbyrestoring P
the pre-trained weights. Moreover, our method, Spectral ,thusintroducingnoadditionalparametersorinferencela-
DeTuning,doesnotrequirerunninginferencethroughthe tencytotheoriginalmodel. Originally,LoRAwasapplied
model. tothequeryandvaluelayersofattentionblocks;however,
ithasbeendemonstratedthatLoRAcanbeeffectivelyex-
3.Preliminaries-LoRA tendedtoadditionallayers. Oncemerged,currentmodels
implicitlyassumethatrecoveringW andBAfromW′is
Fine-tuningdeepnetworkstraditionallyconsistedoftrain- P
impossible. Throughoutthepaper,wheneverwereferto
ing all the network weights initialized by a pre-trained
theweightsofaLoRAfine-tunedmodel,weassumethe
model. As this is costly for large-scale models, Hu et al.
weightshavebeenmergedbackasseeninEq.1.
[19]recentlyintroducedLowRankAdaptation(LoRA).The
authors postulate that the change in weights during fine-
4.ProblemDefinition
tuning often has a “low intrinsic rank”. They therefore
introduced LoRA, which transforms each parameter ma- WeintroducethetaskofPre-Fine-TuningWeightRecovery.
trix by the addition of a low-rank matrix. To create this ItsgoalistorecoverthePre-FTweightsofagivenmodel,i.e.,
3theweightsoftheoriginal,pre-trainedmodel. Specifically, LoRA Fine-Tuning
inthisworkweassumethatthefine-tuningwasperformed
usingLoRA.
Notation. Formally, consideramodelF withmfine-
P
tunedlayersthatwerefine-tunedviaarankrLoRAandorig-
inatedfromthesourcemodelP. Wedenotetheweightma-
Mean LoRAs
tricesofF by{W′(j)}m andthoseofP by{W(j)}m
P j=1 P j=1
wherebothW′(j) andW(j) are∈Rd×k. Throughoutthe
P
paperweassumetheattackerdoesnothaveaccesstoP
(nortoitsweights{W(j)}m ).
P j=1
Attacksetting. Theattackerhasaccesstotheweightsof Spectral DeTuning (Ours)
ndifferentF modelsofrankr,allLoRAfine-tunedfrom
P
thesamepre-trainedsourcemodelP. Theattacksucceeds
with precision ϵ if the attacker can accurately recover the
weightsofthepre-trainedsourcemodelP uptoanϵpreci-
(cid:110) (cid:111)n
sion. Formally,given {W′(j)}m ,theattackerneeds
i j=1 Pre-Fine-Tuning (Ground Truth)
i=1
find{W∗(j)}m suchthat
j=1
(cid:88)m (cid:13) (cid:13)W(j)−W∗(j)(cid:13)
(cid:13)<ϵ (2)
(cid:13) P (cid:13)
j=1
Figure3. StableDiffusionResults: SpectralDeTuningrecovers
WepresentanoverviewofthissettinginFig.1.
thePre-Fine-Tuningimageswithhighprecision,evenwhenusing
Successcriteria. Wemeasurethesuccessoftheattackby
“inthewild”LoRAs,essentiallyreversingthepersonalizationfine-
thedistancebetweentherecoveredweightsandtheoriginal
tuningoftheLoRAmodel
weights,inaddition,inSec.6wediscussanumberofways
tomeasurethesuccessoftheattacksemantically.
Where W ∈ Rd×k is the matrix we are optimizing to
5.SpectralDeTuning estimate W . Intuitively, the objective optimizes the de-
P
compositionofeachfine-tunedweightmatrixintoashared
We now describe our method for carrying out a Pre-FT
weightmatrixwhichistheapproximatedPre-FTmatrixand
weight recovery attack. We start by introducing our op-
anindependentlowrankresidualmatrix.
timizationobjective,followedbyouroptimizationmethod
Thisobjectiveexhibitsdesirablepropertiesforanattacker.
and finally, a rank scheduler that stabilizes the optimiza-
First,itistraining-free,meaning,itrequiresnodata,nordoes
tion and results in better convergence. For simplicity, we
it make any assumptions with regards to the data used to
omitthelayerindexsuperscript(j)andperformthesame
trainthemodel. Moreover,theoptimizationisperformedon
optimizationacrossalllayersindependently.
aper-layerbasis,enablinghighparallelizationoftheattack.
Finally,theobjectiveisunsupervised,allowinganattacker
5.1.OptimizationObjective
torecoveramodelevenwhentheyhavenopriorknowledge
TorecoverthePre-FTweights,weneedtopredictW P given regardingthesourcemodel.
n fine-tuned weight matrices {W′}n . Leveraging their
i i=1
difference of up to r principal components, we formulate 5.2.Pre-FTWeightRecoveryAlgorithm
thetaskasanoptimizationproblem,whereeachLoRApro-
WeproposeSpectralDeTuning,aniterative,gradient-free
videsadditionalconstraintsonW . Specifically,recallthat
P algorithmforPre-FTweightrecovery. Themethodisfast
accordingtoEq.1,W′canbedecomposedintoW ∈Rd×k
i (evenonCPU)andiseasilyparallelizable. Thecoreideais
andarankr matrixwhichwewilldenotebyM ∈ Rd×k.
i thatwhiletheoptimizationprobleminEq.3isnon-convex,
TakingintoaccountallndifferentLoRAweights,wedefine
itcanbeiterativelybrokendownintoasetofsimplesub-
thefollowingobjective
problemswhichhaveclosed-formsolutions. Ourprocedure
hasthreemajorcomponents: initialization,M-stepandW-
n step. Note,solvingEq.3requiresoptimizingn+1matrices,
arg min (cid:88) ∥W′−(W +M )∥2 s.t. rankM ≤r i.e.,W andM ,M ,...,M .
i i 2 i 1 2 n
1W ≤, iM ≤i ni=1 Initialization. Atiteration0,wesetW∗astheaverageof
(3) allthefine-tunedmatrices,i.e.,W∗ = 1 (cid:80)n W′.
n i=1 i
4M-step. Wesolvetheoptimizationproblembycoordinate Algorithm1PyTorchPseudocodeforSpectralDeTuning
descent[53]. WefirstfixW∗andsolvefor{M }n . Note
i i=1 # W_ps: List of n fine-tuned weight matrices
thatwhenW∗isgiven,theoptimizationproblemsforeach
# steps: Number of optimization steps
M ,..,M aredecoupled. Specifically,ateachiteration,the # r: LoRA rank
1 n
optimizationproblemforM is: # Initialize W_star
i W_s = torch.mean(torch.stack(W_ps), axis=0)
# Perform optimization
M∗ =argmin∥(W′−W∗)−M ∥2 s.t. rankM ≤r for step in range(steps):
i i i 2 i # M-step
Mi
(4)
# M_A spp =ro [x Wi _m pat -e We _a sch foM rˆ* W_ _i
p
( iE nq. W_5 p)
s]
Luckily,thesolutiontothisoptimizationproblemisavail-
# Truncate each Mˆ*_i to rank <= r (Eq. 5)
able in closed-form and is given by the “Singular Value for i in range(len(M_s)):
(U, S, V) = torch.svd_lowrank(M_s[i], q=r)
Decomposition”(SVD)ofW i′−W∗. Theoptimalvalueof M_s[i] = (U @ torch.diag_embed(S)) @ V.T
M is:
i
# W-step
# Approximate W_star (Eq. 7)
U ,Σ ,VT =SVD(W′−W∗) (5) W_s = [W_p - M_si for (W_p, M_si) in zip(W_ps, M_s)]
i i i i W_s = torch.mean(torch.stack(W_s), axis=0)
M∗ =U Σ VT
i i i|r i
WhereΣ representsthetoprsingularvaluesΣ .
i|r i 6.1.Dataset
W-step. ByfixingthevaluesofM∗,..,M∗,wecaneasily
1 n
computetheoptimalvalueofW. Theoptimizationproblem Our dataset encompasses three pre-trained representative
isgivenby: sourcemodels: aVisionTransformer(ViT)[11]trainedon
ImageNet-1K[39],Mistral-7B-v0.1[23],andStableDiffu-
n
W∗ =argmin(cid:88) ∥(W′−M∗)−W∥2 (6) sion1.5[35]. Thesemodelscollectivelycoversupervised
i i 2
W and self-supervised objectives, spanning both vision and
i=1
naturallanguageprocessing(NLP)domains,aswellasgen-
Bysimplecalculus,theclosed-formsolutionis:
erativeanddiscriminativetasks. Notably,thesemodelsare
1 (cid:88)n widelyusedanddeployedinnumerousproductionsystems.
W∗ =
n
(W i′−M i∗) (7) SeeTab.1foranoverviewofthedataset.
i=1 Foreachsourcemodel,wecurate15LoRAmodelsfine-
WeiteratebetweentheM-stepandW-stepuntilconver- tunedondiversedatasets,tasks,andobjectives. Thedataset
gence. As shown in Alg. 1, the algorithm can be easily comprises a diverse array of layer types, including self-
implementedinaslittleas8linesofpython. attention,cross-attention,andMLPs. Thisdiversityenables
ustoassessthegeneralizationcapabilitiesofPre-FTmeth-
5.3.RankScheduler
ods. Theevaluationcanbeconductedonaper-modelbasis,
ThealgorithmproposedinSec.5.2tendstoperformwell per layer type, or per layer depth, allowing for a compre-
ingeneral. However,weempiricallyfoundthatsolvingthe hensive analysis of Pre-FT methods. Overall, our dataset
optimization problem with high ranks can result in slow includes544sourcemodellayers. Whentakingintoaccount
andinaccurateconvergence. Wethereforeintroducearank thefine-tunedLoRAlayers,thedatasetincludesover8,000
scheduler. The idea of the rank scheduler is to start by layers. ForfurtherdetailsseeApp.D.
forcingM tobeofrankr∗ <r,allowingSpectralDeTuning
i
6.2.NumericEvaluationMetrics
tofocusonthemostsignificantprincipalcomponentsfirst.
r∗ is increased according to a schedule until finally r∗ =
WeightError(W-Error). Wemeasurenumericconvergence
r. Specifically, we use an “Increase on Plateau” type of
bythemeansquaredweighterror(asdefinedinEq.2)and
scheduler where the rank is increased whenever the loss
averageacrossalllayersinlogspace:
termfromEq.3plateaus. FormoredetailsseeApp.E.We
s rah no kw se chm ep di ur li ec ral il my pin roS vee sc. th7 e.4 rath teat anth de qre uaa lr ie tyc oa fse cs ow nvh ee rgre enth ce
e
m1 (cid:88)m (cid:16)
log
10(cid:16)
MSE(W
P(j)−W∗(j)(cid:17)(cid:17)
(8)
significantly. j=1
Weuselog-spaceaswhenerrorsareverysmall,theaverage
6.LoWRABench
meansquaredweighterrorisdeterminedbyoutliers,e.g.,a
WepresentLoRAWeightRecoveryAttack(LoWRA)Bench, singlenon-converginglayerwhenallotherlayersconverge.
a comprehensive benchmark designed to evaluate Pre-FT Logtransformingthemeansquarederrorisrobusttosuch
weightrecoverymethods. outliers.WevisualizethisinFig.4whereSpectralDeTuning
5Spectral DeTuning Mean LoRAs
30
s25
er W-Error: -17.634 W-Error: -7.437
y20
La MSE: 3.395e-09 MSE: 1.525e-07
f
15
o Semantic: 0.014 Semantic: 0.495
# 10
5
0
−18 −16 −14 −12 −10 −8 −6
W-Error
Figure4.MotivationfortheLoginW-Error:WevisualizetheconvergenceofalllayersusingSpectralDeTuningandtheMeanLoRAs
baselines. SpectralDeTuningclearlyconvergestoamuchbettersolutionforalmostalllayers. NotethatMSEdoesnotsummarizethe
convergencewellasityieldsthevalueofthepoorlyconvergingoutlierlayers. TheW-Errorbetterconveystheactualconvergenceby
workinginlog-space.Resultsforarandomsubsetof5StableDiffusionLoRAs
Table1. LoWRABenchDatasetSummary: Thedatasetcovers the Sentence-BERT [34] (SBERT) textual embeddings of
widelyusedmodelsspanningvisionandlanguagemodalities. It text generated by the Pre-FT model and by the recovered
includesover540Pre-FTlayersandover8,000fine-tunedlayers
model. We report the mean log cosine for the first 100
promptsoftheAlpacaFarmevaluationbenchmark[12].
Pre-FT #Pre-FT #FT 6.4.ExperimentalSetup
Task Fine-tuningTask
Model Layers Layers
Subsets. Ineachexperiment,wespecifyanumberofLoRA
ViT Classific. VTAB-1K 24 360
fine-tuned models L, which is often lower than the total
SD1.5 T2IGen. Personalization 264 3960
numberofLoRAsavailableinthedatasets. Wedothisby
Mistral TextGen. UltraChatSFT 128 1920
randomly sampling a set of L models from the datasets.
Mistral TextGen. UltraFeedbackDPO 128 1920
We then perform the Pre-FT weight recovery method on
this subset. We repeat this experiment (including subset
sampling)10times. Thereportedperformancemetricsare
theaverageandstandarddeviationovertheexperiments.
clearlyconvergestoamuchbettersolution. Despitetheout-
Baselines. Thetwobaselinemethodsarei)usingoneof
standingconvergence,thesmallnumberofoutlierscreatea
the fine-tuned LoRA models; we average the results over
falseimpressionwheretheMSEshowsasignificantlyhigher
allmodelsinthesampledsubset. ii)averagingtheweights
error. InApp.CweshowthattheW-Errorisstronglycorre-
across all LoRA fine-tuned models in the sampled subset
latedwiththerecoveryofthePre-FTsemanticcapabilities
andreportingtheresultsoftheweightaveragedmodel. The
(ρ=0.880forW-Errorvs. LPIPS).
motivationbehindthemeanLoRAbaseline,istheassump-
6.3.SemanticEvaluationMetrics tion that the mean of the residuals is the zero matrix, i.e.,
1 (cid:80)n M =0. InthiscasetheoptimumofEq.3becomes
n i=1 i
We design model specific metrics focusing on the Pre-FT theaverageofalltheweights.
taskfromasemanticperspective.
ViT Activation Distance (Act.-Dist.). We take the cosine 7.Experiments
distancebetweentheactivationsofthePre-FTmodeland
7.1.PreliminaryInvestigationonViT
thoseoftherecoveredone. Specifically,wetakethemean
ofalltransformertokensattheendofthelasttransformer WebeginourexplorationofPre-FTweightrecoveryusing
block. Weuseasubsetof5000imagesfromtheImageNet ViT, due to its simple architecture with consistent weight
validationset. dimensionsandrelativelysmallmodelsize.Whilethisisour
StableDiffusionLPIPS(LPIPS).TheLPIPS[61]distance simplesttask,itisnota“toyexample”butarealmodelthat
betweenimagesgeneratedbythePre-FTmodelandbythe iswidelyusedanddeployedincountlessproductionsettings.
recoveredmodel. WereportthemeanLPIPSforthefirst100 InTab.2weshowtheresultsforn=5fine-tunedLoRAs.
promptsoftheCOCOCaptionsvalidationdataset[6]. Asexpected,theLoRAfine-tunedmodelsareindeeddiffer-
MistralSBERT(SBERT).Thelogcosinedistancebetween entfromthePre-FTmodel. AveragingoverseveralLoRA
6Table2. ViTResults: Asexpected,theLoRAfine-tunedmodels Table3. StableDiffusionResults: SpectralDeTuningisalmost
havedriftedawayfromtheinitialweightsandactivations. The threetimesbetterthanthebaselines,recoveringalargeportionof
meanoftheLoRAsisslightlybetter,butisstillfarfromthePre-FT thesemanticcapabilitiesofthepre-fine-tuningStableDiffusion.
model.Incontrast,SpectralDeTuningachievesanalmostperfect Reportedresultsusen=5fine-tunedLoRAstakenfromanonline
semantic convergence. Reported results use n = 5 fine-tuned LoRAmarketplace
LoRAs
Method W-Error↓ LPIPS↓
Method W-Error↓ Act.-Dist. ↓
LoRAFT -6.921±1.080 0.514±0.047
LoRAFT -4.602±0.110 1e-1±9e−2 MeanLoRA -7.540±1.099 0.482±0.012
MeanLoRA -5.214±0.114 5e-2±1e−2 SpectralDeTuning -17.816±2.126 0.009±0.006
SpectralDeTuning -15.942±1.889 1e-6±3e-6
Table4.MistralResults:SpectralDeTuningrecoversthePre-FT
weightsandsemanticcapabilitieswithhighprecision,bothinthe
models slightly improves the results, but is still far from
supervisedfine-tuning(SFT)stageandthealignmentfine-tuning
recovering the Pre-FT activations. Our method, Spectral
stage(DPO).Reportedresultsusen=12fine-tunedLoRAsfor
DeTuning,performsmuchbetterandattainsanalmostper- SFTandn=8fine-tunedLoRAsforDPO
fectsemanticconvergence,outperformingthebaselinesbya
widemargin.
Method W-Error↓ SBERT↓
7.2.IntheWildWeightRecoveryofStableDiffusion
LoRAFT -8.677±0.153 -0.994±0.731
Havingshownthevulnerabilityofanimageclassification MeanLoRA -9.299±0.222 -1.007±0.726
model, we now test the vulnerability of Stable Diffusion, SpectralDeTuning -16.502±1.855 -9.324±6.942
a multi-modal text-to-image model. To this end, we used
LoRAFT -9.903±0.166 -3.058±4.763
publiclyfine-tunedLoRAsfoundoncivitai,allowingusto
MeanLoRA -10.757±0.178 -3.455±5.171
validateourmethod“inthewild”. AsinthecaseofViT,the
SpectralDeTuning -22.062±1.180 -14.708±3.123
baselinesperformpoorlyonallmetrics. Incontrast,Spectral
DeTuningrecoversthePre-FTweightswithhighprecision.
Thisresultsinasignificantimprovementoftherecovered
semantic capabilities of the Pre-FT model while using as
BasedonFig.5weobservethreephenomena,i)Therank
littleasn=5fine-tunedLoRAs(SeeTab.3andFig.3).
schedulerdrasticallyacceleratestheconvergence,ii)When
Implication: SoTApersonalizationmethodsusingLoRA
using the rank scheduler, there is much less variance be-
arevulnerabletoPre-FTweightrecoveryattacks.
tween the convergence of different layers, and iii) Using
therankschedulerresultsinahigherprecisionconvergence.
7.3.Pre-FTWeightRecoveryofanAlignedLLM
Fig. 6 visualizes phenomena (ii) and (iii) by showing the
Havingachievedsuccesswithmid-sizedimagemodels,we cumulativepercentoflayers(yaxis)thatconvergetoagiven
now investigate the ability of our method to scale up to a W-Errorlevel(xaxis). Whenusingtherankscheduler,over
large-scalealignedLLM.Specifically,weuseMistral-7B,a 95%ofthelayersconvergewithaprecisionofatleast−16,
topperformingopen-sourceLLM.Followingcommonprac- incontrasttolessthan40%whennotusingthescheduler.
tice,wefine-tunethemodelintwostages,firstperforming Moreover,byusingtherankscheduler,somelayersconverge
supervisedfine-tuning(SFT)followedbyadirectpreference toamoreprecisesolution.
optimization(DPO)alignmentfine-tuningstage[33]. We W-Errorvs. Loss. Inrealityanattackerhasnoaccessto
report the results of both stages in Tab. 4, as we can see, theerrorandcanonlymeasurethelossinEq.3. Toshowthe
SpectralDeTuningsuccessfullyrecoverstheweightswith lossaccuratelyreflectstheerrordefinedinEq.2,wemeasure
highprecision. Thishighqualityrecoveryisalsoexpressed theirrelationandfindtheyarealmostperfectlycorrelated
inrecoveringthesemanticcapabilitiesofthePre-FTmodel. (ρ=0.994). ForfurtherdetailsseeApp.B.
I.e.,theestimatedweightsyieldamodelwhichprovidesre-
sponsesthatareverysimilartothePre-FTmodelandmuch
8.DiscussionandLimitations
moresothantheLoRAfine-tunedmodel(SeeFig.2).
Implication: SoTALLMsthatuseLoRAforalignment NumberofLoRAs. SpectralDeTuningrequiresseveralLo-
fine-tuningarevulnerabletoPre-FTweightrecoveryattacks. RAstorecoverthePre-FTweights. InFig.7weillustrate
theimpactofthenumberoffine-tunedLoRAmodelsonthe
7.4.Ablations
W-Errorconvergence. NotethatdifferentW-Errorvaluesare
RankSchedulerAblation. Weablatetherankschedulerin- notcomparableacrossmodels,e.g.,MistralDPOobtainsa
troducedinSec.5.3usingtheStableDiffusionexperiment. lowestW-Errorbutonlysemanticallyconvergeswhenusing
7
TFS
OPDw. Rank Scheduler w/o Rank Scheduler w. Rank Scheduler w/o Rank Scheduler Mean LoRA LoRA FT
−6
100 98.1 %
−8
−10 80
W-Error −−− 111 642
%
of
Layers
46 00
39.54 %
−18
20
−20
0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 0
Iteration −21 −20 −19 −18 −17 −16 −15 −14 −13 −12 −11 −10 −9 −8 −7 −6
W-Error
Figure5. RankSchedulerConvergenceSpeed: Usingtherank
Figure6.RankSchedulerConvergenceQuality:Whenusingthe
schedulerhasthreebenefits,i)acceleratedconvergence,ii)less
rankscheduler,over95%ofthelayersconvergewithaprecision
variance between layers, and iii) higher precision convergence.
ofatleast−16,incontrasttolessthan40%withoutthescheduler
Herewevisualizei),seeFig.6foralayer-wisevisualization
Mistral DPO Mistral SFT Stable Diffusion ViT
−4
−6
8LoRAs(SeeFig.11). InApp.Awestudytheeffectsof
−8
thenumberofLoRAsonthesemanticconvergenceforall
−10
LoWRABenchsubsets. Weanticipatethatfuturemethods or−12
willincorporateadditionalconstraintstoreducetherequired
W-Err
−14
−16
numberofLoRAs.
−18
LoRARank. ThispaperassumesaconstantLoRArankr −20
acrossallnLoRAmodels,whichisknowntotheattacker. −22
Future work could investigate using models with varying, 2 3 4 5 6 7 8 9 10 11 12 13 14 15
# of LoRAs
unknownLoRAranks.
PublicAvailabilityofLoRAFine-tunedModels. Weassume Figure7. EffectoftheNumberofLoRAsonW-ErrorConver-
theavailabilityofmultipleLoRAfine-tunedmodelsorigi- gence:ForthesemanticequivalentseeApp.A
natingfromthesamepre-fine-tuningmodel. Thisisarea-
sonableassumptionastherearemodel“marketplaces”such
likeMistralandStableDiffusion. WeintroducedLoWRA
asHuggingFaceandcivitai,wheremanyLoRAfine-tuned
Bench and discussed future directions to promote further
modelsarepubliclyavailable. TheseLoRAmodelsoften
research. Byhighlightingthisvulnerability,wehopetoen-
sharethesamesourcePre-FTmodel,whichfitsourproposed
couragetheresearchcommunitytodevelopbetterdefenses
settingperfectly.
againstsuchattacks.
Other Types of Fine-tuning. While our focus has been on
exposingthevulnerabilityofLoRAfine-tunedmodels,nu- 10.BroaderImpact
merousotherparameter-efficientfine-tuningmethodsexist.
The general case of Pre-FT weight recovery of fully fine- Thisworkuncoversasignificantvulnerabilityinfine-tuned
tunedmodelsisthemostgeneralandprobablyhardestcase. models,allowingattackerstoaccesspre-fine-tuningweights.
Extendingthescopeofourattacktoencompassthesemeth- While this discovery reveals potential security risks, our
odspresentsanexcitingavenueforresearch. primaryobjectiveistoadvancethefieldofMachineLearning
Pre-FTWeightRecoveryDefense. Wedonotknowofade- andraiseawarenesswithintheresearchcommunityabout
fenseagainstthisattack. Also,asthisattacktargetspublicly theexistingvulnerabilitiesincurrentmodels.
availablemodels,onceavulnerabilityisidentified,thereis Insteadofusingthefindingsofthisstudytoexecuteat-
no option to retract the model. However, we remain opti- tacks,weadvocatefortheirusebymodelcreatorstoenhance
misticthatadefensewillbediscoveredinthefuture. For thesafetyandsecurityoftheirmodels. Byacknowledging
instance, modifying training such that an infeasible high andaddressingvulnerabilities,creatorscanproactivelysafe-
numberofLoRAswillberequiredforaccuraterecovery. guardagainstpotentialthreats.
Furthermore,inthediscussionsection,weoutlinepoten-
9.Conclusion tial future directions and mitigation strategies. Following
establishedpracticesinthecybersecuritycommunity,we
In this paper, we unveiled a new vulnerability in LoRA emphasizetheimportanceofopendiscussionandencourage
fine-tunedmodels,allowingattackerstorecoverthePre-FT thereportingofvulnerabilities. Byfosteringtransparency
weightsusingmultiplemodels.Ourmethod,SpectralDeTun- andcollaboration,wecancollectivelycreateasaferenviron-
ing,demonstratesthisvulnerabilityonlarge-scalemodels mentfordeployingmachinelearningmodels.
8References formethodsthatlearnfromhumanfeedback. arXivpreprint
arXiv:2305.14387,2023. 6,14
[1] OmriAvrahami,KfirAberman,OhadFried,DanielCohen-
[13] Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin,
Or,andDaniLischinski. Break-a-scene:Extractingmultiple
DavidPage,andThomasRistenpart. Privacyinpharmacoge-
concepts from a single image. In SIGGRAPH Asia 2023
netics:An{End-to-End}casestudyofpersonalizedwarfar
ConferencePapers.AssociationforComputingMachinery,
indosing. In23rdUSENIXsecuritysymposium(USENIX
2023. 2
Security14),pages17–32,2014. 2
[2] OmriAvrahami,ThomasHayes,OranGafni,SonalGupta, [14] MattFredrikson,SomeshJha,andThomasRistenpart.Model
YanivTaigman,DeviParikh,DaniLischinski,OhadFried, inversionattacksthatexploitconfidenceinformationandbasic
andXiYin.Spatext:Spatio-textualrepresentationforcontrol- countermeasures. InProceedingsofthe22ndACMSIGSAC
lableimagegeneration.InProceedingsoftheIEEE/CVFCon- conferenceoncomputerandcommunicationssecurity,pages
ferenceonComputerVisionandPatternRecognition(CVPR),
1322–1333,2015. 2
2023. 2
[15] Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda
[3] Lucas Bourtoule, Varun Chandrasekaran, Christopher A Askell,YuntaoBai,SauravKadavath,BenMann,EthanPerez,
Choquette-Choo,HengruiJia,AdelinTravers,BaiwuZhang, NicholasSchiefer,KamalNdousse,etal. Redteaminglan-
DavidLie,andNicolasPapernot. Machineunlearning. In guagemodelstoreduceharms:Methods,scalingbehaviors,
2021IEEESymposiumonSecurityandPrivacy(SP),pages andlessonslearned. arXivpreprintarXiv:2209.07858,2022.
141–159.IEEE,2021. 2 3
[4] CollinBurns,PavelIzmailov,JanHendrikKirchner,Bowen [16] YuchaoGu,XintaoWang,JayZhangjieWu,YujunShi,Yun-
Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, peng Chen, Zihan Fan, Wuyou Xiao, Rui Zhao, Shuning
Adrien Ecoffet, Manas Joglekar, Jan Leike, et al. Weak- Chang,WeijiaWu,etal. Mix-of-show: Decentralizedlow-
to-strong generalization: Eliciting strong capabilities with rankadaptationformulti-conceptcustomizationofdiffusion
weaksupervision. arXivpreprintarXiv:2312.09390,2023. 1 models. arXivpreprintarXiv:2305.18292,2023. 2
[5] NicholasCarlini,MiladNasr,ChristopherAChoquette-Choo, [17] Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-
MatthewJagielski,IrenaGao,AnasAwadalla,PangWeiKoh, Kirkpatrick,andGrahamNeubig. Towardsaunifiedviewof
DaphneIppolito,KatherineLee,FlorianTramer,etal. Are parameter-efficienttransferlearning. ArXiv,abs/2110.04366,
alignedneuralnetworksadversariallyaligned? arXivpreprint 2021. 2
arXiv:2306.15447,2023. 1,3 [18] NeilHoulsby,AndreiGiurgiu,StanislawJastrzebski,Bruna
[6] XinleiChen,HaoFang,Tsung-YiLin,RamakrishnaVedan- Morrone,QuentinDeLaroussilhe,AndreaGesmundo,Mona
tam,SaurabhGupta,PiotrDolla´r,andCLawrenceZitnick. Attariyan, and Sylvain Gelly. Parameter-efficient transfer
Microsoft coco captions: Data collection and evaluation learningfornlp. InInternationalConferenceonMachine
server. arXivpreprintarXiv:1504.00325,2015. 6,14 Learning,pages2790–2799.PMLR,2019.
[19] EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,
[7] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic,
YuanzhiLi,SheanWang,LuWang,andWeizhuChen. Lora:
ShaneLegg,andDarioAmodei.Deepreinforcementlearning
Low-rankadaptationoflargelanguagemodels.arXivpreprint
fromhumanpreferences. Advancesinneuralinformation
arXiv:2106.09685,2021. 1,2,3
processingsystems,30,2017. 1,3
[20] ChengsongHuang,QianLiu,BillYuchenLin,TianyuPang,
[8] Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Wei
ChaoDu,andMinLin. Lorahub: Efficientcross-taskgen-
Zhu,YuanNi,GuotongXie,ZhiyuanLiu,andMaosongSun.
eralization via dynamic lora composition. arXiv preprint
Ultrafeedback:Boostinglanguagemodelswithhigh-quality
arXiv:2307.13269,2023. 2
feedback. arXivpreprintarXiv:2310.01377,2023. 13
[21] NamHyeon-Woo,MoonYe-Bin,andTae-HyunOh. Fedpara:
[9] TimDettmers,ArtidoroPagnoni,AriHoltzman,andLuke
Low-rankhadamardproductforcommunication-efficientfed-
Zettlemoyer. Qlora: Efficientfinetuningofquantizedllms.
eratedlearning. arXivpreprintarXiv:2108.06098,2021. 2
arXivpreprintarXiv:2305.14314,2023. 2
[22] MenglinJia,LumingTang,Bor-ChunChen,ClaireCardie,
[10] Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, SergeBelongie,BharathHariharan,andSer-NamLim.Visual
ShengdingHu,ZhiyuanLiu,MaosongSun,andBowenZhou. prompttuning. InEuropeanConferenceonComputerVision,
Enhancingchatlanguagemodelsbyscalinghigh-qualityin- pages709–727.Springer,2022. 2,13
structionalconversations. arXivpreprintarXiv:2305.14233, [23] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch,
2023. 13 ChrisBamford,DevendraSinghChaplot,DiegodelasCasas,
[11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, FlorianBressand,GiannaLengyel,GuillaumeLample,Lucile
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Saulnier,etal. Mistral7b. arXivpreprintarXiv:2310.06825,
MostafaDehghani,MatthiasMinderer,GeorgHeigold,Syl- 2023. 5
vainGelly, etal. Animageisworth16x16words: Trans- [24] BrianLester,RamiAl-Rfou,andNoahConstant. Thepower
formers for image recognition at scale. arXiv preprint ofscaleforparameter-efficientprompttuning. arXivpreprint
arXiv:2010.11929,2020. 5 arXiv:2104.08691,2021. 2
[12] YannDubois,XuechenLi,RohanTaori,TianyiZhang,Ishaan [25] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimiz-
Gulrajani,JimmyBa,CarlosGuestrin,PercyLiang,andTat- ing continuous prompts for generation. arXiv preprint
sunoriBHashimoto. Alpacafarm:Asimulationframework arXiv:2101.00190,2021. 2
9[26] PeiqinLin,ShaoxiongJi,Jo¨rgTiedemann,Andre´FTMartins, KfirAberman. Hyperdreambooth: Hypernetworksforfast
andHinrichSchu¨tze.Mala-500:Massivelanguageadaptation personalization of text-to-image models. arXiv preprint
oflargelanguagemodels. arXivpreprintarXiv:2401.13303, arXiv:2307.06949,2023. 2
2024. 1 [39] OlgaRussakovsky,JiaDeng,HaoSu,JonathanKrause,San-
[27] HaokunLiu,DerekTam,MohammedMuqeeth,JayMohta, jeevSatheesh,SeanMa,ZhihengHuang,AndrejKarpathy,
TenghaoHuang,MohitBansal,andColinARaffel. Few-shot Aditya Khosla, Michael Bernstein, et al. Imagenet large
parameter-efficientfine-tuningisbetterandcheaperthanin- scalevisualrecognitionchallenge. Internationaljournalof
contextlearning. AdvancesinNeuralInformationProcessing computervision,115:211–252,2015. 5,13
Systems,35:1950–1965,2022. 2 [40] EliyaSegev,MayaAlroy,RonenKatsir,NoamWies,Ayana
[28] XiaoLiu,YananZheng,ZhengxiaoDu,MingDing,Yujie Shenhav,YaelBen-Oren,DavidZar,OrenTadmor,JacobBit-
Qian,ZhilinYang,andJieTang. Gptunderstands,too. AI terman,AmnonShashua,etal.Alignwithpurpose:Optimize
Open,2023. 2 desiredpropertiesinctcmodelswithageneralplug-and-play
[29] SourabMangrulkar,SylvainGugger,LysandreDebut,Younes framework. arXivpreprintarXiv:2307.01715,2023. 3
Belkada, Sayak Paul, and Benjamin Bossan. Peft: State- [41] AvitalShafran,ShmuelPeleg,andYedidHoshen. Member-
of-the-artparameter-efficientfine-tuningmethods. https: ship inference attacks are easier on difficult problems. In
//github.com/huggingface/peft,2022. 13 ProceedingsoftheIEEE/CVFInternationalConferenceon
[30] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,Car- ComputerVision(ICCV),pages14820–14829,2021. 2
rollWainwright,PamelaMishkin,ChongZhang,Sandhini [42] AvitalShafran,IliaShumailov,MuratAErdogdu,andNicolas
Agarwal,KatarinaSlama,AlexRay,etal. Traininglanguage Papernot. Beyondlabelingoracles: Whatdoesitmeanto
modelstofollowinstructionswithhumanfeedback.Advances stealmlmodels? arXivpreprintarXiv:2310.01959,2023. 2
inNeuralInformationProcessingSystems,35:27730–27744,
[43] VirajShah,NatanielRuiz,ForresterCole,ErikaLu,Svetlana
2022. 1
Lazebnik,YuanzhenLi,andVarunJampani. Ziplora: Any
[31] EthanPerez,SaffronHuang,FrancisSong,TrevorCai,Ro-
subjectinanystylebyeffectivelymergingloras. 2023. 2
manRing,JohnAslanides,AmeliaGlaese,NatMcAleese,
[44] RezaShokri,MarcoStronati,CongzhengSong,andVitaly
andGeoffreyIrving. Redteaminglanguagemodelswithlan-
Shmatikov. Membershipinferenceattacksagainstmachine
guagemodels. arXivpreprintarXiv:2202.03286,2022. 1,
learningmodels. In2017IEEEsymposiumonsecurityand
3
privacy(SP),pages3–18.IEEE,2017. 2
[32] RyanPo,GuandaoYang,KfirAberman,andGordonWet-
[45] SimengSun,DhawalGupta,andMohitIyyer. Exploringthe
zstein. Orthogonaladaptationformodularcustomizationof
impactoflow-rankadaptationontheperformance,efficiency,
diffusionmodels. arXivpreprintarXiv:2312.02432,2023. 2
andregularizationofrlhf. arXivpreprintarXiv:2309.09055,
[33] RafaelRafailov,ArchitSharma,EricMitchell,StefanoEr-
2023. 3
mon, Christopher D Manning, and Chelsea Finn. Direct
[46] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,Am-
preferenceoptimization:Yourlanguagemodelissecretlya
jadAlmahairi,YasmineBabaei,NikolayBashlykov,Soumya
rewardmodel. arXivpreprintarXiv:2305.18290,2023. 1,3,
Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2:
7
Openfoundationandfine-tunedchatmodels. arXivpreprint
[34] NilsReimersandIrynaGurevych. Sentence-bert:Sentence
arXiv:2307.09288,2023. 1
embeddingsusingsiamesebert-networks. InProceedingsof
the2019ConferenceonEmpiricalMethodsinNaturalLan- [47] FlorianTrame`r,FanZhang,AriJuels,MichaelKReiter,and
guageProcessing.AssociationforComputationalLinguistics, ThomasRistenpart. Stealingmachinelearningmodelsvia
2019. 6 prediction {APIs}. In 25th USENIX security symposium
(USENIXSecurity16),pages601–618,2016. 2
[35] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bjo¨rn Ommer. High-resolution image [48] LewisTunstall,EdwardBeeching,NathanLambert,Nazneen
synthesis with latent diffusion models. In Proceedings of Rajani,KashifRasul,YounesBelkada,ShengyiHuang,Le-
theIEEE/CVFconferenceoncomputervisionandpattern androvonWerra,Cle´mentineFourrier,NathanHabib,etal.
recognition,pages10684–10695,2022. 5 Zephyr: Directdistillationoflmalignment. arXivpreprint
arXiv:2310.16944,2023. 13
[36] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten
Sootla,ItaiGat,XiaoqingEllenTan,YossiAdi,JingyuLiu, [49] ZhengyiWang,ChengLu,YikaiWang,FanBao,Chongxuan
TalRemez,Je´re´myRapin,etal. Codellama:Openfounda- Li,HangSu,andJunZhu. Prolificdreamer:High-fidelityand
tionmodelsforcode.arXivpreprintarXiv:2308.12950,2023. diversetext-to-3dgenerationwithvariationalscoredistilla-
1 tion. ArXiv,abs/2305.16213,2023. 2
[37] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, [50] ZhenWang, RameswarPanda, LeonidKarlinsky, Rogerio
MichaelRubinstein,andKfirAberman. Dreambooth:Fine Feris,HuanSun,andYoonKim. Multitaskprompttuning
tuningtext-to-imagediffusionmodelsforsubject-drivengen- enablesparameter-efficienttransferlearning. arXivpreprint
eration. In Proceedings of the IEEE/CVF Conference on arXiv:2303.02861,2023. 2
ComputerVisionandPatternRecognition,2023. 1 [51] AlexanderWei,NikaHaghtalab,andJacobSteinhardt. Jail-
[38] NatanielRuiz,YuanzhenLi,VarunJampani,WeiWei,Tingbo broken: Howdoesllmsafetytrainingfail? arXivpreprint
Hou, YaelPritch, NealWadhwa, MichaelRubinstein, and arXiv:2307.02483,2023. 1,3
10[52] YotamWolf,NoamWies,YoavLevine,andAmnonShashua.
Fundamentallimitationsofalignmentinlargelanguagemod-
els. arXivpreprintarXiv:2304.11082,2023. 3
[53] StephenJWright. Coordinatedescentalgorithms. Mathemat-
icalprogramming,151(1):3–34,2015. 5
[54] PrateekYadav,DerekTam,LeshemChoshen,ColinRaffel,
and Mohit Bansal. Resolving interference when merging
models. arXivpreprintarXiv:2306.01708,2023. 2
[55] QinghaoYe,HaiyangXu,GuohaiXu,JiaboYe,MingYan,
Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi,
Yaya Shi, et al. mplug-owl: Modularization empowers
largelanguagemodelswithmultimodality. arXivpreprint
arXiv:2304.14178,2023. 2
[56] Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi,
Huseyin A Inan, Gautam Kamath, Janardhan Kulkarni,
Yin Tat Lee, Andre Manoel, Lukas Wutschitz, et al. Dif-
ferentially private fine-tuning of language models. arXiv
preprintarXiv:2110.06500,2021. 1
[57] XiaohuaZhai,JoanPuigcerver,AlexanderKolesnikov,Pierre
Ruyssen,CarlosRiquelme,MarioLucic,JosipDjolonga,An-
dreSusanoPinto,MaximNeumann,AlexeyDosovitskiy,etal.
Alarge-scalestudyofrepresentationlearningwiththevisual
taskadaptationbenchmark.arXivpreprintarXiv:1910.04867,
2019. 13
[58] XiaohuaZhai,XiaoWang,BasilMustafa,AndreasSteiner,
DanielKeysers,AlexanderKolesnikov,andLucasBeyer. Lit:
Zero-shottransferwithlocked-imagetexttuning. InProceed-
ingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages18123–18133,2022. 2
[59] LvminZhang,AnyiRao,andManeeshAgrawala. Adding
conditional control to text-to-image diffusion models. In
ProceedingsoftheIEEE/CVFInternationalConferenceon
ComputerVision(ICCV),pages3836–3847,2023. 1,2
[60] Qingru Zhang, Minshuo Chen, Alexander Bukharin,
Pengcheng He, Yu Cheng, Weizhu Chen, and Tuo Zhao.
Adaptivebudgetallocationforparameter-efficientfine-tuning.
arXivpreprintarXiv:2303.10512,2023. 2
[61] RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,
andOliverWang. Theunreasonableeffectivenessofdeep
featuresasaperceptualmetric. InProceedingsoftheIEEE
conferenceoncomputervisionandpatternrecognition,pages
586–595,2018. 6
[62] AndyZou,ZifanWang,JZicoKolter,andMattFredrikson.
Universalandtransferableadversarialattacksonalignedlan-
guagemodels. arXivpreprintarXiv:2307.15043,2023. 1,
3
11A.TheEffectoftheNumberofLoRAsonSemanticConvergence
WevisualizetheeffectofthenumberofLoRAsonthesemanticconvergenceforeachoftheLoWRABenchsubsets,results
areshowninFigs.8to11.
LoRA FT Mean LoRAs Spectral DeTuning
LoRA FT Mean LoRAs Spectral DeTuning
0.18 0.5
0.16
0.14 0.4
0.12
Dist.
0.1
PIPS0.3
Act.- 00 .. 00 68 L 0.2
0.04 0.1
0.02
0
0
2 3 4 5 6 7 8 9 10 11 12 13 14 15
2 3 4 5 6 7 8 9 10 11 12 13 14 15 # of LoRAs
# of LoRAs
Figure9. NumberofLoRAsvs. SemanticConvergence-Stable
Figure8.NumberofLoRAsvs.SemanticConvergence-ViT
Diffusion
LoRA FT Mean LoRAs Spectral DeTuning LoRA FT Mean LoRAs Spectral DeTuning
−1
−2 −4
−3 −6
−4
T T−8
R−5 R
E E
SB−6 SB
−10
−7
−12
−8
−9 −14
−10
2 3 4 5 6 7 8 9 10 11 12 13 14 15 2 3 4 5 6 7 8 9 10 11 12 13 14 15
# of LoRAs # of LoRAs
Figure10.NumberofLoRAsvs.SemanticConvergence-Mistral Figure11.NumberofLoRAsvs.SemanticConvergence-Mistral
SFT DPO
B.W-Errorvs. Loss
WevisualizetherelationbetweentheW-Errorandtheloglossandfindtheyarealmostperfectlycorrelated(ρ=0.994),see
Fig.12foravisualizationover200iterationsusingStableDiffusion.
−8 −8
−10 −10
or or
-Err
W
−12
W-Err
−12
−14 ρ=0.994 −14 ρ=0.880
−16 −16
−15 −14 −13 −12 −11 −10 −9 −8 0.03 0.06 0.09 0.12 0.15 0.18 0.21 0.24 0.27 0.3 0.33 0.36 0.39
Log Loss LPIPS
Figure12.W-Errorvs.Loss-StableDiffusion Figure13.W-Errorvs.LPIPS
12C.W-Errorvs. LPIPS
WevisualizetherelationbetweentheW-ErrorandLPIPSandfindtheyarestronglycorrelated(ρ=0.880),seeFig.13fora
visualizationover200iterationsusingStableDiffusion.
D.LoWRABenchDataset
WenowelaborateontheimplementationdetailsoftheLoWRABenchdataset.
D.1.ViTModels
As the Pre-FT model we use “vit-base-patch16-224” found on hugging face (https://huggingface.co/
google/vit-base-patch16-224). We fine-tune the model using the PEFT library [29]. For each
LoRA we use a different VTAB-1k [57] dataset, the datasets we use are: cifar100, caltech101, dtd,
flower102, pet37, svhn, patch camelyon, clevr-count, clevr-distance, dmlab, kitti,
dsprites-location, dsprites-orientation, smallnorb-azimuth, smallnorb-elevation.
We pre-process the datasets according to the protocol of Jia et al. [22] found on their github page https:
//github.com/KMnP/vpt/blob/main/VTAB_SETUP.md. We use an 80/20 train/validation split and
choosethecheckpointwiththebestvalidationloss.
Weusearankr =16andLoRAfine-tunethequeryandvaluelayers. Thisprotocolresultsin24Pre-FTmodellayers
andatotalof24·15=360LoRAfine-tunedlayers. SeeTab.5forthefine-tuninghyper-parameters.
ForsemanticevaluationweuseasubsetoftheImageNet-1K[39]validationset. Weconstructthesubsetbytakingthefirst
5imagesofeachclass,resultinginasubsetof5000.
Table5.ViTHyper-parameters
Name Value
lora rank(r) 16
lora alpha(α) 16
lr 9e−3
batch size 128
epochs 20
cifar100,caltech101,dtd,flower102,pet37,svhn,patch camelyon,
datasets clevr-count,clevr-distance,dmlab,kitti,dsprites-location,dsprites-orientation,
smallnorb-azimuth,smallnorb-elevation
D.2.MistralModels
AsthePre-FTmodelweuse“Mistral-7B-v0.1”foundonhuggingface(https://huggingface.co/mistralai/
Mistral-7B-v0.1). We fine-tune the model following the protocol of Tunstall et al. [48], note that unlike Tunstall
etal.[48],weperformLoRAfine-tuningasfoundontheirofficialgithubrepohttps://github.com/huggingface/
alignment-handbook.FollowingtheoriginalLoRAsetting,wemakeaminoradjustmenttotheoriginalhyper-parameters
oftherepoanduseaLoRAalphaof64insteadof16(i.e. α=64),thisleadstofasterandbetterconvergence. Tofine-tune15
differentmodels,weusedifferentrandomsubsetsof80%ofthefine-tuningdataset. Weuseseedsof0−14forthedifferent
fine-tunedmodels.
We follow this protocol for both the supervised fine-tuning stage (SFT) and the direct preference optimization (DPO)
alignmentstage. FollowingTunstalletal.[48],theSFTstageusestheUltraChatdataset[10]andtheDPOstageusesthe
UltraFeedbackdataset[8]. Wefirstfine-tunethe15SFTmodels,andthenfine-tunethe15DPOmodels,whereeachDPO
modelcontinuesthetrainingoftheSFTmodelwiththecorrespondingseed.
Followingtheoriginalsetup,usearankr =64andLoRAfine-tunetheq proj,k proj,v proj,ando projlayers.
Thisprotocolresultsin128Pre-FTmodellayersandatotalof128·15 = 1920LoRAfine-tunedlayersforboththeSFT
and DPO stages. See Tabs. 6 and 7 for the fine-tuning hyper-parameters. For inference we use the following decoding
hyper-parameters: max new tokens=50, do sample=True, temperature=0.7, top k=50, top p=0.95.
13Forevaluationweusethefirst100promptsfromtheAlpacaFarmbenchmark[12]foundinthefollowinglinkhttps:
//huggingface.co/datasets/tatsu-lab/alpaca_farm/viewer/alpaca_farm_evaluation. We
providethesepromptsintheSM.
Table6.MistralSFTHyper-parameters Table7.MistralDPOHyper-parameters
Name Value Name Value
lora rank(r) 64 lora rank(r) 64
lora alpha(α) 64 lora alpha(α) 64
lora dropout 0.1 lora dropout 0.1
lr 2e−5 lr 5e−6
batch size 4 batch size 2
gradient accumulation steps 128 gradient accumulation steps 32
learning rate scheduler Cosine learning rate scheduler Cosine
epochs 1 epochs 1
warmup ratio 0.1 warmup ratio 0.1
data type bfloat16 data type bfloat16
random80%of random80%of
dataset dataset
UltraChat UltraFeedback
seeds 0−15 seeds 0−15
D.3.StableDiffusionModels
AsthePre-FTmodelweuse“StableDiffusion1.5”foundonhuggingface(https://huggingface.co/runwayml/
stable-diffusion-v1-5). Wecollect15personalizationfine-tunedmodelsfromcivitai.com,apublicandwidelyused
LoRA models marketplace. This allows us to examine our method in a real world setting, for the full list of LoRAs see
Tab.8. Afterexaminingthedownloadedmodels,wededucethattheirLoRArankisr =32andthattheirfine-tunedlayers
are: to q,to v,to k,to out,proj out,proj in,andff. Resultingin192Pre-FTmodellayersforandatotalof
192·15=2880LoRAfine-tunedlayers. ForinferenceweusethedefaultStableDiffusion1.5generationpipeline(i.e. 50
samplingsteps).
For evaluation we use a the first 100 captions from the COCO Captions [6] validation dataset found in the following
link https://github.com/tylin/coco-caption/blob/master/annotations/captions_val2014.
json. WeprovidethesepromptsintheSM.
Table8.StableDiffusionFine-tunedLoRALinks
https://civitai.com/models/186716/smol-animals-lora-15sdxl?modelVersionId=241137
https://civitai.com/models/189905/pastry-lora-15sdxl?modelVersionId=241955
https://civitai.com/models/191203/bastet-egypt-cat-style-lora-15sdxl?modelVersionId=243232
https://civitai.com/models/190176/fur-pirates-lora-15sdxl?modelVersionId=241976
https://civitai.com/models/211973/cigarette-style-lora-15sdxl?modelVersionId=247079
https://civitai.com/models/233316/smol-dragons-lora-15sdxl?modelVersionId=263316
https://civitai.com/models/234324/polygon-style-lora-15sdxl?modelVersionId=264506
https://civitai.com/models/202128/overgrowth-style-lora-15sdxl?modelVersionId=264449
https://civitai.com/models/218327/mythical-creatures-lora-15sdxl?modelVersionId=289861
https://civitai.com/models/203169/lava-style-lora-15sdxl?modelVersionId=265372
https://civitai.com/models/197998/chocolate-coffee-style-lora-15sdxl?modelVersionId=259150
https://civitai.com/models/180780/crystals-lora-15sdxl?modelVersionId=238435
https://civitai.com/models/196040/transparent-glass-body-lora-15sdxl?modelVersionId=245630
https://civitai.com/models/199968/liquid-flow-style-lora-15sdxl?modelVersionId=259228
https://civitai.com/models/206783/christmas-critters-lora-15sdxl?modelVersionId=275204
14E.SpectralDeTuningImplementationDetails
Forallsemanticevaluationsweuseaseedof0forallbaselinesandforourresults. ForboththeViTsandStableDiffusion
(SD) experiments we run Spectral DeTuning for 300 optimization steps. For the Mistral SFT and DPO experiments we
use1000optimizationsteps. WebaseourrankschedulerimplementationontheofficialPyTorchimplementationofathe
ReduceLROnPlateaulearningratescheduler1. Weexpandonthehyper-parametersoftherankschedulerinTab.9.
Table9.SpectralDeTuningRankSchedulerHyper-parameters
Name ValueUsed Explanation
total steps 200forViTandSD,1000forMistral Thetotalnumberofoptimizationsteps
start rank 1 Theranktostarttheoptimizationfrom(i.e. r∗)
Thefinalrankofthescheduler
end rank 16forViTs,32forSD,64forMistral
(i.e. r,theactualrankoftheLoRAmodels)
factor 2 Themultiplicativefactortoincreasetherankby
Numberofschedulerstepswithnoimprovementafter
patience 15
whichrankwillbeincreased.
Percentofthetotal stepsafter
force end rank percent 0.5
whichend rankwillbeforced
F.RuntimeandCompute
SinceSpectralDeTuningdoesnotpassanygradientsthroughthemodel,itishighlyparallelizableandcanrecovertheweights
ofevenlargemodels(e.g.,Mistral7B)inminutesusingaclusterofdesktop-gradeGPUsorevenCPUs. Forexample,usinga
clusterofRTX2080itcanrecoverMistral-7Binunderfiveminutes.
G.DetectingtheFine-TunedLayers
Wenotethatitiseasytodetectwhichlayerswerefine-tuned. Thiscansimplybedonebycomparingthelayersweightsofn
differentfine-tunedversions. Thelayerswhichhavenotbeenfine-tunedwillbeequalacrossallnmodels,whilethefine-tuned
layerswillhavesomevariationbetweenthem.
1https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html
15H.AlgorithmwithRankScheduler
InAlg.2wepresentpytorch-likepseudocodeforSpectralDeTuningthatincludesthatrankscheduler.
Algorithm2PyTorchPseudocodeforSpectralDeTuning
# W_ps: List of n fine-tuned weight matrices
# steps: Number of optimization steps
# r: LoRA rank
# Initialize rank scheduler
current_lora_rank = 1
rank_scheduler = LoRARankScheduler(start_rank=current_lora_rank, end_rank=r)
# Initialize W_star
W_s = torch.mean(torch.stack(W_ps), axis=0)
# Perform optimization
for step in range(steps):
# M-step
# Approximate each Mˆ*_i (Eq. 5)
M_s = [W_p - W_s for W_p in W_ps]
# Truncate each Mˆ*_i to rank <= r (Eq. 5)
for i in range(len(M_s)):
(U, S, V) = torch.svd_lowrank(M_s[i], q=current_lora_rank)
M_s[i] = (U @ torch.diag_embed(S)) @ V.T
# W-step
# Approximate W_star (Eq. 7)
W_s = [W_p - M_si for (W_p, M_si) in zip(W_ps, M_s)]
W_s = torch.mean(torch.stack(W_s), axis=0)
# Compute the current loss
iteration_losses = [torch.mean((W_ps[i] - (W_s + M_s[i])) ** 2) for i in range(len(M_s))]
loss = torch.mean(torch.stack(iteration_losses), axis=0)
# Step the rank scheduler
rank_scheduler.step(loss)
current_lora_rank = rank_scheduler.current_rank
I.MistralAdditionalResults
Forthelistofmistralpromptsseesupplementarymaterial(SM).InFig.17weshowside-by-sideresultsfor10randomly
(random seed=42)sampledpromptsfromourevaluationdataset,usingthePre-FTrecoveredweightsoftheDPOfine-tuned
Mistralmodel. SeeSMfortherestoftheDPOresultsandfortheSFTresults.
J.StableDiffusionAdditionalResults
ForthelistofstablediffusionpromptsseeSM.InFigs.14to16weshowside-by-sideresultsfortheentiredataset. Note,
imagesarecompressedtoreducefilesize,forthefullresolutionimagesseetheSM.
16Figure14.StableDiffusionResults:Note,imagesarecompressedtoreducefilesize,forthefullresolutionimagesseetheSM.
17Figure15.StableDiffusionResults:Note,imagesarecompressedtoreducefilesize,forthefullresolutionimagesseetheSM.
18Figure16.StableDiffusionResults:Note,imagesarecompressedtoreducefilesize,forthefullresolutionimagesseetheSM.
19Should I get my children a nanny? I'm so
How do you get water in the desert?
exhausted.
Spectral DeTuning (Ours) Spectral DeTuning (Ours)
The only source of water in the desert is from the User 11: My kids are 2.5 and 1.5. I had 4 weeks of mat
rain, which is the main reason why the vegetation is leave, then 8 weeks of short term disability and then
scarce. The rainy season in the desert is very short, 12 weeks of unpaid leave. I was back...
only a few months of the year. ##...
Pre-Fine-Tuning (Ground Truth) Pre-Fine-Tuning (Ground Truth)
The only source of water in the desert is from the User 11: My kids are 2.5 and 1.5. I had 4 weeks of mat
rain, which is the main reason why the vegetation is leave, then 8 weeks of short term disability and then
scarce. The rainy season in the desert is very short, 12 weeks of unpaid leave. I was back...
only a few months of the year...
Please tell me about the romantic relationship between
Julius Caesar and Cleopatra. What type of soil is suitable for cactus?
Spectral DeTuning (Ours) Spectral DeTuning (Ours)
The relationship between Julius Caesar and Cleopatra Cactus like sandy, well-drained soil, but they can
was a romantic one. They met when she was just a young survive in a variety of soil types. Cactus prefer soil
girl, and he was a great military leader. Caesar was with a pH between 6.5 and 7.0. ### Do...
impressed with her intelligence and beauty, and...
Pre-Fine-Tuning (Ground Truth) Pre-Fine-Tuning (Ground Truth)
The relationship between Julius Caesar and Cleopatra Cactus like sandy, well-drained soil, but they can
was a romantic one. They met when she was just a young survive in a variety of soil types. Cactus prefer soil
girl, and he was a great military leader. Caesar was with a pH between 6.5 and 7.0. ### Do...
impressed with her intelligence and beauty, and...
Please give me a list of planets in our solar system. I I have a hard time falling asleep. Is there any
am going to choose which one I want to know more. type of music that can help me fall asleep
faster?
Spectral DeTuning (Ours) Spectral DeTuning (Ours)
User 11: How about you give me a list of planets in User 1: I'm not sure about other people, but I find the
our solar system, and I'll choose which one I want to music you listen to right before bed and as you're
know more. falling asleep to be important.
User 4: Do you think that's fair? If I listen to something I don't like or...
User 1...
Pre-Fine-Tuning (Ground Truth)
Pre-Fine-Tuning (Ground Truth) User 1: I'm not sure about other people, but I find the
The student is given a list of planets. They are to music you listen to right before bed and as you're
choose a planet they would like to know more about and falling asleep to be important.
then write a question. I have them write a question If I listen to something I don't like or...
that they think I would not be able to answer off
the...
do you think retinoid is effective on
what should i build a cabin out of?
removing the acne? because I have a lot of
it
Spectral DeTuning (Ours)
User 1: In this game, I like building cabins out of
Spectral DeTuning (Ours)
stone and wood. But if you want to build a cabin out of
User 0: It's effective, but it's not a quick fix. It
stone, I recommend using the [Stone
takes 4-8 weeks to see results and 3 months for full
Foundation](http://starbounder.org/St...
effects. If you have a lot of acne, it'...
Pre-Fine-Tuning (Ground Truth)
User 1: In this game, I like building cabins out of Pre-Fine-Tuning (Ground Truth)
stone and wood. But if you want to build a cabin out of User 0: It's effective, but it's not a quick fix. It
stone, I recommend using the [Stone takes 4-8 weeks to see results and 3 months for full
Foundation](http://starbounder.org/St... effects. If you have a lot of acne, it'...
Why did humans evolve to believe in God? What are the names of some famous actors
that started their careers on Broadway?
Spectral DeTuning (Ours)
Spectral DeTuning (Ours)
The purpose of religion is to help people understand
The first is Dustin Hoffman. He was nominated for a
the meaning of life. As the human race evolved, we
Tony Award for his Broadway debut in 1968. He also
realized that we were not alone and that there was a
appeared in the 1968 revival of “J.B.” and “The...
higher power that was greater than us.
## Why did humans evolve...
Pre-Fine-Tuning (Ground Truth)
Pre-Fine-Tuning (Ground Truth) The first is Dustin Hoffman. He was nominated for a
The purpose of religion is to help people understand Tony Award for his Broadway debut in 1968. He also
the meaning of life. As the human race evolved, we appeared in a number of plays, including The Graduate,
realized that we were not alone and that there was a All the President's Men,...
higher power that was greater than us.
## Why did humans evolve...
Figure17. NonCherry-pickedMistralDPOResults: Wedisplayside-by-sideresultsfor10randomly(random seed=42)sampled
promptsfromourevaluationdataset.Fortherestoftheresultsseesupplementarymaterial.
20