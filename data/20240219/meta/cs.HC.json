[
    {
        "title": "On-Demand Myoelectric Control Using Wake Gestures to Eliminate False Activations During Activities of Daily Living",
        "authors": "Ethan EddyEvan CampbellScott BatemanErik Scheme",
        "links": "http://arxiv.org/abs/2402.10050v1",
        "entry_id": "http://arxiv.org/abs/2402.10050v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10050v1",
        "summary": "While myoelectric control has recently become a focus of increased research\nas a possible flexible hands-free input modality, current control approaches\nare prone to inadvertent false activations in real-world conditions. In this\nwork, a novel myoelectric control paradigm -- on-demand myoelectric control --\nis proposed, designed, and evaluated, to reduce the number of unrelated muscle\nmovements that are incorrectly interpreted as input gestures . By leveraging\nthe concept of wake gestures, users were able to switch between a dedicated\ncontrol mode and a sleep mode, effectively eliminating inadvertent activations\nduring activities of daily living (ADLs). The feasibility of wake gestures was\ndemonstrated in this work through two online ubiquitous EMG control tasks with\nvarying difficulty levels; dismissing an alarm and controlling a robot. The\nproposed control scheme was able to appropriately ignore almost all\nnon-targeted muscular inputs during ADLs (>99.9%) while maintaining sufficient\nsensitivity for reliable mode switching during intentional wake gesture\nelicitation. These results highlight the potential of wake gestures as a\ncritical step towards enabling ubiquitous myoelectric control-based on-demand\ninput for a wide range of applications.",
        "updated": "2024-02-15 16:11:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10050v1"
    },
    {
        "title": "TIAViz: A Browser-based Visualization Tool for Computational Pathology Models",
        "authors": "Mark EastwoodJohn PocockMostafa JahanifarAdam ShephardSkiros HabibEthar AlzaidAbdullah AlsalemiJan Lukas RobertusNasir RajpootShan RazaFayyaz Minhas",
        "links": "http://arxiv.org/abs/2402.09990v1",
        "entry_id": "http://arxiv.org/abs/2402.09990v1",
        "pdf_url": "http://arxiv.org/pdf/2402.09990v1",
        "summary": "Digital pathology has gained significant traction in modern healthcare\nsystems. This shift from optical microscopes to digital imagery brings with it\nthe potential for improved diagnosis, efficiency, and the integration of AI\ntools into the pathologists workflow. A critical aspect of this is\nvisualization. Throughout the development of a machine learning (ML) model in\ndigital pathology, it is crucial to have flexible, openly available tools to\nvisualize models, from their outputs and predictions to the underlying\nannotations and images used to train or test a model. We introduce TIAViz, a\nPython-based visualization tool built into TIAToolbox which allows flexible,\ninteractive, fully zoomable overlay of a wide variety of information onto whole\nslide images, including graphs, heatmaps, segmentations, annotations and other\nWSIs. The UI is browser-based, allowing use either locally, on a remote\nmachine, or on a server to provide publicly available demos. This tool is open\nsource and is made available at:\nhttps://github.com/TissueImageAnalytics/tiatoolbox and via pip installation\n(pip install tiatoolbox) and conda as part of TIAToolbox.",
        "updated": "2024-02-15 14:54:46 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.09990v1"
    },
    {
        "title": "Generative AI in the Construction Industry: A State-of-the-art Analysis",
        "authors": "Ridwan TaiwoIdris Temitope BelloSulemana Fatoama AbdulaiAbdul-Mugis YussifBabatunde Abiodun SalamiAbdullahi SakaTarek Zayed",
        "links": "http://arxiv.org/abs/2402.09939v1",
        "entry_id": "http://arxiv.org/abs/2402.09939v1",
        "pdf_url": "http://arxiv.org/pdf/2402.09939v1",
        "summary": "The construction industry is a vital sector of the global economy, but it\nfaces many productivity challenges in various processes, such as design,\nplanning, procurement, inspection, and maintenance. Generative artificial\nintelligence (AI), which can create novel and realistic data or content, such\nas text, image, video, or code, based on some input or prior knowledge, offers\ninnovative and disruptive solutions to address these challenges. However, there\nis a gap in the literature on the current state, opportunities, and challenges\nof generative AI in the construction industry. This study aims to fill this gap\nby providing a state-of-the-art analysis of generative AI in construction, with\nthree objectives: (1) to review and categorize the existing and emerging\ngenerative AI opportunities and challenges in the construction industry; (2) to\npropose a framework for construction firms to build customized generative AI\nsolutions using their own data, comprising steps such as data collection,\ndataset curation, training custom large language model (LLM), model evaluation,\nand deployment; and (3) to demonstrate the framework via a case study of\ndeveloping a generative model for querying contract documents. The results show\nthat retrieval augmented generation (RAG) improves the baseline LLM by 5.2,\n9.4, and 4.8% in terms of quality, relevance, and reproducibility. This study\nprovides academics and construction professionals with a comprehensive analysis\nand practical framework to guide the adoption of generative AI techniques to\nenhance productivity, quality, safety, and sustainability across the\nconstruction industry.",
        "updated": "2024-02-15 13:39:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.09939v1"
    },
    {
        "title": "Not Just Novelty: A Longitudinal Study on Utility and Customization of AI Workflows",
        "authors": "Tao LongKaty Ilonka GeroLydia B. Chilton",
        "links": "http://arxiv.org/abs/2402.09894v1",
        "entry_id": "http://arxiv.org/abs/2402.09894v1",
        "pdf_url": "http://arxiv.org/pdf/2402.09894v1",
        "summary": "Generative AI brings novel and impressive abilities to help people in\neveryday tasks. There are many AI workflows that solve real and complex\nproblems by chaining AI outputs together with human interaction. Although there\nis an undeniable lure of AI, it's uncertain how useful generative AI workflows\nare after the novelty wears off. Additionally, tools built with generative AI\nhave the potential to be personalized and adapted quickly and easily, but do\nusers take advantage of the potential to customize? We conducted a three-week\nlongitudinal study with 12 users to understand the familiarization and\ncustomization of generative AI tools for science communication. Our study\nrevealed that the familiarization phase lasts for 4.3 sessions, where users\nexplore the capabilities of the workflow and which aspects they find useful.\nAfter familiarization, the perceived utility of the system is rated higher than\nbefore, indicating that the perceived utility of AI is not just a novelty\neffect. The increase in benefits mainly comes from end-users' ability to\ncustomize prompts, and thus appropriate the system to their own needs. This\npoints to a future where generative AI systems can allow us to design for\nappropriation.",
        "updated": "2024-02-15 11:39:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.09894v1"
    },
    {
        "title": "Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence",
        "authors": "Timothy R. McIntoshTeo SusnjakTong LiuPaul WattersMalka N. Halgamuge",
        "links": "http://arxiv.org/abs/2402.09880v1",
        "entry_id": "http://arxiv.org/abs/2402.09880v1",
        "pdf_url": "http://arxiv.org/pdf/2402.09880v1",
        "summary": "The rapid rise in popularity of Large Language Models (LLMs) with emerging\ncapabilities has spurred public curiosity to evaluate and compare different\nLLMs, leading many researchers to propose their LLM benchmarks. Noticing\npreliminary inadequacies in those benchmarks, we embarked on a study to\ncritically assess 23 state-of-the-art LLM benchmarks, using our novel unified\nevaluation framework through the lenses of people, process, and technology,\nunder the pillars of functionality and security. Our research uncovered\nsignificant limitations, including biases, difficulties in measuring genuine\nreasoning, adaptability, implementation inconsistencies, prompt engineering\ncomplexity, evaluator diversity, and the overlooking of cultural and\nideological norms in one comprehensive assessment. Our discussions emphasized\nthe urgent need for standardized methodologies, regulatory certainties, and\nethical guidelines in light of Artificial Intelligence (AI) advancements,\nincluding advocating for an evolution from static benchmarks to dynamic\nbehavioral profiling to accurately capture LLMs' complex behaviors and\npotential risks. Our study highlighted the necessity for a paradigm shift in\nLLM evaluation methodologies, underlining the importance of collaborative\nefforts for the development of universally accepted benchmarks and the\nenhancement of AI systems' integration into society.",
        "updated": "2024-02-15 11:08:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.09880v1"
    }
]