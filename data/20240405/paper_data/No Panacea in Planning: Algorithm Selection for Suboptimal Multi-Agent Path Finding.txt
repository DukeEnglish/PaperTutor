No Panacea in Planning:
Algorithm Selection for Suboptimal Multi-Agent Path Finding
WeizheChen1*,ZhihanWang2*,JiaoyangLi3,SvenKoenig1,BistraDilkina1
1UniversityofSouthernCalifornia
2TheUniversityofTexasatAustin
3CarnegieMellonUniversity
weizhech@usc.edu,zhihan.wang@utexas.edu,jiaoyangli@cmu.edu,skoenig@usc.edu,dilkina@usc.edu
Abstract a strict time limit and solution quality requirement, choos-
ingthespecificalgorithmandspecifichyperparametersisa
Sincemoreandmorealgorithmsareproposedformulti-agent
very important task, and algorithm selection in MAPF has
path finding (MAPF) and each of them has its strengths,
becomeafocusinbothacademiaandindustry.
choosing the correct one for a specific scenario that fulfills
some specified requirements is an important task. Previous Researchers have already shown that machine-learning-
research in algorithm selection for MAPF built a standard based algorithm selection can learn to efficiently propose
workflowandshowedthatmachinelearningcanhelp.Inthis thefastestalgorithminspecificscenarios(Kaduri,Boyarski,
paper,westudygeneralsolversforMAPF,whichfurtherin- and Stern 2020). Recent works has become proposing cus-
cludesuboptimalalgorithms.Weproposedifferentgroupsof tomized neural network architectures for the problem, and
optimizationobjectivesandlearningtaskstohandlethenew
theywanttoshowthatthiscouldhelp.However,webelieve
tradeoff between runtime and solution quality. We conduct
these previous works have improperly built the workflow,
extensive experiments to show that the same loss can not
andmayleadtoawrongconclusion.
be used for different groups of optimization objectives, and
thatstandardcomputervisionmodelsarenoworsethancus- Inthispaper,weaddressthealgorithm-selectionproblem
tomizedarchitecture.Wealsoprovideinsightfuldiscussions for solvers for MAPF, without the specific limit for focus-
onhowfeature-sensitivepre-processingisneededforlearn- ing on the runtime of optimal algorithms only and with-
ingforMAPF,andhowdifferentlearningmetricsarecorre- out the specification that is selecting algorithms between
latedtodifferentlearningtasks.
completely different algorithms but also selecting between
different hyperparameters for a single algorithm. Reducing
Introduction theselimitationsgiveusbroaderpotentialapplications,and
enablesustoshowhowthepreviousworkflowcouldbemis-
Multi-agent path finding (MAPF) is the problem of gen-
leadingeveninslightlydifferentdomains.Westillformulate
erating a set of collision-free paths for a team of agents
the problem as a prediction problem and use image-based
with given the start and goal locations of each agent while
machine learning to make the prediction. We propose mul-
minimizing some optimization objectives (such as travel
tiple groups of objectives where each objective is a way to
times, travel distances, etc.) (Stern et al. 2019). In recent
tradeoffthecostandtheruntime.Werealizethatwhilepre-
years, MAPF has been an emerging research domain that
viousresearchersnormallyconsidertheoptimizationobjec-
has gotten a lot of attention because of its wide appli-
tives, metrics for learning, and learning tasks in a pairwise
cations in warehouses, airport schedules, and autonomous
independentmanner,therearecorrelationsbetweenthethree
driving.WhiletheproblemisprovedtobeNP-hardincer-
perspectives. So, unlike other works, we propose a group
tain cases (Surynek 2010; Yu and LaValle 2013; Ma et al.
of different learning tasks for different metrics, instead of
2016;Nebel2020)andalsohardinpracticeinothercases,
using the same training scheme and evaluating it on multi-
many algorithms are created to find optimal or suboptimal
pletasks.Basedonanewlyconstructeddatasetbuiltonthe
solutions.Forthesamestandardbenchmark,newalgorithms
standard MAPF benchmark (Stern et al. 2019), we use ex-
cansolvethescenariosfasterandfasterorgivebettersolu-
tensiveexperimentstoshowthatthepreviouswaysofusing
tionswithinthesametimelimit.However,thereisnosilver
eitherinterpolationorpaddinginallfeaturesarenotcorrect
bulletintheMAPFresearchcommunity:Eventhelatestal-
in learning for MAPF, and using the same loss function all
gorithm does not perform the best in every scenario (Oku-
thetime,whichiswhatthepriorworksonalgorithmselec-
mura 2023a,b), and different hyperparameters are needed
tion for optimal MAPF did, can make the model perform
for the best performance in different scenarios. Due to the
poorlyforspecificobjectivesinalgorithmselectionforsub-
extremely large number of possible combinations between
optimalMAPF.Wealsoshowhowdifferentmachinelearn-
algorithms and hyperparameters, running them all one by
ingmodelscanmakeadifferenceinthealgorithmselection
one or in parallel is impractical. Therefore, for real-world
performance, in which customized models show no advan-
deployment, when there is a previously known map with
tageoverstandardcomputervisionmodelslikeResNetand
*Theseauthorscontributedequally. ViT.Wealsodiscusshowtochoosetheneuralnetworkused
4202
rpA
4
]AM.sc[
1v45530.4042:viXrain the algorithm selection problem for MAPF that is fast, either only the accuracy of finding the fastest or only the
easytotrain,andperformswell. coveragerate,whichishowlikelythechosenalgorithmcan
finish in a given time limit. Since both criteria are only re-
RelatedWork latedtotheruntimeofthealgorithms,inthispaper,weaddi-
Whilethereareafewworksthatdirectlygeneratesolutions tionally focus on suboptimal algorithms, and consider how
frommachinelearning(Laurentetal.2020),MAPFisnowa- to take both runtime and cost into account simultaneously.
days mainly solved with more classic methods like heuris- Wealsoexploremodernneuralnetworkarchitecturestoval-
tic search algorithms (Sharon et al. 2015), rule-based algo- idateifmodernarchitecturescanhelpinprediction.
rithms (Han and Yu 2020), and reduction-based algorithms In this paper, we formulate the problem as an image-
(Suryneketal.2016).Therearemainlytwogroupsofalgo- basedpredictionproblem.Manyworkscanbeusedtosolve
rithms,namelyoptimalandsuboptimalalgorithms.Theop- the problem. AlexNet (Krizhevsky, Sutskever, and Hinton
timalalgorithmslikeConflict-BasedSearch(CBS)(Sharon 2012) was the first model showing that deep learning can
etal.2015)areguaranteedtogenerateasolutionthatisop- succeedinclassprediction.VGGNet(SimonyanandZisser-
timalbutusuallyrequiresalongruntime.Suboptimalalgo- man2015)wasthenproposedtoshowthatusingasmallker-
rithmsusuallygenerategood-qualitysolutionsfaster,butdo nelsizecanstablypredictgoodresultswhilekeepingtheto-
notguaranteethesolutionfoundtobethebestone.Within talnumberoftrainingparameterslow.GoogLeNet(Szegedy
suboptimalalgorithms,thealgorithmscanbefurtherdivided etal.2015)wasproposedaboutthesametimeforthesame
into two groups, namely, ones that still guarantee the solu- purpose but proposed an inception unit as their solution.
tion quality to be within a suboptimality bound, which is ResNet(Heetal.2016)proposedtouseskiplinksbetween
also known as asymptotically optimal algorithms, like Ex- layerstosolvethevanishinggradientproblem,makingvery
plicit Estimation CBS (EECBS) (Li et al. 2021), and ones deeparchitecturespossible,andhasbecomeoneofthemost
without any guarantees like Prioritized Planning (PP) (Sil- commonlyusedmodelsincomputervision.Inrecentyears,
ver2005),ParallelPush-and-Swap(PPS)(Sajid,Luna,and Transformer(Vaswanietal.2017)hasbecomeincreasingly
Bekris 2012), and Priority Inheritance with Backtracking popular in all machine learning research, including com-
(PIBT+) (Okumura et al. 2022). In this paper, we consider puter vision. Vision Transformer (ViT) (Dosovitskiy et al.
optimalalgorithmsandbothtypesofsuboptimalalgorithms 2021) proposed to split the image into smaller blocks for
ascandidatealgorithms. transformer to use, and is now a popular and successful
Algorithmselectionistheproblemofselectingaspecific model in computer vision. In this paper, we test the afore-
algorithmforaspecificscenario(Smith-Miles2008).Ithas mentionedneuralnetworksthatarepopularincomputervi-
been successfully used in many optimization problems, in- sionandalgorithmselectioninMAPFresearch.
cludingsatisfiabilityandtravelingsalesmanproblem(TSP)
(Kerschke et al. 2018; Xu et al. 2012). The rich studies in Preliminaries
those domains have built up a standard way of measuring
theperformanceofselectedalgorithmsfortheirspecificus- The multi-agent path finding (MAPF) problem is the prob-
age. However, algorithm selection in MAPF is still at an lemoffindingasetofconflict-freepathsforasetofagents
earlystage,wheremostpapers(Sigurdsonetal.2019;Ren inaknownenvironmentwhileminimizingtheirtraveltimes.
et al. 2021) just show that, with a specific technique, the Specifically, in this paper, we consider exactly the same
selection algorithm could be helpful in choosing a correct problem as (Stern et al. 2019; Li et al. 2022), which is a
solver algorithm but lacked thorough performance metrics. four-connected grid map, where each agent is given a start
Sigurdson et al. (2019) is the first to introduce the algo- cellandagoalcell.Ascenarioisdefinedasthecombination
rithm selection problem to MAPF. They proposed a modi- of the description of the map, which is the size of the map
fiedversionofAlexNet(Krizhevsky,Sutskever,andHinton and which cells have obstacles, the start cells, and the goal
2012) and demonstrated its ability to predict the fastest al- cellsofeachagent.Ateachtimestep,anagentcanmoveto
gorithm in MAPF. Kaduri, Boyarski, and Stern (2020) im- anadjacentcellorstayinitscurrentcell.Aconflicthappens
provedtheresultsbyusingVGGNet(SimonyanandZisser- if two agents result in the same cell at the same timestep.
man2015)andgradientboosteddecisiontreewithXGBoost Eachagentremainsatitsgoalcellafteritarrivesuntilevery
(ChenandGuestrin2016).Renetal.(2021)proposedMAP- agentarrivesattheirgoals.Thequalityofonesolutionisthe
FAST,whichaddedmorefeaturesrelatedtotheshortestpath totalsumoftraveltimesofeachagent,whichisalsoknown
betweenthestartandgoallocationsofeachagent.Theyalso asthesumofcostsintheMAPFcommunity.
added two auxiliary output channels into the loss function, Algorithmselectionistheproblemofchoosingasuitable
andusedaninception-basedneuralnetwork(Szegedyetal. algorithmthatisthebestinagivenscenario.Generally,al-
2015) to train the model. Recently, MAPFASTER(Alkazzi gorithmselectionincludesbothselectingcompletelydiffer-
et al. 2022) is proposed to improve the training and infer- entalgorithmsandchoosingthehyperparameter(s)ofafixed
ence speed of the neural network and try to fix a prob- algorithm.(Oursettingofhyperparameterselectionisdiffer-
lem for rescaling the inputs that occur in MAPFAST(Ren ent from algorithm configuration (Eggensperger, Lindauer,
etal.2021).Kaduri,Boyarski,andStern(2021)empirically and Hutter 2019) in that we are given a small set of can-
showed that different types of maps have different prefer- didatehyperparametercombinationsahead,andwewantto
ences for different algorithms, and thus confirmed the use- choose the best one for a new scenario without any trails.)
fulness of algorithm selection. Previous works focused on Forclarity,weusethewordsolvertorefertothesedifferentcandidates.However,westillcalltheproblemalgorithmse- For the hyperparameter selection, we want to select the
lectiontobeconsistentwithotherpapersthatsolvethesame optimality bound for EECBS. The optimality gap w in
problem.Theinputforthealgorithmselectionincludespre- EECBSguaranteesthesolutionfoundtobewithinw times
ciselythesameinformationasaMAPFsolverknowswith- compared to an optimal solution, and more time will be
outaddinganyinformationfromeachcandidatesolver.The spent during the search almost for sure if a small and tight
selectionalgorithmisthenrequiredtooutputthebestsolver. bound is given. But a large w can also find near-optimal
Typically,machine-learning-basedselectionalgorithmsfirst or even optimal solutions in specific scenarios, so choos-
transform the scenario information to desired formats and ing the optimality gap can make the runtime much faster
features they would like to use as input and then use the inthosescenarioswheregivingasmallvalueisnothelpful
learningmodeltooutputtheanswerdirectly.Wefollowthe forEECBStofindabettersolution.Specifically,weaimto
sameworkflowinthispaper. choosetheoptimalitygapfromw =1.05,1.1,1.15,1.2.
In this paper, we formulate our algorithm selection as a
Features Featureshavelongbeenknownasaveryimpor-
standard image-based-input prediction problem solved by
tant factor in machine learning research related to MAPF.
computer vision techniques. It is remarkable that, in the
ManyearlyworksonalgorithmselectionforMAPFusedthe
last decade, computer vision has earned a great improve-
scenarioinformationwithoutanypre-processing(Sigurdson
ment with tens of thousands of papers every year. There
etal.2019;Kaduri,Boyarski,andStern2020).Oneexcep-
aremanynewneuralnetworkmodelscreatedandevaluated
tion(Renetal.2021)consideredonlyagivenshortestpath
on standard datasets like ImageNet (Yang et al. 2020) and
without specifying a clear way to determine which short-
CIFAR-10 (Krizhevsky and Hinton 2009), and many mod-
est path to use when an agent has multiple shortest paths.
elshavesuccessfullybeenusedindifferentapplicationslike
It also over-compressed different kinds of information into
autonomous driving, face recognition, and many novel ap-
eachchannel,whichcanlargelyreducethepotentialperfor-
plications.Thesesuccessfulapplications,inturn,encourage
mance. So, in this work, we use the image representation
the investment and development of computer vision. Fur-
oftheMAPFscenariosfromtheMAPFbenchmarkanduse
thermore, these models have successfully shown that with
a set of features, each one of which is a separate channel
specificdataaugmentation,rawimageinputwithouthuman-
fedintothemodelasinput.Giventhefactthatfeatureuse-
involved complex pre-processing can be as good as using
fulnessvalidationisverycomplexforneural-network-based
moremanuallydesignedfeatures.Thatiswhywewouldlike
approaches,andisnotthemainfocusofthiswork,herewe
to explore many modern computer vision models to see if
justlistthefeaturesusedinthispaperinorder:
they can directly generate some good results. However, as
we will later show in the experiment section, we find that 1. Whether this specific cell is an obstacle. This is always
thereisnopanaceatoplanning:Usingthesamemodelwith thesameinscenariosgeneratedfromthesamemap.
thesamelossfunctiondoesnotworkforallobjectives.
2. Whether this specific cell is a start cell. Different start
cellsdonothaveanyfurtherdifferences.
AlgorithmSelectionforSuboptimalMAPF
3. Similartostartcells,anindicatorofwhetherthespecific
Dataset cellisagoalcellforanyagent.
Becausethereisnostandarddatasetforalgorithmselection 4. Ifeveryonefollowsitsshortestpathselectedby(Hanand
inMAPFrightnow,wefirstdescribehowwebuildourown Yu 2020) without considering any conflict, how many
datasetsbeforewedescribeourlearningtasks. timeswillthecellbevisited.
Candidate Solvers In this paper, we build two separate 5. Totalnumberofconflictsonthecellbetweenallpairsof
datasets for the purpose of doing standard algorithm selec- shortestpathsfromdifferentagents.
tionbetweendifferentalgorithms,andforthepurposeofdo- 6. Total number of conflicts on the cell between all pairs
ing solver selection between different solvers that are from of shortest paths and 1-suboptimal paths from different
thesamealgorithm. agentsthathappensonthecell.
For the standard algorithm selection part, we enumerate
7. How many times will the cell be visited if every agent
some of the typical MAPF solvers nowadays. Our candi-
trieseverypossibleshortestpathonitsownwithoutcon-
date algorithms are: CBS (Sharon et al. 2015), EECBS (Li
sideringanyconflict.
etal.2021),PP(Silver2005),PPS(Sajid,Luna,andBekris
2012), and PIBT+ (Okumura et al. 2022) . We did not in- Here,wedefinea1-suboptimalpathasapathwhoselength
clude some recent research, such as Large Neighborhood is the length of the shortest path plus 1. In this paper, we
Search(LNS)(Lietal.2021),whichcanusevariousMAPF maketheinputarectangleimage,andthenwenormalizeall
solversassubsolvers.LNS-basedsolverscansolveanysce- theinputfeaturestoascalefrom0to100bydividingevery
nariosthataresolvablebyothersolversbyusingthemasthe channel with the maximum value of all maps for a specific
initialsolver,withjustasmalloverhead,andcansolveaddi- channelandmultiplyingthevaluewith100.
tionalscenarioswhen thelaterneighborhoodsearchis per- During our experiments, we realize that although cells
formed. Therefore, comparing LNS-based solvers to more with obstacles can never be occupied or visited by any
standardMAPFsolversisgenerallynotfair.However,theo- agents,treatingthosecellswithavalueof0inallchannels
retically,LNSuserscanalsouseourmodeltochoosewhich is not always helping the learning. Some features provide
algorithmtheywanttouseastheirsubsolvers. information about the level of congestion in the scenario.Therefore,thescenarioshouldbeconsideredmorecrowded
andhavealargervalueonthefeatureswhentherearemore
obstacles on the map, and less crowded when fewer obsta-
clesarepresent.So,wechangeallobstaclecellstoavalue
of 200 for the (4) and (7) channels listed above, which is
theheatmapthatsumsuptheshortestpathfromagivenset,
basedonsomeempiricalresultsonanotcompleteenumer-
ationandtheintuitionwementionedabove.
After defining the features, we need to pre-process the
data to make the input fit into the same neural network so
wedonotneedtotrainseparatemodelsfordifferentmaps.
While previous works (Sigurdson et al. 2019) all use a de-
fault resize1, which is also known as interpolation in many
fields,tomakeallimagetobeofthesamesizewithouteven
mentioning that in the paper, we realize that this is not al-
waysthecorrectthingtodo.Thisresizingwayworksprop-
erly in computer vision because the pictures have a good
property of zooming invariance, i.e., a hand is still a hand
Figure1:Thefrequencyofeachalgorithmbeingthebestone
no matter how it is zoomed in or zoomed out. However, in
on a given map when w = 0.001 in Eq. 3. Different maps
MAPF,eachagentcanonlymoveonecellatonetimestep,
have different numbers of total scenarios because different
so zooming invariance is not held. Therefore, using resize
mapsaredifferentinsizeandobstaclessothetotalcapacity
as the way to rescale images of different sizes to the same
isnaturallydifferent.
sizes is not a proper way. We give another option for pre-
processingthedata,whichisforeachgivenimage,wemake
theoriginalimageinthecenter,andpadtheimagetoafixed
solvers. So we need to consider both runtime and cost (so-
size of 384×384 with the number we get from an obsta-
lution quality) simultaneously. While there are many ways
cle. Specifically, the value padded is not a fixed number in
todothis,weusethissectiontogivetwointuitivewaysof
differentchannels,becausethepaddedpartshouldbeequiv-
definingtheoptimizationobjective.
alenttopaddingobstaclestothemapandobstaclesarenot
Wefirstnormalizethetimeandthecosttoasimilarscale,
necessarilygettingthesamevalueindifferentchannels.
inawaythatisindependentofthesetofcandidatesolvers.
Labels With all the candidate solvers, we run all solvers Suppose the time limit is time , and the sum of costs
limit
onallmapsintheMAPFbenchmark(Sternetal.2019).For for shortest paths for every single agent is cost in the
bound
eachsolver,weenumeratedifferentnumbersofagentswith scenario,thenormalizedtimeandcostarecalculatedby:
astepsizeof10agentsuntiltherearenomorethan2solvers
time
thatcansolveanylargerscenariowithinthetimelimitof2 time′ = (1)
minutes on the map. With all these statistics together with time limit
the features we have just defined, we get an algorithm se- cost
cost′ = , (2)
lection dataset of 89,940 data points and a hyperparameter cost
bound
selectiondatasetof53,691datapoints.Itisnoteworthythat
Furthermore, following the previous convention, if a spe-
the algorithm selection dataset is much larger compared to
cificsolvercannotbefinishedinthetimelimittime in
anypreviouslyuseddatasetthatisaround10K(Kaduri,Bo- limit
anyscenario,thetimeusedforcalculationisdefinedas5×
yarski, and Stern 2020; Ren et al. 2021), and a reasonable
time ,andthecostusedforcalculationis5×cost ,
sizeforastarttryingmoderndeeplearningmodelsthathave limit min
wherecost aretheminimumsumofcostsinallsuccess
millionsofparameterswithoutimmediatelyoverfitting,but min
candidate solvers (i.e., all candidate solvers that find solu-
still quite small compared to standard datasets in machine
tions within the time limit). For clarification, the number 5
learningthatnormallyhavemillionsofdatapoints.
usedhereisanexamplenumberusedinthispaperthatisbig
enoughtoimposeapenaltyforthosewhotimeout,butalso
OptimizationObjectives
nottoolargetodrawexcessiveattentiontothisspecificdata
Previous works on algorithm selection for MAPF typically
point.Othernumbers,suchas2or10,willalsolikelywork.
consider the runtime or success rate (at a fixed runtime
Thefirstandthemostcommonwayofdefininganobjec-
threshold) of a solver as the only objective and never take
tiveistouseaweightedsumofdifferentmetricsasthescore
solutionqualityintoaccount.Inthisway,theycanhopefully
(Bischl et al. 2016; Heins et al. 2021; Seiler et al. 2020).
alwaysdeliverasolutiontothedeployedscenario.However,
Specifically,wecalculatethefollowingobjectivescore:
the actual solution quality can vary largely across differ-
ent solvers in different maps when we consider suboptimal
score(a)=time′ +w∗cost′, (3)
1Researchers in MAPFAST (Ren et al. 2021) said they use a a
padding to formalize the input but in fact, they are not using it wherewisthehyperparameterthatuserscancontroltorep-
accordingtotheirpubliccodeonGithub. resenttheirpreference,andtime′ andcost′ arethenormal-gap.)Throughoutthetext,wewillusetheterm”gap”tore-
fertotheVBS-SBSgap.Givenapre-calculatedvirtualbest
solver (VBS) that always correctly outputs the best solver
in each scenario and a single best solver (SBS) that is al-
ways outputting the same posterior best solver, the gap for
thecurrentsolveraiscalculatedby:
score(a)−score(VBS)
gap(a)= , (6)
score(SBS)−score(VBS)
Figure2:Overallperformanceofdifferentalgorithmselec-
tionmodelsindifferenttasksintermsofaccuracy(higheris where score is the average score function over all data
better) and VBS-SBS gap (lower is better). Blue points are points, which could be the score function we defined in
actualsampleswecollectedindifferentmodels. Eq.3,orjustruntimeifweusethesecondoptimizationob-
jectiveinEq.5.Thisobjectiveiscommonlyknownasamet-
ricforapredictionmodel,with0asthetheoreticalbestand
ized metrics we calculated above. In this case, we want to 1 as the same performance as the prediction model that al-
findthesolverwiththebestscore: waysoutputsthesinglebestsolver.Agoodalgorithmselec-
torshouldhaveagapsmallerthan1,andthesmallerthegap
is,thebettertheselectoris.
min score(a) (4)
However, on some optimization objectives, the gap met-
a
ric does not get better in the same direction with accuracy.
Thesecondgroupofobjectivesistochooseasolverthat
When a user prioritizes accuracy optimization, the model
givesasolutionwithinagivencostboundthefastest.Specif-
will likely converge to weights that favor common scenar-
ically,wefindthesolverasothat:
ios. Although this approach may seem reasonable, it can
produce the least favorable results if the common scenar-
min time
a
a iosareincorrect.Consequently,thiscanleadtopoorperfor-
s.t. cost ≤bound∗cost , (5) mance on metrics that penalize incorrect answers, and the
a min
VBS-SBS gap is one of these metrics. As shown in Fig. 2,
where cost min is the minimum sum of costs in all success havinggoodaccuracydoesnotnecessarilyguaranteeasmall
candidate solvers. This group of objectives is useful in the VBS-SBS gap, and, in most cases, achieving a small gap
casethattheusersjustneedsomeguaranteeonthesolution requires a drop in accuracy. Therefore, we believe that the
quality,butaslongasthesolutionisarelativelygoodone, previous workflow of training a model and then evaluating
theruntimebecomestheonlyconsideration. itwithbothmetricsisnottheappropriateapproachherein
Withdifferentobjectives,wehaveafewdatapointswith MAPF,andusersshouldbuilddifferentlearningtasksafter
the same input but different labels from one scenario. In knowingwhattheytrulywant.
Fig.1,weshowthefrequencyofdifferentsolversbeingthe
best in different scenarios, and we further provide the fre- LearningTasks
quencyplotsofalluniquetasksintheappendix.Weobserve
Inthispaper,basedontheoptimizationobjectiveswehave,
thatthebestsolversarechangingalotwhiletradingoffthe
weconsidertwopopularwaysoflearninganalgorithmse-
runtime and cost at different weights. And it is also differ-
lectionmodel:
ent between maps in how large the difference between sin-
1. Classification: The standard way is to treat the problem
gle best solvers and other solvers is even if the single best
asaclassificationproblem.Themodelpredictstheprob-
solversarethesame.
ability of choosing each solver and is trained with typi-
MetricsforLearning cal classification loss. For inference, the solver with the
largestprobabilityisselected.
After defining the optimization objectives, we briefly talk
2. Regression on Expected Score: This method still pre-
aboutthetwometricsforlearningweuseinthispaper.
dicts the probability of each candidate being the best,
The first metric is the standard accuracy, which is used
but it now uses a regression-based loss instead of a
bothinpopularmachinelearningresearch,andinearlierpa-
classification-basedlossduringtraining.Everytime,the
persinalgorithmselectionforMAPF(Renetal.2021).
probability got from the output is used to calculate the
Accuracy is normally a good metric in ML, but it only
expected score by using the model following the prob-
takes right or wrong into account, not how wrong the pre-
ability, and the loss is a function related to how much
dictions are. On the other hand, if we want to use an al-
differencethisscoreiscomparedtotheVBS.
gorithm selector, we definitely want to know how bad the
wrong choices are as long as the selector is not perfect. So Specifically, we choose to use two variants of classifica-
thesecondgroupofobjectivesisawell-knownmetricinal- tionandonewayofregression.
gorithmselection,theVBS-SBSgap(Xuetal.2012),which Thefirstvariantofclassificationisthemostpopularver-
isalsoknownastheclosedgap(Lindauer,vanRijn,andKot- sion,whichistouseacross-entropylossfortheclassifica-
thoff 2017). (The VBS-SBS gap equals 1 minus the closed tionproblem.WecallthismethodCE(cross-entropy).Thesecondvariantofclassificationisbysimplychanging Padding(p),Resize(r) Gap↓ Acc↑
thecross-entropylosstoabinarycross-entropyloss,which ppp pppp 1.000 0.262
wecallBCE(binarycross-entropy). ppp prrp 1.100 0.298
Thethirdwayoflearningistheregressionontheexpected ppp rppp 1.000 0.262
scores we described above. With the probability obtained ppp rrrp 0.911 0.307
from the model, we compute Huber loss (Huber 1992) for ppp rrrr 1.265 0.305
ourexpectedscoreandthescoreofVBSastheloss.Wecall rrr rrrp 1.118 0.297
thislearningwayReg(Regression). rrr rrrr 0.945 0.279
Alearningtaskisthecombinationofoptimizationobjec-
tivesandaspecificlearningway.WeuseScore-w-ytorefer Table 1: Partial results on different rescale methods on dif-
to the optimization task in Eq. 4, where w is w from Eq. 4 ferentfeaturestrainedwithViTonScore-1-Regtask.’p’de-
and y is the learning way to create a learning task. We use notesusingpaddingand’r’denotesusinginterpolation(de-
Bound-b-y to refer to tasks optimizing as Eq. 5, where b faultresize)inthecorrespondingchanneloffeatures,inthe
is the value of bound in the equation. For example, Score- order shown in the Features section. The full table can be
0.001-CEisthetaskthatwesetw =0.001inEq.3forscore foundintheappendix.
definition,andweusecrossentropyinthetraining.Bound-
1.1-BCEmeanstheoptimizationtaskswithbound=1.1in
Eq.5,andoptimizedbythebinarycross-entropyloss. inance of each solver in our setting, the SBS for the entire
datasetisthesameastheSBSpergridorpermaptype.
Experiments Foreverymodel,weusesomedataaugmentationmethods
topreventthemodelfromoverfitting,whichincluderandom
ExperimentSettings flip,randomrotation,andrandomerasingwithaprobability
Inthispaper,wedevelopourmachinelearningmodelbased of 0.5. We decide to use resize only in the 4th to the 6th
on 5 different computer vision models: VGG16 (VGGNet) channels of the feature and padding in other channels be-
(SimonyanandZisserman2015),ViT-Tiny(ViT)(Dosovit- causetheyareempiricallythebestaswewilllatershow.
skiy et al. 2021; Wightman 2019), MAPFAST (Ren et al. TherunningresultsofallMAPFsolversarecollectedon
2021),MAPFASTER(Alkazzietal.2022),ResNet-18(He the same AWS EC2 m4 server, while the training and test-
etal.2016),basedonthestandardTimmlibrary(Wightman ingofallmachinelearningmodelsareconductedonaxeon-
2019). These models have covered all existing literature in 6130serverwithasingleNVIDIA-V100and184GBRAM.
deep-learning-basedalgorithmselectionforMAPFandalso Allparametersareselectedbygrid-search,andthefullhy-
the most commonly used models in computer vision. Sur- perparametertableisprovidedintheappendix.
prisingly, we found that the auxiliary tasks used in MAP-
FeatureRescale
FASTarenothelpingtheresultforanytasksinourdataset,
soallnumbersofMAPFASTarefrommodelstrainedwith In earlier papers using image-based models (Kaduri, Bo-
onlythefirstoutputchannelthatdirectlyoutputstheproba- yarski, and Stern 2020; Sigurdson et al. 2019; Ren et al.
bilityofeachsolver,andoptimizedasastandardclassifica- 2021;Alkazzietal.2022),researchersarealwaysusingin-
tionproblem.Wedonotincludeanyresultsbasedondeci- terpolationresize(knownasresizeinMLlibrarieslikePy-
siontreesbecausepreviouspapersinalgorithmselectionfor torch(Paszkeetal.2019))tomaketheinputstoafixedsize
MAPF(Kaduri,Boyarski,andStern2020;Renetal.2021) of227×227.RecentalgorithmselectioninMAPFpapersare
havealreadyshownthatneuralnetworkscanoutperformde- followingthistraditionfromcomputervision.However,re-
cisiontreemodelsinmostcases,andalsodecisiontreemod- sizingthepicturesbyinterpolatingthevaluesoneverypixel
els require a much more complex study of which features from the original input is losing many underlying assump-
to use, which is not the focus for this paper. It needs to be tions in planning. For example, we can only move one cell
addressed that ViT is very different from any other model atatime,soacellof1×1ina10×10mapisverydifferent
because it is not a convolutional neural network. We hope fromagroupofcellsof10×10ina100×100map.Onthe
that ViT can perform differently because it does not have other hand, always using the padding to rescale features is
thelimitofthesmallkernelsize,northeshiftedinvariance notalignedwithourintuitioninheatmapfeatureswherewe
propertythatCNNgenerallyhas. probablyonlycareabouttheoverallcrowdness.Giventhat
Foreachtaskwitheachmodel,weshowtheaccuracyand it is hard to collect a lot of data, we want to make full use
VBS-SBS Gap (Gap) for them. We choose to show both ofourdataandfeatureslikeheatmapshouldbeusedacross
ofthembecauseaccuracyisthecurrentlycommonpractice different sizes of map. So in this section, we examine how
foralgorithmselectionforMAPF,whiletheGapisanother the performance of a model will be if we change channels
metricthatiswidelyusedinmoregeneralalgorithmselec- frominterpolationtopadding.
tion.Whileweprimarilysetourbaselineasgettingabetter Because enumerating all possible combinations of
number than SBS, our SBS is selected separately for accu- padding and resizing in different channels needs 27 = 128
racy(SBS )andVBS-SBSgap(SBS ).Fromintuition, experiments, which is too large for us to test them all, we
Acc Gap
SBS isthesolverthatisthemostcommoninFig.1,while assume that channels that have similar meanings should be
Acc
SBS istheonethatcansolvethemostinstance,therefore treated the same, and thus, we can change the rescaling
Gap
itdoesnotgetanylargefailingpenalty.Becauseofthedom- method in groups, i.e., features (1), (2), (3) are in a group,MAPFAST ViT VGGNet ResNet MAPFASTER SBS
Score-0.001-CE 0.81 0.81 0.84 0.91 0.8 0.8
Score-0.001-BCE 0.85 0.83 0.85 0.86 0.8 0.8
Score-0.1-CE 0.61 0.61 0.69 0.61 0.57 0.57
Standard Score-0.1-BCE 0.65 0.62 0.67 0.56 0.57 0.57
Score-1-CE 0.62 0.69 0.66 0.6 0.62 0.62
Score-1-BCE 0.57 0.68 0.64 0.62 0.62 0.62
Bound-1.1-CE 0.56 0.65 0.69 0.61 0.51 0.51
Bound-1.2-CE 0.72 0.74 0.73 0.58 0.19 0.51
EECBS Score-0.001-CE 0.7 0.71 0.7 0.69 0.69 0.69
Score-0.001-BCE 0.69 0.69 0.7 0.69 0.69 0.69
Table2:Theaccuracyfordifferentmodelsindifferenttasks.ThenamesofthetasksareshownintheTaskcolumn,following
thenamingdescribedintheexperimentsettingsection.
MAPFAST ViT VGGNet ResNet MAPFASTER SBS
Score-0.001-Reg 0.89 0.87 1 0.94 1 1
Score-0.1-Reg 0.75 0.71 1 1 1 1
Score-1-Reg 0.71 0.92 1 0.75 1 1
Score-0.001-Reg(EECBS) 1 1 1 0.93 1 1
Table 3: The VBS-SBS gap for different models in different tasks. The names of the tasks are shown in the Task column,
followingthenamingdescribedintheexperimentsettingsection.Thesmallerthenumber,thebetterthemodel.Thefirstthree
rowsarefromthestandarddataset,whilethelastoneisfromourhyperparameterselectionforEECBSdataset.
CE BCE Reg SBS todouble-checkifthesameholdsintheirdatasetgiventhat
theadvantageisnotverysignificantinourexperiment.
Score-0.001-Acc↑ 0.81 0.83 0.79 0.8
Score-0.001-Gap↓ 19.03 18.67 0.87 1 ModelArchitecture
Score-0.1-Acc↑ 0.61 0.62 0.57 0.57
We show our comparison of different model architectures
Score-0.1-Gap↓ 14.83 14.79 0.71 1
in Table 2 and Table 3. We found that while previous re-
Score-1-Acc↑ 0.69 0.68 0.3 0.62
searchers claim that model architectures they proposed can
Score-1-Gap↓ 1.95 1.89 0.92 1
bebetterthanearliermodels,theirarchitecturesfailstosur-
Score-0.001-Acc(EECBS)↑ 0.71 0.69 0.69 0.69
pass popular computer vision models like ResNet and ViT.
Score-0.001-Gap(EECBS)↓ 1.12 1 1 1
Andoverall,theyevenfailtoreachthesamelevelofperfor-
mancesasthestandardmodels.Inouropinion,thepopular
Table4:TheAccuracyandGapofViTtrainedwithdifferent modelsaredesignedtoefficientlyextractbothhigh-leveland
lossindifferentdataset.Weprovidetheresultsofallmodel low-levelinformationfromthegivenpictures,andthuscan
architecturesintheAppendix.Thelasttworowsareresults beusuallybetterthancustomizedmodels.
fromthehyperparameterselectionforEECBSdataset,while Between all the architectures, there is no only winner.
theotherrowsarefromthestandarddataset. And given that ViT wins half of the tasks in both accuracy
andGap,andthatitsunderlyingtransformerarchitectureis
showntobegenerallyrobustinfoundationmodels,werec-
features(5)and(6)areinagroup,andfeatures(4)and(7) ommendViTasthedefaultchoice.VGGNetisstronginac-
each is in a group. We show the results of different combi- curacy,butfailstojumpoutofthelocalminimumintheGap
nationsofinterpolation(resize)andpaddinginTable.1and metrics.MAPFASTperformsgoodinmostcases,butitdoes
theappendixforthefullenumeration.Wefoundthatchoos- not show significant advantage to popular models. Specif-
ingtousewhichrescalingmethodcanmakeadifferent,and ically, MAPFASTER (Alkazzi et al. 2022) never succeeds
change one channel to another is not independent of what in escaping the local optimal of outputting SBS, which we
other channels currently are. In our setting, we found that believe is because of the over-compressed neural network
thebestrescalingmethodistousepaddinginthefirstthree structure.
channelsthatdescribetheMAPFinstanceasstartlocations, Inallgroupsofoptimizationobjectives,therearealways
goal locations and obstacles, and the last channel, which is some learning tasks with some machine learning models
the heatmap of the sum of all possible shortest paths. All that get a gap smaller than 1, and better accuracy com-
other channels should use interpolation. While we do find pared to SBS. This means that algorithm selection in sub-
thisreallyhelpfulinourexperiment,weencouragelateruser optimal solvers and hyperparameter selection between dif-ferent solvers from the same algorithm are both feasible. ACM SIGKDD Conference on Knowledge Discovery and
On the other hand, the performances of learning models DataMining(KDD),785–794.ACM.
are different from task to task, and part of them shows a
Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn,
marginalimprovementcomparedtotheSBS.Thisindicates
D.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.;
agreatpotentialforfutureresearcherstodevelopnewmeth-
Heigold,G.;Gelly,S.;Uszkoreit,J.;andHoulsby,N.2021.
ods to better solve these hard tasks of selecting suboptimal
An Image is Worth 16x16 Words: Transformers for Image
solvers. For clarification, the results from different weights
RecognitionatScale. InProceedingsoftheNinthInterna-
arenotdirectlycomparablesincethedistributionofeachal-
tionalConferenceonLearningRepresentations(ICLR).
gorithmbeingthebestiscompletelydifferentunderdiffer-
Eggensperger, K.; Lindauer, M.; and Hutter, F. 2019. Pit-
entweights,makingthedifficultyofeachtaskalsodifferent.
fallsandBestPracticesinAlgorithmConfiguration. J.Artif.
Metrics-LossCorrespondence
Intell.Res.,64:861–893.
Han, S. D.; and Yu, J. 2020. DDM: Fast Near-Optimal
As we discussed earlier, optimizing accuracy could be the
Multi-RobotPathPlanningUsingDiversified-PathandOp-
oppositeofoptimizinggap.InTable4,weshowtheperfor-
timal Sub-Problem Solution Database Heuristics. IEEE
manceofmodelstrainedindifferentlossesevaluatedunder
RoboticsAutom.Lett.,(2):1350–1357.
differentloss.Itshowsthatthereisnolearningtaskthatcan
be good in both accuracy and VBS-gap. Regression is the He,K.;Zhang,X.;Ren,S.;andSun,J.2016.DeepResidual
mostpromisingwaytobuildalearningtaskwhenusingthe Learning for Image Recognition. In Proceedings of IEEE
VBS-SBS metrics, while CE and BCE are better when us- Conference on Computer Vision and Pattern Recognition
ingtheaccuracymetrics.Thismeansthattheclassicwayof (CVPR),770–778.IEEEComputerSociety.
alwaysusingCEtotrainamodelforallmetricsusedinpre-
Heins,J.;Bossek,J.;Pohl,J.;Seiler,M.;Trautmann,H.;and
vious papers (Kaduri, Boyarski, and Stern 2020; Ren et al.
Kerschke,P.2021. OnthepotentialofnormalizedTSPfea-
2021),isnotpreferablewhenGapisincludedasoneofthe
tures for automated algorithm selection. In Proceedings of
metrics.
the Sixteenth Conference on Foundations of Genetic Algo-
rithms(FOGA),7:1–7:15.ACM.
Conclusion
Huber,P.J.1992. RobustEstimationofaLocationParame-
In this paper, we study algorithm selection for subopti- ter,492–518. Springer. ISBN978-1-4612-4380-9.
mal MAPF solvers. We formulate algorithm selection as a
Kaduri, O.; Boyarski, E.; and Stern, R. 2020. Algorithm
prediction problem with multiple potential formulations to
SelectionforOptimalMulti-AgentPathfinding. InProceed-
tradeoffbetweenruntimeandsolutioncostdifferently.Deep
ingsoftheThirtiethInternationalConferenceonAutomated
learningmodelsaretrainedwithmanycombinationsofop-
PlanningandScheduling(ICAPS),161–165.AAAIPress.
timizationobjectivesandlossfunctionstomakepredictions.
We showed that different metrics in the domains are not Kaduri, O.; Boyarski, E.; and Stern, R. 2021. Experimen-
alignedwitheachother,andmodelsoptimizedforaccuracy talEvaluationofClassicalMultiAgentPathFindingAlgo-
could even go to the opposite direction to the models op- rithms. InProceedingsoftheFourteenthInternationalSym-
timized for VBS-SBS gap. We show that feature-specific posium on Combinatorial Search (SOCS), 126–130. AAAI
ways of rescaling is needed, and that customized neural Press.
networkarchitecturesdonotgenerallyoutperformstandard Kerschke, P.; Kotthoff, L.; Bossek, J.; Hoos, H. H.; and
models from computer vision domains. We hope our find- Trautmann, H. 2018. Leveraging TSP Solver Complemen-
ingscanchangesomeofthecommonpracticesforalgorithm taritythroughMachineLearning. Evol.Comput.,(4).
selection for MAPF that might not be correct. In addition,
Krizhevsky,A.;andHinton,G.2009.Learningmultiplelay-
we show that hyperparameter selection can be successfully
ers of features from tiny images. Technical report, Univer-
donewiththesameframework.
sityofToronto,Toronto,Ontario.
References Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Im-
ageNetClassificationwithDeepConvolutionalNeuralNet-
Alkazzi,J.;Rizk,A.;Salomon,M.;andMakhoul,A.2022. works. InAdvancesinNeuralInformationProcessingSys-
MAPFASTER: A Faster and Simpler take on Multi-Agent tems25(NIPS2012),1106–1114.
Path Finding Algorithm Selection. In IEEE/RSJ Inter-
Laurent, F.; Schneider, M.; Scheller, C.; Watson, J. D.; Li,
national Conference on Intelligent Robots and Systems,,
J.;Chen,Z.;Zheng,Y.;Chan,S.;Makhnev,K.;Svidchenko,
10088–10093.IEEE.
O.; Egorov, V.; Ivanov, D.; Shpilman, A.; Spirovska, E.;
Bischl, B.; Kerschke, P.; Kotthoff, L.; Lindauer, M.; Mal-
Tanevski, O.; Nikov, A.; Grunder, R.; Galevski, D.; Mitro-
itsky, Y.; Fre´chette, A.; Hoos, H. H.; Hutter, F.; Leyton-
vski, J.; Sartoretti, G.; Luo, Z.; Damani, M.; Bhattacharya,
Brown, K.; Tierney, K.; and Vanschoren, J. 2016. ASlib:
N.; Agarwal, S.; Egli, A.; Nygren, E.; and Mohanty, S. P.
A benchmark library for algorithm selection. Artif. Intell.,
2020. Flatland Competition 2020: MAPF and MARL for
41–58.
Efficient Train Coordination on a Grid World. In Proceed-
Chen, T.; and Guestrin, C. 2016. XGBoost: A Scalable ings of the NeurIPS 2020 Competition and Demonstration
TreeBoostingSystem.InProceedingsoftheTwenty-second Track,275–301.PMLR.Li,J.;Chen,Z.;Harabor,D.;Stuckey,P.J.;andKoenig,S. Sharon,G.;Stern,R.;Felner,A.;andSturtevant,N.R.2015.
2021. AnytimeMulti-AgentPathFindingviaLargeNeigh- Conflict-based search for optimal multi-agent pathfinding.
borhood Search. In Proceedings of the Thirtieth Interna- Artif.Intell.,40–66.
tional Joint Conference on Artificial Intelligence (IJCAI), Sigurdson, D.; Bulitko, V.; Koenig, S.; Herna´ndez, C.; and
4127–4135.ijcai.org. Yeoh, W. 2019. Automatic Algorithm Selection In Multi-
Li, J.; Chen, Z.; Harabor, D.; Stuckey, P. J.; and Koenig, agentPathfinding. CoRR.
S. 2022. MAPF-LNS2: Fast Repairing for Multi-Agent Silver,D.2005. CooperativePathfinding. InProceedingsof
PathFindingviaLargeNeighborhoodSearch. InProceed- the Conference on First Artificial Intelligence and Interac-
ingsoftheThirty-SixthConferenceonArtificialIntelligence tiveDigitalEntertainment(AIIDE),117–122.AAAIPress.
(AAAI),10256–10265.AAAIPress. Simonyan,K.;andZisserman,A.2015.VeryDeepConvolu-
Lindauer,M.;vanRijn,J.N.;andKotthoff,L.2017. Open tionalNetworksforLarge-ScaleImageRecognition.InPro-
Algorithm Selection Challenge 2017: Setup and Scenarios. ceedingsoftheThirdInternationalConferenceonLearning
In Proceedings of the Open Algorithm Selection Challenge Representations(ICLR).
2017, volume 79 of Proceedings of Machine Learning Re- Smith-Miles, K. 2008. Cross-disciplinary perspectives on
search,1–7.PMLR. meta-learningforalgorithmselection. ACMComput.Surv.,
Ma, H.; Tovey, C. A.; Sharon, G.; Kumar, T. K. S.; and (1):6:1–6:25.
Koenig, S. 2016. Multi-Agent Path Finding with Payload Stern,R.;Sturtevant,N.R.;Felner,A.;Koenig,S.;Ma,H.;
Transfers and the Package-Exchange Robot-Routing Prob- Walker,T.T.;Li,J.;Atzmon,D.;Cohen,L.;Kumar,T.K.S.;
lem. In Proceedings of the Thirtieth AAAI Conference on Barta´k, R.; and Boyarski, E. 2019. Multi-Agent Pathfind-
ArtificialIntelligence(AAAI),3166–3173.AAAIPress. ing:Definitions,Variants,andBenchmarks. InProceedings
Nebel,B.2020.OntheComputationalComplexityofMulti- oftheTwelfthAnnualSymposiumonCombinatorialSearch
Agent Pathfinding on Directed Graphs. In Proceedings of (SoCS),151–159.AAAIPress.
the Thirtieth International Conference on Automated Plan- Surynek, P. 2010. An optimization variant of multi-robot
ningandScheduling(ICAPS),212–216.AAAIPress. path planning is intractable. In Proceedings of the AAAI
Okumura,K.2023a. ImprovingLaCAMforScalableEven- conferenceonartificialintelligence,volume24,1261–1263.
tually Optimal Multi-Agent Pathfinding. arXiv preprint Surynek, P.; Felner, A.; Stern, R.; and Boyarski, E. 2016.
arXiv:2305.03632. EfficientSATApproachtoMulti-AgentPathFindingUnder
Okumura, K. 2023b. Lacam: Search-based algorithm for theSumofCostsObjective. In22ndEuropeanConference
quick multi-agent pathfinding. In Proceedings of the AAAI onArtificialIntelligence(ECAI),volume285ofFrontiersin
Conference on Artificial Intelligence, volume 37, 11655– ArtificialIntelligenceandApplications,810–818.IOSPress.
11662. Szegedy, C.; Liu, W.; Jia, Y.; Sermanet, P.; Reed, S. E.;
Okumura, K.; Machida, M.; De´fago, X.; and Tamura, Y. Anguelov, D.; Erhan, D.; Vanhoucke, V.; and Rabinovich,
2022. Priority inheritance with backtracking for iterative A. 2015. Going deeper with convolutions. In Proceedings
multi-agentpathfinding. Artif.Intell.,103752. ofIEEEConferenceonComputerVisionandPatternRecog-
nition(CVPR),1–9.IEEEComputerSociety.
Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.;
Chanan,G.;Killeen,T.;Lin,Z.;Gimelshein,N.;Antiga,L.; Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
Desmaison, A.; Ko¨pf, A.; Yang, E. Z.; DeVito, Z.; Raison, L.;Gomez,A.N.;Kaiser,L.;andPolosukhin,I.2017. At-
M.;Tejani,A.;Chilamkurthy,S.;Steiner,B.;Fang,L.;Bai, tentionisAllyouNeed. InAdvancesinNeuralInformation
J.; and Chintala, S. 2019. PyTorch: An Imperative Style,
ProcessingSystems30,5998–6008.
High-Performance Deep Learning Library. In Advances in Wightman,R.2019. PyTorchImageModels. https://github.
NeuralInformationProcessingSystems32,8024–8035. com/rwightman/pytorch-image-models.
Ren,J.;Sathiyanarayanan,V.;Ewing,E.;Senbaslar,B.;and Xu,L.;Hutter,F.;Hoos,H.H.;andLeyton-Brown,K.2012.
Ayanian,N.2021. MAPFAST:ADeepAlgorithmSelector Evaluating Component Solver Contributions to Portfolio-
for Multi Agent Path Finding using Shortest Path Embed- BasedAlgorithmSelectors. InProceedingsoftheFifteenth
dings. In Proceedings of the Twentieth International Con- InternationalConferenceofTheoryandApplicationsofSat-
ferenceonAutonomousAgentsandMultiagentSystems(AA- isfiability Testing (SAT), Lecture Notes in Computer Sci-
MAS),1055–1063.ACM. ence,228–241.Springer.
Sajid, Q.; Luna, R.; and Bekris, K. E. 2012. Multi-Agent Yang, K.; Qinami, K.; Fei-Fei, L.; Deng, J.; and Rus-
Pathfinding with Simultaneous Execution of Single-Agent sakovsky, O. 2020. Towards fairer datasets: filtering and
Primitives. InProceedingsoftheFifthInternationalSympo- balancing the distribution of the people subtree in the Im-
siumonCombinatorialSearch(SOCS),88–96.AAAIPress. ageNet hierarchy. In Proceedings of ACM Conference on
Fairness, Accountability, and Transparency (ACM FAccT),
Seiler,M.;Pohl,J.;Bossek,J.;Kerschke,P.;andTrautmann,
547–558.ACM.
H.2020. DeepLearningasaCompetitiveFeature-FreeAp-
proach for Automated Algorithm Selection on the Travel- Yu, J.; and LaValle, S. M. 2013. Structure and Intractabil-
ing Salesperson Problem. In Proceedings of the Sixteenth ity of Optimal Multi-Robot Path Planning on Graphs. In
International Conference of Parallel Problem Solving from ProceedingsoftheTwenty-SeventhAAAIConferenceonAr-
Nature(PPSN),48–64.Springer. tificialIntelligence(AAAI),1,1443–1449.AAAIPress.Rescaling
Herewegivethefulltableoftheablationstudyoftherescal-
ingmethodinthemainpaper.
Padding(p),Resize(r) Gap Acc
ppp pppp 1.000 0.262
ppp pppr 1.000 0.262
ppp prrp 1.100 0.298
ppp prrr 1.286 0.303
ppp rppp 1.000 0.262
ppp rppr 0.940 0.280
ppp rrrp 0.911 0.307
ppp rrrr 1.265 0.305
rrr pppp 1.000 0.262
rrr pppr 0.995 0.262
rrr prrp 0.959 0.274
rrr prrr 0.923 0.290
rrr rppp 1.008 0.262 Figure3:Datasetresultforthecaseofscore=time+1×
rrr rppr 0.988 0.262 costasscoredefinition.
rrr rrrp 1.118 0.297
rrr rrrr 0.945 0.279
Table5:Resultsondifferentrescalemethodondifferentfea-
tures. ’p’ denote using padding, while ’r’ denote using the
defaultresizeinthecorrespondingchanneloffeatures.The
tableisgeneratedwithresultstrainedwithViTonScore-1-
Regtask.
FullResultsofDifferentModels
Here we provide the full table instead of the ViT only ver-
sionprovidedinthemainpaperasareference.
AdditionalDatasetAnalysis
Whilewehaveonlyshowndatasetillustrationsofonlyone
objective in the paper, in Fig. 3 - 5 we provide the dataset
illustrationsforalltasksusedintheexperiment.Wecansee
Figure4:Datasetresultforthecaseofscore=time+0.1×
thatwhentheobjectiveisdifferent,therelativeperformance
costasscoredefinition.
ofeachalgorithmisalsodifferent.However,thereisalways
onealgorithmthatwinsthesinglebestsolverinaquitedom-
inantway,makingthedatasetveryimbalanced.
butalsohasagoodperformance.Othermodernmodelscan
alsobesuccessfulintaskswhilesmallinthenumberofpa-
ParameterDetails
rameters. On the other hand, when we use the ViT-Large
Hereweprovideourdetailedhyperparametertablewithour modelinsteadofViT-Basemodelonthegroupoftaskswith
searchspaceinTable.7andTable.8.Duetolimitedcomput- w=0.001,wefoundtheperformanceisnotimproving.This
ingresources,forMAPFASTER,weonlyusetheparameter isbecauseourdatasetisrelativelytoosmalltostopalarge
proposedbytheoriginalpaper. modelfromoverfittingthedataset.
DiscussiononChoosingaNeuralNetworkfor
AlgorithmSelection
While we have found that ViT is the neural network that
wins the most time, it is also interesting to see how results
changeaccordingtothenumberofparametersithas,which
affectboththetrainingtimeandtheinferencetime.Wecon-
cludeourfindingsinFig.6.Wefindthatwhilewehaveused
thesmallestvariantsofeachgroupofneuralnetworks,ViT
is the one that not only has a small number of parametersMAPFAST ViT VGGNet ResNet MAPFASTER SBS SBS
cl Acc Gap
Dataset Task Acc↑ Gap↓ Acc↑ Gap↓ Acc↑ Gap↓ Acc↑ Gap↓ Acc↑ Gap↓ Acc↑ Gap↓
Score-0.001-CE 0.81 21.07 0.81 19.03 0.84 20.49 0.91 2.60 0.80 1.00 0.80 1.00
Score-0.001-BCE 0.85 4.48 0.83 18.67 0.85 22.37 0.86 50.94 0.80 1.00 0.80 1.00
Score-0.001-Reg 0.80 0.89 0.79 0.87 0.80 1.00 0.80 0.94 0.80 1.00 0.80 1.00
Score-0.1-CE 0.61 16.73 0.61 14.83 0.69 12.90 0.61 1.11 0.57 1.00 0.57 1.00
Score-0.1-BCE 0.65 10.74 0.62 14.79 0.67 9.20 0.56 2.55 0.57 1.00 0.57 1.00
Score-0.1-Reg 0.57 0.75 0.57 0.71 0.57 1.00 0.57 1.00 0.57 1.00 0.57 1.00
Standard Score-1-CE 0.62 1.82 0.69 1.95 0.66 2.09 0.60 3.52 0.62 2.53 0.62 1.00
Score-1-BCE 0.57 4.42 0.68 1.89 0.64 1.96 0.62 2.53 0.62 2.53 0.62 1.00
Score-1-Reg 0.56 0.71 0.30 0.92 0.26 1.00 0.47 0.75 0.26 1.00 0.62 1.00
Bound-1.1-CE 0.56 2.99 0.65 2.66 0.69 2.81 0.61 4.24 0.51 2.53 0.51 1.00
Bound-1.2-CE 0.72 1.64 0.74 2.07 0.73 4.59 0.58 2.20 0.19 2.53 0.51 1.00
Score-0.001-CE 0.70 1.11 0.71 1.12 0.70 0.97 0.69 1.00 0.69 1.00 0.69 1.00
EECBS Score-0.001-BCE 0.69 1.05 0.69 1.00 0.70 0.93 0.69 1.00 0.69 1.00 0.69 1.00
Score-0.001-Reg 0.69 1.00 0.69 1.00 0.69 1.00 0.69 0.93 0.69 1.00 0.69 1.00
Table 6: The accuracy (Acc) and VBS-SBS gap (Gap) results for different models and different learning tasks in terms of
accuracy and VBS-SBS gap. The names of the tasks are shown in the Task column, following the naming described in the
experimentsettingsection.Thebestresultsforeachmetriconthesameoptimizationobjectivesaremarkedwithbold(Bound
tasksdonothaveboldinGapmetricsbecauseinboundtasksaccuracyisnormallytheprimaryfocus).
VGGNet ViT
inputsize 384 384
optimizer Adams Adams
learningrate 3e-6 3e-6
learningratesearchspace 1e-4,5e-5,3e-5,1e-5,3e-6,1e-6 1e-4,5e-5,3e-5,1e-5,1e-6
weightdecay 3e-2 0
optimizermomentum β ,β =0.9,0.999 β ,β =0.9,0.999
1 2 1 2
batchsize 64 64
trainingepochs 80 80
learningratescheduler Linear Linear
warmup 5 0
randomflipping 0.5 0.5
randomrotate 0.5 0.5
randomerasing 0.5 0.5
Table7:Hyperparametertablewithsearchspace.
Figure 6: Comparing the gap for different neural networks
ontheScore-0.001-Regtaskbasedonparametercount.
Figure 5: Dataset result for the case of score = time +
0.001×costasscoredefinitiononhyperparameterselection
(EECBS)dataset.MAPFAST ResNet
inputsize 384 384
optimizer Adams Adams
learningrate 1e-5 1e-5
learningratesearchspace 1e-4,5e-5,3e-5,1e-5,3e-6,1e-6 1e-4,5e-5,3e-5,1e-5,3e-6,1e-6
weightdecay 0 3e-2
optimizermomentum β ,β =0.9,0.999 β ,β =0.9,0.999
1 2 1 2
batchsize 64 64
trainingepochs 80 80
learningratescheduler Linear Linear
warmup 0 5
randomflipping 0.5 0.5
randomrotate 0.5 0.5
randomerasing 0.5 0.5
Table8:Continuinghyperparametertablewithsearchspace.