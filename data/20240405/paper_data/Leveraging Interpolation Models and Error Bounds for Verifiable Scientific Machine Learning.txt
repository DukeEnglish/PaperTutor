Leveraging Interpolation Models and Error Bounds for Verifiable
Scientific Machine Learning
Tyler Changanl, Andrew Gillettellnl, and Romit Maulikanl,penn
anlMathematics and Computer Science Division, Argonne National Laboratory
llnlCenter for Applied Scientific Computing, Lawrence Livermore National Laboratory
pennInformation Sciences and Technology Department, The Pennsylvania State University
April 5, 2024
Abstract
Effective verification and validation techniques for modern scientific machine learning workflows are
challengingtodevise. Statisticalmethodsareabundantandeasilydeployed,butoftenrelyonspeculative
assumptionsaboutthedataandmethodsinvolved. Errorboundsforclassicalinterpolationtechniquescan
providemathematicallyrigorousestimatesofaccuracy,butoftenaredifficultorimpracticaltodetermine
computationally. Inthiswork,wepresentabest-of-both-worldsapproachtoverifiablescientificmachine
learning by demonstrating that (1) multiple standard interpolation techniques have informative error
bounds that can be computed or estimated efficiently; (2) comparative performance among distinct
interpolants can aid in validation goals; (3) deploying interpolation methods on latent spaces generated
by deep learning techniques enables some interpretability for black-box models. We present a detailed
case study of our approach for predicting lift-drag ratios from airfoil images. Code developed for this
work is available in a public Github repository.
Keywords: interpolation;scientificmachinelearning;verificationandvalidation;uncertaintyquantification
1 Introduction
In recent years, data-driven surrogate modeling research has shown great promise in improving the pre-
dictability and efficiency of computational physics applications [1, 2]. Surrogate models frequently utilize
deep learning techniques for function approximation and have found application in control [3], optimization
[4, 5], uncertainty quantification [6, 7, 8], and data assimilation tasks [9, 10], among others. However, the
widespread adoption of deep learning models is still limited by their black-box nature, which makes their
results difficult to interpret and verify [11]. Therefore, devising new models, techniques, and workflows that
are interpretable and verifiable is considered one of the grand challenge problems for the next decade of
scientific machine learning [12].
Inthisstudy,wefocusontheimportanceofpredictivemodelinginthecontextofcomputationalphysics.
Specifically, we will analyze the usage of established interpolation models for surrogate modeling of complex
physical systems, characterized by high computational costs when using first-principles based techniques.
Wewilladdressacommonandessentialproblemformulationthatarisesindeeplearningmethods,machine-
learning-based regression, and classical multivariate interpolation: given data from a multidimensional con-
tinuous input space, predict a single continuous response variable. More precisely:
given a training set consisting of n data points x Rd paired with response values f(x ) R,
i i
predict the
responseD
values for previously unseen
i{ npu} ts⊂
within some pre-determined
regio{
n
}R⊂
d.
X ⊂
Tobetterunderstandtheperformanceofinterpolantsonlarge,complexdatasets,weturntotheclassical
techniquesformultivariateinterpolationvianonparametricmodels. Oneofthemainadvantagestorestricting
ourstudytointerpolationasopposedtoincludingregression,isthatmanyinterpolationmethodshavestrict
1
4202
rpA
4
]GL.sc[
1v68530.4042:viXraand easily-interpretable error bounds and well-known convergence rates [13]. In the context of scientific
machinelearning,theseerrorboundscanbeleveragedtoverifythecorrectnessofamodelanditsapplicability
to a given problem. Additionally, the direct dependence of these models and their bounds on the training
dataorsimplebasisfunctions,allowsforpredictionstobeinterpreted,particularlywhenworkingwithsmall-
to medium-sized data sets.
In low- and medium-dimensional settings with noiseless (or low noise) training sets, interpolation tech-
niquessuchaspiecewise-linearinterpolation,interpolatingsplines,andinverse-distanceweightingshavebeen
showntobecompetitivewithmachinelearningtechniques,suchasmulti-layerperceptrons(MLPs)andsup-
port vector regressors [14]. Other interpolation techniques such as radial-basis function (RBF) models and
Gaussian processes are frequently used as global [15, 16] and local [17] surrogate models for optimization of
physical systems. By analyzing these methods and their error bounds and computing them on real scientific
machine learning tasks, we will demonstrate the usefulness of these techniques for producing verifiable sci-
entific machine learning workflows. However, we must first address several challenges that have limited the
usage of interpolation models for these regimes in the past.
First, regardless of the approximation techniques used, the predictive accuracy of the resulting model is
fundamentally limited by the size and quality of , relative to the complexity of the problem. In particu-
D
lar, the black-box problem formulation given in the previous paragraph is extremely sensitive to the curse
of dimensionality. As the dimension d of the problem increases, it is expected that maintaining a fixed
level of accuracy in the approximation of f across the entirety of will require exponentially more data
X
(i.e.exponentialgrowthinn). Forgenericdatascienceproblemsinextremelyhigh-dimensionalsettings,itis
worthnotingthatthetop-performingdeeplearningmodelsutilizetrainedorhand-craftedembeddinglayers,
whichareabletoautomaticallyextractlower-dimensionalfeaturesformodelingwhentheinputspacecanbe
effectively embedded by exploiting some problem-specific structure(s) [18]. In the context of computational
physics, these embeddings may be inspired by some domain knowledge or physical structure of the problem
[19, 20, 21, 22]. One key observation is that these embedding layers effectively reduce the problem into a
continuouslatentspace,inwhichthefully-connectedlayersformaresponsesurfaceresemblingthatofmany
classical approximation/interpolation methods.
Second, many classical interpolation techniques are intended for smooth noiseless problems, whereas
real-world functions are often noisy or non-smooth. It is often believed that (1) interpolation models will
not perform well in these high-dimensional black-box modeling regimes, due to risk of overfitting to non-
smoothness and noise in the training data, and (2) machine learning models balance training loss against
overfitting–oftenreferredtoasthebias-variancetradeoffcurve. However,contrarytoconventionalwisdom,
recent work has shown that large over-parameterized models that interpolate or nearly-interpolate training
data often achieve state-of-the-art performance on standard benchmark problems [23], and interpolation
techniquesperformsimilarlytomanyofthemachinelearningtechniquesdiscussedaboveinhigh-dimensional
regimes, so long as the signal-to-noise ratio is within reason [24, 25, 26].
Inthispaper,weproposeasurrogatemodelingstrategythatutilizesinterpolationmethodstogetherwith
theirerrorboundsforverifiability, therebyalleviatingasignificantlimitationofdeeplearningmethods. Our
main contribution is an empirical study of how various known interpolation error bounds can be used to
verify modern machine learning workflows. To do so, we have proposed best practices and approximations
for several well-known interpolation techniques and their error bounds in order make them computable for
practical applications. We also demonstrate how interpolation methods can be leveraged in a real-world
scientific machine learning workflow that leverages deep learning techniques to extract low-dimensional rep-
resentations of challenging high-dimensional problems. Finally, a convenient aspect of certain interpolation
methods is that each prediction is interpretable, allowing us to provide additional diagnostic information
when validating results.
Our work is partially inspired by the paradigm of geometric deep learning [18], which suggests that all
modern deep learning can be decomposed into representation learning vs. regression layers. We are also
inspired by the theoretical work of Belkin [25], who has shown that interpolation is an effective paradigm
for high-dimensional learning. Finally, we build upon the recent work of Lux et al. [26] who studied how
interpolation methods can be effectively utilized for a wide variety of regression problems, and Gillette
and Kur [27] who demonstrated how Delaunay interpolation convergence rates could be used to validate
regression outputs. Setting ourselves apart from these previous works, here, we consider error bounds for
various distinct interpolation methods and observe the properties of a problem that make it amenable to
2prediction by each of these methods, in order to derive best practices. Since there are many advantages
to utilizing deep learning for scientific applications, our main motivation is to identify how deep
learning could be augmented with interpolation, especially during model validation. We argue
that validation is an ideal setting to utilize interpolation, since most interpolation methods do not require
significant hyperparameter tuning and offer predictable performance for well-defined problems.
The remainder of this paper is organized as follows. In Section 2, we will introduce several well-known
interpolationmethodsanddescribetheirrelevantcomputationsanderrorbounds. Wewillalsocomparetheir
prosandcons,specificallywithrespecttoMLP-basedregressionmodels. InSection3,wewillcomparethese
methods for mathematically-defined test functions, with controllable smoothness, skew, and data spacing
factors. This allows us to assess the robustness of each method, and speculate about when each might be
mostuseful. InSection4,weprovideanexamplewherethesemethodsareusedandcomparedonascientific
machine learning case study related to airfoil modeling, in order to demonstrate how these methods can
be used in a scientific machine learning workflow that also leverages representation learning. Finally, in
Section 5, we summarize our results and provide final recommendations about how to use interpolation for
scientific machine learning verification.
2 Interpolation Methods and Error Bounds
Inthissectionwediscusscommonmethodsforinterpolatinganunknownblackboxfunctionf :Rd Rgiven
arbitrary training data inputs = x n Rd and paired outputs f( ) = y n R at an→ arbitrary
“query” or “test” point q
D Rd{ (bi } ui t=1 q⊂
). Specifically, we have
cD hosen{ coi } mi= m1 o⊂
n methods from the
∈ X ⊂ ̸∈ D
literaturethatarewell-definedforlargevaluesofnandd, anddonotrelyuponanystructuredarrangement
of . All of our analysis is also based upon scattered training data , which is the least restrictive case.
D D
We generally assume that f is Lipschitz continuous, which is a standard assumption, but we do not
assume any prior knowledge about the structure of f, such as gradient information, prior expectations, or
constraintsfromphysics. Forcomputationalworkflowswheresuchknowledgeisusedorrequired,ourresults
could be adopted from this general setting to a more specific one. For some of our error analyses, additional
assumptions about f will be required, which we will highlight explicitly.
For each of the methods, we have organized the corresponding subsection into a mathematical summary
of the method, followed by sub-subsections for a description of the error bounds, advantages and challenges
of each technique, and description of our computational methods. To this last point, for each technique, we
have carefully chosen a specific method for calculating a prediction and its error bounds, in order to avoid
ambiguity. These techniques are chosen primarily to best reflect the theory, so that the error bounds will be
mostpracticalandthetechniquescanbeusedconsistentlyacrossawidevarietyofscientificmachinelearning
problems. In particular, we have intentionally avoided tuning any hyperparameters for specific problems, as
this would introduce an additional source of error and bias, which would go against our motivation to use
interpolation methods for verification of scientific machine learning workflows.
2.1 Mesh-based Interpolation and the Delaunay Interpolant
In low dimensions, unstructured mesh-based interpolants are widely used for scattered data sets in com-
putational geometry, visualization, and physical modeling. Error bounds for mesh-based interpolants are
well-understood, especially in the context of finite element methods [28]. Few mesh-based methods can be
extended to arbitrary dimensions, however, due to the so-called the “curse of dimensionality” for geometry-
based methods.
Notably,piecewiselinearinterpolationwithrespecttoasimplicialmeshstructurecanbecarriedoutina
scalableandcomputationallyefficientmannerinhigherdimensions. Todefineapiecewiselinearinterpolant,
one needs a simplicial mesh over the training data inputs, denoted T( ), such that every simplex in T( )
D D
has vertices in . Putting aside the construction of the mesh for a moment, suppose the query point q is
containedintheD simplexS(i) T( ), withvertices x(i,0),...,x(i,d) . Thenthereexistuniqueinterpolation
T ∈ D { }
weights w = w ,...,w given by solving
0 d
{ }
d
A(i)w
=q, w =1
(cid:88)
w
T 1:d 0 − i
i=1
3where
(cid:104) (cid:105)
A(i) = x(i,1) x(i,0) x(i,2) x(i,0) ... x(i,d) x(i,0) . (1)
T − | − | | −
The piecewise linear interpolant fˆ for q in S(i) is then defined as the weighted sum
T T
d
(cid:88) (cid:16) (cid:17)
fˆ (q):= w f x(i,j) (2)
T j
j=0
Note that it is possible for q to be contained in the boundary between multiple simplices, but the value of
fˆ (q)willagreealongtheseboundariessuchthatfˆ iswell-definedandcontinuousontheentireconvexhull
T T
of . This method is called barycentric interpolation and dates back to work by M¨obius [29].
D
To define a mesh T, we employ Delaunay triangulation [30], a classical technique that is widely used for
unstructured meshes in d=2 or 3 [31], but is defined without restriction on the dimension d. The Delaunay
triangulationDT( )isasimplicialmeshwhoseelementsaredeterminedbythe“opencircumball”property.
D
Specifically, for each simplex S(i) DT( ), the open circumball B(i) about S(i) satisfies B(i) = . For
∈ D ∩D ∅
in general position, this definition is also sufficient to guarantee existence and uniqueness of DT( ). We
D D
will use the notation fˆ to mean the the interpolant defined in (2) with mesh T :=DT( ).
DT
D
2.1.1 Error bounds for Delaunay and other simplex interpolants
The generic piecewise linear interpolant fˆ from (2) can be used to approximate any Lipschitz continuous
T
f. Under the stronger assumption that f 1 and every component of f is γ-Lipschitz continuous (for
∈ C ∇
some fixed γ >0), it is shown in [26] that the following first-order Taylor-like bound holds:
γ q x(i,0) 2 √dγk2
f(q) fˆ (q) ∥ − ∥2 + q x(i,0) . (3)
T 2
| − |≤ 2 2σ ∥ − ∥
d
where k =max x(i,0) x(i,d) and σ is the smallest singular value of A(i). Note that in practice,
x(i,0) can be chj o∈ s{ e1 n,.. t. o,d } b∥ e the n− earest∥ v2 ertex ofd S(i) to q. We remark that a similaT r bound is derived in [32]
T
under slightly different assumptions.
Lethdenotethemaximumdiameterofasimplexinthemesh. Sinceboth q x(i,0) andkarefunctions
2
∥ − ∥
of the density of in the query region , they are each bounded above by h. Accordingly, the above bound
D X
reduces to
γ √dγ k
f(q) fˆ (q) h2+ h2. (4)
T
| − |≤ 2 2 σ
d
Notice that k/σ can be upper-bounded by the condition number of
A(i)
and is actually an estimate for the
d T
aspect-ratio of the containing simplex. In other words, so long as the aspect ratio of the simplices in T( )
D
can be upper-bounded, the interpolation error is f(q) fˆ (q) (h2). The correlation between good
T
| − | ∈ O
aspect ratio of simplices and good interpolation error estimates has led to various notions of optimality for
Delaunay triangulations [33, 34].
2.1.2 Advantages and challenges of Delaunay interpolants
The Delaunay interpolant is entirely deterministic with no hyperparameters, a significant advantage over
othertypesofinterpolantsthatwewillconsider. ThereisnoconceptoftrainingorfittingaDelaunay-based
model since fˆ is well-defined. Consequently, there is a “hidden” savings in using Delaunay methods in
DT
that no time or effort needs to be invested in identifying suitable hyperparameters or training a model. In
addition,thesimpleformoffˆ providesaclearnotionofinterpretability: aninterpolatedvalueqisuniquely
DT
determined by a weighted sum of the data points at the vertices of the simplex containing q. Evidence for
the accuracy and efficiency of Delaunay interpolants for regressing scientific data sets was shown in [26].
Additionally, eveninthecontextofclassificationwithnoisydata, theriskofaDelaunayinterpolation-based
classifier has been shown to approach the Bayes risk in high dimensions [24].
A challenge when employing Delaunay interpolants is a potentially expensive computational cost at
inference time. Many common approaches for computing Delaunay triangulations are impractical in even
4moderate dimensions, due to the exponential size of DT( ) with growing d [35]. However, it is possible
D
to identify the single simplex needed to calculate fˆ (q) for any given q at inference time, for the cost of
DT
solving a linear program [36, 37]. This approach is scalable enough for usage with moderately-sized training
sets, but still considerably more expensive than making a single prediction with many comparable neural
network models, such as MLPs. Additionally, when implementing such an approach, one must be careful
of geometric degeneracy, which results in a degenerate linear program and could cause failures in certain
solvers. These degeneracies occur with probability zero in theory, but are extremely common in real-world
data sets. For instance, if any subset of a training set is grid-aligned, the geometry of the data would be
considered degenerate.
Another challenge of Delaunay interpolation is the failure to natively handle extrapolation outside the
convex hull of the training data, denoted CH( ). Consider an extrapolation point z , but z CH( ).
D ∈X ̸∈ D
One solution is to handle this by projecting each such z onto CH( ) and interpolating the projection zˆ.
D
Assuming that f is L-Lipschitz continuous and extending the error bound in (3), we have the extrapolation
error estimate
γ zˆ x(i,0) 2 √dγk2
f(z) fˆ (z) ∥ − ∥2 + zˆ x(i,0) +L zˆ z . (5)
T 2 2
| − |≤ 2 2σ ∥ − ∥ ∥ − ∥
d
This is a reasonable approach when the extrapolation residual zˆ z is relatively small, but can lead to
2
∥ − ∥
extremely large errors when extrapolating far from the convex hull of the data. However, it is worth noting
that large extrapolation residuals correspond to out-of-sample predictions. Therefore, it is expected that
many methods would suffer when making such predictions, and the extrapolation residual can serve as a
useful piece of diagnostic information for any methodology.
2.1.3 Our methods for Delaunay interpolation
In this paper, we use the DelaunaySparse software, which computes only the single simplex from DT( )
D
containing q, as is needed to compute the value of fˆ (q) [38]. One advantage of DelaunaySparse is that
DT
it is extremely robust and handles issues that arise when working with degenerate training sets (i.e., not
in general position) for little additional expense beyond the linear programming formulation. Additionally,
DelaunaySparse automatically detects when a query point q is outside CH( ) and projects q onto the
D
convex hull, as described in Section 2.1.2.
To compute the error bounds from Section 2.1.1, we first note that for real-world problems, the bound
(4) is often overly pessimistic as it is derived from a worst-case analysis. In fact, it is a Taylor-like bound
(cid:13) (cid:13)
centeredatx(i,0),basedonthefactthattheerrorinsimplex-gradientccouldbeatmost(cid:13) f(x(i,0)) c(cid:13)
∇ − 2 ≤
√dγk2/2σ . Thus, σ represents the worst-case error when using the d directional derivatives given by
d d
columns of A to estimate the gradient, assuming that the maximum change in f occurs in the direction
T
∇
of least information. Further, the value of γ is effectively the worst-case Lipschitz constant for f over all
∇
of , which may not be representative of the local variation in f, a more relevant quantity for predicting
X ∇
a value at q.
We modify (4) into a computable estimate that better represents average-case error by applying the
following relaxations at a point q contained in simplex
S(i):
T
• Replace γ with γˆ, the local Lipschitz constant for f over S(i). Estimate γˆ as the max over all three-
∇ T
point divided difference estimates using only vertices from
S(i)
. This corresponds to a relaxation that
T
the componentwise Lipschitz constants of f may change across the domain .
∇ X
• Replace σ with σˆ , the average over all singular-values of the matrix A from (1). This corresponds
d d T
to a relaxation that the maximum change in f is typically not perfectly aligned with the direction
∇
of least information in A .
T
Using the above estimates, the revised bound for simplex-based piecewise linear interpolation becomes
γˆ √dγˆ k
f(q) fˆ (q) h2+ h2. (6)
T
| − |≤ 2 2 σˆ
d
Note that this is no longer a worst-case bound, meaning it can be violated in practice. However, we have
observed empirically that the revised bound is more practical than the original for predicting the true error.
52.2 RBF Interpolants and Thin-Plate Splines
Radial-basisfunction(RBF)interpolantsarefamiliesofinterpolantsthataredefinedbylinearcombinations
of radially-symmetric nonlinear basis functions. Given n data points, the RBF interpolant requires a collec-
tion of n basis functions, denoted Φ:= ϕ(i) n . Typically, each function ϕ is centered at a corresponding
{ }i=1 i
training point x(i) such that ϕ(i)(q) = b ( q x(i) ), where b is a one-dimensional basis function,
Φ 2 Φ
fixed over all Φ. Th∈ e fD unction b :R1 R1 is ca∥ lle− d the∥ kernel function of the interpolant.
Φ
→
The first step in fitting an RBF interpolant is (typically) fitting a “polynomial tail” t(q), computed via
generalizedlinearregressionwithpolynomialbasisfunctions. Inthispaper,wewilluseeitheraleast-squares
approximation for a linear tail, resulting in t(q) = t (q) := α q+β for some α,β, or a constant tail given
1 ⊤
by t(q)=t (q):=(cid:80)n f(x(i))/n.
0 i=1
The next step is to solve the linear system given by
 f(x(1)) t(x(1)) 
−
A c= . .  (7)
Φ  . 
f(x(n)) t(x(n))
−
where
 ϕ(1)(x(1)) ϕ(2)(x(1)) ... ϕ(n)(x(1)) 
 ϕ(1)(x(2)) ϕ(2)(x(2)) ... ϕ(n)(x(2)) 
A Φ :=  . . . . . .  . (8)
 . . . 
ϕ(1)(x(n)) ϕ(2)(x(n)) ... ϕ(n)(x(n))
The RBF interpolant fˆ for q is then defined by
Φ
n
(cid:88)
fˆ (q):= c ϕ(i)(q)+t(q). (9)
Φ i
i=1
Note that since each ϕ(i) is radially symmetric about x(i), A is symmetric. When Φ are also positive
Φ
definite, then A is symmetric positive definite, and (7) can be solved via Cholesky decomposition, which
Φ
is slightly faster than LU or QR decomposition. However, in both cases the time complexity is cubic and
space complexity is quadratic in n [39].
2.2.1 Error bounds for RBFs
ErroranalysisforRBFinterpolationistrickybecausetheerrorboundsdependonglobally-dependentquan-
tities derived from f, which would rarely be known in practice. We focus on a bound provided by Powell
[40] and explained in [41, Theorem 1] as follows. Define
h:= sup inf x x ,
i
x
∈Xxi∈D∥ − ∥
i.e.,histhelargestdistancetoapointin over . Then,foranyneighborhood q suchthat0<h<1,
D X X ∋
there is a constant C, independent of h, and q, such that
D
f(q) fˆ (q) C f h(cid:112) log(h 1) (10)
| − Φ |≤ ∥ ∥Φ −
where f is the homogeneous Sobolev norm of order 2 on f.1 With additional higher order Sobolev or
Φ
∥ ∥
Lipschitz smoothness assumptions on f, the above bound can be improved to (h2k+η) for some η >0 and
O
then used to prove convergence results; see [41].
Sticking with a mere Lipschitiz continuity assumption for f, we are not aware of a computable estimate
for C or f . However, it is useful to note the scaling behavior of (10) with respect to h. Note that h is a
Φ
∥ ∥
measure of the density of in . If becomes dense enough, the estimate is dominated by the log(h 1)
−
D X D
1Thenormonf comesfromthenorminducedbythereproducingkernelHilbertspaceforf,sometimescalledthe“native
space” of f, which reduces to a homogeneous Sobolev norm in this case (by completion of native space with respect to the
Sobolevseminorm);see[41]formoredetails.
6term, which blows up as h 0, in that large h values indicate less density, somehwere in . The blow up
→ X
is a feature, not a bug, of the estimate, as it reflects the numerical ill-conditioning of the linear system (8)
as the training data clusters.
The behavior of the estimate highlights the so-called “uncertainty principle” for RBFs, which roughly
states that it is not possible to achieve uniform convergence and solvability of fˆ [42]. This ill-conditioning
Φ
is still particularly prevalent for unbalanced training sets, and may be amplified depending on the choice of
basis function Φ.
2.2.2 Advantages and challenges of RBFs
When the size of the data set n is small, RBF interpolants are relatively cheap to fit. Additionally, many
choicesofbasisfunctions—includingthethin-platesplinefunctionsthatwewilldescribeinthenextsection—
there are often no hyperparameters. Evaluation of the interpolant at query-time is also quick with O(nd)
complexity. It is thus no surprise that RBF methods are a popular off-the-shelf solution to a wide variety of
interpolation problems.
As n gets large, the complexity of solving (7) becomes prohibitive. The factorization of (8) has a time
complexity (n3) and space complexity of (n2). To reduce this burden for large problems, a hyperparam-
O O
eter k is introduced and the interpolated value is determined using only the k nearest neighbors. However,
cuttingoffbased onaneighborhood criterioncreatesdiscontinuitiesinfˆ , whichcanbeundesirable. For
RBF
theproblemsthatweareworkingwith,thedatasetsdonotgrowlargeenoughinnforthe (n3)complexity
O
to become a concern, so we do not consider any of the above approaches. However, it is worthwhile to note
these issues for larger problems.
For many common RBF kernels, Φ(x) 0 as x so that each ϕ can be interpreted as a similarity
i
→ →∞
metricwithx(i),fori=1,...,n. However,thisalsoimpliesthatwhenqisoutsideCH( ),thenthepredicted
X
value of the RBF kernel will approach the value of the tail, t(q). This may be extremely inaccurate if f is
not well-approximated by a constant or linear function. For other common RBF kernels, Φ(x) may diverge
at infinity, in which case it is difficult to interpret the value of each ϕ (q), and the overall approximation
i
fˆ (q) may also diverge when q is outside CH( ).
Φ
X
Comparedtotheotherinterpolantsthatweconsider,onecriticalchallengeforagenericRBFinterpolant
is that the error bound cannot be easily calculated or approximated. One critical unknown in (10 is the
value of the constants C and f . In principle, these values can be determined independently of the
Φ
∥ ∥
data set , however in practice they cannot be known for many real-world applications. We will see a
D
special case in Section 2.3.1 where an error bound can be derived by statistical means, but this approach is
kernel-dependent.
2.2.3 Our methods for RBF interpolation and the TPS kernel
In this paper, we focus on the thin-plate spline (TPS) kernel RBF interpolant. The tail function is linear,
i.e. t = t , as defined in Section 2.2. The basis functions are ϕ(i)(q) := q x(i) 2log q x(i) . These
1
∥ − ∥ ∥ − ∥
choices are the default settings for the RBFInterpolator class in scipy.interpolate [43], which we use in
this rest of this paper. We denote the resulting interpolant by fˆ .
TPS
WehaveselectedtoexamineTPSRBFinterpolantsforseveralreasons. First, TPSRBFsareconsidered
“standard,” as evidenced by their role as the default setting for scipy.interpolate. Second, TPS RBFs
are less sensitive to the conditioning issue noted in Section 2.2.1 than other choices for basis functions Φ, as
wewillseeinSection2.3. Finally,itisworthnotingthattheTPSkernelhasnoadditionalhyperparameters,
making it a convenient choice for verifying machine learning workflows.
However, TPS RBFs also face some drawbacks relative to other RBF kernels. First, the TPS kernel
x2log x is not monotone decreasing, which prevents it from being interpreted as a similarity metric. Ac-
| |
cordingly, it can be difficult to interpret the predictions of a computed TPS RBF interpolant on a given
dataset. Further, since the kernel function diverges at infinity, the approximation of a TPS interpolant
can become arbitrarily bad if the query point q corresponds to geometric extrapolation, as described in
Section 2.2.1.
For the error bounds, as noted in Section 2.2.1, it is not possible for us to know the true bound due to
the constants C and f . In this paper, we approximate the product of these constants by the Lipschitz
Φ
∥ ∥
7constant L. This yields a practical bound of
f(q) fˆ Lh(cid:112) logh. (11)
TPS
| − |≤
ThisboundissimilartoasimpleLipschitzbound, whichwouldbeareasonablescaleandalsomaintainsthe
same convergence rate as (10). Note that although there is no direct dependence on the dimension d, both
L and h tend to increase with the dimension in practice.
2.3 Gaussian Processes for Interpolation
Gaussianprocesses(GPs)areoftenmotivatedandusedasaregressiontoolforcontextswhereapproximation
of a function is iteratively updated by the addition of new data. In this work, since our data set is fixed
and we are interested in interpolation rather than approximation, we find it more relevant to treat GPs as a
special case of RBFs. 2 Following the notation from (7), (8), and (9), the GP kernel, denoted Φ=GP, has
Gaussian basis functions given by
ϕ(i)(q)=e q x(i) 2/τ,
−∥ − ∥
where τ is a shape parameter that corresponds to the standard deviation of the spatial correlation between
training points.
In many applications of GPs, one uses a domain-specific prior function in place of the polynomial tail
t(q) from (9). Here, we do not assume access to any such prior and hence take the constant approximation
t(q) = t (q) := (cid:80)n f(x(i))/n, which is standard in the GP literature for dealing with a “black box”
0 i=1
function. We denote the resulting interpolant by fˆ .
GP
2.3.1 Approximate error bounds for GPs
Since the type of GP we are considering is a special case of RBFs, deriving practical, guaranteed error
bounds by direct analysis encounters the same challenges described in Section 2.2.1. However, unlike the
TPS method, GPs have a statistical interpretation that admits computable uncertainty estimates based on
the standard deviation of the posterior distribution.
We view fˆ as the posterior distribution over all possible realizations of f given the observed training
GP
data . By this interpretation, we attain an easily computed uncertainty estimate for any value predicted
by
fˆD
. Since the standard assumptions for a GP lead to a Gaussian posterior, two standard deviations
GP
above and below the mean yield (approximately) a 95% confidence interval. Thus, we take two standard
deviations above and below the mean as approximate error bounds for fˆ .
GP
Following the analysis in [16, Ch. 2], the variance of the posterior distribution for fˆ at q is given by
GP
(cid:16) (cid:17) (cid:16) (cid:104) (cid:105) (cid:17)
p fˆ (q) f;E fˆ (q),K(q,x) ,
GP GP
| D ∼N
with variance
  ϕ(0)(x) 
K(q,x)=τ f e −∥q −x ∥2 2/τ −(cid:16) ϕ(0)(q),...,ϕ(1)(q)(cid:17) A−GP1 

. .
.
  ,
ϕ(1)(x)
where τ is the true variance in response values for f and A is given by the RBF interpolation matrix
f GP
from (8) with Φ = GP. For an estimate of the variance at q, which can be used to evaluate the expected
variance in f(q) fˆ (q), this reduces to
GP
| − |
(cid:18) (cid:13)(cid:16) (cid:17)(cid:13)2 (cid:19)
K(q,q)=τ 1 (cid:13) ϕ(0)(q),...,ϕ(1)(q) (cid:13) (12)
f (cid:13) (cid:13)
− A−1
GP
where
∥·∥A− GP1
isthe2-normrescaledbyA−GP1,whichisalsoanormsinceA−GP1 issymmetricpositivedefinite.
Note that this interpretation of GPs relies on additional assumptions about the smoothness of f that
may not hold true in practice. For many real-world f, it is incorrect to assume that response values are
2InterpolatoryGPsarecloselyrelatedtoKrigingmodels,commonlyusedingeostatistics;see[44].
8Gaussian distributions and correlated with other response values based on the exponential of the inverse
squared distance in the input space. Further, if f is not smooth enough, the error approximation by the
above interpretation yields poor estimates. Nevertheless, the uncertainty estimate is widely used and is
considered a useful heuristic in many applications.
2.3.2 Advantages and challenges of GPs
Since they are a form of RBF interpolants, the computational complexity of GPs is the same as previously
described in Section 2.2.2, and we will not discuss them again here. Aside from the TPS RBFs that were
usedinSection2.2,GPshaveanumberofrecognizedadvantages,whichexplainstheirpopularity. First,the
statistical interpretation of GPs enables the often useful uncertainty estimates described in Section 2.3.1,
an interpretation not available for TPS and many other RBF schemes. Second, the GP kernel can be
interpreted as a similarity metric, which allows for interpretability of the predictions of the method, as
discussed in Section 2.2.2. Third, when used with a mean prior (i.e., constant tail t from Section 2.2) and
0
appliedwelloutsidetheconvexhullofthetrainingdata,GPsgivepredictionsthattrendtowardthemeanof
thetrainingdatawithextremelyhighuncertaintyestimates. Thisisareasonableandconservativeapproach
to handle extrapolation compared to the possible divergence of the TPS RBF, but may still yield extremely
large errors.
A major challenge when using the GP uncertainty estimate is that it requires numerous additional
assumptions that may not hold-up in practice. In particular, GPs have very strong smoothness assumptions
about f and assume uniform spatial correlation between response values across the entire query region .
X
In many scientific applications, these additional assumptions are likely too strong, causing the estimates to
lose statistical accuracy.
Additionally, the Gaussian kernel introduces a shape parameter τ, whose value greatly impacts the
predictiveperformanceoftheGPmodel. Recallthe“uncertaintyprinciple”forRBFinterpolantsdiscussedin
Section2.2.1. ThisphenomenonisparticularlybadinthecaseofGPssinceσ decayssquared-exponentially
n
with the pairwise distance between training points. An alternative approach is to add a diagonal “nugget”
matrix εI to A , as is often done for GP regression. Proponents argue that this approach improves the
GP
supportoftheresultinginterpolantwhilealsododginganynumericalissuesresultingfrompoorconditioning
of A [45]. Since such an approach sacrifices the interpolation property and our study is focused on
GP
interpolation methods, we do not employ it here.
Inordertopreventthesematricesfromreachingnumericalsingularity,inpracticetheshapeparameterτ
mustbedecreasedtoimprovetheconditionnumber. Thisinturnrestrictsthesupportofeachkernel,thereby
creating gaps in the support of fˆ , and consequently greatly increasing the global approximation error. In
GP
order to fit a model that is both accurate and numerically stable, the RBF literature recommends choosing
a shape parameter τ that is as large as possible without causing singularity [42]. In modern applications,
significanttimeandenergycanberequiredtoperformhyperparametertuningtofindanappropriatevalueof
τ foreachfunctionf anddataset . Suchad hoc methodsinterferewithourabilitytouseGPinterpolants
X
for verifying machine learning workflows and are thus avoided.
2.3.3 Our methods for fitting GP interpolants
Compared to previous interpolation methods in Sections 2.1.3 and 2.2.3 where we also had to adjust the
error formulae in order to compute them, the GP’s confidence interval computations are clearly laid out
in Section 2.3.1 without ambiguity. Therefore, the main source of ambiguity is to determine the shape
hyperparameter τ of the GP model.
IntheGPmodelingliterature, authorsoftenexperimentwithvariationsoftheGaussiankernel(manyof
which introduce additional hyperparameters) and identify suitable hyperparameters (including τ) through
experimentation and/or domain knowledge. Often, this level of careful hyperparameter tuning is necessary
to achieve state-of-the-art performance with GP models. In this work, we specifically avoid such methods
since they require further verification.
Instead, we solve a small well-defined optimization problem based on the statistical literature to select
a maximum likelihood estimate of τ via scikit-learn [46]. Specifically, the log-marginal likelihood for
9observing the response values y n given the data x n is
{ i }i=1 { i }i=1
n n
1(cid:88) (cid:88) n
logp(y x )= y c logL log2π,
i i i i ii
| −2 − − 2
i=1 i=1
where L is a Cholesky factor of A [47]. In scikit-learn, this marginal likelihood function is maximized
GP
over possible values of τ using a multi-start L-BFGS solver. While this is still technically a small hyper-
parameter optimization problem, the problem is relatively inexpensive to solve and extremely reproducable
since we are tuning a single variable using second-order gradient-based methods.
2.4 Artificial Neural Network and Multilayer Perceptron Models
Inrecentyears,artificialneuralnetwork(ANN)modelshavebecomepopularmethodsforsurrogatemodeling
in scientific machine learning [48, 49, 50, 51, 52, 53]. Most of these architectures are regression-based and
thusnot,strictlyspeaking,interpolants. However,giventhatpartofourmotivationistostudythevalidation
of ANNs for scientific machine learning via interpolation, it makes sense to consider some common ANN
architectures here. As previously outlined, this motivation is backed by theoretical evidence that it is safe
to interpolate in modern complex applications [25] and empirical evidence that many top-performing ANN
models are, in effect, interpolating data [23].
Followingtheterminologyofthegeometricdeeplearningparadigm[18],amodernscientificmachinelearn-
ingANNarchitectureexploitsdomainknowledgeviasymmetriesthatenableitto“learn”lower-dimensional
feature representations. It then regresses these features with fully-connected layers, which may resemble
traditionalMLPs. It is worth noting that many architecturesdo not make aclear distinction between layers
thatperformthesetwotasksandtrainweightsforallkindsoflayerstogetherviabackpropogation. However,
onlythesefullyconnectedlayersarecomparabletointerpolants. Therefore,ourstudyfocusesoncomparison
between true interpolants and MLPs trained to (nearly) zero training error.
Ourscopedoesnotlimitusfromconsideringmorecomplexscientificmachinelearningworkflows, aswill
be demonstrated in Section 4. In general, we will consider ANNs of the following form
fˆ (y)=fˆ (fˆ (y)) (13)
ANN MLP R
where fˆ could be defined over a complex or higher-dimensional feature space but maps to a compact
R
Rd, and fˆ is a function from Rd R accurate on some bounded query domain , as described in
MLP
X Sec⊂ tion 2. The encoder portion of a latent→ space autoencoder network is an example of aX function fˆ that
R
fits the above description. We will consider fˆ of the form
MLP
fˆ (x)=ℓ(N) ℓ(N 1) ... ℓ(0)(x) (14)
MLP −
◦ ◦ ◦
where each “layer” ℓ(i) is of the form
ℓ(i)(x(i))=u(W(i)x(i)+b(i))
where u() is a nonlinear activation function, W(i) is a tensor who’s dimensions are compatible with x(i),
·
and b(i) is a tensor whose dimension match W(i)x(i).
The values of W(i) and b(i) for all ℓ(i) and any parameters in fˆ are determined by applying gradient
R
descent(training)withauser-providedlossfunctionviareverse-modealgorithmicdifferentiation(backprop-
agation).
2.4.1 Advantages and Challenges
One of the driving advantages of neural networks is that they are extremely flexible to utilizing different
representation learning schemes (functions fˆ ) and large networks can be trained in a scalable fashion
R
with extremely large datasets. In the context of scientific machine learning, the function fˆ and/or the
R
loss function can be customized to incorporate scientific domain knowledge and exploit symmetries in the
problem formulation [54, 55].
10Another practical advantage is that while ANN models may require significant amounts of time and
computational resources for training, they are generally much cheaper to evaluate at inference time, which
makes them easy to deploy. Additionally, compared to the interpolation models, they do not require access
to the training set at inference time, which could have privacy advantages in certain contexts. For these
reasons, it is likely impractical to fully replace ANN models (or even portions of them) in many real-world
applications.
However, the major drawbacks of ANN models is that given the formulation in (13) and trained model
weights, it is extremely difficult to interpret why a network made a given prediction. This coupled with
the approach to selecting parameter weights and lack of any hard error bounds makes it extremely difficult
to validate that models are performing accurately at inference time. This is one of the major barriers to
deploying these techniques on mission critical scientific machine learning applications [11].
This is not to say that there is no work in interpretable or uncertainty-aware scientific machine learning.
In [56], it is shown that a 2-layer MLP can achieve approximation-theory-like error bounds with a number
of parameters that grows with the non-smoothness of f, but independently of dimension. However, the
existence of such a model does not guarantee that it will be found during training, or that it even can be
found without exponential amounts of training data. However, this result motivates the usage of MLPs for
manyscientificmachinelearningtasks,whichwerepreviouslysolvedviaclassicalapproximationtheory,such
as those listed in previous sections.
Other works have proposed the usage of ensemble methods to provide uncertainty information [8], which
could be used for error bounding. Some analytic error estimation for neural networks also exist, typically in
domain specific contexts [57, 58, 59].
2.4.2 Our Methods for Training Neural Network Models
In this work, we are focused on validating MLPs, with the understanding that this could be leveraged for
validating portions of more modern architectures. Given the formulation in (14), there is still significant
flexibilityinarchitecturedefinitionswhentrainingMLPmodels, includingthenumberoflayers, weightsper
layer, and choice of activation function u(). There are also significant choices to be made when training.
·
One of the most common activation functions u() for constructing MLPs is the rectified linear unit
·
(ReLU) function, which is what we use in this work. MLPs with ReLU activation (ReLU MLPs) are also
piecewiselinearmodels,whicharestructurallysimilartotheDelaunayinterpolationmodelsfromSection2.1.
Inparticular,whentrainedto(approximately)zerotrainingerror,theybecomepiecewiselinearinterpolants.
In this work, we have trained ReLU MLPs with 3 hidden layers of 100 weights each and ReLU activation
functions via scikit-learn [46]. For training, we use the mean-squared error loss function, a batch size
of 20 for backpropagation, and the Adam optimizer with a learning rate of 10 8. We also use a randomly
−
selectedvalidationsetconsistingof10%oftheprovidedtrainingdataduringtraining,anduseearlystopping
whenthevalidationerrordropsbelow10 6. Thesearerecommendedsettingsforscikit-learnandwewill
−
see that they work well on a wide variety of problem types in Section 3. Additionally, to ensure consistency
of our results, we have trained 100 models for each problem and selected the best performing weights on the
validation set for testing.
While achieving true state-of-the-art performance may require additional work and customization to the
problem at hand, we believe that this is a fair and consistent methodology for our studies.
3 Empirical study of interpolation accuracy
In this section, we will consider the problem of interpolating n procedurally generated synthetic data in
Rd. This allows us to consider the effects of the training data spacing and underlying f on interpolation /
machine learning accuracy. We will consider a case study of a real scientific machine learning problem in
Section4. Withinthissection,SobolsequenceandLatinhypercubesampling(describedlater)iscarriedout
using the Quasi-Monte Carlo submodule scipy.stats.qmc [60], with the scramble option set to True.
Wehaveimplementedinterpolantsanderrorestimatesfromtheprevioussectioninaunified, lightweight
Python library [61]. As detailed in Section 2, we use routines from DelaunaySparse [38] to compute the
Delaunayinterpolant(2)andtherevisederrorbound(6);weuseRBFInterpolatorfromscipy.interpolate
[43] to compute the RBF interpolant (9); we make a simple approximation to the RBF bound (10); we use
11GaussianProcessRegressorfromsklearn.gaussian process[46]tocomputetheGPinterpolant(12)and
associated95%confidenceintervaldescribedin2.3.1,which,forthesakeofsimplicity,werefertoasthe“GP
bound;” and we use MLPRegressor from sklearn.neural network [46] to train a ReLU MLP regressor as
a proxy interpolant.
3.1 Dataset generation and experimental setup
Ourcodeallowsthecreationofrandomdatasetsinadeterministicfashionbyusingseedstosetuparandom
number generator. Each dataset we create is uniquely specified by the following parameters:
• d: dimension of the space from which samples are drawn.
• n: number of samples to draw.
• spacing: Sobol sequence (default), Latin hyper-cube, or uniform.
• seed: integer value used to initialize random number generator in numpy
• ω 0: parameter controlling the “variation” of the response function
≥
• α 0: parameter controlling the “skewness” of the sampled points
≥
Givenasetofparameters, thecodefirstdrawsnsamplesfrom[ 1,1]d, usingthespacingsamplingmethod
−
andarandomnumbergeneratorinitiatedwiththevalueof seed. Skewisappliedtothedatabymultiplying
thejthcoordinateofeachsamplepointbye (j 1)α/(d+1). Bythisdefinition,largervaluesofαcausegreater
− −
skew in the data (with more skew in higher indexed coordinates) while α=0 causes no skew to the data.
With the points x now set, we compute values of the response function f(x ) , defined by
i i
{ } { }
 
d d
1 1(cid:88) (cid:89) 1
f(x i):=f(x i1,...,x id)= 2
d
z j2
−
cos(2πωz j), where z j :=x ij
−
2.
j=1 j=1
Observe that for ω = 0, f is a paraboloid with a minimum value of 1/2 at (1/2,...,1/2), which we will
−
refer to as low variation over [ 1,1]d. Offsetting the paraboloid from the center of the domain removes one
−
aspect of symmetry and thus makes the function more generic. As ω increases, the period of the cosine
terms decrease, introducing increased deviation from the paraboloid shape. When ω =1, f attains two full
periods of the cosine terms over each coordinate direction of [ 1,1]d, which we refer to as high variation.
−
Wehavecarriedoutnumerousexperimentsexploringtheinterpolanterrorsandboundsoverthisparam-
eter space and report the most relevant findings below.
3.2 Effect of function variation (ω) over n and d
In this set of experiments, we look at the performance of the interpolant errors and bounds in four regimes:
interpolation or extrapolation when f has either low or high variation. For “interpolation” experiments, we
randomly select a point on the d-sphere of radius 0.1, which will always lie near the center of the sampling
domain [ 1,1]d. For the “extrapolation” experiments, we randomly select a point on the d sphere of radius
−
2, which is always outside the sampling domain. We use a Sobol sequence as the sampling strategy and set
α = 0 so there is no skew. We either fix the dimension to d = 5 and vary the number of samples, n, or fix
n=8192 and vary d; these values were chosen as representative examples for reasonably sized datasets. We
repeat each experiment with five distinct values of seed and report the average of the results.
In Figure 1, we show the results for fixing d=5. Delaunay and MLP results are shown in (a) while RBF
and GP results are show in (b). Bounds are shown with dashed lines and actual error (since we know the
true function) is shown with solid lines of matching color and markers. We will keep with these conventions
in the remaining subsections.
Turning first to the Delaunay and MLP results in Figure 1a, notice that the Delaunay bound overshoots
the actual error by one to two orders of magnitude above in the interpolation regimes and three or more
ordersofmagnitudeintheextrapolationregimes. Theseexperimentssuggestthattherevisederrorbound(6)
12lowvariation(ω=0) highvariation(ω=1) lowvariation(ω=0) highvariation(ω=1)
101 100
10−1
100
101
10−2
10−1
RBFbound
Delaunaybound 10−3 10−2 RBFerror
10−1 D Me Lla Pun era ry orerror 10−4 10−3 GPbound
100 GPerror
10−2 10−5 10−4
10−6 10−5
103 102
102 102 10−1 101
101
101 100
100
10−1 100
10−2
10−1
10−2 10−1 10−2
103 104 103 104 103 104 103 104
numberofsamples(n) numberofsamples(n) numberofsamples(n) numberofsamples(n)
(a) Delaunay and MLP (b) RBF and GP
Figure 1: For d = 5 fixed and increasing values of n, error bounds and actual error are shown in four
regimes: interpolation (top) vs. extrapolation (bottom) and low variation (left) vs. high variation (right) in
the response function. Of note, the GP bound is orders of magnitude below the actual error in the high
variation case.
maybeoverlyconservative,butthatitremainsanupperboundinallregimes. Thebounddoesnotimprove
with the addition of more data, indicating a bound computed from a subsample of a dataset may suffice
to bound an interpolant for a full dataset. Additionally, observe that the MLP approximation performs
similarly to the Delaunay interpolant. The ReLU MLP is a continuous piecewise linear approximation, just
like the Delaunay interpolant, and hence similar behavior between the two is to be expected.
Looking next at the RBF and GP results in Figure 1b, we see markedly different performance between
the two interpolants. The RBF bound is always a strict upper bound for the RBF error, however it ranges
from a very sharp estimate in the high variation, interpolation case to an overestimate by five orders of
magnitude in the low variation, interpolation case. On the other hand, the GP estimate is a relatively
tight bound for the actual error in the low variation cases, but dramatically underestimates the error, by as
much as five orders of magnitude in the high variation interpolation case. As mentioned in Section 2.3.1,
the poor performance of the GP estimate in this case can be attributed to the fact that f does not satisfy
the smoothness assumptions for the estimate. In an application setting, without a priori knowledge of the
variation in f, the usefulness of the GP estimate is questionable.
Finally, noticethedifferentscalesontheverticalaxes, especiallybetween(a)and(b). TheRBFandGP
errorsarethreeordersofmagnitudebetterthantheDelaunayandReLUMLPerrorsforthelargestnvalues
in the low variation, interpolation case, but this is expected as GP and RBF are providing smooth approxi-
mations to a smooth function with “a lot” of data. The difference in performance between the interpolant
types wears off as we move to the extrapolation regime or the high variation regime. A standout result is
the GP error that actually increases with n in the high variation, extrapolation case. This phenomenon
is explained by the shrinking support of the basis functions for the GP interpolant as more data is added,
which has the effect of removing information from extrapolatory regions.
In Figure 2, we show the results for fixing n = 8192, with additional conventions as in the previous
figure. For the Delaunay and MLP results, notice that the relative positions of the data are mostly stable
for d 5. We infer that the d=5 case from Figure 1a is representative of the relative performance of these
≥
interpolants for higher dimensions (at least up to 20). For d < 5, we see smaller errors in the interpolation
cases, due to the relative density of our fixed n in low dimensions. As d grows, the error effectively plateaus
while the bound increases, reflecting the greater uncertainty inherent in the higher dimensional settings.
For the RBF and GP results in Figure 2b, we notice many orders magnitude lower error of RBFs than
any of the other cases in the interpolation regimes, but the benefit is more modest as d increases or as we
move to an extrapolation regime. Also of note, the GP estimate again underestimates the error in the high
variation case until the dimension gets large (d 18 for interpolation, d 9 for extrapolation). Again, as in
≥ ≥
Figure 1, the RBF bound is found to be correctly bounding the RBF error, albeit sometimes overshooting
13
noitalopretni
noitalopartxe
noitalopretni
noitalopartxelowvariation(ω=0) highvariation(ω=1) lowvariation(ω=0) highvariation(ω=1)
100 100
1111
00001111 −−−−0000 43210123
111
0001111 −−−0000 3210123 D D Me e Ll la a Pu un n era a ry y orb ero ru on rd 1111111 0000000 −−−−−−−
111
4208642 111111 000000 −−−−−− 654321
R
R
G
GB
B
P
PF
F
b
erob
e rr
u
oo
r
n
ru
o
dn rd
102
103 103
102 102 10−1 101
101 101 100
100 100
10−2
10−1
111 000 −−− 321 11 00 −− 21 10−3 11 00 −− 32
5 10 15 20 5 10 15 20 5 10 15 20 5 10 15 20
dimension(d) dimension(d) dimension(d) dimension(d)
(a) Delaunay and MLP (b) RBF and GP
Figure 2: For n = 8192 fixed and increasing values of d, error bounds and actual error are shown in four
regimes: interpolation (top) vs. extrapolation (bottom) and low variation (left) vs. high variation (right) in
the response function. Crossover between the bounds and error as dimension increases is indicative of the
exponentially decreasing density for a fixed sample size.
by a couple orders of magnitude.
3.3 Effect of skew (α) and the importance of scaling
In these experiments, we keep the same conventions for interpolation versus extrapolation regimes and vary
only the parameter α to adjust the skew in the data set. We again use a Sobol sequence, fix d=5 and vary
over n. We compare data with “no skew” (α=0) to “highly skewed” data (α=10) and additionally toggle
rescalingofthe x pointsoffandon. Rescalingiscommonlyusedtoaidnumericalstability(andisrequired
i
{ }
for some machine learning algorithms) so we use this opportunity to study its effect in a toy example.
noskew(α=0) highskew(α=10),notrescaled highskew(α=10), {xi}rescaled
104 Delaunaybound
Delaunayerror
102 MLPerror
100
10−2
103
102
101
100
10−1
10−2
103 104 103 104 103 104
numberofsamples(n) numberofsamples(n) numberofsamples(n)
Figure 3: Delaunay interpolation is not affected by skew in the input data or rescaling, unlike the ReLU
MLP approximant. The Delaunay bound is affected by skew, but rescaling helps. The left column here is
the same as the left column of Figure 1a.
Figure 3, shows the results for Delaunay and MLP. Note first that the Delaunay error is essentially
unaffected by the presence of skew, with or without rescaling. This behavior is expected as the Delaunay
interpolantisdefinedbygeometriccomputationsthatarerobustagainstskewandnotdependentonscaling.
14
noitalopretni
noitalopartxe
noitalopretni
noitalopartxe
noitalopretni
noitalopartxenoskew(α=0) highskew(α=10),notrescaled highskew(α=10), {xi}rescaled
101
100
10−1
10−2
RBFbound
10−3
RBFerror
10−4
10−5 GPbound
10−6 GPerror
102
101
100
10−1
10−2
10−3
103 104 103 104 103 104
numberofsamples(n) numberofsamples(n) numberofsamples(n)
Figure 4: GP and RBF interpolants are affected by skew in the input data and rescaling. If the GP bound
does not decrease as the number of samples increases, it may be a sign of skew in the data. The left column
here is the same as the left column of Figure 1b.
The Delaunay bound with rescaling is about an order of magnitude lower than the bound without rescaling
(in the interpolation regime), suggesting that rescaling is beneficial for improving the estimate. Finally,
observe that the MLP error is slightly worse in the rescaled case, as MLPs are sensitive to data scaling.
In Figure 4, we show the performance of the RBF and GP interpolants. Notice that the GP error and
accompanying bound decreases – by many orders of magnitudes – when the data is not skewed, but stays
mostly flat in the presence of skew, regardless of rescaling. Accordingly, if one observes the GP bound
decreasing as sample size increases, it can be taken as a sign that the data is (likely) not significantly
skewed. The RBF bound does not capture the improvement in the RBF error from increased data (as was
alsoobservedinallcasesofFigure1b)andhencedoesnotprovideanysignaltothepresenceofskew. Finally,
note that the rescaling has a dramatic effect on the errors and bounds in the interpolation regime but only
significantly affects the RBF estimate in the extrapolation regime.
3.4 Prevalence of extrapolation regimes as d increases
In our final set of experiments, we explore the prevalence of extrapolation across changes in n and d.
Determining the probability that a random test point constitutes extrapolation relative to a fixed data set
depends both on properties of the data set and the method by which the test point is selected. We take
a simple approach for both and explain how the takeaway messages are much more than a “just-so” story
about extrapolation.
In Figure 5, we show the results of the following experiment. For n = 28+2i, i = 0,1,2,3 (the same
values used in Figures 1, 3, and 4) we create a data set using a Sobol sequence of n points in [ 1,1]d for
−
d = 2,5,8,11. We set α = 0 (no skew). The value of ω is irrelevant as response values are not used in this
study. For each d, we draw 210 points uniformly from [ 1,1]d, which we call the “test points.” For each
−
test point q, we compute q and determine whether q lies inside or outside the convex hull of the data set,
|| ||
corresponding to an interpolation or extrapolation query, respectively. Finally, we plot a histogram of the
q values,using20binsfrom0to√dandcoloreachbaraccordingtotheproportionofinterpolation(blue)
|| ||
vs extrapolation (red) queries.
Multiple important trends in sampling are evident from the results. Looking across each row, it is clear
that extrapolation queries rapidly become prevalent among the test points as dimension increases. Looking
downeachcolumn, theproportionofinterpolationqueriesisincreasedbyincreasingthenumberofpointsin
thesample,asistobeexpected. However,itisalsoclearthateventually—perhapsaroundd=8—attempting
tomitigateextrapolationqueriesbecomescomputationallyimpractical. Thebottomrighthistogramreflects
16,384 samples in d=11, but only 30% of test points are interpolation queries. This quantity of samples
≈
15
noitalopretni
noitalopartxedimension=2 dimension=5 dimension=8 dimension=11
100 150 11 57 05 200 i en xt te rr ap po ol la at ti io on n
80 125 125 150
100
46 00 75 10 70 5 100
50 50 50
20 25 25
0 0 0 0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 0.0 0.5 1.0 1.5 2.0 0.0 0.5 1.0 1.5 2.0 2.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0
100 150 175 200
150
80 125 125 150
100
46 00 75 10 70 5 100
50 50 50
20 25 25
0 0 0 0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 0.0 0.5 1.0 1.5 2.0 0.0 0.5 1.0 1.5 2.0 2.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0
100 150 175 200
150
80 125 125 150
100
46 00 75 10 70 5 100
50 50 50
20 25 25
0 0 0 0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 0.0 0.5 1.0 1.5 2.0 0.0 0.5 1.0 1.5 2.0 2.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0
100 150 175 200
150
80 125 150
125
46 00 10 70 5 10 70 5 100
50 50 50
20 25 25
0 0 0 0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 0.0 0.5 1.0 1.5 2.0 0.0 0.5 1.0 1.5 2.0 2.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0
L2normofinput L2normofinput L2normofinput L2normofinput
Figure 5: Given n (rows) and d (columns), we create a Sobol sequence data set with n points in [ 1,1]d.
−
For 1024 points drawn uniformly from [ 1,1]d, we show a histogram of the the L2 norm of each point,
−
colored by whether the point is interpolation (blue) or extrapolation (red) relative to the data set. Notice
that extrapolation always dominates as dimension increases, due to the curse of dimensionality.
isalreadylargeinmanyscientificmachinelearningcontexts,andacquiringanorderofmagnitudemoredata
may be infeasible for many real-world applications. A more practical approach to mitigating extrapolation
is to pursue dimension reduction techniques.
Additionally, observe that as dimension increases, the distribution of q values becomes more sharply
(cid:104) || ||(cid:105)
clustered in the interior of the range of possible values (note q 0,√d for q [ 1,1]d). This phe-
|| || ∈ ∈ −
nomenon, known as concentration of volume, is sometimes overlooked in the data science community al-
though it is well understood from the mathematical setting; see, for instance, [62, Theorem 3.2] and the
references that follow. The concentration in q values is due in part to the uniform sampling strategy
|| ||
we selected to draw the test points, however, we observed very similar results when using Latin hypercube
or Sobol sequence sampling instead. Weighted sampling strategies could help distribute q values more
|| ||
evently, however, whether that is beneficial or advisable depends highly on the application context.
4 Case Study: Predicting Lift-Drag Ratios from Airfoil Images
In this section, we will demonstrate how the interpolation techniques and bounds proposed in Section 2 can
beappliedtoreal-worldscientificmachinelearningproblems. Specifically,wedemonstratehowourproposed
functionapproximationtechniquemaybeutilizedforsurrogatemodelingtobypassthesolutionsofcomplex
high-dimensionalpartialdifferentialequations. Thedataandcodeusedforourcasestudyisavailableinthe
Github repository associated with this paper [61].
We start with a function approximation task for aerospace engineering applications. Specifically, the
16
652=selpmasmun
4201=selpmasmun
6904=selpmasmun
48361=selpmasmuntask is to predict lift-to-drag ratios for various airfoil shapes, given training data. In classical modeling
workflows, it is typical to deploy numerical partial differential equation solvers to predict this quantity by
approximatingsolutionstotheNavier-Stokesequations. Thesesolutionsareusedtocomputetheintegrated
quantity of streamwise and normal forces on the airfoil from which the lift-to-drag ratios can be calculated.
In this work, we utilize our function approximation technique to bypass the costly overhead of deploying
numerical solvers, by using data-driven methods.
Our training data for this task is obtained from the UIUC Airfoil Coordinates Database[63]. This is a
collection of coordinates for approximately 1,600 airfoils and their corresponding lift-to-drag ratios. These
data correspond to a wide range of applications from low Reynolds number airfoils for UAVs and model
aircraft to jet transports and wind turbines. Therefore, rapid predictions for the quantity of interest for this
dataset corresponds to potential savings in predictive modeling across several different domains.
The input data is represented as a series of pixels having value 0 for points on or within the airfoil and
value 1 for points in the free-stream surrounding the airfoil. The output data is a scalar variable for the
lift-to-drag ratio. We leverage a publicly available version of the data 3, thus demonstrating a purely data-
drivenapproachforpredictingtheoutputs. Specifically,thisrepositorydeploysadeeplearningconvolutional
neural network to ingest two-dimensional representations of the airfoil coordinates to directly predict the
lift-to-drag ratio.
One of the key challenges of this problem from an interpolation perspective is the high dimensionality
of the problem when considered in the pixel space. Modern deep learning approaches for image classi-
fication would embed these inputs into a lower-dimensional latent space while exploiting the spatial and
scale-invariantstructuresoftheimageviaeitherconvolutionallayersorvisiontransformers. Sinceourprob-
lem involves regression, not classification, we will employ a combination of embedding layers and ReLU
MLP-esque regression layers to implement a scientific machine learning approach. In order to also lever-
age interpolation techniques, we have broken up the training of these layers (denoted f and f in
R MLP
Section 2.4).
Inourapproach,wefirstutilizeaconvolutionalautoencodertocompressthetwo-dimensionalinputdata
to a low-dimensional latent space (i.e., f in the language of Section 2.4). The latent representations of our
R
airfoils are then used for approximating the lift-to-drag ratio using the various interpolation methods. Our
convolutional autoencoder is trained on 80% of the total data set, using a mean-squared error loss function.
Latent space representations are obtained using the trained encoder, which are applied on the raw input
data. Specific details of the autoencoder architecture can be observed in our associated code. The choice of
latent space dimension, validation, and testing are described in subsequent sections. The remaining points
are reserved for a validation and testing set, described in the next subsections.
Note that for all interpolation techniques and the ReLU MLP, we have used the same implementations
described in Section 3 with input and output rescaling.
4.1 Validation
To validate our latent space encoding and models, we interpolate the 5,553 training points used to train the
convolutional autoencoder, and measure the resulting errors for 616 validation points. In order to visualize
the convergence of our methods when adding training data, we measure the relative mean absolute error
(MAE) of each interpolation method and the ReLU MLP on the validation set using various percentages
of the 5,553 training points. In addition, we have measured the average error bounds across all training
sizes. In order to visualize the effectiveness of the error bounds in predicting actual error, we also display
a scatter plot of the predicted error bounds vs. observed error for all validation data when using the full
training set. The resulting relative errors are shown for a 2-dimensional latent space encoding in Figure 6, a
4-dimensional latent space in Figure 7, a 6-dimensional latent space in Figure 8, and a 8-dimensional latent
space in Figure 9.
One of the first things that we notice is that across all latent space dimensions, the GP interpolant
performsfarworsethananyoftheothermethods. NotingtheobservationsfromSection3.2,wecommentthat
this likely indicates that the response surface is nonsmooth in the latent space, and therefore the Gaussian
kernel is not appropriate for this particular problem. It is likely that we could improve performance by
changingthekernelitselfforadifferentoption(suchasaMaternkernel),butasdiscussedinSection2.3,doing
3https://github.com/ziliHarvey/CNN-for-Airfoil
17Delaunayboundsvs. error
10 DelaunayMAE 1
GPMAE
TPSRBFMAE 0.5
1
ReLUMLPMAE
Delaunaybound 0
1e-1 GPbound 0 0.5 1 10 100
TPSRBFbound
GPboundsvs. error
1
0
0 1K 2K 3K 4K 5K 5553 0.5
1e-1 0
0 0.5 1 10 100
TPSboundsvs. error
1
5e-2 extrappts
0.5 interppts
refline
1e-2 0
0 0 0.5 1 10 100
0 1K 2K 3K 4K 5K 5553
Figure 6: Performance with 2-dimensional latent space embedding. Top left: MAE and average error bound
when predicting lift/drag from geometric shape parameters for various training sizes via interpolation and
machine learning methods. Note that results are shown at semilog scale. Bottom left: Only the MAE is
shown at linear scale. Right: Predicted error bounds (x-axis) vs. observed errors (y-axis) for each of the 3
interpolation methods
Delaunayboundsvs. error
10 DelaunayMAE 1
GPMAE
TPSRBFMAE 0.5
1
ReLUMLPMAE
Delaunaybound 0
1e-1 GPbound 0 0.5 1 10 100
TPSRBFbound
GPboundsvs. error
1
0
0 1K 2K 3K 4K 5K 5553 0.5
1e-1 0
0 0.5 1 10 100
TPSboundsvs. error
1
5e-2 extrappts
0.5 interppts
refline
1e-2 0
0 0 0.5 1 10 100
0 1K 2K 3K 4K 5K 5553
Figure 7: Performance with 4-dimensional latent space embedding. Top left: MAE and average error bound
when predicting lift/drag from geometric shape parameters for various training sizes via interpolation and
machine learning methods. Note that results are shown at semilog scale. Bottom left: Only the MAE is
shown at linear scale. Right: Predicted error bounds (x-axis) vs. observed errors (y-axis) for each of the 3
interpolation methods
socouldinterferewithourmotivationtouseinterpolationmethodsforvalidationasdiscussedinSection2.3.3.
Additionally, the GP’s 95% confidence interval regularly shows unreasonably low expected relative errors.
This indicates that the assumption that response values are Gaussian correlated with Euclidean distance is
likely a poor assumption.
On the other hand, the Delaunay interpolant, TPS RBF, and ReLU MLP all offer surprisingly similar
performance on this problem. Additionally, although the error bounds can be an order of magnitude too
18
EAMevitaler
EAMevitaler
EAMevitaler
EAMevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitalerDelaunayboundsvs. error
10 DelaunayMAE 1
GPMAE
TPSRBFMAE 0.5
1
ReLUMLPMAE
Delaunaybound 0
1e-1 GPbound 0 0.5 1 10 100
TPSRBFbound
GPboundsvs. error
1
0
0 1K 2K 3K 4K 5K 5553 0.5
1e-1 0
0 0.5 1 10 100
TPSboundsvs. error
1
5e-2 extrappts
0.5 interppts
refline
1e-2 0
0 0 0.5 1 10 100
0 1K 2K 3K 4K 5K 5553
Figure 8: Performance with 6-dimensional latent space embedding. Top left: MAE and average error bound
when predicting lift/drag from geometric shape parameters for various training sizes via interpolation and
machine learning methods. Note that results are shown at semilog scale. Bottom left: Only the MAE is
shown at linear scale. Right: Predicted error bounds (x-axis) vs. observed errors (y-axis) for each of the 3
interpolation methods
Delaunayboundsvs. error
10 DelaunayMAE 1
GPMAE
TPSRBFMAE 0.5
1
ReLUMLPMAE
Delaunaybound 0
1e-1 GPbound 0 0.5 1 10 100
TPSRBFbound
GPboundsvs. error
1
0
0 1K 2K 3K 4K 5K 5553 0.5
1e-1 0
0 0.5 1 10 100
TPSboundsvs. error
1
5e-2 extrappts
0.5 interppts
refline
1e-2 0
0 0 0.5 1 10 100
0 1K 2K 3K 4K 5K 5553
Figure 9: Performance with 8-dimensional latent space embedding. Top left: MAE and average error bound
when predicting lift/drag from geometric shape parameters for various training sizes via interpolation and
machine learning methods. Note that results are shown at semilog scale. Bottom left: Only the MAE is
shown at linear scale. Right: Predicted error bounds (x-axis) vs. observed errors (y-axis) for each of the 3
interpolation methods
highinmanycases(thisisexpectedsincetheyarebounds),theyaregenerallycorrelatedwiththetrueerror.
Additionally, the Delaunay bounds can be tight when predicting reasonably low error rates (e.g., relative
errors less than 0.5).
From Figure 6, we see the only case where the Delaunay interpolant’s error bounds fail rather spectac-
ularly. In fact, in this case they are anti-correlated with the true error. However, we also notice that the
true relative error rates are half an order of magnitude lower for all the other latent space dimensions and
19
EAMevitaler
EAMevitaler
EAMevitaler
EAMevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitalercontinuetoimprovewithaddeddata,whiletheydonotimprovewhenaddingdataforthisembedding. This
indicates that the 2-dimensional latent space may not be able to accurately represent all of the important
features in the UIUC airfoil dataset. We may infer that the encoding is noisy and interpolation methods are
not able to provide accuracy below the noise level. However, it is worth noting that despite this noise level,
the true performance of all methods remains extremely competitive, indicating that there is little adverse
effect from overfitting.
For the higher-dimensional embeddings in Figures 7, 8, and 9, the bounds hold but become less tight
in higher dimensions for the Delaunay method. In particular, for the 4-dimensional case, we see that the
bounds are asymptotically tight as they approach 0. The bounds remain similar for the TPS RBF in all
dimensions, indicatingthattheembeddedtraining/validationpointsaretightlyclusteredinthelatentspace
even for higher-dimensional embeddings, since the TPS RBF bound is purely distance based. On the other
hand, the proportion of extrapolation points does increase drastically in high dimensions, which is expected
in light of Section 3.4.
In the context of validation, these observations tell us that
• the 2-dimensional representation learned for Figure 6 is not sufficient for this problem as evidenced by
the total failure of the Delaunay error bounds, but the 4-, 6-, and 8-dimensional representations are;
• the 4-dimensional representation is likely to be optimal since it is the lowest-dimensional latent space
where the bounds appear to hold, indicating that the embedding produces a Lipschitz continuous
low-noise function over the latent space;
• when an appropriate latent space is chosen, the practical interpolation bounds given in (6) and (11)
are good predictors of errors for certain training points, especially the the Delaunay bound (6) for
low-dimensional embeddings; and
• theinterpolationmethods—especiallyDelaunayinterpolation—trackverycloselywiththeperformance
of the best ReLU MLP identified via our validation loop, indicating that the interpolation methods
provide reasonable expectations for the highest accuracy achievable via a ReLU MLP.
Finally, it is worth noting that for these data sets and train/validate splits, the interpolation methods
are an order of magnitude cheaper to train and validate than the ReLU MLP. However, one limitation is
thattheinterpolationmethods(especiallytheDelaunaymethod)carryagreaterproportionamountoftheir
computational cost at inference time, with consequent implications for applications that require real-time
predictions. They also require the training data to be held in memory at all times, which can be a privacy
concern. Therefore, for many applications they are best suited as a validation technique.
4.2 Testing
For the test set, the distribution of data is clearly different than on the training and validation sets. Only
46% of test points are inside the convex hull of the embedded training data, while 98% of the validation
points are inside the convex hull of the embedded training data. Therefore, we separately note the expected
and true error rates for test points inside the convex hull vs. the entire test set, to study the difference in
performancebetweenin-distributionandout-of-distributionpredictions. ResultsareshowninTable1. Since
we have already performed validation, the results are only shown when using the entire training set (5,553
training points embedded in 4 dimensions).
Method MAE (total) average bound MAE (in hull) average bound (in hull)
Delaunay 0.21 20.04 0.20 20.77
GP 17.38 0.01 0.19 0.00
TPS RBF 0.23 12.87 0.18 6.08
ReLU MLP 0.21 n/a 0.19 n/a
Table 1: Averaged error bounds and MAE for all the data (left) and only interpolation points (right) for all
4 methods from Section 2
20OnepointofnoteisthattheGPperformanceisactuallycompetitiveforinterpolationpoints,butbecomes
poor when considering extrapolation points. However, the GP’s 95% confidence interval is still significantly
off for all test points.
Compared to errors on the order of 10 2 obtained when using the full training set during validation
−
in Figure 7, we see much higher relative testing errors across all categories of Table 1 at approximately
0.2 MAE. This increase in MAE could be attributed to generalization error and increase in out-of-sample
predictions. However, upon inspection of the error bounds, we observe that true errors regularly exceed the
error bounds in Figure 10. Upon closer inspection, the Delaunay bounds are exceeded by approximately 0.2
for bounds near 0, which is also the increase in MAE. Adding a fixed amount of 0.2 to each relative error
bound makes the Delaunay bounds asymptotically tight again. This agrees with our hypothesis that the
increase is due to generalization error on the test set, which is out-of-sample compared to the training and
validation data. We will further explore this in the next section.
Delaunayboundsvs. error Delaunayboundsvs. error
1 1
0.5 0.5
0 0
0 0.5 1 10 100 0.20.5 1 10 100
GPboundsvs. error GPboundsvs. error
1 1
extrappts extrappts
0.5 interppts 0.5 interppts
refline refline
0 0
0 0.5 1 10 100 0.20.5 1 10 100
TPSboundsvs. error TPSboundsvs. error
1 1
0.5 0.5
0 0
0 0.5 1 10 100 0.20.5 1 10 100
Figure 10: Performance and error bounds with the 4-dimensional latent space embedding for 668 testing
points. Left: Predicted relative error bounds (x-axis) vs. observed relative errors (y-axis) for each of the 3
interpolation methods. Right: Predicted relative error bounds have been shifted by a fixed amount of 0.2.
Finally, it is worth noting that although not shown here, we also considered testing on the 6-dimensional
and 8-dimensional latent space encodings from Section 4.1 to see if they offered improvement. However, for
these embeddings, every test point was far outside the convex hull of the training data in the latent space.
Thisfurtherdemonstratesthedistributionshift,andillustrateshowquicklythecurseofdimensionalitytakes
hold on even moderate-dimensional problems.
4.3 Interpretability
In this section, we demonstrate the interpretability of the interpolation methods while further investigating
the generalization error from Section 4.2. Since the GP was found to be inappropriate for this problem in
the previous section, it is not considered here, although a similar approach could be taken were the GP a
more appropriate kernel for this problem. Additionally, one of the limitations of the TPS RBF is that its
kernelfunctioncannotbeinterpretedasadistancemetric,makingitdifficulttoleveragehere. Thus,wewill
primarily focus on the interpretability of the Delaunay interpolant for this problem.
For the purpose of this demonstration, three particular points were chosen from the test set to visualize
their embedding compared against that of the training points used to make the prediction. Figure 11 shows
the test point with the lowest prediction error that also satisfies the error bounds. Figure 12 shows the
21
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitaler
rorreevitalertest point with the largest prediction error that also violates the error bounds and is an interpolation point.
Figure 13 shows the test point with the largest prediction error that also violates the error bounds and is an
extrapolation point.
Figure 11: Test images where the true error and predicted bounds are both low. Top: True image (left)
and embedding (right). Bottom: The 5 training images used to make the prediction. Notice that visually,
the embedded image has similar angle-of-attack to the test image and the shape of the top of the foil is also
somewhat similar. However, there is already a clear change in the shape of the foil, signifying an imperfect
embedding. The training images are somewhat similar to the embedding, but not nearly as high-quality as
in the validation set.
Figure12: Testimageswherethetrueerrorexceedstheerrorbounds. Top: Trueimage(left)andembedding
(right). Bottom: The 5 training images used to make the prediction. Notice that the training images look
similartotheembeddedimage,resultinginalowerrorbar. However,thetrueimageisvisuallyverydifferent,
resulting in a large actual error.
First notice, that across all three test points, the embeddings are lower-quality compared to in the
validation set. This shows that our latent space representation is subject to significant generalization error.
However, the results in Figures 11, 12, and 13 paint a nice illustration of the utility of our methods. In
particular, Figure11(interpolationpointthatobeyserrorbounds)showsanembeddingthatisdifferentbut
with similar angle-of-attack to the true image, and the training points all closely resemble the embedding.
In Figure 12 (interpolation point that violates the error bounds), we see an embedding that has almost
no similarity with the true image, but closely matches many training points. In this case, the error in
the embedding essentially “tricks” the interpolation bounds. Finally, in Figure 13, the true test image
is somewhat similar in shape, but not identical and with different angle-of-attack to its embedding. The
embedded image also features an odd distortion on the top right side of the airfoil, which is not present in
any of the training images. Thus, it is visually apparent why this point resulted in geometric extrapolation
in the latent space.
In all of the above cases, the interpolation methods would not able to account for a poor autoencoder
embedding. This likely explains why the generalization error was so great, in particular, exceeding the
interpolation error bounds even for the Delaunay method, whereas no predictions in the validation set
22Figure 13: Test images where the true error exceeds the error bounds, but the point was flagged as extrap-
olation. Top: True image (left) and embedding (right). Bottom: The 3 training images used to make the
prediction. Notice that the embedding is poor here. However, the embedded image is also out-of-sample for
the training points, resulting in a high error estimate.
exceeded the interpolation error bounds for the Delaunay method. In support of the above claim, consider
the sample interpolation point and sample extrapolation point from the validation set, shown in Figures 14
and 15, respectively. Note that there is no mention of which points exceed the error bounds here, since on
the validation set, every prediction was within the error bounds.
Figure 14: Validation image that is also an interpolation point. Top: True image (left) and embedding
(right). Bottom: The 5 training images used to make the prediction. Notice that in contrast to Figures 11
and Figure 12, the embedding is very accurate and shares similar shape or angle with several of the training
points.
Figure 15: Validation images that was was flagged as extrapolation. Top: True image (left) and embedding
(right). Bottom: The 3 training images used to make the prediction. Notice that in contrast to Figure 13,
the embedding is very accurate and very similar to one of the corresponding training points.
23ThemoststrikingthingthatisimmediatelyobviousfromFigures14and15isthattheembeddedimages
are visually much more similar to the true images than in any of Figures 11, 12, or 13. This seems to
confirm that it is the failure of our autoencoder embeddings to generalize to the test set, which caused the
interpolationerrorboundstofail. Inthissense,thefailureoftheinterpolationboundsservesisafeaturenot
a bug, as it serves as an alarm bell for an issue in an earlier stage of our scientific machine learning pipeline.
4.4 Summary of Case-Study
Inthissection,westudiedtheutilityofinterpolationmethodsonacomputer-vision-basedregressionproblem
from computational physics. We combined common deep learning techniques (representation learning) with
interpolation by training a convolutional autoencoder. In this particular example, both the TPS RBF and
Delaunay interpolant offered similar performance to the ReLU MLP in both validation and testing. The
failure of the GP method indicates that the Gaussian kernel and possibly other assumptions of GP models
are not well-suited to this application, most likely due to the smoothness of the embedding.
Theadvantagetousingtheseinterpolationtechniques,isthatwewereabletovalidateourtrainedReLU
MLPnetworksagainstothermethodsthatdonotrequireanytraining,givingconfidenceintheirpredictions.
Furthermore,wemadetheory-backedchoicesforthelatentspacedimensionduringvalidation,andquantified
theexpectederrorsonthevalidationdomain. Onthetestingset,weobservedsignificantgeneralizationerror.
However, we were able to quantify what percentage of this was error was due to the representation f ()
R
·
by leveraging the error bounds of the interpolation methods. Then, by studying the increase in geometric
extrapolationinthelatentspace, weconcludedthatthemajorityoftestingsampleswereout-of-distribution
forthetrainingsamples(atleastinthelatentspace). Finally,leveragingtheinterpretabilityoftheDelaunay
interpolant, we were also able to see that the quality of the latent space embeddings had greatly decreased
on the testing set, which is likely a result of this distribution shift.
5 Discussion and Conclusions
In this paper, we have proposed methods for utilizing interpolation techniques to validate scientific machine
learning workflows and interpret how and why various predictions were made during validation and testing.
Although interpolation techniques were traditionally believed to be prone to overfitting, we consistently
observe similar performance between the best interpolation techniques and carefully trained ReLU MLPs.
In conclusion, a few rules of thumb from Section 3 for using these methods include
• TPS RBFs and GP interpolants perform extremely well for smooth problems;
• for nonsmooth problems, Delaunay interpolants appear to be more robust, and our revised Delaunay
interpolation error bounds are more practically useful;
• based on the above, the smoothness of the underlying function is the most important property of the
data set when determining interpolation or MLP regression performance;
• Delaunay interpolants consistently achieve similar performance to ReLU MLPs;
• otherindicatorsofdatasetqualitysuchasskewandspacingarelessimportant,andforthosemethods
that are effected, transforming/rescaling the data set (a standard practice) appears to address the
issues; and
• extrapolation is a major hindrance to the tightness of our interpolation error bounds and also is a
significant indicator of expected error.
Beyond these rules of thumb, we draw the following conclusions from our case-study in Section 4.
• Interpolationmethods,inadditiontomachinelearningmethods,shouldbeatoolforscientificmachine
learning problems;
• error bounds for interpolation methods are useful diagnostic tools for understanding performance of
these methods, and detecting potential issues in the training data and properties of the problem;
24• geometric interpolation vs. extrapolation is consistently a useful tool for judging approximation per-
formance and can also be a warning for distribution shifts that lead to increased generalization error;
• interpolation methods can be leveraged within larger scientific machine learning pipelines, not as a
replacement for, but alongside deep learning methods (such as representation learning);
• Delaunay interpolation and ReLU MLPs (when optimized) seem to achieve similar performance on
real-world problems; and
• as corroborated in other works, the right interpolation methods achieve similar performance to deep
learning methods on real-world noisy problems, and their error bounds can be used to quantify this
noise.
Thereremainopportunitiestocontinuethiswork,studyingtheperformanceofinterpolationtechniqueson
awidervarietyofscientificmachinelearningproblemsandconsideringadditionaloptionsforourinterpolation
methods (particularly the GP methods) and alternative deep learning architectures beyond ReLU MLPs.
Reproduciblity Code used to generate the results appearing in this paper is available in a publicly
available Github repository [61].
Acknowledgments This work was performed under the auspices of the U.S. Department of Energy by
LawrenceLivermoreNationalLaboratoryunderContractDE–AC52–07NA27344andtheLLNL-LDRDPro-
gram under Project tracking No. 21–ERD–028. Release number LLNL–JRNL–846568. This work was also
supported by the U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research,
under Contract DE–AC02–06CH11357 and by award DOE–FOA–2493.
References
[1] R.Vinuesa,S.L.Brunton,Thepotentialofmachinelearningtoenhancecomputationalfluiddynamics,
arXiv preprint arXiv:2110.02085 (2021) 1–13.
[2] G. Carleo, I. Cirac, K. Cranmer, L. Daudet, M. Schuld, N. Tishby, L. Vogt-Maranto, L. Zdeborov´a,
Machine learning and the physical sciences, Reviews of Modern Physics 91 (4) (2019) 045002.
[3] J.Drgona,K.Kis,A.Tuor,D.Vrabie,M.Klauco,Differentiablepredictivecontrol: Anmpcalternative
for unknown nonlinear systems using constrained deep learning, arXiv preprint arXiv:2011.03699 1.
[4] J. Li, M. Zhang, J. R. Martins, C. Shu, Efficient aerodynamic shape optimization with deep-learning-
based geometric filtering, AIAA journal 58 (10) (2020) 4243–4259.
[5] L. Sun, H. Gao, S. Pan, J.-X. Wang, Surrogate modeling for fluid flows based on physics-constrained
deep learning without simulation data, Computer Methods in Applied Mechanics and Engineering 361
(2020) 112732.
[6] R.K.Tripathy,I.Bilionis,Deepuq: Learningdeepneuralnetworksurrogatemodelsforhighdimensional
uncertainty quantification, Journal of computational physics 375 (2018) 565–588.
[7] Y.Zhu, N.Zabaras, Bayesiandeepconvolutionalencoder–decodernetworksforsurrogatemodelingand
uncertainty quantification, Journal of Computational Physics 366 (2018) 415–447.
[8] R. Maulik, R. Egele, K. Raghavan, P. Balaprakash, Quantifying uncertainty for deep learning
based forecasting and flow-reconstruction using neural architecture search ensembles, arXiv preprint
arXiv:2302.09748.
[9] M.Tang,Y.Liu,L.J.Durlofsky,Adeep-learning-basedsurrogatemodelfordataassimilationindynamic
subsurface flow problems, Journal of Computational Physics 413 (2020) 109456.
25[10] R. Maulik, V. Rao, J. Wang, G. Mengaldo, E. Constantinescu, B. Lusch, P. Balaprakash, I. Foster,
R. Kotamarthi, Efficient high-dimensional variational data assimilation with machine-learned reduced-
order models, Geoscientific Model Development 15 (8) (2022) 3433–3445.
[11] C. Rudin, Stop explaining black box machine learning models for high stakes decisions and use inter-
pretable models instead, Nature machine intelligence 1 (5) (2019) 206–215.
[12] R. Stevens, V. Taylor, J. Nichols, A. B. Maccabe, K. Yelick, D. Brown, AI for Science: Report on the
department of energy (DOE) town halls on artificial intelligence (AI) for science, Tech. rep., Argonne
National Lab.(ANL), Argonne, IL (United States) (2020).
[13] E. W. Cheney, W. A. Light, A Course in Approximation Theory, Graduate Studies in Mathematics,
AMS, Providence, RI, USA, 2009.
[14] T. C. H. Lux, L. T. Watson, T. H. Chang, J. Bernard, B. Li, L. Xu, G. Back, A. R. Butt, K. W.
Cameron, Y. Hong, Predictive modeling of I/O characteristics in high performance computing systems,
in: Proceedingsofthe2018SpringSimulationConference(SpringSim2018),the26thHighPerformance
Computing Symposium (HPC ’18), SCS, Baltimore, MD, USA, 2018, p. article no. 8.
[15] J. Mu¨ller, SOCEMO: Surrogate optimization of computationally expensive multiobjective problems,
INFORMS Journal on Computing 29 (4) (2017) 581–596.
[16] R. Garnett, Bayesian Optimization, Cambridge University Press, 2023.
URL https://bayesoptbook.com
[17] S. M. Wild, R. G. Regis, C. A. Shoemaker, ORBIT: Optimization by radial basis function inter-
polation in trust-regions, SIAM Journal on Scientific Computing 30 (6) (2008) 3197–3219. doi:
10.1137/070691814.
[18] M. M. Bronstein, J. Bruna, T. Cohen, P. Veliˇckovi´c, Geometric deep learning: Grids, groups, graphs,
geodesics, and gauges (2021). arXiv:2104.13478, doi:10.48550/arXiv.2104.13478.
[19] M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, P. Vandergheynst, Geometric deep learning: going
beyond Euclidean data, IEEE Signal Processing Magazine 34 (4) (2017) 18–42.
[20] A. N. Gorban, A. Zinovyev, Principal manifolds and graphs in practice: from molecular biology to
dynamical systems, International journal of neural systems 20 (03) (2010) 219–232.
[21] R.Doerner,B.Hu¨binger,W.Martienssen,S.Grossmann,S.Thomae,Stablemanifoldsandpredictabil-
ity of dynamical systems, Chaos, Solitons and Fractals: The Interdisciplinary Journal of Nonlinear
Science, and Nonequilibrium and Complex Phenomena 11 (10) (1999) 1759–1782.
[22] Z. Li, K. Meidani, A. B. Farimani, Transformer for partial differential equations’ operator learning,
arXiv preprint arXiv:2205.13671.
[23] C. Zhang, S. Bengio, M. Hardt, B. Recht, O. Vinyals, Understanding deep learning (still) requires
rethinking generalization, Communications of the ACM 64 (3) (2021) 107–115. doi:10.1145/3446776.
[24] M. Belkin, D. Hsu, P. P. Mitra, Overfitting or perfect fitting? Risk bounds for classification and regres-
sionrulesthatinterpolate, in: Proceedingsofthe32ndInternationalConferenceonNeuralInformation
Processing Systems (NIPS’18), Curran Associates Inc., Montr´eal, Canada, 2018, pp. 2306–2317.
[25] M. Belkin, Fit without fear: remarkable mathematical phenomena of deep learning through the prism
of interpolation, Acta Numerica 30 (2021) 203–248. doi:10.1017/S0962492921000039.
[26] T.C. H.Lux, etal., Interpolationofsparse high-dimensionaldata, NumericalAlgorithms88 (1)(2021)
281–313. doi:10.1007/s11075-020-01040-2.
[27] A. Gillette, E. Kur, Data-driven geometric scale detection via delaunay interpolation (2022). arXiv:
2203.05685.
26[28] J. Shewchuk, What is a good linear finite element? Interpolation, conditioning, anisotropy, and quality
measures, in: Proceedings of the 11th International Meshing Roundtable, 2002, p. 115–126.
[29] A. F. M¨obius, Der barycentrische Calcul, Verlag von Johann Ambrosius Barth, 1827.
[30] B. Delaunay, Sur la sph´ere vide, Bull. Acad. Science USSR VII: Class. Sci. Math., 1934.
[31] S.-W. Cheng, T. K. Dey, J. R. Shewchuk, Delaunay Mesh Generation, Computer and Information
Science Series, CRC Press, Boca Raton, FL, USA, 2012.
[32] R. G. Regis, The calculus of simplex gradients, Optimization Letters 9 (5) (2015) 845–865.
[33] L. Chen, J.-c. Xu, Optimal Delaunay triangulations, Journal of Computational Mathematics 22 (2)
(2004) 299–308.
[34] V. T. Rajan, Optimality of the Delaunay triangulation in Rd, Discrete & Computational Geometry
12 (2) (1994) 189–202.
[35] V. Klee, On the complexity of d-dimensional Voronoi diagrams, Archiv der Mathematik 34 (1) (1980)
75–80.
[36] T. H. Chang, L. T. Watson, T. C. H. Lux, B. Li, L. Xu, A. R. Butt, K. W. Cameron, Y. Hong,
A polynomial time algorithm for multivariate interpolation in arbitrary dimension via the Delaunay
triangulation, in: Proceedingsofthe2018ACMSoutheastConference(ACMSE’18), ACM,Richmond,
KY, USA, 2018, p. article no. 12.
[37] K. Fukuda, “Is it possible to compute only the adjacencies of Voronoi cells in the Voronoi diagram
efficiently?”, in: Polyhedral computation FAQ (blog), August 26, 2004, p. 1, retrieved from: http:
//www.cs.mcgill.ca/~fukuda/soft/polyfaq/polyfaq.html, November 16, 2022.
[38] T. H. Chang, L. T. Watson, T. C. H. Lux, A. R. Butt, K. W. Cameron, Y. Hong, Algorithm 1012:
DELAUNAYSPARSE: Interpolation via a sparse subset of the Delaunay triangulation in medium to
highdimensions,ACMTransactionsonMathematicalSoftware46(2020)1–20. doi:10.1145/3422818.
[39] G.H.Golub,C.F.VanLoan,Matrixcomputations,4thEdition,JohnsHopkinsUniversityPress,2013.
[40] M.J.Powell,Theuniformconvergenceofthinplatesplineinterpolationintwodimensions,Numerische
Mathematik 68 (1) (1994) 107–128.
[41] M. D. Buhmann, Radial basis functions, Acta Numerica 9 (2000) 1–38. doi:10.1017/
S0962492900000015.
[42] R. Schaback, Error estimates and condition numbers for radial basis function interpolation, Advances
in Computational Mathematics 3 (3) (1995) 251–264. doi:10.1007/BF02432002.
[43] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski,
P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. Jarrod Millman,
N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. Carey, I˙. Polat, Y. Feng, E. W. Moore,
J.VanderPlas,D.Laxalde,J.Perktold,R.Cimrman,I.Henriksen,E.A.Quintero,C.R.Harris,A.M.
Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, S. . . Contributors, SciPy 1.0: Fundamental
algorithms for scientific computing in Python, Nature Methods 17 (3) (2020) 261–272.
[44] R.B.Christianson,R.M.Pollyea,R.B.Gramacy,Traditionalkrigingversusmoderngaussianprocesses
for large-scale mining data, Statistical Analysis and Data Mining: The ASA Data Science Journal.
[45] R. B. Gramacy, H. K. H. Lee, Cases for the nugget in modeling computer experiments, Statistics and
Computing 22 (3) (2012) 713–722. doi:10.1007/s11222-010-9224-x.
[46] F.Pedregosa,G.Varoquaux,A.Gramfort,V.Michel,B.Thirion,O.Grisel,M.Blondel,P.Prettenhofer,
R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cournapeau,M.Brucher,M.Perrot,E.Duchesnay,
Scikit-learn: Machine learning in Python, Journal of Machine Learning Research 12 (2011) 2825–2830.
27[47] C. E. Rasmussen, C. K. Williams, et al., Gaussian processes for machine learning, Vol. 1, The MIT
Press, 2006.
[48] P. Baldi, Deep learning in biomedical data science, Annual review of biomedical data science 1 (2018)
181–205.
[49] K. Choudhary, B. DeCost, C. Chen, A. Jain, F. Tavazza, R. Cohn, C. W. Park, A. Choudhary,
A.Agrawal,S.J.Billinge,etal.,Recentadvancesandapplicationsofdeeplearningmethodsinmaterials
science, npj Computational Materials 8 (1) (2022) 59.
[50] N. B. Kovachki, Z. Li, B. Liu, K. Azizzadenesheli, K. Bhattacharya, A. M. Stuart, A. Anandkumar,
Neural operator: Learning maps between function spaces, CoRR abs/2108.08481.
[51] J. N. Kutz, Deep learning in fluid dynamics, Journal of Fluid Mechanics 814 (2017) 1–4.
[52] M.Raissi,P.Perdikaris,G.Karniadakis,Physics-informedneuralnetworks: Adeeplearningframework
for solving forward and inverse problems involving nonlinear partial differential equations, Journal of
Computational Physics 378 (2019) 686–707. doi:https://doi.org/10.1016/j.jcp.2018.10.045.
[53] M.Reichstein,G.Camps-Valls,B.Stevens,M.Jung,J.Denzler,N.Carvalhais,f.Prabhat,Deeplearning
and process understanding for data-driven earth system science, Nature 566 (7743) (2019) 195–204.
[54] P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tac-
chetti, D.Raposo, A.Santoro, R.Faulkner, etal., Relationalinductivebiases, deeplearning, andgraph
networks, arXiv preprint arXiv:1806.01261.
[55] A. Goyal, Y. Bengio, Inductive biases for deep learning of higher-level cognition, Proceedings of the
Royal Society A 478 (2266) (2022) 20210068.
[56] E. Weinan, Machine learning and computational mathematics, Communications in Computational
Physics 28 (5) (2020) 1639–1670. doi:10.4208/cicp.OA-2020-0185.
[57] T.DeRyck,S.Mishra,Genericboundsontheapproximationerrorforphysics-informed(and)operator
learning, Advances in Neural Information Processing Systems 35 (2022) 10945–10958.
[58] I. Gu¨hring, G. Kutyniok, P. Petersen, Error bounds for approximations with deep relu neural networks
in w s, p norms, Analysis and Applications 18 (05) (2020) 803–859.
[59] Y. Shin, Z. Zhang, G. E. Karniadakis, Error estimates of residual minimization using neural networks
for linear pdes, arXiv preprint arXiv:2010.08019.
[60] P. T. Roy, A. B. Owen, M. Balandat, M. Haberland, Quasi-monte carlo methods in python, Journal of
Open Source Software 8 (84) (2023) 5309. doi:10.21105/joss.05309.
URL https://doi.org/10.21105/joss.05309
[61] T.Chang,A.Gillette,R.Maulik,Interpolationmodelsanderrorboundsforverifiablescientificmachine
learning (InterpML) [Github repository], https://github.com/LLNL/interpML (March 2024).
[62] R. Vershynin, Estimation in high dimensions: a geometric perspective, in: Sampling Theory, a Renais-
sance: Compressive Sensing and Other Developments, Springer, 2015, pp. 3–66.
[63] M. S. Selig, UIUC airfoil data site (1996).
URL https://m-selig.ae.illinois.edu/ads/coord_database.html
28