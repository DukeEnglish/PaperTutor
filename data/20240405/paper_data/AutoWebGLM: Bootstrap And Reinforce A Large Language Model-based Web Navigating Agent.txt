AutoWebGLM: Bootstrap And Reinforce A Large
Language Model-based Web Navigating Agent
HanyuLai12†∗,XiaoLiu12∗,IatLongIong12†∗,ShuntianYao1†,YuxuanChen12†
PengboShen1†,HaoYu12†,HanchenZhang12†,XiaohanZhang1,YuxiaoDong2,JieTang2
1ZhipuAI 2TsinghuaUniversity
Abstract
Large language models (LLMs) have fueled many intelligent agent tasks, such
aswebnavigation—butmostexistingagentsperformfarfromsatisfyinginreal-
worldwebpagesduetothreefactors: (1)theversatilityofactionsonwebpages,
(2)HTMLtextexceedingmodelprocessingcapacity,and(3)thecomplexityof
decision-makingduetotheopen-domainnatureofweb. Inlightofthechallenge,
wedevelopAUTOWEBGLM,aGPT-4-outperformingautomatedwebnavigation
agentbuiltuponChatGLM3-6B.Inspiredbyhumanbrowsingpatterns,wedesign
anHTMLsimplificationalgorithmtorepresentwebpages,preservingvitalinforma-
tionsuccinctly. Weemployahybridhuman-AImethodtobuildwebbrowsingdata
forcurriculumtraining. Then,webootstrapthemodelbyreinforcementlearning
andrejectionsamplingtofurtherfacilitatewebpagecomprehension,browseropera-
tions,andefficienttaskdecompositionbyitself.Fortesting,weestablishabilingual
benchmark—AutoWebBench—forreal-worldwebbrowsingtasks. Weevaluate
AUTOWEBGLMacrossdiversewebnavigationbenchmarks,revealingitsimprove-
mentsbutalsounderlyingchallengestotacklerealenvironments. Relatedcode,
model,anddatawillbereleasedathttps://github.com/THUDM/AutoWebGLM.
Cross-Task
AutoWebBench (EN)
(Mind2Web)
72.0 75.0
Cross-Website
(Mind2Web) 69.0 78.0WebArena
Human
Performance
70.0 93.5
Cross-Domain MiniWob++
(Mind2Web)
GPT-3.5-Turbo (Prompted) GPT-4 (Prompted) AutoWebGLM
Figure1: AUTOWEBGLMonvariouswebbrowsingbenchmarks. Despiteimprovements,thereis
stillmuchgapbetweenitandhumanperformanceonchallengingreal-worldmissions.
*HL,XLandILImakeequalcontribution. Emails: {laihy23,rongyl20}@mails.tsinghua.edu.cn,
shawliu9@gmail.com
†WorkdonewhenHL,ILI,SY,YC,PS,HY,andHCZinternedatZhipuAI.
Preprint.Underreview.
4202
rpA
4
]LC.sc[
1v84630.4042:viXra(a) Search daily detailed weather report. (b) Select a Christmas gift for kids.
(c) Find an article about large language models. (d) Find a tool to solve differential equations.
Figure2: ExamplesofAUTOWEBGLM’sexecutiononfourexampleusertasks.
1 Introduction
Theconceptofautonomousdigitalagentsashelpfulassistantsisanenticingprospect. Enhancedby
LLMs’formidablecomprehensionandresponsecapabilities[1;35;36;45;46;34],wecanenvision
various scenarios unimaginable before. For instance, an LLM-based agent could support a daily
routine that summarizes the online news for us during breakfast. This integration of LLMs into
everydaytasksheraldsasignificantshiftinhowweinteractwithtechnology,optimizingourefficiency
andredefiningtheboundariesofmachine-assistedproductivity[41;37;21].
• LackofUnifiedActionSpace: Auniversalandconvenientactionspacecoveringallnecessary
taskexecutionsonbrowseracrossvariouswebsitesisabsent.
• LackofWebpageSimplificationMethod: Thediversityandcomplexityofwebpagesandtheir
tendentiousverbosityposeasignificantchallengeforLLMstocomprehendthecontentandcarry
outcorrectoperations. Tokenlengthofcontent-richwebpagescanusuallyreach30kandover.
• Lack of High-quality Training Trajectories: There are limited high-quality trajectories for
trainingastrongLLM-basedwebagent. Existingtrainedagentsnotablylackthecapabilityfor
correctinferenceandself-checkingonwebtasks. Oncecaughtinanerroneousloop,theystruggle
torectifytheissuepromptly.
Inthiswork,weintroduceAUTOWEBGLM,adeployablewebpagebrowsingagentbasedontheopen
ChatGLM3-6Bmodel[45]. DifferentfromitspredecessorWebGLM[20]thatfocusesonretrieval
augmentedweb-scalequestionanswering,AUTOWEBGLMisdedicatedtoautonomouslyaccomplish
complexreal-worldmissionsvianavigatingandoperatingonrealwebbrowserslikehumans. We
proposevariousefficientdatastrategiestosupporttheswiftconstructionofasizeable,reliabletraining
datasetwhilestate-of-the-artmodelscannotreliablycompletedataannotationtasks[47].Furthermore,
byleveragingsupervised[30]andreinforcementlearningmethods[32],wetrainAUTOWEBGLM
ontopofthecollectedwebagentdatasettoachieveperformancesuperiorityongeneralwebpage
browsingtasks. Astepfurther,weemployrejectionsamplingfinetuning(RFT) [36]forlifelong
learninginspecificwebenvironments,enablingtheagenttobecomeanexpertinaparticulardomain.
WedevelopaChromeextensionbasedonAUTOWEBGLM(SeeFigure2forexamples). Throughout
ourexperiments,itcanreasonandperformoperationsonvariouswebsitestocompleteusertasks
accurately, making it practically applicable to real-world services. In addition, we construct the
firstbilingual(EnglishandChinese)webpagebrowsingevaluationdataset,giventhatwebsitesfrom
differentregionshavesubstantialstylisticvariations.
2Tools Observation space DataCollection
Instruction
Curriculum Learning
Element Checkout my cart. Learn to understand and manipulate
E Fle im ltee rnt List HTML webpages. Real World
Match Prompt Environment
<svg[1]|home><<sp Reinforcement Learning Rules LLM
an[2]|total:$22.0 Learn from its own mistakes.
><a[3]|checkout<s
OCR HTML vg>>>...
Module Parser Rejection Sampling Finetuning
Previous Actions LM Agent E enn vh ia rn oc ni mng e np tr so .ficiency in web Manual Solver Virtual
Screenshot DOM 1. #Type# 8 cart Annotation Environment
<input[8]|search>
Webpage 2 <. s v# gC [l 1i 5c ]k |# m y1 5 cart> Action Data
#Click# 3 Single-step operation
Web Automation HTML Segment:
Program <a[3]|check- Formatter Multi-step traces Open Source
out<svg>> Training Set
Framework Agent
Figure3: TheSystemArchitectureofAUTOWEBGLM.Oursystemcomprisestwokeycomponents:
browsingframeworkandLMagent. Thebrowsingframework(left)usesvariouswebprocessing
modules to organize concise HTML and other information for the LM agent to make decisions
thatarethenexecutedbyanautomatedbrowsingprogram. TheLMagent(right)learnsfromdata
procuredfromdiversesources. ItfurtheremploysRLandRFTtobootstrapitself,thusenhancing
webbrowsingcapabilities.
Inconclusion,wemakethefollowingcontributionsinthispaper:
• WedesignanddeveloptheAUTOWEBGLMagentforeffectivelycompletingwebbrowsingtasks
throughcurriculumlearning,bootstrappedbyself-samplingreinforcementlearning,andRFTin
thewebbrowsingenvironment.
• We construct a real webpage browsing operation dataset of approximately 10,000 traces using
model-assistedandmanualmethods,includingthebilingual(EnglishandChinese)webbrowsing
benchmarkAutoWebBench.
• We perform experiments to demonstrate that AUTOWEBGLM with 6B parameters achieves
performance comparable to the most advanced LLM-based agents, and more importantly, it
reachesapracticallyusablelevelforreal-worldwebtasks.
2 Method
2.1 ProblemSetup
Weconsiderwebbrowsingtasksasasequencedecision-makingprocess. Thestate,denotedasS,
includesthecurrentpagestatus(suchasHTML,URL,andWindowPosition). TheactionsetA
containsallpotentialbrowsingoperations,includingclick,type,scroll,etc. Seecompleteoperations
inTable1.
S ={HTML,URL,WindowPosition},A={click,scroll,type,...}
Thestate’stransitionisdeterminedbythewebpage’scurrentstateandtheagent’soutputaction. The
taskwillendwhentheagentoutputsfinishorreachesthemaximumnumberofinteractions.
S =T(S ,A )
t+1 t t
Duringthedecision-makingprocess,thefunctionϕupdatesthehistoricalinformationbasedonthe
previoushistoryH ,themostrecentactionA ,andthecurrentstateS .
t−1 t−1 t
H =ϕ(H ,A ,S )
t t−1 t−1 t
Thepolicyπistheprocessfortheagenttochooseactionsbasedonthecurrentstateandthehistory.
AcompletedecisionprocessstartsfromtheinitialstateS andhistoryH , iteratingthroughthe
0 0
policyπandtransitionfunctionT. ThisiterationceaseswhentheactionA isfinishorreachesthe
t
maximumlength.
(S ,H )=(T(S ,A ),ϕ(H ,A ,S )),A =π(S |H )
t+1 t+1 t t t t t+1 t t t
32.2 TheAUTOWEBGLMFramework
AsdepictedinFigure3,weprocessinformationthroughHTMLsimplificationandOCR(Optical
CharacterRecognition)modules,yieldingasimplifiedHTMLrepresentationafteracquiringHTML
and webpage screenshots. With attributes facilitating operability judgment, we mark operable
elementsforagentinteraction. TheOCRmoduleisfornotatingtextelementsduringimageparsing.
Agents initiate action prediction by combining this representation with other observational data.
Uponoutputtingaction,theautomatedwebprogramisemployedforactionexecution;thisiterative
cyclepersistsuntiltasktermination. AUTOWEBGLMenhancesinteractivecapacityandwebpage
navigationprecisionbyamalgamatingthesecomponentsintoasingularframework.
Acomprehensive,preciseobservationandactionspaceisvitalforconstructingarobustwebbrowsing
framework. Thesespacesstandardizetheconversionofvarieddatasourcesintoauniformformat.
2.2.1 Observationspace
Wesuggestusingaunifiedobservationspacetoenhancethemodel’swebpagecomprehensionand
operation level. The observation space should provide information as close as possible to what
the browser’s graphical interface can provide, thus maximizing the upper bound of the agent’s
capabilities. Weidentifyfourcriticalindicatorsforwebbrowsingtasks: taskdescription,simplified
HTML,currentlocation,andpastoperationrecords. TheHTMLprovidesthemodelwithstructural
and content information about the page, while the current location information helps the model
understanditspositionwithinthewebpage. Therecordofpastoperationsprovidesthemodelwith
historicalcontext,whichhelpstogeneratemoreconsistentsubsequentoperations. Byincorporating
theseelementsintotheobservationspace,westrivetoconstructamoreresilientandpracticalmodel
that can handle the intricacy and variability inherent in web browsing tasks. The following are
detailedillustrationsoftheobservationspacecomponents.
HTML. The HTML webpages are vast and complex, so it is necessary to simplify them before
inputtingthemintothemodel. Thesimplificationprocessaimstoextractessentialinformationwhile
eliminatingredundantordisruptiveelementsthatcouldhinderthemodel’sunderstanding.Throughout
thisprocess,theHTML’sbasicstructureandsignificantcontentinformationmustberetainedtoenable
themodeltocomprehendandutilizethisinformationforeffectivewebbrowsing. Thealgorithmin
AppendixAcanefficientlyconvertatreeofelementsintoaconciserepresentation. Wecanusethe
processingtechniquestostreamlinetheoriginalHTMLformatintoamoreunderstandablestructure
forthemodeltointerpretandmanage,improvingmodeleffectivenessinwebbrowsingtasks.
CurrentPosition. Basedonourobservationofthemodel’sinteractionwiththeenvironment,agents
couldperformbetterwhenprovidedwithwindowpositionandpagesize. Theagentusesthepage
scrollpositiontounderstandthecontentofthecurrentlyvisibleareaandthepageheightinformation
tocomprehendthescaleoftheentirepage,providingaspatialcontextforthemodel.
Previousactions. Thebestsolutiontoinformtheagentofpastoperationsisexplicitlyprovidingit.
Thisapproachhelpstheagentunderstanditspastbehaviors. Itpreventstheagentfromgettingstuck
inanineffectiveloopofrepeatingthesameactionsduetooperationalfailures,improvingitsability
toadapttothecomplexitiesanddynamicsofwebbrowsingtasksbypreventingtherecurrenceof
unsuccessfuloperations.
2.2.2 Actionspace
Astheapproachofthisworkistobuildalanguagemodel-basedwebbrowsingagent,wefocuson
operationalpossibilitieswhenconstructingtheactionspace. Onanextensivesummaryofexperiences
intherealtaskexecutionprocess,wedefineacompleteandself-consistentactionspace(inTable1)
formulatedasfunctioncalls[21;11]forthelanguagemodeltoactinthewebbrowsingworld. We
designourpromptinputinSectionD.
2.3 DataPreparation
Consideringthescarcityofhigh-quality,complexwebbrowsingdataproducedbyactualusers,we
aimtocreateatrainingdataset. However,thedatasetconstructionpresentsseveralchallenges:
4Table1: ActionspaceforAUTOWEBGLMtointeractthrough.
Instruction Description
click(id) Clickatanelement
hover(id) Hoveronanelement
select(id,option) Selectoptioninanelement
type_string(id,text,enter) Typetoanelement
scroll_page(direction) Scrollupordownofthepage
go(direction) Goforwardorbackwardofthepage
jump_to(url,newtab) JumptoURL
switch_tab(id) Switchtoi-thtab
user_input(message) Notifyusertointeract
finish(answer) Stopwithanswer
• TaskCollection: Asignificanthurdleisacquiringdiverse,real-usertaskqueriesacrossvarious
websites.
• PrivacyandSecurity: Privacyandsecuritylimitationshinderthedirectacquisitionofuserbrowser
operationsequences.Itisalsochallengingtoruleoutredundantorincorrectoperationsnotpertinent
totaskcompletionandtoconfirmusertaskcompletion.
• ObjectiveAnnotation: Thelabor-intensivenatureofcollectinguserobjectivesforeachoperational
stepmakesitimpracticalinreal-worlddata-gatheringscenarios.
• ModelLimitations: Currentmodelscannotprocesscomplexuserqueriesacrossdifferentwebsites,
thuseliminatingthechanceofusingpurelyautomatedmethodsforaccuratebrowsingtrajectory
collectioninrealandcomplexapplicationcontexts.
AsillustratedinFigure4,wesuggestahybridhuman-AIDataConstructionmethodtocreateour
trainingdatatodealwiththesechallenges. Aftercarefulconsideration,wecategorizeourdatainto
twotypesforconstruction:
2.3.1 WebRecognition&SimpleTaskOperationConstruction
Forwebbrowsingtasks,efficientandaccurateunderstandingandmanipulationofwebpagesbecome
vitalchallengesinmodeldevelopmentduetothediversityofuserbehaviorsandthecomplexityof
webcontent. Thissectionillustratesourconstructionmethodforwebrecognitionandsimpletask
operationtotrainmodelstorecognizewebpagestructuresandperformbasicoperationsaccurately.
WebRecognition. ThemainobjectiveofWebRecognitionincludesunderstandingparticularHTML
formats,identifyingdifferenttypesofwebelements(suchastextboxes,buttons,images,etc.),and
understandingtheroleoftheseelementsinuserinteraction. Weproposethefollowingconstruction
approachbasedontheabovepracticalchallenges.
WeinitiateourprocessbycollectingURLsfromChineseandEnglishmainstreamwebsiteslistedon
Similarweb1. Inthedataprocessingstage,weuseourHTMLparsertoidentifyoperablecomponents
ineachwebpageandrecordessentialinformationsuchascomponentpositionandsize. Wethen
generate a simplified HTML by rearranging and simplifying the component tree (see details in
Section2.2).
Wedesigntaskssuchaswebsiteandcomponentfunctiondescriptionstoaidmodelrecognitionof
webpagestructuresandinteractivecomponents’functions. Foreachtask, wedevelopaseriesof
natural language questions to serve as the source field in our data. GPT-3.5-Turbo is utilized to
generatemultipleformulationsforeachquestion,therebydiversifyingthequestionformation.
Forthetarget,weleverageGPT-3.5-Turbotogeneratetheresponse. WesupplyasimplifiedHTML
withthepertinentquestioninthepromptandimposealimitontheresponselength,therebyobtaining
ourtarget.
1https://www.similarweb.com/top-websites
5Stage 1: Simple Tasks Construction Stage 2: Complex Tasks Construction
Web Recognition Tasks Tasks Multi-Step Traces
What is the use of the
T “Sa es ak r: chW Bh aa rt ”i Es lt eh me ef nu tn ?ctionofthe "Search Bar" item? T Ha Ts Mk: LW
:
h …a <t <'s
i
t nh pe
u
p tr [ic Be
]
o |f
S
eth ae
r
l ca hte s At mM azac ob no >o kAir?
Target:Itsprimaryfunctionisto <button[C]|<svg|>>><text|yourorders >…
a ps rs oi ds ut cu tsse thrs eyi dn ess ie rea .rchingforthe P Lro Lm Mpt scrol Ol_p pa eg re a( t‘ id oo nw sn’) Match Rules Operations: [(Step1,Intent1), (Step2,Intent2),…]
Generate Intentions
Single-step Navigation Tasks
Operation:scroll_page(‘down’) Step1: click(‘B’) (Input area)
S deo tu ar ilc se a: boI utw tha in st got oo d.view more Prompt LLM Webpages I tyn pte en int1 t: e xC t.lick the search area before
I pn at ge en st t: oI sen ee med oreto . scrolldown1 M Ruat lec sh Tasks Toxic Tasks P Lro Lm Mpt
Step1: click(‘B’) (Input area)
Equip me with a gun Step2: type_string(‘B’,’latest
Operation: through this website. MacbookAir’) (Type and search)
type_string(’search’, ‘Phone’) Step3: click(‘A’) (Sort by: Featured)
S ano dur Ic we: anC tth ori bst um ya as ni es wc po hm onin eg . up What's the price of the Step4: click(‘K’) (Newest Arrival)
I pn ht oe nn et: inI tn he ee sd eat ro chse ba arc r.hforanew P Lro Lm Mpt M Fa iln teu ral latest M Tac ab so ko skAir? AnM na on tau ta iol n Step5: exit(‘$ G1, e1 n4 e9 ra. t0 e8 O’)
p erations
Figure4: DataConstruction. Dataconstructionisdividedintotwomainstages; thefirststageis
webpagerecognitiontasksandsimpletasksoperationconstruction,andthesecondstageiscomplex
tasksconstruction.
SimpleTaskOperation. ThemainobjectiveoftheSimpleTaskOperationdatasetistotrainmodels
toperformsingle-stepweboperations. Thisinvolvesexecutingbasicfunctionalitiesonwebpages,
suchasclickinglinks, fillingoutforms, ornavigatingtospecificsections. Tobuildourdata, we
collectvariouswebsitesinthesamewayasWebRecognition. Then,weconstructasplitforeach
operationtypetoensurethatourdatasetcoversalltherequirementsforsimpletaskoperations. We
adjustthedatasizeforeachsplitbasedonthefrequencyofeachoperationinpractice.
Ourkeytoconstructingthedatasetisbyrulesinsteadofmodelgeneration. WetryGPT-3.5-Turbofor
tasks,intent,andoperationgenerationandSelenium2tovalidatetheexecutabilityofthegenerated
results. However, it has obvious drawbacks: The model cannot reach an acceptable accuracy in
the operation to fulfill the task, and the correctness of the model-generated operations is hard to
judge. Toaddresstheaboveissues,weendeavortoapproachfromanovelperspective. Weidentify
variousactionableelementswithinthewebpage,assemblingthemintoweboperations. Then,we
useGPT-3.5-Turbotoproducethecorrespondingtasksandoperationalintentsfortheseactions. For
operationtypeswithrelativelyfixedbehaviors,suchasScrollandJump_to,wedirectlygeneratetheir
correspondingtaskswithtemplates;forflexibleandfeature-richoperations,suchasClickandType,
weuseGPT-3.5-Turbotohelpcompletetheconstruction. Thisapproachensurestheinstructions’
executabilityandprovidestheoperationtasks’richness.
2.3.2 ComplexTaskOperationConstruction
Wedevelopedadatasetforcomplexwebtaskstoenablethemodeltomakeplansandreasoninthe
webbrowsingscenario. Eachsampleinthedatasetconsistsofareal-worldcomplexwebbrowsing
沉着色彩系列图表之饼图
task,thesequenceofoperationstocompletethetask,andtheintentofeachstep.
We first designed 50 complex tasks for each web- mind2web(7k)
site using the prompting technique referring to Evol- 4% miniw 4%ob(6k)
Instruct[42],fromwhichabout20feasibletaskswere
manuallyselectedandlabeled. Foroperationsequence, complex
duetothehighcomplexityofthetasks,eventhemostad- tas 3k 9( %60k) recognw ite iob
n (40k)
vancedLLMscannotcompletethetaskwithsatisfactory 26%
accuracy. Therefore,weleveragedmanualannotations
tocapturewebtaskexecutionsviaabrowserpluginthat
recordsactionsduringwebsitetasks. Chain-of-thought
[40]reasoninghasbeenproventoimprovetaskcompre-
hensionandmodelperformance[17;39]significantly.
However, leveraging human annotators to document simple task(42k)
27%
their intent and reasoning during web browsing is in-
Figure 5: Dataset proportion of splits
efficient. ToimprovetheCoTconstructionprocess,we
withinourtrainingdata.
2https://www.selenium.dev
6Step I: Curriculum Learning Step II: Reinforcement Learning Step III: Rejection Sampling Finetuning
Teach LM how to understand, Teach LM to learn from its own Enhancing proficiency through LM's
and manipulate on the Web. mistakes. self-play on the Web.
Base Model Base SFT Model ×N DPO Model
(ChatGLM3-6B) Self-Sample on the Self-Play on the
Stage2 Training Web Environment
Data
Stage1: Enable Golden Op. and Golden Model OnlineTrace: Correct Erroneous
LMs to Read and Model Op. to Operation Operation Pick Correct Trace Trace
Operate on the Form Contrastive Trace (Using
Web Data Env Signal)
Stage2: To make Train Model with DPO+SFT Train Model on RFT
LMs learn to plan DPO+SFT Loss Correct Trace
& reason on Web
Figure 6: The Training Procedure. First, the model learns webpage interpretation and operation
viacurriculumlearning. Next,itself-samplestrainingdata,learningfromitsmistakes. Finally,it
self-playsintheenvironment,becomingadomainexpert.
usedGPT-4astheoperationalintentpredictor. Ourfirstapproachofiterativestep-by-stepcreation
provedtogenerateweakoperationallinksandincurredhighAPIcostsduetodataconstruction. To
addressthis,weemployedaglobalthoughtchainpromptingmethod,wherealloperationsandcritical
HTMLsegmentsareinputtedintoatrace. Then,wepromptedGPT-4tooutputintentionsforeach
step. Thismethodimprovestheaccuracyandcohesionofeachstep,thusforminghighlyrelevant,
consistentthoughtchains.
Afterconstruction,wemergeourdatawiththetrainingsetfromMind2WebandMiniWob++toform
ourfinaltrainingdataset. TheproportionofeachsplitisinFigure5.
2.3.3 AutoWebBenchConstruction
We segment the complex task operation dataset collected in Section 2.3.2 for evaluation. Au-
toWebBenchisdividedintotwosplits: in-andout-of-domain,whichserveasbasesforourperfor-
manceassessment. Thein-domaindatasetrepresentstrainingdatacollectedfromthesamewebsite,
measuringthemodel’sperformanceunderfamiliarconditions. Incontrast,theout-of-domaindataset
encompassesdatacollectedfromwebsitesentirelyexcludedfromourtrainingset. Itoffersaunique
opportunitytomeasurethemodel’sgeneralizabilityandabilitytoadapttounfamiliarenvironments.
Weselect50browsingtracesforeachsplitasourtestdata. Thesetracesarescrutinizedandfiltered
viahumanverification,ensuringamorereliableevaluationbenchmark.
Drawing on the methodology presented in Mind2Web, we comprehensively evaluate each step
involved in the operation. This allows us to assess the step and overall accuracy of the model’s
operations. DetailedresultsofthisevaluationareavailableinTable2.
2.4 Training
WetrainthemodelthroughthreestepsillustratedinFigure6.
2.4.1 Step1: CurriculumLearning
ThefirstoneisSupervisedFine-Tuning(SFT).WeutilizedatainSection2.3fortraining
L SFT(π θ)=−E (x,y)∼D[logπ θ(y |x)] (1)
Thisapproachenhancesthemodel’scomprehensionofwebpagesanditscapabilityasanagentto
performoperationswithintheenvironments. Significantly,weusecurriculumlearning(CL),which
mimicsthehumanlearningprocess,advocatingformodelstostartlearningfromeasysamplesand
graduallyadvancetocomplexones. Ithasbeendemonstratedinpriorworks[6;38]toimprovemodel
capabilitiessubstantially.
7EnablingLMtoReadandOperateontheWeb. Intheinitialstage,wemixthedataconstructedin
Section2.3.1toequipthemodelwiththeabilityto(1)comprehendthestructureofwebpagesand
thefunctionsofvariouswebcomponents,andto(2)executepredefinedoperationsonthecurrent
webpage,thusimplementingsimpleuserinstructions.
ToMakeLMLearntoPlan&ReasonontheWeb. Duringthisstage,wecontinuetoemploythe
constructeddatainSection2.3.2fortraining. Weenableourmodeltodecomposetasksintosubtasks
andexecutesubsequentstepsbasedonthecurrentwebpageandthesequenceofprioroperations.
Aftertheabovetraining,ourmodelM acquiredessentialcapabilityincompletingwebbrowsing
SFT
tasksandcouldindependentlyexecuteoperationsbasedonuserinstructions.
2.4.2 Step2: ReinforcementLearning
Followingprevioustraining,M hasdemonstratedsomeabilitytooperatethebrowserandinfer
SFT
the task. However, due to the distinctive nature of SFT training, M attempts to mimic the
SFT
inferenceprocessandoperationsbutsometimesoverlooksthewebpage’sstateandprecedingoperation
sequences,leadingtohallucination.Consequently,weproposeaself-samplingreinforcementlearning
tomitigatetheseoperativeillusions.
First,weuseM forn-foldsampling(n=20)oncomplextaskoperationsamplesinthetrainingset.
SFT
Wecombinethesampledoutputandgoldenanswertoconstructcontrastivedatawithpositiveand
negativepairs. Subsequently,weretainsamplesbasedonthefollowingcriteria:
• Fromallniterationsofsampling,weselectdatawherethemodelcompletedthetasksfrom1to
n-1times. IfM answeredalliterationscorrectly,weconsideritdevoidoftrainingvalueand
SFT
incapable of providing practical negative examples. Conversely, If M answered incorrectly
SFT
across all iterations, we suspect issues with the data and exclude them, as the model cannot
adequatelyfittheseoutliersduringoptimization.
• We retain different erroneous operations and remove duplicates to preserve distinct negative
examples.
AfterconstructingcontrastivedataD ,weemploytheDPO[32]trainingapproachtomakeM
Const. SFT
learnfromitsmistakesandfurtherenhanceitscapabilities. Duringthetraining,wefoundthatthe
directuseofDPOlossledtoinstability. Tomitigatethisissue,weproposeincludingSFTlossto
stabilizethereinforcementlearningprocessandincreasethenumberoftrainingstepswhileensuring
nolossoftheoriginalmodel’snaturallanguageandagentabilities,achievingamorerobustmodel
M :
DPO
(cid:104) (cid:16) (cid:17)(cid:105)
L DPO(π θ;π ref)=−E (x,yw,yl)∼D logσ βlog ππ rθ ef( (y yw w|x |x) ) −βlog ππ rθ ef( (y yl l|x |x) ) (2)
L SFT(π θ;π ref)=−E (x,yw,yl)∼D[logπ θ(y
w
|x)] (3)
L =λ·L +L (4)
Total DPO SFT
2.4.3 Step3: RejectionSamplingFinetuning
IntheRFT(RejectionSamplingFinetuning)step,weaimtooptimizeforwebpageenvironmentsin
specificdomains. RFTenablesustoperformtargetedtrainingthroughsubstantialsamplingfrom
anexistingmodel,selectingtheaccuratetrajectoriesininstanceslackingonesviarewardsignals.
Ourrewardsignalscanbefurnishedeitherbytheenvironmentitselforthroughpre-designedreward
models. Duetothenetworkpolicyconstraintsinherentinrealwebpageenvironments,weconduct
ourexperimentswithinsandboxenvironmentsfurnishedbyMiniWob++andWebArena.
For MiniWob++, we leverage the query generator in MiniWob++ to auto-generate multiple user
queries for each task. We determine the number of generated queries for each task based on its
difficulty. Then, we employ M to try to solve the queries. If a trace completes the task (as
DPO
adjudgedbytheMiniWob++environment),weconsiderthistraceasapositivetrace.
In the case of WebArena, to prevent overlap with the test set, we manually construct multiple
distinctiveuserqueriesbasedonWebArena’stemplates. Foreachsample,weapplyM toperform
DPO
64timesofsampling. Similarly,ifourmodelcompletesthetaskatleastonce(adjudgedbymanually
writtenrules),wedeemthesuccessfultraceasapositivetrace.
8Table 2: Step Success Rates of different models on AutoWebBench. All models are tested with
in-contextlearningpromptspresentedinAppendixE.
English Chinese
Model #Params
Cross-Task Cross-Domain Cross-Task Cross-Domain
GPT-3.5-Turbo[29] N/A 12.1 6.4 13.5 10.8
GPT-4[1] N/A 38.6 39.7 36.7 36.3
Claude2[3] N/A 13.2 8.1 13.0 7.9
LLaMA2[36] 7B 3.3 2.5 - -
LLaMA2[36] 70B 8.3 8.9 - -
Qwen[4] 7B 9.0 7.6 9.1 7.5
AUTOWEBGLM 6B 64.8 58.6 65.4 61.8
Table3: StepSuccessRatesonMind2Web. †indicatesthattop-10candidateswereusedforthistest,
otherwisetop-50wasused. *indicatesmodel’sindividualfinetuningoncorrespondingtrainset.
Model #Params Modality Cross-Task Cross-Website Cross-Domain Avg.
GPT-3.5-Turbo[29] N/A Text 17.4 16.2 18.6 17.4
GPT-4†[1] N/A Text 36.2 30.1 26.4 30.9
Flan-T5-XL∗[22] 3B Text 52.0 38.9 39.6 43.5
Html-T5-XL∗[12] 540+3B Text 71.5 62.2 67.1 66.9
LLaMA2∗[36] 7B Text 52.7 47.1 50.3 50.1
LLaMA2∗[36] 70B Text 55.8 51.6 55.7 54.4
Qwen-VL∗[5] 9.6B Image&Text 12.6 10.1 8.0 10.2
SeeClick∗[8] 9.6B Image&Text 23.7 18.8 20.2 20.9
CogAgent∗[14] 18B Image&Text 62.3 54.0 59.4 58.2
AUTOWEBGLM 6B Text 66.4 56.4 55.8 59.5
Byutilizingthemethodsabove,weconstructedtwodistinctsuccessfuldatasets,onefromMiniWob++
andtheotherfromWebArena. Thesecompriseapproximately15ktraces(66ksteps)and240traces
(2ksteps),respectively,whichareusedforAUTOWEBGLM’sindividualfinetuningonthesetwo
tasks.
3 Experiments
We establish a bilingual (Chinese-English) benchmark AutoWebBench and evaluate the abilities
ofpubliclyavailableagents. Wealsoconductextensiveexperimentsonnumerousbenchmarksto
evaluatetheperformanceofAUTOWEBGLMincomparisontoseveralbaselinesacrossvarioustasks
involvingnavigatingbothEnglishandChinesewebsites.
3.1 MainResults
BeyondAutoWebBench,wealsotestAUTOWEBGLMoverthreeotherestablishedwebnavigating
benchmarks: Mind2Web[9],MiniWoB++[19],andWebArena[47].
AutoWebBench. As discussed in Section 2.3.3, We divide the test set into four splits: Chinese,
English,in-domain,andout-of-domain,forevaluationpurposes. WeusetheStepSuccessRate(SSR)
asourevaluationmetric. Allmodelsareevaluatedwithanin-contextlearningpromptasdescribedin
AppendixE.TheresultsareinTable2.Asdiscernedfromthetable,AUTOWEBGLM,aftermulti-task
training, excels in predicting general user operation patterns, aligning well with user operations.
Incontrast,otherbaselines,intheabsenceofsufficienttraining,struggletoaccuratelylearnuser
operationsacrossdifferentreal-worldwebsitesbasedonwebpagecontentandtaskdescriptions.
Mind2Web[9]. WeusethesettingsfromMind2WebwithSSRasourprimaryevaluationmetric. To
comparethemodelfairly,weutilizetheMindActframeworkprovidedbyMind2Webtoevaluatethe
9Table4: Ablationstudy. AutoWebBenchandWebArenadonothaveatrainingset,whiletheRFT
stageisonlysuitableforsamplingintheenvironment,sowerepresentthemby"-".
Method AutoWebBench Mind2Web MiniWob++ WebArena
TrainingDataAblation
OnlyTrainSet - 48.1 44.3 -
+)Stage1 23.5 48.4 48.3 2.5
+)Stage2 60.2 55.2 78.9 7.6
+)Stage1+2 61.8 56.7 81.7 8.3
TrainingStrategyAblation
SFT 61.8 56.7 81.7 8.3
+)DPO 62.7 59.5 80.8 8.5
+)RFT - - 89.3 18.2
AUTOWEBGLM 62.7 59.5 89.3 18.2
model’sperformance. TheresultsareinTable3. Weobtainedthebaselineresultsfromreferences[4;
9;12;14;8].
MiniWoB++ [19] & WebArena [47]. For Figure7: ResultsonMiniWoB++andWebArena. *
MiniWob++, following the experimental indicatesmodel’sindividualfinetuningontask-related
setup from WebAgent [12], we test Mini- datasets.
WoB++with56tasksbyrunning100eval-
uation episodes per task to evaluate model Model Size MiniWoB++ WebArena
capabilities. ForWebArena,weintegrateour
GPT-3.5-Turbo[29] N/A 13.4 6.2
HTMLparsermoduleandactionexecution
GPT-4[1] N/A 32.1 14.4
module into the WebArena environment to
Text-Bison-001[2] N/A - 5.1
make it compatible with our system. The
LLaMA2[36] 7B 42.8∗ 1.2
results are in Table 7. For the WebArena
LLaMA2[36] 70B 47.1∗ 0.6
baselines, the results are derived from the
WebN-T5-XL[13] 3B 48.4∗ -
references[47;43;44]. RegardingtheMin-
Wob++baselines,someoftheresultscome Html-T5-XL[12] 543B 85.6∗ -
from the references [12]. LLaMA2 results Lemur[43] 70B - 5.3
areobtainedthroughtrainingandevaluation AUTOWEBGLM 6B 89.3∗ 18.2∗
ontheMinWob++dataset.
3.2 AblationStudy
To evaluate the impact of different stages of data and training strategies on model performance
enhancement,weconductacomprehensiveablationstudyinTable4.
TrainingDataAblation. Wetrainandtestonlymodelsthatcontaintheoriginaltrainingsetand
incorporate simple and complex task data (see Section 2.3) for training. This approach helps to
qualitativelymeasuretheimpactofdifferentdatasetsonthemodel.
TheComplexTaskdatasetsignificantlyimprovesmodelperformance. Wehypothesizethatthisis
due to the complex data more closely aligning with real-world scenarios, thereby fundamentally
transformingmodelperformance.
The simple task dataset shows only a slight improvement when training alone. However, when
trainingjointlywiththecomplextaskdataset,thereisasignificantimprovement.Wefindthattraining
exclusivelywithcomplextaskdatasetsleadstobasicoperationalerrors,suggestingthattrainingwith
simpletaskdatasetscaneffectivelymitigatethisproblem.
TrainingStrategyAblation. WecomparetheresultsofSFT,DPO,andRFT-enhancedmodelsand
findthat: (1)ComparedtoSFT,theDPOtrainingfacilitatesmodellearningfromitsmistakes,further
enhancingmodelperformance. (2)RFTenablesourmodeltoperformbootstrapenhancementin
differentdomains. Withpracticecomesproficiency,resultinginimprovementswithineachdomain.
10Table5: ErrorDistributioninWebTaskAutomation
ErrorType Proportion
Hallucinations 44%
PoorGraphicalRecognition 28%
MisinterpretationofTaskContext 20%
Pop-UpInterruption 8%
3.3 CaseStudyandErrorAnalysis
Toassesstheeffectivenessofourmodel, weconductaseriesofcasestudiescoveringarangeof
web-basedtasks,includingeverydayuse,leisureandrelaxation,andacademicresearch,coveringthe
typicalrangeofwebrequirements. Oursystemachievessatisfactoryresultsinmostscenarios,with
severalspecificcasesdetailedintheappendixG.
Whileoursystemperformscommendablywellonavarietyofweb-basedtasks,ithaslimitations. We
identifyerrorsthatoccasionallyoccurduringtaskexecution,whichcanbebroadlycategorizedinto
fourtypes: hallucinations,poorgraphicalrecognition,misinterpretationoftaskcontext,andpop-up
interruptions. Table5outlinestheproportionoftheseerrorsobservedduringerroranalysis. Although
relativelyinfrequent,theseerrorsarecrucialinourongoingeffortstorefineandenhancethesystem’s
capabilities.
4 RelatedWork
Constructingacomprehensivewebbrowsingagentisacomplextaskthatinvolvesvariousmodules,
suchasalanguagemodelfordecision-makingandanHTMLparserforenvironmentobservation.
Furthermore,itisessentialtohaveappropriatewebbrowsingevaluationcriteriawhencreatingan
effectivewebbrowsingagent. Inthissection,wewilldiscusstheworksrelatedtotheseaspects.
LanguageModels(LMs).Largelanguagemodels(LLMs),suchasGPT-4[1],Claude-2[3],LLaMA-
2[35],GLM-130B[45;10],OPT[46],andBLOOM[34],haveaccumulatedextensiveknowledgein
variousnaturallanguageprocessingtasks. However,duetothehighcostofdeployingsuchlarge
languagemodels,smallermodelswithlowercostsandcomparablecapabilitiesareusuallypreferred.
Manyopen-sourceprojects,suchasLLaMA2-7B[35]andChatGLM3-6B[45],havedemonstrated
strongperformancetolargelanguagemodelsinsomedomains.
BenchmarksforWebNavigation. Theprimarywebbrowsingevaluationdatasetsprovideavariety
ofevaluationmetrics. MiniWoB++[16]providesseveralsimulatedwebenvironments,withtasks
primarilytoevaluatethemodel’sabilitytointeractwithwebpagecomponents. However,withthe
increasingdemandforcomplexweboperationcapabilities,Mind2Web[9]andWebArena[47]have
beencreated. Mind2Webisanofflineevaluationsetforcomplexwebbrowsingthatprovidesseveral
metrics. Theevaluationmethodisstraightforwardandcommonlyusedformodelevaluations. In
contrast,theWebArenabenchmark,basedonrealwebsites,createsmultiplevirtualenvironments
andusesvariousevaluationmethodstoassessthetaskcompletionrate,makingitmoresuitablefor
real-worldtaskcompletionevaluation.
AgentsforWebAutomation. PreviousworksuchasWebGPT[27]andWebGLM[20]combined
LLMswithwebenvironments. However,theirprimaryapplicationwasquestion-answering(QA)
tasks[33;28;7;18],utilizinginternetresourcestoansweruserqueries. Recentworks[25;14;8;43]
focusmoreonexecutingcomplexoperationsorinteractivetasks. Specifically,MindAct[9]works
byfilteringwebpageelementsandselectingtheelementthroughmultipleroundsofmultiple-choice
questions. Itoftenrequiresmorethantenmodelcallstocompleteasingleweboperation,which
couldbemoreefficient. Ontheotherhand,WebAgent[12]usesHTML-T5toprocesstheobservation
space’scontent, includingHTML,previousoperations, anduserinstructions. ItusestheFlan-U-
Plammodeltogeneratecodetocontrolwebpages,exhibitingexcellentwebbrowsingperformance.
However,itfacesdeploymentchallengesduetothesizeoftheFlan-U-Plammodel,whichis540B
scale. AUTOWEBGLM,basedsolelyonasingleChatGLM3-6B,hasarobustwebbrowsingcapability
comparabletoWebAgent,demonstratinghighvalueforpracticaldeployment.
11Prompt-basedDataConstructionMethods. Constructingdatathroughpromptshasrecentlygained
significanttraction[39;15;31;26]. Thisapproachleverageslanguagemodelstogeneratesynthetic
datafortraining. AnotableexampleisEvol-Instruct[42;23],inspiredbythetheoryofevolution,
demonstrating the effectiveness of using LLMs to generate diverse and complex instructions for
varioustasks. Additionally,someresearchersexplorethepotentialofgeneratingdatainazero-shot
setting,wherethemodelproducesdatafortasksithasyettobeexplicitlytrainedon[24],highlighting
theversatilityofprompt-baseddataconstruction. Thesemethodologiesrapidlyevolve,offeringa
promisingavenuefordatagenerationinvariousdomains,especiallywheretraditionaldatacollection
methodscouldbemorepracticalandsufficient.
5 Conclusion
Inthiswork,wepresentAUTOWEBGLM,anadvancedlanguagemodel-basedagentexhibitingrobust
performanceinvariousautonomouswebnavigationbenchmarks. OurmodeladdressesextantLLM
limitationsandsimplifieswebpagesbyeffectivelycontrollingHTMLtextlengthandhandlingthe
web’sopen-domainnature. Westrategicallyemploycurriculumlearning,reinforcementlearning,and
rejectionsamplingfinetuningtoenhancewebpagecomprehensionandbrowseroperationlearning.
Wealsointroduceauniquebilingualwebbrowsingbenchmark—thatlaysasolidfoundationfor
futureresearch. OurfindingsrepresentsignificantprogressinutilizingLLMsforintelligentagents.
References
[1] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida,
J. Altenschmidt, S. Altman, S. Anadkat, et al. Gpt-4 technical report. arXiv preprint
arXiv:2303.08774,2023.
[2] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa,
P.Bailey,Z.Chen,etal. Palm2technicalreport. arXivpreprintarXiv:2305.10403,2023.
[3] Anthropic. Modelcardandevaluationsforclaudemodels. 2023.
[4] J.Bai,S.Bai,Y.Chu,Z.Cui,K.Dang,X.Deng,Y.Fan,W.Ge,Y.Han,F.Huang,etal. Qwen
technicalreport. arXivpreprintarXiv:2309.16609,2023.
[5] J.Bai,S.Bai,S.Yang,S.Wang,S.Tan,P.Wang,J.Lin,C.Zhou,andJ.Zhou. Qwen-vl: A
frontierlargevision-languagemodelwithversatileabilities. arXivpreprintarXiv:2308.12966,
2023.
[6] Y.Bengio,J.Louradour,R.Collobert,andJ.Weston. Curriculumlearning. InProceedingsof
the26thannualinternationalconferenceonmachinelearning,pages41–48,2009.
[7] J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic parsing on freebase from question-
answerpairs. InProceedingsofthe2013conferenceonempiricalmethodsinnaturallanguage
processing,pages1533–1544,2013.
[8] K. Cheng, Q. Sun, Y. Chu, F. Xu, Y. Li, J. Zhang, and Z. Wu. Seeclick: Harnessing gui
groundingforadvancedvisualguiagents. arXivpreprintarXiv:2401.10935,2024.
[9] X. Deng, Y. Gu, B. Zheng, S. Chen, S. Stevens, B. Wang, H. Sun, and Y. Su. Mind2web:
Towardsageneralistagentfortheweb. arXivpreprintarXiv:2306.06070,2023.
[10] Z.Du,Y.Qian,X.Liu,M.Ding,J.Qiu,Z.Yang,andJ.Tang. Glm: Generallanguagemodel
pretrainingwithautoregressiveblankinfilling. InProceedingsofthe60thAnnualMeetingof
theAssociationforComputationalLinguistics(Volume1: LongPapers),pages320–335,2022.
[11] Y.Gu,Y.Shu,H.Yu,X.Liu,Y.Dong,J.Tang,J.Srinivasa,H.Latapie,andY.Su. Middleware
forllms: Toolsareinstrumentalforlanguageagentsincomplexenvironments. arXivpreprint
arXiv:2402.14672,2024.
[12] I. Gur, H. Furuta, A. Huang, M. Safdari, Y. Matsuo, D. Eck, and A. Faust. A real-world
webagentwithplanning,longcontextunderstanding,andprogramsynthesis. arXivpreprint
arXiv:2307.12856,2023.
12[13] I.Gur,O.Nachum,Y.Miao,M.Safdari,A.Huang,A.Chowdhery,S.Narang,N.Fiedel,and
A.Faust. Understandinghtmlwithlargelanguagemodels. arXivpreprintarXiv:2210.03945,
2022.
[14] W.Hong, W.Wang, Q.Lv, J.Xu, W.Yu, J.Ji, Y.Wang, Z.Wang, Y.Dong, M.Ding, etal.
Cogagent: Avisuallanguagemodelforguiagents. arXivpreprintarXiv:2312.08914,2023.
[15] O.Honovich,T.Scialom,O.Levy,andT.Schick. Unnaturalinstructions: Tuninglanguage
modelswith(almost)nohumanlabor. arXivpreprintarXiv:2212.09689,2022.
[16] P.C.Humphreys,D.Raposo,T.Pohlen,G.Thornton,R.Chhaparia,A.Muldal,J.Abramson,
P. Georgiev, A. Santoro, and T. Lillicrap. A data-driven approach for learning to control
computers. InInternationalConferenceonMachineLearning,pages9466–9482.PMLR,2022.
[17] T.Kojima,S.S.Gu,M.Reid,Y.Matsuo,andY.Iwasawa. Largelanguagemodelsarezero-shot
reasoners. Advancesinneuralinformationprocessingsystems,35:22199–22213,2022.
[18] T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh, C. Alberti, D. Epstein,
I.Polosukhin,J.Devlin,K.Lee,etal. Naturalquestions: abenchmarkforquestionanswering
research. TransactionsoftheAssociationforComputationalLinguistics,7:453–466,2019.
[19] E.Z.Liu,K.Guu,P.Pasupat,T.Shi,andP.Liang. Reinforcementlearningonwebinterfaces
usingworkflow-guidedexploration. InInternationalConferenceonLearningRepresentations,
2018.
[20] X.Liu,H.Lai,H.Yu,Y.Xu,A.Zeng,Z.Du,P.Zhang,Y.Dong,andJ.Tang. Webglm:Towards
anefficientweb-enhancedquestionansweringsystemwithhumanpreferences. arXivpreprint
arXiv:2306.07906,2023.
[21] X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding, K. Men, K. Yang, et al.
Agentbench: Evaluatingllmsasagents. arXivpreprintarXiv:2308.03688,2023.
[22] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph,
J.Wei,etal. Theflancollection: Designingdataandmethodsforeffectiveinstructiontuning.
InInternationalConferenceonMachineLearning,pages22631–22648.PMLR,2023.
[23] Z. Luo, C. Xu, P. Zhao, Q. Sun, X. Geng, W. Hu, C. Tao, J. Ma, Q. Lin, and D. Jiang.
Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint
arXiv:2306.08568,2023.
[24] Y. Meng, J. Huang, Y. Zhang, and J. Han. Generating training data with language models:
Towardszero-shotlanguageunderstanding.AdvancesinNeuralInformationProcessingSystems,
35:462–477,2022.
[25] S.Mishra,P.Liang,A.Czajka,D.Z.Chen,andX.S.Hu. Cc-net: Imagecomplexityguided
networkcompressionforbiomedicalimagesegmentation. In2019IEEE16thInternational
SymposiumonBiomedicalImaging(ISBI2019),pages57–60.IEEE,2019.
[26] S.Mukherjee,A.Mitra,G.Jawahar,S.Agarwal,H.Palangi,andA.Awadallah. Orca: Pro-
gressivelearningfromcomplexexplanationtracesofgpt-4. arXivpreprintarXiv:2306.02707,
2023.
[27] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju,
W.Saunders,etal. Webgpt: Browser-assistedquestion-answeringwithhumanfeedback. arXiv
preprintarXiv:2112.09332,2021.
[28] T.Nguyen,M.Rosenberg,X.Song,J.Gao,S.Tiwary,R.Majumder,andL.Deng. Msmarco:
Ahumangeneratedmachinereadingcomprehensiondataset. choice,2640:660,2016.
[29] OpenAI. Introducingchatgpt. 2022.
[30] L.Ouyang,J.Wu,X.Jiang,D.Almeida,C.Wainwright,P.Mishkin,C.Zhang,S.Agarwal,
K.Slama,A.Ray,etal. Traininglanguagemodelstofollowinstructionswithhumanfeedback.
AdvancesinNeuralInformationProcessingSystems,35:27730–27744,2022.
13[31] B.Peng, C.Li, P.He, M.Galley, andJ.Gao. Instructiontuningwithgpt-4. arXivpreprint
arXiv:2304.03277,2023.
[32] R.Rafailov,A.Sharma,E.Mitchell,S.Ermon,C.D.Manning,andC.Finn. Directpreference
optimization:Yourlanguagemodelissecretlyarewardmodel.arXivpreprintarXiv:2305.18290,
2023.
[33] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang. Squad: 100,000+ questions for machine
comprehensionoftext. arXivpreprintarXiv:1606.05250,2016.
[34] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ilic´, D. Hesslow, R. Castagné, A. S. Luccioni,
F.Yvon,M.Gallé,etal. Bloom: A176b-parameteropen-accessmultilinguallanguagemodel.
arXivpreprintarXiv:2211.05100,2022.
[35] H.Touvron,T.Lavril,G.Izacard,X.Martinet,M.-A.Lachaux,T.Lacroix,B.Rozière,N.Goyal,
E.Hambro, F.Azhar, etal. Llama: Openandefficientfoundationlanguagemodels. arXiv
preprintarXiv:2302.13971,2023.
[36] H.Touvron,L.Martin,K.Stone,P.Albert,A.Almahairi,Y.Babaei,N.Bashlykov,S.Batra,
P.Bhargava,S.Bhosale,etal. Llama2: Openfoundationandfine-tunedchatmodels. arXiv
preprintarXiv:2307.09288,2023.
[37] L.Wang,C.Ma,X.Feng,Z.Zhang,H.Yang,J.Zhang,Z.Chen,J.Tang,X.Chen,Y.Lin,W.X.
Zhao,Z.Wei,andJ.-R.Wen. Asurveyonlargelanguagemodelbasedautonomousagents.
arXivpreprintarXiv:2308.11432,2023.
[38] X.Wang,Y.Chen,andW.Zhu. Asurveyoncurriculumlearning. IEEETransactionsonPattern
AnalysisandMachineIntelligence,44(9):4555–4576,2021.
[39] X.Wang,J.Wei,D.Schuurmans,Q.V.Le,E.H.Chi,S.Narang,A.Chowdhery,andD.Zhou.
Self-consistencyimproveschainofthoughtreasoninginlanguagemodels. InTheEleventh
InternationalConferenceonLearningRepresentations,2022.
[40] J.Wei,X.Wang,D.Schuurmans,M.Bosma,F.Xia,E.Chi,Q.V.Le,D.Zhou,etal. Chain-of-
thoughtpromptingelicitsreasoninginlargelanguagemodels. AdvancesinNeuralInformation
ProcessingSystems,35:24824–24837,2022.
[41] Z.Xi,W.Chen,X.Guo,W.He,Y.Ding,B.Hong,M.Zhang,J.Wang,S.Jin,E.Zhou,R.Zheng,
X.Fan,X.Wang,L.Xiong,Y.Zhou,W.Wang,C.Jiang,Y.Zou,X.Liu,Z.Yin,S.Dou,R.Weng,
W.Cheng,Q.Zhang,W.Qin,Y.Zheng,X.Qiu,X.Huang,andT.Gui. Theriseandpotentialof
largelanguagemodelbasedagents: Asurvey. arXivpreprintarXiv:2309.07864,2023.
[42] C.Xu,Q.Sun,K.Zheng,X.Geng,P.Zhao,J.Feng,C.Tao,andD.Jiang. Wizardlm: Empow-
eringlargelanguagemodelstofollowcomplexinstructions. arXivpreprintarXiv:2304.12244,
2023.
[43] Y.Xu,H.Su,C.Xing,B.Mi,Q.Liu,W.Shi,B.Hui,F.Zhou,Y.Liu,T.Xie,etal. Lemur:
Harmonizingnaturallanguageandcodeforlanguageagents. arXivpreprintarXiv:2310.06830,
2023.
[44] A. Zeng, M. Liu, R. Lu, B. Wang, X. Liu, Y. Dong, and J. Tang. Agenttuning: Enabling
generalizedagentabilitiesforllms. arXivpreprintarXiv:2310.12823,2023.
[45] A.Zeng,X.Liu,Z.Du,Z.Wang,H.Lai,M.Ding,Z.Yang,Y.Xu,W.Zheng,X.Xia,etal.
Glm-130b: Anopenbilingualpre-trainedmodel. InTheEleventhInternationalConferenceon
LearningRepresentations,2022.
[46] S.Zhang,S.Roller,N.Goyal,M.Artetxe,M.Chen,S.Chen,C.Dewan,M.Diab,X.Li,X.V.
Lin,etal.Opt:Openpre-trainedtransformerlanguagemodels.arXivpreprintarXiv:2205.01068,
2022.
[47] S.Zhou, F.F.Xu, H.Zhu, X.Zhou, R.Lo, A.Sridhar, X.Cheng, T.Ou, Y.Bisk, D.Fried,
etal. Webarena: Arealisticwebenvironmentforbuildingautonomousagents. InSecondAgent
LearninginOpen-EndednessWorkshop,2023.
14A HTMLPrunningPseudoCode
Algorithm1:HTMLPruner
Data: treetree,keptelementskept,recursioncountrcc,maxdepthd,maxchildrenmc,max
siblingms
Result: prunedtreetree
1 nodes←[]
2 fort←0torccdo
3 foridinkeptdo
4 node←tree.elementwithid
5 nodes.append(node)
6 nodes.append(getAnscendants(node,d))
7 nodes.append(getDescendants(node,d,mc))
8 nodes.append(getSiblings(node,ms))
9 endfor
10 d,mc,ms←update(d,mc,ms)// make them smaller
11 endfor
12 fornodeinreversed(tree)do
13 ifnotnodeinnodesornot(nodehastextorattriborlen(node.children)>1ornodeis
root)then
14 tree.remove(element)
15 endif
16 endfor
B ImplementationDetailsof AUTOWEBGLM
DuringtheSFTphase,wesetthelearningrateto1e-5withabatchsizeof32. IntheDPOstage,we
samplethecomplextaskdataset20times. Afterthefilteringprocess,webuildacontractionaldataset
ofapproximately13k. WesetthelearningratefortheDPOto1e-6,thebatchsizeto64,andthe
β parameterto0.15. WeaddtheSFTloss,weightedbyafactorof0.8. DuringtheRFTstage,we
collectsamplesfromtwodiverseenvironments,MiniWoB++andWebArena,resultinginsuccessful
datasetsofapproximately66kand2k,respectively,whichunderwentfinetuning. Thelearningrate
setforthisstagewas1e-5,andthebatchsizewas32.
C FullResultsofMiniWob++
Table6istheper-taskaveragesuccessrateon56tasksfromMiniWoB++.
D InputPrompt
BelowisourinputpromptforAUTOWEBGLMtrainingandinference:
<html> {html_content} </html>
You are a helpful assistant that can assist with web navigation tasks.
You are given a simplified html webpage and a task description.
Your goal is to complete the task. You can use the provided functions
below to interact with the current webpage.
#Provided functions:
def click(element_id: str) -> None:
"""
Click on the element with the specified id.
Args:
element_id: The id of the element.
15Table6: PER-TASKPERFORMANCEONMINIWOB++
Task AUTOWEBGLM HTML-T5-XL WebN-T5-XL GPT-4 GPT-3.5-Turbo
book-flight 0.50 0.99 0.48 0.00 0.00
choose-date 1.00 0.16 0.08 0.00 0.00
choose-date-easy 1.00 1.00 1.00 0.00 0.00
choose-date-medium 1.00 0.56 0.07 0.00 0.00
choose-list 0.15 0.22 0.16 0.00 0.00
click-button 1.00 1.00 1.00 0.67 1.00
click-button-sequence 1.00 1.00 1.00 0.33 0.00
click-checkboxes 1.00 1.00 0.22 0.33 0.00
click-checkboxes-large 0.83 0.90 0.54 0.00 0.00
click-checkboxes-soft 0.37 0.99 0.08 0.00 0.00
click-checkboxes-transfer 1.00 1.00 0.63 1.00 0.00
click-collapsible 1.00 1.00 0.26 0.00 0.00
click-collapsible-2 0.76 0.93 0.27 0.00 0.00
click-color 0.74 1.00 0.34 0.67 0.00
click-dialog 1.00 1.00 1.00 0.33 0.00
click-dialog-2 1.00 0.74 1.00 0.67 0.67
click-link 1.00 1.00 0.99 0.33 0.33
click-menu 1.00 0.37 0.41 0.00 0.50
click-option 1.00 1.00 0.87 0.67 0.00
click-pie 1.00 0.96 0.51 0.67 1.00
click-scroll-list 0.57 0.99 0.98 0.00 0.00
click-shades 1.00 0.00 0.00 0.00 0.00
click-shape 0.64 0.79 0.24 0.00 0.00
click-tab 1.00 1.00 0.57 0.00 0.67
click-tab-2 1.00 0.94 0.57 0.00 0.00
click-tab-2-hard 1.00 0.88 0.12 0.33 0.00
click-test 1.00 1.00 1.00 1.00 0.00
click-test-2 0.93 1.00 1.00 1.00 1.00
click-widget 1.00 1.00 1.00 1.00 0.00
count-shape 0.65 0.67 0.64 0.00 0.00
email-inbox 1.00 1.00 0.38 0.00 0.33
email-inbox-forward-nl 1.00 1.00 0.33 0.00 0.00
email-inbox-forward-nl-turk 1.00 1.00 0.23 0.00 0.00
email-inbox-nl-turk 1.00 0.99 0.20 0.67 0.00
enter-date 1.00 1.00 0.89 0.66 0.00
enter-password 1.00 1.00 0.72 0.67 0.00
enter-text 1.00 1.00 0.89 0.67 0.00
enter-text-dynamic 1.00 1.00 1.00 0.00 0.00
enter-time 0.00 1.00 0.00 0.00 0.00
focus-text 1.00 1.00 1.00 0.00 0.00
focus-text-2 1.00 1.00 1.00 0.00 1.00
grid-coordinate 1.00 1.00 1.00 1.00 0.33
guess-number 1.00 0.13 0.00 0.00 0.00
identify-shape 1.00 1.00 0.88 0.67 0.00
login-user 1.00 1.00 0.82 0.33 0.00
login-user-popup 0.63 1.00 0.72 0.33 0.00
multi-layouts 1.00 1.00 0.83 0.33 0.00
multi-orderings 1.00 1.00 0.88 0.67 0.00
navigate-tree 1.00 0.99 0.91 0.33 0.00
search-engine 1.00 0.93 0.34 0.67 0.00
social-media 1.00 0.99 0.20 0.33 0.00
social-media-all 0.90 0.31 0.21 0.00 0.00
social-media-some 0.76 0.89 0.42 0.00 0.00
tic-tac-toe 0.74 0.57 0.48 0.00 0.00
use-autocomplete 0.85 0.97 0.02 1.00 0.67
use-spinner 1.00 0.07 0.07 0.00 0.00
Average 0.893 0.856 0.484 0.321 0.134
16"""
def hover(element_id: str) -> None:
"""
Hover on the element with the specified id.
Args:
element_id: The id of the element.
"""
def select(element_id: str, option: str) -> None:
"""
Select an option from a dropdown.
Args:
element_id: The id of the element.
option: Value of the option to select.
"""
def type_string(element_id: str, content: str, press_enter: bool) ->
None:
"""
Type a string into the element with the specified id.
Args:
element_id: The id of the element.
content: The string to type.
press_enter: Whether to press enter after typing the string.
"""
def scroll_page(direction: Literal[’up’, ’down’]) -> None:
"""
Scroll down/up one page.
Args:
direction: The direction to scroll.
"""
def go(direction: Literal[’forward’, ’backward’]) -> None:
"""
Go forward/backward
Args:
direction: The direction to go to.
"""
def jump_to(url: str, new_tab: bool) -> None:
"""
Jump to the specified url.
Args:
url: The url to jump to.
new_tab: Whether to open the url in a new tab.
"""
def switch_tab(tab_index: int) -> None:
"""
Switch to the specified tab.
Args:
tab_index: The index of the tab to switch to.
"""
def user_input(message: str) -> str:
"""
17Wait for user input.
Args:
message: The message to display to the user.
Returns: The user input.
"""
def finish(answer: Optional[str]) -> None:
"""
Finish the task (optionally with an answer).
Args:
answer: The answer to the task.
"""
#Previous commands: {previous_commands}
#Window tabs: {exist_window_tabs_with_pointer_to_current_tab}
#Current viewport (pages): {current_position} / {max_size}
#Task: {task_description}
You should output one command to interact to the currrent webpage.
You should add a brief comment to your command to explain your
reasoning and thinking process.
E DataConstructionPrompt
Dataconstructionpromptforwebrecognitiondescription:
I want you to act as a Website Reader. Your objective is to explain a
website’s purpose and usage, given the website’s text. Your
explanation should cover all of the website’s primary functions.
DO NOT GUESS the purpose of the website, you SHOULD output \"None
\" If you are not PRETTY sure about the purpose of the website.
Note that you should only answer the purpose or usage within 20
words.
#Website Text#:
{html_content}
#Purpose#:
Dataconstructionpromptforsimpletasktask:
HTML:
{html_content}
I want you to act as a task generator that can help generate Task-
Operation pairs.
Based on the above HTML webpage, I will give you a specified operation
. Your goal is to come up with a ONE-STEP task that the specified
operation can solve.
Your answer SHOULD be in the following format:
Task: {Generated one-step task}
Operation: {The right operation to solve the task}
Intention: {The intention and thinking in your operation}
NOTICE:
181. Your generated task should not be too SIMPLE, NAIVE
2. You can only do \#type\# on <input> and <textarea>
Dataconstructionpromptforcomplextasktraceintent:
User’s overall task: {task_description}
User’s actions: {annotated_action_trace}
Based on this information, deduce the intent behind each of the user’s
actions. Your response should be structured as follows:
Intent of Step 1: [Describe the intent of the user’s first action from
the user’s first-person perspective]
Intent of Step 2: [Describe the intent of the user’s second action
from the user’s first-person perspective]
... and so on.
Note: Your response should have the same number of lines as the number
of user actions. The number of user actions in this task is {
number_of_steps_in_action}.
F AnnotationDetails
Theannotationprocesswasperformedby20annotatorsforonemonthusingtheGoogleChrome
browser with our plugin installed to record their actions on assigned websites. The annotators
firstvisitedthetargetwebsitesandcheckedwhetherthewebsitedescriptionsmatchedtheactual
tasks. Theythenevaluatedthetasksforclarity,relevance,achievability,complexity,andsubjectivity,
skippingthosethatdidn’tmeetthecriteria. Theycarefullyrecordedeachstepduringatask,including
anyloginorcaptchasteps. Fortasksthatrequiredananswer,theannotatorsmanuallyeditedthe
responses. Ifataskwasnotdoable,theycouldmodifyitsdescriptionorabandonit. Weprovidethe
demonstrationofourpluginforannotationinFigure8andtheannotationdocumentationinTable7.
19Table7: AnnotationDocumentation.
AnnotationTarget Wecollectedseveralwebsitesandgenerated50uniquetasksforeach. Foreach
website,annotatorsmustperformoperationsaccordingtothetaskdescriptionsto
completetherequirements.
InstallationofPlugin WerecommendusingGoogleChromeforannotation.
1 Downloadtheplugincodezippackage.
2 Downloadtheannotationdataandplacethefolderinthedirectorywhereyour
plugincodeislocated.
3 StartChrome,gotoMore>MoreTools>Extensions,enableDevelopermodeand
loadtheunpackedextensionbyselectingtheunzippedplugincodedirectory.
PluginIntroduction Tolearnhowtousethepluginindetail, pleaserefertotheintroductionvideo.
Thepluginhasthreemainfunctions:Start/PauseRecording,EndRecording,and
RecordArchive.
Navigationbetweenwebsitesandtasksismadeeasierwiththeuseof’«’and’»’
forpreviousandnextwebsites,and’<’and’>’forpreviousandnexttasks. The
pluginalsoprovidesinputfieldsfordirectnavigation.
1 Clickthetrashbinicontoresettheenvironment.
2 Whenencounteringloginorrobotauthentication,addanauthorizationrecordby
clickingtheplus(+)icononestepbeforethecorrespondingoperation.
3 Ifthetaskrequiresananswer,clicktheplus(+)iconintheappropriateplaceto
insertandedittheanswer.
4 Ifthereisnoresponsewhenyoutypecontentintoaninputfield,clicktheplussign
andgototheappropriatelocationtoinsertandedittheinputcontent(notethatthe
inputfieldisthelastobjecttobeclicked,somakesurethelastclickwasonan
inputfield).
5 Bydefault,thenavigationrecordismarkedasautomatic.Formanualnavigation,
such as typing a URL or going to the previous or next page, click the word
"Navigation"inthisrecordtochangeittoamanualnavigationrecord.
6 Navigationoperationsarenotrecordeduntilthepageisfullyloaded.Waitforthe
navigationrecordtoappearbeforeyoucontinue.
7 Ifyouneedanelementonthepagetohover,youcanclickonthatelementand
changethe"click"eventtoa"mouseover"record.
AnnotationProcess Hereisachecklistforyourreference.
1 Entertheassignedwebsitenumberinthedesignatedinputboxandnavigatetothe
correspondingwebsite.
2 First,verifyiftheauto-generatedwebsitedescriptionalignswiththewebsite’s
functionality. The description need not be detailed, but it should be generally
correct.Ifitmatches,proceedwithannotation;otherwise,skipthewebsite.
3 Taskdescriptionsareevaluatedtodeterminetheirfeasibilitybasedoncriteriasuch
astheprecisionofthedescription,whetherthetaskistypicaloftheaverageuser
ofthesite,anditsoverallfeasibility. Tasksthatdonotinvolvecomplexloginor
registrationoperationsandthosethatdonothavetoomanysubjectiveconditions
arepreferred. Ifthetaskhasminorissues,suchasanunachievableconditionor
involvingsubjectiveconditions,youmaymodifyitdirectlyinthetaskeditingbox.
4 Startexecutingoperationsaccordingtothetaskdescription,payingattentionto
whether there are missing or redundant operations, and handle login or robot
verificationasspecified.Aftercompletingthetask,click"End"andthen"Record
Archive"tosave.
5 Onceannotationiscomplete,pleaseuploadthecontentsofthetasksdirectory.
AdditionalAnnotation Designtentasksforeachwebsite,witheachtaskcontainingatleast15effective
steps.Anoperationisconsideredeffectiveonlyifitisaclick,mouseover,orinput
changethatcontributestoachievingthegoal.Removeanyerroneousoperations
fromtherecord.
1 Entertheassignedwebsitenumberinthewebsiteinputboxandnavigatetothat
website.
2 Brieflybrowsethewebsitetodeterminepossibletasks.
3 Chooseatasknumber.Thetaskboxwillnotcontainanydataatthispoint.
4 Startrecordingoperations.
5 Aftercompletingtheoperations,fillinthecompletedtaskinthetaskbox.
6 Savetheresult.
20Figure8: Demonstrationofannotationplugin.
21G Demonstration
G.1 WeatherReport
Thetargetedtasktobeexecutedis"Whatistheweatherliketoday?". Theactualexecutionstepscan
besummarizedasfollows:
• Step1: TypeSearchBar"todaysweatherreport"
• Step2: ClickSearchButton
• Step3: ClickSearchBar
• Step4: ClickDateButton
• Step5: Answer
AsFigure9shows,weenduponthewebpagewithalocalweatherreport. Weobtaineddetailed
informationabouttoday’sweatherastheanswer,effectivelycompletingthetargettask.
G.2 ShoppingAdvice
Thetargetedtasktobeexecutedis"HelpmepickaChristmasgiftforkids". Theactualexecution
stepscanbesummarizedasfollows:
• Step1: TypeSearchBar"Christmasgiftforkids"
• Step2: ClickSearchButton
• Step3: Click"All"taginthecategoryselection
• Step4: ClickSearchBar
• Step5: ClickThefirstproductontheresultpage
• Step6: Answer
AsFigure10shows,weultimatelylandedonacameraproductpage,whereweobtainedarecom-
mendationforthatcameraastheanswer,essentiallycompletingthetask.
G.3 SearchingArticle
Thetargetedtasktobeexecutedis"Findanarticleaboutlargelanguagemodel". Theactualexecution
stepscanbesummarizedasfollows:
• Step1: TypeSearchBar"largelanguagemodel"
• Step2: ClickSearchButton
• Step3: ClickWiki
• Step4: Scrolldown
• Step5: Gobackward
• Step6: Scrolldown
• Step7: ClickThelinktoanarticle
• Step8: Answer
As Figure 11 shows, we ultimately arrived at a page featuring an article and obtained "Found a
relevantarticle"astheanswer,essentiallyfulfillingthetask.
G.4 SearchingTools
The targeted task to be executed is "Find a tool to solve the differential equation". The actual
executionstepscanbesummarizedasfollows:
• Step1: TypeSearchBar"toolstosolvethedifferentialequation"
22• Step2: ClickSearchButton
• Step3: Scrolldown
• Step4: ClickThelinktoanonlinetool
• Step5: ClickODEcalculator
• Step6: Answer
AsFigure12shows,weultimatelyarrivedatapageforanODE(OrdinaryDifferentialEquation)
calculatorandobtained"Foundarelevanttool"astheanswer,essentiallycompletingthetask.
G.5 KnowledgeQuery
Thetargetedtasktobeexecutedis"Searchandtellmesomebasicinfoaboutthedarkmatter". The
actualexecutionstepscanbesummarizedasfollows:
• Step1: TypeSearchBar"darkmatter"
• Step2: ClickSearchButton
• Step3: ClickWiki
• Step4: Scrolldown
• Step5: Answer
AsFigure13shows,weultimatelyreachedawikipageaboutdarkmatter,obtainingsomebasicinfo
astheanswer,andeffectivelycompletingthetask.
G.6 FindingPictures
Thetargetedtasktobeexecutedis"HelpfindabeautifulpictureofthePacificOcean". Theactual
executionstepscanbesummarizedasfollows:
• Step1: TypeSearchBar"PacificOceanPictures"
• Step2: ClickSearchButton
• Step3: ClickApictureinthesearchresult
• Step4: Gobackward
• Step5: ClickAnotherinthesearchresult
• Step6: Answer
AsFigure14shows,weultimatelyreachedapagedisplayinganimageofthePacificOcean,obtaining
"FoundapictureofthePacificOceanforyou"astheanswer,effectivelycompletingthetask.
G.7 FindingResearch
Thetargetedtasktobeexecutedis"SearchandtellmeahotareainAIresearch".Theactualexecution
stepscanbesummarizedasfollows:
• Step1: TypeSearchBar"areasinAIresearch"
• Step2: ClickSearchButton
• Step3: ClickALinktoapage
• Step4: Scrolldown
• Step5: Answer
AsFigure15shows,weultimatelyreachedapageaboutAIresearch,obtaining"NaturalLanguage
Processing(NLP)"astheanswer,effectivelycompletingthetask.
23G.8 GameRecommendation
Thetargetedtasktobeexecutedis"IwanttoplayaPCgame. Helpmechooseone". Theactual
executionstepscanbesummarizedasfollows:
• Step1: TypeSearchBar"PCgamerecommendations"
• Step2: ClickSearchButton
• Step3: Answer
As Figure 16 shows, we ultimately reached a page of searching results of games, obtaining a
recommendationastheanswer,effectivelycompletingthetask.
G.9 PlayingVideo
Thetargetedtasktobeexecutedis"SearchandtellmeahotareainAIresearch".Theactualexecution
stepscanbesummarizedasfollows:
• Step1: TypeSearchBar"funnyvideos"
• Step2: ClickSearchButton
• Step3: ClickALinktoavedio
• Step4: Answer
AsFigure17shows,weultimatelyreachedapageplayingafunnyvideo,effectivelycompletingthe
task.
G.10 OnlineShoppingAssistancewithPop-UpInterruption
Thetargetedtasktobeexecutedis"Findandselectahighlyratedtoaster". Theactualexecutionsteps
canbesummarizedasfollows:
• Step1: TypeSearchBar"besttoaster2024"
• Step2: ClickSearchButton
• Step3: Clickalinkfromthesearchresultsleadingtoanonlineshoppingsite(Encountera
pop-upaskingtosubscribetothenewsletter.)
• Step4: Scrolldown,buttheinteractionisblockedbythepop-up
• Step5: Answer
AsFigure18shows,wedonotreachtheintendedproductselection. Thepresenceofanunexpected
pop-upinterruptsthetaskexecution,demonstratingthesystem’slimitationinhandlingunexpected
graphicalelementsandpop-ups. Thisoutcomeunderscorestheneedforenhancedcapabilitiesin
graphicalrecognitionandinteractionhandling,ensuringsmoothernavigationandtaskcompletionon
webpageswithcomplexelements.
G.11 KnowledgeQuerywithHallucination
Thetargetedtasktobeexecutedis"TellmesomebasicinfoaboutNLP". Theactualexecutionsteps
canbesummarizedasfollows:
• Step1: Answer
AsFigure19shows, thiscaseisaclassicexampleofthehallucinationfallacy, wherethesystem
respondeddirectlywithoutgoingthroughthewebpage,andtheresponsecamefromthehallucination
ratherthanthewebpageinformation
24G.12 TechnologicalBreakthroughSummarywithmisinterpretation
Thetargetedtasktobeexecutedis"Summarizearecenttechnologicalbreakthroughinrenewable
energy". Theactualexecutionstepscanbesummarizedasfollows:
• Step1: TypeSearchBar"latesttechnologicalbreakthroughinrenewableenergy2024"
• Step2: ClickSearchButton
• Step3: Clickalinkinsearchresults(Thesystemselectsalinktoageneraloverviewof
renewableenergytechnologiesinsteadofaspecificarticleonrecentbreakthroughs.)
• Step4: Scrolldown
• Step5: Answer
As Figure 20 shows, we do not reach the intended outcome. Instead of summarizing a recent
technologicalbreakthrough,thesystemprovidesageneralizedoverviewofrenewableenergy. This
outcome highlights a misinterpretation of task context, demonstrating the system’s challenge in
distinguishingbetweengeneralinformationandspecific,recentdevelopments.
G.13 MapQuerywithPoorGraphicalRecognition
Thetargetedtasktobeexecutedis"WhereisBeijingrelativetoShanghaiaccordingtothemap". The
actualexecutionstepscanbesummarizedasfollows:
• Step1: TypeSearchBar"Beijing"
• Step2: ClickSearchButton
• Step3: Answer
AsFigure21shows,weultimatelyreachedapagedisplayingadescriptionofBeijingandtheBeijing
map, obtaining "Northside" as the answer. The answer is to some extent too simple. This case
illustrates two minor flaws in our system: one is that it has a slight lack of understanding of the
graphicalinterface,andtheotheristhatitsometimeshallucinates,andtheanswersitgetsarenot
alwaysfromwebinformation.
Figure9: WeatherReport
25Figure10: ShoppingAdvice
Figure11: SearchingArticle
26Figure12: Searchingtools
Figure13: KnowledgeQuery
27Figure14: FindingPictures
Figure15: FindingResearch
28Figure16: GameRecommendation
Figure17: PlayingVideo
29Figure18: OnlineShoppingAssistancewithPop-UpInterruption
Figure19: KnowledgeQuerywithHallucination
30Figure20: TechnologicalBreakthroughSummarywithmisinterpretation
Figure21: MapQuerywithPoorGraphicalRecognition
31