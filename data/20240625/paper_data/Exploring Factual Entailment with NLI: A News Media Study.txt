Exploring Factual Entailment with NLI: A News Media Study
GuyMor-Lan EffiLevi
HebrewUniversityofJerusalem HebrewUniversityofJerusalem
guy.mor@mail.huji.ac.il efle@cs.huji.ac.il
Abstract 2020),whichhasbeenusedfordecadesforevalu-
atingnaturallanguageunderstandingcapabilities
Weexploretherelationshipbetweenfactuality (Poliak,2020). NLIistraditionallyformulatedasa
andNaturalLanguageInference(NLI)byin-
categoricalclassificationtaskbetweenapremisep
troducingFactRel–anovelannotationscheme
andahypothesish,wherepcaneithercontradict,
that models factual rather than textual entail-
entail or be neutral with respect to h. Large NLI
ment, and use it to annotate a dataset of nat-
datasetssuchasSNLIandMNLI(Bowmanetal.,
urallyoccurringsentencesfromnewsarticles.
Ouranalysisshowsthat84%offactuallysup- 2015; Williams et al., 2018) have become highly
portingpairsand63%offactuallyundermining popular,leadingNLItobeadaptedtovarioususes
pairsdonotamounttoNLIentailmentorcon- such as zero-shot classification (Yin et al., 2019)
tradiction,respectively,suggestingthatfactual and semantic similarity (Reimers and Gurevych,
relationshipsaremoreaptforanalyzingmedia
2019). Infactverification,NLIisusedtoevaluate
discourse. Weexperimentwithmodelsforpair-
therelationsbetweenacandidatefactandtrusted
wiseclassificationonthenewdataset,andfind
piecesofevidence(Zengetal.,2021).
that in some cases, generating synthetic data
However, the adequacy of NLI for analyzing
withGPT-4onthebasisoftheannotateddataset
can improve performance. Surprisingly, few- factualrelationshipsinnewsmediaishinderedby
shotlearningwithGPT-4yieldsstrongresults twoprimaryreasons,relatingtothenatureofthe
onparwithmediumLMs(DeBERTa)trained taskaswellastothecharacteristicsofcommonly
on the labelled dataset. We hypothesize that
usedNLIdatasets. First, largeNLIdatasetssuch
these results indicate the fundamental depen-
SNLI and MNLIdefine the pairwise relationship
denceofthistaskonbothworldknowledgeand
intermsofnecessityofmeaning(Bowmanetal.,
advancedreasoningabilities.
2015;Williamsetal.,2018). Thus,inMNLIanen-
tailmentisdefinedtobethecasewherebyahypoth-
1 Introduction
esis “is necessarily true or appropriate whenever
In recent years, the concept of factuality in news thepremiseistrue”,andsimilarlyacontradiction
media has garnered increasing attention. Studies iswhenthehypothesis“isnecessarilyfalseorinap-
increasingly examine the relation between facts - propriatewheneverthepremiseistrue”(Williams
as presented in news coverage - and phenomena etal.,2018). However,thesetypesofrelationships
suchaspoliticalpolarization,misinformationand may be too restrictive for the analysis of media
fakenews(RoyandGoldwasser,2020;Levy,2021; discourse,whereexplicitcontradictionsandentail-
Bakshyetal.,2015;Garimellaetal.,2021). Asa mentsarelikelytoberare,assuchdiscoursetends
result,theabilitytomodelfactualrelationsbetween takeplaceinthemarginsofplausibility.
claimsbecomesincreasinglyimportant. Thishas Secondly,textsinpopularNLIdatasetsconsider-
ledtoalineofworkonautomatedfact-checking, ablydifferfromnewstexts. WhilesentencesinNLI
whichinvolvestextualpipelinesfordetectingand datasetstendtobeshort,simple,highlygenericand
evaluatingfactualclaims(Zengetal.,2021). conveyasingleideaorstatement,mediasentences
In automatic fact-checking, fact verification is tendtobelonger,morecomplex,morespecificand
predominantlyaddressedviatheNaturalLanguage conveymultiplepiecesofinformation.
Inference(NLI)task,alsoknownasRecognizing AcommonfeatureofNLIdatasetssuchasRTE,
TextualEntailment(RTE)(Zengetal.,2021;Arana- SNLI and MNLI is that while premises are natu-
Cataniaetal.,2022;Nieetal.,2018;Satheetal., rallyoccurringtexts,thehypothesesarespecifically
4202
nuJ
42
]LC.sc[
1v24861.6042:viXrawrittentocorrespondtothecategories(Chatzikyr- bearingontheplausibilityofh,andthelikelihood
iakidisetal.,2017;Williamsetal.,2018). While ofhwouldnotchangeifpwasknowntobeeither
thismethodiseffectiveingeneratinglargeamounts trueorfalse.
of data, constructed hypotheses are likely to ex- While both NLI and FactRel encode a ternary
pressasimplerelationshiptothepremiseandthus entailmentrelationbetweenpairsofsentences,the
notresemblepairsofnaturallyoccurringsentences. factualrelationencodedbyFactRelisquitediffer-
Additionally, Chatzikyriakidisetal.(2017)notes ent from the one encoded by NLI. For example,
thatthesedatasetsfeaturestrictlylogicalrelation- considerthefollowingpairofsentences:
shipsandstressestheneedfordatasetscapturing
othersortsofinferentialrelationships. (1) p. “Youcan’trunafestivaloryoucan’trun
anightcluboralive-musicgigwithsocial
Inthiswork,wesetouttoexaminetherelation-
distancing,”Lordsaid.
ship between NLI and textual factuality. For this
purpose, we have developed a novel annotation h. Peter Marks, the CEO of Rekom,
scheme that expresses factual rather than textual Britain’slargestspecialistlate-nightbar
entailment, encoding each pair of sentences with operator, told Insider the company’s
the relation of factual support, factual undermin- venuesweresettoopenonJune21“with-
ing, or neither. We have annotated a new dataset outCOVIDmeasures.”
of naturally occurring sentence pairs from news
The above example exhibits a relation of factual
media using both our factual entailment scheme
SUPPORT whileitsNLIlabelisNEUTRAL.The
and NLI, enabling a comparison of the schemes
hypothesismatchesthepremiseandexemplifiesit,
on news media. We also check the ability of re-
butthepremisedoesnotnecessitatethehypothesis.
cent generative LLMs (GPT-4) to generate such
A parallel example can be observed in the fol-
pairscorrectly. Weendwithasetofexperiments
lowingpairofsentences:
thatdemonstratetheabilitytolearnthefactualen-
tailment task using fine-tuned models as well as
(2) p. FILE–InthisApril12,2021filephoto,
generativeLLMs,anddrawconclusionsregarding
peoplequeueoutsideaHermesstorein
thetask’srelationtorealworldknowledgeincom-
MayfairinLondon.
parison to NLI. Overall, we analyze differences
betweenNLIandfactualentailmentintheirscope, h. Salesofluxuryapparel,jewelry,leather
relevance to news text and dependence on world goods and beauty products plunged to
knowledge, and show potential for new ways to 217 billion euros in the pandemic year
modelfactualrelations. of2020,from281billioneurosin2019,
sheddingsixyearsofgrowth.
2 FactualEntailment
ThisexampleexhibitsarelationoffactualUNDER-
MININGwhileitsNLIlabelisNEUTRAL.Thereis
For the purpose of exploring the relationship be-
factualtensionbetweenthepremiseandhypothesis,
tweenfactualrelationsandtextualentailment,we
asthepremisecanbeconsideredacounter-example
havedevelopedFactRel,anovelannotationscheme
encodingthefactualentailment betweenpairsof tothehypothesis,butitdoesnotnecessitatethehy-
pothesis’falsity.
sentences. SimilarlytoNLI,FactRelisa3-category
pairwiseclassificationtask. Givenapremisepand There are, however, cases in which the two
a hypothesis h, p can either factually support h schemes converge to the same relation. For ex-
(SUPPORT),factuallyundermineh(UNDERMIN- ample,
ING), or be factually neutral w.r.t h (NEUTRAL).
(3) p. Womanaccusedofattemptedmurderaf-
pissaidtofactuallysupporthwhenpbeingtrue
terdrivingintoPresidentTrumpsupport-
wouldmakehmoreplausibleorlikelytobetrue,
ersinSouthernCalifornia
comparedtoasituationinwhichthetruthvalueof
p is unknown. p is said to factually undermine h h. The vast majority of those cases tallied
whenpbeingtruewouldmakehlessplausibleor byWeilinvolvedmotoristswhoraninto
likelytobetrue,comparedtoasituationinwhich those demonstrating for causes aligned
thetruthvalueofpisunknown. Finally,pissaidto withtheBlackLivesMattermovement,
befactuallyneutralw.r.ttopwhenp’struthhasno Weilsaid.Item Agreement% Kappa Factual/NLI Contra. Entail. Neutral
FactualEntailment 95.2% 0.93 Support 0 48 245
NLI 95.2% 0.85 Undermining 67 0 113
Neutral 0 0 1130
Table 1: Intercoder reliability for annotations of NLI
andfactualentailment,showingrawagreementrateand Table2: Cross-tabulationbetweenNLIandFactualEn-
Cohen’sKappa. tailment,coredataset.
Factual/NLI Contra. Entail. Neutral
ThisexampleisfactuallyNEUTRAL,anditsNLI
Support 5 155 67
labelisNEUTRALaswell.
Undermining 174 1 2
Neutral 17 10 69
3 Dataset
Table3: Cross-tabulationbetweenNLIandFactualEn-
3.1 Construction
tailment,MNLIsubset.
The core dataset comprises 1,507 sentence pairs
sampled from 211 news articles appearing in di-
non-neutralfactualrelationshipsaresignificantly
verseEnglish-languagedigitalnewsoutletsinthe
morecommoninnewsmediathannon-neutralNLI
period 2020-2022. Pairs were sampled from the
relationships. In terms of length, we observe a
samenewsarticleinordertoincreasethelikelihood
significant difference between FactRel and NLI
ofthepairshavinganon-neutralrelationship. The
datasets – the average number of tokens per sen-
sentencepairswereindependentlylabelledbytwo
tence in FactRel is 20.2, compared to 10.1 and
annotators–oneoftheauthorsandaresearchassis-
15.01intherespectivetrainingsplitsofSNLIand
tant–withasubsetannotatedbybothforcalculat-
MNLI.
inginter-coderreliability(Table1). Annotatorsare
Thedualannotationofthedatasetwithfactual
instructed to categorize only non-negligible rela-
entailment and NLI labels allows us to examine
tionsofsupportandunderminingassuch. Conflicts
therelationshipbetweenthetwo. Weexaminethe
wereresolvedbycommitteeconsultation.
correlationbetweenthelabelsutilizingCramér’sV
Thecoredatasetisaugmentedbytwoadditions.
associationmeasurefordiscretevariables. While
First,asubsetof500sentencepairsfromtheMNLI
factualcategoriesarestronglycorrelatedwiththe
datasetwasannotatedwithfactualentailment,for
categories in the MNLI subset (ϕ = 0.72), the
thepurposeofexaminingdifferencesbetweenthe c
correlationislowerinthecoredatasetofnewssen-
MNLIdatasetandtheproposeddataset. Secondly,
tencepairs(ϕ = 0.49). Inthecoredataset, 84%
asyntheticdatasetwasgeneratedusingGPT-4on c
offactuallysupportingpairsand63%offactually
the basis of the training set split from the core
underminingpairsdonotamounttoentailmentor
dataset. Eachsentencepairinthetrainingsetwas
contradiction,respectively(Table2). IntheMNLI
sent to GPT-4 accompanied by an explanation of
subset,thenumbersarerespectively32%and2%
thefactualrelationshiptask,theannotatedlabelfor
(Table3). Thisdiscrepancylikelyindicateshowin
thatpair,andthedefinitionofthelabel. GPT-4was
real news discourse, factual relations are increas-
askedtogenerate10diverseexamplespossessing
inglyuntangledfromsemanticnecessity,compared
thesamelabel,modelledonthesentencepairfrom
todatasetssuchasMNLIwhichcontainsentences
theannotateddataset(seeappendixAforprompts).
specifically written to form relations of semantic
Thus,thesynthesizedaddendumis10timeslarger
necessity.
than the core training set and consists of 12,050
pairs. A subset of 500 GPT generated pairs was
4 Experiments
randomlysampledformanualvalidation,showing
thatin98.4% ofthepairsthemanuallabelling is Wetacklethetaskoffactualentailmentwithseveral
consistentwithGPT. typesandsizesoflanguagemodels.
Baselinemodel. Asasimplebaseline,weem-
3.2 Analysis
bed the premise and hypothesis using the UAE-
Inthecoredataset,93%ofsentencepairsareNLI- Large-V1encoder(LiandLi,2023)andcalculate
neutral, whereas a smaller share of 70% are fac- thecosinesimilaritybetweenthem,onwhichwe
tually neutral (see Table 2). This indicates that trainadecisiontreewithamaxdepthof10.Model F1 ACC Model F1 ACC
MAC MAC
Baseline(Cosinesimilarity) 0.38 0.61 Baseline(Cosinesimilarity) 0.44 0.63
StockNLI(notraining) 0.54 0.72 Fine-tunedGPT-3.5 0.63 0.77
GPT-4zero-shot 0.65 0.80 DeBERTa-NLI/Focalloss 0.70 0.79
GPT-43-shot 0.70 0.81
Table5: Toptrainedmodels,augmentedtrainingset
Fine-tunedGPT-3.5 0.69 0.78
DeBERTa-NLI/Focalloss 0.68 0.8
5 Conclusion
Table4: Topperformingmodels,coretrainingset
Inthispaperweexploredtherelationshipbetween
NLI and factual relations. For this purpose, we
designedanewannotationschemeforfactualen-
ZeroshotandFewShot(notraining). Weuse
tailment, FactRel; examined it in comparison to
two models in a zero-shot setting. First, we uti-
NLIonasampleofannotatedpairsfromnewscov-
lizeastate-of-the-artNLImodeltrainedonmany
erage; and examined the performance of various
NLIdatasets(Laureretal.,2022). TheNLImodel,
modelsonthetask. Wehaveshownthatfactualen-
basedonDeBERTaV3large(Heetal.,2021),was
tailmentrelationsaresignificantlymorecommon
usedasiftheNLIcategoriesareequivalenttoFac-
innewsarticlesincomparisontosemanticentail-
tRel categories (e.g., CONTRADICTION equals
ment, thus underlining the shortcomings of NLI
UNDERMINING).Second,weutilizeGPT-4ina
whenappliedtonaturallyoccurringtext.
zero-shotsettingprovidedonlywithadescription
WehavealsoshownthatGPT-4performsbetter
ofthetaskandthecategories. Weadditionalyuse
in a few-shot setting than smaller models trained
GPT-4 in a 3-shot setting, adding three example
ontheentiretrainingset. Moreover,GPT-4’sper-
pairs,oneforeachcategory.
formanceeveninazero-shotsettingiscompetitive
with other models. The success of these LLMs,
Trained Models. We fine-tune several en-
even with significantly less data, can give us in-
coder models: RoBERTa-base (Liu et al., 2019),
sightonthechallengeinvolvedintheFactReltask
DeBERTa V3 large (He et al., 2021), and De-
andhowitdiffersfromNLI.
BERTa V3 SOTA NLI checkpoint (Laurer et al.,
NLIisafundamentallysemantictask,asdeter-
2022). Training variants included training with
mining whether p entails or contradicts h hinges
class weights and utilizing focal loss. We also
on understanding the meaning of the words and
fine-tune GPT-3.5 using OpenAI’s API with the
conceptsemployedinboth. Thus,ifpsemantically
recommendedsettings. Allthemodelsweretested
entailsh,thenhitselfmustbeincludedeitherex-
usingtwotypesoftrainingsets–thecoretraining
plicitly or implicitly in p itself. The relations are
set, and the augmented set with GPT-4 synthetic
thereforetobefoundinthemeaningofthewords.
pairs added. Full technical details of the training
Modellingfactualrelationships,ontheotherhand,
setuparelaidoutinappendixB.
also requires asignificant amount of background
Macro-F1 results on the validation set for the knowledge on the referents of the words, a de-
baselinemodel, thestockNLImodelandthetop tailed world model, and nuanced reasoning abil-
performingmodelsarereportedinTable4(seeap- ities. Thus, in order to identify that the premise
pendix C for full results). Table 5 examines the “TwitterhaslockedTrump’saccountfor12hours,
effect of adding synthetic data to the training set. and required the removal of the tweets” supports
Overall,theresultsshowthatwhilethetaskislearn- thehypothesis“FacebooklockedTrump’saccount
able,itisnoteasyevenforlargepre-trainedmodels. for 24 hours following two policy violations”, it
GPT-4performssurprisinglywellinbothzero-shot is required to not only understand the words and
and 3-shot settings, with GPT-4 3-shot being the concepts,buttoalsobeabletoinferwhyasocial
most performant model, matching the Macro-F1 networkmightlockone’saccount,andwhysuch
of finetuned DeBERTa with slightly better accu- actions on two social networks are likely to co-
racy. Theinclusionofsyntheticdataenhancesthe occur. ItisthushypothesizedthatLLMsthathave
performanceofthebaselinemodelandDeBERTa- broadworldknowledge,andespeciallythosethat
NLI,butdecreasestheperformanceoffine-tuned excelatreasoningsuchasGPT-4,arewellplaced
GPT-3.5. for this task, and their world knowledge and rea-soningcapabilitiescancompensatefordecreased Kiran Garimella, Tim Smith, Rebecca Weiss, and
exposuretotrainingdata. RobertWest.2021. Politicalpolarizationinonline
news consumption. In Proceedings of the Interna-
Finally, the addition of synthesized data im-
tionalAAAIConferenceonWebandSocialMedia,
proves performance of the top medium size LM,
volume15,pages152–162.
showingthatdatasynthesiscanbesuccessfullyem-
PengchengHe,JianfengGao,andWeizhuChen.2021.
ployedonthistask. However,thisimprovementis
Debertav3:Improvingdebertausingelectra-stylepre-
notconsistentforallconfigurations.
trainingwithgradient-disentangledembeddingshar-
ing.
Limitations
Moritz Laurer, Wouter van Atteveldt, Andreu
InlinewithNLIdatasets,FactRelusesdiscreteclas- Salleras Casas, and Kasper Welbers. 2022. Less
sification labels. While the dataset distinguishes annotating, more classifying – addressing the data
scarcityissueofsupervisedmachinelearningwith
betweensemanticentailmentandcontradictionand
deeptransferlearningandbert-nli. Preprint.
(mere) factual support and undermining, it does
notquantifytheamountofsupportorundermining. Ro’ee Levy. 2021. Social media, news consumption,
andpolarization: Evidencefromafieldexperiment.
However,themodellingoffactualrelationshipscan
Americaneconomicreview,111(3):831–870.
benefitfromaprobabilisticframework,whichwe
leavetofutureresearch. XianmingLiandJingLi.2023. Angle-optimizedtext
embeddings.
Acknowledgements
YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
This work was supported by the Israel Science
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Foundation(Grantno. 2501/22). WethankHagar Roberta: A robustly optimized BERT pretraining
Kaminer for diligent research assistance as well approach. CoRR,abs/1907.11692.
asinsightfulcommentsandsuggestionsduringthe
Yixin Nie, Haonan Chen, and Mohit Bansal. 2018.
annotation process. We extend deep gratitude to
Combiningfactextractionandverificationwithneu-
Shaul R. Shenhav and Tamir Sheafer for their in- ralsemanticmatchingnetworks.
valuableguidance,supportandadvice.
AdamPoliak.2020. Asurveyonrecognizingtextual
entailmentasanNLPevaluation. InProceedingsof
theFirstWorkshoponEvaluationandComparison
References
ofNLPSystems,pages92–109,Online.Association
forComputationalLinguistics.
MiguelArana-Catania,ElenaKochkina,ArkaitzZubi-
aga, Maria Liakata, Robert Procter, and Yulan He. Nils Reimers and Iryna Gurevych. 2019. Sentence-
2022. Naturallanguageinferencewithself-attention BERT:SentenceembeddingsusingSiameseBERT-
forveracityassessmentofpandemicclaims. InPro- networks. InProceedingsofthe2019Conferenceon
ceedingsofthe2022ConferenceoftheNorthAmer- EmpiricalMethodsinNaturalLanguageProcessing
icanChapteroftheAssociationforComputational andthe9thInternationalJointConferenceonNatu-
Linguistics: HumanLanguageTechnologies,pages ralLanguageProcessing(EMNLP-IJCNLP),pages
1496–1511, Seattle, United States. Association for 3982–3992,HongKong,China.AssociationforCom-
ComputationalLinguistics. putationalLinguistics.
EytanBakshy,SolomonMessing,andLadaAAdamic. Shamik Roy and Dan Goldwasser. 2020. Weakly su-
2015. Exposure to ideologically diverse news and pervised learning of nuanced frames for analyzing
opinion on facebook. Science, 348(6239):1130– polarization in news media. In Proceedings of the
1132. 2020ConferenceonEmpiricalMethodsinNatural
LanguageProcessing(EMNLP),pages7698–7716,
SamuelR.Bowman,GaborAngeli,ChristopherPotts,
Online.AssociationforComputationalLinguistics.
and Christopher D. Manning. 2015. A large anno-
tatedcorpusforlearningnaturallanguageinference. AalokSathe,SalarAther,TuanManhLe,NathanPerry,
In Proceedings of the 2015 Conference on Empiri- andJoonsukPark.2020. Automatedfact-checking
calMethodsinNaturalLanguageProcessing,pages of claims from Wikipedia. In Proceedings of the
632–642,Lisbon,Portugal.AssociationforCompu- TwelfthLanguageResourcesandEvaluationConfer-
tationalLinguistics. ence,pages6874–6882,Marseille,France.European
LanguageResourcesAssociation.
StergiosChatzikyriakidis,RobinCooper,SimonDob-
nik, and Staffan Larsson. 2017. An overview of AdinaWilliams,NikitaNangia,andSamuelBowman.
naturallanguageinferencedatacollection: Theway 2018. A broad-coverage challenge corpus for sen-
forward? InProceedingsoftheComputingNatural tenceunderstandingthroughinference. InProceed-
LanguageInferenceWorkshop. ingsofthe2018ConferenceoftheNorthAmericanChapter of the Association for Computational Lin- A SyntheticDataset
guistics: Human Language Technologies, Volume
1 (Long Papers), pages 1112–1122, New Orleans, Thesyntheticcomponentwascreatedbygenerating
Louisiana.AssociationforComputationalLinguis- 10syntheticexamplesforeachannotatedsample
tics.
inthetrainingset,usingGPT-4.
WenpengYin,JamaalHay,andDanRoth.2019. Bench- Thefollowingsystempromptwasused:
markingzero-shottextclassification: Datasets,eval-
uationandentailmentapproach. InProceedingsof
the2019ConferenceonEmpiricalMethodsinNatu-
SYSTEMPROMPT
ralLanguageProcessingandthe9thInternational
JointConferenceonNaturalLanguageProcessing
(EMNLP-IJCNLP),pages3914–3923,HongKong, Youareanadvancedsyntheticdatasetgenera-
China.AssociationforComputationalLinguistics.
tor.
XiaZeng,AmaniSAbumansour,andArkaitzZubiaga. For factual support samples, the following
2021. Automated fact-checking: A survey. Lan-
promptwasused:
guageandLinguisticsCompass,15(10):e12438.
FACTUALSUPPORTPROMPT
’Factual support’ is a relationship between
sentences A and B whereby A being true
increasesthelikelihoodofBbeingtrue.
Forexample:
A:{premise}
B:{hypothesis}
Generate 10 more pairs of sentences
with a factual support relationship. The sen-
tences should be diverse and reflect the type
ofreallifesentencesnormallyfoundinnews
discourse. Thesentencesshouldresemblethe
providedexamplebutshouldalsovary. Like
theprovidedexample,thegeneratedsamples
should not be overly simple. Each sentence
pairshouldbeseparatedwithtwonewlines.
Within each pair, the sentences should
be separated with a single newline. Each
sentenceshouldstartwith’A:’or’B:’. Apart
fromthatdonotgenerateanyotheroutput.
Forfactualunderminingsamples,thefollowing
promptwasused:
FACTUALUNDERMININGPROMPT
’Factual undermining’ is a relationship
betweensentencesAandBwherebyAbeing
truedecreasesthelikelihoodofBbeingtrue.Forexample: Forfactuallyneutralsamples,thethefollowing
A:{premise} promptwasused:
B:{hypothesis}
Generate 10 more pairs of sentences FACTUALNEUTRALITYPROMPT
withafactualunderminingrelationship. The
sentences should be diverse and reflect the
’Factualneutrality’isarelationshipbetween
typeofreallifesentencesnormallyfoundin
sentencesAandBwherebyhasnoeffecton
newsdiscourse. Thesentencesshouldresem-
thelikelihoodofBbeingtrue.
bletheprovidedexamplebutshouldalsovary.
Like the provided example, the generated
Forexample:
samples should not be overly simple. Each
A:{premise}
sentence pair should be separated with two
B:{hypothesis}
newlines.
Generate 10 more pairs of sentences
Within each pair, the sentences should
withafactualneutralityrelationship. Thesen-
be separated with a single newline. Each
tences should be diverse and reflect the type
sentenceshouldstartwith’A:’or’B:’. Apart
ofreallifesentencesnormallyfoundinnews
fromthatdonotgenerateanyotheroutput.
discourse. Thesentencesshouldresemblethe
providedexamplebutshouldalsovary. Like
theprovidedexample,thegeneratedsamples
should not be overly simple. Each sentence
pairshouldbeseparatedwithtwonewlines.
Within each pair, the sentences should
be separated with a single newline. Each
sentenceshouldstartwith’A:’or’B:’. Apart
fromthatdonotgenerateanyotheroutput.
B TrainingSetup
Thecoredatasetwasrandomlysplittoatrainingset
(80%)andavalidationset(20%). Thecoretraining
setcomprises1205samples,andthevalidationset
comprises 302 samples. With the addition of the
synthetically generated data and 500 pairs from
the MNLI dataset, the training dataset comprises
12,249sentencepairs.
Training was performed on an Nvidia A100
GPU, using Huggingface Transformers (v4.34.0)
and PyTorch (v2.0.1). Fine-tuning was for 6
epochs,usingearlystoppingonthevalidationloss.
Best performing checkpoint on the validation set
waskept. Otherwise,trainingusedthedefaulthug-
gingfacehyperparameters. GPT-3.5wasfinetuned
viatheOpenAIAPIwiththerecommendeddefault
settings.
C FullExperimentalResultsTable6: Modelresults. Eachentryindicatesasinglerun.
Gradient Model Data Method F1 ACC
MAC
Training
V DeBERTa-large-NLI Core+Synthetic FocalLoss 0.7 0.79
V DeBERTa-large-NLI Core+Synthetic ClassWeights 0.65 0.77
V DeBERTa-large-NLI Core+Synthetic Regular 0.61 0.74
V DeBERTa-large-V3 Core+Synthetic FocalLoss 0.37 0.58
V DeBERTa-large-V3 Core+Synthetic ClassWeights 0.61 0.75
V DeBERTa-large-V3 Core+Synthetic Regular 0.28 0.71
V RoBERTa-base Core+Synthetic FocalLoss 0.57 0.72
V RoBERTa-base Core+Synthetic ClassWeights 0.6 0.73
V RoBERTa-base Core+Synthetic Regular 0.59 0.74
V DeBERTa-large-NLI Core FocalLoss 0.68 0.8
V DeBERTa-large-NLI Core ClassWeights 0.66 0.75
V DeBERTa-large-NLI Core Regular 0.67 0.78
V DeBERTa-large-V3 Core FocalLoss 0.61 0.75
V DeBERTa-large-V3 Core ClassWeights 0.47 0.56
V DeBERTa-large-V3 Core Regular 0.54 0.71
V RoBERTa-base Core FocalLoss 0.4 0.7
V RoBERTa-base Core ClassWeights 0.45 0.61
V RoBERTa-base Core Regular 0.41 0.68
X GPT-4 None Zero-Shot 0.65 0.8
X GPT-4 3-shot Few-shot 0.7 0.81
V GPT-3.5 Core Regular 0.69 0.78
V GPT-3.5 Core+Synthetic Regular 0.63 0.77
X DeBERTa-large-NLI None Notraining 0.54 0.72
X Baseline Core Cos. Sim. +DecisionTree 0.38 0.61
X Baseline Core+Synthetic Cos. Sim. +DecisionTree 0.44 0.63D Zero-Shotand3-shotPrompts For 3-shot classification, the same system
promptwasused,inconjunctionwiththefollowing
Forzero-shotclassificationwithGPT-4,thefollow-
instructionprompt:
ingsystempromptwasused:
3-SHOTCLASSIFICATIONPROMPT
SYSTEMPROMPT
You will classify the factual relationship
Youareanadvancedclassifier.
between sentences A and B. The factual
Andthefollowinginstructionprompt: relationship can be either ’SUPPORTS’,
’UNDERMINES’, or ’NEUTRAL’. ’SUP-
PORTS’ means that A factually supports B
ZERO-SHOT CLASSIFICATION - if A is true, B is more plausible or likely
PROMPT to be true. ’UNDERMINES’ means that A
factually undermines B - if A is true, then
You will classify the factual relationship B is less plausible or less likely to be true.
between sentences A and B. The factual ’NEUTRAL’ means that the truthness of A
relationship can be either ’SUPPORTS’, has no implication on the likelihood of B
’UNDERMINES’, or ’NEUTRAL’. ’SUP- beingtrue.
PORTS’ means that A factually supports B
- if A is true, B is more plausible or likely
to be true. ’UNDERMINES’ means that A Here’sanexampleoftwosentenceswitha
factually undermines B - if A is true, then ’NEUTRAL’relationship:
B is less plausible or less likely to be true. A: And with us having so much money
’NEUTRAL’ means that the truthness of A investedintoourhoneymoon,wehadnoother
has no implication on the likelihood of B choicebuttoboardtheship.
beingtrue. B: The memory that will stick with her, she
said,iswhentheshipstoppedinSriLankato
Hereisapairofsentences: refuel.
A:{premise}
B:{hypothesis}
Herearetwosentenceswitha’SUPPORTS’
Classify their factual relation. Respond relationship:
with ’SUPPORTS’, ’UNDERMINES’ or A:Industryexpertssaytheincreaseinmilking
’NEUTRAL’,andnothingelse. cowshascomefromexpansionoflongstand-
ingdairies,thelaunchofmilkingoperations
at existing farms that have diversified, and
alsofromtherelocationofdairyoperationsto
SouthDakotafromstatessuchasCalifornia.
B: As in other agricultural industries, dairy
farmersareincreasinglyusinggenetics,data
monitoring,technologyandroboticstoboost
the production of each individual animal
while implementing an economies-of-scale
approachtothesizeoftheirfarms,raisingthe
efficiencyandprofitabilityoftheiroperations.Andherearetwosentenceswithan’UNDER-
MINES’relationship:
A: Guinea had announced late Wednesday
that it was canceling its participation to
protectthehealthofitsathletes.
B:NorthKoreaistheonlycountrytopullout
oftheTokyoOlympics, alsocitingconcerns
relatedtoCOVID-19.
Hereisanewpairofsentences:
A:{premise}
B:{hypothesis}
Classify their factual relation. Respond
with ’SUPPORTS’, ’UNDERMINES’ or
’NEUTRAL’,andnothingelse.