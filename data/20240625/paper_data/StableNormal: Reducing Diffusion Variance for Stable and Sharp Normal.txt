StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal
CHONGJIEYE∗ andLINGTENGQIU∗,TheChineseUniversityofHongkong,Shenzhen,China
XIAODONGGU,AlibabaGroup,China
QIZUO,AlibabaGroup,China
YUSHUANGWU,TheChineseUniversityofHongkong,Shenzhen,China
ZILONGDONG,AlibabaGroup,China
LIEFENGBO,AlibabaGroup,China
YULIANGXIU†,MaxPlanckInstituteforIntelligentSystems,Germany
XIAOGUANGHAN†,TheChineseUniversityofHongkong,Shenzhen,China
I. Monocular Surface Recon
II. Multi-view Surface Recon
III. Normal Enhancement
Stable & Sharp Normal Estimation Real-World Applications
Fig.1. WeproposeStableNormal,whichtailorsthediffusionpriorsformonocularnormalestimation.Unlikepriordiffusion-basedworks,wefocus
onenhancingestimationstabilitybyreducingtheinherentstochasticityofdiffusionmodels(i.e.,StableDiffusion[Rombachetal.2021]).Thisenables
“Stable-and-Sharp”normalestimation,whichoutperformsmultiplebaselines(tryCompare),andimprovesvariousreal-worldapplications(tryDemo).
Thisworkaddressesthechallengeofhigh-qualitysurfacenormalestima- previousattemptsstillstrugglewithstochasticinference,conflictingwith
tionfrommonocularcoloredinputs(i.e.,imagesandvideos),afieldwhich thedeterministicnatureoftheImage2Normaltask,andcostlyensembling
hasrecentlybeenrevolutionizedbyrepurposingdiffusionpriors.However, step,whichslowsdowntheestimationprocess.Ourmethod,StableNormal,
mitigatesthestochasticityofthediffusionprocessbyreducinginference
∗EqualContribution
variance,thusproducing“Stable-and-Sharp”normalestimateswithoutany
†CorrespondingAuthor
additionalensemblingprocess.StableNormalworksrobustlyunderchal-
Authors’ addresses: Chongjie Ye, chongjieye@link.cuhk.edu.cn; Lingteng Qiu, lengingimagingconditions,suchasextremelighting,blurring,andlow
220019047@link.cuhk.edu.cn,TheChineseUniversityofHongkong,Shenzhen,China; quality.Itisalsorobustagainsttransparentandreflectivesurfaces,aswellas
XiaodongGu,dadong.gxd@alibaba-inc.com,AlibabaGroup,China;QiZuo,muyuan. clutteredsceneswithnumerousobjects.Specifically,StableNormalemploys
zq@alibaba-inc.com,AlibabaGroup,China;YushuangWu,yushuangwu@link.cuhk.
acoarse-to-finestrategy,whichstartswithaone-stepnormalestimator
edu.cn,TheChineseUniversityofHongkong,Shenzhen,China;ZilongDong,list.dzl@
alibaba-inc.com,AlibabaGroup,China;LiefengBo,liefeng.bo@alibaba-inc.com,Al- (YOSO)toderiveaninitialnormalguess,thatisrelativelycoarsebutre-
ibabaGroup,China;YuliangXiu,yuliang.xiu@tuebingen.mpg.de,MaxPlanckInstitute liable,thenfollowedbyasemantic-guidedrefinementprocess(SG-DRN)
forIntelligentSystems,Germany;XiaoguangHan,hanxiaoguang@cuhk.edu.cn,The thatrefinesthenormalstorecovergeometricdetails.Theeffectivenessof
ChineseUniversityofHongkong,Shenzhen,China.
4202
nuJ
42
]VC.sc[
1v46861.6042:viXra2 • Ye,etal.
StableNormalisdemonstratedthroughcompetitiveperformanceinstandard
datasetssuchasDIODE-indoor,iBims,ScannetV2andNYUv2,andalso
invariousdownstreamtasks,suchassurfacereconstructionandnormal
enhancement.TheseresultsevidencethatStableNormalretainsboththe
“stability” and“sharpness” foraccuratenormalestimation.StableNormal
representsababyattempttorepurposediffusionpriorsfordeterministices-
timation.Todemocratizethis,codeandmodelshavebeenpubliclyavailable Input GenPercept GeoWizard Ours
inhf.co/Stable-X. [Xuetal.2024] [Fuetal.2024b]
CCSConcepts:•Computingmethodologies→Reconstruction.
Fig.2. ComparativeAnalysisofNormalEstimators:“Stability”vs.
AdditionalKeyWordsandPhrases:MonocularNormalEstimation,Diffusion “Sharpness”.One-stepGenPerceptcompromisesthehigh-frequencyde-
Model,SurfaceReconstruction tailsandproducesoverly-smoothnormalsforobjectsonthetable,while
GeoWizardproducesseeminglysharpnormals,butneithercorrectnorsta-
1 INTRODUCTION ble.Ourmethodwellbalancesstabilityandsharpness.The redboxes
highlightthevisualdifferencementionedabove.
Normalmap,asa2.5Drepresentation,bridges2Dand3Dworlds.In
3Dmodeling,objectsurfacesaretypicallyrepresentedbypolygons.
Normalmapsaddillusorysurfacedetailstothesepolygons,which
enhancestheirrealism.In2Ddomain,ifaccuratelyestimatedfrom
in-the-wildpixels,taskssuchasrelightingorintrinsicdecompo-
sitionbecomefeasible,openingthedoortoabroadspectrumof
applications.StableNormalaimstoestimateaccurate&sharpsurface
normalsfrommonocularcoloredinputs(i.e.,images,videos).
Intheeraofdeeplearning,this“Image2Normal”taskhasbeen
wellexploredinalineofworks[Bansaletal.2016a;Eftekharetal.
2021; Eigen and Fergus 2015a; Fouhey et al. 2013a; Ranftl et al.
2021a;Wangetal.2015a].Recently,advancesindiffusion-based
imagegenerator,oftentrainedonlarge-scaledatasets[Schuhmann
et al. 2022], have shifted the vision community’s focus towards
repurposingthediffusionpriors[Rombachetal.2022a]toestimate
the geometric or intrinsic cues, such as depth [Ke et al. 2024a],
normal[Fuetal.2024b],andmaterials[Kocsisetal.2024]. Fig.3. High-variancenormalestimations.Weshowmultiplesamplesfor
Theseeffortshaveyielded“sharp-looking”results(Fig.3).How- asinglesceneandvisualizethemeanandvarianceofthepredictednormals.
ever, human eyes lack the sensitivity to accurately perceive the Foreachsample,whilethenormalmapsexhibitsharpdetails,thereishigh
varianceinareaswithhigh-frequencycontent.Thishighvarianceinsharp
normalmaps.Despiteproducing“sharp-looking”normals,temporal
inconsistencyexists1,andtheresults,evenafterbeingensembled, regionsmakestheinferencelessreliable.
stilldeviatesignificantlyfromground-truthnormals(Fig.3).Simply
put,theseresultsare“sharp” butneither“correct” nor“stable”.
GenPercept[Xuetal.2024],couldcompromisetherecoveryofhigh-
Weattributethistotwofactors:1)unstableimagingconditions,
frequencydetailsandresultinoverly-smoothnormals(SeeFig.2).
suchasextremelighting,dramaticcameramovement,motionblur,
Thus,findingabalancebetween“stability”vs.“sharpness”isneeded.
andlow-qualityimages.2)inductivebiasofthediffusionprocess
SowepresentStableNormaltotacklethistrade-off.Itdemon-
— stochasticity. Such stochasticity contradicts the nature of the
stratesthat,areliableinitialization,coupledwithastablerefine-
estimationprocess,whichshouldbeasdeterministicaspossible.
ment,isessentialtoproducesharpandstablenormalestimates.
Therefore,acrucialquestionisraised:
Ourapproachfollowsthecoarse-to-finescheme:1)one-stepnormal
How can we mitigate the inherent stochasticity of the diffusion estimation(Section3.3)forreliableinitialization,and2)semantic-
processfordeterministicestimation? guideddiffusionrefinement(Section3.4)toprogressivelysharpen
thenormalmapsinasemantic-awaredirection.
Answeringthisquestioninthenormaldomainismoreurgent
Specifically,aShrinkageRegularizerisintroducedtotrainthe
thanindepthdomain.Sincemonoculardepthestimationtypically
one-step normal estimator, which reduces the training variance
estimatesaffine-invariantdepth(i.e.,depthvaluesuptoaglobal
by splitting the vanilla diffusion loss into generative and recon-
offsetandscale),whilesurfacenormalsarenotsubjecttoscaleand
structionterms.Thisone-stepestimator,namelyYOSO(You-Only-
translationambiguity.Thatistosay,givenasingleimage,thetask
Sample-Once),alreadyperformson-parwithcurrentstate-of-the-art
ofnormalestimation(one-to-onemapping),ismore“determinis-
DSINE[BaeandDavison2024],seeTable3.Additionally,Semantic-
tic”thandepthestimation(one-to-manymapping).However,elim-
GuidedDiffusionRefinementNetwork(SG-DRN)ispresentedto
inatingstochasticityfromthediffusionprocess,liketheone-step
enhancethestabilityofthediffusion-basedrefinementprocessby
1huggingface.co/docs/diffusers/main/en/using-diffusers/marigold_usage#frame-by- integratingDINOsemanticpriors.Suchpriorsdecreasesampling
frame-video-processing-with-temporal-consistency variancewhileenhancinglocaldetails,asshowninFig.6.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 3
WeevaluateStableNormalonDIODE-indoor,iBims,ScannetV2, inspiredbyvisualprompting[Baretal.2022],backgroundprompt-
andNYUv2datasets.Also,weshowhowourstrongnormalesti- ing[Baradadetal.2023]wasintroducedtoreducethedomaingap
matorimprovesvariousreconstructionscenarios(i.e.,object-level, betweensyntheticandrealdata,bysimplyplacingthesegmented
indoor-scene,andnormalintegration-based).Thesuperiorityof objectintoalearnedbackground“prompt”.Despitesteadyadvance-
StableNormalissubstantiatedbothqualitativelyandquantitatively. ments,regression-basednormalestimators,trainedonlimitedand
PleasecheckthevideoandFig.1toseehowrobustStableNormal constraineddata,continuetofacegeneralizationissuesandstruggle
performsinchallengingconditions,suchasextremelighting,blur- tocapturefine-grainedgeometricdetails.
ring,objecttransparency&reflections,orclusteredscenes.
ThemaincontributionsofStableNormalareasfollows: 2.2 Diffusion-basedMonocularNormalEstimation
• Wepinpointthecriticalissuewhydiffusionpriorscannot
Recently,thecomputervisioncommunityhaswitnessedthebloom
bedirectly(w/obellsandwhistles,e.g.post-ensembling)
ofdiffusion-basedText-to-Image(T2I)modelanditsextensions[Pee-
applied on “Image2Normal” task — the inherent conflict
blesandXie2022;Rombachetal.2021;Zhangetal.2023a].Several
betweenthe“stochastic”diffusionprocessand“deterministic”
workshaveexploredhowtoadaptthestrongpretrainedmodel,thus
requirementforgeometriccuesestimation.
repurposeitasgeometriccuesestimator[Fuetal.2024b;Jietal.
• Toaddressthisconflict,weproposeasimple-yet-effective
2023;Keetal.2024b;Liuetal.2023;Longetal.2023;Qiuetal.2024;
solution,namely“StableNormal”.Itjustifiesthatareliable
Zhaoetal.2023].Wonder3D[Longetal.2023]proposestomodelthe
initialization(YOSO),coupledwithastablerefinement(SG-
jointdistributionofcolorandnormaltoenhancetheirconsistency,
DRN),isessentialtoestimatesharpnormalssteadily.
whichhasbeenshowntoimprovethequalityofthefinal3Doutput.
• WeconductextensiveexperimentstoevaluateStableNor-
Richdreamer[Qiuetal.2024]concurrentlytrainsadepthandnormal
mal’s accuracy. It not only outperforms other baselines
diffusionmodelonthelarge-scaleLAION-2Bdataset[Schuhmann
byalargemargininhigh-qualityindoorbenchmarks(i.e.,
etal.2022],utilizingpredictionsfromtheoff-the-shelfnormaland
DIODE-indoor,iBims,andScannetV2),butalsofaraheadof
depthestimators[Lasingeretal.2019].Moreover,Geowizard[Fu
itspeers(i.e.,GeoWizard,DSINE)intermsofinferencesta-
etal.2024b]extendsWonder3Dbyaddingageometryswitcher
bilityatreal-worldscenarios,evenunderextremeconditions.
(indoor/outdoor/object)tosegregatethemulti-sourceddatadistri-
Thisstabilitybenefitsmanydownstreamtasks,seeFig.1.
butionofvariousscenesintodistinctsub-distributions.
2 RELATEDWORKS Althoughthesediffusion-basedapproachescancapture“sharp-
looking” surfacedetails,theseresultsactuallydeviatessignificantly
2.1 Regression-basedMonocularNormalEstimation
fromground-truthinnormalspace,owingtototheinherenthigh-
SurfacenormalestimationfrommonocularRGBinputshasbeen varianceofdiffusionprocess(seeFig.3).Thelargevarianceisfirst
extensivelystudied[Doetal.2020;EigenandFergus2015b;Fouhey introducedbyGaussianinitialization,whichispropagatedandam-
etal.2013b,2014;Huangetal.2019;Ladickýetal.2014;Liaoetal. plifiedintheentiremulti-stepdiffusionprocess(i.e.,signal-leak
2019;Qietal.2018,2022;Wangetal.2016,2020,2015b;Zhangetal. issue[Everaertetal.2024]).Infact,somepriorresearchhasex-
2019].Ingeneral,thepriorregression-basedmethodsconsistofa ploredthisissue,eitheremployinganaffine-invariantensembling
featureextractor,followedbyapredictionhead.Hoiemetal.[Hoiem strategyduringthepost-processingstage[Fuetal.2024b;Keetal.
etal.2005,2007]werethepioneersinframingthisclassictaskas 2024a],orcompletelydiscardingtheiterativemulti-stepgeneration
astatisticallearningproblem.Theoutputspacewasdiscretized, process,thusshiftingtowardsaone-stepperceptionproblem[Xu
andhandcraftedfeatureswereextractedtoclassifythenormals. etal.2024].
However,suchfeaturesaregenerallydesignedforspecificscenarios However, both strategies come with their own pitfalls: post-
andcannotgeneralizewelltounseenscenes. ensembling,whichappliestomultipleoutputs,iscomputationallyin-
Thisgeneralizationproblemwaslateraddressedbydeeplearning tensive.Theassumptionofaffineinvarianceoftenfailstogeneralize
techniquesinadata-drivenmanner[Bansaletal.2016b;Wangetal. acrossdifferenttypesofoutputs,likenormals.WhileGeoWizard[Fu
2015b].Morerecently,Omnidata-V2[Eftekharetal.2021],witha etal.2024b]exhibitssharperresultscomparedtoothertraditional
U-Netarchitecture[Ronnebergeretal.2015],istrainedonalarge- approaches,itdoesnotnotablyimprovequantitativeperformance,
scaledata(12M)capturedfromdiversescenesundervariouscamera suggestingthatdiffusion-basednormalestimatorsinducethedirec-
settings.Baeetal.[Baeetal.2021]proposetoestimatetheper-pixel tionaldeviationinnormalspace(seeFig.3).Furthermore,without
surfacenormalprobabilitydistribution,fromwhichtheexpected thepost-ensemblingstep,thediffusion-basedestimatorstendto
angularerrorcanbeinferredtoquantifythealeatoricuncertainty. produceoutputswithlargevariance(seeFig.3),highlightingits
ThetransitionfromCNNstovisiontransformers(ViT)hasfurther inherentstochasticnature.Regardingtheone-stepapproach,it
advancedthisfield,asdemonstratedbyDPT[Ranftletal.2021b]. oversimplifiesthemarkovchainofthediffusionprocess,smoothing
DSINE[BaeandDavison2024]rethinkshowtocorrectlymodel outintrinsiclocalgeometricdetails,leadingtothetypicalover-
theinductivebiasesforsurfacenormalestimation,andproposesto smoothingartifactsseeninotherregression-basedmethods[Bae
leveragetheper-pixelraydirection,andlearntherelativerotation andDavison2024;Eftekharetal.2021].Therefore,whenrepurpos-
betweennearbypixels.Theseeffortsdecreasetheneedforlarge- ingthediffusionmodelfordeterministicestimationtasks,suchas
scaletrainingdata,DSINEtrainedonlyon160Kimagessurpass normalestimation,atrade-offbetween“stability” and“sharpness”
theOmnidata-V2,whichistrainedonover12Mimages.Recently, arises,whichrequirescarefulconsiderationbeforeproceeding.4 • Ye,etal.
3 METHOD VAE,inwhich𝑐istheadditionaltextpromptembedding(typically
3.1 PreliminariesonDiffusionModel obtainedbyCLIP[Radfordetal.2021]).
Diffusion Probabilistic Models [Ho et al. 2020; Song et al. 2020]
3.2 Diffusion-basedNormalEstimator
aimtomodeladatadistribution𝑝(𝑥)bysequentiallytransforma
Gaussiandistributionviatheso-calledbackwarddiffusionprocess Apart from common multi-modal generation tasks (e.g., text-to-
𝑥 𝑡−1=𝐵 𝑡𝑥 𝑡−𝜇 𝜃𝜖(𝑥 𝑡,𝑡)+𝜖 𝑡 inwhich𝜖 𝑡 ∼N(0,𝜎 𝑡𝐼)and𝜇 𝜃𝜖 predicts image[Rombachetal.2021],text-to-3D[Pooleetal.2023]),the
theinjectednoise.Thisbackwardprocessisuniquelydetermined pre-traineddiffusionmodelshavealsoproventohavesurprisingly
byapredefinedforwarddiffusionprocess𝑥 𝑡+1=𝐴 𝑡𝑥 𝑡 +𝜖 𝑡. goodzero-shotperformanceinseveraldiscriminativetasks,suchas
Asaclassicalexample,DDPM[Hoetal.2020]assumesthatthe classification[Lietal.2023b],andsegmentation[Lietal.2023c;Tian
initialGaussiandistributionN(0,I)canbeobtainedbyrunningthe etal.2024].Andsinceimage-to-imagetranslationcouldbeconsid-
followingforwarddiffusionprocess: eredasasingle-modalgenerationtask,different2Dmodalities(e.g.,
image,normal,depth,cannyedge)couldalsobeinterconverted[Ke
√ √ etal.2024a;Wangetal.2023;Zhangetal.2023a]withtheadapted
𝑞(𝑥 𝑡)= 𝛼 𝑡𝑥 0+ 1−𝛼 𝑡𝝐,𝑥 0∼𝑝(𝑥),𝑡 ∈{0,1,...,𝑇} (1)
orfine-tunedSDmodel.
where 𝝐 ∼ N(0,I),𝑇 denotes the number of the time step, t is
thecurrenttimestep,and𝛼 𝑡 isthenoiseschedulecontrollinghow NormalEstimationwithSD.Sincenormalestimationcanbeseen
fastthedatadistributionistransformedintoastandardGaussian
astranslatinganRGBimageintoanormalmapimage,thediffusion
distribution.Asaresult,thebackwarddiffusionprocessinDDPM
priorfromSDcanalsobeeffectivelyutilized.Astraightforward
provestobe
approachistotaketheRGBimageastheconditioningsignalto
generatethecorrespondingnormalmaps,asinGeoWizard[Fuetal.
𝑥 𝑡−1= √1 𝛼 𝑡𝑥 𝑡 − √︃ 𝛼 𝑡(11 −− Π𝛼 𝑡 𝜏𝑡 =0𝛼 𝜏)𝜇 𝜃𝜖 (𝑥 𝑡,𝑡;)+𝜎 𝑡𝜖 (2) i2 d n0 it t2 i oo4 n ab] ls aa i tgn end na tlM ci osa dr ci eog m wol p id tu h[ tK e ade pbe reyt -a tfi rl r. as2 it n0 e e2 n d4 ca Vo] Ad. iM Engo enr te ch oes dp R ee G rc ,i B nfi ac in ma pl el uy ly, tt i 𝐸h m 𝑛e a ,gc ao e nn d𝑰-
ThelossfunctionforDDPMisadenosingautoencoderloss: then,similartoControlNet[Zhangetal.2023a],wetransformthis
latentcode𝐸𝑛(𝑰)throughanadditionalencoder𝑓 𝜙,intothecontrol
𝐿 𝜃 =E 𝒙0,𝒄,𝑡(cid:13) (cid:13)𝒙0−𝝁𝜃𝒙0(𝒙𝑡,𝒄,𝑡)(cid:13) (cid:13)2 (3) signalforthedecoderblocksoftheU-NetinSD.Thedecoderblocks
ofU-Net,whichisparameterizedby𝜃,andencoder𝑓 𝜙 aretrained
Reparameterization.Itisoftenconvenienttoreparameterizedif-
withthefollowingloss(in𝝐-reparameterization):
fusionmodelsaspredictingtheone-stepdenoisedoutput(called
𝑥 0-reparameterization) instead of the √injected noise (the default
𝝐-reparameterization).InDDPM,𝑥 𝑡 = 𝛼 𝑡𝑥 0+𝜖 𝑡 andthereforeloss 𝐿 𝜃,𝜙 =E 𝝐,𝒄,𝑰,𝑡(cid:13) (cid:13)𝝐−𝝁𝜃𝝐(𝒙𝑡,𝒄,𝑡,𝑓 𝜙(𝐸𝑛(𝑰)))(cid:13) (cid:13)2 (6)
for𝝐-reparameterizationis(uptoascale)
𝐿 𝜃 =E 𝝐,𝒄,𝑡(cid:13) (cid:13)𝝐−𝝁𝜃𝝐(𝒙𝑡,𝒄,𝑡)(cid:13) (cid:13)2 (4) w enh ce or de e𝑰 di fs rot mhe thin ep gu rt oi um na dg te r, u𝑥 th𝑡 n= o𝑞 rm(𝐸 a𝑛 l( m𝑁 ag pt) 𝑁) i gs tt ah te til mat ee sn tt epfe 𝑡a .ture
Duringinference,itisstraightforwardtoestimatethenormal
DiffusionSamplers.Whenthenumberoftimesteps𝑇 islarge
mapforagivenRGBimagebyrunninganywaysamplingalgorithm
enough,boththeforwarddiffusionprocessandthebackwardone
forthetrained(conditional)diffusionmodel.Theestimatednormal
canbeseenasapproximationsoftheircontinuouscounterparts
map,thoughlookingsharp,isstochasticallygenerated.Weobserver
thatcanbemodeledbystochasticdifferentialequations(SDEs).It
thatthehighvarianceintheestimatednormalmapsaretypically
isthereforepossibletosamplefromatrainedDDPMmodelwith
misalignedwiththecorrespondinginputimages.Whileensemble-
SDEsolversorsamplersotherthanthedefaultDDPMbackward
likemethodscanbeused(asproposedinMarigold[Keetal.2024a])
diffusionprocessforbetterefficiency(atacostofprecision).Asan
toreducethevariancethroughaveraging,theresultsarestillless
example,DDIMgeneratessampleswith
thansatisfactoryandtheentireensemblingprocessisquitetime-
√ consuming(seeFig.5).
𝑥
𝑡−1=√
𝛼
𝑡−1·(cid:18)𝑥 𝑡 − 1−𝛼 √𝑡 𝛼·𝝁𝜃𝝐(𝑥 𝑡,𝒄,𝑡)(cid:19)
+direction(𝑥 𝑡)+𝜏𝝐
𝑡 TheVariancefromtheDiffusionModel.Asarguedabove,the
(5)
majorissueofdiffusion-basednormalestimationisthehighvariance
where𝜏 isascalartocontroltheamountofinjectednoiseduring
inthediffusioninferenceprocedure.Thesourcesofrandomness
theprocess.Notably,if𝜏 issetto0,DDIMbecomesadeterministic
indiffusionsamplingalgorithmsaremostly1)theinitialGaussian
sampler(i.e.,independentofanynoise).
noiseand2)allintermediateinjectedGaussiannoises.Thus,we
Text-to-image(T2I)diffusionmodels..Differentfromuncondi- suggest mitigating the variance through a dual-phase inference
tionaldiffusionmodels,T2Idiffusionmodelsaimtogenerateimages approach.Intheinitialphase,areliable"initialestimate"withhigh
withoptionaltextprompts.AclassicalexampleisStableDiffusion certaintyisgenerated.Subsequently,asecondphaseofrefinement
(SD)[Rombachetal.2021],adiffusionmodel𝜇 𝜃(𝑧 𝑡,𝑡,𝑐)builtwith iscarriedoutwitharestrictednumberofdiffusionsamplingsteps,
aU-Netarchitectureandtrainedonthelatentspaceofapretrained ensuringminimalGaussiannoiseinjection.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 5
Fig.4. OverviewoftheStableNormal.Theoverallpipelineiscomposedoftwostages:1)YOSOaimstoproduceaconfidentinitialization𝑥 𝑡+forstagetwo
withanovelShrinkageRegularizer;2)SG-DRNplaystheroleofstabledenoising,byleveragingthestrongersemanticcontrolinformationextractedfrom
DINO[Oquabetal.2024].ThetextualpromptfortheU-Netinbothstagesissetto“The normal map”.
3.3 You-Only-Sample-OnceNormalInitialization 3.4 Semantic-guidedNormalRefinement
One-stepEstimation.Theone-stepsamplingstrategyfornormal Weobservethatforsubsequentsamplingstepsthatrefinetheinitial
estimationisfirstlyintroducedinGenPercept[Xuetal.2024]:no normalestimate,thedesignedimage-conditioneddiffusionmodel
Gaussiannoiseisintroduced,theestimationprocessisdeterministic, tendstoleveragelocalinsteadglobalinformationintheRGBimage
butatacostofoverly-smoothingoutputs.Weinsteadperformone- input.However,itisintuitiveimportantnottorelysolelyonlocal
stepsamplingwithaGaussiannoiseinputtobalancethesharpness imageinformation:forinstance,todeterminethenormalsforpixels
andstability.Inmathematicalterms,weadopt𝑥 𝑡+-parameterization that correspond to a wall, global information is typically much
insteadof𝑥 0-parameterizationandreformualtethelossfunction moreinformative.Wethereforeproposetoincludesemantic(and
showninEq.(6)tothefollowingoneshowninEq.(7): global)featuresfromapre-trainedencoder(forwhichweuseDINO
features[Oquabetal.2024])asanauxiliaryconditionsignal.
𝐿 𝜃,𝜙 =E 𝒙𝑡+,𝒄,𝑰,𝑡+(cid:13) (cid:13)𝒙𝑡+−𝝁𝜃𝑥 𝑡+(𝒙∞,𝒄,𝑡+,𝑓 𝜙(𝐸𝑛(𝑰)))(cid:13) (cid:13)2 (7) A der pc ih cti ete dc it nu Fr ie g.o 4f (bS )G ,- wD hR erN e. tT hehe ime an gti ere coa nrc dh iti it oe nct bu rr ae no cf hS iG s- dD enR oN tei ds
where𝑥 ∞denotesanoisysamplefromtheGaussiandistribution b exy ce𝑓 𝜒 p. tI ft oe rm anpl eo xy trs aa lin ge ht tw wo er igk ha tr sc eh mit ae nct tu icr -e ins ji em cti il oa nrt no ett wha ot rkin
𝑔
𝜓YO thS aO
t
resultedfromrunningtheforwarddiffusionprocess(asinEq.(1))
injectsthesemanticfeaturesintotheencoderlayeroftheU-Netin
with𝑡 approachesinfinityandTissetto1000.Notethatweare
SG-DRN(denotedby𝜇 𝜁).
interestedinmappingadistributionfroma(standard)Gaussian
onetoonethatcorrespondstotime𝑡+ ∈ (0,𝑇),insteadtothatat Semantic-injectionNetwork.Forefficiency,weimplementalight-
time𝑡 =0.Wecallsuchone-stepestimation—You-Only-Sample- weightnetworktofeedsemanticfeaturesintotheU-Net.Specifically,
Once(YOSO).Unfortunately,naïvelyestimating𝑥 𝑡+fromaGaussian thenetworkemploysfourconvlayers(with3×3kernels,1×1strides,
distributionmeanslearningamany-to-onemapping,whichishard. andchannelcountsof16,32,64,128)thatareakintothecondition
Toaddressthisissue,weproposetouseaShrinkageRegularizer. encoderin[Zhangetal.2023a]toalignthespatialresolutionof
DINOfeatureswiththatofnoisylatentfeatures.GiventhatDINO
ShrinkageRegularizer.Wefurtherreducethevarianceinthepre- featurestypicallyhavealowerresolutionthandiffusionlatentfea-
dictednormalmapsbytrainingthediffusionmodelwitharegular- tures,forresolutionalignmentweuseFeatUp[Fuetal.2024a]and
izedloss.Insteadofpenalizingtheentropyofthepredicteddistribu- bi-linearinterpolationtoupsampleDINOfeatures.Thenoisylatent
tionwhichisgenerallyhard,wetakeadifferentpathby“shrinking” featuresareaddedbythealignedDINOfeaturesbeforebeingfed
thedistributionofpredictednormalmaps,𝜇 𝜃𝑥 𝑡+ (𝑥 ∞,𝑐,𝑡,𝑓 𝜙(𝐸𝑛(𝐼))), intothedenoisingU-Net.Duringtraining,thenetworkweightsare
𝑥+ initializedusingaGaussiandistribution,exceptthefinalprojection
totheDiracdeltafunction𝛿(𝑥−𝜇 𝜃𝑡(0,𝑐,𝑡,𝑓 𝜙(𝐸𝑛(𝐼)))):
layer,whichisinitializedasazeroconvolution.
Loss function. Following the I2VGen-XL [Zhang et al. 2023b],
𝐿
𝜃,𝜙
=(cid:40) E E𝒙 𝒙𝑡 𝑡+ +, ,𝒄 𝒄, ,𝑰 𝑰, ,𝑡 𝑡+ +(cid:13) (cid:13)
(cid:13)
(cid:13)𝒙 𝒙𝑡 𝑡+ +− −𝝁 𝝁𝜃 𝜃𝑥 𝑥𝑡 𝑡+ +( (𝒙 0,∞ 𝒄, ,𝑡𝒄 ,, 𝑓𝑡 𝜙,𝑓 (𝜙 𝐸( 𝑛𝐸 (𝑛 𝑰( )𝑰 )))
(cid:13)
(cid:13)) 2)(cid:13) (cid:13) ,2, if𝑝if𝑝 <≥
𝜆
𝜆 w fue ncr te ip oa nra om f𝜇e 𝜁te cr aiz ne bt eh de e𝜇 fi𝜁 neto dt ah s:e𝑥 0-reparameterization.Theloss
where𝑝 ∼𝑈(0,1),and𝜆=0.4. (8) 𝐿 𝜃,𝜒,𝜓 =E 𝒙0,𝒄,𝑰,𝒅,𝑡(cid:13) (cid:13) (cid:13)𝒙0−𝝁𝜁𝑥 0 (cid:16) 𝒙𝑡,𝒄,𝑡,𝑓 𝜒(𝐸𝑛(𝑰)),𝑔 𝜓(𝒅)(cid:17)(cid:13) (cid:13) (cid:13)2 (9)6 • Ye,etal.
where𝒅istheprocessedsemanticfeaturesextractedfromDINO underperformedcomparedtotheoriginalreleasedversion,sowe
and𝑡+ ∈ (0,𝑇). decidedtousetheoriginalmodelforourevaluation.ForGeoWizard,
sincethetrainingcodeisnotavailable,weutilizedthepre-released
3.5 HeuristicDenoisingSampling model4forourevaluations.Weconsiderthisapproachfairbecause
Duringinference,weapplyDDIMtoobtainourfinalnormalpredic- weusethesametrainingdataset.
tion,asEq.(10).Specifically,theinitialnormallatent𝑥 𝑡+,predicted ThetestingdataforevaluationincludesthechallengingDIODE-
fromYOSO,isfedintothesolverwith10-stepDDIM.Empirically, indoor[Vasiljevicetal.2019],iBims[Kochetal.2018],ScanNetV2
wesettheinitialsamplingstep𝑡+as401,whichprovidesanoptimal [Daietal.2017],andNYUv2[Silbermanetal.2012]datasets.As
compromisebetweenstabilityandsharpness. presented in Tab. 2, our method achieves superior performance
acrossiBims,ScanNetV2,andDIODE-indoorbyalargemargin.On
𝑥 𝑡−1=√ 𝛼 𝑡−1·(𝑥ˆ0)+direction(𝑥 𝑡)+𝜏𝝐 NYUv2,ourmethodisslightlyinferiortoDSINE.Wearguethat
bothScannetandNYUV2arecapturedusinglow-qualitysensors,
𝑥ˆ0=𝝁𝜁𝑥 0 (cid:16) 𝒙𝑡,𝒄,𝑡,𝑓 𝜒(𝐸𝑛(𝑰)),𝑔 𝜓(𝒅)(cid:17) (10) thustheirGTnormalarenotaccurate,whichisalsomentioned
𝑥 𝑡+ =𝝁𝜃𝑥 𝑡+ (cid:16) 𝒙∞,𝒄,𝑡+,𝑓 𝜙(𝐸𝑛(𝑰))(cid:17) i cn omG pe ao rW isi oz na srd o[ nFu che at lla el n. g2 i0 n2 g4b sc] e). nF ai rg iou sr ,e w9 hs ih chow ds emth oe nsq tu ra al ti et sat ti hve e
accuracyandsharpnessofStableNormal.
4 EXPERIMENTS
Inthissection,wecompareStableNormalwithotherSOTAs(i.e., (a)OutputVarianceAnalysis (b)InferenceTimeAnalysis
DSINE,Marigold,GenPerceptandGeoWizard)invariousreal-world
datasets.Inaddition,anablationstudyisconductedtodemonstrate
theeffectivenessofdifferentcomponents,i.e.,YOSOandSG-DRN.
4.1 ExperimentalSetup
Datasets. Following GeoWizard [Fu et al. 2024b], our model is
trainedonacomprehensivedatasetofhigh-resolutionimagesand
groundtruthnormalsrenderedfromsyntheticscenesacrossthree
categories:25,463samplesfromHyperSim[Robertsetal.2021]and EnsembleTimes EnsembleTimes
50,884samplesfromReplica[Straubetal.2019]forindoorenvi-
ronments;76,048samplesfrom3DKenBurns[Niklausetal.2019] Fig.5. Thecomparisonofoutputvarianceandinferencetimebetween
and39,630syntheticcityimagesfromMatrixCity[Lietal.2023a]; ourmethod,GeoWizard,andMarigold.Theleftplotshowstheoutput
varianceoverensembletime,whiletherightplotdisplaystheinference
and85,997background-free3DobjectsfromObjaverse[Deitkeetal.
time(includingensembling).Itisimportanttonotethatourmethoddoes
2022].MostofthedataisphotorealisticallyrenderedusingBlender
notemploytheensemblestrategyandonlyrequiresasingleforwardpass.
andUnrealEngine,totalingover250,000image-normalpairs.
Implementation.Wefine-tunetheStableDiffusionV2.12using
theAdamWoptimizer[LoshchilovandHutter2019]withafixed Figure5comparestheinferencevarianceandtimebetweenour
learningrateof3e-5.Pleasecheckoutmoreimplementationdetails methodandGeoWizardontheDIODE-indoordataset.Specifically,
inSupMat.’sAppendixA. weestimateeachimage10timesusingdifferentinitializationseeds,
Metrics.Forevaluation,wefollowthemetricsoutlinedinDSINE[Bae allowing us to calculate the variance for each individual image.
andDavison2024]andcalculatetheangularerrorbetweentheesti- Wethencalculatedtheoverallvarianceforeachmodelbyaverag-
matedandgroundtruthnormalmaps.Wereportboththemeanand ingthesevaluesacrosstheentiredataset.AsshowninFig.5(a),
medianangularerrors,withlowervaluesindicatingbetteraccuracy. GeoWizardemploysanensemblestrategytoreducethevariance
Additionally,wemeasurethepercentageofpixelswithanangular oftheoutput.However,ourapproachsignificantlydecreasesthe
errorbelowspecifiedthresholdsof11.25◦,22.5◦,and30.0◦,where outputvariance(0.410vs.1.370)withoutintroducinganyensemble
higherpercentagesreflectsuperiorperformance. strategies.Furthermore,theensemblestrategycompromisesspeed
to achieve a lower variance. Figure 5 (b) shows that GeoWizard
4.2 Comparisontothestate-of-the-art
samplesfivetimes(approximately10seconds)toreachavariance
WechooseDSINE[BaeandDavison2024],Marigold[Keetal.2024a] of1.370,whileourmethodachievesavarianceof0.410within3
(normalversion3,denoteasMarigold†),GenPercept[Xuetal.2024] secs.TheinferencespeedwastestedonasingleA100GPU.
andGeoWizard[Fuetal.2024b]forcomparison.DSINEistheSOTA
4.3 Ablationstudy
methodamongallregression-basedmethodsandGeoWizardisthe
SOTAamongallexistingdiffusion-basedones.Duetotheunavail- Weconductablationstudiestoanalyzethecontributionofeach
abilityofDSINE’strainingdata,weretrainedthemodelusingthe componentinourframeworkacrossfourdatasets:NYUv2,Scan-
providedcodeandourdataset.Nonetheless,ourretrainedmodel Net,iBims-1,andDIODE-indoor.Bothquantitativeandqualitative
resultsaresummarizedinTable3andFig.6.
2hf.co/stabilityai/stable-diffusion-2-1
3hf.co/prs-eth/marigold-normals-lcm-v0-1 4hf.co/lemonaddie/GeowizardStableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 7
Table1. QuantitativecomparisonontheDTUDataset[Jensenetal.2014].WeshowtheChamferdistance(LowerisBetter).Ourmethodachievesthe
highestreconstructionaccuracyamongothernormalestimationmethods.Differentcellcolorsreferstobest,and2nd-best.
24↓ 37↓ 40↓ 55↓ 63↓ 65↓ 69↓ 83↓ 97↓ 105↓ 106↓ 110↓ 114↓ 118↓ 122↓ Mean↓
2DGS[Huangetal.2024] 0.48 0.91 0.39 0.39 1.01 0.83 0.81 1.36 1.27 0.76 0.70 1.40 0.40 0.76 0.52 0.80
2DGS+DSINE[BaeandDavison2024] 0.62 0.76 0.49 0.38 1.20 1.04 0.68 1.34 1.35 0.76 0.61 0.83 0.42 0.57 0.44 0.76
2DGS+GeoWizard[Fuetal.2024b] 0.54 0.75 0.43 0.38 1.15 0.80 0.66 1.28 1.47 0.80 0.61 0.81 0.40 0.59 0.50 0.75
2DGS+Ours 0.51 0.72 0.41 0.38 1.18 0.86 0.61 1.29 1.09 0.84 0.59 0.79 0.36 0.54 0.43 0.70
Table2. Quantitativeevaluation.HerewecomparewithDSINE[Baeand Table4. AblationstudyoftheeffectivenessofShrinkageRegularizer.Best
Davison2024],Marigold†[Keetal.2024a],andGeoWizard[Fuetal.2024b], resultsarehighlighted.
anothertwodiffusion-basednormalestimators,onfourindoorbenchmarks.
Differentcellcolorsreferstobest,and2nd-best. Ablation Mean↓ Med↓ 11.25◦↑ 22.5◦↑ 30◦↑
DIODE-indoor[Vasiljevicetal.2019]
Method mean↓ med↓ 11.25◦↑ 22.5◦↑ 30◦↑ w/oShrinkageRegularizer 18.624 14.237 37.504 76.569 87.740
w/ShrinkageRegularizer 17.122 13.787 32.950 83.385 89.884
NYUv2[Silbermanetal.2012]
iBims-1[Kochetal.2018]
GeoWizard 20.363 11.898 46.954 73.787 80.804
Marigold† 20.864 11.134 50.457 73.003 79.332 w/oShrinkageRegularizer 18.552 9.049 61.791 79.077 81.852
w/ShrinkageRegularizer 17.695 8.431 63.635 80.212 84.034
GenPercept 20.896 11.516 50.712 73.037 79.216
DSINE 18.610 9.885 56.132 76.944 82.606
Ours 19.707 10.527 53.042 75.889 81.723
ScanNet[Daietal.2017]
GeoWizard 21.439 13.930 37.080 71.653 79.712
AblationonSG-DRN.Wefirstevaluatedtherefinementstep–
Marigold† 21.284 12.268 45.649 72.666 79.045
GenPercept 20.652 10.502 53.017 74.470 80.364 SG-DRN.Werefertothemethodwithouttherefinementpipelineas
DSINE 18.610 9.885 56.132 76.944 82.606 YOSOOnly.AsshowninTable3,thereisaperformancedegradation
Ours 18.098 10.097 56.007 78.776 84.115
onboththeiBims-1andDIODE-indoordatasets,highlightingthe
iBims-1[Kochetal.2018]
GeoWizard 19.748 9.702 58.427 77.616 81.575 criticalroleoftheSG-DRNrefinementmoduleinimprovingnormal
Marigold† 18.463 8.442 64.727 79.559 83.199 estimationaccuracy.Notably,sinceNYUv2andScanNetfeature
GenPercept 18.600 8.293 64.697 79.329 82.978
smoothGTnormals,andthepredictionnormalsbyYOSOOnlyare
DSINE 18.773 8.258 64.131 78.570 82.160
Ours 17.248 8.057 66.655 81.134 84.632 relativelysmoothaswell,thequantitativeperformanceofYOSO
DIODE-indoor[Vasiljevicetal.2019] Onlyevensurpassesthatofthefullversionwiththerefinementpro-
GeoWizard 19.371 15.408 30.551 75.426 86.357
cess.However,thisisnotthecasewhenexaminingthequalitative
Marigold† 16.671 12.084 45.776 82.076 89.879
GenPercept 18.348 13.367 39.178 79.819 88.551 results(seeSupMat.’sFig.R.3).Furthermore,wealsoevaluatethe
DSINE 18.453 13.871 36.274 77.527 86.976 DSINEwithSG-DRNmodule,referedasSG-DRN+DSINE,theresults
Ours 13.701 9.460 63.447 86.309 92.107
onDIODE-indoorandiBIMS-1datasetsalsojustifytheeffectiveness
ofmulti-steprefinement.
Table3. AblationStudies.Differentcellcolorsreferstobestand2nd-best.
YOSONormalInitialization.Next,weinvestigatetheeffectofthe
mean↓ med↓ 11.25◦↑ 22.5◦↑ 30◦↑
YOSOinitialization.Todothis,wetriedanalternativetousethe
NYUv2[Silbermanetal.2012]
Ours 19.707 10.527 53.042 75.889 81.723 outputoftheDSINEmethodinsteadofourYOSOastheinitialization,
YOSOOnly 18.917 10.509 53.074 76.008 82.524 whichistermedasSG-DRN+DSINE.TheresultsontheDIODE-
Oursw/oDINO 19.739 10.536 52.999 75.833 81.667
indoordatasetrevealthatusingDSINE’sinitializationleadstoan
DSINE 18.610 9.885 56.132 76.944 82.606
SG-DRN+DSINE 19.869 10.548 52.952 75.738 81.575 increaseinmeanangleerrorfrom13.701°to18.453°.Thisverifies
ScanNet[Daietal.2017] thatthenecessityofourYOSOinitialization.
Ours 18.098 10.097 56.007 78.776 84.115
YOSOOnly 17.679 9.860 57.220 78.823 84.331
Oursw/oDINO 19.326 11.626 48.115 77.438 83.575 AblationonSemanticfeatureextractor.Therearealternatives
DSINE 18.610 9.885 56.132 76.944 82.606 forextractingsemanticfeatures.WedenotetheonereplacingDINO
SG-DRN+DSINE 19.118 10.221 54.789 77.115 82.568
extractorwithastandardResNet-50backboneasOursw/oDINO,
iBims-1[Kochetal.2018]
Ours 17.248 8.057 66.655 81.134 84.632 withwhich,theperformancedecreasesacrossalldatasets,validat-
YOSOOnly 17.695 8.431 63.635 80.212 84.034 ingthatthesuperiorityofDINOvisualrepresentationtobethe
Oursw/oDINO 18.234 8.875 62.172 80.417 84.347
semanticguidancefornormalestimation.Themostsignificantdrop
DSINE 18.773 8.258 64.131 78.570 82.160
SG-DRN+DSINE 17.877 8.069 66.589 80.630 83.957 isobservedontheDIODE-Indoordataset,wherethemeanangle
DIODE-indoor[Vasiljevicetal.2019] errorrisesfrom13.701°to15.611°.QualitativecomparisonsinFig.6
Ours 13.701 9.460 63.447 88.223 92.107
furtherverifiestheusefulnessofDINOfeatures.
YOSOOnly 17.122 13.787 32.950 83.385 89.884
Oursw/oDINO 15.611 11.912 45.801 86.563 91.843
DSINE 18.453 13.871 36.274 77.527 86.976 EffectsofShrinkageRegularizer.Table4illustratesthatourpro-
SG-DRN+DSINE 14.752 10.139 58.221 86.455 90.888
posedShrinkageRegularizercaneffectivelymitigatethedifficulty
oflearningmany-to-onemapping,improvingoverallmetricson
bothDIODE-indoorandiBims-1benchmark.
ticilpxE8 • Ye,etal.
Fig.6. QualitativeAblationStudy.YOSOcanproducerelativelysharpsurfacenormalestimationswithonlyasingle-stepsampling;however,itsresultsstill
lacksufficientdetails.AfterrefinementbySG-DRN,thepredictedsurfacenormalsbecomesignificantlysharper,asillustratedbythecomparisonbetweenthe
thirdandfourthcolumnsinthefigure.ThiscomparisonhighlightstheimpactofsemanticfeaturesonSG-DRN’sperformance.Specifically,thefirstrow
demonstrateshowusingDINOfeaturesassiststhenetworkinmitigatingtheeffectsoflightingonnormalestimation.ThesecondrowindicatesthatDINO
featuresenableeffectivestructuralmodeling,enhancingtheconsistencyofthenormaloutput.Furthermore,thethirdrowshowsthatDINOfeaturesimprove
thenetwork’sabilitytounderstandmaterials,e.g.,plasticmaterial.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 9
5 APPLICATIONS
5.1 Multi-viewSurfaceReconstruction
Accuratenormalestimationiscrucialforfaithfulsurfacereconstruc-
tions,especiallyfornon-Lambertiansurfaces(Fig.7).Weleverage
ourgeneratednormalmapstoregularizethesurfacereconstruction
pipelinefollowing2DGS[Huangetal.2024].Quantitativeresultson
DTU(Table1)showourmethodachievesthelowestmeanChamfer
distanceamongcomparedtechniques,highlightingthesignificant
impactofouraccuratenormalestimates.
5.2 MonocularSurfaceReconsturction
Ourhigh-fidelitynormalestimationalsobenefitsmonocularsurface
reconstructionvianormalfieldintegration,likeBilateralNormal
Integration(BiNI)[Caoetal.2022].Wecomparemonoculargeomet-
ricregularizationfromdifferentmethodson80DiLiGenTsamples
withground-truthnormals.Table5reportsourmethodsignificantly
improvesNormalRMSE,MeanAngleError(by20%),andDepth
MeanAngleErroroverpreviousmethods,demonstratingrobust
Fig.7. QualitativecomparisononDTU[Jensenetal.2014]dataset.Thefirst
normalestimationacrosslightingconditions.Fig.8visualizesex-
rowdisplaystheinputimagesandestimatednormalmaps.Thesecondrow
tractedmeshcomparisonsagainstGTandGeoWizard,showingour
visualizestherenderedworld-spacenormalmapsafterthereconstruction.
methodfaithfullyrecoversintricategeometricstructures.
Table5. QuantitativeevaluationontheDiLiGenT[Shietal.2019]dataset
formonocularsurfacereconsturctionapplication.Differentcellcolorsrefers
tobest,and2nd-best.
Method N-RMSE↓ MAE↓ D-RMSE↓
DSINE[BaeandDavison2024] 0.50 22.53 0.0053
GeoWizard[Fuetal.2024b] 0.49 24.51 0.0048
Ours 0.41 18.78 0.0044
5.3 NormalEnhancement
RecentgenerativeAIadvancesenable3Dcontentcreationbyfine-
tuningpre-trained2Ddiffusionmodelstopredictmulti-viewnormal
maps[Longetal.2023;Luetal.2024;Qiuetal.2024;Zhengetal.
2024],whicharethenfusedinto3Dmodels.However,existingmeth-
odsproducelow-resolutionandover-smoothoutputslackingfine
details.Toimproveit,weapplyourmethodtoWonder3D[Long
etal.2023]toimprovethedetailofthegeneratedmulti-viewnor-
malmapsandtheresulting3Dshapes.Weupsamplethemulti-view
Fig.8. QualitativecomparisononDiLiGenT[Shietal.2019]dataset.
imagesusingbilinearupsamplingandthelow-resnormalmapsto
initialize𝑥 𝑡,leveragingtheirmulti-viewconsistency.OurSG-DRN
thenrefinestheupsamplednormalmapstorecoverfinerdetails. sharpness”trade-off.Thisisvalidatedbymultipleindoorbench-
FollowingWonder3D[Longetal.2023],wetrainaNeuS[Wangetal. marks,andvariousreal-worldapplications(checkourvideoformore
2021]perobjectusingtherefinednormalmapsandextracthigh-res details).SomefailurecasesareinSupMat.’sAppendixC.Whileour
meshes.Figure10showsourmethodsignificantlyimprovesthe focusisonnormalestimation,webelieveourmethodologyandthe
detailofthegenerated3Dobjectscomparedtotheoriginalone. identifiedtrade-offwillalsobenefitotherrelatedfields,includingbut
notlimitedtodepthestimationandvariousperceptiontasks(e.g.,
6 CONCLUSION
detection,segmentation,etc).Todemocratizethis,wewillmakeour
We present StableNormal, which tailors the diffusion priors for codeandmodelspubliclyavailable,onlyforresearchpurpose.
monocularnormalestimation.Unlikepriordiffusion-basedworks,
weprioritizeenhancingestimationstabilitybyreducinginherentdif-
fusionstochasticity.Ourapproach,acoarse-to-finestrategy,hinges Acknowledgments.WethankGuanyingChenandZhenLiufor
onthebeliefthatareliableinitialguesscombinedwithasemantic- proofreading,ZhenLiuandXuCaoforfruitfuldiscussions.
guidedrefinementprocessiscrucialforbalancingthe“stabilityvs.10 • Ye,etal.
Fig. 9. Qualitative comparison of different methods on NYUv2[Silberman et al. 2012], ScanNet[Dai et al. 2017], iBims-1[Koch et al. 2018], DIODE-
indoor[Vasiljevicetal.2019]datasets.StableNormaloutperformsotherrelatedworksintermsofaccuracyandsharpness.
Fig.10. Comparisonofgeometricsurfacenormalsfordifferentscenes.Thesurfacenormalsarerenderedfromthereconstructed3Dmeshmodels.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 11
REFERENCES
RasmusRamsbølJensen,A.Dahl,GeorgeVogiatzis,EngilTola,andHenrikAanæs.2014.
GwangbinBae,IgnasBudvytis,andRobertoCipolla.2021.EstimatingandExploitingthe LargeScaleMulti-viewStereopsisEvaluation.2014IEEEConferenceonComputer
AleatoricUncertaintyinSurfaceNormalEstimation.In2021IEEE/CVFInternational VisionandPatternRecognition(2014),406–413.
ConferenceonComputerVision(ICCV). https://doi.org/10.1109/iccv48922.2021.01289 YuanfengJi,ZheChen,EnzeXie,LanqingHong,XihuiLiu,ZhaoqiangLiu,TongLu,
GwangbinBaeandAndrewJ.Davison.2024. RethinkingInductiveBiasesforSur- ZhenguoLi,andPingLuo.2023.Ddp:Diffusionmodelfordensevisualprediction.
faceNormalEstimation.InIEEE/CVFConferenceonComputerVisionandPattern InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.21741–
Recognition(CVPR). 21752.
AayushBansal,BryanRussell,andAbhinavGupta.2016a. Marrrevisited:2d-3d BingxinKe,AntonObukhov,ShengyuHuang,NandoMetzger,RodrigoCayeDaudt,
alignmentviasurfacenormalprediction.InProceedingsoftheIEEEconferenceon andKonradSchindler.2024a.RepurposingDiffusion-BasedImageGeneratorsfor
computervisionandpatternrecognition.5965–5974. MonocularDepthEstimation.InComputerVisionandPatternRecognition(CVPR).
AayushBansal,BryanRussell,andAbhinavGupta.2016b. MarrRevisited:2D-3D BingxinKe,AntonObukhov,ShengyuHuang,NandoMetzger,RodrigoCayeDaudt,
AlignmentviaSurfaceNormalPrediction.In2016IEEEConferenceonComputer andKonradSchindler.2024b.RepurposingDiffusion-BasedImageGeneratorsfor
VisionandPatternRecognition(CVPR). https://doi.org/10.1109/cvpr.2016.642 MonocularDepthEstimation.InProceedingsoftheIEEE/CVFConferenceonComputer
AmirBar,YossiGandelsman,TrevorDarrell,AmirGloberson,andAlexeiEfros.2022. VisionandPatternRecognition(CVPR).
Visualpromptingviaimageinpainting.ConferenceonNeuralInformationProcessing TobiasKoch,LukasLiebel,FriedrichFraundorfer,andMarcoKörner.2018.Evaluation
Systems(NeurIPS)35(2022),25005–25017. ofCNN-basedSingle-ImageDepthEstimationMethods. arXiv:1805.01328[cs.CV]
ManelBaradad,YuanzhenLi,ForresterCole,MichaelRubinstein,AntonioTorralba, PeterKocsis,VincentSitzmann,andMatthiasNießner.2024.IntrinsicImageDiffusion
WilliamT.Freeman,andVarunJampani.2023.BackgroundPromptingforImproved forSingle-viewMaterialEstimation.InComputerVisionandPatternRecognition
ObjectDepth. arXiv:2306.05428[cs.CV] (CVPR).
XuCao,HiroakiSanto,BoxinShi,FumioOkura,andYasuyukiMatsushita.2022.Bi- L’uborLadický,BernhardZeisl,andMarcPollefeys.2014.DiscriminativelyTrainedDense
lateralnormalintegration.InEuropeanConferenceonComputerVision.Springer, SurfaceNormalEstimation.468–484. https://doi.org/10.1007/978-3-319-10602-1_31
552–567. KatrinLasinger,RenéRanftl,KonradSchindler,andVladlenKoltun.2019. Towards
AngelaDai,AngelX.Chang,ManolisSavva,MaciejHalber,ThomasFunkhouser,and robustmonoculardepthestimation:Mixingdatasetsforzero-shotcross-dataset
MatthiasNießner.2017.ScanNet:Richly-annotated3DReconstructionsofIndoor transfer.arXivpreprintarXiv:1907.01341(2019).
Scenes. arXiv:1702.04405[cs.CV] AlexanderCLi,MihirPrabhudesai,ShivamDuggal,EllisBrown,andDeepakPathak.
MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs,OscarMichel,EliVander- 2023b.Yourdiffusionmodelissecretlyazero-shotclassifier.InInternationalConfer-
Bilt,LudwigSchmidt,KianaEhsani,AniruddhaKembhavi,andAliFarhadi.2022. enceonComputerVision(ICCV).2206–2217.
Objaverse:AUniverseofAnnotated3DObjects.arXivpreprintarXiv:2212.08051 YixuanLi,LihanJiang,LinningXu,YuanboXiangli,ZhenzhiWang,DahuaLin,andBo
(2022). Dai.2023a.Matrixcity:Alarge-scalecitydatasetforcity-scaleneuralrenderingand
TienVanDo,KhiemVuong,StergiosI.Roumeliotis,andHyunSooPark.2020. Sur- beyond.InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.
faceNormalEstimationofTiltedImagesviaSpatialRectifier.CornellUniversity- 3205–3215.
arXiv,CornellUniversity-arXiv(Jul2020). ZiyiLi,QinyeZhou,XiaoyunZhang,YaZhang,YanfengWang,andWeidiXie.2023c.
AinazEftekhar,AlexanderSax,JitendraMalik,andAmirZamir.2021.Omnidata:A Open-vocabularyobjectsegmentationwithdiffusionmodels.InInternationalCon-
scalablepipelineformakingmulti-taskmid-levelvisiondatasetsfrom3dscans.In ferenceonComputerVision(ICCV).7667–7676.
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.10786– ShuaiLiao,EfstratiosGavves,andCeesG.M.Snoek.2019.SphericalRegression:Learning
10796. Viewpoints,SurfaceNormalsand3DRotationsonn-Spheres.CornellUniversity-
DavidEigenandRobFergus.2015a.Predictingdepth,surfacenormalsandsemantic arXiv,CornellUniversity-arXiv(Apr2019).
labelswithacommonmulti-scaleconvolutionalarchitecture.InProceedingsofthe XianLiu,JianRen,AliaksandrSiarohin,IvanSkorokhodov,YanyuLi,DahuaLin,Xihui
IEEEinternationalconferenceoncomputervision.2650–2658. Liu,ZiweiLiu,andSergeyTulyakov.2023.Hyperhuman:Hyper-realistichuman
DavidEigenandRobFergus.2015b.PredictingDepth,SurfaceNormalsandSemantic generationwithlatentstructuraldiffusion.arXivpreprintarXiv:2310.08579(2023).
LabelswithaCommonMulti-ScaleConvolutionalArchitecture.In2015IEEEInterna- XiaoxiaoLong,Yuan-ChenGuo,ChengLin,YuanLiu,ZhiyangDou,LingjieLiu,Yuexin
tionalConferenceonComputerVision(ICCV). https://doi.org/10.1109/iccv.2015.304 Ma,Song-HaiZhang,MarcHabermann,ChristianTheobalt,etal.2023.Wonder3d:
Martin Nicolas Everaert, Athanasios Fitsios, Marco Bocchio, Sami Arpa, Sabine Singleimageto3dusingcross-domaindiffusion.(2023).
Süsstrunk,andRadhakrishnaAchanta.2024. Exploitingthesignal-leakbiasin IlyaLoshchilovandFrankHutter.2019. DecoupledWeightDecayRegularization.
diffusionmodels.InProceedingsoftheIEEE/CVFWinterConferenceonApplications arXiv:1711.05101[cs.LG]
ofComputerVision.4025–4034. YuanxunLu,JingyangZhang,ShiweiLi,TianFang,DavidMcKinnon,YanghaiTsin,
DavidFFouhey,AbhinavGupta,andMartialHebert.2013a.Data-driven3Dprimitives LongQuan,XunCao,andYaoYao.2024.Direct2.5:DiverseText-to-3DGeneration
forsingleimageunderstanding.InProceedingsoftheIEEEInternationalConference viaMulti-view2.5DDiffusion. arXiv:2311.15980[cs.CV]
onComputerVision.3392–3399. SimonNiklaus,LongMai,JimeiYang,andFengLiu.2019.3DKenBurnsEffectfroma
DavidF.Fouhey,AbhinavGupta,andMartialHebert.2013b.Data-Driven3DPrimitives SingleImage.ACMTransactionsonGraphics38,6(2019),184:1–184:15.
forSingleImageUnderstanding.In2013IEEEInternationalConferenceonComputer MaximeOquab,TimothéeDarcet,ThéoMoutakanni,HuyVo,MarcSzafraniec,Vasil
Vision. https://doi.org/10.1109/iccv.2013.421 Khalidov,PierreFernandez,DanielHaziza,FranciscoMassa,AlaaeldinEl-Nouby,
DavidFordFouhey,AbhinavGupta,andMartialHebert.2014. UnfoldinganIndoor MahmoudAssran,NicolasBallas,WojciechGaluba,RussellHowes,Po-YaoHuang,
OrigamiWorld.687–702. https://doi.org/10.1007/978-3-319-10599-4_44 Shang-WenLi,IshanMisra,MichaelRabbat,VasuSharma,GabrielSynnaeve,Hu
StephanieFu,MarkHamilton,LauraE.Brandt,AxelFeldmann,ZhoutongZhang,and Xu,HervéJegou,JulienMairal,PatrickLabatut,ArmandJoulin,andPiotrBo-
WilliamT.Freeman.2024a.FeatUp:AModel-AgnosticFrameworkforFeaturesat janowski.2024. DINOv2:LearningRobustVisualFeatureswithoutSupervision.
AnyResolution.InTheTwelfthInternationalConferenceonLearningRepresentations. arXiv:2304.07193[cs.CV]
https://openreview.net/forum?id=GkJiNn2QDF WilliamPeeblesandSainingXie.2022.ScalableDiffusionModelswithTransformers.
XiaoFu,WeiYin,MuHu,KaixuanWang,YuexinMa,PingTan,ShaojieShen,Dahua BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2023. Dreamfusion:
Lin,andXiaoxiaoLong.2024b.GeoWizard:UnleashingtheDiffusionPriorsfor3D Text-to-3dusing2ddiffusion.InternationalConferenceonLearningRepresentations
GeometryEstimationfromaSingleImage.arxiv(2024). (ICLR)(2023).
JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilistic XiaojuanQi,RenjieLiao,ZhengzheLiu,RaquelUrtasun,andJiayaJia.2018.GeoNet:
models.Advancesinneuralinformationprocessingsystems33(2020),6840–6851. GeometricNeuralNetworkforJointDepthandSurfaceNormalEstimation.In
DerekHoiem,AlexeiA.Efros,andMartialHebert.2005. Automaticphotopop-up. 2018IEEE/CVFConferenceonComputerVisionandPatternRecognition. https:
ACMTransactionsonGraphics(Jul2005),577–584. https://doi.org/10.1145/1073204. //doi.org/10.1109/cvpr.2018.00037
1073232 XiaojuanQi,ZhengzheLiu,RenjieLiao,PhilipH.S.Torr,RaquelUrtasun,andJiayaJia.
DerekHoiem,AlexeiA.Efros,andMartialHebert.2007.RecoveringSurfaceLayout 2022.GeoNet++:IterativeGeometricNeuralNetworkwithEdge-AwareRefinement
fromanImage.InternationalJournalofComputerVision(Jul2007),151–172. https: forJointDepthandSurfaceNormalEstimation.IEEETransactionsonPatternAnalysis
//doi.org/10.1007/s11263-006-0031-y andMachineIntelligence(Feb2022),969–984. https://doi.org/10.1109/tpami.2020.
BinbinHuang,ZehaoYu,AnpeiChen,AndreasGeiger,andShenghuaGao.2024.2D 3020800
GaussianSplattingforGeometricallyAccurateRadianceFields.InSIGGRAPH2024 LingtengQiu,GuanyingChen,XiaodongGu,QiZuo,MutianXu,YushuangWu,Wei-
ConferencePapers.AssociationforComputingMachinery. https://doi.org/10.1145/ haoYuan,ZilongDong,LiefengBo,andXiaoguangHan.2024. Richdreamer:A
3641519.3657428 generalizablenormal-depthdiffusionmodelfordetailrichnessintext-to-3d.In
Jingwei Huang, Yichao Zhou, Thomas Funkhouser, and LeonidasJ. Guibas. 2019. ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
FrameNet:LearningLocalCanonicalFramesof3DSurfacesfromaSingleRGB 9914–9925.
Image.CornellUniversity-arXiv,CornellUniversity-arXiv(Mar2019).12 • Ye,etal.
AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sandhini LvminZhang,AnyiRao,andManeeshAgrawala.2023a.AddingConditionalControl
Agarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal.2021. toText-to-ImageDiffusionModels.InIEEEInternationalConferenceonComputer
Learningtransferablevisualmodelsfromnaturallanguagesupervision.InInterna- Vision(ICCV).
tionalconferenceonmachinelearning. ShiweiZhang,JiayuWang,YingyaZhang,KangZhao,HangjieYuan,ZhiwuQin,Xiang
RenéRanftl,AlexeyBochkovskiy,andVladlenKoltun.2021a.Visiontransformersfor Wang,DeliZhao,andJingrenZhou.2023b.I2vgen-xl:High-qualityimage-to-video
denseprediction.InProceedingsoftheIEEE/CVFinternationalconferenceoncomputer synthesisviacascadeddiffusionmodels.arXivpreprintarXiv:2311.04145(2023).
vision.12179–12188. ZhenyuZhang,ZhenCui,ChunyanXu,YanYan,NicuSebe,andJianYang.2019.Pattern-
ReneRanftl,AlexeyBochkovskiy,andVladlenKoltun.2021b. VisionTransformers AffinitivePropagationacrossDepth,SurfaceNormalandSemanticSegmentation.
forDensePrediction. InternationalConferenceonComputerVision,International In2019IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).
ConferenceonComputerVision(Jan2021). https://doi.org/10.1109/cvpr.2019.00423
Mike Roberts, Jason Ramapuram, Anurag Ranjan, Atulit Kumar, Miguel Angel WenliangZhao,YongmingRao,ZuyanLiu,BenlinLiu,JieZhou,andJiwenLu.2023.
Bautista,NathanPaczan,RussWebb,andJoshuaM.Susskind.2021. Hyper- Unleashingtext-to-imagediffusionmodelsforvisualperception.InProceedingsof
sim:APhotorealisticSyntheticDatasetforHolisticIndoorSceneUnderstanding. theIEEE/CVFInternationalConferenceonComputerVision.5729–5739.
arXiv:2011.02523[cs.CV] Xin-YangZheng,HaoPan,Yu-XiaoGuo,XinTong,andYangLiu.2024.MVD2:Efficient
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Multiview3DReconstructionforMultiviewDiffusion. arXiv:2402.14253[cs.CV]
Ommer.2021. High-ResolutionImageSynthesiswithLatentDiffusionModels.
arXiv:2112.10752[cs.CV]
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjörnOmmer.
2022a.High-resolutionimagesynthesiswithlatentdiffusionmodels.InComputer
VisionandPatternRecognition(CVPR).10684–10695.
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjörnOmmer.
2022b.High-ResolutionImageSynthesisWithLatentDiffusionModels.InProceed-
ingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).
10684–10695.
OlafRonneberger,PhilippFischer,andThomasBrox.2015.U-Net:ConvolutionalNet-
worksforBiomedicalImageSegmentation.LectureNotesinComputerScience,Lecture
NotesinComputerScience(Jan2015).
ChristophSchuhmann,RomainBeaumont,RichardVencu,CadeGordon,RossWight-
man,MehdiCherti,TheoCoombes,AarushKatta,ClaytonMullis,MitchellWorts-
man,etal.2022.Laion-5b:Anopenlarge-scaledatasetfortrainingnextgeneration
image-textmodels. AdvancesinNeuralInformationProcessingSystems35(2022),
25278–25294.
BoxinShi,ZhipengMo,ZheWu,DinglongDuan,Sai-KitYeung,andPingTan.2019.
ABenchmarkDatasetandEvaluationforNon-LambertianandUncalibratedPho-
tometricStereo.IEEETransactionsonPatternAnalysisandMachineIntelligence41
(2019),271–284. https://api.semanticscholar.org/CorpusID:156683
NathanSilberman,DerekHoiem,PushmeetKohli,andRobFergus.2012. Indoor
SegmentationandSupportInferencefromRGBDImages.InEuropeanConference
onComputerVision.
JiamingSong,ChenlinMeng,andStefanoErmon.2020.Denoisingdiffusionimplicit
models.arXivpreprintarXiv:2010.02502(2020).
JulianStraub,ThomasWhelan,LingniMa,YufanChen,ErikWijmans,SimonGreen,
JakobJEngel,RaulMur-Artal,CarlRen,ShobhitVerma,etal.2019.TheReplica
dataset:Adigitalreplicaofindoorspaces.arXivpreprintarXiv:1906.05797(2019).
JunjiaoTian,LavishaAggarwal,AndreaColaco,ZsoltKira,andMarGonzalez-Franco.
2024.Diffuse,Attend,andSegment:UnsupervisedZero-ShotSegmentationusing
StableDiffusion.ComputerVisionandPatternRecognition(CVPR)(2024).
IgorVasiljevic,NickKolkin,ShanyiZhang,RuotianLuo,HaochenWang,FalconZ.Dai,
AndreaF.Daniele,MohammadrezaMostajabi,StevenBasart,MatthewR.Walter,
andGregoryShakhnarovich.2019.DIODE:ADenseIndoorandOutdoorDEpth
Dataset. arXiv:1908.00463[cs.CV]
PengWang,LingjieLiu,YuanLiu,ChristianTheobalt,TakuKomura,andWenping
Wang.2021. NeuS:LearningNeuralImplicitSurfacesbyVolumeRenderingfor
Multi-viewReconstruction.ConferenceonNeuralInformationProcessingSystems
(NeurIPS)(2021).
PengWang,XiaohuiShen,BryanRussell,ScottCohen,BrianPrice,andAlanL.Yuille.
2016.SURGE:surfaceregularizedgeometryestimationfromasingleimage.Neural
InformationProcessingSystems,NeuralInformationProcessingSystems(Dec2016).
RuiWang,DavidGeraghty,KevinMatzen,RichardSzeliski,andJan-MichaelFrahm.
2020.VPLNet:DeepSingleViewNormalEstimationWithVanishingPointsand
Lines.In2020IEEE/CVFConferenceonComputerVisionandPatternRecognition
(CVPR). https://doi.org/10.1109/cvpr42600.2020.00077
XiaolongWang,DavidFouhey,andAbhinavGupta.2015a.Designingdeepnetworks
forsurfacenormalestimation.InProceedingsoftheIEEEconferenceoncomputer
visionandpatternrecognition.539–547.
XiaolongWang,DavidF.Fouhey,andAbhinavGupta.2015b.DesigningDeepNetworks
forSurfaceNormalEstimation.In2015IEEEConferenceonComputerVisionand
PatternRecognition(CVPR). https://doi.org/10.1109/cvpr.2015.7298652
ZhendongWang,YifanJiang,YadongLu,PengchengHe,WeizhuChen,Zhangyang
Wang,MingyuanZhou,etal.2023. In-contextlearningunlockedfordiffusion
models.ConferenceonNeuralInformationProcessingSystems(NeurIPS)36(2023),
8542–8562.
GuangkaiXu,YongtaoGe,MingyuLiu,ChengxiangFan,KangyangXie,ZhiyueZhao,
HaoChen,andChunhuaShen.2024.DiffusionModelsTrainedwithLargeData
AreTransferableVisualModels.arXivpreprintarXiv:2403.06090(2024).StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 13
A MOREDETAILSABOUTIMPLEMENTATION C FAILURECASE
Wefine-tunethepre-trainedStableDiffusionV2.1[Rombachetal. WhileStableNormalcanproducesharpandstablenormalestimation
2022b]usingtheAdamWoptimizer[LoshchilovandHutter2019] undermostcircumstances,itmayalsofailinsomeextremecaseslike
withafixedlearningrateof3e-5.Toenhancetherobustnessof alldata-drivenmethods.AsdepictedinFigure.R.2,StableNormal
ourmethodagainstexposure,weincorporateexposureaugmen- couldpartiallyoutputthenormalofthingsbehindthetranspar-
tation.Furthermore,wetransformallinputmapstotherange[-1, ent objects(Left) and output a similar color(green) for plants in
1]toalignwiththeVAE’sexpectedinputrange.Duringtraining, images(Right)regardlessofthecomplexnormaldirectionsonthe
weemployrandomcropswithvaryingaspectratiosandpadthe surfaceofplants.Thisisduetotheinductivebiasintroducedbyour
imagestoafixedboxresolutionusingblackpadding.Ourtraining trainingdataset(Lackofdataincludingoutdoorscenesandplants),
processinvolvestwostages:first,wepre-trainournetworkwith which could be solved in the future by adding more simulating
aresolutionof512x512usingabatchsizeof64foraround20,000 renderings.
steps.Subsequently,wefine-tunethemodelona768x768resolution
D MOREQUALITATIVEANALYSISOFYOSO
withabatchsizeof32for10,000steps.Theentiretrainingprocess
takesapproximatelyonedayonfourA100GPUs.Notably,both Althoughourmethodpredictssharperandmoreaccuratenormals
YOSOandSG-DRNemploythesametrainingstrategy. comparedtoYOSOOnly,thequalitativeresultsappearworsethan
thoseofYOSOOnlybecausethegroundtruthnormalmapsofboth
NYUv2andScanNetaresmootherandlessdetailed(seeFig.R.3).
Fig.R.1. ThedetailsofthearchitectureofourU-Net.
B THEARCHITECTUREOFU-NETINBOTHSTAGES
OurstructuremaintainsmostbuildingblocksofControlNet[Zhang
etal.2023a]withseveralmodificationsfornormalestimation(we
showthesecondstagehere).AsdepictedinFigure.R.1,weuse
afixedtextprompt“TheNormalMap"inboththetrainingand
testingphasesandaddasemantic-guidernetworktoencodeDINO
features.Theencodedfeatureisfurtheraddedwiththeoutputofthe
YOSOstagetoactasinputtotheSG-DRN.Thesemanticguiderisa
simplestackingof2Dconvolutionsforobtainfeatures,following
byFeatup[Fuetal.2024a]andbi-linearinterpolationtoupsample Fig.R.3. ThequalitativecomparisonresultsbetweenYOSOOnlyandOurs
theirresolutiontothesameshapeastheYOSOoutput. onbothNYUv2andScanNetdataset.
E MOREQUALITATIVECOMPARISONS
WepresentmorequalitativecomparisonresultsbetweenGeoWiz-
ard[Fuetal.2024b],DSINE[BaeandDavison2024],Marigold[Ke
etal.2024a],GenPercept[Xuetal.2024]andStableNormalfrom
Fig.R.4toFig.R.7.
Fig.R.2. TypicalbadcasesgeneratedbyStabelNormal.14 • Ye,etal.
Fig.R.4. Morequalitativeresults(PartI).FromthelefttotherightareresultsfromDSINE[BaeandDavison2024],GenPercept[Xuetal.2024],GeoWizard[Fu
etal.2024b],Marigold[Keetal.2024b]andStableNormalrespectively.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 15
Fig.R.5. Morequalitativeresults(PartII).FromthelefttotherightareresultsfromDSINE[BaeandDavison2024],GenPercept[Xuetal.2024],GeoWizard[Fu
etal.2024b],Marigold[Keetal.2024b]andStableNormalrespectively.16 • Ye,etal.
Fig.R.6. Morequalitativeresults(PartIII).Fromthelefttotheright(theuptothebottom)areresultsfromGeoWizard[Fuetal.2024b],DSINE[Baeand
Davison2024],andStableNormalrespectively.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal • 17
Fig.R.7. Morequalitativeresults(PartIV).FromthelefttotherightareresultsfromGeoWizard[Fuetal.2024b],DSINE[BaeandDavison2024],and
StableNormalrespectively.