[
    {
        "title": "StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal",
        "authors": "Chongjie YeLingteng QiuXiaodong GuQi ZuoYushuang WuZilong DongLiefeng BoYuliang XiuXiaoguang Han",
        "links": "http://arxiv.org/abs/2406.16864v1",
        "entry_id": "http://arxiv.org/abs/2406.16864v1",
        "pdf_url": "http://arxiv.org/pdf/2406.16864v1",
        "summary": "This work addresses the challenge of high-quality surface normal estimation\nfrom monocular colored inputs (i.e., images and videos), a field which has\nrecently been revolutionized by repurposing diffusion priors. However, previous\nattempts still struggle with stochastic inference, conflicting with the\ndeterministic nature of the Image2Normal task, and costly ensembling step,\nwhich slows down the estimation process. Our method, StableNormal, mitigates\nthe stochasticity of the diffusion process by reducing inference variance, thus\nproducing \"Stable-and-Sharp\" normal estimates without any additional ensembling\nprocess. StableNormal works robustly under challenging imaging conditions, such\nas extreme lighting, blurring, and low quality. It is also robust against\ntransparent and reflective surfaces, as well as cluttered scenes with numerous\nobjects. Specifically, StableNormal employs a coarse-to-fine strategy, which\nstarts with a one-step normal estimator (YOSO) to derive an initial normal\nguess, that is relatively coarse but reliable, then followed by a\nsemantic-guided refinement process (SG-DRN) that refines the normals to recover\ngeometric details. The effectiveness of StableNormal is demonstrated through\ncompetitive performance in standard datasets such as DIODE-indoor, iBims,\nScannetV2 and NYUv2, and also in various downstream tasks, such as surface\nreconstruction and normal enhancement. These results evidence that StableNormal\nretains both the \"stability\" and \"sharpness\" for accurate normal estimation.\nStableNormal represents a baby attempt to repurpose diffusion priors for\ndeterministic estimation. To democratize this, code and models have been\npublicly available in hf.co/Stable-X",
        "updated": "2024-06-24 17:59:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.16864v1"
    },
    {
        "title": "GeoMFormer: A General Architecture for Geometric Molecular Representation Learning",
        "authors": "Tianlang ChenShengjie LuoDi HeShuxin ZhengTie-Yan LiuLiwei Wang",
        "links": "http://arxiv.org/abs/2406.16853v1",
        "entry_id": "http://arxiv.org/abs/2406.16853v1",
        "pdf_url": "http://arxiv.org/pdf/2406.16853v1",
        "summary": "Molecular modeling, a central topic in quantum mechanics, aims to accurately\ncalculate the properties and simulate the behaviors of molecular systems. The\nmolecular model is governed by physical laws, which impose geometric\nconstraints such as invariance and equivariance to coordinate rotation and\ntranslation. While numerous deep learning approaches have been developed to\nlearn molecular representations under these constraints, most of them are built\nupon heuristic and costly modules. We argue that there is a strong need for a\ngeneral and flexible framework for learning both invariant and equivariant\nfeatures. In this work, we introduce a novel Transformer-based molecular model\ncalled GeoMFormer to achieve this goal. Using the standard Transformer modules,\ntwo separate streams are developed to maintain and learn invariant and\nequivariant representations. Carefully designed cross-attention modules bridge\nthe two streams, allowing information fusion and enhancing geometric modeling\nin each stream. As a general and flexible architecture, we show that many\nprevious architectures can be viewed as special instantiations of GeoMFormer.\nExtensive experiments are conducted to demonstrate the power of GeoMFormer. All\nempirical results show that GeoMFormer achieves strong performance on both\ninvariant and equivariant tasks of different types and scales. Code and models\nwill be made publicly available at https://github.com/c-tl/GeoMFormer.",
        "updated": "2024-06-24 17:58:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.16853v1"
    },
    {
        "title": "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts",
        "authors": "Aditya SharmaMichael SaxonWilliam Yang Wang",
        "links": "http://arxiv.org/abs/2406.16851v1",
        "entry_id": "http://arxiv.org/abs/2406.16851v1",
        "pdf_url": "http://arxiv.org/pdf/2406.16851v1",
        "summary": "We present LoCoVQA, a dynamic benchmark generator for evaluating long-context\nextractive reasoning in vision language models (VLMs). LoCoVQA augments test\nexamples for mathematical reasoning, VQA, and character recognition tasks with\nincreasingly long visual contexts composed of both in-distribution and\nout-of-distribution distractor images.\n  Across these tasks, a diverse set of VLMs rapidly lose performance as the\nvisual context length grows, often exhibiting a striking exponential decay\ntrend. This test assesses how well VLMs can ignore irrelevant information when\nanswering queries -- a task that is quite easy for language models (LMs) in the\ntext domain -- demonstrating that current state-of-the-art VLMs lack this\nessential capability for many long-context applications.",
        "updated": "2024-06-24 17:58:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.16851v1"
    },
    {
        "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
        "authors": "Mounika MarreddySubba Reddy OotaVenkata Charan ChinniManish GuptaLucie Flek",
        "links": "http://arxiv.org/abs/2406.16833v1",
        "entry_id": "http://arxiv.org/abs/2406.16833v1",
        "pdf_url": "http://arxiv.org/pdf/2406.16833v1",
        "summary": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
        "updated": "2024-06-24 17:41:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.16833v1"
    },
    {
        "title": "Understanding and Mitigating Tokenization Bias in Language Models",
        "authors": "Buu PhanMarton HavasiMatthew MuckleyKaren Ullrich",
        "links": "http://arxiv.org/abs/2406.16829v1",
        "entry_id": "http://arxiv.org/abs/2406.16829v1",
        "pdf_url": "http://arxiv.org/pdf/2406.16829v1",
        "summary": "State-of-the-art language models are autoregressive and operate on subword\nunits known as tokens. Specifically, one must encode the conditioning string\ninto a list of tokens before passing to the language models for next-token\nprediction. We show that, for encoding schemes such as maximum prefix matching,\ntokenization induces a sampling bias that cannot be mitigated with more\ntraining or data. To counter this universal problem, we propose a novel\nalgorithm to obtain unbiased estimates from a model that was trained on\ntokenized data. Our method does not require finetuning the model, and its\ncomplexity, defined as the number of model runs, scales linearly with the\nsequence length. As a consequence, we show that one can simulate token-free\nbehavior from a tokenized language model. We empirically verify the correctness\nof our method through a Markov-chain setup, where it accurately recovers the\ntransition probabilities, as opposed to the conventional method of directly\nprompting tokens into the language model.",
        "updated": "2024-06-24 17:38:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.16829v1"
    }
]