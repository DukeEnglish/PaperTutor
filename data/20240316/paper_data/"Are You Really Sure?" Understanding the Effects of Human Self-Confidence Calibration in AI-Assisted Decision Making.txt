“Are You Really Sure?” Understanding the Effects of Human
Self-Confidence Calibration in AI-Assisted Decision Making
ShuaiMa XinruWang YingLei
TheHongKongUniversityofScience PurdueUniversity EastChinaNormalUniversity
andTechnology WestLafayette,Indiana,USA Shanghai,China
HongKong,China xinruw@purdue.edu 10195102413@stu.ecnu.edu.cn
shuai.ma@connect.ust.hk
ChuhanShi MingYin XiaojuanMa
SoutheastUniversity PurdueUniversity TheHongKongUniversityofScience
Nanjing,China WestLafayette,Indiana,USA andTechnology
chuhanshi@seu.edu.cn mingyin@purdue.edu HongKong,China
mxj@cse.ust.hk
ABSTRACT 1 INTRODUCTION
InAI-assisteddecision-making,itiscrucialbutchallengingforhu- AItechnologyisincreasinglycrucialinsupportinghumandecision-
manstoachieveappropriaterelianceonAI.Thispaperapproaches making across various domains [2, 7, 47, 84, 90, 92, 93]. In AI-
this problem from a human-centered perspective, “human self- assisteddecision-making,AIprovidesrecommendationswhileleav-
confidencecalibration”.Webeginbyproposingananalyticalframe- ingthefinaldecisiontohumans[90].Giventheinherentuncertain-
worktohighlighttheimportanceofcalibratedhumanself-confidence. tiesofbothhumansandAI,onekeychallengeisensuringhumans’
Inourfirststudy,weexploretherelationshipbetweenhumanself- appropriaterelianceonAI[2,90].ShowingAIconfidencelevelshas
confidenceappropriatenessandrelianceappropriateness.Thenin beenproposedtoaddressthis,asaccurateconfidencescorescan
oursecondstudy,Weproposethreecalibrationmechanismsand indicatethelikelihoodofcorrectpredictions[2,38,47,67,90,91].
comparetheireffectsonhumans’self-confidenceanduserexpe- Nonetheless,studiesonAIconfidencepresentationshowmixed
rience. Subsequently, our third study investigates the effects of outcomes,suggestingitdoesn’talwaysimprovehuman-AIcollabo-
self-confidencecalibrationonAI-assisteddecision-making.Results rationoutcomes[47,90,91].
showthatcalibratinghumanself-confidenceenhanceshuman-AI AkeyreasonforthelimitedeffectivenessofshowingAIconfi-
teamperformanceandencouragesmorerationalrelianceonAI denceisthatpeople’srelianceisnotsolelybasedonAIconfidence
(insomeaspects)comparedtouncalibratedbaselines.Finally,we butalsotheirself-confidence[10,81].Forinstance,overconfident
discussourmainfindingsandprovideimplicationsfordesigning individualsmaydismisscorrectAIrecommendations,whileunder-
futureAI-assisteddecision-makinginterfaces. confidentonesmayoverlyrelyonerroneousAIadvice.Existingre-
searchoftenoverlookstheroleofhumanself-confidenceinthispro-
CCSCONCEPTS cess,assumingthatindividualspossessanappropriateperception
•Human-centeredcomputing→EmpiricalstudiesinHCI. oftheirconfidenceandcanmakerationaldecisionsafterevaluating
AI’sconfidence.However,extensiveevidencefromdecision-making
KEYWORDS andcognitivescienceliteratureshowsthatpeoplefrequentlyex-
hibitpoorlycalibratedself-confidence[52,53,55,78,85].
AI-AssistedDecision-making,Human-AICollaboration,Reliance
Inthiswork,weaddressthiscrucialissueandproposeaninno-
onAIsystems,TrustCalibration,AppropriateReliance
vativeapproachtoimprovethecollaborationbetweenhumansand
ACMReferenceFormat: probabilisticAImodelsthroughhumanself-confidencecalibration.
ShuaiMa,XinruWang,YingLei,ChuhanShi,MingYin,andXiaojuan
Wefirstintroduceananalyticalframeworktouncoverinappropriate
Ma.2024.“AreYouReallySure?”UnderstandingtheEffectsofHuman
humanreliancefromaconfidence-correctnessmatchingperspec-
Self-ConfidenceCalibrationinAI-AssistedDecisionMaking.InProceedings
tive, recognizing that inappropriate self-confidence may hinder
oftheCHIConferenceonHumanFactorsinComputingSystems(CHI’24),
rationalhumanrelianceonAI.Then,throughthreeconsecutive
May11–16,2024,Honolulu,HI,USA.ACM,NewYork,NY,USA,20pages.
https://doi.org/10.1145/XXXXXXX.XXXXXXX studies,weaimtoexplorethreecriticalresearchquestions:
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor • RQ1:Howmayhumans’inappropriateself-confidenceaffectthe
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation appropriatenessoftheirrelianceonAI’ssuggestions?
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe • RQ2:Howcanhumans’self-confidencebecalibratedandhow
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
willdifferentself-confidencecalibrationmechanismsaffecthu-
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/orafee.Requestpermissionsfrompermissions@acm.org. mans’perceptionsanduserexperience?
CHI’24,May11–16,2024,Honolulu,HI,USA • RQ3:Howwillcalibrationofhumans’self-confidenceaffectthe
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
appropriatenessoftheirrelianceonAI’ssuggestionsandtask
ACMISBNXXX-X-XXXX-XXXX-X/XX/XX...$15.00
https://doi.org/10.1145/XXXXXXX.XXXXXXX performance?
4202
raM
41
]CH.sc[
1v25590.3042:viXraCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
ToanswerRQ1,weconductourfirststudyusingincomepre- Insummary,thispaperoffersadistinctiveperspectiveonunder-
dictionasthetask[21,28,69,90].FollowingtheJudgeAdvisor standingandpromptingtheappropriatenessofhumanreliancein
System(JAS)model[75],weperformedathree-stepprocess:indi- AI-assisteddecision-making.Weaspirethatourinvestigationwill
vidualsinitiallymadeajudgmentandassessedtheirself-confidence, contributetoenrichingthecommunity’scomprehensionoftherole
thenreceivedAIrecommendations(withorwithoutaconfidence ofhumanself-confidenceinhuman-AIcollaborationandserveasa
score),andultimatelymadetheirfinaljudgment.Ourfindingsun- cornerstoneforcontinuedresearchofself-confidencecalibration
cover a significant link between the appropriateness of human methodologieswithintherealmofAI-assisteddecision-making.
self-confidenceandtheappropriatenessofhumanrelianceonAI.
Through our analytical framework, we discovered that discrep- 2 RELATEDWORK
anciesbetweenhumanconfidenceandcorrectnesssignificantly
2.1 AppropriateRelianceinAI-Assisted
increaseerrorrates.Theseinsightsunderpinourcoregoal:cali-
Decision-MakingandItsMeasurements
bratingindividuals’self-confidencetooptimizetheappropriateness
oftheirrelianceonAI. Extensiveresearchhasexaminedtheappropriatenessofhuman
InresponsetoRQ2,builtondecision-makingandcognitivesci- relianceonAIsystems(includingbroadlyautomatedsystemsand
encetheoriesrelatedtohumanself-confidencecalibration,wein- robotics)[7,42,48,50,51,83,86].InrecentHCIstudies,thefo-
troducethreecalibrationmechanisms:ThinktheOpposite(Think), cushasshiftedfrommerelyincreasingtrustinAItofacilitating
ThinkinginBets(Bet),andCalibrationStatusFeedback(Feedback). appropriatetrustandreliance[6,8,47,71,79,80,86,88,90].Two
Then,inoursecondstudy,wedeliberatelyremovedAIinvolvement widelyrecognizedphenomena,automationbias[61]andalgorithm
tomitigatepotentialconfoundingfactorsstemmingfromAImodel aversion[16],highlightthechallengeindividualsfaceinaligning
suggestions.Participantsindependentlymadeasetofpredictions, theirtrustandreliancewithAIsystemcapabilities.
andwecomparedthethreeproposedself-confidencecalibration InAI-assisteddecision-makingresearch,thefocushasturnedto-
mechanismsagainstacontrolcondition(withoutanycalibration). wardmanagingtrustandrelianceonacase-by-casebasis[39,80,86].
Besidesobjectivemetrics,wealsocollectedparticipants’percep- Keyconceptsinthiscontextaretrustandreliance[39,80,86].Trust
tionsanduserexperience.Theresultsdemonstratethat,compared reflectssubjectiveperceptionsofAI,oftenassessedusingself-report
tothecontrolcondition,ThinkandFeedbackeffectivelyalignpartic- scales,whilereliancepertainstoobjectivebehaviorinresponseto
ipants’self-confidencelevelswiththeiractualaccuracy.However, AIsystems[2,47,84,90,91].Intriguingly,studieshaverevealed
Thinkyieldsparticipants’higherperceivedcomplexityandmental inconsistenciesbetweentrustandreliance.Increasedself-reported
demand,aswellasloweruserpreferenceandsatisfaction.These trustdoesn’tnecessarilycorrelatewithimprovedreliancebehav-
findings imply that balancing these trade-offs will be a pivotal iors[68].Inthispaper,ourfocusisonstudyinghumanreliance
considerationforfutureresearch. behaviors,whichoftenprovideamorereliableindicatorofappro-
Finally, to answer RQ3, our third study explored the impact priatenesswhenrelyingonAIcomparedtoself-reportedtrust.
ofself-confidencecalibrationonAI-assisteddecision-making.We AppropriaterelianceinvolvesacceptingAIsuggestionswhen
comparedtheresultsofconfidencecalibrationwithabaselinewith- theyarecorrectandrejectingthemwhentheyarewrong.Existing
outcalibration.Thefindingsindicatethatconfidencecalibration studiesemploydiversedefinitionsandmeasurementmethodsfor
leadstopeople’smorerationalreliancebehaviors,reducestheir appropriatereliance,fallingintotwobroadcategories:
under-reliance(thoughover-relianceisnotreduced),andimproves Behavior-BasedMeasurement:Thisapproachassessesap-
taskperformance.Inaddition,basedonouranalyticalframework, propriatereliancebyanalyzinghumanbehaviors,consideringAI
wealsoanalyzedtheproportionofdifferenthuman-AIconfidence- confidenceasanindicatoroftrustworthiness[90,91].Ifhumans
correctnessmatchingsituationsandthecorrespondingerrorrates relymoreonAI’ssuggestionswhentheAIexpresseshighconfi-
inafine-grainedmanner. dence(andrelyonAIlesswhenAIconfidenceislow),it’sdeemed
Inthispaper,wemakethefollowingcontributions: calibratedandappropriate.However,theconfidenceofAImaynot
directlyrepresentthecorrectnessofAI.Therefore,manyworks
• We proposed an analytical framework that unpacks humans’ thatrelyonthismeasureoftheappropriatenessofhumanreliance
(in)appropriatereliancefromanovelperspective,i.e.,human havefoundthatalthoughpeople’strust/reliancegetscalibrated,
self-confidenceappropriateness.Thisframeworkprovidesfresh thefinaltaskperformancedoesnotimprove[90,91].
insightsforunderstandingrelianceappropriateness. Outcome-Based Measurement: This approach directly as-
• Wedesignedanexploratorystudytounderstandtherelationship sessesappropriatereliancebasedonthecorrectnessofAIrecom-
betweentheappropriatenessofhumanself-confidenceandthe mendationsandhumandecisions[2,29,47,71,84].Itcategorizes
appropriatenessofhumanrelianceonAI. inappropriaterelianceintoover-relianceandunder-reliance,quan-
• Wedesignedthreemechanismsforcalibratingself-confidence tifyingtheappropriatenessofhumanrelianceonAIsuggestions.
andevaluatedtheirefficacyandimpactonuserexperiencewhile Over-relianceoccurswhenpeoplealignwithAIpredictionswhen
analyzingtheiradvantagesandlimitations. theAIisincorrect,whileunder-relianceiswhenpeoplerejectAI
• Wefurtherinvestigatedtheinfluenceofself-confidencecalibra- predictionswhentheAIiscorrect.Someworkhasadoptedmore
tiononhumanrelianceonAIsuggestionsanddecision-making stringent criteria, focusing solely on whether people can make
performance.Wefurnishedsubstantialevidenceandadeepun- thecorrectfinaldecisionswhentheirinitialpredictionsandAI
derstandingofthepivotalroleofself-confidencecalibrationin suggestionsdiffer[29,71].Inthispaper,weuseoutcome-based
human-AIcollaborativedecision-making. measurementtoassesshumans’relianceappropriateness.“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
2.2 EnhancingAppropriateReliancein judgmentsonwhethertoadoptAIrecommendations[90].More-
AI-AssistedDecision-Making over,theydidn’texplorethesettingwhereAIshowsconfidence,
whereas our work studies the effects of calibrating human self-
ThefieldofAI-assisteddecision-makingisgainingsignificantatten-
confidencewhenAI’sconfidenceisalsopresented.Anotherrelated
tionwithinHCIcommunities[6,47,49,71,73,79,80,86,88,90,94].
workbyMaetal.[47]modelsthecorrectnesslikelihood(CL)of
Inthishuman-AIcollaborativesetting,AIactsasanadvisor,offer-
humansandAI,comparingthemwithineachtaskcasetoadap-
ingsuggestionsoftenaccompaniedbyuncertainty.Aparamount
tivelyadjustthedecision-makinginterface.However,theirprimary
challengeinthesescenariosisensuringthathumansrelyonAIad-
emphasiswasonenhancingAI’sunderstandingofhumans,rather
viceinanappropriatemanner[39,90].Totacklethisissue,existing
thanindividualsgainingself-calibration.Additionally,theyfound
studieshaveventuredintothreeprimarystrategies.
someusersdoubtedthesystem-estimatedhumanCLwhichhin-
Oneapproachcentersonenhancingindividuals’comprehension
deredtheeffectivenessoftheirapproach.Besides,theynudgeduser
ofAIpredictionuncertainty[86,90].AIpredictionuncertaintyis
choicesthroughtheinterfacedesign,potentiallycompromising
typicallymeasuredviatheAImodel’scalibratedconfidencelevel
userautonomyandraisingethicalconcerns.Incontrast,ourwork
thatcanreflectpredictioncorrectnessprobabilities[25,68].For
focusesoncalibratingindividualself-confidence,notonlyensuring
example,aconfidencescoreof0.6signifiesa60%chanceofacor-
userautonomybutalsoavoidingethicalissuesaroundAInudges.
rectprediction.Somestudiesdirectlydisplaycalibratedconfidence
scorestousers[2,90],whichexploredtheimpactofshowingAI
confidenceontrustcalibrationandtaskperformance.Othersinte-
grateAIconfidenceintointerfacedesign.Forinstance,Rastogietal. 2.3 HumanSelf-confidenceinDecisionMaking
[67]adjusteddecision-makingtimeframesbasedonAIconfidence andtheCalibration
levelstopromotehumans’moreanalyticalthinkingwhenAI’scon-
Confidence,groundedinsubjectiveperceptions,shapesourbelief
fidenceislow.Besides,variousconfidencerepresentationmethods,
inthevalidityofourthoughtsandabilities[24,46].Itplaysapiv-
includingviolinplotsorquestionmarks,havealsobeenexplored
otalroleindecision-makingandreceptivenesstoadvice[4],even
[91].However,theseapproacheshaven’tconsistentlyresultedin
affectingourwillingnesstoheedAIrecommendations[10,45,81].
improvedrelianceappropriatenessortaskperformance[47,90,91]
Humans’self-confidenceoftencorrelateswithcredibilityinvar-
-“onlydisplayingAIconfidencecanbeinsufficient”.
iouscontexts,fromchildren’sperceptionsofadults[77]tojuror
Thesecondapproachfocusesonenhancingindividuals’under-
evaluationsofexpertwitnesses[12].However,self-confidencecan
standingofAIerrorpatterns,aidinginthedevelopmentofhumans’
sometimesstrayfromreality,leadingtooverconfidenceorunder-
accuratementalmodelsforAIcapabilities[1,8,30].Forinstance,
confidence,affectingexpertsandlaypersonsalike[52,53,55,78,85].
Bansaletal.[1]introducedtheconceptof“mentalmodelsofAI
Overconfidence,characterizedbyinflatedself-estimation,canre-
errorboundaries”,highlightingfactorsshapingthesemodels.This
sultinriskychoices[56].Conversely,underconfidence,marked
enablesindividualstodiscernwhentoacceptorrejectAIrecom-
byself-underestimation,canleadtomissedopportunities[18,36].
mendations.Cabreraetal.[8]proposedtodisplay“behaviorde-
Extensiveempiricalstudiesindecision-makinghaveobservedthe
scriptions”ofAImodelstoend-users,providinginsightsintoAI
misalignmentbetweenhumanself-confidenceandactualaccuracy,
performanceonspecificinstances.Thisapproachenhanceshuman-
evidentinclinicaldiagnosisandfinancialdecisions[23,53].For
AIcollaborationbyhelpingusersrecognizeAIfailuresandfostering
example,Milleretal.[53]foundnoconsistentcorrelationbetween
morerelianceonAIwhenitdemonstrateshigheraccuracy.
clinicians’ confidence and decision accuracy, while Grežo et al.
ThethirdapproachaimstoelucidatetherationalebehindAI
[23]revealedoverconfidence’ssignificantimpactonfinancialde-
predictionsthroughAIexplanations[2,29,40,41,65,79,82].These
cisions.Thesefindingshighlighttheimportanceofaccurateself-
explanationstakevariousforms,suchasfeatureimportance,feature
assessment.
contribution,similarexamples,counterfactualexamples,andnatu-
Theliteratureonself-confidencecalibrationdelvesintocogni-
rallanguage-basedexplanations[39,44].However,recentresearch
tiveprocessesandmechanisms.Thisresearchuncoverscognitive
hasunveiledapotentialdrawbackofprovidingAIexplanations:the
biasesandheuristicscontributingtomis-calibration,suchasthe
riskofincreasedover-relianceonAIsystemswhenAIprovidesin-
impactofoverconfidence[56]andtheDunning-Krugereffect[36].
correctsuggestions[2,65,84,90].Thisphenomenonisattributedto
Italsoexploresmetacognitiveprocesses,offeringmanipulationsto
alackofcognitiveengagementwithAIexplanations,asindividuals
enhancecalibration[35,64].Tofostercalibratedself-confidence,
mayoptforquickheuristicjudgments,associatingexplainability
cognitiveapproacheshaveemerged.Pulfordetal.[66]examine
withtrustworthinesswhentheylackthemotivationorabilityfor
externalfeedbackandresponsetime’simpactoncalibration.Moore,
in-depthanalysis[3,6].
inhisbook“PerfectlyConfident”[55],navigateshumanconfidence
Ourapproach,distinctfrompriormethods,focusesonenhancing
complexities,highlightingfactorsinfluencingaccuratejudgments
theappropriatenessofhumans’reliancebycalibratingtheirself-
andofferingpracticalstrategies,includingseekingfeedback,di-
confidence.OnesimilarworktooursisHeetal.’sstudy[29],which
verse perspectives, and a growth mindset. Duke [17] advocates
addressesindividuals’overestimationoftheirabilities(knownas
embracinguncertaintyandviewingdecisionsasbets,offeringa
theDunning-Krugereffect)bycalibratingself-assessmentthrough
strategytoassessrisks,uncertainties,andpotentialoutcomes.
a tutorial. However, their approach primarily targets task-level
Our paper adapted human self-confidence calibration to AI-
self-assessment,whereasrationalreliancerequirescase-by-case
assisteddecision-makingscenarios,examininghowitinfluences
humans’relianceonAIsuggestionsamiduncertainty.CHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
3 UNPACKINGINAPPROPRIATERELIANCE 1.0 1.0 1.0
FROMAHUMANSELF-CONFIDENCE 0.9 0.9 0.9
3.1PE AR pS pP rE opC rT iaIV teE
nessofHumanSelf-Confidence
ycaruccA 00 .. 78 00 .. 78 00 .. 78
0.6 0.6 0.6
Theappropriatenessofhumanself-confidencedependsonhow 0.5 0.5 0.5
0.5 0.6 0.7 0.8 0.9 1.0 0.5 0.6 0.7 0.8 0.9 1.0 0.5 0.6 0.7 0.8 0.9 1.0
wellitalignswithactualcompetenceorperformance[56,57].Over-
Confidence
confidencehappenswhenconfidenceexceedsabilities,whileunder-
confidenceoccurswhenconfidencefallsshort.Indecision-making Figure1:Reliabilitydiagramsforabinaryclassificationtask
research,evaluatingself-confidenceappropriatenessinvolvesgath- [25],illustratingcalibratedconfidence(left,theactualaccu-
eringhumans’predictionsandcorrespondingself-reportedconfi- racyalignswiththestatedconfidence),over-confidence(mid-
dencelevels[52,55,78,85].Next,weintroducethemeasurements dle,theactualaccuracyfallsbelowthestatedconfidence),
ofconfidenceappropriatenessatbothtaskandinstancelevels. andunder-confidence(right,theactualaccuracyisabovethe
statedconfidence).
3.1.1 ExistingMeasurementsofConfidenceAppropriatenessatA
TaskLevel. Manymeasurementshavebeenproposedtoevaluatethe
appropriatenessofconfidenceatatasklevel,suchasOver/Under
3.1.2 MeasuringConfidenceAppropriatenessatAnInstanceLevel.
Confidence Index [52, 85], Brier score [70], Pearson correlation
Basedontheconfidencelevelandthecorrectnessofaspecificpre-
coefficient[15,53,68],etc.Oneofthemostwidelyusedmeasure-
diction,weproposeameasurementcalledConfidence-Correctness
mentsisReliabilitydiagrams[14,27,59](Figure1),assessingthe
Matching(C-CMatchinginshort,showninTable1).Tosimplify
alignmentbetweenstatedconfidenceandactualaccuracy.
theproblem,inthispaper,weconsiderconfidenceatabinarylevel:
Foratask,reliabilitydiagramsfirstpartitionall𝑁 predictions loworhigh1.Foraclassificationtask,anypredictioncanbecate-
into𝑀 binsbasedonthecorrespondingconfidencevalues,then
gorizedintofourtypesbasedonitsconfidence(loworhigh)and
calculatetheaccuracy𝑎𝑐𝑐(𝐵 𝑚),andaverageconfidence𝑐𝑜𝑛𝑓(𝐵 𝑚),
correctness(correctorincorrect).Wedefine[Highconfidence&
foreachbin𝐵 𝑚.Finally,thediagramscanbedrawnbysetting
Incorrectprediction]asOver-confidentand[Lowconfidence&Cor-
confidenceasthehorizontalaxisandactualaccuracyasthevertical
rectprediction]asUnder-confidentinaspecificprediction.Andwe
axis.Withthediagrams,ametriccalledExpectedCalibrationError
classifythesetwoasConfidence-CorrectnessMismatched(C-C
(ECE)[52,85]isusedtoquantifythedifferencebetweenexpected
Mismatchedinshort).Onthecontrary,wedefine[Highconfidence
accuracyandself-reportedconfidenceoverthepartitionedbins.
&Correctprediction]and[Lowconfidence&Incorrectprediction]
ECE=
∑︁𝑀 |𝐵 𝑁𝑚|
|𝑎𝑐𝑐(𝐵𝑚)−𝑐𝑜𝑛𝑓(𝐵𝑚)|, (1)
a Bs asC eo dn ofi nd Ce -n Cce M-C ato chrr ine gct ,n we ess prM opa ot sc ehe and a(C na-C lytM ica at lc fh re ad mein ws oh rkor tt o).
𝑚=1 analyzetheappropriatenessofhumans’relianceonAI.
ECEfirstcomputestheabsolutedifferencebetweentheaccuracy
𝑎𝑐𝑐(𝐵 𝑚) andaverageconfidence𝑐𝑜𝑛𝑓(𝐵 𝑚) withineachbin𝐵 𝑚, 3.2 AnAnalyticalFrameworkIntegrating
thencalculatestheaverageofallbins,weightedbythenumber
HumanandAIConfidenceAppropriateness
ofpredictionsofeachbin|𝐵 𝑚|overthetotalpredictionnumber
𝑁.Inouruserstudies,wewilluseECEtomeasuretheoverallap- Existingstudiesonimprovingrelianceappropriatenessinhuman-
propriatenessofhumanself-confidence.Sinceappropriatereliance AIdecision-makingoftenfocusontheAIconfidenceperspective
requireshumanstodistinguishwhethertorelyonanAI’ssugges- (e.g.,providingdifferentformsofAIconfidence)[67,90,91].How-
tiononacase-by-casebasis[71,90],tounderstandtheeffectsof ever,theyoverlookthesignificanceofassessingtheappropriateness
self-confidenceappropriatenessonrelianceappropriateness,we ofhumanself-confidence[2,84].Withinthecontextofhuman-AI
shouldalsomeasureitataninstancelevel.Thus,next,wepropose collaborativedecision-making,theinterplaybetweenindividuals’
aninstance-levelmeasurementofself-confidenceappropriateness. confidenceintheirownjudgmentsandtheconfidenceexpressed
byAIsystemsplaysapivotalroleinshapinghumanrelianceonAI
Table1:Instance-LevelConfidence-CorrectnessMatching. recommendations[10,81].Therefore,tocomprehensivelyinvesti-
Therearefourtypesofconfidence&correctnesssituations gateandanalyzetheintricaterelationshipamongthesefactors,we
related to a specific prediction in decision-making tasks. proposeanintegratedanalyticalframework.Thisframeworktakes
Whether a C-C is matched does not depend on whether theConfidence-CorrectnessMatching(seeSec3.1.2)ofboth
thepredictioniscorrect,butonwhetherthecorrectnessis humansandAIintoconsiderationtoanalyzethespecificcausesof
alignedwithconfidence. inappropriatereliance.
WeadopttheJudge-AdvisorSystem(JAS)indecision-makingto
Confidence Correctness C-CMatching buildouranalyticalframework(Figure2).InJAS,therewillbethree
typesofpredictions:(1)humaninitialprediction,(2)AIsuggestion,
High Correct C-CMatched
High Incorrect Over-confident(C-CMismatched)
1Notethatthethresholdofconfidencelevels(highorlow)dependsonsomefactors
Low Correct Under-confident(C-CMismatched) suchastaskcharacteristics[2,45,67,68].Forinstance,forbinaryclassificationtasks,AI
Low Incorrect C-CMatched confidencevaluesfallwithintherangeof0.5to1.0,whileformulti-classificationtasks,
thisrangemayextendfrom0to1.0.Somepreviousstudieshaveemployedthresholds
(e.g.,meanormedian)todefinewhatconstitutes"high"confidence[2,45,67,68]“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
Human initial AI Human final Human initial AI Human final
prediction suggestion decision prediction suggestion decision
Incorrect AI reliance Incorrect AI reliance
(Human C-C Mismatched & 1 (Human C-C Matched & 3
AI C-C Matched) AI C-C Matched) C-C Matched
High confidence &
Correct prediction
Incorrect AI reliance Incorrect AI reliance
(Human C-C Mismatched & 2 (Human C-C Matched & 4 Low confidence &
(a) AI C-C Mismatched) (b) AI C-C Mismatched) Incorrect prediction
C-C Mismatched
(HuIn mc ao nrr e Cc -Ct s Mel if s- mre ali ta cn hc ee d & 5 (HIn uc mor are nc Ct -s Ce l Mf- are tcli han edce & 7 CL oo rw re c co tn pf rid ee dn icc te io & n
AI C-C Mismatched) AI C-C Mismatched)
High confidence &
Incorrect prediction
Incorrect self-reliance Incorrect self-reliance
(Human C-C Mismatched & 6 (Human C-C Matched & 8
AI C-C Matched) AI C-C Matched)
(c) (d)
Figure 2: A space of different combinations of 1) initial human prediction correctness and confidence, 2) AI suggestion
correctnessanditsconfidence,and3)humanfinaldecisioncorrectness,atataskinstancelevel.Tosavespace,weonlyhighlight
situationswhereahuman’sinitialpredictiondiffersfromtheAI’ssuggestionandthehuman’sfinaldecisionisincorrect.
Comparing(a)and(b),(a)mayinducemoreincorrectAIrelianceduetoHumanC-CMismatched(Low&Correct).Similarly,(c)
mayleadtomoreincorrectself-relianceduetoHumanC-CMismatched(High&Incorrect).
and(3)humanfinaldecision.Figure2illustratesallcombinationsof (2)and(4),theAIprovidesanincorrectsuggestionbutwithhigh
humanandAIC-CMatchingsituations.Forclarity,here,wefocus confidence(AIC-CMismatched).Comparedtosituations(1)and
oncaseswherehumansinitiallydisagreewithAI(becausehumans (3),insituations(2)and(4),humanscouldeasilybemisledbythe
tendtokeeptheirinitialpredictionswhentheyarethesameasthe AI’shighconfidence,resultinginincorrectAIreliance.Similarly,
AI’srecommendations,feelingconfirmedintheirchoices[2,71]). Figure2(5)-(8)areallsituationswherehumanswithanincorrect
Next, we analyze the potential causes of inappropriate reliance initialpredictionencounteracorrectAIsuggestion.However,in
basedonhumansandAI’sC-CMatching. situations(5)and(7),theAIprovidesacorrectsuggestionbutwith
FromHumanC-CMatchingPerspective.WithinFigure2, lowconfidence(AIC-CMismatched).Comparedtosituations(6)
wedistinguishtwotypesofincorrectreliance:incorrectAIreliance and(8),humansinsituations(5)and(7)couldbemorelikelyto
(Figure2(a)and(b))andincorrectself-reliance(Figure2(c)and ignoreAI’scorrectsuggestionsduetoAI’slowconfidence,leading
(d), which is also another perspective of incorrect AI reliance). toincorrectself-reliance.
However, we speculate that the causes of incorrect AI reliance Overall,wearguethatHumanandAIConfidence-Correctness
inFigure2(a)maybedifferentfromFigure2(b).Similarly,the Matchingjointlyinfluencestheappropriatenessofhumanreliance.
causes of incorrect self-reliance in Figure 2 (c) can be different IfbothhumansandAIareC-CMismatched(Figure2(2)and(5)),it
fromFigure2(d).Specifically,forhumans’incorrectAIreliancein canbeextremelychallengingforhumanstoachieveappropriatere-
Figure2(a)and(b):althoughinbothcases,thehumanfirstmakes liance.Conversely,ifbothhumansandAIareC-CMatched(Figure
acorrectinitialpredictionandthenseesawrongAIsuggestion, 2(3)and(8)),humanswouldbemorelikelytohavecorrectreliance.
theHumanC-CMatchingisdifferent.In(a),people’sconfidencein WhiletheAIcommunityhasexploredcalibratingAIconfidence
theirinitialjudgmentislow(low&correct,C-CMismatched),but toenhanceAIC-CMatching[25],scantfocusintheHCIcommu-
in(b),peopleareveryconfidentintheirinitialjudgment(high& nityhasbeengiventohumanconfidencecalibrationandlittleis
correct,C-CMatched).Weconjecturethathumansin(a)aremore knownaboutitsimpactonrelianceappropriateness.Tofillthis
pronetoadopttheAI’serroneoussuggestionsduetotheirlow researchgap,thispaperintroducesaself-confidencecalibration
self-confidence.Similaranalysiscanbeusedforhumans’incorrect methoddesignedtoimproveHumanC-CMatching.Throughthis
self-relianceinFigure2(c)and(d).Wespeculatethathumansin calibrationapproach,weaimtoreducetheoccurrenceofHuman
case(c)aremorepronetoignoretheAI’scorrectsuggestionsdue C-CMismatch,ultimatelymitigatingincorrectreliancestemming
totheirmistakenlyhighconfidencelevels. fromsuchdiscrepancies.
FromAIC-CMatchingPerspective.IfAIisC-CMismatched,
3.2.1 Howcanweusetheproposedanalyticalframework? Help-
itcanposechallengesforahumantoappropriatelyrelyonAI’s
ingwithPosthocAnalysisofInappropriateReliance.One
suggestions.Forinstance,Figure2(1)-(4)areallsituationswhere
crucialapplicationofthisframeworkisitsuseindissectingthe
humanswithacorrectinitialpredictionencounteranincorrect
causesbehindpeople’sinappropriatereliance,fromaConfidence-
AIsuggestion.However,theAIC-CMatchingvaries.Insituations
CorrectnessMatchingperspective.Specifically,wecancategorizeCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
users’decision-makingdataintodifferenthuman-AIC-CMatching responsibilityconcernshavelessinfluenceonpeople’srelianceon
situations.Bycheckingtheoccurrenceratioofeachsituation,we AI,allowingustofocusonstudyingtheeffectsofhuman-AIconfi-
canknowwhetherhumansorAIhaveconfidence-relatedproblems. dence.Third,priorresearchsuggeststhatintheincomeprediction
Informing AI System Design. The detailed understanding task,laypeople’sconfidencecansometimesbepoorlycalibrated
ofthecausesofusers’inappropriatereliancecanfurtherenable [47].Thismakesitanidealtestbedforustoinvestigatetheeffects
designers to make targeted enhancements to AI system design. ofconfidencecalibration.Wefollowedtheapproachof[21,90],
Forinstance,ifinappropriatereliancepredominantlystemsfrom selectingeightimportantattributestopresenttoparticipants,in-
frequentAIC-CMismatch,designerscaninvolvemechanismsto cludingAge,Yearofeducation,Workclass,Occupation,Maritalstatus,
refinethecalibrationoftheAImodel’sconfidence.Conversely,if Gender,Race,andWorkhoursperweek.
therootcauseliesinrecurringHumanC-CMismatch,designers
4.2.2 AIModel. Weutilizedalogisticregression(LR)modelwith
canaddinterventionstocalibrateusers’self-confidencetoimprove
defaultsklearn2settingsforourincomepredictiontask,inlinewith
theirrationalityinthedecision-makingprocess.
[21].TheLRmodeloptimizestheLoglossandprovidesawell-
calibratedconfidencescore[25,63],whichcanavoidconfounding
4 STUDY1-UNDERSTANDINGTHE
factorscausedbyAI’smiscalibratedconfidenceandhelpusfocus
RELATIONSHIPBETWEENHUMAN
onhumanconfidencecalibration.Afterdatapre-processing,we
SELF-CONFIDENCEAPPROPRIATENESS
trainedourmodelusinga70%randomsplitofthedataset,while
ANDRELIANCEAPPROPRIATENESS participantsreceivedpredictiontrialsfromtheremaining30%.
Ourfirststudyaimstounderstandtherelationshipbetweentheap-
4.2.3 TaskSampleSelection. Toensureareasonablestudyduration,
propriatenessofhumanself-confidenceandtheappropriatenessof
weselected20taskinstancesforthemaintaskandincorporated
humanreliance.Inthisstudy,wedidnotperformanyintervention
additionalinstancesforthetutorial.Ourselectioncriteriapriori-
ontheparticipants’self-confidencetocapturetheirmostnatural
tizedmaintainingbothfidelityindatadistribution[84]andwell-
behaviorswhenmakingdecisionswithAI’sassistance.
calibratedAIconfidencescores[84,90].Withinthe20maintask
instances,halffeaturedAIconfidencescoresbelow0.75,indicating
4.1 ResearchQuestions
lowAIconfidencecases(withanaveragescoreof0.6).Amongthese,
FocusingonourmainresearchquestionRQ1:Howmayhumans’ sixwereaccuratelypredictedbyAI,resultingina60%accuracy.The
inappropriateself-confidenceaffecttheirrelianceappropri- remaininghalfshowcasedconfidencescoresabove0.75,signifying
atenessonAI’ssuggestions?,wespecificallyaskthefollowing highAIconfidencecases(withanaveragescoreof0.9),andnine
sub-questions. ofthesewerecorrectlypredictedbyAI,yieldinga90%accuracy.
Asmentionedinouranalyticalframework(Sec3.2),inappropri- WesetdifferentAIaccuraciesforthelow-confidencesamplesand
atehumanself-confidence(C-CMismatched)mightaffectreliance high-confidencesamplesseparatelybecauseweneedtoensurethat
appropriateness.Therefore,wefirstask, notonlyistheoverallAImodelcalibrated,buttheconfidenceof
- RQ1.1:HowwilldifferentsituationsofhumanC-CMatching theAImodelonourselectedtasksamplesisalsowell-calibrated.
affecthumans’performance?
- RQ1.2:Howwilltheappropriatenessofhumanself-confidence 4.3 Conditions
correlatewiththeappropriatenessofhumanreliance? To understand the relationship between the appropriateness of
Inaddition,beforecalibratinghumans’self-confidence,wewant humanself-confidenceandtheappropriatenessoftheirrelianceon
to first explore whether there will be any difference when AI’s AI,weuseanaturalAI-assisteddecision-makingprocess.Sincewe
confidenceisshownornot. alsowanttoexploretheeffectsofthepresenceofAIconfidence,
wehavetwoconditions:
- RQ1.3:HowwillthepresenceofAIconfidenceaffecttheappro-
priatenessofhumanself-confidence? • WithAIConfidence:ParticipantsreceiveAI’spredictionsalong
- RQ1.4:HowwillthepresenceofAIconfidenceaffecttheappro- withAI’sconfidencescores.
priatenessofhumanrelianceandtaskperformance? • WithoutAIConfidence:ParticipantsreceiveonlyAI’spredic-
tions.
4.2 TaskandAIModel
4.2.1 Task. Weselectedincomepredictionasourtestbed,which 4.4 Procedure
iswidelyusedinexistingAI-assisteddecision-makingstudies[21, After obtaining participant consent, we conducted a tutorial to
28,47,69,90].Participantsweretaskedwithpredictingwhetheran familiarizethemwiththetask.Weexplainedeachattributeinthe
individual’sannualincomeexceeded$50Kbasedonher/hisprofile. profiletable,providedincomedistributiongraphs,andtestedtheir
DataforthistaskcamefromtheAdultIncomedataset[34]inthe understandingwithqualificationquestions.Participantsproceeded
UCIMachineLearningRepository,comprising48,842instances totwotrainingexampleswithgroundtruthbeforethemaintask
with14attributes.Thegroundtruthwasbinary(greater/lessthan withAIassistance.Duringthemaintask(20cases),participants
50K).Wechoseincomepredictionasourtaskforthreereasons. wentthroughthreestepsineachcase(Figure3).Step1:Participants
First,itdoesnotrequirespecificdomainknowledgeortraining madepredictionsandindicatedtheirconfidenceonaslider(50%
whichissuitablefornon-expertparticipants[21].Second,thetask
isrelativelylow-risksofactorssuchaspersonalrisktoleranceand 2https://scikit-learn.org/“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
Step 1 Step 2 Step 3
The profile
Figure3:Theinterfaceandprocedureformakingapredictiononataskinstance.
to100%).Andwetoldparticipants“Inabinary-choicetaskifyou AIC-CMatched).Wethencalculatedtheerrorrateofparticipants’
believeyourconfidencewaslowerthan50%,youmightwanttoflip finalpredictionsindifferenthuman-AIC-CMatchingsituations.
yourprediction”.Step2:TheythenreceivedAIsuggestions(withor
withoutAIconfidence).Step3:Theymadefinaldecisions.Attention-
numberofincorrectpredictionsinaspecificsituation
checkquestionswereincludedduringthemaintasktofilterout ErrorRatebyC-CMatching= ,
numberofallpredictionsinaspecificsituation
inattentiveparticipants.
4.6.2 AnalysisMethod. Sincethedatadidnotpassthenormal-
4.5 Participants itytest,wecomparedtwounpairedgroups(WithAIConfidence
Beforerecruiting,weperformedapoweranalysistodetermine vs.WithoutAIConfidence)viaMann-WhitneyUtestsandcom-
thenecessarysamplesizeforourtwo-groupstudyusingG*Power paredtwopairedgroups(HumanC-CMismatchedvs.HumanC-C
[19].Basedonapilotstudy,wesetthedefaulteffectsize𝑓 =0.6 Matched)viaWilcoxonSigned-Ranktests.AndweusetheSpear-
(indicatingamoderateeffect),asignificancethreshold𝛼 =0.05, mancorrelationtesttoanalyzethecorrelationbetweentheappro-
and a statistical power (1−𝛽) = 0.8, resulting in a sample size priatenessofhumanself-confidenceandtheappropriatenessof
of90.FollowingIRBapproval,participantswererecruitedfrom humanreliance.
Prolific3,meetingcriteriasuchasU.S.residencyforincomepre-
dictiontasks,over99%approvalrate,Englishfluency,atleast1000 4.7 Results
priorapprovals,anddesktopcomputeruse.Ourstudy,employing
4.7.1 EffectsofDifferentHumanConfidence-CorrectnessMatching
abetween-subjectsdesignwithoutrepeatparticipation,yielded94
(RQ1.1). Basedontheproposedframework,wecalculatedtheerror
validresponses(WithAIConfidence:50,WithoutAIConfidence:44)
ratesindifferenthuman-AIC-Cmatchingsituations.Additionally,
afterexcludinginattentiveparticipants.Demographicsincluded49
onlyconsideringhumanC-Cmatching(regardlessofwhetherAI’s
males,45females,andvariedagesandAIexpertiselevels.Incen-
confidencematcheditscorrectness),wedividedparticipants’task
tivesincludeda$1bonusforover90%accuracy.Thestudylasted
instancesintotwocategories:(1)HumanC-CMismatchedand(2)
about15minutes,payinganaverageof$10.5perhour.
HumanC-CMatched.Figure4showstheresults.
4.6 EvaluationMeasuresandAnalysis ConsideringhumanandAIC-Cmatchingtogether(Figure4left),
HumanC-CMismatched&AIC-CMatchedhasahighererrorrate
4.6.1 Measurements. Thisstudymeasurestheappropriatenessof
thanHumanC-CMatched&AIC-CMatched.Thisindicatesthat
participants’self-confidence,theappropriatenessoftheirreliance,
whentheAI’sconfidencematchesitscorrectness,amismatchin
andtheirtaskaccuracy.
humans’confidenceandcorrectnesswillleadtoincreasedincorrect
Appropriatenessofhumanself-confidence.Wemeasurethe
reliance.Additionally,resultsshowthatHumanC-CMismatched
ExpectedCalibrationError(ECE)ofparticipants’prediction,which
&AIC-CMismatched yieldsahighererrorratethanHumanC-
hasbeendescribedinEq.1.
C Matched & AI C-C Matched. It reveals that if humans and AI
Appropriatenessofhumanreliance.Weemploytwometrics:
bothmistakenlyquantifytheirconfidence,itisextremelyhard
(1)Over-Relianceand(2)Under-Reliance.
forhumanstomakeacorrectfinaldecision.Onlyfocusingonthe
NumberofincorrecthumanfinaldecisionswithincorrectAIadvice humanC-Cmatching(Figure4right),wecanseethatHumanC-C
Over-Reliance= ,
TotalnumberofincorrectAIadvice MismatchedshowcasesahighererrorratethanHumanC-CMatched.
Under-Reliance= NumberofincorrecthumanfinaldecisionswithcorrectAIadvice , ThisindicatesthatnomatterwhetherAI’sconfidencematchesits
TotalnumberofcorrectAIadvice correctness,ifthehuman’sself-confidenceisinappropriate(C-C
Basedonouranalyticalframework(seeFigure2),fortheWithAI
Mismatched),thehumanwillhavemoreincorrectreliance.
Confidencecondition,wealsocategorizeparticipants’predictions
Overall,theseresultsvalidateouranalyticalframework’sasser-
thatinitiallydisagreewithAIintodifferenthuman-AIC-CMatch-
tionthatmismatchesbetweenanindividual’sself-confidenceand
ing situations ((1) Human C-C Mismatched & AI C-C Matched,
actualcorrectnessleadtoincreasedincorrectreliance.Hence,this
(2)HumanC-CMatched&AIC-CMismatched,(3)HumanC-C
furthersupportsourinitialmotivation-Ifwecancalibratepeople’s
Mismatched&AIC-CMismatched,and(4)HumanC-CMatched&
self-confidence,wemaybeabletofurtherreducetheoccurrenceof
3www.prolific.co incorrectreliance.CHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
Error Rate in Different Confidence-Correctness Matching Situations
*
1 *
***
*
0.8
*
0.6
0.4
0.2
Human C-C Human C-C Human C-C Human C-C Human C-C Human C-C
Mismatched & AI Matched & AI C-C Mismatched & AI Matched & AI C-C Mismatched Matched
C-C Matched Mismatched C-C Mismatched Matched
Figure4:AnanalysisoferrorrateindifferenthumanandAIConfidence-CorrectnessMatchingsituations.Theleftshowsthe
fourcategoriesconsideringbothhumanandAIC-CMatching.TherightshowsthetwocategoriesonlyconsideringhumanC-C
MatchingnomatterwhetherAIisC-CMatchedornot.Errorbarsindicatestandarderrors.(*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
4.7.2 CorrelationbetweenHumanSelf-ConfidenceAppropriateness 5 STUDY2-COMPARINGTHEEFFECTSOF
andHumanRelianceAppropriateness(RQ1.2). WeintegratedWith DIFFERENTSELF-CONFIDENCE
AIConfidenceandWithoutAIConfidencedataandconductedSpear- CALIBRATIONMECHANISMS
man correlation analysis between ECE and Under-Reliance, and
Inoursecondstudy,weaimtoexplorethemechanismstocalibrate
betweenECEandOver-reliance.TheresultsindicatethatECEposi-
tivelycorrelateswithUnder-reliance(𝜌:0.404,𝑝<0.001)andOver- humanself-confidenceandassesstheirinfluenceonhumans.
reliance(𝜌:0.343,𝑝<0.01).Thesefindingshighlightthepotential
forcalibratinghumanself-confidence(loweringECE)toimprove 5.1 DesignofSelf-ConfidenceCalibration
theappropriatenessofhumanrelianceonAI. Basedonthetheoryandpracticeincognitivescienceanddecision-
making,weproposethreeself-confidencecalibrationdesigns.
ThinktheOpposite(Think).Researchsuggeststhathumans’
4.7.3 TheEffectsofShowingAIConfidence(RQ1.3,RQ1.4). Our
overconfidenceintheirpredictionsisacommonissue[18,31].This
resultsshowthatthereisnosignificantdifferencebetweenwith
oftenoccursduetobiaseslikeanchoring[20,60,67]andconfirma-
orwithoutAIconfidenceinECE.Moreover,thereisnosignificant
tionbias[58].Peopletendtofavorinformationthatsupportstheir
differenceintermsofaccuracy.ParticipantsinWithAIConfidence
views,makingitchallengingtoconsideralternativesindecision-
haveahigherUnder-RelianceandalowerOver-Reliancethanin
making[11].Toimproveself-confidencecalibration,wedesignan
WithoutAIConfidence.ThismightbebecauseshowingAIconfi-
interventioninspiredthe“pre-mortem”proposedbyKlein[32]and
dencemakesparticipantsrecognizetheuncertaintybehindAI’s
Mitchell[54].Participantsareaskedtoimagineascenariowhere
suggestions,leadingtoreducedreliance.Insummary,showingAI
theirinitialdecisionwasactuallywrong,encouragingthemtothink
confidencecannotimprovetheappropriatenessofhumans’self-
beyondtheirinitialperspective[31].Basedonthistheory,wein-
confidence,taskperformance,andrelianceappropriateness(atleast
troduce“ThinkingtheOpposite”(Figure5(a)),whereusers,before
inthispaper’ssetting).InourStudy3,weconsistentlydisplayedAI
reportingtheirself-confidence,needtorespondtotwoquestions:
confidenceintheAI-assisteddecision-makingprocess,aimingto
(1)“Whichfeaturesofthisprofilemightfavoranalternativepre-
understandhowcalibrationofhumanself-confidencewillaffectthe
diction?”and(2)“Ifyourpredictionisincorrect,whatcouldbethe
decision-makingoutcomeswhenbothhumanandAI’sconfidence
mostlikelyreasonforthat?”.Byansweringthesetwoquestions,
arepresented(sothathumanscancomparethem).
usersareexpectedtoquantifytheirconfidencemorecarefully.
ThinkinginBets(Bet)leveragesinsightsfromworksofMoore
4.7.4 Summary. Ingeneral,theresultsofStudy1showthat(RQ [55]andDuke[17],whoproposedtoadjusthumanself-confidence
1.1)HumanC-CMismatchwillleadtomorehumanincorrectre- by using “betting” to incentivize careful consideration of one’s
liance(highererrorrate),soreducingtheoccurrenceofHuman confidencelevel.Inourdesign(Figure5(b)),participantsreceivea
C-CMismatchhasthepotentialtoreducehumans’incorrectre- 200-coinbonusaccount.Theyarepromptedtodecidewhetherand
liance.Inaddition,wealsoobservedthat(RQ1.2)ECEhasastrong howmuchtheywanttobetontheirpredictionsforeachtask(i.e.,
correlationwithOver-RelianceandUnder-Reliance,whichmeans weaskthem“Wanttobet?Howmanycoinsdoyouwanttobet
thatthereductionofECEhasthepotentialtoreduceOver-Reliance onyourprediction?”),withtheiraccountbalanceadjustedbased
andUnder-Reliance.Furthermore,ourfindingsindicatethat(RQ onpredictionaccuracyandtheamountbet.Forinstance,acorrect
1.3and1.4)displayingAIconfidencedidnotresultinareduction predictionwitha10-coinbetresultsina10-coinadditiontotheir
ofECE,nordiditdirectlyenhancetaskperformanceortheappro- account,whileanincorrectpredictionwitha3-coinbetdeducts3
priatenessofhumanrelianceontheAIsystem.Giventhepotential coins.Participantsareinformedthattheircoinswillbeconvertedto
benefitsofenhancingtheappropriatenessofhumanself-confidence, bonusesatarateof200pointsto$1aftertheyfinishtheexperiment.
inthenextstudy,weproceedtodevelopmechanismsforcalibrating Notethatreal-timebalanceupdatesarenotprovidedtoprevent
humanself-confidence. participantsfromknowingthegroundtruth.“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
A B
Real-time Feedback Post-hoc Feedback
C 1
2
Figure 5: Interfaces of different self-confidence calibration conditions. (A) Think the Opposite. (B) Thinking in Bets. (C)
CalibrationStatusFeedbackcontainstwoviews,(1)real-timefeedbackduringthedecision-makingprocessand(2)post-hoc
feedbackafterabatchofdecisiontasks.
CalibrationStatusFeedback(Feedback)alignswithMoore’s orunder-confident.Ahistoricalconfidencestatusisvisuallyrep-
recommendation[55]toprovideevidence-basedassessmentsofper- resentedasacoloredblockandcontinuallyupdatedinthestatus
formanceorprobabilityforself-confidencecalibration.Toachieve bar. The second interface is an overall post-hoc feedback inter-
thisindecision-making,weintroduce“CalibrationStatusFeedback”, face(Figure5(c,right)),offeringbothanoverview(Figure5(1))
offeringtwofeedbackinterfaces.Thefirstisareal-timefeedbackin- andadetailedanalysis(Figure5(2)).Theoverviewsummarizes
terface(Figure5(c,left)),providingimmediatefeedbackaftereach theproportionsofmatch,over-confident,andunder-confident in-
prediction.Usersreceiveinformationabouttheactualanswerand stancesfrompastfeedbacksessions.Italsocalculatestheuser’s
theirself-confidencestatus,categorizedasmatch,over-confident, accuracyandaverageconfidence,providingahigh-levelsummaryCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
like“Basedonyourpastpredictions,youtendtobeover-confident”. calibrationandthenproceedstomake20calibratedpredictions.
Inthedetailedanalysissection,theuser’shistoricalpredictions Notably,theFeedbackconditionincludesanextrafeedbacksession,
aresegmentedintofivebinsbasedonconfidencedistribution.For requiringparticipantstomake20additionalpredictions.
eachbin,accuracyandaverageconfidencearecomputedandvi-
sualizedasareliabilitydiagram[5].An“ideal”reliabilitydiagram 5.5 Procedure
ispresentedforreference,depictingaccuratealignmentbetween
Participantsfollowedthisexperimentalprocess:
confidenceandaccuracytohelpusersdiscernthedisparitybetween
(1) Tutorial:Uponconsenting,participantsweregivenatutorial
theirself-confidenceand“appropriate”self-confidencelevels.Previ-
onthemeaningsandvaluerangesofattributesintheprofiletable,
ousresearchinvestigatinghumanconfidencehasstudiedreal-time
includingtheincomedistributionperattributefromthetraining
andpost-hocfeedbackseparately[22,62,72].Wecombinedthese
dataset. Understanding was verified via qualification questions,
two feedback types for two reasons. First, using only real-time
allowingonlythosewithcorrectanswerstoproceed.
feedbackmightlimitparticipantstorememberingtheirmostrecent
(2) Familiarizationtask:Participantsthencompletedthefirst
confidencelevels,makingithardforthemtohaveacomprehen-
10taskstofamiliarizethemselveswiththetasknature,without
siveunderstandingandrecalloftheirconfidencestatusacrossthe
groundtruthinformationorcalibration.
entire20taskinstances.Second,relyingsolelyonoverallfeedback
(3) CalibrationMechanismTutorial:Participantslearnedabout
couldobscurewhichinstancesleadtoover-orunder-confidence.
theirassignedcalibrationmechanism.IntheThinkandBetcondi-
Whilethiscombinationmaynotbeperfect,weencouragefurther
tions,theyexperimentedwithacalibrationinterface.IntheFeed-
explorationofmoreeffectivefeedbackdesigns.
backcondition,theyparticipatedinafeedbacksession.TheControl
5.2 Conditions conditionskippedthisstep.
(4) MainTask:Movingtothemaintask(20cases),participants
Inthisbetween-subjectsstudy,tominimizepotentialinterference,
expressedtheirconfidenceusingtheexperimentalinterface,cal-
allparticipantsaretaskedwithmakingpredictionswithoutAIassis-
ibrationincludedornot.Thesessionincorporatedtwoattention
tance.Participantsarerandomlyassignedtooneoffourconditions:
checkstoensuredataquality.
• ThinktheOpposite(Think):Inthemaintask,participants (5) ExitSurvey:Participantsconcludedwithasurvey,providing
madetheirdecisionswiththeThinktheOppositeinterface(Figure feedbackontheirexperience.
5(a)).Beforeindicatingtheirconfidence,participantshadtothink
offeatures/attributesthatmightmaketheactualanswercontrary 5.6 Participants
totheirinitialpredictionandgivetheirreasons.
Beforerecruitingparticipants,wecalculatedtherequiredsample
• ThinkinginBets(Bet):UsingtheThinkinginBetsinterface
sizeviaapoweranalysisforthefourgroupsusingG*Power[19].
(Figure5(b))inthemaintask,participantswereinvitedtobeton Wesetthedefaulteffectsize𝑓 =0.25(indicatingamoderateeffect),
theirpredictions(0-10coins)beforeindicatingtheirconfidence. asignificancethreshold𝛼 =0.05,andastatisticalpower(1−𝛽)=
• CalibrationStatusFeedback(Feedback):Participantsfirsten-
0.9.Thisyieldedanecessarysamplesizeof232participants.After
gagedinafeedbacksessionwiththeCalibrationStatusFeedback
obtaininginstitutionalIRBapproval,werecruitedparticipantsfrom
interface(Figure5(c)),andsubsequentlymoveontothemain
Prolific3.Afterexcludingthosewhofailedtheattentioncheck,we
task(withoutfeedbackanymore).
got241validresponses(Think:57,Bet:67,Feedback:55,Control:
• Control:Nocalibrationisappliedinthemaintask.Participants
62).Amongtheseparticipants,117self-reportedasmales,120as
justmadetheirdecisionsandindicatedtheirconfidence.
females,and4asnon-binary.Atotalof35participantswereaged
18-29,74aged30-39,48aged40-49,48aged50-59,and36aged
5.3 ResearchQuestions
over59.Participantsalsoself-ratedtheirknowledgeofartificial
FocusingonthemainresearchquestionRQ2:Howcanhumans’ intelligence:20hadnoknowledge,176knewbasicAIconcepts,
self-confidence be calibrated and how will different self- 38hadusedAIalgorithms,and7wereAIexperts.Toincentivize
confidencecalibrationmechanismsaffecthumans’percep- high-qualitywork,participantsreceiveda$1bonusiftheiroverall
tionsanduserexperience?,weraisetwosub-questions: accuracyexceeded90%.Thestudylastedapproximately20minutes,
- RQ2.1:Howwilldifferentself-confidencecalibrationmecha- withparticipantsearninganaveragewageofabout$11perhour.
nismsaffecthumans’taskperformanceandtheappropriateness
oftheirself-confidence? 5.7 EvaluationMeasuresandAnalysis
- RQ2.2:Howwilldifferentself-confidencecalibrationmecha-
5.7.1 Measurements. Inthisstudy,weassessboththeappropriate-
nismsaffecthumans’perceptions(e.g.,perceivedself-confidence
nessofhumanself-confidenceandtheirexperience.
appropriateness,performance,andcomplexity)anduserexperi-
Fortheappropriatenessofhumanself-confidence,asinstudy1,we
ence(e.g.,mentaldemand,preference,andsatisfaction)?
measureECE.Wealsomeasureparticipants’Over-confidentRatio
andUnder-confidentRatiotogainanuancedunderstanding.
5.4 TaskandAIModel
In this study, we continue to employ income prediction as our Over-ConfidentRatio= Numberofincorrecthumanpredictionswithhighconfidence ,
decisiontask,similartoStudy1.Weselected10+20taskinstances, Totalnumberofhumaninitialpredictions
followingthedataselectioncriteriaestablishedinStudy1.Each
Numberofcorrecthumanpredictionswithlowconfidence
participant,ineverycondition,firstprovides10predictionswithout Under-ConfidentRatio= ,
Totalnumberofhumaninitialpredictions“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
Foruserperceptionsanduserexperience,weemployandadaptthe 5.8.2 EffectsonHumanPerceptionsandUserExperience(RQ2.2).
followingmetricsona7-pointLikertscale(1:StronglyDisagree,7: Figure 7 shows the effects of different calibration interfaces on
StronglyAgree).Exceptfortheperceivedappropriatenessofself- participants’perceptionsanduserexperience.Wefoundthatpar-
confidence,theotherquestionshavebeenvalidatedbypreviousAI- ticipantsperceivedtheirself-confidencetobemoreappropriate
assisteddecision-makingresearch.Wemadenecessaryadaptations inControlthaninThinkandFeedback,whichisveryinteresting
to some items based on our specific scenario. For example, we as this subjective result differs from the actual appropriateness
replaced the word “system” in the scale used in previous work oftheirself-confidence(inControl,theappropriatenessofhuman
with“thedecision-makingprocesswiththeinterface”(becauseour self-confidenceistheworst).Fromthisresult,wecanfindthat
experimentalinterfacecannotbecalledasystem). participantshaveanunreliableperceptionoftheirself-confidence
withoutcalibration(inControl).Thisalsofurtherhighlightsthe
• Perceivedappropriatenessofself-confidence:"Ithinkmyself-confidence
necessitytocalibratepeople’sself-confidence.
wasappropriate(beingabletoreflecttheactualcorrectnesslikeli-
Inaddition,participants’mentaldemandsandperceivedcom-
hoodofmypredictionsaccurately)."
plexityoftheinteractionweresignificantlyhigherinThinkthanin
• Perceivedperformance[33,74,76]:"Iperformedwellinthisincome
otherconditions.Possiblereasonsarethatweaskedpeopletothink
predictiontask."
abouttheproblemfromasecondperspective(i.e.,theopposite)and
• Mentaldemand[7,21,26]:"Ifoundthistaskmentallydemanding."
askedpeopletoidentifyfeaturesthatmightleadtooppositeresults
• Perceivedcomplexity[7]:"Thedecision-makingprocesswiththe
andgivereasonsforthem.Thiscomplexprocessbroughtmore
interfacewascomplex."
consumptionofcognitiveresourcestotheparticipants,sotheyfelt
• Preference[7,37,43,69,87]:"Ilikedthedecision-makingprocess
thattheconditionwasmorecomplexandmentallydemanding.Fur-
withthisinterface."
thermore,wefoundatrendthatThinkledtolowerpreferenceand
• Satisfaction[7,21]:"Iwassatisfiedwiththedecision-makingpro-
satisfactionthanotherconditions.Thismaybebecausepeopleare
cess."
usedtoadoptingheuristicsforquickthinking[31]andforcingthem
toanalyticallythinkaboutoppositesmightchangepeople’susual
5.7.2 AnalysisMethod. Basedonnormalitytests,wefoundmost
wayofthinking,increasethedifficultyofdecision-making,andlead
ofthecollecteddatadidnotfollowanormaldistribution.Therefore,
toaworseuserexperience.Thisfindingisconsistentwithexisting
weemployedKruskal–WallistestswithBonferronicorrection.
workshowingthatcognitiveforcingfunctions,althoughmaking
peoplethinkmorecarefully,alsodegradedtheuserexperience[7].
5.8 Results
Moreover,comparedtoControlcondition,BetandFeedbackdidnot
5.8.1 EffectsonTaskPerformanceandtheAppropriatenessofSelf- leadtoaworseuserexperience.
Confidence(RQ2.1). Figure6showstheeffectsofdifferentcali-
brationinterfacesbeforecalibration(inthefirst10familiarization
tasks)andwithcalibration(inthelast20maintasks).Sincethese 5.8.3 AComprehensiveComparisionofDifferentCalibrationMech-
twobatchesinvolveddifferenttasksamples,weanalyzedthepartic- anisms. Wealsowanttoanalyzethepros,cons,andapplicabilityof
ipants’accuracyandECEinthefirst10andlast20tasksseparately. ourproposedthreeconfidencecalibrationmechanisms(asshownin
Inthefirst10familiarizationtasks(Figure6(a)),wefoundthat Table2).Ageneralconclusionisthattheremaynotbeaperfectcal-
therewasnosignificantdifferenceinaccuracyandECEbetween ibrationmechanism.Specifically,fromtheaforementionedresults,
thefourconditionsbeforecalibration.However,inthemaintask, wecanseethatThinkiseffectiveforimprovingtheappropriateness
withdifferentcalibrations,participants’accuracyandECEwere ofparticipants’self-confidencebutitdamagesparticipants’user
significantlydifferent(Figure6(b)).Specifically,foraccuracy,par- experience.AndsinceThinkrequiresextrainvestmentofcognition
ticipantsinThink,Bet,andFeedbackperformedsignificantlybetter resources,itismoresuitableforhigh-stakestasksandmightnot
thaninControlcondition.Thisrevealsthatthecalibrationmecha- be appropriate for “quick decision-making tasks” that are time-
nismitselfcanleadtoimprovedtaskperformancecomparedtono limited.Besides,althoughwecanobserveatrendforBettoreduce
calibration.Thereasonmightbethatcalibrationmobilizesmore over-confidence(notsignificantly),itisineffectiveinimproving
cognitiveresources,makespeoplethinkmorecarefully,andre- theoverallappropriatenessofhumanself-confidence.Anddespite
duceserrorscausedbyinsufficientthinking.ForECE,weobserved thattheincentive“betting”mechanismisinteresting,itcanbedif-
thatbothThinkandFeedbackhelpedparticipantsmaintainamore ficulttoapplytocertainseriousdecision-makingtasksinwhich
calibratedself-confidencecomparedtoControl.Buttherewasno theincentivemechanismcannotbeestablished.What’smore,al-
significantdifferencebetweenBetandControl.Thisresultreveals thoughFeedbackcaneffectivelyimprovetheappropriatenessof
thatalthoughseeminglypromising,Betwasnoteffectiveenoughto humanself-confidencewithoutleadingtoaworseuserexperience,
calibrateparticipants’self-confidence(perhapsthelossof“coins”is itcancostmoretimeduetothefeedbacksession.Andthefeedback
notmotivatingenough).Moreover,wedidnotfindanysignificant sessionisonlyfeasiblewhengroundtruthdataisaccessible.
differencesamongdifferentconditionsintermsofOver-Confident Overall,ontheonehand,werecommenddesignerschoosea
RatioandUnder-ConfidentRatio.However,wecanobservea suitablecalibrationmechanismbasedonthespecificgoalandtask
trendthatThinkandBet mightleadtolessover-confidenceper- property.Forexample,iftheonlypurposeistoreducehumans’
hapsbecauseparticipantsinthesetwoconditionswereguidedto over-confidenceandtheincentivemechanismcanbeestablished,
thinkof“theopposite”or“possibilityoffailure”,whichledtomore Betmightbeagoodchoice.Ontheotherhand,designersshouldnot
seriousquantificationoftheirconfidence. onlyfocusontheeffectivenessofconfidencecalibrationbutalsoCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
Accuracy and ECE before Calibration Accuracy and Self-Confidence Appropriateness with Calibration
1 1 *
0.9 0.9 ***
0.8 0.8 *
0.7 0.7 Think
0.6 0.6
0.5 0.5 Bet
0.4 0.4 * Feedback
00 .. 23 00 .. 23 ** Control
0.1 0.1
0 0
Accuracy ECE Accuracy ECE Over-Confident Ratio Under-Confident Ratio
𝜒2 4.036 3.403 𝜒2 19.686 12.167 5.583 5.681
𝒑 0.258 0.334 𝒑 < 0.001 0.007 0.134 0.128
(a) (b)
Figure6:Effectsofdifferentcalibrationconditionsonparticipants’accuracyandtheappropriatenessoftheirself-confidencein
differentconditions.(a)Participants’accuracyandECEbeforecalibration(inthefirst10familiarizationtasks).(b)Participants’
accuracy,ECE,Over-ConfidentRatio,andUnder-ConfidentRatiointhemaintaskswithcalibration.Errorbarsindicatestandard
errors.(*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
Participants' Perceptions and User Experience
7
* ***
6 * **** *** * *
5 ***
Think
4
Bet
3
Feedback
2 Control
1
0
Perceived Appropriateness Perceived Performance Mental Demand Perceived Complexity Preference Satisfaction
𝜒2 12.275 3.267 16.374 27.250 10.033 9.955
𝒑 0.006 0.352 0.001 < 0.001 0.018 0.019
Figure7:Participants’perceptionsandself-reporteduserexperienceindifferentconfidencecalibrationconditions.Errorbars
indicatestandarderrors.(*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
Table2:Summaryofthepros,cons,andapplicabilityofthethreecalibrationmechanisms.
Pros Cons Applicability
Effectiveforimprovingtheoverall
Think appropriatenessofhuman Notsuitablefor“quick”
Decreasinguserexperience
Opposite self-confidence;Improvinghuman decision-making
taskperformance
(Potentially)Effectiveforreducing Ineffectiveinimprovingtheoverall Theincentive“betting”mechanism
Thinking
over-confidence;Improvinghuman appropriatenessofhuman isdifficulttoapplyincertain
inBets
taskperformance self-confidence decision-makingtasks
Effectiveforimprovingtheoverall
Calibration Requiringaccesstosometask
appropriatenessofhuman Costingmoretime(duetothe
Status sampleswithgroundtruthfor
self-confidence;Improvinghuman feedbacksession)
Feedback designingthefeedbacksession.
taskperformance
takethepotentialnegativeeffectsonuserexperienceintoconsider- 5.8.4 Summary. Thisexperimentcomparedtheeffectsofthree
ation.Inthispaper’stask,sinceitiseasytoaccessthetrainingdata calibration mechanisms on people’s task performance and self-
withgroundtruth,consideringboththeeffectivenessofconfidence confidenceappropriateness,aswellastheirimpactsonusers’per-
calibrationandtheharmlesseffectsonuserexperience,wechose ceptionsanduserexperience.Theexperimentalresultsrevealthe
FeedbackasourcalibrationmechanisminStudy3tofurtherexplore advantagesanddisadvantagesofdifferentcalibrationmechanisms
itseffectsinAI-assisteddecision-making. andprovidedesignerswithinsightsintothedesignandselectionof“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
calibrationstrategies.Wefoundthattheproposedself-confidence demotaskstobecomefamiliarwiththetaskprocessandthendi-
calibrationcanimprovehumans’taskperformancecomparedtothe rectlyengagedinthemaintasksession.Duringthemaintask,all
controlcondition,butnotallcalibrationmechanismscanimprove participantsfirstmadetheirinitialpredictions(andindicatedtheir
theappropriatenessofhumanself-confidence(RQ2.1).Also,Think confidence),thensawAI’ssuggestionswithconfidence,andfinally
ledtoparticipants’worseuserexperiencebutFeedbackandBetdid madetheirfinaldecisions.
notdecreaseuserexperience(RQ2.2).
6.5 Participants
6 STUDY3-INVESTIGATINGTHEEFFECTSOF Wefirstcalculatedtherequiredsamplesizeviaapoweranalysisfor
HUMANSELF-CONFIDENCECALIBRATION thetwogroupsusingG*Power[19].Wesetthedefaulteffectsize
ONAI-ASSISTEDDECISIONMAKING 𝑓 =0.6(indicatingamoderateeffect),asignificancethreshold𝛼 =
0.05,andastatisticalpower(1−𝛽)=0.8.Thisyieldedanecessary
Ourthirdstudyaimstoexploretheeffectsoftheintroductionof
samplesizeof90participants.AfterobtaininginstitutionalIRB
self-confidencecalibrationonAI-assisteddecision-making.
approval,werecruitedparticipantsfromProlific3.Throughoutthe
experiment,weincluded2attention-checkquestions.Afterfiltering
6.1 ResearchQuestion
datafrominattentiveparticipants,117validresponsesremained
FocusingonourmainresearchquestionRQ3:Howwillcalibra- (Calibration:57,NoCalibration:60).Amongtheseparticipants,57
tionofhumans’self-confidenceaffecttheappropriateness self-reported as males, 55 as females, and 5 as non-binary. Age
oftheirrelianceonAI’ssuggestionsandtaskperformance?, distribution included 20 participants aged 20-29, 35 aged 30-39,
wespecificallyaskthefollowingsub-questions. 18aged40-49,26aged50-59,and18agedover60.Participants’
self-ratedknowledgeofartificialintelligencevaried,with7having
- RQ3.1:Howwillthecalibrationofhumanself-confidenceaffect
noknowledge,76knowingbasicAIconcepts,20havingusedAI
humans’reliancebehaviors?
algorithms,and14beingAIexperts.Toincentivizehigh-quality
- RQ3.2:Howwillthecalibrationofhumanself-confidenceaffect
work,participantsreceiveda$1bonusinadditiontothebasepay-
theappropriatenessofhumanrelianceonAIsuggestions(e.g.,
mentiftheiroverallaccuracyexceeded90%.Theentirestudylasted
over-reliance,under-reliance)?
approximately20minutes,withparticipantsearninganaverage
- RQ3.3:Howwillthecalibrationofhumanself-confidenceaffect
wageofabout$12perhour.
humans’taskperformance?
6.6 EvaluationMeasuresandAnalysis
6.2 TaskSetup
6.6.1 Measurements. Wemeasureparticipants’self-confidenceap-
ThetasksetupmirrorsStudy1andStudy2,employingincome
propriateness,reliance,taskperformance,andrelianceappropriate-
predictionasthedecision-makingtask.
ness.Forself-confidenceappropriateness,weusethesamemetrics
asusedinStudy1and2.
6.3 Conditions
Forreliance,wecollectthefollowingmeasures:
Thisstudydelvesintotheeffectsofhumanself-confidencecalibra-
tionwhencollaboratingwithanAImodelthatdisplaysitsconfi- Agreementfraction= NumberoffinaldecisionssameastheAIsuggestion ,
dence,guidedbytwoconsiderations.First,mostcontemporaryAI Totalnumberofdecisions
NumberofdecisionsuserswitchedtoagreewiththeAImodel
modelsarecapableofgeneratingprobabilityestimations,i.e.,con- Switchfraction= ,
Totalnumberofdecisionswithinitialdisagreement
fidencelevels,makingitacommonandfeasiblepractice.Second,
Followhighconfidencefraction=
revealingAIconfidenceisawidelyrecognizeddesignchoiceforcal- Numberoftaskswhereuserfollowedthepredictionwithhighercondfidence
,
ibratinghumantrustinAI-assisteddecision-making[2,67,90,91]. Totalnumberofdecisionswithinitialdisagreement
Therefore,wefocusonscenarioswhereAIconfidenceispresented. Fortaskperformance,wecalculateparticipants’initialaccuracy
Underthissetting,weexploretwoconditions: (beforeseeingAIsuggestions)andfinalaccuracy(afterseeingAI
suggestions).
• With Calibration: This condition applies Calibration Status
Additionally,basedonouranalyticalframework,wecalculate:
Feedbacktocalibrateparticipants’self-confidence.
• NoCalibration:Inthiscondition,wedonotapplyanyconfi- - DistributionofdifferentC-CMatching:Wecalculatetheratio
dencecalibrationmechanismstoparticipants. of different human and AI C-C Matching when human initial
predictionsdisagreewithAIsuggestions:
6.4 Procedure NumberofpredictionsinaspecificC-CMatchingsituation
,
Thisbetween-subjectsexperimentrandomlyassignedparticipants Totalnumberofdecisionswithinitialdisagreement
- Errors caused by different C-C Matching: We calculate the
toeithertheCalibrationorNoCalibrationconditions.Uponen-
occurrenceofincorrecthumanfinalpredictionscausedbythese
teringtheexperimentalinterface,participantsunderwentatutorial
fourtypesofC-CMatching:
tofamiliarizethemselveswiththetask,whichincludedqualifica-
tionquestionstoensuretheygraspedkeytaskknowledge.Inthe
NumberofincorrectfinaldecisionsinaspecificC-CMatchingsituation
,
Calibrationcondition,participantsthenproceededtoaFeedback Totalnumberofdecisions
sessionforconfidencecalibrationbeforeenteringthemaintask Forrelianceappropriateness,asStudy1,weassessUnder-Reliance
session.ParticipantsintheNoCalibrationconditionstartedwith andOver-Reliance.Following[29],wealsomeasureAccuracy-widCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
(accuracywithinitialdisagreement),astringentmetricforevalu- Human Reliance Behavior
atingtheappropriatenessofhumanrelianceonAI.Thismeasure 0.9 *
focusesonwhetherindividualscanmakecorrectdecisionswhen 0.8
0.7
initiallydisagreeingwithAIrecommendations,thusofferinganas- 0.6
0.5
sessmentmoreindependentofhumaninitialaccuracy.Incontrast, 0.4 Calibration
Under/Over-Reliancedoesnotaccountfortheinitialcorrectness 00 .. 23 No Calibration
ofhumanjudgments(e.g.anincorrectinitialhumanprediction 0.1
0
followedbyacceptanceofanincorrectAIsuggestionisstilldeemed Agreement Fraction Switch Fraction Follow Higher Confidence
in Disagreement
over-reliance).Inotherwords,Under/Over-Relianceismorelikely
𝑼 1958.0 1694.5 2126.0
tobeaffectedbyhumans’independenttaskperformance. 𝒑 0.173 0.932 0.022
Numberofcorrectfinaldecisionswithinitialdisagreement
Accuracy-wid= , Figure9:HumanreliancebehaviorsinCalibrationandNo
Totalnumberofdecisionswithinitialdisagreement
Calibrationconditions.Errorbarsindicatestandarderrors.
6.6.2 AnalysisMethod. Fortheanalysis,sincedatadidnotpass (*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
thenormalitytest,weusednon-parametertests.Specifically,we
compared two unpaired groups via Mann-Whitney U tests and
comparedtwopairedgroupsviaWilcoxonSigned-Ranktests. especially when both human and AI’s confidence is calibrated,
thisresultsuggeststhatthecalibrationofpeople’sself-confidence
6.7 Results promotesamorerationalutilizationoftheconfidenceinformation.
Appropriateness of Human Reliance
Appropriateness of Human Self-Confidence
0.7
0.25 *** 0.6
0.2 0.5
0.4
0.15 * Calibration
Calibration 0.3 No Calibration
0.1 No Calibration 0.2
0.05 0.1
0
0 Under-Reliance Over-Reliance Accuracy-wid
ECE Over-Confident Ratio Under-Confident Ratio
𝑼 1350.5 1505.0 1983.0
𝑼 1051.0 1388.5 1534.5 𝒑 0.047 0.247 0.136
𝒑 < 0.001 0.077 0.335
Figure10:Theappropriatenessofhumanreliance.Errorbars
Figure8:Manipulationcheckresults:theappropriateness
indicatestandarderrors.(*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
ofhumanself-confidenceinCalibrationandNoCalibration
conditions.Errorbarsindicatestandarderrors.(*:𝑝<0.05;
**:𝑝<0.01;***:𝑝<0.001)
6.7.3 EffectsontheAppropriatenessofHumanReliance(RQ3.2).
ResultsrevealthatparticipantsintheCalibrationconditionex-
hibitedsignificantlylowerUnder-Reliance thanthoseintheNo
6.7.1 ManipulationCheck. First,wewanttoverifywhether,in Calibrationcondition(Figure10).However,nosignificantdiffer-
theCalibrationcondition,participants’self-confidenceintheir enceisobservedintermsofOver-RelianceandAccuracy-wid.This
initialpredictionsactuallygetscalibrated.AsshowninFigure8, meansthatcalibratingpeople’sself-confidenceonlyimprovesthe
Mann-WhitneyUtestsrevealthatintheCalibrationcondition, appropriatenessofpeople’srelianceinsomeaspectsbutnotall.We
participants’ECEscoreissignificantlylowerthanthatintheNo willfurtheranalyzethepossiblereasonsintheDiscussion(Sec7.3).
Calibrationcondition.Itrevealsthatparticipants’overallaccuracy
6.7.4 EffectsonTaskPerformance(RQ3.3). Figure11presentspar-
and confidence are better matched given calibration. Although
ticipants’taskperformance(theirinitialaccuracyandfinalaccuracy
whenanalyzedseparately,nosignificantimprovementsarefound
inthetwoconditions).Mann-WhitneyUtestsshowedthatboth
inOver-ConfidentRatioandUnder-ConfidentRatio,notabledecrease
participants’initialandfinalaccuracyintheCalibrationcondition
trendscanbeobserved.Theseresultsconfirmtheeffectivenessof
surpassedthoseintheNoCalibrationcondition.
ourmanipulation.
Notably,intheCalibrationcondition,participants’finalaccu-
6.7.2 EffectsonHumanRelianceBehaviors(RQ3.1). Thecalibration racyoutperformedboththeaccuracyofAIalone(0.75)andtheir
ofhumanself-confidencedidnotleadtosignificantdifferencesin initialaccuracy.Incontrast,intheNoCalibrationcondition,nei-
terms of Agreement Fraction and Switch Fraction (see Figure 9). therparticipants’initialorfinalaccuracyoutperformedAIalone.It
However,weobservedthatwhentheirinitialpredictionsdiffered indicatesthepotentialofself-confidencecalibrationforachieving
fromAI’ssuggestions,participantsintheCalibrationcondition complementaryteamperformance[2,71].WenotethatWilcoxon
moreoftenfollowedthemember(humanorAI)whohadhigher Signed-Ranktestsdidnotshowstatisticallysignificantdifferences
confidencecomparedtothoseintheNoCalibrationcondition. betweenparticipants’initialandfinalperformanceintheCalibra-
Sincehigherconfidencecanreflectahighercorrectnesslikelihood tioncondition.However,thenon-significancedoesnotmeanthat“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
Task Performance resultsinparticipants’reliancebehavior(Sec.6.7.2),calibratingself-
0.85 confidencemakesparticipantsactmorerationally(relyingmore
** * ontheonewhoholdshigherconfidence).WhenAIC-CMatched,
0.8
the AI gives correct recommendations with high confidence or
AI Accuracy
0.75
Calibration incorrectrecommendationswithlowconfidence,followinghigh
0.7 No Calibration confidencewillleadtoahigherlikelihoodtobecorrect.Onthe
0.65 contrary,whenAIC-CMismatched,theAIgivescorrectrecommen-
0.6 dationswithlowconfidenceorincorrectrecommendationswith
Initial Accuracy Final Accuracy highconfidence.Atthistime,followinghighconfidencewilllead
𝑼 2260.0 2159.0 tomoreerrors.However,it’simportanttorecognizethatwhen
𝒑 0.003 0.013
an AI’s confidence is accurately calibrated, instances of AI C-C
MatchedwillsignificantlyoutnumberthoseofAIC-CMismatched.
Figure11:Humans’initialandfinalperformance.Errorbars
Therefore,calibratinghumanself-confidenceaccordinglyshould
indicatestandarderrors.(*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
resultinmorebenefitsthandrawbacks.
6.7.6 Summary. Ingeneral,calibratingpeople’sself-confidence
makespeopleactmorerationallywhenonlyconfidenceinforma-
participantsdidnotpayattentiontoAIsuggestions.Fromthepar-
tionexists(RQ3.1).However,confidencecalibrationonlyreduced
ticipants’SwitchFraction(thefractionofcaseswhereparticipants
under-relianceinoursetting(RQ3.2).Furthermore,self-confidence
changed their initial predictions after seeing AI’s recommenda-
calibrationimprovespeople’sinitialaccuracyandfinalaccuracy
tion)inFigure9,wecanseethatparticipantschangedtheirviews
(RQ3.3).Adetailedanalysisshowsthattheperformanceimprove-
27%ofthetimewhentheydisagreedwiththeAI’sviews.This
mentmaybeduetothereducedoccurrenceofC-CMismatchedand
indicatesthatparticipants’decisionswereinfluencedbyAI’srec-
thecorrespondingerrorsonthehumanside.Additionally,wefound
ommendation.Thereasonbehindthenon-significanceinaccuracy
whenAIC-CMatched,thecalibrationofhumanself-confidence
improvementmaybethatself-confidencecalibrationalsoimproves
significantlyreducedtheerrorrate.Wealsodiscoveredwhenthe
theirinitialperformance(similarfindingscanbeseeninStudy2).
confidenceoftheAIdoesnotmatchitscorrectness,thecalibration
Theimprovedinitialperformanceandreducedinappropriatereliance
ofhumanconfidencehasanegativeeffect.Therefore,morefuture
onAImightjointlyactonparticipants’improvedfinalperformance.
workisneededtospecificallyaddressthisissue.
Sincetheparticipants’initialperformance(𝑀 = 0.78,𝑆𝐷 = 0.11)
wasalreadyhigherthanAI(0.75),itwasdifficulttoachievefurther 7 DISCUSSION
significantimprovementsinfinalperformanceafterworkingwith
Thispaperunderscoresthepivotalroleoftheappropriatenessofhu-
anAIassistantwithslightlyloweraccuracy.
manself-confidenceinAI-assisteddecision-making.Ourproposed
analyticalframeworkintegratestheconfidence-correctnessmatch-
6.7.5 EffectsontheDistributionofDifferentDisagreementsand
ingfrombothhumanandAIperspectives.Throughthisframework,
Errors. Basedontheproposedanalyticalframework,wefurther
wedelveintothecausesofhumans’inappropriaterelianceandan-
digintotaskperformance.Figure12(a)displaysthedistributionof
alyzethepotentialofcalibratinghumanself-confidence.
differentC-CMatchingsituationswhenhuman-AIdisagreements
Ourresearchcomprisesthreeconsecutiveempiricalstudiescen-
occurred.IntheCalibrationcondition,theHumanC-CMismatched
teredonunderstandingtheeffectsofself-confidencecalibration
&AIC-CMatchedsituationissignificantlylowerthanintheNo
in AI-assisted decision-making. The first study investigates the
Calibrationcondition.Additionally,thereisatrendindicatinga
relationshipbetweenhumanself-confidenceappropriatenessand
higherHumanC-CMatched&AIC-CMatchedintheCalibration
theappropriatenessoftheirreliance,emphasizingthesignificance
conditioncomparedtothatintheNoCalibrationcondition.These
ofimprovinghumanself-confidenceappropriatenessindecision-
findingssuggestthatcalibratinghumanself-confidencealignshu-
making.Buildinguponcognitivesciencetheories,thesecondstudy
manconfidencemorecloselywiththeiractualcorrectness,reducing
proposesthreecalibrationmechanisms,empiricallyassessingtheir
mismatchesoccurringfromthehumanside.
impactonself-confidenceappropriatenessanduserexperience.Fol-
Figure12(b)showsadetailedanalysisoftheoccurrenceofer-
lowingthis,thethirdstudyincorporatesthecalibrationofhuman
rorscausedbydifferentC-CMatchingsituations.Wecanseea
self-confidenceintotheAI-assisteddecision-makingprocess,un-
significantreductioninerrorscausedbyHumanC-CMismatched&
coveringitsadvantagesaswellasitslimitations.Inthissection,
AIC-CMatchedintheCalibrationconditioncomparedtotheNo
wedelveintoacomprehensivediscussionofourprincipalfindings
Calibrationcondition.ThisindicatesthatwhileAI-sideerrorsre-
andofferinsightsintodesignimplications.
mainuncontrollable,humanself-confidencecalibrationeffectively
reduceserrorsoriginatingfromthehumanside.
7.1 InappropriateReliance:Over/Under-Trust
Wefurthercategorizeparticipants’decisionsonlybasedonthe
inAIORUnder/Over-ConfidentinOneself?
C-CMatchingoftheAIside(Figure13).Wefindthatintaskcases
whereAIC-CMatched,Calibrationresultsinsignificantlyfewer PreviousstudiesonAI-assisteddecision-makinghaveoftenfocused
errorratescomparedtoNoCalibration.Conversely,intaskcases oncalibratingpeople’strustinAIwhenpromotingappropriate
whereAIC-CMismatched,Calibrationleadstosignificantlymore reliance[2,90,91].Theyattributethatover-relianceonAIstems
errorsthanNoCalibration.Thereasoncanbetiedbacktothe from over-trusting AI, while under-reliance on AI results fromCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
Distribution of Different C-C Matching Situations Occurrence of Errors Caused by Different C-C Matching Situations
0.6 0.1
**
0.5 0.08
0.4
* 0.06
0.3
0.04 Calibration
0.2
No Calibration
0.1 0.02
0 0
Human C-C Human C-C Human C-C Human C-C Human C-C Human C-C Human C-C Human C-C
Mismatched & AI C- Matched & AI C-C Mismatched & AI C- Matched & AI C-C Mismatched & AI C- Matched & AI C-C Mismatched & AI C- Matched & AI C-C
C Matched Mismatched C Mismatched Matched C Matched Mismatched C Mismatched Matched
𝑼 1263.5 1838.0 1715.5 2053.0 𝑼 1251.0 1733.5 1738.5 1401.0
𝒑 0.014 0.470 0.976 0.061 𝒑 0.008 0.879 0.867 0.052
(a) (b)
Figure12:AdetailedanalysiscomparingCalibrationandNoCalibrationbasedontheproposedanalyticalframework.(a)The
distributionofdifferenthuman-AIC-CMatchingsituations.(b)Theoccurrenceoferrorcausedbydifferenthuman-AIC-C
Matchingsituations.Errorbarsindicatestandarderrors.(*:𝑝<0.05;**:𝑝<0.01;***:𝑝<0.001)
Error Rate Categorized by AI C-C Matching perspectives,cancomplementexistingresearch,offeringanew
0.8 * viewpointtocomprehendthebasisofinappropriatereliance.
0.7
0.6
0.5 ** 7.2 RationalReliancewithLimitedInformation
0.4 Calibration InAI-assisteddecision-making,wheregroundtruthremainsun-
0.3 No Calibration
knowntobothhumansandAI,it’scrucialtomakenuancedreliance
0.2
0.1 decisionsbasedoncalibratedconfidence[25,90].Whenfacedwith
0 disagreementsandaccesstoconfidencelevelsfrombothparties,
AI C-C Matched AI C-C Mismatched
adoptingthesuggestionofthehigher-confidencepartyisarational
𝑼 1161.5 1015.5
𝒑 0.002 0.018 choice,asourproposedcalibrationconditionssuggest.However,
it’sessentialtoacknowledgethatthisrationalbehaviordoesn’t
Figure13:AdetailedanalysisoferrorratewhenAI’sconfi- consistentlyleadtomoreaccuratedecisions.Study3,forinstance,
denceinapredictionmatchestheprediction’scorrectness(AI yieldedmixedoutcomes.Whilecalibratinghumanself-confidence
C-CMatched)andwhenAI’sconfidenceinapredictionmis- reducederrorratessignificantlywhenAIC-CMatched,errorrates
matchestheprediction’scorrectness(AIC-CMismatched). increasedsubstantiallyincasesofAIC-CMismatched.Unfortu-
Errorbarsindicatestandarderrors.(*:𝑝 <0.05;**:𝑝 <0.01; nately,AIC-CMismatchedcannotbeeliminatedevenwhenAI’s
***:𝑝<0.001) confidenceiswell-calibrated.Thus,addressingpeople’sreliance
inAIC-CMismatchnecessitatesanapproachbeyondhumanself-
confidencecalibration,potentiallyinvolvingeducatingindividuals
aboutAIerrorboundariestomakemorenuancedjudgments[1].
under-trustingAI.However,wearguethatthisattributionover-
simplifiestheissuewithoutadequatelyconsideringtheconfidence 7.3 TheComplicatedRelationshipbetweenthe
factorfromthehumanperspective.
AppropriatenessofSelf-Confidenceandthe
Weproposethatinappropriatereliancecanarisefrombothinap-
AppropriatenessofReliance
propriatetrustinAIandinappropriateconfidenceinoneself.Forin-
stance,whenpeopleadoptanincorrectsuggestionfromAI,itmight InStudy3,wefoundthatcalibratinghumanself-confidencereduces
beduetobothover-trustingAIandbeingunder-confident.The under-reliancebutdoesn’tsignificantlyimpactover-relianceand
reasonsforthesetwobehaviorsdiffersignificantly.Over-trusting accuracy-wid.Wepositthreepossiblereasonsforsuchinsufficient
AImightresultfromautomationbias[13]orbeinfluencedbycer- improvement.First,whilecalibratinghumanself-confidenceim-
tainelements/informationofAI,suchasstatedaccuracy[89],high provesitsappropriateness,theextentofimprovementfallsshort.
confidencelevels[90],orseeminglyconvincedexplanations[2]. ThisisevidentinFigure8,wheretheOver-ConfidentRatio and
Ontheotherhand,under-confidenceinoneselfmightstemfrom Under-Confident Ratio in the Calibration condition only show
insufficient task expertise, recent task failures, incomplete task trends towards decrease but lack statistical significance. There-
information,orotherpsychologicalfactors[57].Byconducting fore,futureworkneedstodesignmoreeffectiveself-confidence
retrospectiveanalyseswithourproposedanalyticalframework,de- calibrationmechanismstofurtherenhancetheappropriatenessof
signerscanidentifyrootcausesandmaketargetedimprovements people’sself-confidence.Second,self-confidencecalibrationalso
tospecificaspectsofthehuman-AIsystem.Ourproposedanalyti- bringssideeffects,thatis,whenAIC-CMismatched,becausepeople
calframework,whichexaminesinappropriatereliancefromtwo tendtofollowthepredictionofthepartywithhigherconfidence,“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
theerrorrateincreasescomparedwithnocalibration.Third,the ofinappropriatereliance,andmaketargetedimprovements.For
relationshipbetweenself-confidenceandrelianceonAIisintri- instance,developersordesignerscanstatisticallyanalyzeuserpre-
cateandnonlinear.ThiscomplexityalignswithfindingsinHeet dictiondatafromboththeHumanandAIperspectivesregarding
al.’sstudy[29].Inappropriateself-confidenceisonlyoneofmany C-CMatching.IfasignificantC-CMismatchexistsamongusers,
causesofinappropriatereliance.Despitetherebeingasignificant designersshouldintroducecalibrationmechanismstorefineusers’
correlationbetweentheappropriatenessofself-confidenceandthe self-confidence.Conversely,ifAIC-CMatchingissuesprevail,de-
appropriatenessofreliance(Study1),notethatcorrelationdoesnot signersshouldcollaboratewithAIalgorithmengineerstooptimize
equalcausation.Weenvisionamorecomplexinterplayoffactors confidencecalibrationinAI.
influencingthisrelationship,includinghumans’expertise,AIliter- DR3:ChoosingSuitableCalibrationBasedonCalibration
acy,intrinsictrustinAI,andcognitivebiases,amongothers.Thus, PurposeandTaskProperties.There’snoone-size-fits-allcali-
solelycalibratingself-confidencemaynotsufficetofosterappropriate brationmechanism.Whenchoosingcalibrationmethods,designers
relianceonAI.Futureresearchisneededforadeeperunderstanding shouldcomparevariousoptionsbasedonthecalibration’spurpose
ofthisintricatelogic. andtaskproperties.Forinstance,iftargetuserstendtobeover-
confidentintheselectedtask,reducingtheirconfidencecanbe
7.4 MultifacetedEffectsofSelf-Confidence achievedbyemphasizingthecostofdecisionerrors(e.g.,Bet)or
CalibrationonFinalTaskPerformance encouragingthemtoapproachproblemsfromtheoppositeperspec-
tive(e.g.,Think).Ifthetaskitselfprovidesgroundtruthdatafor
Weobservedanimprovementinhumans’taskperformancewith
training,designingafeedbacksessiontocalibrateuserconfidence
self-confidencecalibration.Basedonouranalysis,theimproved
couldbeeffective.
taskperformanceresultsfromthreepivotalfactors.Thefirstfactor
DR4:ConsideringUserExperienceinCalibrationDesign.
isimprovedhumanindependentaccuracy.Study2andStudy3
Whendesigningcalibrationinterfaces,designersshouldnotonly
demonstratethatintheCalibrationcondition,individualsexhibit
testcalibrationeffectivenessbutalsoconsideritsimpactonuser
significantlyimprovedinitialperformancecomparedtotheNoCal-
experience.Somecalibrationmethodsmightdemandhighercogni-
ibrationcondition.Thisenhancementmightarisefromincreased
tiveeffortfromusers,leadingtoincreasedcognitiveburdenand
engagementinSystem2thinkingduringthecalibrationprocess,
decreasedsatisfaction.Therefore,thesemethodsmightnotsuit
reducingerrorsresultingfrominadequateanalyticalthinking[31].
certainusergroupsaversetocriticalthinking.Designersshouldin-
Thesecondfactorisimprovedself-confidenceappropriateness.Self-
corporateuserexperienceandtailorcalibrationmethodsaccording
confidencecalibrationdirectlyreducestheoccurrenceofHuman
totheattributesoftargetusers.Forinstance,designerscanpre-
C-CMismatchanddiminisheserrorsstemmingfromsuchmismatch.
assesstargetusers’intrinsiccognitivemotivationthroughNeedfor
Thethirdfactorishumans’appropriaterelianceonAI.Calibration
Cognition(NFC)scales[9]andthendesigninterventionsaccord-
helpspeoplemakemorerationalreliancechoiceswhenfacingdis-
ingly.Forexample,employingThinkonpeoplewithhighNFC.
agreements.
DR5:UsingSelf-ConfidenceCalibrationforTrainingPur-
Insummary,thefinaltaskperformanceimprovementisaprod-
poses.Ourresultsrevealedthatcalibratinguserconfidencedirectly
uctofmultifacetedfactors.Thisinsightsuggeststhattoenhance
enhancesusers’independenttaskperformance(seeStudy2and
human-AIcollaboration,apartfromfocusingonimprovingAIper-
3).Althoughcalibrationdiffersfromformaltraining,iteffectively
formance,designersshouldtreatthehuman-AIcollaborationasa
fulfillsasimilarrole.Consequently,designershavetheopportu-
wholesystem,makingeffortsfromdiverseperspectives.
nitytoutilizeconfidencecalibrationasatrainingmethodorto
enhanceusertaskperformancefurtherbyintegratingcalibration
7.5 ImplicationsforFutureAI-Assisted
withtraditionaltrainingapproaches.
Decision-MakingInterfaceDesign
DR6:EnsuringAIConfidenceCalibrationBeforeHuman
Basedonthekeyfindingsfromourstudies,wepresentseveral ConfidenceCalibration.ResultsfromStudy3indicatethatcal-
designrecommendationsfordesigners’consideration. ibratinghumanconfidenceonlysignificantlyenhancesreliance
DR1:CalibratingUserSelf-ConfidenceBeforeInitiating appropriatenesswhenAIC-CMatched.Calibratinghumanconfi-
Tasks.TheresultsfromStudy1suggestthatinappropriateuser denceinthecaseofAIC-CMismatchedmayleadtomoreincorrect
self-confidenceexacerbatesinappropriatereliance.Therefore,be- reliance. Therefore, if designers aim to incorporate human self-
foredesigningordeployingAI-assisteddecision-makingsystems, confidencecalibrationintodecision-makinginterfaces,itisessen-
it’scrucialtogatherusers’predictiondatathroughatestingphase tialtoassessthedegreeofAIconfidencecalibrationbeforehand.
tounderstandusers’self-perceivedcompetence(i.e.,confidence) DR7: Guiding Rational Use of Confidence Information.
inthecurrenttask.Ifusers’self-confidenceisunreliable,interven- InsituationswherebothhumanandAIconfidencearewellcal-
tionstocalibrateuserconfidenceshouldbeimplementedinsuch ibrated,followingtheviewpointofthehigher-confidenceparty
cases.Alternatively,designersmayconsidermakingconfidence mayyieldhigherexpectedbenefits.Whileourresultsindicatean
calibrationadefaultsetupinAI-assisteddecision-making. increaseinthe“followhighconfidencefraction”,there’sstillroom
DR2:DiagnosingandImprovingtheSystemUsingtheAn- forimprovement.Designerscanimplementadditionaldesignsto
alyticalFramework.Weencouragedesigners,duringtheiterative directlyenhancepeople’scomprehensionoftheconceptsandben-
phaseofAI-assisteddecision-makingsystemdevelopment,touse efitsofcalibratedconfidenceandencouragepeopletoconsiderthe
ourproposedanalyticalframeworkto“diagnose”theconfidence predictionsofthepartywithhigherconfidencemoreseriously.
calibrationstatusofusersandAI,analyzetheunderlyingcausesCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
7.6 LimitationsandFutureWork Wefirstproposeanovelanalyticalframeworktoparseinappro-
7.6.1 Extendingtomulti-levelconfidence. Inouranalyticalframe- priatereliancefromtheperspectiveofhumanandAIconfidence-
work,wecategorizehumanandAI’sconfidenceintotwolevels, correctnessmatching.Throughthreeuserstudies,wemakethree
whichisnotfine-grainedenough.Actually,ouranalyticalframe- contributions:(1)analyzingtherelationshipbetweentheappro-
workcanbegeneralizedtomulti-levelconfidence.However,this priatenessofhumanself-confidenceandtheappropriatenessof
willbringcombinatorialcomplexityasweneedtonotonlyconsider humanreliance,(2)designingandcomparingdifferentconfidence
whethertheconfidence-correctnessismatched,butalsoconsider calibrationmechanisms,and(3)examiningtheimpactofhuman
thedegreeofmatching(e.g.,[correct&95%confidence]ismore confidence calibration on humans’ behavior, task performance,
matchedthan[correct&85%confidence]).Moreover,thelevelof andrelianceappropriatenesswhenworkingwithAIthatshows
confidencecanalsobetherelativevaluebetweenahumanand confidence.Insummary,thispaperprovidesauniqueperspective
anAI.Forexample,ifAIconfidenceis55%,thenaperson’s65% on understanding and promoting humans’ appropriate reliance
confidencecanbeseenas“higher”confidence.Atthecurrentstage, inAI-assisteddecision-making,sheddinglightonthecalibration
thetwo-leveldivisionisenoughtogiveuspreliminaryinsights.In ofhumanself-confidence.Wehopethatourresearchwillenrich
futurework,wewillexpandtheproposedanalysisframeworkto theunderstandinganddiscoursewithintheresearchcommunity
morefine-grainedconfidence,andexplorewhetheritcanbeused on this topic and pave the way for further research on human
toanalyzetherelativeconfidencelevelsofhumansandAI. self-confidencecalibrationinhuman-AIcollaboration.
7.6.2 GeneralizabilityofProposedCalibrationMechanisms. The REFERENCES
analysisoftheappropriatenessofhumanself-confidencerequires
[1] GaganBansal,BesmiraNushi,EceKamar,WalterSLasecki,DanielSWeld,and
individualstomakeindependentjudgmentsbeforeaccessingAI EricHorvitz.2019.Beyondaccuracy:Theroleofmentalmodelsinhuman-AI
suggestions,whichmaynotsuitscenariosprioritizingefficiency teamperformance.InProceedingsoftheAAAIConferenceonHumanComputation
andCrowdsourcing,Vol.7.2–11.
andone-stagedecision-making.Inaddition,gatheringusers’con- [2] GaganBansal,TongshuangWu,JoyceZhou,RaymondFok,BesmiraNushi,Ece
fidencerequiresusers’extraeffort(althoughslight)andmaynot Kamar,MarcoTulioRibeiro,andDanielWeld.2021. Doesthewholeexceed
itsparts?theeffectofaiexplanationsoncomplementaryteamperformance.In
mirrornaturaldecision-makingprocesseswhereusersformimplicit
Proceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.
confidenceintheirminds.Futureresearchshouldexploremethods 1–16.
toinferconfidenceaccuratelyfromdecision-makingbehaviors,like [3] AstridBertrand,RafikBelloum,JamesREagan,andWinstonMaxwell.2022.How
CognitiveBiasesAffectXAI-assistedDecision-making:ASystematicReview.In
users’hesitation.Additionally,thethreeself-confidencecalibration
Proceedingsofthe2022AAAI/ACMConferenceonAI,Ethics,andSociety.78–91.
mechanismsweproposedallhavelimitations:Feedbackrelieson [4] SilviaBonaccioandReeshadSDalal.2006.Advicetakinganddecision-making:
historicaldataforcalibration;ThinkOppositemayimposecognitive Anintegrativeliteraturereview,andimplicationsfortheorganizationalsciences.
Organizationalbehaviorandhumandecisionprocesses101,2(2006),127–151.
burdens; and Bet isn’t universally applicable due to its reliance [5] JochenBröckerandLeonardASmith.2007.Increasingthereliabilityofreliability
oneconomicincentives.Nonetheless,theconceptofhumanself- diagrams.Weatherandforecasting22,3(2007),651–661.
[6] ZanaBuçinca,PhoebeLin,KrzysztofZGajos,andElenaLGlassman.2020.Proxy
confidencecalibrationandtheanalyticalframeworkcanbeapplied
tasksandsubjectivemeasurescanbemisleadinginevaluatingexplainableAI
todiversedecision-makingtasks.Futureworkisencouragedtode- systems.InProceedingsofthe25thinternationalconferenceonintelligentuser
visemoreeffectiveself-confidencecalibrationstrategiesforspecific interfaces.454–464.
[7] ZanaBuçinca,MajaBarbaraMalaya,andKrzysztofZGajos.2021.Totrustorto
decision-makingscenarios.
think:cognitiveforcingfunctionscanreduceoverrelianceonAIinAI-assisted
decision-making. ProceedingsoftheACMonHuman-ComputerInteraction5,
7.6.3 PersonalizedCalibration. Differentcalibrationstrategiesof- CSCW1(2021),1–21.
[8] ÁngelAlexanderCabrera,AdamPerer,andJasonI.Hong.2023. Improving
feruniqueadvantages.Forexample,Thinkreducesover-confidence
Human-AICollaborationWithDescriptionsofAIBehavior.Proc.ACMHum.-
andmaybenefitthosepronetooverconfidence.Similarly,Betmay Comput.Interact.7,CSCW1,Article136(apr2023),21pages. https://doi.org/10.
affectdifferentgroupsdifferently;itcouldboosttheconfidenceof 1145/3579612
[9] JohnTCacioppo,RichardEPetty,andChuanFengKao.1984. Theefficient
risk-takerswhilereducingtheconfidenceofrisk-averseindividuals.
assessmentofneedforcognition.Journalofpersonalityassessment48,3(1984),
Thispaperonlyexplorestheeffectivenessofdiversecalibration 306–307.
strategiesonthewholepopulation.Apotentialfuturedirectionis [10] LeahChong,GuangluZhang,KosaGoucher-Lambert,KennethKotovsky,and
JonathanCagan.2022.Humanconfidenceinartificialintelligenceandinthem-
toinvestigateuser-personalizedcalibration,tailoringmethodsto selves:TheevolutionandimpactofconfidenceonadoptionofAIadvice.Com-
individualswithdifferentcharacteristics. putersinHumanBehavior127(2022),107018.
[11] MarkConsidine.2012. Thinkingoutsidethebox?Applyingdesigntheoryto
publicpolicy.Politics&Policy40,4(2012),704–724.
7.6.4 CalibratingHumans’PerceptionsofAIConfidence. Onein-
[12] RobertJCramer,JamieDeCoster,PaigeBHarris,LisaMFletcher,andStanleyL
terestingfindingisthatevenwhenhumansandAIarebothC-C Brodsky.2011. Aconfidence-credibilitymodelofexpertwitnesspersuasion:
Matched,humanscanstillmakeincorrectdecisions.Ourpaper Mediatingeffectsandimplicationsfortrialconsultation.ConsultingPsychology
Journal:PracticeandResearch63,2(2011),129.
onlycalibrateshumans’self-confidence.Humans’perceptionof
[13] MaryCummings.2004. Automationbiasinintelligenttimecriticaldecision
AI’sconfidencemayalsoneedtobecalibrated.Futureresearch supportsystems.InAIAA1stintelligentsystemstechnicalconference.6313.
shouldexplore“dualcalibration”,investigatingthecombinedim- [14] MorrisHDeGrootandStephenEFienberg.1983.Thecomparisonandevaluation
offorecasters.JournaloftheRoyalStatisticalSociety:SeriesD(TheStatistician)
pactonAI-assisteddecision-making. 32,1-2(1983),12–22.
[15] BellaMDePaulo,KellyCharlton,HarrisCooper,JamesJLindsay,andLaura
Muhlenbruck.1997. Theaccuracy-confidencecorrelationinthedetectionof
8 CONCLUSION
deception.PersonalityandSocialPsychologyReview1,4(1997),346–357.
[16] BerkeleyJDietvorst,JosephPSimmons,andCadeMassey.2015. Algorithm
Thispaperprovidesacomprehensiveunderstandingoftheimpact
aversion:peopleerroneouslyavoidalgorithmsafterseeingthemerr.Journalof
ofhumanconfidencecalibrationinAI-assisteddecision-making. ExperimentalPsychology:General144,1(2015),114.“AreYouReallySure?”UnderstandingtheEffectsofHumanSelf-ConfidenceCalibrationinAI-AssistedDecisionMaking CHI’24,May11–16,2024,Honolulu,HI,USA
[17] AnnieDuke.2019. Thinkinginbets:Makingsmarterdecisionswhenyoudon’t supportsystemforstrokerehabilitationassessment.ProceedingsoftheACMon
haveallthefacts.Penguin. Human-ComputerInteraction4,CSCW2(2020),1–27.
[18] DavidDunning,KerriJohnson,JoyceEhrlinger,andJustinKruger.2003.Whypeo- [44] QVeraLiaoandKushRVarshney.2021.Human-CenteredExplainableAI(XAI):
plefailtorecognizetheirownincompetence.Currentdirectionsinpsychological FromAlgorithmstoUserExperiences.arXivpreprintarXiv:2110.10790(2021).
science12,3(2003),83–87. [45] ZhuoranLuandMingYin.2021.HumanRelianceonMachineLearningModels
[19] FranzFaul,EdgarErdfelder,AxelBuchner,andAlbert-GeorgLang.2009. Sta- WhenPerformanceFeedbackisLimited:HeuristicsandRisks.InProceedingsof
tisticalpoweranalysesusingG*Power3.1:Testsforcorrelationandregression the2021CHIConferenceonHumanFactorsinComputingSystems.1–16.
analyses.Behaviorresearchmethods41,4(2009),1149–1160. [46] AndrewLuttrell,PabloBriñol,RichardEPetty,WilliamCunningham,andDarío
[20] AdrianFurnhamandHuaChuBoo.2011.Aliteraturereviewoftheanchoring Díaz.2013. Metacognitiveconfidence:Aneuroscienceapproach. Revistade
effect.Thejournalofsocio-economics40,1(2011),35–42. PsicologíaSocial28,3(2013),317–332.
[21] BhavyaGhai,QVeraLiao,YunfengZhang,RachelBellamy,andKlausMueller. [47] ShuaiMa,YingLei,XinruWang,ChengboZheng,ChuhanShi,MingYin,and
2021.Explainableactivelearning(xal)towardaiexplanationsasinterfacesfor XiaojuanMa.2023.WhoShouldITrust:AIorMyself?LeveragingHumanand
machineteachers. ProceedingsoftheACMonHuman-ComputerInteraction4, AICorrectnessLikelihoodtoPromoteAppropriateTrustinAI-AssistedDecision-
CSCW3(2021),1–28. Making.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputing
[22] ClaudiaGonzález-VallejoandAaronBonham.2007.Aligningconfidencewith Systems.1–19.
accuracy:Revisitingtheroleoffeedback.ActaPsychologica125,2(2007),221–239. [48] ShuaiMa,MingfeiSun,andXiaojuanMa.2022.ModelingAdaptiveExpression
[23] MatúšGrežo.2021. Overconfidenceandfinancialdecision-making:ameta- ofRobotLearningEngagementandExploringitsEffectsonHumanTeachers.
analysis.ReviewofBehavioralFinance13,3(2021),276–296. ACMTransactionsonComputer-HumanInteraction(2022).
[24] PiercesareGrimaldi,HakwanLau,andMicheleABasso.2015.Therearethings [49] ShuaiMa,ZijunWei,FengTian,XiangminFan,JianmingZhang,XiaohuiShen,
thatweknowthatweknow,andtherearethingsthatwedonotknowwedo ZheLin,JinHuang,RadomírMěch,DimitrisSamaras,etal.2019. SmartEye:
notknow:Confidenceindecision-making.Neuroscience&BiobehavioralReviews assistinginstantphototakingviaintegratinguserpreferencewithdeepview
55(2015),88–97. proposalnetwork.InProceedingsofthe2019CHIconferenceonhumanfactorsin
[25] ChuanGuo,GeoffPleiss,YuSun,andKilianQWeinberger.2017.Oncalibrationof computingsystems.1–12.
modernneuralnetworks.InInternationalconferenceonmachinelearning.PMLR, [50] ShuaiMa,ChenyiZhang,XinruWang,XiaojuanMa,andMingYin.2024.Beyond
1321–1330. Recommender:AnExploratoryStudyoftheEffectsofDifferentAIRolesin
[26] SandraGHart.2006. NASA-taskloadindex(NASA-TLX);20yearslater.In AI-AssistedDecisionMaking.arXivpreprintarXiv:2403.01791(2024).
Proceedingsofthehumanfactorsandergonomicssocietyannualmeeting,Vol.50. [51] ShuaiMa,TaichangZhou,FeiNie,andXiaojuanMa.2022.Glancee:AnAdaptable
SagepublicationsSageCA:LosAngeles,CA,904–908. SystemforInstructorstoGraspStudentLearningStatusinSynchronousOnline
[27] HollyCHartmann,ThomasCPagano,SorooshSorooshian,andRogerBales.2002. Classes.InCHIConferenceonHumanFactorsinComputingSystems.1–25.
Confidencebuilders:Evaluatingseasonalclimateforecastsfromuserperspectives. [52] AshleyNDMeyer,VelmaLPayne,DerekWMeeks,RadhaRao,andHardeep
BulletinoftheAmericanMeteorologicalSociety83,5(2002),683–698. Singh.2013.Physicians’diagnosticaccuracy,confidence,andresourcerequests:
[28] PeterHaseandMohitBansal.2020.EvaluatingexplainableAI:Whichalgorithmic avignettestudy.JAMAinternalmedicine173,21(2013),1952–1958.
explanationshelpuserspredictmodelbehavior?arXivpreprintarXiv:2005.01831 [53] DeborahJMiller,ElliotSSpengler,andPaulMSpengler.2015.Ameta-analysis
(2020). ofconfidenceandjudgmentaccuracyinclinicaldecisionmaking. Journalof
[29] GaoleHe,LucieKuiper,andUjwalGadiraju.2023.KnowingAboutKnowing:An CounselingPsychology62,4(2015),553.
IllusionofHumanCompetenceCanHinderAppropriateRelianceonAISystems. [54] DeborahJMitchell,JEdwardRusso,andNancyPennington.1989.Backtothe
InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems. future:Temporalperspectiveintheexplanationofevents.JournalofBehavioral
1–18. DecisionMaking2,1(1989),25–38.
[30] ZiyaoHe,YunpengSong,ShuruiZhou,andZhongminCai.2023. Interaction [55] DonAMoore.2020.Perfectlyconfident:Howtocalibrateyourdecisionswisely.
ofThoughts:TowardsMediatingTaskAssignmentinHuman-AICooperation HarperCollins.
withaCapability-AwareSharedMentalModel.InProceedingsofthe2023CHI [56] DonAMooreandPaulJHealy.2008.Thetroublewithoverconfidence.Psycho-
ConferenceonHumanFactorsinComputingSystems.1–18. logicalreview115,2(2008),502.
[31] DanielKahneman.2011.Thinking,fastandslow.Macmillan. [57] DonAMoore,SamuelASwift,AngelaMinster,BarbaraMellers,LyleUngar,
[32] GaryKlein.2007.Performingaprojectpremortem.Harvardbusinessreview85, PhilipTetlock,HeatherHJYang,andElizabethRTenney.2017. Confidence
9(2007),18–19. calibrationinamultiyeargeopoliticalforecastingcompetition. Management
[33] RafalKocielnik,SaleemaAmershi,andPaulNBennett.2019.Willyouacceptan Science63,11(2017),3552–3565.
imperfectai?exploringdesignsforadjustingend-userexpectationsofaisystems. [58] RaymondSNickerson.1998.Confirmationbias:Aubiquitousphenomenonin
InProceedingsofthe2019CHIConferenceonHumanFactorsinComputingSystems. manyguises.Reviewofgeneralpsychology2,2(1998),175–220.
1–14. [59] AlexandruNiculescu-MizilandRichCaruana.2005.Predictinggoodprobabilities
[34] RonnyKohaviandBarryBecker.1996. AdultIncomedataset(UCIMachine withsupervisedlearning.InProceedingsofthe22ndinternationalconferenceon
LearningRepository).https://archive.ics.uci.edu/ml/datasets/Adult/. Machinelearning.625–632.
[35] AsherKoriatandRobertABjork.2006. Illusionsofcompetenceduringstudy [60] MahsanNourani,ChiradeepRoy,JeremyEBlock,DonaldRHoneycutt,Tahrima
canberemediedbymanipulationsthatenhancelearners’sensitivitytoretrieval Rahman,EricRagan,andVibhavGogate.2021.AnchoringBiasAffectsMental
conditionsattest.Memory&Cognition34,5(2006),959–972. ModelFormationandUserRelianceinExplainableAISystems.In26thInterna-
[36] JustinKrugerandDavidDunning.1999.Unskilledandunawareofit:howdiffi- tionalConferenceonIntelligentUserInterfaces.340–350.
cultiesinrecognizingone’sownincompetenceleadtoinflatedself-assessments. [61] RajaParasuramanandDietrichHManzey.2010. Complacencyandbiasin
Journalofpersonalityandsocialpsychology77,6(1999),1121. humanuseofautomation:Anattentionalintegration.Humanfactors52,3(2010),
[37] ToddKulesza,SimoneStumpf,MargaretBurnett,andIrwinKwan.2012.Tellme 381–410.
more?Theeffectsofmentalmodelsoundnessonpersonalizinganintelligent [62] TimothyJPerfect,TaraSHollins,andAdamLRHunt.2000.Practiceandfeedback
agent.InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputing effectsontheconfidence-accuracyrelationineyewitnessmemory.Memory8,4
Systems.1–10. (2000),235–244.
[38] VivianLai,SamuelCarton,RajatBhatnagar,QVeraLiao,YunfengZhang,and [63] JohnPlattetal.1999.Probabilisticoutputsforsupportvectormachinesandcom-
ChenhaoTan.2022.Human-AICollaborationviaConditionalDelegation:ACase parisonstoregularizedlikelihoodmethods.Advancesinlargemarginclassifiers
StudyofContentModeration.InCHIConferenceonHumanFactorsinComputing 10,3(1999),61–74.
Systems.1–18. [64] TimothyJPleskacandJeromeRBusemeyer.2010. Two-stagedynamicsignal
[39] VivianLai,ChachaChen,QVeraLiao,AlisonSmith-Renner,andChenhaoTan. detection:atheoryofchoice,decisiontime,andconfidence.Psychologicalreview
2021.TowardsaScienceofHuman-AIDecisionMaking:ASurveyofEmpirical 117,3(2010),864.
Studies.arXivpreprintarXiv:2112.11471(2021). [65] ForoughPoursabzi-Sangdeh,DanielGGoldstein,JakeMHofman,JenniferWort-
[40] VivianLai,HanLiu,andChenhaoTan.2020. "Whyis’Chicago’deceptive?" manWortmanVaughan,andHannaWallach.2021.Manipulatingandmeasuring
TowardsBuildingModel-DrivenTutorialsforHumans.InProceedingsofthe2020 modelinterpretability.InProceedingsofthe2021CHIconferenceonhumanfactors
CHIConferenceonHumanFactorsinComputingSystems.1–13. incomputingsystems.1–52.
[41] VivianLaiandChenhaoTan.2019.Onhumanpredictionswithexplanationsand [66] BrionyDPulfordandAndrewMColman.1997.Overconfidence:Feedbackand
predictionsofmachinelearningmodels:Acasestudyondeceptiondetection.In itemdifficultyeffects.Personalityandindividualdifferences23,1(1997),125–133.
Proceedingsoftheconferenceonfairness,accountability,andtransparency.29–38. [67] CharviRastogi,YunfengZhang,DennisWei,KushRVarshney,AmitDhurandhar,
[42] JohnDLeeandKatrinaASee.2004.Trustinautomation:Designingforappro- andRichardTomsett.2022.Decidingfastandslow:Theroleofcognitivebiases
priatereliance.Humanfactors46,1(2004),50–80. inai-assisteddecision-making. ProceedingsoftheACMonHuman-Computer
[43] MinHunLee,DanielPSiewiorek,AsimSmailagic,AlexandreBernardino,and Interaction6,CSCW1(2022),1–22.
SergiBermúdeziBadia.2020.Co-designandevaluationofanintelligentdecisionCHI’24,May11–16,2024,Honolulu,HI,USA ShuaiMa,etal.
[68] AmyRechkemmerandMingYin.2022. WhenConfidenceMeetsAccuracy: InProceedingsofthe2020ConferenceonFairness,Accountability,andTransparency.
ExploringtheEffectsofMultiplePerformanceIndicatorsonTrustinMachine 295–305.
LearningModels.InCHIConferenceonHumanFactorsinComputingSystems. [91] JieqiongZhao,YixuanWang,MichelleVMancenido,ErinKChiou,andRoss
1–14. Maciejewski.2023.Evaluatingtheimpactofuncertaintyvisualizationonmodel
[69] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2018.Anchors:High- reliance.IEEETransactionsonVisualizationandComputerGraphics(2023).
precisionmodel-agnosticexplanations.InProceedingsoftheAAAIconferenceon [92] ChengboZheng,YuhengWu,ChuhanShi,ShuaiMa,JiehuiLuo,andXiaojuanMa.
artificialintelligence,Vol.32. 2023.CompetentbutRigid:IdentifyingtheGapinEmpoweringAItoParticipate
[70] KasparRufibach.2010.UseofBrierscoretoassessbinarypredictions.Journalof EquallyinGroupDecision-Making.InProceedingsofthe2023CHIConferenceon
clinicalepidemiology63,8(2010),938–939. HumanFactorsinComputingSystems.1–19.
[71] MaxSchemmer,NiklasKuehl,CarinaBenz,AndreaBartos,andGerhardSatzger. [93] ChengboZheng,KangyuYuan,BingcanGuo,RezaHadiMogavi,ZhenhuiPeng,
2023. AppropriaterelianceonAIadvice:Conceptualizationandtheeffectof ShuaiMa,andXiaojuanMa.2024.ChartingtheFutureofAIinProject-Based
explanations.InProceedingsofthe28thInternationalConferenceonIntelligent Learning:ACo-DesignExplorationwithStudents.arXivpreprintarXiv:2401.14915
UserInterfaces.410–422. (2024).
[72] GlenLSharp,BrianLCutler,andStevenDPenrod.1988.Performancefeedback [94] QianZhu,LeoYu-HoLo,MengXia,ZixinChen,andXiaojuanMa.2022.Bias-
improvestheresolutionofconfidencejudgments.Organizationalbehaviorand AwareDesignforInformedDecisions:RaisingAwarenessofSelf-SelectionBias
humandecisionprocesses42,3(1988),271–283. inUserRatingsandReviews. ProceedingsoftheACMonHuman-Computer
[73] ChuhanShi,YichengHu,ShenanWang,ShuaiMa,ChengboZheng,XiaojuanMa, Interaction6,CSCW2(2022),1–31.
andQiongLuo.2023.RetroLens:AHuman-AICollaborativeSystemforMulti-
stepRetrosyntheticRoutePlanning.InProceedingsofthe2023CHIConferenceon
HumanFactorsinComputingSystems.1–20.
[74] AlisonSmith-Renner,RonFan,MelissaBirchfield,TongshuangWu,JordanBoyd-
Graber,DanielSWeld,andLeahFindlater.2020. Noexplainabilitywithout
accountability:Anempiricalstudyofexplanationsandfeedbackininteractiveml.
InProceedingsofthe2020chiconferenceonhumanfactorsincomputingsystems.
1–13.
[75] JanetASniezekandTimothyBuckley.1995. Cueingandcognitiveconflictin
judge-advisordecisionmaking. Organizationalbehaviorandhumandecision
processes62,2(1995),159–174.
[76] AaronSpringerandSteveWhittaker.2019.Progressivedisclosure:empirically
motivatedapproachestodesigningeffectivetransparency.InProceedingsofthe
24thinternationalconferenceonintelligentuserinterfaces.107–120.
[77] ElizabethRTenney,JennaESmall,RobynLKondrad,VikramKJaswal,and
BarbaraASpellman.2011. Accuracy,confidence,andcalibration:howyoung
childrenandadultsassesscredibility. Developmentalpsychology47,4(2011),
1065.
[78] AmyTurner,MeenaKaushik,Mu-TiHuang,andSrikarVaranasi.2022.Calibrat-
ingtrustinAI-assisteddecisionmaking.
[79] HelenaVasconcelos,MatthewJörke,MadeleineGrunde-McLaughlin,Tobias
Gerstenberg,MichaelSBernstein,andRanjayKrishna.2023.Explanationscan
reduceoverrelianceonaisystemsduringdecision-making.Proceedingsofthe
ACMonHuman-ComputerInteraction7,CSCW1(2023),1–38.
[80] OleksandraVereschak,GillesBailly,andBaptisteCaramiaux.2021.HowtoEvalu-
ateTrustinAI-AssistedDecisionMaking?ASurveyofEmpiricalMethodologies.
ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–39.
[81] KailasVodrahalli,RoxanaDaneshjou,TobiasGerstenberg,andJamesZou.2022.
Dohumanstrustadvicemoreifitcomesfromai?ananalysisofhuman-ai
interactions.InProceedingsofthe2022AAAI/ACMConferenceonAI,Ethics,and
Society.763–777.
[82] DandingWang,QianYang,AshrafAbdul,andBrianYLim.2019. Designing
theory-drivenuser-centricexplainableAI.InProceedingsofthe2019CHIconfer-
enceonhumanfactorsincomputingsystems.1–15.
[83] LuWang,GregAJamieson,andJustinGHollands.2008.Selectingmethodsfor
theanalysisofrelianceonautomation.InProceedingsoftheHumanFactorsand
ErgonomicsSocietyAnnualMeeting,Vol.52.SAGEPublicationsSageCA:Los
Angeles,CA,287–291.
[84] XinruWangandMingYin.2021.Areexplanationshelpful?acomparativestudy
oftheeffectsofexplanationsinai-assisteddecision-making.In26thInternational
ConferenceonIntelligentUserInterfaces.318–328.
[85] NathanWeberandNeilBrewer.2004.Confidence-accuracycalibrationinabsolute
andrelativefacerecognitionjudgments. JournalofExperimentalPsychology:
Applied10,3(2004),156.
[86] MagdalenaWischnewski,NicoleKrämer,andEmmanuelMüller.2023.Measuring
andUnderstandingTrustCalibrationsforAutomatedSystems:ASurveyofthe
State-Of-The-ArtandFutureDirections.InProceedingsofthe2023CHIConference
onHumanFactorsinComputingSystems.1–16.
[87] FumengYang,ZhuanyiHuang,JeanScholtz,andDustinLArendt.2020.How
dovisualexplanationsfosterendusers’appropriatetrustinmachinelearning?.
InProceedingsofthe25thInternationalConferenceonIntelligentUserInterfaces.
189–201.
[88] QianYang,YuexingHao,KexinQuan,StephenYang,YiranZhao,Volodymyr
Kuleshov,andFeiWang.2023. Harnessingbiomedicalliteraturetocalibrate
clinicians’trustinAIdecisionsupportsystems.InProceedingsofthe2023CHI
ConferenceonHumanFactorsinComputingSystems.1–14.
[89] MingYin,JenniferWortmanVaughan,andHannaWallach.2019.Understanding
theeffectofaccuracyontrustinmachinelearningmodels.InProceedingsofthe
2019chiconferenceonhumanfactorsincomputingsystems.1–12.
[90] YunfengZhang,QVeraLiao,andRachelKEBellamy.2020.Effectofconfidence
andexplanationonaccuracyandtrustcalibrationinAI-assisteddecisionmaking.