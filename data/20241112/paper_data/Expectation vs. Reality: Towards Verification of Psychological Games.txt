Expectation vs. Reality:
Towards Verification of Psychological Games
Marta Kwiatkowska1 , Gethin Norman1,2 ,
David Parker1 , and Gabriel Santos1
1 Department of Computer Science, Universityof Oxford, Oxford,UK
{marta.kwiatkowska,david.parker,gabriel.santos}@cs.ox.ac.uk
2 School of Computing Science, University of Glasgow, Glasgow, UK
gethin.norman@glasgow.ac.uk
Abstract. Game theory provides an effective way to model strategic
interactionsamongrationalagents.Inthecontextofformalverification,
theseideascanbeusedtoproduceguaranteesonthecorrectnessofmulti-
agent systems,with adiverserangeofapplicationsfrom computersecu-
rity to autonomous driving. Psychological games (PGs) were developed
asawaytomodelandanalyseagentswithbelief-dependentmotivations,
opening up the possibility to model how human emotions can influence
behaviour. In PGs, players’ utilities depend not only on what actually
happens (which strategies players choose to adopt), but also on what
theplayershadexpected tohappen(theirbelief astothestrategies that
wouldbeplayed).Despitereceivingmuchattentioninfieldssuchaseco-
nomics and psychology, very little consideration has been given to their
applicabilitytoproblemsincomputerscience,nortopracticalalgorithms
and tool support. In this paper, we start to bridge that gap, proposing
methods to solve PGs and implementing them within PRISM-games, a
formal verification tool for stochastic games. We discuss how to model
thesegames,highlightspecificchallengesfortheiranalysisandillustrate
the usefulness of our approach on several case studies, including human
behaviour in traffic scenarios.
1 Introduction
Probabilisticmodelcheckingisawellestablishedtechniqueforformallyverifying
computerised systems that operate in uncertain or stochastic environments. In
ordertoverifysystemscomprisingmultipleautonomousagentsand/orthosein-
volvinghumaninteractions,variousmodelsandconceptsfromgametheoryhave
been adapted for probabilistic model checking. Stochastic games, in particular,
haveshowntobeaversatileandusefulformalismtomodelandstudysituations
involvingcollaborationorcompetitionamongagents,successfullyappliedto,for
example human-in-the-loop autonomous systems [12], robot navigation in the
presence of humans [18] and attack-defence scenarios [2].
Whiletraditionalgametheoryisoftenusedtomodelhumandecisionmaking,
it is unable to model situations such as emotional response and social norms,
4202
voN
8
]TG.sc[
1v99550.1142:viXra2 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
wheretheutilitiesthatplayersaimtomaximisecandependontheirbeliefs.This
inadequacy has been pointed out in [13], which proposed the seminal model of
psychological games (PGs). In these games, a player’s utility depends not only
on what actually happens in the game (i.e., which strategies are chosen by the
players), but also on what the players had expected to happen (i.e., their belief
as to the future behaviour of the other players).
This class of models makes it possible to consider different aspects that con-
tribute to human decision-making, such as regret, trust, fear, reciprocity and
fairness,andhow these may influence playerbehaviour.Crucially,psychological
game predictions have been reproducedin human experiments, thus supporting
the notion of belief-dependent motivations [3]. This has been of particular rele-
vance in economics, when trying to predict and understand how people behave
regardingnon-materialpayoffs.Naturally,though,asautonomouscomputerised
systems become more commonplace, ensuring that they interact safely and effi-
ciently with humans will also require this kind of reasoning.
In this paper, we make the first steps towards a more practical approach to
modellingandanalysingPGs,andinapplyingthemtootherscenarios.Webegin
with one-shot (normal form) games, considering the normal form psychological
games (NFPGs) proposed in [13]. We work with the commonly employed solu-
tion concept of Nash equilibria (NE), which establishes rational strategies for a
game to be those where no player has an incentive to unilaterally deviate from
their strategy. Using the psychological extension of NE from [13], we propose
anapproachtofindingoptimalequilibriaforNFPGsusingsupportenumeration
and non-linear programming, and highlight why computing equilibria for such
games is more computationally challenging.
We next investigate extensive (multi-stage) games with psychological pay-
offs, under the assumption that beliefs are local and state-based. We do so by
considering an extension of concurrent stochastic games (CSGs) whose reward
functions candepend onboth the actionstakenandbeliefs about those actions,
proposingamethodtofindequilibriaforfinite-horizoncumulativerewardsusing
backwardinduction.Wedevelopprototypetoolsupportforpsychologicalgames,
building on the PRISM-games model checker for stochastic games [23]. Using
this, we model and analyse a variety of psychological games, notably studying
humanbehaviourinseveraldifferenttrafficscenarios,andshowcasethe analysis
and insights made possible by our approach.
Related work. Psychological games were proposed in [13] and shown to ad-
mitstandardgame-theoretictechniquessuchasbackwardinductionundersome
restrictions. However, they assume a fixed payoff structure and do not support
belief inference or updating. Dynamic psychological games [5,4,6] address some
of these limitations by allowing belief update. More specifically, they remove
restrictionsenforcedin[13]thatmakebeliefsendogenoustothegames,andpro-
pose a forward induction algorithm with belief updates which allows for more
sophisticatedanalysis.In [31], fairness equilibria areintroduced asanextension
of the framework established in [13], where the payoff of each player is definedExpectation vs. Reality:Towards Verification of Psychological Games 3
as a combination of a material payoff and a psychological payoff whose value
depends on how fairly they think they are being treated.
From an application perspective, conventional game theory has been em-
ployed to model a range of road user behaviours [10,19,34,7,29,11], including
mergingintotraffic andspeedselection,andhasbeen ableto explainhow infor-
mal norms of behaviour can develop among road users and be sustained even if
these informal norms violate the formal regulations of the traffic code. In [19],
the authors point out that autonomous agents should have inferable behaviour
and model a pedestrian crossing interaction as a repeated bimatrix Stackelberg
game in order to measure and establish a bound to inferability loss. A more
complex interaction involving vehicles, pedestrians and cyclists at a crossing
was investigated as a non-zero sum game in [7], which showed that real life be-
haviour corresponded to an equilibrium strategy that went against Norwegian
traffic laws. This example served as inspiration for [29], which used Bayesian
games and examined possible differences in the strategies pedestrians and cy-
clistswouldbelikelytoadoptwhenconsideringautonomousandhumandrivers.
Another exampleis [11],whichalsoconsidersa game-theoreticstochasticmodel
toanalyseinteractionsamongpedestrians,autonomousandregularvehiclesand
investigatesstrategiesforconflictresolutioninuncontrolledtrafficenvironments
based onStackelberg equilibria.However,to the best of our knowledge,psycho-
logical games have not been explored in road user scenarios.
The verification community has developed various software tools with sup-
port for Nash equilibria, such as PRALINE [8], EAGLE [35] and EVE [17],
but we are aware of no tool support for psychological equilibria computation,
in either normal or extensive forms. For probabilistic systems, model checkers
such as PRISM [22] and Storm [16] support a wide range of probabilistic mod-
els,withpartiallyobservableMarkovdecisionprocessesprovidinganalternative
way to reason about belief, over (unobservable) states rather than strategies.
PRISM-games[23]providesverificationandequilibriasynthesisforvarioustypes
ofstochasticgamesincludingCSGs,butuntilnownotforpsychologicalvariants.
2 Preliminaries
We firstrecallnormalformgames(NFGs), overwhichwedefine Nashequilibria
(NE), and then proceed by defining the psychological equivalents: normal form
psychologicalgames (NFPGs) and psychological Nash equilibria (PE).
Classical games.We willwrite Dist(X)forthe setofprobabilitydistributions
over a finite set X.
Definition 1 (Normal form game). A (finite, n-person) normal form game
(NFG) is a tuple N=(N,A,u) where:
– N ={1,...,n} is a finite set of players;
– A = A ×···×A , A is a finite set of actions available to player i ∈ N
1 n i
and A ∩A =∅ for i6=j ∈N;
i j4 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
– u=(u ,...,u ) and u : A→Q is a utility function for player i∈N.
1 n i
In an NFG, each player i ∈ N simultaneously chooses an action a ∈ A from
i i
theiractionsetandeachplayerj thenreceivesutilityu (a ,...,a ).Two-player
j 1 n
NFGs are often called bimatrix games since they can be represented by two
matrices Z ,Z ∈ Ql×m where A = {a ,...,a }, A = {b ,...,b }, Z (i,j) =
1 2 1 1 l 2 1 m 1
u (a ,b )andZ (i,j)=u (a ,b ).Below,weassumeafixedNFGN=(N,A,u).
1 i j 2 2 i j
Definition 2 (Strategyandstrategyprofile).A(mixed)strategyforplayer
i of NFG N is a distribution σ ∈Dist(A ), specifying the probability of choosing
i i
each action in its action set. A strategy profile of N (or just profile) is a tuple
σ =(σ ,...,σ ) of strategies for all players.
1 n
The expected utility of player i under strategy profile σ =(σ ,...,σ ) is:
1 n
u (σ) d=ef u (a ,...,a )· n σ (a ) .
i (a1,...,an)∈A i 1 n j=1 j j
(cid:16) (cid:17)
P Q
We let Σ Ni = Dist(A i) denote the set of all player i strategies, ΣN = i∈NΣ Ni
the set of all strategy profiles and Σ−i = Σj the set of strategy tuples for
N j6=i N Q
all players except i. For strategy profile σ = (σ ,...,σ ) and player i strategy
1 n
Q
σ′, we define the strategy tuple σ = (σ ,...,σ ,σ ,...,σ ) and strategy
i −i 1 i−1 i+1 n
profile σ [σ′]=(σ ,...,σ ,σ′,σ ,...,σ ).
−i i 1 i−1 i i+1 n
Definition 3 (Support). The support Q ⊆ A of a strategy σ for player i
i i i
is the set of actions it chooses with positive probability, i.e., Q = {a ∈ A |
i i i
σ (a ) > 0}. The support of a profile σ is the product of the supports of its
i i
individual strategies σ .
i
WenowdefinethenotionofNash equilibria (NE),whicharestrategyprofilesfor
which there is no incentive for any player to unilaterally change their strategy.
Definition 4 (Best response). For strategy tuple σ ∈Σ−i, a bestresponse
−i N
to σ for player i is a strategy σ⋆ ∈Σi such that u (σ [σ⋆])>u (σ [σ ]) for
−i i N i −i i i −i i
all σ ∈Σi.
i N
Definition 5 (Nashequilibrium).Astrategyprofileσ⋆ isa Nashequilibrium
(NE) and hu (σ⋆)i NE values if σ⋆ is a best response to σ⋆ for all i∈N.
i i∈N i −i
Since multiple NE can exist for an NFG, we are also interested in finding the
optimal equilibriumforagivencriterion.Inthispaper,wefocusonsocial welfare
NE, which are those that maximise the sum of the players’ utilities.
Definition 6 (Social welfare NE). An NE σ⋆ is a socialwelfareoptimalNE
(SWNE)andhu (σ⋆)i corresponding SWNEvaluesifu (σ⋆)+···+u (σ⋆)>
i i∈N 1 n
u (σ)+···+u (σ) for all NE σ.
1 n
We are now ready to discuss normal form psychological games (NFPGs) [13], a
generalisation of NFGs in which a player’s utility can depend not only on the
game’soutcome(actionstaken),butalsoontheplayer’sbelief astotheoutcome.Expectation vs. Reality:Towards Verification of Psychological Games 5
The notions of actions, strategies and strategy profiles remain the same as for
NFGs and, for NFPG N P, we use the same notation Σ Ni P, ΣN
P
and Σ N− Pi.
Beliefsand coherence.Thefirst-orderbeliefs forplayerirepresenttheirbelief
as to the (mixed) strategies that will be taken by the other players. So, the set
of all first-order beliefs for player i is defined as B1 = Dist(Σ−i). Higher-order
i N P
beliefs arebeliefsaboutthebeliefsofotherplayers.Wewilldenotethekthorder
beliefsforplayeribyBk andwriteBk = Bk forthesetofkthorderbeliefs
i −i j6=i j
for all playersother thani. Higher-orderbeliefs are then defined inductively by:
Q
Bk+1 d=ef Dist(Σ−i×B1 ×···×Bk ).
i N P −i −i
Notice that information about beliefs appears multiple times. This allows for
correlationbetweendifferentordersofbelief,e.g.,second-orderbeliefs B2 assign
i
probabilitiesto combinations ofthe strategiesΣ−i andfirst-orderbeliefs B1 of
N P −i
the other players. As in [13], we will assume that beliefs are coherent, meaning
thatthisinformationisconsistent.Forexample,themarginalofplayeri’ssecond-
orderbeliefs withrespectto Σ−i shouldcoincide withi’s first-orderbeliefs. The
N
P
same condition is applied inductively to higher-order belief sets.
Furthermore,since playersare rationaland know that other playersare also
rational,coherencyis assumedto be commonknowledgeandwewillrequirebe-
liefs to be collectively coherent. In other words, each player i only ever believes
that another player j’s beliefs are coherent, that player j believes other players
to be coherent, and so on. We will write B for the set for all collectively coher-
i
ent higher-order beliefs for player i, and define B = B to be the set of
i∈N i
collectively coherent belief profiles, i.e., the set of beliefs for all players.
Q
Psychological games. We can now formally define the psychological variant
of normal form games, where the key difference is that the utility for player i
now also depends on their (collectively coherent) belief b ∈B about the other
i i
players, as well as the actions they actually take.
Definition 7 (Normalformpsychologicalgame).A(finite,n-person) nor-
mal form psychologicalgame (NFPG) is a tuple N P =(N,A,u) where:
– N ={1,...,n} is a finite set of players;
– A is a finite set of actions available to player i ∈ N and A ∩A = ∅ for
i i j
i6=j ∈N;
– u=(u ,...,u )and u : (B ×A)→Q is a utilityfunction for player i∈N.
1 n i i
As for NFGs, we can define the expected utility of player i for a given strategy
profile σ. However, here we must now also include beliefs. More precisely, for
belief b ∈ B for player i and strategy profile σ, we write u (b ,σ) for the
i i i i
expected utility of player i under b and σ.
i
We cannow define the notionofpsychological Nash equilibrium (PE).While
an NE for an NFG N is a strategy profile σ ∈ ΣN, a PE for an NFPG N P is
a pair (b,σ) ∈ B ×ΣN comprising a belief profile b and a strategy profile σ.
P
Crucially,asexplainedin [13],it is assumedthat, inequilibrium, the beliefs b of6 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
the players match a commonly held view of reality. In other words, each player
i believes, with probability 1, that each other player j follows strategy σ , that
j
player j’s beliefs match σ , and so on. For strategy profile σ, this matching
−j
belief profile for all n players is denoted β(σ).
Definition 8 (Psychological Nash equilibrium). A pair (b⋆,σ⋆) of belief
profile b⋆ = (b⋆ 1,...,b⋆ n) ∈ B and strategy profile σ⋆ = (σ 1⋆,...,σ n⋆) ∈ ΣN
P
for
NFPG N P is a psychologicalNash equilibrium (PE) if:
b⋆ =β(σ⋆) (1)
u i(b⋆ i,σ⋆)>u i(b⋆ i,σ −i[σ i]) for all σ
i
∈ΣNi
P
and i∈N. (2)
Thefirstcondition(1)impliesthat,asdiscussedabove,theplayers’beliefsmatch
a commonly held view of reality. The second condition (2) matches the corre-
sponding requirements for NEs of NFGs (see Definitions 4 and 5). As for NEs,
we will generally aim to find a PE that is social welfare optimal, where the sum
of the players’utilities is maximised.
Defining utility functions. Since we focus on psychological Nash equilibria,
condition (1) above, combined with the assumption of collective coherence for
higher-order beliefs, allows us to adopt a simpler formulation of an NFPG’s
utility functions in practice. Although player i’s utility function u depends on
i
its (collectively coherent, higher-order)beliefs about the other players, since we
know that there is a common belief in equilibrium we can simply define u in
i
terms ofthe strategiesalone,that is,as a function ofthe probabilitiesthat each
player j takes each of its actions. Additionally, for simplicity, we allow each
player’sutility to be defined interms ofall the player’sstrategies,including the
players’ own choices of actions.
Example 1.ToillustrateNFPGs,letusconsidertheconfidence gamefrom[13],
which comprises three players. Player 1 submits a proposal, which is randomly
assigned with equal probability to player 2 or 3. They can then chose to ei-
ther accept or reject this proposal. We abbreviate these actions to a and r ,
i i
respectively, for player i=2,3. Player 1 has no actions to take.
Thegamehasbelief-dependentutilities,involvingbothfirst-orderandsecond-
order beliefs. We will write p for the probability that a player i chooses action
a
a in their (mixed) strategy, p for the expectation of another player j 6=i as to
a
theprobabilityp ,i.e.,thefirst-orderbeliefforplayerj,andp fortheexpected
a a
value of p from the perspective of another player, i.e., the second-order belief.
a
Player 1 wants the proposal to be accepted, but their satisfaction about
acceptanceis influencedbytheir beliefabouthowlikely this isto happen:being
more optimistic means they are happier about an acceptance, but also much
unhappier in the case of a rejection. Player 2 is influenced by how confident
player 1 is about acceptance, and is more likely to accept the proposal if they
believe player 1 is more confident. Player 3 always prefers rejection.
These notions are encoded in the players’ utility functions as follows, where
wefollow[13]butshowextradetailsofthederivation.Letusdenotetheprobabil-
itythatplayer1’sproposalisacceptedasp .We havep =(1/2)·(p +p )
acc acc a2 a3Expectation vs. Reality:Towards Verification of Psychological Games 7
sinceplayers2and3areassignedthe proposalwithequalprobability.Similarly,
p = (1/2)·(p +p ) is player 1’s belief as to the likelihood of acceptance,
acc a2 a3
and p =(1/2)·(p +p ) equals player 2’s belief about p .
acc a2 a3 acc
Player 1 has a utility of 1 in case of acceptance, plus a further utility based
on their degree of optimism, i.e., in terms of belief of acceptance, of 2·p .
acc
Conversely,if rejected, their utility is −8·p . Player 2 prefers to accept when
acc
p > 1 so,whenassignedtheproposal,receivesautilityof6·p foraccepting
acc 6 acc
and 1 for rejecting. Player 3 has a utility of 1 if they are assigned the proposal
and reject it, otherwise 0.
Recall from above that, in equilibrium, players’beliefs must match a shared
view of reality, so p = p = p for i = 2,3. We therefore express the utility
ai ai ai
functions for players as expressions in terms of just p . Since player 1 does not
ai
choose an action and players 2 and 3 each can choose between two actions, we
can write player i’s utility function as a 2×2 matrix Z . For each pair of actions
i
of players 2 and 3, the value combines the utility arising when each of player 2
and 3 are assigned the proposal, weighted by probability 1/2:
a r
3 3
a 1+p +p 1/2−(3/2)·(p +p )
Z = 2 a2 a3 a2 a3
1
r 2 1/2−(3/2)·(p a2 +p a3) −4·(p a2 +p a3) !
a r a r
3 3 3 3
a (3/2)·(p +p ) (3/2)·(p +p ) a 0 1/2
Z = 2 a2 a3 a2 a3 Z = 2
2 3
r 2 1/2 1/2 ! r 2 0 1/2!
WhendeterminingPEfortheconfidencegame,wecanignoreplayer1sinceithas
noactions.Inanequilibrium,suboptimalactionscannotbeplayedwithpositive
probability.We can therefore compute a solution by encoding the problemwith
the following set of constraints:
(3/2)·((p +p )·p +(p +p )·p )>(1/2)·(p +p ) ∨(p =0) (3)
a2 a3 a3 a2 a3 r3 a3 r3 a2
(cid:0)(1/2)·(p
a3
+p r3)>(3/2)·((p
a2
+p a3)·p
a3
+(p
a2
+p a3)·p r3)(cid:1)∨(p
r2
=0) (4)
(cid:0) 0>(1/2)·(p a2 +p r2)(cid:1)∨(p a3 =0) (5)
(cid:0)(1/2)·(p
a2
+p r2)>0(cid:1)∨(p
r3
=0) (6)
For example, (3) must hold because eithe(cid:0)r the action a
2
is opti(cid:1)mal for player 2,
i.e., the utility obtained by player 2 when action a is chosen is greater than or
2
equaltothatwhenactionr ischosenunder theoptimalstrategyofplayer3,or
2
the actiona is chosenwith probability 0.Any assignmentthat satisfies allfour
2
constraints is an equilibrium. Given that p +p = 1, the first clause of (5)
a2 r2
cannot be satisfied and thus we must have p = 0. This is consistent with the
a3
fact that a is dominated for player 3, i.e., action r always yields higher utility
3 3
than a . If p =0, we have p =1, which means that the second clause of (6)
3 a3 r3
has to be false. The first clause of (6) is trivially satisfied. Constraints (3) and
(4) can then be reduced to:
(3·p >1)∨(p =0) (7)
a2 a28 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
(1>3·p )∨(p =0) (8)
a2 r2
Wethenobtainsatisfyingassignmentsbysettingp =1/3andp =2/3,p =
a2 r2 a2
1 and p =0 or p =0 and p = 1 with utility vectors u=(u ,u ,u ) equal
r2 a2 r2 1 2 3
to (−8/9,1/2,1/2), (−1,3/2,1/2) and (0,1/2,1/2), respectively. The proposal
hasthe highestchanceofbeing acceptedinthe secondequilibrium,whenplayer
1 is most confident. However, as player 3 is certain to reject, that is also the
worst equilibrium for player 1, who is bound to be disappointed. The last two
equilibria are social welfare optimal with a combined utility of 1. (cid:4)
3 Equilibria Computation for Psychological Games
We now propose methods for analysing NFPGs in order to determine their PEs
and corresponding values. The approach builds upon techniques for the non-
psychological setting, i.e., finding NEs for NFGs. For the case of two-player
NFGs (bimatrix games), we can use well known approachessuch as the Lemke-
Howson [28] algorithm or mixed-integer programming based on regret min-
imisation [32]. For NFGs with more than two players, algorithms include the
Govindan-Wilson [14] or Simplicial Subdivision [27], as well as search methods
based on support enumeration [30].
We take the support enumeration approach for NFPGs, by adapting the
method of [24], which has been used to find social welfare optimal NEs for
NFGs in a similar fashion. This approach exhaustively inspects sub-regions of
the strategy profile space, based on the idea that searching for NEs within a
specific support (see Definition 3)ofa strategyprofile is computationallyeasier.
It relies on encoding the computation of a (social welfare optimal) NE as a
non-linear programming (NLP) problem.
The NLP encoding leverages conditions for a strategy profile to characterise
an NE, presented as a lemma in [24], and based on the notion of feasibility
program introducedin[9,30].ThelemmastatesthatastrategyprofileofanNFG
is an NE if and only if any player switching to a single action in the support
of the profile yields the same utility for the player, and switching to an action
outside the support can only decrease its utility. We adapt that lemma here to
characteriseaPEofanNFPG.ThisresultfollowsdirectlyfromDefinition8and,
in particular, the fact that in equilibrium the belief profile needs to correspond
to the strategies being played.
Lemma 1. A pair (b,σ) comprising a belief profile b and a strategy profile
σ=(σ 1,...,σ n) of N P = (N,A,u) is a PE if and only if (1) and the following
conditions are satisfied:
∀i∈N.∀a ∈A . σ (a )>0→u (b,σ [η ])=u (b,σ) (9)
i i i i i −i ai i
∀i∈N.∀a ∈A . σ (a )=0→u (b,σ [η ])6u (b,σ) (10)
i i i i i −i ai i
where η is the pure strategy that picks action a with probability 1.
ai iExpectation vs. Reality:Towards Verification of Psychological Games 9
We now extend the NLP encoding of the computation of an NE presented
in [24] to the case of an NFPG N P = (N,A,u). Since this encoding uses a
support enumerationapproach,we need to determine the socialwelfareoptimal
PE amongst strategy profiles from a fixed support Q = Q ×···×Q ⊆ A, i.e.,
1 n
for a given set of actions of each player. We first choose a pivot action qp ∈Q ,
i i
whichcanbeanyactioninQ ,foreachplayeri.Theproblemisthentomaximise:
i
u (b⋆,q)· p (11)
i∈N q∈Q i j∈N qj
(cid:16) (cid:16) (cid:17)(cid:17)
subject to: P P Q
u (b⋆,c)· p − u (b⋆,c)· p =0 (12)
i cj i cj
c∈Q−i(q ip) j∈N−i ! c∈Q−i(qi) j∈N−i !
P Q P Q
u (b⋆,c)· p − u (b⋆,c)· p >0 (13)
i cj i cj
c∈Q−i(q ip) j∈N−i ! c∈Q−i(ai) j∈N−i !
P Q P Q
p =1 and p >0 (14)
qi qi
qi∈Qi
P
foralli∈N,q ∈Q \{qp}anda ∈A \Q whereQ (c )=Q ×···×Q ×{c }
i i i i i i −i i 1 i−1 i
×Q ×···×Q , N =N\{i} and b⋆ ∈B.
i+1 n −i
The variables p representthe probabilities of players choosing different ac-
qi
tions,i.e.theprobabilityplayeriselectsactionq ∈Q .Ifasatisfyingassignment
i i
is found, we have a social welfare optimal PE given by the belief and strategy
profiles pair (b⋆,σ⋆), where, for a ∈A , σ⋆(a )=p if a =q and q ∈Q , and
i i i i qi i i i i
0 otherwise. Following condition (1) of Definition 8, we have b⋆ =β(σ⋆).
Constraints (12) and (13) enforce that the solution corresponds to a PE,
encoding constraints (9) and (10), respectively, of Lemma 1 when restricting
to pivot actions. This restriction is sufficient as (9) requires all actions in the
support to yield the same utility. The objective function in (11) corresponds to
thesumoftheindividualutilitiesoftheplayerswhentheyplayaccordingtothe
profile corresponding to the solution. By maximising it, we require the solution
to be socialwelfareoptimal.As itis possible to havemorethan one equilibrium
for which the sum of utilities is optimal, we specify additional lower priority
objectives to maximise individual payoffs following an increasing sequence of
indices i, and thus output a payoff vector with a consistent ordering.
Example2.Considerthetwo-playerNFPGwhoseutilityfunctionsaregivenby
the matrices in Figure 1 (left). Player 1 has no choice (we write A ={⊥}) and
1
player2choosesanactionfromA ={a ,b }.Player2isindifferent(theirutility
2 2 2
is always0),whereasplayer1’s utility depends on(their expectationabout) the
probability p of a being played. Therefore, player 1’s expected utility (which
a2 2
is also the total expected utility) is a function depending only on p :
a2
400 40
u (p )=− ·p 2+ ·p
1 a2
81
a2
9
a2
Since the only player with a choice is indifferent between their own actions, the
constraintsin(12)and(13)aretriviallysatisfiedforallsupportsaslongas(14)is10 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
1
a2 b2 0.75
Z 1 =⊥ (cid:16)−4 80 10·p a2+4 90 0 (cid:17) 0.5
0.25
a2 b2
0
Z 2 =⊥ (cid:16) 0 0 (cid:17) −0.25
−0.5
0 0.2 0.4 0.6 0.8 1
p
a2
Fig.1: Player utilities (left) and total expected utility (right) for Example 2.
alsosatisfied,andthusanystrategyprofile(withanaccompanyingbeliefprofile)
is an equilibrium. Figure 1 (right) plots the total expected utility. This shows
that, in order to achieve the maximum value of 1, player 2 has to randomise,
picking actions a and b with probabilities 0.45 and 0.55, respectively. (cid:4)
2 2
The above example illustrates a contrast with (non-psychological) NFGs, and
gives an indication of why computing optimal equilibria for NFPGs is more
computationally challenging. For NFGs, it suffices to consider pure strategies
only when finding optimal equilibria with a single active player. This can be
exploited [25], avoiding the need to solve an optimisation problem for a given
support.ForNFPGs,thenon-linearityinthefunctionforexpectedutilitymeans
that pure strategies no longer suffice for an indifferent player.
4 Psychological Concurrent Stochastic Games
We next consider concurrent stochastic games (CSGs) [33], which are multi-
stagegamesplayedovergraphswhere,ateachstate,playersmakesimultaneous
choices that cause the game’s state to be probabilistically updated. We present
a psychological variantof CSGs,inwhich, similarlyto NFPGs,a player’sutility
(reward accumulated over a finite horizon) can depend on its belief as to the
strategies to be played as well as the actions that players select. We outline a
procedure to compute equilibria for a class of such games, which restricts the
nature of the players’ beliefs. As in previous work for CSGs [23], we consider
subgame perfect equilibria, which are equilibria at every state of a CSG.
Definition 9 (Concurrentstochasticgame).Aconcurrentstochasticmulti-
player game (CSG) is a tuple C=(N,S,s¯,A,∆,δ) where:
– N ={1,...,n} is a finite set of players;
– S is a finite set of states and s¯∈S is the initial state;
– A=(A ∪{⊥})×···×(A ∪{⊥})where A is afiniteset ofactions available
1 n i
to player i∈N, A ∩A =∅ for i6=j ∈N and ⊥ is an idle action disjoint
i j
from the set ∪n A ;
i=1 i
– ∆: S →2∪n i=1Ai is an action assignment function;
– δ: (S×A)→Dist(S) is a probabilistic transition function.
ytilituExpectation vs. Reality:Towards Verification of Psychological Games 11
Weassumewithoutlossofgeneralitythat,foranyi,j ∈N,i6=j,A ∩ A =∅.
i j
AgivenCSGCstartsintheinitialstates¯and,wheninstates,eachplayeri∈N
selects an action from its available actions A (s) d=ef∆(s)∩A if this set is non-
i i
empty,andfrom{⊥}otherwise.Assumingeachplayeriselectsactiona ,thenext
i
stateofthegameisdeterminedaccordingtothedistributionδ(s,(a ,...,a )).A
1 n
path of C is a sequence π =s −α →0 s −α →1 ··· where s ∈S, α =(ak,...,ak)∈
0 1 k k 1 n
A, ak ∈ A (s ) for i ∈ N and δ(s ,α )(s ) > 0 for all k > 0. We denote by
i i k k k k+1
π(i)the(i+1)thstateofπ,π[i]theactionassociatedwiththe(i+1)thtransition
and, if π is finite, last(π) the final state. Let FPaths and IPaths denote the sets
of finite and infinite paths that start in the initial state, respectively.
A strategy for a player in C resolvesthe player’schoices in each state. These
choices can depend on the execution history and can be randomised, i.e., are
of the form σ : FPaths → Dist(A ) such that if σ (π)(a ) > 0, then a ∈
i i i i i
A (last(π)). As for NFGs, a strategy profile for C is a tuple σ = (σ ,...,σ ) of
i 1 n
strategies for all players. For a given strategy profile σ, a probability measure
Probσ over the infinite paths of C can then be defined in the standardway [20].
C
Psychological CSGs. In order to introduce a psychological variant of CSGs,
we incorporatea notionof beliefs, and then use them to define rewards.Let BA
i
denote, as defined in Section 2, the set of (collectively coherent, higher-order)
beliefsforplayeri,wherefirst-orderbeliefsareoverthesetofactionsA.Abelief
b for player is of the form b : S → BA. It is state-based, in that it provides a
i i i
separatebeliefforeachstatesoftheCSG,andlocal,inthatthesebeliefsgivethe
player’s expectations regarding the actions to be played in s, not about a more
global notion of the player’s strategy. A belief profile is a tuple b=(b ,...,b ).
1 n
A reward structure for player i takes the form r =(rA,rS), where rA: (S×
i i i i
BA×A)→Qisanactionrewardfunction(whichmapsastate,beliefandaction
i
tupletoarationalvaluethatisaccumulatedwhentheactiontupleisselectedin
thestate,assumingagivenlocalbeliefforplayeriinthatstate)andrS: S →Q
i
is a state reward function (which maps each state to a rational value that is
accumulated when the state is passed through).
Theutility (orobjective) foraplayeriinCSGCcanbedefinedbyarandom
variable X :IPaths →R mapping infinite paths to reals. We denote by Eσ(X )
i C i
the expected value of player i’s utility under σ, with respect to the probabil-
ity measure Probσ C. Given utilities X 1,...,X
n
for all the players of C, we can
thendefine(socialwelfare)psychologicalNashequilibria,asforNFPGs.Wewill
restrict our attention to utilities that correspond to finite-horizon objectives,
which may be used to investigate, for instance, the expected reward accumu-
lated over k steps. Such utilities can be expressed by a finite bound k ∈ N and
reward structure r =(rA,rS), with corresponding random variable:
i i i
X (π)= k−1 rA(π(j),b (π(j)),π[j])+rS(π(j)) .
i j=0 i i i
P (cid:0) (cid:1)
Psychological equilibria computation. In both [13] and [5], the authors
pointoutthelimitationsofapplyingbackwardinductiontocomputingequilibria
for extensive (multi-stage) psychological games and show why that approach12 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
cannot be applied to the general case. While a full discussion is outside the
scope of this paper, it suffices to imagine a game in which a player’s utility in
a given state depends on the beliefs they have about actions performed in the
preceding state.Abackwardinductionalgorithmcan,however,beappliedunder
the assumption that psychological utilities at any given state have to be over
local strategies, that is, concerning the actions taken at that same state and
coherentwith anequilibriumsolutionfor the NFPG inthat state.We note that
amoregeneralapproachhasbeenproposedin[5],whichweleaveasfuturework.
Using the above restriction, we devise a backward induction algorithm that
builds,ateachiteration,anNFPGforeverystatesinCaccordingtothereward
structure in s and the values computed for its successors in the previous itera-
tion (initially 0 for all states). We then compute equilibria values andstrategies
by solving the corresponding NLPs following the definitions in Section 3. We
compute equilibria which are locally social welfare optimal. Other criteria, e.g.,
social cost [25] or social fair [26] equilibria, which minimise the overall sum or
the difference between the highest and lowest utilities, respectively, could also
be applied. In the latter case, however, additional constraints would have to be
added to the NLP in Section 3, which would significantly increase the complex-
ity of the problem due to the need to numerically encode logical implications.
Finding all equilibria for a CSG is generally intractable, as the number may be
exponentialevenwithrespecttothe sizeofthe normalformgameateachstate.
5 Case Studies and Experimental Results
We have built a prototype implementation to model and solve psychological
games, and used it to investigate the applicability and performance of our ap-
proach on a selection of normal form and multi-stage psychological games. We
firstconsidertwo-playerinstancesofthe ultimatum andreciprocity gamesof[6],
which exemplify how psychological games can also be used in the computation
of fairness equilibria, as well as how psychological utilities can influence the
strategies of the players. We then present two- and multi-player normal form
games modelling traffic interactions between pedestrians, cyclists and vehicles,
one of which is then extended to a psychological CSG, used to investigate how
information on past decisions can influence players’strategies.
Implementation. We build on top of the PRISM-games model checker [23],
extendingitsexistingmodellinglanguageforCSGs(inwhichnormalformgames
canalsobeencodedassimpleinstances).ThekeydifferenceisthatinPGmodels
thespecificationofrewardstructuresneedstoincorporateaplayer’sbeliefsabout
the other players’ strategies. Since we currently only allow for beliefs in CSGs
overlocalstrategies (see Section 4), rewardsfor a state can only make reference
to (the probability of) actions played in that state. Figure 2 shows a reward
structuredefinitioninourextensionofthe PRISM-gamemodellinglanguagefor
the ultimatum game example (see Section 5.1, below). For simplicity, in this
syntax,we just use the name ofthe actionto denote the probability ofchoosing
it, e.g., reject denotes what we refer to elsewhere as p .
rejectExpectation vs. Reality:Towards Verification of Psychological Games 13
1 // Constants
2 const double theta1; // Player 1’s reciprocity sensitivity
3 const double theta2; // Player 2’s reciprocity sensitivity
4 // Rewards for player 1
5 rewards "r1"
6 [fair,reject] true : 5+theta1*(-4.5)*(2+0.5*reject);
7 [fair,accept] true : 5+theta1*(4.5)*(2+0.5*reject);
8 [greedy,reject] true : 0+theta1*(-4.5)*(-2-0.5*reject);
9 [greedy,accept] true : 9+theta1*(4.5)*(-2-0.5*reject);
10 endrewards
11 // Rewards for player 2
12 rewards "r2"
13 [fair,reject] true : 5+theta2*(-4.5)*(2+0.5*reject);
14 [fair,accept] true : 5+theta2*(4.5)*(2+0.5*reject);
15 [greedy,reject] true : 0+theta2*(-4.5)*(-2-0.5*reject);
16 [greedy,accept] true : 1+theta2*(4.5)*(-2-0.5*reject);
17 endrewards
Fig.2: Reward structures for the ultimatum game, modelled in PRISM-games.
As for regular CSGs, our extension of PRISM-games constructs and stores
PG models using the tool’s Java-based ‘explicit’ engine. In contrast to CSGs,
reward structures for PG models are represented by symbolic expressions over
variables representing action choice probabilities and cannot be evaluated prior
to model checking.We use Gurobi [15] to solvethe NLPs describedin Section3
for finding equilibria values of NFPGs at each state.
Efficiency and Scalability.Computingequilibriavaluesandstrategiescanbe
a complex task, even for the simpler case of finding an arbitrary (non-optimal)
equilibrium of a two-player normal form game. Finding optimal equilibria of
multi-player games is considerably harder, given the increased number of sup-
ports and the non-linearity of the constraints. The addition of psychological
utilities complicates the computation further, as there are no natural restric-
tionsonhowtheseutilitiesmayvarygiventheplayers’strategiesandbeliefs.At
thestatelevel,whenlookingforanoptimalequilibrium,wearerequiredtosolve
an NLP for each support. Given the total number of supports is exponential in
thenumberofactions,i.e.,equals n (2|Ai|−1),computingoptimalvaluesvia
i=1
enumeration can only be efficient for small games.
Q
5.1 Reciprocity and Ultimatum Games
We consideredinstances ofthe reciprocity andultimatum gamesfrom[6],which
are shownin Figure 3. In eachcase, player1 choosesbetween making a fair (f)
or greedy (g) proposal, and player 2 decides to reject (r) or accept (a) it. The
rectangularboxesshowthecorrespondingutilitiesofplayers1and2,withplayer
1’s utility being above that of player 2. We present the games, as in [6], in
extensiveform,withtheplayers’decisionstakensequentially,butwilltreatthem
as simultaneous moves in a single NFPG. Otherwise, beliefs would no longer be
local since player 2’s utility would depend on an earlier decision by player 1.14 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
1 1
fair greedy fair greedy
5 5
5 2 5 2
reject accept reject accept
1 9 0 9
9 1 0 1
(a) Reciprocity game (b) Ultimatum game
Fig.3:Reciprocityandultimatumgamesinextensiveform.Theutilitiesforplay-
ers 1and2 aregiveninthe topandbottom rowsofeachleafnode, respectively.
In both games, player i attempts to maximise the expectation of a utility
functionthatdependsonthechosenactions(α)andbelief(b)andhastheform:
u (α,b)=λ (α)+θ ·κ (α,b)·κ (α,b)
i i i ij ji
whereλ isamaterial utilityfunction(thesearetheutilitiesshowninFigure3),
i
κ reflectsplayeri’skindness toplayerj(expectedmaterialpayoff,whichranges
ij
from negative to positive) and θ ∈R is player i’s reciprocity sensitivity. This
i >0
type of game was originally studied in the context of fairness equilibria [31], in
order to model and investigate scenarios in which agents are willing to sacrifice
material utility to help or punish others depending on how they think they are
being treated.
Theconceptofkindnesswasintroducedin[31]asawaytomeasurethistype
of feeling, and is calculated as the difference between the utility that player i
believes player j will receive (given player i’s choice) minus the average of the
minimumandmaximumutilities playeribelievesplayerj couldgetfori’sother
choices.Forinstance,inthereciprocitygame,ifplayer1choosesfair, κ equals
12
5−1/2·(5+(9·p +1·(1−p ))=2−4·p .Asbefore,weusep fortheprobability
r r r r
of player 2 choosing action r and p for player 1’s belief as to this value.
r
Reciprocating kindness is expressed by the matching of signs of κ and κ .
ij ji
Thus, if, by adopting a particular strategy, player i is perceived to be unkind
to player j, κ will be negative, which will in return motivate player j to be
ij
unkind to player i so that the product of κ and κ is positive. A similar logic
ij ji
applies to when players are perceived to be kind.
As explained earlier in Example 1, when writing the matrices for players’
utility values, we can assume that p =p in equilibrium and just express them
r r
as functions of the probability p . For the reciprocity game we thus have:
r
r a
f 5+θ ·(−4)·(2−4·p ) 5+θ ·(4)·(2−4·p )
Zreciprocity = 1 r 1 r
1
g 1+θ 1·(−4)·(4·p r−2) 9+θ 1·(4)·(4·p r−2)!
r a
f 5+θ ·(−4)·(2−4·p ) 5+θ ·(4)·(2−4·p )
Zreciprocity = 2 r 2 r
2
g 9+θ 2·(−4)·(4·p
r
−2) 1+θ 2·(4)·(4·p r−2)!Expectation vs. Reality:Towards Verification of Psychological Games 15
pg pa u1 u2
1 1 13 13
0.75 0.75
0.5 0.5 9 9
0.25 0.25
0 0 5 5
1 0 1 0 1 0 1 0
0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
0 1 0 1 0 1 0 1
θ1 θ2 θ1 θ2 θ1 θ2 θ1 θ2
pg pa u1 u2
1 1 14 14
0.75 0.75
0.5 0.5 7 7
0.25 0.25
0 0 0 0
1 0 1 0 1 0 1 0
0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
0 1 0 1 0 1 0 1
θ1 θ2 θ1 θ2 θ1 θ2 θ1 θ2
Fig.4:Possible socialwelfare PEs for the reciprocity(top) and ultimatum (bot-
tom) games for a range of reciprocity sensitivities θ ,θ . We show the strategy
1 2
(probabilities p , p of choosinggreedy, accept) andvalues (utilities u and u ).
g a 1 2
and for the ultimatum game:
r a
f 5+θ ·(−9/2)·(2+p /2) 5+θ ·(9/2)·(2+p /2)
Zultimatum = 1 r 1 r
1
g 0+θ 1·(−9/2)·(−2−p r/2) 9+θ 1·(9/2)·(−2−p r/2)!
r a
f 5+θ ·(−9/2)·(2+p /2) 5+θ ·(9/2)·(2+p /2)
Zultimatum = 2 r 2 r
2
g 0+θ 2·(−9/2)·(−2−p r/2) 1+θ 2·(9/2)·(−2−p r/2)!
Figure4 presentsthe strategiesandutility valuesfor SWNEsthat wegenerated
for the reciprocity and ultimatum games using different values of θ and θ .
1 2
Although the games are very similar in structure (there is an equal amount
of material utility that can be split by the two players in different ways), it
is possible to see how the reciprocity sensitivity affects their behaviours and
overall utilities. For instance, in the ultimatum game, when θ = θ = 0 the
1 2
playersare strictly concernedwith their materialutilities and(greedy,accept)is
an acceptable SWNE as the sum of utilities is 10. It is possible to see though
that, as θ increases, player 1 is less likely to play greedy as the split becomes
2
less fair for player 2, who could then retaliate by playing reject.
Wecanalsonoticethat,whenθ =θ =1,theequilibriumforthereciprocity
1 2
andultimatumgamesis(fair,accept)which,despiteleadingtomaterialutilities
of (5,5) in both games, accounts for different overallutilities for the players. In
the former, the utility for each player is equal to u (fair,accept) = 5+1·4·(2−
i
4·p )=13, and for the latter it corresponds to u (fair,accept)=5+1·9/2·(2+
r i
p /2)=14.
r16 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
cross/
wait
γ 1−γ
maintain/
reduce
Fig.5: An illustration for the pedestrian crossing scenario.
5.2 Traffic Games
Wenowreportonaselectionofcasestudiesinspiredbygame-theoreticmodelsof
trafficandroaduserbehaviour.Westartwithasimpleone-shotgamebetweena
vehicle and a pedestrianin a roadcrossingscenario,and how their expectations
can incentivise safe behaviour.Next we introduce a psychologicalvariant of the
Bayesian game presented in [29], which examined how cyclists would interact
differently with autonomous and regular vehicles. Finally, we extend the road
crossingscenariointoaCSGandinvestigatetheimpactofcombininginformation
on past decisions with local expectations in a multi-stage, probabilistic model.
Pedestrian crossing. We consider a scenario where a pedestrian is deciding
whethertocrossaroadnearoncomingtraffic,illustratedinFigure5.Weassume
that the car has a right of way and can reduce (r) or maintain (m) its speed,
while the pedestrian may choose to cross (c) or wait (w). A psychologicalgame
can be constructed by including incentives set to discourage behaviour based
on what they expect the other will do. We assume the pedestrian would be
(illegally)jaywalkingiftheydecidedtocross,andsogivethemanegativereward
proportional to the probability p of that action being taken (multiplied by a
c
constant µ), to model the pedestrian’s fear of being caught and incurring a
penalty. This parameterisation results in the following utility matrices for the
vehicle and the pedestrian:
w c w c
r 1−p 1+p r 1−p 1+p −µ·p
Z = w c Z = r r c
vehicle m 1+p 1−p pedestrian m 1+p 1−p −µ·p
w c m m c
(cid:18) (cid:19) (cid:18) (cid:19)
Figure 6 shows equilibriastrategy profilesand utilities ofthis game for different
values of µ (a more detailed version can be found in Figure 12, Appendix A).
The colours for the points in the bottom and top plots for each value of µExpectation vs. Reality:Towards Verification of Psychological Games 17
µ=1 µ=2 µ=3 µ=4 µ=5
2 2 2 2 2
1 1 1 1 1
0 0 0.5 1 00.51 0 0 0.5 1 00.51 0 0 0.5 1 00.51 0 0 0.5 1 00.51 0 0 0.5 1 00.51
pm pr pm pr pm pr pm pr pm pr
2 2 2 2 2
1 1 1 1 1
0 0 0.5 1 00.51 0 0 0.5 1 00.51 0 0 0.5 1 00.51 0 0 0.5 1 00.51 0 0 0.5 1 00.51
pc pw pc pw pc pw pc pw pc pw
Fig.6: Equilibria strategies and utilities for the vehicle (top) and pedestrian
(bottom) in the pedestrian crossing scenario, for different values of µ.
1 1
yield cycle yield cycle
walk walk
2 2 2 2 2 2
go stop go stop go stop go stop go stop go stop
5 3 -400 15 -500 20 8 6 -400 15 -500 20
7 10 -500 15 -300 15 15 1 -400 7 -200 7
(a) Autonomous Vehicle (b) Human Driver
Fig.7: Original cyclist vs. vehicle game. In [29], the left and right games are
played with probabilities p and 1−p, respectively. The utilities for the cyclist
(1) and the vehicle (2) are given in the top and bottom rows of each leaf node.
serve to match the profiles and utilities of the pedestrian and the vehicle for
differentequilibria.Whileitispossibletoseethatthereisalwaysanequilibrium
(displayed in red) in which the vehicle maintains its speed and the pedestrian
waits,forsmallervaluesofµwealsohaveanequilibriumstrategyprofileinwhich
bothagentsmakerandomchoices.Forexample,intheequilibriumshowninblue
for µ = 2, the vehicle randomly chooses between reducing and maintaining its
speed with probabilities 3/4 and 1/4 respectively, while the pedestrian crosses
or not with probability 1/2, potentially leading to unsafe behaviour. As the
pedestrian’s uneasiness about crossing grows, i.e., as µ increases, the strategy
profiles in which they cross with positive probability disappear, with the only
remaining profile for µ=5 being the one in which they wait.
Cyclist vs. vehicle. Next,we modela cyclistanda vehicle,where the latter is
either autonomous or drivenby a human, at a roadjunction. A similar scenario
was considered in [29], but modelled as a Bayesian game to investigate how
increasingtheshareofautonomousvehiclesaffectstherateofcollisions.Figure7
showsthe gamein extensiveform.The actionsforthe cyclistareyield (y), walk
(w) and cycle (c), and the actions for the vehicle are go (g) and stop (s).
The utilities of the players reflect preferences over potential collisions, in
accordancewithtrafficrulesandanassumptiononthepartofthecyclistthatan
ytilitu
ytilitu18 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
α u u u α u u u
nature cyclist vehicle nature cyclist vehicle
(a,y,g) 0 5·p a 7 (h,y,g) 0 8·p h 15
(a,y,s) 0 3·p a 10 (h,y,s) 0 6·p h 1
(a,w,g) 0 −400·p a -500 (h,w,g) 0 −400·p h -400
(a,w,s) 0 15·p a -15 (h,w,s) 0 15·p h 7
(a,c,g) 0 −500·p a -300 (h,c,g) 0 −500·p h -200
(a,c,s) 0 20·p a 15 (h,c,s) 0 20·p h 7
Table 1: Psychological cyclist vs. vehicle game in normal form. Nature chooses
between autonomous vehicle (a) or human driver (h).
cyclist vehicle nature
1
20 15
15 0.8 =
10 = =
10 0.6
5 5 0.4
0 0 0.2
0 0
0.5 10 0.5 1 0.5 10 0.5 1 0 0 0.2 0.4 0.6 0.8 1
py pc pg ps pa
Fig.8: Strategies and utilities for the cyclist vs. vehicle game.
autonomousvehicle(AV)wouldbeprogrammedtobeasrisk averse aspossible,
while human drivers are often (unintentionally) distracted. So, for example, the
penalty for an AV not stopping while the cyclist crossesthe roadis higher than
for a human-driven vehicle (300 vs. 200). In the original game, it is assumed
that a virtual nature player chooses the type of the vehicle according to a prior
distribution. Here, we consider nature to be an active albeit indifferent player
picking autonomous (a) or human (h), and we set the utilities for the cyclist
to be the original utilities multiplied by their expectation of the vehicle being
driven autonomously (p ) or by a human (p ), as detailed in Table 1.
a h
Figure8showsresultsforthisvariant(amoredetailedversionisinFigure11
ofAppendixA).Inadditiontotheequilibriacomputedin[29](indicatedinblue,
orange3,magentaandbrown),twonewequilibria(indicatedingreenandred)are
presentforthepsychologicalvariant,inwhichnature randomlychoosesbetween
an autonomous vehicle and one with a human driver with probabilities p =
a
14/17 and p = 3/17. Considering the original model from [29] and combining
h
the utilities of the two original games (Figure 7(a) and (b)) into one normal
form game by multiplying the corresponding utilities by p or 1−p, we obtain
the bimatrix game as follows:
g s g s
y −3·p+8 −3·p+6 y −8·p+15 9·p+1
Z = w −400 15 Z = w −100·p−400 14·p+7
cyclist vehicle
   
c −500 20 c −100·p−200 8·p+7
   
3 The utility and strategy for the cyclist are thesame as for the one in magenta.
ytilitu ytilitu
hpExpectation vs. Reality:Towards Verification of Psychological Games 19
s0 h0,0,0i
(w,r)
γ·(1−γ) γ·(1−γ)
(1−γ)·(1−γ) γ·γ
h1,0,0i s1 h1,0,1i s2 s3 h1,1,0i s4 h1,1,1i
Fig.9: Transitions for actions (w,r) from the initial state of the CSG for the
multi-stage pedestrian crossing example. States are of the form hj,c ,c i, for
r w
step count j and variables c , c .
r w
We observe that, if the cyclist decides to yield, the vehicle would only play go
with positive probability if −8·p+15>9·p+1, which gives p614/17.For any
value of p above that threshold, the game has only one equilibrium in (cycle,
stop), with utilities (20,8·p+7). The analysis in [29] suggests that the number
of collisions, i.e., the outcome where the cyclist chooses cycle and the vehicle
chooses go, drops as the proportion of AVs increases. Indeed, if we only have
AVs circulating, the only equilibrium (magenta) is (cycle, stop). However, by
modelling this scenario as a three-player game with nature as an active player,
we seeinFigure 8(andinmoredetailinFigure 11ofAppendix A),fora mix of
AVsandhuman-drivenvehicles,whereAVscorrespondtoapproximately82%of
the fleet,thatthe equilibriumstrategy(greenandred)for the cyclistis actually
to yield. Furthermore, the vehicles can follow two different strategies: one in
which they would go with probability 1 and another in which they stop with
probability approximately 0.97 (shown in red and green, respectively). Finally,
the model in [29] assumes that the cyclists can always differentiate between an
AV and a human-driven vehicle, which is not realistic. In contrast, our model
allowsforthepossibilityofspecifyingpsychologicalpayoffs,meaningtheactions
taken by the cyclist can vary according to their beliefs about the type of the
vehicle, paving the way for more sophisticated models of similar scenarios.
Multi-stage pedestrian crossing. Finally, we consider a probabilistic,multi-
stage version of the earlier pedestrian crossing game, modelled as a CSG with
psychologicalutilities. The state of the CSG has a variable j counting the num-
ber of times the one-shot pedestrian game has been repeated. We also add two
discrete integer-valued variables c ,c ∈ {0,1,...,10} in order to carry infor-
r w
mation forward about the actions taken by both agents. The variables c and
r
c are initialised to 0 and go up (or down) by 1 when the vehicle reduces (or
w
maintains) its speed, and the pedestrian decides to wait (or cross), respectively.
To account for the fact that these observations can be imperfectly made by
the players, c and c are updated probabilistically according to an attention
r w
coefficient γ ∈ [0,1], and so their values can also remain the same with proba-
bility 1−γ,as illustratedinFigure 9.The informationonpastdecisionscarried
by the values of the two variables is then weighted with the local expectations20 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
18 0.7
k=5 k=6 k=7 k=5 k=6 k=7
16 k=8 k=9 k=10 0.65 k=8 k=9 k=10
14
0.6
12
0.55
10
0.5
8
6 0.45
4 0.4
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
γ γ
20 0.8
k=5 k=6 k=7 k=5 k=6 k=7
18 k=8 k=9 k=10 0.75 k=8 k=9 k=10
16
0.7
14
0.65
12
0.6
10
8 0.55
6 0.5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
γ γ
Fig.10:Utility (left) andprobabilityaverages(right)oversampledequilibriafor
different path lengths in the multi-stage pedestrian crossing example.
at each state by modifying the reward matrices in following manner:
w c
r 1−(1/2)·(p +c /10) (3/2)+(1/2)·(p −c /10)
Z = w w c w
vehicle
m 1+(1/2)·(p w+c w/10) (1/2)−(1/2)·(p c−c w/10)!
w c
r 1−(1/2)·(p +c /10) 1+(1/2)·(p +c /10)−µ·p
Z = r r r r c
pedestrian
m (3/2)+(1/2)·(p m−c r/10) (1/2)−(1/2)·(p m−c r/10)−µ·p c!
Figure10showsexpectedutility values andcrossingprobabilityaveragesfor
different values of γ, paths of length k and µ = 1. In a similar fashion to the
one-shotexample,we do notfocus exclusivelyonthe socialwelfaresolutionand
therecouldbemultipleequilibriafortheNFPGsbuiltateachstate.However,for
extensiveormulti-stagegames,itisimpracticaltocomputeallpossibleequilibria
unless the number of states is fairly small. This is particularly true when there
is probabilisticbranching,asthe numberofequilibria (andhence the number of
NLPstobesolved)maygrowveryrapidly.Forthisreason,theprobabilityvalues
reported in Figure 10 (right) are averages over equilibria selected uniformly at
randomateachstate.For eachpathlength andγ,10experiments wererunand
the utility averages for the initial state are displayed in Figure 10 (left).
As the value of γ grows, it is possible to notice a trend in which the pedes-
trian’s behaviour is safer, with the average probability of a crossing decreasing
(top right). This is also reflected in higher utility for the pedestrian (top left),
ytilitu
s’nairtsedep
ytilitus’elcihev
gnissorcfoytilibaborp
gnicuderfoytilibaborpExpectation vs. Reality:Towards Verification of Psychological Games 21
γ ∈ k States Transitions Time(s) k States Transitions Time(s)
[0,0] 6 21 0.76 9 33 1.33
(0,1) 5 91 701 5.97 8 285 2,806 25.7
[1,1] 91 256 4.82 285 897 23.1
[0,0] 7 25 0.83 10 37 1.73
(0,1) 6 140 1,198 9.12 9 385 3,981 39.6
[1,1] 140 413 8.45 385 1,240 35.1
[0,0] 8 29 1.06 11 41 2.09
(0,1) 7 204 1,889 15.9 10 506 5,446 58.7
[1,1] 204 624 14.5 506 1,661 51.9
Table 2: Statistics for the (CSG) multi-stage pedestrian crossing case study.
particularly when considering longer paths. For the vehicle, the utility aver-
ages (bottom left) remain fairly stable but we can also see that the likelihood
of it reducing its speed (bottom right) decreases. This behaviour is desirable,
considering it happens in coordination with decreasing probability values of a
pedestrian crossing and the fact that the vehicle should have a right of way.
To provide an indication of model sizes that we are able to analyse, Table 2
showshowthenumberofCSGstatesandtransitions,andthe averagecomputa-
tiontime, vary for differentvalues ofk and intervalsofγ (note that the number
of transitions and states is the same for any value of γ ∈(0,1), see Figure 9).
6 Conclusions
We have presented techniques that expand the scope of modelling and verifica-
tionforgame-theoreticprobabilisticmodels.Startingwithpsychologicalnormal
form games, we proposed an NLP encoding that allows us to compute optimal
equilibria for individual supports and, through support enumeration, an overall
optimal equilibrium for a given NFPG. We then considered CSGs whose states
can be expressed as NFPGs, and developed an algorithm to compute equilib-
ria for such CSGs under some restrictions on the type of the players’ beliefs.
Finally, we reported on a prototype implementation and showcased novel auto-
mated analysis, made possible through our method, for a range of case studies.
Verification of psychological games is still a largely unexplored topic and
there is ample room for expansion in theory, practice and applications to prob-
lems in computer science. Equilibria computation is a hard problem in general,
and algorithms for psychological equilibria suffer from some of the same com-
putational drawbacks as those for Nash or correlated equilibria, in addition to
presentingnewchallengesoftheirown.Themaincurrentlimitationishavingto
rely on enumeration for computing an optimal solution, which could be some-
what mitigated by parallelisation and filtering supports as a precomputation
step.Future workincludesinvestigatingdynamicpsychologicalgames[5],which
havethe advantageof allowingbelief updates but pose new modelling and com-
putational challenges, and considering aspects of coordination and robustness
via correlated [1] and trembling-hand [21] variants.22 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
Acknowledgements.ThisprojectwasfundedbytheERCundertheEuropean
Union’sHorizon2020researchandinnovationprogramme(FUN2MODEL,grant
agreement No.834115).
References
1. Andr´es, P.: From decision theory to game theory: Reasoning about decisions of
others (2024), Manuscript in preparation, Cambridge UniversityPress.
2. Aslanyan, Z., Nielson, F., Parker, D.: Quantitative verification and synthesis of
attack-defencescenarios. In:Proc. CSF’16. pp. 105–119. IEEE (2016)
3. Attanasi,G.,Nagel,R.:Asurveyofpsychologicalgames:Theoreticalfindingsand
experimental evidence. In: Innocenti, A., Sbriglia, P. (eds.) Games, Rationality
and Behavior. Essays on Behavioral Game Theory and Experiments. pp. 204–232
(2008)
4. Battigalli,P.,Corrao,R.,Dufwenberg,M.:Incorporatingbelief-dependentmotiva-
tioningames.JournalofEconomicBehavior&Organization167,185–218 (2019)
5. Battigalli,P.,Dufwenberg,M.:Dynamicpsychologicalgames.JournalofEconomic
Theory 144(1), 1–35 (2009)
6. Battigalli, P., Dufwenberg, M.: Belief-dependent motivations and psychological
game theory.Journal of Economic Literature 60(3), 833–82 (2022)
7. Bjørnskau,T.: Thezebracrossing game –usinggame theorytoexplain adiscrep-
ancy between road userbehaviour and traffic rules. Safety Science 92 (2015)
8. Brenguier, R.: PRALINE: A tool for computing Nash equilibria in concurrent
games. In:Proc. CAV’13. LNCS, vol. 8044, pp. 890–895. Springer (2013)
9. Dickhaut, J., Kaplan, T.: A Program for Finding Nash Equilibria, pp. 148–166.
SpringerNew York,New York,NY (1993)
10. Elvik, R.: A review of game-theoretic models of road user behaviour. Accident
Analysis & Prevention 62, 388–396 (2014)
11. Ezzati Amini, R., Abouelela, M., Dhamaniya, A., Friedrich, B., Antoniou, C.: A
game-theoretic approach for modelling pedestrian-vehicle conflict resolutions in
uncontrolled traffic environments. Accident Analysis & Prevention 203, 107604
(2024)
12. Feng, L., Wiltsche, C., Humphrey, L., Topcu, U.: Synthesis of human-in-the-loop
controlprotocolsforautonomoussystems.IEEETransactionsonAutomationSci-
enceand Engineering 13(2), 450–462 (2016)
13. Geanakoplos, J., Pearce, D., Stacchetti, E.: Psychological games and sequential
rationality. Games and Economic Behavior 1(1), 60–79 (1989)
14. Govindan, S., Wilson, R.: A global Newton method to compute Nash equilibria.
Journal of Economic Theory 110(1), 65–86 (2003)
15. Gurobi Optimization, LLC: Gurobi Optimizer Reference Manual (2021),
gurobi.com
16. Hensel, C., Junges, S., Katoen, J.P., Quatmann, T., Volk, M.: The probabilis-
tic model checker Storm. International Journal on Software Tools for Technology
Transfer 24(4), 589–610 (2022)
17. J. Gutierrez, J., Najib, M., Perelli, G., Wooldridge, M.: Eve: A tool for temporal
equilibriumanalysis. In:Proc.ATVA’18.LNCS,vol.11138, pp.551–557. Springer
(2018), github.com/eve-mas/eve-parity
18. Junges, S., Jansen, N., Katoen, J.P., Topcu, U., Zhang, R., Hayhoe, M.: Model
checkingforsafenavigationamonghumans.In:Proc.QEST’18.LNCS,vol.11024,
pp.207–222. Springer(2018)Expectation vs. Reality:Towards Verification of Psychological Games 23
19. Karabag, M.O., Smith, S., Fridovich-Keil, D., Topcu, U.: Encouraging inferable
behavior for autonomy: Repeated bimatrix stackelberg games with observations
(2023)
20. Kemeny,J., Snell, J., Knapp,A.: DenumerableMarkov Chains. Springer (1976)
21. Kolpin, V.: Equilibrium refinement in psychological games. Games and Economic
Behavior 4(2), 218–231 (1992)
22. Kwiatkowska,M.,Norman,G.,Parker,D.:PRISM4.0:Verificationofprobabilistic
real-timesystems.In:Proc.CAV’11.LNCS,vol.6806,pp.585–591.Springer(2011)
23. Kwiatkowska,M.,Norman,G.,Parker,D.,Santos,G.:PRISM-games3.0:Stochas-
tic game verification with concurrency, equilibria and time. In: Proc. CAV’20.
LNCS,vol. 12225, pp. 475–487. Springer (2020)
24. Kwiatkowska,M.,Norman,G.,Parker,D.,Santos,G.:Multi-playerequilibriaver-
ification for concurrent stochastic games. In: Proc. QEST’20. LNCS, vol. 12289,
pp.74–95. Springer(2020)
25. Kwiatkowska, M., Norman, G., Parker, D., Santos, G.: Automatic verification of
concurrent stochastic systems. Formal Methods in System Design 58, 188–250
(2021)
26. Kwiatkowska, M., Norman, G., Parker, D., Santos, G.: Correlated equilibria and
fairness in concurrent stochastic games. In: Proc. TACAS’22. LNCS, vol. 13244,
pp.60–78. Springer(2022)
27. Laan, G.V.D., Talman, A.J.J., Heyden, L.V.D.: Simplicial variable dimension al-
gorithms for solving the nonlinear complementarity problem on a product of unit
simplices using a general labelling. Mathematics of Operations Research 12(3),
377–397 (1987)
28. Lemke, C., J. Howson, J.: Equilibrium points of bimatrix games. Journal of the
Society for Industrialand Applied Mathematics 12(2), 413–423 (1964)
29. Michieli, U., Badia, L.: Game theoretic analysis of road user safety scenarios in-
volvingautonomous vehicles. In:Proc. PIMRC’18. pp.1377–1381 (2018)
30. Porter, R., Nudelman,E., Shoham, Y.: Simple search methods for finding a Nash
equilibrium. In:Proc. AAAI’04.pp. 664–669. AAAIPress (2004)
31. Rabin,M.:Incorporatingfairnessintogametheoryandeconomics. TheAmerican
economic review pp.1281–1302 (1993)
32. Sandholm, T., Gilpin, A., Conitzer, V.: Mixed-integer programming methods for
findingNash equilibria. In:Proc. AAAI’05. pp.495–501. AAAIPress (2005)
33. Shapley,L.:Stochasticgames. Proc.NationalAcademyofSciences39,1095–1100
(1953)
34. Shirado,H.,Kasahara,S.,Christakis,N.A.:Emergenceandcollapseofreciprocity
in semiautomatic driving coordination experiments with humans. Proc. National
Academy of Sciences 120(51) (2023)
35. Toumi, A., Gutierrez, J., Wooldridge, M.: A tool for the automated verification
ofNashequilibriain concurrentgames. In:Proc. ICTAC’15. LNCS,vol.9399, pp.
583–594. Springer (2015)24 Marta Kwiatkowska, Gethin Norman, David Parker, and Gabriel Santos
A Appendix
Below, we include larger, more detailed figures for the cyclist vs. vehicle and
pedestrian crossing case studies presented in Section 5.2.
cyclist
((2200,,00,,11))
20
15
10
5
(8,1,0)
(6.1,0.94,0.063)
0 0 ( (3 2. .6 3, ,1 1, ,0 0)
)
py
0.5
10 0.5
pc
1
vehicle
(15,0,1)
15
(15,1,0)
10
(8.4,0.032,0.97)
(7,0,1)
5 (8.4,1,0)
(1.4,0.027,0.97)
0
0
pg
0.5
10 0.5
ps
1
nature
(((000,,,111)))
1
=
0.8 = =
0.6
0.4
0.2 ((00..8822,,00..1188))
(1,0)
0
0 0.2 0.4 0.6 0.8 1
pa
Fig.11: Equilibria strategies and utilities for the cyclist vs. vehicle game. Co-
ordinates for the cyclist, vehicle and nature players correspond to (u,p ,p ),
y c
(u,p ,p ) and (p ,p ), respectively (where u is the utility). For the cyclist, the
g s a h
utilities and strategies are the same in the orange and magenta equilibria.
ytilitu
hp
ytilituExpectation vs. Reality:Towards Verification of Psychological Games 25
µ=1 µ=2
(2,0,1) (2,0,1)
2 2
(2,1,0) (2,1,0)
(1,0.25,0.75)
(1,0.38,0.63)
1 1
1 1
0 0
0 0.5 0 0.5
0.5 0.5
pm
1 0 pr
pm
1 0 pr
(2,0,1) (2,0,1)
2 2
1 (0.75,0.5,0.5) 1
(1,1,0) (0.5,0.5,0.5)
1 1
0 0
0 0.5 0 (0,1,0) 0.5
0.5 0.5
pc
1 0 pw
pc
1 0 pw
µ=4 µ=5
2 2
(1,0,1) (2,1,0) (2,1,0)
1 1
1 1
0 0
0 0.5 0 0.5
0.5 0.5
pm
1 0 pr
pm
1 0 pr
(2,0,1) (2,0,1)
2 2
1 1
(0,0.5,0.5)
1 1
0 0
0 0.5 0 0.5
0.5 0.5
pc
1 0 pw
pc
1 0 pw
Fig.12: Equilibria strategies and utilities for the pedestrian crossing game for
different values of µ. The top plot for each value of µ corresponds to the pedes-
trian and the plot below to the vehicle. Point coordinates values are (u,p ,p )
m r
for the vehicle and (u,p ,p ) for the pedestrian (where u is the utility).
c w
ytilitu
ytilitu
ytilitu
ytilitu