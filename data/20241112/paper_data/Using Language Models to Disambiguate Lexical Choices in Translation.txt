Using Language Models to Disambiguate Lexical Choices in Translation
JoshBarua SanjaySubramanian KayoYin AlaneSuhr
UniversityofCalifornia,Berkeley
{joshbarua,sanjayss,kayoyin,suhr}@berkeley.edu
Abstract Concept: date (fruit)
Variations and Generated Rules
Intranslation,aconceptrepresentedbyasingle Khorma refers to the fruit of the date palm when it is
fully ripe and dried. It is commonly consumed as a sweet,
word in a source language can have multiple
chewysnackorusedinvariousdishes,particularlydesserts.
variationsinatargetlanguage. Thetaskoflex-
Rotab refers to fresh, soft dates that are partially
icalselectionrequiresusingcontexttoidentify
ripe. These dates are moister and sweeter than fully ripe,
whichvariationismostappropriateforasource dried dates (khorma). Rotab is often eaten as a fresh fruit
orusedincookingwhereasofter,sweetertextureisdesired.
text. Weworkwithnativespeakersofninelan-
guages to create DTAiLS, a dataset of 1,377 Kharak refers to dates that are unripe and are in a
semi-dried state. They are less sweet compared to rotab and
sentence pairs that exhibit cross-lingual con-
khorma and are often used in cooking or further processed
ceptvariationwhentranslatingfromEnglish. into other forms.
WeevaluaterecentLLMsandneuralmachine
Lexical Selection
translationsystemsonDTAiLS,withthebest- Source Sentence: she brings me dried dates and tells me old
stories
performingmodel,GPT-4,achievingfrom67
Correct Variation: khorma
to85%accuracyacrosslanguages. Finally,we
uselanguagemodelstogenerateEnglishrules Figure1: GeneratedrulesforEnglishdatewithlexical
describingtarget-languageconceptvariations. variationskhorma,rotab,andkharakinFarsi.
Providingweakermodelswithhigh-qualitylex-
ical rules improvesaccuracy substantially, in pairsspanningninelanguageswhereconceptvari-
somecasesreachingoroutperformingGPT-4. ation can be explained by context in the source
sentence. Evaluating five models on DTAiLS re-
1 Introduction
vealsthat,withoutrulesprovidedin-context,only
Resolvingambiguityintranslationisafundamental the best-performing LLM, GPT-4, is competitive
challenge (Weaver, 1952) that remains unsolved withNMTsystems.
(Campolungo et al., 2022). This paper focuses Wealsopresentasimplemethodforgenerating
on lexical selection, a key aspect of translation rules for lexical selection from LLMs, which na-
thatrequiresusingcontextinasourcesentenceto tivespeakersverifyarehighlyaccurate. Figure1
determine the best translation for an ambiguous showsrulesgeneratedforthreeFarsivariationsof
sourcewordfromseveraltarget-languageoptions. the concept date. We observe improvements in
Figure1showsvariationsoftheconceptdate(fruit) performanceacrossallLLMswhenpromptedwith
inFarsiandanexampleofthelexicalselectiontask. accurate self-generated rules. In addition, while
Our work has two main goals. First, we in- open-weightLLMslagbehindbothNMTsystems
vestigate the capabilities of language models in andGPT-4,providingrulesfromGPT-4canhelp
disambiguating lexical choices in translation by substantiallytobridgethegapinperformance. This
comparinginstruction-tunedlanguagemodelswith suggeststhatparametricknowledgeofconceptvari-
high-performing neural machine translation sys- ationposesagreaterchallengetomodelsthanthe
tems. Second, we test whether language models ability to apply such knowledge in-context. Our
canbeusedtoextractusefulnaturallanguagerules work demonstrates that LMs can generate high-
thataccuratelydescribehowtotranslateambiguous quality rules, and further leverage these rules to
wordsbasedonsource-sidecontext. rivalspecializedNMTsystemsonlexicalselection,
Wework with native speakers to introducethe
butstillfallshortofnativespeakers.1
DatasetofTranslationswithAmbiguityinLexical
1Code and data are publicly released here: https://
Selection (DTAiLS), a test set of 1,377 sentence github.com/Berkeley-NLP/Lex-Rules
4202
voN
8
]LC.sc[
1v18750.1142:viXra2 TaskandData Language #Concepts Precision Recall
Extracted
To evaluate a model’s ability to understand con-
Afrikaans 17 99.2 82.4
ceptvariations,westudylexicalselectionintrans- Armenian 18 85.4 77.8
lation. For example, the noun date has multiple Farsi 100 96.2 72.3
Galician 24 95.8 91.7
lexicalvariationsinFarsi,whichdistinguishesvari-
Hindi 41 96.2 89.4
ationsbyfruitripenessanddryness(Figure1). We Japanese 202 97.6 78.9
Latvian 16 99.1 87.5
collect a dataset of translation pairs that require
Tamil 18 92.4 79.6
understandingandappropriatelyapplyingconcept
Telugu 21 95.9 87.3
variation, where sufficient context is provided to
distinguishbetweenvariations. Table1:Detailsforidentifyingconceptswithvariations,
includingthenumberofextractedconceptsandthepre-
LexicalSelection Intranslation,lexicalselection cisionandrecalloftheextractedvariations. Onaverage,
is the task of selecting the most appropriate lex- weidentify2.3variationsperconcept.
emeinthetargetlanguagethatmapsfromasingle
lexemeinthesourcelanguage,inthecontextofa 2.1 IdentifyingConceptswithVariations
sourcesentence(Apidianaki,2009). Formally,let
Wefirstidentifyconceptsthatarerepresentedasa
(x¯,y¯)beasentencepairwherex¯ = ⟨x ,...,x ⟩
1 |x¯| singlewordinoursourcelanguage(English)but
isasequenceofwordsinthesourcelanguageand
have several variations in a target language. We
y¯ = ⟨y ,...,y ⟩ is its translation in the target
1 |y¯| builduponChaudharyetal.(2021)’sapproachto
language. Forasourcewordx ,wedefinetheset
i identifyfine-grainedlexicaldistinctionsthatarise
ofpossibletranslationsofx asv¯= ⟨v ,...,v ⟩
i 1 |v¯| duetoconceptvariation. Givenaparallelcorpus,
where ∃ j such that v ∈ y¯. The task of lexical
j we lemmatize all words using Stanza (Qi et al.,
selectionistoidentifythemostappropriatetransla-
2020)andcomputewordalignmentsforeachsen-
tionv conditionedonthesourcesentencex¯.
j tencepairwiththeAWESOMEaligner(Douand
Neubig, 2021). Using these alignments, we cre-
SourceData Despitetheexistenceoflarge-scale
ateaone-to-manymappingfromsource-language
datasetsforlow-resourcelanguagesthroughbitext
lexemes to target-language lexemes. Lastly, we
miningtechniques(Schwenketal.,2021),wefo-
removesourcelexemesthatdonotmaptoatleast
cus on datasets curated by human translators to
twotargetlexemes,exhibitlowentropy,orcorre-
mitigatethepotentialforincorrecttranslationsdue
spondtotargetlexemesthatariseduetopolysemy.6
tomisalignment. WeuseOpenSubtitles(Lisonand
While this approach was originally designed and
Tiedemann, 2016; Lison et al., 2018), TED2020
appliedtoSpanishandGreekparallelcorpora,we
(Reimers and Gurevych, 2020), PMIndia (Had-
applyittonineadditionallanguages. Table1lists
dow and Kirefu, 2020), and TEP (Pilehvar et al.,
the total number of extracted concepts for each
2011) to acquire parallel data for English paired
language.
with7low-resourceand2high-resourcelanguages
(Japanese and Farsi).2 All datasets are down- Wealsoperformcomprehensiveanalysisofthis
loaded from the digital platform OPUS3 (Tiede- approach’sprecisionandrecallinidentifyingtarget-
mann,2009). language variations of concepts. All three expert
annotatorsforeachlanguageprovidefeedbackon
Expert Recruitment We work with bilingual the extracted variations, including whether each
speakerstoensureourmethodsanddatafaithfully variationmatchesthemeaningoftheEnglishlex-
representtheprocessesassociatedwithtranslation eme(forcomputingprecision)andwhetheranykey
underconceptvariation. Foreachlanguage,were- variationsaremissingfromtheset(forcomputing
cruitfromProlific4 threeannotatorswhoarefluent recall). Precision is measured as the proportion
Englishspeakersandnativespeakersofthetarget of accurate variations; recall is measured as the
language. Allannotatorsarepaid$16USD/hour.5 proportion of concepts with all key variations re-
covered.7 In general, the precision of identified
2Table7liststhedatasourcesandnumberofsentencepairs
variationsisveryhigh,evenforlow-resourcelan-
availableperlanguage.
3https://opus.nlpl.eu/
4https://www.prolific.com/ 6SeeAppendixB.1foradditionaldetailsonthepipeline.
5Moredetailsonannotatorrecruitmentandtaskdesignare 7AppendixAincludesmoredetailsonthisanalysis,includ-
availableinAppendixA.1. inginter-annotatoragreement.Language FullDataset %Sentences ExpertDataset Language %Correct
w/SufficientContext Rules
Afrikaans 4,123 78.9 180 Afrikaans 99.2
Armenian 9,610 63.9 176 Armenian 86.2
Farsi 43,911 59.0 127 Farsi 95.1
Galician 13,393 67.0 164 Galician 99.4
Hindi 17,417 61.0 145 Hindi 98.5
Japanese 99,741 76.0 149 Japanese 99.1
Latvian 6,944 81.3 184 Latvian 100.0
Tamil 5,833 65.3 134 Tamil 99.2
Telugu 9,167 63.3 118 Telugu 98.0
Table2: DTAiLSdatasetstatistics. Asentenceisdeterminedtohavesufficient Table 3: Mean accuracy of
contextwhenthemajorityofannotatorsselectitsgroundtruthvariation. GPT-4generatedrules.
guages,butourapproachislessconsistentiniden- than 50 tokens in length where the variation ap-
tifyingallpossiblevariationsofasourceconcept, pearsinthetargettranslation. Motivatedbywork
whichcouldbeduetothelimitedsizeofdatasets showing LLMs are useful for describing differ-
usedortheuseofdomain-specificdata. ences between sets of text (Zhong et al., 2022),
weconstructonepromptperconceptincludingall
2.2 DatasetConstruction
target-languagevariationsandtheirrespectivelists
Our goal is to collect a dataset of sentence pairs of source-language sentences, and prompt each
thatrequireunderstandingtarget-languageconcept model to provide a natural language description
variationforaccuratetranslation. Expertannotators of each target-language variation.10 We generate
helpuscuratethisdatasetbyperformingthelexi- rulesfromthreeinstruction-tunedmodels: Gemma-
calselectiontask,providedonlysource-language 1.1(GemmaTeametal.,2024),LLaMA-3(AIat
sentencesandtargetlexemes. Meta,2024),andGPT-4(OpenAI,2023);Figure1
Allannotatorsforagivenlanguagearepresented providesanexamplerulesetfromGPT-4. Foreach
withthesamesetofconceptsandsource-language language,weaskallthreenativespeakerstolabel
sentences. Weshuffletheorderinwhichconcepts, every GPT-4-generated rule for correctness. Ta-
sentences, and target lexemes are shown to each ble3showstheserulesareoverwhelminglycorrect
annotator. Ourresultingdataset,DTAiLS,includes accordingtonativespeakers.
sentencesforwhichthemajorityofannotatorsse-
lected the variation used in the original sentence 4 Experiments
pair, which indicates that there is sufficient con-
textforconsistentlexicalselection. Althoughthere Weevaluatethreeinstruction-tunedmodels,GPT-
could be cases of context-dependent translation 4,LLaMA-3-8B-Instruct,andGemma-1.1-7B-IT;
wherethereisn’tasingleoptimallexicalvariation, andtwohigh-qualityNMTmodelsMADLAD-400-
for our dataset we rely on majority agreement to 10B-MT(Kuduguntaetal.,2023)andNLLB-200-
selectexamplesthatareclearlyevaluable. Table2 3.3B (NLLB Team et al., 2022), sampling with
includesdatasetstatistics.8 temperatureof0.
Wehypothesizethatmodelsperforminglexical
3 RulesforLexicalSelection selectionwillbenefitfromaccesstorulesdescrib-
ingconceptvariations(Section3). Thus,weeval-
We experiment with generating human-readable
uateinstruction-tunedLLMsin3settings: (1)no
English rules that describe all extracted concepts
rules provided, (2) with self-generated rules, and
and their variations, and analyze how these rules
(3)withrulesgeneratedbyGPT-4. Foreachsetting,
influencemodelperformanceonlexicalselection
weinstructthemodeltoexplainitsreasoningprior
whenprovidedasinput.9
toselectingalexicalchoice(Weietal.,2022).11
Foreachtarget-languagevariation,wefindthe
Accuracyismeasuredastheproportionofsen-
50 longest source-language sentences with less
tencesforwhichthemodelselectsthecorrectlexi-
8AppendixA.2containsmoredatasetconstructiondetails.
9Werefertothesenaturallanguagedescriptionsas“rules” 10TheAppendix(Figure9)showstheprompttemplate.
to be consistent with prior work studying lexical selection 11AppendixBincludespromptsusedforlexicalselection
(Chaudharyetal.,2021). andadescriptionoflexicalselectionwithNMTsystems.Afrikaans Tamil Telugu
1.0 1.0 1.0
0.9 0.9 0.9
0.8 0.8 0.8
0.7 0.7 0.7
0.6 0.6 0.6
0.5 0.5 0.5
0.4 0.4 0.4
Galician Hindi Armenian
1.0 1.0 1.0
0.9 0.9 0.9
0.8 0.8 0.8
0.7 0.7 0.7
0.6 0.6 0.6
0.5 0.5 0.5
0.4 0.4 0.4
Japanese Farsi Latvian
1.0 1.0 1.0
0.9 0.9 0.9
0.8 0.8 0.8
0.7 0.7 0.7
0.6 0.6 0.6
0.5 0.5 0.5
0.4 0.4 0.4
Gemma-1.1 LLaMA-3 GPT-4 MADLAD-400 NLLB-200
No Rules Self Rules GPT-4 Rules Frequency Baseline
Figure2: ComparisonsbetweenLMswithandwithoutrulestoNMTsystemsonlexicalselection. Wereportµ
±σ
across3runsforLMexperiments.
calvariation. Weincludeasimplefrequencybase- eration has a one-time cost. When providing the
linethatalwayspredictsthemostcommontarget- open-weightmodelswithrulesacquiredfromthe
languagevariationinourdatasetforeachconcept strongest model (GPT-4), we see total improve-
duringlexicalselection. Figure2showsresultsfor ments up to 23% in accuracy, with these models
eachmodel. performing close to or even exceeding GPT-4 on
severallanguages. However,evenwhenthesehigh-
First,wefindthatSOTANMTsystemstrained
quality (Table 3) rules are provided, there is still
onourlow-resourcelanguagepairsoutperformall
a significant gap to human performance. We hy-
LLMsonTeluguandHindi,whilebeingcompara-
pothesizethatwhilethegeneratedrulesareaccu-
bleonAfrikaans, Galician,Tamil,andFarsi. For
rate,theyfailtoenumerateallpossiblecontextual
theremainingthreelanguages,thebest-performing
factors that could influence lexical choice in all
LLM,achievesa4-15%absoluteimprovementin
translationsettings.
performance over the NMT systems. We find a
largegapinperformancebetweenopen-andclosed-
5 RelatedWork
weight LLMs, with the frequency baseline out-
performing open-weight LLMs without rules in
The most closely related work is by Chaudhary
seven languages. LLaMA-3-8B-Instruct outper-
et al. (2021), who study lexical selection for En-
formsGemma-1.1-7B-ITforallninelanguages.
glishtoSpanishandGreek. Theypresentapipeline
Self-generatedlexicalrulesimprovemodelper- forcollectinglexicalselectiondata,trainmodelsto
formance on nearly all languages, with improve- performlexicalselection,usealinearSVMmodel
mentsbeingevenmoresignificantfortheweaker toextractfeaturesasinterpretablerules,andevalu-
open-weight models. This suggests that models atetheefficacyoftheserulesinasecond-language
canbetterreasonoverlexicalchoicesiftheirpara- acquisition setting. In contrast, we use modern
metric knowledge of concept variation is explic- LMs,generatenaturallanguagerules,andevaluate
itlyincludedascontextintheprompt. Whilelexi- onseverallow-resourcelanguages. Wealsocurate
calselectionwithGPT-4issignificantlymoreex- a test set for lexical selection validated by native
pensive than with open-weight models, rule gen- speakersofourtargetlanguages.
ycaruccALexicalselectioniscloselyrelatedtotheprob- Limitations
lem of ambiguity in machine translation, where
Because our focus is on low-resource languages,
contextisessentialfordisambiguatingvariouspos-
theparallelcorporaweusearesmall;thus,weare
sibletranslations. Fernandesetal.(2023)investi-
only able to extract roughly 20 concepts for six
gatesuchambiguitythatarisesfromdiscourseand
out of nine languages. Further, due to the time
grammar,whileCampolungoetal.(2022)explore
andeffortrequiredtocollecthumanjudgementson
ambiguityduetopolysemy. Iyeretal.(2023)eval-
lexicalselection,12 ourtestsetscuratedbyexperts
uateLLMsontranslationsunderpolysemy,demon-
arejust120-180examplesperlanguageand1,377
stratingthatin-contextlearningandfine-tuningon
examplesoverall. Developingautomatedmethods
ambiguousdatasetsimprovestranslation. Westudy
for example selection is an interesting direction
thepotentialforLLMstoresolveambiguityarising
forfutureworkthatwillenablelarger-scaleevalu-
from target-language concept variation, focusing
ation. Wealsonotethattherecallofthepipeline
onlow-resourcelanguages.
foridentifyingconceptswithvariationsmightbe
Prior work has shown improvements in LLM
inaccurate due to the challenges annotators face
translation quality by incorporating ground truth
brainstormingallpossiblevariationsintheseman-
dictionary entries into prompts (Ghazvininejad
ticspace. Lastly,duetoalackofavailablemodels
etal.,2023). Wefurtherdemonstratethatmodels
for WSD, dependency parsing, and POS tagging
canaccuratelydescribeconceptvariationsinlow-
for low-resource languages, we are only able to
resource languages using only parametric knowl-
evaluate on language pairs where English is the
edge and example usages from source-language
sourcelanguage. Intheory,themethodswepresent
sentences. Ourexperimentsfollowalineofwork
canworkforanyarbitrarylanguagepair.
showing that modern LLMs exhibit non-English
languagecapabilities,thoughtheseLLMsareoften Acknowledgments
trainedprimarilyonEnglishdata(Robinsonetal.,
Theauthorsaregratefultotheanonymousreview-
2023;Asaietal.,2023).
ersforhelpfulfeedback. Thisworkwaspartially
supported by AI2 Young Investigator Grant and
6 Conclusion aGemmaAcademicProgramAward. KYissup-
portedbytheFutureofLifePhDFellowship. Dur-
WeintroduceDTAiLS,adatasetof1,377sentence ing this project, JB was supported by the Berke-
pairswith9languagepairsthatexhibitambiguity ley SURF program. We would also like to thank
intranslationduetoconceptvariation. Usingthis AmartyaBose,NiloofarMireshghallah,Prithviraj
dataset, we evaluate 3 popular instruction-tuned Ammanabrolu,YanaiElazar,MihranMiroyan,PV
LLMsand2high-performingNMTsystemsonthe Subramanian,andElzettevanRensburgforhelpful
task of lexical selection. Out of nine languages discussionsongeneratedlexicalrulesanddataset
tested, the strongest LLM outperforms the NMT construction. Finally, we are deeply thankful to
systems on three languages, has comparable per- all of the crowdworkers who participated in our
formanceonfourlanguages,andfallshortofthese study, without whom this work would not have
systems on two languages. No model is able to beenpossible.
disambiguate the full set of sentences that native
speakerscan.
References
We also present a simple approach to extract
high-qualityrulesfromlanguagemodels,demon- AIatMeta.2024. Llama3modelcard.
strating improvements on lexical selection when
MariannaApidianaki.2009. Data-drivensemanticanal-
LMs are given access to rules. We find that pro- ysis for multilingual WSD and lexical selection in
vidingweakeropen-weightmodelswithrulesfrom translation. InEACL.
a stronger LLM can effectively bridge the gap to
Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu,
orevenoutperformthestrongermodelforseveral
Terra Blevins, Hila B Gonen, Machel Reid, Yu-
languages. Future research could investigate ad- lia Tsvetkov, Sebastian Ruder, and Hannaneh Ha-
ditionalapplicationsoflexicalrulesinNMTand jishirzi. 2023. BUFFET: Benchmarking large lan-
assesshowthesehuman-readablerulescanassist
12Annotating the full Japanese dataset would require
L2learnersinvocabularyacquisition. roughly5thousandtotalhoursofwork.guage models for cross-lingual few-shot transfer. Clément Farabet, Oriol Vinyals, Jeff Dean, Koray
arXivpreprint. Kavukcuoglu,DemisHassabis,ZoubinGhahramani,
Douglas Eck, Joelle Barral, Fernando Pereira, Eli
MicheleBevilacquaandRobertoNavigli.2020. Break- Collins,ArmandJoulin,NoahFiedel,EvanSenter,
ingthroughthe80%glassceiling: Raisingthestate AlekAndreev,andKathleenKenealy.2024. Gemma:
oftheartinwordsensedisambiguationbyincorpo- OpenmodelsbasedonGeminiresearchandtechnol-
ratingknowledgegraphinformation. InACL. ogy. arXivpreprint.
TedByrt,JanetBishop,andJohnB.Carlin.1993. Bias, Marjan Ghazvininejad, Hila Gonen, and Luke Zettle-
prevalenceandkappa. JournalofClinicalEpidemi- moyer.2023. Dictionary-basedphrase-levelprompt-
ology,46(5):423–429. ingoflargelanguagemodelsformachinetranslation.
arXivpreprint.
Niccolò Campolungo, Federico Martelli, Francesco
Saina,andRobertoNavigli.2022. DiBiMT:Anovel
BarryHaddowandFaheemKirefu.2020. PMIndia-A
benchmarkformeasuringwordsensedisambiguation
collectionofparallelcorporaoflanguagesofIndia.
biasesinmachinetranslation. InACL.
arXivpreprint.
AditiChaudhary,KayoYin,AntoniosAnastasopoulos,
VivekIyer,PinzhenChen,andAlexandraBirch.2023.
andGrahamNeubig.2021. Wheniswallaparedand
Towardseffectivedisambiguationformachinetrans-
when a muro?: Extracting rules governing lexical
lationwithlargelanguagemodels. InProceedings
selection. InEMNLP.
of the Eighth Conference on Machine Translation,
WMT.
Zi-YiDouandGrahamNeubig.2021. Wordalignment
by fine-tuning embeddings on parallel corpora. In
SnehaKudugunta,IsaacCaswell,BiaoZhang,Xavier
EACL.
Garcia,DerrickXin,AdityaKusupati,RomiStella,
PatrickFernandes,KayoYin,EmmyLiu,AndréMar- Ankur Bapna, and Orhan Firat. 2023. MADLAD-
tins, andGrahamNeubig.2023. Whendoestrans- 400:Amultilingualanddocument-levellargeaudited
lationrequirecontext? Adata-driven,multilingual dataset. InNeurIPS.
exploration. InACL.
VladimirI.Levenshtein.1965. Binarycodescapableof
JosephLFleiss.1971. Measuringnominalscaleagree- correctingdeletions,insertions,andreversals. Soviet
ment among many raters. Psychological Bulletin, physics.Doklady,10:707–710.
76(5):378–382.
Pierre Lison and Jörg Tiedemann. 2016. OpenSub-
Gemma Team, Thomas Mesnard, Cassidy Hardin, titles2016: Extracting large parallel corpora from
RobertDadashi,SuryaBhupatiraju,ShreyaPathak, movieandtvsubtitles. InLREC.
Laurent Sifre, Morgane Rivière, Mihir Sanjay
Kale,JulietteLove,PouyaTafti,LéonardHussenot, Pierre Lison, Jörg Tiedemann, and Milen Kouylekov.
PierGiuseppeSessa,AakankshaChowdhery,Adam 2018. OpenSubtitles2018: Statistical rescoring of
Roberts, Aditya Barua, Alex Botev, Alex Castro- sentencealignmentsinlarge,noisyparallelcorpora.
Ros, Ambrose Slone, Amélie Héliou, Andrea Tac- InLREC.
chetti, Anna Bulanova, Antonia Paterson, Beth
Tsai, Bobak Shahriari, Charline Le Lan, Christo- NLLB Team, Marta Ruiz Costa-jussà, James Cross,
pherA.Choquette-Choo,ClémentCrepy,DanielCer, Onur Celebi, Maha Elbayad, Kenneth Heafield,
Daphne Ippolito, David Reid, Elena Buchatskaya, Kevin Heffernan, Elahe Kalbassi, Janice Lam,
Eric Ni, Eric Noland, Geng Yan, George Tucker, Daniel Licht, Jean Maillard, Anna Sun, Skyler
George-ChristianMuraru,GrigoryRozhdestvenskiy, Wang, Guillaume Wenzek, Alison Youngblood,
HenrykMichalewski,IanTenney,IvanGrishchenko, BapiAkula,LoïcBarrault,GabrielMejiaGonzalez,
Jacob Austin, James Keeling, Jane Labanowski, PrangthipHansanti,JohnHoffman,SemarleyJarrett,
Jean-Baptiste Lespiau, Jeff Stanway, Jenny Bren- Kaushik Ram Sadagopan, Dirk Rowe, Shannon L.
nan,JeremyChen,JohanFerret,JustinChiu,Justin Spruit, C.Tran, PierreYvesAndrews, NecipFazil
Mao-Jones, Katherine Lee, Kathy Yu, Katie Milli- Ayan,ShrutiBhosale,SergeyEdunov,AngelaFan,
can, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, CynthiaGao,VedanujGoswami,FranciscoGuzm’an,
MachelReid,MaciejMikuła,MateoWirth,Michael Philipp Koehn, Alexandre Mourachko, Christophe
Sharman, Nikolai Chinaev, Nithum Thain, Olivier Ropers,SafiyyahSaleem,HolgerSchwenk,andJeff
Bachem,OscarChang,OscarWahltinez,PaigeBai- Wang. 2022. No language left behind: Scaling
ley, Paul Michel, Petko Yotov, Rahma Chaabouni, human-centeredmachinetranslation. arXivpreprint.
RamonaComanescu,ReenaJana,RohanAnil,Ross
McIlroy,RuiboLiu,RyanMullins,SamuelLSmith, OpenAI.2023. GPT-4technicalreport. arXivpreprint.
SebastianBorgeaud,SertanGirgin,SholtoDouglas,
ShreePandya,SiamakShakeri,SohamDe,TedKli- Mohammad Taher Pilehvar, Heshaam Faili, and Ab-
menko, Tom Hennigan, Vlad Feinberg, Wojciech dol Hamid Pilevar. 2011. TEP: Tehran English-
Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Persianparallelcorpus. InComputationalLinguistics
Gong,TrisWarkentin,LudovicPeran,MinhGiang, andIntelligentTextProcessing.PengQi,YuhaoZhang,YuhuiZhang,JasonBolton,and
Christopher D. Manning. 2020. Stanza: A python
naturallanguageprocessingtoolkitformanyhuman
languages. InACL.
Nils Reimers and Iryna Gurevych. 2020. Making
monolingualsentenceembeddingsmultilingualusing
knowledgedistillation. InEMNLP.
JoshuaRobinsonandDavidWingate.2023. Leveraging
largelanguagemodelsformultiplechoicequestion
answering. InICLR.
NathanielRobinson,PerezOgayo,DavidR.Mortensen,
andGrahamNeubig.2023. ChatGPTMT:Competi-
tiveforhigh-(butnotlow-)resourcelanguages. In
ProceedingsoftheEighthConferenceonMachine
Translation,WMT.
HolgerSchwenk,GuillaumeWenzek,SergeyEdunov,
Edouard Grave, Armand Joulin, and Angela Fan.
2021. CCMatrix: Mining billions of high-quality
parallelsentencesontheweb. InACL-IJCNLP.
JörgTiedemann.2009. NewsfromOPUS-Acollec-
tionofmultilingualparallelcorporawithtoolsand
interfaces. InRecentAdvancesinNaturalLanguage
Processing,2009.
WarrenWeaver.1952. Translation. InProceedingsof
theConferenceonMechanicalTranslation.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,BrianIchter,FeiXia,EdH.Chi,QuocV.Le,
andDennyZhou. 2022. Chain-of-thoughtprompt-
ing elicits reasoning in large language models. In
NeurIPS.
ChujieZheng,HaoZhou,FandongMeng,JieZhou,and
MinlieHuang.2024. Largelanguagemodelsarenot
robustmultiplechoiceselectors. InICLR.
RuiqiZhong,CharlieSnell,DanKlein,andJacobStein-
hardt. 2022. Describing differences between text
distributionswithnaturallanguage. InICML.A AdditionalAnnotationDetails Language TotalAgreement Fleiss’κ PABAK
Afrikaans 0.975 -0.008 0.950
Armenian 0.707 0.181 0.415
A.1 ExpertAnnotation
Farsi 0.857 -0.021 0.713
The filters applied for participants before joining Galician 0.982 -0.006 0.964
Hindi 0.954 -0.016 0.908
include(1)highestlevelofdegreeearnedastech-
Japanese 0.973 -0.009 0.945
nical/communitycollegeoraboveand(2)fluency Latvian 1.000 NaN 1.000
inEnglishandnativeproficiencyinoneofthenine Tamil 0.977 -0.008 0.955
Telugu 0.959 0.319 0.918
languages we study. First, a pilot study was con-
ducted to vet annotators for fluency and compre- Table4: Inter-annotatoragreementstatisticsforevalua-
hensionofthetask. Wethenpublishedtwostudies tionofgeneratedrules.
tothegroupofannotatorswhoqualifiedfromthe
pilot study. The first study required annotation Language TotalAgreement Fleiss’κ PABAK
Afrikaans 0.975 -0.008 0.950
oftherulesgeneratedbyGPT-4andfeedbackon
Armenian 0.634 0.024 0.268
concepts and lexical variations extracted by the Farsi 0.917 0.241 0.835
pipeline(Section2.1)forcomputingprecisionand Galician 0.909 0.254 0.818
Hindi 0.931 0.376 0.862
recall. Theinterfaceforthefirststudycanbefound
Japanese 0.951 0.307 0.903
inFigure3. Thesecondstudyrequiredannotators Latvian 0.974 -0.009 0.947
Tamil 0.818 0.134 0.636
tocompletethelexicalselectiontask. Theinterface
Telugu 0.959 0.652 0.918
forthesecondstudycanbefoundinFigure4. We
ensurethatthesameannotatordoesn’tparticipate Table5: Inter-annotatoragreementstatisticsforpreci-
inbothstudies. Weremoveallpersonalidentifying sionofconceptvariationpipeline.
informationfromalldatacollected. Priortotaking
partinanystudy,annotatorswereinformedofthe
1971)isapopularmetricformeasuringreliability
purposeofthestudyandhowtheirdatawouldbe
ofagreementbetweenmorethan2annotators,and
used.
prevalence-adjustedbias-adjustedkappa(PABAK)
(Byrt et al., 1993) is a modified kappa that ad-
A.2 ExampleSelection
dresses problems that arise from an imbalanced
Collecting human judgments of lexical selection
distributionofdataoverclasses. WeincludeFleiss’
forallparallelsentencesisinfeasible;forexample,
kappa for completeness, but note that it is often
fully annotating Japanese would require labeling
misleadingduetotheveryhighprevalenceofclass
99,741examples(Table2)androughly5thousand
1(correct). Forexample,inthefirstrowofTable4
totalhoursofwork. Duetolimitedresources,we
wefindthatdespiteannotatorsbeingintotalagree-
sampleupto20conceptsforeachtargetlanguage
mentforover97%ofquestions,theFleiss’kappa
and gather 10 sentence pairs per concept, ensur-
measuresuggestspooragreement. Thisisacom-
ingthateachvariationisrepresentedatleastonce.
monparadoxformeasuresofinter-annotatoragree-
This results in a test set of up to 200 sentences
mentthatare“chance-corrected.” Table4presents
per language. For languages with more than 20
inter-annotatoragreementstatisticsforevaluation
extractedconcepts,wefirstfilterforconceptsthat
of generated rules, while Tables 5 and 6 display
havearoughlyuniformdistributionovervariations.
the same for precision and recall of the concept
Specifically,foreachconceptwecomputetherela-
variationextractionpipeline.
tivefrequencyofeachlexicalvariation. Concepts
arediscardedifanyindividualvariationdeviatesby
Language TotalAgreement Fleiss’κ PABAK
morethan20%fromauniformdistribution. After
Afrikaans 0.588 0.056 0.176
filtering, we uniformly sample 20 concepts to be
Armenian 0.444 -0.071 -0.111
includedinthelexicalselectiontask. Farsi 0.360 -0.066 -0.280
Galician 0.792 0.091 0.583
Hindi 0.683 -0.118 0.366
A.3 Inter-AnnotatorAgreement
Japanese 0.510 0.019 0.020
Inthissectionwereportstatisticsoninter-annotator Latvian 0.625 -0.143 0.250
Tamil 0.611 0.201 0.222
agreement for all studies conducted with native
Telugu 0.667 -0.002 0.333
speakers. We include 3 metrics: total agreement
is the proportion of questions for which all 3 an- Table6: Inter-annotatoragreementstatisticsforrecall
notatorswereinagreement,Fleiss’kappa(Fleiss, ofconceptvariationpipeline.10/2/24, 2:53 PM Rules Task
1 remaining examples to annotate. (/?PROLIFIC_PID=joshb&LANGUAGE=japanese&STUDY=full) Main Menu
English Concept: art
Japanese Variations: ["美術", "芸術"]
Are there any commonly used variations for the concept art in Japanese that are missing from ["美術", "芸術"]?
yes
no
If there are any variations in ["美術", "芸術"] that do not mean art, please select them below.
美術
芸術
Rule for 美術: 美術 (bijutsu) refers specifically to fine arts and visual arts. It often pertains to traditional forms of art
such as painting and sculpture, and is commonly used in contexts related to art history and art exhibitions.
Example: 美術館で絵画を鑑賞する。 (Bijutsukan de kaiga o kanshō suru.) - 'Viewing paintings in an art museum.'
Is the rule for 美術 correct?
yes
no
Rule for 芸術: 芸術 (geijutsu) encompasses a broader spectrum of arts, including performing arts, literature, and
music, in addition to visual arts. It is used to discuss art in a general, philosophical, or cultural context. Example:
芸術は⼈⽣に彩りを加える。 (Geijutsu wa jinsei ni irodori o kuwaeru.) - 'Art adds color to life.'
Is the rule for 芸術 correct?
yes
no
Figure3: Interfaceforannotatingrulesandextractedconceptsandvariations.
B httA ps:/d /lod veli yt -mio ovn ed-a col yoE te.nx grp ok-e frr eei .am pp/te asn ks/t 0?a PRl OD LIFe ICt _a PIi Dl =s joshb&LANGUAGE=(jBapaenvesei&laSTcUqDuYa=fuallndNavigli,2020). Sourceword1/s1are
characterized by tuples of their lemmatized form
B.1 PipelineforIdentifyingConceptswith and POS tag ⟨l ,t ⟩ to avoid conflating different
x x
Variations meanings across POS tags. First, we enumerate
all word alignments across the corpus and create
Inthissection, weformallydescribethepipeline
aone-to-manymappingfromeachsourcewordto
for identifying concepts with variations, which
the lexical variations it is aligned with. Second,
we adopt from Chaudhary et al. (2021). Let
weremoveallsourcewordsthatdonotmaptoat
D = {(x¯ ,y¯ ),...,(x¯ ,y¯ )}beaparallelcor-
1 1 |D| |D| least two lexical variations at least 50 times. We
puswhere(x¯ ,y¯)isasource-andtarget-language
i i require50occurrencesforeachvariationtoprevent
sentencepair. Foreachsentencepair,wecompute
incorrecttranslationsbeingextractedduetonoisy
word alignments and lemmatize all words in x¯
i alignments. Next,wedescribeaprocessforfilter-
and y¯ using the AWESOME aligner and Stanza
i ingoutsourcewordsbasedonentropy. Foragiven
respectively. Furthermore, for source sentences
source word tuple ⟨l ,t ⟩ with lexical variations
x x
only,weperformautomaticpart-of-speech(POS)
v¯ = ⟨v ,...,v ⟩, let n be the number of occur-
tagginganddependencyparsingusingStanzaand 1 |v¯| i
rencesofvariationsv . Wecomputetheconditional
i
word-sensedisambiguation(WSD)usingEWISER10/2/24, 2:56 PM Sentences Task
1 remaining examples to annotate. (/?PROLIFIC_PID=joshba&LANGUAGE=japanese&STUDY=full) Main Menu
English Concept: art
Japanese Variations: ["美術", "芸術"]
In this task you will need to select the best translation of art in Japanese based on the context in the English text.
Answer the question as if you were translating the English text to Japanese.
English Text: And there began to be a real difference at this point between the art of improvisation and the art of
composition.
Please select the most appropiate translation of art based on the context in the English text.
美術
芸術
Please rate how confident you are that you have selected the correct translation.
Absolutely sure
Likely but uncertain
No idea
Figure4: Interfaceforlexicalselectiontask.
Language DataSource #ParallelSentences
Afrikaans OpenSubtitles 44,703
Armenian TED2020 37,122
Farsi TED2020,TEP 916,975
Galician TED2020 34,385
Hindi OpenSubtitles,TED2020 140,649
Japanese TED2020 366,661
Latvian TED2020 55,488
Tamil OpenSubtitles,TED2020 43,741
Telugu OpenSubtitles,PMIndia,TED2020 72,860
Table 7: Details for parallel corpora of all nine language included in our study, including data sources and the
numberofparallelsentences.
probabilityofeachvariationv as when referring to a geometric plane. When each
i
n variationismappedtoasourceword,westorethe
https://lovely-moved-coyote.ngrok-free.app/tasks/1?PRiOLIFIC_PID=joshba&LANGUAGE=japanese&STUDY=full 1/1
p(v | l ,t ) =
i x x wordsenseofl asitisusedinthesourcesentence.
(cid:80)|v¯|
n
x
j=1 j Thisallowsustocomputethemostfrequentword
andtheentropyofasourcewordtupleas senseduringpost-processingandremovevariations
belongingtootherwordsenses.
|v¯|
(cid:88)
H(l ,t ) = −p(v | l ,t )log (p(v | l ,t ))
x x j x x e j x x
B.2 LexicalSelectionwithNMTSystems
j=1
Weremoveallsourcewordtupleswithanentropy To perform lexical selection with NMT systems,
below 0.69. Lastly, we remove lexical variations wepassthesourcesentenceasinputandparsethe
thatariseduetopolysemyinthesourceword. In translated text for the predicted lexical variation.
particular, since source words are only character- First,wecheckforanexactsubstringmatchinthe
izedbytheirlemmatizedformandPOS,itispos- translatedtextwithalllexicalvariations. Ifanex-
siblethatweextractvariationsthatcorrespondto actmatchisfound,wetakethattobethepredicted
different senses of l . For example, the source variation. If not, we tokenize the translated text
x
wordtuple< plane,noun >istranslatedinSpan- withStanzaandcomputingtheLevenshteinratio
ishasaviónwhenreferringtoanaircraftandplano (Levenshtein,1965)betweeneverywordandeverylexicalvariation. Weidentifythevariationwiththe 1.0
highestratiotoanywordinthetranslatedtextfor
0.8
fuzzymatching. Ifthisratioexceeds0.7,weselect
it as the predicted variation; otherwise, we con- 0.6
cludethatnovariationisfoundandtheprediction 0.4
islabeledasincorrect.
0.2
B.3 Prompts
0.0
1 2
Position
SincetheGemmafamilyofmodelsdonottakea
Gemma-1.1 LLaMA-3 GPT-4 Self Rules
system prompt as input, we prepend the system
prompt to the user prompt with the role user for Figure5: Percentoftimeeachmodelselectsananswer
allexperimentsinvolvingGemma-1.1. Figures7, ateachpositionwhenthereare2lexicalvariations.
8,and9showthepromptsthatweusetoevaluate
LMs on lexical selection and generate rules. For
1.0
lexical selection with LLMs, we apply the same
fuzzy matching scheme as Section B.2 to match 0.8
the generated answer to a target-language varia-
0.6
tion. Qualitatively,theinstruction-followingcapa-
bilitiesofGPT-4weregreaterthanthatofLlama-3 0.4
andGemma-1.1. IfanyLMfailedtogeneratean 0.2
answeraccordingtotheprovidedtemplate,weap-
0.0
pend“Pleaseencloseyourselectedtranslationfrom 1 2 3
Position
<Translations> with 3 back ticks.” to the prompt Gemma-1.1 LLaMA-3 GPT-4 Self Rules
and resample once. If the LM fails to follow the
Figure6: Percentoftimeeachmodelselectsananswer
templateasecondtime,thepredictionislabeledas
ateachpositionwhenthereare3lexicalvariations.
incorrect.
B.4 PositionBiasinLexicalSelection
B.5 OpenAIModelUsed
We acknowledge that with our prompt, the lexi-
cal selection task is similar to a multiple choice
In our call to the OpenAI API, we use the model
question (MCQ) setup. While humans tend to
nameGPT-4-Turbowhichatthetimeofwritingis
beorder-invariantwhenansweringMCQs,several
apointertogpt-4-turbo-2024-04-09.
priorworkshaveexaminedpositionbiasinLLMs
whensolvingMCQs(RobinsonandWingate,2023;
Zhengetal.,2024). Toensureourevaluationisnot
B.6 ComputationalRequirements
affectedbypositionbiaswetakethreesteps. First,
weshuffletheorderoftranslationsintheprompt
All experiments in this paper that do not involve
for every example during lexical selection to re-
models from OpenAI require approximately 50
ducebias. Second, wereporthowoftentheLMs
GPUhoursonanNVIDIARTXA6000GPU.
select an answer choice at each position across
the Afrikaans, Latvian, and Japanese subsets of
DTAiLS.Figures5and 6showaroughlyuniform
C SoftwareandLicenses
distribution over selected positions for concepts
that have 2 and 3 lexical variations, respectively.
Lastly, we plot the mean and standard deviation The TED2020 dataset uses the CC-BY-NC-4.0
ofeachLMexperimentacross3runsinFigure2. License. All models are utilized from Hugging
Wefindthatthetestaccuracyisconsistentforall Face; LLaMA-3-8B-Instruct uses the Llama3 Li-
models despite each run being initialized with a cense,Gemma-1.1-7B-ITusestheGemmaLicense,
uniqueseedforshufflingtheorderoftranslations. MADLAD-400-10B-MTusestheApacheLicense
Basedonthesefindings,weconcludethatLMsare 2.0,andNLLB-200-3.3BusestheCC-BY-NC-4.0
approximatelyorder-invariantwhendoinglexical License. Ouruseofdatasetsandmodelsisconsis-
selectionwithourpromptingsetup. tentwiththeirintendeduse.
detceleS
emiT
fo
tnecreP
detceleS
emiT
fo tnecreP—————–SystemPrompt—————-
——————-UserPrompt——————
Pleaseselectthebesttranslationof"<Con-
cept>"in"<SourceText>"fromthefollow-
inglist: <Translations>. Carefullyexplain
yourreasoningfirstandthenencloseyour
finalanswerlikethis```answer```.
Figure7: Fullpromptforthelexicalselectiontask.
—————–SystemPrompt—————-
Herearerulesforhowtotranslate"<Con-
cept>"in<TargetLanguage>:<Rules>
——————-UserPrompt——————
Based on the provided rules, please se-
lectthebesttranslationof"<Concept>"in
"<Source Text>" from the following list:
<Translations>. Carefullyexplainyourrea-
soningfirstandthenencloseyourfinalan-
swerlikethis```answer```.
Figure8: Fullpromptforthelexicalselectiontaskwith
self-generatedrules.
—————–SystemPrompt—————-
Please only return a json with the follow-
ingkeys<Translations>andnoothertext.
For each key the value should be a string
inEnglishexplaininghowthemeaningand
usage of that <Target Language> word is
differentfromtheothers. Thestringshould
alsoincludeabriefexamplein<TargetLan-
guage>ofthewordbeingusedwithanEn-
glishtranslation. Pleaseincludethetranslit-
erationfrom<TargetLanguage>toLatin
charactersifnecessary.
——————-UserPrompt——————
Whentranslatingtheconcept"<Concept>"
fromEnglishto<TargetLanguage>,what
is the difference in meaning between
<Translations> and in which contexts
should they be used? Here are sentences
whereeachwordisusedin-contexttohelp
you: <Sentences>
Figure9: FullpromptforgeneratingrulesfromLMs.