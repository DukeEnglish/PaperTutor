The influence of persona and conversational task on social interactions with a LLM-
controlled embodied conversational agent
Leon O. H. Kroczek1*, Alexander May1, Selina Hettenkofer1, Andreas Ruider1, Bernd Ludwig2, &
Andreas Mühlberger1
1Department of Psychology, Clinical Psychology and Psychotherapy, University of Regensburg
2 Chair of Information Science, University of Regensburg
Abstract
Large Language Models (LLMs) have demonstrated remarkable capabilities in conversational tasks. Embodying an LLM
as a virtual human allows users to engage in face-to-face social interactions in Virtual Reality. However, the influence of
person- and task-related factors in social interactions with LLM-controlled agents remains unclear. In this study, forty-six
participants interacted with a virtual agent whose persona was manipulated as “extravert” or “introvert” in three different
conversational tasks (small talk, knowledge test, convincing). Social-evaluation, emotional experience, and realism were
assessed using ratings. Interactive engagement was measured by quantifying participants’ words and conversational turns.
Finally, we measured participants’ willingness to ask the agent for help during the knowledge test. Our findings show that
the extraverted agent was more positively evaluated, elicited a more pleasant experience and greater engagement, and was
assessed as more realistic compared to the introverted agent. Whereas persona did not affect the tendency to ask for help,
participants were generally more confident in the answer when they had help of the LLM. Variation of personality traits of
LLM-controlled embodied virtual agents, therefore, affects social-emotional processing and behavior in virtual interactions.
Embodied virtual agents allow the presentation of naturalistic social encounters in a virtual environment.
1. Introduction (Hasan et al., 2023; Lim et al., 2024). The high degree of
The rise of large language models (LLMs) has flexibility and individualization of LLM controlled
revolutionized human-computer interaction, enabling more conversations makes them superior to scripted speech
sophisticated and intuitive exchanges between people and stimuli implemented in virtual scenarios that can only
machines. LLMs can be instated as conversational agents follow a pre-defined conversational path. Another benefit
(e.g. ChatGPT), allowing users to engage in meaningful of LLMs is that they are pretrained for standard
language-based interactions. While earlier versions of conversation in natural language. Without the need to
conversational agents were based on simple pattern- collect huge, but specialized data corpora for training
matching algorithms that generated pre-defined output dialogue models, LLMs can be integrated immediately in
(Ramesh et al., 2017), LLMs use probabilistic generative virtual agents. This allows use cases in research focused on
processes based on training data to generate responses social interactions as well as applications, for example
(Generative Pre-Trained Transformer, GPT; Yenduri et al., conversations with virtual patients can be used in medical
2024). Furthermore, because LLMs can consider the education (Graf et al., 2024) and extended conversations
contextual information of an input, they allow the could be implemented in virtual exposure therapy
generation of individualized responses that match the user’s .However, while such set-ups can have a profound impact
intention. Because of these properties LLM controlled on human experience and behavior, little is known about
conversational agents are increasingly being used in chat- the underlying mechanisms and contextual influences that
based interactions for example in customer service and drive social interactions with LLM controlled embodied
healthcare (Rivas & Zhao, 2023; Thirunavukarasu et al., virtual agents.
2023). However, while chat-based interactions are useful in In real-life social interactions people are fast to form social
many tasks, face-to-face conversations may be evaluations of their interactive partners (Bar et al., 2006;
advantageous as they allow the simulation of ecological Satchell, 2019) and similar effects have been found for
valid human-to-human interactions and the presentation of interactions with virtual agents (Guadagno et al., 2011).
additional information via non-verbal cues (e.g., gesture, According to the computers as social actors framework
gaze, facial expressions). Importantly, face-to-face social these results can be explained by the automatic and
interactions are better suited for establishing a deeper social unconscious response to social cues regardless of whether
connection between interactive partners than text based these cues are produced by a computer or a human (Nass &
interactions (Sacco & Ismail, 2014). This has inspired the Moon, 2000). In addition, it has been argued that behavioral
development of embodied conversational agents, in which realism, i.e. the degree to which an agent’s social cues
computer-based dialogue systems are combined with resemble human ones, plays a crucial role in this regard
animated virtual agents (Huang, 2018). Presenting (Von Der Pütten et al., 2010) with more behavioral realism
embodied conversational agents in Virtual Reality (VR) as resulting in more social behavior towards the agent.
3D, life-like virtual humans enable users to engage in Regarding human-AI interactions, previous findings
multimodal, face-to-face conversation with an interactive support the computer as social actors framework for
partner in front of them. As with chatbots, recent attempts interactions with chatbots, e.g. by showing that an agent’s
have been made to increase the naturalism of conversations empathic expressions lead to a more favorable social
by incorporating LLMs as embodied conversational agents evaluation than neutral expressions (Liu & Sundar, 2018).
1Furthermore, there is evidence of the impact of personality experience of the virtual interaction (realism and social
traits and communicative style of conversational agents and presence). In addition, the number of words and turns as
robots. For instance, in text-based communication an well as the number of times participants asked the agent for
agent’s assertive and serious personality compared to a help in the knowledge test were measured to quantify
warm and cheerful personality increased the willingness to interactive engagement.
confide in the agent during a job interview (Zhou et al., In a set of preregistered hypotheses we expected (1) that the
2019). With regard to the specific personality traits of small talk conversation would be experienced more
conversational agents it was shown that chatbots scoring pleasant than the knowledge test and the argumentation
high on extraversion resulted in higher social presence and during the convincing task due to increased intimacy during
increased communicative satisfaction compared to less self- and other-disclosure (Park et al., 2011). (2)
extraverted chatbots (Ahmad et al., 2021). Overall, the Furthermore, we expected that the evaluation of the agents
communicative style and personality traits of a persona would differ as a function of conversational task
conversational agent determine how users experience the with respect to sympathy, valence, closeness, and realism,
interaction with an agent. However, this has been mostly with higher ratings for the extraverted compared to the
tested in text-based communication or with pre-determined introverted agent. This difference was expected to be more
responses, and it remains an open question whether similar pronounced in the small talk than in the knowledge and
results can be observed for LLM-controlled agents who are convincing task. (3) In this line, we also expected an
presented face-to-face as an embodied interactive partner in interaction effect between persona and conversational tasks
Virtual Reality. on interactive engagement, i.e. the number of words spoken
Conversational agents built on LLMs can be used for a wide by the participant during a conversation: more words were
variety of tasks. They can be used to answer specific expected in the extraverted compared to introverted
questions about world knowledge, provide detailed condition. This difference was expected to be greater in the
instructions about how to perform a particular task, give small talk task than in the knowledge and convincing tasks.
everyday advice, or serve as social companions in small- (4) Finally, it was hypothesized that participants would ask
talk or even deeper conversations (Skjuve et al., 2023). the extraverted agent more frequently for help than the
Importantly, the nature of a task or context may influence introverted agent, as the barrier to ask for help was expected
how users interact with a conversational agent. For be lower when social interactions were more pleasant due
instance, receiving help from a conversational agent may to the extraverted agent being more talkative and social
generally lead to a more pleasant experience. Furthermore, (Ashfaq et al., 2020).
tasks may interact with personality traits or communicative
style, in a sense that particular traits might be positively 2. Methods
evaluated in some tasks but not in others. Only few studies 2.1. Participants
have investigated this relationship. Roy et al. (2021) found Forty-six healthy volunteers were recruited at Regensburg
that extraverted agents were more favorably rated than University (mean age = 21.24 years , SD = 2.59, 36
introverted agents in tasks where the goal was to provide females). Participants were randomly assigned into two
information, whereas there were no clear preferences in groups of 23 participants with groups being matched for
tasks where the goal was to complete an assignment. gender. A sensitivity analysis conducted using G*Power
Another study demonstrated that users’ competency levels (Faul et al., 2009) revealed that this sample size allowed the
may also play a role in this regard, as high-competency detection of a medium to large effect size of η 2 = .10 with
p
users rated a social-oriented interactive style as more a power of 0.8 for a mixed effect ANOVA design.
useful, while low-competency users rated a task-oriented Participants did not report mental or neurological disorders
style as more useful when interacting with a conversational and had normal or corrected-to-normal vision. All
agent (Chattaraman et al., 2019). Taken together, tasks may participants gave written informed consent. The study was
play an important role in how user’s form social evaluations conducted in line with the Declaration of Helsinki and was
about conversational agents; however, studies that approved by the ethics committee of Regensburg
investigate LLM-controlled embodied virtual agents across University (24-3669-101). Participants received credit
different tasks are missing. points for compensation.
The current study was designed to test how persona
descriptions of an LLM-controlled virtual agent and 2.2. Experimental-Design
conversational tasks would affect experience and behavior The study used a mixed design with the agent’s persona
in face-to-face social interactions. Participants engaged in (extraverted vs. introverted) as a between-subjects factor
face-to-face social interactions with an LLM-controlled and conversational task (small talk vs. knowledge test vs.
agent in Virtual Reality. The persona of the LLM was convincing) as a within-subject factor. During the
manipulated to be either “extraverted” or “introverted”. knowledge test an additional manipulation was introduced
Three conversational tasks were conducted: Small Talk, by alternating between easy and difficult questions that had
Knowledge Test, and Convincing. Tasks were chosen to to be answered by the participants. Sympathy, Valence,
reflect a social conversation focused on self-disclosure Arousal, Closeness, and Naturalism were measured via
(small talk), task-oriented conversation (knowledge test), self-report after each conversational task and number of
and social conversation focused on argumentation words and turns during each task were assessed as
(convincing). Ratings were assessed to measure the social behavioral measures. In the knowledge test, the percentage
evaluation of the agent (sympathy and closeness), of questions for which the participants asked the agent for
emotional experience (valence and arousal), and the help was assessed as an additional metric. Finally, the
2manipulation “extravert” or “introvert”. The personas
included details about the communicative style and gave
examples on how the agent would answer particular
questions (see Table 1, full text in supplementary material).
The descriptions varied in how persona were described as
being sociable, talkative, and enjoying engaging with other
people which all relates to the dimension of extraversion in
the five-factor theory of personality (McCrae & John,
1992). Each persona also included the same information
about how the LLM had to answer specific questions about
Figure 1: Schematic overview of systems components. preferences. This information was included to ensure that
no differences in sympathy based on preferences (e.g.
social presence subscale of the multimodal presence scale
liking dogs better than cats) could arise between personas.
(MPS, Makransky et al., 2017) was measured for each
Additional parameters, such as the maximum number of
conversational task.
generated sentences and the temperature parameter, were
manipulated between the personas (Table 1). The text
2.3. Apparatus
output of the LLM was then converted into speech (male
2.3.1. Technical Set-Up
voice) using a speech2text model (Silero,
All system components are shown in the schematic
https://github.com/snakers4/silero-models). The same
overview in Figure 1. Virtual Reality was presented via a
voice was used for all personality conditions. Finally, the
head-mounted display (Vive Pro, HTC, Taoyuan, Taiwan).
resulting audio was streamed to the Audio2Face application
The virtual environment was rendered and controlled using
(Nvidia Omniverse,
Unreal Engine 5.2 (Epic Games Inc., Raleigh, USA).
https://build.nvidia.com/nvidia/audio2face) where live lip
Participants were placed in a virtual room at a table face-to-
movements were animated based on the “Mark” set-up.
face with a male virtual agent (MetaHuman. Epic Games
Animations and audio were then played by the virtual agent
Inc.). The same agent was used in both between-subject
using the LiveLink plugin in the Unreal Engine.
personality conditions and the distance between participant
and agent was set to 1.8 meter. Eye gaze of the virtual agent
2.3.2. Ratings and Questionnaires
was controlled so that the agent was always looking
After each conversational task, participants were asked to
towards the participant. Participant speech was sampled
rate their experience using a visual analog scale (values 0 -
with an external USB microphone (t-bone SC 420,
100). Ratings included dimensions to describe emotional
Thomann, Germany) and converted to text using the
experience (valence and arousal), as well as social
wav2vec model (Baevski et al., 2020). The text input was
evaluation of the virtual agent (sympathy and closeness).
then forwarded as a prompt to a text generation model
These ratings included sympathy (“How sympathetic was
(“SauerkrautLM-HerO”,
the virtual person?”, 0 = very unsympathetic, 100 = very
https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-
sympathetic), valence (“How unpleasant or pleasant did
HerO) which was run on a separate computer using the text
you feel during the interaction?”, 0 = very unpleasant, 100
generation inference toolkit with streaming enabled.
= very pleasant), arousal (“How high was your arousal
Importantly, deploying all components (including the
during the interaction”), closeness (“How close/connected
LLM) on local servers allowed us to maintain full control
did you feel to the virtual person?”, 0 = very
over all data without the need to rely on third-party services
distanced/unconnected, 100 = very close/connected),
and in accordance to data protection policies. Across all
realism (“How unnatural or natural did you experience the
experimental sessions, the average time of the LLM to
interaction?” 0 = very unnatural, 100 = very natural).
generate a response was 1.29 sec (SD = 0.26, range = 0.68
Because the “knowledge test” conversational task required
– 4.11 sec).
participants to answer questions about general world
Two different personas were implemented as context
knowledge, two additional ratings were included that asked
prompts to the text generation model, i.e. prompts that
for participants’ confidence in the correctness of their
preceded the user input, depending on the persona
answer for questions answered with or without help of the
Table 1: Short persona description and LLM parameters. For full persona descriptions see supplementary material.
Maximum
Persona Prompt Temperature
Sentences
Your name is Moritz. You have a very extroverted character. This
means you are very sociable, enjoy being around people, are active,
Extravert 0.4 3
and talkative. You engage a lot with your conversation partner and
ask interested follow-up questions. […}
Your name is Moritz. You are a very introverted character. This
Introvert means you enjoy being alone, are independent, and very reserved in 0.2 2
social interactions. […]
3virtual agent (“How confident are you that your answers knowledge (e.g. “What is the highest building in the
were correct for questions that you answer on your own/for world?”). Before the task, participants were informed about
questions that you answered with help of the virtual the task, and it was highlighted that they were free to ask
person?”, 0 = very unconfident, 100 = very confident). the virtual agent for help. In contrast to the previous task,
Social anxiety symptoms were assessed using the Social participants had to activate agent’s response mode (where
Phobia Inventory (SPIN ,Connor et al., 2000). In addition, the LLM generated responses for input) by pressing a
the social presence subscale of the Multimodal Presence button. The response mode was automatically deactivated
Scale (MPS; Makransky et al., 2017) was used to measure after the agent/LLM had responded. Questions alternated
the experience of social presence in each conversational between questions that were relatively easy and relatively
task. The subscale averages over five items that have to be hard to answer (based on the experimenter’s evaluation).
answered on a 5-point Likert scale. Furthermore, a German Participants had to give their answer verbally and could
translation of the General Attitudes towards Artificial then forward to the next question using the motion
Intelligence Scale was used (GAAIS, Schepman & controller. The knowledge test lasted for 8 minutes and was
Rodway, 2020). The questionnaire included 16 positive followed by ratings and the social presence subscale of the
items (e.g. opportunities, benefits, and positive emotions MPS outside Virtual Reality.
related to AI) and 16 negative items (concerns and negative “Convincing” was conducted as a last conversational task
emotions related to AI). Items were answered on a 5-point where participants had to ask the virtual agent about
Likert scale, and average scores were calculated for each preferences regarding two options (e.g. “What do you
subscale. Finally, personality traits were measured using prefer: cats or dogs?”). Following the agent’s response,
the 30 item short version of the NEO five-factor-inventory participants then had to convince the agent of the
(NEO-FFI-30, Körner et al., 2008). Data from alternative that had not been chosen by the agent (also
questionnaires are accessible in the open data but were not regardless of their own preferences). In addition,
analyzed in the present study. participants were instructed that they were free in how
many attempts they would try to convince the virtual agent.
2.4. Procedure Preference questions were displayed on the virtual screen
After providing written informed consent, participants were and participants could forward to the next question using
asked to fill in questionnaires about demographic the motion controller. The conversational task had a
information (age, sex, and occupation) and social anxiety duration of 8 minutes and was followed by a final set of
symptoms, participants then sat on a chair and put-on the ratings and the social presence questionnaire.
HMD where the virtual room was presented. Participants After the last conversational task participants were asked to
position in the virtual room was adjusted so that they were fill in questionnaires regarding their general attitudes
sitting at the virtual table, directly facing the virtual agent. towards AI (GAAI), and personality (NEO-FFI 30). The
The virtual agent was presented from the beginning, but the experiment had a total duration of about 1.5 hours.
LLM was not activated before the conversational task, i.e.
there was no speech by the agent before the first 2.5. Pre-test: Validation of LLM persona
conversational task. To ensure that the personality manipulation of the LLM
Next, the first conversational task was initiated by the resulted in the intended changes a personality test (NEO-
experimenter. The small talk conversation was always FFI-30) was conducted for each persona prompt. To
implemented as the first task in order to simulate a natural account for variability in model output, the questionnaire
interaction in which persons first get to know each other. was administered 100 times with both personas. Reliability
Instructions about the task were displayed on a virtual was calculated across repetitions using Cronbach’s alpha.
screen on the table and participants used the motion Consistency was estimated at .87 for the extraverted
controller to forward through instructions. Participants persona and at .92 for the introverted persona
were informed that they would be prompted to verbally ask demonstrating good reliability for both personas. Personas
the virtual agent small talk questions displayed on the were compared for each NEO-FFI subscale. Results
virtual screen and that they could use the motion controller revealed that, across repetitions, the extraverted persona
to forward to the next question. Participants were also scored significantly higher than the introverted on the
specifically instructed that they were free to follow-up on extraversion subscale (extraverted: M = 12.81, SD = 4.21 ,
anything the virtual agent said. The conversational task was introverted: M = 7.87, SD = 3.09), t(181.78) = 9.64, p <
then conducted for a total of eight minutes, during which .001, d = 1.36, while there were no differences on the
the LLM was set active so that responses were generated neuroticism (extraverted: M = 9.38, SD = 3.50, introverted:
for any input that was produced by the participants. The M = 9.39, SD = 2.96), t(192.85) = -0.02, p = .983, d < 0.01,
question which participants had to ask about related to consciousness (extraverted: M = 9.83, SD = 3.51,
general information about the agent (e.g. “Do you have introverted: M = 9.30, SD = 3.04), t(194.02) = 1.14, p =
sisters or brothers?”) and were taken in part from the small .510, d = 0.16, and openness subscale (extraverted: M =
talk questions described in Aron et al. (1997). After 8 8.46, SD = 3.81, introverted: M = 7.51, SD = 3.26),
minutes, participants took off the HMD, answered rating t(193.39) = 1.90, p = .178, d = 0.27 . On the agreeableness
questions, and filled in the social presence subscale of the subscale the introverted persona scored higher than the
MPS. extraverted persona (extraverted: M = 5.44, SD = 3.09,
Afterwards, participants put on the HMD again introverted: M = 7.70, SD = 3.01), t(197.88) = -5.24, p <
and the conversational task “knowledge test” was started in .001, d = 0.74. Overall, the largest effect of persona was
which participant had to answer short questions on world observed with respect to extraversion.
412.12) than for introverted persona (M = 41.19, SD =
2.6. Data Preprocessing and Statistical Analysis 12.71). Sympathy was rated higher for the knowledge test
During the experiment participants’ speech was transcribed task (M = 56.70, SD = 12.37) than for small talk (M =
using the speech-to-text model (see above) and written to a 45.91, SD = 21.31), t(45) = 3.77, p = .001, and convincing
logfile. These data were analyzed by counting the number task (M = 46.47, SD = 46.48), t(45) = 3.80, p = .001, but
of words and turns (e.g. an uninterrupted segment of speech there was no significant difference between small talk and
of the participant with no interleaved response from the convincing, t(45) = -0.20, p = .843.
virtual agent) for each question during a conversational Analysis of participants’ feelings of closeness towards the
task. Note that to characterize interactive engagement, virtual agent revealed a main effect of conversational task
words and turns were analyzed per question rather than as F(2, 88) = 3.69, p = .029, η 2= .08, but no main effect of
p
a total number. This was necessary because otherwise persona, F(1, 44) = 3.36, p = .074, η 2= .07, and no
p
simply asking the displayed question and then switching to interaction effect, F(2, 88) = 1.96, p = .146, η 2 = .04.
p
the next question without any true interactive engagement Follow-up t-tests, however, did not show any significant
would have increased the total number of words or turns differences between conversational tasks (all p > .05 after
(and this behavior would have been more likely to occur for correction for multiple comparisons).
the introverted persona where responses were short). One Overall, the extraverted persona was rated as more likable
participant was excluded from the analysis because only than the introverted persona and agents were rated as most
one question was asked. likable during the knowledge test. Closeness was not
Statistical analysis were conducted in the R environment (R significantly affected by persona or task.
Core Team, 2016). Data for each dependent variable were
analyzed using a mixed effect ANOVA with persona as
between-subject and conversation task as a within-subject
factor. Sphericity violations were corrected using
Greenhaus-Geisser correction. In case of significant
interaction effects post-hoc t-test were conducted using
Holm method to correct for multiple comparisons. Alpha
level was set at .05.
2.7. Open Science Statement
Study procedures and hypotheses were preregistered
(https://osf.io/tukqh/?view_only=977721578f4d42a5bf941
7d6d08bbe46). Ratings, questionnaires, and secondary data
on conversations (word number, turns) as well as analysis
scripts are publicly available in an online repository
(https://osf.io/ws7jf/?view_only=7bb7b39b401a444d8ec5
9bcccb4d2e93). Note that transcriptions of conversations
may contain personal information and are, therefore, not
publicly available.
Figure 2: Social evaluation of the virtual agent in ratings
3. Results of sympathy (top) and perceived closeness (bottom) as a
3.1. Manipulation Check function of LLM persona and conversational task. Error
The number of words generated by the LLM per turn was bars reflect standard error of the mean.
compared between personas as a manipulation check. The
extraverted persona generated significantly more words (M 3.3. Emotional Experience
= 24.19, SD = 75.62) per turn than the introverted persona To characterize the influence of LLM persona and
(M = 15.35, SD = 29.80), t(41.90) = 11.08, p < .001, d = conversational task on emotional experience valence and
3.30 and was thus significantly more talkative. These data arousal ratings were analyzed (Figure 3).
demonstrate that the personality manipulation via persona ANOVA results for valence ratings revealed a main effect
prompts was successful and resulted in the intended effects of persona, F(1,44) = 6.08, p = .018, η 2 = .12, but no main
p
(see also validation of LLM persona above). effect of conversational task, F(2, 88) = 0.34, p =.714 .001,
η 2 < .01, and no interaction effect between persona and
p
3.2. Social Evaluation of Virtual Agent conversational task, F(2, 88) = 0.33, p = .720, η 2 < .01.
p
We investigated how interacting with different LLM Participants interacting with the extraverted persona rated
personas during different conversational tasks affected their experience as more pleasant (M = 56.97, SD = 13.64)
participants’ social evaluation of the virtual agents in terms than participants interacting with the introverted persona
of sympathy and closeness (Figure 2). (M = 45.01, SD = 18.88), but experience was not influenced
Analysis of sympathy of the virtual agent revealed a main by conversational task.
effect of persona, F(1,44) = 21.57, p < .001, η 2 = .33, a Analysis of arousal ratings revealed only a main effect of
p
main effect of conversational task, F(2, 88) = 9.82, p < conversational task, F(2, 88) = 5.49, p = .006, η 2 = .11,
p
.001, η 2 = .18, but no interaction effect between persona but no main effect of persona, F(1, 44) = 1.03, p = .316,
p
and conversational task, F(2, 88) = 2.97, p = .056, η 2 = .06. η 2 = .02, and no interaction effect, F(2, 88) = 1.52, p =
p p
Sympathy was higher for extraverted (M = 58.20, SD = .224, η 2 = .03. Participants rated both the knowledge test
p
5task (M = 44.96, SD = 22.58) and the convincing task (M the convincing task, and interaction during the knowledge
= 44.71, SD = 20.77) as more arousing than the small talk test was rated as more realistic than small talk interaction.
task (M = 35.24, SD = 20.07), t(45) = 2.76, p = .022 and In addition, ANOVA results of social presence revealed a
t(45) = 2.81, p = .022 respectively. There was no main effect of conversational task, F(2, 88) = 6.53, p =
difference in arousal ratings between the knowledge test .002, η 2= .13, but no main effect of persona, F(1, 44) =
p
and the convincing task, t(45) = 0.07, p = .041. 1.19, p = .282, η 2 = .03, and no interaction effect, F(2, 88)
p
LLM persona and conversational tasks had a differential = 0.14, p = .867, η 2 < .01. Post-hoc t-test revealed that
p
effect on emotional experience, while interacting with a social presence was significantly higher during small talk
extraverted persona increased pleasantness compared to compared to the knowledge test, t(45) = 3.72, p = .002, but
interacting with an introverted persona, arousal was mainly there was no significant difference between small talk and
driven by conversational task, with convincing and convincing, t(45) = 1.74, p = .137, and between knowledge
knowledge test being more arousing than the small talk test and convincing, t(45) = -1.87, p = .137.
task. The results show that the extraverted compared to
introverted LLM persona increased realism ratings
specifically for the convincing task. Interestingly, with
respect to conversational tasks, the knowledge test was
rated as more realistic than small talk but small talk induced
a greater feeling of social presence than the knowledge test.
Figure 3: Participants’ emotional experience during social
interaction in terms of valence (top) and arousal (bottom)
as a function of LLM persona and conversational task.
Error bars reflect standard error of the mean.
3.4. Experience of virtual interactions
Another goal was to investigate how LLM persona and
conversational task influenced how realistically the Figure 4: Evaluation of realism (top) and social presence
interactions with the virtual agent were rated and how (bottom) of the virtual interactions as a function of LLM
social presence was experienced (Figure 4). persona and conversational task. Error bars reflect
ANOVA of the realism ratings revealed a main effect of standard error of the mean.
conversational task, F(2, 88) = 6.89, p = .002, η p2 = .14,
but no main effect of persona, F(1, 44) = 3.43, p = .071, η p2 3.5. Behavioral Engagement during Interaction
= .07. However, there was a significant interaction effect of In addition to self-reports, behavioral parameters were
persona and conversational task, F(2, 88) = 5.07, p = .008, measured to investigate how LLM persona and
η p2= .10. Post-hoc Welch t-tests revealed that interaction conversational task affect participants’ engagement in the
with the extraverted persona (M = 38.26, SD = 20.14) was interaction with the virtual agent (Figure 5). Three
rated as more realistic than interaction with the introverted parameters were assessed for this: (1) The number of pre-
persona (M = 20.52, SD = 17.07) during the convincing defined topics/questions that participants worked through
task, t(42.85) = 3.22, p = .002, but there was no difference during a conversational task. Note, that a higher number
in realism between personas for the small talk (Extraverted: means that participants were faster to switch to the next
M = 26.91. SD = 16.38; Introverted: 21.78, SD = 16.13), topic and therefore engaged less with the virtual agent for a
t(43.99) = 1.07, p = .290, and the knowledge test task given topic. (2) The number of words per topic measured
(Extraverted: M = 35.09, SD = 23.99; Introverted: 32.61, the average number of words that participants spoke during
SD = 15.38), t(37.46) = 0.41, p = .679. A follow-up on the a topic, more words means that participants were more
main effect of conversational task showed that the engaged in the conversation. (3) The number of initiated
knowledge test was rated as more realistic than the small turns per topic measured how many back-and-forth
talk task, t(45) = 3.38, p = .004, but there were no alternations with the virtual agent were initialized by
differences between the small talk and convincing task, participants for a single topic in average. A higher number
t(45) = -1.78, p = .129, and between the knowledge test and of turns indicates more interactive engagement.
convincing task, t(45) = 1.90. p = .129. Overall, persona First, the number of the pre-defined topics/questions that
affected the experienced realism of an interaction only in participants worked through with the virtual agent was
analyzed. ANOVA results revealed a significant main
6effect of persona, F(1, 43) = 26.99, p < .001, η 2= .39, a when interacting with the extraverted compared to the
p
significant main effect of conversational task, F(1.52, introverted agent and there the most attempts to continue
65.36) = 178.08, p < .001, η 2= .81, but not interaction the conversation were observed in the convincing task
p
effect, F(1.52, 65.36) = 0.54, p = .538, η 2= .01. Participants followed by the small talk task.
p
reached more of the pre-defined topics/questions when Overall, the behavioral parameters show a consistent
interacting with the introverted (M = 14.11, SD = 7.01) pattern, with the extraverted LLM persona resulting in
compared to the extraverted persona (M = 10.06, SD = more interactive engagement than the introverted persona.
6.34). The highest number of topics/questions was reached This effect was more pronounced in the convincing task for
in the knowledge test task (M = 19.11, SD = 5.45), followed the number of words but not the number of turns.
by the social interaction task (M = 11.24, SD = 4.13), and
the convincing task (M = 5.76, SD = 2.89). Post-hoc t-tests
showed significant differences between all conversational
tasks (ps < .001). Overall, participants reached a higher
number of topics/questions when interactions were shorter
and when the persona manipulation resulted in shorter
responses of the virtual agent (i.e. in the introverted
condition).
Next, the average number of words per pre-defined
topic/question was analyzed. The ANOVA revealed an
effect of persona, F(1, 43) = 16.43, p < .001, η 2= .28, and
p
conversational task, F(1.26, 54.29) = 168.17, p < .001, η 2
p
= .80, as well as an interaction between persona and
conversational task, F(1.26, 54.29) = 6.96, p = .007, η 2 =
p
.14. Post-hoc t-tests were conducted to follow-up on the
interaction effect. There was a significant effect of persona
for each level of conversational task, with greater number
of words for the extraverted persona compared to the
introverted persona (Small Talk: t(30.84) = 2.92, p = .013;
Knowledge Test: t(30.53) = 2.43, p = .021; Convincing:
t(42.01) = 3.34, p = .005). However, an analysis of
differences between conversational tasks revealed that the
extraverted persona group produced significantly more
words in the convincing than the knowledge task compared
Figure 5: Behavioral parameters during conversations as
to the introverted persona group, t(42.11) = 3.12, p = .010,
a function of LLM persona and conversational task. Error
but groups did not differ in differences between the small
bars reflect standard error of the mean.
talk and knowledge test task, t(31.67) = 2.14, p = .067, and
differences between the small talk and convincing task,
3.6. Using AI for help in the knowledge test
t(39.76) = -2.20, p = .068. Overall, participants spoke more
During the knowledge test, participants had to answer
words with the extraverted persona agent than the
questions and were free to ask the virtual agent for help.
introverted persona agent, and more words in the
Questions were grouped into easy and diffult questions.
convincing task than the small talk and knowledge test task.
The percentage of questions for which participants asked
Finally, participants talking with the extraverted persona
for help was then analyzed with a mixed ANOVA using the
specifically increased the number of words in the
between-subject factor persona and the within-subject
convincing task relative to the knowledge task compared to
factor question difficulty. The analysis revealed a
participants talking to the introverted persona agent.
significant main effect of difficulty, F(1, 44) = 666.49, p <
In a further analysis, the number of turns initiated by the
.001, η 2 = .94, but no effect of persona, F(1, 44) = 1.01, p
participant per topic/question was investigated. ANOVA p
= .321, η 2 = .02, and no interaction effect between persona
results showed a significant main effect of persona, F(1,43) p
= 4.36, p <. 001, η 2 = .09, a significant main effect of and difficulty, F(1, 44) = 0.28, p = .601, η p2 < .01. Therefore
p
conversational task, F(1.39, 59.57) = 111.62, p < .001, η 2 participants asked the LLM-controlled agent more
p
frequently for help when difficult questions had to be
= .72, but there was no significant interaction effect, F(1.39,
59.57) = 1.16, p = .304, η 2 = .03. Participants interacting answered (M = 90.03 %, SD = 9.91 %) compared to when
p
easy questions had to be answered (M = 23.12 %, SD =
with the extraverted persona initiated more turns per
17.47 %), but asking for help was not influenced by persona
question (M = 2.78, SD = 2.17) than participants interacting
of the LLM controlled virtual agent.
with the introverted persona (M = 2.27, SD = 1.70). With
In addition, participants rated how confident they were
respect to conversational task, participants initiated more
about the correctness of their answers, either for questions
turns per question in the convincing task (M = 4.40, SD =
answered with or without help of the virtual agent (factor
1.95) than in the small talk task (M = 2.46, SD = 1.00), t(44)
help). Analysis of these confidence ratings revealed a main
= 6.66, p < .001, and more turns per question in the small
effect of help, F(1, 44) = 11.19, p = .002, η 2= .20, but no
talk compared to knowledge test task (M = 0.72, SD = p
effect of persona, F(1, 44) = 0.71, p = .404, η 2 = .02, and
0.24), t(44) = 11.85, p < .001. Therefore, participants were p
no interaction effect, F(1, 44) = 0.11, p = .740, η 2 < .01.
more likely continue a conversation about a particular topic p
7Participants were more confident about the correctness of convincing task. Furthermore, in contrast to our hypothesis
their answers when they asked the LLM controlled agent the small talk was not more pleasant than the knowledge
for help (M = 82.89, SD = 19.07) compared to when they test and convincing task. Finally, while we found no
answered the question without help (M = 70.12, SD = support for the hypothesis that a extraverted LLM
16.80) but this was not modulated by personality of the personality would increase participants tendency to ask the
virtual agent. virtual agent for help during the knowledge test, we did find
Overall, the data show that participants were more likely to that raising question difficulty strongly increased the
ask the LLM for help when hard compared to easy tendency to ask for help and that participants were more
questions had to be answered and they were more confident confident in the answers when they had asked the LLM
in the answers when they had asked for help, however, there controlled agent for help. Overall, the present study
was no influence of the LLM persona. demonstrates that persona of a LLM embodied
conversational agent strongly influences experience and
behavior in social interactions, although more data are
required to characterize the influence of conversational
tasks.
Prompting persona traits in a LLM strongly affects
social evaluation of the virtual agent, emotional experience,
and interactive engagement. Interaction with the
extraverted persona increased the feeling of sympathy
towards the virtual agent compared to the introverted
persona, similarly as in real-word interactions (Wortman &
Wood, 2011). In line with findings from chat-based
interactions (Liu & Sundar, 2018) our results demonstrate
that users are sensitive to the communicative style of a
virtual interactive agent and adapt their behavior and socio-
Figure 6: Behavior and Confidence in the knowledge test emotional processing accordingly. The more positive
conversational task. Graph left shows the percentage of evaluation of the extraverted persona in comparison to the
answered questions for which participants asked the virtual introverted persona is in line with previous studies which
agent for help as a function of question difficulty and found more positive social evaluations (i.e. liking) in real-
persona. Graph right shows how participants rated their life for persons scoring high on sociable aspects of
confidence in the correctness of their answer as a function extraversion such as being talkative and joyful (Wortman
of whether they had asked the virtual agent for help and & Wood, 2011). However, it should be noted that
persona. All error bars reflect the standard error of the extraversion may have a strong influence on an initial
mean. positive evaluation but may have a weaker influence on the
formation of social bonds across longer interactions (Harris
4. Discussion & Vazire, 2016). Interestingly, this was also reflected in the
The goal of this study was to investigate how the persona present study, where we did not observe an influence of
of an LLM controlled embodied conversational agent LLM persona on interpersonal closeness. However, such
modulates experience and behavior in social interactions deeper social connections may develop over longer periods
across different conversational tasks. Participants of time as has been demonstrated for multi-session
interacted with either a extraverted or an introverted LLM interactions with a chatbot (Araujo & Bol, 2024). Overall,
persona during a small talk, a knowledge test or a the present study demonstrates that manipulations of
convincing task. In order to characterize the influence of extraversion via LLM prompts impact socio-evaluative
these manipulations we assessed social-evaluative processes of face-to-face social interactions in immersive
processes, emotional experience, and evaluation of the VR virtual environments and simulate findings from human-
scenario, as well as behavioral parameters such as human interaction.
interactive engagement and participants’ tendency to ask A further target of our study was to shed light on
the LLM for help. Overall, we found consistent evidence the influence of task characteristics on social interaction.
for an effect of persona in line with our hypotheses that Interestingly, participants experienced the argumentation
conversing with the extraverted persona resulted in a more focused conversation as equally pleasant yet more arousing
positive social evaluation, a more positive emotional than the small talk conversation. This finding suggests that
experience and greater interactive engagement than the exchange of arguments was experienced as a deeper
conversing with the introverted persona. There was, conversation rather than an adverse disputation and can be
however, no consistent interaction effect between LLM explained by the fact that the LLM was trained to be a
persona and conversational tasks. The effect of LLM helpful assistant and therefore responses of the model were
persona was only modulated by conversational tasks with always respectful and constructive. Furthermore, we
respect to the experienced realism and number of words, in observed a modulation of the impact of persona by task for
a sense that the relative increase in realism and engagement the evaluation of interactive realism. Interaction with the
from introverted to extraverted was most pronounced in the extraverted persona was experienced as more realistic than
convincing task. This finding did not confirm the interaction with the introverted persona in the deeper
hypothesis that the effect of extraversion would be greater argumentative conversations, but persona did not affect
in the small talk compared to the knowledge test and realism in the other conversational tasks. This suggests that
8persona manipulations become more important when more agents did not produce non-verbal behavior or emotional
elaborative conversations with agents are implemented. In expressions together with the speech output. Non-verbal
contrast, the effects of persona on social evaluation as well behaviors have been demonstrated to have a crucial role for
as emotional experience were consistent across communication and social interactive behavior (Kroczek et
conversational tasks suggesting that participants did not al., 2024; Kroczek & Mühlberger, 2023), future studies
change their initial evaluations. Finally, it should be noted should therefore aim at incorporating both non-verbal and
that virtual agents were evaluated as most positive during verbal behavior resulting in a more naturalistic social
the knowledge test suggesting that receiving help by a interactions (for an example see Llanes-Jurado et al., 2024).
conversational agent per se results in a more favorable The present study highlights the use of LLMs to control
evaluation of the agent. Overall, these data demonstrate that conversations with embodied virtual agents and
task demands and role of an agent can affect the experience demonstrates that an agent’s persona characteristics and
of interactions with LLM-controlled agents and can also communicative style can have a profound impact on
modulate the effects of agent characteristics. experience and behavior across different conversational
Notably, the experimental manipulations of persona and tasks that mimics real-life. This has implications for the use
task affected not only experience of social interactions, but of embodied conversational agents in applications related
also had a direct impact on participants behavior. to mental health and for research focusing on social
Interacting with a extraverted compared to an introverted behavior.
persona agent resulted in greater interactive engagement.
While the underlying mechanisms remain to be explored, it 5. References
is possible that participants tendency to reciprocate the Ahmad, R., Siemon, D., & Robra-Bissantz, S. (2021).
agents’ communicative style may drive the effect (Frisch & Communicating with Machines: Conversational Agents
Giulianelli, 2024; Kroczek & Gunter, 2020; Schoot et al., with Personality and the Role of Extraversion. Hawaii
2016). The present study also supports findings from International Conference on System Sciences.
previous studies, in which manipulation of LLM https://doi.org/10.24251/HICSS.2021.492
personality resulted in behavioral outcomes (Lim et al., Araujo, T., & Bol, N. (2024). From speaking like a person
2024). This is relevant for many applications, e.g. in to being personal: The effects of personalized, regular
education or health care, which aim at activating users. interactions with conversational agents. Computers in
Incorporating LLM-controlled embodied conversational Human Behavior: Artificial Humans, 2(1), 100030.
agents may also be promising for VR applications that https://doi.org/10.1016/j.chbah.2023.100030
provide mental health interventions (Bell et al., 2024; Graf Aron, A., Melinat, E., Aron, E. N., Vallone, R. D., &
et al., 2024; Herbener et al., 2024). Besides interactive Bator, R. J. (1997). The Experimental Generation of
engagement across conversational tasks, the study also Interpersonal Closeness: A Procedure and Some
investigated participants tendency to ask the conversational Preliminary Findings. Personality and Social
agent for help to answer knowledge questions. Using LLMs Psychology Bulletin, 23(4), 363–377.
to acquire knowledge is a typical use task for human-AI https://doi.org/10.1177/0146167297234003
interaction. Our findings did not reveal an effect of persona, Ashfaq, M., Yun, J., Yu, S., & Loureiro, S. M. C. (2020).
neither for easy nor difficult questions. Interestingly, I, Chatbot: Modeling the determinants of users’
however, participants had greater confidence in their satisfaction and continuance intention of AI-powered
answer when they relied on the conversational agent (cf. service agents. Telematics and Informatics, 54, 101473.
Wester et al., 2024). This demonstrates that there is a https://doi.org/10.1016/j.tele.2020.101473
general tendency to accept the answers provided by a LLM Baevski, A., Zhou, H., Mohamed, A., & Auli, M. (2020).
as true (Zhou et al., 2019). Overall, the present study wav2vec 2.0: A Framework for Self-Supervised
provided evidence that interacting with an virtually Learning of Speech Representations (Version 3). arXiv.
embodied and LLM-controlled conversational agent https://doi.org/10.48550/ARXIV.2006.11477
directly impacts users’ behavior and this effect can be Bar, M., Neta, M., & Linz, H. (2006). Very first
further modulated by manipulating the agent’s impressions. Emotion, 6(2), 269–278.
characteristics and communicative style. https://doi.org/10.1037/1528-3542.6.2.269
Social interactions with LLM-controlled embodied virtual Bell, I. H., Pot-Kolder, R., Rizzo, A., Rus-Calafell, M.,
agents are a novel and promising way to study social Cardi, V., Cella, M., Ward, T., Riches, S., Reinoso, M.,
behavior and human-computer interactions. However, there Thompson, A., Alvarez-Jimenez, M., & Valmaggia, L.
are some limitations that need to be discussed. First, the (2024). Advances in the use of virtual reality to treat
conversational tasks were presented in a fixed order which mental health conditions. Nature Reviews Psychology,
may have resulted in carry-over effects as an impression of 3(8), 552–567. https://doi.org/10.1038/s44159-024-
the agent acquired in the small talk task might have 00334-9
persisted across the other tasks (Digirolamo & Hintzman, Chattaraman, V., Kwon, W.-S., Gilbert, J. E., & Ross, K.
1997). With this limitation in mind, it should be noted that (2019). Should AI-Based, conversational digital
the order of the present study was set to resemble a natural assistants employ social- or task-oriented interaction
interaction between humans, where a short phase of getting style? A task-competency and reciprocity perspective for
to know each other typically precedes deeper interaction. older adults. Computers in Human Behavior, 90, 315–
Furthermore, we found that some parameters differed only 330. https://doi.org/10.1016/j.chb.2018.08.048
in later conversational tasks, suggesting that task-specific Connor, K. M., Davidson, J. R. T., Erik Churchill, L.,
effects were preserved. Another limitation is that the virtual Sherwood, A., Foa, E., & Weisler, R. H. (2000).
9Psychometric properties of the social phobia inventory interactions. Behavioural Brain Research, 471, 115126.
(SPIN). New self- rating scale. British Journal of https://doi.org/10.1016/j.bbr.2024.115126
Psychiatry, 176(APR.), 379–386. Kroczek, L. O. H., & Mühlberger, A. (2023). Time to
https://doi.org/10.1192/bjp.176.4.379 Smile: How Onset Asynchronies Between Reciprocal
Digirolamo, G. J., & Hintzman, D. L. (1997). First Facial Expressions Influence the Experience of
impressions are lasting impressions: A primacy effect in Responsiveness of a Virtual Agent. Journal of
memory for repetitions. Psychonomic Bulletin & Nonverbal Behavior. https://doi.org/10.1007/s10919-
Review, 4(1), 121–124. 023-00430-z
https://doi.org/10.3758/BF03210784 Lim, S., Schmälzle, R., & Bente, G. (2024). Artificial
Faul, F., Erdfelder, E., Buchner, A., & Lang, A.-G. social influence via human-embodied AI agent
(2009). Statistical power analyses using G*Power 3.1: interaction in immersive virtual reality (VR): Effects of
Tests for correlation and regression analyses. Behavior similarity-matching during health conversations (No.
Research Methods, 41(4), 1149–1160. arXiv:2406.05486). arXiv.
https://doi.org/10.3758/BRM.41.4.1149 http://arxiv.org/abs/2406.05486
Frisch, I., & Giulianelli, M. (2024). LLM Agents in Liu, B., & Sundar, S. S. (2018). Should Machines Express
Interaction: Measuring Personality Consistency and Sympathy and Empathy? Experiments with a Health
Linguistic Alignment in Interacting Populations of Large Advice Chatbot. Cyberpsychology, Behavior, and Social
Language Models (No. arXiv:2402.02896). arXiv. Networking, 21(10), 625–636.
http://arxiv.org/abs/2402.02896 https://doi.org/10.1089/cyber.2018.0110
Graf, L., Sykownik, P., Gradl-Dietsch, G., & Masuch, M. Llanes-Jurado, J., Gómez-Zaragozá, L., Minissi, M. E.,
(2024). Towards believable and educational Alcañiz, M., & Marín-Morales, J. (2024). Developing
conversations with virtual patients. Frontiers in Virtual conversational Virtual Humans for social emotion
Reality, 5, 1377210. elicitation based on large language models. Expert
https://doi.org/10.3389/frvir.2024.1377210 Systems with Applications, 246, 123261.
Guadagno, R. E., Swinth, K. R., & Blascovich, J. (2011). https://doi.org/10.1016/j.eswa.2024.123261
Social evaluations of embodied agents and avatars. Makransky, G., Lilleholt, L., & Aaby, A. (2017).
Computers in Human Behavior, 27(6), 2380–2385. Development and validation of the Multimodal Presence
https://doi.org/10.1016/j.chb.2011.07.017 Scale for virtual reality environments: A confirmatory
Harris, K., & Vazire, S. (2016). On friendship factor analysis and item response theory approach.
development and the Big Five personality traits. Social Computers in Human Behavior, 72, 276–285.
and Personality Psychology Compass, 10(11), 647–667. https://doi.org/10.1016/j.chb.2017.02.066
https://doi.org/10.1111/spc3.12287 McCrae, R. R., & John, O. P. (1992). An Introduction to
Hasan, M., Ozel, C., Potter, S., & Hoque, E. (2023). the Five‐Factor Model and Its Applications. Journal of
SAPIEN: Affective Virtual Agents Powered by Large Personality, 60(2), 175–215.
Language Models *. 2023 11th International Conference https://doi.org/10.1111/j.1467-6494.1992.tb00970.x
on Affective Computing and Intelligent Interaction Nass, C., & Moon, Y. (2000). Machines and
Workshops and Demos (ACIIW), 1–3. Mindlessness: Social Responses to Computers. Journal
https://doi.org/10.1109/ACIIW59127.2023.10388188 of Social Issues, 56(1), 81–103.
Herbener, A. B., Klincewicz, M., & Damholdt, M. F. https://doi.org/10.1111/0022-4537.00153
(2024). A narrative review of the active ingredients in Park, N., Jin, B., & Annie Jin, S.-A. (2011). Effects of
psychotherapy delivered by conversational agents. self-disclosure on relational intimacy in Facebook.
Computers in Human Behavior Reports, 14, 100401. Computers in Human Behavior, 27(5), 1974–1983.
https://doi.org/10.1016/j.chbr.2024.100401 https://doi.org/10.1016/j.chb.2011.05.004
Huang, H. (2018). Embodied Conversational Agents. In R Core Team. (2016). R: A Language and Environment
K. L. Norman & J. Kirakowski (Hrsg.), The Wiley for Statistical Computing [Software]. https://www.r-
Handbook of Human Computer Interaction (1. Aufl., S. project.org/
599–614). Wiley. Ramesh, K., Ravishankaran, S., Joshi, A., &
https://doi.org/10.1002/9781118976005.ch26 Chandrasekaran, K. (2017). A Survey of Design
Körner, A., Geyer, M., Roth, M., Drapeau, M., Schmutzer, Techniques for Conversational Agents. In S. Kaushik,
G., Albani, C., Schumann, S., & Brähler, E. (2008). D. Gupta, L. Kharb, & D. Chahal (Hrsg.), Information,
Persönlichkeitsdiagnostik mit dem NEO-Fünf-Faktoren- Communication and Computing Technology (Bd. 750, S.
Inventar: Die 30-Item-Kurzversion (NEO-FFI-30). 336–350). Springer Singapore.
PPmP - Psychotherapie · Psychosomatik · Medizinische https://doi.org/10.1007/978-981-10-6544-6_31
Psychologie, 58(6), 238–245. https://doi.org/10.1055/s- Rivas, P., & Zhao, L. (2023). Marketing with ChatGPT:
2007-986199 Navigating the Ethical Terrain of GPT-Based Chatbot
Kroczek, L. O. H., & Gunter, T. C. (2020). Distinct neural Technology. AI, 4(2), 375–384.
networks relate to common and speaker-specific https://doi.org/10.3390/ai4020019
language priors. Cerebral Cortex Communications. Roy, Q., Ghafurian, M., Li, W., & Hoey, J. (2021). Users,
https://doi.org/10.1093/texcom/tgaa021 Tasks, and Conversational Agents: A Personality Study.
Kroczek, L. O. H., Lingnau, A., Schwind, V., Wolff, C., & Proceedings of the 9th International Conference on
Mühlberger, A. (2024). Observers predict actions from Human-Agent Interaction, 174–182.
facial emotional expressions during real-time social https://doi.org/10.1145/3472307.3484173
10Sacco, D. F., & Ismail, M. M. (2014). Social
belongingness satisfaction as a function of interaction
medium: Face-to-face interactions facilitate greater
social belonging and interaction enjoyment compared to
instant messaging. Computers in Human Behavior, 36,
359–364. https://doi.org/10.1016/j.chb.2014.04.004
Satchell, L. P. (2019). From photograph to face-to-face:
Brief interactions change person and personality
judgments. Journal of Experimental Social Psychology,
82, 266–276. https://doi.org/10.1016/j.jesp.2019.02.010
Schepman, A., & Rodway, P. (2020). Initial validation of
the general attitudes towards Artificial Intelligence
Scale. Computers in Human Behavior Reports, 1,
100014. https://doi.org/10.1016/j.chbr.2020.100014
Schoot, L., Heyselaar, E., Hagoort, P., & Segaert, K.
(2016). Does Syntactic Alignment Effectively Influence
How Speakers Are Perceived by Their Conversation
Partner? PloS one, 11(4), e0153521.
https://doi.org/10.1371/journal.pone.0153521
Skjuve, M., Følstad, A., & Brandtzaeg, P. B. (2023). The
User Experience of ChatGPT: Findings from a
Questionnaire Study of Early Users. Proceedings of the
5th International Conference on Conversational User
Interfaces, 1–10.
https://doi.org/10.1145/3571884.3597144
Thirunavukarasu, A. J., Ting, D. S. J., Elangovan, K.,
Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large
language models in medicine. Nature Medicine, 29(8),
1930–1940. https://doi.org/10.1038/s41591-023-02448-8
Von Der Pütten, A. M., Krämer, N. C., Gratch, J., &
Kang, S.-H. (2010). “It doesn’t matter what you are!”
Explaining social effects of agents and avatars.
Computers in Human Behavior, 26(6), 1641–1650.
https://doi.org/10.1016/j.chb.2010.06.012
Wester, J., De Jong, S., Pohl, H., & Van Berkel, N.
(2024). Exploring people’s perceptions of LLM-
generated advice. Computers in Human Behavior:
Artificial Humans, 2(2), 100072.
https://doi.org/10.1016/j.chbah.2024.100072
Wortman, J., & Wood, D. (2011). The personality traits of
liked people. Journal of Research in Personality, 45(6),
519–528. https://doi.org/10.1016/j.jrp.2011.06.006
Yenduri, G., Ramalingam, M., Selvi, G. C., Supriya, Y.,
Srivastava, G., Maddikunta, P. K. R., Raj, G. D.,
Jhaveri, R. H., Prabadevi, B., Wang, W., Vasilakos, A.
V., & Gadekallu, T. R. (2024). GPT (Generative Pre-
Trained Transformer)—A Comprehensive Review on
Enabling Technologies, Potential Applications,
Emerging Challenges, and Future Directions. IEEE
Access, 12, 54608–54649.
https://doi.org/10.1109/ACCESS.2024.3389497
Zhou, M. X., Mark, G., Li, J., & Yang, H. (2019).
Trusting Virtual Agents: The Effect of Personality. ACM
Transactions on Interactive Intelligent Systems, 9(2–3),
1–36. https://doi.org/10.1145/3232077
11