[
    {
        "title": "Penn & Slavery Project's Augmented Reality Tour: Augmenting a Campus to Reveal a Hidden History",
        "authors": "VanJessica GladneyBreanna MooreKathleen Brown",
        "links": "http://arxiv.org/abs/2404.14379v1",
        "entry_id": "http://arxiv.org/abs/2404.14379v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14379v1",
        "summary": "In 2006 and 2016, the University of Pennsylvania denied any ties to slavery.\nIn 2017, a group of undergraduate researchers, led by Professor Kathleen Brown,\ninvestigated this claim. Initial research, focused on 18th century faculty and\ntrustees who owned slaves, revealed deep connections between the university's\nhistory and the institution of slavery. These findings, and discussions amongst\nthe researchers shaped the Penn and Slavery Project's goal of redefining\ncomplicity beyond ownership. Breanna Moore's contributions in PSP's second\nsemester expanded the project's focus to include generational wealth gaps. In\n2018, VanJessica Gladney served as the PSP's Public History Fellow and spread\nthe project outreach in the greater Philadelphia area. That year, the PSP team\nbegan to design an augmented reality app as a Digital Interruption and an\nattempt to display the truth about Penn's history on its campus. Unfortunately,\nPSP faced delays due to COVID 19. Despite setbacks, the project persisted,\nengaging with activists and the wider community to confront historical\ninjustices and modern inequalities.",
        "updated": "2024-04-22 17:32:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14379v1"
    },
    {
        "title": "\"I Upload...All Types of Different Things to Say, the World of Blindness Is More Than What They Think It Is\": A Study of Blind TikTokers' Identity Work from a Flourishing Perspective",
        "authors": "Yao LyuJie CaiBryan DosonoDavis YadavJohn M. Carroll",
        "links": "http://arxiv.org/abs/2404.14305v1",
        "entry_id": "http://arxiv.org/abs/2404.14305v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14305v1",
        "summary": "Identity work in Human-Computer Interaction (HCI) has focused on the\nmarginalized group to explore designs to support their asset (what they have).\nHowever, little has been explored specifically on the identity work of people\nwith disabilities, specifically, visual impairments. In this study, we\ninterviewed 45 BlindTokers (blind users on TikTok) from various backgrounds to\nunderstand their identity work from a positive design perspective. We found\nthat BlindTokers leverage the affordance of the platform to create positive\ncontent, share their identities, and build the community with the desire to\nflourish. We proposed flourishing labor to present the work conducted by\nBlindTokers for their community's flourishing with implications to support the\nflourishing labor. This work contributes to understanding blind users'\nexperience in short video platforms and highlights that flourishing is not just\nan activity for any single Blind user but also a job that needs all\nstakeholders, including all user groups and the TikTok platform, serious and\ncommitted contribution.",
        "updated": "2024-04-22 16:03:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14305v1"
    },
    {
        "title": "Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction",
        "authors": "Anwesha DasZekun WuIza ŠkrjanecAnna Maria Feit",
        "links": "http://dx.doi.org/10.1145/3655610",
        "entry_id": "http://arxiv.org/abs/2404.14232v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14232v1",
        "summary": "Visual highlighting can guide user attention in complex interfaces. However,\nits effectiveness under limited attentional capacities is underexplored. This\npaper examines the joint impact of visual highlighting (permanent and dynamic)\nand dual-task-induced cognitive load on gaze behaviour. Our analysis, using\neye-movement data from 27 participants viewing 150 unique webpages reveals that\nwhile participants' ability to attend to UI elements decreases with increasing\ncognitive load, dynamic adaptations (i.e., highlighting) remain\nattention-grabbing. The presence of these factors significantly alters what\npeople attend to and thus what is salient. Accordingly, we show that\nstate-of-the-art saliency models increase their performance when accounting for\ndifferent cognitive loads. Our empirical insights, along with our openly\navailable dataset, enhance our understanding of attentional processes in UIs\nunder varying cognitive (and perceptual) loads and open the door for new models\nthat can predict user attention while multitasking.",
        "updated": "2024-04-22 14:45:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14232v1"
    },
    {
        "title": "Resistance Against Manipulative AI: key factors and possible actions",
        "authors": "Piotr WilczyńskiWiktoria Mieleszczenko-KowszewiczPrzemysław Biecek",
        "links": "http://arxiv.org/abs/2404.14230v1",
        "entry_id": "http://arxiv.org/abs/2404.14230v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14230v1",
        "summary": "If AI is the new electricity, what should we do to keep ourselves from\ngetting electrocuted? In this work, we explore factors related to the potential\nof large language models (LLMs) to manipulate human decisions. We describe the\nresults of two experiments designed to determine what characteristics of humans\nare associated with their susceptibility to LLM manipulation, and what\ncharacteristics of LLMs are associated with their manipulativeness potential.\nWe explore human factors by conducting user studies in which participants\nanswer general knowledge questions using LLM-generated hints, whereas LLM\nfactors by provoking language models to create manipulative statements. Then,\nwe analyze their obedience, the persuasion strategies used, and the choice of\nvocabulary. Based on these experiments, we discuss two actions that can protect\nus from LLM manipulation. In the long term, we put AI literacy at the\nforefront, arguing that educating society would minimize the risk of\nmanipulation and its consequences. We also propose an ad hoc solution, a\nclassifier that detects manipulation of LLMs - a Manipulation Fuse.",
        "updated": "2024-04-22 14:41:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14230v1"
    },
    {
        "title": "An Artificial Neuron for Enhanced Problem Solving in Large Language Models",
        "authors": "Sumedh Rasal",
        "links": "http://arxiv.org/abs/2404.14222v1",
        "entry_id": "http://arxiv.org/abs/2404.14222v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14222v1",
        "summary": "Recent advancements in artificial intelligence have propelled the\ncapabilities of Large Language Models, yet their ability to mimic nuanced human\nreasoning remains limited. This paper introduces a novel conceptual enhancement\nto LLMs, termed the Artificial Neuron, designed to significantly bolster\ncognitive processing by integrating external memory systems. This enhancement\nmimics neurobiological processes, facilitating advanced reasoning and learning\nthrough a dynamic feedback loop mechanism. We propose a unique framework\nwherein each LLM interaction specifically in solving complex math word problems\nand common sense reasoning tasks is recorded and analyzed. Incorrect responses\nare refined using a higher capacity LLM or human in the loop corrections, and\nboth the query and the enhanced response are stored in a vector database,\nstructured much like neuronal synaptic connections. This Artificial Neuron thus\nserves as an external memory aid, allowing the LLM to reference past\ninteractions and apply learned reasoning strategies to new problems. Our\nexperimental setup involves training with the GSM8K dataset for initial model\nresponse generation, followed by systematic refinements through feedback loops.\nSubsequent testing demonstrated a significant improvement in accuracy and\nefficiency, underscoring the potential of external memory systems to advance\nLLMs beyond current limitations. This approach not only enhances the LLM's\nproblem solving precision but also reduces computational redundancy, paving the\nway for more sophisticated applications of artificial intelligence in cognitive\ntasks. This paper details the methodology, implementation, and implications of\nthe Artificial Neuron model, offering a transformative perspective on enhancing\nmachine intelligence.",
        "updated": "2024-04-22 14:33:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14222v1"
    }
]