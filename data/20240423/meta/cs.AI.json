[
    {
        "title": "SpaceByte: Towards Deleting Tokenization from Large Language Modeling",
        "authors": "Kevin Slagle",
        "links": "http://arxiv.org/abs/2404.14408v1",
        "entry_id": "http://arxiv.org/abs/2404.14408v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14408v1",
        "summary": "Tokenization is widely used in large language models because it significantly\nimproves performance. However, tokenization imposes several disadvantages, such\nas performance biases, increased adversarial vulnerability, decreased\ncharacter-level modeling performance, and increased modeling complexity. To\naddress these disadvantages without sacrificing performance, we propose\nSpaceByte, a novel byte-level decoder architecture that closes the performance\ngap between byte-level and subword autoregressive language modeling. SpaceByte\nconsists of a byte-level Transformer model, but with extra larger transformer\nblocks inserted in the middle of the layers. We find that performance is\nsignificantly improved by applying these larger blocks only after certain\nbytes, such as space characters, which typically denote word boundaries. Our\nexperiments show that for a fixed training and inference compute budget,\nSpaceByte outperforms other byte-level architectures and roughly matches the\nperformance of tokenized Transformer architectures.",
        "updated": "2024-04-22 17:59:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14408v1"
    },
    {
        "title": "PARAMANU-GANITA: Language Model with Mathematical Capabilities",
        "authors": "Mitodru NiyogiArnab Bhattacharya",
        "links": "http://arxiv.org/abs/2404.14395v1",
        "entry_id": "http://arxiv.org/abs/2404.14395v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14395v1",
        "summary": "In this paper, we present Paramanu-Ganita, a 208 million parameter novel Auto\nRegressive (AR) decoder based language model on mathematics. The model is\npretrained from scratch at context size of 4096 on our curated mixed\nmathematical corpus. We evaluate our model on both perplexity metric and GSM8k\nmathematical benchmark. Paramanu-Ganita despite being 35 times smaller than 7B\nLLMs, outperformed generalist LLMs such as LLaMa-1 7B by 28.4% points, LLaMa-2\n7B by 27.6% points, Falcon 7B by 32.6% points, PaLM 8B by 35.3% points, and\nmath specialised LLMs such as Minerva 8B by 23.2% points, and LLEMMA-7B by 3.0%\npoints in GSM8k test accuracy metric respectively. Paramanu-Ganita also\noutperformed giant LLMs like PaLM 62B by 6.4% points, Falcon 40B by 19.8%\npoints, LLaMa-1 33B by 3.8% points and Vicuna 13B by 11.8% points respectively.\nThe large significant margin improvement in performance of our math model over\nthe existing LLMs signifies that reasoning capabilities of language model are\njust not restricted to LLMs with humongous number of parameters.\nParamanu-Ganita took 146 hours of A100 training whereas math specialised LLM,\nLLEMMA 7B, was trained for 23,000 A100 hours of training equivalent. Thus, our\napproach of pretraining powerful domain specialised language models from\nscratch for domain adaptation is much more cost-effective than performing\ncontinual training of LLMs for domain adaptation. Hence, we conclude that for\nstrong mathematical reasoning abilities of language model, we do not need giant\nLLMs and immense computing power to our end. In the end, we want to point out\nthat we have only trained Paramanu-Ganita only on a part of our entire\nmathematical corpus and yet to explore the full potential of our model.",
        "updated": "2024-04-22 17:55:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14395v1"
    },
    {
        "title": "A Multimodal Automated Interpretability Agent",
        "authors": "Tamar Rott ShahamSarah SchwettmannFranklin WangAchyuta RajaramEvan HernandezJacob AndreasAntonio Torralba",
        "links": "http://arxiv.org/abs/2404.14394v1",
        "entry_id": "http://arxiv.org/abs/2404.14394v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14394v1",
        "summary": "This paper describes MAIA, a Multimodal Automated Interpretability Agent.\nMAIA is a system that uses neural models to automate neural model understanding\ntasks like feature interpretation and failure mode discovery. It equips a\npre-trained vision-language model with a set of tools that support iterative\nexperimentation on subcomponents of other models to explain their behavior.\nThese include tools commonly used by human interpretability researchers: for\nsynthesizing and editing inputs, computing maximally activating exemplars from\nreal-world datasets, and summarizing and describing experimental results.\nInterpretability experiments proposed by MAIA compose these tools to describe\nand explain system behavior. We evaluate applications of MAIA to computer\nvision models. We first characterize MAIA's ability to describe (neuron-level)\nfeatures in learned representations of images. Across several trained models\nand a novel dataset of synthetic vision neurons with paired ground-truth\ndescriptions, MAIA produces descriptions comparable to those generated by\nexpert human experimenters. We then show that MAIA can aid in two additional\ninterpretability tasks: reducing sensitivity to spurious features, and\nautomatically identifying inputs likely to be mis-classified.",
        "updated": "2024-04-22 17:55:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14394v1"
    },
    {
        "title": "A Survey on Self-Evolution of Large Language Models",
        "authors": "Zhengwei TaoTing-En LinXiancai ChenHangyu LiYuchuan WuYongbin LiZhi JinFei HuangDacheng TaoJingren Zhou",
        "links": "http://arxiv.org/abs/2404.14387v1",
        "entry_id": "http://arxiv.org/abs/2404.14387v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14387v1",
        "summary": "Large language models (LLMs) have significantly advanced in various fields\nand intelligent agent applications. However, current LLMs that learn from human\nor external model supervision are costly and may face performance ceilings as\ntask complexity and diversity increase. To address this issue, self-evolution\napproaches that enable LLM to autonomously acquire, refine, and learn from\nexperiences generated by the model itself are rapidly growing. This new\ntraining paradigm inspired by the human experiential learning process offers\nthe potential to scale LLMs towards superintelligence. In this work, we present\na comprehensive survey of self-evolution approaches in LLMs. We first propose a\nconceptual framework for self-evolution and outline the evolving process as\niterative cycles composed of four phases: experience acquisition, experience\nrefinement, updating, and evaluation. Second, we categorize the evolution\nobjectives of LLMs and LLM-based agents; then, we summarize the literature and\nprovide taxonomy and insights for each module. Lastly, we pinpoint existing\nchallenges and propose future directions to improve self-evolution frameworks,\nequipping researchers with critical insights to fast-track the development of\nself-evolving LLMs.",
        "updated": "2024-04-22 17:43:23 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14387v1"
    },
    {
        "title": "Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph",
        "authors": "Xiaochen Kev GaoFeng YaoKewen ZhaoBeilei HeAnimesh KumarVish KrishnanJingbo Shang",
        "links": "http://arxiv.org/abs/2404.14372v1",
        "entry_id": "http://arxiv.org/abs/2404.14372v1",
        "pdf_url": "http://arxiv.org/pdf/2404.14372v1",
        "summary": "Model scaling is becoming the default choice for many language tasks due to\nthe success of large language models (LLMs). However, it can fall short in\nspecific scenarios where simple customized methods excel. In this paper, we\ndelve into the patent approval pre-diction task and unveil that simple\ndomain-specific graph methods outperform enlarging the model, using the\nintrinsic dependencies within the patent data. Specifically, we first extend\nthe embedding-based state-of-the-art (SOTA) by scaling up its backbone model\nwith various sizes of open-source LLMs, then explore prompt-based methods to\nharness proprietary LLMs' potential, but find the best results close to random\nguessing, underlining the ineffectiveness of model scaling-up. Hence, we\npropose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous\npatent data analyses, capturing the inherent dependencies across segments of\nthe patent text. As it is model-agnostic, we apply cost-effective graph models\nto our FLAN Graph to obtain representations for approval prediction. Extensive\nexperiments and detailed analyses prove that incorporating FLAN Graph via\nvarious graph models consistently outperforms all LLM baselines significantly.\nWe hope that our observations and analyses in this paper can bring more\nattention to this challenging task and prompt further research into the\nlimitations of LLMs. Our source code and dataset can be obtained from\nhttp://github.com/ShangDataLab/FLAN-Graph.",
        "updated": "2024-04-22 17:22:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.14372v1"
    }
]