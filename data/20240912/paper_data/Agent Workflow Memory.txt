AGENT WORKFLOW MEMORY
ZoraZhiruoWang JiayuanMao DanielFried GrahamNeubig
CarnegieMellonUniversity MassachusettsInstituteofTechnology
ABSTRACT
Despite the potential of language model-based agents to solve real-world tasks
such as web navigation, current methods still struggle with long-horizon tasks
with complex action trajectories. In contrast, humans can flexibly solve com-
plex tasks by learning reusable task workflows from past experiences and using
themtoguidefutureactions. Tobuildagentsthatcansimilarlybenefitfromthis
process,weintroduceAgentWorkflowMemory(AWM),amethodforinducing
commonly reused routines, i.e., workflows, and selectively providing workflows
to the agent to guide subsequent generations. AWM flexibly applies to both of-
flineandonlinescenarios,whereagentsinduceworkflowsfromtrainingexamples
beforehandorfromtestqueriesonthefly. Weexperimentontwomajorwebnavi-
gationbenchmarks—Mind2WebandWebArena—thatcollectivelycover1000+
tasksfrom200+domainsacrosstravel,shopping,andsocialmedia,amongothers.
AWM substantially improves the baseline results by 24.6% and 51.1% relative
success rate on Mind2Web and WebArena while reducing the number of steps
takentosolveWebArenataskssuccessfully. Furthermore,onlineAWMrobustly
generalizes in cross-task, website, and domain evaluations, surpassing baselines
from8.9to14.0absolutepointsastrain-testtaskdistributiongapswiden.
https://github.com/zorazrw/agent-workflow-memory
1 INTRODUCTION
Languagemodel(LM)basedagentsarerapidlyimproving,andarenowabletotackledigitaltasks
suchasnavigatingtheweb(Zhouetal.,2024;Dengetal.,2023)oroperatingmobileapps(Rawles
et al., 2023; 2024). Current agents mostly integrate a fixed set of given examples via training (Fu
et al., 2024; Murty et al., 2024) or in-context learning (Zheng et al., 2024). This allows them to
performwellonactionsequencessimilartothosepresentedintheseexamples,butresultsinalack
of robustness to changes in task contexts or environments (Deng et al., 2023). Essentially, they
fail to grasp the key to disentangling increasingly complex tasks — to extract and learn reusable
taskworkflowssharedacrosssimilartasksandenvironments(Yuetal.,2023;Wangetal.,2024a).
Moreover, asagentssolveeachtaskseparately, theydonotlearnfrompastsuccessesandfailures,
andarethereforeunabletoadaptovertime(Yoranetal.,2024).
Motivated by how humans abstract Get driving time
from A to B
c po em riem nco en st aa nsk dr ao pu pt li yne ss ucfr ho km nop was lt ede gx e- D frois mpl a py la t ch ee A r o tou t Be D dre ic vi ed fe
r
oif
m
ca An
to B
F n thi en ea nd r t sa h
h
H i os
w
i ll ot o mcn a et h i too hnt e,e l
to guide future activities (Chi et al., in a given time s ph ao thrt te os t a w na el ak ri bn yg
Get the zip supermarket …
1981;2014),weproposeagentwork- code of a place
Get the
flow memory (AWM) (§2) to real- coordinates
of a place
ize a similar mechanism in agents.
Find cafe Gap widens to 22.5
AWMinducesworkflowsfromagent near a place
after 40 examples
trajectories by extracting reusable
Find a place
routines, and then integrates these by its name
workflows into agent memory to ATM
baseline
guide future task-solving processes.
Figure1: AWMenablesagentstocontinuouslyinduceand
Eachworkflowrepresentsagoalwith
applyworkflowstoimproveperformance,comparedtostag-
a common routine extracted from
nantbaselines. WeshowresultsbyAWMontheWebArena
available action trajectories, which
mapsplitasanexample.
allows it to effectively capture the
most essential and reusable skills agents need to acquire to successfully solve increasingly com-
plex tasks. As an example, Figure 1 shows workflows induced by AWM on the WebArena map
1
4202
peS
11
]LC.sc[
1v92470.9042:viXratestsplitofthebenchmark(Zhouetal.,2024). AWMstartswithabasicsetofbuilt-inactionsand
solves new tasks in a streaming manner, continuously inducing workflows from the task at hand,
e.g.,learningto“findaplacebyitsname”fromthefirstfewexamples. Moreover,AWMcontinues
tobuildmorecomplexworkflowsontopofnewexperiencesandpreviouslyacquiredworkflows.For
example,the“findaplacebyitsname”workflow,onceinduced,effectivelyservesasasubgoalto
buildamorecomplexworkflow“getthezipcodeofaplace.” Suchcontinuallearningmechanisms
createasnowballeffecttoinduceandapplyincreasinglycomplexworkflowswhileexpandingthe
agentmemory,oftenyieldingasubstantialperformancegapoveravanillaagentthatdoesnotadapt.
Thisgapoverthebaselinerisesashighas22.5pointsonWebArenaafterrollingoveronlytensof
examples(asshownbyFigure1).
AWM readily operates in both offline and online scenarios, where annotated examples are either
available or non-existent. When high-quality annotated examples are available for a task, AWM
operating in an offline fashion can extract reusable workflows from these canonical examples and
integratethemintomemorytoassisttest-timeinference.Evenifnoannotatedexamplesexist,AWM
onlinecanalsoruninansupervision-freesetting,whereititerativelyinducesworkflowsfromself-
generatedpastpredictionsthatarejudgedcorrectbyanevaluatormodule.
WeevaluateAWMontwoagentwebnavigationbenchmarks(§3): WebArena,whichprovidesrig-
orousexecution-basedevaluation(Zhouetal.,2024),andMind2Web,whichemphasizesbroadtasks
anddomaincoverage(Dengetal.,2023).OnWebArena,AWMimprovesoverthetoppublishedau-
tonomousmethod(Drouinetal.,2024)by51.1%relativesuccessrate,andevenoutperformsmeth-
odsaugmentedwithhumanexpertwrittenworkflows(Sodhietal.,2023)by7.9%. OnMind2Web,
AWMeffectivelyimprovesthecross-taskresultsby24.6%inrelativestep-wisesuccessrate.
We further demonstrate the generalizability of AWM on both datasets. On WebArena, we create
a cross-template subset where each example is instantiated from different task templates. AWM
still consistently surpasses all baseline approaches, demonstrating its reliable cross-task workflow
adaptability(§3.1). OnMind2Web,weevaluate AWM onthecross-websiteandcross-domaintest
splitstoexamineitsdomaingenerality,whereitscores8.9–14.0absolutepointshigheroverbaseline,
and the margins become more substantial as the train-test distribution gap widens (§3.2). Both
resultsshowthesuperiorgeneralizationofAWMacrosstasks,websites,anddomains.
2 AGENT WORKFLOW MEMORY
Inthissection,wefirstdescribethewebnavigationtask(§2.1),thenintroducetheworkflowrepre-
sentation(§2.2),anddescribethemechanismofAWMaswellasvariousinstantiations(§2.3).
2.1 PROBLEMSTATEMENT
Forthepurposeofthispaper,weconsideragentswithalanguagemodelbackboneLandtext-based
memory M, where the base memory contains documentation of built-in actions such as CLICK
andTYPE.1 Tosolveataskspecifiedbyanaturallanguage(NL)instructionq,theagentactsinan
environmentdefinedbyatransitionfunctionT. Foreachtimestept ,theenvironmentstates gives
i i
observation o , which is then passed into the model to generate action a via L(q,M,o ) → a .
i i i i
TheactionisexecutedintheenvironmentandchangesthestateasT(s i,a i)→s i+1. Thisobserve-
act loop iterates until the model predicts the stop action a =STOP, or reaches a task termination
i
condition,e.g.,amaximumpre-determinednumberofsteps.
Eachcompletedtaskformsanexperiencee,whichcomprisesanNLinstructionqandatrajectoryof
stepsattemptingtosolvethetask,whereeachsteppcontainstheagentobservationoobtainedfrom
thecurrentstate, andactiontakenbytheagenta, formulatedasp = (o,a). Ourgoalistoinduce
usefulworkflowsW ={w}fromthesetofexperiencesE ={e}constructedfrompastorcollected
examples,usinganinductionmoduleI viaI(E) → W. Weaddinducedworkflowsintotheagent
memoryM asguidanceforsubsequenttask-solving.
Next, we introduce the workflow representation design, workflow induction method, and agent
memoryupdatewithworkflowsinvariedsetups.
1Memoryisusuallyimplementedasasystempromptorauxiliaryinformationinthemainpromptcontext.
22.2 WORKFLOWREPRESENTATION
Similartoanexperience,aworkflowcomprisestwocomponents: first,atextualdescriptionofthe
workflowd;andsecond,aseriesofstepstofinishtheworkflow(p ,p ,⋯ ),asshowninFigure2.
1 2
WorkflowDescription Topresent Who ordered
order #0130?
workflows in a format where agents Environment Step 3. Induce Workflows
canlearnfromthemproperly,itisim- integrate into ❖Workflow Description d
memory This workflow aims to find an
portanttodescribethehigh-levelgoal action Memory c ❖us Wtom ore kr fl o or wd e Tr r aw jeit ch to s rp yecified ID.
of the series of actions. Therefore, state s Agent p1 [ [ [e r aen ca tv is
o
od nne ]]s cc I
l
] in cT e kh e (e d
‘o
c rtu o
d
r ecr rle -ic ln ik nt kp “ -Oa ig dre d
’)
esh rso ”w tos. .. .
we associate each workflow with an observation LM [env desc] Or… de … r { i… d} … is shown.
NL task description d, essentially a Backbone [reason] Order {id} is found, I will
pn now terminate the task.
summaryoftheworkflow’sfunction, [action] stop()
Step 1. Obtain Actions (annotate/generate/…)
by heuristically extracting from ex- # cl iI c n ke (‘e 1d 2 6to ’) c #l i ic dk ot fh te h “ eO br ud te tors n” link to see all orders. Step 2. perienceinstructionsorsummarizing Trajectory Evaluation
# I need to find order 0130 in the current page.
withanLM(see§2.3). scroll(0, 200) … … … … Query solved correctly?
# The current page shows order 0130. Workflow Trajectory The work- send_msg_to_user(“Emma Lopez”)
stop() pass
flow trajectory contains a series of
steps (p ,p ,⋯ ) to finish the pro- Figure2: IllustrationofourAWMpipeline: anagenttakes
1 2 actionstosolvegivenqueries,inducesworkflowsfromsuc-
cess described in d. Each p consists
cessfulones,andintegratesthemintomemory.
of three parts, demonstrated in p in
n
Figure2, Step3. (1)AdescriptionofthecurrentenvironmentstateinNL,suchas“Order{id}is
shown”;(2)Thereasoningprocesselaboratedbytheagenttodecidewhichactiontogeneratebased
on observations, such as “Order {id} is found, I will now terminate the task.”; and (3) an action
representedasanexecutableprogramovertheenvironment,i.e.,stop()thatrealizestermination.
2.3 INDUCINGANDUSINGWORKFLOWS
At the core of AWM is an induction module I that induces a set of workflows W from one or
more past agent experiences E = {e i}m i=1. Each experience e = (q,Pe ) contains an NL task in-
struction q and an action trajectory that consists of a sequence of steps (observation and action)
Pe =(pe,...,pe )thatweretakentosolveq. Theworkflowinductionmoduleoperatesbytakingin
1 n
E andproducingasetofworkflows,asI(E)→W ={w}={(d ,Pd )}.
j j
LM-basedWorkflowInduction Toproduceworkflowsthatmoreaccuratelycapturereusabletra-
jectoriesacrosstasks,weproposeanLM-basedmoduleI thatpromptstheagenttoextractcommon
sub-routinesfromoneormoreinputexperiences.
Differentfromtaskinstructionsthatspecifyconcrete, less-repetitivetasks, e.g., “Buydrycatfood
onAmazonanddelivertomyaddress”,wedeliberatelypromptmodelstoinduceworkflowsatfiner
granularities,i.e.,asub-task“searchforaproductonAmazon”thatfrequentlyre-appearsaspartof
multiple similar instructions. Meanwhile, instead of giving example-specific values (e.g., “dry cat
food”),weenhanceworkflowgeneralitybyabstractingoutexample-specificcontexts,i.e.,replacing
“dry cat food” with a more general name “{product-name}” by specifying this in the workflow
induction prompts. These workflows are segmented (based on double-line breaks in the model
output) and stored separately in the workflow memory. See §A for theOmfflodineel prompts, example Online
workflows,andanexaminationofquality.2
Continuously adding
“Training” w/ Infer test examples Test examples
workflows into agent
AftertheworkflowsWareinduced,theyaretheninte- extra examples w/ workflows passed in a stream memory
gratedintotheagentasauxiliarymemory,M +W → 1 induce
M w, where M stands for the original agent memory, 2 apply grow
andM standsfortheagentmemoryaugmentedwith over
w 1 induce 1 time
induced workflows. When solving a given instruc- workflows 2 apply …
tion q, the agent now produces a series of actions by workflows 2
L(q,M ,o) = L(q,M +W,o) → a. In the follow- … …
w
ing,weintroduceAWMinuseintwoscenarios: workflow add into memory
apply workflows
Figure3: IllustrationofAWM .
offline for test inference
2Wealsoexplorearule-basedworkflowinductionmethod.See§Bformoredetailedexperiments.
3
…
YES
NOOfflineScenario AWMcanoperateinanofflinescenariowhenadditionalcanonicalexperiences
areavailable,suchasdataannotatedbyhumansorsynthesizedbymodels. Inthiscase,weperform
workflow induction and utilization in two standalone processes. As seen in Figure 3, AWM first
takesinalltrainingexamplesfromawebsitebyconcatenatingthemintoasingleprompt,andfeeds
themtotheLMtocreateasetofworkflowsat‘training’time;I(E )→W .Second,AWM
train offline
incorporatesallinducedworkflowsintotheagentmemoryatinferencetimetosolvetestinstructions
L(q,M+W ,otest )→atest.Sincetheworkflowsarefullyinducedbeforetest-timeinference,
offline i i
theagentusesthesameworkflowmemoryW tosolveeachtest.
offline
OnlineScenario Extracanonicalexperiencesarenotalwaysavailableoreasytocollect,especially
thosethatcoverthesamedomainsandtasksasthetestinstructions. AWMalsoworksinanonline,
supervision-freesetting,whereonlytestqueriesareneeded. Agentswith AWM processtest
online
queries in a streaming fashion, where the agents conduct the loop of induce, integrate, and utilize
workflowsafterrunninginferenceforeachtesttask.
Continuously adding
Concretely,theagentstartswiththedefaultmemory workflows into agent Test examples
passed in a stream
M; giventhet-thtestinstructionq passedintothe memory
t
agent, the agent attempts to solve the task by gen- 1 induce
erating an action trajectory (pt 1,pt 2,⋯ ), which col- g or vo ew r 2 apply
lectively forms an experience e = (qt,{pt }). We time 1
t …
adopt the LM-based evaluation model of Pan et al.
2
(2024)tooutputabinarylabel, L (et ) ∈ {0,1}, … …
eval apply workflows
thatjudgesifetsuccessfullysolvesqtbyprompting
for test inference
aneuralmodel. Ifet ispredictedassuccess,i.e.,1,
Figure4: IllustrationsofAWM .
wethentransformitintoworkflow(s)I(et )→{wt
}
online
and add {wt } into the agent memory Mt + {wt } → Mt+1, which serves as the agent memory to
processthet+1-thinstruction. AsdepictedinFigure4,wecontinuethismemory-updatingprocess
by iteratively predicting actions for and inducing workflows from streamed test instructions, until
alltestsareprocessed. Weevaluatethesuccessrateofthepredictedactiontrajectories{pt }forall
testsandreporttheaveragescore.
3 EXPERIMENTS
In this section, we experiment on two major web navigation benchmarks – WebArena (§3.1) and
Mind2Web(§3.2). Foreachbenchmark,wefirstintroducethebenchmarkandtop-performingbase-
line methods, then present our AWM approach and showcase its ability to achieve superior task
successandgeneralizationacrossvariedsetups.
Forbothbenchmarks,weconductAWMonawebsitebasis. Inotherwords,wegroupexamplesby
theirassociatedwebsites,andrespectivelyrunAWMoneachgroup. Thismechanismmaintainsan
smallcollectionofworkflowsthatarenonethelessreleventtothetesttasks.
3.1 WEBARENA
WebArena (Zhou et al., 2024) provides 812 web navigation tasks on five websites that cover four
commonapplicationdomains: e-commerce,socialforumdiscussions,collaborativesoftwaredevel-
opment,andcontentmanagement.Mostimportantly,WebArenasupportsrigorousevaluationonthe
functionalcorrectnessofagenttrajectories.
We adopt the current state-of-the-art method without human-annotated site-specific knowledge,
BrowserGym (Drouin et al., 2024), which altered the agent default action space. We adopt the
BrowserGym framework and its default action space, and represent webpages using accessibility
trees, following the environment representation in Zhou et al. (2024). Because BrowserGym in-
putsbothwebpageHTMLandaccessibilitytreerepresentations,tokeepafaircomparisonwithour
method,wealsoruntheBrowserGymversionwithonlyaccessibilitytreewebpagerepresentations,
denoted as BrowserGym ax−tree. We also compare to the SteP method (Sodhi et al., 2023), which
uses 14 human expert written workflows tailored to solving WebArena. Our method, in contrast,
usesnohumansupervisionandisnottailoredtotheWebArenasetting.
4Table1: TasksuccessrateonWebArenausinggpt-4,andscorebreakdownonfivewebsitesplits.
Method TotalSR Shopping CMS Reddit GitLab Maps #Steps
Withhumanengineeredworkflows
*SteP(Sodhietal.,2023) 33.0 37.0 24.0 59.0 32.0 30.0 -
Autonomousagentonly
WebArena(Zhouetal.,2024) 14.9 14.0 11.0 6.0 15.0 16.0 -
AutoEval(Panetal.,2024) 20.2 25.5 18.1 25.4 28.6 31.9 46.7
BrowserGym(Drouinetal.,2024) 23.5 - - - - - -
BrowserGym ax−tree 15.0 17.2 14.8 20.2 19.0 25.5 7.9
AWM(OURS) 35.5 30.8 29.1 50.9 31.8 43.3 5.9
Followingbaselineapproaches,weuseGPT-4(gpt-4-0613)withatemperatureof0.0toensure
mostly stable model outputs. Because WebArena only has test examples and no additional high-
quality,domain-alignedexamplesexist,weonlyconductAWMintheonlinesettingasin§2.3.
3.1.1 MAINRESULTS
As shown in Table 1, our AWM achieves the best published results on WebArena, surpassing the
BrowserGym baseline by 12.0 absolute points and 51.1% relative increase in overall success rate.
Notably,AWMalsooutperformsSteP,whichusesstrongdomain-specificsupervisionfromhuman-
writtenworkflows,bya7.6%relativeincreaseinoverallsuccessrate. Accordingtothebreakdown
onfivewebsites,ourAWMmethodsubstantiallyenhancestheagentperformanceacrossallwebsites
over the BrowserGym baseline, by 11.8–30.7 absolute points, indicating its general applicability
acrossvarieddomainsandtasks.
Beyondtasksuccess,wealsoevaluatetheaveragenumberofstepstheagenttakestosolveatask,
as shown in the rightmost column in Table 1. AWM conducts about 2.0 fewer steps per example
thantheBrowserGymbaseline. FurthercomparedtotheAutoeval(Panetal.,2024)method,which
necessitatesadditionalevaluationandrefinementstepstosolvetaskscorrectly,ourAWMapproach
uses 40.8 fewer steps on average. Both comparisons show that AWM obtains high success rates
whilemaintainingefficienttrajectories.
3.1.2 EFFICIENTLEARNINGFROMSMALLAMOUNTSOFDATA
TodemonstratethebehavioroftheAWM
online
method, we illustrate the cumulative success
rate over the process of online evaluation, by
evaluatingtheaveragesuccessrateofthefirstk
finishedexamples.
Rapid Stable
As in Figure 5, the agent exhibits a fast learn-
learning inference
ing curve in the beginning (between 0–40 ex- phase phase
amples),byacquiringthemostessentialwork-
flows,whichresultsinhighersuccessrates.Af-
terward,agentslearnmoreadvancedworkflows
(Figure1),whilesuccessratesgraduallystabi-
lize to the highest point in the early learning
Figure 5: AWM enables rapid learning from a
phase. Thisshowcases AWM’sefficientlearn-
small amount of data, i.e., about 40 queries, us-
ing process, which substantially improves per-
ingWebArenamaptestsplitasanexample.
formancewithmerelytensofexamples.
3.1.3 CROSS-TEMPLATEWORKFLOWGENERALIZATION
SometasksintheWebArenabenchmarkhavehighlyoverlappingcanonicaltrajectories,duetothe
benchmark construction process that instantiates multiple examples from a single underlying task
template. AWMintuitivelyimprovesin-templatesuccessrate,thatis,givenoneworkflowinduced
from a successful example, it would be theoretically easier to solve all other examples generated
fromthesametasktemplate.
5Table2:Tasksuccessrateonthecross-templatesubsetofWebArena,aswellastheresultbreakdown
oneachwebsitesplit. Wemarkthenumberofexamplesforeachwebsitesplitunderthename.
Shopping CMS Reddit GitLab Maps
Method TotalSR
(51) (45) (24) (45) (32)
Withhumanengineeredworkflows
*SteP(Sodhietal.,2023) 32.1 26.5 29.3 52.2 27.3 36.4
Autonomousagentonly
AutoEval(Panetal.,2024) 23.2 12.2 17.1 21.7 31.8 36.4
BrowserGym ax−tree 20.5 10.4 17.8 23.1 27.3 28.6
AWM(OURS) 33.2 24.5 29.3 52.2 31.8 39.4
To confirm that the benefits of AWM are not just from learning workflows that help only within
a template, and investigate whether AWFinMd ac panlacoeb btayi intsc nraomsse-template (≈cGreots tsh-et azsipk )cogdeen oefr aa lpizlaacteion,
weextractasubsetofWebArenaexamplessourcingfromnon-overlappingtemplates,bygrouping
Task Objective: Show me {location} on the map Task Objective: Tell me the zip of code of {location}
examplesbytheirtemplatesandraAncdtioonm Tralyjecctohryo:osingoneexamplefroAcmtione Taracjehctoterym: plategroup.Werun
# To find the {location}, I will search for To find the zip code of {location}, I will first search for {location} on
AWMonthiscross-templatesubse"{tloacantiodn}e" oxna OmpeinnStereieftMiatpa. c h A s t i ed e po spv t f e rt ohs me fi esr asi rtm l if ee rw ,iO t hl p eae an srS st or cep ie at teM edar p inf. fOo on rmcre am tlo ioc naatedn, Ic fiw liel ll ( e '1xgt 4r 5aac 't , i {th ln oe c sz aip. t c iood ne } )from the map or
fill('145', {location}) easier workflows click('147')
AsshowninTable2,AWMstillachciliecvk(e'1s47t'h)ehighestperformance,o #v The er sa el al rca
h
n red sulo tsn hae vea pc rh oviw dee
d
b ms uli tt ipe les plit.
TheseresultsdemonstratethatAWMinducedworkflA boud idwld m isno cre rce s aat senip ns g et lo yf fectloivcaetiloyns…g.e Tnhies lroacaltiizone inaclcudreoss tshed ziipf cfoedree.nt
tasks,i.e.,examplesinstantiatedfromdifferenttasktc eom mpl pex l w ao tr ek sflo .ws send_msg_to_user("The zip code is {zip-code}")
Building increasingly com- Find a place by its name Get the zip code of a place
plexworkflows Tomorein-
Task Objective: Show me {location} on the map Task Objective: Tell me the zip of code of {location}
tuitively demonstrate AWM’s Action Trajectory: Action Trajectory:
# To find the {location}, I will search for To find the zip code of {location}, I will first search for {location} on
cross-template generalization "{location}" on OpenStreetMap. A s t ed po sp t f rt oh me fi er as rt l if ee rw , O mp ae pn oS rt tr hee et aM ssa op c. iO atn ec de il no fc oa rt med at, iI o w nill e fixt lr la ('c 1t 4th 5e ', z {i lp o c co ad te io fr no }m ) the
and ability to build increas- fill('145', {location}) easier workflows click('147')
ingly complex workflows (as click('147') Add more steps to # lo cT ah te io s ne sa …rc .h T r he is su lolt cs a h ta iov ne ip nr co luv did ee sd t hm eu zlt ipip cle o de.
build increasingly
exemplified in Figure 1), we complex workflows send_msg_to_user("The zip code is {zip-code}")
conduct a case study to illus-
tratetheworkflowmechanism Figure6: AWMbuildsincreasinglycomplexworkflowsovertime,
behindit. bylearningfrompastexamplesandearlierworkflows.
As exemplified in Figure 6, the agent creates and learns the “Find a place by its name” workflow
in the early stage of the online process by summarizing past examples. Later, when encountering
anexamplethatfurtheraskstoobtainthezipcodeofthelocation, AWMagentlearnstoadoptthe
firstfewstepstofindlocationsbyfollowingtheexistingworkflow,andthenconductsfurthersteps
toobtainthezipcodeoftheplacefound. Integratingthesenewstepsuponthevanillafindlocation
task,theagentsuccessfullybuildsamorecomplexworkflow,i.e.,“getthezipcodeofaplace”.
3.2 MIND2WEB
Mind2Web(Dengetal.,2023)featureswebnavigationincross-task,website,anddomainsettings,
stressingthegeneralityofagentsonversatileoperationsandenvironments. EachtaskinMind2Web
hasafixednumberofsteps;ateachstep,theagentneedstopredictanaction,whichisevaluatedby:
(1)elementaccuracy: tocheckifthecorrectpageelementisselected,(2)actionF tocheckifthe
1
actiontakenontheelementiscorrect,andaggregating(1)and(2)yields(3)stepsuccessratewhich
checksthatbothelementandactionselectionarecorrectatthecurrentstep. Lastly,aftercompleting
everystepinthegiventask, thelastmetric(4)task-levelsuccessratemeasuresifallintermediate
stepsaresuccessfullyconductedforthistask,i.e.,allstepsforthistaskscore1undermetric(3).
BecauseMind2Webprovidesatrainingsetcoveringpartofthetestedwebsites(cross-tasksplit),we
exploreboththeofflinesettingthatinducesworkflowsfromthetrainingsetandappliestotestsets,
andtheonlinesetting,wherewestreamworkflowinductionandinferenceontestqueries(§2.3).
SincewefocusonLM-basedagentsthatonlytaketextualinputs,wecompareAWMtotwostate-of-
the-artmethods,MindAct(Dengetal.,2023)andSynapse(Zhengetal.,2024).MindActintroduces
webpageelementfilteringandmulti-choicetaskformattoeaseobservationprocessing,andSynapse
changestheformattoatrajectorystyleandaugmentsretrievedrelevantexamples. Weintegratethe
element filtering adopted in both methods, and added workflows instead of retrieved examples in
6Synapse,toverifythesuperiorityofreusableworkflowsoverconcreteexamples. Tofairlycompare
with all baseline methods, we run AWM with both gpt-3.5-turbo and gpt-4 models with
temperature0.0. Weusethesamemodelforneuralworkflowinductionandagentactiongeneration.
3.2.1 MAINRESULTS
We first run with AWM offline using Table 3: AWM offline results on Mind2Web cross-
both GPT variants, and find that AWM task dataset. Elem Acc and SR are short for ele-
consistently obtains the highest success ment accuracy and success rate. We footnote the
rate in both step and task levels, lead- GPT variant used by each method, 3.5 and 4 stands
ing to 4.0–8.9% relative and 0.4–2.8 ab- for gpt-3.5-turbo and gpt-4, respectively. We
solute points increases in step-wise and highlightthebestresultwithinthesamemodelvariant.
task-wise success rates than the baselines
Method ElemAcc ActionF StepSR SR
— Synapse with gpt-3.5-turbo and 1
MindAct with gpt-4. Decomposing the MindAct 3.5 20.3 56.6 17.4 0.8
step success rate by element and action CogAgent 3.5 - - 18.6 -
Synapse 34.0 - 30.6 2.4
selection and accuracy, we notice the in- 3.5
AWM 39.0 52.8 34.6 2.8
creases mainly come from more accurate 3.5
elementselection,asindicatedbythe5.0– MindAct 4 41.6 60.6 36.2 2.0
AWM 50.6 57.3 45.1 4.8
9.0elementaccuracyincreaseinTable3. 4
Abstract sub-routines vs. concrete experiences More specifically, compared to the Synapse
(Zheng et al., 2024) method that retrieves the most relevant training examples, AWM achieves a
+5.0elementaccuracyandleadstoa+4.0increaseinstepsuccessrate.Whileaugmentingconcrete,
fullexamplesmaybiasagentstoselectelementssimilartothosepresentedinthegivenexamples,
AWM introduceslessbiasonelementselectionviaitsabstractrepresentationofexample-specific
contextsinworkflows,andthereforeenableshigherstepsuccessrates.
Furthermore,AWMintegratesfrequently-usedsub-routines,whichcanbemoreflexiblyandreadily
leveraged across test examples, compared to the full example trajectories used by Synapse, which
are less likely to appear multiple times. In general, our results indicate that the abstract, reusable
natureofworkflowscontributestothesuperiorityoftheAWMmethod.
Learn to diverge from workflow guidelines Despite more accurate element selection, AWM
getsslightlyloweractionF scoresthanMindAct,possiblybecausetheaugmentedworkflowsmay
1
guidetheagenttotakecertainactionsaligningtotheworkflows, whicharenotalwaysrelevantto
theparticularenvironmentstateathand. Whilefollowingtheworkflowsgenerallyresultsinmore
successfultasktrajectories, agentsstillencountersomechallengesinidentifyingplacestodiverge
fromtheworkflowguidelines.
3.2.2 ONLINEAWMENABLESGENERALIZATION
Beyondtheofflineinductionsetting,wefurtherexploretheAWMintheonlinesetting,similartothe
WebArenaexperimentsetupin§3.1,wherenoadditionaltrainingexamplesareneededbesidestest
queries.Thisnaturallyfacilitatescross-websiteandcross-domaingeneralization,whichweexamine
onthetwoothersplitsprovidedbytheMind2Webdataset: cross-websiteandcross-domaintests.
In addition to the MindAct baseline, we additionally set bars with our AWM setup, by ran-
offline
domlyselectingworkflowsinducedfromthetrainingsetasmemoryaugmentations.Specifically,for
cross-websiteexamples,weselectworkflowsfromthesamedomain; forthecross-domainsetting,
werandomlyselectworkflowsfromalldomains. Weconduct AWM byiterativelyinducing,
online
integrating,andutilizingworkflowsovertestinferences. WealsoexploreAWM offline+online in§C.
As shown in Table 4, both AWM and AWM surpass the MindAct baseline by a large
online offline
margin, resulting in 7.4–8.9, 3.6–3.8, and 14.0–16.9 absolute point improvements in step success
rates,incross-task,cross-website,andcross-domainscenarios.
In-domain, cross-task scenario When tested in-domain, AWM and AWM perform
online offline
comparably to each other. When inspecting the model behaviors in detail, we notice the pros and
cons of each method. AWM induces workflows from model-predicted trajectories that are
online
7Table4:SuccessrateonMind2Webcross-task,cross-website,andcross-domaingeneralizationtest,
usinggpt-4model. EAisshortforelementaccuracyandAF isshortforactionF .
1 1
Cross-Task Cross-Website Cross-Domain
Method
EA AF StepSR SR EA AF StepSR SR EA AF StepSR SR
1 1 1
MindAct* 41.6 60.6 36.2 2.0 35.8 51.1 30.1 2.0 21.6 52.8 18.6 1.0
AWM 50.6 57.3 45.1 4.8 41.4 46.2 33.7 2.3 36.4 41.6 32.6 0.7
offline
AWM 50.0 56.4 43.6 4.0 42.1 45.1 33.9 1.6 40.9 46.3 35.5 1.7
online
not always correct, thus can lead to incorrect workflows that degrade model performance. On the
otherhand,thetrainingandtestexamplesonsomewebsitesvaryintaskdistributions(e.g.,training
examplescoverhowtobuyitemsonAmazon,testexamplesaskforjobapplicationstoAmazonca-
reers.). AWM naturallyresolvesthistrain-testgapbecauseitsoperatingprocessonlyinvolves
online
testqueriesandenvironments,thereforeyieldsworkflowsthatarepresumablymoretargetedtoward
thetestdistribution,whichinturn,leadstohighersuccessratesoverall. Nonetheless,ifdistribution-
matching, high-quality training examples are available, AWM could bring more benefit by
offline
alleviatingthegapissue,astheslightlyhighercross-tasksscoresofAWM inTable4.
offline
Extending to unseen websites and domains When applied on unseen websites or domains,
AWM demonstrates greater generalization abilities, compared to AWM . The perfor-
online offline
mancemarginofAWM (overAWM )widensasthedomaingapsbetweentrainingand
online offline
testing data widen from different websites (e.g., apple to bestbuy) to different domains (e.g., ma-
cys in shopping domain to reddit in social media domain). Because AWM does not require
online
nor rely on information from the training data, it is not affected by any domain gaps. Nonethe-
less, as demonstrated by the substantial improvements of AWM over the MindAct baseline,
offline
AWM stilldemonstratesthatmodelscanbenefitfrommechanisticallysimilarworkflowsfrom
offline
thepreviouslyinducedworkflowrepository.
4 EXPLORING OPTIMAL WORKFLOW REPRESENTATIONS
In this section, we experiment with other possible alternatives to better represent the workflows.
Specifically,weablateworkflowsinsub-routine,abstractformats(§4.1),exploreworkflowsinde-
scriptive texts (§4.2), and lastly, beyond the default workflows that describe environment state in
NL,wecomparestrengthenedobservationswithwebsiteHTMLwithinworkflowsteps(§4.3).
4.1 HOWMUCHDOESTHESUB-ROUTINE,ABSTRACTFORMATCONTRIBUTE?
Inthissection,wecompareourabstract,sub-routine-basedinductionmethodusingLMstoarule-
basedmethodwithoutcontextandsub-routineabstraction.
Specifically,ourrule-basedinductionI firstextractstheactionsequence(e.g.,CLICK→CLICK
rule
→TYPE)ofeachexperienceanddeduplicatesexperiencesbytheiractionsequence. Ineachunique
experience,wethenremovethestepswhoseactioncannotbeexecutedontheenvironment. Wetake
theseunique,validatedexperiencesasworkflows. Findmoredetaileddescriptionsin§B.
WebArena Results As shown in Table 5, using rule- and Table 5: AWM success rate on
LM-based workflow induction performs comparably, with a WebArena using gpt-4, with
small 0.1 gap in success rate; the LM-based method appears rule-andlm-basedinduction.
moreefficientanduses0.4fewersteps. Ourmanualanalysis
foundworkflowsproducedbytheLM-basedinductionmodule Method TotalSR #Steps
I arefiner-grained,preventingagentsfromfollowingunnec-
lm AWM rule 35.6 6.3
essarystepsthatsometimesappearinrule-inducedworkflows, AWM 35.5 5.9
lm
hencemakingthetask-solvingprocessslightlymoreefficient.
Mind2Web Results As shown in Table 6, compared to AWM , AWM improves by a 2.8
rule lm
margin. While augmenting concrete, full examples may bias agents to select elements similar to
those presented in the given examples, AWM introduces less bias on element selection via its
lm
abstractrepresentationofexample-specificcontextsinworkflows.
8Further, AWM uses frequently-used Table6: AWM resultswithdifferentworkflowinduc-
lm
sub-routines, which can be more flexibly tionmethodsonMind2Webcross-taskdataset.
and readily utilized across test examples,
Method ElemAcc ActionF StepSR SR
1
compared to the full example trajectories
MindAct 41.6 60.6 36.2 2.0
induced by AWM , which are less 4
rule AWM 49.5 57.0 43.4 2.0
likely to appear multiple times. In gen- 4,rule
AWM 50.6 57.3 45.1 4.8
eral, our results indicate that the abstract, 4,lm
reusablenatureofworkflowscontributestotheefficacyofAWM method.
lm
4.2 WORKFLOWSINDESCRIPTIVETEXTS
AWM represents workflow steps in a program format. In this section, we compare with a textual
formatforworkflows,tounderstandwhethertextorcodeservesasabetterformatforagentmemory.
Moreconcretely,wepromptgpt-3.5-turbotoverbalizetheactiontrajectoryintheworkflows
induced in earlier experiments. For example, from an action CLICK({submit-id}), its ver-
balized NL representation reads similar to “CLICK the submit button”. We use the same textual
observationandthoughtsfromcodeactionsasobservationandthoughtsinthesetextactions.
From the results in Table 7, AWM text Table7: Mind2Webcross-taskresultswith AWM us-
achieves slightlyhigher element selection ingcodeandtextworkflows.
accuracyandstepsuccessrate,by0.6and
0.3 points, respectively, yet degrades 1.2 Method ElemAcc ActionF 1 StepSR SR
in task success rate. Overall, we do not MindAct 41.6 60.6 36.2 2.0
find substantial performance variance be-
AWM 50.6 57.3 45.1 4.8
tween workflows represented in text and
AWM 51.2 57.4 45.4 3.6
code formats, indicating that both forms text
canbringeffectiveaugmentationstoagentmemory.
4.3 ENVIRONMENTABSTRACTIONINWORKFLOWS
AWMdescribesintermediatewebpagestatesusingNL,yetshowingconcretestatesmaybehelpful
tobettergroundagentsontheenvironment. Sinceawebpage’sfullHTMLcanbeoverlylong,we
filterthewebpagerepresentationusingtherelevancepredictorofDengetal.(2023), andaugment
eachworkflowstepwiththisshortenedHTMLthatonlyhaselementspredictedasrelevant. Werun
gpt-3.5-turbowithonlydescriptions,onlyHTML,andbothtypesofcontent.
As shown in Table 8, NL description Table8: Mind2WebresultsusingGPT-3.5-turbowithdif-
of states is more useful than HTML, ferentenvironmentrepresentations.
asreplacingNLwithHTMLleadstoa
slight0.8dropinstepsuccessrate. In- Desc. HTML ElemAcc ActF 1 StepSR SR
terestingly, using both NL and filtered ✓ ✗ 39.0 52.8 34.6 2.8
HTMLleadstoworseresults. Wecon- ✗ ✓ 38.1 54.0 33.8 2.8
jecturethereasontobetwo-fold. First, ✓ ✓ 37.1 51.3 32.9 2.0
addingNLandHTMLsubstantiallyin-
creasesthecontextlength,thusmakingitharderformodelstohandlethingscorrectly. Second,the
filteredHTMLhasasubstantialnumberofirrelevantitems(missingallcorrectelements47%ofthe
time)thuspotentiallycontradictingNLdescriptionsandimpairingagentabilities.
5 EXPLORING WORKFLOW UTILIZATION IN CONTEXT AND IN ACTION
Besidesintegratingworkflowsasagentmemory,wealsoexploreworkflowsinexpandingtheagent
action space, denoted as AWM . We leverage the programmatic nature of workflows and wrap
AS
eachworkflowintoahigh-levelfunction, similartoashortcuttooltheagentcancalltoperforma
pre-determinedseriesofactions(Wangetal.,2024b). Formally,anagentisinitiallyequippedwith
default,primitiveactionsP (e.g.,click,type),andAWM addstheinducedworkflowactions
AS
W (e.g.,find place,get place zipcode)toitsactionspace.
The agent can call a primitive or workflow action at each step. When a primitive action is called,
theagentimmediatelytakesthataction. Whentheagentcallsaworkflowaction,itwilltriggerthe
9sequence of pre-determined steps in Table 9: Mind2Web results with AWM variant
AS
the workflow. For example, calling the thatalterstheactionspacebesidesmemoryaugmen-
login(username, password) work- tation. Allmethodsusegpt-4.
flowactionresultsinsequentiallyexecuting Method ElemAcc ActionF StepSR SR
1
click(box1-id)→type(box1-id,
MindAct 41.6 60.6 36.2 2.0
username) → click(box2-id)
AWM 50.6 57.3 45.1 4.8
→ type(box2-id, password) →
AWM 51.8 56.7 46.4 3.6
click(submit-id). The workflow AS
actioniscompletedwhenallintermediateprimitiveactionsarefinished.
In Table 9, expanding the agent action space with workflows (AWM ) slightly improves the
AS
step success rate by 1.3 points, and gets the same overall success rate, 3.2, of the base memory-
augmented AWM.Weanalyzedagentpredictionsandfoundtheycallworkflowactionsinmerely
18.5%ofthetasks, suggestingaresistanceofcurrentagentstousenewly-addedactions. Overall,
expandingactionswithworkflowsseemstoreinforceworkflowsinmemory,andbringssmallextra
gainsasauxiliaryactions.
However, workflow actions 1 2
do not always lead to task
success. A representative
example is shown in Fig-
ure 7. When booking
flights, users often input a
city name such as “New
York,” yet the system of-
ten pops up some nearby
Depend on the
airports to support next-step pop up options
search. While one can in- click(120) # id of textbox under ‘To*’
select(‘New York, NY, US (JFK)’)
duceabook flightwork- type(120, “New York”) # enter location
flow that enters all required Figure 7: An example of dynamic environment changes that chal-
dataviaapre-determinedac- lengeworkflowactionutilization.
tion sequence, the action to
choose pop-up airports is executed without seeing the intermediate states with available pop-up
options,andisnotflexibleenoughtodoso. Moreadvancedtechniquessuchasgrantingreal-time
state access or dynamic execution loops can be promising to solve this issue, and we encourage
futureworktoleveragetheAWMframeworktoexplorethese.
6 RELATED WORK
Web Agent Benchmarks The first modern and widely used web agent benchmark is Shi et al.
(2017)’s MiniWob, which evaluates across various scenarios such as flight booking. (Liu et al.,
2018)thencreatedMiniWob++withextrachallenges. Morerecently, WebShop(Yaoetal.,2022)
features a simulated e-commerce website and crowd-sourced text instructions. WebArena (Zhou
et al., 2024) integrates four more websites and enables realistic execution-based evaluations, and
VisualWebArena (Koh et al., 2024) extends with tasks that necessitate visual inputs. Mind2Web
(Deng et al., 2023) proposes versatile tasks and stresses agent generalization across websites and
domains. WeuseWebArenaandMind2Webtoevaluateourmethod’stasksuccessandgenerality.
Enhancing Agents for Complex Tasks Many works improve agents by modifying their action
space,suchasconstrainingitsactionsearchspace(Liuetal.,2018),enablingLMself-feedbackto
refinepredictedactions(Sunetal.,2023),orincorporatinghuman-designedactionstocertaintasks
(Sodhietal.,2023). Otherworksexplorewaystoaugmentagentmemory,suchasaddingexample
demonstrations in context (Haluptzok et al., 2023; Zheng et al., 2024; Fu et al., 2024). However,
high-quality examples are not always available or easy to collect. Our AWM can flexibly operate
evenwhenauxiliaryexamplesarenon-existentandonlytestqueriesareavailable.
LearningCommonProceduresfromExperiences Someworksusefullexamples(Zhengetal.,
2024)ascontextforanagent,yettheyentanglewithexample-specificcontextsandfacechallenges
inextrapolatingtoothertasksordomains(Majumderetal.,2023). Manyworksproposetoextract
frequently reused sub-routines from experiences with rule-based (Ellis et al., 2023; Bowers et al.,
10
tnemnorivnE
noitcA2023; Grand et al., 2023) or LM-based methods (Cai et al., 2023; Wang et al., 2024c;a) methods,
andusethemasauxiliaryskillstoeasefuturetask-solving(Ohetal.,2017;Liangetal.,2023;Yu
et al.,2023; Mao etal., 2023). We exploredboth rule-and LM-based methodsto induce reusable
workflows,andusethemflexiblyascontextguidancethatarefreeofenvironmentgroundingissues.
7 CONCLUSION
Weproposeagentworkflowmemorythatinduces,augments,andusesworkflows,offlinefromavail-
ableexamplesorpurelyonlineatinferencetime. WeevaluateAWMonWebArenaandMind2Web,
and achieve 24.6% and 51.1% relative increases in task success rate. AWM also demonstrates its
superiorgeneralizationabilitiesacrosstasks,websites,anddomains. WehopeAWMshedsinsight
onandboostsadvancesindynamicmemorybuildingandagentadaptationsonvarieddigitaltasks.
ACKNOWLEDGMENTS
We thank Frank Xu, Jiayi Pan, Vijay Viswanathan, Chenglei Si, and Jason Wu for their helpful
discussionsduringtheearlystageofthisproject. ZoraZhiruoWangissupportedbytheCMUTeng
FamilyPresidentialFellowship.
REFERENCES
Matthew Bowers, Theo X. Olausson, Lionel Wong, Gabriel Grand, Joshua B. Tenenbaum, Kevin
Ellis,andArmandoSolar-Lezama.Top-downsynthesisforlibrarylearning.Proc.ACMProgram.
Lang., 7(POPL), jan 2023. doi: 10.1145/3571234. URL https://doi.org/10.1145/
3571234.
Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models
astoolmakers. arXivpreprintarXiv:2305.17126, 2023. URLhttps://arxiv.org/pdf/
2305.17126.
MicheleneTHChi,PaulJFeltovich,andRobertGlaser.Categorizationandrepresentationofphysics
problemsbyexpertsandnovices. Cognitivescience,5(2):121–152,1981.
MicheleneTHChi,RobertGlaser,andMarshallJFarr. Thenatureofexpertise. PsychologyPress,
2014.
Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and
Yu Su. Mind2web: Towards a generalist agent for the web. In Thirty-seventh Conference on
Neural Information Processing Systems Datasets and Benchmarks Track, 2023. URL https:
//openreview.net/forum?id=kiYqbO3wqw.
Alexandre Drouin, Maxime Gasse, Massimo Caccia, Issam H Laradji, Manuel Del Verme, Tom
Marty, Le´o Boisvert, Megh Thakkar, Quentin Cappart, David Vazquez, et al. Workarena:
How capable are web agents at solving common knowledge work tasks? arXiv preprint
arXiv:2403.07718,2024.
KevinEllis,LionelWong,MaxwellNye,MathiasSable-Meyer,LucCary,LoreAnayaPozo,Luke
Hewitt,ArmandoSolar-Lezama,andJoshuaBTenenbaum. Dreamcoder: growinggeneralizable,
interpretableknowledgewithwake–sleepbayesianprogramlearning.PhilosophicalTransactions
oftheRoyalSocietyA,381(2251):20220050,2023.
YaoFu,Dong-KiKim,JaekyeomKim,SungryullSohn,LajanugenLogeswaran,KyunghoonBae,
andHonglakLee. Autoguide: Automatedgenerationandselectionofstate-awareguidelinesfor
largelanguagemodelagents. arXivpreprintarXiv:2403.08978,2024.
GabrielGrand,LionelWong,MatthewBowers,TheoXOlausson,MuxinLiu,JoshuaBTenenbaum,
andJacobAndreas. Lilo:Learninginterpretablelibrariesbycompressinganddocumentingcode.
arXivpreprintarXiv:2310.19791,2023.
PatrickHaluptzok,MatthewBowers,andAdamTaumanKalai. Languagemodelscanteachthem-
selvestoprogrambetter. InTheEleventhInternationalConferenceonLearningRepresentations,
2023. URLhttps://openreview.net/forum?id=SaRj2ka1XZ3.
11JingYuKoh,RobertLo,LawrenceJang,VikramDuvvur,MingChongLim,Po-YuHuang,Graham
Neubig,ShuyanZhou,RuslanSalakhutdinov,andDanielFried.Visualwebarena:Evaluatingmul-
timodalagentsonrealisticvisualwebtasks. InICLR2024WorkshoponLargeLanguageModel
(LLM)Agents,2024. URLhttps://openreview.net/forum?id=RPKxrKTJbj.
JackyLiang,WenlongHuang,FeiXia,PengXu,KarolHausman,BrianIchter,PeteFlorence,and
AndyZeng. Code aspolicies: Languagemodel programsfor embodiedcontrol. In2023 IEEE
InternationalConferenceonRoboticsandAutomation(ICRA),pp.9493–9500.IEEE,2023.
Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, and Percy Liang. Reinforcement learning on
web interfaces using workflow-guided exploration. In International Conference on Learning
Representations,2018. URLhttps://openreview.net/forum?id=ryTp3f-0-.
BodhisattwaPrasadMajumder,BhavanaDalviMishra,PeterJansen,OyvindTafjord,NiketTandon,
LiZhang,ChrisCallison-Burch,andPeterClark. Clin:Acontinuallylearninglanguageagentfor
rapidtaskadaptationandgeneralization. arXivpreprintarXiv:2310.10134,2023.
Jiayuan Mao, Toma´s Lozano-Pe´rez, Joshua B Tenenbaum, and Leslie Pack Kaelbling. Learning
reusable manipulation strategies. In Conference on Robot Learning, pp. 1467–1483. PMLR,
2023.
Shikhar Murty, Christopher Manning, Peter Shaw, Mandar Joshi, and Kenton Lee. Bagel: Boot-
strappingagentsbyguidingexplorationwithlanguage. arXivpreprintarXiv:2403.08140,2024.
JunhyukOh,SatinderSingh,HonglakLee,andPushmeetKohli. Zero-shottaskgeneralizationwith
multi-task deep reinforcement learning. In International Conference on Machine Learning, pp.
2661–2670.PMLR,2017.
JiayiPan,YichiZhang,NicholasTomlin,YifeiZhou,SergeyLevine,andAlaneSuhr. Autonomous
evaluationandrefinementofdigitalagents. arXivpreprintarXiv:2404.06474,2024.
Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, and Timothy P Lillicrap. An-
droidinthewild: A large-scale dataset for android device control. In Thirty-seventh Confer-
ence on Neural Information Processing Systems Datasets and Benchmarks Track, 2023. URL
https://openreview.net/forum?id=j4b3l5kOil.
Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Mary-
bethFair,AliceLi,WilliamBishop,WeiLi, FolawiyoCampbell-Ajala,etal. Androidworld: A
dynamic benchmarking environment for autonomous agents. arXiv preprint arXiv:2405.14573,
2024.
Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Hernandez, and Percy Liang. World of bits:
An open-domain platform for web-based agents. In Doina Precup and Yee Whye Teh (eds.),
Proceedings of the 34th International Conference on Machine Learning, volume 70 of Pro-
ceedings of Machine Learning Research, pp. 3135–3144. PMLR, 06–11 Aug 2017. URL
https://proceedings.mlr.press/v70/shi17a.html.
Paloma Sodhi, SRK Branavan, and Ryan McDonald. Heap: Hierarchical policies for web actions
usingllms. arXivpreprintarXiv:2310.03720,2023.
HaotianSun,YuchenZhuang,LingkaiKong,BoDai,andChaoZhang. Adaplanner:Adaptiveplan-
ningfromfeedbackwithlanguagemodels. InThirty-seventhConferenceonNeuralInformation
ProcessingSystems,2023. URLhttps://openreview.net/forum?id=rnKgbKmelt.
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,
and Anima Anandkumar. Voyager: An open-ended embodied agent with large language mod-
els. Transactions on Machine Learning Research, 2024a. ISSN 2835-8856. URL https:
//openreview.net/forum?id=ehfRiF0R3a.
Zhiruo Wang, Zhoujun Cheng, Hao Zhu, Daniel Fried, and Graham Neubig. What are tools any-
way? asurveyfromthelanguagemodelperspective. InFirstConferenceonLanguageModeling,
2024b. URLhttps://openreview.net/forum?id=Xh1B90iBSR.
12ZhiruoWang,GrahamNeubig,andDanielFried.TroVE:Inducingverifiableandefficienttoolboxes
for solving programmatic tasks. In Forty-first International Conference on Machine Learning,
2024c. URLhttps://openreview.net/forum?id=DCNCwaMJjI.
Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. Webshop: Towards scal-
able real-world web interaction with grounded language agents. In S. Koyejo, S. Mo-
hamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Advances in Neural In-
formation Processing Systems, volume 35, pp. 20744–20757. Curran Associates, Inc.,
2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/
file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf.
Ori Yoran, Samuel Joseph Amouyal, Chaitanya Malaviya, Ben Bogin, Ofir Press, and Jonathan
Berant.Assistantbench:Canwebagentssolverealisticandtime-consumingtasks? arXivpreprint
arXiv:2407.15711,2024.
WenhaoYu,NimrodGileadi,ChuyuanFu,SeanKirmani,Kuang-HueiLee,MontseGonzalezAre-
nas,Hao-TienLewisChiang,TomErez,LeonardHasenclever,JanHumplik,etal. Languageto
rewardsforroboticskillsynthesis. arXivpreprintarXiv:2306.08647,2023.
Longtao Zheng, Rundong Wang, Xinrun Wang, and Bo An. Synapse: Trajectory-as-exemplar
promptingwithmemoryforcomputercontrol.InTheTwelfthInternationalConferenceonLearn-
ingRepresentations,2024. URLhttps://openreview.net/forum?id=Pc8AU1aF5e.
Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,
Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham Neubig. Webarena: A real-
istic web environment for building autonomous agents. In The Twelfth International Confer-
ence on Learning Representations, 2024. URL https://openreview.net/forum?id=
oKn9c6ytLx.
13A LM-BASED WORKFLOW INDUCTION
Asintroducedin§2.3,onerealizationofourworkflowinductionmoduleistopromptLMstogen-
erateabstract,sub-routineworkflowsfromthegivenexamples,i.e.,experience. Inthissection,we
providethedetailedmodelprompt, exemplarworkflowsinducedbymodels, andqualityexamina-
tionontheseworkflows.
A.1 MODELPROMPT
WeprovidetheexactpromptinputtedtothemodelforWebArenaandMind2Webexperimentsbe-
low. Experimentsonbothdatasetsusethesameprompt.
Givenalistofwebnavigationtasks,yourtaskistoextractthecommonworkflows.
Eachgiventaskcontainsanaturallanguageinstruction, andaseriesofactionstosolvethetask.
Youneedtofindtherepetitivesubsetofactionsacrossmultipletasks,andextracteachofthemout
asaworkflow.
Eachworkflowshouldbeacommonlyreusedsub-routineofthetasks. Donotgeneratesimilaror
overlapping workflows. Each workflow should have at least two steps. Represent the non-fixed
elements(inputtext,buttonstrings)withdescriptivevariablenamesasshownintheexample.
A.2 EXAMPLEWORKFLOWS
WepresentseveralexemplarworkflowsinducedonWebArenaandMind2Web,togiveamorecon-
creteimpressionofworkflows.
WebArenaWorkflows WeshowoneexampleworkflowoneachwebsiteinvolvedinWebArena.
##shopping: BrowseProductsinaSpecificCategory
Tobrowseproductsinaspecificcategory,Ineedtonavigatetotherelevantmaincategory. Iwill
startbyhoveringoverthemaincategorymenuitemtorevealthesubcategories.
hover(’main category id’)
Tobrowseproductsinthespecificsubcategory,Ineedtoclickonthesubcategorylink.
click(’subcategory id’)
##shoppingadmin: EditandSaveChanges
Thisworkflowisusedtoeditspecificfieldsandsavechanges.
Toeditaspecificfield,Ineedtolocatethefieldandupdateitsvalue.
clear(’field id’)
fill(’field id’, ’new value’)
Next,Ineedtosavethechangesbyclickingthe”Save”button.
click(’save button id’)
##reddit: Navigatetoaforumsectionandselectaspecificforum
Tonavigatetoaspecificforum,Ineedtoclickonthe”Forums”section.
click(’42’)
Now,Ineedtoclickonthespecificforumlinkbasedontheforumnameprovided.
click(’<forum link id>’)
##gitlab: NavigationtoRepositoryandContributorsSection
Thisworkflowinvolvessearchingforarepositoryandnavigatingtoitscontributorstofinddetailed
contributiondata.
First,searchforthespecificrepositorytogatherinformation.
fill(’130’, ’{RepositoryName}’)
press(’130’, ’Enter’)
Navigatetothe“Contributors”sectiontoviewcontributiondetails.
click(’311’) #“Contributors”link
Obtainandreporttherequiredcontributordetails.
send msg to user(’{ContributorDetails}’)
14##map: CalculateTravelTimeandDistance
To calculate travel time and distance between two locations, I will use the directions feature. I
willfillintherespectivefieldsandselectthemodeoftransportation.
fill(’158’, ’FROM LOCATION’)
fill(’163’, ’TO LOCATION’)
select option(’166’, ’MODE OF TRANSPORTATION’)
click(’171’)
Iwillusethesedetailstoprovidetheuserwithaccuratetraveltimeanddistanceinformation.
send msg to user(’The distance between FROM LOCATION and
TO LOCATION is DISTANCE and the estimated travel time is TIME.’)
Mind2WebWorkflows WepresentoneexampleworkflowineachdatadomaininMind2Web.
#travel: enter flight locations
Giventhatyouareontheflightbookingpage,thisworkflowentersthedepartureanddestination
city/airportforyourflight.
[link]FromDepartureAirportorCityYourOrigin−>CLICK
[textbox]OriginCityorAirport−>TYPE:{your-origin-city}
[link]{best-popup-option}−>CLICK
[link]ToDestinationAirportorCityYourDestination−>CLICK
[textbox]DestinationCityorAirport−>TYPE:{your-destination-city}
[link]{best-popup-option}−>CLICK
#shopping: search and sort
GiventhatyouareontheAmazonsearchresultspage, thisworkflowsearchesforaproductand
sortstheresults.
[textbox]SearchAmazon−>TYPE:{search-term}
[button]Go−>CLICK
[span]Sortby: −>CLICK
[option]{sort-option}−>CLICK
#entertainment: search and select
GiventhatyouareontheIMDbhomepage,thisworkflowsearchesforatermandselectsthebest
match.
[textbox]SearchIMDb−>TYPE:{search-term}
[button]SubmitSearch−>CLICK
[button]{best-match}−>CLICK
A.3 WORKFLOWQUALITYANALYSIS
To provide intermediate information beyond the end-to-end task success, we propose several met-
rics to verify the quality of the model-induced workflows. (1) Number of workflows: The number
of workflows augmented to the memory, fewer workflows is better, whereas agents rely on fewer
workflows to achieve satisfactory performance. (2) Coverage: How many steps in the action tra-
jectoryarecoveredbytheworkflows,highercoveragepresumablysignalsthegeneralapplicability
oftheconcernedworkflow. (3)Functionoverlap: Howmuchfunctionalityoverlapexistsbetween
workflows,wemeasurethisbycountingthenumberofoverlappingsub-trajectories(≤2steps)be-
tweeneachworkflowpairforthesamewebsite. Lessoverlapindicatesmoremaximizedworkflow
management. (4)Utilityrate: Howoftenareworkflowsusedbytestexamples.
We evaluate the workflows on WebArena test examples and Mind2Web cross-task test examples.
WedonotevaluatecoverageonWebArenasinceitrequirescanonicaltrajectories,yetwhicharenot
availableforWebArena. ForMind2Web,wedonotevaluateoncross-websiteandcross-domaintest
examples since workflows induced from training examples do not have domain overlapping with
thesetestexamples,thuslessapplicabletothem.
As shown in Table 10, neural-based induction produces 7.3–7.4 workflows per example, which is
efficientanddonotaddtoomuchcontenttothememory. OnWebArena,theinducedworkflowsare
15Table10: Qualityevaluationofmodel-inducedworkflowsonMind2Webdataset.
Metric #Workflows Coverage FunctionOverlap UtilityRate
WebArena 7.4 - 0.08 0.94
Mind2Web 7.3 0.40 0.20 0.91
usedby0.94ofthetestexamples,indicatingitswideapplicabilityamongvariedtasks.Further,only
0.08ofthestepsbetweenworkflowsoverlap,demonstratingtheefficiencyofworkflowsinsolving
respectivetasks. WorkflowsonMind2Web, althoughusedsimilarlyfrequentlyasindicatedbythe
high0.91utilityrate,haveslightlymorefunctionaloverlap,andonlyachievea0.40coverageover
test examples. However, as the training examples used to induce workflows have substantial task
distributionvarianceswiththecross-tasktestexamples,thisrelativelylowcoverageisreasonable.
B RULE-BASED WORKFLOW INDUCTION
BeyondLM-basedworkflowinduction,wealsoexploredarule-basedworkflowinductionmethod.
Ourrule-basedworkflowinductionmoduleconsistsoftwosteps: (i)experiencededuplication,and
(2)invalidactionfiltering.
For deduplication, we extract the action sequence of the experience, e.g., extracting CLICK
→ CLICK → TYPE from the trajectory CLICK(’12’) → CLICK(’30’) → TYPE(’44’,
"cat"). We group experiences by their action sequence and randomly select n (n = 1 by de-
fault) experiences from each group. Specifically on WebArena, where the task template for each
experience is available. We conduct another round of deduplication by grouping experiences by
theirtasktemplate,andrandomlyselectingn(n=1bydefault)experiencesfromeachgroup. This
processyieldsdiverseexperiencesfromthegivensetofexperiences.
Next,foreachuniqueexperience,weremovetheinvalidstepsinitsactiontrajectory.Invalidactions
meansactionsthatcannotbesuccessfullyexecutedontheenvironment,becausetheinputarguments
do not meet the requirement of the action function. Specifically, we have one rule of determining
invalid actions for CLICK and TYPE, that requires the first argument to be a string-formatted in-
teger (which refers to the id of an element in the environment). We remove CLICK and TYPE
stepsiftheydonotmeetthisrequirement. Forexample,anexperiencewithtrajectoryCLICK(12)
→CLICK(’12’)→CLICK(’30’)→TYPE(44, "cat")→TYPE(’44’, "cat")will
yieldCLICK(’12’)→CLICK(’30’)→TYPE(’44’, "cat"). Weconductthisinvalidac-
tionfilteringforeachuniqueexperience,andtaketheresultingexperiencesasrule-basedworkflows.
C INTEGRATING AWM OFFLINE AND ONLINE
WecomparedAWM andAWM in§3.2,thatadoptsworkflowsinducedseparatelyfrom
offline online
trainingoron-the-flyduringtesting,respectively. Inthissection,weexploreanintegrationofboth
setsofworkflows,AWM off+on,thatinjectsrelevanttrainingworkflowstowarmstarttask-solving,
butalsoaggregatesincreasinglymoreonline-inducedworkflowstobetteradapttotestdistributions.
Table 11: Success rate on Mind2Web cross-task, cross-website, and cross-domain generalization
test,usinggpt-4model. EAisshortforelementaccuracyandAF isshortforactionF .
1 1
Cross-Task Cross-Website Cross-Domain
Method
EA AF StepSR SR EA AF StepSR SR EA AF StepSR SR
1 1 1
MindAct* 41.6 60.6 36.2 2.0 35.8 51.1 30.1 2.0 21.6 52.8 18.6 1.0
AWM 50.6 57.3 45.1 4.8 41.4 46.2 33.7 2.3 36.4 41.6 32.6 0.7
offline
AWM 50.0 56.4 43.6 4.0 42.1 45.1 33.9 1.6 40.9 46.3 35.5 1.7
online
AWM off+on 50.0 57.0 44.5 1.6 41.8 45.5 33.3 1.1 39.3 44.3 34.1 1.5
From Table 11, AWM off+on scores between AWM offline and AWM online across three test splits.
Rather than an additive effect, workflows induced offline and online are not fully compatible with
eachother,particularly,theofflineworkflowsseemtoimpairthegenerativequalityandutilityeffi-
cacyofonlineworkflows,thereforeresultinginmediumresultsoverall.
16