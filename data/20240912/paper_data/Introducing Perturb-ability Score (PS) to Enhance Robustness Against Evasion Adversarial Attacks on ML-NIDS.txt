Introducing Perturb-ability Score (PS) to
Enhance Robustness Against Evasion Adversarial
Attacks on ML-NIDS
Authors’ draft for soliciting feedback
Mohamed elShehaby,
Carleton University,
mohamedelshehaby@cmail.carleton.ca
Ashraf Matrawy,
Carleton University,
ashraf.matrawy@carleton.ca
September 12, 2024
Abstract
This paper proposes a novel Perturb-ability Score (PS) that can be
used to identify Network Intrusion Detection Systems (NIDS) features
that can be easily manipulated by attackers in the problem-space. We
demonstrate that using PS to select only non-perturb-able features for
ML-basedNIDSmaintainsdetectionperformancewhileenhancingrobust-
ness against adversarial attacks.
1 Introduction
Machine Learning (ML) is widely employed in Network Intrusion Detection
Systems (NIDS) due to its high accuracy in classifying large volumes of data
Figure 1: Evasion Adversarial Attacks in Feature-Space vs Problem-Space
Against NIDS
1
4202
peS
11
]RC.sc[
1v84470.9042:viXra[1]. NIDS play a critical role in protecting computer networks by identifying
malicioustraffic. However,ML-basedNIDSmodelscanbethetargetofevasion
adversarial attacks [2]. These attacks aim to deceive the ML model during
decision-making by modifying or adding carefully crafted perturbations to the
input data, often based on the gradient of the target ML model.
Evasion Adversarial Attacks in Feature-Space vs Problem-Space:
Ibitoyeetal. [2]introducedtheconceptof”space”inthetaxonomyofadversar-
ial attacks for network security, distinguishing between feature-space (manipu-
lating feature vectors) and problem-space attacks (modifying actual data), see
Figure 1.
Feature-space attacks may not be practical against NIDS due to challenges
an attacker would face in feature vector access and challenges with feature cor-
relations and network constraints [6]. On the other hand, problem-space at-
tacks are more practical than feature-space as the modifications happen to the
network packets (feasible for an external attacker). They typically start with
feature-space perturbations, then translate to real-world packet modifications
(Inverse Feature-Mapping [5]). Despite being considered more practical than
feature-space attacks, these attacks also face several practicality issues [6], such
as: challenges in maintaining malicious intent and network functionality while
altering packets; keeping up-to-date knowledge of the model, its features, and
extraction techniques; or predicting correct common features. Problem-space
attacks must also address NIDS features constraints.
Perturb-abilityofFeaturesinProblem-SpaceAgainstNIDS:Problem-
space evasion attacks on NIDS involve modifying network packets with the aim
of resulting in manipulations to some features within the feature vector. Per-
turbing certain NIDS features within the problem-space, without affecting net-
work functionality, might be achievable, for instance, adding padding to pay-
loads or introducing delays between packets perturbs length and interarrival
timefeatures(Figure2a). However,problem-spaceconstraintssignificantlylimit
the perturb-ability of many other NIDS features. For example, modifying the
destination IP or port number disrupts network functionality (Figure 2b), and
some features, like backward and inter-flow/-connection features, are inacces-
sible for modification. N.B., by non-perturb-able features, we mean features
that cannot be perturbed in the problem-space while complying with
network constraints. Perturb-able features are the opposite.
2 Perturb-ability Score (PS)
WeintroducethePerturb-abilityScore(PS)toquantifyeachfeature’sperturb-
ability. We also discuss how PS classifies NIDS features and enables a defense
against practical problem-space evasion attacks.
2(a)ExamplesofPerturb-ableFeatures (b)ExamplesofNon-Perturb-ableFeatures
inProblem-SpaceAgainstNIDS inProblem-SpaceAgainstNIDS
Figure 2: Examples of Perturb-able vs Non-Perturb-able Features in Network
Traffic
2.1 Evaluating PS
The goal of PS is to obtain a Perturb-ability score for each feature (f ) in a
i
dataset D, where i is the ID of the feature from 1 to n, and n is the number of
features in D. PS should range from 0 (features extremely hard to perturb in
problem-spacewhilemaintainingthenetworksconstraints)to1(featurescanbe
perturbed in problem-space while maintaining the networks constraints). The
PS [f ] is the geometric average of the following five fields:
Total i
2.1.1 PS [f ]: Strict Header Features/ Affects Network or Malicious
1 i
Functionality:
ThisPSfieldfocusesonstrictHeaderfeaturesandnetwork/maliciousfunction-
ality of network flows after adding perturbations in the problem-space. PS [f ]
1 i
will be 0 if any of the following conditions are true (which will make PS [f ]
Total i
equals 0);
C1: the feature f is a strict header feature (IP addresses in TCP flows,
i
destination port number or protocol)
C2: adding perturbation to feature f will affect the network or malicious
i
functionality of the flow.
PS [f ] can be described with the following equation:
1 i
(cid:40)
0, if (C1 or C2)
PS [f ]=
1 i
1, otherwise
2.1.2 PS [f ]: The range of Possible Values of a Feature:
2 i
This PS field considers the cardinality (number of possible values) of a NIDS
feature. In unconstrained domains like computer vision, attackers can freely
3perturb pixels, which typically have a range of 0 to 255 per channel (e.g., red,
green, blue). Conversely, certain NIDS features have limited cardinality. For
example, a NIDS dataset may have binary or categorical features with a lim-
ited number of categories. Such features offer less flexibility to attackers. The
gradients of the targeted model might suggest perturbations in a specific direc-
tion, but the attacker might be unable to comply due to the limited number of
possible feature values of these features.
PS [f ] will be 1 if f ’s number of Possible Values (PV) is greater than 255
2 i i
(this feature will be similar to computer vision’s pixel, and it will be flexible to
perturb). On the other hand, if f ’s PV (PV[f ]) is less than or equal to 255,
i i
PS [f ] will be equal to a linear function where its output is 1 if f ’s PV is 255,
2 i i
and 0.5 if f ’s PV is 2 (binary).
i
PS [f ] can be described with the following equation:
2 i
(cid:40)
1 if PV[f ]>255
i
PS [f ]=
2 i 0.5+(0.5× (PV[fi]−2)) otherwise
(255−2)
2.1.3 PS [f ]: Correlated Features:
3 i
This PS field considers the correlation between a NIDS feature and other fea-
tures. Due to network constraints within NIDS, many features exhibit corre-
lations. For instance, the flow duration feature is typically correlated with the
total forward and backward inter-arrival times. Such correlated features limit
theattacker’sflexibility. Thegradientsofthetargetedmodelmightrecommend
a specific perturbation to one feature and a different perturbation to another.
However,achievingtheseopposingperturbationssimultaneouslyisverydifficult
if the features are highly correlated within the problem-space. As an example,
an attacker cannot simultaneously increase the flow duration while decreasing
both the forward and backward inter-arrival times.
PS [f ]willbeequaltoalinearfunctionwhereitsoutputis0.5iff ’snumber
3 i i
of Correlated Features (CF) is 10 (the maximum number we observed in our
experiments using our chosen threshold), and 1 if f ’s CF (CF[f ]) is 0.
i i
PS [f ] can be described with the following equation:
3 i
PS [f ]=1−0.05×min(CF[f ],10)
3 i i
2.1.4 PS [f ]: Features that attackers cannot access:
4 i
ThisPSfieldfocusesonfeaturesthatattackerscannotaccess. Examplesofsuch
features include backward features (e.g., Minimum Backward Packet Length)
and interflow features (e.g., number of flows that have a command in an FTP
session (ct ftp cmd)).
PS [f ]’s value will depend on the following conditions;
4 i
4C3: the feature f is not a backward or interflow feature. In other words,
i
attackers can access f .
i
C4: the feature f is a backward or interflow feature; however, it is highly
i
correlated with a forward feature. In other words, attackers can modify f in
i
an indirect way.
C5: the feature f is a backward or interflow feature; however, it is corre-
i
lated with multiple forward features. In other words, attackers can modify f
i
indirectly, but it will be challenging for them as it is correlated with multiple
features.
Otherwise (if none of C3, C4, or C5 apply): the feature f is a back-
i
ward or interflow feature and it is not correlated with any forward feature. In
other words, attackers cannot access f .
i

1, if (C3 or C4)

PS [f ]= 0.5, if (C5)
4 i
0,
otherwise
2.1.5 PS [f ]: Features Correlated with numerous flow Packets:
5 i
ThisPSfieldconsidersfeaturesthatarecorrelatedwithnumerousflowpackets.
PS [f ]’s value will depend on the following condition;
5 i
C6: f is a feature that requires modifying the entire flow of packets (for-
i
ward, backward, or both), such as mean or standard deviation features.
(cid:40)
0.5, if (C6)
PS [f ]=
5 i
1, otherwise
2.1.6 PS [f ]:
Total i
The overall Perturb-ability Score (PS [f ]) for each feature f is calculated
Total i i
as the geometric mean of the five individual PS fields we defined. These PS
fields are assigned a value of 0 if a specific condition renders feature f non-
i
perturb-able within the problem-space. A value of 0.5 is assigned if a condition
only reduces the feasibility of perturbing f . The geometric mean was chosen
i
to ensure that PS [f ] becomes 0 if any of the individual PS fields have a
Total i
value of 0. However, it’s important to note that any PS field value below 1 will
contribute to a decrease in the overall PS [f ].
Total i
PS [f ] can be described with the following equation:
Total i
(cid:118)
(cid:117) 5
(cid:117)(cid:89)
PS Total[f i]= (cid:116)5 PS j[f i]
j=1
The PS will be calculated for all features f in the dataset, from i = 1
Total i
to n, where n is the number of features in the dataset.
5Figure 3: Using PS as a Potential Defense against Practical Problem-Space
Evasion Adversarial Attacks
2.2 Enabling a Potential Defense Through PS
Leveraging NIDS feature constraints can counter problem-space adversarial at-
tacks. Figure 3 introduces our defense approach that uses PS. Our method
excludes features with a high perturb-ability score during the feature selection
process. By doing so, attackers encounter no or very few perturb-able features,
significantly reducing the attack surface. This selection process ensures the
features utilized by the NIDS are inherently resistant to manipulation. While
this may require rethinking traditional feature selection methods, the potential
benefits in preventing evasion attempts are substantial. This simple, efficient
solution utilizes network constraints as a defense with minimal overhead.
3 Preliminary Results
Table 1 shows the distribution of the features after applying PS. Low perturb-
ability/non-perturb-able features (green) have a PS of 0. High perturb-ability/
perturb-ablefeatures(red)haveaPSgreaterthanorequalto0.85. Therestare
considered medium perturb-ability features (yellow). To check the validity of
our PS, we examined a recent problem-space evasion adversarial attack against
NIDS created by Yan et al. [7]. In this attack, the authors use three differ-
ent methods to morph traffic, which acts like adding perturbations to certain
features after feature extraction: modifying length-related features, increasing
the number of packets, and modifying time-related features (the duration of
the entire session or the interval between packets). We checked all the fea-
tures correlated to these methods (e.g., Flow Duration, number of Total Fwd
Packets, Total Length of Fwd Packets, Fwd IAT (Inter Arrival Time) Total,
etc.), and all of these features have a high PS (above 0.85) in the datasets that
we used. This means that using our defense will drop these features, making
these kinds of attacks inapplicable because the attacker is morphing
features that are not selected, which will have no effect on the feature
vector. Moreover, Table 2 shows that using only low perturb-ability (green)
features does not create low-performance models; on the contrary, all of these
models have an accuracy and F1 score above 0.9.
Getting the most out of zero-PS features: To maintain high model
performance with fewer features, we utilized low Pert. (Green) features to
extract useful information, e.g., region from destination IP (extracted using
the ipapi Python library) and application from destination port number. This
information was then one-hot encoded before being fed to the models. Further
6Table 1: The number of features in every perturb-ability class, based on our
proposed PS, where green indicates low perturb-ability features class, yellow
indicatesmediumperturb-abilityfeaturesclass, andredindicateshighperturb-
ability features class
#ofLow #ofMed. #ofHigh
Pert. Class
Pert. Pert. Pert. Total
Dataset
Features Features Features
UNSW-NB15[4] 32 5 10 47
CSE-CIC-IDS2018[3] 39 33 16 88
details on our models’ architectures will be available in the full write-up.
Table 2: The performance of an ANN/Random Forest (RF)/SVM/CNN-based
NIDSwithonlythelowPert. (Green)featuresselectedduringfeaturesselection
Dataset Accuracy Precision Recall F1
UNSW-NB15 0.9878 0.9123 1.0000 0.9541
CSE-CIC-IDS2018 0.9999 0.9987 0.9998 0.9993
UNSW-NB15 0.9890 0.9207 0.9990 0.9582
CSE-CIC-IDS2018 1.0000 0.9997 1.0000 0.9998
UNSW-NB15 0.9879 0.9129 0.9997 0.9543
CSE-CIC-IDS2018 0.9999 0.9984 0.9994 0.9989
UNSW-NB15 0.9884 0.9161 0.9993 0.9559
CSE-CIC-IDS2018 0.9999 0.9996 0.9998 0.9997
4 Conclusion
In this paper, we investigate NIDS features’ perturb-ability by proposing the
Perturb-ability Score (PS). A high PS of a feature means that it can be easily
manipulatedintheproblem-space. AlowPSmeansthatmorphingthatfeature
in the problem-space might be impossible or will make the network flow in-
valid. Moreover, weusedPSinapotentialdefensemechanismagainstpractical
problem-space evasion adversarial attacks by only selecting features with low
PS. The preliminary results show that discarding high PS score features won’t
affect models’ performance.
5 Acknowledgement
This work was supported by the Natural Sciences and Engineering Research
Council of Canada (NSERC) through the NSERC Discovery Grant program.
We thank Meriem Debiche for her assistance with data pre-processing during
her internship at Carleton University, supported by the MITACS Globalink
Research Internship program.
7
NNA
FR
MVSNNCReferences
[1] MohamedElShehabyandAshrafMatrawy. Theimpactofdynamiclearning
on adversarial attacks in networks (ieee cns 23 poster). In 2023 IEEE Con-
ference on Communications and Network Security (CNS),pages 1–2.IEEE,
2023.
[2] Olakunle Ibitoye, Rana Abou-Khamis, Ashraf Matrawy, and M Omair
Shafiq. The threat of adversarial attacks on machine learning in network
security–a survey. arXiv preprint arXiv:1911.02621, 2019.
[3] Lisa Liu, Gints Engelen, Timothy Lynar, Daryl Essam, and Wouter Joosen.
Error prevalence in nids datasets: A case study on cic-ids-2017 and cse-
cic-ids-2018. In 2022 IEEE Conference on Communications and Network
Security (CNS), pages 254–262. IEEE, 2022.
[4] Nour Moustafa and Jill Slay. Unsw-nb15: a comprehensive data set for net-
workintrusiondetectionsystems(unsw-nb15networkdataset).In2015mil-
itary communications and information systems conference (MilCIS), pages
1–6. IEEE, 2015.
[5] Fabio Pierazzi, Feargus Pendlebury, Jacopo Cortellazzi, and Lorenzo Cav-
allaro. Intriguing properties of adversarial ml attacks in the problem space.
In 2020 IEEE symposium on security and privacy (SP), pages 1332–1349.
IEEE, 2020.
[6] Mohamed el Shehaby and Ashraf Matrawy. Adversarial evasion attacks
practicality in networks: Testing the impact of dynamic learning. arXiv
preprint arXiv:2306.05494, 2023.
[7] Haonan Yan, Xiaoguang Li, Wenjing Zhang, Rui Wang, Hui Li, Xing-
wen Zhao, Fenghua Li, and Xiaodong Lin. Automatic evasion of machine
learning-based network intrusion detection systems. IEEE Transactions on
Dependable and Secure Computing, 21(1):153–167, 2023.
8