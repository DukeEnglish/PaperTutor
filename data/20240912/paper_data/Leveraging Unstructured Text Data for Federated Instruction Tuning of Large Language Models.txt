Leveraging Unstructured Text Data for Federated
Instruction Tuning of Large Language Models
RuiYe1∗ RuiGe1∗ FengtingYuchi1 JingyiChai1 YanfengWang2,1 SihengChen1,2
1ShanghaiJiaoTongUniversity 2ShanghaiAILaboratory
Abstract
Federatedinstructiontuningenablesmultipleclientstocollaborativelyfine-tunea
sharedlargelanguagemodel(LLM)thatcanfollowhumans’instructionswithout
directly sharing raw data. However, existing literature impractically requires
thatalltheclientsreadilyholdinstruction-tuningdata(i.e.,structuredinstruction-
responsepairs),whichnecessitatesmassivehumanannotationssinceclients’datais
usuallyunstructuredtextinstead. Addressingthis,weproposeanovelandflexible
frameworkFedIT-U2S,whichcanautomaticallytransformunstructuredcorpus
intostructureddataforfederatedinstructiontuning. FedIT-U2Sconsiststwokey
steps:(1)few-shotinstruction-tuningdatageneration,whereeachunstructureddata
piecetogetherwithseveralexamplesiscombinedtopromptanLLMingenerating
aninstruction-responsepair. Tofurtherenhancetheflexibility,aretrieval-based
exampleselectiontechniqueisproposed,wheretheexamplesareautomatically
selectedbasedontherelatednessbetweentheclient’sdatapieceandexamplepool,
bypassingtheneedofdeterminingexamplesinadvance. (2)Atypicalfederated
instructiontuningprocessbasedonthegenerateddata. Overall,FedIT-U2Scan
be applied to diverse scenarios as long as the client holds valuable text corpus,
broadeningtheapplicationscopeoffederatedinstructiontuning. Weconducta
seriesofexperimentsonthreedomains(medicine,knowledge,andmath),showing
thatourproposedFedIT-U2Scanconsistentlyandsignificantlybringsimprovement
overthebaseLLM.
1 Introduction
Instruction tuning has become one of the most imperative components in training contemporary
instruction-followedlargelanguagemodels(LLMs)[1,2,3,4],wheretypically,thetrainingsamples
arecollectedfromdiversesourcesbyacentralparty[5,6,7]. However,thesedatacouldcontainsen-
sitive(e.g.,privateorproprietary)informationthatcannotbedirectlyshared,makingsuchcentralized
learningparadigminapplicableespeciallyfordomainssuchasmedicine[8]andfinance[9].
Addressing this, federated learning [10, 11] has emerged as a well-suited technique to achieve
instructiontuningofLLMswithoutdirectdatasharing. Infederatedinstructiontuning(FedIT),each
party(i.e.,client)keepsitsprivatedatalocallyandsharestheinstruction-tunedLLMwiththecentral
server,whiletheserveraggregatesLLMsfrommultiplepartiesanddistributestheaggregatedLLM
backtoparticipatingparties. Suchparadigmhasattractedmassiveattentionandinterestsfromboth
academia[12,13,14]andindustry[15,16,17].
DespiteextensiveeffortsdedicatedtoFedIT,existingmethodsimpracticallyrelyontheassumption
thateachpartypossessesstructuredinstruction-tuningdata(i.e.,instruction-responsepairs),which
significantlyconstrainsthereal-worldapplicabilityofFedIT.Inpractice,whileclientsmaypossess
*Equalcontribution.
Preprint.Inprogress.
4202
peS
11
]LC.sc[
1v63170.9042:viXravaluabledatalocally,thisdataoftenexistsinanunstructuredformat(juststringsoftext)ratherthan
naturallyalignswiththestructuredformatrequiredforIT[18]. Consequently,currentFedITsystems
facechallengesinscalability,astheynecessitatemanualannotationofdatabyeachclient.
Tofillthisgap, weproposeanovelandflexibleframeworkFedIT-U2S,whichcanautomatically
transformunstructuredcorpusintostructuredinstruction-tuningdataforFedIT,bypassingthemassive
humaneffortsrequiredfordataannotation. Specifically,FedIT-U2Sconsistsoftwokeysteps: few-
shotinstruction-tuningdatagenerationandFedITonthegenerateddata.(1)Theserverfirstdistributes
anopen-sourcedgeneralLLMandafewexamples(couldbeasfewasonlyone)toparticipating
clients. Duringdatageneration,eachclientqueriestheLLMtogeneratemultipleinstructionpairs,
whereeachpairisgeneratedbyfeedingtheLLMwithapromptthatiscomposedoffewexamples
as the context and a sampled piece of its unstructured data. To further enhance the generality
andscalabilityofFedIT-U2S,weproposearetrieval-basedexampleselectionapproach,wherefor
eachsampledpieceofunstructureddata,similarityscoresarecomputedbycomparingitwithall
the examples sent from the server, after which the top-k examples are selected as the few-shot
examplesinthecontextfordatageneration. (2)Subsequently,typicalfederatedinstructiontuning
islaunchedbasedonthegeneralLLMandthegenerateddatasetsinthepreviousstep. Considering
communicationandcomputationefficiency,LoRA[19]isappliedandthereforeonlyasmallsetof
parametersarelearnedandcommunicated. Overall,ourFedIT-U2SframeworkmakesFedITsystem
aspracticalasGoogle’sGBoardapplication(nextwordprediction)[20],wherethesupervisiondata
directlycomesfromuser’sdatawithoutanymanualeffort.
Toverifytheeffectivenessofourproposedframework,weconductaseriesofexperimentscovering
threedomains(i.e.,medicine,knowledge,andmath). Weshowthatacrossthesedomains,ourFedIT-
U2SconsistentlyimprovestheperformanceofthegeneralLLMonthecorrespondingdownstream
task. Besides, we show the effectiveness of several designs, including retrieval-based example
selectionandfilteringduringdatageneration,providingpotentialdirectionsforfurtherimprovingthe
performanceofFedIT-U2S.
Ourcontributionsareasfollows:
1. Weproposethefirstend-to-endframework(FedIT-U2S)fordirectlyleveragingunstructureddata
forfederatedinstructiontuningoflargelanguagemodels.
2. Weproposearetrieval-basedexampleselectiontechniqueandafew-shotdatagenerationmecha-
nism,whichautomaticallyselectsexamplesforhigherrelatednessandgeneratesstructureddatain
anexpectedmanner.
3. WeverifytheeffectivenessofFedIT-U2Sthroughaseriesofexperimentsonmultipledomains.
2 RelatedWork
Federated Learning of Large Language Models. Federated learning is a privacy-preserving
machinelearningparadigmthatenablesmultipleclientstocollaborativelytrainmachinelearning
models without sharing their raw data [10, 11]. With the rise of large language models (LLMs),
researchers have recently begun to consider federated training of LLMs to safeguard client data
privacyortoaddressthescarcityofpubliclyavailabledata[21,12],whichhasattractedmassive
attentionandinterestsfrombothacademia[12,13,14]andindustry[15,16,17].
Specifically, OpenFedLLM [12] offers an integrated framework and provides a comprehensive
empiricalstudytoshowthepotentialoffederatedinstructiontuningofLLMs(FedIT).Similarly,
FederatedScope-LLM[17]andFedML-LLM[15]provideframeworksthatimplementFedIT;while
FedLLM-Bench[13]offersreal-worlddatasetsandbenchmarks. Besidesframeworksandbench-
marks[22],aseriesofmethodsareproposedtotargetvariousperspectivesincludingsafetyalign-
ment[23],privacy[24],heterogeneouscomputation[25].
However,existingliteratureassumesthatclientdataisstructuredintheformofinstruction-response
pairs,overlookingtherealitythatclientdataoftenexistsinanunstructuredformat. Insuchcases,
clientsarerequiredtoannotatedatabeforeparticipatinginFedIT,whichislabor-intensiveandlimits
itsbroaderadoption. Inthispaper,weaddressthisissueforthefirsttimebyproposingFedIT-U2S,
amethodthatautomatesthetransformationofunstructuredclientdataintostructureddatapriorto
FedIT.ThisreducestheneedformanualannotationandbroadenstheapplicabilityofFedIT.
2Examples LLM ① Generation(only once) Given the [document], create
a [question] and [response]
query select pair. example 1 ([document]
Server [example] [instruction] [response]),
[document]
example 2, example 3
[instruction] [document]
[response]
[document]
generated [instruction] fine-tune
Clients samples [response] ② Training
with raw documents
Figure1: OverviewofourproposedFedIT-U2S.Itconsistsoftwokeysteps: datagenerationand
FedIT.DatagenerationisrequiredonlyoncebeforeFedIT.(1)Foreachrawunstructureddatapiece,
clientsselectafewexamplesbyretrievingfromanexampledatabasetoconstructafew-shottemplate,
promptingtheLLMtogenerateaninstruction-responsepair. (2)Typicalfederatedinstructiontuning
startsbasedonthegeneratedstructuredinstruction-tuningdata.
DataGenerationinLargeLanguageModels. Thequalityandquantityofdataplayacritical
roleinthetrainingoflargelanguagemodels. However,manuallygeneratingandannotatingdatais
labor-intensiveandhardtoscaleup. Addressingthis,thecommunityturnstousingLLMstogenerate
high-qualitydata[26,27,28,29]. Forexample,Self-Instruct[30]leverages8in-contextexamplesto
promptLLMsforgeneratingnewinstructionsamples. WizardLM[26]instructsChatGPTtogenerate
diverseinstructionsviaevolvingprompt. MATRIX[31]instructstheLLMstogeneratedataforvalue
alignmentviasocialsimulation. Genie[18]employsfew-shotmethods[32]totransformunstructured
dataintothreekindsofstructureddata. InstructionPre-training[27]generatesinstruction-tuningdata
toaugmentpre-training.
Inthispaper,weforthefirsttimeconsiderutilizingclients’unstructureddataforFedITofLLMsby
leveragingtheLLMsfordatageneration. Weapplyfew-shotgenerationtechniqueforitssimplicity
andeffectiveness;whilewebelievethattherecouldbeothertechniquesappliedtoourscenario.
3 Methodology
Inthissection,wefirstintroducetheoverallframeworkofourproposedFedIT-U2S(Figure1),which
consistsoftwokeysteps: few-shotinstruction-tuningdatageneration(whichtransformsunstructured
dataintostructuredinstruction-tuningdatapairs)andfederatedinstructiontuningonthegenerated
data. Then,wedetailourdesignofretrieval-basedexampleselectionforfew-shotdatageneration.
3.1 PipelineofFedIT-U2S
AtthebeginningofFedIT-U2S,theserverfirstdistributesanopen-sourcedgeneralLLM(denoted
byθ∗)andasetofexamples(unstructuredandstructuredtextpairs,denotedbyO)toparticipating
clients.
Step1:few-shotinstruction-tuningdatageneration.SupposethereareM clientsinthesystemand
eachclientmholdsanunstructureddatasetDu ={d }Nm,whered isadatapieceandN denotes
m i i=1 i m
thenumberofdatapieces. Sincesuchunstructureddatacannotbedirectlyusedforinstructiontuning,
itconventionallyrequireseachclient’seffortstomanuallycreateinstruction-responsepairsfortuning,
whichiscostlyandfacesthechallengesofscalingup. Toaddressthis,wedesigntoautomatically
transform the unstructured data into a structured instruction-response format via a few-shot data
generationprocess,whichleveragesLLM’sin-contextlearningcapability[32].
Specifically,uponreceivingexamplesetO ={(d ,x ,y )}O ,whereOistheexamplenumber,d
i i i i=1 i
isanunstructureddatadocument,x andy isthedocument-groundedinstructionandresponsere-
i i
spectively,eachclientselectsseveral(denotedbyk)examplesasfew-shotexamplesprompttheLLM
θ∗. DenotetheinstructionforgenerationasI andtheselectedexamplesasS ={(dˆ,xˆ ,yˆ)}k ,
i i i i=1
givenauser’sdatapieced,thepromptP isconstructedas: P =Concat(I,S,d),whereConcat
3denotestheconcatenationoperation(seefullpromptinA).Notethattheseexamplescanbeeither
randomlyselectedfordiversityorselectedaccordingtorelatednessbetweenuserdataandexamples
forbetterdiversity-relatednesstrade-off,whichwillbedetailedinSection3.2. Basedontheprompt,
theLLMθ∗willgenerateaninstruction-responsepair: (x,y)=f(P;θ∗). Therefore,byiterating
onclient’sunstructureddatasetDu ={d }Nm,weobtainastructureddatasetforinstructiontuning:
m i i=1
Ds ={x ,y }Nm.
m i i i=1
SincetheresponsesofLLMsareinanopen-endedformandtherearerandomnessduringgeneration,
somegenerateddatamightfallshortintermsofdataquality. Therefore,additionaldatafilteringis
necessaryforenhancingthedataquality. Here,weconsidertwofilteringmechanisms: rule-based
filteringtoremovedatawithundesiredformatandreward-basedfilteringtoensurethequalityof
selected data. Specifically, we first filter out data that does not follow the format of instruction-
response pair. Secondly, we use an publicly available reward model to score the generated data
samplesandselectthetoptwo-thirdssamples. Thisenablesustoselectdatathatismorealigned
withhumanpreferencesincerewardmodelistrainedtomodelhumanpreference.
Step2: federatedinstructiontuningonthegenerateddata. Withthegenerateddata,atypical
process of federated instruction tuning is started. Considering computation and communication
efficiency,weapplyLoRA[19]astheparameter-efficientfine-tuningtechnique. SupposethereareT
roundsoffederatedlearningroundsintotal. Ateachroundt,theserversendsthemodelparameters
θt to each available client. Then, each client m initializes its local trainable parameters with θt,
keepsthebasemodelparametersθ∗fixed,andstartssupervisedfine-tuningonitsgenerateddataset
Ds ={x ,y }Nm,wherethemodellearnstopredicttheresponsey giventheinstructionx . By
m i i i=1 i i
fine-tuningforseveralsteps,eachclientmobtainsafine-tunedmodelparametersθt andsendsit
m
totheserver. Finally,theserveraggregatesmodelparametersofclientstoobtaintheglobalmodel
parametersforthenextround: θt+1 =(cid:80) mp mθ mt ,wherep m = (cid:80)N im Ni istherelativedatasetsizeof
clientm.
3.2 Retrieval-basedExampleSelectionforFew-ShotGeneration
The chosen examples (i.e., the context) in the prompt could significantly affect the behaviour of
LLMs [33, 34], resulting in different quality of the genrated data. Therefore, to generate high-
qualitystructureddata,selectingappropriatefew-shotexamplesisessential. Generally,examples
thatcloselymatchthetargettextintermsofcontentandstructuretendtoproducemoreeffective
results. However,inpracticalapplications,manuallyidentifyingsuitableexamplescanbeatime-
consumingprocess,makingitinflexibleinadaptingtodiversescenarios. Tomitigatethischallenge,
weproposearetrieval-basedexampleselectionmethodforfew-shotgenerationwhichautomatically
selectsfew-shotexamplesfromamixedexamplepoolaccordingtosimilaritybetweenuserdataand
examples.
GiventhesetofexamplessentfromtheserverO ={(d ,x ,y )}O ,eachclientaimstoselectk
i i i i=1
examplesforeachofitssampledunstructureddatapiece. Specifically,foreachdatapieced,we
compute the similarity Sim(d,d ) for each d in the example pool O using BERT Score as the
i i
metric, which gives a similarity score that reflects the relatedness between the target data piece
andtheexample’scontent. Subsequently,werankthesimilarityscoresandselecttop-kexamples
S = {(dˆ,xˆ ,yˆ)}k , which are mostly likely to guide the LLM to generate high-quality and
i i i i=1
highly-relateddata. TheotherproceduresremainunchangedasinSection3.1.
4 Experiments
4.1 ExperimentalDetails
Training Dataset. We consider three datasets for our experiments [27], which cover domains
includingmedicine,knowledge,andmath. Specifically,PubMedQA[35]isamedicaldatasetfor
biomedicalresearchquestionansweringwithcorrespondingabstractsasthecontext. HotpotQA[36]
isadatasetofWikipedia-basedquestionswithsupportingfactsasthecontext. AQUA_RAT[37]
isamathdatasetforalgebraicwordproblemsanswering. Theproblems,togetherwithsolutions,
formthecontext. Weselect10,000samplesfromeachdatasetfortheexperiments[27],witheach
samplecomprisingapieceoforiginalunstructuredtext,alongwithahumanannotatedinstruction
4PubMedQA HotpotQA AQUA_RAT
BERTScore ROUGE-L BERTScore ROUGE-L BERTScore ROUGE-L
BaseModel 0.1483 0.1496 0.0566 0.2380 -0.0171 0.1529
FedIT-U2S 0.1876 0.1727 0.1774 0.2942 0.0885 0.2383
FedIT-U2S(Filtered) 0.2043 0.1859 0.2439 0.3226 0.1131 0.2452
FedAvgonHumanData 0.2306 0.2017 0.2701 0.3531 0.1381 0.2890
Table 1: Experiments on three datasets: PubMedQA (medical), HotpotQA (knowledge), and
AQUA_RAT(math). OurproposedFedIT-U2Sconsistentlybringsperformnaceimprovementcom-
paredtobasemodel. FedIT-U2S(Filtered)hugelyfillsthegapbetweenbasemodelandFedAvgon
human-annotateddata,indicatingtheeffectivenessofourproposedmethodinbypassingmassive
humaneffortsinannotation.
andresponse,bothderivedfromthetext. OnlytheunstructuredtextisusedinourmethodFedIT-U2S,
whilethehumanannotatedinstruction-responsepairsareusedtoimplementFedAvgasareferenceto
verifytheeffectivenessofourmethod.
Implementation Details. Our implementation is based on the open-sourced codebase Open-
FedLLM* [12]. We use Vicuna-7B [38] as the base model and set the learning rate as 2e−5
withabatchsizeof16. Thecommunicationroundissetto200and2clientsaresampledoutof5
eachroundtoparticipatefederatedinstructiontuning. Weusereward-model-deberta-v3-large-v2as
therewardmodelfollowing[18]. Weselectk =3examplesforfew-shotgeneration.
EvaluationMetrics.(1)BERTScore:BERTScore [39]isanevaluationmetricfornaturallanguage
generationthatmeasuresthesimilaritybetweenacandidatesentenceandreferencesentencesby
leveragingcontextualembeddingsfrompre-trainedlanguagemodelslikeBERT.(2)ROUGE-L:
ROUGE-L[40]isanevaluationmetricusedforsummarizationandtextgenerationtasks,focusing
onthelongestcommonsubsequence(LCS)betweenacandidatesentenceandareferencesentence.
ROUGE-Levaluatestheextenttowhichthecandidatesentencepreservestheorderandcontentof
the reference, providing a more holistic assessment of the generated text’s quality. We select 50
samplesfromeachdatasettoserveasthetestset. Wecomparethemodel-generatedresponsestothe
goldstandardanswers(i.e.,human-annotatedanswersinthetestset)bycalculatingBERTScoreand
ROUGE-Ltoassessperformance.
ComparedLLMs. (1)ThebaseLLM,i.e.,theVicunamodelwithoutadditionaltuning;(2)thebase
LLMtunedviaFedAvgonhuman-annotateddata,whichservesasaperformancereference;(3)the
baseLLMtunedbyourFedIT-U2Swithoutfilteringtechnique;and(4)thebaseLLMtunedbyour
FedIT-U2Swithfilteringtechnique.
4.2 ExperimentalResults
Comparisonswithbaselines. InTable1,wecomparemodelstrainedviaourmethodsongenerated
datawithbasemodelandmodeltrainedviaFedAvg[10]onhuman-annotateddata(asareference).
Experimentsareconductedonthreedatasetsandevaluatedbytwometrics. Fromthetable,wesee
that(1)ourmethodsconsistentlyandsignificantlyimprovestheperformanceofthebasemodelacross
datasetsandevaluationmetrics,indicatingtheeffectivenessofourproposedmethods. Specifically,
in HotpotQA,our method canachieve 0.1873higher BERT Score(0.2439 v.s. 0.0566). (2) Our
methodshugelyfillthegapbetweenbasemodelandthattunedviaFedAvgonhumandata,further
verifyingFedIT-U2S’seffectiveness. However, thereisstillaroomforimprovement, callingfor
morefutureworkstofurtherenhancetheperformance. Withtheincreasinggenerationcapabilityof
LLMs[29,28],weevenbelievethatthereispotentialforsurpassingthisbaseline(FedAvgonhuman
data). (3)Althoughthedatafilteredusingtherewardmodelissmallerinquantity,itbringsamore
significantimprovementtothemodel’sperformance,indicatingtheimportanceofdataqualityinthis
scenario.
Analysisofexampleselectionforfew-shotgeneration. Theeffectivenessoffew-shotgeneration
mayheavilyrelyonthechosenexamplesinthecontext. Therefore, here, wedeeplyanalyzethe
exampleselectionbyconductingaseriesofexperimentsonHotpotQAdatasetsinceweobservea
*https://github.com/rui-ye/OpenFedLLM
5ExperimentalSetup BertScore ROUGE-L
BaseModel 0.0566 0.2380
①Random0+3(3out-domainexamples) 0.0868 0.2211
②Random1+2(1in-domainand2out-domainexamples) 0.1143 0.2426
③Fixed3+0(3fixedin-domainexamples) 0.1774 0.2942
④Random3+0(3randomlyselectedin-domainexamples) 0.2128 0.3054
⑤Retrieval-basedSelectionfromAMixedPool 0.2035 0.2994
Table2: ExperimentsonHotpotQAdatasetforanalysisofexampleselectionduringfew-shotdata
generation. Theresultsshowthatourproposedautomatedretrieval-basedselectiontechniquecan
achievescomparableperformancecomparedtoselectingin-domainexamples(whichrequiresprior
knowledge).
(a)PubMedQA (b)HotpotQA (c)AQUA_RAT
Figure 2: The t-SNE visualization of embeddings of instruction-response pairs in PubMedQA,
HotpotQAandAQUA_RAT.Bluedotsrepresentgenerateddata,whilereddotsrepresenthuman-
annotateddata. Thecloseproximityofeachpairofredandbluedotsindicatesthatthegenerated
datacloselyalignswiththehuman-annotateddata.
largeimprovementinpreviousexperiments. Inthisexperiment,theexamplepoolhas50samples
in total, covering five domains: medicine, math, knowledge, common sense, and daily life. We
considerthefollowingsetupsoffew-shotgenerationinourproposedFedIT-U2S:①Random0+3: 3
out-domainexamplesarerandomlyselected(e.g.,formedicaltask,examplesfromotherdomains
arerandomlyselected);②Random1+2: 1in-domainandtwoout-domainexamplesarerandomly
selected; ③ Fixed 3 + 0: 3 fixed in-domain examples are selected for all generation; ④ Random
3+0: 3in-domainexamplesarerandomlyselected;⑤Retrieval-basedSelection: 3examplesare
automaticallyselectedfromamixedexamplepoolbyourretrieval-basedexampleselectiontechnique.
TheexperimentalresultsareshowninTable2. (1)Comparedtothebasemodel,①,whichintroduces
out-domainexamplesforfew-shotgeneration,doesnotbringevidentimprovementwhile②-⑤all
bring consistent improvement. This indicates the importance of selecting appropriate examples
forfew-shotdatageneration. (2)Comparing①,②,and④,wecanseethatincreasingthenumber
ofin-domainexamplesconsistentlybringsmoreperformanceimprovement, indicatingthevalue
ofintroducingin-domainexamplestofacilitategeneration. (3)Comparing③and④,weseethat
randomlyselectingin-domainexamplesperformsbetterthanselectingfixedexamples,indicating
thevalueofexamplediversityingeneration. (4)Comparing④and⑤, weseethatourproposed
retrieval-based selection from a mixed pool performs comparably to selecting examples from a
in-domainpool(whichrequirespriorknowledge),indicatingtheeffectivenessofourretrieval-based
selectiontechnique. Thisresultsuggeststhatequippedwiththistechnique,ourproposedFedIT-U2S
frameworkcanbeautomaticallydeployedinvariousdomainswithoutmuchpriorknowledge.
Comparisons of generated and human-annotated data. To better understand our method, we
furtheranalyzethecharacteristicsofourgenerateddatabycomparingitwithhuman-annotateddata
fromtwoperspectives: embeddingvisualizationandcasestudies.
(1)Embeddingvisualization: Here,weuset-SNE[41]tovisualizethedatapointsofgeneratedand
human-annotateddata. Foreachdataset,200generatedandhuman-annotatedsamplepairs,sharing
thesamecontext,areselected. Theembeddingsoftheconcatenatedinstructionandresponsetexts
6Figure3: Exampleillustration.
areextractedviasentence-transformers† andmappedtoatwo-dimensionalspaceviat-SNE.The
final2DembeddingsareplottedasshowninFigure2,whereblueandreddotsrepresentgenerated
andhuman-annotateddatarespectively. Fromthefigure,weobservecloseproximitybetweenthe
generatedandhumandatapoints,indicatingahighdegreeofalignmentbetweenthegeneratedand
humandataacrossthedatasets.
(2)CaseStudy: InFigure3,weshowaspecificexampleofgenerateddatasamplefromPubMedQA.
Thehuman-annotateddatasamplewiththesamecontextisalsogivenforcomparison. Instructions
ofbothsamplesaskabouttheeffectivenessofHAinjectionsintreatingkneeOA.Thegenerated
responseconveysameaningsimilartohuman-annotatedresponsebasedonthecontext.
Thesetwoaspectsofcomparisondemonstratethatourgenerateddataishighlysimilartothemanually
annotateddatainbothcontentandstructure,reflectingthehighqualityofthegenerateddata.
5 Conclusions
ThispaperproposesFedIT-U2S,whichdirectlyleveragesclients’unstructuredtextdatatoachieve
federatedinstructiontuningoflargelanguagemodels. FedIT-U2Sconsistsoftwokeysteps: few-shot
instruction-tuningdatagenerationandfederatedinstructiontuningonthegenerateddata. Duringdata
generation,foreachunstructureddatapiece,aclientfirstlyselectsrelatedexamplesviaaretrieval-
basedexampleselectionmechanismandthenusestheseexamplesforguidingtheLLMtogenerate
instruction-responsepairbasedonthedatapiece. Atypicalprocessoffederatedinstructiontuningis
thenconductedbasedonthegenerateddata. Experimentsonthreedomains(medicine,knowledge,
andmath)verifytheeffectivenessofourproposedFedIT-U2S.Ourmethodforthefirsttimeenables
clientswithunstructureddatatobeinvolvedintheprocessoffederatedinstructiontuning,which
occupyalargeproportioninpracticeandareunderutilizedpreviously. Webelievethatthisworkcan
contributetobroadeningtheapplicationscopeoffederatedinstructiontuning.
†https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
7References
[1] OpenAI. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774,2023.
[2] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,
NikolayBashlykov,SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,etal. Llama2: Open
foundationandfine-tunedchatmodels. arXivpreprintarXiv:2307.09288,2023.
[3] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh
Chaplot,DiegodelasCasas,FlorianBressand,GiannaLengyel,GuillaumeLample,Lucile
Saulnier,etal. Mistral7b. arXivpreprintarXiv:2310.06825,2023.
[4] AnYang,BaosongYang,BinyuanHui,BoZheng,BowenYu,ChangZhou,ChengpengLi,
Chengyuan Li, Dayiheng Liu, Fei Huang, et al. Qwen2 technical report. arXiv preprint
arXiv:2407.10671,2024.
[5] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,
ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelsto
followinstructionswithhumanfeedback. NIPS,35:27730–27744,2022.
[6] JasonWei,MaartenBosma,VincentZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,
AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. InICLR,
2021.
[7] ChuntingZhou,PengfeiLiu,PuxinXu,SriniIyer,JiaoSun,YuningMao,XuezheMa,Avia
Efrat,PingYu,LiliYu,etal.Lima:Lessismoreforalignment.arXivpreprintarXiv:2305.11206,
2023.
[8] KaranSinghal,TaoTu,JurajGottweis,RorySayres,ElleryWulczyn,LeHou,KevinClark,
StephenPfohl,HeatherCole-Lewis,DarleneNeal,etal. Towardsexpert-levelmedicalquestion
answeringwithlargelanguagemodels. arXivpreprintarXiv:2305.09617,2023.
[9] ShijieWu, OzanIrsoy, StevenLu, VadimDabravolski, MarkDredze, SebastianGehrmann,
PrabhanjanKambadur,DavidRosenberg,andGideonMann. Bloomberggpt: Alargelanguage
modelforfinance. arXivpreprintarXiv:2303.17564,2023.
[10] BrendanMcMahan,EiderMoore,DanielRamage,SethHampson,andBlaiseAguerayArcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial
intelligenceandstatistics,pages1273–1282.PMLR,2017.
[11] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Ar-
junNitinBhagoji,KallistaBonawitz,ZacharyCharles,GrahamCormode,RachelCummings,
etal. Advancesandopenproblemsinfederatedlearning. FoundationsandTrends®inMachine
Learning,14(1–2):1–210,2021.
[12] RuiYe,WenhaoWang,JingyiChai,DihanLi,ZexiLi,YindaXu,YaxinDu,YanfengWang,
andSihengChen. Openfedllm: Traininglargelanguagemodelsondecentralizedprivatedata
viafederatedlearning. InProceedingsofthe30thACMSIGKDDConferenceonKnowledge
DiscoveryandDataMining,pages6137–6147,2024.
[13] RuiYe,RuiGe,XinyuZhu,JingyiChai,YaxinDu,YangLiu,YanfengWang,andSihengChen.
Fedllm-bench: Realisticbenchmarksforfederatedlearningoflargelanguagemodels. arXiv
preprintarXiv:2406.04845,2024.
[14] JianyiZhang, SaeedVahidian, MartinKuo, ChunyuanLi, RuiyiZhang, GuoyinWang, and
YiranChen. Towardsbuildingthefederatedgpt: Federatedinstructiontuning. arXivpreprint
arXiv:2305.05644,2023.
[15] FedMLInc. Federatedlearningonlargelanguagemodels(llms). https://doc.fedml.ai/
federate/fedllm,2023. Accessed: 2024-03-31.
[16] TaoFan,YanKang,GuoqiangMa,WeijingChen,WenbinWei,LixinFan,andQiangYang.
Fate-llm: Aindustrialgradefederatedlearningframeworkforlargelanguagemodels. arXiv
preprintarXiv:2310.10049,2023.
8[17] WeiruiKuang,BingchenQian,ZitaoLi,DaoyuanChen,DaweiGao,XuchenPan,Yuexiang
Xie,YaliangLi,BolinDing,andJingrenZhou. Federatedscope-llm: Acomprehensivepackage
forfine-tuninglargelanguagemodelsinfederatedlearning. arXivpreprintarXiv:2309.00363,
2023.
[18] Asaf Yehudai, Boaz Carmeli, Yosi Mass, Ofir Arviv, Nathaniel Mills, Assaf Toledo, Eyal
Shnarch,andLeshemChoshen. Genie: Achievinghumanparityincontent-groundeddatasets
generation,2024.
[19] EdwardJHu,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,Weizhu
Chen,etal. Lora: Low-rankadaptationoflargelanguagemodels. InICLR,2021.
[20] AndrewHard,KanishkaRao,RajivMathews,SwaroopRamaswamy,FrançoiseBeaufays,Sean
Augenstein,HubertEichner,ChloéKiddon,andDanielRamage. Federatedlearningformobile
keyboardprediction. arXivpreprintarXiv:1811.03604,2018.
[21] PabloVillalobos,JaimeSevilla,LennartHeim,TamayBesiroglu,MariusHobbhahn,andAnson
Ho. Willwerunoutofdata? ananalysisofthelimitsofscalingdatasetsinmachinelearning.
arXivpreprintarXiv:2211.04325,2022.
[22] LiamCollins,ShanshanWu,SewoongOh,andKheChaiSim. Profit: Benchmarkingperson-
alizationandrobustnesstrade-offinfederatedprompttuning. InInternationalWorkshopon
FederatedLearningintheAgeofFoundationModelsinConjunctionwithNeurIPS2023,2023.
[23] RuiYe,JingyiChai,XiangruiLiu,YaodongYang,YanfengWang,andSihengChen. Emerging
safety attack and defense in federated instruction tuning of large language models. arXiv
preprintarXiv:2406.10630,2024.
[24] YoubangSun,ZitaoLi,YaliangLi,andBolinDing. ImprovingloRAinprivacy-preserving
federatedlearning. InTheTwelfthInternationalConferenceonLearningRepresentations,2024.
[25] YaeJeeCho,LuyangLiu,ZhengXu,AldiFahrezi,MattBarnes,andGauriJoshi.Heterogeneous
loraforfederatedfine-tuningofon-devicefoundationmodels. InInternationalWorkshopon
FederatedLearningintheAgeofFoundationModelsinConjunctionwithNeurIPS2023,2023.
[26] CanXu,QingfengSun,KaiZheng,XiuboGeng,PuZhao,JiazhanFeng,ChongyangTao,and
DaxinJiang. Wizardlm: Empoweringlargelanguagemodelstofollowcomplexinstructions.
arXivpreprintarXiv:2304.12244,2023.
[27] DaixuanCheng,YuxianGu,ShaohanHuang,JunyuBi,MinlieHuang,andFuruWei.Instruction
pre-training: Languagemodelsaresupervisedmultitasklearners,2024.
[28] BoAdler,NiketAgarwal,AshwathAithal,DongHAnh,PallabBhattacharya,AnnikaBrundyn,
JaredCasper,BryanCatanzaro,SharonClay,JonathanCohen,etal. Nemotron-4340btechnical
report. arXivpreprintarXiv:2406.11704,2024.
[29] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,
AieshaLetman,AkhilMathur,AlanSchelten,AmyYang,AngelaFan,etal. Thellama3herd
ofmodels. arXivpreprintarXiv:2407.21783,2024.
[30] YizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,NoahASmith,DanielKhashabi,
andHannanehHajishirzi. Self-instruct: Aligninglanguagemodelwithselfgeneratedinstruc-
tions. arXivpreprintarXiv:2212.10560,2022.
[31] XianghePang,ShuoTang,RuiYe,YuxinXiong,BolunZhang,YanfengWang,andSihengChen.
Self-alignmentoflargelanguagemodelsviamonopolylogue-basedsocialscenesimulation. In
Forty-firstInternationalConferenceonMachineLearning,2024.
[32] TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,
ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,Ariel
Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.
Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz
Litwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,Alec
Radford,IlyaSutskever,andDarioAmodei. Languagemodelsarefew-shotlearners,2020.
9[33] TomBBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,
ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal. Languagemodelsare
few-shotlearners. InProceedingsofthe34thInternationalConferenceonNeuralInformation
ProcessingSystems,pages1877–1901,2020.
[34] QingxiuDong,LeiLi,DamaiDai,CeZheng,ZhiyongWu,BaobaoChang,XuSun,Jingjing
Xu,andZhifangSui. Asurveyforin-contextlearning. arXivpreprintarXiv:2301.00234,2022.
[35] QiaoJin,BhuwanDhingra,ZhengpingLiu,WilliamW.Cohen,andXinghuaLu. Pubmedqa: A
datasetforbiomedicalresearchquestionanswering,2019.
[36] ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,WilliamW.Cohen,RuslanSalakhut-
dinov,andChristopherD.Manning. Hotpotqa: Adatasetfordiverse,explainablemulti-hop
questionanswering,2018.
[37] WangLing,DaniYogatama,ChrisDyer,andPhilBlunsom. Programinductionbyrationale
generation: Learningtosolveandexplainalgebraicwordproblems,2017.
[38] Wei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,
SiyuanZhuang,YonghaoZhuang,JosephEGonzalez,etal. Vicuna: Anopen-sourcechatbot
impressinggpt-4with90%*chatgptquality. Seehttps://vicuna.lmsys.org(accessed14April
2023),2023.
[39] TianyiZhang,VarshaKishore,FelixWu,KilianQ.Weinberger,andYoavArtzi. Bertscore:
Evaluatingtextgenerationwithbert,2020.
[40] Chin-YewLin. ROUGE:Apackageforautomaticevaluationofsummaries. InTextSummariza-
tionBranchesOut,pages74–81,Barcelona,Spain,July2004.AssociationforComputational
Linguistics.
[41] LaurensVanderMaatenandGeoffreyHinton. Visualizingdatausingt-sne. Journalofmachine
learningresearch,9(11),2008.
10A Appendix
Listing1: Few-shotprompttemplate
Given the next [document], create a [question] and [answer] pair that
are grounded in the main point of the document, don’t add any
additional information that is not in the document. The [question] is
by an information-seeking user and the [answer] is provided by a
helping AI Agent.
[document]: {The content of document 1}
### Response:
[question]: {The content of question 1}
[answer]: {The content of answer 1}
[document]: {The content of document 2}
### Response:
[question]: {The content of question 2}
[answer]: {The content of answer 2}
[document]: {The content document 3}
### Response:
[question]: {The content of question 3}
[answer]: {The content of answer 3}
[document]: {The content of the target text}
### Response:
11