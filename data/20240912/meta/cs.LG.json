[
    {
        "title": "Introducing Perturb-ability Score (PS) to Enhance Robustness Against Evasion Adversarial Attacks on ML-NIDS",
        "authors": "Mohamed elShehabyAshraf Matrawy",
        "links": "http://arxiv.org/abs/2409.07448v1",
        "entry_id": "http://arxiv.org/abs/2409.07448v1",
        "pdf_url": "http://arxiv.org/pdf/2409.07448v1",
        "summary": "This paper proposes a novel Perturb-ability Score (PS) that can be used to\nidentify Network Intrusion Detection Systems (NIDS) features that can be easily\nmanipulated by attackers in the problem-space. We demonstrate that using PS to\nselect only non-perturb-able features for ML-based NIDS maintains detection\nperformance while enhancing robustness against adversarial attacks.",
        "updated": "2024-09-11 17:52:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.07448v1"
    },
    {
        "title": "Adaptive Adapter Routing for Long-Tailed Class-Incremental Learning",
        "authors": "Zhi-Hong QiDa-Wei ZhouYiran YaoHan-Jia YeDe-Chuan Zhan",
        "links": "http://arxiv.org/abs/2409.07446v1",
        "entry_id": "http://arxiv.org/abs/2409.07446v1",
        "pdf_url": "http://arxiv.org/pdf/2409.07446v1",
        "summary": "In our ever-evolving world, new data exhibits a long-tailed distribution,\nsuch as e-commerce platform reviews. This necessitates continuous model\nlearning imbalanced data without forgetting, addressing the challenge of\nlong-tailed class-incremental learning (LTCIL). Existing methods often rely on\nretraining linear classifiers with former data, which is impractical in\nreal-world settings. In this paper, we harness the potent representation\ncapabilities of pre-trained models and introduce AdaPtive Adapter RouTing\n(APART) as an exemplar-free solution for LTCIL. To counteract forgetting, we\ntrain inserted adapters with frozen pre-trained weights for deeper adaptation\nand maintain a pool of adapters for selection during sequential model updates.\nAdditionally, we present an auxiliary adapter pool designed for effective\ngeneralization, especially on minority classes. Adaptive instance routing\nacross these pools captures crucial correlations, facilitating a comprehensive\nrepresentation of all classes. Consequently, APART tackles the imbalance\nproblem as well as catastrophic forgetting in a unified framework. Extensive\nbenchmark experiments validate the effectiveness of APART. Code is available\nat: https://github.com/vita-qzh/APART",
        "updated": "2024-09-11 17:52:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.07446v1"
    },
    {
        "title": "Asymptotics of Stochastic Gradient Descent with Dropout Regularization in Linear Models",
        "authors": "Jiaqi LiJohannes Schmidt-HieberWei Biao Wu",
        "links": "http://arxiv.org/abs/2409.07434v1",
        "entry_id": "http://arxiv.org/abs/2409.07434v1",
        "pdf_url": "http://arxiv.org/pdf/2409.07434v1",
        "summary": "This paper proposes an asymptotic theory for online inference of the\nstochastic gradient descent (SGD) iterates with dropout regularization in\nlinear regression. Specifically, we establish the geometric-moment contraction\n(GMC) for constant step-size SGD dropout iterates to show the existence of a\nunique stationary distribution of the dropout recursive function. By the GMC\nproperty, we provide quenched central limit theorems (CLT) for the difference\nbetween dropout and $\\ell^2$-regularized iterates, regardless of\ninitialization. The CLT for the difference between the Ruppert-Polyak averaged\nSGD (ASGD) with dropout and $\\ell^2$-regularized iterates is also presented.\nBased on these asymptotic normality results, we further introduce an online\nestimator for the long-run covariance matrix of ASGD dropout to facilitate\ninference in a recursive manner with efficiency in computational time and\nmemory. The numerical experiments demonstrate that for sufficiently large\nsamples, the proposed confidence intervals for ASGD with dropout nearly achieve\nthe nominal coverage probability.",
        "updated": "2024-09-11 17:28:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.07434v1"
    },
    {
        "title": "Synthetic continued pretraining",
        "authors": "Zitong YangNeil BandShuangping LiEmmanuel CandèsTatsunori Hashimoto",
        "links": "http://arxiv.org/abs/2409.07431v1",
        "entry_id": "http://arxiv.org/abs/2409.07431v1",
        "pdf_url": "http://arxiv.org/pdf/2409.07431v1",
        "summary": "Pretraining on large-scale, unstructured internet text has enabled language\nmodels to acquire a significant amount of world knowledge. However, this\nknowledge acquisition is data-inefficient -- to learn a given fact, models must\nbe trained on hundreds to thousands of diverse representations of it. This\nposes a challenge when adapting a pretrained model to a small corpus of\ndomain-specific documents, where each fact may appear rarely or only once. We\npropose to bridge this gap with synthetic continued pretraining: using the\nsmall domain-specific corpus to synthesize a large corpus more amenable to\nlearning, and then performing continued pretraining on the synthesized corpus.\nWe instantiate this proposal with EntiGraph, a synthetic data augmentation\nalgorithm that extracts salient entities from the source documents and then\ngenerates diverse text by drawing connections between the sampled entities.\nSynthetic continued pretraining using EntiGraph enables a language model to\nanswer questions and follow generic instructions related to the source\ndocuments without access to them. If instead, the source documents are\navailable at inference time, we show that the knowledge acquired through our\napproach compounds with retrieval-augmented generation. To better understand\nthese results, we build a simple mathematical model of EntiGraph, and show how\nsynthetic data augmentation can \"rearrange\" knowledge to enable more\ndata-efficient learning.",
        "updated": "2024-09-11 17:21:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.07431v1"
    },
    {
        "title": "Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation",
        "authors": "Gavin ButtsPegah EmdadJethro LeeShannon SongChiman SalavatiWillmar Sosa DiazShiri Dori-HacohenFabricio Murai",
        "links": "http://arxiv.org/abs/2409.07424v1",
        "entry_id": "http://arxiv.org/abs/2409.07424v1",
        "pdf_url": "http://arxiv.org/pdf/2409.07424v1",
        "summary": "There have been growing concerns around high-stake applications that rely on\nmodels trained with biased data, which consequently produce biased predictions,\noften harming the most vulnerable. In particular, biased medical data could\ncause health-related applications and recommender systems to create outputs\nthat jeopardize patient care and widen disparities in health outcomes. A recent\nframework titled Fairness via AI posits that, instead of attempting to correct\nmodel biases, researchers must focus on their root causes by using AI to debias\ndata. Inspired by this framework, we tackle bias detection in medical curricula\nusing NLP models, including LLMs, and evaluate them on a gold standard dataset\ncontaining 4,105 excerpts annotated by medical experts for bias from a large\ncorpus. We build on previous work by coauthors which augments the set of\nnegative samples with non-annotated text containing social identifier terms.\nHowever, some of these terms, especially those related to race and ethnicity,\ncan carry different meanings (e.g., \"white matter of spinal cord\"). To address\nthis issue, we propose the use of Word Sense Disambiguation models to refine\ndataset quality by removing irrelevant sentences. We then evaluate fine-tuned\nvariations of BERT models as well as GPT models with zero- and few-shot\nprompting. We found LLMs, considered SOTA on many NLP tasks, unsuitable for\nbias detection, while fine-tuned BERT models generally perform well across all\nevaluated metrics.",
        "updated": "2024-09-11 17:10:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.07424v1"
    }
]