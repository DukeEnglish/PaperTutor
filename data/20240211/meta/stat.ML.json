[
    {
        "title": "Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss",
        "authors": "Ingvar ZiemannStephen TuGeorge J. PappasNikolai Matni",
        "links": "http://arxiv.org/abs/2402.05928v1",
        "entry_id": "http://arxiv.org/abs/2402.05928v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05928v1",
        "summary": "In this work, we study statistical learning with dependent ($\\beta$-mixing)\ndata and square loss in a hypothesis class $\\mathscr{F}\\subset L_{\\Psi_p}$\nwhere $\\Psi_p$ is the norm $\\|f\\|_{\\Psi_p} \\triangleq \\sup_{m\\geq 1} m^{-1/p}\n\\|f\\|_{L^m} $ for some $p\\in [2,\\infty]$. Our inquiry is motivated by the\nsearch for a sharp noise interaction term, or variance proxy, in learning with\ndependent data. Absent any realizability assumption, typical non-asymptotic\nresults exhibit variance proxies that are deflated \\emph{multiplicatively} by\nthe mixing time of the underlying covariates process. We show that whenever the\ntopologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class\n$\\mathscr{F}$ -- that is, $\\mathscr{F}$ is a weakly sub-Gaussian class:\n$\\|f\\|_{\\Psi_p} \\lesssim \\|f\\|_{L^2}^\\eta$ for some $\\eta\\in (0,1]$ -- the\nempirical risk minimizer achieves a rate that only depends on the complexity of\nthe class and second order statistics in its leading term. Our result holds\nwhether the problem is realizable or not and we refer to this as a \\emph{near\nmixing-free rate}, since direct dependence on mixing is relegated to an\nadditive higher order term. We arrive at our result by combining the above\nnotion of a weakly sub-Gaussian class with mixed tail generic chaining. This\ncombination allows us to compute sharp, instance-optimal rates for a wide range\nof problems. %Our approach, reliant on mixed tail generic chaining, allows us\nto obtain sharp, instance-optimal rates. Examples that satisfy our framework\ninclude sub-Gaussian linear regression, more general smoothly parameterized\nfunction classes, finite hypothesis classes, and bounded smoothness classes.",
        "updated": "2024-02-08 18:57:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05928v1"
    },
    {
        "title": "Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm Identification in Structured Bandits",
        "authors": "Nicolas NguyenImad AoualiAndrás GyörgyClaire Vernade",
        "links": "http://arxiv.org/abs/2402.05878v1",
        "entry_id": "http://arxiv.org/abs/2402.05878v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05878v1",
        "summary": "We study the problem of Bayesian fixed-budget best-arm identification (BAI)\nin structured bandits. We propose an algorithm that uses fixed allocations\nbased on the prior information and the structure of the environment. We provide\ntheoretical bounds on its performance across diverse models, including the\nfirst prior-dependent upper bounds for linear and hierarchical BAI. Our key\ncontribution is introducing new proof methods that result in tighter bounds for\nmulti-armed BAI compared to existing methods. We extensively compare our\napproach to other fixed-budget BAI methods, demonstrating its consistent and\nrobust performance in various settings. Our work improves our understanding of\nBayesian fixed-budget BAI in structured bandits and highlights the\neffectiveness of our approach in practical scenarios.",
        "updated": "2024-02-08 18:13:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05878v1"
    },
    {
        "title": "Federated Offline Reinforcement Learning: Collaborative Single-Policy Coverage Suffices",
        "authors": "Jiin WooLaixi ShiGauri JoshiYuejie Chi",
        "links": "http://arxiv.org/abs/2402.05876v1",
        "entry_id": "http://arxiv.org/abs/2402.05876v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05876v1",
        "summary": "Offline reinforcement learning (RL), which seeks to learn an optimal policy\nusing offline data, has garnered significant interest due to its potential in\ncritical applications where online data collection is infeasible or expensive.\nThis work explores the benefit of federated learning for offline RL, aiming at\ncollaboratively leveraging offline datasets at multiple agents. Focusing on\nfinite-horizon episodic tabular Markov decision processes (MDPs), we design\nFedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for\nfederated offline RL. FedLCB-Q updates local Q-functions at agents with novel\nlearning rate schedules and aggregates them at a central server using\nimportance averaging and a carefully designed pessimistic penalty term. Our\nsample complexity analysis reveals that, with appropriately chosen parameters\nand synchronization schedules, FedLCB-Q achieves linear speedup in terms of the\nnumber of agents without requiring high-quality datasets at individual agents,\nas long as the local datasets collectively cover the state-action space visited\nby the optimal policy, highlighting the power of collaboration in the federated\nsetting. In fact, the sample complexity almost matches that of the single-agent\ncounterpart, as if all the data are stored at a central location, up to\npolynomial factors of the horizon length. Furthermore, FedLCB-Q is\ncommunication-efficient, where the number of communication rounds is only\nlinear with respect to the horizon length up to logarithmic factors.",
        "updated": "2024-02-08 18:09:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05876v1"
    },
    {
        "title": "Let Your Graph Do the Talking: Encoding Structured Data for LLMs",
        "authors": "Bryan PerozziBahare FatemiDustin ZelleAnton TsitsulinMehran KazemiRami Al-RfouJonathan Halcrow",
        "links": "http://arxiv.org/abs/2402.05862v1",
        "entry_id": "http://arxiv.org/abs/2402.05862v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05862v1",
        "summary": "How can we best encode structured data into sequential form for use in large\nlanguage models (LLMs)? In this work, we introduce a parameter-efficient method\nto explicitly represent structured data for LLMs. Our method, GraphToken,\nlearns an encoding function to extend prompts with explicit structured\ninformation. Unlike other work which focuses on limited domains (e.g. knowledge\ngraph representation), our work is the first effort focused on the general\nencoding of structured data to be used for various reasoning tasks. We show\nthat explicitly representing the graph structure allows significant\nimprovements to graph reasoning tasks. Specifically, we see across the board\nimprovements - up to 73% points - on node, edge and, graph-level tasks from the\nGraphQA benchmark.",
        "updated": "2024-02-08 17:51:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05862v1"
    },
    {
        "title": "How Much is Unseen Depends Chiefly on Information About the Seen",
        "authors": "Seongmin LeeMarcel Böhme",
        "links": "http://arxiv.org/abs/2402.05835v1",
        "entry_id": "http://arxiv.org/abs/2402.05835v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05835v1",
        "summary": "It might seem counter-intuitive at first: We find that, in expectation, the\nproportion of data points in an unknown population-that belong to classes that\ndo not appear in the training data-is almost entirely determined by the number\n$f_k$ of classes that do appear in the training data the same number of times.\nWhile in theory we show that the difference of the induced estimator decays\nexponentially in the size of the sample, in practice the high variance prevents\nus from using it directly for an estimator of the sample coverage. However, our\nprecise characterization of the dependency between $f_k$'s induces a large\nsearch space of different representations of the expected value, which can be\ndeterministically instantiated as estimators. Hence, we turn to optimization\nand develop a genetic algorithm that, given only the sample, searches for an\nestimator with minimal mean-squared error (MSE). In our experiments, our\ngenetic algorithm discovers estimators that have a substantially smaller MSE\nthan the state-of-the-art Good-Turing estimator. This holds for over 96% of\nruns when there are at least as many samples as classes. Our estimators' MSE is\nroughly 80% of the Good-Turing estimator's.",
        "updated": "2024-02-08 17:12:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05835v1"
    }
]