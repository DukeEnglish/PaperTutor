Progressive Entropic Optimal Transport Solvers
ParnianKassraie Aram-AlexandrePooladian MichalKlein
ETHZurich,Apple NewYorkUniversity Apple
pkassraie@ethz.ch aram-alexandre.pooladian@nyu.edu michalk@apple.com
JamesThornton JonathanNiles-Weed MarcoCuturi
Apple NewYorkUniversity Apple
james_thornton2@apple.com jnw@cims.nyu.edu cuturi@apple.com
Abstract
Optimaltransport(OT)hasprofoundlyimpactedmachinelearningbyprovidingthe-
oreticalandcomputationaltoolstorealigndatasets. Inthiscontext,giventwolarge
pointcloudsofsizesnandminRd,entropicOT(EOT)solvershaveemergedasthe
mostreliabletooltoeithersolvetheKantorovitchproblemandoutputan mcou-
×
plingmatrix,ortosolvetheMongeproblemandlearnavector-valuedpush-forward
map. WhiletherobustnessofEOTcouplings/mapsmakesthemago-tochoicein
practicalapplications,EOTsolversremaindifficulttotunebecauseofasmallbut
influentialsetofhyperparameters,notablytheomnipresententropicregularization
strengthε. Settingεcanbedifficult,asitsimultaneouslyimpactsvariousperfor-
mancemetrics,suchascomputespeed,statisticalperformance,generalization,and
bias. Inthiswork,weproposeanewclassofEOTsolvers(PROGOT),thatcanesti-
matebothplansandtransportmaps. Wetakeadvantageofseveralopportunitiesto
optimizethecomputationofEOTsolutionsbydividingmassdisplacementusinga
timediscretization,borrowinginspirationfromdynamicOTformulations[McCann,
1997], and conquering each of these steps using EOT with properly scheduled
parameters. WeprovideexperimentalevidencedemonstratingthatPROGOTisa
fasterandmorerobustalternativetoEOTsolverswhencomputingcouplingsand
mapsatlargescales,evenoutperformingneuralnetwork-basedapproaches. We
alsoprovethestatisticalconsistencyofPROGOTwhenestimatingOTmaps.
1 Introduction
Manyproblemsingenerativemachinelearningandnaturalsciences—notablybiology[Schiebinger
etal.,2019,Bunneetal.,2023],astronomy[Métivieretal.,2016]orquantumchemistry[Buttazzo
et al., 2012]—require aligning datasets or learning to map data points from a source to a target
distribution. Theseproblemsstandatthecoreofoptimaltransporttheory[Santambrogio,2015]and
havespurredtheproposalofvarioussolvers[Peyréetal.,2019]toperformthesetasksreliably. In
thesetasks,wearegivennandmpointsrespectivelysampledfromsourceandtargetprobability
distributionsonRd,withthegoalofeitherreturningacouplingmatrixofsizen m(whichsolves
×
theso-calledKantorovitchproblem),oravector-valuedmapestimatorthatextendstoout-of-sample
data(solvingtheMongeproblem).
Inmodernapplications,wheren,m≳104,apopularapproachtoestimatingeithercouplingormaps
istorelyonaregularizationoftheoriginalKantorovitchlinearOTformulationusingneg-entropy.
Thistechnique,referredtoasentropicOT,canbetracedbacktoSchrödingerandwaspopularized
for ML applications in [Cuturi, 2013] (see Section 2). Crucially, EOT can be solved efficiently
withSinkhorn’salgorithm(Algorithm1),withfavorablecomputational[Altschuleretal.,2017,Lin
etal.,2022]andstatisticalproperties[Genevay,2019,MenaandNiles-Weed,2019]comparedto
linearprograms. MostcouplingscomputednowadaysonlargepointcloudswithinMLapplications
Preprint.
4202
nuJ
7
]LM.tats[
1v16050.6042:viXraEOT Debiased EOT ProgOT
x x y Transported(x ) x
train test train test interpolate
Figure 1: (left) EOT solvers collapse when the value of ε is not properly chosen. This typically
resultsinbiasedmapestimatorsandinblurrycouplings(seeFig.2forthecouplingmatrixobtained
betweenx andy ). (middle)DebiasingtheoutputofEOTsolverscanpreventacollapsetothe
train train
meanseeninEOTestimators,butcomputesthesamecoupling. PROGOT(right)amelioratesthese
problemsinvariousways: bydecomposingtheresolutionoftheOTproblemintomultipletimesteps,
andusingvariousformsofprogressivescheduling,werecoverbothacouplingwhoseentropycanbe
tunedautomaticallyandamapestimatorthatisfastandreliable.
areobtainedusingEOTsolversthatrelyonvariantsoftheSinkhornalgorithm,whetherexplicitly,
orasalower-levelsubroutine[Scetbonetal.,2021,2022]. ThewidespreadadoptionofEOThas
spurredmanymodificationsofSinkhorn’soriginalalgorithm(e.g.,throughacceleration[Thibault
etal.,2021]orinitialization[ThorntonandCuturi,2023]),andencourageditsincorporationwithin
neural-networkOTapproaches[Pooladianetal.,2023,Tongetal.,2023,UsciddaandCuturi,2023].
Thoughincrediblypopular,Sinkhorn’salgorithmis EOT ProgOT
notwithoutitsdrawbacks. Whileapopulartooldue
itsscalabilityandsimplicity,itsnumericalbehavior
is deeply impacted by the amount of neg-entropy
regularization,drivenbythehyperparameterε. Some
practitioners suggest to have the parameter nearly
vanish [Xie et al., 2020, Schmitzer, 2019], others
consider the case where it diverges, highlighting
linkswiththemaximummeandiscrepancy[Ramdas
etal.,2017,Genevayetal.,2019]. 0.0000 0.0001 0.0002 0.0003 0.0004
Figure 2: Coupling matrices between train
Several years after its introduction to the machine
pointsinFig.1. ComparisonofEOTwitha
learning community [Cuturi, 2013], choosing a
suitable regularization term for EOT remains a
fairlylargeε,andPROGOTwhichautomati-
callytunestheentropyofitscouplingaccord-
thornypainpoint. Commonapproachesaresetting
ingtothetargetpointcloud’sdispersion.
ε > 0 to a default value (e.g., the max [Flamary
etal.,2021]ormean[Cuturietal.,2022b]normalizationofthetransportcostmatrix),incorporating
aformofcross-validationoranunsupervisedcriterion[VacherandVialard,2022,VanAsseletal.,
2023], or scheduling ε [Lehmann et al., 2022, Feydy, 2020]. When ε is too large, the algorithm
convergesquickly,butyieldsseverelybiasedmaps(Figure1,left),orblurry,uninformativecouplings
(Figure2). EventheoreticallyandnumericallydebiasingtheSinkhornsolver(Figure1,middle)does
notseemtofullyresolvetheissue[Feydyetal.,2019,Pooladianetal.,2022]. Toconclude,while
strategiesexisttoalleviatethisbias,therecurrentlyexistsnoone-size-fits-allsolutiontothisproblem.
Ourcontribution: anEOTsolverwithadynamiclens. Recentyearshavewitnessedanexplosion
inneural-networkapproachesbasedontheso-called BenamouandBrenierdynamicformulation
ofOT[Lipmanetal.,2022,Liu,2022,Tongetal.,2023,Pooladianetal.,2023]. Abenefitofthis
perspectiveistheabilitytosplittheOTproblemintosimplersub-problemsthatarelikelybetter
conditionedthantheinitialtransportproblem. Withthisobservation,weproposeanovelfamilyof
progressiveEOTsolvers,calledPROGOT,thataremeanttobesturdierandeasiertoparameterizethan
existingsolvers. Ourkeyideaistoexploitthedynamicnatureoftheproblem,andvaryparameters
dynamically,suchasεandconvergencethresholds,alongthetransport. WeshowthatPROGOT
• canbeusedtorecoverbothKantorovitchcouplingsandMongemapestimators,
• strikestherightbalancebetweencomputationalandstatisticaltradeoffs,
• canoutperformother(includingneural-networkbased)approachesonrealdatasets,
• givesrisetoanovel,provablystatisticallyconsistentmapestimatorunderstandardassumptions.
22 Background
Optimaltransport. FordomainΩ Rd,let (Ω)denotethespaceofprobabilitymeasuresover
2
⊆ P
Ω with a finite second moment, and let (Ω) be those with densities. Let µ,ν (Ω), and
2,ac 2
P ∈ P
letΓ(µ,ν)bethesetofjointprobabilitymeasureswithleft-marginalµandright-marginalν. We
consideratranslationinvariantcostfunctionc(x,y):=h(x y),withhastrictlyconvexfunction,
−
anddefinetheWassersteindistance,parameterizedbyh,betweenµandν
(cid:90)(cid:90)
W(µ,ν):= inf h(x y)dπ(x,y). (1)
π∈Γ(µ,ν) −
ThisformulationisduetoKantorovitch[1942],andwecalltheminimizersto(1)OTcouplingsor
OTplans,anddenoteitasπ . Asubclassofcouplingsarethoseinducedbypushforwardmaps. We
0
saythatT :Rd Rd pushesµforwardtoν ifT(X) ν forX µ,andwriteT µ=ν. Given
#
→ ∼ ∼
achoiceofcost,wecandefinetheMonge[1781]formulationofOT
(cid:90)
T := argmin h(x T(x))dµ(x) (2)
0
−
T:T#µ=ν
wheretheminimizersarereferredtoasMongemaps,orOTmapsfromµtoν. UnlikeOTcouplings,
OTmapsarenotalwaysguaranteedtoexist. Though,ifµhasadensity,weobtainsignificantlymore
structureontheOTmap:
Theorem1(Brenier’sTheorem[1991]). Supposeµ (Ω)andν (Ω). Thenthereexistsa
2,ac 2
uniquesolutionto(2)thatisoftheformT =Id
∈ h∗P
f
,whereh∈∗P
istheconvex-conjugateof
0 0
h,i.e. h∗(y):=max x,y h(x),and −∇ ◦∇
x
⟨ ⟩−
(cid:90) (cid:90)
(f ,g ) argmax fdµ+ gdν, (3)
0 0
∈
(f,g)∈F
where := (f,g) L1(µ) L1(ν): f(x)+g(y) h(x y), x,y Ω. . Moreover,theOT
F { ∈ × ≤ − ∀ ∈ }
planisgivenbyπ (dx,dy)=δ (y)µ(dx).
0 T0(x)
Importantly, (3) is the dual problem to (1) and the pair of functions (f ,g ) are referred to as
0 0
the optimal Kantorovich potentials. Lastly, we recall the notion of geodesics with respect to the
Wassersteindistance. Forapairofmeasuresµandν withOTmapT ,theMcCanninterpolation
0
betweenµandν isdefinedas
µ :=((1 α)Id+αT ) µ, (4)
α 0 #
−
whereα [0,1]. Equivalently,µ isthelawofX =(1 α)X+αT (X),whereX µ. Inthe
α α 0
casewhe∈
reh=
pforp>1,theMcCanninterpolatio− nisinfactageodesicintheW∼
asserstein
∥·∥
space[Ambrosioetal.,2005]. Whilethisequivalencemaynotholdforgeneralcosts,theMcCann
interpolationstillprovidesanaturalpathofmeasuresbetweenµandν [Liu,2022].
EntropicOT. Entropicregularizationhasbe- Algorithm1SINK(a,X,b,Y,ε,τ,f init,g init).
come the de-facto approach to estimate all
three variables π , f and T using samples 1: f,g f init,g init(zerobydefault)
0 0 0 ←
(x ,...,x )and(y ,...,y ),bothweighted 2: x 1,...,x n =X, y 1,...,y m =Y
1 n 1 m
by a probability weight vectors a Rn,b 3: C [h(x i y j)] ij
R µˆm + =su (cid:80)mm ning
a
δto 1 a, ndto νˆfor =m (cid:80)ap mpr∈ ox bim+ δati .on A∈ s 4: wh← ile ∥exp−(cid:16) C− εf⊕g(cid:17) 1 m −a ∥1 <τ do
con mmonfi o= r1 mui lax tii onofthm eEOTpi r= o1 blej my ij
sthe
5: f ←εloga −min ε(C −f ⊕g)+f
6: g εlogb min (C⊤ g f)+g
followingε-stronglyconcaveprogram: ← − ε − ⊕
7: endwhile
f⋆,g⋆ = argmax f,a + g,b 8: returnf,g,P=exp((C f g)/ε)
f∈Rn,g∈Rm⟨ ⟩ ⟨ ⟩ − ⊕
ε ef/ε,Keg/ε , (5)
− ⟨ ⟩
whereε > 0andK = [exp( (x y )/ε)] Rn×m. Wecanverifythat(5)isaregularized
i,j − i − j i,j ∈ +
versionof(3)whenappliedtoempiricalmeasures[Peyréetal.,2019,Proposition4.4]. Sinkhorn’s
algorithmpresentsaniterativeschemeforobtaining(f⋆,g⋆),andwerecallitinAlgorithm1,where
foramatrixS=[S i,j]weusethenotationmin ε(S):=[
εlog(cid:0) 1⊤e−Si,·/ε(cid:1)
] i,and isthetensor
− ⊕
3sumoftwovectors, i.e. f g := [f +g ] .Notethatsolving(5)alsooutputsavalidcoupling
i j ij
P⋆ =K exp( (f⋆+g⊕⋆)/ε),whichapproximatelysolvesthefinite-samplecounterpartof(1).
i,j i,j − i j
Additionally,theoptimalpotentialf canbeapproximatedbytheentropicpotential
0
fˆ(x):=min ([g⋆ h(x y )] ), (6)
ε ε j − − j j
whereananalogousexpressioncanbewrittenforgˆ intermsoff⋆. Usingtheentropicpotential,
ε
wecanalsoapproximatetheoptimaltransportmapT bytheentropicmap
0
Tˆ (x)=x h∗ fˆ(x). (7)
ε ε
−∇ ◦∇
ThisconnectionisshowninPooladianandNiles-Weed[2021,Proposition2]forh= 1 2 and
2∥·∥
[Cuturietal.,2023]formoregeneralfunctions.
3 ProgressiveEstimationofOptimalTransport
WeconsidertheproblemofestimatingtheOTsolutionsπ andT ,givenempiricalmeasuresµˆandνˆ
0 0
fromni.i.d. samples. Ourgoalistodesignanalgorithmwhichisnumericallystable,computationally
light,andyieldsaconsistentestimator. Theentropicmap(7)isanattractiveoptiontoestimateOT
mapscomparedtootherconsistentestimators[e.g., HütterandRigollet,2021,Manoleetal.,2021].
Incontrasttothesemethods,theentropicmapistractablesinceitistheoutputofSinkhorn’salgorithm.
WhilePooladianandNiles-Weed[2021]showthattheentropicmapisabonafideestimatorofthe
optimaltransportmap,ithidesthecaveatthattheestimatorisalwaysbiased. Foranypre-setε>0,
theestimatorisneveravalidpushforwardmapi.e.,(Tˆ ) µ=ν,andthisholdstrueasthenumber
ε #
ofsamplestendstoinfinity. Inpractice,thepresenceofthisb̸ iasimpliesthattheperformanceofTˆ
ε
issensitivetothechoiceofε,e.g. asinFigure1. InsteadofhavingSinkhornastheend-allsolver,
weproposetouseitasasubroutine. Ourapproachistoiterativelymovethesourceclosertothe
target,therebycreatingasequenceofmatchingproblemsthatareincreasinglyeasiertosolve. Asa
consequence,thealgorithmislesssensitivetothechoiceofεfortheearlierEOTproblems,sinceithas
timetocorrectitselfatlatersteps.Tomovethesourceclosertothetarget,weconstructaMcCann-type
interpolatorwhichusestheentropicmapTˆ ofthepreviousiterate,asoutlinedinthenextsection.
ε
3.1 Method
Asawarm-up,considerT theoptimaltransportmapfromµtoν. WeletT(0) := T anddefine
0 0
S(0) := (1 α )Id+α T(0). This gives rise to the measure µ(1) =S(1)µ, which traces out the
− 0 0 #
McCann interpolation between (µ,ν) as α varies in the interval (0,1). Then, letting T(1) be the
optimaltransportmapforthepair(µ(1),ν),itisstraightforwardtoshowthatT(1) S(1) = T(0).
◦
Inotherwords,intheidealizedsetting,composingtheoutputofaprogressivesequenceofMonge
problemsalongtheMcCanninterpolationpathrecoversthesolutiontotheoriginalMongeproblem.
Buildingonthisobservation,wesetupaprogressivesequence
ofentropicoptimaltransportproblems,alonganestimatedin- E<latexit sha1_base64="9jnt92zKT27ESeX1mKg/aRlZvTo=">AAACVXicbVBdS9xAFJ2k1trth7vtY18GF8FCWRIR7aO0FPpooauCSZebyY0OzkzCzE1lGfJT+tr+pOKPETq7pqCrB4Y5nHO/OEWjpKMkuY7iJ2tP159tPB+8ePnq9eZw9ObY1a0VOBW1qu1pAQ6VNDglSQpPG4ugC4UnxeXnhX/yE62TtflO8wZzDedGVlIABWk2HGUa6MIJ6790P/xO8r6bDcfJJFmCPyRpT8asx9FsFH3Iylq0Gg0JBc6dpUlDuQdLUijsBlnrsAFxCed4FqgBjS73y9s7vh2Ukle1Dc8QX6p3Ozxo5+a6CJXLS1e9hfioV+iVzVR9zL00TUtoxO3iqlWcar4IhpfSoiA1DwSEleF2Li7AgqAQ371JfWK5xzZ8sqFuwDOLBq9ErTWY0mcVaKnmJVbQKup85qr/fBDyTVfTfEiOdyfp/mT/29748FOf9AZ7x7bYDkvZATtkX9kRmzLBrtgv9pv9if5GN/FavH5bGkd9z1t2D/HmP/FGthE=</latexit> (0)
terpolationpath,betweentheempiricalcounterpartsof(µ,ν).
Weshowthat,aslongasweremainclosetothetrueinterpola-
tionpath(bynotallowingαtobetoolarge),thefinaloutputis T<latexit sha1_base64="I7qYMKh2wPmW0fzW7cZLDhkafVA=">AAACkHicbVBdaxQxFM2OVev6ta2PvoQuQgVZZorUvohVKYj0YcVuW+iMSyZzZxuajyG5oyxh/pS/Rh/rLzE7nbZ264WQw7nn5N6cvJLCYRz/7kV3Vu7eu7/6oP/w0eMnTwdr64fO1JbDhBtp7HHOHEihYYICJRxXFpjKJRzlZx8X/aPvYJ0w+gDnFWSKzbQoBWcYqOlgP1UMTx23/qD55jeTl83Ut5RVfmzNrGnoW3ql2es0KReWX9NfF3QcrINhPIrbordB0oEh6Wo8Xeu9SgvDawUauWTOnSRxhZlnFgWX0PTT2kHF+BmbwUmAmilwmW+/3dAXgSloaWw4GmnL/uvwTDk3V3lQtpsu9xbkf3u5WpqM5U7mha5qBM0vBpe1pGjoIlNaCAsc5TwAxq0Iu1N+yizjGJK/8VKXWOahDpeosOnT1IKGH9woxXTh05IpIecFlKyW2PjUlZe4H/JNltO8DQ63Rsn2aPvL6+Huhy7pVfKcbJBNkpA3ZJd8ImMyIZz8JL/IOfkTrUc70bvo/YU06nWeZ+RGRZ//Ah2FzKo=</latexit> (1) =E(1) S(0)
Prog  
closetoν. Moreover,asthealgorithmprogresses,choosingthe
parametersε becomesalessarduoustask,andcomputationof
i
Tˆ becomesamorestablenumericalproblem. S<latexit sha1_base64="q4YmJsFMTsCUMBXn0IWttGGH/wM=">AAACVXicbVBdS9xAFJ2k1trth7vtY18GF8FCWRIR7aO0L3201FXBpMvN5EYHZyZh5qayDPkpfW1/UumPKXR2jaCrB4Y5nHO/OEWjpKMk+RvFT9aerj/beD548fLV683h6M2Jq1srcCpqVduzAhwqaXBKkhSeNRZBFwpPi6vPC//0B1ona3NM8wZzDRdGVlIABWk2HGUa6NIJ67913/1O8r6bDcfJJFmCPyRpT8asx9FsFH3Iylq0Gg0JBc6dp0lDuQdLUijsBlnrsAFxBRd4HqgBjS73y9s7vh2Ukle1Dc8QX6p3Ozxo5+a6CJXLS1e9hfioV+iVzVR9zL00TUtoxM3iqlWcar4IhpfSoiA1DwSEleF2Li7BgqAQ371JfWK5xzZ8sqFuwDOLBq9FrTWY0mcVaKnmJVbQKup85qpbPgj5pqtpPiQnu5N0f7L/dW98+KlPeoO9Y1tsh6XsgB2yL+yITZlg1+wn+8V+R3+if/FavH5TGkd9z1t2D/Hmfwvpth8=</latexit> (0) E<latexit sha1_base64="kvhJBALaSKj1l/wB5UMScqbheH8=">AAACVXicbVBdS9xAFJ2k1trth7vtY18GF8FCWRIR7aO0FPpooauCSZebyY0OzkzCzE1lGfJT+tr+pOKPETq7pqCrB4Y5nHO/OEWjpKMkuY7iJ2tP159tPB+8ePnq9eZw9ObY1a0VOBW1qu1pAQ6VNDglSQpPG4ugC4UnxeXnhX/yE62TtflO8wZzDedGVlIABWk2HGUa6MIJ6790P/xO+r6bDcfJJFmCPyRpT8asx9FsFH3Iylq0Gg0JBc6dpUlDuQdLUijsBlnrsAFxCed4FqgBjS73y9s7vh2Ukle1Dc8QX6p3Ozxo5+a6CJXLS1e9hfioV+iVzVR9zL00TUtoxO3iqlWcar4IhpfSoiA1DwSEleF2Li7AgqAQ371JfWK5xzZ8sqFuwDOLBq9ErTWY0mcVaKnmJVbQKup85qr/fBDyTVfTfEiOdyfp/mT/29748FOf9AZ7x7bYDkvZATtkX9kRmzLBrtgv9pv9if5GN/FavH5bGkd9z1t2D/HmP/MnthI=</latexit> (1)
ε
µ<latexit sha1_base64="Hqn0pI3MxjMTVscTwp7kH75FX+Y=">AAACLHicbZDPattAEMZX+dM4yp/GyTGXpSaQk5FCcXoMySXHFOLEYBkzWo3sJbsrsTtqMcIv0WvzDHmaXkrptc+RteNAYveDgR/fzDDDl5ZKOoqi38Ha+sbmh63Gdrizu7f/8aB5eOeKygrsikIVtpeCQyUNdkmSwl5pEXSq8D59uJr177+hdbIwtzQpcaBhZGQuBZC3eskYiCe6Gh60onY0F1+FeAEtttDNsBnsJ1khKo2GhALn+nFU0qAGS1IonIZJ5bAE8QAj7Hs0oNEN6vnDU37inYznhfVliM/dtxs1aOcmOvWTGmjslnsz87+9VC9dpvzLoJamrAiNeDmcV4pTwWdp8ExaFKQmHkBY6X/nYgwWBPnMwpAnFg1+F4XWYLI6yUFLNckwh0rRtE5c/sqhTzBezmsV7s7acafd+fq5dXG5yLLBjtkndspids4u2DW7YV0mmGI/2E/2GDwFv4I/wd+X0bVgsXPE3in49wwC2qfe</latexit>ˆ µ<latexit sha1_base64="Yit5Wm1o5Hn/Dzp1ROIKfPoAe2E=">AAACQHicbZDPShxBEMZ7TIw6MWY1N700WQS9LDMS1KPoxaOCq4KzWWp6atzG/jN01yjLsODT5Jo8g2/hG3gLXnNK77qBZM0HDT++qqKqv7xS0lOSPEZzb97Ov1tYXIrfL39Y+dhaXTv3tnYCu8Iq6y5z8KikwS5JUnhZOQSdK7zIb47G9YtbdF5ac0bDCnsaro0spQAKVr+1ng2AeKbrfnYLDisvlTVfm610e9RvtZNOMhF/DekU2myqk/5qtJIVVtQaDQkF3l+lSUW9BhxJoXAUZ7XHCsQNXONVQAMafa+ZfGLEN4NT8NK68Azxifv3RAPa+6HOQ6cGGvjZ2tj8by3XM5up3O810lQ1oREvi8tacbJ8nBAvpENBahgAhJPhdi4G4EBQyDGOeebQ4J2wWoMpmqwELdWwwBJqRaMm8+UfjkOC6Wxer+F8p5PudnZPv7QPDqdZLrIN9pltsZTtsQN2zE5Ylwl2z76x7+xH9BA9RT+j55fWuWg684n9o+jXb5Lqr5k=</latexit>ˆ(1) ⌫<latexit sha1_base64="TP17yukMVL+dDShcLCV/JuXZwOw=">AAACLHicbZDPShxBEMZ7NomaSaJrcsylcQnktMwEUY+LuXhcIfsHnEVqemrcZrt7hu4aZRn2JbyaZ/BpvIh49TnS+yegqx8U/Piqiiq+tFTSURTdB4137z9sbG59DD99/rK909z92ndFZQX2RKEKO0zBoZIGeyRJ4bC0CDpVOEgnv+f9wSVaJwvzh6YljjRcGJlLAeStYTIG4ompzputqB0txF9DvIIWW6l7vhtsJ1khKo2GhALnzuKopFENlqRQOAuTymEJYgIXeObRgEY3qhcPz/gP72Q8L6wvQ3zhPt+oQTs31amf1EBjt96bm2/2Ur12mfKjUS1NWREasTycV4pTwedp8ExaFKSmHkBY6X/nYgwWBPnMwpAnFg1eiUJrMFmd5KClmmaYQ6VoVicu/8+hTzBez+s19H+144P2wel+q3O8ynKLfWd77CeL2SHrsBPWZT0mmGLX7Ib9DW6Du+AheFyONoLVzjf2QsHTPwScp98=</latexit>ˆ
Atstepzero,wesetµˆ(0) =µˆ andcalculatetheentropicmap "
E(0) :=Tˆ from sampε les (µˆ(0),νˆ) with a regularization pa- 0<latexit sha1_base64="GCULt6U8KEXDncVg12FgEsOe5Qw=">AAACJXicbZBNS8NAEIY3fhu/qh69LBbBU0lEqseiF48KthWaUiabiS7ubsLuRimhv8Cr/gZ/jTcRPPlX3H4I2vrCwMM7M8zwxrngxgbBpzc3v7C4tLyy6q+tb2xuVbZ3WiYrNMMmy0Smb2IwKLjCpuVW4E2uEWQssB3fnw/77QfUhmfq2vZz7Eq4VTzlDKyzroJepRrUgpHoLIQTqJKJLnvb3maUZKyQqCwTYEwnDHLbLUFbzgQO/KgwmAO7h1vsOFQg0XTL0acDeuCchKaZdqUsHbm/N0qQxvRl7CYl2Dsz3Rua//ZiOXXZpqfdkqu8sKjY+HBaCGozOoyBJlwjs6LvAJjm7nfK7kADsy4s36eRRoWPLJMSVFJGKUgu+gmmUAg7KCOT/rDvEgyn85qF1lEtrNfqV8fVxtkkyxWyR/bJIQnJCWmQC3JJmoQRJE/kmbx4r96b9+59jEfnvMnOLvkj7+sbFTqk0Q==</latexit> ↵<latexit sha1_base64="Gml4dLv8N11X1+oruPkxzqr110k=">AAACLHicbZDPSsNAEMY3/q3xvx69LBbBU0lE1KPoxWMFawtNKZPNpF3c3YTdjVJCX8KrPoNP40XEq8/htlbQ1g8GfnwzwwxfnAtubBC8eXPzC4tLy5UVf3VtfWNza3vn1mSFZthgmch0KwaDgitsWG4FtnKNIGOBzfjuctRv3qM2PFM3dpBjR0JP8ZQzsM5qRSDyPnSD7lY1qAVj0VkIJ1AlE9W7295GlGSskKgsE2BMOwxy2ylBW84EDv2oMJgDu4Meth0qkGg65fjhIT1wTkLTTLtSlo7d3xslSGMGMnaTEmzfTPdG5r+9WE5dtulZp+QqLywq9n04LQS1GR2lQROukVkxcABMc/c7ZX3QwKzLzPdppFHhA8ukBJWUUQqSi0GCKRTCDsvIpD/suwTD6bxm4faoFp7UTq6Pq+cXkywrZI/sk0MSklNyTq5InTQII4I8kify7L14r9679/E9OudNdnbJH3mfX/kWp9g=</latexit> 0 1<latexit sha1_base64="oBLN5gZFAJte2dwAhqtt5WYQTlU=">AAACJXicbZBNS8NAEIY3fhu/qh69LBbBU0lEqseiF48KthWaUiabiS7ubsLuRimhv8Cr/gZ/jTcRPPlX3H4I2vrCwMM7M8zwxrngxgbBpzc3v7C4tLyy6q+tb2xuVbZ3WiYrNMMmy0Smb2IwKLjCpuVW4E2uEWQssB3fnw/77QfUhmfq2vZz7Eq4VTzlDKyzrsJepRrUgpHoLIQTqJKJLnvb3maUZKyQqCwTYEwnDHLbLUFbzgQO/KgwmAO7h1vsOFQg0XTL0acDeuCchKaZdqUsHbm/N0qQxvRl7CYl2Dsz3Rua//ZiOXXZpqfdkqu8sKjY+HBaCGozOoyBJlwjs6LvAJjm7nfK7kADsy4s36eRRoWPLJMSVFJGKUgu+gmmUAg7KCOT/rDvEgyn85qF1lEtrNfqV8fVxtkkyxWyR/bJIQnJCWmQC3JJmoQRJE/kmbx4r96b9+59jEfnvMnOLvkj7+sbFvuk0g==</latexit>
ε0 ε
rameterε
0
>0. TosetupthenextEOTproblem,wecreatean Figure3: IntuitionofPROGOT:By
intermediatedistributionviatheMcCann-typeinterpolation iteratively fitting to the interpola-
tionpath,thefinaltransportstepis
µˆ(1) :=S(0)µˆ(0), S(0) :=(1 α )Id+α E(0),
ε # ε − 0 0 lesslikelytocollapse,resultingin
withα (0,1). Indoingso,wearemimickingastepalong morestablesolver.
0
∈
theinterpolationpathforthepair(µ,ν). Infact,wecanshow
thatµˆ(1)isclosetoµ asdefinedin(4)(seeLemma11). Forthenextiterationofthealgorithm,we
choosε eε andα ,coα m0 puteE(1) theentropicmapforthepair(µˆ(1),νˆ)withregularizationε ,and
1 1 ε 1
movealongtheestimatedinterpolationpathbycomputingthedistributionµˆ(2). Werepeatthesame
ε
processforK steps. Thealgorithmthenoutputstheprogressiveentropicmap
T(K) :=E(K) S(K−1) S(0),
Prog ◦ ◦···◦
4whereS(k) = (1 α )Id+α E(k) istheMcCann-typeinterpolatoratstepk. Figure3visualizes
k k
−
theone-stepalgorithm,andDefinition2formalizestheconstructionofourprogressiveestimators.
Definition 2 (PROGOT). For two empirical measures µˆ,νˆ, and given step and regularization
schedules(α k)K k=0and(ε k)K k=0,thePROGOTmapestimatorT P(K ro)
g
isdefinedasthecomposition
T(K) :=E(K) S(K−1) S(0)
Prog ◦ ◦···◦
wherethesemapsaredefinedrecursively,startingfromµˆ(0) :=µˆ,andthenateachiteration:
ε
• E(k)istheentropicmapTˆ ,computedbetweensamples(µˆ(k),νˆ)withregularizationε .
εk ε k
• S(k) :=(1 α )Id+α E(k),isaMcCann-typeinterpolatingmapattimeα .
k k k
−
• µˆ(k+1) :=S(k)µˆ(k)theupdatedmeasureusedinthenextiteration.
ε # ε
Additionally,thePROGOTcouplingmatrixPbetweenµˆandνˆisidentifiedwiththematrixsolving
thediscreteEOTproblembetweenµˆ(K)andνˆ.
ε
Thesequenceof(α )K characterizesthespeedofmovementalongthepath. Bychoosingα =
k k=0 k
α(k) we can recover a constant-speed curve, or an accelerating curve which initially takes large
stepsandasitgetsclosertothetarget,thestepsbecomefiner,oradeceleratingcurvewhichdoes
theopposite. ThisisdiscussedinmoredetailinSection4andvisualizedinFigure(4-C).Though
ourtheoreticalguaranteerequiresaparticularchoiceforthesequence(ε )K and(α )K , our
k k=0 k k=0
experimentalresultsrevealthattheperformanceofourestimatorsisnotsensitivetothischoice. We
hypothesizethatthisbehaviorisduetothefactthatPROGOTis“self-correcting”—bysteeringclose
totheinterpolationpath,laterstepsinthetrajectorycancorrectthebiasesintroducedinearliersteps.
3.2 TheoreticalGuarantees
ByrunningPROGOT,wearesolvingasequenceofEOTproblems,eachbuildingontheoutcome
ofthepreviousone. Sinceerrorcanpotentiallyaccumulateacrossiterations,itleadsustoaskifthe
algorithmdivergesfromtheinterpolationpathandwhethertheultimateprogressivemapestimator
T(K) is consistent, focusing on the squared-Euclidean cost of transport, i.e., h = 1 2. . To
Prog 2∥·∥
answerthisquestion,weassume
(A1) µ,ν (Ω) with Ω Rd convex and compact, with 0 < ν ν() ν and
2,ac min max
∈ P ⊆ ≤ · ≤
µ() µ ,
max
· ≤
(A2)theinversemappingx (T (x))−1hasatleastthreecontinuousderivatives,
0
(cid:55)→
(A3)thereexistsλ,Λ>0suchthatλI DT (x) ΛI,forallx Ω
0
⪯ ⪯ ∈
andprovethatPROGOTyieldsaconsistentmapestimator. Ourerrorbounddependsonthenumber
ofiterationsK,viaaconstantmultiplicativefactor. ImplyingthatT(K) isconsistentaslongasK
Prog
doesnotgrowtooquicklyasafunctionofnthenumberofsamples. Inexperiments,wesetK n.
≪
Theorem3(ConsistencyofProgressiveEntropicMaps). Leth= 1 2. Supposeµ,ν andtheir
2∥·∥
optimaltransportmapT satisfy(A1)-(A3),andfurthersupposewehaveni.i.d.samplesfrombothµ
0
andν.LetT P(k r) ogbeasdefinedinDefinition2,withparametersε
k
≍n− 21 d,α
k
≍n− d1 forallk ∈[K].
Then,theprogressiveentropicmapisconsistentandconvergestotheoptimaltransportmapas
(cid:13) (cid:13)2
E(cid:13) (cid:13)T P(K ro) g−T 0(cid:13)
(cid:13)
L2(µ)
≲
log(n),K
n− d1 .
Therateofconvergencefor PROGOT isslowerthantheconvergenceofentropicmapsshownby
Pooladian and Niles-Weed [2021] under the same assumptions, with the exception of convexity
ofΩ. However,theratesthatTheorem3suggestsfortheparametersα andε aresetmerelyto
k k
demonstrateconvergenceanddonotreflecthoweachparametershouldbechosenasafunctionof
k whenexecutingthealgorithm. Wewillpresentpracticalschedulesfor(α )K and(ε )K in
k k=1 k k=1
Section4. TheproofisdeferredtoAppendixB;herewepresentabriefsketch.
Proofsketch. InLemma10,weshowthat
(cid:13) (cid:13)2 (cid:88)K (cid:88)K
E(cid:13)T(K) T (cid:13) ≲ ∆ := E E(k) T(k) 2 ,
(cid:13) Prog− 0(cid:13) L2(µ) k ∥ − ∥L2(µ(k))
k=0 k=0
5whereµ(k)iscorrespondsalocationonthetrueinterpolationpath,andT(k)istheoptimaltransport
map emanating from it. Here, E(k) is the entropic map estimator between the final target points
andthedatathathasbeenpushedforwardbyearlierentropicmaps. Itsufficestocontroltheterm
∆ . SinceE(k) andT(k) arecalculatedfordifferentmeasures,weproveanovelstabilityproperty
k
(Proposition4)toshowthatalongtheinterpolationpath,theseintermediatemapsremainclosetotheir
unregularizedpopulationcounterparts,ifα andε arechosenasprescribed. Thisresultisbased
k k
offtherecentworkbyDivoletal.[2024]andallowsustorecursivelyrelatetheestimationatthek-th
iteratetotheestimationatthepreviousones,downto∆ . Thus,Lemma11tellsusthat,underour
0
assumptionsandparameterchoicesα n−1/dandε n−1/2d,itholdsthatforallk 0
k k
≍ ≍ ≥
∆ ≲ n−1/d.
k log(n)
Sincethestabilityboundallowsustorelate∆ to∆ ,combinedwiththeabove,wehavethat
k 0
∆ ≲ ∆ ≲ n−1/d,
k log(n) 0 log(n)
wherethepenultimateinequalityusestheexistingestimationratesfromPooladianandNiles-Weed
[2021],withourparameterchoiceforε .
0
Proposition4(Stabilityofentropicmapswithvariationsinthesourcemeasure). Leth= 1 2.
2∥·∥
Let µ,µ′,ρ be probability measures over a compact domain with radius R. Suppose T ,T′ are,
ε ε
respectively,theentropicmapsfromµtoρandµ′toρ,bothwiththeparameterε>0. Then
T T′ 2 3R2ε−1W2(µ,µ′).
∥ ε − ε∥L2(µ) ≤ 2
4 ComputingCouplingsandMapEstimatorswith PROGOT
Following the presentation and motivation of PROGOT in Section 3, here we outline a practical
implementation. Recall that µˆ =
(cid:80)n
a δ and νˆ =
(cid:80)m
b δ , and we summarize the
n i=1 i xi m j=1 j yj
locationsofthesemeasurestothematricesX=(x ,...,x )andY =(y ,...,y ),whichareof
1 n 1 m
sizen dandm d,respectively. OurPROGOTsolver,concretelysummarizedinAlgorithm2,
× ×
takesasinputtwoweightedpointclouds,step-lengths(α ) ,regularizationparameters(ε ) ,and
k k k k
thresholdparameters(τ ) ,tooutputtwoobjectsofinterest:thefinalcouplingmatrixPofsizen m,
k k
×
asillustratedinFigure2,andtheentitiesneededtoinstantiatetheT mapestimator,wherean
Prog
implementationisdetailedinAlgorithm3.WehighlightthatAlgorithm2incorporatesawarm-starting
methodwheninstantiatingSinkhornsolvers(Line3). Thisstepmaybeaddedtoimprovetheruntime.
Algorithm2PROGOT(a,X,b,Y,(ε k,α k,τ k) k) Algorithm3T Prog[b,Y,(g(k),ε k,α k) k]
1: f =0 ,g(−1) =0 . 1: input: Sourcepointx Rd
n m ∈
2: fork =0,...,K do 2: initialize: y=x,α K resetto1.
3: f ,g (1 α )f,(1 α )g(k−1) 3: fork =0,...K do
init init k k
5
6
74 :
:
:: Q
Z
Xf,g ←←(k) [d X∇, iP a h← g ∗← (
(
α1 (cid:80)/S P Zji− n Q1k m( ija ) ∇P,X h(, xb i,− −Y, yε jk ), )τ
]
ik ∈,f i Rnit n, ×g dinit) 5
6
74 :
:
:: p
∆
zp ←← ←p[b
[
∇/ hj 1 ∗he T
m
(x
(
pypp T(
−∈
∆g( yk R )) j− m )h ]ε
j
Rk(y ∈d−y Rj m)) ×] j
d
k
8: endfor← − 8: y←∇ y α kz. ∈
← −
9: return: CouplingmatrixP, 9: endfor
10: MapestimatorT [b,Y,(g(k),ε ,α ) ]() 10: return: y
Prog k k k
·
Settingsteplengths. Weproposethreeschedulingschemesfor(α ) : decelerated,constant-speed
k k
andaccelerated. Lett [0,1]denotetheprogressalongtheinterpolationpathatiteratek. Atstep
k
∈
zero,t =α . Thenatthenextstep,weprogressbyafractionα oftheremainder,andtherefore
0 0 1
t =t +α (1 α ). Itisstraightforwardtoshowthatt =1
(cid:81)k
(1 α ).Wecallaschedule
1 0 1 − 0 k − ℓ=1 − ℓ
constantspeed,ift t isaconstantfunctionofk,whereasanaccelerated(resp. decelerated)
k+1 k
−
schedulehast t increasing(resp. decreasing)withk. Table2presentsthespecificchoicesof
k+1 k
−
α foreachoftheseschedules. Byconvention,wesetthelaststeptobeacompletestep,i.e.,α =1.
k K
Setting regularization schedule. To set the regularization parameters (ε )K , we propose Al-
k k=0
gorithm4. Tosetε , weusetheaverageofthevaluesinthecostmatrix[h(x y )] between
0 i j ij
−
source and target, multiplied by a small factor, as implemented in [Cuturi et al., 2022b]. Then
6forε ,wemakethefollowingkeyobservation. Asthelastiteration,thealgorithmiscomputing
K
E(k), anentropicmaproughlybetweenthetargetmeasureanditself. Forthisproblem, weknow
triviallythattheOTmapshouldbetheidentity. Therefore,givenasetofvaluestochoosefrom,we
pickε tobethatwhichminimizesthiserroroverahold-outevaluationsetofY = (y˜ )m
K test j j=1
(cid:88)m (cid:13) (cid:13)2
error(ε;Y test):= (cid:13) (cid:13)y˜ j −E(K)(y˜ j)(cid:13) (cid:13) 2. Algorithm4ε-scheduler(Y test,(s p) p,β 0)
j=1
1: recovera,X,b,Y,(α ) .
k k
Theintermediatevaluesarethensetbyinterpolating 2: setε 1 1 (cid:80) h(x y ).
between β 0ε 0 and ε K, according to the times 3: setσ0 ← 120n 1m (cid:80) ij h(y i − y )j .
t k. Figure 4-C visualizes the effect of applying
4:
forp=← 12 ,0 ..m .2
,P
dlj
o
l − j
Algorithm4forscheduling,asopposedtochoosing
5: ε s σ.
defaultvaluesforε k.
6:
_,←
g,_p
×
SINK(b,Y,b,Y,ε,τ)
Settingthresholdschedule. BysettingtheSinkhorn 7: T =T← [b,Y,(g,ε,1)]
Prog
stopping threshold τ k as a function of time k, one 8: error p Y test T(Y test) 2
canmodulatetheamountofcomputeeffortspentby 9: endfor ←∥ − ∥
the Sinkhorn subroutine at each step. This can be 10: p⋆ =argmin error .
p p
achievedbydecreasingτ k linearlyw.r.t. theiteration 11: ε 1 s p⋆ σ.
number,fromalooseinitialvalue,e.g.,0.1,toafinal
12: (t
←
)
=(1× (cid:81)k
(1 α )) .
t sa ur bg -e ot pv tia mlu ae lτ cK ou≪ plin1 g. sD Poi an ng ds do ur ae ls vu alt rs ian ba letu sr gal (l ky )i an
t
13: rek tuk rn: ((1− −t kℓ )= β1 0ε 0− +t kℓ ε 1k ) k.
eachstepk,whichmighthurtperformance.However,
twocommentsareinorder: (i)Becausethelast thresholdτ canbesetindependently, thefinal
K
couplingmatrixPreturnedbyPROGOTcanbearbitrarilyfeasible,inthesensethatitsmarginalscan
bemadearbitrarilyclosetoa,bbysettingτ toasmallvalue. Thismakesitpossibletocompareina
K
fairwaytoadirectapplicationoftheSinkhornalgorithm. (ii)Becausethecouplingisnormalizedby
itsownmarginalinline(5)ofAlgorithm2,weensurethatthebarycentricprojectioncomputedateach
stepremainsvalid,i.e.,thematrixQisatransitionkernel,withlinevectorsintheprobabilitysimplex.
5 Experiments
WerunexperimentstoevaluatetheperformanceofPROGOTacrossvariousdatasets,onitsabilityto
actasamapestimator,andtoproducecouplingsbetweenthesourceandtargetpoints.
5.1 PROGOTasaMapEstimator
In map experiments, unless mentioned otherwise, we run PROGOT for K = 16 steps, with a
constant-speedscheduleforα ,andtheregularizationschedulesetviaAlgorithm4withβ =5. In
k 0
theseexperiments,wefittheestimatorsontrainingdatausingtheℓ2transportcost,andreporttheir
2
performanceontestdatainFigure4andTable1. Tothisend,wequantifythedistancebetweentwo
testpointclouds(X,Y)withtheSinkhorndivergence[Genevayetal.,2018,Feydyetal.,2019],
alwaysusingtheℓ2transportcost. WritingOT (X,Y)fortheobjectivevalueofEquation(5),the
2 ε
Sinkhorndivergencereads
D (X,Y):=OT (X,Y)
1(cid:0)
OT (X,X)+OT
(Y,Y)(cid:1)
, (8)
εD εD − 2 εD εD
whereε is5%ofthemean(intra)costseenwithinthetargetdistribution(seeAppendixA).
D
Exploratory Experiments on Synthetic Data. We consider a synthetic dataset where X is a d-
dimensionalpointcloudsampledfroma3-componentGaussianmixture. Theground-truthT isthe
0
gradientofaninput-convexneural-network(ICNN)previouslyfittedtopushroughlyXtoamixture
of10Gaussians[Korotinetal.,2021]. Fromthismap,wegeneratethetargetpointcloudY. Unless
statedotherwise,weusen =7000samplestotrainaprogressivemapbetweenthesourceand
train
targetpointcloudsandvisualizesomeofitspropertiesinFigure4usingn =500testpoints.
test
Figure4-(A)demonstratestheconvergenceofT tothetruemapasthenumberoftrainingpoints
Prog
grows, in empirical L2 norm, that is, MSE= 1 (cid:80)ntest T (x ) T (x ) 2. Figure 4-(B)
shows the progression of PROGOT from sourcente tost targi= e1 t a∥ s m0 eai su− redP br yog D εi D∥ (X2 (k),Y) where
X(k) are the intermediate point clouds corresponding to µˆ(k). The curves reflect the speed of
ε
movement for three different schedules, e.g., the decelerated algorithm takes larger steps in the
first iterations, resulting in D (X(k),Y) to initially drop rapidly. Across multiple evaluations,
εD
7(A)EstimatorConsistency (B)Schedulingαk (C)Schedulingεk
40
0.04 Entropic Constant ProgOT
ProgOT Decelerate ProgOTnoε-sched
0.03 100 Accelerate 30
0.02 50
20
0.01
102 103 104 5 10 15 11 12 13 14 15 16
numberofsamples(ntrain) iters(k) iters(k)
Figure4: (A)ConvergenceofT totheground-truthmapw.r.t. theempiricalL2norm,ford=4.
Prog
(B)Effectofschedulingα ,ford=64. (C)Effectofschedulingε usingAlgorithm4,ford=64.
k k
Table1: PerformanceofPROGOTcomparedtobaselines,w.r.tD
εD
betweensourceandtargetof
thesci-Plexdataset. Reportednumbersaretheaverageof5runs,togetherwiththestandarderror.
Drug Belinostat Givinostat Hesperadin 5-drug
d 16 64 256 16 64 256 16 64 256 rank
PCA
PROGOT 2.9 0.1 8.8 0.1 20.8 0.2 3.3 0.2 9.0 0.3 21.9 0.3 3.7 0.4 10.1 0.4 23.1 0.4 1
± ± ± ± ± ± ± ± ±
EOT 2.5 0.1 9.6 0.1 22.8 0.2 3.9 0.4 10.0 0.1 24.7 0.9 4.1 0.4 10.4 0.5 26 1.3 2
± ± ± ± ± ± ± ± ±
DebiasedEOT 3.2 0.1 14.3 0.1 39.8 0.4 3.7 0.2 14.7 0.1 42.4 0.8 4.0 0.5 15.2 0.6 41 1.1 4
± ± ± ± ± ± ± ± ±
MongeGap 3.1 0.1 10.3 0.1 34.4 0.3 2.8 0.2 9.9 0.2 34.9 0.3 3.7 0.5 11.0 0.5 36 1.1 3
± ± ± ± ± ± ± ± ±
ICNN 5.0 0.1 14.7 0.1 42 1 5.1 0.1 14.8 0.2 40.3 0.1 4.0 0.4 14.4 0.5 46 2.1 5
± ± ± ± ± ± ± ± ±
weobservethattheα schedulehaslittleimpactonperformanceandsettleontheconstant-speed
k
schedule. Lastly,Figure4-(C)plotsD (X(k),Y)forthelast6stepsoftheprogressivealgorithm
εD
undertwoscenarios. PROGOT usesregularizationparameterssetaccordingtoAlgorithm4, and
PROGOTwithoutscheduling,setseveryε
k
as5%ofthemeanofthecostmatrixbetweenthepoint
cloudsof(X(k),Y). ThisexperimentshowsthatAlgorithm4canresultindisplacementsX(k)that
are“closer”tothetargetY,potentiallyimprovingtheoverallperformance.
Comparing Map Estimators on Single-Cell Data. We consider the sci-Plex single-cell RNA
sequencingdatafrom[Srivatsanetal.,2020]whichcontainstheresponsesofcancercelllinesto
188drugperturbations,asreflectedintheirgeneexpression. VisualizedinFigure6,wefocuson
5drugs(Belinostat,Dacinostat,Givinostat,Hesperadin,andQuisinostat)whichhaveasignificant
impactonthecellpopulationasreportedbySrivatsanetal.[2020]. Weremovegeneswhichappear
inlessthan20cells,anddiscardcellswhichhaveanincompletegeneexpressionoflessthan20
genes,obtainingn 104 sourceandm 500targetcells,dependingonthedrug. Wewhitenthe
≈ ≈
data,takeittolog(1+x)scaleandapplyPCAtoreducethedimensionalitytod= 16,64,256 .
{ }
Thisprocedurerepeatsthepre-processingstepsofCuturietal.[2023].
Weconsiderfourbaselines: (1)traininganinputconvexneuralnetwork(ICNN)[Amosetal.,2017]
usingtheobjectiveofAmos[2022](2)trainingafeed-forwardneuralnetworkregularizedwiththe
Monge Gap [Uscidda and Cuturi, 2023], (3) instantiating the entropic map estimator [Pooladian
andNiles-Weed,2021]and(4)itsdebiasedvariant[Feydyetal.,2019,Pooladianetal.,2022]. The
firsttwoalgorithmsuseneuralnetworks, andwefollowhyper-parametertuningin[Usciddaand
Cuturi,2023]. Wechoosethenumberofhiddenlayersforbothas[128,64,64]. FortheICNNwe
usealearningrateη = 10−3,batchsizeb = 256andtrainitusingtheAdamoptimizer[Kingma
andBa,2014]for2000iterations. FortheMongeGapwesettheregularizationconstantλ =10,
MG
λ = 0.1 and the Sinkhorn regularization to ε = 0.01. We train the Monge Gap in a similar
cons
setting,exceptthatwesetη =0.01. Tochooseεforentropicestimators,wesplitthetrainingdata
togetanevaluationsetandperform5-foldcross-validationonthegridof 2−3,...,23 ε ,where
0
{ }×
ε iscomputedasinline2ofAlgorithm4.
0
Wecomparethealgorithmsbytheirabilitytoalignthepopulationofcontrolcells,tocellstreated
withadrug. Werandomlysplitthedatainto80% 20%trainandtestsets,andreportthemean
−
andstandarderrorofperformanceoverthetestset,foranaverageof5runs. DetailedinTable1,
PROGOT outperformsthebaselinesconsistentlywithrespecttoD εD((T Prog) #X,Y). Thetable
showscompleteresultsfor3drugs,andtheoverallrankingbasedonperformanceacrossall5drugs.
5.2 PROGOTasaCouplingSolver
Inthissection,webenchmarktheabilityofPROGOTtoreturnacoupling,andcompareittothatofthe
Sinkhornalgorithm. Comparingcouplingsolversisrifewithchallenges,astheirtimeperformance
must be compared comprehensively by taking into account three crucial metrics: (i) the cost of
8
ESM viDkniS viDkniScisplatin dasatinib everolimus
9.8 9.8 10.0
ProgOT ProgOT ProgOT
9.8
9.6 Sinkhorn 9.6 Sinkhorn Sinkhorn
9.6
9.4 9.4
9.4
9.2 9.2
9.2
9.0 9.0 9.0
2.545 2.550 2.555 2.560 2.565 2.570 2.575 12.8812.8912.9012.9112.9212.9312.94 4.64 4.65 4.66 4.67 4.68
Cost Cost Cost
vindesine staurosporine decitabine
9.6 10.4 9.6
9.5 1 10 05 4 10.2 1 10 05 4 9.5 1 10 05 4
103 103 103
9.4 10.0 9.4
9.8
9.3 9.3
9.6
9.2 9.4 9.2
9.1 9.2 9.1
9.0 9.0 9.0
4.0044.0064.0084.0104.0124.0144.016 18.6818.6918.7018.7118.7218.7318.74 2.716 2.718 2.720 2.722 2.724 2.726
Cost Cost Cost
β=0.008 β=0.016 β=0.031 β=0.062 K=2 K=4 K=8
Figure5: Performanceasacouplingsolveronthe4idataset. PROGOT returnsbettercouplings,
intermsoftheOTcostandtheentropy,forafractionofSinkhorniterations,whilestillreturning
acouplingthathasthesamedeviationtotheoriginalmarginals. The(top)rowiscomputedusing
h= . 2,the(bottom)rowshowsresultsforthecosth= 1 pwherep=1.5.
∥∥2 p∥·∥p
transportaccordingtothecouplingP,thatis, P,C ,(ii)theentropyE(P),and(iii)satisfactionof
marginalconstraints P1 a + PT1 ⟨ b .⟩ Duetoourthresholdschedule(τ ) ,asdetailed
m 1 n 1 k k
∥ − ∥ ∥ − ∥
inSection4,bothapproachesareguaranteedtooutputcouplingsthatsatisfythesamethresholdfor
criterion(iii), leavingusonlythreequantitiestomonitor: computeeffortherequantifiedastotal
numberofSinkhorniterations,summedoverallK stepsforPROGOT),transportcostandentropy.
Whilecomputeeffortandtransportcostshould,ideally,beassmallaspossible,certainapplications
requiring, e.g., differentiability[Cuturietal.,2019]orbettersamplecomplexity[Genevayetal.,
2019],maypreferhigherentropies.
Tomonitorthesethreequantities,andcoveraninterestingspaceofsolutionsthat,werunSinkhorn’s
algorithmforalogarithmicgridofε=βε values(hereε isdefinedinLine2ofAlgorithm4),and
0 0
compareittoconstant-speedPROGOTwithK = 2,4,8 . Becauseonecannotcomparethesereg-
{ }
ularizations,weexploremanychoicestoscheduleεwithinPROGOT.Followingthedefaultstrategy
usedinOTT-JAX[Cuturietal.,2022a],wesetateveryiteratek,ε =θc¯ ,wherec¯ is5%ofthethe
k k k
meanofthecostmatrixatthatiteration,asdetailedinAppendixA.WedonotuseAlgorithm4since
itreturnsaregularizationschedulethatistunedformapestimation,whilethegoalhereistorecover
couplingsthatarecomparabletothoseoutputtedbySinkhorn. Wesetthethresholdformarginal
constraintsatisfactionforbothalgorithmsasτ =τ =0.001andrunallalgorithmstoconvergence,
K
withinfiniteiterationbudget. Forthecouplingexperiments,weusethesingle-cellmultiplexdata
ofBunneetal.[2023],reflectingmorphologicalfeaturesandproteinintensitiesofmelanomatumor
cells. Thedatadescribesd=47featuresforn 11,000controlcells,andm 2,800treatedcells,
≈ ≈
foreachof34drugs,ofwhichweuseonly6atrandom. Toalignthecellpopulations,weconsider
twogroundcosts: thesquared-Euclideannorm 2aswellash= 1 p,withp=1.5.
∥·∥ p∥·∥p
Resultsfor6drugsaredisplayedinFigure5. Theareaofthemarkerreflectsthetotalnumberof
Sinkhorniterationsneededforeitheralgorithmtoconvergetoacouplingwithathresholdτ =10−3.
ThevaluesforβandKdisplayedinthelegendareencodedusingcolors.Theglobalscalingparameter
forPROGOTissettoθ =2−4. Figure8and9visualizeotherchoicesforθ. Theseresultsprovethat
PROGOTprovidesacompetitivealternativetoSinkhorn,tocomputecouplingsthatyieldasmall
entropyandcostatalowcomputationaleffort,whilesatisfyingthesamelevelofmarginalconstraints.
Conclusion
Inthiswork,weproposedPROGOT,anewfamilyofEOTsolversthatblenddynamicandstaticformu-
lationsofOTbyusingtheSinkhornalgorithmasasubroutinewithinaprogressivescheme. PROGOT
aimstoprovidepractitionerswithanalternativetotheSinkhornalgorithmthat(i)doesnotfailwhen
instantiatedwithuninformedorill-informedεregularization,thankstoitsself-correctingbehavior
andoursimpleε-schedulingschemethatisinformedbythedispersionofthetargetdistribution,(ii)
9
yportnE
yportnE
yportnE
yportnE
yportnE
yportnEperformsatleastasfastasSinkhornwhenusedtocomputecouplingsbetweenpointclouds,and(iii)
providesareliableout-of-the-boxOTmapestimatorthatcomeswithanon-asymptoticconvergence
guarantee. WebelievePROGOTcanbeusedasastrongbaselinetoestimateMongemaps.
References
J. Altschuler, J. Weed, and P. Rigollet. Near-linear time approximation algorithms for optimal
transport via Sinkhorn iteration. In Advances in Neural Information Processing Systems 30:
AnnualConferenceonNeuralInformationProcessingSystems2017,4-9December2017,Long
Beach,CA,USA,2017.
L.Ambrosio,N.Gigli,andG.Savaré.Gradientflows:inmetricspacesandinthespaceofprobability
measures. SpringerScience&BusinessMedia,2005.
B.Amos. Onamortizingconvexconjugatesforoptimaltransport. InTheEleventhInternational
ConferenceonLearningRepresentations,2022.
B. Amos, L. Xu, and J. Z. Kolter. Input convex neural networks. In Proceedings of the 34th
International Conference on Machine Learning, Proceedings of Machine Learning Research.
PMLR,2017.
J.-D.BenamouandY.Brenier. AcomputationalfluidmechanicssolutiontotheMonge–Kantorovich
masstransferproblem. NumerischeMathematik,2000.
Y.Brenier. Polarfactorizationandmonotonerearrangementofvector-valuedfunctions. Comm.Pure
Appl.Math.,1991.
C. Bunne, S. G. Stark, G. Gut, J. S. del Castillo, M. Levesque, K.-V. Lehmann, L. Pelkmans,
A. Krause, and G. Rätsch. Learning single-cell perturbation responses using neural optimal
transport. NatureMethods,2023.
G.Buttazzo,L.DePascale,andP.Gori-Giorgi. Optimal-transportformulationofelectronicdensity-
functionaltheory. Phys.Rev.A,2012.
G. Carlier, L. Chizat, and M. Laborde. Displacement smoothness of entropic optimal transport.
ESAIM:COCV,2024.
S.ChewiandA.-A.Pooladian. AnentropicgeneralizationofCaffarelli’scontractiontheoremvia
covarianceinequalities. ComptesRendus.Mathématique,2023.
I. Csiszár. I-divergence geometry of probability distributions and minimization problems. Ann.
Probability,3:146–158,1975.
M.Cuturi. Sinkhorndistances: Lightspeedcomputationofoptimaltransport. AdvancesinNeural
InformationProcessingSystems,26,2013.
M. Cuturi, O. Teboul, and J.-P. Vert. Differentiable ranking and sorting using optimal transport.
Advancesinneuralinformationprocessingsystems,32,2019.
M.Cuturi,L.Meng-Papaxanthos,Y.Tian,C.Bunne,G.Davis,andO.Teboul. Optimaltransport
tools(ott): AJAXtoolboxforallthingsWasserstein. arXivpreprint,2022a.
M.Cuturi,L.Meng-Papaxanthos,Y.Tian,C.Bunne,G.Davis,andO.Teboul. Optimaltransport
tools(OTT):AJAXtoolboxforallthingsWasserstein. CoRR,2022b.
M.Cuturi,M.Klein,andP.Ablin. Monge,Bregmanandoccam: Interpretableoptimaltransportin
high-dimensionswithfeature-sparsemaps. InProceedingsofthe40thInternationalConference
onMachineLearning,ProceedingsofMachineLearningResearch.PMLR,2023.
V.Divol,J.Niles-Weed,andA.-A.Pooladian. TightstabilityboundsforentropicBreniermaps. arXiv
preprint,2024.
S.EcksteinandM.Nutz. Quantitativestabilityofregularizedoptimaltransportandconvergenceof
Sinkhorn’salgorithm. SIAMJournalonMathematicalAnalysis,2022.
10J.Feydy. Geometricdataanalysis,beyondconvolutions. AppliedMathematics,2020.
J.Feydy,T.Séjourné,F.-X.Vialard,S.-i.Amari,A.Trouvé,andG.Peyré. Interpolatingbetween
optimaltransportandMMDusingSinkhorndivergences. InThe22ndInternationalConference
onArtificialIntelligenceandStatistics.PMLR,2019.
R.Flamary,N.Courty,A.Gramfort,M.Z.Alaya,A.Boisbunon,S.Chambon,L.Chapel,A.Corenflos,
K. Fatras, N. Fournier, L. Gautheron, N. T. Gayraud, H. Janati, A. Rakotomamonjy, I. Redko,
A.Rolet,A.Schutz,V.Seguy,D.J.Sutherland,R.Tavenard,A.Tong,andT.Vayer. Pot: Python
optimaltransport. JournalofMachineLearningResearch,2021.
N.FournierandA.Guillin. OntherateofconvergenceinWassersteindistanceoftheempirical
measure. Probabilitytheoryandrelatedfields,162(3):707–738,2015.
A.Genevay. Entropy-regularizedoptimaltransportformachinelearning. PhDthesis,ParisSciences
etLettres(ComUE),2019.
A.Genevay,G.Peyré,andM.Cuturi. LearninggenerativemodelswithSinkhorndivergences. In
Proceedingsofthe21stInternationalConferenceonArtificialIntelligenceandStatistics,2018.
A.Genevay,L.Chizat,F.Bach,M.Cuturi,andG.Peyré. Samplecomplexityofsinkhorndivergences.
InThe22ndinternationalconferenceonartificialintelligenceandstatistics,pages1574–1583.
PMLR,2019.
P.Ghosal,M.Nutz,andE.Bernton. StabilityofentropicoptimaltransportandSchrödingerbridges.
JournalofFunctionalAnalysis,283(9):109622,2022.
G.Gut,M.D.Herrmann,andL.Pelkmans. Multiplexedproteinmapslinksubcellularorganization
tocellularstates. Science,2018.
J.-C.HütterandP.Rigollet. Minimaxestimationofsmoothoptimaltransportmaps. TheAnnalsof
Statistics,2021.
L.Kantorovitch. Onthetranslocationofmasses. C.R.(Doklady)Acad.Sci.URSS(N.S.),1942.
D.P.KingmaandJ.Ba.Adam:Amethodforstochasticoptimization.arXivpreprintarXiv:1412.6980,
2014.
A. Korotin, L. Li, A. Genevay, J. M. Solomon, A. Filippov, and E. Burnaev. Do neural optimal
transportsolverswork? AcontinuousWasserstein-2benchmark. Advancesinneuralinformation
processingsystems,2021.
T.Lehmann,M.-K.vonRenesse,A.Sambale,andA.Uschmajew. Anoteonoverrelaxationinthe
Sinkhornalgorithm. OptimizationLetters,2022.
T.Lin,N.Ho,andM.I.Jordan. Ontheefficiencyofentropicregularizedalgorithmsforoptimal
transport. JournalofMachineLearningResearch,2022.
Y.Lipman,R.T.Chen,H.Ben-Hamu,M.Nickel,andM.Le. Flowmatchingforgenerativemodeling.
arXivpreprint,2022.
Q.Liu. Rectifiedflow: Amarginalpreservingapproachtooptimaltransport. arXivpreprint,2022.
T.Manole,S.Balakrishnan,J.Niles-Weed,andL.Wasserman. Pluginestimationofsmoothoptimal
transportmaps. arXivpreprint,2021.
R.J.McCann.Aconvexityprincipleforinteractinggases.Advancesinmathematics,128(1):153–179,
1997.
G.MenaandJ.Niles-Weed. Statisticalboundsforentropicoptimaltransport: samplecomplexityand
thecentrallimittheorem. Advancesinneuralinformationprocessingsystems,2019.
L.Métivier,R.Brossier,Q.Mérigot,E.Oudet,andJ.Virieux. Measuringthemisfitbetweenseismo-
gramsusinganoptimaltransportdistance: Applicationtofullwaveforminversion. Geophysical
SupplementstotheMonthlyNoticesoftheRoyalAstronomicalSociety,2016.
11G.Monge. Mémoiresurlathéoriedesdéblaisetdesremblais. Histoiredel’AcadémieRoyaledes
Sciences,1781.
G. Peyré, M. Cuturi, et al. Computational optimal transport: With applications to data science.
FoundationsandTrends®inMachineLearning,2019.
A.-A.PooladianandJ.Niles-Weed. Entropicestimationofoptimaltransportmaps. arXivpreprint,
2021.
A.-A.Pooladian,M.Cuturi,andJ.Niles-Weed. Debiaserbeware: Pitfallsofcenteringregularized
transportmaps. InInternationalConferenceonMachineLearning.PMLR,2022.
A.-A. Pooladian, H. Ben-Hamu, C. Domingo-Enrich, B. Amos, Y. Lipman, and R. T. Q. Chen.
Multisampleflowmatching: Straighteningflowswithminibatchcouplings. InProceedingsofthe
40thInternationalConferenceonMachineLearning,ProceedingsofMachineLearningResearch.
PMLR,2023.
A.Ramdas,N.GarcíaTrillos,andM.Cuturi. OnWassersteintwo-sampletestingandrelatedfamilies
ofnonparametrictests. Entropy,2017.
F.Santambrogio. Optimaltransportforappliedmathematicians. Springer,2015.
M.Scetbon,M.Cuturi,andG.Peyré. Low-rankSinkhornfactorization. InProceedingsofthe38th
InternationalConferenceonMachineLearning,ProceedingsofMachineLearningResearch,2021.
M.Scetbon,G.Peyré,andM.Cuturi. Linear-timeGromovWassersteindistancesusinglowrank
couplingsandcosts. InProceedingsofthe39thInternationalConferenceonMachineLearning.
PMLR,2022.
G.Schiebinger,J.Shu,M.Tabaka,B.Cleary,V.Subramanian,A.Solomon,J.Gould,S.Liu,S.Lin,
P.Berube,etal. Optimal-transportanalysisofsingle-cellgeneexpressionidentifiesdevelopmental
trajectoriesinreprogramming. Cell,2019.
B.Schmitzer. Stabilizedsparsescalingalgorithmsforentropyregularizedtransportproblems. SIAM
JournalonScientificComputing,2019.
E.Schrödinger. Überdieumkehrungdernaturgesetze. VerlagderAkademiederWissenschaftenin
KommissionbeiWalterDeGruyteru...,1931.
R.Sinkhorn. Arelationshipbetweenarbitrarypositivematricesanddoublystochasticmatrices. The
Annalsofmathematicalstatistics,1964.
S.R.Srivatsan,J.L.McFaline-Figueroa,V.Ramani,L.Saunders,J.Cao,J.Packer,H.A.Pliner,
D.L.Jackson,R.M.Daza,L.Christiansen,etal. Massivelymultiplexchemicaltranscriptomicsat
single-cellresolution. Science,2020.
A.Thibault,L.Chizat,C.Dossal,andN.Papadakis. OverrelaxedSinkhorn–Knoppalgorithmfor
regularizedoptimaltransport. Algorithms,2021.
J.ThorntonandM.Cuturi. Rethinkinginitializationofthesinkhornalgorithm. InProceedingsof
The26thInternationalConferenceonArtificialIntelligenceandStatistics.PMLR,2023.
A. Tong, N. Malkin, G. Huguet, Y. Zhang, J. Rector-Brooks, K. Fatras, G. Wolf, and Y. Bengio.
Improvingandgeneralizingflow-basedgenerativemodelswithminibatchoptimaltransport. arXiv
preprint,2023.
T.UsciddaandM.Cuturi. TheMongegap: Aregularizertolearnalltransportmaps. InInternational
ConferenceonMachineLearning.PMLR,2023.
A.VacherandF.-X.Vialard.Parametertuningandmodelselectioninoptimaltransportwithsemi-dual
Brenierformulation. AdvancesinNeuralInformationProcessingSystems,2022.
H.VanAssel,T.Vayer,R.Flamary,andN.Courty. Optimaltransportwithadaptiveregularisation. In
NeurIPS2023WorkshopOptimalTransportandMachineLearning,2023.
12C.Villanietal. Optimaltransport: oldandnew. Springer,2009.
Y.Xie,X.Wang,R.Wang,andH.Zha.AfastproximalpointmethodforcomputingexactWasserstein
distance. InProceedingsofThe35thUncertaintyinArtificialIntelligenceConference,Proceedings
ofMachineLearningResearch.PMLR,2020.
13Belinostat Dacinostat Givinostat Hesperadin Quisinostat
6 6 6 6 6
4 4 4 4 4
2 2 2 2 2
0 0 0 0 0
2 2 2 2 2
− − − − −
0 5 0 5 0 5 0 5 0 5
xtrain xtest ytrain ytest
Figure6: OverviewofthesinglecelldatasetSrivatsanetal.[2020]. WeshowthefirsttwoPCA
dimensions performed on the training data, and limit the figure to 50 samples. The point cloud
(x ,x )showsthecontrolcellsand(y ,y )aretheperturbedcellsusingaspecificdrug.
train test train test
A AdditionalExperimentsandDetails
Generation of Figure 1 and Figure 2. We consider a toy example where the target and source
cloudsareasshowninFigure1. Wevisualizetheentropicmap[PooladianandNiles-Weed,2021],
itsdebiasedvariant[Pooladianetal.,2022]andPROGOT,whereweconsideradeceleratedschedule
with6steps,andonlyvisualizestepsk =3,5toavoidclutter. Thehyperparametersofthealgorithms
aresetasdescribedinSection5. Figure2showsthecouplingmatrixcorrespondingtothesamedata,
resultingfromthesamesolvers.
SinkhornDivergenceanditsRegularizationParameter. Insomeoftheexperiments,wecalculate
the Sinkhorn divergence between two point clouds as a measure of distance. In all experiments
wesetthevalueofε andaccordingtothegeometryofthetargetpointcloud. Inparticular, we
D
set ε to be default value of the OTT-JAX Cuturi et al. [2022b] library for this point cloud via
ott.geometry.pointcloud.PointCloud(Y).epsilon, thatis, 5%oftheaveragecostmatrix,
withinthetargetpoints.
DetailsofScheduling(α ) . Table2specifiesourchoicesofα forthethreeschedulesdetailedin
k k k
Section4. Figure7comparestheperformanceofPROGOTwithconstant-speedscheduleinred,with
thedecelerated(Dec.) schedulesingreen. Thefigureshowsresultsonthesci-Plexdata(averaged
across5drugs)andtheGaussianMixturesyntheticdata. Weobservethatthealgorithmsperform
roughlyonpar,implyingthatinpracticePROGOTisrobusttochoiceofα.
Table2: SchedulingSchemesforα .
k
Schedule α =α(k) t =t(k)
k k
Decelerated 1/e
1−e−(k+1)
e−1
Constant-Speed 1 k
K−k+2 K
Accelerated 2k−1 (cid:0)k(cid:1)2
(K+1)2−(k−1)2 K
Details of Scheduling (ε ) . For map experiments on the sci-Plex data [Srivatsan et al., 2020],
k k
we schedule the regularization parameters via Algorithm 4. We set β = 5 and consider the set
0
s = 0.1,0.5,1,5,10,20 . For coupling experiments on the 4i data [Gut et al., 2018] we set
p
the reg{ ularizations as follo} ws. Let x(k),...,x(k) denote the interpolated point cloud at iterate
1 n
k (according to Line 7, Algorithm 2) and recall that y ,...,y is the target point cloud. The
1 m
scaledaveragecostatthisiterateisc¯ =(cid:80) h(x(k) y )/(20mn),whichisthedefaultvalueofε
k i,j i − j
typicallyusedforrunningSinkhorn. Thenforeveryk [K],wesetε
k
= θc¯
k
tomakePROGOT
∈
compatibletotheβ regularizationlevelsofthebenchmarkedSinkhornalgorithms. ForFigure5,we
havesetθ =2−4. InFigure8andFigure9,wevisualizetheresultsforθ 2−7,2−4,2−1 togive
∈{ }
anoverviewoftheresultsusingsmallandlargerscalingvalues.
ComputeResources. ExperimentswererunonasingleNvidiaA100GPUforatotalof24hours.
SmallerexperimentsanddebuggingwasperformedonasingleMacBookM2Max.
14GMMdata Sciplex5-drugsaggregated
28
0.24 24
0.20 20
0.16 16
0.12 12
0.08 8
0.04 4
0.00 0
16 64 256 16 64 256
ProgOTnoε-sched DebiasedProgOT ProgOT ProgOTw/oε-sched(Dec.) DebiasedProgOT(Dec.) ProgOT(Dec.)
Figure7: ComparisonofconstantspeedvsdeceleratedPROGOT.
cisplatin,θ=0.008 dasatinib,θ=0.008 everolimus,θ=0.008
9.8 10e5 9.8 10e5 9.8 10e5 10e4 10e4 10e4
10e3 10e3 10e3
9.4 9.4 9.4
9.0 9.0 9.0
2.535 2.545 2.555 2.565 12.88 12.90 12.92 12.94 4.645 4.655 4.665 4.675
cisplatin,θ=0.062 dasatinib,θ=0.062 everolimus,θ=0.062
9.8 10e5 9.8 10e5 9.8 10e5 10e4 10e4 10e4
10e3 10e3 10e3
9.4 9.4 9.4
9.0 9.0 9.0
2.535 2.545 2.555 2.565 12.88 12.90 12.92 12.94 4.645 4.655 4.665 4.675
cisplatin,θ=0.5 dasatinib,θ=0.5 everolimus,θ=0.5
15.5 15.5 15.5
14.5 5 10 00 00 0 14.5 5 10 00 00 0 14.5 5 10 00 00 0
100 100 13.5 100
13.5 13.5
12.5
12.5 12.5 11.5
3.4 3.8 4.2 4.6 5.0 5.4 5.8 14.0 14.8 15.6 4.8 5.2 5.6 6.0 6.4 6.8
Cost Cost Cost
β=0.008 β=0.031 β=0.125 β=0.5 β=2.0 K=4
β=0.016 β=0.062 β=0.25 β=1.0 K=2 K=8
Figure8: ComparisonofPROGOTandSinkhornascouplingsolversforh()= 2. Differentrows
· ∥·∥2
showdifferentchoiceofregularizationθforPROGOTasdetailedinAppendixA.
vindesine,θ=0.008 staurosporine, θ=0.008 decitabine,θ=0.008
10.0 10.0 10.0
10e5 10e5 10e5 10e4 10e4 10e4
10e3 10e3 10e3
9.0 9.0 9.0
4.006 4.010 4.014 4.018 18.67518.68518.69518.705 2.718 2.722 2.726 2.730
vindesine,θ=0.062 staurosporine, θ=0.062 decitabine,θ=0.062
10.0 10.0 10.0
10e5 10e5 10e5 10e4 10e4 10e4
10e3 10e3 10e3
9.0 9.0 9.0
4.006 4.010 4.014 4.018 18.67518.68518.69518.705 2.718 2.722 2.726 2.730
vindesine,θ=0.5 staurosporine, θ=0.5 decitabine,θ=0.5
15 15 15
5000 5000 5000 1000 1000 1000
13 100 13 100 13 100
11 11 11
4.2 4.6 5.0 5.4 18.8 19.2 19.6 20.0 3.0 3.4 3.8
Cost Cost Cost
β=0.008 β=0.031 β=0.125 β=0.5 β=2.0 K=4
β=0.016 β=0.062 β=0.25 β=1.0 K=2 K=8
Figure9: ComparisonofPROGOTandSinkhornascouplingsolversforh= 1.5/1.5. Different
∥·∥1.5
rowsshowdifferentchoiceofregularizationθforPROGOTasdetailedinAppendixA.
15
yportnE
yportnE
yportnE
ESM
yportnE
yportnE
yportnE
viDkniSB Proofs
Preliminaries. Before proceeding with the proofs, we collect some basic definitions and facts.
First,wewritethethep-Wassersteindistanceforanyp 1:
≥
(cid:16) (cid:90)(cid:90) (cid:17)1/p
W (µ,ν):= inf x y pdπ(x,y) .
p
π∈Π(µ,ν) ∥ − ∥
Moreover,itiswell-knownthatp-Wassersteindistancesareorderedforp 1: for1 p q,it
≥ ≤ ≤
holdsthatW (µ,ν) W (µ,ν)[cf. Remark6.6,Villanietal.,2009].
p q
≤
Forthespecialcaseofthe1-Wassersteindistance,wehavethefollowingdualformulation
(cid:90)
W (µ,ν)= sup fd(µ ν),
1
−
f∈Lip
1
whereLip isthespaceof1-Lipschitzfunctions[cf. Theorem5.10,Villanietal.,2009].
1
Returning to the 2-Wasserstein distance, we will repeatedly use the following two properties of
optimaltransportmaps. First,foranytwomeasuresµ,ν andanL-LipschitzmapT,itholdsthat
W (T µ,T ν) LW (µ,ν). (9)
2 # # 2
≤
Thisfollowsfromacouplingargument. Inasimilarvein,wewillusethefollowingupperboundon
theWassersteindistancebetweenthepushforwardofasourcemeasureµbytwodifferentoptimal
transportmapsT andT :
a b
W2((T ) µ,(T ) µ) T T 2 , (10)
2 a # b # ≤∥ a − b ∥L2(µ)
Notationconventions. ForanintegerK N,[K]:= 0,...,K . Wewritea≲btomeanthat
∈ { }
thereexistsaconstantC > 0suchthata Cb. Aconstantcandependonanyofthequantities
≤
present in (A1) to (A3), as well as the support of the measures, and the number of iterations in
Algorithm2. Thenotationa≲
log(n)
bmeansthata C 1(logn)C2bforpositiveconstantsC
1
and
≤
C .
2
B.1 Propertiesofentropicmaps
Beforeprovingpropertiesoftheentropicmap,wefirstrecallthegeneralizedformof(5),whichholds
forarbitrarymeasures(cf. Genevay[2019]):
(cid:90) (cid:90) (cid:90)(cid:90)
sup fdµ+ gdν ε
e(f(x)+g(y)−1 2∥x−y∥2)/εdµ(x)dν(y)+ε.
(11)
−
(f,g)∈L1(µ)×L1(ν)
Whentheentropicdualformulationadmitsmaximixers,wedenotethemby(f ,g )andrefertothem
ε ε
asoptimalentropicKantorovichpotentials[e.g.,Genevay,2019,Theorem7]. Suchpotentialsalways
existifµandν havecompactsupport.
Wecanexpressanentropicapproximationtotheoptimaltransportcouplingπ asafunctionofthe
0
dualmaximizers[Csiszár,1975]:
(cid:16)f (x)+g (y) 1 x y 2(cid:17)
π (x,y):=γ (x,y)dµ(x)dν(y):=exp ε ε − 2∥ − ∥ dµ(x)dν(y). (12)
ε ε
ε
Whennecessary,wewillbeexplicitaboutthemeasuresthatgiverisetotheentropiccoupling. For
example,inplaceoftheabove,wewouldwrite
πµ→ν(x,y)=γµ→ν(x,y)dµ(x)dν(y). (13)
ε ε
Thepopulationcounterpartto(7),theentropicmapfromµtoν,isthenexpressedas
Tµ→ν(x):=E [Y X =x],
ε πε |
andsimilarlytheentropicmapfromν toµis
Tν→µ(y):=E [X Y =y].
ε πε |
We write the forward (resp. backward) entropic Brenier potentials as φ := 1 2 f (resp.
ε 2∥·∥ − ε
ψ := 1 2 g ). Bydominatedconvergence,onecanverifythat
ε 2∥·∥ − ε
φ (x)=Tµ→ν(x), ψ (y)=Tν→µ(y).
∇ ε ε ∇ ε ε
Wenowcollectsomegeneralpropertiesoftheentropicmap,whichwestateovertheballbutcanbe
readilygeneralized.
16Lemma5. Letµ,ν beprobabilitymeasuresoverB(0;R)inRd. Thenforafixedε>0,itholdsthat
bothTµ→ν andTν→µareLipschitzwithconstantupper-boundedbyR2/ε.
ε ε
ProofofLemma5. WeproveonlythecaseforTµ→ν astheprooffortheothermapiscompletely
ε
analogous. Itiswell-knownthattheJacobianofthemapisasymmetricpositivesemi-definitematrix:
Tµ→ν(x)=ε−1Cov (Y X =x)(seee.g.,ChewiandPooladian[2023,Lemma1]). Sincethe
∇ ε πε |
probabilitymeasuresaresupportedinaballofradiusR,itholdsthatsup Cov (Y X =x)
x∥ πε | ∥op ≤
R2,whichcompletestheclaim.
WealsorequirethefollowingresultsfromDivoletal.[2024],aswellasthefollowingobject: for
threemeasuresρ,µ,ν withfinitesecondmoments,write
(cid:90)(cid:90)(cid:90) (cid:16)γρ→µ(x,y)(cid:17)
I¯:= log ε γρ→µ(x,y)dπ(y,z)dρ(x),
γρ→ν(x,z) ε
ε
whereπisanoptimaltransportcouplingforthe2-Wassersteindistancebetweenµandν,andγ is
ε
thedensitydefinedin(13).
Lemma 6. [Divol et al., 2024, Proposition 3.7 and Proposition 3.8] Suppose ρ,µ,ν have finite
secondmoments,then
(cid:90)(cid:90)
εI¯ Tµ→ρ(y) Tν→ρ(z),y z dπ(y,z),
≤ ⟨ ε − ε − ⟩
and
(cid:90)(cid:90)
∥T εµ→ρ(y) −T εν→ρ(z) ∥2dπ(y,z) ≤2I¯ vs ∈u Rp d∥Cov περ→ν(X |Y =v) ∥op.
WearenowreadytoproveProposition4.Webrieflynotethatstabilityofentropicmapsandcouplings
hasbeeninvestigatedbymany[e.g.,Ghosaletal.,2022,EcksteinandNutz,2022,Carlieretal.,2024].
Theseworkseitherpresentqualitativenotionsofstability,orgiveboundsthatdependexponentially
on1/ε. Incontrast,therecentworkofDivoletal.[2024]provesthattheentropicmapsareLipschitz
withrespecttovariationsofthetargetmeasure,wheretheunderlyingconstantislinearin1/ε. We
showthattheirresultalsoencompassesvariationsinthesourcemeasure,whichisofindependent
interest.
ProofofProposition4. Letπ Γ(µ,µ′)betheoptimaltransportcouplingfromµtoµ′. Bydisinte-
∈
gratingandapplyingthetriangleinequality,wehave
(cid:90) (cid:90)(cid:90)
Tµ→ρ(x) Tµ′→ρ(x) dµ(x)= Tµ→ρ(x) Tµ′→ρ(x) dπ(x,x′)
∥ ε − ε ∥ ∥ ε − ε ∥
(cid:90)(cid:90)
Tµ→ρ(x) Tµ′→ρ(x′) dπ(x,x′)
≤ ∥ ε − ε ∥
+ Tµ′→ρ(x) Tµ′→ρ(x′) dπ(x,x′)
∥ ε − ε ∥
(cid:90)(cid:90)
Tµ→ρ(x) Tµ′→ρ(x′) dπ(x,x′)
≤ ∥ ε − ε ∥
R2 (cid:90)(cid:90)
+ x x′ dπ(x,x′)
ε ∥ − ∥
(cid:90)(cid:90) R2
Tµ→ρ(x) Tµ′→ρ(x′) dπ(x,x′)+ W (µ,µ′),
≤ ∥ ε − ε ∥ ε 2
wherethepenultimateinequalityfollowsfromLemma5,andthelaststepisduetoJensen’sinequality.
Toboundtheremainingterm,recallthat
vs ∈u Rp d∥Cov περ→ν(X |Y =v)
∥op
≤R2,
andbythetwoinequalitiesinLemma6,wehave(replacingν withµ′)
(cid:90)(cid:90)
Tµ→ρ(x) Tµ′→ρ(x′) 2dπ(x,x′) 2I¯R2
∥ ε − ε ∥ ≤
172R2
= (εI¯)
ε
2R2 (cid:90)(cid:90)
Tµ→ρ(y) Tµ′→ρ(z),y z dπ(y,z)
≤ ε ⟨ ε − ε − ⟩
2R2(cid:16)(cid:90)(cid:90) (cid:17)
Tµ→ρ(x) Tµ′→ρ(x′) dπ(x,x′) W (µ,µ′),
≤ ε ∥ ε − ε ∥ 2
whereweusedCauchy-Schwarzinthelastline. AnapplicationofJensen’sinequalityandrearranging
resultsinthebound:
(cid:90)(cid:90) 2R2
Tµ→ρ(x) Tµ′→ρ(x′) dπ(x,x′) W (µ,µ′),
∥ ε − ε ∥ ≤ ε 2
whichcompletestheclaim.
Finally,werequirethefollowingresultsfromPooladianandNiles-Weed[2021],whichwerestatefor
conveniencebutunderourassumptions.
Lemma7. [Two-samplebound:PooladianandNiles-Weed,2021,Theorem3] Consideri.i.d.samples
of size n from each distribution µ and ν, resulting in the empirical measures µˆ and νˆ, with the
corresponding. LetTˆ betheentropicmapbetweenµˆandνˆ. Under(A1)-(A3),itholdsthat
ε
(cid:13) (cid:13)2
E(cid:13)Tˆ T (cid:13) ≲ ε−d/2n−1/2+ε2.
(cid:13) ε 0(cid:13) log(n)
− L2(µ)
Moreover,ifε=ε(n) n−1/(d+4),thentheoverallrateofconvergenceisn−2/(d+4).
≍
Lemma8. [One-samplebound:PooladianandNiles-Weed,2021,Theorem4]Consideri.i.d.samples
ofsizenfromν,resultingintheempiricalmeasureνˆ,withfullaccesstoaprobabilitymeasureµ.
LetRˆ betheentropicmapfromµtoνˆ. Under(A1)-(A3),itholdsthat
ε
(cid:13) (cid:13)2
E(cid:13)Rˆ T (cid:13) ≲ ε1−d/2n−1/2+ε2.
(cid:13) ε 0(cid:13) log(n)
− L2(µ)
Moreover,ifε=ε(n) n−1/(d+2),thentheoverallrateofconvergenceisn−2/(d+2).
≍
B.2 RemainingingredientsfortheproofofTheorem3
WestartbyanalyzingourProgressiveOTmapestimatorbetweentheiterates.Wewillrecurseonthese
steps,andaggregatethetotalerrorattheend. Weintroducesomeconceptsandshorthandnotations.
First,theidealprogressiveMongeproblem: LetT(0)betheoptimaltransportmapfromµtoν,and
writeµ(0) :=µ. Thenwrite
S(0) :=(1 α )Id+α T(0),
0 0
−
andconsequentlyµ(1) := (S(0)) µ(0). WecaniterativelydefineT(i) tobetheoptimaltransport
#
mapfromµ(i)toν,andconsequently
S(i) :=(1 α )Id+α T(i),
i i
−
andthusµ(i+1) :=(S(i)) µ(i). ThedefinitionofMcCanninterpolationimpliesthattheseiteratesall
#
lieonthegeodesicbetweenµandν. ThisidealprogressiveMongeproblempreciselymimicksour
progressivemapestimator,though(1)thesequantitiesaredefinedatthepopulationlevel,and(2)the
mapsaredefinedasolutionstotheMongeproblem,ratherthanitsentropicanalogue. Recallthatwe
writeµˆandνˆastheempiricalmeasuresassociatedwithµandν,andrecursivelydefineE(i)tobethe
entropicmapfromµˆ(i)toνˆ,whereµˆ(0) :=µˆ,and
ε ε
µˆ(i+1) :=(S(i)) µˆ(i) :=((1 α )Id+α E(i)) µˆ(i). (14)
ε # ε − i i # ε
WealsorequireRˆ(i), definedtobethetheentropicmapbetweenµ(i) andνˆusingregularization
ε
ε . Thismapcanalsobeseenasa“one-sample"estimator,whichstartsfromiteratesoftheMcCann
i
interpolation,andmapstoanempiricaltargetdistribution.
TocontroltheperformanceofRˆ(i)below,wewanttouseLemma8. Todoso,weneedtoverifythat
ε
µ(i)alsosatisfiesthekeyassumptions(A1)to(A3). Thisisaccomplishedinthefollowinglemma.
18Lemma9(ErrorratesforRˆ(i)). Foranyi 0,themeasuresµ(i)andν continuetosatisfy(A1)to
ε
≥
(A3),andthus
E Rˆ(i) T 2 ≲ε1−d/2n−1/2+ε2.
∥ ε − 0 ∥L2(µ(i)) i i
Proof. Weverifythattheconditions(A1)to(A3)holdforthepair(µ(1),ν);repeatingtheargument
fortheotheriteratesisstraightforward.
First,werecallthatfortwomeasuresµ :=µ,µ :=ν withsupportinaconvexsubsetΩ Rd,the
0 1
⊆
McCanninterpolation(µ ) remainssupportedinΩ;seeSantambrogio[2015,Theorem5.27].
α α∈[0,1]
Moreover,byProposition7.29inSantambrogio[2015],itholdsthat
µ max µ , µ max µ ,ν ,
α L∞(Ω) 0 L∞(Ω) 1 L∞(Ω) max max
∥ ∥ ≤ {∥ ∥ ∥ ∥ }≤ { }
foranyα [0,1],recallthatthequantitiesµ ,ν arefrom(A1). Thus,thedensityofµ(1) =
max max
∈
µ =((1 α )Id+α T) µisuniformlyupperboundedonΩ;altogetherthiscovers(A1). For
α0
−
0 0 #
(A2)and(A3),notethatweareneverleavingthegeodesic. Ratherthanstudythe“forward”map,we
canthereforeinsteadconsiderthe“reverse"map
T¯ :=(α Id+(1 α )T−1),
0 0
−
whichsatisfiesT¯ ν = µ(1) andhenceT(1) = T¯−1. Wenowverifytherequirementsof(A2)and
#
(A3). For(A2),since(T(1))−1 =T¯ =α Id+(1 α )T−1,andT−1 isthree-timescontinuously
0 0
−
differentiablebyassumption,themap(T(1))−1isalsothreetimescontinuouslydifferentiable,with
thirdderivativeboundedbythatofT−1. For(A3),weusethefactthatT = φ forsomefunction
0
∇
φ whichisΛ-smoothandλ-stronglyconvex. Basicpropertiesofconvexconjugationthenimply
0
thatT(1) = φ ,whereφ =(α ∥·∥2 +(1 α )φ∗)∗. Sincetheconjugateofaλ-stronglyconvex
∇ 1 1 0 2 − 0 0
functionisλ−1-smooth,andconversely,weobtainthatthefunctionφ is(α +(1 α )λ−1)−1
1 0 0
stronglyconvexand(α +(1 α )Λ−1)−1. Inparticular,since(α +(1 α )λ−1)−1− min(1,λ)
0 0 0 0
− − ≥
and(α +(1 α )Λ−1)−1 max(1,Λ),weobtainthatDT(1) isuniformlyboundedaboveand
0 0
− ≤
below.
Wedefinethefollowingquantitieswhichwewillrecursivelybound:
∆ :=E E(i) T(i) 2 ,∆ := Rˆ(i) T(i) 2 ,W :=EW2(µˆ(i),µ(i)), (15)
i ∥ − ∥L2(µ(i)) Ri ∥ ε − ∥L2(µ(i)) i 2 ε
aswellas
α
:=1 α +R2 i ,
i i
A − ε
i
whererecallRistheradiusoftheballB(0;R)inRd.
First,thefollowinglemma:
Lemma10. Ifthesupportofµandν iscontainedinB(0;R)andα ≲ε fori=0,...,k,then
i i
(cid:13) (cid:13)2 (cid:88)k
(cid:13)T(k) T (cid:13) ≲ ∆ .
(cid:13) Prog− 0(cid:13)
L2(µ)
i
i=0
Proof. Weprovethislemmabyiteratingoverthequantitydefinedby
(cid:13) (cid:13)2
E :=(cid:13)E(k) S(k−1) S(j) T(k) S(k−1) S(j)(cid:13) .
j (cid:13) (cid:13)
◦ ◦···◦ − ◦ ◦···◦ L2(µ(j))
whenj k 1andE =∆ . ByaddingandsubtractingS(j)andSˆ(j)appropriately,weobtainfor
k k ε
≤ −
j k 1,
≤ −
(cid:13) (cid:13)2
E ≲(cid:13)E(k) S(k−1) S(j) E(k) S(k−1) S(j+1) S(j)(cid:13)
j (cid:13) (cid:13)
◦ ◦···◦ − ◦ ◦···◦ ◦ L2(µ(j))
(cid:13) (cid:13)2
+(cid:13)E(k) S(k−1) S(j+1) S(j) T(k) S(k−1) S(j)(cid:13)
(cid:13) (cid:13)
◦ ◦···◦ ◦ − ◦ ◦···◦ L2(µ(j))
19(cid:16) (cid:17)2
α Lip(E(k))Lip(S(k−1))...Lip(S(j+1)) ∆ +E
j j j+1
≤
 2
k−1
≲ α j (cid:89) ℓ ∆ j +E j+1
ε A
k
l=j+1
≲∆ +E
j j+1
whereinthelastinequalitywehaveusedthefactthatα ≲ε ,sothat ≲1forallk. Repeating
j j k
thisprocessyields(cid:13) (cid:13)T(k) T (cid:13) (cid:13)2 =E ≲(cid:80)k ∆ ,whichcompA letestheproof.
(cid:13) Prog− 0(cid:13)
L2(µ)
0 i=0 k
ToproveTheorem3,itthereforesufficestobound∆ . Weprovethefollowinglemmabyinduction,
k
whichgivestheproof.
Lemma11. Assumed 4. Suppose(A1)to(A3)hold,andα n−1/d andε n−1/2d forall
i i
≥ ≍ ≍
i [k]. Thenitholdsthatfork 0,
∈ ≥
W ≲ n−2/d, and ∆ ≲ n−1/d.
k log(n) k log(n)
Proof. We proceed by induction. For the base case k = 0, the bounds of Fournier and Guillin
[2015] imply that W = E[W2(µˆ,µ)] ≲ n−2/d. Similarly, by Lemma 7, we have ∆ ≲
0 2 0 log(n)
ε−d/2n−1/2+ε2 ≲ n−1/d.
0 0 log(n)
Now,assumethattheclaimedboundsholdforW and∆ . Wehave
k k
W =E[W2((S(k)) µˆ(k),(S(k)) µ(k))]
k+1 2 # ε #
(cid:16) (cid:17) (cid:16) (cid:17)
≲EW2 (S(k)) µˆ(k),(S(k)) µ(k) +EW2 (S(k)) µ(k),(S(k)) µ(k)
2 # ε # 2 # #
(cid:13) (cid:13)2
E[Lip(S(k))2W2(µˆ(k),µ(k))]+E(cid:13)S(k) S(k)(cid:13)
≤ 2 ε (cid:13) − (cid:13) L2(µ(k))
≲ 2W +α2∆
Ak k k k
≲W +α2∆
k k k
≲n−2/d,
wherethelaststepfollowsbytheinductionhypothesisandthechoiceofα . ByProposition4and
k
theprecedingbound,wehave
∆ ≲ E(k+1) Rˆ(k+1) 2 +∆
k+1 ∥ − ε ∥L2(µ(k+1)) Rk+1
≲ε−2 W +∆
k+1 k+1 Rk+1
≲ε−2 n−2/d+∆ .
k+1 Rk+1
Lemma9impliesthat ∆ ≲ n−1/d. Thechoiceofε thereforeimplies∆ ≲
Rk+1 logn k+1 k+1 log(n)
n−1/d,completingtheproof.
20