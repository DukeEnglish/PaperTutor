FedLLM-Bench: Realistic Benchmarks for
Federated Learning of Large Language Models
RuiYe1∗ RuiGe1∗ XinyuZhu1 JingyiChai1 YaxinDu1
YangLiu2 YanfengWang3,1 SihengChen1,3
1ShanghaiJiaoTongUniversity 2TsinghuaUniversity 3ShanghaiAILaboratory
Abstract
Federatedlearninghasenabledmultiplepartiestocollaborativelytrainlargelan-
guagemodelswithoutdirectlysharingtheirdata(FedLLM).Followingthistraining
paradigm,thecommunityhasputmassiveeffortsfromdiverseaspectsincluding
framework,performance,andprivacy. However,anunpleasantfactisthatthereare
currentlynorealisticdatasetsandbenchmarksforFedLLMandpreviousworksall
relyonartificiallyconstructeddatasets,failingtocapturepropertiesinreal-world
scenarios. Addressingthis,weproposeFedLLM-Bench,whichinvolves8training
methods,4trainingdatasets,and6evaluationmetrics,toofferacomprehensive
testbedfortheFedLLMcommunity. FedLLM-Benchencompassesthreedatasets
(e.g.,user-annotatedmultilingualdataset)forfederatedinstructiontuningandone
dataset(e.g.,user-annotatedpreferencedataset)forfederatedpreferencealignment,
whose scale of client number ranges from 38 to 747. Our datasets incorporate
severalrepresentativediversities: language,quality,quantity,instruction,length,
embedding,andpreference,capturingpropertiesinreal-worldscenarios. Basedon
FedLLM-Bench,weconductexperimentsonalldatasetstobenchmarkexisting
FLmethodsandprovideempiricalinsights(e.g.,multilingualcollaboration). We
believethatourFedLLM-BenchcanbenefittheFedLLMcommunitybyreducing
required efforts, providing a practical testbed, and promoting fair comparisons.
Codeanddatasetsareavailableathttps://github.com/rui-ye/FedLLM-Bench.
1 Introduction
Largelanguagemodels(LLMs)haveachievedunprecedentedsuccessindiversedomains[1,2,3,
4,5,6]. TheseLLMsareusuallytrainedbycentralizedlearningparadigm,wherevariousparties
individuallycollectmassivedataformodeltraining. Inthiscase,thedataamountofeachindividual
partyishard toscaleduetothe highcostofcollectingand annotatingdata. However, theirdata
cannotbedirectlysharedforcollaborationduetopropertyandprivacyissues.
To relieve the required cost of each party, federated learning (FL) [7, 8] has emerged as a sound
andoff-the-shelftechniquetofacilitatecollaboration,whichleveragesdecentralizedlanguagedata
tocollaborativelytrainLLMsinaprivacy-preservingway(FedLLM)[9,10,11]. Tofacilitatethe
developmentofFedLLM,therehasbeenaseriesofcodeframeworkssuchasOpenFedLLM[9],
FederatedScope-LLM[10],andFedML-LLM[11];andmanymethodsthattackletheissuesofdata
quality[12],intellectualpropertyprotection[13],privacy[14],limitedresources[15]inFedLLM.
Despite that massive efforts have been made, one significant concern remains: there is currently
no realistic benchmark for FedLLM, making it hard to practically evaluate the effectiveness of
FL methods in real-world scenarios. In such context, each previous work constructs its own FL
*Equalcontribution.
Preprint.Underreview.
4202
nuJ
7
]LC.sc[
1v54840.6042:viXradatasetsbyartificiallypartitioningexistingcentralizeddatasets[9,10,13],fallingshortofcapturing
thenaturalpropertiesexistedinreal-worldcross-userdatasets[16,17]. Evenworse,thesepapers
oftenfollowdifferenttrainingandevaluationsetups,whichsignificantlyincreasesthedifficultyof
re-implementationsandriskofunfaircomparisons[18,14].
Tofillthisgap,weproposethefirstrealisticbenchmarkforFedLLMtermedFedLLM-Bench,offering
acomprehensivetestbedfortheFedLLMcommunity. FedLLM-Benchencompassesthreedatasets
forfederatedinstructiontuning(includingoneuser-annotatedmultilingualdataset: Fed-Aya,and
two datasets with realistic user instructions: Fed-WildChat and Fed-ChatbotIT) and one dataset
(user-annotated preference dataset: Fed-ChatbotPA) for federated preference alignment. These
datasetsareallnaturallysplitbyreal-worlduserIDwiththescalerangingfrom38to747clients,
thereforeexhibitingrealisticfederatedproperties(especiallyforcross-devicesetupinFLwheredata
arepartitionedbyuserdevices). Specifically,datasetsinourFedLLM-Benchinheritthefollowing
diversities(Table1): (1)Language: clients’datasets(e.g.,ourFed-Ayadataset)coverdatafrom
diverselanguages,modelingthereal-worldscenariosofmultilingualcollaboration. (2)Qualityand
Quantity: thequalityandquantityofclients’datasetsvaryacrosseachother,whichisacommon
propertyinreal-worldapplications. (3)Length: thesequencelengthofclients’datacouldbequite
different, representing a new type of data heterogeneity in FL. (4) Preference: different clients
havedifferentpreferencesasverifiedbydifferentpreferredinstructionsininstructiontuningdatasets
(e.g., Fed-WildChat) and different preferred responses in preference alignment dataset (i.e., Fed-
ChatbotPA),mirroringthecomplexitiesofreal-worlddatascenarios. Thesediversitiesmakeour
FedLLM-BenchacomprehensivebenchmarkintheeraofFedLLM,servingasagreatsuccessorto
representativebenchmarksforclassicaltaskssuchasLEAF[19]benchmark.
Basedonthesedatasets,weimplement8representativebaselinemethodsand6evaluationmetrics,
andconductextensiveexperiments. Ourexperimentsmainlydemonstrate(1)thatfederatedlearning
canconsistentlybringperformancegaincomparedtolocaltrainingwithoutcollaboration;and(2)the
performancerankingofseveralrepresentativebaselinemethods. Besidesservingasabenchmarkfor
performancecomparison,ourFedLLM-Benchcanalsosupportexplorationofnewresearchdirections
thankstoitsflexibilityanddiversity. Asanexample,weconductanexploratoryexperimentbased
on the multilingual dataset Fed-Aya, showing that collaboration among similar languages could
potentiallybringmorebenefitscomparingtocollaborationamongalllanguages.
Ourcontributionsareasfollows:
1. WeproposethefirstrealisticFedLLMbenchmark,FedLLM-Bench,whichencompassesfournat-
urallysplitdatasets. FedLLM-Benchcoversdiversetasks,scales,languages,qualities,quantities,
lengths,andpreferences,mirroringthecomplexitiesanddiversitiesofreal-worldscenarios.
2. Weintegratethesedatasetsintoacodebasewith8representativebaselinemethodsand6evaluation
metrics,andopen-sourcethedatasetswiththeintegratedcodebaseforthecommunity.
3. Weconductextensiveexperimentstodemonstratethestatusofseveralexistingbaselinemethods
onourFedLLM-Benchandshowitspotentialinpromotingexplorationofnewresearchdirections.
2 Relatedwork
Federatedlearningforlargelanguagemodels. Federatedlearningisaprivacy-preservingand
collaborativetrainingparadigmthatenablesmultiplepartiestocollaborativelytrainasharedglobal
modelwithoutsharingtheirrawdata[7,8,20,21,22,23]. Dataheterogeneityisoneofthemost
representativechallengesinFL,whereclients’datasetsaredrawnfromdifferentdistributions[24,
25,26,27,28,29]. Addressingthis,numerousmethodshavebeenproposedbyregularization[30],
gradientcorrection[31],featurealignment[32,33,34],adjustmentofaggregationweights[25,35,
36],introducingmomentum[24,37],orleveragingpre-trainedmodels[38,39].
Recently,havingwitnessedthesuccessoflargelanguagemodels(LLMs)incentralizedlearning[1,
40,41,3,42],manyresearchersstarttoexploretrainingLLMsviafederatedlearning,mitigating
the issue of the shortage of public data or private data of one individual [2, 43, 44, 9]. Within
oneyear,therehavebeenmanyframeworkssuchasOpenFedLLM[9],FederatedScope-LLM[10],
FedML-LLM [11], and diverse methods such as FedbiOT [13] that protects model property and
FFA-LoRA[14]thatimprovesperformanceunderdifferentialprivacy.
2Table 1: Summary of our four realistic FedLLM datasets. IT denotes instruction tuning and PA
denotespreferencealignment. #denotes‘thenumberof’andL.denotes‘thelengthof’. Ourdatasets
exhibitdiversitiesincharacteristic,task,clientnumber,quantity,length,andquality.
DatasetName Fed-Aya[45] Fed-ChatbotIT[46] Fed-WildChat[47] Fed-ChatbotPA[46]
Characteristic Multilingual Single-Turnchat Multi-Turnchat Preference
AppliedTask IT IT IT PA
#Clients(Total) 38 237 100 747
#Samples(Total) 25,513 6,166 52,703 9,508
#Samples(Client) 671±815 26±33 527±477 13±21
L.Instruction(Client) 116±199 68±119 331±435 69±124
L.Response(Client) 225±411 211±176 506±470 218±178
DataQuality(Client) 0.63±0.28 0.67±0.22 0.79±0.37 0.68±0.21
However, onesignificantissueofthesepreviousworksisthattheirexperimentsareallbasedon
artificiallycraftedFLdatasets,fallingshortofextrapolatingtheireffectivenessinreal-worldscenarios.
Addressingthis,weproposethefirstrealisticbenchmarkforFedLLM,FedLLM-Bench,whichmirrors
thecomplexitiesanddiversitiesinreal-worldapplications. Besides,weimplement8representative
baselinemethodsinourFedLLM-Benchtodemonstratetheireffectivenessinrealisticscenarios.
Datasetsandbenchmarksinfederatedlearning. Sinceclients’dataarecollectedindependently
withoutcoordination, theissueofdataheterogeneitycommonlyexistsinFL.Alargeproportion
ofFLworks[7,25,30,32]simulatedataheterogeneitybyartificiallypartitioningclassicdatasets
such as CIFAR-10/100 [48], Fashion-MNIST [49], and MNIST [50]. Addressing this, several
realistic benchmarks are proposed for classic tasks such as image and text classification, which
includeLEAF[19](asuiteofuser-splitdatasets),FLAIR[17](multi-labelimageclassification),and
FLamby[16](abenchmarkformedicalanalysis). However,currently,thereisnorealisticdataset
orbenchmarkforthetasksofFedLLM,whileourFedLLM-Benchstandsoutasthefirstoneinthe
literature. Besides,ourFedLLM-Benchcoverstwouniquetaskscomparedtopreviousbenchmarks:
federatedinstructiontuning[51,52,9]andfederatedpreferencealignment[53,54,9].
3 FedLLM-Bench: arealisticbenchmarkforFedLLM
Here,weintroduceourFedLLM-Bench,fromfourperspectives: trainingmethods,descriptionsof
trainingdatasets,analysisoftrainingdatasets,andevaluationmetrics.
3.1 Trainingmethods
FedLLMoverview. FedLLMinvolvesfouriterativesteps: server-to-clientmodeldownloading,local
modeltraining,client-to-servermodeluploading,andglobalmodelaggregation. DuringFedLLM,
clients could collaborate on two critical tasks for LLMs [2]: instruction tuning and preference
alignment,whicharechallengingforindividualsduetohighcostofdatacollection[55,56]. Besides,
variousFLbaselinemethods[30,31,37]canbeincorporatedintoFedLLM.
Tasks: instructiontuning&preferencealignment. Ininstructiontuning[2,9],eachdatasample
isaninstruction-responsepair,wheretheLLMsaretrainedtofollowinstructionstogeneratethe
expectedresponsesviasupervisedfine-tuning. Inpreferencealignment[57,9],eachdatasample
consistsofaninstruction,apreferredandadispreferredresponse,wheretheLLMsaretrainedto
align with the preferred response given user instructions via direct preference optimization [54].
For both two tasks, we adopt the most commonly used parameter-efficient fine-tuning technique
LoRA[58],reducingtherequirementsofcomputationandcommunicationinFL[59,60].
FL:baselinemethods. InourFedLLM-Bench,weimplement8representativebaselinemethods,
includinglocaltrainingwithoutcollaborationand7classicalFLbaselinemethods. Followingthe
standardbaselineFedAvg[7],atthelocaltrainingpart,weimplementFedProx[30]whichapplies
local-globalmodelregularizationandSCAFFOLD[31]whichintroducescontrolvariatetocorrect
localgradients;whileatthemodelaggregationpart,weimplementFedAvgM[24],FedAdagrad[37],
FedYogi[37],andFedAdam[37]whichintroducemodelmomentumtoupdateglobalmodel.
3Distribution of Two Lengths Preference Longer Answer Distribution Data Quality Difference Distribution
en-30% 2000 I Rn es st pru oc nt sio en 100 140
120 ar-15% fr-6% 1500 80 100
te-8% zh-6%ru-2% 1000 60 80
es-11% 40 60
pt-23% 500 20 24 00
0 Aya ChatbotIT WildChat ChatbotPA 00.0 0.2 0.4 0.6 0.8 1.0 0 0.5 0.4 0.3 0.2 0.1 0.0 0.1 0.2
Dataset Preference Ratio Average Data Quality Difference
(a) Language(Fed-Aya) (b) LengthDistribution (c) LengthPreference (d) QualityPreference
Figure1: (a)LangaugedistributionofclientsinFed-Ayadataset. (b)Thedistributionoflengthof
instructionandresponseofclients’data. (c)Distributionoflengthpreference(theratioofauser
preferringlongerresponse)ofclientsinFed-ChatbotPAdataset. (d)Distributionofqualitypreference
(qualitydifferencebetweenpreferredanddispreferreddata)ofclientsinFed-ChatbotPAdataset.
(a) Fed-Aya (b) Fed-ChatbotIT (c) Fed-WildChat (d) Fed-ChatbotPA
Figure2: Distributionsoftop10verbsininstructions(10clientsareplottedforillustration). Our
realisticFedLLMdatasetsexhibitdiversepatternswithrespecttoinstructiontypes.
3.2 Descriptionsoftrainingdatasets
Fed-Aya. Aya[45]datasetisamultilingualinstructiontuningdatasetannotatedbycontributorsfrom
variouscountries[61]. Weselect6high-resourcelanguages: English(en),Spanish(es),French(fr),
Russian (ru), Portuguese (pt), Chinese (zh), and 2 low-resource languages: Standard Arabic (ar)
and Telugu (te). According to the annotator ID, we filter out those who contribute less than 100
annotations,andconstructFed-Aya,whichconsistsof38clientswith25kdatasamplesintotal. This
datasetmodelsareal-worldfederatedscenario[62]wherecollaboratingclientsaredistributedaround
theglobeandaimtoadvancemultilingualLLMs[1,63]. Wevisualizethelanguagedistributionof
Fed-AyadatasetinFigure1(a),showingthatthenumberofclientsfordifferentlanguagesvaries.
Therefore,italsoprovidesadatasetbasisfortheexplorationsofnewresearchtopicsinFedLLM,
includinglanguagepersonalizationandfairnessacrosshigh-andlow-resourcelanguages.
Fed-ChatbotIT.Chatbot-Arena-Conversations[64]isoriginallyacollectionofhuman-annotated
preferencedata,whereeachdatasampleconsistsofauserinstruction,auser-chosenresponseand
auser-rejectedresponse. Here,foreachdatasample,wecombinetheinstructionanduser-chosen
responseasaninstruction-responsepair. Subsequently,accordingtotheuserIDoftheannotator,we
filteroutthosewhocontributelessthan10datasamplesandconstructFed-ChatbotIT,whichconsists
of237clientswith6kdatasamplesintotal. Thisdatasetcapturesthediversitiesofrealisticusecases
insingle-turnqueryofLLMs,whereinstructionsofdifferentuserscouldholddifferentpatterns.
Fed-WildChat. WildChat[47]isacollectionofconversationsbetweenhumansandChatGPT,which
containsabroadspectrumofuser-chatbotinteractions. AccordingtotheIPaddress,wepartitionthe
wholedatasetintoseveraluserdatasetsandfilteroutthosewithlessthan200samples,formingour
Fed-WildChat. Fed-WildChatconsistsof100clientswith53kdatasamplesintotal. Thisdataset
representsreal-worldusecasesbetweenhumansandchatbots,whichinvolvemulti-turninteractions.
Fed-ChatbotPA.WeconstructanotherfederatedversionofChatbot-Arena-Conversations[46]for
preferencealignmenttasks: Fed-ChatbotPA.Specifically,wefilteroutuserswhocontributefewer
than5preferencepairsandtheresultingFed-ChatbotPAconsistsof747clientswith10kdatasamples
intotal. Eachdatasamplecontainsauserinstruction,apreferredanddispreferredresponse. This
4
htgneL rebmuN
tneilC
rebmuN
tneilCData Quality Distribution Data Quality Distribution Data Quality Distribution Data Quality Distribution
4.0 40 120
33 .. 05 33 05 33 05 100
2.5 25 25 80
2.0 20 20 60
1.5 15 15 40
1.0 10 10
0.5 5 5 20
0.0 0.4 0.5 0.6 0.7 0.8 0 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2.25 0 0.2 0.4 0.6 0.8
Average Data Quality Average Data Quality Average Data Quality Average Data Quality
(a) Fed-Aya (b) Fed-ChatbotIT (c) Fed-WildChat (d) Fed-ChatbotPA
Figure3: Thedatasetqualitydistributionofclientsinfourtrainingdatasets: Fed-Aya,Fed-WildChat,
Fed-ChatbotITandFed-ChatbotPA.WeaveragetheIFDscoresofallinstruction-responsepairsof
eachclienttorepresenttheclient’sdatasetquality.
t­SNE Visualization of Fed­ChatbotIT t­SNE Visualization of Fed­WildChat
(a) Fed-Aya (b) Fed-ChatbotIT (c) Fed-WildChat (d) Fed-ChatbotPA
Figure4: Thet-SNEvisualizationofembeddingsofinstruction-responsepairsfrom10clientsin
Fed-Aya,Fed-ChatbotIT,Fed-WildChat,andFed-ChatbotPAdatasets. Eachcolordenotesoneclient.
Wecanseeclusteringphenomenonofoneclient’sdataandthatclients’dataarediverse.
datasetexhibitsreal-worldpropertythatdifferentindividualscouldhavedifferentpreferences. To
verifythis,weanalyzethedatasetfromtwoperspectives. Firstly,wevisualizethelengthpreferences
ofclientsinFigure1(c),whereforeachclientwecomputetheratioofthepreferredresponsesbeing
longerthanthedispreferredresponses. Weseethatmostclientstendtopreferlongerresponses(i.e.,
theratioislargerthan0.5)andclientshavevariouspreferenceratios. Secondly,wevisualizeclients’
qualitypreferencesinFigure1(d),whereforeachclientwecomputetheaveragedqualitydifference
betweenthepreferredanddispreferreddata. Wecanseethediversityofclients’qualitypreferences.
3.3 Analysisoftrainingdatasets
WefurthershowthediversitiesofourdatasetsforFedLLMfromfourperspectives.
(1)Length. Foreachclient, wetokenizetheinstructionandresponseofeachdatasampleusing
tokenizerofLlama2[41],andaveragetheirlengthrespectivelyforeachclient. Weplotthelength
distributionofclientsinFigure1(b). Wecanseethatclients’datavariesindatalengthanddifferent
datasetsexhibitdifferentdistributions,verifyingbothinter-datasetandintra-datasetdiversities. (2)
Instruction. Following Self-Instruct [65], we use the Berkeley Neural Parser [66] to parse the
instructionsandextracttherootverbs. Werandomlysample10clientsforeachdatasetandvisualize
thedistributionoftop-10verbsinFigure2. Wecanseethatclientshavedifferentusagepreferences
intheirinstructionsandthatthetop10verbsvaryamongdatasets. Pleaserefertomoredetailed
visualizations in Figure 7, 9, 10, 11, 12. (3) Quality. We measure the data quality using IFD
metric[67],whereahighervaluedenoteshigherinstruction-followingdifficulty,andaveragethe
qualityofalldatasamplesofoneclient. FromFigure3,wecanobservethediversitiesinclients’data,
anddistinctdistributionsamongthesefourdatasets. (4)Embedding. Werandomlysample10clients,
extracttheembeddingofeachinstruction-responsedatasampleusingtext-embedding-ada-002model
fromOpenAI,andplotthemviat-SNE[68]inFigure4,whereeachcolordenotesoneclient. We
canseethatthereisclusteringphenomenon,indicatingcertainpatternswithinoneclient’sdatathat
mirrorreal-worldcases. Italsodemonstratesthediversityofclients’datasincedotswithdifferent
colorsarelocatedatdifferentregions. (5)Quantity. Weplotclients’dataquantitydistributionin
Figure5. Fromthefigure,weseeavarietyofdataquantityacrossclientsforalldatasets.
Theseanalysisevidentlyrevealsthediversitiesamongclients’datasets,makingourdatasetsappro-
priatecandidatesfortheFedLLMcommunitysincetheycanmirrorthecomplexitiesinreal-world
scenarios.
5
rebmuN
tneilC
rebmuN
tneilC
rebmuN
tneilC
rebmuN
tneilC(a) Fed-Aya (b) Fed-ChatbotIT (c) Fed-WildChat (d) Fed-ChatbotPA
Figure5: DataquantitydistributionacrossclientsofourfourFedLLMdatasets. Wecanseeavariety
ofdataquantitiesofclients,wherealargeproportionofclientshaverelativelyfewdata.
3.4 Evaluationmetrics
To evaluate the effectiveness of the training methods on our realistic FL datasets, we consider 6
evaluationmetrics,including4open-endedmetricsand2close-endedmetrics.
Open-endedevaluation. MT-Bench[64]isoneofthemostacknowledgedevaluationmetricsin
the era of LLMs, which evaluates both one-turn and two-turn conversation capability. Similarly,
Vicuna bench [69] evaluates one-turn instruction-following capability. AdvBench [70] evaluates
thesafetyrategivenunsafeinstructions. Additionally,weconsideranin-domainevaluationmetric
termedRef-GPT4,wherewerandomlysample50unseendataasthetestsetanduseGPT-4torate
thegeneratedresponsegiventheground-truthresponseasreference[71,64];seepromptinFigure8.
Close-ended evaluation. We consider two common close-ended evaluations [72, 41, 42, 1, 9]:
MMLU [73] (measuring knowledge of 57 subjects) and HumanEval [74] (measuring capability
of generating programs from docstrings). We evaluate these two metrics mainly to ensure that
fine-tuningwillnotcompromisethesecapabilitiesacquiredduringpre-training.
4 ExperimentsonFedLLM-Bench
Experimentalsetups. Forinstructiontuningtask,weuseLlama2-7B[41]asthebasemodeland
setthelearningrateas2e−5withabatchsizeof16. Forpreferencealignmenttask,weuseAlpaca-
7B[75]asthebasemodelandsetthelearningrate1e−4withabatchsizeof8,asalargeproportion
ofclientshavefewerthan10datasamples. Weadopt8-bitquantizationonthebasemodelandsetthe
rankofLoRA[58]as16. Thenumberofcommunicationroundsissettoeither100or200andonly
asmallproportionofclientsaresampledforeachround. Wesetthenumberofstepsoflocalmodel
trainingas10formostscenarios. PleaserefertodetailsinAppendixC.1.
4.1 Benchmarkresults
Fed-Aya. Here,weconductexperimentsonFed-AyawithRef-GPT4astheevaluationmetricfor
8languages. Werunlocaltrainingforeachlanguage(randomlysampleoneclientforsimplicity),
and7federatedmethods. FromTable2,weseethat: (1)MostFLmethodscanoutperformlocal
trainingonaverage,indicatingtheeffectivenessofcollaboration. (2)NoFLmethodcanachieve
comprehensivesuperiorityinalllanguages,implyingthenecessityoffutureexplorationoflanguage
personalization[76,77]. (3)FedAvgandFedProxarethetwomosteffectivealgorithmshere.
Fed-ChatbotIT.Here,weconductexperimentsonFed-ChatbotITevaluatedunder5metrics. We
randomlysampletwoclientstorunlocaltrainingandaveragetheirevaluationresults. FromTable3,
weseethat(1)onopen-endedevaluation, allFLmethodsconsistentlyoutperformlocaltraining,
indicatingtheeffectivenessofFLinenhancingthecapabilityofinstructionfollowing. (2)Onclosed-
endedevaluation,FLmethodsperformbetterorarecomparabletolocaltraining,indicatingthatFL
trainingwillnotcompromiseLLMs’generalcapability. (3)Acrossallmetrics,thebestscoresare
achievedbyFLalgorithms;Onaverage,FedAdagrad[37]achievesthebestperformance.
Fed-WildChat. Here,weshowtwoseriesofexperimentsbasedonFed-WildChat: instructiontuning
basedonsingle-turnandmulti-turnconversations, inTable4. Forbothexperiments, weseethat
FLmethodsconsistentlyoutperformlocaltraining,verifyingtheeffectivenessofcollaboration. For
6Table2:ExperimentsonmultilingualdatasetFed-AyaevaluatedviaRef-GPT4.FLmethodsgenerally
performbetterthanlocaltrainingonaverage.However,FLmethodscannotensurebetterperformance
oneverylanguage,implyingthenecessityforexploringlanguagepersonalizationtechniques.
Algorithm ar en es fr pt ru te zh Average
LocalTraining(ar) 2.55 7.55 4.85 5.10 3.95 4.55 1.55 3.35 4.18
LocalTraining(en) 2.55 7.20 5.35 4.60 5.35 4.75 1.60 3.55 4.37
LocalTraining(es) 1.90 7.80 5.55 5.60 4.50 5.20 1.30 5.05 4.62
LocalTraining(fr) 1.85 7.90 4.75 4.20 4.25 5.05 1.30 3.95 4.16
LocalTraining(pt) 1.95 5.95 4.20 5.45 3.85 5.15 1.55 3.95 4.01
LocalTraining(ru) 1.60 7.80 6.05 4.80 4.00 4.50 1.75 4.90 4.43
LocalTraining(te) 2.10 3.70 3.75 3.50 3.05 4.10 1.25 3.60 3.13
LocalTraining(zh) 2.30 8.10 5.45 5.80 4.80 4.30 1.60 4.95 4.66
FedAvg[7] 2.50 8.00 5.50 5.35 4.95 5.65 2.00 5.25 4.90
FedProx[30] 3.20 7.10 5.90 5.65 4.85 5.20 1.60 5.80 4.92
SCAFFOLD[31] 2.65 7.75 6.30 5.35 5.00 6.35 1.45 4.90 4.97
FedAvgM[24] 3.00 7.80 5.35 5.00 5.30 5.65 1.90 5.00 4.86
FedYogi[37] 2.00 8.45 6.15 4.55 3.85 6.30 1.65 4.93 4.73
FedAdagrad[37] 2.50 7.85 5.15 5.25 4.45 5.75 1.55 5.50 4.75
FedAdam[37] 2.40 8.50 5.25 4.70 4.35 5.40 1.90 5.20 4.71
Table3: Experimentsonsingle-turnchatdatasetFed-ChatbotIT.FLmethodsperformconsistently
betterunder open-ended instruction-followingevaluationsandcomparablyunder closed-ended
knowledgeevaluationscomparedtolocaltraining. Overall,FedAdagradisthemosteffective.
Algorithm MT-Bench-1 Vicuna Ref-GPT4 Average HumanEval MMLU
LocalTraining 3.73 6.78 4.49 5.00 13.41 46.31
FedAvg[7] 4.30 6.93 5.29 5.51 14.02 46.10
FedProx[30] 4.25 7.21 5.00 5.49 14.63 46.12
SCAFFOLD[31] 3.86 7.35 4.82 5.34 15.24 46.02
FedAvgM[24] 4.34 7.17 4.76 5.42 14.63 46.13
FedYogi[37] 4.13 7.20 5.00 5.44 15.85 46.24
FedAdagrad[37] 3.94 7.50 4.99 5.48 15.85 46.48
FedAdam[37] 3.88 7.32 5.02 5.41 14.57 46.10
single-turn,weseethatnoFLmethodcandominateinallevaluationmetrics;whileformulti-turn,
weseethatFedAvg[7]consistentlyoutperformsthebestacrossmetrics.
This is an interesting observation since the other baseline methods are shown to be effective in
tacklingdataheterogeneityinothertaskssuchasimageclassification[30,31]. Thisphenomenon
couldbeattributedtotworeasons: (1)trainingfrompre-trainedmodelitselfbenefitstacklingthe
issueofdataheterogeneity[38,39],whichcouldmakesomemodel-leveloptimizationtechniques
not as effective as before [30, 31]. (2) We are fine-tuning with parameter-efficient fine-tuning
technique[58]withasmallnumberoflocalsteps(e.g.,10),reducingtheriskofoverfittingonlocal
datasets[31,60]. Therefore,wecallformorefutureworkstoenhancetheperformanceregarding
data,suchasconsideringdataquality[12]orsyntheticdata[18].
Fed-ChatbotPA.Here,weconductexperimentsoffederatedpreferencealignmentonFed-ChatbotPA
dataset,withaninstruction-tunedLLMasthemodelinitialization. Werandomlysampletwoclients
torunlocaltrainingandaveragetheirevaluationresults. FromTable5,weseethat(1)preference
alignmentcouldenhancetheLLMs’capabilityinfollowinghumansinstructionsinanhelpfuland
harmless manner. (2) All FL methods consistently perform better than local training, indicating
theeffectivenessoffederatedpreferencealignment. Sincethehigh-qualitypreferencedatausually
involvesmassivehumanefforts,eachpartyishardtoscaleupthedata,motivatingdiverseparties
tocollaborateviaFL[56,78,79]. (3)Regardinginstruction-followingcapabilities,FedAvgM[24],
FedProx[30],SCAFFOLD[31],adnFedAvg[7]arefourmosteffectivemethods.
7Table4: Experimentsof single-turn and multi-turn chatonFed-Wildchat. FLmethodsperform
consistentlybetterthanlocaltraining. FedAvgisarobustmethodinthisscenario.
Experiment Single-Turn Multi-Turn
Algorithm MT-1 Vicuna Ref-GPT4 MT-1 MT-2 MT-Bench Ref-GPT4
LocalTraining 4.15 7.03 4.50 3.99 2.56 3.27 4.68
FedAvg[7] 4.81 7.99 5.88 4.84 3.15 3.99 5.86
FedProx[30] 4.86 7.93 5.74 4.58 2.92 3.75 5.26
SCAFFOLD[31] 4.78 7.93 5.57 4.46 3.13 3.79 5.25
FedAvgM[24] 4.52 8.07 5.85 4.53 2.77 3.65 5.34
FedYogi[37] 4.78 8.04 5.48 4.59 2.96 3.78 5.05
FedAdagrad[37] 4.76 7.76 5.93 4.64 3.03 3.84 5.17
FedAdam[37] 4.54 8.03 5.68 4.63 2.85 3.74 4.96
Table5: ExperimentsoffederatedpreferencealignmentonFed-ChatbotPAdataset. FLmethods
consistently perform better than local training, indicating the significance of collaboration via
FL.Comparedtobasemodel,modelstrainedviaFLmethodsachieveconsistentimprovementin
instruction-following capabilitiesand safety,andpreservemostofthe knowledge.
Algorithm MT-Bench-1 Vicuna Average AdvBench MMLU
BaseModel 3.96 6.31 5.14 9.40 40.41
LocalTraining 4.12 6.62 5.37 11.0 38.26
FedAvg[7] 4.44 7.06 5.75 16.2 39.70
FedProx[30] 4.44 7.11 5.78 13.8 39.51
SCAFFOLD[31] 4.53 7.01 5.77 16.0 39.94
FedAvgM[24] 4.71 6.87 5.79 13.3 39.78
FedYogi[37] 4.33 6.62 5.48 11.3 40.27
FedAdagrad[37] 4.40 6.79 5.60 11.0 40.30
FedAdam[37] 4.31 6.72 5.52 11.8 40.26
4.2 Furtherexplorations
Multilingualcollaboration. WehaveobservedinTable2thatdespitethatFLmethodsachievebetter
performancethanlocaltrainingonaverage,theyfailtobringconsistentbenefitsoneveryspecific
language. Such observation motivates us to explore language personalization. Therefore, in this
experiment,weconstructtworepresentativebaselines:FedAvgamongclientswiththesamelanguage
(FedSamLang)andFedAvgamongclientswith"similar"languages(FedSimLang)toexplorethe
potentialmutualbenefitsamonglanguages. Wepartitionlanguagesintofive"similar"groupsbytheir
languagefamily[80]asfollows: (1)StandardArabic,Urdu,andIranianPersian;(2)French,Italian,
Spanish,andPortuguese;(3)EnglishandGerman;(4)Russian,PolishandUkrainian;(5)Simplified
Chinese,TraditionalChinese,JapaneseandKorean.
WeshowtheexperimentalresultsinTable6,wherewecompareFedSamLangandFedSimLangwith
FedAvg(trainedon8languagesaspreviousexperiments)andlocaltraining. Fromtheresults,wecan
seethat(1)FedSamLangoutperformslocaltraininginalllanguagesandachievesthehighestaverage
score,indicatingthebenefitsofcollaborationamongclientswiththesamelanguage. (2)Compared
to FedSamLang, FedSimLang performs better on 3 languages (i.e., en, pt, and zh) but worse on
otherlanguages,showingthatleveragingthepowerofotherlanguagescanbenefitsomeparticular
languages. Thoughthisobservationverifiesthepossibilityofmultilingualcollaboration,weneed
morefutureworkstofullyexploreitspotential. (3)FedSamLangandFedSimLangperformbetteror
comparablycomparedtoFedAvgwithfewercollaborators,indicatingtheeffectivenessoflanguage
personalization. These results call for future works on exploring personalization techniques that
canstrikeagoodbalancebetweenlocalizationandcollaborationorconstructabettercollaboration
structureamongthesemultilingualclients[77].
8Table6: Experimentsofexplorationofefficientcollaborationamonglanguages. FedSimLangper-
formsbetterthanFedSamLangonsomelanguages,indicatingitspartialeffectivenessandcallingfor
futureworksonconstructingefficientcollaborationstructuretofacilitatemultilingualcollaboration.
Algorithm ar es en fr pt ru zh Average
Local 2.55 5.55 7.20 4.20 3.85 4.50 4.95 4.69
FedAvg 2.50 5.50 8.00 5.35 4.95 5.65 5.25 5.31
FedSamLang 3.30 5.90 7.65 6.45 4.10 4.80 5.35 5.36
FedSimLang 3.05 5.85 7.80 5.40 4.90 4.30 5.75 5.30
Differential privacy. Here, we conduct experiments
toevaluatetheeffectivenessofdifferentialprivacy[81],
whereweapplyuser-leveldifferentialprivacy[82]. Ex-
periments are conducted on our Fed-WildChat single-
turndataset;seemoredetailsinAppendixD.Wefixthe
δ =1e−4andtuneϵinrangeof{1e−3,1e−2,0.1,1}that
satisfies(ϵ,δ)-differentialprivacy,andreporttheresults
inFigure6. Resultsshowthat(1)FedAvgwith(1,1e−4)-
differentialprivacycanachievecomparableperformance
comparedtoFedAvgwithoutdifferentialprivacy. (2)With
thereductionofϵ,theprivacypreservationimproveswhile Figure6: ExperimentsonFed-WildChat
the performance degrades. FedAvg with (1e−3,1e−4)- with differential privacy (ϵ,δ) (δ =
differentialprivacycanachievecomparableperformance 1e−4). FedDP-x indicates ϵ = x. Fe-
compared to local training without differential privacy
dAvgwith(1e−2,1e−4)-DPstilloutper-
technique. Tothebestofourknowledge,thisisthefirst forms local training without DP while
timeintheliteraturedemonstratingtheresultsofdifferen- ensuringuser-leveldifferentialprivacy.
tialprivacyinFedLLM.
5 Conclusions
Federatedlearningenablesmultiplepartiestocollaborativelytrainlargelanguagemodelswithout
sharingtheirrawdata(FedLLM),whichhasattractedmanyresearcheffortsfromthecommunity. In
thispaper,weproposethefirstrealisticbenchmarkforFedLLM,FedLLM-Bench,whichinvolves
8trainingmethods,4trainingdatasets,and6evaluationmetrics. Thecorecontributionliesinthe
datasets,whichcoverawiderangeofclientscaleandtwocommontasks(i.e.,instructiontuningand
preferencealignment).Thesedatasetsexhibitmanyreal-worlddiversities,includinglanguage,quality,
quantity,instruction,sequencelength,embedding,andpreference,mirroringreal-worldscenarios.
BasedonFedLLM-Bench,weconductextensiveexperimentsonalldatasetstobenchmarkclassical
FLmethods. Besides,wealsoconductexperimentstoexploretheeffectivecollaborationstrategiesof
cross-languagecollaborationandshowresultswhenincorporatingdifferentialprivacywithfederated
instructiontuning. WebelievethatourFedLLM-BenchcouldbenefittheFedLLMcommunityby
reducingrequiredefforts,providingapracticaltestbed,andpromotingfaircomparisons.
9References
[1] OpenAI. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774,2023.
[2] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,
SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollowinstructionswith
humanfeedback. NIPS,35:27730–27744,2022.
[3] JasonWei,MaartenBosma,VincentZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,AndrewM
Dai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. InInternationalConferenceon
LearningRepresentations,2022.
[4] WeizeChen,YushengSu,JingweiZuo,ChengYang,ChenfeiYuan,Chi-MinChan,HeyangYu,Yaxi
Lu,Yi-HsinHung,ChenQian,etal. Agentverse: Facilitatingmulti-agentcollaborationandexploring
emergentbehaviors. InTheTwelfthInternationalConferenceonLearningRepresentations,2024.
[5] SiruiHong,MingchenZhuge,JonathanChen,XiawuZheng,YuhengCheng,JinlinWang,CeyaoZhang,
ZiliWang,StevenKaShingYau,ZijuanLin,etal. Metagpt:Metaprogrammingformulti-agentcollabora-
tiveframework. InTheTwelfthInternationalConferenceonLearningRepresentations,2024.
[6] KevinMaikJablonka,PhilippeSchwaller,AndresOrtega-Guerrero,andBerendSmit. Leveraginglarge
languagemodelsforpredictivechemistry. NatureMachineIntelligence,pages1–9,2024.
[7] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficientlearningofdeepnetworksfromdecentralizeddata. InArtificialintelligenceand
statistics,pages1273–1282.PMLR,2017.
[8] PeterKairouz,HBrendanMcMahan,BrendanAvent,AurélienBellet,MehdiBennis,ArjunNitinBhagoji,
KallistaBonawitz,ZacharyCharles,GrahamCormode,RachelCummings,etal. Advancesandopen
problemsinfederatedlearning. FoundationsandTrends®inMachineLearning,14(1–2):1–210,2021.
[9] RuiYe,WenhaoWang,JingyiChai,DihanLi,ZexiLi,YindaXu,YaxinDu,YanfengWang,andSiheng
Chen. Openfedllm:Traininglargelanguagemodelsondecentralizedprivatedataviafederatedlearning.
arXivpreprintarXiv:2402.06954,2024.
[10] WeiruiKuang,BingchenQian,ZitaoLi,DaoyuanChen,DaweiGao,XuchenPan,YuexiangXie,Yaliang
Li,BolinDing,andJingrenZhou. Federatedscope-llm:Acomprehensivepackageforfine-tuninglarge
languagemodelsinfederatedlearning. arXivpreprintarXiv:2309.00363,2023.
[11] FedMLInc. Federatedlearningonlargelanguagemodels(llms). https://doc.fedml.ai/federate/
fedllm,2023. Accessed:2024-03-31.
[12] WanruZhao,YaxinDu,NicholasDonaldLane,SihengChen,andYanfengWang. Enhancingdataquality
infederatedfine-tuningoffoundationmodels. arXivpreprintarXiv:2403.04529,2024.
[13] FeijieWu,ZitaoLi,YaliangLi,BolinDing,andJingGao.FedbiOT:asolutionforfederatedlargelanguage
modelfine-tuningwithintellectualpropertyprotection,2024.
[14] YoubangSun,ZitaoLi,YaliangLi,andBolinDing. ImprovingloRAinprivacy-preservingfederated
learning. InTheTwelfthInternationalConferenceonLearningRepresentations,2024.
[15] ZihanFang,ZhengLin,ZheChen,XianhaoChen,YueGao,andYuguangFang. Automatedfederated
pipelineforparameter-efficientfine-tuningoflargelanguagemodels. arXivpreprintarXiv:2404.06448,
2024.
[16] JeanOgierduTerrail,Samy-SafwanAyed,EdwigeCyffers,FelixGrimberg,ChaoyangHe,RegisLoeb,
Paul Mangold, Tanguy Marchand, Othmane Marfoq, Erum Mushtaq, et al. Flamby: Datasets and
benchmarksforcross-silofederatedlearninginrealistichealthcaresettings.AdvancesinNeuralInformation
ProcessingSystems,35:5315–5334,2022.
[17] CongzhengSong,FilipGranqvist,andKunalTalwar. Flair:Federatedlearningannotatedimagerepository.
AdvancesinNeuralInformationProcessingSystems,35:37792–37805,2022.
[18] ZhuoZhang,JingyuanZhang,JintaoHuang,LizhenQu,HongzhiZhang,andZenglinXu.Fedpit:Towards
privacy-preservingandfew-shotfederatedinstructiontuning. arXivpreprintarXiv:2403.06131,2024.
[19] SebastianCaldas, SaiMeherKarthikDuddu, PeterWu, TianLi, JakubKonecˇny`, HBrendanMcMa-
han,VirginiaSmith,andAmeetTalwalkar. Leaf: Abenchmarkforfederatedsettings. arXivpreprint
arXiv:1812.01097,2018.
10[20] SungwonHan,SungwonPark,FangzhaoWu,SundongKim,ChuhanWu,XingXie,andMeeyoungCha.
Fedx: Unsupervisedfederatedlearningwithcrossknowledgedistillation. InEuropeanConferenceon
ComputerVision,pages691–707.Springer,2022.
[21] SungwonPark,SungwonHan,FangzhaoWu,SundongKim,BinZhu,XingXie,andMeeyoungCha.
Feddefender: Client-sideattack-tolerantfederatedlearning. InProceedingsofthe29thACMSIGKDD
ConferenceonKnowledgeDiscoveryandDataMining,pages1850–1861,2023.
[22] PeihuaMaiandYanPang. Verticalfederatedgraphneuralnetworkforrecommendersystem. InInterna-
tionalConferenceonMachineLearning,pages23516–23535.PMLR,2023.
[23] JingweiYi,FangzhaoWu,ChuhanWu,RuixuanLiu,GuangzhongSun,andXingXie. Efficient-fedrec:
Efficientfederatedlearningframeworkforprivacy-preservingnewsrecommendation. InProceedingsof
the2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages2814–2824,2021.
[24] Tzu-MingHarryHsu,HangQi,andMatthewBrown. Measuringtheeffectsofnon-identicaldatadistribu-
tionforfederatedvisualclassification. arXivpreprintarXiv:1909.06335,2019.
[25] RuiYe,MingkaiXu,JianyuWang,ChenxinXu,SihengChen,andYanfengWang. Feddisco:Federated
learningwithdiscrepancy-awarecollaboration. InInternationalConferenceonMachineLearning,pages
39879–39902.PMLR,2023.
[26] ZexiLi,XinyiShang,RuiHe,TaoLin,andChaoWu. Nofearofclassifierbiases:Neuralcollapseinspired
federatedlearningwithsyntheticandfixedclassifier. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,pages5319–5329,2023.
[27] ZiqingFan,ShengchaoHu,JiangchaoYao,GangNiu,YaZhang,MasashiSugiyama,andYanfengWang.
Locallyestimatedglobalperturbationsarebetterthanlocalperturbationsforfederatedsharpness-aware
minimization. arXivpreprintarXiv:2405.18890,2024.
[28] PeihuaMai,RanYan,andYanPang. Rflpa: Arobustfederatedlearningframeworkagainstpoisoning
attackswithsecureaggregation. arXivpreprintarXiv:2405.15182,2024.
[29] ZiqingFan,JiangchaoYao,BoHan,YaZhang,YanfengWang,etal. Federatedlearningwithbilateral
curationforpartiallyclass-disjointdata. AdvancesinNeuralInformationProcessingSystems,36,2024.
[30] TianLi,AnitKumarSahu,ManzilZaheer,MaziarSanjabi,AmeetTalwalkar,andVirginiaSmith.Federated
optimizationinheterogeneousnetworks. ProceedingsofMachineLearningandSystems,2:429–450,2020.
[31] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In Inter-
nationalConferenceonMachineLearning,pages5132–5143.PMLR,2020.
[32] QinbinLi,BingshengHe,andDawnSong. Model-contrastivefederatedlearning. InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition,pages10713–10722,2021.
[33] JianqingZhang,YangLiu,YangHua,andJianCao.Anupload-efficientschemefortransferringknowledge
fromaserver-sidepre-trainedgeneratortoclientsinheterogeneousfederatedlearning. InProceedingsof
theIEEE/CVFConferenceonComputerVisionandPatternRecognition,2024.
[34] JianqingZhang,YangLiu,YangHua,andJianCao. Fedtgp:Trainableglobalprototypeswithadaptive-
margin-enhancedcontrastivelearningfordataandmodelheterogeneityinfederatedlearning. InProceed-
ingsoftheAAAIConferenceonArtificialIntelligence,2024.
[35] JianyuWang,QinghuaLiu,HaoLiang,GauriJoshi,andHVincentPoor. Tacklingtheobjectiveincon-
sistencyprobleminheterogeneousfederatedoptimization. Advancesinneuralinformationprocessing
systems,33:7611–7623,2020.
[36] ZexiLi,TaoLin,XinyiShang,andChaoWu. Revisitingweightedaggregationinfederatedlearningwith
neuralnetworks. InInternationalConferenceonMachineLearning,pages19767–19788.PMLR,2023.
[37] SashankJReddi,ZacharyCharles,ManzilZaheer,ZacharyGarrett,KeithRush,JakubKonecˇny`,Sanjiv
Kumar,andHughBrendanMcMahan. Adaptivefederatedoptimization. InInternationalConferenceon
LearningRepresentations,2020.
[38] JohnNguyen,JianyuWang,KshitizMalik,MaziarSanjabi,andMichaelRabbat. Wheretobegin?onthe
impactofpre-trainingandinitializationinfederatedlearning. InTheEleventhInternationalConferenceon
LearningRepresentations,2023.
11[39] Hong-YouChen,Cheng-HaoTu,ZiweiLi,HanWeiShen,andWei-LunChao. Ontheimportanceand
applicabilityofpre-trainingforfederatedlearning. InTheEleventhInternationalConferenceonLearning
Representations,2023.
[40] HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothéeLacroix,
BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal. Llama:Openandefficientfoundation
languagemodels. arXivpreprintarXiv:2302.13971,2023.
[41] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,Nikolay
Bashlykov, SoumyaBatra, PrajjwalBhargava, ShrutiBhosale, etal. Llama2: Openfoundationand
fine-tunedchatmodels. arXivpreprintarXiv:2307.09288,2023.
[42] AlbertQJiang,AlexandreSablayrolles,ArthurMensch,ChrisBamford,DevendraSinghChaplot,Diego
delasCasas,FlorianBressand,GiannaLengyel,GuillaumeLample,LucileSaulnier,etal. Mistral7b.
arXivpreprintarXiv:2310.06825,2023.
[43] ShijieWu,OzanIrsoy,StevenLu,VadimDabravolski,MarkDredze,SebastianGehrmann,Prabhanjan
Kambadur,DavidRosenberg,andGideonMann. Bloomberggpt: Alargelanguagemodelforfinance.
arXivpreprintarXiv:2303.17564,2023.
[44] SiqiaoXue,CaigaoJiang,WenhuiShi,FangyinCheng,KetingChen,HongjunYang,ZhipingZhang,
JianshanHe,HongyangZhang,GanglinWei,etal. Db-gpt:Empoweringdatabaseinteractionswithprivate
largelanguagemodels. arXivpreprintarXiv:2312.17449,2023.
[45] ShivalikaSingh,FreddieVargus,DanielDsouza,BörjeFKarlsson,AbinayaMahendiran,Wei-YinKo,
HerumbShandilya,JayPatel,DeividasMataciunas,LauraOMahony,etal. Ayadataset:Anopen-access
collectionformultilingualinstructiontuning. arXivpreprintarXiv:2402.06619,2024.
[46] LianminZheng,Wei-LinChiang,YingSheng,SiyuanZhuang,ZhanghaoWu,YonghaoZhuang,ZiLin,
Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. Judging
llm-as-a-judgewithmt-benchandchatbotarena,2023.
[47] WentingZhao,XiangRen,JackHessel,ClaireCardie,YejinChoi,andYuntianDeng. Wildchat: 1m
chatGPTinteractionlogsinthewild.InTheTwelfthInternationalConferenceonLearningRepresentations,
2024.
[48] AlexKrizhevsky,GeoffreyHinton,etal. Learningmultiplelayersoffeaturesfromtinyimages. 2009.
[49] HanXiao,KashifRasul,andRolandVollgraf. Fashion-mnist:anovelimagedatasetforbenchmarking
machinelearningalgorithms. arXivpreprintarXiv:1708.07747,2017.
[50] LiDeng. Themnistdatabaseofhandwrittendigitimagesformachinelearningresearch[bestoftheweb].
IEEEsignalprocessingmagazine,29(6):141–142,2012.
[51] ShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay,DennyZhou,QuocVLe,
BarretZoph,JasonWei,etal. Theflancollection:Designingdataandmethodsforeffectiveinstruction
tuning. InInternationalConferenceonMachineLearning,pages22631–22648.PMLR,2023.
[52] CanXu,QingfengSun,KaiZheng,XiuboGeng,PuZhao,JiazhanFeng,ChongyangTao,andDaxin
Jiang. Wizardlm: Empoweringlargelanguagemodelstofollowcomplexinstructions. arXivpreprint
arXiv:2304.12244,2023.
[53] HannahKirk,AndrewBean,BertieVidgen,PaulRöttger,andScottHale.Thepast,presentandbetterfuture
offeedbacklearninginlargelanguagemodelsforsubjectivehumanpreferencesandvalues.InProceedings
ofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages2409–2430,2023.
[54] RafaelRafailov,ArchitSharma,EricMitchell,ChristopherDManning,StefanoErmon,andChelseaFinn.
Directpreferenceoptimization: Yourlanguagemodelissecretlyarewardmodel. AdvancesinNeural
InformationProcessingSystems,36,2023.
[55] ChuntingZhou,PengfeiLiu,PuxinXu,SrinivasanIyer,JiaoSun,YuningMao,XuezheMa,AviaEfrat,
PingYu,LiliYu,etal. Lima: Lessismoreforalignment. AdvancesinNeuralInformationProcessing
Systems,36,2023.
[56] JiamingJi,MickelLiu,JosefDai,XuehaiPan,ChiZhang,CeBian,BoyuanChen,RuiyangSun,Yizhou
Wang,andYaodongYang. Beavertails:Towardsimprovedsafetyalignmentofllmviaahuman-preference
dataset. AdvancesinNeuralInformationProcessingSystems,36,2024.
12[57] YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna
Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai:Harmlessnessfrom
aifeedback. arXivpreprintarXiv:2212.08073,2022.
[58] EdwardJHu,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,WeizhuChen,etal.
Lora:Low-rankadaptationoflargelanguagemodels. InICLR,2021.
[59] QiangYang,YangLiu,TianjianChen,andYongxinTong. Federatedmachinelearning: Conceptand
applications. ACMTransactionsonIntelligentSystemsandTechnology(TIST),10(2):1–19,2019.
[60] JianyuWang,ZacharyCharles,ZhengXu,GauriJoshi,HBrendanMcMahan,MaruanAl-Shedivat,Galen
Andrew,SalmanAvestimehr,KatharineDaly,DeepeshData,etal. Afieldguidetofederatedoptimization.
arXivpreprintarXiv:2107.06917,2021.
[61] TheAyaProject. Aya:Anopenscienceinitiativetoacceleratemultilingualaiprogress. https://aya.
for.ai,2024. Accessed:2024-06-02.
[62] IttaiDayan,HolgerRRoth,AoxiaoZhong,AhmedHarouni,AmilcareGentili,AnasZAbidin,AndrewLiu,
AnthonyBeardsworthCosta,BradfordJWood,Chien-SungTsai,etal. Federatedlearningforpredicting
clinicaloutcomesinpatientswithcovid-19. Naturemedicine,27(10):1735–1743,2021.
[63] InternLMTeam. Internlm:Amultilinguallanguagemodelwithprogressivelyenhancedcapabilities,2023.
[64] LianminZheng,Wei-LinChiang,YingSheng,SiyuanZhuang,ZhanghaoWu,YonghaoZhuang,ZiLin,
Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. Judging
llm-as-a-judgewithmt-benchandchatbotarena,2023.
[65] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and
HannanehHajishirzi. Self-instruct: Aligninglanguagemodelswithself-generatedinstructions. arXiv
preprintarXiv:2212.10560,2022.
[66] NikitaKitaevandDanKlein. Constituencyparsingwithaself-attentiveencoder. InProceedingsofthe
56thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers),pages
2676–2686,2018.
[67] MingLi,YongZhang,ZhitaoLi,JiuhaiChen,LichangChen,NingCheng,JianzongWang,TianyiZhou,
andJingXiao. Fromquantitytoquality: Boostingllmperformancewithself-guideddataselectionfor
instructiontuning. arXivpreprintarXiv:2308.12032,2023.
[68] LaurensVanderMaatenandGeoffreyHinton. Visualizingdatausingt-sne. Journalofmachinelearning
research,9(11),2008.
[69] Wei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,Siyuan
Zhuang,YonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing. Vicuna: Anopen-source
chatbotimpressinggpt-4with90%*chatgptquality,March2023.
[70] AndyZou,ZifanWang,NicholasCarlini,MiladNasr,J.ZicoKolter,andMattFredrikson. Universaland
transferableadversarialattacksonalignedlanguagemodels,2023.
[71] AhmetÜstün,ViraatAryabumi,Zheng-XinYong,Wei-YinKo,DanielD’souza,GbemilekeOnilude,Neel
Bhandari,ShivalikaSingh,Hui-LeeOoi,AmrKayid,FreddieVargus,PhilBlunsom,ShayneLongpre,
Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. Aya model: An instruction
finetunedopen-accessmultilinguallanguagemodel,2024.
[72] YewKenChia,PengfeiHong,LidongBing,andSoujanyaPoria. InstructEval:Towardsholisticevaluation
ofinstruction-tunedlargelanguagemodels. InAntonioValerioMiceli-Barone,FazlBarez,ShayCohen,
ElenaVoita,UlrichGermann,andMichalLukasik,editors,ProceedingsoftheFirsteditionoftheWorkshop
ontheScalingBehaviorofLargeLanguageModels(SCALE-LLM2024),pages35–64,St.Julian’s,Malta,
March2024.AssociationforComputationalLinguistics.
[73] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob
Steinhardt. Measuringmassivemultitasklanguageunderstanding,2021.
[74] MarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveiraPinto,JaredKaplan,
HarriEdwards,YuriBurda,NicholasJoseph,GregBrockman,AlexRay,RaulPuri,GretchenKrueger,
MichaelPetrov,HeidyKhlaaf,GirishSastry,PamelaMishkin,BrookeChan,ScottGray,NickRyder,
MikhailPavlov,AletheaPower,LukaszKaiser,MohammadBavarian,ClemensWinter,PhilippeTillet,
FelipePetroskiSuch,DaveCummings,MatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-
Voss,WilliamHebgenGuss,AlexNichol,AlexPaino,NikolasTezak,JieTang,IgorBabuschkin,Suchir
13Balaji,ShantanuJain,WilliamSaunders,ChristopherHesse,AndrewN.Carr,JanLeike,JoshAchiam,
VedantMisra,EvanMorikawa,AlecRadford,MatthewKnight,MilesBrundage,MiraMurati,KatieMayer,
PeterWelinder,BobMcGrew,DarioAmodei,SamMcCandlish,IlyaSutskever,andWojciechZaremba.
Evaluatinglargelanguagemodelstrainedoncode,2021.
[75] RohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,
andTatsunoriB.Hashimoto. Stanfordalpaca:Aninstruction-followingllamamodel. https://github.
com/tatsu-lab/stanford_alpaca,2023.
[76] TianLi,ShengyuanHu,AhmadBeirami,andVirginiaSmith. Ditto:Fairandrobustfederatedlearning
throughpersonalization. InInternationalConferenceonMachineLearning,pages6357–6368.PMLR,
2021.
[77] RuiYe,ZhenyangNi,FangzhaoWu,SihengChen,andYanfengWang. Personalizedfederatedlearning
withinferredcollaborationgraphs.InInternationalConferenceonMachineLearning,pages39801–39817.
PMLR,2023.
[78] YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,
Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with
reinforcementlearningfromhumanfeedback. arXivpreprintarXiv:2204.05862,2022.
[79] DeepGanguli,LianeLovitt,JacksonKernion,AmandaAskell,YuntaoBai,SauravKadavath,BenMann,
EthanPerez,NicholasSchiefer,KamalNdousse,etal. Redteaminglanguagemodelstoreduceharms:
Methods,scalingbehaviors,andlessonslearned. arXivpreprintarXiv:2209.07858,2022.
[80] QuentinDAtkinsonandRussellDGray. Howoldistheindo-europeanlanguagefamily?illuminationor
moremothstotheflame. Phylogeneticmethodsandtheprehistoryoflanguages,91:109,2006.
[81] CynthiaDwork,FrankMcSherry,KobbiNissim,andAdamSmith. Calibratingnoisetosensitivityin
privatedataanalysis. InTheoryofCryptography:ThirdTheoryofCryptographyConference,TCC2006,
NewYork,NY,USA,March4-7,2006.Proceedings3,pages265–284.Springer,2006.
[82] KangWei,JunLi,MingDing,ChuanMa,HangSu,BoZhang,andH.VincentPoor. Performanceanalysis
andoptimizationinprivacy-preservingfederatedlearning. CoRR,abs/2003.00229,2020.
[83] MingLi,YongZhang,ShwaiHe,ZhitaoLi,HongyuZhao,JianzongWang,NingCheng,andTianyiZhou.
Superfiltering:Weak-to-strongdatafilteringforfastinstruction-tuning. arXivpreprintarXiv:2402.00530,
2024.
[84] WeiLiu,WeihaoZeng,KeqingHe,YongJiang,andJunxianHe. Whatmakesgooddataforalignment?a
comprehensivestudyofautomaticdataselectionininstructiontuning. arXivpreprintarXiv:2312.15685,
2023.
14A Limitations
Firstly,weexploreLlama-2[41]forinstructiontuningtaskandAlpaca[75]forpreferencealignment
task. More future works are required to explore more model series and sizes. Secondly, safety
alignmentisalsoanimportanttopicintheeraofLLMs,whichisnotcomprehensivelycoveredinour
paper. Thiscouldbeaninterestingandpromisingfuturedirection.
B Datasets
B.1 Lengthsmeasurement
Tomeasureeachdatasample, WeuseLlama2tokenizertotokenizetheinstructionandresponse
ofeachdatasampleandusethenumberoftokensasthesentencelength. Figure1(b)showsthe
distributionoflengthofinstructionandresponseofclients’dataofourfourdatasets.
B.2 Verbsandnouns
Weshowthetop20verbsandcorrespondingtop4nounsofinstructionsofoverallfourdatasetsin
Figure7. WerefertothevisualizationcodeofSelf-instruct[65]. Notethatforallfourdatasets,we
chooseclientswithEnglishsamples. FromFigure7,wecanobservethatdifferentdatasetspossess
diverseinstructiontypesanddistributions.Forexample,thetop2verbsforAyaandWildChatdatasets
are(explain,write)and(write,make),respectively;WhileChatbotITandChatbotPA,whicharefrom
thesamepublicdataset,havealargerangeofkeywordoverlapbutdifferentquantitydistributions.
Wealsoshowthetop20verbsandcorrespondingtop4nounsofinstructionsofindividualclients
fromfourdatasetsinFigure9,Figure10,Figure11andFigure12. Forallfourdatasets,wechoose
clientswithEnglishsamplestopresentverbsandnounsintheirinstructions.
B.3 Qualityevaluation
Weconductdataqualityevaluationwiththepre-trainedLlama2-7B[41]andtheIFDmetric[67].
IFDisaqualityevaluationmetric,qualifyingtheinstruction-followingdifficultyofthegivenmodel
asthedataquality. Ithasbeenwidelyusedin [83,18,84]. FromFigure3,wecanseethatclientsin
fourdatasetshavevariousdataqualities. Thisindicatesthesefourfederateddatasetsdemonstrate
qualityheterogeneity,whichisaninherentpropertyofrealdatasets.
B.4 t-SNEvisualization
We also implement the t-SNE instruction-response embedding in four datasets. Here the ’text-
embedding-ada-002’fromOpenAIisutilizedasthefeatureextractionmodel. Werandomlyselect10
clientsfromeachdatasetandusethet-SNEtwo-dimensionalvisualizationtodemonstratethedata
heterogeneityfromeachclient. FromFigure4,wecouldseethatdatapointsfromthesameclient
clusterinthefeaturespace. ThisisparticularlyevidentinFed-AyaandFed-WildChat,demonstrating
dataheterogeneitywithinthedataset.
B.5 Discussionaboutdataprivacyandsafety
Thebasedatasetsweconstructoursfromhavealreadyundergonescreeningsforsafetyandprivacy.
Forexample,inChatbot-arenaConversationsdataset,mostconversationsthatcontainpersonally
identifiableinformationhavebeenmoved. Fed-ChatbotIT,Fed-ChatbotPAandFed-WildChat,which
arebasedonChatbot-arenaConversationsdatasetandWildChatdataset,maycontainunsafeortoxic
interacts,buttheyarekeptsothatthesedatasetscanbebetterusedtostudyAIsafetyandsimulate
real-worlddialoguescenarios.
15(a) Aya (b) ChatbotIT
(c) WildChat (d) ChatbotPA
Figure7: Thetop20mostcommonrootverbs(innercircle)andtheirtop4directnounobjects(outer
circle)intheinstructionsoffourdatasets.
C Experiments
C.1 Experimentalsetups
WereportthedetailedexperimentalsetupsinTable7. Foreachtable,werandomlysampletwoclients
toconductlocaltrainingandaveragetheirperformanceasthefinalresultsof‘localtraining’inthe
table. WeusedynamiclocalstepsforlocaltraininginChatbotPA.Wecalculatetheprobabilityofa
userbeingselectedinaroundgivenparameterssuchasthetotalnumberofrounds,thenumberof
clientssampledperround,andthetotalnumberofclients. Wethenadjustthelocaltrainingsteps
foreachclientbasedontheirsamplingprobabilityanddatavolume,ensuringthateachclient’sdata
canundergoaboutthreeepochsoftrainingintotal. Ourexperimentsweremainltconductedona
machineequippedwithanNVIDIAGeForceRTX3090GPUwith24GBofVRAM.Experiments
onFed-WildChat(Multi-Turn)wereconductedonamachineequippedwithanNVIDIAA40with
48GBofVRAM.
16Table7: Experimentalsetupsofalldatasets. ‘Localepochs’denotesthenumberoftrainingepochsin
localtraining. Inthecolumnof‘Clients’,x/ydenotesthatthereareyclientsintotalandwesamex
clientsforeachround.
Dataset LocalEpochs Clients LocalSteps GlobalRounds
Fed-Aya 5 4/38 10 200
Fed-ChatbotIT 10 10/237 5 100
Fed-WildChat 5 5/100 10 100
Fed-WildChat(Multi-Turn) 20 3/50 10 50
Fed-ChatbotPA 10 10/747 Dynamic 200
Table8: MT-BenchonWildChatwithDifferentialPrivacyandfixedσ. FedLLMwithDP(σ=0.1)still
outperformslocalanddifferentialprivacycostsslightmodelperformancewhileensuringuser-level
differentialprivacy.
local(813) local(1702) FedAvg FedDP-1e−3 FedDP-1e−2 FedDP-0.1 FedDP-1
3.5375 4.0875 4.6875 4.6750 4.5500 4.5375 1.6875
C.2 Evaluation
Here,weshowtheprompttemplateusedinGPT-4JudgeinFigure8. ForthespecificdatasetAya,
we utilize some test samples from the raw dataset, where each sample contains a question and a
referenceanswer. Weinferthetestedmodelwiththequestionandobtainananswer. Thenwefillin
the"question","answer"and"reference"blanksofthetemplate.
Prompt:
[Instruction]
Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question
displayed below. A good answer should follow these rules:
1.It should be in the same language as the question.
2. It should answer the request in the instruction.
3.It should be factually and semantically comprehensible.
4. It should be grammatically correct and fluent.
Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation,
you must rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating:
[[5]]\". A human annotated answer is given for reference.
[Question]
{question}
[The Start of Assistant's Answer]
{answer}
[The End of Assistant's Answer]
[Reference]
{reference}
Figure8: PrompttemplateusedinGPT-4judge.
D Moredetailsaboutdifferentialprivacy
D.1 Definition
Differential privacy (DP) [81] has emerged as a broadly recognized framework for safeguarding
privacyinstatisticalanalyses. ThroughDP,wecanperformcomputationsonextensivedatasetswhile
ensuringthatindividualdatapointsremainindistinguishable,therebyprotectingpersonalprivacy.
In general, we use privacy parameters ϵ and δ to formally define DP. Specifically, a randomized
mechanism M : D → R is (ϵ,δ)-differential private for ϵ > 0 and δ ∈ [0,1) if for any two
neighboringdatasetsD,D′ ∈DdifferingbyatmostoneentryandforanysubsetofoutputsR⊆R
17itholdsthat
P(M(D)∈R)≤exp(ϵ)P(M(D′)∈R)+δ.
D.2 User-leveldifferentialprivacy
Weimplementuser-leveldifferentialprivacy(UDP)[82]inourexperiments. Following[82],weuse
theGaussianmechanismthatemploystheL normsensitivity. Itaddszero-meanGaussiannoise
2
withvarianceσ2Itoeachcoordinateofthefunctionoutputr(D)asfollows:
M(D)=r(D)+N(0,σ2I),
whereIisanidentitymatrixofthesamesizeasr(D). Thesensitivityofthefunctionrisexpressed
as:
∆r = max ∥r(D)−r(D′)∥ ,
2
D,D′∈D
whichprovidesanupperboundonthenecessaryperturbationtoitsoutputforprivacypreservation.
Byappropriatelyselectingthevalueofσ,thismechanismsatisfies(ϵ,δ)-differentialprivacy.
D.3 Experimentdetailsofdifferentialprivacy
InourexperimentswithUDP,weuseWildChatdataset. Forconvenience,thebatchsizeis1inallDP
experimentsandothersettingsarethesameassingle-turnWildChatexperimentsetting,seedetailsin
Section4.
WeaddGaussiannoisecautiouslycontrolledbyσwhenlocalclientsuploadtheirlocalmodelstothe
server,ensuringUser-leveldifferentialprivacy. Following[82],thevalueofσiscalculatedby:
(cid:113)
2qNln1
δ
σ =δ
l ϵ
whereq isthesamplefractionofclientseachround, N isthefederatedlearningcommunication
round,(ϵ,δ)istheDPparametersanddelta isdecidedasfollows:
l
2ηC
δ =
l |D|
|n|
whereηisthelearningrate,C isthemaximumofgradients,|D|isthesizeofdatasetand|n|isthe
numberofclients. Notethatwhenexpressedwith(ϵ,δ),smallerϵmeanssmallerprivacybudget,in
otherwords,betterprivacyandusuallylowerperformance. However,whenexpressedwithσ,larger
σmeansbetterprivacyandusuallylowerperformance.
Our experiment results are shown in Figure 6 and Table 8. Figure 6 shows that FedLLM with
(0.01,1e−4)-DPstilloutperformslocaltraininganddifferentialprivacycostsslightmodelperfor-
mancewhileensuringuser-leveldifferentialprivacy.
Infact,theσcalculatedinSectionD.2isaproperboundwhenensuringuser-leveldifferentialprivacy
withgiven(ϵ,δ). WealsoconductexperimentswithfixedσandresultsareshowninTable8.
18Figure9: Thetop20mostcommonrootverbs(innercircle)andtheirtop4directnounobjects(outer
circle)intheinstructionsofAyafor12differentEnglishclients. WeselectEnglishclientsonpurpose.
19Figure10: Thetop20mostcommonrootverbs(innercircle)andtheirtop4directnounobjects
(outercircle)intheinstructionsofChatbotITfor20differentclients.
20Figure11: Thetop20mostcommonrootverbs(innercircle)andtheirtop4directnounobjects
(outercircle)intheinstructionsofWildChatfor20differentclients.
21Figure12: Thetop20mostcommonrootverbs(innercircle)andtheirtop4directnounobjects
(outercircle)intheinstructionsofChatbotPAfor20differentclients.
22