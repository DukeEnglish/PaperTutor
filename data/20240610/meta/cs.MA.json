[
    {
        "title": "Massively Multiagent Minigames for Training Generalist Agents",
        "authors": "Kyoung Whan ChoeRyan SullivanJoseph Suárez",
        "links": "http://arxiv.org/abs/2406.05071v1",
        "entry_id": "http://arxiv.org/abs/2406.05071v1",
        "pdf_url": "http://arxiv.org/pdf/2406.05071v1",
        "summary": "We present Meta MMO, a collection of many-agent minigames for use as a\nreinforcement learning benchmark. Meta MMO is built on top of Neural MMO, a\nmassively multiagent environment that has been the subject of two previous\nNeurIPS competitions. Our work expands Neural MMO with several computationally\nefficient minigames. We explore generalization across Meta MMO by learning to\nplay several minigames with a single set of weights. We release the\nenvironment, baselines, and training code under the MIT license. We hope that\nMeta MMO will spur additional progress on Neural MMO and, more generally, will\nserve as a useful benchmark for many-agent generalization.",
        "updated": "2024-06-07 16:41:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.05071v1"
    },
    {
        "title": "Online Frequency Scheduling by Learning Parallel Actions",
        "authors": "Anastasios GiovanidisMathieu LeconteSabrine ArouaTor KvernvikDavid Sandberg",
        "links": "http://arxiv.org/abs/2406.05041v1",
        "entry_id": "http://arxiv.org/abs/2406.05041v1",
        "pdf_url": "http://arxiv.org/pdf/2406.05041v1",
        "summary": "Radio Resource Management is a challenging topic in future 6G networks where\nnovel applications create strong competition among the users for the available\nresources. In this work we consider the frequency scheduling problem in a\nmulti-user MIMO system. Frequency resources need to be assigned to a set of\nusers while allowing for concurrent transmissions in the same sub-band.\nTraditional methods are insufficient to cope with all the involved constraints\nand uncertainties, whereas reinforcement learning can directly learn\nnear-optimal solutions for such complex environments. However, the scheduling\nproblem has an enormous action space accounting for all the combinations of\nusers and sub-bands, so out-of-the-box algorithms cannot be used directly. In\nthis work, we propose a scheduler based on action-branching over sub-bands,\nwhich is a deep Q-learning architecture with parallel decision capabilities.\nThe sub-bands learn correlated but local decision policies and altogether they\noptimize a global reward. To improve the scaling of the architecture with the\nnumber of sub-bands, we propose variations (Unibranch, Graph Neural\nNetwork-based) that reduce the number of parameters to learn. The parallel\ndecision making of the proposed architecture allows to meet short inference\ntime requirements in real systems. Furthermore, the deep Q-learning approach\npermits online fine-tuning after deployment to bridge the sim-to-real gap. The\nproposed architectures are evaluated against relevant baselines from the\nliterature showing competitive performance and possibilities of online\nadaptation to evolving environments.",
        "updated": "2024-06-07 16:14:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.05041v1"
    },
    {
        "title": "FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models",
        "authors": "Rui YeRui GeXinyu ZhuJingyi ChaiYaxin DuYang LiuYanfeng WangSiheng Chen",
        "links": "http://arxiv.org/abs/2406.04845v1",
        "entry_id": "http://arxiv.org/abs/2406.04845v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04845v1",
        "summary": "Federated learning has enabled multiple parties to collaboratively train\nlarge language models without directly sharing their data (FedLLM). Following\nthis training paradigm, the community has put massive efforts from diverse\naspects including framework, performance, and privacy. However, an unpleasant\nfact is that there are currently no realistic datasets and benchmarks for\nFedLLM and previous works all rely on artificially constructed datasets,\nfailing to capture properties in real-world scenarios. Addressing this, we\npropose FedLLM-Bench, which involves 8 training methods, 4 training datasets,\nand 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM\ncommunity. FedLLM-Bench encompasses three datasets (e.g., user-annotated\nmultilingual dataset) for federated instruction tuning and one dataset (e.g.,\nuser-annotated preference dataset) for federated preference alignment, whose\nscale of client number ranges from 38 to 747. Our datasets incorporate several\nrepresentative diversities: language, quality, quantity, instruction, length,\nembedding, and preference, capturing properties in real-world scenarios. Based\non FedLLM-Bench, we conduct experiments on all datasets to benchmark existing\nFL methods and provide empirical insights (e.g., multilingual collaboration).\nWe believe that our FedLLM-Bench can benefit the FedLLM community by reducing\nrequired efforts, providing a practical testbed, and promoting fair\ncomparisons. Code and datasets are available at\nhttps://github.com/rui-ye/FedLLM-Bench.",
        "updated": "2024-06-07 11:19:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04845v1"
    },
    {
        "title": "Software Engineering for Collective Cyber-Physical Ecosystems",
        "authors": "Roberto CasadeiGianluca AguzziGiorgio AudritoFerruccio DamianiDanilo PianiniGiordano ScarsoGianluca TortaMirko Viroli",
        "links": "http://arxiv.org/abs/2406.04780v1",
        "entry_id": "http://arxiv.org/abs/2406.04780v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04780v1",
        "summary": "Today's distributed and pervasive computing addresses large-scale\ncyber-physical ecosystems, characterised by dense and large networks of devices\ncapable of computation, communication and interaction with the environment and\npeople. While most research focusses on treating these systems as \"composites\"\n(i.e., heterogeneous functional complexes), recent developments in fields such\nas self-organising systems and swarm robotics have opened up a complementary\nperspective: treating systems as \"collectives\" (i.e., uniform, collaborative,\nand self-organising groups of entities). This article explores the motivations,\nstate of the art, and implications of this \"collective computing paradigm\" in\nsoftware engineering, discusses its peculiar challenges, and outlines a path\nfor future research, touching on aspects such as macroprogramming, collective\nintelligence, self-adaptive middleware, learning, synthesis, and\nexperimentation of collective behaviour.",
        "updated": "2024-06-07 09:28:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04780v1"
    },
    {
        "title": "Quantifying Misalignment Between Agents",
        "authors": "Aidan KieransAvijit GhoshHananel HazanShiri Dori-Hacohen",
        "links": "http://arxiv.org/abs/2406.04231v1",
        "entry_id": "http://arxiv.org/abs/2406.04231v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04231v1",
        "summary": "Growing concerns about the AI alignment problem have emerged in recent years,\nwith previous work focusing mainly on (1) qualitative descriptions of the\nalignment problem; (2) attempting to align AI actions with human interests by\nfocusing on value specification and learning; and/or (3) focusing on a single\nagent or on humanity as a singular unit. Recent work in sociotechnical AI\nalignment has made some progress in defining alignment inclusively, but the\nfield as a whole still lacks a systematic understanding of how to specify,\ndescribe, and analyze misalignment among entities, which may include individual\nhumans, AI agents, and complex compositional entities such as corporations,\nnation-states, and so forth. Previous work on controversy in computational\nsocial science offers a mathematical model of contention among populations (of\nhumans). In this paper, we adapt this contention model to the alignment\nproblem, and show how misalignment can vary depending on the population of\nagents (human or otherwise) being observed, the domain in question, and the\nagents' probability-weighted preferences between possible outcomes. Our model\ndeparts from value specification approaches and focuses instead on the morass\nof complex, interlocking, sometimes contradictory goals that agents may have in\npractice. We apply our model by analyzing several case studies ranging from\nsocial media moderation to autonomous vehicle behavior. By applying our model\nwith appropriately representative value data, AI engineers can ensure that\ntheir systems learn values maximally aligned with diverse human interests.",
        "updated": "2024-06-06 16:31:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04231v1"
    }
]