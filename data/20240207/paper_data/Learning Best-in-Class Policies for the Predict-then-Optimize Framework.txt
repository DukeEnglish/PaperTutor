Learning Best-in-Class Policies for the Predict-then-Optimize Framework
MichaelHuang*12 VishalGupta*1
Abstract vehicle routing, portfolio allocation, and inventory man-
agement (Elmachtoub&Grigas, 2022; Dontietal., 2017;
We propose a novel family of decision-aware
Wilderetal.,2019).
surrogate losses, called Perturbation Gradient
(PG)losses,forthepredict-then-optimizeframe- The predict-then-optimize framework focuses on plug-in
work. These losses directly approximate the policies for Problem (1). Given a function f : ,
X 7→ Y
downstream decision loss and can be optimized thecorrespondingplug-inpolicyis
using off-the-shelf gradient-basedmethods. Im-
portantly, unlike existing surrogate losses, the πˆ(f(X)) argminf(X) ⊤z, (2)
∈ z
approximation error of our PG losses vanishes ∈Z
as the number of samples grows. This implies with ties broken by some pre-specified tie-breaking rule.
that optimizing our surrogate loss yields a best- Plug-in policies are attractive because they separate the
in-class policyasymptotically, evenin misspeci- prediction procedure(f) from the optimization procedure
fied settings. Thisis the first such resultin mis- (Problem (2)). This decouplingis especially useful when
specified settings and we provide numerical ev- i)decisionszmustsatisfyhardconstraints(modeledby )
Z
idence confirming our PG losses substantively sinceProblem(2)enforcesthembyconstruction,orii)one
outperformexistingproposalswhentheunderly- has a specialized algorithm for solving instances of Prob-
ingmodelismisspecifiedandthenoiseisnotcen- lem(2)(e.g.,acustomvehicle-routingsolver).
trally symmetric. Insofar as misspecification is
Giventheformofπ ,anaturalapproachmightbetolearn
∗
commonplace in practice – especially when we anestimatefˆoff fromthedata,e.g.,byminimizingthe
∗
mightpreferasimpler,moreinterpretablemodel mean-squarederror,andthencomputeπˆ(fˆ(X)). Suchpro-
– PG losses offer a novel, theoretically justified,
ceduresarecalleddecision-blindsincewedonotleverage
method for computationally tractable decision- Problem(1)whenlearningfˆ.
awarelearning.
In their seminal paper (Elmachtoub&Grigas, 2022), the
authors argue decision-aware techniques are superior to
1. Introduction decision-blind ones. Namely, for a fixed hypothesis
class , they propose minimizing the regret
X
Westudythecontextualoptimizationproblem min F R⊆ egreY t(f)whereRegret(f) E Y πˆ(f(X))
f ⊤
π ∗(X) argminf ∗(X) ⊤z, f ∗(X) E[Y X], (1) E Y ⊤∈F πˆ(f ∗(X)) . Thisisequivalent≡ toso (cid:2)lving (cid:3)−
∈ z ≡ |
∈Z (cid:2) minE[ℓ(f((cid:3) X),Y)] whereℓ(t,Y) y πˆ(t). (3)
⊤
where (X,Y) are random variables, and f ≡
Rd is a kn∈ ownX , p× oteY ntially non-convex feasible re- ∈F
Z ⊆ Growing empirical evidence supports the strength of
gion. We work in a data-drivensetting in which f is un-
∗ decision-aware approaches in a variety of settings
known, but we have a dataset (X ,Y ) : i = 1,...,n
{ i i } (Tang&Khalil,2022;Sadanaetal.,2023).
of i.i.d. draws of (X,Y). Problem (1) models appli-
cations in which we observe a potentially informative The challengeis that when is polyhedralor combinato-
Z
context X before selecting the decision π(X) such as rialt ℓ(t,y)isapiecewiseconstant,discontinuousmap.
7→
Itsgradientiseitherzeroorundefinedatallpoints. Hence,
*Equalcontribution 1DataSciencesandOperations,USCMar-
onecannoteasilyapplyafirst-ordermethodlikestochastic
shallSchoolofBusiness,LosAngeles,CA,USA2CUNYBaruch
gradient descent (SGD) to optimize Problem (3) or other
Zicklin School of Business, New York, NY, USA. Correspon-
dence to: Vishal Gupta <guptavis@usc.edu>, Michael Huang gradientbasedalgorithmstosolveitsempiricalcounterpart.
<michael.huang96@login.cuny.edu>. Moreloosely,thegradientsare“uninformative.”
Preliminarywork. UnderreviewbytheInternationalConference Inthispaperwe proposea new familyofsurrogatelosses
onMachineLearning(ICML).Donotdistribute. to approximate ℓ(t,y) based on Danskin’s theorem. We
1
4202
beF
5
]GL.sc[
1v65230.2042:viXraLearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
call this family perturbation gradient (PG) losses. PG m= 4 m=0
−
lossesareLipschitzcontinuous,generalpurpose,andeasy- 40%
to-compute given a black-box oracle which solves Prob- ETO
lem(2).Mostimportantly,theirgradientsare“informative” SPO+
30%
(c.f. Lemma2.2);afterreplacingℓwithaPGloss,onecan PGB
applySGDtoProblem(3)out-of-the-box,oruseagradient-
PGC
20%
basedmethodtosolveitsempiricalcounterpart.
Previousauthorshavealso proposedsurrogateswhichsat-
10%
isfy some of these properties(see Section 1.2). What dis-
tinguishes our work is that under fairly mild assumptions
0%
on the distribution of (X,Y), we prove that the error of
50 100 150 200 50 100 150 200
oursurrogateinapproximatingℓ(t,y)vanishesasn
→∞ n
with a rate that depends on the complexity of . Specif-
F Figure1.(Effect of misspecification.) Relative regret under
ically, for general , we prove the excess regret (i.e. the
Z well-specified (left) and misspecified (right) settings. See Sec-
differenceinregrettothebest-in-classmember)essentially
tion 4.1 for experimental setup. ETO-Linear is a decision-
scaleslike O˜ p(√Rn+n −1/2)whereRn isthe multivari-
blind approach that minimizes MSE. SPO+ is the method of
ate Rademacher complexityof (Theorem 3.5). For lin- (Elmachtoub&Grigas, 2022). PGB and PGC are our proposed
F
ear hypotheses with dim(X) = p, this bound reduces to backwardandcentraldifferencelosses.Allmethodsachieveclose
O˜ ((dp/n)1/4). When is polyhedral, we prove the ex- tozeroregretinthewell-specifiedsetting. Butundermisspecifi-
p
Z
cation,onlythePGlossesconvergetozeroregret.
cess regret is at most O˜
p
νlog( n|Z∠ |) (Theorem 3.9),
whereν
isVClinearsugra(cid:18) pqhdimension(cid:19)
of and ∠ are oftheexpectedloss(Lemma2.2).Inotherwords,gra-
F Z
theextremepointsof (Theorem3.9). Bothboundsvan- dientsare“informative”,andwecanapplyfirst-order
Z
ishasngrows,implyingthatoptimizingoursurrogateloss schemes like SGD in the usual way to minimize the
yieldsabest-in-classpolicyasymptotically(Theorems3.5 expectedsurrogateloss,orusegradient-basedsolvers
and3.9). tominimizetheERMloss.
• We bound the uniform error of our surrogates by a
Critically, our results hold even when f (misspec-
∗
ified setting). To our knowledge, these
a6∈ reF
the first re-
termvanishinginn(Theorems3.5and3.9).Ourproof
utilizes a novel technique that conditions on realiza-
sult of their kind. All existing results on the predict-then-
optimize framework (e.g., Liu&Grigas (2021); Huetal. tions of Y (not X) to bound total variation distance
whichmaybeofindependentinterest.
(2022);Elmachtoubetal.(2023))requiref (thewell-
∗
∈F • Optimizing our surrogate loss yields a best-in-class
specifiedsetting)andsomewhatrestrictiveassumptionson
policy (with respect to the true loss) asymptotically,
thenoiseY f (X)(seeSection1.2). Thisassumptionis
∗
− even if the underlying hypothesis class is misspeci-
notsimplya weaknessin the analysis. Aswe illustratein
fied. To the best of our knowledge, ours is the first
Figure1,existingmethodscanhaveverypoorperformance
computationallyfeasibleproposalforthepredict-then-
under misspecification. As we argue in Section 1.2, the
optimizeframeworkwithsuchaperformanceguaran-
misspecified setting is perhapsthe more theoreticallyrich
tee.
settingfordecision-awarelearning,and,practicallyspeak-
• Weprovidenumericalevidenceshowingthatminimiz-
ing, misspecificationiscommon–especiallywhenprefer-
ing our surrogateloss performscomparablyto SPO+
ringsimplermodelsfortheirexplainabilityorinterpretabil-
when the hypothesisclass is well-specified, and sub-
ity. Hence, we see PG losses as an important theoretical
stantively outperformsSPO+ and decision-blind pro-
andpracticaladvancementin predict-then-optimizeproce-
cedureswhenthehypothesisclassismisspecified.
dures.
1.2.RelatedWork
1.1.Contributions
• We propose a new family of surrogate losses called Elmachtoub&Grigas (2022) first proposed a convex, dif-
PerturbationGradient(PG)lossesforthepredict-then- ferentiablesurrogatelossforProblem(3)calledtheSPO+
optimizeapproachtoProblem(1). Oursurrogatesare loss. The SPO+ lossupperboundsl(t,y). Subsequentre-
Lipschitzcontinuousandcanbeexpressedasthedif- searchershaveproposedotherapproachesincludingreplac-
ferenceofconcavefunctions. ingtheplug-inpolicyProblem(2)witharegularizedcoun-
• WeshowthatthegradientofaPGlossevaluatedata terpart (Wilderetal., 2019), creating a response-surface
sample point is an unbiased estimate of the gradient (Shahetal., 2022; Grigasetal., 2021), or randomized-
smoothing(Berthetetal.,2020). Therecentcomputational
2
tergeRevitaleRLearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
study Tang&Khalil (2022) compares many of these ap- Finally, there are non-surrogatebased approachesto solv-
proachesandfoundthatSPO+performedbestornear-best ing Problem (3). Pogancˇic´etal. (2019) suggest a back-
on all benchmarks. Hence, we benchmark our approach propagation algorithm based on linearizing the objective,
againstSPO+inourexperiments. but again provide no regret guarantee. Structured pre-
diction methods (see Osokinetal. (2017); Goh&Jaillet
Despitetheempiricalstrengthsofdecision-awaremethods,
(2016)andreferencestherein)treatProblem(3)asatypeof
theirtheoreticaljustificationislessclear. Fewmethodses-
multi-classclassificationproblem,ofteninadecision-blind
tablish regret bounds. Wilderetal. (2019); Berthetetal.
way. We focus on decision-aware methods. Policy learn-
(2020) prove that gradients of particular surrogates can
ingmethods((Ban&Rudin,2019;Tulabandhula&Rudin,
be evaluated easily, but do not prove a regret guarantee
2013;Wager&Athey,2017)andreferencestherein)learn
for the minimizer of those surrogates. On the other hand,
the mappingX π(X) by parameterizingit with a spe-
ElBalghitietal.(2022);Huetal.(2022)provegeneraliza- 7→
cific, tractable functionalform. In our setting, when is
tion guarantees relating E[ℓ(f(X),Y)] to its empirical Z
polyhedral, π (X) is a necessarily an extreme point, and
counterpart; hence, if one finds an f with small em- ∗
pirical loss, one is assured
E[l(f(X∈ ),YF
)] is also small.
identifyinganappropriatefunctionalformcanbedifficult.
But minimizing the empirical counterpart to Problem (3)
1.3.NotationandPreliminaries
iscomputationallychallenging.Hence,itisunclearhowto
findsuchf. Throughout, we write a . b to mean that there exists a
universalconstantC suchthata Cb. We denotethe ℓ
The strongest known performance guarantees are for the 2
≤
normby .
SPO+ loss in the well-specified setting (f
∗
). When
k·k
∈ F
the conditional distribution of Y X is centrally sym- To simplify the presentation, we also make the following
|
metric around its mean, Elmachtoub&Grigas (2022) es- boundednessassumptionthroughout:
tablish a Fisher-consistency result. Liu&Grigas (2021)
Assumption1.1(Boundedness). ThereexistsB >0such
strengthen this result, establishing a calibration bound
thatmax z B. Moreover, Y 1,almostsurely.
whichimplies(undersimilarassumptions)thatifthemulti- z ∈Zk k≤ k k≤
variateRademachercomplexityof isO(n 1/2),thenthe
−
F 2. ANew FamilyofSurrogate Losses
empirical minimizer of the SPO+ loss has regret at most
O(n 1/4).
− Definetheplug-inpolicyobjective:
That said, such results are perhaps unsatisfying because
decision-blindmethodstypicallydominatedecision-aware V(t) = min t ⊤z = t ⊤πˆ(t).
z
methods in well-specified settings. Huetal. (2022) show ∈Z
thatwhenf ,theregretofadecision-blindapproach EvaluatingV innomoredifficultthansolvingProblem(2).
∗
∈ F
that minimizes MSE and uses the corresponding plug-in Asaminimumoflinearfunctions,V(t)isconcave.
policy converges to zero faster than the empirical mini-
OurfirstkeyobservationisthatbyDanskin’sTheorem,
mizerofProblem(3). Elmachtoubetal.(2023)provethat
the regret of a decision-blind policy stochastically domi- ∂
natestheregretoftheempiricalminimizerofProblem(3).
∂λV(t+λY) |λ=0=Y⊤πˆ(t)=l(t,y). (4)
Said differently, decision-aware methods offer the most
WecanthusformafamilyofPGsurrogatesbyconsidering
benefit in misspecified settings. Hence, these settings are
differentapproximationstothederivativeontheleft.Inthis
arguablymostinterestingtheoreticallyandpractically.
paper,wefocusontwospecificfinite-differenceschemes:
Mostcloselyrelatedtoourworkareperturbation-basedap-
proachesforestimatingout-of-sampleperformance.These
• BackwardDifferencing(PGB):
workseachuseacleverapplicationofDanskin’stheoremto
deriveanestimateofout-of-sampleperformance. Itoetal. 1
ℓˆb(t,y) (V(t) V(t hy))
(2018);Guoetal.(2022)eachestablishasymptoticconver- h ≡ h − −
genceoftheirestimators(withoutanexplicitrate):Itoetal.
(2018) treats a non-contextual setting and focuses on the • CentralDifferencing(PGC):
ERMestimator. Guoetal.(2022)treatsacausalinference
1
setting. By contrast, Guptaetal. (2022; 2024) establish a ℓˆc(t,y) (V(t+h) V(t h)),
h ≡ 2h − −
finite-sample regret guarantee, but in a small-data, large-
scale data regime with nearly-Gaussian corruptions. In
for some user-definedh > 0. Intuitively,as h 0, both
thispaper,wefocusonthetraditionallarge-sampleregime ℓˆb(t,y)andℓˆc(t,y)shouldbetterapproximateth→
eleftside
(n )withcontexts. h h
→∞ ofEquation(4)andthusapproximateℓ(t,y).
3LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
Backward and central finite differencing are not the only 3. PerformanceGuarantees
waystoapproximateaderivative(e.g.,onemightconsider
Theprimaryadvantageofoursurrogatelossisthatitadmits
higher-orderfinitedifferenceschemes). Studyinghowdif-
formalperformanceguaranteesinthemisspecifiedsetting.
ferentapproximationschemesaffectthequalityofthesur-
We next develop those guarantees. For brevity, we focus
rogatelossisanopenareaofresearch.
onthebackwardPGlossinthissection. Analagousresults
Using the structure of Problem (1), we prove some key holdforthecentralPGloss.
propertiesofoursurrogates.
Lemma 2.1 (Properties of PG Losses). Suppose Assump- 3.1.KeyIdea
tion1.1holds. Foranyt,t Randy ,thePGlosses
′ ∈ ∈Y Our first observation is that the error in our surrogate is
are
boundedby the solution stability of the policy. A similar
a) LipschitzContinuous: boundisusedinGuptaetal.(2024)inadifferentcontext:
Lemma 3.1 (Solution Stability Bounds Error). For any
2B
ℓˆb(t,y) ℓˆb(t ′,y) t t
′
, t,y,h,
− ≤ h k − k
(cid:12) (cid:12) (cid:12)ℓˆc(t,y) ℓˆb(t ′,y)(cid:12) (cid:12)
(cid:12)
B t t
′
. 0
≤
ℓˆb h(t,y) −ℓ(t,y) ≤y ⊤(πˆ(t −hy) −πˆ(t))
− ≤ hk − k
(cid:12) (cid:12) SolutionStability
b) Bounded(cid:12): (cid:12)
(cid:12) (cid:12) | {z }
Inwords,solutionstabilitymeasureshowmuchthepolicy
ℓˆb(t,y) B, ℓˆc(t,y) B. changesgiven small perturbationhy. Notions of stability
≤ ≤
appear throughoutthe machine learning literature and are
(cid:12) (cid:12) (cid:12) (cid:12)
c) Differenti(cid:12)able: (cid:12) (cid:12) (cid:12) fundamental to learnability (Shalev-Shwartzetal., 2010).
(cid:12) (cid:12) (cid:12) (cid:12)
Lemma3.1relatestheerrorofoursurrogatetothisfunda-
1
ℓˆb(t,y)= (πˆ(t) πˆ(t hy)), mentalquantity.Westresstherelationholdsforanyt,h,y.
t
∇ h − −
1 To proveaperformanceguarantee,we willneedtobound
ℓˆc(t,y)= (πˆ(t+hy) πˆ(t hy)).
∇t 2h − − E ℓˆb(f(X),Y) ℓ(f(X),Y) , which by Lemma 3.1
h −
ishat most E Y πˆ(f(X) hiY) E Y πˆ(f(X))) .
⊤ ⊤
Finally,thebackwarddifferenceupperboundsthetrueloss, − −
By Assumption 1.1, the function (t,y) y πˆ(t)
⊤
(cid:2) (cid:3) (cid:2) 7→ (cid:3)
d) Upper-Bound: is a bounded map, bounded by B. Hence,
E Y (πˆ(f(X) hY) πˆ(f(X))) isatmost
⊤
ℓ(t,y) ℓˆb(t,y). − −
≤ (cid:2) Y (cid:3) Y
B TV , ,
Propertyd)mirrorstheupper-boundpropertyoftheSPO+ · f(X) hY f(X)
(cid:18)(cid:18) − (cid:19) (cid:18) (cid:19)(cid:19)
loss. Intuitively, a backward-finite difference of the con-
whereTV(, )isthetotalvariationdistance.
cavefunctionλ V(t+λY)overestimatesthetruederiva- · ·
7→
tive. Thistotalvariationdistancemaynotbesmall;considerthe
casewheref(X)isconcentratedatasinglepoint.Wenext
Althoughtheabovepropertiesaretheoreticallyelegant,the
introduceanassumptiontoboundthisdistance:
primary advantage of our surrogates over the loss ℓ is
Assumption3.2(LipschitzLogConditionalDensity). Let
that gradients are “informative.” More precisely, because
ℓ is discontinuous, E[ℓ(t,Y)] = E[ ℓ(t,Y)], and g( ;f,Y)betheconditionaldensityoff(X) Y. Weas-
t t · |
ℓ(t,Y ) is not an∇ unbiased estim6 ate o∇ f E[ℓ(t,Y)]. sumethatthereexistsaconstantL>0suchthatg( ;f,Y)
t j t ·
∇ ∇ isL-Lipschitzforallf andallY almostsurely.
Oursurrogatesdonothavethisproblem.
∈F
Lemma 2.2 (Informative Gradients). Suppose Assump- Assumption 3.2 is sufficient but not necessary. Other as-
tion 1.1 holds. For all t and Y, E ℓˆb(t,Y) = sumptionsmightalsoensuretheaboveTVdistanceissmall.
∇t h
Forexampleexample,Arbasetal.(2023)showiff(X)is
E ℓˆb(t,Y) .Inparticular, ℓˆb(t,Y )ihsanunbiiased
∇t h ∇t h j amultivariateGaussian,thencorrespondingTVdistanceis
eshtimate of iE ℓˆb(t,Y) . Finally, identical statements mostO(h). WehaverequiredAssumption3.2toholduni-
∇t h
formlyforallf inordertosimplifythestatementof
holdafterreplacihngℓˆb byℓiˆc. ∈ F
h h ourperformanceguaranteesbelow.
Crucially,Lemma2.2impliesthatwecanapplystochastic In any case, Assumption 3.2 allows us to bound the ex-
gradientdescentout-of-the-boxtooptimizeourPGlosses. pectedapproximationerrorofoursurrogate(bybounding
4LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
the expected solution stability) without any additional as- Morespecifically,themultivariateRademachercomplexity
sumptionsonthestructureofProblem(2): isdefinedasfollows,
Lemma3.3(ExpectedApproximationError). SupposeAs- Rn( )=E Rˆn( ) (5)
sumptions 1.1 and 3.2 hold and h < 1. Then, for any F F
L
f , h i 1 n
∈F =E D"fsupE σ
"n
σ i⊤f(X i)
##
0 E ℓˆb(T,Y) ℓˆ(T,Y) (e 1)B L h ∈F Xi=1
≤ h − ≤ − · · where σ = (σ ,...,σ ) and σ are i.i.d. Rademacher
h i i i1 id ij
randomvariables. NotethemultivariateRademachercom-
UsingLemma3.3andHoeffding’sinequality,weimmedi- plexityonlydependsonthedataand ,butnot .
atelygetapointwisebound. F Z
Usingthevectorcontractioninequality,weprove:
Corollary3.4(PointwiseApproximationError). Fixsome
Theorem3.5(UniformErrorBoundforGeneral ). Sup-
f . SupposeAssumptions1.1and3.2holdandh< 1. Z
∈F L pose Assumptions 1.1 and 3.2 hold. For any 0 < δ < 1
Then,forany0<δ < 1,withprobabilityatleast1 δ, 2
2 − and0<h< 1,withprobabilityatleast1 δ
L −
n n
1 1
ℓˆb(f(X ),Y ) E[ℓ(f(X),Y)] sup ℓˆb (f(X ),Y ) E[ℓ(f(X),Y)]
(cid:12) (cid:12) (cid:12)n Xj=1 h j j − (cid:12) (cid:12) (cid:12) f ∈F(cid:12) (cid:12)n Xi=1 h i i − (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) .BLh+B log(1/δ) . (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12). BLh+ B2 Rn( )+B log(1/δ)(cid:12) (cid:12) (cid:12)
r n h F r n
For linear function classes when dim(X) = p, Rn =
WenotethatCorollary3.4doesnotpresentatradeoffinh
–onemightbetemptedtotakeh 0. However,asseenin O˜ dp (ElBalghitietal., 2022). Choosing h =
→ n
Lemma2.1, thesizeofthegradientsofourmethodscales O((cid:18) (dq p/n)(cid:19) 1/4) yields an error of size O˜ ((dp/n)1/4).
like 1/h. Loosely speaking, functions where gradients − p
This is same rate as Liu&Grigas (2021), but also holds
mightexplodearemoredifficulttooptimize.Hence,unlike
inthemisspecifiedsettingwheref / .
many other learning methods, h does not control a bias- ∗ ∈F
variance tradeoff; rather h controls a bias-computational Usingtheseuniformerrorbounds,wecanconstructbounds
complexitytradeoff. Preciselycharacterizingthistradeoff ontheexcessregretoftheminimizerofthesurrogateloss.
remainsan openarea of research. Practically, we suggest Specifically,define
takinghaslargeasthenextlargestterminthebound,i.e.
h=O(n −1/2)above,tomaximizethesmoothnesswithout ERegret(f) ≡E Y⊤πˆ(f(X)) −E Y⊤πˆ(fOR(X))
compromisingtherate.
wherefOR argm(cid:2)in Regret(cid:3)(f). N(cid:2)oteiff ,th(cid:3)en
Corollary3.4capturesthekeyideaofourapproachwitha excessregre∈ tisthesamf ∈eFasregret. However,th∗ e∈ coF nverse
minimum of mathematical overhead. In the next sections is nottrue; it is possible thatthere exists fOR = f with
∗
6
we extend this result to a uniform error bound and regret f suchthatRegret(fOR) = 0. Similarly,forafixed
∗
6∈ F
bound. h< 1,definetheminimizerofthesurrogateloss
L
n
3.2.UniformErrorandRegretBounds fˆ argmin 1 ℓˆb (f(X ),Y ).
h ∈ n h i i
f
We can extend Corollary 3.4 to a uniformerror bound by ∈F Xi=1
suitablyboundingthecomplexityof andusingstandard Then:
F
toolsfromuniformlawsoflargenumbers.Wewillpresent
Corollary3.6(ExcessRegretBoundforGeneral ). Sup-
twosuchbounds. Z
posetheassumptionsofTheorem3.5hold.Then,
Ourfirsterrorboundappliestoanychoiceof .Itdoesnot
matter if the feasible region is polyhedral, nZ on-convex,or ERegret(fˆ) . B3LRn( )+ B .
h
F √n
stronglyconvex. Instead,weleveragetheLipschitznessof
p
thebackwardsPGloss(Lemma2.1a). Thispropertyallows
Formanyhypothesisclasses,themultivariateRademacher
us to apply a vector contraction inequality from Maurer
complexity is vanishing in n – for the linear class when
(2016)toboundtheRademachercomplexityofoursample
surrogatelossbyamultivariateRademachercomplexityof dim(X) = p it is O( d np). Hence, for such classes, fˆ h
thevector-valuedhypothesisclassinducedby . achievesbest-in-classqperformanceasymptotically.
F
5LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
Theorem 3.5 applies to general , but may be loose as This bound vanishes as n , showing that the min-
a consequence. We next presentZ a second uniform error imizer of the surrogate fˆ → ach∞ ieves best-in-class perfor-
h
bound for that holds when is polyhedral by leveraging manceasymptotically.
Z
resultsfromHuetal.(2022).
4. Numerical Experiments
Tothatend,recalldefinitionofVC-linear-subgraphdimen-
sionfromHuetal.(2022).
4.1.DataSetup
Definition 3.7 (VC-Linear-Subgraph Dimension). The
VC-linear-subgraph dimension of a class of functions For our numerics section, we consider the following con-
, is the VC dimension of the sets = textuallinearoptimizationproblem
X ◦
F (x⊆ ,β,Y
t):β f(x) t :f in
Rd+1,F
thatis,
thelargestinte⊤
gerν
fo≤ rwhich∈ theF reexisX tx×
1,...,x
ν
,
m zax f ∗(X)z s.t. z ∈{−1,1 }, (6)
(cid:8) β(cid:8) ,...,β Rd,t R,(cid:9) ...,t (cid:9)Rsuchthat ∈ X
1 ν 1 ν which can be viewed as a classification problem to max-
∈ ∈ ∈
I β f(x ) t :j =1,...,ν :f =2ν imize reward or an offline version of a contextual bandit
j⊤ j
≤
j
∈F problem.Inourexperiments,weletX Unif(0,2)and
(cid:12)(cid:8)(cid:0) (cid:8) (cid:9) (cid:1) (cid:9)(cid:12) ∼
W(cid:12)e makethefollowingassumptionwhichbounds(cid:12)theVC-
4x+2, forx [0,0.55)
linear-subgraphdimensionbyaconstant.
f ∗(x)= − ∈
Assumption3.8(BoundedVCDimension). Thefunction (m(x 0.55) 0.2, forx [0.55,2]
− − ∈
class
The functionis piecewise linear with one piece that has a
¯ = f¯:f¯(x,y)=f(x)+hy, forf ,h R slopeof 4andanotherpiecewithaslopeofm [0, 4].
F ∈F ∈ − ∈ −
The change pointis at x = 0.55 where the two functions
hasVC-l(cid:8)inear-subgraphdimensionatmostν. (cid:9)
meet at 0.2 (see Figure 2). We generate synthetic data
−
Thisassumptionslightlydiffersfromtheassumptionfrom as Y = f ∗(X) + ǫ α. We define ǫ α = √α(ζ 0.5) +
−
Huetal.(2022)sinceitincorporatestheperturbationterm √1 αγ where α [0,1], ζ is an exponential random
− ∈
hy into the plug-in class. However, since the hypothesis variablewithmean0.5,andγ (0,0.25). Byconstruc-
∼ N
class is augmented by an addition parameter h, the VC- tion ǫ is mean-zeronoise with variance0.25. Note, when
linear-subgraph-dimensionof shouldonlydifferbyauni- α=1,ǫisnotcentrallysymmetric,andhencethetheoreti-
versalconstant. UsingVC-linF ear-subgraphdimension,we cal6 resultsof(Liu&Grigas,2021)donotapply.
canobtainthefollowingboundforpolyhedral . Let ∠
Z Z
bethesetofextremepointsof .
Z
Theorem 3.9 (Uniform Error Bound for Polyhedral ). m= 4 m=0
SupposeAssumptions1.1, 3.2 and 3.8 hold. For any 0Z < 2.5 −
δ < 1 and0<h< 1,withprobabilityatleast1 δ,
2 L −
0.0
n
1
sup ℓˆb (f(X ),Y ) E[ℓ(f(X ),Y )]
f (cid:12)n h i i − i i (cid:12)
∈F(cid:12) Xi=1 (cid:12) -2.5
(cid:12) (cid:12)
(cid:12) νlog( ∠ +1)log(1/(cid:12)δ)
(cid:12). BLh + B |Z | (cid:12)
n
r -5.0
Theorem 3.9 shows the error is O h+n 1/2 , and
p −
like Corollary 3.4 highlights that h primarily trades off -7.5
(cid:0) (cid:1)
between bias and computational complexity. Choosing 0.0 0.5 1.0 1.5 2.00.0 0.5 1.0 1.5 2.0
h = O(n 1/2)minimizestheboundtoO (n 1/2)which X
− p −
matchesthegeneralizationerrorofthe truelossinproven
inHuetal.(2022);ElBalghitietal.(2022).Thus,forpoly- Figure2.(SyntheticData)Observationsof(Xi,Yi)form = −4
hedral , our surrogateconvergesno slower than the em-
(left)andm=0(right).Redlineisf∗(X)foreachsetting.
Z
piricalloss,butismorecomputationallytractable.
4.2.LearningLinearHypotheses
Wecanboundexcessregretfˆ forthepolyhedralcase:
h Our first set of experiments focus on a learning the best
Corollary 3.10 (Excess Regret Bound for Polyhedral ).
hypothesis in the linear class, = f : f(x) = β x +
Z 1
SupposetheassumptionsfromTheorem3.9hold.Then, β forβ ,β R . For claritF y, the{ regret of the best-in-
0 1 0
∈ }
class member for this setup is zero. Hence excess regret
ERegret(fˆ h) . B νlog( |Z∠ |+1) . equalsregret.
n
r
6
YLearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
We comparelearning with the PG losses (PGC and PGB)
against two benchmarks: i) minimizing SPO+ loss and
ii) minimizing the least-squares loss and using the corre- ETO
30%
spondingplug-inpolicy.Tang&Khalil(2022)observethat SPO+
SPO+ performs best (or nearly best) across a variety of PGB
benchmarks compared to other predict-then-optimizepro- PGC
20%
cedures; hence it is a strong benmark. Minimizing least-
squareslossisastandardestimate-then-optimizeapproach
andadvocatedforbyHuetal.(2022).
10%
We study misspecification by varying the parameter m.
Whenm=4,f ,butwhenm=4,f .Further-
∗ ∗ ∗
∈F 6 6∈F
more, we study the impact of violatingthe the symmetric
0%
noiseassumptionin(Liu&Grigas,2021)byvaryingα.
-4 -3 -2 -1 0
We estimate and compare the relative regret LevelofMisspecification(m)
(E Y (π (X) πˆ(X)) /E Y π (X) ) across our
⊤ ∗ ⊤ ∗
− Figure3.(Varying Degree of Misspecification) Weplot the rela-
differentapproaches. We optimize our surrogateloss and
(cid:2) (cid:3) (cid:2) (cid:3) tiveregretaswevarymforn = 80andα = 1. Theerrorbars
SPO+withtheBFGSalgorithmintheSciPypackage.
are95%confidenceintervals.
Results
tendtozeroasinFigure1.
Figure1plotstherelativeregretform=0andα=1,that
is, the most misspecified setting with the most asymmet-
ricnoiseǫ. Beyondhighlightingthesuperiorperformance
of the PG losses in misspecified settings, Figure 1 also
showsthechoiceoffinitedifferenceapproximation(back-
30%
wardorcentral)alsoimpactsperformance.Intuitively,cen-
traldifferencinglikelyoutperformsbackwarddifferencing
because in standard, deterministic settings, central finite
differencing has error O(h2) relative to the true deriva- 20%
tive,whilebackwarddifferencinghaserrorO(h)(LeVeque, ETO
2007). Thisintuitioncanbemadeformalinoursettingby SPO+
adaptingLemma3.3,butweomitthedetailsforbrevity. 10% PGB
PGC
Figure 1 also highlights that in settings where estimate-
then-optimizemethodshave fast learningrates ((Huetal.,
2022;Elmachtoubetal.,2023)),thebenefitsmaybesmall 0%
0.00 0.25 0.50 0.75 1.00
since the problem most data-driven algorithms already
LevelofNoiseAsymmetry(α)
achievelowregret. Inourexperiments,weseeevenwhen
n = 20 the relative regret was less than 0.6% across all
Figure4.(VaryingNoiseDistribution)Weplottherelativeregret
methods.
aswevaryαforn = 200. Whenα = 0thenoiseiscentrally
WenextstudymisspecificationinFigure3.Thefigureplots symmetric and when α = 1 the noise is the most asymmetric.
differenttherelativeregretofdifferentmethodsforafixed Theerrorbarsare95%confidenceintervals.
n = 80aswevarythelevelofmisspecificationfromm =
Finally, in Figure 4, we study how changingthe shape of
4(well-specified)tom=0(mostmisspecified).
− the noise distribution impacts the relative regret. We plot
Similar to numerical results in (Elmachtoub&Grigas, experimentswheren = 200andm = 0(misspecifiedset-
2022), our figure shows decision-aware methods out- ting)togetbetterestimatesoftherelativeregretundermis-
perform decision-blind approaches when the hypothesis specification. Theplotsuggeststhatrequiringasymmetric
classismisspecified.However,ourfigureimpliestheSPO+ noiseisnotsimplyaweaknessintheanalysisofSPO+,but
is nearly as susceptible as to misspecification as decision- fundamentaltothemethod.Asthenoisebecomeslesssym-
blind approaches since the relative regret also increases metric,theperformanceofSPO+degrades.Evenwhenthe
rapidly. By contrast, the relative regret for our PG losses assumptionissatisfied(α=0),weseeSPO+isstillsignif-
increasesmoreslowly. We stress, thisexperimentfixesn. icantlyimpactedbymisspecification. By contrast, thePG
Asn 0,ourtheoryshowstheregretofthePGlosseswill lossesperformsimilarlyastheshapeofthenoisevaries.
→
7
tergeRevitaleR
tergeRevitaleRLearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
4.3.ComparisontoNon-ParametricMethods as n . Hence, optimizing our surrogate yields a
→ ∞
best-in-class policy asymptotically, even in misspecified
As an alternative approach to misspecification, (Huetal.,
settings. Our PG losses are the first proposed surrogates
2022) propose utilizing non-parametric methods for
withthispropertyandsubstantivelyoutperformothermeth-
estimate-then-optimize approaches. In this section, we
odsinmisspecifiedsettings.
benchmark the PG losses with the misspecified linear hy-
pothesis class against estimate-then-optimize where is Although we have focused on generalor polyhedral , it
F Z
the reproducing kernel Hilbert space (RKHS) with Gaus- ispossibletoextendourresultstootherstructuredfeasible
sian kernel, (x,y) = exp ρ x y 2 . Specifically, regions(e.g.,strongly-convexfeasibleregions)usingtech-
K − k − k
we utilize kernel ridge regression. We select the best niquesfrom(ElBalghitietal.,2022).
(cid:0) (cid:1)
penaltyparameterin 0.001,0.01,0.1,1,10,100 andρin
{ } The family of PG losses arises from different approaches
0.001,0.01,0.1,1,10 using5-foldcross-validation. We
{ } to approximatinga derivative. As mentioned, an interest-
thencomputecorrespondingplug-inpolicy.Wedenotethis
ingopenquestionisidentifyingthebest-possiblechoiceof
non-parametricmethodbyKRinourplots.
approximation. We also believe that better understanding
theroleofhintradingoffbetweenbiasandcomputational
complexitymightshedlightonimprovealgorithmsandtun-
40% ingprocedures.
PGB 1500
KR
30% PGC Acknowledgements
1000
The authors would like to thank Paul Grigas, Adam El-
20%
machtoub,HamsaBastani,andOsbertBastaniforfeedback
500 onaninitialdraftofthismanuscript.
10%
ImpactStatement
0% 0
50 100 150 200 50 100 200 400 800 Thispaperpresentsworkwhosegoalistoadvancethefield
n n
of Machine Learning. There are many potential societal
consequences of our work, none which we feel must be
Figure5.(Comparison to Non-Parametric Methods under Mis-
specificallyhighlightedhere.
specification) Left figure plots relative regret for m = 0 and
α = 1. Theerrorbarsare95% confidence intervals. Theright
figure plots the ratio of KR computing time to PGC computing References
timeforeachofthe100replications.
Arbas,J.,Ashtiani,H.,andLiaw,C. Polynomialtimeand
Results privatelearningofunboundedgaussianmixturemodels.
In Krause, A., Brunskill, E., Cho, K., Engelhardt, B.,
We plot the relative regret and the ratio of computation
Sabato, S., and Scarlett, J. (eds.), ICML 2023, volume
times between KR and PGC as n increases for m = 0
202 of Proceedingsof Machine Learning Research, pp.
and α = 1 in Figure 5. Our results show that learning
1018–1040.PMLR,2023.
withPG lossesachievessimilarorregretasestimate-then-
optimize with non-parametric methods, particularly PGC. Ban,G.-Y.andRudin,C. Thebigdatanewsvendor: Prac-
The advantage of learning with the PG losses is that it is tical insights from machine learning. Operations Re-
computationally more efficient and the resulting policies search,67(1):90–108,2019.
are more interpretable. PG losses do not have to utilize
cross-validationfortuningandlearninasimpler,butmis- Berthet, Q., Blondel, M., Teboul, O., Cuturi, M., Vert, J.-
specified, hypothesisclass. Thishelpsmotivatethe neces- P., and Bach, F. Learning with differentiable pertubed
sityofourPGlossesthatareabletolearninmisspecicified optimizers. AdvancesinNeuralInformationProcessing
settings. Systems,33:9508–9519,2020.
Donti, P., Amos, B., and Kolter, J. Z. Task-based end-to-
5. Conclusion endmodellearninginstochasticoptimization.Advances
inNeuralInformationProcessingSystems,30,2017.
Inthispaperweproposedanovelfamilyofsurrogatelosses
for the predict-then-optimize framework that can be opti- ElBalghiti,O.,Elmachtoub,A.N.,Grigas,P.,andTewari,
mized using off-the-shelf gradient methods. Most impor- A. Generalization bounds in the predict-then-optimize
tantly,theapproximationerrorofthesesurrogatesvanishes framework. MathematicsofOperationsResearch,2022.
8
tergeRevitaleR
oitaRemiTGPotRKLearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
Elmachtoub,A.N.andGrigas,P. Smart“predict,thenop- Pogancˇic´, M. V., Paulus, A., Musil, V., Martius, G., and
timize”. ManagementScience,68(1):9–26,2022. Rolinek, M. Differentiationof blackbox combinatorial
solvers. InInternationalConferenceonLearningRepre-
Elmachtoub, A. N., Lam, H., Zhang, H., and Zhao,
sentations,2019.
Y. Estimate-then-optimizeversusintegrated-estimation-
optimization versus sample average approximation: A Sadana,U.,Chenreddy,A.,Delage,E.,Forel,A.,Frejinger,
stochasticdominanceperspective,2023. E., and Vidal, T. A survey of contextual optimization
methodsfordecisionmakingunderuncertainty,2023.
Goh, C. Y. and Jaillet, P. Structured prediction
by conditional risk minimization. arXiv preprint Shah, S., Wang, K., Wilder, B., Perrault, A., and Tambe,
arXiv:1611.07096,2016. M. Decision-focusedlearningwithoutdifferentiableop-
timization: Learning locally optimized decision losses,
Grigas,P.,Qi,M.,etal. Integratedconditionalestimation-
2022.
optimization. arXivpreprintarXiv:2110.12351,2021.
Shalev-Shwartz,S.,Shamir,O.,Srebro,N.,andSridharan,
Guo, W., Jordan, M., andZhou, A. Off-policyevaluation
K. Learnability,stabilityanduniformconvergence. The
withpolicy-dependentoptimizationresponse. Advances
Journal of Machine Learning Research, 11:2635–2670,
in Neural Information Processing Systems, 35:37081–
2010.
37094,2022.
Tang,B.andKhalil,E.B. Pyepo:Apytorch-basedend-to-
Gupta,V.,Huang,M.,andRusmevichientong,P.Debiasing
end predict-then-optimizelibrary for linear and integer
in-samplepolicyperformanceforsmall-data,large-scale
programming. arXivpreprintarXiv:2206.14234,2022.
optimization. OperationsResearch,2022. Forthcoming.
Tulabandhula,T.andRudin,C. Machinelearningwithop-
Gupta, V., Huang, M., and Rusmevichien-
erationalcosts. JournalofMachineLearningResearch,
tong, P. Decision-aware denoising.
14(7),2013.
https://ssrn.com/abstract=, February
2024. AvailableatSSRN. Wager, S. and Athey, S. Efficient policy learning. arXiv
preprintarXiv:1702.02896,2017.
Hu, Y., Kallus, N., and Mao, X. Fast ratesfor contextual
linear optimization. ManagementScience, 68(6):4236– Wilder, B., Dilkina, B., andTambe,M. Meldingthe data-
4245,2022. decisionspipeline:Decision-focusedlearningforcombi-
natorialoptimization. InProceedingsofthe AAAICon-
Ito,S.,Yabe,A.,andFujimaki,R. Unbiasedobjectiveesti-
ference on ArtificialIntelligence, volume 33, pp. 1658–
mationinpredictiveoptimization. InInternationalCon-
1665,2019.
ference on Machine Learning, pp. 2176–2185. PMLR,
2018.
LeVeque, R. J. Finite difference methods for ordinary
andpartialdifferentialequations:steady-stateandtime-
dependentproblems. SIAM,2007.
Liu, H. and Grigas, P. Risk bounds and calibration for a
smart predict-then-optimizemethod. Advances in Neu-
ral Information Processing Systems, 34:22083–22094,
2021.
Maurer,A. Avector-contractioninequalityforrademacher
complexities. InAlgorithmicLearningTheory: 27thIn-
ternationalConference, ALT 2016, Bari, Italy, October
19-21,2016,Proceedings27,pp.3–17.Springer,2016.
Mohri, M., Rostamizadeh, A., andTalwalkar, A. Founda-
tionsofMachineLearning. MITpress,2018.
Osokin,A.,Bach,F.,andLacoste-Julien,S. Onstructured
predictiontheorywithcalibratedconvexsurrogatelosses.
AdvancesinNeuralInformationProcessingSystems,30,
2017.
9LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
A. Results andProofs forSection2
A.1.ProofforLemma2.1
Proof. Wefirstprove(a),theLipschitzproperty.WefirstclaimV()isB Lipschitz,since
·
V(t) V(s) = t ⊤πˆ(t) s ⊤πˆ(s) = t ⊤(πˆ(t) πˆ(s)) +(t s)⊤πˆ(s)
− − − −
0,byoptimalityofπˆ(t)
≤
t s πˆ(s) B t| s ,{z }
≤ k − kk k ≤ k − k
where the last inequality follows from Assumption 1.1. A symmetric argumentholds for V(s) V(t) provingV is B
−
Lipschitz.
Returningtoℓˆb(t,y),write
V(t) V(t hy) V(t) V(t hy)
ℓˆb h(t,y) −ℓˆb h(t ′,y) = −
h
−
−
′ −
h
′ −
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)|V(t) −V(t ′) | + |V(t ′ −hy) −V(t −hy)(cid:12) (cid:12) (cid:12) (cid:12)|
≤ h h
2B t t
′
| − |.
≤ h
Anentirelyanalogousargumentholdsforℓˆc(t,y).
h
Wenextprove(b),theboundedednessproperty.Write
V(t) V(t hy) B hy
ℓˆb (t,y) = | − − | k k =B y
h h ≤ h k k
(cid:12) (cid:12)
(cid:12) (cid:12)
Again,ananalogousargumenthol(cid:12) dsforℓˆc(cid:12)
(t,y). Thiscompletestheprooffor(b)
h
Theproofof(c)followsdirectlyfromapplyingDanskin’sTheorem.
Toprove(d),wesee
V(t+hy) V(t)
ℓˆb h(t,y) −ℓ(t,y) =
h
− −y ⊤πˆ(t)
(t+hy)⊤πˆ(t+hy) (t+hy)⊤πˆ(t)
= −
h
0
≥
wherethelastinequalityholdsbyoptimalityofπˆ(t+hy). Rearrangingprovestheresultfor(d).
A.2.ProofofLemma2.2.
Proof. Weapplythedominatedconvergencetheorem.Lete Rdbetheithcoordinatevector. Then,
i
∈
1
∂ E ℓˆb(t,Y) = limE (ℓˆb(t+δ,Y) ℓˆb(t,Y)) (7)
ti h δ 0 δ h − h
h i → (cid:20) (cid:21)
LetW 1(ℓˆb(t+δ,Y) ℓˆb(t,Y)). Then, bythe Lipschitz propertyof Lemma2.1, W 2B, and lim W =
∂ ℓˆb(tδ ,Y≡ )δ almh ostsurely.T− herh esultthenholdsfortheithpartialderivativeofℓˆb fromthed| omδ i| n≤ atedh convergencδ → et0 heoδ rem.
ti h h
Sinceiwasarbitrary,itholdsforalli=1,...,d,andthusholdsforthegradient.Ananalogousproofholdsforℓˆc.
h
10LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
B. Results and ProofsforSection 3
B.1.ProofofLemma3.1.
Proof. ThefirstinequalitywasproveninLemma2.1. Forthesecond,notethatV(t)=t πˆ(t). Hencebyrearranging,
⊤
1
ℓˆb h(t,y) −ℓ(t,y)= h(V(t) −V(t −hy)) −y⊤πˆ(t)
1
= t (πˆ(t) πˆ(t hy) +y (πˆ(t hy) πˆ(t))
⊤ ⊤
h − − − −
y (cid:0)(πˆ(t hy) π(t)), (cid:1)
⊤
≤ − −
bytheoptimalityofπˆ(t).
B.2.ProofforLemma3.3
ToboundtheexpectedapproximationerrorinLemma3.3,werequirethefollowingelementaryresult:
LemmaB.1(DensityRatioBound). SupposeAssumption3.2holds.Then,foranyt,t suchthat t t 1/L,wehave
′ ′
k − k≤
g(t;f,Y)
′
1 (e 1)L t t .
′
g(t;f,Y) − ≤ − k − k
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
Proof. Letg(t) g(t;f,Y). Bytheconv(cid:12)exityoftheexp(cid:12)onential,
≡
exp(x) 1+(e 1)x 0 x 1, and exp(x) 1+x x. (8)
≤ − ∀ ≤ ≤ ≥ ∀
Lets(t)=logg(t). Then,
g(t)
′
log =s(t) s(t) L t t
′ ′
g(t) − ≤ k − k
(cid:18) (cid:19)
Takingtheexponentialofbothsidesandsubtracting1,wehave
g(t)
′
1 exp(L t t ) 1
′
g(t) − ≤ k − k −
(e 1)L t′ t ,
≤ − k − k
wherethelastinequalityfollowsfromEquation(8)andourassumptionthat t t 1/L. Similarly,wehave,
′
k − k≤
g(t)
′
log L t t
′
g(t) ≥− k − k
(cid:18) (cid:19)
g(t)
′
1 exp( L t′ t ) 1
g(t) − ≥ − k − k −
L t t
′
≥− k − k
(e 1)L t t
′
≥− − k − k
Hence,
g(t)
′
1 (e 1)L t t .
′
g(t) − ≤ − k − k
(cid:12) (cid:12)
(cid:12) (cid:12)
Thiscompletestheproof. (cid:12) (cid:12)
(cid:12) (cid:12)
ProofofLemma3.3. LetT =f(X). ConditiononY andletg(t) g(t;f,Y). Then,byLemma3.1,wehave
≡
0 E ℓˆb(T,Y) ℓ(T,Y) Y E Y (πˆ(T hY) πˆ(T)) Y .
≤ h − ≤ ⊤ − −
h (cid:12) (cid:12) i (cid:2) (cid:12) (cid:3)
(cid:12) (cid:12)
11LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
Weboundthislastquantityasfollows:
E Y⊤(πˆ(T hY) πˆ(T)) Y (9)
− −
(cid:2)= g(t)Y⊤πˆ(t hY)dt (cid:12)
(cid:12)
(cid:3) g(t)Y⊤πˆ(t)dt
− −
Z Z
= Y πˆ(t)(g(t+hY) g(t))dt
⊤
−
Z
Y πˆ(t) g(t+hY) g(t) dt
⊤
≤ | − |
Z
(cid:12) g(cid:12)(t+hY)
B (cid:12) g(t) (cid:12) 1 dt
≤ g(t) −
Z (cid:12) (cid:12)
(cid:12) (cid:12)
(e 1)BL(cid:12) hY g(t;f,(cid:12)Y)dt
(cid:12) (cid:12)
≤ − k k
Z
(e 1)BLh
≤ −
TakingtheexpectationoverY completestheproof.
B.3.ProofforTheorem3.5
Proof. Weboundtheuniformerrorasfollows:
n n
1 1
sup ℓˆb (f(X ),Y ) E[ℓ(f(X ),Y )] sup ℓˆb (f(X ),Y ) E ℓˆb (f(X ),Y )
f (cid:12)n h i i − i i (cid:12) ≤ f (cid:12)n h i i − h i i (cid:12)
∈F(cid:12) Xi=1 (cid:12) ∈F(cid:12) Xi=1 h i(cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (i) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
n
| 1 {z }
+sup E ℓˆb (f(X ),Y ) ℓ(f(X ),Y )
f (cid:12)n h i i − i i (cid:12)
∈F(cid:12) Xi=1 h i(cid:12)
(cid:12) (cid:12)
(cid:12) (ii) (cid:12)
(cid:12) (cid:12)
| {z }
Wefirstbound(i). Letting
n
1
Rn ( ) = E Rˆn ( ) = E E sup σ ℓˆb (f(X ),Y )
SL F SL F " σ "f n i h i i ##
h i ∈F Xi=1
andnoting0 ℓˆb h(f(Xi),Yi)+B 1byLemma2.1b,wecanapplythestandardRademachercomplexityresult(Mohrietal.,
≤ 2B ≤
2018,Theorem3.3)toshowforanyδ >0,thefollowingholdsforallf withprobabilityatleast1 δ,
∈F −
1 n ℓˆb(f(X ),Y )+B 1 n ℓˆb(f(X ),Y )+B 1 1
E h i i h i i +2Rn ( )+ log .
n i=1 " 2B # ≤ n i=1 2B SL F sn (cid:18)δ (cid:19)
X X
Toobtainthetwosidedboundfor(i),wecanobtainthesameboundwith ℓˆb h(f(Xi),Yi)+B replacedwith −ℓˆb h(f(Xi),Yi)+B.
2B 2B
Takingtheunionbound,weseethefollowingholdswithprobabilityatleast1 2δ,
−
n
1 1 1
ℓˆb (f(X ),Y ) E ℓˆb (f(X ),Y ) 4BRn ( )+2B log
(cid:12)n h i i − h i i (cid:12) ≤ SL F sn δ
(cid:12) Xi=1 h i(cid:12) (cid:18) (cid:19)
(cid:12) (cid:12)
WenextboundRn SL(cid:12) (cid:12)( F)byapplyingCorollary4ofMaurer(201(cid:12) (cid:12)6)toshow
n n
1 B 1 B
Rn ( )=E sup σ ℓˆb (f(X ),Y ) √2 E sup σ f(X ) = √2 Rn( )
SL F "f n i h i i # ≤ h "f n i⊤ i # h F
∈F Xi=1 ∈F Xi=1
12LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
where the inequality holds via the corollary with the Lipschitz constant from Lemma 2.1a. Combining the bounds, we
showwithprobabilityatleast1 δ,
−
4√2B2 1 1
(i) Rn( )+2B log
≤ h F sn δ
(cid:18) (cid:19)
Finally,webound(ii)inLemma3.3. Combiningtheboundson(i)and(ii)provestheresult.
B.4.ProofforCorollary3.6
Proof. Let
n
1
L (f)= ℓˆb (f(X ),Y ) and L(f)=E[ℓ(f(X),Y)]
n n h i i
i=1
X
Sincethefˆ minimizesL (f)andfOR minimizesL(f),wesee,
b n
L(fˆ) L(fOR) = L(fˆ) L (fˆ)+L (fˆ) L (fOR)+L (fOR) L(fOR)
b b n n b n n
− − − −
L (fˆ) L (fOR)+2sup L (f) L(f)
n n n
≤ − | − |
f
0,byoptimalityoffˆ ∈F
≤
|2sup L{nz(f) L(}f)
≤ | − |
f
∈F
wherethefirstinequalityholdsbytakingthesupremumofthefirsttwoandlasttwopairs,andthesecondinequalityholds
byoptimalityoffˆ. Takingtheexpectationofbothsides,wesee
ERegret(fˆ) 2E sup L (f) L(f)
b n
≤ "f | − |#
∈F
Tocomputetheexpectation,weseebyTheorem3.5andchoosingh= BRn( )that
L F
q
1 1
sup L (f) L(f) B3LRn( )+B log .
n
| − |≤ F n δ
f r
∈F p
withprobabilityatleast1 δRearranging,wehave
−
nt2
P sup L (f) L(f) B3LRn( ) t exp
f
∈F| n − |−
p
F ≥ !≤ (cid:18)−B2
(cid:19)
Bytailintegrationovertandaddingback B3LRn( ),wecanshow
F
p
B
ERegret(fˆ) 2E sup L (f) L(f) . B3LRn( )+ ,
b n
≤ "f | − |# F √n
∈F p
completingtheproof.
B.5.ProofforTheorem3.9
Proof. Weconsiderthefollowingalternativedecompositionoftheuniformerror:
n n
1 1
ℓˆb (f(X ),Y ) E[ℓ(f(X ),Y )] ℓˆb (f(X ),Y ) ℓ(f(X ),Y )
(cid:12)n h i i − i i (cid:12) ≤ (cid:12)n h i i − i i (cid:12)
(cid:12) Xi=1 (cid:12) (cid:12) Xi=1 (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (i) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
n
| 1 {z }
+ ℓ(f(X ),Y ) E[ℓ(f(X ),Y )]
i i i i
(cid:12)n − (cid:12)
(cid:12) Xi=1 (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
13LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
Bounding(i),wehave
n
1
(i) ℓˆb (f(X ),Y ) ℓ(f(X ),Y )
≤ n h i i − i i
Xi=1(cid:12) (cid:12)
n(cid:12) (cid:12)
1 (cid:12) (cid:12)
Y (πˆ(f(X ) hY +hY ) πˆ(f(X )+hY ))
≤ 2n
i⊤ i
−
i ′ i
−
i ′ i
Xi=1h′ ∈X{0,h
}
n
1 1
= Y πˆ(f(X ) hY +hY ) E Y πˆ(f(X ) hY +hY )
2 n
i⊤ i
−
i ′ i
−
i⊤ i
−
i ′ i
h′ ∈X{0,h
}
Xi=1
(cid:2) (cid:3)
n
1 1
+ Y πˆ(f(X )+hY ) E Y πˆ(f(X )+hY )
2 n
i⊤ i ′ i
−
i⊤ i ′ i
h′ ∈X{0,h
}
Xi=1
(cid:2) (cid:3)
n
1 1
+
2 n
E Y i⊤(πˆ(f(X i) −hY i+h′Y i) −πˆ(f(X i)+h′Y i))
h′ ∈X{0,h
}
Xi=1
(cid:2) (cid:3)
n
1
2sup Y πˆ(f(X ) hY ) E Y πˆ(f(X ) hY )
≤ h (cid:12)n
i⊤ i
−
i
−
i⊤ i
−
i
(cid:12)
(cid:12)
(cid:12)
Xi=1
n (cid:2)
(cid:3)(cid:12)
(cid:12)
1 (cid:12) 1 (cid:12)
+
2
(cid:12)
n
E Y i⊤(πˆ(f(X i) −hY i+h′Y i) −πˆ(f(X(cid:12) i)+h′Y i))
h′ ∈X{0,h
}
Xi=1
(cid:2) (cid:3)
wherethefirstinequalityappliesthetriangleinequality,thesecondinequalityappliesLemma3.1, andthelastinequality
combinessimilartermsbytakingthesupremumoverh. Applyingtheboundon(i),wesee
n
1
sup ˆl (f(X ),Y ) E[l(f(X ),Y )]
h i i i i
f (cid:12)n − (cid:12)
∈F(cid:12) Xi=1 (cid:12)
(cid:12) n (cid:12)
(cid:12) 1 (cid:12)
(cid:12) 3sup Y πˆ(f¯(X ,Y )) E Y(cid:12) πˆ(f¯(X ,Y ))
≤ f¯ ∈F¯(cid:12)
(cid:12)
(cid:12)n
Xi=1
i⊤ i i
−
(cid:2)
i⊤ i i
(cid:3)(cid:12)
(cid:12)
(cid:12)
(cid:12) (a) (cid:12)
(cid:12) (cid:12)
n
+sup|1
2
n1 E Y i⊤{ (πz ˆ(f(X i) −hY i+h′Y i) −} πˆ(f(X i)+h′Y i))
f ∈F h′ ∈X{0,h
}
Xi=1
(cid:2) (cid:3)
(b)
Component(a)isbounded|usingTheorem1andTheorem2of{Hzuetal.(2022)showingthereexists}auniversalconstant
C suchthatthefollowingholdswithprobabilityatleast1 δ,
−
νlog( ∠ +1)log(5/δ)
(a) CB |Z | .
≤ n
r
Component(b) is boundedby Equation(9) in the proof of Lemma 3.3. Combining(a) and (b) componentsprovesthe
result.
B.6.ProofforCorollary3.10
Proof. Following the same approach as the proof for Corollary 3.6, we can show with Theorem 3.9 and choosing h =
1 1 that
L√n ≤ L
νlog( ∠ +1)log(1/δ)
sup L n(f) L(f) C′B |Z |
| − |≤ n
f r
∈F
forsomeuniversalconstantC withprobabilityatleast1 δ. Rearrangingwehave
0
−
nt2
P sup L (f) L(f) t exp .
f ∈F| n − |≥ !≤ (cid:18)−C 02B2νlog( |Z∠ |+1) (cid:19)
14LearningBest-in-ClassPoliciesforthePredict-then-OptimizeFramework
Applyingthetailintegralgivesus
ERegret(fˆ) 2E sup L (f) L(f) . B νlog( |Z∠ |+1)
b n
≤ "f | − |# r n
∈F
completingtheproof.
15