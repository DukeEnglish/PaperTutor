UnderreviewasaworkshoppaperatICLR2024
DO DIFFUSION MODELS LEARN SEMANTICALLY
MEANINGFUL AND EFFICIENT REPRESENTATIONS?
QiyaoLiang ZimingLiu
DepartmentofEECS DepartmentofPhysics
MIT MIT
Cambridge,MA02139,USA Cambridge,MA02139,USA
qiyao@mit.edu zmliu@mit.edu
IlaR.Fiete
DepartmentofBCS
MIT
Cambridge,MA02139,USA
fiete@mit.edu
ABSTRACT
Diffusion models are capable of impressive feats of image generation with un-
common juxtapositions such as astronauts riding horses on the moon with prop-
erlyplacedshadows. Theseoutputsindicatetheabilitytoperformcompositional
generalization, but the vast size of training datasets makes it difficult to quanti-
tatively probe how well these models do so and whether they learn internal rep-
resentations that maximally leverage the compositional structure of their inputs.
Here,weconsiderahighlyreducedsettingtoexaminewhetherdiffusionmodels
learnsemanticallymeaningfulandfullyfactorizedrepresentationsofcomposable
features. WeperformcontrolledexperimentsonconditionalDDPMslearningto
generate 2D spherical Gaussian bumps centered at specified x- and y-positions.
Ourresultsshowthattheemergenceofsemanticallymeaningfullatentrepresen-
tationsiskeytoachievinghighperformance. Enroutetosuccessfulperformance
overlearning, themodeltraversesthreedistinctphasesoflatentrepresentations:
(phase A) no latent structure, (phase B) a 2D manifold of disordered states, and
(phase C) a 2D ordered manifold. Corresponding to each of these phases, we
identify qualitatively different generation behaviors: 1) multiple bumps are gen-
erated,2)onebumpisgeneratedbutatinaccuratexandylocations,3)abumpis
generatedatthecorrectxandylocation. Furthermore,weshowthatevenunder
imbalanced datasets where features (x- versus y-positions) are represented with
skewed frequencies, the learning process for x and y is coupled rather than fac-
torized,demonstratingthatsimplevanilla-flavoreddiffusionmodelscannotlearn
efficientrepresentationsinwhichlocalizationinxandy arefactorizedintosep-
arate1Dtasks. Thesefindingssuggesttheneedforfutureworktofindinductive
biasesthatwillpushgenerativemodelstodiscoverandexploitfactorizableinde-
pendent structures in their inputs, which will be required to vault these models
intomoredata-efficientregimes.
1 INTRODUCTION
1.1 BACKGROUND
Text-to-imagegenerativemodelshavedemonstratedincredibleabilityingeneratingphoto-realistic
imagesthatinvolvecombiningelementsininnovativewaysthatarenotpresentinthetrainingdataset
(e.g. astronauts riding a horse on the moon) (Saharia et al., 2022; Rombach et al., 2022; Ramesh
et al., 2021). A na¨ıve possibility is that the training dataset contains all possible combinations of
all elements, and the model memorizes all of these. This would require massive amounts of data,
giventhatthenumberofsuchcombinationsgrowsexponentiallywiththenumberofelements. The
1
4202
beF
5
]GL.sc[
1v50330.2042:viXraUnderreviewasaworkshoppaperatICLR2024
successofgenerativemodelsatconstructingimprobablecombinationsofelementssuggeststhatthey
areabletocompositionallygeneralize,bylearningfactorizedinternalrepresentationsofindividual
elements, and then composing those representations in new ways (Du et al., 2021; Yang et al.,
2023; Du et al., 2023). However, given the massive datasets on which at-scale generative models
are trained, it is difficult to quantitatively assess their ability to extract and combine independent
elementsintheinputdatasets. Thequestionwewouldliketoanswerishowwelldiffusionmodels
learnsemanticallymeaningfulandfactorizedrepresentations.
Toanswerthisquestion,weproposeasimpletask,whichistoreconstructanimagewitha2Dspher-
icalGaussianbumpcenteredatvarious,independentlyvaryingxandy locations. Anaivesolution
is to memorize all possible combinations of the x and y locations, which is expensive. Alterna-
tively, the model can learn x and y as factorized 1D concepts and combine them compositionally.
AschematicillustrationofthetwosolutionsaredepictedinFig.1. Whichsolutionwillthemodel
learn?
(a) (b)
(x,y)
y y
x x
Figure1: Schematicillustrationofafullyfactorizedsolutionvs. anunfactorizedsolution. (a)
isafactorizedsolutionwherethexpositionisgeneratedindependentlyfromthey positionofthe
Gaussian bump by intersecting two oval Gaussian bumps localized in one dimension but not the
other. (b) shows a coupled solution where a single Gaussian bump localized in both dimension
is generated. One difference between the two possibilities is that a network that recognized the
independence of generation in x,y could learn with O(2K) examples, while otherwise it would
takeO(K2)examples.
Specificallyweconductcontrolledexperimentsinthissettingtoinvestigatethefollowingquestions:
1. Howdoestherepresentationlearnedbythemodelrelatetoitsperformance?
2. Howandunderwhatconditionsdosemanticallymeaningfulrepresentationsemerge? How
doestrainingdataaffectthemodel’slearnedrepresentation?
3. Arethelearnedrepresentationsofthemodelsfactorizedunderimbalanceddatasets?
1.2 OURCONTRIBUTIONS
Inthiswork,weaimtotacklethequestionsposedaboveviaanempiricalstudyofatoyconditional
diffusion model using synthetic datasets that can be controllably varied. Our key findings can be
summarizedasfollows:
• Diffusionmodelsundergothreelearningphases. Weobservethethreephasesofmani-
foldformation,includingthreedistinctfailuremodesalongthetrainingprogress.
• Performance is highly correlated with the learned representation. We find that the
formationofanorderedmanifoldisastrongindicatorofgoodmodelperformance.
• Diffusionmodelslearnsemanticallymeaningfulrepresentations. Intheterminallearn-
ing phase, a semantically meaningful representation emerges, and the rate at which it
emergesdependsonthedatadensity.
2UnderreviewasaworkshoppaperatICLR2024
• The learned representations are not efficient (factorized). We discover that even in
imbalanceddatasetswithskewedrepresentationofindependentconcepts,thelearnedman-
ifoldisnotfactorized.
Ourworkisthefirstempiricalstudytothebestofourknowledgethatdemonstratesthephenomenol-
ogyofmanifoldformationinthelatentstatesanditsphasesindiffusionmodelsbyexploitingatoy
model setting with controlled synthetic datasets. Our work demonstrates that a simple diffusion
modelwithastandardarchitecturecannotlearnanefficientrepresentation,andhencewarrantsad-
ditionalengineeringefforts.
2 EXPERIMENTAL SETUP
Dataset Generation. We generate 32 × 32 grayscale images each
consisting of a single 2D spherical Gaussian bump at various locations
of the image. The brightness of the pixel v at position (x,y) in 1 32
(x,y) 1
a given image with a 2D Gaussian bump centered at (µ ,µ ) with
x y
standard deviations of (σ ,σ ) is given by v = 255 × (1 −
exp(cid:8)
−(x−µ
)2/4σ2−(yx −y
µ
)2/4σ2(cid:9)
)
with(x th,y e)
normalized range
σ x
x x y y σ μ y
of v to be [0,255]. Each image is generated with a ground truth y{ y
(x,y)
label of (µ ,µ ), which continuously vary within [0,32]2. In our con-
x y μ
vention of notation, we label the top left corner of the image as (1,1) x
whilethebottomrightcorneroftheimageas(32,32). Asampleimage 32
x
centeredatµ =µ =16withσ =σ =1isshowninFig.2.
x y x y
A dataset of these images consist of the enumeration of all possible Figure 2: Example im-
Gaussians tiling the whole 32 × 32 canvas at increment d in the x- agedata.
x
direction and d in the y-direction. A larger d or d means a sparser
y x y
tilingoftheimagespaceandlessabundantdatawhileasmallerd ord
x y
resultinmoreabundantdatawithdensertilingofthetotalimagespace.
Inasingledataset,weassumethespreadoftheGaussianbumpσ =σ :=σtobeconstant. With
x y
a larger spread leading to more spatial information of neighboring Gaussian bump and a smaller
spreadlessinformation. Byparametericallytuningtheincrementsd andd andthespreadσ,we
x y
cangeneratedatasetsofvarioussparsitiesandoverlaps. Weprovidesomeamoredetailedanalysis
ofthevariousattributesofthedatabasedontheseparametersinAppendixSec.A.5.
Models. WetrainaconditionalDenoisingDiffusionProbabilisticModels(DDPM)(Hoetal.,2020;
Chenetal.,2021;Sahariaetal.,2023)withastandardUNetarchitectureasshowninFig.6inthe
Appendix. Foreachimageinthetrainingdataset,weprovideanexplicitgroundtruthlabel(µ ,µ )
x y
astheinputtotheembedding. Forreference, weinvestigatetheinternalrepresentationlearnedby
the model using the output of layer 4 as labeled in Fig. 6. Since each dataset has inherently two
latentdimensions,x-andy-positions,weusedimensionreductiontoolstoreducetheinternalrep-
resentationofthemodeltoa3Dembeddingfortheeaseofvisualizationandanalysis. Wedeferthe
detailsofmodelarchitecture,dimensionreduction,andexperimentationtoAppendixSectionsA.1
and A.2.
Evaluations. Tobrieflysummarize,weassesstheperformanceofthemodelbasedontheaccuracies
of the images generated and the quality of fit of the 3D embedding of the internal representation
corresponding to the sampled images in predicting the ground truth image labels. We refer to the
twoquantitativeperformanceindicatorsasthepredictedlabelaccuracyandtheaveragedR-squared.
Intuitively, these two metrics range from 0 to 1, with the closer they are to 1 the higher quality of
thegeneratedimages/learnedrepresentation, i.e., thebettertheperformanceofthemodel. Further
detailsonthesemetricscanbefoundinAppendixSec.A.3.
3 RESULTS
Three phases in training. We train various diffusion models on datasets of various increments d
andσ betweenthevalueof0.1to1.0. Forafaircomparisonacrossthesemodels, wefixthetotal
amount of training steps for all models, as measured in units of batches (see Appendix Sec. A.6).
3
{UnderreviewasaworkshoppaperatICLR2024
Wrong Representation Inaccurate Representation Accurate Representation
Phase A Phase B Phase C
Increasing training steps
Figure3: Thethreephasesofmanifoldformation. Thelearnedrepresentations(UMAPreduced,
coloredbythegroundtruthx-positions)ofthediffusionmodelsundergothethreephasesinincreas-
ingorderoftrainingstepsasdepictedinthe3Dvisualizationsinthebottomrow. Ineachphase,the
corresponding qualitative generation behavior is demonstrated with 25 sampled images in the top
row,inwhichthereddotsmarkthegroundtruthlocationsoftheGaussianbumps. (PhaseA)hasno
particularstructureinthelearnedrepresentation,andthegeneratedimageseitherhavenoGaussian
bumps or multiple Gaussian bumps at the wrong locations. (Phase B) has a disordered, quasi-2D
manifoldwithcorrespondinggenerationbehaviorofasingleGaussianbumpatthewronglocation.
(PhaseC)hasanordered2Dmanifoldwiththedesiredgenerationbehavior.
As we increase the amount of training for a given model, we observe the universal emergence of
threephasesinmanifoldformationeachcorrespondingtodistinctgenerationbehavior,asshownin
Fig.3. Inparticular,wenotedthreedistinctfailuremodesduringgeneration,namelyi)noGaussian
bumpisgenerated,ii)asingleGaussianbumpisgeneratedataninaccuratelocation,andiii)multiple
Gaussianbumpsaregeneratedatinaccuratelocations.Duringtheinitialphase(phaseA),theformed
manifold does not have a particular structure or order. The generation behavior during this phase
include all three of the above-mentioned failure modes. As we progressively increase the amount
oftraining,webegintowitnessphaseBemerging,wherethemanifoldformedis2-dimensionalor
quasi-2Dbutunordered. Thepredominantfailuremodeofgenerationduringthisphaseisii,while
the difference between the locations of the generated Gaussian bumps from their ground truths
graduallydiminishesasweproceedintraining. Eventually,themodellearnsa2Dorderedmanifold
withthedesiredgenerationbehavior,reachingtheterminalphaseC.
Internalrepresentationiskeytoperformance. Toinvestigatemodels’performanceandrepresen-
tationslearnedundervariousdatasets,weplotthetwoperformancemetrics,accuracyandaveraged
R-squared, as a function of increasing increments and training steps in Fig. 4. For all datasets of
varying increments, we have fixed the spread of the Gaussian bumps to be σ = 1.0. Noticeably,
comparing Fig. 4 (a) and (b) shows that learning a high-quality representation is key to achieving
betteraccuraciesinimagegeneration. Moreover,ingeneral,weobservethatdatasetswithsmaller
increments lead to faster learning of the desired representation. Hence, given the same amount of
training (having seen the same amount of data), the models trained using datasets that are more
information-dense will result in a better-quality representation learned. On the other hand, with
fewer data, an accurate representation can eventually be learned given enough training to com-
pensate. We briefly comment on the information density of the datasets and discuss the trade-off
betweenoverlapsofneighboringGaussianbumpsandsensitivitytothespatialinformationencoded
inAppendixSec.A.5.
4UnderreviewasaworkshoppaperatICLR2024
(a) (b)
Figure 4: 2D phase diagram of performance metrics as a function of increment and training
steps. (a)showsthepredictedlabelaccuracyand(b)showstheR-squaredaveragedinpredicting
x- and y-positions of the Gaussian bumps from the latent representation. The models are trained
withdatasetsofvariousincrementsfrom0.1to1.0andsigmaof1.0. Thetotalnumberoftraining
stepsareheldconstantacrossallthemodels.
(a) (b)
Figure 5: Performance metrics of models trained using imbalanced datasets. (a) using incre-
mentsofd = 0.1andd = 1.0and(b)usingincrementsofd = 0.1andd = 0.5. Modelsin
x y x y
bothcasesaretrainedwithamplysufficientamountofstepstoreachconvergence.
Thelearnedmanifoldisnotfactorized.Finally,weanswerthequestionofwhethertherepresenta-
tionlearnedisfactorized. Totestthat,wetrainmodelsondatasetsthathaveimbalancedincrements
in the x-direction d compared to the y-direction d . Given such a dataset, we would expect that
x y
themodellearntheseindependentconceptsatdifferentratesbasedontheconclusionfromFig.4,
resulting in a factorized manifold. We tested two scenarios, one of stronger imbalance d = 0.1
x
and d = 1.0, and one of weaker imbalance d = 0.1 and d = 0.5. The performance metrics
y x y
oftheexperimentsinbothcasesareshowninFig.5(a)and(b), respectively. Weseefromthefig-
uresthatdespitehavingmoredatawithfiner-grainedinformationofthex-positions,theaccuracyof
5UnderreviewasaworkshoppaperatICLR2024
generating Gaussian bumpsat the correct y locations is generallyhigher than that at generating at
thecorrectxlocations. Moreover, theR-squaredvaluesinfittingtothex-andthey-positionsare
stronglycorrelated,whichisindicativethattherepresentationslearnedarecoupledratherthanfac-
torized. Overall,weobservethatanimbalanceinthedatasetleadstoadeteriorationinthegeneral
performanceofthemodelratherthanfactorizingtheindependentconcepts.
4 RELATED WORK
Compositional generalization has been empirically investigated in many deep generative models
before (Zhaoetal.,2018;Xuetal.,2022;Okawaetal.,2023). Specifically,Zhaoetal.(2018)in-
vestigatedhowinductivebiasesinGANsandVAEsaffecttheirabilitytocompositionallygeneralize
ontoycognitivepsychologicaltasks. Similarly,Xuetal.(2022)developedanevaluationprotocolto
assesstheperformanceofseveralunsupervisedrepresentationlearningalgorithmsincompositional
generalization,wheretheydiscoveredthatdisentangledrepresentationsdonotguaranteebettergen-
eralization. In a recent empirical study of toy diffusion models, Okawa et al. (2023) shows that
diffusionmodelslearntocompositionallygeneralizemultiplicatively. They,however,didnotfocus
on the mechanistic aspect of the learning dynamics or analyze the representations learned by the
models.
Onealternativedirectionisengineeringinductivebiasesthatencouragetheemergenceofcomposi-
tionalityindiffusionmodelsandbeyond(Esmaeilietal.,2019;Higginsetal.,2018;Duetal.,2021;
Yangetal.,2023;Duetal.,2023). Yangetal.(2023)applieddisentangledrepresentationlearning
techniquestodiffusionmodelstoautomaticallydiscoverconceptsanddisentanglethegradientfield
ofDDPMsintosub-gradientfieldsconditionedinthediscoveredfactors. Alongasimilarline, Du
etal.(2021)proposedanunsupervisedschemefordiscoveringandrepresentingconceptsasseparate
energyfunctionsthatenablesexplicitcompositionandpermutationofthoseconcepts. Inaseriesof
follow-upworks,Liuetal.(2021;2022;2023)exploredcompositionalgenerationwithcomposable
diffusionandenergymodels,aswellasconceptdiscoveryintext-to-imagemodels.
5 CONCLUSION
Do diffusion models learn semantically meaningful and efficient representations? We conduct a
well-controlled toy model study for diffusion models to learn to generate 2D Gaussian bumps at
variousx-andy-positions,givendatasetsthatareparametricallygeneratedtohavevariousdensities
andoverlaps. Throughoutthelearningprocess,weobservethreephasesofthemanifoldformation
and identify corresponding generation behavior with distinctive failure modes in each phase. By
comparingmodelstrainedunderdatasetsofdifferentsizesandoverlaps,weconcludethatlearninga
semanticallymeaningfulrepresentationisessentialtomodel’sperformance.Moreover,weobserved
that models learned a coupled representation of the independent latent features despite trained us-
ing imbalanced datasets. This leads us to conclude that a na¨ıve architecture of diffusion models
donothavetheinductivebiasthatfavorstheemergenceofdisentangled/factorizedrepresentation.
Hence, further investigation on how to learn factorized representation is warranted. A potential
futuredirectionwouldbetoanalyzebiasesthatcouldenablethelearningandgenerationoffactor-
izedrepresentationsindiffusionmodelsandbeyondinacontrolledsettingtobetterunderstandand
overcomesomeofthelimitationsofcurrentdeepgenerativemodelsincompositionalgeneralization.
ACKNOWLEDGMENTS
WethankYilunDuforhelpfuldiscussionsatthepreliminarystageofourwork.
REFERENCES
NanxinChen,YuZhang,HeigaZen,RonJ.Weiss,MohammadNorouzi,andWilliamChan. Wave-
grad:Estimatinggradientsforwaveformgeneration.In9thInternationalConferenceonLearning
Representations,ICLR2021,VirtualEvent,Austria,May3-7,2021.OpenReview.net,2021.URL
https://openreview.net/forum?id=NsMLjcFaO8O.
6UnderreviewasaworkshoppaperatICLR2024
Yilun Du, Shuang Li, Yash Sharma, Josh Tenenbaum, and Igor Mordatch. Unsupervised
learning of compositional energy concepts. In Marc’Aurelio Ranzato, Alina Beygelz-
imer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan (eds.), Advances
in Neural Information Processing Systems 34: Annual Conference on Neural Informa-
tion Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 15608–
15620, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/
838aac83e00e8c5ca0f839c96d6cb3be-Abstract.html.
Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fergus,
Jascha Sohl-Dickstein, Arnaud Doucet, and Will Sussman Grathwohl. Reduce, reuse, recycle:
Compositionalgenerationwithenergy-baseddiffusionmodelsandMCMC. InAndreasKrause,
Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett
(eds.),InternationalConferenceonMachineLearning,ICML2023,23-29July2023,Honolulu,
Hawaii,USA,volume202ofProceedingsofMachineLearningResearch,pp.8489–8510.PMLR,
2023. URLhttps://proceedings.mlr.press/v202/du23a.html.
Babak Esmaeili, Hao Wu, Sarthak Jain, Alican Bozkurt, N. Siddharth, Brooks Paige, Dana H.
Brooks,JenniferG.Dy,andJan-WillemvandeMeent. Structureddisentangledrepresentations.
In Kamalika Chaudhuri and Masashi Sugiyama (eds.), The 22nd International Conference on
Artificial Intelligence and Statistics, AISTATS 2019, 16-18 April 2019, Naha, Okinawa, Japan,
volume 89 of Proceedings of Machine Learning Research, pp. 2525–2534. PMLR, 2019. URL
http://proceedings.mlr.press/v89/esmaeili19a.html.
Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P. Burgess, Matko Bosnjak,
Murray Shanahan, Matthew M. Botvinick, Demis Hassabis, and Alexander Lerchner. SCAN:
learning hierarchical compositional visual concepts. In 6th International Conference on Learn-
ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference
TrackProceedings.OpenReview.net,2018.URLhttps://openreview.net/forum?id=
rkN2Il-RZ.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In
Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-
Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Con-
ference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12,
2020,virtual,2020. URLhttps://proceedings.neurips.cc/paper/2020/hash/
4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html.
Nan Liu, Shuang Li, Yilun Du, Josh Tenenbaum, and Antonio Torralba. Learning to compose
visual relations. In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang,
and Jennifer Wortman Vaughan (eds.), Advances in Neural Information Processing Systems 34:
Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December
6-14,2021,virtual,pp.23166–23178,2021.URLhttps://proceedings.neurips.cc/
paper/2021/hash/c3008b2c6f5370b744850a98a95b73ad-Abstract.html.
NanLiu,ShuangLi,YilunDu,AntonioTorralba,andJoshuaB.Tenenbaum. Compositionalvisual
generation with composable diffusion models. In Shai Avidan, Gabriel J. Brostow, Moustapha
Cisse´, Giovanni Maria Farinella, and Tal Hassner (eds.), Computer Vision - ECCV 2022 - 17th
European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part XVII, volume
13677 of Lecture Notes in Computer Science, pp. 423–439. Springer, 2022. doi: 10.1007/
978-3-031-19790-1\ 26. URL https://doi.org/10.1007/978-3-031-19790-1_
26.
NanLiu, YilunDu, ShuangLi, JoshuaB.Tenenbaum, andAntonioTorralba. Unsupervisedcom-
positionalconceptsdiscoverywithtext-to-imagegenerativemodels. InIEEE/CVFInternational
ConferenceonComputerVision,ICCV2023,Paris,France,October1-6,2023,pp.2085–2095.
IEEE, 2023. doi: 10.1109/ICCV51070.2023.00199. URL https://doi.org/10.1109/
ICCV51070.2023.00199.
Leland McInnes and John Healy. UMAP: uniform manifold approximation and projection for di-
mensionreduction. CoRR,abs/1802.03426, 2018. URLhttp://arxiv.org/abs/1802.
03426.
7UnderreviewasaworkshoppaperatICLR2024
Leland McInnes, John Healy, Nathaniel Saul, and Lukas Grossberger. Umap: Uniform manifold
approximationandprojection. TheJournalofOpenSourceSoftware,3(29):861,2018.
MayaOkawa,EkdeepSinghLubana,RobertP.Dick,andHidenoriTanaka. Compositionalabilities
emergemultiplicatively: Exploringdiffusionmodelsonasynthetictask. CoRR,abs/2310.09336,
2023. doi: 10.48550/ARXIV.2310.09336. URL https://doi.org/10.48550/arXiv.
2310.09336.
AdityaRamesh,MikhailPavlov,GabrielGoh,ScottGray,ChelseaVoss,AlecRadford,MarkChen,
andIlyaSutskever. Zero-shottext-to-imagegeneration. InInternationalConferenceonMachine
Learning,pp.8821–8831.PMLR,2021.
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjo¨rn Ommer. High-
resolutionimagesynthesiswithlatentdiffusionmodels. InProceedingsoftheIEEE/CVFconfer-
enceoncomputervisionandpatternrecognition,pp.10684–10695,2022.
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar
Ghasemipour,RaphaelGontijoLopes,BurcuKaragolAyan,TimSalimans,etal. Photorealistic
text-to-imagediffusionmodelswithdeeplanguageunderstanding. AdvancesinNeuralInforma-
tionProcessingSystems,35:36479–36494,2022.
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet, and Mohammad
Norouzi.Imagesuper-resolutionviaiterativerefinement.IEEETrans.PatternAnal.Mach.Intell.,
45(4):4713–4726,2023. doi: 10.1109/TPAMI.2022.3204461. URLhttps://doi.org/10.
1109/TPAMI.2022.3204461.
Zhenlin Xu, Marc Niethammer, and Colin Raffel. Compositional generalization in unsupervised
compositional representation learning: A study on disentanglement and emergent language. In
Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh (eds.), Ad-
vances in Neural Information Processing Systems 35: Annual Conference on Neural Informa-
tionProcessingSystems2022,NeurIPS2022,NewOrleans,LA,USA,November28-December
9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/
9f9ecbf4062842df17ec3f4ea3ad7f54-Abstract-Conference.html.
TaoYang,YuwangWang,YanLv,andNanningZheng. Disdiff: Unsuperviseddisentanglementof
diffusionprobabilisticmodels.CoRR,abs/2301.13721,2023.doi:10.48550/ARXIV.2301.13721.
URLhttps://doi.org/10.48550/arXiv.2301.13721.
Shengjia Zhao, Hongyu Ren, Arianna Yuan, Jiaming Song, Noah D. Goodman, and Stefano Er-
mon. Bias and generalization in deep generative models: An empirical study. In Samy Ben-
gio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo` Cesa-Bianchi, and Roman
Garnett (eds.), Advances in Neural Information Processing Systems 31: Annual Conference on
Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montre´al,
Canada, pp. 10815–10824, 2018. URL https://proceedings.neurips.cc/paper/
2018/hash/5317b6799188715d5e00a638a4278901-Abstract.html.
A EXPERIMENTAL DETAILS
A.1 ARCHITECTURE
We train a conditional Denoising Diffusion Probabilistic Models (DDPM) Ho et al. (2020) with
a standard UNet architecture of 3 downsampling and upsampling blocks, interlaced self-attention
layers, and skip connections as shown in Fig. 6. Each down/up-sampling blocks consist of max
pooling/upsamplinglayersfollowedbytwodoubleconvolutionallayersmadeupbyconvolutional
layers,groupnormalization,andGELUactivationfunctions.
Theconditionalinformationispassedinateachdown/up-samplingblockasshownintheschematic
drawing. Inourexperiments, wechoosetopreservethecontinuityoftheGaussianbumpposition
labelspassedintothemodelviapositionalencodingratherthanusingaseparatetrainableembedding
layer at each block. Each embedding vector is made by concatenating equal length vectors of the
positionalencodingsofthetimestep,thex-position,andthey-position.
8UnderreviewasaworkshoppaperatICLR2024
Network Architecture:
Embedding Scheme:
Layer 0 Down(64,128)
Positional Positional
Embedding = encoding for ⊕ encoding for
time steps features
Layer 1 Down(128,256)
Positional Encoding:
Layer 2 Down(256,256)
Self-attention
PE (t,2i)=sin(t/100002 /id
) ∀i∈{0,…,N/2−1}
layer of Bottleneck PE (t,2i+1)=cos(t/100002i+ /1d )
corresponding
sizes
Layer 3 Up(512,128)
Positional Encoding Concatenation:
Layer 4 Up(256,64)
Time PEt N ⊕ X PEx N ⊕Y PEy N
Layer 5 Up(128,64)
Figure6: TheUNetarchitectureoftheconditionaldiffusionmodel. Theschematicdiagramof
thestandardUNetarchitectureconsistingofthreedownsampling/upsamplingblockswithinterlaced
self-attention layers and skip connections is shown on the left. The conditional information con-
sistingofaconcatenationofpositionalencodingsoftimestepandx/y-positionsispassedinateach
blockasshownontheright.
Inourexperiments,wevisualizetheoutputsoflayer4astheinternalrepresentationofthediffusion
model. We have chosen not to use the output of the bottleneck layer for our study of the learned
latentmanifold,aswehaveobservedthatthebottlenecklayershavediminishingsignalsinmostof
ourexperiments.
A.2 DIMENSIONREDUCTION
WeprimarilyusethedimensionreductiontechniqueUniformManifoldApproximationandProjec-
tionforDimensionReduction(UMAP)McInnes&Healy(2018)tostudyandvisualizethelearned
representationofthemodel. Specifically,wecollectimagesamplesandtheircorrespondinginternal
representations(outputsoflayer4fromthearchitecturedescribedinSec.A.1). Wethentransform
thehigh-dimensionalinternalrepresentationsintoa3Dembeddingasasampleofthelearnedrep-
resentation,whichwevisualizeandanalyze. ForanimplementationofUMAP,weusedthePython
packageMcInnesetal.(2018).
A.3 EVALUATION
Weassesstheperformanceofthemodelusingtwoprimarycriteria: 1)thequalityofthedenoised
imagesand2)thequalityofthelearnedrepresentation.
Atagiventimeduringoraftertraining,wegenerate500denoisedimagesandtheircorresponding
internal representations of randomly sampled labels based on the training dataset. We predict the
labelsfromtheimagegeneratedbasedonthex-andy-positionsofthegeneratedGaussianbumpin
theimage. Wethencomputetheaccuracyofpredictedlabelsfromthegroundtruthlabelsaveraged
over500samplesas
500
1 (cid:88)
Accuracy= 1(|µi −µˆi|<1)·1(|µi −µˆi|<1), (1)
500 x x y y
i=1
where 1(·) is an indicator function that returns 1 if the expression within holds true, 0 otherwise.
Similarly, we can modify this expression to only assess the accuracy of generated x-positions or
y-positions separately. Here we estimate the center of the Gaussian bump µˆi and µˆi using a la-
x y
belpredictionalgorithmdescribedinAlg.1implementedusingOtsu’simagethresholdingandthe
contour-findingalgorithmintheOpenCVpackage,abbreviatedascv2. Inthecaseswherethereare
nobumpsormorethanonebump,thealgorithmdefaultsbacktofindingthecentroidoftheimage.
9UnderreviewasaworkshoppaperatICLR2024
Algorithm1Labelpredictionalgorithm
1: functionLABELPREDICTION(img)
2: (T,thresh)←cv2.threshold(img,0,255,cv2.THRESH BINARY INV|cv2.THRESH OTSU)
3: contours, ←cv2.findContours(thresh,cv2.RETR ExTERNAL,cv2.CHAIN APPROx SIMPLE)
4: iflen(contours)=0orlen(contours)>1then
5: returnCOMPUTECENTROID2D(img)
6: endif
7: max contour←max(contours,key=cv2.contourArea)
8: (x,y,w,h)←cv2.boundingRect(max contour)
9: cx←x+ w
2
10: cY ←y+ h
2
11: return(cx,cY)
12: endfunction
To assess the quality of the learned representation, we perform two 1D linear regressions on the
UMAP-reduced3Dembeddingoftheinternalrepresentations(outputsoflayer4)correspondingto
the 500 sampled images. We use the R-squared values of fit in both predicting µ and µ as an
x y
indicatorforthequalityofthemanifoldlearnedinrepresentingx-andy-positionsoftheGaussian
bumps.
A.4 TRAININGLOSS
DiffusionmodelsiterativelydenoiseaGaussiannoisyimagex intoanoisefreeimagex overdif-
T 0
fusiontimestepst∈{0,1,...,T}giventheforwarddistributionq(x |x )bylearningthereverse
t t−1
distribution p (x |x ). Given a conditional cue c, a conditional diffusion model (Chen et al.,
θ t−1 t
2021; Saharia et al., 2023) reconstructs an image from a source distribution q(x |c). Specifically,
0
wetrainourneuralnetwork(UNet)topredictthedenoisingdirectionϵ (x ,t,c)atagiventimestep
θ t
t with conditional cue c with the goal of minimizing the mean squared loss (MSE) between the
predictedandthegroundtruthnoiseϵasfollows
L:=E (cid:2) ∥ϵ−ϵ (x ,t,c)∥2(cid:3) , (2)
t∈{0,...,T},x0∼q(x0|c),ϵ∼N(0,I) θ 0
whereweassumeeachnoisevectorϵtobesampledfromaGaussiandistributionN(0,I)I.I.D.at
eachtimestept.
A.5 DATASETS
ThedatasetsweusedfortrainingthemodelsgeneratingtheresultsinSec.3havevariousincrements
d /d andσ. Herewebrieflycommentontheinterplaybetweenincrementsandsigmas, andhow
x y
they affect dataset densities and overlaps. The ultimate goal of our task of interest is to learn a
continuous2DmanifoldofallpossiblelocationsoftheGaussianbumps. Ourdatasetsarediscrete
approximationsofcontinuousmanifoldthatcanbethoughtofasa“web”witheachdatapointasa
“knot,”aschematicillustrationisshowninFig.7(a). Intuitively,thespatialinformationnecessary
foranorganized, continuous, andsemanticallymeaningfulrepresentationtoemergeisencodedin
theoverlapoftheneighboringGaussianbumps,whichistunedviatheparametersdandσ. Aswe
increased,thesizeofthedatasetgetsscaledquadratically,resultingineachGaussianbumptohave
moreoverlapwithitsneighbors.
As we scale up σ, the dataset size remains fixed while the overlaps with neighbors are signifi-
cantlyincreased. InFig.7(b),weplotthenormalizedL2-normoftheproductimageofneighboring
Gaussian bumps as a function of increments for various spreads. Specifically, given two inverted
grayscaleGaussianbumpimages,aandb,thenormalizedL2-normoftheirproductisgivenbythe
√
formula ∥ a∗b∥ /∥a∥ , where ∗ is element-wise multiplication and ∥·∥ is the L2-norm. This
2 2 2
quantityshouldgivearoughmeasureoftheimageoverlapwiththeexceptionatincrementaround
0.5duetothediscretenatureofourdata. Moreover,wenotethatthecuspsinthecurvesoccurfor
the same reason. As we can see, the number of neighbors that a given Gaussian bump has non-
trivialoverlapswithgrowsroughlylinearlytosub-linearlywiththespread. Nonetheless,inSec.B.1
weshowthatthereisnostrongcorrelationbetweenperformanceortherateatwhichsemantically
meaningfulrepresentationsemergesandthespreadoftheGaussianbumps.
10UnderreviewasaworkshoppaperatICLR2024
(a) (b)
d
x
d
y{
i) ii)
iii) iv)
Figure7:TheoverlapofGaussianbumpswithvariousspreads.(a)isaschematicdemonstration
the interplay between the increment d /d and the spread of the Gaussians determined by σ. The
x y
labeleddiagrami-iv)showsexamplesofhavingnooverlap(noneighborinformation),nearestneigh-
boroverlap, nearestneighborandadjacentoverlap, andN-nearestneighborsoverlap, respectively.
(b)showsthenormalizedL2-normoftheinvertedGaussianimageoverlaps.
A.6 TRAININGDETAILS
We train various diffusion models on datasets of various increments d and σ from the range
{0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0}. For each model, we fix the total training steps to be
320,000(numberofepochs×thedatasetsizeinunitsofbatches). Wetrainthemodelsonaquad-
coreNvidiaA100GPU,andanaveragetrainingsessionlastsaround6hours. Foreachmodelwe
runthreeseparateseedsandselecttherunthatachievetheoptimalaccuracyatterminalepoch. To
producetheresultsshowninFig.4andFig.8,wesample500imagesaswellastheircorresponding
outputsatlayer4every6400trainingstepsandattheterminalstep.
B ADDITIONAL RESULTS
B.1 THEROLEOFSIGMA
Previously,inAppendixSec.A.5,wehavediscussedhowspatialinformationencodedinthedatasets
variesbasedontheincrementdandthespreadσ.WeshowinSec.3thatindeedasmallerincrement
resultsinafasterrateofconvergenceleadingtoasemanticallymeaningfullatentrepresentation. In
Fig.8,weshowtheperformancemetricsasafunctionofsigmaandtrainingstepsforthreeseparate
incrementsd = 0.1,0.5,1.0. Thereis,however,nostrongcorrelationbetweenmodelperformance
and increasing sigma. One possible explanation for this could be the fact that changing sigma
only results in a modest change in the dataset (linear to sub-linear in the number of overlapping
neighbors),unlikechangingincrements,whichresultsinaquadraticchangeinthedatasetinaddition
to more fine-grained embeddings. Moreover, we noticed that for some seeds, some of the sigmas
thatwehavetesteddonotlearnasemanticallymeaningfulmanifold. Thisseeddependenceissueis
exacerbatedwithmodelstrainedusingdatasetsofbiggerincrements.
B.2 COMPOSITIONALGENERALIZATIONPERFORMANCE
Can the models compositionally generalize well? To answer this question, we train two models
underanincompletetrainingdatasetofd = 0.1andσ = 1.0,wherewedeliberately“pokeahole”
in the middle of the data manifold and see if the model can still learn an accurate representation.
Fig. 9 shows the performance metrics of the model trained under ∼ 3.5% (a smaller hole) and
∼ 10%(abiggerhole). Wenotethatgivensufficientamountoftraining,bothmodelswereableto
constructasemanticallymeaningful2Drepresentation,withtheaccuracyoftheOODonlyslightly
worseoffinthecasewhere∼10%ofthedataisskippedascomparedtothatwhereonly∼3.5%is
11
{UnderreviewasaworkshoppaperatICLR2024
(a)
(b)
(c)
Figure 8: Phase diagrams of performance metrics as a function of sigmas and training steps
forvariousincrements. (a)Increment=0.1,(b)Increment=0.5,(c)Increment=1.0.
skipped. Ingeneral,themodelswereabletosuccessfullycompositionallygeneralize,althoughthe
mechanismofhowtheydosowarrantsfurtherinvestigation.
12UnderreviewasaworkshoppaperatICLR2024
(a)
(13,13)
(19,19)
(b)
(11,11)
(21,21)
Figure 9: Performance metrics of models trained under an incomplete set of training data.
Bothmodelsaretrainedusingadatasetofd = 0.1andσ = 1.0,with(a)∼ 3.5%and(b)∼ 10%
of the training dataset skipped during training. The training data images with Gaussian bumps
centered within the red-shaded regions in the sample OOD images shown on the left are skipped
duringtraining.
13
DOO
%5.3~
DOO
%01~