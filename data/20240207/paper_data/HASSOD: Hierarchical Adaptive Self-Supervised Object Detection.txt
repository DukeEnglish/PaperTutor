HASSOD: Hierarchical Adaptive Self-Supervised
Object Detection
ShengcaoCao1 DhirajJoshi2 Liang-YanGui1 Yu-XiongWang1
1UniversityofIllinoisatUrbana-Champaign 2IBMResearch
1{cao44,lgui,yxw}@illinois.edu 2djoshi@us.ibm.com
Abstract
Thehumanvisualperceptionsystemdemonstratesexceptionalcapabilitiesinlearn-
ingwithoutexplicitsupervisionandunderstandingthepart-to-wholecomposition
ofobjects. Drawinginspirationfromthesetwoabilities,weproposeHierarchical
Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that
learnstodetectobjectsandunderstandtheircompositionswithouthumansupervi-
sion.HASSODemploysahierarchicaladaptiveclusteringstrategytogroupregions
intoobjectmasksbasedonself-supervisedvisualrepresentations,adaptivelyde-
termining the number of objects per image. Furthermore, HASSOD identifies
thehierarchicallevelsofobjectsintermsofcomposition,byanalyzingcoverage
relations between masks and constructing tree structures. This additional self-
supervisedlearningtaskleadstoimproveddetectionperformanceandenhanced
interpretability. Lastly,weabandontheinefficientmulti-roundself-trainingprocess
utilized in prior methods and instead adapt the Mean Teacher framework from
semi-supervisedlearning,whichleadstoasmootherandmoreefficienttraining
process. Throughextensiveexperimentsonprevalentimagedatasets,wedemon-
stratethesuperiorityofHASSODoverexistingmethods,therebyadvancingthe
state of the art in self-supervised object detection. Notably, we improve Mask
ARfrom20.2to22.5onLVIS,andfrom17.0to26.0onSA-1B.Projectpage:
https://HASSOD-NeurIPS23.github.io.
1 Introduction
Thedevelopmentofhumanvisualperceptionisremarkablefortwokeyabilities: 1)Humansbegin
learningtoperceiveobjectsintheirenvironmentthroughobservationalone[25],withoutneeding
to learn the names of these objects from external supervision. 2) Moreover, human perception
operatesinahierarchicalmanner,enablingindividualstorecognizethepart-to-wholecompositionof
objects[2,23]. Thesecharacteristiccapabilitiesoffervaluableinsightsintothelearningprocesses
ofobjectdetectors,whichstillheavilyrelyontheavailabilityandqualityoffine-grainedtraining
data. For example, the state-of-the-art detection/segmentation model, Segment Anything Model
(SAM)[18],isdevelopedonadatasetof11millionimagesand1billionobjectmasks. Itremainsan
openquestionhowtoeffectivelylearntodetectobjectsandrecognizetheircompositionsfromeven
larger-scaledatasets(e.g.,LAION-5B[26])withoutsuchobject-levelannotations.
Inpriorworkonself-supervisedobjectdetection[37,38],atwo-stagediscover-and-learnparadigmis
adopted: 1)Self-supervisedvisualrepresentations[5,15]areobtained,andasaliency-basedmethod
isemployedtoextractthemostprominentoneorfewobjects. 2)Subsequently,anobjectdetector
istrainedbasedonthesepseudo-labels, sometimesinvolvingmultipleroundsofself-trainingfor
refinement. However,despitesuchattemptstoeliminatetheneedforexternalsupervision,several
weaknessespersistintheseapproaches:1)Narrowcoverageofobjects.Thefocusononlyoneorfew
objectsperimageinpreviousmethodsunderminestheirabilitytofullyexploitthelearningsignalsin
37thConferenceonNeuralInformationProcessingSystems(NeurIPS2023).
4202
beF
5
]VC.sc[
1v11330.2042:viXraInput CutLER HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure1:Fullyself-supervisedobjectdetectionandinstancesegmentationonprevalentimagedatasets.
Ourapproach,HASSOD,demonstratesasignificantimprovementoverthepreviousstate-of-the-art
method,CutLER[38],bydiscoveringamorecomprehensiverangeofobjects. Moreover,HASSOD
understandsthepart-to-wholeobjectcompositionlikehumansdo,whilepreviousmethodscannot.
naturalsceneimagescontainingdozensofobjects,suchasthoseintheMS-COCOdataset[20]. This
narrowfocusalsorestrictsthecapabilityofthesemethodstoaccuratelydetectandsegmentmultiple
objectswithinanimage. 2)Lackofcomposition. Priorworkoftenoverlooksthecompositionof
objects,neglectingtheidentificationofhierarchicallevelsforwholeobjects,partobjects,andsubpart
objects(e.g.,consideringanimageofabicycle;thebicycleisawholeobject,itswheelsandhandles
areparts,andthespokesandtiresaresubparts). Thisoversightnotonlylimitstheinterpretabilityof
learnedobjectdetectors,butalsohindersthemodel’sabilitytotackletheintrinsicambiguityinthe
taskofsegmentation. 3)Inefficiency. Therelianceonmulti-roundself-traininginearliermethods
canresultininefficientandnon-smoothtrainingprocesses,whichfurtherconstrainsthepotentialof
self-supervisedobjectdetectionandcomprehensionofobjectcomposition.
Inspiredbytheunsupervised,hierarchicalhumanvisualperceptionsystem,weproposeHierarchi-
cal Adaptive Self-Supervised Object Detection (HASSOD), aiming to address these limitations
mentionedaboveandbetterharnessthepotentialofself-supervisedobjectdetection,asdepictedin
Figure1. First,unlikepreviousmethodsthatlimittheirfocustooneorfewprominentobjectsper
image,HASSODemploysahierarchicaladaptiveclusteringstrategytogroupregionsintoobject
masks,basedonself-supervisedvisualrepresentations. Byadjustingthethresholdforterminatingthe
clusteringprocess,HASSODiscapableofeffectivelydeterminingtheappropriatenumberofobjects
perimage,thusbetterleveragingthelearningsignalsinimageswithmultipleobjects.
ThesecondkeycomponentofHASSODisitsabilitytoidentifyhierarchicallevelsofobjectsinterms
ofcomposition. Byanalyzingthecoveragerelationsbetweenmasksandbuildingtreestructures,
ourapproachsuccessfullyclassifiesobjectsaswholeobjects,partobjects,orsubpartobjects. This
novelself-supervisedlearningtasknotonlyimprovesdetectionperformance,butalsoenhancesthe
interpretabilityandcontrollabilityofthelearnedobjectdetector,apropertythatpriorself-supervised
detectors lack. Therefore, HASSOD users can comprehend how the detected whole objects are
assembledfromsmallerconstituentparts. Simultaneously,theycancontrolHASSODtoperform
detectionattheirpreferredhierarchicallevel,therebycateringmoreeffectivelytotheirneeds.
Finally, HASSOD abandons the multi-round self-training used in previous methods which lacks
efficiencyandsmoothness. Instead,wetakeinspirationfromtheMeanTeacher[22,31]framework
insemi-supervisedlearning, employingateachermodelandastudentmodelthatmutuallylearn
fromeachother. Thisinnovativeadaptationfacilitatesasmootherandmoreefficienttrainingprocess,
resultinginamoreeffectiveself-supervisedobjectdetectionapproach.
Insummary,thekeycontributionsofHASSODinclude:
2
SIVL
563stcejbO
B1-AS• Ahierarchicaladaptiveclusteringstrategythatgroupsregionsintoobjectmasksbasedonself-
supervisedvisualrepresentations,adaptivelydeterminingthenumberofobjectsperimageand
effectivelydiscovermoreobjectsfromnaturalscenes.
• Theabilitytoidentifyhierarchicallevelsofobjectsintermsofcomposition(whole/part/subpart)
byanalyzingcoveragerelationsbetweenmasksandbuildingtreestructures,leadingtoimproved
detectionperformanceandenhancedinterpretability.
• AnoveladaptationoftheMeanTeacherframeworkfromsemi-supervisedlearning,whichreplaces
themulti-roundself-traininginpriormethods,leadingtosmootherandmoreefficienttraining.
• State-of-the-artperformanceinself-supervisedobjectdetection,enhancingMaskARfrom20.2to
22.5onLVIS[11],andfrom17.0to26.0onSA-1B[18]. Remarkably,theseresultsareachieved
throughtrainingwithonly1/5oftheimagesand1/12oftheiterationsrequiredbypriorwork.
2 RelatedWork
Unsupervisedobjectdetection/discovery. Identifyingandlocatingobjectsinimageswithoutusing
any human annotations is a challenging task, as it requires learning the concept of objects from
image data without any external supervision. OSD [33] formulates this task as an optimization
problemonagraph, wherethenodesareobjectproposalsgeneratedbyselectivesearch, andthe
edges are constructed based on visual similarities. rOSD [34] improves the scalability of OSD
with a saliency-based region proposal algorithm and a two-stage strategy. LOD [35] formulates
unsupervisedobjectdiscoveryasarankingoptimizationproblemforimprovedcomputationefficiency.
FollowingtheobservationthatDINO[5],aself-supervisedpre-trainingmethod,cansegmentthemost
prominentobjectineachimage,LOST[29],FOUND[30],andFreeSOLO[37]trainobjectdetectors
using saliency-based pseudo-labels. TokenCut [39] and CutLER [38] also use self-supervised
representations, but generate pseudo-labels by extending Normalized Cuts [28]. Saliency-based
regionproposalandNormalizedCutsarebothfocusedontheprominentobjectsineachimage,and
usually only propose one or few objects per image. Different from these approaches, HASSOD
producesinitialpseudo-labelsusingahierarchicaladaptiveclusteringstrategy,whichcanadaptively
determinethenumberofobjectsdependingontheimagecontents.
Objectdetectionbyparts. Detectingobjectsbyidentifyingtheircomposingpartshasbeenwidely
studiedincomputervision. DeformablePartsModel(DPM)[9]isaseminalapproachthatutilizes
discriminativelytrainedpart-basedmodelsforobjectdetection,whicheffectivelymodelscomplex
objectstructuresandimprovesovermonolithicdetectors. Afollowingmethod[6]notonlydetects
theobjects,butalsosimultaneouslyrepresentsthemusingbodyparts,highlightingtheimportanceof
bothholisticmodelsandpart-basedrepresentations. Thisideaisextendedbyleveragingbothwhole
objectandpartdetectionstoinferhumanactionsandattributes[10],suggestingtheadvantageofa
combinedapproach. Inthiswork,werevisitthisclassicideaofrepresentinganddetectingwhole
objectsaswellastheirpartsinthecontextofself-supervisedlearning.
3 Approach
In this section, we introduce the learning process in our proposed approach, Hierarchical Adap-
tiveSelf-SupervisedObjectDetection(HASSOD).Followingpriorworkonunsupervisedobject
detection[29,30,37–39],HASSODadoptsatwo-stagediscover-and-learnprocesstolearnaself-
supervised object detector, as illustrated in Figure 2. In the first stage, we discover objects from
unlabeledimagesusingself-supervisedrepresentations,andgenerateasetofinitialpseudo-labels.
Theninthesecondstage,welearnanobjectdetectorbasedontheinitialpseudo-labels,andsmoothly
refinethemodelbyself-training. Thefirststageisbasedonpre-trained,fixedvisualfeatures,andthe
secondstagelearnsanobjectdetectortoimproveoverthefixedvisualfeaturesandpseudo-labels. In
thefollowingsubsections,wedescribethethreecorecomponentsofHASSODindetail.
3.1 HierarchicalAdaptiveClustering
In the first stage, HASSOD creates a set of pseudo-labels as the initial self-supervision source.
Weproposeahierarchicaladaptiveclusteringstrategytodiscoverobjectmasksaspseudo-labels,
usingonlyunlabeledimagesandafrozenself-supervisedvisualbackbone. Figure3providesan
overviewofthisprocedure. Ourhierarchicaladaptiveclusteringalgorithmextendsagglomerative
3Stage 1: Initial Pseudo-Label Discovery Stage 2: Object Detector Learning
(Section 3.1) (Sections 3.2 & 3.3)
Unlabeled Frozen Initial Pseudo- Object Detector
Raw Images DINO ViT Labeled Masks Cascade Mask R-CNN
Mean Teacher
Self-Training
Figure2: Two-stagediscover-and-learnprocessinHASSOD.Stage1usesafrozen,self-supervised
DINO[5]ViTbackbonetodiscoverinitialpseudo-labelsfromunlabeledimages. Stage2learnsan
objectdetectortoimproveoverthepre-trainedfeaturesandinitialpseudo-labels.
𝜃’"#$%#=0.1 Whole Hierarchical
Post- Levels of Objects
Process
Patch-Level Merge All Initial
Features 𝜃!"#$%#=0.2 Pseudo-Labels Part
DINO Post- Ensem-
ViT Process ble Split
Merge
𝜃&"#$%#=0.4 Subpart
Merge
Post-
Process
Figure3:Hierarchicaladaptiveclusteringandhierarchicallevelsofobjects.Theprocedureofcreating
initial pseudo-labels for training the object detector without any human annotations includes the
followingsteps: (Initialize)VisualfeaturesareextractedfromthegivenimagebyaViTpre-trained
withDINO[5],andeach8×8patchisinitializedasoneindividualregion. (Merge)Adjacentregions
withthehighestfeaturesimilaritiesareprogressivelymergedintoobjectmasks, untilthepre-set
thresholdsθmerge arereached. (Post-Process)Objectmasksareselectedandrefinedusingsimple
i
post-processingtechniques. (Ensemble)Resultsfrommultiplethresholds{θmerge}3 arecombined
i i=1
toensurebettercoverageofpotentialobjects. (Split)Analysisofcoveragerelationsdividesobjects
intothreehierarchicallevels: whole,part,andsubpart. Theexampleontherightillustratesthetree
structureofobjectcomposition: Thewholeaircraftiscomposedofanupperandalowerpart. The
upperpartfurtherconsistsofaleftwing,arightwing,andapersonstandingonit.
clustering [12], grouping adjacent image patches into semantically coherent masks based on the
similarity of self-supervised visual representations. More specifically, we use a frozen ViT-B/8
model [8] pre-trained on unlabeled ImageNet [7] by DINO [5], a self-supervised representation
learningmethod,toextractvisualfeatures. Foreachimage,wetakethefeaturemapgeneratedby
thismodelatitsfinalTransformerlayer[32]. Eachspatialelementinthefeaturemapcorrespondsto
a8×8patchintheoriginalimage.
Toinitiatethehierarchicaladaptiveclusteringprocess,wetreateachpatchasanindividualregion.
Wethencomputethepairwisecosinesimilaritybetweenthefeaturesofadjacentregionstomeasure
their closeness in the semantic feature space. The regions are gradually merged into masks that
representobjectsbyiterativelyperformingthefollowingsteps:1)Identifythepairofadjacentregions
withthehighestfeaturesimilarity. 2)Ifthesimilarityissmallerthanthepre-setthresholdθmerge,stop
themergingprocess. 3)Mergethetworegions,andcomputethefeatureofthemergedregionby
averagingallthepatch-levelfeatureswithinit. 4)Updatethepairwisesimilaritybetweenthisnewly
mergedregionanditsneighbors. ThismergingprocessisvisualizedinFigure3,columns1-3.
Oncethemergingprocessiscomplete,weperformaseriesofautomatedpost-processingstepsto
refineandselectthemasks,includingConditionalRandomField(CRF)[19]andfilteringoutmasks
thataresmallerthan100pixelsorcontainmorethantwocornersoftheimage. Thesestepsarebased
onstandardpracticesinpreviouswork[38]andrequirenomanualintervention. Ourhierarchical
adaptiveclusteringstrategyeffectivelygroupsregionsintoobjectmasksbasedonself-supervised
visual representations, adaptively determining the appropriate number of objects per image. In
4imagescontainingmultipleobjectswithheterogeneoussemanticfeatures,themergingprocessstops
earlier, resultinginalargernumberofregionscorrespondingtodifferentobjects. Conversely, in
highlyhomogeneousimages,moreregionsaremerged,leadingtofewerobjectmasks. Thisadaptive
approachenablesHASSODtocovermoreobjectsforself-supervisedlearning,ratherthanbeing
limitedbyoneorafewprominentobjectsineachimageinpriorwork[38,39].
In practice, we are not restricted to one single fixed threshold θmerge to determine the stopping
criterionfortheclusteringprocess. Instead,wefinditbeneficialtoensembleresultsfrommultiple
(e.g.,3)pre-setthresholds{θmerge}3 . Whenthecurrentlyhighestfeaturesimilarityreachesoneof
i i=1
thesethresholds,werecordthederivedobjectmasksfromthemergedregionsatthatstep. Utilizing
multiplethresholdsallowsustocaptureobjectsofvarioussizesandatdifferenthierarchicallevels
of composition, enabling a more comprehensive coverage of objects in scene images. The post-
processingandensemblearevisualizedinFigure3,columns4-5.
3.2 HierarchicalLevelPrediction
Inthefollowingsecondstage,HASSODlearnsanobjectdetectionandinstancesegmentationmodel,
e.g.,CascadeMaskR-CNN[4],usingtheinitialpseudo-labelsgeneratedinthefirststage. Bytraining
onsuchpseudo-labels,themodellearnstorecognizecommonobjectsacrossdifferenttrainingimages,
andthusachievesenhancedgeneralizationtoimageswhichthemodelhasnotseenduringtraining.
Inadditiontothestandardobjectdetectionobjective,weaimtoequipourdetectorwiththeability
tounderstandthehierarchicalstructureamongobjectsandtheirconstituentparts. InHASSOD,we
incorporatetheconceptofhierarchicallevelsintoobjectmasksbyleveragingthecoveragerelations
betweenthem. Formally,wesaymaskAiscoveredbymaskBwhenthreeconditionsaresatisfied
(withrespecttoapre-setcoveragethresholdθcover%): 1)Morethanθcover%ofpixelsinmaskAare
alsoinmaskB.2)Lessthanθcover%ofpixelsinmaskBareinmaskA.3)MaskBisthesmallest
amongallmaskssatisfyingtheprevioustwoconditions. Intuitively,ifmaskBcoversmaskA,it
suggests that A is a part of B and B is at a higher level than A. If we consider A and B as tree
nodes,AshouldbeachildofB.Usingallsuchcoveragerelations,wecanconstructaforestoftrees
thatcontainallmasksinanimage. Ultimately,therootsofalltreesinthisimageareconsidered
as“whole”objects,theirdirectchildrenare“part”objects,andalltheremainingdescendantsare
“subpart”objects. AnexampleisshownontherightsideofFigure3.
After identifying the hierarchical levels of object masks in the pseudo-labels, we attach a new
classificationheadtotheobjectdetectorforlevelprediction,whichclassifieseachpredictedobjectas
awholeobject,apartobject,orasubpartobject. ThisnewcomponentenablesHASSODtomodel
objectcompositioneffectively,resultinginimprovedobjectdetectionperformanceandenhanced
interpretabilitycomparedwithpreviousself-supervisedobjectdetectionmethods. Thehierarchical
levelpredictionheadisaddedalongsidetheexistingforeground/backgroundclassificationhead,box
regressionhead,andmaskpredictionhead. Subsequently,wetraintheobjectdetectorusingtheinitial
setofobjectmaskpseudo-labelsobtainedfromthehierarchicaladaptiveclusteringprocess,aswell
astheadditionallevelpredictiontask.
3.3 MeanTeacherTrainingwithAdaptiveTargets
Notably,theinitialpseudo-labelsderivedinthefirststagecontainnoiseandarenotperfectlyaligned
withrealobjects. Toimproveoversuchnoisypseudo-labels,priorwork[37,38]usuallyemploys
multi-roundself-trainingtorefinethemodel,i.e.,usingawell-traineddetectortore-generatepseudo-
labelsandre-trainanewdetector. Forthefirsttime,HASSODrefinestheobjectdetectorefficiently
and smoothly by adapting the Mean Teacher learning paradigm [22, 31] from semi-supervised
learningtothefullyself-supervisedsetting.
Before introducing our innovative adaptation of Mean Teacher in the self-supervised setting, we
firstbrieflysummarizethemutual-learningprocessinMeanTeacher(seeFigure4). MeanTeacher
employstwomodels,ateacherandastudent,whichlearnfromeachother. Theteachertakesweakly-
augmented,unlabeledimagesasinputandprovidesdetectionoutputsastrainingtargetsforthestudent.
Thestudent’sweightsareupdatedtominimizethediscrepancybetweenitspredictionsandthetargets
given by the teacher on the same unlabeled images but with strong augmentation. In the semi-
supervisedsetting,thestudentreceivessupervisionfromtwosourcessimultaneously. Onesource
isthe“teacher-to-student”branchmentionedabove,andtheotheristhe“label-to-student”branch
5Teacher-to-Student Branch
Teacher's
Predict
Predictions A
Weak Teacher
Aug. Detector
𝐿!"#$%"&
Unlabeled Student's
Image Batch A
EMA Predict
Predictions A
×𝛼!"#$%"&↗
Strong Student Supervise
Aug. Detector
𝐿!)!#’
Unlabeled Student's
Image Batch B
Predict
Predictions B
×𝛼’#("’↘
𝐿’#("’
Initial
Discover
Pseudo-Labels B
Label-to-Student Branch
Figure4: MeanTeacherself-trainingwithadaptivetargetsinHASSOD.Twodetectorsofthesame
architecture,theteacherandthestudent,learnfromeachothertoimproveovertheinitialpseudo-
labels. The teacher is updated as the exponential moving average (EMA) of the student. The
studentreceivessupervisionfromtwobranches: Theteacher-to-studentbranch(top)encourages
thestudenttomimictheteacher’spredictions;thelabel-to-studentbranch(bottom)minimizesthe
discrepancybetweenthestudent’spredictionsandtheinitialpseudo-labels. Duringtraining, our
proposedadaptivetargetstrategyincreasestheweightfortheteacher-to-studentbranch,α ,and
teacher
decreasestheweightforthelabel-to-studentbranch,α ,sincetheteacherbecomesamoreand
label
morereliableself-supervisionsourcecomparedwiththeinitialpseudo-labels.
wherethestudentlearnsfromimageswithground-truthlabels. Bothbranchescomputestandard
detectionlosses(e.g.,boundingboxclassificationandregression),andthestudentisoptimizedto
minimizethetotalloss. Theteacher’sweightsareanexponentialmovingaverageofthestudent’s
weights,ensuringsmoothandstabletrainingtargets.
InHASSOD,wedonothaveanylabeledimagesfromhumansupervisionbutinsteadutilizetwo
sourcesofself-supervision. Onesourceistheinitialpseudo-labelsobtainedfromourhierarchical
adaptiveclustering,whichfunctionssimilarlytothelabels-to-studentbranchinthesemi-supervised
setting. Theothersourceisthedetectionpredictionsmadebytheteachermodel,whichcorresponds
totheteacher-to-studentbranchinMeanTeacher. DifferentfromstandardMeanTeacher,ourmethod
employs adaptive training targets, as we gradually adjust the loss weights for the two branches.
Thisisbecausetheinitialpseudo-labelsmaynoteffectivelycoverallpossibleobjects, whilethe
teachermodelwillprogressivelyimproveasabettersourceofsupervision. Consequently,during
MeanTeacherself-training,wecontinuouslydecreasethelossweightα forthebranchthatuses
label
theinitialpseudo-labelsandincreasethelossweightα forthebranchbasedontheteacher’s
teacher
predictions,followingacosineschedule.
4 Experiments
Inthissection,weconductextensiveexperimentstoevaluateHASSODincomparisonwithprevious
methods. WefirstdescribethetrainingdetailsandefficiencyinSection4.1. Section4.2introduces
thedatasetsandmetricsusedforevaluation. Section4.3presentsourmainresultsofself-supervised
objectdetectionandinstancesegmentation. Section4.4providessomequalitativeresultsandanalysis.
Section 4.5 conducts further experiments to verify the effects of each component in HASSOD.
Additionalquantitativeandqualitativeresultsareincludedintheappendix.
4.1 Data-EfficientandComputation-EfficientTraining
WetrainaCascadeMaskR-CNN[4]withaResNet-50[13]backboneonMS-COCO[20]images.
ThebackboneisinitializedfromDINO[5]self-supervisedpre-training. Weuseboththetrainand
unlabeled splits of MS-COCO, totaling to about 0.24 million images. Notably, this amount of
imagesisonly1/5ofImageNetusedbypriorworkCutLER[38]. ComparedwithImageNet-like[7]
iconicimages, imagesinMS-COCOaremostlycapturedincomplexscenescontainingmultiple
objectswithdiverselayoutsandcompositions. Therefore,eachimageoffersricherlearningresources
forobjectdetectors,enablingeffectivedetectortrainingwithsignificantlyfewerimages. Thewhole
6training process spans 40,000 iterations, taking about 20 hours on 4 NVIDIA A100 GPUs. The
efficiencyandsmoothnessintroducedbytheMeanTeacherself-trainingapproachreducesthetraining
iterationsto1/12ofthatrequiredbyCutLER[38],highlightingthecomputationefficiencyofour
trainingstrategy. ImplementationdetailsareincludedinAppendixJ.
4.2 EvaluationDatasetsandMetrics
Wemainlyconductourexperimentsinazero-shotmanneronthevalidationsetsofthreebenchmark
datasets, namelyObjects365[27], LVIS[11], andSA-1B[18]. Giventhatself-supervisedobject
detectionmethods,includingHASSOD,donotutilizeclasslabelsasaformofsupervision,wefollow
prior work [37–39] and evaluate these models as class-agnostic detectors, comparing them only
againsttheboundingboxesandmasksprovidedinthedatasetannotations.
• Objects365[27]isalarge-scaleobjectdetectiondatasetcontaining365objectcategories. The
combinedvalidationsetsofObjects365v1andv2include80,000imagesintotal.
• LVIS[11]isadatasetthatfeaturesawidevarietyofover1,200objectclasses, usingthesame
images as MS-COCO [20]. LVIS v1.0 validation set has 19,809 images, each annotated with
objectmasksforinstancesegmentation.
• SA-1B[18]isarecentdatasetthatincludes11millionimagesand1billionfine-grained,model-
generatedobjectmasks. SA-1Bprovidesamorecomprehensivecoverageofallpotentialobjects,
facilitatingamorerobustevaluationofself-supervisedobjectdetectors.AsSA-1Bdoesnotprovide
avalidationsplit,weutilizearandomsubsetof50,000imagesforourassessment.
Intermsofevaluationmetrics,wefocusprimarilyonaveragerecall(AR)ratherthanaverageprecision
(AP).ThechoiceofARoverAPismotivatedbythenatureoftheself-supervisedtask. Inadataset
withafixednumberofclasses,objectsnotlabeledbyhumans–simplybecausetheydonotfallunder
thedesignatedclasses–maystillbedetectedbyaself-superviseddetectionmodel. StandardAP
calculationwouldpenalizesuchpredictionsasfalsepositives,despitethembeingvaliddetections.
Incontrast,ARdoesnotsufferfromthisissue,makingitamoreappropriatemetricforourcontext.
Byprioritizingrecall,wecanmoreaccuratelyassesstheabilityofourmodeltoidentifyallrelevant
objects in an image, which aligns with the goal of the self-supervised object detection task. We
evaluateARbasedonbothboundingboxesforobjectdetection(“BoxAR”)andmasksforinstance
segmentation(“MaskAR”).AppendixAdiscussestheevaluationmetricsindetail.
4.3 Self-SupervisedDetectionandSegmentation
After we use HASSOD to train the object detection and instance segmentation model, Cascade
Mask R-CNN, on MS-COCO images, we evaluate our model on Objects365, LVIS, and SA-1B
datasetsinazero-shotmanner,i.e.,nofurthertrainingonthesethreedatasets. Thewholetrainingand
evaluationprocessisrepeatedforthreetimes,andwereportthemeanperformanceforconciseness.
ThestandarddeviationofARislessthan0.6onallthreedatasets. Completeevaluationresultsare
includedinAppendixH.
WecompareHASSODwithpriorstate-of-the-artself-supervisedobjectdetectionmethods,including
FreeSOLO[37]andCutLER[38].WealsoincluderesultsfromSAM[18],thelatestsupervisedclass-
agnosticdetection/segmentationmodel,togainunderstandingofthegapbetweenself-supervisedand
supervisedmodels,andhowHASSODiseffectivelyclosingthisgap. Tobeconsistentwithother
models,weprovideSAMwithonlytherawimagesbutnoboundingboxesorpointsasprompts.
ForpriormethodsFreeSOLO,CutLER,andSAM,wedirectlyevaluatethepubliclyavailablemodel
checkpointsonthegivendatasets. Consideringthatthenumberofground-truthlabelsperimagemay
begreaterthan100,weallowallmodelstooutputupto1,000predictionsperimage.
AsshowninthemainresultssummarizedinTable1,HASSODsignificantlyimprovesthedetection
andsegmentationperformanceoverpreviousself-supervisedmodelsFreeSOLOandCutLER.On
Objects365,weimprovetheBoxARby3.2;onLVIS,weimproveBoxARby3.3,andMaskARby
2.3. ThemostremarkableperformancegainisobservedonSA-1B.WeimproveBoxARfrom18.8
to29.0(relatively+54%)andimproveMaskARfrom17.0to26.0(relatively+53%).
Wegainimprovedrecallsforobjectsofallscales, butsmallandmedium-sizedobjectsrelatively
benefitmorethanlargeobjects. Forinstance,ourAR is2.6×asCutLER’sAR onSA-1B.Itis
S S
worthnotingthatdetectingsmallobjectsisintrinsicallyharderthanlargeobjects–eventhoughthe
7Table 1: Comparison of self-supervised object detection and instance segmentation methods on
prevalentimagedatasets. Weconsidertheaveragerecall(AR)insteadofaverageprecision(AP)
as the main metric, because valid detection of objects outside the categories defined by human
annotationsispenalizedbyAP.HASSODsignificantlyoutperformsthepreviouslybestmethods
FreeSOLO[37]andCutLER[38]intermsofARatallobjectscales(Small,Medium,andLarge). To
understandtheextentofimprovements,wealsoincluderesultsfromstate-of-the-artsupervisedmodel
SAM[18]. HASSODleadstoareducedgapbetweenfullyself-supervisedmodelsandsupervised
SAM.Notably,HASSODonlyuses1/5oftrainingimagesand1/12oftrainingiterationsasCutLER.
Box Mask
Method AR AR AR AR AP AR AR AR AR AP
S M L S M L
Objects365[27]
SAM[18] 54.9 32.1 60.5 67.6 11.9
FreeSOLO[37] 10.2 0.2 5.8 23.4 3.4 Noground-truthmask
CutLER[38] 35.8 17.6 36.1 50.5 11.5 annotationsinObjects365
HASSOD(Ours) 39.0 21.4 40.4 52.1 11.0
LVIS[11]
SAM[18] 42.7 27.7 66.3 75.5 6.1 46.1 31.1 71.3 74.6 6.7
FreeSOLO[37] 6.4 0.3 9.7 34.6 1.9 5.9 0.2 9.2 31.7 1.9
CutLER[38] 23.6 13.1 36.2 55.6 4.5 20.2 11.3 31.1 46.2 3.6
HASSOD(Ours) 26.9 15.6 42.2 56.9 4.9 22.5 12.7 36.1 47.8 4.2
SA-1B[18]
SAM[18] 60.5 19.8 59.8 81.5 38.2 60.8 20.0 59.9 82.2 38.9
FreeSOLO[37] 2.4 0.0 0.1 7.4 1.5 2.2 0.0 0.2 6.9 1.5
CutLER[38] 18.8 5.1 14.6 32.8 9.0 17.0 4.9 13.9 28.5 7.8
HASSOD(Ours) 29.0 13.3 25.1 43.8 15.5 26.0 12.9 22.8 38.3 13.8
labels in SA-1B are produced by the same SAM model, when the bounding box prompts are no
longeravailable,SAMcanonlyreacha20.0MaskARforsmallobjects. Meanwhile,wehalvethe
performancegapbetweenself-supervisedCutLERandsupervisedSAMfrom15.1MaskAR
S
to7.1MaskAR . Bylearningfromhierarchicallevelsofobjectcompositions, HASSODmore
S
effectivelycapturessmallobjectswhicharepartofwholeobjects.
4.4 QualitativeResults
Inthissection,weanalyzesomequalitativeresultsonimagesfromLVIS.Thevisualizationisshown
inFigure5. QualitativeresultsonotherdatasetsareincludedinAppendixK.
As shown in the examples, our proposed HASSOD exhibits a more comprehensive coverage of
all objects incomplex scenes, compared with theprevious state-of-the-artself-supervised object
detectionmethodCutLER[38]. Thisadvantageoriginatesfromthepseudo-labelsgeneratedbyour
hierarchical adaptive clustering, which includes a proper number of candidate objects per image
accordingtotheimagecontents,ratherthanonlyfocusingonafixednumberofobjects. Furthermore,
HASSODcanpredictthehierarchicallevelofeachdetectedobject. Beingafullyself-supervised
model, HASSOD has surprisingly gained the human-like ability to comprehend the composition
ofobjects. Thisabilityleadstobetterinterpretabilityandcontrollability: UsersofHASSODcan
understandthecompositionofeachobjectdetectedbythemodel. Meanwhile,userscanalsocontrol
thesegmentationgranularitybyselectingthepredictionsatthedesiredhierarchicallevel.
ThequalitativeresultsalsoshowsomelimitationsofHASSOD.Bycomparingthelasttwocolumns,
itcanbeobservedthatHASSODproducesrelativelyfewerpredictionsfor“subpart”objects. Thisis
duetothedistributionimbalanceintheinitialpseudo-labels,inwhichonlyabout10%objectsare
subparts. Also,thehierarchicallevelslearnedbyHASSODaresometimesinconsistentwithhuman
perception. Forexample,insteadofrecognizingthepersonasawholeobjectinthelastexample
image,HASSODdetectstheupperandlowerpartsofthebodyaswholeobjects. Duetothelackof
humansupervision,thehierarchicalpredictionofHASSODisnotalwaysalignedwithhumans. We
furtheranalyzethislimitationinAppendixI.
8Input CutLER HASSOD (Ours) HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part Whole + Part + Subpart
Figure 5: Qualitative results on LVIS images. Overall, our HASSOD successfully detects more
objectscomparedwithCutLER[38]. CutLERtendstodetectonlyoneorfewprominentobjects
intheimage,whileHASSODcapturesotherobjectsaswell(e.g.,breadinrow1,andtrafficsign
inrow3). Moreover,HASSODlearnsthecompositionofobjects(e.g.,cat-face-eyeinrow2,and
vehicle-wheel-tireinrow4),whichissimilartohumanperception.
4.5 AblationStudy
Inthissection,weconductanablationstudytounderstandtheeffectsofeachcomponentinHASSOD.
Toevaluatetheperformancemorerobustlyagainstalargersetofhuman-annotatedobject-levellabels,
wecombinetheannotationsofMS-COCO[20]andLVIS[11]ontheval2017split,becausethey
arecomplementarytoeachother: LVISusesthesameimagesasMS-COCO,butlabelsmoreobject
classes. However,LVISannotationsarenotasexhaustiveasMS-COCO,meaningthatobjectswithin
LVIScategoriesmaynotbelabeledonallimages. Aftercombiningthetwosetsofannotationsand
removingduplicates,therearearound20object-levellabelsperimage. Weusethiscombineddataset
forevaluationinalltheablationstudyexperiments,unlessotherwisespecified.
Quality of initial pseudo-labels. We first examine how the design choices in our hierarchical
adaptive clustering influence the quality of initial pseudo-labels. The results are summarized in
Table2. Eachthresholdθmerge ∈{0.1,0.2,0.4}leadstoadifferenttrade-offbetweenthenumberof
i
labelsperimageandtherecall. Ahigherthresholdstopsthemergingprocessearlier,andthusresults
inmorepseudo-labels. Withpost-processing, wecanimprovepseudo-labelqualitybyremoving
abouthalfofthelabels,andincreaseAPsignificantlywithoutlosingmuchAR.Finally,theensemble
ofmultiplemergingthresholdsθmerge ∈{0.1,0.2,0.4}bringsthebestoverallpseudo-labelquality.
i
AppendicesD,E,andFpresentmoredetailsregardingthechoiceofθmerge,computationcosts,and
ViTbackbonesinthisstage.
EffectsofhierarchicallevelpredictionandMeanTeacher. Aftergeneratingtheinitialpseudo-
labels with hierarchical adaptive clustering, we train the object detector with several techniques,
includinghierarchicallevelprediction,MeanTeacherself-training,andadaptivelyadjustinglearning
targets. The contribution of each technique is summarized in Table 3. Each component brings
anadditional0.3-0.5MaskARimprovement, andwhentheyfunctiontogether, thebestoverall
performancecanbeachieved.
9Table2: Ablationstudyonfactorsinfluencingthequalityofinitialpseudo-labels. Thethreshold
θmerge controls the stopping criterion of the merging process, and affects AR and the number of
pseudo-labels. Applyingpost-processingcanremovelow-qualitypseudo-labelswithoutdecreasing
ARbyalargemargin. Ensembleofmultiplepseudo-labelsourcesleadstothebestoverallquality.
Post- Labels Mask
Method θmerge Process perImg AR AR AR AR AP
S M L
MaskCut[38] – ✓ 1.85 3.5 0.0 2.0 20.0 1.5
0.1 5.33 4.4 0.8 5.1 16.6 1.2
0.1 ✓ 2.58 4.1 0.6 5.1 15.6 1.8
Hierarchical 0.2 8.36 5.5 1.2 7.0 18.9 1.3
adaptive 0.2 ✓ 4.20 5.3 0.9 7.0 18.4 1.8
clustering 0.4 23.33 7.9 2.1 12.0 21.7 0.7
(Ours) 0.4 ✓ 11.61 7.8 1.7 12.1 22.1 1.3
ensemble ✓ 12.69 8.9 1.7 12.4 29.1 1.7
Table3: Ablationstudyonfactorsinfluencingthetrainingoftheobjectdetector. Hierarchicallevel
predictionisintroducedasanauxiliarytaskforself-supervision. MeanTeacherself-trainingreplaces
thevanillamulti-roundself-trainingandbringsasmootherandmoreefficienttrainingprocess. The
weightsoftwolearningtargets,initialpseudo-labelsandteacherpredictions,areadaptivelyadjusted
tobuildamoreeffectivecurriculum. Allthethreekeydesignsarecombinedforthebestoverall
performanceofHASSOD.
Level Mean Adaptive Mask
Prediction Teacher Targets AR AR AR AR AP
S M L
20.2 9.2 30.4 42.5 5.7
✓ 20.6 9.7 30.1 43.9 6.1
✓ ✓ 22.1 10.9 32.9 44.5 5.5
✓ ✓ ✓ 22.4 11.3 32.9 45.0 6.3
Improvement over initial pseudo-labels. Although the initial pseudo-labels are produced by a
frozenDINObackboneandtheytendtobenoisyandcoarse,HASSODisnotupper-boundedbythe
qualityofthefixedinitialpseudo-labelsorthepre-trainedbackbone. Thisisbecauseofthefollowing
reasons: 1)Whiletheinitiallydiscoveredpseudo-labelsarenoisy,inthelearningstagewetraina
detectionmodeltolearncommonobjectsandtheirhierarchicalrelationsforenhancedgeneralization
tounseenimages. Bylearningthisdetector,weboostthedetectionARandAPfrom8.9and1.7
(thelastrowinTable2)to20.6and6.1(thesecondrowinTable3),respectively. Meanwhile,the
pre-trainedbackbonefeaturesareadaptedforthedetectiontaskinanend-to-endmanner. 2)We
furtherleverageMeanTeacherforcontinualself-enhancement,andgraduallyminimizethenegative
impactofnoisyinitialpseudo-labels. Theevolvingteacherdetectoranditsfeaturesprovideimproved
pseudo-labelstothestudent. Notably,wecandirectlyreadoutthepredictionsfromtheteacherasthe
refinedhierarchicalpseudo-labels,insteadofinefficientlyrunningtheclusteringalgorithmusingthe
enhancedbackbone. Consequently,wefurtherimprovethedetectionARandAPto22.4and6.3(the
lastrowinTable3),respectively.
5 Conclusion
WepresentHierarchicalAdaptiveSelf-SupervisedObjectDetection(HASSOD),anapproachinspired
byhumanvisualperceptionthatlearnstodetectobjectsandunderstandobjectcompositioninaself-
supervisedmanner. HASSODusesahierarchicaladaptiveclusteringstrategytoproposeavarying
numberofobjectsperimage,andlearnshierarchicallevelsofobjectsbyanalyzinggeometricrelations
betweenobjects. MeanTeacherself-trainingwithadaptivetargetsfacilitatesthedetectortraining
process with smooth learning objectives and improved training efficiency. Empirical evaluation
on recent large-scale image datasets Objects365, LVIS, and SA-1B demonstrates our significant
improvementoverpriorself-superviseddetectors. Wedetailthelimitationsandbroaderimpactsof
HASSODinAppendixI.
10Acknowledgments
ThisworkwassupportedinpartbytheIBM-IllinoisDiscoveryAcceleratorInstitute,NSFGrant
#2106825,NIFAAward#2020-67021-32799,theJumpARCHESendowmentthroughtheHealth
CareEngineeringSystemsCenter,theNationalCenterforSupercomputingApplications(NCSA)
attheUniversityofIllinoisatUrbana-ChampaignthroughtheNCSAFellowsprogram,theIllinois-
InsperPartnership,andtheAmazonResearchAward. ThisworkusedNVIDIAGPUsatNCSADelta
throughallocationsCIS220014,CIS230012,andCIS230013fromtheAdvancedCyberinfrastructure
CoordinationEcosystem: Services&Support(ACCESS)program[3],whichissupportedbyNSF
Grants#2138259,#2138286,#2138307,#2137603,and#2138296.
References
[1] AnkanBansal,KaranSikka,GauravSharma,RamaChellappa,andAjayDivakaran. Zero-shotobject
detection. InECCV,2018. 15
[2] IrvingBiederman. Recognition-by-components:Atheoryofhumanimageunderstanding. Psychological
review,94(2):115,1987. 1
[3] TimothyJ.Boerner,StephenDeems,ThomasR.Furlani,ShelleyL.Knuth,andJohnTowns. ACCESS:
Advancinginnovation:NSF’sadvancedcyberinfrastructurecoordinationecosystem:Services&support.
InPracticeandExperienceinAdvancedResearchComputing,2023. 11
[4] ZhaoweiCaiandNunoVasconcelos. CascadeR-CNN:Delvingintohighqualityobjectdetection. In
CVPR,2018. 5,6,15,16,21
[5] MathildeCaron,HugoTouvron,IshanMisra,HervéJégou,JulienMairal,PiotrBojanowski,andArmand
Joulin.Emergingpropertiesinself-supervisedvisiontransformers.InICCV,2021.1,3,4,6,15,18,20,21
[6] XianjieChen,RoozbehMottaghi,XiaobaiLiu,SanjaFidler,RaquelUrtasun,andAlanYuille. Detectwhat
youcan:Detectingandrepresentingobjectsusingholisticmodelsandbodyparts. InCVPR,2014. 3
[7] JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLiFei-Fei.ImageNet:Alarge-scalehierarchical
imagedatabase. InCVPR,2009. 4,6,15,20
[8] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner,MostafaDehghani,MatthiasMinderer,GeorgHeigold,SylvainGelly,JakobUszkoreit,and
NeilHoulsby. Animageisworth16x16words: Transformersforimagerecognitionatscale. InICLR,
2021. 4,20
[9] PedroFFelzenszwalb,RossBGirshick,DavidMcAllester,andDevaRamanan. Objectdetectionwith
discriminativelytrainedpart-basedmodels. TPAMI,32(9):1627–1645,2009. 3
[10] GeorgiaGkioxari,RossGirshick,andJitendraMalik. Actionsandattributesfromwholesandparts. In
ICCV,2015. 3
[11] AgrimGupta,PiotrDollar,andRossGirshick. LVIS:Adatasetforlargevocabularyinstancesegmentation.
InCVPR,2019. 3,7,8,9,14,19
[12] TrevorHastie,RobertTibshirani,JeromeHFriedman,andJeromeHFriedman. Theelementsofstatistical
learning:datamining,inference,andprediction. Springer,2009. 4
[13] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimagerecognition.
InCVPR,2016. 6,21
[14] KaimingHe,GeorgiaGkioxari,PiotrDollár,andRossGirshick. MaskR-CNN. InICCV,2017. 16
[15] KaimingHe,XinleiChen,SainingXie,YanghaoLi,PiotrDollár,andRossGirshick.Maskedautoencoders
arescalablevisionlearners. InCVPR,2022. 1
[16] Tarun Kalluri, Weiyao Wang, Heng Wang, Manmohan Chandraker, Lorenzo Torresani, and Du Tran.
Open-world instance segmentation: Top-down learning with bottom-up supervision. arXiv preprint
arXiv:2303.05503,2023. 15
[17] DahunKim,Tsung-YiLin,AneliaAngelova,InSoKweon,andWeichengKuo. Learningopen-world
objectproposalswithoutlearningtoclassify. IEEERoboticsandAutomationLetters,7(2):5453–5460,
2022. 15
11[18] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,TeteXiao,
SpencerWhitehead,AlexanderC.Berg,Wan-YenLo,PiotrDollár,andRossGirshick. Segmentanything.
InICCV,2023. 1,3,7,8,14,17,18,19,21,23
[19] PhilippKrähenbühlandVladlenKoltun. EfficientinferenceinfullyconnectedCRFswithGaussianedge
potentials. InNeurIPS,2011. 4,20
[20] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays,PietroPerona,DevaRamanan,PiotrDollár,
andCLawrenceZitnick. MicrosoftCOCO:Commonobjectsincontext. InECCV,2014. 2,6,7,9,14,15,
17,20,21
[21] YangLiu,IdilEsenZulfikar,JonathonLuiten,AchalDave,DevaRamanan,BastianLeibe,AljošaOšep,
andLauraLeal-Taixé. Openingupopenworldtracking. InCVPR,2022. 15
[22] Yen-ChengLiu,Chih-YaoMa,ZijianHe,Chia-WenKuo,KanChen,PeizhaoZhang,BichenWu,Zsolt
Kira,andPeterVajda. Unbiasedteacherforsemi-supervisedobjectdetection. InICLR,2021. 2,5,21
[23] StephenEPalmer.Hierarchicalstructureinperceptualrepresentation.Cognitivepsychology,9(4):441–474,
1977. 1
[24] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen,ZemingLin,NataliaGimelshein,LucaAntiga,AlbanDesmaison,AndreasKöpf,EdwardZ.Yang,
ZachDeVito,MartinRaison,AlykhanTejani,SasankChilamkurthy,BenoitSteiner,LuFang,JunjieBai,
andSoumithChintala. Pytorch:Animperativestyle,high-performancedeeplearninglibrary. InNeurIPS,
2019. 21
[25] JeanPiaget. Theconstructionofrealityinthechild. JournalofConsultingPsychology,19(1):77,1955. 1
[26] ChristophSchuhmann,RomainBeaumont,RichardVencu,CadeWGordon,RossWightman,Mehdi
Cherti,TheoCoombes,AarushKatta,ClaytonMullis,MitchellWortsman,PatrickSchramowski,SrivatsaR
Kundurthy,KatherineCrowson,LudwigSchmidt,RobertKaczmarczyk,andJeniaJitsev. LAION-5B:
Anopenlarge-scaledatasetfortrainingnextgenerationimage-textmodels. InNeurIPSDatasetsand
BenchmarksTrack,2022. 1
[27] ShuaiShao,ZemingLi,TianyuanZhang,ChaoPeng,GangYu,XiangyuZhang,JingLi,andJianSun.
Objects365:Alarge-scale,high-qualitydatasetforobjectdetection. InICCV,2019. 7,8,17,19,21,22
[28] JianboShiandJitendraMalik. Normalizedcutsandimagesegmentation. TPAMI,22(8):888–905,2000. 3
[29] OrianeSiméoni,GillesPuy,HuyVVo,SimonRoburin,SpyrosGidaris,AndreiBursuc,PatrickPérez,
RenaudMarlet,andJeanPonce. Localizingobjectswithself-supervisedtransformersandnolabels. In
BMVC,2021. 3
[30] OrianeSiméoni,ChloéSekkat,GillesPuy,AntonínVobecky`,ÉloiZablocki,andPatrickPérez. Unsuper-
visedobjectlocalization:Observingthebackgroundtodiscoverobjects. InCVPR,2023. 3
[31] AnttiTarvainenandHarriValpola. Meanteachersarebetterrolemodels:Weight-averagedconsistency
targetsimprovesemi-superviseddeeplearningresults. InNeurIPS,2017. 2,5
[32] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,Łukasz
Kaiser,andIlliaPolosukhin. Attentionisallyouneed. InNeurIPS,2017. 4
[33] HuyVVo,FrancisBach,MinsuCho,KaiHan,YannLeCun,PatrickPérez,andJeanPonce. Unsupervised
imagematchingandobjectdiscoveryasoptimization. InCVPR,2019. 3
[34] HuyVVo,PatrickPérez,andJeanPonce. Towardunsupervised,multi-objectdiscoveryinlarge-scale
imagecollections. InECCV,2020. 3
[35] VanHuyVo,ElenaSizikova,CordeliaSchmid,PatrickPérez,andJeanPonce. Large-scaleunsupervised
objectdiscovery. InNeurIPS,2021. 3
[36] WeiyaoWang,MattFeiszli,HengWang,JitendraMalik,andDuTran. Open-worldinstancesegmentation:
Exploitingpseudogroundtruthfromlearnedpairwiseaffinity. InCVPR,2022. 15
[37] XinlongWang,ZhidingYu,ShaliniDeMello,JanKautz,AnimaAnandkumar,ChunhuaShen,andJoseM
Alvarez. FreeSOLO:Learningtosegmentobjectswithoutannotations. InCVPR,2022. 1,3,5,7,8
[38] Xudong Wang, Rohit Girdhar, Stella X Yu, and Ishan Misra. Cut and learn for unsupervised object
detectionandinstancesegmentation. InCVPR,2023. 1,2,3,4,5,6,7,8,9,10,14,15,16,20,21
12[39] Yangtao Wang, Xi Shen, Yuan Yuan, Yuming Du, Maomao Li, Shell Xu Hu, James L Crowley, and
Dominique Vaufreydaz. TokenCut: Segmenting objects in images and videos with self-supervised
transformerandnormalizedcut. InCVPR,2022. 3,5,7
[40] YuxinWu,AlexanderKirillov,FranciscoMassa,Wan-YenLo,andRossGirshick. Detectron2. https:
//github.com/facebookresearch/detectron2,2019. 21
13Appendix
Inthisappendix,SectionAfirstexplainsthedeficiencyoftraditionalMS-COCOAPevaluationin
theself-supervisedsettingandreasonsforadoptingARonmoreclass-extensively-annotateddatasets
likeLVIS.SectionsBandCaddresspotentialconcernsaboutunfaircomparisonwithCutLER[38]
regardingthetrainingdataandthedetectorarchitecture. SectionsD,E,andFpresentadditional
ablationstudyregardingthethresholdchoice,computationcost,andpatchsizeoftheViTbackbone
inourhierarchicaladaptiveclusteringalgorithm. SectionGstudiesdifferentbehaviorsofSAMand
ourproposedHASSODindetectingpartsofobjects. SectionsHandKpresentmorecomprehensive
quantitativeandqualitativeevaluationresultsforcompleteness. SectionIprovidesthefailurecases
ofHASSODandanalyzesitscurrentlimitations. SectionJdescribesthedetailedhyper-parameter
andimplementationsetup.
A DeficiencyofMS-COCOAPEvaluationinSelf-SupervisedObject
Detection
Traditionally, the Average Precision (AP) metric on the MS-COCO dataset [20] has been a gold
standardforassessingtheperformanceofsupervised objectdetectionandinstancesegmentation
models,whicharetrainedandevaluatedonafixedsetofobjectcategoriespre-definedbyhuman
annotators. However,wefindthismetricmisleadinginthecontextofself-supervisedobjectdetection,
whereclasslabelsarenotavailabletothemodelandclass-agnosticpredictionsarenecessary. Inthis
work,weadvocateforevaluatingAverageRecall(AR)ondatasetswithextensiveclassannotations
(e.g., LVIS [11]) as a more reliable metric for comparing different methods. In this section, we
discusstheinherentdeficienciesofMS-COCOAPevaluationusinganillustrativeexample.
To demonstrate this problem objectively, we compare two previous methods, CutLER [38] and
SAM[18]. Bothmodelsfunctionasclass-agnosticobjectdetectors,butSAM,trainedwithhuman
supervision,evidentlyoutperformsCutLERintermsofdetectingandsegmentingobjects,asdepicted
inFigure6. Surprisingly,whenevaluatedonMS-COCOannotations,SAMattainsamere6.7AP,
whichisapproximatelyhalfofCutLER’s12.3AP.Inthiscase,theAPmetriciscontradictingwith
theobservedperformanceofthetwomodelsintermsofaccuratelydetectingandsegmentingasmany
objectsaspossible.
Input CutLER SAM
12.3 AP on MS-COCO 6.7 AP on MS-COCO
Figure 6: MS-COCO average precision (AP) evaluation may not accurately reflect the perfor-
mance of class-agnostic object detectors. We compare two previous class-agnostic object detec-
tion/segmentationmodels,CutLER[38]andSAM[18]. DespiteSAM,asupervisedmodel,detecting
moreobjectswithsuperiorlocalizationthanCutLER,itachievesonlyhalftheAPofCutLER.
TheprimaryreasonforthisdiscrepancyliesintheannotationsofMS-COCO.MS-COCOlabelsonly
80objectcategories,andmodelpredictionsareconsideredastruepositivesonlyiftheyfallwithin
14thesecategories. Consequently,correctpredictionsforobjectsoutsidethe80categoriesareunjustly
deemedfalsepositivesandpenalizedbytheAPmetric,contradictingtheobjectiveofclass-agnostic
objectdetectionandrevealingtheshortcomingsofAPevaluation.
To correct these deficiencies in the evaluation metric, we need two changes: 1) Adopt a dataset
withcomprehensiveannotationsthatincludeasmanyobjectcategoriesaspossible. Ifwesubstitute
MS-COCOground-truthannotationswithLVIS,whichlabelsover1,200objectcategoriesdespite
usingthesameimages,theAPcomparisonisreversed: CutLERscores4.5APonLVIS,whileSAM
attains a higher 6.1 AP. 2) Replace AP with the AR metric. Even with LVIS annotations, not all
objectcategoriesarelabeledineveryimage,resultingincertainvalidobjectdetectionpredictionsstill
beingpenalized. Conversely,ARdoesnotpenalizesuchpredictionsandexhibitsamorepronounced
differencebetweenCutLERandSAM(23.6ARvs.42.7AR).
Insummary,weadvocateforARonclass-extensively-annotateddatasetsastheprimarycomparison
metric,whichcanmoreaccuratelyreflecttheactualperformanceofclass-agnosticobjectdetectors
withreducedbias. Thischoiceofmetricalignswithpriorworkonopen-worlddetection[1,17],
segmentation[16,36],andtracking[21]aswell.
B ComparisonofCutLERandHASSODwithEqualTrainingData
Asdescribedinthemainpaper,HASSODutilizesaResNet-50backboneinitializedwithDINO[5]
weights pre-trained in a self-supervised manner on ImageNet [7], while subsequent training is
conductedonMS-COCO[20]images. WechooseMS-COCOforitscompactsizeandrichnessin
objectsperimage.Duetolimitedcomputationresources,weareunabletoperformHASSODtraining
onImageNet,andweleavelarge-scaletrainingasoneinterestingfuturedirection. Thisdistinctionin
thetrainingdatasetmayleadtoconcernsregardingthefairnessofcomparisonwithpriorwork,such
asCutLER[38],whichtrainsexclusivelyonImageNetdata. However,itisimportanttonotethat
usingbothImageNetandMS-COCOdatainHASSODdoesnotgrantHASSODadditionalbenefit
comparedwithCutLERfortwomainreasons: 1)Thetwodatasetsareleveragedinseparatestages
andnotinablendedmanner. Specifically,ImageNetdataareonlyusedintheDINOpre-training
stage,whileMS-COCOisemployedfordetectortraining. 2)ImageNetcontainsapproximately5×
asmanyimagesasMS-COCO.Thus,ifImageNetisemployedinthedetectortrainingstage,asisthe
casewithCutLER,thiswouldactuallyleadtoastrongerdetector.
Table4: ComparisonbetweenCutLER[38]andHASSODconcerningthetrainingimagedataset.
AlthoughbothCutLERandHASSODleverageDINO[5]weightspre-trainedonImageNet,employ-
ingMS-COCOimagesinthedetectortrainingstagedoesnotleadtosuperiorperformance. CutLER
trainedonImageNetsurpassesCutLERtrainedonMS-COCOacrossallmetrics. Simultaneously,
HASSODoutperformsbothCutLERmodels,despiteusingMS-COCOtrainingdataandrequiring
fewertrainingiterations.
Training Training Mask
Method Images Iterations AR AR AR AR AP
S M L
CutLER[38] MS-COCO[20] 160,000 17.3 6.2 24.2 46.1 5.8
CutLER[38] ImageNet[7] 160,000 18.8 7.2 27.6 46.6 6.2
HASSOD(Ours) MS-COCO[20] 40,000 22.4 11.3 32.9 45.0 6.3
Inordertoaddresstheseconcernsmoreeffectivelyandensureanequalusageoftrainingdata,we
conductanadditionalexperiment. Specifically,wetrainaCascadeMaskR-CNN[4]detectorusing
theCutLERapproachonMS-COCOimagesforoneround(160,000iterations),withtheResNet-50
backboneinitializedwithDINOpre-trainedweights. WeadoptCutLER’soriginalimplementation,
withthesolemodificationbeingtheuseofMS-COCOimagesfortraining. Wecomparethismodel
with a CutLER model trained on ImageNet for one round and our HASSOD model trained on
MS-COCO. The evaluation is conducted against MS-COCO+LVIS annotations, as described in
Section4.5. TheresultsarepresentedinTable4.
By comparing the two CutLER models trained with MS-COCO and ImageNet, we observe that
utilizingdistinctdatasetsforbackbonepre-traininganddetectortrainingdoesnotuniversallyimprove
performance.TheCutLERmodel,exclusivelytrainedonImageNet,surpassesitscounterpartthatuses
15ImageNetforDINOpre-trainingandMS-COCOfordetectortraining,exhibitinggainsof1.5Mask
ARand0.4MaskAP.Meanwhile,HASSOD,despitebeingtrainedonthesmallerMS-COCOdataset
andforashorterduration,outperformsCutLERby3.6MaskAR.Thisremarkableperformanceis
attributedtoHASSOD’scomprehensiveobjectcoverageinimagesanditsefficientusageoftraining
data.
C AdditionalResultsonMaskR-CNN
InHASSOD,wetrainaCascadeMaskR-CNN[4]objectdetectionandinstancesegmentationmodel.
WechoosethisarchitecturefollowingCutLER[38]andweensureafaircomparisonwiththisprior
work. Infact,HASSODcanbeappliedondifferentdetectorarchitectures. Asanexample,wealso
trainaMaskR-CNN[14]andcompareitsLVISperformancewithCutLERinTable5. Withthe
samedetectorarchitecture,HASSODproducesabetterdetectorthanCutLER.Moreimpressively,
our Mask R-CNN (weaker architecture) outperforms CutLER’s Cascade Mask R-CNN (stronger
architecture)onLVIS,highlightingtheadvantageofourapproach.
Table5: ComparisonbetweenCutLER[38]andHASSODwithdifferentdetectorarchitectureson
theLVISdataset. Whentrainingmodelsofthesamearchitecture,HASSODoutperformsCutLER
(row1vs.2,row3vs.4). Notably,HASSODhasastrongerARevenwithaweakerarchitecture(row
2vs.3)ascomparedwithCutLER.
Box Mask
Architecture Method AR AR AR AR AP AR AR AR AR AP
S M L S M L
CutLER[38] 20.7 10.4 33.3 52.0 4.1 18.5 9.6 29.1 44.9 3.4
MaskR-CNN
HASSOD(Ours) 23.8 13.5 38.3 50.9 4.3 21.5 11.8 35.1 46.6 4.1
CutLER[38] 23.6 13.1 36.2 55.6 4.5 20.2 11.3 31.1 46.2 3.6
Cas.MaskR-CNN
HASSOD(Ours) 26.9 15.6 42.2 56.9 4.9 22.5 12.7 36.1 47.8 4.2
D ChoosingThresholdsforHierarchicalAdaptiveClustering
Whendeterminingthemergingthresholds{θmerge},wemainlyconsiderourcomputationalconstraints
i
andempiricalobservations. Thedecisionofmergingthresholdsisnot madebasedonvalidation
performance(Table2),ensuringthatHASSODisfullyself-supervised.
100
80
60
40
20
0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Merging threshold
Figure7: Relationbetweenthenumberofpseudo-labelsperimageafterpost-processing(y-axis)
andthemergingthresholdθmerge(x-axis). Whenθmerge ≥0.5,thenumberofpseudo-labeledmasks
growsrapidly. Empirically,wefindthatwhenthenumberofmasksperimageexceeds20,generating,
loading,andtransformingsuchpseudo-labelsbecomesamajorbottleneckinHASSOD.Therefore,we
choosethreethresholds{θmerge}={0.1,0.2,0.4},mainlyguidedbyacomputationalconsideration.
i
16
egami
rep
slebal-oduesp
fo
rebmuNGuidancebynumberofpseudo-masks. Ourchoicefor{θmerge}isprimarilyguidedbythenumber
i
ofpseudo-labelmasksproducedperimage. Figure7showstherelationshipbetweenthenumber
ofmasksperimageanddifferentthresholds. Whenθmerge ≥ 0.5,thenumberofmasksperimage
escalatesrapidly. Thissteepincreaseincurssignificantcomputationalcosts,bothduringtheinitial
generationofpseudo-labelsandthesubsequentdataloadingandpre-processingproceduresduring
modeltraining.Tostrikeabalancebetweencomputationalefficiencyandthedesiredmaskgranularity,
thresholdsof{θmerge}={0.1,0.2,0.4}arechosen.
i
Table6: Generalizabilityofthemergingthresholds{θmerge}. Withthesamemergingthreshold,the
i
numberofgeneratedpseudo-labelsisnotsignificantlychangingacrossdifferentimagedatasets.
Numberofpseudo-labelsperimage
θmerge
MS-COCO[20] Objects365[27] SA-1B[18]
0.1 2.58 3.49 2.91
0.2 4.20 5.78 4.88
0.4 11.61 12.15 12.70
Thresholdgeneralizationacrossdatasets. Anothernoteworthyobservationisthegeneralizabilityof
thesethresholdsacrossvariousdatasets.InTable6,wepresentthenumberofgeneratedpseudo-labels
perimageonthreedatasets. Withthemergingthresholdθmergefixed,thenumberofgeneratedlabels
is relatively stable, regardless of the source image dataset. Therefore, our pre-set thresholds are
generalizable and require no further tuning when transferred to other datasets. Meanwhile, our
detectionmodelwastrainedonMS-COCOimageswithpseudo-labelsgeneratedusingourpre-set
{θmerge},andcouldgeneralizewelltootherdatasetsinazero-shotmanner,asshowninTable1. This
i
factshowsthatthethresholds{θmerge}areeffectiveregardlessofevaluationdatasets.
i
E ComputationalCostsinHierarchicalAdaptiveClustering
Weadoptthehierarchicaladaptiveclusteringstrategytogenerateourinitialpseudo-labels. Inthis
section,weprovideadditionaldetailsregardingcomputationcostsinthisprocedure.
AsshowninFigure3,thehierarchicaladaptiveclusteringcontainsfoursteps“merge,”“post-process,”
“ensemble,”and“split.” Amongthem,the“merge”stepaccountsforthemajorcomputationcosts.
Wecananalyzeitstimecomplexity: Supposewehavenpatchesinthebeginning,thenthereare
atmostnmergingstepsbeforestopping. Eachmergingsteprequiresretrievingthemostsimilar
pairofadjacentregions. ThecollectionofadjacentpairshassizeatmostO(n),andeachoperation
requirestimeO(logn)ifthiscollectionisorganizedasabalancedbinarytree.Therefore,themerging
processhastimecomplexityO(nlogn). Inourpractice,theinputimagehasresolution480×480,
son= 480 × 480 =3,600. Thistimecomplexityisaffordable.
8 8
Moreconcretely,welistthetimecostsinthehierarchicaladaptiveclusteringonourcomputation
platform in Table 7. Since the procedure is learning-free, we can parallelize the processing of
imagesusingmorethanoneworker. Onourcomputationnodesequippedwith4NVIDIAA100
GPUs,wecanreducetheprocessingtimeto1.59sec/image. With4suchnodes,wecancomplete
thepseudo-labelgenerationforMS-COCOtrainandunlabeledsplits(0.24millionimages)in
1.59×0.24×106 ≈1day.
4×86400
Table7: Timecostsinthestepsofthehierarchicaladaptiveclustering. Notably,withmultipleparallel
workers,wecanreducethetotalprocessingtimeofMS-COCO[20]imagestooneday.
TimeCost ParallelizedCost
Step Workers
(sec/image) (sec/image)
MergeandPost-Process 11.7 8 1.46
EnsembleandSplit 2.1 16 0.13
Total 13.8 - 1.59
17F ImpactofPatchSizeinHierarchicalAdaptiveClustering
WeusetheDINO[5]pre-trainedViT-B/8backbonetogeneratetheinitialpseudo-labelsthrough
our hierarchical adaptive clustering. We observe that the small patch size 8×8 leads to better
pseudo-labelquality. InTable8,wecomparethemaskqualityofpseudo-labelsgeneratedbyViT-B/8
(patch size 8×8) vs. ViT-B/16 (patch size 16×16). For a fair comparison, we use 480×480
input resolution for ViT-B/8 and 960×960 for ViT-B/16, so that they have the same number of
initialpatches. Withthesamemergingthresholdθmerge,ViT-B/16leadstoslightlyfewerlabelsper
image,andthequalityissignificantlyworsethanViT-B/8,especiallyforsmallandmediumobjects.
Therefore, we apply ViT-B/8 in our experiments for its localized visual features and subsequent
high-qualitypseudo-labels.
Table8:ComparisonbetweenDINOViTbackboneswithdifferentpatchsizes8×8and16×16. The
backbonewiththesmallerpatchsizeleadstohigher-qualityinitialpseudo-labelsinthehierarchical
adaptiveclusteringprocedure.
DINO Labels Mask
θmerge
Backbone perImg AR AR AR AR AP
S M L
0.1 2.58 4.1 0.6 5.1 15.6 1.8
ViT-B/8 0.2 4.20 5.3 0.9 7.0 18.4 1.8
0.4 11.61 7.8 1.7 12.1 22.1 1.3
0.1 1.97 3.0 0.3 2.3 14.6 1.1
ViT-B/16 0.2 3.19 3.8 0.4 3.3 17.4 1.2
0.4 10.15 5.7 0.9 6.6 21.7 1.3
G DifferentBehaviorsofSAMandHASSODinObjectPartDetection
SegmentAnythingModel(SAM)[18],asupervisedsegmentationmodel,hasdemonstrateditsability
increatinghigh-quality,fine-grainedsegmentationofimages. Directlycomparingtheperformance
betweenSAMandHASSODwouldbeunbalanced,consideringSAMrequiresextensivehuman-
labeledimagesfortraining,whileHASSODoperatesentirelyunderself-supervision. Despitethis,it
remainsintriguingtounderstandtheirdifferentbehaviors. Inthissection,wedelveintoaqualitative
comparisonbetweenSAMandourproposedHASSODapproach,payingparticularattentiontotheir
respectiveabilitiestodetectconstituentpartsofwholeobjects. Figure8presentsavisualizationfor
thiscomparison.
BothSAMandHASSODcanperformfine-grainedsegmentationwithincomplexscenes,successfully
detectingindividualobjectpartsthatconstituteawholeentity. However,acleardistinctionarisesin
theirrespectiveapproachestowardsthesegmentationoftheseobjectparts.Forscenesinwhichobjects
followagridpattern,wherethewholeentityispartitionedbyregularboundarylinesintosemantically
similarpieces,SAMtendstoperceiveeachgridasadistinctobject. Conversely,HASSODadheresto
aholisticperspectiveforsuchcases,groupingthegridpartstogetherevenatthesubpartlevel,dueto
theirsemanticallyanalogousfeatures.
Inparticular,HASSODexcelsatdistinguishingobjectpartsthatcontaindifferentcontentswithin
wholeobjects. ThisskillofHASSODisespeciallyadvantageousincertainreal-worldapplications.
Forexample,inmedicalimaging,HASSOD’sfine-grainedsegmentationcanpotentiallyassistin
identifyingandseparatingdifferenttissuesoranatomicalstructureswithinascan. Additionally,inthe
manufacturingindustry,HASSODcouldbeusedinqualitycontroltocheckandcompareindividual
componentsofanassembledproduct. WhilebothsegmentationstrategiesofSAMandHASSODare
valid,HASSOD’suniqueabilitytodistinguishsemanticallydifferentpartswithinobjectsprovides
distinctadvantagesinawiderangeofpracticalscenarios.Comprehensivelyquantifyingandanalyzing
such an ability is crucial for advancement of self-supervised object detection and segmentation
approaches,andweconsideritasanimportantfuturedirection.
18Input SAM HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure8: AnalysisofdifferentbehaviorsinobjectpartdetectionbetweensupervisedSAM[18]and
self-supervisedHASSODthroughqualitativevisualization. Whilebothmodelsgeneratefine-grained
segmentation, they exhibit distinct preferences concerning object parts. SAM inclines towards
separatingobjectsfollowingagridpattern(e.g.,comforters,keyboards,tiles),whereasHASSOD
discriminatesobjectsintosemanticallydiverseparts(e.g.,eyesandbeardofacat,handleandbutton
ofacabinet).
H AdditionalEvaluationResultsforCompleteness
AsanadditiontoTable1inthemainpaper,wepresentacomprehensiveevaluationofHASSOD
ontheObjects365[27], LVIS[11], andSA-1B[18]datasetsinTable9. Forarobustmeasureof
performance, we incorporate the standard deviation, estimated from three independently trained
models.
Table9: ComprehensiveevaluationresultsofHASSODacrossthreedatasets. Wesetthemaximum
number of predictions per image to 1,000. The number superscript on AR (e.g., AR10) denotes
thenumberofmostconfidentpredictionstakenintoaccountwhencomputingAR.Thesubscript
onAP(e.g.,AP )representstheIntersection-over-Union(IoU)thresholdutilizedwhenmatching
50
predictionswithgroundtruthlabels. Size-specificmetricsforsmall,medium,andlargeobjectsare
indicatedbythesubscripts , ,and ,respectively. Weincludethestandarddeviation,estimated
S M L
fromthreeindependentruns.
Dataset AR10 AR100 AR1000 ARS ARM ARL AP AP50 AP75 APS APM APL
Box(ObjectDetection)
15.20 36.63 39.03 21.40 40.43 52.10 10.97 20.33 10.27 2.90 10.37 19.47
Objects365[27]
±0.10 ±0.06 ±0.06 ±0.10 ±0.12 ±0.17 ±0.15 ±0.31 ±0.15 ±0.10 ±0.25 ±0.25
10.58 25.01 26.87 15.64 42.22 56.90 4.94 9.03 4.75 2.82 7.90 12.19
LVIS[11]
±0.07 ±0.02 ±0.03 ±0.05 ±0.08 ±0.17 ±0.09 ±0.09 ±0.10 ±0.01 ±0.14 ±0.20
5.52 23.92 29.02 13.34 25.12 43.79 15.47 26.20 15.90 5.39 15.06 21.81
SA-1B[18]
±0.02 ±0.03 ±0.18 ±0.27 ±0.21 ±0.12 ±0.08 ±0.09 ±0.03 ±0.06 ±0.13 ±0.08
Mask(InstanceSegmentation)
9.69 21.11 22.50 12.68 36.14 47.79 4.21 7.99 3.95 1.88 6.96 13.67
LVIS[11]
±0.06 ±0.05 ±0.01 ±0.01 ±0.11 ±0.17 ±0.20 ±0.25 ±0.24 ±0.19 ±0.21 ±0.18
5.27 21.62 25.99 12.90 22.76 38.33 13.85 24.78 13.67 4.09 13.45 20.36
SA-1B[18]
±0.01 ±0.07 ±0.22 ±0.37 ±0.24 ±0.21 ±0.09 ±0.08 ±0.11 ±0.04 ±0.10 ±0.07
19I LimitationsandBroaderImpacts
Limitations. Duetotheself-supervisednatureofHASSOD,thelearnedobjecthierarchicallevels
maynotbeperfectlyalignedwithhumanperception. Thismismatchmayleadtoover-segmentor
under-segmentofobjectsinreal-worldapplications.
Input CutLER HASSOD (Ours)
Figure9: FailurecasesofHASSOD.Top: Overlappingandsimilarobjectsarehardtodistinguish.
Middle: Thewholeobjectcomprisingdiversepartsisnotidentified. Bottom: Textcontentsarenot
preciselylocalized.
We observe that HASSOD performs unsatisfactorily in certain scenes due to this lack of human
supervision. Figure 9 provides a visualization of the failure cases. In the first row, HASSOD
mistakenlytreatsthelowerpartsofthetwoplayersasasinglecoherentobject. Duetotheirsimilar
color and texture, multiple overlapping instances of the same class can sometimes be perceived
as one object. In the second row, HASSOD fails to predict a mask that encompasses the entire
motorcycle. Thisobjectconsistsofhighlyheterogeneousparts,makingitchallengingtorecognize
themascomponentsofasingleentity.Inthethirdrow,HASSODfailstodetectthetext“Koelnmesse,”
andtheboundariesforothertextarenotclear. Wealsoobservethatsucherrorsarenotuniqueto
HASSOD;theyappearinpriorself-supervisedobjectdetectionmethodslikeCutLERaswell. We
believethatfurtherhumansupervisionwouldbenecessaryforcorrectingthesemistakes.
Broader impacts. Detecting object parts with self-supervision may be beneficial to real-world
applicationsincludingroboticmanipulationandinspection. Asageneralobjectdetectionmethod,we
sharerisksassociatedwithapplyingrecognitionmodelssuchasabuseofsurveillancesystems.
J Hyper-ParametersandImplementationDetails
In the initial pseudo-label generation process, we use a frozen ViT-B/8 model [8] pre-trained on
unlabeledImageNet[7]byDINO[5],aself-supervisedrepresentationlearningmethod,toextract
visual features of train and unlabeled images in MS-COCO [20]. Following prior work Cut-
LER[38],weresizetheresolutionofeachimageto480×480,leadingto60×60patchesasinitial
regions. Themergingprocessstopsatthreethresholdsθmerge =0.4,θmerge =0.2,θmerge =0.1,and
1 2 3
resultsfromthesethreethresholdsareensembledafterpost-processing. Thepost-processingsteps
includeConditionalRandomField(CRF)[19]andfillingtheholesineachmask. Wealsofilterout
low-qualitymasksthat1)haveanIntersection-over-Union(IoU)smallerthan0.5beforeandafter
CRF,2)aresmallerthan100pixels,or3)containmorethantwocornersoftheimage(whicharelikely
20background). Thesepost-processingstepsarealsousedinpriorworkincludingCutLER[38]. After
ensemblingresultsfromthethreethresholds{θmerge}3 ,weidentifythehierarchicallevelsofeach
i i=1
objectmaskbasedonthecoveragerelationanalysis. Thecoveragethresholdissettoθcover%=90%.
Inthedetectortrainingstage,wetrainaCascadeMaskR-CNN[4]withaResNet-50[13]backbone
onthesameMS-COCO[20]images. ThebackboneisinitializedfromDINO[5]self-supervised
pre-training. Ourhyper-parametersettingforMeanTeachermostlyfollowsthepracticeofUnbiased
Teacher[22]. Thewholetrainingprocessstartswitha“burn-in”stage, duringwhichthestudent
modelisonlytrainedontheinitialpseudo-labelswithafixedlearningrate0.01andfixedlossweights.
Aftertheburn-instage,theteachermodelisintroduced,andwegraduallyadjustthelearningrate
from0.01to0,thelossweightinthelabel-to-studentbranchfrom1.0to0.0,andthelossweightin
theteacher-to-studentbranchfrom2.0to3.0,allfollowingacosineschedule. Thewholetraining
processspans40,000iterationswithabatchsizeof16images. Thetrainingisperformedon4×
NVIDIAA100GPUs. OurcodeisdevelopedbasedonPyTorch[24]andDetectron2[40].
K AdditionalQualitativeResults
In this section, we present visualization of detection results by CutLER [38] and HASSOD on
Objects365[27]inFigure10andSA-1B[18]inFigure11(seenextpages). Qualitativeresultson
LVIShasbeenincludedinthemainpaper,Figure5.
21Input CutLER HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure10: QualitativeresultsonObjects365[27]. Ineachrow,weshowdetectionresultsofprior
state-of-the-artself-supervisedobjectdetectorCutLER,wholeobjectspredictedbyHASSOD,and
allobjectpredictedbyHASSOD.
22Input CutLER HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure 11: Qualitative results on SA-1B [18]. In each row, we show detection results of prior
state-of-the-artself-supervisedobjectdetectorCutLER,wholeobjectspredictedbyHASSOD,and
allobjectpredictedbyHASSOD.
23