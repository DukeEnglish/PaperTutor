Cooperative Learning with Gaussian Processes for Euler-Lagrange
Systems Tracking Control under Switching Topologies
Zewen Yang1,2, Songbo Dong2, Armin Lederer2, Xiaobing Dai2, Siyu Chen3, Stefan Sosnowski2,
Georges Hattab1,4 and Sandra Hirche2
Abstract—This work presents an innovative learning-based of predictions of GPR is notably sensitive to the quantity
approach to tackle the tracking control problem of Euler- of available training data [10]. Employing a large dataset
Lagrange multi-agent systems with partially unknown dy-
can significantly escalate computational demands, thereby
namics operating under switching communication topologies.
impedingthereal-timeapplicabilityofGPRincontroltasks. The approach leverages a correlation-aware cooperative al-
gorithm framework built upon Gaussian process regression, Various techniques have been developed to mitigate the
whichadeptlycapturesinter-agentcorrelationsforuncertainty training and prediction complexity of GPR, which increases
predictions. A standout feature is its exceptional efficiency in cubically with the number of training samples. These meth-
deriving the aggregation weights achieved by circumventing ods include inducing point techniques [11], finite feature
the computationally intensive posterior variance calculations.
approximations [12], and aggregation strategies [13], while
Through Lyapunov stability analysis, the distributed control
law ensures bounded tracking errors with high probability. these methods primarily focus on single-agent systems. The
Simulation experiments validate the protocol’s efficacy in concepts from aggregation techniques have been extended
effectively managing complex scenarios, establishing it as a to enable cooperative learning using GPR within MASs. In
promising solution for robust tracking control in multi-agent
[14], [15], the event-triggered learning-based incorporating
systems characterized by uncertain dynamics and dynamic
GPR allows individual learning in each agent, such that it
communication structures.
provides probabilistic guarantees for safe consensus control.
I. INTRODUCTION Despite its advantages, this method overlooks the potential
benefit of information exchange between locally learned
Multi-agent systems (MASs) have attracted significant
models. The previous works [16]–[18] propose cooperative
attention within the field of control due to their ability to
learning approaches, where the agents aggregate the predic-
collaboratively achieve overarching objectives [1]. Although
tions from their neighboring agents. While this approach
many studies concentrate on linear agent dynamics, the
achieves accurate predictions, it necessitates the additional
application of control methods developed for linear systems
computationsofGaussianprocessposteriorvariancesforde-
is inadequate for intricate physical systems. In this paper,
terminingaggregationweightsoroptimizedparameters[19],
we delve into Euler-Lagrange MASs, which serve as a
[20]. Although [21], [22] proposed elective learning for
modelingframeworkfordiversephysicalsystemslikerobotic
mitigating the computational burden of joint prediction, the
manipulators [2] and underwater vehicles [3].
proposed method requires prior knowledge, which may not
Accomplishing intricate tasks in MASs often involves
be available for certain systems. In this paper, we present a
extensive investigations of tracking control protocols, as
collaborative learning framework based on cooperative GPR
evident in numerous studies [4]–[7]. Many of these ap-
offering computational efficiency, while still maintaining the
proaches assume a prior understanding of system dynamics
established theoretical bound on tracking error for the MAS
and environmental disturbances, which poses a significant
control.
constraint when dealing with uncertain MASs operating in
Thecontributionofthispaperisintheformofafreshap-
unfamiliar environments. To overcome this challenge, there
proach to cooperative learning for distributed control rooted
has been a surge in interest toward learning-based control
in the GPR technique and is designed to address uncertainty
methods that leverage collected data to infer uncertainties
inEuler-Lagrangemulti-agentsystems(ELMAS).Thenovel
inherent to the environment. Particularly in the context of
learning framework, named cooperative correlation-aware
safe control tasks amidst uncertainties, Gaussian process
GP (Cora-GP), leverages established aggregation methods
regression (GPR) [8] has emerged as a popular choice for
while bypassing the need for calculating GP posterior vari-
modeling the effects of unknown environmental factors on
ances. We provide two computationally efficient strategies
system dynamics. GPR’s appeal lies in its robust expres-
for realizing the Cora-GP approach and incorporate them
sivecapabilities,atheoreticalfoundationthataccommodates
into a distributed consensus tracking control law. The effec-
statistical prediction error bounds, and an intrinsic trade-
tivenessoftheresultingcontrollawsisformallyshownusing
off between bias and variance [9]. Nonetheless, the efficacy
convergenceguaranteesforthetrackingerroroftheELMAS
Preprint. and demonstrated numerically in simulations. Notably, this
1 Robert Koch Institute, Berlin, Germany. 2 Technical University of convergence is achieved in the proximity of the origin, even
Munich, Munich, Germany. 3 The University of Texas at Austin, Austin,
within semi-Markov switching communication topologies.
TX,USA.4 FreieUniversitätBerlin,Berlin,Germany.Correspondenceto:
ZewenYang<yangz@rki.de> The remainder of this article is structured as follows:
4202
beF
5
]AM.sc[
1v84030.2042:viXraPreliminaries and the problem formulation are stated in denoted by τ = t t [23]. Based on this notation,
k k+1 k
−
SectionII.InSectionIII,thenovelcorrelation-awareGPap- we define semi-Markov time-varying topologies as follows.
p suro sa tc rah ci ks inp gre cs oe nn tt re od l. oT fh te hele Ear Ln Min Ag- Sba is se pd rop pro ot so ec do ,l af no dr sc to an bs ile in ty- indD exefi inn giti aon se1 t: oC fo fin xs eid der toa pos lt oo gc ih ea ssti ¯c pr ,oc we hss ere{r r(t ()
t}
)t∈R
0,+
.
r(t)
G ∈ P
for the resulting closed-loop MASs is proven in Section IV. Let the process have step-wise trajectories with jumps at
Anumericalsimulationdemonstratestheeffectivenessofthe times t ,k N satisfying 0 < t < t < < t < ,
k 1 2 n
∈ ··· ···
proposed approach in Section V, followed by a conclusion. suchthatthesequenceoftopologyindexesr(t )satisfiesthe
k
Markov property, i.e., the probability Pr r(t ) = r
k+1 k+1
II. PRELIMINARIESANDPROBLEMFORMULATION r(t ) = r , r(t ) = r , ,r(t ) = r { = Pr r(t ) =|
0 0 1 1 k k k+1
··· } {
r r(t ) = r for all r ,r , ,r ,r
A. Notation and Graph Theory k+1 k k 0 1 k k+1
| } ··· ∈
. Moreover, let the distributions of the holding time
We denote real positive numbers without/with zero as P τ be described in terms of distribution functions
k
R +/R 0,+, naturals without/with zero as N/N 0, respectively. F (τ )viaPr t t τ ,r(t )=j r(t )=i =
ij k k+1 k k k+1 k
If not stated otherwise, identity matrix, null vector and P F (τ ). Th{ e pro− babili≤ ties P = Pr r(| t ) = } j
ij ij k ij k+1
vector or matrix of elements 1 are denoted by I,0 and 1 r(t ) = i define a transition probabilit{ y matrix P =|
k r
with appropriate size, respectively. The Euclidean norm of [P ] R} N×N with P = 0, where i,j . Then,
ij ii
a vector or matrix is denoted by , the cardinality of r(t) de∈ scribes the topology indexes of a semi-M∈ arkP ov time-
∥ · ∥
a set is represented as , and the Kronecker product
varying topology.
N |N|
is indicated by . Minimum/maximum singular values of
The behavior of semi-Markov time-varying topologies can
⊗
a matrix are denoted by σ()/σ¯(). Matrix A 0, if A is be intuitively described as follows. Once a topology ¯
a positive definite matrix.
Th·
e
op·
eration
blkdia≻
g() returns a is chosen, it remains constant for the sojourn time τ . TG
hrk
e
k
blockdiagonalmatrixcreatedbyaligningtheinputmatrices. sojourn time τ is a random variable itself with probability
k
Inthispaper,weusea digraph =( , )todescribethe distributions F , which depend on the current topology and
G V E ij
communicationamongtheELagents,where = 1,...,n the next topology. When the topology is switched, the new
V { }
denotes the set of nodes, and denotes the topology ¯ is sampled from the discrete probability
set of edges. A directed edge (iE ,j)⊆ indV ic× ateV s that the i-th distributionGr Pk+1 ,j = i. Since the edges in this stochastic
ij
agentreceivestheinformationfromj-thagent.Theweighted communicationtopo̸ logychangeovertime,itallowsmorere-
adjacency matrix of is denoted by A = [a ij] Rn×n, alisticmodelingofwirelesscommunicationnetworks,where
G ∈
where an adjacency entry a ij > 0 if (j,i) and a ij = 0 the connection between two agents can break down.
∈ E
otherwise. Moreover, it is assumed that the diagonal entries Inordertoensurethatadistributedalgorithmcoordinating
of the matrix A are zero, which implies a ii = 0, i . the agents can work properly, the communication topology
∀ ∈ V
Furthermore, we define the self-loop included adjacency has to ensure sufficient connectivity among the agents over
matrix Aˇ = [aˇ ij] Rn×n with entry aˇ ij = 1 if a ij > 0, time [23], [24], which requires the following assumptions.
∈
aˇ ii = 1 and a ij = 0 otherwise. The Laplacian matrix Assumption 1: At every time t, the communication topol-
of a digraph is defined as L = D A, where D = ogy ¯ contains a spanning tree with the root node being
diag(d 11,d 22,...d nn) with d ii = (cid:80)n j=− 1a ij is the degree the lG ear d(t e) r node 0.
matrix of graph . The set of neighbours of agent i is
Assumption 1 ensures that theswitching graph has at least a
G
represented by i = j : (j,i) . Similarly, let path from the leader to some agents. In switching systems,
¯=(¯, ¯)bethN edigra{ ph∈ ofV theleader-∈ folE lo} weragentswith
this assumption is common since it is essential for followers
G the noV deE set ¯ = 0 and the edges set ¯ ¯ ¯, to track the leader [25]. In addition, an assumption for the
V { }∪V E ⊆ V ×V
wherethevirtualleaderisdenotedbynode0.TheLaplacian transition probability matrix P needs to be imposed.
r
matrix of ¯ is denoted as Assumption 2: The transition probability matrix P is
G r
(cid:20) (cid:21)
0 0 irreducible.
L¯ = 1×n R(n+1)×(n+1),
L 0 L˜ ∈ This Assumption 2 ensures that all states intercommunicate,
i.e., there exists a positive probability that allows transition-
where L =[a ] Rn, L˜ =D˜ A, and the diag-
0 i0 i=1,...,n ing between any pair of states within finite steps.
onal matrix D˜ =diag(d˜∈ ,...d˜ ) with− d˜ =(cid:80)n a .
11 nn ii j=0 ij
C. Euler-Lagrange Multi-agent System
B. Stochastic Communication Topology
In this paper, we consider an ELMAS consisting of n
Inthispaper,weconsideraclassoftime-varyingstochas- homogenous follower agents, referred to as agents in the
tictopologies(graphs),whichisdescribedbyasemi-Markov following,andonevirtualleader.Inparticular,thedynamics
process. This class of time-varying topologies is based on a of the i-th agent in the ELMAS is described as
set of fixed topologies ¯ , where the index r belongs to
the finite state space
G =r
1,2,...,N with well-defined
H(q i)q¨ i+C(q i,q˙ i)q˙ i+g(q i)+f(p i)=u i, i ∈V, (1)
N N. Let r(t) = rP { , t R , } denote the index of where q = [q ,q ,...,q ]⊤ X Rm is the state
k 0,+ i 1 2 m
the∈ topology at the k-th∈ tiP me in∈ terval t [t ,t ), where of the i-th agent, u = [u ,u∈ ,...,u⊂ ]⊤ Rm is the
k k+1 i 1 2 m
k N . Then, the sojourn (holding) t∈ ime at state r is control input, and p := [q⊤,q˙⊤,q¨⊤]⊤. T∈ he functions
∈ 0 k i i i iH() : Rm Rm×m, C() : Rm Rm Rm×m and consensus tracking if there exists a compact set Ω R2m
e
g()· : Rm →Rm denote the· inertia m× atrix, C→ oriolis matrix containing the origin, so that for all i , e¯(0)⊂ Ω ,
i e
and·
the
gr→
avity vector. Since they can be easily identified there exists a small constant ψ and a
fi∈ niteV ti∀
me T
∈R
,
e +
∈
using well-known techniques from robotics [26], we assume such that the tracking error satisfies e (t) ψ, t T .
i e
∥ ∥≤ ∀ ≥
them to be known in the sequel. The function f() =
[f (),...,f ()]⊤ :R3m Rm isassumedtobeunkn· own, III. DISTRIBUTEDLEARNINGWITHGPS
1 m
but · identical in· all agents→ . This setting can be found in a A. Individual Learning
scenario where a homogeneous fleet of autonomous robots A Gaussian Process (m (p),k(p,p′)) is a stochas-
gp
GP
operates in an unknown environment interfering with the tic process where any finite subset of the observations
robot dynamics, e.g., hydrodynamic forces caused by ocean of variables p(1) p(M) is assigned a joint Gaussian
currentsactingonunderwatervehicles.Thecontroltaskisto distribution d{ efined·· b· y a p} rior mean m () : R3m R
gp
track a virtual leader, whose dynamics follows a prescribed and a covariance function k() : R3m ·R3m →R
0,+
reference trajectory f r():R 0,+ Rm, which yields [8]. The prior mean can be u· sed to inc× lude app→ roximate
· →
modelsintheregression,andthecovariancefunctionreflects
q =f (t), (2)
0 r
structuralpriorknowledgesuchassmoothnessorperiodicity.
where q 0 is the state of the virtual leader. To ensure When no specific structure is known a priori, a frequently
each agent can follow the leader, we pose the following used covariance function is the ARD squared exponential
ass Au sm sup mtio pn tioo nn 3t :he Tr he efe rr ee fn ec ree nt cr eaj te rc at jo ecry tof ryr( f·).
isatleasttwice
σkernel Rk(p an, dp′ l)=σ Rr2ex ap re(cid:0)
s−
o
c21 a(cid:80) llem
j d= h1
yl
j
p2 e( rp
-pj a−
rap m′
j
e) t2 e(cid:1) r, s.where
r r + j +
continuously differentiable and f˙ (t) f¯, f¯ R . G∈ iven a data s∈ et satisfying Assumption 4, Gaussian pro-
r r r 0,+
∥ ∥≤ ∈
This assumption is common for the control of Euler- cess regression is performed by conditioning the prior GP
Lagrange systems as it allows tracking a reference using defined by m gp() and k(, ) on the data set i considering
· · · D
control techniques such as feedback linearization or the i-th agent with M i training data pairs. Without loss
computed torque control [17]. Moreover, since the reference of generality, we set the prior mean to 0. Due to the
trajectory is a design choice, it is not restrictive in practice. assumption of Gaussian noise, the posterior distribution is
To infer a data-driven model of the unknown function f, again Gaussian. Considering scalar systems, i.e., m=1, the
we assume the availability of measurements of f() in each posterior has a mean and variance function [8]
·
agent. These measurements satisfy the following conditions. µ (p)=k(P ,p)⊤(K(P ,P )+σ2I )−1Y ,
Assumption 4: Each agent i has access to a training data
i i i i o Mi i
mse et aD sui re= men(cid:8) t(cid:0) p pi( aϑ ir) s,y (i( pϑ () ϑ(cid:1) )(cid:9) ,ϑ y= (ϑ1 ),.. =.,M Hi c (o qn )s qi ¨sti +ng Co (f qM ,q˙i )∈
q˙
+N rσ ei2 s( pp e) ct= ivk el( yp ,, wp h) − erek(P i,p)⊤(K(P i,P i)+σ o2I Mi)−1k(P i,p),
i i i i i i i
g(q i)
−
u i + ζ(ϑ)), where y i = [y i1,...,y im]⊤, ζ is k(P i,p)=[k(p( i1),p),...,k(p( iMi),p)]⊤,
an independent, identical, zero mean Gaussian noise with
covariance matrix σ o2I. the matrix K(P i,P i)=[k(p( ia),p( ib) )] a,b=1,...,Mi, the train-
This assumption allows each agent to have its own indepen- ingdataP i =[p( i1) ... p( iMi) ],andY i =[y i(1) ... y i(Mi) ]⊤.
dently collected data set without the necessity to share data In order to apply Gaussian process regression to systems
between them directly. It also necessitates comprehensive with dimension m > 1, we consider an independent Gaus-
measurements of the system states, a common requirement sian process for each dimension. Under the assumption of
in data-driven control methods, e.g., [9], [27], [28]. To ad- equalhyper-parametersforeachdimension,themulti-output
dress potential measurement noise in GPR, we may transfer prediction can then be efficiently computed using
noise in the output variable by utilizing Taylor expansion µ (p)=k¯(P ,p)⊤K¯(P ,P )Y¯, (4)
i i i i i
techniques [29], or incorporate noise directly into the kernel
σ2(p)=1 σ2(p), (5)
function [30]. Employing these strategies, the inputs for the i m i
GP model can still be treated as effectively noise-free. where the matrix k¯(P ,p) = I k(P ,p), K¯(P ,P ) =
i m i i i
Based on the distributed data sets under Assumption 4, I (K(P ,P ) + σ2I )−1, ⊗ and training data Y¯ =
we consider the problem of designing a distributed control [ym 1,⊗ ...,ym]⊤i wi ithyj =o [M y(i 1),...,y(Mi) ], j =1,2,...i ,m.
i i i ij ij
law for tracking the virtual leader state q 0 with the agent While Gaussian process regression is known to have
states q i. Due to the unavailability of the exact dynamics, many beneficial properties for practical usage, it suffers
we cannot expect to achieve exact tracking with asymptotic crucially from high computational complexity [8]. This is
stability.However,thetrackingerrorofeachagente¯ i R2m, particularly problematic for the posterior variance σ2(),
∈ ·
which is defined as which requires (M2) computations for on-line evaluation,
O i
e¯ i(t)=[e i(t)⊤,e˙ i(t)⊤]⊤, ∀i
∈V
(3) e wv ie thn aif co(K mp( lP exi, itP yi o) f+ σ (Mo2I M 3)i .) T− h1 eis cop nr se id-c eo ram bp leut ce od mo pf lf e- xli in tye
O i
wheree i =q i q 0,isexpectedtoconvergetoasmallvalue. associated with utilizing posterior variance in control
−
This is formalized using the following notion of stability. schemes, particularly in distributed learning settings, can
Definition 2: An ELMAS consisting of n agents achieves often lead to its exclusion from practical usage. As a result,an alternative and more efficient approach is investigated in otherwises (p)=0 .Thecorrelation-awarefunction
il Mmin×1
i
t ch oi ms pp ra op mer ist io ngac ph eie rfv oe rmco ao np ce er .ative learning objectives without T Mop m( ik n( lP arl g, ep s) t,M eleim mi en n) t: sR fr| oD ml|
×
itsN
in→
putR vM ei cm ti on r,se wle hc it cs hth ree qfi uir rs et
i
(M log(M )) for sorting the values, thereby retaining the
l l
B. Cooperative Learning with Correlation-Aware GPs O
most relevant elements based on their magnitudes.
As GPR suffers from this inherent computational burden, In order to further dilute the computation time for ob-
distributed computing is a promising method. For realizing taining the aggregation weights, correlation-aware GP with
an effective aggregation, the different predictions’ impor- average elements (Cora-GP-Avg) is developed. In this case,
tancemustbetakenintoaccountbyadaptingtheaggregation the function s il() : R3m R simply normalizes the sum
· →
weights. This leads to a dependency of the aggregation of the elements of the vector k(P l,p) denoted as follows
weights on the posterior variance, which means that each 1⊤k(cid:0)
P
,p(cid:1)
a toge an dt dri es su sf tf he ir ss sf hro om rtcoa
mO
in(M goi2 f) ef xo ir ste ina gch mp er te hd oi dc sti ,o wn. eI pn roo pr od se er s il(p)= n
M
ll , for l ∈Ni, (11)
a correlation-aware GP (Cora-GP) algorithm. This approach otherwise s il(p) = 0, where this operation only requires
aggregates the predictions of neighboring agents similarly (M l) for each agent l. Compared to Cora-GP-Top, GoGP-
O
to existing approaches but employs the prior covariance Avgofferstheadvantageoffasterprocessingasiteliminates
k(P,p) between a test point p and the training input P to the need for sorting values. However, it still effectively
determine the aggregation weight of each agent. Therefore, captures the underlying correlation relationships.
the proposed algorithm sidesteps computing the posterior Within the proposed cooperative learning framework, the
variance of GPs. posterior mean µ˜ ij(p) aggregates the weighted prediction
only from the neighbors of agent i, which is guaranteed by
We consider the i-th agent with local multi-output GP is
trained with the set with M pairs of training inputs P
using the elements aˇ ij(r(t)) of the matrix Aˇ r(t). There-
i i i
and training outputsD Y . Moreover, let Mmin =min M l fore, it does only use information accessible through the
i i { l | ∈ communication topology defined by the graph . The
be the minimum number of training samples of neigh- r(t)
i G
N bor} s of the i-th agent. We propose to compute the j-th function h i() determines the weights for aggregation with
the
property· (cid:80)n
h () = 1. The construction of the
dimensionaggregatedposteriormeanofthemulti-outputGP d=1 id ·
of the i-th agent
weightsh id(p)leadstoadependencyonk(P i,p),therefore,
it reflects the correlation between inputs and training data.
µ˜ ij(p)=h i(p)⊤µj(p), i=1,...,n, j =1...,m, (6) To enhance comprehension of the algorithm’s procedure, we
where µj(p) = [µ (p),...,µ (p)]⊤. The aggregation furnish a pseudo-code in Algorithm 1.
1j nj
weight function h ():R3m Rn is defined as The Cora-GP approach has the advantage that its aggre-
i
· → gation scheme does not require the posterior variance of

h id(p)= (cid:80)| lN =w 1ii |d w(p i) l(p), d ∈Ni , (7) i an redi av li rd eu aa dl yG cP os m, pb uu tt edre wlie hs enso dle el ty ermon ink in( gP ti h, ep) in. dT ih ve ids ue av le mct eo ar ns
0, otherwise
functions (4), such that they come at no additional compu-
and the function w():R3m R is calculated by tational cost. Thereby, the computational complexity in each
+
· → agent for predictions is reduced to (M ) with Cora-GP-
w il(p)= aˇ σi gl i( √r( 2t) π) exp(cid:16) −(cid:16) ∥s s˜i il (( pp )) ∥ −w¯ i(cid:17)2 /2σ g2 i(cid:17) , (8) A trav ig nia nn gd
dO
at( aM si el tog( iM ii n)) cw onit th raC stor toa-G pO rP e- vT io oi p usco wn os rid ke s,rin wg ht eh re
e
D
where l=1,...,n. The factor σ R and the parameter this complexity is (M2) [13], [16], [17]. Additionally, the
gi ∈ + O i
w¯
=max(cid:26) aˇ i1(r(t)) ∥s i1(p)
∥
aˇ in(r(t)) ∥s in(p) ∥(cid:27)
,
f su un mct eio qn us alh si od( n· e) .i Tn h( i7 s) ah lla ov we sth ue sb toen de efi rc ivia el up nr io fp oe rmrty pt rh ea dt ict th ie oi nr
i s˜(p) ··· s˜(p)
i i error bounds under the following additional assumption.
(9)
Assumption 5: Every component f (p) of the unknown
are the standard deviation and the expected value of j
function f(p) in (1) with Lipschitz constant L is a sample
the Gaussian distribution (8), respectively, with s˜(p) = f
(cid:80)N
l=i 1aˇ il(r(t)) ∥s il(p) ∥, which ensures that the
mai
ximum
o Lb ipta si cn he id
tz
f cr oo nm tina uouG sau ks es ri na en
l
kp :ro Rc 3e mss
GRP
3m(0,k R(p,p .′)) with
value ofthe correlation function s il() is theexpected value. × → 0,+
· This assumption is not restrictive in practice since it merely
The correlation function s () associated with k(P ,p) for
il l
· definesapriordistributionoverplausiblefunctionsf()[31].
the i-th agent evaluates the correlation between the query ·
This distribution usually covers a large class of functions,
point p and the training data P .
l
e.g., for squared exponential kernels the support of the
Leveraging the results of k(P ,p), we present the first
l distribution corresponds to the continuous functions on a
approach correlation-aware GP with top element (Cora-GP-
Top), the function s il( ·) : R3m
→
RM imin, considering the c uo nm ifop ra mct ps re et di[ c3 t2 io]. nB era rs oe rd boo un nt dhi fs ora Css ou rm a-p Gti Po sn, cath ne befo dll eo rw ivi en dg
.
training data set comprises M data pairs, is designed as
Dl l Lemma 1: For a compact set for p as Ω Rm, consider
follows ∈
the unknown function f() in (1) satisfying Assumption 5
s (p)=Top(k(P ,p),Mmin), for l , (10) and GPs with the training· data set satisfying Assump-
il l i ∈Ni DiAlgorithm 1 Cora-GP algorithm 1,...,m. Moreover, φ(τ,δ) is monotonically decreasing in
Require: n 2 ▷ number of agents τ, while γ(τ) is monotonically growing. Therefore, there
Require: OP≥ TION: Choose Cora-GP-Avg or Cora-GP-Top existsaτ suchthatmin p∈Ωσ i2 j(p) ≥σ m2
in
≥γ i2 j(τ)/φ(τ,δ)
if OPTION is Cora-GP-Top then foralli=1,...,n, j =1,...,m,which,togetherwith(14),
endO ifbtain M imin a tollo [2w 7s ],u us st io ngsi tm hepl fi af cy t( t1 h6 a) t(cid:84)to
m j|
=∆ 1f |∆ij( fp ij)
(| p≤
)
|η ≤i,j η( ip ,j, (δ p) ,. δS )i ,m thil ea nr
for i=1:n do
∆f [η (p,δ),...,η (p,δ)] (17)
i i1 im
Calculate k(P ,p) ∥ ∥≤∥ ∥
i
for l do yields the result with the probability of at least (1 δ)m.
∈Ni −
Calculate k(P ,p) This lemma establishes a uniform prediction error bound
l
Update s (p) based on OPTION via (10) or (11) over the compact domain Ω. For the derivation of the
il
end for Lipschitz constants L and L , we refer to [31].
µij σ i2
j
w¯ , w (p) Eq. (9), Eq. (8)
i il
←
h id(p) Eq. (7) IV. CONSENSUSTRACKINGUNDERSWITCHING
←
µ˜ ij(p) Eq. (6) TOPOLOGY
←
end for
ToachieveconsensustrackingwiththeELMAS(1)under
switching semi-Markov topologies, for each agent i (i
t mio in n4, ∀ σi 2= (p1 ),2,. γ. 2., (τn ). /P φi (c τk ,δτ ),∈ R j+ =, 1δ ,∈ ...( ,0 m,1 ,) such that V), we let fˆ i(p i) = µ˜ i(p i) := [µ˜ i1(p i),...,µ˜ im(p i)]⊤ b∈ e
p∈Ω ij ≥ ij ∀ the prediction of the unknown dynamics f() from agent i
(cid:18) r √m(cid:19) obtained by a Cora-GP (6) and define a feedb· ack linearizing
φ(τ,δ)=2mlog Ω 2log(δ), (12)
distributed control law of the form
2τ −
γ ij(τ)=(L f +L µij)τ +(cid:113) φ(τ,δ)L σ i2 jτ, (13) u i =c iH(q i)ν i+C(q i,q˙ i)q˙ i+g(q i) −fˆ(p i), (18)
where ν is the synchronization error defined by
cfo or nsr tΩ an= tsm ofa tx hp e,p in′∈ dΩ iv∥ idp u− alp G′ P∥, mL eµ ai nj aa nn dd vL aσ rii2 aj nt ch ee fL unip cs tc ioh nit sz , i (cid:88)n
respectively. Then, with probability of at least (1 δ)m, ν i = − a ij(r(t))[α(q i −q j)+(q˙ i −q˙ j)]
it holds for the proposed Cora-GP method in (− 6) that j=0
f µ˜
i
η˜ i(p,δ) for all i = 1,...,m, where µ˜
i
:= =α∆q i+∆q˙ i, (19)
∥ − ∥ ≤
[µ˜ i1,...,µ˜ im]⊤ and η˜ i(p,δ) = [η i1(p,δ),...,η im(p,δ)] where ∆q := (cid:80)n a (r(t))(q q ) is the consen-
with ∥ ∥ sus trackini g error cj o= rr0 espij onding toj − the i i-th agent and its
η ij(p,δ)=2(cid:112) φ(τ,δ/n)h i(p)⊤σj(p), (14) d coer ei fv fia ct ii ev ne t∆ αq˙ i R:= i(cid:80)
s
sn j e= t0 ta oij b( er( pt o) s) i( tq i˙ vj e−
.
q˙ i). The constant
+
where j =1,...,m, σj(p)=[σ (p),...,σ (p)]⊤. ∈
1j nj SincetheCora-GPpredictions(6)andthesynchronization
Proof: According to the Cora-GP algorithm (6), it is error(19)relyonlyonlocallyavailableinformationorvalues
trivialtoshowthej-thdimensionalunknownf()prediction accessible via the communication network, the control law
·
error ∆f ij(p) := f j(p) µ˜ ij(p) with the property in (7) (18) can be implemented in a distributed fashion. Moreover,
| | | − |
is bounded by duetotheerrorboundsforCora-GPpredictionsinLemma1,
∆f ij(p) =(cid:12) (cid:12)h i(p)⊤µj(p) h i(p)⊤1 nf j(p)(cid:12) (cid:12), (15) wecanguaranteethat(18)achievesconsensustracking.This
| =(cid:12) (cid:12)h i(p)| ⊤(cid:0) µj(p) −1 nf j(p− )(cid:1)(cid:12) (cid:12), is Tsh ho ew orn emin 1th :e Cf oo nll so iw dei rng anth Eeo Lr Mem A.
S consisting of n agents
h
(p)⊤(cid:2)
µ (p) f (p),..., µ (p) f
(p)(cid:3)⊤
. described by (1) and a virtual leader described by (2) under
i 1j j nj j
≤ | − | | − | Assumption 3 with switching topologies ¯ satisfying
Similarly to [16], we have the joint j-th prediction error of Gr(t)
Assumption 1, where r(t) is governed by a semi-Markov
the i-th agent with the probability of at least 1 δ bounded
− process with the finite state space = 1,2,...,N and
with P { }
jump times τ following the distribution functions F (t). By
ij
∆f (p) h
(p)⊤(cid:0)(cid:112) φ(τ,δ/n)σj(p)+γj(τ)(cid:1)
, (16) usingtheproposeddistributedlearningcontrollaw(18)with
ij i
| |≤ the chosen gain c R , employing Cora-GP algorithm
[f γo 1r jτ (τ∈ ),R ..+ .,a γn nd jφ (τ( )τ ], ⊤δ ,) M= (2 τ,lo Ωg )(M den(τ o, teΩ s) t/ hδ e) τ, -w ch oe vr ee riγ ngj( nτ u) m= - b Aa ss se ud mo pn tiot nhe 5,a thg een Ei t L∈ d Mat Aa S+ se at cs hiD evi e, si co= nse1 n, s. u. s., trn acs ka it ni gsfy wi in tg
h
ber of Ω. By overapproximating Ω through a hypercube
probability (1 δ)m, δ (0,1), if
with edge length r Ω, the covering number M(τ,Ω) can − ∈
(cid:34) (cid:35)
b Me ob reo ou vn ed re ,d asb My i(r isΩ fi√ nm ite/( f2 oτ r) a) lld, iw =h 1ic ,h ..y .i ,e nld as ni dd te hn eti tt ry ai( n1 i2 n) g. Φ 1= min r(t)∈Pσ (( 1c +L˜ αr 2( )t) −αI nm) −(1 α+ 2α2) ≻0, (20)
targets y(·) are perturbed by Gaussian noise, the posterior − 2
i
standarddeviationispositive,i.e.,thereexistsaσ
min
R
0,+
is satisfied, where c = diag(c 1I m,...,c nI m) and L˜ r(t)=
such that σ (p) σ for all p Ω, i = 1,...,n∈ , j = L˜ I . Then the consensus tracking of the ELMAS
ij min r(t) m
≥ ∈ ⊗achieves with the overall consensus tracking error form of (30) as follows
e¯=[e⊤,e⊤, e⊤,e˙⊤,e˙⊤, e˙⊤]⊤ (21) V˙ ρ⊤Φ ρ+Φ ρ, (31)
1 2 ··· n 1 2 ··· n ≤− 1 2
bounded with where ρ = [ ν , ∆q ]⊤, and Φ and Φ are defined in
1 2
∥ ∥ ∥ ∥
(1+α) Φ (20) and (23), respectively. By using the Young’s inequality,
∥e¯
∥≤ 2min r(t)σ(L˜
r(t))(cid:112)∥ (σ2 (∥
Φ
1)+1/2), (22)
we have Φ 2+ ρ 2
Φ ρ ∥ 2 ∥ ∥ ∥ . (32)
where ∥ 2 ∥∥ ∥≤ 2
Φ =(cid:104) maxσ¯(L˜ )(cid:16) η˜(p,δ) +√nf¯(cid:17) 0(cid:105) . (23) Substituting (32) into (31), one has
2 r∈P r(t) min q∈Xσ¯(H(q)) r 1 Φ 2
Proof: Before delving into the analysis of system V˙ (σ(Φ )+ ) ρ 2+ ∥ 2 ∥ . (33)
1
≤− 2 ∥ ∥ 2
stability, we first present the collective dynamics of the
Furthermore, from (33) follows the fact [33, Lemma 1] that
ELMAS (1)
H(q)q¨+C(q,q˙)q˙ +g(q)+f(p)=u, (24) V(t) V(0)exp( Φ˜ t)+ ∥Φ 2 ∥2 (cid:0) 1 exp( Φ˜ t)(cid:1) , (34)
≤ − 1 2Φ˜ − − 1
1
whereq=[q⊤,...,q⊤]⊤,f(p)=[f(p )⊤,...,f(p )⊤]⊤,
p=[p⊤,...,p1
⊤]⊤,
un =[u⊤,...,u⊤]⊤,1 n whereΦ˜
1
=σ(Φ 1)+1/2andV(0)indicatesthevalueofV
1 n 1 n at time t=0. Therefore, there exist a bounded υ R and
C(q,q˙)=blkdiag(cid:0) C(q 1,q˙ 1),...,C(q n,q˙ n)(cid:1) , T
e
> 0 such that V(t) V(t) υ when t ∈ T e. + Using
{ || | ≤ } ≥
H(q)=blkdiag(H(q ) H(q )), the facts that
1 n
···
g(q)=[g 1(q 1)⊤ g n(q n)⊤]⊤. [∆q,∆q˙] (1+α) ρ (35)
··· ∥ ∥≤ ∥ ∥
Considering the distributed controller (18), the collective due to (28) and the overall consensus tracking error e¯
control law as follows satisfies
u=cH(q)ν+C(q,q˙)q˙ +g(q) ˆf(p), (25) (cid:2) ∆q⊤ ∆q˙⊤(cid:3)⊤ = −(cid:0) I 2 ⊗L˜ r(t)(cid:1) e¯, (36)
−
where ˆf(p)=[fˆ(p )⊤,...,fˆ(p )⊤]⊤, ν=[ν⊤,...,ν⊤]⊤. we have
1 n 1 n
We consider the Lya 1punov ca 1ndidate ∥e¯
∥≤ 2min
r(t)σ(( L1
˜
r+ (t)α )) (cid:112)∥Φ (σ2 (∥
Φ
1)+1/2), (37)
V = ν⊤ν+ ∆q⊤∆q, (26)
2 2 is bounded, which concludes the proof.
where ∆q = [∆q⊤,...,∆q⊤]⊤. Considering the definition FromTheorem1,wecanderiveseveralinsightfulproperties.
1 n
of synchronization error (19), the derivative of ν is One crucial observation is that the high connectivity of the
graph ¯ , characterized by relatively large singular values
r(t)
ν˙ = α∆q˙ (27) of L˜ G at state r(t), leads to a diminished tracking error.
(cid:104) (cid:105) r(t)
+L˜ H(q)−1(C(q,q˙)q˙ +g(q) f(p) u)+q¨ , Therefore, the guaranteed tracking error bound is dictated
r(t) l
− − by the graph’s lowest level of connectivity observed during
whereq¨ l =I n q¨ l.Similarly,thederivativeof∆qisderived the process. Additionally, it is noteworthy that the matrix
⊗
as Φ associated with the control gains also appears in the
1
denominator of (22). This implies that by appropriately
∆q˙ =ν (αI )∆q (28)
nm
− designing the values of c and α, it is possible to achieve
i
arbitrarily small ultimate tracking error bounds.
Combining (27) and (28), one has
V˙ =ν⊤ν˙ +∆q⊤∆q˙, (29) V. SIMULATION
=(αν⊤+∆q⊤)(ν (αI )∆q) For demonstrating the effectiveness of the proposed con-
nm
(cid:104) − (cid:105) trol law (18) based on Cora-GP predictions (6), we consider
+ν⊤L˜
r(t)
H(q)−1(C(q,q˙)q˙ +g(q) f(p) u) q¨
l
.
4 homogeneous 2-link robotic manipulators as described
− − −
in [34]. It is assumed that the 4 manipulators possess the
Substituting the control law (25) into (29), we have
same parameters, in particular, point masses for the links
V˙ = −ν⊤(cL˜ r(t) −αI nm)ν −α∆q⊤∆q −α2ν⊤∆q m 1 = m 2 = 1 kg, length of the links l 1 = l 2 = 1 m. The
+∆q⊤ν ν⊤L˜ (H(q)−1∆f(q) q¨ ). unknown dynamics f() is chosen as
− r(t) − l ·
By employing Lemma 1, this expression can be bounded by f(p)=[q 2sin(4q 2)+cos(q 1),q 2sin(0.2q 12)+cos(q 1)]T.
V˙ σ(cL˜ αI ) ν 2+(1+α2) ν ∆q (30) A total of 1150 training samples is collected by sampling
r(t) nm
−α≤ ∥− ∆q ∥2+σ¯(− L˜ r(t))(cid:0) σ¯(∥ H∥ (q)−1)η˜(p,δ)∥ +∥ √∥ nf¯ r∥ (cid:1) ∥ν ∥, q outf pr uo tm mth eae sud ro em ma ei nn ts[ − f1 (p,1 )]2 byan zd erp oe -mrtu er ab nin Gg at uh se siare nsu nl oti in sg
e
where η˜(p,δ)= [η˜ (p ,δ),...,η˜ (p ,δ)]⊤ . By leverag- with σ = 0.1. The samples of the state q are unevenly
1 1 n n 0
∥ ∥
ing the fact that σ¯(H−1) = 1/σ(H), we have the reduced distributed among the agents as shown in Fig. 1a, leadingWithoutGP IGP CGP
0 0
Cora-GP-Top Cora-GP-Avg
D1 D2 D3 D4 fr(t) 1 2 1 2 101
1
3 4 3 4
¯ ¯ 100
0.5 G1 G2
0 0
0 10−1
1 2 1 2
−0.5
3 4 3 4 10−2
¯ ¯
G3 G4
0 20 40 60 80 100
−1 0 0
−1 −0.5 0 0.5 1 t(s)
q
1 1 2 2 1 Fig. 3: Tracking error plots for the simulated scenarios.
(a)
3 4 4 3
¯ ¯
G5 G6
(b)
Fig. 1: (a) Switching communication topologies; (b) The 100
agentihasthedataset .Meanwhile,theleader’strajectory
i
D
f (t) crosses the whole data area. r
6
10−1
4
WithoutGP IGP CGP Cora-GP-Top Cora-GP-Avg
Fig. 4: The mean tracking error of different approaches.
2
In order to demonstrate the high control performance
and a reduction in computational complexity, we compare
0 20 40 60 80 100 the proposed control law (18) to the same control law with
t(s) cooperative GPs (CGP) as proposed in [16], and individual
Fig. 2: Switching states. GP (IGP) meaning each agent estimates the uncertainties
with its own prediction independently. The corresponding
to M = 350, M = 250, M = 300, M = 250. trajectory of the norm of the overall tracking errors e¯
1 2 3 4
Moreover, the trajectory of the virtual leader is chosen as of one trail over the whole simulation time is illustrated
q (t) = 0.8cos(0.02πt), q (t) = 0.8sin(0.02πt). The in Fig. 3. The disparity in errors becomes evident when
01 02
control gains are set to α =2 and c − =2, respectively, and comparing the scenario without GP to the others. Notably,
i
thefactortoσ =0.15, i .Weuseasetof6switching CGP, Cora-GP-Top, and Cora-GP-Avg exhibit substantial
topologies, whg ii ch are sh∀ ow∈ nV in Fig. 1b. In particular, we reductionsinerrorscomparedtotheIGPmethod.Moreover,
chooseF (τ) e−0.5τ.Theinitialstatesofeachdimension the Mont-Carlo test with 100 times from different initial
ij
of q and q˙ are∼ randomly uniform distribution in the interval conditions demonstrates that both Cora-GP-Top and Cora-
[0,1.6] and [ 0.8,0.8], respectively, for each agent. The ini- GP-Avg achieve equivalent predictive accuracy of CGP
tialprobabili− tyofenteringthesixstatesisgivenrandomlyas while circumventing the computational overhead associated
[0.1705 0.2073 0.0045 0.1863 0.2456 0.1858]. The with calculating the posterior variance of GP in Fig. 4.
transition probability matrix P r is randomly chosen and the Table I presents the computational time of obtaining
switching signals satisfy Assumption 2. aggregationweightsfordifferentapproachesover1000com-
  putations.TheCora-GP-Topmethodexhibitsanaveragetime
0.00 0.10 0.20 0.10 0.50 0.10
reduction of 99.71% compared to CGP, while the Cora-
0.22 0.00 0.28 0.06 0.28 0.17
  GP-Avg method achieves an even more significant average
0.07 0.14 0.00 0.36 0.07 0.36
P r = 0.15 0.23 0.31 0.00 0.08 0.23 , time reduction of 99.97% compared to CGP. In summary,
  the proposed Cora-GP framework for cooperative learning
0.08 0.23 0.23 0.15 0.00 0.31
in MAS performs similarly against CGP without suffering
0.06 0.23 0.18 0.24 0.29 0.00
heavy computation. It enhances the efficiency of obtaining
which determines the probability of one state entering an-
aggregation weights in a crucial aspect when deploying GP-
other state.
basedcooperativelearningmethodologies.Thisimprovement
2q
)t(r
∥¯e∥
e¯ k
kTABLE I: Computation time of aggregation weights.
[13] M.DeisenrothandJ.W.Ng,“DistributedGaussianProcesses,”inPro-
ceedingsofthe32ndInternationalConferenceonMachineLearning,
Approach Mean(ms) Median(ms)
vol.37. Lille,France:PMLR,07–09Jul2015,pp.1481–1490.
Cora-GP-Avg 0.002 0.001 [14] T. Beckers, S. Hirche, and L. Colombo, “Online learning-based
formationcontrolofmulti-agentsystemswithGaussianprocesses,”in
Cora-GP-Top 0.019 0.028
202160thIEEEConferenceonDecisionandControl(CDC). IEEE,
CGP 6.50 6.30 2021,pp.2197–2202.
IGP - - [15] X. Dai, Z. Yang, F. L. Mengtian Xu, G. Hattab, and S. Hirche,
“Decentralized Event-Triggered Online Learning for Safe Consensus
ofMulti-AgentSystemswithGaussianProcessRegression,”2024.
is of particular significance for applications demanding high [16] Z. Yang, S. Sosnowski, Q. Liu, J. Jiao, A. Lederer, and S. Hirche,
prediction rates. “Distributed Learning Consensus Control for Unknown Nonlinear
Multi-Agent Systems based on Gaussian Processes,” in 2021 60th
VI. CONCLUSION IEEEConferenceonDecisionandControl(CDC). Austin,TX,USA:
IEEE,Dec.2021,pp.4406–4411.
This paper introduces a distributed consensus tracking [17] A.Lederer,Z.Yang,J.Jiao,andS.Hirche,“CooperativeControlof
control law incorporated with a novel GP-based cooperative Uncertain Multiagent Systems via Distributed Gaussian Processes,”
IEEE Transactions on Automatic Control, vol. 68, no. 5, pp. 3091–
learningframeworkforuncertainELMASs.Theresultsshow
3098,2023.
a significant stride forward in enhancing the efficiency and [18] X. Dai, Z. Yang, and S. Hirche, “Cooperative Online Learning for
efficacy of aggregation weight strategies for cooperative Multi-Agent System Control via Gaussian Processes with Event-
TriggeredMechanism:ExtendedVersion,”2024.
learning.Withtheproposedlearningapproaches,theprotocol
[19] T.N.Hoang,Q.M.Hoang,K.H.Low,andJ.How,“CollectiveOnline
ensures convergence of tracking errors within guaranteed Learning of Gaussian Processes in Massive Multi-Agent Systems,”
bounds, even when faced with semi-Markov switching com- ProceedingsoftheAAAIConferenceonArtificialIntelligence,vol.33,
no.01,pp.7850–7857,Jul.2019.
munication topologies.
[20] S. He, M. Tang, J. Fu, and J. Liang, “Distributed Online Sparse
Gaussian Process Regression for Multi-Agent Coverage Control,” in
REFERENCES 2023 42nd Chinese Control Conference (CCC). IEEE, 2023, pp.
5464–5469.
[1] K.-K. Oh, M.-C. Park, and H.-S. Ahn, “A survey of multi-agent
[21] Z.Yang,X.Dai,A.Dubey,S.Hirche,andG.Hattab,“WhomtoTrust?
formationcontrol,”Automatica,vol.53,pp.424–440,2015.
ElectiveLearningforDistributedGaussianProcessRegression,”2024.
[2] L.Gao,X.Dai,M.Kleeberger,andJ.Fottner,“Quasi-staticOptimal
[22] Z.Yang,X.Dai,A.Dubey,S.Hirche,andG.Hatab,“Pri-GP:Prior-
ControlStrategyofLatticeBoomCraneBasedonLarge-ScaleFlexible
AwareDistributedGaussianProcessRegression,”2024.
Non-linear Dynamics,” in Simulation and Modeling Methodologies,
[23] X. Guo, J. Liang, and J. Lu, “Scaled Consensus Problem for Multi-
Technologies and Applications. Cham: Springer International Pub-
Agent Systems with Semi-Markov Switching Topologies: A View
lishing,2023,pp.153–177.
fromtheProbability,”JournaloftheFranklinInstitute,vol.358,no.6,
[3] Z.Yan,J.Li,Y.Wu,andZ.Yang,“ANovelPathPlanningforAUV
pp.3150–3166,Apr.2021.
Based on Objects’ Motion Parameters Predication,” IEEE Access,
[24] X.Dong,Y.Zhou,Z.Ren,andY.Zhong,“Time-VaryingFormation
vol.6,pp.69304–69320,2018.
TrackingforSecond-OrderMulti-AgentSystemsSubjectedtoSwitch-
[4] Q. Yang, H. Fang, J. Chen, Z.-P. Jiang, and M. Cao, “Distributed
ing Topologies With Application to Quadrotor Formation Flying,”
GlobalOutput-FeedbackControlforaClassofEuler–LagrangeSys-
IEEETransactionsonIndustrialElectronics,vol.64,no.6,pp.5014–
tems,” IEEE Transactions on Automatic Control, vol. 62, no. 9, pp.
5024,Jun.2017.
4855–4861,Sep.2017.
[25] C.Hua,X.You,andX.Guan,“AdaptiveLeader-FollowingConsensus
[5] C. He and J. Huang, “Leader-Following Consensus for Multiple
forSecond-OrderTime-VaryingNonlinearMultiagentSystems,”IEEE
Euler–Lagrange Systems by Distributed Position Feedback Control,”
TransactionsonCybernetics,vol.47,no.6,pp.1532–1539,Jun.2017.
IEEETransactionsonAutomaticControl,vol.66,no.11,pp.5561–
[26] M.W.Spong,S.Hutchinson,andM.Vidyasagar,RobotModelingand
5568,Nov.2021.
Control,secondeditioned. JohnWiley&Sons,Inc.
[6] Z. Yan, Z. Yang, L. Yue, L. Wang, H. Jia, and J. Zhou, “Discrete-
[27] J.Umlauft,L.Pohler,andS.Hirche,“AnUncertainty-BasedControl
time coordinated control of leader-following multiple AUVs under
LyapunovApproachforControl-AffineSystemsModeledbyGaussian
switchingtopologiesandcommunicationdelays,”OceanEngineering,
Process,” IEEE Control Systems Letters, vol. 2, no. 3, pp. 483–488,
vol.172,pp.361–372,2019.
Jul.2018.
[7] Z.Yan,Z.Yang,X.Pan,J.Zhou,andD.Wu,“Virtualleaderbased
[28] M. Greeff and A. P. Schoellig, “Exploiting differential flatness for
pathtrackingcontrolforMulti-UUVconsideringsampled-datadelays
robustlearning-basedtrackingcontrolusinggaussianprocesses,”IEEE
andpacketlosses,”OceanEngineering,vol.216,p.108065,2020.
ControlSystemsLetters,vol.5,no.4,pp.1121–1126,2021.
[8] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for
[29] H.Kim,H.Chang,andH.Shim,“ModelReferenceGaussianProcess
MachineLearning,ser.AdaptiveComputationandMachineLearning.
Regression: Data-Driven State Feedback Controller,” arXiv preprint
Cambridge,Mass:MITPress,2006.
arXiv:2303.09828,2023.
[9] J.UmlauftandS.Hirche,“FeedbackLinearizationBasedonGaussian
[30] W.Wang,X.Yue,B.Haaland,andC.JeffWu,“Gaussianprocesses
ProcessesWithEvent-TriggeredOnlineLearning,”IEEETransactions
with input location error and applications to the composite parts
onAutomaticControl,vol.65,no.10,pp.4154–4169,2020.
assemblyprocess,”SIAM/ASAJournalonUncertaintyQuantification,
[10] X.Dai,A.Lederer,Z.Yang,andS.Hirche,“CanLearningDeteriorate
vol.10,no.2,pp.619–650,2022.
Control?AnalyzingComputationalDelaysinGaussianProcess-Based
[31] A. Lederer, J. Umlauft, and S. Hirche, “Uniform Error Bounds for
Event-TriggeredOnlineLearning,”inProceedingsofThe5thAnnual
Gaussian Process Regression with Application to Safe Control,” in
Learning for Dynamics and Control Conference, vol. 211. PMLR,
AdvancesinNeuralInformationProcessingSystems,2019,pp.659–
15–16Jun2023,pp.445–457.
669.
[11] E. Snelson and Z. Ghahramani, “Local and global sparse Gaussian
[32] A. van der Vaart and H. van Zanten, “Information Rates of Non-
processapproximations,”inProceedingsoftheEleventhInternational
parametricGaussianProcessMethods,”JournalofMachineLearning
Conference on Artificial Intelligence and Statistics, vol. 2. PMLR,
Research,vol.12,pp.2095–2119,2011.
21–24Mar2007,pp.524–531.
[33] Zeng-GuangHou,LongCheng,andMinTan,“DecentralizedRobust
[12] M. Mutny and A. Krause, “Efficient High Dimensional Bayesian
Adaptive Control for the Multiagent System Consensus Problem
Optimization with Additivity and Quadrature Fourier Features,” in
Using Neural Networks,” IEEE Transactions on Systems, Man, and
AdvancesinNeuralInformationProcessingSystems,vol.31. Curran
Cybernetics,PartB,vol.39,no.3,pp.636–647,Jun.2009.
Associates,Inc.,2018.
[34] R. M. Murray, Z. Li, and S. S. Sastry, A Mathematical Introduction
toRoboticManipulation,1sted. CRCPress,Dec.2017.