[
    {
        "title": "Cooperative Learning with Gaussian Processes for Euler-Lagrange Systems Tracking Control under Switching Topologies",
        "authors": "Zewen YangSongbo DongArmin LedererXiaobing DaiSiyu ChenStefan SosnowskiGeorges HattabSandra Hirche",
        "links": "http://arxiv.org/abs/2402.03048v1",
        "entry_id": "http://arxiv.org/abs/2402.03048v1",
        "pdf_url": "http://arxiv.org/pdf/2402.03048v1",
        "summary": "This work presents an innovative learning-based approach to tackle the\ntracking control problem of Euler-Lagrange multi-agent systems with partially\nunknown dynamics operating under switching communication topologies. The\napproach leverages a correlation-aware cooperative algorithm framework built\nupon Gaussian process regression, which adeptly captures inter-agent\ncorrelations for uncertainty predictions. A standout feature is its exceptional\nefficiency in deriving the aggregation weights achieved by circumventing the\ncomputationally intensive posterior variance calculations. Through Lyapunov\nstability analysis, the distributed control law ensures bounded tracking errors\nwith high probability. Simulation experiments validate the protocol's efficacy\nin effectively managing complex scenarios, establishing it as a promising\nsolution for robust tracking control in multi-agent systems characterized by\nuncertain dynamics and dynamic communication structures.",
        "updated": "2024-02-05 14:33:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.03048v1"
    },
    {
        "title": "LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
        "authors": "Ivar FrischMario Giulianelli",
        "links": "http://arxiv.org/abs/2402.02896v1",
        "entry_id": "http://arxiv.org/abs/2402.02896v1",
        "pdf_url": "http://arxiv.org/pdf/2402.02896v1",
        "summary": "While both agent interaction and personalisation are vibrant topics in\nresearch on large language models (LLMs), there has been limited focus on the\neffect of language interaction on the behaviour of persona-conditioned LLM\nagents. Such an endeavour is important to ensure that agents remain consistent\nto their assigned traits yet are able to engage in open, naturalistic\ndialogues. In our experiments, we condition GPT-3.5 on personality profiles\nthrough prompting and create a two-group population of LLM agents using a\nsimple variability-inducing sampling algorithm. We then administer personality\ntests and submit the agents to a collaborative writing task, finding that\ndifferent profiles exhibit different degrees of personality consistency and\nlinguistic alignment to their conversational partners. Our study seeks to lay\nthe groundwork for better understanding of dialogue-based interaction between\nLLMs and highlights the need for new approaches to crafting robust, more\nhuman-like LLM personas for interactive environments.",
        "updated": "2024-02-05 11:05:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.02896v1"
    },
    {
        "title": "Fast Peer Adaptation with Context-aware Exploration",
        "authors": "Long MaYuanfei WangFangwei ZhongSong-Chun ZhuYizhou Wang",
        "links": "http://arxiv.org/abs/2402.02468v1",
        "entry_id": "http://arxiv.org/abs/2402.02468v1",
        "pdf_url": "http://arxiv.org/pdf/2402.02468v1",
        "summary": "Fast adapting to unknown peers (partners or opponents) with different\nstrategies is a key challenge in multi-agent games. To do so, it is crucial for\nthe agent to efficiently probe and identify the peer's strategy, as this is the\nprerequisite for carrying out the best response in adaptation. However, it is\ndifficult to explore the strategies of unknown peers, especially when the games\nare partially observable and have a long horizon. In this paper, we propose a\npeer identification reward, which rewards the learning agent based on how well\nit can identify the behavior pattern of the peer over the historical context,\nsuch as the observation over multiple episodes. This reward motivates the agent\nto learn a context-aware policy for effective exploration and fast adaptation,\ni.e., to actively seek and collect informative feedback from peers when\nuncertain about their policies and to exploit the context to perform the best\nresponse when confident. We evaluate our method on diverse testbeds that\ninvolve competitive (Kuhn Poker), cooperative (PO-Overcooked), or mixed\n(Predator-Prey-W) games with peer agents. We demonstrate that our method\ninduces more active exploration behavior, achieving faster adaptation and\nbetter outcomes than existing methods.",
        "updated": "2024-02-04 13:02:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.02468v1"
    },
    {
        "title": "Settling Decentralized Multi-Agent Coordinated Exploration by Novelty Sharing",
        "authors": "Haobin JiangZiluo DingZongqing Lu",
        "links": "http://arxiv.org/abs/2402.02097v1",
        "entry_id": "http://arxiv.org/abs/2402.02097v1",
        "pdf_url": "http://arxiv.org/pdf/2402.02097v1",
        "summary": "Exploration in decentralized cooperative multi-agent reinforcement learning\nfaces two challenges. One is that the novelty of global states is unavailable,\nwhile the novelty of local observations is biased. The other is how agents can\nexplore in a coordinated way. To address these challenges, we propose MACE, a\nsimple yet effective multi-agent coordinated exploration method. By\ncommunicating only local novelty, agents can take into account other agents'\nlocal novelty to approximate the global novelty. Further, we newly introduce\nweighted mutual information to measure the influence of one agent's action on\nother agents' accumulated novelty. We convert it as an intrinsic reward in\nhindsight to encourage agents to exert more influence on other agents'\nexploration and boost coordinated exploration. Empirically, we show that MACE\nachieves superior performance in three multi-agent environments with sparse\nrewards.",
        "updated": "2024-02-03 09:35:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.02097v1"
    },
    {
        "title": "A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions",
        "authors": "Hung DuSrikanth ThudumuRajesh VasaKon Mouzakis",
        "links": "http://arxiv.org/abs/2402.01968v1",
        "entry_id": "http://arxiv.org/abs/2402.01968v1",
        "pdf_url": "http://arxiv.org/pdf/2402.01968v1",
        "summary": "Research interest in autonomous agents is on the rise as an emerging topic.\nThe notable achievements of Large Language Models (LLMs) have demonstrated the\nconsiderable potential to attain human-like intelligence in autonomous agents.\nHowever, the challenge lies in enabling these agents to learn, reason, and\nnavigate uncertainties in dynamic environments. Context awareness emerges as a\npivotal element in fortifying multi-agent systems when dealing with dynamic\nsituations. Despite existing research focusing on both context-aware systems\nand multi-agent systems, there is a lack of comprehensive surveys outlining\ntechniques for integrating context-aware systems with multi-agent systems. To\naddress this gap, this survey provides a comprehensive overview of\nstate-of-the-art context-aware multi-agent systems. First, we outline the\nproperties of both context-aware systems and multi-agent systems that\nfacilitate integration between these systems. Subsequently, we propose a\ngeneral process for context-aware systems, with each phase of the process\nencompassing diverse approaches drawn from various application domains such as\ncollision avoidance in autonomous driving, disaster relief management, utility\nmanagement, supply chain management, human-AI interaction, and others. Finally,\nwe discuss the existing challenges of context-aware multi-agent systems and\nprovide future research directions in this field.",
        "updated": "2024-02-03 00:27:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.01968v1"
    }
]