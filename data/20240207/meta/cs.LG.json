[
    {
        "title": "Test-Time Adaptation for Depth Completion",
        "authors": "Hyoungseob ParkAnjali GuptaAlex Wong",
        "links": "http://arxiv.org/abs/2402.03312v1",
        "entry_id": "http://arxiv.org/abs/2402.03312v1",
        "pdf_url": "http://arxiv.org/pdf/2402.03312v1",
        "summary": "It is common to observe performance degradation when transferring models\ntrained on some (source) datasets to target testing data due to a domain gap\nbetween them. Existing methods for bridging this gap, such as domain adaptation\n(DA), may require the source data on which the model was trained (often not\navailable), while others, i.e., source-free DA, require many passes through the\ntesting data. We propose an online test-time adaptation method for depth\ncompletion, the task of inferring a dense depth map from a single image and\nassociated sparse depth map, that closes the performance gap in a single pass.\nWe first present a study on how the domain shift in each data modality affects\nmodel performance. Based on our observations that the sparse depth modality\nexhibits a much smaller covariate shift than the image, we design an embedding\nmodule trained in the source domain that preserves a mapping from features\nencoding only sparse depth to those encoding image and sparse depth. During\ntest time, sparse depth features are projected using this map as a proxy for\nsource domain features and are used as guidance to train a set of auxiliary\nparameters (i.e., adaptation layer) to align image and sparse depth features\nfrom the target test domain to that of the source domain. We evaluate our\nmethod on indoor and outdoor scenarios and show that it improves over baselines\nby an average of 21.1%.",
        "updated": "2024-02-05 18:59:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.03312v1"
    },
    {
        "title": "HASSOD: Hierarchical Adaptive Self-Supervised Object Detection",
        "authors": "Shengcao CaoDhiraj JoshiLiang-Yan GuiYu-Xiong Wang",
        "links": "http://arxiv.org/abs/2402.03311v1",
        "entry_id": "http://arxiv.org/abs/2402.03311v1",
        "pdf_url": "http://arxiv.org/pdf/2402.03311v1",
        "summary": "The human visual perception system demonstrates exceptional capabilities in\nlearning without explicit supervision and understanding the part-to-whole\ncomposition of objects. Drawing inspiration from these two abilities, we\npropose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a\nnovel approach that learns to detect objects and understand their compositions\nwithout human supervision. HASSOD employs a hierarchical adaptive clustering\nstrategy to group regions into object masks based on self-supervised visual\nrepresentations, adaptively determining the number of objects per image.\nFurthermore, HASSOD identifies the hierarchical levels of objects in terms of\ncomposition, by analyzing coverage relations between masks and constructing\ntree structures. This additional self-supervised learning task leads to\nimproved detection performance and enhanced interpretability. Lastly, we\nabandon the inefficient multi-round self-training process utilized in prior\nmethods and instead adapt the Mean Teacher framework from semi-supervised\nlearning, which leads to a smoother and more efficient training process.\nThrough extensive experiments on prevalent image datasets, we demonstrate the\nsuperiority of HASSOD over existing methods, thereby advancing the state of the\nart in self-supervised object detection. Notably, we improve Mask AR from 20.2\nto 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page:\nhttps://HASSOD-NeurIPS23.github.io.",
        "updated": "2024-02-05 18:59:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.03311v1"
    },
    {
        "title": "AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion",
        "authors": "Mohamad QadriKevin ZhangAkshay HindujaMichael KaessAdithya PediredlaChristopher A. Metzler",
        "links": "http://arxiv.org/abs/2402.03309v1",
        "entry_id": "http://arxiv.org/abs/2402.03309v1",
        "pdf_url": "http://arxiv.org/pdf/2402.03309v1",
        "summary": "Underwater perception and 3D surface reconstruction are challenging problems\nwith broad applications in construction, security, marine archaeology, and\nenvironmental monitoring. Treacherous operating conditions, fragile\nsurroundings, and limited navigation control often dictate that submersibles\nrestrict their range of motion and, thus, the baseline over which they can\ncapture measurements. In the context of 3D scene reconstruction, it is\nwell-known that smaller baselines make reconstruction more challenging. Our\nwork develops a physics-based multimodal acoustic-optical neural surface\nreconstruction framework (AONeuS) capable of effectively integrating\nhigh-resolution RGB measurements with low-resolution depth-resolved imaging\nsonar measurements. By fusing these complementary modalities, our framework can\nreconstruct accurate high-resolution 3D surfaces from measurements captured\nover heavily-restricted baselines. Through extensive simulations and in-lab\nexperiments, we demonstrate that AONeuS dramatically outperforms recent\nRGB-only and sonar-only inverse-differentiable-rendering--based surface\nreconstruction methods. A website visualizing the results of our paper is\nlocated at this address: https://aoneus.github.io/",
        "updated": "2024-02-05 18:59:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.03309v1"
    },
    {
        "title": "Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?",
        "authors": "Qiyao LiangZiming LiuIla Fiete",
        "links": "http://arxiv.org/abs/2402.03305v1",
        "entry_id": "http://arxiv.org/abs/2402.03305v1",
        "pdf_url": "http://arxiv.org/pdf/2402.03305v1",
        "summary": "Diffusion models are capable of impressive feats of image generation with\nuncommon juxtapositions such as astronauts riding horses on the moon with\nproperly placed shadows. These outputs indicate the ability to perform\ncompositional generalization, but how do the models do so? We perform\ncontrolled experiments on conditional DDPMs learning to generate 2D spherical\nGaussian bumps centered at specified $x$- and $y$-positions. Our results show\nthat the emergence of semantically meaningful latent representations is key to\nachieving high performance. En route to successful performance over learning,\nthe model traverses three distinct phases of latent representations: (phase A)\nno latent structure, (phase B) a 2D manifold of disordered states, and (phase\nC) a 2D ordered manifold. Corresponding to each of these phases, we identify\nqualitatively different generation behaviors: 1) multiple bumps are generated,\n2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is\ngenerated at the correct $x$ and y location. Furthermore, we show that even\nunder imbalanced datasets where features ($x$- versus $y$-positions) are\nrepresented with skewed frequencies, the learning process for $x$ and $y$ is\ncoupled rather than factorized, demonstrating that simple vanilla-flavored\ndiffusion models cannot learn efficient representations in which localization\nin $x$ and $y$ are factorized into separate 1D tasks. These findings suggest\nthe need for future work to find inductive biases that will push generative\nmodels to discover and exploit factorizable independent structures in their\ninputs, which will be required to vault these models into more data-efficient\nregimes.",
        "updated": "2024-02-05 18:58:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.03305v1"
    },
    {
        "title": "Nevermind: Instruction Override and Moderation in Large Language Models",
        "authors": "Edward Kim",
        "links": "http://arxiv.org/abs/2402.03303v1",
        "entry_id": "http://arxiv.org/abs/2402.03303v1",
        "pdf_url": "http://arxiv.org/pdf/2402.03303v1",
        "summary": "Given the impressive capabilities of recent Large Language Models (LLMs), we\ninvestigate and benchmark the most popular proprietary and different sized open\nsource models on the task of explicit instruction following in conflicting\nsituations, e.g. overrides. These include the ability of the model to override\nthe knowledge within the weights of the model, the ability to override (or\nmoderate) extracted knowledge in the prompt, and lastly the ability to perform\na full jailbreak. Experimentation performed suggest several key findings to\nimprove instruction following - larger models perform the best in following\ninstructions that override internal and contextual instructions, and are\nobedient, even to a fault. When scaling to longer contexts via rope scaling, a\nsignificant buffer needs to be maintained from the edge of the perplexity cliff\nin order to maintain instruction following capabilities. Finally, we observe\nimproving instruction following, and subsequently instruction\noverrides/jailbreaks, is fundamentally at odds with the ability of a language\nmodel to follow given safety filters or guidelines. Thus, we postulate the most\neffective approach for safe, trustworthy AI should be dealt external to the LLM\nitself.",
        "updated": "2024-02-05 18:58:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.03303v1"
    }
]