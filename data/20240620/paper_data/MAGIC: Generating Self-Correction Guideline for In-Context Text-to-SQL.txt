MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL
ArianAskari1∗,ChristianPoelitz2, XinyeTang2
1LeidenUniversity
2Microsoft
1LeidenUniversitya.askari@liacs.leidenuniv.nl
2Microsoft{cpoelitz,xinye.tang}@microsoft.com
Abstract Question: What is the biggest monthly consumption of the
customers who use euro as their currency?
Texto-to-SQL via GPT4 using DIN-SQL method
Self-correction in text-to-SQL is the process
SELECT MAX(SUM(yearmonth.Consumption) / 12) FROM
ofpromptinglargelanguagemodel(LLM)to yearmonth INNER JOIN customers ON yearmonth.CustomerID = Incorrect
reviseitspreviouslyincorrectlygeneratedSQL, customers.CustomerID WHERE customers.Currency = 'EUR' SQL
Self-correction w/ MAGIC’s guideline (Entire response of GPT4)
andcommonlyreliesonmanuallycraftedself-
correction guidelines by human experts that 1.Aggregation within Aggregation: Did I mistakenly try to use an
are not only labor-intensive to produce but a fug ng cr te iog na t (e M f Au Xnc ) t wio in th ( oS uU t M a ) s ud bir qe uc etly ry i ?n s Yid ee s, a thn io st h ise r n oa tg ag lr le og wa et de in SQL. M foi us nta dke
also limited by the human ability in identi- I need to calculate the total consumption per customer first, then
find the maximum of these averages.
fying all potential error patterns in LLM re- 2.Grouping by Customer: Did I forget to group by the customer ID Mistake
after summing their consumption? Yes, to calculate the total found
sponses. WeintroduceMAGIC,anovelmulti- consumption per customer, I need to group by CustomerID.
agentmethodthatautomatesthecreationofthe 3.Correct Calculation of Monthly Consumption: Did I correctly Mistake
calculate the monthly consumption by dividing the total found
self-correctionguideline. MAGICusesthree consumption by 12? Yes, but this calculation should be done after
summing up the consumption for each customer.
specialized agents: a manager, a correction, 4.Filtering on Currency: Did I correctly filter customers based on No
andafeedbackagent. Theseagentscollaborate their currency being 'EUR'? Yes, this part of the query is correct. mistake
5.Selecting the Maximum Monthly Consumption: Did I ensure to
on the failures of an LLM-based method on select the maximum monthly consumption after calculating the
monthly consumption for each customer? This needs to be done in Mistake
the training set to iteratively generate and re- found
a step after calculating the monthly consumption for each
fineaself-correctionguidelinetailoredtoLLM customer.
Revised SQL: SELECT MAX(MonthlyConsumption) FROM
mistakes,mirroringhumanprocessesbutwith- (SELECT yearmonth.CustomerID, SUM(yearmonth.Consumption) /
12 AS MonthlyConsumption FROM yearmonth INNER JOIN
outhumaninvolvement. Ourextensiveexper- customers ON yearmonth.CustomerID = customers.CustomerID Correct
iments show that MAGIC’s guideline outper- WHERE customers.Currency = 'EUR' GROUP BY SQL
yearmonth.CustomerID)
formsexperthuman’screatedones. Weempir-
icallyfindoutthattheguidelineproducedby Figure 1: Example of self-correction using automati-
MAGICenhancetheinterpretabilityofthecor- callygeneratedguidelinesbyMAGIC
rectionsmade,providinginsightsinanalyzing
thereasonbehindthefailuresandsuccessesof
LLMs in self-correction. We make all agent andevenGPT4hasanotableaccuracygapof30%
interactionspubliclyavailabletotheresearch
withinhuman(Lietal.,2023).
community, to foster further research in this
AsolutionforresolvingthemistakesofLLMis
area,offeringasyntheticdatasetforfutureex-
theemergingconceptof‘self-correction’(Madaan
plorationsintoautomaticself-correctionguide-
linegeneration. etal.,2023)thatdefinesastheabilityofLLMsin
revisingtheirpreviousmistakesunderthehypothe-
1 Introduction sisthatrecognizingerrorsiseasierthanavoiding
them(Gouetal.,2024;Madaanetal.,2023). Self-
Converting natural language questions to SQL
correctionincontextoftext-to-SQListheprocess
databasequeries,knownastext-to-SQL,servesasa
of prompting an LLM to revise its previously in-
pivotalcomponentforempoweringnon-expertdata
correctlygeneratedSQL(Zhangetal.,2024;Chen
analystsinextractingdesiredinformationfromre-
etal.,2023).
lationaldatabasesusingnaturallanguage(Quetal.,
Whileself-correctionforLLMshasbeenwidely
2024). Whilelargelanguagemodelshaveshowna
studiedinvarietyoftasksincludingcodegenera-
significantimprovementintext-to-SQLandserve
tion with GPT4 (Shypula et al., 2024; Pan et al.,
as state-of-the methods according to the leader-
2023; Kamoi et al., 2024), it has been relatively
boards(Lietal.,2024b),theyarepronetomistakes
unexploredintext-to-SQL.Thecommonmethod
∗WorkdoneduringaninternshipatMicrosoft. forself-correctinginexistingfew-shotLLMbased
4202
nuJ
81
]LC.sc[
1v29621.6042:viXramethodsthatachievestate-of-the-arteffectiveness MAGIC, a novel multi-agent method, that
isdesigningaself-correctionguidelinebyhuman automates the generation of self-correction
andpromptingittoGPT-4togetherwithitsinitial guideline and outperforms human-written
generated SQL (Pourreza et al., 2023). This self- guideline; yielding to improve effectiveness
correctionguidelinecommonlyengineeredbased ofastrongfew-shotLLMbasedtext-to-SQL
on the train set where an expert human analyzes method.
commonmistakesoftheLLMonthetrainingdata
• Wesystematicallyanalyzetheimpactofours
and design a guideline to prevent common mis-
and existing self-correction methods to per-
takes. Thisprocessisatime-consumingandchal-
formself-correctionacrossdifferentscenarios:
lengingtaskthatislimitedtotheabilityofhumans
Correctingincorrectqueries;non-executable
inidentifyingallthemistakepatternsthatexistin
queries;andallqueries.
the LLM responses (Pourreza et al., 2023; Wang
etal.,2024a;Talaeietal.,2024). • We reproduce all the baselines utilizing the
We propose MAGIC, a novel multi-agent self- sameversionofGPT-4acrossalltheexperi-
correction guideline generation for text-to-SQL, ments,andprovideacomprehensivecompara-
that generates an effective self-correction guide- bleinsightonself-correctionintext-to-SQL.
linethatoutperformshuman-writtenguidelinesand
Wefoundthattherecanbeasignificantgapinterms
yields to improving effectiveness of strong few-
ofeffectivenesswhenutilizingdifferentversionsof
shot LLM based text-to-SQL methods. Similar
GPT-4. Forinstance,ourreplicationofDIN-SQL
tohumanswhoengineertheself-correctionguide-
(Pourrezaetal.,2023)ondevelopmentsetofBIRD
line and apply it to LLMs during inference, with
(Li et al., 2023) achieves 56.52 compared to the
MAGIC,wefirsttackleguidelinegenerationand
originalreportof50.72inthepaper,whichisabout
then utilize the generated guideline during infer-
6pointshigherthanthereportednumber. Thisis
ence. By iterating over the incorrect generated
ourmotivationforreplicatingandreproducingall
SQLsbytheinitialtext-to-SQLmethod,MAGIC
thereportedbaselinesusingsameGPT-4andand
automaticallygeneratestheself-correctionguide-
avoidcopyingnumbersfrompreviouspapers.
line that is tailored to the mistakes of the initial
system. Next, in inference, the self-correction 2 Relatedwork
guidelineofMAGICwillbeintegratedtotheinitial
text-to-SQLmethod,assistingitinpreventingits LLMs for Text-to-SQL. Converting natural lan-
commonmistakes. guagequestionsintoSQLqueries,knownastext-
Unlike previous studies that analyze self- to-SQL,hasbeenanactiveareaofresearchwithin
correctiononasimplemethodthatusesGPT4asits both the natural language processing (NLP) and
backboneoralow-effectiveopen-sourcelanguage database communities for many years (Zelle and
model (Zhang et al., 2024), we employ a strong Mooney, 1996; Guo et al., 2019). Recently, text-
andeffectiveopen-sourcemethodbasedonGPT4, to-SQLhasbenefitedfromthepromisingeffective-
DIN-SQL(Pourrezaetal.,2023),asourinitialtext- ness of Large Language Models (LLMs) (Talaei
to-SQL system aiming to compare our automati- etal.,2024;Pourrezaetal.,2023). Earlymethods
callygeneratedguidelinewithaneffectiveexpert utilizedthezero-shotin-contextlearningcapabili-
human-writtenguideline. Ourexperimentsdemon- tiesofLLMsforSQLgeneration(Rajkumaretal.,
stratethatthegeneratedguidelinebyMAGICleads 2022). Buildingonthis,subsequentmodelshave
toself-explanatoryself-correction,wheretheLLM improvedLLMperformancethroughtaskdecom-
asks itself questions before self-correcting. Fig- positionandtechniquessuchasChain-of-Thought
ure1illustratesanexampleofwheretheMAGIC (CoT) (Wei et al., 2022), including but not lim-
guideline assisted GPT4 to self-correct its previ- itedtomodelslikeDAIL-SQL(Gaoetal.,2023),
ously incorrectly generated SQL. The process is MAC-SQL(Wangetal.,2024a),C3(Dongetal.,
interpretable as the LLM first starts with asking 2023), self-consistency (Wang et al., 2022), and
itselfandthenperformself-correction. least-to-most prompting (Zhou et al., 2023). In
Ourcontributionsareasfollows: addition,therearestudiesfocusingonfine-tuning
LLMsfortext-to-SQL(Lietal.,2024c;Gaoetal.,
• Weestablishthetaskofself-correctionguide- 2023;Lietal.,2024a). WechooseDIN-SQL(Pour-
linegenerationfortext-to-SQL,andintroduce rezaetal.,2023)astheinitialtext-to-SQLsystem1) Input: Question, Few-shot predicted SQL, Ground-truth SQL
Instructing agent
2) Manager Agent 5) Tool: SQL
Executor
3) Feedback Planning 4) Correction
Agent a) Revising agents’ instructions Memory Agent
b) Next agent selection ● Feedbacks
c) Controlling iterations ● Guideline
d) Compiling self-correction guideline ● Interactions
Feedback
Generated self-correction guideline after aggregating 10 feedbacks: 1. Limit Clause Omission - Question: “{question}” - Incorrect
SQL generated by me: {incorrect sql} - Corrected SQL generated by me: {correct sql} - Step-by-step ask-to-myself questions to prevent
the same mistake again: - Did I consider if the question specifies a limit on the number of results? - Have I checked if the results need to
be restricted to meet the question's requirements? ….
Figure2: Illustrationofourproposedmethod,MAGIC.
duetotworeasons: (i)higheffectivenessandavail- dustrycommunitiesforanextendedperiod(Wang
ableopen-sourcecode;(ii)itsself-correctioncom- et al., 2024b), leading to extensive research ex-
ponentisahumanexpertwrittenguidelinebased ploring autonomous agents based on LLMs such
on prior mistakes of the LLM making it a suit- as AutoGPT (Significant Gravitas), OpenAgents
ablebaselineforcomparingtheautomaticallyself- (Xieetal.,2023),andAutoGen(Wuetal.,2023).
correctionguidelinegeneratedbyMAGICwithex- However,therearelimitedstudiesleveragingthis
perthuman-writtenguideline. However,wewould conceptfortext-to-SQL,withMAC-SQLbeingthe
emphasizethatourmethodisindependentofhow only multi-agent method focusing on addressing
thein-contextlearningmethodisdesignedandis the Text-to-SQL task through a new multi-agent
adaptabletotheoutputofanymethod,asweonly collaborativeframework(Wangetal.,2024a). In-
requirethepredictedSQLoftheinitialtext-to-SQL spired by the literature on multi-agent LLMs, in
systemfortacklingself-correctioninMAGIC. MAGIC, we employ a multi-agent collaborative
frameworkthatiterativelyanalyzesthefailuresof
Self-correctionintext-to-SQL.Panetal.(2024)
predicted SQLs by a text-to-SQL method’s and
and (Kamoi et al., 2024) provide an extensive
automaticallygeneratesaself-correctionguideline
overviewofresearchonself-correctioninavariety
tailoredtothemethod’smistakes. Tothebestofour
of domains up to 2024. Here, we focus on self-
knowledge,thereisnopriorworkintheliterature
correctioninText-to-SQL,wheretherehasbeenrel-
thatemploysmulti-agentmethodsfordesigninga
ativelylimitedstudy. Self-debugging(Chenetal.,
self-correction guideline in text-to-SQL or other
2023) generates additional explanations on the
domains.
questionandinitialpredictedSQL,whicharethen
providedtoanLLMforself-correction. DIN-SQL
3 Self-correctionGuidelineGeneration
(Pourreza et al., 2023) designs a human-written
self-correctionguidelineandrevisesalltheinitially
Tasksdefinition. Givenasetofquestionsinnatu-
generatedSQLsaccordingtothisguideline. Self-
rallanguagealongsidethecorrespondingdatabase
consistency is based on generating several candi-
schemaandtheinitiallygeneratedincorrectSQL
datesandemployingavotingprocess,whichhas
queriesbyatext-to-SQLsystem, thetaskofself-
been integrated into Text-to-SQL by DAIL-SQL
correctionguidelinegenerationistogenerateaself-
(Gaoetal.,2023). TherefinercomponentofMAC-
correctionguidelinethatistailoredtotheLLM’s
SQL (Wang et al., 2024a) uses execution errors
mistakesandpreventsitfromrepeatingthem. This
as signals for revising the SQL. To the best of
canbedonebyahumanexpert,anLLM,oracol-
our knowledge, we are the first study to address
laboration between a human expert and an LLM.
self-correctioninText-to-SQLbygeneratingaself-
The typical approach for self-correction involves
correctionguideline.
writingaguidelinefortheLargeLanguageModel
LLM-basedAgents. LLM-basedagentshavebeen manuallybyhumansbasedontheLLM’scommon
apromisingareaofstudyinbothacademicandin- mistakes(Pourrezaetal.,2023;Talaeietal.,2024).
LQS
detcerroC
tnega
gnitcurtsnIThedatausedforguidelinegenerationmustnotbe ofmanagerforrevisingthepredefinedpromptsof
sharedwiththeevaluationdatatopreventoverfit- feedback and correction agents are illustrated in
tingtheguidelinesonthetesterrors. Figures 7 and 8. We found empirically that this
step plays an important role for the manager to
3.1 MAGIC adapt its interactionwith agents. Manager revise
the agent’s instruction based on the previous re-
We tackle the task of generating self-correction
sponseoftheagent,previouspromptthatisused
guidelinefortext-to-SQLsystems,focusingonthe
forinteractingwiththeagent,question,s′,andsgt.
failuresofaninitialmethod,denotedasM,using
thetrainingdataset. AfailureforM occurswhen
Guidelinegeneration. Giveneachsuccessfulrevi-
the predicted SQL is either not executable or its
sionbythecorrectionagent,themanagerstoresthe
execution result differs from that of the ground
correspondingsuccessfulfeedbackthatledtothis
truth SQL, denoted as sgt. In this context, the
initsmemory. Themanagerthenaggregatesthese
predictedSQLthatiseithernotexecutableorhas
stored feedbacks to generate the self-correction
a differing execution result is called an incorrect
guidelinebatch-by-batchusingapredefinedprompt
SQL,denotedass′.
for guideline generation (Figure 9). Each batch
Our method, MAGIC, consists of three agents
consistofk feedbacks. Inourpreliminaryexperi-
illustratedinFigure2: themanager,feedback,and
ments,wedeterminedthatafeedbackbatchsizeof
correctionagents. Theseagentsinteractiteratively
10isoptimal. Inthefirstbatch,themanagerbegins
over the failures to generate the self-correction
withoutanypre-existingguidelineandgeneratean
guideline. We describe this process in detail in
initialguideline. Forsubsequentbatches,theman-
thefollowing.
agerupdatesthealreadygeneratedguideline. This
Feedback-correctioncycle. Giveneachquestion, guidelinegenerationprocessistriggeredattheend
sgt, and s′, the manager agent starts a feedback- ofafeedback-correctioncycleifthemanagerhas
correctioniterationcycle. Ateachiterationofthis accumulatedanewbatchofsuccessfulfeedbacks
cycle,themanagerrequeststhefeedbackagentfor thathasnotyetbeenutilizedforguidelinegener-
anexplanationofthemistakesins′bycomparingit ation. Theself-correctionguidelinegeneratedby
tosgt (steps2to3inFigure2). Next,themanager ourproposedmethod,MAGIC,automaticallyand
agent integrates the feedback received from the fromscratch,ispresentedinFigures11,12,13,14,
feedbackagenttointeractwiththecorrectionagent. 15,and16inappendixsection.
Themanagerrequeststhecorrectionagenttorevise
s′ accordingtotheprovidedfeedback(step3to4 Efficiency. Previous approaches to craft self-
correctionguidelinesneededextensiveexperthu-
in Figure 2). Subsequently, the correction agent
manwork. WithMAGIC,wecanefficientlygen-
generates a new revised SQL. At this stage, the
erate, empirically shown better guideline, in less
manager identifies whether the revised SQL by
than2hour.
thecorrectionagentsuccessfullyleadstoidentical
results with sgt. To do so, the manager uses its
SQLexecutortooltoexecutethecorrectionagent’s
revised SQL (step 5 in Figure 2). The manager 3.2 Agentsaccesstoinformation
endsthiscycleifthestoppingcriteriaaremet. The
stoppingcriteriaareeitherrevisings′ successfully
Althoughthe manageragenthas accessto allthe
bythecorrectionagentorreachingthemaximum
available information during generation of self-
numberofiterations. Weset5asmaximumnumber
correction guideline, the agents has limited ac-
ofiterationinourexperiments.
cess to the information about the task. During
Revising agents’ instruction. In the first itera- theiterations,thecorrectionagentconsistentlyre-
tionofthefeedback-correctioncycle,themanager ceivesonlys′. Thisensuresthatasuccessfulself-
uses two predefined prompts designed for its in- correctioncanindicatethatthefeedbackcouldef-
teractionswiththefeedbackandcorrectionagents, fectivelycoverthemistakesthatexistinthes′. This
as illustrated in Figures 5 and 6 respectively. If isimportantsincethegoalisgeneratingaguideline
thecorrectionagentcannotsuccessfullyrevises′ thatcanpreventfrominitialtext-to-SQLsystemer-
in the first iteration, the manager begins revising rors. Astheresult,theself-correctionagentshould
these predefined prompts. The prompt template focusoncorrectingtheinitialsystemprediction.ScenarioofSelf-CorrectionApplication
CorrectingincorrectSQLs SQLswithExecerror AllSQLs
DIN-SQL
S M C T S M C T S M C T
W/oself-correction 63.14 49.03 38.19 56.52 63.14 49.03 38.19 56.52 63.14 49.03 38.19 56.52
Self-correctionw/oguideline
Self-Debugging (Chen 63.57 50.11 39.67 57.24 63.35 49.03 39.58 56.78 63.03 49.25 38.89 56.58
etal.,2023)
Self-Consistency (Wang 64.56 50.79 40.09 58.08 63.24 49.03 38.19 56.58 64.00 49.68 37.50 57.17
etal.,2022)
Multiple-Prompt (Lee 64.22 50.75 40.02 57.86 63.35 49.03 38.19 56.65 63.68 50.11 39.58 57.30
etal.,2024)
Self-correctionw/guideline
Human Expert G (Wang 63.18 49.19 38.30 56.60 63.20 49.03 38.19 56.58 47.80 46.22 35.30 46.14
etal.,2024a)
Human Expert G (Pour- 64.32 50.32 39.58 57.76 63.58 49.03 38.89 56.98 62.49 48.17 37.50 55.80
rezaetal.,2023)
MAGICG(ours) 65.84 51.61 40.28 59.13 63.69 50.15 39.59 57.32 65.75 49.46 41.67 58.55
Table 1: Effectiveness results in terms of Execution Accuracy (EX) on the DEV set of the BIRD dataset. All
theexperimentshavebeenreproducedbyus. ‘S’,‘M’,‘C’,and‘T’refertodifferentlevelsofdifficulty: Simple,
Medium,Challenging,andTotal,respectively. ThebaselineforNaturalLanguagetoSQLconversionisDIN-SQL
and‘HumanExpertG’referstoself-correctionguideline(prompt)by(Pourrezaetal.,2023)and(Wangetal.,
2024a). ‘MAGICreferstotheguidelinethatisautomaticallygeneratedbyourproposedmethod,MAGIC,usingthe
trainsetofBIRDdataset.
4 Experimentalsetup of multiple valid SQL queries for a single ques-
tion. TheValidEfficiencyScoreevaluatestheef-
Datasets. The Spider (Yu et al., 2018) dataset is ficiency of executing the generated SQL queries,
acollectionof10,181questionsand5,693unique focusingonboththeiraccuracyandexecutiontime,
complex SQL queries across 200 databases in butonlyconsidersqueriesthatproducecorrectre-
138 domains, with each domain featuring multi- sults,i.e.,thosewhoseexecutionoutcomesarecon-
ple tables. It is divided into training, develop- sistentwiththereferencequery. Thisdual-metric
ment, and test sets with 8,659, 1,034, and 2,147 approachprovidesacomprehensiveevaluationof
examples, respectively, across 146, 20, and 34 the model’s ability to generate both accurate and
distinct databases, ensuring no overlap between efficientSQLqueries.
sets. Queriesareclassifiedintofourdifficultylev-
Baselines. We reproduce DIN-SQL using the
elsbasedoncomplexityfactorssuchasSQLkey-
publiclyavailableoriginalimplementation(Pour-
words,nestedsubqueries,anduseofcolumnselec-
reza et al., 2023). For self-correction, we em-
tionsandaggregations. TheBIRDdataset(Lietal.,
ployanextensivesetofbaselinescategorizedinto
2023)comprises12,751uniquequestion-SQLpair-
guideline-dependent and guideline-independent
ingsacross95relativelargedatabases(33.4GB)in
methods. Forguideline-independentmethods,we
37professionaldomainslikeblockchainandhealth-
reproduceself-debugging(Chenetal.,2023)based
care. BIRD introduces external knowledge as an
on the written prompts in the paper. For self-
additional resource for generating accurate SQL
consistency(Wangetal.,2022;Gaoetal.,2023),
queriestobringmorecomplexityintothetask.
we generate 20 SQL queries given the SQL gen-
Metrics. Weemploytwokeymetricsfromexist- erationpromptofDIN-SQLinsteadofgenerating
ingliterature: ExecutionAccuracy(EX)andValid only one SQL and select the final SQL based on
EfficiencyScore(VES).ExecutionAccuracymea- voting. Invoting,weexecuteallSQLqueriesand
suresthecorrectnessofapredictedSQLqueryby selectthemostfrequentlyreturnedresult’sSQL.If
comparing its execution output with that of the oneresultisproducedbyvariousSQLqueries,we
groundtruthSQLquery. ASQLqueryisdeemed select the most efficient one by comparing them
correct if its execution results match those of the againsteachother. FortheMultiple-Promptbase-
ground truth, allowing for a precise assessment line,wefollowtheapproachin(Leeetal.,2024)by
of the model’s performance given the possibility re-orderingcandidatetablesinthepromptandgen-eratingupto20differentcombinations,employing CorrectionMethod EX
avotingmechanismsimilartoourself-consistency
w/oself-correction 78.62
implementation. Forhuman-expertbaselines,we
Self-correctionw/oguideline
utilizetheself-correctionguidelinefromDIN-SQL
Self-Consistency(Wangetal.,2022) 81.64
(Pourrezaetal.,2023),writtenbyhumanexperts, Multiple-Prompt(Leeetal.,2024) 80.22
andtherevisionguidelinefromMAC-SQL(Wang
Self-correctionw/guideline
etal.,2024a),thatisalsowrittenbyhumanexperts
Human’sG(Wangetal.,2024a) 81.15
and are designed specifically for correcting SQL Human’sG(Pourrezaetal.,2023) 80.35
queries with execution errors. However, we also MAGIC’sG(Ours) 85.66
adopttheirapproachforcorrectingincorrectSQL
Table2: Effectivenessresultsforself-correctingincor-
queries and for correcting all initially predicted
rectSQLqueriesontheSPIDERdevelopmentset. We
SQLqueries,regardlessofwhethertheyarecorrect,
compared MAGIC’s generated guideline (MAGIC’s
similar to the scenarios analyzed in (Chen et al.,
G) against two top self-correction baselines: self-
2023)and(Pourrezaetal.,2023)respectively.
consistencyandmultiple-prompt,aswellastwoexpert
humanself-correctionguidelines.
5 Results
Thissectionaddressesthefollowingresearchques- #ofaggregatedbatchoffeedbacks
tions(RQs): 0 1 5 10 39(All)
• RQ1: WhatistheeffectivenessofMAGIC’sself- EX 56.52 57.4 58.8 59.13 59.13
correction guideline compared to the existing
Table3:Impactofnumberofaggregationlevelsoffeed-
state-of-the-art baselines for self-correction in
backsontheeffectivenessofgeneratedself-correction
text-to-SQL, particularly across different error
guidelineonthedevelopmentsetofBIRDdataset.
scenariosanddatasets?
• RQ2: How is the effectiveness of generated
focusingonself-correctionintext-to-SQL(Chen
guidelinesinfluencedbythequantityoffeedback
et al., 2023; Zhang et al., 2024). (ii) SQLs with
-ismorefeedbackalwaysbetter?
executionerrors: thisscenarioiscommoninself-
correctionwherethereisnoavailablecorrectness
• RQ3: Whatistheimpactofmanageragentinter-
oracle, but the goal is to avoid generating incor-
ventiononreducingthenumberofiterationsand
rectandnon-executableSQL(Wangetal.,2024a).
increasingthenumberofcorrectedSQLs?
(iii) All SQLs: this setup is common in methods
Main results (RQ1). Table 1 and 2 present whereself-correctionispartofamulti-stepmodel,
the results of self-correction with the guidelines employingaself-correctionguidelineonallpredic-
generated by MAGIC on the development set of tions(Pourrezaetal.,2023).
BIRD and SPIDER, respectively. Overall, the We find that applying self-correction to all
guidelines generated by our proposed method, predicted SQLs, as in the human-expert writ-
MAGIC,outperformallthebaselinesintermsof ten guideline for self-correction in (Wang et al.,
total effectiveness measured by execution accu- 2024a), reduces effectiveness. Intuitively, when
racyanddemonstratesignificantimprovementsin self-correction is applied for all predicted SQLs,
self-correctionperformanceacrosstheBIRDand thereisariskthattheLLMchangesitspreviously
SPIDER datasets, outperforming self-correction correctpredictiontoanincorrectone,assuggested
guidelineswrittenbyexperthumans. Forexample, by previous work (Li et al., 2024d). Therefore,
MAGIC’sguidelinesimprovetheDIN-SQL(Pour- designingaproperself-correctionguidelineiscru-
rezaetal.,2023)baselinefrom56.52to59.13in cial, or it is safer to apply self-correction where
terms of execution accuracy and outperform the a correctness oracle can identify whether the ini-
self-correctionguidelineof(Wangetal.,2024a)as tialresponseiscorrectornot. Thisoraclecanbe
well,aspresentedinTables5and1respectively. a human user who minimally interacts with the
Weexperimentwithself-correctioninthreesce- systemandonlydetermineswhethertheexecuted
narios,asshowninTable1: (i)correctingincorrect query results meet their expectations. Regarding
SQLs, assuming the availability of a correctness the"SQLswithexecutionerrors"scenario,only46
oracle. This setup is common in recent studies queriespredictedbytheinitialtext-to-SQLsystem(Pourrezaetal.,2023)arenon-executable,which ditional aggregation function column is reported
limitstheeffectivenessofself-correctionforthese alongside the main column name that should be
cases, with several methods achieving the same reported,suchas’SELECTcity,MAX(population)
effectiveness(49.03)formediumquerydifficulty. FROMcities‘wheretheMAX(population)should
notbeincludedinthepredictedqueryaccordingto
Simple medium challenging total thegroundtruth.
400.00
300.00 BIRD Spider
200.00 EX↑ VES↑ AVGi↓ EX↑ AVGi↓
100.00
MAGICmaxi=2
w/omanager 73.01 68.29 1.17 81.40 1.11
0.00
0.00 1.00 2.00 3.00 4.00 w/manager 78.94 80.22 1.12 86.52 1.05
Max number of iterations MAGICmaxi=5
w/omanager 78.60 79.58 2.87 83.28 2.22
a)MAGICw/manager. w/manager 81.81 84.19 2.41 91.78 2.15
Simple medium challenging total
Table4: Theeffectivenessforgeneratingfeedbackson
400.00
the train set of BIRD dataset. The max and AVG
i i
300.00 referstothemaximumnumberofiterationsandaver-
200.00 agenumberofiterationstillstoppingcriteriatriggers
respectively.
100.00
0.00
0.00 1.00 2.00 3.00 4.00 Feedback generation effectiveness (RQ3). Fig-
Max number of iterations ure 3 presents an analysis of the number of cor-
rectedSQLquerieswithandwithouttheinclusion
b)MAGICw/omanager. of the manager agent, by evaluating the perfor-
manceoftheMAGICframeworkacrossarangeof
Figure 3: Analyzing impact of maximum number of
maximumiterationcountsusedasstoppingcriteria,
iterationsonthetotalnumberofcorrectedSQLs,that
from one to five. When the manager agent is ex-
wereinitiallyincorrect,withandwithoutmanagerbeing
involvedinMAGIC.Theanalysisisconductedonthe cluded,thefeedbackagentcontrolsthemaximum
trainsetoftheBIRDdataset. iterationcountandutilizestheSQLexecutortool
tocomparetheexecutionresultsoftherevisedSQL
It is noteworthy that although we have not withthegroundtruthSQL.Thiscomparisonunder-
attempted to combine MAGIC with other base- scoresthesignificantroleofthemanageragentin
lines, as our focus is on analyzing different self- correctingalargernumberofincorrectSQLqueries
correction methods rather than integrating them, within fewer iterations and ultimately correcting
somebaselinescouldpotentiallyenhanceMAGIC moreSQLquerieswhenbothsetupsreachthemax-
ifcombined,suchasSelf-consistency(Wangetal., imumoffiveiterations. Itisimportanttonotethat
2022)andMultiple-Prompt(Leeetal.,2024). excludingthemanageragentfromMAGICisequiv-
Impact of Feedback Quantity (RQ2). Table 3 alenttothecritic-refinecyclemethod(Kamoietal.,
presentstheresultsofthegeneratedself-correction 2024),thathasbeenemployedinothertasks,such
guideline effectiveness by MAGIC, where differ- ascodegeneration. However,unlikeMAGIC,the
entnumbersofbatchesoffeedbackareaggregated critic-refine(Kamoietal.,2024)doesnotproduce
for generating the guideline. We found that after anyguidelinesasaresultofitsfeedbackgeneration
aggregating 10 batches of feedback, each batch process and has not been applied to text-to-SQL
consistof10feedbacks,thegeneratedguidelineby taskstothebestofourknowledge.
MAGICoutperformsexistingself-correctionbase- Wefurtheranalyzetheimpactofmanageragent
lines, including those with guidelines written by intermsofoverallperformanceofself-correction
humans. This shows the efficiency of process of consideringallthequeries. Table4measuresthe
MAGIC for self-correction guideline generation. effectivenessofMAGICintermsofexecutionac-
Furthermore, we found that questions for which curacy(EX)todeterminehowmanycouldbead-
MAGIC cannot provide feedback to self-correct dressedcorrectlyintotalwiththealreadycorrected
areoftencontroversial. Forexample,whenanad- predictionsbyLLMandself-correctedoneswith
sLQS
detcerroC
sLQS
detcerroCMethod EX 2023) as shown in Table 5. As we can observe,
MAGIC’sguidelinesimprovethezero-shotGPT-4
Zero-shotGPT-4(OpenAI,2023b) 40.18
Zero-shotGPT-4+MAGICG(Ours) 48.19 baselinefrom40.18to48.19andfew-shotGPT-4
Few-shotGPT-4(Lietal.,2023) 45.66 from45.56to50.38intermsofexecutionaccuracy,
Few-shotGPT-4(Lietal.,2023)+MAGICG(Ours) 50.38 respectively.
DIN-SQL(Pourrezaetal.,2023) 56.52 Source of examples in guideline. We analyzed
DIN-SQL(Pourrezaetal.,2023)+MAGICG(Ours) 59.13
the relationship between the generated guideline
and the feedback that contributed to its creation.
Table5: Theeffectivenessofself-correctionguideline
generated by our proposed method, MAGIC, across Specifically,weexaminedwhetheranyexamples
differentmethods. in the guideline directly mirrored instances from
the feedback or outputs of the correction agent.
W/ correction W/o correction Ourfindingsindicatethatnoexamplewasdirectly
80
copiedfromthefeedbacktobeusedintheguide-
60 line. Instead, our empirical observations reveal
thatthemanageragenttendstoaggregatemultiple
40
piecesoffeedbacktoconstructnewexamplesinto
20 theself-correctionguideline.
0 Database analysis. Figure 4 illustrates the im-
Stud Club Calif Schools Formula 1 Card Games Code Community
pactoftheself-correctionguidelinesgeneratedby
Database
MAGIC across different databases in the devel-
Figure 4: Analyzing impact of MAGIC’s correction
opment set of the BIRD dataset. We found that
guidelineacrossdifferentdatabasesofdevelopmentset
ofBIRDdataset. whileself-correctionimproveseffectivenessacross
all databases, some databases benefit more from
MAGIC’sguidelines. Thisvariabilitycouldbedue
MAGIC.WealsomeasureValidEfficiencyScore
tothecapabilityoftheLLM,thedifferinglevelsof
(VES)todeterminewhethertheself-correctionby
challenginginformationinthedatabases,orother
MAGICresultsinoptimizedSQLscomparedtothe
factors. Thisobservationcouldmotivatethedevel-
groundtruth. Asitcanbeobserved,MAGICwith
opmentofguidelinesthatareadaptedtodifficulty
the manager agent outperforms the exclusion of
ofdatabaseinthefuture.
manageragentinallsetupsintermsofallmetrics
across the BIRD and SPIDER datasets. Results 7 Conclusions
show that MAGIC with manager agent is able to
This paper presents a new perspective on self-
generatemoreefficientSQLscomparedtoexclu-
correction in in-context learning for text-to-SQL
sion of manager agent, e.g., 84.19 vs. 79.58 in
translation. Itproposesanovelmethodforgenerat-
terms of VES for w/ manager and w/o manager
ingself-correctionguidelines,calledMAGIC.The
ontheBIRDdatasetwherethemaximumnumebr
motivationbehindthisapproachistoovercomethe
ofiterationissetto5. Wemanuallyanalyzedthe
limitationsofexistingmethodsthatgenerateself-
revised prompt by manager agent and found out
correctionguidelinesbyhand,atime-consuming
duringitsinteractionswiththeagentswhereitre-
task. Additionally,itaddressestheimportantand
vises the prompts, the manager agent tends add
costlytaskofautomaticallyfixingincorrectSQL
instructionsforself-correctiontooptimizetheeffi-
generated by humans. This work showcases the
ciencyofSQL,whichmightbethereasonbehind
potentialofleveragingLLMstogeneratetheirown
generatingmoreefficientSQLs.
self-correction guidelines and highlights the sig-
6 Discussion nificance of guideline generation in text-to-SQL.
We emphasize the importance of improving self-
Applicabilitytoothermethods. Weanalyzethe correctionmethodsintext-to-SQLandaddressing
applicabilityoftheguidelinegeneratedbyMAGIC themasaseparatetask. Thefindingsofthisstudy
basedonthemistakesoftheDIN-SQL(Pourreza contributetoadvancingthestate-of-the-artintext-
et al., 2023) method on two other methods that to-SQLtranslation,asourmethodcanbeapplied
generate SQL in a single step: zero-shot GPT-4 to fix issues in any method and provide valuable
(OpenAI, 2023a) and few-shot GPT-4 (Li et al., insightsforfutureresearchinthisdomain.
ycarucca
XE8 Limitations Ryo Kamoi, Yusen Zhang, Nan Zhang, Jiawei Han,
andRuiZhang.2024. Whencanllmsactuallycor-
Inthispaper,wehavedemonstratedthatgenerative rect their own mistakes? a critical survey of self-
LLMs are capable of generating their own self- correctionofllms. arXivpreprintarXiv:2406.01297.
correction guidelines even more effectively than
Dongjun Lee, Choongwon Park, Jaehyuk Kim, and
exsiting guidelines written by human experts in
HeesooPark.2024. Mcs-sql: Leveragingmultiple
previousstudies. However,itisimportanttohigh- promptsandmultiple-choiceselectionfortext-to-sql
light that such training data might not be avail- generation. arXivpreprintarXiv:2405.07467.
ableforthenewquerylanguages. Moreover,while
Haoyang Li, Jing Zhang, Hanbing Liu, Ju Fan, Xi-
ourexperimentsillustratethesuperioreffectiveness
aokangZhang,JunZhu,RenjieWei,HongyanPan,
ofourself-correctionguidelinesincomparisonto
CuipingLi,andHongChen.2024a. Codes: Towards
those developed by human experts, we have not buildingopen-sourcelanguagemodelsfortext-to-sql.
conducted a systematic study to quantify the po- arXivpreprintarXiv:2402.16347.
tentialgenerationofhallucinateddataduringthis
JinyangLi,BinyuanHui,GeQu,JiaxiYang,BinhuaLi,
process and its subsequent impact on the perfor-
BowenLi,BailinWang,BowenQin,RongyuCao,
manceoftheautomaticallygeneratedguidelines. Ruiying Geng, Nan Huo, Xuanhe Zhou, Chenhao
Additionally, despite the high effectiveness of Ma, Guoliang Li, Kevin C. C. Chang, Fei Huang,
the generated guidelines, we wish to underscore Reynold Cheng, and Yongbin Li. 2024b. Bird-sql
leaderboard.
thatforlargebusinesses,itmaystillbeneededto
havehumansreviewtheseguidelines. Nevertheless,
JinyangLi,BinyuanHui,GEQU,JiaxiYang,Binhua
giventhatthegeneratedguidelinestendnottobe Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying
overlylengthyandcanbegeneratedunder2hours Geng,NanHuo,XuanheZhou,ChenhaoMa,Guo-
liangLi,KevinChang,FeiHuang,ReynoldCheng,
(presented in Figure 11 to Figure 16 in appendix
and Yongbin Li. 2023. Can LLMalready serve as
section),webelievethattheeffortrequiredforre-
a database interface? a BIg bench for large-scale
viewing the content of these guidelines is signifi- databasegroundedtext-to-SQLs. InThirty-seventh
cantlymoreefficientthanmanuallyanalyzingall ConferenceonNeuralInformationProcessingSys-
temsDatasetsandBenchmarksTrack.
oftheLLM’serrorsanddevelopingself-correction
guidelinesfromscratch.
JinyangLi, BinyuanHui, GeQu, JiaxiYang, Binhua
Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying
Geng,NanHuo,etal.2024c. Canllmalreadyserve
References asadatabaseinterface? abigbenchforlarge-scale
databasegroundedtext-to-sqls. AdvancesinNeural
Xinyun Chen, Maxwell Lin, Nathanael Schärli, and
InformationProcessingSystems,36.
DennyZhou.2023. Teachinglargelanguagemodels
toself-debug. arXivpreprintarXiv:2304.05128.
Loka Li, Guangyi Chen, Yusheng Su, Zhenhao
Chen, Yixuan Zhang, Eric Xing, and Kun Zhang.
XuemeiDong, ChaoZhang, YuhangGe, YurenMao,
2024d. Confidence matters: Revisiting intrinsic
YunjunGao,JinshuLin,DongfangLou,etal.2023.
self-correction capabilities of large language mod-
C3: Zero-shot text-to-sql with chatgpt. arXiv
els. CoRR,abs/2402.12563.
preprintarXiv:2307.07306.
AmanMadaan, NiketTandon,PrakharGupta,Skyler
Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun,
Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,
Yichen Qian, Bolin Ding, and Jingren Zhou. 2023.
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
Text-to-sql empowered by large language mod-
et al. 2023. Self-refine: Iterative refinement with
els: A benchmark evaluation. arXiv preprint
self-feedback. AdvancesinNeuralInformationPro-
arXiv:2308.15363.
cessingSystems.
ZhibinGou,ZhihongShao,YeyunGong,yelongshen,
Yujiu Yang, Nan Duan, and Weizhu Chen. 2024. OpenAI.2023a. Gpt-4technicalreport.
CRITIC: Large language models can self-correct
withtool-interactivecritiquing. InTheTwelfthInter- R OpenAI. 2023b. Gpt-4 technical report. arxiv
nationalConferenceonLearningRepresentations. 2303.08774. ViewinArticle,2(5).
Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian- Liangming Pan, Michael Saxon, Wenda Xu, Deepak
GuangLou,TingLiu,andDongmeiZhang.2019. To- Nathani,XinyiWang,andWilliamYangWang.2023.
wardscomplextext-to-sqlincross-domaindatabase Automaticallycorrectinglargelanguagemodels:Sur-
with intermediate representation. arXiv preprint veyingthelandscapeofdiverseself-correctionstrate-
arXiv:1905.08205. gies. arXivpreprintarXiv:2308.03188.Liangming Pan, Michael Saxon, Wenda Xu, Deepak Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,
Nathani,XinyiWang,andWilliamYangWang.2024. Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,
Automaticallycorrectinglargelanguagemodels:Sur- Xiaoyun Zhang, and Chi Wang. 2023. Auto-
veyingthelandscapeofdiverseautomatedcorrection gen: Enabling next-gen llm applications via multi-
strategies. TransactionsoftheAssociationforCom- agent conversation framework. arXiv preprint
putationalLinguistics,11:484–506. arXiv:2308.08155.
MohammadrezaPourreza,,andDavoodRafiei.2023. TianbaoXie,FanZhou,ZhoujunCheng,PengShi,Lu-
Din-sql: Decomposed in-context learning of text- oxuanWeng,YitaoLiu,TohJingHua,JunningZhao,
to-sql with self-correction. In Advances in Neural Qian Liu, Che Liu, et al. 2023. Openagents: An
InformationProcessingSystems,volume36,pages openplatformforlanguageagentsinthewild. arXiv
36339–36348.CurranAssociates,Inc.
preprintarXiv:2310.10634.
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,
GeQu,JinyangLi,BowenLi,BowenQin,NanHuo,
DongxuWang,ZifanLi,JamesMa,IreneLi,Qingn-
Chenhao Ma, and Reynold Cheng. 2024. Before
ingYao,ShanelleRoman,ZilinZhang,andDragomir
generation, align it! a novel and effective strategy
Radev.2018. Spider: Alarge-scalehuman-labeled
formitigatinghallucinationsintext-to-sqlgeneration.
datasetforcomplexandcross-domainsemanticpars-
arXivpreprintarXiv:2405.15307.
ingandtext-to-SQLtask. InProceedingsofthe2018
Conference on Empirical Methods in Natural Lan-
Nitarshan Rajkumar, Raymond Li, and Dzmitry Bah-
guageProcessing,pages3911–3921,Brussels,Bel-
danau. 2022. Evaluating the text-to-sql capabil-
gium.AssociationforComputationalLinguistics.
ities of large language models. arXiv preprint
arXiv:2204.00498. JohnMZelleandRaymondJMooney.1996. Learning
toparsedatabasequeriesusinginductivelogicpro-
Alexander G Shypula, Aman Madaan, Yimeng Zeng, gramming. InProceedingsofthenationalconference
Uri Alon, Jacob R. Gardner, Yiming Yang, Mi- onartificialintelligence,pages1050–1055.
lad Hashemi, Graham Neubig, Parthasarathy Ran-
ganathan,OsbertBastani,andAmirYazdanbakhsh. Bin Zhang, Yuxiao Ye, Guoqing Du, Xiaoru Hu,
2024. Learningperformance-improvingcodeedits. Zhishuai Li, Sun Yang, Chi Harold Liu, Rui Zhao,
InTheTwelfthInternationalConferenceonLearning Ziyue Li, and Hangyu Mao. 2024. Benchmark-
Representations. ingthetext-to-sqlcapabilityoflargelanguagemod-
els: A comprehensive evaluation. arXiv preprint
SignificantGravitas. AutoGPT. arXiv:2403.02951.
Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,
Shayan Talaei, Mohammadreza Pourreza, Yu-Chen
Nathan Scales, Xuezhi Wang, Dale Schuurmans,
Chang,AzaliaMirhoseini,andAminSaberi.2024.
ClaireCui,OlivierBousquet,QuocVLe,etal.2023.
Chess: Contextualharnessingforefficientsqlsynthe-
Least-to-mostpromptingenablescomplexreasoning
sis.
inlargelanguagemodels. InTheEleventhInterna-
tionalConferenceonLearningRepresentations.
BingWang,ChangyuRen,JianYang,XinnianLiang,Ji-
aqiBai,LinzhengChai,ZhaoYan,Qian-WenZhang,
DiYin,XingSun,andZhoujunLi.2024a. Mac-sql:
A multi-agent collaborative framework for text-to-
sql.
LeiWang,ChenMa,XueyangFeng,ZeyuZhang,Hao
Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,
XuChen,YankaiLin,etal.2024b. Asurveyonlarge
languagemodelbasedautonomousagents. Frontiers
ofComputerScience,18(6):186345.
XuezhiWang,JasonWei,DaleSchuurmans,QuocVLe,
EdHChi, SharanNarang, AakankshaChowdhery,
andDennyZhou.2022. Self-consistencyimproves
chainofthoughtreasoninginlanguagemodels. In
TheEleventhInternationalConferenceonLearning
Representations.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
etal.2022. Chain-of-thoughtpromptingelicitsrea-
soninginlargelanguagemodels. AdvancesinNeural
InformationProcessingSystems,35:24824–24837.9 Appendix
9.1 Prompts
Thepromptsthatareusedareasfollow:
• Thepromptforthepredefinedinteractionof
manager agent with feedback agent can be
seeninFigure5,andthepromptwiththatthe
manageragentrevisesitspreviouspredefined
promptcanbeseeninFigure7.
• Thepromptforthepredefinedinteractionof
manager agent with feedback agent can be
Systemroleprompt:
seeninFigure6,andthepromptwiththatthe
Your task is to correct the predicted SQL
manageragentrevisesitspreviouspredefined
based on the provided feedback by expert
promptcanbeseeninFigure8.
human.
• Thepromptformanageragenttogeneratethe
self-correctionguidelinecanbeseeninFigure 1. Input Information: You will receive
9. a question, a database schema, a predicted
SQLquery,andahumanfeedback.
Furthermore, an example of last iteration of our
proposedmethod,MAGIC,onaquestionofBIRD
2. SQLformatinyourresponse:
dataset,thatledtoasuccessfulself-correctioncan
-Youmustensurethatyourresponsecontains
beseeninFigure10.
avalidSQL.
-TheformatofSQLinyourresponsemustbe
Systemroleprompt:
inthefollowingformat: “‘sqlSQL“‘.
Complete the text in chat style like a
database manager expert. Write in simple
Userroleprompt:
present without using correct SQL. Accept
whattheuseridentifiesascorrectorincorrect.
-SchemaOverview: {schema}
-ColumnsDescription: columnsDescription
Userroleprompt:
-Question: {question}
"question": "{question}",
- Predicted SQL: “‘sql {Incorrect SQL}
"evidence": "{evidence}",
“‘
"CorrectSQL": "{CorrectSQL}",
-ExpertHumanFeedback: {feedback}
"IncorrectSQL": "{IncorrectSQL}",
Figure 6: The predefined prompt for interaction of
IncorrectSQLmistakesare:
magicagentwithcorrectionagent.
Figure 5: The predefined prompt for interaction of
magicagentwithfeedbackagent.Systemroleprompt:
You are a helpful AI assistant that manages
otherassistants.
Systemroleprompt
You are a helpful AI assistant that manages Userroleprompt:
otherassistants. Manager,pleasereviewthefollowingprompt
forthefollowingagentandgeneratearevised
prompt.
Userroleprompt So far you have revised the prompt for
Manager,pleasereviewthefollowingprompt {iteration_number}times.
forthefollowingagentandgeneratearevised Agent description: This agent generates
prompt. correctionsforSQLqueriesbasedonexpert
So far you have revised the prompt for humanfeedback.
{iteration_number}times. Previousoutputofagentthatwasnotuseful:
Agent description: This agent generates {agent_outputs[-1]}
feedback based on the comparison between Previous prompt of agent that you should
predictedandgroundtruthSQLqueries. revise: {agent_prompts[-1]}
Previousoutputofagentthatwasnotuseful:
{agent_outputs[-1]} ####
Previous prompt of agent that you should The ideal output of agent should be the
revise: {agent_prompts[-1]} following but we cannot directly give the
idealoutputtotheagent:
Reviseprompt(Returntheentirepromptsoit Idealoutputofagent: {CorrectSQL}
canbedirectlypasstotheagent): ####
Figure7: Theprompttemplateofmanagerforrevising Reviseprompt(Returntheentirepromptsoit
thepredefinedpromptsoffeedbackagent. canbedirectlypasstotheagent):
Figure8: Theprompttemplateofmanagerforrevising
thepredefinedpromptsofcorrectionagent.#Guidelineformat:
number. Reminderofmistake
-Question: "Question"
- Incorrect SQL generated by me: “‘sql
incorrectsql“‘
- Corrected SQL generated by me: “‘sql
correctedsql“‘
- Negative and strict step-by-step ask-to-
myself questions to prevent same mistake
again:
#Guidelinesofar:
{current_guideline} // current guideline
variableisemptyatfirst
# Recent mistakes that must be aggre-
gatetoGuideline:
{batch_of_successful_feedbacks}
# Updated Guideline (Return the entire
ofguideline):
Figure 9: The prompt of manager for self-correction
guidelinegeneration.Figure10: Illustrationoflastiterationofourproposedmethod,MAGIC,onaquestionofBIRDdataset,thatledtoa
successfulself-correction.
d e L s Q i v S e R ?1991 raey eht fo rebotcO eht rof yrotarobal eht ni denimaxe
stneitap
fo
ega
egareva
eht si tahW :noitseuQ :tupnI )1
'03-01-1991' DNA '10-01-1991'
NEEWTEB
etaD
ot srefer 1991 fo rebotcO .)))yadhtriB(raey ,'9991'(TCARTBUS(GVA ot srefer
sihT
.9991
fo
flah
tsrif
rof
ega egarevA :ecnedivE
tcerrocnI
'13-01-1991' DNA '10-01-1991' NEEWTEB etaD EREHW DI.yrotarobaL
=
DI.tneitaP
NO yrotarobaL NIOJ RENNI tneitaP MORF ))REGETNI SA )yadhtriB ,'Y%'(emitfrts(TSAC
- 1991(GVA
TCELES :LQS detciderp tohs-weF laitinI
LQS '03-01-1991' DNA '10-01-1991' NEEWTEB etaD.1T EREHW
DI.2T
=
DI.1T
NO 2T SA tneitaP NIOJ RENNI 1T SA yrotarobaL MORF ))yadhtriB.2T ,'Y%'(EMITFRTS
- '9991'(GVA
TCELES :LQS hturt dnuorG
tnegA noitcerroC )4
gnitcurtsnI
LQS :looT )5 tnegA reganaM )2
gnitcurtsnI
tnegA kcabdeeF )3
tnega
rotucexE
tnega
:tnega noitcerroc ot reganam fo noitcurtsni cimanyD 1.4
gninnalP
:tnega kcabdeef ot reganam fo noitcurtsni cimanyD .1.3
.… a nevig eb lliw uoY :**noitamrofnI tupnI** .1
yromeM snoitcurtsni ’stnega gnisiveR )1
eht etaluclac oT }noitseuq{ :"noitseuq" .txet eht etelpmoC
:noitamrofnI dedivorP ####
skcabdeeF ● noitceles tnega txeN )2
- 9991(GVA esu ,9991 fo flah tsrif eht rof ega egareva
}weivrevO amehcS{ :**weivrevO amehcS** -
enilediuG ● snoitareti gnillortnoC )3
.))yadhtriB ,'\\Y%'\\(EMITFRTS
}noitseuQ{ :**noitseuQ** -
snoitcaretnI ● enilediug noitcerroc-fles gnilipmoC )4
'10-01-1991' morf si egnar etad tnaveler eht ,1991 rebotcO roF
kcabdeeF
}LQS detciderP{ :**LQS detciderP** -
.ts13 eht gnidulcxe ,'03-01-1991' ot
:**kcabdeeF namuH trepxE** -
}LQS hturt-dnuorG{ :"LQS tcerroC"
:srorre lareves sniatnoc yreuq LQS dedivorp ehT
}LQS tcerrocnI{ :"LQS tcerrocnI"
.ts13 rebotcO sedulcni yltcerrocni yreuq ehT :**rorrE egnaR etaD** .1
.tnemetats LQS tcerrocni dedivorp eht ni sekatsim eht yfitnedI
.etad siht edulcxe dluohs egnar etad tcerroc ehT
01 gnitagergga retfa enilediug noitcerroc-fles detareneG .6
ti fi sa ega setaluclac yletaruccani yreuq ehT :**noitaluclaC egA** .2
:skcabdeef
eg
.a n o ,r g k io tc snf a ei9 s bn u9 u di q9 y h e 1 ec c e hnr a fa te o t e r st r esy rp epi pse wxn ah e so t t n c n de a e ns s t au k ys c l .i n ed s da o tnl el au io d ty ro a uc nrh me ceAs u cm r q aon .s m fo e tl nl ai a ot h i a hc c dTl t eu e n y: rc d* o r*l s i ea i vy t i uc c oc ` qn n ) rt y p uc e La e ft e Q s dr d hr i h Snso tt n a c r n dio B os ee C e th d, c p 'T d Y e ey n s r%. t r1 . a a on a '9 B( co x t E9 a ai : at1 Md ka t n s enl Igl y T ai ti nt am S Ts Fi r l * Rr d # ee *e n # n r Tt .e e a # e3 Sw d h # g `
oe t Lm d Qa ee Ss t h c: e e it tL r cm h tnQ est o e rS y t rn rtb o it e m e c cd v be nie e l r I o tr ar -ao p t r sc d ”e o en }en nt iI ef e os i- c ng n i te ” so sL p} ei tn Q t s l us uo S e qn sit u { eos d “q re i te :s u e nft elcq h oe ue{ t is t “ qr sfy r i: e o mn e d uCo h e- ? Qoi t kt s-s t f c - ti -}e nek l r :qu s ee h nsQ a md c o it i p Is e tc- i ne e dre in ot v nur sro ac oqo -i Hy Ces c I b rs n d - g-i si im p{ D ? n' ne: s iO e rot - t eS m l iu te t: s ln s- is Fy e eiu ab u} r ta l g q q cd fl a o eC s e e r et rt h rt a c e oi k tm er b cae tr m e ni trnL so e Ie u i. c m m .1 g n 2{
s s eae e g sv d e aL ia u g rQ hh l enc c S vns a iha t i r tn w hc .e ee 2e c t hm , air 1.h tr td e 9so w s 1t 9c e ea 3n 1, h tt ' a1 is t r m le 3 e usL h - obe cQ 0T l roi a1 f fS i t c: c- c y * 1 e t O a* Lc 9 pr dQe o 9 s g hr r 1 S nr r teo r'E i ic d toc b cn uen t e ee lgi ' c r1 hde n rx0 o tih a e v- c fT R 0 e on,1 ' 0 ie re -: ae3h1k t ea h-t9c 0 yD T,9a r 1 e* 1 eb :-* rv' 1 hd oe. e 9 te 1 r g w 9 r ge En: 1 nof s a ' iHe rd tr o a ck e at ee .a tt Y r't sa t 1a ts 1 b r 0 edie 3 um - c n 0 e snr 1 e l h ea ye-G t b br r1 e s eo 9 e. ev ft2 9 ec ge s. O 1 R3 u as '
LQS tcerroC :LQS desiver detareneG .2.4
emas : e em ht y tnb e d ve et ra pr e on t e sg n oL iQ tsS eu d qe ft lc ee sr yro mC -o - t -} klq ss a t pc ee tr sro -yc bn -i p{ e:e tSm - y b }l qd se t ta cere rrn oe cg {
.3 . ed he td niv i o dr ep t ae cc in lpe ud div se i e tnh et mro e L taQ tsS L t Qce Sr r to cc e re rh ot c nh it i ew h t Tn e :nts oi is tan co ic lp t uo Dn
SA ))REGETNI SA )yadhtriB ,'Y%'(emitfrts(TSAC - 9991(GVA TCELES
tcerroc eht deilppa dna deifitnedi yletarucca I evaH - :niaga ekatsim
lacitcatnys ro lacigol a ylirassecen ton si hcihw ,txet dedivorp
= DI.tneitaP NO yrotarobaL NIOJ RENNI tneitaP MORF egAegarevA
eht yfirev I diD - ?stnemeriuqer s'noitseuq eht no desab snoitidnoc gniretlif
… tub LQS ni rorre
'13-01-1991' < etaD DNA '10-01-1991' => etaD EREHW DI.yrotarobaL
dednetni eht htiw ngila yeht erusne ot snoitidnoc dna srotarepo lacigol … ?cigol yreuqSQL Query Correction Guidelines
This document serves as a guideline for correcting SQL queries based on specific feedback. It
aims to help in identifying common mistakes and providing a structured approach to rectify them,
ensuring the queries accurately fulfill the requirements.
Guideline Format:
[number]. [Reminder of Mistake]
Question: "Question"
Incorrect SQL generated by me: Incorrect SQL
Corrected SQL generated by me: sql Corrected SQL
Negative and strict step-by-step ask-to-myself questions to prevent the same mistake
again:
Recent Mistakes and Corrections:
1. Limit Clause Omission
Question: "Name movie titles released in year 1945. Sort the listing by the
descending order of movie popularity."
Incorrect SQL generated by me: SELECT movie_title FROM movies WHERE
movie_release_year = 1945 ORDER BY movie_popularity DESC;
Corrected SQL generated by me: sql SELECT movie_title FROM movies WHERE
movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1;
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I consider if the question specifies a limit on the number of results?
Have I checked if the results need to be restricted to meet the question's
requirements?
2. Incorrect Filtering Condition
Question: "Find the professor ID and position in faculty who taught high-level
undergraduate course of less than 10 in ID."
Incorrect SQL generated by me: SELECT person.p_id, person.hasPosition
FROM person INNER JOIN taughtBy ON person.p_id = taughtBy.p_id INNER
JOIN course ON taughtBy.course_id = course.course_id WHERE
course.courseLevel = 'Level_400' AND course.course_id < 10 AND
person.professor = 0
Corrected SQL generated by me: sql SELECT p.p_id, p.hasPosition FROM
person p INNER JOIN taughtBy tb ON p.p_id = tb.p_id INNER JOIN course
c ON tb.course_id = c.course_id WHERE c.courseLevel = 'Level_400' AND
c.course_id < 10 AND p.professor = 1
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Have I accurately identified and applied the correct filtering conditions based
on the question's requirements?
Did I verify the logical operators and conditions to ensure they align with the
intended query logic?
Figure11: Self-correctionguidelinethatisgeneratedbyourmethod,MAGIC,automatically. Page1.3. Misinterpretation of Requirements
Question: "Among the faculty affiliated professor, how many professors teaches
professional or master/undergraduate courses?"
Incorrect SQL generated by me: SELECT COUNT(DISTINCT T1.p_id) FROM
person AS T1 INNER JOIN taughtBy AS T2 ON T1.p_id = T2.p_id INNER JOIN
course AS T3 ON T2.course_id = T3.course_id WHERE T1.professor = 0 AND
T1.hasPosition = 'Faculty' AND T3.courseLevel = 'Level_500'
Corrected SQL generated by me: sql SELECT COUNT(DISTINCT T1.p_id) FROM
person AS T1 INNER JOIN taughtBy AS T2 ON T1.p_id = T2.p_id INNER JOIN
course AS T3 ON T2.course_id = T3.course_id WHERE T1.professor = 1 AND
T1.hasPosition = 'Faculty_aff' AND T3.courseLevel = 'Level_500'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I fully understand the question's requirements before writing the query?
Have I ensured that all conditions and filters accurately reflect the question's
intent?
4. Incorrect Aggregation and Calculation
Question: "What is the average number of professional or master/undergraduate
courses being taught by each professor?"
Incorrect SQL generated by me: SELECT COUNT(DISTINCT taughtBy.course_id)
/ COUNT(DISTINCT taughtBy.p_id) AS average_courses_per_professor FROM
taughtBy INNER JOIN course ON taughtBy.course_id = course.course_id
WHERE course.courseLevel = 'Level_500'
Corrected SQL generated by me: sql SELECT AVG(course_count) AS
average_courses_per_professor FROM (SELECT COUNT(*) AS course_count
FROM taughtBy INNER JOIN course ON taughtBy.course_id =
course.course_id WHERE course.courseLevel = 'Level_500' GROUP BY
taughtBy.p_id) AS subquery
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Have I used the correct aggregation functions to calculate averages or totals as
required by the question?
Did I consider using subqueries for complex calculations to ensure accuracy?
5. Counting Specific Column vs. All Rows
Question: "How many male users are in the age group of M32-38?"
Incorrect SQL generated by me: SELECT COUNT(*) FROM gender_age WHERE
gender = 'M' AND group = 'M32-38'
Corrected SQL generated by me: sql SELECT COUNT(gender) FROM gender_age
WHERE gender = 'M' AND `group` = 'M32-38'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I use COUNT(*) when I should have specified the column I was interested
in counting?
Have I ensured to use backticks around reserved keywords when they are used
as column names?
6. Directly Targeting the Youngest Age
Question: "What is the gender of the youngest user?"
Figure12: Self-correctionguidelinethatisgeneratedbyourmethod,MAGIC,automatically. Page2.Incorrect SQL generated by me: SELECT gender FROM gender_age ORDER BY
age ASC LIMIT 1
Corrected SQL generated by me: sql SELECT gender FROM gender_age WHERE
age = (SELECT MIN(age) FROM gender_age)
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I consider the most efficient way to directly target the desired value?
Have I evaluated if using a subquery could provide a more accurate and
efficient solution?
7. Ordering and Limiting for Maximum Value Retrieval
Question: "What is the age of the oldest active user that participated in the event held
on 5/6/2016 at coordinates 121, 31?"
Incorrect SQL generated by me: SELECT MAX(gender_age.age) FROM
gender_age INNER JOIN events ON gender_age.device_id =
events.device_id INNER JOIN app_events ON events.event_id =
app_events.event_id WHERE app_events.is_active = 1 AND
events.timestamp LIKE '2016-05-06%' AND events.longitude = 121 AND
events.latitude = 31
Corrected SQL generated by me: sql SELECT gender_age.age FROM
gender_age INNER JOIN events_relevant AS er ON gender_age.device_id =
er.device_id INNER JOIN app_events ON er.event_id =
app_events.event_id WHERE app_events.is_active = 1 AND
SUBSTR(er.timestamp, 1, 10) = '2016-05-06' AND er.longitude = 121 AND
er.latitude = 31 ORDER BY gender_age.age DESC LIMIT 1
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I correctly use ordering and limiting to retrieve the maximum or minimum
value?
Have I ensured the conditions and joins are accurately targeting the required
data?
8. Manual Calculation of Average
Question: "What is the average score of the movie 'The Fall of Berlin' in 2019?"
Incorrect SQL generated by me: SELECT AVG(rating_score) FROM ratings
INNER JOIN movies ON ratings.movie_id = movies.movie_id WHERE
movies.movie_title = 'The Fall of Berlin' AND rating_timestamp_utc
LIKE '2019%'
Corrected SQL generated by me: sql SELECT CASE WHEN COUNT(r.rating_id)
= 0 THEN NULL ELSE SUM(r.rating_score) / COUNT(r.rating_id) END AS
average_score FROM ratings AS r INNER JOIN movies AS m ON r.movie_id =
m.movie_id WHERE m.movie_title = 'The Fall of Berlin' AND
r.rating_timestamp_utc >= '2019-01-01' AND r.rating_timestamp_utc <
'2020-01-01'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Have I considered performing manual calculations for more control over the
result?
Did I use precise date filtering methods to ensure accuracy?
9. Simplifying Date Filtering
Figure13: Self-correctionguidelinethatisgeneratedbyourmethod,MAGIC,automatically. Page3.Question: "Indicate the location of all the events that occurred on April 30, 2016."
Incorrect SQL generated by me: SELECT * FROM table WHERE timestamp
BETWEEN '2016-04-30 00:00:00' AND '2016-04-30 23:59:59'
Corrected SQL generated by me: sql SELECT longitude, latitude FROM
events WHERE date(timestamp) = '2016-04-30'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I consider the simplest and most effective method for date filtering?
Have I avoided unnecessary complexity in filtering by date and time?
10. Incorrect Table and Condition Use for App Installation Analysis
Question: "On which brand of phone are the most applications installed?"
Incorrect SQL generated by me: SELECT T1.phone_brand, COUNT(*) AS
installed_count FROM phone_brand_device_model2 AS T1 JOIN events AS T2
ON T1.device_id = T2.device_id JOIN app_events AS T3 ON T2.event_id =
T3.event_id WHERE T3.is_installed = 1 GROUP BY T1.phone_brand ORDER BY
installed_count DESC LIMIT 1
Corrected SQL generated by me: sql SELECT T1.phone_brand, COUNT(*) AS
active_count FROM phone_brand_device_model2 AS T1 JOIN events_relevant
AS T2 ON T1.device_id = T2.device_id JOIN app_events_relevant AS T3 ON
T2.event_id = T3.event_id WHERE T3.is_active = 1 GROUP BY
T1.phone_brand ORDER BY active_count DESC LIMIT 1
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I ensure to use the correct tables that contain the relevant data for my
analysis?
Have I correctly identified the condition that matches the question's intent
(active vs. installed)?
11. Misuse of DISTINCT in Counting Unique Device IDs
Question: "How many men under the age of 23 have apps installed but are not active
on their devices?"
Incorrect SQL generated by me: SELECT COUNT(DISTINCT
gender_age.device_id) FROM gender_age INNER JOIN events ON
gender_age.device_id = events.device_id INNER JOIN app_events ON
events.event_id = app_events.event_id WHERE gender_age.gender = 'M'
AND gender_age.age < 23 AND app_events.is_installed = 1 AND
app_events.is_active = 0
Corrected SQL generated by me: sql SELECT COUNT(gender_age.device_id)
FROM gender_age INNER JOIN events_relevant ON gender_age.device_id =
events_relevant.device_id INNER JOIN app_events_relevant ON
events_relevant.event_id = app_events_relevant.event_id WHERE
gender_age.gender = 'M' AND gender_age.age < 23 AND
app_events_relevant.is_active = 0
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I unnecessarily use DISTINCT when the query logic or data model does not
require it?
Have I ensured that my joins and conditions accurately reflect the data's
structure and the question's intent?
12. Date Filtering and Table Naming for Event Analysis
Figure14: Self-correctionguidelinethatisgeneratedbyourmethod,MAGIC,automatically. Page4.Question: "Which gender logged in the most to an event in the first 10 days of May
2016?"
Incorrect SQL generated by me: SELECT gender, COUNT(*) AS login_count
FROM gender_age INNER JOIN events ON gender_age.device_id =
events.device_id WHERE timestamp BETWEEN '2016-05-01 00:00:00' AND
'2016-05-10 23:59:59' GROUP BY gender ORDER BY login_count DESC LIMIT
1
Corrected SQL generated by me: sql SELECT T.gender, COUNT(T.device_id)
AS login_count FROM (SELECT gender_age.gender, gender_age.device_id
FROM gender_age INNER JOIN events_relevant ON gender_age.device_id =
events_relevant.device_id WHERE date(events_relevant.timestamp)
BETWEEN '2016-05-01' AND '2016-05-10') AS T GROUP BY T.gender ORDER BY
login_count DESC LIMIT 1
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I use the most accurate method for date filtering to match the question's
requirements?
Have I selected the correct tables and used aliases for clarity and efficiency in
my query?
13. Accuracy in Calculating Average Age for Specific Conditions
Question: "Calculate the average age of people who have apps installed but are not
active on their devices."
Incorrect SQL generated by me: SELECT AVG(ga.age) AS average_age FROM
gender_age ga JOIN events e ON ga.device_id = e.device_id JOIN
app_events ae ON e.event_id = ae.event_id WHERE ae.is_installed = 1
AND ae.is_active = 0;
Corrected SQL generated by me: sql SELECT AVG(gender_age.age) FROM
gender_age JOIN events_relevant ON gender_age.device_id =
events_relevant.device_id JOIN app_events_relevant ON
events_relevant.event_id = app_events_relevant.event_id WHERE
app_events_relevant.is_installed = 1 AND app_events_relevant.is_active
= 0
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Have I ensured to use the correct tables for a more accurate analysis?
Did I correctly apply conditions to match the specific scenario described in the
question?
14. Selecting Specific Columns for Efficiency
Question: "Please list any three events that happened on the 1st of May 2016 that
have the same latitude of 31."
Incorrect SQL generated by me: SELECT * FROM events WHERE timestamp LIKE
'2016-05-01%' AND latitude = 31 LIMIT 3
Corrected SQL generated by me: sql SELECT event_id FROM events WHERE
timestamp LIKE '2016-05-01%' AND latitude = 31 LIMIT 3
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I only select the columns necessary for the question's requirements,
ensuring efficiency?
Have I used the correct filtering criteria to accurately target the desired data?
Figure15: Self-correctionguidelinethatisgeneratedbyourmethod,MAGIC,automatically. Page5.15. Correcting Device ID and Aggregation Method
Question: "What is the difference between the events of device number
-9222956879900150000 that can be located and those that are unable to be located?"
Incorrect SQL generated by me: SELECT (SUM(CASE WHEN latitude != 0 AND
longitude != 0 THEN 1 ELSE 0 END) - SUM(CASE WHEN latitude = 0 AND
longitude = 0 THEN 1 ELSE 0 END)) AS location_difference FROM events
WHERE device_id = -9222956879900150000;
Corrected SQL generated by me: sql SELECT SUM(IIF(latitude != 0 AND
longitude != 0, 1, 0)) - SUM(IIF(latitude = 0 AND longitude = 0, 1,
0)) AS difference FROM events WHERE device_id = '-922956879900150000'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I verify the accuracy of key identifiers such as device IDs before executing
the query?
Have I utilized the most efficient aggregation method to achieve the desired
calculation?
16. Table Naming and Alias Usage for Clarity
Question: "Show the avatar of the user who gave the rating at 2019/10/17 1:36:36."
Incorrect SQL generated by me: SELECT
ratings_users.user_avatar_image_url FROM ratings INNER JOIN
ratings_users ON ratings.user_id = ratings_users.user_id WHERE
ratings.rating_timestamp_utc = '2019-10-17 01:36:36'
Corrected SQL generated by me: sql SELECT
lists_users.user_avatar_image_url FROM ratings INNER JOIN lists_users
ON ratings.user_id = lists_users.user_id WHERE
ratings.rating_timestamp_utc = '2019-10-17 01:36:36'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Have I ensured to reference the correct tables as per the question's context?
Did I use aliases where appropriate to enhance the readability and clarity of my
query?
17. Direct Counting Without Unnecessary Distinct
Question: "How many users belong to the same behavior category as comics?"
Incorrect SQL generated by me: SELECT COUNT(DISTINCT T1.app_id) FROM
app_labels AS T1 INNER JOIN label_categories AS T2 ON T1.label_id =
T2.label_id WHERE T2.category = 'comics'
Corrected SQL generated by me: sql SELECT COUNT(app_id) FROM app_labels
INNER JOIN label_categories ON app_labels.label_id =
label_categories.label_id WHERE category = 'comics'
Negative and strict step-by-step ask-to-myself questions to prevent the same
mistake again:
Did I unnecessarily use DISTINCT when the query logic does not require it?
Have I ensured that my conditions accurately target the required data without
adding unnecessary complexity?
Figure16: Self-correctionguidelinethatisgeneratedbyourmethod,MAGIC,automatically. Page6.