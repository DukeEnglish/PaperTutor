Influence Maximization via Graph Neural Bandits
YutingFeng VincentY.F.Tan BogdanCautis
DepartmentofElectricalandComputer DepartmentofMathematics, UniversityofParis-Saclay,
Engineering(ECE) DepartmentofECE, CNRSLISN
NationalUniversityofSingapore NationalUniversityofSingapore bogdan.cautis@universite-paris-saclay.fr
yt.f@nus.edu.sg vtan@nus.edu.sg
ABSTRACT researchdirectlymirrorstheincreasinglyprevalentandsuccessful
WeconsideraubiquitousscenariointhestudyofInfluenceMax- marketingstrategyoftargetingkeyindividuals(influencers).
imization (IM), in which there is limited knowledge about the TheobjectiveofIMistypicallyformulatedbymaximizingthe
topology of the diffusion network. We set the IM problem in a expectedspreadunderastochasticdiffusionmodel,whichcharac-
multi-rounddiffusioncampaign,aimingtomaximizethenumberof terizestheinformationdisseminationprocess.Theworkof[18]laid
distinctusersthatareinfluenced.Leveragingthecapabilityofban- thefoundationsfortheIMliterature,byintroducingtwoprominent
ditalgorithmstoeffectivelybalancetheobjectivesofexploration models:LinearThreshold(LT)andIndependentCascade(IC).These
andexploitation,aswellastheexpressivityofneuralnetworks, models,widelyadoptedinsubsequentresearch,representdiffusion
ourstudyexplorestheapplicationofneuralbanditalgorithmsto networksasprobabilisticgraphs,wheretheedgesareweightedby
theIMproblem.WeproposetheframeworkIM-GNB(Influence probabilitiesofinformationtransmission.
MaximizationwithGraphNeuralBandits),whereweprovideanes- SelectingtheseednodesmaximizingtheexpectedspreadisNP-
timateoftheusers’probabilitiesofbeinginfluencedbyinfluencers hardundercommondiffusionmodels[18].Despitethedevelopment
(alsoknownasdiffusionseeds).Thisinitialestimateformsthebasis ofapproximatealgorithms,exploitingthemonotonicityandsub-
forconstructingbothanexploitationgraphandanexploration modularityofthespread,scalingIMalgorithmstolargenetworks
one.Subsequently,IM-GNBhandlestheexploration-exploitation remainschallenging.Acquiringmeaningfulinfluenceprobabilities
tradeoff,byselectingseednodesinreal-timeusingGraphCon- isequallychallenging,aslearningthemfrompastinformationcas-
volutional Networks (GCN), in which the pre-estimated graphs cades(e.g.,asin[11,13])canbedata-intensiveandthusimpractical.
areemployedtorefinetheinfluencers’estimatedrewardsineach Moreover,theapplicabilityofsuchmodelsislimitedinscenarios
contextualsetting.Throughextensiveexperimentsontwolarge wherehistoricalcascadesarenotavailable.
real-worlddatasets,wedemonstratetheeffectivenessofIM-GNB Inthefaceofthesechallenges,sinceeventhemostefficientIM
comparedwithotherbaselinemethods,significantlyimprovingthe algorithmssuchas[16,30]relyonassumptionsandparameters
spreadoutcomeofsuchdiffusioncampaigns,whentheunderlying thatoftenfailtocapturethecomplexrealityofhowinformation
networkisunknown. spreadsonline,achangeinresearchdirectionhasbeenfollowed
recently.Itconsistsofapproachesthatneitherrelyonpre-defined
CCSCONCEPTS
diffusionmodelsnorrequireupfrontknowledgeofthediffusion
•Informationsystems→Socialrecommendation;Socialad-
network.Instead,theseonlinemethods,suchas[17,20,33],learnto
vertising;•Human-centeredcomputing→Socialmedia;So-
spreadonthefly.Moreprecisely,theyinvolveasequentiallearning
cialrecommendation;•Networks→Socialmedianetworks.
agentthatactivelygathersinformationthroughamulti-roundinflu-
encecampaign.Ineachround,theagentselectsso-calledseednodes,
KEYWORDS
observestheresultinginformationspread,andusesthisfeedback
Informationdiffusion,influence,influencermarketing,contextual tomakebetterchoicesinsubsequentrounds,withthecampaign’s
bandits,graphneuralnetworks. totalrewardbeingtheobjectivethatistobeoptimized.Sucha
learningframeworkleadsnaturallytoapolicythatbalancesexplor-
1 INTRODUCTION ingunknownaspects(i.e.,thediffusiondynamics)withexploiting
knownandsuccessfulchoices(i.e.,thehigh-performingspreadseed
Motivatedbytheriseof“influencermarketing”insocialmedia
nodes),usingmulti-armedbandits[21].
advertising,aclassofalgorithmicproblemstermedInfluenceMax-
WeconsiderinthispapersuchananonlineIMscenariowith
imization (IM) has emerged, starting with the pioneering work
limitednetworkinformation.Specifically,thediffusiongraphis
of[10,18].Thesealgorithmsaimtoidentifythemostinfluential
largelyunknown,exceptforasetofpredefinedinfluencers,repre-
nodeswithinadiffusionnetworkforinitiatingthespreadofspe-
sentingthepotentialseedsforinformationdisseminationateach
cificinformation,therebymaximizingitsreach.Inmanyways,this
roundofamulti-rounddiffusioncampaign.Additionally,weincor-
poratecontextualfeaturesofbothinfluencersandtheinformation
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor
beingdiffused.Regardingthelatter,therationaleisthatwithina
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation campaignaimingtomaximizethereachofaspecificmessage,its
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored. framingandpresentationcansignificantlyimpactitsspread.For
Forallotheruses,contacttheowner/author(s).
instance,apoliticalcampaignmayusevariousformatslikenews
KDD’24,August25–29,2024,Barcelona,Spain
©2024Copyrightheldbytheowner/author(s). articles,opinionpieces,datavisualizations,ormultimediacontent,
ACMISBN979-8-4007-0490-1/24/08. eachleadingtodistinctdiffusionpatterns.
https://doi.org/10.1145/3637528.3671983
4202
nuJ
81
]GL.sc[
1v53821.6042:viXraKDD’24,August25–29,2024,Barcelona,Spain Feng,Tan,andCautis
Weleveragesuchcontextualinformationthroughtheformal extensiveexperiments,weshowthatouralgorithmoutperforms
frameworkofContextualMulti-ArmedBandits(CMABs)[21].Fur- baseline methods, highlighting the utility of GNBs as a prin-
thermore,recognizingthatsignificantcorrelationsbetweenthefea- cipledapproachtooptimizeinfluencecampaignsinuncertain
turesofthebasic(to-be-influenced)usersmayexist,albeitunknown environments.
totheagent,andthatbyimplicationtheiractivationprobabilities
maybecorrelated,weenhancethelearningframeworkwithmech- 2 RELATEDWORK
anismsbywhicheachactivationcanprovideusefulinformation InfluenceMaximization(IM)addressesthechallengeofidentify-
aboutneighbouringusersinthenetworkaswell,allowingtorefine ingasetofseeds(influencers)withinasocialnetworktomaximize
theagent’spredictions.WeachievethisbyadaptingtoourIMprob- informationspread.Researchersfirstexploredthisproblemin[10].
lemsettingtheGraphNeuralBandits(GNB)frameworkof[26](a Later,[18]providedaclearformulationoftheproblem,including
banditalgorithmforrecommendersystems).Correlationgraphs howinfluencespreadsthroughstochasticmodelslikeIndependent
areconstructedbasedonthesimilarityofuserstobeinfluenced Cascade(IC)andLinearThreshold(LT).Theyalsodescribedthe
bythesameinfluencer,andGNBsarethenemployedtohandlethe importantpropertiesofthespreadobjective,itsapproximationguar-
challengesassociatedwithgraph-basedbanditalgorithm.Indoing anteesandhardnessresults.Sincethen,suchstochasticmodelshave
so,ourworkisthefirsttoleveragetheimplicitrelationshipsthat becomewidelyadoptedintheliterature,andmostworksfocused
mayexistbetweenbasicusersintheunknowndiffusionmedium. onfindingapproximatesolutionsthatcanbecomputedefficiently.
In essence, we dynamically model these relationships based on Akeybreakthroughwastheconceptofreverseinfluencesampling,
theobservedcampaignfeedback,andweusethemasinputfora introducedin[6]andmadepracticalin[23,30,31].Diffusionmodel-
graphneuralnetwork(GNN)-basedlearningalgorithmguidingthe basedIMapproachesrelyondiffusiongraphswheretheedgesare
seedselectionprocessateachround,optimizingchoicesunderthe labeledbyweights(spreadprobabilities).Inempiricalevaluations,
exploit-exploreparadigm. theseweightsmaybedata-based[14,15](computedfromdiffusion
OverviewofourIMscenario.AsusualinIMscenarios,werun cascades),degreebased,orsimplyassumedrandom.Somerecent
campaignsunderbudgetconstraints(limitedseedingsandrounds), studies[12,24]employrepresentationlearningtoinferinfluence
withthegoaltomaximizethenumberofdistinctusersactivated, probabilitiesfromground-truthdiffusioncascades,aresourcethat
startingfromknowninfluencers.Thelearningagentchoosesseeds maynotbereadilyavailableinmanyapplicationscenarios.(See
sequentially,i.e.,ateachround,withpotentialre-seeding,andfeed- therecentsurvey[22]forareviewoftheIMliterature.)
backconsistssolelyoftheactivatednodesaftereachround,without BanditsforInfluenceMaximizationByvirtueoftheirversa-
additionaldetailsonthetriggeringcauses.Thefeedbackisused tilityandsequentialnature,banditalgorithmsareapttobeused
torefineestimatesofinfluencerpotential,guidingfutureseeding in IM problems, especially in uncertain diffusion environments
choices.Aligningwiththeoverallobjective,eachround’sreward withwhichalearningagentmayinteractrepeatedly[17,29,34,37].
isthenumberofnewlyactivatedusers,andthecampaignaimsto A multi-round, sequential setting allows to spread information
maximizethecumulativerewardacrossrounds.Inthisscenario, andgatherfeedback,strikingabalancebetweeninfluencing/ac-
wemimicreal-worldinfluencermarketing,whereaccessislimited tivatingnodesineachroundandlearninginfluenceparameters
toafewinfluencers,feedbackisrestrictedtouseractions(likepur- foruncertainorunexplorednetworkfacets.Thisstrategyclosely
chasesorsubscriptions),andthegoalistoreachasmanyunique mirrorsreal-worldinfluencermarketingscenarios,inwhichcam-
usersaspossible. paignsoftenunfoldovertime.[34]isoneoftheearliestworksthat
Ourcontributions.Wedetailourcontributionsinthefollowing: mapanIMproblemformulationtoacombinatorialmulti-armed
• ByintroducingtheIM-GNBframework,weconnectGNBsand bandit (CMAB) paradigm, where diffusions are assumed to fol-
theIMproblem.Thisintegrationisnon-trivialduetotheinherent lowtheICmodel.IMLinUCB[35]learnstheoptimalinfluencers
challengesoflearningfromgraph-structureddataandmaking dynamically,whilerepeatedlyinteractingwithanetworkunder
sequentialdecisionsunderuncertainenvironmentsinthecontext the IC assumption as well. Vaswani et al. [33] introduces a dif-
ofdiffusioncampaigns. fusionmodel-agnosticframework,basedonapairwise-influence
• Wetacklethechallengeofbalancingexplorationandexploitation semi-banditfeedbackmodelandtheLinUCB-basedalgorithm,ad-
indynamicinfluencepropagationbyincorporatingcontextual dressingscenariosinvolvingnewmarketersthatexploitexisting
banditsintotheIM-GNBframework.Thisenablesustoeffec- networks.Sincetheaforementionedapproachesleverageagiven
tivelyexplorethepotentialrewardswhileexploitingavailable diffusiongraphtopology,theinherentdifficultyofobtainingsuch
information,resultinginenhancedinfluencespreadinreal-world datalimitstheirpracticalinterest.
scenarios. Operatinginhighlyuncertaindiffusionscenariosthat(i)make
• Weconstructuser-usercorrelationgraphsforexploitationand noassumptiononthediffusionmodeland(ii)lackknowledgeof
exploration purposes, capturing intricate interactions among thediffusiontopologyandhistoricalactivations(cascades),[20]
usersandinfluencersineachroundofthediffusioncampaign. proposesFAT-GT-UCB,whereaGood–Turingestimatorisused
Thisgraph-basedapproachisscalabletovariousnetworkset- tocapturetheutility(calledremainingpotential)ofaninfluencer,
tings,evenwithoutpriorknowledgeofthenetwork’stopology throughoutthemultipleroundsofadiffusioncampaign.Theyalso
structure. considerafatigue effectforinfluencers,sincethesemaybeare
• Wedevelopanovelalgorithmthatoptimallyselectsseednodes repeatedly chosen in the sequential rounds. GLM-GT-UCB [17]
inreal-time,withcontextualbanditsintegratedwithGNNsto considersthesamesettingas[20],whileexploitingcontextualin-
refinetherewardestimatesineachcontextualsetting.Through formation(e.g.,featurespertainingtoinfluencersortheinformationInfluenceMaximizationviaGraphNeuralBandits KDD’24,August25–29,2024,Barcelona,Spain
beingconveyed).Ourworksharesasimilarsetting,wherethenet- (whichhascardinality|𝐼 𝑡|=𝐿)thesetofactivatedseeds,𝑆(𝐼 𝑡,𝐶 𝑡)
worktopologyisunknownandnoassumptionsaremadeaboutthe istheround’sspread(allactivatedusers)startingfromthechosen
diffusionmodel.Inamulti-rounddiffusioncampaign,weselectat seedset𝐼 𝑡.Ourobjectiveistomaximizethecumulativeanddistinct
eachrounddiffusionseeds,withoutfactoringininfluencerfatigue. spreadofthe𝑇 rounds,i.e.,find
BanditswithdeeplearningEarlyworks[1,9,28]inthecon- (cid:20)(cid:12)
(cid:216)
(cid:12)(cid:21)
textualbanditliteraturefocusedonlinearmodels,assumingthe argmax E (cid:12)
(cid:12)
𝑆(𝐼 𝑡,𝐶 𝑡)(cid:12)
(cid:12)
. (1)
expectedrewardateachroundislinearinthefeaturevector.This 𝐼𝑡⊆𝐾,|𝐼𝑡|=𝐿,∀1≤𝑡≤𝑇 1≤𝑡≤𝑇
assumption,however,oftenfailstoholdinpractice,promptingex- AdaptationtothebanditsettingToadapttheIMproblemtoa
plorationintononlinearornonparametriccontextualbandits[7,32]. contextualbanditsetting,thesetofinfluencers𝐾canbeconsidered
However,thesemorecomplexmodelsimposerestrictiveassump- thesetofarmstobepulledin𝑇 rounds.Ateachround𝑡,withthe
tionsontherewardfunction,suchasLipschitzcontinuity[7],orare- providedmessage𝐶 𝑡 asthecontext,thesetofarms𝐼 𝑡 = {𝑘 𝑖} 𝑖𝐿
=1
wardfunctionfromareproducingkernelHilbertspace(RKHS)[32]. is chosen. For each chosen arm𝑘 𝑖,𝐴 𝑘𝑖 is the set of basic users
Toovercometheselimitations,severalrecentstudies[27,38,41] activated or influenced by seed (arm)𝑘 𝑖. For each basic user𝑢,
leveragetheexpressivityofdeepneuralnetworks(DNNs)toin- let𝑐 𝑢𝑡 denotethetotalnumberoftimesithasbeeninfluencedor
corporatenonlinearmodels,whichrequirelessdomainknowledge. activateduntilround𝑡.Withthesetofactivatedusers(influence
Theworksof[27,38]employDNNsforeffectivecontexttransfor- spread)asthenodesemi-banditfeedback,therewardisthenumber
mationwithalinearexplorationpolicy,showingnotableempirical ofnewactivations[17]as
s inu tc rc oe ds us cd ee ss Npi et ue rt ah lUe Cab Bs ,e an pc re oo vf abre lygr ee ffit cg iu ea nr ta nn et ue re as l. cT oh ne tew xo turk alo bf a[ n4 d1 i] t 𝑅 𝑡 = ∑︁ 1{𝑐 𝑢𝑡 >0}−𝑅 𝑡−1; 𝑅 0=0, (2)
algorithmusingDNN-basedrandomfeaturemappingstoconstruct
𝑢∈(cid:208) 𝑘𝑖∈𝐼𝑡𝐴𝑘𝑖
theUCB,withanear-optimalregretguarantee.Theconstructof Notethatdistinctactivationsareusedforthecumulativereward,
theUCBisbasedonthepastgradientoftheexploitationfunction. i.e.,agivenuserwillbecountedonlyonceinthetotalreward,even
Theworkof[40]assignsanormaldistributionasthedistribution ifithasbeeninfluencedseveraltimes.
oftherewardofeacharm,similarlytothedeviationcomputed ModelingwithgraphbanditsWearemainlymotivatedbyappli-
onthegradientoftheestimationfunction.Similartosomeother cationscenariosinsocialmedia(e.g.,informationcampaignsfor
studies, EE-Net [2] has an exploitation network to estimate re- elections,onlineadvertising,publicawarenesscampaigns,crisis
wardsforeacharm.Itadditionallybuildsanexplorationnetwork informationdiffusion,etc.),whereusersmayexhibitsimilarprefer-
topredictthepotentialgainforeacharm,relativetothecurrentes- encesandinfluencesusceptibilityforcertaindiffusiontopics(e.g.,
timate,wheretheinputoftheexplorationnetworkaretheprevious sharingthesamepoliticalviews)initiatedbycertaininfluencers
gradientsoftheexploitationfunction.TheworkofQietal.[26] (arms),whiletheymayreactdifferentlyandbemoresusceptibleto
employscontextualneuralbanditsinrecommendersystems,to otherinfluencersforothertopics(e.g.,entertainmentorsports).
buildagraphneuralbanditframeworkwhereeacharmisinduced Thus, instead of representing the social graph uniformly, in
withanexploitationgraphandanexplorationone,withtheweights the bandit setting, we allow each arm𝑘 𝑖 at each round𝑡 to in-
ofedgesrepresentingusers’correlationsregardingtheexploitation duceadistinctgraph𝐺 𝑖,𝑡(U,𝐸,𝑊 𝑖,𝑡)torepresentuserconnectivity.
andexplorationperformed.Theeffectivenessof[26]intherecom- With𝒌𝑖 the𝑑 1-dimensionalfeaturevectorofarm𝑘 𝑖 and𝑪𝑡 the𝑑 2-
mendationsettingservesasourinitialmotivationforleveragingits dimensionalcontextvector,theexpectedreward1ateachround
neuralbanditsframeworkinourIMproblem.Giventhesimilarities 𝑡 ∈ [𝑇]broughtbyarm𝑘 𝑖 isdefinedas
inpredictinguserpreferences(user-iteminrecommendersystems
𝑟 𝑖,𝑡 =𝑓(𝒌𝑖,𝑪𝑡,𝐺 𝑖,𝑡). (3)
oruser-influencersusceptibilityinIM),weexploitagraphneural
contextualbanditalgorithmtomaximizetheinfluencespreadin In𝐺 𝑖,𝑡,eachuser𝑢 ∈ U = {1,2,...,𝑚} correspondstoanode,
multi-rounddiffusioncampaigns. 𝐸 is the set of edges connecting users, and𝑊 𝑖,𝑡 = {𝑤 𝑖,𝑡(𝑢,𝑢′) :
𝑢,𝑢′ ∈U}isthesetofweightscorrespondingtoeachedge𝑒 ∈𝐸.
3 PROBLEMFORMULATION
Modelingrealapplications,weassumethattheweightsoftheedges
We formulate the Influence Maximization (IM) problem with a connectingnodesin𝐺 𝑖,𝑡 representusers’similarityw.r.t.thesame
discrete-timediffusionmodel[18],adoptingacombinatorialmulti- influencer(arm𝑘 𝑖),i.e.,theprobabilitytobesimilarlyinfluenced
armedbanditparadigmtoestimatetheinfluencespread. byarm𝑘 𝑖 inround𝑡,whichisdefinedas
I teM rizP er do bb yle sm tocW hai st th icin ot rh ee pc ido en mte ix ct ino ff oi rn mfo ar tm ionat dio iffn us sc ie on na pr hio es nc oh ma er nac a- , 𝑤 𝑖,𝑡(𝑢,𝑢′)=Φ(1)(cid:16) E(cid:2)𝑝 𝑖𝑡 ,𝑢|𝒌𝑖,𝑪𝑡(cid:3),E(cid:2)𝑝 𝑖𝑡 ,𝑢′|𝒌𝑖,𝑪𝑡(cid:3)(cid:17) , (4)
p sea er dtic uu sl ea rr sly (ino fln us eo nc ci ea rl sm )ae nd dia a, mth pe lii fin efo dr tm ha roti uo gn hs sp hr ae ra id ngis ai nn diti ra et te wd eb ey
t-
where𝑝 𝑖𝑡
,𝑢
=ℎ 𝑢(𝒌𝑖,𝑪𝑡) ∈ [0,1]theexpecteddiffusionprobabil-
itybetweeninfluencer(arm𝑘 𝑖)anduser𝑢underthecontext𝑪𝑡,
ingviauserinteractions.Foracampaignofinformationspread
consistingof𝑇 rounds(trials),weselecttheinfluencersateach
andΦ(1) :R×R→Rmapstheexpecteddiffusionprobabilityof
usersw.r.t.influencer𝑘 𝑖 totheweightsamongusersin𝐺 𝑖,𝑡.
roundtomaximizetheoverallinformationspread.
seeW dse ,aar be ug di gv ee tn ofa 𝑇kn roo uw nn dsb (a ts re ias lse )t .Aof ti en afl cu he rn oc ue nr ds 𝑡𝐾 ∈= {1{ ,𝑘 2𝑖} .𝑛 𝑖 .= .1 ,𝑇a }s
,
knoH wo nw ie nve or u, rth pe ros bi lm emila sr eit ty ting gr .a Tph hu𝐺 s𝑖, w𝑡 ean pd rot ph oe sefu an nct ei so tn imℎ a𝑢 tear ge rau pn h-
theenvironmentprovidesuswiththemessage𝐶 𝑡 todiffuse,and 1Notethatthisexpectedreward𝑟𝑖,𝑡isassessingthedistinctactivationsbyarm𝑘𝑖at
thereare𝐿 ∈ {1,2,...,𝑛}seedstobeactivatedinitially.With𝐼 𝑡 round𝑡,inalignmentwiththerewardbroughtbyeacharmin𝐼𝑡,asdefinedinEq.(2).KDD’24,August25–29,2024,Barcelona,Spain Feng,Tan,andCautis
𝐺 𝑖( ,1 𝑡) =(U,𝐸,𝑊 𝑖,( 𝑡1) )toapproximate𝐺 𝑖,𝑡 byexploitingthecurrent probabilities([P𝑢(1) ]𝑡−1aretheupdatedparametersofthenetwork
observations.Thisisknownastheexploitationgraph.Wealsocon- fromround𝑡−1).Theweightsin𝐺 𝑖( ,1 𝑡) are
s thid ee er xa pp er ce t- ed defi dn iffe ud sh ioy npo pt rh oe bs ais bif lu itn yct 𝑝i 𝑖o 𝑡 ,𝑢n ,ℎ s𝑢( o1) a( s𝒌 t𝑖 o,𝑪 e𝑡 s) tit mo aa tp ep 𝑊ro 𝑖,x 𝑡im wa itt he 𝑤 𝑖( ,1 𝑡) (𝑢,𝑢′)=Φ(1)(cid:0)ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡),ℎ 𝑢(1 ′) (𝒌𝑖,𝑪𝑡)(cid:1), (7)
𝑊 𝑖,( 𝑡1) inthegraph𝐺 𝑖( ,1 𝑡) .Withthepre-estimatedgraph𝐺 𝑖( ,1 𝑡) ,the whereΦ(1) isthesamefunctioninEq.(4).Foreachuser𝑢,ℎ 𝑢(1) will
estimaterewardofarm𝑘 𝑖 acrossallusersisthenexpressedas betrainedbygradientdescent(GD)withthegivencontextandthe
chosenarmasinputandtherewardaslabel.Thelossisdefinedas
Toquantifytheestima𝑟ˆ𝑖 t, i𝑡 on= g𝑓 a( p1) (u(cid:0) 𝒌 n𝑖 c, e𝑪 r𝑡 t, a𝐺 in𝑖( t,1 𝑡 y)(cid:1) o. festimation)betwe( e5 n) L𝑢(1) = (cid:16) ℎ 𝑢(1)(cid:0) 𝒌𝑖,𝑪𝑡;P𝑢(1)(cid:1)−𝑑 𝑢𝑡(cid:17)2 , (8)
𝐺 𝑖( ,1 𝑡) and𝐺 𝑖,𝑡 (ortomeasurethepotentialgainontheestimated where𝑑 𝑢𝑡 =1if𝑐 𝑢𝑡 >0and𝑐 𝑢𝑡−1=0,else𝑑 𝑢𝑡 =0.Recallthatweuse
diffusionprobabilityforeachuser-influencerpair),wealsopropose 𝑐 𝑢𝑡 todenotethetotalnumberoftimesuser𝑢hasbeenactivated
anexplorationgraph,denotedby𝐺 𝑖( ,2 𝑡) =(U,𝐸,𝑊 𝑖,( 𝑡2) ),whereanalo- (influenced)uptoandincludinground𝑡,andweonlycountthe
gouslytheweightsamongusers𝑤 𝑖( ,2 𝑡) (𝑢,𝑢′) ∈𝑊 𝑖,( 𝑡2) indicateusers’ newlyactivatednodesateachround.
correlationsw.r.t.potentialgains,expressedas 4.1.2 Userexplorationgraph. Recentworksonneuralbandits[2–
𝑤(2) (𝑢,𝑢′) 4,40,41]takeadvantageoftherepresentationpowerofneural
𝑖,𝑡
networkstolearntheuncertaintyofestimation(potentialgain).
=Φ(2)(cid:0)ℎ 𝑢(𝒌𝑖,𝑪𝑡)−ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡),ℎ 𝑢′(𝒌𝑖,𝑪𝑡)−ℎ 𝑢(1 ′) (𝒌𝑖,𝑪𝑡)(cid:1) (6) Theseworksusethepastgradienttoincorporatethefeatureofarms
andthelearneddiscriminativeinformationofestimationfunction
for Wso im the tf hu en ec xti po ln orΦ a( t2 io) n:R gr× apR h→
𝐺 𝑖( ,2
𝑡R
)
,w thh eic ph oi ts ensi tm iai lla gr at io nΦ of(1 a) r.
m𝑘
𝑖
(ℎ 𝑢( Q1) i(𝒌 e𝑖 t, a𝑪 l𝑡 .) [i 2n 6]ou ar ppw lio er dk) t.
his paradigm in collaborative filtering
acrossalltheusersisdefinedas𝑏ˆ 𝑖,𝑡 = 𝑓(2)(𝒌𝑖,𝑪𝑡,𝐺 𝑖( ,2 𝑡) ).Ateach foruser-itempairpredictioninonlinerecommendationscenarios
round𝑡,thearmset𝐼 𝑡 isselectedasargmax𝐼𝑡⊂𝐾:|𝐼𝑡|=𝐿(𝑟ˆ𝑖,𝑡 +𝑏ˆ 𝑖,𝑡). a sin md ild ae rm ityon ws it tr hat pe rd edit is cte iff ngec uti sv ee rn pe rs es f. eS rein nc ce esth toe wIM ardp sro itb el mem s(s ih na or ues
r
Thismaximizestheoverallinfluencespreadinthecampaign.
casesusceptibilitytoinfluencers),especiallywhentheconnections
Thedetailsoftheconstructionsoftheexploitationandexplo-
(correlations)amongusersarereinforcedbysocialties,weapply
rationgraphsaregiveninSec.4below.
thepastgradienttoquantifythe“explorationbonus”[21].
4 PROPOSEDFRAMEWORK Forauser𝑢 ∈ U,weuseaneuralnetworkℎ 𝑢(2) tolearnthe
Manyrecentworks[17,35]ontheIMproblemthatexploitbandits uncertainty of the estimated diffusion probability between arm
fortheexploration-exploitationtrade-offassumethattherewardis 𝑘 𝑖 anduser𝑢,i.e.,E[𝑝 𝑖,𝑡|𝑢,𝒌𝑖,𝑪𝑡]−ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡),similartoEq.(6).
alinearorgeneralizedlinearfunctionofarmvectors.Considering Asin[2],weapplyℎ 𝑢(2) directlyonthepreviousgradientofℎ 𝑢(1) .
thehighcomplexityanddynamicityofsocialnetwork-relateddata, Analogously,theexplorationgraph𝐺 𝑖( ,2 𝑡) = (U,𝐸,𝑊 𝑖,( 𝑡2) ) iscon-
weusetherepresentationpowerofneuralnetworkstofirstly,learn
users’connectivitytobuildexploitationandexplorationgraphsand
structedwith𝑊 𝑖,( 𝑡2) =(cid:8)𝑤 𝑖( ,2 𝑡) (𝑢,𝑢′):𝑢,𝑢′ ∈U(cid:9) ,and𝑤 𝑖( ,2 𝑡) (𝑢,𝑢′)is
secondly,learntheunderlyingrewardfunctionandthepotential theexplorationcorrelationamongusers,definedas
gainsontheestimatedreward.Theoverallframeworkofourmodel 𝑤 𝑖( ,2 𝑡) (𝑢,𝑢′)=Φ(2)(cid:16) ℎ 𝑢(2)(cid:0)∇ℎ 𝑢(1)(cid:1),ℎ 𝑢(2 ′)(cid:0)∇ℎ 𝑢(1 ′)(cid:1)(cid:17) . (9)
isillustratedinFig.1.
Thepreviousgradient∇ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡) =∇ Pℎ 𝑢(1) (𝒌𝑖,𝑪𝑡;[P𝑢(1) ]𝑡−1)
4.1 EstimatingtheUserGraphs isthenetworkgradientatround𝑡−1,with[P𝑢(1) ]𝑡−1thelastup-
Inthissection,wefirstprovideastrategytoestimatetheusers’ datedparametersofℎ 𝑢(1) .Inaddition,Φ(2) isthefunctiondefined
correlationstobeinfluencedbythesamearm,formingthebasis inEq.(6)andℎ 𝑢(2) willbetrainedwithGD,wheretheprevious
fortheexploration-exploitationstrategyinSec.4.2. gradientofℎ 𝑢(1) iscomputedbasedontheinputsamples,andthe
4.1.1 Userexploitationgraph. Webridgetheusersinthesocial residualdiffusionprobability(potentialgainontheestimateddiffu-
graphwithdiffusionprobabilitiesbetweeninfluencersandusers. sionprobability)isthelabel,withthelossgivenas
Theintuitionisthatgiventhesamemessagetobediffused(context
𝐶 𝑡),userswhoexhibithighcorrelationsinthisgrapharemorelikely L𝑢(2) = (cid:16) ℎ 𝑢(2)(cid:0)∇ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡)(cid:1)−(cid:0)𝑑 𝑢𝑡 −ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡)(cid:1)(cid:17)2 . (10)
tobeinfluencedbythesameinfluencer.Asthecontextchanges,an Regardingthenetworkstructureofℎ(1) andℎ(2),sincethere
influencermaynotexertthesameinfluenceonusers.Thus,ateach
arenodatacharacteristicsrequiringspecificmodelssuchasRNNs
round𝑡 andforeachinfluencer(arm)𝑘 𝑖,weinduceanexploitation
forsequentialdependenciesorCNNsforvisualcontent,wesimply
graph𝐺 𝑖( ,1 𝑡) torepresenttheusers’correlations. employan𝐽-layerfullyconnected(FC)neuralnetworkatthisstage
In the exploitation graph𝐺 𝑖( ,1 𝑡) , the weights among users are forinitialgraphestimation.
referredtoasusers’correlationsw.r.t.thediffusionprobabilityfrom Tosummarise,weuseℎ 𝑢(1) ,denotinguser𝑢,toobtainthees-
arm𝑘 𝑖 (hencelikelihoodtoinfluencedbythesameinfluencer𝑘 𝑖). timated diffusion probability from influencer (arm)𝑘 𝑖 to𝑢 (the
Foreachuser𝑢 ∈U,weuseaneuralnetworkasthepre-defined estimationfunctionisbuiltforeachuserindividually,i.e.,thereare
hypothesisfunctionℎ 𝑢(1) =ℎ 𝑢(1) (𝒌𝑖,𝑪𝑡;[P𝑢(1) ]𝑡−1)tolearnthese 𝑚estimationfunctionsℎ 𝑢(1) intotal),andtheexploitationgraphInfluenceMaximizationviaGraphNeuralBandits KDD’24,August25–29,2024,Barcelona,Spain
Exploitation
Graph estimation Reward and potential gain estimation Arm selection
&F e coa ntu tere
x
tv ve ect co tor
r Exploitation graph𝐺 𝑖(cid:4666) ,𝑡1(cid:4667) GCN FC Network Reward
𝑤 1(cid:4666) 21(cid:4667) 𝑓(cid:4666)1(cid:4667)
ℎ𝑢(cid:4666)1 1(cid:4667)
ℎ𝑢(cid:4666)1 2(cid:4667) ℎ𝑢(cid:4666)1(cid:4667)(cid:3435)𝒌𝒊,𝒕,𝑪𝒕(cid:3439)
𝑤 1(cid:4666) 31(cid:4667) 𝑤 2(cid:4666) 31(cid:4667)
Input Output
𝑝̂𝑖𝑢1
𝑝̂. 𝑖𝑢.
2
.
𝑝̂𝑖𝑢𝑚
𝑟𝑖̂,𝑡(cid:3404)(cid:3496)(cid:3533) 𝑖∈𝒰(cid:3435)𝑝̂ 𝑖𝑡 ,𝑢(cid:3439)2
ℎ𝑢(cid:4666)1 3(cid:4667)
∇ℎ𝑢(cid:4666)1(cid:4667)
𝑤𝑢(cid:4666)1 1,(cid:4667) 𝑢2(cid:3404)Φ(cid:4666)1(cid:4667)(cid:3435)hu(cid:4666)1 1(cid:4667),hu(cid:4666)1 2(cid:4667)(cid:3439)
∇𝑓(cid:4666)1(cid:4667) argmax(cid:4666)𝑟 𝑖̂ ,𝑡(cid:3397)𝑏(cid:3552) 𝑖,𝑡(cid:4667)
𝑤𝑢(cid:4666)2 1,(cid:4667) 𝑢2(cid:3404)Φ(cid:4666)2(cid:4667)(cid:3435)hu(cid:4666)2 1(cid:4667),hu(cid:4666)2 2(cid:4667)(cid:3439)
𝐼𝑡⊂𝐾,|𝐼𝑡|(cid:3404)𝐿
𝑤(cid:4666)2(cid:4667) 𝑓(cid:4666)2(cid:4667)
12 ...
ℎ𝑢(cid:4666)2 1(cid:4667) ℎ ℎ𝑢(cid:4666) 𝑢(cid:4666)2 2
2
3(cid:4667)
(cid:4667)
ℎ𝑢(cid:4666)2(cid:4667)(cid:3435)∇ℎ𝑢(cid:4666)1(cid:4667)(cid:3439) E𝑤 x1(cid:4666) p32 l(cid:4667)
o ration
gr𝑤 ap2(cid:4666) 32 h(cid:4667) 𝐺In (cid:4666)2p (cid:4667)u t
GCN FC Network
Output 𝑧 P𝑖̂𝑢 o1
t e
n𝑧𝑖̂ t𝑢 ia2
l gain
𝑧𝑖̂𝑢𝑚 𝑏(cid:3552) 𝑖,𝑡(cid:3404)(cid:3496)(cid:3533) 𝑖∈𝒰(cid:3435)𝑧 𝑖̂𝑡 ,𝑢(cid:3439)2
𝑖,𝑡
Exploration
Figure1:TheframeworkofIM-GNB.Foreacharm,weinitiallytakethearmfeaturevectorandthecurrentcontextvector
(𝒌𝑖,𝑪𝑡)asinputstoestimatethediffusionprobabilityforeachuser-armpairwithℎ 𝑢(1) .Subsequently,weassessthepotential
gainonthediffusionprobabilitywiththepastgradientofℎ 𝑢(1) ,yieldingbothexploitationandexplorationgraphs.Withthe
pre-estimatedgraphs,werefinetheestimateofthediffusionprobabilityforeachuser-armpairwith𝑓(1)and𝑓(2).Theaggregate
rewardofthearmacrossallusersisderivedfromthesumofalltherefinedindividualdiffusionprobabilities.Thepotential
gainismeasuredsimilarly.Finally,weselectthearmwiththehighestsumofestimatedrewardanditspotentialgain.
𝐺 𝑖( ,1 𝑡) forarm𝑘 𝑖 isbuiltsuchthatthebasicusersarecorrelated We adopt a simplified Graph Convolutional Network (GCN)
basedonestimateddiffusionprobabilities.Wealsoapplyℎ 𝑢(2) to model[36]tolearntheaggregatedrepresentationoftheexploita-
representtheuncertaintyoftheestimateddiffusionprobability, tiongraph.With𝑆 𝑖( ,1 𝑡) and𝑿𝑖( ,1 𝑡) asinputs,thefeaturerepresentation
andtheexplorationgraph𝐺 𝑖( ,2 𝑡) correspondingtoarm𝑘 𝑖 isbuilt matrixisexpressedas
suchthattheusersarecorrelatedbasedonthepotentialgains.The 𝐻 G =𝜎(cid:16) (cid:0)𝑆 𝑖( ,1 𝑡)(cid:1)𝛾 𝑿𝑖( ,1 𝑡) ;P G(1)(cid:17) , (11)
graphestimationprocessisgiveninLines13–17ofAlgorithm1.
where 𝜎 is the activation function, P(1) ∈ R𝑚(𝑑 1+𝑑 2)×𝑝 is the
G
trainableweightmatrixintheGCNmodel,and𝛾 isthenumberof
4.2 Exploitation-ExplorationwithGNNs
hopstheinformationpropagatingovertheusergraph,indicating
Withtheusercorrelationgraphs𝐺 𝑖( ,1 𝑡) and𝐺 𝑖( ,2 𝑡) forexploitation thatafter𝑘layersanodeobtainsthefeatureinformationfromall
andexplorationrespectively,wenowhavearefinedestimateofthe nodesfound𝛾 hopsawayinthegraph.IntheGCNmodel,𝑿𝑖( ,1 𝑡) is
diffusionprobabilitiesbetweeninfluencersandusers,aswellasthe appliedtothecorrespondingweightmatrixP(1) sothatP(1)
is
expectedtotalspread(newlyactivatedusers),i.e.,thereward. G G
partitionedforeachuser𝑢 ∈Utogetthe𝑝-dimensionalarm-user
4.2.1 GNNforexploitation. Inround𝑡,foreacharm𝑘 𝑖,withthe diff Tu osi fo un rtr he ep rr re es fien nt ea tt hio en 𝑝, -c do ir mre es np so in ond ain lg art moe -ua sc eh rr po aw iro rf e𝐻 prG es∈ enR ta𝑚 ti× o𝑝 n.
pre-estimatedexploitationgraph𝐺 𝑖( ,1 𝑡) forarm𝑘 𝑖 asinput,weuse in𝐻 G,weaddan 𝐽-layerFCneuralnetworktotheGCNmodel,
aGNNmodel 𝑓(1)(𝒌𝑖,𝑪𝑡,𝐺 𝑖( ,1 𝑡) ;P(1)) toestimatetherewardde- andfor𝑙 ∈{1,2,...,𝐽 −1}therepresentationforeachlayeris
scribedinEq.(3),withP(1) representingtheparametersof𝑓(1). 𝐻 𝑙 =𝜎(cid:0)𝐻 𝑙−1·P 𝑙(1)(cid:1), and 𝐻 0=𝐻 G, (12)
R𝑚W ×𝑚ed fre ofi mne thfo er ee xa pc loh ita ar tm iona gs ry am phm 𝐺et 𝑖(r ,1 𝑡ic ) ,a wd ij ta hce en acc hy em lea mtr eix nt𝐴 i𝑖 n( ,1 𝑡) th∈
e
w lai yt eh r𝐻 in𝑙 t∈ heR F𝑚 C×𝑝 n, ea twnd orP k𝑙 .(1 F) orbe thin eg lath ste lt ar ya ein r,a wbl ee hp aa vr eametersineach
matrixcorrespondingtothecorrelationsweights𝑤 𝑢,𝑢′ between 𝑃ˆ 𝑖,𝑡 =𝐻 𝐽−1·P 𝐽(1), (13)
user𝑢anduser𝑢′in𝐺 𝑖( ,1 𝑡) ,andthenormalizedadjacencymatrix[19] wheretheP 𝐽(1) aretheparametersinthelastlayer,and𝑃ˆ 𝑖,𝑡 ∈R𝑚 is
being𝑆 𝑖( ,1 𝑡) =𝐷−1 2𝐴 𝑖( ,1 𝑡)𝐷−1 2,with𝐷thedegreematrix.Weconcate- the𝑚-dimensionalvectorwitheachelementtherefinedestimated
natethearmfeaturevector𝒌𝑖 withthecontextvector𝑪𝑡 tobuild diffusionprobability𝑝ˆ 𝑖𝑡 ,𝑢 ∈Rbetweenarm𝑘 𝑖 anduser𝑢 ∈U.
the feature matrix 𝑿𝑖,𝑡 = diag([𝒌𝑖,𝑪𝑡],[𝒌𝑖,𝑪𝑡],...,[𝒌𝑖,𝑪𝑡]) ∈ Withtherefinedestimateddiffusionprobabilitybetweenarm
R𝑚×𝑚(𝑑 1+𝑑 2). 𝑘 𝑖 andalltheusers,theestimatedrewardforarm𝑘 𝑖 acrossalltheKDD’24,August25–29,2024,Barcelona,Spain Feng,Tan,andCautis
usersiscomputedasthenormoftheoutputlayer: Algorithm1:IM-GNB
𝑟ˆ𝑖,𝑡 =∥𝑃ˆ 𝑖,𝑡∥=√︄ ∑︁ (cid:0)𝑝ˆ 𝑖𝑡 ,𝑢(cid:1)2. (14) I On up tu pt u: t:In Afl ru men rc ee cr omse mt𝐾 en, dn au tm iob ne fr oo rf es ae cl hec tt ii mon es s𝐿 teppe 𝑡rround
𝑢∈U
1 Initializationofallthetrainableparameters
TheexploitationnetworkwillbetrainedwithGDbasedonthe 2 for𝑡 =1,2,3,...,𝑇 do
influencespreadfromarm𝑘 𝑖,wherethepredictedoutputarethe 3 Receivefromenvironmentthecontext𝑪𝑡
diffusionprobabilitiesacrossallusers,withthelabel(reward) 4 for𝑘 𝑖 ∈𝐾 do
𝑟 𝑖,𝑡 = ∑︁ 𝑑 𝑢𝑡. (15) 5 constructtwousergraphs𝐺 𝑖( ,1 𝑡) and𝐺 𝑖( ,2 𝑡) from
𝑢∈𝐴𝑘𝑖
ProcedureEstimatinggraphsforarm𝑘
𝑖
R atec roal ul nth da 𝑡t ,𝐴 a𝑘 n𝑖 di 𝑑s 𝑢𝑡th ie ss de et fio nf eu dse ar ss ta hc eti dv ia st te id nco tr ai cn tfl ivu ae tn ioce nd sb iny Ear qm .(𝑘 8)𝑖
.
6 C 𝑟ˆo 𝑖,m
𝑡
p =u 𝑓te (1e )s (t 𝒌im 𝑖,a 𝑪t 𝑡e ,𝐺of 𝑖( ,1 𝑡re ) ;w [a Prd (1)]𝑡−1)
Forarefinedlearningoneachuser-armdiffusionpair,wecalculate 7 and,potentialgain
thequadraticlossw.r.t.eachuserindividually,as 𝑏ˆ 𝑖,𝑡 =𝑓(2)(∇[𝑓(1)]𝑖,𝑡,𝐺 𝑖( ,2 𝑡) ;[P(2)]𝑡−1)
L(1) = ∑︁ (cid:0)𝑝ˆ𝑖𝑡 ,𝑢−𝑑 𝑢𝑡(cid:1)2. (16) 8 choosearmset𝐼 𝑡 =argmax𝐼𝑡⊂𝐾,|𝐼𝑡|=𝐿(𝑟ˆ𝑖,𝑡 +𝑏ˆ 𝑖,𝑡)and
𝑢∈𝐴𝑘𝑖 observethetruereward(spread)𝑅 𝑡 inEq.(2),which
representsthenewlyactivatedusers.
4.2.2 GNNforexploration. Similartotheusergraphpre-estimation
9
for𝑢 ∈Udo
describedinSec.4.1,wefollowtheexploration-exploitationstrat-
egybyapplyingagradient-basedexplorationfunctionw.r.t.the 10
traintheusernetworksℎ 𝑢(1) (·;P𝑢(1) ),ℎ 𝑢(2) (·;P𝑢(2) )
exploitationfunction;alsosee[2,26,40,41]forsimilarstrategies. 11 for𝑘 ∈Kdo
Inround𝑡,foreacharm𝑘 𝑖,withtheinducedexplorationgraph 12 traintheGNNmodels𝑓(1)(·;P(1)),𝑓(2)(·;P(2))
𝐺 𝑖( ,2 𝑡) wherethepre-estimatedweightsinSec.4.1.2representtheex-
13 Procedure,Estimating graphs for arm(𝑘 𝑖,𝑡)
p t𝑓 wl (o 2 er ) ea ( nt ∇io e𝑓n x( p1c ) eo , cr 𝐺 tr e𝑖e ( , d2l 𝑡a ) rt ;i ePo wn ( as 2 r)a d)m t aoo nn e dg v eau sls tu ie a mr ts e a, ttw eh de e ra p ep o wp tel ay n rdta i )n a flo ot g rh ae ainr rmG (tN h 𝑘eN 𝑖,g wm ap ho ed b re e el - 1 14 5 for Fea oc rh eu ds ge er wpa ei ir gh(𝑢 t, 𝑤𝑢 𝑖′ ( ,) 1 𝑡)∈ (𝑢U ,𝑢× ′)U ∈𝑊d 𝑖o ,( 𝑡1) ,update
∇𝑓(1) = ∇ P𝑓(1)(𝒌𝑖,𝑪𝑡;[P(1)]𝑡−1), and P(1) and P(2) are the 𝑤 𝑖( ,1 𝑡) (𝑢,𝑢′)=Φ(1)(ℎ 𝑢(1) (𝑘 𝑖,𝑡),ℎ 𝑢(1 ′) (𝑘 𝑖,𝑡))
parametersof𝑓(1) and𝑓(2) respectively. 16 Foredgeweight𝑤 𝑖( ,1 𝑡) (𝑢,𝑢′) ∈𝑊 𝑖,( 𝑡1) ,update
netW we ora kd to op lt eath rne ts ha em re epn re et sw eno tr ak tia or nc mhi ate trc it xu fr oe ra ths ein exth ple oe rax tp iolo nit ga rt aio pn
h
𝑤 𝑖( ,2 𝑡) (𝑢,𝑢′)=Φ(2)(ℎ 𝑢(2) (∇ℎ 𝑢(1) ),ℎ 𝑢(2 ′) (∇ℎ 𝑢(1 ′) ))
witha𝑘-hopsimplifiedGCN,andtopredictthepotentialgainwith 17 return𝐺 𝑖( ,1 𝑡) and𝐺 𝑖( ,2 𝑡)
an 𝐽-layer FC neural network. The architecture of 𝑓(2) can be
alsoimplementedviaEqs.(11)–(13),withtheinputfeaturevector
𝑿𝑖( ,2 𝑡) ∈ R𝑚×𝑚𝑞 andtrainablematrixP G(2) ∈ R𝑚𝑞×𝑝 intheGCN 4.2.3 IM-GNBarmselection. WesummarizetheIM-GNBframe-
model,where𝑞isthedimensionofinputgradient.IntheGCNof workinAlgorithm1.Foraninformationdiffusioncampaignwith
𝑓(2),theinputgradientmatrix𝑿𝑖( ,2 𝑡)
issimilarlyappliedtopartition
𝑇 rounds,weselect𝐿influencers(arms)fromaknowninfluencers
theweightmatrixP
G(2)
,sothateachuser-armpairisrepresented
b roa use nd𝐾 𝑡a ft oe ra ec ah chro au rn md 𝑘𝑡 𝑖,to wedi fiff ru ss te lyt ch oe ng si tv re un ctm the ess ta wg oe u𝑪 s𝑡 e. rA gt rae pac hh
s
bya𝑝-dimensionalvectorforthepurposeofexploration.
i.e.,theexploitationgraphandtheexplorationgraphviaaprocedure
In the output layer we obtain an𝑚-dimensional vector 𝑍ˆ 𝑖,𝑡,
(Lines13–17)ofpre-estimationongraphweights,whichcapture
whereeachelementrepresentstheestimatedpotentialgain𝑧ˆ𝑖𝑡
,𝑢
∈
users’correlationsintermsofexploitationandexplorationrespec-
R,𝑢 ∈ U (with |U| = 𝑚)foreachuser-armpair.Withtheesti- tively.Withthederivedgraphs,wecomputetheoverallexpected
matedpotentialgainsfromtheoutputlayer,theoverallestimated reward𝑟ˆ𝑖,𝑡 andpotentialgain𝑏ˆ 𝑖,𝑡 foreacharminEqs.(14)and(17),
potentialgainforarm𝑘 𝑖 isobtainedasthenormofoutput𝑍ˆ 𝑖,𝑡,i.e., asthenormsoftheoutputvectorsfrom𝑓(1) and𝑓(2).Next,we
𝑏ˆ 𝑖,𝑡 =∥𝑍ˆ 𝑖,𝑡∥=√︄ ∑︁ (cid:0)𝑧ˆ 𝑖𝑡 ,𝑢(cid:1)2. (17) s ee stle imct att ih oe na ar nm dps oe tt eb na tis ae ld gao in n𝑟t ˆh 𝑖,𝑡e +m 𝑏ˆ 𝑖a ,𝑡xi (m Liu nm e8o ).f Ft ih nae lls yu ,m foro ef ar ce hw ua sr ed r
𝑢∈U 𝑢 ∈U,wetraintheuser’sneuralnetworksfrompre-estimation,
Whentraining 𝑓(2) withGD,thequadraticlossiscomputed andwetrainforeacharm𝑘 𝑖 ∈𝐾 theGNNmodels(Lines9–12).
betweentheestimatedpotentialgainandtheresidualgain(thegap Weobservefromtheabovethatateachround𝑡,ℎ 𝑢(1) willtakeas
betweentherewardinEq.(15)andtheestimatedreward),as inputthefeaturevectorofacertainarm𝑘 𝑖,alongwiththecontext
L(2) = ∑︁ (cid:16) 𝑧ˆ𝑖𝑡 ,𝑢−(cid:0)𝑑 𝑢𝑡 −𝑝ˆ𝑖𝑡 ,𝑢(cid:1)(cid:17)2 . (18) v foe rct uo sr e𝑪 r𝑡 𝑢t bo ep inro gv ii nd fle ua en ni cn ei dtia bl ye ast ri mma 𝑘t 𝑖e .So un bt sh ee qd ui eff nu ts lyio ,n thp ero gb raa db ii eli nty t
𝑢∈𝐴𝑘𝑖 ofℎ 𝑢(1) isemployedasinputtoestimatethepotentialgainindiffu-
Thecomputationsoftherewardandpotentialgainaresumma- sionprobability.Parametersinℎ 𝑢(1) andℎ 𝑢(2) undergocontinuous
rizedinLines5–7inAlgorithm1. trainingandupdatingateachroundtorefinetheapproximationInfluenceMaximizationviaGraphNeuralBandits KDD’24,August25–29,2024,Barcelona,Spain
functionsforuser𝑢,predictingtheprobabilityofbeinginfluenced challengesduetotheirpotentiallylargevalues.Thisisparticu-
byanyarmwithinvariouscontexts.Similarly,fortherewardesti- larlyrelevantinSec.4.2.2,wheretheinputgradientdimensionis
mationforeacharmwith𝑓(1)and𝑓(2),𝑓(1)takesasinputthearm 𝑚(𝑑 1+𝑑 2)𝑝+(𝐽 −1)𝑝2+𝑝.Toaddressthisissue,andinspiredby
featurevectorandcontextvector,aswellasthepre-estimatedgraph approachescommonlyemployedinCNN-relatedworks,weusethe
𝐺 𝑖( ,1 𝑡) torefinetheinitialestimationonthediffusionprobability,al- averagepoolingtechniquetoeffectivelyreducetheinputdimension
lowingtoestimatetherewardacrossallusers,andthegradientof andimproveefficiency.
𝑓(1) servesastheinputofexplorationfunction𝑓(2).Both𝑓(1) and 5 EXPERIMENTS
𝑓(2) undergocontinuoustrainingtorefinetherewardestimation
Inthissection,weevaluateourmodelIM-GNBondatasetsfrom
function(exploitation)andpotentialgain(exploration).Thisitera-
TwitterandSinaWeibo.Wecompareitwithbaselinesalsodesigned
tiveprocessensuresthat𝑓(1) and𝑓(2) adapteffectivelytodiverse formulti-rounddiffusioncampaigns,andweanalyzethecompar-
contextsandusercorrelationgraphs. isonresultsintheend.Forreproducibility,theIM-GNBcodeis
availableathttps://github.com/goldenretriever-5423/IM_GNB.
4.2.4 ComplexityAnalysis. Recallfromthepreviousnotationcon- DatasetsTwitterandWeiboaretwoofthelargestsocialmedia
ventionsthatwehave|𝐾|=𝑛arms,𝑚users,andthedimensions
platforms.WecollectedtheTwitterdatasetthroughitsAPI.Inour
ofthefeaturevectorsandcontextinformationare𝑑 1and𝑑 2respec- contextanalysisforTwitter,weapply𝐾-meansclusteringonthe
tively.Forsimplicity,weuse𝑑 𝑔todenotethedimensionofallthe publicvocabularyglove-twitter-200[25],availablefromtheGen-
inputgradients,andweassumethatthesamestructureisusedfor simwordembeddingopen-sourcelibrary2.Theresultingclusters
alltheFCneuralnetworksinourmodel.Inparticular,eachneural providecentroidsthatserveasrepresentativethemeswithinthe
networkhas𝐽 layersandeachlayerhas𝑛neurons.
dataset.Subsequently,werepresentthemasadistributionacross
Forthepre-estimationofuserexploitationandexplorationgraphs, thesecentroids(10inourexperiments)toencodetweets.Eachword
ateachround,thecomplexityofthepre-definedhypothesisfunc- inatweetisassignedtoitsnearestcentroid,resultingintheoverall
tionsℎ 𝑢(1) andℎ 𝑢(2) (FCneuralnetworks)is𝑂(cid:0)|𝐾|𝑚𝐽(𝑑 1+𝑑 2)𝑛(cid:1) for distribution.Thefeaturevectoroftheinfluenceristhenormalized
exploitationand𝑂(|𝐾|𝑚𝐽𝑑 𝑔𝑛)forexploration. aggregationofallitshistoricaltweets.TheWeibodataset[39]is
FortherefinedestimationprocedurewhereweuseGCNs,aswe apubliclyavailableonebuiltforinformationdiffusionstudies.In
predictcorrelationsamongallusers,thegraphscanbeseenascom- thisdataset,eachpostisencodedwithadistributionoverthe100
plete.Assumingthattheexploration/exploitationGCNssharethe topics[39]usinglatentDirichletallocation[5].SimilartotheTwit-
sameNNstructure,thetimeandspacecomplexitiesforexploitation terdataset,thefeaturevectoroftheinfluenceristhenormalized
are𝑂(cid:0)|𝐾|𝐽(𝑚2(𝑑 1+𝑑 2)+𝑚(𝑑 1+𝑑 2)2)(cid:1) and𝑂(cid:0)|𝐾|𝐽(𝑚2+(𝑑 1+𝑑 2)2+ aggregateofthetopicdistributionofallhistoricaltweets.
𝑚(𝑑 1+𝑑 2))(cid:1) respectively,andforexploration𝑂(cid:0)|𝐾|𝐽(𝑚2𝑑 𝑔+𝑚𝑑 𝑔2)(cid:1) To simulate campaigns on social media, we assume that the
and𝑂(cid:0)|𝐾|𝐽(𝑚2+𝑑 𝑔2+𝑚𝑑 𝑔)(cid:1) . marketerhasaccesstoonlyafewmostimportantinfluencersto
Fromtheabovediscussion,wecanobservethatthenumberof diffusethemessageinthecampaigns.Hence,wefixthesizeofthe
usersandthedimensionoftheinputgradientarethemostcritical influencerset𝐾 byselectingtheuserswiththehighestnumber
parametersindeterminingthetimecomplexity.Weconsiderthe of reposts in our Twitter and Weibo logs, and we keep all the
followingmethodstoreducethecomputationalcomplexity. tweetsrelatedtothem.Thestatisticsofthedatasetsbeforeandafter
filteringaregiveninTables1and2.Ineachcampaign,werandomly
Userclustering. Inapplicationswithbillionsofusersonsocial chosethecontexts(tweets),referredtoastopicdistributions,for
media,itisimpracticalandexcessivelycostlytopredictdiffusion eachroundfromthepoolofavailablecontextswithinthedataset.
probabilitiesandcorrelationsatthegranularityofindividualusers.
Table1:Descriptionoforiginaldatasets.
Inresponsetothischallenge,wecanleveragethepostingactivity
(e.g.,retweetinghistory)ofuserstoconstructatopicdistribution
#users #originaltweets #retweets
vectorforeachuser.Wecanthenclusterusersintoaspecificnum-
berofgroups,witheachusergrouprepresentingamacro-node Twitter 11.6M 242M 341.8M
inasmallersocialgraph.Notably,thetheoreticalunderpinnings Weibo 1.8M 300K 23.8M
outlinedearlierremainapplicabletotheseclusteredusergroups,
anduser𝑢becomes𝑢 𝑐𝑖,𝑖 =1,2,...,𝑚′and∪𝑚 𝑖=′ 1𝑢
𝑐𝑖
=U,with𝑚′
denotingthenumberofclusteredgroups.Despitethisadjustment, Table2:Descriptionoffiltereddatasets.
wecontinuetorefertotheusergroup𝑢
𝑐𝑖
asuser𝑢forsimplicity.
#users #originaltweets #retweets
Theintroductionofclusteringcansignificantlyreducecompu-
tationalcost,transformingthespacecomplexityoftheadjacency Twitter 31.6k 19k 1M
matrixintheGCNfrom𝑚×𝑚toamorecomputationallyefficient Weibo 54.4k 6K 1M
scale. Experiments are carried out on the number of clustering
groupsinSec.5toshowtheimpactofthenumberofclusterson
BaselinesWecompareIM-GNBtoasetofbanditmodelsdesigned
theperformanceofthemodel.
fortheIMproblemunderthesamemulti-roundcampaignsscenario,
wheretheunderlyingnetworkisunknownandnoassumptions
Inputgradients. InSec.4.1.2andSec.4.2.2,wesawthatthein-
putdimensionsforthepreviousgradientscanposecomputational 2https://pypi.org/project/gensim/KDD’24,August25–29,2024,Barcelona,Spain Feng,Tan,andCautis
aboutthediffusionmodelsaremade.LogNorm-LinUCB[17]and issurpassedbycertainbaselinemethods,notablyGLM-GT-UCB,
GLM-GT-UCB[17]aretherecent,state-of-the-artapproachesto whichexhibitmorerapidlearningcapabilities.Weattributethis
maximizeinformationdiffusionduringsuchIMcampaigns.LogNorm- phenomenontothenatureofIM-GNBasadata-drivenmodel,typ-
LinUCBdirectlyadaptstheLinUCBalgorithmbyusinglogarith- icalofmoderndeeplearning-basedapproaches.Theefficiencyof
micnormalizationandcontextualinformationtomakesequential IM-GNBimprovesrapidlywiththeaccumulationofdata(i.e.,as
selectionsofspreadseeds,whileGLM-GT-UCBemploysagener- moreroundspassby),indicatingpotentialslowerconvergenceini-
alizedlinearmodelandtheGood–Turingestimatortodetermine tially,butyieldingbetterresultsasthenumberofroundsincreases.
theremainingpotentialofinfluencers.WealsocomparewithFAT- Additionally,theWeibodatasetisapubliclyavailabledatasetthat
GT-UCB[20],acontext-freemodelwhichhastheparticularityto consistsofartificiallyextracteddatafromdiffusioncascades,while
considerthefatigue,i.e.,aninfluencers’diminishingtendencyto theTwitterdataset,albeitsparserthanWeibo,offersinsightscloser
activatebasicusersastheyarere-seededthroughoutthecampaign. toreal-worldIMscenarios.
Wealsogeneralizeseveralstate-of-the-artneuralbanditmethods– Inbothdatasets,Lognorm-LinUCBgenerallyoutperformsthe
NeuralUCB [40] and NeuralTS [41], as well as the well-known otherbaselines.WhilethereareinstanceswhereGLM-GT-UCB
LinUCB[8]toourmulti-roundIMcampaign.Finally,wealsoim- brieflyoutperformsLognorm-LinUCBintheinitialstages,thelat-
plementareferencemodelthatrandomlychoosestheinfluencer(s) terdemonstratesstableperformancewithsmallererrorbars.This
ateachround,asin[17]. underscorestherobustnessofthelog-normalassumptiononthe
ExperimentalSettingInourexperiments,toreducethecompu- rewarddistribution.NeuralUCBandNeuralTS,asscalarizationsof
tationcost,wefirstclusteralltheusersinto50groups.Forthe thegeneralneuralbanditmodel,exhibitcomparableperformances
pre-estimationofthegraphweights,weusea3-layerFCneural acrossbothdatasets.Notably,theireffectivenesslagsbehindmod-
networkasthehypothesisclassforbothℎ 𝑢(1) andℎ 𝑢(2) ,toestimate elstailoredformulti-rounddiffusioncampaignswhen𝐿issmall.
thediffusionprobabilityandpotentialgain.ThefunctionsΦ(1) and However,when𝐿increases,themodelsareempoweredwithmore
Φ(2) thatmaptheusers’correlationstotheweightsinthegraphs data,showingmarkedperformanceimprovements.
HyperparameterAnalysis
areradialbasisfunctions(RBFs),withtheirbandwidthssetto5.For
theGCNmodel,weexploretheuseof3hops(i.e.,𝛾 =3)tocapture Number of clusters: We conduct experiments on the number of
multi-levelrelationshipswithintheusergraphs,witha3-layerFC
clustersintheTwitterdatasetwith𝐿 =2,andtheresultsonthe
neuralnetworkconnectedattheend.Thepoolingstepsizesto lastround(finalaccumulatedspread)areshowninFig.4ofthe
reducedimensions[26]fortheinputgradientsin𝑓(2) aresetto appendix.WeobservefromFig.4thatthecampaignperformance
1,000and10,000respectivelyfortheTwitterandWeibodatasets. improvesasthenumberofclustersincreasesfrom2to150atthe
beginning.However,beyond200clusters,performancebeginsto
EmpiricalResultsForadiffusioncampaign,ateachround,the
decline.Thisdeclinecanbelikelyattributedtoinsufficientdata
environmentfirstprovidesthecontext,analgorithmthenselects
withineachclusterforeffectivelearningwiththeconstraintsof
theround’sinfluencer(s),andfinally,atweetissampledforthe
alimitedbudgetonthenumberofrounds.Additionally,compu-
specificpairofinfluencer(s)andcontextfromthedataset.Thenew
tationalcostsescalateexponentiallyastheclustersizegoesup.
activations are determined by discounting the users previously
Throughtheanalysis,aclustersizeof20to50seemstostrikethe
encountered from the set of users associated with the sampled
rightbalancebetweenperformanceandcomputationalefficiency.
tweet.Allourempiricalresultsareaveragedover100independent
Thisobservationnotonlyvalidatestheinitialrationaleforcluster-
runs(themeansandstandarddeviationsarereported),andthe
ingusers,butalsounderscoresthesignificanceofcomputational
diffusionbudgetissetto500rounds.
efficiencyinoptimizingsocialcampaignsunderbudgetconstraints.
Comparisonwithbaselines:Weconductedcomparisonswithvarious
BoostedExplorationScores:Banditalgorithmsaimtostrikeadelicate
baselinesontheTwitterandWeibodatasets,varyingthenumber
ofchosenseeds(𝐿)perroundwithin{1,2,...,5}.Theresultsare balancebetweenexploitingknowninformationtomaximizeshort-
termgainsandexploringunknownoptionstoimprovelong-term
showninFig.2andFig.3respectively.Fromthetwofigures,wecan
performance.Inthisspirit,wealsoconsiderintheexperiments
observethat,acrossbothdatasets,ourmodelIM-GNBgenerally
avariantofexploration,inwhichweboosttheexplorationscore
outperformsthebaselines.Notably,ontheTwitterdataset,IM-GNB
ofunchosenarmshavingzerorewardoutcomes,toincreasethe
exhibitsasignificantlyincreasedadvantageoverthebaselines,as
thenumberofseedsincreasesupto𝐿=3.However,thisadvantage likelihoodofexploringalternativearms.Werunexperimentson
diminishesas𝐿continuestogrow,astheprobabilityofselecting
theTwitterdatasetwith𝐿=2comparingtheuseofsuchartificially
boostedexplorationagainstitsabsence.Theresultsarepresented
thecorrectarmsincreasesforallmodels.Infact,fortheextreme
scenariowhere𝐿=|𝐾|=10,thisresultsinthesameperformances in Fig. 5 in the appendix, and confirm the effectiveness of this
approach;thisfurthersupportstheimportanceofexplorationto
acrossallmodelsduetotheselectionoftheentirebasesetofseeds.
uncovervaluableinsightsandoptimizeonlinedecisionmaking.
Similarly,fortheWeibodataset,IM-GNBdemonstratesitslargest
advantageat𝐿=4.Theseresultsvalidateourmotivationtoleverage
6 CONCLUSION
theexpressivityofbothneuralnetworksandbanditalgorithmsin
Insummary,ourIM-GNBframeworkseamlesslyleveragestheex-
IMcampaigns,enablingustoeffectivelycapturedynamicuser-user
pressivityofGNBstotacklethechallengesofmulti-roundIMin
anduser-influencerinteractionsusingGNBs.
uncertainenvironments.Ournovelapproachtackleskeyissuesin
Itisworthnotingthat,intheWeibodataset,particularlywhen
𝐿 is small (e.g.,𝐿 = 1,2), the performance in the initial rounds learningfromgraph-structureddataandmakessequentialdecisions
inuncertainenvironments.Byincorporatingcontextualbandits,InfluenceMaximizationviaGraphNeuralBandits KDD’24,August25–29,2024,Barcelona,Spain
Figure2:ComparisonofIM-GNBwithbaselinesontheTwitterdataset.
Figure3:ComparisonofIM-GNBwithbaselinesontheWeibodataset.
weobtaininitialestimatesofdiffusionprobabilitiestoconstruct Acknowledgements. ThisworkisfundedbytheSingaporeMinistry
exploitationandexplorationgraphs.Subsequently,theseestimates ofEducationAcRFTier2(A-8000423-00-00).Thisresearchispart
arerefinedwithGCNs,toenhancetheinfluencespread.Theframe- of the programme DesCartes and is supported by the National
work’sscalability,evenwithoutpriorknowledgeofthenetwork Research Foundation, Prime Minister’s Office, Singapore under
topology,makesitavaluableandversatiletoolforoptimizingdif- itsCampusforResearchExcellenceandTechnologicalEnterprise
fusioncampaigns. (CREATE)programme.TheauthorsthankFengzhuoZhangand
JunwenYang(bothNUS)forvaluablediscussions.KDD’24,August25–29,2024,Barcelona,Spain Feng,Tan,andCautis
REFERENCES
[28] PaatRusmevichientongandJohnNTsitsiklis.2010. Linearlyparameterized
[1] NaokiAbe,AlanWBiermann,andPhilipMLong.2003.Reinforcementlearning bandits.MathematicsofOperationsResearch35,2(2010),395–411.
withimmediaterewardsandlinearhypotheses.Algorithmica37(2003),263–293. [29] LichaoSun,WeiranHuang,PhilipSYu,andWeiChen.2018. Multi-round
[2] Yikun an, Yuchen Yan, Arindam Banerjee, and Jingrui He. 2022. EE-Net: influencemaximization.InProceedingsofthe24thACMSIGKDDInternational
Exploitation-ExplorationNeuralNetworksinContextualBandits.InProceedings ConferenceonKnowledgeDiscovery&DataMining.2249–2258.
ofInternationalConferenceonLearningRepresentations. [30] YouzeTang,YanchenShi,andXiaokuiXiao.2015. InfluenceMaximization
[3] YikunBanandJingruiHe.2021. Localclusteringincontextualmulti-armed inNear-LinearTime:AMartingaleApproach.InProceedingsofthe2015ACM
bandits.InProceedingsoftheWebConference2021.2335–2346. SIGMODInternationalConferenceonManagementofData.1539–1554.
[4] YikunBan,JingruiHe,andCurtissBCook.2021.Multi-facetcontextualbandits: [31] YouzeTang,XiaokuiXiao,andYanchenShi.2014.Influencemaximization:Near-
Aneuralnetworkperspective.InProceedingsofthe27thACMSIGKDDConference optimaltimecomplexitymeetspracticalefficiency.InProceedingsofthe2014
onKnowledgeDiscovery&DataMining.35–45. ACMSIGMODInternationalConferenceonManagementofData.75–86.
[5] DavidMBlei,AndrewYNg,andMichaelIJordan.2003.LatentDirichletalloca- [32] MichalValko,NathanielKorda,RémiMunos,IliasFlaounas,andNeloCristian-
tion.JournalofMachineLearningResearch3,Jan(2003),993–1022. ini.2013. Finite-timeanalysisofkernelisedcontextualbandits.InProc.ofthe
[6] ChristianBorgs,MichaelBrautbar,JenniferChayes,andBrendanLucier.2014. UncertaintyinArtificialIntelligence(UAI).
Maximizingsocialinfluenceinnearlyoptimaltime.InProceedingsoftheTwenty- [33] SharanVaswani,BranislavKveton,ZhengWen,MohammadGhavamzadeh,Laks
FifthAnnualACM-SIAMSymposiumonDiscreteAlgorithms.SIAM,946–957. V.S.Lakshmanan,andMarkSchmidt.2017.Model-IndependentOnlineLearn-
[7] SébastienBubeck,RémiMunos,GillesStoltz,andCsabaSzepesvári.2011. X- ingforInfluenceMaximization.InProc.ofthe34thInternationalConferenceon
ArmedBandits.JournalofMachineLearningResearch12,5(2011). MachineLearning.3530–3539.
[8] WeiChu,LihongLi,LevReyzin,andRobertSchapire.2011.Contextualbandits [34] SharanVaswani,LaksLakshmanan,andMarkSchmidt.2015.Influencemaxi-
withlinearpayofffunctions.InProc.oftheFourteenthInternationalConference mizationwithbandits.arXivpreprintarXiv:1503.00024(2015).
onArtificialIntelligenceandStatistics.208–214. [35] ZhengWen,BranislavKveton,MichalValko,andSharanVaswani.2017.Online
[9] VarshaDani,ThomasPHayes,andShamMKakade.2008. Stochasticlinear influencemaximizationunderindependentcascademodelwithsemi-bandit
optimizationunderbanditfeedback.InProceedingsoftheConferenceonLearning feedback.AdvancesinNeuralInformationProcessingSystems30(2017).
Theory.355–366. [36] FelixWu,AmauriSouza,TianyiZhang,ChristopherFifty,TaoYu,andKilian
[10] PedroM.DomingosandMatthewRichardson.2001.Miningthenetworkvalue Weinberger.2019. Simplifyinggraphconvolutionalnetworks.InProc.ofthe
ofcustomers.InProceedingsoftheseventhACMSIGKDDinternationalconference InternationalConferenceonMachineLearning.PMLR,6861–6871.
onKnowledgediscoveryanddatamining,SanFrancisco,CA,USA,August26-29, [37] QingyunWu,ZhigeLi,HuazhengWang,WeiChen,andHongningWang.2019.
2001.57–66. Factorizationbanditsforonlineinfluencemaximization.InProceedingsofthe25th
[11] NanDu,LeSong,ManuelGomez-Rodriguez,andHongyuanZha.2013.Scalable ACMSIGKDDInternationalConferenceonKnowledgeDiscovery&DataMining.
influenceestimationincontinuous-timediffusionnetworks.InConferenceon 636–646.
NeuralInformationProcessingSystems.3147–3155. [38] TomZahavyandShieMannor.2020.Deepneurallinearbandits:Overcoming
[12] ShanshanFeng,GaoCong,ArijitKhan,XiuchengLi,YongLiu,andYeowMeng catastrophicforgettingthroughlikelihoodmatching.InInternationalConference
Chee.2018.Inf2vec:Latentrepresentationmodelforsocialinfluenceembedding. onLearningRepresentations.
In2018IEEE34thInternationalConferenceonDataEngineering(ICDE).IEEE, [39] JingZhang,BiaoLiu,JieTang,TingChen,andJuanziLi.2013.SocialInfluence
941–952. LocalityforModelingRetweetingBehaviors.InProc.oftheInternationalJoint
[13] ManuelGomez-RodriguezandBernhardSchölkopf.2012.InfluenceMaximization ConferenceonArtificialIntelligence(IJCAI).
inContinuousTimeDiffusionNetworks.InProceedingsoftheInternational [40] WeitongZhang,DongruoZhou,LihongLi,andQuanquanGu.2021. Neural
ConferenceonMachineLearning. Thompsonsampling.InternationalConferenceonLearningRepresentation(2021).
[14] AmitGoyal,FrancescoBonchi,andLaksVSLakshmanan.2010.Learninginflu- [41] DongruoZhou,LihongLi,andQuanquanGu.2020.Neuralcontextualbandits
enceprobabilitiesinsocialnetworks.InProceedingsoftheThirdACMInternational withUCB-basedexploration.InProc.oftheInternationalConferenceonMachine
ConferenceonWebsearchandDataMining.241–250. Learning.11492–11502.
[15] AmitGoyal,FrancescoBonchi,andLaksVSLakshmanan.2011.AData-Based
ApproachtoSocialInfluenceMaximization.InProc.VLDBEndow.73–84.
[16] KekeHuang,SiboWang,GlennS.Bevilacqua,XiaokuiXiao,andLaksV.S.
Lakshmanan.2017.RevisitingtheStop-and-StareAlgorithmsforInfluenceMaxi-
mization.Proc.VLDBEndow.10,9(2017),913–924.
[17] AlexandraIacob,BogdanCautis,andSilviuManiu.2022.Contextualbanditsfor
advertisingcampaigns:Adiffusion-modelindependentapproach.InProceedings
ofthe2022SIAMInternationalConferenceonDataMining(SDM).SIAM,513–521.
[18] DavidKempe,JonKleinberg,andÉvaTardos.2003.Maximizingthespreadof
influencethroughasocialnetwork.InProceedingsoftheNinthACMSIGKDD
InternationalConferenceonKnowledgeDiscoveryandDataMining.137–146.
[19] ThomasNKipfandMaxWelling.2016.Semi-supervisedclassificationwithgraph
convolutionalnetworks. InternationalConferenceonLearningRepresentations
(2016).
[20] PaulLagrée,OlivierCappé,BogdanCautis,andSilviuManiu.2018.Algorithms
foronlineinfluencermarketing.ACMTransactionsonKnowledgeDiscoveryfrom
Data(TKDD)13,1(2018),1–30.
[21] TorLattimoreandCsabaSzepesvári.2020.BanditAlgorithms.CambridgeUni-
versityPress.
[22] YandiLi,HaoboGao,YunxuanGao,JianxiongGuo,andWeiliWu.2023.ASurvey
onInfluenceMaximization:FromanML-BasedCombinatorialOptimization.ACM
Trans.Knowl.Discov.Data17,9,Article133(Jul2023),50pages.
[23] HungTNguyen,MyTThai,andThangNDinh.2016.Stop-and-stare:Optimal
samplingalgorithmsforviralmarketinginbillion-scalenetworks.InProceedings
ofthe2016internationalconferenceonmanagementofdata.695–710.
[24] GeorgePanagopoulos,FragkiskosDMalliaros,andMichalisVazirgiannis.2020.
Multi-tasklearningforinfluenceestimationandmaximization.IEEETransactions
onKnowledgeandDataEngineering34,9(2020),4398–4409.
[25] JeffreyPennington,RichardSocher,andChristopherDManning.2014.Glove:
Globalvectorsforwordrepresentation.InProc.ofthe2014ConferenceonEmpirical
MethodsinNaturalLanguageProcessing(EMNLP).1532–1543.
[26] YunzheQi,YikunBan,andJingruiHe.2023.GraphNeuralBandits.InProceedings
ofthe29thACMSIGKDDConferenceonKnowledgeDiscoveryandDataMining.
1920–1931.
[27] CarlosRiquelme,GeorgeTucker,andJasperSnoek.2018.DeepBayesianbandits
showdown.InInternationalConferenceonLearningRepresentations,Vol.9.InfluenceMaximizationviaGraphNeuralBandits KDD’24,August25–29,2024,Barcelona,Spain
A SUPPLEMENTARYCOMPLEXITY Theypertaintotheanalysisofthenumberofclusteringgroups
EXPERIMENTS andforartificiallyboostedexploration.
Fig.4showsthatthecampaignperformanceimprovesasthe
WeprovideinTable3acomparisononrunningtime(inhours)w.r.t.
thenumberofclusteringgroups𝑚′when𝐿=2.Wecanobserve numberofclustersincreasesfrom2to150atthebeginning.How-
ever,beyond200clusters,performancebeginstodecline.Thisde-
thatafinergranularity(moregroups)maynotresultinbetterper-
clinecanbelikelyattributedtoinsufficientdatawithineachcluster
formance(asshowninFig.4),whilecostgoesupexponentially.We
for effective learning under the constraints of a limited rounds
chose50groupsthatrepresentsagoodtradeoffbetweenaccuracy
budget.
andcomplexityinourexperiments.
Fig.5confirmstheeffectivenessofartificiallyaugmenting/boost-
ingtheexplorationscoreoftheunchosenarmswithzeroreward
Table3:Resultsforrunningtime.
outcomes,inordertoincreasethelikelihoodofexploringalterna-
tivearms.
𝑚′ 2 5 10 20 50 100 150 200 250
runningtime 5.35 7.02 9.71 12.35 41.43 125.49 225.67 391.54 735.35
B ANALYSISONTHENUMBEROF
CLUSTERINGGROUPSANDFOR
ARTIFICIALEXPLORATION
Twitter - L=2 - round=500
34000
33000
32000
31000
30000
2 5 10 20 50 100 150 200 250
#clusters
Figure4:Analysisonthenumberofclusteringgroups.
Twitter - L=2
explore
30000 non-artifical
artificial
25000
20000
15000
10000
5000
0
0 100 200 300 400 500
rounds
Figure5:Analysisonartificiallyboostedexploration.
Here,wepresenttheremainingfigures(Figs.4and5)thatwere
mentionedinthemaintextbutomittedduetospaceconsiderations.
daerps
evitalumuc
daerps
evitalumuc