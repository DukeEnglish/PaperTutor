Instruct, Not Assist:
LLM-based Multi-Turn Planning and Hierarchical Questioning
for Socratic Code Debugging
PriyankaKargupta∗,IshikaAgarwal∗,DilekHakkani-Tur,JiaweiHan
1DepartmentofComputerScience,UniversityofIllinoisatUrbana-Champaign
{pk36, ishikaa2, dilek, hanj}@illinois.edu
Abstract
Student: Hey, I really need help. My Fibonacci function
is not returning the correct number.
Socratic questioning is an effective teaching
Single-Turn Assistant: I'll be happy to help you. You made
strategy, encouraging critical thinking and an error in the recursive function. Here is the corrected code:
problem-solving. Theconversationalcapabil-
ities of large language models (LLMs) show
greatpotentialforprovidingscalable,real-time
studentguidance. However,currentLLMsof-
tengiveawaysolutionsdirectly,makingthem
ineffective instructors. We tackle this issue Multi-Turn Instructor: I'll be happy to help you. How is the
in the code debugging domain with TreeIn- Fibonacci sequence defined and computed?
struct, anInstructoragentguidedbyanovel Student: The Fibonacci sequence is a series of numbers in
statespace-basedplanningalgorithm. TreeIn- which each number is the sum of the two preceding ones.
structasksprobingquestionstohelpstudents Instructor: That is correct! Let's take a step further. How
are you utilizing recursion for computing the sequence?
independentlyidentifyandresolveerrors. Ites-
…
timatesastudent’sconceptualandsyntactical
Student: Oh, I see. I made an error in the recursive
knowledge to dynamically construct a ques- condition. I should change n-2 to n-1.
tiontreebasedontheirresponsesandcurrent
Figure1: TheInstructor’sgoalistogeneratemulti-turn
knowledge state, effectively addressing both
SocraticquestionswhileguidingtheStudenttowards
independent and dependent mistakes concur-
thecorrectsolution.
rently in a multi-turn interaction setting. In
additiontousinganexistingsingle-bugdebug-
gingbenchmark,weconstructamorechalleng- theuseofLLMsforprovidingfeedbackandguid-
ingmulti-bugdatasetof150codingproblems, ancetostudents(Wangetal.,2023;Kazemitabaar
incorrectsolutions,andbugfixes–allcarefully etal.,2024;Sheeseetal.,2024;Lyuetal.,2024).
constructedandannotatedbyexperts. Exten-
However,LLMsaretypicallyoptimizedtogenerate
sive evaluation shows TreeInstruct’s state-of-
customer-serving,assistant-likeresponses,which
the-artperformanceonbothdatasets,provingit
also translates into the types of questions asked.
tobeamoreeffectiveinstructorthanbaselines.
Furthermore,areal-worldcasestudywithfive This style of questioning can be sub-optimal de-
studentsofvaryingskilllevelsfurtherdemon- pendingonthespecificdomainthatquestiongener-
stratesTreeInstruct’sabilitytoguidestudents ationisappliedto,especiallyeducationaldomains
to debug their code efficiently with minimal (Cotton,1988;Sahamid,2016;Yangetal.,2005;
turnsandhighlySocraticquestioning.
Wilson,1987). Forinstance,ifastudentisseeking
helpfromaninstructorforcorrectingtheirmistakes
1 Introduction (e.g., debugging their buggy code), we consider
two forms of potential responses: assistant-like
Withtherapidlyexpandingconversationalandrea-
and instructor-like. As shown in Figure 1, an
soningabilitiesoflargelanguagemodels(LLMs),
assistant-like response would not be a successful
there has been a substantial rise in demand for
educationalinteractionasitleadstotheAssistant
exploitingtheircapabilitieswithinamultitudeof
directly providing an answer. On the other hand,
educationalapplications(Kasnecietal.,2023)in
anInstructor-likeresponsereflectstheeducational
orderto widenaccessibility topersonalizedfeed-
philosophyofSocraticquestioning.
back. Specifically, several recent works explore
Socraticquestioningisateachingstrategywhere
*Theseauthorscontributedequallytothiswork. the Student independently solves their problem
4202
nuJ
71
]LC.sc[
1v90711.6042:viXrabyansweringguidingquestions,insteadofbeing (state variables) to be resolved in order to com-
given the solution directly (Wilson, 1987). This prehend and correct their bug(s). We define all
is a more effective learning strategy because the potentialpathstocompletethesetasksasthestate
weightoflearningfallsontheStudentastheymust space. WetraversethespaceusingSocraticques-
put in effort to answer a question as opposed to tionsandtracewhichvariableshavebeenresolved,
solelyrelyingonthemodel(Cotton,1988;Kasneci groundedbasedontheStudent’sresponses.
et al., 2023). Therefore, we aim to re-orient an While existing LLM-based tutors are effective
LLMtobeanInstructor,notanassistant,byasking infixingtheStudent’scodewithhighsuccess,they
Socraticquestionsthat(1)helptheStudentunder- areeitherpronetodirectlyrevealingcodeanswers
standtheirmistakes,and(2)donotdirectlyprovide orcannotbeadaptedtonewStudentresponses. For
theanswer. Totacklethesechallenges,wepropose example,CodeAid(Kazemitabaaretal.,2024)di-
TreeInstructbasedonthefollowingprinciples: rectlyrevealsthecodeanswerandprovidescode
57% of the time. It achieves a mere 55% rate of
1. Statespaceestimation: AnInstructorplansits
helpfulness. On the other hand, TreeInstruct ex-
conversationwithaStudentbasedonthe“dis-
ploits the state space to dynamically construct a
tance”betweentheirinitialanswerandtheop-
tree of questions based on (1) incorrect Student
timal,correctanswerwithintheestimatedstate
responses,or(2)gapsintheStudent’sknowledge.
space. Inotherwords,ittrackstheknowledge
Thesiblingandparent-childrelationshipsbetween
stateoftheStudentwithinthisspacethroughout
questionsreflectthemannerinwhichtheytraverse
theInstructor-Studentinteractions.
the state space. Finally, it exploits both the Stu-
2. Tree-basedSocraticquestioning: AnInstruc- dent’sknowledgestateandanyproposedbugfixes
torgeneratesturn-levelSocraticquestionscon- toserveasthedynamicstoppingcondition. Overall,
ditioned on both the Student’s current knowl- TreeInstruct takes a more structured approach to
edge state and misunderstanding(s), the latter multi-turnconversationalfeedback,as(1)ground-
derivedfromtheirresponsestotheInstructor’s ingtheconversationonthestatespacerepresenta-
questions. This step dynamically constructs a tionensuresthatallbugsaresufficientlyaddressed,
Socracticquestiontree. and(2)constructingatreebasedontheStudent’s
3. Adaptiveconversationrestructuring: AnIn- currentlevelofunderstandingallowsformorerel-
structor updates their initial conversation plan evantandpersonalizedquestiongeneration.
based on how the Student is progressing in Wesummarizeourcontributionsbelow:
the conversation, as reflected by updates (or
• Tothebestofourknowledge,TreeInstructisthe
lackthereof)totheStudent’sknowledgestate.
firstworktoexplorestatespaceestimationand
Thisplanningcanincludebothquestioningand
dynamic tree-based questioning for multi-turn
teachingactions.
Socraticinstruction.
While these principles can apply to many edu- • Weconstructanovelchallengingmulti-bugde-
cational domains, this paper focuses on code de- buggingdatasetwith150expert-annotatedcon-
bugging,whichpresentsuniquechallenges. Real- ceptualandsyntacticalproblemsandbuggysolu-
worldcodedebuggingofteninvolvesmultiple,po- tions/fixes.
tentiallyinterdependentconceptualandsyntactical • Extensiveexperimentsonanexistingbenchmark
bugs. For instance, Figure 1 shows that first re- and our constructed dataset demonstrate that
solvingtheStudent’sconceptualmisunderstanding TreeInstruct can be universally applied to both
ofrecursioninFibonaccihelpsthemidentifytheir openandclosedsource-settings.
recursivesyntacticalbug(Figure1). However,ex-
• WealsoshowcasethatTreeInstruct’sstrongSo-
istingworkfailstoaccountforsuchnuancesand
cratic questioning abilities widely outperform
assumessingle-turnfeedback(Kazemitabaaretal.,
allbaselinesthroughboth(1)rigorousquantita-
2024; Wang et al., 2023; Lyu et al., 2024). This
tive and qualitative expert evaluation (on aver-
ignores the sub-steps required for the Student to
age,preferredover78.43%ofthetime)and(2)
understandeachbug.
real-worldinteractionswithstudentsofvarying
Incontrast,TreeInstructconstructsamulti-turn
codingabilities.
debuggingplan(staterepresentation), definedas
thesetofStudentmisunderstandingsandmistakes Reproducibility: Wereleaseourdataandsourcecode1 tofacilitatefurtherstudies. 2.3 LLMsforInteractiveEducation
RecentgenerativeapproacheswithintheAItutor-
2 RelatedWorks
ing space have attempted to generate responses
whichcatertothestudent’stypeofmistakeorre-
2.1 KnowledgeTracing
quest, but only in single-turn settings. CodeAid
Knowledgetracingtracksstudentknowledgetoper-
(Kazemitabaar et al., 2024) is an assistive tool
sonalizetheirlearningexperience,includingunder-
that helps students debug their code. However,
standingspecificconcepts,behavior,andrecallabil-
the Instructor is specifically designed to directly
ity. Therearetwoprimarymethods: probabilistic
providesingle-turnresponsestotheStudent,such
anddeeplearning-based. Probabilisticknowledge
as answering student questions, explaining con-
tracing, as it was first introduced, uses a Hidden
cepts,andhelpingtowritecode. Incontrast,Tree-
MarkovModel(HMM)tomaintainbinarystates,
Instruct aims to instruct the Student socratically
learned and unlearned, for each skill as learners
through questions. BRIDGE (Wang et al., 2023)
engagewithexercises. Thisapproach,fromwhich
is an Instructor-like framework that aims to help
wedrawinspiration,updatesthelikelihoodofthese
studentswithmathmistakes. TheLMestimatesthe
states based on performance (Corbett and Ander-
typeoferror,thestrategyoferrorremediation,and
son,1994;Yudelsonetal.,2013). Somemodelsuse
theinstructorintentionbehindtheremediation(all
open-endedpathstostates(Raffertyetal.,2016),
are chosen from a predetermined set). However,
while others use deep learning-based, long-term
ourmethodologymakesuseofamorestructured
memorycapabilitiesessentialforlearning(Piech
approachthatworkswellformulti-turnconversa-
etal.,2015). Thesemethodsareperformative,but
tionswhileadaptingtotheStudent’slearning.
suchstatespaceshindereffectivenessandrequire
largeamountsofannotatedtrainingdata. Input:
Problem Statement,
Our methodology addresses the challenge of Buggy Code, Correct Code
Instructor Student Verifier
limitedannotateddatabydynamicallygenerating
State Space Estimation
statesduringinteractionsbetweeninstructorsand
State Variable Value
students. Wemonitortheseevolvingstatesthrough
Task 1 (e.g., Understand) False
acomponentwerefertoastheVerifier. Usingthese
Task 2 (e.g., Recognize) False
dynamicallygeneratedstates,wetailortheeduca-
Task 3 (e.g., Modify) False
tional experience by personalizing the sequence
tasks to lead student to
andtypeofquestionsposedtolearners. Buggy Code → u n derstanding their conceptual → Correct Code
and syntactical mistakes
2.2 SocraticReasoninginEducationalAI
Tree-Based Questioning
TherehavebeenseveralworksexploringSocratic
Nodes:
reasoning in education (Herbel-Eisenmann and Instructor’s state Update state
variable guided representation
Breyfogle,2005;WangandDemszky,2024;Alic questions True, True, False
et al., 2022; Demszky and Hill, 2022). More re- Edges:
Path to new
cently,priorwork (Al-Hossamietal.,2023b,a)has understanding
based on Student Output:
highlighted the poor performance of prompting- response and Final bug fixes
basedmethodsinperformingSocraticReasoning Verifier analysis from Student
for the education domain (Achiam et al., 2023),
Figure2: WeproposeTreeInstruct,anoveltree-guided
even with Chain-of-Thought (CoT) (Wei et al.,
instructionalquestioningframeworkformeaningfuled-
2022), as they often give away answers without ucationaldebuggingguidance.
asking clarifying questions, or the questions are
unrelatedtothestudent’sresponseororiginalbug 3 Methodology
(Achiametal.,2023). Incontrast,TreeInstructmiti-
As shown in Figure 2, TreeInstruct aims to dy-
gatesthisissuebyexplicitlygroundingthequestion
namicallyguidethemulti-turnconversationbased
generationsteponbothatargetstatevariableτ and
onitsestimatedstatespace. Section3.1.2provides
anyStudentmisunderstandinggaugedfromtheir
an overview of the three different agents we use
previousresponse.
and their respective roles during the state space
1https://github.com/agarwalishika/TreeInstruct generation/updateandtreeconstructionprocessesAlgorithm1TreeInstruct
Require: P (ProblemDescription),B(BuggyCode,BugDescriptions),C(CorrectedBCode,BugFixes)
1: S ={τ ,τ ,...,τ }←GenerateState(P,B,C) ▷Section3.2:Staterepresentation:(resolved?,task)
1 2 k
2: l←0,Q←{l:[]},H ←[],F ←{} ▷Treelevel,questionlist/level,conv.history,Studentbugfixes
3: q←GenerateQuestion(P,B,C,τ ) ▷Section3.3:Generateinitialquestion
1
4: while∃τ ∈Ss.t.¬isResolved(S,F,C)do ▷Section3.4:Processwhiletasksorbugsremain
5: r←StudentResponse(q)
6: v,w←VerifyResponse(q,r) ▷Section3.3:isrtoqcorrect(v);whyorwhynot(w)?
7: H.add(q,r)
8: Q[l].add(q)
9: ifv=falsethen ▷Incorrectstudentresponse
10: q←GenerateSiblingQuestion(τ,Q[l],H,w) ▷Section3.3:factorinwhythestudentwasincorrect
11: else ▷Correctstudentresponse
12: S,w←UpdateUnderstanding(S,q,r) ▷Section3.3:tasksτ ...τ resolved?If¬S[τ],why(w)?
i k
13: if¬S[τ]then
14: q←GenerateChildQuestion(τ,Q[l],H,w) ▷Section3.3:factorinwhyτ wasunresolved
15: l←l+1 ▷Advancetonexttreelevel
16: else ▷Taskτ resolved
17: F ←GetStudentBugFixes(H) ▷Section3.4:askStudentforbugfixes(ifany)
18: l←0,Q←{l:[]} ▷τ resolved→createnewtree
(outlinedinFigure3). ThisallowsTreeInstructto 1. State space estimation (Section 3.2): The
respondtotheStudent’scurrentlevelofunderstand- Verifier determines a set of tasks which will
ingadequately. Algorithm1containsthepseudo- lead a Student’s to understanding and correct-
codeforallcomponentsinourmethod. ing their problem and buggy code. This is
GenerateStateinAlg. 1.
3.1 Preliminaries
2. Assess Student Response (Section 3.3): Once
3.1.1 ProblemDescription
the Student answers the Instructor’s question,
Asinput,theInstructorisgiventheStudent’sbuggy theVerifiermustjudgetheresponse’saccuracy,
code that contains e errors, a problem statement, giventhequestion-answerpairinteraction. This
bug descriptions, and their respective fixes. The isVerifyResponseinAlg. 1.
Instructor guides the Student to generate a list of
3. Assess Student Understanding of Target State
all bug fixes based on their interactions with the
Variable(Section3.3): ToupdatetheStudent’s
Instructor. The overall goal is for the Student to
statespacerepresentation,theVerifiermustde-
resolvetheirownconceptualandsyntacticalerrors
terminewhethertheStudentwouldhaveneeded
inaSocraticfashiontoreachthecorrectcode.
asufficientunderstandingofthetargetstatevari-
ableinordertogeneratetheirresponse. Thisis
3.1.2 Agents
UpdateUnderstandinginAlg. 1.
In a real-world setting, a Socratic educator (e.g.,
aninstructor,ateachingassistant,aprofessor)ex- 4. Verify Student Bug Fixes (Section 3.4): Each
ecutestwotaskswheninteractingwithaStudent: timetheStudentunderstandsatargetstatevari-
(1) ask relevant questions to the Student, and (2) able, they are asked to provide, if any, recom-
assesstheStudent’sunderstandingbasedontheir mendedbugfixesbasedontheconversationhis-
responses. Followingthiscyclicalpattern,webreak tory. Thisservesasanearlystoppingcondition.
downoureducatorintotworoles: anInstructorand ThisisisResolvedinAlg. 1.
aVerifier,withpersonapromptsspecifiedinTables
3.2 StateSpaceEstimation
9and11inAppendixI,respectively. TheInstructor
andVerifierperformtheirrespectivetasksspecified Thegoalofstatespaceestimationistodetermine
in Algorithm 1 via zero and one-shot prompting. theoptimalcriteriatotrackaStudent’sglobalun-
TheInstructoragent’sjobistogeneratequestions derstanding of a problem P and their code, such
toasktheStudent(GenerateQuestion,GenerateSi- thatfromtheinitialbuggystateB,wecantraverse
blingQuestion,andGenerateChildQuestioninAlg. thespacetoreachthegoalstate(correctcodeC).
1; details provided in Section 3.3). The Verifier Wedefinethestatespaceasthesetofallpossi-
agenthasasignificantlymoreinvolvedrole: ble tasks that a Student could perform to correctTree-Based Questioning (Section 3.3) A→B indicates B is generated conditioned on A
1
1 → Instructor: I'll be happy to help you. How is the Fibonacci sequence defined and computed? Create New Tree #1
Student: The nth term in the Fibonacci sequence is the sum of the n-1 and n-2 terms.
Answers correctly & understands
1 True Understand the definition of the Fibonacci Sequence. target state attribute 1. 2
2 False Recognize that the recursive call only returns the sequence till the (n-2)th term.
Update State and
2 → Instructor: How are you utilizing recursion for computing the sequence? Create New Tree #2
Student: I recursively call the fibonacci function to get the sequence up till the (n-1)th term to retrieve the
preceding two terms.
, Does not properly understand their code and hence answers incorrectly. Answers incorrectly 2
2 → Instructor: That's not entirely correct. Let’s walk through your code; if you call fibonacci(3), what will Use Answer Feedback
sequence be initialized to? to Generate Sibling
Student: It will be set to [0].
2 False Did not recognize that their recursive call uses the wrong argument (n-2). Answers correctly; 2
doesn’t understand
target state attribute. 2.
2 → Instructor: That’s correct! And is this sufficient for the computation on line 10?
Use State Feedback to
Student: No, we expect [0,1] instead. I made an error in the recursive condition. I should change n-2 to n-1. Generate Child
2 True Recognize that the recursive call only returns the sequence till the (n-2)th term.
3 True Modify the recursive call from fibonacci(n-2) to fibonacci(n-1).
Figure3: Wedetailtheprocessfortree-basedquestiongeneration. Blueandorangetext/backgroundsindicatethat
theInstructorandVerifierareperformingthetaskrespectively.
theirbuggycode. Weclaimthattheoptimalstate 3.3 Tree-BasedQuestioning
space can be represented by a series S of k tasks
whichleadstheStudentfromtheirbuggycodeB Tree-basedquestioninghelpstostructurethelog-
to (1) understanding their conceptual and syntac- icalflowoftheconversationandallowsformore
ticalmistakesand(2)correctingtheircode. Each relevant,personalizedquestions. Weuseatreeto
of these tasks is a state variable τ which either encodetheStudent’spathtounderstandingatleast
i
has a value of True or False based on whether or onespecifictargetstatevariableτ . Ineachtree,(1)
i
nottheStudenthascompletedit. Attheverybegin- nodesarequestions,(2)siblingnodesreflectques-
ningoftheInstructor-Studentconversation,allof tionswhichaimtosequentiallysolidifythecurrent
thesevariablesaresetto“False”. Weprovidethe misunderstanding,and(3)eachoftheparent-child
estimatedstatespaceusedinFigures2and3. edgesconnectnodesthatguidetonewunderstand-
ing. GuidedbythestatespaceinSection3.2,each
1. τ : False, Understand the definition of the Fi- levellinthetreehasquestionsq ofasimilardiffi-
1
bonacciSequence. cultyanddepth;thelastlevelofthetreeindicates
thataspecificstatevariablehasbeenresolved. The
2. τ : False,Recognizethattherecursivecallonly
2
returnsthesequencetillthe(n−2)th term. Verifieragentdictatesthemovementfromlevelto
levelandtreetotree.
3. τ : False,Modifytherecursivecallfromfib-
3
onacci(n-2)tofibonacci(n-1).
Conditional generation of sibling questions.
The state variables τ are structured such that TheInstructorconditionallygeneratessiblingques-
i
earlier tasks have a higher priority, as their com- tionsatlevellifandonlyiftheStudentincorrectly
pletionmayconsequentlyresolvelatertasks. For answerstheInstructorquestion(lines6and10in
instance, a student’s buggy code may reflect that Alg. 1). Asshowninthesecondandthirdquestion
theydonotunderstandanedgecasementionedin ofFigure3,thesequestionsmustleadtothesame
theproblemstatement. However,oncethismisun- leveloftargetunderstandingastheoriginalgener-
derstandingisresolved,theStudentmaysimultane- ated question intended so therefore, the question
ouslycorrecttheirrelatedsyntacticalmistakes. On canberephrasedormademorespecific. Toensure
theotherhand,attemptingtoresolvethesyntactical this,wegroundthequestiongenerationbasedon
mistakes,“Modifyingtheconditionintheifstate- twothings: (1)thepreviousquestionsfrom level
ment”, beforehand may lead to an unproductive l, and (2) the Verifier’s explanation for why the
andlessstructuredconversationoverall. Studentgotthequestionwrong.Conditionalgenerationofchildquestions. The 4 Experiments
Instructorconditionallygenerateschildquestions
4.1 ExperimentalSetup
atlevell+1ifandonlyiftheStudentcorrectlyan-
swerstheInstructorquestion(addressestheques- In order to evaluate TreeInstruct, we uti-
tionandhasnomistakesintheiranswer),butstill lize a proxy Student agent based on the
doesnotunderstandthetargetstatevariableτ (line Mistral-7B-Instruct model (?) to mimic
i
14inAlg. 1). Asshowninthefourthquestionof the abilities of a student while responding to the
Figure3,thesequestionsaimtoguidetheStudent Instructor. ThepromptweusetodefinetheStudent
toamorecompleteunderstandingofthetargetstate. personaisoutlinedinTable10ofAppendixI.We
Toensurethis,wegroundthequestiongeneration additionally provide GPT4 API experimental set
ontwothings: (1)thepreviousquestionsfromlevel updetailsinAppendixG.
l−1,and(2)theVerifier’sexplanationofthegaps
4.2 Datasets
intheStudent’stargetstateunderstanding.
We use two datasets to evaluate our method on.
3.4 AdaptiveConversationRestructuring
First,theSocraticDebuggingBenchmarkdataset
OncetheVerifieragentdeterminesthatthetarget
from (Al-Hossami et al., 2023b), which consists
state/taskhasbeenresolved,weexploitthesame
of 149 problems, each with a problem statement,
process to update all remaining tasks τ ∈ S, as
studentbuggycode,bugfixesanddescriptionsin
multiple dependent bugs may have been concur-
English,andcorrectcode. Eachproblemhasone
rentlyresolvedwithinthesametree. Afteratleast
syntacticalorconceptualbug. Second,tochallenge
thetargetstatevariablehasbeenresolved(line13 ourmethod,wealsocraftanoveldataset,MULTI-
inAlg. 1),wecreateanewtreeforanyremaining DEBUG,basedon50popularprogrammingprob-
tasks,asshowninthefirstinteractionofFigure3. lems2. Foreachofthe50problems,weinject1,2,
Thisstepiscrucialtothemulti-bugsetting,asmu-
and3bug(s)thatastudentwouldmakeforatotal
tuallyindependentbugswouldbenefitfromhaving
of 150 different samples. We keep track of these
separateanddistincttreesofquestioning.
bugswithmatchingbugfixesanddescriptions.
Forfurtheradaptivenesstotheconversation,we
Bugsareeitherconceptualorsyntactical. Con-
additionallyprovide(1)anearlystoppingcondition
ceptualbugsusuallycauseruntimeerrorsorresult
basedontheStudent’sintermediatebugfixes,and
in incorrect output. Examples include misunder-
(2)amaximumtreewidthanddepththreshold,af-
standing the problem statement, encountering an
terwhichTreeInstructchoosestoteachtheStudent
infiniteloop,orincorrectlyusingalibraryormath-
theirremaininggapinknowledge.
ematical operator (/ vs // in Python). Syntacti-
• Bugfixes: Afterataskτ hasbeenresolved,the calbugscausecompilationerrorsduetoincorrect
Student is prompted to provide a list of natu- Pythonsyntax(e.g.,missingacolon).
ral language bug fixes (e.g. "Replace ‘i‘ with
4.3 Baselines
‘i+1‘ on line 6.") based on their entire conver-
sation history with the Instructor. The Verifier TodeterminethesuccessofTreeInstruct,wealso
willdetermineifalloftheground-truthbugfixes measuretheperformanceonafewbaselines. First
haveanisomorphiccounterpartwithinthesetof is a baseline called Vanilla. Given the same in-
suggested Student bug fixes. Isomorphism can putasTreeInstruct’sInstructor,thismethodsimply
bedefinedas(1)havingthesameconclusionor asks the base model to ask Socratic questions to
output,(2)sharingthesameunderlyinglogical the Student - it does not utilize the tree structure,
structureorpattern,and/or(3)beingconvertible nordoesitestimatetheStudent’sknowledge. We
toeachotherthroughaseriesoflogicaltransfor- use both Meta-Llama-3-8B-Instruct (?) and
mations. Ifallground-truthbugfixeshavebeen GPT-4 (Achiametal.,2023)asbasemodelsfor
resolved,thenwemaystopearly. theVanillabaseline.
Second, we use BRIDGE (Wang et al., 2023).
• Teaching: Aftergeneratingamaximumnumber
Since we are adapting this for Socratic code de-
of sibling questions q or depth l, the Instructor
bugging, we use the error type, the remediation
appendsthecorrectanswertoQ[l][0]andre-ask
strategy, and the remediation intention to guide
Q[l][−1] to the Student. This ensures that the
conversationflowsincasetheStudentgetsstuck. 2https://github.com/Garvit244/LeetcodeTable1: ResultsontheSocraticDebuggingBenchmarkDataset(SingleBug). Boldedand†valuesdenotethetop2
methodsrespectively.
Syntactical(42samples) Conceptual(107samples)
Methods Avg.Turns Success Relevant Indirect Logic Success Relevant Indirect Logic
Vanilla 3.23 80.95 83.72† 76.19 78.70† 76.64† 87.35† 80.32† 78.79†
Bridge 6.00 78.57† 76.50 82.24† 41.72 62.14 78.12 79.86 34.38
TreeInstruct 5.41 77.27 92.01 96.48 88.95 80.26 95.63 89.10 94.63
Table2: ResultsontheMULTI-DEBUGdataset. Intotal,1-bughas29syntacticaland21conceptualbugs,2-bug
has50syntacticaland50conceptualbugs,and3-bughas78syntacticaland72conceptualbugs. Boldedand†
valuesdenotethetop2methodsrespectively.
Syntactical Conceptual
Bugs Methods Avg.Turns Success Relevant Indirect Logic Success Relevant Indirect Logic
Vanilla 2.36 71.43 92.16 55.12 84.15 78.57 94.58 59.17 84.17
1 BRIDGE 16.60 50.00 93.93 98.04 24.23 68.00 97.27 96.67 35.38
TreeInstruct 7.24 76.19 93.98† 94.08 85.28† 71.43 97.57† 93.02† 86.02†
TreeInstruct 3.94 75.00† 100.00 95.59† 96.63 76.92† 100.00 88.01 94.76
Vanilla 8.32 53.26 83.45 74.41 60.82 62.50 86.96 74.13 59.90
2 BRIDGE 15.28 34.88 89.47 89.33 52.40 42.71 89.67 88.06 46.64
TreeInstruct 9.04 66.67† 93.00† 92.17† 84.59† 72.62† 94.15† 92.58† 81.46†
TreeInstruct 6.14 69.32 97.96 98.47 90.14 73.91 99.58 98.47 94.45
Vanilla 17.48 44.00† 69.88 64.31 52.38 67.00 84.68 84.68 41.51
BRIDGE 8.44 19.00 87.78 83.95 64.95 43.00 90.09 85.78 44.65
3 TreeInstruct 10.46 43.00 95.68† 88.88† 80.94† 72.00† 96.76† 97.95 83.28†
TreeInstruct 10.46 73.00 100.00 99.27 95.57 92.00 98.40 95.89† 93.63
the question generation, along with the problem- promotedacoherentconversation,facilitatingthe
specificinputgiventoTreeInstruct’sInstructor. For Student’sproblem-solvingprocess. EachInstructor
both baselines, we limit the conversations to 20 questionisassignedwithabinaryvalueforeachof
turnspernumberofbugs. thethreeattributes.
4.4 EvaluationMetrics: Quantitative Metrics: We apply quantitative
metrics to objectively evaluate the effectiveness
Weperformqualitativeandquantitativeevaluation
andefficiencyofourframework. Wecalculatethe
of our methods. Details for each metric are pro-
overallSuccessRate(Success)withthenumberof
vided in Appendix A. The scores are averaged
bugfixesgeneratedbytheStudentthatareisomor-
acrossallturnsandthenaveragedacrossallprob-
phictothegroundtruthsetofbugfixes. Wealso
lems. Intheresults,wescalethescoresby100.
computetheaveragenumberofturns(Avg. Turns)
QualitativeMetrics: Wedevelopabinaryscale requiredbythemethodtoreachthegoalstate.
to assess the Socratic quality of questions. We
4.5 OverallResults
measureeachmetricmanually,givingascoreof1
iftheattributeismet,and0otherwise. In Tables 1 and 2, we see that with more struc-
Relevance(Relevant)measureswhetherthein- turedrepresentationsofstudentknowledgeand
structor’squestionwaspertinenttotheerrorsinthe conversation state, TreeInstruct demonstrates
Student’scode. Indirectness(Indirect)measures significantimprovementsbeyondthebaselines.
iftheinstructor’squestionrefrainedfromdirectly Across all multi-bug settings, we see an overall
revealing solutions to the bugs. Finally, Logical improvementof16.6%and11.59%inthesuccess
Flow (Logic) checks if the instructor’s question rates for syntactical and conceptual bugs, respec-tively. Wealsoseeanimprovementof13.47%and 3-bugsettings. Toelaborate,1-bugstatespacerep-
14.89%forsyntacticalandconceptualbugs,respec- resentations suggest 3 or 4 state variables (more
tively,acrossthethreeconversationmetrics. Inthe subtasks)tosolveabugthat2-or3-bugstatespace
1-bugsetting,weseethattheVanilla baseline representationstake1or2statevariablestosolve
hasthehighestsuccessforconceptualbugs. How- (exampleprovidedinAppendixD).Thisindicates
ever, this setting simultaneously has the lowest that, across states, 1-bug settings have an easier
Indirectnessscore,indicatingthatquestionswere time keeping questions relevant to the bugs (as
very direct, and gave hints towards the bug fixes, thereisonlyone). Additionally,theconversation
which evidently increased the success rate. We flowsbetterastherearenointer-bugdependencies
see the same trend in the syntactical, single bug thattheInstructorhastotakeintoaccount.
onVanilla settinginTable1. Overall,TreeIn-
Bug dependency affects success rate. Table 2
structdemonstratesstrongperformancedespite
shows that the success rate (SR) for 3-bug and 1-
drasticallydifferentbasemodels, and .
bug are higher than that of 2-bug. 1-bug settings
Side-by-Side evaluation: Using the conversa- areoverallrelativelyeasiergiventhatonlyonebug
tional metrics, we performed a side-by-side eval- mustberesolved. However,comparedtothebase-
uationthatmeasureshowoftenauserprefersour lines, which feature low success and logic rates,
methodTreeInstructoverthebaselines. Morede- Tree-Instructdemonstratesacomparativelystrong
tailsareinAppendixE,inwhichweseethatonav- performancein3-bugsettings. Thisislikelydueto
erage,TreeInstructwaspreferredoverBRIDGE itsstatespaceandtreecreationstructurefactoring
79.43%more,andoverVanilla77.43%more. intheinter-bugdependencies.
Forexample,intheFibonacciprobleminFigure
HumanStudentInteraction: Wealsoconducta
1, a student could have made the following two
separatecasestudywherehumanstudentsdirectly
bugs: (1)theydidnotaddabasecasefortherecur-
interactwithTreeInstruct(detailsinAppendixF).
sion,and(2)theydidnotcorrectlywritetherecur-
We see that with varying levels of programming
sivecall. Oncetheysolveoneofthebugs,theywill
backgrounds, TreeInstruct is able to help all stu-
have understood recursion better, enabling them
dentsresolvethebugsintheircode.
to solve the other bug easily. TreeInstruct’s pri-
oritization of conceptual errors in the state space
4.5.1 Analysis
estimation(Section3.2)anddependencyawareness
Conceptual bugs are easier to solve than syn-
(Section 3.4) are the key to its high 3-bug perfor-
tactical. Inbothtables,acrossallsettings,itcan
mance. Thesamecannotnecessarilybesaidforthe
beseenthatquestionstargetedtowardsconceptual
2-bugsettingasitcouldhavemutuallyindependent
bugs have higher scores than those towards syn-
bugsthatrequirespecialattentiontosolve.
tactical bugs. Syntactical bugs might be "harder
to see" for the language model as it goes against 5 Conclusion
thegenerationprocesstogeneratesyntacticallyin-
Thispaperproposesanovelmethod,TreeInstruct,
correctcode. Breakingitdown,alanguagemodel
forstatespaceestimationanddynamictree-based
trained to generate code will always add a colon
questioningformulti-turnSocraticinstruction. We
attheendofforloops,if-statements,andmethod
construct a novel multi-bug debugging dataset,
signaturesbecausethemodelistrainedtodothat.
MULTI-DEBUG,with150expert-annotatedcon-
Eventhoughthebuggycodemighthaveamissing
ceptualandsyntacticalproblemsandbuggysolu-
colon,thelanguagemodelmightignoreit.
tions/fixes. Extensiveexperimentsonanexisting
Morebug-specificstatevariableshelps(1)gen- benchmarkandMULTI-DEBUGdemonstratethat
eratemorerelevantquestionsand(2)maintain TreeInstructcanbeuniversallyappliedtobothopen
conversationalflow. Table2showsthatscores andclosedsource-settings. Wealsoshowcasethat
for Relevance and Logic on conceptual bugs de- TreeInstruct’sstrongSocraticquestioningabilities
creases as the number of bugs increases (from widely outperform all baselines through both (1)
100%relevanceand94.76%logicalflowin1-bug rigorous quantitative and qualitative expert eval-
to98.4%relevanceand93.63%logicalflowin3- uation (preferred over 77.94% of the time), and
bug). Thestatespacerepresentationforthe1-bug (2)real-worldinteractionswithstudentsofvarying
settingismuchlesscompactasthatofthe2-and codingabilities(inAppendixF).6 Limitations&FutureWork tured fine-tuning approach to help the model bet-
ter leverage the Verifier feedback and tree-based
WhileTreeInstructprovidesanintuitiveframework
question generation process and make hierarchi-
whichdemonstratespromisingresultsforeffective
calSocraticplanningandquestioninginherenttoa
multi-turn Socratic instruction, it contains a few
model. Overall,TreeInstructcanalsobeextended
limitationsthatformthefoundationforfuture,im-
to automatically generalize to different teaching
pactfulresearchareas.
domains(e.g.,quantitativereasoning).
Firstly, Tables 1 and 2 shows high qualitative
scores for the questions asked by TreeInstruct. 7 EthicsStatement
Whiletheseareencouraging,thesuccessratesstill
We are committed to the transparency and repro-
havelargeroomforimprovement–thehighestsuc-
ducibility of our research. We encourage our re-
cess rate is 77.27%. This indicates that Socratic
searchcommunitytomakeuseofouropen-source
questionsalonearenotsufficientforteachingastu-
code and dataset to further improve our method-
denttodebugtheircode. Wejudgetheefficacyof
ology. Our research involves the evolving inter-
questionslocally,whereasthenextstepwouldbe
sectionoflargelanguagemodels(LLMs)andedu-
tojudgethemgloballyacrosstheconversation. We
cation, wherethedeploymentoflanguagemodel
leaveittofutureworktodeviseaneffectiveglobal
instructorsandtheirinteractionswithstudentshave
questioningschemeandevaluationmetric.
beenrelativelyunexplored. Theroleoftechnology
Additionally, our method is dependent on the
and language models is being widely discussed
basemodel’sreasoningcapabilities,specificallyfor
with respect to its impact on student dependence
the Verifier agent. In our results, with a stronger
andlackofcriticalthinking. Giventherapidand
model,weseehigherscoresforLogicandSuccess.
wide-scale deployment of LMs to the public, we
Although our method shows comparable results
emphasize the importance of designing Socratic
between GPT-4 and Llama-3-8b, this may be a
dialoguesystemsinthehopesofbetteringeduca-
bottleneck,asstrongerandbiggermodelsrequirea
tionalsupportforallstudentsandeducators.
higherdeploymentcost.
Next,inthefewfailurecases,weseesomead-
verse effects of our method’s reliance on the rea-
References
soning capabilities of the base model. First, our
methodcangetstuckintoacyclicalconversation JoshAchiam,StevenAdler,SandhiniAgarwal,Lama
Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
withtheStudentiftheyareparticularlyweakinan
DiogoAlmeida,JankoAltenschmidt,SamAltman,
areaandcannotunderstandthetargetstateevenaf- ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
termultipleroundsofdirectquestioningandteach- arXivpreprintarXiv:2303.08774.
ing. In these cases, the number of turns rises to
ErfanAl-Hossami,RazvanBunescu,JustinSmith,and
20-30.
RyanTeehan.2023a. Canlanguagemodelsemploy
Moreover,thebaselanguagemodelscannotfully thesocraticmethod? experimentswithcodedebug-
grasp abstract concepts such as trees and linked ging. arXivpreprintarXiv:2310.03210.
lists. Even humans require diagrams to work out
ErfanAl-Hossami,RazvanBunescu,RyanTeehan,Lau-
potentialsolutionsorteachoneanother. Withthe
relPowell,KhyatiMahajan,andMohsenDorodchi.
language-reliant teaching strategies, our method 2023b. Socraticquestioningofnovicedebuggers: A
mightnotbeabletoeffectivelyteachinthesedo- benchmarkdatasetandpreliminaryevaluations. In
Proceedingsofthe18thWorkshoponInnovativeUse
mains.
ofNLPforBuildingEducationalApplications(BEA
These limitations give way to exciting future
2023),pages709–726.
work. Firstly, we can make use of vision lan-
guagemodelstoprovidestudentswithmulti-modal Sterling Alic, Dorottya Demszky, Zid Mancenido,
Jing Liu, Heather Hill, and Dan Jurafsky. 2022.
teachingstrategies,insteadofrelyingsolelyonlan-
Computationallyidentifyingfunnelingandfocusing
guage. Additionally, we can enhance the frame-
questions in classroom discourse. arXiv preprint
work, so it will explore new instruction methods arXiv:2208.04715.
whenthequestioningbecomescyclical. Thiscan
AlbertTCorbettandJohnRAnderson.1994. Knowl-
alsohelpmaketheInstructormorereliabletogen-
edgetracing: Modelingtheacquisitionofprocedural
erateconsistentoutputacrossmultiplerunsonthe
knowledge. Usermodelinganduser-adaptedinter-
sameproblem. Furthermore,wecanutilizeastruc- action,4:253–278.KathleenCotton.1988. Classroomquestioning. School JudithDWilson.1987. Asocraticapproachtohelping
improvementresearchseries,5:1–22. noviceprogrammersdebugprograms. ACMSIGCSE
Bulletin,19(1):179–182.
DorottyaDemszkyandHeatherHill.2022. Thencte
transcripts: Adatasetofelementarymathclassroom Ya-TingCYang,TimothyJNewby,andRobertLBill.
transcripts. arXivpreprintarXiv:2211.11772. 2005. Using socratic questioning to promote criti-
calthinkingskillsthroughasynchronousdiscussion
BethAHerbel-EisenmannandMLynnBreyfogle.2005.
forumsindistancelearningenvironments. Theamer-
Questioningourpatternsofquestioning. Mathemat-
icanjournalofdistanceeducation,19(3):163–181.
icsteachinginthemiddleschool,10(9):484–489.
MichaelV.Yudelson,KennethR.Koedinger,andGeof-
EnkelejdaKasneci,KathrinSeßler,StefanKüchemann,
freyJ.Gordon.2013. Individualizedbayesianknowl-
MariaBannert,DarynaDementieva,FrankFischer,
edgetracingmodels. InArtificialIntelligenceinEdu-
UrsGasser,GeorgGroh,StephanGünnemann,Eyke
cation,pages171–180,Berlin,Heidelberg.Springer
Hüllermeier,etal.2023. Chatgptforgood? onop-
BerlinHeidelberg.
portunitiesandchallengesoflargelanguagemodels
foreducation. Learningandindividualdifferences,
A EvaluationMetrics
103:102274.
Here,wedescribeourqualitativeandquantitative
Majeed Kazemitabaar, Runlong Ye, Xiaoning Wang,
AustinZHenley, PaulDenny, MichelleCraig, and metricsindepth. Thescoresareaveragedacrossall
ToviGrossman.2024. Codeaid: Evaluatingaclass- turnsandthenaveragedacrossallproblemsofthe
roomdeploymentofanllm-basedprogrammingassis- samesettinganddataset. Inourresults, wescale
tantthatbalancesstudentandeducatorneeds. arXiv
thescoresby100.
preprintarXiv:2401.11314.
Qualitative: Wedevelopabinaryscaletoassess
WenhanLyu,YimengWang,TingtingRachelChung,
Yifan Sun, and Yixuan Zhang. 2024. Evaluating the Socratic quality of questions. Previous work
the effectiveness of llms in introductory computer identifiesmultipledimensionsofSocraticquestion-
scienceeducation:Asemester-longfieldstudy. arXiv
ing,includingrelevancetospecificneeds,implicit-
preprintarXiv:2404.13414.
nessoftheanswer,andstructuralcoherence. For
ChrisPiech,JonathanBassen,JonathanHuang,Surya eachquestion,wemeasurethebelowattributesof
Ganguli, Mehran Sahami, Leonidas J Guibas, and
the conversation manually (giving a score of 1 if
JaschaSohl-Dickstein.2015. Deepknowledgetrac-
theattributeismet,and0otherwise):
ing. Advancesinneuralinformationprocessingsys-
tems,28.
• Relevance(Relevant): Theinstructor’squestion
AnnaNRafferty,EmmaBrunskill,ThomasLGriffiths, waspertinenttotheerrorsinthestudent’scode.
andPatrickShafto.2016. Fasterteachingviapomdp
• Indirectness(Indirect): Theinstructor’sques-
planning. Cognitivescience,40(6):1290–1332.
tion refrained from directly revealing solutions
HusniahSahamid.2016. Developingcriticalthinking tothebugs.
through socratic questioning: An action research
• LogicalFlow(Logic): Theinstructor’squestion
study. InternationalJournalofEducationandLiter-
acyStudies,4(3):62–72. promoted a coherent conversation, facilitating
thestudent’sproblem-solvingprocess.
BradSheese,MarkLiffiton,JaromirSavelka,andPaul
Denny.2024. Patternsofstudenthelp-seekingwhen
Quantitative: Weapplyquantitativemetricsto
usingalargelanguagemodel-poweredprogramming
objectivelyevaluatetheeffectivenessandefficiency
assistant. In Proceedings of the 26th Australasian
ComputingEducationConference,pages49–57. ofourframework.
Rose E Wang and Dorottya Demszky. 2024. Edu- • Overall Success Rate (Success): We check
convokit: Anopen-sourcelibraryforeducationcon-
whether the final list of bug fixes generated by
versationdata. arXivpreprintarXiv:2402.05111.
theStudent,B ,andthegroundtruthsetofbig
S
RoseE.Wang,QingyangZhang,CarlyRobinson,Su- fixes, B , are isomorphic (Section 3.4). The
GT
sannaLoeb,andDorottyaDemszky.2023. Bridging
successrateiscalculatedas|B ∪B |/|B |.
GT S GT
thenovice-expertgapviamodelsofdecision-making:
Acasestudyonremediatingmathmistakes. • Average Number of Turns (Avg. Turns): We
computetheaveragenumberofturnsrequiredby
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
the method to reach the goal state. This metric
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
etal.2022. Chain-of-thoughtpromptingelicitsrea- providesinsightintotheefficiencyanddepthof
soninginlargelanguagemodels. AdvancesinNeural theinteractionprocess.
InformationProcessingSystems,35:24824–24837.Table3: Resultsonthe3-bugsettingoftheMULTI-DEBUGdatasetcomparedwiththreeablationsettings. TI
indicatesTreeInstruct,ourmethod.
Syntactical Conceptual
Methods Avg.Turns Success Relevant Indirect Logic Success Relevant Indirect Logic
Vanilla 17.48 44.00† 69.88 64.31 52.38 67.00 84.68 84.68 41.51
BRIDGE 8.44 19.00 87.78 83.95 64.95 43.00 90.09 85.78 44.65
TreeInstruct 10.46 43.00 95.68† 88.88 80.94† 72.00† 96.76† 97.95 83.28†
TreeInstruct 10.46 73.00 100.00 99.27 95.57 92.00 98.40 95.89† 93.63
TI NoTeaching 9.69 30.61 90.75 97.61† 72.84 50.00 94.62 95.17 68.78
TI NoState 16.34 25.51 51.61 97.21 41.09 53.00 47.57 94.70 20.36
B HumanExpertEvaluators • FordeterminingSuccess,donotpenalizethe
Student if the bug fix is in natural language
Asmentionedbefore,ourmetricsinTables1and2
ratherthancode.
wereobtainedusingvolunteerhumanexperteval-
uators: two computer science teaching assistants C AblationStudies
withatleastfouryearsofhigh-school,undergradu-
Table 3 compares the results of the 3-bug setting
ate, andgraduate-levelteachingexperience, with
withtwoablationsettings:
proficiencyinPythonandlocatedintheUSA.They
weregiventhesamesetofinstructionsandthefol-
• NoTeaching: Weremovetheteachingfunc-
lowingsetofguidelines:
tionality that kicks in when the Student has
answered three consecutive questions incor-
• Assignascoreof1forRelevanceiftheques-
rectly. Conversationisstillguidedbythestate
tionwilleventuallyleadtheStudenttounder-
spacerepresentation,tree-basedquestioning,
standtheirbug(s).
itsupdates,andthebugfixesproposedbythe
Student.
• Assignascoreof0forIndirectifaquestion
explicitlyorimplicitlystatesasolution.
• NoState: Weremovethestatespacerepresen-
tation. We guide conversation based on the
• Assign a score of 0 for Logic if the current
conversation history, the previous questions
questiondoesnotnaturallyflowfromtheStu-
asked,theVerifierfeedbackontheStudent’s
dent’spreviousanswer.
answer,andthebugfixesproposedbytheStu-
dent.
Belowaresomespecialcases/considerationsthe
evaluatorswerealsogiven:
Overall, we can see that when comparing the
Llama-basedablationswiththeGPT4-basedbase-
• IftheVerifieriswrongandasksthesameques-
lines,ourablationperformanceisstillcompetitive,
tiondespitetheStudentgettingthequestion
especially with respect to the relevance and indi-
correct,giveascoreof0forRelevance.
rectnessofthequestions. However,thesignificant
drops in performance indicate the importance of
• Ifaquestionseemsoutoforder,giveascore
ourdifferentmodules,especiallyTI NoState.
of0forLogic.
Weprovideadetailedanalysisofourablationre-
• If a question deep into the conversation is sultsbelow:
vague, gives a score of 0 for Relevance and From TI to TI No Teaching, we see
Logic. the Success rates and Logic scores to drop by
17.20% and 11.32%, respectively, on average.
• If the answer is provided in a hint after 2 Teaching is a crucial part of our method because
roundsofsimilarquestions,andtheStudent iftheStudenttrulydoesnotknowaconcept,then
stilldoesnotunderstand,donotpenalizethe asking them more questions will not help them
InstructorforIndirect. learn. WhiletheInstructor’sjobinTreeInstructistoaskquestions,atacertainpoint,itshouldteach
theStudenttocleartheirconfusion. Hence,when
weremoveteaching,weseeevenfewerbugssolved
andmorerepeatedquestionsbeingasked,leading 1. Understand the problem statement and the
tolowlogicalflow. However,westillsee requirementtofindtwonumbersthataddupto
Next, for TI No State, we see significant aspecifictarget.
drops of 18.25% in Success rates, 46.63% in 2. Understandthelogicbehindcalculatingthe
Relevance, and 51.39% in Logic scores, on av- differenceastarget-nums[i].
erage. The state space representation guides the 3. Correctlyimplementthedifferencecalcula-
questiongeneration,ensuresthequestionsareon tioninthecode.
topictothebugs,andkeepstrackoftheStudent’s
misunderstandings. Without this grounding, we Table 4: State space representation for 1-bug on the
two-sumproblem.
noticedthattheconversations(1)deviatefromthe
realbugs–exploringareassuchastimecomplexity
optimization,whichmightnotbethefocusofthe
problem,(2)containcountlessrepeatedquestions
that the Student already answered, and (3) jump
from topic to topic abruptly in consecutive turns.
Theseresultsshowhowimpactfulthestatespace
representationis.
1. Understand how to correctly calculate the
D ComparingStateSpace difference between the target and the current
RepresentationsinMulti-BugSettings numberinthearray.
2. Understandthedifferencebetweenlistsand
Here,wecomparethestatespacerepresentations
dictionariesinPython.
ofthe1-bug,2-bug,and3-bugsettingsforthetwo
3. CorrectlyinitializeadictionaryinPython.
sumproblem. Inthetwosumproblem,givenisan
4. Understandhowtouseadictionarytostore
arrayofintegersandatargetvalue. Thegoalisto
andretrievevaluesinPython.
return the indices of two numbers that add up to
thetargetvalue. Belowisthecorrectcode. Table 5: State space representation for 2-bug on the
two-sumproblem.
1. def twoSum( self , nums, target ):
2. d = {}
3. for i in range( len (nums)):
4. difference = target −nums[ i ]
5. if difference in d:
6. return [d[ difference ] , i ]
7. d[nums[ i ]] = i
8. return d
1. Understand how to correctly calculate the
In the 1-bug setting, the Student mis- differenceas‘target-nums[i]‘.
takenly writes nums[i]-target instead of 2. Understand how to initialize a dictionary
target-nums[i] on line 4. In the 2-bug set- using‘‘insteadof‘[]‘.
ting,alongwiththepreviousbug,theStudentalso 3. Understandhowtouseadictionarytostore
initializesdasalist(d=[])insteadofadictionary andretrievevalues.
online2. Finally,inthe3-bugsetting,theStudent 4. Understand the correct syntax for an if-
forgetstoaddacolonattheendoftheif-statement condition,includingthenecessarycolonatthe
online5. end.
Tables4,5,and6outlinethestatespacerepre-
Table 6: State space representation for 3-bug on the
sentationsforthe1-bug,2-bug,and3-bugsettings.
two-sumproblem.
Asshown,1-buguses3states(states1,2,and3)to
solvethesamebutthat3-buguses1state(state1)
tosolve. Thismeansthe1-bugstaterepresentation
ismuchlesscompactthanthatfor3-bug.Table7: Resultsontheside-by-sideevaluation. Bolded allyprovidebadinputsthatwilltrytomake
and†valuesdenotethetop2comparisonsrespectively.
themethodfail.
Note: S-bug refers to the Socratic Debugging Bench-
mark. WeabbreviateTreeInstructasTI. • Level2: StudentisnewtoTreeInstruct;they
areabasicprogrammerwhohasbeenlearning
Comparison 3-bug 2-bug 1-bug S-bug
tocodeinPythonforafewmonths.
TIvsBRIDGE 71.43† 68.00† 83.67 94.63
TIvsVanilla 100.00 90.00 69.39† 50.33† • Level3: StudentisnewtoTreeInstruct;they
BRIDGEvsVanilla 57.14 62.00 40.82 24.83 areanon-computersciencemajorwhodoes
notusePythonoften,butknowsthebasichigh
levelconceptsofdatastructuresandsyntax.
E SidebySideEvaluation
• Level4: StudentisnewtoTreeInstruct;they
Asmentionedinthemaintext,weperformaside- havebeenusingPythonfor2yearsandisin
by-side evaluation to measure the percentage of theirfinalyearofundergraduateeducationin
timesauserprefersourmethodTreeInstructover computerscience.
thebaselinesbaselines. Preferencewasmeasured
as the average of all conversation metrics across • Level 5: Student knows how TreeInstruct
syntacticalandconceptualbugs. Basedonthemet- works;theyactasanallytointentionallypro-
rics,weassigneachmethodaranking(1,2,or3). vide good inputs so the method can resolve
Table7showsthatTreeInstructwaspreferred68- thebugsinaslittleturnsaspossible.
94.6%ofthetimeoverthebaselines. Onaverage,
Whenconductingthestudy,weadheredtothefol-
TreeInstructwaspreferredoverBRIDGE79.43%
lowingexperimentalprocess:
ofthetime,andoverVanilla77.43%ofthetime.
1. We presented the student with the problem
Interpretation. WhenwesayTreeInstructwas
statementandgavethemasmuchtimeasthey
preferred79.43%moreoverBRIDGE,thismeans
neededtofullyunderstandit.
thatacrossall503-bugproblemsandrankingcon-
figurations, TI was given a higher ranking than
2. Thestudentsweregiventwominutestoreview
BRIDGE(TIisranked#1whileBRIDGEisranked
the buggy code. We noted down how many
#2,TIisranked#1whileBRIDGEisranked#3,TI
bugseachofthestudentswereabletoidentify
isranked#2whileBRIDGEisranked#3)79.44%
beforetheirconversation.
of the time. Each of the 50 problems can have
multiple preferences (TI over BRIDGE, TI over 3. ThestudentsconversedwithTreeInstructun-
Vanilla, Bridge over Vanilla, etc.) which is why til they were able to identify all of the bugs
theywillnotnecessarilyaddupto100. presentinthecode.
F InteractiveEvaluationwithHuman Weprovidetheresultsofthisinteractivestudy
Students in Table 8. We used the same three single and 3-
bugquestionsforallstudents,leadingto30human
For our main evaluation, we used
studentinteractionsintotal. Wealsoconducteda
Mistral-7B-Instruct to represent a
post-interactioninterviewwitheachofthestudents
Student. We noticed that Mistral is an overconfi-
andprovideanoverviewoftheirfeedbackbelow:
dent model that (1) suggests incorrect bug fixes
inbetweentheconversationsand(2)jumpstofix Socraticquestioninghelpedstudentslearnpro-
bugs that do not exist in the code. Therefore, we grammingconcepts. TheLevel3studentstated
worked with human students to test our method that,"Iftherewasnoconversation,Iwouldbeput
onthefollowingtwosettings: SocraticDebugging off from attempting to fix and just try a bunch of
on TreeInstruct and 3-bug on TreeInstruct differentthingsbasedontheerrors."Overall,stu-
. We gathered 5 humans of varying levels of dents of Levels 2-4 (students with no knowledge
programmingbackgroundsandknowledge: ofthesystem)werenotabletoidentifyallofthe
bugsbeforetheirinteractions,butendedupsolving
• Level 1: Student knows how TreeInstruct themindependentlyundertheSocraticguidanceof
works; they act as an adversary to intention- TreeInstruct.Table 8: Results of human student evaluation across s(ingle)-bug (Socratic Debugging benchmark) and 3-bug
(MULTI-DEBUGdataset)settings,brokendownbythestudentlevel.
Syntactical Conceptual
Bugs Methods Avg.Turns Success Relevant Indirect Logic Success Relevant Indirect Logic
Level1 6.0 100.00 66.67 66.67 100.00 100.00 91.67† 100.00 50.79
Level2 12.0 100.00 66.67 83.33† 75.00† 50.00† 100.00 100.00 50.00
S-bug Level3 8.0 0.00† 87.50† 100.00 50.00 100.00 67.50 90.00† 42.50
Level4 1.0 100.00 100.00 0.00 100.00 100.00 57.14 100.00 64.29†
Level5 1.0 100.00 100.00 100.00 100.00 100.00 100.00 75.00 75.00
Level1 19.0 83.33† 75.93 97.92† 74.77 100.00 100.00 88.89† 79.49
Level2 11.7 83.33† 100.00 100.00 78.57 100.00 100.00 86.67 82.50
3-bug Level3 6.67 100.00 100.00 100.00 85.71† 100.00 100.00 100.00 100.00
Level4 4.7 100.00 93.33† 100.00 76.67 100.00 100.00 83.33 88.89†
Level5 3.0 100.00 100.00 83.33 100.00 100.00 83.33† 100.00 83.33
Underlying model had a significant impact on averageof31,000outputand2,200outputtokens,
userexperience. Studentshadasignificantlybet- whichaddsupto$1.06perconversation.
ter experience with TreeInstruct compared to
G.2 MistralandLlama
TreeInstruct . Specifically, the quality of the
Verifier determined whether or not the questions WeruntheMistral-7B-Instruct-0.2andLlamamod-
posedbytheInstructorwouldbeoverlyrepetitive elslocallyon2NVIDIA-RTXA6000GPUs. For
ornot. onepassonadataset(i.e.,150problems/conversa-
tions),TreeInstructtakesapproximately4hours.
F.1 Analysis
H License
Table8containstheresults. WeseethatfromLevel
1toLevel5,theconversationhavefewerturns,es-
Allofthedatasetsusedinthiswork,includingour
peciallyinthe3-bugsetting. Additionally,wesee
own, is under the Apache 2.0 License. Our use
thatsyntacticalbugsarehardertosolveforweaker
of existing artifact(s) is consistent with their in-
students (on average, a success rate of 86.67%),
tendeduse,specificallyfortheSocraticDebugging
which is intuitive as these students do not have a
benchmarkandingeneral,programmingpractice
strongfoundationinPythonsyntax. Ontheother
andfeedbackfortheproblemsusedintheMULTI-
hand, conceptual bugs are easier to solve (on av-
DEBUGdataset.
erage, a 95% success rate). Overall, the results
showthatourmethodcanadapttovariouslevels I Prompts
ofstudentseffectively.
Afewofthepromptsuseone-shotlearning,andthe
G ModelInferenceExperimentalSetup fieldsareprefixedwith"example". Theseexamples
are hand chosen, with no criteria in mind. The
G.1 GPT-4API
exampleproblemrelatestoasolutionthatoutputs
ForGPT-4,wemadeuseofOpenAI’sGPT-4API. theFibonaccisequenceoflengthn,wherenisthe
Overall, we use temperature sensitivity t = 0 for input. We provide the specific prompts starting
all generation tasks, except for t = 0.1 for state fromthenextpage.
spaceestimationandt = 0.3forinstructorquestion
generation.
Using$30/1Minputtokensand$60/1Moutput
tokens, we break down the cost for each method.
TreeInstructusesanaverageof35,000inputtokens
and 4,000 output tokens, which adds up to $1.29
per conversation. BRIDGE uses an average of
18,000inputand5,500outputtokens,whichadds
up to $0.87 per conversation. Vanilla uses anYou are an Instructor helping a Student debug their code to solve the following problem statement
(aftertag’problem’). Youhaveaccesstotheirbuggycode(aftertag’bug_code’). Donotaskquestions
thatexplicitlyorimplicitlymentionthefollowing:
Table9: Instructoragentpersonaprompt
YouareaStudentwritingcodetosolvetheaboveproblemstatement(aftertag’problem’),andyou
havewrittenthebelowbuggycode(aftertag’buggy_code’). YouareseekinghelpfromyourInstructor
helpsolveyour’buggy_code’. YourroleistoanswerthequestionsthattheInstructorasksyouasif
youwereanintroductoryprogrammerwithabeginner’slevelofcodingknowledge.
Table10: Studentagentpersonaprompt
YouareanassistanttotheInstructorhelpingaStudentdebugtheircodetosolvethefollowingproblem
statement(aftertag’problem’). YourroleistodeterminetheStudent’sunderstanding(orlackthereof)
withintheInstructor-Studentinteractions. Youhaveaccesstothecorrectcode(aftertag’correct_code’).
AssumetheStudentisaintroductoryprogrammerwithabeginner’slevelofcodingknowledge.
Table11: Verifieragentpersonaprompt
Giventhestudent’sbuggycode(aftertag’buggy_code’),bugdescription(aftertag’bug_description’),
bugfixes(aftertag’bug_fixes’),andthecorrectcode(aftertag’correct_code’)forsolvingtheproblem
statement (after tag ’problem’), we define the state representation of a set of Instructor-Student
interactions as a series of necessary tasks which lead the Student from their ’buggy_code’, with
bugsdescribedin’bug_description’,tounderstandingandcorrectingtheirconceptualandsyntactical
mistakestoreach’correct_code’withthe’bug_fixes’.
Wedefineastaterepresentationasalistofstateattributes,whereeachattributedenotesaspecifictask
that is NECESSARY for the student to successfully understand and implement the given problem.
A NECESSARY task directly addresses at least one of the ’bug_description’s and thus, is NOT
ALREADYADDRESSEDin’buggy_code’. Inotherwords,ifataskisnotsuccessfullycompleted,
theStudentwillneverbeabletocorrecttheir’buggy_code’to’correct_code’.
Ifthestudent’s’buggy_code’showsthattheyhavealreadyunderstoodandimplementedaspecifictask,
DONOTINCLUDEthattaskasastateattributesinceitisREDUNDANT.
Thelistshouldbeordered,withearlierattributes/tasksgivenpriorityoverlaterones(e.g.,conceptual
understandingtasksareapre-requisiteandthusmoreimportantthansyntacticaltasks). Thefollowing
isanexampleofthestaterepresentationforthegivenexampleproblemstatement: exampleproblem:
Implement a Fibonacci sequence using recursion. {example buggy code} {example correct code}
{examplestaterepresentation}. Nowdothesameforthefollowingproblemstatement,correctcode,
andstudentbuggycode: {problemstatement},{correctcode},{buggycode}
Table12: InternalVerifierprompttoestimatethestatespacerepresentation;correspondstotheGenerateState()
methodinline1ofAlg1.TheStudenthaswrittencode(aftertag’student_code’)tosolvetheproblem(aftertag’problem’)and
isansweringaquestion(aftertag’Student’)fromtheInstructor(aftertag’Instructor’)basedontheir
understandingofthe’problem’andtheir’student_code’. IFtheStudentsuggestsasolutiontoabug
theyidentify,alsoconsiderthefollowing:
EnsurethattheStudent’ssuggestionisisomorphictoanyoneofthebugfixesmentionedintheprovided
’bug_fixes’;ifnot,then’answer_has_no_mistakes’shouldbe"False". AStudent’ssuggestionisisomor-
phictoabugfixifthey(1)havethesameconclusionoroutput,(2)sharethesameunderlyinglogical
structureorpattern,and(3)areconvertibletoeachotherthroughaseriesoflogicaltransformations.
Answerthefollowingquestionsandwithinyourreasoning,thinkabouthowyouwouldanswerthe
"instructor_question"yourselfandincludethisinyour"explanation".: answer_addresses_question:
<DoestheStudent’sresponse(aftertag’Student’)directlyanswertheInstructor’squestion(aftertag
’Instructor’)? Output"Trueor"False">answer_has_no_mistakes: <IstheStudent’sresponse(aftertag
’Student’)totheInstructor’squestion(aftertag’Instructor’)logical(nologicalerrorsormistakes)?
Output"Trueor"False">
Instructor: {Instructorquestion}
Student: {Studentresponse}
bug_fixes: {bugfixes}
student_code: {studentcode}
Table13: InternalVerifierprompttoassesstheaccuracyoftheStudentresponsewithrespecttotheInstructor’s
question;correspondstotheVerifyResponse()methodinline6ofAlg1.
A Student has sufficient understanding of a certain topic (specified at tag "target_understanding")
whentheresponsesthattheyprovidetotheInstructor(specifiedinthe"conversation_history")would
REQUIREthemtocomprehend"target_understanding". Thiscaneitherbedemonstrated(1)explicitly,
wheretheStudentdirectlymentions"target_understanding",OR(2)implicitly,wheretheirreasoning
isisomorphictocompletingthetaskin"target_understanding". AStudent’sreasoningisisomorphic
to the "target_understanding" if they (1) have the same conclusion or output, (2) share the same
underlyinglogicalstructureorpattern,and(3)areconvertibletoeachotherthroughaseriesoflogical
transformations.
BasedontheStudent’sresponse(aftertag’student_response’)totheInstructor’squestion(aftertag
’instructor_question’)andtheconversationhistory(aftertag’conversation_history’),doyoubelieve
that the Student needed to sufficiently comprehend the "target_understanding" in order to provide
theirresponses(aftertag’Student’in’conversation_history’)totheInstructor’squestions(aftertag
’Instructor’in’conversation_history’)throughouttheconversationhistory? Includespecificquotes
fromthe"conversation_history"inyour"explanation". Withinyourreasoning,thinkabouthowyou
wouldanswerthe"instructor_question"yourselfandincludethisinyour"explanation".
Instructor: {Instructorquestion}
Student: {Studentresponse}
target_understanding: {targetunderstanding}
Table14:InternalVerifierprompttoupdatethestatespacewithrespecttoasingle-turnInstructor-Studentinteraction;
correspondstotheUpdateUnderstanding()methodinline12ofAlg1.Are any bug fixes mentioned in the conversation that you have had with the Instructor (under tag
"conversation_history")? Ifno,return"None". Ifyes,thenfollowtheformatbelow:
First,basedonyourcurrentunderstandingoftheproblem(tag"problem")andyourconversationwith
theInstructor,summarize(aftertag"bug_summarization")thebugsinthecodeexplicitlymentioned
withinthe"conversation_history"thatyoubelievewillreviseyourbuggycode(aftertag"buggy_code")
toacorrectimplementationofthe"problem"statement. Then,basedonthissummary,outputalistof
theexplicitlymentionedbugfixes(from"bug_fix_1"to"bug_fix_n",wherenisthenumberofbug
fixestomake),eachdescribedbriefly.
Anexampleformat/wordingofabriefbugfixwouldbe: "Replace‘i‘with‘i+1‘online6."
conversationhistory: {convohistory}
Table 15: Instructor to Student prompt that asks the Student to generate a list of bug fixes; corresponds to the
GetStudentBugFixes()methodinline17ofAlg1.
For the problem description given above (after tag ’problem’), you are given two sets of bug fixes
(undertags’suggested_bug_fixes’and’correct_bug_fixes’). Foreachbugfixin’correct_bug_fixes’,is
thereatleastonebugfixin’suggested_bug_fixes’thatisisomorphic? Twobugfixesareisomorphicif
they(1)havethesameconclusionoroutput,(2)sharethesameunderlyinglogicalstructureorpattern,
and (3) are convertible to each other through a series of logical transformations. Output "True" or
"False"asyouranswerwithanexplanation.
suggestedbugfixes: {student_bf}
correctbugfixes: {correct_bf}
Table16: InternalVerifierpromptcheckiftheStudenthassuggestedallthecorrectbugfixesthatarepresentinthe
groundtruthsetofbugfixes,correspondstoisResolved()inline4ofAlg. 1.
Based on the student’s current level of understanding, as demonstrated through their conversation
history(tag"conversation_history"),whatis1follow-upquestionwiththesamelevelofdepthand
difficultyRELATIVEtothe’previous_questions’thatyoucouldaskbasedontheStudent’sexplanation
that would help them reach the "target_understanding"? Make sure that the question addresses the
reasonswhytheStudentgotthepreviousquestion(s)wrong,asdetailedintag"misunderstanding",
suchthattheStudentismorelikelytoresolvethesemisunderstandings. Youmustgenerateaquestion
suchthatanycorrectanswertoyourquestionshouldautomaticallyreflectthe"target_understanding"
andresolvethe"misunderstanding".
target_understanding: {target}
conversation_history: {conversationhistory}
previous_questions: {previousquestions}
previous_misunderstanding: {explanations}
ThesequestionsshouldhelptheStudentarriveattheanswerthemselves;doNOTgiveanydirecthints
towardsthesolution(undertag"bug_fixes"andtag"bug_description").
bug_fixes: {bugfixes}
bug_descriptions: {bugdescriptions}
Table17: InternalInstructorprompttogenerateasiblingquestion;correspondstotheGenerateSiblingQuestion()
methodinline10ofAlg1.Based on the student’s current level of understanding, as demonstrated through their conversation
history(tag"conversation_history"),whatis1follow-upquestionwithincreasingdepthanddifficulty
RELATIVE to the ’previous_questions’ that you could ask based on the Student’s explanation that
wouldhelpthemreachthe"target_understanding"? Makesurethatthequestionaddressesthereasons
whytheStudenthasnotreachedthe"target_understanding",asdetailedintag"misunderstanding",
suchthattheStudentismorelikelytoresolvethese"misunderstanding"sbyansweringyourquestion.
target_understanding: {target}
conversation_history: {conversationhistory}
previous_questions: {previousquestions}
previous_misunderstanding: {explanations}
ThesequestionsshouldhelptheStudentarriveattheanswerthemselves;doNOTgiveanydirecthints
towardsthesolution(undertag"bug_fixes"andtag"bug_description").
bug_fixes: {bugfixes}
bug_descriptions: {bugdescriptions}
Table 18: Internal Instructor prompt to generate a child question; corresponds to the GenerateChildQuestion()
methodinline14ofAlg1.
Basedonthebuggycodeandthetargetunderstandingstate(undertag"target_understanding"),whatis
onequestion(k=1)thatyoucouldaskthatwouldhelptheStudentreachthe"target_understanding"?
ThesequestionsshouldhelptheStudentarriveattheanswerthemselves;doNOTgiveanydirecthints
towardsthesolution(aftertag’bug_fixes’).
ThesequestionsshouldhelptheStudentarriveattheanswerthemselves;doNOTgiveanydirecthints
towardsthesolution(undertag"bug_fixes"andtag"bug_description").
target_understanding: {target}
bug_fixes: {bugfixes}
bug_descriptions: {bugdescriptions}
Table19: InternalInstructorprompttogeneratetheinitialquestion;correspondstotheGenerateQuestion()method
inline3ofAlg1.