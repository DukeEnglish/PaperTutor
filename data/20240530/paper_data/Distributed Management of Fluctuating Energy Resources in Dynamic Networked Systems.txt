1
Distributed Management of Fluctuating Energy
Resources in Dynamic Networked Systems
Xiaotong Cheng†, Ioannis Tsetis†, Setareh Maghsudi
Abstract—Modern power systems integrate renewable dis- However,theDERs’performancedependsonseveralfactors,
tributed energy resources (DERs) as an environment-friendly such as time and weather. As such, they suffer from high
enhancement to meet the ever-increasing demands. However, the
uncertainties [2], [5], which exacerbates their integration into
inherentunreliabilityofrenewableenergyrendersdevelopingDER
power grids. Besides, the variability, unpredictability, and high
management algorithms imperative. We study the energy-sharing
problem in a system consisting of several DERs. Each agent complexity of the DERs system remain crucial challenges
harvests and distributes renewable energy in its neighborhood [6]. The challenge is even more imminent considering the
to optimize the network’s performance while minimizing energy mismatch between renewable generation and load demand,
waste. We model this problem as a bandit convex optimization
which causes outages or severe energy waste [3]. Therefore, it
problem with constraints that correspond to each node’s limi-
is essential to distribute energy generated by DERs carefully
tations for energy production. We propose distributed decision-
makingpoliciestosolvetheformulatedproblem,whereweutilize and without delay. Furthermore, privacy is crucial, especially
the notion of dynamic regret as the performance metric. We also on the demand side [7]. In brief, the challenge is to develop
include an adjustment strategy in our developed algorithm to an efficient distribution mechanism in DERs to satisfy users’
reduce the constraint violations. Besides, we design a policy that demandswhileminimizingenergywasteunderuncertaintyand
deals with the non-stationary environment. Theoretical analysis
rare information exchange.
shows the effectiveness of our proposed algorithm. Numerical
Previous research focused on offline energy resource man-
experimentsusingareal-worlddatasetshowsuperiorperformance
of our proposal compared to state-of-the-art methods. agement [8]–[10] with the ideal assumption that the generated
energy and the load demand are either deterministic or known
Index Terms—Bandit convex optimization, distributed energy
a priori before scheduling. However, in practical applications,
resources, resource-sharing, sequential decision-making.
generating renewable resources is time-variant and involves
uncertainfactorsthatcannotbepredictedorcontrolledprecisely
I. INTRODUCTION [2],[5],[11].Tosolvethereal-timeenergydistributionproblem,
[7]proposesonlinecentralizedanddistributedalgorithmsbased
The beneficial characteristics of renewable energy, such as
on the gradient method. Reference [6] uses the alternating
sustainability, make it inevitable to integrate wind- and solar
direction method of multipliers (ADMM) within a model
resources into power generation systems [1] to satisfy the
predictive control (MPC) framework to control and optimize
ever-increasing energy demand while remaining environment-
thepowerschedulingproblem.Reference[3]designsanonline
friendly. Distributed energy resources (DERs) are small-scale
algorithm for the real-time energy management of microgrid
electricitysupplyordemandresourcesconnectedtotheelectric
systemsbycombiningtheofflineoptimalsolutionwithwindow-
grid. They include solar power, wind power, geothermal power,
based sequential optimization.
hydrothermal power, etc., as clean energy resources [2]. They
Inthepriorworksthatinvestigateonlineenergymanagement
are a potential environmental- and economically valuable
[3], [7], online convex optimization (OCO) is a popular
solution for power systems [3].
framework.However,alargebodyofliteratureassumesthatthe
Compared to conventional fossil-based energy generation, gradient at any point in the decision space is accessible, which
DERs reduce carbon dioxide emissions and have lower often does not hold in real-world applications. To mitigate this
transmission- and distribution costs [2]. Besides, compared shortcoming, we develop a gradient-free online algorithm for
with traditional large-scale power plants, DERs are small and energy-sharing in DERs. While sharing energy is the main
highly flexible [4]. Such characteristics enable more power focus of this work, our proposed method applies to a vast
generation and increase supply reliability in a cost-effective spectrum of application domains beyond energy management,
manner. suchas computational taskoffloading,distributedlearning,and
the like.
†Equalcontribution.
X. Cheng is with the Department of Electrical Engineering and Infor-
A. Related Work
mation Technology, Ruhr-University Bochum, 44801 Bochum, Germany
(email:xiaotong.cheng@ruhr-uni-bochum.de).I.TsetisiswiththeDepartment Optimization strategies are well-known solutions to optimal
of Computer Science, University of Tübingen, 72074 Tübingen, Germany
DERsmanagementproblems.Ourworkaddsanessentialfactor
(email:ioannis.tseitis@uni-tuebingen.de).S.MaghsudiiswiththeDepartment
of Electrical Engineering and Information Technology, Ruhr-University to the state-of-the-art methods, namely, uncertainty and lack of
Bochum,44801Bochum,GermanyandwiththeFraunhoferHeinrichHertz information. As such, the research related to ours stems from
Institute,10587Berlin,Germany(email:setareh.maghsudi@rub.de).
two main categories, namely, distributed energy resources and
Apartofthispaperappearedatthe2023IEEEInternationalConferenceon
Acoustics,Speech,andSignalProcessing(ICASSP2023). online convex optimization under bandit feedback.
4202
yaM
92
]YS.ssee[
1v51091.5042:viXra2
Reference [12] investigates optimal power management for with long-term constraints. To alleviate those difficulties, OCO
residential customers in a smart grid (SG) combined with and BCO under constraints are potential solutions. Reference
renewableenergygenerationandbatterystorage.Theproposed [29] considers the online convex optimization problem with
√
solution is based on Lyapunov optimization. It can achieve long-termconstraints.TheproposedalgorithmachievesO( T)
close-to-optimal performance with a trade-off between battery regret bound and O(T3/4) bound of constraint violation.
capacity and cost savings. Similarly, [13] adopts a Lyapunov Following [29], [28] proposes an adaptive online gradient
optimization method to solve the energy management problem descentalgorithmtosolveonlineconvexoptimizationproblems
forSGunderunpredictableloaddemandsofusers.Specifically, with long-term constraints. Reference [30] considers the online
users in the energy distribution network have renewable energy convexoptimizationproblemwithstochasticconstraints,which
√
resources, an energy storage device, and a connection to the can achieve O( T) regret bound and constraint violations. It
√
power grid, which collaboratively satisfy their load demands. further proves O( T logT) high probability regret bound and
The proposed dynamic energy management scheme optimally constraint violations.
schedulestheusageofallenergyresourcesbasedonthecurrent Finally,distributedconvexoptimization[31]–[33]andconvex
system state only. However, the strategies above are all central optimization in non-stationary environment [34] attract increas-
and require a controller/coordinator. Reference investigates ing attention. In this paper, we solve the energy management
the energy management problem by formulating it as a problem in DERs by formulating it as a distributed BCO
convexoptimizationproblem,anddevelopsacentralizedoffline problem with constraints in a non-stationary environment.
solution. Reference [14] extends [7] by designing distributed
algorithms to solve the formulated problem. Similarly, in [4],
B. Contributions
the authors consider an optimal DERs coordination problem
Inthispaper,weinvestigatethereal-timeenergymanagement
over multiple time periods subject to constraints and solve
problem for networked DERs systems consisting of a number
it via a distributed consensus algorithm based on gradient
of nodes, each of which is an energy- generator and consumer
strategy. Reference [15] develops a simplified Markov model
simultaneously. It is an extension of our previous work [35],
for photovoltaic power generation and proposes a stochastic
however, our previous work only considers the distributed
dynamic programming optimization framework to solve the
energy management in a stationary environment while in this
energy management problem. To reduce the communication
work we consider a more complicated problem. We list our
cost of distributed structure in energy management, reference
contributions briefly below.
[16] designs an optimization algorithm with event-triggered
communication and control mechanism. • We investigate an energy-sharing problem in a network of
Besides, most strategies require critical information, such systems. We minimize the detrimental impact of energy
as the consumers’ demands and usage, which scarifies the shortage on systems’ performance because of uncertainty
users’ privacy. Consequently, several authors propose privacy- inenergyproductionorharvesting.Wemodelthisproblem
preserving methods for distributed energy management [17]– as an online convex optimization in a non-stationary
[19]. environment.
In addition to the solution based on optimization theory, • In our setting, we consider a bandit feedback, where each
some prior works study the energy management in DERs node/useronlyobservestheenergysatisfactionlevelofits
from a game-theoretical [20]–[23] or a reinforcement learning neighbors. Thus, the nodes in the network can maintain
perspective [19], [24]. In our work, we propose a distributed privacyanddonotrevealtheirconsumptionandgeneration
online convex optimization strategy with privacy preservation. level to other nodes.
Therefore, we do not elaborate game-theoretical methods • To solve the proposed energy resource sharing problem
intensively. with a gradient-free method, we develop an algorithm,
Zinkevich et al. [25] design an online convex optimization namely, Distributed Resource Sharing with regularized
(OCO) algorithm based on gradient descent inspired by the Lagrangian function, inspired by [33] and its extension in
infinitesimalgradientascentconceptfromrepeatedgames.The a dynamic environment, which achieve a dynamic regret
√
regret of the learning method is upper bounded by O( T). boundofO˜((1+P T)21T1 2+(1+P T)1 4T43)andO˜(T3 4(1+
Reference[26]extends[25]toabanditsetting,namely,bandit P T)1 2), respectively, where T refers to the total number
convex optimization (BCO), where in each period, only the ofroundsandP T referstothepath-lengthofcomparators.
cost-utility ratio is observable. The proposed gradient-free Table I compares our proposed algorithm with the state-
method obtains a regret bound O(T3/4) for the general case of-the-art.
forboundedandLipschitz-continuousconvexlossfunction.The • To reduce the constraint violation in real-world imple-
authorsof[27]proposeanear-optimalalgorithmforBCOwith mentation, we propose one adjustment step that does not
strongly-convex and smooth loss functions and prove a regret worsen the regret bound.
√
bound of O˜( T). Besides, they introduce a self-concordant • We evaluate our proposed algorithm using a real-world
barrier function to solve constrained BCO problems. In that datasetandcompareitwithstate-of-the-artalgorithms.Ex-
research, the authors assume that the constraint always holds, perimental results show that our proposal reduces energy
and apply a projection step. Nevertheless, considering the con- waste, thereby preventing an environmental damage.
straintsattheprojectionstepiscomputationallyexpensive[28]. The rest of this paper is organized as follows. In Section II,
Besides,inpracticalapplications,thelearnermaybeconcerned we formulate the problem. Section III motivates and explains3
TABLE I: Our two proposed algorithms compared to the SOTA research in BCO.
Reference Problem Type Constraint Feedback Hyper parameter Dynamic Regret Meta-learning
[29] Centralized (cid:37) Bandit Constant (cid:37) (cid:37)
[33] Distributed (cid:33) Bandit Time-varying (cid:33) (cid:37)
[34] Centralized (cid:37) Bandit Constant (cid:33) (cid:33)
[36] Centralized (cid:33) Full Information Time-varying (cid:33) (cid:33)
DRS Distributed (cid:33) Bandit Time-varying (cid:33) (cid:37)
MA-NSDRS Distributed (cid:33) Bandit Time-varying (cid:33) (cid:33)
the “Distributed Resource Sharing” (DRS) algorithm and
its improved version “Meta Algorithm for Non-stationary
Distributed Resource Sharing” (MA-NSDRS). Section III
includes the theoretical analysis. Section IV demonstrates the
numerical results and Section V summarizes our work. All
proofs appear in the Appendix. In Section IV, we demonstrate
the numerical simulations using a real-world dataset from the
DERsdataofNewYorkState[37].Finally,SectionVconcludes
the work and suggests some future research directions.
II. PROBLEMFORMULATION
Fig. 1: System Model.
Considerasmartpowersystemwithmultiplenodescollected
in the set N = {1,2,...,N}. Each node has a renewable
energy generator and an energy consumption module. Hence,
it is simultaneously an energy producer and a consumer, i.e., we assume the generation of each node is independent of each
a prosumer [18], [19]. Each node might have distinct energy other in the network. Besides, the energy demand of node
productionandenergyconsumptionlevels.Thus,itisconnected i at time step t is l . It can keep its generated resources
i,t
to some other nodes to as a potential compensation for his or transfer x (k) to its neighbor k ∈ N . The allocation
i,t i
energy shortage, or to donate energy. Specially, if the energy vector of node i yield x =[x (1),...,x (N)]∈X , where
i,t i,t i,t i
transmission loss between two nodes is expected to exceed a X ⊆RN. Finally, at each round, the total resources of agent
i +
(cid:80)
specifiedthresholdfractionofthetransmittedenergy,thenodes i (cid:80)yields k∈N˜ ix k,t(i), which includes the received resources
do not exchange energy, resulting in no edge between them in x (i)andtheamountnodeireservesforitselfx (i).
k∈Ni k,t i,t
the graph. Conversely, an edge exists if the transmission loss We define node i’s utility in terms of its energy satisfaction
is below this threshold. Thus, our model considers DERs in level compared to its demand l . Formally,
i,t
a small graphical area with little energy transmission loss. In
(cid:80)
x (i)
addition to the self-generated energy, each node also connects f¯ =min{ k∈N˜ i k,t ,1}. (1)
to the main power grid. Note that the main power grid receives i,t l i,t
inputfromthetraditionalpowergenerationplants,whichincurs Besides, distributing energy has a hard (feasibility) constraint:
high power loss during the transmission and relies mainly on The energy that node i distributes to its neighbors should not
fossil fuel consumption. As such, it is not the ideal source exceed the generation. Formally,
of the energy. Each node firstly relies on the local energy
(cid:88)
generation and the received energy from its neighbors in a g i,t = x i,t(j)−d i,t =⟨a˜ i,x i,t⟩−d i,t ≤0, (2)
small graphical area. The main power grid only assists in vital j∈N˜
i
cases as the last choice, and we consider the simplified model
where a˜ is the i-th row of the matrix A˜. Considering the
with the main grid with unlimited capacity. Beyond that, it i
cooperation among agents, we define the loss function as
does not play any role in our setting; Therefore, we do not
include it in our mathematical model. Figure 1 depicts the f =1− 1 (cid:88) f¯ =1− 1 ⟨a˜ ,f¯⟩, (3)
system model . i,t |N˜ | j,t |N˜ | i t
TheDERstransmissionfollowstheundirectednetworkgraph
i j∈N˜
i
i
G =(N,E),i.e.,alongsidetheedgesE.LetN ={j :(i,j)∈ where f¯ =[f¯ ,...,f¯ ]. In other words, the loss function
i t 1,t N,t
E} be the set of node i’s neighbors and N˜ =N ∪{i}, the set measures the shortage level of each node’s neighbors after the
i i
that includes node i’s neighbors and node i. Similarly, A is the cooperative energy allocation. For simplicity, we assume that
adjacency matrix of the network, where A =1 if (i,j)∈E theneighbornodesarecloseenoughsothattheenergytransfer
i,j
and A˜ =A+I when the neighboring nodes include the node cost is negligible. However, extending our methodology to
itself. the case of costly energy transfer is straightforward. Below,
At each round t, node i’s energy generation amount is d , we state assumptions concerning the loss function (3) and the
i,t
whichisarandomvariablewithexpectationµ .Forsimplicity, constraint function (2) and a proposition concerning the loss
i,t4
function. limitation, we define the dynamic regret as the difference
between the cumulative loss of the player i and that of a
Assumption 1. Thelossfunctionf andtheconstraintfunction
comparator sequence u ∈X. Formally,
arebounded.WedenotetheirboundsbyF andG,respectively. i,t
T T
Assumption 2. For each agent, the action space X i is inside D−Ri (u ,...,u )=E[(cid:88) f (x )]−(cid:88) f (u ).
a ball with radius R and contains a ball with radius r . T i,1 i,T i,t i,t i,t i,t
i i t=1 t=1
(6)
Proposition 1. The loss function (3) is convex and Lipschitz
continuous with the lipschitz constant L= 1 . Incontrasttothestaticregret,thedynamicregret(6)compares
minj∈Nlj
with a sequence of changing comparators; Hence, it is more
Proof. See Appendix B.
suitable to measure the algorithms’ performance under a non-
Remark 1. The proposed loss function (3) measures the stationary environment.
energy satisfaction level in each node’s neighborhood, which Besides regret, constraint violation, defined below, is a
is proportional to the extra energy charged from the main grid. performance metric of the algorithm.
Under this setup, we aim to minimize the total energy cost of
T
the conventional energy drawn from the main grid. Vi =(cid:88) g+(x ), (7)
T i,t i,t
Remark 2. We can introduce a variation of the loss function t=1
(3) by incorporating a discount factor c(i,j)∈(0,1] for edge where the operator (·)+ = max(·,0) adds all the violations
(i,j) in the network. This factor models the energy dissipation over all iterations. We call it hard constraint and the metric
through transfer. For this modified condition, we define the cumulative hard constraint violation [36].
loss function as
f =1− 1 (cid:88) f¯ III. PROPOSEDSOLUTION
i,t |N˜ | j,t
i j∈N˜
i
We first propose an algorithm to solve the formulated
(cid:80)
=1−
1 (cid:88)
min{
k∈N˜ ic(i,k)x k,t(i)
,1}. (4)
problem in a stationary environment. Afterward, we generalize
|N˜ i|
j∈N˜
i
l i,t the algorithm to deal with the non-stationary environment.
Notethatthisadjustmentdoesnotcompromisetheperformance
A. Distributed Resource-sharing Algorithm
of our algorithm, as it is agnostic to the specific form of
any convex and Lipschitz continuous loss function. As such, We summarize our developed distributed resource-sharing
our proposed algorithm remains applicable and effective. In algorithm(DRS)withbanditfeedbackinAlgorithm1.Detailed
general, a class of loss function that satisfy Assumption 1 and description follows.
2 is workable under our proposed algorithm. For simplicity
andconsistency,wecontinuetoutilizethelossfunctiondefined Algorithm 1 DRS for i∈N
in (3). 1: Initialize: u i,1 ∈SN˜ i, z i,1 ∈(1−ξ i,t)X i, x i,1 =z i,1+
δ u , x′ =x , i∈[n].
i,1 i,1 i,1 i,1
A. Problem Formulation
2: for t=2,...,T do
The energy management procedure follows in successive 3: Play action x′ .
i,t−1
roundst=1,...,T.Itiswidelyrecognizedthatthegeneration 4: Get f¯ i,t−1(x′ i,t−1) and g i,t−1(x′ i,t−1).
of renewable energy resources has random and intermittent 5: Communicate with neighbors and obtain f i,t−1 accord-
characteristics inherently [38]; Hence, we model it as a non- ing to (3).
stationary process. Consequently, the energy shortage at each 6: Select random unit vector u i,t. Let
node is also non-stationary.
z =P (z −η Γˆ ) (8)
Our objective is to develop an algorithm for each node to i,t (1−ξi,t)Xi i,t−1 i,t i,t
minimize the cumulative loss, given by (3), with minimized x =z +δ u (9)
i,t i,t i,t i,t
constraint violations, given by (2). That is equivalent to regret q =(q +γ (g (x′ )−β q ))
i,t i,t−1 i,t i,t−1 i,t−1 i,t i,t−1 +
minimization in a bandit setting. We assume that nodes fully (10)
comply with the output of the algorithm. For a fixed time
horizon T, the static regret is the cost of not playing the 7: if (cid:80) j∈N˜ ix i,t(j)>d i,t then
optimal action in the hindsight. Formally, 8:
S−R Ti
=E[(cid:88)T
f i,t(x i,t)]− xm ∈i
Xn(cid:88)T
f i,t(x). (5)
x′ i,t(i)=
(cid:80)N
jx =i 1,t x(i i,) t(j)d i,t, (11)
t=1 t=1
The static regret implicitly assumes that there is a reasonably 9: else
good decision over all iterations [34]. However, in non- 10: x′ i,t =x i,t.
stationary environments, the underlying distribution of the 11: end if
online reward function changes [39]–[41]. To address this 12: end for5
straIn teD gyRS in,t ph ae raa lg lee ln .ts Lr eu tn zth be eo an nlin ue pdb aa tn ind git vc ao rn iv ae bx leo .p Tti hm ei az ca tt ii oo nn ( ξ|Ni|1
=FiL˜
δ)21 /( rR2/ w2 i+
t
thRP L˜T) =3 4, 3Lβ
i, +t
=
LRG
/rit1
1 a/2
n, dγ
Ai, st
su=
mpG ti2
i
o1
t n1/2
1
aa nn dd
i,t i,t i
vectorxdenotesanestimationofz,i.e.,x=z+δu,whereu
2 hold. The expected dynamic regret and the violation of
is a randomly generated unit vector. The DRS algorithm firstly
constraints of Algorithm 1 satisfy
initializes the parameter by randomly sampling u i,1 ∈ SN˜ i
and z
i,1
∈ (1−ξ i,t)X i. It then calculates the corresponding D−R Ti ≤O˜((1+P T)21T1 2 +(1+P T)1 4T3 4) (19)
x i,1 and x′ i,1. V Ti ≤O˜([(1+P T)1 2T +(1+P T)1 4T5 4]1 2), (20)
At every round t, each agent i plays an action x′ that
y fri oe mlds its som nee igi hn bd oiv ri sd ,u ea al cl hos as gf e¯ ni, tt− o1 b. taA inft ser thr eec fiei nv ai lng lof se sei, dt fb i,a t−ck
1
f lo or gTany fac co tom rp s.ar Inato ar bos ve eq ,u Pen Tce =u (cid:80)1,
T
t. =. 2., ∥u uT t−∈ uX t−a 1n ∥d iO s˜( th·) eo pm ai tt hs
-
based on its own and neighbors’ losses. Subsequently, the length.
algorithm updates the estimations using the bandit gradient
Proof. See appendix C.
descent method via two projection functions. Motivated by
regularized Lagrangian proposed in [28], [29], [33], we define
The following corollary characterises the regret of Algo-
the regularized Lagrangian function for DRS as
rithm 1 for the path length P =0.
T
β
L (x,q)=f (x)+qg (x)− q2, (12) Corollary 1. Set the hyper parameters δ =
i,t i,t i,t 2 i,t
w fuh ne cr te iof ni s, ,t wan hd ileg i q,t ∈re Rsp +ec it siv te hl ey dd ue an lo vte art ih ae bll eo .s Ts- hean ud pdc ao tn est sr ta ei pn st ( γ th| iN e,tLi ˜ s| =F tai t)
G
i1 2
c2
i( 1
t
r1R
e/
g22 t/ rs e2 a t) n1 4 od,
f
ξ Aη ii l,, gtt o== ritδ h(
i,
m| tN /i r 1|1 iF . siL I a˜ f t) iA s1 2 fis( s eR u s2 mt/ p2 t) io3 4 n, sβ 1i,t an= d 2Gi ht1 o1/ l2 d, ,
(8) and (10) are originally from
x
i,t+1
=P X(x i,t−η i∇ xL i,t(x i,t,q i,t)), (13) S−R Ti ≤O˜(T3/4), V Ti ≤O˜(T85). (21)
q i,t+1 =(q i,t+γ i∇ qL i,t(x i,t,q i,t)) +, (14) Corollary 2. Set the hyperparameters δ i,t =
where ∇ xL i,t(x i,t,q i,t)) = ∇f i,t(x i,t) + (∇g i,t(x i,t))Tq
i,t
(|N Li ˜|Fi)1 2(R2/2+ tRPT)1 4, η i,t = ( |Ni|1 FiL˜)1 2(R2/2+ tRPT)43,
and ∇ L (x ,q )) = g (x )−βq . Lemma 1 offers β = 1 , γ = 1 and ξ = δ /r . If
the
appq roxi, it mai t, it oni o,t
f the
gri a,t dieni, tt
under
bi, at
ndit feedback.
Asi, st umptioG nsit1 1/2 andi 2,t
hold,
G w2 iit th1/2
our
adjusi, tt
ment
stei p,t
s
(i
Line
7-10) in Algorithm 1, the dynamic regret bound and static
Lemma 1 ( [26]). Fix δ >0 as a small smoothing parameter.
regret bound have the same growth order as
Over the random unit vectors u,
E [f(x+δu)]=fˆ(x) (15) D−R Ti ≤O˜((1+P T)21T1 2 +(1+P T)1 4T3 4) (22)
u
S−Ri ≤O˜(T3/4). (23)
E [f(x+δu)u]= δ ∇ˆf(x), (16) T
u N Proof. See appendix D.
where N is the dimension of x.
ByLemma1,theupdateddirectioninformationunderbandit
B. Meta Algorithm for Non-stationary DRS
feedback yields
As stated by Theorem 1, selecting the hyperparameters
Γˆ i,t =∇ˆf i,t−1(z i,t−1)+(∇ˆg i,t−1(z i,t−1))Tq i,t (17) that minimize the regret depends on P T; Nevertheless, P T
N is unknown and difficult to predict in real-world applications.
= [f (x )u +(g (x )u )Tq ].
δ i,t i,t−1 i,t−1 i,t−1 i,t−1 i,t−1 i,t The online ensemble is a solution to address that problem.
i,t−1
(18) It maintains candidates in parallel and uses expert-tracking
algorithms to combine predictions and track the best parameter
Besides, (10) is the same as projection function (14) without
in a grid search manner [42].
any approximations.
Nonetheless, in bandit convex optimization, implementing
Most cutting-edge methods to handle time-varying con-
the online ensemble is cumbersome since only the reward/loss
straints prevent constraint violations in the long run, e.g.,
function value is available. The parameter-free algorithm
on average, while ignoring intermediary rounds. However, in
proposed in [34] mitigates this limitation in the bandit convex
reality, such a setting can be severely harmful and even make
optimization without considering the constraint violation.
the problem infeasible. To deal with that issue, we propose
Motivated by [34] and [36], we propose our MA-NSDRS
adjustments in our method that reduce or eliminate constraint
(Metaalgorithmfornon-stationarydistributedresourcesharing)
violations. If the aggregated energy distribution of a node
algorithm, which is also an online ensemble method. More
exceeds its existing generated resources, then it calculates a
precisely, it combines a meta algorithm and several expert
new distribution profile to its neighborhood (including itself)
x i ∈RN˜ i according to (11). algorithms with our proposed DRS algorithm (Algorithm 1).
Details follow.
1) Performance Guarantees: The following theorem states
a) Expert Algorithm: Algorithm 2 maintains the pool of
the regret bound of our proposed algorithm.
candidate step sizes H for each agent and initializes an expert
Theorem 1. Set δ
i,t
= (|N Li ˜|Fi)1 2(R2/2+ tRPT)1 4, η
i,t
= for each candidate step size.6
AccordingtoTheorem1,thebestpossiblestepsizeisη† = Algorithm 2 MA-NSDRS: Meta algorithm for non-stationary
i,t
(cid:113) distributed resource sharing
R (2R2+R P )/(|N |F L˜)·t−3/4. Due to the unknown
path-i lengti h P ,i thT is stepi sizei is not available. Since 0≤P ≤ 1: Input: time horizon T, number of experts K, pool of
T T
candidate step sizes H = {η ,...,η }, learning rate of
2R T,onecanconcludethatthebeststepsizeliesintherange 1 K
i
the meta algorithm ϵ.
(cid:115) (cid:115)
|N2 iR |Fi3 iL˜t−3 4 ≤η† ≤ 2R |Ni3( i1 |F+ iL˜T) t− 43. (24) 2: In •iti ual ii ,z 0e ∈: SN˜ i, z
i,0
∈ (1−ξ i)X i, x
i,0
= z i,0+δ iu i,0,
x′ =x , i∈[N].
Therefore, the pool of candidate step sizes H yields i,0 i,0
(cid:115) • (K experts) ω ik ,1 = K K+1 k(k1 +1)
H=(cid:110) η
k
=2k−1 2|N2R i|F3
iL˜
·t− 43|k =1,2,...,K(cid:111) , (25) 3 4:
:
for Rt ec= eiv1 e,. x..
k
i,, tT frod mo
each expert k
whereK =⌈1 2log 2(1+T)⌉+1isthenumberofcandidatestep zk i,t =P (1−ξi)Xi(zj i,t−1−η kΓˆ i,t) (28)
sizes. The configuration (25) ensures the existence of an index
k st∗ ep∈ si[ zK e] insu Hch wt hh ia ct h,η k d∗ es≤ piteη† be≤ ing2η sk u∗ b; oi p.e ti. m, ath l,er ise se ux fi fis cts ieno tn lye 5: Obtain z i,t =(cid:80) k∈[K]ω ik ,tzk i,t
close to the optimal step size η†. 6: Ob (cid:80)tain x i,t =z i,t+δ iu i,t
Define the surrogate loss l :(1−ξ)X →R as
7: if j∈N˜ ix i,t(j)>d i,t then
t 8:
l t(x)=⟨∇ˆf i,t(x),x−x t⟩, (26)
x′ (i)=
x i,t(i)
d , (29)
i,t (cid:80)N
x (j)
i,t
where ∇ˆf (x) is the estimated gradient. The properties of j=1 i,t
i,t
the surrogate loss are as follow [34]. 9: else
Property 1. For any x∈(1−ξ)X, ∇l (x)=∇ˆf (x).
10: x′
i,t
=x i,t.
t i,t 11: end if
Property 2. For any v ∈ (1 − ξ)X, E[fˆ(x ) − fˆ(v)] ≤ 12: Update
t t t
E[l t(x t)−l t(v)] q =(q +γ (g (x′ )−β q )) (30)
i,t i,t−1 i i,t−1 i,t−1 i i,t−1 +
Attimestept,eachexpertk runstheonlinegradientdescent
zk
i,t
=P (1−ξi,t)Xi(zj i,t−1−η kΓˆ i,t), (27) 13: P glay (a xct ′ion )x
.
′ i,t−1 and receive f¯ i,t−1(x′ i,t−1) and
i,t−1 i,t−1
where η k ∈H is the step size of the expert k, Γˆ i,t is defined 14: Communicate with neighbors and obtain f i,t−1 accord-
in (18). Thanks to the Property 1, all experts can perform the ing to (3).
exact online gradient descent in the same direction Γˆ i,t at each 15: Compute gradient and construct surrogate loss as
time step t [34].
l (z)=⟨∇ˆf ,z−z ⟩. (31)
i,t i,t i,t
b) Meta Algorithm: To combine the predictions from
multiple experts, we utilize the exponentially weighted average
forecaster algorithm [43] with non-uniform initial weights 16: Update the weight of each expert k by
as meta algorithm (Line 16). The modified meta algorithm, ωk exp(cid:0) −ϵl (zk )(cid:1)
togetherwithourproposedDRSalgorithm,yieldsourproposed ωk = i,t i,t i,t (32)
i,t+1 (cid:80) ωk exp(cid:0) −ϵl (zk )(cid:1)
MA-NSDRS algorithm for minimizing the dynamic regret of k∈[K] i,t i,t i,t
our formulated problem in non-stationary environments. The 17: end for
MA-NSDRS algorithm is summarized in Algorithm 2.
1) Performance Guarantees:
Theorem 2. Select the step sizes according to (25), δ i,t = Corollary 3. Follow the hyper parameter selection in
( ξ p| i rN , otLi p˜| = eF ri) δ lei1 2 , at( / rR nr2 ii n/ .2 gL+ t reR atP teAT s) ϵs1 4 u f, om rβ p ti t h, it eon m= 1 etaG ani at1 d l1 g/ o22 r, ih tγ hoi ml, dt ,. t= B hey MG se2 i Al1 t e1 -c N/2 t Sin Da g Rnd a
S
( AT |h sN se Li ˜ uo |F mre i p)m t1 2 io( n2 R: 2 t 1/2s a)e n1 4t d, s β 2t ie ,p t ho= ls di .Gze tis ht1 1 e/2a s,c tac γo ti i,r ctd =i rn eg gG re2 it t1 to 1/ o2 f( .2 AA5 l) s g, s ou rmδ ii t, e ht mtha= 2t
algorithm guarantees the following bound on the expected satisfies
dynamic regret
S−Ri ≤O˜(T3/4). (34)
T
E[D−R Ti ]≤O˜(T3 4(1+P T)1 2), (33)
Corollary 4. Select the step sizes according to (25), δ =
f oo mr ita sn ly ogco Tm fp aa cr ta ot ro s,r as ne dqu Pe Tnc =e u (cid:80)1, T t=.. 2. ∥, uu tT −∈ uX t−. 1B ∥e is sid te hs e, pO˜ a( th·) - ( ξ|N Li ˜| =Fi δ)1 2( /R r2/ .2 L+ t eR tP AT s) s1 4 u, mβ pti i,t on=
1
aG ni dt1 1/ 22, hoγ li d,t
.
S= incG e2 i t1 t h1/ e2i m, at en td
a
length. i,t i,t i
algorithm only influences on the update step (8), the constraint
Proof. See Appendix E. violation of Algorithm 2 remains as stated in Theorem 1 in7
the non-stationary environment
V Ti ≤O˜([(1+P T)1 2T +(1+P T)1 4T5 4]1 2). (35)
Similarly, the constraint violation of Algorithm 2 in stationary
environment (P =0) yields
T
V Ti ≤O˜(T85). (36)
Besides, when the adjustment step is applied in MA-NSDRS,
the dynamic regret bound and the static regret bound follow
the same growth-rate as
E[D−R Ti ]≤O˜(T3 4(1+P T)1 2),S−R Ti ≤O˜(T3/4). (37) Fig. 2: Map of DERs facilities.
Remark 3. DRS algorithm has a storage and computational
complexity independent of t since it stores and updates only
z i,t anda i,t.Incontrast,theMA-NSDRSalgorithmhasaO(T) 800 N No od de e 1 2 N No od de e 3 4 N No od de e 5 6
storagecomplexitybecausethereareK =⌈1log (1+T)⌉+1 700
2 2
experts running at each time step. The computational complex- 600
ity of the MA-NSDRS algorithm is O(T2). Both the DRS and 500
400
MA-NSDRS algorithms operate distributedly. However, due to
300
the higher computational costs associated with larger network
200
sizes or longer time horizons, the MA-NSDRS algorithm faces
100
scalability limitations. 0 2000 4000 6000 8000 10000
t (Trials)
(a) Network structure. (b)Time-varyingelectricitygeneration.
IV. NUMERICALRESULTS Fig. 3: Setting of Experiment I.
We evaluate our proposed resource-sharing policy using a
real-world dataset, which records the energy production and
TheresultsappearinFigure4.Figure4ashowsthesystem’s
position of several DER facilities in the state of New York
cumulative loss. Figure 4b depicts the corresponding constraint
[37].1 According to our problem formulation, we consider the
violation. In addition, the figures illustrate the difference
connected DERs in a relative small graphical area. Therefore,
between the two cases when the adjustment is utilized and
weselectfacilitiesinStatenIsland.Figure2showsanoverview
otherwise. Figure 4 shows that MA-NSDRS-NA, which is our
ofthelocationsofdifferentkindsofDERsfacilities.Itincludes
20-solar photovoltaic system (PV), six combined heat and
power (CHP), zero anaerobic digester (ADG), six fuel cells
andoneenergystorageinStatenIsland.Here,weonlyconsider 5000 DRS DRS MA-NSDRS 2000 MA-NSDRS
the PVs. 4000 D MR AS -N-N SA DRS-NA D MR AS -N-N SA DRS-NA
1500 In our setting, each graph vertex is an electricity gener- 3000
ator and consumer simultaneously. We assume each node’s 2000 1000
generation capacity is determined by the dataset. Besides, as 1000 500
the dataset does not include a demand model, we consider a 0 0
0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000
t (time step) t (time step)
balanced demand across the network. Specifically, the total
(a) Average cumulative loss. (b) Constraint violation.
demand of all nodes equals the total generation capacity, and
each node has an equal share of this demand. Besides, we Fig. 4: Result of Experiment I.
assume that if the distance between two PVs is within two
proposedAlgorithm2withouttheadjustmentstep,hasthebest
districts, one can consider them connected. Each node can
performance concerning both regret and constraint violation.
transmit the energy produced to its neighboring nodes as
Indeed, it has the lowest cumulative loss and its long term
reflected by the graph structure. As our algorithm operates
constraint violation are also guaranteed to converge to zero.
under a bandit feedback model, the specific demand model at
Compared to DRS algorithms, MA-NSDRS algorithms have
each node does not impact its performance in experiments.
better performance; that is, the meta algorithm in MA-NSDRS
can track the optimal hyperparameter in the non-stationary
A. Experiment I environment.
First, we evaluate our proposed method with a small size Besides, after adding the adjustment step, the regret of
network with only six PV facilities (six nodes). Figure 3a and both algorithms (DRS and MA-NSDRS) increases, which
Figure 3b show the network structure and the time-varying is consistent with our theoretical analysis. Figure 4b shows
generated capacity for each node respectively. that the adjustment step reduces the constraint violation to
zero, whereas the algorithms without the adjustment step offer
1Thedataisavailableathttps://der.nyserda.ny.gov/map/ only long-term guarantees. Thus, there is a trade-off between
ssoL
evitalumuC
)Wk(
yticirtcelE
.neG
noitaloiV
ecruoseR
detcepxE8
No. P No. P No. P
minimizing the regret and constraint violation. To evaluate our T T T
algorithm from the energy-efficient perspective, in Figure 5, 1 974.44 8 701.17 15 1008.00
we depict the percentage of the energy level compared with 2 856.72 9 520.08 16 724.83
the required amount in each node. We also include the initial 3 1272.47 10 959.51 17 697.88
energy level as the reference. 4 1005.35 11 895.04 18 644.84
5 1372.40 12 2227.02 19 460.73
6 1255.26 13 846.01 20 499.80
7 804.10 14 1400.75
1.75 DRS MA-NSDRS Init
1.50 TABLE II: P T of each node under the time-varying energy
1.25 distribution.
1.00
0.75
0.50 300000 DRS 16000 DRS
0.25 250000 M D MRA AS- -N N-NS SAD DR RS
S-NA
11 24 00 00 00 M D MRA AS- -N N-NS SAD DR RS
S-NA
0.00 1 2 3 4 5 6 200000 BanSaP 10000 BanSaP
150000 8000
Fig. 5: Resource distribution of each node. 6000 100000
4000
50000 2000
From Figure 5, one can conclude that our proposed algo- 0 0
0 5000 10000 15000 20000 25000 30000 0 5000 10000 15000 20000 25000 30000
t (time step) t (time step)
rithms, especially MA-NSDRS, result in an efficient energy
(a) Average cumulative loss. (b) Constraint violation.
distribution among nodes, meaning that most of them achieve
their required level. Particularly, the proposed algorithms Fig. 7: Result of Experiment II.
change the situation of nodes 1, 4, and 5 from energy-
inadequate to full satisfaction, i.e., above the threshold 1.0. At
the same time, they prevent wasting the energy in node 2,3,6.
DRS MA-NSDRS Init
2.5
B. Experiment II 2.0
In this section, we evaluate our proposed algorithms in a 1.5
network with 20 PV facilities. Figure 6 shows the network
1.0
structure. Besides, Table II includes the path length P
T
0.5
of the optimal comparator sequence under the time-varying
energy distribution. We compare our proposed algorithms 0.0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
with one benchmark, i.e., an adapted version of BanSaP
algorithm proposed in [44]. The BanSaP algorithm addresses Fig. 8: Resource distribution of each node.
the challenge of online convex optimization with time-varying
loss functions and constraints, aligning well with our problem
Figure 7a shows the cumulative loss of the proposed
formulation.BanSaPalgorithmhasthesamecomputationaland
algorithms. Figure 7b depicts the corresponding constraint
storage complexity as our proposed DRS algorithm. Besides,
violation. Figure 8 illustrates the resource efficiency level and
it was specifically designed to tackle the task allocation
the initial resource condition. Based on the figures, we can
problem within IoT management, a scenario analogous to our
conclude the following.
energy resource allocation challenge. Therefore, we choose to
benchmark our proposed algorithm against BanSaP to evaluate • In Figure 7, our proposed algorithm MA-NSDRS-NA
its effectiveness. achieves the best performance in terms of minimizing the
loss and constraint violation.
• Compared to the algorithms without adjustment step, the
algorithms with adjustment demonstrate a higher cumu-
lative loss; Nonetheless, when adherence to feasibility
constraints is paramount, adjusting the step is inevitable.
• Figure 8 shows the energy level compared with the
satisfactory amount in each node after convergence of
the proposed algorithms. Despite the performance dip
resulting from the adjustment step, our algorithm excels
inreallocatingenergyresources,ensuringamoreequitable
distribution across the network. Notably, our proposed
algorithm brings about significant enhancements in the
Fig. 6: Network structure of Experiment II. energy distribution within the network. Specifically, it
effectively uses the energy surplus in nodes 6, 11, and 14
ssoL
evitalumuC
noitaloiV
ecruoseR
detcepxE9
to mitigate the energy shortages in nodes 1, 2, 3, 5, 8, Lemma 2. [33] For any constants θ ∈[0,1], κ∈[0,1), and
and 13. Remarkably, several shortage nodes(1,2,3,8) have s≤T ∈N , it holds that
+
no direct connection to those with excessive energy levels.
1 1 1
This achievement shows the considerable advantages of (t+1)κ(
tθ
− (t+1)θ)≤
t
∀t∈N +, (40)
our algorithm in optimizing energy efficiency throughout
the entire network. (cid:88)T 1 T1−κ
≤ , (41)
• Compared to BanSaP, all the variations of our proposed tκ 1−κ
t=s
algorithm have better performance concerning cumulative
T
loss and constraint violation. There are several reasons to
(cid:88)1
≤2logT, if T ≥3. (42)
explain the weak performance of BanSaP. First, it uses t
t=s
a constant hyperparameter, which causes high estimation
errorsinthebeginningduetothebanditfeedback.Besides,
Based on Theorem 2 in [25], we can conclude the dynamic
its update step is different from ours. In addition, in
regret of online gradient descent (OGD) with time-varying
BanSaP, there is no adjustment and no meta algorithm to
learning rate as shown in the following Theorem.
track the optimal hyperparameter.
• Compared to DRS algorithms, MA-NSDRS has better
performanceintermsofbothlossandconstraintviolation. Theorem 3 (Dynamic Regret of OGD). Consider the online
Thereasonisthemetaalgorithm,whichtrackstheoptimal gradient descent (OGD), which starts with any x ∈ X and
learning rate in the non-stationary environment and thus performs the following update [25], [34]
has a better performance. That implies that our proposed
x =P (x −η ∇f (x )).
t+1 X t t t t
variation of DRS Algorithm 2 can manage the dynamic
environment better. AssumeX isbounded,i.e.,∥x−y∥ ≤R,∀x,y ∈X andthe
2
gradient is also bounded ∥∇f (x )∥≤G , ∀x∈X,t∈[T].
t t f
V. CONCLUSION The dynamic OGD is upper bounded by
In this study, we have addressed the problem of distributed
(cid:88)T (cid:88)T (cid:88)T R2
resourcesharinginnetworksunderadynamicenvironment.We f (x )− f (u )≤G F2 η +
t t t t f t 2η
proposed a distributed algorithm based on the bandit convex 1
t=1 t=1 t=1
optimization and its variation with a meta algorithm. They T T
guarantee O˜((1+P T)1 2T21 +(1+P T)1 4T3 4) and O˜(T3 4(1+ +R2(cid:88) ( 1 − 1 )+R(cid:88)∥u t+1−u t∥ ,
P T)21) expected regret, respectively. Besides, we evaluate our t=1 2η t 2η t+1 t=1 η t
algorithms using a real-world dataset of DERs and compare for any comparator sequence u ,...,u ∈X. Besides, P =
1 T T
their performance with a benchmark, namely, BanSaP. The (cid:80)T ∥u −u ∥ is the path-length.
t=2 t t−1
results show the superior performance of our algorithms. A
significant direction for future research is to generalize our
Note that the proofs of Lemma 2 and Theorem 3 stated
methodstomorepracticalsettings,forexample,byconsidering
above appear in [25], [33], [34], so we do not include them
the correlation of DERs generation between connected nodes
here to avoid redundancy.
or those nearby each other, considering incorporating power
flow models, or allowing for a time-varying/directed network
structure. Lemma 3. Let {x } be the decision sequence generated by
t
(48). The following inequality holds for any sequence {u }
t
APPENDIX
with u ∈X, ∀t,
t
A. Auxiliary Results
L (x ,q)−L (u ,q )
In this section, we provide all auxiliary materials, including t t t t t
1
definitions, propositions, lemmas, and theorems, which we ≤ (∥u −x ∥2−∥u −x ∥2)
2η t t t t+1
require to prove our claims. t
1
Definition 1. [45] A function f : Rn → R is convex if its +
2γ
(∥q−q t∥2−∥q−q t+1∥2)
t
domain is a convex set and for all x,y in its domain, and for
η ∥∇ L (x ,q )∥2 γ ∥∇ L (x ,q )∥2
all λ∈[0,1], we have: + t x t t t + t q t t t . (43)
2 2
f(λx+(1−λ)y)≤λf(x)+(1−λ)f(y). (38)
Definition 2. [46]Areal-valuedfunctionf :R→Riscalled Proof. According to the update step in our algorithm, we have
Lipschitz continuous if there exists a positive real constant K ∥u −x ∥2
t t+1
such that, for all real x and y,
=∥u −P (x)∥
t X
∥f(x)−f(y)∥≤K∥x−y∥ (39) ≤∥u −(x −η ∇ L (x ,q ))∥2
t t t x t t t
Proposition 2. [34] E[fˆ(z )−fˆ(v )] ≤ E[⟨∇ˆf (x),z − =∥u −x ∥2+2(u −x )Tη ∇ L (x ,q )+η2∥∇ L (x ,q )∥2.
t t t t t t t t t t t x t t t t x t t t
v ⟩]. (44)
t10
Thus, we obtain by g (u )≤0 and definition of Lagrangian in (12), we have
t t
(x t−u t)T∇ xL t(x t,q t)≤ 21
η
(∥u t−x t∥2−∥u t−x t+1∥2) f t(x t)−f t(u t)+qg t+(x t)
t 1
+ η 2t∥∇ xL t(x t,q t)∥2. (45) ≤ 2η t(∥u t−x t∥2−∥u t−x t+1∥2)
1 β
Similarly, it holds + (∥q−q ∥2−∥q−q ∥2)+ (∥q∥2−∥q ∥2)
2γ t t+1 2 t
t
(q−q t)T∇ qL t(x t,q t)≤ 21
γ
(∥q−q t∥2−∥q t−q t+1∥2)
+
η t∥∇ xL t(x t,q t)∥2
+
γ t∥∇ qL t(x t,q t)∥2
. (51)
t 2 2
γ
+ 2t∥∇ qL t(x t,q t)∥2. (46) Take the summation of the inequality above from t=1 to T,
we have
Following [25], since the Lagrangian function (12) is convex
in its first argument and concave in its second, we arrive at (cid:88)T
[f (x )−f (u )+qg+(x )]
t t t t t t
L (x ,q )−L (u ,q )≤(x −u)T∇ L (u ,q )
t t t t t t t x t t t t=1
L t(x t,q)−L t(x t,q t)≤(q−q t)∇ qL t(x t,q t). ≤G2(cid:88)T
η (F2+∥q
∥2)+G2(cid:88)T
γ (G2+β2∥q ∥2)
f t t g t t t
Summing up yields
t=1 t=1
T−1 T
L t(x t,q)−L t(u t,q t) + (cid:88) ( 1 − 1 )Q2+(cid:88)β t(∥q∥2−∥q ∥2)
2γ 2γ 2 t
=L (x ,q)−L (x ,q )+L (x ,q )−L (u ,q ) t+1 t
t t t t t t t t t t t t=1 t=1
≤(x t−u)T∇ xL t(u t,q t)+(q−q t)∇ qL t(x t,q t)
+
∥q∥2 +(cid:88)T 1
(∥u −x ∥2−∥u −x ∥2). (52)
≤ 21
η
(∥u t−x t∥2−∥u t−x t+1∥2) 2γ 1 t=1 2η t t t t t+1
t
1
+ (∥q−q ∥2−∥q−q ∥2)
2γ t t+1
t
η ∥∇ L (x ,q )∥2 γ ∥∇ L (x ,q )∥2
+ t x t t t + t q t t t . (47)
2 2
ThisinequalityisobtainedaccordingtoProposition3in[29],
∥∇ L (x ,q )∥2 ≤ 2G2(1+∥q ∥2) and ∥∇ L (x ,q )∥2 ≤
x t t t f t q t t t
2G2(G2+β2∥q ∥2), where F is the bound of loss function
g t t
Theorem 4 (Expected Dynamic Regret of OGD with con-
and G the bound of the constraint function, G and G are
f g
straints). Consider the OGD with constraints, which begins
the bound of loss function gradient and constraint function
with any x ∈X. It performs
1 gradient respectively. Besides,
q
t+x 1t+ =1 =
P
(P 0,+X ∞(x )(t q− t+η t γ∇ t∇xL qt L(x t(t x, tq ,t q))
t))
( (4 48 9)
)
(cid:88)T 21
η
(∥u t−x t∥2−∥u t−x t+1∥2)
t
t=1
Suppose the feasible domain X is bounded, i.e., ∥x−y∥ ≤ T
R for any x,y ∈ X; Meanwhile, the online
functi2
ons
≤(cid:88)(cid:16) 1
∥u −x ∥2−
1
∥u −x ∥2
2η t t 2η t+1 t+1
have bounded gradient magnitude, i.e., ∥∇f t∥ 2 ≤ G f and t=1 t t+1
∥∇g t∥ 2 ≤G g for any x∈X and t∈[T]. Then, the dynamic + 1 ∥u −x ∥2− 1 ∥u −x ∥2
regret of OGD is upper bounded by 2η t+1 t+1 2η t+1 t+1
t+1 t
1 1 (cid:17)
(cid:88)T
[f t(x t)−f t(u t)]
+
2η
t∥u t+1−x t+1∥2−
2η
t∥u t−x t+1∥2 (53)
t=1 According to [36],
T T T−1
≤G fF2(cid:88) η t+G gG2(cid:88) γ t+ (cid:88) ( 2γ1 − 21
γ
)Q2 (cid:88)T
(∥u −x ∥2−∥u −x
∥2)≤2R(cid:88)T
∥u −u ∥.
t+1 t t+1 t+1 t t+1 t+1 t
t=1 t=1 t=1
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥u t+1−u t∥
(50)
Tt= h1
erefore, we have
t=1
2η 2η 2η η
1 t t+1 t
t=1 t=1 T
for any comparator sequence u ,...,u ∈X and P is the (cid:88) 1 (∥u −x ∥2−∥u −x ∥2)
path-length defined as P T =(cid:80)1 T t=2∥u t−T u t−1∥ 2. T t=1 2η t t t t t+1
Proof. First, we state the key self-bounding property. Accord- ≤
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥u t+1−u t∥
.
2η 2η 2η η
ing to Lemma 3, let the {u t} become the optimal sequence, 1 t=1 t t+1 t=1 t11
Then we can obtain of (1- f¯). Thus, it suffices that we prove the convexity of
T function f¯here.
(cid:88)
[f (x )−f (u )+qg+(x )] (cid:80)
t=1 t t t t t t 1−f¯ j,t =1−min{ k∈N˜ ljx k(j) ,1}
≤G2 f(cid:88)T η t(F2+∥q t∥2)+G2 g(cid:88)T γ t(G2+β t2∥q t∥2)+ ∥ 2q γ∥2 =1−min{((cid:80) k∈Nj jx k(j))+x i(j)
,1}
1
t=1 t=1 l
j
T−1 T
+ (cid:88) ( 1 − 1 )Q2+(cid:88)β t(∥q∥2−∥q ∥2) ( =1) 1−min{q(j)+x i(j) ,1}
2γ 2γ 2 t l
t+1 t j
t=1 t=1
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥u t+1−u t∥
. (54)
( =2) 1− 1 2(q(j)+
l
x i(j) +1−|q(j)+
l
x i(j) −1|)
2η 2η 2η η j j
1 t=1 t t+1 t=1 t 1 (cid:88)
=1− (q(j)+x (j)+l −|q(j)+x (j)−l |)
Select β t >2G2 fη t+2G2 gγ tβ t2, then the inequality becomes 2l j j∈N˜
i
i j i j
T 1
(cid:88) =1−(q(j)+l )− (x (j)−|q(j)+x (j)−l |)
[f t(x t)−f t(u t)+qg t+(x t)] j 2l
j
i i j
t=1 (3) 1
= C− (x (j)−|q(j)+x (j)−l |).
≤G
F2(cid:88)T
η +G
G2(cid:88)T
γ
+T (cid:88)−1
(
1
−
1
)Q2
2l
j
i i j
f t g t 2γ 2γ (cid:80)
t+1 t For simplicity, in Equality (1), we have q(j)= x (j).
t=1 t=1 t=1 k∈Nj k
+(cid:88)T β
t∥q∥2+
∥q∥2
+
R2 +R2(cid:88)T
(
1
−
1
)
E nuq mua bl eit ry
s
( b2 a) ser def oer ns tt ho ea fn oa lll oy wzi in ng gt fh oe rmm ui ln aim mu im n(av ,a bl )ue =of 1(t aw +o
2 2γ 2η 2η 2η 2
+Rt= (cid:88)1
T ∥u t+1−u
t∥1
,
1 t=1 t t+1
T
tb h−
h
eu|
s
fa o,−
la
locb
c
w|)
o
i.
r
ndE giq
n
mu ga ul ti
o
st ty
D
h(
e
o3
fi
l) dnr :ie tf ie or ns 1to
,
s foet rti tn hg eC fun= ct1 io− n2 t1 olj( bq e(j c) o+ nvl ej x) ,.
η
t
t=1
1
which can also be written as C−
2l
(λx i(j)+(1−λ)y i(j)
j
T T T
(cid:88) [f (x )−f (u )]+q(cid:88) g+(x )−( 1 +(cid:88)β t)q2 −|q(j)+λx i(j)+(1−λ)y i(j)−l j|)≤
t t t t t t 2γ 2 (cid:16) 1 (cid:17) (cid:16)
1
t=1 t=1 t=1 λ C− (x (j)−|q(j)+x (j)−l |) +(1−λ) C
(cid:88)T (cid:88)T T (cid:88)−1 1 1 2l j i i j
≤G F2 η +G G2 γ + ( − )Q2 1 (cid:17)
f t g t 2γ 2γ − (y (j)−|q(j)+y (j)−l |)
t=1 t=1 t=1 t+1 t 2l i i j
j
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥u t+1−u t∥
.
⇐( =4 ⇒)
(λx i(j)+(1−λ)y i(j))
2η 2η 2η η
1 t t+1 t
t=1 t=1 −|q(j)+(λx (j)+(1−λ)y (j))−l |)≥
i i j
By taking maximization for q over the range (0,+∞), we get
λ(x (j)−|q(j)+x (j)−l |)
i i j
(cid:88)T
[f (x )−f (u )]+
[(cid:80)T t=1g t(x t)+]2 +(1−λ)(y i(j)−|q(j)+y i(j)−l j|)
t=1 t t t t 2/γ 1+2(cid:80)T t=1β t ⇐( =5 ⇒) −|q(j)+(λx i(j)+(1−λ)y i(j))−l j|)
T T T−1
≤G F2(cid:88) η +G G2(cid:88) γ + (cid:88) ( 1 − 1 )Q2 ≥−λ|q(j)+x i(j)−l j|−(1−λ)|q(j)+y i(j)−l j|
f t g t 2γ 2γ
t+1 t ⇐⇒|q(j)+(λx (j)+(1−λ)y (j))−l |)
t=1 t=1 t=1 i i j
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥u t+1−u t∥
.
≤λ|q(j)+x i(j)−l j|+(1−λ)|q(j)+y i(j)−l j|, (55)
2η 2η 2η η
1 t t+1 t
t=1 t=1 where (4) follows by setting C = λC + (1 − λ)C and
Besides, by substituting the regret bound by its lower bound multiplying both sides of the equation by − 1 . (5) results
as
(cid:80)T
f (x )−f (u ) ≥ −FT, we can obtain the upper from λx (j)+(1−λ)y (j)=(λx
(j)+(1−λ2 )lj
y (j)). Using
t=1 t t t t i i i i
bound of constraint violation. the triangle inequality, i.e., |γ+δ|≤|γ|+|δ|, one can prove
that the following inequality holds:
|q(j)+(λx (j)+(1−λ)y (j))−l |)
i i j
B. Proof of Proposition 1
≤λ|q(j)+x (j)−l |+(1−λ)|q(j)+y (j)−l |
i j i j
Part 1- At first, we prove the convexity of the loss function
Finally, by summing over all the neighbors, we conclude that
(3).
our loss function is convex.
The loss function f (x ) = 1 − 1 (cid:80) f¯ =
|N˜1 i|(cid:80)
j∈N˜
i(cid:16) 1 − min{(cid:80)i k∈Ni ˜ lj ixk(j) ,1}(cid:17) i|N s˜ i t| he j c∈ oN m˜ i bij n,t ation losP sa fr ut nc2 t- ioS nec (o 3n ).dly, we prove the Lipschitz-continuity of the12
Based on definition, the loss function is term (a) can be upper bounded by Theorem 4 as follows.
(cid:80)
f i,t(x i,t)=1− |N˜1
i|
j(cid:88)
∈N˜
imin{ k∈Njx k,t l( jj)+x i,t(j) ,1}, (cid:88) t=T 1(cid:16) fˆ i,t(z i,t)−fˆ i,t(v i,t)(cid:17) ]
(cid:80) T T T−1
w neh ie gr he borsk .∈ DN ej nx ok t, et( (cid:80)j) only xdepe (jn )ds =o mn ,th fe orac dt ii fo fn ereo nf tn ao cd te ioi n’ ss ≤F i2(cid:88) Gˆ fi,tη i,t+G2
i
(cid:88) γ t+ (cid:88) ( 2γ1 − 2γ1 )Q2
k∈Nj k,t t=1 t=1 t=1 i,t+1 i,t
x and y of node i,
i,t i,t
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥v i,t+1−v i,t∥
f(x )−f(y )
i,t i,t 2η i,1 2η i,t 2η i,t+1 η i,t
(cid:80) t=1 t=1
= |Nj ˜∈ iN |˜ i(cid:16) min{m+ ly ji,t(j) ,1}−min{m+ lx ji,t(j) ,1}(cid:17) ,
≤F
i2(cid:88)T 2|N δ2i|2
η i,t+G2
i
(cid:88)T
γ
t+T (cid:88)−1
(
2γ1
−
2γ1
)Q2
(56) t=1 i,t t=1 t=1 i,t+1 i,t
which leads to four possible result
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥v i,t+1−v i,t∥
.
2η 2η 2η η
• m+y lji,t(j) < 1 and m+x lji,t(j) < 1: f(x i,t)−f(y i,t) = i,1 t=1 i,t i,t+1 t=1 i,t
•
(cid:80)
m+j∈
y
ljiN ,˜ ti
(jy )i, ≥t(j 1)−
lj
ax ni, dt(j m);
+x lji,t(j) ≥1: f(x i,t)−f(y i,t)=0;
B
tξ
eie
, rt
ms )i ∥d
u
(e bs
i
),,
t+ a1
nd−(cid:80)
tu
eT
t=
ri
m,1
t∥∥ (.v
cTi ), ht c+
e
a1
nr−
ig
bov
eri
o
b, ut
o∥
s ua nn da el
dys=
bis yin 2L[3
(cid:80)4(cid:80)
]
TsT
t h= o1
δw(1
s t ah
n−
a dt
• (cid:80)m+ j∈y lji N, ˜t i( (j) 1−≥ x1
i, lt
ja (n j)d )≤m+ (cid:80)x lji, jt ∈(j N˜) i< yi,t1 (j:
)−
lf jx(x i,ti (,t j) );−f(y i,t) = (cid:80) losT
t s= f1
u( nL cδ
ti i, ot
n+ fL ,R reξ
si p,t
e) ctw ivi et lh y,L wit th he ouL tip ins vc oh li vtz inc gon thst et= a1 un nti ko,t nf ot wh ne
• m+yi,t(j) < 1 and m+xi,t(j) ≥ 1: path-length. Thus, the final regret bound follows as:
lj lj
(cid:80) yi,t(j)−xi,t(j) ≤ f(x ) − f(y ) = T T
j∈N˜ i lj i,t i,t E[(cid:88) f (x )]−(cid:88) f (u )
(cid:80) (yi,t(j) −1)<0. i,t i,t i,t i,t
j∈N˜ i lj t=1 t=1
Thus, for different actions x
i,t
and y
i,t
of node i, we have ≤F2(cid:88)T 2|N i|2
η
+G2(cid:88)T
γ
+T (cid:88)−1
(
1
−
1
)Q2
∥f(x)−f(y)∥≤K∥x−y∥,whereK ≥ 1 .According i δ2 i,t i t 2γ 2γ
minj∈Nlj t=1 i,t t=1 t=1 i,t+1 i,t
to Definition 2, the loss function is Lipschitz continuous with
Lipschitz constant L= minj1 ∈Nlj.
+
R2 +R2(cid:88)T
(
1
−
1 )+R(cid:88)T ∥v i,t+1−v i,t∥
2η 2η 2η η
i,1 i,t i,t+1 i,t
t=1 t=1
T T
(cid:88) (cid:88)
+2L δ + (Lδ +LRξ ). (58)
i,t i,t i,t
C. Proof of Theorem 1 t=1 t=1
The expected dynamic regret can be decomposed as:
By selecting δ
i,t
= (|N Li ˜|Fi)1 2(R2/2+ tRPT)1 4, η
i,t
=
E[(cid:88)T
f (x
)]−(cid:88)T
f (u )
( ξ| iN ,ti =|1 Fi δL˜ i) ,t21 /( rR i,2 w/2 e+ tR caP nT) o3 4 b, taβ ini,t th=
e
finG ait l1 1 r/ e2 g, reγ ti,t bo= undG :2 i1 t1/2, and
i,t i,t i,t i,t
t=1 t=1 T T
(cid:88) (cid:88)
T E[ f (x )]− f (u )
=E[(cid:88)(cid:16)
fˆ (z )−fˆ (v
)(cid:17)
]
i,t i,t i,t i,t
i,t i,t i,t i,t t=1 √ t=1
(cid:124)
t=1
(cid:123)(cid:122) (cid:125)
≤(|N i|F iL˜)1 2( T(R2/2+RP T)21 +(R2/2+RP T)41T3 4)
+E[(cid:88)T
(cid:16)
f
i,tte (r xm i( ,a t)
)−fˆ i,t(z
i,t)(cid:17)
]
+ (|N Ri /|F 2i +L˜) P1 2 T√P TT43((|N i|F iL˜)21 +RlogT +1)
t=1 +Q2logT + T
(cid:124) (cid:123)(cid:122) (cid:125)
term(b) =O˜((1+P T)1 2T1 2 +(1+P T)41T3 4). (59)
T
+E[(cid:88)(cid:16)
fˆ (v )−f (u
)(cid:17)
], (57) Similarly, the constraint violation can also be decomposed as
i,t i,t i,t i,t
t=1 T T T T
(cid:124) (cid:123)(cid:122) (cid:125) (cid:88) g (x )+ =(cid:16)(cid:88) g (x )+−(cid:88) gˆ(z )+(cid:17) +(cid:88) gˆ(z )+,
term(c) t t t t t t t t
t=1 t=1 t=1 t=1
where v ,...,v is the comparator sequence, v =(1−
i,1 i,T i,t
ξ )u , and ξ is the shrinkage parameter. where the first term is bounded by
(cid:80)T
(Lδ + LRξ ),
i,t i,t i,t t=1 i,t i,t
Theterm(a)isessentiallythedynamicregretofthesmoothed and Theorem 4 shows the bound of second term. Thus, the
functions. In the bandit feedback model, the gradient estimator
is set according to (18). Therefore, the step (48) is actually the
online gradient descent over the smoothed function fˆ . Thus,
i,t13
constraint violation is bounded by We have
(cid:88)T
g t(x t)+ ≤O˜([(1+P T)1 2T +(1+P T)1 4T5 4]21).
(cid:88)T
l i,t(zk i,∗
t)−(cid:88)T
l i,t(v i,t)
t=1 t=1 t=1
≤
Gˆi fF2 (cid:88)T
ηk∗
+
R i2 +R2(cid:88)T
(
1
−
1
)
2 i,t 2ηk∗ i 2ηk∗ 2ηk∗
t=1 i,1 t=1 i,t i,t+1
T
D. Proof of Corollary 2
+R
(cid:88)∥v i,t+1−v i,t∥
i η†
t=1 i,t
Proof. Based on (11), the total adjustment can be defined as
∆ the= log si s,t( fux ni, ct t) iow nit ih
s
L∆ ip= sc(cid:80) hitN i z= c1 o| nx ti i, nt( ui o) u− s,x w′ i, et( hi) a| veand because ≤|N i|2F i2(cid:88)T 2(η δi† †,t
)2
+ R η†2
t=1 i,t 1
R′(T)=R(T)+ (cid:88) [f(x′ i,t)−f(x i,t)] +R2(cid:88)T
(
1
−
1
)+2R
(cid:88)T ∥v i,t+1−v i,t∥
≤R(T)+g Li,t> (cid:88)0
(cid:13) (cid:13)x′ i,t−x i,t(cid:13) (cid:13)
(cid:113)i
t=1
η i†
,t
η i†
,t+1
i
t=1
η i†
R,t
(cid:113) |N |F L˜logT
gi,t>0 = |N i|F iL˜(cid:112) 2R i+R iP T(R i+1)T43 + i √ i i ,
N 2R i+P T
(cid:88) (cid:88)
≤R(T)+L |x i,t(i)−x′ i,t(i)| where the first inequality follows from Theorem 3, and the
gi,t>0i=1 second inequality is based on Lemma 1. Besides, ηk∗ ≤
T η† ≤ 2ηk∗ and the last equality holds by substituting
(cid:88)
=R(T)+L g+(x ) (cid:113)
i,t i,t η† = R (2R2+R P )/(|N |F L˜)·t−3/4 and δ = δ† =
t=1 i i i T i i
≤O˜((1+P T)1 2T21 +(1+P T)1 4T3 4). (|N i|F iR i/L˜)1/2t−1/4.
Therefore, the regret increases with the same magnitude as the
previous regret bound. That completes the proof. The next step is to bound the meta-regret. The surrogate
loss l satisfies
t
|l (z)|≤|⟨∇ˆf (z ),z−z ⟩|
i,t i,t i,t i,t
(cid:13) (cid:13)
≤(cid:13)∇ˆf (z)(cid:13) ∥z−z ∥≤2GˆiR, (62)
E. Proof of Theorem 2 (cid:13) i,t (cid:13) i,t f
2
∀z ∈(1−ξ)X.
As shown in (57), the dynamic regret can be decomposed
into three parts. Based on the analysis in Appendix C, term (b)
and term (c) defined in (57) can be bounded by
2L(cid:80)T
δ
t=1 i,t
and
(cid:80)T
(Lδ +LRξ ), respectively.
Lemma 4. [34] For any step size ϵ>0, we have
t=1 i,t i,t
Proposition 2 shows that term (a) defined in (57) can be (cid:88)T
l (z )−
min((cid:88)T
l (zk)+
1
ln
1
)≤2ϵTGˆ2R2. (63)
upper bounded by
t=1
t t k∈[K]
t=1
t t ϵ ω 1k f
T
(cid:88) (cid:113)
term (a)≤E[ (l i,t(z i,t)−l i,t(v i,t))]. (60) By setting ϵ= 1/2TGˆ2 fR2, we can obtain that
t=1
Besides, we have [34] (cid:88)T
l (z
)−(cid:88)T
l (zk)≤Gˆ
R√
2T(1+ln
1
) (64)
t t t t f ωk
(cid:88)T (cid:88)T (cid:88)T t=1 t=1 1
(l (z )−l (v ))= l (z )− l (zk )
t i,t i,t i,t i,t i,t i,t i,t where Gˆ is the estimated gradient.
t=1 t=1 t=1 f
(cid:124) (cid:123)(cid:122) (cid:125)
meta-regret
T T
(cid:88) (cid:88)
+ l (zk )− l (v )), Lemma 4 holds for any k ∈[K] including k∗. Thus,
i,t i,t i,t i,t
t=1 t=1
(cid:124) exper(cid:123) t-(cid:122)
regret
(cid:125) (cid:88)T
l (z
)−(cid:88)T
l (zk∗ )≤GˆiR
√
2T(1+ln
1
)
(61) i,t i,t t i,t f i ωk∗
t=1 t=1 i,1
where zk i,1,...,zk i,T is the prediction sequence of expert k. ≤ R iF i|N i|√ 2T(1+2ln(k∗+1))
This regret decomposition works for any k ∈ [K]. Each δ i,T
(cid:113)
expert performs deterministic online gradient descent over = 2R iF i|N i|L˜T43(1+2ln(k∗+1)). (65)
the surrogate loss. Hence, we use Theorem 3 to bound the
expert-regret. Assume that k∗ is the nearest optimal step size. By combining with the expert regret and term (b) and (c) in14
(57), the dynamic regret is bounded by [14] Y.Wang,S.Mao,andR.M.Nelms,“Distributedonlinealgorithmfor
optimalreal-timeenergydistributioninthesmartgrid,”IEEEInternet
(cid:88)T (cid:88)T ofThingsJournal,vol.1,no.1,pp.70–80,2014.
E[ f i,t(x i,t)]− f i,t(u i,t) [15] A.Salazar,A.Berzoy,W.Song,andJ.M.Velni,“Energymanagement
ofislandednanogridsthroughnonlinearoptimizationusingstochastic
t=1 t=1
dynamic programming,” IEEE Transactions on Industry Applications,
=term (a)+term (b)+term (c)
vol.56,no.3,pp.2129–2137,2020.
T T [16] L.Ding,G.Y.Yin,W.X.Zheng,Q.-L.Hanetal.,“Distributedenergy
(cid:88) (cid:88)
≤term (a)+2L δ + (Lδ +LRξ ) management for smart grids with an event-triggered communication
i,t i,t i,t
scheme,” IEEE Transactions on Control Systems Technology, vol. 27,
t=1 t=1 no.5,pp.1950–1961,2018.
(cid:113)
≤ |N i|F iL˜(cid:112) 2R i+R iP T(R i+1)T3 4 [17] M ba. seS d. trH an. saN ci tz iva em ei, neM rg. yJ m. aH nao gs esa min e, nta sn yd steE m. sF fe or rna ren sd ie dz e, nt“ iaM lu bult ii la dg ie nn gt s-
(cid:113) with distributed energy resources,” IEEE Transactions on Industrial
+ R i √|N i|F iL˜logT +(cid:113) 2R iF i|N i|L˜T43(1+2ln(k∗+1)) [18] I Mnf .o Krm hoa rti ac ss a, nv yo ,l A. .16 N, an jao fi. -3 G, hp ap le. l1 o8 u3 ,6 a– n1 d8 R47 ., R2 a0 z1 z9 a. ghi,“Aframeworkfor
2R +P
i T jointschedulingandpowertradingofprosumersintransactivemarkets,”
(cid:113)
(cid:113) R |N |F L˜logT IEEETransactionsonSustainableEnergy,vol.12,no.2,pp.955–965,
≤ |N i|F iL˜(cid:112) 2R i+R iP T(R i+1)T3 4 + i √ 2Ri +i P [19] 2 Y0 .2 Y0 e. , Y. Tang, H. Wang, X.-P. Zhang, and G. Strbac, “A scalable
i T privacy-preservingmulti-agentdeepreinforcementlearningapproachfor
(cid:113)
+ 2R iF i|N i|L˜T43(1+2ln(⌈log 2(1+P T/(2R i))⌉+1)) l oa nrg Se m-s ac ra tle Gp re ide ,r- vto o- l.pe 1e 2r ,t nr oan .s 6a ,c pti pv .e 5e 1n 8e 5rg –y 52t 0ra 0d ,i 2n 0g 2,” 1.IEEETransactions
=O˜(T3 4(1+P T)1 2). (66) [20] AA ..- LH e. onM -Goh ars ce in ai ,a “n A-R uta od n, omV. ouW s. deW mo an ng d, -sJ id. eJa mts ak ne av gi ec mh, enR t. baS sc eh do ob ner g, aa mn ed
-
theoreticenergyconsumptionschedulingforthefuturesmartgrid,”IEEE
Besides,theupdatestepwithrespecttotheconstraintviolation
TransactionsonSmartGrid,vol.1,no.3,pp.320–331,2010.
keeps the same, thus the constraint violation is the same as [21] H.K.Nguyen,H.Mohsenian-Rad,A.Khodaei,andZ.Han,“Decentral-
Theorem 1. izedreactivepowercompensationusingnashbargainingsolution,”IEEE
TransactionsonSmartGrid,vol.8,no.4,pp.1679–1688,2015.
[22] J.Wang,H.Zhong,J.Qin,W.Tang,R.Rajagopal,Q.Xia,andC.Kang,
REFERENCES “Incentivemechanismforsharingdistributedenergyresources,”Journal
ofModernPowerSystemsandCleanEnergy,vol.7,no.4,pp.837–850,
[1] W.Wei,F.Liu,andS.Mei,“Distributionallyrobustco-optimizationof 2019.
energyandreservedispatch,”IEEETransactionsonSustainableEnergy, [23] S. Maghsudi and M. van der Schaar, “Distributed task management
vol.7,no.1,pp.289–300,2015. incyber-physicalsystems:Howtocooperateunderuncertainty?”IEEE
[2] G. Xu, W. Yu, D. Griffith, N. Golmie, and P. Moulema, “Toward TransactionsonCognitiveCommunicationsandNetworking,vol.5,no.1,
integrating distributed energy resources and storage devices in smart pp.165–180,2019.
grid,”IEEEInternetofThingsjournal,vol.4,no.1,pp.192–204,2016. [24] Y.Wan,J.Qin,X.Yu,T.Yang,andY.Kang,“Price-basedresidential
[3] K.Rahbar,J.Xu,andR.Zhang,“Real-timeenergystoragemanagement demandresponsemanagementinsmartgrids:Areinforcementlearning-
forrenewableintegrationinmicrogrid:Anoff-lineoptimizationapproach,” basedapproach,”IEEE/CAAJournalofAutomaticaSinica,vol.9,no.1,
IEEETransactionsonSmartGrid,vol.6,no.1,pp.124–134,2014. pp.123–134,2021.
[4] D.Wu,T.Yang,A.A.Stoorvogel,andJ.Stoustrup,“Distributedoptimal [25] M.Zinkevich,“Onlineconvexprogrammingandgeneralizedinfinitesimal
coordinationfordistributedenergyresourcesinpowersystems,”IEEE gradientascent,”inProceedingsofthe20thInternationalConferenceon
TransactionsonAutomationScienceandEngineering,vol.14,no.2,pp. MachineLearning(ICML-03),2003,pp.928–936.
414–424,2016. [26] A. D. Flaxman, A. T. Kalai, and H. B. McMahan, “Online convex
[5] W. Yu, D. An, D. Griffith, Q. Yang, and G. Xu, “Towards statistical optimizationinthebanditsetting:gradientdescentwithoutagradient,”
modelingandmachinelearningbasedenergyusageforecastinginsmart 2004.[Online].Available:https://arxiv.org/abs/cs/0408007
grid,”ACMSIGAPPAppliedComputingReview,vol.15,no.1,pp.6–16, [27] E. Hazan and K. Levy, “Bandit convex optimization: Towards tight
2015. bounds,”AdvancesinNeuralInformationProcessingSystems,vol.27,
[6] T.Wang,D.O’Neill,andH.Kamath,“Dynamiccontrolandoptimization 2014.
ofdistributedenergyresourcesinamicrogrid,”IEEETransactionson [28] R. Jenatton, J. Huang, and C. Archambeau, “Adaptive algorithms for
SmartGrid,vol.6,no.6,pp.2884–2894,2015. onlineconvexoptimizationwithlong-termconstraints,”inInternational
[7] Y. Wang, S. Mao, and R. M. Nelms, “Online algorithm for optimal ConferenceonMachineLearning. PMLR,2016,pp.402–411.
real-timeenergydistributioninthesmartgrid,”IEEETransactionson [29] M.Mahdavi,R.Jin,andT.Yang,“Tradingregretforefficiency:online
EmergingTopicsinComputing,vol.1,no.1,pp.10–21,2013. convexoptimizationwithlongtermconstraints,”TheJournalofMachine
[8] I.Atzeni,L.G.Ordóñez,G.Scutari,D.P.Palomar,andJ.R.Fonollosa, LearningResearch,vol.13,no.1,pp.2503–2528,2012.
“Noncooperative and cooperative optimization of distributed energy [30] H.Yu,M.Neely,andX.Wei,“Onlineconvexoptimizationwithstochastic
generation and storage in the demand-side of the smart grid,” IEEE constraints,”AdvancesinNeuralInformationProcessingSystems,vol.30,
TransactionsonSignalProcessing,vol.61,no.10,pp.2454–2472,2013. 2017.
[9] K. M. Chandy, S. H. Low, U. Topcu, and H. Xu, “A simple optimal [31] J. Li, C. Gu, Z. Wu, and T. Huang, “Online learning algorithm for
powerflowmodelwithenergystorage,”in49thIEEEConferenceon distributedconvexoptimizationwithtime-varyingcoupledconstraints
DecisionandControl(CDC). IEEE,2010,pp.1051–1057. andbanditfeedback,”IEEETransactionsonCybernetics,2020.
[10] Y.Zhang,N.Gatsis,andG.B.Giannakis,“Robustenergymanagement [32] S.Liang,G.Yinetal.,“Distributedsmoothconvexoptimizationwith
formicrogridswithhigh-penetrationrenewables,”IEEETransactionson coupledconstraints,”IEEETransactionsonAutomaticControl,vol.65,
SustainableEnergy,vol.4,no.4,pp.944–953,2013. no.1,pp.347–353,2019.
[11] S.MaghsudiandM.vanderSchaar,“Anon-stationarybandit-learning [33] X.Yi,X.Li,T.Yang,L.Xie,T.Chai,andK.H.Johansson,“Distributed
approachtoenergy-efficientfemto-cachingwithrateless-codedtransmis- banditonlineconvexoptimizationwithtime-varyingcoupledinequality
sion,”IEEETransactionsonWirelessCommunications,vol.19,no.7, constraints,”IEEETransactionsonAutomaticControl,vol.66,no.10,
pp.5040–5056,2020. pp.4620–4635,2021.
[12] Y.Guo,M.Pan,andY.Fang,“Optimalpowermanagementofresidential [34] P.Zhao,G.Wang,L.Zhang,andZ.-H.Zhou,“Banditconvexoptimization
customers in the smart grid,” IEEE Transactions on Parallel and in non-stationary environments,” The Journal of Machine Learning
DistributedSystems,vol.23,no.9,pp.1593–1606,2012. Research,vol.22,no.1,pp.5562–5606,2021.
[13] S.Salinas,M.Li,P.Li,andY.Fu,“Dynamicenergymanagementfor [35] I. Tsetis, X. Cheng, and S. Maghsudi, “A bandit online convex
thesmartgridwithdistributedenergyresources,”IEEETransactionson optimizationapproachtodistributedenergymanagementinnetworked
SmartGrid,vol.4,no.4,pp.2139–2151,2013. systems,” in ICASSP 2023-2023 IEEE International Conference on15
Acoustics,SpeechandSignalProcessing(ICASSP). IEEE,2023,pp.
1–5.
[36] H.Guo,X.Liu,H.Wei,andL.Ying,“Onlineconvexoptimizationwith
hardconstraints:Towardsthebestoftwoworldsandbeyond,”Advances
inNeuralInformationProcessingSystems,vol.35,pp.36426–36439,
2022.
[37] “Map of new york state distributed energy resources facilities,” https:
//der.nyserda.ny.gov/map,accessed:14-10-2022.
[38] S. Maghsudi and E. Hossain, “Distributed user association in energy
harvestingsmallcellnetworks:Anexchangeeconomywithuncertainty,”
IEEETransactionsonGreenCommunicationsandNetworking,vol.1,
no.3,pp.294–308,2017.
[39] M.SugiyamaandM.Kawanabe,Machinelearninginnon-stationary
environments:Introductiontocovariateshiftadaptation. MITpress,
2012.
[40] J.Gama,I.Žliobaite˙,A.Bifet,M.Pechenizkiy,andA.Bouchachia,“A
surveyonconceptdriftadaptation,”ACMcomputingsurveys(CSUR),
vol.46,no.4,pp.1–37,2014.
[41] P.Zhao,X.Wang,S.Xie,L.Guo,andZ.-H.Zhou,“Distribution-freeone-
passlearning,”IEEETransactionsonKnowledgeandDataEngineering,
vol.33,no.3,pp.951–963,2019.
[42] T.VanErvenandW.M.Koolen,“Metagrad:Multiplelearningratesin
onlinelearning,”AdvancesinNeuralInformationProcessingSystems,
vol.29,2016.
[43] N. Cesa-Bianchi and G. Lugosi, Prediction, learning, and games.
Cambridgeuniversitypress,2006.
[44] T.ChenandG.B.Giannakis,“Banditconvexoptimizationforscalable
anddynamicIoTmanagement,”IEEEInternetofThingsJournal,vol.6,
no.1,pp.1276–1286,2018.
[45] N. Andrei, “Convex functions,” Adv. Model. Optim, vol. 9, no. 2, pp.
257–267,2007.
[46] J.Heinonen,LecturesonLipschitzanalysis. UniversityofJyväskylä,
2005,no.100.