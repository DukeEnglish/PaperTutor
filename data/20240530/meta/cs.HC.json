[
    {
        "title": "Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models",
        "authors": "Tianrun ChenChunan YuJing LiJianqi ZhangLanyun ZhuDeyi JiYong ZhangYing ZangZejian LiLingyun Sun",
        "links": "http://arxiv.org/abs/2405.19326v1",
        "entry_id": "http://arxiv.org/abs/2405.19326v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19326v1",
        "summary": "In this paper, we introduce a new task: Zero-Shot 3D Reasoning Segmentation\nfor parts searching and localization for objects, which is a new paradigm to 3D\nsegmentation that transcends limitations for previous category-specific 3D\nsemantic segmentation, 3D instance segmentation, and open-vocabulary 3D\nsegmentation. We design a simple baseline method, Reasoning3D, with the\ncapability to understand and execute complex commands for (fine-grained)\nsegmenting specific parts for 3D meshes with contextual awareness and reasoned\nanswers for interactive segmentation. Specifically, Reasoning3D leverages an\noff-the-shelf pre-trained 2D segmentation network, powered by Large Language\nModels (LLMs), to interpret user input queries in a zero-shot manner. Previous\nresearch have shown that extensive pre-training endows foundation models with\nprior world knowledge, enabling them to comprehend complex commands, a\ncapability we can harness to \"segment anything\" in 3D with limited 3D datasets\n(source efficient). Experimentation reveals that our approach is generalizable\nand can effectively localize and highlight parts of 3D objects (in 3D mesh)\nbased on implicit textual queries, including these articulated 3d objects and\nreal-world scanned data. Our method can also generate natural language\nexplanations corresponding to these 3D models and the decomposition. Moreover,\nour training-free approach allows rapid deployment and serves as a viable\nuniversal baseline for future research of part-level 3d (semantic) object\nunderstanding in various fields including robotics, object manipulation, part\nassembly, autonomous driving applications, augment reality and virtual reality\n(AR/VR), and medical applications. The code, the model weight, the deployment\nguide, and the evaluation protocol are: http://tianrun-chen.github.io/Reason3D/",
        "updated": "2024-05-29 17:56:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19326v1"
    },
    {
        "title": "The Future of Child Development in the AI Era. Cross-Disciplinary Perspectives Between AI and Child Development Experts",
        "authors": "Mathilde Neugnot-CerioliOlga Muss Laurenty",
        "links": "http://arxiv.org/abs/2405.19275v1",
        "entry_id": "http://arxiv.org/abs/2405.19275v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19275v1",
        "summary": "This report explores the potential implications of rapidly integrating\nArtificial Intelligence (AI) applications into children's environments. The\nintroduction of AI in our daily lives necessitates scrutiny considering the\nsignificant role of the environment in shaping cognition, socio-emotional\nskills, and behaviors, especially during the first 25 years of cerebral\ndevelopment. As AI becomes prevalent in educational and leisure activities, it\nwill significantly modify the experiences of children and adolescents,\npresenting both challenges and opportunities for their developmental\ntrajectories. This analysis was informed by consulting with 15 experts from\npertinent disciplines (AI, product development, child development, and\nneurosciences), along with a comprehensive review of scientific literature on\nchildren development and child-technology interactions. Overall, AI experts\nanticipate that AI will transform leisure activities, revolutionize education,\nand redefine human-machine interactions. While AI offers substantial benefits\nin fostering interactive engagement, it also poses risks that require careful\nconsiderations, especially during sensitive developmental periods. The report\nadvocates for proactive international collaboration across multiple disciplines\nand increased research into how technological innovations affect child\ndevelopment. Such efforts are crucial for designing a sustainable and ethical\nfuture for the next generation through specific child-centered regulations, and\nhelping to educate all potential stakeholders (regulators, developers, parents\nand educators, children) about responsible AI use and its potential impacts on\nchild development.",
        "updated": "2024-05-29 17:07:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19275v1"
    },
    {
        "title": "Personalized Interiors at Scale: Leveraging AI for Efficient and Customizable Design Solutions",
        "authors": "Kaiwen ZhouTianyu Wang",
        "links": "http://arxiv.org/abs/2405.19188v1",
        "entry_id": "http://arxiv.org/abs/2405.19188v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19188v1",
        "summary": "In this paper, we introduce an innovative application of artificial\nintelligence in the realm of interior design through the integration of Stable\nDiffusion and Dreambooth models. This paper explores the potential of these\nadvanced generative models to streamline and democratize the process of room\ninterior generation, offering a significant departure from conventional,\nlabor-intensive techniques. Our approach leverages the capabilities of Stable\nDiffusion for generating high-quality images and Dreambooth for rapid\ncustomization with minimal training data, addressing the need for efficiency\nand personalization in the design industry. We detail a comprehensive\nmethodology that combines these models, providing a robust framework for the\ncreation of tailored room interiors that reflect individual tastes and\nfunctional requirements. We presents an extensive evaluation of our method,\nsupported by experimental results that demonstrate its effectiveness and a\nseries of case studies that illustrate its practical application in interior\ndesign projects. Our study contributes to the ongoing discourse on the role of\nAI in creative fields, highlighting the benefits of leveraging generative\nmodels to enhance creativity and reshape the future of interior design.",
        "updated": "2024-05-29 15:29:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19188v1"
    },
    {
        "title": "Alt4Blind: A User Interface to Simplify Charts Alt-Text Creation",
        "authors": "Omar MouredShahid Ali FarooquiKarin MullerSharifeh FadaeijouybariThorsten SchwarzMohammed JavedRainer Stiefelhagen",
        "links": "http://arxiv.org/abs/2405.19111v1",
        "entry_id": "http://arxiv.org/abs/2405.19111v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19111v1",
        "summary": "Alternative Texts (Alt-Text) for chart images are essential for making\ngraphics accessible to people with blindness and visual impairments.\nTraditionally, Alt-Text is manually written by authors but often encounters\nissues such as oversimplification or complication. Recent trends have seen the\nuse of AI for Alt-Text generation. However, existing models are susceptible to\nproducing inaccurate or misleading information. We address this challenge by\nretrieving high-quality alt-texts from similar chart images, serving as a\nreference for the user when creating alt-texts. Our three contributions are as\nfollows: (1) we introduce a new benchmark comprising 5,000 real images with\nsemantically labeled high-quality Alt-Texts, collected from Human Computer\nInteraction venues. (2) We developed a deep learning-based model to rank and\nretrieve similar chart images that share the same visual and textual semantics.\n(3) We designed a user interface (UI) to facilitate the alt-text creation\nprocess. Our preliminary interviews and investigations highlight the usability\nof our UI. For the dataset and further details, please refer to our project\npage: https://moured.github.io/alt4blind/.",
        "updated": "2024-05-29 14:19:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19111v1"
    },
    {
        "title": "Towards Standardizing AI Bias Exploration",
        "authors": "Emmanouil KrasanakisSymeon Papadopoulos",
        "links": "http://arxiv.org/abs/2405.19022v1",
        "entry_id": "http://arxiv.org/abs/2405.19022v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19022v1",
        "summary": "Creating fair AI systems is a complex problem that involves the assessment of\ncontext-dependent bias concerns. Existing research and programming libraries\nexpress specific concerns as measures of bias that they aim to constrain or\nmitigate. In practice, one should explore a wide variety of (sometimes\nincompatible) measures before deciding which ones warrant corrective action,\nbut their narrow scope means that most new situations can only be examined\nafter devising new measures. In this work, we present a mathematical framework\nthat distils literature measures of bias into building blocks, hereby\nfacilitating new combinations to cover a wide range of fairness concerns, such\nas classification or recommendation differences across multiple multi-value\nsensitive attributes (e.g., many genders and races, and their intersections).\nWe show how this framework generalizes existing concepts and present frequently\nused blocks. We provide an open-source implementation of our framework as a\nPython library, called FairBench, that facilitates systematic and extensible\nexploration of potential bias concerns.",
        "updated": "2024-05-29 12:03:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19022v1"
    }
]