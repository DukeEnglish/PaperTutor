[
    {
        "title": "X-VILA: Cross-Modality Alignment for Large Language Model",
        "authors": "Hanrong YeDe-An HuangYao LuZhiding YuWei PingAndrew TaoJan KautzSong HanDan XuPavlo MolchanovHongxu Yin",
        "links": "http://arxiv.org/abs/2405.19335v1",
        "entry_id": "http://arxiv.org/abs/2405.19335v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19335v1",
        "summary": "We introduce X-VILA, an omni-modality model designed to extend the\ncapabilities of large language models (LLMs) by incorporating image, video, and\naudio modalities. By aligning modality-specific encoders with LLM inputs and\ndiffusion decoders with LLM outputs, X-VILA achieves cross-modality\nunderstanding, reasoning, and generation. To facilitate this cross-modality\nalignment, we curate an effective interleaved any-to-any modality\ninstruction-following dataset. Furthermore, we identify a significant problem\nwith the current cross-modality alignment method, which results in visual\ninformation loss. To address the issue, we propose a visual alignment mechanism\nwith a visual embedding highway module. We then introduce a resource-efficient\nrecipe for training X-VILA, that exhibits proficiency in any-to-any modality\nconversation, surpassing previous approaches by large margins. X-VILA also\nshowcases emergent properties across modalities even in the absence of similar\ntraining data. The project will be made open-source.",
        "updated": "2024-05-29 17:59:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19335v1"
    },
    {
        "title": "LLMs Meet Multimodal Generation and Editing: A Survey",
        "authors": "Yingqing HeZhaoyang LiuJingye ChenZeyue TianHongyu LiuXiaowei ChiRuntao LiuRuibin YuanYazhou XingWenhai WangJifeng DaiYong ZhangWei XueQifeng LiuYike GuoQifeng Chen",
        "links": "http://arxiv.org/abs/2405.19334v1",
        "entry_id": "http://arxiv.org/abs/2405.19334v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19334v1",
        "summary": "With the recent advancement in large language models (LLMs), there is a\ngrowing interest in combining LLMs with multimodal learning. Previous surveys\nof multimodal large language models (MLLMs) mainly focus on understanding. This\nsurvey elaborates on multimodal generation across different domains, including\nimage, video, 3D, and audio, where we highlight the notable advancements with\nmilestone works in these fields. Specifically, we exhaustively investigate the\nkey technical components behind methods and multimodal datasets utilized in\nthese studies. Moreover, we dig into tool-augmented multimodal agents that can\nuse existing generative models for human-computer interaction. Lastly, we also\ncomprehensively discuss the advancement in AI safety and investigate emerging\napplications as well as future prospects. Our work provides a systematic and\ninsightful overview of multimodal generation, which is expected to advance the\ndevelopment of Artificial Intelligence for Generative Content (AIGC) and world\nmodels. A curated list of all related papers can be found at\nhttps://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
        "updated": "2024-05-29 17:59:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19334v1"
    },
    {
        "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series",
        "authors": "Ge ZhangScott QuJiaheng LiuChenchen ZhangChenghua LinChou Leuang YuDanny PanEsther ChengJie LiuQunshu LinRaven YuanTuney ZhengWei PangXinrun DuYiming LiangYinghao MaYizhi LiZiyang MaBill LinEmmanouil BenetosHuan YangJunting ZhouKaijing MaMinghao LiuMorry NiuNoah WangQuehry QueRuibo LiuSine LiuShawn GuoSoren GaoWangchunshu ZhouXinyue ZhangYizhi ZhouYubo WangYuelin BaiYuhan ZhangYuxiang ZhangZenith WangZhenzhu YangZijian ZhaoJiajun ZhangWanli OuyangWenhao HuangWenhu Chen",
        "links": "http://arxiv.org/abs/2405.19327v1",
        "entry_id": "http://arxiv.org/abs/2405.19327v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19327v1",
        "summary": "Large Language Models (LLMs) have made great strides in recent years to\nachieve unprecedented performance across different tasks. However, due to\ncommercial interest, the most competitive models like GPT, Gemini, and Claude\nhave been gated behind proprietary interfaces without disclosing the training\ndetails. Recently, many institutions have open-sourced several strong LLMs like\nLLaMA-3, comparable to existing closed-source LLMs. However, only the model's\nweights are provided with most details (e.g., intermediate checkpoints,\npre-training corpus, and training code, etc.) being undisclosed. To improve the\ntransparency of LLMs, the research community has formed to open-source truly\nopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training\ncorpus and training code) are being provided. These models have greatly\nadvanced the scientific study of these large models including their strengths,\nweaknesses, biases and risks. However, we observe that the existing truly open\nLLMs on reasoning, knowledge, and coding tasks are still inferior to existing\nstate-of-the-art LLMs with similar model sizes. To this end, we open-source\nMAP-Neo, a highly capable and transparent bilingual language model with 7B\nparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the\nfirst fully open-sourced bilingual LLM with comparable performance compared to\nexisting state-of-the-art LLMs. Moreover, we open-source all details to\nreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning\npipeline, checkpoints, and well-optimized training/evaluation framework are\nprovided. Finally, we hope our MAP-Neo will enhance and strengthen the open\nresearch community and inspire more innovations and creativities to facilitate\nthe further improvements of LLMs.",
        "updated": "2024-05-29 17:57:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19327v1"
    },
    {
        "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution",
        "authors": "Minghan LiXilun ChenAri HoltzmanBeidi ChenJimmy LinWen-tau YihXi Victoria Lin",
        "links": "http://arxiv.org/abs/2405.19325v1",
        "entry_id": "http://arxiv.org/abs/2405.19325v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19325v1",
        "summary": "Large language models (LLMs) often hallucinate and lack the ability to\nprovide attribution for their generations. Semi-parametric LMs, such as kNN-LM,\napproach these limitations by refining the output of an LM for a given prompt\nusing its nearest neighbor matches in a non-parametric data store. However,\nthese models often exhibit slow inference speeds and produce non-fluent texts.\nIn this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a\nnovel semi-parametric language modeling approach that is capable of\nincorporating real-world text spans of arbitrary length into the LM generations\nand providing attribution to their sources. NEST performs token-level retrieval\nat each inference step to compute a semi-parametric mixture distribution and\nidentify promising span continuations in a corpus. It then uses an approximate\nspeculative decoding procedure that accepts a prefix of the retrieved span or\ngenerates a new token. NEST significantly enhances the generation quality and\nattribution rate of the base LM across a variety of knowledge-intensive tasks,\nsurpassing the conventional kNN-LM method and performing competitively with\nin-context retrieval augmentation. In addition, NEST substantially improves the\ngeneration speed, achieving a 1.8x speedup in inference time when applied to\nLlama-2-Chat 70B.",
        "updated": "2024-05-29 17:55:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19325v1"
    },
    {
        "title": "Are Large Language Models Chameleons?",
        "authors": "Mingmeng GengSihong HeRoberto Trotta",
        "links": "http://arxiv.org/abs/2405.19323v1",
        "entry_id": "http://arxiv.org/abs/2405.19323v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19323v1",
        "summary": "Do large language models (LLMs) have their own worldviews and personality\ntendencies? Simulations in which an LLM was asked to answer subjective\nquestions were conducted more than 1 million times. Comparison of the responses\nfrom different LLMs with real data from the European Social Survey (ESS)\nsuggests that the effect of prompts on bias and variability is fundamental,\nhighlighting major cultural, age, and gender biases. Methods for measuring the\ndifference between LLMs and survey data are discussed, such as calculating\nweighted means and a new proposed measure inspired by Jaccard similarity. We\nconclude that it is important to analyze the robustness and variability of\nprompts before using LLMs to model individual decisions or collective behavior,\nas their imitation abilities are approximate at best.",
        "updated": "2024-05-29 17:54:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19323v1"
    }
]