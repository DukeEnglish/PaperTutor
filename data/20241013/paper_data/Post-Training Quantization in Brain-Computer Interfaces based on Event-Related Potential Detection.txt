Post-Training Quantization in Brain-Computer Interfaces based on
Event-Related Potential Detection
Hubert Cecotti1, Dalvir Dhaliwal1, Hardip Singh1, Yogesh Kumar Meena2
Abstract—Post-training quantization (PTQ) is a technique as 8-bit integers (int8), instead of 32-bit floating-point num-
used to optimize and reduce the memory footprint and com- bers. In addition, it can improve inference speed because
putational requirements of machine learning models. It has
operationsbecomefastertocomputewithreducedprecision,
beenusedprimarilyforneuralnetworks.ForBrain-Computer
which leads to improved inference speed. This is especially
Interfaces (BCI) that are fully portable and usable in various
situations, it is necessary to provide approaches that are beneficial for deploying models on resource-constrained de-
lightweight for storage and computation. In this paper, we vices like mobile phones, IoT devices, or edge devices. This
propose the evaluation of post-training quantization on state- is the case With portable BCIs where the battery is typi-
of-the-art approaches in brain-computer interfaces and assess
cally located behind the head with limited battery capacity.
their impact on accuracy. We evaluate the performance of the
By decreasing the precision of computations, post-training
single-trialdetectionofevent-relatedpotentialsrepresentingone
major BCI paradigm. The area under the receiver operating quantization can lower the power consumption of inference,
characteristic curve drops from 0.861 to 0.825 with PTQ when makingitmoreenergy-efficient,whichiscrucialforbattery-
appliedonbothspatialfiltersandtheclassifier,whilereducing powered devices such as portable BCI. Quantized models
the size of the model by about × 15. The results support
can bedeployed onsuch hardware, enablingthe deployment
the conclusion that PTQ can substantially reduce the memory
of advanced machine learning models in situations where it
footprint of the models while keeping roughly the same level
of accuracy. was previously impractical. Other advantages include faster
transmission. Quantized models have smaller sizes, making
I. INTRODUCTION them faster to transmit over networks, which is advanta-
geous for applications requiring frequent model updates or
Non-invasive brain-computer interfaces (BCIs) are acces- communication with remote servers. In clinical applications
sible to a broader range of users, including individuals that require continuous monitoring of the patient’s brain
with disabilities, children, and elderly individuals [1]. These states, it is necessary to exchange data rapidly. Post-training
devices can help individuals with motor impairments com- quantization allows for the deployment of deep learning
municate, control assistive devices, and interact with their models on cheaper hardware, as the reduced computational
environment more effectively, improving their quality of life and memory requirements enable the use of less powerful
and independence [2], [3]. processorsandsmallermemoryconfigurations.Thispartcan
Machine learning deployment to the target environment be a challenge if the classification is performed on the client
is a challenging task. It is due to the heavy burden of side, on a BCI headset, which does not include a GPU for
hardware requirements that machine learning, in particular processing the ongoing EEG data. Finally, quantized models
whenbasedondeeplearningneuralnetworks[4],modelslay arewell-suitedfordeploymentonhardwareacceleratorsthat
oncomputationcapabilitiesandpowerconsumption[5],[6]. are optimized for low-precision computations (i.e., 8-bits).
Methods based on post-training quantification are powerful There are several methods for post-learning weight quan-
to accelerate the optimization of such machine learning tization. In uniform quantization, weights are quantized into
models. a fixed number of levels uniformly across the entire weight
Post-training quantization (PTQ) is a technique used to range. This is a simple and commonly used method, but it
optimizeandreducethememoryfootprintandcomputational may not always provide the best compression or accuracy.
requirementsofmachinelearningmodels[7],[8].Ithasbeen Unlike uniform quantization, non-uniform quantization as-
mainly used with large deep-learning architectures. It has signsmorebitstoregionswheretheweightsaremorecritical
advantages that are relevant to non-invasive portable brain- for accuracy and fewer bits to less critical regions. This can
computer interfaces. It is also unknown the extent to which potentiallyimproveaccuracycomparedtouniformquantiza-
such approaches can impact the classifier’s performance. tion. K-Means involves clustering the weight values into a
First, it reduces memory footprint. Quantization reduces the fixed number of centroids and then quantizing the weights
memory required to store model parameters and activations to the nearest centroid [9]. It can lead to better compression
by representing them with lower precision numbers, such and accuracy compared to uniform quantization. Despite
the reduction in precision, post-training quantization often
Thisworkwassupportedbyanyorganization maintains the model’s accuracy within an acceptable range.
1HC is with the Department of Computer Science, California State Advancedtechniquessuchasquantization-awaretrainingcan
University,Fresno,USAhcecotti@csufresno.edu
further mitigate any loss in accuracy. With models being
2YKMiswiththeHuman-AIInteraction(HAIx)Lab,IITGandhinagar,
Indiayk.meena@iitgn.ac.in used in brain-computer interfaces, it is unknown how the
4202
tcO
01
]CH.sc[
1v02970.0142:viXraFig.2. Examplesoftarget(top)andnon-target(bottom)faces.
Fig. 1. Rapid Serial Visual Presentation Task (RSVP) on the computer
screen.
B. Signal processing and classification
The EEG signal was acquired with a BioSemi ActiveTwo
performance will drop or remain steady when using post-
amplifier with 32 active electrodes placed according to the
learning weight quantization.
10-10 international system. The EEG signal was acquired
The main contribution is the presentation and evaluation
at 512 Hz then subsequently downsampled to 128 Hz and
of post-training quantization on two classifiers for single-
bandpassed between 0.01 and 42.66 Hz. For single-trial
trial detection of event-related potentials. We consider the
detection, we consider a time segment of 1 second post-
approachbasedonthexDAWNspatialfilterscombinedwith
stimulus, hence the input is: 128 × 32.
the BLDA classifier and the Extreme Learning Machine
(ELM) classifier. C. xDAWN+BLDA
The paper is organized as follows: The data and methods
For single-trial detection (target vs. non-target), we con-
are provided in Section II. The performance of the models
sider the combination of the xDAWN spatial filtering ap-
with and without post-training quantization is given in given
proach with the Bayesian Linear Discriminant Analysis
in Section III. The impact of the results on portable BCIs
classifier (BLDA) [11]–[13]. This approach has been used
is discussed in Section IV. Finally, the main findings are
in multiple studies for the P300 speller and RSVP tasks.
resumed in Section V.
Thetechniquedoesnotrequiremanyhyperparameters,sothe
resultscanbeeasilyreproduced.Thenumberofspatialfilters
II. METHODS
wassetto8,sothematrixofweightsforspatialfilteringis8
A. Experimental task ×32.Withthebias,itrepresents128∗8+1=1025weights
Nineteen healthy adult participants participated in the for the linear classifier.
study. All the subjects provided written informed consent,
D. ELM algorithm
reportednormalorcorrected-to-normalvision,andnohistory
of neurological problems. The idea behind the Extreme Learning Machine (ELM)
TheexperimentalprotocolwasreviewedbytheCalifornia algorithm is that we do not adjust the weights and biases
State University, Fresno institutional review board and was of the input to hidden layer neurons (as we do for normal
following the Helsinki Declaration of 1975, as revised in networks) [14], [15]. Instead, we randomly assign these
2000. Visual stimuli consisted of images (335×419 pixel) weights once and keep them that way until the process
from the FACES database (2052 images) that was created at is finished. Instead, ELM analytically calculates the output
the Max Planck Institute for Human Development (MPIB), layer weights. This calculation is typically done with the
Berlin,Germanybetween2005and2007[10].Visualstimuli least-square solution.
were centered on the screen (visual angle ≈ 20o). Partici-
β =(HTH)−1∗H)∗T
pants were seated comfortably 80 cm from the screen. They
wereaskedtoavoidmovingduringtheexperimentstoavoid Whereβ istheoutputweight.(HTH)−1∗H)istheMoore-
muscular artifacts. PenroseinverseoftheH matrix(Moore-Penroseinverseisa
The experiment was a rapid serial visual presentation task long series of calculations where a matrix and its transpose
(presentation of images going at 2 Hz) containing the target are multiplied together. Then we perform the inverse on that
and non-target images (target images with a probability of and finally multiply it again with the transpose (HTH)−1∗
10%). Target images are faces of old smiling men, and non- H)). H is the output matrix of the input and hidden layer.
targetimagesarefacesofyoungneutralwomen(SeeFig.2). [14], [15]. This is done to minimize the error between the
Each condition has 10 blocks that are separated by a predictedoutputandthetruelabel.Itfindstheoptimalweight
pause, i.e., the participant can start each block when he/she that helps in getting the closest to the desired output.
isready.Eachblockhas8sequences,eachsequencecontains ELM randomly assigns input layer weights and hidden
20images.Withatargetprobabilityof10%,therearealways layer biases, eliminating the need for iterative tuning and
2targetsand18non-targetsineachsequence.Itleadsto160 bypassing like gradient descent procedures do. After the
target and 1440 non-target images per condition. randomassignment,ELMcalculatestheoutputlayerweightsusing a simple least squares estimate enabling efficient In the subsequent section, we consider the values that are
learning. used for the normalization of the int4 or int8 as doubles (64
ELM learning process can be further represented mathe- bits)butfloats(32bits)couldbeusedaswellwithoutadrop
matically as follows. in performance.
H G. Performance evaluation
(cid:88)
o = β f(x ∗w +bi)j =1,...,N
j i j i
For the performance evaluation, we consider the area
i=0
underthereceiveroperatingcharacteristiccurve(AUC)with
where N is the number of training samples, x = Input,
j a five-fold cross-validation. We denote by 0 the absence
w are the randomly assigned input weight vector, b is the
i i of weight quantization. Before the ELM classifier, we also
randomly assigned hidden layer bias, f is the activation
consider the xDAWN spatial filters without quantization of
function, β is the analytically calculated output weight
i the spatial filters.
vector [14], [16]. In the evaluation, we consider 200 hidden
units. III. RESULTS
Th results are presented in Tables I and II. They include
E. Post-weight quantization - ELM
theAUCperformancewiththecorrespondingsize(inbits)of
We consider five conditions for setting the weights be- themodels.Thesizerelatedtothemodelisdecomposedinto
tween the input and the hidden layer. the weights of the spatial filters (filter) and the weights of
1) Random weights and biases generated between the theclassifier(classifier).TheAUCacrosssubjectsis0.861±
range [-1,1]. 0.097 without quantization of the model’s parameters with
2) Inputweightsandbiasesinitializedtobinaryvalues(1 the xDAWN+BLDA classifier. By considering the int4+max
bit) 1 or -1. forboththeweightsofthespatialfiltersandtheweightsand
3) Input weighs and biases initialized to binary values (1 biasoftheclassifier,theperformancedropsto0.825±0.109.
bit) 0 or 1. By considering the quantization only for the spatial filters,
4) The weights and biases are set to any of the values (2 the best approach reaches 0.864, higher than the default
bits): [-1,-0.33,0.33,1]. condition. When the quantization is applied to the classifier,
5) Input weights and biases are initialized to 8 distinct thehighestperformanceisobservedwithint8combinedwith
values between -1 and 1. These values have a 2/7 the min/max approach.
gap: [-1.0000 -0.7143 -0.4286 -0.1429 0.1429 0.4286 The performance with the ELM classifier is lower com-
0.7143 1.0000]. pared to BLDA, as the mean AUC is only 0.692±0.100
across subjects. By considering the different post-training
We consider two conditions for setting the weights between quantizationapproaches,itispossibletosubstantiallyreduce
the hidden layer and the output layer after their evaluation. the size of the model, first by considering only 1 bit for the
It is possible to quantize the calculated weights using a first hidden layer, and second, by adding the quantization
histogram(256bins)byselectingthemeanvalueofeachbin. through the histogram, where each weight is one byte, in
First, a histogram of the weights is created. For the second additiontothenormalizationparametersthatremaindoubles.
condition, where we used the weights -1 and 1, it would The performance with the ELM demonstrates the interest of
show two bins (-1 and 1). If we had 10 weights where six theapproachandshowsthevariabilityofperformanceacross
were -1 and four of them 1, this will be visually represented classifiers, as the BLDA classifier provides better results.
in the histogram. We denote by 1, 2, 3, 4, and 5 the five By using a Wilcoxon signed-rank test with Bonferroni
conditions, and 11, 12, 13, 14, 15, the conditions with the correction, we provide the results of the pairwise analysis
histogram quantization of the weights between the hidden (1 for significant, 0 for not significant) in Tables III and IV.
layer and the output layer. The results in Table III indicate that the post-training quan-
tization for both spatial filters and the classifiers provided
F. Post-weight quantization - xDAWN+BLDA
the worst results, with a drop of about 0.04 in the AUC
Weconsidertwotypesofintegersthatcanbepositiveand for the xDAWN+BLDA approach. While there is a drop in
negative. With int4 (4 bits), there is one bit for the sign and performance, it allows to reduce the size of the model by
3bitsforthevalue(from-8to7).Withint8(8bits),thereis a factor of 15.61. There are also other differences between
one bit for the sign and 7 bits for the values ranging from - thebaselineandthepost-trainingquantizationwithcondition
128 to 127. For the quantization, we consider two solutions: 0/1.
1) the maximum value of the absolute value of the set of
weightstoquantize,or2)theminimumandmaximumvalue
IV. DISCUSSION
of the set of weights to quantize. In the latter case, it is A key question that was addressed in this paper was
just a linear mapping from a range of values [v ,v to whether post-training quantization has an impact on the
min max
[−128,127]or[−8,7]withonlyintegers.Wedenoteby1,2, accuracy of single-trial event-related potential detection.
3, and 4 the methods: max+int4, max+int8, min-max+int4, While the answer is positive, the drop in performance is
min-max+int8. not substantial and does not represent an obstacle to usingTABLEI
AUCFORSINGLE-TRIALDETECTIONUSINGTHEXDAWN+BLDAMETHOD
Method 0/0 1/0 2/0 3/0 4/0 0/1 0/2 0/3 0/4 1/1
Filter 16384 1088 2112 1152 2176 16384 16384 16384 16384 1088
Classifier 65600 65600 65600 65600 65600 8264 4164 8328 4228 4164
Total 81984 66688 67712 66752 67776 24648 20548 24712 20612 5252
1 0.708 0.664 0.713 0.550 0.696 0.697 0.709 0.704 0.709 0.616
2 0.774 0.776 0.776 0.778 0.777 0.770 0.774 0.777 0.774 0.668
3 0.902 0.899 0.906 0.906 0.906 0.898 0.902 0.897 0.902 0.890
4 0.916 0.916 0.917 0.900 0.914 0.913 0.916 0.915 0.917 0.847
5 0.796 0.796 0.797 0.790 0.796 0.791 0.795 0.794 0.795 0.792
6 0.962 0.963 0.961 0.961 0.962 0.960 0.962 0.961 0.962 0.950
7 0.983 0.983 0.983 0.985 0.984 0.982 0.983 0.983 0.983 0.973
8 0.937 0.930 0.937 0.935 0.937 0.933 0.937 0.936 0.937 0.926
9 0.932 0.922 0.933 0.929 0.931 0.931 0.931 0.932 0.932 0.908
10 0.760 0.758 0.764 0.766 0.762 0.758 0.761 0.756 0.760 0.753
11 0.749 0.733 0.750 0.758 0.750 0.746 0.751 0.743 0.750 0.686
12 0.846 0.839 0.843 0.833 0.840 0.847 0.845 0.836 0.846 0.818
13 0.852 0.852 0.851 0.837 0.852 0.845 0.852 0.851 0.852 0.830
14 0.670 0.685 0.694 0.696 0.694 0.660 0.671 0.674 0.671 0.689
15 0.958 0.954 0.958 0.960 0.959 0.952 0.958 0.954 0.958 0.919
16 0.972 0.973 0.974 0.972 0.974 0.974 0.972 0.970 0.972 0.921
17 0.961 0.962 0.962 0.958 0.961 0.960 0.961 0.961 0.961 0.952
18 0.852 0.846 0.851 0.846 0.851 0.832 0.851 0.818 0.852 0.774
19 0.834 0.803 0.836 0.822 0.839 0.826 0.836 0.826 0.836 0.762
Mean 0.861 0.855 0.864 0.852 0.862 0.857 0.861 0.857 0.862 0.825
SD 0.097 0.1 0.093 0.112 0.095 0.099 0.096 0.097 0.096 0.109
TABLEII
AUCFORSINGLE-TRIALDETECTIONUSINGTHEXDAWN+ELMMETHOD
Method 1 2 3 4 5 11 12 13 14 15
1 0.525 0.545 0.511 0.532 0.512 0.552 0.542 0.257 0.554 0.530
2 0.640 0.627 0.509 0.637 0.586 0.582 0.629 0.391 0.645 0.622
3 0.702 0.705 0.517 0.709 0.685 0.662 0.652 0.498 0.712 0.666
4 0.685 0.671 0.477 0.657 0.649 0.699 0.701 0.408 0.709 0.654
5 0.630 0.615 0.465 0.635 0.619 0.608 0.612 0.295 0.630 0.588
6 0.795 0.820 0.492 0.830 0.834 0.812 0.811 0.497 0.815 0.803
7 0.834 0.840 0.531 0.844 0.839 0.841 0.869 0.445 0.827 0.860
8 0.855 0.850 0.501 0.851 0.833 0.855 0.850 0.545 0.821 0.860
9 0.681 0.750 0.492 0.692 0.711 0.691 0.706 0.503 0.721 0.746
10 0.654 0.635 0.520 0.648 0.620 0.636 0.594 0.504 0.620 0.625
11 0.583 0.580 0.476 0.575 0.554 0.568 0.576 0.336 0.585 0.574
12 0.724 0.726 0.440 0.750 0.727 0.678 0.726 0.358 0.718 0.735
13 0.674 0.656 0.449 0.699 0.658 0.707 0.670 0.407 0.663 0.642
14 0.594 0.507 0.477 0.565 0.544 0.522 0.520 0.316 0.560 0.559
15 0.730 0.731 0.504 0.760 0.730 0.698 0.716 0.496 0.723 0.722
16 0.875 0.850 0.492 0.861 0.865 0.858 0.860 0.510 0.859 0.853
17 0.779 0.809 0.520 0.831 0.817 0.798 0.827 0.530 0.827 0.803
18 0.609 0.598 0.463 0.565 0.573 0.592 0.600 0.511 0.623 0.604
19 0.578 0.533 0.417 0.562 0.511 0.554 0.557 0.145 0.549 0.566
Mean 0.692 0.687 0.487 0.695 0.677 0.680 0.685 0.419 0.693 0.685
SD 0.100 0.112 0.030 0.111 0.118 0.109 0.114 0.110 0.101 0.11
TABLEIII TABLEIV
STATISTICALSIGNIFICANCETHROUGHPAIRWISECOMPARISONS STATISTICALSIGNIFICANCETHROUGHPAIRWISECOMPARISONS
(XDAWN+BLDA). (XDAWN+ELM).
Method 0/0 1/0 2/0 3/0 4/0 0/1 0/2 0/3 0/4 1/1 Method 1 2 3 4 5 11 12 13 14 15
0/0 x 0 0 0 0 1 0 0 0 1 1 x 0 1 0 0 0 0 1 0 0
1/0 - x 1 0 1 0 0 0 0 1 2 - x 1 0 0 0 0 1 0 0
2/0 - - x 0 0 1 0 1 0 1 3 - - x 1 1 1 1 0 1 1
3/0 - - - x 0 0 0 0 0 1 4 - - - x 1 0 0 1 0 0
4/0 - - - - x 1 0 0 0 1 5 - - - - x 0 0 1 0 0
0/1 - - - - - x 1 0 1 1 11 - - - - - x 0 1 0 0
0/2 - - - - - - x 0 0 1 12 - - - - - - x 1 0 0
0/3 - - - - - - - x 0 1 13 - - - - - - - x 1 1
0/4 - - - - - - - - x 1 14 - - - - - - - - x 0such an approach in portable BCI applications. In addi- Acknowledgment
tion to improving BCI accuracy, it is necessary to provide
This study was supported by the NIH-R15 NS118581
lightweight models that can be deployed on hardware with
project.
limited memory and, more importantly, with limited power
consumption. REFERENCES
The development of portable non-invasive BCIs is critical [1] J.R.Wolpaw,N.Birbaumer,W.J.Heetderks,D.J.McFarland,P.H.
andrequiresconsideringthecomputationalcostandmemory Peckham, G. Schalk, E. Donchin, L. A. Quatrano, C. J. Robinson,
T.M.Vaughanetal.,“Brain-computerinterfacetechnology:areview
storage of the models being used. The battery should last
ofthefirstinternationalmeeting,”IEEEtransactionsonrehabilitation
long enough to allow the user to have some independence. engineering,vol.8,no.2,pp.164–173,2000.
With brain monitoring devices, EEG signal processing and [2] M. A. Bockbrader, G. Francisco, R. Lee, J. Olson, R. Solinsky,
and M. L. Boninger, “Brain computer interfaces in rehabilitation
classification can occur in real-time at a fast pace, hence
medicine,”PM&R,vol.10,no.9,pp.S233–S243,2018.
requiring many decisions over time. [3] U. Chaudhary, N. Birbaumer, and A. Ramos-Murguialday, “Brain–
Traditional BCIs are often bulky and require users to be computer interfaces for communication and rehabilitation,” Nature
ReviewsNeurology,vol.12,no.9,pp.513–525,2016.
stationary during operation. Portable BCIs, however, allow
[4] J.Fang, A.Shafiee, H.Abdel-Aziz,D. Thorsley,G.Georgiadis, and
userstomovearoundfreelywhileusingthedevice,enabling J. H. Hassoun, “Post-training piecewise linear quantization for deep
applications in real-world environments (e.g., home, work- neural networks,” in Computer Vision–ECCV 2020: 16th European
Conference,Glasgow,UK,August23–28,2020,Proceedings,PartII
place, or community settings). Furthermore, portable BCIs
16. Springer,2020,pp.69–86.
offer improved user experience by eliminating the need for [5] V.Sze,Y.-H.Chen,J.Emer,A.Suleiman,andZ.Zhang,“Hardware
tethered connections or cumbersome equipment. Users can for machine learning: Challenges and opportunities,” in 2017 IEEE
customintegratedcircuitsconference(CICC). IEEE,2017,pp.1–8.
wear these devices discreetly, leading to greater comfort and
[6] P.Jawandhiya,“Hardwaredesignformachinelearning,”Int.J.Artif.
acceptance, particularly in social or public settings. Intell.Appl,vol.9,no.1,pp.63–84,2018.
Portable non-invasive BCIs make brain-computer inter- [7] I.Hubara,Y.Nahshan,Y.Hanani,R.Banner,andD.Soudry,“Accurate
posttrainingquantizationwithsmallcalibrationsets,”inInternational
action accessible to a broader range of users, including
ConferenceonMachineLearning. PMLR,2021,pp.4466–4475.
individuals with severe disabilities or mobility impairments. [8] R. Banner, Y. Nahshan, and D. Soudry, “Post training 4-bit quanti-
These devices enable users to control computers, prosthetic zationofconvolutionalnetworksforrapid-deployment,”Advancesin
NeuralInformationProcessingSystems,vol.32,2019.
limbs, or other assistive devices using their brain signals,
[9] D. Napoleon and P. G. Lakshmi, “An efficient k-means clustering
enhancing their independence and quality of life without algorithmforreducingtimecomplexityusinguniformdistributiondata
being connected to a desktop computer. Portable BCIs have points,” in Trendz in information sciences & computing (TISC2010).
IEEE,2010,pp.42–45.
significant potential for clinical applications (e.g., rehabilita-
[10] N.C.Ebner,M.Riediger,andU.Lindenberger,“Faces-adatabaseof
tion, neurofeedback therapy, and monitoring of neurological facialexpressionsinyoung,middle-aged,andolderwomenandmen:
conditions).Suchdevicescanbeusedinhome-basedrehabil- Development and validation,” Behavior Research Methods, vol. 42,
pp.351–362,2010.
itationprograms,remotepatientmonitoring,andearlydetec-
[11] B.Rivet,A.Souloumiac,V.Attina,andG.Gibert,“xdawnalgorithmto
tion of neurological disorders, leading to improved health- enhance evoked potentials: application to brain–computer interface,”
care outcomes and reduced healthcare costs. Finally, such IEEE Transactions on Biomedical Engineering, vol. 56, no. 8, pp.
2035–2043,2009.
systems can support various applications beyond assistive
[12] B.Rivet,H.Cecotti,E.Maby,andJ.Mattout,“Impactofspatialfilters
technologies,includinggaming,entertainment,mentalhealth during sensor selection in a visual P300 brain-computer interface,”
monitoring, and cognitive enhancement. Their portability BrainTopography,vol.12,no.1,pp.55–63,2012.
[13] U.Hoffmann,J.-M.Vesin,T.Ebrahimi,andK.Diserens,“Anefficient
and ease of use open up diverse opportunities for research,
p300-basedbrain–computerinterfacefordisabledsubjects,”Journalof
development, and commercialization. Neurosciencemethods,vol.167,no.1,pp.115–125,2008.
Future works will deal with the change of the models so [14] J.Wang,S.Lu,S.-H.Wang,andY.-D.Zhang,“Areviewonextreme
learningmachine,”MultimediaToolsandApplications,vol.81,no.29,
the computation is performed on int8, and to determine to
pp.41611–41660,2022.
what extent it impacts the energy consumption. While it is [15] S. Ding, X. Xu, and R. Nie, “Extreme learning machine and its
possible to quantize the model with values on 4 bits, 4-bit applications,”NeuralComputingandApplications,vol.25,pp.549–
556,2014.
computingismostlyobsolete,andpresent-dayprogramming
[16] “Extremelearningmachine:Theoryandapplications,”Neurocomput-
languages do not support 4-bit data types. ing,vol.70,no.1,pp.489–501,2006,neuralNetworks.
V. CONCLUSION
Post-trainingquantizationisnotreservedfordeeplearning
architecture and can be implemented on different types
of classifiers. Post-training quantization represents one step
toward the deployment of BCI on hardware with limited
resources,wheretheanalysisofbrainresponsesisperformed
at a high pace with limited resources. While it is neces-
sary to decompose storage requirements from processing
requirements, we have shown that lots of information could
be stored on 4-bit integers for the spatial filters and/or the
model.