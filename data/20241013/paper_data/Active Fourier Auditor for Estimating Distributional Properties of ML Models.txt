Active Fourier Auditor for Estimating
Distributional Properties of ML Models
Ayoub Ajarra ayoub.ajarra@inria.fr
E´quipe Scool, Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189- CRIStAL
Bishwamittra Ghosh bghosh@u.nus.edu
Max Planck Institute for Software Systems, Saarbru¨cken, Germany
Debabrota Basu debabrota.basu@inria.fr
E´quipe Scool, Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189- CRIStAL,
France
Abstract. With the pervasive deployment of Machine Learning (ML) models
in real-world applications, verifying and auditing properties of ML models
havebecomeacentralconcern.Inthiswork,wefocusonthreeproperties:ro-
bustness, individual fairness, and group fairness. We discuss two approaches
for auditing ML model properties: estimation with and without reconstruc-
tion of the target model under audit. Though the first approach is studied
in the literature, the second approach remains unexplored. For this purpose,
we develop a new framework that quantifies different properties in terms of
the Fourier coefficients of the ML model under audit but does not paramet-
rically reconstruct it. We propose the Active Fourier Auditor (AFA), which
queries sample points according to the Fourier coefficients of the ML model,
andfurtherestimatestheproperties.Wederivehighprobabilityerrorbounds
on AFA’s estimates, along with the worst-case lower bounds on the sample
complexity to audit them. Numerically we demonstrate on multiple datasets
and models that AFA is more accurate and sample-efficient to estimate the
properties of interest than the baselines.
1
4202
tcO
01
]GL.sc[
1v11180.0142:viXra2 AJARRA, GHOSH AND BASU
CONTENTS
1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
2 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
3 Active Fourier Auditor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.1 The Cost of Reconstruction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.2 Model Properties with Fourier Expansion . . . . . . . . . . . . . . . . . . . . . . . . 8
3.3 NP-hardness of Exact Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.4 Algorithm: Active Fourier Auditor (AFA) . . . . . . . . . . . . . . . . . . . . . . . . 10
4 Theoretical Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
5 Empirical Performance Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
6 Conclusion and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
7 Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
A The cost of auditing with reconstruction: Proof of Proposition 2 . . . . . . . . . . . . . . 19
B Computing Model’s Properties with Fourier Coefficients: Proofs of Section 3.2 . . . . . . . 20
B.1 Robustness and Individual Fairness . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
B.2 Group Fairness: Statistical Parity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
C Theoretical Analysis: Proofs of Section 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
C.1 Upper Bounds on Sample Complexity of AFA . . . . . . . . . . . . . . . . . . . . . . 25
C.2 Manipulation-proofness of AFA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
C.3 Lower Bound on Sample Complexity without Manipulation-proofness. . . . . . . . . 31
C.4 Additional Technical Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
D Extensions to Multi-class Classification. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
E Experimental Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
E.1 Uniformly Random Sampling (I.I.D.) estimators (Uniform) . . . . . . . . . . . . . . 39
E.2 Baseline Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
E.3 Additional Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
Author’s addresses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40ACTIVE FOURIER AUDITOR 3
1. INTRODUCTION
As Machine Learning (ML) systems are pervasively being deployed in high-stake applications,
mitigating discrimination and guaranteeing reliability are critical to ensure the safe pre and post-
deployment of ML (Madiega, 2021). These issues are addressed in the growing subfield of ML, i.e.
trustworthyorresponsibleML(Rasheedetal.,2022;Lietal.,2023),intermsofrobustnessandfair-
ness of ML models. Robustness quantifies how stable are a model’s predictions under perturbation
of its inputs (Xu and Shie, 2011; Kumar et al., 2020). Fairness (Dwork et al., 2012; Barocas et al.,
2023) seeks to address discrimination in predictions both at the individual level and across groups.
Thus, AI regulations, such as the European Union AI Act (Madiega, 2021), increasingly suggest
certifying different model properties, such as robustness, fairness, and privacy, for a safe integration
of of ML in high-risk applications. Thus, estimating these model properties under minimum inter-
actions with the models has become a central question in algorithmic auditing (Raji et al., 2020;
Wilson et al., 2021; Metaxa et al., 2021; Yan and Zhang, 2022).
Example 1. Following (Ghosh et al., 2021, Example 1), let us consider an ML model that
predictswhoiseligibletogetmedicalinsurancegivenasensitivefeature‘age’,andtwonon-sensitive
features ‘income’ and ‘health’. Owing to historical bias in the training data, the model, i.e. an
explainable decision tree, discriminates against the ‘elderly’ population by denying their health
insurance and favors the ‘young’ population. Hence, an auditor would realize that the model does
not satisfy group fairness since the difference in the probability of approving health insurance
between the elderly and the young is large. In addition, the model violates individual fairness,
where perturbing the feature ‘age’ from elderly to young increases the probability of insurance.
Further, the model lacks robustness if perturbing any feature by an infinitesimal quantity flips the
prediction.
Related Work: ML Auditing. Towards trustworthy ML, several methods have been proposed
to ally audit an ML model by estimating different distributional properties of it, such as fairness
and robustness, where the model hyper-property has to be assessed against the distribution of
inputs. A stream of work focuses on property verification that verifies whether these properties are
violated above a pre-determined threshold (Goldwasser et al., 2021; John et al., 2020; Mutreja and
Shafer, 2023; Herman and Rothblum, 2022; Kearns et al., 2018). Thus, we focus on estimating these
properties instead of a ‘yes/no’ answer, which is a harder problem than verification (Goldwasser
et al., 2021). On estimating distributional properties, Neiswanger et al. (2021) proposed a Bayesian
approach for estimating properties of black-box optimizers and required a prior distribution of
models. Wang et al. (2022) studies simpler distributional properties, e.g. the mean, the median, and
the trimmed mean defined as a conditional expectation, using offline and interactive algorithms.
Yan and Zhang (2022) considered a frequentist approach for estimating group fairness but assumed
the knowledge of the model class and a finite hypothesis class under audit. These assumptions
are violated if we do not know the model type and can be challenging for complex models, e.g.
deep neural networks. Albarghouthi et al. (2017); Ghosh et al. (2021) considered finite models for
estimating group fairness w.r.t. the features distribution, and Ghosh et al. (2022) further narrowed
downtolinearmodels.Therefore,weidentifythefollowinglimitationsoftheexistingmethodsinML
auditing. (1) Property-specific auditing: most methods considered a property-specific tailored
approach to audit ML systems, for example either robustness (Cohen et al., 2019; Salman et al.,
2019), group fairness (Albarghouthi et al., 2017; Ghosh et al., 2021), or individual fairness (John4 AJARRA, GHOSH AND BASU
Robustness
DataDistribution IndividualFairness
FourierCoefficients
GroupFairness
Inputsample
Sampler
Black-boxmodel
Prediction
AFA
Fig 1: A schematic of AFA.
etal.,2020).(2)Model-specific auditing:allthemethodsconsideredapriorknowledgeaboutthe
ML model (Neiswanger et al., 2021; Ghosh et al., 2021, 2022; Yan and Zhang, 2022), or a white-box
access to it (Cohen et al., 2019; Salman et al., 2019). These are unavailable in practical systems
such as API-based ML. Therefore, our research question is: Can we design a unified ML auditor for
black-box systems for estimating a set of distributional properties including robustness and fairness?
Contributions. We propose a framework, namely AFA (Active Fourier Auditor), which is an
ML auditor based on the Fourier approximation of a black-box ML model (Figure 1). We observe
that existing black-box ML auditors work in two steps: the model reconstruction step, where they
reconstruct a model completely, and the estimation step, where they put an estimator on top of
it (Yan and Zhang, 2022). We propose a model-agnostic strategy that does not need to reconstruct
the model completely. In particular, for any ML model admitting a Fourier expansion, we compute
thesignificantFouriercoefficientsofamodelacceptingcategoricalinputdistributionssuchthatthey
areenoughtoestimatedifferentdistributionalpropertiessuchasrobustness,individualfairness,and
group fairness. Our contributions are:
• Formalism. For any bounded output model (e.g. all classifiers), we theoretically reduce the esti-
mation of robustness, individual fairness, and group fairness in terms of the Fourier coefficients
of the model. The key idea is based on influence functions, which capture how much a model
output changes due to a change in input variables and can be computed via Fourier coefficients
(Section 3). We propose two types of influence functions for each of these properties that unifies
robustness and individual fairness auditing while put group fairness in a distinct class.
• Algorithm. In AFA, we integrate Goldreich-Levin algorithm (Goldreich and Levin, 1989; Kushile-
vitz and Mansour, 1993) to efficiently compute the significant Fourier coefficients of the ML
model, which are enough to compute the corresponding properties. AFA yields a probably ap-
proximately correct (PAC) estimation of distributional properties. We propose a dynamic version
of Goldreich-Levin to accelerate the computations.
(cid:16) (cid:113) (cid:17)
• Theoretical Sample Complexity. We show that our algorithm requires O˜ 1 log 1 samples to
ϵ δ
yield (ϵ,δ) estimate of robustness and individual fairness, while it needs
O˜(cid:0)1
log
1(cid:1)
samples to
ϵ2 δ
audit group fairness. We further derive a lower bound on the sample complexity of (ϵ,δ)-auditing
ofgroupfairnesstobeΩ˜(δ ).Further,forgroupfairness,weprovethatAFAismanipulation-proof
ϵ2
under perturbation of 2n−1 Fourier coefficients.
• Experimental Results. We numerically test the performance of AFA to estimate the three prop-
erties of different types of models. The results show that AFA achieves lower estimation error
while estimating robustness and individual fairness across perturbation levels. Compared to ex-
isting group fairness auditors, AFA not only achieves lower estimation error but also incurs lowerACTIVE FOURIER AUDITOR 5
computation time across models and the number of samples.
2. BACKGROUND
Before proceeding to the contributions, we discuss the three statistical properties of ML models
that we study, i.e. robustness, individual fairness, and group fairness. We also discuss basics of
Fourier analysis that we leverage to design AFA.
Notations. Here, x represents a scalar, and x represents a vector. X is a set. We denote 1,n as
(cid:74) (cid:75)
the set {1,...,n}. We denote the power set of X by P(X).
Properties of ML Models. A Machine Learning (ML) model h is a deterministic or probabilis-
tic mapping from an n-dimensional input domain of features (or covariates) X to set of labels
(or response variables or outcomes) Y. For example, for Boolean features X ≜ {−1,1}n, and for
categorical features, X ≜ [K]n. For binary classifiers, Y ≜ {0,1}.
We assume to have only black-box access to h, i.e. we send queries from a data-generating distri-
bution and collect only the labels predicted by h. The dataset on which h is tested is sampled from
a data-generating distribution D over X ×Y, which has a marginal distribution D over X.
X,Y
We aim to audit a distributional (aka global) property µ : H × D → R of an ML model
X,Y
h : X → Y belonging to an unknown model class H while having only black-box access to h.
Hereafter, we develop the methodology for binary classifiers and Boolean features. Later, we
discuss approaches to extend the proposed methodology to categorical features and multi-class
classifiers, and corresponding experimental results. In this paper, we study three properties of ML
models, i.e. robustness (µ ), individual fairness (µ ), and group fairness (µ ), which are
Rob IFair GFair
defined below.
Robustness is the ability of a model h to generate same output against a given input and its
perturbed (or noisy) version. Robustness has been central to sub-fields of AI, e.g. safe RL (Garcıa
and Fern´andez, 2015), adversarial ML (Kurakin et al., 2016; Biggio and Roli, 2018), and gained
attention for safety-critical deployment of AI.
Definition 1 (Robustness). Given a model h and a perturbation mechanism Γ of input x ∈ X,
robustness of h is µ (h) ≜ P [h(x) ̸= h(y)].
Rob x∼D, y∼Γ(x)
Examples of perturbation mechanisms include Binary feature flipping N (x) ≜ {x′ | ∀i ∈
ρ
[n],x′ = x × Bernoulli(ρ)} (O’Donnell, 2014), Gaussian perturbation N (x) ≜ {x′ | x′ = x +
i i ρ
ϵ where ϵ ∼ Normal(0,ρ2I)} (Cohen et al., 2019), among others.
In trustworthy and responsible AI, another prevalent concern about deploying ML models is
bias in their predictions. This has led to the study of different fairness metrics, their auditing
algorithms, and algorithms to enhance fairness (Mehrabi et al., 2021; Barocas et al., 2023). There
are two categories of fairness measures (Barocas et al., 2023). The first is the individual fairness
that aims to ensure that individuals with similar features should obtain similar predictions (Dwork
et al., 2012).
Definition 2 (Individual Fairness). For a model h and a neighbourhood Γ(x) of a x ∈ X, the
individual fairness discrepancy of h is µ (h) ≜ P P[h(x) ̸= h(y)].
IFair x∼D, y∼Γ(x)
The neighborhood Γ(x) is commonly defined as the points around x which are at a distance less
than ρ ≥ 0 w.r.t. a pre-defined metric. The metric depends on the application of choice and the6 AJARRA, GHOSH AND BASU
input data (Mehrabi et al., 2021). IF of a model measures its capacity to yield similar predictions
for similar input features of individuals (Dwork et al., 2012; A. Friedler et al., 2016). The similarity
between individuals are measured with different metrics. Let d and d be the metrics for the
X Y
metric spaces of input (X) and predictions (Y), respectively.
A model h satisfies (ϵ,ϵ′)-IF if d (x,x′) ≤ ϵ implies d (h(x),h(x′)) ≤ ϵ′ for all (x,x′) ∈
X Y
X2 (A. Friedler et al., 2016). For Boolean features and binary classifiers, the natural candidate
for d and d is the Hamming distance. This measures the difference between vectors x and x′
X Y
by counting the number of differing elements. Thus, d (x,x′) ≤ l means that x′ has l different
X
bits than x. As auditors, we are interested in measuring how much the Hamming distance between
outcomes of x and x′, i.e. ϵ′. However, since the data-generation process and the models might be
stochastic,wetakeastochasticviewanduseaperturbationmechanismthatdefinesaneighborhood
around each input sample.
Group fairness is the other category of fairness measures that considers the input to be gener-
ated from multiple protected groups (or sub-populations), and we want to remove discrimination in
predictions across these protected groups (Mehrabi et al., 2021). Specifically, we focus on Statistical
Parity (SP) (Feldman et al., 2015; Dwork et al., 2012) as our measure of deviation from group
fairness. For simplicity, we discuss SP for two groups, but we can also generalize it to multiple
groups.
Definition 3 (Statistical Parity). The statistical parity of h is µ (h) ≜ |P [h(x) =
GFair x∼D
1|x = 1]−P [h(x) = 1|x = −1]|, where x is the binary sensitive attribute.
A x∼D A A
In AFA, we use techniques of Fourier analysis to design one computational scheme for simulta-
neously estimating these three properties of an ML model.
A Primer on Fourier Analysis.DesigningAFAismotivatedbytheFourierexpansionofBoolean
functions. Fourier coefficients are distribution-dependent components that capture key information
about the distribution’s properties. This study was initially addressed by (O’Donnell, 2014), who
focused on the uniform distribution. Later, (Heidari et al., 2021) generalized this result to arbitrary
distributions, which we leverage further.
Proposition 1 (Heidari et al. (2021)). There exists a set of orthonormal parity functions
{ψ } such that any function h : {−1,1}n → {−1,1} is decomposed as
S S⊆[n]
(cid:88)
h(x) = hˆ(S)ψ (x) for any x ∼ D. (2.1)
S
S⊆[n]
The Fourier coefficients hˆ(S) ≜ E [h(X)ψ (x)] are unique for all S ⊆ [n].
x∼D S
Example 2. Let us consider h to be the XOR function on x ∈ {−1,1}2. This means that
h(−1,−1) = h(1,1) = 0 and h(1,−1) = h(−1,1) = 1. The Fourier representation of h(x) =
0.5+0.5x +0.5x −0.5x x , when x is sampled from a uniform distribution on {−1,1}2.
1 2 1 2
Example 3. Suppose random variables X and X are drawn i.i.d. from the standard normal
1 2
distribution N(0,1) (Heidari et al., 2021). Define another random variable X as X = X X . It
3 3 1 2
can be verified that the Gram-Schmidt basis of XOR of X ,X ,X has four zero coefficients, i.e. the
1 2 3
sets including X do not influence the outcomes. This is because X ’s information is encoded in X
3 3 1
and X jointly.
2ACTIVE FOURIER AUDITOR 7
Table 1
Example 3
S ∅ {1} {2} {1,2} {3} {1,3} {2,3} {1,2,3}
χ 1 x x x x x x x x x x x x
S 1 2 1 2 3 1 3 2 3 1 2 3
ψ 1 x x x x 0 0 0 0
S 1 2 1 2
Influence functions. To estimate the properties of interest, we use a tool from Fourier analy-
sis, i.e. influence functions (O’Donnell, 2014). They measure how changing an input changes the
output of a model. Different influence functions are widely used in statistics, e.g. to design robust
estimators (Mathieu et al., 2022), and ML, e.g. to find important features (Heidari et al., 2021),
to evaluate how features induce bias (Ghosh et al., 2021), to explain contribution of datapoints on
predictions (Ilyas et al., 2022). Here, we use them to estimate model properties.
Definition 4 (Influence functions). If Γ is a transformation of an input x ∈ X, the influ-
ence function is defined as Inf (h) ≜ P [h(x) ̸= h(Γ(x))]. Inf (h) is called deterministic if the
Γ x∼D Γ
transformation Γ is deterministic, and randomized if Γ randomized.
In general, deterministic influence functions are used in Boolean function analysis (O’Donnell,
2014). In contrast, in Section 3, we express robustness, individual fairness, and group fairness with
randomized influence functions. We also show that the influence functions can be computed using
the Fourier coefficients of the model under audit (Equation (2.1)).
3. ACTIVE FOURIER AUDITOR
In the black-box setting, the access to the model h is limited by the query oracle, accessible
to the auditor. The auditor’s objective is to estimate the property µ through interaction with this
oracle. The definition of the property estimator relies on the information made available to the
auditor during this interaction. In the context of auditing with model reconstruction (Yan and
Zhang, 2022), the auditor is denoted as µˆ : H×B → R. Here, the auditor has access to an unlabeled
pool and applies active learning techniques (e.g. CAL algorithm) to query samples. This process
uses the additional information given by the hypothesis class where the model h lives. Following the
reconstruction phase, the auditor has an approximate model hˆ of true model h, enabling estimation
of the property via plug-in estimator µˆ(hˆ).
Now, we present a novel non-parametric black-box auditor AFA that assumes no knowledge of
the model class and the data-generating distribution. Unlike the full model-reconstruction-based
auditors, AFA uses Fourier expansion and adaptive queries to estimate the robustness, Individual
Fairness (IF), and Group Fairness (GF) properties of a model h. In this setting, the auditor is
defined as µˆ : F × B → R, where F represents the set of Fourier coefficients upon which the
µ µ
property µ depends. First, we show that property estimation with model reconstruction always
incurshighererror.Then,weshowthatrobustness,IF,andGFforbinaryclassifierscanbecomputed
using Fourier coefficients of h. Finally, we compute the Fourier coefficients and thus, estimate the
properties at once (Algorithm 1). We begin by defining a PAC-agnostic auditor that we realise with
AFA.
Definition 5 (PAC-agnostic auditor). Let µ be a computable distributional property of model
h. An algorithm A is a PAC-agnostic auditor if for any ϵ,δ ∈ (0,1), there exists a function m(ϵ,δ)8 AJARRA, GHOSH AND BASU
such that ∀m ≥ m(ϵ,δ) samples drawn from D, it outputs an estimate µˆ satisfying P(|µˆ −µ| ≤
m m
ϵ) ≥ 1−δ.
Remark. µ(h) is a computable property if there exists a (randomized) algorithm, such that when
given access to (black-box) queries, it outputs a PAC estimate of the property µ(h) (Kearns et al.,
2018). Any distributional property, including robustness, individual fairness and group fairness, is
computable given the existence of the uniform estimator.
3.1 The Cost of Reconstruction
The naive way to estimate a model property is to reconstruct the model and then use a plug-in
estimator (Yan and Zhang, 2022). However, this requires an exact knowledge of the model class and
comes with an additional cost of reconstructing the model before property estimation. For group
fairness, we show that the reconstruct-then-estimate approach induces significantly higher error
than the reconstruction error, while the exact model reconstruction itself is NP-hard (Jagielski
et al., 2020).
Proposition 2. If hˆ is the reconstructed model from h, then
(cid:40) (cid:41)
|µ (hˆ)−µ (h)|≤min 1,
Px∼D[hˆ(x)̸=h(x)]
.
GFair GFair min(Px∼D[x
A
=1],Px∼D[x
A
=−1])
Proposition 2 connects the estimation error and the reconstruction error before plugging in the
estimator. It also shows that to have a sensible estimation the reconstruction algorithm needs to
achieve an error below the proportion of minority group, which can be significantly small requiring
high sample complexity. The proof is deferred to Appendix A. This motivates an approach that
avoids model reconstruction by computing only the right components of the model expansion. To
capture the information relevant to estimating our properties of interest, we will represent them in
terms of Fourier coefficients given in the model decomposition. Then we aim to adaptively estimate
larger Fourier coefficients in contrast to model reconstruction method requiring to recovering all the
Fourier coefficients.
3.2 Model Properties with Fourier Expansion
Throughout the rest of this paper, we denote by {ψ } the basis derived from Proposition
S S⊆[n]
1. In this section, we express the model properties of h using its Fourier coefficients. The detailed
proofs are deferred to Appendix B.
a. Robustness.Robustnessofamodelhmeasuresitsabilitytomaintainitsperformancewhennew
dataiscorrupted.Auditingrobustnessrequiresagenerativemodeltoimitatethecorruptions,which
ismodelledbytheperturbationmechanism(Definition1).AswefocusontheBooleancase,theworst
case perturbation Γ is the protocol of flipping vector coordinates with a probability ρ. Specifically,
ρ
a corrupted sample y is generated from x such that for every component, we independently set
y = x with probability 1+ρ and y = −x with probability 1−ρ. This perturbation mechanism
i i 2 i i 2
leads us to the ρ-flipping influence function.
Definition 6 (ρ-flipping Influence Function). The ρ-flipping influence function of any model
h is defined as Inf (h) ≜ P [h(x) ̸= h(y)].
ρ x∼D,y∼Γρ(x)ACTIVE FOURIER AUDITOR 9
For a Boolean classifier, we further observe that Inf (h) = E [h(x)h(y)]. This allows
ρ x∼D, y∼Nρ(x)
us to show that the robustness of h under Γ perturbation is measured by ρ-flipping influence
ρ
function, and thus, can be computed using Fourier coefficients of h.
Proposition 3. Robustness of h under the Γ flipping perturbation is equivalent to the ρ-
ρ
flipping influence function, and thus, can be expressed as
(cid:88)
µ (h) = Inf (h) = ρ|S|hˆ(S)2. (3.1)
Rob ρ
S⊆[n]
b. Individual Fairness (IF). To demonstrate the universality of our approach, we express IF
with the model’s Fourier coefficients. We consider the perturbation mechanism Γ = Γ (·) that
ρ,l
independently flips uniformly l vector coordinates with a probability 1+ρ. Thus, we consider a
2
neighbourhood with E [d (x,x′)] ≤ 1(1+ρ)l around each sample x as the similar set of
x′∼Γ ρ,l(x) X 2
individuals. This perturbation mechanism leads us to the (ρ,l)-flipping influence function.
Definition 7 ((ρ,l)-flipping influence function). The (ρ,l)-flipping influence function of any
model h is defined as Inf (h) = P [h(x) ̸= h(y)].
ρ,l x∼D,y∼N (x)
ρ,l
We leverage (ρ,l)-flipping influence function to express IF of h in terms of its Fourier coefficients
(Proposition 4).
Proposition 4. Individual fairness defined with respect to the Γ perturbation is equivalent
ρ,l
to the (ρ,l)-flipping influence function, and thus, can be expressed as
(cid:88)
µ (h) = Inf (h) = ρ|S l|hˆ(S)2, (3.2)
IFair ρ,l
S⊆[n]
where S denotes the power sets for which l features change.
l
Unifying robustness and IF: The Characteristic Function. It is worth noting that IF
is similar to robustness, differing only by a single degree of freedom, i.e. the number of flipped
directions l. Specifically, from Equation (3.1) and (3.2), we observe that both the properties as
µ(h) = (cid:80) S⊆[n]char(S,µ ·)hˆ(S)2, such that char(S,µ Rob) = ρ|S|, and char(S,µ IFair) = ρ|S l|. We call
char as the characteristic function of the property.
c. Group Fairness (GF). Now, we focus on Group Fairness which aims to ensure similar pre-
dictions for different subgroups of population (Barocas et al., 2023). We focus on Statistical Parity
(SP) as the measure of deviation from GF (Feldman et al., 2015). To quantify SP, we propose a
novel membership influence function.
Definition 8 (Membership influence function). If A denotes a sensitive feature, we define the
(cid:104)
membership influence function w.r.t. A as the conditional probability Inf (h) ≜ P h(x) ̸=
A x,y∼D
(cid:12) (cid:105)
h(y)(cid:12)x = 1,y = −1 .
(cid:12) A A
Inf (h) is the conditional probability of the change in the outcome of h due to change in group
A
membership of samples from D. In other words, it expresses the amount of independence between
the outcome and group membership.10 AJARRA, GHOSH AND BASU
Note that the membership influence function is a randomised version of the deterministic in-
fluence function in (O’Donnell, 2014). If we denote the transformation of flipping membership, i.e.
sensitive attribute of x, f (x), the classical influence function is Infdet = P [h(x) ̸= h(f (x))].
A A x∼D A
The limitation of this deterministic function is that given x ∼ D the transformed vector f (x) may
A
not represent a sample from D. Thus, it fails to encode the information relevant to SP, whereas the
proposed membership influence function does it correctly as shown below.
Proposition5. Statisticalparityofhw.r.tasensitiveattributeAanddistributionD istheroot
of the second order polynomial P (X), i.e.
α(1−α)X2−hˆ(∅)(1−2α)X−(cid:80) hˆ(S)2−(1−hˆ2(∅))
,
hˆ S⊆[n],S∋A 2
where α = P [x = 1] and hˆ(∅) is the coefficient of empty set.
A
x∼D
Summary of the Fourier Representation of Model Properties. Robustness and individual
fairness have the same Fourier pattern. They depend on all the Fourier coefficients of the model but
differ only on their characteristic functions. In contrast, statistical parity of a sensitive feature A
depends only on the Fourier coefficient of that sensitive feature hˆ({A}) and the Fourier coefficient
of the empty set hˆ(∅).
3.3 NP-hardness of Exact Computation
We have shown that the exact computation of robustness and individual fairness depends on all
Fouriercoefficientsofthemodel.SinceeachFouriercoefficientofhisgivenbyhˆ(S) = E [h(x)ψ (x)],
S
x∼D
exactlycomputingasingleFouriercoefficienttakesO(|X|)time.Additionally,thenumberofFourier
coefficients to compute to estimate robustness and individual fairness is exponential in the dimen-
sion of the input domain (2n). Thus, exactly computing robustness and individual fairness requires
O(2n|X|) time. This gives us an idea about the computational hardness of the exact estimation
problem. Now, we prove estimating large Fourier coefficients to be NP-complete.
Theorem 1. Let Q ≜ {x,h(x)} be the set of input samples sent to h and the predictions
obtained. Given τ ∈ R , exactly computing all the τ-significant Fourier coefficients of h is NP-
≥0
complete.
Proof Sketch. For a set of queries Q and for each power set S, Fourier coefficient is given by
hˆ(S) = 1 (cid:80) h(x)ψ (x). Maximizing the Fourier coefficient |hˆ(S)| is equivalent to max-
|Q| (x,h(x))∈Q S
imizing the agreement or disagreement between h and the sign of ψ for each truth assignment.
S
Alternatively, maximizing |hˆ(S)| is equivalent to finding a truth assignment that maximizes the
number of true clauses in a CNF, where each clause is a disjunction of h(x) and the sign of ψ (x),
S
and the CNF includes all such clauses for all x ∈ Q. This is known as the Max2Sat (maximum
two satisfiability) problem, which is known to be NP-complete. Hence, we conclude that finding
large Fourier coefficients is also NP-complete. This result shows that the exact computation of the
Fourier coefficients for our properties is NP-hard. This has motivated us to design AFA, which we
later proved to be an (ϵ,δ)-PAC agnostic auditor.
3.4 Algorithm: Active Fourier Auditor (AFA)
We have shown that finding significant Fourier coefficients can be an NP-hard problem. In this
section, we propose AFA (Algorithm 1) that takes as input a restricted access of q > 0 queries
from the data-generating distribution and requests labels from the black-box oracle of h (Line 2).ACTIVE FOURIER AUDITOR 11
Algorithm 1 Active Fourier Auditor (AFA)
1: Input: Sensitive attribute A, Query access to h, τ,δ∈(0,1), ϵ←τ2/4
2: {x ,h(x )} ← BlackboxQuery(h,q)
k k k∈[q]
3: L ← GoldreichLevin(h,q,τ,δ)
h
4: µˆ(h)← (cid:80) char(µ,S)hˆ(s)2
S∈Lh
5: µˆ (h)←P−1(0)
GF hˆ
6: return {µˆ ,µˆ ,µˆ }
RB IF GF
Those queries enable us to find the squares of significant Fourier coefficients and estimate them
simultaneously. The list of the significant Fourier coefficients L of the model h contains both
h
subsets and their estimated Fourier weights. We adopt a Goldreich-Levin (GL) algorithm based
approach (Goldreich and Levin, 1989; Kushilevitz and Mansour, 1993) to find such list of significant
Fourier coefficients (Figure 2). Since estimating the properties – robustness, individual fairness and
groupfairness–dependonestimatingthoseFouriercoefficients,weplugintheircomputedestimates
and output an (ϵ,δ)-PAC estimate of the properties (Line 4 and 5).
Algorithmic Insights. To compute the significant Fourier coefficients, we start with the power
set. Now, we denote the subsets containing an element i as B (X), and the subsets not containing
i
i as B (X). Let Υ denote a trajectory starting from the set of all Fourier coefficients in the binary
¬i
search tree of Fourier coefficients (Figure 1). The question is that from the power set, how can we
design a Υ to reach subsets of Fourier coefficients above a given threshold τ?
In AFA, we dynamically create “buckets” of coefficients for this purpose. Each bucket BS,k, rep-
resents a collection of power sets, such that BS,k ≜ {S∪T | T ⊆ {k+1,...,n}}. The corresponding
weight is quantified by WS,k ≜ (cid:80) hˆ(S ∪T)2. In this context, WS,k measures the total
T⊆{k+1,...,n}
contribution of the Fourier coefficients associated with the elements in the bucket BS,k. The bucket
is initialized at B∅,0, which represents the weight of the power set of 1,n . By Parseval’s identity,
we know that the weight of the power set is 1, i.e. (cid:80) hˆ(S)2 = 1.(cid:74) The(cid:75) bucket BS,k is then split
S∈P(X)
into two buckets of the same cardinal: BS,k−1 and BS∪{k+1},k+1. We then estimate the weight of
each bucket by sending black-box queries to the model h. The algorithm discards the bucket whose
weight is below the threshold. When all the buckets collected at a round consist of exactly one
element each, i.e. we reach the leaves, the algorithm halts and the buckets collected in this process
are subsets of 1,n that have large Fourier coefficients.
(cid:74) (cid:75)
Extension to Continuous Features. Heidari et al. (2021) extend Proposition 1 to encompass
a general Euclidean space. We use the generic construction of Fourier coefficients in the Euclidean
space to extend our computations for feature spaces involving both categorical and continuous
features. Rest of our computations follow naturally.
Extension to Multi-class Classification. We also deploy AFA for multi-class classification,
where Y consists of multiple labels. In this setting, the concept of group fairness, i.e. µ (h) ≜
GFair
max |P [h(x) = y|x = 1] − P [h(x) = y|x = −1]|, is called multicalibration (Dwork
y∈Y x∼D A x∼D A
et al., 2023). Here, we construct Fourier expansions of the model for each pair of labels. Then, we
use Proposition 5 to compute the group fairness for each of the expansions, and finally, take the
maximum to estimate multi-group fairness of h. Formal details are deferred to Appendix D. We
experimentally evaluate both the extensions.
4. THEORETICAL ANALYSIS
Upper Bounds on Sample Complexity.12 AJARRA, GHOSH AND BASU
B(X)
B (X) B (X)
0 ¬0
B (X) B (X) B (X) B (X)
0,1 0,¬1 ¬0,1 ¬0,¬1
. . . . . . . .
. . . . . . . .
. . . . . . . .
B B ... ... ... ... ... ... ... ... ... ... ... ...B B
Υ Υ Υ Υ
1 2 k−1 k
Fig 2: AFA begins with the set of all Fourier coefficients, with weight 1, which is above the threshold
τ < 1. It proceeds by splitting the bucket and verifies at each level of the tree the weight of
the node. If the weight is below the threshold, the algorithm halts. Otherwise, it continues to
expand, yielding a set of (informative) trajectories Υ, the subsets with large Fourier coefficients are
{B (X),··· ,B (X)}.
Υ1 Υ
k
Theorem 2 (Upper bounds for Robustness and Individual Fairness). AFA is a PAC-agnostic
auditorforrobustnessandindividualfairnesswithsamplecomplexityO(cid:16) char(L,µ)(1−4char(L¯,µ))(cid:113)
log
2(cid:17)
.
ϵ δ
Here, char(L,µ) ≜ (cid:80) char(S,µ) and char(L¯,µ) ≜ (cid:80) char(S,µ).
· · · ·
S∈L S∈L¯
Theorem3(UpperboundsforGroupFairness). AFAyieldsan(ϵ,δ)-PACestimateofµ (h)
GFair
if it has access to predictions of
O(cid:0)1
log
4(cid:1)
input samples.
ϵ2 δ
(cid:113)
WeprovethatAFAachievesanoptimalrateofO˜(1 log 1)forrobustnessandindividualfairness
ϵ δ
and an O˜(1 log 1) rate for group fairness. Consequently, under the same number of samples, AFA
ϵ2 δ
exhibits a higher error rate for group fairness compared to robustness and individual fairness, as
group fairness involves solving a quadratic equation while the others correspond to their respective
influence functions. The proofs of these theorems are in Appendix C.
Rethinking Manipulation-proof. Yan and Zhang (2022) first propose manipulation-proof au-
diting that primarily revolves around fully reconstructing the model, and defines the manipulation-
proof subclass using a version space. However, this approach may overlook numerous other models
that, while having a significant probability mass in areas where they disagree with the black-box
model, exhibit similar behavior to the black-box model w.r.t. the property. In contrast, we propose
to capture all those functions by defining only the essential information required for auditing.
Definition 9 (Fourier strategic manipulation-proof). Let h be a model that admits a Fourier
expansion as in h = (cid:80) hˆ(S)ψ . We say that an auditor A achieves optimal manipulation-
S⊆[n] S
proofness for estimating a (distributional) property µ when A is a PAC-agnostic auditor (Defini-
tion5)andoutputsanexponential-sizesubclassoffunctionsthatsatisfies∀h,h′ ∈ M,P(|µ(h)−µ(h′)| ≥ ϵ) ≤
δ.ACTIVE FOURIER AUDITOR 13
Table 2
Average estimation error for statistical parity across different ML models. ‘—’ denotes when a method cannot scale
to the model. The best method is in bold.
Dataset COMPAS Student Drug
Model LR MLP RF LR MLP RF LR MLP RF
µCAL 0.312 — — — — — — — —
Uniform 0.077 0.225 0.077 0.132 0.225 0.077 0.254 0.116 0.127
AFA 0.006 0.147 0.006 0.030 0.147 0.006 0.220 0.040 0.120
Theorem 4 (Manipulation-proofness of AFA). AFA achieves optimal manipulation-proofness
for estimating statistical parity with manipulation-proof subclass of size 2n−2.
Lower Bounds without Manipulation-proofness. In the following, we propose a lower bound
foryieldingaPACestimateofthestatisticalparitywithnomanipulation-proofconstraint.Addition-
ally, we assume the auditing algorithm can sequentially query the black-box model with informative
queries. The proof is in Appendix C.3.
Theorem 5 (Lower bound without manipulation-proofness). Let ϵ ∈ (0,1), δ ∈ (0,1/2]. We
aim to obtain (ϵ,δ)-PAC estimate of SP of model h ∈ H, where the hypothesis class H has VC
dimension d. For any auditing algorithm A, there exists an adversarial distribution realizable by the
model to audit such that with Ω˜(δ ) samples, A outputs an estimate µˆ of µ (h∗) with P[|µˆ −
ϵ2 GFair
µ (h∗)| > ϵ] > δ.
GFair
Our results extend the existing sample complexity results with model reconstruction (Yan and
Zhang, 2022), and also provide a reference of optimality for upper bounds. We highlight the gap
from the upper bound established in Theorem 3, attributed to the lack of the manipulation proof.
5. EMPIRICAL PERFORMANCE ANALYSIS
Inthissection,weevaluatetheperformanceofAFAinestimatingmultiplemodels’groupfairness,
robustness, and individual fairness. Below, we provide a detailed discussion of the experimental
setup, objectives, and results.
Experimental Setup. We conduct experiments on COMPAS (Angwin et al., 2016), student
performance (Student) (Cortez and Silva, 2008), and drug consumption (Drug) (Fehrman et al.,
2019)datasets.Thedatasetscontainamixofbinary,categorical,andcontinuousfeaturesforbinary
andmulti-classclassification.WeevaluateAFAonthreeMLmodels:LogisticRegression(LR),Multi-
layer Perceptron (MLP), and Random Forest (RF). The ground truth of group fairness, individual
fairness, and robustness is computed using the entire dataset as in (Yan and Zhang, 2022). For
group fairness, we compare AFA with uniform sampling method, namely Uniform, and the active
fairness auditing algorithms (Yan and Zhang, 2022, Algorithm 3), i.e. CAL and its variants µCAL and
randomized µCAL, which requires more information about the model class than black-box access.
We report the best variant of CAL with the lowest error. For robustness and individual fairness, we
compare AFA with Uniform. Each experiment is run 10 times and we report the averages. We refer
to Appendix E.1 for details.
Our empirical studies have the following objectives:
1. How accurate AFA is with respect to the baselines to audit robustness, individual fairness, and
group fairness for different models and datasets?14 AJARRA, GHOSH AND BASU
0.3 CAL
Uniform
101
0.2 AFA
100
0.1
0.0 10 1
200 400 600 800 1000 CAL Uniform AFA
Budget Algorithms
Fig 3: Error (left) and running time (right) of different auditors in estimating statistical parity of
COMPAS in LR.
Table 3
Estimation error for robustness and individual fairness by Uniform and AFA. Bold case means lower error.
Robustness Individual Fairness
ρ Uniform AFA Uniform AFA
0.25 0.033 0.016 0.036 0.029
0.30 0.333 0.078 0.309 0.047
0.35 0.299 0.139 0.248 0.092
2.HowsampleefficientandcomputationallyefficientAFAiswithbaselinesinauditingdistributional
properties?
Accurate, Sample Efficient, and Fast Estimation of Group Fairness. In Table 2, we
demonstrate the estimation error of group fairness by different methods across datasets and mod-
els. AFA yields the lowest estimation error, hence a better method, than all baselines in all nine
configurations of models and datasets. Among baselines, CAL cannot estimate group fairness be-
yond COMPAS on LR, due to the requirement of a finite version space, which is provided only for
COMPASonLR.Uniform,albeitsimpletoimplement,invariablydemonstrateserroneousestimate.
Thus, AFA is the most accurate auditor for group fairness w.r.t. baselines.
Figure 3 (left) demonstrates the sample efficiency of different methods for statistical parity. AFA
requires the lowest number of samples to reach almost zero estimation error. Thus, AFA is sample
efficient than other methods. Figure 3 (right) demonstrates the corresponding runtimes, where AFA
isthesecondfastestmethodafterUniformandfasterthanCAL.Therefore, AFA yields a well balance
between accuracy, sample efficiency, and running time among baselines.
Accurate Estimation of Robustness and Individual Fairness. Table 3 demonstrates the
estimation error for robustness and individual fairness achieved by AFA and Uniform with different
ρ’s and 1000 samples from COMPAS dataset and LR model. AFA yields lower estimation error than
Uniform across different models, and for higher values of ρ, the improvement due to AFA increases.
Intuitively, Uniform samples IID from the space of input features, perturbs samples uniformly
randomly, then queries the black-box model to obtain labels of perturbed samples to estimate
properties. In contrast, AFA queries samples recursively to cover the feature space and estimates
large Fourier coefficients without perturbing the input features. This also reflects the theoretical
sample complexity results for Uniform and AFA, i.e. O(1/ϵ2) and O(1/ϵ), respectively. Thus, AFA
is more accurate than Uniform to estimate robustness and individual fairness.
rorrE
noitamitsE
emit
gninnuRACTIVE FOURIER AUDITOR 15
6. CONCLUSION AND FUTURE WORK
We propose AFA, a Fourier-based model-agnostic and black-box approach for universally audit-
ing an ML model’s distributional properties. We focus on three properties: robustness, individual
fairness, andgroup fairness. We show that the significant Fourier coefficients of theblack-boxmodel
yield a PAC approximation of all properties, establishing AFA as a universal auditor of ML. Em-
pirically, AFA is more accurate, and sample efficient, while being competitive in running time than
existing methods across datasets. In the future, we aim to extend AFA to estimate distributional
properties other than the three studied in this paper.
7. ACKNOWLEDGEMENTS
This work was supported by the Regalia Project partnered by Inria and French Ministry of
Finance. D. Basu acknowledges the ANR JCJC project REPUBLIC (ANR-22-CE23-0003-01) and
the PEPR project FOUNDRY (ANR23-PEIA-0003).
REFERENCES
A. Friedler, S., Scheidegger, C., and Venkatasubramanian, S. (2016). On the (im)possibility of
fairness. In arxiv. arxiv:1609.07236.
Albarghouthi,A.,D’Antoni,L.,Drews,S.,andNori,A.V.(2017). Fairsquare:probabilisticverifica-
tion of program fairness. Proceedings of the ACM on Programming Languages, 1(OOPSLA):1–30.
Angwin,J.,Larson,J.,Mattu,S.,andKirchner,L.(2016). Machinebiasriskassessmentsincriminal
sentencing. ProPublica, May, 23.
Barocas, S., Hardt, M., and Narayanan, A. (2023). Fairness and machine learning: Limitations and
opportunities. MIT Press.
Biggio,B.andRoli,F.(2018).Wildpatterns:Tenyearsaftertheriseofadversarialmachinelearning.
InProceedingsofthe2018ACMSIGSACConferenceonComputerandCommunicationsSecurity,
pages 2154–2156.
Cohen, J., Rosenfeld, E., and Kolter, Z. (2019). Certified adversarial robustness via randomized
smoothing. In international conference on machine learning, pages 1310–1320. PMLR.
Cohn, D., Atlas, L., and Richard, L. (1994). Improving generalization with active learning. In
Machine Learning (20), pages 201–221.
Cortez, P. and Silva, A. M. G. (2008). Using data mining to predict secondary school student
performance.
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R. (2012). Fairness through awareness.
In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS 12),
volume 86, pages 214––226.
Dwork,C.,Lee,D.,Lin,H.,andTankala,P.(2023). Frompseudorandomnesstomulti-groupfairness
and back. In The Thirty Sixth Annual Conference on Learning Theory, pages 3566–3614. PMLR.16 AJARRA, GHOSH AND BASU
Fehrman, E., Egan, V., Gorban, A. N., Levesley, J., Mirkes, E. M., and Muhammad, A. K. (2019).
Personality traits and drug consumption. Springer.
Feldman, M., Friedler, S., Moeller, J., Scheidegger, C., and Venkatasubramanian, S. (2015). Certi-
fying and removing disparate impact. In In proceedings of the 21th ACM SIGKDD international
conference on knowledge discovery and data mining, pages 259–268.
Garcıa,J.andFern´andez,F.(2015). Acomprehensivesurveyonsafereinforcementlearning. Journal
of Machine Learning Research, 16(1):1437–1480.
Ghosh, B., Basu, D., and Meel, K. S. (2021). Justicia: A stochastic sat approach to formally verify
fairness. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
7554–7563.
Ghosh,B.,Basu,D.,andMeel,K.S.(2022). Algorithmicfairnessverificationwithgraphicalmodels.
In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 9539–9548.
Goldreich, O. and Levin, L. A. (1989). A hard-core predicate for all one-way functions. In D. S.
Johnson, editor, Proceedings of the 21st Annual ACM Symposium on Theory of Computing, May
14-17.
Goldwasser, S., N. Rothblum, G., Shafer, J., and Yehudayoff, A. (2021). Interactive proofs for
verifying machine learning. Innovations in Theoretical Computer Science Conference (ITCS).
Heidari, M., Sreedharan, J., Shamir, G. I., and Szpankowski, W. (2021). Finding relevant infor-
mation via a discrete fourier expansion. Proceedings of the 38th International Conference on
Machine Learning, PMLR 139:4181-4191.
Herman,T.andRothblum,G.N.(2022). Verifyingtheunseen:Interactiveproofsforlabel-invariant
distribution properties. STOC: Proceedings of the 54th Annual ACM SIGACT Symposium on
Theory of Computing.
Ilyas, A., Min Park, S., Engstrom, L., Leclerc, G., and Madry, A. (2022). Datamodels: Predicting
predictions from training data. arXiv preprint arXiv:2202.00622.
Jagielski, M., Carlini, N., Berthelot, D., Kurakin, A., and Papernot, N. (2020). High accuracy
and high fidelity extraction of neural networks. In 29th USENIX security symposium (USENIX
Security 20), pages 1345–1362.
John,P.G.,Vijaykeerthy,D.,andSaha,D.(2020). Verifyingindividualfairnessinmachinelearning
models. Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI).
Kearns, M., Neel, S., Roth, A., and Steven Wu, Z. (2018). Preventing fairness gerrymandering:
Auditing and learning for subgroup fairness. Proceedings of the 35th International Conference on
Machine Learning, PMLR.
Kumar,R.S.S.,Nystr¨om,M.,Lambert,J.,Marshall,A.,Goertzel,M.,Comissoneru,A.,Swann,M.,
and Xia, S. (2020). Adversarial machine learning-industry perspectives. In 2020 IEEE security
and privacy workshops (SPW), pages 69–75. IEEE.ACTIVE FOURIER AUDITOR 17
Kurakin, A., Goodfellow, I. J., and Bengio, S. (2016). Adversarial machine learning at scale. In
International Conference on Learning Representations.
Kushilevitz, E. and Mansour, Y. (1993). Learning decision trees using the fourier spectrum. SIAM
J. Comput., 22(6):1331–1348.
Li, B., Qi, P., Liu, B., Di, S., Liu, J., Pei, J., Yi, J., and Zhou, B. (2023). Trustworthy ai: From
principles to practices. ACM Computing Surveys, 55(9):1–46.
Madiega, T. (2021). Artificial intelligence act. European Parliament: European Parliamentary
Research Service.
Mathieu, T., Basu, D., and Maillard, O.-A. (2022). Bandits corrupted by nature: Lower bounds on
regret and robust optimistic algorithms. Transactions on Machine Learning Research.
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A. (2021). A survey on bias
and fairness in machine learning. ACM computing surveys (CSUR), 54(6):1–35.
Metaxa,D.,Park,J.S.,Robertson,R.E.,Karahalios,K.,Wilson,C.,Hancock,J.,Sandvig,C.,etal.
(2021). Auditingalgorithms:Understandingalgorithmicsystemsfromtheoutsidein. Foundations
and Trends® in Human–Computer Interaction, 14(4):272–344.
Mutreja, S. and Shafer, J. (2023). Pac verification of statistical algorithms. 36th Annual Conference
on Learning Theory (COLT).
Neiswanger, W., Wang, K. A., and Ermon, S. (2021). Bayesian algorithm execution: Estimating
computable properties of black-box functions using mutual information. Proceedings of the 38th
International Conference on Machine Learning (ICML).
O’Donnell, R. (2014). Analysis of Boolean Functions. Cambridge University Press, Cambridge,
Massachusetts.
Raji, I. D., Smart, A., White, R. N., Mitchell, M., Gebru, T., Hutchinson, B., Smith-Loud, J.,
Theron, D., and Barnes, P. (2020). Closing the ai accountability gap: Defining an end-to-end
framework for internal algorithmic auditing. In Proceedings of the 2020 conference on fairness,
accountability, and transparency, pages 33–44.
Rasheed, K., Qayyum, A., Ghaly, M., Al-Fuqaha, A., Razi, A., and Qadir, J. (2022). Explainable,
trustworthy, and ethical machine learning for healthcare: A survey. Computers in Biology and
Medicine, 149:106043.
Salman,H.,Li,J.,Razenshteyn,I.,Zhang,P.,Zhang,H.,Bubeck,S.,andYang,G.(2019). Provably
robust deep learning via adversarially trained smoothed classifiers. Advances in neural informa-
tion processing systems, 32.
Wang, Y., Baharav, T. Z., Han, Y., Jiao, J., and Tse, D. (2022). Beyond the best: Estimating
distribution functionals in infinite-armed bandits. arXiv preprint arXiv:2211.01743.
Wilson, C., Ghosh, A., Jiang, S., Mislove, A., Baker, L., Szary, J., Trindel, K., and Polli, F. (2021).
Building and auditing fair algorithms: A case study in candidate screening. In Proceedings of the
2021 ACM Conference on Fairness, Accountability, and Transparency, pages 666–677.18 AJARRA, GHOSH AND BASU
Xu, H. and Shie, M. (2011). Robustness and generalization. In Ma´ech Learn, volume 86, pages
391––423.
Yan, T. and Zhang, C. (2022). Active fairness auditing. In International Conference on Machine
Learning, pages 24929–24962. PMLR.ACTIVE FOURIER AUDITOR 19
APPENDIX A: THE COST OF AUDITING WITH RECONSTRUCTION: PROOF OF
PROPOSITION 2
Proposition 2. If hˆ is the reconstructed model from h, then
(cid:40) (cid:41)
P [hˆ(x) ̸= h(x)]
|µ (hˆ)−µ (h)| ≤ min 1, x∼D . (A.1)
GFair GFair
min(P [x = 1],P [x = −1])
x∼D A x∼D A
Proof. Step 1. We begin the proof by lower bounding the probability of yielding different
predictions by h and hˆ.
P [hˆ(x) ̸= h(x)] = P [hˆ(x) ̸= h(x)|x = 0] P [x = 0]+ P [hˆ(x) ̸= h(x)|x = 1] P [x = 1]
A A A A
x∼D x∼D x∼D x∼D x∼D
(cid:16) (cid:17)
≥ p P [hˆ(x) ̸= h(x)|x = 0]+ P [hˆ(x) ̸= h(x)|x = 1]
A A
x∼D x∼D
The first equality is a consequence of the law of total probability. The last inequality holds as we
define p ≜ min{ P [x = 1], P [x = 0]}.
A A
x∼D x∼D
Since p ̸= 0, we get
1
P [hˆ(x) ̸= h(x)] ≥ P [hˆ(x) ̸= h(x)|x = 0]+ P [hˆ(x) ̸= h(x)|x = 1]. (A.2)
A A
p
x∼D x∼D x∼D
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Term1 Term2
Step 2. We observe that the Term 2 above can be rewritten as
P [hˆ(x) = 1|x = 1] = P [hˆ(x) = 1,h(x) = −1|x = 1]+ P [hˆ(x) = 1,h(x) = 1|x = 1]
A A A
x∼D x∼D x∼D
≤ P [hˆ(x) ̸= h(x)|x = 1]+ P [h(x) = 1|x = 1]
A A
x∼D x∼D
The last inequality is true due to the fact that hˆ(x) = 1,h(x) = −1 is a sub-event of the event
h(x) ̸= hˆ(x).
Now, by symmetry of h and hˆ, we get
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) P [hˆ(x) = 1|x = 1]− P [h(x) = 1|x = 1](cid:12)≤ P [hˆ(x) ̸= h(x)|x = 1] (A.3)
(cid:12) A A (cid:12) A
(cid:12)x∼D x∼D (cid:12) x∼D
Similarly, working further with the Term 1 yields
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) P [hˆ(x) = 1|x = 0]− P [h(x) = 1|x = 0](cid:12)≤ P [hˆ(x) ̸= h(x)|x = 0] (A.4)
(cid:12) A A (cid:12) A
(cid:12)x∼D x∼D (cid:12) x∼D
Step 3. Finally, using triangle inequality yields
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
|µ(hˆ)−µ(h)| ≤ (cid:12) P [hˆ(x) = 1|x = 0]− P [h(x) = 1|x = 0](cid:12)+(cid:12) P [hˆ(x) = 1|x = 1]− P [h(x) = 1|x = 1](cid:12)
(cid:12) A A (cid:12) (cid:12) A A (cid:12)
(cid:12)x∼D x∼D (cid:12) (cid:12)x∼D x∼D (cid:12)20 AJARRA, GHOSH AND BASU
≤ P [hˆ(x) ̸= h(x)|x = 0]+ P [hˆ(x) ̸= h(x)|x = 1]
A A
x∼D x∼D
1
≤ P [hˆ(x) ̸= h(x)]
p
x∼D
The second step comes from inequalities (A.3) and (A.4), while the last one is due to inequality
(A.2).
APPENDIX B: COMPUTING MODEL’S PROPERTIES WITH FOURIER COEFFICIENTS:
PROOFS OF SECTION 3.2
B.1 Robustness and Individual Fairness
Proposition 3. Let ρ ∈ [−1,1].
The robustness of a binary classifier h : {−1,1}n → {−1,1} under the Γ flipping perturbation
ρ
is equivalent to the ρ-flipping influence function, and thus, can be expressed as
(cid:88)
µ (h) = Inf (h) = ρ|S|hˆ(S)2.
Rob ρ
S⊆[n]
Proof.
Step 0: Robustness in terms of a composition of expectations over the perturbation
Γ and D. By the definition of robustness, we have:
ρ
Inf (h) = P [h(x) ̸= h(y)]
ρ
x∼D
y∼Γρ(x)
= E [h(x)h(y)]
x∼D
y∼Γρ(x)
Where the second equation comes from the fact that h takes values in {−1,1}.
Step 1: Robustness via operator approach. We commence the proof by defining the robust
operator T : {−1,1}n → R as
ρ
T h(x) ≜ E [h(y)].
ρ
y∼Nρ(x)
Given the expression of the influence function in step 0, we have:
Inf (h) = E [h(x)h(y)]
ρ
x∼D
y∼Nρ(x)
= E [h(x) E h(y)]
x∼D y∼Nρ(x)
= E [h(x)T h(x)]
ρ
x∼D
≜ ⟨ h,T h⟩
ρ D
The second equation comes from the linearity of the expectation, and the last step comes from
the definition of the inner product that depends on the distribution D.ACTIVE FOURIER AUDITOR 21
Now, we expand both the model h and the operator T h in the Gram-Schmidt basis given by
ρ
Heidari et al. (2021):
2n 2n
(cid:88) (cid:88)
Inf (h) = ⟨ hˆ(S )ψ (·), hˆ(S ) E [ψ (y)]⟩
ρ
i1=1
i1 Si1
i2=1
i2
y∼Nρ(·)
Si2 D
2n 2n
= (cid:88) (cid:88) hˆ(S )hˆ(S )⟨ ψ ,fρ ⟩
i1 i2 Si1 Si2 D
i1=1i2=1
Where, for all x ∈ {−1,1}n and for all i ∈ {1,··· ,2n}, we used the following notation: fρ (x) ≜
Si
E [ψ (y)].
Si
y∼Nρ(x)
Step 2: Reduction of the robust operator to basis elements operators.
Let x ∈ X,
fρ (x) = E [ψ (y)]
Si
y∼Nρ(x)
Si
i−1
(cid:88)
= E [χ (y)]− α E [ψ (y)]
Si i,j Sj
y∼Nρ(x)
j=1
y∼Nρ(x)
i−1
= E [(cid:89) y ]−(cid:88) α fρ (x)
y∼Nρ(x)
k∈Si
k
j=1
i,j Sj
i−1
= (cid:89) E [y ]−(cid:88) α fρ (x)
k∈Siy∼Nρ(x)
k
j=1
i,j Sj
i−1
= (cid:89) ρx −(cid:88) α fρ (x)
k i,j Sj
k∈Si j=1
The second inequality comes from replacing each basis element from the Gram-Schmidt orthog-
onalization process with its expression in terms of parity functions. In the fourth equation, the
expectation over each component is computed by the perturbation process Γ , that is for each k in
ρ
S , x is flipped with probability 1−ρ.
i k 2
i−1
fρ (x) = ρ|Si|χ (x)−(cid:88) α fρ (x)
Si Si i,j Sj
j=1
i−1 i−1
= ρ|Si|ψ (x)+ρ|Si|(cid:88) α ψ (x)−(cid:88) α fρ (x)
Si i,j Sj i,j Sj
j=1 j=1
i−1
= ρ|Si|ψ (x)+(cid:88) α (ρ|Si|ψ (x)−fρ (x)).
Si i,j Sj Sj
j=122 AJARRA, GHOSH AND BASU
Now, we compute the inner product left in step 1 to conclude the proof:
k−1
⟨ ψ ,fρ ⟩ = ⟨ ψ ,ρ|S k|ψ +(cid:88) α (ρ|S k|ψ −fρ )⟩
Si S k D Si S k k,j Sj Sj D
j=1
k−1
= ρ|S k|δ +(cid:88) δ α (ρ|S k|−⟨ ψ ,fρ ⟩ )
i,k j,k k,j Si Sj D
j=1
⟨ ψ ,fρ ⟩ = ρ|S k|δ
Si S
k
D i,k
Where the last step comes from the fact that j < k.
Step 4: Conclusion.
2n 2n
Inf (h) = (cid:88) (cid:88) hˆ(S )hˆ(S )⟨ ψ ,fρ ⟩
ρ i1 i2 Si1 Si2 D
i1=1i2=1
2n 2n
(cid:88) (cid:88)
= hˆ(S i1)hˆ(S i2)ρ|Si1|δ
i1,i2
i1=1i2=1
2n
(cid:88)
= ρ|Si|hˆ(S )2
i
i=1
(cid:88)
= ρ|S|hˆ(S)2
S⊆[n]
We deduce the Fourier pattern in robustness property:
(cid:88)
µ (h) = ρ|S|hˆ(S)2
Rob
S⊆[n]
The proof for individual fairness proceeds similarly by considering the operator T : {−1,1}n →
ρ
R, defined as:
T h(x) = E [h(y)]
ρ,l y∼N (x)
ρ,l
B.2 Group Fairness: Statistical Parity
We first establish the relationship between group fairness and Fourier coefficients.
Lemma 1. If Inf (h) denotes the membership influence function for the sensitive attribute A of
A
the model h, we have the following result that relates the influence function to the model’s h Fourier
coefficients:
(cid:88)
Inf (h) = hˆ(S)2
A
S⊆[n]
S∋AACTIVE FOURIER AUDITOR 23
Proof. The membership influence function for the sensitive attribute A is given by:
Inf (h) = P [h(x) ̸= h(y)]
A
x∼D+
y∼D−
This function is closely related to the Laplacian of the target model in the direction of the
sensitive attribute A, defined as:
h(x)−h(y)
L h(x,y) := ,∀(x,y) ∈ (X+,X−)
A
2
Since h takes values in {−1,1}, one can see that |L h(x,y)|2 = 1 .
A {h(x)̸=h(y)}
By taking the expectation over the left and right part:
∥L h∥2 = E [L h(x,y)2] = Inf (h)
A D+,D− A A
x∼D+
y∼D−
1 (cid:88) 1 (cid:88)
∀(x,y) ∈ X+×X− : L h(x,y) = hˆ(S)ψ (x)− hˆ(S)ψ (y)
A S S
2 2
S⊆[n] S⊆[n]
1 (cid:88) 1 (cid:88)
= hˆ(S)ψ (x)+ hˆ(S)ψ (x)
S S
2 2
S⊆[n] S⊆[n]
S∋A S̸∋A
1 (cid:88) 1 (cid:88)
− hˆ(S)ψ (y)− hˆ(S)ψ (y)
S S
2 2
S⊆[n] S⊆[n]
S∋A S̸∋A
1 (cid:88) 1 (cid:88)
∀(x,y) ∈ X+×X− : L h(x,,y) = hˆ(S)ψ (x)− hˆ(S)ψ (y)
A S S
2 2
S⊆[n] S⊆[n]
S∋A S∋A
By Parseval identity, ∥L h∥2 = (cid:80) hˆ(S)2.
A D+,D−
S⊆[n]
S∋A
Hence,
(cid:88)
Inf (h) = ∥L h∥2 = hˆ(S)2
A A D+,D−
S⊆[n]
S∋A
Proposition 5. Statistical parity of h w.r.t a sensitive attribute A and distribution D is the
root of the second order polynomial
(cid:88)
(1−hˆ2(∅))
P (X) ≜ α(1−α)X2−hˆ(∅)(1−2α)X − hˆ(S)2− , (B.1)
hˆ
2
S⊆[n],S∋A
where α = P [x = 1] and hˆ(∅) is the coefficient of the empty set.
A
x∼D24 AJARRA, GHOSH AND BASU
Proof. We use the following notation in the proof:
p = P [h(x) = 1]
x∼D
α = P [X+] (probability of belonging to the first sensitive group)
x∼D
µ+ (h) = P [h(x) = 1|x = 1]
GFair A
x∼D
µ− (h) = P [h(x) = 1|x = −1]
GFair A
x∼D
We have,
µ (h) = µ+ (h)−µ− (h) (B.2)
GFair GFair GFair
By the law of total probability, we also have:
p = αµ+ (h)+(1−α)µ− (h) (B.3)
GFair GFair
We first express the membership influence function in terms of the statistical parity:
Inf (h) = P [h(x) ̸= h(x′)|x = 1,x′ = −1]
A A A
x,x′∼D
= P [h(x) = 1,h(x′) = 0|x = 1,x′ = −1]+ P [h(x) = −1,h(x′) = 1|x = 1,x′ = −1]
A A A A
x,x′∼D x,x′∼D
= µ+ (h)(1−µ− (h))+µ− (h)(1−µ+ (h))
GFair GFair GFair GFair
= µ+ (h)+µ− (h)−2µ+ (h)µ− (h)
GFair GFair GFair GFair
Hence, we have:
µ+ (h)+µ− (h)−2µ+ (h)µ− (h)−Inf (h) = 0
GFair GFair GFair GFair A
From equation B.2, and equation B.3, we have:
(cid:40)
µ+ (h) = p+(1−α)µ (h)
GFair GFair
µ− (h) = p−αµ (h)
GFair GFair
The expression becomes:
2α(1−α)µ (h)2+(1−2p)(1−2α)µ (h)−Inf (h)+2p(1−p) = 0
GFair GFair A
The Fourier coefficient of the empty set is given by:
hˆ(∅) = E [h(x)]
x∼DACTIVE FOURIER AUDITOR 25
= E [21 −1]
{h(x)=1}
x∼D
hˆ(∅) = 2 P [h(x) = 1]−1
x∼D
Since p = P [h(x) = 1], we get the desired result.
x∼D
Corollary 6. If D is the uniform distribution, statistical parity is exactly the Fourier coeffi-
cient of the sensitive attribute, i.e.
µ (h) = hˆ({A})
GFair
Proof.
µ (h) = | P [h(x) = y|x ∈ A+]− P [h(x) = y|x ∈ A−]|
GFair
x∼D x∼D
1 1
= | P [h(x) = y|x ∈ A+]− − P [h(x) = y|x ∈ A−]+ |
x∼D 2 x∼D 2
1 1
= | E [21 −1|x ∈ A+]− E [21 −1|x ∈ A−]|
2x∼D {h(x)=1} 2x∼D {h(x)=1}
1 1
= | E [h(x)|x ∈ A+]− E [h(x)|x ∈ A−]|
2x∼D 2x∼D
1 1
= | E [h(x)ψ (x)|x ∈ A+]− E [h(x)ψ (x)|x ∈ A−]|
A A
2x∼D 2x∼D
APPENDIX C: THEORETICAL ANALYSIS: PROOFS OF SECTION 4
C.1 Upper Bounds on Sample Complexity of AFA
Claim 1. Let {A } a finite set of events indexed by I. Then,
i i∈I
(cid:104)(cid:92) (cid:105) (cid:88) (cid:104) (cid:105)
P A ≥ P A −|I|+1
i i
i∈I i∈I
The proof is a consequence of the union bound.
Lemma 2 (Two-Sample Hoeffding’s Inequality). If X ,...X , X′,...X′ are iid random vari-
1 m1 1 m2
ables taking values in [−1,1] generating by the distribution D, such that
1
(cid:88)m1 (cid:88)m2
µ = E[X2], and µˆ = X X′,
m m i j
1 2
i=1 j=1
then
(cid:110) m m ϵ2(cid:111)
1 2
P[|µˆ−µ| ≤ 4ϵ] ≥ 1−2exp −
8
The proof is obtained by employing one sample Hoeffding inequality to the random variable
Z = X X′.
i,j i j26 AJARRA, GHOSH AND BASU
Theorem 2 (Upper bounds for Robustness and Individual Fairness). Given ϵ ∈ (0,1) and δ ∈
(0,1], AFA is a PAC-agnostic auditor for robustness and individual fairness with sample complexity
(cid:16)char(L,µ)(1−4char(L¯,µ))(cid:114)
2(cid:17)
O log .
ϵ δ
Here, char(L,µ) ≜ (cid:80) char(S,µ) and char(L¯,µ) ≜ (cid:80) char(S,µ).
· · · ·
S∈L S∈L¯
Proof.
Step 0. Let us define τ2 ≜ 4ϵ.
Let x ,··· ,x ,x′,··· ,x′ are sampled i.i.d. from D, where m = m +m denotes the total
1 m1 1 m2 1 2
number of samples, and m and m to be the number of samples with x = 1 and x = −1,
1 2 a A
respectively.
Let L denote the list of subsets exhibiting Fourier coefficients larger than τ.
Step 1.Bydefinitionsofchar(S,µ),andtheresultsofProposition3and4,weunifiedlyexpress
·
both the ‘true’ properties of h as
(cid:88)
µ(h) = char(S,µ)hˆ(S)2
S⊆ 1,n
(cid:88)(cid:74) (cid:75)
= char(S,µ)E [h(x)h(y)ψ (x)ψ (y)]. (C.1)
x,y∼D S S
S⊆ 1,n
(cid:74) (cid:75)
Now, for any S ∈ L, we define an unbiased estimator of the squared Fourier coefficients as
1
(cid:88)m1 (cid:88)m2
hˆ (S)2 ≜ h(x )h(x′)ψ (x )ψ (x ). (C.2)
AFA m m i j S i S j
1 2
i=1 j=1
Hence, the estimators of these properties, i.e. robustness and individual fairness, takes the form
1
(cid:88)(cid:88)m1 (cid:88)m2
µˆ ≜ char(S,µ)h(x )h(x′)ψ (x )ψ (x ). (C.3)
AFA m m i j S i S j
1 2
S∈Li=1 j=1
Step 2. Using Equation (C.1) and (C.3), we express the estimation error as
(cid:12) (cid:12)
(cid:12) (cid:88) (cid:88) (cid:12)
|µ(h)−µˆ | = (cid:12) char(S,µ)hˆ(S)2− char(S,µ)hˆ (S)2(cid:12)
AFA (cid:12) AFA (cid:12)
(cid:12) (cid:12)
S⊆ 1,n S∈L
(cid:12) (cid:74) (cid:75) (cid:12)
(cid:12)(cid:88) (cid:88) (cid:88) (cid:12)
= (cid:12) char(S,µ)hˆ(S)2+ char(S,µ)hˆ(S)2− char(S,µ)hˆ (S)2(cid:12)
(cid:12) AFA (cid:12)
(cid:12) (cid:12)
S∈L S̸∈L S∈L
(cid:88) (cid:88) (cid:12) (cid:12)
≤ char(S,µ)hˆ(S)2+ char(S,µ)(cid:12)hˆ(S)2−hˆ (S)2(cid:12)
(cid:12) AFA (cid:12)
S̸∈L S∈L
(cid:88) (cid:88) (cid:12) (cid:12)
≤ τ2 char(S,µ)+ char(S,µ)(cid:12)hˆ(S)2−hˆ (S)2(cid:12). (C.4)
(cid:12) AFA (cid:12)
S̸∈L S∈LACTIVE FOURIER AUDITOR 27
The penultimate inequality is due to the fact that |x+y| ≤ |x|+|y| for all x,y ∈ R. The last
inequality is by the definition of L, i.e. ∀S ⊆ 1,n : S ̸∈ L implies that |hˆ(S)| ≤ τ. AFA gets access
(cid:74) (cid:75)
to this list of subsets L due to the Goldreich-Levin algorithm.
Step 3. Now, we leverage Equation (C.4), to derive an PAC estimation bound for robustness
and individual fairness. Specifically,
(cid:104) (cid:105) (cid:104)(cid:88) (cid:105)
P |µ(h)−µˆ | ≥ ϵ ≤ P char(S,µ)|hˆ(S)2−hˆ (S)2| ≥ ϵ−τ2char(L¯,µ) (C.5)
AFA AFA
S∈L
Here, we denote by char(L,µ) the sum (cid:80) char(S,µ) and char(L¯,µ) the sum (cid:80) char(S,µ).
S∈L S̸∈L
Step 4. Now, by consecutively applying Claim 1 and Lemma 2, we get an upper bound on the
estimation error of the squared Fourier coefficients in L.
(cid:104)(cid:92)(cid:110)(cid:12) (cid:12) (cid:111)(cid:105) (cid:88) (cid:104)(cid:12) (cid:12) (cid:105)
P (cid:12)hˆ(S)2−hˆ (S)2(cid:12) ≤ 4ϵ ≥ P (cid:12)hˆ(S)2−hˆ (S)2(cid:12) ≤ 4ϵ −|L|+1
(cid:12) AFA (cid:12) (cid:12) AFA (cid:12)
S∈L S∈L
(cid:110) m m ϵ2(cid:111)
1 2
≥ |L|−2|L|exp − −|L|+1
8
(cid:110) m m ϵ2(cid:111)
1 2
≥ 1−2|L|exp −
8
(cid:12) (cid:12)
This result naturally yields a bound on (cid:80) char(S,µ)(cid:12)hˆ(S)2−hˆ (S)2(cid:12).
S∈L (cid:12) AFA (cid:12)
(cid:104)(cid:88) (cid:12) (cid:12) (cid:105) (cid:104)(cid:91)(cid:110)(cid:12) (cid:12) (cid:111)(cid:105)
P char(S,µ)(cid:12)hˆ(S)2−hˆ (S)2(cid:12) ≥ 4char(L,µ)ϵ ≤ P (cid:12)hˆ(S)2−hˆ (S)2(cid:12) ≥ 4ϵ
(cid:12) AFA (cid:12) (cid:12) AFA (cid:12)
S∈L S∈L
(cid:110) m m ϵ2(cid:111)
1 2
≤ 2|L|exp −
8
The last inequality is due to the union bound.
Step 5. Finally, using the fact that 4ϵ = τ2 and properly substituting to ensure 4char(L,µ)ϵ ≥
ϵ−τ2char(L¯,µ), we get
P(cid:104)(cid:88) char(S,µ)(cid:12)
(cid:12)hˆ(S)2−hˆ
(S)2(cid:12)
(cid:12) ≥
ϵ−τ2char(L¯,µ)(cid:105)
≤
2|L|exp(cid:110)
−
m 1m 2ϵ2 (cid:111)
(cid:12) AFA (cid:12) 128char(L,µ)2(1−4char(L¯,µ))2
S∈L
Hence, by Equation (C.5),
(cid:104) (cid:105) (cid:110) m m ϵ2 (cid:111)
1 2
P |µ(h)−µˆ | ≥ ϵ ≤ 2|L|exp −
AFA 128char(L,µ)2(1−4char(L¯,µ))2
By the definition of the sample complexity, the probability in the RHS has to be less than a
given δ. Thus,
128char(L,µ)2(1−4char(L¯,µ))2 2|L|
m m ≥ log .
1 2 ϵ2 δ28 AJARRA, GHOSH AND BASU
√
Since L ≥ 1 and m = m +m ≥ 2 m m , we conclude
1 2 1 2
√
8
2char(L,µ)(1−4char(L¯,µ))(cid:114)
2
m ≥ log
ϵ δACTIVE FOURIER AUDITOR 29
Theorem 3 (Upper bounds for Group Fairness). Given ϵ ∈ (0,1) and δ ∈ (0,1], AFA yields an
(ϵ,δ)-PAC estimate of µ (h) if it has access to predictions of
GFair
(cid:18) (cid:19)
1 4
O log
ϵ2 δ
input samples.
Proof. Step 1. First, we aim to express the group fairness as a root of the second-order
polynomial in Proposition 5, and thus, to check when this approach is valid.
We observe that the discriminant of this second order polynomial is
∆ = (2p+1)2(2α−1)2+8α(1−α)Inf −1
A
= 4α2+4p2−4α−4p+1+8α(1−α)Inf
A
(cid:88)
= 4α2+4p2−4α−4p+1+8α(1−α) hˆ2(S)
S⊆ 1,n
(cid:88)(cid:74) (cid:75) (cid:88)
= 4α2+4p2−4α−4p+1+8α(1−α) hˆ2(S)+8α(1−α) hˆ2(S)
S∈L S̸∈L
(cid:88)
≥ 4α2+4p2−4α−4p+1+8α(1−α) hˆ2(S)
S∈L
≥ 4α2+4p2−4α−4p+1+8|L|τ2α(1−α)
≥ 4α2+4p2−4α−4p+1+32ϵα(1−α)
1 1
= 4(1−8ϵ)(α− )2+4(p− )2−(1−8ϵ)
2 2
For ϵ > 1, ∆ is positive. Thus, µ (h), i.e. the zero of a second-order polynomial, can be
8 GFair
expressed as
(cid:32) (cid:33)0.5
−(1−2α)(1−2p)+ 4α2+4p2−4α−4p+1+8α(1−α)Inf
A
µ (h) =
GFair
4α(1−α)
Here, p = 1+hˆ(∅) and Inf = Inf (h) = (cid:80) hˆ(S)2.
2 A A
S⊆ 1,n , S∋A
Step 2. We consider the following estim(cid:74) at(cid:75) or yielded by AFA1.
(cid:32) (cid:33)0.5
−(1−2α)(1−2pˆ)+ 4α2+4pˆ2−4α−4pˆ+1+8α(1−α)I(cid:100)nf
A
µˆ (h) = ,
GFair
4α(1−α)
where
pˆ=
1+hˆ AFA(∅)
, and I(cid:100)nf
A
=
(cid:88)
hˆ AFA(S)2.
2
S∈L
S∋A
1Notethatthisestimatorisindependentofαorp,unliketherestrictiveassumptionsrequiredinexistingworks(Yan
and Zhang, 2022).30 AJARRA, GHOSH AND BASU
To simplify notations, we denote:
∆ = 4α2+4p2−4α−4p+8α(1−α)Inf +1 (C.6)
A
∆ˆ = 4αˆ2+4pˆ2−4α−4p+8α(1−α)I(cid:100)nf A+1 (C.7)
Step 3. We have,
(cid:20) (cid:21) (cid:20) (cid:21) (cid:20) (cid:21)
2α(1−α)ϵ
P |µ(cid:92) −µ (h)| ≤ ϵ ≥ P |pˆ−p| ≤ +P |∆ˆ −∆| ≤ 2α(1−α)ϵ −1
GFair GFair
|1−2α|
On the other hand,
(cid:20) (cid:21) (cid:20) (cid:21) (cid:20) (cid:21) (cid:20) (cid:21)
ϵ ϵ ϵ
P |∆ˆ −∆| ≤ ϵ ≥ P |pˆ2−p2| ≤ +P |pˆ−p| ≤ +P |I(cid:100)nf A−Inf A| ≤
12 12 24α(1−α)
Similar to the previous proof and we apply using Two-sample Hoeffding on the first and third
term above, while we use the classical Hoeffding for the second term. Together they yield a sample
(cid:32) (cid:33)
(cid:26) (cid:113) (cid:27)
complexity upper bound of O max 1 log 4, 1 log 2 , which is O(1 log 4) for ϵ ∈ (0,1) and
ϵ2 δ ϵ δ ϵ2 δ
δ ∈ (0,1].
C.2 Manipulation-proofness of AFA
Theorem 4 (Manipulation-proofness of AFA). AFA achieves optimal manipulation-proofness
for estimating statistical parity with manipulation-proof subclass of size 2n−2.
Proof. We are interested in hypotheses h for which µ (h) = µ (h∗).
GFair GFair
Let h∗ denote the model under audit and let h be any model that admits Fourier decomposition,
we have:
(cid:88)
h = hˆ(S)ψ
S
S⊆[n]
(cid:88)
= hˆ(S)ψ +hˆ(∅)ψ
S ∅
S⊆[n]
S̸=∅
(cid:88) (cid:88)
= hˆ(S)ψ + hˆ(S)ψ +hˆ(∅)ψ
S S ∅
S⊆[n] S⊆[n]
S̸=∅,S∋A S̸=∅,S̸∋A
On the other hand,
∀S : S ∋ A,hˆ(S) = h∗(S),hˆ(∅) = h∗(∅) =⇒ µ (h) = µ (h∗)
GFair GFair
Where the last line comes from the dependence of statistical parity on the Fourier coefficients of
the empty set and any subset that contains the protected feature (e.g, Formula 5).ACTIVE FOURIER AUDITOR 31
(cid:40)
Hence, the manipulation proof subclass is: h : (cid:80) hˆ(S)ψ : ∀S ⊆ [n] : (S = ∅)∨(S ∋ A) =⇒
S
S⊆[n]
(cid:41)
hˆ(S) = hˆ∗(S) , which has a size of 2n−2.
C.3 Lower Bound on Sample Complexity without Manipulation-proofness
Theorem 5 (Lower bound without manipulation-proofness). Let ϵ ∈ (0,1), δ ∈ (0,1/2]. We
aim to obtain (ϵ,δ)-PAC estimate of SP of model h ∈ H, where the hypothesis class H has VC
dimension d. For any auditing algorithm A, there exists an adversarial distribution realizable by the
model to audit such that with Ω˜(δ ) samples, A outputs an estimate µˆ of µ (h∗) with P[|µˆ −
ϵ2 GFair
µ (h∗)| > ϵ] > δ.
GFair
Proof. Let H be a hypothesis class of VC dimension VC(H), we start with case VC(H) ∈ 2N.
LetZ = {ζ ,...,ζ ,ζ ,··· ,ζ } ⊆ X asubspaceshatteredbyH,letN beourqueryingbudget.
1 d d+1 2d
Step1:Constructionofadversarialdistribution.LetZ+ = {ζ ,...,ζ }andZ− = {ζ ,...,ζ }.
1 d d+1 2d
We define the adversarial distribution as the distribution satisfying:
(cid:40)
x|X+ ∼ U{Z+}
D =
x|X− ∼ U{Z−}
For any i ∈ 1,2d and given the iid assumption, any z ∼ Z+ will be denoted z+ and similarly any
z ∼ Z− will(cid:74) be de(cid:75) noted z−.
Consider hypotheses H and H that chooses h∗ randomly from {0,1}Z:
0 1
• H : picks h∗ such that for all i ∈ 1,d independently:
0
(cid:74) (cid:75)
(cid:40)
1 with probability 1 −ϵ
h∗(z ) := 2 (C.8)
i 0 with probability 1 +ϵ
2
and for all i ∈ d+1,2d (independently):
(cid:74) (cid:75)
(cid:40)
1 with probability 1 +ϵ
h∗(z ) := 2 (C.9)
i 0 with probability 1 −ϵ
2
• H : picks h∗ such that for all i ∈ 1,d independently:
1
(cid:74) (cid:75)
(cid:40)
1 with probability 1 +ϵ
h∗(z ) := 2 (C.10)
i 0 with probability 1 −ϵ
2
and for all i ∈ d+1,2d (independently):
(cid:74) (cid:75)
(cid:40)
1 with probability 1 −ϵ
h∗(z ) := 2 (C.11)
i 0 with probability 1 +ϵ
232 AJARRA, GHOSH AND BASU
If h∗ is chosen under hypothesis H , the probability that involves h∗ will be denoted P .
i i
The case where VC(H) ∈ 2N+1 reduces to VC(H) ∈ 2N by giving a delta mass distribution to
ζ on the subspace shattered by H.
2d+1
Step 2: Bounding demographic parity by bounding p and Inf
A
In order to get a lower bound for estimating statistical parity, we express it in terms of the
probability of positives and the randomized influence function.
(cid:104) (cid:105) (cid:104) (cid:105) (cid:104) (cid:105)
P µˆ−µ(h∗) > ϵ ≥ P pˆ−p(h∗) > c αϵ +P I(cid:100)nf A−Inf A(h∗) > c α,1ϵ2+c
α,2
, (C.12)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
TermI TermII
√ (cid:113)
where c = 4α(1−α)(12− 6) , c = 1+ 1 and c = 2 1 .
α 11(1−2α) α,1 2α(1−α) α,2 32α2(1−α)2
Step 2.a: Bounding the Term I. Turning an estimation problem into a testing problem. Under
hypothesis H , we have:
0
(cid:104) ϵ(cid:105) (cid:104) 2α−11 2α−1 ϵ(cid:105)
P pˆ−p(h∗) ≥ ≥ P pˆ≥ ,p(h∗) ≤ −
0 0
2 2 2 2
(cid:104) 2α−1(cid:105) (cid:104) 2α−1 ϵ(cid:105)
≥ P pˆ≥ +P p(h∗) ≤ − −1
0 0
2 2 2
Under hypothesis H , we have:
1
(cid:104) ϵ(cid:105) (cid:104) 2α−1 2α−1 ϵ(cid:105)
P pˆ−p(h∗) ≤ ≥ P pˆ≥ ,p(h∗) ≥ +
1 1
2 2 2 2
(cid:104) 2α−1(cid:105) (cid:104) 2α−1 ϵ(cid:105)
≥ P pˆ< +P p(h∗) ≥ + −1
1 1
2 2 2
Since
(cid:104) ϵ(cid:105) 1 (cid:104) ϵ(cid:105) 1 (cid:104) ϵ(cid:105)
P pˆ−p(h∗) ≥ = P pˆ−p(h∗) ≥ + P pˆ−p(h∗) ≥
0 1
2 2 2 2 2
Using the fact that P[A∩B] ≥ P[A]+P[B]−1, we have:
(cid:32)
(cid:104) ϵ(cid:105) 1 (cid:104) 2α−1(cid:105) (cid:104) 2α−1(cid:105)
P pˆ−p(h∗) ≥ ≥ P pˆ≥ +P pˆ< (C.13)
0 1
2 2 2 2
(cid:33)
(cid:104) 2α−1 ϵ(cid:105) (cid:104) 2α−1 ϵ(cid:105)
+P p(h∗) ≤ − +P p(h∗) ≥ + −2 (C.14)
0 1
2 2 2 2
By Le Cam’s lemma:
(cid:104) 2α−1(cid:105) (cid:104) 2α−1(cid:105)
P pˆ≥ +P pˆ< ≥ 1−TV(P ∥ P ) (C.15)
0 1 0 1
2 2ACTIVE FOURIER AUDITOR 33
Concentration of p(h∗). To lower bound the remaining term in (C.14), we prove Lemma 3.
This proves result C.21.
Similar to the proof of the first result, by Hoeffding inequality,
(cid:104) α ϵ(cid:105) (cid:16) dϵ2(cid:17)
P p+(h∗) > − ≤ 2exp −
1 2 2 2α2
(cid:104) 1−α ϵ(cid:105) (cid:16) dϵ2 (cid:17)
P p−(h∗) > − ≤ 2exp −
1 2 2 2(1−α)2
The proof of result C.22 concludes by proceeding with the remaining steps in the same manner as
the previous proof.
(cid:104) 2α−1 ϵ(cid:105) (cid:16) dϵ2 (cid:17) (cid:16) dϵ2 (cid:17)
P p(h∗) ≤ − ≥ 1−2exp − −2exp − (C.16)
0 2 2 32α2 2(1−α)2
(cid:104) 2α−1 ϵ(cid:105) (cid:16) dϵ2 (cid:17) (cid:16) dϵ2 (cid:17)
P p(h∗) ≥ + ≥ 1−2exp − −2exp − (C.17)
1 2 2 32α2 2(1−α)2
By symmetry of the statistical test we have the result in C.22.
Step 2.b: Bounding Term II. Similar to step 2.a, we have:
(cid:104) ϵ(cid:105) 1 (cid:104) ϵ(cid:105) 1 (cid:104) ϵ(cid:105)
P |I(cid:100)nf A−Inf A(h∗)| ≥ = P
0
|I(cid:100)nf A−Inf A(h∗)| ≥ + P
1
|I(cid:100)nf A−Inf A(h∗)| ≥
2 2 2 2 2
We deduce
(cid:32)
(cid:104) ϵ(cid:105) 1 (cid:104) 1(cid:105) (cid:104) 1(cid:105)
P I(cid:100)nf A−Inf A(h∗) ≥ ≥ P
0
I(cid:100)nf
A
≥ +P
1
I(cid:100)nf
A
< + (C.18)
2 2 2 2
(cid:33)
(cid:104) 1 ϵ(cid:105) (cid:104) 1 ϵ(cid:105)
P Inf (h∗) ≤ − +P Inf (h∗) ≥ + −2 (C.19)
0 A 1 A
2 2 2 2
By Le Cam’s lemma, we have:
(cid:18) (cid:19) (cid:18) (cid:19)
1 1
P Inf (h∗) > +P Inf (h∗) ≤ ≥ 1−TV(P ∥ P )
0 A 1 A 0 1
2 2
Concentration of Inf (h∗). To lower bound the remaining term in (C.19), we prove Lemma 4.
A
Under hypothesis H , we have:
0
(cid:104) ϵ2(cid:105) (cid:104) 1 1 ϵ2(cid:105)
P
0
I(cid:100)nf A−Inf A(h∗) ≥ ≥ P
0
I(cid:100)nf
A
≥ ,Inf A(h∗) ≤ −
2 2 2 2
(cid:104) 1(cid:105) (cid:104) 1 ϵ2(cid:105)
≥ P
0
I(cid:100)nf
A
≥ +P
0
Inf A(h∗) ≤ − −1
2 2 234 AJARRA, GHOSH AND BASU
Under hypothesis H , we have:
1
(cid:104) ϵ(cid:105) (cid:104) 1 1 ϵ(cid:105)
P
1
I(cid:100)nf A−Inf A(h∗) ≥ ≥ P
1
I(cid:100)nf
A
≥ ,Inf A(h∗) ≥ −
2 2 2 2
(cid:104) 1(cid:105) (cid:104) 1 ϵ(cid:105)
≥ P
1
I(cid:100)nf
A
< +P
1
Inf A(h∗) ≥ − −1
2 2 2
Step 3: Upper bounding the statistical distances Let’s show that H and H are hard to distin-
0 1
guish. In other words, let’s show that D (P ||P ) = O(ϵ2)
KL 0 1
(cid:16) (cid:17)
The quantity D P ||P depends on how the algorithm A interacts with the oracle O(h∗)
KL 0 1
and construct a brick of history denoted by Hist. We can observe that this quantity is exactly
(cid:16) (cid:17)
D P (y|(x,y) ∈ Hist,x)||P (y|(x,y) ∈ Hist,x) averaged on the whole available querying set.
KL 0 1
More formally, we prove Lemma 5 that states
N (cid:34) (cid:18) (cid:12)(cid:12) (cid:19)(cid:35)
D KL(cid:16) P 0||P 1(cid:17) = (cid:88) E D
KL
P 0(y i|(x,y) ∈ H ii −st 1,x i)(cid:12) (cid:12)(cid:12) (cid:12)P 1(y i|(x,y) ∈ H ii −st 1,x i) .
(cid:12)(cid:12)
i=1
Thenextstepistoupperboundthisquantity:AtiterationI,wedistinguishbetweentwoseparate
cases:
• If x ∈ Hist , then A will always output the same value under both hypotheses H and H ,
i i−1 0 1
which was sent by oracle O(h∗). Hence,
D (cid:0) P (y |(x,y) ∈ Hist ,x )∥P (y |(x,y) ∈ Hist ,x )(cid:1) = 0
KL 0 i i−1 i 1 i i−1 i
• If x ∈/ Hist , we have the following table that summarizes all possibilities under hypotheses
i i−1
H and H , conditioning on X+:
0 1
H\y 1 0
H 1 − ϵ 1 + ϵ
0 2 2 2 2
H 1 + ϵ 1 − ϵ
1 2 2 2 2
And under hypotheses H and H , conditioning on X−:
0 1
H\y 1 0
H 1 + ϵ 1 − ϵ
0 2 2 2 2
H 1 − ϵ 1 + ϵ
1 2 2 2 2
From the two tables, we deduce the overall result by expanding over each protected group
(e.g, X−,X+)
H\y 1 0
H 1 + (1−2α)ϵ 1 − (1−2α)ϵ
0 2 2 2 2
H 1 − (1−2α)ϵ 1 + (1−2α)ϵ
1 2 2 2 2
We end up with a binary entropy upper bound:
(cid:18) (cid:12)(cid:12) (cid:19) (cid:18) (cid:19)
D KL P 0(y i|(x,y) ∈ H ii −st 1,x i)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)P 1(y i|(x,y) ∈ H ii −st 1,x i) = kl 1
2
+ (1− 22α)ϵ , 1
2
− (1− 22α)ϵACTIVE FOURIER AUDITOR 35
Fact 1. For a,b ∈ (1, 3) : D (a,b) ≤ 3(b−a)2
4 4 KL
Hence,
(cid:18) (cid:12)(cid:12) (cid:19)
D
KL
P 0(y i|(x,y) ∈ H ii −st 1,x i)(cid:12) (cid:12)(cid:12) (cid:12)P 1(y i|(x,y) ∈ H ii −st 1,x i) ≤ 3(1−2α)2ϵ2
(cid:12)(cid:12)
D (P ||P ) ≤ 3N(1−2α)2ϵ2 (C.20)
KL 0 1
By Pinsker’s inequality;
 (cid:18) (cid:19) (cid:18) (cid:19) (cid:114)
1 1 1
  P 0 p(h∗) >
2
+P 1 p(h∗) ≤
2
≥ 1− 2D KL(P 0||P 1)
(cid:18) (cid:19) (cid:18) (cid:19) (cid:114)
1 1 1
  P
0
Inf A(h∗) > +P
1
Inf A(h∗) ≤ ≥ 1− D KL(P 0||P 1)
2 2 2
By using result from (C.20),
    P 0(cid:18) p(h∗) > 21(cid:19) +P 1(cid:18) p(h∗) ≤ 21(cid:19) ≥ 1−(cid:114) 3N(1− 22α)2ϵ2
   P 0(cid:18) Inf A(h∗) > 21(cid:19) +P 1(cid:18) Inf A(h∗) ≤ 21(cid:19) ≥ 1−(cid:114) 3N(1− 22α)2ϵ2
Results in (C.21) and (C.22) further yield
(cid:114)
(cid:104) ϵ(cid:105) 1 (cid:16) dϵ2 (cid:17) (cid:16) dϵ2 (cid:17) 3N |1−2α|ϵ
P pˆ−p(h∗) ≥ ≥ −2exp − −2exp − −
2 2 32α2 2(1−α)2 2 2
(cid:114)
1 (cid:16) dϵ2 (cid:17) 3N |1−2α|ϵ
≥ −4exp − − ,
2 8M2 2 2
α
where M = max(α,1−α).
α
Further, (C.23) and (C.24) yield
(cid:114)
(cid:104) ϵ(cid:105) 5 (cid:16) dϵ(cid:17) (cid:16) dϵ(cid:17) 3N(1−2α)2ϵ2
P I(cid:100)nf A−Inf A(h∗) ≥ ≥ −4exp − −4exp − −
2 2 2 18 8
(cid:114)
5 (cid:16) dϵ(cid:17) 3N(1−2α)2ϵ2
≥ −8exp − −
2 18 8
Finally, solving the inequality
(cid:114)
−dϵ2 3N(1−2α)2ϵ2
3−4exp − ≥ δ
18 8
(cid:32) (cid:33)2
yields the sample complexity to be N ≤ 8 δ−3+4exp(−dϵ2 ) .
3(1−2α)2ϵ2 1836 AJARRA, GHOSH AND BASU
C.4 Additional Technical Lemmas
Lemma 3.
(cid:104) 2α−1 ϵ(cid:105) (cid:16) dϵ2 (cid:17) (cid:16) dϵ2 (cid:17)
P p(h∗) ≤ − ≥ 1−2exp − −2exp − (C.21)
0 2 2 32α2 2(1−α)2
(cid:104) 2α−1 ϵ(cid:105) (cid:16) dϵ2 (cid:17) (cid:16) dϵ2 (cid:17)
P p(h∗) ≥ + ≥ 1−2exp − −2exp − (C.22)
1 2 2 32α2 2(1−α)2
Proof.
(cid:104) (cid:105)
p(h∗) = P h∗(x) = 1
(cid:104) (cid:12) (cid:105) (cid:104) (cid:12) (cid:105)
= αP h∗(x) = 1(cid:12)X+ +(1−α)P h∗(x) = 1(cid:12)X−
(cid:12) (cid:12)
d d
α (cid:88) 1−α (cid:88)
= 1 + 1
d {h∗(zi)=1} d {h∗(z d+i)=1}
i=1 i=1
p(h∗) = p+(h∗)+p−(h∗)
Where p+(h∗) = α (cid:80)d 1 and p−(h∗) = 1−α (cid:80)d 1
d i=1 {h∗(zi)=1} d i=1 {h∗(z d+i)=1}
Under H (resp. H ), dp+(h∗) is the sum of d Bernoulli variables of mean 1 −ϵ (resp. 1 +ϵ).
0 1 α 2 2
Under H (resp. H ), d p+(h∗) is the sum of d Bernoulli variables of mean 1 +ϵ (resp. 1 −ϵ).
0 1 1−α 2 2
(cid:104) α ϵ(cid:105) (cid:16) dϵ2 (cid:17)
P p+(h∗) > − ≤ 2exp −
0 2 4 32α2
(cid:104) ϵ 1−α(cid:105) (cid:16) dϵ2 (cid:17)
P p−(h∗) > − ≤ 2exp −
0 2 2 2(1−α)2
On the other hand,
(cid:104) 2α−1 ϵ(cid:105) (cid:104) α ϵ ϵ 1−α(cid:105)
P p(h∗) ≤ − ≥ P p+(h∗) ≤ − ,p−(h∗) ≤ −
0 0
2 2 2 4 2 2
(cid:104) α ϵ(cid:105) (cid:104) ϵ 1−α(cid:105)
≥ P p+(h∗) ≤ − +P p−(h∗) ≤ − −1
0 0
2 4 2 2
(cid:16) dϵ2 (cid:17) (cid:16) dϵ2 (cid:17)
≥ 1−2exp − −2exp −
32α2 2(1−α)2
Lemma 4 (Concentration of Influence Function).
(cid:104) 1+ϵ(cid:105) (cid:16) dϵ(cid:17) (cid:16) dϵ(cid:17)
P Inf (h∗) ≤ ≥ 3−4exp − −4exp − (C.23)
0 A
2 2 18
(cid:104) 1−ϵ(cid:105) (cid:16) dϵ(cid:17) (cid:16) dϵ(cid:17)
P Inf (h∗) > ≥ 3−4exp − −4exp − (C.24)
1 A
2 2 18ACTIVE FOURIER AUDITOR 37
Proof.
(cid:104) (cid:12) (cid:105)
Inf (h∗) = P h∗(x) ̸= h∗(x′)(cid:12)x ∈ X+,x′ ∈ X−
A (cid:12)
(cid:104) (cid:12) (cid:105) (cid:104) (cid:12) (cid:105)
= P h∗(x) = 1,h∗(x′) = 0(cid:12)x ∈ X+,x′ ∈ X− +P h∗(x) = 0,h∗(x′) = 1(cid:12)x ∈ X+,x′ ∈ X−
(cid:12) (cid:12)
(cid:104) (cid:12) (cid:105) (cid:104) (cid:12) (cid:105) (cid:104) (cid:12) (cid:105) (cid:104) (cid:12) (cid:105)
= P h∗(x) = 1(cid:12)x ∈ X+ P h∗(x) = 0(cid:12)x ∈ X− +P h∗(x) = 0(cid:12)x ∈ X+ P h∗(x) = 1(cid:12)x ∈ X−
(cid:12) (cid:12) (cid:12) (cid:12)
1 (cid:88) 1 (cid:88)
= 1 1 + 1 1
d2 {h∗(zi)=1} {h∗(z d+j)=0} d2 {h∗(zi)=0} {h∗(z d+j)=1}
1≤i,j≤d 1≤i,j≤d
Inf (h∗) = Inf+ (h∗)Inf− (h∗)+Inf+ (h∗)Inf− (h∗)
A A,1 A,0 A,0 A,1
Where, Inf+ (h∗) = 1 (cid:80)d 1
A,1 d i=1 {h∗(zi)=1}
Inf− (h∗) = 1 (cid:80)d 1 ,
A,0 d i=1 {h∗(z d+i)=0}
Inf+ (h∗) = 1 (cid:80)d 1 ,
A,0 d i=1 {h∗(zi)=0}
Inf− (h∗) = 1 (cid:80)d 1 .
A,1 d i=1 {h∗(z d+i)=1}
• UnderH (resp.H ),Inf+ (h∗))isthesumofdBernoullivariablesofmean 1−ϵ(resp. 1+ϵ).
0 1 A,1 2 2
• Under H (resp. H ), Inf− (h∗) is the sum of d Bernoulli variables of mean 1−ϵ (resp. 1+ϵ).
0 1 A,0 2 2
• Under H (resp. H ), Inf+ (h∗) is the sum of d Bernoulli variables of mean 1+ϵ (resp. 1−ϵ).
0 1 A,0 2 2
• Under H (resp. H ), Inf− (h∗) is the sum of d Bernoulli variables of mean 1+ϵ (resp. 1−ϵ).
0 1 A,1 2 2
Applying Hoeffding inequality under hypothesis H gives:
0
(cid:104) 1 ϵ(cid:105) (cid:16) dϵ2(cid:17)
P Inf+ (h∗) > − ≤ 2exp − (C.25)
0 A,1 2 2 2
(cid:104) 1 ϵ(cid:105) (cid:16) dϵ2(cid:17)
P Inf− (h∗) > − ≤ 2exp − (C.26)
0 A,0 2 2 2
From C.25 and C.26, we deduce:
(cid:104) (cid:16)1 ϵ(cid:17)2(cid:105) (cid:16) dϵ2(cid:17)
P Inf+ (h∗)Inf− (h∗) ≤ − ≥ 2−4exp − (C.27)
0 A,1 A,0 2 2 2
Similar, the upper bound of the second part is:
(cid:104) (cid:16)1 ϵ(cid:17)2(cid:105) (cid:16) dϵ2(cid:17)
P Inf+ (h∗)Inf− (h∗) ≤ + ≥ 2−4exp − (C.28)
0 A,0 A,1 2 2 18
Combining results C.27 andC.28 yields result C.23. By the symmetry of the hypotheses H and
0
H , we obtain the second result.
1
Lemma 5.
N (cid:34) (cid:18) (cid:12)(cid:12) (cid:19)(cid:35)
D KL(cid:16) P 0||P 1(cid:17) = (cid:88) E D
KL
P 0(y i|(x,y) ∈ H ii −st 1,x i)(cid:12) (cid:12)(cid:12) (cid:12)P 1(y i|(x,y) ∈ H ii −st 1,x i)
(cid:12)(cid:12)
i=138 AJARRA, GHOSH AND BASU
Proof. By definition,
(cid:88) P 0(Q)
D (P ||P ) = P (Q) log
KL 0 1 0
P (Q)
1
Q∈Hist
N
=
(cid:88)
P (Q) log
(cid:81)N i=1P 0(y i|(x,y) ∈ H ii −st 1,x i)P A(x i|(x,y) ∈ H ii −st 1)
0 (cid:81)N P ((y |(x,y) ∈ Hist ,x )P (x |(x,y) ∈ Hist )
Q∈Hist i=1 1 i i−1 i A i i−1
N
Q={(x1,y1),...(xN,yN)}
=
(cid:88)
P (Q)
(cid:88)N
log
P 0(y i|(x,y) ∈ H ii −st 1,x i)
0 P ((y |(x,y) ∈ Hist ,x )
Q∈Hist i=1 1 i i−1 i
N
Q={(x1,y1),...(xN,yN)}
=
(cid:88)N (cid:88)
P (Q) log
P 0(y i|(x,y) ∈ H ii −st 1,x i)
0 P ((y |(x,y) ∈ Hist ,x )
i=1 Q∈Hist 1 i i−1 i
N
Q={(x1,y1),...(xi,yi)}
=
(cid:88)N (cid:88)
P (y |(x,y) ∈ Hist ,x )P ((x,y) ∈ Hist ,x ) log
P 0(y i|(x,y) ∈ H ii −st 1,x i)
0 i i−1 i 0 i−1 i P ((y |(x,y) ∈ Hist ,x )
i=1{(x1,y1),...(xi,yi)} 1 i i−1 i
=
(cid:88)N (cid:88)
P ((x,y) ∈ Hist ,x
)(cid:88)
P (y |(x,y) ∈ Hist ,x ) log
P 0(y i|(x,y) ∈ H ii −st 1,x i)
0 i−1 i 0 i i−1 i P ((y |(x,y) ∈ Hist ,x )
i=1{(x1,y1),...(xi−1,yi−1),xi} yi 1 i i−1 i
N (cid:32) (cid:12)(cid:12) (cid:33)
(cid:88) (cid:88) (cid:12)(cid:12)
= P 0((x,y) ∈ H i−1,x i)D
KL
P 0(y i|(x,y) ∈ H i−1,x i)(cid:12)(cid:12)P 1(y i|(x,y) ∈ H i−1,x i)
(cid:12)(cid:12)
i=1Hi−1,xi
Hence,
N (cid:34) (cid:18) (cid:12)(cid:12) (cid:19)(cid:35)
(cid:16) (cid:17) (cid:88) (cid:12)(cid:12)
D
KL
P 0||P
1
= E D
KL
P 0(y i|(x,y) ∈ H i−1,x i)(cid:12)(cid:12)P 1(y i|(x,y) ∈ H i−1,x i)
(cid:12)(cid:12)
i=1
APPENDIX D: EXTENSIONS TO MULTI-CLASS CLASSIFICATION
If{a ,··· ,a }denotesthesetofcategoriessuchthatforalli ̸= j ∈ {1,··· ,n},X = h−1({a ,a }),
1 n i,j i j
and A the set:
h
(cid:91)(cid:110) (cid:111)
A = h : X → {a ,a },h (X ) = h(X )
h i,j i,j i j i,j i,j i,j
i̸=j
Based on the result in Proposition 5 the Fourier pattern of multicalibration is as follows:
µ (h) = maxP−1(0)
Rob gˆ
g∈A
h
This adaptation is evaluated empirically to assess how well AFA performs in this setting.ACTIVE FOURIER AUDITOR 39
APPENDIX E: EXPERIMENTAL DETAILS
All our computations are performed on an 11th Gen Intel® Core™ i7-1185G7 processor (3.00
GHz, 8 cores) with 32.0 GiB of RAM.
E.1 Uniformly Random Sampling (I.I.D.) estimators (Uniform)
Random estimators use i.i.d. sampling in order to estimate each distributional property. We
note that group fairness estimation requires a different sampling strategy and interaction with the
black-box oracle of h.
Robustness. The true robustness is defined as:
µ (h) = P [h(x) ̸= h(y)]
Rob
x∼D
y∼Nρ(x)
Random estimator samples i.i.d. points from D, which we denote as S. Thus, the estimator can be
written as
(cid:92) 1 (cid:88)
µ (h) = 1
Rob |S| h(x)̸=h(y)
x∈S
y∼Nρ(x)
Individual Fairness. Likewise, individual fairness estimation given by random estimator is:
(cid:92) 1 (cid:88)
µ (h) = 1
IFair |S| h(x)̸=h(y)
x∈S
y∼N (x)
ρ,l
Group Fairness. Let S+ denote a set of samples from the first protected group and S− a set
of samples from the second protected group. Group Fairness (with demographic parity measure) is
defined as:
(cid:92) 1 (cid:88) 1 (cid:88)
µ (h) = 1 − 1
GFair |S+| h(x)=1 |S−| h(x)=1
x∈S+ x∈S−
E.2 Baseline Algorithms
We assess AFA on statistical parity by comparing its performance in sample complexity and
runningtimetothemethodologiesinvestigatedbyYanandZhang(2022).Intheirmethod,auditing
has an additional step: approximating the model through reconstruction before plugging in the
estimator. Those methodologies use active learning algorithms for approximating the black-box
model i.e, CAL algorithm (Cohn et al., 1994), along with its variant for property active estimation
µ-CAL, and its randomized version.
Furthermore, efficient AFA is employed to find significant Fourier coefficients within subsets
containing the protected attribute, this model forces search over within subsets containing the
protected attribute. In other words, AFA focuses on half of the buckets 2n−1 (buckets that contain
the protected attribute), where n is the dimension of the input space.
E.3 Additional Experimental Results
Individual fairness. For individual fairness, the perturbation parameter l is a free parameter
for which Hamming distance measures individual similarity. The parameter l answers the question:
What degree of similarity should the model refrain from distinguishing? Hence,agoodauditorwould40 AJARRA, GHOSH AND BASU
Table 4
Estimation error for individual fairness across models and datasets. Bold numbers mean lower error.
Dataset COMPAS Student
Model LR MLP RF LR MLP RF
Uniform 0.050 0.072 0.070 0.12 0.08 0.173
AFA 0.002 0.035 0.048 0.079 0.057 0.050
have the same performance for all possible parameter values l. To evaluate that, we fix ρ = 0.30 and
compare AFA and random estimator performances for a range of values of parameter l. Experiment
details are summarized in Table 5.
Table 5
A summary of theoretical results: This table summarizes the expression of the estimation for each property with
query complexity and computational complexity. Bold refers to the best method.
l-parameter AFA µ error random µ error
IFair IFair
11 0.123 0.267
10 0.119 0.254
7 0.141 0.244
5 0.169 0.230
3 0.166 0.222
As Figure 4 shows, AFA always outperform random estimator for the property of individual
fairness for all different values of perturbation parameter l.
Statistical parity. We evaluate SP for the Student Performance dataset, with gender as the pro-
tected attribute. Figure 5 shows that AFA’s error converges faster to the zero value compared to
Uniform.
We empirically evaluate the Fourier Pattern for multicalibration by training a logistic regression
model on the DRUG dataset, where gender is considered the protected attribute. Figure 6 shows
the consistency of AFA performance when the black-box model has multiple outcomes.
E´quipe Scool Max Planck Institute for Software Systems
Univ. Lille, Inria Saarbru¨cken, Germany
UMR 9189-CRIStAL, CNRS, Centrale Lille
Lille, France
E´quipe Scool
Univ. Lille, Inria
UMR 9189 - CRIStAL, CNRS, Centrale Lille
Lille, FranceACTIVE FOURIER AUDITOR 41
(a) l=11 (b) l=10
(c) l=7 (d) l=5
(e) l=3
Fig 4: Comparison of AFA and random estimator on COMPAS dataset for different values of
perturbation parameter l.42 AJARRA, GHOSH AND BASU
AFA
Random
101
Statistical Parity
0.150 AFA 100
Uniform
0.125
0.100 10 1
0.075
10 2
0.050
0.025
200 400 600 800 1000
Budget Budgets
Fig 5: Error (left) and running time (right) of auditors in estimating statistical parity of logistic
regression for Student Performance dataset.
100
AFA
Random
Statistical Parity
0.26 AFA
Uniform
0.25
101
0.24
0.23
0.22 102
0.21
200 400 600 800 1000
Budget Budgets
Fig 6: Error (left) and running time (right) of different auditors in estimating statistical parity of
logistic regression for Drugs Consumption dataset.
rorre
egarevA
rorre
egarevA
emit
gninnuR
emit
gninnuR
001
001
002
002
003
003
004
004
005
005
006
006 007
007
008
008
009
009
0001
0001