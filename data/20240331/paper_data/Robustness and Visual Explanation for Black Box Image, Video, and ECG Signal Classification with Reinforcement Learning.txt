Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal
Classification with Reinforcement Learning
Soumyendu Sarkar*†, Ashwin Ramesh Babu†, Sajad Mousavi†, Vineet Gundecha, Avisek Naug,
Sahand Ghorbanpour
Hewlett Packard Enterprise
{soumyendu.sarkar, ashwin.ramesh-babu, sajad.mousavi, vineet.gundecha, avisek.naug, sahand.ghorbanpour}@hpe.com
Abstract sequence of actions to converge on the goal with a long-term
view, which makes them very powerful. Addressing these
We present a generic Reinforcement Learning (RL) frame-
issues, we introduce a Reinforcement Learning agent for
work optimized for crafting adversarial attacks on different
a Platform (RLAB) capable of efficient adversarial attacks.
model types spanning from ECG signal analysis (1D), im-
This agent employs a ”Bring Your Own Filter” (BYOF) ap-
age classification (2D), and video classification (3D). The
framework focuses on identifying sensitive regions and in- proach (figure 1) and utilizes a dual-action mechanism to
ducing misclassifications with minimal distortions and vari- manipulate image distortions, with the aim of high success
ous distortion types. The novel RL method outperforms state- rates with fewer queries. For each application, we evalu-
of-the-art methods for all three applications, proving its ef- ated the performance of the proposed frameworks with var-
ficiency. Our RL approach produces superior localization ious models and data sets to show the reliability of our
masks, enhancing interpretability for image classification and method. We consider three types of metrics to evaluate per-
ECG analysis models. For applications such as ECG analysis,
formance, and our results show that the proposed reinforce-
our platform highlights critical ECG segments for clinicians
ment learning-based attack strategy generates superior re-
while ensuring resilience against prevalent distortions. This
sults in all three applications compared to the state-of-the-art
comprehensive tool aims to bolster both resilience with ad-
approaches. The main contributions of this work are:
versarial training and transparency across varied applications
and data types.
• A common attack framework that spans multiple di-
mensions, from 1D ECG signals to 2D images, and
2+D videos
• Reinforcement Learning-based Adversarial Attack with
multiple custom distortion types to measure the lowest
distortion needed for misclassification as a metric for ro-
bustness and resiliency.
• Visual explanation in the form of localization and heat
map derived from RL attack agent.
• Adversarial training to enhance robustness.
Original Image Distortion Map Adversarial Image
Proposed Method
Figure 1: Mix of distortion filters for Adversarial Attack.
Steps: 176, L2: 4.45. Demo: https://tinyurl.com/24ww544s Problem Formulation
A trained Deep Neural Network (DNN) model under eval-
Introduction
uation can be represented as y = argmaxf (x; θ). Our ap-
Deep learning models, despite their prowess, are vulnera- proach generates perturbation δ such that, y ̸= f (x + δ; θ).
ble to input data corruption, posing challenges in safety- The distance between the original and the adversarial sam-
critical applications like self-driving cars and facial recogni- ple, D(x, x + δ) will be any function of the lp norms. The
tion. Black-box attacks generally work with limited model objective is to fool the classifier while keeping D to a mini-
information but tend to be inefficient, relying heavily on mum.
hand-crafted heuristics (2; 1; 23). There has been sub-
stantial progress in Reinforcement Learning across vari- Robustness Evaluation
ous fields, from complex control systems to training LLMs The input data are divided into fixed size patches of size n
(19; 3; 6; 14; 12; 15; 16; 13; 18; 17; 9; 21; 4). These smart for 1D, n × n for 2d data, t × n × n for 3D data where t
agents can navigate through various environments and take a represents the temporal dimension. For every step, the RL
agent decides to take two actions,
*Corresponding Author
†These authors contributed equally. 1. Patches to which distortions are addedFigure 2: Overview of RL Framework for Robustness and Explainability for signals, images, and video.
2. patches from which distortions are removed scene/signal, which is represented in figure 2 as ”explain-
ability”.
This process is done iteratively until the model misclassi-
fies the data or until the budget for the number of maximum
Results and Discussion
allowed steps is reached. This loop is represented as the ”ro-
bustness evaluation” block in the figure 2. The intuition For all three applications (ECG analysis, Image Classifica-
behind having two actions (addition and removal) is inspired tion, Video Classification), we use three evaluation metrics,
by the application of reinforcement learning for board games average success rate, number of queries, and the l2, linf ,
where the most effective moves or actions can be determined to measure the effectiveness of the attack framework. For
using methods such as Deep Tree Search (DTS) (22). Unlike all applications, we have evaluated more than 1 dataset and
board games, there is a possibility to reset earlier actions that more than three different victim models to assess the effec-
were taken in the past that proved to be less effective, reduc- tiveness of the proposed framework. Results prove that the
ing the computational complexity from O(Nd) to O(N ). RL agent could generate an ”average success rate” of 100
Here, N represents the computational complexity of one percent most of the time with a much smaller query bud-
level of evaluation and corresponds to the size of the data, get when compared to the competitors (8; 10; 11; 16). Fur-
and d represents the depth of the tree search which translates thermore, the proposed framework could maintain the ”av-
to the number of actions taken ahead of time. The generated erage number of queries” lower than the competitors for all
adversarial samples are further used to fine-tune the victim three applications. Also, the effectiveness of localization is
model to improve robustness which is represented in the fig- evaluated with metrics such as dice coefficient and IOU and
ure 2 as ”model refinement to enhance robustness”. compared with the popular gradient and non-gradient-based
approaches (20; 5; 7), with the proposed method showing
Bring Your Own Filter
superiority over the other approaches. Also, retraining the
The RLAB platform is extremely versatile with any type of
model with adversarial samples significantly improved ro-
distortion of choice. The RL algorithm learns a policy to
bustness when evaluated on benchmark datasets (10).
adapt to the filter used such that the adversarial samples are
generated with minimum distortion D. Furthermore, the al-
Conclusion
gorithm can be used with a mixture of filters such that the
The proposed reinforcement learning-based attack frame-
agent first decides which filter to use for every step and fur-
work is effective causing misclassification for many appli-
ther determines the patches to which the distortion should
cations with different data dimensions, showing its ability
be added. We experimented with four naturally occurring
distortions (Gaussian Noise, Gaussian blur, dead pixel, and to generalize for different data dimensions. The approach is
illuminate). capable of using any distortion types that suit the use case to
generate meaningful adversarial samples. Furthermore, the
Explainability visual explanations generated by the RL agents provide in-
sights into the decisions of the AI models. The framework is
The RL agent has been trained to add distortion to the most
currently being evaluated for LLMs.
sensitive region of the data such that the misclassification
can be introduced with a minimum number of steps. This ap-
References
proach has encouraged the agent to add distortion to the re-
gion of the data that corresponds to the predicted class. This [1] Maksym Andriushchenko, Francesco Croce, Nicolas
creates an accurate localization of the objects/peaks in the Flammarion, and Matthias Hein. Square attack: aquery-efficient black-box adversarial attack via ran- Naug. Reinforcement learning based black-box ad-
dom search. In European conference on computer vi- versarial attack for robustness improvement. In 2023
sion, pages 484–501. Springer, 2020. IEEE 19th International Conference on Automation
[2] Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, Science and Engineering (CASE), pages 1–8, 2023.
and Arun Balaji Buduru. A survey of black-box ad- [11] Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad
versarial attacks on computer vision models. arXiv Mousavi, Vineet Gundecha, Sahand Ghorbanpour,
preprint arXiv:1912.01667, 2019. Alexander Shmakov, Ricardo Luna Gutierrez, Anto-
[3] Christian Schroeder de Witt, Tarun Gupta, Denys nio Guillen, and Avisek Naug. Robustness with black-
Makoviichuk, Viktor Makoviychuk, Philip H. S. Torr, box adversarial attack using reinforcement learning. In
Mingfei Sun, and Shimon Whiteson. Is independent AAAI 2023: Proceedings of the Workshop on Artificial
learning all you need in the starcraft multi-agent chal- Intelligence Safety 2023 (SafeAI 2023), volume 3381.
lenge?, 2020. https://ceur-ws.org/Vol-3381/8.pdf, 2023.
[4] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, [12] Soumyendu Sarkar, Vineet Gundecha, Sahand Ghor-
Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex banpour, Alexander Shmakov, Ashwin Ramesh Babu,
Graves, Martin A. Riedmiller, Andreas Kirkeby Fidje- Alexandre Pichard, and Mathieu Cocho. Skip train-
land, Georg Ostrovski, Stig Petersen, Charlie Beattie, ing for multi-agent reinforcement learning controller
Amir Sadik, Ioannis Antonoglou, Helen King, Dhar- for industrial wave energy converters. In 2022 IEEE
shan Kumaran, Daan Wierstra, Shane Legg, and Demis 18th International Conference on Automation Science
Hassabis. Human-level control through deep reinforce- and Engineering (CASE), pages 212–219. IEEE, 2022.
ment learning. Nature, 518:529–533, 2015. [13] Soumyendu Sarkar, Vineet Gundecha, Sahand Ghor-
[5] Harish Guruprasad Ramaswamy et al. Ablation-cam: banpour, Alexander Shmakov, Ashwin Ramesh Babu,
Visual explanations for deep convolutional network Avisek Naug, Alexandre Pichard, and Mathieu Co-
via gradient-free localization. In proceedings of the cho. Function approximation for reinforcement learn-
IEEE/CVF winter conference on applications of com- ing controller for energy from spread waves. In
puter vision, pages 983–991, 2020. Edith Elkind, editor, Proceedings of the Thirty-Second
[6] Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad International Joint Conference on Artificial Intelli-
Mousavi, Zachariah Carmichael, Vineet Gundecha, gence, IJCAI-23, pages 6201–6209. International Joint
Sahand Ghorbanpour, Ricardo Luna Gutierrez, Anto- Conferences on Artificial Intelligence Organization, 8
nio Guillen, and Avisek Naug. Benchmark generation 2023. AI for Good.
framework with customizable distortions for image [14] Soumyendu Sarkar, Vineet Gundecha, Alexander
classifier robustness. In Proceedings of the IEEE/CVF Shmakov, Sahand Ghorbanpour, Ashwin Ramesh
Winter Conference on Applications of Computer Vi- Babu, Paolo Faraboschi, Mathieu Cocho, Alexandre
sion, pages 4418–4427, 2024. Pichard, and Jonathan Fievez. Multi-objective rein-
[7] Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad forcement learning controller for multi-generator in-
Mousavi, Sahand Ghorbanpour, Vineet Gundecha, An- dustrial wave energy converter. In NeurIPs Tackling
tonio Guillen, Ricardo Luna, and Avisek Naug. Rl- Climate Change with Machine Learning Workshop,
cam: Visual explanations for convolutional networks 2021.
using reinforcement learning. In Proceedings of the [15] Soumyendu Sarkar, Vineet Gundecha, Alexander
IEEE/CVF Conference on Computer Vision and Pat- Shmakov, Sahand Ghorbanpour, Ashwin Ramesh
tern Recognition (CVPR) Workshops, pages 3861– Babu, Paolo Faraboschi, Mathieu Cocho, Alexandre
3869, June 2023. Pichard, and Jonathan Fievez. Multi-agent reinforce-
[8] Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad ment learning controller to maximize energy efficiency
Mousavi, Sahand Ghorbanpour, Vineet Gundecha, An- for multi-generator industrial wave energy converter.
tonio Guillen, Ricardo Luna, and Avisek Naug. Ro- In Proceedings of the AAAI Conference on Artificial
bustness with query-efficient adversarial attack us- Intelligence, volume 36, pages 12135–12144, 2022.
ing reinforcement learning. In Proceedings of the [16] Soumyendu Sarkar, Sajad Mousavi, Ashwin Ramesh
IEEE/CVF Conference on Computer Vision and Pat- Babu, Vineet Gundecha, Sahand Ghorbanpour, and
tern Recognition (CVPR) Workshops, pages 2330– Alexander K Shmakov. Measuring robustness
2337, June 2023. with black-box adversarial attack using reinforcement
[9] Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad learning. In NeurIPS ML Safety Workshop, 2022.
Mousavi, Sahand Ghorbanpour, Vineet Gundecha, Ri- [17] Soumyendu Sarkar, Avisek Naug, Antonio Guillen,
cardo Luna Gutierrez, Antonio Guillen, and Avisek Ricardo Luna Gutierrez, Sahand Ghorbanpour, Sa-
Naug. Reinforcement learning based black-box ad- jad Mousavi, Ashwin Ramesh Babu, and Vineet Gun-
versarial attack for robustness improvement. In 2023 decha. Concurrent carbon footprint reduction (c2fr)
IEEE 19th International Conference on Automation reinforcement learning approach for sustainable data
Science and Engineering (CASE), pages 1–8. IEEE, center digital twin. In 2023 IEEE 19th International
2023. Conference on Automation Science and Engineering
[10] Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad (CASE), pages 1–8, 2023.
Mousavi, Sahand Ghorbanpour, Vineet Gundecha, Ri- [18] Soumyendu Sarkar, Avisek Naug, Ricardo
cardo Luna Gutierrez, Antonio Guillen, and AvisekLuna Gutierrez, Antonio Guillen, Vineet Gundecha,
Ashwin Ramesh Babu, and Cullen Bash. Real-time
carbon footprint minimization in sustainable data
centers with reinforcement learning. In NeurIPS 2023
Workshop on Tackling Climate Change with Machine
Learning, 2023.
[19] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec
Radford, and Oleg Klimov. Proximal policy optimiza-
tion algorithms. ArXiv, abs/1707.06347, 2017.
[20] Ramprasaath R Selvaraju, Michael Cogswell, Ab-
hishek Das, Ramakrishna Vedantam, Devi Parikh, and
Dhruv Batra. Grad-cam: Visual explanations from
deep networks via gradient-based localization. In Pro-
ceedings of the IEEE international conference on com-
puter vision, pages 618–626, 2017.
[21] Alexander Shmakov, Avisek Naug, Vineet Gundecha,
Sahand Ghorbanpour, Ricardo Luna Gutierrez, Ash-
win Ramesh Babu, Antonio Guillen, and Soumyendu
Sarkar. Rtdk-bo: High dimensional bayesian optimiza-
tion with reinforced transformer deep kernels. In 2023
IEEE 19th International Conference on Automation
Science and Engineering (CASE), pages 1–8. IEEE,
2023.
[22] David Silver, Aja Huang, Chris J Maddison, Arthur
Guez, Laurent Sifre, George Van Den Driessche, Ju-
lian Schrittwieser, Ioannis Antonoglou, Veda Panneer-
shelvam, Marc Lanctot, et al. Mastering the game of
go with deep neural networks and tree search. nature,
529(7587):484–489, 2016.
[23] Chenxu Wang, Ming Zhang, Jinjing Zhao, and Xiaohui
Kuang. Black-box adversarial attacks on deep neural
networks: A survey. In 2022 4th International Confer-
ence on Data Intelligence and Security (ICDIS), pages
88–93. IEEE, 2022.