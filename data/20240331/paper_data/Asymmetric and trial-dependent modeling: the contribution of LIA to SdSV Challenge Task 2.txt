Asymmetric and trial-dependent modeling:
the contribution of LIA to SdSV Challenge Task 2
Pierre-MichelBousquet,MickaelRouvier
LIA -AvignonUniversity
first.lastname@univ-avignon.fr
Abstract speakerrecognitionbutitalsohasaparticularity,whichisoften
overlookedinthespeakerrecognitionfield: Table1showsthat
The SdSvchallenge Task 2 provided an opportunity toassess
the characteristics of the speech material provided for enroll-
efficiency and robustness of modern text-independent speaker
mentandfortestaredifferentenoughtoassumeamismatchbe-
verification systems. But it also made it possible to test new
tweenthedistributionoftheirvectorrepresentations. Itwould
approaches, capable of taking intoaccount themain issues of
alsobeofbenefittotakeintoaccountsuchamismatch. More-
thischallenge(duration,language,...).Thispaperdescribesthe
over,mixing,inauniqueevaluation,trialswithasmallorlarge
contributionsofourlaboratorytothespeakerrecognitionfield.
enrollment sample and, also, test utterances inPersian or En-
Thesecontributionshighlighttwootherchallengesinaddition
glishcanlimitefficiencyofauniquemodeling. Designingspe-
toshort-duration andlanguage: themismatchbetween enroll-
cificback-endmodelsfordealingwithtrialmismatchcouldbe
ment and test data and the one between subsets of the eval-
ofinterest.Section3explainshowwehitonallthesepoints.
uation trial dataset. The proposed approaches experimentally
showtheirrelevanceandefficiencyontheSdSvevaluation,and
2. Front-end feature extraction
couldbeofinterestinmanyreal-lifeapplications.
2.1. InitialDNNlearning
1. Introduction
The system used in SdSV Challenge is based on x-
TheShort-durationSpeakerVerificationTask2evaluationisa vector/PLDA.Ourx-vectorsystemisbuiltbasedontheKaldi
text-independent speaker recognition evaluation, based on the recipe[10], butwithsomemodifications. Voxceleb2[11]and
recentlyreleasedDeepMinedataset[1,2].Thisdatasetiscom- Librispeech[12]setsarecombinedtogeneratethetrainingset
prisedofvariousdurationutterances(withasignificantpropor- forthex-vectorextractor.
tion of less than 10 seconds) recorded by Persian native per- Thefollowingdataaugmentationmethodsareusedinthis
sons,someoftheminEnglish. Theevaluationproposestotest paper. Apartfromthefouraugmentationmethodsusedin[10],
andimprovespeakerrecognitionmethodsonspeechdatawith we also include audio compression randomly picked between
varyingdegreeofphoneticoverlapbetweentheenrollmentand ogg, mp3 and flaccodec, high-pass filteringrandomly picked
testutterances[3].Robustnessofspeakerembeddingsextracted in[1000Hz;3000Hz]andlow-passfilteringrandomlypickedin
fromdeepneuralnetworks(DNN)toshort-durationutterances [500Hz;1500Hz]. Finally, the training data consist of 8-fold
andefficiencyofthedomainadaptationtechniques(asPersian augmentation that combines clean data with 7 copies of aug-
languageisunknowntotheusualspeechdatabases)canbeseen menteddata.
asthemainobjectivesofthischallenge. ThefairlywideDeep- Duringthetrainingpart theutterancesarefurthercutinto
Minedevelopmentdatasetprovidedforthischallenge,whichis segmentsof2sfortheneuralnetworktraining. 60-dimensional
speaker-labeled, allows to better fit model to data, even if the filter banks (Fbanks) are used for the x-vector system, with
availabilityofsomeEnglishspeechesspokenbyPersiannative anenergy-based VoiceActivityDetector (VAD)toremovesi-
personsislacking. lence. Ashort-timecepstralmeansubtractionisappliedovera
The task of language domain adaptation is usually ad- 3-secondslidingwindow.
dressedduringtheback-endprocedure. Severalmethodshave Table2presentstheExtended-TDNNarchitectureused. In
been proposed, unsupervised [4, 5, 6], or supervised [7, 8, 9] addition to this architecture, we proposed to increase the di-
whenin-domainlabeleddataareavailable.ForSdSv,theavail- mensionofeachlayerto1024onlyfortheframe-level. Except
abilityofarelativelylargesizeandlabeledin-domain dataset thelayer9whichisusedasanexpansionlayerandisfixedto
makes itpossible toalsoconsider language pre-adaptation in- 3000 dimension. Theembeddings are extracted after the first
side the supervised learning of a DNN-based feature extrac- denselayerwithadimensionalityof512. Theneuralnetwork
tor.Section2.2detailsourproposedapproachofDNNPersian- istrainedfor9epochsusingnatural-gradientstochasticgradient
refinement. descentandminibatchsizeof128.
Table1:DataprovidedbySdSvforspeakerverification.
2.2. Front-endlanguageadaptation
enrollment test In order to adapt the x-vector system to a new language, we
use the neural network trained on Voxceleb2 and Librispeech
1to29utterances(averageof7) 1utterance
corpus as pre-trained model. Then, we propose to freeze on
givinganetspeechduration (95%lessthan
pre-trainedmodelallpre-poolingTDNNlayersandre-trainthe
from3to120seconds 5seconds)
otherlayersonDeepMinecorpus(using8-foldaugmentation).
Theneuralnetworkistrainedonlywith1epochandminibatch
Thechallenge focuseson short-durationand cross-lingual sizeof128(weobserveintheleaderboardthatmoreepochsdo
4202
raM
82
]DS.sc[
1v43691.3042:viXraTable2:TopologyoftheExtended-TDNNx-vectorarchitecture. wherewkdenotesthekthofnsexamplesforthespeakers.
Then,amultivariateregressioniscarriedout,whichminimizes
Layer Layertype Context Size theleastsquareerror. DenotingbyY itherow-matrixoftheyi
1 TDNN-ReLU t-2:t+2 1024 theclosed-formexpressionsofAandMare:
2 Dense-ReLU t 1024
3 TDNN-ReLU t-2,t,t+2 1024 A=Y 2tY 1 Y 1tY 1 −1
4 Dense-ReLU t 1024 M=cov(y2(cid:0)−Ay1(cid:1)) (5)
5 TDNN-ReLU t-3,t,t+3 1024
6 Dense-ReLU t 1024 wherecov()isthecovariancematrix. Astraightforwardcom-
7 TDNN-ReLU t-4,t,t+4 1024 putationshowsthattheLLRscorebetweentwovectorsw 1,w
2
8 Dense-ReLU t 1024 oftype1and2canbeexpressedinasimpleform(simplerthan
9 Dense-ReLU t 3000 intheoriginalpaper)as:
10 Pooling(mean+stddev) t 6000
11 Dense(Embedding)-ReLU t 512
1 12
3
DD enen ses -e S-R ofe tL mU
ax
tt Nb51 sp2
ks
s(w 1,w 2)=− 21
(cid:18)
ww 21 −− µµ 21 (cid:19)t M
(cid:18)
ww 21 −− µµ 21
(cid:19)
(6)
uptoaconstant,where
notimproveresults).Theresulting”Persian-refined”DNNbet-
t ie nr itc iao lm trb ai in ne is ngth se er ti ac nh din af do er qm ua at cio yn toof thth ee taw rgid ee tlb au nt go uu at g-o e.f-domain M=
(cid:18)
Φ A1Φ Φt 1 1+
Φt
1Γ 1
AΦ
1ΦΦ
t
1A1Φ
t
+t 1A Γt
2+M
(cid:19)−1
3. Back-end asymmetricmodeling −
(cid:18)
Φ 1Φt
1
0+Γ
1 Φ 2Φt
20
+Γ
2
(cid:19)−1
(7)
3.1. Four-covariancemodel
3.2. Specificscorenormalization
AsexplainedintheintroductionandobservedinTable1,itcan
be assumed that the distributions of the target speaker model Taking benefit of the score normalization to enhance perfor-
andof thetestx-vectoraresufficientlydistincttorequiretwo mancerequiresadaptingtheusual S-normalizationtothespe-
PLDAmodelings. Introducedin[13]formismatchofduration cific case of an asymmetric model: the impostor cohorts are
betweenenrollmentandtestdata,thefour-covariancemodel(4- dependentonthetypeofdataandtheorderofpairwisevectors
cov)isanasymmetricmodeling,whichallowstocomputetwo toscoremustberespected. Givenatrialbetweenenrollment-
distinct PLDA models, here one for enrollment data and the basedandtestvectorsw e andw t,score-normalizationisper-
other for test data, then to fit a probabilistic relation between formedonscores(w e,w t)suchthat:
theminordertocomputeaLLR-score,despitethemismatch.
lengF tho -r nS ord mSv alc izh ea dlle an veg re a, gw ee oc fh to ho es ee na ros lt la mrg ee nt ts sp ae ma pk le er ,m sio nd ce el tt hh ie
s s(w e,w t)=
21s(w e,w σ(t) s− (wµ e,( Ωs( tw ))e,Ω t))
approachhasprovedtobeefficientandrobust[14]. Letdenote
byw 1 avectoroftype1(hereofthelattertype,computedon b + 1s(w e,w t)−µ(s(Ω e,w t)) (8)
anenrollmentsampleasdescribedincolumn1ofTable1)and 2 σ(s(Ω e,w t))
similarlyw 2oftype2(hereatestvectorasdescribedincolumn whereΩ e,Ω t arecohortimpostors,specifictoenrollmentand
2ofTable1).TheGaussianPLDAmodel[15]fortypei,i=1
test, and µ,σ are the mean and standard deviation functions,
or2,assumesthat:
possiblycomputedonthetopscoresonly.
w i =µi+Φ iyi+εi
3.3. Trial-dependentmodels
yi ∼N(0,I)
εi ∼N(0,Γ i) (1)
Table3:Percentagesoftrialsintheevaluationtrialset,depend-
where N denotes the normal pdf, I is the identity matrix, µi ingonthetargetspeakermodel(howmanyenrollmentsegments
aglobal offset andthelatentvariableyi isonly dependent on areavailable?)andonthetestlanguage.
thespeakerandstatisticallyindependentoftheresidualtermεi.
The4-covmodelingassumesalinearrelationbetweenthetwo
testlanguage
PLDAmodelsbytheirspeakerfactors:
enrollment#segs Persian English Total
<5 36% 38% 74%
y2 =Ay1+η (2) >5 4% 22% 26%
40% 60%
η∼N(0,M) (3)
Toestimate the matricial parameters A and M, the point
Table3detailstheproportionoftrialsintheevaluationset,
estimate of training speaker factors yi is computed using the
dependingonthesizeofthespeakerenrollmentsampleandon
expectationgivenbythePLDAE.M.algorithm:
thelanguageoftest.The4-covmodelallowstofitPLDAmod-
els to each of these enrollment-test cases. Table 4 shows the
ns different training sets used for PLDA, depending on the trial.
yi= nsΦt iΓ− i 1Φ i+I −1Φt iΓ− i 1 (wk−µi) (4) We apply the 4-cov model to each type of mismatch: (aver-
(cid:0) (cid:1) Xk=1 ageofsampleofvarioussizeandduration)/(oneshortdurationutteranceinPersianorEnglish). Thelanguageofthetestseg- Table5: ResultsofthedifferentcontributionstotheSdSveval-
mentsisestimatedbyaspeechdetector. Fortestutterancesin uation.
English,PLDAisinterpolatedasproposedin[7],usingourEn-
glish training database. Let us note that the x-vectors of this EER% minDCF
databaseareextractedfromourPersian-refinedneuralnetwork, Initial 7.38 0.3682
hencepartiallyadaptedtoPersianlanguage. WithDeepMinedev.set 4.41 0.2103
Forabetter understanding, wedetailone caseofTable4. +out-of-domainadaptedset 4.42 0.1823
The last row corresponds totrialswithmore than 5 examples 4cov-model 3.28 0.1554
forenrollmentandatestutteranceinEnglish: +specificS-norm 3.15 0.1427
+trial-dependentmodels 2.88 0.1261
• thePLDA training dataset for model 1 of 4-cov model
(theoneforenrollment)ismadeupoflength-normalized
averagesof12vectorslastingmorethan7.5seconds,ex-
tracted from utterances of the DeepMine development alltheback-endtransformations(centering,whitening,length-
set[1]). normalizationandPLDA)insteadoftheinitialdatabase.Letus
notethat,hence,noadaptationofout-of-domaindatatoPersian
• thePLDAtrainingdatasetsformodel2of4-covmodel
languageiscarriedoutduringtheback-endprocesstoenhance
(theonefortest)arecomprisedofutteranceslastingless
modeling. The third system additionally leverages an out-of-
than 5 seconds, from (i) the same DeepMine develop-
domain development set for back-end trainings. This dataset
mentset,(ii)ouradaptedEnglishdevelopmentset. The
isextractedfromtheoneusedforthefirstlearningstepofthe
resulting model for test interpolates the last two sub-
DNNextractorandadaptedbyusingfDA[5],anunsupervised
models(i)and(ii)[7].
domainadaptationmethod,similartoCORAL[4],whichtakes
Asthefinalscorefiletosubmitmixesfourscoringformu- intoaccounttheresidualcomponents.Theresultingadaptedset
las,thescoresarecalibratedbyusingdevelopmenttrialdatasets, thenallowsinterpolationbetweenout-of-domainandin-domain
specifictothefourcasesofTable4andallbasedonDeepMine PLDA models [7]. As expected, systems employing the in-
developmentdata. domaindevelopment setduring front-endandback-end learn-
ing outperform the initial submission. It is worth noting that
Table4:Datasetsfortrial-dependentmodeltraining.L-average including the adapted out-of-domain development set intothe
meansthelength-normalizedaverageoftheenrollmentsample. PLDAmodelings (row3) significantlyincreases performance,
butonlyintermsofminimalDCF.
Thefourthsystemappliesthefour-covariance model. Let
trial: 4-covariancemodel
usnotethatthissystemdoesnotusetheadaptedout-of-domain
enrollment test model1 model2
dataset during the back-end trainings. For the enrollment
#segs language forenrollment fortest
model, the training speaker models are the length-normalized
3vectors
averages of 15 examples (3 original segments + 12 data aug-
<5 Persian L-average <5sec.
mented)and,forthetestmodel,onlytrainingsegmentsofless
<5sec.
than5secondsareselected. Thegainofperformanceinvolved
3vectors <5sec.
bythismethodissignificant,bothintermsofEERandminDCF,
<5 English L-average &
evenwithoutthehelpofthewideout-of-domain development
<5sec. English-dev
set.
12vectors
Thefollowingsystemaddstothelatterthespecificscore-
>5 Persian L-average <5sec.
normalizationproposedinsection3.2,with400top-scores.The
>7.5sec.
resultinggainof performance showsthat thenormalization of
12vectors <5sec.
scoreiscompatiblewithanasymmetricmodel.
>5 English L-average &
Thelastsystemappliesthetrial-dependent4-covmodeling
>7.5sec. English-dev
describedinsection3.3andTable4. Thegainofperformance
confirmstheheterogeneitybetweenthetrialpartitionslistedin
Table4andtheabilityofthe4-covmodeltohandlesuchtype
4. Experiments andresults ofmismatch.
Relevance and efficiency of our various contributions are
For acoustic features MFCC are extracted by using Kaldi clearly demonstrated. The final system takes full account of
toolkit[16]with23cepstralcoefficientsandlog-energy,acep- the challenges of SdsV Task 2: short-duration utterances and
stralmeannormalizationbeingappliedwithawindowsizeof adaptation tonew language, reported intermsofperformance
3seconds. Voice ActivityDetection removes silence and low inthefirstrowsofTable5,thenmismatchbetweenenrollment
energy speech segments. The simple energy-based VAD uses andtestdistributionsortrialpartitions,reportedinthelastrows.
theC0componentoftheacousticfeature.
Table 5 provides results of our contributions, in terms of 5. Conclusions
EERandminDCF,asreportedintheSdSvTask2leaderboard.
The first system (initial) trains the DNN and all the back-end The SdSv challenge made it possible to test and compare the
transformationsbyusingonlytheout-of-domaindatabase,de- efficiency of DNN based systems to deal with short-duration
scribed in section 2.1. The second system benefits from the utterances. Data augmentation could also contribute to better
DeepMinein-domaindevelopmentsetprovidedbytheSdSvor- fitthesedata, whichareknowntobeveryvaried. Thetaskof
ganizers. ItisusedtorefinetheDNNlearningbyusingthead- language adaptation was usually tackled during the back-end
ditionaltrainingstagedescribedinsection2.2,thenforlearning process.FortheSdSvchallenge,theavailabilityofasizablein-domainlabeleddatasetallowedtoextendthistasktotheDNN [12] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Lib-
supervisedlearningstage. rispeech: AnASRcorpusbasedonpublicdomainaudiobooks,”
Our contribution highlights the concern of mismatch be- in2015IEEEInternationalConferenceonAcoustics,Speechand
SignalProcessing(ICASSP),2015,pp.5206–5210.
tweenenrollmentandtestspeechmaterial,intermsofquantity
ofinformation. Theproposedfour-covariancemodelappliesa [13] P.-M. Bousquet and M. Rouvier, “Duration mismatch
specificasymmetricmodeling,whichfocusesonatypeofmis- compensation using four-covariance model and deep neu-
ral network for speaker verification,” in Proc. Inter-
match. Itrevealsthebenefitofrefiningtheback-endmodeling
speech 2017, 2017, pp. 1547–1551. [Online]. Available:
totakeintoaccountthisissue. Moreover,thismodelallowsfor
http://dx.doi.org/10.21437/Interspeech.2017-93
better fitofspecificities, heretherelativeheterogeneity ofthe
[14] P.Rajan,A.Afanasyev,V.Hautama¨ki,andT.Kinnunen,“From
evaluationtrials.
singletomultipleenrollment i-vectors: Practical PLDAscoring
ThelastsystemofTable5wasourfinalsubmissionforthis
variantsforspeakerverification,”Digit.SignalProcess.,vol.31,
challenge.Thegoodrankingobtainedwithasystemusingasin- pp.93–101,2014.
glefront-endfeatureextractorshowsthatasystemincludingall
[15] S.J.PrinceandJ.H.Elder,“Probabilisticlineardiscriminantanal-
thesecontributionsisabletocompetewithfusionsofsystems
ysisforinferencesaboutidentity,”inInternationalConferenceon
basedondistinctDNNarchitecturesandconfigurations. ComputerVision. IEEE,2007,pp.1–8.
[16] D. Povey, A. Ghoshal, G. Boulianne, L. Burget, O. Glembek,
6. Acknowledgements N. Goel, M. Hannemann, P. Motlicek, Y. Qian, P. Schwarz,
J.Silovsky,G.Stemmer,andK.Vesely,“Thekaldispeechrecog-
ThisresearchwassupportedbytheANRagency(AgenceNa- nitiontoolkit,”inIEEEWorkshoponAutomaticSpeechRecogni-
tionale de la Recherche), on the RoboVox project (ANR-18- tion&Understanding. IEEESignalProcessing Society, Dec.
CE33-0014). 2011,iEEECatalogNo.:CFP11SRW-USB.
7. References
[1] H.Zeinali,H.Sameti,andT.Stafylakis,“DeepMinespeechpro-
cessingdatabase:Text-dependentandindependentspeakerverifi-
cationandspeechrecognitioninPersianandEnglish.”inSpeaker
andLanguageRecognitionWorkshop(IEEEOdyssey),2018,pp.
386–392.
[2] H. Zeinali, L. Burget, and J. Cernocky, “A multi purpose and
largescalespeechcorpusinPersianandEnglishforspeakerand
speechrecognition:theDeepMinedatabase,”inProc.ASRU2019
The2019IEEEAutomaticSpeechRecognitionandUnderstand-
ingWorkshop,2019.
[3] K.A.Zeinali,HosseinnadLee,J.Alam,andL.Burget,“Short-
duration speaker verification (SdSV) challenge 2020: the chal-
lenge evaluation plan.” arXiv preprint arXiv:1912.06311, Tech.
Rep.,2020.
[4] J. Alam, G. Bhattacharya, and P. Kenny, “Speaker verification
in mismatched conditions with frustratingly easy domain adap-
tation,” inSpeaker andLanguage Recognition Workshop(IEEE
Odyssey),2018.
[5] P.-M. Bousquet and M. Rouvier, “On Robustness of Unsuper-
vised Domain Adaptation for Speaker Recognition,” in Proc.
Interspeech 2019, 2019, pp. 2958–2962. [Online]. Available:
http://dx.doi.org/10.21437/Interspeech.2019-1524
[6] K. A. Lee, Q. Wang, and T. Koshinaka, “The CORAL+
algorithm for unsupervised domain adaptation of PLDA,”
CoRR, vol. abs/1812.10260, 2018. [Online]. Available:
http://arxiv.org/abs/1812.10260
[7] D. Garcia-Romero and A. McCree, “Supervised domain adap-
tation fori-vector basedspeaker recognition,” inIEEEInterna-
tionalConferenceonAcoustics, Speech, andSignalProcessing,
ICASSP,2014,pp.4047–4051.
[8] H.Aronowitz,“Interdatasetvariabilitycompensationforspeaker
recognition,” 2014IEEEInternationalConferenceonAcoustics,
SpeechandSignalProcessing(ICASSP),pp.4002–4006,2014.
[9] J.A.V.Lo´pezandE.Lleida,“BayesianadaptationofPLDAbased
speakerrecognitiontodomainswithscarcedevelopmentdata,”in
Speaker and Language Recognition Workshop (IEEE Odyssey),
2012.
[10] D.Snyder,D.Garcia-Romero,G.Sell,D.Povey,andS.Khudan-
pur,“X-vectors:Robustdnnembeddingsforspeakerrecognition,”
in2018IEEEInternationalConferenceonAcoustics,Speechand
SignalProcessing(ICASSP). IEEE,2018,pp.5329–5333.
[11] J.S.Chung, A.Nagrani, andA.Zisserman,“VoxCeleb2: Deep
speakerrecognition,”inProc.Interspeech2018,2018,pp.1086–
1090.