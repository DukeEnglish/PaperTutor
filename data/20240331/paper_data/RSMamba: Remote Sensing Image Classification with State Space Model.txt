1
RSMamba: Remote Sensing Image Classification
with State Space Model
Keyan Chen1, Bowen Chen1, Chenyang Liu1, Wenyuan Li2, Zhengxia Zou1, Zhenwei Shi1,⋆
Beihang University1, The University of Hong Kong2
Abstract—Remotesensingimageclassificationformsthefoun- data and output classification probabilities in an end-to-end
dationofvariousunderstandingtasks,servingacrucialfunction manner. In terms of network architecture, it can primarily be
inremotesensingimageinterpretation.Therecentadvancements
categorizedintoCNNsandattentionnetworks.Theformerab-
of Convolutional Neural Networks (CNNs) and Transformers
stracts image features layer by layer through two-dimensional
have markedly enhanced classification accuracy. Nonetheless,
remotesensingsceneclassificationremainsasignificantchallenge, convolution operations, as demonstrated by ResNet [6]. The
especially given the complexity and diversity of remote sensing lattercaptureslong-distancedependenciesbetweenlocalareas
scenarios and the variability of spatiotemporal resolutions. The of the entire image through the attention mechanism, thereby
capacityforwhole-imageunderstandingcanprovidemoreprecise
achieving a more robust semantic response, represented by
semantic cues for scene discrimination. In this paper, we intro-
ViT [7], SwinTransformer [8], etc. Substantial progress has
duce RSMamba, a novel architecture for remote sensing image
classification.RSMambaisbasedontheStateSpaceModel(SSM) also been made in remote sensing image classification. For
and incorporates an efficient, hardware-aware design known instance, ET-GSNet [9] distills the rich semantic prior of ViT
as the Mamba. It integrates the advantages of both a global into ResNet18, fully capitalizing on the strengths of both.
receptive field and linear modeling complexity. To overcome
P2Net [10] introduces an asynchronous contrastive learning
the limitation of the vanilla Mamba, which can only model
method to address the issue of small inter-class differences in
causal sequences and is not adaptable to two-dimensional image
data, we propose a dynamic multi-path activation mechanism to fine-grained classification.
augment Mamba’s capacity to model non-causal data. Notably, To a certain extent, the classification accuracy heavily
RSMamba maintains the inherent modeling mechanism of the dependsonthemodel’sabilitytoeffectivelyhandletheimpact
vanillaMamba,yetexhibitssuperiorperformanceacrossmultiple
of complex and diverse remote sensing scenarios and variable
remote sensing image classification datasets. This indicates that
spatio-temporal resolution. Transformer [11], based on the
RSMambaholdssignificantpotentialtofunctionasthebackbone
offuturevisualfoundationmodels.Thecodewillbeavailableat attention mechanism and capable of obtaining responses from
https://github.com/KyanChen/RSMamba. valuable areas across the entire image, presents an optimal
solutiontothesechallenges.However,itsattentioncalculation,
Index Terms—Remote sensing images, image classification,
foundation model, backbone network, Mamba characterized by square complexity, poses significant chal-
lenges in terms of modeling efficiency and memory usage as
the input sequence length increases or the network deepens.
I. INTRODUCTION
TheStateSpaceModel(SSM)[12]canestablishlong-distance
THe advancement of remote sensing technology has sig- dependency relationships through state transitions and exe-
nificantly heightened interest in high-resolution earth cute these transitions via convolutional calculations, thereby
observation. Remote sensing image classification, serving as achieving near-linear complexity. Mamba [13] proves highly
thebedrockofremotesensingimageintelligentinterpretation, efficient for both training and inference by incorporating
is a crucial element for subsequent downstream tasks. It plays time-varying parameters into the plain SSM and conducting
a pivotal role in applications such as land mapping, land use, hardwareoptimization.Vim[14]andVMamba[15]havesuc-
and urban planning. Nonetheless, the complexity and diver- cessfully introduced Mamba into the two-dimensional visual
sity of remote sensing scenarios, coupled with the variable domain,achievingacommendablebalanceofperformanceand
spatio-temporal resolution, present substantial challenges to efficiency across multiple tasks.
automated remote sensing image classification [1–4]. In this paper, we introduce RSMamba, an efficient state
Researchers have been diligently working towards alleviat- spacemodelforremotesensingimageclassification.Owingto
ing these challenges and enhancing the models’ applicability itsrobustcapabilityinmodelingglobalrelationshipswithinan
acrossdiverseapplicationscenarios.Earlymethodologiespre- entire image, RSMamba can also exhibit potential versatility
dominantly focused on feature construction, extraction, and across a broad spectrum of other tasks. RSMamba is based
selection, investigating feature engineering machine learning on the previous Mamba [13], but has introduced a dynamic
methods represented by SIFT, LBP, color histograms, GIST, multi-path activation mechanism to alleviate the limitations
BoVW[5],etc.Inrecentyears,theadventofdeeplearninghas of the plain Mamba, which can only model in a single
revolutionizedtheconventionalparadigmthatheavilyreliedon direction and is position-agnostic. Significantly, RSMamba
specialized human prior knowledge. Deep learning possesses is designed to preserve the inherent modeling mechanism
the capability to autonomously mine effective features from of the original Mamba block, while introducing non-causal
4202
raM
82
]VC.sc[
1v45691.3042:viXra2
ProjectionLayer Pooling&Projection Multi-PathSSMBlock ×N
σ SiLUFunction …
SharedWeightsMambaMixer 1 2 3 L
ActivateGate Multi-Path
ForwardPath
SSMEncoder SharedWeightsMambaMixer
…
PE + L L-1 L-2 1 Conv1D σ BS lS oM ck
ReversePath
LinearProjection …
5 L 1 7 Norm σ × + ∑
Overlap 1 2 … L ShufflePath
Patching
Fig.1. AnoverviewoftheproposedRSMamba.
and position-positive improvements external to the block. This process can be formulated through the subsequent linear
Specifically, the remote sensing image is partitioned into ordinary differential equation (ODE),
overlappingpatchtokens,towhichpositionencodingisadded
h′(t)=Ah(t)+Bx(t)
to form a sequence. We construct three path copies, namely (1)
forward, reverse, and random. These sequences are modeled
y(t)=Ch(t)
to incorporate global relationships through the Mamba block wherey ∈RN isderivedfromtheinputsignalx∈RN andthe
using shared parameters, and subsequently activated through hidden state h∈RN. A∈RN×N denotes the state transition
linear mapping across different paths. Given the efficiency of matrix. B∈RN and C∈RN are the projection matrices. To
the Mamba block, large-scale pre-training of RSMamba can
realizethecontinuoussystemdepictedinEq.1inadiscretized
be achieved cost-effectively.
form and integrate it into deep learning methods. A and B are
The primary contributions of this paper can be summarized discretized using a zero-order hold (ZOH) with a time scale
as follows: parameter ∆. The process is shown as follows,
i) We propose RSMamba, an efficient global feature mod- A¯ =exp(∆A)
eling methodology for remote sensing images based on the (2)
B¯ =(∆A)−1(exp(∆A)−I)·∆B
State Space Model (SSM). This method offers substantial
advantagesintermsofrepresentationalcapacityandefficiency After discretization, Eq. 1 can be rewritten as,
and is expected to serve as a feasible solution for handling
h =A¯h +B¯x
large-scale remote sensing image interpretation. k k−1 k
(3)
ii)Specifically,weincorporateaposition-sensitivedynamic y k =C¯h k
multi-path activation mechanism to address the limitation of
where C¯ represents C. At last, the output can be calculated in
the original Mamba, which was restricted to modeling causal
a convolution representation, as follows,
sequences and was insensitive to the spatial position.
iii) We conducted comprehensive experiments on three K¯ =(C¯B¯,C¯A¯B¯,··· ,C¯A¯L−1 B¯)
distinct remote sensing image classification datasets. The y=x∗K¯ (4)
results indicate that RSMamba holds significant advantages
overclassificationmethodsbasedonCNNsandTransformers. where L is the length of the input sequence, and K¯ ∈ RL
denotes the structured convolutional kernel.
II. METHODOLOGY
B. RSMamba
Leveraging the inherent characteristics of the SSM model,
RSMamba is proficient in effectively capturing the global RSMamba transforms 2-D images into 1-D sequences and
dependencies within remote sensing images, thereby yielding captureslong-distancedependenciesusingtheMulti-PathSSM
a wealth of semantic category information. This section will Encoder,asdepictedinFig.1.GivenanimageI ∈RH×W×3,
begin with an introduction to the preliminaries of SSM, we employ a 2-D convolution with a kernel of k and a stride
followed by an overview of RSMamba. Subsequently, we of s to map local patches into pixel-wise feature embeddings.
will explore the dynamic multi-path activation block in depth. Subsequently,thefeaturemapisflattenedintoa1-Dsequence.
Finally, we will elaborate on the network structure for three Topreservetherelativespatialpositionrelationshipwithinthe
distinct versions of RSMamba. image,weincorporatepositionencodingP.Theentireprocess
is as follows,
T =Φ (Φ (I,k,s))
A. Preliminaries Flatten Conv2D
(5)
T =T +P
The State Space Model (SSM) is a concept derived from
modern control theory’s linear time-invariant system which where Φ represents the 2-D convolution, while Φ
Conv2D Flatten
mapsthecontinuousstimulationx∈RN toresponsey ∈RN. signifies flattening operation. T ∈ RL×d and P ∈ RL×d
ecneuqeStupnI
etacilpuD
。式公⼊键处此在
egnarraeR
egnarraeR3
(cid:80)
correspondtotheinput1-Dsequenceandpositionalencoding, Softmaxoperation. gathersfeaturesfromthethreedifferent
respectively. information flows.
In RSMamba, we have not utilized the [CLS] token to
aggregatetheglobalrepresentation,asisdoneinViT.Instead, D. Model Architecture
thesequenceisfedintomultipledynamicmulti-pathactivation
The Mamba mixer Φθ represents the standard mixer
Mamba blocks for long-distance dependency modeling. Sub- mixer
block within the Mamba [13] framework. Drawing upon the
sequently,thedensefeaturesnecessaryforcategoryprediction
principles of ViT, we have developed three distinct versions
are derived through a mean pooling operation applied to
ofRSMambacharacterizedbydifferentparametersizes:base,
the sequence. This procedure can be iteratively delineated as
large, and huge. The specific hyperparameters for each ver-
follows,
Ti =Φi (Ti−1)+Ti−1 sion are detailed in Tab. I. Details about the hyperparameter
mp-ssm (6) meaning can be found in [13].
sˆ=Φ (Φ (Φ (TN)))
proj LN mean
where i signifies the ith layer, while Ti represents the output TABLEI
sequence of the ith-layer, with T0 = T ∈ RL×d. Φ THEHYPERPARAMETERSETTINGSFORDIFFERENTRSMAMBAVERSIONS.
mp-ssm N:NUMBEROFBLOCKS,HS:HIDDENSIZE,IS:INTERMEDIATESIZE,
denotes the dynamic multi-pathactivation Mamba block, with TSR:TIMESTEPRANK,SSMSS:SSMSTATESIZE.
atotalnumberofN.Φ symbolizesmeanpoolingoperation
mean
with the sequence dimension and Φ is layer normalization. Version N HS IS TSR SSMSS
LN
Φ is used to project the latent dimension d to the number
proj Base 24 192 384 12 16
of classes.
Large 36 256 512 16 16
Huge 48 320 640 20 16
C. Dynamic Multi-path Activation
The vanilla Mamba is employed for the causal modeling of
1-D sequences. It encounters difficulties in modeling spatial III. EXPERIMENTALRESULTSANDANALYSES
positional relationships and unidirectional paths, thereby lim- A. Dataset Description
itingtheapplicabilitytovisualdatarepresentation.Toaugment
To evaluate the efficacy of the proposed method, we under-
its capacity for 2-D data, we introduce a dynamic multi-
took extensive experiments on three distinct remote datasets:
path activation mechanism. Importantly, this mechanism, to
UC Merced Land-Use Dataset (UC Merced) [2], AID [1],
preservethestructureofthevanillaMambablock,exclusively
andNWPU-RESISC45Dataset(RESISC45)[3].Eachencom-
operates on the block’s input and output. Specifically, we
passesauniqueassortmentofcategoriesandimagequantities.
duplicate three copies of the input sequence to establish three
UCMerced[2]:TheUCMercediscomposedof21distinct
different paths, namely the forward path, reverse path, and
scene categories, with each category containing 100 aerial
random shuffle path, and leverage a plain Mamba mixer
images of 256 × 256 pixel resolution. The images possess
with shared parameters to model the dependency relation-
a spatial resolution of 0.3m, culminating in a total of 2100
shipsamongtokenswithinthesethreesequences,respectively.
images.Werandomlyextracted70imagesfromeachcategory
Subsequently, we revert all tokens in the sequences to the
for training.
correct order and employ a linear layer to condense sequence
AID [1]: The AID incorporates 30 categories and an ag-
information, thereby establishing the gate of the three paths.
gregate of 10,000 images sourced from Google Earth. The
Thisgateisthenusedtoactivatetherepresentationofthethree
sample quantity varies across different scene types, ranging
differentinformationflowsasshowninFig.1.Theprocessof
from 220 to 420. Each aerial image measures 600 × 600
the ith block is delineated as follows,
pixels, with spatial resolutions spanning from 8m to 0.5m,
Ti =Φk (Ti) thereby encapsulating a multitude of resolution scenarios. We
k pather
Tˆi =Φθ (Ei) designated 50% of the images from each category as training
k mixer k data.
Tˆ ki =Φk revert-pather(Eˆ ki)
(7) RESISC45 [3]: The RESISC45 comprises 31,500 remote
g =Φ (Φ (Φ (Φ ({Eˆi})))) sensing images obtained from Google Earth, segregated into
softmax gate-proj mean cat k
Ti+1
=(cid:88)2
g ·Tˆi
45 scene categories. Each category contains 700 RGB im-
k k ages with 256×256 pixel resolution. The spatial resolution
k=0
fluctuates between approximately 30m to 0.2m per pixel. We
where Ti represents the input sequence for the ith layer.
allocated 70% of the images from each category for training
Φk ,k ∈{0,1,2} denotes the kth sequence path, including
pather purposes.
theforwardpath,reversepath,andrandomshufflepath.Φθ
mixer
is the vanilla Mamba mixer with parameter θ. Φk
revert-pather
B. Implementation Details
denotes the operation to revert all tokens to the forward
order. Φ signifies sequence concatenation with the feature In our paper, we employ a fixed input image size of
cat
dimension. Φ denotes mean pooling along the sequence 224×224 and implement data augmentation techniques in-
mean
length dimension. Φ linearly projects the 3d dimension cluding random cropping, flipping, photometric distortion,
gate-proj
to 3 for sequence information activation. Φ denotes mixup, cutMix, etc. Images are processed into sequential data
softmax4
TABLEII
COMPARISONSWITHOTHERMETHODSACROSSDIFFERENTTESTSETS.
Params UC Merced AID RESISC45
Method
(M) P R F1 P R F1 P R F1
ResNet-18 [6] 11.2 87.98 87.46 87.40 88.70 88.17 88.30 88.73 88.44 88.45
ResNet-50 [6] 23.6 91.99 91.74 91.65 89.44 88.66 88.87 92.67 92.47 92.47
ResNet-101 [6] 42.6 92.40 92.22 92.12 91.03 90.63 90.81 92.75 92.57 92.56
DeiT-T [16] 5.5 86.92 86.66 86.53 85.23 84.52 84.52 87.66 86.78 86.79
DeiT-S [16] 21.7 88.95 88.41 88.41 85.88 85.19 85.34 88.21 87.47 87.43
DeiT-B [16] 85.8 89.14 88.73 88.70 87.32 86.07 86.07 89.04 88.62 88.65
ViT-B [7] 88.3 91.09 90.79 90.77 89.39 88.65 88.86 88.84 88.65 88.62
ViT-L [7] 303.0 91.98 91.32 91.26 90.19 88.86 89.17 91.22 91.08 91.04
Swin-T [8] 27.5 90.87 90.63 90.40 86.49 85.66 85.77 90.15 90.06 90.06
Swin-S [8] 48.9 91.08 90.95 90.82 87.50 86.80 86.89 92.05 91.88 91.84
Swin-B [8] 86.8 91.85 91.74 91.62 89.84 89.01 89.07 93.63 91.58 93.56
Vim-Ti† [14] 7.0 89.06 88.73 88.68 87.76 86.98 87.13 89.24 89.02 88.97
VMamba-T [15] 30.0 93.14 92.85 92.81 91.59 90.94 91.10 93.97 93.96 93.94
RSMamba-B (Ours) 6.4 94.14 93.97 93.88 92.02 91.53 91.66 94.87 94.87 94.84
RSMamba-L (Ours) 16.2 95.03 94.76 94.74 92.31 91.75 91.90 95.03 95.05 95.02
RSMamba-H (Ours) 33.1 95.47 95.23 95.25 92.97 92.51 92.63 95.22 95.19 95.18
through a two-dimensional convolution with a kernel size of of Transformer architectures hinges on the induction and bias
16 (k =16) and a stride of 8 (s=8). Position encodings are ofgeneralfeaturesacrosslarge-scaletrainingdata.Incontrast,
represented by randomly initialized learnable parameters. For RSMamba’s performance does not rely on extensive data
supervisedtraining,weemploythecross-entropylossfunction accumulation, but a longer training duration can further lead
and utilize the AdamW optimizer with an initial learning rate to substantial performance gains.
of 5e − 4 and a weight decay of 0.05. The learning rate
is decayed using a cosine annealing scheduler with a linear D. Ablation Study
warmup. The batch size for training is set at 1024, and the To verify the effectiveness of each component, ablation
training process spans a total of 500 epochs. We employ experiments were conducted on the AID dataset. Unless ex-
Precision (P), Recall (R), and F1-score (F1) as performance plicitlystated,thebaseversionofthemodelwasutilized,with
metrics. no modifications made to the associated hyperparameters.
1) Effect of Class Tokens: To obtain dense semantic fea-
tures for classification, we leveraged mean pooling in RS-
C. Comparison with the State-of-the-Art
Mambatoamalgamateglobalinformation,asopposedtousing
We compare our proposed RSMamba with other prevalent class tokens akin to ViT [7]. Tab. III delineates the effect
deep learning methods for image classification, including the of incorporating class tokens at varying positions and mean
ResNet [6] series underpinned by CNN architecture, and the pooling on the classification performance. The experimental
DeiT [16], ViT [7], and Swin Transformer [8] series, all of findings indicate that the insertion of class tokens at the head,
which are grounded in Transformer architecture. The com- tail, or both does not yield superior performance. However,
parative classification performance of these methods across insertion in the middle of the sequence can result in a sub-
the UC Merced, AID, and RESISC45 datasets is presented stantialenhancementinperformance.Moreover,meanpooling
in Tab. II. The experimental results reveal that: i) RSMamba on the sequence can exhibit optimal performance. These
exhibits robust performance across datasets of varying sizes, observations suggest that the direction of information flow in
with its efficacy being minimally impacted by the volume of Mamba significantly influences performance. Concurrently, it
training data. This could be attributed to its relatively fewer was observed during the experiment that mean pooling can
parameters, negating the need for extensive data for inductive expedite the network’s convergence.
bias. ii) An increase in the depth and width of RSMamba 2) Effect of Multiple Scanning Paths: The vanilla Mamba,
contributes to a performance enhancement across the three derived from modeling causal sequences, poses a significant
datasets.However,therateofimprovementislesspronounced challenge applying to two-dimensional image data devoid
comparedtotheResNetandTransformerseries.Thiscouldbe of causal relationships. To address this issue, we propose
because the base version of RSMamba has already achieved a the multiple scanning path mechanism, i.e., forward, reverse,
high degree of accuracy relative to other methods, suggesting and random shuffling. To fuse the information flow from
that the base version could be a viable starting point for other these diverse paths, the most straightforward method would
applicationtasks. iii) Ourexperiments alsoindicate thatwhile be averaging. However, our objective is to adaptively acti-
CNN architectures converge readily, the superior performance vate the information derived from each path. Consequently,5
TABLEIII TABLEV
EFFECTOFCLASSTOKENSANDMEANPOOLINGONPERFORMANCE. EFFECTOFPOSITIONALENCODING.
Head Tail Middle MeanPooling P R F1 Design P R F1
✓ 87.71 86.71 86.92 None 90.64 90.22 90.25
✓ 88.68 87.58 87.74 PE Fourier 91.62 90.85 91.04
✓ ✓ 87.92 86.35 86.79
Learnable 92.02 91.53 91.66
✓ 91.63 91.19 91.24
✓ 92.02 91.53 91.66 2242px,k=16,s=16 89.93 89.31 89.38
Token 2242px,k=16,s=8 92.02 91.53 91.66
3842px,k=16,s=8 92.75 91.98 92.16
TABLEIV
EFFECTOFDIFFERENTSCANNINGPATHSONPERFORMANCE.
Forward Reverse Shuffle Mean/Gate P R F1
✓ - 88.14 87.11 87.24 RSMambaconcurrentlyharnessestheadvantagesofCNNsand
✓ ✓ Mean 89.55 88.45 88.61 Transformers, specifically their linear complexity and global
✓ ✓ Gate 90.83 89.87 90.07 receptive field. We introduce a dynamic multi-path activa-
✓ ✓ ✓ Gate 92.02 91.53 91.66
tion mechanism to alleviate the limitations of unidirectional
modeling and position insensitivity inherent in the vanilla
Mamba. RSMamba maintains the internal structure of the
we have designed a gate to regulate the information flow
Mamba and offers the flexibility to easily expand parameters
from the various paths. Tab. IV illustrates the performance
to accommodate various application scenarios. Experimental
enhancements achieved through these designs. An increase
evaluations conducted on three distinct remote sensing im-
in the number of paths correlates with an improvement in
age classification datasets demonstrate that RSMamba can
classification effectiveness. The gating mechanism also offers
outperform other state-of-the-art classification methods based
certain advantages over feature averaging. It is important to
on CNN and Transformer. Consequently, RSMamba exhibits
notethatweutilizedaveragepoolingfeaturesforclassification
considerable potential to serve as the backbone network for
in this instance. If we were to adopt a ViT-like class token
next-generation visual foundation models.
design, the absence of a multi-path scheme would lead to a
substantial decline in performance.
3) Effect of Positional Encoding: To enhance RSMamba
REFERENCES
withthecapacitytomodelrelativespatialrelationships,wein-
corporatepositionencodingintotheflattenedimagesequence. [1] G.-S. Xia, J. Hu, F. Hu, B. Shi, X. Bai, Y. Zhong,
Tab. V delineates the influence of the presence, absence, and L. Zhang, and X. Lu, “Aid: A benchmark data set for
type of position encoding on the classification performance. performance evaluation of aerial scene classification,”
Thelackofpositionencodingleadstoadegradationinperfor- IEEE Transactions on Geoscience and Remote Sensing,
mance,whereasbothFourierencodingandlearnableencoding vol. 55, no. 7, pp. 3965–3981, 2017.
contribute to performance enhancements. It should be noted [2] Y. Yang and S. Newsam, “Bag-of-visual-words and spa-
that,givenRSMamba’sabilitytorestorethetokensofdifferent tialextensionsforland-useclassification,”inProceedings
paths to their original order, the impact of the presence or of the 18th SIGSPATIAL international conference on
absenceofpositionencodingissomewhatmitigated.However, advances in geographic information systems, 2010, pp.
the integration of position encoding can still yield a slight 270–279.
incremental improvement. [3] G. Cheng, J. Han, and X. Lu, “Remote sensing image
4) Effect of the Number of Tokens: RSMamba’s proficient scene classification: Benchmark and state of the art,”
capability in global feature abstraction significantly alleviates Proceedings of the IEEE, vol. 105, no. 10, pp. 1865–
the complications associated with the length of tokens. As a 1883, 2017.
result, in this paper, we employ an overlapping image patch [4] K.Chen,W.Li,J.Chen,Z.Zou,andZ.Shi,“Resolution-
division method. Tab. V elucidates the effects of the presence agnosticremotesensingsceneclassificationwithimplicit
orabsenceofoverlap,aswellastheenlargementofimagesize. neural representations,” IEEE Geoscience and Remote
The division of image patches with overlap allows each token Sensing Letters, vol. 20, pp. 1–5, 2022.
toencapsulatemoreexhaustiveinformation,therebyleadingto [5] Y. Li, H. Zhang, X. Xue, Y. Jiang, and Q. Shen, “Deep
an enhancement in performance. Augmenting the image size learning for remote sensing image classification: A sur-
facilitatestheinclusionofmoredetails,whichcorrespondingly vey,” Wiley Interdisciplinary Reviews: Data Mining and
yields substantial performance gains. The linear modeling Knowledge Discovery, vol. 8, no. 6, p. e1264, 2018.
complexityemployedbySSMenablesaconsiderableincrease [6] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual
in sequence length, even under conditions constrained by learning for image recognition,” in Proceedings of the
resources. IEEE conference on computer vision and pattern recog-
nition, 2016, pp. 770–778.
IV. DISCUSSIONANDCONCLUSION
[7] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weis-
In this paper, we introduce a novel state space model for senborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Min-
remote sensing image classification, referred to as RSMamba. derer, G. Heigold, S. Gelly et al., “An image is worth6
16x16 words: Transformers for image recognition at
scale,” arXiv preprint arXiv:2010.11929, 2020.
[8] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang,
S. Lin, and B. Guo, “Swin transformer: Hierarchical vi-
sion transformer using shifted windows,” in Proceedings
of the IEEE/CVF international conference on computer
vision, 2021, pp. 10012–10022.
[9] K. Xu, P. Deng, and H. Huang, “Vision transformer: An
excellent teacher for guiding small networks in remote
sensing image scene classification,” IEEE Transactions
on Geoscience and Remote Sensing, vol. 60, pp. 1–15,
2022.
[10] J. Chen, K. Chen, H. Chen, W. Li, Z. Zou, and Z. Shi,
“Contrastive learning for fine-grained ship classification
in remote sensing images,” IEEE Transactions on Geo-
science and Remote Sensing, vol. 60, pp. 1–16, 2022.
[11] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,
L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin,
“Attention is all you need,” Advances in neural informa-
tion processing systems, vol. 30, 2017.
[12] A. Gu, K. Goel, and C. Re´, “Efficiently modeling long
sequences with structured state spaces,” arXiv preprint
arXiv:2111.00396, 2021.
[13] A. Gu and T. Dao, “Mamba: Linear-time sequence
modeling with selective state spaces,” arXiv preprint
arXiv:2312.00752, 2023.
[14] L. Zhu, B. Liao, Q. Zhang, X. Wang, W. Liu, and
X.Wang,“Visionmamba:Efficientvisualrepresentation
learning with bidirectional state space model,” arXiv
preprint arXiv:2401.09417, 2024.
[15] Y. Liu, Y. Tian, Y. Zhao, H. Yu, L. Xie, Y. Wang, Q. Ye,
and Y. Liu, “Vmamba: Visual state space model,” arXiv
preprint arXiv:2401.10166, 2024.
[16] H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablay-
rolles,andH.Je´gou,“Trainingdata-efficientimagetrans-
formers&distillationthroughattention,”inInternational
conference on machine learning. PMLR, 2021, pp.
10347–10357.