[
    {
        "title": "Evaluating Large Language Models for Generalization and Robustness via Data Compression",
        "authors": "Yucheng LiYunhao GuoFrank GuerinChenghua Lin",
        "links": "http://arxiv.org/abs/2402.00861v1",
        "entry_id": "http://arxiv.org/abs/2402.00861v1",
        "pdf_url": "http://arxiv.org/pdf/2402.00861v1",
        "summary": "Existing methods for evaluating large language models face challenges such as\ndata contamination, sensitivity to prompts, and the high cost of benchmark\ncreation. To address this, we propose a lossless data compression based\nevaluation approach that tests how models' predictive abilities generalize\nafter their training cutoff. Specifically, we collect comprehensive test data\nspanning 83 months from 2017 to 2023 and split the data into training and\ntesting periods according to models' training data cutoff. We measure: 1) the\ncompression performance on the testing period as a measure of generalization on\nunseen data; and 2) the performance gap between the training and testing period\nas a measure of robustness. Our experiments test 14 representative large\nlanguage models with various sizes on sources including Wikipedia, news\narticles, code, arXiv papers, and multi-modal data. We find that the\ncompression rate of many models reduces significantly after their cutoff date,\nbut models such as Mistral and Llama-2 demonstrate a good balance between\nperformance and robustness. Results also suggest that models struggle to\ngeneralize on news and code data, but work especially well on arXiv papers. We\nalso find the context size and tokenization implementation have a big impact of\non the overall compression performance.",
        "updated": "2024-02-01 18:56:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.00861v1"
    },
    {
        "title": "SymbolicAI: A framework for logic-based approaches combining generative models and solvers",
        "authors": "Marius-Constantin DinuClaudiu Leoveanu-CondreiMarkus HolzleitnerWerner ZellingerSepp Hochreiter",
        "links": "http://arxiv.org/abs/2402.00854v1",
        "entry_id": "http://arxiv.org/abs/2402.00854v1",
        "pdf_url": "http://arxiv.org/pdf/2402.00854v1",
        "summary": "We introduce SymbolicAI, a versatile and modular framework employing a\nlogic-based approach to concept learning and flow management in generative\nprocesses. SymbolicAI enables the seamless integration of generative models\nwith a diverse range of solvers by treating large language models (LLMs) as\nsemantic parsers that execute tasks based on both natural and formal language\ninstructions, thus bridging the gap between symbolic reasoning and generative\nAI. We leverage probabilistic programming principles to tackle complex tasks,\nand utilize differentiable and classical programming paradigms with their\nrespective strengths. The framework introduces a set of polymorphic,\ncompositional, and self-referential operations for data stream manipulation,\naligning LLM outputs with user objectives. As a result, we can transition\nbetween the capabilities of various foundation models endowed with zero- and\nfew-shot learning capabilities and specialized, fine-tuned models or solvers\nproficient in addressing specific problems. In turn, the framework facilitates\nthe creation and evaluation of explainable computational graphs. We conclude by\nintroducing a quality measure and its empirical score for evaluating these\ncomputational graphs, and propose a benchmark that compares various\nstate-of-the-art LLMs across a set of complex workflows. We refer to the\nempirical score as the \"Vector Embedding for Relational Trajectory Evaluation\nthrough Cross-similarity\", or VERTEX score for short. The framework codebase\nand benchmark are linked below.",
        "updated": "2024-02-01 18:50:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.00854v1"
    },
    {
        "title": "X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection System",
        "authors": "Kiymet KayaElif AkSumeyye BasBerk CanberkSule Gunduz Oguducu",
        "links": "http://arxiv.org/abs/2402.00839v1",
        "entry_id": "http://arxiv.org/abs/2402.00839v1",
        "pdf_url": "http://arxiv.org/pdf/2402.00839v1",
        "summary": "The effectiveness of Intrusion Detection Systems (IDS) is critical in an era\nwhere cyber threats are becoming increasingly complex. Machine learning (ML)\nand deep learning (DL) models provide an efficient and accurate solution for\nidentifying attacks and anomalies in computer networks. However, using ML and\nDL models in IDS has led to a trust deficit due to their non-transparent\ndecision-making. This transparency gap in IDS research is significant,\naffecting confidence and accountability. To address, this paper introduces a\nnovel Explainable IDS approach, called X-CBA, that leverages the structural\nadvantages of Graph Neural Networks (GNNs) to effectively process network\ntraffic data, while also adapting a new Explainable AI (XAI) methodology.\nUnlike most GNN-based IDS that depend on labeled network traffic and node\nfeatures, thereby overlooking critical packet-level information, our approach\nleverages a broader range of traffic data through network flows, including edge\nattributes, to improve detection capabilities and adapt to novel threats.\nThrough empirical testing, we establish that our approach not only achieves\nhigh accuracy with 99.47% in threat detection but also advances the field by\nproviding clear, actionable explanations of its analytical outcomes. This\nresearch also aims to bridge the current gap and facilitate the broader\nintegration of ML/DL technologies in cybersecurity defenses by offering a local\nand global explainability solution that is both precise and interpretable.",
        "updated": "2024-02-01 18:29:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.00839v1"
    },
    {
        "title": "ALISON: Fast and Effective Stylometric Authorship Obfuscation",
        "authors": "Eric XingSaranya VenkatramanThai LeDongwon Lee",
        "links": "http://arxiv.org/abs/2402.00835v1",
        "entry_id": "http://arxiv.org/abs/2402.00835v1",
        "pdf_url": "http://arxiv.org/pdf/2402.00835v1",
        "summary": "Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competing\ntasks of increasing importance in privacy research. Modern AA leverages an\nauthor's consistent writing style to match a text to its author using an AA\nclassifier. AO is the corresponding adversarial task, aiming to modify a text\nin such a way that its semantics are preserved, yet an AA model cannot\ncorrectly infer its authorship. To address privacy concerns raised by\nstate-of-the-art (SOTA) AA methods, new AO methods have been proposed but\nremain largely impractical to use due to their prohibitively slow training and\nobfuscation speed, often taking hours. To this challenge, we propose a\npractical AO method, ALISON, that (1) dramatically reduces training/obfuscation\ntime, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2)\nachieves better obfuscation success through attacking three transformer-based\nAA methods on two benchmark datasets, typically performing 15% better than\ncompeting methods, (3) does not require direct signals from a target AA\nclassifier during obfuscation, and (4) utilizes unique stylometric features,\nallowing sound model interpretation for explainable obfuscation. We also\ndemonstrate that ALISON can effectively prevent four SOTA AA methods from\naccurately determining the authorship of ChatGPT-generated texts, all while\nminimally changing the original text semantics. To ensure the reproducibility\nof our findings, our code and data are available at:\nhttps://github.com/EricX003/ALISON.",
        "updated": "2024-02-01 18:22:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.00835v1"
    },
    {
        "title": "A YANG-aided Unified Strategy for Black Hole Detection for Backbone Networks",
        "authors": "Elif AkKiymet KayaEren OzaltunSule Gunduz OguducuBerk Canberk",
        "links": "http://arxiv.org/abs/2402.00831v1",
        "entry_id": "http://arxiv.org/abs/2402.00831v1",
        "pdf_url": "http://arxiv.org/pdf/2402.00831v1",
        "summary": "Despite the crucial importance of addressing Black Hole failures in Internet\nbackbone networks, effective detection strategies in backbone networks are\nlacking. This is largely because previous research has been centered on Mobile\nAd-hoc Networks (MANETs), which operate under entirely different dynamics,\nprotocols, and topologies, making their findings not directly transferable to\nbackbone networks. Furthermore, detecting Black Hole failures in backbone\nnetworks is particularly challenging. It requires a comprehensive range of\nnetwork data due to the wide variety of conditions that need to be considered,\nmaking data collection and analysis far from straightforward. Addressing this\ngap, our study introduces a novel approach for Black Hole detection in backbone\nnetworks using specialized Yet Another Next Generation (YANG) data models with\nBlack Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our\nmethod of selecting and analyzing four YANG models relevant to Black Hole\ndetection in ISP networks, focusing on routing protocols and ISP-specific\nconfigurations. Our BHMM approach derived from these models demonstrates a 10%\nimprovement in detection accuracy and a 13% increase in packet delivery rate,\nhighlighting the efficiency of our approach. Additionally, we evaluate the\nMachine Learning approach leveraged with BHMM analysis in two different network\nsettings, a commercial ISP network, and a scientific research-only network\ntopology. This evaluation also demonstrates the practical applicability of our\nmethod, yielding significantly improved prediction outcomes in both\nenvironments.",
        "updated": "2024-02-01 18:17:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.00831v1"
    }
]