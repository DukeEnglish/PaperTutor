Hostile Counterspeech Drives Users From Hate Subreddits
DanielHickey1,MatheusSchmitz2,DanielM.T.Fessler3,4,5,PaulE.Smaldino6,7,KristinaLerman2,
GoranMuric´2,KeithBurghardt2
1OregonStateUniversity,DepartmentofBotanyandPlantPathology,Corvallis,OR97331,USA
2USCInformationSciencesInstitute,MarinadelRey,CA90292,USA
3DepartmentofAnthropology,UniversityofCalifornia,LosAngeles,LosAngeles,CA90095,USA
4BedariKindnessInstitute,UniversityofCalifornia,LosAngeles,LosAngeles,CA90095,USA
5CenterforBehavior,Evolution,&Culture,UniversityofCalifornia,LosAngeles,LosAngeles,CA90095,USA
6DepartmentofCognitiveandInformationSciences,UniversityofCalifornia,Merced,Merced,CA95343,USA
7SantaFeInstitute,SantaFe,NM87501,USA
hickeyda@oregonstate.edu,mschmitz@usc.edu,dfessler@anthro.ucla.edu,psmaldino@ucmerced.edu,lerman@isi.edu,
gmuric@isi.edu,keithab@isi.edu
Abstract Kro¨ll 2015). The design of Reddit1 is especially conducive
to this phenomenon, as communities, called “subreddits,”
Counterspeech – speech that opposes hate speech – has canbeformedtodiscussvirtuallyanytopic,andparticipants
gained significant attention recently as a strategy to reduce
canhidebehindanonymoushandles.Inthepresenceofhate
hate on social media. While previous studies suggest that
online,substantialresearchhasexploredthephenomenonof
counterspeech can somewhat reduce hate speech, little is
“counterspeech,”whichdescribesspeechthatcombatshate
knownaboutitseffectsonparticipationinonlinehatecom-
narratives.Usersexposedtocounterspeechhavebeenshown munities,norwhichcounterspeechtacticsreduceharmfulbe-
havior.Webegintoaddressthesegapsbyidentifying25large todecreasetheirsubsequentusageofhatespeechonX(for-
hate communities (“subreddits”) within Reddit and analyz- merlyTwitter)(Heetal.2021;Hangartneretal.2021;Gar-
ing the effect of counterspeech on newcomers within these landetal.2022).Encouragingcounterspeechisthereforean
communities.Wefirstconstructanewpublicdatasetofcare- attractiveoptionforsocialmediaplatformsseekingtocom-
fully annotated counterspeech and non-counterspeech com- bat hate, especially as content moderation can potentially
ments within these subreddits. We use this dataset to train backfire (Johnson et al. 2019; Horta Ribeiro et al. 2021)
a state-of-the-art counterspeech detection model. Next, we and platforms face pressure to decrease moderation in fa-
use matching to evaluate the causal effects of hostile and
voroffreespeech(Kozyrevaetal.2023).Indeed,Facebook
non-hostile counterspeech on the engagement of newcom-
has launched initiatives to support online counterspeech 2.
ersinhatesubreddits.Wefindthat,whilenon-hostilecoun-
Despitetheeffectivenessofcounterspeechinreducinghate
terspeech is ineffective at keeping users from fully disen-
gaging from these hate subreddits, a single hostile counter- speech on some platforms, at present little is known as to
speechcommentsubstantiallyreducesbothfuturelikelihood theefficacyofvariouscounterspeechtactics.Moreover,the
ofengagement.Whileofferingnuancetotheunderstanding impactofcounterspeechonotherbehaviors,suchasengage-
ofcounterspeechefficacy,theseresultsa)leaveunanswered mentinhatecommunities,hasbeenunderstudied.
thequestionofwhetherhostilecounterspeechdissuadesnew- Weaddressthisknowledgegapwithacausalmodel-based
comersfromparticipationinonlinehatewritlarge,ormerely
studytoanalyzetheeffectofinteractionsinhatesubreddits
drivesthemintoless-moderatedandmoreextremehatecom-
(where speech that disparages other groups based on their
munities, and b) raises ethical considerations about hostile
identityisnormalized)andnon-hatesubreddits(asetofsub-
counterspeech, which is both comparatively common and
reddits where such speech is not normalized). After utiliz-
mightexacerbateratherthanmitigatethenetlevelofantago-
nisminsociety.Thesefindingsunderscoretheimportanceof inganovelmethodtoextracthatesubredditsfromdata,we
future work to improve counterspeech tactics and minimize annotateahigh-qualitydatasetofcommentsfromnewcom-
unintendedharm. ers and their replies, labeling whether each comment con-
tains counterspeech or not. A model trained on our dataset
outperformspreviousattemptstodetectcounterspeech.We
Introduction then study how interactions on hate and non-hate subred-
dits affect the probability that a new user continues to be
Hate groups have been shown to cause harm in online en-
anactivemember.Wefocusonnewusersbecausetheyare
vironments (Chan, Ghose, and Seamans 2016), and online
more likely to not return compared to users with long his-
hate can influence offline events (Lewis, Rowe, and Wiper
tories of participation in the community. We use replies to
2019). With the rapid growth of the internet, social media
auser’sfirstpostasatreatment,and,oneachsubreddit,we
platformsmakeiteasierthaneverforuserswhosubscribeto
compare users who received a reply to control users who
hate-basedideologiestofindlike-mindedothers (Caianiand
Copyright©2024,AssociationfortheAdvancementofArtificial 1www.reddit.com
Intelligence(www.aaai.org).Allrightsreserved. 2https://counterspeech.fb.com/en/
4202
yaM
82
]YC.sc[
1v47381.5042:viXraAnnotating Data Model
768 nodes
Blind to annotators Discussion 192 nodes
x 50
Likely
Counterspeech
Hi I’m new Hate speech?
here Counterspeech? 2 nodes
Hello Hate speech? x 100
Likely Counterspeech?
In-group Hate speech?
Downsample Counterspeech? Subreddit
+
Hate speech? Karma
Counterspeech? RoBERTa
Embedding 26 features
Experiment Conditions Causal Inference
Non-hate subreddit
Pr(Treatment User Leaves)
Treatment
New user
Non-hate user
Hate subreddit
Yes
Receives
Hate user reply? Matched Users Engagement = Pr(Treatment User Stays)
Risk Ratio Pr(Control User Stays)
No
Non-attack
Counterspeech user
New user
Control
Attack Pr(Control User Leaves)
Counterspeech user
Figure1:Schematicofthemodelandcounterspeechexperiment.(Topleftpanel)Redditcommentsarefirstcollectedfromhate
subreddits,withcounterspeechupsampledbasedonamodelthatpredictsiftextcontainscounterspeech.Thesedataaresentto
annotatorswhoassesswhetherthetextcontainscounterspeech,discussdisagreementsinannotations,andthenannotateagain
foratotalof900annotatedcomments.(Toprightpanel)ThesedataareembeddedwithRoBERTa,andusedtotrainaneural
networkwhosesecondhiddenlaterisconcatenatedwithsubredditandkarma(upanddownvote)informationofthatcomment.
(Bottomleftpanel)Wethencreateamatchedpaircausalmodeltodeterminetheeffectofhostileandnon-hostilecounterspeech,
aswellastheeffectofin-groupspeechwithinbothhatesubredditsandcounterpartnon-hatesubreddits.(Bottomrightpanel)
Foreachcondition,wecompareuserswhoreceivedareplytosimilaruserswhodidnot.Finally,theeffectofthereplyisthe
ratiobetweentheprobabilityausercontinuestopostinthesubredditwhentheyreceiveareplyversuswhentheydonot.
postedbutneverreceivedareply.Inhatesubreddits,weper- Insummary,ourcontributionsareasfollows:
formthisexperimentmultipletimesfornewcomerswhodo
• Wedevelopanovelmethodtodetecthatesubreddits.
notthemselvesusecounterspeech(i.e.,participantsin,rather
thancriticsof,ahatecommunity),separatelymeasuringthe
• We produce and publicly release a dataset that provides
effect of replies for newcomers who receive hostile coun-
examplesofcounterspeechwithinavarietyofhatesub-
terspeech replies (as identified using the Perspective API),
reddits.
newcomers who receive non-hostile counterspeech replies,
andnewcomerswhoreceiverepliesthatdonotcontaincoun- • Weapplycausalmodelingtechniquestodeterminehowa
terspeech. We find that, in non-hate subreddits, new users user’sfirstinteractionsaffecttheirretentionandactivity
who receive a reply to their first post show a greater like- inhateandnon-hatesubreddits.
lihood of continuing to be active, yet, on most hate sub-
• Wequantifyhowcounterspeechcontributestoreductions
reddits, the reverse is true for users who receive counter-
inuserretentiononhatesubredditswhileleavingreten-
speech. However, the effect of counterspeech is most sig-
tiononothersubredditslargelyunaffected.
nificant when it is also an attack on the new user. These
resultsarereinforcedwithamixed-effectlogisticregression Overall, this work contributes to our understanding of
model,whichshowsthatcounterspeechaloneisnotsignif- counterspeechtactics,andtheirlimitations,whencombating
icantlyassociatedwithuserretention.Thehostilenatureof hatespeechandreducingengagementwithhatesubreddits.
counterspeech,however,mayalsocomewithnegativecon- Our code and data are available at the following repository
sequencesnotmeasuredinthisstudy. https://github.com/dan-hickey1/reddit-counterspeech.
resu
weN
resu
etah
weNRelatedWork previous studies (He et al. 2024). Several published stud-
ies have attempted to detect counterspeech (typically on
EngagementinOnlineCommunities
X) and determine its efficacy. For example, one study de-
Users have many motivations for joining online commu- tectedanti-Asiancounterspeechandfoundexposuretoitre-
nities: exchanging information, acquiring social support, ducedusers’hatespeechlevels(Heetal.2021).Anotherde-
or merely alleviating boredom (Ridings and Gefen 2004; tected counterspeech and hate speech by identifying mem-
Stockdale and Coyne 2020), and they may be recruited by bers associated with two political movements — one far-
friendsoracquaintances(amoreeffectivepathwaythanim- right movement and one created in opposition to it (Gar-
personal advertising) (Kraut and Resnick 2012). However, land et al. 2022). The authors suggest that counterspeech,
not all motivations for joining a community are positive. especially when organized, works to counteract the rela-
Usersfromonecommunitymayinvadeanothercommunity tive amount of hate shown on Twitter. Outside of X, stud-
with negative posts (Jhaver et al. 2018), which can reduce ies have constructed datasets to detect counterspeech on
theoverallactivityintheinvadedcommunity(Kumaretal. YouTube(Mathewetal.2019)andReddit(Yu,Blanco,and
2018).Andsomecommunitiesare,attheircore,focusedon Hong2022).Scholarshavealsocreatedataxonomyofcoun-
discussionsofantagonisticandhatefulaims,includingthose terspeech, categorizing the ways it can manifest (Mathew
thatareracist,sexist,orxenophobic. et al. 2019). Through experimental methods, researchers
After a user initially joins a community, various fac- have found empathy-based counterspeech to be effective
torscontributetowhethertheycontinueparticipating.When in causing users to retrospectively delete their racist posts
newcomersreceiverepliestotheirfirstposts,theyaremore and reduce their future usage of hate speech (Hangartner
likely to keep posting in that community (Arguello et al. etal.2021).Experimentshavealsorevealedhowexposureto
2006;KrautandResnick2012).Thepositiveimpactofthe non-hostile counterspeech reduced bystanders’ willingness
reply is strengthened when it contains positive (Arguello to engage in hostile counterspeech (Obermaier, Schmuck,
et al. 2006) or personalized (Kraut and Resnick 2012) lan- and Saleem 2023), and how exposure to counterspeech de-
guage. However, not all newcomers may be desired by or creasedbeliefinharmfulstereotypesforpoliticallyleft-wing
beneficialforagivencommunity(KrautandResnick2012; individuals, but increased belief in stereotypes for right-
Choi,Kraut,andFichman2008).Forexample,membersof wingindividuals(Scha¨feretal.2023).
pro-anorexiacommunitiesemploygatekeepingtacticstoex- We add to the existing body of work on counterspeech
cludenewcomerslabeledas“wannarexics”(BoeroandPas- bydevelopingamodeltodetectcounterspeechinhatesub-
coe2012).Similarnegativeinteractionswithnewusersare redditsandanalyzingtheefficacyoftwocounterspeechtac-
also seen in Stack Exchange Q&A boards (Santos et al. ticsonhateuserengagement.Moreover,thisstudyisoneof
2020). thefirsttoanalyzecounterspeechefficacyonReddit,aplat-
form characterized by affordances for users to create top-
OnlineHateCommunities ically distinct communities with bespoke moderation poli-
cies and norms. Additionally, while previous studies have
Because online hate communities occur on various plat-
focused on specific targets of hate or specific hate commu-
formswithdifferentaffordances,researchmustsituateeach
nities,weevaluatetheeffectsofcounterspeechacrossava-
platforminthelargeronlinehateecosystem(Zahrah,Nurse,
rietyofhatecommunitieswithdifferingtargetedidentities.
and Goldsmith 2022; Rieger et al. 2021; Zannettou et al.
2018; Russo et al. 2023). Velasquez et al. (Velasquez et al.
Methods
2021), for example, analyzed six online platforms to char-
acterizehowhatecontentcanspreadamongplatforms.An- OurmethodologypipelineisoutlinedinFig.1.Wefirstcol-
otherstudyfoundmoderatinghatecontentononeplatform lectdataonhatecommunities,annotateadatasetforcoun-
cancausehatecontenttospreadmorequicklyonotherplat- terspeech detection, catch users who do and do not receive
forms,motivatingcross-platformregulationofsocialmedia replies (including counterspeech replies), and finally mea-
(Johnsonetal.2019).Eachplatformalsohasauniquerole; suretheeffectofthereply(ourtreatment).
Facebook,forexample,isusedtoactivelyrecruitmembers,
DetectingHateCommunities
while X (formerly Twitter) is used to amplify the message
of the group and reach a larger audience (Phadke and Mi- Defining a hate group as “an organization or collection of
tra2020).Platformsalsocanuniquelyencouragehate,such individualsthat...hasbeliefsorpracticesthatattackorma-
as Reddit’s upvote feature aiding in platforming hate con- lignanentireclassofpeople,typicallyfortheirimmutable
tentonr/The Donald(Gaudetteetal.2021),whilelikesand characteristics,”3 we seek to extract subreddits that dispar-
retweetscanencouragetoxicityonX(Jiangetal.2023).In ageaclassofindividualsforpropertiestheycannotchange,
thepresentstudy,weprovidegreaterinsightintothedynam- whichwequantifyascontainingasubstantialpercentageof
icsofhategroupsonReddit,furtherinforminghowReddit hate words compared to baseline subreddits. We audit this
maycomparetootherplatforms. definition by extracting probable hate subreddits and com-
paringthecontentsthereinwiththatofknownhatesubred-
Counterspeech dits.
Counterspeech describes speech that actively opposes acts 3https://www.splcenter.org/20200318/frequently-asked-
ofhatespeech,whichisakintocorrectivebehaviorseenin questions-about-hate-groups\#hate\%20groupIn more detail, we begin with a seed sample of four or marginally hate, subreddits being erroneously identified
hate subreddits from prior research on hate communities as hate. From the perspective of hypothesis testing, this is
(Schmitz, Muric, and Burghardt 2022; Chandrasekharan conservative, as diluting the pool of hate subreddits would
et al. 2017). We add to this sample banned or quarantined reduce, rather than increase, the likelihood that our explo-
subreddits described in the “controversial Reddit commu- ration would find any differences in the internal dynamics
nities” Wikipedia page (Wikipedia contributors 2022) with of subreddits that we classify respectively as hate or non-
strong references to hate in descriptions of their content or hate. That said, qualitative checks reveal that the subred-
reasons for removal; there are 10 such subreddits with as- dits that our method identifies as hate communities are in-
sociatedhateusers.Additionalcandidatehatesubredditsare deed such. With the caveat that much of the material will
thoseinwhichtheaforementionedhateusersareactive(we behighlyoffensivetomostreaders,weinvitereaderstoex-
assume similar subreddits receive significant cross-user ac- plore the contents of this set of subreddits themselves and
tivity).Weobtainthe1,000subredditswiththehighestpro- makejudgmentsastowhethertheyareforumsforhate(the
portionofusersfromeachhatesubreddit,wherewegather list of subreddits is contained in the following repository:
absolutemembershipfromeachsubreddittoobtainthepro- https://github.com/dan-hickey1/reddit-counterspeech).
portion.Asthereisoverlapbetweenthetop1,000fromeach
hatesubreddit,thisresultsinatotalof2,177candidatesub- CreatingaCounterspeechDetectionModel
reddits. Toeffectivelyseparatenewcomerswhoreceiverepliescon-
We extract each candidate hate subreddit’s most recent taining counterspeech from newcomers who do not receive
posts using the official Reddit API as of July 2022. If the suchreplies,wecreateamodelthatcanautomaticallydetect
subreddit is banned, quarantined, or private, the request counterspeechonRedditwithhighaccuracy.WhileYuetal.
wouldfail,thusprovidingacomputationallyefficientwayof havereleasedadatasetforcounterspeechdetectiononRed-
filteringforsuchsubreddits.Fromourcollectionofbanned, dit,itwascollectedfromasampleofallsubreddits,mean-
quarantined,orprivatesubreddits,weretainsubredditswith ingitmaynotbeeffectiveindetectingcounterspeechwithin
more than 3,000 users, as that is the size of the small- the distinct subcultures that we examine (Yu, Blanco, and
est subreddit (namely r/GreatApes) among the initial four Hong 2022). To create a high-performance model for de-
subreddits derived from prior work (Schmitz, Muric, and tectingcounterspeech,weconductmultiplestagesofmodel
Burghardt2022;Chandrasekharanetal.2017).Foreachre- construction and evaluation, which ultimately leads to the
maining candidate hate subreddit, we obtain a list of 100 creation of a new counterspeech dataset specialized to the
candidate hate words using the Sparse Additive GEnera- setof25hatesubredditsinthisstudy.Inthissection,wede-
tive (SAGE) model (Eisenstein, Ahmed, and Xing 2011), scribe this process in further detail. Our dataset annotation
following Schmitz et al. (Schmitz, Muric, and Burghardt and model training methodology is outlined in Fig. 1, top
2022). SAGE compares a target corpus to a baseline cor- panels.
pustofindthewordsmostcharacteristicoftheformer.For Stage1:Annotatingadatasetforcounterspeechdetec-
our baseline corpus, we employ a sample of randomly se- tion in hate subreddits. We use a semi-supervised learn-
lectedRedditpostsusingtheRedditAPI.Afterthetop100 ingstrategytocreateadatasetthatweannotateforcounter-
most characteristic words of each subreddit are obtained speech. More specifically, we use the dataset and methods
(the top 100 words are chosen as it is a reasonable num- outlined in Yu et al. (Yu, Blanco, and Hong 2022) to train
ber for people to annotate), three human annotators (who a preliminary counterspeech detection model, and use pre-
are also authors of this paper) rate each word as 0 = not dictionsfromthemodeltopopulatethedatasetwithexam-
hate speech, 1 = sometimes hate speech depending on the ples of likely counterspeech. However, unlike Yu et al., we
context,or2=alwayshatespeech(thecontextofthesub- simplify our classification from three labels (hate, counter-
reddits are taken into account when annotating). The an- speech, and neutral comments) to two (counterspeech and
notations results in a Fleiss Kappa score of 0.5, indicating non-counterspeech, which we call “in-group speech”). We
moderateagreementamongraters,whichissimilartocom- separate comments from newcomers who receive replies
mon reliability scores for annotation of hate speech (Vid- into four categories for each of the studied subreddits: 1)
genetal.2021).Wordswithatotalscoreoffourorgreater, newcomerswhousein-groupspeechandreceiveareplythat
summed across all annotators, are classified as hate speech employs in-group speech, 2) newcomers who use counter-
(meaning broad agreement that this word is sometimes or speech and receive a reply that employs in-group speech,
alwayshatespeech).Candidatesubredditswithgreaterthan 3) newcomers who employ in-group speech and receive a
five hate words common to that subreddit are classified replythatiscounterspeech,and4)newcomerswhoemploy
as hate subreddits; 14 met this criterion. This high thresh- counterspeechandreceiveareplythatiscounterspeech(i.e.,
old was used to separate objectively hate subreddits from boththenewcomercommentandreplyareinoppositionto
thosethataresimplyundermoderated.Threeofthesubred- thehatefulnarrativeofthesubreddit).Todeterminethecon-
dits(r/TheRedPill,r/milliondollarextreme,andr/CringeAn- fidencethresholdsfordistinguishingtheseclasses,500ran-
archy) are independently obtained from Wikipedia’s (non- dom comments from the hate subreddits extracted in Sec-
exhaustive) list of highly prominent hate subreddits, sup- tion are labeled by one of the authors of this study, and
porting the validity of our method. However, given how the threshold that results in the highest F1-score using this
context-dependentsomehatewordsare,thisprocedurestill method is chosen. Note that the goal of this stage is only
casts a broad net, potentially resulting in some non-hate, to obtain an initial sense of the efficacy of current coun-terspeech detection methods and to make it more likely to tionalneurons,meaningthemodelwetrainwiththesefea-
obtain counterspeech from a small sample of text. We sub- tures contains 218 neurons in the second layer. To find the
sequently perform more rigorous reliable annotation later. standard errors of performance metrics, we train the model
A dataset of 100 newcomer and reply comment pairs is 50 separatetimes, randomly splittingthe dataset into train-
then assembled, with one pair from each category sampled ing,validation,andtestingdatausinga70/15/15splitwitha
from each subreddit (25 subreddits × 4 categories = 100 differentrandomseedeachtime.Themeanandstandarder-
pairs). This dataset is assembled to evaluate reliability in rorsacrossall50trainingroundsforeachperformancemet-
the annotation process. Four annotators, including one au- ric are reported. In addition to training on our newly anno-
thorofthispaperandthreeundergraduateorrecentlygrad- tateddataset,wealsoreporttheperformanceonourdataset
uatedstudentswithabackgroundinsocialsciencearethen ofamodeltrainedontheentiregolddatasetfromYuetal.,as
trainedtoannotatethepairsofcommentsforwhetherornot wellasanensembleofmodelstrainedonbothdatasets.All
eachnewcomercommentandeachreplycontainedcounter- modelsaretrainedusinganinternalcomputingclusterwith
speech.Aswearealsointerestedintheassociationbetween a 1080TI GPU. The learning rate for training is 1×10−4
counterspeech and personal attacks, the annotators also la- andabatchsizeof32.
bel whether each reply is an attack or not. Annotators are The dataset and code used for training are available at
instructed to score each comment on a scale of -10 to 10, the following link: https://github.com/dan-hickey1/reddit-
where a score of -10 means the annotator is entirely con- counterspeech. Upon publication, we intend to adhere to
fident the comment is not counterspeech (or an attack, de- FAIRprinciples(FORCE112020)bymakingthedatapub-
pendingonwhichisbeingassessed),ascoreof10meansthe licly available to anyone who wishes to use it, and easily
annotatorisentirelyconfidentthecommentiscounterspeech accessible from this paper. The data will be in a widely
or an attack, and a score of 0 represents complete uncer- usedformat(CSV),andtheIDsoriginallyobtainedfromthe
tainty. Additionally, as context has been shown to improve Pushshift dataset will be included in case researchers wish
annotations (Yu, Blanco, and Hong 2022), the parent posts to supplement the dataset with additional features. How-
ofthenewcomers’commentsareincludedinthedataset,as ever, we will omit usernames to preserve the anonymity of
well as the usernames of the authors of the posts (to pre- the authors of the text. Importantly, as the counterspeech
servetheanonymityoftheRedditusers,wedonotpublicly datasetcontainsnumerousinstancesofhatespeechdirected
releaseusernames).Theannotatorsaregivenanannotation at various identity groups, researchers should exercise cau-
guide that defines counterspeech, describes each subreddit tionwhenaccessingthedataset.
in our study, and provides examples of counterspeech and
in-groupspeech.Afterannotatingtheinitialsetof100pairs, AnalyzingContentofReplies
theannotatorsdiscusstheinstancesinwhichtheydisagree. Tofurthercharacterizerepliescontainingcounterspeech,we
Then, they annotate 50 newcomer-reply pairs. After bina- usethePerspectiveAPI,acollectionofmodelsusedforthe
rizing the scores by labeling any annotation score greater detection of toxic online posts (Google Jigsaw 2017). The
than0ascounterspeechoranattack,theFleisskappascore PerspectiveAPIhasbeenwidelyutilizedandvalidatedina
forcounterspeechis0.70,andtheFleisskappascoreforat- variety of domains, (Pavlopoulos et al. 2019; Frimer et al.
tacksis0.75,bothofwhichrepresentgoodagreement,and 2022; Saveski, Roy, and Roy 2021), including Reddit (Ku-
are higher than is typically seen for counterspeech or hate mar et al. 2022; Mittos et al. 2020). We measure two at-
speechdetection(Heetal.2021).Theannotatorsthensplit tributes from the Perspective API to better understand the
up a dataset of 400 comment pairs, with three annotators content of replies: “toxicity” and “attack on commenter.”
assignedtoeachpair.These400pairs,plusthe50pairsan- The Pearson correlation between these attributes is weak
notated earlier, comprise the full dataset for training a new (r = 0.012, calculated from replies in all hate subreddits),
counterspeechmodel.Foreachcomment,themajorityvote hencetheseconstituteindependentmetrics.Importantly,the
istakentodecidewhetheritiscounterspeech.Notethat,be- toxicity metric is meant to classify hate speech as toxic, a
causethedatasetiscomprisedofpairsofcomments,thisre- typeofcontentprevalentinourstudiedcommunities.How-
sultsin900examplesofcommentslabeledascounterspeech ever,theattackoncommentermetricisnotintendedtode-
orasin-groupspeech. tect hate speech as attacks, unless the recipient of the re-
Stage 2: Training a new model for counterspeech de- ply is also the intended target of the hate speech. We also
tection.Afterassemblingadatasetofcommentscategorized explored the severe toxicity metric from Perspective by re-
as counterspeech or in-group speech, we use the same ar- placingregulartoxicitywithseveretoxicityinouranalysis,
chitecture described in Yu et al. to train a new model (Yu, findingtheoverallresultstobesimilar.Weuseregulartoxic-
Blanco, and Hong 2022). Additionally, we train a neural ityonlybecauseithasbeenmuchmorethoroughlyvalidated
networkwithaslightlydifferentarchitectureofthreefully- across a range of datasets (Pavlopoulos et al. 2019; Frimer
connectedlayerswith768neurons,192neurons,and2neu- etal.2022;Saveski,Roy,andRoy2021;Kumaretal.2022;
rons. The Tanh activation function is used for the first two Mittos et al. 2020). Perspective also recommends a proba-
layers and the softmax activation function is used for the bilitythresholdof0.7fortheirtoxicitymetric,whichwedo
final layer. In addition to training models only on the em- notperforminourmainanalyses,insteadtreatingthemetric
bedding,wealsousethecommentkarmaandthesubreddit as a continuous variable. However, we repeat our analyses
(representedasaone-hotencodingvector)asfeaturescon- usingathresholdof0.7forbothtoxicityandattackoncom-
catenatedtothesecondlayeroftheneuralnetworkasaddi- menter metrics and find similar results. In addition to theattributes from the Perspective API, we measure the senti- lar users who did not receive replies, based on four poten-
mentofeachreplytoafirstpostusingVADER(Huttoand tialconfounders:thetimeelapsedbetweenaccountcreation
Gilbert 2014), a lexicon and rule-based sentiment analysis and their first post in the studied subreddit; the nest level
toolspecificallygearedtowardssocialmediatext.Whereas (with1indicatingatop-levelcomment,2indicatingadirect
theattributesfromthePerspectiveAPIareintendedtocap- reply, 3 indicating a reply to that reply, etc.) of their first
turenegativeorhurtfulreplies,sentimentanalysisallowsus comment; the sentiment valence of their first post, as mea-
tocapturethevalenceofreplies,includingpositivity. sured by VADER (Hutto and Gilbert 2014); and the num-
“Hostile” counterspeech is identified using the Perspec- ber of words in their first post. Features such as these have
tive API attack on commenter model, using the threshold previouslybeenshowntoimpactusers’likelihoodofreceiv-
forclassifyingattacksthatmaximizestheF1-scorebasedon ingrepliesinonlinediscussions(Arguelloetal.2006).Each
our annotated dataset described in Section . A reply with user is assigned a vector of these features, and the Maha-
anattackoncommenterprobabilitygreaterthanorequalto lanobisdistanceofeachtreatmentusertoeachcontroluser
0.54 is considered an attack (F1 = 0.38). Additionally, we iscalculated.Thus,themostsimilarcontrolusertoagiven
calculate the average value of these attributes for replies to treatmentuseristheuserwiththelowestMahalanobisdis-
newcomersinnon-hatesubreddits.Theaveragevalueacross tancetothattreatmentuserwhodidnotreceiveareply.This
allsubredditsispresentedforeachcategory. processisappliedtobothhateandnon-hatesubreddits.As
Tounderstandhowstronglythesemodelsareaffectedby matchingiscomputationallyexpensive,eachmatchingpool
hatespeech,wetesthowsensitivetheoutputsofeachmodel islimitedto30,000users.
areinresponsetohatewords.Webuildalexiconof260hate To ensure that the matching process is successful, we
wordsfromall25subredditsusingtheprocessofobtaining measure the standardized mean difference (SMD) between
and annotating words described in Section . We then cal- the treatment and control group for each covariate within
culate the attack on commenter and toxicity probabilities, each set of matched users. Following guidance from prior
as well as sentiment scores for each post with hate words, literature (Verma et al. 2022), we ensure the SMD is be-
and for each post with hate words replaced with neutral low 0.2 for all covariates within all matched samples. As
synonyms (for example the n-word is replaced with “black the matched pairs in our experiments consistently exhibit
person”),seehatespeechlexiconsandreplacedwordshere SMDsabove0.2,weperformapruningprocesswithineach
(WARNING:Containsoffensiveterms):https://github.com/ matched sample, where the matched pairs with the highest
dan-hickey1/reddit-counterspeech; we take care to ensure Mahalanobis distances are removed from the sample until
that the neutral word replacements are not included in the theSMDforallcovariatesisbelow0.2.Ifamatchedsample
VADER lexicon, as that could bias our results. The aver- is reduced to a sample size of 25 without successfully re-
age toxicity, attack on commenter, and sentiment outputs ducingtheSMD,thatsampleisexcludedfromfurtheranal-
for replies in each subreddit are then compared, including ysis,reducingthesizeofthepoolofsubreddits.Asthispro-
replies that did not originally contain hate words. This re- cesseliminatesmanysubredditsfromconsideration,wealso
placementdoesnot,however,significantlyaffectthevalues, performouranalyseswithoutpruningmatchedsamples,ob-
asseeninSIFig.11. servingsimilarresults.
Tocomparetheoveralleffectsofrepliesinhatesubreddits
Matching
tothoseofrepliesinnon-hatesubreddits,wecollect324ran-
To make causal inferences about hate subreddits and their domsubredditsbyobtainingrandompostsfromtheReddit
users, we employ a Mahalanobis distance matching ap- API,identifyingthesubredditassociatedwitheachpost,and
proach (Stuart 2010) wherein we compare similar users in usingthePushshiftAPI(Baumgartneretal.2020)tocrawl
each community, one of whom receives a reply, shown in allsubredditswithgreaterthan10,000subscribersandless
Fig.1,bottompanels.Weexploretworelatedanalyses:first, than 2 million subscribers (larger subreddits are excluded
estimating the effect of a reply within each subreddit. Sec- duetothetimerequiredtocrawlsubredditsusingPushshift).
ond, estimating the overall effects of replies based on sub- We use Mahalanobis distance matching to pair each hate
reddit type. Within each hate subreddit, using the counter- subreddit with a counterpart non-hate subreddit from this
speechmodelwetrainedwiththehighestF1-score,wesplit sample, employing the same process described for the user
usersintoseparategroupstomakeinferences,asdescribed matchingbutwithdifferentfeatures(describedbelow).Each
inSection:thosereceivingin-groupreplies,thosereceiving matchednon-hatesubredditismanuallyinspectedtoensure
non-hostile counterspeech replies, and those receiving hos- thatthepostsarenotprimarilymadebyautomatedaccounts,
tilecounterspeechreplies. andareprimarilyEnglish-speaking,asthetextanalysistools
Ourprocessoffindingtreatmentandcontrolusersderives weusefordownstreamanalysisareintendedforEnglish.
from methods used by Schmitz et al. (Schmitz, Muric, and Comparing the engagement in banned (hate) subreddits
Burghardt 2022). Features are measured before the treat- andnon-bannedsubredditscanbiastheresultsofouranal-
ment.Inthematchingprocess,auserinthetreatmentgroup ysis becauseposts by users whowould otherwise be active
is chosen, the most similar user in the control group is se- afterasubredditisbannedwouldnotappearinthedataset.
lectedasitspair,andtheprocessisrepeateduntilthereare In this case, the engagement of users might appear lower
nounmatchedusersinthetreatmentgroup.Toestimatethe simply because the posts they would have made could not
direct effect of replies within each subreddit and category be created. We account for this in the process of match-
of interaction, we match users who receive replies to simi- ing subreddits. Namely, for each hate subreddit, we obtainthe90thpercentileofthetimetakenfornewcomerstopost user’s post (toxicity, attack on commenter, VADER senti-
a second time. This value, alongside the number of users mentscores,andthecounterspeechprobabilityaccordingto
within the subreddit, and the activity rate of the subreddit themodelwiththehighestROC-AUCscore).Wefitseparate
(definedastheaveragenumberofpostsperuserpermonth) modelsforhateandnon-hatesubreddits,withcounterspeech
isusedtomatcheachhatesubredditwithanon-hatesubred- only being measured in hate subreddits. To ensure that our
dit.Limitingtothe90thpercentilepreventsourresultsfrom models are valid, we compute the variance inflation factor
being skewed by users who could not post a second time (VIF),findingthatnocoefficientreachesaVIFgreaterthan
becausethesubreddithadbeenbanned.Movingforward,a 5(thusfeaturesarenotmulticollinear(Senaviratna,Cooray
ban is simulated for each non-hate subreddit by excluding etal.2019)).Asweareprimarilyinterestedintheeffectof
posts made after their respective matched hate subreddit’s counterspeechoncontinuedengagementinhatesubreddits,
ban date, as well as users who posted after the 90% per- we exclude newcomers who use counterspeech from con-
centilereturntimebeforetheban. siderationinourmixedeffectmodel,asnewcomerswhouse
counterspeechareinherentlyatlowerriskofbeingradical-
MeasuringEngagement ized.
Withineachsubreddit,weidentifyuserswhosefirstpostisa
comment(postwithinasubmission)madebefore2022,and Results
use a metric we term the Engagement Risk Ratio (ERR) Counterspeech detection trained on our dataset outper-
to measure the effect of a reply within a given subreddit. formsmodelstrainedonexistingdatasets.
TheERRisdefinedastheproportionofuserswhoreceived
repliesandcontinuetoengage(continuetopostcomments
orsubmissions inanother threador hatesubreddit) divided
by the proportion of users who did not receive replies and
continuetoengage:
Pr(continuetoengage—reply)
ERR= (1)
Pr(continuetoengage—noreply)
This is analogous to risk ratios commonly used in, for ex-
ample,epidemiology(Cipriani,Nose`,andBarbui2007).In
thiscase,the“risk”referstothelikelihoodofcontinueden-
gagement in the given communities. Replies are associated
withincreasedengagementiftheERRisgreaterthanone,
and decreased engagement if it is less than one. We exclu-
sivelycountdiscussionsinotherthreadsorhatesubreddits,
asrepliescouldelicitanargumentfromthenewcomer,caus-
ingthemtocontinuepostingwithinthesamediscussion.
In addition to measuring continued engagement in hate Figure 2: (A) Performance of models for detecting coun-
subreddits,weperformasurvivalanalysis(Bewick,Cheek, terspeech using different training data. F1 scores are cho-
and Ball 2004) measuring whether users continue posting senbasedonthethresholdthatmaximizestheF1score.(B)
in any subreddit on the platform for up to a year following DatasetsizesforYuetal.(Yu,Blanco,andHong2022)and
their first post. This determines whether counterspeech has hatecommunitydata.
animpactongeneralRedditactivityratherthanengagement
with hate subreddits specifically (if people leave Reddit al- Figure 2 shows ROC-AUC and F1-scores for counter-
together,forexample,theymighthavesimplymovedtoan- speechdetectionmodelstrainedonvariousdatasources.A
other, potentially more fringe, platform). For each type of modelusingYuetal.’sarchitecture(Yu,Blanco,andHong
interaction, we conduct the survival analysis by measuring 2022)thatistrainedonlyonthedatasetwecreatedisonpar
theproportionofuserswhopostedineachsubredditthatare with a model trained on data from Yu et al. In contrast, a
still active on Reddit k weeks after their first post in said model that incorporates karma of the comments as well as
subreddit, with k ranging from 1-52. We perform this sep- thesubredditsfromwhichtheycomebooststheROC-AUC,
aratelyforthetreatmentandcontrolgroup.Thetimeseries precision,andrecallsignificantly.Importantly,thisincrease
ofusersurvivalforthetreatmentandcontrolusersarethen in performance is obtained with a substantial reduction in
comparedusingthelog-ranktest(BlandandAltman2004). dataset size (690 training examples versus 5K). Addition-
ally,precisionissubstantiallyhigherwhenwecombinepre-
ModelingImpactsofReplyAttributes
dictions from the model trained on the data from Yu et al.
Tounderstandhowrepliesandtheircontentimpactuserre- andthemodeltrainedonourdataset(whichincludeskarma
tentioninhatesubreddits,wecreateamixed-effectlogistic andsubredditdata).Whileweopttousethemodelandclas-
regressionmodeltomeasurethelikelihoodthatausercon- sification threshold that maximizes the F1 score in our re-
tinues to post in another thread after their first post (what sults presented in the main text, due to the class imbalance
we term an “engaged” user). The subreddit are random ef- in hate vs. counterspeech (12% of our annotated examples
fects,whilefixedeffectsarefeaturesofthefirstreplytothe are counterspeech), there is merit in opting for a more pre-cise model, as our samples of detected counterspeech will
besmallerthanoursamplesofdetectednon-counterspeech,
and thus more negatively impacted by false positives. We
repeat our analyses using an ensemble of a model trained
onthedatasetprovidedbyYuetal.andamodeltrainedon
ourdataset;thisensemblereachesaprecisionof0.50com-
paredto0.31forthemaintextmodel.Ourresultsarerobust
regardless of the model used for classification. The perfor-
manceofvaryingarchitecturesareshownintheSI4.
Repliescontaininghostilecounterspeechleadtolower
engagement in hate subreddits. Replies containing hos-
tily counterspeech lead to a significantly lower ERR than
in-groupinteractionsinhatesubreddits,interactionsinnon-
hatesubreddits,andrepliescontainingcounterspeechwith-
out attacks (Fig 3; Wilcoxon signed-rank test p < 0.01 for
each comparison (Wilcoxon 1945)). The mean ERR for
hostilecounterspeechreducestheprobabilityauserwillstay
on a hate subreddit (ERR = 0.88), in contrast to other in- Figure3:Hostilecounterspeechrepliessignificantlyreduce
teractions where ERR is roughly 1.0, representing a neu- engagementinhatesubreddits.Weplottheengagementrisk
tral effect of replies. Importantly, if we combine hostile ratioofnon-hatesubredditusersreplyingtoeachother,hate
and non-hostile counterspeech categories, the mean ERR in-groupsubredditusersreplyingtoeachother,non-hostile
isalsobelowone,andthedistributionissignificantlydiffer- counterspeechrepliestoin-groupusersandhostilecounter-
entfromin-groupinteractionsandnon-hatesubreddits.As- speech replies to in-group users. Distributions of engage-
sessing other categories of interactions within hate subred- ment risk ratios for different interaction types. Points rep-
dits (Figure 6), in-group speech replying to counterspeech resentengagementriskratiosofindividualsubreddits,while
leadstoalowerERRthanin-groupinteractions,similarto
boxplots summarize the overall distributions for each sub-
counterspeech replying to in-group speech. The ERRs of reddit type. Values of engagement risk ratios greater than
thecounterspeechreplyingtocounterspeechcategory,onthe oneimplythatrepliesareassociatedwithmoreactiveusers,
otherhand,exhibithighvariance,withnosignificantdiffer- whilevalueslessthanoneimplythatrepliesareassociated
encefromtheothercategoriesofinteractions.Thisislikely with less active users. The lines in the boxes represent me-
due to the rarity of such interactions – the sample sizes of dians, while the boxes and outer lines represent the inter-
this category within each subreddit are notably small, and quartilerangeand95%quantiles,respectively.
this category is more prone to error than other categories,
asdetectingcounterspeechresultsinahigherfalsepositive
ratethandetectingin-groupspeech,andthiserrorratecom-
withhatesubredditsinanywayappeartoengagelesswith
pounds when attempting to predict two instances of coun-
Redditoverallcomparedwiththosepostinginnon-hatesub-
terspeech.ERRforalltypesofinteractionsareshowninSI
reddits, possibly because a larger proportion of these users
Fig. 6. We show robustness of our results by plotting ERR
arebannedfrompostingontheplatform.
fortheYuetal.,modelinSIFig.7,andtheERRofreturn-
ing 6 weeks later in SI Fig. 8. Finally, these results are ro- Content of replies is predictive of whether users will
bustwhenplottingthemedianactivityrateratherthanERR, stop posting in hate subreddits. To understand how the
showninSIFigs.9&10. contentofrepliesrelatestosubredditengagement,webuild
Counterspeech does not have an impact on gen- mixed-effectlogisticregressionmodels,wheretheresponse
eralRedditretention.Surprisingly,hostileandnon-hostile variable is whether a user continues to post in a different
counterspeechdoesnotseemtoaffectgeneralRedditreten- thread from that in which their first post appeared, and the
tion,asshownbyFig4.Wecomparethetreatmentandcon- independentvariablesarewhethertheyreceiveareply,and,
trol users for each interaction type in each subreddit using ifso,thesentiment,toxicity,attackoncommenter,andcoun-
a log-rank test (Bland and Altman 2004). As the survival terspeech scores of that reply. Additionally, we include the
curves are composed of average proportions across multi- karma of the reply, as how well-received a reply is by the
ple subreddits, we use normalized counts of active/inactive communitymayimpactthenewcomers’futureengagement.
usersforeachsubredditforthelog-ranktesttoensurethatall Table 1 summarizes the results. We also describe the mean
subreddits are considered equally. For all interaction types, valuesofdifferentindicatorsintheSIandplotthesevalues
thereisnosignificantdifferencebetweentreatmentandcon- inSIFig.5.
trolusers(p > 0.8).Forrobustness,wealsocheckthesig- Themodelsshowthat,fornewusers,eachreplyreceived
nificance of each subreddit and interaction type combina- decreasestheirlikelihoodofremainingengagedinthatsub-
tion, finding that, out of 100 comparisons, only two sig- reddit,aftercontrollingforcovariates.Themodelsalsoshow
nificant differences (adjusted p < 0.05) are found: one in that attacks on commenters and counterspeech negatively
the group of non-hate subreddits and one in the group of affect engagement when combined, but the effect of coun-
in-group interactions. Notably, however, users who engage terspeech itself is not significant. The models suggest thatbothcanbeeffectiveinsomeways.Interestingly,however,
hostilecounterspeechdoesnot reduceengagementonRed-
ditasawhole.Althoughthisseemstoimplythatreceiving
hostile counterspeech causes hate users to significantly re-
ducetheirexpressionsofhateonline(andcouldevencause
them to rethink their beliefs in this regard), it is also pos-
siblethatreceivinghostilecounterspeechonRedditmerely
causes hate users to refrain from expressing hate on Red-
dit,butdoesnotaltertheirbehavioronotherplatforms(and,
moreover,couldevenmotivatethemtoincreasetheirexpres-
sionsofhateonplatformswheretheydonotreceivehostile
counterspeech).
These results have a number of implications for re-
searchers,onlinepolicymakers,andcommunitymoderators.
First,thenewcounterspeechdetectionmodelcanbeusedby
researchers to better understand counterspeech at scale, or
Figure 4: Survival curves of general Reddit retention for alternatively, when studying hate communities, this model
eachinteractiontype. can filter out users who are likely opposed to the views of
thehatecommunitiesinwhichtheyareposting,therebyre-
ducingnoisewhenmeasuringhateuserbehavior.However,
thehigherhostilityofrepliescontainingcounterspeecharea if such a model is applied in content moderation settings,
principalcontributingfactortothelowerERRsforin-group therearerisksassociatedwithmisclassification.Namely,if
userswhoreceivecounterspeechreplies. counterspeechisincorrectlylabeledashatespeech(forex-
ample because counterspeech mentions hate speech (Glig-
Hate Non-hate oric et al. 2024)), then this could lead to counterspeakers
FixedEffects Coef±SE
being censored, and if hate speech is incorrectly labeled as
MeanIntercept 0.22±0.08 0.14±0.05
counterspeech, this could lead to the platforming of offen-
REPLY -0.04±0.02 0.14±0.01
sivespeech.
REPLY×COUNTER 0.13±0.1 N/A
REPLY×ATTACK -0.25±0.03 -0.18±0.02 In addition to training a model, we demonstrate a clear
REPLY×TOXICITY -0.02±0.03 -0.01±0.03 link between the receipt of replies containing hostile coun-
REPLY×SENTIMENT 0.08±0.02 0.04±0.01 terspeech and reduced engagement by newcomers in on-
REPLY×KARMA 0.05±0.01 0.03±0.01 linehatecommunities.Itmaybetemptingtoconcludethat
REPLY×ATTACK×COUNTER -0.48±0.17 N/A hostilecounterspeechoughttobeencouraged.However,as
REPLY×KARMA×COUNTER 0.07±0.05 N/A Benesch et al. note in their guide to engaging in counter-
RandomEffects Variance speech(Beneschetal.2016),thiscouldunintentionallypro-
Subreddit 0.17 0.16
mote more hostility or discourage bystanders from engag-
ingincounterspeech.Experimentalresultssuggestthatnon-
Table 1: Logistic mixed effect model for the probability a
hostilecounterspeechiseffectiveatcombatinghatespeech,
user will continue to be active after their first post. Coeffi-
and may set an example for the type of counterspeech that
cientsinboldindicatep<0.05.
bystanders feel compelled to use in the future (Hangartner
etal.2021;Obermaier,Schmuck,andSaleem2023).Given
the potential drawbacks of hostile counterspeech and the
Discussion
apparent lower efficacy of non-hostile counterspeech, prior
In this study we create a new dataset and model for coun- studiesthatconflatethesetwotypesofcounterspeechcould
terspeechdetectioninReddithatecommunitiesthatoutper- leadtoincorrectconclusions(Heetal.2021;Garlandetal.
forms models trained on existing published data. We use 2022).Forexample,ifthereasonthatthesestudiesobserve
this new model to analyze replies to first posts in a sam- decreasesinhatespeechduetocounterspeechissimplythat
ple of 25 hate and 25 counterpart non-hate subreddits to the counterspeech in question is particularly hostile, then
assess the overall effect that counterspeech has on engage- the net benefits of counterspeech implied by these studies
ment. We find that hostile counterspeech is more likely to maybediluted–orevenoutweighed–bythepotentialconse-
cause users to leave hate subreddits than to continue en- quencesofhostilespeech.
gagingwiththem,whiletheeffectisneutralfornon-hostile Despite the concerning implications of our study, this
counterspeech. This distinction shows that hostile counter- should not be taken as a warning against counterspeech al-
speech replies in hate subreddits discourage new contribu- together. Counterspeech is a particularly compelling form
tors from continuing to participate, which adds to previous of mitigating hate for several reasons. First, counterspeech
results regarding the impact of negative replies on engage- can be employed by any user of a social media platform,
ment in online communities (Arguello et al. 2006). That empowering individuals and organizations without roles of
being said, we find that both hostile and non-hostile coun- authorityatsocialmediacompaniestopositivelyimpactso-
terspeechcanreducemeanactivityonhatesubreddits,thus cial media environments. Additionally, moderation efforts,such as the removal of harmful speech, are often criticized Baumgartner,J.;Zannettou,S.;Keegan,B.;Squire,M.;and
as being at odds with freedom of expression on social me- Blackburn, J. 2020. The Pushshift Reddit Dataset. CoRR,
dia platforms (at the time of writing this paper, the latter abs/2001.08435.
is the position taken by X concerning content moderation
Benesch, S.; Ruths, D.; Dillon, K. P.; Saleem, H. M.; and
(twi2023)).Evenifsocialmediacompaniesarenotsympa-
Wright, L. 2016. Considerations for successful counter-
thetic to the freedom-of-speech argument, external market
speech. Dangerousspeechproject.
pressures may cause them to significantly reduce the size
Bewick, V.; Cheek, L.; and Ball, J. 2004. Statistics review
andabilityoftheirtrustandsafetyteams(FieldandVanian
12:survivalanalysis. Criticalcare,8:1–6.
2023).Withintheserealities,counterspeechcancontinueto
becultivated. Bland, J. M.; and Altman, D. G. 2004. The logrank test.
Limitations.Despiteourmodel’simprovedperformance Bmj,328(7447):1073.
over existing baselines, more work is needed to create a
Boero,N.;andPascoe,C.J.2012. Pro-anorexiacommuni-
better counterspeech detection model. Importantly, while
ties and online interaction: Bringing the pro-ana body on-
weperformseveralrobustnesschecks,theimperfectperfor- line. Body&Society,18(2):27–57.
manceofourmodelmayimpactthedownstreamresultspre-
Caiani, M.;and Kro¨ll, P.2015. The transnationalization of
sentedinthisstudy.Therearemultiplepotentialreasonsfor
theextreme rightand theuse ofthe Internet. Int.J. Comp.
ourperformancegap.First,ourdatasetissmall,containing
Appl.,39(4):331–351.
900 examples. This is exacerbated by the imbalance in the
rate of counterspeech and in-group speech. Deep learning Chan, J.; Ghose, A.; and Seamans, R. 2016. The Internet
models typically perform better with more data (e.g., tens and Racial Hate Crime: lewis2019 Spillovers from Online
ofthousandsoftrainingexamples),sothereisgreatpoten- Access. MISQuarterly,40(2):381–404.
tialforourmodel’sperformancetoimproveifamuchlarger
Chandrasekharan, E.; Pavalanathan, U.; Srinivasan, A.;
datasetisused.Additionally,ourdatasetcontainsexamples
Glynn, A.; Eisenstein, J.; and Gilbert, E. 2017. You Can’t
ofcounterspeechwithinvarioussubreddits,spanningmany
Stay Here: The Efficacy of Reddit’s 2015 Ban Examined
more types of hate than have previously been considered
ThroughHateSpeech. CSCW,1(CSCW).
in counterspeech detection. Even within categories of hate,
Choi, B.; Kraut, R.; and Fichman, M. 2008. Matching
the culture of the subreddits can be very different, and this
People and Groups; Recruitment and Selection in Online
can impact how counterspeech manifests within each com-
Games. https://tinyurl.com/s3b77wj9.
munity.Finally,identifyingcounterspeechcanbesomewhat
subjective, making the annotations themselves noisy (Da- Cipriani,A.;Nose`,M.;andBarbui,C.2007. Whatisarisk
vani,D´ıaz,andPrabhakaran2022). ratio?EpidemiologyandPsychiatricSciences,16(1):20–21.
Davani,A.M.;D´ıaz,M.;andPrabhakaran,V.2022.Dealing
FutureDirections with disagreements: Looking beyond the majority vote in
subjectiveannotations. TACL,10:92–110.
Whilewefindthatrepliescontaininghostilecounterspeech
reduce the engagement of newcomers in those commu- Eisenstein,J.;Ahmed,A.;andXing,E.P.2011. Sparsead-
nities, there remain additional challenges and questions ditivegenerativemodelsoftext. InICML,1041–1048.
aboutcounterspeechandengagementinonlinehategroups. Field,H.;andVanian,J.2023.Techlayoffsravagetheteams
Namely, future work could explore the impact of counter- thatfightonlinemisinformationandhatespeech. CNBC.
speechonbehavioroutsideofhatesubreddits,suchashate
FORCE11.2020.TheFAIRDataprinciples.https://force11.
speech and antagonism levels in non-hate subreddits. Fur-
org/info/the-fair-data-principles/.
thermore, as there are many other types of counterspeech
that we do not explore, such as humor or empathy-based Frimer,J.A.;Aujla,H.;Feinberg,M.;Skitka,L.J.;Aquino,
counterspeech (Mathew et al. 2019), more sophisticated K.; Eichstaedt, J. C.; and Willer, R. 2022. Incivility is ris-
models could be built to distinguish among those types of ing among American politicians on Twitter. Soc. Psychol.
counterspeech,estimatetheirprevalence,andevaluatetheir Personal.Sci.,19485506221083811.
efficacy. Finally, as the affordances of different platforms Garland, J.; Ghazi-Zahedi, K.; Young, J.-G.; He´bert-
can impact the amount of counterspeech, how it manifests,
Dufresne, L.; and Galesic, M. 2022. Impact and dynamics
andhoweffectiveitis,futurestudiescouldexplorecounter- ofhateandcounterspeechonline. EPJDataSci.,11(1):3.
speechinonlineenvironmentsoutsideofRedditandX.
Gaudette, T.;Scrivens, R.;Davies, G.; andFrank, R. 2021.
Upvoting extremism: Collective identity formation and the
References
extreme right on Reddit. New Media Soc., 23(12): 3491–
2023. Freedom of Speech, Not Reach: An Update on Our 3508.
EnforcementPolicy. https://tinyurl.com/twit-blog. Gligoric, K.; Cheng, M.; Zheng, L.; Durmus, E.; and Ju-
rafsky, D. 2024. NLP Systems That Can’t Tell Use from
Arguello,J.;Butler,B.S.;Joyce,E.;Kraut,R.;Ling,K.S.;
Mention Censor Counterspeech, but Teaching the Distinc-
Rose´,C.;andWang,X.2006. Talktome:Foundationsfor
tionHelps. arXivpreprintarXiv:2404.01651.
successfulindividual-groupinteractionsinonlinecommuni-
ties. InCHI,959–968. GoogleJigsaw.2017. PerspectiveAPI.Hangartner,D.;Gennaro,G.;Alasiri,S.;Bahrich,N.;Born- Obermaier,M.;Schmuck,D.;andSaleem,M.2023. I’llbe
hoft,A.;Boucher,J.;Demirci,B.B.;Derksen,L.;Hall,A.; there for you? Effects of Islamophobic online hate speech
Jochum,M.;Munoz,M.M.;Richter,M.;Vogel,F.;Wittwer, and counter speech on Muslim in-group bystanders’ inten-
S.;Wu¨thrich,F.;Gilardi,F.;andDonnay,K.2021.Empathy- tiontointervene. NewMedia&Society,25(9):2339–2358.
basedcounterspeechcanreduceracisthatespeechinasocial Pavlopoulos,J.;Thain,N.;Dixon,L.;andAndroutsopoulos,
mediafieldexperiment. PNAS,118(50). I.2019. Convaiatsemeval-2019task6:Offensivelanguage
He, B.; Ma, Y.; Ahamad, M.; and Kumar, S. 2024. identification and categorization with perspective and bert.
Corrective or Backfire: Characterizing and Predicting InSemEval,571–576.
User Response to Social Correction. arXiv preprint Phadke, S.; and Mitra, T. 2020. Many faced hate: A cross
arXiv:2403.04852. platform study of content framing and information sharing
He, B.; Ziems, C.; Soni, S.; Ramakrishnan, N.; Yang, D.; byonlinehategroups. InCHI,1–13.
andKumar,S.2021. Racismisavirus:Anti-Asianhateand Ridings, C. M.; and Gefen, D. 2004. Virtual community
counterspeechinsocialmediaduringtheCOVID-19crisis. attraction:Whypeoplehangoutonline. J.Comput.-Mediat.
InASONAM,90–94. Commun.,10(1):JCMC10110.
Horta Ribeiro, M.; Jhaver, S.; Zannettou, S.; Blackburn, J.; Rieger,D.;Ku¨mpel,A.S.;Wich,M.;Kiening,T.;andGroh,
Stringhini, G.; De Cristofaro, E.; and West, R. 2021. Do G.2021. AssessingtheExtentandTypesofHateSpeechin
platform migrations compromise content moderation? evi- FringeCommunities:ACaseStudyofAlt-RightCommuni-
dence from r/the donald and r/incels. CSCW, 5(CSCW2): ties on 8chan, 4chan, and Reddit. Social Media+ Society,
1–24. 7(4):20563051211052906.
Hutto,C.;andGilbert,E.2014.Vader:Aparsimoniousrule- Russo, G.; Verginer, L.; Horta Ribeiro, M.; and Casiraghi,
basedmodelforsentimentanalysisofsocialmediatext. In G.2023. SpilloverofAntisocialBehaviorfromFringePlat-
ICWSM,volume8,216–225. forms: The Unintended Consequences of Community Ban-
Jhaver,S.;Ghoshal,S.;Bruckman,A.;andGilbert,E.2018. ning. ICWSM,17(1):742–753.
Online harassment and content moderation: The case of Santos, T.; Burghardt, K.; Lerman, K.; and Helic, D. 2020.
blocklists. TOCHI,25(2):1–33. Can Badges Foster a More Welcoming Culture on Q&A
Jiang, J.; Luceri, L.; Walther, J. B.; and Ferrara, E. 2023. Boards? ICWSM,14(1):969–973.
Social Approval and Network Homophily as Motivators of Saveski, M.; Roy, B.; and Roy, D. 2021. The structure of
OnlineToxicity. arXivpreprintarXiv:2310.07779. toxicconversationsonTwitter. InTheWebConf,1086–1097.
Johnson, N. F.; Leahy, R.; Restrepo, N. J.; Vela´squez, N.; Scha¨fer,S.;Rebasso,I.;Boyer,M.M.;andPlanitzer,A.M.
Zheng,M.;Manrique,P.;Devkota,P.;andWuchty,S.2019. 2023. Can We Counteract Hate? Effects of Online Hate
Hidden resilience and adaptive dynamics of the global on- Speech and Counter Speech on the Perception of Social
linehateecology. Nature,573(7773):261–265. Groups. CommunicationResearch,00936502231201091.
Kozyreva, A.; Herzog, S. M.; Lewandowsky, S.; Hertwig, Schmitz, M.; Muric, G.; and Burghardt, K. 2022. Quanti-
R.;Lorenz-Spreen,P.;Leiser,M.;andReifler,J.2023. Re- fying how hateful communities radicalize online users. In
solving content moderation dilemmas between free speech 2022 IEEE/ACM International Conference on Advances in
andharmfulmisinformation. PNAS,120(7):e2210666120. SocialNetworksAnalysisandMining(ASONAM),139–146.
Kraut, R. E.; and Resnick, P. 2012. Building successful IEEE.
online communities: Evidence-based social design. Cam- Senaviratna,N.;Cooray,T.;etal.2019. Diagnosingmulti-
bridge,MA:MITPress. collinearity of logistic regression model. Asian J. Probab.
Kumar, D.; Hancock, J.; Thomas, K.; and Durumeric, Z. Stat.,5(2):1–9.
2022. UnderstandingLongitudinalBehaviorsofToxicAc- Stockdale,L.A.;andCoyne,S.M.2020. Boredandonline:
countsonReddit. arXiv:2209.02533. Reasonsforusingsocialmedia,problematicsocialnetwork-
Kumar,S.;Hamilton,W.L.;Leskovec,J.;andJurafsky,D. ing site use, and behavioral outcomes across the transition
2018. Community interaction and conflict on the web. In from adolescence to emerging adulthood. J. Adolesc., 79:
TheWebConf,933–943. 173–183.
Lewis,R.;Rowe,M.;andWiper,C.2019. Online/chan2016 Stuart,E.A.2010. Matchingmethodsforcausalinference:
continuities: Exploring misogyny and hate in online abuse Areviewandalookforward. Stat.Sci.,251:1–21.
offeminists. InOnlineothering,121–143.Springer. Velasquez,N.;Leahy,R.;Restrepo,N.J.;Lupu,Y.;Sear,R.;
Mathew, B.; Saha, P.; Tharad, H.; Rajgaria, S.; Singhania, Gabriel, N.; Jha, O.; Goldberg, B.; and Johnson, N. 2021.
P.; Maity, S. K.; Goyal, P.; and Mukherjee, A. 2019. Thou Online hate network spreads malicious COVID-19 content
shalt not hate: Countering online hate speech. In ICWSM, outsidethecontrolofindividualsocialmediaplatforms.Sci.
volume13,369–380. Rep.,11(1):1–8.
Mittos,A.;Zannettou,S.;Blackburn,J.;andDeCristofaro, Verma, G.; Bhardwaj, A.; Aledavood, T.; De Choudhury,
E.2020. “Andwewillfightforourrace!”Ameasurement M.; and Kumar, S. 2022. Examining the impact of shar-
studyofgenetictestingconversationsonRedditand4chan. ingCOVID-19misinformationonlineonmentalhealth. Sci.
InICWSM,volume14,452–463. Rep.,12(1):8045.Vidgen, B.; Nguyen, D.; Margetts, H.; Rossini, P.; and opt for the model we trained with the highest F1 score, it
Tromble,R.2021. IntroducingCAD:theContextualAbuse is also reasonable to use models that maximize precision
Dataset. InNAACL,2289–2303.Online:ACL. whenpredictingrelativelyrareeventslikecounterspeech,as
Wikipedia contributors. 2022. Controversial Red- falsepositivescansignificantlybiasthedetectedsample.For
dit communities — Wikipedia, The Free Encyclope- thisreason,wecreateanensembleofmodelsthatclassifies
dia. https://en.wikipedia.org/wiki/Controversial Reddit counterspeech based on the predictions of a model trained
communities. [Online;accessed7-October-2022]. on the Yu et al. (Yu, Blanco, and Hong 2022) dataset and
our dataset. We test the precision for various combinations
Wilcoxon, F. 1945. Individual Comparisons by Ranking
ofthresholdsforthesemodels,findingamaximumprecision
Methods. BiometricsBulletin,1(6):80–83.
of 0.5. The results of predictions made from this ensemble
Yu, X.; Blanco, E.; and Hong, L. 2022. Hate speech and
areshowninFigure7,andtheyarequalitativelythesameas
counterspeechdetection:Conversationalcontextdoesmat-
theresultsshowninthemaintext(Figure3).
ter. arXivpreprintarXiv:2206.06423.
Long-term effects of counterspeech on engagement.
Zahrah, F.; Nurse, J. R.; and Goldsmith, M. 2022. A com- While counterspeech may have an immediate effect on
parisonofonlinehateonRedditand4chan:acasestudyof users’ decisions to stop participating in a hate community,
the2020USelection. InSAC,1797–1800. it may not have a long-term effect on members’ partici-
Zannettou, S.; Bradlyn, B.; De Cristofaro, E.; Kwak, H.; pation within a community. To examine the long-term ef-
Sirivianos,M.;Stringini,G.;andBlackburn,J.2018. What fects of counterspeech, we repeat our analysis of the effect
isgab:Abastionoffreespeechoranalt-rightechochamber. of counterspeech on ERRs, but instead of the outcome be-
InWWW,1007–1014. ing whether or not a newcomer continued to participate in
the hate subreddits at all, we measure whether or not the
newcomers remains active in the hate subreddits at least x
SupplementaryInformation
weeks following their first post, testing different values for
Resultsforalltypesofnewcomerinteractions x. Users who cease posting on Reddit completely prior to
Figure5showsthemeanattackoncommenter(A),toxicity theendofourtimethresholdareremovedfromthesamples
(B), and sentiment (C) scores for all types of possible in- toaccountforsurvivorshipbias.Ingeneral,wefindthatfor
teractions,whichincludestypesnotdirectlyrelevanttoour smalltimethresholds,suchassixweeks(Figure8),there-
researchquestion(namely,whennewcomerswhousecoun- sultsarelargelythesameasourprimaryanalysis.However,
terspeech receive replies). As expected, in-group replies to for longer time thresholds, such as six months or one year,
counterspeecharemorehostile,toxic,andnegativethanin- duetothepruningofusersthatstoppedpostingontheplat-
group replies to in-group speech. However, counterspeech form, our sample sizes were reduced to the point where no
repliestocounterspeecharealsoshowntobemorehostile, meaningfulconclusionscouldbemade.
toxic, and negative than in-group interactions in hate sub- Measuring activity rates instead of Engagement Risk
redditsorinteractionsinnon-hatesubreddits.Thiscouldbe Ratios. In addition to measuring the proportion of users
due to the fact that the false-positive rate when predicting who do and do not receive replies that continue to post in
counterspeech is higher than the false-negative rate, mean- hate subreddits (ERR), we compare the activity rates of
ingthatpredictingtwoinstancesofcounterspeechproduces matchedusers,wheretheactivityrateisdefinedasthenum-
alessreliableestimatethanpredictingoneinstanceofcoun- berofpostsperweekfollowingthefirstpostinahatesub-
terspeechandoneinstanceofin-groupspeech.Theengage- reddit. While the effect of counterspeech on median activ-
ment risk ratios for these additional interaction types are ity rates within hate subreddits appears to be significantly
showninFig.6.Theplotrevealsthattheeffectofin-group lower than the effect of in-group interactions (Figure 10),
replies to counterspeech on subsequent engagement tends the results are not consistent when measuring mean activ-
tobeconsiderablylowerthantheeffectsobservedfromin- ityrates(Figure9).Thisislikelybecauseactivityratesare
groupinteractionsinhatesubredditsorinteractionsinnon- a highly skewed metric, even after accounting for potential
hate subreddits. The p-values of reply attributes and ERRs automated accounts. For this reason, the effect of counter-
forallpossiblecombinationsofinteractiontypesarefound speech on mean activity rates is unclear, as shown by the
inTables2and3,respectively. lackofsignificantdifferencesinFigure9.
AdditionalRobustnessChecks
Modelperformancewithdifferentarchitectures.Table4
displaysperformancemetricsformodelstrainedonavariety
ofarchitecturesanddatasets.ForF1andROC-AUCscores,
the neural network architecture described in the main text
performssignificantlybetterthanallothermodels.
Effectsofcounterspeechonengagementusingamore
precise counterspeech detection model. As the perfor-
manceofourcounterspeechdetectionmodelisfarfromper-
fect, it is reasonable to question whether our results would
differ using a model with higher performance. While weFigure5:Replyattributesofallinteractions.(a)Attacksoncommenters,(b)meantoxicity,and(c)meansentiment.
Group P-value
A B Attacks Toxicity Sentiment
Non-hate In-grouprepliestoin-group <0.001 <0.001 <0.001
Non-hate In-grouprepliestoCounterspeech <0.001 <0.001 <0.001
Non-hate Counterspeechrepliestoin-group <0.001 <0.001 <0.001
Non-hate Counterspeechrepliestocounterspeech <0.001 <0.001 <0.001
In-grouprepliestoin-group In-grouprepliestoCounterspeech <0.001 <0.001 <0.001
In-grouprepliestoin-group Counterspeechrepliestoin-group <0.001 <0.001 <0.001
In-grouprepliestoin-group Counterspeechrepliestocounterspeech <0.001 <0.001 <0.001
In-grouprepliestocounterspeech Counterspeechrepliestoin-group 0.37 <0.001 <0.001
In-grouprepliestocounterspeech Counterspeechrepliestocounterspeech 0.003 <0.001 <0.001
Counterspeechrepliestoin-group Counterspeechrepliestocounterspeech 0.003 <0.001 <0.001
Table2:P-valuesforallcomparisonsofgroupsforreplyattributesshowninSIFigure5.Allp-valuesarecalculatedfromthe
Wilcoxonsign-ranktest.
Group P-value
A B ERR
Non-hate In-grouprepliestoin-group 0.007
Non-hate In-grouprepliestoCounterspeech 0.001
Non-hate Counterspeechrepliestoin-group(attack) <0.001
Non-hate Counterspeechrepliestoin-group(noattack) 0.1
Non-hate Counterspeechrepliestocounterspeech 0.006
In-grouprepliestoin-group In-grouprepliestoCounterspeech 0.006
In-grouprepliestoin-group Counterspeechrepliestoin-group(attack) 0.005
In-grouprepliestoin-group Counterspeechrepliestoin-group(noattack) 0.7
In-grouprepliestoin-group Counterspeechrepliestocounterspeech 0.03
In-grouprepliestocounterspeech Counterspeechrepliestoin-group(attack) 0.5
In-grouprepliestocounterspeech Counterspeechrepliestoin-group(noattack) 0.008
In-grouprepliestocounterspeech Counterspeechrepliestocounterspeech 0.05
Counterspeechrepliestoin-group(attack) Counterspeechrepliestoin-group(noattack) 0.006
Counterspeechrepliestoin-group(attack) Counterspeechrepliestocounterspeech 0.1
Counterspeechrepliestoin-group(noattack) Counterspeechrepliestocounterspeech 0.1
Table3:P-valuesofERRsforallcomparisonsofinteractiontypesshowninSIFigure6.Figure6:DistributionsofERRsforallinteractiontypes.Pointsrepresentengagementriskratiosofindividualsubreddits,while
boxplotssummarizetheoveralldistributionsforeachsubreddittype.Valuesofengagementriskratiosgreaterthanoneimply
replies are associated with more active users, while values less than one imply replies are associated with less active users.
The lines in the boxes represent medians, while boxes and outer lines represent the inter-quartile range and 95% quantiles,
respectively.
Dataset ModelArchitecture ROC-AUC F1-Score Precision Recall
HateCommunityText+Metadata RoBERTa+NN 0.75±0.01 0.37±0.01 0.31±0.01 0.46±0.02
HateCommunityText+Metadata RoBERTa+RF 0.71±0.01 0.37±0.01 0.36±0.04 0.51±0.01
HateCommunityText+Metadata RoBERTa+NB 0.70±0.01 0.33±0.01 0.22±0.01 0.74±0.01
HateCommunityText+Metadata RoBERTa+SVC 0.70±0.01 0.27±0.01 0.19±0.02 0.87±0.04
HateCommunityText+Metadata RoBERTa+XGBoost 0.64±0.01 0.34±0.01 0.30±0.02 0.57±0.03
HateCommunityText+Metadata RoBERTa+LR 0.63±0.01 0.30±0.01 0.25±0.01 0.55±0.04
HateCommunityText+Metadata MPNet+NN 0.70±0.01 0.32±0.01 0.22±0.01 0.58±0.02
HateCommunityText+Metadata Yuetal. 0.69±0.01 0.31±0.01 0.21±0.01 0.62±0.02
HateCommunityText RoBERTa+NN 0.70±0.01 0.32±0.01 0.23±0.01 0.55±0.02
Yuetal. RoBERTa+NN 0.70±0.01 0.34±0.01 0.25±0.01 0.57±0.02
Yuetal. Yuetal. 0.69±0.01 0.32±0.01 0.24±0.01 0.53±0.02
Ensemble RoBERTa+NN N/A 0.23±0.01 0.50±0.03 0.15±0.01
Table4:Counterspeechdetectionmodelperformanceforvariousarchitecturesandtrainingdatasets.Allmodelsoptimizefor
F1scoreexceptfortheensemble,whichoptimizesforthehighestrecall.NN=neuralnetwork,RF=randomforest,NB=naive
Bayes,SVC=supportvectorclassifier,LR=logisticregression.Figure 7: ERR distributions when using an ensemble of models trained on Yu et al. and our counterspeech datasets. This
ensembleissignificantlymoreprecisethanthemodelusedfortheresultsinthemaintext(precision=0.5).Figure8:ERRdistributionsformeasuringwhetheruserscontinuetoparticipateinhatesubredditsatleastsixweeksfollowing
theirinitialpost.Figure 9: Percentage differences in mean activity rate by interaction type. Within each subreddit, the percentage difference
betweeneachpairoftreatmentandcontrolusersistaken,andthemeanpercentagedifferenceforthesubredditiscalculated.
Barsrepresenttheaveragemeanpercentagedifference,whiletheerrorbarsrepresentstandarderrors.Figure10:Percentagedifferencesinmedianactivityratebyinteractiontype.Withineachsubreddit,thepercentagedifference
betweeneachpairoftreatmentandcontrolusersistaken,andthemedianpercentagedifferenceforthesubredditiscalculated.
Barsrepresenttheaveragemedianpercentagedifference,whiletheerrorbarsrepresentstandarderrors.Figure11:Impactofreplacinghatewordswithneutralwordsonreplyattributes.Whiletherearedifferencesinthedistributions
withhatewordsreplaced,theyarenotlargeenoughtoaccountforanyofthedifferencesobservedamonggroupsinthisstudy.