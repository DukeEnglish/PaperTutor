3DitScene: Editing Any Scene via Language-guided Disentangled
Gaussian Splatting
QIHANGZHANG,TheChineseUniversityofHongKong,HKSAR
YINGHAOXU,StanfordUniversity,UnitedStatesofAmerica
CHAOYANGWANG,SnapInc.,UnitedStatesofAmerica
HSIN-YINGLEE,SnapInc.,UnitedStatesofAmerica
GORDONWETZSTEIN,StanfordUniversity,UnitedStatesofAmerica
BOLEIZHOU,UniversityofCaliforniaLosAngeles,UnitedStatesofAmerica
CEYUANYANG,ByteDance,China
‚ÄúMove the girl, then delete the girl and Rotate the camera‚Äù
‚ÄúRotate the camera then delete the dog‚Äù ‚ÄúRotate the dog‚Äù
‚ÄúRemove the headscarf then move the camera‚Äù ‚ÄúMove the boy outside‚Äù
Fig.1. Imagepairseditedby3DitScene.Ourmethodhasthecapabilitytosimultaneouslyhandlediversetypesofeditingacrossboth2Dand3Ddimensions.
Sceneimageeditingiscrucialforentertainment,photography,andadver- techniques.LanguagefeaturesfromCLIPthenintroducesemanticsinto
tisingdesign.Existingmethodssolelyfocusoneither2Dindividualobject 3Dgeometryforobjectdisentanglement.WiththedisentangledGaussians,
or3Dglobalsceneediting.Thisresultsinalackofaunifiedapproachto 3DitSceneallowsformanipulationatboththeglobalandindividuallevels,
effectivelycontrolandmanipulatescenesatthe3Dlevelwithdifferentlevels revolutionizingcreativeexpressionandempoweringcontroloverscenesand
ofgranularity.Inthiswork,wepropose3DitScene,anovelandunified objects.Experimentalresultsdemonstratetheeffectivenessandversatility
sceneeditingframeworkleveraginglanguage-guideddisentangledGaussian of3DitSceneinsceneimageediting.Codeandonlinedemocanbefound
Splattingthatenablesseamlesseditingfrom2Dto3D,allowingprecise atourprojecthomepage:https://zqh0253.github.io/3DitScene/.
controloverscenecompositionandindividualobjects.Wefirstincorporate
CCSConcepts:‚Ä¢Computingmethodologies‚ÜíComputervision.
3DGaussiansthatarerefinedthroughgenerativepriorsandoptimization
AdditionalKeyWordsandPhrases:Imageediting,3Dscenegeneration
4202
yaM
82
]VC.sc[
1v42481.5042:viXra2 ‚Ä¢ Zhang,Q.etal
1 INTRODUCTION
GANsforvariousimageeditingtasks,includingimage-to-image
Editingsceneimagesisofgreatimportanceinvariousfields,rang- translation,latentmanipulation[Jahanianetal.2019;Shenetal.
ingfromentertainment,professionalphotographyandadvertising 2020;Xuetal.2021;Yangetal.2021;Zhuetal.2020],andtext-guided
design.Contenteditingallowstocreateimmersiveandcaptivating manipulation[Patashniketal.2021].However,duetolimitations
experiencesforaudiences,conveytheartisticvisioneffectivelyand in training on large-scale data, GANs often struggle to perform
achievethedesiredaestheticoutcomes.Withtherapiddevelopment wellonreal-worldsceneimages.Asdiffusionmodelsmakenotable
ofdeepgenerativemodeling,manyattemptshavebeenmadetoedit progress,thecommunityisincreasinglyfocusingonharnessingthe
animageeffectively.However,theyhaveencounteredlimitations potenttext-to-imagediffusionmodelforrealimageediting[Chen
thathinderedtheirpotential. etal.2023a;Galetal.2022;Hertzetal.2022,2023;Kawaretal.2023;
Previousmethodsprimarilyconcentrateonsceneeditingin2D Kimetal.2022;Mengetal.2021a;Ruizetal.2023;Suetal.2022].
imagespace.Theycommonlyrelyongenerativepriors,suchas However,thesemethodsareconfinedtothe2Ddomainandare
GANs and Diffusion Models (DM), and employ techniques like limitedineditingobjectswithina3Dspace.Concurrently,other
modificationofcross-attentionmechanisms[Hertzetal.2022,2023], researchefforts[Yenphraphaietal.2024a]attempttoaddress3D-
andoptimizationofnetworkparameters[Chenetal.2023a;Gal awareimageediting,buttheyintroducesinconsistencyintheediting
et al. 2022; Kawar et al. 2023; Kim et al. 2022; Ruiz et al. 2023] process,andcannotchangethecameraperspectiveoftheentire
to edit the appearance and object identity within scene images. scene.Incontrast,ourmodelleveragesanexplicit3DGaussianto
Whilesomeeffortshavebeenmadetoextendthesemethodsto3D convert2Dimagesinto3Dspacewhiledisentanglingobjectswith
editing,theyignore3Dcuesandposeachallengeinmaintaining3D languageguidance.Thisapproachenablesourmodelnotonlyto
consistency,especiallywhenchangingthecamerapose.Moreover, consistentlyperform3D-awareobjecteditingbutalsofacilitates
theseapproachestypicallyfocusonglobalscenesandlacktheability scene-levelnovel-viewsynthesis.
todisentangleobjectsaccurately,resultinginlimitedcontrolover Single-view3DSceneSynthesis.Among3Dscenesgeneration[Chen
individualobjectsatthe3Dlevel. etal.2023b,c;Chungetal.2023;Epsteinetal.2024;H√∂lleinetal.
Inordertoeditanysceneimagesandenable3Dcontroloverboth 2023;Maoetal.2023;Zhangetal.2023b],conditionalgenerationon
sceneanditsindividualobjects,wepropose3DitScene,anovel asingle-viewpresentsanuniquechallenge.Previousapproaches
sceneeditingframeworkwhichleverageanewscenerepresentation, address this challenge by training a versatile model capable of
language-guideddisentangledGaussianSplatting.Concretely,the inferringa3Drepresentationofascenebasedonasingleinput
givenimageisfirstprojectedinto3DGaussianswhicharefurther image [Flynn et al. 2019; Han et al. 2022; Hong et al. 2023; Hu
refinedandenrichedthrough2Dgenerativeprior[Pooleetal.2022; et al. 2021; Li et al. 2021; Tucker and Snavely 2020; Wiles et al.
Rombachetal.2022].Wethusobtainacomprehensive3Dscene 2020;Yuetal.2021].However,thesemethodsdemandextensive
representationthatnaturallyenablesnovelviewsynthesisfora datasets for training and tend to produce blurry textures when
givenimage.Inaddition,languagefeaturesfromCLIParedistilled confrontedwithsignificantchangesincameraviewpoints.Recently,
intothecorresponding3DGaussianstointroducesemanticsinto3D severalworkshaveembraceddiffusionpriors[Chanetal.2023;Gu
geometry.Thesesemantic3DGaussianshelpdisentangleindividual etal.2023;Liuetal.2023;Qianetal.2023;Tangetal.2023;Xu
objectsoutoftheentirescenerepresentation,resultinginlanguage- etal.2023]toacquireaprobabilisticdistributionforunseenviews,
guideddisentangledGaussiansforscenedecomposition.Theyalso leading to better synthesis results. Nevertheless, these methods
allowforamoreuser-friendlyinteractioni.e.,userscouldquery oftenconcentrateonobject-centricscenesorlack3Dconsistency.
specific objects or interest via text. To this end, our 3DitScene Ourapproachconnect2Dimagesand3Dsceneswithexplicit3D
enablesseamlesseditingfrom2Dto3Dandallowformodifications Gaussiansandincorporatediffusionknowledge,whichovercome
atboththeglobalandindividuallevels,empoweringcreatorsto thementionedchallenges.
haveprecisecontroloverscenecomposition,andobject-leveledits.
Wedubourpipelineas3DitScene.Differentfrompreviousworks 3 METHOD
thatfocusonaddressingasingletypeofediting,3DitSceneinte-
Ourtargetistoproposea3D-awaresceneimageeditingframework
grateseditingrequirementswithinaunifiedframework.Ourteaser thatallowssimultaneouscontroloverthecameraandobjects.To
figuredemonstratestheversatilityof3DitScenebyshowcasingits
accomplishthis,Sec.3.1introducesanovelscenerepresentation
applicationtodiversesceneimages.Wehaveconductedevaluations calledlanguage-guideddisentangledGaussiansplatting.Inorder
of3DitSceneundervarioussettings,andtheresultsdemonstrate
to achieve object-level control, Sec. 3.2 further distills language
significantimprovementsoverbaselinemethods. featuresintotheGaussiansplattingrepresentation,achievingdis-
entanglement at the object level. We elaborate the optimization
2 RELATEDWORK processinSec.3.3anddemonstratetheflexibleusercontrolenabled
byourframeworkduringinferenceinSec.3.4.
ImageEditingwithGenerativeModels.Thefieldof2Dimage
synthesishasadvancedsignificantlywiththedevelopmentofgen-
3.1 3DGaussianSplattingfromSingleImage
erativemodelssuchasGANs[Karrasetal.2021,2019]anddiffusion
models [Ho et al. 2020; Rombach et al. 2022; Song et al. 2020]. Preliminary.3DGaussianSplatting(3DGS)[Kerbletal.2023]has
Many studies capitalize on the rich prior knowledge embedded been proved effective in both reconstructive [Luiten et al. 2023;
in generative models for image editing. Some endeavors utilize Yangetal.2023]andgenerativesetting[Tangetal.2023;Zouetal.3DitScene:EditingAnySceneviaLanguage-guidedDisentangledGaussianSplatting ‚Ä¢ 3
Input View
RGB branch
If reference view
Initialize
Depth DM
f
Render Stable
Novel View Diffusion
Stable
Diffusion
Semantic branch
Expand Render CLIP
Depth DM Language-guided
disentangled 3DGS
Fig.2. 3DitScenetrainingpipeline.Giveninputview,wefirstinitialize3DGSbyliftingpixelsto3DspaceandthenexpanditovernovelviewsbyRGBand
depthinpainting.Semanticfeaturesarethendistilledinto3DGaussianstoachieveobject-leveldisentanglement.
1. Query with language 2. Disentangled representation 3. Diverse editing results
‚Äúa corgi‚Äù
CLIP
Fig.3. 3DitSceneInferencepipeline.Usercanqueryobjectofinterestvialanguageprompt.Enabledbythedisentangled3Drepresentation,usercan
changecameraviewpoint,andmanipulatetheobjectofinterestinaflexiblemanner.
2023].Itrepresentsa3Dsceneviaasetofexplicit3DGaussians. the images rendered by the current 3DGS in the form of Score
Each 3D Gaussian describes its location by a center vector x ‚àà DistillationSampling[Pooleetal.2022]loss,denotedasL SDS.
R3, a scaling factor s ‚àà R3, a rotation quaternion q ‚àà R4, and 3DGSexpansionbyinpainting.Whencameraperspectiveschanges,
alsostoresanopacityvalueùõº ‚àà Randsphericalharmonics(SH) renderedviewswillcontainholesduetoocclusionornewregion
coefficientsc‚ààRùëò (ùëòrepresentsthedegreesoffreedomofSH)for outsidetheoriginalviewfrustum.WeuseStableDiffusiontoinpaint
volumetricrendering.Alltheaboveparameterscanbedenotedas theuncoveredregions.Then,thenewlyaddedpixelsneedtobe
Œò = {xùëñ,sùëñ,qùëñ,ùõº ùëñ,cùëñ|ùëñ ‚àà [0,¬∑¬∑¬∑,ùëÅ ‚àí1]},whereùëÅ isthenumber accuratelytransformedinto3Dspacetoalignseamlesslywiththe
of 3D Gaussians. A tile-based rasterizer is used to render these existing3DGaussians.
Gaussiansinto2Dimage. Previous methods [Chung et al. 2023; H√∂llein et al. 2023; Yu
Image-to-3DGSinitialization.GivenaninputimageI‚ààR3√óùêª√óùëä , etal.2023]firstpredictthedepthvalues,andthenuseheuristic
anoff-the-shelfdepthpredictionmodelisappliedtoestimateits methodstoadjustthevaluestoalignwiththeexisting3Dstructure.
depthmapD‚ààRùêª√óùëä .Then,wecouldtransformimagepixelsinto However,relyingonheuristicmethodsoftenoverlookedvarious
3Dspace,formingthecorresponding3Dpointclouds: scenarios,leadingtoartifactssuchasdepthdiscontinuitiesorshape
deformations.
P =ùúô 2‚Üí3(I,D,K,T), (1) Instead, we propose a novel method to lifted novel contents
to 3D while ensuring seamless alignment without any heuristic
whereKandTarecameraintrinsicandextrinsicmatricesrespec-
procedures.Thekeyinsightistotreattheproblemasanimage
tively.SuchpointcloudsParethenusedtoinitializethe3DGSby
inpaintingtask,andutilizestate-of-the-artdiffusion-baseddepth
directlycopyingthelocationandcolorvalues,withotherGS-related
estimationmodels[Fuetal.2024;Yangetal.2024]asapriortosolve
parametersrandomlyinitialized.Torefinethe3DGS‚Äôsappearance,
thetask.Duringdenoisingsteps,ratherthanusingmodelstopredict
weadoptareconstructionloss:
thenoiseovertheentireimage,weemploytheforwarddiffusion
L recon=‚à•I‚àíùëì(P,K,T)‚à•2 2, (2) processtodeterminethevalueoffixedareas[Mengetal.2021b].
Thisapproachguaranteesthefinalresult,afterdenoising,adheres
whereùëì istherenderingfunction. tothedepthoforiginalfixedparts,ensuringsmoothexpansion.
We further enhance the rendered quality by leveraging prior Aftersmooth3DGSexpansionviadepthinpainting,wetakethe
knowledgefromimagegenerativefoundationmodel,namelyStable imaginednovelviewsasreferenceviews,andapplyreconstruc-
Diffusion [Rombach et al. 2022]. It provides update direction to tion loss L recon to supervise the updated 3DGS. SDS loss L SDS4 ‚Ä¢ Zhang,Q.etal
isadoptedforviewsrenderedfromcameraperspectivesthatare
Table1. Userstudyresult.Wereportthepercentageoffavoriteusersfor
theconsistencyandqualityofimageseditedbyeachmethod
interpolatedbetweentheuser-providedviewpointandthenewly
imaginedviews.
AnyDoor Ojbect3DIT ImageScuplting Ours
3.2 Language-guidedDisentangledGaussianSplatting
Human 5.1 16.8 12.7 65.4
Consistency
Basedonthe3DGSbuiltfromsingleinputimage,userscangenerate GPT4-v 0.0 6.7 31.3 62.0
novelviews.Inthissection,wefurtherdistillCLIP[Radfordetal. Human 10.4 0.5 25.1 64.0
Quality
2021]languagefeatureto3DGaussians.Thisintroducesemantics GPT4-v 6.7 13.3 39.2 40.8
into3Dgeometry,whichhelpsdisentangleindividualobjectsoutof
theentirescenerepresentation.
Languagefeaturedistillation.Weaugmenteach3DGaussian thetextprompteùëô as:
withalanguageembeddinge‚ààRùê∂ ,whereùê∂denotesthenumber
ofthechannels.SimilartoRGBimageI,a2Dsemanticfeaturemap score=min
exp(e¬∑eùëô)
, (5)
E‚ààRùê∂√óùêª√óùëä
canalsoberenderedbytherasterizer.Tolearnthe
ùëñ exp(e¬∑eùëô)+exp(e¬∑eùëñ canon)
embedding,wefirstuseSegmentAnythingModel(SAM)[Kirillov whereeùëñ istheCLIPembeddingsofcanonicalphrasesincluding
canon
etal.2023;Zhangetal.2023a]togetsemanticmasksMùëñ.Then, ‚Äúobject‚Äù,‚Äúthings‚Äù,‚Äústuff‚Äù,and‚Äútexture‚Äù.Gaussiansthathaverelevance
wecanobtainembeddingofeachobjectI‚äôMùëñ andsupervisethe scoresbelowapredefinedthresholdareexcluded.Theremaining
correspondingregiononrenderedfeaturemapE,accordingtothe partisidentifiedastheobjectofuserinterest.
distillationloss: Boundingbox.Userscanalsoselectanobjectbydrawinganap-
L distill=‚àëÔ∏Å(cid:13) (cid:13)(cid:0) E‚àíùëî(I‚äôMùëñ)(cid:1)‚äôMùëñ(cid:13) (cid:13)2 2, (3) wpr io thxi im na thte eb bo ou un nd din ing gb bo ox xar ao ru en fid rsit to idn et nh te ifiin edp ,u ft oi lm loa wge e. d3 bD yG Ka -u Mss ei aa nn ss
ùëñ
clusteringbasedontheirlanguageembeddingse.Assumingthe
whereùëîistheCLIP‚Äôsimageencoder,and‚äôdenoteselement-wise
objectisthemostsignificantonewithintheboundingbox,clusters
multiplication.FollowingLangSplat[Qinetal.2024],weadditionally whosenumberofGaussiansdoesnotexceedathresholdproportion
trainanautoencodertocompresstheembeddingspacetooptimize willbediscarded.
thememoryconsumptionoflanguageembeddinge. Inthemeantime,usercanalsoadjustthecameraviewpointby
Scenedecomposition.Afterdistillation,wecandecomposethe specifyingintrinsicandextrinsicparameters.
sceneintodifferentobjects.Thisenablesusertoqueryandground
specificobject,andperformeditingoversingleobject(e.g.transla- 4 EXPERIMENTS
tion,rotation,removal,re-stylizing). 4.1 Settings
Itisworthnotingthatsuchscenedecompositionpropertynot
onlyenablesmoreflexibleeditsduringinferencestage,butalso Implementationdetails.Toliftanimageto3D,weuseGeoWiz-
providesaugmentationoverscenelayoutsduringtheoptimization ard [Fu et al. 2024] to estimate its relative depth. Stable Diffu-
process. Since now we can query and render each object inde- sion[Rombachetal.2022]‚Äôsinpaintingpipelineisadoptedtogener-
pendently, we apply random translation, rotation, and removal atenewcontentfor3DGS‚Äôsexpansion.WeleverageMobileSAM[Zhang
overobjects.Thisaugmentationoverthescenelayoutleadstoa etal.2023a]andOpenCLIP[Ilharcoetal.2021]tosegmentand
significant improvement in the appearance of occluded regions, computerenderedviews‚Äôfeaturemaps,whicharefurtherleveraged
ultimatelyenhancingtheoverallqualityoftheeditedviews(see tosupervisethelanguageembeddingof3DGaussians.WeuseStable
Sec.4.4). DiffusiontoperformScoreDistillationSampling[Pooleetal.2022]
duringoptimization.Giventhealreadydecentimagequalityatthe
3.3 Training startofoptimizationbenefitedfromexplicit3DGSinitialization,we
adoptalowclassifier-freeguidance[HoandSalimans2022]scale.
Theoveralltrainingobjectivecanbeexpressedas:
Baselines.Wecompareourmethodwithfollowingsceneimage
L=ùúÜ reconL recon+ùúÜ SDSL SDS+ùúÜ distillL distill, (4) editingworks:(1)AnyDoor[Chenetal.2023a]isa2Ddiffusion-
basedmodelthatcanteleporttargetobjectsintogivensceneimages.
whereùúÜ recon,ùúÜ SDSandùúÜ distillarecoefficientsthatbalanceeachloss ItleveragesStableDiffusion‚Äôspowerfulimagegenerativepriorby
term. finetuninguponit.(2)Object3DIT[Micheletal.2024]isdesigned
for3D-awareobject-centricimageeditingvialanguageinstructions.
3.4 Inference
ItfinetunesStableDiffusionoverasyntheticdatasetcontainingpairs
Duetothedisentanglednatureofourrepresentation,userscannow oforiginalimage,languageinstruction,andeditedimage.(3)Image
interactwithandmanipulateobjectsinaflexiblemanner.Here,we Sculpting[Yenphraphaietal.2024b]isalsodesignedfor3D-aware
mainlydiscusspromptingobjectsviatwodifferentmodalities: object-centricimageediting.Itestimatesa3Dmodelfromanobject
Textprompt.Userscanqueryanobjectthroughtextpromptsas intheinputimagetoenableprecise3Dcontroloverthegeometry.
showninFig.3.FollowingLERF[Kerretal.2023]andLangSplat[Qin It also uses Stable Diffusion to refine the edited image quality.
etal.2024],wecalculatetherelevancyscorescorebetweenthe (4)AdaMPI[Hanetal.2022]focusesonthecontrolovercamera
languageembeddingeinthe3DGaussiansandtheembeddingof perspective. It leverages monocular depth estimation and color3DitScene:EditingAnySceneviaLanguage-guidedDisentangledGaussianSplatting ‚Ä¢ 5
view 1 view 2 view 3 disentangled object
Fig.4. Visualizationofrenderedimagesandfeaturemaps.Foreachsample,weshowthreeviewsofrenderedimagesandfeaturemaps.Todemonstrate
thedisentangledscenerepresentation,weusethelanguageembeddingtoselectaforegroundobjectandrenderitexclusively.
Input AnyDoor Object 3DIT Image Sculpting Ours basedonconsistencywiththeoriginalimageandqualityforeach
sample.Wecollectfeedbackfrom25users,andreporttheresult
inTab.1.Ourmethodconsistentlyoutperformspreviousbaselines
intermsofbothconsistencyandimagequality.Asrecommended
in a previous study [Wu et al. 2024], GPT4-v has the ability to
evaluate3Dconsistencyandimagequality.Therefore,weinclude
GPT-4vasanadditionalcriterion.ThepreferenceofGPT4-viswell
alignedwithhumanpreference,whichonceagaindemonstratesthe
superiorityof3DitScene.
4.3 Qualitativeresults
Fig.4showcasesthegeneratednovelviewswiththeirrespective
featuremapsproducedbyourframework.Thefeaturemapsdemon-
strateremarkableaccuracyincapturingthesemanticcontentofthe
Fig.5. Comparisonresultsofobject-centricmanipulation.Weapply
translation,resizing,andremovaloverforegroundobjects.Twodifferent images. This ability to distinctly separate semantic information
editresultsareshownforeachmethod. plays a crucial role in achieving precise object-level control In
thefollowing,wedemonstrateflexibleeditingoversceneimages
enabledbyourframework,andalsocomparewithbaselinemethods.
inpaintingwithlearnedadaptivelayereddepthrepresentations.(5) Objectmanipulation.Sincedifferentmethodsdefineobjectmanip-
LucidDreamer[Chungetal.2023]tacklesnovelviewsynthesisby ulation,particularlytranslationoperations,indifferentcoordinate
queryingStableDiffusion‚Äôsinpaintingpipelinewithdensecamera systems1,itbecomeschallengingtoevaluatethemunderaunified
trajectories. andfairsetting.Therefore,weevaluateeachmethodunderitsown
specificsettingtoachievethebestpossibleresult.AsshowninFig.5,
4.2 Quantitativeresults
AnyDoorstrugglestomaintainobjectidentityand3Dconsistency
We conduct a user study to compare the edited results by our
methodwiththeestablishedbaselines.Wegenerate20samplesfor 1AnyDoor,Object3DITandImageSculptingrespectivelyemploys2Dmasks,language
eachmethodandrequestuserstovotefortheirpreferredmethod prompts,andimagecoordinatesforcontrol.Weusecoordinatesin3Dspaceinstead.6 ‚Ä¢ Zhang,Q.etal
Input AdaMPI LucidDreamer Ours
Fig.6. Comparisonresultsofcameracontrol.Weshowtwoviewswithdifferentcameraperspectivesforeachmethod.
Fig.7. Ablationresultsforlayoutaugmentationduringoptimization.Toevaluatethedegreeofobject-leveldisentanglement,weconductobjectremoval
foreachsample.Thetoprowdisplaystheinputimage,whilethenexttworowsshowcasetheeditedscene
whenmanipulatingobjectlayouts,primarilyduetotheabsence occlusionrelationshipswithinthescene,suchasmovingthegirlto
of 3D cues. Object 3DIT, trained on synthetic datasets, exhibits bepartiallyoccludedbyaforegroundobjectinthelastrowexample.
limitedgeneralizationabilitytorealimages.Byleveraginga3D Camera control. We compare our methods with AdaMPI and
modelderivedfromtheinputimage,ImageSculptingachievesbetter LucidDreamerforcameracontrol.AsillustratedinFig.6,AdaMPI
results.Nonetheless,itencountersissueswithinconsistencywhen onlyfocusesonscenarioswherethecamerazoomsin,anddoes
manipulatingobjects.Thisarisesfromthefactthattheysolelyrely notconsidernovelviewsynthesis.Therefore,thisapproachisnot
onthe3Dmodelforprovidingroughguidance,resultingintheloss suitablefor3D-awareimageeditingwhenlargecameracontrolis
offinerdetailsduringoptimization. required.LucidDreameralsoleveragesStableDiffusion‚Äôsinpainting
Incontrast,ourmethoddeliverssatisfactory3D-awareobject- capacityfornovelviewsynthesis.However,itsuffersfromsudden
leveleditingresults.Itmaintainsaccurate3Dconsistencyofedited transitions in the content within the frame (see sample in the
objects after rearranging their layout. Additionally, it preserves bottomline).Italsorequiresdensecameraposes.Incontrast,our
tupnI
.gua
o/w
.gua
/w3DitScene:EditingAnySceneviaLanguage-guidedDisentangledGaussianSplatting ‚Ä¢ 7
Input w/o w/o ÔºàCFG=50Ôºâ w/o Ours
Fig.8. Ablationresultsforlossterms.Weshowrenderednovelviewsunderdifferentlosssettings.Theleftcolumnliststheinputimage.Inrightcolumns,
twoviewsareshownforeachconfiguration.ThequalitydegradeswhenreconstructionorSDSlosstermisdiscarded
notonlyenablesmoreflexibleinference,butalsocontributestothe
optimizationprocess.
(a)
Lossterms.Duringoptimization,weadoptthreelossterms:L recon,
L SDS,andL distill.L distillplaysacriticalroleindistillinglanguage
embeddinginto3D.Theremainingtwotermsfocusonenhancing
thevisualqualityofimages.Here,weinvestigatethecontribution
(b) ofthesetwoitemsthroughanablationstudy.Asinputimagescan
provideguidanceofoverallstructureanddetailedappearance,there
isnoneedofapplyingalargeclassifierfreeguidance(CFG)value
forSDSloss.Thus,bydefault,wechoose5astheCFGvalue.
(c) AsillustratedinFig.8,theimagequalitydegradesseverelywith-
outL reconorL SDS.WithoutL recon,theimageisonlyrefinedbythe
SDSloss,whichcreatesdiscrepancieswiththeoriginalimage.When
theCFGvalueissetlow,5asdefault,theimageappearslackingin
Fig. 9. Ablation results for depth inpainting. Row (a): images and
detailsandexhibitsunusualtexturepatterns.IncreasingtheCFG
correspondingdepthmap(onlyavailableinthelefthalf);Row(b):depth
valueintroducesmoredetails,yetleadstoinconsistencieswiththe
mappredictedbyheuristicalignment;Row(c):depthmappredictedbyour
originalimage,whiletheissueofstrangetexturepatternspersists.
depthinpaintingmethod.
Additionally,onlyapplyingL reconresultstofloatingartifactsand
blurriness across the entire image. In conclusion, both SDS and
reconstructionlossarecrucialforachievingdecentimagequality.
Depthinpainting.Whenexpanding3DGSatnovelviews,weneed
methodonlyneedsasfewasthreecameraposesandenablessmooth
toestimatethedepthmapofunseenregions.Here,wecompare
transitions from the input view to novel views, enhancing user
ourinpainting-baseddepthestimationwithheuristic-basedmethod.
controloverthecameraperspective.
Fig.9showimageswithdepthmapavailableintheleftpart.The
taskistopredictthedepthmapoftherightpart.Methodrelying
4.4 Ablationstudy
onheuristicalignmentresultstoartifactslikedepthdiscontinuity.
Layoutaugmentationduringoptimization. Asourrepresenta- Incontrast,ourproposedmethodiscapableofproducingaccurate
tiondisentanglesatobjectlevel,wecouldperformlayoutaugmen- depthmapsthatalignwellwiththeleftknownpart.
tationduringoptimization.Here,weinvestigatewhetherdisentan-
5 CONCLUSIONANDDISCUSSION
glementpropertybenefitstheoptimizationprocess.Weusethetask
ofremovingobjectstoevaluatethedegreeofdisentanglement. Wepresentanovelframework,3DitScene,forsceneimageediting.
AsillustratedinFig.7,whenlayoutaugmentationisdisabled Our primary objective is to facilitate 3D-aware editing of both
duringoptimization,floatingartifactscanbeobserved.Wediscover objectsandtheentirescenewithinaunifiedframework.Weachieve
thattheseGaussianslieinsidetheobject.Theyareoccludedby thisbyleveraginganewscenerepresentation,language-guided
Gaussiansatthesurface.Astheydonotcontributetotherendering disentangledscenerepresentation.Thisrepresentationislearntby
result,theyareconsequentlynotupdatedbygradientdescentduring distillingCLIP‚Äôslanguagefeatureinto3DGaussians.Theseman-
optimization,leavingtheirlanguageembeddingsunsupervised. tic3DGaussianseffectivelydisentangleindividualobjectsoutof
Incontrast,whenapplyinglayoutaugmentationduringoptimiza- the entire scene, , thereby enabling localized object editing. We
tion,suchGaussianswillbeexposedwhentheforegroundobjectis test3DitSceneunderdifferentsettingsandproveitssuperiority
movedaway,andhenceupdated.Withthisablation,itisconcluded comparedtopreviousmethods.
thatthedisentanglementpropertyoftheproposedrepresentation8 ‚Ä¢ Zhang,Q.etal
REFERENCES
RuoshiLiu,RundiWu,BasileVanHoorick,PavelTokmakov,SergeyZakharov,and
EricRChan,KokiNagano,MatthewAChan,AlexanderWBergman,JeongJoonPark, CarlVondrick.2023.Zero-1-to-3:Zero-shotoneimageto3dobject.InProceedings
AxelLevy,MiikaAittala,ShaliniDeMello,TeroKarras,andGordonWetzstein.2023. oftheIEEE/CVFInternationalConferenceonComputerVision.9298‚Äì9309.
Generativenovelviewsynthesiswith3d-awarediffusionmodels.ICCV(2023). JonathonLuiten,GeorgiosKopanas,BastianLeibe,andDevaRamanan.2023.Dynamic
DaveZhenyuChen,HaoxuanLi,Hsin-YingLee,SergeyTulyakov,andMatthiasNie√üner. 3dgaussians:Trackingbypersistentdynamicviewsynthesis. arXivpreprint
2023b.Scenetex:High-qualitytexturesynthesisforindoorscenesviadiffusionpriors. arXiv:2308.09713(2023).
arXivpreprintarXiv:2311.17261(2023). WeijiaMao,Yan-PeiCao,Jia-WeiLiu,ZhongcongXu,andMikeZhengShou.2023.
XiChen,LianghuaHuang,YuLiu,YujunShen,DeliZhao,andHengshuangZhao. ShowRoom3D:TexttoHigh-Quality3DRoomGenerationUsing3DPriors.arXiv
2023a. Anydoor:Zero-shotobject-levelimagecustomization. arXivpreprint preprintarXiv:2312.13324(2023).
arXiv:2307.09481(2023). ChenlinMeng,YutongHe,YangSong,JiamingSong,JiajunWu,Jun-YanZhu,and
ZhaoxiChen,GuangcongWang,andZiweiLiu.2023c.Scenedreamer:Unbounded3d StefanoErmon.2021a.Sdedit:Guidedimagesynthesisandeditingwithstochastic
scenegenerationfrom2dimagecollections.arXivpreprintarXiv:2302.01330(2023). differentialequations.arXivpreprintarXiv:2108.01073(2021).
JaeyoungChung,SuyoungLee,HyeongjinNam,JaerinLee,andKyoungMuLee. ChenlinMeng,YutongHe,YangSong,JiamingSong,JiajunWu,Jun-YanZhu,and
2023.Luciddreamer:Domain-freegenerationof3dgaussiansplattingscenes.arXiv StefanoErmon.2021b.Sdedit:Guidedimagesynthesisandeditingwithstochastic
preprintarXiv:2311.13384(2023). differentialequations.arXivpreprintarXiv:2108.01073(2021).
DaveEpstein,BenPoole,BenMildenhall,AlexeiAEfros,andAleksanderHolynski. OscarMichel,AnandBhattad,EliVanderBilt,RanjayKrishna,AniruddhaKembhavi,
2024. Disentangled3DSceneGenerationwithLayoutLearning. arXivpreprint andTanmayGupta.2024.Object3dit:Language-guided3d-awareimageediting.
arXiv:2402.16936(2024). AdvancesinNeuralInformationProcessingSystems36(2024).
JohnFlynn,MichaelBroxton,PaulDebevec,MatthewDuVall,GrahamFyffe,Ryan OrPatashnik,ZongzeWu,EliShechtman,DanielCohen-Or,andDaniLischinski.2021.
Overbeck,NoahSnavely,andRichardTucker.2019.Deepview:Viewsynthesiswith Styleclip:Text-drivenmanipulationofstyleganimagery.InCVPR.
learnedgradientdescent.InCVPR. BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2022. Dreamfusion:
XiaoFu,WeiYin,MuHu,KaixuanWang,YuexinMa,PingTan,ShaojieShen,Dahua Text-to-3dusing2ddiffusion.arXivpreprintarXiv:2209.14988(2022).
Lin,andXiaoxiaoLong.2024.GeoWizard:UnleashingtheDiffusionPriorsfor3D GuochengQian,JinjieMai,AbdullahHamdi,JianRen,AliaksandrSiarohin,Bing
GeometryEstimationfromaSingleImage.arXivpreprintarXiv:2403.12013(2024). Li,Hsin-YingLee,IvanSkorokhodov,PeterWonka,SergeyTulyakov,etal.2023.
RinonGal,YuvalAlaluf,YuvalAtzmon,OrPatashnik,AmitHBermano,GalChechik, Magic123:Oneimagetohigh-quality3dobjectgenerationusingboth2dand3d
andDanielCohen-Or.2022. Animageisworthoneword:Personalizingtext-to- diffusionpriors.arXivpreprintarXiv:2306.17843(2023).
imagegenerationusingtextualinversion.arXivpreprintarXiv:2208.01618(2022). MinghanQin,WanhuaLi,JiaweiZhou,HaoqianWang,andHanspeterPfister.2024.
JiataoGu,AlexTrevithick,Kai-EnLin,JoshuaMSusskind,ChristianTheobalt,Lingjie LangSplat:3DLanguageGaussianSplatting.InCVPR.
Liu,andRaviRamamoorthi.2023.Nerfdiff:Single-imageviewsynthesiswithnerf- AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sandhini
guideddistillationfrom3d-awarediffusion.InICML. Agarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal.2021.
YuxuanHan,RuichengWang,andJiaolongYang.2022.Single-viewviewsynthesisin Learningtransferablevisualmodelsfromnaturallanguagesupervision.InInterna-
thewildwithlearnedadaptivemultiplaneimages.InACMSIGGRAPHConference tionalconferenceonmachinelearning.PMLR,8748‚Äì8763.
Proceedings. RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBj√∂rnOmmer.
AmirHertz,RonMokady,JayTenenbaum,KfirAberman,YaelPritch,andDaniel 2022.High-ResolutionImageSynthesisWithLatentDiffusionModels.InCVPR.
Cohen-Or.2022. Prompt-to-promptimageeditingwithcrossattentioncontrol. NatanielRuiz,YuanzhenLi,VarunJampani,YaelPritch,MichaelRubinstein,andKfir
arXivpreprintarXiv:2208.01626(2022). Aberman.2023.Dreambooth:Finetuningtext-to-imagediffusionmodelsforsubject-
AmirHertz,AndreyVoynov,ShlomiFruchter,andDanielCohen-Or.2023.Stylealigned drivengeneration.InCVPR.
imagegenerationviasharedattention.arXivpreprintarXiv:2312.02133(2023). Yujun Shen, Ceyuan Yang, Xiaoou Tang, and Bolei Zhou. 2020. InterFaceGAN:
JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilistic InterpretingtheDisentangledFaceRepresentationLearnedbyGANs.IEEETPAMI
models.(2020). (2020).
JonathanHoandTimSalimans.2022.Classifier-freediffusionguidance.arXivpreprint YangSong,JaschaSohl-Dickstein,DiederikPKingma,AbhishekKumar,StefanoErmon,
arXiv:2207.12598(2022). andBenPoole.2020.Score-basedgenerativemodelingthroughstochasticdifferential
LukasH√∂llein,AngCao,AndrewOwens,JustinJohnson,andMatthiasNie√üner.2023. equations.arXivpreprintarXiv:2011.13456(2020).
Text2room:Extractingtextured3dmeshesfrom2dtext-to-imagemodels. arXiv XuanSu,JiamingSong,ChenlinMeng,andStefanoErmon.2022.Dualdiffusionimplicit
preprintarXiv:2303.11989(2023). bridgesforimage-to-imagetranslation.arXivpreprintarXiv:2203.08382(2022).
YicongHong,KaiZhang,JiuxiangGu,SaiBi,YangZhou,DifanLiu,FengLiu,Kalyan JiaxiangTang,JiaweiRen,HangZhou,ZiweiLiu,andGangZeng.2023.Dreamgaussian:
Sunkavalli,TrungBui,andHaoTan.2023.LRM:LargeReconstructionModelfor Generativegaussiansplattingforefficient3dcontentcreation. arXivpreprint
SingleImageto3D.arXivpreprintarXiv:2311.04400(2023). arXiv:2309.16653(2023).
RonghangHu,NikhilaRavi,AlexanderCBerg,andDeepakPathak.2021.Worldsheet: RichardTuckerandNoahSnavely.2020.Single-viewviewsynthesiswithmultiplane
Wrappingtheworldina3dsheetforviewsynthesisfromasingleimage.InICCV. images.InCVPR.
GabrielIlharco,MitchellWortsman,RossWightman,CadeGordon,NicholasCarlini, OliviaWiles,GeorgiaGkioxari,RichardSzeliski,andJustinJohnson.2020. Synsin:
RohanTaori,AchalDave,VaishaalShankar,HongseokNamkoong,JohnMiller, End-to-endviewsynthesisfromasingleimage.InCVPR.
HannanehHajishirzi,AliFarhadi,andLudwigSchmidt.2021. OpenCLIP. https: TongWu,GuandaoYang,ZhibingLi,KaiZhang,ZiweiLiu,LeonidasGuibas,Dahua
//doi.org/10.5281/zenodo.5143773Ifyouusethissoftware,pleaseciteitasbelow.. Lin,andGordonWetzstein.2024.GPT-4V(ision)isaHuman-AlignedEvaluatorfor
AliJahanian,LucyChai,andPhillipIsola.2019. Onthe"steerability"ofgenerative Text-to-3DGeneration.arXivpreprintarXiv:2401.04092(2024).
adversarialnetworks.arXivpreprintarXiv:1907.07171(2019). YinghaoXu,YujunShen,JiapengZhu,CeyuanYang,andBoleiZhou.2021.Generative
TeroKarras,MiikaAittala,SamuliLaine,ErikH√§rk√∂nen,JanneHellsten,Jaakko HierarchicalFeaturesfromSynthesizingImages.InCVPR.
Lehtinen,andTimoAila.2021.Alias-FreeGenerativeAdversarialNetworks. YinghaoXu,HaoTan,FujunLuan,SaiBi,PengWang,JiahaoLi,ZifanShi,Kalyan
TeroKarras,SamuliLaine,andTimoAila.2019.Astyle-basedgeneratorarchitecture Sunkavalli,GordonWetzstein,ZexiangXu,etal.2023.Dmv3d:Denoisingmulti-
forgenerativeadversarialnetworks.InCVPR. viewdiffusionusing3dlargereconstructionmodel.arXivpreprintarXiv:2311.09217
BahjatKawar,ShiranZada,OranLang,OmerTov,HuiwenChang,TaliDekel,Inbar (2023).
Mosseri,andMichalIrani.2023.Imagic:Text-basedrealimageeditingwithdiffusion CeyuanYang,YujunShen,andBoleiZhou.2021.Semantichierarchyemergesindeep
models.InCVPR. generativerepresentationsforscenesynthesis.IJCV(2021).
BernhardKerbl,GeorgiosKopanas,ThomasLeimk√ºhler,andGeorgeDrettakis.2023. LiheYang,BingyiKang,ZilongHuang,XiaogangXu,JiashiFeng,andHengshuang
3DGaussianSplattingforReal-TimeRadianceFieldRendering.ACMTransactions Zhao.2024.Depthanything:Unleashingthepoweroflarge-scaleunlabeleddata.
onGraphics42,4(2023). arXivpreprintarXiv:2401.10891(2024).
JustinKerr,ChungMinKim,KenGoldberg,AngjooKanazawa,andMatthewTancik. ZiyiYang,XinyuGao,WenZhou,ShaohuiJiao,YuqingZhang,andXiaogangJin.2023.
2023.Lerf:Languageembeddedradiancefields.InCVPR.19729‚Äì19739. Deformable3dgaussiansforhigh-fidelitymonoculardynamicscenereconstruction.
GwanghyunKim,TaesungKwon,andJongChulYe.2022.Diffusionclip:Text-guided arXivpreprintarXiv:2309.13101(2023).
diffusionmodelsforrobustimagemanipulation.InCVPR. JiraphonYenphraphai,XichenPan,SainanLiu,DanielePanozzo,andSainingXie.2024a.
AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,Laura ImageSculpting:PreciseObjectEditingwith3DGeometryControl.arXivpreprint
Gustafson,TeteXiao,SpencerWhitehead,AlexanderCBerg,Wan-YenLo,etal. arXiv:2401.01702(2024).
2023.Segmentanything.arXivpreprintarXiv:2304.02643(2023). JiraphonYenphraphai,XichenPan,SainanLiu,DanielePanozzo,andSainingXie.2024b.
JiaxinLi,ZijianFeng,QiShe,HenghuiDing,ChanghuWang,andGimHeeLee.2021. ImageSculpting:PreciseObjectEditingwith3DGeometryControl.arXivpreprint
Mine:Towardscontinuousdepthmpiwithnerffornovelviewsynthesis.InICCV. arXiv:2401.01702(2024).3DitScene:EditingAnySceneviaLanguage-guidedDisentangledGaussianSplatting ‚Ä¢ 9
AlexYu,VickieYe,MatthewTancik,andAngjooKanazawa.2021.pixelnerf:Neural QihangZhang,ChaoyangWang,AliaksandrSiarohin,PeiyeZhuang,YinghaoXu,
radiancefieldsfromoneorfewimages.InCVPR. Ceyuan Yang, Dahua Lin, Bolei Zhou, Sergey Tulyakov, and Hsin-Ying Lee.
Hong-XingYu,HaoyiDuan,JunhwaHur,KyleSargent,MichaelRubinstein,WilliamT 2023b. Scenewiz3d:Towardstext-guided3dscenecomposition. arXivpreprint
Freeman,ForresterCole,DeqingSun,NoahSnavely,JiajunWu,etal.2023.Won- arXiv:2312.08885(2023).
derJourney:GoingfromAnywheretoEverywhere.arXivpreprintarXiv:2312.03884 JiapengZhu,YujunShen,DeliZhao,andBoleiZhou.2020.In-domainganinversion
(2023). forrealimageediting.InECCV.
ChaoningZhang,DongshenHan,YuQiao,JungUkKim,Sung-HoBae,SeungkyuLee, Zi-XinZou,ZhipengYu,Yuan-ChenGuo,YangguangLi,DingLiang,Yan-PeiCao,and
andChoongSeonHong.2023a.FasterSegmentAnything:TowardsLightweight Song-HaiZhang.2023.Triplanemeetsgaussiansplatting:Fastandgeneralizable
SAMforMobileApplications.arXivpreprintarXiv:2306.14289(2023). single-view3dreconstructionwithtransformers.arXivpreprintarXiv:2312.09147
(2023).10 ‚Ä¢ Zhang,Q.etal
‚ÄúRemove the sheep and Rotate the camera‚Äù
‚ÄúMove the boy, then Rotate the camera‚Äù
‚ÄúRotate the camera, and Replace the rabbit with cat‚Äù
Fig.10. Imagepairseditedby3DitScene.3DitScene:EditingAnySceneviaLanguage-guidedDisentangledGaussianSplatting ‚Ä¢ 11
‚ÄúMove the toy bear closer, and Rotate the camera‚Äù
‚ÄúReplace the chicken made of clay with a ball of yarn, then Rotate the camera‚Äù
‚ÄúRotate the camera, and Remove the woman‚Äù
Fig.11. Imagepairseditedby3DitScene.