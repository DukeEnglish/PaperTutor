LLM experiments with simulation: Large Language
Model Multi-Agent System for Process Simulation
Parametrization in Digital Twins
Yuchen Xia, Daniel Dittler, Nasser Jazdi, Haonan Chen, Michael Weyrich
Institute of Industrial Automation and Software Engineering
University of Stuttgart
Stuttgart Germany
{yuchen.xia; daniel.dittler; nasser.jazdi; michael.weyrich}@ias.uni-stuttgart.de
Abstract— This paper presents a novel design of a multi- large language models to automate the interaction with digital
agent system framework that applies a large language model twin simulation, thus determining feasible parametrizations
(LLM) to automate the parametrization of process simulations for controlling the simulated processes?
in digital twins. We propose a multi-agent framework that
includes four types of agents: observation, reasoning, decision To answer this question, the key contributions of this paper
and summarization. By enabling dynamic interaction between include:
LLM agents and simulation model, the developed system can
• Multi-agent framework: We present a novel LLM-
automatically explore the parametrization of the simulation and
agent architecture that dynamically interacts with
use heuristic reasoning to determine a set of parameters to
digital twin simulation to determine feasible
control the simulation to achieve an objective. The proposed
parameter settings for simulated physical processes.
approach enhances the simulation model by infusing it with
heuristics from LLM and enables autonomous search for
• Proof-of-concept: A case study demonstrates the
feasible parametrization to solve a user task. Furthermore, the
system’s capability to automate simulation
system has the potential to increase user-friendliness and reduce
parametrization, employing heuristic knowledge
the cognitive load on human users by assisting in complex
reasoning from LLMs.
decision-making processes. The effectiveness and functionality
of the system are demonstrated through a case study, and the • Industrial applications: the results suggest that
visualized demos are available at a GitHub Repository: integrating LLMs with digital twin technologies can
https://github.com/YuchenXia/LLMDrivenSimulation
enhance the intelligence and user-friendliness of
industrial digital twin systems, improving
Keywords—Large Language Models, Multi-Agent System,
operational efficiency and accessibility.
Digital Twin, Simulation, Intelligent Automation.
I. INTRODUCTION
II. BACKGROUND
Figure 1 selectively illustrates the key conceptual
Digital twin technology has significantly improved
components in this work. These components include a
productivity in industries such as engineering and
manufacturing by providing virtual replicas of physical physical entity under study, its virtual counterpart in the form
systems. Digital twin system offers an infrastructure that of a digital twin, and an LLM multi-agent system designed
enables users to monitor, simulate, predict, and control real- for intelligent interaction.
world processes in realtime, thereby improving decision-
making and enhancing operational efficiency.[1]
Currently, users are responsible for interpreting data from
digital twins, understanding complex system behaviors, and
making informed decisions. Human users can only process a
limited amount of information at a time, constraining the
efficiency and usability of digital twin systems. Processing
information requires cognitive effort and specialized
Figure 1 Key conceptual components in this work
knowledge, often necessitating extensive training to ensure
accurate understanding and effective control of the processes
A. Digital twin
that is represented in digital twins. Additionally, the
While definitions of digital twins differ in similar details
availability of such skilled users can be limited, and the high
knowledge barrier can lead to delays and compromised [1][2], they converge on key aspects: A digital twin is a
decision-making. software system that represents a physical entity or system
that mirrors real-world conditions, processes, and systems. It
Large Language Models (LLMs) have demonstrated
remains synchronized with its physical counterpart through
significant intelligence in understanding knowledge.
interfaces that manage data acquisition and control physical
Incorporating the intelligence of LLMs with digital twin
processes (e.g., through an automation system) [3]. In the
technology allows for a higher degree of automation and
context of this paper, two primary parts of the digital twin are
system intelligence, presenting new opportunities to enhance
selectively considered:
digital twins.
Information Model: This component focuses on the
Given the critical role users play in interacting with digital structured integration and management of descriptive data. It
twins to monitor and predictively control processes, a serves as the core of data storage and retrieval within the
pertinent question arises: Can this user role be assisted bydigital twin system, facilitating access and processing of III. THEORETICAL FRAMEWORK OF A MULTI-AGENT SYSTEM
detailed information about the physical entity.[4]
In this work, we propose a structured framework for multi-
Simulation model: In contrast to the information model,
agent system with that assigns distinct roles and
the simulation component is predictive and dynamic. It is responsibilities to each LLM agent within the information
primarily used for operational testing and scenario analysis, processing pipeline. This framework includes four types of
enabling the exploration of potential outcomes based on agents: observation, reasoning, decision and summarization.
various inputs and conditions.[5]
Observation agent: This agent collects and observes real-
The digital twin serves as a critical digital interface for the
time data from the digital twin, focusing on operational
LLM system. It provides LLM agents with access to
parameters, current conditions, and changes in key metrics
information about physical processes, thereby enabling the
crucial for optimal outcomes. It identifies pertinent
LLM system to develop intelligent applications based on
observation data, filters out noise and irrelevant information,
these data.
and distills important insights to establish a factual foundation
B. “Divide and conquer” and LLM multi-agent system for further analysis.
Due to the complexity of the task or the complex data to Reasoning agent: Incorporating data preprocessed by the
be processed from the digital twin, a single LLM often cannot observation agent, the reasoning agent interprets and analyzes
produce satisfactory results. To address this, complex tasks the observed data and insights. It generates reasoning steps
are decomposed into smaller, more manageable components. toward actionable decisions. This process can be characterized
This “divide and conquer” approach allows multiple LLM as heuristic reasoning, as it utilizes knowledge patterns that
agents to collaboratively tackle these tasks, leading to a the LLM has acquired from extensive training data.
comprehensive and effective solution. This principle can be
Decision agent: Upon completion of the reasoning phase,
realized by designing LLM multi-agent systems.
the decision agent generates executable actions based on the
C. Related works previously generated intermediate results. These generated
actions can be formulated as API calls, procedure calls or
Several studies have explored the development of LLM-
services in a software system to invoke operations.
powered applications, often applying the “divide and
conquer” principle to design these systems. These can be Summarization agent: The summarization agent
mainly organized on two levels: consolidates the outcomes of the observation, reasoning, and
decision processes. It compiles a concise report highlighting
Model level: in related works, several frameworks have
the significant insights and results, providing an overview of
been developed to manage the complexity. The Chain-of-
system performance. This agent helps users quickly
Thought (CoT)[6]framework facilitates systematic, step-by-
understand key information about the system’s behavior.
step reasoning, while the Tree-of-Thought (ToT)[7] allows
LLMs to explore multiple pathways, identifying the most This multi-agent system design framework resembles the
viable solutions. Additionally, the ReAct framework [8] scientific methodology used in empirical experiments. It
generates reasoning traces and task-specific actions in an provides a structured and reproducible approach for creating
interleaved manner, effectively addressing complex tasks. LLM multi-agent systems. By clearly defining roles and
These frameworks can be realized by systematic prompting responsibilities in information processing, this framework
to guide the reasoning processes of LLMs, enhancing their aids in the systematic development, rigorous testing, and
capability to solve intricate problems. iterative improvement of systems powered by LLMs.
Alternative methods involve fine-tuning the LLM to
IV. METHODOLOGY
modify its text generation behavior. Techniques such as
Proximal Policy Optimization (PPO)[9] and Direct Policy A. System overview
Optimization (DPO)[10] adjust the generation policies of the
LLM, enhancing its ability to produce logically connected
texts and thereby improving its problem-solving capabilities.
Agents level: Recent studies [11],[12] have explored
frameworks to design LLM agents playing different roles in
task-oriented coordination within simulated social
environments, emphasizing reflection and decision-making
processes. Another study introduces a framework that
enables LLMs to act as game players controlling real-time
strategy games by analyzing complex data and managing
game dynamics [13]. In our prior work, we developed a
multi-agent system to autonomously plan and control
automation systems via a digital twin system [3].
Additionally, a comprehensive survey summarized in [14]
reviews recent advancements in LLM multi-agent systems.
Figure 2 Architecture overview of LLM multi-agent system
In the following section, we present a novel multi-agent interacting with simulation model in a digital twin
system framework to interact with simulation models in As shown in Figure 2, this architecture comprises three
digital twin system to perform simulated experiments to layers. At the top layer, the user interface receives user
determine satisfactory parametrization of a process. requirements and the objectives of the simulation, which are
set as target goals for the simulation to achieve. In the middle
layer, an LLM multi-agent system interacts with digital twinsvia data and control interfaces. At the fundamental layer, the container in a controlled sequence, and then the container is
digital twin is structured to update and operate step-by-step in shaken to redistribute the contents.
a cyclic manner. During each cyclic simulation step, data is
accessed through a data interface, and simulation parameters
are adjusted via a control interface.
The observation agent processes the information from the
data interface to extract significant insights and distill crucial
aspects from the extensive data retrieved, setting the stage for
the next agent to achieve targeted goals. Subsequently, the
reasoning agent applies heuristic reasoning to analyze the
situation and deduce the next viable control strategies, and the Figure 4 The simulated physical process
decision agent generates actions in the form of parametrized The case study experiments, depicted in Figure 4,
function calls to adjust the simulation’s parameters for the demonstrate how the order of adding the balls (light, normal,
upcoming step based on the previously generated observation heavy) and the duration of shaking affect the mixture’s
and reason in text. Collectively, the agents monitor the cyclic homogeneity.
steps of the simulation and control its progression.
Data from each cycle and the corresponding control
parameters are recorded in a simulation log component, which
captures detailed information about the LLM agents’ iterative
decision-making processes. The summarization agent
compiles these logs for each simulation step to develop a
concise parametrized sequential control plan, which will be
reported to the user as a feasible solution to a user task.
Figure 5 The experimenting results with the physical process
B. Information representation conversion between digital
We parametrized these variables to explore different
twins and LLM agents
combinations and their impact on the mixing outcome.
1) Information processing of LLM agents
Several experiments’ parameter settings and results are
In this multi-agent system, each agent functions as an
summarized, as shown in Figure 5.
information processing component. A specific prompt is
crafted for each agent to direct its behavior according to the A. Simulation model for the case study
sub-task it handles within the multi-agent framework (cf. In the simulation, we model a container as a 10x10 matrix
Figure 3). Both input and output information are converted where two primary actions are possible: adding different types
into textual form. This conversion requires a translation of balls and shaking the container. With each shake of the
process that transforms modeled information from the digital container, there is a probability of heavier balls switching
twin simulation model into a textual knowledge positions with nearby lighter balls beneath. The simulation
representation. This representation is then integrated into a begins with the user setting a goal to achieve “an evenly
prompt template. We apply this method to program the LLM distributed mixture”, as shown in Figure 6. The interaction
with the LLM multi-agent system is facilitated through a chat
multi-agent system in the case study section.
box, and the simulation’s progress is visualized on the user
interface.
Figure 3 LLM agent as an information processor through
Prompting
2) JSON and function call as agent output
The generated text is converted into JSON format to
Figure 6 The user interface with chat box and visualized simulation
facilitate technical processing by the software. At the end of
The LLM multi-agent system processes the user
the agent information processing pipeline, the decision agent
command, observing, reasoning, and controlling the
produces a parameterized function call that serves as an simulation steps to achieve the desired outcome. The final
actionable decision. This function call is managed by the result, including a visualization of the outcome and a summary
simulation model’s interface, which executes the operations of the control sequence, is then presented to the user in a
within the simulation model for the next simulation step. concise format, as illustrated in Figure 7 and the demo.
V. A CASE STUDY AND IMPLEMENTATION
For a practical demonstration of the concept, we
implemented a simplified container mixing process. This
simulation is akin to mixing process in a blender, where the
objective is to achieve a homogeneous mixture of balls (or
particles) with varying densities. The balls are added to the Figure 7 The LLM enhanced simulation execution processB. Knowledge representation in text and the simulation framework allow for more efficient
strategic planning and process control.
To realize this application, a key aspect is the conversion
of knowledge representation: translating the simulation
VII. CONCLUSION AND OUTLOOK
representation into a textual format that the LLM can
This research demonstrates the viability of incorporating
interpret while preserving the knowledge. In the case study,
Large Language Models into digital twin frameworks to
the state of the container is represented as a matrix, where
automate the parametrization of simulations. By developing
each position within the matrix is denoted by a number, as
an LLM multi-agent system that interacts with the data and
shown in Figure 8. Each number corresponds to a specific
control interfaces of the digital twin, we can create more
type of ball, which is explicitly defined within the agent’s
intelligent and user-friendly applications. The iterative,
prompt. This textual conversion is critical for allowing the
heuristic-based approach utilized by LLM agents mirrors the
LLM to perceive and interact with the simulation data
human problem-solving process and aims to generate real-
meaningfully.
time operational strategies for process control within a
simulation environment. Moving forward, we plan to conduct
further systematic testing and evaluations, refine the system,
and investigate the LLM multi-agent framework on more
sophisticated simulation models. We expect that continued
advancements will broaden the application scope of LLM-
enhanced digital twins, potentially leading to more efficient
Figure 8 Conversion of simulation information into textual
and productive systems across various industrial sectors.
knowledge representation
To enhance the LLM’s ability to assess the distribution ACKNOWLEDGMENT
within the mixture, we have integrated a quantifiable proxy
This work was supported by Stiftung der Deutschen Wirtschaft
metric. This metric quantitatively measures the degree of (SDW) and the Ministry of Science, Research and the Arts of the
homogeneity in the distribution. After calculation, this State of Baden-Wuerttemberg within the support of the projects of
indicator is also integrated into the prompt: the Exzellenzinitiative II.
∑𝐷𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦 𝑜𝑓 𝑁𝑒𝑖𝑔ℎ𝑏𝑜𝑟 Special thanks to Yuye Tong for assisting with the preparation of
𝐷𝑒𝑔𝑟𝑒𝑒 𝑜𝑓 𝑒𝑣𝑒𝑛 𝑑𝑖𝑠𝑡𝑟𝑖𝑏𝑢𝑡𝑖𝑜𝑛= the experiment materials.
𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑏𝑎𝑙𝑙𝑠
VI. RESULTS AND DISCUSSION
REFERENCES
[1] D. Dittler, D. Braun, T. Müller, V. Stegmaier, N. Jazdi, and M. Weyrich,
We developed this system, the code and demo video is
“A procedure for the derivation of project-specific intelligent Digital Twin
released on the GitHub repository. The LLM operates implementations in industrial automation,” May 2022.
similarly to a human experimenter within a virtual [2] B. Ashtari Talkhestani et al., “An architecture of an Intelligent Digital
Twin in a Cyber-Physical Production System,” At-
environment, interfacing with a digital twin to achieve an
Automatisierungstechnik, Sep. 2019, doi: 10.1515/AUTO-2019-0039.
objective. [3] Y. Xia, M. Shenoy, N. Jazdi, and M. Weyrich, “Towards autonomous
system: flexible modular production system enhanced with large language
model agents,” in 2023 IEEE 28th ETFA, 2023. doi:
10.1109/ETFA54631.2023.10275362.
[4] Y. Xia, Z. Xiao, N. Jazdi, and M. Weyrich, “Generation of Asset
Administration Shell with Large Language Model Agents: Interoperability
in Digital Twins with Semantic Node,” Mar. 2024, [Online]. Available:
https://arxiv.org/abs/2403.17209v1
[5] P. Häbig et al., “A Modular System Architecture for an Offshore Off-grid
Platform for Climate neutral Power-to-X Production in H2Mare,” May
2023, [Online]. Available: https://arxiv.org/abs/2305.16285v1
[6] J. Wei et al., “Chain of Thought Prompting Elicits Reasoning in Large
Figure 9 The outcomes of experiments from the interaction Language Models,” NeurIPS, 2022.
between LLM and digital twin simulation [7] S. Yao et al., “Tree of Thoughts: Deliberate Problem Solving with Large
The system is capable of executing multiple simulation Language Models,” NeurIPS, 2023, doi: 10.48550/ARXIV.2305.10601.
[8] S. Yao et al., “ReAct: Synergizing Reasoning and Acting in Language
runs, allowing the LLM multi-agent system to explore a range Models,” Oct. 2022, [Online]. Available:
of parameter settings and determine the most effective https://arxiv.org/abs/2210.03629v3
[9] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. K. Openai,
configurations, as demonstrated in Figure 9. This iterative
“Proximal Policy Optimization Algorithms,” Jul. 2017, [Online].
process mirrors the method by which humans apply heuristic Available: https://arxiv.org/abs/1707.06347v2
[10] R. Rafailov, A. Sharma, E. Mitchell, C. D. Manning, S. Ermon, and C.
reasoning to experiment with various configurations in search
Finn, “Direct Preference Optimization: Your Language Model is Secretly a
of an optimal solution. Reward Model,” Advances in NeurIPS, Dec. 2023.
The integration of LLMs into the digital twin framework [11] J. C. Sung Park Joseph O et al., “Generative Agents: Interactive Simulacra
of Human Behavior,” UIST 2023 - Proc. of the 36th Annual ACM Symp.
offers several advantages. Firstly, it enhances user experience
on User Interface Software and Technology, Oct. 2023, doi:
by making interactions more intuitive and automating the 10.1145/3586183.3606763.
parametrization process. Secondly, it lowers the knowledge [12] Y. Li, Y. Zhang, and L. Sun, “MetaAgents: Simulating Interactions of
Human Behaviors for LLM-based Task-oriented Coordination via
barrier, making advanced digital twin technologies accessible
Collaborative Generative Agents,” Oct. 2023, [Online]. Available:
to a wider range of users. This automation significantly https://arxiv.org/abs/2310.06500v1
reduces the need for manual effort in interpreting complex [13] W. Ma et al., “Large Language Models Play StarCraft II: Benchmarks and
A Chain of Summarization Approach,” Dec. 2023, [Online]. Available:
details and performing reasoning tasks, thereby accelerating https://arxiv.org/abs/2312.11865v1
the entire process. Moreover, utilizing a simulated [14] T. Guo et al., “Large Language Model based Multi-Agents: A Survey of
Progress and Challenges,” Jan. 2024, Accessed: May 24, 2024. [Online].
environment for testing provides a risk-free scenario analysis,
Available: https://arxiv.org/abs/2402.01680v2
which minimizes operational risks associated with real-world
testing. Finally, the combined predictive capabilities of LLMs