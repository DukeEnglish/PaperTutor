[
    {
        "title": "Conformal Thresholded Intervals for Efficient Regression",
        "authors": "Rui LuoZhixin Zhou",
        "links": "http://arxiv.org/abs/2407.14495v1",
        "entry_id": "http://arxiv.org/abs/2407.14495v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14495v1",
        "summary": "This paper introduces Conformal Thresholded Intervals (CTI), a novel\nconformal regression method that aims to produce the smallest possible\nprediction set with guaranteed coverage. Unlike existing methods that rely on\nnested conformal framework and full conditional distribution estimation, CTI\nestimates the conditional probability density for a new response to fall into\neach interquantile interval using off-the-shelf multi-output quantile\nregression. CTI constructs prediction sets by thresholding the estimated\nconditional interquantile intervals based on their length, which is inversely\nproportional to the estimated probability density. The threshold is determined\nusing a calibration set to ensure marginal coverage. Experimental results\ndemonstrate that CTI achieves optimal performance across various datasets.",
        "updated": "2024-07-19 17:47:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14495v1"
    },
    {
        "title": "Enhancing Variable Importance in Random Forests: A Novel Application of Global Sensitivity Analysis",
        "authors": "Giulia VannucciRoberta SicilianoAndrea Saltelli",
        "links": "http://arxiv.org/abs/2407.14194v1",
        "entry_id": "http://arxiv.org/abs/2407.14194v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14194v1",
        "summary": "The present work provides an application of Global Sensitivity Analysis to\nsupervised machine learning methods such as Random Forests. These methods act\nas black boxes, selecting features in high--dimensional data sets as to provide\naccurate classifiers in terms of prediction when new data are fed into the\nsystem. In supervised machine learning, predictors are generally ranked by\nimportance based on their contribution to the final prediction. Global\nSensitivity Analysis is primarily used in mathematical modelling to investigate\nthe effect of the uncertainties of the input variables on the output. We apply\nit here as a novel way to rank the input features by their importance to the\nexplainability of the data generating process, shedding light on how the\nresponse is determined by the dependence structure of its predictors. A\nsimulation study shows that our proposal can be used to explore what advances\ncan be achieved either in terms of efficiency, explanatory ability, or simply\nby way of confirming existing results.",
        "updated": "2024-07-19 10:45:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14194v1"
    },
    {
        "title": "Achieving Well-Informed Decision-Making in Drug Discovery: A Comprehensive Calibration Study using Neural Network-Based Structure-Activity Models",
        "authors": "Hannah Rosa FriesacherOla EngkvistLewis MervinYves MoreauAdam Arany",
        "links": "http://arxiv.org/abs/2407.14185v1",
        "entry_id": "http://arxiv.org/abs/2407.14185v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14185v1",
        "summary": "In the drug discovery process, where experiments can be costly and\ntime-consuming, computational models that predict drug-target interactions are\nvaluable tools to accelerate the development of new therapeutic agents.\nEstimating the uncertainty inherent in these neural network predictions\nprovides valuable information that facilitates optimal decision-making when\nrisk assessment is crucial. However, such models can be poorly calibrated,\nwhich results in unreliable uncertainty estimates that do not reflect the true\npredictive uncertainty. In this study, we compare different metrics, including\naccuracy and calibration scores, used for model hyperparameter tuning to\ninvestigate which model selection strategy achieves well-calibrated models.\nFurthermore, we propose to use a computationally efficient Bayesian uncertainty\nestimation method named Bayesian Linear Probing (BLP), which generates\nHamiltonian Monte Carlo (HMC) trajectories to obtain samples for the parameters\nof a Bayesian Logistic Regression fitted to the hidden layer of the baseline\nneural network. We report that BLP improves model calibration and achieves the\nperformance of common uncertainty quantification methods by combining the\nbenefits of uncertainty estimation and probability calibration methods.\nFinally, we show that combining post hoc calibration method with\nwell-performing uncertainty quantification approaches can boost model accuracy\nand calibration.",
        "updated": "2024-07-19 10:29:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14185v1"
    },
    {
        "title": "On Policy Evaluation Algorithms in Distributional Reinforcement Learning",
        "authors": "Julian GerstenbergRalph NeiningerDenis Spiegel",
        "links": "http://arxiv.org/abs/2407.14175v1",
        "entry_id": "http://arxiv.org/abs/2407.14175v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14175v1",
        "summary": "We introduce a novel class of algorithms to efficiently approximate the\nunknown return distributions in policy evaluation problems from distributional\nreinforcement learning (DRL). The proposed distributional dynamic programming\nalgorithms are suitable for underlying Markov decision processes (MDPs) having\nan arbitrary probabilistic reward mechanism, including continuous reward\ndistributions with unbounded support being potentially heavy-tailed.\n  For a plain instance of our proposed class of algorithms we prove error\nbounds, both within Wasserstein and Kolmogorov--Smirnov distances. Furthermore,\nfor return distributions having probability density functions the algorithms\nyield approximations for these densities; error bounds are given within\nsupremum norm. We introduce the concept of quantile-spline discretizations to\ncome up with algorithms showing promising results in simulation experiments.\n  While the performance of our algorithms can rigorously be analysed they can\nbe seen as universal black box algorithms applicable to a large class of MDPs.\nWe also derive new properties of probability metrics commonly used in DRL on\nwhich our quantitative analysis is based.",
        "updated": "2024-07-19 10:06:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14175v1"
    },
    {
        "title": "MSCT: Addressing Time-Varying Confounding with Marginal Structural Causal Transformer for Counterfactual Post-Crash Traffic Prediction",
        "authors": "Shuang LiZiyuan PuNan ZhangDuxin ChenLu DongDaniel J. GrahamYinhai Wang",
        "links": "http://arxiv.org/abs/2407.14065v1",
        "entry_id": "http://arxiv.org/abs/2407.14065v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14065v1",
        "summary": "Traffic crashes profoundly impede traffic efficiency and pose economic\nchallenges. Accurate prediction of post-crash traffic status provides essential\ninformation for evaluating traffic perturbations and developing effective\nsolutions. Previous studies have established a series of deep learning models\nto predict post-crash traffic conditions, however, these correlation-based\nmethods cannot accommodate the biases caused by time-varying confounders and\nthe heterogeneous effects of crashes. The post-crash traffic prediction model\nneeds to estimate the counterfactual traffic speed response to hypothetical\ncrashes under various conditions, which demonstrates the necessity of\nunderstanding the causal relationship between traffic factors. Therefore, this\npaper presents the Marginal Structural Causal Transformer (MSCT), a novel deep\nlearning model designed for counterfactual post-crash traffic prediction. To\naddress the issue of time-varying confounding bias, MSCT incorporates a\nstructure inspired by Marginal Structural Models and introduces a balanced loss\nfunction to facilitate learning of invariant causal features. The proposed\nmodel is treatment-aware, with a specific focus on comprehending and predicting\ntraffic speed under hypothetical crash intervention strategies. In the absence\nof ground-truth data, a synthetic data generation procedure is proposed to\nemulate the causal mechanism between traffic speed, crashes, and covariates.\nThe model is validated using both synthetic and real-world data, demonstrating\nthat MSCT outperforms state-of-the-art models in multi-step-ahead prediction\nperformance. This study also systematically analyzes the impact of time-varying\nconfounding bias and dataset distribution on model performance, contributing\nvaluable insights into counterfactual prediction for intelligent transportation\nsystems.",
        "updated": "2024-07-19 06:42:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14065v1"
    }
]