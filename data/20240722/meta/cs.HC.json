[
    {
        "title": "AudioInsight: Detecting Social Contexts Relevant to Social Anxiety from Speech",
        "authors": "Varun ReddyZhiyuan WangEmma TonerMax LarrazabalMehdi BoukhechbaBethany A. TeachmanLaura E. Barnes",
        "links": "http://arxiv.org/abs/2407.14458v1",
        "entry_id": "http://arxiv.org/abs/2407.14458v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14458v1",
        "summary": "During social interactions, understanding the intricacies of the context can\nbe vital, particularly for socially anxious individuals. While previous\nresearch has found that the presence of a social interaction can be detected\nfrom ambient audio, the nuances within social contexts, which influence how\nanxiety provoking interactions are, remain largely unexplored. As an\nalternative to traditional, burdensome methods like self-report, this study\npresents a novel approach that harnesses ambient audio segments to detect\nsocial threat contexts. We focus on two key dimensions: number of interaction\npartners (dyadic vs. group) and degree of evaluative threat (explicitly\nevaluative vs. not explicitly evaluative). Building on data from a Zoom-based\nsocial interaction study (N=52 college students, of whom the majority N=45 are\nsocially anxious), we employ deep learning methods to achieve strong detection\nperformance. Under sample-wide 5-fold Cross Validation (CV), our model\ndistinguished dyadic from group interactions with 90\\% accuracy and detected\nevaluative threat at 83\\%. Using a leave-one-group-out CV, accuracies were 82\\%\nand 77\\%, respectively. While our data are based on virtual interactions due to\npandemic constraints, our method has the potential to extend to diverse\nreal-world settings. This research underscores the potential of passive sensing\nand AI to differentiate intricate social contexts, and may ultimately advance\nthe ability of context-aware digital interventions to offer personalized mental\nhealth support.",
        "updated": "2024-07-19 17:01:12 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14458v1"
    },
    {
        "title": "From Instruction to Insight: Exploring the Functional and Semantic Roles of Text in Interactive Dashboards",
        "authors": "Nicole SultanumVidya Setlur",
        "links": "http://arxiv.org/abs/2407.14451v1",
        "entry_id": "http://arxiv.org/abs/2407.14451v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14451v1",
        "summary": "There is increased interest in the interplay between text and visuals in the\nfield of data visualization. However, this attention has predominantly been on\nthe use of text in standalone visualizations or augmenting text stories\nsupported by a series of independent views. In this paper, we shift from the\ntraditional focus on single-chart annotations to characterize the nuanced but\ncrucial communication role of text in the complex environment of interactive\ndashboards. Through a survey and analysis of 190 dashboards in the wild, plus\n13 expert interview sessions with experienced dashboard authors, we highlight\nthe distinctive nature of text as an integral component of the dashboard\nexperience, while delving into the categories, semantic levels, and functional\nroles of text, and exploring how these text elements are coalesced by dashboard\nauthors to guide and inform dashboard users.\n  Our contributions are: 1) we distill qualitative and quantitative findings\nfrom our studies to characterize current practices of text use in dashboards,\nincluding a categorization of text-based components and design patterns; 2) we\nleverage current practices and existing literature to propose, discuss, and\nvalidate recommended practices for text in dashboards, embodied as 12\nheuristics that underscore the semantic and functional role of text in offering\nnavigational cues, contextualizing data insights, supporting reading order,\netc; 3) we reflect on our findings to identify gaps and propose opportunities\nfor data visualization researchers to push the boundaries on text usage for\ndashboards, from authoring support and interactivity to text generation and\ncontent personalization.\n  Our research underscores the significance of elevating text as a first-class\ncitizen in data visualization, and the need to support the inclusion of textual\ncomponents and their interactive affordances in dashboard design.",
        "updated": "2024-07-19 16:48:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14451v1"
    },
    {
        "title": "Exploring Indoor Air Quality Dynamics in Developing Nations: A Perspective from India",
        "authors": "Prasenjit KarmakarSwadhin PradhanSandip Chakraborty",
        "links": "http://arxiv.org/abs/2407.14393v1",
        "entry_id": "http://arxiv.org/abs/2407.14393v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14393v1",
        "summary": "Indoor air pollution is a major issue in developing countries such as India\nand Bangladesh, exacerbated by factors like traditional cooking methods,\ninsufficient ventilation, and cramped living conditions, all of which elevate\nthe risk of health issues like lung infections and cardiovascular diseases.\nWith the World Health Organization associating around 3.2 million annual deaths\nglobally to household air pollution, the gravity of the problem is clear. Yet,\nextensive empirical studies exploring these unique patterns and indoor\npollutions extent are missing. To fill this gap, we carried out a six months\nlong field study involving over 30 households, uncovering the complexity of\nindoor air pollution in developing countries, such as the longer lingering time\nof VOCs in the air or the significant influence of air circulation on the\nspatiotemporal distribution of pollutants. We introduced an innovative IoT air\nquality sensing platform, the Distributed Air QuaLiTy MONitor (DALTON ),\nexplicitly designed to meet the needs of these nations, considering factors\nlike cost, sensor type, accuracy, network connectivity, power, and usability.\nAs a result of a multi-device deployment, the platform identifies pollution\nhot-spots in low and middle-income households in developing nations. It\nidentifies best practices to minimize daily indoor pollution exposure. Our\nextensive qualitative survey estimates an overall system usability score of\n2.04, indicating an efficient system for air quality monitoring.",
        "updated": "2024-07-19 15:15:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14393v1"
    },
    {
        "title": "As Generative Models Improve, People Adapt Their Prompts",
        "authors": "Eaman JahaniBenjamin S. ManningJoe ZhangHong-Yi TuYeMohammed AlsobayChristos NicolaidesSiddharth SuriDavid Holtz",
        "links": "http://arxiv.org/abs/2407.14333v1",
        "entry_id": "http://arxiv.org/abs/2407.14333v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14333v1",
        "summary": "In an online experiment with N = 1891 participants, we collected and analyzed\nover 18,000 prompts to explore how the importance of prompting will change as\nthe capabilities of generative AI models continue to improve. Each participant\nin our experiment was randomly and blindly assigned to use one of three\ntext-to-image diffusion models: DALL-E 2, its more advanced successor DALL-E 3,\nor a version of DALL-E 3 with automatic prompt revision. Participants were then\nasked to write prompts to reproduce a target image as closely as possible in 10\nconsecutive tries. We find that task performance was higher for participants\nusing DALL-E 3 than for those using DALL-E 2. This performance gap corresponds\nto a noticeable difference in the similarity of participants' images to their\ntarget images, and was caused in equal measure by: (1) the increased technical\ncapabilities of DALL-E 3, and (2) endogenous changes in participants' prompting\nin response to these increased capabilities. More specifically, despite being\nblind to the model they were assigned, participants assigned to DALL-E 3 wrote\nlonger prompts that were more semantically similar to each other and contained\na greater number of descriptive words. Furthermore, while participants assigned\nto DALL-E 3 with prompt revision still outperformed those assigned to DALL-E 2,\nautomatic prompt revision reduced the benefits of using DALL-E 3 by 58%. Taken\ntogether, our results suggest that as models continue to progress, people will\ncontinue to adapt their prompts to take advantage of new models' capabilities.",
        "updated": "2024-07-19 14:13:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14333v1"
    },
    {
        "title": "Experiences of Censorship on TikTok Across Marginalised Identities",
        "authors": "Eddie L. UnglessNina MarklBjörn Ross",
        "links": "http://arxiv.org/abs/2407.14164v1",
        "entry_id": "http://arxiv.org/abs/2407.14164v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14164v1",
        "summary": "TikTok has seen exponential growth as a platform, fuelled by the success of\nits proprietary recommender algorithm which serves tailored content to every\nuser - though not without controversy. Users complain of their content being\nunfairly suppressed by ''the algorithm'', particularly users with marginalised\nidentities such as LGBTQ+ users. Together with content removal, this\nsuppression acts to censor what is shared on the platform. Journalists have\nrevealed biases in automatic censorship, as well as human moderation. We\ninvestigate experiences of censorship on TikTok, across users marginalised by\ntheir gender, LGBTQ+ identity, disability or ethnicity. We survey 627 UK-based\nTikTok users and find that marginalised users often feel they are subject to\ncensorship for content that does not violate community guidelines. We highlight\nmany avenues for future research into censorship on TikTok, with a focus on\nusers' folk theories, which greatly shape their experiences of the platform.",
        "updated": "2024-07-19 09:50:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14164v1"
    }
]