[
    {
        "title": "The Vision of Autonomic Computing: Can LLMs Make It a Reality?",
        "authors": "Zhiyang ZhangFangkai YangXiaoting QinJue ZhangQingwei LinGong ChengDongmei ZhangSaravan RajmohanQi Zhang",
        "links": "http://arxiv.org/abs/2407.14402v1",
        "entry_id": "http://arxiv.org/abs/2407.14402v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14402v1",
        "summary": "The Vision of Autonomic Computing (ACV), proposed over two decades ago,\nenvisions computing systems that self-manage akin to biological organisms,\nadapting seamlessly to changing environments. Despite decades of research,\nachieving ACV remains challenging due to the dynamic and complex nature of\nmodern computing systems. Recent advancements in Large Language Models (LLMs)\noffer promising solutions to these challenges by leveraging their extensive\nknowledge, language understanding, and task automation capabilities. This paper\nexplores the feasibility of realizing ACV through an LLM-based multi-agent\nframework for microservice management. We introduce a five-level taxonomy for\nautonomous service maintenance and present an online evaluation benchmark based\non the Sock Shop microservice demo project to assess our framework's\nperformance. Our findings demonstrate significant progress towards achieving\nLevel 3 autonomy, highlighting the effectiveness of LLMs in detecting and\nresolving issues within microservice architectures. This study contributes to\nadvancing autonomic computing by pioneering the integration of LLMs into\nmicroservice management frameworks, paving the way for more adaptive and\nself-managing computing systems. The code will be made available at\nhttps://aka.ms/ACV-LLM.",
        "updated": "2024-07-19 15:30:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14402v1"
    },
    {
        "title": "Multi-robot maze exploration using an efficient cost-utility method",
        "authors": "Manousos LinardakisIraklis VarlamisGeorgios Th. Papadopoulos",
        "links": "http://arxiv.org/abs/2407.14218v1",
        "entry_id": "http://arxiv.org/abs/2407.14218v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14218v1",
        "summary": "In the field of modern robotics, robots are proving to be useful in tackling\nhigh-risk situations, such as navigating hazardous environments like burning\nbuildings, earthquake-stricken areas, or patrolling crime-ridden streets, as\nwell as exploring uncharted caves. These scenarios share similarities with maze\nexploration problems in terms of complexity. While several methods have been\nproposed for single-agent systems, ranging from potential fields to flood-fill\nmethods, recent research endeavors have focused on creating methods tailored\nfor multiple agents to enhance the quality and efficiency of maze coverage. The\ncontribution of this paper is the implementation of established maze\nexploration methods and their comparison with a new cost-utility algorithm\ndesigned for multiple agents, which combines the existing methodologies to\noptimize exploration outcomes. Through a comprehensive and comparative\nanalysis, this paper evaluates the performance of the new approach against the\nimplemented baseline methods from the literature, highlighting its efficacy and\npotential advantages in various scenarios. The code and experimental results\nsupporting this study are available in the following repository\n(https://github.com/manouslinard/multiagent-exploration/).",
        "updated": "2024-07-19 11:35:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14218v1"
    },
    {
        "title": "Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication",
        "authors": "Pouya AgheliNikolaos PappasPetar PopovskiMarios Kountouris",
        "links": "http://arxiv.org/abs/2407.14092v1",
        "entry_id": "http://arxiv.org/abs/2407.14092v1",
        "pdf_url": "http://arxiv.org/pdf/2407.14092v1",
        "summary": "This paper studies decision-making for goal-oriented effective communication.\nWe consider an end-to-end status update system where a sensing agent (SA)\nobserves a source, generates and transmits updates to an actuation agent (AA),\nwhile the AA takes actions to accomplish a goal at the endpoint. We integrate\nthe push- and pull-based update communication models to obtain a push-and-pull\nmodel, which allows the transmission controller at the SA to decide to push an\nupdate to the AA and the query controller at the AA to pull updates by raising\nqueries at specific time instances. To gauge effectiveness, we utilize a grade\nof effectiveness (GoE) metric incorporating updates' freshness, usefulness, and\ntimeliness of actions as qualitative attributes. We then derive effect-aware\npolicies to maximize the expected discounted sum of updates' effectiveness\nsubject to induced costs. The effect-aware policy at the SA considers the\npotential effectiveness of communicated updates at the endpoint, while at the\nAA, it accounts for the probabilistic evolution of the source and importance of\ngenerated updates. Our results show the proposed push-and-pull model\noutperforms models solely based on push- or pull-based updates both in terms of\nefficiency and effectiveness. Additionally, using effect-aware policies at both\nagents enhances effectiveness compared to periodic and/or probabilistic\neffect-agnostic policies at either or both agents.",
        "updated": "2024-07-19 07:57:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.14092v1"
    },
    {
        "title": "Matching-Driven Deep Reinforcement Learning for Energy-Efficient Transmission Parameter Allocation in Multi-Gateway LoRa Networks",
        "authors": "Ziqi LinXu ZhangShimin GongLanhua LiZhou SuBo Gu",
        "links": "http://arxiv.org/abs/2407.13076v1",
        "entry_id": "http://arxiv.org/abs/2407.13076v1",
        "pdf_url": "http://arxiv.org/pdf/2407.13076v1",
        "summary": "Long-range (LoRa) communication technology, distinguished by its low power\nconsumption and long communication range, is widely used in the Internet of\nThings. Nevertheless, the LoRa MAC layer adopts pure ALOHA for medium access\ncontrol, which may suffer from severe packet collisions as the network scale\nexpands, consequently reducing the system energy efficiency (EE). To address\nthis issue, it is critical to carefully allocate transmission parameters such\nas the channel (CH), transmission power (TP) and spreading factor (SF) to each\nend device (ED). Owing to the low duty cycle and sporadic traffic of LoRa\nnetworks, evaluating the system EE under various parameter settings proves to\nbe time-consuming. Consequently, we propose an analytical model aimed at\ncalculating the system EE while fully considering the impact of multiple\ngateways, duty cycling, quasi-orthogonal SFs and capture effects. On this\nbasis, we investigate a joint CH, SF and TP allocation problem, with the\nobjective of optimizing the system EE for uplink transmissions. Due to the\nNP-hard complexity of the problem, the optimization problem is decomposed into\ntwo subproblems: CH assignment and SF/TP assignment. First, a matching-based\nalgorithm is introduced to address the CH assignment subproblem. Then, an\nattention-based multiagent reinforcement learning technique is employed to\naddress the SF/TP assignment subproblem for EDs allocated to the same CH, which\nreduces the number of learning agents to achieve fast convergence. The\nsimulation outcomes indicate that the proposed approach converges quickly under\nvarious parameter settings and obtains significantly better system EE than\nbaseline algorithms.",
        "updated": "2024-07-18 00:54:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.13076v1"
    },
    {
        "title": "Information Compression in Dynamic Games",
        "authors": "Dengwang TangVijay SubramanianDemosthenis Teneketzis",
        "links": "http://arxiv.org/abs/2407.12318v1",
        "entry_id": "http://arxiv.org/abs/2407.12318v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12318v1",
        "summary": "One of the reasons why stochastic dynamic games with an underlying dynamic\nsystem are challenging is since strategic players have access to enormous\namount of information which leads to the use of extremely complex strategies at\nequilibrium. One approach to resolve this challenge is to simplify players'\nstrategies by identifying appropriate compression of information maps so that\nthe players can make decisions solely based on the compressed version of\ninformation, called the information state. For finite dynamic games with\nasymmetric information, inspired by the notion of information state for\nsingle-agent control problems, we propose two notions of information states,\nnamely mutually sufficient information (MSI) and unilaterally sufficient\ninformation (USI). Both these information states are obtained with information\ncompression maps independent of the strategy profile. We show that Bayes-Nash\nEquilibria (BNE) and Sequential Equilibria (SE) exist when all players use\nMSI-based strategies. We prove that when all players employ USI-based\nstrategies the resulting sets of BNE and SE payoff profiles are the same as the\nsets of BNE and SE payoff profiles resulting when all players use full\ninformation-based strategies. We prove that when all players use USI-based\nstrategies the resulting set of weak Perfect Bayesian Equilibrium (wPBE) payoff\nprofiles can be a proper subset of all wPBE payoff profiles. We identify MSI\nand USI in specific models of dynamic games in the literature. We end by\npresenting an open problem: Do there exist strategy-dependent information\ncompression maps that guarantee the existence of at least one equilibrium or\nmaintain all equilibria that exist under perfect recall? We show, by a\ncounterexample, that a well-known strategy-dependent information compression\nmap used in the literature does not possess any of the properties of MSI or\nUSI.",
        "updated": "2024-07-17 05:08:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12318v1"
    }
]