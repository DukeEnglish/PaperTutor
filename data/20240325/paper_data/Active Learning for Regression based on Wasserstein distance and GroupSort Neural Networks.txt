Active Learning for Regression based on
Wasserstein distance and GroupSort Neural
Networks
Bobbia Benjamin, Picard Matthias
March 25, 2024
Abstract
Thispaperaddressesanewactivelearningstrategyforregressionprob-
lems. The presented Wasserstein active regression model is based on the
principles of distribution-matching to measure the representativeness of
the labeled dataset. The Wasserstein distance is computed using Group-
Sort Neural Networks. The use of such networks provides theoretical
foundationsgivingawaytoquantifyerrorswithexplicitboundsfortheir
sizeanddepth. Thissolutioniscombinedwithanotheruncertainty-based
approachthatismoreoutlier-toleranttocompletethequerystrategy. Fi-
nally, this method is compared with other classical and recent solutions.
The study empirically shows the pertinence of such a representativity-
uncertaintyapproach,whichprovidesgoodestimationallalongthequery
procedure. Moreover, the Wasserstein active regression often achieves
morepreciseestimationsandtendstoimproveaccuracyfasterthanother
models.
1 Introduction
Collectingdataisasignificantchallengeinmachinelearning,andmoregenerally
in statistics. The amount of data necessary to get a sharp estimation of a
function can get unreasonably high, especially when the task involves high-
dimensional objects. In various applications, extracting and gathering enough
unlabeled data is not a big challenge. However, labeling them can be a very
costly and time-consuming process. In fields such as statistical physics, we
would often need to run complex simulations or call an expert to label data
manually. Hence we want to be able to get a satisfying estimation with a more
compactsetoflabeleddata. Amongtheproposedsolutions,wecanmentionfew-
shot learning (Li et al., 2006) and transfer learning (Ben-David et al., 2010).
Those solutions leverage from another model previously trained on a similar
task to simplify our model’s training. To dodge the issue, we can also resort
to generative adversarial models (Goodfellow et al., 2014) or diffusion models
(Trabucco et al., 2023): the idea is to augment a dataset using generated data,
1
4202
raM
22
]GL.sc[
1v80151.3042:viXrathese approaches need to learn not only the targeted task but how to create
new data and criticize them to prevent the addition of incoherent points into
the pool. In this paper, we will take another approach called active learning.
In this framework, we can call an “oracle” that has the ability to label samples
of our data with a certain cost. The keystone of this learning procedure is to
find the most relevant samples that both maximize the performances of the
estimator and minimize the query cost.
1.1 Active Learning framework and notations
Weareinterestedinperformingactivelearningforaregressiontaskusingpool-
based sampling. We consider an unknown function h from Rd to R. We aim
to estimate h given a sample (X ,Y )n of i.i.d copies of the random variables
i i i=1
(X,Y) ∈ Rd×R with Y = h(X). We call P the unknown distribution of X.
X
Inourframework,notallvaluesY areobservedforeveryvalueX . Thesample
i i
(X ,Y )n can be divided into two subsets K and U (respectively for known
i i i=1
and unknown values of h(X)) such that for all X ∈K the value of h(X )=Y
i i i
is observed but not for X ∈ U. The most natural setup which requires active
i
learning is when K (of size n ) is significantly smaller than U (of size n ) and
K U
not large enough to allow a fairly good estimation of h. Finally, hˆ denotes an
estimator of h. In this paper, the estimator hˆ is chosen to belong to one class
of neural networks. However, the methodology developed here focuses mainly
on the query step. Hence it can be adapted to other classes of estimators hˆ.
The error made by hˆ is measured with a strictly convex loss function l from
R2 to[0,+∞). Theestimatorofhischosenasaminimumoftheexpectederror
risk:
(cid:16) (cid:17)
R (hˆ)=E l(hˆ(X),Y)) (1)
PX
Obviously, since the probability measure P is unknown, the explicit compu-
X
tation of R (hˆ) is hopeless. Hence, we are going to define hˆ minimizing the
PX
empirical counterpart of the expected error risk:
n
RP n(hˆ)= n1 (cid:88) l(hˆ(X i),Y i) (2)
i=1
where P denotes the empirical measure of (X ,...,X ):
n 1 n
n
1 (cid:88)
δ .
n Xi
i=1
Since most values Y
i
are unobserved, RP n(hˆ) is uncomputable. Hence our pur-
pose is to find out a batch B ⊂ U with a fixed size n providing the best
B
improvementoftheestimationofhonK∪B comparedtotheestimationusing
only K. After choosing B, we would need to send it to the oracle to label it.
In pool-based active learning, the idea is to accomplish this task by leveraging
our pool of unlabelled data U. During the past years, several options to iden-
tify the best batch to query have been explored: the first method proposed by
2(Lewis and Gale, 1994) consisted in querying the points with the highest pre-
diction uncertainty (uncertainty-based sampling). Numerous derived strategies
were investigated: targeting points with the highest expected error (Roy and
McCallum, 2001), expected variance (Zhang and Oles, 2000), or cross-entropy
(Shannon, 2001) when selecting the batch. Other approaches like query-by-
committee (Burbidge et al., 2007) or greedy sampling (Wu et al., 2019) tried
not only to focus on the reduction of the model error but also on the prospect
of adding diversity in the choice of B to get a pool more representative of the
underlying distribution. We refer to the monography (Settles, 2012) and the
survey (Ren et al., 2020) for overall information about active learning and de-
tails on query strategies. A more recent idea that has shown some good results
istodirectlycreatearepresentativeness-basedmodelbyselectingB usingprob-
abilitydistributionmatching(Shuietal.,2020). Theaimistolabelthesamples
that will minimize the distance between P and P . This means that we
X K∪B
achieve a selection of the best empirical representation of P among empirical
X
measures of size n +n (according to the chosen distance). Afterward, we
K B
send the batch B to the oracle to get the value of h(X ) for X ∈ B and learn
i i
hˆ as the minimum of:
R (hˆ)= 1 (cid:88) l(hˆ(x),Y ) (3)
PK∪B n +n i
B K
x∈K∪B
This process can be iterated as long as there is still enough unlabelled data
and enough budget.
Inthefollowing,thedifferencebetweenprobabilitydistributionsismeasured
using the Wasserstein distance, which has already proven efficient in classifica-
tion tasks (Shui et al., 2020).
1.2 The Wasserstein distance
Definition 1. Let P and Q two probability measures on a metric space (X,c).
For p∈[1,∞[, the Wasserstein distance of order p between P and Q is defined
as
W (P,Q)=inf{E(c(X,Y)p)1/p, X ∼P,Y ∼Q}. (4)
p
Note that the Wasserstein distance is a proper distance only on the sub-
set of probability measures P such that there exists a point x ∈ X where
0
(cid:82) c(x,x )pP(dx) < ∞. In our active learning framework, this is not an issue:
X 0
since we are focusing on using the 1-Wasserstein distance, this condition only
requiresassumingthatP hasafiniteexpectation. Thefirst-orderWasserstein
X
distance is of main interest since it can be expressed as a supremum over all
1-Lipschitz functions with respect to the distance c using the following propo-
sition:
Proposition 1 (Kantorovich-Rubinstein duality (C´edric, 2009)). Let P and
Q two probability measures on the same space X, and c a cost function. The
31-order Wasserstein distance is defined as
(cid:90) (cid:90)
W (P,Q)=sup φ dP − φ dQ. (5)
1
φ X X
Where the supremum is taken over all 1−Lipschitz functions with respect to the
cost c, namely |φ(x)−φ(y)|≤c(x,y) for all x,y ∈X.
The present formulation is a dual formula holding only for the 1-order
Wasserstein distance. It is much more interpretable and easier to compute
than the original definition. In the present work, we are only working with this
formulation. Hence we can regard it as a definition.
Even if the proper value of a Wasserstein distance cannot be interpreted
by itself, it characterizes the weak convergence of probability distributions (see
e.g.(C´edric, 2009)), which guaranty the convergence of our method. Moreover,
the existence of large deviation bounds and generally good behavior with re-
specttoLipschitzfunctionsmayhelptoprovidearateofconvergence(Fournier
and Guillin, 2015) but we let this for future works. We can also refer to the
monography (Panaretos and Zemel, 2020) for other useful examples of its use
in statistics.
2 Wasserstein Active Regression
2.1 Theoretical foundations
Before introducing the proper model, some necessary assumptions about the
mathematical background of the approach are stated. We first assume that
the random variable X takes its values in X which is a compact subset of Rd
endowedwithanorm∥.∥. Thisisratherintuitiveandallowstheuseofnumerous
resultsaboutLipschitzapproximations. Toprovethenexttheorem,wewillalso
have to assume that the target function and the cost function are 1-Lipschitz
respectivelywithrespectto∥.∥andtheL1 norm. Thesecanseemlikerestrictive
conditions, but we will see later that we can get rid of them in practice. The
following theorem (closely related to (Shui et al., 2020)) acts as a guideline for
the presented approach.
Theorem 1. If the functions hˆ and G : x ∈ X → l(hˆ(x),h(x)) are 1-Lipschitz
functions, we have:
|R (hˆ)−R (hˆ)|≤W (P ,P ) (6)
PX PK∪B 1 X K∪B
Proof. By definition of G, we can write
(cid:12)(cid:90) (cid:90) (cid:12)
|R PX(hˆ)−R PK∪B(hˆ)|=(cid:12) (cid:12)
(cid:12)
G dP X − G dP K∪B(cid:12) (cid:12)
(cid:12)
X X
(cid:12)(cid:90) (cid:90) (cid:12)
(cid:12) (cid:12)
≤ sup (cid:12) φ dP X − φ dP K∪B(cid:12).
(cid:12) (cid:12)
φ∈Lip1 X X
4The Kantorovich-Rubinstein duality directly leads to the result.
Working with Lipschitz functions offers several benefits. On the one hand,
theyarenecessarytocomputetheWassersteindistance(whenusingtheKantorovich-
Rubinstein duality). On the other hand, they are robust and help us prevent
overfitting on the estimation of h. More precisely, for ε > 0, if for x, y ∈ X
such that ∥x−y∥ ≤ ε then ∥hˆ(x)−hˆ(y)∥ ≤ ε hence the robustness. The pro-
tection against overfitting might be less easy to see. Consider a point y such
that |h(y)−hˆ(y)|≤ δ for a given δ > 0. Then for all x such that ∥x−y∥≤ ε,
the triangular inequality entails |hˆ(x)−h(x)|≤2ε+δ. As a consequence, even
if an observation of h(x) is very noisy, this noise can’t affect much the estima-
tion as long as there exists another point in a neighborhood of x with a sharp
estimation.
Remark1. Wecangeneralizetheassumptionspreviouslypresentedtoestimate
any Lipschitz functions with this model. Indeed, the cornerstone of theorem 1
is that G is 1-Lipschitz. Hence, if h is λ -Lipschitz, hˆ is λ -Lipschitz and the
1 2
loss function l is λ-Lipschitz, then for x,y ∈X
|G(x)−G(y)|=|l(hˆ(x),h(x))−l(hˆ(y),h(y))| (7)
≤λ(λ(|h(x)−h(y)|+|hˆ(x)−hˆ(y)|)) (8)
≤λ ∥x−y∥+λ ∥x−y∥ (9)
1 2
=λ(λ +λ )∥x−y∥. (10)
1 2
ItisenoughtodivideGbyλ +λ togeta1-Lipschitzfunction. Actually,wecan
1 2
completelyremovethisfactorbecausetheprocessofminimizingthecostfunction
will not change, with or without it. So in practice, it is not taken into account,
the only constraint is that hˆ and h should be Lipschitz. This is not restrictive
since we assume X to be compact. Indeed, any piecewise differentiable functions
on compact sets are Lipschitz.
Corollary 1. Assume that E(Xd/2+2) < ∞, then for any batch B ⊂ U, we
have:
(cid:18) (cid:19)
1
|R PX(hˆ)−RP K∪B(hˆ)|≤W 1(P n,P K∪B)+OP
nd/2
. (11)
Proof. The triangular inequality gives
W (P ,P )≤ W (P ,P )+W (P ,P ).
1 X K∪B 1 X n 1 n K∪B
For any ε ∈ (0,1), Theorem 2 from (Fournier and Guillin, 2015) applied to
W (P ,P ) provides the existence of positive constants α and β not depending
1 X n
on n such that
ε1−d/2
P(W (P ,P )>ε)≤αe−βnεd +α .
1 X n nd/2
Hence the result.
5Remark 2. The assumption E(Xd/2+2)<∞ can be relaxed, in fact result from
(Dudley, 1969) allows to show that convergence remains true but with a speed
of convergence in n−1/d. Which is much worst especially in the case of high
dimensional covariates.
This bound, based on the result from (Fournier and Guillin, 2015), suggests
that making W 1(P n,P K∪B) decrease may reduce the gap between RP K∪B(hˆ)
and RP X(hˆ). Another advantage of this formulation is that W 1(P n,P K∪B) is
computable whereas W (P ,P ) is not.
1 X K∪B
Remark 3. Note that the distance W (P ,P ) may be small with respect to
1 n K∪B
OP(cid:0) 1 (cid:1) ,especiallywhenthesubsetK islargewithrespecttoU. However,this
nd/2
is not the range that is focused on this active learning procedure. In addition,
the term OP(cid:0) 1 (cid:1) does not depend on B, as a consequence it can be interpreted
nd/2
as the remaining error bound after all the dataset has been queried.
Wecanrewritethecorollary1toidentifythemilestonesofouractivelearning
strategy:
R PX(hˆ)≤RP K∪B(hˆ)+W 1(P n,P K∪B)+c n, (12)
withc notdependingonB. HencetheminimizationofR (hˆ)canbeachieved
n PX
by optimizing the right-hand side of inequality (12) on hˆ and B. This leads to
the construction of two criteria for the batch selection. More precisely, a score
function S is considered, and points x ∈ U maximizing this score are added
to the batch. In the active learning framework, such a function is often called
an acquisition function. The bound (12) leads to the consideration of a score
function of the form:
S(x)=r(x)+w(x), x∈U, (13)
were r relies on the minimization of RP (hˆ) whereas w relies on the Wasser-
K∪B
steindistance. Notethatthereisnocounterparttotheconstantc inthescore
n
function since this constant does not depend on B. The construction of the
functions r and w are detailed in the following sections.
2.2 Training the estimator
To achieve the learning step, we minimize the term R (hˆ) defined as:
PK
R (hˆ)= 1 (cid:88) l(hˆ(x),h(x)) (14)
PK n
K
x∈K
with respect to hˆ. Afterward, we will query data by using a hybrid strategy
based on two criteria: we want to pick the batch B that makes W (P ,P )
1 n K∪B
decreases the most, and we also want to maximize the uncertainty of hˆ in order
to encourage our model to train on data where hˆ struggles at estimating the
right labels. Intuitively, the batch B has to be composed of points containing
as much information as possible about the underlying data distribution and
located in places where hˆ can still improve its estimations.
6Figure 1: Values of φ on a labelled and an unlabelled distribution in [0,1]
2.3 Minimizing the Wasserstein distance
Consideringthefirstcriterion, itisclearlyunreasonabletocomputeallWasser-
stein distances W (P ,P ) for each possible B. To tackle this issue we
1 n K∪B
compute the Wasserstein distance using the Kantorovitch-Rubinstein duality
between P and P by maximizing Wˆ defined as
n K
(cid:12)(cid:90) (cid:90) (cid:12)
Wˆ(φ)=(cid:12) (cid:12) φ dP n− φ dP K(cid:12) (cid:12) (15)
(cid:12) (cid:12)
X X
(cid:12) (cid:12)
(cid:12)1 (cid:88)n 1 (cid:88) (cid:12)
=(cid:12) φ(X )− φ(x)(cid:12) (16)
(cid:12)n i n (cid:12)
(cid:12) K (cid:12)
i=1 x∈K
with φ belonging to the set of 1-Lipschitz functions. Note that the maximisa-
tion of Wˆ allows to approximate the Wassserstein distance since W (P ,P )=
1 n K
sup{Wˆ(φ) | φ is 1-Lipschitz}. From a practical point of view, φ is a neural
network that we optimize by using Wˆ as a cost function. The function φ hence
obtainedentirelycharacterizesW (P ,P ). TominimizeW (P ,P ),wehave
1 n K 1 n K
to choose the batch B belonging to U that maximizes φ, and add it to K by
labeling it.
We can deduce from Equation (16) that the maximization of Wˆ(φ) involves
the minimization of φ near points in K, and its maximization near points in U.
Becauseφmustbe1-Lipschitz,thefluctuationsofthefunctionareconstrained.
Anintuitiveconsequenceisthatφhastomakecompromises: somepointsmust
be ”ignored” in order to be maximum near more relevant locations. Indeed, φ
tends to take its highest values (respectively, lowest) near clusters of unlabelled
points (respectively, labeled points). However, if there are no labeled points
in the neighborhood, φ can increase without restrictions. These behaviors are
illustrated in the figure below:
Here,φismaximizedforunlabelledpointsthatareveryfarfromanylabeled
points,orpackedinacluster. Consequently,inthecontextofactivelearning,we
7canusetheWassersteindistanceasadiversity-basedandrepresentativity-based
sampling method.
In order to guarantee a proper estimation of the Wasserstein distance, we
have to impose φ to be a 1-Lipschitz function. A classic method would be to
penalizethegradientofφforenforcingitsboundedness(Gulrajanietal.,2017),
(Gouketal.,2021). But,inthiscase,wemayunderestimatetheWassersteindis-
tance in a proportion that we can’t quantify (to our knowledge). Consequently,
we chose to use Group Sort Neural Networks, which present good properties
for the estimation of 1−Lipschitz functions (see section 3 for the definition and
mains properties). A density result from (Anil et al., 2019) ensures that the
supremum over such networks is equal to the Wasserstein distance (see Propo-
sition 2).
2.4 Minimizingthepredictionsuncertaintyandquerypro-
cedure
This section addresses the problem of the construction of the score function S
basedontheWassersteindistancewithanuncertainty-basedmethod. Toquery
the most relevant data in U, we need to evaluate each of them through the
function S and build B by taking the points that maximize it. As presented
in section 2.1, the score function includes two terms r and w. For x ∈ U, the
term w(x) relies on the decay of the Wassertein distance W (P ,P ) when
1 n K∪B
x is added to B. In this sense, w is chosen proportional to φ maximizing (16),
namely
w(x)=βφ(x) (17)
withβapositiveconstant. Thechoiceofrisnotsostraightforward. Inthebest-
casescenario,wewouldbeabletoretrievethelossandmaker(x)=l(hˆ(x),h(x))
withx∈U toquerythepointswherethislossisthelargest(ashintedby (14)).
However, forsuchx, thevariableh(x)isnotobserved. Toourknowledge, there
is no efficient way to estimate the loss without losing too much generality. This
issue comes from the fact that a regression framework with no assumptions on
the second-order derivative of h leads to a non-convex optimization problem.
So instead of focusing on the loss function, a disagreement sampling approach
will be considered to reduce the uncertainty of the predictions. The objective
is to determine the regions where the model struggles the most to find a stable
estimation of the output. To do so, several copies of hˆ are trained. Then,
data in U are ranked according to the estimated standard deviation s of their
h
prediction. Formally, the uncertainty s (x) of a point x∈U is defined as:
h
(cid:118)
(cid:117) k (cid:32) k (cid:33)2
s (x)=(cid:117) (cid:116)1 (cid:88) hˆ (x)− 1 (cid:88) hˆ (x) (18)
h k i k i
i=1 i=1
where(hˆ ,...,hˆ )areretrainedversionofhˆ. Thepointspickedoutaretheones
1 k
withthehighestuncertainty. However,amainconcernaboutuncertainty-based
sampling is its tendency to give more importance to unrepresentative regions
8of the input space, such as outliers. To correct this undesired behavior, for
each point in U, we penalize its estimated standard deviation prediction by the
mean of its distance from the other points. Moreover, a hyperparameter α>0
is added to weight the penalization of points located far from the barycenter
of data distribution. Note that this hyperparameter might be misleading for
distributions with several data clusters. So without much knowledge of the
data distribution, it might be safer to put the hyperparameter to relatively
low values (less than 1) to reduce the risk of creating a bias. Gathering these
considerations lead to:
s (x)
r(x)= h , x∈U. (19)
(cid:0)1 (cid:80)n
∥X −x∥
(cid:1)α
n i=1 i 2
Note that r depends on the values taken by our pool of estimators (hˆ ,...,hˆ ),
1 k
whereas w depends only on the probability distribution of the covariates. Such
dependencies can induce a major difference between the scale of the two terms
r andw. Inordertotacklethisissuethosetermsaredividedbytheirrespective
empiricalstandarddeviationonU. Suchhomogenizationcanavoidthesituation
whereonecriterionbecomesthesolediscriminatorinourscorefunctionbecause
of its bigger variance. Nonetheless, this gives the final score function used to
evaluate every x∈U to measure their benefit in order to minimize R (hˆ):
PX
s (x) φ(x)
S(x)= h +β (20)
s r(cid:0) n1 (cid:80)n i=1∥X i−x∥ 2(cid:1)α s φ
where s and s are respectively the empirical standard deviation of r and
r φ
φ. Finally, the queried batch contains the points for which the equation (20)
reaches the maximum value. The hyperparameter β can be tuned by the user
to decide whether to give more weight to one criterion or to the other.
The score function is based on three of the main strategies used in active
learning: diversity, representativity, and uncertainty. This allows our method
to leverage several important aspects of the data distribution and of the chosen
estimator. The two hyperparameters α and β give some flexibility to tune the
function. We detail the algorithm that was created to apply this method:
Algorithm 1 (One iteration of batch selection).
• arguments :
– The labeled set K and the unlabeled set U .
– The batch size n .
B
– The vectors θ and θ of parameters of the networks hˆ and φ. We
h φ
initialize those vectors randomly.
– η and η , the learning rates of hˆ and φ respectively.
h φ
– Uncertainty/representativity-diversity trade-off parameter β.
– Outlier penalization parameter α.
9• training hˆ :
Update θ = θ −η ∇ on K. The gradient descent is performed with
h h h θh
the Adam algorithm (Kingma and Ba, 2014).
• Query :
Set B empty.
While size(B)̸=n do
B
1. updateθ =θ +η ∇ onK∪B. Thegradientdescentisperformed
φ φ φ θφ
with the Adam algorithm (Kingma and Ba, 2014).
2. Compute S(x) for all x in U
3. Add the x with the highest S(x) value to B and remove it from U
End While
• Updating sets :
K =K∪B and U =U\B.
Remark 4. In this algorithm, it is important to note that we retrain φ to select
each point of B one by one. We do so in order to favor diversity in the queried
batch. Indeed, if the same function φ is used to pick out the entire batch B,
the algorithm has a tendency to choose a restricted cluster of points. Which is
counter-effective in regards to the objective of the coefficient φ in the acquisition
function S.
Tocreatetheinitialpooloflabeleddata,wewillusetheK-meansalgorithm:
we define b clusters and take the closest points to each cluster center.
0
Algorithm 2 (Full WAR Algorithm).
• Arguments :
– Same as algorithm 1
– The number of rounds N (i.e. the number of call to algorithm
query
1).
– Number of initial data b .
0
• Initialisation :
Query the b initial data using K-means
0
• For N =1...N Do algorithm 1.
query
3 Group Sort Neural Networks
Informally, GroupSort neural networks introduced by (Anil et al., 2019) are
simply neural networks with an activation function that sorts the input of each
layer. This activation function divides the input into several blocs of the same
10size and sorts the elements in each block in decreasing order. The output is
hence the concatenation of the sorted blocs. As an example, if the input is
(9,6,10,8,6,10,7,9,5,9,6,4,5,8,8),
the output of the GroupSort activation function with grouping size 3 is
(9,6,10, 8,6,10, 7,9,5, 9,6,4, 5,8,8)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124)(cid:123)(cid:122)(cid:125) (cid:124)(cid:123)(cid:122)(cid:125) (cid:124)(cid:123)(cid:122)(cid:125)
(10,9,6, 10,8,6, 9,7,5, 9,6,4, 8,8,5)
ThechoiceofneuralnetworksusingtheGroupSortactivationfunctionismainly
motivatedbythefactthat(Aniletal.,2019)hasshownthedensityofthesetof
suchneuralnetworksinthesetof1-Lipschitzfunctions. Whichallowsgivingan
exact expression of the Wasserstein distance in terms of such neural networks
(see Proposition 2). They also showed empirically that they converge faster
thanothermethodswhenitcomestoestimating1−Lipschitzfunctions. Recent
works(Biauetal.,2022;Biauetal.,2020;St’ephanovitchetal.,2022)highlight
thepertinenceofGroupSortneuralnetworksinthisarea,hencetheirimportance
for query by probability matching applications using the Wasserstein distance.
3.1 Presentation
Definition2(GroupSortactivationfunction(Aniletal.,2019)). Letk andn∈
N, the Group Sort function σ is a function from Rn to Rn which split an input
k
(x ,...,x ) into n/k blocs of size k and return the vector in which each bloc is
1 n
ordered. More formally, one define for i = 1,...,n/k, G = {x ,...,x }
i k(i−1) ki
and
σ(x ,...,x )=(G˜ ,...,G˜ ) (21)
1 n 1 n/k
where G˜ is the ordered version of G . That is, for x and x ∈G˜ , x ≤x if
i i k j i k j
k <j. The integer k is called the grouping size.
Definition 3 (GroupSort neural network (Tanielian et al., 2021) ). Let q ∈ N
and α ∈ Λ, with Λ = {V ,...,V ,c ,...,c } where the V are matrices and c
1 q 1 q i i
are vector with dimension detailed in definition ??. We define the feedforward
neural network with q layers h , from Rd to Rp, iteratively as
α
• l =σ(V x+c )
1 1 1
• l =σ(V l +c ) for i=2...q
i i i−1 i
where the function σ is a Group Sort activation function.
The assumption characterizing the networks of interest involves two matrix
norms defined for a matrix A and a vector X as
∥A∥ = sup ∥AX∥ and ∥A∥ = sup ∥AX∥
∞ ∞ 2,∞ ∞
∥X∥∞=1 ∥X∥2=1
where ∥.∥ denotes the euclidean norm whereas ∥.∥ denotes the norm of the
2 ∞
supremum.
11Assumption 1 ((Tanielian et al., 2021)). For α∈Λ, we assume that
• ∥V ∥ ≤1
1 2,∞
• max(∥V ∥ ,...,∥V ∥ )≤1
2 ∞ q ∞
• there exists K >0 such that max(∥c ∥ ,...,∥C ∥ )≤K.
1 ∞ q ∞
For k ≥2, we call GS the set of GroupSort neural network with grouping size
k
k satisfying this assumption.
Inpractice,theconstructionofaneuralnetworkfulfillingassumption1relies
on Bjork’s orthonormalization algorithm (Bj¨orck and Bowie, 1971). Finally,
density results in the set of 1−Lpischitz functions stated in (Anil et al., 2019)
highlight the fact that the Wasserstein distance can be computed exactly by
only looking at the space of GroupSort neural networks.
Proposition 2. Let X a compact subset of Rd endowed with the L metric.
1
ConsiderGS thesetofallGroupSortneuralnetworkswithσ astheactivation
2 2
function. Then, for P and Q two probability measures on X, we have:
(cid:90) (cid:90)
W (P,Q)= sup φ dP − φ dQ. (22)
1
φ∈GS2 X X
Proof. By the Kantorovich-Rubinstein duality [11] we know that
(cid:90) (cid:90)
W (P,Q)= sup φ dP − φ dQ.
1
φ∈Lip1 X X
Moreover Anil et al. (2019) have shown that the set GS is constituted of 1-
2
Lipschitz functions. And furthermore showed that this set is dense in the set
of 1-Lipschitz function for the L norm. So we conclude the proof establishing
∞
the continuity of the map
Φ: (Lip ,∥.∥ ) → (R,|.|)
1 ∞
(cid:82) (cid:82)
φ (cid:55)→ φ dP − φ dQ.
X X
In fact, we can show that this map is Lipschitz continuous. Indeed, let φ and
1
φ ∈Lip , we have
2 1
(cid:12)(cid:90) (cid:90) (cid:90) (cid:90) (cid:12)
(cid:12) (cid:12)
|Φ(φ 1)−Φ(φ 2)|=(cid:12) φ
1
dP − φ
1
dQ− φ
2
dP + φ
2
dQ(cid:12)
(cid:12) (cid:12)
X X X X
(cid:90) (cid:90)
≤ ∥φ −φ ∥ dP + ∥φ −φ ∥ dQ
1 2 1 2
X X
≤2∥φ −φ ∥ .
1 2 ∞
A sequence of Group Sort neural networks allowing the computation of the
Wassersteindistancemayinvolvesnetworkswithgrowingdepthandsize. How-
ever (Tanielian et al., 2021) have provided, for a given error, bounds for both
depth and size (see next section).
123.2 Network Architecture
ThissectionpresentaresultaboutsufficientdepthandsizeforGroupSortneural
networks in order to achieve a given precision on the estimation of the Wasser-
stein distance.
SincethesetGS containsallGroupSortneuralnetworks,thedensityresult
2
involvestheconsiderationofaneuralnetworkwithnon-boundedsizeanddepth.
Consequently,ifφisrestrictedtosomefixedsizeanddepth,wewillnotbeable
to make a perfect approximation of W (P,Q). Nevertheless, Tanielian et al.
1
(Tanielianetal., 2021)gaveboundsforbothdepthandsizeconsideringagiven
error. This can help to create the right architecture for the network φ.
Proposition 3. Let ε>0, there exist φ∗ ∈GS such that
2
(cid:12) (cid:18)(cid:90) (cid:90) (cid:19)(cid:12)
(cid:12) (cid:12)W 1(P,Q)− φ∗ dP − φ∗ dQ (cid:12) (cid:12)≤ε, (23)
(cid:12) (cid:12)
X X
and, for any 0<δ <ε the dimensions of φ∗ is bounded as follows :
(cid:18)(cid:16)√ (cid:17)d2(cid:19)
• Size of φ∗ is a O d .
ε−δ
(cid:16) (cid:16) √ (cid:17)(cid:17)
• Depth of φ∗ is a O d2log 4 d .
2 ε−δ
Proof of Proposition 3. Letφ∗ ∈GS , P,QtwoprobabilitymeasuresonX and
2
δ >0, we have
(cid:12) (cid:18)(cid:90) (cid:90) (cid:19)(cid:12) (cid:12) (cid:18)(cid:90) (cid:90) (cid:19)(cid:12)
(cid:12) (cid:12)W 1(P,Q)− φ∗ dP − φ∗dQ (cid:12) (cid:12)≤(cid:12) (cid:12)W 1(P,Q)− φ 0 dP − φ 0dQ (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
X X X X
(cid:12)(cid:18)(cid:90) (cid:90) (cid:90) (cid:90) (cid:19)(cid:12)
+(cid:12) (cid:12) φ 0 dP − φ 0dQ− φ∗ dP − φ∗dQ (cid:12) (cid:12).
(cid:12) (cid:12)
X X X X
Where φ is a 1-Lipschitz function chosen such that,
0
(cid:12) (cid:18)(cid:90) (cid:90) (cid:19)(cid:12)
(cid:12) (cid:12)
(cid:12)W 1(P,Q)− φ
0
dP − φ 0dQ (cid:12)≤δ.
(cid:12) (cid:12)
X X
Such a function exists since the Wasserstein distance is a supremum over 1-
Lipschitzfunctions. Asaconsequence,thisremarktogetherwiththelastbound
given in the proof of Proposition 2, we have for any δ, that there exists a
Lipschitz function φ such that
0
(cid:12) (cid:18)(cid:90) (cid:90) (cid:19)(cid:12)
(cid:12) (cid:12)W 1(P,Q)− φ∗ dP − φ∗dQ (cid:12) (cid:12)≤δ+2∥φ 0−φ∗∥ ∞.
(cid:12) (cid:12)
X X
Now, to estimate W (P,Q) using neural network φ∗ in GS accepting an error
1 2
of ε, we can choose φ∗ such that
ε−δ
∥φ −φ∗∥ ≤ .
0 ∞ 2
13Forsuchanapproximation,Tanielianetal. [29]haveshownthatthedepthof
√ √
φ∗ canbechosenequalto(( d/(ε−δ))d/2)anditssizeasaO(d2log (4 d/(ε−
2
δ))). Note that these two quantities are as greater as ε and δ are closer. But,
thoseboundsdonotinvolvethevaluesofφ ,that’swhywecanchooseδsmaller
0
as we want.
Theboundsprovidedinthissectionarehuge,especiallyforhighdimensional
covariates. One can see in section 4 that we can achieve the wanted accuracy
with smaller networks.
4 Numerical experiments
For every dataset used, we split the trainset and the testset using a ratio of
80/20. We started the active learning procedure shown in Algorithm 1 initial-
izing K with around 2% to of the data available and we queried about 2% of
thetrainsetateachiteration. Themodelsweretrainedbyminimizingthemean
squared error. The accuracy of the fitted models hˆ was measured using RMSE.
We retrieved the accuracy achieved in each model when 25% of the dataset
werequeried. Finally, wecomputedtheareaunderthelearningcurveusingthe
composite trapezoidal rule.
4.1 Models and datasets used
WecomparedtheWARmodelwith8models, eachusingdifferentquerystrate-
gies: Random query, query by disagreement sampling with a committee of 5
neural networks, greedy Sampling on the Inputs (GSx) (Wu et al., 2019), im-
proved Greedy Sampling (iGS) (Wu et al., 2019), query by information density
(euclidean method), query by information density (cosine method), improved
Representativeness-Diversity Maximization (iRDM) (Liu, 2021) and inverse-
Distance based Exploration for Active Learning (IDEAL)(Bem, 2023).
These tests were performed using five UCI datasets: Boston Housing (Har-
rison and Rubinfeld, 1978), Airfoil Self-Noise (T.F. Brooks and Marcolini., ),
Energy efficiency (Tsanas and Xifara, 2012), Concrete Slump Test (Y20, 2007),
and Yacht Hydrodynamics (Gerritsma et al., 1981). In the presented tables
these dataset are denoted respectively as ”Bo”, ”Ai”, ”En”, ”Ya” and ”Co”.
More information is available in the supplementary materials. There were sev-
eraltargetcolumnsintheEnergyEfficiencyandConcreteSlumpTestdatasets,
we kept the Heating Load and SLUMP columns respectively, and dropped the
others. Every categorical feature was already in a numerical form. We used a
Min-Max scaler to scale the input data.
4.2 Implementation
Ineverymodel,theestimatorhˆ isaneuralnetworkwithtwohiddenlayerswith
respective sizes 16 and 32, completed by RELU activation functions. They all
ran for 100 epochs in fullbatch. We add L2 regularization on h with a weight
14decay of 0.001 to prevent overfitting. Optimization was performed with an
initial learning rate of 0.001 using Adam (β =0.9, β =0.999). Importantly, hˆ
1 2
parameters were not reset after each round in order to give more importance to
the points queried during the first rounds (more on that in section 4.4). The
hyperparameters of WAR and IDEAL were tuned for each dataset using Grid
Search.
Specifically for the WAR implementation, we also had to train φ. We used
Adam (still with β =0.9, β =0.999) and an initial learning rate of 0.01. φ
1 2
belongs to GS (grouping size of 2). We used a committee of 5 estimators to
2
compute the uncertainty. The results presented below are the RMSE averaged
over 5 repetitions.
4.3 Results
The error made by the different algorithms after querying 25% of the dataset
is presented in table 1. The table 2 presents the area under the learning curves
which are displayed in figure 2. Only the learning curves of three of the five
datasetsarepresented,thetwoothersarepostponedtosupplementarymaterial.
Table 1: RMSE when 25% percent of the data is labeled
Bo Ai En Ya Co
Random 4.33 9.66 2.69 3.95 6.58
Disagreement 4.45 11.47 2.83 4.53 6.87
GSx 4.30 16.26 2.60 2.17 7.33
iGS 4.12 9.06 2.57 2.10 7.00
Euclidean 6.03 19.68 3.41 4.22 8.08
Cosine 5.60 19.57 3.83 3.25 8.32
iRDM 4.28 10.21 2.67 4.33 7.35
IDEAL 4.54 7.53 2.62 3.36 7.50
WAR 3.63 8.67 2.65 2.71 6.15
The WAR algorithm (in light green) is consistently demonstrating a rela-
tively fast convergence, often having the lowest RMSE for a given number of
data. Italsotendstooutperformtheothermethodseventually. Theresultscan
be interpreted as a consequence of the effort to mitigate the risks of querying
some outliers during the early stages of the process, thanks to the penalization
α inserted in the acquisition function. Indeed, these outliers could have created
a bias during the training of hˆ, by getting an ill-deserved representation in the
weightsoftheestimator(rememberthatwedonotresethˆ parametersafterwe
finish a round).
Besides, one can notice that WAR is always performing better than the
simple disagreement sampling method. This highly suggests that the query
criterionbasedontheWassersteindistancethatcompletestheacquisitionfunc-
15tion increases substantially the converging speed. This also gives an easy way
to increase the performance of the model: by adding more estimators to the
committee, we get a better estimation of each of their predictions’ standard
deviations, and the final predictions can be refined by computing the mean or
the median of each of their outputs.
Table 2: Area under each of the models’ curve
Bo Ai En Ya Co
Random 228 625 126 143 274
Disagreement 216 675 126 150 235
GSx 212 660 121 126 233
iGS 208 588 126 138 237
Euclidean 262 702 144 161 263
Cosine 265 754 172 142 268
iRDM 210 584 121 140 229
IDEAL 211 558 119 135 224
WAR 194 583 114 133 213
This gives a sense of the general performance of each method. Here, WAR
is always among the best models. Thanks to this approach, few outliers are
queried which leads to a bias reduction and a better performance overall in the
query procedure.
Figure 2: Evolution of the mean of each model RMSE when increasing the
trainset size for Concrete Slump data set
4.4 A Link to curriculum learning
The formula S(x) that we use to decide the next points to query can be seen
as a way to quantify the amount of information provided by each data in U to
16achieve the given task (approximating h). So it seems reasonable to give more
weight to the points carrying the most information. In our case, the data that
were queried during the first rounds contain arguably more information than
the ones queried after. By not resetting hˆ parameters after each round, the
model will be trained more often on the points queried at the beginning. This
approach can be linked to curriculum learning introduced by (Bengio et al.,
2009), where available data are ranked from easy to hard and then train on
them in that order. In active learning, we are not explicitly trying to rank data
in this manner. However, the two fields share similar approaches to reach a
good estimation of h since the model is trained on a richer and more complex
dataset after each iteration. We refer to the survey (Soviany et al., 2022) for
more information about curriculum learning.
5 Conclusion and future works
We proposed an active learning strategy for regression using probability dis-
tribution matching and uncertainty-based sampling and provided theoretical
foundations. The model relies on three important aspects of data distributions
in general (namely: uncertainty, diversity, and representativity) to evaluate the
benefit of each point regarding our problem. This makes it more adjustable to
everyinputspaceinafashionthatreducestheriskofqueryingoutliers. Theuse
of GroupSort neural networks has shown its relevance in such a setup thanks
to their theoretical guarantees and good convergence properties. The empirical
study highlights the efficiency of combining uncertainty-based approaches with
the Wasserstein distance to select data and shows that keeping the weights of
the estimator after each round can lead to better results. A strength of this
methodology is its versatility. In fact, it can be applied with any learner hˆ as
long as this learner is Lipschitz continuous.
For future works, we plan to study the impact of the query batch size (n )
B
on the model convergence to improve our query strategy. We will also develop
methodstoestimatethebestvaluesofthehyperparametersβ,andα,according
to the other parameters of the problem. Finally, we wish to link our method to
othercurriculumlearningapproachesandseeifsomeideasofthisdomaincould
be extended to active learning.
6 Additional experiments
6.1 Benchmarks details
This section summarizes some details on the dataset and models used in the
benchmarkstudy. Thetable3givesthevaluesofthedifferentmodels. Whereas
the table 4 provides the size information about datasets, such as numbers fea-
tures, entries or different subsamples size.
The signification of other models’ hyperparameters:
17Boston Airfoil Energy1 Yacht Concrete
WAR - α 2 0 0 1 1
WAR - β 3 2.5 2.5 3 6
iRDM - c 5 5 5 5 5
max
IDEAL - ω 3 0.5 1 1 1
IDEAL - δ 3 3 3 0.3 0.1
Figure 3: Model hyperparameters
• c = maximum number of iteration
max
• δ = weight of the exploration factor
• ω= weight of the density measure
Boston Airfoil Energy1 Yacht Concrete
number of features 13 5 8 6 7
trainset length 404 1202 614 246 82
testset length 102 301 154 62 21
initial labeled pool length 8 24 12 5 2
batch queried length 8 24 12 5 2
Figure 4: Dataset details
6.2 Graphs
The non-displayed learning curves in the core document (mentioned in section
4 can be found in this section. All figures show the same behavior as described
in the core document, which comforts the mentioned conclusions.
18(a) Airfoil Self-Noise (b) Yacht Hydrodynamics
(c) Boston Housing (d) Energy Efficiency
Figure 5: Evolution of the mean of each model RMSE when increasing the
trainset size
References
(2007). Modeling slump flow of concrete using second-order regressions and
artificial neural networks. Cement and Concrete Composites, 29(6):474–
480.
(2021). Pool-based unsupervised active learning for regression using iterative
representativeness-diversitymaximization(irdm). Pattern Recognition Let-
ters, 142:11–19.
(2023). Activelearningforregressionbyinversedistanceweighting. Information
Sciences, 626:275–292.
Anil, C., Lucas, J., and Grosse, R. B. (2019). Sorting out lipschitz function
approximation.
Ben-David,S.,Blitzer,J.,Crammer,K.,Kulesza,A.,Pereira,F.,andVaughan,
J. (2010). A theory of learning from different domains. Machine Learning,
79:151–175.
Bengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum
learning. International Conference on Machine Learning.
19Biau, G., Cadre, B., Sangnier, M., and Tanielian, U. (2020). Some Theoretical
Properties of GANs. Annals of Statistics, 48(3):1539–1566.
Biau,G., Sangnier,M.,andTanielian,U.(2022). Sometheoreticalinsightsinto
wasserstein gans. 22(1).
Bj¨orck, r. and Bowie, C. (1971). An iterative algorithm for computing the best
estimate of an orthogonal matrix. SIAM Journal on Numerical Analysis,
8(2):358–364.
Burbidge, R., Rowland, J. J., and King, R. D. (2007). Active learning for re-
gression based on query by committee. In Yin, H., Tino, P., Corchado, E.,
Byrne, W., and Yao, X., editors, Intelligent Data Engineering and Auto-
matedLearning-IDEAL2007,pages209–218,Berlin,Heidelberg.Springer
Berlin Heidelberg.
C´edric, V. (right 2009). Optimal transport : old and new / Villani C´edric.
Grundlehren der mathematischen Wissenschaften. Springer, Berlin.
Dudley, R. M. (1969). The Speed of Mean Glivenko-Cantelli Convergence. The
Annals of Mathematical Statistics, 40(1):40 – 50.
Fournier, N. and Guillin, A. (2015). On the rate of convergence in Wasserstein
distance of the empirical measure. Probability Theory and Related Fields,
162(3-4):707.
Gerritsma, J., Onnink, R., and Versluis, A. (1981). Geometry, resistance and
stabilityofthedelftsystematicyachthullseries. International shipbuilding
progress, 28:276–297.
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In
Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N., and Weinberger,
K.,editors,AdvancesinNeuralInformationProcessingSystems,volume27.
Curran Associates, Inc.
Gouk, H., Frank, E., Pfahringer, B., and Cree, M. J. (2021). Regularisation
of neural networks by enforcing lipschitz continuity. Machine Learning,
110(2):393–416.
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A. C.
(2017). Improved training of wasserstein gans. CoRR, abs/1704.00028.
Harrison, D. and Rubinfeld, D. L. (1978). Hedonic housing prices and the de-
mandforcleanair. JournalofEnvironmentalEconomicsandManagement,
5(1):81–102.
Kingma, D. and Ba, J. (2014). Adam: A method for stochastic optimization.
International Conference on Learning Representations.
20Lewis, D. D. and Gale, W. A. (1994). A sequential algorithm for training text
classifiers. In Croft, B. W. and van Rijsbergen, C. J., editors, SIGIR ’94,
pages 3–12, London. Springer London.
Li, F.-F., Fergus, R., and Perona, P. (2006). One-shot learning of object cate-
gories. IEEE Trans. Pattern Anal. Mach. Intell., 28(4):594–611.
Panaretos,V.M.andZemel,Y.(2020). Aninvitationtostatisticsinwasserstein
space.
Ren, P., Xiao, Y., Chang, X., Huang, P.-Y., Li, Z., Chen, X., and Wang, X.
(2020). Asurveyofdeepactivelearning. arXiv preprint arXiv:2009.00236.
Roy, N. and McCallum, A. (2001). Toward optimal active learning through
sampling estimation of error reduction. In International Conference on
Machine Learning.
Settles, B.(2012). Active Learning. SynthesisLecturesonArtificialIntelligence
and Machine Learning Series. Morgan & Claypool.
Shannon,C.E.(2001). Amathematicaltheoryofcommunication. SIGMOBILE
Mob. Comput. Commun. Rev., 5(1):3–55.
Shui, C.,Zhou,F., Gagn´e,C., andWang,B.(2020). Deepactivelearning: Uni-
fied and principled method for query and training. In International Con-
ference on Artificial Intelligence and Statistics, pages 1308–1318. PMLR.
Soviany,P.,Ionescu,R.T.,Rota,P.,andSebe,N.(2022). Curriculumlearning:
A survey. Int. J. Comput. Vision, 130(6):1526–1565.
St’ephanovitch, A., Tanielian, U., Cadre, B., Klutchnikoff, N., and Biau, G.
(2022). Optimal 1-wasserstein distance for wgans. ArXiv, abs/2201.02824.
Tanielian, U., Sangnier, M., and Biau, G. (2021). Approximating lipschitz con-
tinuous functions with groupsort neural networks. ArXiv, abs/2006.05254.
T.F.Brooks,D.P.andMarcolini.,A. Airfoilself-noiseandprediction. Technical
report, NASA RP-1218.
Trabucco,B.,Doherty,K.,Gurinas,M.,andSalakhutdinov,R.(2023). Effective
data augmentation with diffusion models.
Tsanas, A. and Xifara, A. (2012). Accurate quantitative estimation of energy
performanceofresidentialbuildingsusingstatisticalmachinelearningtools.
Energy and Buildings, 49:560–567.
Wu, D., Lin, C.-T., and Huang, J. (2019). Active learning for regression using
greedy sampling. Information Sciences, 474:90–105.
Zhang, T. and Oles, F. J. (2000). A probability analysis on the value of un-
labeled data for classification problems. In Proc. 17th International Conf.
on Machine Learning,pages1191–1198.MorganKaufmann,SanFrancisco,
CA.
21