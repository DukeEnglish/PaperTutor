A Picture Is Worth a Graph: Blueprint Debate on Graph for
Multimodal Reasoning
ChangmengZheng DayongLiang WengyuZhang
csczheng@comp.polyu.edu.hk ft_ldy@mail.scut.edu.cn wengyu.zhang@connect.polyu.hk
TheHongKongPolytechnic SouthChinaUniversityofTechnology TheHongKongPolytechnic
University University
Xiao-YongWei∗ Tat-SengChua QingLi
x1wei@polyu.edu.hk dcscts@nus.edu.sg qing-prof.li@polyu.edu.hk
TheHongKongPolytechnic NationalUniversityofSingapore TheHongKongPolytechnic
University University
ABSTRACT ofsemantics,includingbearsedge,earthworm,collaredlemming,
Thispaperpresentsapilotstudyaimedatintroducingmulti-agent andothers.Asaconsequence,thiscanresultinthecontextand
debateintomultimodalreasoning.Thestudyaddressestwokey summarybeingtrivialized,shiftingtheemphasisfromlichentoa
challenges:thetrivializationofopinionsresultingfromexcessive moregeneralizedconceptofthetundraecosystem,whereinboth
summarizationandthediversionoffocuscausedbydistractorcon- bilberryandmushroomexhibitahighdegreeofcorrelation.Similar
cepts introduced from images. These challenges stem from the issueexistswhenMADisemployed,wherethesummarizercon-
inductive (bottom-up) nature of existing debating schemes. To cludesthediversesemanticsintogeneralwordslikeecosystemand
address the issue, we propose a deductive (top-down) debating foodweb,makingtheconclusionlessspecific.Inaddition,MAD
approach called Blueprint Debate on Graphs (BDoG). In BDoG, mayencountertheissueoffocusdiversion,whichoccurswhen
debatesareconfinedtoablueprintgraphtopreventopiniontrivi- Chain-of-Thoughts(CoT)isutilizedandnewconceptsintroduced
alizationthroughworld-levelsummarization.Moreover,bystoring arehighlycorrelatedwithaparticularconcepts(e.g.,mathematical
evidenceinbrancheswithinthegraph,BDoGmitigatesdistractions model[5]),leadingtoanincreasedweightingofthatconceptwithin
causedbyfrequentbutirrelevantconcepts.Extensiveexperiments thecontext.
validateBDoG,achievingstate-of-the-artresultsinScienceQAand Wearguethatthesechallengesariseduetotheinductivenature
MMBenchwithsignificantimprovementsoverpreviousmethods. ofexistingdebatingschemes,whereinagentopinionsaregathered
fromdisparateconceptsatword-levelandconsensusisachieved
1 INTRODUCTION throughbottom-upsummarization.Thisapproachmaybeeffective
inconfinedNLPtasks[8,9],wherethetopicisoftenlimitedto
Multimodalreasoningdependsontwokeyaspects:thecreation
asmallnumberofconceptsandtheapplicationofCoTremains
ofaunifiedrepresentationofsemanticsfromdifferentmodalities
constrained.However,inamultimodalscenario,certainmodalities
andtheintegrationofthesediversesemanticswhileensuringlogi-
(e.g.,images)areinformation-richandhaveahigherlikelihoodof
calconsistency.Whiletheadvancementinlargelanguagemodels
introducingdistractingconcepts[20].Consequently,itincreases
(LLMs)hasmadeitpossibletorepresentthesemanticsinnatu-
thesemanticdivergencewithinthecontextandthelikelihoodof
rallanguages[1],theintegrationofdiversesemanticsremainsa
trivialization.Thesemanticdivergenceincreasesfurtherwhenthe
challengingissue,eveninexclusiveNLPtasks.Oneapproachto
impactsofthoseconceptsareamplifiedthroughCoT,particularly
tacklethischallengeismulti-agentdebate(MAD),wheremultiple
whenthenewlyintroducedconceptsexhibitbiasestowardscertain
LLMsactasagents,eachcontributingtheirownperspectiveson
concepts,resultinginfocusdiversion.
thetargettopicandreachingaconsensusthroughdebates[4,16].
Toaddressthisissue,weproposeandeductivereasoningscheme
ThisschemecouldbeadoptedbyincorporatingaspecificLLMfor
called Blueprint Debate on Graph (BDoG, pronounced bee-dog).
eachmodalityasanagent.
BDoGisinspiredbytheblueprintdebatethathasbeenwidelyem-
Despitebeingrelativelyunexploredinthemultimodaldomain,
ployedinreal-worlddebates,whichdistinguishesitselffromother
MADencountersnumerouschallengesinabroadercontext.MAD
debatesbyitsconcentrationonevaluatingandrefiningaproposal
maysufferfromthetrivializationofopinions,whichisaresultof
(e.g.,blueprint)toaddressspecificchallengesorissues.BDoGbe-
thesummarizationstepperformedattheconclusionofeachdebat-
ginsbyaggregatingconceptsfrommodalitiesandincorporating
inground.Theobjectiveofthisstepistoseekagreementamong
withtheirrelationshipsintoainitialgraph.Thisgraphservesas
theparticipatingagentsregardingtheiropinions.Consequently,
ablueprintthatconfinesthescopeofthediscussionratherthan
thisprocesscanleadtothedebate’sfocusbeingdirectedtowards
havingitopentoirrelevantsemanticsasinexistingschemes.More
ageneralconcept,servingasanadaptationtoaccommodatethe
importantly,BDoGconductsthedebateinatop-downmannerby
diverserangeofsemantics.Oneexamplecanbeobservedinthe
markingdownconclusionsonthegraph.Thispreventstrivializa-
reasoningoftheMultimodalLanguageModel(MLLM)depicted
tionasspecificconceptsarepreservedratherthanmergedinto
inFigure1,wheretheimagemodalitypresentsadiverserange
generalones.ThiscanbefoundfromtheexampleshowninFigure
1,wherethescopeislimitedtothetundraecosystemwhilespecific
∗CorrespondingAuthor
4202
raM
22
]IA.sc[
1v27941.3042:viXraChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
Input MAD BDoG
W coh ni tc ah
in
o sf
m
th ae tts ee
r
o tr hg aa tn wis am
s
s ( (A B))B Mil ub se hr rr oy
om
A- f- f- ir- m--- a- t- iv-- e-- S- i- d- eF :irst-roundDebate-------------- B-- l- u- e- p-- r- i- n- t- :-----DebateInitializ ea art ti ho won rm-------------
once part of the lichen? The lichen is at the bottom of the food web, so caribou lemming
the matter…Therefore, all of these organisms eateat decomposedecompose
c No en gt aa ti in v… eSide: C byonsumed p or ney eal tichen preyo en at a forc xtic
The lichen is eaten by the lemming, …the lichen mushroom bilberry
bear
will be found in the lemming,….
----------------First-roundDebate--------------
Summarizer: AffirmativeGraph: NegativeGraph:
The debate solution is correct in…The matter
t d bh i afa lf at e nrw e ca ens ,t a. o. ne r dgco a …ns ,y i iss tmt ce asm .
n
T a hhn aed
v
f
e
ois ao u d rs
i
pe wd pe lb b
e
y ei sm
f
fa ea d cn tey l
o
ic na tt he
e I ds
es coo mil
posed
car Ii sbo eu atenIse ba et ae rnby g n fre u ot t ms rient cs ons to ai il
n
ca Isri eb ao tu enI bs yeaten
entire system. (TrivializationofOpinion). into by by bear
Baselines ---------------Second-roundDebate------------ lichen mushroom d lice hc eo nmposed lichen
MLLM: AffirmativeSide: ---------------Second-roundDebate------------
We could use a mathematical model to track the
B mo at th tet rh e th b ai tl b we arr sy o a nn cd e t ph ae r tm ou f s th hr eo lo icm he c no .ntain movement of matter… AffirmativeGraph: NegativeGraph:
NegativeSide: mushroom lichen mushroom lichen
MLLM-CoT:
Rationale:The image shows a food relation Humansare a part of the ecosystem, and they contains contains
between several animals and plants in a tundra can have a significant impact on the movement ----------------DebateTermination--------------
ecosystem… The lichen is a composite organism of matter through the ecosystem… BlueprintDebate-on-Graph:
that consists of a fungus and an alga. The fungus Summarizer: Rationale:The lichen is decomposed into soil.
provides the physical structure of the lichen, We could use a combinationof mathematical The mushroom gets its nutrients from the soil.
while the alga provides the food for the fungus.. modeling and experimentation to track the Sothe mushroom contains matter that was once
(FocusDiversion) movement of matter through…(FocusDiversion) part of the lichen.
Answer:Botharecorrect. Answer:(A)bilberry. Answer:(B)mushroom
Figure1:ComparisonresultsfromScienceQAdatasetofdirectanswerfromMLLM,MultimodalChain-of-Thought(CoT),
Multi-agentDebate(MAD)andOurBlueprintDebateonGraph(BDoG).
conceptslikemushroomandlichenareretained.Furthermore,the sub-questionstoenabledeep-layerreasoning.SCITUNE[10]and
graphprovideacompactandhigh-levelguidanceforthediscussion T-SciQ[30]aimtoteachlargelanguagemodelstoanswerscience
process.Thenewlyintroducedconceptsareincorporatedintorele- questionsviathegenerationofmixedrationalesderivedfromboth
vantbranchesinsteadofremainingasaword-levelthoughtswithin largepretrainedmodelsandhumanannotators.Chameleon[21]
thecontext.Thisreducesthelikelihoodoffocusdiversionsince, accomplishescomplexmultimodalreasoningtasksbyintegrating
inDBoG,thecompetitionofsemanticsoccursatthebranchlevel variousexternaltools(e.g.,largelanguagemodels,off-the-shelf
ratherthanthewordlevel.ThiscanbeseenfromFigure1,where vision models, and web search engines). Nevertheless, existing
themostrelevantbranchesrelatedtothesoilandcariboustandout methods exhibit limitations as they heavily rely on either few-
fromthecompetition,eliminatingtheirrelevantsemantciseffec- shotlearningorsupervisionto“guide”thereasoningprocess.In
tively.Inadditiontotheadvantagesofscope-confinedguidance ordertoovercomethisdependency,weproposetheincorporation
andbranch-levelcompetition,BDoGalsoincreasesexplainability, ofdebatingfeaturesintoourmethod.Thisenablestheagentsto
allowingforthetrackingofdiscussionprogress.Thisisevidentin engageinanadversarialdiscussion,allowingthemto“figureout”
Figure1,inwhichtheprogressofdebatingismoreunderstandable thecorrectdirectionautonomously.Asaresult,ourapproachmakes
thanword-levelreasoning(i.e.,MLLM-CoTorMAD). zero-shotlearningfeasiblebyreducingtherelianceonexternal
guidanceorsupervision.
2 RELATEDWORKS
2.2 Multi-agentDebate
2.1 MultimodalReasoning
TomitigatethesusceptibleerrorinCoTreasoning,Shinnetal.[26]
Multimodalreasoningisacrucialcomponentinthedevelopment andMadaanetal.[22]employmodeltoreflectontaskfeedback
ofadvancedartificialintelligence(AI)systemsthataimtoreplicate signalsthatcaninducebetterdecision-makinginsubsequenttrials.
human-likeintelligence[20].ThistypeofreasoningenablesAI [39]exploitpreviouslygeneratedanswerashinttoprogressively
systemstoprocessandanalyzeinformationfromvarioussources guidetowardscorrectanswer.Althoughthesemethodseffectively
andforms,suchastext,images,audio,andvideo,inaintegratedand enhancetheperformanceofLLM,theystruggletoproducenovel
coordinatedmanner[3,25].Thelatestadvancementsinmultimodal ideasoncetheyhavedeterminedaresponse,astheyrelysolely
largelanguagemodels,suchasBLIP2[14],KOSMOS[13]andLLaVA oninternalrepresentationsforgeneration[12].Researchersare
[18]havedemonstratedsignificantprogressincomplexreasoning, currentlydevelopingmulti-agentcollaborativesystemstoaddress
asthesemodels[38]nowhavethecapabilitytogeneratestep-by- aboveissuesinpure-textualscenarios[36].Bydesigningthesesys-
step rationalesprior toproducing the finalanswer, following a tems,largelanguagemodels(LLMs)canworktogethertocomplete
chain-of-thought(CoT)manner.Zhengetal.[40]proposeaduty- tasksorengageinproductivedebatesbyofferingcontrastingper-
distinctpromptingmethodwhereinquestionsaredecomposedinto spectives[4,7,16].Zhangetal.[37]furtherrevealthecollaborationAPictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
mechanismfromasocialpsychologyview.Thispaperrepresents steps.Contrarytopriorworkonconversationalagents,Zhenget
aninitialendeavortoexpanduponthismethodtofacilitatemul- al.[40]employtheinstructionpleasedecomposethequestionse-
timodalreasoning.Byincorporatingmultipleperspectivesfrom quentiallyintonecessarysub-inquiriestoacquirethesub-question
differentmultimodallanguagemodels,wecanhelpaddresssome sequence𝑄 1,𝑄 2,...,𝑄 𝑡 inasingleinteraction.Withinthisframe-
ofthelimitationsofindividualmodels.Moreover,weaddressthe work,thefinalresponse𝐴isobtainedbyaggregatingtheanswers
trivializationofopinionsandfocusdiversionproblemsofvanilla 𝐴 𝑖 toeachsub-question𝑄 𝑖 andthegeneratedCoTrationale𝑅 𝑖.
multi-agentdebateviaBlueprintDebateonGraph(BDoG). Self-Correction.Self-correctiontechniques[34]endeavortoitera-
tivelyenhancemodelpredictionsbyleveragingfeedbackgenerated
2.3 Graph-augmentedLLMs
fromthemodelitself.Inparticular,afeedbackfunction𝑓 :𝑅→𝑅′
isadoptedtoiterativelymapmodeloutputstotherefinedresponses.
Priorresearchhasinvestigatedtheintegrationofstructuredgraphs,
MAD.Multi-agentDebate[16]presentsapromisingframework
suchasknowledgegraphs(KGs),intolargelanguagemodels(LLMs)
that fosters discursive exchange and cross-pollination of ideas
byembeddingtheknowledgeintotheunderlyingneuralnetworks
betweenconversationalmodels.Consideradebatecomprising 𝑗
[17,32].Nevertheless,embeddingKGswithinLLMsmaycompro-
roundsamongstasetoflargelanguagemodelsactingasinterlocu-
misetheinherentexplainabilityandadaptabilityassociatedwith tors.Ineachround,Theproponent generatesarationale𝑅 𝑝′ and
knowledgereasoningandupdating[11].Totacklethesechallenges,
response𝐴 𝑝 revisedinlightoftherationales𝑅 𝑜 presentedbythe
recentstudieshaveputforthinnovativesolutions.Lietal.[15]
opponentinpriorturns.
proposedanadaptivequerygenerator,facilitatingthecreationof
queriesacrossvariousquerylanguages(e.g.,SPARQL)toinferratio-
4 BLUEPRINTDEBATEONGRAPH
nales.Wangetal.[29]devisedastructuredmulti-roundquestion-
answering(QA)format,whichextractsexternalknowledgeand Inthissection,weintroduceBlueprintDebate-on-Graph(BDoG).
generatescoherentreasoningtracesgroundedinpreciseanswers. AsillustratedinFigure2,BDoGtakesadeductiveapproachinstead
Sunetal.[27]introducedThink-on-Graph(ToG),amethodthat ofinducinganswersfromword-levelthoughts.Itutilizesgraphs
sequentiallyreasonsoverKGstolocaterelevanttriples,thereby tostructuretheopinionsandproposalsprovidedbyagents.This
supporting the LLM in predicting the final answer. In the con- graph-levelstructuringofthedebatingcontexthelpsminimizeopin-
textofmultimodalreasoning,CCoT[23]substitutestherationale iontrivializationandfocusdiversion.Furthermore,BDoGadopts
generationprocesswithscenegraphextractiontoenhancethecom- antop-downapproachwhichimprovesmultimodalreasoningby
positionalcapabilitiesoflargemultimodalmodels.KAM-CoT[24], iterativelyrefininganinitialproposal,representedasablueprint
ontheotherhand,incorporatesexternalKGsduringthetwo-stage graph.Thisintegratesopinionsfromdiverseperspectivesthrough
trainingprocess,yieldingstate-of-the-artfine-tuningoutcomesin thecompetitionandcooperationamongmultipleagents.
multimodalreasoning.Incontrasttoexistingmethodsthatutilize
ThedebatingprogressofBDoGatthe𝑖𝑡ℎ
roundcanbeformu-
staticgraphs,ourproposedBDoGpreservesthedynamicsandpre- latedasaquadruple
cisionofKGsthroughiterativeupdatesofentities,attributes,and T𝑖 =(G𝑖,S,A,F) (1)
relationships,guidedbyablueprintdebateprocess.
where,givenamultimodalsourcesetS = {𝑄,𝐼,𝐶},thedebating
isconductedamongasetofagentsA = {𝑎 𝑗},𝑗 ∈ Z+,inwhich
3 PRELIMINARY
eachagentcanuseoperationsfromthesetofF ={𝑓 𝑘},𝑘 ∈Z+to
Webeginbyoutliningexistingapproachesfortacklingthemul- propose/summarizeopinionsbyrefiningthegraph-of-thoughtsG𝑖 .
timodalreasoningproblem.Figure2showsthespecificdistinct Attheendofthe𝑖𝑡ℎ round,G𝑖 isupdatedtoG𝑖+1toinitiatethe
amongthem.Formally,givenaquestion𝑄consistingof𝑡 tokens, nextround.
ourgoalistoidentifythecorrectanswer𝐴fromasetofcandidate
answers.Inthecontextofmultimodalreasoning,theexpectedan- 4.1 BlueprintG0 Initialization
swerisintendedtobeinferredbasedonavisualcontext𝐼 anda
Toinitiatethedebating,weneedtoconvertthemultimodalsources
textualclue𝐶,inadditiontothequestionitself.
intoablueprintgraph.Thisconversionisachievedthroughthe
V anan anil sl wa eP rr 𝐴om bypt ai un gg m. eV na tn inil gla tp hr eo im npp uti tn wg ia thpp ilr lo ua sc trh ae ts iva eim ext ao mp pr le ed si 𝐷ct o twpe or aa dti do in tiofu nn ac lt si uon b-𝑓 f0 un∈ ctF ion: sS
𝑓
𝑡↦→ anG d0 𝑓. 𝑣T fo oi rm ep xl te ram ce tin nt g𝑓 0 e, nw tie tied sefi ann de
inadditiontothequestion𝑄,visualcontext𝐼,andtextualclue𝐶.
relationsfromthetextualsources(i.e.,𝑄and𝐶)andvisualsource
MultimodalCoT.AsnotedbyLuetal.[20],incorporatingin- (i.e.,𝐼),respectively.Theimplementationof𝑓 0isformulatedas
termediatereasoningsteps(rationales)canaidinpredictingthe
correctanswer,especiallyforcomplexmultimodalreasoningtasks. 𝑓 0: S↦→G0
Toaddressthis,wefirstgeneratearationale𝑅={𝑟 1,𝑟 2,...,𝑟 𝑘}given 𝑓 𝑡(𝑄)∪𝑓 𝑣(𝐼)∪𝑓 𝑡(𝐶)↦→⟨V0,E0⟩
theinput.Thegeneratedrationale𝑅isthenconcatenatedwiththe
𝑤.𝑟.𝑡 𝑆𝑖𝑧𝑒, 𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 (2)
originallanguageinputtoupdatethelanguagerepresentation.This
augmentedlanguageinputisfedtogetherwiththeoriginalvisual where∪denotestheunionoftwosetsofgraphs.The2constraints
input𝐼 intothesamemodeltoinferthefinalanswer. are as follows: 1) Size Constraint: The size of G0 needs to be
DDCoT.TheDuty-DistinctChainofThoughtframeworkproposes restrictedwithinaspecificrangetopreventanexcessivenumber
anovelapproachfordeconstructingquestionsintofundamental ofcluesthatcoulddistracttheinferenceoraninsufficientnumber
sub-questions,similartobreakingdownreasoningintoelementary toanswerthequestioneffectively.2)RelevanceConstraint:WeChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
𝑄,𝐼,𝐶 𝑄,𝐼,𝐶 𝑄,𝐼,𝐶 𝑄,𝐼,𝐶 𝑄,𝐼,𝐶
Deconstruct Proponent Opponent Blueprint
Initialization
Debate
𝑄 1 𝑄 2 𝑄 3 𝑅 𝑅 ! 𝑅 # Prop. 𝐺 Oppo.
Refine Refine
𝑅 Refine
Debate Debate
𝑅
1
𝑅
2
𝑅
3
𝑅 !" 𝑅 #" 𝐺$ 𝐺%
𝑅′
𝐴 1 𝐴 2 𝐴 3 𝐴 ! 𝐴 # 𝐺∗ Refine
𝐴 𝐴 𝐴 𝐴 𝐴
(a)CoT (b)DDCoT (c)Self-Correction (d)MAD (e)BDoG
Figure2:ComparisonofCoT,Duty-DistinctCoT(DDCoT),Self-Correction,Multi-agentDebate(MAD)andOurproposed
BlueprintDebateonGraph(BDoG).Q:inputquestion,I:inputimage,C:contextorhint,A:answer,R:rationale,G:blueprint.
shouldmergetherelationshipsextractedfrom𝐼 and𝐶 towards ourfocusliesondiscussingtheseguidingprinciplesandconstraints.
thoseofthequestion𝑄,ensureingalltheknowledgeencapsulated OurpromptimplementationswillbeprovidedinAppendix.
inG0isrelevanttothequestion.
Extensivelibrariesareavailablefor𝑓 𝑡 and𝑓 𝑣,astheyhavebeen 4.2 AgentsandRoles
extensivelyresearched(e.g.,namedentityrecognition,relationex-
Inthedebate,wecantreateachLLMasanagentthatparticipates
tractionfor𝑓 𝑡,imagecaptioning,visualgroundingfor𝑓 𝑣).However,
inthediscussionbyrefiningtheblueprintgraphG0.Justlikeina
the recent advancements in multimodal large language models
realdebate,eachagent𝑎 𝑗 ∈Ahasadistinctroleassigned.Wede-
(MLLM)havemadeitconvenienttoimplementthesesub-functions
finethreerolesasasetofR ={𝑃𝑟𝑜𝑝𝑜𝑛𝑒𝑛𝑡,𝑂𝑝𝑝𝑜𝑛𝑒𝑛𝑡,𝑀𝑜𝑑𝑒𝑟𝑎𝑡𝑜𝑟}.
usingin-contextlearningbasedprompts.Forexample,toextend
Theserolesnotonlyhelpstructurethediscussionbutalsopro-
thequery𝐼 inthecontext,wecanemployCoTtoimplement𝑓 𝑡 as
motecriticalthinkingandensureacomprehensiveandin-depth
𝑓 𝑡(𝑄):Giventhequestion{Q},pleaseprovidethenecessarysteps
explorationofthetopic.
toanswerthisquestion.
Proponentagentsadvocateanddefendthecurrentblueprint
byrefiningcurrentG𝑖 intoanaffirmativeevidencegraphG+.A
wherethe{}denotestheplaceholderintheprompt.
For𝑓 𝑣(𝐼),itsimplementationvariesdependingonLLMsused. debatingfunctionisassignedforthispurposeas
ForGPT-4,theimageneedstobeencodedinBase64format.Gem- 𝑃𝑟𝑜𝑝𝑜𝑛𝑒𝑛𝑡 𝑓+: G𝑖 ×S↦→G+
iniutilizesPILforimageencoding.InstructBLIPoffersitsEVA-G
encodertoconverttheimageintoaneigenvector.The𝑓 0canthen ⟨V𝑖,E𝑖 ⟩∪𝑓 𝑡(𝑄)∪𝑓 𝑣(𝐼)↦→⟨V+,E+⟩
beimplementedas 𝑤.𝑟.𝑡 𝑆𝑖𝑧𝑒, 𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒, 𝐶𝑜𝑚𝑝𝑎𝑐𝑡𝑛𝑒𝑠𝑠 (3)
𝑓 0: Given the image{𝑓 𝑣(𝐼)} andquestion {𝑓 𝑡(𝑄)}, generate a
scenegraphwithevidencetoanswerthequestion.Pleaseensure Anexemplarimplementationis
adherencetofollowingconstrains:{𝑆𝑖𝑧𝑒},{𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒}. 𝑓 +:As{𝑝𝑒𝑟𝑠𝑜𝑛𝑎𝑙𝑖𝑡𝑦},youareassignedasanaffirmativede-
baterandhavebeenprovidedwithanevidencegraph{G𝑖
}for
wheretwoexemplarconstraintsare
𝑆𝑖𝑧𝑒 :Thegraphmustnotbeempty.Pleaserestrictthemaximum
answeringthequestion{𝑓 𝑡(𝑄)}relatedtotheimage{𝑓 𝑣(𝐼)}.Try
toenhancethegraphbyincorporatingyourinsightstowards
numberofobjectsinthegraphto20.
anoptimalsolution.Pleaseensureadherencetofollowingcon-
𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 :Theobjectsandrelationswithinthegraphshould strains:{𝑆𝑖𝑧𝑒},{𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒},{𝐶𝑜𝑚𝑝𝑎𝑐𝑡𝑛𝑒𝑠𝑠}.
bepertinenttoaddressingthequestion.
Notethatwehaveincorporatedtheconclusionfrom[7,36]that
Itworthmentioningthatalthoughweprovidesomeexemplar theagent’sunderstandingoftherolecanbeimprovedbyusing
implementationsoffunctionsandconstraints,theeffectivenessof
the{𝑝𝑒𝑟𝑠𝑜𝑛𝑎𝑙𝑖𝑡𝑦}fortargetedpersonalityinjection.Furthermore,
promptscanvarysignificantlydependingontheMLLMused.The thepersonalitycanbetailoredtobespecific,suchas“Ben,ahigh
successofmultimodalreasoningreliesmoreonthedevelopmentof schoolstudentwithanimpressiveacademicrecordandrespected
guidingprinciplesforpromptingthemodelsandconstraintsforreg- bypeersforyourknowledgeandlogicalthinking.”TheProponent
ularizingtheresultinggraph.Therefore,intherestofthissection, debateadherestotheSizeandRelevanceconstraintsdefinedin
Eq.(3),anditalsoincludestheCompactnessConstraint:TheAPictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
refinedgraphshouldbeasconciseaspossible,ensuringthatthe StoppingCriteria:Theconditiontoconcludethedebatecanbe
blueprintremainsfocused. determinedbyassessingthemodificationsmadetotheevidence
Opponentagentschallengeandpresentargumentsagainstthe graphcomparedtothepreviousroundas
blueprintG+byupdatingitintoanegativeevidencegraphG− as (cid:13) (cid:13)G𝑖+1−G𝑖(cid:13) (cid:13)≤𝜖 (6)
𝑂𝑝𝑝𝑜𝑛𝑒𝑛𝑡 𝑓− : G+×S↦→G−
where∥·∥isadistancemetricdefinedonthegraphs.Therationale
⟨V+,E+⟩∪𝑓 𝑡(𝑄)∪𝑓 𝑣(𝐼)↦→⟨V−,E−⟩
isthatwitheachsuccessfulroundofdebate,theevidencebecomes
𝑤.𝑟.𝑡 𝑆𝑖𝑧𝑒, 𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒, 𝐶𝑜𝑚𝑝𝑎𝑐𝑡𝑛𝑒𝑠𝑠 (4) moreconcise,leadingtothecondensationoftheevidencegraph.
Therefore,wecanquantifythemodificationbytallyingthenumber
Anexemplarimplementationis
ofentities(relations)thathavebeenupdatedandprunedas
𝑓 +:As{𝑝𝑒𝑟𝑠𝑜𝑛𝑎𝑙𝑖𝑡𝑦},youareassignedasanegativedebater
and have been provided with an affirmative evidence graph
(cid:13) (cid:13)G𝑖+1−G𝑖(cid:13) (cid:13)=(cid:13) (cid:13)⟨V𝑖+1,E𝑖+1⟩−⟨V𝑖,E𝑖 ⟩(cid:13)
(cid:13)
{G+}foransweringthequestion{𝑓 𝑡(𝑄)}regardingtheimage =(cid:13) (cid:13){V𝑖+1∩V𝑖 }(cid:13) (cid:13)+(cid:13) (cid:13){E𝑖+1∩E𝑖 }(cid:13)
(cid:13)
{𝑓 𝑣(𝐼)}.Trytodetectpotentialflawsanddrawbacksofthegraph
andupdateitwithyourinsights.Pleaseensureadherenceto +(cid:13) (cid:13){V𝑖 −V𝑖+1∩V𝑖 }(cid:13) (cid:13)+(cid:13) (cid:13){E𝑖 −E𝑖+1∩E𝑖 }(cid:13) (cid:13). (7)
followingconstrains:{𝑆𝑖𝑧𝑒},{𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒},{𝐶𝑜𝑚𝑝𝑎𝑐𝑡𝑛𝑒𝑠𝑠}.
5 EXPERIMENTS
Theutilizationofthefunctions 𝑓 + and 𝑓 − fostersanadversarial
5.1 BackboneModels
dynamicbetweentheProponentandOpponent,ensuringadiverse
andcomprehensivediscussion. Toevaluateitsperformanceandgeneralizability,wehaveimple-
Tofacilitatethedebating,Moderatoragentssynthesizesthe mentedBlueprintDebate-on-Graph(BDoG)usingdifferentpreva-
argumentsandopinionspresentedbyboththeproponentandop- lentmultimodallargelanguagemodelsasbackbones,including
ponentbymergingthe G+ and G− intoaconclusiongraph G∗ 1)GeminiProVision[28],anextensivelyparameterizedmodel
as developedbyGoogle,2)InstructBLIP[6],whichpossessesmore
𝑀𝑜𝑑𝑒𝑟𝑎𝑡𝑜𝑟 𝑓 ∗: G+∪G− ↦→G∗ constraineddimensionsandcomputationalresourcesrelativeto
alternativearchitectures,and3)GPT-4whichisthefourthitera-
⟨V+,E+⟩∪⟨V−,E−⟩↦→⟨V∗,E∗⟩
tionoftheGPTmodeldevelopedbyOpenAI.Moreimplementation
𝑤.𝑟.𝑡 𝑆𝑖𝑧𝑒, 𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒, 𝐶𝑜𝑚𝑝𝑎𝑐𝑡𝑛𝑒𝑠𝑠 (5) detailscanbefoundfromtheAppendix.
Anexemplarimplementationis
5.2 DatasetsandMetrics
𝑓 ∗: As {𝑝𝑒𝑟𝑠𝑜𝑛𝑎𝑙𝑖𝑡𝑦}, you are assigned as a moderator in a
Inlinewiththegeneralsetupdescribedin[21,40],weperformour
debateandhavebeenprovidedwithanaffirmativeevidence
graph{G+}andanegativeevidencegraph{G−}toaddressthe experimentsusingtwoextensivelyadoptedmultimodalquestion
question{𝑓 𝑡(𝑄)}regardingtheimage{𝑓 𝑣(𝐼)}.Trytoconsolidate answering(QA)datasets.Thesedatasetsarewidelyrecognizedas
standard benchmarks, specifically designed to evaluate the per-
thetwographsintoasinglegraphtowardstheoptimalsolution,
formanceandeffectivenessofmodelsinaddressingmultimodal
andprovideaconclusiveanswertothequestion.
reasoning tasks. The two benchmarks are: 1) ScienceQA-IMG
(SQA-IMG)[20]representsthefirstmultimodalscientificquestion-
4.3 DebateProgressandGraphCondensation answeringcorpuscomprising21,000inquiriespairedwithmultiple
InitializationandRoleAssignment:OncetheblueprintG0has choicesandaccompanyingimages.Asatraining-freeapproach,
beeninitialized,thedebatecommenceswiththeassignmentofroles wesolelyutilizetheTESTandDEVpartitionsofScienceQA-IMG
toagentsinA.Denotetheassignmentofarole𝑟 ∈Rtoanagent followingpriorwork[20]forcomparativeassessment.Addition-
𝑎 𝑗 as𝑎 𝑗 := 𝑟,toensureabalanceddebate,anequalnumberof ally,thequestionswithinScienceQAcanbecategorizedintothree
agentsareassignedasProponentsandOpponents,withonlyone subdomains:naturalsciences(NAT),socialsciences(SOC),andlin-
agentassignedastheModerator.TheRoleAssignmentRegulation guisticsciences(LAN).2)MMbench[19]offersamoresystematic
iswritten androbustmeansforreasoningevaluationcomparedtoexisting
benchmarkssuchasVQAv2orCOCOCaptions.Weemploythe
(cid:13) (cid:13){𝑎 𝑗|𝑎
𝑗
:=𝑃𝑟𝑜𝑝𝑜𝑛𝑒𝑛𝑡}(cid:13) (cid:13)=(cid:13) (cid:13){𝑎 𝑘|𝑎
𝑘
:=𝑂𝑝𝑝𝑜𝑛𝑒𝑛𝑡}(cid:13) (cid:13),
officialdatasplit(MMBench-Dev)andcodereleasedbytheorigi-
(cid:13) (cid:13){𝑎 𝑙|𝑎 𝑙 :=𝑀𝑜𝑑𝑒𝑟𝑎𝑡𝑜𝑟}(cid:13) (cid:13)=1. natingauthors.Thestatisticsofthetwobenchmarksaredelineated
inAppendix.Wereporttheaccuracymetricasdeterminedthrough
Debating:Afterrolesareassigned,thedebatecanbeconducted
aheuristicmatchingprocedure,followingthesamesettingofthe
iterativelybetweentheProponentsandOpponentsasillustrated
officialbenchmark[20].
inFigure2.TheinitialblueprintG0isthenupdatedinsubsequent
debaterounds.Ineachround,theModeratorsummarizestheaffir-
5.3 PerformanceComparisontoSOTAMethods
mativeandnegativegraphsinaconclusiongraphonthebasisof
whichatentativeanswerisalsoprovided.Ifthedebateisnotcon- Weevaluatetheproposedmethodbybycomparingitagainsttwo
cluded,theModeratorinitiatesthenextroundbyassignG− asthe setsofstate-of-the-artapproachesasfollows:
blueprintG𝑖+1.Otherwise,theModerator’sanswerisconsidered • Open-SourceMultimodalLLMswithRelativelyModeratePa-
finalandadopted. rametersincludingMiniGPT-4[41],Qwen-VLandQwen-VL-ChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
Model Size SQA-IMG MMBench theirnatureofobtainingvisualinformationthroughimagecap-
MiniGPT-4[41] 7B 37.7 24.3 tioning). Even the open-source VL models of the former group
Qwen-VL[2] 7B 58.6(67.1) 38.2 achievescomparableperformancetothoseofthelatterone,with
Qwen-VL-Chat[2] 7B 68.6(68.2) 60.6 muchsmallerparameterscales.WithBDoG,whichreinforcesmul-
mPLUG-Owl2[35] 8B 63.9 66.5 timodalreasoningbygraphregulation,theperformanceofdirect
CogVLM-Chat[31] 17B 69.6 63.7 multimodalreasoningofInstructBLIPandGeminiProVisionhave
LLaVA-v1.5[18] 13B 71.9(71.6) 68.2 beenimprovedby6.1%and19.8%ontheMMBenchdataset.
InstructBLIP[6] 13B 59.2(63.1) 36.0
InstructBLIP+BDoG 13B 63.5 55.8 5.4 AblationStudy
GPT-3.5+CoT[33] 175B 67.4 -
InordertogainacomprehensiveunderstandingofBDoG,wecon-
GPT-3.5+DDCoT[40] 175B 72.5 -
ductanablationstudywherewedecomposeBDoGintotwovari-
GPT-4+CoT[33] - 71.5 75.1
ants:
GPT-4+BDoG - 77.2 79.2 • BDoG𝐷𝑒𝑏𝑎𝑡𝑒 :weremovethegraphregulationandconstraints,
GeminiProVision[28] - 76.5 75.2
resultinginadebate-onlyapproach(i.e.,vanillamulti-agentde-
GeminiProVision+BDoG - 81.1 81.3
bate)forinvestigatingthespecificcontributionofthedebating
Table1:Overallzero-shotresultsonScienceQA-IMGtestset componentofBDoG.
andMMBenchdevset.Size=backbonemodelsize.Thereare • BDoG𝐺𝑟𝑎𝑝ℎ : we remove the debating rounds, resulting in a
limitedzero-shotresultspreviouslypublishedonScienceQA- graph-basedreasoningmethodforinvestigatingthespecificcon-
IMG, so we reimplemented above models and report our tributionofthegraphregulationcomponentofBDoG.
findings.Wherepossible,weincluderesultsfromtheLLaVA
Moreover,weanalyzetheperformanceofthetwovariantsonthe
paperforcomparison(showninparentheses).ForMMBench,
benchmarksbybreakingitdownintosubcategories.Thisanalysis
werefertothescoreslistedontheofficialpublicleaderboard.
allowsustoinvestigatethepreferencesofthesetwovariantsfor
differenttypesofquestions.TheresultsarepresentedinTable2,
whereitcanbeobservedthatbothvariantsdemonstratecompara-
bleperformanceacrossvariousbenchmarks.Thissuggeststhatthe
Chat[2],CogVLM-Chat[31],mPLUG-Owl2[35],LLaVA-v1.5 debateandgraphcomponentsofBDoGcontributetoitseffective-
[18],andInstructBLIP[6].Thesemodelshaveparameterscales nessinasimilarmanner.Throughthecombinationofthesetwo
rangingfrom7Bto17B componentsinBDoG,theperformancehasexperiencedfurther
• Closed-SourceMultimodalLLMswithLarge-ScaleParameters: improvementcomparedtotheindividualvariants.However,when
GPT-3.5[33],GPT-4V[1]andGeminiProVision[28].Following consideringspecificcategories,distinctionsinthecontributionsof
thegeneralstandard,GPT-3.5andGPT-4havebeenincorporated thedebateandgraphcomponentsbecomeapparent.
withtheCoT[33]orDDCoT[40](builtbasedonimagecaption- Impactofthedebatecomponent:BDoG𝐷𝑒𝑏𝑎𝑡𝑒 demonstrates
ingresults).Thesemodelsareknownfortheirparameterscales consistentimprovementsacrossbothbenchmarkswithadebate-
above175Bandareconsideredtohavethebestperformancein onlysetting,whichencouragesLLMagentstocollaborativelyrefine
mostoftheliterature. andcorrectpriorresponses.Forsciencequestions,BDoG𝐷𝑒𝑏𝑎𝑡𝑒 fa-
TheresultsareshowninTable1.TheintegrationofBDoGhas cilitatesthemodel’sfocusonspecificerrors,suchasdirection,size,
resultedinasignificantimprovementacrossdifferentbackbones, andposition,leadingtoimprovedperformanceinthenaturalsci-
asevidencedbytheperformancegainsof4.3% ∼ 5.7%onSQA- encedomain(boostingaccuracyfrom53.7to59.7forInstructBLIP
𝐷𝑒𝑏𝑎𝑡𝑒
IMGand6.1% ∼ 19.8%onMMBench.Notably,whencombined and68.9to73.3forGeminiProVision).Additionally,BDoG
withGeminiProVision,BDoGachievesSOTAperformanceonthe significantlyenhanceslogicalreasoningtasks(improvingaccuracy
ScienceQA-IMGtestsetandMMBenchdevelopmentset,achieving from 14.2 to 43.7). However, the debate-only nature has limita-
accuraciesof81.1%and81.3%,respectively.Otherobservationsthat tions,includingtrivializationandfocusdiversionissues.Without
indicateBDoG’sadvantageoverSOTAmethodsinclude: thegraphregulation,overallperformancedecreasesfrom55.8to
BDoGhelpsreducetheperformancegapbetweenlarge 42.6forInstructBLIP,particularlywhenaddressingquestionsthat
andsmallmodels.Itiscommonlybelievedthatmodelswithlarger requireattentiontospecificattributesandrelations.
parameterscalestendtoperformbetterthansmallerones.This Impactofthegraphregulation:Withagraph-regularizedknowl-
𝐺𝑟𝑎𝑝ℎ
observationgenerallyholdstrue,asshowninTable1formodels edgebaseforthediscussion,BDoG alsodemonstratesconsis-
withoutBDoG.However,theintroductionofBDoGhasledtoa
tentimprovementof2.3%∼15.1%oversthebasemodelsonboth
reductionintheperformancegapbetweenthesetwotypesofmod- benchmarks.Comparedtothetext-basedanddebate-onlymethod
𝐷𝑒𝑏𝑎𝑡𝑒
els.ThiscanbeseenintheimprovementachievedbyInstructBLIP, BDoG , it performs evidently better on the MMBench by
whichhasexperiencedaboostof4.3%andachievesanaccuracyof 1.4%∼8.5%.Thisisnotasurprise,becauseMMBenchemphasizes
63.5%onSQA-IMG,comparabletothatofGPT-3.5. moretheattributeandrelationswhichchallengesamodel’sability
BDoGreinforcesthemultimodalreasoning.FormTable1,we onstructuralreasoning.Althoughincorporatingfact-relatedgraph
𝐺𝑟𝑎𝑝ℎ
canalsoobservetheadvantageofdirectmultimodalreasoning(e.g., informationprovesbeneficialinBDoG ,theabsenceoftheit-
open-sourceVLmodels,andGeminiProVision)overindirectmul- erativelyrefineddebateprocedureresultsindecreasedperformance
timodalreasoning(e.g.,GPT3.5+CoTandGPT3.5+DDCoTdueto duetothecoarseanddistortedextractionofblueprintinformation.APictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
ScienceQA-IMG-Dev ScienceQA-IMG-Test MMBench-Dev
Model Method
NAT SOC LAN Avg NAT SOC LAN Avg LR AR RR FP-S FP-C CP Avg
MniGPT-4[41] 42.9 30.6 43.7 38.4 42.0 30.1 50.0 37.7 7.5 31.3 4.3 30.3 9.0 35.6 24.3
Qwen-VL[2] 52.1 59.8 58.3 55.0 55.7 62.0 77.3 58.7 16.1 44.7 34.8 35.2 39.2 46.6 38.2
Qwen-VL-Chat[2] 60.9 67.4 62.5 63.3 67.7 69.6 75.0 68.6 32.2 59.8 43.5 66.2 48.3 79.4 60.6
Base
mPLUG-Owl2[35] 60.6 68.0 45.8 62.8 62.5 66.2 61.4 63.9 32.2 72.4 60.9 68.6 60.1 79.4 66.5
CogVLM-Chat[31] 63.1 69.2 77.1 65.6 68.0 72.2 70.4 69.7 29.7 65.8 60 66.9 58 76.7 63.7
LLaVA-v1.5[18] 66.1 74.9 72.9 69.4 70.1 74.2 81.8 71.9 44.1 67.3 60.0 72.0 59.4 82.1 68.2
Base 53.7 57.3 47.9 54.8 58.1 61.0 61.4 59.2 14.2 46.3 22.6 37.0 21.4 49.0 36.0
+BDoG𝐷𝑒𝑏𝑎𝑡𝑒 59.7 55.6 54.2 58.1 63.1 58.2 72.7 61.4 43.7 57.8 31.5 42.7 19.5 39.1 42.6
InstructBLIP[6] +BDoG𝐺𝑟𝑎𝑝ℎ 58.1 61.3 52.1 59.0 60.6 62.6 68.2 61.5 58.8 65.5 41.2 51.2 18.6 46.1 51.1
+BDoG 61.1 64.0 52.1 61.9 61.1 66.5 75.0 63.5 63.3 71.9 37.8 56.3 20.3 59.1 55.8
Base 68.9 81.6 75.0 73.7 72.9 81.5 88.6 76.5 55.9 80.4 73.9 79.5 61.5 82.1 75.2
+BDoG𝐷𝑒𝑏𝑎𝑡𝑒 73.3 81.1 77.1 76.2 75.3 82.8 93.2 78.5 71.1 85.1 83.1 78.9 71.9 81.3 79.3
GeminiProVision[28] +BDoG𝐺𝑟𝑎𝑝ℎ 69.8 84.8 87.5 75.6 74.7 86.8 88.6 79.6 75.0 84.5 80.7 81.4 73.0 83.6 80.7
+BDoG 73.6 86.2 85.4 78.4 76.6 87.4 93.2 81.1 74.0 84.8 83.4 81.3 73.7 84.4 81.3
Table2:AblationstudyonScienceQA-IMGdevandtestsetandMMBenchdevset.Questionclasses:NAT=naturalscience,SOC
=socialscience,LAN=languagescience,LR=LogicalReasoning;AR=AttributeReasoning;RR=RelationReasoning;FP-S=
Fine-grainedPerception(SingleInstance);FP-C=Fine-grainedPerception(CrossInstance);CP=CoarsePerception.
Which country is highlighted? Arethetwocandyjarsinthepicture
Options: thesameshape?
A.Haiti Options:
B.Dominica A.Same
C.the Dominican Republic B.Notthesame
D.Trinidad and Tobago C.Can’tjudge
Round1 Round1
BDoGDebate: BDoG: Haiti BDoGDebate: BDoG:
Small Small
The highlighted country is the Dominica. Located The two candy jars in the picture arenot the Square Blue Round Purple
Dominica is an island country in the Trinidad _in same shape. The first candy jar is a cylinder,
Caribbean Sea,…There are a few possible andTobago Caribbean Sea while the second candy jar is a sphere....
s oo f l eu cti oo nn os m to ic t h de e vp er lo ob pl mem en o t.f OD no em si on li uc ta i' os n l a ic s k t o Located_in D jae rss p ai rt ee nth oe t s te h es i sm amila er i st hie as p, e t .h Te htw eyo ac ra en dy Contains Candy1 Contains Ca And ny s2 wer:C
focus on developing the tourism industry… Dominica D Reo pm ui bn li ic ca different in height, diameter, and shape. Jar1 Jar2
Round2 Round2
BDoGDebate: BDoG: GeneratedMarks: BDoGDebate: BDoG: Candy2
Green The highlighted Contains
I believe that these three solutions would Haiti Color country is Dominica. The two candy jars in the picture are the Candy1 Jar2 Shape
help to address the problem of Dominica‘s The other islands are same shape. They are both cylindrical jars Contains Radius
l c pa o ec m ok p mo lef i t oe m fc eo Dnn oto mfm ro ii nc m i cd ate h .v ee glo op vm ere nn mt. e . n. ta al no dn g th-t ee rm T a Tnr odi bn aid ga od DC omol io nr ica HIs ighlighten q do ut e sr te il oe nv .a ..n t to the w o isn i tt l ah y l la d e i rr f o f te hu r an e nd n c tb hea e s … e ja a ri n s o d t nh a ta htr eo t hu ren ig d j ha t tro . op n. T thh ee left R 5a cd miusJar1 Shap Ce ylin5 dc em r Cylinder
Round3 Round3
BDoGDebate: BDoG: BDoGDebate: BDoG:
Country Cylinder Answer:
I think the highlighted country is Barbados. Green Answer: I think that the best solution to this problem A.Same
It is an island country located in the Type B.Dominica is to use a different type of candy jar. There
Caribbean Sea. It is known for its beautiful Color Is are many different types of candy jars…, so Shape
b ise aa lc sh oe as , p.. oa pn ud la f rr i te on ud ril sy t p de eo stp il ne a. t T ioh ne . country Dominica Highlighted i st h s ah po eu al sd tb he e e oa ts hy e rt o c af nin dd y o jan re . that is the same Jar1 Same Cylinder
Jar2
𝐷𝑒𝑏𝑎𝑡𝑒
Figure3:CasestudyofourproposedBlueprintDebateonGraph(BDoG)andvallinaMulti-agentDebate(BDoG )on
ScienceQA-IMG (left) and MMBench (right) datasets. Green color indicates the correct answer/rationale and Red means
incorrect/irrelevantpredictions.
Impactofcombiningthedebateandgraphcomponents:By enhanceslogicalreasoning(LR)throughamechanismthatrefines
combiningthetwocomponents,BDoGachievesgainsacrossnearly thereasoningprocessiteratively,emphasizingtheimportanceof
allcategories.IntheScienceQA-IMGdataset,BDoGexhibitscon- multi-stepreasoningrationales.Theblueprintgraphstructureof
sistentandsteadyimprovements,averagingaround5%compared BDoG,whichexplicitlymodelsobjects,attributes,andrelations,
to the baseline models. This suggests that BDoG is robust and contributestoimprovedreasoningabilitiesinAttributeReasoning
generalizeswellforscience-relatedquestions.Remarkably,BDoG (AR)andRelationReasoning(RR).TheGeminiProVisionmodel
significantlyoutperformsthebaselinemodel(InstructBLIP)onthe alsoexhibitscomparableperformanceimprovements,withBoG
MMBench-Devset,particularlyintheareasofLogicalReasoning contributingtoenhancedfine-grainedperceptionacrossinstances
(LR)withamarginof49.1%,AttributeReasoning(AR)withamargin
of26.6%,andRelationReasoning(RR)withamarginof15.2%.BDoGChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
(FP-C),resultinginagainof12.2%.Thisimprovementcanbeattrib-
utedtotheconnectionsestablishedbetweenvariousobjectswithin 1600 #Update 3500 #Update
thedebate-on-graphframework. 1400 #Prune 3000 #Prune
#Add #Add
Acasestudyfortheiterativeimprovementontheblueprint: 1200 2500
BDoGleveragestheadvantagesofbothstructuredevidencethrough 1000 2000
800
graphregulationanditerativerefinementthroughdebating.Thisis 1500
600
evidentintheconsistentimprovementobservedontheblueprint 400 1000
graph,showcasingthecombinedbenefitsofthesetwocomponents. 200 500
Figure3providesrunningexamplesdemonstratingthesuperiorrea- R1 R2 Round R3 R4 R1-R2 RR o2 u-R n3 d R3-R4
soningperformanceofourproposedBDoGframeworkcompared
𝐷𝑒𝑏𝑎𝑡𝑒 Figure 4: Statistics of intra-round (left) and inter-round
totheBDoG method.
(right)BlueprintcondensationofBDoGwithGeminiProVi-
TheleftcasedrawsfromtheScienceQAdataset,testinggeo-
𝐷𝑒𝑏𝑎𝑡𝑒 sionforScienceQA-IMGtestset.#Update:numberofupdated
graphicknowledgeandmapinterpretation.WhileBDoG
attributes;#Add:numberofnewly-addedentities/relations;
correctlyansweredDominicaishighlighted,italsogeneratedirrele-
#Prune:numberofprunedentities/relations.
vantinformationaboutDominica’seconomicdevelopment.This
misguidedtheagentsintooff-topicdiscussion,concludingincor-
rectlywithBarbados.Incontrast,BDoGconcentratedontheques-
model’sperformancetendedtoconvergewithinthesecondorthird
tion and options, iteratively refining the blueprint entities and
round.Thiscanbeattributedtotheunderlyingreasoningtypically
relationstoarriveattherightanswerofDominica.
beingabletoanswerquestionswithin2-3steps.
TheexampleontherightcomesfromtheMMBenchdataset
Additionally,Figure4illustratesthenumberofupdatedattributes,
requiringcross-instanceperception.Astheimagecontainedboth
newlyaddedorremovedentitiesorrelationsbetweenandwithin
𝐷𝑒𝑏𝑎𝑡𝑒
candiesandjars,itposedachallenge.WithBDoG relyingon
rounds.AstrengthofourproposedBDoGframeworkisitsability
textalone,agreementwasrarelyreachedasresponseschangedover
toquantifythedebateprocessbyinspectinggraphchanges.This
debaterounds.However,BDoGfirstgeneratedablueprintdefin-
demonstratestheeffectivenessofdynamicallyadjustingtheinitial
ingimageobjectsandattributes.Thisestablishedthediscussion
graphbasedonthediscussion.TheresultsinFigure4arealsocon-
scope.BDoGthenprunedirrelevantcandyinformation,focusing
sistentwithourhypothesisthatdisagreementsanderrorscanbe
discussiononthespecificobject-jars.Itoutputthefinalanswer
decreasedasthedebateprogresses.
bycomparingandconnectingthetwojarsub-graphs.
𝐷𝑒𝑏𝑎𝑡𝑒
Insummary,Figure3demonstratesthatBDoGbeatsBDoG
onbothdatasetsthroughitsblueprint-drivenapproach.Thiscon-
centratesgraph-basedreasoningonsalienttopicsandprunesirrel- 1.0 0.9
BDoG (Debate)
evantdetailstoarriveatwell-supportedconclusions. BDoG
0.811 0.813
0.8 0.784 0.8
0.765
0.752 0.736
ScienceQA-IMG-Test MMBench-Dev
Round 0.6 0.7
BDoG-S BDoG-L BDoG-S BDoG-L
1 60.5 80.6 51.6 81.0 0.4 0.6
2 63.5 80.9 54.6 81.1
3 63.1 81.1 55.8 81.3
0.2 0.5
4 63.3 81.4 55.8 80.9
Table 3: Model performance with respect to the iteration
0.0 0.4
roundofdebate.BDoG-S:InstructBLIPwithBDoG,BDoG-L: SQA-IMG-Test SQA-IMG-Dev MMBench-Dev
Datasets
GeminiProVisionwithBDoG.
Figure5:Effectivenessvs.efficiencyresults,comparingour
proposed Blueprint Debate-on-Graph (BDoG) and vanilla
Multi-agent Debate (BDoG (Debate)) on GeminiProVision.
5.5 MonitoringTheDebatingProgress Thebarchartindicatestheinferencetimeonthreedatasets
andlinesindicatethezero-shotperformance(Accuracy).
We evaluated the model’s performance against the termination
criteriaacrossmultipledebateroundsbasedonthedatainTable
3.Ouranalysisshowedthatformodelswithsmallerparameters
5.6 EfficiencyAnalysis
likeInstructBLIP,movingfromasingleroundtotworoundsledto
significantgainsinperformance.Thisimprovementwasparticu- We further compared the effectiveness versus efficiency of our
𝐷𝑒𝑏𝑎𝑡𝑒
larlynotablewhenincreasingthenumberofroundsfromoneto BDoGframeworkagainstBDoG ,withresultsshowninFig-
two.However,forlargermodelsthatmayreachagreementmore ure 5. Maintaining concise content focused on key aspects, the
easily,theperformanceenhancementwasrelativelymodestwhen graphstructureofBDoGdemonstratedsuperiorefficiency,requir-
𝐷𝑒𝑏𝑎𝑡𝑒
amplifyingthenumberofdebaterounds.Ingeneral,wefoundthe ingapproximately50%lessinferencetimethanBDoG .By
tnuoC
noitacifidoM
hparG
ycaruccA
tnuoC
noitacifidoM
hparG
emiT
ecnerefnIAPictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
firstgeneratingablueprint,BDoGdefinesthescopeofthecurrent onKnowledgeandDataEngineering(2023).
state,therebyimprovingmodelefficiencybyfilteringirrelevant [12] JieHuang,XinyunChen,SwaroopMishra,HuaixiuStevenZheng,AdamsWei
Yu,XinyingSong,andDennyZhou.2023. LargeLanguageModelsCannot
information.Concurrently,Figure5showsBDoGoutperformed
Self-CorrectReasoningYet.InTheTwelfthInternationalConferenceonLearning
𝐷𝑒𝑏𝑎𝑡𝑒
BDoG ineffectiveness,achievingover5percentagepoints Representations.
𝐷𝑒𝑏𝑎𝑡𝑒 [13] ShaohanHuang,LiDong,WenhuiWang,YaruHao,SakshamSinghal,Shuming
higheraccuracythanBDoG acrossthreetestsets.
Ma,TengchaoLv,LeiCui,OwaisKhanMohammed,BarunPatra,etal.2024.Lan-
ThisenhancedeffectivenesscanbeattributedtoBDoG’sframe- guageisnotallyouneed:Aligningperceptionwithlanguagemodels.Advances
workconcentratingonimportantknowledgeratherthangenera- inNeuralInformationProcessingSystems36(2024).
𝐷𝑒𝑏𝑎𝑡𝑒 [14] JunnanLi,DongxuLi,SilvioSavarese,andStevenHoi.2023.Blip-2:Bootstrapping
tionaltextualcontentwithoutguidance,asinBDoG .Defin- language-imagepre-trainingwithfrozenimageencodersandlargelanguage
ingablueprinttoestablishthediscussionboundariesbeforegener- models.arXivpreprintarXiv:2301.12597(2023).
[15] XingxuanLi,RuochenZhao,YewKenChia,BoshengDing,ShafiqJoty,Soujanya
atingagraphstructureenhancesbothefficiencyandeffectiveness
Poria,andLidongBing.2023.Chain-of-Knowledge:GroundingLargeLanguage
byrestrictingthemodel’sreasoningtosalienttopics.Insummary, ModelsviaDynamicKnowledgeAdaptingoverHeterogeneousSources.InThe
Figure5illustratesBDoGdemonstratedbettertimeperformance TwelfthInternationalConferenceonLearningRepresentations.
𝐷𝑒𝑏𝑎𝑡𝑒 [16] TianLiang,ZhiweiHe,WenxiangJiao,XingWang,YanWang,RuiWang,Yujiu
andpredictivepowercomparedtoBDoG ,validatingtheutil-
Yang,ZhaopengTu,andShumingShi.2023. EncouragingDivergentThink-
ityofourapproachinbalancingcomputationalcostandpredictive inginLargeLanguageModelsthroughMulti-AgentDebate. arXivpreprint
accuracythroughfocused,blueprint-drivendebate. arXiv:2305.19118(2023).
[17] BillYuchenLin,XinyueChen,JaminChen,andXiangRen.2019. KagNet:
Knowledge-AwareGraphNetworksforCommonsenseReasoning.InProceedings
6 CONCLUSION ofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingand
the9thInternationalJointConferenceonNaturalLanguageProcessing(EMNLP-
Thispaperhaspresentedapioneeringpilotstudythatintroduces IJCNLP).2829–2839.
multi-agentdebateintotherealmofmultimodalreasoning.We [18] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee.2024. Visualin-
structiontuning.Advancesinneuralinformationprocessingsystems36(2024).
tackledtwoprominentchallengesfacedinthiscontext:theissue [19] YuanLiu,HaodongDuan,YuanhanZhang,BoLi,SongyangZhang,Wangbo
ofopinionsbeingtrivializedandfocusdiversion.Byrecognizing Zhao,YikeYuan,JiaqiWang,ConghuiHe,ZiweiLiu,etal.2023.Mmbench:Is
yourmulti-modalmodelanall-aroundplayer?arXivpreprintarXiv:2307.06281
thelimitationsofexistingdebatingschemes,weproposeBlueprint
(2023).
DebateonGraphs(BDoG),whichconfinesdebatestoablueprint [20] PanLu,SwaroopMishra,TanglinXia,LiangQiu,Kai-WeiChang,Song-Chun
graphandstoresevidenceingraphbranches,toaddressthechal- Zhu,OyvindTafjord,PeterClark,andAshwinKalyan.2022.Learntoexplain:
Multimodalreasoningviathoughtchainsforsciencequestionanswering.Ad-
lengesofword-levelopiniontrivializationanddistractioncaused
vancesinNeuralInformationProcessingSystems35(2022),2507–2521.
byirrelevantconcepts.ExtensiveexperimentsconductedinSci- [21] PanLu,BaolinPeng,HaoCheng,MichelGalley,Kai-WeiChang,YingNianWu,
enceQAandMMBenchvalidatetheefficacyofBDoG,surpassing Song-ChunZhu,andJianfengGao.2024.Chameleon:Plug-and-playcomposi-
tionalreasoningwithlargelanguagemodels.AdvancesinNeuralInformation
previousmethodsandestablishingnewstate-of-the-artresults. ProcessingSystems36(2024).
[22] AmanMadaan,NiketTandon,PrakharGupta,SkylerHallinan,LuyuGao,Sarah
REFERENCES Wiegreffe,UriAlon,NouhaDziri,ShrimaiPrabhumoye,YimingYang,etal.
2024.Self-refine:Iterativerefinementwithself-feedback.AdvancesinNeural
[1] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,Floren- InformationProcessingSystems36(2024).
ciaLeoniAleman,DiogoAlmeida,JankoAltenschmidt,SamAltman,Shyamal [23] ChancharikMitra,BrandonHuang,TrevorDarrell,andRoeiHerzig.2023.Com-
Anadkat,etal.2023. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774 positionalchain-of-thoughtpromptingforlargemultimodalmodels. arXiv
(2023). preprintarXiv:2311.17076(2023).
[2] JinzeBai,ShuaiBai,ShushengYang,ShijieWang,SinanTan,PengWang,Junyang [24] Debjyoti Mondal, Suraj Modi, Subhadarshi Panda, Rituraj Singh, and Go-
Lin,ChangZhou,andJingrenZhou.2023. Qwen-vl:Afrontierlargevision- dawariSudhakarRao.2024. KAM-CoT:KnowledgeAugmentedMultimodal
languagemodelwithversatileabilities.arXivpreprintarXiv:2308.12966(2023). Chain-of-ThoughtsReasoning.arXivpreprintarXiv:2401.12863(2024).
[3] RemiCadene,HediBen-Younes,MatthieuCord,andNicolasThome.2019.Murel: [25] HyeonseobNam,Jung-WooHa,andJeongheeKim.2017.Dualattentionnetworks
Multimodalrelationalreasoningforvisualquestionanswering.InProceedingsof formultimodalreasoningandmatching.InProceedingsoftheIEEEconferenceon
theIEEE/CVFconferenceoncomputervisionandpatternrecognition.1989–1998. computervisionandpatternrecognition.299–307.
[4] Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,WeiXue,Shanghang [26] NoahShinn,FedericoCassano,AshwinGopinath,KarthikNarasimhan,and
Zhang,JieFu,andZhiyuanLiu.2023. ChatEval:TowardsBetterLLM-based ShunyuYao.2024.Reflexion:Languageagentswithverbalreinforcementlearn-
EvaluatorsthroughMulti-AgentDebate.InTheTwelfthInternationalConference ing.AdvancesinNeuralInformationProcessingSystems36(2024).
onLearningRepresentations. [27] JiashuoSun,ChengjinXu,LumingyuanTang,SaizhuoWang,ChenLin,Yeyun
[5] KarlCobbe,VineetKosaraju,MohammadBavarian,MarkChen,HeewooJun, Gong,LionelNi,Heung-YeungShum,andJianGuo.2023.Think-on-Graph:Deep
LukaszKaiser,MatthiasPlappert,JerryTworek,JacobHilton,ReiichiroNakano, andResponsibleReasoningofLargeLanguageModelonKnowledgeGraph.In
etal.2021. Trainingverifierstosolvemathwordproblems. arXivpreprint TheTwelfthInternationalConferenceonLearningRepresentations.
arXiv:2110.14168(2021). [28] GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-Baptiste
[6] WenliangDai,JunnanLi,DongxuLi,AnthonyMengHuatTiong,JunqiZhao, Alayrac,JiahuiYu,RaduSoricut,JohanSchalkwyk,AndrewMDai,AnjaHauth,
WeishengWang,BoyangAlbertLi,PascaleFung,andStevenC.H.Hoi.2023.In- etal.2023.Gemini:afamilyofhighlycapablemultimodalmodels.arXivpreprint
structBLIP:TowardsGeneral-purposeVision-LanguageModelswithInstruction arXiv:2312.11805(2023).
Tuning.ArXivabs/2305.06500(2023). [29] KehengWang,FeiyuDuan,SiruiWang,PeiguangLi,YunsenXian,Chuantao
[7] YilunDu,ShuangLi,AntonioTorralba,JoshuaBTenenbaum,andIgorMor- Yin,WengeRong,andZhangXiong.2023. Knowledge-drivencot:Exploring
datch.2023.ImprovingFactualityandReasoninginLanguageModelsthrough faithfulreasoninginllmsforknowledge-intensivequestionanswering.arXiv
MultiagentDebate.arXivpreprintarXiv:2305.14325(2023). preprintarXiv:2308.13259(2023).
[8] JieHe,TaoWang,DeyiXiong,andQunLiu.2020. Theboxisinthepen: [30] LeiWang,YiHu,JiabangHe,XingXu,NingLiu,HuiLiu,andHengTao
Evaluatingcommonsensereasoninginneuralmachinetranslation.InFindings Shen.2023. T-SciQ:TeachingMultimodalChain-of-ThoughtReasoningvia
oftheAssociationforComputationalLinguistics:EMNLP2020.3662–3672. LargeLanguageModelSignalsforScienceQuestionAnswering.arXivpreprint
[9] DanHendrycks,CollinBurns,StevenBasart,AndyZou,MantasMazeika,Dawn arXiv:2305.03453(2023).
Song,andJacobSteinhardt.2020.MeasuringMassiveMultitaskLanguageUn- [31] WeihanWang,QingsongLv,WenmengYu,WenyiHong,JiQi,YanWang,Junhui
derstanding.InInternationalConferenceonLearningRepresentations. Ji,ZhuoyiYang,LeiZhao,XixuanSong,etal.2023.Cogvlm:Visualexpertfor
[10] SameeraHorawalavithana,SaiMunikoti,IanStewart,andHenryKvinge.2023. pretrainedlanguagemodels.arXivpreprintarXiv:2311.03079(2023).
Scitune:Aligninglargelanguagemodelswithscientificmultimodalinstructions. [32] YananWang,MichihiroYasunaga,HongyuRen,ShinyaWada,andJureLeskovec.
arXivpreprintarXiv:2307.01139(2023). 2023. VQA-GNN:ReasoningwithMultimodalKnowledgeviaGraphNeural
[11] LinmeiHu,ZeyiLiu,ZiwangZhao,LeiHou,LiqiangNie,andJuanziLi.2023.A NetworksforVisualQuestionAnswering.InProceedingsoftheIEEE/CVFInter-
surveyofknowledgeenhancedpre-trainedlanguagemodels.IEEETransactions nationalConferenceonComputerVision.21582–21592.ChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
[33] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi, [37] JintianZhang,XinXu,andShuminDeng.2023.Exploringcollaborationmecha-
QuocVLe,DennyZhou,etal.2022.Chain-of-thoughtpromptingelicitsreason- nismsforllmagents:Asocialpsychologyview.arXivpreprintarXiv:2310.02124
inginlargelanguagemodels.AdvancesinNeuralInformationProcessingSystems (2023).
35(2022),24824–24837. [38] ZhuoshengZhang,AstonZhang,MuLi,HaiZhao,GeorgeKarypis,andAlex
[34] SeanWelleck,XimingLu,PeterWest,FaezeBrahman,TianxiaoShen,Daniel Smola.2023.Multimodalchain-of-thoughtreasoninginlanguagemodels.arXiv
Khashabi,andYejinChoi.2022. GeneratingSequencesbyLearningtoSelf- preprintarXiv:2302.00923(2023).
Correct.InTheEleventhInternationalConferenceonLearningRepresentations. [39] ChuanyangZheng,ZhengyingLiu,EnzeXie,ZhenguoLi,andYuLi.2023.
[35] HaiyangXu,QinghaoYe,MingshiYan,YayaShi,JiaboYe,YuanhongXu,Chen- Progressive-hintpromptingimprovesreasoninginlargelanguagemodels.arXiv
liangLi,BinBi,QiuchenQian,WeiWang,GuohaiXu,JiZhang,SongfangHuang, preprintarXiv:2304.09797(2023).
FeiranHuang,andJingrenZhou.2023.mPLUG-2:AModularizedMulti-modal [40] GeZheng,BinYang,JiajinTang,Hong-YuZhou,andSibeiYang.2023.DDCoT:
FoundationModelAcrossText,ImageandVideo.InInternationalConferenceon Duty-DistinctChain-of-ThoughtPromptingforMultimodalReasoninginLan-
MachineLearning. guageModels.InThirty-seventhConferenceonNeuralInformationProcessing
[36] ZhangyueYin,QiushiSun,ChengChang,QipengGuo,JunqiDai,Xuan-Jing Systems.
Huang,andXipengQiu.2023.Exchange-of-thought:Enhancinglargelanguage [41] DeyaoZhu,JunChen,XiaoqianShen,XiangLi,andMohamedElhoseiny.2024.
modelcapabilitiesthroughcross-modelcommunication.InProceedingsofthe2023 MiniGPT-4:EnhancingVision-LanguageUnderstandingwithAdvancedLarge
ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.15135–15153. LanguageModels.InTheTwelfthInternationalConferenceonLearningRepresen-
tations. https://openreview.net/forum?id=1tZbq88f27