FEDERATED BAYESIAN DEEP LEARNING: THE APPLICATION OF
STATISTICAL AGGREGATION METHODS TO BAYESIAN MODELS
APREPRINT
JohnFischer MarkoOrescanin JustinLoomis
DepartmentofComputerScience DepartmentofComputerScience DepartmentofComputerScience
NavalPostgraduateSchool NavalPostgraduateSchool NavalPostgraduateSchool
Monterey,CA93954 Monterey,CA93954 Monterey,CA93954
john.fischer@nps.edu marko.orescanin@nps.edu
PatrickMcClure
DepartmentofComputerScience
NavalPostgraduateSchool
Monterey,CA93954
March22,2024
ABSTRACT
Federatedlearning(FL)isanapproachtotrainingmachinelearningmodelsthattakesadvantage
ofmultipledistributeddatasetswhilemaintainingdataprivacyandreducingcommunicationcosts
associatedwithsharinglocaldatasets. Aggregationstrategieshavebeendevelopedtopoolorfuse
the weights and biases of distributed deterministic models; however, modern deterministic deep
learning(DL)modelsareoftenpoorlycalibratedandlacktheabilitytocommunicateameasureof
epistemicuncertaintyinprediction,whichisdesirableforremotesensingplatformsandsafety-critical
applications. Conversely,BayesianDLmodelsareoftenwellcalibratedandcapableofquantifying
andcommunicatingameasureofepistemicuncertaintyalongwithacompetitivepredictionaccuracy.
Unfortunately,becausetheweightsandbiasesinBayesianDLmodelsaredefinedbyaprobability
distribution,simpleapplicationoftheaggregationmethodsassociatedwithFLschemesfordeter-
ministicmodelsiseitherimpossibleorresultsinsub-optimalperformance. Inthiswork, weuse
independentandidenticallydistributed(IID)andnon-IIDpartitionsoftheCIFAR-10datasetanda
fullyvariationalResNet-20architecturetoanalyzesixdifferentaggregationstrategiesforBayesian
DL models. Additionally, we analyze the traditional federated averaging approach applied to an
approximate Bayesian Monte Carlo dropout model as a lightweight alternative to more complex
variationalinferencemethodsinFL.Weshowthataggregationstrategyisakeyhyperparameterin
thedesignofaBayesianFLsystemwithdownstreameffectsonaccuracy,calibration,uncertainty
quantification,trainingstability,andclientcomputerequirements.
Keywords Bayesiandeeplearning·federatedlearning·MonteCarlodropout·uncertaintydecomposition·uncertainty
quantification·variationalinference
1 Introduction
1.1 Motivation
Remotesensorsareubiquitousintheworldtoday. Thisisduetothecontinualadvancementinhardwaretechnology,
whichsupportstheirdeploymentinever-shrinking,affordabledevices. Themassdeploymentofremotesensorshas
resulted in an explosion in the amount of data collected in support of various research groups, corporations, and
governmententities[1]. Theoverwhelmingtaskofanalyzingthisdatahasresultedinadesiretoautomateortoaugment
4202
raM
22
]GL.sc[
1v36251.3042:viXraFederatedBayesianDeepLearning APREPRINT
dataanalysisusingdeeplearning(DL)techniques. Inmanyremotesensingapplications,thecostofcollecting,labeling,
communicating,andstoringlocaldatamaybeacceptable;however,whendeployingsensorsallovertheworld,these
costscanbreachthethresholdofacceptability. Inotherapplications,thetransferandstorageofuserdataraisesdata
privacyconcernsandregulations,suchastheGeneralDataProtectionRegulation(GDPR)[2],andimposessignificant
restrictionsonthehandlingofsuchdata. Inordertoaddresstheseissues,McMahanetal.[3]developedatechnique
thattheytermedfederatedlearning(FL),wherebyclientmodelstrain,orupdate,aninstanceofaglobalmodelusing
locallycaptureddataandperiodicallysendupdatedmodelparameterstoacentralserverforaggregation. ByusingFL,
itispossibletotakeadvantageofnumerousdistributeddatasetswhilemaintainingprivacyandreducingcommunication
costsassociatedwithtrainingonacollectionoftheseindividualdatasets.
SincetheseminalworkbyMcMahanetal.[3],asignificantamountofresearchhasbeendonetoaddressthenumerous
challenges associated with implementing an FL framework. This list of challenges includes, but is not limited to,
efficiencyofcommunications[4,5,6],deviceheterogeneity[7,8,9],statisticalheterogeneity[10,11,12,13],and
privacypreservation/security[14,15,16,17]. Often,whenaddressingtheaforementionedproblemsintheFLliterature,
adeterministicmodelarchitectureisassumed[3,7,11]. Whiledeterministicdeeplearningmodelsarecapableof
achievinghighaccuracy,theyareoftenuncalibrated[18](i.e.,model-predictedprobabilitiesforeachclassdonotmatch
theempiricalfrequencyforthatclass)anddonotprovideaccesstoepistemic(model)uncertaintyinprediction. The
inabilitytoaccessepistemicuncertaintyisproblematicinmanyremotesensingandothersafety-criticalapplications,
whereitisimportantthattheunderlyingmodeliscapableofcommunicatingameasureofepistemicuncertaintyin
predictionandthattheuncertaintybecalibrated.
Althoughthestatistics,meteorological,andmulti-sensorfusionliteraturearerichwithprobabilisticpoolingorfusion
approaches[19,20,21], theredoesnotexistadetailedstudyoftheseprobabilisticpooling/fusionstrategiesinthe
FLsetting. Recognizingthattherearenumerouswaysofaggregating, orfusing, probabilitydistributionsandthat
thereisnoagreedupontechnique,Kolianderetal.[22]provideacomprehensivereviewoffusiontechniquesandthe
motivationforutilizingvariousfusiontechniquesandclient/siteweightingschemes. Utilizingseveralofthestrategies
from [22] and additional strategies from [3] and [23], we analyze the effect of fusion techniques in the Bayesian
federatedlearning(BFL)setting,withafocusonthequalityofuncertainty. Toalignwiththenomenclaturecommonin
FLliteraturethroughoutthismanuscript,weusetheterm“aggregate"inplaceof“fuse”or“pool.”
1.2 Contributions
Inthispaper,wemakethefollowingcontributions:
1. Were-framestatisticalaggregationstrategiesinthecontextofFL,specificallyforBayesiandeeplearning
(BDL).
2. We evaluate six aggregation strategies for BDL models in the FL setting on independent and identically
distributed(IID)andnon-IIDpartitionsofapopularcomputervisiondatasetcommonlyusedtobenchmark
performanceinmachinelearning(ML)andFLapplications. Weshowthataggregationstrategyisacrucial
hyperparameterinthedesignofaBFLalgorithm.
3. Weevaluatethreeclientweightingstrategiesinconjunctionwitheachofthesixaggregationstrategiesunder
evaluation.
4. WeexamineapopularlightweightBayesianapproximation,MonteCarlo(MC)dropout,intheFLsettingand
compareitsperformancetomorecomplexvariationalinference(VI)models.
5. Weevaluatenotonlythepredictionaccuracy,butalsothecalibrationanduncertainty(totalanddecomposed)
ofbothmean-fieldGaussianVIandMCdropoutVImodelsusedintheFLsetting.
6. WeshareourFlowerFederatedLearningFramework[24]implementationtofacilitatefurtherexperimentation
withaggregationmethodsandclientweightingtechniquesonadditionaldatasets.1
2 BackgroundandRelatedWork
2.1 FederatedLearning
In FL, client models train, or update, an instance of a global model using locally captured data and periodically
send updated model parameters to a central server for aggregation [3]. Often, this technique is utilized to take
advantage of numerous local datasets while maintaining privacy. Additionally, in remote sensing platforms and
1https://github.com/meekus-fischer/BayesianFederatedLearning
2FederatedBayesianDeepLearning APREPRINT
other edge devices, FL significantly reduces the communication costs associated with training on these individual
datasets. Weusethefollowingnotationthroughoutthismanuscript: k ∈{1,...,K}representstheindividualclients,
Dk = {(x ,y ),...,(x ,y )} represents the local dataset of client k with |Dk| local training examples, D
1 1 |Dk| |Dk|
comprisestheentiretrainingdatasetsplitamongstK clients,θk isthesetofparametersforclientkandFLroundr,
r
θg isthesetofparametersfortheglobalmodelatroundr,ω istheaggregationweightforclientk,Bisthelocal
r k
minibatchsize,Eisthenumberoflocalepochs,andηisthelearningrate. Ingeneral,wecandescribethefederated
optimizationproblemofK clientswiththefollowing:
K
(cid:88)
min f(θg), where f(θg)= ω f (θg). (1)
k k
θ∈Rd
k=1
IntheML/FLcontext,f (θ)oftencorrespondstoL (Dk,θ),thelocallossofclientkonDk withmodelparametersθ.
k k
Weplacethefollowingconstraintonclientaggregationweights:
(cid:80)K
ω =1. Inpractice,thisoptimizationisdone,
k=1 k
asdescribedinAlg.1,overmultipleoptimization/communicationrounds. First,theserverinitializestheglobalmodel
(ordistributesapre-trainedbaselinemodel)anddistributesthemodelparameterstoeachoftheclients. Duringeach
optimizationroundr,clientstraintheglobalmodel,usingavariantofStochasticGradientDescent(SGD),forEepochs
beforereturningtheclientparameterstotheserver. Theserverthenusesanaggregationfunction(e.g.,FedAvg[3])to
combinethemodelweightsandbiasesofeachclientintoanewglobalmodel,anddistributesthenewglobalmodel
parameterstoeachoftheclients. ThisprocessrepeatsforRcommunicationrounds,oruntilconvergence.
Algorithm1:FederatedLearning.
ServerExecutes:
initializeθg
0
foreachroundr=0,1,...,R-1do
foreachclientk ∈{1,...,K}inparalleldo
θk ←ClientUpdate(k,θg)
r+1 r
ω =CalculateClientWeights()... [Computew usingEq.(18),(19),(20),or(21)]
k
θg ←AggregateClients({θ1 ,...,θK },ω)... [Eq. (10),(11),(12),(15),(16),or(17)]
r+1 r+1 r+1
ClientUpdate(k,θg): //Runonclientk
MB ←(splitDk intominibatchesofsizeB)
θk ←θg
foreachlocalepochifrom1toEdo
forminibatchb∈MBdo
θk ←θk−η∇ℓ(θk;b)
returnθk totheserver
2.2 BayesianDeepLearning
Toinstillsufficientconfidenceintheperformance, orcapability, ofMLmodelsfordeploymentonremotesensing
platforms, or safety-critical applications, and to ensure the models are able to adapt to dynamic environments, it
iscriticalthatthemodelsarecapableofcommunicatingameasureofepistemicuncertaintyinprediction[25,26].
BDLmodelsapplyBayesianmethodsinordertoprovideaccesstotheuncertaintymeasure(epistemicuncertainty),
whichdeterministicMLmodelsareincapableofproviding. Insteadofutilizingpointestimates(deterministicML),
BDL learns a probability distribution over model parameters [27]. BDL has its roots in Bayesian statistics, where
inferenceaboutmodelparameters,θ,givendata,D,involvesthecalculationoftheposteriorp(θ|D). Placingaprior
p(θ)onmodelparameters(e.g.,theweightsandbiasesofaBDLarchitecture)enablesthecalculationoftheposterior
distributionofmodelweightsandbiasesutilizingBayes’rule:
p(D|θ)p(θ)
p(θ|D)= . (2)
p(D)
Ultimately,predictionamountstocalculating
3FederatedBayesianDeepLearning APREPRINT
(cid:90)
p(y∗|x∗,D)= p(y∗|x∗,θ)p(θ|D)dθ, (3)
Θ
wherex∗istheinputfeaturevector,y∗isacorrespondingprediction,Θrepresentstheparameterspaceofthemodel,
andp(y∗|x∗,D)istheprobabilityofthatpredictiongivenatrainedmodel. Duetothefactthatp(D)inEq.(2)isnot
directlyaccessible,itmustbecalculatedusingknownquantities.
(cid:90)
p(D)= p(D,θ)dθ. (4)
Θ
High-dimensionalintegrals,suchastheoneinEq.(4),oftenhavenoclosedformandarecomputationallyintractable[28].
Inpractice,approximateinferenceisused. Therearemanymethodsforapproximateinference;however,twoofthe
mostcommonapproachesareMarkovChainMonteCarlo(MCMC)samplingandVI[29]. AlthoughMCMCisoften
describedasthe“goldstandard”forapproximateinference,VIiscommonlyfavoredinBDL,duetotheincreasedspeed
andtheabilitytoscalewithlargedataandlargemodels[30]. ThereareanumberofapproachestoimplementingVI;
twoofthemostcommonofimplementations—Flipout[31]andLocalReparameterizationTrick[32]—useGaussian
distributionsandeffectivelydoublethenumberofmodelparameters. Anothercommonapproach,MCdropout,was
showntobeaneffectiveBayesianapproximationthatdoesnotdoublethenumberofmodelparameters[33]. Inmany
situations,eachofthesemethodshasbeenempiricallyshowntoleadtousefulapproximationofp(θ|D),providing
accesstoimproveduncertaintyestimationwhencomparedtotheuncertaintyprovidedbydeterministicmodels. Inthis
work,weutilizeFlipoutVImodelsandMCdropoutmodelsasourBDLmodels.
The essence of VI is that optimization is used to approximate the true posterior p(θ|D) by identifying the closest
distributionq (θ),parameterizedbyϕ,totheposterioramongafamilyofpre-determined(variational)distributions
ϕ
(commonlyaGaussian). Often,the“closeness”isdeterminedusingKullback-Leibler(KL)divergence,acommon
information-theoreticmeasureofsimilaritybetweentwodistributions.
(cid:90) q (θ)
KL[q (θ)||p(θ|D)]= q (θ)log ϕ dθ. (5)
ϕ ϕ p(θ|D)
Θ
TheoptimizationobjectiveforVIthenbecomes
L =KL[q (θ)||p(θ)]−E [logp(D|θ)], (6)
q ϕ q
whereE representstheexpectedvalueundertheprobabilitydistributionq (θ). Inthisform,alsoknownasthenegative
q ϕ
EvidenceLowerBound(ELBO),itbecomesclearthattheoptimizationobjectiveisthesumofadata-dependentportion
(likelihoodcost),andapriordependentportion(complexitycost)[34].
ThequalityoftheapproximationinVIishighlydependentonthechoiceofthevariationaldistributionfamily. As
mentionedinthepreviousparagraph,weconsidertwodistinctapproaches,amean-fieldGaussiandistributionwith
aFlipoutMCestimatorofKL-divergence[31]andMCdropout,whichusesaBernoullidistributionoverthemodel
weightsandbiases[33]. Inthefirst, theuseofGaussiandistributions, parameterizedbythemeanandvarianceof
the distribution, doubles the number of parameters in the model architecture, when compared to its deterministic
counterpart. TheuseoftheGaussiandistributionresultsinamorechallengingoptimizationproblemrelativetoMC
dropout. IntheMCdropoutapproach,thereisnoadditionalincreaseinthenumberofmodelparameters,andminimal
changesarerequiredtothemodelarchitecture[35,25,33]. Itisthesesimplificationsthatmotivateouranalysisofthe
MCdropoutmodelintheFLframeworkasalightweightBayesianapproximation.
2.3 UncertaintyQuantificationandDecomposition
InBDLmodelsusedforclassification,predictiveprobabilityp(y =c|x)isapproximatedbyusingMCintegration
withM samples[36]. Themeanprobabilityperclassp¯ iscalculatedusingthepredictionprobabilities,pˆ ,where
c cm
pˆ =p(y =c|x,θm)andθmissampledfromanapproximationofp(θ|D).
cm
M
1 (cid:88)
p¯ = pˆ . (7)
c M cm
m=1
4FederatedBayesianDeepLearning APREPRINT
Thepredictedclassforeachsampleischosenbyselectingtheclassthatyieldsthehighestmeanprobability. Inaddition
toapredictedclass,theM MCsamplesallowforthecalculationofpredictiveentropyandvariance. Predictiveentropy
hasseveralinterpretations;however,ininformationtheory,entropyisinterpretedastheamountofinformationcontained
inapredictivedistribution[28]. Normalizedpredictiveentropy(H˜),forthemulti-classclassificationproblem,isgiven
by
H˜ (y |x)=−(cid:88) p(y =c|x)logp(y =c|x) , (8)
p logC
c∈C
whereC representsallpossibleclasses[37]. Althoughentropyiscommonlyusedasameasureofaleatoricuncertainty
indeterministicandBayesiandeeplearning,Depewegetal.[38]interpretentropyasameasureofpredictiveuncertainty,
whichcouldbefurtherbrokendownintoitsaleatoricandepistemicuncertaintycomponents. Aleatoricuncertaintyis
knownasdatauncertaintyandcannotbereducedwithanincreaseintrainingdata. Epistemicuncertaintyisknown
asmodeluncertaintyandcanbereducedbyincreasingtheamountoftrainingdata[28]. Epistemicuncertaintyisnot
accessibleusingdeterministicmodels.
ForBDLmodels,varianceprovidesanothermeasureoftotaluncertainty,whichcanbebrokendownintoepistemicand
aleatoricuncertainty. Kendalletal.[26]andKwonetal.[39]separatelyproposemethodsforestimatingaleatoricand
epistemicuncertaintywithKwonetal. modifyingtheapproachin[26]togivethefollowingestimator:
M M
1 (cid:88) 1 (cid:88)
diag(pˆ )−pˆ⊗2+ (pˆ −p¯ )⊗2, (9)
M m m M m c
m=1 m=1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
aleatoric epistemic
whereM isthenumberofMCsamples,pˆ isac-dimensionalvectorcontainingthepredictiveprobabilitiesofeach
m
class(pˆ ),diag(pˆ )isadiagonalmatrix,pˆ⊗2 =pˆ pˆT,and(pˆ −p )⊗2 =(pˆ −p )(pˆ −p )T.
cm m m m m m c m c m c
2.4 FederatedBayesianLearning
Inscenariosinvolvingbigdatawithmanydistributedremotesensingplatforms,theneedtoadapttodynamicenvi-
ronments,andtheneedtobenefitfromtheabilitytocommunicateameasureofuncertainty,theapplicationofBDL
toFLisanaturalone. SeveralworkshaveappliedBayesiantechniquestotheFLproblem. In[40],theauthorsapply
theLaplaceapproximationatboththeclientandservertoreduceaggregationerrorsandregularize,orguide,local
modeltraining. Notably,inthiswork,theauthorschoosetoaggregateclientmodelsusingamixtureofGaussians.
FedBE[41]constructsaglobalmodelbyfittingadistribution(GaussianorDirichlet)totheclientmodelsandsampling
from this distribution to arrive at a higher-quality global model. Similarly, FedAG [42] applies uncertainty in the
aggregationstepbyusingtheclientparameterstofitaGaussiandistributionattheserver. In[43],theauthorspresenta
BFLframeworkwhereeachclientperformsapproximateBayesianinference,usingMCMCsampling,anddistillsthe
clients’posteriordistributionintoasingledeepneuralnetworkviaknowledgedistillationtechniquesforaggregationat
theserver. pFedBayes[12]isapersonalizedFLmodelthatusesVItolearnapersonalizedlocalmodelateachclient
whilelearningasharedglobalmodel.
WiththeexceptionofpFedBayes[12],noneoftheseworksemployVI. WhilepFedBayes[12]utilizesVI,theglobal
modelusesasimpleaveragingmethodforclientparameteraggregation,andnoadditionalmethodsarediscussed,or
analyzed. Additionally,inpFedBayes[12],theauthorsutilizeamodelwithasinglevariationallayer(i.e.,withthe
exceptionoftheoutputlayer,alllayersaredeterministic). Thisworkisthefirsttime,toourknowledge,thatanyonehas
utilizedafullyvariationalmodel(i.e.,allmodellayersarevariational)toanalyzetheeffectsofthechoiceofaggregation
functionandclientweightingschemeonBDLmodelsinFL.
TheuseofBDLinFLintroducesseveraluniqueproblems. First,themodelweightsandbiasesinaVImodelareno
longerapointestimate. Eachweightandbiasisdefinedbytheparametersofadistribution. InthecaseofaGaussian,
thisisthemeanandvarianceofthedistribution.Inthefollowingsub-sections,wepresentmultipleaggregationstrategies
forunivariateGaussiandistributionsandtheirunderlyingtheory. Next,wediscusstheselectionofclientweightsinthe
aggregationprocess. Often,thesizeofthelocaltrainingdatasetisutilizedtoweighteachclient. However,thisisnot
theonlymethod,andwepresentseveralotherweightingschemesforanalysis. Finally,inmean-fieldGaussianVIwe
oftenselectpriorswithafixedmeanofzeroandafixedvariance,p(θ)=N(0,σ2 I),fortheregularizationtermin
prior
5FederatedBayesianDeepLearning APREPRINT
theoptimizationproblem. However,inthiswork,weposethequestionofwhetherornottoupdatetheprioraftereach
roundofoptimization. Weanalyzetheeffectofupdatingtheprioreachroundvs. maintainingafixedpriorthroughout
thetrainingprocess.
2.5 AggregationStrategies
Althoughthereareasignificantnumberprobabilisticaggregationapproachesthathavebeenpresentedintheliter-
ature [19, 20, 21], we focus our study on six select strategies from [3, 21, 22, 44, 45] due to their suitability for
implementation in the FL construct. In the following sub-sections, we discuss each of these approaches using the
univariate Gaussian distribution for each parameter (θ ), parameterized by its mean (µ ) and variance (σ2), as the
i i i
modeldistribution. WeuseunivariateGaussiansbecauseofouruseofmean-fieldGaussianVI,whereweassumeeach
parameterisindependent. ThesixapproachesareNaiveWeightedAveraging(NWA)[3],WeightedSumofNormal
Distributions(WS),LinearPooling(LP)[22],Conflation/WeightedConflation(WC)[21,44],andDistributedWeight
Consolidation(DWC)[23]. Weusethefollowingnotationinourdiscussion: K isthesetofclientmodels,q isthe
k
distributionforclientk,q istheglobal(server)distribution,andω
istheweightofclientkwith(cid:80)K
ω =1.
g k k=1 k
2.5.1 NaiveWeightedAveraging
ThisaggregationmethodissimilartotheFedAvgalgorithm[3]andissimplestoftheaggregationtechniques. Inthe
casewhereω = |Dk|,NWAisequivalenttoFedAvg. Althoughthismethodwasshowntobeeffectiveforaggregating
k |D|
deterministicmodelweightsandbiasesin[3],independentlyaggregatingthemeanandvarianceparametersinthis
mannerignoresthestatisticalpropertiesoftheGaussianDistribution. Thismethodisfamiliartothestatisticalliterature,
however, and is described as Centered Linear Pool (CLP) in [46], and used extensively in [46, 47, 48]. Clements
defendstheuseofthisvariancecalculationin[47]notingthatthevariancecalculatedusingLPisofteninflatedbythe
“disagreement”term(describedinSectionII.G.3),andtheNWAmethodisequaltotheexpectedvarianceofarandomly
selectedclient.
K K
(cid:88) (cid:88)
µ = ω µ , σ2 = ω σ2 . (10)
qg k qk qg k qk
k=1 k=1
Ultimately,thismethodinvolvestakingtheweightedaverageofeachoftheclients’individualmodelparametersto
formtheglobalmodelwithoutregardforwhateachoftheparametersrepresents.
2.5.2 WeightedSumofNormalDistributions
IfthemeanandvarianceofeachmodelparameterareconsideredaspartofaunivariateGaussiandistribution,instead
ofbeingconsideredindividuallyasinNWA,itispossibletotaketheweightedaverageofeachoftheclientGaussian
distributions. Thisstrategyassumestheweightsofeachclientaremutuallyindependent.
K K
(cid:88) (cid:88)
µ = ω µ , σ2 = ω2σ2 . (11)
qg k qk qg k qk
k=1 k=1
TheresultantGaussiandistributioninWShasthesamemeanasinNWA,butthevarianceparameterdiffers. Because
the ω parameter falls in the range of [0,1], and we square each client’s weight parameter ω in WS, the variance
k
parameterinWSwillalwaysbelessthanorequaltothevarianceparameterinNWA.
2.5.3 LinearPooling
TheLPtechniqueisstudiedextensivelyintheforecastingliterature[49,46,48,50,51,52]andisconnectedtomodel
averagingandmultiplemodeladaptiveestimation(MMAE)[53],asdescribedbyKolianderetal. in[22]. Toderivethe
LPoperatorforunivariateGaussianrandomvariables,wedefineeachclientdistributionasq (θ) = N(θ;µ ,σ )
k qk qk
where µ = E [θ] and σ2 = E [θ−µ ]2. LP is then defined as the linear combination of each of the client
qk qk qk qk qk
distributions:
k
(cid:88)
q (θ)= ω N(θ;µ ,σ ). (12)
g k qk qk
k=1
6FederatedBayesianDeepLearning APREPRINT
Theglobalmeanisthendefinedbyµ =E [θ],whichisjusttheweightedaverageoftheclientmeans(µ ):
qg qg qk
K
(cid:88)
µ = ω µ . (13)
qg k qk
k=1
Theglobalvariancecansimilarlybedefinedasσ2 =E [θ−µ ]2,whichisbrokendownbyLahirietal.[54]into
qg qg qg
twocomponents. Thefirstcomponentistheweightedaveragevarianceofeachclientσ2 . Thesecondcomponentisthe
qk
“disagreement”componentoftheglobalvarianceandcapturesthediscrepancybetweenclients.
K K
(cid:88) (cid:88)
σ2 = ω σ2 + ω (µ −µ )2
qg k qk k qk qg
k=1 k=1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(14)
avgclientvar disagreementterm
K
(cid:88)
= ω (σ2+(µ −µ )2).
k k k qg
k=1
In[46],theauthorsshowthatLPimposesanupwardbiasontheglobalvarianceresultinginunder-confidentpredictions.
WebrieflymentionedoneofthewaysinwhichresearchershavedealtwiththisupwardbiasintheNWAsubsection.
CLP,whichisequivalenttoNWA,isavariantofLPwhichignoresthedisagreementtermintheLPvariancecalculation
andreducesthisupwardbias.
2.5.4 ConflationandWeightedConflation
TheConflationandWCmethods[21,44]arethenormalizedproductofclientdistributionsandarecloselyrelatedto
Log-LinearPooling(LLP)[22]. LLPisaweightedgeometricaverageofclientdistributionsandissonamedbecauseit
isalinearfunctionofclientdistributionsinthelog-domain[22]. WhencombiningGaussiandistributions,LLPdiffers
fromWConlyinthenumeratoroftheglobalvarianceterm,withLLPreplacingω withavalueof1. Asshown
max
in[21,44],Conflation/WChasseveraldesirableproperties. Thesepropertiesinclude:
• Conflation/WCiscommutative,associative,anditerative.
• TheresultingdistributionoftheConflation/WCofGaussiandistributionsisaGaussian.
• TheresultoftheConflation/WCofGaussiandistributionsmatchestheresultoftheweighted-least-squares
method.
• Conflation/WCminimizesthelossofShannoninformationasaresultoftheconsolidationofmultipleGaussian
distributionsintoasingleGaussiandistribution.
• Conflation/WCisthebestlinearunbiasedestimate.
• Conflation/WCyieldsamaximumlikelihoodestimator.
WeprovidetheformulasforbothConflation,Eq.(15),andWC,Eq.(16),below.
(cid:80)K µqk
k=1 σ2 1
µ = qk , σ2 = . (15)
qg (cid:80)K 1 qg (cid:80)K 1
k=1 σ2 k=1 σ2
qk qk
Readers familiar with the Inverse Variance Weighting (IV) technique [45] may notice that the Conflation formula,
Eq.(15),isidenticaltotheformulaforIV. IVisawell-knownmethodforcombiningrandomvariablesinsuchaway
astominimizethevarianceoftheresultingdistribution.
(cid:80)K ωkµqk
µ = k=1 σ q2 k , σ2 = ω max . (16)
qg (cid:80)K ωk qg (cid:80)K ωk
k=1 σ2 k=1 σ2
qk qk
7FederatedBayesianDeepLearning APREPRINT
Notably,WCproducesaGaussiandistributionwithameanvaluewhichisproportionaltotheclientweights,inversely
proportionaltoclientvariances,andhasavariancewhichisnevergreaterthanthevarianceoftheclientwiththegreatest
weight.
2.5.5 DistributedWeightConsolidation
DWCwasintroducedbyMcClureetal.[23]asacontinuallearningtechniquetocombineorconsolidatethemodel
weightsandbiasesofmultipleBayesianneuralnetworks(BNNs)trainedonindependentdatasets. Thismethodbuilds
ontheconceptofVariationalContinualLearning[55]andBayesianIncrementalLearning[56]. However,bothofthese
methodsrequirethattheunderlyingmodelsbetrainedsequentially. InDWC,multipledisparatemodels(clients)canbe
trainedindependently,andtheirweightsandbiasescanbeconsolidatedintoasinglenetwork(globalmodel),similarto
theFLsetting. DWCisrelatedtotheSupra-Bayesianframeworkdescribedin[22],whichinvolvestheselectionof
apriordistribution,p(θ),andtheupdateofthepriorusingaBayesianupdaterule. InDWC,weareusingtheglobal
model,q (θ),astheprior,p(θ),andapplyingthesameBayesianupdaterule. InEq.(17),weprovidetheformulasfor
◦
theglobalmeanandvariance,thederivationofwhichcanbefoundin[23].
(cid:80)K µqk −(cid:80)K−1 µq◦
k=1 σ2 k=1 σ2 1
µ = qk q◦ , σ2 = . (17)
qg (cid:80)K 1 −(cid:80)K−1 1 qg (cid:80)K 1 −(cid:80)K−1 1
k=1 σ2 k=1 σ2 k=1 σ2 k=1 σ2
qk q◦ qk q◦
whereµ andσ2 correspondtotheglobalmeanandvariancefromthepreviousround,respectively. Itshouldbe
q◦ q◦
notedthatDWCwasdesignedtostartwithabasemodeltrainedonsomeinitialdataset,andnotarandominitialization.
Additionally,intheDWCsetting,each“client”trainsasynchronouslyontheirlocaldatasetbeforeaggregatingclient
parameters. ThisisthefirsttimethatthismethodhasbeenappliedtoandanalyzedintheBFLsetting.
2.6 DeterminingWeightParameters
In the seminal work on FL, McMahan et al. [3] weighted client updates based on the size of each client’s local
datasetrelativetothedatasetsofallotherclients. AlthoughthismethodiscommoninFL,therehavebeenseveral
works[57,22]whichexplorevarioustechniquesforweightingclientstoachievevaryingobjectives(robustnessagainst
outliers,reducingcommunications,trainingefficiency,etc.). Wetreattheclientweightingschemeasahyperparameter
andanalyzetheresults(withafocusonuncertainty)ofusingfourdifferenttechniquesforselectingclientweights.
Notably,theimplementationofseveralofthesemethodsrequirethattheunderlyingmodelsbeBayesian. Assuch,we
onlyapplyeachweightingtechniquetomodelsforwhichitisapplicable.
2.6.1 EqualWeight
Thefirst,andsimplest,methodistogiveequalweighttoeachclientintheupdateprocessusingEq.(18). Inadditionto
itssimplicity,itdoesnotrequireanyaprioriknowledgeoftheclientdatasets. Asaresult,itiscompletelyindependent
oftheamountoftrainingdata,orthequalityoftrainingdata,ateachclientsite,andisnotresistanttooutliersorextreme
updates. Thismethodisapplicabletobothdeterministicandprobabilisticmodels.
1
ω = . (18)
k K
2.6.2 LocalTrainDatasetSize
Thismethodwasintroducedin[3],andiswidelyusedintheFLliterature. Inordertoapplythisweightingscheme,the
servereitherneedstohaveaprioriknowledgeofthesizeoftheclientdatasets,ortheclientneedstocommunicatethe
sizeoftheirtrainingdatasetwiththemodelupdate. Whenthedataisdistributedevenlyamongstclients,thismethod,
Eq.(19),isequivalenttoEqualWeight. Thismethodisapplicabletobothdeterministicandprobabilisticmodels. Since
eachofourdatasetpartitionsresultsinclientshavinganequalamountofdata, thismethodisequivalenttoEqual
Weight.
|D |
ω = k . (19)
k |D|
8FederatedBayesianDeepLearning APREPRINT
2.6.3 MaximumDiscrepancyWeighting
Kolianderetal. describedmaximumdiscrepancyweightingin[22]. Thistechniqueinvolvestreatingtheclientweights
asameasureofdistance. InEq.(20),weuseKullbackLeiblerDivergence. However,othermeasuresofdistanceor
divergencecouldbeused. Bycomputingclientweightsinthismanner,theserverplaceshigherimportanceonmodel
weightsandbiasesthatarenotextreme(relativetotheotherclients). Thegammavalue(γ )andomegavalue(ω )in
k k
Eq.(20)aretheun-normalizedandnormalizedweightsofeachclient,respectively. Thismethodisonlyapplicableto
probabilisticmodels. However,asimilartechniquecouldbeusedindeterministicmodelsusingtheL2norm,oranother
measureofdistance. Weonlyapplythistechniquetotheprobabilistic(VI)models.
1 γ
γ = max , ω = k . (20)
k j∈{1,...,K}KL[q k ||q j] k (cid:80)K j=1γ j
2.6.4 DistancetoaFixedPoint
Thismethodissimilartomaximumdiscrepancyweightinginthatitalsotreatsclientweightsasameasureofdistance.
Insteadofcalculatingthedivergencesbetweenthedistributionsofthemodelweightsandbiasesforindividualclients,
weusethedivergencebetweenthedistributionsofthemodelweightsandbiasesforindividualclientsandtheglobal
modelfromthepreviousround. Ineffect,thisplacesagreaterimportanceonclientsthatdonotdivergesignificantly
fromthecurrentglobalmodel. Similartomaximumdiscrepancyweighting,thegammavalue(γ )andomegavalue
k
(ω )inEq.(21)aretheun-normalizedandnormalizedweightsofeachclient,respectively. Again,thismethodisonly
k
applicabletoprobabilisticmodels;however,asimilartechniquecouldbeusedindeterministicmodelsusingtheL2
norm,oranothermeasureofdistance. Weonlyapplythistechniquetotheprobabilistic(VI)models.
1 γ
γ = , ω = k . (21)
k KL[q g ||q k] k (cid:80)K j=1γ j
3 Experiments
3.1 Datasets
WeutilizetheCIFAR-10[58]imageclassificationdatasettobenchmarkourmodelsandmodelparameteraggregation
rules. TheCIFAR-10datasetconsistsof50,000trainingimagesand10,000testimagesofsize32x32x3pixels,which
belongtooneof10classes. Similarto[3,10,59],weadoptbothanIIDandnon-IIDpartitioningstrategy. Inboth
strategies,wepartitionthetrainingdatasetamongst10clients. FortheIIDstrategy,weassigneachclientauniform
distributionoverthe10classes. Forthenon-IIDstrategy,wefollowthestrategyintroducedbyLietal. in[59]and
adopt both a quantity-based label imbalance and a distribution-based label imbalance. In the quantity-based label
imbalancescenario,wefirstsortthedatabyclassanddividethedatainto20partitionsofsize2,500,andrandomly
assigneachclienttwopartitionsfromdifferentclasses(i.e.,eachclienttrainingdatasetcontainsexamplesfromtwo
classeswith2,500examplesofeachclass). Inthedistribution-basedlabelimbalancescenario,eachclientisallocateda
proportionofthesamplesofeachlabelaccordingtotheDirichletdistribution,whichisparameterizedbyα[60]. Inour
experiment,weuseαparametersof0.5and5.0tosimulatedifferentlevelsofclassimbalanceacrossclienttraining
datasets.
3.2 Architecture
We utilize the Flower Federated Learning Framework [24] to implement the FL setup. In order to conduct a fair
comparisonofperformanceacrossmodelconfigurations,weutilizetheResNet-20[61]architectureinadeterministic,
MC dropout [33], and Flipout [31] (VI) configuration, as shown in Fig. 1. Notably, when trained on acentralized
training dataset, all variants of the ResNet-20 model used in this paper achieved comparable performance to the
benchmarkperformancereportedbyHeetal.[61]ontheCIFAR-10dataset,seeTable1. Themodelswerecodedusing
Tensorflowv2.9andTensorflowProbabilityv0.16[62]andallexperimentswereperformedonNVIDIARTX8000
graphicsprocessingunits.
9FederatedBayesianDeepLearning APREPRINT
Figure1: ResNetModelBlockStructure. (a)depictsthestructureofaResNetblockinthedeterministicconfiguration.
(b)depictsthestructureofthesameResNetblockintheMCdropoutconfigurationwiththeadditionofadropoutlayer
aftereachconvolutionalandlinearlayer. Thesedropoutlayersareenabledduringtheinferencephase. (c)depictsthe
ResNetblockintheFlipoutconfiguration. EachconvolutionalandlinearlayerisreplacedbytheTensorflowProbability
implementationofthecorrespondingFlipoutLayer. Changesfromthedeterministicconfigurationarehighlightedin
orange.
Table1: ResNet-20CentralizedTrainingResults
Model Accuracy
Deterministic 90.14
MCDropout 90.91
Flipout 90.42
3.3 GeneralExperimentSetupandEvaluationMetrics
Forallexperiments,weutilizeK =10clients,B =32localminibatchsize,andη =.001initiallocallearningrate
withanexponentialschedulethatreducesthelearningratebyafactorof.04everyroundafterasilentperiodof50
aggregationrounds. Additionally,weuseadropoutrateof0.2forMCdropoutmodelsandourFlipoutmodelsuse
p(θ)=N(0,100I).
Wepresenttheresultsofeachexperimentusingaccuracyandnegativeloglikelihood(NLL). NLLisequivalenttothe
KLDivergencebetweenamodel’spredicteddistributionandaone-hotencodedtruedistribution[28],withalower
NLLcorrespondingtoabetterrepresentation. Intermsofcalibration,Filosetal.[36]demonstratedthatifamodel’s
performanceincreasesasthenumberofdiscardedhigh-uncertaintypredictionsincreases,themodeliswell-calibrated.
As a result, we utilize accuracy vs. data retained curves to assess the calibration of models based on normalized
predictiveentropy,aleatoricuncertainty,andepistemicuncertainty.
3.4 EvaluationofAggregationMethods-1LocalEpoch
Inthisexperiment,weevaluateeachoftheproposedaggregationstrategieswithE =1localepochs. Eachsimulation
isrunthreetimesfor400rounds,andtheresults,showninTable2,areaveragedacrossexperiments.
IntermsofaccuracyandNLL,noaggregationstrategyoutperformsotheraggregationstrategiesonalldatadistributions.
Notably, NWA and LP do not perform as well as WS, WC, and conflation, which all perform similarly to the
deterministicmodelbaseline(NWA). LPperformsespeciallypoorlyonalldatadistributions.
UncertaintycalibrationplotsaredepictedinFig.2. Whenlookingatthebulkuncertaintymetric(normalizedentropy),
intheIIDandnon-IIDDirichlet(0.5and5.0)cases,alloftheglobalmodelsdisplayacalibrateduncertainty. Even
thoughtheglobalmodelsarecalibrated,themodelstrainedusingWS,WC,andconflationappeartobebettercalibrated
thanthemodelstrainedusingLPandNWA(i.e.,testaccuracyincreasesmorerapidlyasthemostuncertainsamplesare
discardedfromthetestdata). Bybreakingdownthebulkuncertaintyintoitsepistemicandaleatoriccomponents,the
10FederatedBayesianDeepLearning APREPRINT
performancedifferenceisamplified. Specifically,whenfilteringbasedonepistemicuncertainty,modelstrainedusing
WS,WC,andconflationperformmuchbetterthanthosetrainedusingLPandNWA. Inthenon-IID2-Classcase,the
relationshipsbetweenaggregationstrategiesissimilar. However,notalltheglobalmodelshaveacalibratedepistemic
uncertaintycomponent.
InFig. 3,weplotlearningcurvecomparisons(testsetaccuracyvsfederationround)foreachofthedatadistributions.
Again,modelstrainedusingWS,WC,andconflationexhibitsimilarbehavior. Themodelstrainedusingeachofthese
aggregationmethodsconvergemuchfasterthantheLPandNWAstrategies.
Table2: SimulationResults-SiteEpochs(E =1)
IID Non-IID2-Class Non-IIDDir(α=0.5) Non-IIDDir(α=5.0)
Model Agg.Fn. ClientWeighting Accuracy NLL Accuracy NLL Accuracy NLL Accuracy NLL
Deterministic NWA TrainSize 87.66±0.001 0.370±0.005 51.45±0.020 1.55±0.040 83.45±0.003 0.485±0.008 85.78±0.003 0.435±0.001
MCDropout NWA TrainSize 89.19±0.001 0.330±0.006 47.20±0.020 1.65±0.020 85.52±0.002 0.431±0.004 87.45±0.002 0.373±0.005
TrainSize 81.67±0.002 0.576±0.004 43.04±0.025 1.68±0.006 74.77±0.008 0.721±0.015 79.89±0.002 0.62±0.005
NWA MaxDisc 81.28±0.001 0.581±0.002 47.81±0.024 1.65±0.013 75.45±0.009 0.722±0.005 80.06±0.003 0.608±0.012
Distance 81.76±0.003 0.576±0.007 40.00±0.030 1.80±0.036 75.92±0.011 0.717±0.003 80.04±0.001 0.614±0.002
TrainSize 87.41±0.002 0.388±0.006 53.52±0.056 1.41±0.076 83.74±0.002 0.508±0.014 85.17±0.004 0.465±0.01
WS MaxDisc 87.81±0.004 0.377±0.004 47.72±0.049 1.49±0.048 84.17±0.004 0.487±0.008 84.90±0.002 0.476±0.001
Flipout(VI) Distance 87.55±0.003 0.391±0.004 51.84±0.014 1.47±0.021 83.23±0.003 0.51±0.005 85.07±0.002 0.464±0.005
TrainSize 77.21±0.004 0.683±0.007 35.50±0.048 1.85±0.046 67.67±0.008 0.925±0.02 74.7±0.007 0.744±0.016
LP MaxDisc 77.35±0.004 0.681±0.012 37.86±0.018 1.79±0.014 69.35±0.009 0.895±0.017 76.01±0.011 0.717±0.023
Distance 77.69±0.002 0.674±0.005 32.48±0.064 1.90±0.085 68.47±0.015 0.914±0.034 75.94±0.005 0.721±0.009
TrainSize 87.95±0.001 0.377±0.006 53.00±0.052 1.44±0.096 83.18±0.004 0.510±0.009 85.09±0.003 0.478±0.001
WC MaxDisc 87.81±0.002 0.384±0.004 50.71±0.025 1.49±0.044 83.70±0.002 0.514±0.004 84.86±0.002 0.470±0.005
Distance 87.52±0.002 0.389±0.002 46.41±0.037 1.52±0.037 83.17±0.001 0.514±0.006 85.23±0.002 0.464±0.006
Conflation N/A 87.42±0.001 0.385±0.003 53.09±0.008 1.46±0.027 83.18±0.001 0.502±0.008 84.94±0.005 0.471±0.008
Figure2: UncertaintycalibrationplotsforE = 1. VIaggregationmethodcomparisonplotoftestsetaccuracyvs.
ratioofdataretainedforIIDandnon-IID2-classdatadistributions. Non-IIDDirichletdistributionplotsshowtrends
andrelationshipsthatmirrorIIDdistributionresults. Normalizedentropyandepistemicuncertaintyplotsareshown,
aleatoricuncertaintyplotsshowtrendsandrelationshipsthatmirrornormalizedentropy.
11FederatedBayesianDeepLearning APREPRINT
Figure3: LearningcurveplotsforE =1. Plotoftestsetaccuracyvs. federationroundforVIaggregationmethodsfor
eachdatadistribution.
3.5 EvaluationofAggregationMethods-5LocalEpochs
Next, weincreasetheamountofclientcomputationandevaluateeachoftheproposedaggregationstrategieswith
E =5localepochs. Eachsimulationisrunthreetimesfor200rounds,andtheresults,showninTable3,areaveraged
acrossexperiments.
Theresults,depictedinTable3,showmuchmoreparitybetweenaggregationstrategiesintermsofaccuracyandNLL.
Infact,modelstrainedusingtheNWAstrategyperformaswellas,orbetter,thantheotheraggregationstrategiesacross
theboard. WhencomparedtotheE = 1experimentresults(Table2),modelsemployingWS,WC,andconflation
showminimalimprovementwhenclientcomputationisincreased. Insomecases(WC/conflation-non-IID2-class),the
modelstrainedusingE =5actuallyperformworse. Notably,noneoftheVIaggregationmethodsperformaswellas
thedeterministicbaselineontheIIDornon-IIDDirichletdatadistributions. However,allofthemsignificantlyimprove
onthedeterministicbaselineinthenon-IID2-classcase.
SimilartotheaccuracyandNLLresults,thecalibrationdifferencesacrossaggregationstrategiesaredrasticallyreduced
in the IID and non-IID Dirichlet cases. However, as is the case in the E = 1 experiments, NWA and LP do not
displayacalibratedepistemicuncertaintycomponent. ThelearningcurvecomparisonplotsinFig.5displaythesame
relationshipsastheirE =1counterpartsinFig.3.
3.6 EvaluationofAggregationMethods-DWCandModelPre-training
TheresultsoftheDWCexperimentsarepresentedseparatelyduetosignificantdifferencesinthetrainingsetuprequired
bytheDWCaggregationstrategy. InTable4,wepresentDWCresultswithandwithoutglobalmodelpre-training. For
comparison,weemploythesamepre-trainingstrategyusingtheWSaggregationmethod. EachoftheDWCandmodel
pre-trainingexperimentsisrunthreetimesforasinglefederationround,whereeachclienttrainsfor400localepochs.
Beforedistributingtheglobalmodeltoeachclient,theserverpre-trainstheglobalmodelon10%oftheCIFAR-10
12FederatedBayesianDeepLearning APREPRINT
Table3: SimulationResults-SiteEpochs(E =5)
IID Non-IID2-Class Non-IIDDir(α=0.5) Non-IIDDir(α=5.0)
Model Agg.Fn. ClientWeighting Accuracy NLL Accuracy NLL Accuracy NLL Accuracy NLL
Deterministic NWA TrainSize 90.74±0.003 0.371±0.009 48.50±0.040 1.56±0.060 87.33±0.002 0.456±0.008 89.06±0.002 0.456±0.008
MCDropout NWA TrainSize 91.16±0.002 0.264±0.003 44.90±0.040 1.58±0.030 87.91±0.001 0.357±0.002 89.53±0.002 0.316±0.001
TrainSize 88.76±0.002 0.334±0.005 56.36±0.017 1.55±0.021 85.26±0.001 0.439±0.001 87.46±0.001 0.380±0.004
NWA MaxDisc 88.87±0.001 0.336±0.002 55.91±0.061 1.55±0.083 85.43±0.001 0.435±0.002 87.30±0.003 0.380±0.002
Distance 88.98±.003 0.332±0.004 45.60±0.129 1.59±0.098 85.35±0.003 0.436±0.008 87.38±0.001 0.377±0.001
TrainSize 88.37±0.004 0.446±0.008 56.96±0.004 1.36±0.015 84.53±0.002 0.585±0.004 85.51±0.002 0.545±0.002
WS MaxDisc 88.23±0.005 0.429±0.002 49.84±0.036 1.42±0.012 84.68±0.004 0.587±0.005 84.92±0.009 0.554±0.006
Flipout(VI) Distance 88.34±0.003 0.444±0.003 48.49±0.021 1.42±0.017 84.91±0.004 0.581±0.005 85.75±0.007 0.545±0.014
TrainSize 88.05±0.002 0.358±0.002 55.41±0.023 1.60±0.040 83.59±0.001 0.478±0.006 86.36±0.001 0.408±0.003
LP MaxDisc 88.19±0.001 0.356±0.001 48.87±0.031 1.65±0.041 84.00±0.003 0.472±0.008 86.62±0.002 0.404±0.004
Distance 87.91±0.001 0.363±0.004 41.95±0.050 1.65±0.049 84.03±0.001 0.471±0.004 86.47±0.001 0.408±0.004
TrainSize 88.21±0.002 0.443±0.002 52.23±0.027 1.41±0.040 84.49±0.004 0.583±0.006 86.01±0.006 0.542±0.014
WC MaxDisc 88.34±0.002 0.430±0.007 49.21±0.051 1.49±0.059 83.52±0.002 0.589±0.012 84.47±0.014 0.548±0.012
Distance 88.28±0.005 0.437±0.012 48.25±0.026 1.44±0.043 85.17±0.005 0.574±0.009 85.37±0.007 0.578±0.006
Conflation N/A 88.16±0.008 0.444±0.006 52.47±0.028 1.39±0.031 84.86±0.003 0.586±0.015 85.59±0.006 0.550±0.003
Figure4: UncertaintycalibrationplotsforE = 5. VIaggregationmethodcomparisonplotoftestsetaccuracyvs.
ratioofdataretainedforIIDandnon-IID2-classdatadistributions. Non-IIDDirichletdistributionplotsshowtrends
andrelationshipsthatmirrorIIDdistributionresults. Normalizedentropyandepistemicuncertaintyplotsareshown,
aleatoricuncertaintyplotsshowtrendsandrelationshipsthatmirrornormalizedentropy.
datasetforamaximumof100localepochs. Toavoidoverfittinginourglobalmodelpre-training,weemployanearly
stoppingstrategywhichmonitorsvalidationaccuracywithapatienceof10epochs.
InTable4,thefirstrowholdstheresultsforDWCwithoutpre-trainingtheglobalmodel. Inthiscase,DWCdoesnot
holdupasaviableaggregationmethod. OneofthepotentialexplanationsforthepoorperformanceofDWCinthis
setup,istheuseofarandomlyinitializedmodelastheinitialglobalmodel. Thisisduetofactthattheglobalmodelis
heavilyweightedinDWC. Asaresult,weexperimentedwithpre-trainingtheglobalmodelonasmallsubsetofthe
overalltrainingdataset. Thissetupmorecloselyresemblestheexperimentalsetupin[23]. Additionally,thisisalikely
13FederatedBayesianDeepLearning APREPRINT
Figure5: LearningcurveplotsforE =5. Plotoftestsetaccuracyvs. federationroundforVIaggregationmethodsfor
eachdatadistribution.
scenarioforanetworkofdistributedsensorswhereamodelispre-trainedonacentralizeddatasetanddeployedona
groupofsensorsforcollaborativelearning.
IntermsofaccuracyandNLL,ourpre-trainingsetupdoesnotperformcomparablytotheE =1orE =5experiments
intheIIDandNon-IIDDirichletcases. Ontheotherhand,inthenon-IID2-classcase,themodelsthatwerepre-trained
performexceedinglywell. InadditiontoasignificantimprovementinaccuracyandNLL,theuncertaintycalibration
plotsinFig.6displaywell-calibratedbulk(normalizedentropy)anddecomposed(aleatoricandepistemic)uncertainty
components.
Table4: SimulationResults-DWC
IID Non-IID2-Class Non-IIDDir(α=0.5) Non-IIDDir(α=5.0)
Model Agg.Fn. Pre-train Accuracy NLL Accuracy NLL Accuracy NLL Accuracy NLL
Flipout DWC No 34.95±1.230 1.73±0.031 11.64±1.73 2.69±0.220 17.25±3.14 2.440±0.210 31.83±1.05 1.801±0.029
Flipout DWC Yes 71.42±0.270 0.83±0.007 66.35±1.53 0.97±0.038 68.81±0.42 0.918±0.007 65.87±1.36 0.972±0.026
Flipout WS Yes 72.70±0.008 0.80±0.017 64.63±1.02 1.01±0.051 62.65±0.02 1.061±0.061 68.18±0.02 0.913±0.051
3.7 UpdatingthePriorEveryFederationRound
Inthisexperiment,weassesstheeffectofupdatingtheprioraftereveryfederationround. Eachoftheseexperiments
areruntwiceontheIIDdatapartition,andtheresultsareaveragedacrossexperiments. TheresultsinTable5showa
precipitousdropinaccuracyandNLLwhencomparedtotheresultsinTables2and3,demonstratingthatupdatingthe
prioreveryfederationroundisnotaneffectivestrategy.
14FederatedBayesianDeepLearning APREPRINT
Figure6: Uncertaintycalibrationplotsforglobalmodelpre-trainingexperiments. DWCandWSaggregationmethod
comparisonplotoftestsetaccuracyvs. ratioofdataretainedforIIDandnon-IID2-classdatadistributions. Non-IID
DirichletdistributionplotsshowtrendsandrelationshipsthatmirrorIIDdistributionresults. Normalizedentropyand
epistemicuncertaintyplotsareshown,aleatoricuncertaintyplotsshowtrendsandrelationshipsthatmirrornormalized
entropy.
Table5: SimulationResults-PriorUpdatedEveryFederationRound(E =1)
IID
Model Agg.Fn. ClientWeighting Accuracy NLL
NWA TrainSize 41.84±.59 1.55±.009
WS TrainSize 43.54±.54 1.53±.017
Flipout(VI) LP TrainSize 46.14±.50 1.46±.011
WC TrainSize 44.23±.52 1.51±.002
Conflation N/A 42.62±.58 1.56±.007
3.8 ClientWeightingStrategies
ResultsoftheE =1andE =5experimentswithdifferentclientweightingstrategiesaredepictedinTables2and3.
TheseexperimentswereconductedinconjunctionwiththeE =1andE =5experiments,andutilizedthesamesetup.
Unfortunately,thisexperimentwasinconclusive,andtheresultsdidnotelucidatetheimportanceofthedifferentclient
weightingtechniques.
3.9 MCDropoutasaLightweightAlternativetoMean-fieldGaussianVI
TheMCdropoutexperimentswereconductedinconjunctionwiththeE =1andE =5experimentsandthesetupis
thesame. AccuracyandNLLresultsarepresentedinTables2and3.
15FederatedBayesianDeepLearning APREPRINT
For both E = 1 and E = 5, in terms of accuracy/NLL, the MC dropout models using NWA perform similarly to
the deterministic baseline. In the IID and non-IID Dirichlet cases, the MC dropout models outperform all the VI
aggregationmethods. Ontheotherhand,inthenon-IID2-classcase,theMCdropoutmodeldoesnotperformnearlyas
wellasthetop-performingVIaggregationmethods.
InFig.7,wepresentuncertaintycalibrationcomparisonplotsforE =1. Likethepreviousuncertaintycalibrationplots,
thenon-IIDDirichletplotsdepictthesametrendsandrelationshipsastheIIDplotsandarenotshown. TheE = 5
calibrationplotsalsofollowsimilarrelationshipsandtrendstotheE =1plotsandarenotshown. Inbothcases,the
modelstrainedonIIDandnon-IIDDirichletdatadistributionsappeartobewell-calibrated. Incontrast,inthenon-IID
2-classcase,theMCdropoutmodelsshowpoorcalibrationoftheepistemicuncertainty.
Figures8and9depictthelearningcurvecomparisonsforE =1andE =5. Similartothecalibrationplots,WSis
usedasareferenceforcomparison. ForE =1,theMCdropoutmodelsconvergeatamarginallyslowerrate. Inthe
non-IID2-classcaseforE =5,showninFig.9,theMCdropoutmodelconvergesatasignificantlyslowerratethan
themean-fieldGaussianVImodeltrainedusingWS.
Figure 7: Uncertainty calibration plots for MC dropout experiments (E = 1). MC dropout (NWA) and VI (WS)
aggregationmethodcomparisonplotoftestsetaccuracyvs. ratioofdataretainedforIIDandnon-IID2-classdata
distributions. Non-IIDDirichletdistributionplotsshowtrendsandrelationshipsthatmirrorIIDdistributionresults.
Normalizedentropyandepistemicuncertaintyplotsareshown,aleatoricuncertaintyplotsshowtrendsandrelationships
thatmirrornormalizedentropy.
4 Discussion
Inourevaluationofsixdifferentaggregationmethods,andthreeclientweightingschemes,wedemonstratedthatthe
results vary based on the training data distribution and number of local training epochs per federation round. We
showedthattheselectionoftheaggregationmethodisacriticalhyperparameter,withdownstreameffectsonmodel
performance(accuracy),calibration,andtrainingtime,whichmustbeselectedbasedonthemachinelearningmodel
16FederatedBayesianDeepLearning APREPRINT
Figure8: LearningcurveplotsforMCdropoutexperiments(E =1). Plotoftestsetaccuracyvs. federationroundfor
MCdropout(NWA)andVI(WS)aggregationmethodsforeachdatadistribution.
type,dataset,andotherhyperparameters. Notably,weestablishedthatoftentheseaggregationstrategiescanbeplaced
intotwogroups,witheachgroupexhibitingsimilarperformance(accuracy/NLL),calibration,andconvergencerate.
ThefirstgroupconsistsofWS,WC,andconflation. ThesecondgroupconsistsofNWAandLP. Modelsemploying
theaggregationstrategiesinthefirstgrouptendtoexhibitrelativelyhighaccuracy,lowNLL,andrapidconvergence
withasinglelocalepochoftrainingduringeachfederationround. Thesemodelsarealsobettercalibratedthantheir
counterpartsfromthesecondgroup,whichrequirefivelocalepochsoftrainingperfederationroundtoreachthesame
performancelevel. Theserelationshipsmayfacilitateatargetedhyperparametersearch. Specifically,thesimilarities
amongststrategiesineachgroupmayallowthetestingofasinglestrategyfromeachgrouptonarrowthesearch.
Althoughourexperimentsonclientweightingtechniqueswerenotfruitful, webelievethatthismaybeduetothe
CIFAR-10datasetandthemodelweselected. InFLimplementationswithmorecomplexarchitecturesandcomplex,
real-world,datasets,wheredistributionsarehighlynon-IID,theseweightingtechniquesmayhelptosmoothtraining
andreducetheeffectsofanon-representativeclientoranadversaryattemptingtodisruptthetrainingprocess. Further
experimentationwithlargerandmorecomplexmodelsanddatasetsisnecessarytovalidatethesebeliefs.
TheDWCalgorithmrequiredsomesignificantadjustmentstoourexperimentalsetup;however,itdroveustoexperiment
withpre-training. Inmanyremotesensingtasks,likevisualtargetrecognitionorpassivesonartargetclassification[63],
thissetupislikely. Priortodeploymentonaremotesensingplatform,themodelneedstobetrainedandevaluatedona
representativedatasetuntilitdemonstratesanacceptablelevelofperformance. Therandominitializationisnotrealistic
intheseremotesensingapplications. Oncethemodelisdeployedonagroupofsensors,itcanbefine-tunedusingFL
inasetupthatmirrorsourexperimentalsetup. Inthisapplication,DWCisaviablesolutionanddisplayscomparable
performancetoWS.
ThecostofdeployingVImodelstoremotesensingplatformsandtrainingthosemodels,inmanycases,isprohibitive.
MCdropoutisalightweightalternativetomean-fieldGaussianVIwhich,priortothiswork,hasnotbeendirectly
comparedtoVIintheFLenvironment. Inourexperiments,weshowedthatintheIIDandnon-IIDDirichletcases,MC
dropoutperformsonparwithoneofthetopperformingVIaggregationmethods(WS). Infact,intermsofaccuracy
andNLL,theMCdropoutmodelsoutperformthemean-fieldGaussianVImodels. Althoughthemean-fieldGaussian
17FederatedBayesianDeepLearning APREPRINT
Figure9: LearningcurveplotsforMCdropoutexperiments(E =5). Plotoftestsetaccuracyvs. federationroundfor
MCdropout(NWA)andVI(WS)aggregationmethodsforeachdatadistribution.
VImodelstendedtoconvergefaster,theMCdropoutmodelshavehalfthenumberofparameters,whichrequirefewer
clientresourcesandlowercommunicationrequirementsbetweenclientandserver. Thenon-IID2-classdatadistribution
casewastheexception: theMCdropoutmodelsconvergedslower, showedareductioninaccuracy, anddisplayed
poor calibration. In some cases, the use of an MC dropout model utilizing the NWA aggregation strategy may be
anacceptablelightweightalternativetomean-fieldGaussianVImodelsemployingoneoftheaggregationstrategies
discussedinthismanuscript.
5 ConclusionandFutureWork
Inremotesensingandsafety-criticalapplications,theabilityofamodeltocommunicateameasureofepistemicuncer-
taintyisessential. BDLmodelsarecapableofcommunicatingameasureofepistemicuncertaintywhilesimultaneously
deliveringcompetitivepredictionaccuracywhencomparedtotheirdeterministiccounterparts. However,tofullyrealize
the benefits of BDL in the FL setting, it is important to understand the downstream effects of the selected model
aggregationmethod. Inthismanuscript,weusedfourdifferentpartitionsoftheCIFAR-10datasetandafullyvariational
ResNet-20architecturetoanalyzesixBFLmodelaggregationmethodsformean-fieldGaussianVImodels. Thisisthe
firsttime,toourknowledge,thatafullyvariationalarchitecture(i.e.,allmodellayersarevariational)hasbeenutilized
inthistypeofanalysis. Additionally,whentrainedonacentralizeddataset,eachofthevariantsofourResNet-20
architectureachievedcomparableperformancetothebenchmarkperformancereportedbyHeetal.[61],seeTable1.
Assuch,wewereabletocompareourFLresultstoanimportantMLbenchmarkandprovideamoredetailedlookat
uncertainty. Ultimately,weidentifiedtheaggregationmethodasacriticalhyperparameterinthedevelopmentofaBFL
strategy,andweshowedthat,incertainapplications,MCdropoutisanacceptablelightweightalternativetomean-field
GaussianVI. Inbothcases(mean-fieldGaussianVIandMCdropout),ourglobalmodels(Table3,E =5)achieved
testsetaccuracywithin±2−3%ofthecentralizedbenchmark.
18FederatedBayesianDeepLearning APREPRINT
6 Disclaimer
The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily
representing the official policies or endorsements, either expressed or implied, of the U.S. Government. The U.S.
GovernmentisauthorizedtoreproduceanddistributereprintsforGovernmentpurposesnotwithstandinganycopyright
annotationsthereon.
References
[1] PatriciaMabry, “Makingsenseofthedataexplosion: Thepromiseofsystemsscience,” AmericanJournalof
PreventiveMedicine,vol.40,pp.S159–61,May2011.
[2] PaulVoigtandAxelvondemBussche, TheEUGeneralDataProtectionRegulation(GDPR):APracticalGuide,
SpringerPublishingCompany,Incorporated,1stedition,2017.
[3] BrendanMcMahan,EiderMoore,DanielRamage,SethHampson,andBlaiseAguerayArcas, “Communication-
efficientlearningofdeepnetworksfromdecentralizeddata,” inProceedingsofthe20thInternationalConference
onArtificialIntelligenceandStatistics.Apr.2017,vol.54ofProceedingsofMachineLearningResearch,pp.
1273–1282,PMLR.
[4] JakubKonecˇný,H.BrendanMcMahan,FelixX.Yu,PeterRichtárik,AnandaTheerthaSuresh,andDaveBacon,
“Federatedlearning: Strategiesforimprovingcommunicationefficiency,” arXivpreprintarXiv:1610.05492,2016.
[5] HangyuZhuandYaochuJin, “Multi-objectiveevolutionaryfederatedlearning,” IEEETransactionsonNeural
NetworksandLearningSystems,vol.31,no.4,pp.1310–1322,2019.
[6] Felix Sattler, Simon Wiedemann, Klaus-Robert Müller, and Wojciech Samek, “Robust and communication-
efficientfederatedlearningfromnon-I.I.D.data,” IEEETransactionsonNeuralNetworksandLearningSystems,
vol.31,no.9,pp.3400–3413,2020.
[7] TianLi,AnitKumarSahu,ManzilZaheer,MaziarSanjabi,AmeetTalwalkar,andVirginiaSmith, “Federated
optimizationinheterogeneousnetworks,” inProceedingsofMachineLearningandSystems,2020,vol.2,pp.
429–450.
[8] XiaohuiXu,SijingDuan,JinruiZhang,YunzhenLuo,andDeyuZhang, “Optimizingfederatedlearningondevice
heterogeneitywithasamplingstrategy,” in2021IEEE/ACM29thInternationalSymposiumonQualityofService
(IWQOS),2021,pp.1–10.
[9] YassineLaguel,KrishnaPillutla,JerômeMalick,andZaidHarchaoui, “Asuperquantileapproachtofederated
learningwithheterogeneousdevices,” in202155thAnnualConferenceonInformationSciencesandSystems
(CISS),2021,pp.1–6.
[10] YueZhao,MengLi,LiangzhenLai,NaveenSuda,DamonCivin,andVikasChandra, “Federatedlearningwith
non-IIDdata,” arXivpreprintarXiv:1806.00582,2018.
[11] CanhT.Dinh,NguyenTran,andJoshNguyen, “PersonalizedfederatedlearningwithMoreauenvelopes,” in
AdvancesinNeuralInformationProcessingSystems,2020,vol.33,pp.21394–21405.
[12] XuZhang,YinchuanLi,WenpengLi,KaiyangGuo,andYunfengShao, “Personalizedfederatedlearningvia
variationalBayesianinference,” inProceedingsofthe39thInternationalConferenceonMachineLearning.Jul.
2022,vol.162ofProceedingsofMachineLearningResearch,pp.26293–26310,PMLR.
[13] Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar, “Personalized federated learning with theoretical
guarantees: Amodel-agnosticmeta-learningapproach,” inAdvancesinNeuralInformationProcessingSystems,
2020,vol.33,pp.3557–3568.
[14] KeithBonawitz,VladimirIvanov,BenKreuter,AntonioMarcedone,H.BrendanMcMahan,SarvarPatel,Daniel
Ramage,AaronSegal,andKarnSeth, “Practicalsecureaggregationforprivacy-preservingmachinelearning,” in
Proceedingsofthe2017ACMSIGSACConferenceonComputerandCommunicationsSecurity,2017,CCS’17.
[15] Robin C. Geyer, Tassilo Klein, and Moin Nabi, “Differentially private federated learning: A client level
perspective,” arXivpreprintarXiv:1712.07557,2017.
[16] AbhishekBhowmick,JohnC.Duchi,JulienFreudiger,GauravKapoor,andRyanRogers, “Protectionagainst
reconstructionanditsapplicationsinprivatefederatedlearning,” arXivpreprintarXiv:1812.00984,2018.
[17] LipingLi,WeiXu,TianyiChen,GeorgiosB.Giannakis,andQingLing, “RSA:Byzantine-robuststochastic
aggregationmethodsfordistributedlearningfromheterogeneousdatasets,” ProceedingsoftheAAAIConference
onArtificialIntelligence,vol.33,no.01,pp.1544–1551,Jul.2019.
19FederatedBayesianDeepLearning APREPRINT
[18] ChuanGuo,GeoffPleiss,YuSun,andKilianQ.Weinberger, “Oncalibrationofmodernneuralnetworks,” in
Proceedingsofthe34thInternationalConferenceonMachineLearning.Aug.2017,vol.70ofProceedingsof
MachineLearningResearch,pp.1321–1330,PMLR.
[19] ZhanshengDuan,X.RongLi,andU.D.Hanebeck, “Multi-sensordistributedestimationfusionusingminimum
distancesum,” in17thInternationalConferenceonInformationFusion(FUSION),2014,pp.1–8.
[20] Christian Genest and James V. Zidek, “Combining probability distributions: A critique and an annotated
bibliography,” StatisticalScience,vol.1,no.1,pp.114–135,1986.
[21] TheodoreHill, “Conflationsofprobabilitydistributions,” TransactionsoftheAmericanMathematicalSociety,
vol.363,Aug.2008.
[22] GuntherKoliander,YousefEl-Laham,PetarDjuric,andFranzHlawatsch,“Fusionofprobabilitydensityfunctions,”
ProceedingsoftheIEEE,vol.110,pp.404–453,042022.
[23] PatrickMcClure,CharlesYZheng,JakubKaczmarzyk,JohnRogers-Lee,SatraGhosh,DylanNielson,PeterA
Bandettini, and Francisco Pereira, “Distributed weight consolidation: A brain segmentation case study,” in
AdvancesinNeuralInformationProcessingSystems,2018,vol.31.
[24] DanielJBeutel,TanerTopal,AkhilMathur,XinchiQiu,TitouanParcollet,andNicholasDLane, “Flower: A
friendlyfederatedlearningresearchframework,” arXivpreprintarXiv:2007.14390,2020.
[25] YarinGal,UncertaintyinDeepLearning,Ph.D.thesis,Dept.ofEngineering,UniversityofCambridge,Cambridge,
England,2016.
[26] AlexKendallandYarinGal, “WhatuncertaintiesdoweneedinBayesiandeeplearningforcomputervision?,” in
AdvancesinNeuralInformationProcessingSystems,I.Guyon,U.V.Luxburg,S.Bengio,H.Wallach,R.Fergus,
S.Vishwanathan,andR.Garnett,Eds.,2017,vol.30.
[27] DavidMBlei,AlpKucukelbir,andJonDMcAuliffe, “Variationalinference: Areviewforstatisticians,” Journal
oftheAmericanStatisticalAssociation,vol.112,no.518,pp.859–877,2017.
[28] OliverDurr,BeateSick,andElvisMurina, ProbabilisticDeepLearningWithPython,KerasandTensorFlow
Probability,chapter8, ManningPublicationsCo.,2020.
[29] ChristopherMBishop, PatternRecognitionandMachineLearning, Springer,NewYork,NY,USA,2006.
[30] MatthewD.Hoffman,DavidM.Blei,ChongWang,andJohnPaisley, “Stochasticvariationalinference,” Journal
ofMachineLearningResearch,vol.14,no.4,pp.1303–1347,2013.
[31] YemingWen,PaulVicol,JimmyBa,DustinTran,andRogerGrosse, “Flipout: Efficientpseudo-independent
weightperturbationsonmini-batches,” inInternationalConferenceonLearningRepresentations,2018.
[32] DurkPKingma,TimSalimans,andMaxWelling, “Variationaldropoutandthelocalreparameterizationtrick,” in
AdvancesinNeuralInformationProcessingSystems,2015,vol.28.
[33] YarinGalandZoubinGhahramani, “DropoutasaBayesianapproximation: Representingmodeluncertaintyin
deeplearning,” inProceedingsofThe33rdInternationalConferenceonMachineLearning.20–22Jun2016,
vol.48ofProceedingsofMachineLearningResearch,pp.1050–1059,PMLR.
[34] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra, “Weight uncertainty in neural
networks,” inProceedingsofthe32ndInternationalConferenceonMachineLearning.Jul.2015, vol.37of
ProceedingsofMachineLearningResearch,pp.1613–1622,PMLR.
[35] Yarin Gal, Riashat Islam, and Zoubin Ghahramani, “Deep Bayesian active learning with image data,” in
Proceedingsofthe34thInternationalConferenceonMachineLearning.Aug.2017,vol.70ofProceedingsof
MachineLearningResearch,pp.1183–1192,PMLR.
[36] Angelos Filos, Sebastian Farquhar, Aidan N Gomez, Tim GJ Rudner, Zachary Kenton, Lewis Smith, Milad
Alizadeh,ArnouddeKroon,andYarinGal, “AsystematiccomparisonofBayesiandeeplearningrobustnessin
diabeticretinopathytasks,”2019.
[37] LaurenceA.F.ParkandSimeonSimoff, “Usingentropyasameasureofacceptanceformulti-labelclassification,”
inAdvancesinIntelligentDataAnalysisXIV.2015,pp.217–228,SpringerInternationalPublishing.
[38] Stefan Depeweg, Jose-Miguel Hernandez-Lobato, Finale Doshi-Velez, and Steffen Udluft, “Decomposition
ofuncertaintyinBayesiandeeplearningforefficientandrisk-sensitivelearning,” inProceedingsofthe35th
InternationalConferenceonMachineLearning.Jul.2018,vol.80ofProceedingsofMachineLearningResearch,
pp.1184–1193,PMLR.
20FederatedBayesianDeepLearning APREPRINT
[39] YongchanKwon,Joong-HoWon,BeomJoonKim,andMyungheeChoPaik, “Uncertaintyquantificationusing
Bayesian neural networks in classification: Application to biomedical image segmentation,” Computational
Statistics&DataAnalysis,vol.142,2020.
[40] L.Liu,X.Jiang,F.Zheng,H.Chen,G.Qi,H.Huang,andL.Shao, “ABayesianfederatedlearningframework
withonlineLaplaceapproximation,” IEEETransactionsonPatternAnalysis&MachineIntelligence,vol.46,no.
01,pp.1–16,Jan.2024.
[41] Hong-YouChenandWei-LunChao, “FedBE:MakingBayesianmodelensembleapplicabletofederatedlearning,”
inInternationalConferenceonLearningRepresentations,2021.
[42] AdamThorThorgeirssonandFrankGauterin, “Probabilisticpredictionswithfederatedlearning,” Entropy,vol.
23,no.1,Dec.2020.
[43] ShreyBhatt,AishwaryaGupta,andPiyushRai,“Bayesianfederatedlearningviapredictivedistributiondistillation,”
2022.
[44] TheodoreP.HillandJackMiller, “Howtocombineindependentdatasetsforthesamequantity,” Chaos: An
InterdisciplinaryJournalofNonlinearScience,vol.21,no.3,Sep.2011.
[45] WilliamG.CochranandSarahPorterCarroll, “Asamplinginvestigationoftheefficiencyofweightinginversely
astheestimatedvariance,” Biometrics,vol.9,no.4,pp.447–459,1953.
[46] MalteKnüppelandFabianKrüger, “Forecastuncertainty,disagreement,andthelinearpool,” JournalofApplied
Econometrics,vol.37,no.1,pp.23–41,2022.
[47] MichaelP.Clements, “Aremacroeconomicdensityforecastsinformative?,” InternationalJournalofForecasting,
vol.34,no.2,pp.181–198,2018.
[48] VictorZarnowitzandLouisA.Lambros, “Consensusanduncertaintyineconomicprediction,” JournalofPolitical
Economy,vol.95,no.3,pp.591–621,1987.
[49] M.Stone, “Theopinionpool,” TheAnnalsofMathematicalStatistics,vol.32,no.4,pp.1339–1342,1961.
[50] MichaelP.Clements, “Forecastuncertainty—exanteandexpost: U.S.inflationandoutputgrowth,” Journalof
Business&EconomicStatistics,vol.32,no.2,pp.206–216,2014.
[51] KajalLahiriandXuguangSheng, “Measuringforecastuncertaintybydisagreement: Themissinglink,” Journal
ofAppliedEconometrics,vol.25,Feb.2008.
[52] ChristianGenestandKevinMcConway,“Allocatingtheweightsinthelinearopinionpool,”JournalofForecasting,
vol.9,pp.53–73,1990.
[53] P.D.HanlonandP.S.Maybeck, “Multiple-modeladaptiveestimationusingaresidualcorrelationKalmanfilter
bank,” IEEETransactionsonAerospaceandElectronicSystems,vol.36,no.2,pp.393–406,2000.
[54] KajalLahiri,ChristieTeigland,andMarkZaporowski, “Interestratesandthesubjectiveprobabilitydistribution
ofinflationforecasts,” JournalofMoney,CreditandBanking,vol.20,no.2,pp.233–248,1988.
[55] Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, and Richard E. Turner, “Variational continual learning,” in
InternationalConferenceonLearningRepresentations,2018.
[56] MaxKochurov,TimurGaripov,DmitryPodoprikhin,DmitryMolchanov,ArseniiAshukha,andDmitryVetrov,
“Bayesianincrementallearningfordeepneuralnetworks,”2018.
[57] Jonatan Reyes, Lisa Di-Jorio, Cécile Low-Kam, and Marta Kersten-Oertel, “Precision-weighted federated
learning,” arXivpreprintarXiv:2107.09627,2021.
[58] AlexKrizhevsky, “Learningmultiplelayersoffeaturesfromtinyimages,” M.s.thesis,UniversityofToronto,
Toronto,Ontario,Canada,2009.
[59] QinbinLi,YiqunDiao,QuanChen,andBingshengHe,“Federatedlearningonnon-IIDdatasilos:Anexperimental
study,” in2022IEEE38thInternationalConferenceonDataEngineering(ICDE),2022,pp.965–978.
[60] Tzu-MingHarryHsu,HangQi,andMatthewBrown, “Measuringtheeffectsofnon-identicaldatadistributionfor
federatedvisualclassification,” arXivpreprintarXiv:1909.06335,2019.
[61] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun, “Deepresiduallearningforimagerecognition,” in
2016IEEEConferenceonComputerVisionandPatternRecognition(CVPR),2016,pp.770–778.
[62] MartínAbadi,AshishAgarwal,PaulBarham,EugeneBrevdo,ZhifengChen,CraigCitro,GregS.Corrado,Andy
Davis,JeffreyDean,MatthieuDevin,SanjayGhemawat,IanGoodfellow,AndrewHarp,GeoffreyIrving,Michael
Isard,YangqingJia,RafalJozefowicz,LukaszKaiser,ManjunathKudlur,JoshLevenberg,DandelionMané,Rajat
Monga,SherryMoore,DerekMurray,ChrisOlah,MikeSchuster,JonathonShlens,BenoitSteiner,IlyaSutskever,
21FederatedBayesianDeepLearning APREPRINT
KunalTalwar,PaulTucker,VincentVanhoucke,VijayVasudevan,FernandaViégas,OriolVinyals,PeteWarden,
MartinWattenberg,MartinWicke,YuanYu,andXiaoqiangZheng, “TensorFlow: Large-scalemachinelearning
onheterogeneousdistributedsystems,”2015.
[63] JohnFischer,MarkoOrescanin,PaulLeary,andKevinB.Smith, “ActiveBayesiandeeplearningwithvector
sensorforpassivesonarsensingoftheocean,” IEEEJournalofOceanicEngineering,vol.48,no.3,pp.837–852,
2023.
22