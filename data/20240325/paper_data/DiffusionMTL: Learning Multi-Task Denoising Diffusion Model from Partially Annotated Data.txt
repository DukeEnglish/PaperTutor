DiffusionMTL: Learning Multi-Task Denoising Diffusion Model
from Partially Annotated Data
HanrongYeandDanXu(cid:0)
DepartmentofComputerScienceandEngineering,HKUST
ClearWaterBay,Kowloon,HongKong
{hyeae, danxu}@cse.ust.hk
Abstract
Recently, there has been an increased interest in the Task 0
practical problem of learning multiple dense scene under-
Noisy Prediction or Multi-Task Denoised
standing tasks from partially annotated data, where each Noisy Feature Conditioning Output
training sample is only labeled for a subset of the tasks.
The missing of task labels in training leads to low-quality Task T
and noisy predictions, as can be observed from state-of-
the-art methods. To tackle this issue, we reformulate the
Diffusion Process Denoising Process
partially-labeled multi-task dense prediction as a pixel-
Initial Decayed Denoising Step 1 Denoising Step 2
level denoising problem, and propose a novel multi-task
denoising diffusion framework coined as DiffusionMTL. It
designsa jointdiffusion anddenoising paradigmto model
a potential noisy distribution in the task prediction or fea-
turemapsandgeneraterectifiedoutputsfordifferenttasks.
To exploit multi-task consistency in denoising, we further Figure 1. Motivative illustration of the proposed DiffusionMTL
introduce a Multi-Task Conditioning strategy, which can for multi-task partially supervised dense prediction. The model
denoise the manually decayed multi-task prediction or feature
implicitly utilize the complementary nature of the tasks to
maps (denoted as {X0,...,XT}, T,S are the numbers of tasks
help learn the unlabeled tasks, leading to an improvement S S
andstepsseparately)inastepbystepmanner,andobtainthede-
inthedenoisingperformanceofthedifferenttasks. Exten-
noisedoutputs{X0,...,XT}.Thedenoisingprocessisguidedby
0 0
sive quantitative and qualitative experiments demonstrate
thedesignedmulti-taskconditionfeatureF .
cond
thattheproposedmulti-taskdenoisingdiffusionmodelcan
significantly improve multi-task prediction maps, and out- learning. Ontheonehand,multi-taskmodelsarenaturally
perform the state-of-the-art methods on three challenging more efficient than single-task models with similar struc-
multi-taskbenchmarks,undertwodifferentpartial-labeling turesbecausedifferenttaskscansharesomenetworkmod-
evaluation settings. The code is available at https:// ules.Ontheotherhand,differenttasksareabletohelpeach
prismformore.github.io/diffusionmtl/. 1 otherandimproveoverallperformancebysharinginforma-
tionthroughcross-taskconsistency[5]. However,annotat-
ingareal-worldmulti-tasklearningdatasetatthepixellevel
1.Introduction isadauntingtask. Asanalternative, collectingdataanno-
tatedfordifferenttasksandusingthemtotrainamulti-task
Multi-task learning for dense scene understanding [1–4]
modelisamuchmorefeasibleapproach.Thismotivatesre-
is an important research topic that has recently gained a
centwork[6]thatdefinesanimportantnewproblemknown
lot of attention from computer vision researchers. It aims
as “Multi-Task Partially Supervised Learning (MTPSL)”,
at jointly learning multiple scene-related dense prediction
where each training sample contains labels for a subset of
tasks,includingsemanticsegmentation,surfacenormales-
thetasks, ratherthanalltasks. Asthereisalackofmulti-
timation, depth estimation, etc. This multi-task learning
tasklabelsforeachtrainingsample,thepartiallysupervised
problem has dual superiority over traditional single-task
multi-tasklearningproblemismorechallengingcompared
1ThepaperisacceptedbyCVPR2024. tothefullysupervisedmulti-tasklearningproblem.Tohan-
1
4202
raM
22
]VC.sc[
1v98351.3042:viXradle this problem, previous state-of-the-art models [6] fo- MTLmodel,andshowthatDiffusionMTLsignificantlyout-
cus on improving label efficiency by enforcing cross-task performsthecurrentstate-of-the-artmethodbyalargemar-
consistency. They train an additional network to construct gin,usingthesamebackboneandfewermodelparameters.
a joint feature space for each task pair, which helps im- Insummary,thecontributionofthispaperisthreefold:
provethemulti-taskoptimizationprocessanddemonstrates • Weproposethefirstmulti-taskdenoisingdiffusionframe-
promising multi-task performance under MTPSL. Despite workforthepartiallylabeledmulti-taskdenseprediction
theirsuccessinimprovingmodelperformance,thesparsity problem. The innovative framework reformulates multi-
of training labels in MTPSL still inevitably leads to noisy task dense prediction as a joint pixel-level diffusion and
predictionmapswhichcanbeobservedfrompreviousstate- denoisingprocess,whichempowersustogeneraterecti-
of-the-art models, as shown in Figure 7. Therefore, there fiedhigher-qualitymulti-taskpredictions.
isaneedforanewmethodologytoeffectivelydenoisethe • WedevelopanovelMulti-TaskDenoisingDiffusionNet-
noisymulti-taskdensepredictionstoimprovethemulti-task workspecificallydesignedtoaddresstheissueofnoisein
predictionquality. initial prediction maps. An effective Multi-Task Condi-
tioningmechanismisdesignedinourdiffusionmodelto
Toaddresstheabove-mentionedproblem,weproposea
enhance the denoising performance. We further devise
novelmulti-taskdenoisingdiffusionframeworkthatcanef-
two effective diffusion mechanisms, namely Prediction
fectivelyremovenoisefromthedensepredictionsandrec-
DiffusionandFeatureDiffusion,forrefiningtasksignals
tify multi-task prediction maps. We formulate the multi-
inpredictionandfeaturespacesseparately.
taskdensepredictionproblemasajointpixel-leveldenois-
• Extensive experiments have been conducted on three
ing and generation process, and propose a new multi-task
prevalent partial-labeling multi-task benchmarks under
modelcoinedas“DiffusionMTL”.DiffusionMTLlearnsto
two different settings, which clearly validate the effec-
denoisenoisymulti-taskpredictionswiththehelpofdiffu-
tiveness of our proposal. Our method demonstrates sig-
sion models [7], which are particularly effective in recov-
nificantperformanceimprovementscomparedtothepre-
eringdatadistributionfromnoisyinput. Itjointlyperforms
viousstate-of-the-artmethods.
thediffusionanddenoisingprocessestodiscoverpotential
noisy distributions of the multi-task prediction maps, and
2.RelatedWork
learnstorectifythepredictionmaps.Wefurtherpresenttwo
distinct diffusion mechanisms: Prediction Diffusion and
Multi-Task Dense Scene Understanding with Partially
Feature Diffusion. Prediction Diffusion learns to remove
Annotated Data Multi-task learning (MTL) for dense
noise from the multi-task prediction maps, while Feature
scene understanding has been widely studied in recent
Diffusionlearnstorefinethemulti-taskfeaturemaps. Un-
years [1, 3, 5, 9–16]. By learning several tasks together,
like typical diffusion models used for image synthesis [8],
MTL enhances the computational efficiency of both train-
ourdenoisingnetworkisdesignedtoachievetwoobjectives
ing and inference compared to single-task models while
simultaneously.Firstly,itmustreversetheMarkoviannoise
achieving better performance [4, 17, 18]. To improve the
diffusion process, i.e., remove the manually added noise
performanceofmulti-tasklearning, someresearchershave
from the input maps. Secondly, it is encouraged to gen-
focusedonimprovingtheoptimizationprocessofMTLby
erate higher-quality multi-task predictions from the noisy
designinglossfunctions[2,6,19–21]andmanipulatinggra-
input, therebyimprovingoverallmulti-taskpredictionper-
dients [22–26], while other researchers work on design-
formance.Furthermore,toexploitmulti-taskconsistencyin
ing powerful multi-task model architectures [27–37]. It is
thedenoisingprocess,wedesignaMulti-TaskConditioning
worth noting that the aforementioned methods are mainly
mechanismforourDiffusionMTLmodel. Thismechanism
designedforfully-supervisedmulti-tasklearning,wherethe
utilizesthepredictionmapsgeneratedbythedecodersofall
labelsofalltasksareassumedtobegivenforeachtraining
thetaskstoeffectivelyfacilitatethedenoisingprocessofa
image. However, in real-world scenarios, it is not always
target task. Meanwhile, the outputs of the unlabeled tasks
feasibletoobtainlabelsforalltasks,andwemayhavedata
also receive supervision signals from the ground-truth la-
with only some of the tasks available. To address this is-
belsofothertasks,allowingourDiffusionMTLtonotonly
sue,anewproblemnamedMulti-TaskPartiallySupervised
enhancethedenoisingperformanceofthelabeledtasksbut
Learning(MTPSL)hasbeendefinedby[6]. InMTPSL,the
alsofacilitatethelearningofunlabeledtasks.
training samples are only partially annotated for the tasks,
Toevaluatetheeffectivenessofourapproachformulti- which poses new challenges to multi-task learning due to
task partially supervised learning, we have conducted thesparsityoflabelsinthetrainingdata. Tomeetthechal-
extensive experiments on three challenging partially- lenge,XTC[6]hasbeenproposedtobetterleveragepartial
annotated multi-task datasets, namely PASCAL, NYUD, annotationsbyimprovinglabelefficiency. Itmapsthelabel
and Cityscapes. Both quantitative and qualitative results spacesofdifferenttasksintoonejointfeaturespaceanduti-
demonstrate the effectiveness of the proposed Diffusion- lizescross-taskconsistencytolearntaskswithoutlabelsfor
2Multi-Task Denoising Diffusion Network
Initial Multi-Task 1 Diffusion Process 2 Denoising Process Denoised Multi-Task
Prediction Maps Prediction Maps
Image Task with GT Label ( ) Task with GT Label
Noise Decay Denoiser
Multi-Task
Task Loss Task Loss
Conditioning
Backbone
Task without GT Label Task without GT Label
Noise Decay Denoiser
Task Loss Task Loss
Figure2. IllustrationoftheproposedDiffusionMTL(PredictionDiffusion)frameworkfortheMTPSLsetting. DiffusionMTLfirstuses
aninitialbackbonemodelforproducingstarterpredictionmapsforalltasks. Todenoisetheinitialpredictionmapsandgeneraterectified
maps,weproposeaMulti-TaskDenoisingDiffusionNetwork(MTDNet).MTDNetinvolvesadiffusionprocessandadenoisingprocess.
During training, the initial prediction map of the labeled target task T is gradually degraded by applying noise, resulting in the noisy
predictionmapPT. Then,weutilizeaMulti-TaskConditionedDenoiser(referredtoasthe“Denoiser”)todenoisePT iterativelyover
S S
S steps,resultinginacleanpredictionmapPT thatissupervisedbytheground-truthlabel. Forbetterlearningofunlabeledtasks,we
0
proposeaMulti-TaskConditioningmechanisminthedenoisingprocesstostimulateinformationsharingacrossdifferenttasks. During
inference,thediffusionanddenoisingprocessesareappliedtoalltaskstoproducedenoisedmulti-taskpredictionmaps.
Initial Feature Map of sion models and has the potential to inspire the design of
Target Task
futurediffusionmodelsfordeterministictasks.
Noise Task
Denoiser
Decay Head
3.TheProposedDiffusionMTLApproach
Multi-Task Denoised
Initial Feature Maps Conditioning Prediction Map Inthissection,wewillintroducethedetailsofourproposed
of Ohter Tasks
multi-task denoising diffusion framework, DiffusionMTL,
Figure3.IllustrationoftheproposedDiffusionMTL(FeatureDif-
as illustrated in Fig. 2. DiffusionMTL has two steps: (i)
fusion),whichconductsnoisedecayanddenoisingoninitialfea-
First,aninitialbackbonemodelgeneratespreliminarypre-
turemapsFT . ThedenoisedfeaturemapsFT areprojectedto
init 0
thefinalpredictionmapPT withataskheadafterthedenoising. dictionmapsformultipledensesceneunderstandingtasks.
0
(ii) Second, a proposed Multi-Task Denoising Diffusion
each training sample. Although this approach has shown Network(MTDNet)takesinthenoisyinitialmulti-taskpre-
promisingresults, itstillinevitablysuffersfromnoisypre- dictionmapsandproducesrefinedpredictionresults. These
dictions because the model is under-trained with a limited twopartsaretrainedtogetherinanend-to-endmannerwith
numberofground-truthlabels. Todirectlytacklethenoisy partiallyannotateddata.
prediction problem, our proposal takes a distinct approach
bydesigninganovelmulti-taskdenoisingframeworktoim-
3.1.InitialBackboneModel
provethequalityofmulti-taskpredictionmaps.
Diffusion Models Diffusion models [7, 38] are a class of Weadoptaclassicencoder-decoderstructureforthemulti-
generative models that have been widely used for image task dense prediction [4, 17, 32]. The initial backbone
synthesis tasks, and have achieved state-of-the-art perfor- model utilizes a task-shared encoder f , which accepts
enc
mance on several benchmarks [7, 8, 39–41]. However, an input image I ∈ RH×W×3 (where H and W repre-
adapting diffusion models for multi-task dense prediction sent height and width, respectively) and projects it to ob-
is not straightforward. Although some attempts have been tain a multi-channel backbone feature map F ∈
backbone
made to apply diffusion models to single-task determinis- RH′×W′×C. The backbone feature map has a height of
tic problems including image classification [42], segmen- H′, a width of W′, and C channels. It is shared by
tation [43–47] and detection [48], they are not suitable for all the tasks. And then, to generate task-specific feature
multi-taskdensesceneunderstanding.Inthispaper,wepro- maps for T tasks, we adopt a series of task-specific de-
pose a novel multi-task diffusion model that can denoise coders {f1 ,f2 ,...,fT } with identical network struc-
dec dec dec
noisypredictionmapsformultipletasksandobtainfinerre- turesanddifferentnetworkparameters. Thegeneratedini-
sultsunderthemulti-taskpartially-supervisedsetting. Our tial task feature maps from the decoders are notated as
approach represents an exploratory advancement in diffu- {F1 ,F2 ,...,FT }. Forthet-thtask,wecomputethe
init init init
3Denoising Step
Step Embedding
MN ao pis oy f P Tr ae rd gi ec t Tio an sk Conv Denoised Prediction Map
... Task
Head
Conv
I Pn rit ei da il c M tiou nlt Mi-T aa ps sk T tasks Stack Conv
Conv
Conv
3×3 Convolution Add
Multi-Task Conditioning Multi-Task Conditioned Denoiser
Figure4. PipelineofasinglestepsinthedenoisingprocessofDiffusionMTL(PredictionDiffusion). Multi-TaskConditioning: The
initialpredictionmapsforalltasksareprojectedtotask-specificfeaturesandthenstacked. Thestackedfeaturesarethenprocessedwith
a3×3convolutiontoreducethechanneldimension,resultinginaMulti-TaskConditionFeatureF whichissharedacrossalltasks.
cond
Multi-Task Conditioned Denoiser: The denoiser consists of several cross-attention transformer blocks, which learn to denoise input
conditionedonF . Foritsinput,weperforma3×3convolutiononthenoisypredictionmapPT andcombinetheoutputwiththe
cond s
stepembedding, obtainingataskembeddingET. ThedenoisertakesF asqueryinputandE askeyandvalueinputs. Weusea
s cond s
task-specificheadtoobtainthedenoisedpredictionmapPT ,whichistheinputofthenextdenoisingsteps−1.
s−1
task-specificinitialfeaturemapFt as: process, we incrementally degrade the information in the
init
initialpredictionmapsbyapplyingnoisewithaMarkovian
Ft =ft (f (I)). (1)
init dec enc chain. In the denoising process, we introduce a novel de-
TocomputeaninitialdensepredictionmapPt forthet- noisingnetworkthatistrainedtogeneratecleanprediction
init
thtask,weapplyatask-specific1×1convolutionft on mapsfromthedegradedonesinaniterativemanner. With-
pred
thecorrespondingtaskfeaturemapFt : outlossofgenerality,weelaborateontheone-labelsetting
init
ofthemulti-taskpartiallysupervisedlearning,whereweas-
Pt =ft (Ft ). (2)
init pred init sumethatthecurrenttrainingsamplehaslabelforonlyone
task(taskT).Wenamethislabeledtaskasthe“targettask”.
In this way, we obtain the T initial prediction maps of all
T tasks. The initial prediction maps are noisy as we can
observefromFig.2. Weaimtorectifythenoisymulti-task 3.2.1 DiffusionProcess
predictionmapswiththefollowingMTDNet.
Inthediffusionprocess(or“forwardprocess”)[7],wecon-
3.2.Multi-TaskDenoisingDiffusionNetwork struct a fixed Markov chain with a total length of S steps.
ForthetargettaskT,Gaussiannoiseisgraduallyappliedto
In this paper, we put forward a novel diffusion model,
theinitialmapXT inastep-by-stepmanner. HereXT
named Multi-Task Denoising Diffusion Network (MTD- init init
istheinitialpredictionmapPT (inPredictionDiffusion)
Net) for denoising the aforementioned noisy prediction init
orinitialtaskfeaturemapFT (inFeatureDiffusion).Sup-
maps.Toachievethisgoal,wedesigntwoorthogonaldiffu- init
posethedecayedmapatdenoisingstepsoftargettaskT is
sionmechanismsinourunifiedMTDNet, focusingondif-
XT,thediffusionprocessqcanbeformulatedas:
ferent signal domains: (i) Prediction Diffusion and (ii) s
√
Feature Diffusion. These mechanisms differ in terms of q(XT|XT )=N(XT| α¯ XT ,(1−α¯ )I), (3)
s init s s init s
the signal space in which the diffusion model is applied.
FeatureDiffusionrefinesthetask-specificfeatureswithina where {α¯ ,s ∈ 1,2,...,S} are hyperparameters. In prac-
s
high-dimensional latent space, while Prediction Diffusion tice, we could directly compute the final decayed map.
directly improves the initial task predictions in the output Through mathematical derivation, the decayed prediction
space. Feature Diffusion facilitates a comprehensive im- map of target task T at the final step S can be formulated
√ √
provement of high-level visual information within an ex- asXT = α¯ XT + 1−α¯ ϵ,whereϵ∼N(0,I). For
S S init S
panded latent space, while Prediction Diffusion demon- moretheoreticaldetailspleasereferto[7].
strates effective denoising capabilities along with better
computational efficiency. More details about their differ-
3.2.2 DenoisingProcess
encewillbeprovidedwhendescribingthedifferentcompo-
nentsofMTDNet. AsshowninFig.2forPredictionDiffu- AsthecorecomponentofourMTDNet,thedenoisingpro-
sionandFig.3forFeatureDiffusion,wefollowtheDDPM cessinvolvesdesigningaMulti-TaskConditionedDenoiser,
paradigm[7], whichisseparatedinto2processes: adiffu- referred to as “Denoiser”, to denoise the noisy multi-task
sionprocessandadenoisingprocess. Duringthediffusion prediction maps or feature maps. Specifically, given the
4
...
K,
V
Q
Norm
Norm
Cross-Attention Norm
Norm
Feed-Forward
Feed-Forward
K, V
Q
K, V
QPseudocode1DiffusionMTLunderone-labelsetting tasks.Oncewehaveobtainedtask-specificfeaturesforallT
1: functionDIFFUSIONMTL(version,mode,I,L,T,S,T) tasks,wecombinethemalongthechanneldimension. The
2: Input: version∈{‘PredictionDiffusion’,‘FeatureDiffu- resulting tensor is then subjected to a 3×3 convolutional
sion’},mode∈{‘train’,‘infer’},inputimageI,labelmapL, layer, which reduces the channel dimension to C and then
targettaskT,diffusionstepsS,numberoftasksT flattens the spatial dimension, resulting in a vector known
3: Output:TraininglossordenoisedpredictionmapPT 0 as the multi-task condition feature F cond. We refer to this
4: F backbone ←f enc(I) computationalprocessasf cond.
5: fort←1,2,...,T do Multi-TaskConditionedDenoiserWeillustratethestruc-
6: Ft
init
←f dt ec(F backbone) ▷Computeinitialtask
ture of denoiser in Fig. 4. The denoiser is a series of
features
cross-attentiontransformerblocks,takinginthenoisymap
7: Pt ←ft (Ft ) ▷Computeinitialprediction
init pred dec XT,thedenoisingsteps,andthemulti-taskconditionfea-
maps s
tureF asinput,andgeneratesthedenoisedmapXT .
8: endfor cond s−1
9: ifversion=‘PredictionDiffusion’then XT s−1 isusedasinputforthenextstepinaniterativeman-
10: XT ←PT ner.Specifically,westartbyprojectingthenoisymapofthe
init init
11: F cond ←f cond(P1 init,P2 init,...,PT init) targettasktoaC-channeltaskembeddingviaa3×3con-
12: elseifversion=‘FeatureDiffusion’then volution and flatten its spatial dimension. Then we embed
13: XT init ←FT init the denoising step s using a typical sinusoidal embedding
14: F cond ←f cond(F1 init,F2 init,...,FT init) module [8]. We call this process “Step Embedding”. We
15: endif addthestepembeddingtothetaskembedding. Theresult-
16: ϵ∼N(0 √,I) √ ▷Samplenoise ingtaskembeddingET assumestheroleofkeyandvalue
17: XT
S
← α¯ SXT init+ 1−α¯ Sϵ ▷Diffusionprocess
tensors (K,V) in
thes
subsequent transformer blocks, and
18: fors←S,S−1,...,1do
F issuppliedtothetransformerblocksasthequeryQ:
19: XT
s−1
←Denoiser(XT s,s,F cond) ▷Denoisingstep cond
20: endfor
21: ifversion=‘PredictionDiffusion’then Q←F cond, K←ET s , V←ET s . (4)
22: PT ←XT
0 0 ThetransformerblocksreceiveQ,K,andVasinput.Each
23: elseifversion=‘FeatureDiffusion’then
24: PT ←fT (XT) ▷Finaltaskhead block comprises linear normalization, cross-attention, and
0 head 0
feed-forward networks as shown in Fig. 4. For a more
25: endif
26: ifmode=‘train’then comprehensiveunderstandingofthedetailsoftransformer,
27: returncompute loss(PT,L) ▷Computelosswith please consult [49]. Here, the cross-attention transformer
0
availablelabeloftargettask blocks absorb information from the task embedding ET
s
28: elseifmode=‘infer’then guidedbythemulti-taskconditioningfeatureF .
cond
29: returnPT 0 ▷Outputdenoisedpredictionmap The output procedure of a denoising step is different in
30: endif Prediction Diffusion and Feature Diffusion. In Prediction
31: endfunction Diffusion,theoutputofthetransformerblocksisreshaped
toaspatialmapandprojectedtopredictionmapPT us-
s−1
ingatask-specificheadwhichconsistsofseveralconvolu-
decayed noisy map of target task XT S from the diffusion tional layers with ReLU. In Feature Diffusion, the output
process, Denoiser generates XT S−1, XT S−2,..., XT 0 in an it- of transformer blocks is projected to a feature map FT s−1,
erative manner. In the following, we will first introduce a which serves as the output of this step (i.e. XT ). More
s−1
novel Multi-Task Conditioning strategy, and then describe implementation details can be found in Sec. 4.1. We can
how Denoiser computes the denoised map in each denois- formulateeachstepinthedenoisingprocessas:
ing step. Fig. 4 illustrates the computation pipeline for a
singledenoisingstepofPredictionDiffusion. XT =Denoiser(XT,s,F ),
s−1 s cond (5)
Multi-TaskConditioningTohelpdenoisethepredictionor s∈S,S−1,...,1.
featuremapsofthelabeledtasks,aswellasenablelearning
unlabeledtasksunderapartiallyannotatedsetting,wepro- For the final output after S denoising steps, Prediction
pose a Multi-Task Conditioning strategy in the denoising Diffusion directly generates the denoised prediction map
process.Itfirstobtainsa“multi-taskconditionfeature”(de- of target task PT, which is used to compute task-specific
0
notedasF )fromtheinitialmapsofallthetasks.F losssupervisedbytheavailableground-truthlabel. InFea-
cond cond
capturesthejointmulti-taskinformation,whichislaterused ture Diffusion, we need a final task-specific head fT to
head
to condition the denoising network. To obtain F , we projectthedenoisedfeaturemapsFT tothefinalprediction
cond 0
firstprojecttheinitialmulti-taskmapstofeaturespaceviaa map PT. We present the detailed training and inference
0
3×3convolutionandobtaintask-specificfeaturesforallT pipelinesofDiffusionMTLinPseudocode1.
53.3.ModelOptimization Initial Decayed Denoising Step 1 Denoising Step 2 Ground-Truth
The whole DiffusionMTL model can be trained under the
MTPSL setting in an end-to-end manner. Specifically, for
eachtrainingsample,weapplytask-specificlossesonboth
theinitialpredictionmapsaswellasthefinaldenoisedpre-
diction maps of the tasks with labels. For the unlabeled
tasks,therearenoground-truthsupervisionsignals,butthe Figure 5. Visualization of the prediction maps at different pro-
task-specific decoders are able to be implicitly trained via cessesonCityscapes. OurDiffusionMTLeffectivelydenoisesthe
noisypredictionmapsofbothtasks.
theproposedMulti-TaskConditioning. Moredetailsabout
lossesareintroducedinthesupplementalmaterials. Semseg Depth MTLPerf
#labels Method
mIoU↑ absErr↓ ∆m↑
4.Experiments Single-Task 75.82 0.0125 -
MTLBaseline 73.19 0.0168 -18.81%
4.1.ExperimentalSetup SS[6] 71.67 0.0178 -
one/random XTC[6] 74.90 0.0161 -
Datasets and Tasks Following the pioneering work in XTC*[6] 73.36 0.0158 -14.74%
DiffusionMTL(Prediction) 74.90 0.0131 -2.79%
multi-taskpartiallysupervisedlearning[6],weadoptthree
DiffusionMTL(Feature) 75.67 0.0130 -2.13%
prevalent multi-task datasets with dense annotations, i.e.
Table1. ComparisonwithSOTAsonCityscapes. Theproposed
PASCAL[50],NYUD[51],andCityscapes[52].PASCAL
DiffusionMTLdemonstratessuperiorperformanceonbothtasks.
isacomprehensivedatasetprovidingimagesofbothindoor
One-label setting is equivalent to the random-label setting on
and outdoor scenes. There are 4,998 training images and Cityscapes.“*”denotesre-implementedresults.
5,105testingimages,withlabelsofsemanticsegmentation,
ting, where the number of labeled tasks for each image is
human parsing, and object boundary detection. Addition-
random. We use exactly the same image-task label map-
ally,[1]generatespseudolabelsforsurfacenormalsestima-
pingsas[6]forastrictlyfaircomparison.
tionandsaliencydetection.NYUD(orNYUD-v2)provides
Implementation Details For most models in the experi-
images of indoor scenes as well as dense annotations for
ments,weuseResNet-18asbackbonewithImageNetpre-
13-classsemanticsegmentationanddepthestimation. The
images are resized to 288×384. The surface normals can trained weights provided by PyTorch. We concatenate the
feature maps of the four stages of ResNet-18 along the
begeneratedfromdepth. Thetrainingsetcontains795im-
channel dimension and process them with a 3×3 convo-
ages,whilethetestingsetcontains654images. Cityscapes
lution to reduce the number of channels to 512. For our
capturesstreetscenesofdifferentcitieswithfinepixel-level
DiffusionMTL, the initial multi-task backbone has a task-
annotations.Following[6,10],weuse7-classsemanticseg-
specific decoder for each task, using 2 residual convolu-
mentationandmonoculardepthestimationtasksintheex-
periments. Theimagesareresizedto128×256. Thereare
tionalblocks[53],followedbya1×1convolutionaspre-
diction head. Each residual convolutional block contains
2,975trainingimagesand500validationimages.
two 3 × 3 convolutions with BN and ReLU. The denois-
TaskMetricsWeadoptthesamemetricsfordifferenttasks
ing network uses 4 task-shared cross-attention transformer
as previous work [6]. We use the mean Intersection over
blocks, which are followed by a task-specific head of four
Union (mIoU) to evaluate the performance of the seman-
3×3CONV-ReLUlayersanda1×1convolutionfortask
tic segmentation (Semseg) and human parsing (Parsing)
predictioninPredictionDiffusion.Weuse2stepsinthedif-
tasks, while the absolute error (absErr) is used for eval-
fusionprocess. Moreimplementationdetailscanbefound
uating the monocular depth estimation task (Depth). For
inthesupplementalmaterials.
the surface normal estimation task (Normal), we use the
meanerrorofangles(mErr)astheevaluationmetric,while
4.2.MainExperiments
forthesaliencydetectiontask(Saliency),weusethemaxi-
malF-measure(maxF).Theobjectboundarydetectiontask DeclarationofComparisonModels Weconsiderseveral
(Boundary) is evaluated using the optimal-dataset-scale F- models for comparison to verify the effectiveness of our
measure (odsF). To quantify the overall multi-task perfor- proposed DiffusionMTL framework: (i) “MTL Baseline”
mancerelativetothesingle-taskbaseline, wecalculatethe isthebaselinemodel. ItsharesthesamebackboneasDif-
meanrelativedifferenceacrossalltasks,denotedasMulti- fusionMTL and utilizes a strong task-specific decoder for
taskPerformance(MTLPerf∆ )[1]. eachtask.Itconsistsof6residualconvolutionalblocks,fol-
m
MTPSL Evaluation Settings There are two evaluation lowedbya1×1convolutionaspredictionhead. (ii)“SS”
settings for multi-task partially supervised learning [6]: and “XTC” [6] are pioneering state-of-the-art methods as
(i) one-label setting, where each training image has the introducedinrelatedwork. XTCisre-implementedonour
ground-truthlabelofonlyonetask. (ii)random-labelset- MTL Baseline based on their official codes for fair com-
6Semseg (mIoU) 0.0133 Depth (absErr) 750G FLOPs Backbone Method #ParamsFLOPSSemsegParsingSaliencyNormalBoundaryMTLPerf
75.00
0.0132 700G
mIoU↑mIoU↑ maxF↑ mErr↓ odsF↑ ∆m↑
74.80 0.0131 650G DiffusionMTL(Feature) 133M 676G 57.78 58.98 77.82 16.11 64.50 +3.65%
DiffusionMTL(Prediction) 133M 628G 59.43 56.79 77.57 16.20 64.00 +3.23%
74.60 600G R18
0.0130 —w/oDiffusion 133M 628G 57.77 56.39 77.44 17.34 60.60 +0.11%
74.40 550G —w/oMulti-TaskCond 125M 558G 55.95 55.90 77.22 17.87 61.50 -1.33%
0.0129
500G
77 44 .. 02 00 00 .. 00 11 22 78 44 05 00 GG
R50
D D —i if f wf fu u /os si i Do on n ifM M fuT T siL L on( (F Pe ra edtu icr te i) on) 1 1 15 5 59 9 9M M
M
7 6 64 9 92 4 4G G
G
565 808 ... 197 028 56 5 81 9 .. . 69 9 91 4 7 7 77 7 6. . .0 5 67 8
4
11 1 76 7 .. . 54 3 09 1 66 6 26 3 .. . 82 8 00 0 --0 20. ..7 867 66% %%
73.80 0.0126 350G —w/oMulti-TaskCond 150M 625G 57.29 59.37 76.90 17.74 63.70 -2.91%
1 2 3 1 2 3 1 2 3
Figure6.StudyoftrainingDiffusionMTLwithvarying Table 2. Ablation study on PASCAL. “w/o Diffusion” indicates replacing the
numbersofdiffusionstepsonCityscapes. Addingdif- diffusion model with an iterative refinement model using an identical network
fusionstepsincreasestheperformanceandFLOPs. structure.“w/oMulti-TaskCond”meansremovingMulti-TaskConditioning.
PASCAL NYUD
#labels Method Semseg Parsing Saliency Normal Boundary MTLPerf Semseg Depth Normal MTLPerf
#Params FLOPS
mIoU↑ mIoU↑ maxF↑ mErr↓ odsF↑ ∆m↑ mIoU↑ absErr↓ mErr↓ ∆m↑
Single-TaskBaseline 219M 817G 50.34 59.05 77.43 16.59 64.40 - 45.28 0.4802 25.93 -
MTLBaseline 157M 608G 49.71 56.00 74.50 16.85 62.80 -2.85% 43.92 0.5138 26.44 -3.99%
SS[6] - - 45.00 54.00 61.70 16.90 62.40 - 27.52 0.6499 33.58 -
one XTC[6] - - 49.50 55.80 61.70 17.00 65.10 - 30.36 0.6088 32.08 -
XTC*[6] 173M 608G 55.08 56.72 77.06 16.93 63.70 +0.37% 43.97 0.5140 26.30 -3.79%
DiffusionMTL(Prediction) 133M 628G 59.43 56.79 77.57 16.20 64.00 +3.23% 44.97 0.5137 26.17 -2.86%
DiffusionMTL(Feature) 133M 676G 57.78 58.98 77.82 16.11 64.50 +3.65% 44.47 0.5059 25.84 -2.27%
Single-Task 219M 817G 51.51 57.90 80.30 15.24 67.80 - 48.25 0.4792 24.65 -
MTLBaseline 157M 608G 62.23 55.88 78.67 15.47 66.70 +2.44% 45.93 0.4839 25.53 -3.12%
SS[6] - - 59.00 55.80 64.00 15.90 66.90 - 29.50 0.6224 33.31 -
random XTC[6] - - 59.00 55.60 64.00 15.90 67.80 - 34.26 0.5787 31.06 -
XTC*[6] 173M 608G 62.44 55.81 78.56 15.45 66.80 +2.52% 46.03 0.4811 25.97 -3.44%
DiffusionMTL(Prediction) 133M 628G 63.68 55.84 79.87 15.38 66.80 +3.44% 47.44 0.4803 25.26 -1.45%
DiffusionMTL(Feature) 133M 676G 62.55 56.84 80.44 14.85 67.10 +4.27% 46.82 0.4743 24.75 -0.77%
Table3. Quantitativemulti-taskperformancecomparisonwiththestate-of-the-arts(SOTAs)onPASCALandNYUD.Allmodelsusea
ResNet-18asthebackbone. ‘one’meanseachtrainingimagehasonlyonelabeledtask,while‘random’meanseachtrainingimagehas
a random number of labeled tasks. The proposed DiffusionMTL, including both Prediction Diffusion and Feature Diffusion, achieves
significantlybetterperformancewhileusingfewermodelparameters.“*”denotesourre-implementedresults.
Input Semseg Parsing Saliency Normals Boundary on Saliency, while the multi-task performance ∆ is also
m
improved by +6.08%. Compared with the state-of-the-
art method XTC, our proposal achieves an improvement
of +2.86% in terms of the multi-task performance ∆ .
m
We can observe consistent performance gains under the
random-labelsetting. Similarly,undertheone-labelsetting
ofNYUD,ourFeatureDiffusionimproves∆ by+1.52% m
compared with XTC. On Cityscapes, where the one-label
Figure 7. Qualitative comparison between the state-of-the-art settingisequivalenttotherandom-labelsetting, themulti-
XTC [6] and our method on PASCAL under one-label setting. task performance ∆ is improved by +11.95% compared
m
XTCsuffersfromtheissueofnoisypredictions. Incontrast,our with the previous best XTC. For computational efficiency,
DiffusionMTLmodellearnstodenoisethenoisypredictionmaps,
as shown in Table 3, our model consumes only 133M net-
resultinginsignificantlybettermulti-taskpredictionmaps.
work parameters, which is clearly less than 173M used by
parison. (iii)“Single-Task”isasingle-tasklearningversion XTC[6]. Thesesignificantresultscanfullyshowtheeffec-
of the MTL Baseline. It contains a set of separate models tivenessoftheproposedDiffusionMTLmethod,whichsub-
whereeachmodelistrainedtolearnonlyonesingletask. stantiallyoutperformsthecompetingmethodsonallbench-
Quantitative Comparison with SOTAs We compare the markswhileusingfewermodelparameters.
proposed DiffusionMTL with several strong competitors
introduced in Sec. 4.2 on three widely-used benchmarks, Qualitative Comparison with SOTAs To examine the
i.e. Cityscapes, PASCAL, and NYUD. We show the re- quality of generated multi-task predictions by Diffusion-
sults of the three benchmarks in Table 1 and Table 3, re- MTL,wevisualizethepredictionsbyPredictionDiffusion
spectively. As can be observed from the tables, our Diffu- trained under the one-label setting of PASCAL, and com-
sionMTL demonstrates significant improvements over the pare them with the outputs of SOTA model [6] as well as
competingMTLBaselineandXTC[6]onallthreebench- ground-truth labels in Fig. 7. The images are randomly
marks. Specifically, under the challenging one-label set- chosen from the testing set of PASCAL. We observe that
ting on PASCAL, our DiffusionMTL (prediction) outper- the generated multi-task predictions of the previous best
forms the MTL Baseline by +9.72 on Semseg and +3.07 methodarenoisy,whichconfirmsourmotivationtodesigna
7
]6[
CTX
sruO
TG0.53 75.0
60 57 78 17.5 62.5 45.0 27
0.0132
0.52 74.5
50 56 76 17.0 60.0 42.5 26
55 16.5 0.51 74.0 0.0130
Semseg Parsing Saliency Normal Boundary Semseg Depth Normal Semseg Depth
(mIoU ) (mIoU ) (maxF ) (mErr ) (odsF ) (mIoU ) (absErr ) (mErr ) (mIoU ) (absErr )
PASCAL PASCAL PASCAL PASCAL PASCAL NYUD NYUD NYUD CS CS
Figure8. Performanceoftheinitialmulti-taskpredictions(blue)andthedenoisedpredictions(yellow)ofDiffusionMTL(Prediction)on
PASCAL,NYUD,andCityscapesunderone-labelsetting.Ourdenoisingnetworkimprovesthepredictionqualityofall10tasks.
Initial Decayed Denoising Step 1 Denoising Step 2 Ground-Truth self-attention blocks. This variant is indicated as “w/o
Multi-TaskCond”. Multi-taskconditioningleadstosignifi-
cantimprovementonalltasks,underscoringtheuniqueim-
portanceofmulti-taskinformationsharinginthepartially-
labeledmulti-tasklearningproblem.
Comparison of Feature Diffusion and Prediction Dif-
fusion As observed in Table 2, both multi-task diffusion
mechanisms show significant multi-task performance on
different backbones. Prediction Diffusion is more compu-
tationallyefficientduetothelowerdimensionsoftheinter-
mediate maps, whereas Feature Diffusion achieves higher
performanceonmosttasksbycapturingmorevisualinfor-
mationinthefeatures.
QualitativeAnalysisofDenoisingEffectInthedenoising
process, the model is designed to denoise the noisy multi-
Figure 9. Visualization of the prediction maps at different pro- taskpredictionmapsthataredegradedbythediffusionpro-
cesses on PASCAL. Our DiffusionMTL can denoise and rectify cess. ToevaluatethedenoisingperformanceofourPredic-
thenoisymulti-taskpredictionmaps. tion Diffusion, we provide visualizations of the multi-task
predictionmapsatdifferentphasesinFig.5andFig.9. Our
multi-taskdenoisingframeworkforthemulti-taskpartially
model generates clean and accurate multi-task prediction
supervisedlearningproblem. WiththeproposedDiffusion-
maps from noisy inputs, which firmly indicates the effec-
MTL,thepredictionqualityissignificantlyimproved.
tivenessofourmulti-taskdenoisingframework.
4.3.AblationStudy InfluenceofDiffusionStepsWeplottheperformancemet-
ricsagainstdiffusionstepsonCityscapesinFig.6. Ourob-
We conduct comprehensive ablation experiments to evalu-
servationsrevealthatutilizingtwostepsyieldsanotableim-
ate the effectivenessof different components of Diffusion-
provementinperformancecomparedtousingjustonestep.
MTLformulti-taskpartiallysupervisedlearningandshow
Moreover,increasingthenumberofstepsfurtherenhances
theresultsonPASCALone-labelsettinginTable2.
performance, albeitatahighercomputationalcost. There-
Effectiveness of Multi-Task Denoising Diffusion Net-
fore,wesetthedefaultnumberofstepstotwo.
work To further confirm the effectiveness of the proposed
multi-task denoising diffusion network (MTDNet), we re-
place it with an iterative refinement network using an 5.Conclusion
identicalnetworkstructure(i.e.cross-attentiontransformer
blocks in Prediction Diffusion). This variant is denoted as Our study aims to address the issue of noisy predictions
“w/o Diffusion” in Table 2. MTDNet brings a significant in multi-task learning from partially annotated data. We
multi-taskperformanceimprovementof+3.12(ResNet-18) proposeaunifiedmulti-taskdenoisingdiffusionframework
and+2.20(ResNet-50)usingthesamecomputationalcosts, that refines multi-task signals in the feature and prediction
which clearly validates the effectiveness of the proposed spaces separately. Additionally, we introduce an effective
multi-task denoising method. Moreover, we plot the per- Multi-TaskConditioningstrategytoenhancedenoisingper-
formancemetricsofinitialpredictionsandfinalpredictions formanceandfacilitatelearningofunlabelledtasksthrough
in Fig. 8, which shows improvement brought by MTDNet cross-task information sharing. Extensive experiments on
onall10tasksofthreebenchmarks. three prevalent datasets validate our approach, which out-
EffectivenessofMulti-TaskConditioningToevaluatethe performspreviousmethodsbyasignificantmargin.
efficacy of the multi-task conditioning strategy, we con- AcknowledgementThisresearchispartiallysupportedby
duct ablation experiments by removing it from Diffusion- the Early Career Scheme of the Research Grants Council
MTL(Prediction)andreplacingcross-attentionblockswith (RGC)oftheHongKongSARundergrantNo. 26202321.
8References [18] David Bruggemann, Menelaos Kanakis, Anton Obukhov,
Stamatios Georgoulis, and Luc Van Gool. Exploring re-
[1] Kevis-Kokitsi Maninis, Ilija Radosavovic, and Iasonas
lational context for multi-task dense prediction. In ICCV,
Kokkinos. Attentive single-tasking of multiple tasks. In
2021. 2
CVPR,2019. 1,2,6
[19] Siwei Yang, Hanrong Ye, and Dan Xu. Contrastive multi-
[2] AmirRZamir,AlexanderSax,NikhilCheerla,RohanSuri, taskdenseprediction. InAAAI,2023. 2
ZhangjieCao,JitendraMalik,andLeonidasJGuibas. Ro-
[20] ShikunLiu,StephenJames,AndrewJDavison,andEdward
bustlearningthroughcross-taskconsistency.InCVPR,2020.
Johns. Auto-lambda: Disentanglingdynamictaskrelation-
2
ships. TMLR,2022.
[3] Iasonas Kokkinos. Ubernet: Training a universal convolu- [21] Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task
tional neural network for low-, mid-, and high-level vision learningusinguncertaintytoweighlossesforscenegeome-
usingdiversedatasetsandlimitedmemory. InCVPR,2017. tryandsemantics. InCVPR,2018. 2
2 [22] BoLiu, XingchaoLiu, XiaojieJin, PeterStone, andQiang
[4] Dan Xu, Wanli Ouyang, Xiaogang Wang, and Nicu Sebe. Liu.Conflict-aversegradientdescentformulti-tasklearning.
Pad-net: Multi-tasks guided prediction-and-distillation net- InNeurIPS,2021. 2
work for simultaneous depth estimation and scene parsing. [23] Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong,
InCVPR,2018. 1,2,3 HenrikKretzschmar,YuningChai,andDragomirAnguelov.
[5] Simon Vandenhende, Stamatios Georgoulis, Wouter Justpickasign:Optimizingdeepmultitaskmodelswithgra-
Van Gansbeke, Marc Proesmans, Dengxin Dai, and Luc dientsigndropout. InNeurIPS,2020.
VanGool. Multi-tasklearningfordensepredictiontasks: A [24] Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and An-
survey. TPAMI,44(7):3614–3633,2021. 1,2 drew Rabinovich. Gradnorm: Gradient normalization for
[6] Wei-HongLi,XialeiLiu,andHakanBilen. Learningmulti- adaptivelossbalancingindeepmultitasknetworks.InICML,
pledensepredictiontasksfrompartiallyannotateddata. In 2018.
CVPR,2022. 1,2,6,7,11,12,15,16,17,18 [25] Zirui Wang, Yulia Tsvetkov, Orhan Firat, and Yuan Cao.
[7] JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffu- Gradient vaccine: Investigating and improving multi-task
sionprobabilisticmodels. InNeurIPS,2020. 2,3,4 optimization in massively multilingual models. In ICLR,
[8] PrafullaDhariwalandAlexanderNichol. Diffusionmodels 2020.
beatgansonimagesynthesis. InNeurIPS,2021. 2,3,5 [26] TianheYu,SaurabhKumar,AbhishekGupta,SergeyLevine,
Karol Hausman, and Chelsea Finn. Gradient surgery for
[9] IshanMisra,AbhinavShrivastava,AbhinavGupta,andMar-
multi-tasklearning. InNeurIPS,2020. 2
tialHebert. Cross-stitchnetworksformulti-tasklearning. In
[27] Hanrong Ye and Dan Xu. Taskprompter: Spatial-channel
CVPR,2016. 2
multi-task prompting for dense scene understanding. In
[10] ShikunLiu,EdwardJohns,andAndrewJDavison. End-to-
ICLR,2023. 2
endmulti-tasklearningwithattention. InCVPR,2019. 6
[28] RomanBachmann,DavidMizrahi,AndreiAtanov,andAmir
[11] YuZhangandQiangYang. Asurveyonmulti-tasklearning.
Zamir. Multimae: Multi-modal multi-task masked autoen-
TKDE,2021.
coders. InECCV,2022.
[12] Amir R Zamir, Alexander Sax, William Shen, Leonidas J
[29] Yangyang Xu, Xiangtai Li, Haobo Yuan, Yibo Yang, and
Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy:
Lefei Zhang. Multi-task learning with multi-query trans-
Disentanglingtasktransferlearning. InCVPR,2018.
formerfordenseprediction. TCSVT,2023.
[13] Menelaos Kanakis, Thomas E Huang, David Bru¨ggemann,
[30] HanrongYeandDanXu. Taskexpert: Dynamicallyassem-
FisherYu,andLucVanGool.Compositelearningforrobust
bling multi-task representations with memorial mixture-of-
andeffectivedensepredictions. InWACV,2023.
experts. InICCV,2023.
[14] HanxueLiang,ZhiwenFan,RishovSarkar,ZiyuJiang,Tian- [31] Xiaogang Xu, Hengshuang Zhao, Vibhav Vineet, Ser-Nam
longChen,KaiZou,YuCheng,CongHao,andZhangyang Lim,andAntonioTorralba. Mtformer: Multi-tasklearning
Wang. M3vit:Mixture-of-expertsvisiontransformerforef- viatransformerandcross-taskreasoning. InECCV,2022.
ficientmulti-tasklearningwithmodel-acceleratorco-design. [32] HanrongYeandDanXu. Invertedpyramidmulti-tasktrans-
InNeurIPS,2022. formerfordensesceneunderstanding. InECCV,2022. 3,
[15] Zitian Chen, Yikang Shen, Mingyu Ding, Zhenfang Chen, 11
Hengshuang Zhao, Erik Learned-Miller, and Chuang Gan. [33] HanrongYeandDanXu. Invpt++: Invertedpyramidmulti-
Mod-squad:Designingmixtureofexpertsasmodularmulti- task transformer for visual scene understanding. arXiv
tasklearners. arXivpreprintarXiv:2212.08066,2022. preprintarXiv:2306.04842,2023.
[16] Lukas Hoyer, Dengxin Dai, Yuhua Chen, Adrian Koring, [34] Wei-HongLi,XialeiLiu,andHakanBilen. Universalrepre-
SumanSaha,andLucVanGool. Threewaystoimprovese- sentations:Aunifiedlookatmultipletaskanddomainlearn-
manticsegmentationwithself-superviseddepthestimation. ing. arXivpreprintarXiv:2204.02744,2022.
InCVPR,2021. 2 [35] Yuan Gao, Jiayi Ma, Mingbo Zhao, Wei Liu, and Alan L
[17] Simon Vandenhende, Stamatios Georgoulis, and Luc Yuille. Nddr-cnn: Layerwise feature fusing in multi-task
Van Gool. Mti-net: Multi-scale task interaction networks cnns by neural discriminative dimensionality reduction. In
formulti-tasklearning. InECCV,2020. 2,3,11 CVPR,2019.
9[36] YuanGao, HaopingBai, ZequnJie, JiayiMa, KuiJia, and [53] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.
WeiLiu. Mtl-nas: Task-agnosticneuralarchitecturesearch Deep residual learning for image recognition. In CVPR,
towards general-purpose multi-task learning. In CVPR, 2016. 6
2020.
[37] LijunZhang,XiaoLiu,andHuiGuan.Automtl:Aprogram-
mingframeworkforautomatingefficientmulti-tasklearning.
InNeurIPS,2021. 2
[38] JaschaSohl-Dickstein, EricWeiss, NiruMaheswaranathan,
and Surya Ganguli. Deep unsupervised learning using
nonequilibriumthermodynamics. InICML,2015. 3
[39] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan
Ho. Variationaldiffusionmodels. NeurIPS,2021. 3
[40] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
PatrickEsser,andBjo¨rnOmmer.High-resolutionimagesyn-
thesiswithlatentdiffusionmodels. InCVPR,2022.
[41] WilliamPeeblesandSainingXie. Scalablediffusionmodels
withtransformers. arXivpreprintarXiv:2212.09748,2022.
3
[42] XizewenHan,HuangjieZheng,andMingyuanZhou. Card:
Classification and regression diffusion models. arXiv
preprintarXiv:2206.07275,2022. 3
[43] Dmitry Baranchuk, Ivan Rubachev, Andrey Voynov,
ValentinKhrulkov,andArtemBabenko. Label-efficientse-
manticsegmentationwithdiffusionmodels. InICLR,2022.
3
[44] Tomer Amit, Eliya Nachmani, Tal Shaharbany, and Lior
Wolf. Segdiff: Image segmentation with diffusion proba-
bilisticmodels. arXivpreprintarXiv:2112.00390,2021.
[45] Ting Chen, Lala Li, Saurabh Saxena, Geoffrey Hinton,
and David J Fleet. A generalist framework for panop-
tic segmentation of images and videos. arXiv preprint
arXiv:2210.06366,2022.
[46] Zhangxuan Gu, Haoxing Chen, Zhuoer Xu, Jun Lan,
Changhua Meng, and Weiqiang Wang. Diffusioninst: Dif-
fusion model for instance segmentation. arXiv preprint
arXiv:2212.02773,2022.
[47] Hanrong Ye, Jason Kuen, Qing Liu, Zhe Lin, Brian Price,
and Dan Xu. Seggen: Supercharging segmentation mod-
elswithtext2maskandmask2imgsynthesis. arXivpreprint
arXiv:2311.03355,2023. 3
[48] ShoufaChen,PeizeSun,YibingSong,andPingLuo. Diffu-
siondet:Diffusionmodelforobjectdetection.arXivpreprint
arXiv:2211.09788,2022. 3
[49] AshishVaswani,NoamShazeer,NikiParmar,JakobUszko-
reit,LlionJones,AidanNGomez,ŁukaszKaiser,andIllia
Polosukhin. Attentionisallyouneed. InNeurIPS,2017. 5
[50] MarkEveringham,LucVanGool,ChristopherKIWilliams,
JohnWinn,andAndrewZisserman.Thepascalvisualobject
classes(voc)challenge. IJCV,111:98–136,2010. 6,11
[51] NathanSilberman,DerekHoiem,PushmeetKohli,andRob
Fergus. Indoor segmentation and support inference from
rgbdimages. InECCV,2012. 6,11
[52] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo
Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe
Franke, Stefan Roth, and Bernt Schiele. The cityscapes
datasetforsemanticurbansceneunderstanding. InCVPR,
2016. 6,11
10A.SupplementalImplementationDetails Method #ParamsFLOPSGPT Ura Min emS me Im oUse ↑gP ma Ir os Uin ↑gS ma ali xe Fnc ↑yN mo Er rm ra ↓lBo ou dn sFda ↑ryMT ∆L mP ↑erf
MTLBaseline 157M 608G 6163M 49.71 56.00 74.50 16.85 62.80 -2.85%
A.1.AdditionalDetailsaboutDiffusionMTL XTC[6] 173M 608G 6409M 55.08 56.72 77.06 16.93 63.70 +0.37%
MTINet[17] 281M 589G 11533M 54.32 57.73 77.12 16.41 64.20 +1.21%
InvPT[32] 141M 1182G 9993M 56.96 57.05 77.19 16.80 63.20 +1.27%
Multi-Task Denoising Diffusion Network. This section D Di if ff fu us si io on nM MT TL L( (P Fr ee ad tuic rt ei )on) 1 13 33 3M M 6 62 78 6G G 5 57 80 13 1M M 55 79 .. 74 83 5 56 8. .7 99 8 7 77 7. .5 87 2 1 16 6. .2 10 1 6 64 4. .0 50 0 ++ 33 .. 62 53 %%
providesadditionaldetailsabouttheimplementationofDif- Table4.One-labelsettingonPASCALwithResNet-18backbone.
fusionMTL on different datasets. For our experiments,
includerandomcroppingandrandomhorizontalflipping.
we set the default diffusion steps to 2 using a linear vari-
ance scheduler with a range from 10−3 to 10−2. All self- B.AdditionalQuantitativeStudy
attentionblocksintheDenoiseruseasinglehead.
Loss functions. For semantic segmentation, human pars- B.1.ComparisonwithSOTArefinementmethods.
ing, saliency detection, and boundary detection, we use
Weconductextensiveexperimentstocompareourproposal
cross-entropy loss. For depth and surface normal estima-
with previous SOTA MTL refinement methods, including
tion,weoptforL1loss.Themulti-tasklossbalanceweights
MTI-Net[17]andInvPT[32],basedontheResNet-18base-
arethesameasthoseusedin[6].
line under the one-label setting on PASCAL dataset. The
results,presentedinTable4,demonstratethesuperiorper-
A.2.ImplementationDetailsonDifferentDatasets
formanceofDiffusionMTLacrossalltasks.
For all three partial-labeling benchmarks (PASCAL,
B.2.ComparisonunderFully-AnnotatedSetting
NYUD, and Cityscapes), we use exactly the same image-
tasklabelmappingsasthoseusedin[6].
Our method can be applied to fully-annotated bench-
PASCALOnPASCAL-Context[50](abbreviatedas“PAS- marks. We conduct experiments on fully-annotated PAS-
CAL”),intheone-labelsetting, thereare1000, 999, 1000, CAL dataset using ResNet-18 and show the results in Ta-
1000, 999imagesseparatelylabeledforsemanticsegmen- ble 5. Our method demonstrates stronger performance
tation, human parsing, surface normal estimation, saliency compared to both the baseline as well as the state-of-the-
detection,andboundarydetection. Intherandom-labelset- art(SOTA)methodXTC[6]andInvPT[32].
ting,thereare450,2553,2480,2445,and2557imagesla-
beled for semantic segmentation, human parsing, surface Semseg Parsing Saliency Normal Boundary MTLPerf
Method #Params FLOPS
normalestimation,saliencydetection,andboundarydetec-
mIoU↑ mIoU↑ maxF↑ mErr↓ odsF↑ ∆m↑
STLBaseline 219M 817G 52.56 62.21 82.75 14.12 68.90 -
tion, respectively, We pad the images to a resolution of MTLBaseline 157M 608G 62.91 57.37 81.82 14.49 66.40 +0.90%
XTC[6] 173M 608G 63.29 57.93 82.09 14.48 66.50 +1.34%
512×512. We use the Adam optimizer and a polynomial InvPT[32] 141M 1182G 64.38 59.49 83.52 14.75 66.80 +2.31%
DiffusionMTL(Prediction) 133M 628G 64.31 58.68 83.07 14.44 67.10 +2.44%
learningrateschedulerwithabaselearningrateof2×10−5. DiffusionMTL(Feature) 133M 676G 64.62 60.14 83.99 14.17 67.80 +3.84%
All models are trained for 100 epochs with a batch size of Table5.Fully-annotatedsettingonPASCALwithResNet-18.
6. Weadoptthesamedataaugmentationsasin[17],which
B.3.ComputationandMemoryCostComparison.
include random scaling, cropping, random horizontal flip-
ping,andcolorjittering. We have already shown the parameters and FLOPs com-
NYUD [51] In the one-label setting, 265 images are la- parisonwiththeMTLbaselineandXTCinTable3ofour
beledforsemanticsegmentation,265imagesarelabeledfor mainpaper. WefurtherprovidethetrainingGPUmemory
monoculardepthestimation,and265imagesarelabeledfor inTable4ofthisdocument. Ourmethodshowshigherpa-
surfacenormalestimation.Intherandom-labelsetting,392, rameter/memory efficiency and comparable computational
408,and385imagesarerespectivelylabeledforthesetasks. costswithsignificantlybetterperformance.
Theimagesareresizedtoaresolutionof288×384.Weuse
theAdamoptimizerandapolynomiallearningratesched- C.AdditionalQualitativeStudy
ulerwithabaselearningrateof2×10−5. Allmodelsare
C.1.DenoisingEffectivenessofDiffusionMTL
trainedfor200epochswithabatchsizeof4. Weadoptthe
same data augmentations as in [6], which include random To assess the denoising performance of our model, we vi-
croppingandrandomhorizontalflipping. suallyexaminethenoisymulti-taskpredictionmapsgener-
Cityscapes [52] As we only evaluate two tasks on the atedthroughthediffusionprocess, aswellasthedenoised
Cityscapesdataset,theone-labelsettingisequivalenttothe outputsproducedbyPredictionDiffusionbasedonResNet-
random-label setting. The training split contains 1,487 la- 18onCityscapesdatasetunderaone-labeltrainingsetting.
beledimagesforsemanticsegmentationand1,488labeled TheobtainedresultsareshowcasedinFig.10andFig.11.
imagesformonoculardepthestimation. Weadoptalearn- TheeffectivenessofourproposedDiffusionMTLisdemon-
ingrateof10−4.Allmodelsaretrainedfor200epochswith strated by its ability to successfully denoise the noisy pre-
abatchsizeof8. Theimagesareresizedtoaresolutionof dictionmaps,resultinginsignificantlyimprovedmulti-task
128×256. Weadoptthedataaugmentationsin[6],which predictions that align better with the ground-truth labels.
11These results serve as additional validation for our moti-
vation behind designing a robust multi-task denoising dif-
fusionframework,addressingthechallengesinherentinthe
multi-taskpartiallysupervisedlearningproblem.
C.2.ComparisonwithSOTA
Inordertofurtherdemonstratetheperformanceadvantage
of DiffusionMTL, we present a set of randomly selected
samplesgeneratedbyourmodelandthepreviousstate-of-
the-art model (i.e., XTC [6]) on Cityscapes in Fig. 12 and
Fig. 13. We further compare the results on PASCAL in
Fig. 14 and Fig. 15. These models are trained under the
sameone-labelmulti-taskpartiallysupervisedlearningset-
ting. ThesuperiorityofpredictionmapsgeneratedbyDif-
fusionMTLintermsofaccuracyisevidentonbothdatasets.
This compelling evidence serves to further validate the ef-
fectivenessofourproposeddenoisingdiffusionmodel.
12Initial
Decayed
Denoised
Ground-
Truth
Initial
Decayed
Denoised
Ground-
Truth
Figure10. Qualitativecomparisonoftheinitialmulti-taskpredictions,decayedpredictions,ourdenoisedresults,andground-truthlabels
onCityscapesunderone-labelsetting. OurDiffusionMTLisabletorectifynoisyinputandgeneratecleanpredictionmaps. Themodel
usedinthiscomparisonistrainedontheCityscapesdatasetundertheone-labelMTPSLsetting.
13Initial
Decayed
Denoised
Ground-
Truth
Initial
Decayed
Denoised
Ground-
Truth
Figure11. Qualitativecomparisonoftheinitialmulti-taskpredictions,decayedpredictions,ourdenoisedresults,andground-truthlabels
onCityscapesunderone-labelsetting. OurDiffusionMTLisabletorectifynoisyinputandgeneratecleanpredictionmaps. Themodel
usedinthiscomparisonistrainedontheCityscapesdatasetundertheone-labelMTPSLsetting.
14XTC
Ours
GT
XTC
Ours
GT
XTC
Ours
GT
Figure12. Qualitativecomparisonbetweenourmethodandthestate-of-the-artmethod(i.e.XTC[6])fordepthestimationandsemantic
segmentation tasks in Cityscapes dataset, using the same ResNet-18 backbone. Our DiffusionMTL approach outperforms the previous
state-of-the-artmethodinproducingsuperiorpredictionmaps.Notably,eachtrainingsampleislabeledforonlyonetask.
15XTC
Ours
GT
XTC
Ours
GT
XTC
Ours
GT
Figure13. Qualitativecomparisonbetweenourmethodandthestate-of-the-artmethod(i.e.XTC[6])fordepthestimationandsemantic
segmentationtasksontheCityscapesdataset,usingthesameResNet-18backbone.OurDiffusionMTLapproachoutperformstheprevious
state-of-the-artmethodinproducingsuperiorpredictionmaps.Notably,eachtrainingsampleislabeledforonlyonetask.
16Input Semseg Parsing Saliency Normals Boundary
XTC
Ours
GT
XTC
Ours
GT
XTC
Ours
GT
XTC
Ours
GT
Figure14.Qualitativecomparisonbetweenourmethodandthestate-of-the-artmethod(i.e.XTC[6])inPASCALdataset,usingthesame
ResNet-18 backbone. Our DiffusionMTL approach outperforms the previous state-of-the-art method in producing superior prediction
maps.Notably,eachtrainingsampleislabeledforonlyonetask.
17Input Semseg Parsing Saliency Normals Boundary
XTC
Ours
GT
XTC
Ours
GT
XTC
Ours
GT
XTC
Ours
GT
Figure15.Qualitativecomparisonbetweenourmethodandthestate-of-the-artmethod(i.e.XTC[6])inPASCALdataset,usingthesame
ResNet-18 backbone. Our DiffusionMTL approach outperforms the previous state-of-the-art method in producing superior prediction
maps.Notably,eachtrainingsampleislabeledforonlyonetask.
18