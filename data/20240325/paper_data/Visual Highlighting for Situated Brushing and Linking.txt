EurographicsConferenceonVisualization(EuroVis)2024 COMPUTERGRAPHICSforum
W.Aigner,D.Archambault,andR.Bujack Volume43(2024),Number3
(GuestEditors)
Visual Highlighting for Situated Brushing and Linking
NinaDoerr ,BenjaminLee ,KatarinaBaricova ,DieterSchmalstieg ,MichaelSedlmair
UniversityofStuttgart,Germany
Color Overview of VR environment Links
Outline Arrow
Figure1:Inouruserstudy,wepresentavirtualsupermarketwithfourhighlightingtechniques.Center:First-personviewofthesupermarket
whilebrushingascatterplot,withproductsontheshelveshighlighted.Topleft:TheColortechnique.Bottomleft:TheOutlinetechnique.
Topright:TheLinktechniquewithproductsbehindthecameraselected.Bottomright:StillimageoftheArrowtechnique.
Abstract
Brushingandlinkingiswidelyusedforvisualanalyticsindesktopenvironments.However,usingthisapproachtolinkmany
data items between situated (e.g., a virtual screen with data) and embedded views (e.g., highlighted objects in the physical
environment)islargelyunexplored.Tothisend,westudytheeffectivenessofvisualhighlightingtechniquesinhelpingusers
identifyandlinkphysicalreferentstobrusheddatamarksinasituatedscatterplot.Inanexploratoryvirtualrealityuserstudy
(N=20),weevaluatedfourhighlightingtechniquesunderdifferentphysicallayoutsandtasks.Wediscusstheeffectivenessof
thesetechniques,aswellasimplicationsforthedesignofbrushingandlinkingoperationsinsituatedanalytics.
CCSConcepts
•Human-centeredcomputing → Empiricalstudiesinvisualization;EmpiricalstudiesinHCI;Informationvisualization;
1. Introduction store having its own embedded visualization. While this scenario
Situatedanalytics(SitA)involvestheuseofsituatedvisualizations works well for products in view, it does not scale well to prod-
[WF09]toimprovesense-makinginphysicalcontexts[ETM∗15, ucts outside of one’s view. Even with out-of-view labeling tech-
TWD∗18].Itisfacilitatedpredominantlybytheuseofaugmented niques[GLH∗18,LYBP23],thecustomerinone-to-oneconfigura-
reality (AR) [BKT∗22]. Willett et al. [WJD17] distinguish visu- tion would still need to look at and interpret the visualization of
alizationsdirectlyembeddedwithoneparticularphysicalreferent eachindividualproduct[LSS23].Theissueisexacerbatedbythe
fromsituatedvisualizationsthatindirectlylinktoareferentorthe smallfieldofview(FOV)ofcurrentstate-of-the-artARheadsets.
entire environment. Shin et al. [SBB∗23] note that most current Situated visualizations that are presented independently of in-
SitAtoolsusethereferentasatriggertoinstantiateandmodifyvi- dividual referents can naturally consolidate the data pertaining to
sualizations.Forinstance,scannerapplicationsaugmentreal-world many referents in one view or dashboard [MM21,SLQS23]. In-
objectswithadditionalinformationastheycomeintoview.SitAis steadoflookingatmultipleembeddedvisualizations,asinglesit-
thereforereliantontheuser’sviewpointandinteractionswiththe uated overview visualization can be looked at instead. However,
realworldtodeterminewhatinformationtodisplay. shouldthetaskrequiretheidentificationorphysicalmanipulation
of referents (e.g., when shopping), then supporting the transition
Although this “physical world first” approach feels natural in
between a situated visualization of all referents to an individual-
the context of AR, it is inherently constrained in situations with
ized,embeddedviewofspecificreferentsisrequired[WJD17].
many physical referents or referents that are spread far apart
[LSS23]. Consider the classic supermarket scenario introduced We postulate that this problem is functionally equivalent to
by ElSayed et al. [ETM∗16], which features each product in the brushing and linking, a fundamental technique in visual analyt-
©2024TheAuthors.ComputerGraphicsForumpublishedbyEurographics-TheEuropeanAsso-
ciationforComputerGraphicsandJohnWiley&SonsLtd.
ThisisanopenaccessarticleunderthetermsoftheCreativeCommonsAttributionLicense,which
permitsuse,distributionandreproductioninanymedium,providedtheoriginalworkisproperly
cited.
4202
raM
22
]CH.sc[
1v12351.3042:viXra2of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
ics [Rob07]. Selections made in the situated visualization must et al. [KSF10] list several challenges related to visual perception
bevisuallylinkedtothecorrespondingphysicalreferents.Linking in AR which are caused by the environment, image capture, dis-
thereforeservesbothanalytic(makingselectionsbasedoncertain play,andvisualrepresentation.Satkowskietal.[SD21]studyhow
criteria)andperceptualpurposes(findingandlocatingobjects). thereal-worldbackgroundaffectsperceptioninAR,andAssoret
al.[APHD24]proposeadesignspaceofhowtohandlenon-visible
In this paper, we explore multiple techniques to visually high-
physical referents. Similarly, AR must always consider the inter-
lightphysicalreferentsinthecontextofbrushingandlinking.We
playofvisualrepresentationwiththeexistingandimmutableap-
focusonthelinkingbetweenasituatedvisualizationanditsphysi-
pearance of the real world. Therefore, any visualization pipeline
calreferent,ratherthantheinteractionsusedtoperformthebrush-
targetingARneedstodealwiththefusionofrealandvirtualvisual
ing,asitisthevisuallinkingthatfundamentallyfacilitatesthetran-
attributes[ZLG∗21].Addressingthesechallengesrequiresawide
sitionbetweenviews.Whileexistingworkhasinvestigatedmany
rangeofvisualencodingmethods[SH16,chapter7].
waystohighlightandguideattentionin3Denvironments(seeSec-
tion2),tothebestofourknowledge,nonehaveexploredhighlight-
2.2. Brushingandlinking
ingforbrushingandlinkinginSitA.Weselectedfourhighlighting
Oneofthecoretopicsofthispaperisbrushingandlinking[Rob07],
techniques known from either traditional brushing and linking or
which is the process of locating the corresponding items of in-
attention guidance in AR/VR. We conducted an exploratory user
terestinmultipleviews.Fundamentally,itcomprisestwosequen-
study(N=20),usingasupermarketscenario.Thestudywascarried
tialstages,whereinselectionsmadeinonevisualization(brushing)
outinvirtualreality(VR)toavoidhardwareandtrackinglimita-
areautomaticallyshowninanothervisualization(linking)[Kei02].
tionsofcurrentARdevices.Insummary,wecontribute:
Muchresearchhasfocusedonthebrushingcomponent,investigat-
• Anopen-sourceVRprototypedemonstratingtheuseofbrushing inginteractiontechniquestosupporttheeffectiveselectionofdata
andlinkinginasituatedanalyticsscenario pointsindesktopcomputing[KPV∗18].
• Anexploratoryuserstudythatseekstocompare,evaluate,and
In immersive analytics, brushing and linking have seen (ar-
understandfourcommonhighlightingtechniques
guably limited) use, be it to compare multiple immersive coordi-
• Observations and lessons learned for the application of high-
natedviews[AWG∗15,LPED20]ortosupportcollaborativeaware-
lightingtechniquesinsituatedbrushingandlinkingcontexts
ness[LHC∗21,SBDE23,SS22].Mostmethodsusesimple3Dse-
lection techniques (e.g., raycasting) or pure 2D selection tech-
2. Relatedwork
niques (e.g., touchscreen inputs). While we do not propose new
First, we consider situated analytics (Section 2.1) and, second,
brushinginteractiontechniques,wearethefirst(tothebestofour
brushing and linking (Section 2.2) and its use in immersive and
knowledge) to explore brushing and linking in a SitA context—
situatedenvironments.Aswefocusonthelinkingcomponent,we
particularlywhenusingphysicalreferentsasacoordinatedview.
alsodiscussattentionguidanceinARandVR(Section2.3).
2.3. Attentionguidanceinaugmentedandvirtualreality
2.1. Immersiveandsituatedanalytics
InSitA,weassumethatthelinkingcomponenttargetsviewsand
Immersivetechnologies,bothVRandAR,areincreasinglybeing
referentsintherealworld.Hence,itcanbedescribedasavisual
usedforimmersiveanalytics[MSD∗18]ofspatialdata[FP21]and
searchtaskfortargetobjectsinanARdisplay.Notethatthiswork
abstractdata[KFS∗22].Researchhasshownhowthe3Denviron-
considers attention guidance as a means to support visual search
ment can be used as an “immersive space to think” [LDG∗21],
andidentification,andnotasinstructionalcuesformovementtrain-
populating this space with multiple views and representa- ing[YLS24]orassemblytasks[PZB∗23].Wolfeetal.[WVEG11]
tions[RBR22].However,caremustbetakentoconsiderthepitfalls
characterizevisualsearchasthetaskofvisuallyidentifyingatarget
ofdesigningforimmersivedisplays[ML14].DesignersofVRin-
amongother,irrelevantobjects(distractors).Iftherearetoomany
terfacesforanalyticsmusttakeintoaccountthecharacteristicsof
distractors,anaivevisualsearchbecomesinefficient[Ver02].We
VR displays that differ from desktop computing, such as stereo-
mustthereforeensurethatthevisualsearchistolerantofclutterand
scopicdepth,angularresolution,fieldofview,orfatiguerelatedto
occlusion,sincewecannotchangetherealworld.Thereshouldbe
physicalnavigationandinteraction[LKM∗17].
sufficient contrast and legibility between real and virtual objects.
RecentworkconsidersimmersiveanalyticstechniqueswithAR Wehavetobeabletodirectauser’sattentiontotherelevantob-
in physical environments, a new direction referred to as situated jects,inparticular,iftheseareoutofview.
analytics(SitA)[ETM∗15,ETM∗16].SitAischaracterizedbythe
According to Cockburn et al. [CKB09], conventional InfoVis
ability to perform higher-level analytical reasoning aided by the
methodstoguidevisualattentionandsearch,suchasoverview+
user’sphysicalenvironment[SBB∗23],particularlywhenthereis
detailorfocus+context,occupyalotofscreenspaceastheyen-
a semantic relationship between the data and its physical refer-
largeobjectsorintroducereplicasofdifferentsizes.Asamajoral-
ents[WF09,WJD17].Whileresearchhasinvestigatedhowsituated
ternative,theymentioncue-basedapproaches,whichmodifyobject
visualizationscanbedesignedforSitA[LSS23,SBB∗23],consid-
renderingstyles.Linetal.[LYBP23]notethatsuchcuesarepre-
ering human perception to leverage efficient visual processing—
ferredinAR,sinceresizingorduplicatingoccupiestoomuchofthe
particularlyinsituatedcontexts—isagrandchallenge[EBC∗21].
naturalviewspace.Thesecue-basedtechniquesforhighlightingfo-
DesignersofSitAsystems(andARinterfacesingeneral)must calobjectscanselectfromavarietyofrenderingattributes.Abase-
handle the additional constraint that visual representations can- lineisformedbyhighlights,whichemphasizeatargetbymodify-
not always be positioned on a “clean slate” background. Kruijff ingitscolorthroughoutthetargetareaorasanoutline[KPV∗18].
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking 3of14
In immersive displays, several more sophisticated tech- buildingfaçadewithwindowsasreferents[TOK∗16].Webuiltthe
niques have been proposed to ensure that a given contrast is supermarket using VR as a kind of information-rich virtual envi-
achieved[GAM18,KVZ∗13].Contrastmodulation,evenbelowa ronment [BNC∗03,PKB05], serving as a simulated test environ-
detectablethreshold[VMFS11],canpre-attentivelyguidetheuser. ment that can be carefully controlled and replicated [RWBH09].
Otherattributesthatcanbemodifiedtohighlightorattractatten- WhileusingARwouldbemoreecologicallyvalid,theuseofVR
tionincludespatialfrequencies(i.e.,focusorblur)[KMH01],stere- avoidsthetechnicalchallengesoftrackingeachproduct[CFSS23]
oscopy[KCWK20],ortemporalfrequencies[LSGB20]. or logistical challenges of renting or building a store. Previous
work also suggested that findings in AR can be replicated in VR
Cockburn et al. [CKB09] further mention proxies as cues.
[GCOK21,LBHB09,LBBH10,LRM∗13],whichfurthermotivates
Arrow-shapedproxiesarecommonlyusedinAR[GLH∗18,TK06],
andvalidatesouruseofasimulatedsupermarketinVR.
mostlikelybecausetheyaresimpletosynthesizeandeasytoun-
derstand. Naturally, proxies are a popular means to guide toward
out-of-viewtargets.Inadditiontoarrows,variouspopularshapes 3.2. Highlightingtechniques
includehalos[BR03],funnels[BTOX06],compass-like[SL00]or Weimplementedfourdifferenthighlightingtechniquesinourpro-
radar-like widgets [JHPR11], and lines or trajectories [PLE∗19]. totype.Thesetechniquesareusedinconjunctionwiththeaccom-
PreviousworkalsocomparestheeffectofvariousvisualcuesinVR panying brushing component, which is described in Section 3.3.
andAR.Severalauthors[BSEN18,KKO∗14,TEM∗19,WGRF22]
Example images of all four techniques can be seen in Figure 1.
investigate the performance differences of visual search with re- Notethatalltechniquesuseasolidyellowcolorwhererelevantin
specttothefieldofviewofthedisplay.Otherstudiescomparemul- ordertoensureaconsistentappearanceacrossconditions.
tipleattentionguidance(i.e.,highlighting)techniqueswithrespect
totheeffectivenessandpreservationofimmersion[LSGB20],the Colorislikelythedefactohighlightingtechniqueusedinregu-
effectiveness of multimodal cues [MTE∗20], or the influence of larbrushingandlinking[KPV∗18,Rob07].Itmainlybenefitsfrom
stationary and moving distractors [DARS23]. Moreover, our se- thepre-attentive“popout”effect,particularlywhenthenewcolor
lection of techniques was influenced by the work of Whitlock et highly contrasts with the background. Hence, we incorporate it
al.[WSS20]ontheperceptionoffundamentalgraphicalattributes into our prototype, changing the color of the product to a solid
inimmersiveanalytics.However,noneoftheseworksinvestigate yellowwhenselected.Whilewehadinitiallytriedtouseasemi-
theuseofARorVRattentionguidanceinthecontextofbrushing transparentyellowtintontheproductsinstead,pilottestsshowed
andlinking.Therefore,ourworkseekstobridgethegapbetween thatthismodewasnotabletosufficiently“pop-out”specificprod-
thesetwotopicsnecessarytoenablebrushingandlinkinginSitA. ucts: A red cereal box, when tinted yellow, simply looks like an
orangecerealbox,andnotaredonethatishighlighted.
3. Experimentalprototypeforsituatedbrushingandlinking
Outline is another common technique found in brushing and
This research aims to investigate how visual highlighting could linking [GSL∗14,GGL∗14]. Moreover, it is also a popular tech-
supportbrushingandlinkinginSitA.AsmentionedinSection2, nique used in visual highlighting to show that an object is “se-
brushing and linking, as well as visual highlighting (i.e., atten- lected”[DMT∗18,SCZ∗20].AlthoughColorandOutlinehavesim-
tion guidance) are not novel ideas when considered individually, ilarcharacteristicsinhowtheyhighlighttargets,theactualappear-
but it is the intersection in SitA that requires further study. For- ance of a product is visible for Outline but not for Color. Some-
tunately, existing techniques can be adapted to SitA. To ensure a times a more subtle, non-obtrusive highlighting can be beneficial
more grounded and systematic approach, we draw upon popular (e.g.,forsafety).Weshowoutlinesonthebordersoftheselected
techniquesalreadyusedinbrushingandlinkinginvisualanalytics, groceryproductsincameraspace.Wechoseawidthfortheoutline
andattentionguidanceinARandVR.Thisapproachhasdualben- which,afterpilottesting,wefeltwassufficientlywidetoseethe
efits.First,wecanimmediatelyseeifpriorresearchdirectlytrans- outline,butthinenoughnottoobstructneighboringproducts.
latesintoSitA.Second,wecanestablishabaselineunderstanding
Links are trajectories used to draw connections between enti-
of brushing and linking in SitA without the confounding effects
ties [CC07]. In the context of brushing and linking, a link indi-
ofpotentiallycomplexhighlightingtechniques.Inthissection,we
catesthattwoconnecteddatamarksarethesameunderlyingdata
describeaVRprototypethatwedevelopedtoinvestigatesituated
record[KPV∗18].ThesamepremiseholdsinSitA,whereadata
brushingandlinking,whichisopensourceonGitHub[DL24].
mark on the situated visualization (i.e., the virtual tablet in Fig-
ure1)isexplicitlyconnectedtoitsassociatedreferent.Particularly
3.1. Scenario
forthecomparisonandanalysisacrossview,directconnectionscan
SitA is relevant in many situations involving data and its physi-
facilitatetasks.Tothisend,weleverageapriorUnityimplementa-
calcontext[BKT∗22].Brushingandlinkingbecomesusefulwhen
tionbyProuzeauetal.[PLE∗19]whichdrawsvisuallinksbetween
consideringtheactualappearanceorlocationofphysicalreferents.
pairsofobjectsina3Dscene.Weadjustedsomeoftheirscript’spa-
We therefore chose a supermarket scenario to situate our experi-
rameterstomakethelinksmoreresponsivetomovement,because
mentalprototypeandthesubsequentuserstudy(Figure1).Asu-
weallowthesituatedvisualizationtobemovedbytheuser.
permarket is a popular scenario in the SitA literature [AWG∗15,
ETM∗15,EST16].Itsdefiningfeatureisanabundanceofgrocery Arrowsareubiquitoussymbolsusedtodirectattention.Theyare
products(referents)laidoutonshelves,whichvaryinlayout,mak- popularforattentionguidanceinAR,particularlytowardsobjects
ingthescenariowell-suitedforbrushingandlinking.Wealsocon- orpointsofinterestthatareoutofview[KR14,TK06,WGRF22,
sidered similar environments, such as a library with books or a YLF∗20].Thus,weconsiderhowsimilararrowscouldbeusedto
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.4of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
1) Adjust data dimensions 2) Adjust filters 3) Brush data marks 4) Point and select highlighted product(s)
Figure2:Sequentialframesofbrushingonasituatedscatterplotandidentifyinglinkedproducts(referents)duringouruserstudy,withthe
virtualtabletbeingheldatheadheightforillustrativepurposes.Frame1:Theuseradjuststhedatadimensionsasdesired.Frame2:Theuser
adjuststhefilterstoshowonlythedatamarkswithinthedesiredranges.Frame3:Theuserselectsthedatamarks.Frame4:Theuserfinds
thehighlightedproduct(s)andconfirmsidentificationbypointingandselectingwithcontroller.
highlight objects in SitA. For our study, we extended FlyingAR- markscannotbebrushed,ensuringthatnounwantedpointsarein-
row [GLH∗18], which repeatedly instantiates 3D arrows in front cluded. Step-by-step images of this situated brushing and linking
of the user that then fly toward a target object. Static arrows like processareshowninFigure2.Thetabletcouldbeheldcomfort-
Wieland et al. [WGRF22] or Yu et al. [YLF∗20] spawn in the ablyathipheightwithoutobscuringanyreferents,aswasthecase
viewport,causingclutterwhentherearemultipletargetsandhence foreveryoneduringourpilottestingandsubsequentuserstudy.As
might be less beneficial in real-life scenarios than dynamic ar- ourintentionistoevaluatetheeffectivenessofthefourtechniques
rows [GLH∗18]. We also suspect that adding animations or mo- tohighlightreferents,wefocusontheunidirectionalbrushingfrom
tionmakestargetsmoresalient.SinceGruenefeldetal.[GLH∗18] thesituatedvisualizationtothereferents.
claim a low workload, we suspected the dynamic arrow to be a
reasonablechoiceforhighlightinginSitA.Ouradaptedversionof 4. Userstudy
FlyingARrowisabletopresentmultiplearrowsconcurrentlyand WeconductedauserstudywithourVRprototypetodeterminehow
dynamicallychangethearrowstosupporton-the-flybrushing. thehighlightingtechniquespresentedinSection3.2performunder
differentreferentlayoutsaswellassituatedbrushingandlinking
Alternativesbeyondthesefourfundamentalhighlightingtech-
tasks.Theoverallgoalofthestudywastodetermine:(1)howwell
niqueswereconsideredbutexcludedafterpreliminarytesting.Size
existingtechniquesfrombrushingandlinkingandattentionguid-
wasanobviouscandidate[GCC17],butitbecameapparentthatex-
ance hold up in SitA; (2) how well each highlighting technique
pandingobjectsintherealworldisimpracticalbecausetheytake
supportsouruserexperiencecategories(Section4.4);and(3)how
up too much of the physical space [LYBP23]. Semantic depth of
brushingandlinkinginSitAcanpotentiallybeimproved.
field[KMH01]wasanothercandidate,asblurcanintentionallyob-
scure unimportant parts of the scene. However, we soon realized
4.1. Studyconditions
thatblurisnotonlyvisuallydistracting,butalsopotentiallydanger-
ouswhencertainpartsoftherealworldarevisuallydeteriorated. Ouruserstudyinvolvedtwoindependentvariables:
Highlightingtechnique.Color,Outline,Link,andArrow,asde-
3.3. Brushinginteractions scribedinSection3.2.
As the premise of our work involves both brushing and linking,
Shelf layout. Inside-FOV or Outside-FOV. For Inside-FOV,
ourprototypeneedsfacultiestoenablebrushinginasituatedvisu-
there are only four shelves in front of the user. Outside-FOV ex-
alization.Avirtualtabletattachedtothenon-dominant-handcon-
tendsthelayoutbyaddingfourshelvesbehindtheuser,withfront
troller(Figure1,center)presentsa2Dscatterplot,generatedwith
andbackrowsspaced4.8mapart.Thisextendedlayoutemulates
DXR[SLC∗19].Thexandydatadimensionsofthescatterplotare
situationswherethehighlightedreferentsmaybepositionedout-
determinedbybuttonsontherightsideofthetablet.Thetablet’s
sideoftheuser’sFOV.Eachshelfis2mwideby2mtall,form-
size(40cmby31cm)ensuresthatitscontentsareeasilyreadable
ing an overall aisle with a width of 8 m in total (Figure 3 left).
inVR,whilestillsmallenoughtonotbevisuallyobtrusive.
Neither layout forces the user to move to resolve occlusion. This
Weoptforasimplebrushingapproach,reminiscentofthebrush- choiceeliminatestheneedtosupportanyspecialVRlocomotion
ingmechanismusedinFIESTA[LHC∗21].Brushingisperformed techniques,whichwouldprobablyhaveconfoundedourresults.
by pointing the dominant-hand controller at the scatterplot and
pressingeithertheindexbuttontoaddtotheselectionorthegrip 4.2. Tasksanddata
button to remove it from the selection. We provide two modes Ourstudyinvolvedthreemaintasktypes:single-selection,multi-
forbrushing:sphericalandrectangular.Themodecanbechanged selection,andstatementresponse.Alltasksrequiredparticipantsto
using the corresponding buttons on the tablet. Any brushed data first make a selection on the scatterplot and then look for one or
marks on the scatterplot turn a solid yellow. To make selections more highlighted products on the supermarket shelves. All tasks
eveneasier,weaddedsimplerangefiltersalongthetwodataaxes. are bivariate, with the scatterplot selection being conditioned in
Thesefiltersarerepresentedashandleswhichcanbedraggedus- bothdimensions.Thetasksareintentionallykeptlow-leveltoal-
ingraycastinteractions,similartoImAxes[CCD∗17].Filtereddata lowforgeneralizabilityacrossvariousSitAapplicationsinvolving
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking 5of14
thresholds.Thissimplificationdoesnotconfoundourprimaryfo-
cusonthe“linking”.Figure2showsthestepsinvolvedinsolving
amulti-selectiontask,includingindicatingidentifiedreferents.In
termsofmovement,weneitherforcedparticipantstomovenorre-
4.8 m
strictedtheirmovement.Whenaskedforclarification,wetoldthem
thatallproductscouldbeseenjustbyturning.
8 m
We conducted our study using a desktop PC equipped with an
IntelCorei9-9980XECPU,RTX2080Tiwith11GBVRAM,and
Figure 3: Left: A top-down view of the virtual environment in
128GBofRAM.WeusedanOculusQuestProheadsetwithtwo
whichthe studytakesplace. Right:Aclose-up viewofthe panel
handcontrollers.Theheadsetwasconnectedviaa5mQuestLink
andtheuserinterfacepromptingauserresponse.
USB cable to the PC running our application developed in Unity
version2022.2.20f1.Allquestionnaireswereadministeredonthe
multiplephysicalreferents,suchasbrowsingcarsbasedonmileage samePCusingLimeSurvey.Thestudywascarriedoutinanopen
andprice,orplanningseatingarrangementsataweddingbasedon spaceof360cmby220cmthatwasfreeofobstructions.
guests’ageandrelationshiptothebrideandgroom.
Single-selectiontasks.Identify,select,andlocateasingleprod-
4.4. Measures
uct (referent) that matches a bivariate criterion, e.g., “Select the
productthathasthehighestfatandnosugar.”Thistaskhelpsde- TaskPerformance.Wemeasuredtaskperformanceusingcom-
termineatechnique’seffectivenessinlocatingasinglereferent. pletiontimeanderrors.Foreachtask,werecordedtheoverallcom-
pletion time, the time of the last interaction with the tablet (i.e.,
Multi-selection tasks. Identify, select, and locate all products
buttonpresses,filterchanges,andbrushing),andthetimewhenthe
thatmatchabivariatecriterion,e.g.,“Selectallproductsthathave
firstproductwasselected(Figure2,frame4).Theoverallcomple-
morethan22.5gproteinandlessthan9.5gfat.”Thistaskhelps
tiontimeistheintervalbetweenstartingthetaskandselectingthe
determineatechnique’seffectivenessinlocatingmultiplereferents,
finalproductorrespondingtothegivenargumentviatherespective
asitrequireshighlightingtobeappliedtomultipleproductssimul-
button.Incorrectlyselectedproductsarecountedaserrors.
taneously. All questions have five products that match the given
criteriontoensureconsistencyacrosstrials. UserExperience.Wemeasureduserexperienceusingtwoques-
tionnaires.Aquestionnairewascompletedaftereachshelflayout
Statement response tasks. Respond with “Yes”, “No”, or
foreachtechnique,andanother,finalquestionnaire,afterallcondi-
“Maybe”toagivenstatementthatdescribesthedatasetandsuper-
tions.Thein-betweenquestionnaireincludedNASA-TLX [Har06],
marketlayout,e.g.,“Veganproductsthatcontainmorethan51gof
free-text forms for comments on user strategies and experiences,
carbohydratearedistributedonlyinthecenter-leftandcenter-right
as well as additional feedback. The physical environment might
shelves.”Thistaskrequiresparticipantstoobserveacollectionof
not be as accessible as the desktop visualizations and might in-
referents together and make a judgment on their spatial arrange-
troduceadditionalfactorsthatinfluencecertainhighlightingtech-
ment.Thetaskisalsoreminiscentofstandardbrushingandlinking,
niques.Hence,wecameupwiththefollowingcategoriesthatsuch
whereinallbrushedpointsshouldbevisibleandconsideredwhen
techniques should support through internal discussions, our own
judgingcorrelationsanddependenciesinthelinkedview[Kei02].
experiences and findings with SitA, and reported findings in the
Weusedacurateddatasetthatcontains11variables(7quantita- literature. The final questionnaire included these categories using
tive,4categorical)for98products,whichweplacedonthesuper- 9-pointLikertscales(1=worst,9=best,unlessstatedotherwise).
marketshelves.Thisdatawasmanuallyscrapedfromsupermarket
Generalexperience.Asubjectiveratingofhowthehighlighting
websites, and all values were checked for plausibility. Minor ad-
techniqueperformedingeneral.
justments were made to these values to accommodate the above
tasks.TheInside-FOV conditiononlyusesareduceddatasetof39 Out-of-view. A highlighting technique ideally accounts for
productsfittinginthefront-facingsetofshelves. physicalreferentsbeingoutofvieworoccluded,sinceidentifying
canbeequallychallengingforvirtualandphysicalobjects.
4.3. Experimentalsetup Visualclutter.Ahighlightingtechniqueideallysupportsmark-
WeusedtheexperimentalprototypedescribedinSection3.Allin- ingmultiplereferentswithoutclutter,sincescalabilityisoftende-
structionsandbuttonsusedtoanswerthestatementresponsetasks
siredforbothinfovis[RPA∗22]andSitA[BPR20].
(“Yes”,“No”,“Maybe”)areshownintheupperareaofthetablet
Obstruction. A highlighting technique ideally minimizes oc-
(seeFigure3right).Additionally,functionalitywasaddedforthe
cludingitssurroundingandobstructingthetask,asdistractingor
single-andmulti-selectiontaskstoindicatethattheyhave“iden-
reducingtheuser’srealworldawarenesscanbedangerous(1=not
tified” the required products. As we are not interested in the us-
atall,9=very).
abilityofbrushingscatterplotsinVR,wedecidedtostreamlinethe
process after pilot testing revealed it to be too cumbersome. Red Subtlety. A highlighting technique ideally balances between
visual cues were added to indicate the two required data dimen- saliency and subtlety, as some SitA contexts (e.g., for safety) re-
sionsforeachtaskandtoindicatetherequiredvaluerangesalong quireamoresubtlehighlightingtechnique(1=verysubtle,9=very
theaxes.Thefilterhandlesweremodifiedto“snap”totheserange obtrusive).
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.6of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
Explicitconnections.Ahighlightingtechniqueideallysupports Color Shelf Layout
direct connections of data marks and referents, since making as- Outline
Inside FOV
sumptionsacrossviewsiscommoninvisualanalytics[Rob07]and Link
Outside FOV
potentiallyinSitAscenariosaswell. Arrow
0 2 4 6 8 10 12 14 16 18 20 22 24
Linking Completion Time (s)
Recognition.Ahighlightingtechniqueideallybalancesbetween
(a)Overalllinkingcompletiontime.
identifyingandobscuringthetarget,assomereal-worldtasks(like
groceryshopping)mightrequiretobeawareoftheactualappear- Color Shelf Layout
ancewhileothersdonot(1=notatall,9=very). Outline Inside FOV
Link
Outside FOV
Enjoyment.Ahighlightingtechniquebalancesbetweenusabil- Arrow
ityandenjoymentresultingfromanaestheticallypleasingdesign. 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30
Linking Completion Time for Multi−Selection Task (s)
Therelevanceofthecategoriesvariesbetweenusecases.How- (b)Linkingcompletiontimeforthemulti-selectiontask.
ever,wecollectedallcategoriesthroughouttheexperimentstoob-
Figure4:Completiontimemeasuresusingmeanand95%CIs.
tainafullcharacterizationofpossiblesituatedbrushingandlinking
contexts.Thefinalquestionnairealsoaskedparticipantstodescribe
theirstrategiesfordifferenttechniquesandshelflayoutconditions, response), the participant removed the VR headset to answer the
andprovidegeneralfeedback. in-betweenquestionnaire.Afterashortbreak(ifneeded),theyput
theheadsetbackontoproceedwiththestudy.
4.5. Studydesignandprocedure
Poststudy(5-10minutes).Afteralltrialswerecompleted,the
Weusedawithin-subjectsstudydesigntoevaluateourtwoinde- participant answered a final questionnaire. Then they were given
pendent variables: highlighting technique (Color, Outline, Link, compensationasarewardfortheirparticipation.
Arrow); and shelf layout (Inside-FOV, Outside-FOV). Each con-
dition consisted of three tasks, one per each task type (single- 4.6. Guidingquestions
selection,multi-selection,statementresponse).Eachquestionwas
Fortheanalysisofourexploratorystudy,wedevisedfourguiding
randomly selected from a set of eight predefined questions per
questions,alongwithsomeofourpriorexpectations:
typeoftask.Thus,eachparticipanthadtoperformfourhighlight-
ing techniques × two shelf layouts × three tasks = 24 trials. We • GQ1:Whichtechniquesperformsthebestintermsoftask
counterbalancedtheorderofthehighlightingtechniqueusingLatin performance,andwhichtheworst?WeexpectthatLinkwill
squares.However,weusedafixedorderforboththeshelflayout havethefastestcompletiontimeduetoitsguidanceeffect,even
(Inside-FOV→Outside-FOV)andthetasktype(single→multi toout-of-viewtargets,aswellasitsdirectconnectionbetween
→statement),becausethesetwoaspectshaveanaturallyincreas- datamarksanditsreferents.WealsoexpectthatArrowleadsto
inglevelofdifficulty.Participantswerecompensatedwith C12. theslowestcompletiontimeforthemulti-selectiontaskdueto
itslimitedscalability.Wehavenoexpectationsabouterrorrates.
Introduction (5 minutes). The participant was welcomed and
• GQ2:Whichtechniqueissubjectivelypreferredordisliked?
introducedtothepurposeofthestudy.Aftersigningaconsentand
Link fits many required features of our tasks and requirements
privacyform,theywereaskedfortheirhandiness,askedtofillin
(e.g.,out-of-viewhighlightingordirectconnectionofdatamarks
a demographic questionnaire, and introduced to the VR headset
andtheirreferents).Weassumethatitisperceivedastheeasiest
and controllers. They were informed that they could take breaks
andfastesttechniqueandexpectittobepreferred.
orwithdrawatanypointinthestudywithoutconsequences.
• GQ3:Whichtechniqueistheleastpreferredifmanytargets
Training(10-15minutes).Theexperimenterfirstexplainedthe arenotinview?WeexpectArrowtobeperceivedworst,asit
VR prototype to the participant, describing the supermarket and isnotscalableand,therefore,cluttersanenvironmentcontaining
tablet,the availableinteractions andthe tasksthey wouldbe per- manytargets.Fortargetsoutsidetheview,weexpectColorand
forming.PowerPointslideswithpictureswerealsoshownduring Outlinetobetheleastpreferred,astheydonothaveguidance
thebriefing.TheparticipantthenputontheVRheadsetandprac- andnodirectconnectionsbetweendatamarksandreferents.
ticedbrushingandlinkinginteractionsusingasimplifiedlayoutof • GQ4: Which technique is perceived as the most subtle and
11productsandtheaforementionedsizehighlightingtechnique.In least obstructive? We expect Outline to be deemed the most
this phase, notask was assigned, andthe participant could freely subtleandleastobstructive,asitobscuresonlytheboundaryof
trytheinteractionswithouttimepressure. thetargetsanddoesnotcauseclutterevenwithmanytargets.
Main study (40-50 minutes). The participant was then given
eachoftheconditionsandtasksinthecounterbalancedorderde- 5. Results
scribedabove.Wheneveranewhighlightingtechniquewasintro- We recruited 20 participants (8 female and 12 male) via univer-
duced,theparticipantwasgivenashorttutorialusinganothersim- sity mailing lists and social media, with different age groups be-
plifiedlayoutoffourproductstoletthemseewhatthehighlight- tween18and55years(mode=26–30).19participantshadcorrect
ingtechniquelookedlike.Betweeneachtrial,theparticipantwas orcorrected-to-normalvision,whileoneparticipanthadastigma-
toldtoreturntothecenteroftheroomandfacethedirectionindi- tism. We had 16 participants who were right-handed, and 4 par-
catedbytheimageonthefloor(seeFigure3left).Aftercompleting ticipantswhowereleft-handed.Mostofourparticipantshadsome
eachsetofthreetasks(single-selection,multi-selection,statement visualizationexperience(16/20between2and4ona5-pointLikert
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.
euqinhceT
euqinhceTN.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking 7of14
Color 1 1 Shelf Layout
Outline 4 6 Inside FOV General Experience
Link 1 11 Outside FOV
Arrow 5 15 Out−of−View
0 5 10 15
Total Error Count
(a)Totalerrorcountsacrossallparticipants.
Clutter
Color Technique Shelf Layout
Outline Inside FOV Obstruction Color
Link
Outside FOV
Arrow Outline
0 Euc2 lidean Dista4 nce of Error6 (m) 8 Subtlety Link
(b)Distancesbetweeneachincorrectproductanditsclosestcorrectproduct. Arrow
Figure5:Errormeasuresforthesingle-andmulti-selectiontask. Explicit Connection
scale),andonlyafewparticipantshadlittle(4/20between0and1). Recognition
MorethanhalfoftheparticipantshadsomeVRexperience(12/20
between2and4ona5-pointLikertScale),andtheremainingpar-
Enjoyment
ticipantshadlittle(8/20between0and1).
1 2 3 4 5 6 7 8 9
FollowingtherecommendationsofCumming[Cum14]andthe 9−Likert Scale Score
American Psychological Association [Ame20], we visually ana- Figure6:Meanand95%CIsofthecategoryratings.
lyze the data based on their mean and 95% confidence intervals
using forest plots. In general, the evaluation and subsequent dis- layoutconditions,withtheworstresultsfortheOutside-FOV.Ar-
cussionfocusesmoreonthedifferencesbetweenthehighlighting rowistheworstfortheInside-FOV.Byandlarge,theresultsfor
techniquesthanontheshelflayoutconditions. themulti-selectiontaskareverysimilartotheoverallresultsabove,
withaslightlystrongerarticulationofthemaincharacteristics.
5.1. Taskperformance
Errors We also measured errors as incorrectly selected prod-
CompletiontimeanderrorsareshowninFigure4andFigure5. ucts in single- or multi-selection tasks and removed duplicate er-
rorscausedbyselectingthesameincorrectproductrepeatedly.Fig-
CompletionTime Sinceouranalysisfocusesonthelinkingpart
ure5ashowsthetotalcountoferrorsamongallparticipants.Color
of the task, we calculated linking completion time defined as the
hadthelowestnumberoferrorsandArrowthemost,withOutside-
overallcompletiontimeminusthetimeofthelastinteractiononthe
FOVbeingmorepronetoerrors,especiallyforLinkandArrow.In
tablet.Duringthestudy,wenoticedthatsomeparticipantsdidnot
addition,Figure5bshowsforeacherrorhowfarthecorrectprod-
brushalldatamarksatonce,butratherbrushedoneatatimewhen
uctwasinmeters.Fromthisresult,weseethatmostoftheerrors
usingcertaintechniques.Forthesecases,wemanuallycalculated
madeusingColor andOutlineweremorethan1maway,mainly
thebrushingtimeandlinkingtimefromtherecordedvideo.
duetoincorrectbrushingonthescatterplot.Thiswasconfirmedby
For the overall linking completion time, which includes all reviewing the respective video footage. In contrast, for Link and
tasks, we received 24 values per participant (4 techniques × Arrow,manyerrorswerelessthan0.5maway,suggestingthatpar-
2shelflayouts×3tasks).Toaggregatethesevaluesforeachtech- ticipantsactuallymistooktheproducttheyneededtoselect—with
niqueandshelflayoutperparticipant,wefirstaveragedthevalues somealsoduetoincorrectbrushing.Overall,LinkandArrowwere
beforecalculatingtheoverallmeanandtherespectiveconfidence morepronetoerrorswhenidentifyingahighlightedproduct.
interval.Theresultsoftheoveralllinkingcompletiontimecanbe
seeninFigure4a.TheInside-FOVlinkingCTisgenerallyfaster 5.2. Userexperience
thantheOutside-FOVforalltechniques.Color andLinkperform
We now report questionnaire results of the category ratings and
similarly;LinkisslightlybetterfortheInside-FOV,butworsefor
NASA-TLX.
theOutside-FOV.WhileOutlineresultedinsimilarresultsforthe
Inside-FOV,theresultsindicateasubstantialperformancedropfor Category Rating The results of the 9-point Likert scale ratings
Outside-FOVtargets.Outlineistheonlytechniquewithalargegap areinFigure6.Highvaluesarebetterforallcategories,exceptfor
betweenthetwoshelflayoutconditions.Arrowistheworstforthe obstruction,subtlety,andrecognition,wherelowvaluesarebetter.
Inside-FOV,and,secondworstforOutside-FOV.
• General experience Color and Link performed similarly, fol-
Wealsoevaluatedthelinkingcompletiontimeforthemulti- lowed (with large gaps) by Outline and, lastly, Arrow. While
selectiontask.Wewerespecificallyinterestedinthistask,asmulti- Outlinereceivedamediocrerating,Arrowwasratedverylow.
selectionconstitutesthe"corediscipline"ofbrushingandlinking. • Out-of-viewLinkwasrankedthebest.Withaconsiderablegap;
TheresultsareshowninFigure4b.Asbefore,theInside-FOVhas Color,Arrow,andOutlinefollowed.
lowervaluesthantheOutside-FOV.Overall,Colorperformsbest, • Visual clutter Color and Link resulted in the best scores, fol-
closely followed by Link, as its Outside-FOV completion time is lowedbyOutline.Withaconsiderablegap,Arrowwastheworst
slightly higher. Again, Outline has a large gap between the shelf andconsideredtobethemostvisuallycluttered.
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.
euqinhceT
euqinhceT
yrogetaC8of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
Mental Demand Performance Effort Frustration
Color
Shelf Layout
Outline
Inside FOV
Link
Outside FOV
Arrow
0 2 4 6 8 101214161820 0 2 4 6 8 101214161820 0 2 4 6 8 101214161820 0 2 4 6 8 101214161820
TLX Score
Figure7:Meanand95%CIsoftheNASA-TLXsubscalesmentaldemand,performance,effortandfrustration.
• Obstruction (low better): Color, Outline, and Link all per- "[looked]atnamedshelvesbeforetendingtothetask"(P16).For
formedverywell,whileArrowwasworstbyalargemargin. themulti-selectiontask,oneparticipantstatedthatthey"[selected]
• Subtlety(lowbetter):Outlinewasperceivedbyfarasthemost theproductsontheshelvesgoingfromlefttoright"(P16).Another
subtletechnique.Theotherthreewerenotconsideredsubtle. participantclaimedthattheyadaptedtheirstrategy"[toselect]one
• ExplicitconnectionsLinkwinswiththehighestscore. objectatatimeinsteadofselectingallatonce"(P3)forthemulti-
• Recognition(lowbetter):Linkwasjudgedthebestforrecogniz- selectionandstatementtask,aftertryingouttheArrowcondition.
ingtheproduct,followedbyOutline.ColorandArrowresulted
ColorandOutlinerequiremoremovement.Aquarterofour
inmediocrescores.
participants said that it was easier to solve tasks with Color, and
• Enjoyment Enjoyment results are similar to General experi-
they were able to "[select] multiple products at once" (P3) with
ence,withthehighestenjoymentforLinkandColor,followed
Color and Outline. However, both techniques subjectively felt to
byOutlineand,farbehind,Arrow.
involve more movement, since there is no "indication for objects
ColorandLinkperformedthebestforallratings.Outlinewasthe outsidethefieldofview"(P12),and,hence,"[they]hadtolookat
sole favorite in subtlety, and Link in explicit connection. Arrow the shelves to find them, and had to look twice to make sure that
wastheworstinsixcategories,andsecondtolastintheothertwo. [they]hadnotforgottenanyitem"(P1).
NASA-TLX We briefly report on four subscales of the NASA- OutlineishardertoperceivethanColor.Someparticipantsar-
TLX:mentaldemand,performance,effort,andfrustration(Fig- guedthat"forOutline,[theyhad]topaymoreattentioncompared
ure7).Physicalandtemporaldemandarenotreportedhereasthe toColorbecauseitscolorfuledgehasasmallsize"(P7)and"[it
task is not physically intensive nor does it have time constraints, requires] more mental processing and visual search" (P18). Fur-
thoughtheirscoresweresimilartomentaldemand.Pleaseseethe thermore, the participants argued that some products had similar
supplementalmaterialfortheremainingNASA-TLXdata. boundaries,and,hence,Outlinewashardertoperceiveasthecon-
trastwas"notalwaysoptimal"(P17).
For performance, Inside-FOV scores are slightly higher than
Outside-FOVscoresbutarestillcomparable.ColorandLinkhave Link works well for out-of-view but worse in peripheral
similarhighscores,followedbyOutlineandArrow.Overall,there regions. According to several participants, Link makes multi-
arenolargedifferencesbetweenthetechniques.Theremainingre- selectiontaskseasierastheycan"justfollowtheline[...]toselect
sultsformentaldemand,effort,andfrustrationshowsimilarpat- theitem"(P1)and"neededtopaylessattentiontotheshelvesdi-
terns. In these three subscales, scores were similar between both rectly"(P18).Linkisalsoeffectiveforout-of-viewtargetsas"the
shelflayouts.LinkandColorarefollowedbyOutlineandArrow. lines[helped]toindicatethatthehighlightedproductsarebehind
WhileLink andColor haveasimilarlylowscoreforeffort,Link [you]withouttheneedtoturnaround"(P20).However,somepar-
slightlyoutperformsColorformentaldemandandfrustration. ticipantscriticizedthevisibilityofLink intheperipheralregions.
AccordingtoP2,thesewereambiguous,andP12saidifthetablet
Overall,theresultsresemblethoseofthecategoryratings:Color
hidessomelines,theymaybemissed.
andLinkperformedthebest,followedbyOutline,andlastlyArrow.
However,theyaremuchlesspronouncedinNASA-TLX. Arrowrequirespatienceandstrategiesformanytargets.Al-
thoughP1wasabletofollowthepathofArrow,mostofthepartic-
5.3. Qualitativeanalysisandcomments ipantscriticizedthatArrowis"annoying"(P7)and"exhaustingfor
theeyes"(P13).Althoughthegeneraldirectioncanbeguessed,the
As mentioned in Section 4, we also included free-text forms for
movementofthearrow"[seemed]tobeinfluencedbyuserorien-
further feedback. In addition to mentioning strategies, there were
tation"(P17),and,hence,itisdifficulttofindtheactualtarget.Ac-
commentsonourtaskdesign,aswellasonbrushingandfiltering
cordingtoseveralparticipants,"[theyhad]towaittoseewherethe
methods.Asthisworkfocusesonhighlightingandlinking,wefo-
arrowsgo,foreachproductseparately"(P5)and"if[theymissed]
cusonfeedbackontheseissues.
theexactmomentithits,[they]hadtowaitagainforthenextone"
Tasks can have—but do not need—strategies. Regarding (P14).Therefore,theytriedto"keepfullystill"(P7).Severalpartic-
strategies,oneparticipantmentionedthattheyfirst"[readthetask] ipantsalsoarguedthattheyperformedstrategiesformulti-selection
very quickly while selecting the [components]" (P6). For a later andstatementresponsetasks,asArrowproduceda"verycrowded
question,theyclarifiedthatthey"expanded[their]previousstrat- visual field" (P18). For example, participants "tried to crouch to
egywiththeredstripesontheaxes"(P6).Anotherparticipant(P16) seemoreclearlyifthearrowswereflyingonlyupward" (P17)or
describedasimilarstrategyforthestatementtask,sincetheyalso "searchedforanoutlier"(P18).
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.
euqinhceTN.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking 9of14
6. Discussion addressdifferentpropertiesforahighlightingtechniqueinsituated
analytics,itseemsthatthesubjectivepreferenceforeitherofthem
Weconcludeourpaperwithasummaryofourobservations,impli-
woulddependontheusecase.AdistinctadvantageofColoristhat
cationsforfuturework,limitations,andsomefinalremarks.Sec-
itiseasytounderstandandhasabrightcolor.Oneparticipantstated
tion6.1discussestheresultsbasedontheguidingquestions.
that"[Color]seemedtheeasiest[technique]tome"(P20).Unlike
Color,Linksupportsfindingtargetswhichareoutofview,asone
6.1. Observationsandlessonslearned
cansolelyfollowthelinefromitsbeginningtoitsend.Severalpar-
ColorandLinkperformthebestintermsofcompletiontime, ticipantsmentionedthatLinkhighlightedtargetsbehindthemwell
followedbyOutlineandArrow. OurresultsshowthatColorand (P12,P17,P18).However,intheperiphery,itcanbedifficulttoac-
Link resulted in the lowest completion time. Color was slightly curatelydeterminetheendpointofalink(P2).Hence,wespeculate
faster for the Outside-FOV, whereas Link was slightly faster for thatincreasingthelinkthicknesswithincreasingdistanceorusing
the Inside-FOV. While we expected Link to perform well as per acombinationofColorandLinkmayincreaseoverallsatisfaction,
GQ1,ColorwassurprisinglyabletohandletheOutside-FOVcon- especiallyforreal-worldawareness.
ditiondespiteitslackofsupportforout-of-viewandexplicitlink
representations. We assume that this is due to the strong contrast Arrowistheleastpreferreddespiteitsabilitytodirecttoout-
ofColor,whichmakesitavalidchoicewhenatargetsearcharea of-view targets. Since Arrow clearly has the lowest results for
ordirectionisknowninadvance.Linkmayhaveunderperformed generalexperienceandenjoyment,wecandeclareittheleastpre-
forOutside-FOVasitwouldpassdirectlythroughtheparticipant’s ferredtechniqueforGQ2andGQ3,atleast,forourscenario.This
own body, making it difficult to visually trace it. Although Out- observation is also reflected in the comments of our participants,
linehighlightsatargetinasimilarmannerasColor,ithassimilar whodescribedArrowas"irritating"(P1),"annoying"(P7)oreven
meancompletiontimefortheInside-FOV,butnotfortheOutside- "exhausting for the eyes" (P13). Gruenefeld et al. [GLH∗18] had
FOV.Accordingtomultipleparticipants(P2,P5,P7),withamore similar task performance results, but found a lower workload for
solidandbettercontrastofOutline,itwouldhavesimilarbenefits Arrow,whichcouldbeduetoourscenariowithitsmanytargets.
asColor.Forexample,P2arguedthat"[Outlinewas]muchharder Our animated Arrow resulted in worse results than the static ar-
tosee[...]thantheproductsthatwerehighlighted[byColor]"(P2).
rowsofWielandetal.[WGRF22]andYuetal.[YLF∗20],which
Lastly,ArrowwasclearlytheslowestasexpectedinGQ1.Partic- couldbe dueto itsusage asa baselinecondition basedon famil-
ipantsclearlysummarizedtheissue:"for[Arrow]Ihadtowaitto iarityreasons.SinceWielandetal.[WGRF22]onlyconsidereda
besurewhereitgoes"(P5),whileothertechniquessuchasColor singletargetatatime,weassumethattheirarrowapproachwould
andLink "madeitpossibletosolveproblemsataglance" (P18). alsoresultinclutterformultipletargets.Onereasonmightbethe
This aligns with known reasoning for why static representations clutterintroducedbyArrowthataffectsitsabilitytohighlightmany
canbesuperiortoanimations[HR07,TMB02].Itispossiblethat targets. P12 observed that "[Arrow is] obstructing too much of
acombinationofstatichighlightswithsalientanimationscouldbe theview,especiallywhentherearemultipletargets"(P12).How-
effective,thoughatthecostofincreasedvisualclutter. ever, Link was not perceived as cluttered, suggesting that anima-
tion might causes poor scalability. Additionally, all previous ap-
Color had the least amount of errors, with Outline, Link, and proaches[GLH∗18,WGRF22,YLF∗20]includedestimationtasks
Arrowperformingincreasinglyworse. WefoundthatColorwas thatcouldhaveledtobetterresultsforArrowifappliedinourcon-
clearlythemostaccuratehighlightingtechnique,whichonceagain text.OnecouldmodifyArrowsuchthatitisnotaffectedbyhead
may be due to its strong contrast. Note that, in several instances, movementsifmanytargetsarepresent.However,theclutterofAr-
errors were caused by mistakes in brushing the scatterplot or se- rowremainsamajordrawback.
lectingtherightproduct—likelycausedbythechallengingraycast
interactions.However,astheseissuesaffectallhighlightingtech- Outlineisthemostsubtleandleastobstructing. WhileOutline
niques uniformly, we believe that this does not invalidate our re- hasthelowestmeanratingintermsofsubtlety,allmethodsexcept
sults.Therefore,thelackoferrorsoflessthan1mforbothColor Arrowranksimilarlyintermsofobstruction.However,comments
andOutlineindicatesthat,whentheproductwascorrectlybrushed, fromparticipants,suchas"Ihadtolookateachproducttobereally
theyresultedinlittletonomistakes.Incontrast,Link andArrow sureitisnothighlighted"(P5),suggestthatOutlineisindeedthe
performedmuchworseforerrors,probablybecausetheyonlyin- most subtle regarding our GQ4. We assume that the contours of
dicate the center point of the target. As they do not indicate the Outlineareperceivedaspartoftherealsceneandnotasartificial
contoursofthetarget,likeColororOutlinedo,participantsinstead highlighting.AlthoughweexpectedLinktobesubtleaswell,the
selectedsimilar-lookingnearbyvariants(e.g.,differentyogurtfla- endofalineappearsmoreartificial.Onereasonfortheresultsof
vors).Therefore,wearguethat,whenataskinvolvessimilarvari- Arrowmaybetheanimations,whichpotentiallyobstructthefield
etiesordistractors,ColorandOutlinecanreduceambiguitiesover ofview.Whilesubtletymaynotbeavirtueforfastvisualsearch
Link and Arrow—especially if it is unclear if the referents stand orclassicalbrushingandlinkingapplications,therearescenarios
aloneindividuallyoraregroupedasone. whereasubtle,non-obstructivetechniquewithhighreal-worldis
beneficial.Forexample,wewanttoavoidwalkingintoanobjector
ColorandLinkaresubjectivelypreferred. WefoundthatColor
anotherpersonwhilemovingtowardtheselectedreferent.
wasgenerallypreferredoverLink.However,ColorandLinkdiffer
significantlyfromOutlineandArrow.Similarresultscanbeseen Brushing in situated analytics matters. We also received sev-
forenjoyment.WeargueforGQ2thatbothColorandLinkarepre- eralcommentsonthebrushingcomponentofourprototype.Partic-
ferred over the remaining techniques. Given that Color and Link ipantsagreedthatitwaseasytobrush,asthe"redmarkedareason
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.10of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
theaxis[helped]alot"(P12),indicatingthattheircognitiveload Whilewebelievethesupermarketisgeneralizabletoothersce-
wasreducedasintended.Participantshoweverstillstruggledwith narios,ourstudylackedseveralconditionsthatshouldbeexplored
adjustingthefilterhandlesusingtheraycastinteractions,which"af- infuturework.First,ourshelflayoutsdidnotforceparticipantsto
fected[their]frustration"(P17).P16alsowanted"toseehowmany movebecauseofocclusions.Weassumeout-of-viewhighlighting
[datamarks]areselectedonthetablet",whichwouldbeneeded techniquessuchasLinkaremorebeneficialhere,especially,since
inaproperSitAapplication.Anysuchimprovementstobrushing theycanalsohelpwithwayfinding.Second,wechoseonlystatic
wouldnaturallybenefitanyimmersiveapplication,notjustSitA. referents,whereasreferentscanalsobedynamic(e.g.,autonomous
robots,animals).Third,ourreferentsareatacomfortablehuman
6.2. Examplescenariosandapplications scalewhencomparedtobuildingsorlandscapes.Thesecharacter-
Basedonourresults,weseethefollowingpracticalusageforour isticsnotpresentinourscenariorequirefurtherevaluation.
techniques. Color is valid to use for targets behind the user due
to its bright color. However, the scenarios should not require the 6.4. Limitations
perceptionoftheactualappearance,butonlythesilhouetteofthe
Some limitations can potentially affect the interpretation of the
target. We further assume that the general direction of the target
findingsreportedinourwork.First,oursmallsamplesizeandthe
mustbeknowninadvance.UnlikethemoreobtrusiveColor,Out-
chosentaskscouldaffecttheresultsanddesignconsiderationsof
lineisperceivedasmoresubtle,buthardertosee.However,onecan
ourwork.Inaddition,weadjustedandcalculatedourlinkingcom-
seetheactualreferent’sappearance.Forexample,guidingatrainee
pletiontimebasedonthelastselectiononthetablet,assumingthat
toadesiredtoolduringservice.IncontrasttoColor andOutline,
participantswouldfirstbrushalldatamarksandthenselectthere-
Linkmightbeabetterchoicefortargetsthathaveagreaterdistance
spective targets on the shelves. While we manually adjusted the
andarepotentiallyoccludedbyotherobjects.WesuspectLinkto
timestamps for participants who obviously used a different strat-
beavalidchoiceinwidesearchspacessuchasalibraryinwhich
egy, it is possible that some participants missed a data mark dur-
booksaredistributedacrossmanyshelvesandfloors.Basedonthe
ingthemulti-selectiontask.Hence,sometimestampsmaybenon-
results, Arrow required more work to find the correct target. We
representative.Sinceweusedanopenexperimenterstudydesign,
assumethatscenarioswhichprimarilyrequire directionguidance
weassumethatthisrarelyhappenedanddoesnotlimitourresults.
benefitfromalimitednumberofarrows.
Another limitation is our use of VR to simulate AR, even if
6.3. Futuredirections transferability from VR to AR has been demonstrated for other
tasks [LBHB09,LRM∗13]. We assume that any differences ob-
Weintentionallyusedbaselinehighlightingtechniquesestablished
served between the highlighting techniques in our study will still
in brushing and linking and attention guidance. Based on our re-
translateintoAR,andthereasonsforusingonetechniqueoverthe
sults,thereareclearavenuesforimprovingeachofthefourtech-
otherremainthesame.However,itislikelythattheireffectiveness
niques. Although we did not directly evaluate the matter, Color
inARwilllargelybedictatedbythetechnicalcapabilitiesofthe
lacks a way to perceive the actual target (since it is distorted by
AR headset and tracking solution [CFSS23]. For example, track-
thecolor).AmodifiedOutlinewithincreasedcontrastandoutline
ingdriftmaycausenoticeablemisalignmentinobjectsilhouettes
widthcouldinheritmostofthebenefitsofColor,whilenot(fully)
whenusingColor,whichmayjustifytheuseofothertechniques
occludingtheunderlyingtargets.ForLink,wesuggestthatadjust-
lesssensitivetothisissuelikeLink orArrow.Thestudyofthese
ingsizebasedondistance,aswellasaddingawayofperceiving
considerationsliesfirmlyoutsidethescopeofthiswork.
linesbehindthetabletoruser,wouldfurtherincreasethealready
encouraging results. However, care has to be taken to avoid ex-
cessivevisualclutter[HRD∗19].WeassumethatArrowmightbe 7. Conclusions
more beneficial if the user’s movements did not have an impact
We present an initial exploration of brushing and linking for sit-
onitspath,orifusedasasupplementaryindicatorcombinedwith
uated analytics in AR. We describe four highlighting techniques,
ColororOutline.Ingeneral,itseemslikelythatahybridtechnique
representingconventionalapproachestobrushingandlinkingand
can overcome the weaknesses of individual techniques, provided
attentionguidance.Weusedthesetechniquesinanexploratoryuser
that we can avoid too much clutter. However, the optimal choice
studyandfoundthatColor isstillareasonablechoiceasahigh-
will likely depend on the scenario. For example, applying Color
lightingtechniqueforsituatedbrushingandlinking.Wealsosaw
tolargeobjectscanbevisuallyoverwhelming,evenifColor was
thatArrow,ahighlightingtechniquethatrequiresspatialinterpre-
themostfavoredoverall.Futureworkmayseektodeviseanadap-
tation,performedworstintermsofbothtaskperformanceanduser
tivehighlightingtechniquetotunethevisualcharacteristicsofthe
experience. Based on our overall results, we propose that a com-
highlightingtothecurrentviewingsituation.
bination of highlighting techniques might reap the benefits while
Future work should also investigate brushing. If brushing in overcomingindividualweaknesses.Weconsiderourworkastart-
reverse, i.e., brushing physical referents, an analyst could com- ingpointtobringbrushingandlinkingintotherealandmergingit
pare the values of nearby referent after physically navigating to withprevioustechniquesdesignedfor“reading”theenvironment.
an interesting real-world area, such as inspecting the bargain bin
in the supermarket. Several techniques could support brushing in Acknowledgments. We thank DFG (495135767 and EXC
thismanner,includingspatialfiltering[FMS93,JLB∗00],aggrega- 2120/1–390831618), Carl-Zeiss-Stiftung (P2016-03-004), FWF
tion[TOK∗16],andselection[SCZ∗20]techniques.Weleavethe (I5912-N), and the Alexander von Humboldt Foundation funded
explorationofthisinversebrushingforfuturework. bytheGermanFederalMinistryofEducationandResearch.
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking 11of14
References visualattentionguidancetechniques. InExtendedAbstractsofthe2023
CHIConferenceonHumanFactorsinComputingSystems(NewYork,
[Ame20] AMERICAN PSYCHOLOGICAL ASSOCIATION (WASHING-
2023),ACM.doi:10.1145/3544549.3585816.3
TON,DISTRICTOFCOLUMBIA)(Ed.):PublicationManualoftheAmer-
icanPsychologicalAssociation,seventheditioned.2020.7 [DL24] DOERRN.,LEEB.:Vishigh,2024.URL:https://github.
com/doerrna/VisHigh.3
[APHD24] ASSOR A., PROUZEAU A., HACHET M., DRAGICEVIC P.:
HandlingNon-VisibleReferentsinSituatedVisualizations.IEEETrans. [DMT∗18] DILLMANK.R.,MOKT.T.H.,TANGA.,OEHLBERGL.,
Visual Comput. Graphics 30, 1 (Jan. 2024), 1336–1346. doi:10. MITCHELL A.: Avisualinteractioncueframeworkfromvideogame
1109/TVCG.2023.3327361.2 environmentsforaugmentedreality. InProceedingsofthe2018CHI
ConferenceonHumanFactorsinComputingSystems(NewYork,2018),
[AWG∗15] AHNJ.,WILLIAMSONJ.,GARTRELLM.,HANR.,LVQ., CHI ’18, ACM, p. 1–12. URL: https://doi.org/10.1145/
MISHRA S.: SupportingHealthyGroceryShoppingviaMobileAug- 3173574.3173714,doi:10.1145/3173574.3173714.3
mented Reality. ACM Transactions on Multimedia Computing, Com-
munications, and Applications 12, 1s (2015), 16:1–16:24. doi:10. [EBC∗21] ENS B., BACH B., CORDEIL M., ENGELKE U., SERRANO
1145/2808207.2,3 M.,WILLETTW.,PROUZEAUA.,ANTHESC.,BÜSCHELW.,DUNNE
C., DWYER T., GRUBERT J., HAGA J. H., KIRSHENBAUM N.,
[BKT∗22] BRESSA N., KORSGAARD H., TABARD A., HOUBEN S., KOBAYASHID.,LINT.,OLAOSEBIKANM.,POINTECKERF.,SAFFO
VERMEULEN J.: What’stheSituationwithSituatedVisualization?A D., SAQUIB N., SCHMALSTIEG D., SZAFIR D. A., WHITLOCK M.,
Survey and Perspectives on Situatedness. IEEE Trans. Visual Com- YANG Y.: Grand challenges in immersive analytics. In Proceedings
put.Graphics28,1(2022),107–117. doi:10.1109/TVCG.2021. ofthe2021CHIConferenceonHumanFactorsinComputingSystems
3114835.1,3 (2021).doi:10.1145/3411764.3446866.2
[BNC∗03] BOWMAND.A.,NORTHC.,CHENJ.,POLYSN.F.,PYLA [EST16] ELSAYEDN.A.M.,SMITHR.T.,THOMASB.H.: HORUS
P.S.,YILMAZU.:Information-richvirtualenvironments:Theory,tools, EYE:SeetheInvisibleBirdandSnakeVisionforAugmentedReality
andresearchagenda. InProceedingsoftheACMSymposiumonVirtual InformationVisualization. In2016IEEEInternationalSymposiumon
RealitySoftwareandTechnology(NewYork,2003),VRST’03,ACM, MixedandAugmentedReality(ISMAR-Adjunct)(2016),IEEE,pp.203–
p.81–90.doi:10.1145/1008653.1008669.3 208.doi:10.1109/ISMAR-Adjunct.2016.0077.3
[BPR20] BÜTTNER S., PRILLA M., RÖCKER C.: AugmentedReality [ETM∗15] ELSAYED N., THOMAS B., MARRIOTT K., PIANTADOSI
TrainingforIndustrialAssemblyWork-AreProjection-basedARAs- J., SMITH R.: SituatedAnalytics. In2015BigDataVisualAnalytics
sistiveSystemsanAppropriateToolforAssemblyTraining?InProceed- (BDVA)(USA,2015),IEEE,pp.1–8. doi:10.1109/BDVA.2015.
ingsofthe2020CHIConferenceonHumanFactorsinComputingSys- 7314302.1,2,3
tems(NewYork,2020),ACM,pp.1–12. doi:10.1145/3313831.
3376720.5 [ETM∗16] ELSAYED N. A. M., THOMAS B. H., MARRIOTT K., PI-
ANTADOSIJ.,SMITHR.T.:SituatedAnalytics:Demonstratingimmer-
[BR03] BAUDISCH P., ROSENHOLTZ R.: Halo: A technique for vi- siveanalyticaltoolswithAugmentedReality. J.Vis.Lang.Comput.36,
sualizing off-screen objects. In Proceedings of the SIGCHI Confer- C(2016),13–23.doi:10.1016/j.jvlc.2016.07.006.1,2
ence on Human Factors in Computing Systems (2003), p. 481–488.
doi:10.1145/642611.642695.3 [FMS93] FEINER S., MACINTYRE B., SELIGMANN D.: Knowledge-
basedaugmentedreality.Commun.ACM36,7(jul1993),53–62.doi:
[BSEN18] BORK F., SCHNELZER C., ECK U., NAVAB N.: Towards 10.1145/159544.159587.10
efficientvisualguidanceinlimitedfield-of-viewhead-mounteddisplays.
IEEETrans.VisualComput.Graphics24,11(2018),2983–2992.doi: [FP21] FONNET A., PRIÉ Y.: Survey of Immersive Analytics. IEEE
10.1109/TVCG.2018.2868584.3
Trans.VisualComput.Graphics27,3(Mar.2021),2101–2122. doi:
10.1109/TVCG.2019.2929033.2
[BTOX06] BIOCCAF.,TANGA.,OWENC.,XIAOF.:Attentionfunnel:
Omnidirectional3dcursorformobileaugmentedrealityplatforms. In
[GAM18] GROGORICK S., ALBUQUERQUE G., MAGNOR M.: Gaze
guidanceinimmersiveenvironments. In2018IEEEConferenceonVir-
ProceedingsoftheSIGCHIConferenceonHumanFactorsinComputing
tualRealityand3DUserInterfaces(VR)(2018),pp.563–564. doi:
Systems(2006),p.1115–1122.doi:10.1145/1124772.1124939.
10.1109/VR.2018.8446215.3
3
[CC07] COLLINS C., CARPENDALE S.: VisLink:RevealingRelation-
[GCC17] GUTWIN C., COCKBURN A., COVENEY A.: Peripheral
Popout:TheInfluenceofVisualAngleandStimulusIntensityonPopout
shipsAmongstVisualizations. IEEETrans.VisualComput.Graphics
Effects. InProceedingsofthe2017CHIConferenceonHumanFactors
13,6(2007),1192–1199.doi:10.1109/TVCG.2007.70521.3
inComputingSystems(NewYork,2017),CHI’17,ACM,pp.208–219.
[CCD∗17] CORDEIL M., CUNNINGHAM A., DWYER T., THOMAS doi:10.1145/3025453.3025984.4
B. H., MARRIOTT K.: ImAxes: Immersive Axes as Embodied Af-
fordancesforInteractiveMultivariateDataVisualisation. InProceed-
[GCOK21] GRANDI J. G., CAO Z., OGREN M., KOPPER R.: Design
andsimulationofnext-generationaugmentedrealityuserinterfacesin
ingsUserInterfaceSoftwareandTechnology(NewYork,2017),ACM,
virtualreality.In2021IEEEConferenceonVirtualRealityand3DUser
pp.71–83.doi:10.1145/3126594.3126613.4
InterfacesAbstractsandWorkshops(VRW)(2021),pp.23–29. doi:
[CFSS23] CALEPSO A. S., FLECK P., SCHMALSTIEG D., SEDLMAIR 10.1109/VRW52623.2021.00011.3
M.: Exploring Augmented Reality for Situated Analytics with Many
[GGL∗14] GRATZL S., GEHLENBORG N., LEX A., PFISTER H.,
Movable Physical Referents. In Proceedings of the 29th ACM Sym-
STREITM.:Domino:Extracting,Comparing,andManipulatingSubsets
posiumonVirtualRealitySoftwareandTechnology(NewYork,2023),
AcrossMultipleTabularDatasets.IEEETrans.VisualComput.Graphics
VRST’23,ACM,pp.1–12.doi:10.1145/3611659.3615700.3,
20,12(2014),2023–2032. doi:10.1109/TVCG.2014.2346260.
10
3
[CKB09] COCKBURNA.,KARLSONA.,BEDERSONB.B.:Areviewof [GLH∗18] GRUENEFELD U., LANGE D., HAMMER L., BOLL S.,
overview+detail,zooming,andfocus+contextinterfaces. ACMComput.
HEUTENW.: FlyingARrow:PointingTowardsOut-of-ViewObjectson
Surv.41,1(jan2009).doi:10.1145/1456650.1456652.2,3
AugmentedRealityDevices. InProceedingsofthe7thACMInterna-
[Cum14] CUMMINGG.: Thenewstatistics:Whyandhow. Psycholog- tionalSymposiumonPervasiveDisplays(NewYork,2018),PerDis’18,
icalScience25,1(2014),7–29. PMID:24220629. doi:10.1177/ ACM,pp.1–6.doi:10.1145/3205873.3205881.1,3,4,9
0956797613504966.7
[GSL∗14] GEYMAYER T., STEINBERGER M., LEX A., STREIT M.,
[DARS23] DOERRN.,ANGERBAUERK.,REINELTM.,SEDLMAIRM.: SCHMALSTIEG D.: Show me the invisible: Visualizing hidden con-
Bees,birdsandbutterflies:Investigatingtheinfluenceofdistractorson tent. InProceedingsoftheSIGCHIConferenceonHumanFactorsin
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.12of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
ComputingSystems(NewYork,2014),CHI’14,ACM,pp.3705–3714. Theroleoflatencyinthevalidityofarsimulation. In2010IEEEVir-
doi:10.1145/2556288.2557032.3 tualRealityConference(VR)(2010),pp.11–18. doi:10.1109/VR.
2010.5444820.3
[Har06] HARTS.G.:Nasa-taskloadindex(nasa-tlx);20yearslater.Pro-
ceedingsoftheHumanFactorsandErgonomicsSocietyAnnualMeeting [LBHB09] LEEC.,BONEBRAKES.,HOLLERERT.,BOWMAND.A.:
50,9(2006),904–908.doi:10.1177/154193120605000909.5 Areplicationstudytestingthevalidityofarsimulationinvrforcon-
trolled experiments. In 2009 8th IEEE International Symposium on
[HR07] HEER J., ROBERTSON G.: AnimatedTransitionsinStatistical MixedandAugmentedReality(2009),pp.203–204. doi:10.1109/
DataGraphics.IEEETrans.VisualComput.Graphics13,6(Nov.2007),
ISMAR.2009.5336464.3,10
1240–1247.doi:10.1109/TVCG.2007.70539.9
[LDG∗21] LISLE L., DAVIDSON K., GITRE E. J., NORTH C., BOW-
[HRD∗19] HURTER C., RICHE N. H., DRUCKER S. M., CORDEIL MAN D. A.: SensemakingStrategieswithImmersiveSpacetoThink.
M.,ALLIGIERR.,VUILLEMOTR.: Fiberclay:Sculptingthreedimen- In2021IEEEVirtualRealityand3DUserInterfaces(VR)(Mar.2021),
sionaltrajectoriestorevealstructuralinsights.IEEETrans.VisualCom- pp.529–537.doi:10.1109/VR50410.2021.00077.2
put.Graphics25(12019),704–714. doi:10.1109/TVCG.2018.
2865191.10 [LHC∗21] LEE B., HU X., CORDEIL M., PROUZEAU A., JENNY B.,
DWYER T.: Shared Surfaces and Spaces: Collaborative Data Visual-
[JHPR11] JO H., HWANG S., PARK H., RYU J.-H.: Aroundplot:Fo- isation in a Co-located Immersive Environment. IEEE Trans. Visual
cus+contextinterfaceforoff-screenobjectsin3denvironments. Com- Comput.Graphics27,2(2021),1171–1181. doi:10.1109/TVCG.
puters&Graphics35,4(2011),841–853.Semantic3DMediaandCon- 2020.3030450.2,4
tent.doi:10.1016/j.cag.2011.04.005.3
[LKM∗17] LAVIOLA J. J., KRUIJFF E., MCMAHAN R. P., BOWMAN
[JLB∗00] JULIER S., LANZAGORTA M., BAILLOT Y., ROSENBLUM D., POUPYREV I. P.: 3D User Interfaces: Theory and Practice.
L., FEINER S., HOLLERER T., SESTITO S.: Informationfilteringfor Addison-WesleyProfessional,2017.2
mobile augmented reality. In Proceedings IEEE and ACM Interna-
[LPED20] LIUJ.,PROUZEAUA.,ENSB.,DWYERT.:DesignandEval-
tionalSymposiumonAugmentedReality(ISAR2000)(2000),pp.3–11.
uation of Interactive Small Multiples Data Visualisation in Immersive
doi:10.1109/ISAR.2000.880917.10
Spaces. In2020IEEEConferenceonVirtualRealityand3DUserIn-
[KCWK20] KREKHOVA.,CMENTOWSKIS.,WASCHKA.,KRÜGERJ.: terfaces (VR) (Atlanta, 2020), IEEE, pp. 588–597. doi:10.1109/
Deadeyevisualizationrevisited:Investigationofpreattentivenessandap- VR46266.2020.00081.2
plicabilityinvirtualenvironments. IEEETrans.VisualComput.Graph- [LRM∗13] LEEC.,RINCONG.A.,MEYERG.,HÖLLERERT.,BOW-
ics26,1(2020),547–557. doi:10.1109/TVCG.2019.2934370.
MAND.A.: Theeffectsofvisualrealismonsearchtasksinmixedre-
3
alitysimulation. IEEETrans.VisualComput.Graphics19,4(2013),
[Kei02] KEIM D. A.: Information visualization and visual data min- 547–556.doi:10.1109/TVCG.2013.41.3,10
ing. IEEE Trans. Visual Comput. Graphics 8, 1 (2002), 1–8. doi: [LSGB20] LANGED.,STRATMANNT.C.,GRUENEFELDU.,BOLLS.:
10.1109/2945.981847.2,5 Hivefive:Immersionpreservingattentionguidanceinvirtualreality. In
[KFS∗22] KRAUS M., FUCHS J., SOMMER B., KLEIN K., ENGELKE Proceedingsofthe2020CHIConferenceonHumanFactorsinComput-
U., KEIM D., SCHREIBER F.: Immersive analytics with abstract 3d ingSystems(2020).doi:10.1145/3313831.3376803.3
visualizations:Asurvey. ComputerGraphicsForum41,1(2022),201– [LSS23] LEE B., SEDLMAIR M., SCHMALSTIEG D.: DesignPatterns
229.doi:https://doi.org/10.1111/cgf.14430.2 for Situated Visualization in Augmented Reality. IEEE Trans. Visual
[KKO∗14] KISHISHITAN.,KIYOKAWAK.,ORLOSKYJ.,MASHITAT., Comput.Graphics30,1(2023),1–12.doi:10.1109/TVCG.2023.
3327398.1,2
TAKEMURA H., KRUIJFF E.: Analysingtheeffectsofawidefieldof
view augmented reality display on search performance in divided at- [LYBP23] LINT.,YANGY.,BEYERJ.,PFISTERH.: LabelingOut-of-
tention tasks. In 2014 IEEE International Symposium on Mixed and ViewObjectsinImmersiveAnalyticstoSupportSituatedVisualSearch-
Augmented Reality (ISMAR) (2014), pp. 177–186. doi:10.1109/ ing. IEEETrans.VisualComput.Graphics29,3(2023),1831–1844.
ISMAR.2014.6948425.3 doi:10.1109/TVCG.2021.3133511.1,2,4
[KMH01] KOSARA R., MIKSCH S., HAUSER H.: Semantic depth of [ML14] MCINTIRE J. P., LIGGETT K. K.: The (possible) utility of
field.InIEEESymposiumonInformationVisualization,2001.INFOVIS stereoscopic 3d displays for information visualization: The good, the
2001.(2001),pp.97–104.doi:10.1109/INFVIS.2001.963286. bad,andtheugly. In2014IEEEVISInternationalWorkshopon3DVis
3,4 (3DVis)(2014),pp.1–9. doi:10.1109/3DVis.2014.7160093.
2
[KPV∗18] KOYTEK P., PERIN C., VERMEULEN J., ANDRÉ E.,
CARPENDALE S.: MyBrush: Brushing and Linking with Personal [MM21] MA Q., MILLET B.: Design guidelines for immersive dash-
Agency. IEEETrans.VisualComput.Graphics24,1(2018),605–615. boards. Proceedings of the Human Factors and Ergonomics So-
doi:10.1109/TVCG.2017.2743859.2,3 ciety Annual Meeting 65, 1 (2021), 1524–1528. doi:10.1177/
1071181321651177.1
[KR14] KASAHARAS.,REKIMOTOJ.: JackIn:Integratingfirst-person
viewwithout-of-bodyvisiongenerationforhuman-humanaugmenta- [MSD∗18] MARRIOTT K., SCHREIBER F., DWYER T., KLEIN K.,
tion. InProceedingsofthe5thAugmentedHumanInternationalCon- HENRYRICHEN.,ITOHT.,STUERZLINGERW.,THOMASB.H.:Im-
ference(NewYork,2014),AH’14,ACM,pp.1–8. doi:10.1145/ mersiveAnalytics. LectureNotesinComputerScience.SpringerInter-
2582051.2582097.3 nationalPublishing,2018. doi:10.1007/978-3-030-01388-2.
2
[KS auF g1 m0] enteK dRU reI aJ lF iF tyE r. e, viS siW teA dN
.
J I. nE 2. 0, 1F 0E II EN EER ES In. t: ernP ae tr ic oe np at lua Sl ymiss pu oe ss iui mn [MTE∗20] MARQUARDTA.,TREPKOWSKIC.,EIBICHT.D.,MAIERO
onMixedandAugmentedReality(2010),pp.3–12. doi:10.1109/ J.,KRUIJFFE.,SCHÖNINGJ.: Comparingnon-visualandvisualguid-
ISMAR.2010.5643530.2
ancemethodsfornarrowfieldofviewaugmentedrealitydisplays.IEEE
Trans. Visual Comput. Graphics 26, 12 (2020), 3389–3401. doi:
[KVZ∗13] KALKOFEN D., VEAS E., ZOLLMANN S., STEINBERGER 10.1109/TVCG.2020.3023605.3
M.,SCHMALSTIEGD.:AdaptiveghostedviewsforAugmentedReality.
In2013IEEEInternationalSymposiumonMixedandAugmentedRe-
[PKB05] POLYS N. F., KIM S., BOWMAN D. A.: Effects of infor-
mation layout, screen size, and field of view on user performance in
ality(ISMAR)(Oct.2013),pp.1–9. doi:10.1109/ISMAR.2013.
information-richvirtualenvironments. ProceedingsoftheACMSympo-
6671758.3
siumonVirtualRealitySoftwareandTechnology,VRST(2005),46–55.
[LBBH10] LEEC.,BONEBRAKES.,BOWMAND.A.,HÖLLERERT.: doi:10.1145/1101616.1101626.3
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking 13of14
[PLE∗19] PROUZEAU A., LHUILLIER A., ENS B., WEISKOPF D., Augmented Reality Adjunct (USA, 2022), IEEE, pp. 146–154. doi:
DWYER T.: Visual Link Routing in Immersive Visualisations. In 10.1109/ISMAR-Adjunct57072.2022.00035.2
Proceedingsofthe2019ACMInternationalConferenceonInteractive
[TEM∗19] TREPKOWSKIC.,EIBICHD.,MAIEROJ.,MARQUARDTA.,
SurfacesandSpaces(NewYork,2019),ISS’19,ACM,pp.241–253.
doi:10.1145/3343055.3359709.3
KRUIJFFE.,FEINERS.: Theeffectofnarrowfieldofviewandinfor-
mationdensityonvisualsearchperformanceinaugmentedreality. In
[PZB∗23] PIETSCHMANNL.,ZÜRCHERP.,BUBIKE.,CHENZ.,PFIS- 2019IEEEConferenceonVirtualRealityand3DUserInterfaces(VR)
TERH.,BOHNÉT.: QuantifyingtheImpactofXRVisualGuidanceon (2019),pp.575–584.doi:10.1109/VR.2019.8798312.3
UserPerformanceUsingaLarge-ScaleVirtualAssemblyExperiment.In
2023IEEEVisualizationandVisualAnalytics(VIS)(Oct.2023),IEEE
[TK06] TONNIS M., KLINKER G.: Effective control of a car driver’s
ComputerSociety,pp.211–215.doi:10.1109/VIS54172.2023. attentionforvisualandacousticguidancetowardsthedirectionofim-
00051.2
minentdangers.In2006IEEE/ACMInternationalSymposiumonMixed
andAugmentedReality(2006),pp.13–22. doi:10.1109/ISMAR.
[RBR22] ROBERTS J. C., BUTCHER P. W., RITSOS P. D.: Oneview 2006.297789.3
isnotenough:Reviewofandencouragementformultipleandalterna-
tiverepresentationsin3dandimmersivevisualisation. Computers11(2 [TMB02] TVERSKYB.,MORRISONJ.B.,BETRANCOURTM.:Anima-
2022),20.doi:10.3390/COMPUTERS11020020.2 tion:Canitfacilitate?InternationalJournalofHuman-ComputerStudies
57,4(Oct.2002),247–262.doi:10.1006/ijhc.2002.1017.9
[Rob07] ROBERTSJ.C.: Stateoftheart:Coordinated&multipleviews
inexploratoryvisualization. InFifthInternationalConferenceonCo- [TOK∗16] TATZGERN M., ORSO V., KALKOFEN D., JACUCCI G.,
ordinatedandMultipleViewsinExploratoryVisualization(CMV2007) GAMBERINIL.,SCHMALSTIEGD.: Adaptiveinformationdensityfor
(USA, 2007), IEEE Computer Society, pp. 61–71. doi:10.1109/ augmentedrealitydisplays. In2016IEEEVirtualReality(VR)(USA,
CMV.2007.20.2,3,6 2016),IEEE,pp.83–92.doi:10.1109/VR.2016.7504691.3,10
[RPA∗22] RICHER G., PISTER A., ABDELAAL M., FEKETE J.-D., [TWD∗18] THOMASB.H.,WELCHG.F.,DRAGICEVICP.,ELMQVIST
SEDLMAIR M., WEISKOPF D.: Scalability in visualization. IEEE N.,IRANIP.,JANSENY.,SCHMALSTIEGD.,TABARDA.,ELSAYED
Trans.VisualComput.Graphics(2022),1–15.doi:10.1109/TVCG. N. A. M., SMITH R. T., WILLETT W.: Situated analytics. In Im-
2022.3231230.5 mersiveAnalytics,MarriottK.,SchreiberF.,DwyerT.,KleinK.,Riche
[RWBH09] RAGANE.,WILKESC.,BOWMAND.A.,HOLLERERT.: N. H., Itoh T., Stuerzlinger W., Thomas B. H., (Eds.). Springer In-
Simulationofaugmentedrealitysystemsinpurelyvirtualenvironments. ternational Publishing, Cham, 2018, pp. 185–220. doi:10.1007/
In Proceedings of the 2009 IEEE Virtual Reality Conference (2009), 978-3-030-01388-2_7.1
p.287–288.doi:10.1109/VR.2009.4811058.3 [Ver02] VERTEGAAL R.: Designing attentive interfaces. In Proceed-
[SBB∗23] SHIN S., BATCH A., BUTCHER P. W. S., RITSOS P. D., ingsofthe2002SymposiumonEyeTrackingResearch&Applications
ELMQVISTN.: TheRealityoftheSituation:ASurveyofSituatedAn- (2002),p.23–30.doi:10.1145/507072.507077.2
alytics. IEEE Trans. Visual Comput. Graphics (2023), 1–19. doi: [VMFS11] VEASE.E.,MENDEZE.,FEINERS.K.,SCHMALSTIEGD.:
10.1109/TVCG.2023.3285546.1,2
Directingattentionandinfluencingmemorywithvisualsaliencymodu-
[SBDE23] SAFFOD.,BATCHA.,DUNNEC.,ELMQVISTN.: Through lation. InProceedingsoftheSIGCHIConferenceonHumanFactorsin
TheirEyesandInTheirShoes:ProvidingGroupAwarenessDuringCol- ComputingSystems(NewYork,May2011),CHI’11,ACM,pp.1471–
laborationAcrossVirtualRealityandDesktopPlatforms. InProceed- 1480.doi:10.1145/1978942.1979158.3
ingsofthe2023CHIConferenceonHumanFactorsinComputingSys-
tems(NewYork,2023),CHI’23,ACM,pp.1–15. doi:10.1145/
[WF09] WHITE S., FEINER S.: SiteLens:Situatedvisualizationtech-
niques for urban site visits. In Proceedings of the SIGCHI Confer-
3544548.3581093.2
enceonHumanFactorsinComputingSystems(NewYork,2009),ACM,
[SCZ∗20] SIDENMARK L., CLARKE C., ZHANG X., PHU J., pp.1117–1120.doi:10.1145/1518701.1518871.1,2
GELLERSENH.: OutlinePursuits:Gaze-assistedSelectionofOccluded
ObjectsinVirtualReality. InProceedingsofthe2020CHIConference
[WGRF22] WIELAND J., GARCIA R. C. H., REITERER H., FEUCHT-
onHumanFactorsinComputingSystems(NewYork,2020),CHI’20, NER T.: Arrow, bézier curve, or halos? – comparing 3d out-of-view
ACM,pp.1–13.doi:10.1145/3313831.3376438.3,10 objectvisualizationtechniquesforhandheldaugmentedreality. In2022
IEEE International Symposium on Mixed and Augmented Reality (IS-
[SD21] SATKOWSKIM.,DACHSELTR.:Investigatingtheimpactofreal- MAR)(2022),pp.797–806. doi:10.1109/ISMAR55827.2022.
worldenvironmentsontheperceptionof2dvisualizationsinaugmented 00098.3,4,9
reality. InProceedingsofthe2021CHIConferenceonHumanFactors
inComputingSystems(NewYork,2021),CHI’21,ACM. doi:10. [WJD17] WILLETTW.,JANSENY.,DRAGICEVICP.: EmbeddedData
1145/3411764.3445330.2 Representations. IEEETrans.VisualComput.Graphics23,1(2017),
461–470.doi:10.1109/TVCG.2016.2598608.1,2
[SH16] SCHMALSTIEGD.,HÖLLERERT.: AugmentedReality-Princi-
plesandPractice.Addison-WesleyProfessional,2016.2 [WSS20] WHITLOCK M., SMART S., SZAFIR D. A.: Graphical per-
ception for immersive analytics. In 2020 IEEE Conference on Vir-
[SL00] SUOMELAR.,LEHIKOINENJ.: ContextCompass. InDigestof
tualRealityand3DUserInterfaces(VR)(2020),pp.616–625. doi:
Papers.FourthInternationalSymposiumonWearableComputers(Oct.
10.1109/VR46266.2020.00084.3
2000),IEEEComputerSociety,pp.147–147. doi:10.1109/ISWC.
2000.888481.3 [WVEG11] WOLFE J. M., VÕ M. L.-H., EVANS K. K., GREENE
[SLC∗19] SICAT R., LI J., CHOI J., CORDEIL M., JEONG W.-K., M. R.: Visual search in scenes involves selective and nonselective
BACHB.,PFISTERH.: DXR:AToolkitforBuildingImmersiveData pathways. Trends in Cognitive Sciences 15, 2 (2011), 77–84. doi:
Visualizations.IEEETrans.VisualComput.Graphics25,1(2019),715– 10.1016/j.tics.2010.12.001.2
725.doi:10.1109/TVCG.2018.2865152.4 [YLF∗20] YU D., LIANG H.-N., FAN K., ZHANG H., FLEMING C.,
[SLQS23] SAYARA A., LEE B., QUIJANO-CHAVEZ C., SEDLMAIR PAPANGELISK.: Designandevaluationofvisualizationtechniquesof
M.: Designing Situated Dashboards: Challenges and Opportunities. off-screenandoccludedtargetsinvirtualrealityenvironments. IEEE
In2023IEEEInternationalSymposiumonMixedandAugmentedRe- Trans.VisualComput.Graphics26,9(2020),2762–2774. doi:10.
alityAdjunct(ISMAR-Adjunct)(2023),pp.97–102. doi:10.1109/ 1109/TVCG.2019.2905580.3,4,9
ISMAR-Adjunct60411.2023.00028.1
[YLS24] YUX.,LEEB.,SEDLMAIRM.:DesignSpaceofVisualFeed-
[SS22] SERAJI M. R., STUERZLINGER W.: XVCollab: An Immer- forwardAndCorrectiveFeedbackinXR-BasedMotionGuidanceSys-
sive Analytics Tool for Asymmetric Collaboration across the Virtual- tems,Feb.2024.arXiv:2402.09182,doi:10.1145/3613904.
ity Spectrum. In 2022 IEEE International Symposium on Mixed and 3642143.2
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.14of14 N.Doerr,B.Lee,K.Baricova,D.Schmalstieg&M.Sedlmair/VisualHighlightingforSituatedBrushingandLinking
[ZLG∗21] ZOLLMANN S., LANGLOTZ T., GRASSET R., LO W. H.,
MORI S., REGENBRECHT H.: Visualizationtechniquesinaugmented
reality:Ataxonomy,methodsandpatterns.IEEETrans.VisualComput.
Graphics 27, 9 (2021), 3808–3825. doi:10.1109/TVCG.2020.
2986247.2
©2024TheAuthors.
ComputerGraphicsForumpublishedbyEurographicsandJohnWiley&SonsLtd.