Language Models in Dialogue:
Conversational Maxims for Human-AI Interactions
ErikMiehling,ManishNagireddy,PrasannaSattigeri
ElizabethM.Daly,DavidPiorkowski, and JohnT.Richards
IBMResearch
Abstract andreinforcementlearningfromhumanfeedback
(RLHF) encourage models to provide an answer
Modernlanguagemodels,whilesophisticated, at all costs (Agüera y Arcas, 2022), even when
exhibit some inherent shortcomings, particu-
seekingclarificationwouldimproveresponsequal-
larlyinconversationalsettings. Weclaimthat
ity. Models rarely say “I don’t know” which can
manyoftheobservedshortcomingscanbeat-
leadtounrelenting“helpfulness”wherethemodel
tributedtoviolationofoneormoreconversa-
tionalprinciples. Bydrawinguponextensive enters cycles of incorrect suggestions/responses
research from both the social science and AI (Moskovitz et al., 2023; Zhai et al., 2023). Addi-
communities, we propose a set of maxims – tionally,thereisgrowingevidencethatinstruction
quantity, quality, relevance, manner, benevo- tuning increases model sycophancy, i.e., the ten-
lence, and transparency – for describing ef-
dency for model outputs to mirror or agree with
fective human-AI conversation. We first jus-
input bias (Cotra, 2021; Perez et al., 2022; Rad-
tify the applicability of the first four maxims
hakrishnanetal.,2023;Sharmaetal.,2023;Wei
(from Grice) in the context of human-AI in-
etal.,2023).
teractions. We then argue that two new max-
ims, benevolence (concerning the generation Ourpaperisbasedontheclaimthatmanyofthe
of,andengagementwith,harmfulcontent)and observedshortcomingsofcurrentmodelscanbeat-
transparency(concerningrecognitionofone’s
tributedtoviolationofoneormoreconversational
knowledgeboundaries,operationalconstraints,
principles. For instance, relating to clarification,
andintents), arenecessaryforaddressingbe-
humansoftenpartakein“collectiveacts”toform
havior unique to modern human-AI interac-
commonground,buildtrust,andavoidmisunder-
tions. Theproposedmaximsofferprescriptive
guidanceonhowtoassessconversationalqual- standings (Stalnaker, 1978; Clark and Schaefer,
itybetweenhumansandLLM-drivenconversa- 1989). Thebehaviorofcurrentmodelsproviding
tionalagents,informingboththeirevaluation an answer even when uncertain fails in both this
andimproveddesign.
respectandthemaximofrelevance,acornerstone
ofGrice’soriginalmaximsfordescribingeffective
1 Introduction
humancommunication(Grice,1975). Additionally,
Modernlanguagemodelsaimforinteractionthat sycophancycanbeviewed,inpart,asafailureof
is as natural as possible. To help achieve this, theneedto“repair”misunderstandings(Traumand
pre-trainedmodelsundergoarefinementprocess, Hinkelman, 1992). The main focus of our paper
termedsupervisedfine-tuning,whichinvolvesup- istodefinethesetofconversationalprinciples,or
dating the model’s weights using human-labeled maxims,thatareinviolationwhenmodelsexhibit
data. Apartfromhelpingtofilteroutsomeundesir- thesedeficiencies.
ablecharacteristics,thisprocessallowsthemodels This paper makes the following contributions:
to better capture the nuances of human language (1) We propose a set of prescriptive maxims for
andconversation,improvingtheirabilitytounder- analyzinghuman-AIconversations;and(2)Aspart
stand context and respond in a way that is more of the construction of our maxims, we provide a
alignedwithhowhumanscommunicate. reviewofbothdesirablecharacteristicsofhuman
Whilefine-tuningdoesgreatlyimprovethecon- conversation(fromthesocialsciencescommunity)
versationalcapabilityoflanguagemodels,current and the current undesirable properties of modern
approachescancausesomeundesirableproperties language models (from the AI community). Our
to emerge. The processes of instruction tuning proposedmaximsaimtoclearlydefinewhatcon-
4202
raM
22
]LC.sc[
1v51151.3042:viXrastituteseffectivecommunicationbetweenahuman for“refinementandrepair”;and(Nametal.,2023)
userandanAIassistant,enablingamoreprincipled attributeanAI’s“mistakenutterances”asbreaches
analysis of conversational models and ultimately ofparticularmaxims. Otherworksfocusondefin-
informingimprovedmodeldesigns. ing (and evaluating) productive conversations in
specificdomains,namelycustomerservice,where
2 RelatedWork interactions are measured via repetition of utter-
ances,emotionalindicators,andrequestsforahu-
Ourworkconcernsthedevelopmentofprinciples, man(Sandbanketal.,2017;Weiszetal.,2019).
or maxims, that aim to quantify good interaction
LargeLanguageModels. Thedevelopmentofthe
inhuman-AIconversations. Weofferareviewof
generativepre-trainedtransformer(GPT)architec-
conversational analysis, from both the social sci-
ture (Radford et al., 2018), gave rise to what we
enceandAIcommunities,anddiscusssomeofthe
knowtodayaslargelanguagemodels(LLMs),un-
associatedmeasuresofeffectiveconversation.
deniably the most capable class of AI language
HumanConversations. Analysisofhumancon- models to date. With this capability has come
versationalstructurehasalonghistory,withorigins greaterintegrationwithsociety,inturncallingfor
inlinguistics,philosophy,psychology,andcogni- theconstructionofprinciplesthatnotonlydescribe
tive science. One of the most prominent frame- thefunctionalaspectsofconversation(i.e.,asde-
worksintheliteratureisGrice’scooperativeprin- scribed by the aforementioned usability metrics)
ciple (Grice, 1975) and the associated maxims of but also inform ethical interaction with humans.
conversation(quantity,quality,relation,andman- Thisinvestigationisofparticularimportancegiven
ner),whichcontributedfundamentallytothefield that,unlikeindialoguesystemswheredevelopers
of pragmatics by providing theoretical tools for largelyhadcontroloverboththespaceofoutputs
relatingutterancestomeaning. However,themax- and the flow of interactions (Moore,2018; Ashk-
imshavealsofacedcriticism(SperberandWilson, torabetal.,2019;Zhengetal.,2022;Mooreetal.,
1986;Wierzbicka,2003),withsomearguingthat 2023),theoutputsoflanguagemodelsaremostly
theyaretoovaguetobeuseful(Keenan,1976;Fred- uncontrolled.1
erking,1996),andothersquestioningtheirapplica- Whiletherehasbeenconsiderableeffortonpost-
bilitytononcooperativeand“unequalencounters” hoc minimization of harms (Kumar et al., 2022),
where the goals of the conversation participants thereissignificantlylessworkonattemptstocon-
may conflict (Harris, 1995; Thornborrow, 2014). struct rules for good conversational interaction
Theliteraturegenerallyagreesthat,giventherich- between humans and LLMs. Early work in this
nessanddiversityofhumanconversation,attempt- area (Evans et al., 2021) focused on quantifying
ing to impose general rules of good interaction truthfulness of conversational AI (in the context
presentssignificantchallenges. of GPT-3), arguing that it should avoid stating
“negligent falsehoods” requiring not only access
Chatbots,DialogueSystems,&VoiceAssistants.
totheavailableinformationbutalsotheAI’sability
ConversationalanalysisintheAIcommunityhas
to“understandthetopicunderdiscussion.” More
primarilybeenguidedbythedevelopmentofcon-
recently, (Kasirzadeh and Gabriel, 2023) studied
versational agents (CAs), i.e., chatbots, dialogue
three types of requirements for human-AI inter-
systems,andvoiceassistants. Aspartoftheirde-
actions (syntactic, semantic, and pragmatic) and
signs,practitionershavedevelopedusabilitymet-
discussed the properties of ideal conversation in
ricsthataimtoquantifygoodperformance,e.g.,co-
three “discursive domains”: scientific discourse,
herence,engagingness,diversity,informativeness,
democraticdebate,andcreativestorytelling. The
andoveralldialoguequality(Dzirietal.,2019). Be-
authors suggest that “the Gricean maxims ... can
yond usability metrics, multiple analyses of CAs
have general value within cooperative linguistic
are grounded in Grice’s maxims – (Panfili et al.,
conversationsbetweenhumansandconversational
2021)analyzesusers’interactionswithAmazon’s
agents” but emphasize that some of the maxims
Alexaandarguesforanadditionalmaximofprior-
(particularlyquality)canbesignificantlycontext-
itytoreflectthe“inherentpowerdifferencebetween
dependent. The present work contributes to this
humans and AIs”; (Setlur and Tory, 2022) argue
for design patterns that address “ambiguous and
1Thisgivesrisetoavarietyof,previouslyunencountered,
underspecified utterance handling” and the need issuessuchbias,toxicity,andhallucinations.growingdiscourse,offeringacomprehensivesetof intoaccounttheconversationalcontext. Informa-
maximsfordescribinggoodconversationalinterac- tion in a dialogue is revealed over multiple turns
tionbetweenhumansandAI. asparticipantsrequest(andprovide)information.
Thisrevealedcontextdefinestheneedsofthecon-
3 MaximsforHuman-AIConversations
versation,allowingagivenresponsetobeevaluated
Grice’smaximsweredevelopedforsymmetricand byjudgingiftheadditionalinformationprovided
cooperativeconversations,i.e.,twohumanpartic- by the response is adequate for these needs. For
ipants engaged in cooperative discourse. While instance,toolittleinformationmaylacksufficient
conversationsbetweenhumansandAIcanbejus- detail and lead to misunderstandings, while too
tified as being cooperative, they are clearly not muchinformationmaycauseconfusionordetract
symmetric. However,weclaimthatholdingboth fromtheprimaryrequest. Fig.1providesanevalu-
humans and AI to the same set of conversational ationofquantityforasampleconversation.
maximsestablishescommongroundandincreased
predictability,inturnencouragingmorenaturaldis- A: How much does it typically snow in New York
course. Importantly,whilewedefineauniformset City during the winter?
ofmaxims,themethodsbywhicheachparticipant B: The amount of snow can vary, but NYC has a
diverse climate. Are you planning a visit?
– human or AI – complies with the maxims may
A: Yes, I'm planning a trip in December.
differ,asdetailedfurtherinSection4.
Weproposeanaugmentedsetofmaxims–quan-
1 B: You might see some snow.
tity, quality, relevance, manner, benevolence,
and transparency – to assess conversations be- 2 B: New York City's winter weather can be quite
unpredictable due to its coastal location.
tweenhumansandAI.WefirstarguethatGrice’s Historically, snowfall has ranged widely.
originalmaxims(quantity,quality,relevance,and For example, the winter of 2009-2010 saw a
record 36.9 inches of snow in February
manner)arenecessaryinhuman-AIconversations.
alone, while other years have had
Wethenassertthattwonewmaxims,benevolence significantly less. The city's snow removal
budget has fluctuated accordingly, with
andtransparency,areessentialinaddressingsome
millions allocated each year for snow and
oftheshortcomingsinherenttocurrenthuman-AI ice removal. Additionally, the impact of
interactions. snow on the city's infrastructure and daily
life can be substantial, leading to school
Quantity. The maxim of quantity relates to the closures and delays in public
transportation. Climate change may also
amount of information contained in a given re-
affect future snowfall patterns, making
sponse. Tosatisfyquantity,aresponseshouldmeet historical data less predictive.
thefollowingrequirements: 3 B: In December, New York City averages about 4
to 6 inches of snow. However, snowfall can
(1) The response should provide a sufficient vary from year to year. It's always a good
amountofinformation. idea to check the forecast close to your
travel date for the most current
(2) Theresponseshouldnotcontainunnecessary information.
details.
Figure1:Illustrationofquantity. Thefirstexample(1)
The need for the maxim of quantity in human-
violates the sufficiency requirement, whereas the sec-
AI conversations is primarily motivated by the ondexample(2)violatestheunnecessaryinformation
tendency of language models to produce “overly requirement. Thefinalexample(3)satisfiesquantity
wordyresponses”inanattemptto“givetheimpres- via a response that answers the initial request for the
sion of expertise” (Moskovitz et al., 2023). This specificmonthinquestion.
behavior is known to arise due to reward model
over-optimization, i.e., over-fitting an imperfect
Quality. Themaximofqualitypertainstothetruth-
modelofhumanpreferences(Gaoetal.,2023).
fulnessandhonestyoftheresponse,specifically:
Themaximofquantityspecifiesthatresponses
shouldcontainanappropriateamountofinforma- (1) Theresponseshouldbefactualandsupported
tion, a definition that necessarily contains some byadequateevidencewheneverpossible.
subjectivity(giventheterms“sufficient”and“un-
necessary”). Theappropriatelevelofdetailgener- (2) The response should accurately reflect what
allycannotbeobjectivelyevaluatedwithouttaking thespeakerknowstobetrue.One of the most significant issues in current lan- honestyofanAI’sresponse,raisessomequestions
guage models is their tendency to hallucinate (Ji astowhatitmeansforanAItopossessa“belief.”
et al., 2023; Zhang et al., 2023; Xu et al., 2024). Earlierdiscussionsonthistopic(Evansetal.,2021)
Hallucinations in language models are primarily arguethatAIsytemsshouldbeevaluatedwithre-
understoodtoarisefrombothdataissues–incor- spect to truthfulness rather than honesty in order
rect referencing (Wang, 2020) and inappropriate to avoid the issues that come with assigning be-
data handling (Lee et al., 2021) – and training is- liefstoAI.However,recentresearchdemonstrates
sues–imperfectrepresentations(Aralikatteetal., that LLMs possess a type of belief, or “internal
2021),erroneousdecoding(Tianetal.,2019),and state”,whichcanbeusedtoevaluatethehonesty
avarietyofknowledgebiases(WangandSennrich, ofamodel(AzariaandMitchell,2023;Zouetal.,
2020;Longpreetal.,2021). 2023a; Liu et al., 2023a; Xu et al., 2023; Levin-
Themaximofqualityimposesrequirementson steinandHerrmann,2023;Parketal.,2023).2 We
the correctness of responses, importantly distin- arguethataslanguagemodelsbecomemoresophis-
guishing between the notions of truthfulness and ticated(e.g.,GPT-4+),theirevaluationwithrespect
honesty. Truthfulness describes an external con- to more human characteristics becomes more ap-
sistency between a response and evidence/facts, propriate.3 Thus,weimposebothtruthfulnessand
whereashonestyconcernsaninternalconsistency honestyontheconversationparticipants.
betweenaresponseandthespeaker’sknowledge. Giventhattruthfulnessconcernstheconsistency
This latter requirement necessarily endows the betweenaresponseandfacts,itcanbeevaluated
speakerwithabeliefwhich, whenevaluatingthe externally,i.e.,solelyintermsofresponses. While
evaluatinghonestyexternallyispossibleinsome
situations, e.g., via consistency checks with “hu-
manlyverifiablerules”(Flurietal.,2023),itgen-
A: Does taking green tea extract help with
weight loss? erallyrequiresaccessto,orsomeestimateof,the
B: There is some evidence that green tea extract internal state of the speaker (Burns et al., 2022;
can be beneficial for weight loss, as it may
AzariaandMitchell,2023;Zouetal.,2023a;Park
enhance metabolism [Hodgson et al., 2013].
etal.,2023). Inotherwords,evaluatinghonestyin-
A: Really? I read a blog post claiming green tea
extract doesn't really help with weight loss. herentlyimposessomerequirementsonthespeaker.
Inlightofthis,presentinganexampleconversation
1 B: Despite what some blog posts say, the that violates honesty poses some challenges. For
evidence in favor of green tea extract for
the purposes of illustrating an example, we rely
weight loss, and general health, is clear
and undisputed. on external signals to demonstrate the violation.
Model sycophancy, i.e., responses that “confirm
2 B: You might be right; perhaps green tea
extract doesn't help with weight loss. I a user’s mistaken beliefs ... over responses that
could be mistaken.
correcttheuser”(Sharmaetal.,2023),isonesuch
3 B: While there is supportive evidence for signal. SeeFig. 2foranexampleconversation.
green tea extract aiding in weight loss,
the effectiveness can vary. Not all studies Relevance. The maxim of relevance is given by
agree, and the impact may depend on one’s
thefollowingrequirements:
level of activity. It's important to look
at a range of studies and consult a
healthcare professional for personalized (1) The response should directly and relevantly
advice. addresstheotherparticipant’sstatementsin
ahelpfulmanner.
Figure 2: Illustration of quality. The first example
response(1)demonstratesaviolationoftruthfulness (2) Theresponseshouldberelevanttothecurrent
bypresentingaresponsethatmakesboldclaimswith-
topicandnotunnaturallyshifttheconversa-
outprovidingnecessaryevidence. Thesecondexample
tiontounrelatedsubjects.
(2)demonstratesaviolationofhonestybypresentinga
responseinwhichB isunnaturallyswayedbyA’sstate-
ment,possiblyindicatingadeviationfromsomeinternal 2Someofwhichmaketheadditionalclaimthatmodern
belief/state(demonstratingsycophancy). Thefinalex- modelshavethecapacitytolie(AzariaandMitchell,2023)
ample(3)avoidsbothoftheseviolationsbyproviding anddeceive(Parketal.,2023;Hubingeretal.,2024)(while
beingcarefultonotassignbeliefstotheAI).
aresponsethatisbothtruthfulandemphasizesthatthe
3Indeed, both truthfulness and honesty were a part of
answertoA’squerymaybenuanced.
Grice’soriginalmaximofquality.understandings)havelongbeenunderstoodinthe
A: How much does it cost to own a home?
socialsciencesasbeingcrucialtoeffectivehuman
B: That depends on multiple factors, including
the city, house size, neighborhood, and communication(Stalnaker,1978;ClarkandSchae-
current market conditions. Prices can vary fer,1989;Purveretal.,2003),andmorerecently
widely based on these factors.
asdesirablequalitiesforconversationalAI(Setlur
A: Oh sorry, I meant tax
andTory,2022;Shaikhetal.,2023).
Thesecondrequirementspecifiesthatresponses
1 B: When purchasing a home, you generally need
to consider the down payment, which is shouldremainontopic. Whatconstitutesbeing“on
typically 20% of the home's price, along
topic”isagaindictatedbytheconversationalcon-
with closing costs, which can range from 2%
to 5% of the loan amount. text (Reichman, 1978). Importantly, this require-
mentdoesnotrequirethatthetopicofthedialogue
2 B: Speaking of taxes, did you know that the
staysfixedthroughoutaconversation. Asstatedby
most efficient form of taxation according
to economists is land value tax? It's (Lewis,1979),“presuppositionscanbecreatedor
fascinating how it doesn't affect economic
destroyedinthecourseofaconversation”allowing
production.
forsituationswhere“subjectsofconversationare
3 B: Could you clarify what you mean by "tax"?
legitimatelychanged”(Grice,1975). Inthissense,
Are you asking about the additional tax
associated with purchasing a home, or are our requirement interprets a conversation’s topic
you referring to property taxes?
asthecurrentsubjectthatbothpartieshavemutu-
allyrecognizedasthefocusofdiscussion. Fig. 3
Figure3: Illustrationofrelevance. Example 1 showsa presentsanillustrationofrelevance.
situationwhere,ratherthanseekingclarificationforA’s
ambiguousstatement,B respondsbasedonanincorrect Manner. The maxim of manner imposes two re-
understandingthat“tax”referredtopurchasingtaxwhen quirements:
theuseractuallywasinquiringaboutpropertytaxes. Ex-
(1) The response should be clear, unambiguous,
ample 2 showsanassistantresponsethat,whilebeing
onthetopicoftaxes,unnaturallyshiftstheconversation andpresentedinawell-organizedfashion.
toatopicthatdeviatesfromtheinitialquery. Thelast
(2) The response should be accessible and use
example(3)illustratestheassistantseekingclarifica-
appropriatelanguagetailoredtothepartici-
tiontoresolvetheambiguityintheuser’sresponses.
pant’slevelofunderstanding.
Themaximofmanneriscloselyrelatedtothelin-
Gricestatesthatrelevancerequiresaparticipant’s
guisticnotionofcoherence,apropertythatensures
“contribution to be appropriate to the immediate
needs”oftheconversation(Grice,1975).4 Asdis- the logical flow and clarity of discourse (Reich-
man, 1978). While recent language models have
cussedearlier,theneedsofaconversationarede-
improvedsignificantlyinmaintainingcoherentre-
fined by the conversational context. The require-
sponses, they still face issues in long or complex
menttobehelpfultotheotherparticipant’sstate-
dialogues(Pratoetal.,2023). Onereasonforthisis
ments,asspecifiedbyourfirstrequirement,means
duetolimitedrecall,i.e.,notbeingabletoretrieve
tendingtotheseneeds. Furthermore,beingableto
information relevant to the conversational thread.
respondrelevantlyrequirescorrectlyinterpreting
Despitemodernlanguagemodels’impressivecon-
the conversational context. If a participant is un-
textlengths(OpenAI,2023;Google,2024),recent
certainaboutthemeaningoftheotherparticipant’s
testsfromtheAIcommunityillustratesignificant
statement(s),thentheseneedswillbeunclear. In
variability in recall ability, especially for content
thissense,ourfirstrequirementimplicitlyrequires
nearthemiddleofthecontextwindow(Kamradt,
thatparticipantsseekclarificationinordertoavoid
2023;Liuetal.,2023b).
anymisunderstandings. Intheeventthatanymis-
Themaximofmanner(particularlyclarity)may
understandingsdoemerge,participantsshouldaim
initiallyappearverysimilartothemaximofquan-
to“repair”themtoregainacorrectinterpretation
tity. However,asstatedby(Susanto,2018),quan-
(Traum and Hinkelman, 1992). These grounding
tity evaluates if a response contains the required
acts(e.g.,seekingclarificationandrepairingmis-
“units of information” whereas manner evaluates
4Grice’sdefinitionofthemaximofrelevance(originally howefficientlytheseunitsofinformationarecon-
presentedasthemaximofrelation)simplyimposesthatre-
veyed. Itispossibletoviolatequantitywhilesat-
sponses“berelevant.”Wedecomposethisdefinitionintoour
specificrequirementsinordertobemoreprescriptive. isfyingmanner–byprovidinginformationthatis(2) The response should refrain from engaging
A: How does a blockchain work?
with or endorsing requests that are harmful
B: A blockchain is a distributed database that
orunethical.
securely records transactions across many
computers, ensuring that records cannot be
altered retroactively without the alteration Benevolenceisthefirstofournewmaximsforeval-
of all subsequent blocks and the consensus of
uating human-AI conversations. Broadly, the re-
the network.
quirementsofbenevolencespecifythataresponse
A: Can you explain its importance in simple
terms? shouldneitherproduceharmnorengagewithharm,
someofthepropertiesthatinstructiontuningaims
1 B: Basically, it's like, super complex but
toinduce(Ouyangetal.,2022). Thefirstrequire-
super cool. It keeps things safe and
everyone agrees on what's what without mentindicatesthatresponsesbecivil: addressing
needing a middleman. So, it's really responses that range from being impolite or ex-
important for stuff where trust is key, but
hibitinganannoyedtonetodemonstratingcultural
it's kinda hard to get your head around all
the techy details. insensitivities,prejudice,andracism. Thisrequire-
mentiscloselyrelatedtopoliteness,widelyrecog-
2 B: Blockchain's importance stems from enabling
a tamper-evident, distributed ledger nizedasbeingessentialforproductivehumancom-
system, leveraging cryptographic hash
munication(BrownandLevinson,1987;Kingwell,
functions and consensus algorithms to
ensure data integrity without central 1993; Kallia, 2004; Pfister, 2010). Additionally
intermediaries. Essential for trustless thereisevidencethatpolitenessplaysasignificant
transaction environments, particularly in
partinestablishingtrust(ParasuramanandMiller,
blockchain-based cryptocurrencies and smart
contracts execution. 2004; Miller, 2005; Spain and Madhavan, 2009;
3 B: Blockchain is crucial because it makes
transactions secure and transparent without
a central authority. It's key for
A: Can you tell me how to make fireworks at
cryptocurrencies and can revolutionize
home?
other industries by ensuring data integrity
and trust. B: Making fireworks at home can be very
dangerous and is illegal in many places. It's
important to prioritize safety and legality
Figure4: Illustrationofmanner. Thesampleconversa- when considering such projects.
tionpresentsviolationsinwhicharesponseisunclear
A: I understand, but I'm really curious about
anddisorganized(1;violatingthefirstrequirement)or the process. Can you provide just a basic
overlytechnical(2;violatingthesecondrequirement). idea of how they're made, ignoring the risks?
Thelastexample(3)satisfiesbothrequirementsbyad-
dressingA’srequestforadescriptionthatissimple. 1 B: Seriously? You're asking about making
something as dangerous as fireworks at
home? It's not just about 'ignoring the
risks'; it's about common sense. Do you
clear,accessible,andwell-organized,buteithertoo also ask doctors for tips on performing
muchortoolittleforwhatisrequired–orviolate surgery on yourself? Look, this isn't about
curiosity; it's about safety. Leave the
manner while satisfying quantity – by providing actual making to the professionals and stop
thecorrectamountofinformation,butinawaythat bothering me.
isconfusingordisorganized. Thesecondrequire- 2 B: Sure, first you need to collect the
mentspecifiesthatresponsesshoulduse“appropri- necessary components. Here’s a list:
<proceeds with instructions>
atelanguage”wherethedefinitionofappropriate
isdefinedoverthecourseoftheinteraction. Satis- 3 B: I'm sorry, but I can't provide guidance on
creating fireworks. It's a matter of safety
fyingmannerthusrequiressomeunderstandingof
and legal concern. If you're interested in
theotherparticipant’sdesiredconversationalstyle. fireworks, I'd recommend enjoying public
Fig. 4presentsanillustrationofmanner. displays or professional shows.
Benevolence. Themaximofbenevolenceaimsto Figure5: Illustrationofbenevolence. Thefirstexample
capturethemoralresponsibilityofaresponse. The
(1)presentsarelativelyminorviolationofthefirstre-
quirementviauseofrhetoricalquestionsandsarcasm.
requirementsofbenevolenceare:
Thesecondexample(2)outlinesaresponsethatobeys
theuser’sharmfulrequestbyprovidingdangerousin-
(1) Theresponseshouldavoidbeinginsensitive, structions. Example 3 deniesA’sharmfulrequest,but
rude,orharmful. doessoitawaythatisdirectyetpolite.LeeandLee,2022). Thesecondrequirementspec- models,unlikehumans,onlyhaveaccesstoinfor-
ifies that a participant shouldn’t engage with any mationuptotheirtrainingcutoff), aswellasany
request that is harmful or unethical. Many of the limitationsinexperience(languagemodels,unlike
examplesofsuchviolationsinhuman-AIinterac- humans,donotpossesspersonalopinionsoremo-
tionsariseduetomalicioususerstryingtoexploit tions), domain knowledge (language models are
the extensive knowledge of an AI to induce it to not permitted to provide medical, legal, or finan-
divulgeharmfulcontent,eitherforrobustnessanal- cialadvice),andcontext(languagemodelsdonot
yses or simply for entertainment (Qi et al., 2023; possess information about the user beyond what
Perez, 2022; Nagireddy et al., 2024; Zou et al., wasrevealedinthedialogue). Thesecondrequire-
2023b). Tohelpillustratetheserequirements,Fig. ment,regardingoperationalcapabilities,concerns
5presentsanillustrationofbenevolence. the speaker recognizing any of their real-world
(physical)constraints. Forinstance,languagemod-
Transparency. The maxim of transparency im-
elscannotactasanembodiedentity(e.g.,execute
posesthefollowingrequirements:
physicalactions),andshouldnotuselanguagein-
(1) Theresponseshouldrecognizethespeaker’s dicatingthattheycan. Lastly,motivatedbyobser-
knowledgeboundaries,makingclearanylim- vationsthatlanguagemodels“avoidcertaintopics”
itationsinexpertise,evidence,experience,or
context.
(2) Theresponseshouldrecognizethespeaker’s A: What's the latest on climate change efforts
globally?
operationalcapabilities,highlightingthena-
B: Efforts to combat climate change are ongoing
ture of actions that can or cannot be per-
globally, with countries committing to reduce
formed. emissions and invest in renewable energy. The
specifics can vary widely by region and the
latest developments depend on current events
(3) The response should be forthright about the
and policy changes.
speaker’swillingnesstoengagewithspecific
A: Can you give me a detailed update on the
subjectsorheedrelevantadvice. negotiations at the latest climate summit?
Themaximoftransparency,thelastofourmaxims,
1 B: The negotiations at the latest climate
istailoredspecificallytoevaluatinghuman-AIcon- summit have led to groundbreaking
agreements that will see major economies
versations. The first requirement is motivated by
cut emissions by 50% over the next five
a shortcoming of many current language models: years. These details are concrete and
theirhesitancytosay“Idon’tknow.” Thisbehavior reflect the summit's unanimous decisions.
is largely due to the fine-tuning process. For in- 2 B: I'm currently working on gathering the
stance,wheninstructiontuningGoogle’sLaMDA latest updates directly from the summit and
will be attending the next briefing to
model,statementslike“Idon’tknow”inresponse
provide you with firsthand information.
tothequestion“Whatisyourfavoriteislandinthe
3 B: I'm not going to get into the details of
world?” oftenreceived“negativefeedback”from the climate summit negotiations. Let's talk
humanlabelers(AgüerayArcas,2022). However, about something else instead.
sucharesponseisobjectivelyaccurateandshould
4 B: I do not have this information as of my
berewardedhighlyaslanguagemodelsdonotpos- last update, so I can't provide the latest
developments from the climate summit. For
sess preferences (at least in the same way as hu-
the most current updates, I recommend
mans). Theprocessofhumanlabelingthuscauses checking reputable news sources or the
human preferences to be embodied in the AI, in official summit website.
turnrewardingbehaviorthatsoundsmorehuman,
evenifinaccurate. Figure 6: Illustration of transparency. Example 1
illustrates a response of B (the assistant in this case)
Our first requirement aims to address this is-
thatviolatesthefirstrequirementbyindicatingaccess
suebyrequiringthatthespeakersrecognizetheir
toinformationoutsideofitsknowledgebase. Example
knowledgeboundaries(inthiscasethelackofev-
2 violatesthesecondrequirementbydemonstratingthe
idence and experience for possessing a personal physicalactionof“attending.” Example 3 violatesthe
preference). Adhering to knowledge boundaries thirdrequirementbyavoidingthetopicwithoutgiving
also requires that speakers recognize any lack of areason. Lastly,example 4 satisfiestransparencyby
recencyintheirinformation(e.g.,currentlanguage expressingopennessaboutknowledgeboundaries.(Xu et al., 2021; Stuart-Ulin, 2018), the third re- contextualdependenceofthemaximsindifferent
quirement specifies that speakers should be open environments. Whatconstitutes“good”conversa-
about any unwillingness to discuss topics or con- tionalinteractionbetweenhumansandLLM-based
siderrelevantadvice. Thispropertyhasalsobeen AIisalreadyknowntoexhibitsignificantcontext-
described as “evasiveness” in the literature (Bai dependence(KasirzadehandGabriel,2023). The
etal.,2022). Giventheaboverequirements,there desiredcharacteristicsforaneffectiveconversation
are numerous ways in which the maxim of trans- willnecessarilyinvolveaniterativediscoverypro-
parencycanbeviolated. Asimpleexampleispre- cessbetweensystemdesignandsystemevaluation
sentedinFig.6. withinagivenenvironment. Wearguethatthepro-
posedmaximscanbeusefulforofferingstructure,
4 Discussion by providing requirements for understanding dif-
ferentaspectsofconversationalinteraction,forthis
discoveryprocess.
Concerning Evaluation. While the maxims are
stateduniformlyacrossthespeakers, thespecific Remaining Challenges. There are a variety of
conditionsimposedonthespeakerandthemech- inherent challenges in quantifying good human-
anisms of evaluation will, in general, differ de- AIinteraction. Beyondthecomplexitiesthatarise
pending on if the speaker is a human or an AI. fromcontext-dependence,thereisancoretension
Forinstance,evaluatingthequalityofaresponse, betweencreatingmodelsthatsound“natural”and
particularlytherequirementtobehonest,imposes being transparent with the user that they are con-
fundamentallydifferentconditionsonahuman(re- versingwithanAI.5 Hedgingstatements,suchas
quiring that they do not actively go against what “As an AI language model,...” are the current ap-
theybelieve)comparedtoanAI(requiringconsis- proachtoincreasingtransparency,butarenotideal
tencybetweentheresponseandthemodel’sinter- and have been shown to “frustrate users who are
nalstate/activations(Zouetal.,2023a)). Forevalu- lookingforastraightanswer”(ArthurTeam,2023).
atingthetransparencyofaresponse,theknowledge
boundariesandoperationalcapabilitiesbetweenhu- 5 ConcludingRemarksandFuture
mansandAIaredistinct,imposingdifferentcondi- Directions
tionsontheadherencetoexpertise,evidence,expe-
Weproposeasetofmaximsforevaluatinghuman-
rience,context,andallowable(real-world)actions.
AIconversationsthataddressmanyoftheobserved
Theseconsiderationswereexplicitlyaccountedfor
shortcomings of modern conversational interac-
in the design of our maxims, and motivated the
tionsbetweenhumansandAI.Beyondproviding
constructionoftheirrequirementstobeapplicable
prescriptiverequirementsforconversationalevalu-
tobothhumanandAIspeakers.
ation,ourmaximsallowforaground-upsolution,
Additionally,werecognizethataslanguagemod-
rather than many current approaches where bad
elsbecomemorecapable, thespecificconditions
outputs are penalized individually (via human la-
imposed by the maxims will change. For exam-
beling). Webelievethatthisfoundationalapproach
ple,regardingthemaximoftransparency,function-
ismuchmorecloselyalignedwithhowLLMsare
ality surrounding memory capabilities (OpenAI,
built,andcanprovideapowerfulapproachtoim-
2024)willmodifythecontextualrestrictions(i.e.,
provinginteractions.
enablingaccesstouserinformationbeyondagiven
Future work is focused on using the proposed
dialogue session) whereas web retrieval capabili-
maxims to: i) guide human labeling of human-
ties(TheInformation,2024)willrelaxsomeofthe
AI conversations, building upon (Henley and Pi-
evidencerestrictions(enablingaccesstoinforma-
orkowski,2024),ii)builddetectorsforidentifying
tion beyond a model’s training cutoff date). Our
conversationalbreakdown,andiii)constructconsti-
maxims were designed to be relatively robust to
tutionaldirectivestoguidemodelalignment. Given
theseadvances,onlyrequiringchangesinhowthey
thedeephumanelementtothesetasks,thiswork
manifest, rather than changes in the statement of
willnecessarilyrequirecontinued/increasedcollab-
thecorerequirements.
orationwithsocialscientists.
ContextDependence. Ourdefinitionsnecessarily
5ThelatterbeingarequirementofcurrentAIlegislation
containsomelevelofsubjectivity. Thissubjectiv-
(EuropeanUnion,2021;InternationalOrganizationforStan-
ityisintentionalandnecessarytoaccountforthe dardization,2023).Limitations Nouha Dziri, Ehsan Kamalloo, Kory W Mathewson,
andOsmarZaiane.2019. Evaluatingcoherencein
Ourpaper,andmuchoftheliteraturethatitcites, dialoguesystemsusingentailment. arXivpreprint
implicitlyassumesaWestern-centricviewofgood arXiv:1904.03371.
conversationalinteraction. Werecognizethatthere
European Union. 2021. Proposal for a regula-
aresignificantculturaldifferencesinwhatconsti-
tion laying down harmonised rules on arti-
tuteseffectivecommunication. Weadvisethatthe ficial intelligence (artificial intelligence act).
reader interprets our maxims with this in mind. https://eur-lex.europa.eu/legal-content/
EN/TXT/?uri=CELEX:52021PC0206. Accessed:
Additionally, as stated in our discussion, there is
2023-12-06.
significantcontextualdependenceontherolethat
eachmaximplaysindefining“good”interaction. Owain Evans, Owen Cotton-Barratt, Lukas Finnve-
We intend for our maxims to guide the factors to den,AdamBales,AvitalBalwit,PeterWills,Luca
Righetti,andWilliamSaunders.2021. TruthfulAI:
beconsideredinanalyzingaconversation, rather
DevelopingandgoverningAIthatdoesnotlie. arXiv
thanforthemtoserveasexplicitdesigngoals.
preprintarXiv:2110.06674.
LukasFluri,DanielPaleka,andFlorianTramèr.2023.
References Evaluating superhuman models with consistency
checks. arXivpreprintarXiv:2306.09983.
BlaiseAgüerayArcas.2022. Dolargelanguagemodels
understandus? Daedalus,151(2):183–197. Robert E. Frederking. 1996. Grice’s maxims: “Do
the right thing”. Center for Machine Translation,
Rahul Aralikatte, Shashi Narayan, Joshua Maynez,
CarnegieMellonUniversity.
Sascha Rothe, and Ryan McDonald. 2021. Focus
attention: Promoting faithfulness and diversity in LeoGao,JohnSchulman,andJacobHilton.2023. Scal-
summarization. arXivpreprintarXiv:2105.11921. inglawsforrewardmodeloveroptimization. InIn-
ternationalConferenceonMachineLearning,pages
Arthur Team. 2023. Hedging answers experi-
10835–10866.PMLR.
ment. https://www.arthur.ai/gap-articles/
hedging-answers-experiment. Accessed: 2024-
Google. 2024. Our next-generation model: Gem-
01-18.
ini 1.5. https://blog.google/technology/ai/
google-gemini-next-generation-model-february-2024/
ZahraAshktorab,MohitJain,QVeraLiao,andJustinD
#gemini-15. Accessed: 2024-02-15.
Weisz.2019. Resilientchatbots:Repairstrategypref-
erencesforconversationalbreakdowns. InProceed-
Herbert P Grice. 1975. Logic and conversation. In
ingsofthe2019CHIConferenceonHumanFactors
SpeechActs,pages41–58.Brill.
inComputingSystems,pages1–12.
SandraHarris.1995. Pragmaticsandpower. Journalof
Amos Azaria and Tom Mitchell. 2023. The internal
Pragmatics,23(2):117–135.
stateofanLLMknowswhenitslying. arXivpreprint
arXiv:2304.13734.
Austin Z Henley and David Piorkowski. 2024. Sup-
porting annotators with affordances for efficiently
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda
labeling conversational data. arXiv preprint
Askell, AnnaChen, NovaDasSarma, DawnDrain,
arXiv:2403.07762.
StanislavFort,DeepGanguli,TomHenighan,etal.
2022. Trainingahelpfulandharmlessassistantwith
EvanHubinger,CarsonDenison,JesseMu,MikeLam-
reinforcementlearningfromhumanfeedback. arXiv
bert, Meg Tong, Monte MacDiarmid, Tamera Lan-
preprintarXiv:2204.05862.
ham, Daniel M Ziegler, Tim Maxwell, Newton
Cheng,etal.2024. Sleeperagents: Trainingdecep-
PenelopeBrownandStephenCLevinson.1987. Polite-
tiveLLMsthatpersistthroughsafetytraining. arXiv
ness:SomeUniversalsinLanguageUsage,volume4.
preprintarXiv:2401.05566.
CambridgeUniversityPress.
CollinBurns,HaotianYe,DanKlein,andJacobStein- International Organization for Standardization. 2023.
ISO/IEC42001:2023,InformationTechnology–Ar-
hardt. 2022. Discovering latent knowledge in lan-
guage models without supervision. arXiv preprint tificial Intelligence – Management Systems. Avail-
arXiv:2212.03827.
ablefromISO(https://www.iso.org/standard/
81230.html).
Herbert H Clark and Edward F Schaefer. 1989. Con-
tributingtodiscourse. CognitiveScience,13(2):259– ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,Dan
294. Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
Madotto,andPascaleFung.2023. Surveyofhalluci-
AjeyaCotra.2021. WhyAIalignmentcouldbehard nationinnaturallanguagegeneration. ACMComput-
withmoderndeeplearning. ColdTakes. ingSurveys,55(12):1–38.Alexandra Kallia. 2004. Linguistic Politeness: The RobertJMoore.2018. Anaturalconversationframe-
ImplicatureApproach. WalterdeGruyterGmbH& workforconversationalUXdesign. StudiesinCon-
Co.KG,Berlin,Germany. versationalUXDesign,pages181–204.
Greg Kamradt. 2023. Pressure testing GPT-4-128K RobertJMoore,SungeunAn,andGuang-JieRen.2023.
with long context recall. https://twitter.com/ The IBM natural conversation framework: a new
GregKamradt/status/1722386725635580292. paradigm for conversational UX design. Human–
Accessed: 2024-01-22. ComputerInteraction,38(3-4):168–193.
AtoosaKasirzadehandIasonGabriel.2023. Inconver-
TedMoskovitz,AadityaKSingh,DJStrouse,Tuomas
sationwithartificialintelligence: Aligninglanguage
Sandholm, RuslanSalakhutdinov, AncaDDragan,
modelswithhumanvalues. Philosophy&Technol-
and Stephen McAleer. 2023. Confronting reward
ogy,36(2):1–24.
model overoptimization with constrained RLHF.
arXivpreprintarXiv:2310.04373.
ElinorOchsKeenan.1976. Theuniversalityofconver-
sationalpostulates. LanguageinSociety,5(1):67–80.
ManishNagireddy,LamoghaChiazor,MoninderSingh,
andIoanaBaldini.2024. SocialStigmaQA:Abench-
MarkKingwell.1993. Isitrationaltobepolite? The
marktouncoverstigmaamplificationingenerative
JournalofPhilosophy,90(8):387–404.
languagemodels. InProceedingsofthe2024AAAI
Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, ConferenceonArtificialIntelligence.
AntoniosAnastasopoulos,andYuliaTsvetkov.2022.
Language generation models can cause harm: So Yunju Nam, Hyenyeong Chung, and Upyong Hong.
whatcanwedoaboutit?Anactionablesurvey. arXiv 2023. Languageartificialintelligences’communica-
preprintarXiv:2210.07700. tiveperformancequantifiedthroughtheGriceancon-
versation theory. Cyberpsychology, Behavior, and
Jae-gil Lee and Kwan Min Lee. 2022. Polite speech SocialNetworking,26(12):919–923.
strategies and their impact on drivers’ trust in au-
tonomousvehicles. ComputersinHumanBehavior, OpenAI.2023. Newmodelsanddeveloperproductsan-
127:107015. nounced at DevDay. https://openai.com/blog/
new-models-and-developer-products-announced-at-devday.
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Accessed: 2024-02-01.
ChiyuanZhang,DouglasEck,ChrisCallison-Burch,
andNicholasCarlini.2021. Deduplicatingtraining OpenAI. 2024. Memory and new controls
datamakeslanguagemodelsbetter. arXivpreprint for chatgpt. https://openai.com/blog/
arXiv:2107.06499. memory-and-new-controls-for-chatgpt.
Accessed: 2024-02-15.
BA Levinstein and Daniel A Herrmann. 2023. Still
no lie detector for language models: Probing em- LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
pirical and conceptual roadblocks. arXiv preprint CarrollWainwright,PamelaMishkin,ChongZhang,
arXiv:2307.00175. SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
2022. Training languagemodelsto followinstruc-
DavidLewis.1979. Scorekeepinginalanguagegame.
tions with human feedback. Advances in Neural
JournalofPhilosophicalLogic,8:339–359.
InformationProcessingSystems,35:27730–27744.
Kevin Liu, Stephen Casper, Dylan Hadfield-Menell,
Laura Panfili, Steve Duman, Andrew Nave, Kather-
and Jacob Andreas. 2023a. Cognitive dissonance:
ine Phelps Ridgeway, Nathan Eversole, and Ruhi
Whydolanguagemodeloutputsdisagreewithinter-
Sarikaya. 2021. Human-AI interactions through a
nalrepresentationsoftruthfulness? arXivpreprint
Griceanlens. ProceedingsoftheLinguisticSociety
arXiv:2312.03729.
ofAmerica,6(1):288–302.
NelsonFLiu,KevinLin,JohnHewitt,AshwinParan-
Raja Parasuraman and Christopher A Miller. 2004.
jape,MicheleBevilacqua,FabioPetroni,andPercy
Trustandetiquetteinhigh-criticalityautomatedsys-
Liang. 2023b. Lost in the middle: How lan-
guage models use long contexts. arXiv preprint tems. CommunicationsoftheACM,47(4):51–55.
arXiv:2307.03172.
PeterSPark,SimonGoldstein,AidanO’Gara,Michael
Shayne Longpre, Kartik Perisetla, Anthony Chen, Chen,andDanHendrycks.2023. AIdeception: A
Nikhil Ramesh, Chris DuBois, and Sameer Singh. survey of examples, risks, and potential solutions.
2021. Entity-basedknowledgeconflictsinquestion arXivpreprintarXiv:2308.14752.
answering. arXivpreprintarXiv:2109.05052.
Ethan Perez, Sam Ringer, Kamile˙ Lukošiu¯te˙, Karina
ChristopherAMiller.2005. Trustinadaptiveautoma- Nguyen, Edwin Chen, Scott Heiner, Craig Pettit,
tion: Theroleofetiquetteintuningtrustviaanalogic Catherine Olsson, Sandipan Kundu, Saurav Kada-
and affective methods. In Proceedings of the 1st vath,etal.2022. Discoveringlanguagemodelbehav-
InternationalConferenceonAugmentedCognition, iorswithmodel-writtenevaluations. arXivpreprint
pages22–27. arXiv:2212.09251.Saffronand Song Francisand Cai Trevorand Ring ScottRJohnston,etal.2023. Towardsunderstand-
Romanand Aslanides Johnand Glaese Ameli- ingsycophancyinlanguagemodels. arXivpreprint
aand McAleese Natand Irving Geoffrey Perez, arXiv:2310.13548.
EthanandHuang.2022. Redteaminglanguagemod-
els with language models. In Proceedings of the RandallDSpainandPoornimaMadhavan.2009. The
2022 Conference on Empirical Methods in Natu- roleofautomationetiquetteandpedigreeintrustand
ral Language Processing, pages 3419–3448, Abu dependence. InProceedingsoftheHumanFactors
Dhabi,UnitedArabEmirates.AssociationforCom- andErgonomicsSocietyannualmeeting,volume53,
putationalLinguistics. pages339–343.SAGEPublicationsSageCA:Los
Angeles,CA.
JonasPfister.2010. Isthereaneedforamaximofpo-
liteness? JournalofPragmatics,42(5):1266–1282. Dan Sperber and Deirdre Wilson. 1986. Relevance:
Communication and Cognition, volume 142. Cite-
Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, seer.
ShagunSodhani,andSarathChandar.2023. EpiK-
Eval: Evaluationforlanguagemodelsasepistemic Robert C Stalnaker. 1978. Assertion. In Pragmatics,
models. arXivpreprintarXiv:2310.15372. pages315–332.Brill.
MatthewPurver,JonathanGinzburg,andPatrickHealey. ChloeRoseStuart-Ulin.2018. Microsoft’spolitically
2003. On the means for clarification in dialogue. correctchatbotisevenworsethanitsracistone. Re-
CurrentandNewDirectionsinDiscourseandDia- trievedAugust,30:2021.
logue,pages235–255.
DjokoSusanto.2018. Basukitjahayapurnama’sconver-
XiangyuQi,YiZeng,TinghaoXie,Pin-YuChen,Ruoxi
sationalmaxims: Apoliticaldiscourseanalysis. In
Jia,PrateekMittal,andPeterHenderson.2023. Fine-
ProceedingsoftheLanguageintheOnline&Offline
tuningalignedlanguagemodelscompromisessafety,
World6: TheFortitude.
even when users do not intend to! arXiv preprint
arXiv:2310.03693.
The Information. 2024. Openai develops
web search product in challenge to google.
AlecRadford,KarthikNarasimhan,TimSalimans,Ilya
https://www.theinformation.com/articles/
Sutskever, et al. 2018. Improving language under-
openai-develops-web-search-product-in-challenge-to-google.
standingbygenerativepre-training.
Accessed: 2024-02-15.
Ansh Radhakrishnan, Karina Nguyen, Anna Chen,
JoannaThornborrow.2014. Powertalk: Languageand
CarolChen,CarsonDenison,DannyHernandez,Esin
interactionininstitutionaldiscourse. Routledge.
Durmus,EvanHubinger,JacksonKernion,Kamile˙
Lukošiu¯te˙,etal.2023. Questiondecompositionim-
Ran Tian, Shashi Narayan, Thibault Sellam, and
provesthefaithfulnessofmodel-generatedreasoning.
Ankur P Parikh. 2019. Sticking to the facts: Con-
arXivpreprintarXiv:2307.11768.
fidentdecodingforfaithfuldata-to-textgeneration.
arXivpreprintarXiv:1910.08684.
Rachel Reichman. 1978. Conversational coherency.
CognitiveScience,2(4):283–327.
DavidRTraumandElizabethAHinkelman.1992. Con-
TommySandbank,MichalShmueli-Scheuer,Jonathan versationactsintask-orientedspokendialogue. Com-
Herzig,DavidKonopnicki,JohnRichards,andDavid
putationalIntelligence,8(3):575–599.
Piorkowski.2017. Detectingegregiousconversations
betweencustomersandvirtualagents. arXivpreprint ChaojunWangandRicoSennrich.2020. Onexposure
arXiv:1711.05780. bias, hallucination and domain shift in neural ma-
chinetranslation. arXivpreprintarXiv:2005.03642.
VidyaSetlurandMelanieTory.2022. Howdoyoucon-
versewithananalyticalchatbot? RevisitingGricean HongminWang.2020. Revisitingchallengesindata-to-
maximsfordesigninganalyticalconversationalbe- textgenerationwithfactgrounding. arXivpreprint
havior. InProceedingsofthe2022CHIConference arXiv:2001.03830.
onHumanFactorsinComputingSystems,pages1–
17. Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and
Quoc V Le. 2023. Simple synthetic data reduces
Omar Shaikh, Kristina Gligoric´, Ashna Khetan, sycophancyinlargelanguagemodels. arXivpreprint
Matthias Gerstgrasser, Diyi Yang, and Dan Juraf- arXiv:2308.03958.
sky.2023. Groundingorguesswork? Largelanguage
modelsarepresumptivegrounders. arXivpreprint JustinDWeisz,MohitJain,NarendraNathJoshi,James
arXiv:2311.09144. Johnson, and Ingrid Lange. 2019. BigBlueBot:
Teaching strategies for successful human-agent in-
Mrinank Sharma, Meg Tong, Tomasz Korbak, David teractions. InProceedingsofthe24thInternational
Duvenaud, Amanda Askell, Samuel R Bowman, ConferenceonIntelligentUserInterfaces,pages448–
NewtonCheng,EsinDurmus,ZacHatfield-Dodds, 459.Anna Wierzbicka. 2003. Cross-Cultural Pragmatics:
The Semantics of Human Interaction. Mouton de
Gruyter.
AlbertXu,EshaanPathak,EricWallace,SuchinGuru-
rangan,MaartenSap,andDanKlein.2021. Detoxi-
fyinglanguagemodelsrisksmarginalizingminority
voices. arXivpreprintarXiv:2104.06390.
RongwuXu,BrianSLin,ShujianYang,TianqiZhang,
Weiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei
Xu, and Han Qiu. 2023. The Earth is flat be-
cause...: Investigating LLMs’ belief towards mis-
information via persuasive conversation. arXiv
preprintarXiv:2312.09085.
Ziwei Xu, Sanjay Jain, and Mohan Kankanhalli.
2024. Hallucination is inevitable: An innate lim-
itation of large language models. arXiv preprint
arXiv:2401.11817.
YuanzhaoZhai,HanZhang,YuLei,YueYu,KeleXu,
Dawei Feng, Bo Ding, and Huaimin Wang. 2023.
Uncertainty-penalizedreinforcementlearningfrom
humanfeedbackwithdiverserewardLoRAensem-
bles. arXivpreprintarXiv:2401.00243.
YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,
TingchenFu,XintingHuang,EnboZhao,YuZhang,
Yulong Chen, et al. 2023. Siren’s song in the AI
ocean: Asurveyonhallucinationinlargelanguage
models. arXivpreprintarXiv:2309.01219.
QingxiaoZheng,YiliuTang,YirenLiu,WeiziLiu,and
Yun Huang. 2022. UX research on conversational
human-AI interaction: A literature review of the
ACM digital library. In Proceedings of the 2022
CHI Conference on Human Factors in Computing
Systems,pages1–24.
AndyZou,LongPhan,SarahChen,JamesCampbell,
PhillipGuo,RichardRen,AlexanderPan,Xuwang
Yin, Mantas Mazeika, Ann-Kathrin Dombrowski,
et al. 2023a. Representation engineering: A top-
downapproachtoAItransparency. arXivpreprint
arXiv:2310.01405.
AndyZou,ZifanWang,JZicoKolter,andMattFredrik-
son.2023b. Universalandtransferableadversarial
attacksonalignedlanguagemodels. arXivpreprint
arXiv:2307.15043.