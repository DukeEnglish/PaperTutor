Empirical Equilibria in Agent-based Economic systems with Learning agents
KshamaDwarakanath1,SvitlanaVyetrenko1,TuckerBalch2
1JPMorganAIResearch,SanFrancisco,California,USA
2EmoryUniversity,Atlanta,Georgia,USA
kshama.dwarakanath@jpmorgan.com
Abstract erogeneousABMsasabottom-upapproachtowardsmodel-
ingnuancesoftherealworldmoreaccurately.
We present an agent-based simulator for economic systems
Reinforcement learning (RL) involves an agent learn-
withheterogeneoushouseholds,firms,centralbank,andgov-
ing to act in an uncertain, dynamic environment via trial-
ernment agents. These agents interact to define production,
consumption,andmonetaryflow.Eachagenttypehasdistinct and-error to maximize objectives (Kaelbling, Littman, and
objectives,suchashouseholdsseekingutilityfromconsump- Moore 1996). In multi-agent settings, learning agents in-
tionandthecentralbanktargetinginflationandproduction. troduce non-stationarity and potential partial observability
Wedefinethismulti-agenteconomicsystemusinganOpenAI for each other (Busoniu, Babuska, and De Schutter 2008).
Gym-style environment, enabling agents to optimize their Multi-agent reinforcement learning (MARL) studies such
objectives through reinforcement learning. Standard multi- problems by modeling the system as a stochastic game
agent reinforcement learning (MARL) schemes, like inde-
where the environment state evolves based on joint actions
pendentlearning,enableagentstolearnconcurrentlybutdo
of all agents (Littman 1994; Hu and Wellman 1998). Stan-
not address whether the resulting strategies are at equilib-
dardMARLtechniqueshaveindependentlylearningagents
rium.ThisstudyintegratesthePolicySpaceResponseOracle
thatupdatetheirpoliciessimultaneously,disregardingother
(PSRO) algorithm, which has shown superior performance
overindependentMARLingameswithhomogeneousagents, learning agents. MARL is related to game theory, which
with economic agent-based modeling. We use PSRO to de- studies multiple agents in static or repeated tasks (Fuden-
velop agent policies approximating Nash equilibria of the berg and Levine 1998; Bowling and Veloso 2000; Hu and
empiricaleconomicgame,therebylinkingtoeconomicequi- Wellman 2003). Prior research has compared independent
libria.OurresultsdemonstratethatPSROstrategiesachieve andcoordinated(orjointaction)learninginsimple,cooper-
lowerregretvaluesthanindependentMARLstrategiesinour ativegames(Tan1993;ClausandBoutilier1998).
economic system with four agent types. This work aims to
RecentworkhasincorporatedABMsandMARLineco-
bridgeartificialintelligence,economics,andempiricalgame
nomicsystems(Trottetal.2021;Curryetal.2022;Mietal.
theorytowardsfutureresearch.
2023),butthereislittlefocusonwhetherlearnedagentsare
at equilibrium, a central notion in economics (Hahn 1973).
1 Introduction Empirical game-theoretic analysis (EGTA) studies equilib-
Agent-based modeling (ABM) offers significant potential riainempiricalgamesdefinedbyagentinteractionsincom-
foradvancingeconomicsbydefiningagentsandtheirinter- plex ABMs (Wellman 2020). Here, we use RL for strat-
actions to produce complex emergent behaviors even from egygenerationalongsideEGTAtolearnapproximateNash
simplerules(MacalandNorth2005).ABMshavebeenap- equilibriumstrategiesforoureconomicABM.Specifically,
plied in robotics (Vorotnikov et al. 2018), financial mar- weemploythePolicySpaceResponseOracle(PSRO)algo-
kets(Byrd,Hybinette,andBalch2019),trafficmanagement rithm proposed in (Lanctot et al. 2017) to integrate MARL
(Adleretal.2005),socialnetworks(Gattietal.2014),and with equilibrium analysis for multiple heterogeneous eco-
recently,insimulatingsocialinteractionswithLLMs(Park nomicagents.Wesummarizeourcontributionsbelow.
etal.2023).Prominenteconomistshighlightthebenefitsof
1. WeconsideraPython-basedmacroeconomicABMwith
ABMs in modeling complex scenarios accounting for hu-
heterogeneous households, firms, a central bank, and
manadaptationandlearning(FarmerandFoley2009).The
government,thatallowseasycustomizationofagentcon-
field of Agent-based Computational Economics advocates
figurationsandincorporatingreinforcementlearningca-
for ABMs’ ability to simulate ‘turbulent’ social conditions
pabilitiesthroughOpenAIGym-styleenvironments.
unseeninhistoricaldata,andtomodeldynamicsoutofequi-
librium (Srbljinovic´ and Sˇkunca 2003; Tesfatsion and Judd 2. We base agent heterogeneity parameters and action
spaces on economic literature and real-world data, such
2006).(HamillandGilbert2015)promotesABMsforbridg-
asUSwagestatistics,toensurerealisticsimulationinthe
ingthegapbetweenmicroeconomics(individualagentmod-
absenceofpubliclyavailable,individualagentdata.
eling) and macroeconomics (aggregate observations at sys-
tem level). (Arthur 2021) highlights the advantages of het- 3. We use the PSRO algorithm to learn adaptive strategies
4202
guA
12
]AM.sc[
1v83021.8042:viXrafor our economic agents, that form part of a Nash equi- Agent-based economic modeling and RL. RL tech-
librium of this general-sum game involving four agent niquesarewellsuitedtomodelhouseholdbehaviorineco-
types,withmultipleagentspertype. nomics, where households seek to maximize utilities over
time (Chen et al. 2021; Hill, Bardoscia, and Turrell 2021;
4. WecomparestrategieslearnedwithindependentMARL
Atashbar and Shi 2023). RL has also been used to opti-
and PSRO in a hypothetical economic scenario inves-
mize other economic strategies, such as revenue redistri-
tigating the impact of heterogeneous household skills
bution (Koster et al. 2022), monetary policy (Chen et al.
on their preferences to work at different firms. Findings
2021; Hinterlang and Ta¨nzer 2021), and tax policy (Zheng
show that PSRO households work more hours at firms
et al. 2022). (Zheng et al. 2022) pioneered multi-agent RL
wheretheyhavehigherskills.Asidefromqualitativedif-
(MARL)ineconomicABMsbystudyingtaxpolicydesign
ferences in strategies from both schemes, PSRO strate-
with agents and a planner. The planner sets marginal tax
gies achieve lower total regret when agents are allowed
ratestobalanceequalityandproductivity,whileagentsmax-
tounilaterallyswitchtothealternativestrategy.
imizetheirendowmentutility.(Curryetal.2022)introduced
a macroeconomic real-business-cycle ABM using MARL
2 LiteratureReview
forconsumers,firms,governmentstrategies,albeitwithlim-
itationsincludingabsenceofthecentralbank’sroleinmon-
EconomicModels. DynamicStochasticGeneralEquilib-
etarypolicy,uniformtaxredistribution,andomissionofin-
rium (DSGE) models are macroeconomic models widely
ventory holding risk for firms. (Mi et al. 2023) developed
used by Central Banks for macroeconomic forecasting and
aneconomicsimulatorfortaxationusingMARL,scalingto
policy analysis (Del Negro and Schorfheide 2013). Early
10,000 household agents who maximize consumption util-
work,like(KydlandandPrescott1982),introducedaDSGE
ities, while the government aims to improve social welfare
model with a representative household and firm, analyz-
and economic growth. Although only a few recent studies
ing steady-state observables and quadratic approximations
explore MARL within economic ABMs, this research area
around them. (Krusell and Smith 1998) extended this by
is gradually expanding (Dwarakanath et al. 2024; Brusatin
incorporating household heterogeneity in income, wealth,
et al. 2024). But, none of these studies examine the impact
and temporal preferences. Modern macroeconomic model-
oftheMARLschemeonachievingaNashequilibrium.
ingfocusesonmodelsestimatedfromrealdata(Christiano,
Eichenbaum, and Evans 2005; Woodford 2009). The Fed- EmpiricalGame-TheoreticAnalysis. Gametheorystud-
eral Reserve Bank of New York provides public access to iestheinteractionbetweenmultipleplayersoragents,each
its DSGE model (Del Negro, Giannoni, and Schorfheide aiming to maximize their utility based on the joint strat-
2015), and forecasts (Del Negro et al. 2015). Despite ex- egy of all agents (Von Neumann 1928). A mixed strategy
tensive literature, DSGE models rely on linearization tech- Nashequilibriumisasetofprobabilitydistributionswhere
niques studying local perturbations around deterministic noagentcangainutilitybydeviatingfromtheirprobabilis-
steadystates,alongwithrestrictiverepresentativeagentas- tic strategy, given other agents’ strategies (Von Neumann
sumptions.Thesesimplifyingassumptionslimittheirability and Morgenstern 2007). This concept is crucial for equi-
to capture the full complexity of real economies (Haldane librium in economic systems, as it implies that no agent
andTurrell2019),andmakethemsusceptibletomodelmis- hasanincentivetochangetheirstrategyunilaterally.While
specificationerrors(FarmerandFoley2009). therearetoolstofindNashequilibria(KnightandCampbell
2018; Savani and Turocy 2023), applying these to our eco-
Agent-based modeling in Economics. The field of
nomicABMishardbecausetheyneedafinitegamedefini-
Agent-basedComputationalEconomicsusesABMstosim-
tion.First,eachagent’sstrategysetisunboundedasstrate-
ulate interactions among economic agents, addressing fac-
gies are temporal policies, mapping states to actions. Sec-
tors like agent heterogeneity, adaptation and modeling dy-
ond,analyticallycharacterizingagentutilitiesishardasthey
namicsoutofequilibriumunlikeDSGEmodels(Tesfatsion
represent cumulative rewards over time, which depends on
andJudd2006).ABMsofferaflexibleframeworktomodel
other agents’ strategies. Empirical game-theoretic analysis
complex,heterogeneous,boundedrationaleconomicagents
(EGTA) offers a solution by addressing games where pro-
with diverse objectives (Stiglitz 2018). (Deissenberg, Van
ducing an explicit game model is impractical (Walsh et al.
DerHoog, andDawid2008)aimed tocreatea comprehen-
2002; Wellman 2006). EGTA bridges agent-based simula-
sive ABM of the European economy, initially focusing on
tionandgametheorybyestimatingagamefromsimulation
labormarketdynamicsandlaterexpandingtoincludeindus-
datageneratedoveraspaceofstrategies(Wellman2020).
tryevolution,creditmarkets,andconsumption(Dawidetal.
2016).WhilecalibratingABMswithrealdataischallenging EGTAandRL. InEGTA,buildingstrategysetsforsimu-
duetothenumerousagent-specificparameters,theycanbe lationcanbedonebasedonheuristicstrategies(Walshetal.
validated by reproducing economic stylized facts. There is 2002) or generating new strategies through RL (Schvartz-
significantworkonABMsofendogenousgrowthandbusi- manandWellman2009).Subsequently,(Lanctotetal.2017)
ness cycles which are empirically validated by replicating introducedthePolicySpaceResponseOracle(PSRO)algo-
a set of micro- and macro-economic facts (Dosi, Fagiolo, rithm,forstrategy/policyspaceexplorationingeneralmulti-
andRoventini2006;Dosietal.2017).Theyuserule-based playergamesusingdeepRL(theresponseoracle).PSROit-
agentswith predefinedbehaviors,offering aframework for erativelyaddsnewstrategiesbycomputinganapproximate
studyingmonetaryandfiscalpolicy(Dosietal.2015). best response using RL to a meta-strategy (set of mixedstrategies across agents) of the empirical game. Unlike in- wheres(t+1) ∼ T(s(t),a (t),··· ,a (t)).Timesteptis
1 n
dependentMARL,whichdealswithnon-stationaritydueto a simulation period, typically one quarter of a year in eco-
agentsupdatingpoliciessimultaneously,PSROupdatesone nomicABMs.
agentatatimeinastationaryenvironmentwhereothersfol-
low their meta-strategy. PSRO generalizes the Double Or- 3.1 Households
acle algorithm for 2-player games, when using Nash equi- Households are the consumer-workers that provide skilled
libriumasthemeta-strategy(McMahan,Gordon,andBlum laborforproductionatfirms,whilealsoconsumingsomeof
2003;Wright,Wang,andWellman2019).(Smith,Anthony, the produced goods. They are paid wages for their labor at
andWellman2020)enhancedPSROusingQ-Mixingtoease thefirmsandpayforthepriceofconsumedgoods.Thegov-
learning, showing reduced training time for 2 and 3 player ernmentcollectsincometaxesontheirlaborincome,partof
gameswithhomogeneousplayers. whichcouldberedistributedbacktohouseholdsastaxcred-
Whilepreviousworkhascomparedindependentlearning its in the subsequent year. They also earn (accrue) interest
toschemesincorporatingjointactioninformationforcoop- on theirsavings (debt)from the centralbank. These mone-
erative games (Claus and Boutilier 1998), little is known taryinflowsandoutflowsgovernthedynamicsofhousehold
about how these techniques compare for dynamic general- savingsfromonetimesteptothenext.
sumgamesontheequilibriareached(ifandwhentheydo). The observations of household i at time t include tax
In this work, we use deep RL to generate new strategies credit κ , tax rate τ , interest rate r , wages of all firms
t,i t t
within the EGTA framework for an economic ABM with {w :∀j},pricesofgoodsofallfirms{p :∀j}andtheir
t,j t,j
households, firms, central bank, and government. Our ap- monetary savings m . The actions include their hours of
t,i
proachappliesPSROtoeconomicABMs,settingthemeta- labor forall firms {n : ∀j} and unitsof good requested
t,ij
strategytoaNashequilibriumoftheempiricalgameineach forconsumptionatallfirms{creq : ∀j}.Thedynamicsre-
t,ij
epoch.BysolvingforaNashequilibriumineveryepochand latedtohouseholdiaregivenby
usingRLtoimproveexistingstrategiestoreachanewNash (cid:40) creq (cid:41)
equilibrium, we establish a connection to (empirical) eco- c =min creq,Y · t,ij (1)
nomicequilibrium,whichisotherwisedifficulttoelucidate. t,ij t,ij t,j (cid:80) creq
k t,kj
We also contrast independent MARL (IMARL) and PSRO
(cid:88)
onthelearnedstrategies,focusingontheirregretvalues. m t+1,i =(1+r t)m t,i+ (n t,ijω ijw t,j −c t,ijp t,j)
j
3 Multi-AgentEconomicSystem (cid:88)
−τ · n ω w +κ (2)
t t,ij ij t,j t,i
Our economic ABM has four types of agents: House- j
holds who are consumers of goods and provide skilled
In (1), when the requested consumption for firm j exceeds
labor for production of goods; Firms who utilize labor
its inventory Y , goods are allocated proportionally to re-
t,j
to produce goods and pay wages; Central Bank that
quests so that the realized consumption of goods of firm j
monitors price inflation and production to set interest rate
byhouseholdiisc .(2)istheevolutionofsavingsfromt
t,ij
for household savings; and the Government that collects
tot+1whereω denotestheskillofhouseholdiatfirmj.
ij
income taxes from households that could potentially be
The reward for household i at t is given by
redistributed as tax credits. Each agent is modeled as a (cid:80)
u(c ,n ,m ;γ ,ν ,µ )where
learner aiming to maximize the discounted sum of its j t,ij t,ij t+1,i i i i
rewards over a horizon H. This multi-agent economic c1−γ |m|1−γ
u(c,n,m;γ,ν,µ)= −νn2+µ·sign(m)
system is formalized as a Partially Observable Markov 1−γ 1−γ
Game (Hu and Wellman 1998), represented by Γ =
withanisoelasticutilityfromconsumptionandsavings,and
⟨N,S,{A }n ,{O }n ,T,{O }n ,{R }n ,{β }n ,
i i=1 i i=1 i i=1 i i=1 i i=1 aquadraticdisutilityoflabor(EvansandHonkapohja2005).
H⟩ where N = {1,2,··· ,n} is the set of agents, S is
Households are heterogeneous in their skills per firm ω ,
the state space, A is the action space of agent i with ij
i andutilityparameters(γ ,ν ,µ ).
A = A ×A ×···×A denotingthejointactionspace, i i i
1 2 n
O istheobservationspaceofagenti,T : S ×A → P(S)
i 3.2 Firms
is the transition function mapping current state and joint
Firms are the producer-employers that use household la-
action to a probability distribution over the next state,
O : S → P(O ) is the observation function mapping bortoproducegoodsforconsumption.Theypaywagesfor
i i
thereceivedlaborandreceiverevenuefrompricespaidfor
current state to a probability distribution over observations
ofagenti,R :S ×A→Ristherewardfunctionofagent consumed goods. Their production is subject to an exoge-
i
nous, stochastic production factor that captures any exter-
i,β ∈ [0,1)isthediscountfactorofagenti,andH isthe
i
nalshocks(Hill,Bardoscia,andTurrell2021).Firmsaccu-
horizon. The objective of each agent i ∈ N is to find a
mulateinventorywhentheyproducemoregoodsthancon-
sequence of individual actions to maximize expected sum
sumedbyhouseholds,whichtheyseektominimize.
ofdiscountedrewardsoverthehorizon
Theobservationsoffirmj attimetincludetotalhouse-
(cid:34)H−1 (cid:35)
hold labor
(cid:80)
n ω , total consumption
(cid:80)
c , exoge-
max E (cid:88) β itR i(s(t),a 1(t),··· ,a n(t)) nous shock ε ti ,j,t e,i xj ogi ej nous production factori ϵ t−t,i 1j ,j, previ-
(ai(0),···,ai(H−1))
t=0 ous wage w t,j, previous price p t,j and inventory Y t,j. Theactionsincludewageperunitoflaborw andpriceper The observations of the government at time t include
t+1,j
unitofgoodp thatgointoeffectatthenexttimestep. the previous tax rate τ , previous tax credits {κ : ∀i},
t+1,j t t,i
(cid:80)
Thedynamicsofquantitiesrelatedtofirmj aregivenby previous tax collected {τ n ω w : ∀i} and a
t j t,ij ij t,j
ϵ =(ϵ )ρjexp(ε ) (3) time varying household weight in relation to social wel-
t,j t−1,j t,j fare {l : ∀i}. Our framework lets the designer choose
(cid:32) (cid:33)αj weightst,i
l based on their choice of social welfare metric
(cid:88) t,i
y t,j =ϵ t,j n t,ijω ij (4) e.g., l t,i ≡ 1 for the utilitarian social welfare function ver-
i sus l t,i = 1{i = argmin km t,k} for the Rawlsian social
Y =Y +y −(cid:88) c (5) welfare function. We choose l t,i to be a function of house-
t+1,j t,j t,j t,ij
hold savings with parameters α > 0,β > 0, and l >
i (cid:26) l l 2
max{l ,−α m +β }, ifm >0
(3)describestheexogenousproductionfactorϵ asfollow- l > 0asl = 1 l t,i l t,i .
t,j 1 t,i min{l ,−2α m +β }, ifm ≤0
ingalog-autoregressiveprocesswithcoefficientρ ∈[0,1], 2 l t,i l t,i
j
ϵ = 1,andε ∼ N
(cid:0)
ε¯
,σ2(cid:1)
beinganexogenousshock.
So, the government underweights high-savings households
0,j t,j j j and overweights those with high debt, ensuring all house-
(4)isthefirm’sproductionprocessperaCobb-Douglaspro-
holds are weighted between l and l . The actions in-
ductionfunctionusingskilledlaborwithelasticityparame- 1 2
clude tax rate τ , and fraction of tax credit distributed
terα ∈ [0,1](CobbandDouglas1928).Thefirmupdates t+1
j to each household i, f , that go into effect at the
itsinventoryatthenexttimestepbasedoncurrentinventory t+1,i
next time step. The dynamics are given by κ =
andthedifferencebetweensupplyanddemandasin(5). (cid:16) (cid:17) t+1,i
(cid:80) (cid:80)
Therewardforfirmj attisgivenby ξf
t+1,i k
τ
t
jn t,kjω kjw
t,j
, where f
t,i
∈ [0,1] with
(cid:80)
(cid:88) (cid:88) f = 1 so that portion ξ ∈ [0,1] of collected taxes is
p c −w n ω −χ p Y i t,i
t,j t,ij t,j t,ij ij j t,j t+1,j redistributed. The tax credit for household i at t + 1 is a
i i fractionf ofthisredistributedamount.
t+1,i
where the first two terms depict profits as the difference in Therewardforthegovernmentisameasureofhousehold
consumption revenue and labor costs, while the last term socialwelfare,givenherebyaweightedsumoftheirutilities
capturesinventoryrisk.Firmsareheterogeneousintheirsec- (cid:88)
l R
tor, modeled by shock process and production parameters t,i t,i,H
i
(ρ ,ε¯ ,σ ,α ),andtheirweightingforinventoryriskχ .
j j j j j where l is the weight associated to household i and,
t,i
(cid:80)
R = u(c ,n ,m ;γ ,ν ,µ ) is the reward
3.3 CentralBank t,i,H j t,ij t,ij t+1,i i i i
functionmeasuringtheutilityforhouseholdiattimet.
Thecentralbankistheregulatoryagencythatmonitorsthe
pricesandproductionofgoodstosetinterestratesforhouse-
4 PolicySpaceResponseOracles
hold savings. By changing the interest rate on household
We adapt the Policy Space Response Oracles (PSRO)
savings,itaffectstheconsumptionandlaborpatternsofthe
algorithm from (Lanctot et al. 2017) to our economic
household.Theseinturnaffectthepricesofgoodsproduced
ABM in Algorithm 1. The object of analysis is a Nor-
byfirms.Thecentralbankseekstosetinterestratestomeet
mal form game (Π,U,n) between agents in our n-agent
inflationtargetsandboostproduction.
economic system. Agent i selects a pure-strategy/policy
The observations of the central bank at time t include
(cid:80) π : O → P(A ) from its policy set Π . The joint pol-
totalpriceofgoodsoverthelastfivequarters{ p : i i i i
∀k ∈ {0,1,2,3,4}}andtotalfirmproduction(cid:80) jj y t,t j− .k T,j he i Ucy :se Πt is →Π R=
n
m( aΠ p1 s, j· o· i· n, tΠ pn ol) i, cyan πd =the (u πtil ,i ·ty ··f ,u πnc )tio ton
1 n
action includes the interest rate r that goes into effect
t+1 utilities (discounted cumulative rewards) for each agent i
atthenexttimestep.Thedynamicsincludecomputingthe (cid:104) (cid:12)
annualinflationrateoftotalpriceasπ =
(cid:80) jpt,j
.
asU i(π)=E (cid:80) tH =− 01β itR i(s(t),a 1(t),··· ,a n(t))(cid:12) (cid:12)s(t+
Therewardforthecentralbankisgt iven(cid:80)
bj
ypt−4,j
1) ∼ T(s(t),a 1(t),··· ,a n(t)),a j(t) ∼ π
j(cid:105)
. Agent i can
alsoadoptamixed-strategyσ ∈ P(Π ),randomizingover
 2 i i
policiesinΠ accordingthedistributionσ .Ajointstrategy
−(π
t−π⋆)2+λ(cid:88)
y t,j σ = (σ
1,···i
,σ n) is a mixed-strategy
Nai
sh equilibrium if
j noagenticangaininutilitybydeviatingfromσ i whenall
otheragentsplayσ .Algorithm1setsthemeta-strategyto
whereπ⋆ isthetargetinflationrate.And,λ > 0weighsthe −i
beaNashequilibriumofthelatestempiricalgame.
productionrewardinrelationtomeetingtheinflationtarget.
To compare the quality of strategies got by IMARL and
PSRO,wecomputeregretvaluesagainstadeviationsetcon-
3.4 Government
taining strategies of both methods. As in (Smith, Anthony,
Thegovernmentistheregulatoryagencythatcollectstaxes
and Wellman 2020), define the total regret of joint strategy
fromhouseholdsontheirlaborincomeinordertomaintain σ=(σ ,··· ,σ )withrespecttodeviationsetΣas
1 n
infrastructure. It sets an income tax rate and can choose to
n (cid:18) (cid:19)
distributeaportionofthecollectedtaxesbacktohouseholds R(σ,Σ)=(cid:88) maxU (σ˜ ,σ )−U (σ ,σ )
i i −i i i −i
astaxcreditsinordertoimprovehouseholdsocialwelfare.
i=1
σ˜i∈ΣAlgorithm1:PSRO(Lanctotetal.2017) Temporalprogression. Att=0,householdshave$0sav-
ings, firms have 0 units of inventory and set default prices
Input: InitialpolicysetsΠ ={π0}foreveryagenti.
i i andwages,thecentralbanksetsdefaultinterestrate,andthe
Parameter: PSROepochsN anddeepRLepisodesM.
governmentsetsdefaulttaxrateandgives$0oftaxcredits.
1: SimulateutilitiesU(π0,··· ,π0)
1 n For each subsequent step t ≥ 0, households take in obser-
2: InitializeNashequilibriumσ i =1(π0 i)foreveryi vations to set labor hours and request consumption. Firms
3: whileEpochein1,··· ,N do
use labor to produce goods (3)-(4), fulfil consumption (1)
4: forAgentiin1,··· ,ndo
andupdateinventory(5).Theythensetsprice,wageforthe
5: forRLepisodekin1,··· ,M do
nextstep.Eachhouseholdupdatessavingsbasedonrealized
6: Sampleotheragentpoliciesπ −i ∼σ −i consumption(2)andpaystaxestothegovernment(2).The
7: Trainoracleπe
i
overtrajectoryfrom(πe i,π −i)
centralbankmonitorspricesandproductionstosetinterest
8: endfor
rate for the next step. The government collects taxes to set
9: AugmentpolicysetΠ i =Π i∪{πe i} taxrateanddistributecreditsinthenextstep.
10: endfor
11: SimulateutilitiesU(π)fornewpoliciesπ∈Π Calibration and realism. While the utility of our ABM
12: ComputeNashequilibriumσfromU(Π) framework lies in qualitative analysis of economic scenar-
13: endwhile ios rather than forecasting, we take three steps to ensure
Output:Nashequilibriumσ=(σ ,··· ,σ ). simulatorvalidity.First,webaseagentparametersonexist-
1 n
ingliterature.Second,ouractionspacesreflecttypicalreal-
world values from the US Bureau of Labor Statistics (U.S.
where the term within the summation captures regret to Bureau of Labor Statistics 2023c) e.g., wages chosen from
agent i. Since Σ = ΣIMARL ∪ ΣPSRO, this metric assesses {7.25,19.65,32.06,44.46,56.87}, with $7.25 per hour as
utility loss when agents are confined to one method over the minimum wage and $32.06 as the default. Lastly, we
the other. As IMARL gives pure strategies, σIMARL = validate our simulator by reproducing key economic styl-
(1{πIMARL},··· ,1{πIMARL}). ized facts, such as the inverse relationship between firm
1 n
price and consumption and the direct relationship between
5 ExperimentalFramework inflation and interest rates (Svensson 2020). Also, (Dong,
Dwarakanath, and Vyetrenko 2023) verifies that our simu-
5.1 EconomicSystemSimulator
lateddatamatchesreal-worldtrendsintheChildTaxCredits
Our simulator is built on ABIDES, an agent-based inter-
scenario.Seetheappendixformoredetails.
active discrete event simulator widely used to simulate fi-
nancial markets with diverse traders (Byrd, Hybinette, and 5.2 Scenario:HeterogeneityinHouseholdSkills
Balch 2019). ABIDES agent have access to their internal
Every household i has a distinct skill level per firm j, de-
states, and receive information about other agents via mes-
noted ω . We explore the impact of household skills on
sages. A simulation kernel handles message passing, and ij
theirlaborpreferencesatfirms.Consideraneconomywith2
runs simulations over a specified time horizon while main-
heterogeneouslyskilledhouseholds,2heterogeneousfirms,
tainingagenttimestamps.ABIDESwasextendedforsingle
centralbankandgovernmentoverahorizonof10years(40
agentRLusinganOpenAIGymstyleextensionin(Amrouni
quarters), where all agents use RL. Firm 1 is a less labor-
etal.2021).WeexpandthistotheMARLsettingbyhaving
intensive technology firm, while firm 2 is a more labor-
a single Gym agent control action setting of all RL agents,
intensive agriculture firm. Household 1 is more skilled at
allowingforamixoflearningandrule-basedagents.
firm 1, with both households having similar skills for firm
Agent configuration. There are four agent classes, one 2. Households have γ = 0.33, ν = 0.5, µ = 1.0 and
per type as in Section 3, each initialized with default het- (cid:20) ω ω (cid:21) (cid:20) 2 1(cid:21)
β = 0.99withskills 11 12 = .Firmshave
erogeneity parameters sourced from literature. Parameters H ω ω 1 1
21 22
forhouseholdagentsfollow(Chenetal.2021),firmagents β = 0.99,ρ = 0.97,ε¯= 0,σ = 0.1,andχ = 0.1.Firm1
F
follow(Hill,Bardoscia,andTurrell2021),andcentralbank beinglesslaborintensivehasproductionelasticityα = 2,
follow (Hinterlang and Ta¨nzer 2021). See the appendix for while firm 2 has α = 1. Central bank’s paramete1 rs ar3 e
2
more details. Simulation runs require specification of the π⋆ =1.02,λ=0.25andβ =0.99.Thegovernmentre-
CB
horizoninquarters,numberofagentspertype,andhetero- distributes10%oftaxesascredits,withξ =0.1,β =0.99,
G
geneityparametersifdifferentfromthedefaultvalues. α =1,β =1.2,l =10−3andl =β +2α =3.2.
l l 1 2 l l
Agentcommunication. Sinceagentscanonlyaccesstheir
5.3 Learningdetails
internal states, any information from other agents must be
requested using messages. Recipients of messages respond We use a single policy network per agent type that also in-
bysharingapartoftheirinternalstateswiththesender.For putsheterogeneityparameterstodistinguishbetweenagents
example,thehouseholdagentsendsamessagetoeachfirm ofthesametype.TheProximalPolicyOptimization(PPO)
agentaskingforitspriceandwage.Thefirmagentresponds algorithmwithintheRLlibpackage(Schulmanetal.2017;
bysendingthatinformationwhichisusedinthehousehold’s Liang et al. 2018) is used to learn policies within PSRO.
observation. This applies to every feature in an agent’s ob- PPOisalsousedwithinIMARLasabaselineforcompari-
servationthatisexternaltoitself,andpertainstoallagents. son.BothmethodsusenormalizedobservationsandrewardsFigure1:DiscountedcumulativerewardsduringtrainingforIMARL(left)andPSRO(right).
Figure 2: Household labor hours (left) and consumption Figure3:Price(left)andwage(right)offirmswithIMARL
(right)withIMARL(top)andPSRO(bottom).WithPSRO, (top) and PSRO (bottom). While F2 is cheaper than F1 in
less-skilledH2worksmoreandconsumesmorethanH1. bothschemes,thecontrastislowerwithPSRO.
tostabilizelearning.Learningratesare2×10−3,2×10−3, worksimilarhourswithIMARL,household1worksfewer
2×10−3, 5×10−3 for the household, firm, central bank hours than household 2 with PSRO. Thus, the impact of
and government policies within PSRO, and are 2 × 10−3, lower skill of household 2 forcing it work longer hours to
5×10−3,5×10−3,1×10−2forIMARL.Then=4poli- achieverewardsisexplicitunderPSRO.WithPSRO,house-
ciesaretrainedoverM = 100episodesoverN = 8PSRO hold1beingmoreskilledatfirm1,worksmorehoursthere
epochs. Our choices for (N,M) are restricted by the need (red line) than at firm 2 (green line), while household 2,
to simulate utilities for O(e3) new joint policies in epoch equallyskilledatbothfirms,showsnosuchpreference.Sim-
e ∈ {1,··· ,N} over 10 runs. We parallelize runs across ilarly, while both households request similar consumption
agenttypesperepochinline4ofAlgorithm1.Seetheap- with IMARL, household 1 requests less than household 2
pendixforadditionallearningdetails. withPSRO.Also,bothhouseholdsconsumemorefromfirm
2thanfromfirm1underbothschemes,atrendinfluencedby
6 ExperimentalResults firmpricingasdiscussednext.Thehighercontrastinhouse-
holdbehaviorswithPSROisalsoseeninthelargergapbe-
6.1 Comparisonoftrainingrewards
tweentheirtrainingrewardsinFigure1.
Figure1showsdiscountedcumulativerewardsduringtrain-
Firm policy. Figure 3 compares price (left) and wage
ing for IMARL (left) and PSRO (right) with each subplot
(right) of firms with IMARL (top) and PSRO (bottom). In
correspondingtoagentsofaparticulartype.Faintlinesshow
both schemes, firm 2 sets lower prices than firm 1 due to
perepisoderewards,solidlinesshowtheirmovingaverage,
itshigherproductionoutputgiventhesamelaborinput(see
anddashedblacklinesshowrewardsofthesharedpolicyfor
(4) for elasticity α ), leading to larger inventory accumu-
thattype.DashedgrayverticallinesonthePSROplotsepa- j
lation. To reduce inventory, firm 2 prices its goods lower,
rateonePSROepochfromthenext.Notably,PSROachieves
driving households to prefer consuming from firm 2 over
comparablerewardstoIMARL,reachingsimilarlevelsafter
firm 1. The difference in prices is lower under PSRO than
800episodesasIMARLdoesafter4000episodes.And,the
IMARL, which can be attributed to the equilibrium behav-
PSRO policy for the central bank outperforms its IMARL
iorofhouseholds,whocontinueconsumingmorefromfirm
counterpart. However, note that simulating utilities of new
2aslongasitspriceremainslowerthanfirm1’s.Thus,firm
joint policies at the end of each PSRO epoch becomes in-
2hasnoincentivetokeeppricesverylowaslongasthey’re
creasinglycomputationallyintensiveasepochsprogress.
lower than firm 1’s, and households have no reason to al-
tertheirconsumptionstrategyatequilibrium.Aboutwages,
6.2 Comparisonoflearnedpolicies
firm2offersslightlyhigherwagesthanfirm1underIMARL
Agent policies learned with IMARL and PSRO are tested to encourage more consumption and clear inventory. How-
in500episodes.And,histogramsofagentobservationsand ever,bothfirmsofferidenticallylowwagesunderPSRO.
actionspertimestepacrosstestepisodesareplottedinsub-
Central Bank policy. Figure 4 compares interest rate set
sequentfigureswhereverticallinesindicatemeanvalues.
by the central bank (left) and inflation (right) under both
Household policy. Figure 2 compares labor hours (left) schemes.WithIMARL,thecentralbankutilizesallavailable
and consumption requests (right) of households with rateoptions,whereaswithPSRO,ittendstoavoidtheinter-
IMARL (top) and PSRO (bottom). While both households mediate rates of 1.625% and 4.375%. Still, both methodsHousehold Firm CentralBank Government Total
IMARL 0.00(0.00%) 3.82(5.33%) 0.00(0.00%) 0.39(0.06%) 4.21(0.22%)
PSRO 0.00(0.00%) 0.00(0.00%) 0.17(1.27%) 0.00(0.00%) 0.17(0.01%)
Table1:Absolute(andpercentage)regretacrossagenttypes,withPSROachievinglowertotalregretcomparedtoIMARL.
Discussion. With PSRO, we observe a larger distinction
between heterogeneous households: lower-skilled house-
hold 2 works more and consumes more than higher-skilled
household 1. The distinction between heterogeneous firms
Figure4:Interestratesetbythecentralbank(left)andinfla- is lower, with prices and wages getting closer while main-
tion (right) with IMARL and PSRO. PSRO uses fewer rate taining a small price difference for competitive advantage
optionsthanIMARL,whileachievingtargetinflation. through households’ consumption preferences. The central
bankachievestargetinflationwithasmaller(butmoredis-
parate)setofrateoptions,andthegovernmentcollectssim-
ilartaxrevenuewithlowerrates,drivenbyincreasedhouse-
holdlaborcomparedtoIMARL.MARLismorechallenging
than single-agent RL due to environment non-stationarity
Figure 5: Tax rate (left) and total tax collected (right) by from multiple evolving agents. While MARL policies are
thegovernmentwithIMARLandPSRO.Thegovernmentis sensitivetothetrainingscheme(BowlingandVeloso2000,
able to collect similar tax amounts from households while 2002), IMARL and PSRO also have different objectives.
settinglowertaxrateswithPSROduetohigherlaborhours. IMARL focuses on concurrently finding policies that max-
imize rewards without considering equilibrium concepts. It
doesn’taddresshowasingleagentmightadjustitspolicyif
successfully achieve the target inflation rate of π⋆ = 1.02 thoseofotheragentswerefixed.However,PSROwithNash
on average. But, we observe quarters with very high infla- equilibriummeta-strategies,aimstoproduceasetofpolicies
tion with IMARL (see tails of blue histogram) unlike con- wherenoagenthasanincentivetochangetheirpolicyifall
trolledinflationwithPSRO.Seetheappendixfordetailson othersfollowtheirPSRO-derivedpolicies.Toquantitatively
thetemporalevolutionofinflationandinterestrates. comparepoliciesfrombothschemes,wecomputeabsolute
regret and percentage regret that reflect utility loss when
Governmentpolicy. Figure5comparestaxrate(left)and
agentsarerestrictedtoonepolicyoveranother.Weseethat
totalhouseholdtaxcollected(right)underbothschemes.Al-
PSROachieveslowertotalregret,indicatingthatagentsfol-
thoughthegovernmentsetslowertaxrateswithPSROthan
lowing PSRO policies are less incentivized to change their
IMARL,thetaxcollectedremainssimilardueincreasedla-
policy,evenwithaccesstoIMARLpolicies.
borhourswithPSROasinFigure2.PSROagentslearnan
equilibrium where households work more while paying a
7 Conclusion
smallerproportionoftheirincomeintaxes.InIMARL,high
taxratesincentivizehouseholdstoreducelabortominimize Weaimtoexpandtheuseofagent-basedmodelingandrein-
taxpayments,whichinturnpushesthegovernmenttoraise forcement learning in economics by incorporating a multi-
taxratesfurthertomaintaincreditredistribution.Incontrast, agent reinforcement learning (MARL) scheme grounded
PSROpoliciesstabilizeatanequilibriumwhereneitherthe in equilibrium concepts. We introduce a highly config-
householdsnorthegovernmenthaveanincentivetodeviate. urable multi-agent economic simulator that allows users to
define the number, types, and heterogeneity of objective-
Regret metrics. Table 1 shows the regret of strategies
maximizing economic agents, enabling the simulation of
σIMARLandσPSROagainstdeviationsetΣ=ΣIMARL∪ΣPSRO
various counterfactual scenarios. By implementing Policy
across the four agent types, along with total regret. Since
SpaceResponseOracles(PSRO),amethodcombiningem-
utilityunitsdifferacrossagenttypes,summingregretvalues
piricalgame-solvingwithdeepRL,welearnpoliciesforhet-
tocomputetotalregretmaynotbemeaningful.So,wealso
erogeneouseconomicagentsthatformpartofaNashequi-
reportpercentageregretas
maxσ˜i∈ΣUi(σ˜i,σ−i)−Ui(σi,σ−i)
,in librium, linking MARL to economic equilibria. Our com-
Ui(σi,σ−i)
parenthesesnexttoabsoluteregret.Totalpercentageregretis parison of PSRO and independent MARL in a scenario in-
gotbydividingtotalregretbythetotalutilityacrossagents volvinghouseholdskillsandlaborpreferencesunderscores
for each scheme. While households experience zero regret PSRO’sstrengthsinfindingpolicieswithlowertotalregret.
underbothschemes,PSROachieveslowertotalregretcom- While analytically quantifying equilibria in economic sys-
paredtoIMARL.Firmsandgovernmentexperiencehigher temswithdiverse,heterogeneousagentsischallenging,we
regret under IMARL, where firm 2 sets lower prices and hopethisframeworkwithempiricalgame-solvingbroadens
higher wages, and the government collects slightly less in theuseofagent-basedmodelingineconomics,offeringpoli-
taxes. Both schemes result in low total percentage regret, cymakersapowerfultooltoexplorepolicyoutcomesinsim-
withPSROachievingnear-zerototalpercentageregret. ulatedeconomies(FarmerandFoley2009).Disclaimer Claus, C.; and Boutilier, C. 1998. The dynamics of re-
inforcement learning in cooperative multiagent systems.
Thispaperwaspreparedforinformationalpurposesinpart
AAAI/IAAI,1998(746-752):2.
by the Artificial Intelligence Research group of JPMorgan
Chase & Co. and its affiliates (“JP Morgan”) and is not a Cobb,C.W.;andDouglas,P.H.1928. Atheoryofproduc-
productoftheResearchDepartmentofJPMorgan.JPMor- tion. AmericanEconomicAssociation.
gan makes no representation and warranty whatsoever and Curry, M.; Trott, A.; Phade, S.; Bai, Y.; Zheng, S.; et al.
disclaimsallliability,forthecompleteness,accuracyorre- 2022.AnalyzingMicro-FoundedGeneralEquilibriumMod-
liabilityoftheinformationcontainedherein.Thisdocument elswithManyAgentsusingDeepReinforcementLearning.
isnotintendedasinvestmentresearchorinvestmentadvice, Technicalreport.
or a recommendation, offer or solicitation for the purchase
Dawid, H.; Harting, P.; van der Hoog, S.; and Neugart, M.
orsaleofanysecurity,financialinstrument,financialprod-
2016. A heterogeneous agent macroeconomic model for
uct or service, or to be used in any way for evaluating the
policyevaluation:Improvingtransparencyandreproducibil-
meritsofparticipatinginanytransaction,andshallnotcon-
ity.
stituteasolicitationunderanyjurisdictionortoanyperson,
ifsuchsolicitationundersuchjurisdictionortosuchperson Deissenberg, C.; Van Der Hoog, S.; and Dawid, H. 2008.
wouldbeunlawful. EURACE: A massively parallel agent-based model of the
Europeaneconomy. Appliedmathematicsandcomputation,
References 204(2):541–552.
Del Negro, M.; Giannoni, M.; Li, P.; Moszkowski, E.; and
Adler,J.L.;Satapathy,G.;Manikonda,V.;Bowles,B.;and
Smith, M. 2015. New York Fed DSGE Model (Version
Blue, V. J. 2005. A multi-agent approach to cooperative
1002). https://github.com/FRBNY-DSGE/DSGE.jl.
trafficmanagementandrouteguidance. TransportationRe-
searchPartB:Methodological,39(4):297–318. Del Negro, M.; Giannoni, M. P.; and Schorfheide, F. 2015.
InflationintheGreatRecessionandNewKeynesianModels.
Amrouni, S.; Moulin, A.; Vann, J.; Vyetrenko, S.; Balch,
American Economic Journal: Macroeconomics, 7(1): 168–
T.;andVeloso,M.2021. ABIDES-gym:gymenvironments
96.
formulti-agentdiscreteeventsimulationandapplicationto
financialmarkets. InProceedingsoftheSecondACMInter- Del Negro, M.; and Schorfheide, F. 2013. DSGE model-
nationalConferenceonAIinFinance,1–9. based forecasting. In Handbook of economic forecasting,
volume2,57–140.Elsevier.
Arthur,W.B.2021. Foundationsofcomplexityeconomics.
NatureReviewsPhysics,3(2):136–145. Dong, J.; Dwarakanath, K.; and Vyetrenko, S. 2023. An-
alyzing the Impact of Tax Credits on Households in Sim-
Atashbar, T.; and Shi, R. A. 2023. AI and macroeconomic
ulated Economic Systems with Learning Agents. arXiv
modeling: Deep reinforcement learning in an RBC model.
preprintarXiv:2311.17252.
InternationalMonetaryFund.
Dosi, G.; Fagiolo, G.; Napoletano, M.; Roventini, A.; and
Bowling,M.;andVeloso,M.2000. Ananalysisofstochas-
Treibich,T.2015. Fiscalandmonetarypoliciesincomplex
ticgametheoryformultiagentreinforcementlearning.Cite-
evolving economies. Journal of Economic Dynamics and
seer.
Control,52:166–189.
Bowling,M.;andVeloso,M.2002. Multiagentlearningus-
Dosi,G.;Fagiolo,G.;andRoventini,A.2006.Anevolution-
ing a variable learning rate. Artificial intelligence, 136(2):
ary model of endogenous business cycles. Computational
215–250.
Economics,27:3–34.
Brusatin, S.; Padoan, T.; Coletta, A.; Gatti, D. D.; and
Dosi, G.; Napoletano, M.; Roventini, A.; and Treibich, T.
Glielmo,A.2024. Simulatingtheeconomicimpactofratio-
2017. MicroandmacropoliciesintheKeynes+Schumpeter
nalitythroughreinforcementlearningandagent-basedmod-
evolutionary models. Journal of Evolutionary Economics,
elling. arXivpreprintarXiv:2405.02161.
27:63–90.
Busoniu, L.; Babuska, R.; and De Schutter, B. 2008. A
Dwarakanath, K.; Vyetrenko, S.; Tavallali, P.; and Balch,
comprehensive survey of multiagent reinforcement learn-
T. 2024. ABIDES-Economist: Agent-Based Simulation of
ing. IEEETransactionsonSystems,Man,andCybernetics,
Economic Systems with Learning Agents. arXiv preprint
38(2):156–172.
arXiv:2402.09563.
Byrd,D.;Hybinette,M.;andBalch,T.H.2019. Abides:To-
wardshigh-fidelitymarketsimulationforairesearch. arXiv Evans,G.W.;andHonkapohja,S.2005. Policyinteraction,
preprintarXiv:1904.12066. expectationsandtheliquiditytrap. ReviewofEconomicDy-
namics,8(2):303–323.
Chen, M.; Joseph, A.; Kumhof, M.; Pan, X.; Shi, R.; and
Farmer, J. D.; and Foley, D. 2009. The economy needs
Zhou,X.2021. Deepreinforcementlearninginamonetary
model. arXivpreprintarXiv:2104.09368. agent-basedmodelling. Nature,460(7256):685–686.
Christiano, L. J.; Eichenbaum, M.; and Evans, C. L. 2005. Federal Reserve Board. 2023. Selected Interest Rates
Nominal rigidities and the dynamic effects of a shock to (Daily). https://www.federalreserve.gov/releases/h15/.
monetary policy. Journal of political Economy, 113(1): 1– Fudenberg,D.;andLevine,D.K.1998.Thetheoryoflearn-
45. ingingames,volume2. MITpress.Gatti,M.;Cavalin,P.;Neto,S.B.;Pinhanez,C.;dosSantos, Littman, M. L. 1994. Markov games as a framework for
C.; Gribel, D.; and Appel, A. P. 2014. Large-scale multi- multi-agent reinforcement learning. In Machine learning
agent-based modeling and simulation of microblogging- proceedings,157–163.
based online social network. In Multi-Agent-Based Simu-
Lundberg, S. M.; and Lee, S. 2017. A Unified Approach
lationXIV:InternationalWorkshop,17–33.
to Interpreting Model Predictions. In Guyon, I.; Luxburg,
Hahn, F. H. 1973. On the notion of equilibrium in eco- U.V.;Bengio,S.;Wallach,H.;Fergus,R.;Vishwanathan,S.;
nomics:aninaugurallecture. CambridgeUniversityPress. andGarnett,R.,eds.,AdvancesinNeuralInformationPro-
Haldane,A.G.;andTurrell,A.E.2019. Drawingondiffer- cessingSystems30,4765–4774.LongBeach:CurranAsso-
ent disciplines: macroeconomic agent-based models. Jour- ciates,Inc.
nalofEvolutionaryEconomics,29:39–66. Macal, C. M.; and North, M. J. 2005. Tutorial on agent-
Hamill,L.;andGilbert,N.2015. Agent-basedmodellingin basedmodelingandsimulation. InProceedingsoftheWin-
economics. JohnWiley&Sons. terSimulationConference.
Hildenbrand, W. 1983. On the “law of Demand”. Econo- McMahan,H.B.;Gordon,G.J.;andBlum,A.2003. Plan-
metrica:JournaloftheEconometricSociety,997–1019. ning in the presence of cost functions controlled by an ad-
Hill, E.; Bardoscia, M.; and Turrell, A. 2021. Solving het- versary.InProceedingsofthe20thInternationalConference
erogeneousgeneralequilibriumeconomicmodelswithdeep onMachineLearning(ICML-03),536–543.
reinforcementlearning. arXivpreprintarXiv:2103.16977. Mi, Q.; Xia, S.; Song, Y.; Zhang, H.; Zhu, S.; and Wang,
Hinterlang,N.;andTa¨nzer,A.2021.Optimalmonetarypol- J. 2023. TaxAI: A Dynamic Economic Simulator and
icyusingreinforcementlearning.Technicalreport,Deutsche BenchmarkforMulti-AgentReinforcementLearning.arXiv
BundesbankDiscussionPaper. preprintarXiv:2309.16307.
Hu, J.; and Wellman, M. P. 1998. Multiagent Reinforce- Park, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.;
ment Learning: Theoretical Framework and an Algorithm. Liang, P.; and Bernstein, M. S. 2023. Generative agents:
InProceedingsoftheFifteenthInternationalConferenceon Interactive simulacra of human behavior. arXiv preprint
MachineLearning,242–250. arXiv:2304.03442.
Hu, J.; and Wellman, M. P. 2003. Nash Q-learning for Savani, R.; and Turocy, T. L. 2023. Gambit: The package
general-sumstochasticgames. Journalofmachinelearning forcomputationingametheory,Version16.0.2.http://www.
research,4(Nov):1039–1069. gambit-project.org.
InternalRevenueService.2022. 2022TaxRateSchedules. Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and
https://www.irs.gov/media/166986. Klimov,O.2017. Proximalpolicyoptimizationalgorithms.
Kaelbling, L. P.; Littman, M. L.; and Moore, A. W. 1996. arXivpreprintarXiv:1707.06347.
ReinforcementLearning:ASurvey. JournalofArtificialIn-
Schvartzman,L.J.;andWellman,M.P.2009.StrongerCDA
telligenceResearch,4:237–285.
strategiesthroughempiricalgame-theoreticanalysisandre-
Knight,V.;andCampbell,J.2018.Nashpy:APythonlibrary inforcement learning. In Proceedings of The 8th Interna-
for the computation of Nash equilibria. Journal of Open tional Conference on Autonomous Agents and Multiagent
SourceSoftware,3(30):904. Systems-Volume1,249–256.
Koster, R.; Balaguer, J.; Tacchetti, A.; Weinstein, A.; Zhu, Smith, M.; Anthony, T.; and Wellman, M. 2020. Iterative
T.; Hauser, O.; Williams, D.; Campbell-Gillingham, L.; Empirical Game Solving via Single Policy Best Response.
Thacker, P.; Botvinick, M.; et al. 2022. Human-centred InInternationalConferenceonLearningRepresentations.
mechanismdesignwithDemocraticAI. NatureHumanBe-
Srbljinovic´, A.; and Sˇkunca, O. 2003. An introduction to
haviour,6(10):1398–1407.
agent based modelling and simulation of social processes.
Krusell,P.;andSmith,A.A.,Jr.1998. Incomeandwealth
Interdisciplinary Description of Complex Systems, 1(1-2):
heterogeneity in the macroeconomy. Journal of political
1–8.
Economy,106(5):867–896.
Statista. 2023. Per capita consumption of the bread
Kydland,F.E.;andPrescott,E.C.1982. Timetobuildand
and cereal products in the United States from 2017 to
aggregatefluctuations.Econometrica:JournaloftheEcono-
2027. https://www.statista.com/forecasts/1374278/size-of-
metricSociety,1345–1370.
the-bread-and-cereal-product-market-in-the-united-states.
Lanctot, M.; Zambaldi, V.; Gruslys, A.; Lazaridou, A.;
Stiglitz, J. E. 2018. Where modern macroeconomics went
Tuyls,K.;Pe´rolat,J.;Silver,D.;andGraepel,T.2017.Auni-
wrong.OxfordReviewofEconomicPolicy,34(1-2):70–106.
fied game-theoretic approach to multiagent reinforcement
learning. Advances in neural information processing sys- Svensson, L. E. 2020. Monetary policy strategies for the
tems,30. FederalReserve. Technicalreport,NationalBureauofEco-
nomicResearch.
Liang,E.;Liaw,R.;Nishihara,R.;Moritz,P.;Fox,R.;Gold-
berg,K.;Gonzalez,J.;Jordan,M.;andStoica,I.2018. RL- Tan, M. 1993. Multi-agent reinforcement learning: Inde-
lib:AbstractionsforDistributedReinforcementLearning.In pendentvs.cooperativeagents. InProceedingsofthetenth
InternationalConferenceonMachineLearning. internationalconferenceonmachinelearning,330–337.Taylor, J. B.; and Williams, J. C. 2010. Simple and robust CalibrationandRealism
rules for monetary policy. In Handbook of monetary eco-
Table2providesdetailsonthevaluesandsourcesfordefault
nomics,volume3,829–859.Elsevier.
agentparametersinoursimulator.Defaultagentparameters
Tesfatsion,L.;andJudd,K.L.2006. Handbookofcompu- are replaced by otherwise specified values when modeling
tationaleconomics:agent-basedcomputationaleconomics. heterogeneity.Agentactionspacescompriseauniformgrid
Elsevier. ofvaluesaroundthedefaultvaluesinbold,whileadhering
toanyminimumvalueconstraints.
Trott, A.; Srinivasa, S.; van der Wal, D.; Haneuse, S.; and
Zheng, S. 2021. Building a foundation for data-driven, in-
VerificationofStylizedFacts
terpretable,androbustpolicydesignusingtheaieconomist.
arXivpreprintarXiv:2108.02904. To illustrate the ability of our simulator to reproduce eco-
nomicstylizedfacts,weplayouttheagentpolicieslearned
U.S.BureauofLaborStatistics.2023a. Averagehourlyand
withIMARLintestepisodeswhereweobserveconformity
weekly earnings of all employees on private nonfarm pay-
tothefollowingstylizedfacts.
rolls by industry sector, seasonally adjusted. https://www.
bls.gov/news.release/empsit.t19.htm. TheLawofDemand. Thelawofdemandstatesthatcon-
U.S. Bureau of Labor Statistics. 2023b. Average sumption of a good decreases as the price of the good in-
price data (in U.S. dollars), selected items. https: creases given that other factors remain the same (Hilden-
//www.bls.gov/charts/consumer-price-index/consumer- brand1983).Weplotthepricessetbybothfirms(left)along-
price-index-average-price-data.htm. sidethetotalconsumptionacrosshouseholdsperfirm(right)
inFigure6.Weplotthedistributionacrosstestepisodesof
U.S.BureauofLaborStatistics.2023c. EmploymentSitua-
averagefirmpricesperepisode.Weobservethatfirm1that
tion. https://www.bls.gov/news.release/empsit.toc.htm.
setshigherpricesreceiveslowerconsumption.
USA.gov. 2023. Minimum wage. https://www.usa.gov/
Positive impact of inflation on interest rate. Standard
minimum-wage.
monetary policy rules express the interest rate set by the
VonNeumann,J.1928.OntheTheoryofGamesofStrategy. Central Bank (CB) as an increasing function of inflation
MathematischeAnnalen,100:295–320. (TaylorandWilliams2010).Thus,theinterestrateisraised
Von Neumann, J.; and Morgenstern, O. 2007. Theory of in response to high inflation and, is lowered in response
gamesandeconomicbehavior(60thAnniversaryCommem- to low inflation. To study the impact of inflation on the
orativeEdition). Princetonuniversitypress. learnedCBpolicy,weperformanexplainabilityanalysisof
theProximalPolicyOptimizationpolicynetworkthattakes
Vorotnikov,S.;Ermishin,K.;Nazarova,A.;andYuschenko,
in observations to give out CB action of interest rate. We
A. 2018. Multi-agent robotic systems in collaborative
use the tool called SHAP (for SHapley Additive exPlana-
robotics. In Interactive Collaborative Robotics: Third In-
tions) to decompose the network output locally into a sum
ternationalConference,270–279.
of effects attributed to each observation feature (Lundberg
Walsh, W. E.; Das, R.; Tesauro, G.; and Kephart, J. O. and Lee 2017). Figure 7 shows the impact of the CB’s ob-
2002. Analyzing complex strategic interactions in multi- servationfeaturesoninterestrate,sortedindecreasingorder
agent systems. In AAAI-02 Workshop on Game-Theoretic oftheirimportances.Thelengthofeachbarcorrespondsto
andDecision-TheoreticAgents,109–118. the magnitude of importance of the feature with red show-
ing positive impact and blue showing negative impact. The
Wellman,M.P.2006.Methodsforempiricalgame-theoretic
featurenamesareprecededbytheirnumericalvaluesonthe
analysis. InAAAI,volume980,1552–1556.
vertical axis. Figure 7 is interpreted as follows. The previ-
Wellman,M.P.2020.Economicreasoningfromsimulation-
oustotalpriceacrossfirmsisthemostimpactfulfeature,fol-
basedgamemodels.Œconomia.History,Methodology,Phi-
lowedbythecurrenttotalpriceandthen,thetotalproduction
losophy,(10-2):257–278.
across firms. Observe that current total price is lower than
Woodford, M. 2009. Convergence in macroeconomics: el- thatpreviously,indicatinglowinflationwhichimpactsinter-
ements of the new synthesis. American economic journal, estrateinanegativemanner.Thisverifiesthepositiverela-
1(1):267–279. tionshipbetweeninflationandinterestrate.Inaddition,low
valueforproductionimpactsinterestrateinanegativeman-
Wright, M.; Wang, Y.; and Wellman, M. P. 2019. Iterated
ner.Thisisbecausewhenproductionislow,theCBwantsto
Deep Reinforcement Learning in Games: History-Aware
increaseproductionbypushinghouseholdstoprovidemore
TrainingforImprovedStability. InProceedingsofthe2019
labor.Thisisdonebyreducinginterestratessothathouse-
ACMConferenceonEconomicsandComputation,EC’19,
holds earn lower interest on their savings, causing them to
617–636.NewYork,NY,USA:AssociationforComputing
providelaborsoastoearnlaborincome.
Machinery.
Zheng,S.;Trott,A.;Srinivasa,S.;Parkes,D.C.;andSocher, LearningDetails
R.2022.TheAIEconomist:Taxationpolicydesignviatwo-
Each agent has continuous observation space and discrete
level deep multiagent reinforcement learning. Science Ad-
actionspaceasdescribedinTable2.Inordertoeaselearn-
vances,8(18):2607.
ing, we normalize agent rewards as in Table 3. LearningAgent VariableType Notation Value Source
Householdi Parameter ω 1.00
ij
γ 0.33 (Chenetal.2021)
i
ν 0.50 (Chenetal.2021)
i
µ 0.10 (Chenetal.2021)
i
β 0.99 (Chenetal.2021)
i,H
Action n {0,240,480,720,960} 40hoursperweek
t,ij
≈480hoursperquarter(12weeks)
creq {0,6,12,18,24} Percapitaconsumptionof1lb
t,ij
ofbreadperweek(Statista2023).
Firmj Parameter ρ ,ε¯ ,σ 0.97,0.00,0.10 (Hill,Bardoscia,andTurrell2021)
j j j
α 2 (Hill,Bardoscia,andTurrell2021)
j 3
χ 0.10
j
β 0.99
j,F
Action w {7.25,19.65,32.06,44.46,56.87} Minimumwage(USA.gov2023)and
t,j
averagehourlyearningsinMay2022
(U.S.BureauofLaborStatistics2023a).
p {188,255,322,389,456} Priceofbread/lbinMay2022
t,j
(U.S.BureauofLaborStatistics2023b)
multipliedby200consumablegoods.
CentralBank Parameter π⋆ 1.02 (Svensson2020;HinterlangandTa¨nzer2021)
λ 0.25 (Svensson2020)
β 0.99 (HinterlangandTa¨nzer2021)
CB
Action r {0.00250,0.01625,0.03,0.04375,0.05750} Federalfundsrate
t
(FederalReserveBoard2023)
Government Parameter ξ 0.10
β 0.99
G
Action τ {0.1000,0.1675,0.2350,0.3025,0.3700} Lowesttohighesttaxbracketsin2022
t
(InternalRevenueService2022)
(cid:80)
f {1,2,3,4,5}then,normalizedby f
t,i k t,k
Table2:Defaultagentparametersandagentactionspacesinoursimulator.Bold-facedvaluesrepresentdefaultactions.
Agent Reward Normalizedreward
Householdi (cid:80) u(c ,n ,m ;γ ,ν ,µ ) (cid:80) u(c ,nt,ij, mt+1,i ;γ ,ν ,µ )
j t,ij t,ij t+1,i i i i j t,ij n¯i (n¯i(cid:80) jw¯j)(cid:16)(cid:80) (cid:80)j jpt 1,j(cid:17) i i i
Firmj p t,j(cid:80) ic t,ij −w t,j(cid:80) in t,ijω ij −χ jp t,jY t+1,j pt p, ¯j j(cid:80) (cid:80)i ic c¯t i,ij − wt w¯,j j(cid:80) (cid:80)i in n¯t i,ijω ij −χ jp¯jexp(p ε¯t j,j +Y 1t 0+ σ1 j,j )(cid:80) in¯i
CentralBank −(π
−π⋆)2+λ(cid:16)
(cid:80) y
(cid:17)2
−(π
−π⋆)2+λ(cid:16)(cid:80) jyt,j(cid:17)2
wherey¯ =((cid:80) n¯ )αj
t j t,j t (cid:80) jy¯j j i i
(cid:80) (cid:80)
Government l R l ×NormalizedrewardofHouseholdi
i t,i t,i,H i t,i
Table3:Normalizationofagentrewards.Valuesfordefaultlaborhoursn¯ ,consumptionc¯,pricep¯ andwagew¯ aregivenby
i i j j
thebold-facedvaluesinTable2.
ratesperagenttypearesetviaagridsearchover{10−3,2× 5. And, PSRO epochs run in sequence in line 3. For line
10−3,5×10−3,10−2}foreachlearningscenario.Thefinal 11, we run 10 parallel simulations per joint policy to com-
learningratesarethefirstsetthatachievedimprovementand pute agent utilities as their average discounted cumulative
convergenceintrainingrewardsforallagents. rewards over those runs. This was run on an AWS ec2 in-
stance of type c5.12xlarge, with Linux OS, 48 vCPUs and
ComputeDetails no GPU. Experiments were run using python 3.7.16 with
gym0.22.0,ray1.7.0andtensorflow2.8.0.Thetrainingtime
We parallelize training across agent types per PSRO epoch
for 8 PSRO epochs with 100 RL episodes per epoch was
in line 4 of algorithm 1. Per agent type, the policy is up-
about7hours.Forcomparison,IMARLtrainingover4000
dated sequentially from one RL episode to the next in lineFigure6:Pricessetbyfirms(left)andhouseholdconsump-
tion(right)withIMARL.Observethatfirm1thatsetshigher
pricereceiveslowerconsumptionfromhouseholdsverifying
thelawofdemand.
Figure8:Interestrate(left)andinflation(right)withIMARL
(top)andPSRO(bottom)overtime.Fromthebottomrowof
plots,observethatquarterswithhighinflationseethesetting
ofhighinterestratesandvice-versa.
Figure 7: SHAP analysis of Central Bank policy that sets
interest rate given observations. Notice that high previous Figure 9: Distribution of change in interest rate between
priceandrelativelylowercurrentpriceinfluenceratenega- quarterswithIMARLandPSRO.WithPSRO,rateschange
tivelyalongsidelowproductioninfluencingratenegatively. lessfrequently,butbylargeramountswhentheydo.
episodes took under an hour on the same instance without counted cumulative rewards over 100 test episodes. Figure
anyadditionalparallelizationonourend. 10showsutilitiesofeachofthefouragenttypes,whenthey
unilaterally deviate from their IMARL/PSRO policy to the
AdditionalExperimentalResults other.Theseutilitiesareusedtocomputetheregretmetrics
in Table 1. For example, the regret of IMARL for house-
CentralBankpolicy
holdsiscalculatedasfollows:whenallotheragentsadhere
Figure8showsthetemporalevolutionofinterestratesetby totheirIMARLpolicies(toprow),householdsgainnoutil-
thecentralbank(forthenextquarter)ontheleftinresponse ity by switching from their IMARL policy (left column) to
toinflation(inthecurrentquarter)ontherightforIMARL theirPSROpolicy(rightcolumn),resultinginaregretof0.
(top) and PSRO (bottom). The blue traces show observa- However,firmsandthegovernmentexperiencepositive re-
tionspertestepisodewiththeblacklineshowingtheaverage gretfromtheIMARLpolicy.
across test episodes. From the bottom row of plots, we ob-
servethatquarterswithhighinflation(relativetoπ⋆ =1.02)
seethesettingofhighinterestrates,andthosewithlowinfla-
tionseethesettingoflowinterestrates.Thisisinlinewith
standardmonetarypolicyrulesthatexpresstheinterestrate
setbytheCentralBankasanincreasingfunctionofinflation
(TaylorandWilliams2010).
Inaddition,weobservetraceswhereinflationisveryhigh
withIMARLwhereasitismorecontainedwithPSRO.Also
see that the central bank seems to change rates more fre-
quentlywithIMARL.Toinvestigatethisfurther,weplotthe
distribution of change in interest rates from one quarter to
thenext(acrosstestepisodes)inFigure9.SeethatPSROhas
higherdensitythanIMARLinthebinfor0change.However
asobservedinsection6.2,whenthecentralbankdoesalter
rateswithPSRO,thechangesarelarger,asittendstoavoid
Figure 10: Agent utilities used in computing regret of
theintermediateratesof1.625%and4.375%.
IMARL and PSRO policies. Regret is given by the differ-
Regretmetric encebetweenoff-diagonalanddiagonalentriesineachrow
whenpositive,andzerootherwise.
The regret metric is derived from agent utilities for each
joint policy, where utility is the average of an agent’s dis-