[
    {
        "title": "Simplified and Generalized Masked Diffusion for Discrete Data",
        "authors": "Jiaxin ShiKehang HanZhe WangArnaud DoucetMichalis K. Titsias",
        "links": "http://arxiv.org/abs/2406.04329v1",
        "entry_id": "http://arxiv.org/abs/2406.04329v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04329v1",
        "summary": "Masked (or absorbing) diffusion is actively explored as an alternative to\nautoregressive models for generative modeling of discrete data. However,\nexisting work in this area has been hindered by unnecessarily complex model\nformulations and unclear relationships between different perspectives, leading\nto suboptimal parameterization, training objectives, and ad hoc adjustments to\ncounteract these issues. In this work, we aim to provide a simple and general\nframework that unlocks the full potential of masked diffusion models. We show\nthat the continuous-time variational objective of masked diffusion models is a\nsimple weighted integral of cross-entropy losses. Our framework also enables\ntraining generalized masked diffusion models with state-dependent masking\nschedules. When evaluated by perplexity, our models trained on OpenWebText\nsurpass prior diffusion language models at GPT-2 scale and demonstrate superior\nperformance on 4 out of 5 zero-shot language modeling tasks. Furthermore, our\nmodels vastly outperform previous discrete diffusion models on pixel-level\nimage modeling, achieving 2.78~(CIFAR-10) and 3.42 (ImageNet 64$\\times$64) bits\nper dimension that are comparable or better than autoregressive models of\nsimilar sizes.",
        "updated": "2024-06-06 17:59:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04329v1"
    },
    {
        "title": "Regularized KL-Divergence for Well-Defined Function-Space Variational Inference in Bayesian neural networks",
        "authors": "Tristan CinquinRobert Bamler",
        "links": "http://arxiv.org/abs/2406.04317v1",
        "entry_id": "http://arxiv.org/abs/2406.04317v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04317v1",
        "summary": "Bayesian neural networks (BNN) promise to combine the predictive performance\nof neural networks with principled uncertainty modeling important for\nsafety-critical systems and decision making. However, posterior uncertainty\nestimates depend on the choice of prior, and finding informative priors in\nweight-space has proven difficult. This has motivated variational inference\n(VI) methods that pose priors directly on the function generated by the BNN\nrather than on weights. In this paper, we address a fundamental issue with such\nfunction-space VI approaches pointed out by Burt et al. (2020), who showed that\nthe objective function (ELBO) is negative infinite for most priors of interest.\nOur solution builds on generalized VI (Knoblauch et al., 2019) with the\nregularized KL divergence (Quang, 2019) and is, to the best of our knowledge,\nthe first well-defined variational objective for function-space inference in\nBNNs with Gaussian process (GP) priors. Experiments show that our method\nincorporates the properties specified by the GP prior on synthetic and small\nreal-world data sets, and provides competitive uncertainty estimates for\nregression, classification and out-of-distribution detection compared to BNN\nbaselines with both function and weight-space priors.",
        "updated": "2024-06-06 17:57:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04317v1"
    },
    {
        "title": "Approximation-Aware Bayesian Optimization",
        "authors": "Natalie MausKyurae KimGeoff PleissDavid ErikssonJohn P. CunninghamJacob R. Gardner",
        "links": "http://arxiv.org/abs/2406.04308v1",
        "entry_id": "http://arxiv.org/abs/2406.04308v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04308v1",
        "summary": "High-dimensional Bayesian optimization (BO) tasks such as molecular design\noften require 10,000 function evaluations before obtaining meaningful results.\nWhile methods like sparse variational Gaussian processes (SVGPs) reduce\ncomputational requirements in these settings, the underlying approximations\nresult in suboptimal data acquisitions that slow the progress of optimization.\nIn this paper we modify SVGPs to better align with the goals of BO: targeting\ninformed data acquisition rather than global posterior fidelity. Using the\nframework of utility-calibrated variational inference, we unify GP\napproximation and data acquisition into a joint optimization problem, thereby\nensuring optimal decisions under a limited computational budget. Our approach\ncan be used with any decision-theoretic acquisition function and is compatible\nwith trust region methods like TuRBO. We derive efficient joint objectives for\nthe expected improvement and knowledge gradient acquisition functions in both\nthe standard and batch BO settings. Our approach outperforms standard SVGPs on\nhigh-dimensional benchmark tasks in control and molecular design.",
        "updated": "2024-06-06 17:55:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04308v1"
    },
    {
        "title": "Stratified Prediction-Powered Inference for Hybrid Language Model Evaluation",
        "authors": "Adam FischJoshua MaynezR. Alex HoferBhuwan DhingraAmir GlobersonWilliam W. Cohen",
        "links": "http://arxiv.org/abs/2406.04291v1",
        "entry_id": "http://arxiv.org/abs/2406.04291v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04291v1",
        "summary": "Prediction-powered inference (PPI) is a method that improves statistical\nestimates based on limited human-labeled data. PPI achieves this by combining\nsmall amounts of human-labeled data with larger amounts of data labeled by a\nreasonably accurate -- but potentially biased -- automatic system, in a way\nthat results in tighter confidence intervals for certain parameters of interest\n(e.g., the mean performance of a language model). In this paper, we propose a\nmethod called Stratified Prediction-Powered Inference (StratPPI), in which we\nshow that the basic PPI estimates can be considerably improved by employing\nsimple data stratification strategies. Without making any assumptions on the\nunderlying automatic labeling system or data distribution, we derive an\nalgorithm for computing provably valid confidence intervals for population\nparameters (such as averages) that is based on stratified sampling. In\nparticular, we show both theoretically and empirically that, with appropriate\nchoices of stratification and sample allocation, our approach can provide\nsubstantially tighter confidence intervals than unstratified approaches.\nSpecifically, StratPPI is expected to improve in cases where the performance of\nthe autorater varies across different conditional distributions of the target\ndata.",
        "updated": "2024-06-06 17:37:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04291v1"
    },
    {
        "title": "Online learning of quantum processes",
        "authors": "Asad RazaMatthias C. CaroJens EisertSumeet Khatri",
        "links": "http://arxiv.org/abs/2406.04250v1",
        "entry_id": "http://arxiv.org/abs/2406.04250v1",
        "pdf_url": "http://arxiv.org/pdf/2406.04250v1",
        "summary": "Among recent insights into learning quantum states, online learning and\nshadow tomography procedures are notable for their ability to accurately\npredict expectation values even of adaptively chosen observables. In contrast\nto the state case, quantum process learning tasks with a similarly adaptive\nnature have received little attention. In this work, we investigate online\nlearning tasks for quantum processes. Whereas online learning is infeasible for\ngeneral quantum channels, we show that channels of bounded gate complexity as\nwell as Pauli channels can be online learned in the regret and mistake-bounded\nmodels of online learning. In fact, we can online learn probabilistic mixtures\nof any exponentially large set of known channels. We also provide a provably\nsample-efficient shadow tomography procedure for Pauli channels. Our results\nextend beyond quantum channels to non-Markovian multi-time processes, with\nfavorable regret and mistake bounds, as well as a shadow tomography procedure.\nWe complement our online learning upper bounds with mistake as well as\ncomputational lower bounds. On the technical side, we make use of the\nmultiplicative weights update algorithm, classical adaptive data analysis, and\nBell sampling, as well as tools from the theory of quantum combs for multi-time\nquantum processes. Our work initiates a study of online learning for classes of\nquantum channels and, more generally, non-Markovian quantum processes. Given\nthe importance of online learning for state shadow tomography, this may serve\nas a step towards quantum channel variants of adaptive shadow tomography.",
        "updated": "2024-06-06 16:54:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.04250v1"
    }
]