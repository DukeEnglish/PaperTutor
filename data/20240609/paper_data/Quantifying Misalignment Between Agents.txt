Quantifying Misalignment Between Agents
AidanKierans1,AvijitGhosh2,1,HananelHazan3,ShiriDori-Hacohen1
1UniversityofConnecticut
2HuggingFace3TuftsUniversity
aidan.kierans@uconn.edu,avijit.g@uconn.edu,hananel@hazan.org.il,shiridh@uconn.edu
Abstract argumentthatsocialmediaAItodayisalreadymisaligned
withhumanity(e.g.throughextensivedisinformationspread).
Growing concerns about the AI alignment problem have
However,thesesocialmediasystemsarenotmisalignedgen-
emergedinrecentyears,withpreviousworkfocusingmainly
erally with all of humanity, but rather they are misaligned
on(1)qualitativedescriptionsofthealignmentproblem;(2)
with certain individuals and groups. For example, human
attemptingtoalignAIactionswithhumaninterestsbyfocus-
ingonvaluespecificationandlearning;and/or(3)focusing agentsintheRussianIRAactivelysowingpropagandamay
onasingleagentoronhumanityasasingularunit.Recent actuallybebenefitingsignificantlyfromFacebook’sAIand
workinsociotechnicalAIalignmenthasmadesomeprogress considerthemselvesalignedwithit.Moreover,FacebookAI
indefiningalignmentinclusively,butthefieldasawholestill islargelyalignedwithitsindividualemployeesandcorpo-
lacksasystematicunderstandingofhowtospecify,describe, rateshareholdersintheareaofmaximizingcorporatevalue,
andanalyzemisalignmentamongentities,whichmayinclude althoughsomeofthoseindividualsmaybemisalignedwith
individual humans, AI agents, and complex compositional
AIwithrespecttotheirownsocialmediaactivityandhow
entitiessuchascorporations,nation-states,andsoforth.Pre-
itimpactstheirwell-being.Ofcourse,evenwithinacoun-
viousworkoncontroversyincomputationalsocialscience
try,therearefrequentandstrongdisagreementsoverwhat
offersamathematicalmodelofcontentionamongpopulations
constitutesmisalignmentandwhy,althoughthetermitself
(ofhumans).Inthispaper,weadaptthiscontentionmodel
tothealignmentproblem,andshowhowmisalignmentcan mightnotbeused.Forexample,peopleonthepoliticalright
varydependingonthepopulationofagents(humanorother- intheUSAwouldarguethattheFacebookAIsystemismis-
wise)beingobserved,thedomaininquestion,andtheagents’ alignedbecauseitissubvertingfreespeech,whilethoseon
probability-weightedpreferencesbetweenpossibleoutcomes. thepoliticalleftwouldarguethatitismisalignedbecauseit
Ourmodeldepartsfromvaluespecificationapproachesand amplifiesdisinformation.Thequestionemerges:withwhom
focusesinsteadonthemorassofcomplex,interlocking,some- aretheyaligned,andonwhat?ThealignmentofanAIagent
times contradictory goals that agents may have in practice.
orsystemmightbewithanadversary,ratherthanwiththe
Weapplyourmodelbyanalyzingseveralcasestudiesranging
developers and/or owners of it; and the alignment or lack
fromsocialmediamoderationtoautonomousvehiclebehavior.
thereofmightbecontext-oragent-dependent.
Byapplyingourmodelwithappropriatelyrepresentativevalue
TheinfluentialARCHESpaperposedthequestion,“where
data,AIengineerscanensurethattheirsystemslearnvalues
maximallyalignedwithdiversehumaninterests. couldonedrawthethresholdbetween‘notverywellaligned’
and ‘misaligned’[..]?” (Critch and Krueger 2020, pg. 14).
Thispaperfocusesonbothofthesechallenges:first,defining
1 Introduction
alignmentacrossmultipleagents;andsecond,quantifying
Inrecentyears,growingconcernshaveemergedaboutthe misalignmentmathematically.
AIalignmentproblem(Russell2019;Christian2020,e.g.). To that end, we propose a novel probabilistic model of
Previousworkhasmostlybeenqualitativeinitsdescription misalignmentthatispredicatedonthepopulationofagents
ofthealignmentproblemand/orhasattemptedtoalignAIac- beingobserved(whetherhuman,AI,oranycombinationof
tionswithhumaninterestsbyfocusingonvaluespecification thetwo),aswellastheproblemareaathandand,byexten-
andlearning(CritchandKrueger2020;Leikeetal.2018); sion,theagents’valuesandsenseofimportanceregarding
alternatively,mostmodelsassumealignmenttoasingleagent thatarea.Todoso,weextendandadaptamodelofcontention
orhumanityasawhole.However,westilllackasystematic fromcomputationalsocialscience(Jang,Dori-Hacohen,and
understandingofhowmisalignmentshouldbedefinedand Allan2017)andapplytheadaptedmodeltothealignment
measured.Onebiggapisthedearthofdiscussiononhuman problem.Wedemonstrateourmodel’scapabilities,including
misalignmentasitrelatestoAI. expressivenessandexplanatorypower,bydemonstratingits
WithrespecttothecurrentAIsystemsthatexisttoday,Rus- applicability to several case studies, which are difficult to
sell(Russell2019)madeaboldbutintuitivelyconvincing accountforinpreviousmodelsofalignment:
Copyright©2024,AssociationfortheAdvancementofArtificial 1. Socialmediamoderation:ApplicationofAIinmultilin-
Intelligence(www.aaai.org).Allrightsreserved. gualcontentmoderationonsocialmediaplatforms.The
4202
nuJ
6
]AM.sc[
1v13240.6042:viXrachallengeliesinensuringthatmoderationsystemsalign havoc on preexisting societal structures. Using our under-
withdiverseculturalnormsandlegalregulationsacross standingofthemessinessandcomplexityinherentinhuman
differentregionstoeffectivelyidentifyandmitigateharm- interactionandsocieties,wearelayingthegroundworkfora
fulcontent. morerobustandnuancedunderstandingofwhatitmeansfor
2. Shopping recommender systems: Showing AI-based AItobealignedinmulti-stakeholder,multi-objectivesettings,
recommendersystemsthatbeenusedbyretailers,toper- whichisfarmorerealisticandrepresentativeofreal-world
sonalize product recommendations for individual cus- situations.
tomers. The focus is on increasing sales and customer Someexistingliteraturehasmentionedthealignmentis-
satisfaction by aligning the recommendations with the suesposedbyvaluepluralism.Intuitively,AIshouldsatisfy
retailer’sgoalsandthecustomer’spreferences. someconsensusbetweenhumanculturalvaluestobeconsid-
ered“alignedwithhumanvalues”(Gabriel2020),butthere
3. Autonomousvehiclepre-collisionscenario:Thealign-
arenomethodsofmeasuringthe(mis)alignmentofvalues
mentofpedestriansandautonomousdriverswithsafety
betweenculturesand/orAIagents.Socialchoicetheorypro-
objectives, particularly in pre-collision scenarios. It in-
videsusefultoolsformeasuringhumanopinionswhichcould
volves analyzing the decision-making process of au-
provideagoodreferencepointforaligningAI(Gabriel2020;
tonomous vehicles to avoid collisions with pedestrians,
Prasad2019),butthatworkleavesopenthequestionsofwho
vehicles,orotherobstacleswhileensuringefficientroute
to align the AI agent(s) to and how to measure that align-
completion.
ment.Likewise,althoughthereisworklinkingthePrincipal-
Our contributions in this paper are as follows: (1) we AgentproblemineconomicstoAISafety(Hadfield-Menell
introduceamathematicalmodelofmisalignment,offering 2021;Goertzel,Iklé,andPotapov2022),weobservealack
itasaprobabilitypredicatedon(a)theobservedpopulation ofdiscussiononhowthedegreeofmisalignmentbetween
of agents and (b) a specific problem area; (2) we propose principalsandagentsistobemeasured.
utilizingtheincompatibilityofagentgoalswithrespectto
Our model departs from existing work by viewing mis-
theproblemareainquestioninordertoarriveatanestimate
alignmentasatraitrootedinapopulationofagents,andin-
forthatprobability;(3)weuseseveralcasestudiestoshow
herentlyquantifiableinnature,ratherthanbinary.Wesuggest
how to find that probability and scale it according to how
thatmisalignmentcanbeseparatelyobservedbetweenpairs
important each problem area is to each agent; and (4) we
ofagentsandthengeneralizedandquantifiedinamuchlarger
discussimplicationsandbenefitsofutilizingthismodelin
group.Ourmodelalsodepartsfrommostotherdefinitionsof
measuringmisalignmentinmixedpopulationsofhumans,AI
alignment,byfocusingonagentvaluesinmultiple“problem
agents,orboth.
areas”orcategories,ratherthanconsideringallcategoriesat
onceandwithequalvalue.Thatsaid,wefollow(Sierraetal.
2 RelatedWork
2021)indefiningvalues/goalsaspreferencesoverstatesof
AsAImodelsbecomemorepowerfulandasmoreresearch theworld.
and funding is poured into building General Purpose AI Oneproposalforsolvingtheproblemofselectingvalues
(GPAI)systems,themisalignmentofsuchmodelsisagrow- foralignmentistocomparenovelsituationstothenearest
ing concern. Several researchers have argued that existing paradigmatic case(s) (Peterson 2019) in conceptual space.
AI systems are causing or exacerbating threats to the in- Our “problem areas” are similar to Peterson’s “paradigm
formation ecosystem such as misinformation and disinfor- cases”inthattheybreaksituationsdowntotherelevantfac-
mation,hatespeech,biasandweaponizedcontroversy(e.g. torsthatwe“knowhowtoanalyze.”However,whilePeterson
BucknallandDori-Hacohen2022;Dori-Hacohenetal.2021; assumesthatagentsagreeonthepreferredresults/principles
Russell2019);andthreateninghumanity’scollectivesense- fromparadigmcasesbutmaydisagreeonwhichcasesapply
making,decision-making,andcooperativeabilities(e.g.Bak- to a situation, we assume instead that all agents agree on
Coleman et al. 2021; Seger et al. 2020). Most prior work whichcasesarerelevant(albeitwithvaryingweight)butmay
hasdefinedmisalignmentasaglobalcharacteristicofanAI disagreeaboutthedesiredoutcomes.
system, and often as a binary (see surveys in Sierra et al.
2021).Somemorerecentworkinmachineethicsattemptto Multi-objectivealignment Contemporarylargelanguage
answerquestionslike“whomshouldAIalignwith?”(seeJi modelsaretypicallyalignedwith“humanvalues”viarein-
etal.2024, p.8),andotherworkmeasuresalignmentwith forcementlearningfromhumanfeedback(RLHF)(Ouyang
respectto“humanvalues”(seeJietal.2024, pp.50-51),but et al. 2022) or reinforcement learning from AI feedback
neitherareaoftheliteraturemeasurestheextenttowhichAI (RLAIF) (Bai et al. 2022). However, since humans have
isalignedtoonegroupversusanother.Previousworkalso multiple,sometimescontradictoryvalues,theemergingdo-
providesaformaldefinitionandmeasureofvaluecompatibil- mainofmulti-objectivealignmentdividesthetasktosepa-
itywithrespecttosystemicnorms(MontesandSierra2022), ratelyoptimizefortargetbehaviorqualitieslikehelpfulness,
butdoesnotaddresscompatibilityofoneagent’svalueswith harmlessness, and honesty (Yang et al. 2024; Rodriguez-
anotheragent’svalues. Soto, Lopez-Sanchez, and Rodriguez-Aguilar 2023; Jang
OurworkdepartsfrommostapproachestoAIAlignment etal.2023;Zhouetal.2023).
andSafetybydrawingoninsightsfromcomputationalsocial However,thesetargetbehaviorssometimescontradicteach
science and rooted in a rich understanding of information other;alanguagemodelmayhelpfullyandhonestlytellsome-
ecosystemthreats,aspaceinwhichAIisalreadywreaking onehowtobuildabomb,butthisisnotharmless.Toaccountfor these contradictions, an approach called Controllable among populations (of humans); that paper addresses the
PreferenceOptimization(Guoetal.2024)providesaway question of “controversial to whom?” This model offers a
totranslateexplicitlyspecifiedscoresfordesiredbehaviors promisingavenueregardingmisalignmentduetoitsempha-
(e.g.<Helpfulness:5><Honesty:3>)todiscreteoutcomes sis on disagreements and its flexibility in covering a wide
thatarealignedwiththosescores.Givensomedataonthe rangeofpopulationsandtopics.Ourmisalignmentmodelex-
scoresthatdifferentpopulationspreferforeachbehavior,and tends,modifiesandadaptsthismodelofcontentioninorder
treatingtypesofbehaviorsasproblemareas,ourmodelcould toquantifymisalignmentfromaprobabilisticstandpointin
beusedtofindwhichscoresshouldbegiventoalanguage amixedpopulationofhumansandAI;wethereforebenefit
modeltomaximizeitscross-populationalignment. from a similar flexibility. Appendix A compares the con-
Likewise,theseobjectivesmaychangeovertime.Methods tentionmodel’snotationtoacomprehensivelistofsymbols
likeMetaAlignerusea“policy-agnostic”approachthat“fa- anddefinitionsusedherein.
cilitateszero-shotpreferencealignmentforunseenobjectives
via in-context learning.” (Yang et al. 2024) The ability to 3 Modelingmisalignmentinpopulations
accountfornewobjectivesiscomplimentedbyourmodel’s
Ourpaperrestsonakeyobservation,whichisthat“solving”
flexibilitywithaddingnewproblemareas.Asthequalities
theAIalignmentproblem,orevendeeplyunderstandingthe
andoutcomespeoplecareaboutchangeovertime,theprob-
complexityinherentinthatproblem,hasaprecondition:an
lem areas considered for measuring AI alignment can be
understandingoftheextantchallengesinaligninghumans,or
editedeasily,andpolicy-agnosticalignmentmethodscanbe
measuringtheiralignment(orlackthereof),whichinitselfis
adjustedtomatch.
anintractableproblemthatisfarfromresolved.Forevidence,
Themeasurementofhumanpopulationvaluesnecessary
oneneedsonlytoopentheirpreferredsourceofnews:the
forprovidingalignmenttargetsisalsochallenging,buthas
evidenceof(human)conflicts,powerstruggles,andstrifeis
promising support in the literature. Schwartz developed a
allaroundus.Thoughtheterm“alignment”isnotoftenuti-
compelling and enduring model of “basic human values”
lizedtodescribesuchconflicts,itisnonethelessappropriate
andhowthey’reexpressedacrosscultures(Schwartz2012).
forit:aligninghumansisacentralchallengeinhumanlife,
Morerecentworkexploresidentifyingcontext-specificval-
fromarmedconflictthroughtomarketcompetitionandeven
ues(Liscioetal.2021),mappingvaluesexpressedbylarge
maritalstrife.
languagemodelstohumanvaluedata(Masoudetal.2024;
This observation calls to mind the phenomenon of con-
Yaoetal.2023),andidentifyingthevalueoriginsofdisagree-
tentioninpublicdiscourse.Buildingonthecomputational
ments (van der Meer et al. 2023; Sutrop and others 2020).
modelforcontention(Jang,Dori-Hacohen,andAllan2017),
There is even work on identifying values expressly for so-
which quantifies the proportion of people in disagreement
ciotechnical AI alignment (Liscio et al. 2023; Osman and
onstancesregardingatopic,parameterizedbytheobserved
d’Inverno2024),thoughitleavesopenthequestionofhow
group of individuals (referred to as the “population”), we
toquantifytheextenttowhichonesetofvaluesoranotheris
nowextendthismodeltocapturemisalignmentwithrespect
heldbyanAIagent.
togoals.Anextensionofthehumanpopulationintoahybrid
Human-AIcollaborationandplanning Theconceptof populationofhumanandAIagentsisfairlystraightforward.
"GoalStateDivergence"describedrecentlyinthecontextof Perhapssurprisingly,thecontentionmodelconvertstoour
human-AIcollaboration(Sikes,Keren,andSreedharan2024) novelmisalignmentmodelinananalogousmanner:whereby
issimilartoourmodelinitsdescriptionofmisalignedgoals contention was determined and quantified by individuals’
asadifferenceinfluents1,butfocusesjustonexpectedversus stances on a given topic (Jang, Dori-Hacohen, and Allan
planned outcomes, and not the various preferences agents 2017),wecanuseindividuals’goalsinagivenproblemarea
mighthavebetweenpossibleoutcomes.Intent-matchingis in order to determine and quantify misalignment. We be-
anotherapproachinthesameniche(ShaikhandGoodrich gin with a general formulation of misalignment, and then
2020). describe a special case in which goals are assumed to be
Asinthemulti-objectivealignmentliterature,thereisalso mutuallyexclusiveandeveryagentholdsonlyonegoal.
workonrecognizinghumanintentions(YounandOh2007)
ProblemAreas Wewillmodelgoalsaspreferenceswith
andobjectives(MecherguiandSreedharan2024),especially
respect to the problem areas, which are sets of related flu-
in proposed solutions to the cooperative inverse reinforce-
ents.Decidinghowtogroupfluentstodecidetheproblem
mentlearning(CIRL)problem.(Hadfield-Menelletal.2024;
areasinascenarioiseasytodointuitively,butdifficultto
Dragan2019;Fisacetal.2020)Combinedwithourmodel,
definerigorously.WewilldiscussthischallengeintheLimi-
thiscouldbeapplicabletorecognizingthegoalsofagents
tationssection,butfornow,wewilluseintuitionandoutside
inasituationinordertoalignanAIagentwithallhumans
examplestochoosetheproblemareasforourcasestudies.
involved.
• InCARLA:thingsthathaveCARLApenaltycoefficients
Jang et al.’s contention model Prior work on contro-
(e.g.acollisionwithapedestrianortheegovehiclerun-
versy(Jang,Dori-Hacohen,andAllan2017)incomputational
ningastopsign)
social science offers a mathematical model of contention
• In a multiplayer adverserial game: a particular player
1A“fluent”isaconditionorfactthatistrueofasituationata winning the game; defeating a particular player of the
giventime.(McCarthyandHayes1981) game• Inabstract:Terminalgoalsandinstrumentalgoals
• Insocialmediamoderation:Proliferationofinformation P(ma|Ω,PA)
onsomesubject(e.g.gunlaws,immigration,reproductive :=P(ia ,ia selectedrandomlyfromΩ
1 2
rights)
|holds(ia ,g ,PA)
1 i
• Indecidingwheretoeatfordinner:abudget,apreferred ∧holds(ia ,g ,PA),
2 j
cuisine
∃g ,g ∈G)·P(conflict|g ,g )
i j i j
Eachofthesebulletpointsisalistoffluents,i.e.conditions =P(ia 1,ia 2selectedrandomlyfromΩ
oftheworld.Wemightwanttosaythatacollectionoffluents |ia ∈G ∧ia ∈G ,∃G ,G ∈Ω,
1 i 2 j i j
isaproblemarea,andalsothateachfluentisitselfaproblem
∃g ,g ∈G)·P(conflict|G ,G )
i j i j
area.Thisreflectshowaconditionoftheworldmaydescribe
NotethatwearesamplingfromΩuniformlyandwithout
orimplymultipleotherconditionsoftheworld.
replacement.Thisdefinitioncanbetriviallyextendedtoany
sub-populationω ⊆Ω(Jang,Dori-Hacohen,andAllan2017,
Definitions LetΩ={ia ..ia }beapopulationofnindi-
1 n
forderivationsee).Likewise,assigningdifferentweightsto
vidualagents(whomaybepeopleorAIsystems).LetPAbe
differentPAscanbeincorporatedbyfollowingtheaddition
aproblemareaofinteresttoatleastoneagentinpopulation
ofimportancetotheJangetal.controversymodel.
Ω. We define A to be a binary variable to denote whether
ornottheagentsarealignedonagivenproblemarea.We Mutuallyexclusivegoals Analogouslytocontention,sig-
alsodefinetwobinaryvaluesaandmaforA,respectively, nificantmisalignmentislikelytooccurwhentherearetwoor
aligned and misaligned. For example, P(A = a|Ω,PA) moremutuallyexclusivegoalswithinaproblemarea.Adding
denotes the probability that Ω is aligned with respect to someconstraintsinthatveinallowedcontentiontobequanti-
PA, which we can shorten to P(a|Ω,PA). By definition, fiedinastraightforwardmanner(Jang,Dori-Hacohen,and
P(a|Ω,PA)+P(ma|Ω,PA)=1. Allan2017);muchofthatmathematicalanalysiscarriesover
Letg denoteagoalwithregardtotheproblemareaPA, neatly into misalignment. First, we restrict every agent to
andlettherelationshipholds(ia,g,PA)denotethatindivid- holdonlyonegoalinaproblemarea;second,weseteach
ualagentiaholdsgoalg withregardtoproblemareaPA. goal to be in conflict with each other goal, and by exten-
LetGˆ = {g 1,g 2,..g k}bethesetofkgoalswithregardsto sion imply that G i ∩G j = ∅. We also set a lack of a goal
problemareaPAinthepopulationΩ.Weuseg todenote tonotbeinconflictwithanyexplicitgoal.Oncethesecon-
0
thatanagentholdsnogoalonacertainPA2: straints are added, we can follow the same calculation as
Jangetal.(Jang,Dori-Hacohen,andAllan2017)inorderto
holds(ia,g ,PA) ⇐⇏∃g ∈Gˆ s.t.holds(ia,g ,PA). computeP(ma|Ω,PA),i.e.,theprobabilityofmisalignment
0 i i
givenaspecificpopulationandproblemarea,resultinginthe
We set G = {g }∪Gˆ be the set of k +1 extant goals followingvalue:
0
withregardtoPAinΩ;putdifferently,∀ia∈Ω,∃g ∈Gs.t.
Σ (|G |) Σ (|G |)
holds(ia,g,PA).Wecannowdefineameasure,conflict, P(ma|Ω,PA)= i∈{1..k} i · j∈{1..k},j̸=i j
denoting the incompatibility of a pair of goals. We use |Ω| |Ω|
P(conflict|g ,g ) = 1 to denote that g and g are in
acompletecoi nflj ict,meaningmutually-exci lusive;lj ikewise,
P(ma|Ω,PA)=
(cid:80)k i=1(|G i|)
·
(cid:80)k j=1(|G j|)
−
(cid:80)k i=1(|G i|2)
P(conflict|g i,g j) = 0 denotes that two goals are com- |Ω| |Ω| |Ω|2
pletelycompatibleandalignedwitheachother.Bydefinition,
P(conflict|g i,g i)=0. Σ i∈{1..k}(|G i|)2−Σ i∈{1..k}(|G i|2)
P(ma|Ω,PA)=
Let a goal group denote a subgroup of the population |Ω|2
that hold the same goal: for i ∈ {0..k}, let G = {ia ∈
i
(cid:83)
Ω|holds(ia,g ,PA)}.Byconstruction,Ω= G .Wecan Σ Σ (2|G ||G |)
i i i P(ma|Ω,PA)= i∈{2..k} j∈{1..i−1} i j (1)
easilyoverloadtheconflictrelationshiptoextendtogoal
|Ω|2
groups,s.t.P(conflict|G ,G ):=P(conflict|g ,g ).
i j i j
and P(a|Ω,PA) = 1 − P(ma|Ω,PA). Armed with this
Now,assumingagentsregardeachPAwithequalweight,
equation, one can utilize information about the number of
wecanquantifytheproportionofthepopulationwhohold
agentsholdingagivengoalwithinaproblemarea,inorder
incompatiblegoals.Followingthecontentionmodel(Jang,
toderiveaparametricquantityformisalignment,intherange
Dori-Hacohen,andAllan2017),wecanmodelmisalignment
[0,|G|−1](where|G|−1isthenumberofdistinctgoalsin
todirectlyreflectthisquestion:“Ifwerandomlyselectapair |G|
ofagents,howlikelyaretheytoholdincompatiblegoals?” thepopulation).3
Let P(ma|Ω,PA) be the probability that if we randomly
3While the probability is restricted to be strictly less than 1,
selecttwoagentsinΩ,theywillconflictwithrespecttoPA:
thatcouldbeconsideredafeatureratherthanabug:apopulation
withmultipleincompatiblegoalsisbydefinitionimpossibletofully
2Thiscouldbebecausetheyarenotawareoftheproblemarea, align.Alternatively,normalizationcanbeemployedtoreach[0,1]
orelsetheyareawareofitbutdonothaveanyrelevantgoal. range(Jang,Dori-Hacohen,andAllan2017,see)regardlessof|G|.4 Casestudies bedenotedasathirdagent,a ,whichmayeffectivelyholda
3
setofimplicitviewsduetoitstrainingdata.
In what follows, we will introduce three case studies that
Todefineproblemareas,agents,andgoalswithmathemat-
showcaseourmodel’sexpressivepowerandvalueasapoten-
icalnotationsinthecasestudy,weestablishthefollowing
tialoptimizationfunction.
shiftsfromthecontentionmodel,withitalicstermsrepresent-
Thefirstcasestudy,focusedonsocialmediamoderation,
ingtheoriginalcontentionmodel(Jang,Dori-Hacohen,and
istheclosestindomainandapplicationtotheoriginalcon-
Allan2017)andboldtermsrepresentingourmisalignment
tentionmodel(Jang,Dori-Hacohen,andAllan2017),while
model:
differingfromitinitsorientationtowardsactionratherthan
1. Topics become Problem Areas (PA): These are the
opinions.Wethereforeuseitasabridgetoconnecttheorigi-
specificdomainsortopicsofinterestinwhichalignmentor
nalcontentionmodelwiththenewmisalignmentmodel.We
misalignment(originally:contention)mayoccur.Inourcase,
willthenshowcasetheimportanceofgoalsandproblemar-
wehavetwotopically-focusedproblemareas:guncontrol
easwherebyanindividual’sactionsaremediatedbyAIinthe
(PA )andimmigrationpolicy(PA ),aswellasathird
casestudyofshoppingrecommendersystems.Finally,we gc im
problemarea(PA )regardingparticipationintheonline
willthenproceedtointroduceanautonomousvehiclecase fo
forum.
studyindetail,includingworkingthroughthemathematical
2. People become Agents (a): These are the entities in-
derivations.
volvedinthescenario,suchassocialmediausersandlan-
guage model moderators. These can include any number
4.1 Socialmediamoderation
of human agents as well as one or more AI-based agents;
In(Johnsonetal.2022),theauthorstalkabouttheAIalign- tomakeourexampleconcrete,wereferspecificallytoone
mentproblemasitpertainstolanguagemodels,specifically American social media user (a 1), one Italian social media
valuemisalignment.Mostconsumer-gradegeneralpurpose user(a 2),andoneLMmoderator(a 3).
AI models are made in the USA, and exhibit US-centric 3. Stances become Goals (g): These represent the ob-
values.Subsequently,anAmericanlanguagemodel’sviews jectives or values held by each agent regarding each prob-
on,say,guncontrol,aredistinctlydifferentfrom—andmis- lem area; in this case study, the goals may be quite sim-
alignedwith—thegeneralperceptionofguncontrollawsin ilar to the users’ respective opinions. For each agent a i
Australia,India,orFrance.Therangeofopinionsandtheir andproblemareaPA j,wedenotethegoalasg ji.Wethus
distributioninthepopulationmaybecompletelydistinct;in haveninegoalstotal-onegoalperproblemareaperagent:
fact,theOvertonwindow4forbothcountriesmaybewidely g1 ,g1 ,g1 ;g2 ,g2 ,g2 ;andg3 ,g3 ,g3 .
gc im fo gc im fo gc im fo
divergingornon-overlappingentirely.Inthiscasestudy,we PleaserefertoTable1fordefinitionsofthedifferentgoals
lookathowthismisalignmentmaytranslateintoarealworld for these agents. Note that there is not an inherently high
use case – social media moderation. Multilingual content misalignmentbetweenthethreeusers.However,asdiscussed
moderationusingAIisalreadyareality(Meta2021;Tech above,mostlanguagemodels—includingtheonewhicha 3
2021), yet these models are known to perform poorly for might consult for discerning which opinions are extreme
lowresourcelanguages(CenterforDemocracy&Technol- or toxic—are trained on US-centric data and embody im-
ogy(CDT)2024).LetusconsideronesuchLLM-moderated plicitly US-centric values. Therefore, a 3 is more likely to
socialmediausecase. perceiveopinionsoutsideoftheUSmainstream,whichare
Considertwodistinctproblemareas:guncontrol(PA ) disproportionatelylikelytobeexpressedbynon-American
gc
andimmigrationpolicy(PA im).Now,envisionagroupof forumparticipants,asextreme.Ergo,a 3willbemorelikely
socialmediausers,somefromtheUnitedStates,somefrom toblockcontentfromsuchusers,eveniftheiropinionswould
Italy, and some from other countries. Setting aside cross- be considered quite moderate and civil in their own coun-
lingualconcerns,wewillassumew.l.o.g.thatallusersare try.Themodelmightopttohideordeletethepostrelated
communicating in English. The challenge arises when the toguncontrol,giventhedivergenceinvaluesbetweenthe
languagemodelmoderatorneedstonavigatedifferinguser usersandpotentialsocietalsensitivities.Thiswouldleadtoa
perspectivesonthesetopics. misalignmentbetweena 2anda 3,withthemoderatorblock-
Forinstance,let’sassumethatoneAmericanuser,denoted ingtheparticipantfromachievingg f2 o-fullparticipationin
as a , holds strong opinions on gun control which is well theforum.Meanwhile,postsregardingimmigrationpolicy,
1
withintheboundsofUS-centricvalues,whileanItalianuser, wherebothusersalign,mightremainuntouchedduetothem
denotedasa ,hasastronglycontrastingviewpointwhich matchingUS-centricvalues,thusremainingalignedonthat
2
wouldbefairlycommonintheircountry.However,bothusers problemarea.
maysharesimilarviewsonimmigrationpolicy,denotedas Insuchascenario,amoreeffectivelanguagemodelmod-
g1 and g2 , respectively5, despite their cultural and geo- erator would need to discern these divergent perspectives,
im im
graphicaldifferences.TheLanguageModelmoderatorcan accountforculturaldifferences,andalignitsmoderationde-
cisionsaccordingly.Whenfacedwithcontentiouspostson
4TheOvertonWindowis“therangeofpoliciespoliticallyac- socialmediatouchinguponbothguncontrolandimmigration
ceptabletothemainstreampopulationatagiventime”(Wikipedia policies,anidealmodelwouldencouragehealthydisagree-
2024) ments,withoutoverlypenalizingcontentthatisoutsideof
5Forconvenienceandbrevity,weabbreviatetheholdsfunction itstrainingdata;andwhilerecognizingthathealthydebateis
tothisnotation;holds(a ,g,PA )←→gi. not,inandofitself,amisalignedgoal.
i j jAgent ProblemArea Goal
a GunControl(PA ) g1 ="expresssupportforlessrestrictiveguncontrollaws"
1 gc gc
a ImmigrationPolicy(PA ) g1 ="expresssupportforstricterimmigrationcontrols"
1 im ab
a ForumParticipation(PA ) g1 ="participatefullyintheforum"
1 fo fo
a GunControl(PA ) g2 ="expresssupportforstricterguncontrollaws"
2 gc gc
a ImmigrationPolicy(PA ) g2 ="expresssupportforstricterimmigrationcontrols"
2 im ab
a ForumParticipation(PA ) g2 ="participatefullyintheforum"
2 fo fo
a GunControl(PA ) g3 ="blockunreasonable,toxicand/orextremeopinionsonguncontrol"
3 gc gc
a ImmigrationPolicy(PA ) g3 ="blockunreasonable,toxicand/orextremeopinionsonimmigration"
3 im ab
a ForumParticipation(PA ) g3 ="effectivelymoderatetheforumtoavoidtoxiccontent"
3 fo fo
Table1:Socialmediamoderationcasestudy:goalsforeachagentwithrespecttoeachproblemarea.a :Americansocialmedia
1
user,a :Italiansocialmediauser,a :Moderatoragent
2 3
4.2 Shoppingrecommendersystems groceriesviathemobileappandreceivingthemlaterthatday
Inthiscasestudy,weconsiderthecaseofshoppingAI-based viaR i’sdriveupoption;thisaffordsthemtimesavingsand
recommendersystems.Considerasetofretailers,whichmay convenience,since(a)R iRS quicklypullsuptheir“usuals,”
beonline-only(suchasAmazon)ora“hybrid”retailerwith and suggests appropriate meal combinations; and (b) they
bothonlineandbrick-and-mortarlocations(suchasTarget). save time and energy by using the drive-up option. For c k
Inanygivenpurchasingsituation,customersmaygravitate these benefits outweigh possible cost savings or healthier
to a specific retailer for a variety of reasons: convenience, foodatotherretailers(Gobbo,Forno,andMagnani2022).
price, selection, and so forth. The retailers are serving the In this scenario, it is easy to see that c k, R i, and R iRS are
customerontheweboronamobileapp,orevenacombi- well aligned; c k is a happy and loyal customer, returning
nationofmobileappandin-personservice6.MostAI-based toR i timeandagain,andbenefitingfromtimesavingand
recommendersystemsarepersonalizedtoindividualusers, convenienceintheirbusylife.
and may be incredibly successful in serving up items that In the second scenario (bottom right of Figure 1), c k is
the customer will seriously consider, and possibly end up again shopping on R i’s mobile app, this time late at night
purchasing.Theseitemscouldbewellthoughtoutpurchases afteramajorholiday.Aftercheckingoutwithacartfullof
thatserveacustomerandtheirinterestswell;or,theymaybe healthy groceries (to be picked up on the way home from
mindlessimpulsepurchases,causingthecustomerfinancial worktomorrow),aconfluenceoffactors7 leadsR iRS tostart
loss,needlessclutter,andpotentiallyregret—orevenguilt recommendingc k itemafteritemfromapost-holidayclear-
andshame(Sivapalanetal.2014). ancesale.Duetothelatehourandtheseeminglyattractive
Let us consider this problem more formally. Let R = prices—nottomentiontheaddictivenatureofonlineshop-
{R 1..R m} be a set of retailers and let R iRS ∈ RS denote ping (Rose and Dhandayudham 2014)—c k’s resistance to
aspecificretailerR ’sAI-basedrecommendersystem.Let impulse purchases is compromised, and they are tempted
i
c ..c ∈ C beasetofcustomerswhoshopatoneormore into purchasing a large selection of holiday items they do
1 n
of the retailers in R. By design, we can assume that R ’s notneednorwant.Whenlargeboxesfullofholidayitems
i
recommendersystem,RRS,ismostlikelybuilttobealigned arrive at their doorstep, c k feels guilt for not thinking the
i
withtheinterestsandgoalsofR ,andmisalignedwithmost purchase through, ultimately wasting time and energy re-
i
or all other retailers, R
j
∈ R where i ̸= j; nevertheless, turningthem.Thus,withrespecttohouseholditems(PA hs),
as we will see, this does not guarantee perfect alignment c k is aligned with neither R iRS nor R i. Nor, when returns
betweenRRS andR .Aswewillalsosee,customersmay areaccountedfor,areRRS’srecommendationsalignedwith
i i i
bevariouslyalignedormisalignedwithspecificretailers. R i’sinterests;theretailerspentresourcesshippingalargeset
Consider a specific customer c ∈ C, a working parent ofitemsthatwasultimatelyunwanted,generatingalosson
k
shoppingataspecifichybrid“big-box"retailer,R ;twospe- thesale,shrinkingtheretailer’sprofitmargins,andsouring
i
cificscenariosaredetailedinFigure1.First,c k isshopping c k ontheretailer—riskingdrivingawayanotherwiseloyal
forgroceriesatR (topright),withthegoalofpurchasing customer(Röllecke,Huchzermeier,andSchröder2018).
i
groceries (PA ) quickly and conveniently, ordering their Inatraditionalalignmentsetting,itisdifficulttosquare
gs
thesetwoscenarios.IstheAI-basedRRS alignedwithR ?
i i
6Forexample,manymobileappsforbrick-and-mortarretailers withc ?ormisalignedwithoneorboth?Theexpectationof
k
intheUSincludebarcodescannerswhichallowyoutocompare asingle,globalalignmentstateorscorefortheAIsystemis
theirin-storepricestotheironlineprice.Thesescannersalsoenable
easycomparison-shoppingfromone’slocationinsidearetailer’s 7Suchaslowprice,overstockinventory,andpurchasinghistory,
physicalstore,inrealtime,acrossmultipleonlineretailers. tonameafew.Customer goal: convenience
at a low price
Alig n e d
Target’s goal: make money
MM isais
lia gl nig
en de ad g:
ap iu nr
:
c rh ea fuse
nd
Customer goal(s):
● don’t waste money impulse shopping
● don’t fill house with junk before moving
Figure1:ShoppingRecommenderSystemcasestudy.Thecustomer(a =c ),abig-boxretailer(a =R ,inthiscaseTarget),and
1 k 2 i
therecommendersystemmediatingbetweenthem(a =RRS)arevariouslyalignedormisaligneddependingontheproblemarea.Onthe
3 i
topright,c isshoppingforgroceries(PA )atR ,affordingthemtimesavingsandconvenience.Onthebottomright,RRS leadsc down
k gs i i k
animpulseshoppingrabbitholeofclearanceholidayitemsfortheirhousehold(PA ),leadingtowastedmoney,unwanteditems,guilt,
hs
1
and—ultimately—loerprofitabilitytoR ,viaitemreturnsandrefunds.
i
violatedacrossthescenarios;norcanthedifferencesbeonly tobetter,morealignedresults.
ascribedtotwotargetsforalignmentortovariationovertime.
Rather, c is simultaneously variously aligned and mis- 4.3 Autonomousvehiclepre-collisionscenario
k
alignedwithR .Furthermore,theAI-basedrecommender
i
systemRRS islikewisevariouslyalignedandmisaligned
i
withbothc andR .
k i
By separating the scenarios by problem area, the align-
ment and misalignment situation becomes clear. The vari-
ousagentgoalsaredescribedinTable2.Thuswecansee
that for problem area PA and this set of goals, all three
gs
agents—customer,retailerandrecommendersystem—end
upbeingwell-aligned;thoughitbecomesclearthatcustomer
satisfactionisnotrepresentedwellnoroptimizedforinthe
recommender system, risking a potential misalignment in
otherscenarios.WithrespecttoproblemareaPA andthis Figure2:Autonomousvehiclecasestudyusingscenario17
hs
setofgoals,itbecomespatentlyobvioushowthethreeagents andassociatedfigurefromCARLA(Dosovitskiyetal.2017).
caneasilybecomemisaligned.Suddenly,whatmightseem A car (ia ) and a pedestrian (ia ) (a = R have the
car ped 2 i
like a fairly reasonable goal for the recommender system samegoalsacrossproblemareas,butprioritizethemquite
becomesametricripeforrewardhacking(Hadfield-Menell differently.
et al. 2017; Skalse et al. 2022). Its goal of optimizing for
sales(ratherthannetsales,i.e.afteraccountingforreturns) Manypaperscomparethepre-crashautonomousvehicle
andinventorydisposalis“successfully”accomplished,but (AV)decision-makingtothetrolleyproblemfrommoralphi-
onlyattheexpenseofnetprofits(R iRS misalignedwithR i) losophy(Tolmeijeretal.2023),andthoughtheaccuracyof
andcustomersatisfaction(bothRRS andR misalignedwith the comparison has been challenged, the discussion high-
i i
c ).Despitethisgrossmisalignment,wenotethatthecus- lightsaclearneedfordeliberateethicaldecision-makingin
k
tomerandretailerremainalignedwithrespecttothegrocery thedesignofAValgorithms(NyholmandSmids2016).This
shoppingproblemarea.Carefullyselectingabetteroptimiza- case study uses a simple scenario from CARLA, a major
tiontargetfortherecommendersystem—possibly,onethat challengeandleaderboardforAVresponsestocommonpre-
explicitlymodelspotentialcustomermisalignment—canlead crashscenarios(Dosovitskiyetal.2017),toillustratehowtoAgent ProblemArea Goal
a =c GroceryShopping(PA ) g1 =“convenienceatalowprice”
1 k gs gs
a =c HouseholdItemShopping(PA ) g1 =“don’twastemoneyimpulseshopping;don’tfillhouse
1 k hs ab
withjunkbeforemoving”
a =R GroceryShopping(PA ) g2 =“beatlastquarter’snetprofitsperstorelocationby1%or
2 i gs gs
more;don’tdegradecustomersatisfaction”
a =R HouseholdItemShopping(PA ) g2 =“increaseonlinenetprofits;movepost-holidayinventory
2 i hs hs
quickly;don’tdegradecustomersatisfaction”
a =RRS GroceryShopping(PA ) g3 = “optimize recommendations for highest total purchase
3 i gs gs
dollaramountatcheckouttime”
a =RRS HouseholdItemShopping(PA ) g3 =“optimizerecommendationsforinventorydisposaland
3 i hs hs
highesttotalpurchasedollaramountatcheckouttime”
Table2:ShoppingRecommenderSystemcasestudy:GoalsforEachAgentwithRespecttoEachProblemArea.a :customer,
1
a :retailer,a :recommendersystem
2 3
measurethealignmentofAVmodelrewardstootheragents’ penalty would be (1 - penalty coefficient) for that penalty.
interests.Accordingtothepre-crashscenariotypologythat Thus, for the car’s goal of avoiding collision with another
informedtheCARLAscenarioselection,thisisoneofthe vehicle, we can describe this as holds(ia ,g ,w =
car avoid
topthreesingle-vehiclescenariosintermsof“economiccost 0.40,PA ). We assume that the pedestrian mostly cares
p2
andfunctionalyearslost”(Najmetal.2007). aboutnotbeinghitbyacar,andotherwisewouldprefernot
To determine the problem areas, consider the coeffi- towitnessorcauseanaccidentorharm.
cients used to determine the CARLA scores, which rep- As for the route-completion PA’s, we will assume that
resent the “value” to the ego vehicle for achieving or bothagentsplaceequalweightonreachingtheirdestinations
avoiding specific behaviors. In the context of the CARLA whilefollowingwhateverroutestheyhaveplanned,though
leaderboard,thesescoresarecombinedusingtheequation we could modify the goals in those PA’s or include a PA
R i(cid:81)p jed,...,stop(pj i)#infractionsj, which is the product of rel Sat ie nd ceto als lp ae ge ed no tsf ir nou thte isc so cm ep nl ae rt ii oon hoif ldw te hew sa an mte ed gt oo.
als,just
theroutecompletionpercentageandtheincurredinfraction
with different weights – reflecting that everyone wants to
penaltiesacrossalltestedscenarios.Sincelowerpenaltyco-
avoidunsafe/collisionevents–wecanconsidertheweighted
efficientstranslatetogreaterpunishments,wesetthecar’s
conflictbetweengoalstobetheaverageweightsofgoalsheld
weightforaproblemareatobe1−p,wherepisthepenalty
onthatproblemarea.Usethefollowingequationtocompute
imposedforeachinfractionintheCARLAchallenge.
theresultingmisalignment:
Wecansaythattherearetwomainproblemareas(PAs):
completing the route, and driving safely. As in the real
world,theseobjectivesoverlapsomewhat.Theinstrumental
P(ma|Ω,PA):=
goals/sub-PAs will just be the components of the relevant
P(ia ,ia selectedrandomlyfromΩ|
partsoftheoverallscore. 1 2
holds(ia ,g ,PA)∧
Considerscenario17fromtheCARLAscenariolist:"Ob- 1 i
stacleavoidancewithoutprioraction.""Theego-vehicleen- holds(ia ,g ,PA),∃g ,g ∈G)
2 j i j
countersanobstacle/unexpectedentityontheroadandmust
(w +w )
perform an emergency brake or an avoidance maneuver." ·P(conflict|g ,g )· ia1 ia2
i j 2
Assumethattheunexpectedentityisapedestrian.
Tocomputethealignmentinthisscenario,we’llneedto ForPA p1,themisalignmentcanbecalculatedasfollows:
knowtheproblemareas,goals,andconflictbetweenthose
P(ma|{ia ,ia },PA )=
goals. car ped p1
The PAs are as listed above. To describe the goals, let P(ia car,ia pedselectedrandomlyfromΩ|
ia refer to the vehicle, let ia refer to the pedestrian, holds(ia ,g ,w ,PA )
car ped car avoid car p1
andusetheconstructionholds(ia,g,w,PA)tosaythatthe
∧holds(ia ,g ,w ,PA ))
car avoid ped p1
individualagentiaholdsgoalg withweightwinproblem
w +w
a ar be oa vP ebA e. tF ho er gb ore av li oty f, al ve ot ig da iv no gid thf eor da en sy cro ibf et dhe evP eA nts .described ·P(conflict|g avoid,g avoid)· car
2
ped
ThecoefficientsprovidedbyCARLAaremultipliedwith The probability of these agents having these goals is 1.
each other and with the route completion to produce the Also,removethe"conflict"termbecauseallagentsholdthe
driving distance, so the weight of the goal of avoiding a samegoal.Thus,simplifying:ProblemArea Description Weight:Car Weight:Ped MisalignmentScore
PA Collisionwithpedestrian 0.50 0.90 0.70
p1
PA Collisionwithothervehicle 0.40 0.15 0.275
p2
PA Collisionwithastaticelement 0.35 0.15 0.25
p3
PA Runningaredlight 0.30 0.05 0.175
p4
PA Runningastopsign 0.20 0.05 0.125
p5
PA Gettingblockedfor4minutes 0.30 0.05 0.175
p6
PA Carfailstomaintainaminimumspeed 0.30 0.01 0.155
p7
PA Carfailstoyieldtoemergencyvehicles 0.30 0.05 0.175
p8
PA Overallmisalignmentonpenalties N/A N/A 0.254
p
Table3:ProblemAreas(PAs)withcorrespondingdescriptions,weightforeachagent’sgoalwithregardtoeachproblemarea,
andmisalignmentscores.
whatthemeaningof"alignment"iswhenhumansthemselves
aremisaligned.WhensocialmediabotscontrolledbyRussia
w +w
P(ma|{ia ,ia },PA )= car ped spreaddisinformationonsocialmediaandinfluencepublic
car ped p1 2
opinioninanothercountry,shouldweconsiderthosebotsto
0.50+0.90
= =0.70 bealignedormisaligned?Foramuchmoremundaneexam-
2 ple,whereshouldtheAI’sallegianceliewhenachildwants
The overall misalignment on PA is the average of the Alexatoplay“BabyShark,”andtheirparentwantsanything
p
difference in weighted conflict across each sub-PA, so for butthat?CurrentapproachesforAIalignmentoftenfallshort
PA throughPA ,thataverageis0.254. ofcapturingsuchcomplexscenarios.
p1 p8
Notethatthecar’sgoalweightscouldbemodifiedinorder Byprovidingamathematicalframeworkforquantifying
tobring themisalignment evenlower, but thismay notbe misalignmentinthemannerwedescribed,wefirstandfore-
desirableinthiscase;ifthecarlowersitsweightsregarding mostenablemodelingcomplexreal-worldscenariosofmis-
non-pedestriancollisions,thiswouldlowermisalignmentbe- alignmentamonghumanpopulations,rangingfromaglobal
tweenthesetwoagents.However,thiswouldlikelyincrease scale (e.g. nation-state conflicts, religious tensions, multi-
the overall chance of collisions due to less regard for fol- nationalconglomerates,etc.),throughnational(e.g.national
lowingtrafficlawsandavoidingothervehicles.Thisisnota elections,politicalpolarization,taxation,etc.)andlocal(e.g.
failureofourmodel;sincethepedestrianactuallydoescare stateormunicipalelections)scales,orevenhyper-localscale
significantlymoreaboutavoidingpedestriancollisions,and (e.g.familyfights,maritaldiscord,neighbordisputes).Di-
significantlylessaboutthecaravoidingothercarsandob- vergentmisalignmentprobabilitiesmaybeexhibitedsimul-
jectsandfollowingtrafficlaws,anyaccuratealignmenteffort taneously for the same group of people when evaluating
wouldhavetheseexternalities.Theproblemwiththeseother differentproblemareas.Examplescanincludeacouplefight-
collisionrisksisthatnon-pedestriancollisionsandviolations ingovertheirfinanceswhileagreeingontheirchild-rearing
increaserisktootherstakeholders,suchasthepassengersof approach,andthe“strangebedfellows”phenomenonwhen
thevehicle,othervehicles,andsoon.Thus,asparticipants politicalenemiesmightagreeonacertainpolicyforexpe-
in society who may find ourselves as drivers, pedestrians, diency.Likewise,forasingleproblemarea,differentpopu-
etc.,ifwewanttoreduceaccidentsoverall,weshouldwant lations(including,butnotlimitedto,varioussubsetsofone
anautonomousvehicle’sgoalsandweightstobealignedto largepopulation)mayexhibitwildlydifferentmisalignment
manystakeholdersinmanyscenarios.8 probabilities:anentirecountrymaybehighlymisalignedon
taxationpolicy,whilethepopulationofaprogressivestate
5 Discussion suchasMassachusettsmightbeextraordinarilyalignedon
raisingtaxes.
Intherealworld,peopleoftendisagree,andarefrequently
misaligned; power struggles, resource allocation conflicts,
AIRiskAnalysis MisalignedAIisoneofthemainexisten-
andinternationalclashesarecommon.Thelong-term,total
tialrisks(x-risks)facinghumanity(Avinetal.2018;Baum
alignmentofvalues,interests,andgoalsacrossalldomains,
etal.2019;Ord2020),withsignificantargumentspointing
foranygivengroupofhumans,isbyfartheexception,notthe
to the possibility of its posing the largest and most likely
rule.AligningAItohumansorhumanitywillbeachalleng-
x-risk (Bostrom 2002). A recent paper presented potential
ing–ifnotoutrightfutile–goal,unlesswecandetermine
pathwaysfromcurrentandnear-termAItoincreasedx-risk,
whichdoesnotpresupposeAGI(BucknallandDori-Hacohen
8ThisdrawsaninterestingparalleltoJohnRawls’VeilofIg-
2022);instead,theauthorsproposethatpowerstrugglessuch
norancethoughtexperiment,inthatinordertoimprovesocietal
outcomes,wemustconsidertheperspectiveofeveryoneinvolved asAI-poweredinternationalandstate-corporateconflictsmay
withoutpartialitytoourownstatus.Foramoreexplicituseofthe playalargeroleinincreasedx-risk(and/orothercatastrophic
VeilofIgnoranceforAIalignment,see(Weidingeretal.2023) tailrisks)duetoother,non-AGIrisksourcessuchasnuclearwar,runawayclimatechange,andsoforth.Crucially,several itseemslikereducingcollisionrisk,behavingpredictably,
recent papers have argued that current AI is already mis- and following the traffic laws are all mostly mutually
alignedwithhumanity(BucknallandDori-Hacohen2022; reinforcing,eventhoughnoneoftheaboveisnecessary
Russell2019,e.g.)andalsothathumanity’scollectivesense- orsufficientforanyother.Forexample,rollingthrougha
making and decision-making capacities are already being stopsignisagainstthelawbutpredictableandthuslowers
compromised and diminished by present-day AI, such as collisionrisk,butspeedingthroughthestopsigndefies
therecommendersystemsatthecoreofsocialmediaplat- allthreecriteria.
forms(Bak-Colemanetal.2021;BucknallandDori-Hacohen • There may be arbitrarily many states of the world, but
2022;Segeretal.2020,e.g.).Byrecastingmisalignmentas we only care about a relatively small number of those
first and foremost a human-centered problem, rather than statesatagiventime.Aformaldefinitionofwhichfluents
an AI-centric problem, and drawing on existing literature shouldbeconsideredshouldsomehowexcludethingslike
that studies human conflict and contention, our paper ties themovementofeachspeckofdust.Thisissomewhat
directlyintothislineofresearchthatsuggeststhatAImay related to the “frame problem”, which concerns which
servetoincrease,accelerateandintensifytherisksofhuman fluentsmustbeincludedinordertoadequatelydescribe
conflict—alreadyathornyandarguablyintractableproblem a state of an environment (McCarthy and Hayes 1981;
evenbeforeAI’sadvent(Boulaninetal.2019;Johnson2019; Dennett2006).Similartosome"solutions"totheframe
Lin2019;Maas,Matteuci,andCooke2022).Furthermore, problem,whichassertthatonlythefluentschangedbyan
byprovidingaflexibleframeworkthatcanbeusedtoaccount actionneedtobeincludedinitsdescription(Thielscher
for,analyzeandquantifymisalignmentamongavastarrayof 1998),wemightsaythatonlyfluentsthatmeaningfully
agents,bothhumanandartificial,ourworkholdssignificant affect/interactwithourgoalsshouldbementioned.How-
promisetoadvanceourfield’sunderstandingofthealignment ever,thispresentsanew(andnolesschallenging)problem
problem.Finally,ourmodelencouragesAIsafetyandalign- ofdefiningorpredictingallofthefluentsthatrelatetoour
mentresearcherstoavoidthepotentiallyreductionisttrapsof goals.
(a)“narrowly”aligningAIwitheitherindividualhumansor
Solvingthesechallengesinordertoproduceamorerigor-
humanityasawholebyhighlightingthechallengesinalign-
ousdefinitionofaproblemareaisleftforfuturework.
inganydiversegroupofindividuals,whetherthatgroupin-
cludesAIagentsornot;and(b)adoptingatechno-optimistic Future work In addition to addressing the limitations
and/ortechno-positivistmindsetthatnaivelysupposesthat above, future work can examine how the degree of align-
thealignmentproblemcanbesolvedbytechnologicalmeans menttoparticularobjectivesdeterminesoverallalignmentto
alone. We sincerely hope that our paper sparks more con- apersonorpeopledependingonwhattheycareabout.This
versationintheAIsafetyandalignmentcommunitiesabout could use the "win-rates" of alignment to objectives (like
thesociotechnicalaspectsofthealignmentproblem,andthe those used by MetaAligner (Yang et al. 2024)) or to spec-
needtoincludeadiversegroupofresearchersandpractition- ifiedscores(likethoseusedbyamethodlikeControllable
erswithexpertiseindiversedomainsfarbeyondcomputer PreferenceOptimization(Guoetal.2024)).Ineithercase,
scienceandphilosophydepartments;andbyextension,con- our model can accept human preference data and use it to
tributestoimprovinghumanity’soddsoffindingrealisticand measureAIalignmenttothegoalsofdiversepopulationsof
sustainableapproachestoreducingx-risk. humans.
Furthermore, we have focused on analyzing alignment
Limitations Ourmodeldoesnotconcernwhethertheac-
inpopulationsofhumanandmachineagents.Futurework
tionsoftheagenthaveapositiveornegativeoutcomeonthe
mayconsiderthepossibilityofextendingthismodeltonon-
agent itself. Likewise, we leave open the question of how
humanbiologicalentities,fromtheultra-microlevelsuchas
anagent’sgoalscouldbelearned,thoughwenotethatother
intra-cellularinteractionsorinter-cellbehaviorsinaculture,
researchershavemadesomeprogressonthatfront(Brown
through microbial populations, to the alignment of entire
etal.2021).Finally,welackthespacetodescribeadditional
ecosystemssuchaspredatorandpreypopulations,ant/bee
case-studies of our model or run simulations of any case
colonies,etc.Inthesesituationstherearedifferentincentives,
studies.
such as an environment with less than perfect and instant
Therearealsosomechallengestodescribingtheproblem
communicationbetweenallpartieswherepartialinformation
areasinascenario:
isavailabletodifferentagents.
• Aproblemareamaybeacombinationorgestaltofmulti-
plesub-areas.Forexample,inadrivingscenario,thePA 6 Conclusion
ofnotrunningastopsigncouldbedescribedasagestalt Our novel extension of the contention model (Jang, Dori-
of the PAs of following traffic laws, reducing collision Hacohen,andAllan2017)affordsameanstoquantifymis-
risk,andbehavingpredictably.Perhapsthedifferencebe- alignmentingivenagentpopulations,whichmayincludea
tweenagestaltandacombination,namelywhetherthePA mixofhumansandAIagents.Withthismodel,misalignment
ismorethanthesumofitssub-areas,shoulddetermine predicated on an observed population group as well as an
whetheritisconsideredseparatelyfromthesub-areason observedproblemareaprovidesamechanismforarichand
theirown. nuancedunderstandingofmisalignmentthatbettermatches
• Problemareasmayrelateto(andrelymutuallyupon)one real-worldconditionsthancouldasimplebinaryoraglobal
another.Intheredlightexamplefromthepreviousbullet, numericvalue.References Dennett, D. C. 2006. "Cognitive wheels: The frame prob-
Avin,S.;Wintle,B.C.;Weitzdörfer,J.;ÓhÉigeartaigh,S.S.; lemofAI". Philosophyofpsychology:Contemporaryread-
Sutherland,W.J.;andRees,M.J.2018. Classifyingglobal ings.NewYork,NY,US:Routledge/Taylor&FrancisGroup.
catastrophicrisks. Futures,102:20–26. ISBN 0-415-36861-8 (Hardcover); 0-415-36862-6 (Paper-
back);0-203-02895-3(Digital(undefinedformat));978-0-
Bai, Y.; Kadavath, S.; Kundu, S.; Askell, A.; Kernion, J.;
415-36861-2(Hardcover);978-0-415-36862-9(Paperback);
Jones,A.;Chen,A.;Goldie,A.;Mirhoseini,A.;McKinnon,
978-0-203-02895-7(Digital(undefinedformat)). Pages:454.
C.; Chen, C.; Olsson, C.; Olah, C.; Hernandez, D.; Drain,
D.; Ganguli, D.; Li, D.; Tran-Johnson, E.; Perez, E.; Kerr, Dori-Hacohen,S.;Sung,K.;Chou,J.;andLustig-Gonzalez,
J.; Mueller, J.; Ladish, J.; Landau, J.; Ndousse, K.; Luko- J. 2021. Restoring Healthy Online Discourse by Detect-
suite, K.; Lovitt, L.; Sellitto, M.; Elhage, N.; Schiefer, N.; ingandReducingControversy,Misinformation,andToxicity
Mercado,N.;DasSarma,N.;Lasenby,R.;Larson,R.;Ringer, Online,2627–2628. NewYork,NY,USA:Associationfor
S.;Johnston,S.;Kravec,S.;Showk,S.E.;Fort,S.;Lanham, ComputingMachinery. ISBN9781450380379.
T.; Telleen-Lawton, T.; Conerly, T.; Henighan, T.; Hume, Dosovitskiy, A.; Ros, G.; Codevilla, F.; Lopez, A.; and
T.;Bowman,S.R.;Hatfield-Dodds,Z.;Mann,B.;Amodei, Koltun,V.2017. CARLA:Anopenurbandrivingsimulator.
D.; Joseph, N.; McCandlish, S.; Brown, T.; and Kaplan, J. InConferenceonrobotlearning,1–16.PMLR.
2022. ConstitutionalAI:HarmlessnessfromAIFeedback.
Dragan, A. 2019. Specifying AI Objectives as a Human-
arXiv:2212.08073.
AI Collaboration problem. In Proceedings of the 2019
Bak-Coleman, J. B.; Alfano, M.; Barfuss, W.; Bergstrom, AAAI/ACMConferenceonAI,Ethics,andSociety,329–329.
C.T.;Centeno,M.A.;Couzin,I.D.;Donges,J.F.;Galesic, HonoluluHIUSA:ACM. ISBN978-1-4503-6324-2.
M.; Gersick, A. S.; Jacquet, J.; Kao, A. B.; Moran, R. E.;
Fisac,J.F.;Gates,M.A.;Hamrick,J.B.;Liu,C.;Hadfield-
Romanczuk,P.;Rubenstein,D.I.;Tombak,K.J.;VanBavel,
Menell,D.;Palaniappan,M.;Malik,D.;Sastry,S.S.;Grif-
J.J.;andWeber,E.U.2021. Stewardshipofglobalcollective
fiths,T.L.;andDragan,A.D.2020. Pragmatic-Pedagogic
behavior. ProceedingsoftheNationalAcademyofSciences,
ValueAlignment. InAmato,N.M.;Hager,G.;Thomas,S.;
118(27).
andTorres-Torriti,M.,eds.,RoboticsResearch,volume10,
Baum,S.D.;Armstrong,S.;Ekenstedt,T.;Häggström,O.; 49–57.Cham:SpringerInternationalPublishing. ISBN978-
Hanson, R.; Kuhlemann, K.; Maas, M. M.; Miller, J. D.; 3-030-28618-7978-3-030-28619-4. SeriesTitle:Springer
Salmela,M.;Sandberg,A.;Sotala,K.;Torres,P.;Turchin, ProceedingsinAdvancedRobotics.
A.;andYampolskiy,R.V.2019. Long-termtrajectoriesof
Gabriel,I.2020. ArtificialIntelligence,Values,andAlign-
humancivilization. Foresight,21(1):53–83.
ment. MindsandMachines,30(3):411–437.
Bostrom,N.2002. ExistentialRisks:AnalyzingHumanEx-
Gobbo, A. D.; Forno, F.; and Magnani, N. 2022. Making
tinctionScenariosandRelatedHazards. JournalofEvolution
“goodfood”morepracticable?Thereconfigurationofalter-
andTechnology,9.
native food provisioning in the online world. Sustainable
Boulanin,V.;Avin,S.;Sauer,F.;Borrie,J.;Scheftelowitsch,
ProductionandConsumption,29:862–871.
D.;Bronk,J.;Stoutland,P.O.;Hagström,M.;Topychkanov,
Goertzel,B.;Iklé,M.;andPotapov,A.2022. ArtificialGen-
P.;Horowitz,M.C.;Kaspersen,A.;King,C.;Amadae,S.;
eralIntelligence:14thInternationalConference,AGI2021,
andRickli,J.-M.2019. TheImpactofArtificialIntelligence
PaloAlto,CA,USA,October15–18,2021,Proceedings. Lec-
on Strategic Stability and Nuclear Risk, Volume I, Euro-
tureNotesinComputerScience.SpringerInternationalPub-
AtlanticPerspectives. Technicalreport,SIPRI.
lishing. ISBN9783030937584.
Brown,D.S.;Schneider,J.;Dragan,A.;andNiekum,S.2021.
Guo, Y.; Cui, G.; Yuan, L.; Ding, N.; Wang, J.; Chen, H.;
ValueAlignmentVerification. InMeila,M.;andZhang,T.,
eds.,Proceedingsofthe38thInternationalConferenceon Sun,B.;Xie,R.;Zhou,J.;Lin,Y.;Liu,Z.;andSun,M.2024.
MachineLearning,volume139ofProceedingsofMachine ControllablePreferenceOptimization:TowardControllable
LearningResearch,1105–1115.PMLR. Multi-ObjectiveAlignment. ArXiv:2402.19085[cs,eess].
Bucknall, B. S.; and Dori-Hacohen, S. 2022. Current and Hadfield-Menell,D.2021. ThePrincipal-AgentAlignment
Near-TermAIasaPotentialExistentialRiskFactor. InPro- ProbleminArtificialIntelligence. Ph.D.thesis,EECSDe-
ceedingsofthe2022AAAI/ACMConferenceonAI,Ethics, partment,UniversityofCalifornia,Berkeley.
andSociety,AIES’22,119–129.NewYork,NY,USA:As- Hadfield-Menell, D.; Dragan, A.; Abbeel, P.; and Russell,
sociationforComputingMachinery. ISBN9781450392471. S. 2024. Cooperative Inverse Reinforcement Learning.
CenterforDemocracy&Technology(CDT).2024. Inves- ArXiv:1606.03137[cs].
tigating Content Moderation Systems in the Global South. Hadfield-Menell,D.;Milli,S.;Abbeel,P.;Russell,S.J.;and
https://cdt.org/insights/investigating-content-moderation- Dragan,A.2017. Inverserewarddesign. Advancesinneural
systems-in-the-global-south/. informationprocessingsystems,30.
Christian,B.2020. TheAlignmentProblem:MachineLearn- Jang,J.;Kim,S.;Lin,B.Y.;Wang,Y.;Hessel,J.;Zettlemoyer,
ingandHumanValues. WWNorton&Company. L.;Hajishirzi,H.;Choi,Y.;andAmmanabrolu,P.2023. Per-
Critch, A.; and Krueger, D. 2020. AI Research Con- sonalizedSoups:PersonalizedLargeLanguageModelAlign-
siderations for Human Existential Safety (ARCHES). mentviaPost-hocParameterMerging. ArXiv:2310.11564
arXiv:2006.04948. [cs].Jang,M.;Dori-Hacohen,S.;andAllan,J.2017. Modeling Najm,W.G.;Smith,J.D.;Yanagisawa,M.;etal.2007. Pre-
ControversywithinPopulations. InProceedingsoftheACM crashscenariotypologyforcrashavoidanceresearch. Tech-
SIGIRInternationalConferenceonTheoryofInformation nical report, United States. Department of Transportation.
Retrieval,ICTIR’17,141–149.NewYork,NY,USA:Asso- NationalHighwayTrafficSafety....
ciationforComputingMachinery. ISBN9781450344906.
Nyholm, S.; and Smids, J. 2016. The ethics of accident-
Ji,J.;Qiu,T.;Chen,B.;Zhang,B.;Lou,H.;Wang,K.;Duan, algorithmsforself-drivingcars:Anappliedtrolleyproblem?
Y.;He,Z.;Zhou,J.;Zhang,Z.;Zeng,F.;Ng,K.Y.;Dai,J.; Ethicaltheoryandmoralpractice,19(5):1275–1289.
Pan,X.;O’Gara,A.;Lei,Y.;Xu,H.;Tse,B.;Fu,J.;McAleer,
Ord,T.2020. ThePrecipice:ExistentialRiskandtheFuture
S.;Yang,Y.;Wang,Y.;Zhu,S.-C.;Guo,Y.;andGao,W.2024.
ofHumanity. HachetteBooks. ISBN978-0316484916.
AIAlignment:AComprehensiveSurvey. arXiv:2310.19852.
Osman, N.; and d’Inverno, M. 2024. Modelling Human
Johnson, J. 2019. Artificial intelligence & future warfare:
ValuesforAIReasoning. Publisher:[objectObject]Version
implicationsforinternationalsecurity. Defense&Security
Number:1.
Analysis,35(2):147–169.
Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright,
Johnson,R.L.;Pistilli,G.;Menédez-González,N.;Duran,
C.L.;Mishkin,P.;Zhang,C.;Agarwal,S.;Slama,K.;Ray,
L.D.D.;Panai,E.;Kalpokiene,J.;andBertulfo,D.J.2022.
A.;Schulman,J.;Hilton,J.;Kelton,F.;Miller,L.;Simens,M.;
The Ghost in the Machine has an American accent: value
Askell,A.;Welinder,P.;Christiano,P.;Leike,J.;andLowe,
conflictinGPT-3. arXivpreprintarXiv:2203.07785.
R. 2022. Training language models to follow instructions
Leike, J.; Krueger, D.; Everitt, T.; Martic, M.; Maini, V.;
withhumanfeedback. arXiv:2203.02155.
and Legg, S. 2018. Scalable agent alignment via reward
modeling:aresearchdirection. ArXiv:1811.07871[cs,stat]. Peterson,M.2019.Thevaluealignmentproblem:ageometric
approach. EthicsandInformationTechnology,21(1):19–28.
Lin, H. 2019. The existential threat from cyber-enabled
informationwarfare. BulletinoftheAtomicScientists,75(4): Prasad, M. 2019. Social Choice and the Value Alignment
187–196. Problem. InArtificialIntelligenceSafetyandSecurity.Boca
Liscio,E.;Lera-Leri,R.;Bistaffa,F.;Dobbe,R.I.;Jonker, Raton,FL:CRCPress/Taylor&FrancisGroup. ISBN978-1-
C. M.; Lopez-Sanchez, M.; Rodriguez-Aguilar, J. A.; and 138-32084-0. OCLC:1059131742.
Murukannaiah, P. K. 2023. Value inference in sociotech- Rodriguez-Soto, M.; Lopez-Sanchez, M.; and Rodriguez-
nical systems. In Proceedings of the 2023 International Aguilar,J.A.2023. Multi-objectivereinforcementlearning
ConferenceonAutonomousAgentsandMultiagentSystems, fordesigningethicalmulti-agentenvironments. NeuralCom-
1774–1780. putingandApplications.
Liscio,E.;vanderMeer,M.;Jonker,C.M.;Mouter,N.;and Rose, S.; and Dhandayudham, A. 2014. Towards an un-
Murukannaiah,P.K.2021.Axies:IdentifyingandEvaluating derstandingofInternet-basedproblemshoppingbehaviour:
Context-SpecificValues. Theconceptofonlineshoppingaddictionanditsproposed
Maas,M.M.;Matteuci,K.;andCooke,D.2022. Military predictors. Journalofbehavioraladdictions,3(2):83–89.
ArtificialIntelligenceasContributortoGlobalCatastrophic
Russell,S.2019. HumanCompatible:ArtificialIntelligence
Risk. InCambridgeConferenceonCatastrophicRisks2020.
andtheProblemofControl. Penguin.
Draftavailableathttps://papers.ssrn.com/sol3/papers.cfm?
Röllecke, F. J.; Huchzermeier, A.; and Schröder, D. 2018.
abstract_id=4115010.
ReturningCustomers:TheHiddenStrategicOpportunityof
Masoud,R.I.;Liu,Z.;Ferianc,M.;Treleaven,P.;andRo-
ReturnsManagement.CaliforniaManagementReview,60(2):
drigues, M. 2024. Cultural Alignment in Large Language
176–203.
Models:AnExplanatoryAnalysisBasedonHofstede’sCul-
turalDimensions. ArXiv:2309.12342[cs]. Schwartz,S.H.2012. AnOverviewoftheSchwartzTheory
ofBasicValues. OnlineReadingsinPsychologyandCulture,
McCarthy, J.; and Hayes, P. J. 1981. Some Philosophical
2(1).
ProblemsfromtheStandpointofArtificialIntelligence. In
Webber,B.L.;andNilsson,N.J.,eds.,ReadingsinArtificial Seger,E.;Avin,S.;Pearson,G.;Briers,M.;ÓhÉigeartaigh,
Intelligence, 431–450. Morgan Kaufmann. ISBN 978-0- S.;andBacon,H.2020.Tacklingthreatstoinformeddecision-
934613-03-3. makingindemocraticsocieties:Promotingepistemicsecurity
Mechergui,M.;andSreedharan,S.2024. GoalAlignment: inatechnologicall-advancedworld. Technicalreport,The
Re-analyzing Value Alignment Problems Using Human- AlanTuringInstitute,DefenceandSecurityProgramme.
AwareAI. ProceedingsoftheAAAIConferenceonArtificial Shaikh, M. T.; and Goodrich, M. A. 2020. A Measure to
Intelligence,38(9):10110–10118. MatchRobotPlanstoHumanIntent:ACaseStudyinMulti-
Meta. 2021. Harmful Content Can Evolve ObjectiveHuman-RobotPath-Planning. In202029thIEEE
Quickly: Our New AI System Adapts to Tackle It. InternationalConferenceonRobotandHumanInteractive
https://ai.meta.com/blog/harmful-content-can-evolve- Communication(RO-MAN),1033–1040.Naples,Italy:IEEE.
quickly-our-new-ai-system-adapts-to-tackle-it/. ISBN978-1-72816-075-7.
Montes,N.;andSierra,C.2022. SynthesisandProperties Sierra, C.; Osman, N.; Noriega, P.; Sabater-Mir, J.; and
ofOptimallyValue-AlignedNormativeSystems. Journalof Perelló,A.2021. Valuealignment:aformalapproach. Pub-
ArtificialIntelligenceResearch,74:1739–1774. lisher:arXivVersionNumber:1.Sikes, K.; Keren, S.; and Sreedharan, S. 2024. Reducing and their respective analogues in our novel misalignment
Human-RobotGoalStateDivergencewithEnvironmentDe- model.Weprovidethistotheinterestedreaderwhowould
sign. ArXiv:2404.15184[cs]. liketoworkthroughthemathematicalderivationsfromthe
Sivapalan,S.;Sadeghian,A.;Rahnama,H.;andMadni,A.M. contention model (Jang, Dori-Hacohen, and Allan 2017),
2014. Recommendersystemsine-commerce. In2014World whichweomithereduetospaceconsiderations.
AutomationCongress(WAC),179–184.IEEE. WhenwethenutilizethemodelinthecontextoftheAI
alignmentproblem,wecanbettermodelthecomplexsitu-
Skalse,J.;Howe,N.;Krasheninnikov,D.;andKrueger,D.
ationsthatmayarisewhenanygroupofhumans—andthe
2022. Definingandcharacterizingrewardgaming. Advances
AIagentsthosehumansdevelop,design,and/orcontrol—are
inNeuralInformationProcessingSystems,35:9460–9471.
variouslyalignedandmisaligned.Curiously,ourfinalformu-
Sutrop,M.;andothers.2020. DeepConceptualMoralDis-
lationofmisalignmentisalsoevocativeinitssimilaritytothe
agreements:OverWhatDoWeDisagreeandWhy? Trames,
informationtheoreticdefinitionofentropyanditsattendant
24(3):295–314. Publisher:TeadusteAkadeemiaKirjastus. binomialcoefficients.9Webelievethistobenocoincidence;
Tech, B. 2021. Multilingual Message Content Modera- withthisequationinmind,wecanseehowgroupsholding
tionatScale. https://medium.com/bumble-tech/multilingual- incompatible goals serve as a form of information, while
message-content-moderation-at-scale-ddd0da1e23ed. entropy or “heat” (in both the metaphoric and literal, ther-
Thielscher, M. 1998. Introduction to the fluent calculus. modynamic senses of the word) would be maximal when
LinköpingUniversityElectronicPress. misalignedagentgroupsareeach |G| andidenticalinsize.
|Ω|
Tolmeijer,S.;Arpatzoglou,V.;Rossetto,L.;andBernstein,
A. 2023. Trolleys, crashes, and perception—a survey on
howcurrentautonomousvehiclesdebatesinvokeproblematic
expectations. AIandEthics,1–12.
vanderMeer,M.;Vossen,P.;Jonker,C.M.;andMurukan-
naiah,P.K.2023. DoDifferencesinValuesInfluenceDis-
agreementsinOnlineDiscussions? ArXiv:2310.15757[cs].
Weidinger,L.;McKee,K.R.;Everett,R.;Huang,S.;Zhu,
T. O.; Chadwick, M. J.; Summerfield, C.; and Gabriel, I.
2023. UsingtheVeilofIgnorancetoalignAIsystemswith
principlesofjustice. ProceedingsoftheNationalAcademy
ofSciences,120(18):e2213709120.
Wikipedia.2024. Overtonwindow. https://en.wikipedia.org/
wiki/Overton_window[Accessed:5/14/24].
Yang, K.; Liu, Z.; Xie, Q.; Huang, J.; Zhang, T.; and
Ananiadou, S. 2024. MetaAligner: Towards General-
izable Multi-Objective Alignment of Language Models.
ArXiv:2403.17141[cs].
Yao, J.; Yi, X.; Wang, X.; Gong, Y.; and Xie, X. 2023.
Value FULCRA: Mapping Large Language Models to
the Multidimensional Spectrum of Basic Human Values.
ArXiv:2311.10766[cs].
Youn,S.-J.;andOh,K.-W.2007.IntentionRecognitionusing
aGraphRepresentation. WorldAcademyofScience,Engi-
neeringandTechnology,InternationalJournalofComputer,
Electrical,Automation,ControlandInformationEngineer-
ing,1:1–6.
Zhou,Z.;Liu,J.;Yang,C.;Shao,J.;Liu,Y.;Yue,X.;Ouyang,
W.; and Qiao, Y. 2023. Beyond One-Preference-Fits-All
Alignment:Multi-ObjectiveDirectPreferenceOptimization.
ArXiv:2310.03708[cs].
A AppendixA:Notationcomparisonbetween
ContentionandMisalignmentmodels
As discussed in the paper, our misalignment model draws
significantlyonapreviouslyproposedmodelofcontention 9Withonekeydifference,namely,thatofg ;eitherforcingevery
0
duetoJangetal.(2017).Table4includesacomprehensive agenttoholdagoal,orelsechangingg toconflictwitheveryother
0
list of symbols and definitions from the contention model goal,causesmatocollapseandbecomeidenticaltoentropy.Orig.Symbol Orig.Definition NewSymbol NewDefinition
Ω apopulation Ω apopulation
T atopic PA aproblemarea
p aperson ia anindividualagent(e.g.,humanorAI)
θ atupleof{Ω,T} θ atupleof{Ω,PA}
theprobabilityofcontentiongivenθ, theprobabilityofalignmentgivenθ,i.e.,
P(C|θ) i.e.,theprobabilitythattopicTis P(A|θ) theprobabilitythatagivenpopulationΩ
contentiousinagivenpopulationΩ isalignedwithrespecttoPA
C abinaryrandomvariableforcontention A abinaryrandomvariableforalignment
c abinaryvaluetosetCtobe“contentious” ma abinaryvaluetosetAtobe“misaligned”
nc abinaryvaluetosetCtobe“non-contentious” a abinaryvaluetosetAtobe“aligned”
s astancewithrespecttotopicT g agoalwithrespecttoproblemareaPA
apersonpholdsstanceswithrespectto anagentiaholdsgoalgwithrespectto
holds(p,s,T) holds(ia,g,PA)
topicT problemareaPA
Sˆ kstanceswithrespecttotopicT Gˆ kgoalswithrespecttoproblemareaPA
P(conflict|si,sj) l ce ov ne fll io cf t,c 1o =n cfl oic mt pb le et tw ele ye cn os ni flia cn td ins gj )(0=no P(conflict|gi,gj) l ce ov ne fll io cf t,c 1o =n cfl oic mt pb le et tw ele ye cn og ni flia cn td ing gj )(0=no
s0 alackofstance g0 alackofgoal
S Sˆ(cid:83)s0 G Gˆ(cid:83)g0
Gi agroupofpeoplewhoholdstancesi Gi agroupofagentswhoholdgoalgi
anopposinggroupinthepopulation anopposinggroupinthepopulation
Oi
thatholdastancethatconflictswithsi
Oi
thatholdagoalthatconflictswithgi
Table 4: Notation Change from Jang et. al’s contention model (Jang, Dori-Hacohen, and Allan 2017) to our misalignment
model.Notethatthecontentionmodelonlyreferstopopulationsofindividualpeople,whereasourmodelcanflexiblyhandle
combinationsofhumanandAIagents.