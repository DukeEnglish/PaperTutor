Diffusion-based Iterative Counterfactual
Explanations for Fetal Ultrasound Image Quality
Assessment
Paraskevas Pegios1,4, Manxi Lin1, Nina Weng1, Morten Bo Søndergaard
Svendsen2, Zahra Bashir3, Siavash Bigdeli1, Anders Nymark Christensen1,
Martin Tolsgaard2, and Aasa Feragen1,4
1 Technical University of Denmark, Kongens Lyngby, Denmark
{ppar,afhar}@dtu.dk
2 Region Hovedstaden Hospital, Copenhagen, Denmark
3 Slagelse Hospital, Copenhagen, Denmark
4 Pioneer Centre for AI, Copenhagen, Denmark
Abstract. Obstetricultrasoundimagequalityiscrucialforaccuratedi-
agnosisandmonitoringoffetalhealth.However,producinghigh-quality
standard planes is difficult, influenced by the sonographer’s expertise
and factors like the maternal BMI or the fetus dynamics. In this work,
weproposeusingdiffusion-basedcounterfactualexplainableAItogener-
aterealistichigh-qualitystandardplanesfromlow-qualitynon-standard
ones. Through quantitative and qualitative evaluation, we demonstrate
theeffectivenessofourmethodinproducingplausiblecounterfactualsof
increasedquality.Thisshowsfuturepromisebothforenhancingtraining
ofcliniciansbyprovidingvisualfeedback,aswellasforimprovingimage
quality and, consequently, downstream diagnosis and monitoring.
Keywords: Explainable AI · Diffusion Models · Fetal Ultrasound
1 Introduction
The quality of obstetric ultrasound screening images is crucial for the clinical
downstream tasks [32], involving fetal growth estimation, preterm birth predic-
Standard Plane Non-Standard Planes
TH
CSP Bone
TH Boundary
CSP
FP
Fig.1:Standardplanes(SPs)aredefinedasparticularanatomicalplanesthrough
the body (left); here we show examples of high-quality SPs (middle) and low-
quality non-standard planes (NSPs) (right) for the fetal head. A fetal head SP
shouldshowthalamus(TH),cavumseptipellucidi(CSP),butnot fossaposterior
(FP). The bone boundaries should support the correct placement of calipers.
4202
raM
31
]VI.ssee[
1v00780.3042:viXra2 P. Pegios et al.
tion,aswellasabnormalitydetection.Ifthecapturedanatomicalplanesarenot
preciseortheanatomicalregionstobemeasuredarenotvisualizedwell,thenthe
measurements and estimated outcomes will be incorrect (Fig. 1). To standard-
ize image quality, international ultrasound societies establish precise criteria for
defining fetal ultrasound quality [28]. However, the acquisition of high-quality
imagesishamperedbothbytheclinician’sleveloftrainingandbyphysicalchar-
acteristics such as maternal BMI or the fetus’ position. As a result, acquiring
standard planes of sufficiently high quality can be very challenging.
As a step towards solving this problem, we develop a method for generating
counterfactuals that, taking a fetal ultrasound image as input, predicts how
a higher quality image of the same anatomy would have looked like. This is
motivated by potential future applications [21] in two rather different use cases:
First,byshowcasingapathfromtheacquiredimagetoahigher-qualitystandard
planeofthesameanatomy,wecansupportlessexperiencedcliniciansinlearning
toacquirebetterultrasoundimages.Second,ifanon-standardplaneultrasound
image can be used to generate a higher-quality standard plane of the same
anatomy, this might be used to obtain better outcome predictions for those
patients where high-quality standard planes are hard to acquire.
Our methodbuilds on existing diffusion-based counterfactual explainable AI
(XAI) methods from computer vision. However, these needfurtherdevelopment
to be useful for fetal ultrasound: Traditional counterfactual XAI methods are
largelydevelopedforimagesoffaces[9,10,31],e.g.togeneratesmilingversionsof
famouspeople.Asone’sidentityshouldnotchange,andasthesecounterfactuals
can often be obtained by changing only a few pixels, sparsity constraints [9,10]
andmaskedinpainting[31]areoftenappliedasdatafidelitytermstoleaveone’s
identityunchanged.Forfetalultrasound,however,improvedimagequalityoften
requires changing many pixels: Blur typically occurs over large regions, and
correcting an anatomically incorrect plane requires changing the entire image.
To this end, we contribute a) an iterative counterfactual explanation approach
thatdrivestowardhigherconfidencecounterfactualsachievingbroadchangesto
theinputandb)anextensiveevaluationthatdemonstratesthatwecanproduce
plausible high-quality counterfactuals for fetal ultrasound images.
2 Related Work
Over recent years, deep learning methods have supported fetal ultrasound qual-
ity assessment, including image-based [13,14,32] and video-based [16,19,34] ap-
proaches.Otherapproachesfocusonthegenerationofsyntheticfetalultrasound
images [21] either to improve fine-graded classification [11,17,24] or to gener-
atetrainingmaterialfornovicesonographers[4,12,20].ThesuccessofDenoising
DiffusionProbabilisticModels[7,25](DDPMs)enablesthecreationofhighlyre-
alistic fetal ultrasound images [8] or the detection of out-of-distribution frames
from fetal ultrasound videos [23]. Aligned with our motivation for supporting
non-experts, [20] employs a GAN-based method with domain adaptation to
predict a high-quality standard plane using previous video frames. In our work,Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality 3
Diffusion-based Iterative Counterfactual Explanations
NSP SP
Diff-ICE Diff-ICE
c io nr pru up tt Guidance NSP
s l or
SP
One Iteration standard plane classifier
Fig.2: Top: Each iteration uses previous output to enhance counterfactual con-
fidence. Bottom-left: Efficient gradient estimation at each time step t for one
iteration. Bottom-right: Standard plane classifier and guiding gradient flow.
werelyonimageinputsandleveragediffusion-basedcounterfactualexplanations
to predict the path from low-quality to high-quality images.
Counterfactual explanations try to answer the question: How does an image
looklikeifitisclassifieddifferentlybyagivenclassifier?Differentfromadversar-
ial examples, counterfactuals should be realistic, i.e., close to the data manifold
which is usually approximated with generative models. In medical imaging, dif-
ferent methods have been proposed including VAE-based [3], GAN-based [30]
and diffusion-based [27,29] approaches. Yet, these are applied to tasks where
changes are highly localized. In our work, we leverage recent advancements in
diffusion guidance [5] and counterfactuals [31] to apply a computationally feasi-
bleiterativeapproachwhereeachsteputilizesaperceptuallossasadatafidelity
term, rather than sparsity [9,10] or inpainting [10,31] to refine diffusion-based
counterfactuals. This allows us to achieve more global counterfactual changes.
3 Method
3.1 Preliminaries on Diffusion Models
DDPMs [7] are defined by two processes: The forward and the reverse. In the
former, an input image x is gradually corrupted by adding Gaussian noise
0
at each time step t, while the latter gradually removes it to generate a clean
image. Formally, the forward process is defined by generating the time t image
√
(cid:0) (cid:1)
x ∼ N 1−β x ,β I iteratively from the original, clean image x , where
t t t−1 t 0
{β} controls the variance of the noise added per step. The time t image x
t=1:T t
can be sampled directly [25] using x and the reparametrization trick,
0
√ √
x = α¯ x +ϵ 1−α¯ ,ϵ∼N(0,1), (1)
t t 0 t
where α =1−β and α
=(cid:81)t
α . The reverse process also consists of Gaus-
t t t s=1 s
sian transitions whose mean and covariance are predicted by neural networks:4 P. Pegios et al.
x ∼ N (µ (x ,t),Σ (x ,t)), where x ∼ N (0,I). In practice, a denoiser
t−1 θ t θ t T
ϵ (x ,t)predictsthenoisefromEq.(1)ratherthanpredictingthemeanµ (x ,t)
θ t θ t
(cid:16) (cid:17)
directly, giving µ θ(x t,t)= √ 11
−βt
x t− √ 1β −t α¯tϵ θ(x t,t) .
3.2 Diff-ICE: Diffusion-based Iterative Counterfactual Explanations
Wequantifyimagequalityusingaclassifierf,whichistrainedtopredictwhether
fetal ultrasound images are standard or non-standard (SP or NSP) planes. As
bothultrasoundimagequality[14]andoutcomeprediction[26]benefitfromcom-
bining images with segmentations, classifier f consists of a segmentation model
s and a predictor l trained sequentially. The classifier takes as inputs the image
and the segmentation predictions, f(x)=l(s(x),x). This adds explainability to
the classifier, as the segmentations can be visualized as partial explanations.
Following [9,31], we corrupt the input x up to a limited noise level τ, with
1 ≤ τ ≤ T, using Eq.(1) to initialize a noisy version of the input and guide xc
τ
towards the desired counterfactual class y with guided diffusion [4]. To this end,
we minimize a loss function L and shift the average sample with its gradient g,
xc ∼N (µ (xc,t)−Σ (xc,t)g,Σ (xc,t)). (2)
t−1 θ t θ t θ t
As the classifier f is trained on clean images, we use the learned denoiser to get
one-stepdenoisedpredictionsandpassthemthroughf bysolvingEq.(1)forx ,
0
√
xc− 1−α ϵ (xc,t)
xˆc = t √ t θ t , (3)
0|t α
t
Computing the gradient w.r.t. xc as in [1,33], i.e, g = ∇ L, necessitates
t xc t
backpropagating through the denoiser. As this is computationally expensive,
we instead follow an efficient gradient estimation [5,31] which avoids excessive
backpropagationandspeedsupsampling.Thus,foreacht,wecomputegradients
w.r.t xˆc , i.e, g =∇ L in Eq. (2). We use the counterfactual guiding loss
0|t xˆc 0|t
(cid:16) (cid:16) (cid:17) (cid:17) (cid:16) (cid:17)
L(x,xˆc ,y)=λ L f xˆc ,y +λ L xˆc ,x , (4)
0|t c c 0|t p p 0|t
whereL istheclassificationlosswhichguidestowardsthedesiredlabely,L is
c p
an l2-based perceptual loss which guides the process in terms of proximity, and
λ and λ are hyperparameters which control the guidance strength. Typical
c p
applications focus on localized counterfactual changes and use a pixel-based l1-
norm for L [10,31] or this is added as an extra term on the noisy images [9].
p
Our loss function prioritizes broad changes while preserving anatomical fidelity.
Yet, achieving global changes is challenging, as setting τ for a limited noise
level preserves semantic information in one-step denoised predictions but allows
guidance mostly in refinement stages [33]. Increasing the strength of λ may
c
result in not meaningful generations [1]. Thus, we propose a Diffusion-based
IterativeCounterfactualExplanationapproach(Diff-ICE)toenhanceconfidence
in counterfactuals and enable more global alterations. Through L iterations ofIterative Counterfactual Explanations for Fetal Ultrasound Image Quality 5
the counterfactually guided reverse process, each using the previous output as
input, we refine the counterfactuals while maintaining fidelity constraints close
to the original input x in Eq. (4). Our approach is summarized in Fig. 2.
4 Experiments and Results
Dataandbaseimplementation. Weworkwithtwodatasetsextractedfroma
nationalfetalultrasoundscreeningdatabase(ANONYMIZED).TheGROWTH
dataset,whichisusedtotrainboththeunconditionaldiffusionmodelandaseg-
mentationmodelusedintheguidingstandardplaneclassifierf,consistsof4363
(2842/1521 for train/test) fetal ultrasound images from growth scans including
head, abdomen, femur, and cervix images. The HEAD dataset is used to train
and test the full guiding classifier f, and consists of fetal head ultrasound im-
ages which include 240 high-quality standard planes (SP) and 1339 low-quality
non-standard planes (NSP).
As the guiding standard plane classifier f we choose a robust and inter-
pretablearchitecturethatcombinesaDTU-Net[15]segmentationmodelswitha
SonoNet-16[2]classifierlfollowing[26].Robustnessisimportanttoensurehigh-
quality counterfactuals, and interpretability makes the counterfactuals easier to
monitor both for technical developers and clinicians at different levels of experi-
ence.ThesegmentationmodelsisdevelopedonGROWTH.Thus,wetrainand
evaluate the classifier’s predictor l sequentially keeping the weights of g fixed on
a split of 121/26/93 SP and 712/204/423 NSP images for train/validation/test
with non-overlapping patients resulting in 78% balanced test accuracy.
An unconditional DDPM [7] is also trained on GROWTH using 1000
diffusion steps, following model architecture described in [9], training for 300K
iterations with batch size 16, learning rate 10−4, weight decay of 0.05, and no
dropout. For all models, images are resized to 224×288, embedded text and
calipers are removed [22] and pixel intensity is normalized to [−1,1].
To generate counterfactual explanations, we empirically set L = 5, τ =
120of400re-spacedtimesteps,λ =30andsearchforλ ∈{40,60,80}[9].The
p c
perceptual loss uses a ResNet-50 trained on RadImageNet [18].
Baselines. 1)DiME[9]employsanexpensivenestedloopofthereverseguided
processes per time step t to obtain clean images and applies a scaling trick to
estimate gradients w.r.t. noisy images. 2) A single iteration of Diff-ICE, hence-
forthDiff-ICE ,implementsFastDiME[31]withoutmask-basedinpainting(this
1
is tailored for localized changes and would be a disadvantage in our setting). 3)
Inspiredby[1]weimplementDiff-ICE -x takingthegradientw.r.tnoisyimages.
1 t
For fair comparison, baselines use the same loss (Eq. (4)) and hyperparameters.
Performance metrics. We evaluate realism by computing Fréchet Inception
Distance[6](FID)andFréchetSonoNetDistance[12](FSD)betweentheoriginal
NSP images and their valid SP counterfactuals. We further introduce SonoSim,6 P. Pegios et al.
Table 1: Comparison of Diff-ICE with baseline diffusion-based approaches.
Realism Validity Efficiency
Method FID↓FSD↓SonoSim↑ MQD↑BKL↓MAD↑ FR↑ Batch Total GPUM
Time(s) Time(h) (GB)
DiME 41.5 0.396 0.854 0.291 0.391 0.231 0.966 3151.9±730.4 37.65 9.6
Diff-ICE1-xt 39.9 0.403 0.855 0.301 0.413 0.208 0.936 231.4±56.8 2.77 33.7
Diff-ICE1 39.0 0.355 0.856 0.253 0.387 0.234 0.982 115.6±34.2 1.38 9.6
Diff-ICE 42.4 0.435 0.790 0.371 0.336 0.284 0.982 448.6±22.9 5.27 9.6
Table 2: Intermediate results for each iteration of Diff-ICE.
Realism Validity Efficiency
Iteration FID ↓ FSD ↓ SonoSim ↑ MQD ↑ BKL ↓ MAD ↑ Batch Iteration
Time (s) Time (h)
1 38.96 0.355 0.856 0.253 0.387 0.234 115.6 ± 34.2 1.38
2 41.26 0.420 0.830 0.317 0.370 0.250 88.6 ± 22.3 1.06
3 42.25 0.464 0.818 0.314 0.362 0.258 85.8 ± 21.9 1.03
4 43.17 0.454 0.807 0.355 0.357 0.262 77.9 ± 18.7 0.96
5 42.42 0.435 0.790 0.371 0.336 0.284 78.9 ± 17.4 0.95
which computes the cosine similarity using SonoNet-64 [2] features, similar to
those used in FSD. To measure validity of generated images, we use standard
counterfactual validity metrics from computer vision such as Flip Ratio (FR),
i.e., the frequency of counterfactuals classified as SP, Mean Absolute Differ-
ence [31] (MAD) of confidence prediction between original NSP and counterfac-
tual SP, and Bounded remapping of KL divergence [9] (BKL), which measures
similarity between the counterfactual’s prediction by f, and the SP one-hot
counterfactuallabel.ThevaliditymetricsBKL,MAD,andFRarecomputedfor
those NSP test images that are classified as NSP by f. In addition to verifying
that counterfactuals indeed move towards the SP class according to the guiding
classifierf,wedevelopaProgressiveConceptBottleneckModel[14](PCBM)as
an oracle using GROWTH, and use its confidence to measure overall Quality
Scores (QS ) for both input x and counterfactual xc. To simulate a realistic
O
evaluation scenario and ensure reliable oracle predictions for our analysis, we
include cases with confident predictions of the original NSP input, i.e., original
inputs x classified as NSP, QS (x) < 0.5 (see Fig. S2 in Supplementary Mate-
O
rial). As an oracle validity metric, we introduce Mean overall Quality Difference
defined as MQD= 1 (cid:80)N I(QS (x )<0.5)·QD (xc,x ) where I is the indi-
N i=1 O i O i i
catorfunction,N =423NSPtestimagesandQD (xc,x)=QS (xc)−QS (x).
O O O
To evaluate efficiency, we compute batch time in seconds, total time in hours,
and GPU memory, using a batch size of 10 on an NVIDIA RTX A6000.Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality 7
(a) (b) (c) (d) (e) (f)
NSPInput Iter1 Iter2 Iter3 Iter4 Iter5
Fig.3: Iterations of Diff-ICE from the low-quality NSP to a higher-quality SP,
visualized with predicted segmentations for interpretability (expert mask anno-
tation for NSP input). Diff-ICE can synthesize planes that (correctly) contain
thalamus (TH), and cavum septi pellucidi (CSP) from NSP planes that don’t
contain this. It is also capable of creating planes that (correctly) remove fossa
posterior (FP). In addition to these local and explicit changes, Diff-ICE also
achieves broad changes and refinements.
Results. Wegeneratedcounterfactualexplanationsforall423NSPtestimages
from HEAD. Tables 1 and 2 list results for all methods and each interme-
diate iteration of Diff-ICE, respectively. Note that there is an expected inverse
relationshipbetweenrealism(similaritytoinput)andvalidity(improvedSPpre-
diction), meaning that the choice of iterations is a trade-off. Table 2 illustrates
thistrend,withrealismdecreasingasvalidityincreaseswithmoreiterations.We
chose L = 5 due to small qualitative differences between 4th and 5th iteration,
asshowninFig.3,illustratingpathsfromlow-qualityNSPtohigher-qualitySP.
In addition to image-level SP confidence scores, the oracle PCBM [14] also
predicts individual quality scores (QS , QS and QS for fossa posterior
FP CSP TH
(FP),cavumseptipellucidi(CSP),andthalamus(TH)).Asafine-grainedassess-8 P. Pegios et al.
Overall (O) Fossa Posterior (FP) Cavum S. P. (CSP) Thalamus (TH)
1.0 0.8 1.0
0.8 0.8 0.6 0.8 00 .. 46 00 .. 46 00 .. 24 000 ... 246
0.2 0.2 0.0 0.0
0.0 0.0 0.2 0.2
0.2 0.2 0.4 00 .. 64
0.4 0.4
0.00.10.20.30.40.5 0.20.40.60.81.0 0.0 0.2 0.4 0.6 0.8 0.00.20.40.60.8
QSO(x) QSFP(x) QSCSP(x) QSCSP(x)
Fig.4:QualityDifference(QD)asafunctionofNSPinput’sQualityScore(QS).
mentofDiff-ICE,weshowtheirqualityscoredifferencesbetweencounterfactual
andNSPinput(QD ,QD ,QD )asafunctionofinput’squalityinFig.4.
FP CSP TH
Qualitative validation. A Fetal Medicine consultant with 10 years of experi-
ence in obstetric imaging was asked to select the best quality image from pairs
of real NSP images and associated Diff-ICE counterfactuals. Image pairs with
QD > 0 were sampled uniformly, and displayed in randomized position and
O
order. The expert selected Diff-ICE counterfactuals in 41 out of 50 image pairs,
demonstratingtheabilityofDiff-ICEtoindeedenhancetheinput’squality.The
expert also stated qualitatively that differences were global, including improved
presentationofboneoutlines,TH,andCSP,andimprovedoverallimagequality.
Ablation study. We conducted an ablation study to assess the impact of pa-
rameters τ and λ , in our single iteration baseline Diff-ICE , relative to our
c 1
iterative method Diff-ICE, as well as to investigate the influence of L in Eq. 4.
p
We observed that trying to achieve global counterfactual changes by increasing
classifier’s strength too much (λ = 400) leads to adversarial examples while
c
increasing the input noise level too much (τ = 200) results in changes in the
anatomyoftheheadorcollapsetoadversarialexamplestoo.Inallcases,remov-
ing the L impacts the realism of counterfactuals. Detailed quantitative results
p
(Tab.S3)andvisualexamples(Fig.S1)canbefoundinSupplementaryMaterial.
5 Discussion and Conclusion
Our experimental results highlight the effectiveness of our iterative approach to
producehigherconfidencecounterfactualsandbroaderchangescomparedtothe
singleiterationbaselines.Ourmethodiscomputationallyfeasible,leveragingthe
efficientgradientestimationschemeweemploy.FromFig.4weseethatimprove-
ment is largest when the initial quality is poor, which is intuitive, as changes to
already high-quality images should be minimal. For all three anatomical struc-
tures, the image quality associated with the structure is generally improved
by the counterfactual. Diff-ICE performs particularly well in removing the un-
wanted FP, whereas there are some cases where, in particular, TH and CSP are
)cx,x(ODQ )cx,x(PFDQ )cx,x(PSCDQ )cx,x(HTDQIterative Counterfactual Explanations for Fetal Ultrasound Image Quality 9
not improved. We note, however, that these cases feature fairly well-represented
structuresintheinputsandourmethodbalancesoverallimage-levelqualitywith
the quality of individual structures (see Fig. S3 in Supplementary Material).
To conclude, we propose Diff-ICE, to enhance confidence in counterfactuals
and enable global changes. Our method demonstrates its capability to produce
plausiblecounterfactualexplanationsforthechallengingtaskoffetalultrasound
quality assessment as well as its potential for future applications.
Acknowledgements. This work was supported by the Pioneer Centre for AI
(DNRF grant nr P1), the DIREC project EXPLAIN-ME (9142-00001B), and
the Novo Nordisk Foundation through the Center for Basic Machine Learning
Research in Life Science (NNF20OC0062606). P.P. would like to thank Thanos
Delatolas for insightful discussions.
References
1. Bansal,A.,Chu,H.M.,Schwarzschild,A.,Sengupta,S.,Goldblum,M.,Geiping,J.,
Goldstein,T.:Universalguidancefordiffusionmodels.In:IEEE/CVFConference
on Computer Vision and Pattern Recognition. pp. 843–852 (2023)
2. Baumgartner, C.F., Kamnitsas, K., Matthew, J., Fletcher, T.P., Smith, S., Koch,
L.M., Kainz, B., Rueckert, D.: Sononet: real-time detection and localisation of
fetal standard scan planes in freehand ultrasound. IEEE transactions on medical
imaging 36(11), 2204–2215 (2017)
3. Cohen,J.P.,Brooks,R.,En,S.,Zucker,E.,Pareek,A.,Lungren,M.P.,Chaudhari,
A.:Gifsplanationvialatentshift:asimpleautoencoderapproachtocounterfactual
generationforchestx-rays.In:MedicalImagingwithDeepLearning.PMLR(2021)
4. Dhariwal,P.,Nichol,A.:Diffusionmodelsbeatgansonimagesynthesis.Advances
in neural information processing systems 34, 8780–8794 (2021)
5. He,Y.,Murata,N.,Lai,C.H.,Takida,Y.,Uesaka,T.,Kim,D.,Liao,W.H.,Mitsu-
fuji,Y.,Kolter,J.Z.,Salakhutdinov,R.,etal.:Manifoldpreservingguideddiffusion.
In: The Twelfth International Conference on Learning Representations (2023)
6. Heusel,M.,Ramsauer,H.,Unterthiner,T.,Nessler,B.,Hochreiter,S.:Ganstrained
byatwotime-scaleupdateruleconvergetoalocalnashequilibrium.Advancesin
neural information processing systems 30 (2017)
7. Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in
neural information processing systems 33, 6840–6851 (2020)
8. Iskandar, M., Mannering, H., Sun, Z., Matthew, J., Kerdegari, H., Peralta, L.,
Xochicale,M.:Towardsrealisticultrasoundfetalbrainimagingsynthesis.In:Med-
ical Imaging with Deep Learning, short paper track (2023)
9. Jeanneret, G., Simon, L., Jurie, F.: Diffusion models for counterfactual explana-
tions. In: Asian Conference on Computer Vision. pp. 858–876 (2022)
10. Jeanneret,G.,Simon,L.,Jurie,F.:Adversarialcounterfactualvisualexplanations.
In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (2023)
11. Lasala, A., Fiorentino, M.C., Micera, S., Bandini, A., Moccia, S.: Exploiting
class activation mappings as prior to generate fetal brain ultrasound images with
gans. In: 2023 45th Annual International Conference of the IEEE Engineering in
Medicine & Biology Society (EMBC). pp. 1–4. IEEE (2023)10 P. Pegios et al.
12. Lee,L.H.,Noble,J.A.:Generatingcontrollableultrasoundimagesofthefetalhead.
In: 17th International Symposium on Biomedical Imaging (ISBI). pp. 1761–1764.
IEEE (2020)
13. Lin, M., Ambsdorf, J., Sejer, E.P.F., Bashir, Z., Wong, C.K., Pegios, P., Raheli,
A., Svendsen, M.B.S., Nielsen, M., Tolsgaard, M.G., et al.: Learning semantic im-
age quality for fetal ultrasound from noisy ranking annotation. arXiv preprint
arXiv:2402.08294 (2024)
14. Lin,M.,Feragen,A.,Bashir,Z.,Tolsgaard,M.G.,Christensen,A.N.:Isaw,icon-
ceived, i concluded: Progressive concepts as bottlenecks. arXiv:2211.10630 (2022)
15. Lin, M., Zepf, K., Christensen, A.N., Bashir, Z., Svendsen, M.B.S., Tolsgaard,
M., Feragen, A.: Dtu-net: Learning topological similarity for curvilinear structure
segmentation. In: International Conference on Information Processing in Medical
Imaging. pp. 654–666. Springer (2023)
16. Liu, S., Ying, Q., He, S., Yang, X., Ni, D., Huang, R.: Hierarchical agent-based
reinforcement learning framework for automated quality assessment of fetal ul-
trasound video. In: 20th International Symposium on Biomedical Imaging (ISBI).
pp. 1–5. IEEE (2023)
17. Maack,L.,Holstein,L.,Schlaefer,A.:Gansforgenerationofsyntheticultrasound
images from small datasets. Current Directions in Biomedical Engineering 8(1),
17–20 (2022)
18. Mei,X.,etal.:Radimagenet:anopenradiologicdeeplearningresearchdatasetfor
effective transfer learning. Radiology: Artificial Intelligence 4(5), e210315 (2022)
19. Men, Q., Teng, C., Drukker, L., Papageorghiou, A.T., Noble, J.A.: Multimodal-
guidenet: Gaze-probe bidirectional guidance in obstetric ultrasound scanning. In:
International Conference on Medical Image Computing and Computer-Assisted
Intervention. pp. 94–103. Springer (2022)
20. Men, Q., Zhao, H., Drukker, L., Papageorghiou, A.T., Noble, J.A.: Towards stan-
dard plane prediction of fetal head ultrasound with domain adaption. In: 20th
International Symposium on Biomedical Imaging (ISBI). pp. 1–5. IEEE (2023)
21. Mendez,M.,Sundararaman,S.,Probyn,L.,Tyrrell,P.N.:Approachesandlimita-
tions of machine learning for synthetic ultrasound generation: A scoping review.
Journal of Ultrasound in Medicine 42(12), 2695–2706 (2023)
22. Mikolaj, K., Lin, M., Bashir, Z., Svendsen, M.B.S., Tolsgaard, M., Nymark, A.,
Feragen, A.: Removing confounding information from fetal ultrasound images.
arXiv:2303.13918 (2023)
23. Mishra,D.,Zhao,H.,Saha,P.,Papageorghiou,A.T.,Noble,J.A.:Dualconditioned
diffusion models for out-of-distribution detection: Application to fetal ultrasound
videos.In:InternationalConferenceonMedicalImageComputingandComputer-
Assisted Intervention. pp. 216–226. Springer (2023)
24. Montero, A., Bonet-Carne, E., Burgos-Artizzu, X.P.: Generative adversarial net-
works to improve fetal brain fine-grained plane classification. Sensors 21 (2021)
25. Nichol, A.Q., Dhariwal, P.: Improved denoising diffusion probabilistic models. In:
International Conference on Machine Learning. pp. 8162–8171. PMLR (2021)
26. Pegios, P., Sejer, E.P.F., Lin, M., Bashir, Z., Svendsen, M.B.S., Nielsen, M., Pe-
tersen, E., Christensen, A.N., Tolsgaard, M., Feragen, A.: Leveraging shape and
spatial information for spontaneous preterm birth prediction. In: International
Workshop on Advances in Simplifying Medical Ultrasound. pp. 57–67. Springer
(2023)
27. Ribeiro, F.D.S., Xia, T., Monteiro, M., Pawlowski, N., Glocker, B.: High fidelity
image counterfactuals with probabilistic causal models. In: International Confer-
ence on Machine Learning. pp. 7390–7425. PMLR (2023)Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality 11
28. Salomon,L.,etal.:Isuogpracticeguidelines:ultrasoundassessmentoffetalbiom-
etry and growth. Ultrasound in obstetrics & gynecology 53(6), 715–723 (2019)
29. Sanchez,P.,Kascenas,A.,Liu,X.,O’Neil,A.Q.,Tsaftaris,S.A.:Whatishealthy?
generative counterfactual diffusion for lesion localization. In: MICCAI Workshop
on Deep Generative Models. pp. 34–44. Springer (2022)
30. Singla, S., Eslami, M., Pollack, B., Wallace, S., Batmanghelich, K.: Explaining
the black-box smoothly—a counterfactual approach. Medical Image Analysis 84,
102721 (2023)
31. Weng, N., Pegios, P., Feragen, A., Petersen, E., Bigdeli, S.: Fast diffusion-
based counterfactuals for shortcut removal and generation. arXiv preprint
arXiv:2312.14223 (2023)
32. Wu, L., Cheng, J.Z., Li, S., Lei, B., Wang, T., Ni, D.: Fuiqa: fetal ultrasound
imagequalityassessmentwithdeepconvolutionalnetworks.IEEEtransactionson
cybernetics 47(5), 1336–1349 (2017)
33. Yu,J.,Wang,Y.,Zhao,C.,Ghanem,B.,Zhang,J.:Freedom:Training-freeenergy-
guided conditional diffusion model. In: IEEE/CVF International Conference on
Computer Vision. pp. 23174–23184 (2023)
34. Zhao, H., Zheng, Q., Teng, C., Yasrab, R., Drukker, L., Papageorghiou, A.T.,
Noble, J.A.: Memory-based unsupervised video clinical quality assessment with
multi-modalitydatainfetalultrasound.MedicalImageAnalysis90,102977(2023)Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality I
Supplementary Material
(a) (b) (c) (d) (e)
NSPInput τ =80 τ =120, τ =200 Diff-ICE
λc=400
Fig.S1:Ablation study.λ =400(c)resultsinnotmeaningfulcounterfactuals
c
oradversarialnoises.τ =80(b)cannotachievestrongchanges,andτ =200(d)
can lead to changes in the anatomy or collapse to adversarial examples.II P. Pegios et al.
Table S3: Ablation study on parameters τ, λ and the effect of L .
c p
Parameters Realism Validity Efficiency
τ Lp FID↓FSD↓SonoSim↑ MQD↑BKL↓MAD↑ BatchTime(s)TotalTime(h)
80 ✓ ✗ 3 38 9. .10 92 0 0. .3 373 12 0 0. .8 888 38 0 0. .2 20 07 9 0 0. .4 41 16 6 0 0. .1 27 03 5 7 76 0. .4 1± ±2 12 9. .2 7 0 0. .9 83 4
✓ 38.96 0.355 0.856 0.253 0.387 0.234 115.6±34.2 1.38
120 ✗ 40.66 0.427 0.851 0.259 0.388 0.234 88.5±25.2 1.06
✓/λc=400 73.18 14.80 0.656 0.352 0.026 0.059 68.5±5.1 0.88
160 ✓ ✗ 4 41 2. .3 00 4 0 0. .4 41 87 2 0 0. .8 82 27 1 0 0. .3 30 33 2 0 0. .3 36 67 8 0 0. .2 25 55 3 1 13 01 8. .9 3± ±3 39 1. .9 2 1 1. .6 31 0
200 ✓ ✗ 4 44 5. .1 54 3 0 0. .4 57 01 9 0 0. .7 77 87 2 00 .. 337 95 7 00 .. 33 54 09 00 .. 22 77 12 1 17 33 8. .4 4± ±5 42 0. .4 3 2 1. .1 62 6
Overall Quality of NSP Inputs
0.8 QSO(x)
0.6 Q QS SO O( (x x) )> <0 0. .5 5
0.4
0.2
0.0
0.2
0.4 f(x)
0.6 NSP
0.8 SP
0.0 0.2 0.4 0.6 0.8
QSO(x)
Fig.S2:Oracle validity metric.QualityDifference(QD)asafunctionofNSP
input’sQualityScore(QS).Theplotincludes417validDiff-ICEcounterfactuals
out of the 423 NSP inputs from our test set. To compute MQD we include 310
SP counterfactuals (circles) for which their original NSP is correctly predicted
to have low image quality, i.e., QS (x)<0.5. The classifier f used for counter-
O
factual guidance correctly predicts 330 (blue samples) of the NSP inputs.
Fig.S3: Limitations. Rows: NSP inputs with segmentation annotations and
Diff-ICE counterfactuals with segmentation predictions. Cases where expert
chose NSP input: Diff-ICEbalancesqualitybyincreasingoverallandCSPqual-
ity but with the cost of slightly reducing TH (right) or FP (left) quality.
)cx,x(ODQ