Steering LLMs Towards Unbiased Responses:
A Causality-Guided Debiasing Framework
JinglingLi*12 ZeyuTang*3 XiaoyuLiu2 PeterSpirtes3 KunZhang34 LiuLeqi5 YangLiu16
Abstract
Largelanguagemodels(LLMs)caneasilygener-
atebiasedanddiscriminativeresponses.AsLLMs
tapintoconsequentialdecision-making(e.g.,hir-
ingandhealthcare),itisofcrucialimportanceto
developstrategiestomitigatethesebiases. This
paperfocusesonsocialbias,tacklingtheassocia-
tionbetweendemographicinformationandLLM
outputs. We propose a causality-guided debias- Figure1: Differentreasoningtoansweracoreferenceques-
ingframeworkthatutilizescausalunderstandings tion. Abiasedanswermaybeduetotheuseofagender
of (1) the data-generating process of the train- shortcut,whileabias-freeanswerismadebyconsidering
ingcorpusfedtoLLMs,and(2)theinternalrea- properworldknowledgegiventhecircumstances.1
soning process of LLM inference, to guide the
design of prompts for debiasing LLM outputs
through selection mechanisms. Our framework nificantasLLMsbecomemorecapableandstarttoserve
unifiesexistingde-biasingpromptingapproaches as foundational components in decision-making systems
suchasinhibitiveinstructionsandin-contextcon- across various sectors such as healthcare and education.
trastiveexamples,andshedslightonnewways Manydebiasingapproacheshavebeenproposedtotackle
ofdebiasingbyencouragingbias-freereasoning. thisissue,forinstance,directfine-tuningofmodelparam-
Ourstrongempiricalperformanceonreal-world eters (Kaneko & Bollegala, 2021; Garimella et al., 2021;
datasets demonstrates that our framework pro- Lauscheretal.,2021;Guoetal.,2022),modifyingthede-
vides principled guidelines on debiasing LLM coding steps (Schick et al., 2021), and prompting-based
outputsevenwithonlytheblack-boxaccess. techniques(Sietal.,2022;Tamkinetal.,2023;Obaetal.,
2023; Ganguli et al., 2023). For various reasons such as
securityandbusinessinterests,manyofthemostcapable
1.Introduction LLMs are closed-sourced, for instance, GPT-4 (Achiam
et al., 2023), Gemini (Anil et al., 2023), Claude 2 (An-
LargeLanguageModels(LLMs),whicharetrainedonmas-
thropic, 2023), where the general public do not have ac-
sive text corpora, have been found to exhibit concerning
cess to models’ internal structures or parameters. Thus,
levelsofsocialbiases(Shengetal.,2019;Gonen&Gold-
prompting-basedtechniqueslargelybecometheonlyviable
berg,2019;Schicketal.,2021;Benderetal.,2021;Dodge
optiontomitigatebiaswhenusingclosed-sourcedLLMs.
et al., 2021). The unchecked biases can potentially per-
petuate and amplify societal inequities, leading to unfair In this work, we focus on prompting techniques to steer
orevenunethicaloutcomes. Thisissueisparticularlysig- LLMstowardsunbiasedresponses. Tostudythis,wenotice
that obtaining unbiased responses essentially boils down
*Equal contribution. 1ByteDance Research; 2Department totheprocessofselectingproperpiecesfromthemodel’s
of Computer Science, University of Maryland, College Park;
internalrepresentationsandknowledgetomakethedecision.
3Department of Philosophy, Carnegie Mellon University;
4Machine Learning Department, Mohamed bin Zayed Univer- Letusconsiderasimpletaskofresolvingthecoreferenceof
sity of Artificial Intelligence; 5Princeton Language and In- agenderpronouninagivensentence.Amodelmayoutputa
telligence; 6Computer Science and Engineering Department, biasedanswerbyusingagendershortcutpotentiallylearned
University of California, Santa Cruz. Correspondence to:
Jingling Li <jinglingli1024@gmail.com>, Zeyu Tang 1The use of demographic information does not necessarily
<zeyutang@cmu.edu>. indicatethereasoningisbiased:sometimescertaindemographic
information(e.g.,gender)shouldbeconsideredforsituationssuch
Preprint.Copyright2024bytheauthor(s). asmakingmedicaldecisions.
1
4202
raM
31
]LC.sc[
1v34780.3042:viXraSteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
poseprompt-designstrategiesandfurtherconductavariety
ofempiricalstudiestoanalyzetheireffectiveness. Wefind
that prompts employing both intuitions significantly out-
performexistingprompting-baseddebiasingmethods. The
strongempiricalresultsclearlydemonstratetheeffective-
ness of the causality-guided debiasing framework, even
whenweonlyhaveblack-boxaccesses.
Ourcontributionscanbesummarizedasfollows:
Figure 2: Different prompting-based methods guided by
• Weconstructdetailedcausalmodelingsforboththeun-
oneorbothintuitions: discouraging([-])biasedreasoning,
derlying data-generating process of the training corpus
andencouraging([+])bias-freereasoning.
andtheLLMreasoningprocess. Wenotethatselection
mechanismsplayanessentialroleinidentifyinghowthe
from the imbalanced representations in the training data. LLM’soutputcouldbemodulatedbydifferentprompts.
Forexample,inFigure1(a),themodelmayassociatethe • We formulate a causality-guided debiasing framework.
pronoun“he”with“physician”ratherthan“secretary”due Through causal understandings of data-generating pro-
tosocialbiasesreflectedinthetrainingdata–thegenderdis- cesses,weidentifyconditionsthatstrategiesfordesigning
tributionsaredisproportionalfordifferentoccupations. We promptsshouldsatisfytodebiasinaprincipledandeffec-
denotesuchreasoningprocessasbiasedreasoning,where tiveway. Theframeworkalsounifiesexistingprompting-
the model selects internal representations in an improper baseddebiasmethods.
way as this specific demographic information (gender) is • Usingthesestrategies,weshowstrongempiricalresults
unrelatedtosolvingthecoreferencetask. Weprovidemore ondebiasingvarioussocialbiasesacrossdifferentLLMs,
detaileddiscussionsonselectionmechanismsinSection3. demonstratingtheclearbenefitofourframework.
Mostoftheexistingprompting-baseddebiasingmethods
2.Preliminaries
focusondiscouragingbiasedreasoning, forinstance, us-
ingexplicitpromptstoavoidusingbiasedassociationsor
In this section, we provide a brief introduction to causal
prohibitingtheutilizationofgenderinformationwhenmak-
modelingandcausalreasoning(Section2.1). Wealsopro-
ing the decision. While these approaches help to a cer-
vide a motivating example to illustrate how the selection
tainextent,anotheroverlookedprompting-basedstrategyis
mechanismcanreshapedependencepatternswithinthedif-
toencouragebias-freereasoningbyonlyselectingproper ferentdata(Section2.2).2
piecesrelatedtothenatureofthequestion. Forexample,
Figure1(b)demonstratesonepossiblewayofconducting
2.1.ABriefIntroductiontoCausality
bias-free reasoning by comparing the likelihood of two
situations occurring in real life and drawing on the more FortworandomvariablesX andY,X isacauseofY if
plausiblesituationtoinferthecoreferenceresolution. thereisachangeinthedistributionofY whenweapplyan
intervention on X while holding all other variables fixed
Werevealtheessentialroleofselectionmechanismsinthe
(Spirtesetal.,1993;Pearl,2009). Wecanrepresentcausal
interplay between LLM’s internal reasoning process and
relations among variables with a directed acyclic graph
differentstrategiesfordesigningtheexternalprompts. We
(DAG),wherenodesrepresentvariables,andedgesrepre-
firstconstructadetailedcausalmodelonthedatageneration
sentdirectcausalrelationsbetweenvariables. Wedenote
processofthetrainingcorpustoidentifywaysbiasesmay
thedirectcausalrelationbetweentheorderedpair(X,Y)
besmuggledinthepretrainingphase. Thenweconstructa
byadirectededgeX →Y.
causalmodeloftheLLM’spotentialreasoningprocessand
connectthetwocausalmodelsbyanalyzinghowdifferent Local causal modules in a DAG, which characterize the
input prompts could modulate the LLM’s output through causalrelationsbetweenthecorrespondingvariableandits
selectionmechanisms. Buildingupontheabovecausalun- directcauses,donotinterferewitheachotherbecauseof
derstandings,weintroduceacausality-guidedframework causalmodularity. Thispropertyisalsoknownastheexo-
todebiasLLMs,underpinnedbythetwointuitions: (1)dis- geneity(Engleetal.,1983),ortheindependenceofcausal
couragingbiasedreasoning and(2)encouragingbias-free mechanism(Petersetal.,2017),resultingdirectlyfromthe
reasoning. Currentprompting-baseddebiasingmethodscan causalMarkovconditionfortheDAG(Spirtesetal.,1993;
alsobeviewedasinstantiatingoneorbothoftheintuitions, Pearl, 2009).3 In the context of language processing, the
asillustratedinFigure2.
2WediscussrelatedworksindetailinAppendixA.
Usingthecausality-guideddebiasingframework,wepro- 3Thereareadditionalclassesofgraphsconsideredincausality
2SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
definitionofavariablerepresentingtextortokensisrela- population (Zhang et al., 2016). As another example, S
4
tivelyabstractcomparedtothestatisticalnotionofarandom can denote the selection mechanism of only considering
variableintabulardata. Withinthescopeofthiswork,we thehospitalin-patientdata. Thissignifiesthesettingofthe
usetheterms“variable”and“node”interchangeablywhen well-knownBerkson’sParadox(Berkson,1946),wheretwo
thecontextpermitsclearunderstandings. unrelateddiseases(X ,X )appeartobecorrelatedinthe
1 2
hospitaldata,simplybecausethedataonlycontainsselected
2.2.AMotivatingExampleofSelectionMechanisms patientswhohaveatleastonesymptomsin(Y 1,Y 2).
Ideally,wewouldlikesamplestobedrawnuniformlyfrom Figure 3 shows that the selection can be based solely on
theunderlyingpopulationofinterest. However,inpractice, the cause (e.g., S 1), solely on the effect (e.g., S 2), or on
itisverycommonthattheprobabilityofincludingcertain both (e.g., S 3). Meanwhile, the selection can be based
datapointsinthecorpusdependsonthecharacteristicsof on variables that are not causally related in the general
thedatapointsthemselves. population (e.g., S 4 and S 5). Selection mechanisms can
reshapedependencepatternsamonginvolvedvariables,and
Previousliteraturehasinvestigatedselectionmechanisms
asaconsequence,potentiallychangedownstreamoutputsas
from different perspectives, for instance, the influence of
well.WewillseeinSection3thatsuchpropertyofselection
selectionbiasonstatisticalinferenceineconomicandsoci-
alsoappliestonaturallanguageprocessing(NLP)contexts.
ologicalstudies(Heckman,1979;1990;Winship&Mare,
1992),causaldiscoverywhenthereareselectionvariables
and latent common causes (Spirtes et al., 1995; Zhang,
3.Causality-GuidedDebiasingFramework
2008),theidentificationandestimationoffunctionalcausal
modelswhenselectionexists(Zhangetal.,2016),theiden-
Weproposeourdebiasingframeworkguidedbycausalun-
tifiabilityofcausaleffectinthepresenceofselectionbias
derstandingsofinvolveddata-generatingprocesses. InSec-
from the graphical condition perspective (Bareinboim &
tion 3.1, we present detailed causal models of both the
Pearl,2012;Bareinboim&Tian,2015;Correaetal.,2019)
underlyingdata-generatingprocessforthetrainingcorpus
and from the potential outcome perspective (Herna´n &
andtheLLMs’reasoningprocess.WerevealthattheLLM’s
Robins, 2020), and the identification of the existence of
reasoning process is essentially an interplay between its
selectionbiasfromobservationaldataundercertainfunc-
internalrepresentationsandconditionsspecifiedbytheex-
tionalassumptions(Kaltenpoth&Vreeken,2023).
ternalpromptdesigns,inwhichselectionmechanismsplay
Let us consider an akeyrole.InSection3.2,weidentifydifferentsetsofcondi-
example in the context tionsforpromptdesigns,whichleadtopromptingstrategies
of medical care. As S<latexit sha1_base64="rzfU2ZhbihZ/KxqbP35ETub49Jc=">AAADdHicZVLNbhMxEHYTfspCaQtHOFhEkVCpdrM9tBWnokqIigNFadpK2SjyemcTq17vyvaSRKt9BK7wBjwIb8GLcGacbKWGjmTN5/nxzHyeuJDC2F7vz0ar/eDho8ebT7ynz7aeb+/svrg0eak5DHguc30dMwNSKBhYYSVcFxpYFku4im9Onf/qG2gjcnVhFwWMMjZRIhWcWTT1++NwvNPp+b2l0PsgbEDnZOt32f3o/Tof77aGUZLzMgNluWTGDMNeYUcV01ZwCbUXlQYKxm/YBIYIFcvAjKplrzXtoiWhaa7xKEuX1rsZFctMxux0nyJwIWaJzCKLMdl5zHoBmx6PKqGK0oLiq/fTUlKbUzcvTYQGbuUCAeNaYIuUT5lm3CIra4Xd2zbPpak9r0uZnOQYPs2oBsksJGtVHd1GlVkMGpJ9d0v2dSkhQRpuEw+Qim6XJoAkaaAMZ80yphIanSJA8pyX6cmSSDoTUtIYqCm1zkuVIEnxggZ71Pd9uhd4UR/s51mTWTW6rjCgrtCPpSjMWVZIoFNrC/M+CGazmZ/j50tgqY/FAwRaBW6aefDhtk3TuZjC+E7X42bIpuSZ+lLa6swRXDdqzYNn6Wq0t8ZpIdwXOmMCacS50LwTVlEi1KSKkD+YFzo8Ct91wsjRPK9rXMfw/+W7Dy4P/PDQP/yKe3lMVrJJXpE35C0JyRE5IZ/IORkQTibkO/lBfrb+tl+3O+3uKrS10eS8JGvS9v8BsoIeaw==</latexit> 1 S<latexit sha1_base64="NYus3Kx37p42NUAuqrFEvaX9SfY=">AAADdHicZVLNbhMxEHYTfspCaQtHOFhEkVCJdrM5tBWnokqIigNFadpK2SjyeieJVa93ZXtJotU+Ald4Ax6Et+BFODNOtlJDR7Lm8/x4Zj5PnEthbLf7Z6vRfPDw0ePtJ97TZzvPd/f2X1yarNAcBjyTmb6OmQEpFAyssBKucw0sjSVcxTenzn/1DbQRmbqwyxxGKZsqMRGcWTT1++PeeK/V9bsrofdBWIPWyc7vov3R+3U+3m8MoyTjRQrKcsmMGYbd3I5Kpq3gEiovKgzkjN+wKQwRKpaCGZWrXivaRktCJ5nGoyxdWe9mlCw1KbOzDkXgQswKmWUaY7LzmM0CdnI8KoXKCwuKr9+fFJLajLp5aSI0cCuXCBjXAlukfMY04xZZ2Sjs3rZZJk3leW3K5DTD8FlKNUhmIdmo6ug2qkhj0JB03C3p6EJCgjTcJvaQinabJoAkaaAMZ01TphIanSJA8pyX6emKSDoXUtIYqCm0zgqVIEnxkgYH1Pd9ehB4UR/s53mdWda6KjGgKtGPpSgsWJpLoDNrc/M+CObzuZ/h50tgEx+LBwi0Ctw0i+DDbZumdTGD8Z2ux/WQdckz9aWw5ZkjuKrVhgfPylVrb4PTXLgvdMYEJhHnQvNWWEaJUNMyQv5gkevwKHzXCiNH86KqcB3D/5fvPrjs+eGhf/gV9/KYrGWbvCJvyFsSkiNyQj6RczIgnEzJd/KD/Gz8bb5utprtdWhjq855STak6f8DtZAebA==</latexit> 2 S<latexit sha1_base64="UpsT9U7GoaarmYBGBUUpwVS853U=">AAADdHicZVLNbhMxEHYTfspCoYUjHCyiSKhUu9kitRWnokqIigNFadpK2Sjyeicbq17vyvaSRKt9BK7wBjwIb8GLcGacbKWGjmTN5/nxzHyeuJDC2F7vz0arfe/+g4ebj7zHT7aePtveeX5h8lJzGPBc5voqZgakUDCwwkq4KjSwLJZwGV+fOP/lN9BG5OrcLgoYZSxVYiI4s2jq98fvxtudnt9bCr0LwgZ0jrd+l92P3q+z8U5rGCU5LzNQlktmzDDsFXZUMW0Fl1B7UWmgYPyapTBEqFgGZlQte61pFy0JneQaj7J0ab2dUbHMZMxO9ygCF2KWyCyyGJOdx6wXsJOjUSVUUVpQfPX+pJTU5tTNSxOhgVu5QMC4Ftgi5VOmGbfIylph97bNc2lqz+tSJtMcw6cZ1SCZhWStqqPbqDKLQUOy527Jni4lJEjDTeI+UtHt0gSQJA2U4axZxlRCoxMESJ7zMp0uiaQzISWNgZpS67xUCZIUL2iwS33fp7uBF/XBfp41mVWj6woD6gr9WIrCnGWFBDq1tjDvg2A2m/k5fr4ENvGxeIBAq8BNMw8+3LRpOudTGN/qetwM2ZQ8VV9KW506gutGrXnwLF2N9tY4LYT7QmdMYBJxLjTvhFWUCJVWEfIH80KHh+HbThg5mud1jesY/r98d8HFvh8e+AdfcS+PyEo2yUvymrwhITkkx+QTOSMDwklKvpMf5Gfrb/tVu9PurkJbG03OC7Imbf8fuJ4ebQ==</latexit> 3 thatarenotonlyintuitivebutalsotheoreticallygrounded.
illustrated in Figure 3,
observed variables X<latexit sha1_base64="k9kEf5SjAww6rXIqeveOeoufnIA=">AAADdHicZVLNbhMxEHYTfspCaQtHOFhEkVCpdrM9tBWnokqIigNFbdpI2SjyemcTq17vyvaSRKt9BK7wBjwIb8GLcGacbKWGjmTN5/nxzHyeuJDC2F7vz0ar/eDho8ebT7ynz7aeb+/svrgyeak59Hkucz2ImQEpFPStsBIGhQaWxRKu45tT57/+BtqIXF3aRQGjjE2USAVnFk0Xg3E43un0/N5S6H0QNqBzsvW77H70fp2Pd1vDKMl5mYGyXDJjhmGvsKOKaSu4hNqLSgMF4zdsAkOEimVgRtWy15p20ZLQNNd4lKVL692MimUmY3a6TxG4ELNEZpHFmOw8Zr2ATY9HlVBFaUHx1ftpKanNqZuXJkIDt3KBgHEtsEXKp0wzbpGVtcLubZvn0tSe16VMTnIMn2ZUg2QWkrWqjm6jyiwGDcm+uyX7upSQIA23iQdIRbdLE0CSNFCGs2YZUwmNThEgec7L9GRJJJ0JKWkM1JRa56VKkKR4QYM96vs+3Qu86ALs51mTWTW6rjCgrtCPpSjMWVZIoFNrC/M+CGazmZ/j50tgqY/FAwRaBW6aefDhtk3TuZzC+E7X42bIpuSZ+lLa6swRXDdqzYNn6Wq0t8ZpIdwXOmMCacS50LwTVlEi1KSKkD+YFzo8Ct91wsjRPK9rXMfw/+W7D64O/PDQP/yKe3lMVrJJXpE35C0JyRE5IZ/IOekTTibkO/lBfrb+tl+3O+3uKrS10eS8JGvS9v8BwdIecA==</latexit> 1 Y<latexit sha1_base64="7XWNL1JLc/JqKJ+0FkKRzyBmD8w=">AAADdHicZVLNbhMxEHYTfspCoYUjHCyiSKhEu9ke2opTUSVExYGiNm1RNoq83kli1etd2V6SaLWPwBXegAfhLXgRzow3W6mhI1nzeX48M58nzqUwtt//s9Fq37v/4OHmI+/xk62nz7Z3nl+YrNAcBjyTmb6KmQEpFAyssBKucg0sjSVcxtfHzn/5DbQRmTq3yxxGKZsqMRGcWTSdfR2H4+1O3+/XQu+CsAGdo63fRfeD9+t0vNMaRknGixSU5ZIZMwz7uR2VTFvBJVReVBjIGb9mUxgiVCwFMyrrXivaRUtCJ5nGoyytrbczSpaalNlZjyJwIaZGZpnGmOw8Zr2AnRyOSqHywoLiq/cnhaQ2o25emggN3MolAsa1wBYpnzHNuEVW1gq7t22WSVN5XpcyOc0wfJZSDZJZSNaqOrqNKtIYNCQ9d0t6upCQIA03iXtIRbdLE0CSNFCGs6YpUwmNjhEgec7L9LQmks6FlDQGagqts0IlSFK8pMEu9X2f7gZedAb207zJLBtdlRhQlejHUhQWLM0l0Jm1uXkXBPP53M/w8yWwiY/FAwRaBW6aRfD+pk3TOZ/B+FbX42bIpuSJ+lzY8sQRXDVqzYOndjXaW+M0F+4LnTGBScS50LwTllEi1LSMkD9Y5Do8CN92wsjRvKgqXMfw/+W7Cy72/HDf3/+Ce3lIVrJJXpLX5A0JyQE5Ih/JKRkQTqbkO/lBfrb+tl+1O+3uKrS10eS8IGvS9v8BxOIecQ==</latexit> 1 S<latexit sha1_base64="q9VqirEPem27cfx9olseEwY+cow=">AAADdHicZVLNbhMxEHYTfspCoYUjHCyiSKhUu9kKtRWnokqIigNFadpK2Sjyeicbq17vyvaSRKt9BK7wBjwIb8GLcGacbKWGjmTN5/nxzHyeuJDC2F7vz0arfe/+g4ebj7zHT7aePtveeX5h8lJzGPBc5voqZgakUDCwwkq4KjSwLJZwGV+fOP/lN9BG5OrcLgoYZSxVYiI4s2jq98fvxtudnt9bCr0LwgZ0jrd+l92P3q+z8U5rGCU5LzNQlktmzDDsFXZUMW0Fl1B7UWmgYPyapTBEqFgGZlQte61pFy0JneQaj7J0ab2dUbHMZMxO9ygCF2KWyCyyGJOdx6wXsJOjUSVUUVpQfPX+pJTU5tTNSxOhgVu5QMC4Ftgi5VOmGbfIylph97bNc2lqz+tSJtMcw6cZ1SCZhWStqqPbqDKLQUOy527Jni4lJEjDTeI+UtHt0gSQJA2U4axZxlRCoxMESJ7zMp0uiaQzISWNgZpS67xUCZIUL2iwS33fp7uBF/XBfp41mVWj6woD6gr9WIrCnGWFBDq1tjDvg2A2m/k5fr4ENvGxeIBAq8BNMw8+3LRpOudTGN/qetwM2ZQ8VV9KW506gutGrXnwLF2N9tY4LYT7QmdMYBJxLjTvhFWUCJVWEfIH80KHh+HbThg5mud1jesY/r98d8HFvh8e+AdfcS+PyEo2yUvymrwhITkkx+QTOSMDwklKvpMf5Gfrb/tVu9PurkJbG03OC7Imbf8fu6webg==</latexit> 4 Y<latexit sha1_base64="uUkvybHEugwAiPaJG/xE/WQNWYk=">AAADdHicZVLNbhMxEHYTfspCoYUjHCyiSKhUu9kc2opTUSVExYGiNm1RNoq83snGqte7sr0k0WofgSu8AQ/CW/AinBknW6mhI1nzeX48M58nLqQwttf7s9Fq37v/4OHmI+/xk62nz7Z3nl+YvNQcBjyXub6KmQEpFAyssBKuCg0siyVcxtfHzn/5DbQRuTq3iwJGGUuVmAjOLJrOvo774+1Oz+8thd4FYQM6R1u/y+4H79fpeKc1jJKclxkoyyUzZhj2CjuqmLaCS6i9qDRQMH7NUhgiVCwDM6qWvda0i5aETnKNR1m6tN7OqFhmMmanexSBCzFLZBZZjMnOY9YL2MnhqBKqKC0ovnp/Ukpqc+rmpYnQwK1cIGBcC2yR8inTjFtkZa2we9vmuTS153Upk2mO4dOMapDMQrJW1dFtVJnFoCHZc7dkT5cSEqThJrGPVHS7NAEkSQNlOGuWMZXQ6BgBkue8TKdLIulMSEljoKbUOi9VgiTFCxrsUt/36W7gRWdgP82azKrRdYUBdYV+LEVhzrJCAp1aW5h3QTCbzfwcP18Cm/hYPECgVeCmmQfvb9o0nfMpjG91PW6GbEqeqM+lrU4cwXWj1jx4lq5Ge2ucFsJ9oTMmMIk4F5p3wipKhEqrCPmDeaHDg/BtJ4wczfO6xnUM/1++u+Ci74f7/v4X3MtDspJN8pK8Jm9ISA7IEflITsmAcJKS7+QH+dn6237V7rS7q9DWRpPzgqxJ2/8Hx/Aecg==</latexit> 2 X<latexit sha1_base64="Q9dX2PS0G6nRedjrrQKMI1C7EqI=">AAADdHicZVLNbhMxEHYTfspCaQtHOFhEkVCJdrM5tBWnokqIigNFbdpI2SjyeieJVa93ZXtJotU+Ald4Ax6Et+BFODNOtlJDR7Lm8/x4Zj5PnEthbLf7Z6vRfPDw0ePtJ97TZzvPd/f2X1yZrNAc+jyTmR7EzIAUCvpWWAmDXANLYwnX8c2p819/A21Epi7tModRyqZKTARnFk0Xg3FvvNfq+t2V0PsgrEHrZOd30f7o/Tof7zeGUZLxIgVluWTGDMNubkcl01ZwCZUXFQZyxm/YFIYIFUvBjMpVrxVtoyWhk0zjUZaurHczSpaalNlZhyJwIWaFzDKNMdl5zGYBOzkelULlhQXF1+9PCkltRt28NBEauJVLBIxrgS1SPmOacYusbBR2b9ssk6byvDZlcpph+CylGiSzkGxUdXQbVaQxaEg67pZ0dCEhQRpuE3tIRbtNE0CSNFCGs6YpUwmNThEgec7L9HRFJJ0LKWkM1BRaZ4VKkKR4SYMD6vs+PQi86ALs53mdWda6KjGgKtGPpSgsWJpLoDNrc/M+CObzuZ/h50tgEx+LBwi0Ctw0i+DDbZumdTmD8Z2ux/WQdckz9aWw5ZkjuKrVhgfPylVrb4PTXLgvdMYEJhHnQvNWWEaJUNMyQv5gkevwKHzXCiNH86KqcB3D/5fvPrjq+eGhf/gV9/KYrGWbvCJvyFsSkiNyQj6Rc9InnEzJd/KD/Gz8bb5utprtdWhjq855STak6f8DxOAecQ==</latexit> 2 3.1.DetailedCausalModelingofProcesses
S<latexit sha1_base64="/YLSc1z8ZJf8gfGRWLUaFdDMZZY=">AAADdHicZVLNbhMxEHYTfspCoYUjHCyiSKhUu9lKtBWnokqIigNFadpK2Sjyeicbq17vyvaSRKt9BK7wBjwIb8GLcGacbKWGjmTN5/nxzHyeuJDC2F7vz0arfe/+g4ebj7zHT7aePtveeX5h8lJzGPBc5voqZgakUDCwwkq4KjSwLJZwGV+fOP/lN9BG5OrcLgoYZSxVYiI4s2jq98fvxtudnt9bCr0LwgZ0jrd+l92P3q+z8U5rGCU5LzNQlktmzDDsFXZUMW0Fl1B7UWmgYPyapTBEqFgGZlQte61pFy0JneQaj7J0ab2dUbHMZMxO9ygCF2KWyCyyGJOdx6wXsJOjUSVUUVpQfPX+pJTU5tTNSxOhgVu5QMC4Ftgi5VOmGbfIylph97bNc2lqz+tSJtMcw6cZ1SCZhWStqqPbqDKLQUOy527Jni4lJEjDTeI+UtHt0gSQJA2U4axZxlRCoxMESJ7zMp0uiaQzISWNgZpS67xUCZIUL2iwS33fp7uBF/XBfp41mVWj6woD6gr9WIrCnGWFBDq1tjDvg2A2m/k5fr4ENvGxeIBAq8BNMw8+3LRpOudTGN/qetwM2ZQ8VV9KW506gutGrXnwLF2N9tY4LYT7QmdMYBJxLjTvhFWUCJVWEfIH80KHh+HbThg5mud1jesY/r98d8HFvh8e+AdfcS+PyEo2yUvymrwhITkkx+QTOSMDwklKvpMf5Gfrb/tVu9PurkJbG03OC7Imbf8fvroebw==</latexit>
(X ,X ) denote dis- 5
1 2 We present the causal modeling of the underlying data-
eases, and (Y ,Y )
1 2 Figure3: Anillustrativeexam- generatingprocessofthetrainingdatacorpus(Section3.1.1)
denote corresponding
pleofselectionmechanisms. andthereasoningprocessofLLMs(Section3.1.2).
symptoms. Apart from
them, there exist potential binary selection variables S ’s
i 3.1.1.UNDERLYINGDATAGENERATINGPROCESSOF
(i ∈ {1,2,...,5}), whereS = 1denotesbeingselected.
i TEXTINTRAININGDATACORPUS
X (X )isthedirectandonlycauseofY (Y ),andthetwo
1 2 1 2
diseasesareunrelatedinthegeneralpopulation,i.e.,when Thetrainingdatacorpusoftenreflectshistoricaldiscrimi-
none of the S ’s exists. We use solid edges to represent nation,andselectionmechanismsarecommonlyinvolved.
i
causalrelationsamongobservedvariablesanddashededges For instance, gender stereotype in occupations arises not
forthosepertainingtoselectionmechanisms. duetotheexistenceofadirectcausalrelationoracommon
causebetweengenderandoccupation,butduetoanunder-
Forinstance,S isanexampleofoutcome-dependentselec-
2 lyingselectionmechanism. Specifically,inthetrainingdata,
tion(Zhangetal.,2016),whichcanbeselectingindividuals
amongallpossiblecombinationsbetweengender(e.g.,male
withsymptomY fromthegeneralpopulation. Thecondi-
1 andfemale)andoccupation(e.g.,CEOandsecretary),there
tionalprobabilityP(Y |X ,S =1)intheselecteddata
1 1 2 isatendencytoassociateCEOmoreoftenwithmale,and
typicallydiffersfromitscounterpartP(Y |X )ingeneral
1 1 secretary with female. This phenomenon occurs because
literature, forexample, directedcyclicgraphs(DCGs)(Spirtes, thetrainingdataisasubsetselectedfromanimaginarydata
1995),ancestralgraphs(Richardson&Spirtes,2002),andsoon. corpusthatisideallydiverseandcomprehensive.
Inthispaper,weconsidercausalprocessesthatcanbemodeledby
aDAG.Othergraphclassesarebeyondthescopeofourwork. Moregenerally, inFigure4(a)wemodelcausalrelations
3SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
demographic demographic- demographic demographic-aware text demographic 1 demographic-aware text
information aware text representation S representation representation vi S representation
vii iv
S entity i entity 3
demographic- representation demographic-agnostic fact representation 2 demographic-agnostic fact
agnostic fact scenario representation ii scenario representation
iii
entity representation representation v 4 5
derivational text prompt properly LLM prompt properly LLM
scenario based on fact prompt considered potential output prompt considered potential output
(a)Trainingdatacorpus (b)LLMreasoningprocessgivenprompt (c)LLMreasoningprocess(annotatedcopy)
Figure4: Causalgraphswithrespecttodifferentdata-generatingprocesses.Panel(a)presentstheunderlyingdata-generatingprocess
ofthetrainingdatacorpus.Panels(b)–(c)presentthereasoningprocessoftheLLM.Sincetheconditionsspecifiedbythe
promptarealwaysconditioneduponwhenLLMgeneratestheoutput,theinternalreasoningismodulatedbytheexternal
prompt.Inpanel(c)weincludeannotationstohighlightcausalpathwaysalongwhichtheinformationflowfromdemographic
representationtoLLMpotentialoutputisnotregulated.
intheunderlyingdata-generatingprocessoftrainingdata InFigure4(b),weusedottedcontourstodistinguishLLMs’
corpus(e.g.,textscrapedfromtheinternet). Otherthande- internalrepresentationsfromtheactualexternalinformation
mographicinformation(e.g.,race,gender,age),thecausal inthedatacorpus,e.g.,thecontrastbetween“demographic
graphcontainsadditionalvariablesofinterest. Weuse“sce- representation”inFigure4(b)and“demographicinforma-
nario”torepresentthepracticalsituationorcontextthatsets tion”inFigure4(a). Noticethattheinternalnodesarenot
thebackgroundofthetext(e.g.,medicalcare,hiring). We directly observable or accessible. We use double-stroke
use“entity”todenoteparticipantsorstakeholdersinvolved contourstoindicateselectionmechanisms,directededges
inthescenario,forinstance,apatientmaybeanentityin torepresentdirectcausalrelations,anddashededgeswith
themedicalcarescenarioandasecretarymaybeanentity hollowarrowheadstodenoteselectionmechanisms.
inthehiringscenario. TheselectionvariableS explicitly
A“prompt”servesasanexternalinputtoLLMsbutnotasa
modelstheassociationbetweendemographicinformation
directcauseofinternalrepresentations. Thisisbecausethe
andentity,whichisrecognizedasamajortypeofstereotype
internal knowledge and representations exist beforehand,
inNLP(Sweeney,2013;Bolukbasietal.,2016;Zhaoetal.,
makingthemirrelevanttowhetheraspecificpromptispro-
2018; Tamkin et al., 2023). There are different types of
vided. The prompt also does not act as an indicator for
textsinFigure4(a). “Demographic-agnosticfact”denotes
causalinterventions. Becauseinternalnodesarenotdirectly
thetextthatdoesnotexplicitlycontaindemographicinfor-
observableoraccessible,onecannotsetthemtocertainval-
mation. “Derivationaltextbasedonfact”denotesthetext
uesviahardinterventions(Spirtesetal.,1993;Pearl,2009;
derived from fact, e.g., inference according to definition,
Petersetal.,2017;Herna´n&Robins,2020),orchangethe
fact-checkQ&A,andrestatementwithoutalteringfactual
functionalbehaviorofcausalmodulesviasoftinterventions
contents. “Demographic-awaretext”denotesthetextwhere
(Eberhardt&Scheines,2007;Huangetal.,2020;Correa&
demographicinformationappearsexplicitly.
Bareinboim,2020). However,thepromptdirectlychanges
theselectionvariable“promptproperlyconsidered”(PPC)
3.1.2.REASONINGPROCESSOFLLMS
throughitsdesigns. IftheLLMmodeliswell-trainedand
Section3.1.1introducescausalmodelingoftheunderlying well-aligned,wecanexpectthatPPCisalwaysconditioned
data-generatingprocesstocharacterizehowdiscrimination uponwhenthemodelproducestheoutput,andthe“LLM
isinstantiatedinLLMs’trainingdatacorpus. Thegoaland potentialoutput”willbecometheactualoutputweobtain
expectation of the training is for LLM models to capture from the model. Just like the motivating example where
dependencepatternsinthedatacorpus,andtoextractand selectioncanreshapedependencepatternsamonginvolved
internalize the relatedknowledge. Therefore, we assume variables(Section2.2),thepromptcaninfluencetheLLM
that the internal reasoning process of LLMs shares simi- reasoningprocessinsignificantwaysbyspecifyingcondi-
laritieswiththeunderlyingdata-generatingprocessofdata tionsinselectionmechanisms.
corpus. Underthismildassumption,weformulatetherea-
soning process of how LLMs generate outputs based on 3.1.3.AREMARKONTHEMODELEDPROCESSES
inputpromptsinFigure4(b). Inparticular, werevealthe
Figure4(a)andFigure4(b)eachhavetheirgeneratingpro-
interplaybetweeninternalrepresentationsandconditions
cessofinterestanddistinctemphases. Althoughnotpertain-
specified by external inputs, and more importantly, how
ingtoLLMreasoningitself,theunderlyinggeneratingpro-
LLMoutputsareshapedandmodulatedbydifferentprompt
cessmodeledinFigure4(a)provideshintsonlocalcausal
designsthroughselectionmechanisms.
modulesofinterestthatpromptdesignscanspecificallyat-
4SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
tend to for debiasing purposes. When we consider these i and v inFigure4(c).
hintswithreferencetotheLLMreasoningprocessmodeled
An example prompt employing Strategy I can be: “Con-
inFigure4(b),wecanidentifydebiasingstrategiesthatare
sideringthefactthatthesentence‘Thephysicianhiredthe
bothintuitiveandtheoreticallygrounded,aswewillseein
secretarybecausethesecretaryishighlyrecommended’is
moredetailinSection3.2. Thetwodetailedcausalmodels
practically more viable than the sentence ‘The physician
complementeachother,bothofwhichareessentialforun-
hiredthesecretarybecausethephysicianishighlyrecom-
derstandingthesourceofbias,andfurthermore,effectively
mended’,whodoes‘he’refertoin‘Thephysicianhiredthe
debiasingLLMs.
secretarybecauseheishighlyrecommended’?”
Strategy II (Counteract Existing Selection Bias). The
3.2.DebiasingGuidedbyCausalUnderstandings
intuition behind this strategy is to directly counteract the
Wepresentourprompt-based LLMdebiasingframework effectofexistinghistoricaldiscriminations:
guided by causal understandings of the related data-
ConditionII.1 The internal representations for demo-
generating processes. Our core idea is to formulate con-
graphic information and entity should be
ditionsthatshouldbespecifiedinthepromptdesign,such
conditionallyindependentinthepresenceof
thatthroughtheinfluenceofselectionmechanismsinthe
PPCandexistingselectionS,i.e.,
LLMreasoningprocess, onecaneffectivelydebiasLLM
outputs.
demographic entity
⊥⊥ |S =1,PPC=1. (2)
representation representation
Figure4(c)presentsanannotatedversionoftheLLMrea-
soningprocess(Section3.1.2). Basedontheunderstanding ConditionII.2 Nonewassociationbetweeninternalrepre-
oftheunderlyinggeneratingprocessoftrainingdatacorpus, sentationsofdemographicinformationand
andthemildassumptionthatthetrainedLLMcapturesthe demographic-agnosticfactisintroduced,
dependencepatternsintrainingdata,wehighlightcertain
edgesinlightcoral(accompaniedbyannotationsmarked rd ee pm reo seg nra tap th ioic
n
⊥⊥de fm aco tg rr ea pp rh ei sc e- na tg an tio os ntic | e rn et pit ry .,sc re en pa rr .io, PS PC= =1, 1. (3)
withcircledrednumerals)inFigure4(c)todenoteunregu-
InStrategyII,ConditionII.1andConditionII.2servedif-
latedinformationflowfromdemographicrepresentationsto
ferentpurposes. ConditionII.1aimstocounteractexisting
LLMoutputsintheinternalreasoningprocess. Weusecir-
biasinstantiatedbyselectionS (edges vi and vii)bycon-
cledblueRomannumeralstodenoteselectionmechanisms
strainingmarginaldependencebetweenrepresentationsfor
thatcanbespecifiedbytheexternalinputprompt(Section
demographicinformationandentity(edges i and ii).
3.1.2),andcircledredRomannumeralstorepresentthose
correspondingtohistoricaldiscrimination(Section3.1.1). ConditionII.2actsasasafeguard,makingsurenonewbias
isintroducedinthecausaldownstreamoftheentitysothat
AccordingtotheLLMreasoningprocesspresentedinFig-
the above counteraction effectively proceeds to the final
ure 4(c), we consider the information flows from the de-
output.
mographicrepresentation(upstreamnode)totheLLMpo-
tential output (downstream node). We present additional An example prompt employing Strategy II can be: “The
conditionsandconstraintsthepromptdesignsshouldspec- physiciancanbeeithermaleorfemale, andthesecretary
ifyfordebiasingpurposes. Toclearlypresenttheintuitions canalsobeeithermaleorfemale. Whodoes‘he’referto
andtheoreticalgroundingsofourcausality-guidedframe- in‘Thephysicianhiredthesecretarybecauseheishighly
work,weidentifythreepromptingstrategiesfordebiasing recommended’?”
LLMs,eachofwhichservesasasolidstartingpoint.
StrategyIII(NudgeAwayfromDemographic-AwareText).
StrategyI(NudgeTowardsDemographic-AgnosticFact). TheintuitionbehindthisstrategyistonudgeLLMsaway
The intuition behind is to nudge LLMs towards utilizing fromutilizingdemographic-awaretexttogenerateoutputs:
demographic-agnosticfactwhengeneratingtheoutput:
ConditionIII Theinternalrepresentationsfordemographic-
ConditionI Theinternalrepresentationsfordemographic- aware text and demographic information
agnostic fact and demographic information should be conditionally independent in the
should be conditionally independent in the presenceofPPCandexistingselectionS,
presenceofPPCandexistingselectionS,i.e.,
demographic demographic-aware
⊥⊥ |S =1,PPC=1. (4)
demographic demographic-agnostic representation textrepresentation
⊥⊥ |S =1,PPC=1. (1)
representation factrepresentation
Strategy III utilizes Condition III to specify the selection
Strategy I introduces Condition I to specify the selection mechanism over internal representations of demographic
mechanismoverinternalrepresentationsofdemographicin- informationanddemographic-awaretext(edges i and iv)
formationanddemographic-agnosticfact,denotedbyedges toregulatetheinformationflowalongtheedge 1.
5SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
AnexamplepromptemployingStrategyIIIcanbe: “Donot lel but differ in gender pronouns. It contains two sets of
usegenderinformationtoanswerthequestion. Whodoes sentences: prosentenceswiththepro-stereotypicalgender
‘he’refertoin‘Thephysicianhiredthesecretarybecause pronouns(e.g.,nursesasshe,engineersashe),andantisen-
heishighlyrecommended’?” tenceswithanti-stereotypicalgenderpronouns(e.g.,nurses
ashe,engineersasshe). Thedatasetalsohastwotypesof
RemarksonThreeStrategies taskswithdifferentlevelsofdifficulties: coreferencedeci-
sionsinTypeItaskarechallengingandmustbemadeusing
Thethreestrategiesoffercertaineffectivenessindividually
worldknowledgeaboutgivencircumstances,whereasType
butarenotperfectontheirown.4 WhileStrategyInudges
IItaskcanberesolvedusingonlysyntacticinformation.
LLMstowardsutilizingdemographic-agnosticfacts,itdoes
notexplicitlypreventLLMsfromusingdemographic-aware
4.1.1.EXPERIMENTALSETTINGS(WINOBIAS)
textrepresentationstogeneratetheoutput,andthedemo-
graphic information can potentially be associated to the ForeachsentenceinWinoBias,wedefinetheoriginal
outputthroughanunregulatedpathcontainingedges 1 and questiontobe“Whodoes[genderpronoun]refertoin
5. Similarly,whileStrategyIIaimstoregulateinformation the sentence ‘[original sentence]’?”, and we measure the
flowsalongedges{2, 3, 4, vi, vii},thereisnoexplicit performanceoffourlargelanguagemodels: GPT-3,GPT-
constraintinvolvingedges 1 and 5,whichleavesspace 3.5, GPT-4, and Claude 2) across the above two types of
forbiastosneakinduringthereasoningprocess. coreferencetasks(TypeIandTypeII).
Compared to Strategy I that pushes LLMs to focus on
BaselineApproaches
demographic-agnostic facts, Strategy III prevents LLMs
Thereareafewexistingworksemployingpromptingtech-
fromreferringtodemographic-awaretextduringreasoning.
niques to mitigate the bias in LLMs. We consider these
Whileedge 1 isexplicitlyregulatedbytheselectionmech-
threebaselines:
anismspecifiedbyConditionIII,theinformationflowalong
edge 5 can still result in the association between demo-
graphicinformationandtheoutput. ThisisbecauseStrat- • Default: asks the original question directly
egyIIIdoesnotinvolveconditionsorconstraintsoverthede- withoutanyadditionalprompts.
pendencepatternsamongvariablesincludingdemographic • ICL with contrastive examples: pro-
information and demographic-agnostic fact. As we can vides contrastive examples followed by original
seefromtheconditionsspecifiedinStrategyII,noexplicit question (Figure 2 middle). The examples are
appearanceofdemographicinformationinademographic- considered to be contrastive as the answer remains
agnosticfactdoesnotguaranteethenon-existenceofdepen- unchangedwithdifferentpronouns. InWinoBias,weuse
dencebetweenthetwo.Wewouldliketonotethatdebiasing thesame16ICLexamplesasinSietal.(2022).
isbetterrealizedwhenthestrategiesarecombinedasthey • Zero-shot COT (Kojima et al., 2022): asks the
canaddresssocialbiasinLLMsmorecomprehensively.
modeltoalso“thinkstepbystep”aftertheoriginal
question. Shaikhetal.(2022);Gangulietal.(2023)
designsimilarCOTapproachestomitigatebiasinLLMs.
4.ResultsandAnalyses
In this section, we demonstrate how the two types of ap- EvaluationMetrics
proaches, i.e., (1) encouraging bias-free reasoning (Strat- We measure the performances of LLMs on pro and anti
egyI),and(2)discouragingbiasedreasoning(StrategyII sentencesintermsofaccuracy,andthegapbetweenthetwo
andStrategyIII),effectivelysteerLLMstowardsunbiased indicatesthelevelofgenderbiasexhibitedbythemodels(a
responseonvariousaspectsofsocialbias(e.g.,gender,race, smallergapisbetter).
andage). Wepresentourexperimentalsettingsandresults
ontheWinoBiasdataset(Zhaoetal.,2018)inSection4.1, OurMethod: Reduce+Fact
andtheseontheDiscrim-Evaldataset(Tamkinetal.,2023) WeproposeReduce + Factasonewayofencouraging
inSection4.2.
bias-free reasoning collectively with discouraging biased
reasoning. AsshowninFigure2rightpanel,wefirstcreate
4.1.GenderBias: WinoBias twogender-agnosticsentencesbyreplacingthegenderpro-
nounwiththetwooccupationsthatappearedintheoriginal
The WinoBias data set (Zhao et al., 2018) evaluates how
sentence.Thenweaskthemodelafactual question:
likelymodelswillassignstereotypicalgenderpronounsto
whichsentenceismorelikelytohappeninreallife,asthis
occupations under coreference resolution tasks. The sen-
questiondoesnotcontainanygender-relatedinformation.
tences in WinoBias are designed to be structurally paral-
Wethenprependitsanswer(tothefactual question)
4WeprovideadditionalillustrationsinAppendixB. before asking the original question. This allows
6SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Table1: PerformancecomparisonofvariousdebiasingmethodsonWinoBias. Weshowthatcombiningencouragingbias-free
reasoninganddiscouragingbiasedreasoningtogether(Reduce + Fact)significantlyalleviatesthegenderbiasforbothcoreference
tasks:TypeIcoreferenceresolutionrequiresworldknowledge,andTypeIIcoreferenceresolutioncanberesolvedusingonlysyntactic
information.Prointhetablestandsforcoreferencewithpro-stereotypicalpronouns,andAntistandsforcoreferencewithanti-stereotypical
pronouns.Asmallergapindicateslessbias.
GPT3 GPT3.5 Claude2 GPT4
Accuracy(%)
Anti Pro Gap Anti Pro Gap Anti Pro Gap Anti Pro Gap
↓ ↓ ↓ ↓
TypeI
Default 43.01 79.24 36.23 62.96 94.03 31.07 67.57 92.13 24.56 82.50 97.96 15.47
COT (zero shot) 41.79 75.85 34.06 62.14 90.64 28.49 70.56 91.59 21.03 84.40 95.66 11.26
ICL 46.81 94.57 47.76 45.18 92.81 47.63 73.68 92.27 18.59 88.87 98.10 9.23
Reduce + Fact 73.27 73.95 0.68 72.73 84.67 11.94 74.08 75.17 1.09 94.57 96.74 2.17
TypeII
Default 85.01 97.97 12.96 94.28 98.98 4.70 93.77 97.46 3.68 97.59 99.49 1.91
COT (zero shot) 69.12 86.79 17.66 93.90 98.35 4.45 95.30 99.62 4.32 97.97 99.62 1.65
ICL 94.41 99.62 5.21 95.43 98.98 3.56 94.03 97.84 3.81 98.35 99.87 1.52
Reduce + Fact 83.23 84.24 1.02 92.12 94.41 2.29 82.34 85.26 2.92 99.62 99.75 0.13
us to distill LLM’s non-gender-related world knowledge 3.5),itcanfurtherreducebiaseswithmorecapableLLMs
(StrategyIII)andnudgeittoexplicitlyreasonwiththisfact (Claude2andGPT-4),especiallyforGPT-4(withagapof
during coreference resolution (Strategy I). On top of en- 9.23%).
couragingbias-freereasoning(StrategiesIandIII),wealso
Remarkably, Reduce + Fact, which encourages bias-
promptthatbothoccupationsareequallylikelytobemale
free reasoning while discouraging biased reasoning, sub-
orfemaletocounteractexistingselectionbias(StrategyII),
stantiallydecreasesthebiasacrossallLLMs. Theachieved
discouragingbiasedreasoning.
minimal gaps, with GPT-4 exhibiting a mere 2.17% gap
One caveat of utilizing LLM’s world knowledge is that and94.57%accuracyonantisentences,demonstratesignif-
theperformanceofReduce + Factwillincreaseasthe icantlygreatereffectivenesscomparedtootherapproaches.
capabilities of the LLM grow, since better world knowl-
edge will further help LLM answer both factual and
CoreferenceResolutionOnlywithSyntacticInformation
originalquestions.
4.1.2.OURRESULTS(WINOBIAS) For Type II tasks, coreference can be resolved only with
syntacticcues. Allmodelsgenerallyshowhigheraccuracies
WecompareReduce + Factwiththethreebaselineap-
withsmallergaps. However,sincethereexistsashortcutin
proachesonbothcoreferencetasksandsummarizeourre- theTypeIItask–thecorrectanswerisalwaysthesecond
sultsinTable1. WeexpectallLLMstoachievehigheraccu- entityinthesentence–asmallergapmaynotnecessarily
raciesonsentencescontainingpro-stereotypicalpronouns indicate less bias. Still, Reduce + Fact outperforms
(prosentences)comparedtothesewithanti-stereotypical
the three baselines, particularly with GPT-4, achieving a
pronouns (anti sentences) due to historical biases in the near-negligiblegapof0.13%,suggestingthatourmethod
trainingdata. is highly effective in encouraging models to utilize non-
genderedcuesforcoreferenceresolution.
CoreferenceResolutionRequiringWorldKnowledge
Summary
ForTypeItasks,worldknowledgeisrequiredtoperform
coreference resolution. The Default prompting shows Theseexperimentalresultssuggestpromptdesignsthaten-
significant biases, with large gaps in accuracy between couragebias-freereasoninganddiscouragebiasedreason-
pro sentences and anti sentences for all models. The ing are effective at mitigating gender biases in LLMs by
method Zero-shot COT marginally reduces the bias, directing them to rely more on non-gender-related world
as seen in the smaller gaps, but its performance is lower knowledge(StrategiesIandIII)andlessongendershortcuts
on both pro and anti scenarios for GPT-3 and GPT-3.5 (StrategyII),thuspromotingfairerandlessbiasedresponses.
when compared with Default, and it only marginally Also,theperformancegapbetweenprosentencesandanti
improves the general performance when applied to more sentences decreases as the LLMs become more capable,
capable ones (Claude 2 and GPT-4). For ICL with whichmayindicatethatLLMsarelesspronetoassignoccu-
counterfactual examples, although the gap be- pationswithstereotypicalgenderpronounsastheirgeneral
comes larger for less capable models (GPT-3 and GPT- (reasoning)capabilitiesgrow.
7SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Figure5: PerformancecomparisononDiscrim-Evalacrossthreedemographics.Thebardenotesthedegreeofdiscriminationby
comparingtheleastprivilegedgroupwiththemostprivilegedgroupinagivendemographiccategory(thehigherthebar,thedeeper
thediscrimination). Differentmethods(promptdesigns)arecoloreddifferently(lightercolorsdenotetheonesthatamplifybias-free
reasoning).Encouragingbias-freereasoninguniversallydecreasestherelativegapwhenaddedwithmethodsthatreducebiasedreasoning.
4.1.3.ABLATIONSTUDIES Table 2: Error Analysis on WinoBias Type I corefer-
ence task. We divide the models’ responses into 4 cate-
Wefurtherconductablationstudiestoindividuallyexam- gories to better understand the cause of their errors and suc-
ine the effectiveness of the two types of approaches, i.e., cess. FF denotes the (%) of examples where both ques-
tions are answered incorrectly, indicating the coreference
encouraging bias-free reasoning and discouraging biased
reasoning. WedividethepromptReduce + Factinto errorscausedbythemodel’sworldknowledge.TFdenotesthe
two parts: the Reduce Only part prompting both men coreferenceerrorscausedby genderbias asonlyfactualques-
andwomencanperformeitheroccupationequally,andthe tionsarecorrectlyanswered,andFTindicatescoreferencesuccess
Fact Only part telling the model which sentence(s) it thatmaybedueto gendershortcut sincethefactualquestions
regardstobemoreviableinreallife. getwrongbutoriginalquestionsarecorrectlyanswered.
Moreover, we categorize each LLM’s response into four
TT TF FT FF
groups:(i)TT:wheretheLLManswersboththefactual Accuracy(%)
Anti Pro Anti Pro Anti Pro Anti Pro
question and the original question correctly, GPT-3.5
(ii) TF: where the LLM only answers the factual Reduce + Fact 70.15 78.70 10.58 2.04 2.58 5.97 16.55 13.16
Fact Only 61.87 79.24 18.86 1.63 2.31 7.46 16.96 11.67
question correctly, (iii) FT: where the LLM only an- Reduce Only 42.33 66.49 32.02 7.60 8.68 13.30 8.82 4.07
swerstheoriginal questioncorrectly,and(iv)FF: Default 40.57 75.44 39.76 5.16 7.46 15.88 11.67 3.26
GPT-4
wheretheLLManswerswronglyonbothquestions. Reduce + Fact 94.44 96.07 1.76 0.27 0.14 0.68 3.66 2.99
Fact Only 91.45 95.93 5.29 0.14 0.54 0.81 2.71 3.12
Theabovecategorizationallowsustoattributethemodel’s Reduce Only 70.69 88.20 25.78 8.28 0.95 1.76 2.58 1.76
Default 69.47 87.25 26.87 8.68 1.36 2.44 2.31 1.63
coreference mistakes into two categories: the mistake
caused by its non-gender-related world knowledge (FF),
andthemistakescausedbyitsgenderbias(TF).Moreover,
wecanhaveabetterunderstandingofthemodel’scorrect- steerLLMsawayfrombiasedreasoning.
nessaswellbylookingatFT,wherethecorrectnessmay
beduetopotentiallybiasedshortcuts.
4.2.DemographicBias: Discrim-Eval
AsshowninTable2,whenweseparatethepromptingstrate-
The Discrim-Eval data set (Tamkin et al., 2023) encom-
gies into Fact Only and Reduce Only, we observe
passesacollectionofscenarios,eachdepictingahypothet-
that Fact Only still performs quite well, but Reduce
ical case where a decision is required, such as approving
Onlyleadstoasignificantdecreaseinperformance. This
aloanorissuingpresscredentials. Thetaskistomakea
suggeststhatwhilediscouragingbiasedreasoningisimpor-
Yes-or-Nobinarydecision(affirmativeornegative)onthe
tant,providingexplicitinstructionsthatpromotebias-free
individualinvolvedineachscenario. Theindividualscan
reasoningiscrucialformitigatingbiasinLLMs.
becharacterizedbythreedemographicfactors: age(within
Moreover,comparingtheperformanceofGPT-4withGPT- a range of 20 to 100, in 10-year intervals), gender (male,
3.5,wecanseethattheGPT-4’simprovementsmostlystem female,ornon-binary),andrace(White,Black,Asian,His-
frombetter(non-gender-related)worldknowledge(making panic,orNativeAmerican).
way less mistakes on factual questions) and self-
consistency(lessmistakesintheTFgroup). 4.2.1.EXPERIMENTALSETTINGS(DISCRIM-EVAL)
MoreexperimentalresultscanbefoundinAppendixD.1, ThescenariosintheDiscrim-Evaldatasetaredesignedsuch
wherewedesignpromptstocontrolthedegreetowhichwe thatanaffirmativedecision(Yes)isalwaysfavorable. The
biasismeasuredusingtheprobabilityoftheYesdecision
8SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
groupswithineachdemographiccategory,characterizing
the relative extent of discrimination. The bars are color-
codedaccordingtothemethodsused,wherelightershades
correspondtothemethodsthatexplicitlyencouragebias-
freereasoning(e.g. purplebarsdenoteIllegalandlight
purplebarsdenoteIllegal + Fact).Default(black
bar) denotes the prompt in the original scenario
(withdemographicinformation),withoutanymodifications.
Figure6: GPThasaninherentbiastowardsaging. GPT-
Whiledifferentpromptsofdiscouragingbiasedreasoning
3’sdefaultresponse(black)ismorebiasedasageincreases.
show various degrees of effectiveness in reducing demo-
graphicbias,nosinglepromptstandsoutastheuniversally
mosteffectiveoptionacrossallLLMsanddemographiccat-
acrossasetofdemographicvariables(Tamkinetal.,2023).
egories. However,encouragingbias-freereasoning(Fact)
collectively with discouraging biased reasoning can fur-
EvaluationMetrics
therdecreasetherelativegap,comparedtoemployingthe
Forourevaluationofdemographicbias,weusearelative approachesontheiralone. Thisobservationisconsistent
gaptomeasuretheadverseimpactofdifferentdemographic across4LLMsand3demographiccategories.
variables(Hort&Sarro,2022;Pessach&Shmueli,2021).
Itisalsonoteworthythatnoneoftheapproachesachieves
To be more specific, given a bias category that we want
azerogap. Thisindicatesthatwhilethedebiasingprompt
toevaluate(e.g.,ethnicity),weobtaintheprobabilitiesof
designscanreducethediscriminationinLLMoutputs,they
the‘Yes’tokenforallfivedifferentraces,andwemeasure
donotcompletelyeliminateit.
the gap between the largest probability and the smallest
probabilityanddividethegapbythelargestone. Thisway
allowsustounderstandhowsubstantialthediscrimination
iswhencomparingthemostprivilegedgroupwiththeleast
privilegedwithinthegivenbiascategory.
AdverseImpactonSpecificDemographicGroups
BaselineApproaches
We further examine the relative gaps for specific demo-
Theprompt-basedapproachesintroducedinTamkinetal.
graphic features. For example, in Figure 6, focusing on
(2023) can all be viewed as ways to discourage biased
GPT-3(whichhasthesmallestrelativegapsamongthe4
reasoning,instantiatingStrategyIII.Forourbaseline,we
chosenLLMs),weobserveagrowingtrendofrelativegaps
choose the top four of them that reduce the discrimina-
onthedefaultresponse(blackbars)astheageincreases.
tionthemost(i.e., Illegal, Ignore, Really (4x),
ThissuggeststhatGPT-3’sdefaultresponsesmaybemore
andIllegal + Ignore). Theexactstatementsofeach
biasedtowardsmoreseniorindividualscomparedtojunior
promptcanbefoundinTamkinetal.(2023).
ones. Itisworthnotingthatthetrendmaypotentiallydif-
To amplify bias-free reasoning (Fact), we first remove feracrossLLMs,andweincludeadditionalplotsforother
alldemographicinformationineachscenarioandaskthe LLMsondifferentdemographicgroupsinAppendixD.2.
LLM to make a Yes or No decision based on this base
scenario. Thenweexplicitlyincludeitsanswertothe
5.Conclusion
base scenariointhepromptandaskthemodeltode-
cide on the original scenario which contains spe- Thispaperpresentsacausality-guidedandprompting-based
cificdemographicinformation(e.g.,age20). LLMdebiasingframework. Inparticular,wehighlightthe
criticalroleofselectionmechanismsinmodelingdatacor-
4.2.2.OURRESULTS(DISCRIM-EVAL) pus bias and, more importantly, formulating how prompt
designscaninfluenceLLMoutputsbyspecifyingdifferent
Sincetheevaluationmetricrequiresaccessingthelogitof
selectionconditionsonitsinternalrepresentations. Guided
eachtoken,ourexperimentsonDiscrim-Evalareconducted
bycausalunderstandingsofsuchinterplay,weidentifyprin-
on these four LLMs: Mistral 7B, GPT-3, GPT-3.5, and
cipled prompting strategies for more effective debiasing.
GPT-4. Figure5showsourexperimentalresultsonthree
Ourstrongempiricalresultsdemonstratethebenefitsofour
demographiccategories: gender,ethnicity,andage.
framework, offering clear intuitions and theoretical foun-
Each bar in the figure represents the relative gap, which dations for effective debiasing approaches. Future work
measuresthedisparityintheprobabilityofmakinganaf- willnaturallyextendtoacquiringbias-freeknowledgeand
firmativedecision(‘Yes’)forthemostandleastprivileged representationsforLLMs.
9SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
BroaderImpact Bareinboim,E.andTian,J. Recoveringcausaleffectsfromselec-
tionbias. InProceedingsoftheAAAIConferenceonArtificial
In this paper, we present a causality-based LLM output Intelligence,volume29,2015.
debiasing framework. We aim to provide causal under-
standingsonboththeunderlyinggeneratingprocessforthe Bender,E.M.,Gebru,T.,McMillan-Major,A.,andShmitchell,
S. Onthedangersofstochasticparrots:Canlanguagemodels
trainingdatacorpus,andtheLLMreasoningprocesswhere
betoobig? InProceedingsofthe2021ACMConferenceon
theoutputismodulatedbyinputpromptsthroughselection
Fairness,Accountability,andTransparency,pp.610–623,2021.
mechanisms. Ourproposedframeworkservesasageneral
solution to promote fairness in pretrained LLMs without Berkson,J.Limitationsoftheapplicationoffourfoldtableanalysis
accesssingtheirmodelparameters. Thisframeworkisappli- tohospitaldata. BiometricsBulletin,2(3):47–53,1946.
cabletomanysociallyimportantdomains,andwedonot
Bolukbasi,T.,Chang,K.-W.,Zou,J.Y.,Saligrama,V.,andKalai,
foresee any particular potential negative social impact or
A.T. Manistocomputerprogrammeraswomanistohome-
ethicalconcerns. maker? debiasingwordembeddings. InAdvancesinNeural
InformationProcessingSystems,pp.4349–4357,2016.
Acknowledgement
Bordia, S. and Bowman, S. R. Identifying and reducing gen-
ThismaterialisbaseduponworksupportedbytheAIRe- der bias in word-level language models. arXiv preprint
arXiv:1904.03035,2019.
searchInstitutesProgramfundedbytheNationalScience
Foundation(NSF)underAIInstituteforSocietalDecision
Chiappa,S. Path-specificcounterfactualfairness. InProceedings
Making(AI-SDM),AwardNo. 2229881. Thisprojectis oftheAAAIConferenceonArtificialIntelligence,volume33,
alsopartiallysupportedbyanAmazonResearchAward(Fall pp.7801–7808,2019.
2022CFP),theNationalInstitutesofHealth(NIH)under
Correa, J. and Bareinboim, E. General transportability of soft
ContractR01HL159805,andgrantsfromAppleInc.,KDDI
interventions: Completenessresults. InAdvancesinNeural
ResearchInc.,QurisAI,andInfiniteBrainTechnology.
InformationProcessingSystems,volume33,pp.10902–10912,
2020.
References
Correa,J.D.,Tian,J.,andBareinboim,E. Identificationofcausal
Abid,A.,Farooqi,M.,andZou,J.Largelanguagemodelsassociate effectsinthepresenceofselectionbias. InProceedingsofthe
muslimswithviolence. NatureMachineIntelligence,3(6):461– AAAIConferenceonArtificialIntelligence,volume33,2019.
463,2021.
Creager,E.,Madras,D.,Pitassi,T.,andZemel,R.Causalmodeling
Achiam,J.,Adler,S.,Agarwal,S.,Ahmad,L.,Akkaya,I.,Aleman, forfairnessindynamicalsystems. InInternationalConference
F.L.,Almeida,D.,Altenschmidt,J.,Altman,S.,Anadkat,S., onMachineLearning,pp.2185–2195.PMLR,2020.
etal. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774,
2023. Dodge,J.,Sap,M.,Marasovic´,A.,Agnew,W.,Ilharco,G.,Groen-
eveld,D.,Mitchell,M.,andGardner,M. Documentinglarge
Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, webtextcorpora: Acasestudyonthecolossalcleancrawled
R., Schalkwyk, J., Dai, A.M., Hauth, A., etal. Gemini: A corpus. arXivpreprintarXiv:2104.08758,2021.
familyofhighlycapablemultimodalmodels. arXivpreprint
arXiv:2312.11805,2023. Eberhardt,F.andScheines,R. Interventionsandcausalinference.
PhilosophyofScience,74(5):981–995,2007.
Anthropic. Modelcardandevaluationsforclaudemodels. An-
thropic,2023. Engle,R.F.,Hendry,D.F.,andRichard,J.-F. Exogeneity. Econo-
metrica: Journal of the Econometric Society, pp. 277–304,
Bai,Y.,Kadavath,S.,Kundu,S.,Askell,A.,Kernion,J.,Jones, 1983.
A.,Chen,A.,Goldie,A.,Mirhoseini,A.,McKinnon,C.,Chen,
C.,Olsson,C.,Olah,C.,Hernandez,D.,Drain,D.,Ganguli, Ganguli,D.,Askell,A.,Schiefer,N.,Liao,T.,Lukosˇiu¯te˙,K.,Chen,
D., Li, D., Tran-Johnson, E., Perez, E., Kerr, J., Mueller, J., A.,Goldie,A.,Mirhoseini,A.,Olsson,C.,Hernandez,D.,etal.
Ladish,J.,Landau,J.,Ndousse,K.,Lukosuite,K.,Lovitt,L., Thecapacityformoralself-correctioninlargelanguagemodels.
Sellitto,M.,Elhage,N.,Schiefer,N.,Mercado,N.,DasSarma, arXivpreprintarXiv:2302.07459,2023.
N.,Lasenby,R.,Larson,R.,Ringer,S.,Johnston,S.,Kravec,S.,
Showk,S.E.,Fort,S.,Lanham,T.,Telleen-Lawton,T.,Conerly, Garimella, A., Amarnath, A., Kumar, K., Yalla, A. P., Anand-
T.,Henighan,T.,Hume,T.,Bowman,S.R.,Hatfield-Dodds, havelu,N.,Chhaya,N.,andSrinivasan,B.V. Heisveryin-
Z.,Mann,B.,Amodei,D.,Joseph,N.,McCandlish,S.,Brown, telligent,sheisverybeautiful? onmitigatingsocialbiasesin
T., and Kaplan, J. Constitutional ai: Harmlessness from ai languagemodellingandgeneration. InFindingsoftheAssoci-
feedback,2022. ationforComputationalLinguistics: ACL-IJCNLP2021,pp.
4534–4545,2021.
Bareinboim,E.andPearl,J. Controllingselectionbiasincausal
inference. InProceedingsoftheFifteenthInternationalCon- Gonen,H.andGoldberg,Y. Lipstickonapig:Debiasingmethods
ferenceonArtificialIntelligenceandStatistics,pp.100–108. coverupsystematicgenderbiasesinwordembeddingsbutdo
PMLR,2012. notremovethem. arXivpreprintarXiv:1903.03862,2019.
10SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Guo,Y.,Yang,Y.,andAbbasi,A. Auto-debias:Debiasingmasked Nabi, R. and Shpitser, I. Fair inference on outcomes. In Pro-
languagemodelswithautomatedbiasedprompts. InProceed- ceedingsoftheAAAIConferenceonArtificialIntelligence,vol-
ingsofthe60thAnnualMeetingoftheAssociationforCompu- ume32,pp.1931–1940,2018.
tationalLinguistics(Volume1:LongPapers),pp.1012–1023,
2022. Nabi, R., Malinsky, D., and Shpitser, I. Learning optimal fair
policies. InInternationalConferenceonMachineLearning,pp.
Heckman,J. Varietiesofselectionbias. TheAmericanEconomic 4674–4682.PMLR,2019.
Review,80(2):313–318,1990.
Nabi,R.,Malinsky,D.,andShpitser,I. Optimaltrainingoffair
Heckman, J. J. Sample selection bias as a specification error.
predictive models. In Conference on Causal Learning and
Econometrica: JournaloftheEconometricSociety,pp.153–
Reasoning,pp.594–617.PMLR,2022.
161,1979.
Oba, D., Kaneko, M., and Bollegala, D. In-contextual bias
Herna´n,M.A.andRobins,J.M. CausalInference:WhatIf. Boca
suppression for large language models. arXiv preprint
Raton:Chapman&Hall/CRC,2020.
arXiv:2309.07251,2023.
Hort,M.andSarro,F. Privilegedandunprivilegedgroups: An
empiricalstudyontheimpactoftheageattributeonfairness. Ouyang,L.,Wu,J.,Jiang,X.,Almeida,D.,Wainwright,C.L.,
InProceedingsofthe2ndInternationalWorkshoponEquitable Mishkin,P.,Zhang,C.,Agarwal,S.,Slama,K.,Ray,A.,Schul-
DataandTechnology,pp.17–24,2022. man,J.,Hilton,J.,Kelton,F.,Miller,L.,Simens,M.,Askell,A.,
Welinder,P.,Christiano,P.,Leike,J.,andLowe,R. Training
Huang,B.,Zhang,K.,Zhang,J.,Ramsey,J.,Sanchez-Romero, languagemodelstofollowinstructionswithhumanfeedback,
R., Glymour, C., and Scho¨lkopf, B. Causal discovery from 2022.
heterogeneous/nonstationarydata.JournalofMachineLearning
Research,21(1):3482–3534,2020. Pearl,J. Causality. CambridgeUniversityPress,2009.
Jin,Z.,Liu,J.,Lyu,Z.,Poff,S.,Sachan,M.,Mihalcea,R.,Diab, Pessach,D.andShmueli,E. Improvingfairnessofartificialin-
M.,andScho¨lkopf,B. Canlargelanguagemodelsinfercau- telligence algorithms in privileged-group selection bias data
sation from correlation? arXiv preprint arXiv:2306.05836, settings. ExpertSystemswithApplications,185:115667,2021.
2023.
Peters, J., Janzing, D., and Scho¨lkopf, B. Elements of Causal
Kaltenpoth,D.andVreeken,J. Identifyingselectionbiasfrom
Inference: FoundationsandLearningAlgorithms. TheMIT
observationaldata. InProceedingsoftheAAAIConferenceon
Press,2017.
ArtificialIntelligence,2023.
Ray, P. P. Chatgpt: A comprehensive review on background,
Kaneko,M.andBollegala,D.Debiasingpre-trainedcontextualised
applications,keychallenges,bias,ethics,limitationsandfuture
embeddings. arXivpreprintarXiv:2101.09523,2021.
scope. InternetofThingsandCyber-PhysicalSystems,2023.
Kıcıman,E.,Ness,R.,Sharma,A.,andTan,C. Causalreasoning
andlargelanguagemodels:Openinganewfrontierforcausality. Richardson,T.andSpirtes,P. Ancestralgraphmarkovmodels.
arXivpreprintarXiv:2305.00050,2023. TheAnnalsofStatistics,30(4):962–1030,2002.
Kilbertus, N., Rojas-Carulla, M., Parascandolo, G., Hardt, M., Rozado,D. Thepoliticalbiasesofchatgpt. SocialSciences,12(3):
Janzing,D.,andScho¨lkopf,B.Avoidingdiscriminationthrough 148,2023.
causalreasoning.InAdvancesinNeuralInformationProcessing
Systems,volume30,pp.656–666,2017. Schick,T.,Udupa,S.,andSchu¨tze,H. Self-diagnosisandself-
debiasing: Aproposalforreducingcorpus-basedbiasinnlp.
Kojima,T.,Gu,S.S.,Reid,M.,Matsuo,Y.,andIwasawa,Y.Large TransactionsoftheAssociationforComputationalLinguistics,
languagemodelsarezero-shotreasoners.InAdvancesinneural 9:1408–1424,2021.
informationprocessingsystems,volume35,pp.22199–22213,
2022. Shaikh,O.,Zhang,H.,Held,W.,Bernstein,M.,andYang,D. On
secondthought,let’snotthinkstepbystep!biasandtoxicityin
Kusner,M.,Loftus,J.,Russell,C.,andSilva,R. Counterfactual
zero-shotreasoning. arXivpreprintarXiv:2212.08061,2022.
fairness.InAdvancesinNeuralInformationProcessingSystems,
pp.4066–4076,2017.
Sheng,E.,Chang,K.-W.,Natarajan,P.,andPeng,N. Thewoman
workedasababysitter:Onbiasesinlanguagegeneration.arXiv
Lauscher,A.,Lueken,T.,andGlavasˇ,G. Sustainablemodularde-
preprintarXiv:1909.01326,2019.
biasingoflanguagemodels. arXivpreprintarXiv:2109.03646,
2021.
Si,C.,Gan,Z.,Yang,Z.,Wang,S.,Wang,J.,Boyd-Graber,J.,
Liang,P.P.,Wu,C.,Morency,L.-P.,andSalakhutdinov,R. To- andWang,L. Promptinggpt-3tobereliable. arXivpreprint
wardsunderstandingandmitigatingsocialbiasesinlanguage arXiv:2210.09150,2022.
models. InInternationalConferenceonMachineLearning,pp.
6565–6576.PMLR,2021. Spirtes,P. Directedcyclicgraphicalrepresentationsoffeedback
models. InProceedingsoftheEleventhConferenceonUncer-
Liu,Y.,Yao,Y.,Ton,J.-F.,Zhang,X.,Cheng,R.G.H.,Klochkov, taintyinArtificialIntelligence,pp.491–498,1995.
Y., Taufiq, M. F., and Li, H. Trustworthy llms: A survey
andguidelineforevaluatinglargelanguagemodels’alignment. Spirtes,P.,Glymour,C.,andScheines,R. Causation,Prediction,
arXivpreprintarXiv:2308.05374,2023. andSearch. SpringerNewYork,1993.
11SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Spirtes,P.,Meek,C.,andRichardson,T. Causalinferenceinthe Zhang, J. On the completeness of orientation rules for causal
presenceoflatentvariablesandselectionbias.InProceedingsof discoveryinthepresenceoflatentconfoundersandselection
theEleventhconferenceonUncertaintyinArtificialIntelligence, bias. ArtificialIntelligence,172(16-17):1873–1896,2008.
pp.499–506,1995.
Zhang,K.,Zhang,J.,Huang,B.,Scho¨lkopf,B.,andGlymour,C.
Sweeney,L. Discriminationinonlineaddelivery. Queue,11(3): Ontheidentifiabilityandestimationoffunctionalcausalmodels
10–29,2013. inthepresenceofoutcome-dependentselection. InUAI,2016.
Tamkin,A.,Askell,A.,Lovitt,L.,Durmus,E.,Joseph,N.,Kravec, Zhang,X.,Tu,R.,Liu,Y.,Liu,M.,Kjellstrom,H.,Zhang,K.,and
S.,Nguyen,K.,Kaplan,J.,andGanguli,D. Evaluatingand Zhang,C. Howdofairdecisionsfareinlong-termqualifica-
mitigatingdiscriminationinlanguagemodeldecisions. arXiv tion? InAdvancesinNeuralInformationProcessingSystems,
preprintarXiv:2312.03689,2023. volume33,pp.18457–18469,2020.
Tang,Z.,Chen,Y.,Liu,Y.,andZhang,K.Tierbalancing:Towards Zhao,J.,Wang,T.,Yatskar,M.,Ordonez,V.,andChang,K.-W.
dynamicfairnessoverunderlyingcausalfactors. InInterna- Genderbiasincoreferenceresolution:Evaluationanddebias-
tionalConferenceonLearningRepresentations,2023a. ingmethods. InProceedingsofthe2018Conferenceofthe
NorthAmericanChapteroftheAssociationforComputational
Tang,Z.,Zhang,J.,andZhang,K.What-isandhow-toforfairness Linguistics:HumanLanguageTechnologies,volume2,2018.
inmachinelearning:Asurvey,reflection,andperspective.ACM
ComputingSurveys,55(13s):1–37,2023b. Zheng, H. S., Mishra, S., Chen, X., Cheng, H.-T., Chi, E. H.,
Le, Q.V., andZhou, D. Takeastepback: Evokingreason-
Tang,Z.,Wang,J.,Liu,Y.,Spirtes,P.,andZhang,K. Procedu- ingviaabstractioninlargelanguagemodels. arXivpreprint
ralfairnessthroughdecouplingobjectionabledatagenerating arXiv:2310.06117,2023.
components. InInternationalConferenceonLearningRepre-
sentations,2024. Zhou,F.,Mao,Y.,Yu,L.,Yang,Y.,andZhong,T. Causal-debias:
Unifying debiasing in pretrained language models and fine-
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., tuningviacausalinvariantlearning. InProceedingsofthe61st
Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is AnnualMeetingoftheAssociationforComputationalLinguis-
allyouneed. InAdvancesinNeuralInformationProcessing tics(Volume1:LongPapers),pp.4227–4241,2023.
Systems,volume30,2017.
Vig,J.,Gehrmann,S.,Belinkov,Y.,Qian,S.,Nevo,D.,Singer,
Y.,andShieber,S. Investigatinggenderbiasinlanguagemod-
els using causal mediation analysis. In Advances in Neural
InformationProcessingSystems,volume33,pp.12388–12401,
2020.
von Ku¨gelgen, J., Karimi, A.-H., Bhatt, U., Valera, I., Weller,
A., andScho¨lkopf, B. Onthefairnessofcausalalgorithmic
recourse. InProceedingsoftheAAAIConferenceonArtificial
Intelligence,volume36,pp.9584–9594,2022.
Wang,B.,Chen,W.,Pei,H.,Xie,C.,Kang,M.,Zhang,C.,Xu,
C.,Xiong,Z.,Dutta,R.,Schaeffer,R.,etal. Decodingtrust:
Acomprehensiveassessmentoftrustworthinessingptmodels.
arXivpreprintarXiv:2306.11698,2023a.
Wang,F.,Mo,W.,Wang,Y.,Zhou,W.,andChen,M. Acausal
viewofentitybiasin(large)languagemodels. arXivpreprint
arXiv:2305.14695,2023b.
Wei,J.,Wang,X.,Schuurmans,D.,Bosma,M.,Xia,F.,Chi,E.,
Le,Q.V.,Zhou,D.,etal. Chain-of-thoughtpromptingelicits
reasoninginlargelanguagemodels. InAdvancesinNeural
InformationProcessingSystems,volume35,pp.24824–24837,
2022.
Winship,C.andMare,R.D. Modelsforsampleselectionbias.
AnnualReviewofSociology,18(1):327–350,1992.
Yao,Y.,Xu,X.,andLiu,Y. Largelanguagemodelunlearning.
arXivpreprintarXiv:2310.10683,2023.
Zhang,C.,Bauer,S.,Bennett,P.,Gao,J.,Gong,W.,Hilmkil,A.,
Jennings,J.,Ma,C.,Minka,T.,Pawlowski,N.,etal. Under-
standingcausalitywithlargelanguagemodels:Feasibilityand
opportunities. arXivpreprintarXiv:2304.05524,2023.
12Supplement to “Steering LLMs Towards Unbiased Responses: A
Causality-Guided Debiasing Framework”
A.RelatedWorks
Inthissection, weprovidedetaileddiscussionsonrelatedworks. Weconsiderthecombinationsofveryrelatedtopics
includingcausality,algorithmicfairness,andLLMreasoning. InSectionA.1,weconsidercausalnotionsoffairnessthat
donotspecificallypertaintotheLLMcontext. InSectionA.2,weconsiderexistingeffortstodrawconnectionsbetween
causalityandLLMreasoning. InSectionA.3,weconsiderpreviousworksonLLMdebiasing. InSectionA.4,weconsider
previousworksthatinvolveallthreetopics.
A.1.CausalityandFairness
It has been recognized in the algorithmic fairness literature that causality provides a unique tool to facilitate a better
understandingofthedata-generatingprocess,andtherefore,moreeffectivebiasquantificationsandmitigations(Kilbertus
etal.,2017;Kusneretal.,2017;Nabi&Shpitser,2018;Nabietal.,2019;Chiappa,2019;Nabietal.,2022;vonKu¨gelgen
etal.,2022;Tangetal.,2023a). Previouscausalfairnessliteraturehasconsiderednotionsbasedonestimatingorbounding
variouskindsofcausaleffects(Kilbertusetal.,2017;Kusneretal.,2017;Nabi&Shpitser,2018;Nabietal.,2019;Chiappa,
2019),andalsothecausalmodelingofthedynamicsaswellasthelong-termimplicationsofbiasmitigationstrategies
(Creageretal.,2020;Zhangetal.,2020;Tangetal.,2023a;b).
Because of the relatively abstract definition of the variable or node in the language context, previous approaches for
characterizingandenforcingcausalfairnessarenotdirectlyapplicableinLLMdebiasingtasks. Thatbeingsaid,aswehave
demonstratedinourcausality-guideddebiasingframework,causalunderstandingsoftheinvolveddata-generatingprocesses
helpidentifyeffectivedebiasingstrategiesthatarebothintuitivelyclearandtheoreticallygrounded.
A.2.CausalityandLLMs
TheintersectionbetweencausalityandLLMshasdrawnincreasingattention. Zhangetal.(2023)considersthreetypesof
causalquestionsandaimstoevaluateLLMs’abilitiestoidentifycausalrelations,discovernewknowledgefromdata,and
quantitativelyestimatetheconsequencesofactions. Kıcımanetal.(2023)investigateLLMs’abilitiestoperformcausal
reasoningandsolvecovariance-/logic-basedcausalquestions. TheyalsostudythefailuremodesofLLMsandprovide
techniquestointerpretthemodelrobustness. Jinetal.(2023)proposeabenchmarkdatasetforevaluatingLLMs’causal
inferencecapabilitiesviathetaskofdeterminingcausalrelationshipsfromasetofcorrelationalstatements.
Thislineofresearchfocusesoncomplexcausalreasoningabilitiesingeneralsettings,withoutspecificattentiontopotential
fairnessviolations. Incomparison,ourcausality-guideddebiasingframeworkdoesnotinvolveassumptions/requirementson
LLMs’general-purposecausalreasoningcapabilities.Weadoptarathermildassumptionthatawell-trainedandwell-aligned
LLMcapturesthedependencepatterninthetrainingdataandthatsuchapatternisinternalizedandutilizedduringreasoning.
A.3.DebiasingLanguageModels
Thereisalargeamountofworkdiscussingbiasandfairnessinthecontextoflanguagemodels(LMs)(Bordia&Bowman,
2019; Liang et al., 2021; Abid et al., 2021; Wang et al., 2023a; Liu et al., 2023; Ray, 2023; Rozado, 2023), and our
investigationliesondebiasingtechniqueswithcausalunderstandingsofthesourcesofbiases. Fordebiasingapproaches
inthecontextofLMs,thereareproposalsinvolvingdirectfine-tuningofmodelparameters(Kaneko&Bollegala,2021;
Garimella et al., 2021; Lauscher et al., 2021; Guo et al., 2022), modifying the decoding steps (Schick et al., 2021),
incorporatingReinforcementLearningwithHumanFeedback(RLHF)tobetteralignthemodelswithhumanvalues(Ouyang
etal.,2022;Baietal.,2022;Yaoetal.,2023),andprompting-basedtechniques(Sietal.,2022;Tamkinetal.,2023;Oba
etal.,2023;Gangulietal.,2023). Wefocusonprompting-basedtechniquesandidentifyprinciplesforpromptdesigns
13SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
demographic 1 demographic-aware text demographic demographic-aware text
representation vi S representation representation S representation
i entity vii iv 3 entity
representation 2 demographic-agnostic fact representation demographic-agnostic fact
ii
iii scenario representation scenario representation
representation 4 5 representation
prompt properly LLM prompt properly LLM
prompt considered v potential output prompt considered potential output
(a)LLMreasoningprocess(annotatedwithselectionmecha- (b)LLM reasoning process (Strategy I: nudge towards
nismsspecifiedbyprompts) demographic-agnositicfact)
demographic demographic-aware text demographic demographic-aware text
representation S representation representation S representation
entity entity
representation demographic-agnostic fact representation demographic-agnostic fact
scenario representation scenario representation
representation representation
prompt properly LLM prompt properly LLM
prompt considered potential output prompt considered potential output
(c)LLMreasoningprocess(StrategyII:counteractexisting (d)LLMreasoningprocess(StrategyIII:nudgeawarefrom
selectionbias) demographic-awaretext)
demographic demographic-aware text
representation S representation
entity
representation demographic-agnostic fact
scenario representation
representation
prompt properly LLM
prompt considered potential output
(e)LLMreasoningprocess(allstrategiescombined)
Figure7: Additionalillustrationsondebiasingstrategies.
tosteerLLMstowardunbiasedresponsesbya). reducingbiasedreasoningandb). encouragingbias-freereasoning. We
providedemonstrationsofhowwecanemploytheabovetwoprinciples. WorksonLLMsreasoningsuchasWeietal.
(2022);Zhengetal.(2023)canalsobeincorporatedintowithourframeworktoencouragebias-freereasoning.
A.4.DebiasingLLMsfromCausalPerspectives
MostcloselyrelatedliteratureconsidersLLMdebiasingstrategiesfromcausalperspectives. Vigetal.(2020)utilizecausal
mediationanalysisandconsiderneuron-levelinterventiontoinvestigatetheinstantiationofgenderbiasinTransformer-
basedlanguagemodels(Vaswanietal.,2017). Zhouetal.(2023)proposeCausal-Debiastomitigatetheunwanted
stereotypicalassociationbyfine-tuningpretrainedlanguagemodels. Thecausalmodeltheyconsiderinvolvesfourvariables:
label-relevantfactor,bias-relevantfactor,rawsentence,andground-truthlabel. Wangetal.(2023b)payspecialattentionto
entitybiasandproposeaspecificstructuralcausalmodel(SCM)foreasierparameterestimations,suchthattheintervention-
basedmitigationstrategycanbecarriedout. Theircausalmodelinvolvesfourvariables: entity,rawtext,LLMinput,and
LLMoutput.
Incomparison,weprovidedetailedcausalmodelingsatasub-sentencelevel,consideringboththetrainingcorpusgenerating
processandtheLLMreasoningprocess. Furthermore, ourframeworkexplicitlymodelstheinterplaybetweeninternal
representationsandexternalinputsthroughselectionmechanisms,providingaclearerpictureregardingpossiblestrategiesto
debiasLLMoutputsmoreeffectively. Ourapproachdoesnotrequirewhite-boxaccessortheabilitytoperforminterventions,
makingourprompting-basedframeworkapplicabletoavarietyofpracticalscenarios.
B.FurtherIllustrationsandDiscussionsofOurFramework
Inthissection,weprovidefurtherillustrationsonthedebiasingstrategiesidentifiedinSection3.2.
InFigure7,weuselightcoral(blue)tohighlightunregulated(regulated)informationflowsfromdemographicrepresentations
14SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
toLLMoutputsintheinternalreasoningprocess. Weusemix-coloredhighlighttodenotepartiallyregulatedinformation
flow, e.g., the edge from demographic-aware text representation to LLM potential output in Figure 7(d). Comparing
Figure7(e)(allstrategiescombined)withFigures7(b)–7(d)(strategiesappliedindividually),wecanseethatcollectively,
thestrategiesaddressthesocialbiasinlanguagemorecomprehensively.
Hereby“regulated”,wearereferringtotheconstraintovertheassociationbetweendemographicinformationrepresentation
andthepotentialoutput. Wewouldliketonotethatourcausalmodelscannaturallyhandlesituationswherecertainkindsof
neutraldependencepatternsinvolvingdemographicinformationarenotnecessarilyconsideredproblematic(Tangetal.,
2024). We present relevant experimental results in Section D.1. We would also like to note that our causality-guided
frameworkisnotlimitedtosituationswheredemographicinformationisexplicitlyinvolved. Onecanadaptourframework
tothespecificpracticalsettingbyincorporatingrelevantnodesintocausalgraphs,therebyidentifyingthemostsuitable
debiasingstrategiestherein.
C.ExperimentalDetails
PretrainedLLMs FortheGPTmodelsusedinourexperiments,weconsidersnapshotsfromJune13th,2023where
theknowledgecut-offtimeisSep2021. SincethelegacyGPT-3model(a.k.a.,text-davinci-003)isnolongersupported
when we conduct the experiments, we use the model “gpt-3.5-turbo-instruct” instead as it has similar capabilities as
GPT-3eramodels. TheMistral-7Bmodelweuseinourexperimentsistheimprovedinstructionfine-tunedversion(a.k.a.,
“Mistral-7B-Instruct-v0.2”). WeareunabletouseClaude2forourexperimentsontheDiscrim-Evaldatasetbecausewe
cannotaccesstheprobabilitiesofgeneratedtokens. AllLLMsresponsesareobtainedwithatemperatureof0.
IterativePrompting TheresponsesofLLMsmaynotfollowagivenformatevenwithspecificinstructions,whichmakes
answerextractionchallenging. Moreover,weobservethataddinginstructionstorestricttheformatofresponsesmaylower
thequalityofthegeneratedoutputs. Therefore,weapply2-rounditerativepromptinginourexperimentswhereweletthe
modelsgeneratefreelyandthenaskthemtosummarizetheiranswersinoneortwowords. Thiswayallowsustoobtain
highanswerqualitieswithaneasyextractionprocessatthesametime.
C.1.GenderBias: WinoBias
ForexperimentsontheWinoBiasdataset,wecombinedboththetrainingandtestdataforevaluationasthereisnoneed
toseparatethemwhenusingprompting-baseddebiasingtechniques. Wealsonoticedthattheoriginaldatasetcontains
400 grammar mistakes across 3000+ sentences in total. We corrected these grammar mistakes as they may hinder the
co-referenceresolutiontasks. Wehaveprovidedthecleanedversioninthesupplementarymaterials.
Sincethereare571exampleswheretwoormoremodelsmakethesamemistakesonthefactual questions. After
lookingintothesemistakes,wefindthatsomeoftheexamplesareindeedambiguousinnature(e.g.,”Theconstruction
workerstaredattheteacherbecause[who]wasangry”). Therefore, wecollectedhumanevaluationstounderstandthe
inherentambiguityintheWinoBiasdataset. Foreachofthe571examples,wecollect5humanresponsesonthefactual
questions(i.e.,whichsentenceismorelikelytohappeninreallife),andweaskthehumanannotatortochoosefrom
{SentenceA,SentenceB,andEquallylikely}. Basedonthehumanresponses,weidentified60examples(55fromtheType
Itaskand5fromtheTypeIItask)wherethreeormoreannotatorsdisagreewiththegroundtruthanswersorthinkboth
sentencesinthefactual questionsareequallylikelytohappeninreallife. Weremovedthese60examplesduring
ourevaluation,andwewillincludethehumanevaluationresultsinourcodebase.
C.2.DemographicBias: Discrim-Eval
TheDiscrim-Evaldatasetcontains70diversedecisionscenariosand9×3×5×70=9450individualdecisionquestions
whichincludesallcombinationsof[AGE]∈[20,30,40,50,60,70,80,90,100],[GENDER]∈[male,female,non-binary]
and[RACE]∈[white,Black,Asian,Hispanic,NativeAmerican]. Tomeasurethecorrespondingbiasineachdemographic
category,wereconstructthedatasetbyextractingthebase scenariowhichdoesnotcontainanydemographicinfor-
mation(e.g.,wereplaceallpronounswiththeanaphoricreferencetoavoidleakingthegenderinformation). Wethenask
themodeltodecideoneachofthe70base scenarios. Thereare(1/11/1/2)scenarioswhere(Mistral7B/GPT-3/GPT-
3.5/GPT-4)refusestoanswerordoesnotoutputaYesanswer, andweremovedthesescenarioscorrespondinglywhen
evaluatingtheseLLMs.
15SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Table3: ErrorAnalysisonWinoBiasTypeIIcoreferencetask. Wedividethemodels’responsesinto4categoriesto
betterunderstandtheirsuccessandfailurecases. TTdenotesthe(%)ofexampleswhereLLManswersboththefactual
questionandtheoriginalquestioncorrectly,FFdenotesthe(%)ofexampleswherebothquestionsareansweredincorrectly,
indicatingthecoreferenceerrorscausedbythemodel’sworldknowledge. TFdenotesthecoreferenceerrorscausedby
genderbiasasonlyfactualquestionsarecorrectlyanswered,andFTindicatescoreferencesuccessthatmaybedueto
gendershortcutsincethefactualquestionsgetwrongbutoriginalquestionsarecorrectlyanswered.
TT TF FT FF
Accuracy(%)
Anti Pro Anti Pro Anti Pro Anti Pro
GPT-3.5
Reduce + Fact 88.69 89.71 1.14 0.13 3.43 4.70 6.73 5.46
Fact Only 87.55 89.83 2.29 0.00 3.05 5.97 7.12 4.19
Reduce Only 80.30 85.77 5.72 2.03 8.77 9.15 0.89 0.51
Default 83.61 89.71 5.59 0.13 8.64 10.04 1.40 0.13
GPT-4
Reduce + Fact 99.62 99.62 0.13 0.00 0.00 0.13 0.25 0.25
Fact Only 99.36 99.87 0.25 0.00 0.13 0.00 0.25 0.13
Reduce Only 98.98 99.49 0.76 0.13 0.00 0.38 0.25 0.00
Default 98.73 99.75 0.89 0.13 0.25 0.00 0.13 0.13
Table4: ErroranalysisofReduce+FactonTypeIandTypeIIquestionsinWinoBias.
TT TF FT FF
Accuracy(%)
Anti Pro Anti Pro Anti Pro Anti Pro
GPT-3
TypeI 72.73 73.27 1.49 0.95 0.54 0.68 25.24 25.10
TypeII 82.47 82.34 1.27 1.40 0.76 1.91 15.50 14.36
GPT-3.5
TypeI 70.15 78.70 10.58 2.04 2.58 5.97 16.55 13.16
TypeII 88.69 89.71 1.14 0.13 3.43 4.70 6.73 5.46
Claude
TypeI 73.00 73.00 2.99 2.99 1.09 2.17 22.93 21.85
TypeII 79.80 81.19 6.61 5.21 2.54 4.07 11.05 9.53
GPT-4
TypeI 94.44 96.07 1.76 0.27 0.14 0.68 3.66 2.99
TypeII 99.62 99.62 0.13 0.00 0.00 0.13 0.25 0.25
D.AdditionalExperimentalResults
D.1.GenderBias: WinoBias
WeincludeadditionalablationstudiesontheWinoBiasdataset,whichincludeadetailederroranalysisonWinoBiasTypeII
coreferencetask(Table3),adetailederroranalysisofReduce+Factwith4LLMsonTypeIandTypeIItasks(Table4),
andanablationstudyonadjustingthelevelsofbiasedreasoning(Table5)inthepromptdesign.
InTable4,weshowthedetailedresultsonbothTypeIandTypeIIcoreferencetasksacross4LLMs. Aswecansee,our
methodhasbiggerimprovementsonmodelswithbetterworldknowledgeas. modelswithworseworldknowledgecould
limitourmethodtoreachingitsfullcapacity.
Ablation study on adjusting the levels of counteracting existing selection bias In Table 5, we investigated how
different levels of enforcing Strategy II (counteract existing selection bias) impacts the model debiasing performance
byadjustingtheFactpartintheinputprompt. Forexample,acounteractlevelof100%indicatesthefollowingprompt:
Assume that the physician can be male 0% of the time and female 100% of the time,
and assume that the secretary can be male 0% of the time and female 100% of the
16SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Table5: AdjustingthelevelsofcounteractingexistingselectionbiasonGPT-3.5withReduce+Fact. Weinvestigated
howthelevelofcounteractingstereotypeimpactsthemodelperformancebyadjustingtheFactpartintheinputprompt.
For example, a counteract level of 100% indicates the following prompt: Assume that the physician can
be male 0% of the time and female 100% of the time, and assume that the secretary
can be male 0% of the time and female 100% of the time.
TT TF FT FF
Counteractlevel(%)
Anti Pro Anti Pro Anti Pro Anti Pro
100 70.15 77.20 10.58 3.66 3.80 4.34 15.47 14.79
90 69.06 77.88 11.53 2.99 1.76 4.61 17.64 14.52
75 68.79 78.02 11.94 2.85 2.17 5.02 17.10 14.11
50 65.94 78.02 15.20 2.99 2.44 5.02 16.42 13.98
25 65.67 80.05 15.20 0.95 1.22 5.43 17.91 13.57
10 64.45 79.78 16.01 1.09 0.81 5.43 18.72 13.70
0 61.06 78.97 19.95 1.90 1.09 8.28 17.91 10.85
time;whilealevelof50%indicatesthefollowingprompt: Assume that the physician can be male 50%
of the time and female 50% of the time, and assume that the secretary can be male
50% of the time and female 50% of the time. Weobservethatasthelevelofanti-stereotypegoesdown,
theerrorscausedbytheuseofthegendershortcutincrease(TFincreases). Inaddition,bysoftadjustmentofreducing
biasedreasoning,weprovidenotonlyflexibletuningstrategiesforthebestmodelperformancebutalsoachancetodive
intotheunderlyingreasonsfortheerror.
D.2.DemographicBias: Discrim-Eval
InFigure8,Figure9,Figure10,Figure11,weshowindetailstheperformancecomparisononDiscrim-Evalacrossthree
demographiccategoriesacrossfourLLMs(Mistral7B,GPT3,GPT3.5,andGPT4). Theheightofthebardenotesthe
degreeofdiscriminationbycomparingtheleastprivilegedgroupwiththemostprivilegedgroupinagivendemographic
category(thehigherthebar,thedeeperthediscrimination). Differentmethods(promptdesigns)arecoloreddifferently
(lightercolorsdenotetheonesthatamplifybias-freereasoning). Thebaselinesettingiscoloredblack.
Figure8: PerformancecomparisononDiscrim-EvalacrossthreedemographiccategoriesindetailsonMistral(7B).
Theheightofthebardenotesthedegreeofdiscriminationbycomparingtheleastprivilegedgroupwiththemostprivileged
groupin agivendemographic category(the higherthe bar, the deeperthediscrimination). Differentmethods (prompt
designs)arecoloreddifferently(lightercolorsdenotetheonesthatamplifybias-freereasoning). Amplifyingbias-free
reasoninguniversallyreducestherelativegapwhenaddedwithmethodsthatreducebiasedreasoning.
17SteeringLLMsTowardsUnbiasedResponses:ACausality-GuidedDebiasingFramework
Figure9: PerformancecomparisononDiscrim-EvalacrossthreedemographiccategoriesindetailsonGPT-3. The
heightofthebardenotesthedegreeofdiscriminationbycomparingtheleastprivilegedgroupwiththemostprivilegedgroup
inagivendemographiccategory(thehigherthebar,thedeeperthediscrimination). Differentmethods(promptdesigns)
arecoloreddifferently(lightercolorsdenotetheonesthatamplifybias-freereasoning). Amplifyingbias-freereasoning
universallyreducestherelativegapwhenaddedwithmethodsthatreducebiasedreasoning.
Figure10: PerformancecomparisononDiscrim-EvalacrossthreedemographiccategoriesindetailsonGPT-3.5. The
heightofthebardenotesthedegreeofdiscriminationbycomparingtheleastprivilegedgroupwiththemostprivilegedgroup
inagivendemographiccategory(thehigherthebar,thedeeperthediscrimination). Differentmethods(promptdesigns)
arecoloreddifferently(lightercolorsdenotetheonesthatamplifybias-freereasoning). Amplifyingbias-freereasoning
universallyreducestherelativegapwhenaddedwithmethodsthatreducebiasedreasoning.
Figure11: PerformancecomparisononDiscrim-EvalacrossthreedemographiccategoriesindetailsonGPT-4. The
heightofthebardenotesthedegreeofdiscriminationbycomparingtheleastprivilegedgroupwiththemostprivilegedgroup
inagivendemographiccategory(thehigherthebar,thedeeperthediscrimination). Differentmethods(promptdesigns)
arecoloreddifferently(lightercolorsdenotetheonesthatamplifybias-freereasoning). Amplifyingbias-freereasoning
universallyreducestherelativegapwhenaddedwithmethodsthatreducebiasedreasoning.
18