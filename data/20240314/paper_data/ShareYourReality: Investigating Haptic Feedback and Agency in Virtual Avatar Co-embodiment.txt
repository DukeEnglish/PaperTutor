ShareYourReality:InvestigatingHapticFeedbackandAgencyinVirtualAvatar
Co-embodiment
KARTHIKEYAPUTTURVENKATRAJ,CentrumWiskunde&InformaticaDelftUniversityTechnology,Nether-
lands
WOMEIJER,DelftUniversityofTechnology,Netherlands
MONICAPERUSQUÍA-HERNÁNDEZ,NaraInstituteofScienceandTechnolgy,Japan
GIJSHUISMAN,DelftUniversityofTechnology,Netherlands
ABDALLAHELALI,CentrumWiskunde&Informatica,Netherlands
Oculus Quest 2:
- display virtual
environment
Touch controllers:
- shared control
of virtual hands
- haptic feedback
on overlap
User 1 Joint action task User 2
Fig.1. Twousersco-embodyingvirtualhandsperformingtwotypesofjointactiontasksinasharedvirtualrealityenvironment
Virtualco-embodimentenablestwouserstoshareasingleavatarinVirtualReality(VR).Duringsuchexperiences,theillusionofshared
motioncontrolcanbreakduringjoint-actionactivities,highlightingtheneedforposition-awarefeedbackmechanisms.Drawingon
theperceptualcrossingparadigm,weexplorehowhapticscanenablenon-verbalcoordinationbetweenco-embodiedparticipants.
Inawithin-subjectsstudy(20participantpairs),weexaminedtheeffectsofvibrotactilehapticfeedback(None,Present)andavatar
Authors’addresses:KarthikeyaPutturVenkatraj,CentrumWiskunde&InformaticaandDelftUniversityTechnology,Amsterdam,Netherlands,
karthike@cwi.nl;WoMeijer,DelftUniversityofTechnology,Delft,Netherlands,W.I.M.T.Meijer@tudelft.nl;MonicaPerusquía-Hernández,NaraInstitute
ofScienceandTechnolgy,Ikoma,Japan,m.perusquia@is.naist.jp;GijsHuisman,DelftUniversityofTechnology,Delft,Netherlands,g.huisman@tudelft.nl;
AbdallahElAli,CentrumWiskunde&Informatica,Amsterdam,Netherlands,aea@cwi.nl.
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents
ofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton
serversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ManuscriptsubmittedtoACM
ManuscriptsubmittedtoACM 1
4202
raM
31
]CH.sc[
1v36380.3042:viXra2 Venkatrajetal.
controldistribution(25-75%,50-50%,75-25%)acrosstwoVRreachingtasks(Targeted,Free-choice)onparticipants’SenseofAgency
(SoA),co-presence,bodyownership,andmotionsynchrony.Wefound(a)lowerSoAinthefree-choicewithhapticsthanwithout,(b)
higherSoAduringthesharedtargetedtask,(c)co-presenceandbodyownershipweresignificantlyhigherinthefree-choicetask,(d)
players’handmotionssynchronizedmoreinthetargetedtask.Weprovidecautionaryconsiderationswhenincludinghapticfeedback
mechanismsforavatarco-embodimentexperiences.
CCSConcepts:•Human-centeredcomputing→Humancomputerinteraction(HCI);•VirtualReality;
AdditionalKeyWordsandPhrases:Virtualreality,avatarco-embodiment,haptics,senseofagency,bodyownership,co-presence,
perceptualcrossing
ACMReferenceFormat:
KarthikeyaPutturVenkatraj,WoMeijer,MonicaPerusquía-Hernández,GijsHuisman,andAbdallahElAli.2024.ShareYourReality:
InvestigatingHapticFeedbackandAgencyinVirtualAvatarCo-embodiment. 1,1(March2024),25pages.https://doi.org/xx.xxxx/
xxxxxxx.xxxxxxxx
1 INTRODUCTION
VirtualReality(VR)technologiesenablepeopletonotonlyimmersethemselvesinartificialdigitalworlds,butalsoenable
previouslyimpossibleinteractionsthatchallengeourassumptionsaboutourvirtualbodiesandsocialcoordination
processesinsuchvirtualspaces.Theproliferationofconsumerhead-mounteddisplays(HMDs)havemadeVRsystems
anincreasinglycommonplatformthroughwhichvirtualsocialinteractionscantakeplace[16,45].VRenablesmeeting
inashared,immersivevirtualenvironment[20,34],andinteractingwithvirtualrepresentationsofhumanavatarsand
virtualagents.SocialinteractionsareakeyfactorinVR–notonlytopreventisolationofindividualsinthevirtual
environment[49],butalsotoenablejointsocialactivitiesandinteractions[48,58]inandbeyondsocialVRplatforms
suchasVRChatandRecRoom[42].
DespitethemyriadwaysthatsocialVRplatformscanimplementmulti-userfunctionality,themostcommonly
used method today is giving each user their own individual avatar to navigate through the virtual environment.
Typically,suchinteractionsadoptafirst-personperspective,whichisanimportantcontributingfactortocreating
asenseofbodyownership(i.e.,theexperienceofhavingavirtualbody[27])andagency(i.e.,involvingasenseof
controloveravirtualbody[4])towardstheuser’svirtualavatar.ExtendingbeyondcommonsocialVRinteractions,
researchershaverecentlyexploredtheconceptof“virtualco-embodiment”[11,15],wheretwousersembodyasingle,
sharedavatar.Thisinherentlydiffersfromasharedvisualexperiencewheremultipleuserswouldonlysharethe
sameviewingperspective[66].Virtualco-embodimentoffersamulti-userexperiencecharacterizedbysharedcontrol
overtheavatar’smovement.Sincetwoormorepeoplesharecontrolovertheavatar,thereisanincreaseinsocial
coordination[11].Such‘fusionary’interactionsareacomponentofwhatisdubbedthe“JIZAIBody"[21]:theconcept
bywhichacomputer-mediatedhumanbodycanseamlesslyadapttosocialstructurechanges,suchthatanyadditions
oralterations(virtualorphysical)wouldfeelasmuchtheirownastheiroriginalbody.Thisrelatestorecentefforts
towardsensiblehuman-computerintegration[7,40],whichextendsthenotionofcybernetics[62].Indeed,experiments
haveshownthatparticipantswhoco-embodyavirtualavatarreporthighlevelsofperceivedcontrol,withlowerlevels
ofactualcontrol[17,28].Thisenhancedperceptionofcontrolcanbeusefulforrehabilitationspecialistsandsupport
personnelthatuseimmersivetechnologyforthetreatmentofphysicalandcognitivefunctionofindividualsthathave
sufferedfromstroke[37]anddementia[69],respectively.Thesharedcontrolofvirtualco-embodimentprovidesan
assistivemethodologytoimproveaccessibilityforthesevulnerableindividualsduringthesetupandnavigationof
virtualenvironments.Incasesofstrokerehabilitation,co-embodimentcanalsobeincorporatedalongsidetechniques
ManuscriptsubmittedtoACMShareYourReality 3
suchasMirrorTherapy[36],toenrichmotorsupportintheVRsystembyincorporatingshared(human)assistanceto
adapttorequirementsforeachindividualneed.
Researchhasshownthatindividualscanadapttodifferentmediatoachievetheircommunicationgoals[43],where
thedegreeofembodimentandtimerequiredforsuchembodimentmayvarydependingonthevisualandvisuo-motor
consistencyoftheartificial(virtual)andbiologicalbody[1,10,25].Furthermore,whenanotherentitythatissentient
orappearstobesentientispresentinthesameenvironment,anotherdimensioncalled‘socialpresence’comesinto
play[42,54].Thedegreeofexperiencedsocialpresencedependsontheperson’sperceivedabilitytoaccessanother
individual’sintentions,intelligence,andsensoryimpressions.Immersivequalities,contextualproperties,andindividual
differences,canpredicttheextenttowhichsocialpresenceisexperiencedbyusersinVR[42].Withoutasufficient
levelofsocialpresence,theotherentityisperceivedasartificialandnotasanintentionalsocialbeing[42].Without
suchperceivedintentionality,sharedandcollaborativetasksbecomedifficult,makingahighsenseofsocialpresence
vitalforasmoothcollaborativeexperiencetooccurduringvirtualco-embodiment.
However,aspecificchallengeinco-embodimentisthatthevisualfeedbackaloneofthecombinedmotionofthe
sharedavatardoesnotfullyprovidetheintentionalinformationofone’spartnerbecausethesharedavatar’smotionis
partiallydeterminedbyone’sownmotion.Virtualco-embodimentleadstoasituationwherethereisanintermingling
ofself-presencewithsocialpresence,wheretheidentityoftheselfisintrinsicallylinkedtotheavatarandthepresence
ofanotherintentionalsubject.Thisintentionalityistranslatedthroughtheamountofcontrolavailableforeachperson
overthesharedavatar.Whileresearchershaveexploredvirtualco-embodimentinrelationtousers’perceptionof
theirembodimentofthesharedavatar[11,15]anditsuseformotorskilllearning[28,29],theroleofsocialpresence
anditsinfluenceonsocialcoordinationwithinthiscontexthasnotyetbeenfullycharacterized.Extensionsofthis
conceptbyHapuarachchiandKitazaki[18]andHapuarachchietal.[17]havehighlightedtheneedfornon-verbal
communicationmechanismstobeimplementedintheparadigmofco-embodimenttoenhancesenseofembodiment
towardstheco-embodiedavatar.Indeed,duringsuchco-embodimentexperiences,theillusionofsharedmotioncontrol
canbecoupledwithusercommunicationtechniquesthatsupportcoordination,highlightingtheneedforposition-aware
feedbackmechanisms[59].Hapticfeedbackmaybeespeciallyappropriateherebecauseitcanpositivelyinfluence
theexperienceofsocialpresence[42].Forthis,wedrawonAuvrayetal.[2]’shaptic’perceptualcrossingparadigm’,
whichwasconceivedtostudysocialinteractiondynamicsinrealtimethroughtactilesensorimotorinteractions[30].
Perceptualcrossingreferstosituationswheretwoperceptualactivitiesofthesamekindmeeteachother,suchaswhen
twopeoplecatcheachother’seye(jointgazeandattention[56]),ormutualsocialtouch[50].Thisparadigmoffers
usafoundationtobuildsystemsthatenablestudyingoffactorsinvolvedinmutualrecognitionbetweenpeoplein
remoteinteractions.Giventhefocusofco-embodimentscenariosonasenseofsharedcontrolwitharemotelylocated
otherperson,webelievetheperceptualcrossingparadigmlendsitselfwelltostudyingsensorimotorinteractionsin
co-embodiedVR.
Inthispaper,wedrawontheperceptualcrossingparadigm[2],toexplorehowhapticfeedbackcanbeintegratedinto
avirtualco-embodimentscenario,wherepairsofparticipantssharecontroloveravirtualhand.Buildingontheideaof
hapticperceptualcrossing,weimplementedhapticfeedback(on/off)whenusers’handpositionsoverlapinvirtualspace.
Weexaminehowhapticcuescanenableawarenessofeachotherandcoordinationbetweenco-embodiedparticipants.
Weask:(RQ)Howdohapticfeedbackmechanismsandvariedavatarcontroldistributioninfluenceusers’senseof
agency,co-presence,bodyownership,andmotionsynchronyintargetedandfree-choicevirtualavatarco-embodiment
tasks?Inacontrolled,within-subjectsstudywith20participantpairs,weexaminedtheeffectsofpositionalhaptic
feedback(None,Present)andavatarcontroldistribution(25-75%,50-50%,75-25%)acrosstwocubeselectiontasks
ManuscriptsubmittedtoACM4 Venkatrajetal.
50% 50%
User 1
User 2
Weighted average
shared avatar
Fig.2. Illustrationoftheweightedaveragevirtualco-embodimentmethod,wherethemotionofthesharedavatar(center)isgenerated
bytakingtheweightedaverageofthemotionofUser1(left)andUser2(right)
(Targeted,Free-choice)onparticipants’senseofagency(SoA),co-presence,bodyownership,andmotionsynchrony.
Ourfindingsshowed(a)alowersenseofagencyinthefree-choicewithhapticscomparedtonohapticfeedback,(b)
higheragencyduringthesharedtargettask,(c)co-presenceandembodimentweresignificantlyhigherintaskswhere
thereweremultipletargets,and(d)players’handmotionssynchronizedmoreinthetargetedtask.
Ourexploratoryworkofferstwoprimarycontributions:(1)Weintegratetheconceptofperceptualcrossinginto
theparadigmofvirtualco-embodimenttoenableposition-awarehapticnon-verbalcommunicationcuesbetweentwo
users;(2)Weprovideempiricallybackedinsightsshowingtheinfluenceofhapticsontheperceivedsenseofagency
duringtargetedandfree-choiceselectiontasksundervariablecontrolofsharedvirtualhands.
2 BACKGROUNDANDRELATEDWORK
Inthissection,wedescribepriorworkonvirtualco-embodiment,controlsharingtechniques,hapticsintegratedinto
co-embodimentexperiences,andtheperceptualcrossingparadigm.
ManuscriptsubmittedtoACMShareYourReality 5
2.1 Virtualavatarco-embodimentandtheSenseofAgency
Virtualco-embodimentreferstooccurrenceswheremultipleuserscansimultaneouslyinteractwiththevirtualenviron-
mentusingasharedavatar.Giventhattwoormoreindividualssharecontrolovertheavatar,thereisanincreasein
socialcoordination[11].Tothisend,priorworkhasshownthatparticipantswhoco-embodyavirtualavatarreported
highlevelsofperceivedcontrol,withlowerlevelsofweightedpercentageofactualcontrol[17,28].Thismakesita
promisingtoolforVR-basedrehabilitation[23]andtraining[14,19]applications,sincealearnerwithlowcontrolcan
feelastrongersenseofagency(SoA)whileperformingtheactivitywithateacherwithhighcontrol.Onedomainin
whichresearchersaretryingtoleveragetheimmersivecapabilitiesofVRisinthesupportandtreatmentofdementia
patients[69]–theseindividualsareconsideredvulnerableandtheytypicallyfinditchallengingtooperatebasicVR
controls[31].Insuchcases,co-embodimentcanenableassistiveaccessibilityfortheseindividuals,guidedbysupport
personnel.Thiswouldenablethemtonotonlytrain,butalsomaintainahighlevelofagencyduringsuchimmersive
experiences.Furthermore,VRhasshownpotentialforitsabilitytostimulateMirrorNeurons(MNs)oftheinternal
sensorimotorsystemofstrokepatients[5].Insuchsettings,patientsareimmersedintrainingscenariosinvirtual
environmentsthatinvolveexecutingmotoractions,suchasobservingandvisualizingmirrorlimbmovementswiththe
intenttoimitatetheseactions.ThesehaveshownenhancedMNactivation,leadingtofasterpost-strokerecovery[37].
Tothatend,co-embodimentcanbefurtherleveragedwithinthesetechniquesinordertoimprovetheeffectiveness
ofsuchtreatmentsthroughenhancedagencyandnuancedcontrolovermovementsexecutedbythepatientsactively
guidedbytheirtrainersorcaregivers.
Inthecontextofavatarco-embodiment,the‘SenseOfEmbodiment’(SoE)canbemanifestedthroughthreemain
components:SenseofSelf-Location,SenseofBodyOwnership,andtheSenseofAgency[27].SenseofSelf-Location
referstothefeelingof‘beinginside’avirtualbody,whilesenseofbodyownershipandagencyreferstothefeeling
of‘having’and‘controlling’thevirtualbody,respectively.Studieshaveexploredvariousfactorsandtheirinfluence
onthesecomponents,andhaveshownthatmanipulationsoftheoverallSoEarepossiblethroughchangesinavatar
representations,degreeofcontrol,andperspectiveoftheusers[10,41].Similarly,theinfluenceofsharingthevirtual
bodywithanotheruseranditseffectonSoEwasstudiedinexperimentsofvirtualco-embodiment.Here,thesenseof
agencyandbodyownershipplayapivotalrolethatdeterminestheengagementlevelduringthesharedperceptual
activity[11,15,17,18,29].
2.2 Avatarco-embodimentcontrolsharingtechniques
Torealizesuchco-embodiment,themotionofasharedavatarhaspreviouslybeengeneratedusingtwotechniques:the
weightedaverageco-embodimentmethod[11,15,28]andthebody-part-segmentedco-embodimentmethod[17,18].
Theweighted-averagemethodinvolvesassigningaweightbetween0and100percenttoeachuserandgeneratingthe
movementofthesharedavatarbyinterpolatingtheweightedaverageofthereal-timepositionandorientationofthe
controllersofboththeusers(Figure2)[11,15,28].Thebody-part-segmentedco-embodimentmethodisatechnique
wherethemotionofindependentlimbsofasharedavatariscontrolledbyeachuserseparately[17,18].Inthispaper
wefocusonthefirstmethod,wheresharedinteractionscanbemanipulatedbyboththeusersandtheirinfluenceis
determinedbythepercentageofcontroltheypossess.Sincewefocusonposition-awarefeedbackmechanisms,wedraw
ontheweighted-averagemethodtoenablethis.Resultsfrom[11,15,28]allshowedthatsenseofagencyincreased
withtheincreaseinthecontrolweightfortheparticipantduringavatarco-embodiment.Inallthestudies,participants
couldcoordinatetheirmovementsinjointaction,leadingtothesharingofmotorintentionandsynchronization.Ina
ManuscriptsubmittedtoACM6 Venkatrajetal.
follow-upstudybyKodamaetal.[29],theyevaluatedparticipants’taskperformanceandmotorskilllearningability.
Theyconcludedthatlearningusingvirtualco-embodimentwasmoreefficientthantheperspective-sharingmethod,in
whichatranslucentteacheravatarwassuperimposedonthelearner’sfirst-personperspectiveview.However,contrary
tothepreviousstudies,nosignificantdifferenceswereobservedbetweenthedifferentcontrolweightconditions.We
drawonthedesignconsiderationsfrom[11,15,28]todesignourstudyprotocol.
2.3 Hapticsforvirtualco-embodiedexperiences
SincetheearlydaysofVR,hapticfeedbackhasbeenacentralcomponentinmanyVRsystems[55]andhasbeen
usedtoenableadiversityoftouch-basedinteractionsinVR[60],withthemostcommontypeofhapticfeedbackin
VRapplicationsbeingvibrotactileandforcefeedback[65].Studiesthathaveexploredhapticsasacommunication
mediuminthecontextofsharedvirtualspacesreportenhanceduserexperiences[24,68].Importanttoourpresent
purposes,theadditionofhapticfeedbacktosocialVRhasbeenfoundtoconsistentlyenhanceperceivedsocialpresence
[42].Inworkonco-embodiment,theapplicationofhapticfeedbackisessentiallyunderstudied.Hapuarachchiand
Kitazaki[18]exploredthemanipulationofthesenseofagencybyprovidingvisualfeedbackofthepartner’starget
duringco-embodiment,andHapuarachchietal.[17]implementedpassivehapticsbyattachingabackbracetoboth
theusers,allowingthemtomaintainconsistentshoulderposturewhilecontrollingthesharedavatarusingthebody-
part-segmentedco-embodimentmethod.Theseexplorationshighlightthevalueofidentifyingwhattypeoffeedback
modalitiescanbeintegratedintothevirtualco-embodimentparadigmtoprovideuserswithadvancedperceptual
capabilities.Whilevisualfeedbackoffersmoreinformationtotheuser,itleadstocluttered,chaoticexperienceswhen
scaledup.Thus,hapticfeedbackprovidesanalternativetoovercomethislimitation.Thechallengeinthecontextof
co-embodimentistodesignthefeedbackmechanisminawaythatdoesnotincreasethecognitiveloadrequiredto
differentiatebetweentheinteractionwiththeenvironmentandthepresenceoftheotheruser.Giventheforegoing,we
implementhapticfeedbackasacommunicationmediumtoindicatetheotherusers’positionduringco-embodiment.
2.4 Perceptualcrossingparadigmforenhancingsocialcoordination
Theperceptualcrossingparadigm[2]wasconceivedtostudysocialinteractiondynamicsinrealtimethroughtactile
sensorimotorinteractions[30].Theclassicalparadigmfeaturesaminimalist1Denvironment–aline–thatloopsaround
creatingacontinuousinteractionspacenotvisibletotheusers.Twousersareeachrepresentedinthevirtualspace
byanavatar(adot)thattheycancontrolusingastandardcomputermouse.Whentheiravatarencountersavirtual
objectinthe1Dspacetheyreceivehapticfeedback.Therearethreetypesofobjectsintheenvironment:astaticobject,
theuser’savatars,andtheuser’s’shadow,’anobjectthatmoveswiththeusers’avatarsatasetdistance.Allobjects
haveexactlythesamesizeandproducethesamehapticfeedbackwhenencountered.Whenoneuserencountersthe
shadowoftheotheruser,onlytheinteractinguserreceiveshapticfeedbackwhiletheotheruser(towhomtheshadow
belongs),doesnot.Theonlyconditionwhenbothusersreceivehapticfeedbacksimultaneouslyiswhenbothusers’
avatarsencountereachother.Usersaretaskedwithclickingthemousewhentheythinktheyareinteractingwiththe
avataroftheotheruser.Intheoriginalstudies[2,3],usersweresuccessfullyabletolocateeachotherinthe1Dvirtual
space.However,theprobabilityofclickingwhenencounteringanotheruser’savatarwasnotsignificantlyhigherthan
clickingwhenencounteringanotheruser’sshadow.Successfulidentificationoftheothercouldonlybeexplainedby
thestabilityofmutualrecognition;userswouldencounteroneanother,moveback,encountereachotheragain,and
repeat,creatinganoscillatingmovementpatternofrepeatedencounters.Inotherwords,userswouldonlysuccessfully
recognizeeachotherduringperceptualcrossing(i.e.,perceptualactivitiesofthesamekindmeeteachother).
ManuscriptsubmittedtoACMShareYourReality 7
Haptic feedback Control distribution Task
No haptic feedback (NH) W25 = User 1 (25%) + User 2 (75%) Task 1 24
Haptic feedback on overlap (H) X W W5 750 == UU ss ee rr 11 (( 75 50 %% )) ++ UU ss ee rr 22 (( 25 50 %% )) x p2 e rr e tap se ktitionsX Task 2 = Trials
Pre-study Training Task 1 Task 1 Task 2 Task 2 Post-study
Consent form 1 User Targeted Targeted Free-choice Free-choice
IPQ
Demographics Instructions Trial Trial Trial Trial
Post-study SSQ
Pre-study SSQ
Wear & adjust HMD
Tra Trin iain lg QuS eo sA
tion
QuS eo sA
tion
QuS eo sA
tion
QuS eo sA
tion
S ine tm eri v-s iet wructured
+controllers x 1 trial x 6 trials x 6 trials x 6 trials x 6 trials
~60 min
Fig.3. DiagramillustratingthedifferentphasesoftheStudyprocedure,alongwithtextuallabelsexplainingeachcomponent
Extensionsofthebasicparadigmhaveshownthat,inateam-basedversionoftheparadigmwhereuserswere
instructedtocollaborate,participantssuccessfullyidentifiedtheother’savatarand,forthoseencounters,reportedthe
clearestawarenessoftheothers’presence[12].Aversionoftheparadigmthatusedafollowingtaskinaskewed1D
environmenthighlightedthatusersweresuccessfulinfollowingeachother’smovementsthroughhapticperceptual
crossing[32].Thoughpartofthestrengthoftheperceptualcrossingparadigmliesintheminimalistapproach,2D
extensionshavealreadybeensuccessful[33].Tothebestofourknowledge,no3Dimplementationsoftheparadigm
haveeverbeenattempted.Weseeaninterestingopportunityintheimplementationoftheparadigm’sbasicpremise
(i.e.,hapticfeedbackuponcontactinavirtualspacetosignifythepresenceoftheother)asaninteractivecuethatcould
aidmovementcoordinationaswellasenhanceperceivedsocialpresenceinvirtualco-embodimentscenarios.
3 METHODS
Inthissection,wedescribeourresearchmethodology,includingthestudydesign,experimentalprotocol,objectiveand
subjectivemeasures,ourhardwareandsoftwaresetup,studyprocedure,andparticipantsample.
3.1 Studydesign
OurstudyhastwomainIndependentVariables(IVs),andfollowsa3(IV1:ControlDistribution:25-75%vs.50-50%vs.
75-25%)x2(IV2:HapticFeedback:Nonevs.Present)within-subjectdesign,testedinacontrolled,virtualenvironment.
Thecontroldistributionconsistedofthreesetsofweighingplayeroneandplayertwo’scontroloverthesharedavatar:
25-75%,50-50%,75-25%(referredtoasW25,W50,W75).Therewaseithernohapticfeedback(NH)orhapticfeedback
whenparticipants’handsoverlapped(H)inthevirtualspace.Thisinteractionwasdesignedusingvirtualspheres
(radius8cm),whichisapproximatelythesizeofthevirtualhandmeshthatwasattachedtothecontrollersinthe
virtualenvironment.Whenthespheresofeachuserintersectwitheachother,thehapticfeedbackistriggeredforboth
theusers.Thestudywasdividedintothreephases:Training,Task1,andTask2(Figure3).Thereweresixdistinct
conditions(3controldistributionx2hapticfeedback)foreachtaskthatwasperformedbyapairofparticipants.The
experimentconsistedoftwotaskswhereeachoftheseconditionswererepeatedtwice,bringingthetotalto24(2tasks
x2repetitions)trialsfortheentirestudy.Thesubjectiveresponsesoftheparticipantsonthesenseofagencywere
collectedwithaquestionnaireaftereachtrial,whilethesenseofco-presenceandembodimentquestionnaireswere
collectedaftereachhapticfeedbackcondition/block(aftersixtrials).Task1wasalwaysperformedbeforeTask2,and
thetwohapticfeedbackconditionswerecounterbalancedaccordingtoaLatinsquaredesignsuchthatstartingtrial
ManuscriptsubmittedtoACM
tnemidobmE
+ ecneserp-oC
eriannoitseuQ
tnemidobmE
+ ecneserp-oC
eriannoitseuQ
tnemidobmE
+ ecneserp-oC
eriannoitseuQ
tnemidobmE
+ ecneserp-oC
eriannoitseuQ8 Venkatrajetal.
ofeachsessionconsistedofallpossiblecombinationsofhapticandcontrolconditions,withtheremainderoftrials
subsequentlyrandomizedtomitigateordereffects.Thestudywasdesignedsuchthatasampleconsistsofpairsof
participants.Forexample,inasession,participant1wouldperformthetaskwith25%controlfourtimes(4x),twice
withandtwicewithouthapticfeedback,whiletheircounterparthad75%control(performedalso4x).Similarlyfor
50%(4x)and75%(4x).Thereforefor"25%","75%",and"50%",therewere4samplesforeachtask(twicewithandtwice
withouthapticfeedback).
3.2 Protocol
3.2.1 Jointactionreachingtasks. Themostcommonmethodtoevaluatevirtualco-embodimentisusingareaching
task.Inthistask,participantstouchanobjectsuchasacube[15]orsphere[11,18]usingasharedavatar.Thistask
typicallyfocusesonlyonparticipants’motion,asaddingadditionalinteractions(e.g.,buttonpresses)canincrease
taskcomplexity,whichmayrenderthetaskunsuitableforstudyingsharedcontrol.Fribourgetal.[11]introduceda
reachingtask,forthreescenarios:free,target,andtrajectory.Duringthefreetask,eachparticipantwasfreetochoose
anyspheretotouch,whilethespheretobetouchedwashighlightedinthetargettask.Thetrajectorytaskinvolved
followingaparticularpathbeforetouchingahighlightedsphere,anditfocusedmoreonprecision.Tohelpanswerour
RQ,weneedtobetterunderstandtheinfluenceofmovementfreedomandintentiononthelevelofembodiment(sense
ofagencyandbodyownership)overthesharedavatarusinghaptics.Therefore,weimplementedtworeachingtasks:
targeted(Task1)andfree-choice(Task2),whichwedescribebelow.
3.2.2 Training. Inthetrainingphase,basiccontrolsofourVRsystemwereexplainedtoeachparticipant,includinghow
tousethecontrollerbuttonstointeractwithwidgetsinthescene.Afterward,eachparticipantperformedanindividual
training trial, which showed the participants how to complete Task 1. Since the training session was performed
individually,nohapticfeedbackwasprovidedbeforehand,sincethiscanonlyoccurinthelaterpartofthestudy
involvingco-embodiment.
3.2.3 Task1:Targeted. InTask1,participantsusedthesharedrighthandoftheavatartotouchacubethatspawnedin
theirfieldofview(Figure4(a)).Oncethesharedhandcollidedwiththecube,thecubewouldberemoved.Afterasecond
delay,anothercubewasspawnedatapseudo-randomizedlocation1(Figure4(b)).Thelocationwaspseudo-randomized,
insteadofpre-generated,tominimizelearningeffects.Thedelayprovidedasmallresettimefortheparticipantsto
avoidphysicalandcognitivefatigue.Aspatialchimesoundalsooriginatedfromthespawnedlocationofthecube,to
indicatetoparticipantsthelocationofthenewcubeasitisdifficultforuserstorealizeifthecubehasappearedata
locationthatisnotwithintheirfieldofview.Participantshadtotouchthecubeatotalof17timesineachtrialduring
Task1.
3.2.4 Task2:Free-choice. InTask2,fivecubesarespawnedinfrontoftheparticipants,whohadtomovetheshared
handtotouchanyofthemtoprogress(Figure5).Inthiscase,whenthesharedhandcollidedwithanyofthecubes,all
thecubeswouldgetremoved,andafteraseconddelay,allthecubeswouldre-spawnbackinthesamepositions.During
Task2,ineachtrial,participantshadtotouchoneofthefivecubesatotaloffivetimestoproceed.Thistaskwasdesigned
tosimulateascenariowhereparticipantswouldhavetocollaborativelychoosetheco-embodiedmovementwithout
verbalcommunication.Thisprovidedasuitablescenariotoinvestigateiftheposition-awarefeedbackmechanism
modeledontheperceptualcrossingparadigmwillenabletheco-embodieduserstoworktogether.
1Therandomlocationswerelimitedtowithinthespaceinfrontoftheparticipantstoensurethecubeswerevisibleandreachable.
ManuscriptsubmittedtoACMShareYourReality 9
(a)Cubespawnedinparticipant’sfieldofview (b)Cubespawnedinnextpositionaftercollisionwithvirtualhand
Fig.4. First-personperspectiveofcubeinteractioninthetargetedtask
Fig.5. First-personperspectiveofcubeinteractioninthefree-choicetask
3.3 Measures
3.3.1 Objectivemeasures. Theorientation(Roll,Pitch,andYaw)andposition(X,Y,Zcoordinates)ofbothparticipants’
HMD and controllers were recorded at the applications’ default sampling rate of 70Hz during the entire session.
ManuscriptsubmittedtoACM10 Venkatrajetal.
Additionally,thestartandendtimeofeachtrialandthedurationofoverlapoftheparticipants’righthandswere
recorded.
3.3.2 Subjectivemeasures. ParticipantsfilledintheSimulatorSicknessQuestionnaire(SSQ)[26]beforeandafterthe
study.Additionally,participantsfilledintheIgroupPresenceQuestionnaire(IPQ)[51]attheendofthestudy.
DuringTask1andTask2,participantsusedtheOculusmotioncontrollerstoprovideaLikert-scaleratingranging
from"notatall"(1)to"fullyincontrol"(7)forthequestion“Howmuchdoyoufeelincontrol?”aftereachtrialtomeasure
theirsubjective“SenseofAgency”overthesharedavatar.ThesequestionswereembeddedaspanelsinVR,allowing
participantstostayimmersedintheVRexperience[47].Aftereachhapticfeedbackcondition,participantswould
answerthreequestionsabouttheir“senseofco-presence”andthreequestionsabouttheir“senseofbodyownership”,
takenfromstandardquestionnairesofco-presence[46]andavatarembodiment[44].Giventhesequestionsbelongto
twodifferentquestionnaires,wecalculatethereliabilityscoresseparately.Thesesixquestionswereselectedbasedon
theirrelevancetothestudydesign,whilereducingparticipants’workloadandthetotalsessiontimecomparedtousing
thefullquestionnaires.
Co-presence(CP)questionnaire(Cronbach’s𝛼=0.87)
(1) IfeltthatIwasinthepresenceoftheotherperson
(2) IfeltthattheotherpersonandIweretogetherinthesamespace
(3) Ifeltthattheotherpersonrespondedtoshiftsinmymovement(e.g.,posture,position)
BodyOwnership(BO)questionnaire(Cronbach’s𝛼=0.58)
(1) Ifeltasifmy(real)handsweredriftingtowardthevirtualhandsorasifthevirtualhandsweredriftingtoward
my(real)hands
(2) Ifeltasifthemovementsofthevirtualhandswereinfluencingmyownmovements
(3) Atsomepoint,itfeltasifmyrealhandswerestartingtotakeonthepostureorshapeofthevirtualhandsthatI
saw
3.4 Hardwareandsoftwaresetup
ParticipantsperformedthestudyusingOculusQuest2Head-MountedDisplays(HMDs)andOculusTouchVRmotion
controllersconnectedtodesktopcomputers.ThesecomputersranthevirtualenvironmentwecreatedusingUnreal
Engine5.12,andwereconnectedwithEthernettoensureminimumlatencybetweenthecomputers.Onecomputer
hostsalocalserverwhilethesecondcomputerjoinedthisserverasaclient.Eachcomputerrecordedtherotationand
positionoftheirrespectiveusers.Tocreateaco-embodiedavatar,thelevelspawnsa“sharedhands”avatarinthe
virtualworld.Thisvirtualrepresentationwaschosentomodelagenderneutralrepresentationofhands(cf.,[52]).Since
thecontrollerwasnotrepresentedinvirtualspace,wedidnothavethepositionofthehandtobewrappedaround
thecontroller,andinsteadshowedadefaultopenpalmpositionpose.Todeterminethepositionofeachoftheshared
hands,theavatarlinearlyinterpolatesbetweenthepositionofUser1andUser2,expressedbythefollowingequation:
x fusion=𝛼xuser1+(1−𝛼)xuser2 (0<𝛼 <1) (1)
2https://www.unrealengine.com/
ManuscriptsubmittedtoACMShareYourReality 11
Intermittent Sinusoidal
Heartbeat Constant
Fig.6. Waveformsoffourvibrationpatternsusedinpre-study(createdinUnrealEngine):Intermittent(topleft),Sinusoidal(top
right),Heartbeat(bottomleft)andConstant(bottomright)
where𝛼 controlstheinterpolationsuchthattheresultingpositionis100%ofPlayer1when𝛼 is1and100%ofPlayer
2’spositionwhen𝛼is0.ThisvaluecanbesettovarythecontroloverthesharedhandsineachleveltoW25/W50/W75
tocreatetheconditionsoutlinedinthestudydesign.
3.4.1 Hapticfeedbackdesign. PreviousexperimentsbyWentzeletal.[61]testedtechniquestomodulateamplification
levelsofvibrationsandfoundthatitimpactedtheuser’scomfort.Sinceourstudyismodelledontheperceptualcrossing
paradigm[2],whichusessimplisticON/OFFfeedbackforinteractionsbetweentheparticipants,wealsoimplement
thehapticfeedbacktoONwhenparticipantshandsareinthesamevirtualpositionandOFFotherwise.Noadditional
hardwareisimplementedforsophisticatedvibrotactilefeedbackcuesasthescopeofthisstudyislimitedtousing
thestandardoculusmotioncontrollers.Therefore,weconductedapre-studytomakeaninformeddecisiononthe
intensityandpatternofthevibrations.FifteenParticipants(Meanage=25.66,SD=2.09)testedfourcommontype
vibrationpatterns[53]:Intermittent,Sinusoidal,Heartbeat,andConstant(Figure6)incombinationwithfourintensity
levels:10,20,30,and40.Theintermittentpatternconsistedoftwovibrationoccurrenceseverysecond,thesinusoidal
hadoneoccurrencepersecond,theheartbeatpatternconsistedoftwoshortoccurrencesfollowedbyapauseevery
second,andtheconstantpatternhadacontinuousvibrationthroughout.TheseweretestedinVRusingthesame
motioncontrollersthatwouldbeusedforthemainstudy.Whilereceivinghapticfeedback,participantsratedona
Likertscaletheirperceivedcomfortrangingfromveryuncomfortable(1)toverycomfortable(7),andtheirperceived
intensitylevelrangingfromverycalm(1)toveryintense(7).
ManuscriptsubmittedtoACM12 Venkatrajetal.
Patterntype Pattern Perceived Perceived
intensity (mean) (mean)
intensity comfort
Intermittent 10 3.2 4.4
Intermittent 20 3.6 4.4
Intermittent 30 4.5 3.8
Intermittent 40 5.2 3.4
Heartbeat 10 1.8 5.2
Heartbeat 20 3.3 4.2
Heartbeat 30 3.4 3.9
Heartbeat 40 4 3.8
Sinusoidal 10 3.4 5.1
Sinusoidal 20 4.2 4.4
Sinusoidal 30 5.4 3.8
Sinusoidal 40 4.2 3.6
Constant 10 3.8 4.1
Constant 20 5.3 3.2
Constant 30 6.6 2.4
Constant 40 6.7 2.2
Table1. Resultsofourpre-studyonperceivedmeanintensityandcomfortfor16hapticpatterns.Themeanperceivedintensity
ratingsrangebetween1.8to6.7(where1isverycalmand7veryintense)andthemeanperceivedcomfortratingsrangebetween2.2
to5.2(where1isveryuncomfortableand7verycomfortable).Thechosenvariant"sinusoidalpatternwithintensity20"receiveda
meanintensityratingof4.2andcomfortratingof4.4.
FromTable1,resultsshowedthathigh-intensityvibrations(30,40)hadlowercomfortratingsoverall.Thehighest
comfortratingwasgiventotheheartbeatandsinusoidalpatternsatintensity10.However,thisintensitylevelwasoften
hardlynoticeablebysomeparticipants.Thevariantwiththesinusoidalpatternatintensity20,providedabalancedlevel
ofintensity(meanscore=4.266)whilestillbeingcomfortable(meanscore=4.4).Therefore,wechosetoimplement
thisvariantofthehapticfeedbackforourmainstudy.
3.5 Studyprocedure
Atthestudylocation,atablewasplacedwhereparticipantswouldfilloutalltheforms:demographics,informed
consent,pre-andpost-studySSQ,andIPQ.Twocomputerswereplacedsidebysideonaseparatetableandwere
connectedtoHMDs(Figure7).OneparticipantwasrandomlyassignedtothecomputeractingasUser1,andthe
othertothecomputeractingasUser2.Avideocamerawasalsoinplacetorecordbothparticipants’motionswhile
theyperformedthetasks.AvideoshowingthisinteractionisprovidedinSupplementaryMaterialA.Thepositionin
whichbothparticipantswouldstandwasmarkedonthefloor.Toreduceanypossibilityofinjuryandtosimplifythe
interactions,participantsconductedthetrialswhilestanding,andonlyusedtheirrighthandforthemotiontask.The
spatialchimesoundwaschanneledthroughtheHMDspeakers,setatacomfortable60%volume.
Upontheirarrival,participantswereaskedtoreadandsigntheinformedconsentformandfillinapre-study
SSQ.SimilartoFribourgetal.[11],participantswerebriefedthattheywouldbesharingtheavatarduringalltrials
andinstructedtoavoidcommunicatingwitheachotherverbally.Noinstructionswereprovidedregardingthehaptic
feedback,allowingparticipantstointerpretthemeaningofthevibrotactilecuewhenitoccursduringthetasks.This
wasdonetoevaluatetheeffectivenessofthechosenvibrationpatterninestablishingsynchronizationpatternsbetween
participantsautonomously,aswasdoneintheoriginalperceptualcrossingexperiments[2,3].Participantsprovided
subjectiveratingsontheirsenseofagency,co-presence,andbodyownershipaftereachsetoftrialsusingquestionnaires
ManuscriptsubmittedtoACMShareYourReality 13
Fig.7. Animageofthestudysetupthatshowstwousersperformingatask,andthetwocomputerscreensshowingtheperspective
viewofeachuser
presentedinsidethevirtualenvironment.Eachparticipantperformed25trials(includingrepetitions),andanswered
32questionsduringthestudy(24SenseofAgency+4Co-presence+4Bodyownership).Attheendofthestudy,
participantsfilledinthepost-studySSQalongwiththeIPQ.Finally,asemi-structuredinterviewwasconductedwith
bothparticipants,whichlastedaround15minutes.Duringtheinterviews,weaskedparticipantsabouttheiroverall
impressionofthestudy,theirperceptionsofthesharedmotionandthehapticfeedback,theirimpressionsregarding
thetwotasks,andprovocationsregardingfurtherusecasesofvirtualco-embodiment.Thecompleteinterviewguideis
providedinSupplementaryMaterialB.Sessionslastedanaverageof60minutes,whereasthewithin-VRportiontook
approximately25minutes.Eachparticipantwascompensatedwitha€/$10giftvoucherforparticipating.Ourstudy
receivedapprovalfromourinstitute’sethicsanddataprotectioncommittee,wherewealsofollowedanyguidelines
pertainingtoanyprevailingcleanliness(cf.,COVID-19)regulations.
3.5.1 Participants. Twenty pairs of participants3 (40 people, 23f, 17m) were recruited (M=25.95 years, SD=2.59).
Participantswererecruitedprimarilyfromthefirstauthor’suniversity.Allwereright-handed.Fifteenparticipants
reportednopriorVRexperience;17reportedbeingnoviceusers(havingusedVRatleastonce),andeightreported
occasionalVRuse.Ofthe20pairs,threewerecouples,12werefriends,andfivedidnotknoweachother(i.e.,strangers).
Therewerethreemale-malepairs(twofriendpairs,onestrangerpair).Thereweresixfemale-femalepairs(fivefriend
pairs,onestrangerpair).Therewereelevenmale-femalemixedpairs(threewerecouples,sixwerefriendpairs,two
werestrangerpairs).
3Foreffectsizef=0.25under𝛼=0.05andpower(1-𝛽)=0.95,with24repeatedmeasurementswithinfactors,aminimumof12participantsisneeded.
ManuscriptsubmittedtoACM14 Venkatrajetal.
4 ANALYSISANDRESULTS
Amixed-methodsapproachwasadoptedforanalysis,whichmeanstheresultsofthequantitativeanalysisareinterpreted
alongwiththequalitativeanalysistoexplainthephenomenaobserved.
4.1 Pre-processingandanalysisapproach
4.1.1 Synchronymeasure. Users’handmotiondatawasre-sampledto100Hz.Wecleanedthedatabyremovingmissing
values,NAs(NotAvailable)duetologgingerrors,andduplicates.Thisresultedintheremovalof11,679records,with
afinaldatasetsize=880,549records.Severalmeasuresofinter-personalsynchronyexist,fromdyadicsynchronyin
VRaswasdonebySunetal.(2019)[57],tobreathingsynchronyaswasdonebyElAlietal.(2023)[8].Givenour
dataset,weanalyzejointmotionsynchronybyadaptingSunetal.’s[57]approach—weperformthefollowingstepsto
obtainoursynchronymeasures:Theextracted<X,Y,Z>positionalmovementdatawasusedtocalculatethedistance
movedbetweeneachtimestampforeachparticipant.WecalculatetheEuclideandistancesforthemovementofboth
participants,bytakingthesquareofthedifferencebetweentheconsecutivepositionsineachdirection(X,YandZ).We
thencomputethesquarerootofthesumofthesesquareddifferencestocalculatetheoverallEuclideandistanceforthe
movementbetweeneachtimestamp.Theintervalsofthetimestampsthatareconsideredforthiscalculationareshort
(intheorderofmilliseconds),thereforeanyrepeatedmovements(leftandright)thatoccuroveranintervalwillbe
captured,andwillbedifferentfromacontinuousmotioninasingledirection.
WethencomputetherollingSpearmancorrelationbetweeneachparticipants’summed(righthand)Euclidean
movement.SinceourEuclideanmeasureswerenotnormallydistributed,weusedrollingSpearman’sRankCorrelation
Coefficientwithawindowsizeof450samplestocomparethetwomovementseries.ThemeanoftherollingSpearman’s
RankCorrelationCoefficientwasthencalculatedforall24trialsacrossthe20sessions4.
4.1.2 Statisticalanalysisapproach. Thecombinedeffectsoftask,control,andhapticsonparticipants’subjectiveratings
ofperceivedSenseofAgency(SoA),co-presence,bodyownership,andmeanSpearman’sRankCorrelationCoefficient
wereanalyzedbyfittingafullmixed-effectsmodelforeachdataset.First,thenormalityofthedatawastestedusingthe
Shapiro-Wilktest.Resultsforalldependentvariablesshowedthatthedatadistributionsignificantlydeviatedfrom
normality(p<0.05).Therefore,alignedranktransformswereappliedtothedatabeforefittingittothemodel[63].
Holm-Bonferronicorrectionswereappliedtothedatasets,andcontrasttestswereconductedusingART-C[9].The
resultsoftheanalysisofvarianceforallresponsevariablesareprovidedinTable2.
4.2 Quantitativeresults
4.2.1 SenseofAgency. TheanalysisoftheSenseofAgency(SoA)ratingsareshownasboxplotsinFigure8(a),where
lineswithasterisksindicatepairwise,Holm-Bonferronicorrected,significance.Afullmixed-effectsmodelshowed
significanceforTaskandHaptics(p<0.000).SignificantinteractioneffectswerealsofoundbetweenTaskandHaptics(p
<0.000).ContrasttestsforthemaineffectofTaskrevealedthatresponsesweresignificantlyhigherinTask1compared
toTask2.Moreover,thecontrasttestforHapticsrevealedthatparticipants’feelingsofcontrolweresignificantlygreater
inconditionswithouthapticfeedbackcomparedtoconditionswithhapticfeedback.Thecontrasttestontheinteraction
effectsbetweenTaskandHapticsshowedsignificantdifferencesacrossalllevelsexceptbetweenTask1-Nohaptics
conditionxTask1-Hapticscondition(p=0.219).
4Weadditionallytestedcosinesimilaritymeasures,givenWohltjenetal.[64]’sapproachthatusedDynamicTimeWarpingtocalculatecosinesimilarity
scores;however,theresultsweresimilartoours,andthereforeweonlyreporttheSpearmanRankcorrelationresults.
ManuscriptsubmittedtoACMShareYourReality 15
ResponseVariable Factor Level Mean Median SD F df p 𝜂 𝑝2
SenseofAgency Task1 4.53 5.00 1.44
Task 172.02 1 <.000*** 0.16
Task2 3.45 3.00 1.45
On 3.86 4.00 1.57
Haptics 12.93 1 <.000*** 0.01
Off 4.12 4.00 1.5
W25 4.05 4.00 1.53
0
Control W50 3.97 4.00 1.54 0.24 2 0.78
W75 3.96 4.00 1.56
TaskxHaptics - - - - 13.61 1 <.000*** 0.01
TaskxControl - - - - 0.30 2 0.74 0
HapticsxControl - - - - 0.52 2 0.59 0
TaskxHapticsxControl - - - - 0.05 2 0.95 0
Co-presence1 Task1 4.30 5.00 2.00
Task 26.35 1 <.000*** 0.18
Task2 5.35 6.00 1.64
On 4.84 5.00 1.88
Haptics 0.24 1 0.62 0
Off 4.81 5.00 1.93
TaskxHaptics - - - - 0.80 1 0.37 0.01
Co-presence2 Task1 3.54 3.00 1.92
Task 34.38 1 <.000*** 0.23
Task2 4.71 5.00 1.81
On 4.15 4.00 1.95
Haptics 0.03 1 0.86 0
Off 4.10 4.00 1.96
TaskxHaptics - - - - 2.31 1 0.13 0.02
Co-presence3 Task1 3.68 4.00 1.80
Task 28.28 1 <.000*** 0.19
Task2 4.80 5.00 1.76
On 4.09 4.00 1.86
Haptics 1.24 1 0.27 0.01
Off 4.39 5.00 1.86
TaskxHaptics - - - - 0.51 1 0.48 0
BodyOwnership1 Task1 5.29 5.00 1.08
Task 1.72 1 0.19 0.01
Task2 4.93 5.00 1.45
On 5.00 5.00 1.27
Haptics 1.42 1 0.24 0.01
Off 5.21 5.00 1.30
TaskxHaptics - - - - 0.22 1 0.64 0
BodyOwnership2 Task1 5.15 5.00 1.30 <
Task 0.38 1 .001** 0.08
Task2 5.55 6.00 1.47
On 5.30 6.00 1.30
Haptics 1.00 1 0.32 0.01
Off 5.40 6.00 1.51
TaskxHaptics - - - - 1.31 1 0.26 0.01
BodyOwnership3 Task1 4.43 4.50 1.40
Task 0.99 1 0.32 0.01
Task2 4.23 4.00 1.58
On 4.31 4.00 1.45
Haptics 0.01 1 0.94 0.00
Off 4.34 4.50 1.54
TaskxHaptics - - - - 0.09 1 0.77 0
MeanRollingSpearman’sRank Task1 0.39 0.41 0.21
Task 57.15 1 <.000*** 0.11
Correlationcoefficient
Task2 0.27 0.25 0.20
On 0.34 0.36 0.20
Haptics 2.02 1 0.15 0
Off 0.32 0.33 0.22
W25 0.34 0.37 0.21
Control W50 0.31 0.28 0.21 2.96 1 0.08 0
W75 0.34 0.36 0.22
TaskxHaptics - - - - 1.10 1 0.29 0
TaskxControl - - - - 0.04 1 0.83 0
HapticsxControl - - - - 0.25 1 0.61 0
TaskxHapticsxControl - - - - 2.36 1 0.12 0
Table2. AnalysisofDevianceonthefullmixed-effectsmodelforSenseofAngency(SoA),co-presence,bodyownershipandmean
rollingSpearmanRankCorrelationusingAlignedRankTransformeddata.ForSenseofAgency,themodelshowssignificanceforthe
factorsTask,HapticsandtheinteractionofTaskandHaptics(***p<0.001).ForCo-presence1,Co-presencMea2naunscdriCptos-upbrmesitetnedceto3A,tChMe
modelshowssignificanceonlyfortheTaskfactor(***p<0.001).ForBodyownership2,themodelshowssignificanceonlyfortheTask
factor(**p<0.01)andforMeanrollingSpearman’srankcorrelationcoefficient,themodelshowssignificanceonlyfortheTaskfactor
(***p<0.001).16 Venkatrajetal.
(a) PerceivedSenseofAgency(SoA)ratingsforTask-Hapticcondi-(b)PerceivedSenseofAgency(SoA)ratingscorrespondingtocontrol
tionswherelineswithasterisksindicatingpairwiseHolm-Bonferroni-distributionforeachtask
correctedsignificance
Fig.8. Senseofagencyresponsestothequestion“Howmuchdoyoufeelincontrol?”askedaftereverytrialduringthestudy.
ThecomparisonofthereportedSoAwithrespecttotheactualcontrolthatparticipantshadoverthesharedavataris
shownasboxplotsinFigure8(b).ParticipantstendedtooverestimateandratehigherSoAwhentheyhadonly25%
control(Md=5,M=4.47,SD=1.4)and50%control(Md=5,M=4.49,SD=1.45)inTask1.However,inthecaseof75%control
(Md=4,M=4.48,SD=1.47)inTask1,participantsfeltlowerlevelofcontroloverthesharedavatar.Weobservecontrasting
resultsforTask2,whereratingsforconditionsof25%control(Md=3,M=3.39,SD=1.42)wereratedthelowestfollowed
byratingsfor50%control(Md=4,M=3.45,SD=1.44).Notably,inthecaseof75%control(Md=3.5,M=3.43,SD=1.5),
participantsratedlowerSoAinTask2comparedtoTask1.
GiventhattheSoAmeasurewastheonlytimeseriesmeasurementwecollected,wefurtherconductedtemporal
analysis to assess whether these ratings changed across trials. While there were some changes in the responses
(indicatingparticipantswerenotrandomlyassigningratings),thelowcorrelationsandlackofvisiblepatternsdid
notwarrantfurtherstatisticalanalysis.Weprovidethisanalysis(SoAratingplotsovertrialandcorrelationplot)in
SupplementaryMaterialC.
4.2.2 Co-presence. Participantratingsoftheco-presencequestionnairearevisualizedasboxplotsinFigure9,where
lineswithasterisksindicatepairwiseHolm-Bonferroni-correctedsignificance.Afullmixed-effectsmodelshowed
significanceonlyforTaskacrossallthreeresponses.Nosignificantinteractioneffectswerefound.Contraststestshowed
thatco-presenceratingsweresignificantlyhigherinTask2comparedwithTask1forCo-presence1,Co-presence2,
andCo-presence3.
4.2.3 Bodyownership. Analysisofparticipantratingsforthebodyownershipquestionnairearevisualizedasboxplots
inFigure10(a),wherelineswithasterisksindicatepairwiseHolm-Bonferroni-correctedsignificance.Afullmixed-effects
modelshowedsignificanceonlyforTaskforbodyownership2responses.Nosignificantinteractioneffectswerefound.
ContrasttestsshowedthatbodyOwnership2ratingsweresignificantlyhigherinTask2comparedwithTask1.
ManuscriptsubmittedtoACM
sgnitar
ycnega
fo
esneSShareYourReality 17
Co-presence 1 Co-presence 2 Co-presence 3
CP1 CP2 CP3 CP1 CP2 CP3
(a)PerceivedCo-presenceratingsforeachquestionforeachtaskwhere (b)Co-presence(CP)ratingsperquestionforhapticsconditions
lineswithasterisksindicatingpairwiseHolm-Bonferroni-correctedsig-
nificance
Fig.9. Co-presence(CP)questionnaireresponses.Co-presence
1:“IfeltthatIwasinthepresenceoftheotherperson";Co-presence2:“IfeltthattheotherpersonandIweretogetherin
thesamespace";Co-presence3:“Ifeltthattheotherpersonrespondedtoshiftsinmymovement"Bonferroni-corrected
significance.Ontheright(b)theperceivedcopresenceratingsperquestionforhapticfeedbackconditionsshownas
boxplots.
Body ownership 1 Body ownership 2 Body ownership 3
BO1 BO2 BO3 BO1 BO2 BO3
(a)Perceivedbodyownership(BO)ratingsovervirtualhandsforeach (b)Bodyownership(BO)ratingsperquestionforhapticsconditions
questionforeachtaskwherelineswithasterisksindicatingpairwise
Holm-Bonferroni-correctedsignificance
Fig.10. Bodyownership(BO)questionnaireresponses.Bodyownership
1:“Ifeltasifmy(real)handsweredriftingtowardthevirtualhandsorasifthevirtualhandsweredriftingtowardmy
(real)hands";Bodyownership2:“Ifeltasifthemovementsofthevirtualhandswereinfluencingmyownmovements";
Bodyownership3:“Atsomepoint,itfeltasifmyrealhandswerestartingtotakeonthepostureorshapeofthevirtual
handsthatIsaw"
4.2.4 Controllermotionsynchronization. Theanalysisofparticipants’controllermotionsynchronizationisvisualized
astime-seriesplotinFigure11.Afullmixed-effectsmodelshowedsignificanceforTask.Nosignificantinteraction
ManuscriptsubmittedtoACM18 Venkatrajetal.
Task 1 trials Task 2 trials
Fig.11. Motioncontrollersynchronization(usingrollingSpearman’sRankCorrelationwith450samples)betweenusers.Plotshows
synchronyacrosstrialsforeachsession
effectswerefound.ContrasttestsforthemaineffectofTaskrevealedthatmotionsynchronizationwassignificantly
higherinTask1thanTask2.
4.2.5 IPQPresenceratings. TheIPQ[51]hasa7-pointLikertscale,rangingfrom-3to3,wherethiswastransformed
toascaleof1to7duringanalysis.ResultswithrespecttoeachpresencefactorwithinIPQrevealsthatparticipants
experiencedhighlevelsofInvolvement(M=5.08,SD=1.49)andSpatialPresence(M=4.29,SD=1.74),butfeltonlyneutral
levelsofGeneralPresence(M=3.52,SD=1.78)andRealism(M=3.52,SD=1.92).
4.2.6 SSQMotionsickness. Participants’reportedmotionsicknesswasmeasuredbeforeandafterthestudyusingthe
SSQquestionnaire[26].AWilcoxonsigned-ranktestwasconductedsincethedatadidnothaveanormaldistribution.
Resultsshowedsignificantdifferencesbetweenthepre-study(Md=1.125,IQR=0.31)andpost-study(Md=1.28,IQR=0.39)
scores(Z=-4.03,p<0.01,r=-0.63)indicatingthatparticipantsdidexperiencemotionsicknessduringthestudy,evenif
slight.
4.3 Qualitativeresults
Weusedaninductivethematicanalysis[6]approach.First,theleadauthorextensivelyreviewedtheinterviewtranscripts
andrecordedvideos,generatinginitialcodesandthemes.Then,theotherauthorsreviewedthecodesandthemesfor
consistencyandofferedadditionalthemesasneeded.Quotesareattributedtoparticipantsbyindicatingwhichpair
(P1-P20)theybelongedto,followedbythespecificparticipant(PN-1orPN-2)whereappropriate.
4.3.1 Frustrationwithshareddecisions. ParticipantsassociatedtheirexperiencewhileperformingTask1withbeing
morecomfortablethanduringTask2,statingthat“Ididn’tfeelmuch[sharedcontrol]inthebeginningbutinthesecond
ManuscriptsubmittedtoACMShareYourReality 19
taskwiththechoiceitfelthorrible”[P10-2].Infact,manyparticipantsexpressedthat,withoutasharedgoal,theyoften
“[...]thoughtthatI’mnotcontrollingandsomebody’sheretocontrolthehands,anditmademeabitangry”[P15-2].
Overall,notonlydidparticipantsfeelmoreateasewithsharingthemotionwhenacommontargetwaspresented,but
theadditionoffreechoicesinTask2addedconfusionandfrustration.
4.3.2 Perceptionofsharedmotion. Onlyabouthalfoftheparticipants(21/40)wereconsciouslyawarethatthemotion
oftheavatarwassharedbetweenthemandtheirpartnerduringTask1,whiletherestexpressedthatitonlybecame
evidenttothemduringTask2,whendifferencesinchoicesemergedbetweenthemandtheirpartners.Participants
attributedthedifferencesbetweentheirmotionandthatoftheavataras“glitches”or“delays”,ratherthantheinputof
theotherpersoninthepair.Forinstance,[P8-1]mentioned,“Inthebeginning,itfeltlikethehandwasnotworking
well”,and[P16-2]remarked,“Isawthis(movement),andIthoughtitwasanalgorithm”.Importantly,duringTask2,
whenparticipantsfeltadiminishedsenseofagencyortheirpartners’movementswerenotwellcoordinated,they
exaggeratedtheirmovements.Thiscompensatedforaperceivedlackofresponsivenessinsharedmotion:“WhenI
movedmyhand,Inoticedthehanddidn’tmovethatmuch,sotocompensateforit,Ihadtoreachoutmore”[P8-1].This
wasparticularlyevidentwhentherewasasubstantialdifferenceinheightbetweenthepairsofparticipants,wherethere
wasanimbalanceofcontrolduetothetallerparticipants’extendedreach,whichresultedinafrustratingexperience
withsharedmotionforthepartnerwithlessreach.
4.3.3 Followingandleading. Participantsspontaneouslytookonamorefollowerorleaderroleduringthetrials.While
someparticipantsfocusedonactivelyfollowingtheirpartners’movements,aimingtocoordinatetheiractionsbetter,
otherstookovertheleadbymisbehavingand“[...]tryingtocheckcontrolbydoingtheoppositemovement”[P3-2],so
thattheshareofcontrolwasmoreapparent.DuringTask2,thisdifferencewasmoreevident,withfollowersexpressing
thatsince,“[...]Ihadnocontrol,IthoughtIwouldfollowwhateverpatterninmovementtheotherpersonwasdoing”
[P11-1].Ontheotherhand,leadersusedthisambiguitybymovingtheirhandsdramaticallytoshiftthesharedhand,
regardlessoftheamountofcontroltheyhadovertheavatar:“Icansortoflimitotherpersons’actionsandactually
feelmoreincontrol”[P14-1].Additionally,fiveparticipantpairsnotedthattherelationshipwiththeirpartnersalso
influencedthedegreeofco-operationtheywereinclinedtoachieve.Forexample,pairsthatkneweachother[P7]
mentionedthattheywouldbemoreattentivetotheotherperson’smovementhaditbeenwithanunfamiliarperson.
4.3.4 Motionsynchrony. AhighlevelofmotionsynchronizationwasobservedduringTask1;participantsstartedthe
studywithdistinctmotions,whicheventuallyjoinedwhenoneparticipantbeganmimickingthehandmotionofthe
other.Participantsmadesimilarobservations,referringtothesesynchronizationsas“rhythms”or“flows”.Forexample,
[P1-1]mentioned:“afterafewroundsitfeltlikeweweregettingintothisrhythm,”and[P2-2]stated:“Istartedwitharc
motionand[P2-1]wasdoingadifferentmotion,then[P2-1]startedmovingwitharcmotion”.
4.3.5 Perceptionofvibrationpatternsandassociations. Severalparticipantsdidnotfullygraspduringthestudythat
hapticfeedbackwouldoccurwhentheirhandsoverlappedwiththeirpartner,whileothersinferrednegativeassociations
withthehapticfeedbackduringthestudy,basedontheirpriorexperiencewithvibrationfeedbackpatterns.Forexample,
participantsexpressedthattheyinterpretedthehapticsashostile:“IthoughtmaybeIwaswrongthat’swhythe
vibrationsarecomingtopushmeinanotherdirection”[P6-2]orthatthehapticfeedbackwas“[...]veryrandom,likeit
wasmalfunctioning”[P7-2].Participantswhoviewedthehapticsaspositivefeedbacktendedtoassociateitwithvideo
games:“IplaytheNintendoSwitch,andifyouwininthegame,itwillhavevibration”[P18-2].
ManuscriptsubmittedtoACM20 Venkatrajetal.
5 DISCUSSION
Belowwediscussourstudylimitationsandfuturework,andthereafterdiscussourkeyfindingsbyinterpretingand
synthesizingtheresultsofourquantitativeandqualitativeanalysis.
5.1 Studylimitationsandfuturework
First,wetestedonlyasubsetofquestionsincommonco-presenceandembodimentquestionnaires–whilesuch
additionalmeasurescouldshedfurtherlightontheexperienceofvirtualco-embodiment,thiswasadeliberatedesign
choicetoensureusersdonotexperiencefatigueandoverloadduringthestudy.Second,whilewefollowedclosely
Jeunetetal.[22]’squestionregardingthesenseofagency,wefoundthatsomeparticipantsmayhavemisinterpreted
whatwasmeantby‘feelingofcontrol’.Theyjudgedthequestiontoberelatedtosuccessinthetaskratherthanactual
controlovertheirbodymovements.Indeed,agencywithinHCIcanhavemultipleinterpretations(see[4]forareview),
andweseethisasapromisingavenueforfutureworktoexploreothermethodsforevaluatingthesenseofagencyin
suchsharedvirtualco-embodimentexperiences.Third,itmaybeworthwhiletofurtherextendthebasicperceptual
crossingparadigminfuturework,bysystematicallyinvestigatinghowvaryingthepresenceandtypeofhaptics-related
instructionsandtrainingbeforehandwouldinfluenceparticipants’sharedagencyduringco-embodimenttasks.Fourth,
werestrictedourselvestostudyinghandownership,wedonotinvestigaterealisticfull-bodyavatarrepresentations
(cf.,[11,28]).Furthermore,previousstudieshaveshownthattherealismoftheavatar[10]andusers’choiceofavatar
[35]impactstheirsenseofembodiment.Givenourfocuswasonbetterunderstandingtheroleofhapticfeedbackand
sharedcontroldistributionacrosstargetedandfree-choicetasks,wekeptourstudyvariablestoaminimumtoavoid
blowinguptheparameterspace.However,thisprovidesaninterestingareaforfurtherresearch–doesthetypeofavatar
body,ormixedhandrepresentationsharedamongstuserssimilarlyinfluencesthesenseofagencyandco-presence?
Fifth,itworthexploringhowheightdifferencesbetweenparticipantsandtheirreachcanimpactexperiencesofshared
avatarcontrol.Tothisend,priorworkhasdevelopedmethodsthatcangenerateavatarbodycharacteristicsthatcan
adapttovariableheightsofparticipantsthatcanbeused[67]–thiswouldhelpensurethatcontrolisdistributed
preciselybetweentheparticipants,evenifthisdoesnotnecessarilyreflectreal-worldusercharacteristics.Finally,given
ourfindingthatthetypeofrelationshipwithanotherpersoncaninfluencefollowingandleadingbehavior(cf.,Sec
4.3.3),thisopensupopportunitiestofurtherexamineco-embodimentinteractionsindifferentdyadcompositions.
5.2 Elucidatingtheroleofhapticfeedbackandavatarcontroldistributionforvirtualavatar
co-embodiment
Ourstudyexploredtheimpactofincludinghapticfeedbackandvaryingavatarcontroldistributiononusers’sense
ofagency,co-presence,bodyownershipandmotionsynchronyacrossreachingtasksinavirtualco-embodiment
scenario(RQ).Tothisend,onekeyobjectivewastoassesshowtheconditioninwhichparticipantswouldreceive
hapticfeedbackwhentheirhandsoverlappedwouldaffectthesethreefactorsinscenariosinvolvingsharedgoalsand
freechoice.Ourfindingsindicatethatthepresenceofhapticfeedbackyieldedasignificanteffectonthesenseofagency
duringourstudy,thoughinunexpectedways.Participantsfeltasignificantlygreatersenseofagencyduringconditions
withouthapticfeedbackcomparedtoconditionswithhapticfeedback.Giventhathapticfeedbackiswell-suitedfor
conveyingnon-verbalcues[39],weexpectedthathapticswouldfacilitate,nothindersensori-motorcoordination
andguidance[38].Furthermore,ourqualitativefindings(Sec4.3.5)indicatedthatthevibrotactilepatternswithinour
hapticfeedbackwereperceivedtobeahindranceandattimesintrusive.Despitethatwetookcaretoensurepleasant
ManuscriptsubmittedtoACMShareYourReality 21
vibrotactilepatternsthroughapre-study,asparticipantsreported,theywereremindedofsmartphoneandsmartwatch
vibrationsandnotifications.Tointerpretthisfinding,wefirstnotethatgivenourfocusontranslatingelementsof
perceptualcrossingintotheavatarco-embodimentparadigm,werestrictedourstudytothecontextofautonomous
interactionprocessesduringsharedperceptualactivities.Thismeansthatevenwithoutconsciousawarenessofthe
vibrotactilecues,weexpectedthatsuchposition-awarehapticfeedbackmechanismswouldsupportsharedperceptual
experiences,inthiscase,sharedmotoractivityduringtargetedandfree-choicereachingtasks.However,giventhe
salienceofthehapticstimuli,wesuspectthathapticsmayhaveloweredthesenseofagencyforparticipantsasthey
mayhavefeltoverwhelmedbytheotherusers’guidance.This,alongwiththeinterplayofcontrol,coordination,and
physicalattributes,wouldhavethenplayedaroleinshapingthestrategiestheparticipantsusedinsynchronizing
withtheotheruserduringthehapticfeedbackconditions.Together,theforegoingraisecautionsabouthowhaptics
canbeintegrated,suggestingthatincludingvibrotactile-basedhapticfeedbackasapositionalguidancemechanismin
3Dvirtualspaceduringsuchsharedcontrolinteractionsmaynotbeaneffectivemeansforimprovingsharedavatar
co-embodimentexperiences.
5.3 Sharedcontrol,motorsynchrony,andperceptualcrossingacrosstargetedandfree-choicetasks
Ourfindingsindicatethatparticipants’reportedfeelingsofcontrol(SoA)donotalignwiththeactuallevelsofcontrol.
Wefoundthatparticipants’senseofagencyincreasedbetween25%and50%controlconditions,whileadecreasewas
observedbetween50%and75%conditions.ThisresultechoesthefindingsofKodamaetal.(2023)[29],whodidnotfinda
cleardifferentiationbetweenthetestedlevelsofcontrol.Moreover,wefoundthatparticipantsfeltasignificantlygreater
senseofagencyinTask1(targeted)comparedwithTask2(free-choice).Sincetheconditionswerecounterbalancedand
trialsrandomized,participantsmayhavehadadifficulttimetojudgeabsolutecontrollevels,astheyhadnorelative
comparisontoindicatesuchexperiencedcontrollevels.Weuseabsolutejudgementsformeasurementofsubjective
responsessinceitisthestandardpracticeacrosspriorwork[11,15]thatinvestigatesthesenseofagencyandalso
providedameanstotestifhapticswouldleadtohigher(perceived)senseofagencyinagiventrial,withoutreferencing
backtoearliertrials(whichmaynothavehadhapticsactivated).Assuch,overestimationofcontrolwasapparent
duringTask1.ThislendscredencetothefindingsbyFribourgetal.[11],whoalsofoundthatparticipantsperceived
agreatersenseofagencywhenthegoalwassharedcomparedtosituationswhereparticipantspursueddifferent
goals.Furthermore,participantsfeltasignificantlygreatersenseofco-presenceduringTask2comparedwithTask1,
suggestingthatstrongmotionsynchronizationeffectsmayhavediminishedtheawarenessoftheother.Thiswasfurther
echoedbyparticipants,wheresomereportedalackofawarenessthattheyweresharinganavatarwiththeirpartners
duringTask1.Qualitativeanalysesofuserresponsesintheperceptualcrossingparadigmalsohighlightthatmovement
synchronizationmightnotalwaysnecessarilyindicaterecognitionofeachother[30].Inourspecificimplementation,in
Task1(targeted),itmighthavebeenthecasethatthestraight-forwardtaskenvironmentaffordedhighsynchronization,
butnorealspaceforactiveexplorationtotakeplace(i.e.,similartotheoscillatingmovementsfounduponsuccessful
recognitionofeachotherinperceptualcrossingstudies)limitingopportunitiestobecomeawareoftheotherparticipant.
Assuch,participants’attentiontotheirpartners’movementandneedtoexplicitlycommunicateverballywiththeir
partnersduringTask2alsoindicatesthattheyweremoreinclinedtoconsciouslyco-ordinate,comparedtothemore
autonomousinteractionthatwasobservedduringTask1.
Wealsofoundthatparticipantsfeltthatthemovementsofthevirtualhandswereinfluencingtheirownmovements
(Bodyownership2;cf.,Sec.4.2.3)significantlygreaterduringTask2comparedwithTask1.Thiswasfurtherreflected
uponbyparticipantswhostatedtheyactivelystrategizedtoeitherexertmorecontroloverthevirtualhandorto
ManuscriptsubmittedtoACM22 Venkatrajetal.
followitsmovementsduringTask2.Interestingly,similarstrategizingaboutmovementswhenencounteringother
usersarefoundintheperceptualcrossingparadigm,whereinsomecasesuserswouldspontaneouslyadoptleaderand
followerroles[13].Forexample,usersmaychoosetoremainstationaryandpassivelyreceivetheother’stouch[30].
Theseparallelsareinterestinggiventhestarkdifferencesinavailablesensoryinformationinourtaskscomparedtothe
perceptualcrossingparadigm.Itraisesinterestingquestionsaboutwaysinwhichthebasicparadigmcanbeextended
andintegratedintomoremulti-sensorysharedvirtualenvironments.Theforegoingraisefundamentalquestionsabout
thenatureofsharedcontrolandsocialcoordinationasweintegratewithmachinesandoneanother[40]:towhat
extentshouldwebeconsciouslyawareofbodilyfeedbackmechanismsduringsharedactivities?Giventheimportance
ofmotionsynchronyinvaryingthelevelsofconsciousawarenessofthevirtualother,towhatextentshouldshared
bodycontrolsystems,whetherwithhumansormachines,leveragethiswithoutimpedingonusers’senseofperceived
andactualagency?
6 CONCLUSION
Weinvestigatedwhetherintegratinghapticsintosharedavatarco-embodimentcanenhanceusers’sharedVRex-
periences.Drawingontheperceptualcrossingparadigm,weexaminewhetherimplementingnon-verbalfeedback
mechanisms(namely,hapticfeedback)withinembodiedinteractionbetweentwouserscanimprovesuchsocialcoordi-
nationexperiences.Insightsfromthisworkprovideadeeperunderstandingofthedynamicsbetweenusersduring
co-embodimentanditsimpactontheperceptionsoftheirsenseofagency,co-presence,andbodyownershiptowardsa
virtualhand.Wefoundthathapticfeedbackgiventoparticipantswhentheirhandsoverlappedledtoadiminished
senseofagencyduringco-embodiment.Ourfindingsshowed(a)alowersenseofagencyinthefree-choicewith
hapticscomparedtonofeedback,(b)higheragencyduringthesharedtargettask,(c)co-presenceandembodiment
weresignificantlyhigherintaskswherethereweremultipletargets,(d)users’handmotionssynchronizedmoreinthe
targetedtask.Ourworkcontributesadeeperunderstandingandcautionaryconsiderationsfortheroleofvibrotactile
hapticfeedbackandsharedcontroldistributionintheemergingareaofvirtualavatarco-embodiment.
REFERENCES
[1] FerranArgelaguet,LudovicHoyet,MichaelTrico,andAnatoleLecuyer.2016.Theroleofinteractioninvirtualembodiment:Effectsofthevirtual
handrepresentation.In2016IEEEVirtualReality(VR).IEEE,Greenville,SC,USA,3–10. https://doi.org/10.1109/VR.2016.7504682
[2] MalikaAuvray,CharlesLenay,andJohnStewart.2009.Perceptualinteractionsinaminimalistvirtualenvironment.NewIdeasinPsychology27,1
(April2009),32–47. https://doi.org/10.1016/j.newideapsych.2007.12.002
[3] MalikaAuvrayandMariekeRohde.2012.Perceptualcrossing:thesimplestonlineparadigm.Frontiersinhumanneuroscience6(2012),181.
[4] DanBennett,OussamaMetatla,AnneRoudaut,andElisaD.Mekler.2023.HowDoesHCIUnderstandHumanAgencyandAutonomy?.InProceedings
ofthe2023CHIConferenceonHumanFactorsinComputingSystems(Hamburg,Germany)(CHI’23).AssociationforComputingMachinery,New
York,NY,USA,Article375,18pages. https://doi.org/10.1145/3544548.3580651
[5] DianaCarvalho,SilmarTeixeira,MarinaLucas,Ti-FeiYuan,FernandaChaves,CarolinePeressutti,SergioMachado,JulianaBittencourt,Manuel
Menéndez-González,AntonioEgidioNardi,etal.2013.Themirrorneuronsysteminpost-strokerehabilitation.Internationalarchivesofmedicine6,
1(2013),1–7.
[6] HarrisEdCooper,PaulMCamic,DebraLLong,ATPanter,DavidEdRindskopf,andKennethJSher.2012.Thematicanalysis.InAPAHandbookof
ResearchMethodsinPsychology:Vol.2.ResearchDesigns.AmericanPsychologicalAssociation,Washington,57–71. https://doi.org/10.1037/13620-000
[7] PatriciaCornelio,PatrickHaggard,KasperHornbaek,OrestisGeorgiou,JoannaBergström,SriramSubramanian,andMariannaObrist.2022.The
senseofagencyinemergingtechnologiesforhuman-computerintegration:Areview.Front.Neurosci.16(Sept.2022),949138.
[8] AbdallahElAli,EkaterinaR.Stepanova,ShalviPalande,AngelikaMader,PabloCesar,andKasparJansen.2023.BreatheWithMe:ExploringVisual
andVibrotactileDisplaysforSocialBreathAwarenessduringColocated,CollaborativeTasks.InExtendedAbstractsofthe2023CHIConferenceon
HumanFactorsinComputingSystems(Hamburg,Germany)(CHIEA’23).AssociationforComputingMachinery,NewYork,NY,USA,Article58,
8pages. https://doi.org/10.1145/3544549.3585589
ManuscriptsubmittedtoACMShareYourReality 23
[9] LisaA.Elkin,MatthewKay,JamesJ.Higgins,andJacobO.Wobbrock.2021.AnAlignedRankTransformProcedureforMultifactorContrastTests.
https://doi.org/10.48550/arXiv.2102.11824arXiv:2102.11824[cs,stat].
[10] RebeccaFribourg,FerranArgelaguet,AnatoleLecuyer,andLudovicHoyet.2020. AvatarandSenseofEmbodiment:StudyingtheRelative
PreferenceBetweenAppearance,ControlandPointofView.IEEETransactionsonVisualizationandComputerGraphics26,5(May2020),2062–2072.
https://doi.org/10.1109/TVCG.2020.2973077
[11] RebeccaFribourg,NamiOgawa,LudovicHoyet,FerranArgelaguet,TakujiNarumi,MichitakaHirose,andAnatoleLecuyer.2021. VirtualCo-
Embodiment:EvaluationoftheSenseofAgencyWhileSharingtheControlofaVirtualBodyAmongTwoIndividuals. IEEETransactionson
VisualizationandComputerGraphics27,10(Oct.2021),4023–4038. https://doi.org/10.1109/TVCG.2020.2999197
[12] TomFroese,HiroyukiIizuka,andTakashiIkegami.2014.Embodiedsocialinteractionconstitutessocialcognitioninpairsofhumans:aminimalist
virtualrealityexperiment.Scientificreports4,1(2014),3672.
[13] TomFroese,HiroyukiIizuka,andTakashiIkegami.2014.Usingminimalhuman-computerinterfacesforstudyingtheinteractivedevelopmentof
socialawareness.Frontiersinpsychology5(2014),1061.
[14] MarGonzalez-Franco,RodrigoPizarro,JulioCermeron,KatieLi,JacobThorn,WindoHutabarat,AshutoshTiwari,andPabloBermell-Garcia.2017.
ImmersiveMixedRealityforManufacturingTraining.FrontiersinRoboticsandAI4(2017). https://www.frontiersin.org/articles/10.3389/frobt.2017.
00003
[15] TakayoshiHagiwara,MakiSugimoto,MasahikoInami,andMichiteruKitazaki.2019.SharedBodybyActionIntegrationofTwoPersons:Body
Ownership,SenseofAgencyandTaskPerformance.In2019IEEEConferenceonVirtualRealityand3DUserInterfaces(VR).IEEE,Osaka,Japan,
954–955. https://doi.org/10.1109/VR.2019.8798222
[16] AyahHamadandBochenJia.2022.HowVirtualRealityTechnologyHasChangedOurLives:AnOverviewoftheCurrentandPotentialApplications
andLimitations.InternationalJournalofEnvironmentalResearchandPublicHealth19,18(2022). https://doi.org/10.3390/ijerph191811278
[17] HarinHapuarachchi,TakayoshiHagiwara,GowrishankarGanesh,andMichiteruKitazaki.2023. Effectofconnectioninducedupperbody
movementsonembodimenttowardsalimbcontrolledbyanotherduringvirtualco-embodiment.PLOSONE18,1(Jan.2023),e0278022. https:
//doi.org/10.1371/journal.pone.0278022
[18] HarinHapuarachchiandMichiteruKitazaki.2022.Knowingtheintentionbehindlimbmovementsofapartnerincreasesembodimenttowardsthe
limbofjointavatar.ScientificReports12,1(July2022),11453. https://doi.org/10.1038/s41598-022-15932-x
[19] D.J.Harris,T.Arthur,J.Kearse,M.Olonilua,E.K.Hassan,T.C.DeBurgh,M.R.Wilson,andS.J.Vine.2023.Exploringtheroleofvirtualrealityin
militarydecisiontraining.FrontiersinVirtualReality4(2023). https://www.frontiersin.org/articles/10.3389/frvir.2023.1165030
[20] PaulHeidicker,EikeLangbehn,andFrankSteinicke.2017.InfluenceofavatarappearanceonpresenceinsocialVR.In3DUserInterfaces(3DUI),
2017IEEESymposiumon.IEEE,LosAngeles,CA,USA,233–234.
[21] MasahikoInami,DaisukeUriu,ZendaiKashino,ShigeoYoshida,HirotoSaito,AzumiMaekawa,andMichiteruKitazaki.2022.Cyborgs,Human
Augmentation,Cybernetics,andJIZAIBody.InAugmentedHumans2022(Kashiwa,Chiba,Japan)(AHs2022).AssociationforComputingMachinery,
NewYork,NY,USA,230?242. https://doi.org/10.1145/3519391.3519401
[22] CamilleJeunet,LouisAlbert,FerranArgelaguet,andAnatoleLecuyer.2018.“DoYouFeelinControl?”:TowardsNovelApproachestoCharacterise,
ManipulateandMeasuretheSenseofAgencyinVirtualEnvironments.IEEETransactionsonVisualizationandComputerGraphics24,4(April2018),
1486–1495. https://doi.org/10.1109/TVCG.2018.2794598
[23] M-CarmenJuan,JulenElexpuru,PauloDias,BeatrizSousaSantos,andPaulaAmorim.2023.Immersivevirtualrealityforupperlimbrehabilitation:
comparinghandandcontrollerinteraction.VirtualReality27,2(2023),1157–1171.
[24] SungchulJung,NawamKarki,MaxSlutter,andRobertW.Lindeman.2021.OntheUseofMulti-sensoryCuesinSymmetricandAsymmetricShared
CollaborativeVirtualSpaces.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW1(April2021),1–25. https://doi.org/10.1145/3449146
[25] SamanthaKeenaghan,LucyBowles,GeorginaCrawfurd,SimonThurlbeck,RobertW.Kentridge,andDorothyCowie.2020.Mybodyuntilproven
otherwise:Exploringthetimecourseofthefullbodyillusion.ConsciousnessandCognition78(2020),102882. https://doi.org/10.1016/j.concog.2020.
102882
[26] RobertS.Kennedy,NormanE.Lane,KevinS.Berbaum,andMichaelG.Lilienthal.1993.SimulatorSicknessQuestionnaire:Anenhancedmethodfor
quantifyingsimulatorsickness.TheInternationalJournalofAviationPsychology3,3(1993),203–220. https://doi.org/10.1207/s15327108ijap0303_3
Place:USPublisher:LawrenceErlbaum.
[27] KonstantinaKilteni,RaphaelaGroten,andMelSlater.2012. TheSenseofEmbodimentinVirtualReality. Presence:TeleoperatorsandVirtual
Environments21,4(Nov.2012),373–387. https://doi.org/10.1162/PRES_a_00124
[28] DaikiKodama,TakatoMizuho,YujiHatada,TakujiNarumi,andMichitakaHirose.2022.EnhancingtheSenseofAgencybyTransitionalWeight
ControlinVirtualCo-Embodiment.In2022IEEEInternationalSymposiumonMixedandAugmentedReality(ISMAR).IEEE,Singapore,Singapore,
278–286. https://doi.org/10.1109/ISMAR55827.2022.00043
[29] DaikiKodama,TakatoMizuho,YujiHatada,TakujiNarumi,andMichitakaHirose.2023. EffectsofCollaborativeTrainingUsingVirtualCo-
embodimentonMotorSkillLearning.IEEETransactionsonVisualizationandComputerGraphics29,5(May2023),2304–2314. https://doi.org/10.
1109/TVCG.2023.3247112
[30] HirokiKojima,TomFroese,MizukiOka,HiroyukiIizuka,andTakashiIkegami.2017.Asensorimotorsignatureofthetransitiontoconscioussocial
perception:co-regulationofactiveandpassivetouch.FrontiersinPsychology8(2017),1778.
ManuscriptsubmittedtoACM24 Venkatrajetal.
[31] AmandaLazar,HilaireThompson,andGeorgeDemiris.2014.ASystematicReviewoftheUseofTechnologyforReminiscenceTherapy.Health
Education&Behavior41,1_suppl(2014),51S–61S. https://doi.org/10.1177/1090198114537067arXiv:https://doi.org/10.1177/1090198114537067PMID:
25274711.
[32] CharlesLenay.2021.Perceivingatadistance:enaction,exteriorityandpossibility–atributetoJohnStewart.AdaptiveBehavior29,5(2021),485–503.
[33] CharlesLenay,JohnStewart,MariekeRohde,andAmalAliAmar.2011.“Youneverfailtosurpriseme”:thehallmarkoftheOther:Experimental
studyandsimulationsofperceptualcrossing.InteractionStudies.SocialBehaviourandCommunicationinBiologicalandArtificialSystems12,3(Nov.
2011),373–396. https://doi.org/10.1075/is.12.3.01len
[34] JieLi,YipingKong,ThomasRöggla,FrancescaDeSimone,SwamyAnanthanarayan,HuibdeRidder,AbdallahElAli,andPabloCesar.2019.
MeasuringandUnderstandingPhotoSharingExperiencesinSocialVirtualReality.InProceedingsofthe2019CHIConferenceonHumanFactorsin
ComputingSystems(Glasgow,ScotlandUk)(CHI’19).ACM,NewYork,NY,USA,1?14. https://doi.org/10.1145/3290605.3300897
[35] SohyeLimandByronReeves.2009.BeingintheGame:EffectsofAvatarChoiceandPointofViewonPsychophysiologicalResponsesDuringPlay.
MediaPsychology12,4(2009),348–370. https://doi.org/10.1080/15213260903287242arXiv:https://doi.org/10.1080/15213260903287242
[36] Che-WeiLin,Li-ChiehKuo,Yu-ChingLin,Fong-ChinSu,Yu-AnLin,andHsiu-YunHsu.2021.Developmentandtestingofavirtualrealitymirror
therapysystemforthesensorimotorperformanceofupperextremity:Apilotrandomizedcontrolledtrial.IEEEAccess9(2021),14725–14734.
[37] DestawBMekbib,DerejeKebebewDebeli,LiZhang,ShanFang,YulingShao,WeiYang,JiaweiHan,HongjieJiang,JunmingZhu,ZhiyongZhao,
etal.2021.Anovelfullyimmersivevirtualrealityenvironmentforupperextremityrehabilitationinpatientswithstroke.AnnalsoftheNewYork
AcademyofSciences1493,1(2021),75–89.
[38] MiguelMelo,GuilhermeGonçalves,PedroMonteiro,HugoCoelho,JoséVasconcelos-Raposo,andMaximinoBessa.2020.Domultisensorystimuli
benefitthevirtualrealityexperience?Asystematicreview.IEEETransactionsonVisualizationandComputerGraphics28,2(2020),1428–1442.
[39] JonasMollandEva-LottaSallnäs.2009.Communicativefunctionsofhapticfeedback.InInternationalConferenceonHapticandAudioInteraction
Design.Springer,Springer,Berlin,Heidelberg,1–10.
[40] FlorianFloydMueller,PedroLopes,PaulStrohmeier,WendyJu,CaitlynSeim,MartinWeigel,SurangaNanayakkara,MariannaObrist,ZhuyingLi,
JosephDelfa,JunNishida,ElizabethM.Gerber,DagSvanaes,JonathanGrudin,StefanGreuter,KaiKunze,ThomasErickson,StevenGreenspan,
MasahikoInami,JoeMarshall,HaraldReiterer,KatrinWolf,JochenMeyer,TheclaSchiphorst,DakuoWang,andPattieMaes.2020.NextStepsfor
Human-ComputerIntegration.InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI’20).
AssociationforComputingMachinery,NewYork,NY,USA,1?15. https://doi.org/10.1145/3313831.3376242
[41] NamiOgawa,TakujiNarumi,andMichitakaHirose.2019.VirtualHandRealismAffectsObjectSizePerceptioninBody-BasedScaling.In2019IEEE
ConferenceonVirtualRealityand3DUserInterfaces(VR).IEEE,Osaka,Japan,519–528. https://doi.org/10.1109/VR.2019.8798040
[42] CatherineS.Oh,JeremyN.Bailenson,andGregoryF.Welch.2018.ASystematicReviewofSocialPresence:Definition,Antecedents,andImplications.
FrontiersinRoboticsandAI5(Oct.2018),114. https://doi.org/10.3389/frobt.2018.00114
[43] ZiziPapacharissi.2005.TheReal-VirtualDichotomyinOnlineInteraction:NewMediaUsesandConsequencesRevisited.AnnalsoftheInternational
CommunicationAssociation29,1(Jan.2005),216–238. https://doi.org/10.1080/23808985.2005.11679048
[44] TabithaC.PeckandMarGonzalez-Franco.2021. AvatarEmbodiment.AStandardizedQuestionnaire. FrontiersinVirtualReality1(Feb.2021),
575943. https://doi.org/10.3389/frvir.2020.575943
[45] TeklaS.Perry.2016.Virtualrealitygoessocial.IEEESpectrum53,1(2016),56–57. https://doi.org/10.1109/MSPEC.2016.7367470
[46] DanielPimentelandCharlotteVinkers.2021.CopresenceWithVirtualHumansinMixedReality:TheImpactofContextualResponsivenesson
SocialPerceptions.FrontiersinRoboticsandAI8(April2021),634520. https://doi.org/10.3389/frobt.2021.634520
[47] SusannePutze,DmitryAlexandrovsky,FelixPutze,SebastianHöffner,JanDavidSmeddinck,andRainerMalaka.2020.BreakingTheExperience:
EffectsofQuestionnairesinVRUserStudies.InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)
(CHI’20).AssociationforComputingMachinery,NewYork,NY,USA,1?15. https://doi.org/10.1145/3313831.3376144
[48] JulianRasch,VladislavDmitrievicRusakov,MartinSchmitz,andFlorianMüller.2023.Going,Going,Gone:ExploringIntentionCommunication
forMulti-UserLocomotioninVirtualReality.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.ACM,Hamburg
Germany,1–13. https://doi.org/10.1145/3544548.3581259
[49] SelmaRizvic,GreggYoung,AvinashChanga,BojanMijatovic,andIvonaIvkovic-Kihic.2022. DaVinciEffect-multiplayerVirtualReality
experience.InEurographicsWorkshoponGraphicsandCulturalHeritage,FedericoPonchioandRuggeroPintus(Eds.).TheEurographicsAssociation,
. https://doi.org/10.2312/gch.20221229
[50] AinoSaarinen,VilleHarjunen,IngaJasinskaja-Lahti,IiroP.Jääskeläinen,andNiklasRavaja.2021.Socialtouchexperienceindifferentcontexts:A
review.Neuroscience&BiobehavioralReviews131(2021),360–372. https://doi.org/10.1016/j.neubiorev.2021.09.027
[51] ThomasSchubert,FrankFriedmann,andHolgerRegenbrecht.2001.Theexperienceofpresence:Factoranalyticinsights.Presence:Teleoperators&
VirtualEnvironments10,3(2001),266–281.
[52] ValentinSchwind,PascalKnierim,CagriTasci,PatrickFranczak,NicoHaas,andNielsHenze.2017."TheseAreNotMyHands!":EffectofGender
onthePerceptionofAvatarHandsinVirtualReality.InProceedingsofthe2017CHIConferenceonHumanFactorsinComputingSystems(Denver,
Colorado,USA)(CHI’17).AssociationforComputingMachinery,NewYork,NY,USA,1577–1582. https://doi.org/10.1145/3025453.3025602
[53] HastiSeifi,KailunZhang,andKaronEMacLean.2015.VibViz:Organizing,visualizingandnavigatingvibrationlibraries.In2015IEEEWorldHaptics
Conference(WHC).IEEE,,254–259.
ManuscriptsubmittedtoACMShareYourReality 25
[54] HarrisonJesseSmithandMichaelNeff.2018.CommunicationBehaviorinEmbodiedVirtualReality.InProceedingsofthe2018CHIConferenceon
HumanFactorsinComputingSystems(MontrealQC,Canada)(CHI’18).ACM,NewYork,NY,USA,1–12. https://doi.org/10.1145/3173574.3173863
[55] MandayamASrinivasanandCagatayBasdogan.1997.Hapticsinvirtualenvironments:Taxonomy,researchstatus,andchallenges.Computers&
Graphics21,4(1997),393–404.
[56] LisaJ.Stephenson,S.GarethEdwards,andAndrewP.Bayliss.2021. FromGazePerceptiontoSocialCognition:TheShared-AttentionSystem.
PerspectivesonPsychologicalScience16,3(2021),553–576. https://doi.org/10.1177/1745691620953773arXiv:https://doi.org/10.1177/1745691620953773
PMID:33567223.
[57] YiluSun,OmarShaikh,andAndreaStevensonWon.2019. Nonverbalsynchronyinvirtualreality. PLOSONE14,9(092019),1–28. https:
//doi.org/10.1371/journal.pone.0221803
[58] AnastasiosTheodoropoulos,DimitraStavropoulou,PanagiotisPapadopoulos,NikosPlatis,andGeorgeLepouras.2023.DevelopinganInteractive
VRCAVEforImmersiveSharedGamingExperiences.VirtualWorlds2,2(May2023),162–181. https://doi.org/10.3390/virtualworlds2020010
[59] CordulaVesper,EkaterinaAbramova,JudithBütepage,FrancescaCiardo,BenjaminCrossey,AlfredEffenberg,DayanaHristova,AprilKarlinsky,
LukeMcEllin,SariRRNijssen,etal.2017.Jointaction:Mentalrepresentations,sharedinformationandgeneralmechanismsforcoordinatingwith
others.Frontiersinpsychology7(2017),2039.
[60] ChyannaWee,KianMengYap,andWoanNingLim.2021.HapticInterfacesforVirtualReality:ChallengesandResearchDirections.IEEEAccess9
(2021),112145–112162. https://doi.org/10.1109/ACCESS.2021.3103598ConferenceName:IEEEAccess.
[61] JohannWentzel,Gregd’Eon,andDanielVogel.2020.ImprovingVirtualRealityErgonomicsThroughReach-BoundedNon-LinearInputAmplification.
InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(CHI’20).AssociationforComputingMachinery,NewYork,NY,
USA,1–12. https://doi.org/10.1145/3313831.3376687
[62] NorbertWiener.1948.Cybernetics:orControlandCommunicationintheAnimalandtheMachine(2ed.).MITPress,Cambridge,MA.
[63] JacobO.Wobbrock,LeahFindlater,DarrenGergle,andJamesJ.Higgins.2011.Thealignedranktransformfornonparametricfactorialanalyses
usingonlyanovaprocedures.InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems(CHI’11).AssociationforComputing
Machinery,NewYork,NY,USA,143–146. https://doi.org/10.1145/1978942.1978963
[64] SophieWohltjen,BrigittaToth,AdamBoncz,andThaliaWheatley.2023. Synchronytoabeatpredictssynchronywithotherminds. Scientific
Reports13,1(2023),3591.
[65] Tae-HeonYang,JinRyongKim,HanbitJin,HyunjaeGil,Jeong-HoiKoo,andHyeJinKim.2021.RecentAdvancesandOpportunitiesofActive
MaterialsforHapticTechnologiesinVirtualandAugmentedReality.AdvancedFunctionalMaterials31,39(2021),2008831. https://doi.org/10.1002/
adfm.202008831arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/adfm.202008831
[66] UngyeonYangandGerardJounghyunKim.2002.ImplementationandEvaluationof"JustFollowMe":AnImmersive,VR-Based,Motion-Training
System.Presence:Teleoper.VirtualEnviron.11,3(jun2002),304–323. https://doi.org/10.1162/105474602317473240
[67] YongjingYe,LibinLiu,LeiHu,andShihongXia.2022.Neural3Points:LearningtoGeneratePhysicallyRealisticFull-bodyMotionforVirtualReality
Users. https://doi.org/10.48550/arXiv.2209.05753arXiv:2209.05753[cs].
[68] YizhongZhang,ZhiqiLi,SichengXu,ChongLi,JiaolongYang,XinTong,andBainingGuo.2023.RemoteTouch:EnhancingImmersive3DVideo
CommunicationwithHandTouch. http://arxiv.org/abs/2302.14365arXiv:2302.14365[cs].
[69] ShizheZhu,YouxinSui,YingShen,YiZhu,NawabAli,ChuanGuo,andTongWang.2021.EffectsofVirtualRealityInterventiononCognition
andMotorFunctioninOlderAdultsWithMildCognitiveImpairmentorDementia:ASystematicReviewandMeta-Analysis.FrontiersinAging
Neuroscience13(2021). https://doi.org/10.3389/fnagi.2021.586999
ManuscriptsubmittedtoACM