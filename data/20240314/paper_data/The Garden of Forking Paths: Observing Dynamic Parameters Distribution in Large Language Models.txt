The Garden of Forking Paths:∗Observing Dynamic Parame-
ters Distribution in Large Language Models
CarloNicoliniIpaziaS.p.A.,Milan,Italy c.nicolini@ipazia.com
JacopoStaianoDepartmentofEconomicsandManagement,UniversityofTrento,Trento,Italy jacopo.staiano@unitn.it
BrunoLepriFondazioneBrunoKessler,Trento,Italy;IpaziaS.p.A.,Milan,Italy lepri@fbk.eu
RaffaeleMarinoDepartmentofPhysicsandAstronomy,UniversityofFlorence,Florence,Italy raffaele.marino@unifi.it
Abstract
A substantial gap persists in understanding the reasons behind the exceptional perfor-
manceoftheTransformerarchitectureinNLP.Aparticularlyunexploredareainvolvesthe
mechanistic description of how the distribution of parameters evolves over time during
training. Inthisworkwesuggestthatlookingatthetimeevolutionofthestatisticdistribu-
tionofmodelparameters,andspecificallyatbifurcationeffects,canhelpunderstandingthe
model quality, potentially reducing training costs and evaluation efforts and empirically
showingthereasonsbehindtheeffectivenessofweightssparsification.
1 Introduction
Since its introduction in 2017 (Vaswani et al., 2017), the Transformer architecture has spurred enormous
research efforts leading to significant advancements across many research fields such as Computer Vi-
sion (Dosovitskiy et al., 2020), Speech (Gulati et al., 2020) and Language Processing (Brown et al., 2020).
As the deployment of state-of-the-art language models becomes ubiquitous in natural language process-
ing applications, the demand for transparency and explainability has intensified and a new research area
denotedasMechanisticInterpretability(MI)emerged (Conmyetal.,2023).
MI is the attempt to microscopically describe the internals of neural networks by analysing the weights,
with the goal of reverse engineering their macroscopic properties. Similar to how statistical mechanics
links microscopic particle behavior to macroscopic system properties, MI delves into the micro-level de-
tails of neural networks’ parameters to elucidate their impact on macro-level functionalities and model
outputs. This analogy underscores interpretability’s role in bridging the explanatory gap within neural
networks, akin to how statistical mechanics contributes to understanding collective dynamics in particle
systemswhereindividualmicroscopiclawsgiverisetolargescaleproperties(Huang,2008).
In this sense, researchers have undertaken diverse approaches, ranging from probing attention mecha-
nisms (Gurnee & Tegmark, 2023) to understand the internal space and time representation of Large Lan-
guageModels(LLMs),orbyanalyzingresidualstreams(Yu&Yang,2023)asawaytodescribetheconcepts
flowing through the network’s layers. Others have pushed forward analogies between Transformers and
interacting particle systems (Geshkovski et al., 2023), where each word, akin to a particle in a ensemble,
followstheflowinfluencedbythecollectivebehavior.
In this paper, we extend the analogy between Mechanistic Interpretability and Statistical Mechan-
ics (Huang, 2008) to investigate the microscopic network parameters’ evolution over time, by exploring
thepropertiesofPythia(Bidermanetal.,2023),apubliclyaccessibleLLM.Wedescribethemodelinterms
ofdynamicalparameters’evolutionoftheembeddinglayers,andstudytheireffectonthegeneratedout-
put.
∗“TheGardenofForkingPaths"isatributetothetitleofashortnovelfromthewriterandpoetJorgeLuisBorges.
1
4202
raM
31
]LC.sc[
1v93780.3042:viXraOurempiricalfindingssuggestatwo-foldcharacteroftheseinternalparameters’dynamics:
• Inthefirstphasesofthetrainingprocess,adiffusiveprocesstakesplacewherethemodelexplores
thelandscapeineverydirection(asmanyasthenumberofnetworkparameters);
• Then,afteracertaintransientperiod,theparameters’dynamicconvergestoadeterministicevolu-
tion,whereastheunderlyingprocessisnolongerdiffusive.
With this study we aim to shed light on unexpected dynamics unfolding beyond the transient period.
Wepositthatthisphenomenonisprofoundandhasfar-reachingimplications, thusdemandingthorough
analyses. Moreover, the observed phenomenon of weights converging to two distinct, apparently zero-
symmetricvalues,warrantsfurtherinvestigationduetoitspotentialbiologicalrelevance. Thissymmetry
mighthintatanunderlyingprocessmirroredinthebrain,whereexcitatoryandinhibitoryneuronscompete
fordominanceduringlearning.Indeed,asobservedinNajafietal.(2020),excitatoryandinhibitorysubnet-
works are equally selective during decision-making process, and emerge simultaneously during learning
process. This intriguing parallelism demands deeper analysis to illuminate the connection between our
forkingpathbehavior,observedindiversemodelsizes,andthecorrespondingneurologicalprocessesob-
servedinthehumanandanimalbrain(Najafietal.,2020).
Our observations yield insights with significant practical applications, particularly in relation to the dy-
namics observed during the training processes of neural networks. The presence of a bifurcation phe-
nomenon within the dynamics of the weights—across different models of varying sizes and trained on
diversedatasets—naturallysuggestsapracticalprotocolforspontaneouslystoppingthetrainingprocess.
Specifically,thisbifurcationsignalsatransitiontoastationarystate,indicatingthatfurthertrainingmaynot
altertheweightvaluessignificantly. Therefore,byrecognizingtheabsenceofsignificantfluctuationsinthe
dynamics,onecanefficientlyconcludethetrainingoncesuchastationarystateisachieved. Thisadvance-
ment has profound implications for efforts to mitigate the environmental impact of training LLMs. In an
erawherecombatingclimatechangeisparamount,reducingtheenergyconsumptionoftrainingprocesses
isacriticalgoal. Ournewexitprotocolfortrainingoffersastrategytoachievethisobjective, minimizing
energyexpenditurewithoutcompromisingtheeffectivenessofthetraining.
Thestructureofthismanuscriptfollowsalogicalprogressiontofacilitatetheunderstandingofourwork.In
Section3weprovideanoverviewoftheinternalarchitectureofLLMs. Weanalyzeanddetailthemethods
andtoolsweutilizedtoinvestigatethedynamicsofthelastembeddinglayerparameters.Followingthis,in
Section4weoutlineourkeyfindings,withtheeffectsofthebifurcationonmodelperplexity. Weprovidea
possibleinterpretationofthesephenomena,aligningthemwiththeunderlyingtheory,andsuggestpossible
causesandimplications. Wefinallysummarizeourinsights,reiteratetheimplicationsofourfindings,and
indicatedirectionsforfutureresearch.
2 Related work
Our work follows the direction traced by Mechanistic Interpretability (MI) studies recently done for the
Transformers architecture. The first supporting studies behind most MI attempts are based on intuitive
visualizationsoftheinternallayersofTransformers(Vig,2019;Voitaetal.,2019;Cheferetal.,2021), with
mostofthembasedonindividualneuronsasunitofanalysis.
AttheheartofMIliestheconjecturethatartificialneuralnetworks,akintotheirbiologicalcounterparts,ex-
hibitanuancedinterdependencebetweenstructureandfunction(Sporns,2016). Thealgorithmsimplicitly
encapsulatedwithinthecomputationalgraphsofmodels(analogoustosynapsesinthebrain)areintricately
linkedtosynapticstrengths(parametervalues). Consequently,thefoundationalcapabilitiesmanifestedby
both systems are contingent upon the synergy of these inherent structural and functional attributes (Liu
et al., 2024; Nainani, 2024). In most MI studies it is prevailing to identify the neurons of a model as the
fundamental unit of examination. However, a scrutiny centered on neurons may lack insightfulness due
tophenomenasuchaspolysemanticity, i.e. theneurons’capacitytoexhibitdistinctresponsestounrelated
inputs,aselucidatedinpreviousworks(Olahetal.,2017;Brickenetal.,2023).
2OurworktriestoaddresssomeoftheaspectsexposedintheMIliterature. Inparticular,toourknowledge,
we are the first to visually analyze the parameters distribution of the embedding layers among multiple
trainingcheckpoints,individuatingabifurcationeffectwithaquasi-symmetricbimodalweightsdistribu-
tion. We believe our observation is at the root of the effectiveness of extreme quantization methods like
the one recently proposed by Ma et al. (2024) where weights are allowed to only take 3 distinct values
{1,0,−1}.
Powerful MI techniques are used to explain factual association and hallucinations in Meng et al. (2022)
and Yuksekgonul et al. (2023), where the authors focused at the individual parameter-level showing that
while each MLP layer in the Transformer block has the ability to store factual associations, the attention
layeractsmorelikearouter,transferringfactualknowledgewhereitwillbeusedinthenextlayer. More-
over, as shown by Voita et al. (2023), having a full mechanistic interpretation of the evolution of network
parameters is important, as fully trained models display a large amount of neurons that never activate
(deadneurons).
Theseobservationsmotivateourstudy,asoneofthereasonswhymethodslikequantization(Dettmers&
Zettlemoyer,2023;Xiaoetal.,2023)andsparsification(Dettmersetal.,2022)leadtogooddownstreamre-
sults,isprobablyadecreaseinnetworkinformationduringtraining.Specifically,asdemonstratedbyAchille
etal.(2017),intheinitialpartoftraininganetworkweightsarehighlysensitivetoinputdataandtendto
contain less information. Once the connections are aligned with the data distribution, they are harder to
modify,anobservationthatisalsolinkedtolearningprocessesinanimalsandhuman(Najafietal.,2020).
In this respect, our work accumulates further experimental evidence about the presence of dead neurons
causedbycounteractinginhibitoryandexcitatoryeffects.
Furthermore, the curious phenomenon of grokking (Power et al., 2022) is analyzed with the lens of MI
in Nanda et al. (2023) where the sudden increase in validation accuracy is explained as a gradual (and
notsudden)amplificationofindividualneuralmechanismsencodedinthenetworkweights. Otherworks
such as the ones by Liu et al. (2022a;b) have instead leveraged statistical mechanics principles to decode
the intricate grokking behavior witnessed in deep learning models. The observations of our study are in
line with the questions raised in the work by Merrill et al. (2023): how does grokking relate to network
sparsification? In other words, are training set memorization (as in grokking) and extreme network self-
sparsificationtwoaspectsofthesamephenomenon? Indeed,grokkingcanbeseenasthecompetitionofa
densenetworkthatdominatesbeforethetransitionandgeneralizespoorly,andasparseonethatdominates
afterwards(Merrilletal.,2023).
TheemergingpropertiesofLLMs–andthelackthereof(Weietal.,2022)–canalsobeevaluatedinMIterms.
For example, the work by Schaeffer et al. (2023) has shown that emergent abilities are heavily dependent
onthenon-linearityoftheresearcher’schoiceofevaluationmetrics,ratherthanspecificphenomenawithin
networkweights. Indeed,whenevaluatingtheemergenceofabilitiesusingdiscreteevaluationmetrics(on
multipleanswersdatasets)anyimprovementisdetectedonlywhenexceedingarandomchoicethreshold,
thus giving the illusion of ’emergence’ while instead the answer is simply efficiently retrieved from the
pre-training weights (Lu et al., 2023). This is the main reason why we only concentrate on perplexity
measurements(Section4.2)ratherthanotherevaluationmetrics.
Motivatedbythesetheoreticalandempiricalinvestigationsinthenextsectionswedetailourmethodolog-
icalapproachandresults.
3 Materials and methods
3.1 Models and data
Weanalyzedthe143checkpointsofthewell-knownLLMPythia(Bidermanetal.,2023),trainedonboththe
deduplicated and non-deduplicated ThePile dataset (Gao et al., 2020) and made available by EleutherAI1
throughtheHuggingfaceplatform(Wolfetal.,2019)tofacilitateinterpretabilityworksinbothspatialand
temporalscalingdimensions.
1https://www.eleuther.ai
3Inpursuitofreproducibility,thePythiamodelsuiteensuresuniformityacrossitsnetworksbyemploying
identicalglobalarchitectures(seeSection3.2),utilizingthesameoptimizationmethod,andprocessingdata
fromaconsistentdatasetinastandardizedorder.
Thenetworksizerangesfromsmall(14Mparameters)toverylarge(≈ 12Bparameters),withthenumber
oflayersrangingfromaminimumofsixforthe14M,31Mand70Mmodels,toamaximumofthirty-sixfor
thelargest12Bmodel.
Importantly,wehaveutilizedtwosetsofmodelsandweindicateinthetextwhetherthemodelwastrained
onthededuplicated(DD)ornon-deduplicated(NDD)ThePiledataset. Morespecifically,thesmallestmod-
els from the Pythia suite (14M and 31M parameters) have been trained on the NDD dataset, while the
models from 70M parameters and above are instead trained on the DD dataset. We analyzed both the
NDDandDDmodels: whiletheunderlyingtrainingdatasetisdifferent,thebehaviourobservedontheir
dynamicsissimilar.
As a side note, although intermediate checkpoints have been disclosed for BLOOM as well (Workshop
et al., 2022), BLOOM has undergone training using a singular model size, specifically with 176 billion
parameters. Incontrast,Pythiahasbeentrainedacrossaspectrumofmodelsizes. Thisdistinctiveaspect,
facilitatingexaminationsofbotharchitecturalscalingandtrainingdynamics,servesastherationalebehind
ourpreferenceforPythiaoverBLOOM.Finally,duetothehighcomputationalcosts,thisworkfocuseson
the smallest models, with parameters count ranging from 14M to 1B, as indicated in Table 1 by boldface
rows.
3.2 Network architecture
WefollowthenotationdelineatedinMcGrathetal.(2023). Transformersfunctionbyprocessingsequences
oftensorsflowingthroughaseriesofself-attentionoperationsandtoken-wisefeed-forwardlayers. Math-
ematically, an auto-regressive language model is a map from t−1 input tokens x<t = (x 1,...,x t−1) to a
probabilitydistributionoverthenexttokenx usingafunction f :
t θ
p(x t|x<t) = f θ(x<t) (1)
=softmax(π t(x<t)) (2)
whereθarethenetworkparameters,distributedinmultipleblocksandlayers,andtheoutputtokenscores
π are called logits. The network architecture is encoded by the recursive function f , composed of a first
t θ
embeddinglayermappingtokensintothelatentnetworkspace(withanadditionalmatrixoflearnablepo-
sitionalembeddingsW ),andfollowedbyLrepeatedstackedlayersimplementingthefollowingrecursive
P
operations:
π =LayerNorm(zl)·W
t t U
zl = zl +al +ml
t t−1 t t
al =MHSA(zl−1)
t ≤t
ml =MLP(zl−1) (3)
t t
whereLayerNormisthelayernormalizationoperation(Baetal.,2016),MHSAistheMultiHeadSelfAtten-
tionoperator(Vaswanietal.,2017)andMLP(·)isatwolayerperceptronwithGeLUactivationfunction.
Our emphasis is on decoder-only, autoregressive language models employing a causal attention mask.
Specifically,thePythiamodels(Bidermanetal.,2023)arebasedontheGPT-NeoXarchitecturewithafew
modificationssuchastheintroductionofrotaryembeddingsforthematrixW (Suetal.,2021)anduntied2
P
embedding and unembedding matrices (Belrose et al., 2023), coloured in green in Figure 1. Additionally,
thebasicTransformerblockinPythiaentailsaMHSAoperatorimplementedthroughFlashAttention(Dao
etal.,2022)forcomputationalefficiencyreasons.
2AsopposedtotiedembeddingandunembeddingmatriceswhereW UT =WE.
4Moreprecisely,whiletheinnerdetailsoftheGPT-NeoXarchitectureareslightlydifferentfromthedescrip-
tionprovidedintherecursivesetofrulesindicatedinEq.3,themainlogicremainslargelythesame.
The last unembedding layer is represented by a rectangular matrix W mapping the latent embedding
U
space into the larger vocabulary space. Finally, the softmax operation converts the logits π to properly
t
normalized probabilities. The properties of the analyzed models in the Pythia suite utilized in this paper
arereportedinTable1.
ModelSize Non-embed. parameters Layers Embeddimension Heads Dataset
14M 1.2M 6 128 8 NDD
31M 4.7M 6 256 8 NDD
70M 19M 6 512 8 DD
160M 85M 12 768 12 DD
410M 302M 24 1024 16 DD
1.0B 806M 16 2048 8 DD
Table1: PropertiesofthePythiamodelsutilizedinthiswork.
Embeddingparameters’countistheproductofembeddingdimensiontimesthevocabularysizeandhasa
largereffectinsmallerandshallowermodels,whereasinlargermodelsthisisproportionallylessrelevant.
TheentirePythiadecoder-onlynetworkarchitectureisshowninFigure1.
A. B. C.
Output logits π 14M model 1B model
Tr
ai
ni
Unembedding n g
st
W U e p
Add & Norm
Feedforward W U t=1k A t=1k
Add & Norm
W U t=143k A t=143k
Multi head D.
attention A
Step 1000
1B model
Step 143k
Rotary embeddings
+
encoding
Input
embeddings
One-hot tokens Vocabulary
Figure 1: Panel A. Pythia models’ basic architecture. The unembedding layer W is the last green layer.
U
The attention matrix A is entailed in the red coloured multi-head self attention layer. Panel B. shows the
outputembeddingmatrixatfirstandlasttrainingstepforthe14Mmodel. Forillustrationpurposethefirst
512outof50304columnsareshown. PanelC.showsthefirstlayerattentionmatrixatfirstandlasttraining
stepforthe1Bmodel. PanelDshowstheaverageoftokenlogitsofalongsentenceforthe1Bmodelboth
atfirstandlasttrainingstep.
5
N
x
redoceD
eulav
stigoL3.2.1 Dealing with very large arrays
Eachmodelincludes143trainingcheckpointsatconstantintervalsof1000steps–fromstep1000to143,000.
Storinginmemory,forinstancethe70Mmodel,isfeasible,requiringapproximately24GBofRAMforthe
fullsnapshotinfloat16precision; however, thisprovesunfeasiblewithlargermodelsduetorapidlyes-
calating memory requirements. For this reason, we have selectively sliced specific layers of the network,
whileavoidingexplicitstorageinmemoryoperatingthroughdisk/memorymapping. Thismemorymap-
pingoperationallowstovisualizethetemporalevolutionoverthetrainingdimensionofspecificsubsetsof
themodelparameters.
4 Results
Inthissection,weprovideanumberofinterestingobservationsaboutthetemporaldynamicsofindividual
network parameters. We have focused our analysis on the final unembedding layer represented by W ,
U
alargerectangularmatrixmappingthelatentembeddingspaceintothevocabularyspace(andviceversa
for the initial embedding layer). The matrix W has shape (d, v), where d is the embedding dimension
U
specific to each model, ranging from 128 to 2048, and v = 50304 is the fixed vocabulary size of the BPE
tokenizer(Blacketal.,2022). EachofthePythiasuitemodels,asdescribedearlier,contains143checkpoints
of W . Importantly, the unembedding layer W provides a direct mapping from the latent embedding
U U
spacetothemoreexplainabledictionaryspacewhereeachelementisatoken.
4.1 Temporal dynamic of unembedding layer parameters
WedenotetheentirehistoryofunembeddinglayermatricesW withelementsw ,where: thefirstindex
U tdv
t denotes the checkpoint 1000 ≤ t ≤ 143000; d is the embedding dimension, and the v is the vocabulary
size. Forvisualizationpurposes,weflattenw overthelasttwodimensionstoobtainamatrixwithtwo
tdv
indicestandkwherek =1,...(d×v).
Figure2showsthetemporalevolutionoftheparameterdensityfortheunembeddinglayerdenotedasw
tk
forthe14M,31M,70Mand160Mmodels,topleft,topright,bottomleftandbottomrightpanelrespectively.
14Mand31Mmodelsweretrainedonthenon-deduplicated(NDD)versionofThePiledataset,while70M
and160Mmodelsweretrainedonthededuplicated(DD)versionofThePiledataset. Figure2showshow
suchmodelsexhibitabruptchangesintheirtemporaldynamics. Allmodelsdisplaytwoclearregimes: the
firstoneisdiffusive,thesecondoneisbimodalquasi-deterministic. Forexample,inthebottomleftpanel,
we observe how, for the 70M model, these two clear regimes emerge: before reaching ≈ 80,000 training
steps, the dynamics of the model’s parameters resemble a diffusion process; conversely, after ≈ 80,000
trainingsteps,theweightsmoveintoabimodalquasi-deterministicprocess. Fromthebottomrightpanel
of Figure 2, we observe a very similar behavior for the 160M model, only shifted temporally along the
training time axis, and thus emerging after ≈ 105,000 training steps. The other two models, i.e., 14M
and 31M, exhibit the same behavior; however, because they were trained on a different dataset, namely,
thenon-deduplicated(NDD)one,acomparisonbetweenthefourmodelstounderstandapossiblescaling
with the number of training steps cannot be made and it will be addressed in future publications. Here,
theonlyobservationwecanmakeisthatthecompositionofthedatasetmightinfluencethetimingofthe
bifurcation event (Ott, 2002). Specifically, when training involves non-deduplicated (NDD) datasets, the
redundantinformationcontainedwithinmayhindertherapidapproachtothebifurcationpoint.
The observation that the models’ weights reach a stationary state through their own dynamics, as men-
tioned in the introduction, naturally suggests a practical protocol for spontaneously ending the training
process: thisbifurcationmarksatransitiontoastationarystate,indicatingthatfurthertrainingisunlikely
to significantly alter the weight values. Thus, by observing the absence of significant fluctuations in the
dynamics,onecanefficientlyterminatethetraininguponachievingsuchastationarystate. Moreover,our
observations also suggest that a specific quantization of the weights can be performed. Indeed, as shown
in Ma & et al. (2024), using a ternary set of {−1,0,1} for each parameter, the performance of large lan-
guage models (LLMs) remains unchanged. In our observations, particularly in the unembedding layer, a
quantizationtodistinctvaluesfortheweightsoccursnaturally.
614M 31M
0 20 40 60 80 100 120 140 0 20 40 60 80 100 120 140
Trainingstep(103) Trainingstep(103)
70M 160M
0 20 40 60 80 100 120 140 0 20 40 60 80 100 120 140
Trainingstep(103) Trainingstep(103)
Figure2: Dynamicsofthedensityoftheunembeddinglayerforfourmodels. Onthefirstrowthemodels
trainedonNDDdataset,onthebottomrowthemodelstrainedonDDdataset.
To better quantify the above observations, we have computed the mean square displacement over time
for the models. To do this, we integrate the demeaned slices of w over the first dimension t from 1 to τ
tk
obtaininganewarraywˆ as:
τ
∑
wˆ = w −⟨w ⟩, (4)
τk tk tk
t=1
where ⟨w ⟩ = 1 ∑d×vw . We then indicate the variance of wˆ over each temporal slice as the mean
tk d×v k=1 tk τk
squaredisplacementMSD(τ),definedas:
MSD(τ) =
1 d ∑×v
wˆ2 (5)
(d×v)−1 τk
k=1
Figure3illustratestheevolutionofMSD(τ)overtheavailablecheckpointsforthe70Mand160Mmodels
aswellforthe14Mand31M.Inphysics,Brownianmotion(Uhlenbeck&Ornstein,1930)displaysalinear
relationbetweenmean-squareddisplacementandtime(Zwanzig,2001). Inthiscaseforbothmodels, we
observe a quasi-linear growth. We believe this has to do with unbounded brownian diffusion in a first
phaseoftraining,whereuniformspreadingofnetworkparameterstakesplacewithinthelosslandscape.
7
ytisneD
ytisneD ytisneD
ytisneDHowever, surprisingly after a peak in MSD(τ), corresponding exactly to the bifurcation (Strogatz, 2018)
discussedabove,asharpfallfollows. ThedrasticdecreaseofMSD(τ)(toitsownsmallvalue)isrelatedto
sub-lineardiffusion,aphenomenonhappeninginthephysicsofcrowdedsystems(Koketal.,2016),where
thenetworkisapproachinganarrowminimuminthelossfunctionlandscape.
Wehypothesizethattheabovedescribedbifurcationprocesswillappearforthe410Mmodeltoo,however
wearerestrictedbythelimitedcheckpointavailability. Hence, wereasonablybelievethatthebifurcation
hypothesisisvalidandlistsomeobservationssupportingitinthenextsectionsofthismanuscript.
10 70M 40 14M
160M 31M
8
30
6
20
4
10
2
0 0
0 20 40 60 80 100 120 140 0 20 40 60 80 100 120 140
Trainingstep(103) Trainingstep(103)
Figure 3: Mean square displacement over unembedding layer weights as a function of the training steps.
Left: thesmallest70Mand160Monthededupeddataset. Right: thesmallestmodels14Mand31Monthe
non-dedupeddataset. Verticaldashedlinesareshownatthepeak MSD(τ).
Importantly,theMSD(τ)isanimplicitmodelpropertyanditisnotdependentonevaluationdatasets. In
thenextsectionswedrawaparallelbetweentheobservedpatternofgradualincreaseandsuddendecrease
of MSD(τ) with model perplexity, suggesting that this numerical figure may significantly influence text
generationtasks. Thisobservationmakesitpossibletonumericallypredicttheonsetofbettertextquality
withouttheneedofstandardevaluationmetrics,likethosebasedonmultipleanswerorthosebasedonlast
wordprediction(Wangetal.,2018;Papernoetal.,2016).
4.2 Evaluation of model perplexity
Wehaveevaluatedthemodelperplexitybasedontokenlogitsofaseriesoffixedlengthphrases. Notwith-
standing some known limitations, like direct effects of punctuation marks or dependency with text
length (Wang et al., 2022), perplexity is widely considered a fair and intuitive metric and it is commonly
adopted for language modeling evaluation. Indeed, as demonstrated in Dettmers & Zettlemoyer (2023),
evaluationsbasedonperplexityaresufficientandpreferableforcomparingtextgenerationtasks.
Perplexity is defined for a sequence of T tokens X = (x ,x ,...,x ) as the exponential of the average of
0 1 T
negativelog-likelihoodsofasequenceoftokens. Itreads:
(cid:40) (cid:41)
1 ∑T
PPL(X) =exp −
T
logp θ(x t|x<i) , (6)
i=1
where p θ(x t|x<t) is defined in Equation 1. Lower perplexity values indicate that the model is predicting
thenexttokenwithhighlevelofconfidence,whilehighperplexityindicatesthatmostofthetokensappear
withequallylikelyprobability,henceprovidingthetextgenerationphasewithhighlevelsofambiguityon
thenexttokentopredict.
4.2.1 Forward approach
Wehaveevaluatedtheperplexityofentiresentencescontainedinthefirst500elementsofthetestsetofthe
Lambadadataset(Papernoetal.,2016).
8
)τ(DSM )τ(DSMWe computed the perplexity score for the above sentences across all the models mentioned in the text,
consideringdifferentcheckpointsandmodelsizes. Theresults,showninFigure4,confirmthebifurcation
behaviourobservedovertheunembeddinglayerbothfortheDDandNDDmodels.
The effect is more evident when appreciated in the logarithmic scale (right panel, Figure 4). The model
perplexity drops to zero exactly for the checkpoints where the bifurcation starts. We have limited the
evaluationon10%oftheLambadatestsetforcomputationalreasons.
70M 100
40 160M
410M 10−3
1B
30
14M 10−6
31M
20 10−9
Model
70M
10−12
410M
10 160M
10−15 1 1B
4M
0 31M
0 20000 40000 60000 80000 100000120000140000
10−18
0 20000 40000 60000 80000 100000120000140000
Trainingstep(103) Trainingstep(103)
Figure4: Perplexityofgeneratedtokensonthefirst500examplesofthetestsetofLambadadataset. Left:
perplexityexpressedinlinearscale. Right: sameplotofperplexitybutexpressedinlogarithmicscale. An
horizontalblacklineisdrawnatzeroperplexityinbothplots.
4.2.2 Causal unmasking approach
In parallel to the above simple perplexity calculation, we have devised another method to augment the
dataset that takes into account the model generated text quality. In detail, we have run a text generation
processwithcausalunmaskingofthetokensineachphrase.
WefirsttokenizedeachindividualsentenceswiththeGPTNeoxTokenizer,obtainingasequenceoft tokens
s
X = (x ,...x ). ForeachtokenizedsentenceX wethenconsideredthesetofallt linearlyorderedsub-
s 1 ts s s
sentencesrangingfromlength1to t , inotherwordstheset x = {(x ,...,x )} with k ≤ t . Wethenlet
s sk 1 k s
themodelcompleteeachofthesub-sentencesx uptotheoriginallengtht ,resultinginatotaloft setsof
sk s s
logitsforeachsentenceX.
Attheinitialphasewithonlyfewtokensbeingavailable,themodelisforcedtogeneratealargenumberof
remainingtokens,withresultsthatspawnfrompurerepetitionoffewtokens(inearlyphasesoftraining)
torepeatedemissionoflongersub-sequences. Inthiswaywecanevaluatehowthemodelbuildsuponits
internalknowledge,havingonlyafewtokensatdisposal. Ontheotherhand,whenapproachingtheend
of the phrase, we expect logits to be more sharply peaked. For this reason, we verified if logits are more
sharplypeakedaroundcertaintokens.Asexpected,largermodelstendtoproviderealistictextseveninthe
earlyphasesoftraining,whilesmallermodelshavethetendencytorepeatpartsoftheunmaskedinput.
WeillustratethecausalunmaskingprocessinFigure5withashortexamplephrase.
Similarlytowhatobservedwiththeforwardapproach,Figure6showsadramaticdroptowardszeroofthe
perplexityforboththe70Mand160Mmodelsexactlyatthesamecheckpointsdisplayingtheemergenceof
bifurcation in the parameters’ plot and the drop of the diffusion coefficient as already shown in Figure 3.
Wealsonotethat,ashypothesizedabove,perplexityforthe410Mmodelisstartingtodroptozerocloseto
thelastcheckpoints. Thisbehavioursupportsourhypothesisthatlargermodelsshouldtendtoexhibitthe
bifurcationbehaviour,butonlywhentrainedlongerthanfortheavailablecheckpoints.
9
ytixelpreP ytixelprePInput sentence
New York is the most popular
Model generation
New New New . New New
New York city city city city
New York is New New New
New York is the city city city
New York is the most great
New York is the most popular
Figure5: Causalunmaskingprocess. Thetokenizedsentenceisusedtogeneratesixnewsentences,where
themodelcompletesfromaninitialsetoftokensuptotheinitialphrasenumberoftokens. Ateachnewly
generatedsub-sentencethemodelgeneratesnewtokens,depictedingray.
30 70M 100
160M
25
410M
10−3
20 1B 10−6
15
10−9
10
10−12
5
10−15
0
10−18
0 25 50 75 100 125 150 0 25 50 75 100 125 150
Trainingstep(103) Trainingstep(103)
Figure6:Perplexityofgeneratedtokenswiththecausalunmaskingapproach.Left:perplexityexpressedin
linearscale.Right:sameplotofperplexitybutexpressedinlogarithmicscale.Itispossibletoseeperplexity
rapidlygoingtozeroexactlyatthepointofmaximumMSD(τ). Thesmallermodels,14Mand31M,arenot
showninthefiguresolelyforthesakeofimageclarity,buttheyshowthesamebehaviour.
4.3 Rank of output embedding layer covariance
Tosupportourfindings,wehavefinallytestedanhypothesisregardingthemultidimensionaldistribution
of the embedding vectors produced by the last output unembedding matrix for all models, but here we
presenttheresultsonlyforthe70Mand160Mmodels.
We have fed batches of various sizes (from 16 to 64) of multivariate normally distributed vectors V ∼
N(0,I )andmultipliedthemwiththeoutputunembeddingmatrixW atdifferentcheckpointstoget
d
embed
Ut
transformedbatchesofvectorsVˆ = W ·V.
t Ut
Then,wehavecomputedthecovariancematricesC overthebatchdimensionoftheresultingvectorsVˆ
t t
and evaluated rank(C ) up to a tolerance parameter with values in the domain [0.1,1]. The covariance
t
matrixrankshrinksatdifferenttolerancelevelsexactlyatthecheckpointsforwhichthemodelexhibitsthe
bifurcationintheweights’dynamicsasfromFigure2.
10
ytixelpreP ytixelprePFigure7: Thecovariancerank(leftcolumn)anditsfirstderivative(rightcolumn)forthe70Mmodel(top
row)andforthe160Mmodel(bottomrow).
TheneteffectofthecovariancematrixshrinkageobservedinFigure7istheprojectionofisotropicembed-
dings onto a smaller subspace of the full vocabulary. This suggests that after the bifurcation, the model
focusesonasubsetofthepossibleemittedtokens,leavingamuchsmallerprobabilitytotokensassociated
withdimensionsforwhichthesubspaceisreduced, inaccordancetotheunevendistributionofwordsin
naturallanguage,whichisknowntofollowapower-lawdistributionofwords(Zipf,1949).
5 Conclusions
In this study we have analyzed both the temporal and spatial dimensions of training a large language
model. As discussed above, our work is the first one dealing with distribution of network weights as a
whole,bymeansofcomputationalmethodsborrowedfromstatisticalmechanics.
More specifically, this work shows that a bifurcation occurs in the dynamics of the weights during the
trainingprocess.Suchtransitionsareobservedacrossvariousmodelsofdifferentsizestrainedwithdistinct
datasets. We have conducted a thorough and meticulous analysis of this aspect and concluded that this
bifurcationmarksatransitiontoastationarystate,indicatingthatfurthertrainingisunlikelytosignificantly
altertheweightvalues. Thus,trainingcanbeefficientlyterminateduponreachingsuchastationarystate.
Moreover,ourstudyhasofferedapossibleinterpretationofthebifurcationphenomenonintermsofmodel
perplexity.
11Just as in the early days of thermodynamics, when empirical observations drove technological advance-
ments,weadvocateforthedevelopmentofLargeLanguageModels(LLMs)tobegroundedintheobser-
vationoftheirinternaldynamics. Theidentificationofstationarystatesintheweightdynamicsexemplifies
thisphilosophy,markingasteptowardamoreobservationalandtheoreticallyinformedapproachtoLLM
development.
Intriguingly, we finally note how recent works in the physics of complex networks point at diversity of
informationpathwaysasthemaindriverofsparsityinrealnetworksGhavasieh&DeDomenico(2024): in
thissense,wehypothesizethatthepoli-semanticityofnaturallanguagemayactasthemaindrivingforce
fornetworkself-sparsification.
The presented results can have far-reaching implications as they demonstrate that keeping track of the
collectivebehaviourofnetworkweightscouldbeapowerfulindicatoroftrainingconvergence,asopposed
to the classical methods based on evaluation metrics which suffer from the confounding effects of non-
linearity, hencegivingraisetofalseclaimsabout"emergent"properties. Asafuturework, wewouldlike
to further investigate the training loss dynamics, to check whether the sudden changes in quantitative
microscopic parameters align with the development of induction heads in the model, as shown by (Bietti
etal.,2023).
Acknowledgments
We thank Ipazia S.p.A. for offering computing resources. The work of J.S. has been partially funded by
IpaziaS.p.A.R.M.issupportedby#NEXTGENERATIONEU(NGEU)andfundedbytheMinistryofUni-
versityandResearch(MUR),NationalRecoveryandResiliencePlan(NRRP),projectMNESYS(PE0000006)
"A Multiscale integrated approach to the study of the nervous system in health and disease" (DR. 1553
11.10.2022).
References
AlessandroAchille,MatteoRovere,andStefanoSoatto. Criticallearningperiodsindeepneuralnetworks.
arXivpreprintarXiv:1711.08856,2017.
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450,2016.
NoraBelrose,ZachFurman,LoganSmith,DannyHalawi,IgorOstrovsky,LevMcKinney,StellaBiderman,
and Jacob Steinhardt. Eliciting latent predictions from transformers with the tuned lens. arXiv preprint
arXiv:2303.08112,2023.
Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mo-
hammadAflahKhan,ShivanshuPurohit,USVSNSaiPrashanth,EdwardRaff,etal. Pythia: Asuitefor
analyzinglargelanguagemodelsacrosstrainingandscaling. arXivpreprintarXiv:2304.01373,2023.
AlbertoBietti,VivienCabannes,DianeBouchacourt,HerveJegou,andLeonBottou. Birthofatransformer:
Amemoryviewpoint. arXivpreprintarXiv:2306.00802,2023.
SidBlack,StellaBiderman,EricHallahan,QuentinAnthony,LeoGao,LaurenceGolding,HoraceHe,Con-
nor Leahy, Kyle McDonell, Jason Phang, et al. Gpt-neox-20b: An open-source autoregressive language
model. arXivpreprintarXiv:2204.06745,2022.
Trenton Bricken, Adly Templeton, Joshua Batson, Brian Chen, Adam Jermyn, Tom Conerly, Nick Turner,
Cem Anil, Carson Denison, Amanda Askell, Robert Lasenby, Yifan Wu, Shauna Kravec, Nicholas
Schiefer, Tim Maxwell, Nicholas Joseph, Zac Hatfield-Dodds, Alex Tamkin, Karina Nguyen, Brayden
McLean, Josiah E Burke, Tristan Hume, Shan Carter, Tom Henighan, and Christopher Olah. Towards
monosemanticity: Decomposinglanguagemodelswithdictionarylearning. TransformerCircuitsThread,
2023. https://transformer-circuits.pub/2023/monosemantic-features/index.html.
12Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,
ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei. Languagemod-
els are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Ad-
vancesinNeuralInformationProcessingSystems,volume33,pp.1877–1901.CurranAssociates,Inc.,2020.
HilaChefer, ShirGur, andLiorWolf. Transformerinterpretabilitybeyondattentionvisualization. InPro-
ceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,pp.782–791,2021.
Arthur Conmy, Augustine N Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adrià Garriga-
Alonso. Towards automated circuit discovery for mechanistic interpretability. arXiv preprint
arXiv:2304.14997,2023.
TriDao,DanFu,StefanoErmon,AtriRudra,andChristopherRé.Flashattention:Fastandmemory-efficient
exact attention with io-awareness. Advances in Neural Information Processing Systems, 35:16344–16359,
2022.
TimDettmersandLukeZettlemoyer. Thecasefor4-bitprecision: k-bitinferencescalinglaws. InInterna-
tionalConferenceonMachineLearning,pp.7750–7774.PMLR,2023.
TimDettmers,MikeLewis,YounesBelkada,andLukeZettlemoyer. Llm.int8():8-bitmatrixmultiplication
fortransformersatscale. arXivpreprintarXiv:2208.07339,2022.
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Un-
terthiner,MostafaDehghani,MatthiasMinderer,GeorgHeigold,SylvainGelly,etal. Animageisworth
16x16words: Transformersforimagerecognitionatscale. arXivpreprintarXiv:2010.11929,2020.
LeoGao,StellaBiderman,SidBlack,LaurenceGolding,TravisHoppe,CharlesFoster,JasonPhang,Horace
He,AnishThite,NoaNabeshima,etal.Thepile:An800gbdatasetofdiversetextforlanguagemodeling.
arXivpreprintarXiv:2101.00027,2020.
BorjanGeshkovski,CyrilLetrouit,YuryPolyanskiy,andPhilippeRigollet. Amathematicalperspectiveon
transformers. 2023.
Arsham Ghavasieh and Manlio De Domenico. Diversity of information pathways drives sparsity in real
worldnetworks. NaturePhysics,pp.1–8,2024.
Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang,
Zhengdong Zhang, Yonghui Wu, et al. Conformer: Convolution-augmented transformer for speech
recognition. arXivpreprintarXiv:2005.08100,2020.
WesGurneeandMaxTegmark.Languagemodelsrepresentspaceandtime.arXivpreprintarXiv:2310.02207,
2023.
KersonHuang. Statisticalmechanics. JohnWiley&Sons,2008.
Ven Jyn Kok, Mei Kuan Lim, and Chee Seng Chan. Crowd behavior analysis: A review where physics
meetsbiology. Neurocomputing,177:342–362,2016.
Ziming Liu, Ouail Kitouni, Niklas S Nolte, Eric Michaud, Max Tegmark, and Mike Williams. Towards
understandinggrokking: Aneffectivetheoryofrepresentationlearning. AdvancesinNeuralInformation
ProcessingSystems,35:34651–34663,2022a.
Ziming Liu, Eric J Michaud, and Max Tegmark. Omnigrok: Grokking beyond algorithmic data. arXiv
preprintarXiv:2210.01117,2022b.
ZimingLiu,EricGan,andMaxTegmark. Seeingisbelieving: Brain-inspiredmodulartrainingformecha-
nisticinterpretability. Entropy,26(1):41,2024.
13Sheng Lu, Irina Bigoulaeva, Rachneet Sachdeva, Harish Tayyar Madabushi, and Iryna Gurevych. Are
emergent abilities in large language models just in-context learning? arXiv preprint arXiv:2309.01809,
2023.
Shuming Ma and et al. The era of 1-bit llms: All large language models are in 1.58 bits. arXiv preprint
arXiv:2402.17764,2024.
Shuming Ma, Hongyu Wang, Lingxiao Ma, Lei Wang, Wenhui Wang, Shaohan Huang, Li Dong, Ruiping
Wang,JilongXue,andFuruWei. Theeraof1-bitllms: Alllargelanguagemodelsarein1.58bits. arXiv
preprintarXiv:2402.17764,2024.
Thomas McGrath, Matthew Rahtz, Janos Kramar, Vladimir Mikulik, and Shane Legg. The hydra effect:
Emergentself-repairinlanguagemodelcomputations. arXivpreprintarXiv:2307.15771,2023.
KevinMeng,DavidBau,AlexAndonian,andYonatanBelinkov. Locatingandeditingfactualassociations
ingpt. AdvancesinNeuralInformationProcessingSystems,35:17359–17372,2022.
William Merrill, Nikolaos Tsilivis, and Aman Shukla. A tale of two circuits: Grokking as competition of
sparseanddensesubnetworks. arXivpreprintarXiv:2303.11873,2023.
JatinNainani. Evaluatingbrain-inspiredmodulartraininginautomatedcircuitdiscoveryformechanistic
interpretability. 2024.
FarzanehNajafi,GamaleldinFElsayed,RobinCao,EftychiosPnevmatikakis,PeterELatham,JohnPCun-
ningham,andAnneKChurchland. Excitatoryandinhibitorysubnetworksareequallyselectiveduring
decision-makingandemergesimultaneouslyduringlearning. Neuron,105(1):165–179,2020.
Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress measures
for grokking via mechanistic interpretability. ArXiv, abs/2301.05217, 2023. URL https://api.
semanticscholar.org/CorpusID:255749430.
Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. Feature visualization. Distill, 2017. doi: 10.
23915/distill.00007. https://distill.pub/2017/feature-visualization.
EdwardOtt. Chaosindynamicalsystems. Cambridgeuniversitypress,2002.
Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro
Pezzelle,MarcoBaroni,GemmaBoleda,andRaquelFernández. Thelambadadataset: Wordprediction
requiringabroaddiscoursecontext. arXivpreprintarXiv:1606.06031,2016.
AletheaPower,YuriBurda,HarriEdwards,IgorBabuschkin,andVedantMisra. Grokking: Generalization
beyondoverfittingonsmallalgorithmicdatasets. arXivpreprintarXiv:2201.02177,2022.
Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. Are emergent abilities of large language models a
mirage? arXivpreprintarXiv:2304.15004,2023.
OlafSporns. NetworksoftheBrain. MITpress,2016.
Steven H Strogatz. Nonlinear dynamics and chaos with student solutions manual: With applications to physics,
biology,chemistry,andengineering. CRCpress,2018.
Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced
transformerwithrotarypositionembedding. arXivpreprintarXiv:2104.09864,2021.
GeorgeEUhlenbeckandLeonardSOrnstein. Onthetheoryofthebrownianmotion. Physicalreview,36(5):
823,1930.
AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,ŁukaszKaiser,
andIlliaPolosukhin. Attentionisallyouneed. Advancesinneuralinformationprocessingsystems,30,2017.
JesseVig. Amultiscalevisualizationofattentioninthetransformermodel. 2019.
14Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov. Analyzing multi-head self-
attention: Specializedheadsdotheheavylifting,therestcanbepruned. arXivpreprintarXiv:1905.09418,
2019.
Elena Voita, Javier Ferrando, and Christoforos Nalmpantis. Neurons in large language models: Dead, n-
gram,positional. arXivpreprintarXiv:2309.04827,2023.
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue:
A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint
arXiv:1804.07461,2018.
YequanWang,JiawenDeng,AixinSun,andXuyingMeng. Perplexityfromplmisunreliableforevaluating
textquality. arXivpreprintarXiv:2210.05892,2022.
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
MaartenBosma,DennyZhou,DonaldMetzler,etal. Emergentabilitiesoflargelanguagemodels. arXiv
preprintarXiv:2206.07682,2022.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric
Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers: State-of-the-art
naturallanguageprocessing. arXivpreprintarXiv:1910.03771,2019.
BigScience Workshop, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic´, Daniel
Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, et al. Bloom: A 176b-parameter
open-accessmultilinguallanguagemodel. arXivpreprintarXiv:2211.05100,2022.
GuangxuanXiao,JiLin,MickaelSeznec,HaoWu,JulienDemouth,andSongHan. Smoothquant:Accurate
andefficientpost-trainingquantizationforlargelanguagemodels,2023.
ZepingYuandKailaiYang. Exploringtheresidualstreamoftransformers,112023.
Mert Yuksekgonul, Varun Chandrasekaran, Erik Jones, Suriya Gunasekar, Ranjita Naik, Hamid Palangi,
Ece Kamar, and Besmira Nushi. Attention satisfies: A constraint-satisfaction lens on factual errors of
languagemodels. arXivpreprintarXiv:2309.15098,2023.
George Kingsley Zipf. Human behavior and the principle of least effort. 1949. URL https://api.
semanticscholar.org/CorpusID:141120597.
RobertZwanzig. Nonequilibriumstatisticalmechanics. Oxforduniversitypress,2001.
15