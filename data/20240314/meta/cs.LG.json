[
    {
        "title": "Simple and Scalable Strategies to Continually Pre-train Large Language Models",
        "authors": "Adam IbrahimBenjamin ThérienKshitij GuptaMats L. RichterQuentin AnthonyTimothée LesortEugene BelilovskyIrina Rish",
        "links": "http://arxiv.org/abs/2403.08763v1",
        "entry_id": "http://arxiv.org/abs/2403.08763v1",
        "pdf_url": "http://arxiv.org/pdf/2403.08763v1",
        "summary": "Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to start the process over again once new data becomes available. A much\nmore efficient solution is to continually pre-train these models, saving\nsignificant compute compared to re-training. However, the distribution shift\ninduced by new data typically results in degraded performance on previous data\nor poor adaptation to the new data. In this work, we show that a simple and\nscalable combination of learning rate (LR) re-warming, LR re-decaying, and\nreplay of previous data is sufficient to match the performance of fully\nre-training from scratch on all available data, as measured by final loss and\nlanguage model (LM) evaluation benchmarks. Specifically, we show this for a\nweak but realistic distribution shift between two commonly used LLM\npre-training datasets (English$\\rightarrow$English) and a stronger distribution\nshift (English$\\rightarrow$German) at the $405$M parameter model scale with\nlarge dataset sizes (hundreds of billions of tokens). Selecting the weak but\nrealistic shift for larger-scale experiments, we also find that our continual\nlearning strategies match the re-training baseline for a 10B parameter LLM. Our\nresults demonstrate that LLMs can be successfully updated via simple and\nscalable continual learning strategies, matching the re-training baseline using\nonly a fraction of the compute. Finally, inspired by previous work, we propose\nalternatives to the cosine learning rate schedule that help circumvent\nforgetting induced by LR re-warming and that are not bound to a fixed token\nbudget.",
        "updated": "2024-03-13 17:58:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.08763v1"
    },
    {
        "title": "Efficient Combinatorial Optimization via Heat Diffusion",
        "authors": "Hengyuan MaWenlian LuJianfeng Feng",
        "links": "http://arxiv.org/abs/2403.08757v1",
        "entry_id": "http://arxiv.org/abs/2403.08757v1",
        "pdf_url": "http://arxiv.org/pdf/2403.08757v1",
        "summary": "Combinatorial optimization problems are widespread but inherently challenging\ndue to their discrete nature.The primary limitation of existing methods is that\nthey can only access a small fraction of the solution space at each iteration,\nresulting in limited efficiency for searching the global optimal. To overcome\nthis challenge, diverging from conventional efforts of expanding the solver's\nsearch scope, we focus on enabling information to actively propagate to the\nsolver through heat diffusion. By transforming the target function while\npreserving its optima, heat diffusion facilitates information flow from distant\nregions to the solver, providing more efficient navigation. Utilizing heat\ndiffusion, we propose a framework for solving general combinatorial\noptimization problems. The proposed methodology demonstrates superior\nperformance across a range of the most challenging and widely encountered\ncombinatorial optimizations. Echoing recent advancements in harnessing\nthermodynamics for generative artificial intelligence, our study further\nreveals its significant potential in advancing combinatorial optimization.",
        "updated": "2024-03-13 17:55:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.08757v1"
    },
    {
        "title": "DAM: Dynamic Adapter Merging for Continual Video QA Learning",
        "authors": "Feng ChengZiyang WangYi-Lin SungYan-Bo LinMohit BansalGedas Bertasius",
        "links": "http://arxiv.org/abs/2403.08755v1",
        "entry_id": "http://arxiv.org/abs/2403.08755v1",
        "pdf_url": "http://arxiv.org/pdf/2403.08755v1",
        "summary": "We present a parameter-efficient method for continual video\nquestion-answering (VidQA) learning. Our method, named DAM, uses the proposed\nDynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable\nefficient adaptation to continually arriving datasets, (iii) handle inputs from\nunknown datasets during inference, and (iv) enable knowledge sharing across\nsimilar dataset domains. Given a set of continually streaming VidQA datasets,\nwe sequentially train dataset-specific adapters for each dataset while freezing\nthe parameters of a large pretrained video-language backbone. During inference,\ngiven a video-question sample from an unknown domain, our method first uses the\nproposed non-parametric router function to compute a probability for each\nadapter, reflecting how relevant that adapter is to the current video-question\ninput instance. Subsequently, the proposed dynamic adapter merging scheme\naggregates all the adapter weights into a new adapter instance tailored for\nthat particular test sample to compute the final VidQA prediction, mitigating\nthe impact of inaccurate router predictions and facilitating knowledge sharing\nacross domains. Our DAM model outperforms prior state-of-the-art continual\nlearning approaches by 9.1% while exhibiting 1.9% less forgetting on 6 VidQA\ndatasets spanning various domains. We further extend DAM to continual image\nclassification and image QA and outperform prior methods by a large margin. The\ncode is publicly available at: https://github.com/klauscc/DAM",
        "updated": "2024-03-13 17:53:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.08755v1"
    },
    {
        "title": "Neural reproducing kernel Banach spaces and representer theorems for deep networks",
        "authors": "Francesca BartolucciErnesto De VitoLorenzo RosascoStefano Vigogna",
        "links": "http://arxiv.org/abs/2403.08750v1",
        "entry_id": "http://arxiv.org/abs/2403.08750v1",
        "pdf_url": "http://arxiv.org/pdf/2403.08750v1",
        "summary": "Studying the function spaces defined by neural networks helps to understand\nthe corresponding learning models and their inductive bias. While in some\nlimits neural networks correspond to function spaces that are reproducing\nkernel Hilbert spaces, these regimes do not capture the properties of the\nnetworks used in practice. In contrast, in this paper we show that deep neural\nnetworks define suitable reproducing kernel Banach spaces.\n  These spaces are equipped with norms that enforce a form of sparsity,\nenabling them to adapt to potential latent structures within the input data and\ntheir representations. In particular, leveraging the theory of reproducing\nkernel Banach spaces, combined with variational results, we derive representer\ntheorems that justify the finite architectures commonly employed in\napplications. Our study extends analogous results for shallow networks and can\nbe seen as a step towards considering more practically plausible neural\narchitectures.",
        "updated": "2024-03-13 17:51:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.08750v1"
    },
    {
        "title": "Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework",
        "authors": "Jingling LiZeyu TangXiaoyu LiuPeter SpirtesKun ZhangLiu LeqiYang Liu",
        "links": "http://arxiv.org/abs/2403.08743v1",
        "entry_id": "http://arxiv.org/abs/2403.08743v1",
        "pdf_url": "http://arxiv.org/pdf/2403.08743v1",
        "summary": "Large language models (LLMs) can easily generate biased and discriminative\nresponses. As LLMs tap into consequential decision-making (e.g., hiring and\nhealthcare), it is of crucial importance to develop strategies to mitigate\nthese biases. This paper focuses on social bias, tackling the association\nbetween demographic information and LLM outputs. We propose a causality-guided\ndebiasing framework that utilizes causal understandings of (1) the\ndata-generating process of the training corpus fed to LLMs, and (2) the\ninternal reasoning process of LLM inference, to guide the design of prompts for\ndebiasing LLM outputs through selection mechanisms. Our framework unifies\nexisting de-biasing prompting approaches such as inhibitive instructions and\nin-context contrastive examples, and sheds light on new ways of debiasing by\nencouraging bias-free reasoning. Our strong empirical performance on real-world\ndatasets demonstrates that our framework provides principled guidelines on\ndebiasing LLM outputs even with only the black-box access.",
        "updated": "2024-03-13 17:46:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.08743v1"
    }
]