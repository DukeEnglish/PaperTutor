[
    {
        "title": "Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation",
        "authors": "Zhenyu HeGuhao FengShengjie LuoKai YangDi HeJingjing XuZhi ZhangHongxia YangLiwei Wang",
        "links": "http://arxiv.org/abs/2401.16421v1",
        "entry_id": "http://arxiv.org/abs/2401.16421v1",
        "pdf_url": "http://arxiv.org/pdf/2401.16421v1",
        "summary": "In this work, we leverage the intrinsic segmentation of language sequences\nand design a new positional encoding method called Bilevel Positional Encoding\n(BiPE). For each position, our BiPE blends an intra-segment encoding and an\ninter-segment encoding. The intra-segment encoding identifies the locations\nwithin a segment and helps the model capture the semantic information therein\nvia absolute positional encoding. The inter-segment encoding specifies the\nsegment index, models the relationships between segments, and aims to improve\nextrapolation capabilities via relative positional encoding. Theoretical\nanalysis shows this disentanglement of positional information makes learning\nmore effective. The empirical results also show that our BiPE has superior\nlength extrapolation capabilities across a wide range of tasks in diverse text\nmodalities.",
        "updated": "2024-01-29 18:59:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.16421v1"
    },
    {
        "title": "Learning to Manipulate under Limited Information",
        "authors": "Wesley H. HollidayAlexander KristoffersenEric Pacuit",
        "links": "http://arxiv.org/abs/2401.16412v1",
        "entry_id": "http://arxiv.org/abs/2401.16412v1",
        "pdf_url": "http://arxiv.org/pdf/2401.16412v1",
        "summary": "By classic results in social choice theory, any reasonable preferential\nvoting method sometimes gives individuals an incentive to report an insincere\npreference. The extent to which different voting methods are more or less\nresistant to such strategic manipulation has become a key consideration for\ncomparing voting methods. Here we measure resistance to manipulation by whether\nneural networks of varying sizes can learn to profitably manipulate a given\nvoting method in expectation, given different types of limited information\nabout how other voters will vote. We trained nearly 40,000 neural networks of\n26 sizes to manipulate against 8 different voting methods, under 6 types of\nlimited information, in committee-sized elections with 5-21 voters and 3-6\ncandidates. We find that some voting methods, such as Borda, are highly\nmanipulable by networks with limited information, while others, such as Instant\nRunoff, are not, despite being quite profitably manipulated by an ideal\nmanipulator with full information.",
        "updated": "2024-01-29 18:49:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.16412v1"
    },
    {
        "title": "Scaling Sparse Fine-Tuning to Large Language Models",
        "authors": "Alan AnsellIvan VulićHannah SterzAnna KorhonenEdoardo M. Ponti",
        "links": "http://arxiv.org/abs/2401.16405v1",
        "entry_id": "http://arxiv.org/abs/2401.16405v1",
        "pdf_url": "http://arxiv.org/pdf/2401.16405v1",
        "summary": "Large Language Models (LLMs) are difficult to fully fine-tune (e.g., with\ninstructions or human feedback) due to their sheer number of parameters. A\nfamily of parameter-efficient sparse fine-tuning (SFT) methods have proven\npromising in terms of performance but their memory requirements increase\nproportionally to the size of the LLMs. In this work, we scale sparse\nfine-tuning to state-of-the-art LLMs like LLaMA 2 7B and 13B. At any given\ntime, for a desired density level, we maintain an array of parameter indices\nand the deltas of these parameters relative to their pretrained values. We\niterate among: (a) updating the active deltas, (b) pruning indices (based on\nthe change of magnitude of their deltas) and (c) regrowth of indices. For\nregrowth, we explore two criteria based on either the accumulated gradients of\na few candidate parameters or their approximate momenta estimated using the\nefficient SM3 optimizer. We experiment with instruction-tuning of LLMs on\nstandard dataset mixtures, finding that SFT is often superior to popular\nparameter-efficient fine-tuning methods like LoRA (low-rank adaptation) in\nterms of performance and comparable in terms of run time. We additionally show\nthat SFT is compatible with both quantization and efficient optimizers, to\nfacilitate scaling to ever-larger model sizes. We release the code for SFT at\nhttps://github.com/AlanAnsell/peft and for the instruction-tuning experiments\nat https://github.com/ducdauge/sft-llm.",
        "updated": "2024-01-29 18:43:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.16405v1"
    },
    {
        "title": "A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect",
        "authors": "Yunkang CaoXiaohao XuJiangning ZhangYuqi ChengXiaonan HuangGuansong PangWeiming Shen",
        "links": "http://arxiv.org/abs/2401.16402v1",
        "entry_id": "http://arxiv.org/abs/2401.16402v1",
        "pdf_url": "http://arxiv.org/pdf/2401.16402v1",
        "summary": "Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from the\nconcept of normality in visual data, widely applied across diverse domains,\ne.g., industrial defect inspection, and medical lesion detection. This survey\ncomprehensively examines recent advancements in VAD by identifying three\nprimary challenges: 1) scarcity of training data, 2) diversity of visual\nmodalities, and 3) complexity of hierarchical anomalies. Starting with a brief\noverview of the VAD background and its generic concept definitions, we\nprogressively categorize, emphasize, and discuss the latest VAD progress from\nthe perspective of sample number, data modality, and anomaly hierarchy. Through\nan in-depth analysis of the VAD field, we finally summarize future developments\nfor VAD and conclude the key findings and contributions of this survey.",
        "updated": "2024-01-29 18:41:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.16402v1"
    },
    {
        "title": "Zero-shot Imitation Policy via Search in Demonstration Dataset",
        "authors": "Federco MalatoFlorian LeopoldAndrew MelnikVille Hautamaki",
        "links": "http://arxiv.org/abs/2401.16398v1",
        "entry_id": "http://arxiv.org/abs/2401.16398v1",
        "pdf_url": "http://arxiv.org/pdf/2401.16398v1",
        "summary": "Behavioral cloning uses a dataset of demonstrations to learn a policy. To\novercome computationally expensive training procedures and address the policy\nadaptation problem, we propose to use latent spaces of pre-trained foundation\nmodels to index a demonstration dataset, instantly access similar relevant\nexperiences, and copy behavior from these situations. Actions from a selected\nsimilar situation can be performed by the agent until representations of the\nagent's current situation and the selected experience diverge in the latent\nspace. Thus, we formulate our control problem as a dynamic search problem over\na dataset of experts' demonstrations. We test our approach on BASALT\nMineRL-dataset in the latent representation of a Video Pre-Training model. We\ncompare our model to state-of-the-art, Imitation Learning-based Minecraft\nagents. Our approach can effectively recover meaningful demonstrations and show\nhuman-like behavior of an agent in the Minecraft environment in a wide variety\nof scenarios. Experimental results reveal that performance of our search-based\napproach clearly wins in terms of accuracy and perceptual evaluation over\nlearning-based models.",
        "updated": "2024-01-29 18:38:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.16398v1"
    }
]