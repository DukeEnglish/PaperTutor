Beyond Automated Evaluation Metrics: Evaluating Topic Models On
Practical Social Science Content Analysis Tasks
ZongxiaLi1 AndrewMao1 DanielStephens3 PranavGoel1
EmilyWalpole2 AldenDima2 JuanFung2 JordanBoyd-Graber1
1UniversityofMaryland,{zli12321, amao, pgoel, jbg}@cs.umd.edu
2NIST,{emily.walpole, alden.dima, juan.fung}@nist.gov
3MorganStateUniversity,dstephens@morgan.edu
Abstract documents as mixtures of latent topics, each rep-
resented by a distribution over words. The most
Topicmodelsareapopulartoolforunderstand-
ing text collections, but their evaluation has popular topic model, Latent Dirichlet Allocation
beenapointofcontention. Automatedevalua- (LDA)(Bleietal.,2003)hasover40,000citations
tionmetricssuchascoherenceareoftenused, withnumerousextensionsandvariants(Churchill
however,theirvalidityhasbeenquestionedfor andSingh,2022).
neuraltopicmodels(NTMs)andcanoverlook
Prior research has demonstrated the effective-
a model’s benefits in real-world applications.
ness of combining LDA with an active learning
Tothisend,weconductthefirstevaluationof
classifiertohelppeoplecreatelabelsetsmoreef-
neural,supervisedandclassicaltopicmodels
ficiently (Poursabzi-Sangdeh et al., 2016): topic
inaninteractivetask-basedsetting. Wecom-
binetopicmodelswithaclassifierandtesttheir modelsprovideaglobaloverviewofthedata,ex-
abilitytohelphumansconductcontentanaly- posing the broad themes of the corpus that help
sisanddocumentannotation. Fromsimulated, with creating a label set; active learning selects
realuserandexpertpilotstudies,theContex-
documentsthatdirecttheannotator’sattentionto
tualNeuralTopicModeldoesthebestonclus-
topically distinct examples to label, and train the
terevaluationmetricsandhumanevaluations;
classifiermoreefficiently.
however, LDA is competitive with two other
However,agapremainsintheliterature,given
NTMsunderoursimulatedexperimentanduser
studyresults,contrarytowhatcoherencescores recent advancements in topic modeling. Neural
suggest. Weshowthatcurrentautomatedmet- topic models (NTM), which use continuous text
ricsdonotprovideacompletepictureoftopic embeddingstocapturecontextualandsemanticre-
modelingcapabilities, buttherightchoiceof lationshipsinhigh-dimensionaldata,havegained
NTMs can be better than classical models on
prominence,outperformingclassicaltopicmodels
practicaltasks.
on automatic evaluation metrics, such as coher-
1 Introduction ence (Aletras and Stevenson, 2013). However,
automatedevaluationmetricshavebeencalledinto
Establishing a label set to organize a collection
question,anddonotnecessarilycorrelatewithhu-
of documents is a fundamental task in many
manratingsontopicmodeloutputs(Hoyleetal.,
fields such as social science, linguistics, educa-
2021b). There is a lack of work assessing neu-
tion,andbioinformatics(Liuetal.,2016;Pauland
ralmodelsontheirpracticalapplications,suchas
Girju,2009). Forexample,inthesocialsciences,
helpingpeopleconductcontentanalysis.
groundedtheoryemphasizesstructuralcodingas
Weaimtofillthisgap,andevaluatetheeffective-
a framework for discovering similarities and dif-
nessofneural,supervised,andclassicaltopicmod-
ferences in large-scale experimental data and as-
els to help social scientists with content analysis
signing meaning to it (Glaser and Strauss, 2017;
and label set creation. Specifically, we introduce
Lindstedt, 2019; Krommyda et al., 2021). Such
Topic Enabled Neural Organization and Recom-
a process is difficult and time-consuming, partly
mendationsystem(TENOR),aninteractivetoolthat
because it requires a global understanding of the
supportsvarioustopicmodelswithactivelearning
entire dataset, and local knowledge to accurately
for speeding up the process of content analysis.1
labelindividualdocuments.
We conduct synthetic experiment on LDA, super-
Topicmodeling(Boyd-Graberetal.,2017)has
viseLDAandthree NTMswithfollowupuserstudy
emerged as a popular tool to help with the cod-
ing process (Section 2.4). These models treat 1https://github.com/zli12321/TENOR.git
4202
naJ
92
]LC.sc[
1v84361.1042:viXraandexpertuserstudyandshowthatthechoiceof cationwithtopics. Supervisedmodels(Mcauliffe
ContextualizedTopicModel(Bianchietal.,2021) and Blei, 2007) change as labels are added and
(CTM) help users create higher quality label sets cancapture—forinstance—whenauserassociates
thanusingclassicalLDA,asmeasuredbybothclus- two labels with a topic. Thus we evaluate neural
termetrics(Section4.5)anduserratings. However, andclassicaltopicmodelsthattaskshumanswith
LDA is still competitive or better with two other creatingalabelsetandannotatingadocumentcol-
popular NTMs. Thus we show that thoughtfully lection,withtheassistanceoftopicmodelsanda
usingtopicmodelsaspartofalargersystemwith textclassifierontheBillsdataset.2 Wedelveinto
human interactions gives a more comprehensive specific topic models, active learning, evaluation
evaluation and understanding of their real-world metricsfortherestofthissection.
usage(Section 4.5).
2.1 TopicModels
2 Background Topic models identify latent themes within a cor-
pus, providing a snapshot of its overall narrative.
Manuallysortingthousandsofdocumentstoestab-
Given a set of documents and a specified topic
lishalabelsettocreateismentallychallengingand
count K, these models divide documents into K
time-consuming. Baumer et al. (2017) compare
clusters. Eachclusterrepresentsatopicdefinedby
grounded theory with topic modeling, and show
keyterms,denotingitscoretheme. Examplesfrom
that although the two methods are from distinct
various models are in Appendix 3. Users can ex-
fields,theyproducesimilarinsightsonlarge-scale
plorethecorpus’smainthemesandlabelindividual
data. Topicmodelsclusterdocumentsandextract
documentswiththetopicsandkeywords.
meaningfulthemesandcanhelppeoplefigureout
basiccategoriesoflabels. SupervisedLatentDirichletAllocation sLDA
Forthetaskofcontentanalysis,thecurrentma- retainsthegenerativeprocessinherenttoLDA,but
chine learning and NLP literature mainly focuses also introduces an additional step to generate la-
on the development NTMs (Hoyle et al., 2021b), belsforeachdocumentgivenitsdistributionover
because they are winning nearly every automatic topic assignments in a document. For example,
coherencemetric. However,mostofthecomputa- for movie comment reviews, LDA generates gen-
tionalsocialsciencecommunityremainsfocused eraltopicspeoplediscussfromthereviewsthatwe
on older probabilistic models (Abdelrazek et al., havenocontrolwithsLDA canalignuserstarrat-
2023) due to NTMs more complex architecture. ingswithtopicsinthegenerativeprocess,wherewe
Thus,weexplorethisopenquestion: shouldweuse caneasilyanalyzetopicsforeachstarratinglevel.
classicalorneuraltopicmodelsforlabelinduction Weusetheclassifier’spredictionsassurrogatere-
andcontentanalysis? sponsevariables,andupdatessLDAconstantlyas
One of the reasons that NTMs might be better users label more documents in our study. We ex-
is that ALTO showed the benefits of active learn- pect sLDA generates topics that are more related
ing (Settles, 2012): start with a dataset with an totheuserinputsbyinteractingwiththeclassifier
undefinedlabelset; usersaddlabelstothesetby trainedwithuserinputlabels.
going through individual documents (guided by
Neural Topic Models Current popular neural
topicoverviews);oncetheusersestablishatleast
topic models include Contexualized topic mod-
two distinct labels for the label set, a classifier
els (Bianchi et al., 2021, CTM), Bertopic (Groo-
trained on the labeled documents can help point
tendorst, 2022), and Embedded topic model (Di-
userstodocumentsthatareeitherdifficultforthe
eng et al., 2020, ETM). Theses neural models
current label set or that might require new labels.
takes advantage of pre-trained word embeddings
Oneofthecriticismsofneuraltopicmodelsisthat
with rich contextual information to enhance the
theyaretoogranularandspecific,butthismaybe
quality of discovered topics. CTM leverages pre-
a boon for label induction: it can find candidates
trained language models like SBERT (Reimers
foranewlabel.
andGurevych,2019)togeneratesentenceembed-
In addition to ignoring neural models (which
dingsconcatenatedwithBag-of-Word(BoW)rep-
had not reached maturity), another lacuna of
resentation of documents, and run a variational
(Poursabzi-Sangdehetal.,2016)isthatitignores
supervisedtopicmodelsthatcancombineclassifi- 2http://www.congressionalbills.orgautoencoder (VAE) on the representation, while thedocumentwiththehighestpreferencefunction
Bertopic uses UMAP (McInnes et al., 2020) and score(themostconfusingdocument)ischosen.
HDBSCAN(McInnesetal.,2017)createandrefine Given K topics from topic models, each doc-
topics from encoded word embeddings. ETM is ument is characterized by a specific topic distri-
retainsthesamegenerativeprocessasLDAbutthe bution, denoted by θd = {θd,θd,...,θd }. For a
1 2 K
topicsarelearnedfromwordembeddingsthatcon- particulardocument,itspredominanttopicis:
tainrichsemanticmeaningsinsteadofpureword
distributions. θd = mK axθd. (2)
max i
i=1
2.2 ActiveLearning
Wealsoadopthierarchicalsamplingforactive
Activelearning(Settles,2012)guidesusers’atten-
learning (Dasgupta and Hsu, 2008) to flat topic,
tiontoexamplesthatwouldbethemostbeneficial
withthepreferencefunction
tolabelforaclassifier,usingtechniquessuchasun-
certaintysampling. Bydirectinguserstoannotate
uncertaindocumentsfirst, activelearningisvalu- Ht d(X) = H d(X)∗θ md ax. (3)
ableinsituationsconstrainedbytimeorbudget.
With a clearly defined preference function, we
2.3 PreferenceFunctions chooseatopick∗ firstbasedonthefollowingcri-
During the initial stages of training, it is crucial terion: Given K topics, let D k denote the set of
foraclassifiertogeneralizetounseendataquickly. alldocumentsthataremostprominentlyassociated
Arapidimprovementfacilitateshigh-qualitydata withtopick. Theclassifierselectsatopick∗ such
analysis andoptimizes time andcosts, especially that its documents’ median preference score, Ht,
d
for largedatasets (Dasgupta andHsu, 2008). We ismaximized. Formally,thisis
usepreferencefunctionstoachievethisearlyrapid
gain of classifier generalization to the rest of the k∗ = argmax median{︁Ht(X) : d ∈ D }︁ .
d k
datasets so users can take advantage of TENOR k∈{1,2,...,K}
(4)
earlyintheirtoolusage.
Apreferencefunctionusesuncertaintysampling
2.4 EvaluationMetrics
to pick the most beneficial document and guide
users’ local attention to that document to label. Ourobjectiveisforuserstoestablishnewlabelsets
According to the preference function, the classi- foracommondataset. Incrowdsourcingscenarios,
fier favors documents with the highest confusion comparingtheaccuracyoflabelsgeneratedbydif-
scores. Forourbaselineclassifier,whenitdoesnot ferentuserswithoutapredefinedlabelsetbecomes
incorporatetopicmodels,thepreferencefunction impossible(Kleinberg,2002). Weusethreeclus-
foradocumentdis: teringmetricstoevaluatetheconcordancebetween
thelabelspredictedbytheclassifiertrainedonuser
n
H (X) = −∑︂ P(x )logP(x ). (1) inputlabelsandthegoldstandardlabelsforafair
d i i
comparison. Besides standard cluster evaluation
i=1
metrics, we also measure the coherence for each
Here, H d represents the cross-entropy (Mao topic of LDA, sLDA, NTMs. More details of the
et al., 2023) of the classifier. This approach en- metricsareinAppendixA.
suresthattheclassifierconsistentlyprioritizesthe
mostinformativedocumentstopresenttotheuser Purity Purityevaluateshowpureaninducedclus-
for labeling. The preference function also incor- ter is: in other words, what proportion of docu-
poratesvectorrepresentationoftopicmodelsand ments are placed in a cluster that is not commin-
users’ feedback to match their individual prefer- gledwithdocumentswithanothergoldlabel(Zhao,
ences(Zhangetal.,2019). 2005). Aswewillseewithmanyoftheclustering
When incorporating topic models and ac- metrics, there is a clear failure mode: the purity
tive learning, the preference function is topic- metric can be easily manipulated by assigning a
dependent, which involves a sequential decision- unique label to each document. We mitigate this
makingprocess: first,themostconfusingtopicby riskbynotdisclosingthesemetricstolabelersand
theclassifierisselected,andthen,withinthistopic, limitingthetimeusershavetocreatelabels.Adjusted Normalized Mutual Information 3 StudySetup
(ANMI) NormalizedMutualInformation(Strehl
3.1 Groups
and Ghosh, 2003, NMI) assesses clustering qual-
itybymeasuringtheinterdependencebetweentrue Forthesimulateduserstudy,weusethefollowing
and predicted labels. One can gain insights into models:
theotherbyunderstandingonesetoflabels. The
ANMI (Amelio and Pizzuti, 2016), an enhance- 1. ActiveLearningonly–(NONE);
mentofNMI,correctsforthechancealignmentof 2. ActiveLearning,LDA–(LDA)
clusters. 3. ActiveLearning,sLDA–(sLDA)
4. ActiveLearning,Bertopic–(Bertopic)
Adjusted Rand Index (ARI) The Rand Index 5. Active Learning, Embedded Topic Model–
(RI)(Rand, 1971, RI) measures the similarity be- (ETM)
tween two clusters by evaluating the agreement 6. ActiveLearning,ContextualizedTopicModel–
between them. Specifically, it counts all sample (CTM)
pairsandnotepairsthatareeithergroupedorsep-
aratedinbothclusters. TheAdjustedRandIndex Ourbaseline(1)givesusersaccesstoaclassifier
(ARI) (Sundqvist et al., 2022, ARI) refines this withactivelearning,butnotopicmodeltoverify
measure. WhileRIgaugesbasicagreement,ARI thebenefitofhavingatopicmodelinhelpingusers
accountsforandcorrectsanyrandomclusteragree- createlabels.
ment,providingamoreaccuratesimilarityassess-
ment. 3.2 Dataset
Our simulated experiment uses the 20news-
Coherence Normalizedpointwisemutualinfor-
groups(Mitchell,1999)andtheCongressionalbills
mation(NPMI)measureshowsemanticallysimilar
dataset. Bothdatasetshavehierarchicallabels;the
the top words of a topic are, which came up for
firstlevelisageneralcategory,suchasHealth,Ed-
classical topic models, but can also be used for
ucationfortheBills,andrec,scifor20newsgroups.
NTMs (Aletras and Stevenson, 2013).3 Theoreti-
Undereachofthefirstlayerlabels,therearemore
cally,ahigherNPMIindicatesthatthekeywordsof
specific labels; for example, under Health, there
a topic are more cohesive and easier to interpret.
areHealthInsurance,MentalHealthandCognitive
Weuse NPMI toevaluatethequalityofindividual Capacities,ChildrenandPrenatalCare,etc.
topicsgeneratedbytopicmodels.
Since we want to test our system theoretically
The clustering metrics evaluate the alignment,
and in a user study setting, having datasets with
quality,andinformationoverlapbetweentwoclus-
hierarchicallabelsenablesustousemorespecific
ters. A higher value in these metrics indicates
labelsasuserinputlabelsandmoregenerallabels
greatersimilarityandalignmentbetweentheclus-
as standard labels in simulated experiments. In
ters. However,usingjustoneofthemtomeasure
real-worldsettings,usersaremorelikelytomake
user label quality has limitations. If users assign
morespecificlabelsthataremorecloselyrelated
everydocumentadifferentlabel,theywillreacha
tothecontentsofindividualdocuments.
perfectpurityscore,butthatviolatesthetask. ARI
doesnotmeasurethequalityofindividualclusters. 3.3 SimulatedExperiment
Forexample,twoclustersmighthavehighARI,but
Beforeconductingareal-worlduserstudy,werun
both are very poor quality. ANMI is sensitive to
simulatedexperimentsonbothdatasets. Wechoose
thenumberofclusters,whereasignificantdiffer-
K = 35 topics for all five topic models.4 Since
enceinthenumberofclustersbetweenthestandard
usersaremorelikelytocreatemoredetailedlabels
clusterandclassifierpredictionscanleadtoarea-
for each document, we use sub-labels as pseudo-
sonable ANMI score, but the clusters have a high
userlabels,whileusingthemoregenerallabelsas
mismatch. By using all of them to complement
our gold standard. We use logistic regression as
eachother,wearemoreconfidentincomparingthe
ourclassifierandunigramtf-idfasinputfeatures
qualityofclassifierpredictions.
4WechooseK =35becauseitoptimizesaveragecoher-
3NPMIandANMIareoverdifferentevaluationmetricsover enceforalltopicmodels.Trainingdetailsandhyperparameter
differentprobabilityspaces. selectionsareinAppendixBNONE LDA sLDA CTM ETM Bertopic
Bills 20newsgroup
0.8
0.7
0.6
0.5
0.4
0.3
0.3 0.20
0.2 0.15
0.10
0.1 0.05
0.0 0.00
0.4
0.4 0.3
0.2
0.2
0.1
0.0 0.0
0 100 200 300 400 0 100 200 300 400
Number Documents Labeled
Figure1: Clusterscoresofsimulatedlabelingexperiments,medianof15runs. CTMwithactivelearningobtainsthe
highestscoreacrossallmetricsanddatasets. LDAandsLDAarebetterthanorcompetitivewiththeotherNTMs
(ETM,Bertopic).
fortheclassifier.5 Wealsoconcatenatetopicproba- LDA sLDA CTM ETM Bertopic
0.07 0.09 0.09 0.21 0.15
bilitydistributionsforallthedocumentswithtf-idf
features, which encodes topic information to the Table1: NTMsallshowahigherNPMIcoherencethan
classifier for groups with topic models. We use LDA,where ETM hasthehighestcoherence,followed
incremental leaning (Rosenblatt, 1958) to fit and byBertopicthenCTM. However,theNTMswithhigher
updatetheclassifierforeverydocumentlabeled.6 coherence are not better than CTM and LDA under a
task-basedexperimentinFigure1.
Theclusteringqualityisassessedbytheclassifier’s
predictionswiththemoregenerallabelsusingthe
three evaluation metrics. We run the experiment solely on automated evaluation metrics does not
for 400 documents since we expect it to be the capture how much the users find the topic model
maximumforaparticipanttolabelwithinanhour. helpfulinhelpingthemconductcontentanalysis.
Our user study investigates this question and sur-
Coherenceandsimulatedexperimentresultsdo
veysusers’ratingsonhowtheyfindtopicmodels
not have a direct relationship Figure 1shows
useful.
thatCTMdoesthebestonallclustermetricsonboth
datasets,while LDA andsLDA remaincompetitive 4 UserStudy
with other NTMs. Although Table 1 shows that
all NTMs have higher NPMI coherence than LDA, Weconductageneraluserstudyandexpertstudyto
with ETM has the highest coherence followed by comparetopicmodelsintherestofthepaper. For
BertopicandCTM,thesimulatedexperimentshow thegeneraluserstudy,weuse(1),(2),(3),and(6)
oppositeresultsthancoherenceranking,with ETM sinceCTMisthebest-performingneuralmodelin
doestheworstamongallthegroupsandCTMdoes thesimulatedexperiment. WeusetheBillsdataset
thebest,where LDAandsLDAareevenbetterthan toconducta60-userstudywithourinterface,with
BertopicandETMonthe20newsgroupdataset. 15peopleineachgroup. OurBillsdatasetcontains
Oursimplesimulatedexperimentsserveasare- selectedtopicsthatareeasyenoughforthegeneral
liable proxy for the user study. However, relying public,thusourgeneraluserstudydoesnotrequire
user expertise in the social science field, and we
5Usingsentencetransformerfeaturesproducessimilarre- care more about the overall user experience and
sultsbuttakesmuchlongertoupdate
cluster results while users are using the tool. We
6There are two exceptions we reinitialize the classifier:
we reinitialize the classifier and train it with labeled docu- thenrunfollowupexpertstudyonanexpertdataset,
mentsifanewlabelclassisintroducedtotheclassifier; if where the experts are familiar with the topics in
SLDAisupdatedwithsurrogateresponsevariables,werebuild
thedatasetwiththebesttwomodelsfromouruser
thefeaturesbyconcatenatingtf-idffeatureswithnewtopic
information. study results. The goal of the expert study is to
ytiruP
IRA
IMNAensure that our user study results can generalize NONE LDA sLDA CTM
toexperts,wherealltheparticipantshavesimilar
backgroundsinadataset. 0.6
0.4
4.1 UserStudyInterface
Forthegroupsusingtopicmodels,usersareshown 0.2
documentsgroupedbytheirtoptopic, withtopic
0.2
keywords. The document selected by the active
learningpreferencefunctionishighlightedanddis-
0.1
playedbothatthetopofitstopicandatthetopof
theinterface. Whenusersclickadocument, they
0.4
are presented with its full text, label options, top
0.3
5 topics, and top 10 keywords per topic. Words 0.2
above a 0.05 threshold in the primary topic are 0.1
highlighted. In NONE group, users see unsorted 20 40 60
Minutes Elapsed
documentswiththerecommendedoneatthetop.
Clickingadocumentshowsonlyitscontent,with- Figure2: Userstudylabelclustermetricsagainsttime.
Foreachgroup,wetakethemedianofeachmetricfor
outtopickeywordsorhighlights. Detailedinterface
everyminutepassed. Theuserstudyresultsaresimilar
informationisinAppendix E.
tothesimulatedexperiment;CTMdoesthebestonall
threeclusteringmetrics.
4.2 ParticipantRecruitment
WesourcedparticipantsviaProlific,restrictingour
selection to individuals from the US with an ap- classification. Theclassifierwithneuraltopicprob-
proval rate exceeding 95% and at least ten pre- ability features, trained on user input labels, can
vious submissions. Participants were randomly generalizeunseendatabetterthanclassicalgener-
assignedtooneoffourgroups,eachaccommodat- ativetopicprobabilityfeatures. Although CTM is
ing a maximum of 15 participants.7 Participants thebest,havingtheclassifierhaveaccesstotopic
firstreviewedthetaskinstructionsandunderwenta model features is better for the classifier to gen-
brieftutorialtofamiliarizethemselveswiththepro- eralize and predict unseen data than not having
cess. Theythenengagedinaone-houruserstudy accesstotheminouruserstudy. Welatermanually
session. Aftercompletingthesession,participants evaluatethevalidityoftheuserlabelsbyrandom
wereredirectedtoafollow-upsurveytoreceivea samplingwithdetailsinAppendixD.
20-dollarcompensation.
4.3 ClusterQualityEvaluationMetrics
sLDA performs worse on cluster metrics com-
pared to LDA and CTM This could be partly
We record the purity, ARI, and ANMI for every
attributedtoinaccuraciespresentintheclassifier’s
minutepassedduringeachsession. Foreachgroup,
predictions on the dataset. For instance, when a
weplotthemedianofeachmetricforeveryminute
userlabels30documentsmidwaythroughtheses-
passed(Figure2).
sion, the classifier, in turn, predicts labels for the
entiredataset. However,iftheclassifieronlyhasa
Topic model groups do better than NONE
fewtrainingexamples,andthequalityoflabelsis
Throughoutthe60-minutestudysession,theclas-
low,usingitspredictionsasresponsevariablesto
sifier has a wide gap between groups with topic
modelsand NONE. Topicmodelgroupshavefaster
trainsLDA togeneratedocumenttopicprobability
asfeaturescanconfusetheclassifier. Nonetheless,
earlygainsonallthreemetricsthanNONE.
sLDA can align certain topics with user intent la-
CTM doesthebestonclustermetrics,followed bels,whichmeansthatsLDA mightbecapableof
by CTM, sLDA, and NONE. In real-world user generating topic keywords that are semantically
applications, CTM stilldemonstratesadvantageon similartouserlabels,thusimprovingusers’overall
experience. Subsequentsurveyanalyseswillinves-
7Weusethesametrainedmodelsfromthesimulatedex-
tigatewhethersLDAsubstantiatesthishypothesis
periment.WeupdatesLDAinthebackendoncetheprevious
trainingiscomplete. inusersurveyratings.
ytiruP
IRA
IMNANPMI Confidence HighlRieglhi ance
st 0 0 I'- - ---,----'' I'- - ----,----''
C\J0 c:i ----,----0 0 ' I----,---- 0 ' Ia ----,----'' B 0 ' (0 11) - - D---,----'' QBg ' ( 11) st 0 - - - ----,----' EJD
0
0
0c:i
"!
si:I
I
----'---'
000
0''
C'J
C\Jst --
-
'
----'---' ------'------ C'J
0C\J
--
-
D
----'---''
0' ''
LDA sLDAs L DA(uCsTeMr) LDA NONE sLDA(u CsTeMr) LDA NONE sLDA(uCsTeMr)
Topic-KeCyowhoerrdesn ce Topic-KeyRweolridasn ce Satisfaction
(
C'J11)
st
0 -
-
--
g
D
----'---'' (
11)
stI'
0
-
-
-
--
B
□----,----'' B----,----'''
''
(
11)I'
st
0-
-
-
--
g ----,----0
''''
8----,---- ''' D----,---- I'
C'J - ------'------ D
C\J - C\J - C'J -
C\J - 0 0
0 - ' ' 0 - '
LDA NONE sLDA(u CsTeMr) LDA NONE sLDA(u CsTeMr) LDA NONE sLDA(u CsTeMr)
Figure3: ThefirstPlotshowsNPMICoherenceforalltopicsontheBillsdataset,wheresLDA(user)istrainedon
userinputlabels,andsLDAistheinitialmodelusedforallsLDAusers. Therestoftheplotsshowsusers’rating
ondifferentquestionsonascale1to7,whichthehigherisbetter. AlthoughsLDAisworsethanLDAandCTMon
clusteringevaluations,mostofthemedianofuserratingsdonotdifferfromCTM,andbetterthanLDAinsome
ratings. Forratings2to4,NONEgroupsusersallrate0becausetheydonothaveaccesstothosefeatures
Examiningcoherence,qualityofdocumentclus- on average Figure 4, the second to sixth plot
ters, and quality of topic keywords We go show a summary of users’ ratings for question
throughthetopicswithtop2,middle2,andbottom 1 to 5. The median of user ratings on CTM and
2coherencescoresforthemodelsweuseforuser sLDA aresimilarformostofthequestionsexcept
study(includingsLDAtrainedonuserlabels),and forTopic-KeywordCoherence,whichsLDAfalls
show the NPMI, topic keywords, and a randomly short. Basedonthemedianuserratings,usersgen-
selectedpassagefromthetopicinTable3and 5.8 erallyrelymoreontopickeywordsandhighlights
Although the coherence scores vary for different tocreatelabelsfordocumentsiftheyareassigned
topics,thetopkeywordsarerepresentativeofthe to CTM or sLDA group. Users also rate the topic
documents. Figure 4showsalowmediancoher- keywordstheyusetolabeldocumentsasmoreco-
encescoredoesnotnecessarilyshowlowermedian herentforCTMandsLDA. Althoughtheclassifierin
user ratings. CTM has the highest top coherence sLDAfallsshortonthethreeclustermetricsamong
scoresbutthemediancoherencescoreislowerthan thethreetopicmodels,usersgenerallyhavebetter
sLDAand LDA. However, CTMstilldoesthebetter overallexperiencewithsLDAthan LDAusers.
onclusteringevaluationsanduserratings.
Although LDA’stopicshavehighermedianco-
4.4 UserRatings herence scores, overall users’ median ratings
are lower First plot in figure 4 shows the co-
Oursurveycomprisesfivequestionsaimedatgaug-
herenceofall35topicsforLDA,sLDA,CTM,and
ing user judgment and evaluating topic models,
usingascalerangingfrom1to7.9
sLDAtrainedonuserlabels. Althoughthetoptop-
ics for CTM, sLDA and sLDA(user) have higher
CTM andsLDAusersrelymoreontopicmodel coherencescoresthan LDAdoes, LDA’scoherence
features with more confidence than LDA users scores are quite tight in the boxplot and LDA has
8We load the saved sLDA model trained on user labels highermediancoherencethantheothertwomod-
predictedbytheclassifierattheendofthesession,wecallit els. sLDA(user)hasdiversecoherencescoresforits
sLDA(user).
topics. However,whenlookingatthemedianuser
9Confidenceaskshowconfidenttheusersfeelabouttheir
createdlabels.HighlightRelianceaskshowmuchtheusers
ratingofallthefivequestions,LDAdoesnotshow
rely on the highlight functionality to make labels. Topic- anybetteradvantagethanCTM andsLDA. There-
KeywordsCoherenceaskswhetherusersfindthetopickey-
sultsupportstheclaimthatthereisnotastrongand
wordscoherentwhiletheyexploretopicsandperusekeywords
toassisttheminlabelcreation.Topic-keywordDependence directrelationshipbetweencoherenceandhuman
investigates the frequency at which users consult the most usabilityandrelianceontopicmodelswhentopic
relatedtopickeywordswhilecreatinglabelsfordocuments.
modelsareusedtodogeneraldatasetexploration
Satisfactionassessestheusers’overallsatisfactionwiththe
tool,exploringwhetherusersfindthetoollikableandhelpful. andlabelsetestablishment,whereusersfocuson
I
B
I I
I I
I
I
I
I I I
I
I
IMetric p-Value SignificantPair
TENOR ALTO
0.5 Confidence 0.327 None
0.4 HighlightReliance 0.035 sLDAvs. LDA
topicCoherence 0.017 CTMvs.sLDA
0.3 topicReliance 0.034 CTMvs. LDA
satisfaction 0.002 NONEvs.Other3
0.08
0.04 Table2: Thetableshowssignificancetestresultsacross
subjectiveratingsforthreegroupsata0.05significance
0.00
level. Formetrics2to4,weexcludeNONEtodotest-
0.20 ing. Thethirdcolumnshowsthegrouppairsthatare
0.15 statisticallysignificant. Forexample,thesignificantpair
0.10 forsatisfactionisbetweenNONEandotherthreegroups
0.05 withtopicmodels,anditindicatesadifferenceofuser
0 10 20 30 40 50
Number Documents Labeled
satisfactionratingbetweenNONEandotherthreegroups
undera95%confidencelevel, wherethe NONE users
Figure4: Werunafollowuppilotstudywith6social are less satisfied with their experience from the sixth
scienceexperts(3eachgroup)ontheirinternalsocial plotinFigure4.
sciencedataset(800documents),whichtheyarefamiliar
withthetopicsinthedataset. Uptothe50thdocuments
labeled, CTM still generalize well for expert datasets all hold at least a graduate degree in community
andexpertusers. resilience related field that focuses on assisting
communitiesandstakeholdersonissuesrelatedto
anticipatedhazardsconditions,disasterprepared-
individualdocumentstocreatelabels.
ness,andissuesrelatedtobuildingsandtheinter-
Differenttopicmodels,differentpurposes We dependenciesofphysicalinfrastructuresystems.10
run ANOVA (Fisher, 1935) and Posthoc-test We use the same user interface described in Sec-
Turkey-Kramerforpairwisecomparisonbetween tion4.1withthegivenexpertdataseton800doc-
ratings of any two of the user groups. Users are uments. The dataset is related to community re-
lesslikelytorelyonthetopickeywordsgenerated silience topics and also have hierarchical labels
by LDAtolabeldocuments,comparedto CTM and createdbymultipleexpertsusingCohen’sKappa
sLDA based on significance results in table 2 be- agreement (McHugh,2012) over a six-monthpe-
cause LDA generates too general topic keywords riod. Figure 4 shows that CTM is still better than
thatarelessusefultolabelindividualdocuments. LDA on two out of three clustering metrics, and
Forspecifictasks,suchaslabelsetestablishment similarARIatthe50thdocumentlabeledwhenthe
andtasksinvolvingunderstandingindividualdocu- usershavesimilarexpertiseonthedataset.
ments,CTMisabetterchoice.
Expertsrelylessontopickeywordstolabeldoc-
CTM is good at task-based applications We umentsbutstillfindsthetoolconvenientanduse-
see an improvement of clustering metrics using ful Since all the experts are quite familiar with
CTM,aswellasoverallhigheruserpreferencerat- thetopicsinthedataset,oneexpertusingLDAmen-
ings over the classical topic models in the label tionsthatthetopickeywordsarenothelpfulbutthe
set creation task. Although there has been a de- highlighted texts are more helpful for individual
bateon NTMsproducinglessinterpretabletopics, documentannotation. LDAproducestopicsthatare
under the correct choice of NTMs, we do not toogeneralthatexpertsalreadyfamiliarwithwhile
see a significant difference in user ratings be- themorespecifickeywordsfrom CTM areabetter
tweenNTMandtheclassicaltopicmodelsexcept choiceforexpertstoreadandforclassification.
forTopic-KeywordReliance,whereusersseemto
prefer NTMs’ topic keywords to make labels for 5 RelatedWork
documents.
Applicationsoftopicmodelsareimportant,asex-
4.5 ExpertVerification emplified by previous work by Fang et al (Fang
et al., 2023), which addresses the human-centric
WeconductfollowupexpertstudiesusingLDAand
applications of topic models. (Bakharia et al.,
CTM, which are the two winning conditions in
our general user study on 6 experts. The experts 10https://www.nist.gov/community-resilience
ytiruP
IRA
IMNA2016) shows that interactive topic models have offbetweenusingneural,supervised,orclassical
gained traction among social science researchers topicmodels. Whilesomerecentstudieshavecom-
and data analysts. Nevertheless, classical topic pared NTM and LDA with human analysis of the
models dominate most applications in social sci- topicoutputs,theystillpredominantlyrelyonau-
enceresearch(Boyd-Graberetal.,2017;Lin,2009). tomatic evaluation metrics (Papadia et al., 2023),
Despitetheirtheoreticaladvantages,thispersistent withlimitedemphasisonanalyzingthequalityof
preference for classical models underscores the models from a human perspective or task-based
need for comprehensive studies on the practical utility of topic models. These studies concluded
utilityofNTMs. that LDA outperforms NTM in metrics such as di-
Asoneofthemostpopulartopicmodels, LDA versity (Dieng et al., 2019), similarity (Webber
hasbeenwidelyappliedandtestedinvariousfields, et al., 2010), coherence(Röder et al., 2015), and
such as health area (Paul and Dredze, 2011), po- classification(Phanetal.,2008). However,these
liticalopinionanalysis(Chenetal.,2010),social conclusionsarefornon-Englishdatasets. Ourre-
mediadataanalysis(Zhaoetal.,2011),etc. Since searchintendstobridgethisgapbyconductingan
there is already tons of work using LDA on hu- English-language topic model quality evaluation,
manapplications,LDAhasshowntobeaneffective incorporating human interaction to help content
topicmodelforrealapplications. analysis.
Our approach differs from previous studies,
Most of the work has explored sLDA’s power
whichcomparesNTMsandclassicalmodels’stabil-
to predict response variables for texts and docu-
ityandalignmentwithstationary,pre-determined
ments (Xu and Eguchi, 2022). Few works have
groundtruthlabels(Hoyleetal.,2021a). Inthefor-
studiedusingsLDAtoaligntopicswithuserintent
mer, LDA wasbetter;inthelatter, LDA wasbetter
labelstoestablishlabelsetsfordocuments. Using
thanmany NTMs(Hoyleetal.,2021b). However,
sLDAinteractivelyfordocumentrecommendation
(Hoyle et al., 2021a)’s approaches only evaluate
and annotation is more intuitive and straightfor-
topicmodelsbyanalyzinghumanratingsontopic
wardthanusingunsupervisedclassicalLDA.
keywords or topic keywords with labels without
BesidessLDA,therecentpopularityofneuralnet-
anytaskapplications. Incontrast,ourmethodalso
worksleadstothepopularityofdoingtopicmodel-
incorporatesgeneralandexpertusers’preferences
ingwiththem. NTMshavegainedpopularityinma-
onusingtopickeywordstocomprehendandcate-
chinelearningresearchwithoverahundredinvari-
gorizeindividualdocuments.
ants (Zhao et al., 2021). So far, the evaluation of
NTMsismainlybasedontopiccoherence,topicdi-
6 Conclusion
versity,andclassificationapplications(Zhaoetal.,
2021). ThemajorframeworkofNTMsaremostly We provide an interactive task-based evaluation
sequentialNTMs,whichleveragesthearchitecture of neural, supervised, and classical topic models,
powerofRecurrentNeuralNetwork(RNN); NTMs usingthetaskofcontentanalysisandlabelsetcre-
with pre-trained language models, such as BERT, ation. UsingCTMwithanactivelearningclassifier
that already learns the semantic relationship and helps both expert and non-expert annotators pro-
associationofwordsfromalargecorpusoftexts. ducehigherqualitylabelsetsmorequickly,accord-
NTMshavetheadvantageofproducinghigherauto- ingtoclustermetricsandhumanratings,validating
maticevaluationscores,andclassificationabilities, that the right choice of NTMs can be better than
alongwithothermoreextensiveapplicationsthat LDA for content analysis. However, LDA is still
classical topic models cannot do, which includes competitivewithtwoother NTMs,contrarytowhat
texts generation (Tang et al., 2019; Wang et al., coherencescoreswouldsuggest. Weshowthatcur-
2019), summarization (Zhao et al., 2020; Wang rentautomatedmetricsdonotprovideacomplete
etal.,2020). pictureoftopicmodelingcapabilities,buttheright
However, withthenewpopularityof NTMs, to choice of NTMs can still be better than classical
thebestofourknowledge,therearestillfewworks modelsonpracticaltasks. Futureworkcaninclude
using NTMs for social science, medical areas, or exploring more effective ways to use topic mod-
political opinion analysis, due to their complex elsforcontentanalysis,whereexpertsuseTENOR
architectureandmorecomputingresourcedemand- to conduct the coding process and answer their
ing. Ourworkexaminesthisgaptostudythetrade- researchquestions.7 Limitations participatingourexpertverificationexperimentand
providingvaluablequalitativecommentsandfeed-
Weprovideahuman-in-the-loopframeworktoeval-
back. ZongxiaLi,AndrewMao,DanielStephens,
uate topic models, extending beyond automated
andPranavGoel’scontributionsaresupportedby
evaluation metrics. Yet, our experiment only fo-
the NIST Professional Research Experience Pro-
cusesonaverynarrowandspecifictasktoevaluate
gram.
topicmodels. Inaddition,althoughourworkshows
thattherightchoiceofNTMcanbeemorepower-
ful than LDA for specific tasks, the debate about References
evaluation of topic models is still present. From
AlyAbdelrazek,YomnaEid,EmanGawish,WalaaMed-
alanguageperspective,ourexperimentsarebased hat, andAhmedHassan.2023. Topicmodelingal-
onEnglishdatasetonly. Ourconclusionstheoreti- gorithms and applications: A survey. Information
Systems,112:102131.
callycanbegeneralizedtosomeotherlanguages
butneedtobepracticallytested. Itmightcometoa NikolaosAletrasandMarkStevenson.2013. Evaluat-
differentconclusionforlanguageswithcompletely ingtopiccoherenceusingdistributionalsemantics. In
Proceedingsofthe10thInternationalConferenceon
differentstructuresthanEnglish. Inaddition,given
ComputationalSemantics(IWCS2013)–LongPa-
our objective is to create label sets for document
pers,pages13–22,Potsdam,Germany.Association
collections,wetrainsLDA usingclassifierpredic- forComputationalLinguistics.
tionsofthedataset. However,thelimitedtraining
Alessia Amelio and Clara Pizzuti. 2016. Correction
examplescomparedtotheentiredatasetcanaffect
forcloseness: Adjustingnormalizedmutualinforma-
accuracy. Thisresultsinlowerclustermetricsfor tionmeasureforclusteringcomparison: Correction
sLDA compared to CTM and LDA. A more com- forcloseness: Adjustingnmi. ComputationalIntelli-
prehensivefutureanalysisofsLDA,usingaccurate gence,33.
responsevariableslikemoviestarratingsandhu-
Aneesha Bakharia, Peter Bruza, Jim Watters, Bhuva
maninteraction,couldsolidifythebenefitsofsLDA. Narayan, and Laurianne Sitbon. 2016. Interactive
Inaddition,oursimulatedexperimentcoversthree topicmodelingforaidingqualitativecontentanalysis.
InProceedingsofthe2016ACMonConferenceon
NTMs but our general user study only covers the
HumanInformationInteractionandRetrieval,CHIIR
best NTM–CTM. Although the simulated experi-
’16,page213–222,NewYork,NY,USA.Association
mentsshowsthatBertopicandETMcanbeworse forComputingMachinery.
atclassificationthanLDA,wehavenotinvestigated
EricP.S.Baumer,DavidMimno,ShionGuha,Emily
theuserratingsandpreferencesonother NTMsin
Quan,andGeriK.Gay.2017. Comparinggrounded
ourpaper. theoryandtopicmodeling: Extremedivergenceor
unlikelyconvergence? J.Assoc. Inf.Sci.Technol.,
8 Ethics 68(6):1397–1410.
FedericoBianchi,SilviaTerragni,andDirkHovy.2021.
WereceivedapprovalfromtheInstitutionalReview
Pre-trainingisahottopic: Contextualizeddocument
Board before initiating the user study. All partic- embeddingsimprovetopiccoherence. InProceed-
ipants are based in the United States. Users are ingsofthe59thAnnualMeetingoftheAssociationfor
ComputationalLinguisticsandthe11thInternational
requiredtoreviewaninstructionandconsentstate-
JointConferenceonNaturalLanguageProcessing
mentbeforeparticipationcommitment. Theyhave
(Volume 2: Short Papers), pages 759–766, Online.
the option to withdraw if they disagree with the AssociationforComputationalLinguistics.
terms. Throughout the study, no personal infor-
David M Blei, Andrew Y Ng, and Michael I Jordan.
mationthatcouldrevealidentitiesiscollected. To
2003. Latentdirichletallocation. Journalofmachine
the best of our knowledge, our study presents no Learningresearch,3(Jan):993–1022.
knownrisks.
JordanBoyd-Graber,YueningHu,andDavidMinmo.
2017. ApplicationsofTopicModels. NowFounda-
9 Acknowledgement
tionsandTrends.
We thank anonymous reviewers and Alexander BiChen,LeileiZhu,DanielKifer,andDongwonLee.
Hoylefortheirinsightfulcommentsforhelpingus 2010. Whatisanopinionabout? exploringpolitical
standpoints using opinion scoring model. In Pro-
makeourpaperexperimentsandargumentsmore
ceedingsoftheTwenty-FourthAAAIConferenceon
solid. We thank Emily Walpole and Juan Fung’s
Artificial Intelligence, AAAI’10, page 1007–1012.
communityresiliencegroupsfortakingtheirtime AAAIPress.RobChurchillandLisaSingh.2022. Theevolutionof LLiu,LTang,WDong,SYao,andWZhou.2016. An
topicmodeling. ACMComput.Surv.,54(10s). overviewoftopicmodelinganditscurrentapplica-
tionsinbioinformatics. SpringerPlus,5(1):1608.
SanjoyDasguptaandDanielHsu.2008. Hierarchical
samplingforactivelearning. InProceedingsofthe Anqi Mao, Mehryar Mohri, and Yutao Zhong. 2023.
25th International Conference on Machine Learn- Cross-entropy loss functions: Theoretical analysis
ing,ICML’08,page208–215,NewYork,NY,USA. andapplications.
AssociationforComputingMachinery.
JonMcauliffeandDavidBlei.2007. Supervisedtopic
AdjiB.Dieng,FranciscoJ.R.Ruiz,andDavidM.Blei. models. Advancesinneuralinformationprocessing
2020. Topicmodelinginembeddingspaces. Trans- systems,20.
actionsoftheAssociationforComputationalLinguis-
tics,8:439–453. MaryLMcHugh.2012. Interraterreliability: thekappa
statistic. BiochemiaMedica,22(3):276–282.
AdjiB.Dieng,FranciscoJRRuiz,andDavidM.Blei.
LelandMcInnes,JohnHealy,andS.Astels.2017. hdb-
2019. Thedynamicembeddedtopicmodel. ArXiv
scan: Hierarchicaldensitybasedclustering. J.Open
preprintarXiv:1907.05545.
SourceSoftw.,2:205.
Zheng Fang, Lama Alqazlan, Du Liu, Yulan He, and
LelandMcInnes,JohnHealy,andJamesMelville.2020.
Rob Procter. 2023. A user-centered, interactive,
Umap: Uniformmanifoldapproximationandprojec-
human-in-the-looptopicmodellingsystem.
tionfordimensionreduction.
Ronald A. Fisher. 1935. The Design of Experiments.
Tomas Mikolov, Kai Chen, Gregory S. Corrado, and
OliverandBoyd,Edinburgh.
Jeffrey Dean. 2013. Efficient estimation of word
representationsinvectorspace. InInternationalCon-
BarneyGlaserandAnselmStrauss.2017. Discoveryof
ferenceonLearningRepresentations.
groundedtheory: Strategiesforqualitativeresearch.
Routledge.
Tom Mitchell. 1999. Twenty Newsgroups.
UCI Machine Learning Repository. DOI:
Maarten Grootendorst. 2022. Bertopic: Neural topic
https://doi.org/10.24432/C5C323.
modelingwithaclass-basedtf-idfprocedure.
GabrielePapadia,MassimoPacella,MassimilianoPer-
AlexanderHoyle,PranavGoel,AndrewHian-Cheong,
rone,andVincenzoGiliberti.2023. Acomparisonof
Denis Peskov, Jordan Boyd-Graber, and Philip
differenttopicmodelingmethodsthrougharealcase
Resnik. 2021a. Is automated topic model evalua-
studyofitaliancustomercare. Algorithms,16(2).
tionbroken? theincoherenceofcoherence. InAd-
vances in Neural Information Processing Systems,
Michael Paul and Roxana Girju. 2009. Topic model-
volume34,pages2018–2033.
ingofresearchfields: Aninterdisciplinaryperspec-
tive. InProceedingsoftheInternationalConference
AlexanderHoyle,PranavGoel,DenisPeskov,Andrew
RANLP-2009, pages 337–342, Borovets, Bulgaria.
Hian-Cheong,JordanBoyd-Graber,andPsResnik.
AssociationforComputationalLinguistics.
2021b. Isautomatedtopicmodelevaluationbroken?:
Theincoherenceofcoherence. MichaelJ.PaulandMarkDredze.2011. Youarewhat
youtweet: Analyzingtwitterforpublichealth. Pro-
Jon Kleinberg. 2002. An impossibility theorem for ceedings of the International AAAI Conference on
clustering. InAdvancesinNeuralInformationPro- WebandSocialMedia.
cessingSystems,volume15.MITPress.
Xuan Hieu Phan, Minh Le Nguyen, and Susumu
MariaKrommyda,AnastasiosRigos,KostasBouklas, Horiguchi. 2008. Learning to classify short and
andAngelosAmditis.2021. Anexperimentalanal- sparsetext&webwithhiddentopicsfromlarge-scale
ysis of data annotation methodologies for emotion datacollections. InTheWebConference.
detectioninshorttextpostedonsocialmedia. Infor-
matics,8(1). ForoughPoursabzi-Sangdeh,JordanBoyd-Graber,Leah
Findlater, and Kevin Seppi. 2016. ALTO: Active
MinchulLee.2022. bab2min/tomotopy: 0.12.3. learningwithtopicoverviewsforspeedinglabelin-
ductionanddocumentlabeling. InProceedingsofthe
Jimmy Lin. 2009. Is searching full text more effec- 54thAnnualMeetingoftheAssociationforCompu-
tivethansearchingabstracts? BMCBioinformatics, tationalLinguistics(Volume1: LongPapers),pages
10:46. 1158–1169,Berlin,Germany.AssociationforCom-
putationalLinguistics.
NathanC.Lindstedt.2019. Structuraltopicmodeling
forsocialscientists: Abriefcasestudywithsocial WilliamMRand.1971. Objectivecriteriafortheevalu-
movementstudiesliterature,2005–2017. SocialCur- ationofclusteringmethods. JournaloftheAmerican
rents,6(4):307–318. Statisticalassociation,66(336):846–850.NilsReimersandIrynaGurevych.2019. Sentence-bert: W Xu and K Eguchi. 2022. A supervised topic em-
Sentenceembeddingsusingsiamesebert-networks. bedding model and its application. PLoS One,
InConferenceonEmpiricalMethodsinNaturalLan- 17(11):e0277104. PMID: 36331905; PMCID:
guageProcessing. PMC9635756.
Hongming Zhang, Hantian Ding, and Yangqiu Song.
MichaelRöder,AndreasBoth,andAlexanderHinneb-
2019. Sp-10k: Alarge-scaleevaluationsetforselec-
urg.2015. Exploringthespaceoftopiccoherence
tionalpreferenceacquisition.
measures. WSDM ’15, page 399–408, New York,
NY,USA.AssociationforComputingMachinery.
HeZhao,DinhPhung,VietHuynh,YuanJin,LanDu,
and Wray Buntine. 2021. Topic modelling meets
FrankRosenblatt.1958. Theperceptron: aprobabilistic
deep neural networks: A survey. In Proceedings
model for information storage and organization in
of the Thirtieth International Joint Conference on
thebrain. Psychologicalreview,65(6):386.
ArtificialIntelligence,IJCAI-21,pages4713–4720.
InternationalJointConferencesonArtificialIntelli-
BurrSettles.2012. Activelearning(synthesislectures
genceOrganization. SurveyTrack.
onartificialintelligenceandmachinelearning). In
Findings. He Zhao, Piyush Rai, Lan Du, Wray Buntine, Dinh
Phung, andMingyuanZhou.2020. Variationalau-
Alexander Strehl and Joydeep Ghosh. 2003. Cluster toencodersforsparseandoverdisperseddiscretedata.
ensembles—aknowledgereuseframeworkforcom- In Proceedings of the Twenty Third International
bining multiple partitions. J. Mach. Learn. Res., ConferenceonArtificialIntelligenceandStatistics,
3(null):583–617. volume 108 of Proceedings of Machine Learning
Research,pages1684–1694.PMLR.
MartinaSundqvist,JulienChiquet,andGuillemRigaill.
2022. Adjustingtheadjustedrandindex: Amultino- WayneXinZhao, JingJiang, JianshuWeng, JingHe,
mialstory. Comput.Stat.,38(1):327–347. Ee-PengLim,HongfeiYan,andXiaomingLi.2011.
Comparingtwitterandtraditionalmediausingtopic
HongyinTang,MiaoLi,andBeihongJin.2019. Atopic models. In European Conference on Information
augmentedtextgenerationmodel: Jointlearningof Retrieval.
semanticsandstructuralfeatures. InProceedingsof
YingZhao.2005. CriterionFunctionsforDocument
the2019ConferenceonEmpiricalMethodsinNatu-
Clustering. Ph.D.thesis,USA. AAI3180039.
ralLanguageProcessingandthe9thInternational
JointConferenceonNaturalLanguageProcessing
10 Appendix
(EMNLP-IJCNLP),pages5090–5099,HongKong,
China.AssociationforComputationalLinguistics. A ClusteringEvaluationMetricDetails
Wenlin Wang, Zhe Gan, Hongteng Xu, Ruiyi Zhang, We list and show the calculation details of auto-
GuoyinWang,DinghanShen,ChangyouChen,and
matedevaluationmetricsdiscussedinSection2.4
Lawrence Carin. 2019. Topic-guided variational
for easy of reproducing our work in this section.
auto-encoder for text generation. In Proceedings
ofthe2019ConferenceoftheNorthAmericanChap- Supposetheclassifieristrainedonexistingdocu-
teroftheAssociationforComputationalLinguistics: mentswithuserinputlabels(5%ofthedocuments),
HumanLanguageTechnologies,Volume1(Longand
and the classifier predicts labels for all the docu-
Short Papers), pages 166–177, Minneapolis, Min-
ments, and they are partitioned into clusters de-
nesota.AssociationforComputationalLinguistics.
notedasΩ = {ω ,ω ,...,ω }. Theofficialgold
1 2 K
Zhengjue Wang, Zhibin Duan, Hao Zhang, Chaojie clustersaredenotedasC = {c ,c ,...,c }.
1 2 J
Wang, Long Tian, Bo Chen, and Mingyuan Zhou.
2020. Friendlytopicassistantfortransformerbased Purity Itiscalculatedbyassigningeachcluster
abstractive summarization. In Proceedings of the to the class which is most frequent in the cluster,
2020ConferenceonEmpiricalMethodsinNatural
andcountingthecorrectlyassignedpointsinthat
LanguageProcessing(EMNLP),pages485–497,On-
cluster. Theformulatocalculatethepuritybetween
line.AssociationforComputationalLinguistics.
thepredictedandthegoldclustersis:
WilliamWebber,AlistairMoffat,andJustinZobel.2010.
1 ∑︂
Asimilaritymeasureforindefiniterankings. ACM Purity(Ω,C) = max|ω ∩c |. (5)
k j
Trans.Inf.Syst.,28(4). N j
k
A. T. Wilson and P. A. Chew. 2010. Term weighting N is the total number of points, ω is the kth
k
schemes for latent dirichlet allocation. In Human cluster, c isthejthclass. ω ∩c isthenumber
j k j
LanguageTechnologies: The2010AnnualConfer-
ofpointsinclusterω thatbelongstoclassc ,and
enceoftheNorthAmericanChapteroftheAssocia- k j
max ismaximumnumberofclassc intersection
tionforComputationalLinguistics,pages465–473. j j
AssociationforComputationalLinguistics. withclusterω (Zhao,2005).
kAdjustedNormalizedMutualInformation The Normalized Pointwise Mutual Information
AdjustedNormalizedMutualInformation(ANMI) NPMI evaluates how semantically related the top
isanimprovedversionoftheNormalizedMutual words in each topic are to the documents in that
Information(NMI)metricusedforcomparingthe topic,whichinturnreflectsthequalityofthegen-
similaritybetweentwoclusteringsthatadjustsfor eratedtopicsbyatopicmodel:
chancetomakethescoremorerobustandcompa-
rableacrossdifferentsituations: log P(x,y)
P(x)·P(y)
NPMI(x,y) = . (9)
2×(MI−E[MI]) −logP(x,y)
ANMI = . (6)
(H(C)+H(K))−2×E[MI]
P(x,y)representstheprobabilityofwordsxandy
The mutual information (MI) measures how co-occuringtogetherinasetofdocuments,where
muchinformationweknowaboutthegoldcluster- P(x)andP(u)areprobabilitiesofobservingwords
ingbyknowingaboutthepredictedclustering. The xandyindependentlyinthesetofdocuments.
expectedmutualinformation E[MI] iscalculation
B SimulatedExperimentDetails
of what the MI would be if the predicted clusters
were completely at random, but still considering
Training Topic Models We preprocess the
the size of the clusters. H(K) measures the ran-
datasetbytokenizingandfilteringstopwords;we
domnessordisorderwithinthegoldclusteringand
use a tf-idf threshold of three to remove rare and
H(C)measurestherandomnessordisorderwithin
too-commonwords.
thepredictedclustering–entropy. Ahigherentropy
For LDA and sLDA, we use the Tomotopy li-
meanshigherrandomnessfortheclusters(Amelio
brary (Lee, 2022), which uses Gibbs sampling
andPizzuti,2016).
to train classical topic models. To compare two
Adjusted Rand Index Rand Index (RI) com- datasetsfairly,wechoseK = 35topicsforallfive
putesthesimilaritybetweentwoclusteringbycon- topicmodelsinourgroup,whichoptimizedaver-
sideringpairsthatareassignedinthesameordif- agecoherence. ForLDAandsLDA,weusetheterm
ferent clusters in the predicted and true cluster- weight scheme ONE (Wilson and Chew, 2010).
ing(Rand,1971). TheformulaforRIis: sLDAtakesmoreextrahyperparametersthan LDA
does. ForsLDA,wealsousebinary-typeresponse
TP+TN
RI = . (7) variablestoindicateuserinputlabels. Otherwise,
TP+TN+FP+FN
LDA andsLDA usethedefaulthyperparameterval-
TPisthenumberofpairsthatareinthesameset
ues. sLDA initially does not take in any response
inboththepredictedandgoldclusters,and TN is
variables. WetrainLDAandsLDAwith2000itera-
tionsuntilasmallerchangeoflog-likelihoodand
thenumberofpairsthatareindifferentsetsinthe
NPMIcoherence.
predicted and gold clusters. Otherwise, the pairs
areeitherFPorFN.
For CTM, we use SBERT
paraphrase-distilroberta-base-v2 to
TheAdjustedRandIndex(ARI)isthecorrected-
fetch sentence embeddings for the dataset, then
for-chance version of the RI. It accounts for the
concatenate them with BoW representation. We
factthattheRIscorewillincreaseasthenumberof
used CombinedTM (Bianchi et al., 2021) with
clustersincreases,eveniftheclusteringisrandom:
a 768 contextual size, with K = 35 topics,
RI−ExpectedRI and trained it with 250 epochs. We also use
RI = . (8)
MaxRI−Expected RI paraphrase-distilroberta-base-v2 to fetch
sentenceebmeddingstotrainBertopic. For ETM,
ExpectedRIistheexpectedvalueoftheRIunder weuseWord2Vec(Mikolovetal.,2013)toencode
randomlabeling,respectingthemarginaldistribu- documentsandtrainitwith250epochs.
tionsofclustersizes. MaxRIisthehighestpossible
valuethattheRIcouldtake,giventheconstraintsof Classifier Initialization and Features Since
theclusteringproblem. AMaxRIof1.0indicates usersaremorelikelytocreatemoregranularlabel
twoclusteringsareidentical,butwhenadjustingit specifications for each document. We used sub-
for chance, Max RI can be less than 1 depending labels as pseudo user-entered labels while using
onthedistributionofclustersizes. themoregenerallabelsasourgoldstandard.WeusesklearnSGDasourclassifierforactive liable proxy, allowing us to expect similar trends
learningdocumentselection.11 Wetransformour whenactualhumanlabelingisinplayandtotrack
rawdatasetusingunigramtf-idfasinputfeatures theevolutionofclassifierpredictionsasmoredocu-
fortheclassifier. For LDA,sLDA,and CTMgroups, mentsarelabeledovertime. However,weacknowl-
wealsoconcatenatetopicprobabilitydistributions edge that relying solely on simulated evaluation
forallthedocumentswithunigramtf-idffeatures metricshaslimitations. Theclassifierdoesnotcon-
thatalsoencodetopicinformationtotheclassifier. siderusingtopickeywordsandtopicoverviewsto
Sincetheclassifierrequiresatleasttwoclassesto createlabels. Otherfactors,includingfatigueand
befitted,wepickrandomdocuments,andusesub- lossofattention,mightalsoaffectthequalityofla-
labels as surrogate user input labels, and activate belscreatedbyrealusers. Suchmetricsalsodonot
the preference function until the classifier has at capturethecompleteessenceofuserpreferences,
least two class labels. We use incremental lean- especially concerning the keywords produced by
ing(Rosenblatt,1958)tofitandupdatetheclassi- topicmodels,thehighlightedkeywords,orthespe-
fier,retainingoriginallylearnedparameters.12 The cific documents recommended by the preference
classifier’spredictionswiththemoregenerallabels function.
assesstheclusteringquality.
C DatasetDetails
SimulatedExperiment Uponanalyzingthedoc-
The Bills have over 400,000 bills spanning from
umentlengthsinourdataset,wededucedthatcon-
1947 to 2009, where each bill is meticulously la-
sideringindividualreadingspeedvariances,auser
beled with primary and secondary topics, as de-
can feasibly label between 90 to 400 documents
tailedinacomprehensivecodebook.13 Thelatest
within an hour. For our simulated user study, we
iterationofthisdatasethasseenitstopicslabeled
automaticallyrunouralgorithmforeachgroupto
by adept human coders, who were trained using
inputlabelsfor400documents,constantlyupdat-
theprecedingdatasetversion. Theinter-annotator
ingtheclassifierforeverydocumentlabeled,and
agreementwasobservedtobeanimpressive95%
sLDA forevery50documentslabeled. Eachgroup
for primary topics and 75% for secondary ones.
underwent15iterationsoftheexperiment. Forcon-
Suchextensiveandrefinedlabeling,carriedoutby
sistency, we aggregated the results by taking the
trainedannotatorsovernumerousyears,assuresthe
medianvalueforeachdocumentineachgroup.
dataset’slabelquality. The20newsgroupisapopu-
Validity of Simulated Experiments Of all the larbenchmarkdatasetthathas6majorlabelsand
methods, CTM consistently does better on purity, 20 sub-labels. We remove duplicate documents,
ARI,andANMI,whichunderscorestherightchoice documents that are shorter than 30 tokens, docu-
of NTMcangeneratetopicprobabilityfeaturesthat mentsthatcontainsensitivetopics,anddocuments
dobetteronclassification. Suchfeatures,rootedin thatthegeneralpublicisnotfamiliarwiththeBills
pre-trainedembeddings,areperceivedbycompact and20newsgroupdataset.
machinelearningmodelsasmoreintuitivethanthe
D UserLabelEvaluations
generativetopicprobabilitiesyieldedbyclassical
modelslikeLDAandsLDA. sLDAandETM,onthe Wedoasanitycheckonthe800randomlyselected
otherside,isworsethan LDA,whereLDAremains labeled documents, to ensure users are creating
competitiveagainsttwootherNTMs. Theclassifier meaningfullabels. Withineachgroup,wesortthe
without topic information falls short behind the usersbasedonthesummationofpurity,ARI,ANMI
classifierwithtopicinformationexceptforETM. at the end of the 61st minute in ascending order.
Oursimplesimulatedexperimentsserveasare- Wetakethemiddle8usersandrandomlypick200
labeleddocumentsfromeachgroup. Wehavetwo
11Weusehyperparameters: loss=’log_loss’,penalty=’l2’,
annotatorsmanuallyjudgetheuserlabelsbasedon
tolerance=10e-3,random_state=42,learning_rate=’optimal’,
eta0=0.1,validation_fraction=0.2,andalpha=0.000005. the following two criteria: 1. Can the user label
12There are two exceptions we reinitialize the classifier: beconsideredequivalentorasubfieldofthegold
ifanewlabelclassisintroducedtotheclassifier,wereini-
label (major label and sub label)? 2. Does the
tializetheclassifierandtrainitwithlabeleddocuments; if
sLDAisupdatedwithsurrogateresponsevariables,werebuild user label reflect the contents of the passage? If
thefeaturesbyconcatenatingtf-idffeatureswithnewtopic
probabilitydistributions,andrestarttheclassifierwithnew 13https://comparativeagendas.s3.amazonaws.com/
features. codebookfiles/Codebook_PAP_2019.pdf.the annotator rates ‘yes’ for criteria 1, criteria 2
willbeskipped. Otherwise,theannotatorwillneed
to read the actual passage to judge the quality of
the user labels. Among 800 labeled documents,
we have 787 documents that satisfy at least one
of the two criteria, which ensures most users are
makingmeaningfullabelsandcarefullyconducting
thestudy.
E UserInterface
Figure5andFigure6showabasiclayoutof CTM
used in our user study. The keywords and docu-
mentclusterswillnotbedisplayedtoNONEgroup
users. Instead,arandomlistofdocumentsaredis-
playedtotheminFigure5page. InFigure6page,
NONE usersare notdisplayed withthe TopTopic
Keywordsandthehighlightedtexts.
F TopicModelKeywords
Table 3, 4, and 5 show the 2 topics with high-
est,median,andlowestNPMIcoherencescoresfor
LDA,sLDA,CTM,andsLDAtrainedwithuserinput
labelsasresponsevariables. Thetopickeywords
generatedby LDA aremoregeneralandinclusive
while the topic keywords generated by CTM are
morespecificandrelatedtothetoppassages.Figure5: Fortopicmodelsessions,usershavedisplayedalltopics,keywords,anddocumentsbelongingtoeach
topic. Ifactivelearningpicksadocument,thetopicandthedocumentclustercontainingthatdocumentwillbe
displayedattheverytopofthispage. Thedocumentisalsodisplayedonthetopofthedocumentcluster. For
example,thedocumentmarkedredisanexampleofadocumentpickedbyactivelearning. Forthebaseline,NONE
group,topickeywords,anddocumentclustersarenotdisplayed. Alldocumentsaredisplayedinoneblock,andthe
recommendeddocumentisalwaysontopofthepageaboveotherdocuments.
Figure6: Forauser-selecteddocument, ausercaneithermakealabelforthedocumentorskipthedocument.
Thetop5mostrelevanttopicsandtopkeywordsfortheselecteddocumentaredisplayedontherightside. The
highlightfunctionhelpsusersquicklyfindwordsthatareabovethe0.05thresholdforachosentopic. Userscould
alsoselectalabelfromthedropdownbox,whichthelabelsarerankedbysoftmaxprobabilitiesoftheclassifier,and
thedropdownlabelsarewhattheusershavecreatedsofar. ForNONE,thehighlightsandtopicswillnotbeavailable
totheusers.Model NPMI Keywords Passage
LDA 0.39 exemption, income, dependent, in- Toprovidethatcertainsurvivorbenefits
crease, taxpayer, tax, spouse, per- receivedbyachildunderpublicretire-
sonal,additional,include mentsystemsshallnotbetakenintoac-
countindeterminingwhetherthechild
isadependentforincometaxpurposes.
LDA 0.24 tax,revenue,internal,code,income, To amend the Internal Revenue Code
section,taxis,pay,credit,individual of 1954 to include the sintering and
burning of clay, shale, and slate used
aslightweightaggregatesasatreatment
processconsideredasmining.
sLDA 0.35 rescind, control, authority, budget, Torescindcertainbudgetauthoritypro-
president, special, impoundment, posed to be rescinded (R92-66) in
propose,transmit,section a special message transmitted to the
CongressbythePresidentonMarch20,
1992.
sLDA 0.22 tax,revenue,income,internal,code, ToamendtheInternalRevenueCodeto
exemption,section,individual,taxis, provide that gain or loss from the sale
shall orexchangeofcertainrealestateshall
betreatedasacapitalgainorloss.
CTM 0.50 president, authority, propose, re- Abilltorescindcertainbudgetauthority
scind, congress, special, impound- contained in the message of the Presi-
ment, march, accordance, trasmit, dent of January 27, 1978 (H. Doc. 95-
message 285), transmitted pursuant to the Im-
poundmentControlActof1974.
CTM 0.38 exemption, include, taxpayer, per- Toincreasefrom$600to$750theper-
sonal, additional, increase, depen- sonal income tax exemptions of a tax-
dent,spouse,income,old payer (including the exemption for a
spouse,theexemptionforadependent,
andtheadditionalexemptionforoldage,
orblindness).
sLDA(user) 0.42 budget, rescind, control, president, ToamendpartCoftheBalancedBudget
authority, impoundment, congress, andEmergencyDeficitControlActof
transmit,message,section 1985toextendthediscretionaryspend-
ing limits and pay-as-you-go through
fiscalyear2009.
sLDA(user) 0.26 education,school,student,loan,pro- ToamendtheHigherEducationActof
gram,secondary,institution,elemen- 1965toexpandtheloanforgivenessand
tary,educational,teacher loancancellationprogramsforteachers,
toprovideloanforgivenessandloancan-
cellation programs for nurses, and for
otherpurposes.
Table3: TopicmodelsautomaticallydiscovertopicsandthemesintheBillsdataset. Thesetopicsgiveusersaglobal
senseofprobablestoriesandthemesinadataset. Weshowthetop2topicsforeachtopicmodelandtheirrelevant
keywordsandrelevantpassages. sLDAistheinitialmodelwithoutfittingwithresponsevariables,whichisused
forallusersinsLDAgroup. sLDA(user)usesapre-savedmodel,whichisderivedfromthemediancalculations
(medianofsummationofpurity,ARI,ANMIamong15users)across15usersinsLDA. sLDA(user)generatestop
topicswithhighertopcoherencescoresthanothermodels. Thekeywordsalsoappearmoreoftenandaremore
relatedtopassages.Model NPMI Keywords Passage
LDA 0.13 water,wildlife,conservation,fish,es- To create a joint commission of the
tablish, management, resource, na- United States and the State of Alaska
tional,development,coastal tomakeadministrativedeterminations
ofnavigabilityofinlandnontidalwaters
in the State of Alaska for State selec-
tions.
LDA 0.12 food,drug,use,cosmetic,respect,hu- AbilltoamendSections403and405of
man,child,information,intend,man- theFederalFood,Drug,andCosmetic
ufacturer Act to require that foods intended for
humanconsumptionbelabeledtoshow
the amount of sodium and potassium
theycontain.
sLDA 0.10 labor,section,employee,national,or- ToamendtheRailroadRetirementAct
ganization,fair,provision,relations, of 1937 and the Social Security Act
right,railway toeliminatethoseprovisionswhichre-
strict the right of a spouse or survivor
toreceivebenefitssimultaneouslyunder
bothacts.
sLDA 0.07 highway, title, section, amend, na- A bill to supplement the Federal Aid
tional,code,fund,system,construc- Road Act, approved July 11, 1916, as
tion,stat amended and supplemented, to autho-
rizeappropriationsfortheconstruction
ofgreatlyneededrurallocalroads,and
forotherpurposes.
CTM 0.07 contract,standards,work,wage,con- Abilltoprovideforthecreditabilityof
tractor, cause, hour, fair, employer, certainserviceindeterminingtheorder
employee ofretentionforcompetingemployeesin
areductioninforceaffectingtheFederal
GrainInspectionService.
abrctm 0.06 revenue, internal, code, section, es- Toamendsection112(b)oftheInternal
tate, sale, admission, value, treat- RevenueCode(relatingtorecognition
ment,relate ofgainincertaincorporateliquidations)
sothatitwillapplytocaseswherethe
transferofallthepropertyundertheliq-
uidationoccurswithin1calendarmonth
in1953.
sLDA(user) 0.03 program, establish, improve, devel- A bill to improve existing tertiary eye
opment,system,promote,assist,pro- centers,toexaminethedeliveryofeye
vide,national,encourage caretothegeneralpublic,andtostudy
thefeasibilityofimplementingasystem
of tertiary eye care centers throughout
theUnitedStates.
sLDA(user) 0.02 state,fund,program,year,title,estab- To amend the National Housing Act
lish,assistance,construction,facility, to authorize the Secretary of Hous-
authorize ing and Urban Development to insure
mortgagesfortheacquisition,construc-
tion...
Table4: Thetableshowsthe18thand19thcoherenttopicsdiscoveredbydifferenttopicmodels. Thebottom2
topicsforsLDA(user)onlyhaveafewpassagesassociatedwitheachofthem.Model NPMI Keywords Passage
LDA -0.10 person, foreign, prohibit, business, To provide an exception from certain
engage,country,trade,domestic,en- grouphealthplanrequirementstoallow
able,stock smallbusinessestousepre-taxdollars
to assist employees in the purchase of
policies in the individual health insur-
ancemarket,andforotherpurposes.
LDA -0.08 vessel, coast, guard, marine, specie, ToamendtheMerchantMarineActof
merchant,port,law,academy,endan- 1936 and the Maritime Academy Act
gered of 1958 to enlarge the mission of the
U.S.MerchantMarineAcademyandto
assist in enlarging the mission of the
Statemaritimeacademies.
sLDA -0.12 meat,product,inspection,state,con- A bill to modify the method of deter-
tinental,shelf,outer,poultry,import, mining quantitative limitations on the
land importation of certain articles of meat
and meat products, to apply quantita-
tive limitations on the importation of
certainadditionalarticlesofmeat,meat
products, and livestock, and for other
purposes.
sLDA -0.11 fla, know, value, historic, shall, na- A bill to provide that the reservior
tional,site,use,fort,dam formed by the lock and dam referred
to as the Millers Ferry lock and dam
on the Alabama River, Alabama, shall
hereafterbeknownastheWilliamBill
DannellyReservior.
CTM -0.29 locate, convey, transfer, territory, To provide for the conveyance of cer-
memorial, historical, washington, tainexcessrealpropertyoftheUnited
smithsonian,city,conveyance StatestothecityofMission,thecityof
McAllen, andthecityofEdinburg, all
situatedintheStateofTexas.
CTM -0.12 highway,aid,interstate,road,alaska, Toamendsection5oftheDepartment
system,fund,fla,commission,trans- of Transportation Act to authorize the
portation NationalTransportationSafetyBoardto
employ5,000investigatorstocarryout
itspowersanddutiesunderthatact.
sLDA(user) -0.36 gas,purpose,greenhouse,wheat,red, To provide that the rules of the Envi-
cheese,cheddar,operate,exist,stan- ronmental Protection Agency entitled
dards National Emission Standards for Haz-
ardousAirPollutantsforReciprocating
InternalCombustionEngines...
sLDA(user) -0.31 gram, trans, drugs, deadline, inter- TodirecttheCommissionerofFoodand
vention, temple, manatees, plains, DrugstorevisetheFederalregulations
ombudsman,leaseholder applicabletothedeclarationofthetrans
fat content of a food on the label and
in the labeling of the food when such
contentislessthan0.5gram.
Table5: Thetableshowstheleasttwocoherenttopicsdiscoveredbydifferenttopicmodels. Thebottom2topicsfor
sLDA(user)onlyhaveafewpassagesassociatedwitheachofthem.