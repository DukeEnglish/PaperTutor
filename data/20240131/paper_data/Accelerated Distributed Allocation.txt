Accelerated Distributed Allocation
Mohammadreza Doostmohammadian∗, Alireza Aghasi†
Abstract—Distributed allocation finds applications in many asynchronous ADMM [32], primal-dual ADMM-like [30],
scenariosincludingCPUscheduling,distributedenergyresource primal-dual laplacian gradient flow [31], proportional-integral
management, and networked coverage control. In this paper,
control-based [33], and nonnegative surplus-based algorithm
we propose a fast convergent optimization algorithm with a
[34]. In the context of distributed machine-learning, some
tunable rate using the signum function. The convergence rate
of the proposed algorithm can be managed by changing two signum-based solutions [35]–[37] and distributed heavy-ball
parameters. We prove convergence over uniformly-connected methods are proposed to improve the convergence rate [38].
multi-agent networks. Therefore, the solution converges even The all-time feasibility of primal-based solutions implies that
if the network loses connectivity at some finite time intervals.
at any termination time of the algorithm, the solution meets
The proposed algorithm is all-time feasible, implying that at
theresource-demandconstraintfeasibility,whileindual-based
any termination time of the algorithm, the resource-demand
feasibility holds. This is in contrast to asymptotic feasibility solutions,ittakessometimetomeetthisconstraintfeasibility.
in many dual formulation solutions (e.g., ADMM) that meet Therefore, the dual-based solutions must be fast enough to
resource-demand feasibility over time and asymptotically. satisfy the resource-demand constraint in time, otherwise,
IndexTerms—Distributedallocation,scheduling,graphtheory, it may cause service disruption and breakdown. This is
optimization especially of interest in distributed generator coordination and
energy resource management [4]. Further, ADMM algorithms
suffer from all-time-connectivity requirements, i.e., they need
I. INTRODUCTION
to not lose connectivity at any time to avoid divergence and
ALLOCATION and scheduling find applications in CPU non-optimal solutions.
scheduling [1]–[3], energy resource allocation [4]–[7], This work proposes a nonlinear Laplacian gradient solution
linearlyconstrainedminimumvariance(LCMV)beamforming for distributed allocation and scheduling via primal formula-
[8], coverage control [9]–[11], vehicle traffic networks [12]– tion. The proposed solution is all-time feasible, which means
[15].Thispaperfocusesonfasterconvergencetowardsoptimal that at any iteration the resource-demand constraint holds.
resource allocation. Accelerated convergence is essential for This avoids feasibility violation and service disruption. We
rapidly adapting to changing conditions and ensuring timely prove convergence over uniformly-connected networks. This
responses to resource allocation requests. Traditional central- is important as in real mobile multi-agent systems the agents
izedmethodsoftenproveinadequateinaddressingtheintrica- may come into or leave the communication range of one
cies, efficiency, and scale of contemporary distributed large- another, which may cause dynamic networks with uniform-
scale systems. Therefore, the ongoing research has shifted connectivity instead of all-time connectivity. The other reason
towards decentralized algorithms seamlessly adapting to the is the possibility of packet drops and temporary link failure
ever-changing landscape of these systems [16]–[18]. Fast over the network. The main feature of our algorithm is its
convergence is particularly critical where real-time or near- accelerated convergence, which is tunable by changing the
real-time performance is required, such as cloud computing, associated parameters. The proposed nonlinear continuous-
edge computing, Internet of Things (IoT) [19], and in the time dynamics improves the convergence rate of the existing
context of distributed computing environments [3]. Recently, primal-based solutions (over uniformly-connected networks)
fast distributed averaging algorithms are considered in the by two parameters associated with signum-based functions.
literature that further motivates this work [20], [21]. As compared to most existing literature, this work (i) relaxes
The existing literature on distributed allocation and the all-time connectivity requirement in most literature [4],
scheduling are classified into two main domains: linear [22]–[34] to uniform-connectivity, (ii) leads to an all-time
primal-based [4], [22]–[24] and dual-based solutions feasible solution in contrast to asymptotic feasibility in dual-
[25]–[34], e.g., alternating-direction-method-of-multipliers based solutions [25]–[34], and (iii) improves the convergence
(ADMM).Theprimal-basedsolutions[22]–[24]areingeneral rateoftheexistingall-timefeasibleprimal-basedsolutions[4],
slower than ADMM-based setups; however, the primal-based [22]–[24]. More importantly, the points (i)-(iii) are addressed
solutions are all-time feasible [22]–[24], i.e., the solution altogetherand,toourbestknowledge,noexistingworkinthe
holds resource-demand feasibility at all times. The work [23] literature addresses these.
improves the convergence rate by adding momentum term
as compared to [22], [24]. Dual-based solutions include:
II. PROBLEMFORMULATIONANDPRELIMINARIES
Lagrangian-based [25], dual consensus ADMM [27]–[29],
Notation: 1 denotes all ones vector of size n. ∇F(x)
n
∗ Faculty of Mechanical Engineering, Semnan University, Semnan, denotes the gradient of function F(·) with respect to state
Iran doost@semnan.ac.ir. † Department of Electrical Engineer-
parameter x. ∂F(x) denotes the generalized derivative of the
ing and Computer Science, Oregon State University, Oregon, USA
alireza.aghasi@oregonstate.edu. nonsmooth function F(x). L HF : Rn ⇒ R denotes the
4202
naJ
82
]PS.ssee[
1v89551.1042:viXra2
set-valued Lie-derivative of function F with respect to the Proof: The proof follows the so-called Karush-Kuhn-
dynamics x˙ ∈∂H(x). See detailed definitions in [39]. Tucker (KKT) conditions, i.e., the optimizer is a factor of 1
n
Problem: Consider a network of n agents to be allocated as the gradient of the linear constraint 1⊤x−b=0 [41].
n
withashareofoverallresourcesx equaltob.Theseresources
i
areassociatedwithacostf i(x i).Thesumofoverallresources III. THEPROPOSEDACCELERATEDALGORITHM
is constant equal to b and the allocation needs to optimize
Forthedistributedsetupweconsideranundirectednetwork
the overall cost. This problem is modelled as the following
G ofnagentscommunicatingoptimizationdataoverweighted
constrained optimization problem [24]:
links. The adjacency matrix of this network is denoted by
(cid:88)n W and is symmetric. We assume the network is uniformly
P : min F (x)= f (x ), s.t. 1⊤x−b=0, (1)
1 0 i i n connected, i.e., its union over finite time intervals is strongly
x
i=1 connected while it is not necessarily connected at every
where x i is the state of the agent i representing the amount time instant. Then, our proposed accelerated continuous-time
of resources allocated to the agent i and x := [x 1;...;x n]. dynamics is as follows:
The global state vector x denotes the column vector of all
a cl ol no sc ta rt ae id ntst 1a ⊤ nte xs a −nd bn =is 0th (oe rn 1u ⊤ nm xbe =r o bf )a ig men pt ls ie. sTh the atfe ta hs eib sil ui mty x˙ i =−η (cid:88) W ij(cid:16) sgnα(cid:16) ddf xi
i
− ddf xj j(cid:17) +sgnβ(cid:16) ddf xi
i
− ddf xj j(cid:17)(cid:17)
of resources to be allocated is fixed and constrained with the
j∈Ni
(4)
value b. The functions f (x ) represent the cost of allocating
i i
with 0<α<1 and β >1 as rate tuning parameters, W =
resourcestobeminimized.Thesefunctionsarestrictlyconvex. ij
W ≥ 0 as symmetric link weight factors, η as the positive
The agenr/node states might be locally constrained with some ji
step-rate, N as the set of neighbors of i over the multi-agent
box constraints m ≤ x ≤ M , implying that the amount i
i i i
network G, and signum (or sign) function defined as [35]
of allocated resource to node i is upper-bounded by M and
i
lower-bounded by m i. These local constraints can be added sgnα(u)=u|u|α−1 (5)
as penalizing convex terms to the cost function referred to
as penalty functions or barrier functions [40], [41]. Then, and sgnβ(·) similarly follows. Based on the definition of
considering the penalty term as F(cid:101)(x) the objective function sgnα(·) and sgnβ(·) one can rewrite the dynamics (4) as,
c ph ea nn ag lte ys fi un nt co tit oh ne σif [so xr [ im 4 −2]F M,( [4x i]3) +]: += σF [0 m(x i) −+ xF i(cid:101) ]+(x ,). One examp (2le
)
x˙
i
= 

η− (cid:80)η(cid:80) j∈j N∈ iN WiW ij(cid:16)ij s(cid:16) gs ng αn (α u( )u +)+ sgs ng βn (β u( )u (cid:17)) ,(cid:17) , i if
f
u u≥ <0 0,
.
with [u]+ =max{u,0}c, c∈Z+ [41]. Note that this function with u= dfi − dfj. The proposed gradient tracking equation
dxi dxj
is smooth for c ≥ 2, and for the non-smooth case of c = 1 in discrete time is in the following form:
one can use the following smooth approximation [42], [43]:
L(u,ρ)= σ
ρ
log(1+exp(ρu)), (3) x i(k+1)=x i(k)−η (cid:88) W ij(cid:16) sgnα(df i( dx xi i(k)) − df j( dx xj j(k)) )
j∈Ni
whereσ weightstheboxconstraintpenaltytermsascompared +sgnβ(df i(x i(k))
−
df j(x j(k)) )(cid:17)
to the main objective function f i(x i). In other words, by dx i dx j
(6)
setting σ > 1 the solution is more toward satisfying the
box constraint, while σ < 1 puts less weight to satisfy with k as the discrete-time index. For gradient descent in
the box constraint and thus more toward optimizing the discrete-time, it is known that the step size η should satisfy
cost/objective function. It is proved that by choosing ρ large 0 < η < 1/L with L as the Lipschitz constant of F(·).
enough L(u,ρ) gets arbitrarily close to max{u,0} and the Note that, following Lemma 1, to reach the optimizer x∗ the
maximum gap between the two functions inversely scales gradient dfi atallagentsineedtoreachconsensus.Therefore,
dxi
with ρ [42], [43]. Similarly, other smooth and convex barrier the proposed dynamics drive the states at all agents such that
functions can be found in [40], [41]. Note that the sum of the difference of their gradients converges to zero, and at the
strictly convex local cost functions and convex penalty terms optimal point we have ∇F(x∗)∈span(1 ).
n
is strictly convex. Further, the penalty functions are generally
Remark 1. Signum functions sgnα(·) and sgnβ(·) accelerate
non-quadraticwhichimpliesthat addingthemtotheobjective
the convergence rate of the dynamics (4) and (6) toward
function makes the optimization problem non-quadratic. This
the optimal point. The parameters α and β tune the rate
makes the problem different from and more challenging than
of convergence. By decreasing parameter α and increasing
the existing consensus-based quadratic problems, e.g., [6]. It
parameter β both dynamics converge faster. However, this
should be mentioned that using barrier or penalty terms is an
may cause higher residual and chattering as discussed later.
approximate solution to address the local box constraints.
So, there is a trade-off between the convergence rate and
Lemma 1. [22] The strictly convex constrained optimization steady-state residual. In fact, the term sgnβ(·) improves the
problem (1) has a unique optimal solution x∗ for which convergence rate in the regions far from the optimizer x∗
the objective gradient satisfies ∇F(x∗) ∈ span(1 ), where and, on the other hand, sgnα(·) improves the convergence
n
∇F(x∗):=(df1(x∗),..., dfn(x∗))⊤. rate in the close vicinity of the optimizer x∗. This is because
dx1 1 dxn n3
we have sgnα(dfi − dfj) > dfi − dfj for |dfi − dfj| < 1 Lemma 4. Let W be a symmetric adjacency matrix of G.
and this implied sx ti hat d inxj thesed rx ei giond sxj (closerdx toi thedx oj ptimal Then, for ϕ∈Rn the following holds,
equilibrium) the convergence is faster. Similarly, we have n n
sgnβ(dfi − dfj) > dfi − dfj for |dfi − dfj| > 1 and (cid:88) ϕ (cid:88) W sgnα(ϕ −ϕ )=
dxi dxj dxi dxj dxi dxj i ij i j
this makes the convergence faster in regions far from the i=1 j=1
equilibrium in Lemma 1. Therefore, the convergence rate is n
1 (cid:88)
faster than the linear case; however, it is not uniform in −
2
W ij|ϕ i−ϕ j|α+1. (8)
all regions due to the nonlinearity (this is also shown by i,j=1
simulation). In the linear case [4] with α = 1 and β = 1, Similar equation holds for sgnβ(·).
the convergence rate is O(1).
k Proof:WehaveW =W ,andsgnα(·),sgnβ(·)assign-
ij ji
Intherestofthepaper,weprovefeasibilityandconvergence
preserving odd functions. Therefore,
for continuous-time dynamics (4) and equivalent results hold
for the discrete-time dynamics (6). The following lemma ϕ iW ijsgnα(ϕ j −ϕ i)+ϕ jW jisgnα(ϕ i−ϕ j)
proves the all-time feasibility of the proposed solution. =W (ϕ −ϕ )sgnα(ϕ −ϕ )
ij i j j i
Lemma 2. Initializing with a feasible state satisfying the =−W ij|ϕ i−ϕ j|α+1. (9)
constraint 1⊤ nx(0)−b=0, the dynamics (6) remains all-time The proof similarly follows for sgnβ(·).
feasible for t>0.
Theorem 1. For feasible initialization over uniformly-
Proof: For any t > 0 under dynamics (6) the feasibility
connectednetworkG,dynamics(4)convergestotheoptimizer
constraint satisfies the following,
of allocation/scheduling problem (1).
n n
1⊤x˙ =(cid:88) x˙ =−η(cid:88) (cid:88) W (cid:16) sgnα(df i − df j ) Proof: The proof is based on nonsmooth Lyapunov
n i ij dx i dx j analysis in [39]. Denote by F∗ = F(x∗) the optimal value
i=1 i=1j∈Ni
of the cost function in (1). Define the Lyapunov function
df df (cid:17)
+sgnβ( i − j ) . (7) as the residual F(x(t)) = F(x(t)) − F∗ at every time t
dx dx
i j
alongthesolutionofdynamics(4).ForthispositiveLyapunov
Note that the signum function is odd and sign-preserving. function,theuniqueequilibriumisF(x∗)=0.Following[39,
Therefore, sgnα(−u) = −sgnα(u) and sgnβ(−u) = Proposition10],thederivativeofthisLyapunovfunctionF(x)
−sgnβ(u) with u = dfi − dfj. Also, the link weights are satisfies ∂F(x(t)) ∈ L F(x(t)) ∈ R [39, Proposition 10]
dxi dxj H
symmetricandwehaveW ij =W ji.Therefore,W ijsgnα(u)+ where H refers to the solution dynamics (4). Then, the
W jisgnα(−u) = 0 and the summation in the right-hand-side generalized gradient of the residual is as follows:
ofEq.(7)iszero.Then,wehave1⊤x˙ =0.Sincethesolution
is initially feasible, this proves
all-n
time feasibility. ∂F(x)=∇F(x)x˙
=(cid:88)n df
ix˙
dx i
i
Lemma 3. If the multi-agent network G(t) is uniformly i=1
n
connected, the optimal solution x∗ given by Lemma 1 is the =(cid:88) df i(cid:16) −η (cid:88) W (cid:16) sgnα(df i − df j )
unique equilibrium of (6). dx ij dx dx
i i j
i=1 j∈Ni
Proof: We prove this by contradiction. Assume another +sgnβ(df i − df j )(cid:17)(cid:17) .
equilibriumxfordynamics(6)forwhich∇F(x)∈/ span(1 ). dx dx
(cid:98) (cid:98) n i j
Thisimpliesthatforthispoint dfi ̸= dfj foratleastonepair
dxi dxj Then, using Lemma 4,
o agf ea ng te sn ats =i, aj r. gA ms as xu λm ∈e {1∇ ,...F ,n( }x
(cid:98)
ϕ(cid:98)) λ= an( dϕ(cid:98)1 b,. =.. a, rϕ(cid:98)
gn
m) i⊤
n
λa ∈n {d 1,.fi ..n ,nd }ϕ(cid:98)th λe
. ∂F(x)=−
η
2(cid:16)(cid:88)n
W ij|
ddf
xi −
ddf
xj |α+1
From the contradiction we have ϕ(cid:98)a > ϕ(cid:98)b. Uniform con- i,j=1 i j
n fie nc itt eivi tt iy meo -f int th ere van let Two fr ok
r
G w( ht) ichim tp hl eie res t eh xa it ststhe are pae tx his ots vea
r
+
(cid:88)n
W ij|
ddf
xi −
ddf
xj
|β+1(cid:17)
. (10)
∪t+TG(t) from a to b. This path includes (at least) two i,j=1 i j
t
agents a′,b′ such that ϕ(cid:98)a′ > ϕ(cid:98)b′. Then, in a subdomain Theaboveimpliesthat∂F(x)≤0andtheLyapunovfunction
of [t,t + T], there exists at least a neighbouring agent l isnon-increasingunderdynamics(4).Theinvariantaccumula-
for which ϕ(cid:98)a′ > ϕ(cid:98)l and from the dynamics (6) we have tionsetundertheproposeddynamicsincludesthestatevalues
(cid:80)
l∈N a′
sgnα(ϕ(cid:98)a′ − ϕ(cid:98)l) + sgnβ(ϕ(cid:98)a′ − ϕ(cid:98)l) > 0; similarly, ∂F(x) = 0, i.e., {x∗|∇F(x∗) ∈ span{1 n}}. This follows
there is a neighbouring agent l for which ϕ(cid:98)b′ < ϕ(cid:98)l and from Lemma 1. Following the all-time feasibility of the solu-
(cid:80)
˙
l∈N b′
sgnα(ϕ(cid:98)b′ ˙− ϕ(cid:98)l) + sgnβ(ϕ(cid:98)b′ − ϕ(cid:98)l) < 0. Therefore, t Tio hn isfr io mm plL iee sm tm haa t2 thth ee ue nq iu qi ul eibr oi pu tm ima il zs eo rs sa ati ts isfi fe ys in1 g⊤ nx 1⊤∗− xb ∗= =0 b.
x (cid:98)a′ < 0 and x (cid:98)b′ > 0. This contradicts the equilibrium n
and ∇F(x∗) ∈ span{1 } is the equilibrium of dynamics (4)
assumption for x and proves the lemma. n
(cid:98)
(∂F(x)=0)andforotherpoints∂F(x)<0.This∂F(x)<0
Note that, as in consensus algorithms, uniform connectivity
holds if there exist few links over the network and does not
istheleastrequirementforconvergencetowardoptimalvalue.
require all-time connectivity. Thus, using LaSalle’s invariance4
principle[4,Theorem2.1],thesolutionconvergestothesetI
contained in {x|0 ∈ L F(x(t)),1⊤x = b} with L F(x(t))
H n H
denoting the Lie derivative of the residual with respect to Eq.
(4). Since I = {x∗}, and maxL F(x(t)) < 0 for x ∈/ I,
H
dynamics (4) globally asymptotically converges to I = {x∗}
[39, Theorem 1]. This completes the proof.
Finally, we summarize our solution in the Algorithm 1.
Algorithm 1: The Accelerated Allocation Algorithm Fig. 1. (Left) Time-evolution of the residual value under the proposed
accelerated dynamics (4) as compared with some existing literature: linear
1 Input: N i, W, η, m i, M i, b, f i(·); [4],acceleratedlinearwithb=0.5[23],finite-timewithν =0.7[44],and
2 Initialization: t=0, random feasible x i(0); saturatedwithδ=1[45],[46]solutions(Right)Time-evolutionofthestate
3 while algorithm running do valuesofallagentsundertheproposeddynamics.
4 Agent i receives the gradient dfj from agents in
dxj
j ∈N over the multi-agent network G;
i
5 Agent i computes Eq. (4) (or Eq. (6));
6 Agent i sends its gradient dfi to neighboring
dxi
agents j where i∈N over G;
j
7 Return Final state x∗ i and objective function f i(x∗ i);
It should be noted that the discrete-time dynamics (6) may
result in steady-state residual due to the non-Lipschitz nature Fig. 2. (Left) The residual decay rate for different α and β values under
dynamics(4).(Right)Theresidualevolutionunderdiscrete-timedynamics(6)
of the sign-based function. This residual is closely dependent
fordifferentα,β,andη values.
on step-rate η and parameters α and β. To be more specific,
larger η, smaller (close to zero) α, and larger β result in
largersteady-stateresiduals.Sothereisatrade-offbetweenthe as states evolve over time, implying that the sum of states is
optimalitygapandconvergencerateoftheproposeddynamics constantandthesolutionisall-timefeasible.Thisimpliesthat
in discrete-time, i.e., the faster convergent solution may result ateverytime-instanttheresource-demandfeasibilityconstraint
in a higher residual. This is better shown by the simulations 1⊤x(t)=b=3000 holds.
n
in the next section. Note that this is not an issue in the Next,wesimulatetheresidualevolutionfordifferentαand
continuous-time case. β values and fixed η =0.1 to tune the convergence rate. The
costandnetworkparametersaresetthesameasintheprevious
IV. SIMULATIONS simulation.ThenetworkG isswitchedbetween6Erdos-Renyi
For simulation, we choose a random time-varying Erdos- networks every 1 sec while the union of the 6 networks is
Renyi network of n = 50 nodes with p = 20% linking connected(implyinguniformconnectivity).Thetimeevolution
probability.Thecostfunctionatagentiisf (x )=a x2+b x oftheresidualsandstatesareshowninFig.2-(Left).Itisclear
i i i i i i
with randomly chosen a ∈(0,0.3] and b ∈(0,10]. The box that increasing β and decreasing α improves the convergence
i i
constraints are m =20,M =105 addressed in the objective rate. For β = 1 and α = 1 the algorithm represents the
i i
function via logarithmic penalty term (3) with ρ = 1,σ = 1. linear case provided for comparison. Finally, Fig. 2-(Right)
By setting σ = 1 we equally weight the objective function represents the evolution of the discrete-time dynamics (6) for
as compared to the penalty term (for box constraint). Also, different values of α, β, and η. Larger η, smaller (close to
note that the algorithm works for any ρ and we choose ρ=1 zero)α,andlargerβ resultinfasterconvergencedespitelarger
as an example here. The states are initialized with random steady-state residuals. This shows the trade-off between the
valuessatisfyingthefeasibilitycondition1⊤x(0)=b=3000. convergence rate and the optimality gap.
n
In Fig. 1, the residual under dynamics (4) is compared with
some primal-based all-time feasible solutions proposed in the V. CONCLUSIONS
literature, namely, linear [4], accelerated linear [23], finite- This paper presents fast all-time feasible allocation and
time [44], and saturated [45], [46] solutions. Note that these scheduling algorithm over uniformly-connected networks, ad-
primal-based solutions are all-time feasible in contrast to the vancing the dual-based solutions in terms of connectivity and
recent dual-based (e.g., ADMM) solutions [25]–[34]. This is feasibility.Also,itadvancestheprimal-basedsolutioninterms
the reason behind comparing our work with the mentioned of uniform-connectivity and accelerated convergence. As a
primal-based literature. For our dynamics we set α = 0.3, future direction, one can consider other types of nonlinear so-
β =1.7,andη =0.2.Recallthatdual-basedsolutionsarenot lutions. For example, it is known that signum-based solutions
all-time feasible. As it is clear from the figure the decay rate arerobusttonoise/disturbances[47].Theuniformconnectivity
of the proposed solution is faster than the mentioned works. also allows for convergence over unreliable networks with
Thetimeevolutionofthestatesisalsoshowninthefigure.As packetdrops.Resourceallocationinthepresenceofmalicious
shown in the figure, the average of states remains unchanged agents [48] is another future direction.5
REFERENCES [23] E. Ghadimi, M. Johansson, and I. Shames, “Accelerated gradient
methodsfornetworkedoptimization,” inAmericanControlConference.
IEEE,2011,pp.1668–1673.
[1] M.Doostmohammadian,A.Aghasi,A.I.Rikos,A.Grammenos,E.Ka-
[24] A.CherukuriandJ.Corte´s, “Initialization-freedistributedcoordination
lyvianaki, C. N. Hadjicostis, K. H. Johansson, and T. Charalambous,
foreconomicdispatchundervaryingloadsandgeneratorcommitment,”
“Distributed anytime-feasible resource allocation subject to heteroge-
Automatica,vol.74,pp.183–193,2016.
neous time-varying delays,” IEEE Open Journal of Control Systems,
[25] T.T.DoanandC.L.Beck,“Distributedlagrangianmethodsfornetwork
vol.1,pp.255–267,2022.
resource allocation,” in IEEE Conference on Control Technology and
[2] M. Doostmohammadian, A. Aghasi, A. Rikos, A. Grammenos, E. Ka-
Applications(CCTA).IEEE,2017,pp.650–655.
lyvianaki, C. Hadjicostis, K. Johansson, and T. Charalambous, “Dis-
[26] M. Doostmohammadian, W. Jiang, and T. Charalambous, “DTAC-
tributedcpuschedulingsubjecttononlinearconstraints,” inIEEEConf.
ADMM:Delay-tolerantaugmentedconsensusADMM-basedalgorithm
onControlTechnologyandApplications,2022,pp.746–751.
for distributed resource allocation,” in IEEE 61st Conference on
[3] A.Grammenos,T.Charalambous,andE.Kalyvianaki,“CPUscheduling
DecisionandControl(CDC).IEEE,2022,pp.308–315.
in data centers using asynchronous finite-time distributed coordination
[27] G.Banjac,F.Rey,P.Goulart,andJ.Lygeros, “Decentralizedresource
mechanisms,” IEEETrans.onNetworkScienceandEngineering,2023.
allocationviadualconsensusADMM,”inAmericanControlConference
[4] A. Cherukuri and J. Corte´s, “Distributed generator coordination for (ACC).IEEE,2019,pp.2789–2794.
initialization and anytime optimization in economic dispatch,” IEEE [28] T.Chang, “AproximaldualconsensusADMMmethodformulti-agent
Transactions on Control of Network Systems, vol. 2, no. 3, pp. 226– constrainedoptimization,”IEEETransactionsonSignalProcessing,vol.
237,2015. 64,no.14,pp.3719–3734,2016.
[5] M. Doostmohammadian, “Distributed energy resource management: [29] L.Jian,J.Hu,J.Wang,andK.Shi,“Distributedinexactdualconsensus
All-timeresource-demandfeasibility,delay-tolerance,nonlinearity,and ADMMfornetworkresourceallocation,” OptimalControlApplications
beyond,” IEEEControlSystemsLetters,2023. andMethods,vol.40,no.6,pp.1071–1087,2019.
[6] S. Kar, G. Hug, J. Mohammadi, and J. M. F. Moura, “Distributed [30] N.S.AybatandE.YazdandoostHamedani, “AdistributedADMM-like
state estimation and energy management in smart grids: A consensus methodforresourcesharingovertime-varyingnetworks,”SIAMJournal
+ innovations approach,” IEEE Journal of Selected Topics in Signal onOptimization,vol.29,no.4,pp.3036–3068,2019.
Processing,vol.8,no.6,pp.1022–1038,2014. [31] D. Ding and M. R. Jovanovic´, “A primal-dual laplacian gradient flow
[7] M.Alizadeh,X.Li,Z.Wang,A.Scaglione,andR.Melton, “Demand- dynamics for distributed resource allocation problems,” in Annual
sidemanagementinthesmartgrid:Informationprocessingforthepower AmericanControlConference(ACC).IEEE,2018,pp.5316–5320.
switch,” IEEESignalProcessingMagazine,vol.29,no.5,pp.55–67, [32] W. Jiang, M. Doostmohammadian, and T. Charalambous, “Distributed
2012. resourceallocationviaADMMoverdigraphs,”inIEEE61stConference
[8] J. Zhang, A. I. Koutrouvelis, R. Heusdens, and R. C. Hendriks, “Dis- onDecisionandControl.IEEE,2022,pp.5645–5651.
tributedrate-constrainedLCMVbeamforming,”IEEESignalProcessing [33] B.Shao,M.Li,andX.Shi, “Distributedresourceallocationalgorithm
Letters,vol.26,no.5,pp.675–679,2019. forgenerallinearmultiagentsystems,”IEEEAccess,vol.10,pp.74691–
[9] H.SayyaadiandM.Moarref, “Adistributedalgorithmforproportional 74701,2022.
task allocation in networks of mobile agents,” IEEE Transactions on [34] Y.Xu,T.Han,K.Cai,Z.Lin,G.Yan,andM.Fu, “Adistributedalgo-
AutomaticControl,vol.56,no.2,pp.405–410,Feb.2011. rithmforresourceallocationoverdynamicdigraphs,”IEEETransactions
[10] M. Doostmohammadian, H. Sayyaadi, and M. Moarref, “A novel onSignalProcessing,vol.65,no.10,pp.2600–2612,2017.
consensus protocol using facility location algorithms,” in IEEE Conf. [35] X. Shi, G. Wen, and X. Yu, “Finite-time convergent algorithms for
onControlApplications&IntelligentControl,2009,pp.914–919. time-varying distributed optimization,” IEEE Control Systems Letters,
[11] M. Moarref and H. Sayyaadi, “Facility location optimization via 2023.
multi-agent robotic systems,” in IEEE International Conference on [36] T. Doan, S. Maguluri, and J. Romberg, “Finite-time analysis of
Networking,SensingandControl.IEEE,2008,pp.287–292. distributed TD(0) with linear function approximation on multi-agent
[12] J. Zeng, Y. Qian, F. Yin, L. Zhu, and D. Xu, “A multi-value cellular reinforcement learning,” in International Conference on Machine
automata model for multi-lane traffic flow under lagrange coordinate,” Learning.PMLR,2019,pp.1626–1635.
ComputationalandMathematicalOrganizationTheory,pp.1–15,2022. [37] J.Zhang,K.You,andT.Bas¸ar, “Distributeddiscrete-timeoptimization
in multiagent networks using only sign of relative state,” IEEE
[13] J. Zeng, Y. Qian, J. Li, Y. Zhang, and D. Xu, “Congestion and
TransactionsonAutomaticControl,vol.64,no.6,pp.2352–2367,2018.
energyconsumptionofheterogeneoustrafficflowmixedwithintelligent
connectedvehiclesandplatoons,” PhysicaA:StatisticalMechanicsand [38] R. Xin and U. A. Khan, “Distributed heavy-ball: A generalization
itsApplications,vol.609,pp.128331,2023. and acceleration of first-order methods with gradient tracking,” IEEE
TransactionsonAutomaticControl,vol.65,no.6,pp.2627–2633,2019.
[14] Y.Qian,J.Zeng,N.Wang,J.Zhang,andB.Wang,“Atrafficflowmodel
[39] J. Cortes, “Discontinuous dynamical systems,” IEEE Control systems
considering influence of car-following and its echo characteristics,”
magazine,vol.28,no.3,pp.36–73,2008.
NonlinearDynamics,vol.89,pp.1099–1109,2017.
[40] X. Wu, S. Magnusson, and M. Johansson, “A new family of feasible
[15] J.Zhang,Y.Qian,J.Zeng,X.Wei,andH.Li, “Hybridcharacteristics
methods for distributed resource allocation,” in IEEE Conference on
of heterogeneous traffic flow mixed with electric vehicles considering
DecisionandControl,2021,pp.3355–3360.
the amplitude of acceleration and deceleration,” Physica A: Statistical
[41] DBertsekas,ANedic,andAOzdaglar, ConvexAnalysisandOptimiza-
MechanicsanditsApplications,vol.614,pp.128556,2023.
tion, AthenaScientific,Belmont,MA,2003.
[16] T.Yang,X.Yi,J.Wu,Y.Yuan,D.Wu,Z.Meng,Y.Hong,H.Wang,
[42] D.JurafskyandJ.H.Martin,SpeechandLanguageProcessing,Prentice
Z. Lin, and K. H. Johansson, “A survey of distributed optimization,”
Hall,2020.
AnnualReviewsinControl,vol.47,pp.278–305,2019.
[43] Y.Nesterov, “Introductorylecturesonconvexprogramming,volumeI:
[17] A. Nedic´ and J. Liu, “Distributed optimization for control,” Annual
Basiccourse,” Lecturenotes,vol.3,no.4,pp.5,1998.
ReviewofControl,Robotics,andAutonomousSystems,vol.1,pp.77–
[44] G. Chen, J. Ren, and E. N. Feng, “Distributed finite-time economic
103,2018.
dispatchofanetworkofenergyresources,”IEEETransactionsonSmart
[18] M. Assran, A. Aytekin, H. Feyzmahdavian, M. Johansson, and M. G. Grid,vol.8,no.2,pp.822–832,2016.
Rabbat, “Advances in asynchronous parallel and distributed optimiza- [45] M.Doostmohammadian,A.Aghasi,M.Vrakopoulou,andT.Charalam-
tion,” ProceedingsoftheIEEE,vol.108,no.11,pp.2013–2031,2020. bous, “1st-order dynamics on nonlinear agents for resource allocation
[19] Y.He,S.Zhang,L.Tang,andY.Ren, “Largescaleresourceallocation over uniformly-connected networks,” in IEEE Conference on Control
for the Internet of Things network based on ADMM,” IEEE Access, TechnologyandApplications.IEEE,2022,pp.1184–1189.
vol.8,pp.57192–57203,2020. [46] M. Doostmohammadian, A. Aghasi, M. Vrakopoulou, H. R. Rabiee,
[20] L.XiaoandS.Boyd, “Fastlineariterationsfordistributedaveraging,” U.A.Khan,andT.Charalambous,“Distributeddelay-tolerantstrategies
Systems&ControlLetters,vol.53,no.1,pp.65–78,2004. forequality-constraintsum-preservingresourceallocation,” Systems&
[21] J.Zhang, “Poweroptimizedandpowerconstrainedrandomizedgossip ControlLetters,vol.182,pp.105657,2023.
approachesforwirelesssensornetworks,” IEEEWirelessCommunica- [47] G. E. Dullereud and F. Paganini, A course in robust control theory: a
tionsLetters,vol.10,no.2,pp.241–245,2020. convexapproach, Springer,1999.
[22] L. Xiao and S. Boyd, “Optimal scaling of a gradient method for [48] R.Wang,Y.Liu,andQ.Ling, “Byzantine-resilientresourceallocation
distributed resource allocation,” Journal of Optimization Theory and overdecentralizednetworks,” IEEETransactionsonSignalProcessing,
Applications,vol.129,no.3,pp.469–488,2006. vol.70,pp.4711–4726,2022.