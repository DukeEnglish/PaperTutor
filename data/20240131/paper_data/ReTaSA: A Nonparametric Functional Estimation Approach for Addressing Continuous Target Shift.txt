PublishedasaconferencepaperatICLR2024
RETASA: A NONPARAMETRIC FUNCTIONAL ESTIMA-
TION APPROACH FOR ADDRESSING CONTINUOUS TAR-
GET SHIFT
HwanwooKim1†,XinZhang2†,JiweiZhao3,QinglongTian4∗
UniversityofChicago1,MetaAI2,UniversityofWisconsin-Madison3,UniversityofWaterloo4
ABSTRACT
The presence of distribution shifts poses a significant challenge for deploying
modernmachinelearningmodelsinreal-worldapplications. Thisworkfocuses
on the target shift problem in a regression setting (Zhang et al., 2013; Nguyen
etal.,2016). Morespecifically,thetargetvariabley(alsoknownastheresponse
variable),whichiscontinuous,hasdifferentmarginaldistributionsinthetraining
sourceandtestingdomain,whiletheconditionaldistributionoffeaturesxgiveny
remainsthesame. Whilemostliteraturefocusesonclassificationtaskswithfinite
targetspace,theregressionproblemhasaninfinitedimensionaltargetspace,which
makesmanyoftheexistingmethodsinapplicable. Inthiswork,weshowthatthe
continuous target shift problem can be addressed by estimating the importance
weightfunctionfromanill-posedintegralequation. Weproposeanonparametric
regularizedapproachnamedReTaSAtosolvetheill-posedintegralequationand
provide theoretical justification for the estimated importance weight function.
Theeffectivenessoftheproposedmethodhasbeendemonstratedwithextensive
numericalstudiesonsyntheticandreal-worlddatasets.
1 INTRODUCTION
Letx∈Rpbethefeaturevector,y ∈Rbethetargetvariable,andp(x,y)betheirjointprobability
distribution. Classicsupervisedlearningassumesthetrainingandtestingdataaredrawnfromthe
samedistribution(i.e.,thejointdistributionp(x,y)doesnotchangeacrossdomains). However,in
practice,distributionalshiftsbetweenthetrainingandtestingdataarepervasiveduetovariousreasons,
suchaschangesintheexperimentalobjects,thedatacollectionprocess,andthelabelingprocess
(Quinonero-Candelaetal.,2008;Storkey,2009). Whenthedistributionalshiftoccurs,theknowledge
learnedfromthetrainingsourcedatamaynolongerbeappropriatetobedirectlygeneralizedtothe
testingdata.
Asacommontypeofdistributionalshift,thetargetshiftassumesthattheconditionaldistribution
offeaturesgiventhetargetvariablep(x|y)remainsthesameinthetrainingsourceandtestingdata
domains,butthemarginaldistributionofthetargetvariablep(y)differs. Existingworks(Tasche,
2017;Guoetal.,2020;Liptonetal.,2018;DuPlessis&Sugiyama,2014;Iyeretal.,2014;Tian
etal.,2023)ontargetshiftprimarilyfocusedonthecasewhereyiscategorical(alsoknownaslabel
shiftorclasspriorchange),whilethecaseswithcontinuousy(theregressiontask)havereceivedless
attention. However,thetargetshiftprobleminregressiontasksisubiquitousinreal-worldmachine
learningapplications. Forexample,theSequentialOrganFailureAssessment(SOFA)score(Jones
etal.,2009)isthecontinuousindicatorassociatedwithpatients’wellnesscondition. Considering
thescenariowheretheSOFAscoreisemployedtodeterminethetransferdestinationofpatients:
those with higher SOFA scores, indicative of severe illness, are more likely to be transferred to
largemedicalfacilitieswithadvancedmedicalequipmentandhighlyskilledstaff. Consequently,
thedistributionofSOFAscoresamongpatientsdiffersbetweenlargemedicalfacilitiesandsmaller
clinics,whilethedistributionoffeaturesgiventheSOFAscoreremainsthesameacrossdifferent
hospitals. Nevertheless,theSOFAscorepredictivemodeltrainedonlargemedicalfacilities’datasets
mightleadtoabadperformanceifdirectlyappliedtosmallerclinics’datasets. Anotherscenariofor
∗Correspondencetoqinglong.tian@uwaterloo.ca †EqualContribution
1
4202
naJ
92
]LM.tats[
1v01461.1042:viXraPublishedasaconferencepaperatICLR2024
continuoustargetshiftistheanti-causalsetting(Schölkopfetal.2012)whereyisthecauseofx. For
example,itisreasonabletoassumethatheight(y)isthecauseofthebodyweight(x),andwecan
assumethatp(x|y)isdomaininvariant.
Thisworkaimstofillthisresearchgapandfocusonthetargetshiftproblemintheregressiontasks.
Weconsidertheunsuperviseddomainadaptationsetting(Kouw&Loog,2021),inwhichthetraining
sourcedatasetprovidesthefeature-target(i.e.,(x,y))datapairswhilethetestingdatasetonlyhas
featuredata(i.e.,x)available. Thegoalistoimprovethepredictivemodel’sperformanceonthe
testingdatasetbyleveragingtheknowledgegainedfromthetrainingsourcedata.
Related Work The importance-weighted adaptation is one of the most popular approaches in
addressingthetargetshiftproblem. However,mostoftheexistingimportance-weightedadaptation
methods are designed specifically for dealing with the shift in the classification tasks (Saerens
etal.,2002;Liptonetal.,2018;Azizzadeneshelietal.,2019;Alexandarietal.,2020;Gargetal.,
2020). Intheclassificationtasks,supposethetargetvariableyhaskclasses(e.g.,k =2forbinary
classification). Then,theimportanceweightestimationcanbesimplifiedtoanoptimizationproblem
withkparameters. However,whenthetargetvariableyiscontinuous(e.g.,inaregressionproblem),
theseapproachesarenotfeasible,asitremainsunclearhowtorepresentthecontinuoustargetspace
withafinitenumberofparameters. Existingworkonthecontinuoustargetshiftisscarceasopposed
toitscategoricalcounterpart. Exceptforsomeheuristicapproaches,wefoundtwoworks(Zhang
etal.,2013;Nguyenetal.,2016)thataddressedtargetshiftusingtheideaofdistributionmatching
(i.e.,minimizingthedistancebetweentwodistributions). However,neitherofthetwoworksprovided
sufficient theoretical justifications for their proposed methods: neither consistency nor error rate
boundshavebeenestablished. Furthermore,bothKMM(Zhangetal.(2013))andL2IWE(Nguyen
etal.(2016))needtooptimizeaquadraticallyconstrainedquadraticprogram.
OurContributions Inthispaper,weproposetheRegularizedContinuousTargetShiftAdapatation
(ReTaSA) method, a novel importance-weighted adaptation method for continuous target shift
problem. ThekeycomponentoftheReTaSAmethodistheestimationofthecontinuousimportance
weightfunction,whichiscrucialforshiftadaptation.Usingtheestimatedimportanceweightfunction,
onecanadjustthepredictivemodelforthetargetdomainviaweightedempiricalriskminimization
(ERM).Ourkeyresultsandtheirsignificancearesummarizedasfollows:
1. We formulate the problem of estimating the continuous importance weight function as
finding a solution to an integral equation. However, such an integral equation becomes
ill-posedwhenthetargetvariableiscontinuous. Weintroduceanonparametricregularized
methodtoovercomeill-posednessandobtainstablesolutions.
2. Wesubstantiateourmethodbytheoreticallyexaminingtheproposedimportanceweight
functionestimator. Thetheoreticalfindings,outlinedinTheorem1,demonstratethestatisti-
calconsistencyoftheestimatedweightfunction. Inadditiontoestablishingconsistency,
wealsoquantifytheconvergencerateofournovelimportance-weightfunctionestimator,
therebyenhancingthedistinctivecontributionsofourresearch.Tothebestofourknowledge,
thisisthefirstworktoofferatheoreticalguaranteeunderthecontinuouscase.
3. Wedevelopaneasy-to-useandoptimization-freeimportance-weightestimationformula
thatonlyinvolvessolvingalinearsystem. Throughcomprehensivenumericalexperiments,
wedemonstratethattheReTaSAmethodsurpassescompetitiveapproachesinestimation
accuracyandcomputationalefficiency.
2 THE TARGET SHIFT INTEGRAL EQUATION AND REGULARIZATION
Weusesubscriptssandttorepresentthetrainingsource-andtestingdatadomains,respectively.
Thetargetshiftassumptionsaysthatp (x|y)=p (x|y)whilep (y)̸=p (y),andthegoalistotrain
s t s t
apredictivemodelE (cid:98)t(y|x)onthetargetdomain. Intermsofdatasamples,wehavelabeleddata
{(x ,y )}n ∼p (x,y)fromthesourcedomainandunlabeleddata{x }n+m ∼p (x)fromthe
i i i=1 s i i=n+1 t
testingdatadomain. Notethatdatafromthetestingdatadomainhavenoobservationonthetarget
variabley;thus,wecannottrainE (cid:98)t(y|x)directlyandmustleveragethefeature-targetdatapair(x,y)
fromthetrainingsourcedomain.
2PublishedasaconferencepaperatICLR2024
Wedefinetheimportanceweightfunctionasω(y)≡p (y)/p (y),thetargetshiftassumptionimplies
t s
that
p (x) (cid:82) p (x,y)dy (cid:82) p (x,y)ω(y)dy (cid:90)
t = t = s = p (y|x)ω(y)dy. (1)
p (x) p (x) p (x) s
s s s
Equation(1)hasthreeterms: p (x)/p (x),p (y|x),andω(y). Supposep (x)/p (x)andp (y|x)
t s s t s s
are known, then (1) can be viewed as an integral equation to solve the unknown function ω(y).
Theimportanceweightfunctionω(y)isthekeytotargetshiftadaptation: lettingℓ(·,·)betheloss
function, the risk of any predictive model f(·) on the testing data domain can be converted to a
weighted risk on the training source domain: E [ℓ{f(x),y}] = E [ω(y)ℓ{f(x),y}], where E
t s s
and E represent the expectation with respect to the training source and testing data distribution,
t
respectively. Suchequivalenceimpliesthatwecanlearnapredictivemodelforthetargetdomainvia
weightedERMusingdatafromthesourcedomainwiththeimportanceweightfunctionω(y). Most
existingworkdealswiththeclassificationtaskswithfinitekclasses,inwhichycomesfromafinite
discretespace{1,··· ,k}. Thus,theright-hand-sideof(1)canberepresentedinasummationform
(cid:80)k
p (y|x)ω(y)and{ω(y),y =1,··· ,k}canbeestimatedbysolvingthek-dimensionallinear
y=1 s
equations (Lipton et al., 2018). However, when y is continuous, the importance weight function
cannotbereducedtoafinitenumberofparametersasycantakeaninfinitenumberofvalues. Sucha
differencepinpointsthedifficultiesthatarisewhenyiscontinuous.
Operator Notations We first introduce a few operator notations for our problem formulation.
Consideringthetrainingsourcedistributionp (x,y),weuseL2(x,y)todenotetheHilbertspace
s
formean-zerosquare-integrablefunctionsof(x,y). Theinnerproductforanyh ,h ∈L2(x,y)is
1 2
definedby⟨h ,h ⟩ = (cid:82) h (x,y)h (x,y)p (x,y)dxdy = E {h (x,y)h (x,y)},andthenormis
1 2 1 2 s s 1 2
inducedas∥h∥=⟨h,h⟩1/2. Similarly,weuseL2(x)orL2(y)torespectivelydenotethesubspace
thatcontainsfunctionsofxory only. Inthiscase,theinnerproducth ,h ∈ L2(x)orL2(y)is
1 2
(cid:82) (cid:82)
givenby⟨h ,h ⟩ = h (x)h (x)p (x)dxor⟨h ,h ⟩ = h (y)h (y)p (y)dy. Additionally,we
1 2 1 2 s 1 2 1 2 s
definetwoconditionalexpectationoperators
T :L2(y)→L2(x),s.t.Tφ=E {φ(y)|x}, (2)
s
T∗ :L2(x)→L2(y),s.t.T∗ψ =E {ψ(x)|y}. (3)
s
T andT∗areadjointoperatorsbecause
(cid:90) (cid:90)(cid:90)
⟨Tφ,ψ⟩= ψ(x)E {φ(y)|x}p (x)dx= φ(y)ψ(x)p (x,y)dydx
s s s
(cid:90)
= φ(y)E {ψ(x)|y}p (y)dy =⟨φ,T∗ψ⟩
s s
foranyφ∈L2(y)andψ ∈L2(x). Usingtheoperatornotations,werewrite(1)as
Tρ =η, (4)
0
whereη(x) ≡ p (x)/p (x)−1andρ (y) ≡ ω(y)−1istheunknownfunctiontobesolved. We
t s 0
defineη(x)insuchwaytosatisfythemean-zeroconditionE {η(x)}=0sothatη(x)∈L2(x).
s
Identifiability Withtheabovereformulation,anaturalquestioniswhetherρ isidentifiable,i.e.,
0
thesolutionoftheequation(4)isunique. Tofurtherensureuniquenessofthesolutionto(4),letthe
nullsetofT
beN(T)=(cid:8) φ:Tφ=0,φ∈L2(y)(cid:9)
. Thenρ isauniquesolutionto(4)ifandonly
0
ifN(T)={0}. BecauseT isaconditionalexpectationoperator,wecanequivalentlyexpressthe
identifiabilityconditionwiththefollowingcompletenesscondition. WereferthereaderstoNewey&
Powell(2003)foradetaileddiscussiononthecompletenesscondition.
Condition1(IdentifiabilityCondition). Theimportanceweightfunctionω(y)isidentifiablein(1)if
andonlyifE {φ(y)|x}=0almostsurelyimpliesthatφ(y)=0almostsurelyforanyφ∈L2(y).
s
Ill-posedness&Regularization Eventhoughtheintegralequationin(4)hasauniquesolution
underCondition1,wearestillnotreadilyabletosolveforρ . Thisisbecause(4)belongstotheclass
0
ofFredholmintegralequationsofthefirstkind(Kress,1999),whichisknowntobeill-posed. More
specifically,itcanbeshownthatevenasmallperturbationinη canresultinalargechangeinthe
solutionρ in(4). Thisphenomenonisreferredtoasan"explosive"behavior(Darollesetal.,2011),
0
3PublishedasaconferencepaperatICLR2024
forwhichweprovidedetailsinSectionAthesupplementarymaterials. Suchsensitivedependence
upon input (i.e., η) is problematic because, in practice, the true function η is unknown, and an
estimatedversionηwouldbepluggedin. Nomatterhowaccuratetheestimationis,theestimatedη
(cid:98) (cid:98)
willinevitablydifferfromη,thusleadingtoalargeerroronρ .
0
Toaddresstheill-posednessofEquation(4),weadopttheTikhonovregularizationtechnique,which
hasbeenbroadlyappliedinvarioustasks,forexample,theridgeregression(Hoerl&Kennard,1970),
andtheinstrumentalregression(Carrascoetal.,2007;Fève&Florens,2010;Darollesetal.,2011).
TheTikhonovregularizationyieldsaregularizedestimatorρ byminimizingapenalizedcriterion
α
ρ =argmin∥Tρ−η∥2+α∥ρ∥2,
α
ρ∈L2(y)
whereαisaregularizationparameter.Thisminimizationleadstothefirst-orderconditionforaunique
solutionto(αI+T∗T)ρ=T∗η,whereIistheidentityoperator. Furthermore,bythedefinitionof
T andT∗in(2)-(3),wecanrewritethefirst-orderconditionas
αρ(y)+E [E {ρ(y)|x}|y]=E {η(x)|y}. (5)
s s s
3 ESTIMATION OF THE IMPORTANCE WEIGHT FUNCTION
Thissectionfocusesonhowtoestimatethesolutionfunctionρ using(5). Estimatingρ requires
α α
twosteps:thefirststepistoreplace(5)withasample-basedversion;thesecondstepistosolveforthe
estimateρ fromthesample-basedequation. Weemploythekernelmethodtofindthesample-based
(cid:98)α
versionof(5). Tothisend,withoutlossofgenerality,weassumexandytakevaluesin[0,1]pand
[0,1] respectively. In particular, we use a generalized kernel function, whose definition is given
below.
Definition1. Lethbeabandwidth,abivariatefunctionK :[0,1]×[0,1]→R satisfying:
h ≥0
1)K (x,x˜)=0,ifx>x˜orx<x˜−1, forallx˜∈[0,1];
h
(cid:90) y (cid:26) 1 forq =0,
2)h−(q+1) xqK (x,x˜)dx=
h 0 for1≤q ≤ℓ−1,
y−1
isreferredasaunivariategeneralizedkernelfunctionoforderℓ.
Basedontheabovedefinition,thedensityestimatesaregivenby
n n
(cid:88) (cid:88)
p (x,y)=(nhp+1)−1 K (x−x ,x)K (y−y ,y), p (y)=(nh)−1 K (y−y ,y),
(cid:98)s X,h i Y,h i (cid:98)s Y,h i
i=1 i=1
n+m n
(cid:88) (cid:88)
p (x)=(nhp)−1 K (x−x ,x), p (x)=(nhp)−1 K (x−x ,x),
(cid:98)t X,h i (cid:98)s X,h i
i=n+1 i=1
wherepisthedimensionofx,histhebandwidthparameter,K isaunivariategeneralizedkernel
Y,h
function,andK isaproductofunivariategeneralizedkernelfunctionsdefinedforeachcomponent
X,h
ofX. Inaddition,weestimateη(x)withη(x)=p (x)/p (x)−1. Insteadofsimplycalculatingthe
(cid:98) (cid:98)t (cid:98)s
ratiooftwodensityestimates,thereareothermethodsforcomputingthedensityratio(e.g.,Sugiyama
etal.2012). Duetothespacelimit,wefocusonthesimpleapproachη(x)=p (x)/p (x)andleave
(cid:98) (cid:98)t (cid:98)s
moredetailsinSectionC.2.2ofthesupplementarymaterials.
LetρbeanarbitraryfunctioninL2(y). Usingthekerneldensityestimates,theNadaraya–Watson
estimatesofE {ρ(y)|x},E {η(x)|y},andE [E {ρ(y)|x}|y]are,respectively,givenby
s s (cid:98) s s
(cid:80)n
ρ(y )K (x−x ,x)
(cid:80)n
η(x )K (y−y ,y)
E (cid:98)s{ρ(y)|x}= (cid:80)i=1
n
Ki X (, xh
−x
,xi
)
, E (cid:98)s{η (cid:98)(x)|y}= (cid:80)i=1 n(cid:98) Ki Y (, yh
−y
,yi
)
,
j=1 X,h j j=1 Y,h j
and
E (cid:98)s[E
(cid:98)s{ρ(y)|x}|y]=(cid:40) (cid:88)n
K Y,h(y−y
k,y)(cid:41)−1(cid:40) (cid:88)n (cid:80) (cid:80)n
i=1
nρ(y Ki)K
X (,
xh(x
−ℓ
x− ,x xi,x )ℓ)
K Y,h(y−y
ℓ,y)(cid:41)
.
k=1 ℓ=1 j=1 X,h ℓ j ℓ
4PublishedasaconferencepaperatICLR2024
Usingtheestimatesabove,wecanobtainthesample-basedversionof(5),andthenextstepisto
solveforthefunctionρ. Bylettingy =y ,...,y ,wehavethefollowinglinearsystem:
1 n
α[ρ(y )...ρ(y )]T +C C [ρ(y )...ρ(y )]T =C [η(x )...η(x )]T (6)
1 n x|y y|x 1 n x|y (cid:98) 1 (cid:98) n
whereC andC arebothn×nmatricesandtheir(i,j)thentriesaregivenby
x|y y|x
(cid:0) C x|y(cid:1)
ij
= (cid:80)nK Y K,h(y i (− yy −j, yy i)
,y )
and (cid:0) C y|x(cid:1)
ij
= (cid:80)nK X K,h(x i (− xx −j, xx i ,)
x
).
ℓ=1 Y,h i ℓ i ℓ=1 X,h i ℓ i
Wecanobtaintheestimateofρ on{y ,...,y }bysolvingthelinearsystem(6)as
α 1 n
[ρ (y ),...,ρ (y )]T =(cid:0) αI+C C (cid:1)−1 C [η(x ),...,η(x )]T . (7)
(cid:98)α 1 (cid:98)α n x|y y|x x|y (cid:98) 1 (cid:98) n
Notethattheestimateson{y ,...,y }in(7)areallweneedbecausetheimportanceweightsare
1 n
ω(y )=ρ (y )+1,i=1,...,n;thus,forafamilyofregressionmodels,denotedbyF,thetrained
(cid:98) i (cid:98)α i
regressionmodelforthetargetdomaincanbeobtainedfromtheweightedERM
n
E (cid:98)t(Y|X=x)=argmin1 (cid:88) ω (cid:98)(y i){f(x i)−y i}2 .
n
f∈F
i=1
4 THEORETICAL ANALYSIS
In this section, we provide a theoretical understanding of the proposed kernel-based importance
weightfunction-basedadaptation. Inparticular,weestablishtheconsistencyofρˆ ,asolutionofthe
α
sample-basedapproximation,tothesolutionρ oftheequation(4)undersuitableassumptions. We
0
definetwoestimatedconditionalexpectationoperatorsas
(cid:90)
T(cid:98):L2(y)→L2(x),s.t.T(cid:98)φ=E (cid:98)s{φ(y)|x}≡ φ(y)p (cid:98)s(y|x)dy, (8)
(cid:90)
T(cid:98)∗ :L2(x)→L2(y),s.t.T(cid:98)∗ψ =E (cid:98)s{ψ(x)|y}≡ ψ(x)p (cid:98)s(x|y)dx (9)
Furthermore, by plugging η(x) = p (x)/p (x)−1, we have the kernel-based approximation of
(cid:98) (cid:98)t (cid:98)s
equation(5)as
(cid:16) (cid:17) (cid:104) (cid:105)
αI+T(cid:98)∗T(cid:98) ρ=T(cid:98)∗η (cid:98) or αρ(y)+E (cid:98)s E (cid:98)s{ρ(y)|x}|y =E (cid:98)s{η (cid:98)(x)|y}. (10)
Now,weprovideatheoreticaljustificationforourproposedkernel-basedregularizationframework.
Specifically, we first prove the consistency of the solution obtained from (10), denoted by ρ ≡
(cid:98)α
(cid:16) (cid:17)−1
αI+T(cid:98)∗T(cid:98) T(cid:98)∗η (cid:98). Towardthisend,westateseveralnecessaryassumptions.
Assumption1. Thejointsourcedensityp (x,y)andmarginalsourcedensitiesp (x)andp (y)
s s s
satisfy(cid:82) (cid:82)
(cid:110)
ps(x,y)
(cid:111)2
p (x)p (y)dxdy <∞.
ps(x)ps(y) s s
Remark1. TheimplicationofAssumption1isthattwooperatorsT andT∗definedin(2)and(3)are
Hilbert-Schmidtoperatorsandthereforecompact,whichadmitsthesingularvaluedecomposition.
Toestablishconsistency,werestrictthefunctionspaceinwhichthesolutionρ resides.Consequently,
0
weintroducetheβ-regularityspaceoftheoperatorT forsomeβ >0,
Definition 2. For β > 0, the β-regularity space of the compact operator T is defined as Φ =
β
(cid:110) (cid:111)
ρ∈L2(y)suchthat (cid:80)∞ ⟨ρ,φ ⟩2/λ2β <∞ , where {λ }∞ are the decreasing sequence of
i=1 i i i i=1
nonzerosingularvaluesofT and{φ }∞ isasetoforthonormalsequenceinL2(y). Inotherwords,
i i=1
forsomeorthonormalsequence{ϕ }∞ ⊂L2(x),Tϕ =λ φ holdsforalli∈N.
i i=1 i i i
Assumption2. Thereexistsaβ >0suchthatthetruesolutionρ ∈Φ .
0 β
Remark2. Ingeneral,foranyβ ≥β ,Φ ⊆Φ (Carrascoetal.,2007).Therefore,theregularity
1 2 β1 β2
levelβ governsthecomplexityofthespace. Adetaileddiscussionoftheβ-regularityspaceisgiven
inSectionA.1ofthesupplementarymaterials.
5PublishedasaconferencepaperatICLR2024
Assumption 3. We assume x ∈ [0,1]p, y ∈ [0,1]; and the k-times continuously differen-
tiabledensities p (x,y), p (x) and p (x) areallboundedaway fromzeroontheirsupports, i.e.,
s s t
p (x,y),p (x),p (x)∈[ϵ,∞), forsomeϵ>0.
s s t
Remark 3. The equation (1) is problematic when p (x) goes to zero. Therefore we need the
s
assumptionthatp (x)isboundedfrombelowbysomeconstantϵ > 0. Also,weneedthesupport
s
ofp (x)tobeasubsetofthesupportofp (x). Whenp (x)goestozere,whilep (x)isnotzero,it
t s s t
correspondstotheout-of-distribution(OOD)setting(Zhouetal.,2023).
Asweadopttheclassofmultivariategeneralizedkernelfunctionsformedbyaproductofunivariate
generalizedkernelfunctions,weimposethefollowingcommonassumptionswhichcanbefoundin
(Darollesetal.,2011;Hall&Horowitz,2005)
Assumption4. Withabandwidthparameterh,ageneralizedkernelfunctionK :[0,1]×[0,1]→
h
R satisfiesthefollowingconditions:
≥0
1. K (x,y)=0ifx∈/ [y−1,y]∩C,whereC isacompactintervalindependentofy.
h
2. sup |K (x,y)|<∞.
h
x∈C,y∈[0,1]
Remark 4. Note that the domain restriction is primarily for the purpose of theoretical analysis.
In fact, any compact domain would suffice. The continuous differentiability and boundedness
assumptionsonthedensityaretoobtainuniformconvergenceofKDEestimators,whichservesas
animportanttooltoestablishconsistency. Suchuniformconvergenceresultsbasedontheordinary
kernelfunctionsneedadditionalrestrictionsonthedomain,whilethegeneralizedkernelfunctions
canobtainuniformconvergenceovertheentirecompactsupportDarollesetal.(2011).
Toguaranteeconvergenceinprobability,wemakeassumptionsonthedecayingrateofthebandwidth
parameterhandregularizationparameterαwithrespecttothesamplesizen.
Assumption 5. The kernel bandwidth h, regularization parameter α and the source sample
size n satisfy lim log(n)/(nhp+1) = 0. Furthermore, the target sample size m satisfies
h→0
n→∞
lim log(m)/(mhp)=0.
h→0
m→∞
Remark5. Theassumptionimpliesthatthegrowthrateofnisfasterthanthedecayingrateofhp+1
sothatnhp+1growsfasterthanthelog(n)rate. Similarton,werequirethegrowthrateofmtobe
fasterthanthedecayingrateofhp. Astheassumptionindicates,thepriceonemustpaytoestablish
aconvergencerateinthehigh-dimensionalsettingisnon-negligible.
Weformallystatetheconsistencyresult,ofwhichtheproofisprovidedinSectionBofthesupple-
mentarymaterials.
Theorem1. Forβ ≥2,underAssumptions1-5,onecanshowthat||ρ −ρ ||2isoforder
(cid:98)α 0
(cid:32) (cid:18) (cid:19)(cid:18) (cid:19)
1 1
O α2+ +h2γ +h2γ +1 α(β−2)
p nhp+1 nhp+1
(cid:18) (cid:19)(cid:32) (cid:114) (cid:32) (cid:114) (cid:33)(cid:33)(cid:33)
1 1 1 logm logm
+ +h2γ +1 +h2γ + hγ + . (11)
α2 nhp+1 n mhp mhp
(cid:18) (cid:113) (cid:19)
Inparticular,ifmax h2γ, lo mg( hm p)hγ,lo mg( hm p) = o p(α2)and lim α→0 nα2 = ∞,ρ (cid:98)α converges
n→∞
inprobabilitytoρ ,i.e.,||ρ −ρ ||2 =o (1),asα,h→0,n→∞,andm→∞.
0 (cid:98)α 0 p
Remark 6. In the proof, we conduct the theoretical analysis by decomposing the error between
ρ and ρ into three parts. Each term, inside the O (·) expression in (11), indicates the errors
0 (cid:98)α p
manifestedbyeachofthethreeparts. ThefirstterminsidetheO (·)representstheerrorbetween
p
the unregularized solution ρ and the regularized solution ρ . The second term appears due to
0 α
kernel-basedapproximationofconditionalexpectationoperators. Thelastfactorreflectsthecostof
estimatingconditionalexpectationoperatorsandtarget/sourcedensities. Naturally,thetargetsample
sizeonlygetsinvolvedinthelastterm.
6PublishedasaconferencepaperatICLR2024
Remark 7. To establish consistency, n must grow faster than α2 to make nα2 divergent. In the
meantime, the decay rate of regularization parameter α2 should be slower than all three terms
(cid:112)
h2γ, log(m)/(mhp)hγ andlog(m)/(mhp). Therefore,theassumptionindicatesthattheregular-
izationparametershoulddecayslowerasthedimensionofthefeaturebecomeslarger,i.e.,alarger
regularizationeffectisneededforahigherdimension. Furthermore,theassumptionindicatesthat
onecanuseasmallerregularizationparameterforsmootherdensitieswithalargerorderofthe
generalizedkernelfunction.
Remark 8. Theorem 1 provides a bound for the estimation error’s weighted L2 norm (i.e.,
∥ρ −ρ ∥2 = (cid:82) {ρ (y)−ρ (y)}2 p (y)dy). Comparedwithafunction’sordinaryL2 norm(i.e.
(cid:98)α 0 (cid:98)α 0 s
(cid:82) {ρ (y)−ρ (y)}2 dy), theweightedL2 normdirectlyboundsthetargetdomaingeneralization
(cid:98)α 0
error. MoredetailsaregiveninSectionB.1ofthesupplementarymaterials.
5 EXPERIMENTS
Inthissection,wepresenttheresultsofnumericalexperimentsthatillustratetheperformanceof
ourproposedmethodinaddressingthecontinuoustargetshiftproblem. Wewillfirststudywiththe
syntheticdataandthenapplythemethodstotworeal-worldregressionproblems. Ourexperiments
areconductedonaMac-BookProequippedwitha2.9GHzDual-CoreIntelCoreI5processorand
8GBofmemory. Werelegatedtheexperimentaldetails(e.g.,hyperparametertuning)andextensive
experimentswithhigh-dimensionaldatasetstoSectionCinthesupplementarymaterial.
5.1 NONLINEARREGRESSIONWITHSYNTHETICDATA
Wefirstconductasyntheticdataanalysiswithanon-
linear regression problem. Inspired by the setting
in Zhang et al. (2013), we generate the dataset with 4 Source Data
x=y+3×tanh(y)+ϵ,whereϵ∼Normal(0,1).The Target Data
target y forsourcedata isfrom Normal(0,2), while 2
s
thetestingdatahasthetargety fromNormal(µ ,0.5).
t t 0
Weuseµ toadjustthetargetshiftbetweenthetraining
t
sourceandtestingdata.Wesetthesizeofthetargettest- 2
ingdataas0.8ofthisstudy’strainingsourcedatasize,
4
i.e.,m=0.8×nunlessotherwisespecified. Figure1
showsanexamplewithµ =0.5andn=200. Asfor
t 20 10 0 10
thetargetprediction,weadoptthepolynomialregres- x
sionmodelwithdegreesas5. Inthissimulationstudy,
weconsiderthreeexistingadaptationstrategiesasbase- Figure 1: An illustration of the nonlinear
linemethods: 1).Non-Adaptation,inwhichthesource regressionsyntheticdatawithn=200and
datatrainedmodelisdirectlyappliedfortheprediction. µ =0.5. Thebluedotsarethesourcedata,
t
2).Oracle-Adaptation,ofwhichtheimportanceweight andtheredplusmarksarethetargetdata.
functionisthegroundtruth. 3).KMM-Adaptationpro-
posedbyZhangetal.(2013). 4).L2IWE-AdaptationproposedbyNguyenetal.(2016). Itisworth
notingthatOracle-Adaptationisinfeasibleinpracticeastheshiftmechanismisunknown.
EvaluationMetrics Twometricsareusedtoevaluatetheadaptationperformanceinourexperi-
ments: 1). WeightMSE:themeansquareerroroftheestimatedadaptationweightsv.s. theweights
fromOracle-Adaptation,i.e.,(cid:80)n ∥ωˆ(y )−ω(y )∥2/n.Non-AdaptationcalculatestheweightMSE
i=1 i i
byassumingnoshiftasωˆ(y)≡1. 2). DeltaAccuracy(∆Accuracy): thepercentageoftheimproved
predictionMSEcomparedwiththatofNon-Adaptation,andthelargervaluerepresentsthebetter
improvement. Weconductedallexperimentswith50replications.
Experimental Results Our firststudy focuseson theadaptation methods’performances under
different data sizes. We fix µ = 0.5 and change the data size n from 100 to 1000. The results
t
are shown in Figure 2 (a)&(d). Our proposed method performs significantly better than L2IWE-
AdaptationandKMM-Adaptationmethodintermsofbothweightestimationandpredictionaccuracy.
ComparedwithNon-Adaptation,KMMandL2IWEmethodsreducetheweightMSEbyabout25%
7
yPublishedasaconferencepaperatICLR2024
4
2.0 None None 2.0 None
1.5 K L O2M uI rWM sE 3 K L O2M uI rWM sE 1.5 K L O2M uI rWM sE
2 1.0 1.0
1
0.5 0.5
100 200 500 1000 0.5 1.0 1.5 2.0 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Sample Size µt m/n
(a)WeightMSEvsSampleSize (b)WeightMSEvsTargetShift (c)WeightMSEvsSizeRatio
Oracle
30 30 KMM 30
L2IWE 20 Ours
20
20
Oracle 10 Oracle
10 KMM KMM
L2IWE 0 L2IWE 10
Ours Ours
0
100 200 500 1000 0.5 1.0 1.5 2.0 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Sample Size µt m/n
(d)∆AccuracyvsSampleSize (e)∆AccuracyvsTargetShift (f)∆AccuracyvsSizeRatio
Figure2: Performancescomparisonoverdifferenceadaptationmethods. Thefirstrowusesweight
MSEasametric,andthesecondoneshowstheperformancemeasuringby∆Accuracy. (a)&(d)are
theperformanceoverdifferentsamplesizes. Thesamplesizesrangefrom{100,200,500,1000}.
(b)&(e)aretheperformancesoverdifferenttargetshiftsµ . Thevaluesofµ rangefrom0.1to2.
t t
(c)&(f)aretheperformancesoverdifferenttarget-sourcedatasizeratiom/nandthevaluesrange
from0.2to0.8. Thesolidcurvesarethemeanvaluesandtheshadowregionsare95%CIerrorbands.
and 60%, respectively, while our method reduces it by more than 75%. For prediction accuracy,
increasingdatasizefrom100to1000,ourmethodimprovesaccuracyfromabout15%to22%while
KMM-Adaptationimproveslessthan10%. TheL2IWEmethodisbetterthantheKMMmethodbut
stillnotasgoodastheproposedmethod.
Furthermore, we study the performances under different target shifts with the results shown in
Figure2(b)&(e). Consistently,ourproposedadaptationmethodstilloutperformsKMMandL2IWE.
ItcanbeseenfromFigure2(b)thatasµ increases,theshiftbecomessevere,andtheweightMSE
t
getslargerforallthemethods. However,ourproposedmethodkeepstheweightMSEsmallerthan
0.8foralltheµ values,whileKMMandL2IWEhavetheweightMSEmorethan1.5. Also,forthe
t
predictionperformance,ourproposedmethodisclosetotheOracle-Adaptationwhenµ increases
t
withimprovedaccuracybymorethan20%. ButKMMandL2IWEgenerallygetworseperformance
asµ increases.
t
Wealsoevaluatetheimpactoftargetdatasizemontheperformance. Wefixthesourcedatasize
n = 500, and the target shift µ = 0.5. We tune the size ratio m/n in {0.2, 0.4, 0.6, 0.8}. The
t
experimentalresultsareshowninFigure2(c)&(f). ItcanbeseenfromFigure2(c)thatthetarget
data size m has a relatively small impact on the adaptation performances. The weight MSE and
deltaaccuracycurvesareflatoverdifferentvaluesofm/n. Butwhencomparingtheperformanceof
ourmethodswithKMMandL2IWE,wecanseethatourmethodcanconsistentlyachievehigher
predictionaccuracyandsmallerweightMSE.Thus,weconcludethatourproposedmethodperforms
better than the two existing methods under different sample sizes and target shift settings in this
nonlinearregressionstudy.
5.2 REAL-WORLDDATAEXPERIMENTS
Inthissection,wewillconducttheexperimentswithtworeal-worlddatasets: theSOCRdataset1and
theSzegedweatherrecorddataset2. TheSOCRdatasetcontains1035recordsofheights,weights,
andpositioninformationforsomecurrentandrecentMajorLeagueBaseball(MLB)players. Inthis
dataset,thereisastrongcorrelationbetweentheplayer’sweightsandheights. Also,itisnaturalto
considerthecausalrelation: height→weight,whichjustifiesthecontinuoustargetshiftassumption.
1http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights
2https://www.kaggle.com/datasets/budincsevity/szeged-weather
8
ESM
thgieW
)%(
ycaruccA
atleD
ESMthgieW
)%(ycaruccAatleD
ESMthgieW
)%\(
ycaruccA
atleDPublishedasaconferencepaperatICLR2024
Table1: TheexperimentalresultsforSOCRandSzegedweatherdatasets. Thenumbersreported
beforeandafter±symbolizethemeanandstandarddeviation,respectively.
SOCRDataset SzegedWeatherDataset
Adaption WeightMSE ∆Pred. MSE(%) WeightMSE ∆Pred. MSE(%)
Oracle – 12.726 - 35.572
±1.026 ±26.237
KMM 0.477 3.076 2.343 0.516
±0.269 ±5.175 ±1.488 ±65.107
L2IWE 0.178 −5.933 1.047 −8.400
±0.025 ±1.763 ±0.650 ±27.622
Ours 0.025 6.705 0.756 19.567
±0.009 ±0.977 ±0.878 ±15.679
Thus, we consider players’ weights as the covariate x and their heights as y. In our study, we
conducted 20 random trials. In each trial, we treat all outfielder players as the testing data and
randomlyselect80%oftheplayerswiththeotherpositionsasthetrainingsourcedata.
Thesecondreal-worldtaskunderinvestigationistheSzegedtemperaturepredictionproblem. This
datasetcomprisesweather-relateddatarecordedinSzeged, Hungary, from2006to2016. Inthis
study,wetakethetemperatureasthetarget,andhumidityascovariate. Thisisbecausethereisa
causalrelationshipbetweentemperatureandhumidity: ittendstodecreaserelativehumiditywhen
temperaturerises. Wetreateachyear’sdataasanindividualtrial. Ineachtrial,weutilizedatafrom
JanuarytoOctoberasthetrainingsourcedataset,whiledatafromNovemberandDecemberconstitute
thetestingdataset. Inthisdata-splittingscheme,thetestingdatatendstohavelowertemperature
valuesthanthetrainingsourcedata.
TheexperimentalresultsaresummarizedinTable1. Aswedonotknowthetruedistributionoftarget
variablesinreal-worlddatasets,wecalculatetheoracleimportanceweightinanempiricalway: we
usetherealtargetvaluesacrosstrainingandtestingdatasetstoestimatethecorrespondingdensity
functions,thenleveragetheratiooftheestimateddensityfunctionsfortheoracleimportanceweight.
WeuseweightMSEand∆predictionMSE(%)astheperformancemetrics. Itcanbeseenthatour
proposedadaptationmethodperformsbetterthanKMMandL2IWEwithsmallerweightMSEand
larger∆predictionMSE:Ourmethodimprovestheweightestimationbyreducingabout95%and
77%weightMSEforSOCRandSzegedweatherdatasets,respectively. Also,for∆predictionMSE,
ourmethodimprovesabout4%fortheSOCRdatasetand19%fortheSzegedweatherdataset. Also,
notethatourmethod’sestimationvariation(i.e.,thestandarddeviation)issmallerthanKMMand
IL2IWE.Thus,weclaimthatourmethodperformswellinbothestimationaccuracyandstability.
6 DISCUSSIONS
We address the continuous target shift problem by nonparametrically estimating the importance
weightfunction,bysolvinganill-posedintegralequation. Theproposedmethoddoesnotrequire
distribution matching and only involves solving a linear system and has outperformed existing
methodsinexperiments. Furthermore,weoffertheoreticaljustificationfortheproposedmethodology.
Ourapproachhaseffectivelyextendedtohigh-dimensionaldatabyintegratingtheblack-box-shift-
estimation method introduced in Lipton et al. (2018). The essence of this method is to use a
pre-trainedpredictivemodeltomapthefeaturesxtoascalarE(cid:98)s(y|x);thusavoidingthecurseof
dimensionality. Duetospaceconstraints,wepresentadditionalexperimentsonhigh-dimensional
datainthesupplementarymaterials.
Thisstudyisprimarilycenteredontrainingpredictivemodelsinthetargetdomain. Anassociated
questionnaturallyarisesregardingthequantificationofuncertaintyinpredictions. Whileexisting
researchhasaddressedthisconcerninthecontextofclassification(e.g.,Podkopaev&Ramdas2021),
anoticeablegapexistswhenconsideringthecontinuouscase.Toourbestknowledge, thisaspect
remainsunexploredinthecurrentliteratureandcouldbeaprospectiveavenueforfutureresearch.
Finally,itisnoteworthythatweconsiderthecasewherethesupportofy onthetargetdomainis
a subset of that in the source domain. Consequently, another potential future research question
willbetoaddresscontinuoustargetshiftsundertheout-of-distributionsetting. Lastly,weadopta
simpledensityratioestimationmethod(forη(x))inthispaperandestablishtheoreticalresultsupon
it. WecomparethissimpledensityratiomethodwiththeRuLSIFmethodinSectionC.2.3ofthe
supplementary,butmoreextensivecomparisonswithotherexistingmethodscouldbeofinterest.
9PublishedasaconferencepaperatICLR2024
ACKNOWLEDGEMENT
QinglongTianissupportedbytheNaturalSciencesandEngineeringResearchCouncilofCanada
(NSERC)DiscoveryGrantRGPIN-2023-03479.
REFERENCES
Amr M. Alexandari, Anshul Kundaje, and Avanti Shrikumar. Maximum likelihood with bias-
corrected calibration is hard-to-beat at label shift adaptation. In International Conference on
MachineLearning,2020.
KamyarAzizzadenesheli,AnqiLiu,FannyYang,andAnimashreeAnandkumar.Regularizedlearning
fordomainadaptationunderlabelshifts. InInternationalConferenceonLearningRepresentations,
2019.
Marine Carrasco, Jean-Pierre Florens, and Eric Renault. Linear inverse problems in structural
econometrics estimation based on spectral decomposition and regularization. In Handbook of
Econometrics,volume6,pp.5633–5751.Elsevier,2007.
Serge Darolles, Yanqin Fan, Jean-Pierre Florens, and Eric Renault. Nonparametric instrumental
regression. Econometrica,79:1541–1565,2011.
MarthinusChristoffelDuPlessisandMasashiSugiyama. Semi-supervisedlearningofclassbalance
underclass-priorchangebydistributionmatching. NeuralNetworks,50:110–119,2014.
Frédérique Fève and Jean-Pierre Florens. The practice of non-parametric estimation by solving
inverseproblems: theexampleoftransformationmodels. TheEconometricsJournal,13:S1–S27,
2010.
SaurabhGarg,YifanWu,SivaramanBalakrishnan,andZacharyC.Lipton. Aunifiedviewoflabel
shiftestimation. InConferenceonNeuralInformationProcessingSystems,2020.
JiaxianGuo,MingmingGong,TongliangLiu,KunZhang,andDachengTao. LTF:Alabeltransfor-
mationframeworkforcorrectinglabelshift. InInternationalConferenceonMachineLearning,
2020.
PeterHallandJoelL.Horowitz.Nonparametricmethodsforinferenceinthepresenceofinstrumental
variables. TheAnnalsofStatistics,33:2904–2929,2005.
ArthurE.HoerlandRobertW.Kennard. Ridgeregression: Biasedestimationfornonorthogonal
problems. Technometrics,12:55–67,1970.
ArunIyer,SakethaNath,andSunitaSarawagi. Maximummeandiscrepancyforclassratioestimation:
Convergence bounds and kernel selection. In International Conference on Machine Learning,
2014.
AlanE.Jones,StephenTrzeciak,andJeffreyA.Kline. Thesequentialorganfailureassessmentscore
forpredictingoutcomeinpatientswithseveresepsisandevidenceofhypoperfusionatthetimeof
emergencydepartmentpresentation. CriticalCareMedicine,37:1649,2009.
Wouter M. Kouw and Marco Loog. A review of domain adaptation without target labels. IEEE
TransactionsonPatternAnalysisandMachineIntelligence,43:766–785,2021.
RainerKress. LinearIntegralEquations. Springer,1999.
ZacharyC.Lipton,Yu-XiangWang,andAlexanderJ.Smola. Detectingandcorrectingforlabelshift
withblackboxpredictors. InInternationalConferenceonMachineLearning,2018.
WhitneyK.NeweyandJamesL.Powell. Instrumentalvariableestimationofnonparametricmodels.
Econometrica,71:1565–1578,2003.
TuanDuongNguyen,MarthinusChristoffel,andMasashiSugiyama. Continuoustargetshiftadapta-
tioninsupervisedlearning. InAsianConferenceonMachineLearning,2016.
10PublishedasaconferencepaperatICLR2024
AleksandrPodkopaevandAadityaRamdas. Distribution-freeuncertaintyquantificationforclassifi-
cationunderlabelshift. InConferenceonUncertaintyinArtificialIntelligence,2021.
JoaquinQuinonero-Candela,MasashiSugiyama,AntonSchwaighofer,andNeilDLawrence.Dataset
shiftinmachinelearning. MITPress,2008.
MarcoSaerens,PatriceLatinne,andChristineDecaestecker. Adjustingtheoutputsofaclassifierto
newaprioriprobabilities: asimpleprocedure. NeuralComputation,14:21–41,2002.
BernhardSchölkopf,DominikJanzing,JonasPeters,EleniSgouritsa,KunZhang,andJorisMooij.
Oncausalandanticausallearning. InInternationalConferenceonMachineLearning,2012.
AmosStorkey. Whentrainingandtestsetsaredifferent: Characterizinglearningtransfer. InDataset
ShiftinMachineLearning.MITPress,2009.
MasashiSugiyama,TaijiSuzuki,andTakafumiKanamori. DensityRatioEstimationinMachine
Learning. CambridgeUniversityPress,2012.
DirkTasche. Fisherconsistencyforpriorprobabilityshift. JournalofMachineLearningResearch,
18:3338–3369,2017.
QinglongTian,XinZhang,andJiweiZhao. ELSA:Efficientlabelshiftadaptationthroughthelens
ofsemiparametricmodels. InInternationalConferenceonMachineLearning,2023.
KunZhang,BernhardSchölkopf,KrikamolMuandet,andZhikunWang. Domainadaptationunder
targetandconditionalshift. InInternationalConferenceonMachineLearning,2013.
KaiyangZhou,ZiweiLiu,YuQiao,TaoXiang,andChenChangeLoy. Domaingeneralization: A
survey. IEEETransactionsonPatternAnalysisandMachineIntelligence,45:4396–4415,2023.
11