[
    {
        "title": "From Mobilisation to Radicalisation: Probing the Persistence and Radicalisation of Social Movements Using an Agent-Based Model",
        "authors": "Emma F. ThomasMengbin YeSimon D. AngusTony J. MathewWinnifred LouisLiam WalshSilas ElleryMorgana Lizzio-WilsonCraig McGarty",
        "links": "http://arxiv.org/abs/2408.12795v1",
        "entry_id": "http://arxiv.org/abs/2408.12795v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12795v1",
        "summary": "We are living in an age of protest. Although we have an excellent\nunderstanding of the factors that predict participation in protest, we\nunderstand little about the conditions that foster a sustained (versus\ntransient) movement. How do interactions between supporters and authorities\ncombine to influence whether and how people engage (i.e., using conventional or\nradical tactics)? This paper introduces a novel, theoretically-founded and\nempirically-informed agent-based model (DIMESim) to address these questions. We\nmodel the complex interactions between the psychological attributes of the\nprotester (agents), the authority to whom the protests are targeted, and the\nenvironment that allows protesters to coordinate with each other -- over time,\nand at a population scale. Where an authority is responsive and failure is\ncontested, a modest sized conventional movement endured. Where authorities\nrepeatedly and incontrovertibly fail the movement, the population disengaged\nfrom action but evidenced an ongoing commitment to radicalism (latent\nradicalism).",
        "updated": "2024-08-23 02:18:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12795v1"
    },
    {
        "title": "MEDCO: Medical Education Copilots Based on A Multi-Agent Framework",
        "authors": "Hao WeiJianing QiuHaibao YuWu Yuan",
        "links": "http://arxiv.org/abs/2408.12496v1",
        "entry_id": "http://arxiv.org/abs/2408.12496v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12496v1",
        "summary": "Large language models (LLMs) have had a significant impact on diverse\nresearch domains, including medicine and healthcare. However, the potential of\nLLMs as copilots in medical education remains underexplored. Current\nAI-assisted educational tools are limited by their solitary learning approach\nand inability to simulate the multi-disciplinary and interactive nature of\nactual medical training. To address these limitations, we propose MEDCO\n(Medical EDucation COpilots), a novel multi-agent-based copilot system\nspecially developed to emulate real-world medical training environments. MEDCO\nincorporates three primary agents: an agentic patient, an expert doctor, and a\nradiologist, facilitating a multi-modal and interactive learning environment.\nOur framework emphasizes the learning of proficient question-asking skills,\nmulti-disciplinary collaboration, and peer discussions between students. Our\nexperiments show that simulated virtual students who underwent training with\nMEDCO not only achieved substantial performance enhancements comparable to\nthose of advanced models, but also demonstrated human-like learning behaviors\nand improvements, coupled with an increase in the number of learning samples.\nThis work contributes to medical education by introducing a copilot that\nimplements an interactive and collaborative learning approach. It also provides\nvaluable insights into the effectiveness of AI-integrated training paradigms.",
        "updated": "2024-08-22 15:41:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12496v1"
    },
    {
        "title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards",
        "authors": "Shresth VermaNiclas BoehmerLingkai KongMilind Tambe",
        "links": "http://arxiv.org/abs/2408.12112v1",
        "entry_id": "http://arxiv.org/abs/2408.12112v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12112v1",
        "summary": "LLMs are increasingly used to design reward functions based on human\npreferences in Reinforcement Learning (RL). We focus on LLM-designed rewards\nfor Restless Multi-Armed Bandits, a framework for allocating limited resources\namong agents. In applications such as public health, this approach empowers\ngrassroots health workers to tailor automated allocation decisions to community\nneeds. In the presence of multiple agents, altering the reward function based\non human preferences can impact subpopulations very differently, leading to\ncomplex tradeoffs and a multi-objective resource allocation problem. We are the\nfirst to present a principled method termed Social Choice Language Model for\ndealing with these tradeoffs for LLM-designed rewards for multiagent planners\nin general and restless bandits in particular. The novel part of our model is a\ntransparent and configurable selection component, called an adjudicator,\nexternal to the LLM that controls complex tradeoffs via a user-selected social\nwelfare function. Our experiments demonstrate that our model reliably selects\nmore effective, aligned, and balanced reward functions compared to purely\nLLM-based approaches.",
        "updated": "2024-08-22 03:54:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12112v1"
    },
    {
        "title": "Empirical Equilibria in Agent-based Economic systems with Learning agents",
        "authors": "Kshama DwarakanathSvitlana VyetrenkoTucker Balch",
        "links": "http://arxiv.org/abs/2408.12038v1",
        "entry_id": "http://arxiv.org/abs/2408.12038v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12038v1",
        "summary": "We present an agent-based simulator for economic systems with heterogeneous\nhouseholds, firms, central bank, and government agents. These agents interact\nto define production, consumption, and monetary flow. Each agent type has\ndistinct objectives, such as households seeking utility from consumption and\nthe central bank targeting inflation and production. We define this multi-agent\neconomic system using an OpenAI Gym-style environment, enabling agents to\noptimize their objectives through reinforcement learning. Standard multi-agent\nreinforcement learning (MARL) schemes, like independent learning, enable agents\nto learn concurrently but do not address whether the resulting strategies are\nat equilibrium. This study integrates the Policy Space Response Oracle (PSRO)\nalgorithm, which has shown superior performance over independent MARL in games\nwith homogeneous agents, with economic agent-based modeling. We use PSRO to\ndevelop agent policies approximating Nash equilibria of the empirical economic\ngame, thereby linking to economic equilibria. Our results demonstrate that PSRO\nstrategies achieve lower regret values than independent MARL strategies in our\neconomic system with four agent types. This work aims to bridge artificial\nintelligence, economics, and empirical game theory towards future research.",
        "updated": "2024-08-21 23:47:46 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12038v1"
    },
    {
        "title": "VIRIS: Simulating indoor airborne transmission combining architectural design and people movement",
        "authors": "Yidan XueWassim JabiThomas E. WoolleyKaterina Kaouri",
        "links": "http://arxiv.org/abs/2408.11772v1",
        "entry_id": "http://arxiv.org/abs/2408.11772v1",
        "pdf_url": "http://arxiv.org/pdf/2408.11772v1",
        "summary": "A Viral Infection Risk Indoor Simulator (VIRIS) has been developed to quickly\nassess and compare mitigations for airborne disease spread. This agent-based\nsimulator combines people movement in an indoor space, viral transmission\nmodelling and detailed architectural design, and it is powered by topologicpy,\nan open-source Python library. VIRIS generates very fast predictions of the\nviral concentration and the spatiotemporal infection risk for individuals as\nthey move through a given space. The simulator is validated with data from a\ncourtroom superspreader event. A sensitivity study for unknown parameter values\nis also performed. We compare several non-pharmaceutical interventions (NPIs)\nissued in UK government guidance, for two indoor settings: a care home and a\nsupermarket. Additionally, we have developed the user-friendly VIRIS web app\nthat allows quick exploration of diverse scenarios of interest and\nvisualisation, allowing policymakers, architects and space managers to easily\ndesign or assess infection risk in an indoor space.",
        "updated": "2024-08-21 16:54:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.11772v1"
    }
]