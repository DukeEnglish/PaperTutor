[
    {
        "title": "How Diffusion Models Learn to Factorize and Compose",
        "authors": "Qiyao LiangZiming LiuMitchell OstrowIla Fiete",
        "links": "http://arxiv.org/abs/2408.13256v1",
        "entry_id": "http://arxiv.org/abs/2408.13256v1",
        "pdf_url": "http://arxiv.org/pdf/2408.13256v1",
        "summary": "Diffusion models are capable of generating photo-realistic images that\ncombine elements which likely do not appear together in the training set,\ndemonstrating the ability to compositionally generalize. Nonetheless, the\nprecise mechanism of compositionality and how it is acquired through training\nremains elusive. Inspired by cognitive neuroscientific approaches, we consider\na highly reduced setting to examine whether and when diffusion models learn\nsemantically meaningful and factorized representations of composable features.\nWe performed extensive controlled experiments on conditional Denoising\nDiffusion Probabilistic Models (DDPMs) trained to generate various forms of 2D\nGaussian data. We found that the models learn factorized but not fully\ncontinuous manifold representations for encoding continuous features of\nvariation underlying the data. With such representations, models demonstrate\nsuperior feature compositionality but limited ability to interpolate over\nunseen values of a given feature. Our experimental results further demonstrate\nthat diffusion models can attain compositionality with few compositional\nexamples, suggesting a more efficient way to train DDPMs. Finally, we connect\nmanifold formation in diffusion models to percolation theory in physics,\noffering insight into the sudden onset of factorized representation learning.\nOur thorough toy experiments thus contribute a deeper understanding of how\ndiffusion models capture compositional structure in data.",
        "updated": "2024-08-23 17:59:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.13256v1"
    },
    {
        "title": "Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder",
        "authors": "Marie HuynhAaron KlineSaimourya SurabhiKaitlyn DunlapOnur Cezmi MutluMohammadmahdi HonarmandParnian AzizianPeter WashingtonDennis P. Wall",
        "links": "http://arxiv.org/abs/2408.13255v1",
        "entry_id": "http://arxiv.org/abs/2408.13255v1",
        "pdf_url": "http://arxiv.org/pdf/2408.13255v1",
        "summary": "Early detection of autism, a neurodevelopmental disorder marked by social\ncommunication challenges, is crucial for timely intervention. Recent\nadvancements have utilized naturalistic home videos captured via the mobile\napplication GuessWhat. Through interactive games played between children and\ntheir guardians, GuessWhat has amassed over 3,000 structured videos from 382\nchildren, both diagnosed with and without Autism Spectrum Disorder (ASD). This\ncollection provides a robust dataset for training computer vision models to\ndetect ASD-related phenotypic markers, including variations in emotional\nexpression, eye contact, and head movements. We have developed a protocol to\ncurate high-quality videos from this dataset, forming a comprehensive training\nset. Utilizing this set, we trained individual LSTM-based models using eye\ngaze, head positions, and facial landmarks as input features, achieving test\nAUCs of 86%, 67%, and 78%, respectively. To boost diagnostic accuracy, we\napplied late fusion techniques to create ensemble models, improving the overall\nAUC to 90%. This approach also yielded more equitable results across different\ngenders and age groups. Our methodology offers a significant step forward in\nthe early detection of ASD by potentially reducing the reliance on subjective\nassessments and making early identification more accessibly and equitable.",
        "updated": "2024-08-23 17:55:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.13255v1"
    },
    {
        "title": "Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption",
        "authors": "Sakhinana Sagar SrinivasChidaksh RavuruGeethan SannidhiVenkataramana Runkana",
        "links": "http://arxiv.org/abs/2408.13248v1",
        "entry_id": "http://arxiv.org/abs/2408.13248v1",
        "pdf_url": "http://arxiv.org/pdf/2408.13248v1",
        "summary": "Semiconductor imaging and analysis are critical yet understudied in deep\nlearning, limiting our ability for precise control and optimization in\nsemiconductor manufacturing. We introduce a small-scale multimodal framework\nfor analyzing semiconductor electron microscopy images (MAEMI) through\nvision-language instruction tuning. We generate a customized\ninstruction-following dataset using large multimodal models on microscopic\nimage analysis. We perform knowledge transfer from larger to smaller models\nthrough knowledge distillation, resulting in improved accuracy of smaller\nmodels on visual question answering (VQA) tasks. This approach eliminates the\nneed for expensive, human expert-annotated datasets for microscopic image\nanalysis tasks. Enterprises can further finetune MAEMI on their intellectual\ndata, enhancing privacy and performance on low-cost consumer hardware. Our\nexperiments show that MAEMI outperforms traditional methods, adapts to data\ndistribution shifts, and supports high-throughput screening.",
        "updated": "2024-08-23 17:42:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.13248v1"
    },
    {
        "title": "Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs",
        "authors": "Evin JaffYuhao WuNing ZhangUmar Iqbal",
        "links": "http://arxiv.org/abs/2408.13247v1",
        "entry_id": "http://arxiv.org/abs/2408.13247v1",
        "pdf_url": "http://arxiv.org/pdf/2408.13247v1",
        "summary": "LLM app ecosystems are quickly maturing and supporting a wide range of use\ncases, which requires them to collect excessive user data. Given that the LLM\napps are developed by third-parties and that anecdotal evidence suggests LLM\nplatforms currently do not strictly enforce their policies, user data shared\nwith arbitrary third-parties poses a significant privacy risk. In this paper we\naim to bring transparency in data practices of LLM apps. As a case study, we\nstudy OpenAI's GPT app ecosystem. We develop an LLM-based framework to conduct\nthe static analysis of natural language-based source code of GPTs and their\nActions (external services) to characterize their data collection practices.\nOur findings indicate that Actions collect expansive data about users,\nincluding sensitive information prohibited by OpenAI, such as passwords. We\nfind that some Actions, including related to advertising and analytics, are\nembedded in multiple GPTs, which allow them to track user activities across\nGPTs. Additionally, co-occurrence of Actions exposes as much as 9.5x more data\nto them, than it is exposed to individual Actions. Lastly, we develop an\nLLM-based privacy policy analysis framework to automatically check the\nconsistency of data collection by Actions with disclosures in their privacy\npolicies. Our measurements indicate that the disclosures for most of the\ncollected data types are omitted in privacy policies, with only 5.8% of Actions\nclearly disclosing their data collection practices.",
        "updated": "2024-08-23 17:42:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.13247v1"
    },
    {
        "title": "JacNet: Learning Functions with Structured Jacobians",
        "authors": "Jonathan LorraineSafwan Hossain",
        "links": "http://arxiv.org/abs/2408.13237v1",
        "entry_id": "http://arxiv.org/abs/2408.13237v1",
        "pdf_url": "http://arxiv.org/pdf/2408.13237v1",
        "summary": "Neural networks are trained to learn an approximate mapping from an input\ndomain to a target domain. Incorporating prior knowledge about true mappings is\ncritical to learning a useful approximation. With current architectures, it is\nchallenging to enforce structure on the derivatives of the input-output\nmapping. We propose to use a neural network to directly learn the Jacobian of\nthe input-output function, which allows easy control of the derivative. We\nfocus on structuring the derivative to allow invertibility and also demonstrate\nthat other useful priors, such as $k$-Lipschitz, can be enforced. Using this\napproach, we can learn approximations to simple functions that are guaranteed\nto be invertible and easily compute the inverse. We also show similar results\nfor 1-Lipschitz functions.",
        "updated": "2024-08-23 17:21:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.13237v1"
    }
]