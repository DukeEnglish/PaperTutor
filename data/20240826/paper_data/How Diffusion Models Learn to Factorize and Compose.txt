How Diffusion Models Learn to Factorize and
Compose
QiyaoLiang ZimingLiu MitchellOstrow IlaFiete
MassachusettsInstituteofTechnology
{qiyao,zmliu,ostrow,fiete}@mit.edu
Abstract
Diffusionmodelsarecapableofgeneratingphoto-realisticimagesthatcombine
elementswhichlikelydonotappeartogetherinthetrainingset, demonstrating
theabilitytocompositionallygeneralize. Nonetheless,theprecisemechanismof
compositionalityandhowitisacquiredthroughtrainingremainselusive. Inspired
by cognitive neuroscientific approaches, we consider a highly reduced setting
to examine whether and when diffusion models learn semantically meaningful
andfactorizedrepresentationsofcomposablefeatures. Weperformedextensive
controlledexperimentsonconditionalDenoisingDiffusionProbabilisticModels
(DDPMs)trainedtogeneratevariousformsof2DGaussiandata. Wefoundthat
the models learn factorized but not fully continuous manifold representations
for encoding continuous features of variation underlying the data. With such
representations,modelsdemonstratesuperiorfeaturecompositionalitybutlimited
abilitytointerpolateoverunseenvaluesofagivenfeature.Ourexperimentalresults
further demonstrate that diffusion models can attain compositionality with few
compositionalexamples,suggestingamoreefficientwaytotrainDDPMs. Finally,
weconnectmanifoldformationindiffusionmodelstopercolationtheoryinphysics,
offeringinsightintothesuddenonsetoffactorizedrepresentationlearning. Our
thoroughtoyexperimentsthuscontributeadeeperunderstandingofhowdiffusion
modelscapturecompositionalstructureindata.
1 Introduction
Large-scaletext-to-imagegenerativemodelscanproducephoto-realisticsyntheticimagesthatcom-
bineelementsinanovelfashion(compositionalgeneralization). Nonetheless,theabilityofmodelsto
doso,aswellastheirfailuremodes,arenotwell-studiedsystematicallyinlargediffusionmodels
duetothesizeofthemodelandthecomplexandhigh-dimensionalnatureoftheirtrainingdatasets.
Factorizationandcompositionalgeneralizationhavebeentheoreticallyandempiricallyinvestigated
inmanydeepgenerativemodelsbeforeZhaoetal.[2018],Higginsetal.[2017],Burgessetal.[2018],
Monteroetal.[2021],Xuetal.[2022],Okawaetal.[2023],Wiedemeretal.[2023],Bowersetal.
[2016],Chaabounietal.[2020]. However,thesestudieshavenotreachedaunanimousconclusion
onwhetherfactorizedrepresentationslearnedintheintermediatelayersofthemodelpromotecom-
positionalgeneralizationinthemodelperformance. Specifically,severalstudiesXuetal.[2022],
Monteroetal.[2021],Chaabounietal.[2020]havefoundlittlecorrelationbetweenfactorizationand
compositionality,contrarytoothersthatsuggestthatfactorizationpromotescompositionalityBengio
etal.[2013],Higginsetal.[2017],Burgessetal.[2018],Duanetal.[2020],Bowersetal.[2016].
As a result, there is no consensus on the exact mechanism of compositionality and how models
gaintheabilitytocompositionallygeneralize. However,thesepreviousstudiesinvolvedatawitha
complexmixofdiscreteandcontinuouslyvaryingfeatures,makingitdifficulttoexplicitlyanalyze
themodel’slearnedrepresentationsbeyondthedisentanglementscore,andtherebyhinderingadeeper
understandingoffactorizationandcompositionality.
Preprint.Underreview.
4202
guA
32
]IA.sc[
1v65231.8042:viXraDespitetheremarkablecompositionalabilitiesdemonstratedbydiffusion-basedtext-to-imagegen-
erativemodels,explicitexplorationoffactorizationandcompositionalgeneralizationofdiffusion
modelshasbeenrelativelylimited. Inarecentempiricalstudyoftoydiffusionmodels,Okawaet.
al.Okawaetal.[2023]showsthatdiffusionmodelslearntocompositionallygeneralizemultiplica-
tively. Theytoo,however,didnotfocusonthemechanisticaspectofcompositionalgeneralization
withinthemodeloranalyzetherepresentationslearnedbythemodels. Toinvestigatefactorization
andcompositionalityindiffusionmodels,weconductextensiveexperimentsonconditionaldenoising
diffusionprobablisticmodels(DDPMs)Hoetal.[2020]trainedwithvarious2DGaussiandatasets
tocharacterizetheirlearnedrepresentationsandgeneralizationperformance.1 Drawinginspiration
fromtraditionalcognitivepsychologyandneurosciencestudiesonanimalsandhumans,wedesign
straightforwardcognitivetasksformodelstoperformwhileanalyzingboththeirgenerationoutput
(“behavior”)andtheirintermediatelayerrepresentations(“neuralactivities”). Specifically,weevalu-
atethediffusionmodel’sabilitytogeneralizebygenerating2DGaussianbumpscenteredatspecified
x,ycoordinatesonafinitecanvas. Wedeliberatelychosealow-dimensionaldatasetandasimplified
experimentalsetuptoenableaclearanalysisofhowthemodel’srepresentationfactorizationrelates
toitsgeneralizationcapabilities.
Conceptually,themodelscanadoptdifferentparameterizationsofthex,ycoordinatesfortheGaus-
sianbumps,eachwithvaryingimplicationsfordataefficiency. ConsideraK-dimensionaldataset
createdfromthecompositionofmultipleindependentlyvarying1-dimensional(1D)latentfeatures
(e.g. a factorizable data distribution P(x ,x ,...,x ) = P(x )P(x )...P(x )). Hypotheti-
1 2 K 1 2 K
cally, a model may learn either a joint representation of all K dimensions P(x ,x ,...,x ) ̸=
1 2 K
P(x )P(x )...P(x ) or learn independent 1D representations P(x )P(x )...P(x ). In the
1 2 K 1 2 K
formercase,iftherewereN statesperdimension,themodelwouldneedtoseeapproximatelyNK
samplesduringtraining. Ifthemodelcouldsomehowrecognizetheindependenceofthedifferent
factors,asfewasKN trainingsamplesmightsuffice. Wetermtheformeracoupledrepresentation,
whilethelatterisafactorizedone. Factorizedrepresentationscouldbefarmoresampleefficientto
learn,potentiallypermittingbettergeneralization,andaremorerobustandadaptablefordownstream
applications.Inbiologicalneuralnetworks,featuresofindependentvariationaretypicallyrepresented
inafactorizedmanner. Forinstance,primatesencodeallocentricposeinformationinafactorized
fashion,leveraginggridcellsfortwo-dimensionallocationandheaddirectioncellsfororientation
LindseyandIssa[2023],MoserEI[2008],Haftingetal.[2005b],Chaudhurietal.[2019],Taube
etal.[1990],Taube[2007],Haftingetal.[2005a],Stensolaetal.[2012],BurakandFiete[2009].
Further,spatialinformationaboutobjectsintheenvironmentisfactorizedintoplacecellsandother
spatialcodingcellsMoseretal.[2015],MoserEI[2008].
Across three related studies, we investigate how diffusion models learn to encode independent
featuresofthedataset,howthatinformsthemodel’sabilitytogeneralizeout-of-training-distribution
in terms of composition and interpolation, and how variations in the training data could impact
suchgeneralization. Tobeprecise,herewedefinecompositionalityastheabilitytogeneratenovel
combinations of feature values that are not observed during training (e.g., given {(a,b),(c,d)},
output{(a,d),(c,b)}). Wedefineinterpolationastheabilitytolinearlycombinedifferentfeature
values (e.g., output x = 16 given x = 15 and x = 17). The failure of the model to perform the
designedtaskscouldbeduetoitsinabilitytohandlecomposition,interpolation,oracombinationof
both. Wetrainthemodelon2DGaussiandataand,insomecases,explicitlyinclude1DGaussian
stripeswithspecifiedx,ypositionsthatcanbecombinedtoformthedesired2DGaussian. Wethen
posethefollowingquestions:
1. Dodiffusionmodelslearnfactorizedrepresentations? Ifso, whendotheseemergeover
training?
2. Dothetrainedmodelslearntogeneralizebeyondthetrainingdistribution,andwhatkindof
trainingdataissufficientforthisgeneralization?
3. Doestheinclusionofafewexplicitlyfactorizedexamplesintraining(e.g. the1DGaussian
data)improvesampleefficiencyandgeneralization?
Contributions. Inthreeexperiments,wefindthat:
1ApreliminaryversionofthisworkwaspresentedattheME-FoMoandBGPTworkshopsatICLR2024
Liangetal.[2024].
21. Givenfactorized,continuousconditionalinputs,diffusionmodelslearn“hyper-factorized”
representationsthatareorthogonalnotonlyforindependentfeaturesbutalsodifferentvalues
ofthesamefeature(Section3.1).
2. Modelscomposewellbutinterpolatepoorly. Modelscancompositionallygeneralizewhen
theyobservethefullextentofeachindependentlatentfeaturealongwithafewcompositional
examples(Section3.2).
3. Modelstrainedondatasetscontainingisolatedfactorsofvariationrequireanexceptionally
smallnumberofcompositionalexamplestocompositionallygeneralize,showingremarkable
dataefficiency(Section3.2).
4. Formationofafactorizedrepresentationforeachcontinuousdimensionofvariationrequires
athresholdamountofcorrelateddata,relatedtopercolationtheoryinphysics(Section3.3).
Ourresultssuggestthatdiffusionmodelscanlearnfactorized,thoughnotfullycontinuous,represen-
tationsofcontinuousfeatureswithindependentvariations. Thesemodelsdemonstrateexceptional
compositionalitybuthavelimitedinterpolationability,evenwithsufficienttraininganddata. Our
analysisoffersdeeperdiagnosticinsightsintothemechanismoffactorizationandcompositionality
ofdiffusionmodelsfromamicroscopicrepresentationperspective. Moreover,ourinsightsonthe
dataefficiencyoftrainingwithisolatedfactorsofvariationwithfewcompositionalexamplessuggest
thepossibilityoffarmoredataefficientmethodsoftrainingdiffusionmodels.
2 Methods
Dataset. We generate N ×N pixel grayscale images. By
default,wesetN =32unlessotherwisespecified. Eachimage
containsone2DGaussianbump(“blob”),themultiplicationof 2D Gaussian Bump 2D Gaussian SOS
averticalandahorizontal1DGaussianstripe,orone2DGaus-
sianaddition,thesumofaverticalandahorizontal1DGaussian σx σx
stripe(“sumofstripes(SOS’s)”),atvariousx,ylocations. The y σy{ μy y σy{ μy
brightnessv ofthepixelatposition(x,y)fora2DGaus-
(x,y) μx μx
sianblobcenteredat(µ ,µ )withstandarddeviation(σ ,σ )
x y x y
isgivenasvbump = 255×(1−e−(x−µx)2/4σ x2−(y−µy)2/4σ y2 ) x x
(x,y)
andasvSOS =255×[1−1(e−(x−µx)2/4σ x2+e−(y−µy)2/4σ y2 )] Figure1: Example32×32image
(x,y) 2
fora2DGaussianSOSwiththenormalizedrangeofv to dataofa2DGaussianbump(left)
(x,y)
anda2DGaussianSOS(right).
be[0,255]. Eachimageisgeneratedwithagroundtruthlabel
of(µ ,µ ),whichcontinuouslyvarywithin[0,N]2unlessoth-
x y
erwisespecified. Inourconventionofnotation,welabelthe
topleftcorneroftheimageas(1,1)whilethebottomrightcorneroftheimageas(N,N). Sample
32×32imagesof2DGaussianbumpandSOScenteredatµ = µ = 16withσ = σ = 1are
x y x y
showninFig.1.
AsingledatasetoftheseimagesconsistoftheenumerationofallpossibleGaussianstilingthewhole
N ×N canvasatincrementd inthex-directionandd inthey-direction. Alargerd ord means
x y x y
asparsertilingoftheimagespaceandfewerdatawhileasmallerd ord resultinmoredatawith
x y
denser tiling of the total image space. Moreover, each 2D Gaussian have independent spread in
thexandy directiongivenbyσ andσ ,withalargerspreadleadingtomorespatialoverlapof
x y
neighboringGaussiansandasmallerspreadlessoverlap. Byparametericallytuningtheincrements
d andd andthespreadσ andσ ,wecangeneratedatasetsofvarioussparsitiesandoverlaps. We
x y x y
provideamoredetailedanalysisofthevariousattributesofthedatabasedontheseparametersin
AppendixA.5. ForthemajorityoftheexperimentalresultsweshowinSec.3,wehavechosentofix
σ :=σ =σ =1.0andd:=d =d =0.1unlessotherwisespecified. Adefault32×32dataset
x y x y
ofd=0.1contains102400images.
Models&Evaluations. WetrainaconditionalDDPM[Hoetal.,2020,Chenetal.,2021,Saharia
etal.,2023]withastandardUNetarchitectureasshowninAppendixFig.7. Foreachimageinthe
trainingdataset,weprovideanexplicitgroundtruthlabel(µ ,µ )asaninputtothenetwork. For
x y
reference,weinvestigatetheinternalrepresentationlearnedbythemodelusingtheoutputoflayer
4 as labeled in Fig. 7. Since each dataset has inherently two latent dimensions, x and y, we use
dimensionreductiontoolssuchasPCAorUMAPMcInnesandHealy[2018]toreducetheinternal
3
{ {representationofthemodeltoa2D/3Dembeddingfortheeaseofvisualizationandanalysis. We
deferthedetailsofmodelarchitecture,dimensionreduction,andexperimentationtoAppendixA.1
and A.2. Briefly,weassesstheperformanceofthemodelbasedontheaccuracyofitsgenerated
imagesatcorrectlydisplayingthecenterlocationofthe2DGaussian. Furtherdetailsontheprecise
definitionoftheaccuracymetriccanbefoundinAppendixA.3.
3 Results
3.1 Modelslearnfactorizedbutnotfullycontinuousrepresentations
In this section, we aim to understand the factorization of the model’s learned representation via
explicit inspection of its topology and geometry. Given a conditional DDPM trained on the 2D
Gaussianbumpdatasetdescribedabove,wefirstinvestigatewhetherthemodellearnsacoupledor
factorizedrepresentation. Naïvely,a2DGaussiandatasetwithtwoindependentfeaturesofvariation,
x and y, has a 2D plane-like latent representation. Unfortunately, simply inspecting the learned
representation would not allow us to easily differentiate between a coupled versus a factorized
representationsincetheCartesianproductoftwolinesL1 ×L1 ⊂ R×R = R2 istopologically
andgeometricallyequivalenttoaplaneP2 ⊂ R2. Toovercomethisissue, weperformasimple
modificationtotheGaussiandataset. Weimposeperiodicboundaryconditionsintheimagespaceto
connecttheleft-rightandtop-bottomboundariesoftheimagesuchthatthelatentrepresentationof
thedatasetformsatorus. Mathematically,atorusisdefinedbytheCartesianproductoftwocircles
S1×S1. ACliffordTorusisanexampleofafactorizedrepresentationofthetorus,witheachcircle
independentlyembeddedinR2, resultingina4-dimensionalobject. However, themostefficient
representationintermsofextrinsicdimensionalityistheregulartorusT2,whichisembeddedin
R3, albeit unfactorized. Various 2D projections of the 3D torus and the Clifford (4D) torus are
showninFig.2(a). DuetogeometricdifferencesbetweentheCliffordandthe3Dtorus,wecannow
distinguishwhetherthemodellearnsafactorizedrepresentation. Ifthemodelweretorepresentxand
yindependentlywithtworingmanifolds,weexpecttoseeaCliffordtorusintheneuralactivations,
ratherthanadifferentgeometrysuchasthe3Dtorus.
Toapplythegeometrytestsfordifferentiatingbetweenthe3DandtheCliffordtorus,wefirstneed
to confirm that the model indeed learns a torus representation of the dataset by computing the
topologicalfeaturesofthelearnedrepresentationviapersistenthomology. InFig.2(b),wecompare
thepersistencediagramsofastandardtorus(left)withthefinallearnedrepresentationofthemodel
(right). Bothdiagramsexhibitthesimilartopologicalfeatures,rank-1H group,rank-2H group
0 1
(withoverlappingorangepointsontopinbothdiagrams),andrank-1H group,signalingthatthe
2
modelindeedlearnsatorusrepresentation.
Wetheninvestigatewhenthistorusrepresentationemergesduringtraining. InFig.2(c),weshowthe
model’sperformanceasmeasuredbytheaccuracyofitsgeneratedimages(top)andthecorresponding
effectivedimension(bottom)ofthelearnedrepresentationsacrosstraining,asmeasuredbythepartic-
ipationratio(givenby((cid:80) λ )2/(cid:80) λ2,whereλ istheeigenvalueofthei-thprincipalcomponent
i i i i i
Gaoetal.[2017]). Intuitively,theparticipationratiocountsthedominanteigen-components,provid-
ingameasureoftheeffectivedimensionofthegeometricobjectofinterest. Adetailedinspectionof
theeffectivedimensionofthelearnedrepresentationsoverthetrainingdurationinformsusofwhether
andhowthemodelarrivesatafactorized,4Drepresentation. WeseeinFig.2(c)thatastraining
progresses,themodel’sinternalrepresentationfirstundergoesadimensionincreasethenadecrease,
eventuallyconvergingtoaround7dimensionsafter200epochs. Whilethedimensionalityconverged
toahigherdimensionthan4,thetop4eigenvectorsbecamenotablymoreprominentasthetraining
converges,asindicatedintheeigenspectrainFig.2(d). Thissignalsthata4D,ratherthan3D,torus
representationiseventuallylearned. VariousPCAprojectionsofthelearnedrepresentationsalongthe
trainingprocessareshowninFig.2(g)-(i),wheretheprojectionsinthelastepochresemblesthoseof
theCliffordtorusshownin(a).
ToconfirmwhetherthemodellearnsaCliffordtorus,weemploytheorthogonalityandparallelism
testsoftoriCuevaetal.[2021b](detailsfoundinAppendixB).InanidealCliffordtorus,therings
along the poloidal direction should be parallel with each other, and similarly for those along the
toroidaldirection. Moreover,theringsalongthepoloidaldirectionshouldbeorthogonalwithrespect
totheringsinthetoroidaldirection.Theorthogonalityandparallelismtestsmeasuretheorthogonality
andparallelismofsubspacesspannedbyvariousringsonthetorus. IfthemodellearnsaClifford
4Figure2:Metricsofamodeltrainedusing2DGaussianbumpdatasetswithperiodicboundaries.
(a)2Dprojectionsofastandard3Dtorus(left)anda4DCliffordtorus(right). The3Dtorusisan
exampleofacoupledrepresentationthatcanbelearnedbythemodelwhilethe4Dtorusisafactorized
one. (b)Persistencediagramsofastandardtorus(left,thediagramlooksthesameforCliffordtori)
andthelearnedrepresentationofthemodelattheterminalepoch(right). Therearetwooverlapping
orangepointsforH inbothdiagrams. (c)Modelaccuracy(top)andeffectivedimension(bottom)of
1
representationlearnedbythemodelasafunctionoftrainingepochs. (d)PCAeigenspectrum(the
first15dimensions)ofthemodel’slearnedrepresentationsandtheircorrespondingsampleaccuracy
percentageandexplainedvarianceratioofthetop4PCs(labeledtoprightofeachpanel)atvarious
checkpointsduringtraining. (e)-(g)PCAvisualizationsofthelearnedrepresentationsatepoch0,150,
andterminalepoch,respectively.
torusrepresentation,thesubspacesthatcodeforxandyshouldbeorthogonal,andthesubspaces
that code for x (y) for any given y (x) should be equivalent (parallel). Given a pair of x and y,
weconstruct2DsubspacesofringsS(fixx)andS(fixy)spannedbyfixingxwhilevaryingyand
fixingywhilevaryingx,respectively. Weperform3setsoftests: 1)x-on-yteststestorthogonality
andparallelismbetweensurfacesS(fixx)andS(fixy)forallcombinationsofxandy;2)x-on-x
tests test orthogonality and parallelism between S(fixx ) and S(fixx ) for all combinations of
1 2
differentx’s;3)y-on-yteststestorthogonalityandparallelismbetweenS(fixy )andS(fixy )for
1 2
allcombinationsofdifferenty’s.
InFig.3, wecomparetheorthogonalityandparallelismteststatisticsbetweenanideal3Dtorus
(left), the model’s learned representation at the final epoch (center), and an ideal Clifford torus
(right). Comparing test 1 statistics (top row) between the model representation and the standard
3DandCliffordtori,weseethatthemodelencodesxandy independentlyinmostlyorthogonal
subspaces, similartoaCliffordtorus. Thetest2and3statistics(middleandbottomrow)ofthe
modelrepresentation,however,doesnotmatchthoseofeitherthe3DortheCliffordtorus. Infact,the
statisticsfromtests2and3ofthemodelrepresentationcloselyresemblethosefromtest1ofthe3D
torus.Thismeansthatthemodelisencodingdifferentvaluesofxinanalmostorthogonal,asopposed
toparallel,fashion,similarlyfordifferentvaluesofy. Theseobservationssignifythatthemodels
“hyper-factorizes”eachindividualfactorofvariationbytreatingthemmoresimilarlytocategorical
variableswithnonzerooverlapsbetweenneighboringcategoriesratherthanfully-continuousvariables,
whichexplainswhytheeffectivedimensionofthemodel’slearnedrepresentationishigherthan4
afterconvergenceinFig.2(c). Althoughtheseobservationsaremadefromamodeltrainedonatorus
dataset,weexpectthemodeltohavesimilarencodingschemesacrossallvariantsofourGaussian
bumpdatasets.
5(a) (b) (c)
Learned Representation
3D Torus Clifford Torus
at Terminal Epoch
Figure3: Comparisonoforthogonalityandparallelismteststatisticsbetween3Dtorus,model’s
learnedrepresentation,andCliffordtorus. x-on-y(toprow),x-on-x(middlerow),y-on-y(bottom
row)orthogonality(leftcolumn)andparallelism(rightcolumn)teststatisticsarecomparedbetween
(a)anideal3Dtorus(blue),(b)thelearnedrepresentationbythemodel(green),and(c)anideal
Cliffordtorus(orange).
3.2 Modelscancomposebutnotinterpolate
Inthissection,weexaminethemodel’sabilitytocompositionallygeneralize. Specifically,wetrain
themodelonincompletedatasetsof2DGaussianSOSs,inwhichweleaveoutallGaussianSOSs
centeredinthered-shadedtestregions(Fig.4(f), samplingdistributionsshowninFig. 4(a), (b)).
Wethenassesstheperformanceofthemodelsingenerating2DGaussianSOSscenteredwithinand
outsideofthetestregions. Herewechoosethewidthofthecutstobearound6pixelswide,which
roughlycorrespondstothewidthoftheGaussianstripesofσ =1.0. Wedesignthelesionssuchthat
wecanprobethemodel’sabilityatcompositionallygeneralizingoutofthetrainingdistributionas
wellasitsabilitytospatiallyinterpolateinasinglevariablealone. Thereare4possibleoutcomes
basedonthemodel’sabilitytocomposeandinterpolate,andwegivepredictionsforthemodel’s
generalizationperformanceineachcase:1)themodelcannotcomposeorinterpolate:here,wewould
seelowperformanceacrossthetestregions;2)themodelinterpolatesbutcannotcompose: here,we
wouldseehighperformanceacrossthetestregions;3)themodelcomposesbutcannotinterpolate:
here,wewouldseehighperformanceinonedimensionbutnottheotherinthenon-intersectingpart
ofthetestregions,lowperformanceintheintersection;4)themodelcancomposeandinterpolate:
here,wewouldseehigherperformanceacrossthetestregions. Wenotethatcase(2)and(4)are
indistinguishableviathebehaviorofthemodel.
Inourfirstexperiment, wesimplytrainourmodelona2DGaussianSOSdatasetwherealldata
centeredinthetestregionsareleftout,i.e. excludingallµ ,µ ∈[13,19]asshowninFig.4(a). We
x y
callthismodelthe2Dmodelsincethemodelistrainedononly2DGaussianSOSdata. Wethen
examinetheterminalaccuracyofthe2DmodelingeneratingGaussianSOSsatthecorrectµ and
x
µ invariouspartsofthetestregions,whichwesectionintoahorizontalpart,averticalpart,both
y
excludingtheareaoftheirintersection,andtheintersectionitself(shownschematicallyinFig.4(f)).
Wenotethatthe2Dmodelachieveshighaccuracyingeneratingµ whilesufferslowaccuracyin
y
generatingµ intheverticalsection.Similarly,the2Dmodelachieveshighaccuracyingeneratingµ
x x
whilesufferslowaccuracyingeneratingµ inthehorizontalsection. Themodelsufferslowaccuracy
y
ingeneratingbothµ andµ intheintersectionregion. Theseobservationshavetwoimplications: i)
x y
themodelisfactorizedandcompositionalsinceitisabletogeneratethecorrectµ orµ irrespective
x y
oftheother;ii)themodelhaslimitedabilitytospatiallyinterpolate,whichsuggeststhatitdoesnot
learnafullycontinuousmanifoldinitsactivationspace(seeFig.10(c)). Theseobservationsmeet
ourexpectationforoutcomecase(3),whenthemodelcancomposebutnotinterpolateandresonates
ourconclusionfromSec.3.1thatthemodelhaslearnedtofactorizexandy,buthasnotlearneda
consistentrepresentationacrossallx’s(andlikewisey’s). InAppendixC.3Fig.11,wequantitatively
assessmodel’sabilitytointerpolateasafunctionoftheheld-outrangewidthinthedatamanifoldand
foundthatmodel’sabilitytointerpolategraduallydecreaseasafunctionoftheheld-outregionwidth.
6
ecafrus
neewteB
ecafrus
neewteB
ecafrus
neewteB
)y xfi(S
dna
)x
xfi(S
)2x
xfi(S
dna
)1x
xfi(S
)2y
xfi(S
dna
)1y
xfi(S(a) (c) (f)
2D Gaussian SOS Dataset
Vertical
0 13 19 32 x
Inter- Horizontal Horizontal
section
(d)
0 13 19 32 y
Vertical
(b)
1D Gaussian Stripe Dataset
(g)
(e)
0 32 x 0 32 y
Figure4: ModelstrainedonGaussianSOSdatasetstogeneralizetothetestregions. Wetrain
threemodelsonvariousGaussianSOSdatasetstotesttheirabilitytocompositionallygeneralize
inthered-shaded,held-outtestregionsshowninthesampleimage(f). (a)The2DGaussianSOS
datasetcontainsallcombinationof2DGaussianSOSsforallxandybetween0and32exceptfor
theheld-outrangebetween13and19. (b)The1DGaussianstripedatasetcontainshorizontaland
vertical1DGaussianstripesoffullrangeofxandyvaluesbetween0and32. Theaccuracyofthe
threemodelsingeneratingthecorrectxandylocationoftheGaussianSOSisshownfordifferent
sectionsofthetestregions: (c)Theverticalsectionexcludingtheintersection,(d)thehorizontal
sectionexcludingtheintersection,and(e)theintersection. (f)Sampleimageofa2DGaussianSOS
withthedifferenttestregionslabeled. (g)showstheaccuracyofmodelsrunwithvarioussubsampling
rateofthe2DGaussianbump+1DGaussianstripedataset.
Tofurtherverifyourhypothesisthatthemodeliscapableofcompositionbutnotinterpolation,we
design an alternative dataset that includes a mixture of 2D Gaussian SOS data and 1D Gaussian
stripedata(singlestripesthatareeitherhorizontalorvertical). Specifically, wegenerateasetof
1DGaussianstripedataacrosstheentirerangeofxandywithoutanyheld-outregions,asshown
in Fig. 4(b). Note that the 1D Gaussian stripe data respects the 2D structure of the conditional
inputembedding. Theexactgenerationprocedureforthe1DGaussianstripedatasetisdescribedin
AppendixC.1. This1Ddatasetisthencombinedwiththeprevious2DGaussianSOSdatasetwiththe
sameheld-outtestregions. Theresulting2D+1Ddatasetcontains1Ddatainallrangeofxandybut
hasnotseen2Ddata(compositionof1D)inthetestregions. Themodeltrainedunderthisdataset,
deemedthe2D+1Dmodel,hashighperformanceingeneratingbothµ andµ acrossallofthetest
x y
regions. Thisshowsthatgiventhenecessary“ingredients"(1DGaussianstripesofallrangeofxand
y),themodelisabletocomposetheminapropermanner(2DGaussianSOSs). Theseobservations
againconfirmthatthelearnedrepresentationofthemodelisfactorizedbutnotconsistentacrossa
singlefeature,meaningthatthemodelisabletocomposeindependentfeaturesbutnotinterpolate
withinasinglefeaturedimension.
Finally,wetestwhethercompositionalitycanbelearnedgivennocompositionalexamplesinthe
trainingdataset. Totestthis,wetraina1Dmodelonthe1DGaussianstripedatasetasdescribed
above. Ourresultsshowthatwhilemodelachievesrespectableaccuracyingeneratingthecorrect
µ acrossthetest regions, itdoesnotsimultaneously generatethecorrect µ , indicatingthatthe
y x
modeldidnotlearntoproperlycomposethe1Dstripes. Thisisalsoevidentfromthegenerated
imagesamplesfromthe1DmodelshowninFig.10(c). Withoutanycompositionalexamples,the
modelfailstogeneratetheintersectionoftwo1DGaussianstripesanddefaultsbacktogenerating
oneofthestripesatthecorrectlocation. Whilethe1Dmodelhasalsolearnedtofactorizexandy
asindependentconcepts,itisnotabletogeneralizehereduetothelackofcompositionalexamples.
Hence,basedontheperformanceofthe1D,2D,and2D+1Dmodelsthatwehaveseenabove,we
concludethatcompletecompositionalgeneralizationrequiresdataofallrangeofx’sandy’sand
somecompositionalexamplesofthetwotobepresentwithinthedataset.
7
ycneuqerF
ycneuqerF
ycneuqerF
ycneuqerF(a) Bumps (b) Bumps w/ Stripes (c)
Figure5: Sampleefficiencygainsfromtrainingthemodelonindependentfactorsofvariation.
(a-b): Results on N = 32 Gaussian 2D bump generation. (a) Model accuracy in generating 2D
Gaussian bumps from training on 2D Gaussian bumps, shown as a function of the subsampling
percentage. (b) Model accuracy in generating 2D Gaussian bumps from training on mixed 2D
Gaussianbumps+1DGaussianstripes. Reddashedlinesin(a),(b)markathresholdaccuracyof0,
60,and100%. (c)Log-logplotofdatasetsizeneededtoreach60%thresholdaccuracyasafunction
ofimagesizeN with2DGaussianbumpstrainingdata(blue)versusmixed2DGaussianbumps+
1DGaussianstripetrainingdata(orange): distinctscalingsofdataefficiencyvisualizedbydashed
grayandblacklines,whichprovidealinearandquadraticreference,respectively.
Buildingonourpreviousresults,weinvestigatewhethercombiningthe2DGaussianbumpdataset
with1Dstripedatacanimpartadifferentformofcompositionalitytothemodel–multiplicativerather
thanadditive. Todothis,wecreateadatasetthatmirrorsthe2D+1DGaussianSOSset,substituting
the2DGaussianSOSdatawith2DGaussianbumpdatawhilemaintainingthesametestregions. The
latentrepresentationofthisdatasetcanbefoundinFig.9(h)intheAppendix. Theresultingmodel
trainedunderthe2DGaussianbump+1DGaussianstripedatasetisabletogenerate2DGaussian
bumpswithinthetestregionsupto70%accuracy,suggestingthatthemodelisadeptathandlingan
alternativeformofcompositionality. Wefurtherinvestigatedwhetherthenumberof2DGaussian
bumpexamplesinthedatasetinfluencescompositionalitybysubsamplingthe2DGaussianbumpsin
thein-distributionregions(Fig. 9(g)). Theresultsshowthatmodelstrainedondatasetswithvarying
percentagesofsubsampled2DGaussianbumpsachievesimilarperformanceacrossthetestregions,
evenwithaslittleas20%oftheoriginaldata. Thesefindingssuggestthattrainingforcompositional
generalizationcanbeefficientlyachievedbyusingafullrangeofdataforeachindividualfactorof
variation,alongwithafewcompositionalexamples.
Tovalidatethebenefitoftrainingwith2D+1Ddatasets,weanalyzedthedataefficiencyscalingof
modelstrainedon2DGaussianbumps+1DGaussianstripes,comparingthemtomodelstrained
solelyon2DGaussianbumpsasafunctionofimagesizeN. Forboththebaselineandaugmented
datasets,weexcluded20%ofthe2DGaussianbumpsfromthecentersquareregionoftheN ×N
canvasforout-of-distribution(OOD)evaluations. Theaccuracyofthemodelsareplottedagainst
thepercentageof2DGaussianbumpssubsampledinFig.5(a)forthebaselinedatasetand(b)for
theaugmenteddataset. Theresultsclearlydemonstratethatthemodeltrainedontheaugmented
datasetperformsbetterwithasignificantlylowerpercentageof2DGaussianbumpsinthetraining
dataset. Wethenplottedthesizesofthebaselineandaugmenteddatasetsrequiredtoreacha60%
accuracythresholdasafunctionofN onalog-logscaleinFig.5(c). Wefoundthatmodelstrainedon
theaugmenteddatasetsonlyrequirelinearnumberofdatainN whilethosetrainedonthebaseline
datasetsrequirequadraticnumberofdatainN. Thisresultsuggeststhataugmenteddatasetswith
samplesofallindependentfactorsplusafewcompositionalexamplesprovideanefficienttraining
methodthathassamplecomplexitylinearinthenumberoffactors. InAppendixC.2andC.4,we
furtherdiscussthesampleefficiencyoflearningcompositionalityfromdatasetofisolatedfactorsof
variationplusfewcompositionalexamples.
In summary, our findings indicate that the model excels at compositionality but struggles with
interpolation.Consequently,effectivegeneralizationnecessitatesthatthetrainingsetencompassesthe
fullrangeofeachindividualfactorofvariation,alongsidecompositionalexamples. Furthermore,we
discoveredthatmodelstrainedondatasetsfeaturingexplicitlyfactorizedexamplesexhibitremarkable
data efficiency and adaptability to various forms of compositionality. These results align with
theobservedfactorizationpatternsinthemodelrepresentationdiscussedinSec.3.1andsuggest
promisingstrategiesfordevelopingmoredata-efficienttrainingschemesthatutilizetailoreddatasets.
8(a) d (b) (c)
x
d y{
(d) (e)
Figure6: Percolationtheoryofmanifoldformationandinterpolation. (a)Schematicdrawingof
theGaussianbumpsofvariouswidthonalatticeofgridsized andd . (b)Overlapsofneighboring
x y
Gaussian bumps as a function of the grid size d := d = d for various Gaussian widths. (c)
x y
Theoreticalsimulationoflargestconnectedmassratioasafunctionofpercentageofdataintraining
set λ with threshold overlap of 0.005 for various Gaussian widths. (d) Ground truth (left) and
generated image (right) of a sample Gaussian bump data of σ = 0.1 centered at µ = 16 and
x
µ =16. (e)Terminalaccuracyofmodelsasafunctionofλtrainedwithdatasetsthatonlydifferin
y
theGaussianbumpwidthsforvariousGaussianbumpwidths.
3.3 Connectionbetweenmanifoldlearningandpercolationtheory
Wehaveestablishedthatthemodellearnsfactorized(butnotfullycontinuous)andcompositionalrep-
resentations. Next,weidentifyapotentialconnectionbetweenmanifoldlearningindiffusionmodels
andpercolationtheoryinphysics,whichprovidesanormativeexplanationastohowfactorization(or
compositionalgeneralization)emerges. Tostart,wenotethatourGaussianbumpdatasetscanbe
approximatedasasimplePoissonBoolean(Gilbert’sdisk)modelGilbert[1961],Hanisch[1980],
awell-studiedsystemincontinuumpercolationtheory. Fig.6(a)showsaschematicillustrationof
ourdatasetofGaussianbumpsapproximatedasdisksofvariouswidthsona2D32×32latticeof
gridspacingsd andd . Inpercolationtheory,thequantityofinterestisthecriticalfractionofnodes
x y
thatneedtohavenon-zerooverlapsinorderfortheentiresystemtobeinterconnectedwithhigh
probability. Formostsystems(finite-andinfinite-sized),thereexistaphasetransitionthatoccursat
thecriticalfractionthatcanbeeitheranalyticallyderivedornumericallyestimated,withthetransition
becomingsharperasthesystemsizescales. Inourcontext, sincetheGaussianbumpimagesare
pixelated,overlapsbetweenneighboringGaussianbumpsarenotsmooth. InFig.6(b),weplotthe
normalizedL2-normoftheneighboringdistance-d-separatedGaussianbumpswithvariousspread
σ’s. WenotethatsincetheL2-normmeasureofoverlapisnormalizedto1betweenagivenGaussian
bumpanditself,theoverlapbetweenagivenGaussianbumpandaslightlyoffsetGaussianbump
temporarilygoesbeyond1duetothediscretenatureofthedata.
Wehypothesizethatbelowathresholdamountoftrainingdata,thediffusionmodelcannotconstruct
afaithfulrepresentationofthetrainingdataset. Fromthepercolationperspective,iftheredoesnot
existalargeenoughinterconnectedcomponentwithinthedataset,themodelwillfailtolearnthe
relativespatiallocationofthedatapoints,makingithardtolearnafaithful2Drepresentation. Totest
thishypothesis,wefirstsimulatedthemassratiooflargestinterconnectedcomponentsasafunction
oftheunitareadatadensityλwithour2DGaussianbumpdatasets. Forsimulation,weuseadataset
of1024datapoints,correspondingtod:=d =d =1.0ona32×32lattice. Wethenrandomly
x y
sampleλ×1024pointsonthelatticetocomputethesizeofthelargestinterconnectedclusterof
Gaussianbumps. Here,wedefineahyperparameterofthresholdoverlapbeyondwhichweconsider
twoGaussianbumpsasoverlapping. InFig.6(c),weshowthesimulationresults. averagedover5
runs,withthechosenthresholdoverlapof0.005fordatasetswithvariousσ’s. Additionalsimulation
resultswithvariouschosenoverlapthresholdscanbefoundinAppendixD.
Next,wequantifytheconnectionbetweenpercolationtheoryandmanifoldformationindiffusion
models. Toaccountforthestochasticityinsamplingthedatasetsandavoidsignificantoverheadin
9
{modeltraining, wechooseafixsetofgridpointsonthe32×32latticeandgeneratedatasetsof
varyingσ’sfromthisfixedsetofgridpoints. Moreover,wechooseeachsampledfractionofthe
datasettobeastrictsupersetofthesmallersampledfractionsofthedataset. Forexample,datasetat
λ=0.2containsallofdatasetatλ=0.1,anddatasetatλ=0.3containsallofdatasetatλ=0.2
and hence all of λ = 0.1, so on and so forth. For datasets of different σ’s, we chose the same
gridpointssuchthattheonlydifferencebetweendatasetsofdifferentσ’sisjusttheσ itself. This
procedureeliminatesallthestochasticityduetotheprobabilisticnatureofpercolation,andensures
thatdifferencesintrainingareonlyduetothedifferencesinσandλ. Toensurefaircomparison,we
proportionallyaddtrainingtimetoeachmodeltrainedwithfewerdatasuchthatthetotalamountof
trainingbatchesareconstantacrossallmodels.
InFig.6(e),wedisplaytheaccuracyofmodelstrainedwithdifferentfractionsofatrainingdatasetof
atotalsizeof1024forvariousσ’s. Wenotethattherearehighvariancesinthemodelperformance,
especiallyforσ =0.3,0.5. Thisisduetostochasticityinmodeltrainingitselfaswellasthegradual
asopposedtoasharpphasetransition,asshowninsimulationFig.6(c). Inaddition,wenoticethat
basedonthesimulation,σ =0.1willnotforgeanyconnectedclusterduetoitsminusculespread. In
Fig.6(d),ansampleimageofGaussianbumpsofσ =0.1isshownontheleft,whereitisamere
pixelcenteredat(µ ,µ ). Nonetheless,inexperimentFig.6(e),weseethatthemodelisableto
x y
learntheσ =0.1datasetatλ=0.8,0.9. Thisispartiallyduetothefactthatthenoisingprocessin
diffusiontrainingsmearsouttheGaussianbumpofσ = 0.1togiveitalargereffectivewidth,as
showninthegeneratedbumpimageinFig.6(d). Ingeneral,ourexperimentalresultsagreewiththe
percolationtheorypredictionthatsmallersimilaritiesbetweenthesamplesmakesitharderforthe
modelstolearnmeaningfulrepresentations,despitethesamequanitityofdata. Theportraitsofthe
learnedrepresentationsbythemodelsgeneratingFig.6(e)isshowninFig.15ofAppendixD.2.
4 Discussion
Intheprevioussection,wehaveshownthatdiffusionmodelsarecapableoflearningfactorizedand
semi-continuousrepresentations. Thisallowsforcompositionalgeneralizationacrossfactorsthat
haveappearedinthetrainingdataset,evengivenonlyasmallnumberofcompositionalexamples.
While we studied a toy system, our results imply that the diffusion model architecture has some
inductivebiasesfavoringfactorizationandcompositionality,asseeninastonishingcompositional
text-to-imagegenerationexamplessuchasan“astronautridingahorseonthemoon". Ourresults
demonstratefurtherthatifthetrainingdataincludeisolatedfactorsofindependentvariationand
somecompositionalexamples,diffusionmodelsarecapableofattaininghighperformanceinOOD
compositional generalization. While it is true that natural images are much more complex, and
therecanbenumerousformsofcompositionalitywithinasingleimage,thedatasetsandmodesof
compositionwestudiedwerenottrivial. Nonetheless,furtherinvestigationisnecessarytounderstand
thecompositionalityandfactorizationofmodelswhenmultipleformsofcompositionalityareatplay.
Furthermore,weshowedaconnectionbetweenthemodels’performance,asrelatedtoitsabilityto
learnafaithfulrepresentationofthedataset,andpercolationtheoryinphysics. Percolationtheory
providesaplausiblemechanisticinterpretationoftheobservedsuddenemergenceinthemodel’s
capability beyond a threshold number of data points. Further work is needed to characterize the
precise connection between percolation theory and manifold formation, in both toy settings and
realisticsettings. Inrealisticdatasets,mutualinformationorcosinesimilaritybetweendatapoints
canserveasabstractformsofoverlap. Moreover,theideaofpercolationcanbefurtherextended
tostudyalternativeobservationsofphasetransitionsindeeplearning, suchaspercolationofthe
chain-of-knowledgeinlargelanguagemodels.
5 Conclusion
We have shown that diffusion models are capable of learning factorized representations that can
compositionallygeneralizeOOD,givendatacontainingthefullrangeofeachindependentfactor
of variation and a small amount of compositional examples. Our study suggests that diffusion
modelshavetheinductivebiasforfactorizationandcompositionality,whicharebelievedtobekey
ingredientsforscalability.Weidentifiedthatthediffusionmodelsfailtogeneralizeout-of-distribution
when1)thereareunseenvaluesofagivenfactorofvariationforthecomposition,2)thereareno
compositionalexamplesinthetrainingdataset,3)thereisaninsufficientquantityofdata,and4)
10thereisaninsufficientamountofoverlapsbetweendata. Together,ourresultsimplythatamore
efficienttrainingdatasetcanbeconstructedbyincorporatingsamplesthatfeatureexplicitfactorized
examplesalongwithafewcompositionalexamplesthathavesubstantialoverlap. Byoptimizingthe
trainingdatainthismanner,wecanenhancethedataefficiencyscalingofdiffusion-basedmodels.
Futureinvestigationsshouldconsidercontrolledexperimentswithdataoptimizationforimproving
dataefficiencyofdiffusionmodelsusingmorerealisticdata.
References
YoshuaBengio,AaronC.Courville,andPascalVincent. Representationlearning: Areviewand
newperspectives. IEEETrans.PatternAnal.Mach.Intell.,35(8):1798–1828,2013. doi: 10.1109/
TPAMI.2013.50. URLhttps://doi.org/10.1109/TPAMI.2013.50.
JeffreyS.Bowers,IvanI.Vankov,MarkusF.Damian,andColinJ.Davis. Whydosomeneuronsin
cortexrespondtoinformationinaselectivemanner? insightsfromartificialneuralnetworks. Cog-
nition,148:47–63,2016. ISSN0010-0277. doi: https://doi.org/10.1016/j.cognition.2015.12.009.
URLhttps://www.sciencedirect.com/science/article/pii/S0010027715301232.
YoramBurakandIlaRFiete. Accuratepathintegrationincontinuousattractornetworkmodelsof
gridcells. PLoSComput.Biol.,5(2):e1000291,February2009. ISSN1553-734X,1553-7358. doi:
10.1371/journal.pcbi.1000291.
ChristopherP.Burgess,IrinaHiggins,ArkaPal,LoïcMatthey,NickWatters,GuillaumeDesjardins,
andAlexanderLerchner. Understandingdisentanglinginβ-vae. CoRR,abs/1804.03599,2018.
URLhttp://arxiv.org/abs/1804.03599.
RahmaChaabouni,EugeneKharitonov,DianeBouchacourt,EmmanuelDupoux,andMarcoBaroni.
Compositionalityandgeneralizationinemergentlanguages. InDanJurafsky,JoyceChai,Natalie
Schluter,andJoelR.Tetreault,editors,Proceedingsofthe58thAnnualMeetingoftheAssociation
forComputationalLinguistics,ACL2020,Online,July5-10,2020,pages4427–4442.Association
for Computational Linguistics, 2020. doi: 10.18653/V1/2020.ACL-MAIN.407. URL https:
//doi.org/10.18653/v1/2020.acl-main.407.
Rishidev Chaudhuri, Berk Gerçek, Biraj Pandey, Adrien Peyrache, and Ila Fiete. The intrinsic
attractormanifoldandpopulationdynamicsofacanonicalcognitivecircuitacrosswakingand
sleep. Nat. Neurosci., 22(9):1512–1520, September 2019. ISSN 1097-6256, 1546-1726. doi:
10.1038/s41593-019-0460-x.
NanxinChen,YuZhang,HeigaZen,RonJ.Weiss,MohammadNorouzi,andWilliamChan. Waveg-
rad: Estimatinggradientsforwaveformgeneration. In9thInternationalConferenceonLearning
Representations,ICLR2021,VirtualEvent,Austria,May3-7,2021.OpenReview.net,2021. URL
https://openreview.net/forum?id=NsMLjcFaO8O.
Christopher J Cueva, Adel Ardalan, Misha Tsodyks, and Ning Qian. Recurrent neural network
modelsforworkingmemoryofcontinuousvariables: activitymanifolds,connectivitypatterns,
anddynamiccodes. arXivpreprintarXiv:2111.01275,2021a.
Christopher J. Cueva, Adel Ardalan, Misha Tsodyks, and Ning Qian. Recurrent neural network
modelsforworkingmemoryofcontinuousvariables: activitymanifolds,connectivitypatterns,and
dynamiccodes. CoRR,abs/2111.01275,2021b. URLhttps://arxiv.org/abs/2111.01275.
Sunny Duan, Loic Matthey, Andre Saraiva, Nick Watters, Chris Burgess, Alexander Lerchner,
and Irina Higgins. Unsupervised model selection for variational disentangled representation
learning. In8thInternationalConferenceonLearningRepresentations,ICLR2020,AddisAbaba,
Ethiopia,April26-30,2020.OpenReview.net,2020. URLhttps://openreview.net/forum?
id=SyxL2TNtvr.
PeiranGao,EricTrautmann,ByronYu,GopalSanthanam,StephenRyu,KrishnaShenoy,andSurya
Ganguli.Atheoryofmultineuronaldimensionality,dynamicsandmeasurement.bioRxiv,2017.doi:
10.1101/214262. URLhttps://www.biorxiv.org/content/early/2017/11/12/214262.
E.N.Gilbert.Randomplanenetworks.JournaloftheSocietyforIndustrialandAppliedMathematics,
9(4):533–543,1961. doi: 10.1137/0109045. URLhttps://doi.org/10.1137/0109045.
11TorkelHafting,MarianneFyhn,SturlaMolden,May-BrittMoser,andEdvardIMoser.Microstructure
ofaspatialmapintheentorhinalcortex. Nature,436(7052):801–806,August2005a. ISSN0028-
0836,1476-4687. doi: 10.1038/nature03721.
TorkelHafting,MarianneFyhn,SturlaMolden,May-BrittMoser,andEdvardI.Moser.Microstructure
of a spatial map in the entorhinal cortex. Nature, 436:801–806, 2005b. URL https://api.
semanticscholar.org/CorpusID:4405184.
Karl-HeinzHanisch. Onclassesofrandomsetsandpointprocessmodels. J.Inf.Process.Cybern.,
16(8/9):498–502,1980.
IrinaHiggins,LoïcMatthey,ArkaPal,ChristopherP.Burgess,XavierGlorot,MatthewM.Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrainedvariationalframework. In5thInternationalConferenceonLearningRepresentations,
ICLR2017,Toulon,France,April24-26,2017,ConferenceTrackProceedings.OpenReview.net,
2017. URLhttps://openreview.net/forum?id=Sy2fzU9gl.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In
Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-
Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Con-
ference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-
12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/
4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html.
QiyaoLiang,ZimingLiu,andIlaFiete. Dodiffusionmodelslearnsemanticallymeaningfuland
efficientrepresentations? CoRR,abs/2402.03305,2024. doi: 10.48550/ARXIV.2402.03305. URL
https://doi.org/10.48550/arXiv.2402.03305.
JackW.LindseyandEliasB.Issa. Factorizedvisualrepresentationsintheprimatevisualsystem
anddeepneuralnetworks. April2023. doi: 10.1101/2023.04.22.537916. URLhttp://dx.doi.
org/10.1101/2023.04.22.537916.
LelandMcInnesandJohnHealy. UMAP:uniformmanifoldapproximationandprojectionfordimen-
sionreduction. CoRR,abs/1802.03426,2018. URLhttp://arxiv.org/abs/1802.03426.
LelandMcInnes,JohnHealy,NathanielSaul,andLukasGrossberger. Umap: Uniformmanifold
approximationandprojection. TheJournalofOpenSourceSoftware,3(29):861,2018.
Milton Llera Montero, Casimir J. H. Ludwig, Rui Ponte Costa, Gaurav Malhotra, and Jeffrey S.
Bowers. The role of disentanglement in generalisation. In 9th International Conference on
LearningRepresentations,ICLR2021,VirtualEvent,Austria,May3-7,2021.OpenReview.net,
2021. URLhttps://openreview.net/forum?id=qbH974jKUVy.
May-BrittMoser,DavidC.Rowland,andEdvardI.Moser. Placecells,gridcells,andmemory. Cold
SpringHarborPerspectivesinBiology,7(2),Feb2015. doi: 10.1101/cshperspect.a021808.
MoserMB.MoserEI,KropffE. Placecells,gridcells,andthebrain’sspatialrepresentationsystem.
2008. doi: 10.1146/annurev.neuro.31.061307.090723. URLhttps://pubmed.ncbi.nlm.nih.
gov/18284371/.
MayaOkawa,EkdeepSinghLubana,RobertP.Dick,andHidenoriTanaka. Compositionalabilities
emergemultiplicatively: Exploringdiffusionmodelsonasynthetictask. CoRR,abs/2310.09336,
2023. doi: 10.48550/ARXIV.2310.09336. URLhttps://doi.org/10.48550/arXiv.2310.
09336.
ChitwanSaharia,JonathanHo,WilliamChan,TimSalimans,DavidJ.Fleet,andMohammadNorouzi.
Imagesuper-resolutionviaiterativerefinement. IEEETrans.PatternAnal.Mach.Intell.,45(4):
4713–4726, 2023. doi: 10.1109/TPAMI.2022.3204461. URL https://doi.org/10.1109/
TPAMI.2022.3204461.
Hanne Stensola, Tor Stensola, Trygve Solstad, Kristian Frøland, May-Britt Moser, and Edvard I
Moser. Theentorhinalgridmapisdiscretized. Nature,492(7427):72–78,December2012. ISSN
0028-0836,1476-4687. doi: 10.1038/nature11649.
12JSTaube,RUMuller,andJBRanck,Jr. Head-directioncellsrecordedfromthepostsubiculumin
freelymovingrats.i.descriptionandquantitativeanalysis. J.Neurosci.,10(2):420–435,February
1990. ISSN0270-6474. doi: 10.1523/JNEUROSCI.10-02-00420.1990.
Jeffrey S Taube. The head direction signal: origins and sensory-motor integration. Annu. Rev.
Neurosci.,30:181–207,2007. ISSN0147-006X. doi: 10.1146/annurev.neuro.29.051605.112854.
ThaddäusWiedemer,PrasannaMayilvahanan,MatthiasBethge,andWielandBrendel.Compositional
generalizationfromfirstprinciples. InAliceOh,TristanNaumann,AmirGloberson,KateSaenko,
MoritzHardt,andSergeyLevine,editors,AdvancesinNeuralInformationProcessingSystems36:
AnnualConferenceonNeuralInformationProcessingSystems2023,NeurIPS2023,NewOrleans,
LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/
paper/2023/hash/15f6a10899f557ce53fe39939af6f930-Abstract-Conference.html.
ZhenlinXu,MarcNiethammer,andColinRaffel. Compositionalgeneralizationinunsupervised
compositional representation learning: A study on disentanglement and emergent language.
In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors,
Advances in Neural Information Processing Systems 35: Annual Conference on Neural Infor-
mation Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - De-
cember 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/
9f9ecbf4062842df17ec3f4ea3ad7f54-Abstract-Conference.html.
Shengjia Zhao, Hongyu Ren, Arianna Yuan, Jiaming Song, Noah D. Goodman, and Stefano Er-
mon. Biasandgeneralizationindeepgenerativemodels: Anempiricalstudy. InSamyBengio,
HannaM.Wallach,HugoLarochelle,KristenGrauman,NicolòCesa-Bianchi,andRomanGarnett,
editors,AdvancesinNeuralInformationProcessingSystems31: AnnualConferenceonNeural
InformationProcessingSystems2018,NeurIPS2018,December3-8,2018,Montréal,Canada,
pages 10815–10824, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
5317b6799188715d5e00a638a4278901-Abstract.html.
A ExperimentalDetails
A.1 Architecture
We train a conditional denoising diffusion probabilistic model (DDPM) Ho et al. [2020] with a
standard UNet architecture of 3 downsampling and upsampling blocks, interlaced self-attention
layers, and skip connections as shown in Fig. 7. Each down/up-sampling blocks consist of max
pooling/upsamplinglayersfollowedbytwodoubleconvolutionallayersmadeupbyconvolutional
layers,groupnormalization,andGELUactivationfunctions.
Theconditionalinformationispassedinateachdown/up-samplingblockasshownintheschematic
drawing. Inourexperiments,wechoosetopreservethecontinuityoftheGaussianpositionlabels
passedintothemodelviaexplicitpositionalencodingratherthanusingaseparatetrainableembedding
MLPateachblock. Eachembeddingvectorismadebyconcatenatingequal-lengthvectorsofthe
positionalencodingsofthetimestep,thex-position,andthey-position.
Inourexperiments,wevisualizetheoutputsoflayer4astheinternalrepresentationofthediffusion
model. Wehavechosennottousetheoutputofthebottlenecklayerforourstudyofthelearned
latentmanifold,aswehaveobservedthatthebottlenecklayershavediminishingsignalsinmostof
ourexperiments. Thisislikelyduetothepresenceoftheskipconnections. Thischoicedoesnot
affectthevalidityofourmainresults,aswearefocusedonthefactorizationofthemodel’slearned
representation.
A.2 DimensionReduction
WeprimarilyusethedimensionreductiontechniqueUniformManifoldApproximationandProjection
forDimensionReduction(UMAP)McInnesandHealy[2018]tostudyandvisualizethelearned
representationofthemodel. Specifically,wecollectimagesamplesandtheircorrespondinginternal
representations(outputsoflayer4fromthearchitecturedescribedinSec.A.1). Wethentransform
the high-dimensional internal representations into a 3D embedding as a sample of the learned
13Network Architecture:
Embedding Scheme:
Layer 0 Down(64,128)
Positional Positional
Embedding = encoding for ⊕ encoding for
time steps features
Layer 1 Down(128,256)
Positional Encoding:
Layer 2 Down(256,256)
Self-attention
PE (t,2i)=sin(t/100002 /id
) ∀i∈{0,…,N/2−1}
layer of Bottleneck PE (t,2i+1)=cos(t/100002i+ /1d )
corresponding
sizes
Layer 3 Up(512,128)
Positional Encoding Concatenation:
Layer 4 Up(256,64)
Time PEt N ⊕ X PEx N ⊕Y PEy N
Layer 5 Up(128,64)
Figure7: TheUNetarchitectureoftheconditionaldiffusionmodel. Theschematicdiagramof
thestandardUNetarchitectureconsistingofthreedownsampling/upsamplingblockswithinterlaced
self-attentionlayersandskipconnectionsisshownontheleft. Theconditionalinformationconsisting
ofaconcatenationofpositionalencodingsoftimestepandx/y-positionsispassedinateachblockas
shownontheright.
representation, which we visualize and analyze. For an implementation of UMAP, we used the
PythonpackageMcInnesetal.[2018].
A.3 Evaluation
Weassesstheperformanceofthemodelusingtwoprimarycriteria: 1)thequalityofthedenoised
imagesand2)thequalityofthelearnedrepresentation.
Atagiventimeduringoraftertraining,wegenerate1024denoisedimagesandtheircorresponding
internal representations of sampled labels based on 32 × 32 grid points. We predict the label
correspondingtoeachgeneratedimagebasedonthex-andy-positionsofthegeneratedGaussian
bump/SOSintheimage. Wethencomputetheaccuracyofpredictedlabelsfromtheground-truth
labelsaveragedover1024samplesas
1024
1 (cid:88)
Accuracy= 1(|µi −µˆi|<1)·1(|µi −µˆi|<1), (1)
1024 x x y y
i=1
where1(·)isanindicatorfunctionthatreturns1iftheexpressionwithinholdstrue, 0otherwise.
Similarly, wecanmodifythisexpressiontoonlyassesstheaccuracyofgeneratedx-positionsor
y-positionsseparately. HereweestimatethecenteroftheGaussianbump/SOSµˆi andµˆi byfinding
x y
thelocationofthedarkestpixelintheimage. InthecaseswheretherearenoGaussianbumps/SOS’s
ormorethanonebump/SOS,thealgorithmdefaultsbacktofindingthecentroidoftheimage. We
then construct the learned representation of the model based on the neural activations of layer 4
correspondingtothe1024sampledimagescollectedattheterminaldiffusiongenerationtimestep.
We note that we have investigated neural activations collected at alternative diffusion generation
timestepsandfoundthattheydonotnoticeablydifferfromtimesteptotimestep.
A.4 TrainingLoss
Diffusion models iteratively denoise a Gaussian noisy image x into a noisefree image x over
T 0
diffusion timesteps t ∈ {0,1,...,T} given the forward distribution q(x |x ) by learning the
t t−1
reversedistributionp (x |x ). Givenaconditionalcuec,aconditionaldiffusionmodel[Chen
θ t−1 t
etal.,2021,Sahariaetal.,2023]reconstructsanimagefromasourcedistributionq(x |c).Specifically,
0
wetrainourneuralnetwork(UNet)topredictthedenoisingdirectionϵ (x ,t,c)atagiventimestep
θ t
14t with conditional cue c with the goal of minimizing the mean squared loss (MSE) between the
predictedandthegroundtruthnoiseϵasfollows
L:=E (cid:2) ∥ϵ−ϵ (x ,t,c)∥2(cid:3) , (2)
t∈{0,...,T},x0∼q(x0|c),ϵ∼N(0,I) θ 0
whereweassumeeachnoisevectorϵtobesampledfromaGaussiandistributionN(0,I)I.I.D.at
eachtimestept.
A.5 Datasets
ThedatasetsweusedfortrainingthemodelsgeneratingtheresultsinSec.3havevariousincrementsd
andσ.Herewebrieflycommentontheinterplaybetweenincrementsandsigmas,andhowtheyaffect
datasetdensitiesandoverlaps. Theultimategoalofourtaskofinterestistolearnacontinuous2D
manifoldofallpossiblelocationsoftheGaussianbumps/SOS’s. Intuitively,thespatialinformation
necessaryforanorganized,continuous,andsemanticallymeaningfulrepresentationtoemergeis
encodedintheoverlapoftheneighboringGaussianbumps/SOS’s,whichistunedviatheparameters
dandσ. Asweincreased,thesizeofthedatasetgetsscaledquadratically,resultingindensertilings
oftheGaussianbumps/SOS’s.
Aswescaleupσ,thedatasetsizeremainsfixedwhiletheoverlapswithneighborsaresignificantly
increased.InFig.6(b),weplotthenormalizedL2-normoftheproductimageofneighboringGaussian
bumpsasafunctionofincrementsforvariousspreads. Specifically,giventwoinvertedgrayscale
Gaussianbumpimages,aandb,thenormalizedL2-normoftheirproductisgivenbytheformula
√
∥ a∗b∥ /∥a∥ , where ∗ is element-wise multiplication and ∥·∥ is the L2-norm. This quantity
2 2 2
shouldgivearoughmeasureoftheimageoverlapwiththeexceptionatincrementaround0.5dueto
thediscretenatureofourdata. Moreover,wenotethatthecuspsinthecurvesoccurforthesame
reason. Aswecansee,thenumberofneighborsthatagivenGaussianbumphasnon-trivialoverlaps
withgrowsroughlylinearlytosub-linearlywiththespread. Sincethemodelconstructsnon-parallel
representationencodingsofdifferentvaluesofx’sandy’s, moreneighborinformationresultsin
moreoverlapsbetweendifferentvaluesofx’sandy’sandhencebetterrepresentationlearned,as
showninthepercolationresultsinFig.6inSec.3.3. OverlapsinGaussianSOSdatacanbesimilarly
analyzed,albeitthedifferencesinoverlapsofneighboringGaussianSOS’sofvariousspreadσ’sis
notaspronouncedduetothelargecoverageareaofeachGaussianstripe.
A.6 TrainingDetails
Wetrainthemodelsonaquad-coreNvidiaA100GPU,andanaveragetrainingsessionlastsaround
6 hours (including intermediate sampling time). Each model is given an inversely proportional
amountoftrainingtimeasafunctionofthesizeofthedatasetthatitistrainedonsuchthatthereis
sufficientamountoftrainingforthemodelstoconverge. Foreachmodel,wesample1024samples
correspondingtothe32×32gridpointsofµ andµ pairstilingtheentireimagespace. Themodel
x y
is trained with the AdamW optimizer with built-in weight decay, and we employ a learning rate
schedulerfromPytorchduringtraining. Wedidnotperformanyhyperparametertuning,althoughwe
wouldexpectourobservationstoholdregardless.
B OrthogonalityandParallelTest
B.1 MotivationfortheAnalysis
Tobetteridentifywhetherthediffusionmodelslearntofactorizeitsrepresentations,wechooseto
studyperiodicrepresentationsofGaussianbumps,whichweexpecttoformtoroidalmanifoldsinthe
latentspaceasopposedtoplanarmanifolds.Thisisbecausetoroidalmanifoldshavemultiplestandard
realizationswhichvarybasedontheirdegreeofentanglementinthetworings. Inparticular,the
standardtorusembedstheringsinthreedimensionsthatcouplethetwoperiodicvariables,whereas
theCliffordTorusembedseachringinitsownorthogonalsubspace. Thisdifferenceingeometry
motivatesthetwoanalysesthatweimplementedtoidentifywhichgeometrythediffusionmodel
learned.
15(a) Between surfaces S(fix x) and S(fix y) (b) Between surfaces S(fix x) and S(fix x)
1 2
Figure8: Wassersteindistancesoforthogonalityandparallelismtestsstatisticsbetweenlearned
representationsandidealClifford/3Dtori.
B.2 ComputationoftheTests
We implement the orthogonality and parallelism tests as in Cueva et al. [2021a]. Briefly, the
orthogonalitytestaskswhethertheringsthatcodeforeachvariablelieinorthogonalsubspaces–ifso,
thisindicatesthatthetorushasaClifford-likegeometry. Theparallelismtestaskswhetherringsin
onevariablearealignedintheothervariable. Ifso,thisalsoindicatesthatthetorushasaClifford-like
geometry.
Theanalysisfirstrequiresidentifyingeachring–surprisingly,wefoundthatwhentheringsformed,
thetopfourPrincipalComponentscomprisedthem. Inparticular,thefirstringwereconsistently
spannedbyPCs1and3,andthesecondwasspannedbyPCs2and4(Fig.2(f)and(g)). Thus,we
confirmedthatwecouldusePCAforouranalysis.
Foreachanalysis,weidentifytheringsubspacesbyfixingonevariableoftheinput,andsweeping
theothervariable. Wedosoforeachindex,arrivingat32differentsubsetsofthedataforvariablex
and32differentpointsforvariabley. Next,wecomputethetoptwoPrincipalComponentsforeach
subsetofthedata,therebyidentifyingthering.
Fortheorthogonalitytest,werandomlydrawpairsofringsthatarefixedinxandyandcomputethe
pairwiseanglesbetweeneachrings’PrincipalComponentsviacosinesimilarity. Fortheparallelism
test,wecomputetherandomlydrawnpairsofringsthatarefixedinthesamevariable.Next,wecreate
aprojectionmatrixP fromthesubspacesdefinedbyoneoftherings,andcalculatethereconstruction
errorofthesecondring’sprojectionontothatsubspace:
r =|h−PPTh|2. (3)
2
Ineachtest,weaggregatehistogramsoftherespectivemetric. Toidentifythesimilaritybetween
ourdataandeithertoroidalembedding,wecomputethesamehistogramsforboththeCliffordand
standardtorus(basedonasimulationwithsimilarspacinginxandy samples),andcomputethe
Wassersteindistancebetweenthedataandthesesimulations. TheWassersteindistancesbetween
theorthogonalityandparallelismteststatisticsofthemodel’slearnedrepresentationandthoseofan
idealCliffordtorusand3DtorusareshowninFig.8asafunctionofthetrainingepochs. Wenote
thatthemodel’slearnedrepresentationsatsmallertrainingepochsarenotnecessarilyatorus,hence
themetriccomparisonatthosepointshaslesssignificance.
16C CompositionandInterpolation
C.1 GaussianStripe/SOSDatasetGeneration
(a) (b) (c) (d)
0D Gaussian SOS Data 1D Gaussian SOS Data 2D Gaussian SOS Data 2D Gaussian Bump Data
(e) (f) (g) (h)
SOS
SOS
SOS
Figure9: SampleGaussianstripe/SOS/bumpdataimagesanddatasetlatentrepresentations
used for generating models in Fig. 4. We generate the 1D Gaussian stripes via embedding the
32×32imageframeintoanextendedlatentspaceof44×44,wheretheextendedportionisnot
visibletothemodel. (a)-(c)showexampleimagesof0D,1D,and2DGaussianSOSdataimages,
where the dimensionality of the image is defined by the dimension of the portion of data visible
withinthe32×32imageframe. (d)showstheequivalentaugmentationof2DGaussianbumpdata
intheembeddedspace. Foreachdataimage,weassignitspositionlabelsfromrange0to44while
keepingtheimagesizetobe32×32bycroppingoutthe“extendedspace"intheimage. Basedon
theseimagedata,weconstructthe2D,1D,and2D+1DdatasetsofGaussianSOS’sthatweuseto
trainthemodelsinFig.4. (e)-(g)showthelatentrepresentationofthe2D,1D,and2D+1Ddatasets
respectively,wherethegreendotsrepresent2DGaussianSOSdata,thebluedotsrepresentthe1D
GaussianSOSdata,andtheyellowpointsthe0DGaussianSOSdata. Weleaveall2DGaussianSOS
centeredinthered-shadedregionoutofthetrainingdatasetforourcompositionalgeneralization
evaluation. (h) shows the equivalent dataset to the 2D+1D dataset with the 2D Gaussian SOS’s
replacewith2DGaussianbumps,wherethemagentapointsrepresentthe2DGaussianbumpdata.
Togenerate1DGaussianstripedatasetshowninFig.4(b)whilemaintainingthestructureofthe2D
conditionalembeddings,weembedthe32×32datalatentspaceintoanextended44×44latentspace
whilemaintainingtheimagepixelsizetobe32×32. Functionally,thisallowsustomixintothe2D
GaussianSOSdatasets1D(and0D)Gaussiandata,asdefinedbytheportionoftheGaussianthatis
actuallyvisibletothemodelinthe32×32pixels. Examplesof0D,1D,and2DGaussianSOSdata
areshowninFig.9(a)-(c),respectively. Fig.9(e)-(g)thenshowtheactualdatalatentrepresentations
ofthe2D,1D,and2D+1Ddatasetsthatweusetotrain2D,1D,and2D+1Dmodelsdescribedin
Sec.3.2. Here,thegreenpointsrepresenteachindividual2DGaussianSOSdata,thebluepoints
representthe1DGaussianSOSdata,andtheyellowpointsthe0DGaussianSOSdata. Inallthree
datasets,weleaveouttheallGaussianSOSdatacenteredintheredshadedregions. Wenotethat
duetothenatureofourdatagenerationscheme,the2Ddataonlyexistwithintheimagespace(and
somespillover)andthe1D(and0D)dataonlyexistintheextendeddatalatentspace. Becauseofthe
nonzerowidthoftheGaussianstripes,aportionofthedataalongtherimofthe32×32imagespace
isactually2Dwithaportionoftheoverlapsbetweenthehorizontalandtheverticalstripesvisible
withintheimageframe. Intrainingthe1DmodelshowninFig.4,wehaveremovedtherimwhere
anyoverlapbetweenthehorizontalandverticalGaussianstripesispartiallyvisiblewithintheimage,
asshowninFig.9(f). Themodeltrainedonsucha1Ddatasetwithoutanycompositionalexampleis,
asdiscussedinSec.3.2,notabletohandletheconjunctionofthe2Gaussianstripes,asshownin
Fig.10(a)-(c).
17C.2 GeneralizationwithFewCompositionalExamples
InSec.3.2,wehaveseenthatthemodelsaresufficientlydataefficientinlearningthecompositionality
givenafew2Dexamples.Herewecomparetheperformanceofmodelstrainedonapure1DGaussian
stripedatasetversusa1DGaussianstripedataset+asmallamount2Dcompositionalexamplesalong
theimagerim,wheretheconjunctionofthestripesareonlypartiallyvisiblewithinthedataimages.
Herewenamethepure1DGaussianstripedatasetas1Dstripeswithout2Drimandthealternative
as1Dstripeswith2Drim. ThedatalatentrepresentationsofbothdatasetsareshowninFig.10(a),
(d)andtheoverall,in-distribution,andout-of-distributionsampledimageaccuracyofmodelstrained
onthesedatasetsareshownin(b)and(e). Wenotefromthegenerationbehaviorthatthemodel
trainedwithoutthe2Drimhasahardtimegeneratingtheportionoftheimageswherethevertical
andhorizontalstripesoverlap. However,givenasmallsetofexamplesofpartialoverlaps,themodel
hascompletelygainedtheabilitytoproperlycomposethestripes. Specifically,themodeltrained
withthe2Drimachievesthesamelevelofaccuracy,ifnotbetteraccuracy,thanthe2D+1Dmodel
shown in Fig. 4 with ample of 2D compositional examples. This suggests that models can learn
compositionalstructureefficientlyfrommerelyafewcompositionalexamples. Moreover,wehave
showninSec.3.2Fig.4(g)thatthistypeofsampleefficiencyistransferabletoanalternativetypeof
compositionality.
(a) (b) (d) (e)
(c) (f)
Figure10: Comparisonbetween1DGaussianstripedatasetwithandwithout2DGaussianSOS
examples. (a)showsthelatentmanifoldofapure1DGaussianstripedatasetwiththerimof2D
GaussianSOSexamplesremovedalongthe32×32imagespace. Theoverall,ID,andOODaccuracy
ofthegenerateimagesofthemodeltrainedunderthisdatasetisshownin(b)alongwith25randomly
selectedgeneratedimagesin(c). (d)showsthelatentmanifoldofthe1DGaussianstripedataset
with2DGaussianSOSdataincludedalongtheimagerim. Theoverall,ID,andOODaccuracyof
thegenerateimagesofthemodeltrainedunderthisdatasetisshownin(e)alongwith25randomly
selectedgeneratedimagesin(f).
C.3 Model’sAbilitytoInterpolate
AsdiscussedinSec.3.2,themodelshavepoorabilitytointerpolateasevidentfromthefactthat
models cannot generalize to unseen values of x and y in the OOD experiments where an entire
rangeofxandyareremovedfromthetrainingdataset(Fig.4). Thisisbecausethemodellearned
non-parallel representations of different values of x’s and y’s, hence treating x and y similar to
categorical values where there are non-zero overlaps between neighboring categories. We have
18establishedinSec.3.2Fig.4thatthe2Dmodeltrainedonthe2DGaussianSOSdatasetswiththe
redheld-outtestregionscanindeedcomposebutnotinterpolate. Herewequantitativelyinvestigate
themodel’sabilitytointerpolatewhentrainedon2DGaussianSOSdatasetsofvaryingwidthsin
theheld-outxrange,asillustratedinFig.11(a). InFig.11(b),weshowthetrainedmodels’overall,
in-distribution,andout-of-distributionimage-generationaccuracyasafunctionoftheheld-outrange
widths. WenoticethattheaccuracyingeneratingimagesintheOODregiondegradesgradually
as function the held-out range width. This is likely due to the fact that the models learn parallel
encodingsofdifferentvaluesofx’sandy’sthathavenontrivialoverlapswitheachotherbasedon
thespatialoverlapoftheGaussianSOSdata. Similarlythelearnedrepresentationsbythemodel
becomeincreasinglydisconnectedasafunctionofthewidthsizes,whichisinagreementwiththe
macroscopicgenerationbehaviorofthemodel.
(a) (b)
Width
(c)
Figure11: Investigationofmodel’sabilitytointerpolate. (a)Datamanifoldwithaverticallesion
inthecenterofthemanifoldofvariouswidth. (b)ModelOODaccuracydecaysasafunctionofthe
widthofthelesion. (c)Thelearnedrepresentation(UMAPreduced)ofmodelstrainedwithdatasets
oflesionwidths1.0,3.5,and8.0.
C.4 Model’sAbilitytoCompose
In this section, we investigate model’s ability to compositionally generalize when we cut out an
out-of-distributionsquareregionofsizeW ×W intheimagedatamanifold. Specifically,weare
interestedintwoscenario: 1)interiorcompositionalgeneralizationwheretheOODcutisinthe
centerofthedatamanifold,and2)exteriorcompositionalgeneralizationwheretheOODcutisatthe
cornerofthedatamanifold. Ineithercase,wewanttotestoutdiffusionmodel’sabilitytogeneralize
totheOODregionsasafunctionoftheOODregionwidthW. Wetestmodelsunderbothsettingsof
interiorandexteriorcompositionalgeneralizationwhentrainedusinga2DGaussianbumpdatasetor
a2DGaussianSOSdataset. TheresultsshowthatfortheGaussianbumpdataset,themodel’sability
tocompositionallygeneralizeininteriorregionsslowlydecaywhileinexteriorregionsquicklydecay
asafunctionoftheOODregionwidth.Ontheotherhand,themodel’sperformanceremainsrelatively
highforalltestedOODregionwidthsinbothinteriorandexteriorcompositionalgeneralizationwhen
trainedontheGaussianSOSdataset. TheseresultsshowthattheGaussianSOSdatasetindeedallows
themodeltoacquirecompositionalityinamorerobustaswellassampleefficientmanner.
19
{(a) Interior Comp Gen (c) 2D Gaussian Bump Interior OOD (d) 2D Gaussian SOS Interior OOD
32 x 32
OOD
WxW
ID
(b) Exterior Comp Gen (e) 2D Gaussian Bump Exterior OOD (f) 2D Gaussian SOS Exterior OOD
32 x 32
ID
OOD
WxW
Figure12: Interiorandexteriorcompositionalgeneralizationof2DGaussianbumpand2D
GaussianSOSdatasets. (a)showsaschematicdrawingofinteriorcompositionalgeneralization
whereweleaveoutdatapointswithinaninteriorred-shadedOODregionofthedatamanifold. (b)
showstheaschematicdrawingofexterior compositionalgeneralizationwhereweleaveoutdata
pointswithinanexteriorred-shadedOODregionofthedatamanifold. ThesizeoftheOODregions
inbothscenarioisW ×W. (c),(d)showstheaccuracyofmodelstrainedon2DGaussianbumpand
2DGaussianSOSdatasetsforinteriorcompositionalgeneralizationasafunctionofvariousOOD
regionwidthW. (e),(f)showstheaccuracyofmodelstrainedon2DGaussianbumpand2DGaussian
SOSdatasetsforexteriorcompositionalgeneralizationasafunctionofvariousOODregionwidthW.
D ManifoldformationandPercolationTheory
D.1 PercolationTheoreticalSimulation
InSec.3.3,wehaveshownsimulationresultsonpercolationFig.6(c)tomatchwithourexperimental
datain(e). Specifically,weperformthesimulationonactual2DGaussianbumpdatasetsgeneratedin
thesamewayasthoseusedtotrainthemodelsgeneratingtheexperimentalresults. Hereweemploy
aneighborhood-findingalgorithmthatrecursivelyiteratesthroughandfindallislandofconnected
clusterswithinagivensampleofadatasetof σ andsizeλ×1024. Intheneighborhood-finding
algorithm, we define a given set of two 2D Gaussian bumps to be connected if the normalized
L2 metric (introduced in Appendix A.5 and plotted in Fig. 6(b)) is beyond a given threshold,
which becomes a hyper-parameter in our simulation. A higher threshold overlap means that the
neighborhood-findingalgorithmhasamorestringentstandardsforjudgingwhichsetofbumpsare
connected,andthatitishardertopercolategiventhesameamountofdata. Thesimulationresults
averagedover5sampledatasetsperpointareshowninFig.13forvariousσ’sandthresholdoverlaps.
As we increase the threshold overlap in the simulation, the percolation thresholds of datasets of
various σ’s become delayed. Given a large enough threshold overlap, some of the datasets with
smallσ’sneverpercolates. Moreover,wenoticethatinsimulationσ =0.1neverpercolatesdueto
itswidthofapixelwide. Nonetheless,themodelhaslearnedtogeneratedtheσ = 0.1Gaussian
bumpswithalargereffectivewidthsuchthatthemodelisabletoconstructafaithfulmanifoldof
theσ = 0.1datasetatlargeλ. InFig.6(c),wehavechosentodisplaythesimulationresultswith
thresholdoverlapof0.005tobestmatchwiththeobservedexperimentaldata. Suchalowthreshold
overlapsignifiesthatthemodelissensitivetorelativespatialoverlapsamongdataimages.
D.2 PercolationExperimentalDetails
Intestingoutpercolationtheoryinexperiment,wereliedonaspecificdatagenerationprocedureto
eliminatemuchofthestochasticityinsamplingdatasetstoavoidhavingtotrainalargenumberof
models. InFig.6(d),thedatasetsusedtotrainmodelofdifferentfordifferentλ’sarethesameacross
20Figure13: Percolationsimulationofvariousσ’swithdifferentoverlapthresholds.
(a) (b)
(c)
Figure14: SupportingfiguresforpercolationsimulationandexperimentsfromFig.6. (a)Latent
representationofdatasetsusedtogenerateresultsinFig.6. (b)Simulationoflargestconnecting
clustermassratiowiththresholdoverlapof0.05forσ’scorrespondingtothoseshowninFig.6(e).
(c)ThefinaltrainingandvalidationlossesasafunctionofλofmodelsinFig.6(e).
allσ’sexceptfortheσ’s. Thesharedunderlyinglatentrepresentationsofthedatasetsareshownin
Fig.14(a)fordifferentλ’s. Moreover,weshowanexamplesimulationofthelargestconnectedmass
ratioofthesespecificdatasetswiththresholdoverlapof0.05inFig.14(b).
Notethathere, asdescribedinSec.3.3, eachsubsequentdatasetofalargerλisasupersetofall
preceding datasets of smaller λ’s. As a result, we know that if the dataset with σ percolates at a
givenλ ,thenitautomaticallypercolatesatanyλ≥λ . Thisisanimportantestablishmentsince
c c
themodelstrainedwithdatasetsofsmallσ’sseemtohavehighvarianceintheoutcometraining
accuracyfordifferentλ’s,asshowninFig.6(d). Giventhefactthatallmodelstrainedondatasets
withlargerλhaveasupersetofinformationthanthosetrainedondatasetswithsmallerλ’s,wecan
attributethevarianceintheexperimentaloutcomepartiallytotheinstabilityinthetrainingitself
ratherthanpercolationtheory.
21Figure 15: Final learned representations corresponding to models that generated results in
Fig.6.
Onehypothesisfortheobservedinstabilityinmodelstrainedondatasetswithsmallerσvaluesisthat
thesmallinterconnectedcomponentswithinthedatasetleadtoanunstablelearnedrepresentation,
makingitmoresensitivetofluctuationsduringoptimization. Thelearnedrepresentationofthemodel
corresponding to each data point shown in Fig. 6(d) are plotted in Fig. 15. As we can see, with
fewerdatapoints(smallerλ)andsmallerσ,thelearnedrepresentationhasalessrigidstructureas
comparedtothoselearnedwithmoredataandlargerσ’s. Furthermore,wenoticethatthetraining
andvalidationlossofthemodelgrowslinearlyasafunctionofthenumberoftrainingdata,asshown
inFig.14(c). Thissuggestthatwithalargersetofdata,themodelhaslessconfidenceinitslearned
representationduetothevastnumberofdataithastoaccommodatedespitelearningahigher-quality
representation. Givenasmallerdataset,themodelcaneasilyaccommodatealldatawithrelatively
smalltraining/validationlossesdespitelearningalow-qualityrepresentation.
22