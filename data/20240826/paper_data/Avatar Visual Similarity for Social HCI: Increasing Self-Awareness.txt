Avatar Visual Similarity for Social HCI: Increasing Self-Awareness
Bernhard Hilpert1,3,4, Claudio Alves da Silva2, Leon Christidis1, Chirag Bhuvaneshwara1,
Patrick Gebhard1, Fabrizio Nunnari1, and Dimitra Tsovaltzi1
1Affective Computing Group, German Research Center for Artificial Intelligence (DFKI)
2Saarland University
3LIACS, Universiteit Leiden
4Department of Computer Science, Vrije Universiteit Amsterdam
August 26, 2024
Abstract
Self-awareness is a critical factor in social human-human interaction and, hence, in social HCI interaction. Increasing self-
awareness through mirrors or video recordings is common in face-to-face trainings, since it influences antecedents of self-
awarenesslikeexplicitidentificationandimplicitaffectiveidentification(affinity). However,increasingself-awarenesshasbeen
scarcely examined in virtual trainings with virtual avatars, which allow for adjusting the similarity, e.g. to avoid negative
effects of self-consciousness [10]. Automatic visual similarity in avatars is an open issue related to high costs. It is important
tounderstandwhichfeaturesneedtobemanipulatedandwhichdegreeofsimilarityisnecessaryforself-awarenesstoleverage
the added value of using avatars for self-awareness. This article examines the relationship between avatar visual similarity
and increasing self-awareness in virtual training environments. We define visual similarity based on perceptually important
facial features for human-human identification and develop a theory-based methodology to systematically manipulate visual
similarityofvirtualavatarsandsupportself-awareness. Threepersonalizedversionsofvirtualavatarswithvaryingdegreesof
visualsimilaritytoparticipantswerecreated(weak,mediumandstrongfacialfeaturesmanipulation). Inawithin-subjectstudy
(N=33),wetestedeffectsofdegreeofsimilarityonperceivedsimilarity,explicitidentificationandimplicitaffectiveidentification
(affinity). Results show significant differences between the weak similarity manipulation, and both the strong manipulation
and the random avatar for all three antecedents of self-awareness. An increasing degree of avatar visual similarity influences
antecedentsofself-awarenessinvirtualenvironments.
1 Introduction
Self-awareness is a critical factor in social human-human interaction and, hence, in social HCI interaction.
Being aware of their own emotions and thoughts may allow users to reflect on and later adapt behavior. In
traditional training settings, self-awareness has been induced through methods of self-representation such
as mirrors or video recordings. However, with fast-paced developments in technology that facilitate newer,
more interactive, and immersive virtual training settings (e.g. [5]), the self-representation methods must
be adequately adapted. Avatars are virtual agents that act as representations of individuals and may be
controlled by a human. As such, they can be used as personalized awareness tools to increase self-awareness
and are often used in virtual environments such as online games, social media, and, more recently, in virtual
worlds [19]. The concept of virtual representation, or the use of avatars as a means of visual representation
in virtual environments, has gained significant attention in recent years [17]. Previous work has investigated
theuseofdigitalawarenesstoolstoincrease, especiallygroupsocialawareness[58,46,59,62]. However, the
use of avatars to increase self-awareness has been less investigated and has focused on supporting emotion
regulation in general settings [51] and in teacher professional development settings [36, 41]. Still, little is
1
4202
guA
32
]CH.sc[
1v48031.8042:viXraknown about how avatars can be used to differentially influence self-awareness for different purposes and
what the mechanism behind this influence is. Previous research on increasing self-awareness, concentrated
on using mirrors [8] and video recordings [8, 55] as external representations of oneself. The assumption
here is that the external representation needs to be similar to the individual. An avatar that is visually
similar to oneself, might create the same effect for virtual environments. An added value of avatars as
external representations is, that they act as ”bridges” to virtual worlds in the sense of mixed-reality or XR
[34], which can be used for immersive but adjustable interactions, beyond what is feasible in the real world
and at a low cost [32]. They also offer themselves for social interaction training, for instance for developing
empathyandconflictresolutionstrategies,inschoolcontextsandbeyond[15]. Inthesamesense,theavatars
themeselves can be adjusted to better serve the research or training purposes. One main aspect that has
drawnalotofattentionarepersonalizedavatars,atermthatreferstothevisualsimilaritytotheindividual.
But what degree of such visual similarity is most beneficial for increasing self-awareness, and how should
this similarity be defined?
There exists conflicting evidence regarding the degree of similarity needed and how similarity should be
defined. Some studies show that more similarity is good (e.g., [69]), while other studies and empirical
findings (e.g., uncanny valley) show too much similarity might have adversary effects [56]. A strongly
realistic (i.e., similar) avatar can, for example, be experienced as “rather heterogeneous or inharmonious to
the surrounding virtual environment” [30]. In order to examine further the effects of the avatar on a user,
we first need to understand which features influence perceived similarity and to be able to define how to
manipulate specific facial features of virtual avatars. This article therefore investigates, how we can define
the degree of similarity to be able to manipulate personalized avatars and increase self-awareness (RQ 1).
To this end, it extents and refines a technical methodology presented first in [2] to manipulate specific facial
featuresofvirtualavatarsbythedegreesofvisualsimilaritytotheuser. Further,thearticlealsocontributes
to defining the preconditions of increasing self-awareness with avatars (namely, perceived similarity as well
as explicit and implicit identification) to guide further research on topics involving avatar visual similarity.
Subsequently, we test the proposed methodology in a comprehensive user study with regard to its effects
on all three antecedents (RQ 2), examining to what extent the systematic manipulation of visual avatar
similarity influences perceived similarity (RQ 2.1) as well as explicit (RQ 2.2) and implicit identification
(RQ 2.3).
2 Theoretical Background
2.1 (Virtual) Emotion Regulation Trainings
Social interaction can be very emotionally challenging on a multitude of levels, especially when it comes to
conflict of interests and different socio-emotional perspectives. This challenge increases in multi-party and
multi-cultural interaction, like modern classrooms. Teachers find it hard and are often insufficiently trained
to deal with the integration of different cultural backgrounds and the socio-emotional conflicts that these
may give rise to. They need to adequately manage both heterogeneous learning groups with regard to the
taught content, and behavioral conflicts in class in order to secure a constructive learning environment and
supportstudentdevelopment[35,61]. Thiscanbeverystressfulandrequiresaneffectivecapacityforconflict
regulation [18], taking into account multiple student perspectives at once, without interrupting the ongoing
lesson. Students are sharp in perceiving subtle emotions and underlying aggression in teacher behavior,
and recursive teacher-student discussions disturb classroom conflict resolution [20]. Emotion regulation
strategiesthatcontributetoapositiveclassroomclimateinvolvereappraisal,asopposedtosuppression[29],
and self-compassion, which can support understanding and coping with one’s own and other’s emotions in
learning settings [41]. However, emotion regulation presupposes self-awareness [45]. Non-effortful implicit
emotional awareness (IEA, e.g. self-awareness) and effortful explicit emotional awareness (EEA, e.g. self-
compassion) jointly influence higher emotion regulation [24]. Misinterpreting students’ reactions occurs
more frequently between different cultural groups, where different modes of communication, especially non-
verbal, lead to confusion. When students express in an emotional way that they do not feel integrated into
2the class, like e.g. “You don’t tell me what to do”, teachers may often feel like their authority is being
questioned, or that they do not have the class under control. If they are self-aware, they may apply emotion
regulation strategies to combat these feelings of inadequacy, threat or shame effectively, and move on to
deal with the situation. Training teachers’ self-awareness and consequently emotion regulation can thus
improve subtle (non-)verbal behavior and conflict regulation without superimposing additional unnecessary
cognitive effort and stress. However, teacher training in realistic conflict situations and practicing in real
classrooms as a unique possibility [35] pose ethical risks. Mixed-reality trainings, implementing interactive
simulation technology [23, 21, 22] and socially interactive agents (SIAs) with positive effects on human
emotion regulation [52, 25] may offer a viable solution. They can provide a safe space to train situational
andself-awarenessandresultingconflictbehaviorthroughrealisticvirtualinteractions[53]. Astheybecome
more and more interactive and immersive, they allow users to interact as if they were in a real classroom,
and practice the handling of conflict situations. Further, they offer options for playback and natural social
interactive feedback (e.g., [5]) which can act as awareness tools to make users aware of their own behaviors
and others’ reactions and induce self-awareness by supporting reflection [60]. Despite these promises, many
questions on the psycho-social design of such environments require further investigation in order for these
promises to be held. One of these questions is the degree of avatar similarity conducive for self-awareness.
2.2 Self-Awareness, Similarity and Avatar Similarity
Mirrors[8]orcameras[55]arevalidatedwaystoinduceself-awareness. Self-relatedstimuli(e.g. ourownface)
are more relevant to us than stimuli related to others [7], and the sense of self is inherently linked to one’s
ownface[44]. InmodernVR-trainingsettingswherethefaceisusuallycoveredwiththeequipment,inducing
self-awarenessintraditionalwaysbecomesmoredifficult[43],asmirrorsorvideorecordingsarenotpossible.
Moreover, mixed-reality concepts involve the use of avatars that can cohabit a shared world with virtual
agents[40]. Totakethisintoconsideration,recentresearchintroducedtheuseofpersonalizedavatars. When
usingvisuallysimilaravatars, usersfeltsufficientlyself-represented[65]andemotionallyattached[26]tothe
stimuliandtheseavatarscouldincreasethelevelsofself-awarenessinusers[31]. Avatarsarevirtualbodiesor
vehiclesthatusersengagein,inordertointeractwithavirtualenvironment[17]. Inaddition,theyhavebeen
conceptualizedassymbolicrepresentationsofthefaceforcomputer-mediatedcommunication[16]. Similarity
between the avatar and the person can be achieved in a variety of ways. Some examples include matching
visualcharacteristicssuchashairandclothes[6,30], andmatchingormismatchingweight[42]. Thespecific
similarity between the user’s and, respectively, avatar’s face (subsequently called visual similarity) has been
of special importance for the increase of self-presence [3], body ownership, and even identification with the
avatar [30, 57]. Similarity can be either objective, when considering, for example, degrees of observable
similarities [49], or subjective, referring to the perceived similarity between two people. Perceived similarity
was found to have a higher impact on predicting self-awareness than observable similarity (i.e. similarity in
measurableterms)insomestudies(e.g. in[64]). However, thereisscarceliteratureonsimilarityforvisually
detailed and humanoid avatars. Moreover, most studies (e.g. [65, 3]) examine the effects of comparing
personalized versus a generic avatar. To the best of our knowledge, there is no previous work on varying
the degree of visual facial similarity systematically and testing the optimal degree of similarity to increase
self-awareness.
Toaddressthisgap, weproposeusingavatarsasvisualrepresentationsofhumanswhichofferthepossibility
to define a systematic manipulation and investigate visually detailed humanoid avatars as a possibility to
systematically manipulate their facial similarity. In section, 3, we present a methodology based on defining
facialcharacteristicsandhowtoembedtheirmanipulationinthewholeface. Giventheeffectsfoundinpast
literature presented above, we hypothesize, that our new method of manipulation of visual similarity will
induceamaineffectofavatar-personsimilaritymanipulationonperceivedsimilarity, comparedtoarandom
avatar.
Hypothesis 1: The avatar will be perceived as most similar in the condition, where the facial features were
not systematically manipulated and gradually less similar with an increasing degree of manipulation.
Asanextstepinexaminingtheeffectsofvisualavatarsimilarityonself-awareness,wedefinetherelationship
3between an individual and their virtual representation or online persona as a sense of identification. Cohen
[11] suggests that explicit identification is a two-stage process, with the first stage being the selection of
relevantvisualfeaturesandthesecondstagebeingthecomparisonofthosefeaturestostoredrepresentations
in memory. This process allows the recognition of familiar objects. Over a set of carefully constructed
studies, [65] found a significant correlation between avatar-person similarity and self-awareness, attributed
to triggering the same processes of self-representation as a mirror would. This type of identification occurs
because of a perception that characteristics and values are shared and is “a process or state of seeing oneself
as similar to, the same as, or fused with another object or person” [17]. Facial avatar-person similarity
has been shown to lead to a higher sense of self-presence [3] and self-identification [57]. Thus, given the
proposed manipulation of visual avatar-person similarity, we hypothesize, that there will be a main effect of
avatar-person similarity manipulation on explicit identification, compared to a random avatar.
Hypothesis 2: There will be higher explicit identification with the avatar in the condition, where the facial
features were not systematically manipulated, gradually declining with an increasing degree of manipulation.
Visual similarity is also a key aspect of implicit identification, as it involves the ability to recognize objects
thataresimilarinappearance,eveniftheyarenotidentical,andinfluencestheintentiontousetheavataras
wellasemotionalattachment[57]. Peopleidentifywiththeirin-gameavatarsiftheyhaveapositiveattitude
towards them [47] and find the avatar characteristics important to themselves [38]. Subsequently, visual
similarity has been shown to increase avatar appreciation (enjoyment, comfort, helpfulness) in users [13].
They tend to develop a sense of affinity towards their avatar, which can lead to increased self-disclosure and
more authentic interactions online [68]. Affinity can be described as natural liking “driven by subconscious
processes that are beyond conscious control” [54]. Affinity can also be related to the degree of attraction or
similaritybetweentwoormoreentities. Thereisasignificanteffectofperceivedvisualsimilaritybetweenan
avatar and the user on self-awareness [26, 27], which can be attributed to the personalized avatar triggering
emotions, beliefs and attitudes like affinity that facilitated identification. Thus, given the proposed manip-
ulation of visual avatar-person similarity, we hypothesize, that there will be a main effect of avatar-person
similaritymanipulationonimplicitaffectiveidentification,operationalizedasaffinity,comparedtoarandom
avatar.
Hypothesis3: Therewillbehigherimplicitaffectiveidentificationinthecondition,wherethefacialfeatures
were not systematically manipulated, gradually declining with an increasing degree of manipulation.
In conclusion, visual avatar-person similarity that influences both perceived similarity, explicit self-
identification as well as implicit affective identification with the avatar and could be used to elicit self-
awareness in human users in sophisticated interactive virtual training environments.
3 A Theory-Based Methodology
Inthissection,thetheory-baseddevelopmentofthemethodologytosystematicallyvaryvisualavatar-person
similarity is described.
3.1 Perceptual Sensitivity and the Selection of Facial Features
In cognitive science literature, a subset of critical facial features with high perceptual sensitivity (PS) has
been identified, which is described as the sensitivity to detect feature differences across faces and that are
crucialfordeterminingtheidentityoffaces(i.e. facerecognitionacrossdifferentimagesofthesameface)[1].
In a set of studies, facial features were adjusted in a systematic and quantitative manner within a so-called
”face-space”, and perceptual effects of these adjustments were measured to determine a subset of critical
features for which participants were found to show high perceptual sensitivity [1]. However, their research
manipulated specifically static 2D images. In our approach to transfer these findings to dynamic avatars,
the following five critical facial features were selected, based on [1]: Chin shape, jaw width, eye shape, lip
thickness, and nose shape. Beyond their importance for identification, the selection of these five features for
the process of avatar-person similarity manipulation was based on their technical feasibility to manipulate
4them in the open-access operationalization of the methodology discussed in Section 3.2.
3.2 Avatar Creation and Modification
In order to ensure the replicability of this work, we aimed to use exclusively openly accessible software tools
to create the different degrees of avatar-person similarity manipulation.
Previousstudiesapplieddifferenttechniquestoachievedifferentlevelsofavatar-personsimilarity. [30]created
avatars comprising a 3D mesh (a structural construction of a polygon-based 3D model), reconstructed from
real imagery of participants, towards a cartoon-like virtual character-based avatar created by a 3D artist.
Other studies used a 3D scan of the participant’s faces to create highly similar avatar faces [57], avatars
with a face that was modeled by a 3D artist after photographs [3], and online construction tools embedded
in applications or games such as Yahoo! [65] and Second-Life [26]. The present study was concerned with
a way to manipulate the avatar-self similarity by applying a scale on the same continuum, i.e. using the
same source of a most similar avatar and afterwards being able to vary from that most similar avatar in a
scale (e.g. see Table 1), manipulating PS effectively. Thus, a technical set-up that allowed for continuous
manipulation of each of the 5 selected high-PS facial features was selected.
Tocomplywiththeresearchgoalofcreatingvisuallydetailedhumanoidavatars,weselectedexistingsoftware
that allowed us to generate a realistic (i.e. high visual fidelity) 3D avatar from participant’s photos, and
then vary the appearance systematically according to differing degrees of similarity. Our selection criteria
included a) the possibility to manipulate specific facial features on a continuous scale, b) the possibility to
animate the created avatars (e.g. create short videos of facial movements) and c) a pragmatic approach
to only use tools, that are open-access, require minimal technical knowledge and a reasonable amount of
time and effort to create multiple avatars for each participant in order to make our methodology applicable
for other research teams as well. After considering a range of available software tools, FaceGen Modeller
Demo (facegen.com/modeller.htm) and MetaHuman Creator (metahuman.unrealengine.com) were selected
to be used in this study. Other tools were considered (e.g. in3D or MeInGame), but subsequently excluded,
because they did not fit the criteria above.
FaceGen Modeller Demo (subsequentlycalledFaceGen)isadesktopsoftwaretogenerate3Dheadsfromone
or more pictures. The ideal results are obtained from inputting three images (front, left, and right of the
face). FaceGenallowsmodifying150+parameterssuchasdemographics(age, gender, racialgroup), shapes,
colours, textures and individual facial features based on slide menus. Some of the limitations in regard to
this study include that it only generates a 3D model of a face (not including hair) and does not include
animation capabilities.
To compensate, we also used MetaHuman Creator, which is a free cloud-base app developed by Epic Games
to create 3D high-fidelity virtual avatars (including hair). The creation of avatars does not require artistic
modeling skills, since its 3D creation capabilities are also based on slide menus and interface controls.
Another advantage of MetaHuman for this scenario of the research is that it allows exporting the 3D avatar
to animation tools, which can be used to personalize facial animations including eye tracking.
3.3 Manipulation of Avatar-Person Similarity
Besides the challenge of creating a manipulable avatar most similar to a person, this research faced the
challenge of defining a methodology to vary the degree of similarity between the avatar and the user. As
elaborated in (Section 2.2), avatar-person similarity has usually been manipulated in the model of low
similarity being a generic avatar that might simply match gender, race and ethnicity, to high similarity by
matching clothes, or even the participant’s faces (e.g. [67]). However, with fast advancements in animation
technology[4]andtheriseofplatformsfortheiruselikee.g. theMetaverse(e.g.,[50,33]),creating”realistic”
personalized avatars and subsequently their similarity becomes relative to the technological progress. Even
more importantly, as this research aims to better understand on a process level how visual similarity affects
self-awareness and its antecedents in interactive virtual trainings, we aimed for a more fine-grained analysis
of visual similarity manipulation beyond a simple distinction between personalized vs. non-personalized.
5Table 1: Degrees of Similarity Manipulation
S M Description
High 0% Avatar face modeled from participants’ pictures (i.e. highly similar with 0% of ma-
nipulation of facial features)
Medium 50% Avatar face modeled from participant’s pictures, then applied a percentage of ma-
nipulation (50%) on selected facial features (chin shape, jaw width, eye shape, lip
thickness, nose shape).
Low 100% Avatar face modeled from participant’s pictures then applied a percentage of manip-
ulation (100%) on selected facial features (see above).
S =DegreeofSimilarity,M =DegreeofManipulation
To implement this, a scale was designed to guide the definition of the conditions for creating degrees of
similarity variations (i.e. a visual similarity scale, inspired by approaches taken by [39]) for this research
studythatservedasthebaselineforavatar-personsimilaritymanipulation(seeTable1). Thisapproachhas
the advantage that it can be continuously adapted to the requirements of other scenarios and generalized
to future developments and improvements in avatar creation technology, while still keeping the similarity
manipulation standardized and scientific.
Togeneratethemostsimilarfacialavatarstimuli(0%-condition),weuseMetaHumanCreator,byoverlaying
afrontfacephotoontheMetaHumanCreatorsurfaceandmanuallyadjustingthecontrolsuntilasatisfactory
outcome is reached (see Figure 1).
Figure 1: MetaHuman interface and a picture overlay demonstrating the manual creation process
Forthefacialmanipulationofthe50%-and100%-conditions,weuseFaceGenfirst,whichgenerates3Dfaces
from photos and offers modifiers in the form of sliders. FaceGen allows for the distinct manipulation of the
facial features on a scale from -10 to +10, with the tool automatically determining the participant’s facial
features’ scale-value based on their pictures (see Figure 2 for reference).
After FaceGen attributes the scale value for each feature based on the participant’s pictures (0% condition),
the facial variations are then calculated for each feature - (chin shape, jaw width, eye shape, lip thickness,
nose shape) and respective level of manipulation (50% and 100%). The direction of the similarity degree
manipulation in FaceGen (towards -10 or +10) was defined as the direction of the longest distance from the
scalevalueautomaticallydeterminedbyFaceGenuponuploadofthephotos. Forinstance,ifafaceanalyzed
by FaceGen (0% condition) points to a chin shape feature having the value of 0.58 in its scale (from -10 to
+10), the variations would be towards -10, which is the longest distance from 0.58. Using this example, the
manipulation of the chin shape for the 50% condition would result in updating the chin shape scale value
from0.58to-4.71(absolutedistancefrom0.58to-10dividedbytwominus0.58),andforthe100%condition
to -10, which is the longest possible distance from the original value, 0.58. An exception is made for the lip
6Figure 2: FaceGen interface
thickness feature, which was defined to always move in the positive direction (+10) to avoid deformations
on the face that would be impossible to reproduce on MetaHuman (i.e. unrealistic thinner lips sizes). Each
facialfeatureismanipulatedindividuallyonFaceGen, andeachresultingimageisexported. Thisrepresents
a FaceGen export of 10 images per participant (see Figure 3 for reference).
Figure 3: Samples of FaceGen facial manipulation parameters and outcomes
Asthelaststep,thefirstMetaHumanconditionmadefromtheparticipant’spictures(0%)istriplicatedand
each facial feature manipulation in MetaHuman for the 50% and 100% conditions is reproduced, following
the same process from the first condition to generate the variations by overlaying the exported FaceGen
images. Figure 4 illustrates the output of the different conditions from MetaHuman.
Figure 4: Original photo and the 0%-, 50%- and 100%- variations
4 User Study
In a first user study, the effects of the varying degrees of visual similarity manipulation on the antecedents
of self-awareness were examined. Following the recommendations for open research practices [12, 66], all
materials (coding plan, data and analysis code) can be found on OSF1. (Note: Due to anonymization, the
1https://osf.io/zfbjx/?view_only=cbec58b6ab38428aba43c778b511d97c
7data and analysis will be made public after the review process, as it contains information that would reveal
the authors’ nationality.)
4.1 Participants
The study was conducted with voluntary participants recruited via various online platforms. Participants
were required to be at least 18 years old, have access to a computer/mobile device with a camera, and have
a minimum level of English proficiency of B2 according to the Common European Reference Framework for
Languages(CEFR;CouncilofEurope2001). OfthetotalofN =88participants, n =55wereexcludeddue
to incomplete responses or not responding to the second email (1). The final sample of n = 33 consisted of
n = 13 males and n = 20 females between 18 and 40 years (M = 27.6 years, SD = 4.74 years). We offered
participants who completed the study the option of receiving a short video of their personalized avatar and
participating in a contest to win Amazon vouchers.
4.2 Study Design and Procedure
A within-subjects study was conducted fully online and used self-administered questionnaires delivered via
an online survey platform (limesurvey.org). In order to systematically test hypotheses 1-3, we used the
methodologydetailedinSection3, tosystematicallyvarythedegreeofsimilarity. Thus, thestudyconsisted
of four conditions: high, medium, and low similarity (see Table 1) plus one control group (CG). The study
was divided into two sessions, with an interval of 24 to 72 hours between them that corresponds to the time
consideredtogeneratethepersonalizedavatars. Themaindependentvariableswereperceivedavatar-person
similarity, explicit cognitive identification as well as implicit-emotional identification with the avatar.
In the first session, participants were asked to review introductory information about the study and sign
the consent form and data protection. Participants confirmed their eligibility by self-reporting their level of
English proficiency. If participants reported a proficiency level below the required level, they visualized a
message that thanked them for participating and ending the survey. Participants with the required profi-
ciency level preceded the survey by filling out a questionnaire that included data collection such as e-mail
address 2, three facial images (as required by FaceGen) and demographic data.
Oncethedataoftheparticipantsfromthefirstsurveywasreceived,theimageswereusedtocreatepersonal-
izedavatarstovaryingdegreesofsimilaritytothefacesoftheparticipants,asdescribedinSection3.3. Once
the avatars were created in MetaHuman, a 12 second-long GIF was created recording the predefined idle
facialanimationfromeachofthethreeconditions(0%, 50%and100%). Theidlefacialanimationcontained
simple facial movements of a natural human look.
Asthenextstep,wesetupthesecondsurveybyaddingtherecordingsofeachpersonalizedavatarcondition
in the form of animated images (GIF). The conditions and instruments were presented to the participants
in random order. The previous same-gender participant’s 0% avatars were used as a control condition. The
first two participants were presented with control-condition a male and female avatar was created ahead
from two volunteers’ pictures.
4.3 Measurements and Instruments
The instruments for collecting the data described in the study design section were the following.
Demographics: Participants were asked age and gender, level of formal education, the field and semester of
study / current profession. In addition, we collect participants’ affinity with technology, attachment style,
and previous experiences with avatars.
Perceived facial similarity between avatar and user: The subscale ’physical similarity’ from the polythetic
identification model [17], containing five items, was used to measure physical similarity (Hypothesis 1).
2E-mail addresses were saved in a separate dataset. The merging was done using a unique alphanumeric token. All data
thatcouldbeusedtoidentifyparticipantsweredeletedaftermergingwascomplete.
8ExplicitcognitiveIdentificationwiththeAvatar: Noexistingscalewasfoundtomeasureexplicitidentification
(Hypothesis 2). The self-created items were used on a seven-point Likert scale , which includes a question
based on the definition of identification by [17], ’If I look at the GIF, it feels like I am this avatar’, and two
questions from [63], ’I identify with this avatar’ and ’I feel represented by this avatar’.
Implicit-emotional Identification with the Avatar: Implicit-emotional Identification (Hypothesis 3) was op-
erationalizedastheaffinitytowardstheavatar. Weusedtheaffinityscalefrom[54]whichcontainsfiveitems
on a seven-point Likert scale.
Perceived Realism of the Avatar (Manipulation Check): We use a single item based on [30]: ’How realistic is
the avatar?’ on a seven-point Likert scale.
4.4 Data Analysis
Prior to conducting the analysis, we assessed the presence of potential outliers, identifying values that
exceed Q3 + 1.5xIQR or fall below Q1 - 1.5xIQR as outliers. A total of n=5 outliers were detected. On
examination, the scores of these outliers were found to be within the range of plausible data, with no
indication of measurement errors or inattention by the participants. Furthermore, analyses conducted using
both raw data and data excluding outliers yielded similar results. Consequently, we opted to retain the
outliers and present findings based on the complete data set.
We hypothesized that for all three tested constructs, there would be a significant main effect for condition,
with the most similar (0% condition) scoring highest for perceived similarity, explicit identification and
affinity. A repeated-measures ANOVA was used to examine the effect of condition (0%-, 50%-, 100%-
Manipulation,CG)oneachofthedependentvariablesindividually. Shapiro-TestfornormalityandMauchly’s
Test for sphericity both indicated violations. However, ANOVAs are rather robust against normality and
sphericity violations, see [28]. Upon closer examination of the data, we decided to keep the ANOVA as our
main analysis method. In order to ensure, the final reported result would not be biased by either the small
samplesizeortheviolationsinthepreconditions,weperformedanadditionalANOVAwithbootstrappingas
wellasaFriedmantestfornon-parametricdata. Sincetheseanalysesshowedidenticaleffects, wereportthe
ANOVAresultshere. However,allanalysesandresultscanbefoundintheadditionalonlinematerialofthis
article. Moreover, the reported results were corrected using the Greenhouse-Geisser method. Further, we
performedpost-hoct-teststoexaminethedifferencesbetweeneachconditionmoreclosely(Bonferroni-Holm
corrections were applied). Results are reported individually per construct.
As a manipulation check, we tested the perceived realism of the avatars with one item. While in the 0%-,
50% and the CG it was perceived as rather realistic, there was a significant main effect for realism with the
100%-condition having the lowest mean, indicating, that the avatar was seen as significantly less realistic.
Naturally, inahighlypersonalized(smallsample-size)studylikethis, individualdifferencesandattitudesof
participantsmayplayarole. Sincethemethodandtheresultsofthisstudywillserveasthefundamentfora
subsequentstudyseries,weadditionallyoptedforanin-depthexplorativeanalysis. Firstly,weexaminedthe
correlationsbetweenallthreedependentmeasuresandgender,realism,experiencewithavatars,affinitywith
technology and attachment style. In a second step, we performed several ANCOVAs to examine possible
confounding effects of the demographic variables. Data analyses were conducted with R version 4.2.3.
4.5 Results
The aim of this research in the context of data collection for the study was to validate the applicability of
the methodology developed and test its effects on selected antecedents of self-awareness. We hypothesized
that for all three tested constructs, there would be a significant main effect for condition, with the most
similar (0% condition) scoring highest for perceived similarity, explicit identification and affinity (implicit
identification).
All means and standard deviations can be found in Table 2.
94.5.1 Perceived Similarity
Hypothesis 1 examined the effect of the degree of avatar-person similarity manipulation (condition) on
perceived similarity. The ANOVA revealed a significant main effect for condition, F(1.87,59.72) = 10.13, p
<.001, η2 = .11. Subsequent comparisons did not show a significant effect between the 0%- (M = 3.34, SD
= 1.26) and the 50%-condition (M = 3.18, SD = 1.21), t(32) = 1.36, p = .183, as well as the CG, t(32) =
3.46, p = .008 and between the 100%-condition and the CG, t(32) = 2.14, p = .08. All other comparisons
showedasignificantdifference,showingasteadydeclineinsimilaritywithincreasingsimilaritymanipulation
(0% = highest - CG = lowest). This included significant effects between the 0%- and the 100%-condition
(M = 2.75, SD = 0.85), t(32) = 3.17, p <.013, as well as the CG (M = 2.44, SD = 0.73), t(32) = 3.83,
p = .003. Further, between the 50%- and 100%-condition, t(32) = 2.54, p = .049. Thus, H1 was partially
confirmed: Manipulation of avatar-person similarity influences the perceived similarity, except for the first
two degrees of manipulation (see Fig. 5).
Figure 5: Effects of similarity manipulation on perceived similarity. Dots (left) represent data points of
individual participants, violins (right) distribution within conditions
4.5.2 Explicit Identification
Hypothesis 2 examined the effect of the degree of avatar-person similarity manipulation (condition) on
explicit identification. The ANOVA revealed a significant main effect for condition, F(2.03,65.01) = 13.11,
p <.001, η2 = .13 Subsequent comparisons did not show a significant effect between the 0%- (M = 2.76, SD
=1.84)andthe50%-condititon(M =2.64,SD =1.72),t(32)=0.64,p =.527,orbetweenthe100%-(M =
1.82, SD =1.05)andtheCG(M =1.53, SD =0.67), t(32)=1.68, p =.206. Allothercomparisonsshowed
a significant difference, showing a decline in explicit identification with increasing similarity manipulation.
This included significant effects between the 0%- and the 100%, t(32) = 3.71, p = .002, as well as the CG,
t(32) = 4.05, p = .002. Further, between the 50%- and 100%, t(32) = 4.03, p = .002, as well as the CG,
t(32) = 4.16, p = .001. Thus, H2 was also partially confirmed: Manipulation of avatar-person similarity
influences also explicit identification, except for the first and last two degrees of manipulation (see Fig. 6).
4.5.3 Implicit Identification (Affinity)
Hypothesis 3 examined the effect of the degree of avatar-person similarity manipulation (condition) on
affinity. The ANOVA revealed a significant main effect for condition, F(2.2,70.44) = 7.66, p <.001 , η2 =
.05. Subsequent comparisons again did neither find a significant effect between the 0%- (M = 3.22, SD =
1.77) and the 50%-group (M = 3.08, SD = 1.72), t(32) = 0.95, p = .694, nor between the 100%- (M =
2.52, SD = 1.51) and the CG (M = 2.37, SD = 1.3), t(32) = 0.74, p = .694. However, all of the other
groupcomparisonsshowedasignificantdifference,showingadeclineinexplicitidentificationwithincreasing
similarity manipulation.
10Figure 6: Effects of similarity manipulation on explicit identification. Dots (left) represent data points of
individual participants, violins (right) distribution within conditions
This included significant effects between the 0%- and the 100%, t(32) = 3.30, p = .014, as well as the CG,
t(32) = 3.32, p = .014. Further, between the 50%- and 100%, t(32) = 3.17, p = .014, as well as the CG,
t(32) = 2.77, p = .028. Thus, H2 was again partially confirmed: Manipulation of avatar-person similarity
influences also explicit identification, except for the first and last two degrees of manipulation (see Fig. 7).
Figure 7: Effects of similarity manipulation on affinity. Dots (left) represent data points of individual
participants, violins (right) distribution within conditions
4.5.4 Exploratory in-depth analysis
In order to gather learnings for follow-up studies and future research, we performed an exploratory in-depth
analysis. As a first step, correlations between the dependent variables and the demographic variables were
examined. Results can be found in Table 2. In an additional analysis of covariances, we examined whether
the variables realism, gender and previous experience with an avatar played a role. The analysis indicated
an influence of the covariates in a type II ANCOVA, that did not show anymore when performing the type
III variant, but no significant effect was found overall. The exact parameters, R scripts and results of this
analysis can be found in the additional online material on OSF.
11Table 2: Means, standard deviations, and correlations with confidence intervals
Variable M SD 1 2 3 4 5 6
1 Similarity 2.93 1.08
2 IE 2.80 1.61 .82∗∗
[.76, .87]
3 EE 2.18 1.48 .84∗∗ .85∗∗
[.79, .89] [.79, .89]
4 Realism 4.44 1.68 .45∗∗ .51∗∗ .44∗∗
[.31, .58] [.38, .63] [.29, .57]
5 Attachment 2.85 0.40 .08 .24∗∗ .14 .26∗∗
[-.09, .25] [.08, .40] [-.03, .30] [.09, .41]
6 AfT 5.91 1.36 -.22∗ -.29∗∗ -.22∗ -.04 .09
[-.37, -.05] [-.44, -.12] [-.38, -.05] [-.21, .13] [-.09, .25]
7 Experience 1.76 0.43 .12 .10 -.01 .19∗ .22∗ -.04
[-.05, .29] [-.08, .26] [-.18, .17] [.02, .35] [.05, .38] [-.21, .13]
Note. MandSDareusedtorepresentmeanandstandarddeviation,respectively. EE=ExplicitIdentification. IE=Implicit
identification/Affinity. Attachment=Attachmentstyle. AfT=AffinityforTechnology. Experience=Previousexperience
withavatars. Valuesinsquarebracketsindicatethe95%confidenceinterval. Theconfidenceintervalisaplausiblerangeof
populationcorrelationsthatcouldhavecausedthesamplecorrelation[14]. *indicatesp<.05. **indicatesp<.01.
5 Discussion
This user study investigated the effect of manipulating specific facial features of virtual avatars by degrees
of visual similarity to the participants on perceived similarity of the avatar, as well as two antecedents of
self-awareness: explicit and implicit identification. The process of developing the methodology for avatar
similarity variation involved the investigation of tools and solutions, the testing of their functionalities, and
research on the theoretical background of aspects in which the methodology could be applied (i.e. visual
similarity, affinity, identification, etc). A similarity scale was defined, formalizing three degrees of similarity
variation (high similarity - 0%, medium similarity-50%, low similarity-100%). A user study was set up and
performedtovalidatetheapplicationoftheproposedmethodologyandtesttheeffectsofsystematicsimilarity
variation on the antecedents of self-awareness. Spefically, we hypothesized that a higher degree of visual
similarity would lead to higher perceived similarity as well as explicit and implicit identification/affinity.
The results of the study generally confirm these hypotheses.
5.1 User Study: Hypothesis Discussion
Manipulation check: All degrees except the 100%-manipulation were perceived as realistic. This lets us
assume that all effects, especially the ones between the 0%-, 50%- and CG, can be attributed to the manip-
ulation rather than an unnatural distortion of the participants’ faces.
H1: Manipulating visual avatar-person similarity using the developed methodology indeed showed an effect
on the similarity perceived by the user in the expected direction (confirming H1). This also serves as an
additionalmanipulationcheckforthefollowinganalyses. Singlecomparisonsrevealed,thattherewasasteady
decline in perceived similarity between degrees of manipulation, indicating that the approach of adjusting
specific facial features to manipulate the degree of similarity is suitable. This result provides an argument
againstgenericoraveragedavatars. Thedifferencebetween0%-and50%-manipulation,althoughobjectively
different, was not perceived as dissimilar. This effect could be explained if we assume that the manipulation
was still perceived too similar in the two conditions and gives future researchers and practitioners a bit of
an error margin to work with, in terms of manipulating visual similarity.
H2: Avatar-person similarity also showed an effect on the explicit identification by the user in the expected
12direction (confirming H2). Thus, the participants tended to identify more with an avatar, the more it was
objectively similar to them. While not particularly surprising, this result has important implications, given
that identification is one of the key antecedents in eliciting self-awareness. Examining the distributions of
answers between the four conditions closely, however, in the 0% and 50%-condition, a wide range of answers
was observable, compared to the other two conditions, where answers largely concentrated on the lower
end of the scale. Single comparisons revealed that there was a steady decline in explicit identification with
decreasing similarity. Taken together, these detailed analyses deliver a strong argument against generic,
non-personalized avatars whenever explicit identification with the avatar and self-awareness elicitation are
goals in the study. Here too, the difference between 0%- and 50%-manipulation did not have an effect on
explicit identification by the user, and neither did the difference between 100%-manipulation and the CG.
This effect could be explained assuming, that for a difference in identification, a small change in the avatar
seems not enough, while in the 100%-condition, the participants apparently did not recognize themselves
anymore(asfurtherindicatedbythesignificanteffectbetween50%-and100%-, butnot100%-manipulation
and CG). An interaction with the missing realism could be claimed here. However, the missing effect in
the CG, which was perceived as realistic, speaks against that. We can conclude that, in terms of explicit
identification, the right amount of similarity manipulation is important.
H3: Lastly, manipulating visual avatar-person similarity indeed showed an effect on implicit affective iden-
tification (affinity) in the expected direction. Apart from merely identifying with the avatar, participants
also rather created an emotional bond - an affinity - towards avatars that are more similar to them. Single
comparisons revealed the same pattern of effects between the conditions as in explicit identification, again
indicating, that, whenever affinity or self-awareness are to be elicited, using a generic avatar could be coun-
terproductive. Similarly, the difference between 0%- and 50%-manipulation did not produce an effect on
affinity, neither did the difference between 100%-condition and the CG. Again, a small change in avatar-
person similarity did not seem to affect the affection towards the avatar, while in the 100%-condition, the
participants apparently did not feel an emotional affinity anymore (as indicated by the sig effect between 50
and 100 but not 100 and CG).
Exploratory in-depth analysis: The dependent variables showed significant correlations between each other
as well as to possible demographic covariates such as realism, attachment style, affinity for technology and
previous experience with avatars. The former result was expected given the conceptual closeness of the
given constructs. Therefore, our results do show that the concepts are distinct but not disjoint. In order to
differentiate the relevant subtle differences between them, a fine-grained differentiation as presented in this
study is necessary. Naturally, in a highly-individualized setting like personal avatars, individual differences
and attitudes of participants may influence results. While we could find indications that the examined
covariates do play a role (comparison of type II vs. type III ANCOVA, see results in OSF), no significant
effects could be reported. This might be due to the fact that the manipulation and sample size of this
particular study were not explicitly set-up for this kind of analysis. However, reporting these indications is
still relevant, for them to be taken into account for future studies and implementations to avoid ”one-size-
fits-all” applications.
5.2 General Discussion
This research presents a novel approach using avatars in virtual environments as a tool to systematically
manipulate and test the effects of unavoidably induced self-awareness. One of the most challenging aspects
of this research relies on developing and implementing an approach to creating humanoid avatars that accu-
ratelyrepresent participants(RQ 1). The detailedreproducible step-by-stepdescription ofthemethodology
presented in this article was aimed at introducing a generalizable open-access approach of creating visually
similar avatars. It allows by design that avatars present dynamic features (being able to show facial expres-
sions through animations) and that such avatars could be easily manipulated to create variations of them
(degreesofsimilaritybetweentheavatarandtheuser). Oneofthemajoradvantagesoftheapproachchosen
in this work, is that it was all based on openly accessible tools, so the methodology could be easily adapted
forfutureresearchbyotherresearchteams. Theuserstudysuggeststhattheproposedmethodologyinclud-
13ing the definition of the manipulation of relevant facial features can be applied to vary visual avatar-person
similarity through facial feature manipulation (RQ 2). The presented results are in line with past research
indicating that avatar-person identification corresponds with perceived visual similarity. Further, as this
researchaimstoexaminetheeffectofvisualsimilarityontheelicitationofself-awarenessanditsantecedents
on a process level for its use in interactive virtual trainings, we aimed for a more fine-grained examination
of visual similarity manipulation beyond a simple distinction between personalized vs. non-personalized.
Compared to previous studies, this article examined in closer detail how avatar-person similarity is pro-
cessed by users and the effects it produces. Introducing this custom methodology revealed that perceived
similarity as well as explicit and implicit affective identification with virtual avatars are both dependent on
the degree of visual avatar-person similarity and highlighted, that generic avatars are insufficient for ma-
nipulations that depend on them, like self-awareness. As visual avatar-person similarity is correlated with
explicit identification [65] and affinity (i.e., liking persons perceived as similar) which both were found to
predict self-awareness [26, 27], next steps in future research might involve the identification and testing of
other aspects of similarity, such as behavioural contingency, to increase support self-awareness. Given that
self-awarenessandconsequently,self-compassionarekeyingredientsinreflectionandemotionregulation[24],
the effects of interactive virtual trainings such as [5], where teachers interact with interactive virtual agents
(students), could be amplified significantly by personalizing teacher avatars to increase their self-awareness.
These findings also have important implications for the design of virtual environments in the area of inter-
active virtual training environments in general, such as online educational games, simulations and virtual
worlds, where the use of avatars may be beneficial for training situations. This is especially important for
scenarios where constructs related to perceptions of the self, like self-awareness, self-compassion (and its
subcomponentslikemindfulness),butalsopresenceandimmersionareaimedat[9]. Similarly,inlightofour
in-depth analysis, the application of this method to virtual training environments should take into account
that in personalized settings like these, individual preconditions of the participants should be considered.
For example, given the correlation between attachment style and the dependent variables in this study, a
personalized style of animations as proposed in [48] might be an initial step in this direction.
On the practical side, these research findings are significant in light of the fact that many applications from
computer games to educational tools allow players to create and customize avatars. A special advantage of
the used methodology for the scenario of the research is that it allows exporting the 3D avatar to animation
tools, which can be used to personalize facial animations including eye tracking. Most importantly, this
research paves the way to automatic personalized behavior feedback [5, 2]. Further, the methodology was
designed in a way that can generalize to improvements in technology for avatar creation. With technology
evermore advancing, virtual representation is already starting to become a key ingredient in virtual reality
such as e.g. the Metaverse [37, 33] or mixed-reality applications e.g. with the Apple Vision Pro platform
[70]. The present study shows, how much of a difference for self-representation and immersion personalized
avatars could have. Future work is needed to examine this further.
5.3 Limitations and Future Work
The technical methodology for creating avatar variations was applied to a study that used animated facial
images (GIF) of avatars and it is possible that the results may differ from studies that require the use of
dynamic avatars containing the whole body. Equivalently, further research with dynamic avatars is needed
to validate the findings and explore the full potential of avatars as a means of increasing self-awareness.
Controlling for movement similarity must be considered in that case. Regarding the avatar generation, the
sample size of the study was relatively small, and further research is needed to replicate the results of the
methodology. For both of these limitations, a larger follow-up study is already running at this moment.
Another limitation is in regard to the limitations of the solutions that were used to create avatars and their
variations. Some of the visual characteristics (e.g. hair, beard, eyebrows format) have a limited amount of
pre-defined choices that might not match some participants’ features. Further, it might be the case that
when the low similarity condition was presented first in the study survey, it set the scene for the perception
of all avatars, and caused the participant to perceive them all as very different from themselves. However,
sincetheorderofpresentationoftheconditionswasrandomized,abiasingoftheresultsthroughthisspecial
14caseisratherunlikely. Moredataneedstobecollectedtovalidatethatlimitation. Futureresearchapplying
this methodology for manipulating perceived similarity, explicit identification or affinity should take into
account that this manipulation has to be made large enough in order to actually make a difference. Finally,
future research should consider applied research scenarios to validate the methodology for other effects
measurements when considering avatar-person similarity. As such, a series of follow-up studies is currently
in the phase of data collection, applying personalized avatars created through the presented methodology in
an interactive mixed-reality classroom training environment [5]. This will show whether the effects found in
this study will replicate in an applied, dynamic and interactive setting.
6 Conclusion
This article presents a theory-based methodology to manipulate the facial features of virtual avatars by
degrees of visual similarity with the aim of affecting perceived similarity to the user (RQ 1). We evaluated
this methodology and showed the effect of manipulating the degree of visual avatar-person similarity on the
antecedents for increasing self-awareness with avatars, namely, perceived similarity, explicit identification
and implicit identification/affinity (RQ 2).
In this work, we aimed for a fine-grained examination of visual similarity manipulation beyond a simple
distinction between personalized vs. non-personalized avatars. Our results underline that in scenarios in
whichconstructsrelatedtoperceptionsoftheself,likeself-awareness,self-compassion(andmindfulness),but
also presence and immersion are aimed at, generic avatars might not be enough providing a foundation for
futureworkinthisarea. Therefore,itiscrucialforfutureHCIresearchtoconsidermorenuancedapproaches
to visual similarity manipulation in these scenarios to achieve better outcomes. This work contributes to
the research on increasing awareness and paves the way for the automatic generation of similar avatars.
It is important to note that although the results of the study showed that the highest, albeit not perfect,
avatar visual similarity is conducive to antecedents of awareness, it is still possible that this effect depends
on individual differences, e. g. trait self-consciousness [10]. Automatically manipulating and adapting the
degreeofavatarvisualsimilarity,canbeusedtosupportself-awarenessinvirtualenvironments,whiletaking
into account individual differences. Additionally, this research enables to variably manipulate the behaviour
of the personalised avatar for self-awareness in immersive virtual environments, for instance to train for
further behavioural change.
Acknowledgements
MITHOS:ThisworkwasfundedbytheGermanFederalMinistryofEducationandResearch: 16SV8687. We
thank Joanna Mauer, Tobias Lang, Anna Lea Reinwarth, Janet Wessler, Tanja Schneeberger and Benedikt
Wirth for their help with this study.
References
[1] Abudarham, N., and Yovel, G. Reverseengineeringthefacespace: Discoveringthecriticalfeatures
for face identification. Journal of Vision 16, 3 (2016), 40–40.
[2] Alves da Silva, C., Hilpert, B., Bhuvaneshwara, C., Gebhard, P., Nunnari, F., and Tso-
valtzi, D. Visual similarity for socially interactive agents that support self-awareness. In Proceedings
of the 23rd ACM International Conference on Intelligent Virtual Agents (2023), pp. 1–3.
[3] Aymerich-Franch, L., Kizilcec, R. F., and Bailenson, J. N. The relationship between virtual
self similarity and social anxiety. Frontiers in human neuroscience 8 (2014), 944.
[4] Basak, S., Corcoran, P., McDonnell, R., and Schukat, M. 3d face-model reconstruction from
a single image: A feature aggregation approach using hierarchical transformer with weak supervision.
Neural Networks 156 (2022), 108–122.
15[5] Bhuvaneshwara, C., Anglet, M., Hilpert, B., Chehayeb, L., Meyer, A.-K., With-
anage Don, D., Tsovaltzi, D., Gebhard, P., Biermann, A., Auchtor, S., Lauinger, N.,
Kaiser, A., Kersting, F., and Mehlmann, G. Mithos-mixed reality interactive teacher training
system for conflict situations at school. In Proceedings of the International Society of the Learning
Sciences (2023).
[6] Birk, M. V., Atkins, C., Bowey, J. T., and Mandryk, R. L. Fostering intrinsic motivation
through avatar identification in digital games. In Proceedings of the 2016 CHI conference on human
factors in computing systems (2016), pp. 2982–2995.
[7] Bre´dart, S., Delchambre, M., and Laureys, S. Short article: One’s own face is hard to ignore.
Quarterly journal of experimental psychology 59, 1 (2006), 46–52.
[8] Carver, C. S., and Scheier, M. F. Self-focusing effects of dispositional self-consciousness, mirror
presence, and audience presence. Journal of personality and social psychology 36, 3 (1978), 324.
[9] Chandrasiri, A., Collett, J., Fassbender, E., and De Foe, A. A virtual reality approach to
mindfulness skills training. Virtual Reality 24 (2020), 143–149.
[10] Chehayeb,L.,Tsovaltzi,D.,Arora,R.,andGebhard,P.Individualdifferencesandthefunction
ofemotionsinsocio-emotionalandcognitiveconflict: Ifanagentshamesyou,willyoustillbebored? In
2021 9th International Conference on Affective Computing and Intelligent Interaction Workshops and
Demos (ACIIW) (2021), IEEE, pp. 1–8.
[11] Cohen, J. Defining identification: A theoretical look at the identification of audiences with media
characters. Mass communication & society 4, 3 (2001), 245–264.
[12] Collaboration, O. S. Estimating the reproducibility of psychological science. Science 349, 6251
(2015), aac4716.
[13] Cui, J., Aghajan, Y., Lacroix, J., van Halteren, A., and Aghajan, H. Exercising at home:
Real-time interaction and experience sharing using avatars. Entertainment Computing 1, 2 (2009),
63–73.
[14] Cumming, G. The new statistics: Why and how. Psychological science 25, 1 (2014), 7–29.
[15] Dalinger, T., Thomas, K. B., Stansberry, S., and Xiu, Y. A mixed reality simulation offers
strategic practice for pre-service teachers. Computers & Education 144 (2020), 103696.
[16] Donath, J. Mediated faces. In Cognitive Technology (2001), pp. 373–390.
[17] Downs, E., Bowman, N. D., and Banks, J. A polythetic model of player-avatar identification:
Synthesizing multiple mechanisms. Psychology of popular media culture 8, 3 (2019), 269.
[18] Duarte, J., and Pinto-Gouveia, J. Empathy and feelings of guilt experienced by nurses: A cross-
sectional study of their role in burnout and compassion fatigue symptoms. Applied Nursing Research
35 (2017), 42–47.
[19] Fox, J., and Ahn, S. J. Avatars: portraying, exploring, and changing online and offline identities. In
Handbook of research on technoself: identity in a technological society. IGI Global, 2013, pp. 255–271.
[20] Frenzel,A.C.,Daniels,L.,andBuric´,I.Teacheremotionsintheclassroomandtheirimplications
for students. Educational Psychologist 56, 4 (2021), 250–264.
[21] Gebhard,P.Alma: alayeredmodelofaffect.InProceedingsofthefourthinternationaljointconference
on Autonomous agents and multiagent systems (2005), pp. 29–36.
[22] Gebhard, P., Schneeberger, T., Baur, T., and Andre´, E. Marssi: Model of appraisal, reg-
ulation, and social signal interpretation. In Proceedings of the 17th International Conference on Au-
16tonomous Agents and Multi-Agent Systems (2018), International Foundation for Autonomous Agents
and Multiagent Systems, pp. 497–506.
[23] Greenwald, S. W., Kulik, A., Kunert, A., Beck, S., Fro¨hlich, B., Cobb, S., Parsons,
S., Newbutt, N., Gouveia, C., Cook, C., et al. Technology and applications for collaborative
learning in virtual reality. In International Society of the Learning Sciences. (2017).
[24] Gyurak, A., Gross, J. J., and Etkin, A. Explicit and implicit emotion regulation: A dual-process
framework. Cognition and emotion 25, 3 (2011), 400–412.
[25] Hilpert, B., Gebhard, P., and Schneeberger, T. Employing virtual agents for building trust in
driving automation: A qualitative pilot study. In Workshop on Robo-Identity: Artificial identity and
multi embodiment at the 16th International Conference on Human-Robot Interaction (HRI’21) (2021).
[26] Hooi, R., and Cho, H. Being immersed: avatar similarity and self-awareness. In Proceedings of the
24th Australian Computer-Human Interaction Conference (2012), pp. 232–240.
[27] Hooi, R., and Cho, H. Avatar-driven self-disclosure: The virtual me is the actual me. Computers in
Human Behavior 39 (2014), 20–28.
[28] Ito, P. Robustness of anova and manova test procedures. Handbook of statistics 1 (1980), 199–236.
[29] Jiang, J., Vauras, M., Volet, S., and Wang, Y. Teachers’ emotions and emotion regulation
strategies: Self- and students’ perceptions. Teaching and Teacher Education 54 (2016), 22–31.
[30] Jo, D., Kim, K., Welch, G. F., Jeon, W., Kim, Y., Kim, K.-H., and Kim, G. J. The impact
of avatar-owner visual similarity on body ownership in immersive virtual reality. In Proceedings of the
23rd ACM Symposium on Virtual Reality Software and Technology (2017), pp. 1–2.
[31] Kang, H., and Kim, H. K. Myavatarandtheaffirmedself: Psychologicalandpersuasiveimplications
of avatar customization. Computers in Human Behavior 112 (2020), 106446.
[32] Ke, F., Lee, S., and Xu, X. Teaching training in a mixed-reality integrated learning environment.
Computers in Human Behavior 62 (2016), 212–220.
[33] Kim, D. Y., Lee, H. K., and Chung, K. Avatar-mediated experience in the metaverse: The impact
of avatar realism on user-avatar relationship. Journal of Retailing and Consumer Services 73 (2023),
103382.
[34] Kocur, M., Sehrt, J., Schwind, V., and Henze, N. Designinginteractiveavatarsformixedreality
applications. Tutorial at Mensch und Computer (MuC’22). https://doi. org/10.18420/muc2022-mci-
tut03-408 (2022).
[35] Krause, A., Dorsemagen, C., and Baeriswyl, S. Zur Arbeitssituation von Lehrerinnen und
Lehrern: Ein Einstieg in die Lehrerbelastungsund-gesundheitsforschung. Springer, 2013.
[36] Kunter, M., Baumert, J., and Blum, W. Professionelle Kompetenz von Lehrkr¨aften: Ergebnisse
des Forschungsprogramms COACTIV. Waxmann Verlag, 2011.
[37] Lawrence, J., Pan, Y., Goldman, D. B., McDonnell, R., Robillard, J., O’Sullivan, C.,
Sheikh, Y., Zollhoefer, M., andSaragih, J. Stateoftheartintelepresence. InACMSIGGRAPH
2022 Courses (2022), pp. 1–74.
[38] Mayhew, M. G., Gardner, J., and Ashkanasy, N. M. Measuring individuals’ need for identifica-
tion: Scale development and validation. Personality and Individual Differences 49, 5 (2010), 356–361.
[39] Park, H., Brown, S., and Chu, S. L. Understanding avatar identification through visual similarity
forricherstorycreation. InHCIInternational2019-Posters: 21stInternationalConference, HCII2019,
Orlando, FL, USA, July 26–31, 2019, Proceedings, Part II 21 (2019), Springer, pp. 423–431.
17[40] Park, J., and Ogle, J. P. How virtual avatar experience interplays with self-concepts: the use of
anthropometric 3D body models in the visual stimulation process. Fashion and Textiles 8, 1 (2021).
[41] Park,S.,andTsovaltzi,D.Implicitandexplicitemotionregulationforconflictresolution: Narrative
and self-compassion as anti-bullying training. In Proceedings of the 16th International Conference of
the Learning Sciences-ICLS 2022, pp. 187-194 (2022), International Society of the Learning Sciences.
[42] Pen˜a,J.,Khan,S.,andAlexopoulos,C.Iamwhatisee: Howavatarandopponentagentbodysize
affectsphysicalactivityamongmenplayingexergames. Journal of Computer-Mediated Communication
21, 3 (2016), 195–209.
[43] Petrocchi, N., Ottaviani, C., and Couyoumdjian, A. Compassion at the mirror: Exposure to
a mirror increases the efficacy of a self-compassion manipulation in enhancing soothing positive affect
and heart rate variability. The Journal of Positive Psychology 12, 6 (2017), 525–536.
[44] Porciello, G., Holmes, B. S., Liuzza, M. T., Crostella, F., Aglioti, S. M., and Bufalari,
I. Interpersonal multisensory stimulation reduces the overwhelming distracting power of self-gaze:
psychophysical evidence for ‘engazement’. Scientific Reports 4, 1 (2014), 6669.
[45] Price, C. J., and Hooven, C. Interoceptive awareness skills for emotion regulation: Theory and
approach of mindful awareness in body-oriented therapy (MABT). Frontiers in Psychology 9, MAY
(2018), 1–12.
[46] Puhl, T., Tsovaltzi, D., and Weinberger, A. A long-term view on learning to argue in facebook:
Theeffectsofgroupawarenesstoolsandargumentationscripts. InInternational Society of the Learning
Sciences (2015).
[47] Rahill, K. M., and Sebrechts, M. M. Effects of avatar player-similarity and player-construction
on gaming performance. Computers in Human Behavior Reports 4 (2021), 100131.
[48] Reinwarth, A. L., Schneeberger, T., Nunnari, F., Gebhard, P., Altmann, U., and
Wessler, J. Look what i made it do-the modelit method for manually modeling nonverbal behav-
ior of socially interactive agents. In Companion Publication of the 25th International Conference on
Multimodal Interaction (2023), pp. 200–204.
[49] Rogers, E. M., and Bhowmik, D. K. Homophily-heterophily: Relational concepts for communica-
tion research. Public opinion quarterly 34, 4 (1970), 523–538.
[50] Salagean, A., Crellin, E., Parsons, M., Cosker, D., and Stanton Fraser, D. Meeting
your virtual twin: Effects of photorealism and personalization on embodiment, self-identification and
perception of self-avatars in virtual reality. In Proceedings of the 2023 CHI Conference on Human
Factors in Computing Systems (2023), pp. 1–16.
[51] Schneeberger, T., Gebhard, P., and Tsovaltzi, D. Exhail: Explicit and implicit emotion regu-
lation training with a social agent. In Proceedings of the International Society of the Learning Sciences
(2018).
[52] Schneeberger, T., Sauerwein, N., Anglet, M. S., and Gebhard, P. Stress management train-
ing using biofeedback guided by social agents. In 26th International Conference on Intelligent User
Interfaces (New York, NY, USA, 2021), IUI ’21, Association for Computing Machinery, p. 564–574.
[53] Schneeberger, T., Scholtes, M., Hilpert, B., Langer, M., and Gebhard, P. Can social
agents elicit shame as humans do? In Int. Conf. on Affective Computing and Intelligent Interaction
(2019), IEEE, pp. 164–170.
[54] Seymour, M., Yuan, L. I., Dennis, A., Riemer, K., et al. Have we crossed the uncanny val-
ley? understanding affinity, trustworthiness, and preference for realistic digital humans in immersive
environments. Journal of the Association for Information Systems 22, 3 (2021), 9.
18[55] Silvia, P. J., and Phillips, A. G. Self-awareness, self-evaluation, and creativity. Personality and
Social Psychology Bulletin 30, 8 (2004), 1009–1017.
[56] Stein, J. P., and Ohler, P. Venturing into the uncanny valley of mind—The influence of mind
attribution on the acceptance of human-like characters in a virtual reality setting. Cognition 160, May
2018 (2017), 43–50.
[57] Suh, K.-S., Kim, H., and Suh, E. K. Whatifyouravatarlookslikeyou? dual-congruityperspectives
for avatar use. MIs Quarterly (2011), 711–729.
[58] Tsovaltzi, D., Bodemer, D., Erkens, M., Heimbuch, S., Puhl, T., Schnaubert, L., and
Weinberger, A. Effects of explicit and implicit guidance on external and self-regulation through
conflict awareness. In Book of Abstracts EARLI 2017 (2017).
[59] Tsovaltzi, D., Dutta, N., Puhl, T., and Weinberger, A. Group and individual level effects of
supporting socio-cognitive conflict awareness and its resolution in large sns discussion groups: A social
network analysis. In International Society of the Learning Sciences. (2017).
[60] Tsovaltzi, D., Dutta, N., Puhl, T., and Weinberger, A. Group and individual level effects of
supporting socio-cognitive conflict awareness and its resolution in large sns discussion groups: A social
network analysis. In Computer-Supported Collaborative Learning Conference, CSCL (2017), vol. 1,
pp. 247–254.
[61] Tsovaltzi, D., and Makhkamova, A. The influence of compassion and self-compassion on
perspective-taking and conflict resolution in learning contexts. In International Society of the Learning
Sciences (ISLS) (2020).
[62] Tsovaltzi, D., Puhl, T., Judele, R., and Weinberger, A. Group awareness support and ar-
gumentation scripts for individual preparation of arguments in facebook. Computers & Education 76
(2014), 108–118.
[63] Van Looy, J., Courtois, C., and De Vocht, M. Player identification in online games: Validation
of a scale for measuring identification in mmorpgs. In Proceedings of the 3rd International Conference
on Fun and Games (2010), pp. 126–134.
[64] Vasalou, A., and Joinson, A. N. Me, myself and i: The role of interactional context on self-
presentation through avatars. Computers in human behavior 25, 2 (2009), 510–520.
[65] Vasalou, A., Joinson, A. N., and Pitt, J. Constructing my online self: avatars that increase self-
focused attention. In Proceedings of the SIGCHI conference on Human factors in computing systems
(2007), pp. 445–448.
[66] Wessler, J., Schneeberger, T., Hilpert, B., Alles, A., andGebhard, P. Empiricalresearchin
affective computing: an analysis of research practices and recommendations. In 2021 9th International
Conference on Affective Computing and Intelligent Interaction (ACII) (2021), IEEE, pp. 1–8.
[67] Yee, E. C. Facial similarity and player-avatar identification. Master’s thesis, Nanyang Technological
University, 2021.
[68] Yee, N. The psychology of massively multi-user online role-playing games: Motivations, emotional in-
vestment,relationshipsandproblematicusage. Avatars at work and play: Collaboration and interaction
in shared virtual environments (2006), 187–207.
[69] Yee, N., and Bailenson, J. The proteus effect: The effect of transformed self-representation on
behavior. Human communication research 33, 3 (2007), 271–290.
[70] Zhang, Z., Mateu, L. G. G., and Fort, J. M. Apple vision pro: a new horizon in psychological
research and therapy. Frontiers in psychology 14 (2023).
19