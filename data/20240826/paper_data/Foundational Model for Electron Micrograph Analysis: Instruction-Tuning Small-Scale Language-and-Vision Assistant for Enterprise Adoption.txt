Foundational Model for Electron Micrograph Analysis: Instruction-Tuning
Small-Scale Language-and-Vision Assistant for Enterprise Adoption
SakhinanaSagarSrinivas1 ChidakshRavuru2 GeethanSannidhi3 VenkataramanaRunkana1
Abstract consumerelectronics,automotivetechnologies,andspace
Semiconductor imaging and analysis are criti- applications.Miniaturizationiscrucialtothesemiconductor
cal yet understudied in deep learning, limiting industry,enablingthecreationofsmaller,morepowerful,
our ability for precise control and optimization andmoreefficientdevicesthatadvancethecapabilitiesand
insemiconductormanufacturing. Weintroduce functionalityofelectronicproducts. However,thispursuit
a small-scale multimodal framework for ana- faceschallengesthatrequireprecisionandcontroltoensure
lyzing semiconductor electron microscopy im- system-levelperformanceandovercomingmanufacturing
ages (MAEMI) through vision-language instruc- inaccuracies. Totackletheseobstacles,theindustrylever-
tiontuning.Wegenerateacustomizedinstruction- agessophisticatedimagingtechniquesforthoroughtesting
following dataset using large multimodal mod- and analysis. The relentless pursuit of miniaturization in
elsonmicroscopicimageanalysis. Weperform semiconductormanufacturingdemandsanever-increasing
knowledgetransferfromlargertosmallermod- focus on achieving nanoscale precision. Advanced tools,
els through knowledge distillation, resulting in suchasscanningelectronmicroscopy(SEM)andtransmis-
improvedaccuracyofsmallermodelsonvisual sion electron microscopy (TEM), play a vital role in the
questionanswering(VQA)tasks. Thisapproach semiconductor industry’s push for precision. These elec-
eliminatestheneedforexpensive,humanexpert- tron beam instruments offer high-resolution micrographs
annotateddatasetsformicroscopicimageanalysis (microscopic images), revealing intricate details of semi-
tasks. Enterprisescanfurtherfine-tuneMAEMI conductormaterialsandstructuresatthenanoscale. Their
ontheirintellectualdata,enhancingprivacyand sophisticated imaging capabilities are crucial for quality
performance on low-cost consumer hardware. control, including failure analysis, allowing precise char-
OurexperimentsshowthatMAEMIoutperforms acterizationofmicrostructures. Asindispensableassetsin
traditional methods, adapts to data distribution ensuringsemiconductorsconformtodesignspecifications,
shifts,andsupportshigh-throughputscreening. these tools help enable subsequent process optimization
1.Introduction ordesignadjustmentstomitigatedefects. Characterizing
Semiconductors,crucialformodernelectronics:,undergoa materialsatthenanoscaleiscriticaltodrivingongoingtech-
complexmulti-stepproductionprocess. Fablessfirmssuch nologicalprogress. However,currenttechnologyfallsshort
asQualcommandNVIDIAdesignandsimulatechipfunc- ineffectivelyaddressingthefullspectrumofcomplexities
tionalities,whilemanufacturingisoutsourcedtofoundries andspecializedrequirementsformaterialcharacterization
likeTSMCandSamsung. Foundrieshandlesemiconductor inthesemiconductorindustry, particularlyinaccuratela-
chipfabrication,whichincludesphotolithographytoimprint beling and analysis of electron micrographs. Therefore,
circuit patterns on silicon wafers, etching and doping for recentadvancementsinArtificialIntelligence(AI),includ-
circuitformation,andintricatelayeringforcircuitintercon- ingLargeMultimodalModels(LMMs)likeGemini(Team
nection. Afterfabrication,chipsundergoqualityassurance, etal.,2023)andGPT-4TurbowithVision(OpenAI,2023),
including electrical and stress testing, to confirm perfor- whichcombineadvancednaturallanguageprocessingwith
manceanddefect-freestatus. Packagedsemiconductorsare visualunderstandingcapabilities,cansignificantlyimpact
assembledintodeviceslikemicroprocessorsandmemory thesemiconductormanufacturingprocessinseveralways.
chips, integrated into various electronic systems, such as These vision-language models allow for the analysis of
high-resolution electron micrographs, revealing intricate
1TCS Research, Bangalore 2IIT Dharwad 3IIIT nanoscalestructuresofsemiconductormaterials. Byidenti-
Pune. Correspondence to: Sakhinana Sagar Srinivas
fyingandprovidinginsightsintopatterns,themultimodal
<sagar.sakhinana@tcs.com>.
largelanguagemodelsenablequalitycontrolandimprove
Published at ICML 2024 Workshop ML for Life and Material theprecisionandefficiencyofsemiconductormanufactur-
Science:FromTheorytoIndustryApplications,Vienna,Austria ing. Whileproprietary,general-purposeLMMsofferben-
2024.Copyright2024bytheauthor(s).
1
4202
guA
32
]VC.sc[
1v84231.8042:viXraInstruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
efits, their adoption faces challenges due to concerns re- performance comparable to larger models through trans-
gardingsharingenterprisedata. Sharingsensitiveinforma- fer learning, all while decreasing computational require-
tionwiththird-partyservicescouldexposenoveldesigns ments. Itfollowsa‘teaching-via-data‘methodandutilizes
andprocesses,underminingsemiconductorfirms’intellec- state-of-the-art,vision-languagemodelstogeneratecustom
tualpropertyportfolioandjeopardizingfutureinnovation. instruction-following data on niche tasks to train smaller
Conversely, open-source, small-scalemultimodalmodels modelsfortask-specificadaptation,avoidingtheneedfor
(SMMs)likeLLaVA(Liuetal.,2023)andMiniGPT-4(Zhu human-annotateddata. Ourapproachempowersenterprises
et al., 2023) can be more cost-effective for task-specific tofine-tunesmall-scale,pre-trainedmultimodalmodelson
customizationonmicroscopicimageanalysis,enablingsafe, theirowndatawithintheirinfrastructure,enhancingprivacy,
reliable,on-premisesenterpriseadoption. Thesmallermul- security,andreducingcomputationalcosts,whileimprov-
timodalmodelsofferbetterinterpretabilityduetotheiropen- ingtheirabilitytorespondtocomplexmultimodalinputs.
sourcenature. However,theymaynotmatchthereasoning Overall, it offers a promising solution to the limitations
andgeneralizationcapabilitiesofproprietaryLMMs,some- of existing proprietary LMMs, potentially democratizing
timesproducinglesscoherentandcontextuallyrelevantout- accesstotheirhigh-endcapabilitiesandacceleratingtheir
puts.Inaddition,generatinghigh-qualitytrainingdatasetsis adoptionacrossawiderangeoftasks. Toaddressthechal-
crucialforcustomizingSMMsformicroscopicimageanaly- lenges of privacy concerns, scarcity of high-quality data,
sis,butacquiringsuchdatasetsisscarceandexpensive. The andsmall-scalemodelsgeneralizationandinterpretability,
annotationprocessrequiresexpertknowledgeandspecial- ourstudyintroducesanovelapproachcalled‘On-Premises
izedtools,makingittime-consumingandresource-intensive. SecureMultimodalInstructionTuningofSMMs’. Thisap-
Additionally,thediverseimagecharacteristicsandrepresen- proachenablesSMMstoachieveperformancecomparable
tationsresultingfromthedifferentimagingtechniquespose tolargermodelsthroughtransferlearning,whiledecreas-
asignificantchallengetodevelopingageneralizablemul- ingcomputationalrequirements. Itfollowsa‘teaching-via-
timodalmodelthatcanperformeffectivelyacrossvarious data’methodandutilizesstate-of-the-art,vision-language
electronmicrograph-baseddatasets. Furthermore,electron models to generate custom instruction-following data on
micrograph-basedimage-captioningandopen-endedVQA niche tasks. This synthetic data is used to train smaller
tasksarepromisingbutchallengingduetocompleximage modelsfortask-specificcustomization,avoidingtheneed
characteristics,suchashighintra-classdissimilarity,high forhuman-annotateddata. Ourapproachempowersenter-
inter-classsimilarity,andspatialheterogeneity(referFig- prisestofine-tunesmaller,pre-trainedmodelsontheirown
ure1). Thesecomplexitiesposeobstaclestoaccurateimage datawithintheirinfrastructure,enhancingprivacy,security,
understandingandquestionanswering. and reducing computational costs, while improving their
abilitytorespondtocomplexmultimodalinputs. Overall,
it offers a promising solution to the limitations of exist-
ing proprietary LMMs, potentially democratizing access
to their high-end capabilities and accelerating their adop-
(a)Highintra-dissimilarityinelectronmicrographsofMEMS tionacrossawiderangeoftasks. Inthiswork,wepresent
devices.
theMultimodalAssistantforElectronMicrographAnalysis
(MAEMI), an end-to-end trained, small-scale multimodal
modeldesignedformicroscopicimageanalysis. Weutilize
visual-languageinstructiontuningtocustomizeMAEMIon
(b)Highinter-classsimilarityinelectronmicrographsofvar- microscopicimageanalysisusingGPT-4-TurbowithVision
ious nanomaterials: powders, films, porous structures, and generatedhigh-fidelitymultimodallabeleddata,eliminat-
particles.
ingtheneedforadditionalhumanannotationefforts. The
generated instruction-following dataset comprises image-
question-answer pairs that delve into various aspects of
nanomaterialsinmicroscopicimages,createdbyprompting
a large-scale, pre-trained multimodal model (like GPT-4
(c)Spatialheterogeneityofunevensizedistributioninnanopar-
ticlemicrographs. TurbowithVision)withtask-specificinstructionsbasedon
thetargetmicroscopicimages. Thehigh-qualitygenerated
Figure1.Challengesinanalyzingelectronmicrographsfromthe
SEMdataset(Aversaetal.,2018). datasettrainstheproposedframeworktoanalyzeelectron
microscopyimagesofnanomaterials,enablingittoanswer
Toaddressthechallengesofprivacyconcerns,scarcityof
questionsaboutthecontentwithinthevisualinputs. Our
high-quality data, and small-scale models generalization
approach empowers smaller models with zero-shot learn-
andinterpretability,ourstudyintroducesanovelapproach
ingcapabilities,enablingthemtograspboththeintricate
called ‘On-Premises Secure Multimodal Instruction Tun-
contextwithinmicroscopicimages,includingspatialrela-
ing of SMMs’. This approach enables SMMs to achieve
2Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
tionshipsandobjectinteractions,andthenuancedseman- text itself. We train the framework in a supervised learn-
tics and intent behind the questions. Consequently, this ingsetting,minimizinglanguagemodelinglosstoground
leadstoimprovedgroundedlanguagegenerationandvisual its text generation in visual information. This results in
reasoningcapabilities,resultinginmoreaccurateanswers. accurate answers closely aligned with the image content,
Furthermore,ourapproachfacilitatesknowledgedistillation empoweringtheframeworkwithmicroscopicimageanaly-
fromlargertosmallermodels,ultimatelyenhancingtheir sisexpertise. Insummary,theproposedframework,trained
performancetobeonparwithlargermodelsinmicroscopic throughvision-languageinstructiontuning,takesasinput
image analysis tasks. Our novel encoder-decoder multi- a multimodal prompt of microscopic images paired with
modalframeworkefficientlyprocessesandalignsimages auxiliaryimagedescriptions,andoutputsfree-formtextas
andtexttogeneratetextualresponsestoquestionsacross answerstoarangeofopen-ended,image-relatedquestions.
imagecaptioningandopen-endedVQAtasks. Keycompo- Refer to the technical appendix, which dives deeper into
nentsofMAEMIforthezero-shotimagecaptioningtaskare thetechnicaldetailsandtheproposedframework,MAEMI
illustratedinFigure2. Themultimodalmodel,MAEMI,inte- variantsformulti-classclassificationandVQAtasks.
gratesvisualprocessingandlanguagemodelingforanswer-
2.ExperimentsAndResults
ingquestionsaboutspecificimagefeatures. Itincludes: (a)
2.1.Datasets
Thevisionencoder,usingavisiontransformer(Dosovitskiy
Our study utilized the SEM dataset (Aversa et al., 2018),
etal.,2020),analyzesthemicroscopicimagesbysplitting
which comprises more than 21,000 electron micrographs
them into patches and using self-attention mechanism to
covering ten different nanomaterials. We employed this
capturebeyondpair-wisepatchrelationships. Thisallows
comprehensive dataset to generate a diverse set of high-
forunderstandingtheglobalcontextandhighlightingrel-
quality instruction-tuning data in the form of question-
evantvisualregionsandrelationships. A<cls>tokenat-
answer pairs using GPT-4 Turbo with Vision,. Figure 3
tends to and aggregates information from all patches, re-
displaysrepresentativeimagesforeachofthetennanoma-
sultinginahigher-levelvisualsemanticrepresentationto
terialcategories. Wetrainedourframeworkexclusivelyon
capturetheoverallcontextorsummaryoftheinputimage.
this machine-generated multimodal data, eliminating the
(b)The text encoder, crucial for analyzing end-user ques-
needforhuman-annotateddata. Incontrasttoaprevious
tions,takesasinputaninterleavedmultimodalprompt. We
study(Modarresetal.,2017),whichworkedwithasubsetof
insert<image>tokeninthepromptattheimagelocation
thedata,weleveragedtheentirepubliclyavailabledatasetas
andappendan<Encode>tokentofacilitatemultimodalin-
thesubsetdatawasnotpubliclyaccessibleinitsentirety,en-
tegration,withitsoutputembeddingsymbolizingthefused
ablingmorecomprehensiveandrobustframeworktraining.
representation. Thetextencoderleveragesinstruction-tuned
Weconductedrigorousbenchmarkingresultingindemon-
Llama-2-7b, apretrainedlanguagemodel, tocapturelan-
strably improved task performance. Further experiments
guage nuances and context. The language-only model is
confirmed the framework’s generalizability across open-
customizedusingparameter-efficientfinetuningtechnique,
source material datasets within its thematic area. Please
enhancingitsabilitytointerpretend-userquestions. Both
refertothetechnicalappendixformorediscussion.
thevisionandlanguage-onlyunimodalencoderssynergize
2.2.ExperimentalStudies
tointerpretend-userquestionsandanalyzevisualinputfor
Weevaluatedourframeworkonzero-shot/few-shotmulti-
generatinganswersconsistentwiththevisualcontext. (c)
class classification tasks for microscopic images, image-
It utilizes a multi-layered structure with multiple blocks,
captioningtasks,andopen-endedVQAtasks. Thisin-depth
alternatingbetweenself-attentionandgatedcross-attention
analysis aimed to understand microscopic images better.
blocks.Thisdesignfacilitatescomplexinteractionsbetween
Additionally,weconductedVQAtaskstoassessintra-class
visual and textual modalities. By extracting and refining
dissimilarity,inter-classsimilarity,andspatialheterogene-
informationfrombothmodalitiesateachlevel,theframe-
ity,providingamorecomprehensiveunderstandingofthe
workprogressivelybuildsacomprehensiveunderstanding,
nanomaterialsunderlyingelectronmicrographs.
enablingcoherentandcontextuallyrelevantanswerstothe
end-userquestions. Gatedcross-attentionblocksintegrate 2.3.Results
visualfeatureswithtextualfeatures. Thegatingmechanism As shown in Table 1, our framework, MAEMI, generates
actsasanon-linearfilterandcontrolstheflowofinforma- detailed and logically consistent captions, outperforming
tion from the vision encoder to the language processing baselineslikeInstructBLIP(Daietal.), LLaVA(Liuetal.,
cross-attentionblocks,allowingtheframeworktofocuson 2023),andMiniGPT-4(Zhuetal.,2023)ontheimagecap-
relevant visual features for the text generation task. Self- tioningtask. Ourimagecaptioningapproachusesmetrics
attention blocks, on the other hand, allow the framework suchasBLEU,METEOR,andROUGEtoevaluatetextqual-
toweightheimportanceofdifferentpartsofthefusedin- ity,focusingonaspectslikesimilarity,languagefluency,and
formation. Withintheself-attentionblocks,thisisusedto coherence. Table2comparesrandomlysampledelectron
refine the text features based on their context within the microscopeimageswiththeirtruecaptions,alongside
3Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Output: text
The image is a scanning electron microscope (SEM) photo of spherical
nanomaterial particles of varying sizes on a textured background,
with a measurement scale indicating a nanometer range. Feed Forward layer
Trained
Frozen
𝓁-th SELF ATTN BLOCK Self Attention
K=V =[Y] Q=[Y]
𝓁-th GATED CROSS ATTN
tanh gating
1-st SELF ATTN BLOCK Feed Forward layer
Vision
Encoder 1st GATED CROSS ATTN
tanh gating
DyQLoRA-FA LLaMA-7b Cross Attention
Processed text K=V =[X] Q=[Y]
<image> This is an electron microscopy image belonging to the particle-
based nanomaterial category. Give me a short description of the image. X Y
Vision Language
Input Input
Input: visual data and text
This is an electron microscopy image belonging to the particle-based
nanomaterial category. Give me a short description of the image.
Figure2.TheschematicillustratesMAEMI,asmall-scale,autoregressivetextgenerationmodel.Ittakesasinputamultimodalprompt
consistingofthetargetimageinterleavedwithauxiliaryimagedescriptionsandcaptioninginstructions(orend-userquestions),and
outputsvisuallygroundeddescriptivetextinazero-shotsetting.MAEMIutilizesavisiontransformerandapre-trainedlanguagemodel
toanalyzeimagesandinterpretquestionsaboutthem. Bothencoderssynergizethroughamulti-layerstructureofalternatinggated
cross-attentionandself-attentionblocks,effectivelyintegratingbothmodalities–visualandtextualinformation–togenerateaccurateand
contextuallyrelevantanswers.Theframeworkistrainedinasupervisedlearningsettingusingavision-languageinstructiontuningdataset
togenerateanswersthataregroundedinvisualinformationandalignedwiththetargetimagecontent.
Figure3.Thefigureshowsrepresentativemicroscopicimagesofdiversenanomaterials:biologicalstructures,fibers,films,MEMSdevices,
nanowires(top);nanoparticles,patternedsurfaces,poroussponges,powders,tips(bottom).(Source:(Aversaetal.,2018))
Table1.Thetablesummarizestheproposedframework’sperformanceincomparisontovariousmethodsontheimagecaptioningtask.
Method BLEU-2 BLEU-4 ROUGE-1 ROUGE-2 ROUGE-L METEOR
InstructBLIP(Daietal.) 0.7003±0.032 0.6501±0.039 0.8116±0.016 0.7348±0.005 0.8018±0.021 0.8323±0.024
LLaVA(Liuetal.,2023) 0.7043±0.035 0.6609±0.043 0.8097±0.016 0.7456±0.005 0.8038±0.021 0.8244±0.023
MiniGPT-4(Zhuetal.,2023) 0.7644±0.086 0.6757±0.100 0.8264±0.035 0.7831±0.014 0.8146±0.047 0.8510±0.052
MAEMI 0.7862±0.089 0.6979±0.115 0.9014±0.041 0.8410±0.016 0.8448±0.054 0.8698±0.062
framework-generatedcaptionswiththeirBLEU-2,ROUGE- onauniquemultimodaldatacreatedwithGPT-4Turbofor
L, and METEOR scores indicating caption similarity to VQAtasksonconsumerhardware.Thepre-trainedassistant
the ground truth. The experimental results for zero/few- allowsfurthercustomizationwithprivatedata,allwithout
shotclassification,open-endedVQAtasks,andothersare exposingsensitiveinformationtoexternal,proprietarymul-
discussedinthetechnicalappendix. timodalmodels. Thissecure, efficient, andcost-effective
methodology unlocks exciting possibilities for enterprise
3.Conclusion
applications. Empirical results confirm our framework’s
Ourresearchunveilsagroundbreakingmethodforanalyzing superiority,achievingnotableaccuracyimprovementsover
electronmicrographsforthesemiconductorindustry. We priortechniqueswhileremainingcomputationallyefficient.
utilizetransferlearningtodistillknowledge,customizing
aninstruction-followinglanguage-visionassistanttrained
4Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Table2.Thetableshowselectronmicroscopeimagesandtheirtruecaptionsalongsidemachine-generatedcaptions. Thetablealso
includesevaluationmetricslikeBLEU-2,ROGUE-L,andMETEOR,whichmeasurethesimilaritybetweentruecaptionsandgenerated
captions.Bypresentingbothground-truthandmachine-generatedcaptionsside-by-side,thetableenablesanalysisoftheframework’s
performanceincapturingvisualdetailsandsemanticsofthemicroscopicimages.Themulti-metricapproachallowsprecisemeasurement
oftheproposedframework’sperformanceonthecaptioningtaskforthisscientificimagedataset.
BLEU-2/
Image GroundTruth Answers ROGUE-L/
METEOR
Thiselectronmicroscopyimagedis- Thiselectronmicroscopyimageex-
playsaneuronwithitsdendritictree hibitsaneuronwithitsdendritictree 0.847
andsynapticconnections,magnified andsynapticconnections,magnified 0.944
10,000times. 10,000times 0.941
ThisSEMimageshowstightlywo- ThisSEMimagedisplaystightlywo-
venfibrousmaterial,witheachfiber venfibrousmaterial,witheveryfiber 0.659
distinctlymagnified225timestore- distinctly magnified 225 times, re- 0.821
vealitstwistedstructure. vealingitstwistedstructure. 0.852
ThisSEMimagecapturesagranu- ThisSEMimagecapturesagranu-
larfilmsurfacewithamagnification lar film surface, magnified 50,000 0.724
of 50,000 times, revealing the mi- times,revealingthemicrostructure 0.878
crostructureofthecoatedmaterial. ofthecoatedmaterial. 0.767
ThisSEMimageshowsamicroelec- ThisSEMimageshowsamicroelec-
tromechanicalsystem(MEMS)with tromechanicalsystem(MEMS)with 0.795
intricatewiringandelectrodes,cap- intricatewiringandelectrodes,mag- 0.882
turedat100timesmagnification. nified100times 0.842
This SEM image depicts an array ThisSEMimagedepictsanarrayof
of vertical nanowires, showcasing verticalnanowires,displayingtheir 0.843
theiruniformityandhighaspectra- uniformity and high aspect ratio, 0.927
tio,magnifiedat80,000times. magnified80,000times. 0.902
ThisSEMimagerevealsclustersof ThisSEMimageshowsclustersof
sphericalnanoparticles,eachgroup- sphericalnanoparticles,eachcluster 0.813
ingdistinctfromtheothers,magni- distinctfromtheothers,magnified 0.889
fied11,000times. 11,000times 0.879
ThisSEMimagedisplaysahighly
ThisSEMimagedisplaysahighly
ordered,diamond-shapedpatterned
ordered,diamond-shapedpatterned 0.907
surface,magnified345times,char-
surface, magnified345times, typi- 0.947
acteristic of nano-fabrication tech-
calofnano-fabricationtechniques 0.940
niques.
This SEM image shows a porous This SEM image shows a porous
sponge-likematerialwithvariously sponge-like material with voids of
0.616
sized and shaped voids, magnified varioussizesandshapes,magnified
0.760
50,000 times to reveal the texture 50,000times,revealingthetexture
0.778
andporosity. andporosity.
This SEM image reveals a dense This SEM image displays a dense
aggregation of nanoscale particles aggregation of nanoscale particles 0.664
formingapowder,withamagnifica- formingapowder,magnified13,570 0.760
tionof13,570times. times 0.679
This SEM image shows a sharply This SEM image shows a sharply
pointed nanomaterial tip, high- pointed nanomaterial tip, high- 0.710
lighted against a stark background lightedagainstastarkbackground, 0.760
atamagnificationof100,000times. magnified100,000times. 0.737
5Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
References Chen,Z.,Xie,L.,Niu,J.,Liu,X.,Wei,L.,andTian,Q. Vis-
former: Thevision-friendlytransformer. InProceedings
Ainslie, J., Lee-Thorp, J., de Jong, M., Zemlyanskiy, Y.,
oftheIEEE/CVFInternationalConferenceonComputer
Lebro´n,F.,andSanghai,S. Gqa: Traininggeneralized
Vision,pp.589–598,2021c.
multi-querytransformermodelsfrommulti-headcheck-
points. arXivpreprintarXiv:2305.13245,2023. Chowdhery,A.,Narang,S.,Devlin,J.,Bosma,M.,Mishra,
G., Roberts, A., Barham, P., Chung, H.W., Sutton, C.,
Aversa,R.,Modarres,M.H.,Cozzini,S.,Ciancio,R.,and
Gehrmann,S.,etal. Palm: Scalinglanguagemodeling
Chiusole,A. Thefirstannotatedsetofscanningelectron
withpathways. arXivpreprintarXiv:2204.02311,2022.
microscopyimagesfornanoscience. Scientificdata,5(1):
1–10,2018. Dai, W., Li, J., Li, D., Tiong, A., Zhao, J., Wang, W., Li,
B.,Fung,P.,andHoi,S. Instructblip: Towardsgeneral-
Bianchi,F.M.,Grattarola,D.,Livi,L.,andAlippi,C.Graph
purposevision-languagemodelswithinstructiontuning.
neuralnetworkswithconvolutionalarmafilters. IEEE
arxiv2023. arXivpreprintarXiv:2305.06500.
transactionsonpatternanalysisandmachineintelligence,
2021. d’Ascoli,S.,Touvron,H.,Leavitt,M.,Morcos,A.,Biroli,
G.,andSagun,L. Convit: Improvingvisiontransformers
Bielak, P., Kajdanowicz, T., and Chawla, N. V. Graph
withsoftconvolutionalinductivebiases. arXivpreprint
barlowtwins: Aself-supervisedrepresentationlearning
arXiv:2103.10697,2021.
frameworkforgraphs. arXivpreprintarXiv:2106.02466,
2021. Defferrard, M., Bresson, X., and Vandergheynst, P. Con-
volutionalneuralnetworksongraphswithfastlocalized
Bresson,X.andLaurent,T. Residualgatedgraphconvnets.
spectral filtering. Advances in neural information pro-
arXivpreprintarXiv:1711.07553,2017.
cessingsystems,29,2016.
Caron, M., Touvron, H., Misra, I., Je´gou, H., Mairal, J.,
Deshpande,A.M.,Minai,A.A.,andKumar,M. One-shot
Bojanowski, P., andJoulin, A. Emergingpropertiesin
recognition of manufacturing defects in steel surfaces.
self-supervisedvisiontransformers. InProceedingsof
ProcediaManufacturing,48:1064–1071,2020.
the IEEE/CVF International Conference on Computer
Vision,pp.9650–9660,2021. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
D.,Zhai,X.,Unterthiner,T.,Dehghani,M.,Minderer,M.,
Chen,C.-F.,Panda,R.,andFan,Q. Regionvit: Regional-
Heigold,G.,Gelly,S.,etal. Animageisworth16x16
to-localattentionforvisiontransformers. arXivpreprint
words:Transformersforimagerecognitionatscale.arXiv
arXiv:2106.02689,2021a.
preprintarXiv:2010.11929,2020.
Chen, C.-F. R., Fan, Q., and Panda, R. Crossvit: Cross-
Du, J., Zhang, S., Wu, G., Moura, J. M., and Kar, S.
attentionmulti-scalevisiontransformerforimageclassi-
Topologyadaptivegraphconvolutionalnetworks. arXiv
fication. InProceedingsoftheIEEE/CVFInternational
preprintarXiv:1710.10370,2017.
ConferenceonComputerVision,pp.357–366,2021b.
Fayyaz, M., Kouhpayegani, S. A., Jafari, F. R., Sommer-
Chen, M., Wei, Z., Huang, Z., Ding, B., and Li, Y. Sim-
lade,E.,Joze,H.R.V.,Pirsiavash,H.,andGall,J. Ats:
pleanddeepgraphconvolutionalnetworks. InInterna-
Adaptivetokensamplingforefficientvisiontransformers.
tionalConferenceonMachineLearning,pp.1725–1735.
arXivpreprintarXiv:2111.15667,2021.
PMLR,2020a.
Fey,M. Justjump: Dynamicneighborhoodaggregationin
Chen, T., Xu, B., Zhang, C., and Guestrin, C. Training
graphneuralnetworks. arXivpreprintarXiv:1904.04849,
deep nets with sublinear memory cost. arXiv preprint
2019.
arXiv:1604.06174,2016.
Gao,H.andJi,S. Graphu-nets. Ininternationalconference
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. A
onmachinelearning,pp.2083–2092.PMLR,2019.
simpleframeworkforcontrastivelearningofvisualrep-
resentations. In International conference on machine Gilmer,J.,Schoenholz,S.S.,Riley,P.F.,Vinyals,O.,and
learning,pp.1597–1607.PMLR,2020b. Dahl,G.E. Neuralmessagepassingforquantumchem-
istry. InInternationalconferenceonmachinelearning,
Chen,X.andHe,K. Exploringsimplesiameserepresen-
pp.1263–1272.PMLR,2017.
tationlearning. In ProceedingsoftheIEEE/CVFCon-
ferenceonComputerVisionandPatternRecognition,pp. Graham,B.,El-Nouby,A.,Touvron,H.,Stock,P.,Joulin,
15750–15758,2021. A.,Je´gou,H.,andDouze,M. Levit: avisiontransformer
6Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
inconvnet’sclothingforfasterinference. InProceedings Krizhevsky,A.,Sutskever,I.,andHinton,G.E. Imagenet
oftheIEEE/CVFInternationalConferenceonComputer classification with deep convolutional neural networks.
Vision,pp.12259–12269,2021. CommunicationsoftheACM,60(6):84–90,2017.
Grill,J.-B.,Strub,F.,Altche´,F.,Tallec,C.,Richemond,P., Lee, S. H., Lee, S., and Song, B. C. Vision transformer
Buchatskaya,E.,Doersch,C.,AvilaPires,B.,Guo,Z., forsmall-sizedatasets. arXivpreprintarXiv:2112.13492,
GheshlaghiAzar,M.,etal. Bootstrapyourownlatent- 2021.
a new approach to self-supervised learning. Advances
Li, Y., Tarlow, D., Brockschmidt, M., and Zemel, R.
in Neural Information Processing Systems, 33:21271–
Gatedgraphsequenceneuralnetworks. arXivpreprint
21284,2020.
arXiv:1511.05493,2015.
Hassani, A., Walton, S., Shah, N., Abuduweili, A., Li, J.,
Liu, H., Li, C., Wu, Q., andLee, Y.J. Visualinstruction
andShi,H. Escapingthebigdataparadigmwithcompact
tuning. arXivpreprintarXiv:2304.08485,2023.
transformers. arXivpreprintarXiv:2104.05704,2021.
Liu,Z.,Lin,Y.,Cao,Y.,Hu,H.,Wei,Y.,Zhang,Z.,Lin,
He,K.,Zhang,X.,Ren,S.,andSun,J. Deepresiduallearn-
S.,andGuo,B. Swintransformer: Hierarchicalvision
ingforimagerecognition. InProceedingsoftheIEEE
transformerusingshiftedwindows. InProceedingsofthe
conferenceoncomputervisionandpatternrecognition,
IEEE/CVFInternationalConferenceonComputerVision,
pp.770–778,2016.
pp.10012–10022,2021.
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. Mo-
Modarres,M.H.,Aversa,R.,Cozzini,S.,Ciancio,R.,Leto,
mentumcontrastforunsupervisedvisualrepresentation
A.,andBrandino,G.P. Neuralnetworkfornanoscience
learning. InProceedingsoftheIEEE/CVFconferenceon
scanningelectronmicroscopeimagerecognition. Scien-
computervisionandpatternrecognition,pp.9729–9738,
tificreports,7(1):1–12,2017.
2020.
Morris,C.,Ritzert,M.,Fey,M.,Hamilton,W.L.,Lenssen,
Heo,B.,Yun,S.,Han,D.,Chun,S.,Choe,J.,andOh,S.J.
J.E., Rattan, G., andGrohe, M. Weisfeilerandleman
Rethinkingspatialdimensionsofvisiontransformers. In
goneural: Higher-ordergraphneuralnetworks. InPro-
ProceedingsoftheIEEE/CVFInternationalConference
ceedingsoftheAAAIconferenceonartificialintelligence,
onComputerVision,pp.11936–11945,2021.
volume33,pp.4602–4609,2019.
Hu,E.J.,Shen,Y.,Wallis,P.,Allen-Zhu,Z.,Li,Y.,Wang,
OpenAI. Gpt-4v(ision) system card. 2023. URL
S.,Wang,L.,andChen,W. Lora:Low-rankadaptationof
https://cdn.openai.com/papers/GPTV_
largelanguagemodels. arXivpreprintarXiv:2106.09685,
System_Card.pdf.
2021.
Renggli, C., Pinto, A. S., Houlsby, N., Mustafa, B.,
Huang,G.,Liu,Z.,VanDerMaaten,L.,andWeinberger,
Puigcerver, J., and Riquelme, C. Learning to
K. Q. Densely connected convolutional networks. In
merge tokens in vision transformers. arXiv preprint
ProceedingsoftheIEEEconferenceoncomputervision
arXiv:2202.12015,2022.
andpatternrecognition,pp.4700–4708,2017.
Robbins, H. and Monro, S. A stochastic approximation
Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., method. Theannalsofmathematicalstatistics,pp.400–
Dally,W.J.,andKeutzer,K. Squeezenet: Alexnet-level 407,1951.
accuracywith50xfewerparametersand¡0.5mbmodel
size. arXivpreprintarXiv:1602.07360,2016. Shaw, P., Uszkoreit, J., and Vaswani, A. Self-attention
with relative position representations. arXiv preprint
Kim, D.andOh, A. Howtofindyourfriendlyneighbor- arXiv:1803.02155,2018.
hood:Graphattentiondesignwithself-supervision.arXiv
preprintarXiv:2204.04879,2022. Simonyan, K. and Zisserman, A. Very deep convolu-
tionalnetworksforlarge-scaleimagerecognition. arXiv
Kingma,D.P.andBa,J. Adam: Amethodforstochastic preprintarXiv:1409.1556,2014.
optimization. arXivpreprintarXiv:1412.6980,2014.
Sun, F.-Y., Hoffmann, J., Verma, V., and Tang, J. Info-
Klicpera, J., Bojchevski, A., andGu¨nnemann, S. Predict graph: Unsupervised and semi-supervised graph-level
thenpropagate:Graphneuralnetworksmeetpersonalized representationlearningviamutualinformationmaximiza-
pagerank. arXivpreprintarXiv:1810.05997,2018. tion. arXivpreprintarXiv:1908.01000,2019.
7Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Yuan, L., Chen, Y., Wang, T., Yu, W., Shi, Y., Jiang, Z.-
Anguelov,D.,Erhan,D.,Vanhoucke,V.,andRabinovich, H.,Tay,F.E.,Feng,J.,andYan,S. Tokens-to-tokenvit:
A. Going deeper with convolutions. In Proceedings Trainingvisiontransformersfromscratchonimagenet.In
oftheIEEEconferenceoncomputervisionandpattern ProceedingsoftheIEEE/CVFInternationalConference
recognition,pp.1–9,2015. onComputerVision,pp.558–567,2021.
Team,G.,Anil,R.,Borgeaud,S.,Wu,Y.,Alayrac,J.-B.,Yu, Zbontar,J.,Jing,L.,Misra,I.,LeCun,Y.,andDeny,S. Bar-
J.,Soricut,R.,Schalkwyk,J.,Dai,A.M.,Hauth,A.,etal. lowtwins:Self-supervisedlearningviaredundancyreduc-
Gemini: afamilyofhighlycapablemultimodalmodels. tion. InInternationalConferenceonMachineLearning,
arXivpreprintarXiv:2312.11805,2023. pp.12310–12320.PMLR,2021.
Thakoor,S.,Tallec,C.,Azar,M.G.,Munos,R.,Velicˇkovic´, Zhang, B. and Sennrich, R. Root mean square layer nor-
P.,andValko,M. Bootstrappedrepresentationlearning malization. AdvancesinNeuralInformationProcessing
ongraphs. InICLR2021WorkshoponGeometricaland Systems,32,2019.
TopologicalRepresentationLearning,2021.
Zhang,L.,Zhang,L.,Shi,S.,Chu,X.,andLi,B. Lora-fa:
Thekumparampil, K. K., Wang, C., Oh, S., and Li, L.-
Memory-efficientlow-rankadaptationforlargelanguage
J. Attention-based graph neural network for semi- models fine-tuning. arXiv preprint arXiv:2308.03303,
supervisedlearning. arXivpreprintarXiv:1803.03735,
2023.
2018.
Zhang, Z., Zhang, H., Zhao, L., Chen, T., Arik, S., and
Touvron,H.,Cord,M.,Douze,M.,Massa,F.,Sablayrolles,
Pfister,T. Nestedhierarchicaltransformer:Towardsaccu-
A.,andJe´gou,H.Trainingdata-efficientimagetransform-
rate,data-efficientandinterpretablevisualunderstanding.
ers&distillationthroughattention. InInternationalCon-
2022.
ferenceonMachineLearning,pp.10347–10357.PMLR,
2021a. Zhou,D.,Kang,B.,Jin,X.,Yang,L.,Lian,X.,Jiang,Z.,
Hou,Q.,andFeng,J. Deepvit: Towardsdeepervision
Touvron,H.,Cord,M.,Sablayrolles,A.,Synnaeve,G.,and
transformer. arXivpreprintarXiv:2103.11886,2021.
Je´gou, H. Going deeper with image transformers. In
ProceedingsoftheIEEE/CVFInternationalConference Zhu, D., Chen, J., Shen, X., Li, X., and Elhoseiny, M.
onComputerVision,pp.32–42,2021b. Minigpt-4: Enhancing vision-language understanding
with advanced large language models. arXiv preprint
Touvron,H.,Lavril,T.,Izacard,G.,Martinet,X.,Lachaux,
arXiv:2304.10592,2023.
M.-A.,Lacroix,T.,Rozie`re,B.,Goyal,N.,Hambro,E.,
Azhar,F.,etal. Llama:Openandefficientfoundationlan- Zhu,Y.,Xu,Y.,Yu,F.,Liu,Q.,Wu,S.,andWang,L. Deep
guagemodels. arXivpreprintarXiv:2302.13971,2023. graphcontrastiverepresentationlearning. arXivpreprint
arXiv:2006.04131,2020.
Valipour,M.,Rezagholizadeh,M.,Kobyzev,I.,andGhodsi,
A. Dylora: Parameter efficient tuning of pre-trained
modelsusingdynamicsearch-freelow-rankadaptation.
arXivpreprintarXiv:2210.07558,2022.
Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,
L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. At-
tentionisallyouneed. Advancesinneuralinformation
processingsystems,30,2017.
Velicˇkovic´, P., Cucurull, G., Casanova, A., Romero, A.,
Lio,P.,andBengio,Y. Graphattentionnetworks. arXiv
preprintarXiv:1710.10903,2017.
Wu,H.,Xiao,B.,Codella,N.,Liu,M.,Dai,X.,Yuan,L.,
andZhang,L. Cvt: Introducingconvolutionstovision
transformers. InProceedingsoftheIEEE/CVFInterna-
tionalConferenceonComputerVision,pp.22–31,2021.
Xie,Z.,Zhang,Z.,Cao,Y.,Lin,Y.,Bao,J.,Yao,Z.,Dai,Q.,
andHu,H. Simmim: Asimpleframeworkformasked
imagemodeling. arXivpreprintarXiv:2111.09886,2021.
8Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
A.TechnicalAppendix isacriticalhyperparameterthatinfluencesthebalancebe-
A.1.DynamicLow-RankAdaptationwithActivation tweenthepretrainedlanguagemodel’sadaptationcapacity,
MemoryReduction(DyQLoRA-FA) computationalefficiency,andoverallperformanceduring
thefine-tuningprocessfortask-specificcustomization. Dur-
Low-RankAdaptation(LoRA(Huetal.,2021))isadeep
ing training, the low-rank weight matrices B and A are
learningtechniqueusedtoefficientlyfine-tunelarge-scale
updated,whileW remainsfixed. Duringthefine-tuning
pre-trainedlanguagemodelsonconsumerhardwaretoadapt 0
ofpre-trainedlanguagemodels,gradientsforeachtrainable
fornichedomain-specifictasks. Itaccomplishesthiswith-
parameterarecalculatedusingthelossfunction. Thesegra-
out introducing additional inference latency and without
dientsguideoptimizers,suchasAdam(Kingma&Ba,2014)
theneedforextensiveretraining. LoRAadaptstheselarge-
orSGD(Robbins&Monro,1951),inupdatingthetrainable
scalemodelstodomain-specifictasksbypreservingthevast
parameters. Additionally,optimizersmaintainextrastatein-
knowledge acquired during pretraining, thereby avoiding
formationfortheseparameters,whichincludesmomentum
catastrophicforgetting—aphenomenonwherethelanguage
andadaptivelearningrates. Thus,fine-tuningpre-trained
modellosespreviouslylearnedinformationwhileacquiring
language models necessitates storing not only the model
new information. This selective adaptation of large pre-
parametersbutalsotheirgradientsandoptimizerstatesin
trainedlanguagemodelsisachievedbyinsertingsmallpairs
memory. LoRAproportionallydecreasesthememoryover-
oftrainablelow-rankweightmatrices,knownasadapters,
headassociatedwiththegradientsandoptimizerstatesby
intoeachpretrainedmodellayer. Bykeepingtheoriginal
reducingthenumberoftrainableparametersthroughlow-
pretrainedmodelweightsunchanged,LoRAupdatesonly
rankadaptation. Thisreductioniscrucialfortask-specific
these auxiliary parameters, achieving comparable perfor-
fine-tuningoflarge-scalelanguagemodels. Consequently,
mance to full-parameter fine-tuning. LoRA primarily fo-
LoRArequiresfewercomputationalresourcesthanfullfine-
cusesonthelinearlayersinTransformer-basedlarge-scale
tuning, making it a more efficient and scalable approach
languagemodels(Vaswanietal.,2017),forseveralkeyrea-
foradaptingpre-trainedlanguagemodelstospecifictasks.
sons:(a)Theselayersareprevalentinsucharchitecturesand
However,substantialmemoryisstillnecessarytostorethe
containasignificantportionofthelanguagemodel’sparam-
largeinputactivations(i.e.,thehigh-dimensionalinterme-
eters. (b)Theyarewell-suitedforlow-rankapproximations,
diate outputs of layers, such as X in Equation 1) during
offeringabalancebetweenlanguagemodeladaptabilityand
thefeed-forwardpass. Thisisnecessaryforcomputingthe
computationalefficiency. (c)Additionally,modifyinglinear
gradientsofthelow-rankweightsduringback-propagation.
layersdirectlyimpactsthelanguagemodel’slearningcapa-
Highactivationmemorydemandssignificantlylimitscal-
bilities,makingthemidealtargetsforefficientandeffective
ability, especiallywhen computational resourcesare con-
fine-tuning. Bytakingadvantageofthedistinctfeaturesof
strained. Approaches such as selective LoRA (Hu et al.,
linearlayers,LoRAincorporatesadditionaltrainableparam-
2021)oractivationrecomputation(Chenetal.,2016)can
eters (∆W) to capture task-specific information, thereby
potentiallyalleviatethesedemands,butsufferfromtrade-
updatingthepretrainedlanguagemodelwithoutalteringthe
offsintermsofperformanceandefficiency. Inconclusion,
originalweights(W ). Thelow-rankadaptation,inwhich
0 whileLoRAenablesefficientadaptationofpre-trainedlan-
theoriginalweightmatricesaretransformedbyaddingthe
guagemodelstospecifictasksordomains,addressingthe
productofpairoflow-rankmatrices,effectivelyallowsthe
substantialactivationmemorydemandsduringfine-tuning
pretrainedlanguagemodeltolearndomain-specifictasks,
remains a key challenge. LoRA-FA (Zhang et al., 2023)
asexpressedbelow:
significantly reduces the activation memory footprint by
Y=(W 0+∆W)X=W 0X+(αAB)X (1) freezingthepretrainedweights(W 0),theprojection-down
Here,Y ∈Rb×dout andX∈Rb×din representtheoutputand weight(A),andupdatingonlytheprojection-upweight(B)
ineachlinearlayer. InLoRA-FA,thefrozenAisrandomly
inputtensors,respectively. Weomitthebiastermforsim-
initializedfromanormaldistribution,whileBisinitialized
plicity. d andd denotetheinputandoutputdimensions,
in out
tozeroandupdatedduringfine-tuning. Thisapproachal-
respectively. bdenotesthebatchsize. Theoriginalweight
matrix,denotedasW
0
∈Rdin×dout,preservesthepretrained lowsforthecomputationofgradientssolelyforB,leading
toasubstantialreductionincomputationalload. Moreover,
knowledge. ∆W, the low-rank approximation added to
itnecessitatesstoringonlythereduced-dimensionalityinput
W duringlanguagemodeladaptation,enablesfine-tuning
0
toB(i.e.,AX),whereAmapsthehigh-dimensionalinput
fordomain-specifictaskswhilepreservinggeneralcapabili-
Xtoasignificantlysmallerr-dimensionalspace,facilitating
ties. Theprojection-downweightmatrixAhasdimensions
Rdin×r,andtheprojection-upweightmatrixBhasdimen- thecomputationofgradientsforBduringbackpropagation
sionsRr×dout. Therankofthedecomposition,denotedasr, with reduced activation memory. This approach signifi-
cantlyreducestheactivationmemoryrequirementswithout
issignificantlysmallerthand ord (i.e.,r ≪d ord ).
in out in out
α,apositiveconstant,istypicallyvaluedat 1. Therank,r, compromisingfine-tuningperformanceandwithoutintro-
r ducing additional computational overhead and inference
9Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
latency. Consequently,itenablesefficientfine-tuningofpre-
∂L ∂L
trainedlanguagemodelsunderresourceconstraintswhile B↓b =B↓b−η· ;A↓b =A↓b−η·
new ∂B↓b new ∂A↓b
preservingaccuracyandminimizingmemoryconsumption.
B[1:b,:]=B↓b ;A[:,1:b]=A↓b
However,LoRA-FAmayhavepotentiallimitations,includ- new new
ingpotentiallyslowerconvergenceratesintheinitialstages whereηisthelearningrate. Wemanagethecomputational
offine-tuningandtheneedforcarefulhyperparameterop- complexityassociatedwithvaryingranksinDyLoRA-FA
timizationofrankrtoachievepeakperformance. Further- through custom gradient accumulation and rank normal-
more,LoRA-FAisastaticlow-rankadapterthatworksonly ization. Gradient accumulation enables more stable and
withaspecificallytrainedrankr. Toaddresstheselimita- efficient learning by collecting gradients over multiple it-
tions,DyLoRA(Valipouretal.,2022)introducesdynamic erations,whileranknormalizationequalizestheimpactof
low-rankadaptersthataretrainableanddeployableacross different ranks on language model fine-tuning by scaling
arangeofranks, therebyeliminatingtheneedtofindthe gradientsaccordingtoranksize. Weemployweight-only
optimalrankthroughmultipletrainings. Dynamiclow-rank quantization (WOQ) for fine-tuning pre-trained language
adaptersofferseveralkeybenefits. Firstly,theirabilityto models. WOQcompressestheoriginalweightsofthepre-
dynamicallyadjusttheirrankallowsforanoptimaltrade- trained language model by converting its high-precision
offbetweencomputationalefficiencyandpre-trainedlan- weights(usually16-bitfloating-point)intolower-precision
guagemodelperformanceonspecializeddomain-specific formats(e.g.,8-bitintegers). Thisresultsinadrasticreduc-
tasks. Secondly, because these adapters can adapt their tion in the language model’s memory footprint and com-
rank according to the specific task and data distribution, putational requirements. We fine-tune the quantized pre-
theyareparticularlywell-suitedforscenariosinvolvingcon- trainedlanguagemodelonspecificdatasetsrelatedtothe
tinuouslearningorfrequentchangesindatadistributions, target domain-specific task using the parameter-efficient
especiallywhenfacingout-of-distribution(OOD)data. We fine-tuning(PEFT)techniquesuchasDyLoRA-FA,which
utilize DyLoRA to train and deploy LoRA-FA across a compensatesforanyaccuracydropsresultingfromquantiza-
rangeofranks,r ∈Range[r ,r ],withr andr as tion. DyQLoRA-FA,whichinvolvesquantization,hasbeen
min max min max
newhyperparameters. Duringtrainingateachstep,arank foundtoreducememoryrequirementssignificantly,albeitat
b is sampled from a pre-defined categorical distribution, thecostofaslightlylongertrainingtime. Thistrade-offis
b ∼ p (Range[r ,r ])andthematricesaretruncated generallyconsideredacceptable,especiallywhenitallows
B min max
toA↓bandB↓basfollows: fortheuseoflow-costGPUs.Insummary,DyQLoRA-FAis
aflexibleandefficientmethodforfine-tuninglargelanguage
B↓b=B[1:b,:]
modelsacrossvariousranksizes. Itmaintainsperformance
A↓b=A[:,1:b]
withoutretraining,ishighlymemory-efficient,haslowcom-
Y=W 0X+(αA↓bB↓b)X putational cost, and achieves comparable performance to
where A↓b and B↓b are the truncated forms of A and B full-parameterfine-tuningondiversetasks.
atrankb,theback-propagationinvolvescomputinggradi-
A.2.Fine-Tuning,PretrainedLargeLanguage
ents ∂L and ∂L , where L is the loss function. The
∂A↓b ∂B↓b Models(LLMs)
back-propagationtechniqueaimstoupdatethesematrices
basedonthelossfunction,takingintoaccountthedynamic Llama2(Touvronetal.,2023),anadvancedautoregressive
adaptationinrank. WecomputegradientwithrespecttoB pretrainedlanguagetransformerbuiltfornaturallanguage
asfollows: ConsiderthecontributiontotheoutputYfrom processing (NLP) tasks, leverages supervised fine-tuning
B: Y = (αA↓bB↓b)X. ThegradientofthelossLwith (SFT) and reinforcement learning with human feedback
B
respecttoB↓bis: (RLHF) to generate responses ideal for chat applications
and various language generation tasks. Its robust foun-
∂L ∂L ∂Y
= · B dation in understanding and generating human-like text,
∂B↓b ∂Y ∂B↓b
∂L B (cid:18) ∂L (cid:19) combined with its ability to effectively interpret and pro-
=αA↓b X duce natural language, makes it well-suited for complex
∂B↓b ∂Y
B
NLP tasks. Llama-2’s architecture comprises 32 layers
Similarly,thegradientofthelossLwithrespecttoA↓bis:
and32attentionheads,efficientlyhandlinglargetokense-
∂L ∂L ∂Y quencesofupto4096tokens. ItincorporatesRMSNorm
= · B
∂A↓b ∂Y ∂A↓b pre-normalization(Zhang&Sennrich,2019),SwiGLUacti-
B
∂L (cid:18) ∂L (cid:19) vationfunctions(Chowdheryetal.,2022),rotarypositional
=αB↓b X
∂A↓b ∂Y embeddings(Shawetal.,2018),andagrouped-queryatten-
B
tionmechanism(Ainslieetal.,2023)toachievethisefficient
Thegradientsareusedtoupdatethetrainableparameters
processing. Wefine-tunedLlama-2-7Busingaparameter-
usinganoptimizerlikeAdamorSGDasfollows,
efficient fine-tuning technique (PEFT) called Dynamic
10Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
AdaptationwithActivationMemoryReduction(DyQLoRA- multimodalpromptsthatguideGPT-4Vtogeneratecontex-
FA).Thefine-tuningleveragedavision-languageinstruction tuallyrichtextualresponsestonaturallanguagequestions
tuningdatasetgeneratedbyGPT-4TurbowithVision,based aboutthenanomaterial’sstructureandpatternsunderlying
on image captioning and open-ended VQA tasks. This theelectronmicrographs.ThisapproachcapitalizesonGPT-
task-specificfine-tuningenhancesLlama-2’sabilitytocom- 4V’sinherentdomain-specificknowledge,acquiredduring
prehendcomplexlanguageinnichedomains,particularly trainingonavastmultimodalcorpus,toyieldcomprehen-
evidentinitsimprovedinterpretationofnaturallanguage siveinsightsintothesemicroscopicimages. Theseinsights
questionsrelatedtoelectronmicrographs. Theresultingpre- helpstogeneratediversemultimodalinstruction-following
trainedlanguagemodeldemonstratesadvancedcapabilities data,vitalfortrainingSMMstogeneralizewellonelectron
inquestionanalysisandhandlingcomplexlanguage,lead- microscopyimageanalysistasks.
ingtoastrongercorrespondencebetweenimagesandtext.
A.4.MultimodalInstruction-FollowingData
Llama-2’sseamlessintegrationwithvisionencodersmakes
itpowerfulformultimodaltasks. Theproposedframework The generation of high-quality, diverse, and task-specific
caneffortlesslyprocessbothvisualandtextualdata,which multimodalinstruction-followingdatausingGPT-4Turbo
is particularly valuable when analyzing images and their with Vision is a powerful approach for training versatile,
correspondingdescriptions. moreefficient,andsmallermultimodalmodelsforVQAand
image-captioningonmicroscopicimageanalysistasks.This
A.3.PretrainedLargeMultimodalModels
approachoffersseveralbenefits,including: (a)Enhancing
We build upon pre-trained Large Multimodal Models modelcapabilities: GPT-4TurbowithVision’s,owingto
(LMMs) to generate image-question-answer triplets as itsvastpre-trainingknowledgecangeneratequestionsthat
instruction-tuningdatasetstotrainsmallermultimodalmod- comprehensivelyinvestigatediversefacetsofnanomaterials
els (SMMs) through vision-language instruction tuning. underlyingelectronmicrographs,includingsize,distribu-
Thisknowledgetransfer,ordistillation,fromLMMsaccel- tion,morphology,andstructure. Thesequestionsaremore
eratesandenhancesSMMs’learning,ultimatelyleadingto complex,nuanced,andrequirereasoningandknowledgebe-
moreaccurate,relevant,andcontextually-awareresponses yondbasicimagerecognition. Thiscanexpandthelimitsof
intasksdemandingcomprehensionofbothvisualandlin- whatsmallermultimodalmodelscanlearnandenablethem
guisticinputs,suchaszero-shotVQAandimagecaptioning to answer more challenging visual questions about these
forelectronmicroscopyimagesanalysis. WeutilizeOpe- microscopic images. (b) Improving zero-shot learning:
nAI’sstate-of-the-artmultimodalmodel,GPT-4Turbowith Trainingsmallermodelsondiversequestionsandanswers
Vision(GPT-4-vision-preview),whichsurpassesthelimita- fosters deeper insights into the relationships between vi-
tionsofitspredecessors,toefficientlygeneratehigh-quality sualfeatures,language,andtaskobjectives. Thisenhances
training data for instruction tuning SMMs. This allows theirabilitytoanswernewquestionsonunseenmicroscopic
SMMstogeneralizewelltonew,unseenquestions. GPT-4 imageswithoutfurthertraining,acriticalelementforprac-
Turboboastsasignificantlyexpandedcontextwindowof ticalapplications. (c)Facilitatingknowledgedistillation:
128ktokens(≈300pagesperprompt), a3xreductionin GPT-4 Turbo with Vision can generate detailed, nuanced
inputtokencost,a2xreductioninoutputtokencost,anda question-answer pairs that describe microscopic images,
maximumoutputlengthof4096tokensformoreelaborate includingtheirvisualpropertiessuchasshape,texture,pat-
textgeneration. TheGPT-4TurbowithVisionAPI,accessi- terns,andsurfacecharacteristics. Furthermore,itcandraw
blethroughMultimodalModelingasaService(MMaaS), connectionstosize,distribution,morphology,andstructural
acceptsbothimageandtextinputstogeneratemultimodal relationships,leveragingitsextensiveinternalknowledge
outputs. ByleveragingMMaaS,whichutilizesproprietary acquired during pre-training. This facilitates knowledge
GPT-4TurbowithVisionasanon-demandcloudservice distillation,transferringvaluabletask-specificknowledge
accessedviaanAPI,userscandesigntask-specificprompts fromlargertosmallermodels. Asaresult,smallermodels
to query pre-trained LMMs for solving multimodal tasks become more efficient, accurate, and transparent in their
of interest. This approach is analogous to how users ac- reasoning since they don’t need to learn everything from
cessLLMsviaLanguageModelingasaService(LMaaS) scratchwithexpensivehuman-annotateddatasets. (d)Gen-
forlanguage-specifictasks. Designedforlarge-scale,con- eratingdiversequestion-answerpairs: Finally,theend-
current requests, APIs are ideal for integration into auto- userqueriescanbeusedtogeneratediversequestion-answer
matedsystems.Ourexplorationofsmallmultimodalmodels pairsthatdelveintovariousaspects,properties,andchar-
(SMMs)forelectronmicrographanalysisbeginsbyleverag- acteristics of microscopic images. This further enriches
ingGPT-4TurbowithVision(GPT-4V)togeneratenatural the training data for smaller models, equipping them to
language questions as task-specific instructions for VQA handle a wider range of end-user queries. Our approach
andimage-captioningtasks.Bypairingthesequestionswith leverages the power of zero-shot chain-of-thought (CoT)
the corresponding target electron micrographs, we create promptingtoguidelargemultimodalmodels(LMMs)like
11Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
GPT-4TurbowithVisiontocreateanoveltrainingdataset representation?. Prompt10: **ContextandAppli-
ofimage-question-and-answertriplesspecificallydesigned cation**-Whatistheintendedapplicationoruse
forSMMs. AsshowninTables11-20,thegeneratedQ&A ofthenanomaterialbeingdepicted? -Isthisaexper-
pairscorrespondtoasampleofmicroscopicimagesofdif- imentalsample,oratheoreticalorsimulation-based
ferentnanomaterialsfromtheSEMdataset(Aversaetal., representation?
2018). Through knowledge distillation, SMMs achieve
performanceonparwithorevenexceedingthatoflarger, A.5.VisionEncoder
more generalized multimodal models. The high-quality
We start with an input image I, a 3D tensor of dimen-
dataset,encompassingbothimagesandcorrespondingQ&A
sionsH ×W ×C,representingheightH,widthW,and
pairsextractedfromLMMs,providesaclearfoundationfor
colorchannelsC perpixel. Theimageisdividedintonon-
SMMstounderstandhowcertainconcept-basedquestions
overlapping patches sized P × P × C. Tokenizing the
andtheircorrespondinganswersarevisuallyrepresented.
image results in n = HW patches. These patches are
P2
linearly encoded into 1D vectors, forming a sequence of
Prompt1: **Basics**-Whattypeofnanomaterial
tokensI′ ∈ Rn×d,wheredisthedimensionalityofpatch
is depicted in the image? - What is the scale of
embeddings.Positionalembeddingsareaddedtoeachpatch
the image? (e.g., what does one unit of measure-
embeddingtopreservespatialinformation. Aspecialclas-
mentrepresent?). Prompt2: **Morphologyand
sificationtoken,<cls>,isappendedforaggregatinginfor-
Structure**-Whatisthegeneralshapeormorphol-
mationacrosspatchesforglobalrepresentation. Thistoken
ogyofthenanomaterialsintheimage? -Arethere
sequenceisprocessedbyavariantoftheVisionTransformer
distinct layers, phases, or domains visible? - Do
(ViT)withstackedencoderlayersusinghierarchicalatten-
thenanomaterialsappearuniforminsizeandshape
tionmechanism. Thestackedencoderlayersprocesspatch
or are they varied?. Prompt 3: **Size and Dis-
embeddingsthroughhigher-orderattentionmechanismsfor
tribution**-Whatistheapproximatesizeorsize
multi-scalevisualcomprehension,fromfinedetailstoglobal
rangeoftheindividualnanostructures? -Howare
context. Itinvolveslocalandglobalmulti-headattention
thenanomaterialsdistributedthroughouttheimage?
phases,firstfocusingonpatchinterrelationshipsandthen
(e.g., evenlyspaced, clustered, random)-Isthere
incorporatingtheclassificationtokenforaholisticunder-
anyevidenceofaggregationorbundling?. Prompt
standing. Theoutputistheembeddingoftheclassification
4: **SurfaceCharacteristics**-Doesthenanoma-
tokenh ,representingtheimage’sunifiedvisualcontext.
terial appear smooth, rough, or have any specific cls
Insummary,thevisionencoderbreaksdowntheimageinto
textures? -Arethereanyvisibledefects,pores,or
patches,convertsthemintotokens,andintegratesthemus-
impuritiesonthesurface?. Prompt5: **Composi-
ingalayeredhierarchicalattentionmechanismtoproduce
tionandElements**-Isthereevidenceofcomposi-
a comprehensive representation, h , encapsulating both
tionalvariationsintheimage(e.g.,differentcolors, cls
local and global aspects of the image. A vision encoder
brightness,orcontrasts)? -Arethereanylabelsor
analyzesimagestoextractvisualknowledgelikeobjects,
markersindicatingspecificelementsorcompounds
textures,andpatterns,encodingthemintoarepresentation
present?. Prompt 6: **Interactions and Bound-
understoodbyalanguagemodel. Thisvisualunderstanding
aries**-Howdoindividualnanostructuresinteract
is then fused with a natural language question, allowing
with one another? (e.g., are they touching, fused,
the model to accurately interpret the question in the con-
orseparate?) -Arethereclearboundariesbetween
text of the image and generate precise answers to visual
different structures or phases?. Prompt 7: **Ex-
questions. Thisprocesseffectivelybridgesthegapbetween
ternalEnvironment**-Isthereanyevidenceofthe
visualandlinguisticinformation,leadingtoricherandmore
nanomaterialinteractingwithitssurroundingenvi-
meaningfulmultimodalreasoningandgeneration.
ronmentormatrix(e.g.,solvents,polymers,orother
materials)? -Arethereotherstructuresorobjects A.6.SamplingStrategiesforInstructionTuningDataset
intheimagethatarenotnanomaterials? Ifso,what Generation
arethey?. Prompt8: **ImageTechniqueandMod-
To generate instruction-following multimodal data using
ifications**-Whatimagingtechniquewasusedto
GPT-4Turbowithvisionforfew-shotimageclassification
capturethisimage? (e.g.,SEM,TEM)-Werethere
(refertoFigure5)andtoanalyzeelectronmicrographsfor
any post-processing or modifications made to the
highintra-classdissimilarity,highinter-classsimilarity,and
image(e.g.,falsecoloring,3Drendering)?. Prompt
spatialheterogeneity(refertoFigures6-8),weimplement
9:**FunctionalFeatures**-Ifapplicable,arethere
the following strategies. We train a Vision Transformer
anyfunctionalfeaturesvisible(e.g.,activesites,re-
(ViT)throughsupervisedlearningtominimizecross-entropy
gionswithdistinctproperties)? -Aretheredynamic
lossandimprovemulticlassclassificationaccuracy.Theout-
processescapturedintheimageorisitastatic
putembedding(h )fromthe(<cls>)tokenprovidesacom-
cls
12Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
prehensiveimagerepresentation.Forfew-shotclassification, and8showcasetailoredMAEMIvariantsforVQAtaskson
weuseasimilarity-drivensamplingmethod. Wehypothe- electronmicrographs,addressingintra-classdissimilarity,
sizethattrainingwithdemonstrationsthatresemblethetar- inter-classsimilarity,andspatialheterogeneityrespectively.
getimage’sdatadistributionwillenhanceadaptabilityand Tables 4, 5, and 6 compare the performance of different
accuracy. Toachievethis,weusecosinesimilarityofclassi- methodsontheaforementionedVQAtask,respectively.
ficationtokenembeddingstoselectthetop-Ksimilarimages
A.8.ExperimentalSetup
fromthetrainingsetthataremostsimilartothetargetimage.
MAEMIisanAIassistantwithanSMM(smallermultimodal
Tocomprehendhighinter-classsimilarityandconversely,
model)asitsbackbone,specializinginelectronmicroscopic
highintra-classdissimilarity,wegeneratequestion-answer
imageanalysis. Itintegratesvisualandtextualdatatounder-
pairsusingGPT-4Turbowithvisionforeachtargetimage.
standmicroscopicimagesandanswerquestions. TheSMM,
Forinter-classsimilarity,wesamplehighlysimilarimages
with its vision and language capabilities, enables image
acrossnanomaterialcategories. Conversely,forintra-class
captioningandvisualquestionansweringonmicroscopic
dissimilarity, we sample highly dissimilar images within
images. Theproposedvision-and-languageassistantneural
thesamecategory. Thisprocessallowsustogaindeeper
networkarchitectureincludesavisionencoder,apretrained
insightsfromtheelectronmicrographs.
language-only-instruction-tuneddecoder(Llama-2-7b),and
A.7.AdditionalInformation multiple intertwined blocks of gated cross-attention and
Weinvestigatetheeffectofusingtrainingdatawithdiverse self-attentionlayers,allowingfortask-specificadaptation
instructionlengths(image-question-answertriplets)gener- onconsumerhardware.Thisisachievedusingthegenerated
ated by GPT-4 Turbo with Vision on the performance of vision-languageinstruction-tuningdata(image-textpairs)
smaller multimodal models. By incorporating both short createdbyalargemultimodalmodel(GPT-4TurbowithVi-
(concise) and long (detailed) answers for the same natu- sion)totraintheSMMformicroscopicimageanalysistasks.
ral language question into the training datasets, we aim Thesmallermodelleveragestwokeyattentionmechanisms:
to optimize these smaller models for tasks ranging from gatedcross-attentionandself-attention,toprocessbothvi-
basicclassificationandimagecaptioningtocomplexsce- sualandtextualdataandgeneratehuman-likedescriptions.
narioanalysis. Thisapproachofemployingvaried-length Gated cross-attention allows the smaller model to selec-
data offers several potential benefits. Exposing a smaller tively focus on relevant parts of the electron micrograph
modeltodiversesentencestructuresandvisualcomplexities basedonthetextualinput. Self-attentionthenrefinesthe
fostersgreaterflexibilityandadaptability. Thisapproach understandingbyweighingdifferentpartsofthecombined
enhances its ability to process real-world scenarios with information. Despiteitssize,thesmallermodelgenerates
varyinglevelsofdetail,improvinggeneralizabilityandre- accurate, contextually relevant, and coherent text compa-
ducingoverfitting. Furthermore,itchallengesthesmaller rable to larger models, showcasing its ability to interpret
model’sreasoningabilities,promotingadeeperunderstand- naturallanguagequestions,utilizevisualcontext,andpro-
ingoftherelationshipsbetweenvisualfeaturesandtextual duceeffectiveresponses. TotraintheSMMinasupervised
descriptions. Consequently,thesmallermultimodalmodel’s learning setting, we employed the SEM dataset (Aversa
performanceintaskslikeimagecaptioningandVisualQues- etal.,2018),acollectionofelectronmicrographsofvarious
tion Answering (VQA) improves, making it more robust
nanomaterialswithdimensionsof1024×768×3pixels.
andversatileforpracticalapplications. Figures4,5,6,7, Wepreprocessedthemicroscopicimagesbyresizingthem
and8illustrateMAEMI,amultimodalassistantforelectron to224×224×3pixelsandapplyingdatastandardization
micrograph analysis. MAEMI takes a multimodal prompt tonormalizethedatatohaveameanof0.5andavariance
consistingofelectronmicrographsandsupplementaryinfor- of1acrossallchannels. Thispreprocessingensuredthat
mation(e.g.,metadata,annotations)andproducesfree-form imagevaluesfellwithintherangeof-1and1. Tocapture
textasoutput. Figure4and5showvariantsoftheMAEMI localfeatureseffectively,wedividedtheresizedimagesinto
frameworkonthezero/few-shotclassificationtask. Tables smallerpatches,representingthemicrographsassequences
7 and 8 present experimental results comparing the accu- ofpatches. Eachpatchwas32pixelswideandhigh. Weset
racy of our proposed multiclass classification framework boththepatchdimension(d pos)andthepositionembedding
against multiple baseline algorithms. Table 3 shows the dimension (d) to 64 to capture sufficient spatial informa-
framework’sperformanceonopen-endedVQA.Table10 tionwithineachpatchsequence. Thisapproachallowedthe
shows a sample of electron microscope images with true SMMstolearnfromlocalfeatureswithinthemicrographs
labels,generatedcaptions,andsimilarityscores(BLEU-2, whilemaintainingcontextthroughthesequenceofpatches,
ROUGE-L,METEOR)comparingthecaptionstothelabels. improvingtheSMM’sunderstandingandanalysisofcom-
Samplequestionsandanswersfromtheinstruction-tuning plexnanomaterials. Parameter-efficientfine-tuningofthe
Q&A dataset (created by GPT-4 Turbo with Vision) for Llama-2-7bmodelleveragesthedynamicadaptationwith
trainingMAEMIareshowninTables11-20. Figures6,7, activation memory reduction (DyQLoRA-FA) technique,
13Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
characterizedby threekeyhyperparameters: a) Rank(r): sequences)betweenthetranslatedtextandreference
Thisparameterbalancesthesmallermodel’scapacityand texts, considering various n-gram lengths. BLEU
complexitybycontrollingthelow-rankapproximationof mainly evaluates translation precision, ensuring the
thetrainableweightmatrices.Duringtraining,risrandomly machinetranslation’swordsandphrasesappearinthe
selectedfromapredefinedrange(r = 4,r = 16). referencetexts. Itcountsmatchingn-grams,usinga
min max
Ahigherrankyieldsamoreexpressivemodelwithmore clippingmechanismtoavoidover-countingincasesof
adaptable parameters, while a lower rank promotes com- n-gramrepetition. Thescorerangesfrom0to1,with
putationalefficiency. (b)Alpha(α): Thisscalingfactoris 0indicatingnooverlapand1denotingcompletesimi-
typicallysettoasmallvalue,suchas 1,basedontherank. larity. Higherscoressuggestbettertranslationquality.
r
Alpha controls the step size of the parameter updates. A
• METEOR (Metric for Evaluation of Transla-
larger alpha enables more aggressive updates, which can
tion with Explicit Ordering): METEOR evaluates
improveperformancebutmayalsocausetraininginstabil-
machine-generated text against ground-truth refer-
ity. (c) LoRA dropout: Specifically applied to low-rank
ences, measuring overlap and considering linguistic
adapterlayers,thisdropoutmechanismcombatsoverfitting
qualitieslikesynonymyandparaphrasing. Itusesan
andenhancesgeneralization. Atypicalvalueforthishyper-
alignmentmoduletomapunigramsbetweenthecan-
parameteris0.05. Weutilize8-bitweightquantizationfor
didateandreferencetexts,prioritizingexactmatches,
pre-trainedmodelweightsviatheDyQLoRA-FAtechnique
stem/lemma matching, and semantic similarity. To
toenableefficientfine-tuningonconsumerhardwarewhile
evaluateperformance,itanalyzesbothhowmuchof
retainingcomparableperformance. Thetrainingregimefor
thereferencetextisaddressed(coverageforrecall)and
theSMMcomprised50epochs,employinganinitiallearn-
ingrateof1×10−3toensurecontrolledoptimization,and how closely the generated text matches the wording
(alignment for precision). Scores range from 0 to 1,
abatchsizeof32. Fortheself-attentionandcross-attention
withhighervaluesindicatingbetterperformance. Un-
layers, we configured the number of attention heads (H)
likeBLEU,METEORbetteralignswithhumanquality
tobe4andthedimensionalityofKey/Query/Value(d )to
h
judgmentsbyconsideringrecall,linguisticvariations,
be 32. To optimize SMM performance, we implemented
and stronger correlation at the sentence or segment
twokeystrategies: (a)Earlystoppingonthevalidationset:
level.
We halted the training when the SMM’s performance on
thevalidationdataplateaued, effectivelypreventingover-
• ROUGE Score (Recall-Oriented Understudy for
fitting;(b)Learningratescheduler: Thelearningratewas
Gisting Evaluation): ROUGE measures the quality
systematicallyreducedbyhalfifthevalidationlossdidnot
of generated text by comparing it with ground-truth
improveforfiveconsecutiveepochs.Thisreductionassisted
references. It analyzes overlapping textual elements
theSMMinconvergingtoabettersolutionandfurthermit-
(likewordsorphrases)betweenthecandidateandrefer-
igated overfitting. Furthermore, we employed the Adam
encetexts. ThebasicROUGE-Nmetriccomputesthe
optimizationalgorithm(Kingma&Ba,2014)toupdatethe
numberofoverlappingn-grams.VariantslikeROUGE-
SMM’s trainable parameters. In our work, we have two
L, ROUGE-W, and ROUGE-S measure the longest
typesofinstruction-followingdata: (a)amulti-classclas-
commonsubsequence,fullwordconsecutivematches,
sificationtask-identificationofnanomaterialcategoryin
andskip-bigrammatches,respectively. Scoresrange
zero/fewshotsettings,and(b)anopen-endedvisualques-
from0to1,where0meansnooverlapand1indicates
tionanswering(VQA)task. Forsupervisedfine-tuning,we
completeoverlap. Higherscoressuggestbetterquality,
minimize the standard cross-entropy loss built using the
showingthemodel’ssummarycapturescontentsimilar
PyTorchframework. WeutilizeNvidiaV100GPUs(32GB
tohumanreferences.
RAM)todevelopthecustomSMMmodel.
A.9.EvaluationMetrics
Inthefieldofimage-captioning,visualquestionanswering
(VQA),severalmetricsareusedtoevaluatethequalityof
thegeneratedtext. Thesemetricsassessdifferentaspects
oftextgeneration,suchasitssimilaritytoreferencetexts,
grammaticalcorrectness,andsemanticrelevance. Here’san
overviewofsomekeymetrics:
• BLEU Score (Bilingual Evaluation Understudy):
TheBLEUscorescoreevaluatesmachine-generated
textqualitybymeasuringitssimilaritytoground-truth
references. Itcomparestheoverlappingn-grams(word
14Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Output: text
Particles
Trained
Feed Forward layer
Frozen
𝓁-th SELF ATTN BLOCK
𝓁-th GATED CROSS ATTN Self Attention
K=V =[Y] Q=[Y]
1-st SELF ATTN BLOCK tanh gating
Vision
Feed Forward layer
Encoder 1st GATED CROSS ATTN
DyQLoRA-FA LLaMA-7b
tanh gating
Processed text
Cross Attention
<image> This is an electron microscopy image. Predict the category of the image
from these 10 categories: Biological, Fibres, Films and Coated Surfaces, MEMS K=V =[X] Q=[Y]
Devices and Electrodes, Nanowires, Particles, Patterned Surface, Porous Sponge, X Y
Powder, Tips. Vision Language
Input: visual data and text Input Input
This is an electron microscopy image. Predict the category of the
image from these 10 categories: Biological, Fibres, Films and
Coated Surfaces, MEMS Devices and Electrodes, Nanowires,
Particles, Patterned Surface, Porous Sponge, Powder, Tips.
Figure4.Theschematicillustratesthesmall-scale,multimodalassistantforelectronmicrographanalysis(MAEMI),acontent-aware,
visually-conditioned,autoregressivetextgenerationmodelthattakesamultimodalpromptcontainingelectronmicrographsinterleaved
withtextualdescriptions,andproducesfree-formtextasoutput.Theinputconsistsofatargetimage,user-providedsupplementarytext,
andtask-specificinstruction.Thegoalistocategorizetheimageintooneoftencategoriesinazero-shotsetting.
Output: text
Trained Particles
Feed Forward layer
Frozen
𝓁-th SELF ATTN BLOCK
Self Attention
𝓁-th GATED CROSS ATTN K=V =[Y] Q=[Y]
tanh gating
Vision 1-st SELF ATTN BLOCK
Encoder Feed Forward layer
1st GATED CROSS ATTN
DyQLoRA-FA LLaMA-7b tanh gating
Concatenate Processed text Cross Attention
S=0 S=4 S=5 <image> <image> These electron microscopy images belong K=V =[X] Q=[Y]
to the particle-based nanomaterial category. <image> Predict the X Y
query image label. Vision Language
Input Input
Input: visual data and text
These electron microscopy images belong to the particle-based nanomaterial category. Predict the query image label.
Figure5.Theschematicillustratesasmall-scale,multimodalassistantforelectronmicrographanalysis(MAEMI),avisually-conditioned,
autoregressivetextgenerationmodel.Themultimodalinputconisitsofmicroscopicimagesarbitrarilyinterleavedwithtextualdescriptions
andproducesfree-formtextasoutput.Theinputincludesafewdemonstrationexamplesasinput-outputmappings(microscopicimages
theircorrespondinglabels),andatask-specificinstruction.Thegoalistopredictthelabelforthetargetimageinafew-shotsetting.
15Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Output: text The electron microscopy images depict diverse films and coated
surfaces nanomaterials: a dense uniform film, a fibrous coating,
Trained granular particulate surface, and a smooth layered coating.
Feed Forward layer
Frozen
𝓁-th SELF ATTN BLOCK
Self Attention
𝓁-th GATED CROSS ATTN K=V =[Y] Q=[Y]
tanh gating
Vision 1-st SELF ATTN BLOCK
Encoder Feed Forward layer
1st GATED CROSS ATTN
DyQLoRA-FA LLaMA-7b tanh gating
Concatenate Processed text Cross Attention
S=0 S=1 S=2 S=3 <image> <image> <image> <image> These electron microscopy K=V =[X] Q=[Y]
images exhibit considerable variation within the group yet all fall
under the films and coated surfaces category of nanomaterials. X Y
Vision Language
Provide a brief analysis of the characteristics that define them as such.
Input Input
Input: visual data and text
These electron microscopy images exhibit considerable variation within the group yet
all fall under the films and coated surfaces category of nanomaterials. Provide a brief
analysis of the characteristics that define them as such.
Figure6.Theschematicillustratestheproposedsmall-scalemultimodalassistantforelectronmicrographanalysis(MAEMI).Itleverages
amultimodalpromptthatinterleavesvisualdatafromelectronmicroscopyimageswithuser-providedauxiliarytextdatatogenerate
descriptiveoutput.Themultimodalmodelisdesignedtogenerateaccurateandconcisedescriptionsofthevisualfeaturesinhigh-contrast
images,linkingthemtotheclassificationoftheelectronmicrographsintoaspecificnanomaterialcategory.Duringinference,MAEMI
utilizesitsdomain-specificknowledgetointerpretintertwinedvisualfeaturesandquerytext,generatingaccurateandinformativeresponses
aboutmicroscopicimageswithinthespecifiedcategory.Note:Forclarityandbrevity,theoutputtexthasbeensimplified.
Output: text The electron microscopy images show smooth films and coated
surfaces, discrete particles, networked porous sponges, and
Trained clustered powders, each with distinctive textures and structures.
Feed Forward layer
Frozen
𝓁-th SELF ATTN BLOCK
Self Attention
𝓁-th GATED CROSS ATTN K=V =[Y] Q=[Y]
tanh gating
Vision 1-st SELF ATTN BLOCK
Encoder Feed Forward layer
1st GATED CROSS ATTN
DyQLoRA-FA LLaMA-7b tanh gating
Concatenate Processed text Cross Attention
S=0 S=1 S=2 S=3 < wi hm ila eg se i> m < ili am r,a sg he o> w < ci am sa eg de i> st < inim cta ng ae n> o mTh ae ts ee ri ae ll e tc yt pr eo sn : Fm ili mcr so s ac no dp Cy oim ata eg de s, K=V =[X] Q=[Y]
Surfaces, Particles, Porous Sponges, and Powders (from left to right). X Y
Describe the specific features that differentiate these categories. Vision Language
Input Input
Input: visual data and text
These electron microscopy images, while similar, showcase distinct nanomaterial types: Films and
Coated Surfaces, Particles, Porous Sponges, and Powders (from left to right). Describe the specific
features that differentiate these categories.
Figure7.TheschematicillustratesMAEMI,aproposedsmall-scalemultimodalassistantfortheVQAtaskonelectronmicrographs.It
leveragesamultimodalpromptthatinterleavesvisualdataofsimilar-looking,high-resolutionelectronmicrographsshowcasingdiverse
nanomaterialcategoriessuchasfilmsandcoatedsurfaces,particles,poroussponges,andpowderswithuser-providedauxiliarytextdata.
Additionally,MAEMIreceivesspecificuserqueriesthatpromptittoanalyzeanddescribetheuniquevisualfeaturesdistinguishingeach
category,therebygeneratingpreciseandconciseresponsesdescribingtheuniquevisualfeaturesdistinguishingeachcategory. Note:
Theoutputtextissimplifiedforthesakeofillustrationandconciseness.
16Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Output: text The images depict nanoscale particles with varied shapes,
aggregation, and contrast, typical features of nanomaterials under
Trained electron microscopy.
Feed Forward layer
Frozen
𝓁-th SELF ATTN BLOCK
Self Attention
𝓁-th GATED CROSS ATTN K=V =[Y] Q=[Y]
tanh gating
Vision 1-st SELF ATTN BLOCK
Encoder Feed Forward layer
1st GATED CROSS ATTN
DyQLoRA-FA LLaMA-7b tanh gating
Concatenate Processed text Cross Attention
S=0 S=1 S=2 S=3 <image> <image> <image> <image> These electron microscopy K=V =[X] Q=[Y]
images have spatial heterogeneity and belong to particles
nanomaterial category. Give me a brief description of how their X Y
Vision Language
features classify them into this specific category.
Input Input
Input: visual data and text
These electron microscopy images have spatial heterogeneity and belong to particles
nanomaterial category. Give me a brief description of how their features classify them
into this specific category.
Figure8.Theschematicoutlinesthearchitectureofthesmall-scalemultimodalassistant(MAEMI),whichistailoredfortheanalysisof
electronmicroscopyimagesofnanomaterials.Ittakesbothvisualandtextualinputs:aseriesofhigh-resolutionelectronmicrographs
showcasing the spatial variations and diverse morphologies of theparticles, combined with user-provided auxiliary text data. The
multimodalmodel,guidedbyuserinstructions,producesbrief,precisedescriptions,highlightingthevisualfeaturesuniquetoeach
nanomaterialcategoryunderlyingtheimages. Forclarityandbrevity,theoutputtexthasbeensimplified. Note: We’vepresentedthe
outputtextinasimplifiedformatforbetterreadability.
Table3. TableshowstheperformanceofsLAVAcomparedtobaselinesonopen-endedVQAtask.
Method BLEU-2(↑) BLEU-4(↑) ROUGE-1(↑) ROUGE-2(↑) ROUGE-L(↑) METEOR(↑)
InstructBLIP(Daietal.) 0.704±0.063 0.571±0.078 0.808±0.032 0.710±0.011 0.765±0.042 0.822±0.048
LLaVA(Liuetal.,2023) 0.711±0.070 0.579±0.085 0.809±0.032 0.713±0.011 0.767±0.042 0.823±0.046
MiniGPT-4(Zhuetal.,2023) 0.735±0.075 0.598±0.090 0.823±0.033 0.726±0.012 0.780±0.043 0.842±0.047
MAEMI 0.801±0.085 0.731±0.105 0.903±0.036 0.785±0.014 0.834±0.050 0.882±0.055
Table4. ThetableshowssLAVAexcelsonVQAtaskonhighintra-dissimilarityofnanomaterials.
Method BLEU-2(↑) BLEU-4(↑) ROUGE-1(↑) ROUGE-2(↑) ROUGE-L(↑) METEOR(↑)
InstructBLIP(Daietal.) 0.667±0.063 0.541±0.078 0.764±0.032 0.672±0.011 0.724±0.042 0.778±0.048
LLaVA(Liuetal.,2023) 0.651±0.070 0.530±0.085 0.740±0.032 0.652±0.011 0.702±0.042 0.754±0.046
MiniGPT-4(Zhuetal.,2023) 0.673±0.075 0.548±0.090 0.754±0.033 0.664±0.012 0.714±0.043 0.770±0.047
MAEMI 0.732±0.085 0.668±0.105 0.826±0.036 0.717±0.014 0.762±0.050 0.807±0.055
Table5. ThetableshowssLAVAexcelsonVQAtaskonhighinter-similarityofnanomaterials.
Method BLEU-2(↑) BLEU-4(↑) ROUGE-1(↑) ROUGE-2(↑) ROUGE-L(↑) METEOR(↑)
InstructBLIP(Daietal.) 0.676±0.063 0.548±0.078 0.775±0.032 0.682±0.011 0.734±0.042 0.789±0.048
LLaVA(Liuetal.,2023) 0.675±0.070 0.550±0.085 0.767±0.032 0.677±0.011 0.730±0.042 0.782±0.046
MiniGPT-4(Zhuetal.,2023) 0.690±0.075 0.561±0.090 0.773±0.033 0.682±0.012 0.733±0.043 0.791±0.047
MAEMI 0.744±0.085 0.679±0.105 0.841±0.036 0.730±0.014 0.775±0.050 0.820±0.055
Table6. ThetableshowssLAVAexcelsonVQAtaskrelatedtonanomaterials’spatialheterogeneity.
Method BLEU-2(↑) BLEU-4(↑) ROUGE-1(↑) ROUGE-2(↑) ROUGE-L(↑) METEOR(↑)
InstructBLIP(Daietal.) 0.614±0.055 0.496±0.068 0.703±0.028 0.619±0.010 0.667±0.037 0.716±0.042
LLaVA(Liuetal.,2023) 0.620±0.061 0.503±0.074 0.704±0.028 0.622±0.010 0.669±0.037 0.717±0.040
MiniGPT-4(Zhuetal.,2023) 0.640±0.066 0.521±0.079 0.717±0.029 0.632±0.010 0.681±0.037 0.734±0.041
MAEMI 0.698±0.074 0.637±0.092 0.787±0.031 0.684±0.012 0.728±0.044 0.769±0.048
17Instruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
A.10.EmpiricalInsightsintoNanomaterial
Classification
Ourresearchthoroughlyevaluatedtheproposedframework
MAEMIforclassifyingelectronmicrographsofdiversenano-
materials. These complex materials vary in composition,
Table8.Thetableshowsthecomparisonofsupervised-learning
morphology,structure,andotherproperties,whichisevi-
GNNs(GraphNeuralNetworks),self-supervisedGCL(GraphCon-
dentintheirelectronmicrographs. Theframeworkachieved
trastingLearning)algorithmsontheclassificationtask.
highaccuracyontheimbalancedSEMdataset(Aversaetal.,
2018) using metrics like precision, recall, and F1-score, Algorithms Top-1 Top-5
demonstratingitseffectivenessincategorizingnanomateri- GBT(Bielaketal.,2021) 0.547 0.706
GRACE(Zhuetal.,2020) 0.598 0.750
alswithdifferentpatternsinazero-/few-shotsetting. Table
BGRL(Thakooretal.,2021) 0.556 0.696
9 reports the experimental results. The multi-metric ap-
InfoGraph(Sunetal.,2019) 0.526 0.702
proachprovidedadetailedanalysis,highlightingMAEMI’s APPNP(Klicperaetal.,2018) 0.632 0.786
efficiencyinhandlingvariouscategories,especiallythose AGNN(Thekumparampiletal.,2018) 0.538 0.894
with fewer labeled instances. Overall, our findings con- ARMA(Bianchietal.,2021) 0.582 0.987
DNA(Fey,2019) 0.622 0.916
firmMAEMI’srobustnessinclassifyingnanomaterials,con-
GAT(Velicˇkovic´etal.,2017) 0.491 0.985
tributingtoadvancementsinmaterialscharacterizationand
GGConv(Lietal.,2015) 0.563 0.992
research. GraphConv(Morrisetal.,2019) 0.658 0.996
GCN2Conv(Chenetal.,2020a) 0.732 0.998
Table7.Tableshowstheperformancecomparisons:Ourmethod ChebConv(Defferrardetal.,2016) 0.504 0.951
vs.ConvNets,visiontransformers(ViTs),&visionself-supervised GraphConv(Morrisetal.,2019) 0.509 0.993
GraphUNet(Gao&Ji,2019) 0.657 0.978
learning(VSL)algorithmsforclassificationtask.
MPNN(Gilmeretal.,2017) 0.603 0.999
Algorithms Top-1 Top-5 RGGConv(Bresson&Laurent,2017) 0.618 0.961
SuperGAT(Kim&Oh,2022) 0.598 0.985
AlexNet((Krizhevskyetal.,2017)) 0.528 0.827 TAGConv(Duetal.,2017) 0.598 0.999
DenseNet((Huangetal.,2017)) 0.569 0.929 Zero-Shot-ImageCaptioning/MAEMI 0.773 0.876
ResNet((Heetal.,2016)) 0.485 0.897
Few-Shot-ImageCaptioning/MAEMI 0.965 0.991
VGG((Simonyan&Zisserman,2014)) 0.538 0.808
GoogleNet((Szegedyetal.,2015)) 0.609 0.969
SqueezeNet((Iandolaetal.,2016)) 0.404 0.698
Barlowtwins(Zbontaretal.,2021) 0.148 0.410
SimCLR(Chenetal.,2020b) 0.130 0.379
byol(Grilletal.,2020) 0.143 0.453
moco(Heetal.,2020) 0.169 0.472
simsiam(Chen&He,2021) 0.188 0.535
CCT(Hassanietal.,2021) 0.570 0.981
CVT(Wuetal.,2021) 0.577 0.930
ConViT(d’Ascolietal.,2021) 0.609 0.957 Multi-classmetrics
Category
ConvVT(Wuetal.,2021) 0.319 0.921
Precision Recall F1Score
CrossViT(Chenetal.,2021b) 0.442 0.915
SwinT(Liuetal.,2021) 0.707 0.993 Biological 0.949±0.009 0.981±0.007 0.954±0.013
VanillaViT(Dosovitskiyetal.,2020) 0.655 0.970 Tips 0.939±0.005 0.952±0.008 0.936±0.011
Visformer(Chenetal.,2021c) 0.398 0.856 Fibres 0.982±0.007 0.987±0.000 0.982±0.000
ATS(Fayyazetal.,2021) 0.540 0.973 PorousSponge 0.956±0.014 0.955±0.013 0.955±0.010
CaiT(Touvronetal.,2021b) 0.657 0.989 FilmsCoatedSurface 0.961±0.005 0.960±0.009 0.961±0.008
DeepViT(Zhouetal.,2021) 0.546 0.988 PatternedSurface 0.969±0.016 0.968±0.006 0.953±0.014
Dino(Caronetal.,2021) 0.049 0.437 Nanowires 0.953±0.012 0.965±0.007 0.977±0.011
Distillation(Touvronetal.,2021a) 0.533 0.955 Particles 0.961±0.006 0.959±0.011 0.942±0.023
LeViT(Grahametal.,2021) 0.624 0.970 MEMSDevices 0.965±0.011 0.953±0.008 0.953±0.009
NesT(Zhangetal.,2022) 0.660 0.985 Powder 0.959±0.014 0.960±0.009 0.940±0.011
PatchMerger(Rengglietal.,2022) 0.578 0.975
PiT(Heoetal.,2021) 0.555 0.979 Table9.Thetableshowstheeffectivenessofourproposedframe-
RegionViT(Chenetal.,2021a) 0.606 0.948
work,comparedtoexistingmethods,intermsofprecision,recall,
SMIM(Xieetal.,2021) 0.171 0.646
andF1-scoreforaccuratelyclassifyingnanomaterialsofdifferent
T2TViT(Yuanetal.,2021) 0.749 0.992
categories.
ViT-SD(Leeetal.,2021) 0.597 0.973
Zero-Shot-ImageCaptioning/MAEMI 0.773 0.876
Few-Shot-ImageCaptioning/MAEMI 0.965 0.991
18
steNvnoC
LSV
)sTiV(sremrofsnarTnoisiV
LCG
skrowteNlarueNhparGInstruction-TuningSmall-ScaleLanguage-and-VisionAssistantforElectronMicrographAnalysis
Table10.Thetableshowsaselectionofelectronmicroscopeimageswiththeircorrespondingtruelabelsforanopen-endedVQAtaskthat
describestheoverallshapeandmorphologyofthenanomaterialsunderlyingtheelectronmicrographs.Wealsoincludetheframework
generatedresponsesordescriptionsforeachimage.Additionally,theBLEU-2,ROGUE-L,andMETEORmetricsareincludedtoevaluate
theirsimilaritytotheaccuratelabels.
BLEU-2/
Image GroundTruth Answers ROGUE-L/
METEOR
The nanomaterials exhibit a The nanomaterials exhibit a
branched, web-like structure with branched, web-like structure with
0.786
varyingstrandthickness,indicative varying strand thicknesses, sug-
0.872
of a porous, high-surface-area gestingaporous,high-surface-area
0.947
morphology. morphology
The nanomaterials have a twisted, Thenanomaterialspossessatwisted,
0.461
rope-likemorphologywithmultiple rope-like morphology, featuring
0.872
strandsintertwinedtogether. multiplestrandsintertwined
0.827
Thenanomaterialsarepolygonal,re- The nanomaterials appear polygo-
0.770
semblingamosaicoftightlypacked, nal,resemblingamosaicoftightly
0.872
irregularlyshapedflatplates. packed,irregularshapedflatplates.
0.850
Theimageshowcasesamicrofabri- Thisimageshowcasesamicrofabri-
cated pattern with a square central cated pattern with a square central
0.844
areaandsymmetricallyarrangedge- areaandsymmetricallyarrangedge-
0.872
ometriclinepatternsextendingout- ometriclinesextendingoutwardon
0.917
wardonaporousbackground. aporousbackground.
The nanomaterials are cylindrical The nanomaterials are cylindrical
rods standing vertically with uni- rods, standing vertically with uni- 0.787
formalignmentandconsistentspac- formalignmentandconsistentspac- 0.872
ingbetweenthem. ingamongthem. 0.861
Thenanomaterialsexhibitrod-like Thenanomaterialsexhibitrod-like
andellipsoidalshapeswithsmooth and ellipsoidal shapes, featuring 0.736
surfaces and are well-dispersed smooth surfaces and are well- 0.872
acrossthesubstrate. dispersedoverthesubstrate 0.808
The nanomaterials have a hexago- The nanoscale materials have a
nal shape with well-defined edges hexagonalshapewithwell-defined 0.618
and are arranged in an ordered, edges and are positioned in an or- 0.872
honeycomb-likepattern. derly,honeycomb-likearrangement 0.749
Thenanomaterialsdisplayaporous, Thenanomaterialsdisplayaporous,
foam-likestructurewithirregularly foam-like structure, having irregu- 0.847
shapedvoidsandanetworkofinter- larlyshapedvoidsandanetworkof 0.872
connectedstruts. interconnectedstruts 0.881
The nanomaterials appear as clus- Thenanomaterialsaredisplayedas
0.738
tered, irregularly shaped particles clustered, irregularly shaped parti-
0.872
witharoughsurfacetexture. cleswitharoughsurfacetextures.
0.837
Thenanomaterialisconicalwitha Thenanomaterialisconical,featur-
0.780
pointedtipandasmoothgradientin ingapointedtipandasmoothgradi-
0.872
diameterfrombasetoapex. entindiameterfromitsbasetoapex.
0.881
19Table11: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
patternedsurfacenanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuningofsmaller
modelsfortheanalysisandinterpretationofcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimageofpatternedsurface
nanomaterials,pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Theimageisascanningelectronmicroscope(SEM)imageofapatterned
surfacenanomaterial,withascalebarindicatingthat1micrometer(µm)is
theunitofmeasurement.
**MorphologyandStructure** Thenanomaterialsintheimagehaveahexagonalshapeormorphology.
Theredonotappeartobedistinctlayers,phases,ordomainswithintheindi-
vidualhexagonalunits,butthereisaconsistentpatterntotheirarrangement.
Thenanomaterialsappeartobeuniforminsizeandshape,suggestinga
controlledfabricationprocess.
**SizeandDistribution** Thenanostructuresarehexagonalanduniforminsize,likelyinthehun-
dredsofnanometersrange,judgingbythe1µmscalebar. Theyareevenly
spacedthroughouttheimagewithnoevidenceofaggregationorbundling.
**SurfaceCharacteristics** Thenanomaterialappearstohaveatexturedsurface,possiblyduetothe
patterning technique used to create the hexagonal shapes. No visible
defects,pores,orimpuritiesareapparentintheimageprovided,suggesting
acleananduniformfabricationprocess.
**CompositionandElements** TheSEMimageismonochromatic,withbrightnessandcontrastvariations
hinting at topographical or compositional differences. The absence of
specificlabelsormarkersmeansexactcompositioncan’tbedetermined.
AnnotationsarestandardSEMparameters,notcompositionaldata.
**InteractionsandBoundaries** Theindividualnanostructuresareseparate,withclearboundariesbetween
them, and do not appear to be touching or fused. There is a consistent
gap that defines the boundaries of each hexagonal structure, indicating
well-definedindividualunits.
**ExternalEnvironment** TheSEMimagedisplaysisolatednanomaterials, freefrominteractions
with solvents, polymers, or other substances. The uniform, featureless
backgroundindicateseitheravacuumoranon-descriptsolidsubstrateat
thismagnification,withnoothervisiblestructuresorobjectsunrelatedto
thepatternednanomaterials.
**Image Technique and Modifica- TheimagewastakenwithaScanningElectronMicroscope(SEM),evi-
tions** dentfromtypicalSEMannotationslike“EHT”and“WD”. Itshowsno
signsofpost-processing,suchasfalsecoloring,andappearsasastandard
monochromaticSEMoutput.
**FunctionalFeatures** There are no obvious functional features like active sites with distinct
propertiesvisibleinthisimage.
**ContextandApplication** Theintendedapplicationofthenanomaterialisunclearwithoutcontext.
TheimageisarealSEMcaptureofanexperimentalsample,notatheoreti-
calorsimulation-basedrepresentation.Table12: Thetablepresentsaninstruction-followingdataset,comprisingimage-question-answertriplesgenerated
using GPT-4 Turbo with vision in response to open-ended natural language prompts about a microscopic image
depictingbiologicalnanomaterials. Insummary,thisGPT-assistedvision-languagedatasetfacilitatesthetrainingof
smallermodels,enablingthemtoeffectivelyanalyzecomplexmicroscopicimagesforopen-endedVQAtasks.
Basedontheprovidedimageofbiological
nanomaterials,pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Thebiologicalnanomaterialshownintheimageisaneuronwithitsden-
dritictree. Thescalebarrepresentstwomicrometers(2µm),providinga
referenceforthesizeofthestructuresintheimage.
**MorphologyandStructure** The nanomaterials in the image are biological in nature and exhibit a
complexmorphologycharacteristicofneuronalcells. Theneuronhasa
prominent cell body from which multiple dendrites extend, forming an
intricate network. There are no distinct layers, phases, or domains in
thetraditionalmaterialsciencesense,asthisisabiologicalsample. The
neurondisplayscompartmentalizationwiththecellbody,dendrites,and
possiblyaxonhillocksorinitialsegmentsvisible. Thenanomaterialsare
varied in size and shape, as typical for biological structures. Dendrites
exhibitdiversethickness,length,andbranchingpatterns,reflectinginherent
biologicalvariability.
**SizeandDistribution** The individual nanostructures, the dendrites, vary in size but typically
rangefromafewhundrednanometerstoacoupleofmicrometersindiam-
eter. Theyaredistributedthroughouttheimageinaconnected,somewhat
randompattern,emanatingfromacentralneuroncellbody. Thereisno
evidenceofaggregationorbundling,asthesestructurestendtospreadout
ratherthanclustertogether.
**SurfaceCharacteristics** Thenanomaterial,whichisaneuronwithitsdendritictree,appearstohave
atexturedsurfacecharacteristicofbiologicalstructures,ratherthanbeing
smooth. Thedendritesandcellbodyshowacomplex, granularsurface
textureunderthemagnificationprovided. Nospecificdefects,pores,or
impuritiescanbediscernedfromthisimage;suchfeatureswouldrequire
highermagnificationtoresolve.
**CompositionandElements** The monochromatic image, typical of electron microscopy, lacks color-
basedcompositionalvariations. Yet,itshowsvariationsinbrightnessand
contrast,suggestingtopographicalormaterialdensitydifferencesinthe
neuronanditsdendrites.
**InteractionsandBoundaries** Themonochromaticelectronmicroscopeimageshowstopographicaland
densityvariations,butnocompositionaldifferencesorlabeledelements.
**ExternalEnvironment** The SEM image shows only the isolated neuron, with no evidence of
externalinteractionsormatrixmaterial.
**Image Technique and Modifica- The image was captured using Scanning Electron Microscopy (SEM).
tions** Thereisnoevidentpost-processingormodificationslikefalsecoloringor
3Drendering;itappearstobeastandardgrayscaleSEMimage
**FunctionalFeatures** TheSEMimageoftheneurondoesnotvisiblyshowanyspecificfunctional
featureslikeactivesites.
**ContextandApplication** Theimageisofanexperimentalsample, anactualneuron, capturedus-
ing Scanning Electron Microscopy (SEM), rather than a theoretical or
simulation-basedrepresentation.Table13: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
using GPT-4 Turbo with vision in response to open-ended natural language prompts about a microscopic image
depictingfibersnanomaterial. Insummary,thisGPT-assistedvision-languagedatasetfacilitatesthetrainingofsmaller
models,enablingthemtoeffectivelyanalyzeandinterpretcomplexmicroscopicimagesforopen-endedVQAtasks.
Basedontheprovidedimageoffibresnanomaterials,
pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Theimageshowsnanofibers,whichareextremelyfinefiberswithdiameters
in the nanometer range. The scale of the image is not indicated, so it’s
notpossibletodeterminetheexactmeasurementwithoutascalereference.
However,giventhatthesearenanofibers,wecaninferthatthewidthof
thesefibersislikelyintherangeoftenstohundredsofnanometers.
**MorphologyandStructure** Thenanomaterialsintheimagehaveafibrousmorphology,indicatinga
long,slendershape. Therearenodistinctlayers,phases,ordomainsvisible
intheimageprovided. Thefibersseemfairlyuniforminshape,suggesting
a controlled synthesis process. However, due to the image’s resolution
andtheabsenceofascale,itischallengingtoaccuratelycommentonthe
uniformityofsize.
**SizeandDistribution** Thefibersappeartobeintherangeofnanometersindiameter,although
the exact size cannot be determined without a scale. They are densely
distributed,withsomebundlingandclusteringvisible.
**SurfaceCharacteristics** Thenanomaterialfibersappeartohaveasmoothtextureoverall. Noclear
defects,pores,orimpuritiesarevisiblefromthisimage. Theresolutionis
notsufficienttoidentifyfinersurfacedetails.
**CompositionandElements** The image is in grayscale, and there are no visible labels or markers
indicatingspecificelementsorcompounds. Therearenoapparentcolor
variationsthatwouldsuggestcompositionaldifferences. Theuniformity
ofcontrastthroughoutthefiberssuggeststheyarelikelycomposedofa
singlematerialorthatanycompositionalvariationsarenotdiscernibleat
thisscaleandimagequality.
**InteractionsandBoundaries** The nanostructures appear to be touching and interacting closely, with
somedegreeoffusionorentanglement,typicalforfibrousnetworks. There
arenoclearboundariesbetweendifferentstructuresorphases;itlookslike
acontinuousphaseofsimilarfibers.
**ExternalEnvironment** TheSEMimageshowsisolatednanofiberswithnovisibleexternalinterac-
tionsormatrix.
**Image Technique and Modifica- Thegrayscaleimage,likelycapturedviaastandardscanningelectronmi-
tions** croscope(SEM),showcasesnanomaterialsinsharpdetail,typicalofSEM
outputs. Noevidencesuggestspost-processing,likefalsecoloringor3D
rendering,indicatingastraightforwardSEMimagewithoutmodifications.
**FunctionalFeatures** Theimagedoesnotshowanydistinctfunctionalfeatureslikeactivesitesor
regionswithvaryingproperties;itappearstobeauniformstructure. Since
it’sanSEMimage,itcapturesastaticrepresentationofthenanofibersand
doesnotdepictanydynamicprocesses.
**ContextandApplication** Theintendedapplicationofthenanomaterialintheimagecannotbedeter-
minedwithoutadditionalcontext. Theimageappearstobeofanexperi-
mentalsample,typicalofreal-worldSEMimaging,ratherthanatheoretical
orsimulation-basedrepresentation.Table14: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
filmsandcoatedsurfacesnanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuningof
smallermodelsfortheanalysisandinterpretationofcomplexmicroscopicimagesinthecontextofopen-endedVQA
tasks.
Basedontheprovidedimageoffilmsandcoated
surfacenanomaterials,pleaseanswerthefollowing
questions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** TheimageisaScanningElectronMicroscope(SEM)imageofananoma-
terial,possiblymetallicorceramicnanoparticles. Thescalebarindicates
that1micrometer(µm)isrepresented,allowingforthesizeoftheparticles
tobeestimatedinrelationtothisscale.
**MorphologyandStructure** Thenanomaterialsintheimagehaveageneralmorphologythatappearsto
bepolygonal,withmostparticlesexhibitingangularedgesandflatsurfaces.
Therearenodistinctlayers,phases,ordomainsvisible;itappearstobea
homogenoussurfaceofsimilarparticles. Theparticlesseemtobefairly
uniforminsizeandshape,suggestingacontrolledsynthesisprocess.
**SizeandDistribution** Theindividualnanostructuresappeartobeinthesub-micronsizerange,
likelyseveralhundrednanometersacross,giventhescalebarof1microm-
eterforreference. Theyaredistributedthroughouttheimagequitedensely,
withlittletonospacebetweenadjacentparticles,whichindicatesauniform
surfacecoverage. Thereseemstobeminimalaggregationorbundling;the
particlesmostlyappearasdistinctentitieswithsomecontactpoints,which
istypicalforparticlesthathavesettledoutofadispersionontoasubstrate.
**SurfaceCharacteristics** Thenanomaterialsurfaceappearstoberelativelyroughwithatextured
appearance,whichischaracteristicofaggregatednanoparticles. Thereare
noobviousdefects,pores,orimpuritiesvisibleatthismagnification. The
roughnessislikelyduetotheindividualparticles’edgesandsurfacesrather
thanafeatureoftheparticlesthemselves.
**CompositionandElements** There is no evidence of compositional variations in the grayscale SEM
image,andtherearenolabelsindicatingspecificelementsorcompounds.
The uniformity in color suggests a homogenous material, but specific
compositioncannotbedeterminedfromthisimagealone.
**InteractionsandBoundaries** Theindividualnanostructuresaretouchingandseemtobesintered,with
nocleargapsbetweenthem. Thereareclearboundariesbetweenindividual
particles,butnodistinctphasesorseparatestructuresarevisible.
**ExternalEnvironment** No,thereisnoevidenceofthenanomaterialinteractingwithanysurround-
ingenvironmentormatrixintheSEMimage,andnootherstructuresor
objectsarepresentotherthanthenanomaterialsthemselves.
**Image Technique and Modifica- TheimagewascapturedusingaScanningElectronMicroscope(SEM).
tions** Therearenoindicationsofpost-processingormodificationssuchasfalse
coloringor3Drendering;itappearstobeastandardgrayscaleSEMimage.
**FunctionalFeatures** In the SEM image, functional features like active sites or regions with
distinct properties are not discernible. SEM images typically provide a
staticrepresentationandcannotcapturedynamicprocesses,sothisimage
isastaticrepresentationofthenanomaterialatthetimeofimaging.
**ContextandApplication** Fromtheimagealone,thenanomaterial’spurposeisindeterminate. It’sa
real,experimentalScanningElectronMicroscope(SEM)image,usedfor
analyzingsurfacemorphologyandstructure.Table15: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
nanowiresnanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuningofsmallermodels
fortheanalysisandinterpretationofcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimageofnanowire
nanomaterials,pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Theimagedepictsnanowires,andthescalebarrepresents200nanometers
(nm).
**MorphologyandStructure** The nanomaterials have a cylindrical, rod-like morphology, typical of
nanowires. Therearenodistinctlayers,phases,ordomainsvisibleinthis
image. Thenanowiresappeartoberelativelyuniforminsizeandshape,
suggestingacontrolledsynthesisprocess.
**SizeandDistribution** The individual nanostructures, which are nanowires, are approximately
200nanometersorlessinlengthasindicatedbythescalebar. Theyappear
to be densely packed and evenly distributed across the image with no
significantclusteringorrandomdistribution. Thereisnoclearevidenceof
aggregationorbundling;thenanowiresstandindividually,whichistypical
forwell-synthesizednanowires.
**SurfaceCharacteristics** Thenanomaterials,whicharenanowires,appeartohaveasmoothsurface
withnosignificantroughnessorspecifictexturevisibleatthismagnification.
Therearenoclearlyvisibledefects,pores,orimpuritiesonthesurfaceofthe
nanowiresintheprovidedimage. Theuniformityandsmoothnesssuggest
ahighlevelofcontrolinthesynthesisprocessofthesenanostructures.
**CompositionandElements** In the grayscale electron microscope image, variations in brightness or
contrast usually show compositional differences, due to varied electron
scatteringbydifferentelements. Theprovidedimage’suniformcolorand
contrastimplyahomogeneouscompositioninthenanowires. Nolabelsor
markersindicatespecificelementsorcompounds,andtheimagedoesn’t
directlyrevealthenanomaterials’chemicalcomposition.
**InteractionsandBoundaries** Theindividualnanostructures,whicharenanowires,appearseparateand
notfusedtogether,witheachnanowirestandingdistinctfromothers. There
areclearboundariesbetweeneachnanowire,withnovisiblemergingor
blendingatthebasesortips,indicatingtheyarewell-definedindividual
entities.
**ExternalEnvironment** Thereisnovisibleevidenceintheimageofthenanomaterialinteracting
with an external environment or matrix such as solvents, polymers, or
othermaterials. Theimageappearstobefocusedsolelyonthenanowires
themselves. Therearenootherstructuresorobjectspresentthataredistin-
guishablefromthenanomaterials.
**Image Technique and Modifica- The image was captured using Scanning Electron Microscopy (SEM).
tions** There are no indications of post-processing or modifications like false
coloringor3Drendering;itappearstobeastandardgrayscaleSEMimage.
**FunctionalFeatures** Therearenovisiblefunctionalfeatureslikeactivesitesorregionswith
distinct properties in the image. The image is a static representation; it
does not capture dynamic processes, as SEM images are snapshotsand
cannotdepictmotionorchangeovertime.
**ContextandApplication** Nanomaterialapplicationunclear. Depictednanowiresusedinelectron-
ics,photonics,research. SEMimagesuggestsexperimentalsample,not
theoreticalrepresentation,forobservationathighmagnifications.Table16: Thetablepresentsmoreinformativeandaccuratequestion-answerpairs,comparedtotraditionalmethods,
generatedusingGPT-4Turbowithvisioninresponsetonaturallanguagepromptsaboutaninputmicroscopicimage
fromtheporousspongenanomaterialcategory. Tosummarize,GPT-assistedvisualinstructiondatageneration(thatis,
question-answerpairs)providesin-depthinsightsintoanimagerelatedtoporousspongenanomaterials.
Basedontheprovidedimageofporoussponge
nanomaterials,pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Thenanomaterialintheimageisaporoussponge-likestructure. Thescale
oftheimageindicatesthat1micrometer(µm)istheunitofmeasurement.
**MorphologyandStructure** Thenanomaterialsintheimagehaveanirregular,highlyporousmorphol-
ogy with many voids. There are no distinct layers, phases, or domains
visible;it’sacontinuousnetworkofmaterial. Thenanomaterialsdonot
appearuniforminsizeandshape;there’savarietyintheporesizesandthe
thicknessofthematerialbetweenthepores.
**SizeandDistribution** Theindividualnanostructuresvaryinsize,withporesrangingfromvery
smalltorelativelylargeinthecontextofthescaleprovided. Theporesdo
nothaveauniformsizeandseemtoberandomlydistributedthroughout
thematerial. Thereisnoclearevidenceofaggregationorbundling;the
materialseemstobeasinglecontinuousphasewithinterconnectedpores.
**SurfaceCharacteristics** Thenanomaterialappearstohavearoughtexturewithnumerousvisible
poresofvaryingsizes,whicharecharacteristicofahighlyporoussurface.
Thewallsofthematerialbetweentheporesalsoseemroughandirregular.
Visible defects or variations in the pore size and distribution across the
surfacecanbeconsideredimpurities,whicharetypicalforporousmaterials
likeaerogelsorfoam-likestructures.
**CompositionandElements** There are no visible compositional variations in the image; it appears
uniform in color and contrast. No labels indicate specific elements or
compoundswithinthenanomaterial.
**InteractionsandBoundaries** The individual nanostructures are fused, forming a continuous network
withoutclearboundariesbetweenseparatestructuresorphases. Thepores
areinterconnected,suggestingasingle,cohesivematerial.
**ExternalEnvironment** The image does not show any evidence of the nanomaterial interacting
withanexternalenvironmentormatrixsuchassolventsorpolymers. The
entirefieldofviewisoccupiedbythenanomaterial,withnootherdistinct
structures or objects present that are not part of the nanomaterial itself.
All visible features appear to be intrinsic to the porous structure of the
nanomaterial.
**Image Technique and Modifica- TheimagingtechniqueusedisScanningElectronMicroscopy(SEM),as
tions** indicatedbythelabelsontheimagesuchas”EHT”(electronhightension),
whichisspecifictoSEM.Therearenoobvioussignsofpost-processing
ormodificationssuchasfalsecoloring; theimageappearstobeaSEM
grayscalerepresentation.
**FunctionalFeatures** Asforfunctionalfeatureslikeactivesitesorregionswithdistinctproperties,
thesearenotdiscernibleattheresolutionandformatoftheimage.
**ContextandApplication** Thenanomaterialislikelyintendedforapplicationslikecatalysis,filtra-
tion,orinsulation,givenitsporousstructure. Theimageisofanactual
experimentalsample,asindicatedbyitsSEMimagingcharacteristics.Table17: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageoftips
nanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuningofsmallermodelsforthe
analysisandinterpretationofcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimageoftipsnanomaterials,
pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Theimageshowsanelectronmicroscopeimageofananomaterialtip,likely
forscanningprobemicroscopy. Thescalebarrepresents10micrometers.
**MorphologyandStructure** Thenanomaterialintheimagehasaconicalshape,characteristicofasharp
tip used in microscopic probes. There are no distinct layers, phases, or
domainsvisibleinthisimage. Itappearstobeasingle,uniformstructure
without visible variation in size or shape along its length, suggesting a
consistentmanufacturingprocess.
**SizeandDistribution** The image depicts a single nanostructure with a conical tip. The scale
bar indicates that the tip width is less than 10 micrometers, and the tip
itselftaperstoapoint,whichischaracteristicofnanomaterialtipsusedfor
scanningprobemicroscopy. Thereisonlyonenanomaterialvisible,sowe
cannotcommentonthedistributionorspacingofmultiplenanostructures.
Similarly,thereisnoevidenceofaggregationorbundling,astheimage
showsasolitarynanostructure.
**SurfaceCharacteristics** Thenanomaterialtipintheimageappearsrelativelysmooth,whichistypi-
calfornanomaterialsusedinhigh-precisionapplicationslikemicroscopy.
Thereareminorvariationsonthesurfacethatcouldbeindicativeofsome
roughnessorsurfacetexture,buttheseareminimal. Theredon’tseemto
beanylargevisibledefects,pores,orimpurities;however,thepresenceof
smallsurfaceimperfectionscannotberuledoutatthismagnificationand
resolution.
**CompositionandElements** The grayscale image does not show compositional variations in color.
However, brightness and contrast variations can indicate differences in
composition or density. The uniform grayscale suggests homogeneous
materialcomposition. Therearenolabelsindicatingspecificelementsor
compounds.
**InteractionsandBoundaries** Theimageshowsasinglenanomaterialtipwithnovisibleinteractionsor
boundarieswithothernanostructures.
**ExternalEnvironment** Intheimage,thereisnodirectevidenceofthenanomaterialinteractingwith
asurroundingenvironmentormatrix. Thebackgroundisfeaturelessand
uniform,whichsuggeststhattheimagefocusessolelyonthenanomaterial
tip and does not include other materials or structures such as solvents,
polymers,oradditionalobjects.
**Image Technique and Modifica- TheimagewascapturedusingaScanningElectronMicroscope(SEM).
tions** Therearenoapparentpost-processingormodificationslikefalsecoloring
or3Drendering;it’sarawgrayscaleSEMimage.
**FunctionalFeatures** Nospecificfunctionalfeatureslikeactivesitesarevisibleintheimage. It’s
astaticrepresentation,notcapturinganydynamicprocesses.
**ContextandApplication** Thenanomaterialdepictedislikelyforuseinscanningprobemicroscopy,
suchasAtomicForceorScanningTunnelingMicroscopy. Theimageisof
anexperimentalsample.Table18: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
particlesnanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuningofsmallermodels
fortheanalysisandinterpretationofcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimageofparticles
nanomaterials,pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Theimageshowssphericalnanoparticles,andthescalebaratthebottom
indicates that 100 nanometers (nm) is the unit of measurement. Each
particleappearstobeabout100nmindiameter.
**MorphologyandStructure** Thenanomaterialsintheimagearegenerallysphericalinshapeandappear
tobehighlyuniforminsizeandshape,suggestingamonodispersedistribu-
tion. Therearenodistinctlayers,phases,ordomainsvisible;theparticles
areconsistentintheirmorphologythroughouttheimage.
**SizeandDistribution** The approximate size of the individual nanostructures, judging by the
scalebar,isabout100nanometersindiameter. Thenanomaterialsaredis-
tributedevenlythroughouttheimage,withauniformspacingthatsuggests
a well-ordered array and minimal aggregation or bundling. There’s no
visibleevidenceofclustering;eachparticleisisolatedfromitsneighbors,
indicativeofastablecolloidalsystem.
**SurfaceCharacteristics** Thenanomaterialsappeartohaveasmoothsurfacewithoutanynoticeable
roughnessorspecifictextures. Theresolutionoftheimagedoesnotallow
fortheidentificationofanydefects,pores,orimpuritiesonthesurfaceof
thenanoparticles. Theoveralluniformityandsmoothnesssuggesthigh-
qualitysynthesismethodswithoutobviousdefectsorcontamination.
**CompositionandElements** There are no visible compositional variations in the image, and there
are no labels indicating specific elements or compounds. The particles
appearuniformlybright,suggestingahomogenousmaterialwithoutvisible
impurities.
**InteractionsandBoundaries** Thenanostructuresareseparateandnotfusedtogether,withclearbound-
ariesbetweeneachparticle,indicatingnosignificantinteractionoraggrega-
tion. Therearenodifferentstructuresorphasesvisible;allparticlesappear
identicalandareevenlyspaced.
**ExternalEnvironment** Theimagedoesn’tprovideevidenceofthenanomaterialinteractingwith
itssurroundingenvironmentormatrix;it’saclose-upwithafocussolely
onthenanoparticles. Therearenootherstructuresorobjectsvisiblethat
arenotpartofthenanomaterialsthemselves. Thebackgroundisconsistent
with what you’d expect in electron microscopy - featureless, providing
contrasttotheparticlesbeingstudied.
**Image Technique and Modifica- The image was captured using Scanning Electron Microscopy (SEM).
tions** There’snoapparentpost-processingormodificationslikefalsecoloringor
3Drendering;itappearstobeastandardgrayscaleSEMimage.
**FunctionalFeatures** Nofunctionalfeaturessuchasactivesitesorregionswithdistinctproperties
arevisibleintheimage.
**ContextandApplication** Thenanomaterial’sapplicationisunclearfromtheimage. Suchnanopar-
ticlesmayserveinmedicine,electronics,catalysis,ormaterialsscience.
Thislookslikeanexperimentalsample,notasimulation.Table19: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
powdernanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuningofsmallermodelsfor
theanalysisandinterpretationofcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimageofpowdernanomaterial,
pleaseanswerthefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** The image is a scanning electron microscope (SEM) image showing a
powdernanomaterial.Thescalebarindicates2micrometers(µm),meaning
eachunitonthescalebarrepresents2µminthesample.
**MorphologyandStructure** Thenanomaterialsintheimageexhibitanirregular,clumpedmorphology,
withnodistinctlayers,phases,ordomainsreadilyapparentfromthisview.
Theparticlesdonotappearuniforminsizeandshape;thereisavarietyof
sizesandagglomerations,whichiscommoninpowderednanomaterials
duetotheirhighsurfaceenergyleadingtoaggregation.
**SizeandDistribution** The individual nanostructures vary in size, but due to the scale bar in-
dicating 2 micrometers, we can estimate that the particles range from
sub-micrometertoacoupleofmicrometersindiameter. Thedistribution
ofnanomaterialsthroughouttheimageisclusteredandrandomratherthan
evenlyspaced,whichistypicalforpowderedmaterialsinaSEMimage.
There is evidence of aggregation or bundling, as many particles appear
tobeclumpedtogether,forminglargeraggregatesratherthanexistingas
isolated,individualparticles.
**SurfaceCharacteristics** Thenanomaterialsintheimagehavearoughandtexturedsurface,which
istypicalforpowderednanomaterialsasseenunderhighmagnification.
Therearenoclearlyvisibledefects,pores,orimpuritiesthatcanbedis-
tinctlyidentifiedfromtheimageprovided. However,thegranularityand
irregularityofthesurfacessuggestahighsurfacearea,whichisacommon
characteristicofnanomaterials.Theroughnesscouldcontributetopotential
sitesforchemicalactivityoradsorption.
**CompositionandElements** TheSEMimageshowsuniformgrayscaleintensity,suggestingahomo-
geneous composition without visible evidence of different elements or
compounds. Therearenospecificlabelsormarkersindicatingthepresence
ofparticularelementsorcompoundsintheimage.
**InteractionsandBoundaries** Individualnanostructuresintheimageappeartobetouchingandfused,
forming clusters with no clear boundaries between them, indicating a
degreeofagglomeration. Therearenovisibledistinctboundariesbetween
differentstructuresorphases.
**ExternalEnvironment** The SEM image shows only the nanomaterial tip, with no evidence of
interactionwithorimmersioninanexternalenvironmentormatrix. No
otherstructuresormaterialsarevisible.
**Image Technique and Modifica- TheimagewascapturedusingScanningElectronMicroscopy(SEM).It
tions** appearstobeastandardSEMoutputwithoutfalsecoloringor3Drendering.
SEMimagesaregrayscale,andtherearenosignsofpost-processing.
**FunctionalFeatures** TheSEMimagedoesnotvisiblyshowanyspecificfunctionalfeatureslike
activesites.
**ContextandApplication** TheintendedapplicationofthenanomaterialintheSEMimagecannot
bedeterminedfromtheimagealone. Itisanexperimentalsample,nota
theoreticalorsimulation-basedrepresentation.Table20: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
MEMSdevicesandelectrodesnanomaterials. Insummary,thisGPT-assistedvision-languagedatasetaidsinthetuning
ofsmallermodelsfortheanalysisofcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
BasedontheprovidedimageofMEMSdevicesand
electrodesnanomaterial,pleaseanswerthefollowing
questions.
Queryprompt GPT-4Turbowithvisionoutput
**Basics** Theimageshowsnanoscaleelectrodesorconductivepaths,possiblypart
ofamicroelectromechanicalsystem(MEMS).Thescalebarindicatesthat
eachunitofmeasurementrepresents2micrometers.
**MorphologyandStructure** The nanomaterials in the image exhibit a linear, elongated morphology,
likely representing nanowires or nanorods. There appear to be distinct
parallellayersorstrips,whichcouldbeseparatephasesormaterialcom-
ponents. The uniformity in the spacing between the layers suggests a
controlledfabricationprocess. Thenanomaterialsthemselvesseemtohave
aconsistentwidth,indicatingauniformsizeandshapeacrossthevisible
structures.
**SizeandDistribution** Thenanostructuresintheimageappearasstraight,parallellineswitha
consistent width less than 2 micrometers. They are evenly spaced and
aligned,indicatingacontrolleddistributiontypicaloffabricatednanomate-
rials. Thereisnoevidenceofaggregationorbundling,supportingtheidea
ofdeliberatedesignoftenseeninMEMSdevices.
**SurfaceCharacteristics** Thenanomaterial’ssurfaceappearsrelativelysmooth,withminorvariations
that could be indicative of texture or grain boundaries. There are some
visible defects and impurities, such as particles or irregularities on the
surfacebetweentheparallellines.
**CompositionandElements** ThemonochromaticSEMimageshowsuniformbrightnessalongthenano-
material,suggestinghomogeneouscompositionwithoutvisiblevariation.
Nolabelsindicatespecificelementsorcompounds.
**InteractionsandBoundaries** Thenanostructuresareseparateanddonotappeartobetouchingorfused,
indicatingtheyarelikelyisolatedconductivepathsorelectrodes. There
areclearboundariesbetweenthestructures,asevidencedbythedistinct,
parallellinesthatseparatethem.
**ExternalEnvironment** Thereisnoevidenceofinteractionwithasurroundingenvironmentorma-
trixintheimage. Allvisiblefeaturesappeartobepartofthenanomaterial
system,withnootherdistinctobjectspresent.
**Image Technique and Modifica- The imaging technique used is Scanning Electron Microscopy (SEM),
tions** as indicated by the details in the image. There’s no evidence of post-
processingmodificationslikefalsecoloringor3Drendering; theimage
appearstobeastandardgrayscaleSEMimage.
**FunctionalFeatures** Theimage,beingastaticSEMrepresentation,doesnotcapturedynamic
processes. Asforfunctionalfeatures,theparallellinearstructureslikely
represent active regions, such as conductive paths in a MEMS device.
However,specificactivesitesorregionswithdistinctpropertiesarenot
explicitlyvisibleinthisimage.
**ContextandApplication** SEMimagerevealsnanomaterialstructuresuitedforelectronics/MEMS
(electrodes/conductors). TheimageisarealSEMphotograph,notatheo-
reticalorsimulation-basedrepresentation.A.11.AdditionaldatasetsandExperimentalresults A.11.3.KTH-TIPS
Tobolstertherobustnessandgeneralizabilityofourframe- TheKTH-TIPS3 dataset,whichservesasacornerstonein
work, we conducted evaluations using a diverse range of textureanalysis,comprisesanextensivecollectionof810
open-sourcebenchmarkdatasets.Thesedatasetsarerelevant electronmicrographs. Eachoftheseimageshasbeenmetic-
to our researchdomain and encompass a broadspectrum ulouslycategorizedintooneoftendistinctmaterialclasses.
of applications. This comprehensive evaluation strategy Thesehigh-resolutionimages,eachmeasuring200×200
notonlyvalidatedtheefficacyofourframeworkbutalso pixels,captureadiverserangeofmaterialsundervarying
demonstrateditsadaptabilitytoawiderrangeofdatasets, lightingconditions,orientations,andscales. Thecompre-
extendingbeyondtheSEMdataset(Aversaetal.,2018). hensive collection encompasses textures such as sponge,
orangepeel,styrofoam,cotton,cracker,linen,crust,sand-
A.11.1.NEU-SDD((DESHPANDEETAL.,2020))
paper, aluminum foil, and corduroy. The representative
To thoroughly evaluate the effectiveness of our proposed imagesfromeachmaterialclasscanbeseeninFigure11.
method, specifically for open-ended VQA tasks involv- To evaluate the effectiveness of our proposed method in
ingmultipledefectcategories,weutilizedtheNEU-SDD multi-categorytexture-basedclassificationandopen-ended
dataset 1. This dataset comprises an extensive collection visualquestionanswering(VQA)tasks,weconductedcom-
of 1,800 electron microscopy images illustrating surface prehensiveexperiments.
defectsonhot-rolledsteelplates. TheNEU-SDDdataseten-
A.11.4.ADDITIONALINFORMATION
abledustoevaluateourframework’sabilitytocomprehend
AcommonmisconceptionisthatGPT-4TurbowithVision
complexvisualinformationandprovideinsightfulanswers
can handle all tasks, from image classification to visual
toquestionsaboutthesurfacedefects. Eachdefectcategory
questionanswering(VQA),withaone-size-fits-allprompt.
intheNEU-SDDdatasetisrepresentedby300images,with
Inreality, eachtaskrequiresacarefullydesignedprompt
each image having a resolution of 200×200 pixels. The
specifictothedataset,leveragingourunderstandingofthe
datasetiscategorizedintosixdistincttypesofdefects,with
model’scapabilities. Diversepromptingstrategiesarees-
300representativemicrographsforeachcategory.Thesecat-
sential in AI, not just beneficial. By tailoring prompts to
egoriesencompassadiverserangeofsurfaceimperfections,
individualneeds,weunlockthefullpotentialofadvanced
includingpittedsurfaces,scratches,rolled-inscale,crazing,
AImodelsandensuregenerationofhigh-quality,instruction-
patches,andinclusiondefects. Notably,eachimageinthe
followingdatasets. Weleveragecustompromptstailoredto
datasetfeaturesonlyonetypeofdefect. Figure9provides
eachspecificadditionaldatasets. Thisallowsustogener-
illustrative images from each category. In summary, the
ateinstruction-followingdatasetsfocusedonthematerial
NEU-SDD dataset represents a valuable resource for the
categoriespresentintheinputmicroscopyimages. Subse-
developmentandevaluationofsurfacedefect-basedVQA
quently,smallermodelstrainedonthisgenerateddatacan
algorithms. Itsdiverserangeofdefects, andhigh-quality
learnhumanintentfromlargerteachermodels,ultimately
imagesmakeitachallengingandrealisticbenchmarkfor
achievingstate-of-the-artperformanceondownstreamtasks.
thistask.
ToevaluatetheeffectivenessoftheMAEMIframework,we
A.11.2.CMI conductedacomprehensiveperformancecomparisonwith
The CMI dataset2, meticulously curated by corrosion ex- existingSOTAmodelsacrossvarioustasks. Specificallyfor
multi-classclassificationtasks,Table21presentsclassifica-
perts,comprises600high-resolutionelectronmicrographs
tionaccuracyresults,demonstratingMAEMI’sperformance
that vividly capture the deterioration of corroded panels.
relativetobaselinemodels. Inthedomainofopen-ended
These meticulously labeled images adhere to the ASTM-
VQA,Table22showcasesMAEMI’sperformance,provid-
D1654standardsandfeatureindividualscoresrangingfrom
ingadetailedcomparisonwithalternativeapproaches. To
5to9,correspondingto120uniquemicrographseach.Each
furtherillustrateMAEMI’scapabilitiesinopen-endedVQA,
micrograph has a spatial resolution of 512 × 512 pixels,
Tables30,31, and32offerconcreteexamplespresenting
providingagranularviewofthecorrosiondamage. Figure
images,correspondingquestions,andthegeneratedanswers.
10showcasesrepresentativeimagesfromeachscore-based
Thesetablesgobeyondtextualcomparisonbyincorporating
category. We conducted experimental studies to evaluate
performanceevaluationmetricssuchasBLEU-2,ROUGE-
theeffectivenessofourproposedtechniqueforbothmulti-
L,andMETEOR,ensuringaquantitativeassessment. Addi-
categoryclassificationandopen-endedVQAtasks.
tionally,Tables23- 29presentsamplesfromtheinstruction-
1Datasource: http://faculty.neu.edu.cn/
tuningQ&Apairsdataset,generatedbyGPT-4Turbowith
yunhyan/NEU_surface_defect_database.html
2https://arl.wpi.edu/corrosion_dataset Vision. This dataset plays a crucial role in the training
processofsmallermodels.
3https://www.csc.kth.se/cvap/databases/
kth-tips/index.htmlFigure9.ThefiguredisplaysacuratedcollectionofelectronmicroscopyimagesfromtheNEU-SDDdataset(Deshpandeetal.,2020),also
knownastheNEUSurfaceDefectDatabase.Thisspecializeddatasetisprimarilyusedfordetectingandclassifyingsurfacedefectson
steel.Itcontainsimagesrepresentingsixdifferenttypesofsteelsurfacedefectsfoundonhot-rolledsteelstrips:pittedsurfaces,scratches,
rolled-inscale,crazing,patches,andinclusiondefects.Thedatabaseplaysacrucialroleindevelopingframeworksforqualitycontrolin
manufacturingandautomatedinspectionsystemsbyprovidingadiverserangeofdefecttypesandimagesforcomprehensivetestingand
evaluation.
Figure10.ThefigureshowsacuratedcollectionofelectronmicrographsfromtheCMIdataset,whichhavebeenmethodicallycategorized
basedontheASTM-D1654standards.Itfeaturescorrosionseverityscoresfrom5to9,suggestingascalethatmeasurestheprogressionof
corrosiondamageonthematerialpanels.Withscoresrangingfrom5to9indicatingaprogressionfrommoderatetolessseverecorrosion.
TheCMIdatasetincludes600imagesofmaterialpanelsundergoingdifferentlevelsofcorrosion,eachevaluatedandconfirmedbyexperts
throughstandardizedlaboratorytesting.
Figure11.ThefigureshowsacuratedselectionofelectronmicrographsfromtheKTH-TIPStexturedatasetshowcasingthetendiverse
materialclasses,includingsponge,orangepeel,styrofoam,cotton,cracker,linen,crust,sandpaper,aluminumfoil,andcorduroy.
Algorithms NEU-SDD CMI KTH-TIPS
ResNet 0.906 0.928 0.941
GoogleNet 0.936 0.928 0.929
SqueezeNet 0.955 0.943 0.963
VanillaViT 0.962 0.968 0.972
MAEMI 0.985 0.983 0.991
Table21.Thetablecomparesthemulti-categoryclassificationperformanceoftheproposedframeworkagainstestablishedbenchmarks
acrossdatasets.
Table22.ThetableshowsMAEMIframeworkexcelsonopen-endedVQAtaskacrossbenchmarkdatasetswiththeircorrespondingscores
inseveralevaluationmetrics.
Method BLEU-2(↑) BLEU-4(↑) ROUGE-1(↑) ROUGE-2(↑) ROUGE-L(↑) METEOR(↑)
InstructBLIP(Daietal.) 0.822 0.666 0.933 0.832 0.895 0.955
LLaVA(Liuetal.,2023) 0.814 0.664 0.956 0.841 0.903 0.951
MiniGPT-4(Zhuetal.,2023) 0.855 0.687 0.966 0.828 0.901 0.982
MAEMI 0.908 0.823 0.984 0.889 0.942 0.992
senilesaBB.CMI
Table23: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
corrosioncategory5,accordingtoASTM-D1654standards. Insummary,thisGPT-assistedvision-languagedataset
aidsintuningsmallermodelstointerpretcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Pleaseanswerthefollowingquestionsabouttheprovided
imageofcorrosioncategory5,classifiedaccordingto
ASTM-D1654standards.
Queryprompt GPT-4Turbowithvisionoutput
What is the primary purpose of the Theimageisusedforresearchonmaterialcorrosion,specificallytoclassify
image? theextentofdamageaccordingtostandardizedcorrosionseveritylevelsin
aVisualQuestionAnsweringsystem. It’sapartofadatasetfortraining
machinelearningmodelsincorrosiondetection.
Howistheseverityofcorrosionvisu- Theseverityofcorrosionintheimagesisdeterminedbytheextensiveness
allyrepresentedinthisrating? ofthecorrodedarea-intermsofsize,depth,colorchanges,andpresenceof
rustorpitting. ThelowerASTM-D1654ratingscoreslikea5hereindicate
moreseverecorrosion,withlargerandmorenumerousdefectsvisibleon
themetalsurface.
What is the dominant feature in the Theimage’sdominantfeatureisalargeX-shapedmark,suggestingsevere
image? corrosionoradeliberateassessmentmarkinginthecorrosiondataset. Its
size, shape, and contrasting color against the surface indicate a lower
corrosionseverityrating,implyingsignificantdamageordeterioration.
Describethecolorandtextureofthe TheX-shapeintheimageisdark,suggestingheavyoxidationordegrada-
X-shape. tion. Thetextureisroughanduneven,hintingatflakingorpittingtypical
ofcorrodedmetal. Thecolorcontrastswiththelighterbackground,possi-
blyindicatingearlycorrosionstagesorintactcoatings. Thisisatypical
appearanceofasurfacethathasexperiencedsignificantcorrosion.
What’snotableaboutthebackground Thebackgroundhasamottledappearancewithcolorvariationsfromlighter
surroundingtheX-shape? todarkershades,resemblingrustandwearfromcorrosion. Theuneven
surfaceshowspittinganddiscoloration,suggestingtheonsetofcorrosion.
ThiscontextindicatestheX-shapeispartofalargercorrodedareabeing
studiedformaterialdegradation.
Aretherevisibleboundariesordivi- ThedistinctX-shapeboundariessuggestacleardivisionfromtheback-
sions between the X-shape and the ground,possiblyduetodeepercorrosionsettingitapartordifferencesin
background? imageprocessingormetaltreatmentinthatarea.
Isthereapatterntothecorrosionem- Generally, corrosion mayspread outward frompoints oforigin, butthe
anatingfromtheX-shape? exactpatternwoulddependonvariousfactorsincludingthematerialand
environmentalconditions.
Howdothedarkspecklesontheback- Dark speckles on a corroded surface indicate areas where the material
ground contribute to the overall ap- hasstartedtopitortheprotectivelayerhasbeencompromised,allowing
pearanceofcorrosion? oxidation. Theirvaryingsizeanddensitygiveinsightsintotheseverityand
progressionofcorrosion. Theycreatevisualtexturereflectingtheirregular
natureofcorrosionacrossthesurface.
What does a rating of 5 signify Acorrosionratingof5signifiesseveredegradationthatcancompromise
in terms of material integrity and integrityandlongevity,requiringattention,maintenance,orreplacementto
longevity? ensuresafetyandfunctionality.Table24: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
corrosioncategory9,accordingtoASTM-D1654standards. Insummary,thisGPT-assistedvision-languagedataset
aidsintuningsmallermodelstoanalyzeandinterpretcomplexmicroscopicimagesinthecontextofopen-endedVQA
tasks..
Pleaseanswerthefollowingquestionsabouttheprovided
imageofcorrosioncategory9,classifiedaccordingto
ASTM-D1654standards.
Queryprompt GPT-4Turbowithvisionoutput
Whatistheprimaryintentoftheim- The primary intent of the image you’ve provided, which belongs to the
age? corrosion9categoryfromtheCMIdataset,istoserveasadetailedelectron
micrographforthestudyofcorrosion. Itappearstocapturetheadvanced
stateofdeteriorationonmetalpanels,providingahigh-resolutionviewto
analyzeandunderstandthepatternsandprogressionofcorrosion.Thiskind
ofimageistypicallyusedbyresearchersandprofessionalsinthefieldof
materialscienceandengineeringtoassesstheconditionofmetalstructures,
todevelopbettercorrosion-resistantmaterials,andtotesttheeffectiveness
of anti-corrosion treatments. The image’s adherence to ASTM-D1654
standards indicates that it has been categorized and scored based on a
standardized measure of evaluating the severity of corrosion, which is
crucialforconsistentscientificanalysisandresearch.
Can you describe the overall color Theimagedisplaysapredominantlybeigeortanbackgroundwithacentral
schemeoftheimage? featurethatappearsasarustorbrownishstreak,indicativeofcorrosion.
Thisstreakhasvariationsinintensity,withsomeareasappearingdarker,
suggestingdifferentstagesorconcentrationsofcorrosion.
What is the main corroded feature Themaincorrodedfeatureintheimageisalong,linearstreakofcorrosion
presentintheimage? runningacrossthefieldofview.Thisstreakischaracterizedbyitsbrownish,
rust-likecolor,whichcontrastswiththelighterbeigebackground. Itlikely
representsasignificantareaofmetaldegradation,withvariationsincolor
intensityindicatingdifferentlevelsordepthsofcorrosiondamage.
How does the corrosion manifest Thecorrosionshowsasarust-coloredlinewherethecoatingwaslikely
aroundthisscribedline? removed, allowing corrosion to start. Around this line, the corrosion
spreadsoutward,creatingagradientwheretherustcolorfadesawayfrom
thecentralline. Thisindicatesseverecorrosionnearthescribedline,with
lessimpactonthesurroundingmetal.
Given the context of corrosion rat- A rating of 9 in the context of corrosion severity, especially within a
ings,howdoesaratingof9compare scalethatadherestoASTM-D1654standards,typicallyindicatesminimal
tootherratingsintermsofcorrosion corrosion,withthemetalsurfaceremainingmostlyintact. Lowerratings
severity? woulddenotemoreseverecorrosiondamage.
Isthecorrosionconsistentthroughout Thecorrosionalongthescribedlineisnotuniform;itvariesinintensity,
thescribedline? suggestingdifferentlevelsofcorrosionseverityalongtheline.
Howdoesthebackgroundoftheim- Thebackgroundoftheimageisauniformbeigeortancolor,whichappears
ageappearincomparisontothecor- smoothandundamaged,contrastingwiththecorrodedareathatshowsa
rodedarea? brownish,texturedstreakindicativeofcorrosiondamage.
Ifoneweretoruntheirfingersacross Touching the corroded panel in the image would reveal roughness and
theimage,whatdifferencesintexture unevenness along the corroded line, contrasting with the smoother, in-
might they expect between the cor- tactbackground. Thecorrodedareafeelsirregularandpitted,whilethe
rodedscribeandthebackground? surroundingareaissmoother. However,thistextureisonlyvisuallyper-
ceptibleintheimage,nottactile.C.KTH-TIPS
Table25: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageofthe
aluminiumfoil. Insummary,thisGPT-assistedvision-languagedatasetaidsintuningsmallermodelstoanalyzeand
interpretcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Referringtotheprovidedimageofaluminumfoil,
pleaseprovideanswerstothequestionsbelow.
Queryprompt GPT-4Turbowithvisionoutput
Whatistheprimarymaterialdepicted Theprimarymaterialdepictedintheimageyouprovidedappearstobe
intheimage? aluminumfoil.Aluminumfoilistypicallycharacterizedbyitsshinysurface
anditsabilitytocrumpleandfoldeasily,creatingarangeofhighlightsand
shadowsthatgiveitadistinctivetexturedappearance. Theimageshows
thesecharacteristics,suggestingthatitisindeedaluminumfoil.
Howisthesurfacetextureofthema- Thesurfacetextureofthealuminumfoilintheimageishighlyirregular
terial? and crinkled, characterized by sharp folds and creases that reflect light
differently. Thiscreatesacomplexpatternofhighlightsandshadows. The
crumplednatureresultsinachaotic,randomtexturetypicalofmanipulated
foil. Thetexturevarieswiththedegreeofcrumplingandlightingangle,
contributingtothefoil’suniqueanddetailedappearance.
What color predominates in the im- The image predominantly displays shades of gray, characteristic of the
age? metallic sheen of aluminum foil. The varying brightness within those
shadesisduetothecrinkledtextureandhowitreflectslight.
Arethereanyreflectionsorshinesvis- Yes,therearemultiplereflectionsandshinesvisibleonthematerial,which
ibleonthematerial? areindicativeofaluminumfoil’sreflectivemetallicsurface. Thecrinkles
andfoldscreatevaryingdegreesofbrightnessandcontrast,emphasizing
theshinyqualityofthefoil.
Howwouldyoudescribetheoverall Theoverallpatternonthealuminumfoilishighlyirregularandchaotic,
patternonthefoil? withnouniformityorrepeatingmotifs. Itconsistsofnumerousrandom
creasesandfoldsthatcreateacomplexandintricatetexture. Thepattern
isformedbythewaythefoilhasbeencrumpled,resultinginadisordered
arrayofreflectiveanglesandsurfaces.
Isthefoilflatordoesitappeartohave Thefoilappearstohavedepthandvolumeduetothepronouncedcreases
depthandvolume? andfolds,whichcreateathree-dimensionaleffect,thecrumplinggivesita
texturedappearancethatsuggestsasenseofdepth.
Doesthefoilcovertheentiretyofthe Thefoilappearstocovertheentiretyoftheimagewithnootherdistinct
image? elementsorobjectspresent.
Howwouldyoudescribethelighting The lighting on the foil seems to be diffuse, with no harsh or direct re-
onthefoil? flections, suggesting a soft, indirect light source. This type of lighting
enhancesthevisibilityofthetexturebycastinggentleshadowswithinthe
creaseswithoutcreatingoverpoweringglare.
Isthereanyuniformityinthecrinkles The crinkles and folds in the aluminum foil appear to be random and
andfolds,oraretheyrandom? without any discernible pattern or uniformity. Each crease and fold is
unique,contributingtotheoverallcomplextextureofthematerial.
Isthebackgrounddistinguishable,or Thefoilcoversthebackgroundcompletely,makingitindistinguishable.
doesthefoilcoveritcompletely? Therearenovisibleelementsordetailsbeyondthefoilitselfintheimage.Table26: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageofthe
corduroyfabric. Insummary,thisGPT-assistedvision-languagedatasetaidsintuningsmallermodelstoanalyzeand
interpretcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Referringtotheprovidedimageofcorduroyfabric,
pleaseprovideanswerstothequestionsbelow.
Queryprompt GPT-4Turbowithvisionoutput
Whattypeofmaterialisdepictedin Theimageyou’veprovidedappearstobeatexturethatisconsistentwiththe
theimage? materialclassofcorduroy. Corduroyischaracterizedbyitsdistinctpattern
ofraisedridges,orwales,whichruninparallellines. Thetextureinthe
imageexhibitsthesehallmarkridges,suggestingthatitindeedrepresentsa
corduroymaterial.
Whatcolordoesthecorduroyfabric Thecorduroyfabricintheimageprimarilyexhibitsabrowncolor.
primarilyexhibit?
Describe the texture and pattern no- Thetextureofthecorduroyintheimageischaracterizedbyitsdistinctive
ticeableonthecorduroy ridgesorwales,whichareraisedparallellinesthatrunalongthelength
of the fabric. These wales give corduroy its unique texture that is both
visualandtactile. Thepatternisrepetitiveandconsistent,witheachwale
typicallyhavingauniformwidthandheight,creatingacordedlookthat
is typical of this type of fabric. The valleys between the wales appear
aslineardepressionsthatalternatewiththeraisedwales,contributingto
the overall texture of the material. The texture also suggests a soft and
somewhatvelvetyfeel,whichiscommonwithcorduroyfabrics.
Aretheseraisedlinesuniformlydis- Yes, in the image of the corduroy fabric, the raised lines, or wales, are
tributedthroughoutthefabric? uniformlydistributed,givingitaconsistenttextureandappearance. The
regularspacingandsimilarwidthofeachwalecontributetothematerial’s
uniformlook.
Howdoeslightinteractwiththefab- Intheimage,lightinteractswiththefabric’stexture,creatinghighlights
ric’stexture? and shadows along the corduroy’s wales. The raised ridges catch light,
enhancing brightness and sheen on the peaks, while the valleys remain
shadowed, accentuating the fabric’s depth and texture. This interplay
enhancesthecorduroy’sthree-dimensionallookandemphasizesitstactile
quality. Thelight’sdirectionalityalsoaffectstexturevisibility;angledlight
increasesthecontrastbetweenthewalesandgrooves,makingthetexture
morepronounced.
Describe the spacing between the Thespacingbetweentheribsinthecorduroyisuniformandeven,typical
ribs. oftheregularpatternassociatedwiththismaterial.
Howdoesthefabric’stexturevarybe- Thefabric’stexturevariesbetweentheraisedlines(wales)andthegaps
tweentheraisedlinesandthegapsin (channels)inthatthewalesaremorepronouncedandmayfeelthickeror
between? plush,whilethechannelsarerecessed,creatingasofterandsmootherfeel
incomparison.
Are there any visible imperfections Theimageofthecorduroydoesnotexhibitanyvisibleimperfectionsor
orsignsofwearonthecorduroy? signsofwear;thewalesappearconsistentandintact,indicatingthefabric
islikelyingoodcondition.
From which angle or perspective is Thefabricisbeingobservedfromadirect,overheadangle,lookingstraight
thefabricbeingobserved? downontothesurface,allowingforaclearviewofthetextureandpattern
ofthecorduroy.
Istheimageafullrepresentationof Theimageseemstorepresentjustasectionofthecorduroyfabric,notthe
thefabricorjustasection? fullextentofthematerial. Itprovidesaclose-upviewthatfocusesonthe
textureandpatterndetail.Table27: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
thelinenfabric. Insummary,thisGPT-assistedvision-languagedatasetaidsintuningsmallermodelstoanalyzeand
interpretcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Referringtotheprovidedimageofthelinenfabric,
pleaseprovideanswerstothequestionsbelow.
Queryprompt GPT-4Turbowithvisionoutput
What is the primary material dis- Theimageisarepresentationofalinentexture. Linenisknownforits
playedintheimage? distinctive,slightlyirregularweaveandnaturalfiberlook,whichisvisible
intheimageprovided.
Canyouidentifytheprimarycolorof Theprimarycolorofthelinenfabricintheuploadedimageappearstobea
thelinenfabricintheimage? beigeorlighttancolor. Thiscolorisoftenassociatedwithnaturallinen
materials.
Describethetextureorpatternvisible Thelinen’stextureintheimageshowsadistinct,wovenpatterntypicalof
onthelinen? linenfabrics. Theweaveistightandregular,withslightthreadthickness
variation,givingitanatural,irregularappearance. Thepatternfeaturesa
crisscrossarrangement,creatingagrid-likestructure. Thesurfacehasa
mattefinish,suggestingasoft,naturalfeeltypicaloflinentextiles.
Howwouldyoudescribethespacing Thespacingbetweenthewoventhreadsintheimageappearstobequite
betweenthewoventhreads? close,butwithenoughseparationtomakeindividualthreadsdistinguish-
able. Thethreadsarewoveninaconsistentpattern,indicativeofatightly
wovenfabric,yettheyarenotsotightlyboundthattheylosethetextured
appearancedistinctivetolinen. Thistypeofspacingistypicalforquality
linen,allowingfordurabilitywhileretainingbreathability.
Does the linen appear soft or rigid Basedonthevisibletextureintheimage,thelinenappearstohaveasoft
basedonthevisibletexture? quality. The slight irregularities in the thread thickness and the natural
weavepatternsuggestflexibility,whichischaracteristicoflinenfabrics.
Despiteitsstructuredandtightweave,linenisknownforitsnaturalsoftness
andtheimagedoesnotsuggestanystiffnessthatwouldindicaterigidity.
Arethereanyobservablesheenorre- Fromtheimageprovided,thelinendoesnotexhibitasignificantsheenor
flectivepropertiesonthelinen? reflectiveproperties. Thesurfaceappearsmatte,withthenatural,slightly
uneventextureoftheweaveabsorbinglightratherthanreflectingit. This
lack of luster is typical for linen, which is known for its more subdued,
earthyaestheticratherthanaglossyorshinyappearance.
Howconsistentisthetexturethrough- Thetextureofthelinenintheimageisconsistent,withauniformweaving
outthedisplayedsection? patternindicatinghigh-qualitytextileproduction. Subtlenaturalvariations
inthreadthickness,characteristicoflinen,don’tdisruptthefabric’soverall
uniformity. Thisconsistentweavesuggestsasmooth,evenfeel,desirable
inlinenfabrics.
Basedonthevisibleattributes, how Thelinenfabricintheimagewouldlikelyofferatactileexperiencethatis
wouldyoudescribethetactilesensa- characteristicallytexturedandcrisptothetouch,withanatural,slightly
tionofthefabric? irregular feel indicative of its organic origin. The tight yet breathable
weavesuggestsafabricthatisbothdurableandcomfortable,providinga
sensationofbothsoftnessandstructuredquality.
Are there any discernible imperfec- Based on the image, the fabric is uniform, free from snags, pulls, or
tionsoruniquecharacteristicsinthe discoloration. Thenaturalvariationinthreadthickness,characteristicof
fabric? linen,providesadistinct,organictexture,enhancingitsaestheticandtactile
appeal. Overall,thefabricappearshighquality,embodyingthenuanced
detailstypicalofwovenlinen.D.NEU-SDD
Table28: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageofthe
scratchescategoryofsurfacedefects. Insummary,thisGPT-assistedvision-languagedatasetaidsintuningsmaller
modelstoanalyzeandinterpretcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimagefromthescratches
category,pleaserespondtothefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
What category does this texture be- Thecategoryofthetextureintheprovidedimagebelongstothescratches
longto? category. Scratchesarecharacterizedbylinearmarkingsorindentationson
thesurface,whichcanvaryindepthandwidth. Thesedefectsaretypically
aresultofmechanicaldamagewhereanobjecthascomeintocontactwith
thesurfacewithenoughforcetomarit. InthecontextoftheNEU-SDD
dataset, this image would be used to train algorithms to recognize and
categorizesuchimperfectionsonhot-rolledsteelplates.
Describethecentralfeatureintheim- Thecentralfeatureintheimageisalinear,verticalscratchmark,character-
age? izedbyadistinct,brightlineagainstadarkerbackground,indicativeofa
surfacedefectonthematerial.
Howwouldyoudescribethecontrast Thecontrastbetweenthescratchandthesurroundingtextureisquitepro-
betweenthescratchandthesurround- nounced. Thescratchappearsasabright,linearstreakagainstauniformly
ingtexture? darkerbackground,whichindicatesasignificantdifferenceinreflectivity
ortexturebetweenthescratchandtherestofthesurface.Thishigh-contrast
featuremakesthescratchreadilyidentifiable.
What color tones dominate the im- Theimageisgrayscale,soitisdominatedbyshadesofgray. Thereareno
age? colortonesinagrayscaleimage,onlyvariationsfromblacktowhite.
Canyoudefinetheorientationofthe The orientation of the scratch is vertical, extending from the top to the
scratch? bottomoftheimage.
Howwouldyoudescribetheedgesof Theedgesofthescratchappearrelativelystraightandparallel,suggestinga
thescratch? singular,consistentforcethatcreatedit.Theyarewell-defined,indicatinga
cleardemarcationbetweenthescratchitselfandthesurroundingunaffected
material.
Isthescratchinthecenterortowards Thescratchiscentrallylocatedintheimage,runningverticallydownthe
thesideoftheimage? middleoftheframe..
Aretheremultiplescratchesorjusta Basedontheimageprovided,thereisasingleprominentscratchvisible
singleprominentone? runningverticallydownthecenter.
Is the rest of the image’s texture Therestoftheimage’stextureappearsgrainy,withaspeckledpatternof
smoothorgrainy? lighteranddarkergrayareasindicativeofthemicroscopicsurfacetexture
ofthematerial.
How does the brightness of the The scratch is significantly brighter than the overall image. It stands
scratchcomparetotheoverallimage? outasadistinct,lighterfeatureagainstthepredominantlydarker,grainy
backgroundoftherestoftheimage.
If you were to touch the scratch, Basedonthevisualcharacteristicsofthescratchintheimage,itwould
woulditfeelraisedorrecessed? likelyfeelrecessed. Thebrightnessofthescratch,incontrasttothedarker
surroundingarea,suggestsagrooveorindentationinthematerial’ssurface.Table29: Thetablepresentsaninstruction-followingdatasetcomposedofimage-question-answertriplesgenerated
usingGPT-4Turbowithvisioninresponsetoopen-endednaturallanguagepromptsaboutamicroscopicimageof
thepatchescategoryofsurfacedefects. Insummary,thisGPT-assistedvision-languagedatasetaidsintuningsmaller
modelstoanalyzeandinterpretcomplexmicroscopicimagesinthecontextofopen-endedVQAtasks.
Basedontheprovidedimagefromthepatchescategory,
pleaserespondtothefollowingquestions.
Queryprompt GPT-4Turbowithvisionoutput
What category does this texture be- Thetextureintheimagebelongstothepatchescategoryofsurfacedefects.
longto?
Describethedominantfeaturesinthe The image shows a grayscale texture with varied patterns of light and
image? darkareas. Dominantfeaturesincludeirregularlyshapeddarkerpatches
distributed across a lighter background, suggesting an uneven surface
typicalofthe”patches”defectcategoryinsteel. Thesepatchesappearas
areasofconcentrationorclusters,contrastingwiththelightergrayscale
background,andmayindicatesurfaceinconsistenciesorrepairs.
Howwouldyoucharacterizethecon- Thecontrastbetweenthepatchesandthesurroundingareaintheimageis
trastbetweenthepatchesandthesur- quitepronounced. Thepatchesappearasdistinct,darkerareasagainsta
roundingarea? lighterbackground,indicatingasignificantdifferenceintone. Thisstark
contrast helps to highlight the irregularities and the texture differences
betweenthedefectivepatchesandtherestofthesurface.
Whatcolortonesareprevalentinthe Theimageisingrayscale,showingblack,white,andgraytones. Itlacks
image? color,displayingintensityvariationsfromblack(lowintensityorabsence
of material) to white (high intensity or presence of material), with gray
shadesindicatinglevelsinbetween. Thedarkergraypatchessuggestlower
intensityareascomparedtothelightergraysurroundingsurface.
Describetheshapeandarrangement Thepatchesintheimageareirregularlyshapedandvaryinsizeandform,
ofthepatches? distributedrandomlyacrossthesurface.Someclustertogether,whileothers
areisolated,withjagged,poorly-definededgesblendingintothelighter
background. Thisirregularityinshapeandarrangementtypifiesmaterial
surfacedefects.
How does the texture within the Within the patches, the texture appears to be denser and more chaotic
patchescomparetotherestoftheim- comparedtotherestoftheimage. Thegranularityismorepronounced,
age? witharougher,lessuniformappearance. Incontrast,thesurroundingareas
exhibitasmootherandmoreconsistenttexturewithlightershadesofgray,
suggesting a less disturbed surface. The patches stand out due to their
distinct,ruggedtextureagainsttherelativelyuniformbackground.
Would you say the patches are cen- Thepatchesappeartobedispersedthroughouttheimageratherthancen-
tralizedormoredispersed? tralized. Theyarespreadacrossthesurfacewithoutaclearconcentrationin
anyparticularcentralarea,indicatingarandomdistributionofthesurface
defects.
Do the patches have well-defined Thepatchesdonothavewell-definedboundaries;theiredgesareirregular
boundaries? andblendintothesurroundingarea.
Describethegranularityoftheback- The background texture in the image is relatively smooth and uniform,
groundtexture? withfinegranularity. Thiscontrastswiththeroughertextureofthepatches,
makingtheoverallsurfaceappearheterogeneous.
Inareal-worldscenario,howmight Patchesonmaterialscanformduetocorrosion,wearandtear,manufactur-
suchpatchesformonmaterials? ingflaws,inconsistentrepairsortreatments,andchemicalexposure,often
indicatingareasofweakness.
Does the image lean more towards Theimageisoverallneutralintone,withabalancebetweenlightanddark
beingbright,dark,orneutraloverall? areas,neitherleaningdistinctlytowardsbeingbrightnordark.Table30.Thetabledisplaysacollectionofelectronmicroscopeimagesthatdepictmetalcorrosion,accompaniedbytheiraccuratelabels.
Additionally,itincludesmachine-generateddescriptionsforeachimage,whichareobtainedfromanopen-endedVQAtaskthatexamines
contributingfactors.Theeffectivenessofthesegenerateddescriptionsisassessedbycomparingtheirsimilaritytotheactuallabels,using
BLEU-2,ROUGE-L,andMETEORevaluationmetrics.
BLEU-2/
Image GroundTruth Answers ROGUE-L/
METEOR
Thecorrosiononthismetalcouldbe Thecorrosiononthismetalcouldbe
influencedbyenvironmentalfactors duetoenvironmentalfactors(mois-
(moisture,temperature,exposureto ture, temperature, chemical expo-
0.689
chemicals),themetal’scomposition, sure),themetal’scomposition,pro-
0.833
protectivecoatingfailures,andpos- tectivecoatingfailures,andpossibly
0.802
siblyphysicaldamagethatcompro- physicaldamagecompromisingthe
misedthesurface. surface
The corrosion shown may be due The corrosion shown may be due
toenvironmentalelements,material toenvironmentalfactors,defectsin 0.725
defects,orinadequatecorrosionpro- materials, or inadequate corrosion 0.848
tectionmeasures. protectionmeasures. 0.806
Corrosion here appears influenced Corrosionappearsinfluencedbydi-
bydirectexposuretoelements,pos- rectexposuretoelements,possibly
0.824
sibly exacerbated by an abrasive exacerbatedbyanabrasivemethod
0.905
treatment that may have removed thatmayhaveremovedsomeprotec-
0.901
protectivecoatings. tivecoatings.
Thestreakingpatternsindicatewa-
Thestreakingpatternssuggestwater
terflow,suggestingthatexposureto
flow,soexposuretomoistureanden- 0.725
moistureandenvironmentalfactors
vironmentalconditionslikelyplayed 0.829
likelyplayedrolesinthecorrosion
rolesinthecorrosionprocess. 0.886
process.
Inthisimage,corrosionseemsmin- Inthisimage,corrosionappearsmin-
imal, suggesting effective protec- imal, indicating that effective pro-
0.711
tive measures, possibly the triva- tectivemeasures,possiblyincluding
0.842
lentchromiumpretreatment,arein thetrivalentchromiumpretreatment,
0.931
place. areinplace.Table31.Thistableshowcasesaselectionofelectronmicroscopeimagesalongsidetheircorrespondinglabels,andframework-generated
descriptionsonanopen-endedVQAtaskdelvingintomaterialpropertieslikedurability,degradation,andenvironmentalimpact. To
gaugetheeffectivenessoftheautomaticallygenerateddescriptionsfortheseimages,weevaluatedtheirsimilaritytothetruelabelsusing
metricssuchasBLEU-2,ROUGE-L,andMETEOR.
BLEU-2/
Image GroundTruth Answers ROGUE-L/
METEOR
The material shown, likely alu- The shown material, likely alu-
minumfoil,isdurableandresistant minumfoil,isdurableandresistant
0.844
to degradation but can have a sig- to degradation but can have a sig-
0.913
nificantenvironmentalimpactifnot nificantenvironmentalimpactifnot
0.869
recycledproperly. recycledcorrectly.
The material appears to be bread, The material, which appears to
withlowdurability,quickbiodegra- be bread, possesses low durability, 0.736
dation,andminimalenvironmental quickbiodegradation,andminimal 0.903
impact. environmentalimpact. 0.855
The material appears to be carpet, The material, appearing to be car-
which is moderately durable, de- pet, possesses moderate durability,
0.447
grades over years, and can be en- degradesovertime, andcanbeen-
0.667
vironmentallyimpactfulifsynthetic vironmentallysignificantifmadeof
0.727
andnotrecycled. syntheticmaterialsandnotrecycled.
This textile, possibly canvas or Thistextile,whichcouldbecanvas
burlap, has high durability, slow or burlap, has high durability, de- 0.453
degradation, and if natural, a low grades slowly, and has a low envi- 0.634
environmentalimpact. ronmentalimpactifitisnatural 0.648
Thematerial,presumablyspongeor
Thematerial,likelyspongeorfoam,
foam,iscomparativelylessdurable,
is less durable, degrades variably, 0.500
degrades in various ways, and po-
andcanhaveahigherenvironmental 0.652
tentiallyhasahigherenvironmental
impactifnotbiodegradable. 0.688
impactifitlacksbiodegradability.
The fabric, likely comprised of a
The fabric, likely a natural fiber
natural fiber weave, is moderately
weave, is moderately durable, 0.635
durable,biodegradeseffectively,and
biodegradable, and has a low envi- 0.810
usuallyhasaminimalenvironmen-
ronmentalimpactwhenuntreated. 0.865
talimpactwhenuntreated
Thesubstance,whichappearstobe
The material, resembling an or-
an organic rind, exhibits moderate
ganicrind,hasmoderatedurability, 0.393
durability,hasbiodegradablequali-
biodegradableproperties,andalow 0.615
ties, and generally results in a low
environmentalimpact. 0.718
environmentalimpact.
Thematerial,likelysandpaper,isde- Thesubstance,resemblingsandpa-
signedforshort-termuse,degrades per, is constructed for limited use,
0.499
withwear,andhasamoderateenvi- degradeswithwear,andhasamod-
0.696
ronmentalimpactdependingonthe erateenvironmentalimpact,varying
0.573
backingmaterial. withthebacking.
Thematerial,resemblingasponge, The substance, which looks like a
haslowtomoderatedurability,vari- sponge,haslowtomoderatedurabil-
0.474
abledegradation, and apotentially ity,degradesvariably,andcanhave
0.615
high environmental impact if syn- ahighenvironmentalimpactifitis
0.708
thetic. synthetic.
Thesubstance,possiblyglitteryfab-
The material, likely glittery fabric
ric or paper, displays low to mod-
orpaper,haslowtomoderatedura-
erate durability, tends to degrade 0.609
bility,candegradeslowly,andoften
slowly,andoftenleadstoahighen- 0.696
hasahighenvironmentalimpactdue
vironmentalimpactfrommicroplas- 0.731
tomicroplasticpollution.
ticpollution.Table32.Thetabledisplaysaselectionofelectronmicroscopeimagesalongwiththeircorrespondinglabelsandframework-generated
descriptions. Thesedescriptionsareevaluatedfortheireffectivenessinaopen-endedVQAtaskthatinvestigatesdefectsandtheir
identifyingfeatures.Weassessthesimilaritybetweentheautomaticallygenerateddescriptionsandthetruelabelsusingmetricssuchas
BLEU-2,ROUGE-L,andMETEOR.
BLEU-2/
Image GroundTruth Answers ROGUE-L/
METEOR
Theimagedisplayscrazing,charac- Thepictureshowscrazing,marked
0.378
terized by a network of fine, inter- byafine,interconnectednetworkof
0.600
linkedcracksonthesurface. cracksonitssurface
0.721
Theimageshowsthedefectknown Theimageexhibitsthedefectknown
asinclusion, identifiablebydarker asinclusion,evidentfromthedarker 0.695
areasorspotsembeddedwithinthe areasorspotswithinthematerial’s 0.800
material’smatrix. matrix. 0.820
Theimageshowsadefectknownas The image depicts the defect re-
patches,whicharecharacterizedby ferred to as patches, characterized 0.460
large, dark, and irregularly shaped byexpansive,dark,andirregularly 0.651
areasonthematerial’ssurface. shapedregionsonthesurface. 0.703
The image shows a pitted surface The image illustrates a pitted sur-
defect, characterized by numerous facecondition,withnumeroussmall 0.524
small,shallowdepressionsscattered andshallowdepressionsdistributed 0.737
acrossthematerial’ssurface. acrossthematerial’ssurface. 0.643
The image illustrates the defect
Theimageshowsthedefectknown
knownasrolled-inscale,recogniz-
asrolled-inscale,indicatedbydark 0.511
ablebythedarkstreaksandembed-
streaks and spots embedded in the 0.667
dedspotsonitssurface,oftenseen
surface,typicalofmetalworking. 0.741
inmetalworking.
The image shows a defect called Theimagerevealsscratchesasade-
scratches, identifiable by the long, fect,recognizablebythelong,slen- 0.417
thin, and straight lines running der,andstraightpathsetchedacross 0.619
acrossthematerial’ssurface. thematerial’sface. 0.524