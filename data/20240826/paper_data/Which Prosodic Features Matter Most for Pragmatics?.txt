WHICHPROSODICFEATURESMATTERMOSTFORPRAGMATICS?
NigelG.Ward,DivetteMarco,OlacFuentes
UniversityofTexasatElPaso
ComputerScienceDepartment
ElPaso,Texas,79912,USA
ABSTRACT d) Toenablebetterevaluationofthequalityoftheprosodyoutput
ofagenerativesystem,forpracticalneeds,including:
We investigate which prosodic features matter most in conveying
d1) Theevaluationofspeechsynthesizeroutput[7].Aquicksurvey
prosodicfunctions.Weusetheproblemofpredictinghumanpercep-
of the papers on speech synthesis at Interspeech 2023 shows that,
tionsofpragmaticsimilarityamongutterancepairstoevaluatethe
while most discuss prosody, the features considered were mostly
utilityofprosodicfeaturesofdifferenttypes. Wefind,forexample,
pitchandduration,withonly10%mentioningintensityandonlyone
thatduration-relatedfeaturesaremoreimportantthanpitch-related
voicingproperties. Evenwhenspecificallytargetingbetterexpres-
features,andthatutterance-initialfeaturesaremoreimportantthan
sivity,conversationalstyle,andbetterprosody[8,9,10],designers
utterance-final features. Further, failure analysis indicates that
ofmetrics,lackingtrueknowledgeofwhatmatters,mayfallbackon
modeling using pitch features only often fails to handle important
what’sfamiliar,namelypitchandsometimesduration.
pragmatic functions, and suggests that several generally-neglected
d2) Building better speech-to-speech translation systems, where
acousticandprosodicfeaturesarepragmaticallysignificant,includ-
there is increasing interest in faithfully conveying more than just
ing nasality and vibrato. These findings can guide future basic
thelexicalcontent[11,12]. Knowledgeofwhichprosodicfeatures
research in prosody, and suggest how to improve speech synthesis
mattermostcansupportthedesignofbetterlossfunctions.
evaluation,amongotherapplications.
d3)Evaluatingthepowerofdiscreteandotherlearnedrepresenta-
IndexTerms— speechsynthesisevaluation,errormetrics,prag-
tions[13].
maticsimilarity,prosodicfeaturesets,feature-importanceanalysis,
d4) The design of better speech codecs. Compression algorithms
English,Spanish
havebeentraditionallydesignedtomaximizeintelligibilityandnat-
uralness, but for use in interactive communication, preservation of
1. MOTIVATION certainprosodicfeaturesisalsolikelyimportant.
d5)Designinginterpretablefeedback. Thiscanbeforpeoplewish-
We ask: What prosodic features matter most in the expression of ingtolearnhowtocommunicatemoreeffectivelyinbusinessorin
pragmaticfunctions? relationships, or for special populations such as second language
Wechoosetofocusonpragmaticfunctionsbecauseoftheirim- learners, those in rehabilitation after a stroke, and children with
portanceinemergingscenariosforspeechtechnology,suchasdialog speechorlanguagepathologies.
systems involving interpersonal sensitivity or deployed in situated Over the decades, there have been numerous investigations of
robots[1]. Prosodyiswell-knowntohaveimportantrolesincon- which prosodic features matter most for various specific purposes,
veyingmanypragmaticfunctions[2,3,4]. mostlyinclassificationandregressiontasks.Theseincludeemotion
Our question may seem dated. Certainly it is now irrelevant recognition [14, 15, 16], classification of linguistic structures such
foranyshort-termprojectforwhichthereisadequatetrainingdata. astones,boundaries,andaccents[17,18,19],estimatingjudgments
In such cases, rather than agonize over which features to use, we oflanguagelearners’accentedness,intelligibility,andotherproper-
can just use everything available, leaving it to the machine learn- ties[20],predictionofturn-takingactions[21],languagemodeling
ingalgorithmtoexploitthemeffectively. Thisstrategyisespecially [22], speaker identification [23], language identification [24], and
well-suitedtotheuseofpretrainedmodels,whichcanencodemuch detectingclinicalconditions[25].Manyinterestingthingshavebeen
prosodicinformation[5]. found,andthisbodyofworkhasgreatlyinfluencedthefeaturesin-
Nevertheless,attemptingtoanswerthisquestioncouldserve: cludedinprosodic-featuretoolkits[15,26]. However,noneofthis
a)Tosupportsystemdevelopment,whenlackingsufficienttraining workhasaddressedpragmaticsotherthanincidentally.
datatobuildamodelfromscratch.Developerscanusesomeknowl-
Inthispaperweuse“pragmatics”inabroadsense, toinclude
egeofwhichprosodicfeaturesgenerallymattermost,tohelpthem
allaspectsofinteractionindialogthatgobeyondthelexicalseman-
buildastarting-pointarchitectureormodel,whichcanthenbefine-
ticmeaning. Thesearediverse: indialog, peoplefrequentlyshow
tunedonavailabledata.
enthusiasm,makeclarifications,cueaction,clarify,criticize,praise,
b)Tosupportprioritization,forpsycholinguistsandothersdoingba-
introducenewtopics,yieldtheturntotheother,andsoon.
sic research, of research directions and questions, and for applied
researchers,forexampleforchoosingwhattofocusontodescribe
someunderstudiedlanguage,thenatureofsomecommunicationdis- 2. METHODS
order,orsomeaspectofsociolinguisticvariation.
c)Tosupportthedesignofcontrolparameterstoserveas“knobs” Ourinterestistheprosodyofpragmaticfunctionsingeneral,notfor
forhuman-in-the-loopspecificationorpost-editingoftheprosodyof anyonespecifictask. Weaccordinglychosetostudyprosodyinthe
speechsynthesizeroutput[6]. context of a general problem: estimating the perceived pragmatic
4202
guA
32
]LC.sc[
1v04231.8042:viXrasimilaritybetweenpairsofutterances. (Thiscanbeseenasagen- Correlation
eralizationofattemptstomodelhowhumansperceivesimilarityfor EuclideanDistance –0.33
intonation[27,28,29],andofmodelingsimilarexpressivity[10]). LinearRegression 0.44
Our working assumption is that a set of prosodic features that can KNNRegression 0.58
supportsuchestimates,acrossawidevarietyofdata,islikelytobe RandomForestRegression 0.70
usefulformanyapplicationsinvolvingpragmaticfunctions. Thus, cosineoverselectedHuBert 0.74
weleveragethismodel-buildingproblemtogleaninsightintowhat
aspectsofprosodymatter.
Table1:Pearson’scorrelationbetweeneachmodels’predictionsand
thehumanjudgments.
2.1. Data
Weexploitadatasetrecentlycollectedforanotherpurpose[30].This
consistsofpairsofutterances,eachwithanassessedpragmaticsim- prosodicphenomena,butcanroughlyrepresentthesortsofoverall
ilarityvalue,onacontinuousscalefrom1to5,basedontheaverage levels and contours that are often associated with pragmatic func-
rating of 6 to 9 human judges. There are 458 pairs in American tions.
English, ourmainfocusforthispaper, and235NorthernMexican Thissetissimplistic,andinparticularincludesnothingrelating
Spanishpairs. totime-sequencemodeling,notablynotemporaldeltasorfunction-
Eachutterancepairconsistsofaseedutteranceextractedfroma als,butourworkingassumptionisthatwecanstilllearnfromit.
recordeddialogandasubsequentre-enactmentofthatutterance.Re-
enactmentsweredoneundervariousconditionsdesignedtocreatea
2.3. ModelsandPredictionResults
varietyofdegreesofsimilarity.Critically,thedialogswererecorded
with diverse scenarios to broaden the coverage of pragmatic func- Whileourmainaiminthispaperistoanalyzefeatureimportance,
tions[31],andwithinthese,theseedswerealsoselectedfordiver- modelingpragmaticsimilarityisaproblemofimportanceinitsown
sity[30]. Thusthecoverageislikelyfarbroaderthanseeninany right[30,34],forexample,forusecasesd1–d3above,sothissub-
single-genre corpus. Examples of the diversity of pragmatic func- sectionfocusesonthatperspective.
tionsappearbelow. Ourprimarymetricsformodelqualityarecorrelationsbetween
Inpreliminaryanalysiswenotedaninterestingpropertyofthis the systems’ similarity estimates and the human judgments. We
dataset:somefeaturedistributionsdifferbetweenthere-enactments alsocomputedMSE,andtheresultswereconsistent. Ourprimary
andtheseeds.Inparticularthere-enactmentstendtohavelessvari- train/test split was between judgments collected in Sessions 1 and
ationinthepitchfeatures,andtobelouderandmorecreaky. 2, a month apart. We also did experiments using 10-fold cross-
validationacrossallthedata,andtheresultsweresimilar.
The models used are as follows: Euclidean Distance is a re-
2.2. Features
implementation of [32]. In this all features are weighted equally
Wewantedasetoffeaturesthatwasbroadincoverage, robustfor (aftereachisz-normalized). Forthenextthreemodels, theinputs
dialog data, generally perceptually relevant, and simple, to enable werethe 100featuredeltas, thatis, the featurevaluesfor theseed
easyinterpretationoftheresults. minus the values for the reenactment. (Performance using instead
Specifically, we chose Avila’s [32] adaptation of selected Mi- theabsolutedifferenceswasalwayssomewhatlower,asonemight
dlevelToolkit[26]featurestotileutterances. Thissetincluded10 expect for models blind to the seed-reenactment distinction.) For
basefeatures:intensity,lengthening,creakiness,speakingrate,peak theKNNRegressionModel,kwas50. FortheRandomForestRe-
disalignment(mostlylatepeak),cepstralpeakprominencesmoothed gression there were 100 trees. The ”selected HuBert cosine” uses
(CPPS),aninverseproxyforbreathyvoice,andfourpitchfeatures, the cosine similarity between feature representations consisting of
namelymeasuresofperceivedpitchhighness, pitchlowness, pitch 103Hubertlayer-24featuresselectedtomaximizeperformanceon
wideness, andpitchnarrowness. Whilethisfeaturesetisfarfrom the training data [34]. We note that none of these models is very
ideal, it is suitable for this exploration. Uniquely, it was designed sophisticated—lackingdynamictimewarpingorotheralignment
to capture the prosody of pragmatic functions — unlike prosodic methods, use of average- or max-pooling, non-linear or configura-
feature sets designed for paralinguistic properties, music, or gen- tional compositions of features, and so on — but are adequate for
eralsignalprocessing—anditwasdesignedtoberobusttomicro- exploratorypurposes.
prosodyandvariousphenomenaofconversation. Atthesametime, TheresultsareseeninTable1. First,weseetheusualtrade-off
itisflawed.Likeotherfeaturesets,noneofitscomponentfeaturesis between model simplicity/explainability and performance. More
simultaneouslyfullyrobust,fullycorrespondingtoperception,and interestingly, we see that the best designed-features model, with
fully accurate. For example, as the speaking rate feature is based randomforestregression, isdoingalmostaswellasthepretrained
onspectralflux,itsvaluescanbeaffectedbydiverseancillaryand features model. This indicates that the penalty for using designed
confoundingfactors,includingthepresenceofcreakyvoice,andthe features is small, and use of a more sophisticated decision model
CPPS feature correlates only roughly with perceptions of breathi- mightclosethegap. Further,examiningthecorrelationsseparately
ness.Nevertheless,whenusedforstatisticalandmodelingpurposes for pairs which were lexically different and for pairs which were
oversufficientdata,thefeaturesinthissetcanbeuseful,asseenby lexically-identical,performanceontheformerwasnear-random,but
theirutilityinnumerousbasicandappliedstudies[33]. 0.80forthelatter,asgoodaswithpretrainedfeatures[34].
Eachbasefeatureisnormalizedpertracktoberoughlyspeaker-
independent. We then use average values over each of ten non- 3. FEATURE-IMPORTANCEANALYSES
overlapping windows, that span fixed percentages of its duration:
0–5%, 5–10%, 10–20%, 20–30%, 30–50%, andsymmetricallyout Givenasetoffeaturesandatask,therearemanywaystomeasurethe
to100%.Thisrepresentationisnotsuitedtosyllable-orword-bound importanceoffeaturesetsandsubsets[18].Weaccordinglyinvesti-Feature Importance Correlation
speakingrate 43.7% 0.64
lengthening 20.9% 0.54
peakdisalignment 7.8% 0.32
CPPS 5.9% 0.04
pitchhighness 4.1% 0.12
pitchnarrowness 4.0% –0.06
pitchwideness 3.9% 0.00
creakiness 3.5% 0.14
pitchlowness 3.3% 0.13
intensity 3.1% –0.03
4pitchfeatures 15.2% 0.16
all10features 100.0% 0.70
Table2:Featuretypes,orderedbyimportancefortherandomforest
regression model and also showing performance of a model using
featuresofthistypealone.
Fig. 1: Single-feature correlations between the judgments and the
deltasforfiveofthemostinformativefeaturetypes,acrossbothSes-
sion1andSession2data.TheX-axisrepresentstheregions,defined
byfixedpercentagesoftheutteranceduration.
gatedusingthreemethods.First,wesimplycomputedthePearson’s
correlation between each of the 100 features and the target judg-
ments. Secondweexaminedhowmucheachfeaturecontributedto
theperformanceoftheRandomForestRegressionModels; specif- 3.2. MostImportantFeaturePositions
ically,weobtainedthefeatureimportancevaluesintermsofimpu-
ritydecreaseforeachfoldandaveragedthese. Third,wedidsubset Figure2summarizessomeoftheevidenceregardingwhichfeature
andablationstudies, examiningperformancewhenincludingonly, positionsmattermost. Itseemsthattheprosodyabout70–90%into
orwhenexcludingonly,variousfeaturetypes. theutterancesisrelativelyinformative.Sincethiswasespeciallytrue
forpeakdisalignment,pitchwideness,pitchhighness,andlengthen-
Theimplicationsnotedbelowareallmultiplysupported,so,to
ing, we suspect that this may relate to the common occurrence of
save space, we present only a selection of the evidence. However
varioustypesofpitchpeak(suchasnuclearaccents)atthispointin
we note that there is no consistent ranking of features, as seen in
manyutterances.Therewereotherinteractionsbetweenfeaturetype
Table2. Thisisnotsurprising;rather,theexistenceoffeaturetypes
andposition—speakingrateisespeciallyinformativeinthebegin-
with low correlations but relatively high importance indicates that
ningsandmiddlesofutterances,peakdisalignmentatthebeginning,
the features are not independent, and instead, as often noted [33],
andthelengtheningfeaturemostlytowardtheend—butthesedid
specificconfigurationsoffeatureslikelybearspecificmeanings.We
not seem to fall into any pattern. There is some evidence that the
alsonotethatthefeaturesarehighlyredundant:ablatinganyspecific
typeonlyslightlyreducestheperformance.
3.1. MostImportantFeatureTypes
Table 2 shows results per feature type, and Figure 1 displays the
correlations for five informative feature types, We draw three im-
plications: 1) Duration features are important, with speaking rate
thetopfeaturebyeverymeasures. Interestingly,whilelengthening
is strongly anti-correlated with speaking rate, we it still has some
independent value, increasing the performance over speaking rate
aloneby0.02(correlationwithhumanjudgments). 2)Thevalueof
thepitchfeaturesislow. Thiswasnotentirelyasurprise, because
the reasons that pitch is popular — being salient, easy to visual-
ize,familiarfrommusic,relativelyeasytomeasure,andhistorically
important—donotimplyactualutility,andwesuspectedthatthe
self-evidentimportanceofpitchfeaturesformodelingreadspeech
maynotcarryovertodialog. Howevertheimportanceofthepitch
featureswassurprisinglysmall. Asthisisthefirststudytoactually
measurethevalueofprosodicfeaturesforpragmaticfunctions,the
Fig. 2: Feature importance as a function of position (time slice):
lastwordisyettobewritten,butwecanconcludeatleastthatpitch
ontheleftaxis,performanceofamodelusingonlyfeaturesatthat
featuresdonotdeservetheexclusiverespectthattheyoftenget. 3)
position;ontherightaxis,summedimportanceintherandomforest
Theleastinformativefeaturesoverallareintensityandpitchnarrow-
regressionmodel.
ness.prosodyearlyinutterancesisrelativelymoreimportantandthefinal model, andofcourse, themagnitudeofthedivergenceswasmuch
prosodyistheleastimportant,butthelattermaybeoverstatedinthe lessthanforthepitch-onlymodel.
figure,asthe95-100%featuresarenotrobusttovariationinwhere Audioillustratingthesepointsisavailableathttps://www.cs.utep.
the labelers marked utterance ends, and in these dialogs the utter- edu/nigel/pros-prag/.
ancesoftentrailedoff. Overall,however,wedidnotfindanystrong
tendenciesregardingwhichfeaturepositionsaremostimportant.
5. SPANISH
4. QUALITATIVEANALYSES Wondering which of the findings above might apply beyond En-
glish,werepeatedmostoftheanalysesusingtheSpanishdatafrom
Our first qualitative analysis was a brief exploration of why pitch- [30]. In brief, we found: 1) These features serve to predict prag-
only model performed so much worse than the all-feature model. matic similarity fairly well for Spanish too (0.73 correlation, with
We examined a small sampling of pairs for which the predictions 10-foldcross-validation). 2)Thefeaturetypeswiththehighestcor-
oftheformerwerefarmoreaccuratethanthoseofthelatter. Sev- relationsonlypartlyoverlappedthoseforEnglish,withthetopthree
eralpragmaticfunctionswerecommoninthesepairs,mostlycom- being speaking rate, creakiness, and pitch wideness. 3) Modeling
monlypositive/negativeassessment,turnhold/yield,andcorrection usingpitchalonewasagainfarinferiortousingallfeatures,butthe
ofamisunderstanding. Themostcommonprosodic-acousticprop- penaltywaslessthanforEnglish(correlationof0.41,with10-fold
erties present in these pairs, which also seemed to be involved in cross-validation),4)Utterance-finalfeatureswereagaintheleastin-
conveyingthesemeanings,includednasalityandspeakingratevaria- formative,5)Modelstrainedononelanguageandtestedontheother
tion.Saliently,eachofthesepoorly-handledpairshadasynthesized- performedreasonablywell(e.g.SpanishtrainedonEnglish:correla-
speechre-enactment. Fromthisweinferthatthesynthesizerused, tion0.68),butnotaswellaslanguage-specificmodels. 6)Common
namely Amazon Polly, is not able to effectively control (or even featureslackingfromthemodelbutimportantforhumanperception
much vary, it seems) many of the prosodic characteristics that are ofdifferencesagainincludednasalityanddevoicing.7)Humansof-
importanttohumanperception.Asfarasweknow,thisisalsolikely ten overlooked differences in creakiness, nasality, and breathiness,
true for all synthesizers, and we speculate that this is due in large andtheseoftenseemedtoreflectgender-specificpatternsofuse.
parttothepitch-prioritizinglossfunctionsthattheyaretrainedto.
Our second qualitative analysis explored the limitations of 6. SUMMARYANDLIMITATIONS
Avila’s100-featureset. Althoughdesignedtobewidelyinclusive,
it did not quite support state-of-the-art performance, at least with Wehavereportedtheresultsofthefirstsystematicstudyofwhich
the models tried. Again we did failure analysis, this time more prosodic features matter most for pragmatics. While we can, of
thoroughly,examining30pairsforwhichthepredictionsofourbest courseprovidenodefinitiveanswertothisquestion—thebestfea-
model,theRandomForestRegressionmodel,testedin10-foldcross turesetwillalwaysdependonthetask,language,speakerpopulation
validation,divergedmostfromthehumanjudgments. andsoon—thisexplorationhascontributed:
Firstweexaminedpairswhichthemodelratedmuchhigherthan
• a new method for evaluating the pragmatic adequacy of
didthejudges, lookingfordifferencesthatourearscouldhearbut
prosodicfeaturesets
thatthemodellikelyhadmissed.Almostalloftheseinvolveddiffer-
encesinnasality.Alsocommonweredifferencesinpausefrequency, • someexplainablemodelsforpredictinghumanjudgmentsof
length,andlocation. Otherfactorswenoticedinclude,inroughor- pragmaticsimilarity
deroffrequency,wordssaidwithorwithoutlaughing,theexactpho-
• anewmethodfordiscoveringimportantbutlackingfeatures
neticformofnon-lexicalutterances,suchasoh,phoneticreduction
• indicationsforwhichfeaturesshouldbeincludedinevalua-
including devoicing, stressing of specific words, vibrato, falsetto,
tionmetricsforapplications,notablynotonlypitchfeatures
non-lexical sighs, uses of glottal stops, ejectives, and strong har-
butalsoduration-relatedandvoicingfeatures
monicity. Speakingratevariationsandbreathinesswerealsocom-
monfactors,eventhoughthespeakingrateandCPPSfeatureswere • identificationofpragmaticfunctionsthatarepoorlyhandled
intendedtocoverforsuchperceptions. by pitch-only feature sets, including making corrections,
Second,weexaminedpairsthatthemodelratedmuchlowerthan marking positive or negative feeling, and indicating turn
thejudges. Onefrequentfactorwasdifferencesinpacingorpause hold/yieldintentions
placement that were not significant to our ears, but seemed to trip
• identificationoffeaturesthatareunderstudiedbutimportant
upthemodel. Thissuggests,unsurprisingly,thatamodelcoulddo
for pragmatics, and thereby deserving of further study, no-
better with some kind of alignment or max-pooling. Another fac-
tablynasalityandvibrato
torwasapparentindividual-or,often,gender-basedvariantprosodic
formsforconveyingthesamemeaning. Forexample,inohmygod, Whilewehavebrokennewground,wenotethatthisstudyhas
it’s working (female) and yo, it’s working (male), where, in addi- numerouslimitations,includingthesmalldatasizes,thesimplicity
tiontothelexicaldifferences,theformerusedvibrato,breathyand ofthefeaturesandmodeling, thelackofcoverageofallgenresof
falsettovoice,andthemalecreakyvoice,bothconveyedexcitement dialog,andthefocusonAmericanEnglish.Furtherworkisneeded.
andmatchedwellinnuance.Thus,whilemostaspectsofspokenEn-
glishareamenabletogender-agnosticmodeling, thissuggeststhat Acknowledgment
thisstrategywillnotworkwellforpragmatics-relatedprosody.
Third,werevisitedthesepairsandasamplingofpairsthatwere This work was supported in part by National Science Foundation
handledwell,hopingtodiscoverwhichpragmatic-functiondistinc- award2348085andtheAIResearchInstitutesprogramoftheNSF
tionsremainproblematic, evenwiththefullfeatureset. However, andbytheInstituteofEducationSciences,U.S.DepartmentofEdu-
therewerenoclearpatterns:allthefunctionsidentifiedasproblem- cationthroughAward#2229873–NationalAIInstituteforExcep-
atic for the pitch-only model were often handled well by the full tionalEducation.7. REFERENCES [17] Neville Ryant, Malcolm Slaney, Mark Liberman, Elizabeth
Shriberg,andJiahongYuan, “HighlyaccurateMandarintone
[1] Matthew Marge, Carol Espy-Wilson, Nigel G. Ward, et al., classificationintheabsenceofpitchinformation,” inProceed-
“Spokenlanguageinteractionwithrobots:Researchissuesand ingsofSpeechProsody,2014.
recommendations,” ComputerSpeechandLanguage,vol.71,
[18] AntonBatliner, JanBuckow, RichardHuber, VolkerWarnke,
2022.
ElmarNo¨th,andHeinrichNiemann, “Prosodicfeatureevalua-
[2] Dagmar Barth-Weingarten, Nicole Dehe´, and Anne Wich- tion:Bruteforceorwelldesigned,”inProc.14thInt.Congress
mann, WhereProsodyMeetsPragmatics, Brill,2009. ofPhoneticSciences,1999,vol.3,pp.2315–2318.
[3] HarmLameris,JoakimGustafsson,andE´vaSze´kely,“Beyond [19] AntonBatliner, JanBuckow, RichardHuber, VolkerWarnke,
style:Synthesizingspeechwithpragmaticfunctions,”inInter- ElmarNo¨th, andHeinrichNiemann, “Boilingdownprosody
speech,2023,pp.3382–3386. fortheclassificationofboundariesandaccentsinGermanand
English,” inEurospeech,2001,pp.2781–2784.
[4] WeiqinLi,PeijiYang,etal.,“Spontaneousstyletext-to-speech
synthesis with controllable spontaneous behaviors based on [20] Eduardo Coutinho, Florian Ho¨nig, et al., “Assessing the
languagemodels,” inInterspeech,2024. prosodyofnon-nativespeakersofEnglish: Measuresandfea-
turesets,” inConferenceonLanguageResourcesandEvalua-
[5] Guan-TingLin,Chi-LuenFeng,etal., “Ontheutilityofself-
tion(LREC2016),2016,pp.1328–1332.
supervisedmodelsforprosody-relatedtasks,” inIEEEWork-
shoponSpokenLanguageTechnology(SLT),2022,pp.1104– [21] GabrielSkantze, “Turn-takinginconversationalsystemsand
1111. human-robotinteraction:Areview,”ComputerSpeech&Lan-
guage,vol.67,pp.101178,2021.
[6] Dan Andrei Iliescu, Devang S Ram Mohan, Tian Huey Teh,
andZackHodari, “Controllableprosodygenerationwithpar- [22] Nigel G. Ward, Alejandro Vega, and Timo Baumann,
tialinputs,” inIEEEICASSP,2024,pp.11916–11920. “Prosodicandtemporalfeaturesforlanguagemodelingfordi-
alog,” SpeechCommunication,vol.54,pp.161–174,2011.
[7] Petra Wagner, Jonas Beskow, et al., “Speech synthesis eval-
uation: State-of-the-artassessmentandsuggestionforanovel [23] LucianaFerrer,NicolasScheffer,andElizabethShriberg, “A
researchprogram,” inProceedingsofthe10thSpeechSynthe- comparison of approaches for modeling prosodic features in
sisWorkshop(SSW10),2019. speakerrecognition,” inIEEEICASSP,2010,pp.4414–4417.
[24] Raymond W. M. Ng, Tan Lee, Cheung-Chi Leung, Bin Ma,
[8] Wen-ChinHuang,BenjaminPeloquin,etal., “AHolisticCas-
andHaizhouLi, “Analysisandselectionofprosodicfeatures
cadeSystem,Benchmark,andHumanEvaluationProtocolfor
for language identification,” in IEEE International Conf. on
ExpressiveSpeech-to-SpeechTranslation,” inICASSP,2023.
AsianLanguageProcessing,2009,pp.123–128.
[9] YayueDeng,JinlongXue,etal., “ConCSS:Contrastive-based
[25] Ethan Weed and Riccardo Fusaroli, “Acoustic measures of
context comprehension for dialogue-appropriate prosody in
prosodyinright-hemispheredamage:Asystematicreviewand
conversationalspeechsynthesis,” inIEEEICASSP,2024,pp.
meta-analysis,” Journal of Speech, Language, and Hearing
10706–10710.
Research,vol.63,no.6,pp.1762–1775,2020.
[10] Kevin Heffernan, Artyom Kozhevnikov, et al., “Aligning
[26] Nigel G. Ward, “Midlevel prosodic features toolkit (2016-
speechsegmentsbeyondpuresemantics,” inFindingsofthe
2023),” https://github.com/nigelgward/midlevel,2023.
Association for Computational Linguistics, 2024, pp. 3626–
3635. [27] DikJ.Hermes, “Auditoryandvisualsimilarityofpitchcon-
tours,” JournalofSpeech,Language,andHearingResearch,
[11] Lo¨ıcBarrault,Yu-AnChung,etal., “Seamless: Multilingual
vol.41,pp.63–72,1998.
expressive and streaming speech translation,” arXiv preprint
arXiv:2312.05187,2023. [28] Uwe D. Reichel, Felicitas Kleber, and Raphael Winkelmann,
“Modelling similarity perception of intonation,” in Inter-
[12] Eliya Nachmani, Alon Levkovitch, Yifan Ding, Chulayuth
speech,2009,pp.1711–1714.
Asawaroengchai, Heiga Zen, and Michelle Tadmor Ra-
[29] OlivierNocaudieandCorineAste´sano, “Evaluatingprosodic
manovich, “Translatotron3:Speechtospeechtranslationwith
similarity as a means towards L2 teacher’s prosodic control
monolingualdata,” inIEEEICASSP,2024,pp.10686–10690.
training,” SpeechProsody2016,pp.26–30,2016.
[13] LeyuanQu,TaihaoLi,etal.,“Disentanglingprosodyrepresen-
[30] NigelG.WardandDivetteMarco,“Acollectionofpragmatic-
tationswithunsupervisedspeechreconstruction,” IEEE/ACM
similarity judgments over spoken dialog utterances,” in Lin-
Transactions on Audio, Speech, and Language Processing,
guisticResourcesandEvaluationConference,2024.
2023.
[31] NigelG. Ward, Jonathan E. Avila, Emilia Rivas, andDivette
[14] AntonBatliner,StefanSteidl,BjornSchuller,etal.,“Whodun-
Marco, “Dialogs re-enacted across languages, version 2,”
nit: Searchingforthemostimportantfeaturetypessignalling
Tech. Rep. UTEP-CS-23-27, University of Texas at El Paso,
emotion-relateduserstatesinspeech,” ComputerSpeechand
DepartmentofComputerScience,2023.
Language,vol.25,pp.4–28,2011.
[32] Jonathan E. Avila and Nigel G. Ward, “Towards cross-
[15] FlorianEyben,KlausR.Scherer,etal.,“TheGenevaminimal-
languageprosodytransferfordialog,” inInterspeech,2023.
isticacousticparameterset(GeMAPS)forvoiceresearchand
affectivecomputing,”IEEETransactionsonAffectiveComput- [33] Nigel G. Ward, Prosodic Patterns in English Conversation,
ing,vol.7,pp.190–202,2016. CambridgeUniversityPress,2019.
[34] Nigel G. Ward, Andres Segura, Alejandro Ceballos, and Di-
[16] Bogdan Vlasenko, Sargam Vyas, et al., “Comparing data-
vetteMarco, “Towardsageneral-purposemodelofperceived
driven and handcrafted features for dimensional emotion
pragmaticsimilarity,” inInterspeech,2024.
recognition,” inIEEEICASSP,2024,pp.11841–11845.