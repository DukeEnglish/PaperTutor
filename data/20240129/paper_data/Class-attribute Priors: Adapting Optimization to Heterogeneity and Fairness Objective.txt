Class-attribute Priors: Adapting Optimization to
Heterogeneity and Fairness Objective
XuechenZhang1,MingchenLi2,JiasiChen2,ChristosThrampoulidis3,SametOymak2
1UniversityofCalifornia,Riverside
2UniversityofMichigan,AnnArbor
3UniversityofBritishColumbia
xzhan394@ucr.edu,milii@umich.edu,jiasi@umich.edu,cthrampo@ece.ubc.ca,oymak@umich.edu
Abstract assigningindividualweightstoclassesduringoptimization.
Therecentproposalsonimbalancedclassification(Lietal.
Modernclassificationproblemsexhibitheterogeneitiesacross
2021;Chawlaetal.2002)canbeviewedasgeneralization
individualclasses:Eachclassmayhaveuniqueattributes,such
of weighting and can be interpreted as developing unique
assamplesize,labelquality,orpredictability(easyvsdiffi-
loss functions for individual classes. More generally, one
cult),andvariableimportanceattest-time.Withoutcare,these
canuseclass-specificdataaugmentationschemes,regular-
heterogeneities impede the learning process, most notably,
whenoptimizingfairnessobjectives.Confirmingthis,under izationorevenoptimizers(e.g.Adam,SGD,etc)toimprove
agaussianmixturesetting,weshowthattheoptimalSVM targettestobjective.Whilepromising,thisapproachsuffers
classifierforbalancedaccuracyneedstobeadaptivetothe whentherearealargenumberofclassesK:naivelylearning
classattributes.ThismotivatesustoproposeCAP:Aneffec- class-specificstrategieswouldrequireO(K)hyperparame-
tiveandgeneralmethodthatgeneratesaclass-specificlearning ters(O(1)strategyhyperparameterperclass).Thisnotonly
strategy(e.g.hyperparameter)basedontheattributesofthat createscomputationalbottlenecksbutalsoraisesconcernsof
class.Thisway,optimizationprocessbetteradaptstohetero-
overfittingfortailclasseswithsmallsamplesize.
geneities. CAP leads to substantial improvements over the
To overcome such bottlenecks, we introduce the Class-
naiveapproachofassigningseparatehyperparameterstoeach
attribute Priors (CAP) approach. Rather than treating hy-
class.WeinstantiateCAPforlossfunctiondesignandpost-hoc
perparametersasfreevariables,CAPisameta-approachthat
logitadjustment,withemphasisonlabel-imbalancedproblems.
WeshowthatCAPiscompetitivewithpriorartanditsflex- treatsthemasafunctionoftheclassattributes.Aswediscuss
ibilityunlocksclearbenefitsforfairnessobjectivesbeyond later,exampleattributesAofaclassincludeitsfrequency,
balancedaccuracy.Finally,weevaluateCAPonproblemswith label-noiselevel,trainingdifficulty,similaritytootherclasses,
labelnoiseaswellasweightedtestobjectivestoshowcase test-timeimportance,andmore.OurprimarygoalwithCAP
howCAPcanjointlyadapttodifferentheterogeneities. isbuildinganattribute-to-hyperparameterfunctionA2H
thatgeneratesclass-specifichyperparametersbasedonthe
attributes associated with that class. This process infuses
1 Introduction
high-levelinformationaboutthedatasettoacceleratethede-
Contemporary machine learning problems arising in natu- signofclass-specificstrategies.TheA2Hmapstheattributes
rallanguageprocessingandcomputervisionofteninvolve Atoaclass-specificstrategyS.Theprimaryadvantageis
largenumberofclassestopredict.Collectinghigh-quality robustnessandsampleefficiencyofA2H,asitrequiresO(1)
trainingdatasetsforalloftheseclassesisnotalwayspossi- hyperparameterstogenerateO(K)strategies.Themaincon-
ble,andrealisticdatasets(Menonetal.2020;Feldman2020; tributionofthisworkisproposingCAPframeworkandinstan-
Hardt,Price,andSrebro2016)sufferfromclass-imbalances, tiatingitforlossfunctiondesignandpost-hocoptimization
missing or noisy labels (among other application-specific whichrevealsitsempiricalbenefits.Specifically,wemake
considerations).Optimizingdesiredaccuracyobjectiveswith thefollowingcontributions:
suchheterogeneitiesposesasignificantchallengeandmo-
1. IntroducingClass-attributePriors(Sec3).Wefirstpro-
tivatesthecontemporaryresearchonimbalancedclassifica-
videtheoreticalevidenceonthebenefitsofusingmultiple
tion,fairness,andweak-supervision.Additionally,besides
attributes (see Fig 2). This motivates CAP: A meta ap-
distributionalheterogeneities,wemighthaveobjectivehet-
proachthatutilizesthehigh-levelattributesofindividual
erogeneity.Forinstance,thetargettestaccuracymaybea
classes to personalize the optimization process. Impor-
particularweightedcombinationofindividualclasses,where
tantly,CAPisparticularlyfavorabletotailclasseswhich
importantclassesareupweighted.
containtoofewexamplestooptimizeindividually.
Aplausibleapproachtoaddressthesedistributionaland
2. CAPimprovesexistingapproaches(Sec4).Byintegrat-
objectiveheterogeneitiesisdesigningoptimizationstrategies
ingCAPwithinexistinglabel-imbalancedtrainingmeth-
thataretailoredtoindividualclasses.Aclassicalexampleis
ods,CAPnotonlyimprovestheirperformancebutalso
Copyright©2024,AssociationfortheAdvancementofArtificial increases their stability, notably, AutoBalance (Li et al.
Intelligence(www.aaai.org).Allrightsreserved. 2021)andlogit-adjustmentloss(Menonetal.2020).
4202
naJ
52
]GL.sc[
1v34341.1042:viXraC Acla cs us r ad cis ytribution Previous class distribution InstantiationsofCAP:
Target class distribution 1.Bileveloptimizationoflossfunction
2.Post-hocoptimizationoflogits
DistinctFairnessObjectives(Sec4.3):
Sample size & Predictability Sample size & Distribution shift Label quality
Heterogeneous CAP Balancederror
Function QuantilesorConditionalvalueatRisk
Class 1 Attributes S Standarddeviationofclass-conditionalerrors
Weightederror
= Class 2 Dictionary DistinctHeterogeneities(Sec4.2):
Full Dataset … … Train Objective Classfrequency
Predictiondifficulty
Class n Variableclassimportance
Labelnoiselevel
Figure1:Lefthandside:CAPviewstheglobaldatasetasacompositionofheterogeneoussub-datasetsinducedbyclasses.Weextract
high-level attributes from these classes and use these attributes to generate class-specific optimization strategies (which correspond to
hyperparameters).Ourproposalisefficientlygeneratingthesehyperparametersbasedonclass-attributesthroughameta-strategy.Righthand
side:WedemonstratethatCAPleadstostate-of-the-artstrategiesforlossfunctiondesignandpost-hocoptimization.CAPcanleveragemultiple
attributestoflexiblyoptimizeavarietyoftestobjectivesunderheterogeneities.
3. CAPadaptstofairnessobjective(Sec4.2).CAP’sflex- weightthelossfunctionsotheoptimizationgeneratesaclass-
ibilityisparticularlypowerfulfornon-standardsettings balancedmodel.Inadditiontothesemethods,(Lietal.2021)
thatpriorworksdonotaccountfor:CAPachievessignif- proposesabileveltrainingschemethatdirectlyoptimizesl
icantimprovementwhenoptimizingfairnessobjectives and∆onasufficientsmallimbalancedvalidationdatawith-
otherthanbalancedaccuracy,suchasstandarddeviation, outthepriortheoreticalinsights.However,thetheory-based
quantileerrors,orConditionalValueatRisk(CVaR). methods require expertise and trial and error to tune one
4. CAPadaptstoclassheterogeneities(Sec4.3).CAPcan temperature variable, making it time-consuming and chal-
alsoeffortlesslycombinemultipleattributes(suchasfre- lengingtoachieveafine-grainedlossfunctionthatcarefully
quency, noise, class importance) to boost accuracy by handleseachclassindividually.Althoughthebilevel-based
adaptingtoproblemheterogeneity. methodconsidereachclassseparatelyandpersonalizesthe
weightusingvalidationdata,optimizingthebilevelproblem
Finally,whileweinstantiateCAPfortheproblemsofloss-
istypicallytime-consumingduetotheHessiancomputations.
functiondesignandpost-hocoptimization,CAPcanbeap-
Bileveloptimizationisalsobrittle,especiallywhen(Lietal.
plied for the design of class-specific augmentations, regu-
2021)optimizestheinnerlossfunction,whichcontinually
larization schemes, and optimizers. This work makes key
changestheinneroptimaduringthetraining.
contributions to fairness and heterogeneous learning prob-
Regardingthebroadergoaloffairnesswithrespecttopro-
lemsintermsofmethodology,aswellaspracticalimpact.
tectedgroups,theliteraturecontainsseveralproposals(Sahu
AnoverviewofourapproachisshowninFig.1
etal.2018;Kleinberg,Mullainathan,andRaghavan2016).
Balancederrorandstandarddeviation(Calmonetal.2017;
1.1 RelatedWork
Alabi, Immorlica, and Kalai 2018) between subgroup pre-
Theexistingliteratureestablishesaseriesofalgorithms,in- dictionsarewidelyusedmetrics.However,theymaybein-
cludingsampleweighting(Alshammarietal.2022;Maldon- sensitivetocertaintypesofimbalances.TheDifferenceof
ado et al. 2022; Kubat, Matwin et al. 1997; Wallace et al. EqualOpportunity(DEO)(Kinietal.2021;Hardt,Price,and
2011; Chawla et al. 2002), post-hoc tuning (Menon et al. Srebro 2016) was proposed to measure true positive rates
2020; Zhang et al. 2019; Kim and Kim 2020; Kang et al. across groups. (Zafar et al. 2017) focus on disparate mis-
2019;Yeetal.2020),andlossfunctionstuning(Caoetal. treatmentinbothfalsepositiverateandfalsenegativerate.
2019;Kinietal.2021;Menonetal.2020;Khanetal.2017; ManymodernMLtasksnecessitatemodelswithgoodtail
Cuietal.2019;Lietal.2022;Tanetal.2020;Zhangetal. performance,focusingonunderrepresentedgroups.Recent
2017),andmore(Zhangetal.2023).Thisworkaimstoes- works have introduced techniques that promote better tail
tablishaprincipledapproachfordesigningalossfunction accuracy(Hashimotoetal.2018;Sagawaetal.2019,2020;
for imbalanced datasets. Traditionally, a Bayes-consistent Lietal.2021;KiniandThrampoulidis2020).Theworst-case
loss function such as weighted cross-entropy (Xie et al. subgrouperroriscommonlyusedinrecentpapers(Kinietal.
2018; Morik, Brockhausen, and Joachims 1999) has been 2021;Sagawaetal.2019,2020).Anotherpopularmetricto
used. However, recent work shows it only adds marginal evaluatethemodel’stailperformanceistheCVaR(Condi-
benefit to the over-parameterized model due to overfitting tional Value at Risk) (Williamson and Menon 2019; Zhai
during training. (Menon et al. 2020; Ye et al. 2020; Kini etal.2021;Michel, Hashimoto, andNeubig2021),which
etal.2021)proposeafamilyoflossfunctionsformulatedas computes the average error over the tails. Previous works
(cid:16) (cid:17)
ℓ(y,f(x)) = log 1+(cid:80) elk−ly ·e∆kfk(x)−∆yfy(x) (Hashimoto et al. 2018; Duchi and Namkoong 2021; Hu
k̸=y
et al. 2018; Michel, Hashimoto, and Neubig 2021; Lahoti
withtheoreticalinsights,wheref(x)denotestheoutputlog-
etal.2020)alsomeasuretailbehaviourusingDistributionally
itsofxandf (x)representstheentrythatcorrespondsto
y RobustOptimization(DRO).
labely.Abovemethodsdeterminethevalueofland∆tore-2 ProblemSetup
Thispaperinvestigatestheadvantagesofutilizingattribute-
basedpersonalizedtrainingapproachesforaddressinghetero-
geneousclassesinthecontextofclassimbalance,labelnoise,
andfairnessobjectiveproblems.Webeginbypresentingthe
generalframework,followedbyanexaminationofspecific
fairnessissues,whichencompassbothdistributionalandob-
jectiveheterogeneities.Consideramulti-classclassification
problemforadataset(x ,y )N sampledi.i.dfromadistri-
i i i=1
butionwithinputspaceX andK classes.Let[K]denotethe (a)Imbalanceπ=0.1 (b)Imbalanceπ=0.2
set{1..K}andforthetrainingsample(x,y),x∈X isthe
inputandy ∈[K]istheoutput.f :X →RK representsthe Figure2:Theoptimalhyperparameterδ ∗ dependsonboth
attributes:frequency(π)anddifficulty(σ /σ ).
modelandoistheoutputlogits.yˆ = argmax o + −
f(x) k∈[K] k
is the predicted label of the model f(x). We also denote
K ×K identity matrix by I . Moreover, in the post-hoc
K assigninglargermargintotheminorities.Inparticular,setting
setup,alogitadjustmentfunctiong :RK →RK isemployed
δ = 1 recovers the vanilla SVM. CS-SVM is particularly
tomodifythelogits,resultinginadjustedlogitsoˆ=g(o).
relevanttooursettingbecauseithasrigorousconnectionsto
Ourgoalistotrainamodelthatminimizesaspecificclassi-
thegeneralizedcross-entropylossinSec3.2(seeAppendix
ficationerrormetric.Theclass-conditionalerrorsaredefined
Ffordetails).GivenCS-SVMsolution(wˆ ,ˆb ),wemeasure
overthedatadistributionasErr = P[y ̸=yˆ (x)|y =k]. δ δ
k f
thebalancederrorasfollows:
The standard classification error is denoted by Err =
plain
P[y ̸=yˆ f(x)].Insituationswithlabelimbalance,Err plainis R (δ):=P (cid:110) y(xTwˆ +ˆb )>0(cid:111) .
dominatedbythemajorityclasses.Tothisend,balancedclas- bal (x,y)∼GMM δ δ
sificationerrorErr bal = K1 (cid:80)K k=1Err k iswidelyemployed Weask:HowdoestheoptimalCS-SVMclassifier(i.e,the
asafairnessmetric.Wewilllaterintroduceotherobjectives optimalhyperparameterδ)dependonthedataattributes,i.e.
thataimtoachievedifferentfairnessgoals.Acompletelist onthefrequencyπandonthedifficultyσ /σ ?Toanswer
+1 −1
oftheobjectivesweexaminecanbefoundinAppendix. this we consider a high-dimensional asymptotic setting in
whichn,d → ∞atalinearrated/n =: d¯.Thisregimeis
3 OurApproach:Class-attributePriors(CAP)
convenientaspreviousworkhasshownthatthelimitingbe-
Westartwithamotivatingquestion: haviorofthebalancederrorR (δ)canbecapturedprecisely
bal
Q:Doesutilizingmultipleclassattributesprovablyhelp? by analytic formulas (Montanari et al. 2019). Specifically,
To answer this, we consider the benefits of multiple at- (Kinietal.2021)computesformulasfortheoptimalhyper-
tributes for a binary gaussian mixture model (GMM) and parameterδwhenπisvariablebutbothclassesareequally
provideasimpletheoreticaljustificationwhysynergistically difficult, i.e. σ = σ . Here, we derive risk curves for
+1 −1
leveragingattributescanhelpbalancedaccuracy.Considera arbitrary σ by extending their study and investigate the
±1
GMMwheredatafromthetwoclassesaregeneratedas synergisticeffectoffrequencyanddifficulty.
Figure 2 confirms our intuition: the optimal hyperpa-
(cid:26)
+1 ,withprob.π
y =
−1 ,withprob.1−π
and x|y ∼N(yµ,σ yI d). r aa nm de dt ie fr ficδ ∗ ul( ty y-a (ax sis w)d elo le as sin thd eee trd aid ne inp gen sd amon plt eh se izf ere ,q xu -ae xn ic sy
).
Specifically,weobserveinbothFigures2(a,b)thatasthemi-
Noteherethatthetwoclassesareimbalancedasafunction
norityclassbecomeseasier(aka,thesmallerratioσ /σ ),
of the value of π ∈ (0,1), which models class frequency. +1 −1
δ decreases. That is, there is less need to assign an even
Also, the two classes are allowed to have different noise
largermarginfortheminority.Conversely,asσ /σ in-
variancesσ .Thisisourmodelforthedifficultyattribute: +1 −1
±1 creasesandminoritybecomesmoredifficult,itsmargingets
examplesgeneratedfromtheclasswithlargervarianceare
aboost.Finally,comparingFigures2(a)to2(b),notethatδ
“moredifficult"toclassifyastheyfallfurtherapartfromtheir ∗
takes larger values for larger imbalance ratio (i.e., smaller
mean.Intuitively,a“good"classifiershouldaccountforboth
frequencyπ),againaggreeingwithcommonsense.
attributes.Weshowherethatthisisindeedthecaseforthe
SinceGMMdataissynthetic,δ canbecomputedanalyti-
modelabove.Oursettingisasfollows:DrawnIIDsamples ∗
cally.OurapproachCAPwillfacilitaterealizingsuchbenefits
(x ,y )fromtheGMMdistributionabove.Withoutlossof
i i systematicallyandefficientlyforarbitraryclassattributes.
generality,assumeclassy = +1isminority,i.e.π < 1/2.
Wetrainlinearclassifier(w,b)bysolvingthefollowingcost-
3.1 AttributesandAdaptationtoHeterogeneity
sensitivesupport-vector-machines(CS-SVM)problem:
Toproceed,weintroduceourCAPapproachataconceptual
(cid:26) δ y =+1 levelandprovideconcreteapplicationsofCAPtolossfunc-
(wˆ ,ˆb ):=argmin∥w∥ s.t.y (xTw+b)≥ i .
δ δ w,b 2 i i 1 y i =−1 tion design in the next section. Recall that our high-level
goalisdesigningamapfromA2HthattakesattributesA of
k
Here,δ isahyperparameterthatwhentakingvalueslarger classkandgeneratesthehyperparametersoftheoptimization
thanone,itpushestheclassifiertowardsthemajority,thus strategyS .EachcoordinateA [i]characterizesaspecific
k kAttributes Definition Notation Applicationscenario
A Classfrequency π =P(y =k) Imbalancedclasses
FREQ k
A Class-conditionalerror P(y ̸=yˆ) Difficultvseasyclasses
DIFF
A Test-timeclassweights ωtest of(3) Weightedtestaccuracy
WEIGHTS k
(cid:12)
A Labelnoiseratio P(yCLEAN ̸=y(cid:12)yclean =k) Datasetswithlabelnoise
NOISE
A Normofclassifierweights See(Caoetal.2019) Imbalancedclasses
NORM
Table1:Definitionofexampleattributesandassociatedapplicationscenarios.AttributesA andA arecomputedduring
DIFF NORM
thetraining(forpost-hocoptimization,itispre-training).Forbileveltrainingtheyarecomputedattheendofwarm-up.The
upperattributesinredcolorarethoseweutilizeinourexperiments.AlsoweuseA todenotecombinedattributes.
ALL
attributeofclassksuchaslabelfrequency,labelnoiseratio, [ω ,l ,∆ ]correspondtoaparticularrowofW ∈ R3×M
k k k
trainingdifficultyshowninTable1.TomodelA2H,onecan sinceW =[w ,w ,w ]⊤.OurgoalisthentuningtheW
ω l ∆
useanyhypothesisspaceincludingdeepnets.However,since matrixovervalidationdata.Inpracticalimplementation,we
A2Hwillbeoptimizedoverthevalidationloss,dependingon defineafeaturedictionary
theapplicationscenario,itisoftenpreferabletouseasimpler
linearizedmodel. D =[F(A 1) ··· F(A K)]⊤ ∈RK×M. (2)
Linearizedapproach.Supposeeachclasshasnattributes
Each row of this dictionary is the features associated to
withA k ∈ Rn.WewilluseanonlinearfeaturemapF(·) : the attributes of class k. We generate the strategy vectors
Rn → RM whereM istheembeddingspace.Supposethe ∆,l,ω ∈ RK (for all classes) via ω = Dw , ∆ =
c tel ra is zs e- dsp be yci afi wc est igra ht teg my atS rik x∈ WRs ∈.T Rh se ×n M,A s2 oH thc aa tnbeparame- sigmoid(√ K ∥DD ww ∆∆ ∥),l=Dw l. ω
Forbothlossfunctiondesignandpost-hocoptimization,
S =A2H(A ):=WF(A ). (1) weuseadecomposablefeaturemapF.Concretely,suppose
k k k
wehavebasisfunctions(F )m .Thesefunctionsarechosen
OurgoalbecomesfindingW sothattheresultingstrategies i i=1
to be poly-logarithms or polynomials inspired by (Menon
maximizethetargetvalidationobjective.ObservethatW has
etal.2020;Yeetal.2020).ForithattributeA [i] ∈ R,we
s×M parametersratherthans×K parameterswhichisthe k
generateF(A [i])∈Rmobtainedbyapplying(F )m .We
naiveapproachthatlearnsindividualstrategies.Inpractice, k i i=1
thenstitchthemtogethertoobtaintheoverallfeaturevector
K canbesignificantlylarge,sofortypicalproblems,M ≪
F(A )=[F(A [1])⊤ ··· F(A [m])⊤]∈RM:=m×n.We
K. Moreover, W ties all classes together during training k k k
emphasizethatpriorapproachesarespecialinstanceswhere
throughweight-sharingwhereasthenaiveapproachwould
wechooseasinglebasisfunctionandsingleattributeπ .
bebrittlefortailclassesthatcontainverylimiteddata. k
Whichattributestouseandwhymultipleattributeshelp?
3.2 CAPforLossFunctionDesign Attributesshouldbechosentoreflecttheheterogeneityacross
individualclasses.Theseincludeclassfrequency,difficulty
Considerthegeneralizedcross-entropyloss
of prediction, noise level and more. We list such potential
ℓ(y,f(x))=ω ylog(1+(cid:88) elk−ly ·e∆kfk(x)−∆yfy(x)). attributesAinTable1.ThefrequencyA FREQ iswidelyused
tomitigatelabelimbalance,andA isinspiredbytheim-
k̸=y NORM
balancedlearningliterature(Caoetal.2019).However,these
Here,(ω ,l ,∆ )K arehyperparametersthatcanbetuned maynotfullycapturetheheterogenousnatureoftheproblem.
k k k k=1
tooptimizethedesiredtestobjective.Forclassk,wegetto As discussed above for GMMs (Fig 2), some classes can
choose the tuple S := [ω ,l ,∆ ] which can be consid- bemoredifficulttolearnandrequiremoreupweightingde-
k k k k
eredasitstrainingstrategy.HereelementsofS arisefrom spitecontainingsufficienttrainingexamples.Thismotivates
k
existingimbalance-awarestrategies,namelyweightingω , the use of A . Moreover, rather than balanced accuracy,
k DIFF
additive logit-adjustment l and multiplicative adjustment wemaywishtooptimizegeneraltestobjectivesincluding
k
∆ . weighted accuracy with varying class importance. We can
k
Example: LA and CDT losses viewed as CAP. For label declarethesetest-timeweightsasanattributeA .Ap-
WEIGHTS
imbalanced problems, (Menon et al. 2020; Ye et al. 2020) pendix provides theoretical justification for incorporating
propose to set hyperparameters l and ∆ as a function A by showing CAP can accomplish Bayes optimal
k k WEIGHTS
of frequency π = P(y = k). Concretely, they propose logitadjustmentforweightederror.Morebroadly,anyclass-
k
l = −γlog(π ) (Menon et al. 2020) and ∆ = πγ (Ye specificmeta-featurecanbeusedasanattributewithinCAP.
k k k k
etal.2020)forsomescalarγ.Thesecanbeviewedasspecial Reducedsearchspaceandincreasedstability.Searching
instancesofCAPwherewehaveasingleattributeA =π land∆onRK withveryfewvalidationsamplesraisesthe
k k
andA2H(x)is−γlog(x)orxγ respectively. problemofunstableoptimization.(Lietal.2021)indicates
Our approach can be viewed as an extension of these to thebileveloptimizationisbrittleandhardtooptimize.They
attributes beyond frequency and general class of A2H. In introducealongwarm-upphaseandaggregateclasseswith
lightof(1),hyperparametersofaspecificelementofS = similarfrequencyintog groups,reducingthesearchspace
ktok/gdimensions.However,toachieveafine-grainedloss adjusts the output of f to minimize the fairness objective.
function,gcannotbeverylarge,sothesearchspaceremains Thusthefinalmodelofpost-hocoptimizationisg◦f(x).
large. In our method, with a good design of D (normally
n ≈ 2 and m ≈ 3), we can utilize a constant 2mn ≪ K 4 ExperimentsandMainResults
thatefficientlyreducesthesearchspaceandprovidesbetter
In this section, we present our experiments in the follow-
convergenceandstability.
ing way. Firstly, we demonstrate the performance of CAP
Weremarkthatdictionaryisageneralandefficientdesign
on both loss function design via bilevel optimization and
thatcanrecovermultipleexistingsuccessfulimbalancedloss
post-hoclogitadjustmentinSec.4.1.Sec.4.2demonstrates
functiondesignalgorithms.Forexample,(Menonetal.2020)
thatCAPprovidesnoticeableimprovementsforfairnessob-
and(Yeetal.2020)bothutilizethefrequencyasAandapply
jectivesbeyondbalancedaccuracy.ThenSec.4.3discusses
logarithm and polynomial functions as F on frequency to
theadvantageofutilizingattributesandhowCAPleverages
determineland∆respectively.Moreover,letA = I and
k
theminnoisy,long-taileddatasetsthroughperturbationex-
F beanidentityfunction,thentrainingw ,w isequivalent
l ∆
periments.Lastly,wedefertheexperimentdetailsincluding
totrainl,∆whichrecoversthealgorithmof(Lietal.2021).
hyper-parameters,numberoftrails,andotherreproducibility
Despitetheabilitytogeneralize,thedictionaryismoreflexi-
informationtoappendix.
bleandpowerfulsincetheattributescanbechosenbasedon
Dataset.Inlinewithpreviousresearch(Menonetal.2020;
thescenarios.Forexample,naturally,classfrequencyisacrit-
Yeetal.2020;Lietal.2021),weconducttheexperiments
icalcriterioninanimbalanceddataset,butclassificationerror
on CIFAR-LT and ImageNet-LT datasets. The CIFAR-LT
inearlytrainingcanalsobeagoodcriterionforevaluating
modifies the original CIFAR10 or CIFAR100 by reducing
classtrainingdifficulty.Furthermore,somespecificattributes
thenumberofsamplesintailclasses.Theimbalancefactor,
canbeintroducedtonoisyorpartial-labeleddatasetstohelp
representedasρ=N /N ,isdeterminedbythenum-
designabetterlossfunction.Ourempiricalstudyelucidates max min
ber of samples in the largest (N ) and smallest (N )
thebenefitofcombiningmultipleattributesandthedictionary max min
classes. To create a dataset with the imbalance factor, the
performanceonthenoisyimbalanceddataset.
samplesizedecreasesexponentiallyfromthefirsttothelast
3.3 Class-specificLearningStrategies:Bilevel class. We use ρ = 100 in all experiments, consistent with
OptimizationandPost-hocoptimization previous literature. The ImageNet-LT, a long-tail version
ofImageNet,has1000classeswithanimbalancedratioof
ToinstantiateCAPasameta-strategy,wefocusontwoim-
ρ = 256. The maximum and minimum samples per class
portantclass-specificoptimizationproblems:lossfunction
are 1280 and 5, respectively. During the search phase for
designviabileveloptimizationandpost-hoclogitadjustment.
bilevelCAP,wesplitthetrainingsetinto80%trainingand
Wedescribetheminthissectionanddemonstratethatboth
20% validation to obtain the optimal loss function design.
methodsoutperformthestate-of-the-artapproaches.Thefig-
We remark that the validation set is imbalanced, with tail
ureinAppendixillustrateshowCAPisimplementedunder
classescontainingveryfewsamples,makingitchallenging
bi-leveloptimizationandpost-hocoptimizationindetail.
tofindoptimalhyper-parameterswithoutoverfitting.Forall
•Strategy1:Lossfunctiondesignviabileveloptimization.
otherpost-hocexperiments(Sec.4.2and4.3),wefollowthe
Inspiredby(Lietal.2021)andfollowingourexpositionin
setupof(Menonetal.2020;Hardt,Price,andSrebro2016)
Section 3.1, we formalize the meta-strategy optimization
bytrainingamodelonentiretrainingdatasetasthepre-train
problemas
model,andoptimizingalogitadjustmentgonabalancedval-
min L (w ,w ,f) s.t. minL (w ,w ,f)
val l ∆ train l ∆ idationdataset.Additionally,allCIFAR-LTexperimentsuse
wl,w∆ f
ResNet-32(Heetal.2016),andImageNet-LTexperiments
wheref isthemodelandL ,L arevalidationandtrain-
val train useResNet-50.
inglossesrespectively.OurgoalisfindingCAPparameters
w ,w thatminimizethevalidationlosswhichisthetarget
l ∆ 4.1 CAPImprovesPriorMethodsUsingPost-hoc
fairnessobjective.Followingtheimplementationof(Lietal.
orBilevelOptimization
2021),wesplitthetrainingdatato80%trainingand20%val-
idationtooptimizeL andL .Theoptimizationprocess Thissectionpresentsourlossfunctiondesignexperimentson
train val
issplittotwophases:thesearchphasethatfindsCAPparam- imbalanceddatasetsbyincorporatingCAPintothetraining
etersw ,w andtheretrainingphasethatusestheoutcome schemeof(Lietal.2021;Menonetal.2020;Yeetal.2020),
l ∆
ofsearchandentiretrainingdatatoretrainthemodel.We asdiscussedinSec.3.3.Table2demonstratesourresults.The
notethat,duringinitialsearchphase,(Lietal.2021)employs firstpartdisplaystheoutcomesofvariousexistingmethods
alongwarm-upphasewheretheyonlytrainf whilefixing withtheiroptimalhyper-parameters.Itisworthnotingthat
w ,w toachievebetterstability.Incontrast,wefindthat the original best results for single-level methods ((Menon
l ∆
CAPeitherneedsveryshortwarm-upornowarm-upatall et al. 2020; Ye et al. 2020)) are obtained from grid search
pointingtoitsinherentstability. onthetestdataset,whichleadstomuchbetterperformance
•Strategy2:Post-hocoptimization.In(Menonetal.2020; thanourreproducedresultsusingvalidationgridsearchin
Feldmanetal.2015;Hardt,Price,andSrebro2016),theau- Table.2.Moreover,bothofthegridsearchmethodsdemand
thordisplaysthatthepost-hoclogitadjustmentcanefficiently substantial computation budgets. As illustrated in the sec-
addressthebiaswhentrainingwithimbalanceddatasets.For- ondpartofTable2,bilevelandpost-hocCAPsignificantly
mally,givenamodelf,apost-hocfunctiong : RK → RK improvethebalancederroracrossalldatasets.Method CIFAR10-LT CIFAR100-LT ImageNet-LT
Crossentropy 30.45(±0.49) 61.94(±0.28) 55.59(±0.26)
Logitadjustment(LA)(Menonetal.2020) 21.29†(±0.43) 58.21†(±0.31) 52.46♯
CDT(Yeetal.2020) 21.57†(±0.50) 58.38†(±0.33) 53.47♯
Plain (AutoBalance(Lietal.2021)) 21.15♯ 56.70♯ 50.91♯
Bilevel
CAP :A 20.22(±0.35) 56.38(±0.19) 49.31(±0.34)
Bilevel ALL
CAP :A 20.87(±0.38) 57.63(±0.26) 51.46(±0.20)
Post-hoc ALL
Table2:Balancederroronlong-taileddatausinglossfunctiondesignedviabileveloptimization.♯:bestreportedresultstaken
from(Lietal.2021).†:Reproducedresults.
20 15 70 Plain Plain Plain
LA 15 LA LA
CAP 10 CAP 60 CAP
10
50 5
5
40
0 0
0.00 0.25 0.50 0.75 0.00 0.25 0.50 0.75 15 20 25
a a Standarddeviation(Err SDev)
(a)Errorsofquantileclasses (b)Conditionalvalueoferrors (c)Aggregationoferrors
Figure3:BenefitofCAPforoptimizingdifferentFairnessObjectives.Wecompareamongplainpost-hoc,LApost-hocand
CAP .(a):ResultsofoptimizingquantileclassperformanceQuant = P[y ̸=yˆ (x)|y =K ],whereK denotesthe
post-hoc a f a a
class index with the worst ⌈K×a⌉-th error. (b): Results of optimizing tail performance CVaR . (c): Results of optimizing
a
R(Err)=λ·Err +(1−λ)·Err .Theplotshowsthetrade-offbetweenstandarddeviationofclass-conditionalerrors
plain SDev
Err andStandardmisclassificationerrorErr asλvaries.SeeSec.4.2fordetaileddefinitionanddiscussions.
SDev plain
4.2 BenefitsofCAPforOptimizingDistinct mizingtheCVaR tendtoimprovethetailbehaviorofthe
a
FairnessObjectives classifier,whichisamoregeneralfairnessobjective.Fig.3b
showsthetestimprovementsoverthreeapproaches,andCAP
Recentworksonlabel-imbalanceplacesasignificantempha-
isconsistentlybetterthanallothermethods.
sisonthebalancedaccuracyevaluations(Menonetal.2020;
Finally,forthecombinedriskR(Err),wedefineR(Err)=
Lietal.2021;Caoetal.2019).However,inpractice,thereare
λ·Err +(1−λ)·Err where Err is the regular
manydifferentfairnesscriteriaandbalancedaccuracyisonly plain SDev plain
classificationerrorandErr denotesthestandarddeviation
oneofthem.Infact,aswediscussin(3),wemightevenwant SDev
ofclassificationerrors.Weplottheerror-deviationcurveby
to optimize arbitrary weighted test objectives. In this sec-
varyingλfrom0to1withstepsize0.1onthreeapproachesin
tion,wedemonstratetheflexibilityandmeritsofCAPwhen
Fig.3c,eachpointcorrespondstoadifferentλ.Weobserve
optimizingfairnessobjectivesotherthanbalancedaccuracy.
thatplainpost-hoccannotachieveasmallstandarddeviation,
TheexperimentsareconductedontheCIFAR100-LTdataset
andpost-hocLAdegradeswhenachievingsmallerErr ,
usingthepost-hocapproaches.Forthefairnessobjectives,we SDev
CAP accomplish the best performance and are flexible to
mainlyfocusonthreeobjectives:quantileclasserrorQuant ,
a adapttodifferentobjectives.
conditionalvalueatrisk(CVaR)CVaR ,andthecombined
a
risk R(Err), which consists of standard deviation of error Whenusingplainpost-hoc(withoutCAP),eachclasspa-
andtheregularclassificationerror. rameterisupdatedindividually.Thus,optimizingforspecific
classes (e.g., Quant ) dramatically hurts the performance
We first demonstrate the performance on quantile class a
errorQuant =P[y ̸=yˆ (x)|y =K ],whereK denotes of other classes which are ignored. Confirming this, we
a f a a
theclassindexwiththeworst⌈K×a⌉-therror.Forinstance, foundthatoptimizingplainpost-hocisunstableanddoesnot
in CIFAR100-LT, where K = 100, Quant denotes the achievedecentresults.Ontheotherhand,whilepost-hocLA
0.2
outperformsplainpost-hoc,optimizingonlyonetemperature
test error of the worst 20 percentile class. That is, we sort
variablelacksfine-grainedadaptationtovariousobjectives.
theclassesindescendingorderoftesterrorandreturnthe
Incontrast,CAPachievesanoticeablybetterperformanceon
error of the class 20%th class ID. Thus, each selection of
a raises a new objective. Fig. 3a shows the improvement allobjectivesthankstoitsbestofbothworldsdesign.
over the pre-trained model when optimizing Quant
a
with Table3showsmoreresults.Err weighteddenotesaweighted
multipleselectionsofa.WeobservethatCAPsignificantly testobjectiveinducedbyweightsωtest ∈RK givenby
k
outperformsbothlogitadjustmentandplainpost-hoc.
CVaR =E[Err |Err >Quant ]measurestheaverage K K
errorof⌈a K×a⌉clak sseswk ithworstea rrors.InsteadofQuant a, Err weighted =(cid:88) ω ktestErr k where (cid:88) ω ktest =K. (3)
whichonlyfocusesonthespecificquantileclasserror,opti- k=1 k=1
tnemevorpmi
tnauQ a
tnemevorpmiaRaVC )
rrE(rorredradnatS
nialpPost-hocmethods Err Err CVaR Quant Err
bal SDev 0.2 0.2 weighted
Pretrained 61.94(±0.28) 27.13(±0.35) 96.95(±0.15) 93.01(±0.58) 62.53(±0.53)
Plain -1.62(±0.36) -8.51(±0.75) -11.48(±0.81) -12.79(±0.43) -2.82(±0.56)
Post-hoc
LA -3.73(±0.29) -8.72(±0.66) -12.21(±0.50) -15.01(±0.35) -3.62(±0.37)
Post-hoc
CAP -4.36(±0.25) -13.92(±0.24) -14.75(±0.87) -18.34(±0.47) -6.21(±0.49)
Post-hoc
Table3:Theerrordifferencebetweenotherapproachescomparedtopre-trainedmodel.Thefirstlineshowstheperformanceof
Pretrainedmodel,andthefollowinglineshowstheerrordifferenceofothermethods(smallerisbetter).Forobjectiveswitha,
weseta=0.2.Thisiscommonlyusedfordifficultorfewclassesinotherpapers(Zhaietal.2021;Liuetal.2019).
CIFAR100-LT ImageNet-LT CIFAR10-LT+Noise
Err Err Err Err Err Err
bal SDev bal SDev bal SDev
Crossentropy 61.94(±0.28) 27.13(±0.35) 55.59(±0.26) 29.10(±0.64) 43.76(±0.74) 31.69(±0.81)
Plain (AutoBalance(Lietal.2021)) 56.70(±0.32) 20.13(±0.68) 50.93(±0.16) 26.06(±0.61) 40.04(±0.79) 36.30(±0.89)
Bilevel
CAP :A 56.64(±0.21) 19.10(±0.67) 50.82(±0.13) 24.36(±0.49) 39.91(±0.66) 26.54(±0.80)
Bilevel FREQ
CAP :A 58.27(±0.24) 17.62(±0.65) 52.97(±0.30) 21.28(±0.58) 40.61(±0.61) 14.49(±0.72)
Bilevel DIFF
CAP :A +A 56.38(±0.19) 18.53(±0.63) 49.31(±0.34) 22.14(±0.46) 38.36(±0.79) 19.78(±0.75)
Bilevel FREQ DIFF
Table4:Attributeshelpoptimizationadapttodatasetheterogeneity.Weconductexperimentsusingbilevellossdesignandreport
thebalancedmisclassificationerror,andstandarddeviationofclass-conditionalerrorswithdifferentclass-specificattributes.
Overall,Table3showsthatCAPconsistentlyachievesthe portantly,CAPisparticularlyfavorabletotailclasseswhich
best results on multiple fairness objectives. An important containtoofewexamplestooptimizeindividually.Onlyus-
conclusionisthat,thebenefitofCAPismoresignificantfor ingA achievessmallestErr demonstratingthatopti-
DIFF SDev
objectivesbeyondbalancedaccuracyandimprovementsare mizationwithA tendstokeepbetterclass-wisefairness
DIFF
around2%ormore(comparedto(Menonetal.2020)orplain becauseA isdirectlyrelatedtoclasspredictability.The
DIFF
post-hoc).Thisisperhapsnaturalgiventhatpriorworksput combination of A and A shows that incorporating
FREQ DIFF
anoutsizedemphasisonbalancedaccuracyintheiralgorithm multiple class-specific attributes provides additional infor-
design(Menonetal.2020;Lietal.2021). mationaboutthedatasetandjointlyenhancesperformance.
Overall,theresultsindicatethatCAPestablishesaprincipled
4.3 BenefitsofCAPforAdaptingtoDistinctClass approachtoadapttomultiplekindsofheterogeneity.
Heterogeneities
5 Discussion
Continuing the discussion in Sec. 3.1, we investigate the
advantageofdifferentattributesinthecontextofdatasethet- WeproposedCAPasaflexiblemethodtotackleclasshetero-
erogeneity adoption. In Table 4, we conduct loss function geneitiesandgeneralfairnessobjectives.CAPachieveshigh
design CAP experiments on CIFAR-LT and ImageNet-LT performance by efficiently generating class-specific strate-
dataset. Specifically, besides using regular CIFAR100-LT giesbasedontheirattributes.Wepresentedstrongtheoretical
andImageNet-LT,weintroducelabelnoiseintoCIFAR10- andempiricalevidenceonthebenefitsofmultipleattributes.
LTfollowing(Tanakaetal.2018;Reedetal.2014)toextend Evaluationsonpost-hocoptimizationandlossfunctionde-
theheterogeneityofthedataset.Toaddthelabelnoise,firstly, signrevealedthatCAPsubstantiallyimprovesmultipletypes
wesplitthetrainingdatasetto80%trainand20%validation offairnessobjectivesaswellasgeneralweightedtestobjec-
to accommodate bilevel optimization. Then we randomly tives.InAppendixD,wealsodemonstratethetransferability
generateanoiseratior ∈ RK,r ∼ U(0,0.5)thatdenotes acrossourstrategies:Post-hocCAPcanbepluggedinasa
i
thelabelnoiseratioforeachclass.Finally,keepingtheval- lossfunctiontofurtherboostaccuracy.
idation set clean, we add label noise into the train set by Broaderimpacts.Althoughourapproachandapplications
randomlyflippingthelabelsofselectedtrainingsamples(ac- primarilyfocusonlossfunctiondesignandposthocoptimiza-
cordingtothenoiseratio)toallpossiblelabels.Asaresult, tion,CAPapproachcanalsohelpdesignclass-specificdata
allclassescontainanunknownfractionoflabelnoiseinthe augmentation,regularization,andoptimizers.Additionally,
noisyCIFAR10-LTdataset,whichraisesmoreheterogeneity rather than heterogeneities across classes, one can extend
andchallengeinoptimization.Throughbileveloptimization, CAP-stylepersonalizationtoproblemsinmulti-tasklearning
weoptimizethebalancedclassificationlossandreportthe andrecommendationsystems.Limitations.Withaccessto
balancedtesterroranditsstandarddeviationaftertheretrain- infinitedata,onecansearchforoptimalstrategiesforeach
ingphaseinTable4.AsshowninTable4,weemploylabel class.Thus,theprimarylimitationofCAPisitsmulti-taskde-
frequencyA whichisdesignedforsamplesizehetero- signspacethatsharesthesamemeta-strategyacrossclasses.
FREQ
geneityandA whichisdesignedforclasspredictability However,asexperimentsdemonstrate,inpracticalfinitedata
DIFF
as the attributes in CAP approach. Table 4 highlights that settings,CAPachievesbetterdataefficiency,robustness,and
CAPconsistentlyoutperformsothermethodswhiledifferent testperformancecomparedtoindividualtuning.
attributescanshapetheoptimizationprocessdifferently.Im-Acknowledgements He,K.;Zhang,X.;Ren,S.;andSun,J.2016. Deepresidual
ThisworkwassupportedbytheNSFgrantsCCF-2046816 learningforimagerecognition. InProceedingsoftheIEEE
andCCF-2212426,NSFCAREER1942700,NSERCDis-
conferenceoncomputervisionandpatternrecognition,770–
coveryGrantRGPIN-2021-03677,GoogleResearchScholar 778.
award,AdobeDataScienceResearchaward,andArmyRe- Hu, W.; Niu, G.; Sato, I.; and Sugiyama, M. 2018. Does
searchOfficegrantW911NF2110312. distributionallyrobustsupervisedlearninggiverobustclas-
sifiers? InInternationalConferenceonMachineLearning,
References 2029–2037.PMLR.
Kang,B.;Xie,S.;Rohrbach,M.;Yan,Z.;Gordo,A.;Feng,
Alabi,D.;Immorlica,N.;andKalai,A.2018. Unleashing
J.; and Kalantidis, Y. 2019. Decoupling representation
linearoptimizersforgroup-fairlearningandoptimization. In
ConferenceOnLearningTheory,2043–2066.PMLR. and classifier for long-tailed recognition. arXiv preprint
arXiv:1910.09217.
Alshammari, S.; Wang, Y.-X.; Ramanan, D.; and Kong, S.
Khan,S.H.;Hayat,M.;Bennamoun,M.;Sohel,F.A.;and
2022. Long-tailedrecognitionviaweightbalancing. InPro-
Togneri, R. 2017. Cost-sensitive learning of deep feature
ceedingsoftheIEEE/CVFConferenceonComputerVision
representationsfromimbalanceddata. IEEEtransactionson
andPatternRecognition,6897–6907.
neuralnetworksandlearningsystems,29(8):3573–3587.
Calmon,F.;Wei,D.;Vinzamuri,B.;NatesanRamamurthy,
Kim,B.;andKim,J.2020. Adjustingdecisionboundaryfor
K.;andVarshney,K.R.2017. Optimizedpre-processingfor
classimbalancedlearning. IEEEAccess,8:81674–81685.
discriminationprevention. Advancesinneuralinformation
processingsystems,30. Kini, G.; and Thrampoulidis, C. 2020. Analytic study of
doubledescentinbinaryclassification:Theimpactofloss.
Cao,K.;Wei,C.;Gaidon,A.;Arechiga,N.;andMa,T.2019.
arXivpreprintarXiv:2001.11572.
Learningimbalanceddatasetswithlabel-distribution-aware
Kini,G.R.;Paraskevas,O.;Oymak,S.;andThrampoulidis,
marginloss. arXivpreprintarXiv:1906.07413.
C. 2021. Label-Imbalanced and Group-Sensitive Classifi-
Chawla,N.V.;Bowyer,K.W.;Hall,L.O.;andKegelmeyer,
cationunderOverparameterization. acceptedtotheThirty-
W.P.2002. SMOTE:syntheticminorityover-samplingtech-
fifthConferenceonNeuralInformationProcessingSystems
nique. Journalofartificialintelligenceresearch,16:321–
(NeurIPS).
357.
Kleinberg,J.;Mullainathan,S.;andRaghavan,M.2016. In-
Chen,X.;andHe,K.2021. Exploringsimplesiameserep-
herenttrade-offsinthefairdeterminationofriskscores.arXiv
resentationlearning. InProceedingsoftheIEEE/CVFCon-
preprintarXiv:1609.05807.
ferenceonComputerVisionandPatternRecognition,15750–
Kubat, M.; Matwin, S.; et al. 1997. Addressing the curse
15758.
of imbalanced training sets: one-sided selection. In Icml,
Cui,Y.;Jia,M.;Lin,T.-Y.;Song,Y.;andBelongie,S.2019.
volume97,179–186.Citeseer.
Class-balancedlossbasedoneffectivenumberofsamples.
Lahoti,P.;Beutel,A.;Chen,J.;Lee,K.;Prost,F.;Thain,N.;
InProceedingsoftheIEEE/CVFConferenceonComputer
Wang,X.;andChi,E.2020. Fairnesswithoutdemograph-
VisionandPatternRecognition,9268–9277.
icsthroughadversariallyreweightedlearning. Advancesin
Deng, Z.; Kammoun, A.; and Thrampoulidis, C. 2019. A
neuralinformationprocessingsystems,33:728–740.
ModelofDoubleDescentforHigh-dimensionalBinaryLin-
Li,M.;Zhang,X.;Thrampoulidis,C.;Chen,J.;andOymak,
earClassification. arXivpreprintarXiv:1911.05822.
S. 2021. AutoBalance: Optimized Loss Functions for Im-
Duchi,J.C.;andNamkoong,H.2021. Learningmodelswith balancedData. InBeygelzimer,A.;Dauphin,Y.;Liang,P.;
uniformperformanceviadistributionallyrobustoptimization. andVaughan,J.W.,eds.,AdvancesinNeuralInformation
TheAnnalsofStatistics,49(3):1378–1406. ProcessingSystems.
Feldman,M.;Friedler,S.A.;Moeller,J.;Scheidegger,C.; Li, T.; Cao, P.; Yuan, Y.; Fan, L.; Yang, Y.; Feris, R. S.;
andVenkatasubramanian,S.2015. Certifyingandremoving Indyk, P.; and Katabi, D. 2022. Targeted supervised con-
disparateimpact. Inproceedingsofthe21thACMSIGKDD trastivelearningforlong-tailedrecognition. InProceedings
internationalconferenceonknowledgediscoveryanddata oftheIEEE/CVFConferenceonComputerVisionandPattern
mining,259–268. Recognition,6918–6928.
Feldman, V. 2020. Does learning require memorization? Liu,Z.;Miao,Z.;Zhan,X.;Wang,J.;Gong,B.;andYu,S.X.
a short tale about a long tail. In Proceedings of the 52nd 2019. Large-scalelong-tailedrecognitioninanopenworld.
AnnualACMSIGACTSymposiumonTheoryofComputing, InProceedingsoftheIEEE/CVFConferenceonComputer
954–959. VisionandPatternRecognition,2537–2546.
Hardt, M.; Price, E.; and Srebro, N. 2016. Equality Maldonado,S.;Vairetti,C.;Fernandez,A.;andHerrera,F.
of opportunity in supervised learning. arXiv preprint 2022. FW-SMOTE: A feature-weighted oversampling ap-
arXiv:1610.02413. proachforimbalancedclassification. PatternRecognition,
Hashimoto,T.;Srivastava,M.;Namkoong,H.;andLiang,P. 124:108511.
2018. Fairnesswithoutdemographicsinrepeatedlossmini- Menon,A.K.;Jayasumana,S.;Rawat,A.S.;Jain,H.;Veit,
mization. InInternationalConferenceonMachineLearning, A.;andKumar,S.2020. Long-taillearningvialogitadjust-
1929–1938.PMLR. ment. arXivpreprintarXiv:2007.07314.Michel, P.; Hashimoto, T.; and Neubig, G. 2021. Model- Learning with Long-Tailed Distributions. arXiv preprint
ingthesecondplayerindistributionallyrobustoptimization. arXiv:1912.04486.
arXivpreprintarXiv:2103.10282. Zhang, X.; Fang, Z.; Wen, Y.; Li, Z.; and Qiao, Y. 2017.
Montanari, A.; Ruan, F.; Sohn, Y.; and Yan, J. 2019. The Rangelossfordeepfacerecognitionwithlong-tailedtraining
generalizationerrorofmax-marginlinearclassifiers:High- data. InProceedingsoftheIEEEInternationalConference
dimensional asymptotics in the overparametrized regime. onComputerVision,5409–5418.
arXivpreprintarXiv:1911.01544. Zhang,Y.;Kang,B.;Hooi,B.;Yan,S.;andFeng,J.2023.
Morik,K.;Brockhausen,P.;andJoachims,T.1999. Com- Deeplong-tailedlearning:Asurvey. IEEETransactionson
biningstatisticallearningwithaknowledge-basedapproach: PatternAnalysisandMachineIntelligence.
acasestudyinintensivecaremonitoring. Technicalreport,
TechnicalReport.
Reed,S.;Lee,H.;Anguelov,D.;Szegedy,C.;Erhan,D.;and
Rabinovich,A.2014.Trainingdeepneuralnetworksonnoisy
labelswithbootstrapping. arXivpreprintarXiv:1412.6596.
Sagawa,S.;Koh,P.W.;Hashimoto,T.B.;andLiang,P.2019.
Distributionallyrobustneuralnetworksforgroupshifts:On
theimportanceofregularizationforworst-casegeneralization.
arXivpreprintarXiv:1911.08731.
Sagawa,S.;Raghunathan,A.;Koh,P.W.;andLiang,P.2020.
An investigation of why overparameterization exacerbates
spuriouscorrelations. InInternationalConferenceonMa-
chineLearning,8346–8356.PMLR.
Sahu, A. K.; Li, T.; Sanjabi, M.; Zaheer, M.; Talwalkar,
A.; and Smith, V. 2018. On the convergence of federated
optimization in heterogeneous networks. arXiv preprint
arXiv:1812.06127,3.
Tan,J.;Wang,C.;Li,B.;Li,Q.;Ouyang,W.;Yin,C.;and
Yan,J.2020. Equalizationlossforlong-tailedobjectrecog-
nition. InProceedingsoftheIEEE/CVFconferenceoncom-
putervisionandpatternrecognition,11662–11671.
Tanaka,D.;Ikami,D.;Yamasaki,T.;andAizawa,K.2018.
Jointoptimizationframeworkforlearningwithnoisylabels.
InProceedingsoftheIEEEconferenceoncomputervision
andpatternrecognition,5552–5560.
Wallace, B. C.; Small, K.; Brodley, C. E.; and Trikalinos,
T. A. 2011. Class imbalance, redux. In 2011 IEEE 11th
internationalconferenceondatamining,754–763.Ieee.
Williamson,R.;andMenon,A.2019. Fairnessriskmeasures.
In International Conference on Machine Learning, 6786–
6797.PMLR.
Xie, S.; Zheng, H.; Liu, C.; and Lin, L. 2018. SNAS:
stochastic neural architecture search. arXiv preprint
arXiv:1812.09926.
Ye,H.-J.;Chen,H.-Y.;Zhan,D.-C.;andChao,W.-L.2020.
Identifyingandcompensatingforfeaturedeviationinimbal-
anceddeeplearning. arXivpreprintarXiv:2001.01385.
Zafar, M. B.; Valera, I.; Gomez Rodriguez, M.; and Gum-
madi, K. P. 2017. Fairness beyond disparate treatment &
disparateimpact:Learningclassificationwithoutdisparate
mistreatment. InProceedingsofthe26thinternationalcon-
ferenceonworldwideweb,1171–1180.
Zhai,R.;Dan,C.;Suggala,A.;Kolter,J.Z.;andRavikumar,
P.2021. BoostedCVaRClassification. AdvancesinNeural
InformationProcessingSystems,34.
Zhang,J.;Liu,L.;Wang,P.;andShen,C.2019. ToBalance
or Not to Balance: A Simple-yet-Effective Approach forTrain dataset Feature dictionary Hyperparameter Train Test
dataset dataset
… 𝑀 𝐾
Attribute 𝐾s 𝑀 … 𝑠 … … … 𝐾 …… 𝑀 Bi- Post-
…
…………… …
…
𝑛 𝐾 …… … M≪𝐾 = 𝑠 … …… ⟹ level hoc Evaluate
A2H
Figure 4: The overview of CAP approach. CAP is the overall framework proposed in our paper, with A2H being the core
algorithm.A2Hisameta-strategythattransformstheclass-attributepriorknowledgeintohyper-parameterS foreachclass
throughatrainablematrixW,formingatrainingstrategythatsatisfiesthedesiredfairnessobjective.Thelefthalfofthefigure
specificallyillustrateshowouralgorithmcalculatesandtrainstheweights.Inthefirststage,wecollectclass-relatedinformation
andconstructanattributetableofn×K dimension.Thisisageneralprior,whichisrelatedtothedistributionoftrainingdata,
thetrainingdifficultyofeachclass,andotherfactors.Then,hefirststepofA2HistocomputeaK×M FeatureDictionary
D =F(A)byapplyingasetoffunctionsF.WeremarkthatM <<K andM isonlyrelatedtothenumberofattributesnand
|F|,makingitaconstant.Therefore,thesearchspaceisO(1).Then,inthesecondstep,theweightmatrixWistrainedthrough
bi-levelorpost-hocmethodstoconstructthehyperparameterS.
A Listoffairnessobjectives
Welistallthenotationofobjectivesweusedinthemainpaperinthissection.
Symbol Meaning
ℓ,f Lossfunction(specificallycross-entropy),predictor
Err(f) Erroroff onentirepopulation
Err Class-conditionalerroroff onclassK=k
k
Err Standardmisclassificationerror
plain
Err Balancedmisclassificationerror,averageofclass-conditionalerrors
bal
Err Weightedmisclassificationerror
weighted
Err Standarddeviationofclass-conditionalerrors
SDev
Quant Errorsofquantileclassesatlevela
a
CVaR Conditionalvalueoferrorsatlevela
a
R(Err) Aggregationofclass-conditionalerrors
B Frameworkoverview.
C ExtendedDiscussionofWarm-upandTrainingStability
InSec.3.2,wediscusshowCAPstabilizesthetrainingandeasesthenecessarilyofwarm-up.Now,weextendthediscussion
andprovidemoreexperimentstodemonstratefurtherthebenefitoftheCAPstrategyinthissection.InTable5,weconduct
experimentsonbilevellossfunctiondesignonCIFAR10-LT.Firstly,weinvestigatetheperformanceofthedefaultinitialization
(DI)ofPlain wherel=0and∆=1with100,120and200warm-upepochs.Thenweprovidetheresultwherelstarts
Bilevel
withlogitadjustmentprior.Finally,weimplementtheself-supervisionpre-trainedmodelbySimSiam(ChenandHe2021).
Table5presentstherelationshipbetweentheErr ofthepre-trainedmodelandthefinalErr afterbileveltraining.Onedirect
SDev bal
observationisthatErr highlycorrelateswithErr .ConsideringErr measuresthefairnessofthepre-trainedmodel,we
SDev bal SDev
believethatabetterpre-trainedmodelpromotesthetestperformanceaccordingly.
Moreover,regardingLAinitialization,onecanconcludethatinitializingthetrainingwithadesignedlosssuchasLAlosscan
significantlyimprovetheresult.Still,itrequiresadditionaleffortandexpertiseindesigningthatspecificloss,especiallywhenthe
fairnessobjectiveisnotonlybalancederrorandvariousheterogeneitiesexistinthedata.Whiletheself-supervisedpre-trained
modelachievesthebestErr andErr amongallmethods,trainingtheself-supervisionmodelrequiresalongtime.Our
SDev bal
proposedCAP ,whichutilizestheattributes,notonlyensurestotakeadvantageofpriorknowledgebutalsostabilizes
Bilevel
theoptimizationbysimultaneouslyupdatingweightsofallclassesthankstothedictionarydesign.CAP achieves20.16
Bilevel
Err onCIFAR10-LTand56.55Err onCIFAR100-LTwithonly5epochsofwarm-up,whichimprovesonbothcomputation
bal bal
efficiencyandtestperformance.
D Furtherpost-hocdiscussion
Connectiontopost-hocadjustmentTobetterunderstandthepotentialofCAPandtheconnectionbetweenlossfunctiondesign
andpost-hocadjustment,wedesignanexperimentwithresultsshowninTable6.Inthisexperiment,weusethesamedictionary,
splittheoriginaltrainingdatato80%trainand20%validation,andtrainamodelf usingregularcross-entropylossonthe80%
… … … … … …Train Dataset Train Dataset Test Dataset
20% Validation 80% Training
Network trained
Bi- Optimize 𝑾to Network trained 𝑾⋆ using optimal hyper-
level meet fairness using 𝑺=𝑾𝑫" parameter 𝑺∗ Fairness-focused
network
objectives.
Optimal 𝑾⋆by A2H Optimal model
Search phase Retrain phase Evaluation phase
Training Validation Transferring from Test Dataset
post-hoc to loss
function design
Post Network trained Optimize the post-hoc
-hoc without hyper- function gfor fairness Fairness-focused network
parameters objectives with post-hoc function
Optimal model Optimal g
Pre-train phase Post-hoc Evaluation phase
training phase
Figure5:CAPframeworkfordetailedimplementation.ThisfigureillustrateshowCAPisimplementedunderbi-leveloptimization
andpost-hocoptimization.Throughouttheentirefigure,theonlytrainableparametersareWandthenetwork(inthegreenbox).
Inthesearchphaseofbileveloptimization,wefirstconductan80-20%train-valsplit.Then,wetrainthenetworkwithparametric
lossfunctionforinneroptimizationon80%trainingdatasetandtrainWtoachievefairnessobjectiveforouteroptimizationon
20%validationdataset.Andinpost-hocimplementation,wefirsttrainthenetworkwithouthyperparametersonthetraining
datasetanddothepost-hocoptimizationonthevalidationset.Bothbilevelandpost-hocyieldoptimalfairnessweightW∗,for
bi-levelandpost-hoctransferring,weusetheoptimalW∗toretrainafairness-focusedmodelontheentiretrainingdataset.If
onlypost-hocadjustmentsareconducted,wedirectlymodifythepre-trainedmodel’slogitwithapost-hocfunction.
DI,100epoch DI,120epoch DI,200epoch LA,120epoch Self-sup(ChenandHe2021)
Err whensearchphasebegin 0.23 0.20 0.28 0.17 0.13
SDev
Err 24.58 21.39 23.36 21.15 20.57
bal
Table5:Bileveltrainingwithdifferentwarm-upleadtodifferentresultonCIFAR10-LT.Weinvestigatetheperformanceofthe
defaultinitialization(DI)ofPlain wherel=0and∆=1with100,120and200warm-upepochs,andwealsoprovide
bilevel
theresultwherelstartswithlogitadjustmentprior.Weimplementtheself-supervisionpre-trainedmodelbySimSiam(Chenand
He2021).Weremarkthat120epochsWarm-upwithDIorLAlossareusedin(Lietal.2021).
trainsetasthepre-trainedmodel,whichisbiasedtowardtheimbalanceddistribution.Ourgoalistofindapost-hocadjustmentg
sothatg◦f achievesminimumbalancedlossonthe20%validationset.InTable6,thesearchingphasedisplaysthetesterrorof
adjustedmodelg◦f.FollowingthetransferabilitydiscussioninSec.3.3,weusethesearchedpost-hocadjustmentastheloss
functiondesigntoretrainthemodelfromscratchontheentiretrainingdataset.Interestingly,retrainingfurtherimprovesthe
post-hocperformance.Aspost-hocadjustmentrequiresonlyabout1/5ofthetimeandfewercomputationalresourcesthanloss
functiondesign,itprovidesasimpleandefficientapproachforlossfunctiondesign.
Wealsoobservethattrainingw alongwithw leadstoperformancedegradationcomparedtoonlytrainingw ,andtraining
l ∆ l
onlyw alsoperformsworsethanw .Weconductmoreexperimentsandprovideexplanationsforthis.Ineachpartofthe
∆ l
Table6,wecomparetheperformanceofoptimizingland∆inthesimilarsetup,forexample,LAprovidesadesignoflwhile
CDTadjuststhelossbydesignaspecific∆.Amongallthemethods,optimizinglorw alwaysachievethebestresult.We
l
observeadegenerationwhenoptimizingonly∆orbothl&∆.Throughthissection,Fig.6and7exhibitsomeinsightsand
intuitionstowardsthisphenomenon.
Fig.6showsthelogitsvaluebeforeandafterpost-hocadjustment.Withoutproperearly-stoppingorregularization,∆in
Fig.6cwillkeepincreasingandresultinastretchedlogitsdistribution,wherethelogitsbecomelargerandlarger.Notethat
Fig 6c stops after 500 epochs, but longer training will even further enlarge the logits. Furthermore, because the data is not
linearseparable,∆mayreducethelossinunexpectedways.ThemismatchbetweentestlossandbalancedtesterrorinFig.7b
verifiedthisconjecture.Thelossdecreasesattheendofthetrainingwhilethebalancederrorincreases.Thatmighthappen
because∆performsamultiplicativeupdateonlogitsasshowninFig.6c.Finally,thelogitsvaluebecomesmuchlarger,but
theimprovementislimited.Lemma1inpaper(Lietal.2021)alsoofferspossibleexplanationbyprovinglossfunctionisnot
consistentforstandardorbalancederrorsiftherearedistinctmultiplicativeadjustmentsi.e.∆ ̸=∆ forsomei,j ∈[K].
i jCIFAR10-LT CIFAR100-LT
searchphase retrain searchphase retrain
Post-hocLA(Menonetal.2020) 21.43(±0.30) 22.34(±0.34) 58.48(±0.23) 57.65(±0.25)
Post-hocCDT(Yeetal.2020) 23.58(±0.37) 21.79(±0.40) 58.60(±0.26) 57.86(±0.27)
l 20.90(±0.28) 21.71(±0.29) 57.98(±0.22) 57.82(±0.19)
Plain ∆ 23.74(±0.34) 24.06(±0.36) 58.61(±0.29) 58.80(±0.31)
Post-hoc
l&∆ 23.41(±0.30) 23.38(±0.33) 57.80(±0.24) 58.57(±0.23)
w 20.81(±0.15) 20.65(±0.36) 57.73(±0.25) 57.15(±0.30)
l
CAP w 22.31(±0.38) 21.06(±0.43) 58.07(±0.32) 57.26(±0.35)
Post-hoc ∆
w &w 20.87(±0.38) 20.32(±0.64) 57.63(±0.26) 57.08(±0.21)
l ∆
Table6:Balancederroronlong-taileddatausingpost-hoclogitsadjustment.Thesearchphaseresultsrevealthetestaccuracyof
post-hocadjustment,whichissearchedona20%validationset.Theretrainresultsshowthetransferabilityfrompost-hoclogits
adjustmenttolossfunctiondesign.
Decisionboundary Decisionboundary Decisionboundary
Majoritylogitsvalue(f y=0(x)) Majoritylogitsvalue(f y=0(x)) Majoritylogitsvalue(f y=0(x))
(a)Pretrain (b)CAP :w (c)CAP :w
Post-hoc l Post-hoc ∆
Figure6:Theevolutionoflogitsinpost-hoclogitsadjustmentCAPwhenoptimizingw andw individually.Inthisexperiment,
l ∆
wetrainaResNet-32asthepre-trainedmodelonCIFAR10-LT,wheretheclassy =0hasthelargestsamplesizeandy =9
hasthesmallestsamplesizewhentraining.InFig.6a,weplotthelogitsvalueftest(x)oftestdataset.Specifically,forbetter
y
visualizationandunderstanding,weonlypicktwoclasses,thelargestclass(y =0)asmajorityandthesmallestclass(y =9)
asminority.Thex-axisisthelogitvalueofmajorityclassf (x)andthey-axisisthelogitvalueofminorityclassf (x).
y=0 y=9
Thus,theblueline(y =x)canbetreatedasthedecisionboundarybetweenthetwoclasses.InFig.6bshowsthelogitsafter
CAP withonlyoptimizingw andFig.6bshowsthelogitsafterCAP thatonlyoptimizingw .Forclarification,the
Post-hoc l Post-hoc ∆
logitsaredirectlypickedfromCIFAR10-LTclassificationproblemwhicharenotbinaryclassificationlogits.Wealsoremark
thatanychoiceofmajorityandminoritythatsatisfiesNtrain >Ntrain showsthesimilarresultevenunderanothertraining
majority minority
distributiondifferedfromCIFAR10-LT(e.g.flippingtheminorityandmajority).
Insum,themaindifferencebetweenusingthetwodifferenthyperparametersforpost-hoclogitadjustmentisthatlperforms
anadditiveupdateonlogits,however,∆performsamultiplicativeupdate.Thatwillleadstodifferentbehaviors.Forexample,
ifthereisatruebutrarelabelk =iwithnegativelogitsvalueo ;meanwhile,thereareotherlabelswithpositiveornegative
i
values,multiplicativeupdateusing∆couldn’thelplabelkchangestheclassbecausethelogitsisalreadynegative.Forpost-hoc
logitadjustmentusingl,itcaneliminatetheinfluenceoftheoriginalvalue.Smallervaluesofl couldalwaysmakeoˆ =o −l
i i i i
havealargerboostthanoˆ Fig.6indeedshowsthatthereexistmanysampleslikethis.
k̸=i
E ProofsofFisherConsistencyonWeightedLoss
FormoreinsightoftheweightedtestlosswediscussedinSec.4.3,(Menonetal.2020)proposesafamilyofFisherconsistent
pairwisemarginlossas
(cid:88)
ℓ(y,f(x))=α y·log[1+ e∆ yy′ ·ef y′(x)−fy(x)]
y′̸=y
wherepairwiselabelmargins∆ denotesthedesiredgapbetweenscoresfory andy′.Logitadjustmentloss(Menonetal.
yy′
2020)correspondstothesituationwhereα = 1and∆ = logπ y′ whereπ = P(y).Theyestablishthetheoryshowing
y yy′ πy y
thatthereexistsafamilyofpairwiseloss,whichFisherconsistentwithbalancedlosswhen∆ =logα y′π y′ foranyα∈RK.
yy′ αyπy +
))x(
9=yf(eulavstigolytironiMEpoch Epoch
(a)CAP :w (b)CAP :w
Post-hoc l Post-hoc ∆
Figure7:TesterrorandlossduringCIFAR10-LTpost-hoctraining.InFig.7aweonlyoptimizew andweobservethatbalanced
l
testerrordecreaseswithtestlosssimultaneously.However,inFig.7bwhereweonlyoptimizew ,thetestloss(theorange
∆
curve)iskeepingdecreasing,buttestbalancederror(thebluecurve)firstreachesminimumandthenincreases.Thismismatch
togetherwithFig.6furtherexplainthereasonofdegenerationwhenoptimizew bypost-hoc.
∆
However,Sec.4.3focusesontheweightedlosswhichismoregeneralandformulatedasfollowing.
(cid:88)
ℓ ω(y,f(x))=α y·ω ytestlog[1+ e∆ yy′ ·ef y′(x)−fy(x)] (4)
y′̸=y
Following(Menonetal.2020),Thm.1deducesthefamilyofFisher-consistentlosswithweightedpairwiseloss.Thefollowed
discussiondemonstratesthatCAPusingA andA isabletorecoverFisher-consistentlossforanyωtest.
FREQ WEIGHTS
Theorem1. Foranyδ ∈RK,theweightedpairwiseloss(4)isFisherconsistentwithweightsandmargins
+
δ
α = y ∆ =log(δ′/δ )
y π yy′ y y
y
Proof. Supposeweusemargin∆ =logδ y′,theweightedlossbecome
yy′ δy
ℓ (y,f(x))=−ωtestlog
δ yefy(x)
ω y (cid:80) y′∈[K]δ y′ef y′(x)
efy(x)+log(δy)
=−ωtestlog
y (cid:80) ef y′(x)+log(δ y′)
y′∈[K]
LetP (y |x)∝ω P(y |x)denotethedistributionwithweightingω.TheBayes-optimalscoreoftheweightedpairwiseloss
ω y
willsatisfyf∗(x)+log(δ )=logP (y |x),whichisf∗(x)=logPω(y|x).
y y ω y δy
Supposewehaveagenericweightsα∈RK,theriskwithweightedlosscanbewrittenas
+
(cid:88)
E [ℓ (y,f(x))]= π ·E [α ℓ (y,f(x))]
x,y ω,α y x|y=y y ω
y∈[L]
(cid:88)
= π α ·E [ℓ (y,f(x))]
y y x|y=y ω
y∈[L]
(cid:88)
∝ π¯ ·E [ℓ (y,f(x))]
y x|y=y ω
y∈[L]
whereπ¯ ∝π α .Thatmeansbymodifythedistributionbasetoπ¯,learningwiththeωandαweightedloss4isequivalentto
y y y
learningwiththeωweightedloss.Undersuchadistribution,wehaveclass-conditionaldistribution.
P (x|y)·π¯ π¯ P (x)
P(y |x)= ω y =P (y |x)· y · ω ∝P (y |x)·α ωtest
P(x) ω π P(x) ω y y
y
Thenforanyδ ∈ RK,letα = δy,theBayes-optimalscorewillsatisfyf∗(x) = logP(y|x) = logPω(y|x) +C(x)where
+ πy y δy πy
C(x)doesnotdependony.Thus,argmax f∗(x)=argmax Pω(y|x),whichistheBayes-optimalpredictionforthe
y∈[L] y y∈[L] πy
weightederror.
rorredecnalaB
ssoL
rorredecnalaB
ssoLInconclusion,thereisaconsistentfamilyofweightedpairwiselossbychooseanysetofδ >0andletting
y
δ
α = y
y π
y
δ
∆ =log
y′
.
yy′
δ
y
Corollary1.1. InCAP,settingattributesas[A ,A ],F =[log(·)].Whenw =[1,−1],CAPfullyrecoversaloss(5),
FREQ WEIGHTS l
whichisFisher-consistentwithweightedpairwiseloss.
Proof. Thisresultcanbedirectlydeducedbysettingδ = πy .Wehave
y ωtest
y
π ωtest
α =1/ωtest and ∆ = y′ y
y y yy′ π ωtest
y y′
Thenthecorrespondinglogit-adjustedlosswhichisFisher-consistentwithweightedpairwiselossis
ℓ(y,f(x))=−α ωtestlog
δ y·efy(x)
=−log
efy(x)+logπy−logω ytest
. (5)
y y (cid:80) y′∈[L]δ
y′
·ef y′(x) (cid:80) y′∈[L]ef y′(x)+logπ y′−logω yte ′st
ForaforementionedCAPsetup,wehaveD=[log(π),log(ωtest)],sotheCAPadjustedlosswithw =[1,−1]is
y l
efy(x)+logπy−logω ytest
ℓ (y,f(x))=−log . (6)
CAP (cid:80) ef y′(x)+logπ y′−logω yte ′st
y′∈[L]
Whichisexactlythesameas5.
F MultipleAttributesBenefitAccuracyinGMM
Inthissection,wegiveasimpletheoreticaljustificationwhymultipleattributesactingsynergisticallycanfavoraccuracy.To
illustratethepoint,weconsiderabinaryGaussianmixturemodel(GMM),wheredatafromthetwoclassesaregeneratedas
follows:
(cid:26)
+1 ,withprob.π
y = and x|y ∼N(yµ,σ I ). (7)
−1 ,withprob.1−π y d
Noteherethatthetwoclassescanbeimbalanceddependingonthevalueofπ ∈(0,1),whichmodelsclassfrequency.Also,the
twoclassesareallowedtohavedifferentnoisevariancesσ .Thisisourmodelforthedifficultyattribute:examplesgenerated
±1
fromtheclasswithhighestvarianceare“moredifficult"toclassifyastheyfallfurtherapartfromtheirmean.Intuitively,a“good"
classifiershouldaccountforbothattributes.Weshowherethatthisisindeedthecaseforthemodelabove.
Oursettingisasfollows.LetnIIDsamples(x ,y )fromthedistributiondefinedin(7).Withoutlossofgenerality,assumeclass
i i
y =+1isminority,i.e.π <1/2.Wetrainlinearclassifier(w,b)bysolvingthefollowingcost-sensitivesupport-vector-machines
(CS-SVM)problem:
(cid:26)
δ y =+1
(wˆ ,ˆb ):=argmin∥w∥ sub.toy (xTw+b)≥ i . (8)
δ δ w,b 2 i i 1 y i =−1
Here,δisahyperparameterthatwhentakingvalueslargerthanone,itpushestheclassifiertowardsthemajority,thusgiving
largermargintotheminorities.Inparticular,settingδ =1recoversthevanillaSVM.ThereasonwhyCS-SVMisparticularly
relevanttooursettingisthatitrelatescloselytotheVS-loss.Specifically,(Kinietal.2021)showthatinlinearoverparameterized
(akad>n)settingstheVS-losswithmultiplicativeweights∆ 1leadstosameperformanceastheCS-SVMwithδ =∆ /∆ .
± + −
Finally,givenCS-SVMsolution(wˆ ,ˆb ),wemeasurebalancederrorasfollows:
δ δ
(cid:110) (cid:111)
R (δ):=P y(xTwˆ +ˆb )>0 .
bal (x,y)∼(7) δ δ
Weask:HowdoestheoptimalCS-SVMclassifier(i.e,theoptimalhyperparameterδ)dependonthedataattributes,i.e.on
thefrequencyπ andonthedifficultyσ /σ ?Toanswerthisweconsiderahigh-dimensionalasymptoticsettinginwhich
+1 −1
n,d → ∞atalinearrated/n =: d¯.Thisregimeisconvenientaspreviousworkhasshownthatthelimitingbehaviorofthe(a) (b)
Figure8:Theoptimalhyperparameterdependsonbothattributes:frequency(π)anddifficulty(σ /σ ).
+ −
balancederrorR (δ)canbecapturedpreciselybyanalyticformulas(Deng,Kammoun,andThrampoulidis2019;Montanari
bal
etal.2019).Specifically,(Kinietal.2021)usedthatanalysistocomputeformulasfortheoptimalhyperparameterδ.However,
theyonlydiscussedhowδvarieswiththefrequencyattributedandonlystudiedscenarioswherebothclassesareequallydifficult,
i.e.σ =σ .Ourideaistoextendtheirstudytoinvestigateapotentialsynergisticeffectoffrequencyanddifficulty.
+1 −1
Figure8confirmsourintuition:theoptimalhyperparameterδ dependsbothonthefrequencyandonthedifficulty.Specifically,
∗
weseeinbothFigures8(a,b)thattheeasiertheminorityclass(aka,thesmallerratioσ /σ ),δdecreases.Thatis,thereisless
+1 −1
needtofavormuchlargermargintotheminority.Ontheotherhand,asσ /σ increasesandminoritybecomesmoredifficult,
+1 −1
evenlargermarginisfavoredforit.Finally,comparingFigures8(a)toFigure8(b),notethatδ takeslargervaluesforlarger
∗
imbalanceratio(i.e.,smallerfrequencyπ),againaggreeingwithourintuition.
G Experimentdetailsandreproducibility
The functions are always fixed regardless of the datasets and objectives change F = [log(A),A,Aβ,A2β,A4β]. In our
experiments,wesetβ =0.075.
ForreproducedresultinTable2,wegridsearchonvalidationdatasetandretrainforfaircomparison,sotheresultisworse
thanthevaluereportedin(Menonetal.2020;Yeetal.2020)whicharegridsearchedonwholetestdataset.
Forbileveltraining,followingthetrainingprocessin(Lietal.2021),westartthevalidationoptimizationafter120epochs
warmup and training 300 epochs in total. The learning rate decays at epochs 220 and 260 by a factor 0.1. The lower-level
optimizationuseSGDwithaninitiallearningrate0.1,momentum0.9,andweightdecay1e−4,over300epochs.Atthesame
time,theupper-levelhyper-parameteroptimizationalsousesSGDwithaninitiallearningrate0.05,momentum0.9,andweight
decay1e−4.Togetbetterresults,weinitializelusingLAlossinexperimentsinTable2.Forafaircomparison,thereisno
initializationinotherexperiments.ForLAandCDTresultsinTable2,wedogridsearchontheimbalancedvalidationdataset
andretrainforafaircomparison.
Formostoftheexperiments,exceptErr inTable3,weplotorreporttheaverageresultof3runs.ForErr where
weighted weighted
thetargetweightαwasgeneratedrandomly,werepeattentimeswithdifferentrandomseeds.Wereporttheaverageresultof10
trailsofdifferentωtestforErr .Ateachtrial,weightsωtestaregeneratedi.i.d.fromtheuniformdistributionover[0,1]and
weighted k
thennormalized.
Alltheexperimentsarerunwith2GeForceRTX2080TiGPUs.