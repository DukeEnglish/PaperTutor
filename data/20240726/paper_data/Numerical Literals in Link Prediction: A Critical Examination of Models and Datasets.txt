Numerical Literals in Link Prediction: A Critical
Examination of Models and Datasets
Moritz Blum1[0000−0003−4924−3903], Basil Ell1,2[0000−0002−8863−3157], Hannes Ill,
and Philipp Cimiano1[0000−0002−4771−441X]
1 Bielefeld University, CITEC, Inspiration 1, 33619, Bielefeld, Germany
{mblum, bell, cimiano}@techfak.uni-bielefeld.de, hannes.ill@tum.de
2 University of Oslo, Problemveien 11, 0313 Oslo, Norway
basile@ifi.uio.no
Abstract. Link Prediction (LP) is an essential task over Knowledge
Graphs (KGs), traditionally focussed on using and predicting the re-
lations between entities. Textual entity descriptions have already been
showntobevaluable,butmodelsthatincorporatenumericalliteralshave
shownminorimprovementsonexistingbenchmarkdatasets.Itisunclear
whether a model is actually better in using numerical literals, or better
capable of utilizing the graph structure. This raises doubts about the
effectiveness of these methods and about the suitability of the existing
benchmark datasets.
We propose a methodology to evaluate LP models that incorporate nu-
merical literals. We propose i) a new synthetic dataset to better un-
derstand how well these models use numerical literals and ii) dataset
ablations strategies to investigate potential difficulties with the exist-
ing datasets. We identify a prevalent trend: many models underutilize
literalinformationandpotentiallyrelyonadditionalparametersforper-
formancegains.Ourinvestigationhighlightstheneedformoreextensive
evaluations when releasing new models and datasets.
Keywords: Link Prediction · Numerical Literals · Evaluation.
1 Introduction
Knowledge Graphs (KGs) store information in a graph-structured form as sets
of relational triples (i.e., triples with a relation that connects two entities) and
attributive triples (i.e., triples with a relation that annotates an entity with lit-
eral information). Prominent KGs are Freebase [5] and Wikidata [28]. A small
exampleKGisshowninFig.1.KGshaveemergedasamethodtorepresentand
store knowledge in various domains and applications, and will, as the authors
believe, play an important role in generative AI as they complement LLMs for
Retrieval Augmented Generation [16]. Nevertheless, KGs are inherently incom-
pleteforvariousreasons[7].Inthepast,effortshavebeenmadetodevelopLink
Prediction (LP) methods to predict missing triples based on the triples already
available.
4202
luJ
52
]GL.sc[
1v14281.7042:viXra2 Blum et al.
isa
?isa
height
324meter
Fig.1: Example KG about the Eiffel Tower. The KG contains the entities Eiffel
Tower, Tourist Attraction, and Observation Tower; and the literal value 324
meter: the height of the Eiffel Tower.
MostLPapproachesfocusonrelationaltriples,i.e.,onlyuserelationaltriples
to predict missing relational triples. Neither do these models make use of at-
tributive triples when predicting relational triples, nor do these models predict
attributive triples – these models ignore information encoded in literals that
might be valuable. In the example shown in Fig. 1, a model should predict the
is a relation between Eiffel Tower and Observation Tower. Ideally, a model has
learned from the data that a Tourist Attraction that has a certain height (e.g.,
above some threshold) is an Observation Tower. Here, a model needs to incor-
porate information expressed by the relational triple (Eiffel Tower, is a, Tourist
Attraction) and information expressed by the attributive triple (Eiffel Tower,
height, 324 meter) to predict the missing triple.
To incorporate literals, specialized models [30,34] or extensions of models
were proposed [3,8,13,24,31]. Most models only operate on one, and only some
on multiple types of literals. Even though some models are technically able to
predict literal values (e.g. [17,31,32]), we focus on the more prominent task of
incorporating literals into the prediction of relational triples. Language Mod-
els (LMs) that operate on textual entity descriptions recently set state-of-the-
art performance for LP [20]. The inclusion of numerical literals has shown only
small improvements in models that do not use literals on common benchmark
datasets[13,31].However,weassumethatnumericalliteralsarehighlyvaluable,
especially for scientific KGs about physical experiments [4] or manufacturing
processes [23], which store a large amount of information as numerical data. We
focus on numerical literals as there is a lack of research on how well LP models
that were designed to be able to use numerical literals can and do make use of
numerical literals.
Typically, when new models or model extensions that can incorporate liter-
als are published, then they are compared to state-of-the-art models that can
incorporate numerical literals and to the base model they extend by standard
metrics like Mean Reciprocal Rank (MRR) on benchmark datasets. As the im-
provements through incorporating literals is minor, we can not be sure whether
themodelsareusingtheattributivetriples,orwhethertheattributivetriplesin
the existing datasets are valuable.Numerical Literals in LP: A Critical Examination of Models and Datasets 3
The benchmark datasets that contain literals are often created by enriching
standard LP datasets, e.g., FB15k-237 or YAGO3-10, with literal information
from their larger source KGs. These datasets might not be perfectly suited for
the evaluation of LP models that incorporate literals, as, e.g., a certain amount
of attributive triples in FB15k-237 connect entities to identifiers (IDs) for other
databases that are not exploitable by a model.3 Here, we only point to the
IDrelations,butotherattributivetriplesmightalsonotbevaluable.Something
similarmightbethecaseformostofthesedatasets.Tothebestofourknowledge,
no published evaluation has proven that the numerical literals in these datasets
provide information relevant for LP. Therefore, we can not investigate whether
theliteralsareusedbythemodels,makingthemnotsuitableforbenchmarking.
Overall, research on LP with numerical literals lacks a detailed evaluation of
and comparison with the existing models and lacks insights on the used bench-
mark datasets. Therefore, we present the following contributions: i) We propose
methodtoextendadatasetwithrelationalandattributivetriples,wherethepre-
dictionofrelationaltriplesofthatkindcanonlythenbecarriedoutsuccessfully
ifamodelmakesuseoftheattributivetriples.ii)Weproposeablationstrategies
for the existing evaluation datasets to investigate whether the numerical literals
provide any additional knowledge, or whether the numerical literals only add
information already contained in the relational triples. iii) We evaluate existing
LP models which state to incorporate numerical literals on our semi-synthetic
benchmark dataset and on datasets that we obtained by applying our ablation
strategies to existing benchmark datasets, to gain insights into the models ca-
pabilities to incorporate literals and to gain insights into the suitability and
difficulty of the existing datasets.
2 Preliminaries
With G we denote a directed labeled multi-graph with numerical literals. G is
a set of triples (s,p,o) ∈ U ×U ×(U ∪R), where U, and R are disjoint sets of
URIsandnumericalvalues.4 Thesetoftriplescanbecategorizedintorelational
triples G and attributive triples G :
E A
G ={(s,p,o) | ∃(s,p,o)∈G s.t. o∈U}
E
G ={(s,p,v) | ∃(s,p,v)∈G s.t. v ∈R}
A
3 Tab. 3 in App. A shows that for FB15k-237, 3/10 of the triples related to the most
frequentattributiverelationsholdsuchIDs,overall6.9%ofallattributivetriplesin
the dataset.
4 Although typically KGs contain various types of literals, such as string literals or
date literals, here we focus only on numerical literals and we do not distinguish
between different types of numerical literals such as integer and float.4 Blum et al.
The set of entities E ⊆ U, the set of entity relations R ⊆ U, and the set of
E
attributive relations R ⊆U are defined as follows:
A
E ={x | ∃(s,p,o)∈G s.t. x=s∨(x=o∧o∈U)}
R ={p | ∃(s,p,o)∈G }
E E
R ={p | ∃(s,p,v)∈G }
A A
2.1 Link Prediction Models
LP models are trained to predict missing triples using triples already available.
Traditional Link Prediction Models Traditional LP models can be consid-
eredasafunctionf thatassignsascoref(⃗s,p⃗,⃗o)∈Rtoeachtriple(s,p,o)where
s,p,o∈U and⃗edenotestheembeddingoftheentitye.Thesemodelsaretrained
toscoretruetriples(i.e.,triplesinG )higherthanfalsetriples(i.e.,triplesnot
E
inG ).Notably,theconventionalLPmodelsdonotincorporateliterals.Popular
E
models are TransE [6], DistMult [33], ComplEx [27], and TuckER [2].
Link Prediction Approaches Incorporating Numerical Literals Some
LP models that are able to incorporate numerical literals are extensions of tra-
ditional LP models. These models use a feature vector ⃗x for each entity e∈E.
e
Each dimension of the feature vector ⃗x corresponds to a relation r ∈R . The
e A
value for a dimension is randomly selected from {v | ∃(e,r,v)∈G } or is set to
A
"0", when the entity e has no value for the relation r in G .5 These models can
A
be categorized into two types.
Fusion via a modification of the scoring function Suchmodelsusethenumerical
features ⃗x as (additional) input features, i.e., they modify the scoring func-
e
tion explicitly. We investigate two established approaches: i) LiteralE [13], by
Kristiadietal.,extendstraditionalLPmodelsbyaddingalearnableparametric
gatefunctiong(⃗e,⃗x )toobtainaliteral-enrichedentityembeddingthatreplaces
e
the initial embedding in the scoring function. This makes LiteralE universally
combinable with most existing embedding methods. In this paper, we evalu-
ate LiteralE and LiteralE . ii) KBLN [8] is a reduced variant of
DistMult ComplEx
KBLRNbyGarcía-Duránetal.KBLRNisaproductofexpertsmodelthatcom-
binesrelational(vectorsthatdescribeinwhichgraphpatternsanentityoccurs),
latent (entity and relation embeddings), and numerical literal features. KBLN
leaves out the expert for relational information.
5 Replacing non-existing features with "0" can be considered critical as "0" might
also be a valid literal value. Established methods like, e.g., LiteralE, make this
abstraction.Toensurenonegativeeffect,wecomputedtheproportionof"0" literal
valuesintheuseddatasetswhichismarginallysmall:FB15k-2370.006%,YAGO3-10
0%, LitWD48K 1.67%.Numerical Literals in LP: A Critical Examination of Models and Datasets 5
Fusion via a modification of the objective function Such models learn to predict
numerical features jointly with the LP objective.6 Thereby, the entity embed-
dingsincorporateinformationfromboththegraphstructureandnumericalliter-
als. In this paper, we investigate two established approaches: i) MTKGNN [25],
by Tay et al., introduces a neural network for numerical value regression in ad-
dition to a neural network for triple scoring. ii) TransEA [31], by Wu et al., is
an extension of TransE [6] that learns a set of functions g = {g | p ∈ R } for
p A
numerical value regression.
A different line of research investigates methods applied to the datasets in-
stead of the models.
Fusion via literal transformations Modelsthattransformattributivetriplesinto
relational triples allow traditional LP models to incorporate literal information
without modifying the scoring function or objective function. In this paper,
we investigate the following approaches considered state-of-the-art in LP with
numerical literals: KGA [29], by Wang et al., transforms numerical attributive
triplesintorelationaltriplesbydiscretizingnumericalvaluesintobins,andchain-
ing these bins, modeling multiple levels of granularity.
For a broader overview of literal-aware LP models, we refer to [10].
2.2 Datasets
Widely used LP datasets that contain numerical literals are: FB15k-237 [26],
YAGO3-10[15],andLitWD48K[9].Anextensiveoverviewaboutexistingdatasets
and their types of literals can be found in [9].
We briefly describe the datasets used in this paper. These datasets are pub-
licly accessible under CC-BY licenses. i) FB15k-237 is a subset of FB15k which
isasubsetofFreebase.Toutanovaetal.createdFB15k-237byremovinginverse
relations from FB15k that allowed even simple models to achieve high scores
by simply inverting triples [26]. We use the version of FB15k-237 that was ex-
tendedwithnumericalliteralasprovidedbyKristiadietal.[13].7 ii)YAGO3-10
isasubsetofYAGO3 [14]thatonlycontainstriplesassociatedwithentitiesthat
occurinatleasttenrelationsleadingmostlytotriplesrelatedtopeople.YAGO3-
10 does not contain literals, but they can be derived from YAGO3. Again, we
use the numerical literals provided by Kristiadi et al. iii) LiterallyWikidata [9]
comprises three datasets designed to evaluate LP models utilizing literal data,
sourcedfromWikidata andWikipedia.Thesedatasetsvaryinsizeandstructure;
we use the largest, LitWD48K.
Tab. 2 in App. A shows the general characteristics of the datasets used in
this paper.
6 Theliteralinformationisimplicitlyencodedintotheembeddingsandnotexplicitly
provided during inference.
7 See https://github.com/SmartDataAnalytics/LiteralE/tree/master/data.6 Blum et al.
2.3 Evaluation Metrics
The models are compared via the filtered mean rank (MR) metric, the mean
reciprocalrank(MRR)metric,andHits@kfork ∈{1,3,10},asproposedby[6].
For each triple in the test set, the subject and the object entities are corrupted
byreplacingthembyanye∈E.Thescoreforeachtripleisusedtorankthetest
triple among all of those triples by sorting in ascending order. Triples already
contained in the graph are removed before ranking, to not cause true triples to
increase the rank of the test triples.
TheMRisthemeanrank,theMRRisthemeanofthemultiplicativeinverse
of the ranks, and Hits@k is the proportion of ranks ≤k.
3 Related Work
To the best of our knowledge, no existing work focuses on a methodology for
evaluating LP models with numerical literals or other types of literals.
LP models are evaluated according to standard metrics such as MR and
MRR, following the evaluation protocol proposed by Bordes [6], where models
are treated as black-boxes. Safavi et al. raise concerns about the reliability of
theseranking-basedmetrics[19].Theypointoutthatwhilearankingmetricmay
suggestgoodperformancebecausethecorrecttripleisrankedhigh,itcouldstill
receive a lower score than an incorrectly top-ranked triple.
In-depth evaluations, e.g., analyzing particular relations or distinguishing
betweenheadandtailpredictions(asdonebyBordesetal.[6]),areuncommon.
SuchananalysiscanbeusefultoinvestigatehowspecificKGcharacteristicscan
be learned by a model, e.g., if symmetric relations can be properly represented
by the model.
ExplainabilitymethodscouldprovideinsightsintothebehaviorofLPmodels.
Whereas rule-based approaches [12] and explainers over graph neural network-
based approaches [35,36] can offer explanations for model predictions, particu-
larly shallow models like TransE or DistMult are difficult to explain. Ismaeil et
al. generate interpretable vectors for entity embeddings [11]. They employ em-
bedded feature selection techniques to extract propositional features from the
KG that are important for a given KG embedding model.
Another way to gain insights into the specific behavior and capabilities of
LP models is to build datasets in a way such that obtaining good LP results
requires the models to have specific capabilities, thus these datasets enable to
test to what extent a model has these capabilities. E.g., recent work stated a
lackofevaluationdatasetscoveringcertainKGpropertieslikeagivenentitytype
system, pairs of mutually inverse relations, or mediator objects to represent n-
ary relationships. Shirvani-Mahdavi et al. evaluate these properties on a newly
proposed version of the Freebase KG [22].
TheoutlinedopenchallengeofevaluatingandexplainingtraditionalLPmod-
elswithoutconsideringliteralsresultsinascarcityofresearchontheevaluation
and explainability of LP with literals.Numerical Literals in LP: A Critical Examination of Models and Datasets 7
AlthoughtheoriginalreleasesofexistingLPdatasetssuchasFB15k-237and
YAGO3-10 lack attributive triples, they have been extended with textual and
numericalattributessourcedfromtheirrespectiveKGs.However,theseenriched
datasets contain numerous entities without numerical attributes,8 and the pro-
vided numerical attributes are not proven to be helpful for LP, as, e.g., 6.9%
of the attributive triples in FB15k-237 hold IDs. Consequently, Gesese et al.
introduced a series of LP datasets called LiterallyWikidata, constructed from
Wikidata and Wikipedia, specifically for LP involving numerical and textual
literals [9]. The graph structure of LiterallyWikidata was designed for bench-
marking LP models, avoiding issues such as that inverse relations could leak
information or the existence of any shortcut features.
Despite the existence of datasets tailored for LP tasks involving (numerical)
literals,thesedatasetsarederivedfromrealKGs,makingitchallengingtoaccu-
rately assess the true advantages of integrating (numerical) literal information.
The most related work is García-Durán et al.’s input feature ablation study,
which investigated which graph structure features improved their model’s per-
formance [8].
4 Methodology
Wei)proposeamethodtoenrichanexistingdatasetwithsyntheticinformation
thatenablesustofindoutifnumericalliteral-awaremodelsarecapableofusing
numerical literals to make predictions about relational triples. Furthermore, ii)
we develop a set of ablation methods to gain further insights into the existing
literal-awaredatasets,whetherinsomedatasetsattributivetriplesmightnotbe
used for LP, or whether information is represented redundantly as attributive
and relational triples.
When elucidating the derivable conclusions from the following ablation ex-
periments, we denote a model trained on the dataset D as m(D) and define
σ(m(D)) as the result of evaluating m(D) according to some measure of perfor-
mance σ (such that a higher value indicates better performance).
4.1 Semi-Synthetic LP Dataset with Literals
To ensure attributive triples to be relevant, we propose a dataset extension
methodology with the intention to introduce a new learning goal given by a
function h into the dataset.
For simplicity, we restrict h to be a function that predicts a relation r
syn−r
from an existing entity e to one of two classes added to the dataset, namely
c and c , based on the attributive triple (e,r ,v). More precisely, our
high low syn−a
function h is defined as:
(cid:40)
(e,r ,c ) if ∃(e,r ,v)∈G′ with v >0.5
syn-r high syn-a
h(e)=
(e,r ,c ) if ∃(e,r ,v)∈G′ with v ≤0.5
syn-r low syn-a
8 See Tab. 2 in App. A8 Blum et al.
?isa
... ...
isa isa
value value value
324meter 368meter 21meter
Fig.2:Exampleofthesyntheticdatasetenrichment.TheentititesHigh-rise and
Low-rise represent c and c and is a is used as the r relation. Ide-
high low syn−a
ally, an LP model predicts the tail entity High-rise for the given head Berliner
Fernsehturm and the is a relation.
To remove any noise from the original G , we replace it by G′ defined as
A A
{(e,r ,v) | e∈E′} where v∼Uniform(0,1) and E′ ⊆E. We then apply h to
syn−a
every e∈E′ to obtain relational triples that are added to G′ . The new dataset
E
is defined as G′ =G′ ∪G′ . An example is shown in Fig. 2.
E A
Notethatthefunctionhcouldbemorecomplex,takingintoaccountmultiple
relational and attributive triples, make use of more than the one target relation
r and the two target entities c and c , and realize something more
syn−r high low
complex than comparing a value against a threshold value.
Let E and E be defined as follows: E := {e ∈ E′ | ∃(e,r ,v) ∈
high low high syn−a
G′ ∧v >0.5} and E :={e∈E′ | ∃(e,r ,v)∈G′ ∧v ≤0.5}. (Note that
A low syn−a A
E =E ∪E and E ∩E =∅.)
high low high low
Our goal is to measure the models’ ability to score the synthetic relational
triples according to h. As this is a binary classification task, we define the accu-
racy, denoted by Acc, as follows:
true +true
Acc:= high low (1)
|E |+|E |
high low
where true is the number of e ∈ E for which r(e,r ,c ) ≥
high heigh syn−a high
r(e,r ,c ). true is defined analogously.
syn−a low low
We consider the following situations where we can derive conclusions:
i)ifσ(m(G ∪G′ ))<σ(m(G ∪G )),i.e.,themodelthathasnoaccesstothe
E A E A
original attributive triples performs worse, then the attributive triples are used
for the prediction;
ii) ifσ(m(G ∪G′ ))≥σ(m(G ∪G )), i.e., bothmodelsperform equallywell,
E A E A
or the model that used the random features performs better, then the model is
not capable of making use of literals.
4.2 Literal Features Ablation
Ifamodelhasproventoincorporateliteralsfromasyntheticdatasetintothepre-
diction, this model should be evaluated on the established benchmark datasets.Numerical Literals in LP: A Critical Examination of Models and Datasets 9
To gain insights into the performance increase by using literals, one has to com-
pare models that use literals against the same model without access to literals.
For some models, e.g., MTKGNN, we cannot remove the attributive triples
fromthedataset,asthesemodelsdirectlyoperateonthenumericalfeaturesonly,
and do not learn a separate entity embedding. For other models, e.g., LiteralE,
removing the attributive triples from the dataset reduces the number of model
parameters.
Therefore, we propose an ablation method where each entity is related with
each attributive relation to a certain value. Given G = G ∪ G , we create
E A
G′ = G ∪G′ where G′ is created as follows: for each entity e ∈ E and each
E A A
relation p ∈ R , we add the triple (e,p,v) to G′ where v is a certain literal
A A
value we assign.
Assomemodelsonlyoperateonnumericalfeatures,assigningthesamevalue
to all attributive triples would lead to identical features for all entities. Conse-
quently,suchmodelswouldlosetheabilitytodistinguishtheentities.Therefore,
we propose to sample v randomly from Uniform(0,1).
We consider the following situations where we can derive conclusions about
a model and a dataset, under the assumption that the model can make use of
literalsaccordingtotheexperimentsofthemodelonthesemi-syntheticdataset:
i) if σ(m(G ∪G′ )) < σ(m(G ∪G )), i.e., the model that has no access to
E A E A
the original attributive triples performs worse, then the attributive triples are
relevant for the prediction task;
ii) ifσ(m(G ∪G′ ))≥σ(m(G ∪G )), i.e., bothmodelsperform equallywell,
E A E A
or the model that used the random features performs better, then, either the
information represented via attributive triples is redundantly represented via
relational triples, the literal information is difficult to use by the models, or no
information relevant for LP is represented via attributive triples.
4.3 Relational Features Ablation
The previous experiments may leave open whether attributive triples are not
relevant for the prediction task, challenging to leverage, or whether information
is represented redundantly as relational and attributive triples. To gain insights
into the redundancy of relational and attributive triples for a given dataset, we
proposeanablationmethodthattargetsrelationalattributes,thusmodifiesG .
E
We reduce G to G s.t.
E E−α
1) |G |=(1−α)|G | where α∈[0,1] is a user-defined real value.
E−α E
2) ∀e∈E :(∃p,o:(e,p,o)∈G )∨(∃s,p:(s,p,o)∈G )
E−α E−α
3) ∀p∈R :(∃s,o:(s,p,o)∈G )
E E−α
Thismeans,weremoverelationaltriplesfromGuntil|G |=(1−α)|G |.
E−α E
We ensure that there remains at least one triple per entity e ∈ E and relation
p ∈ R such that embeddings are learned. Note that for some G and α ∈ R+
E E
it can be the case that there is no G that satisfies both constraints. Thus,
E−α
there is a limit to how much G can be reduced.
E
We consider the following situations where we can derive conclusions:10 Blum et al.
i) if with the reduced set of relational triples the random feature ablation has
an effect on model performance (i.e., σ(m(G ∪G ))≫σ(m(G ∪G′ ))),
E−α A E−α A
then that means that information is represented redundantly as attributive and
relationaltriplesandthatattributivetriplesarerelevantforthepredictiontask;
ii)ifwiththereducedsetofrelationaltriplestherandomfeatureablationhasstill
noeffectonthemodelperformance(i.e.,σ(m(G ∪G ))≈σ(m(G ∪G′ ))),
E−α A E−α A
then attributive triples are either difficult to incorporate or not relevant for the
prediction task.
5 Experimental Setup
We apply our methodology to all numerical literal-aware models mentioned
in [10] and the state-of-the-art model KG [29].
Implementation WerunourexperimentswithLiteralE ,LiteralE ,
DistMult ComplEx
KBLN, and MTKGNN with the code of Kristiadi et al. [13].9
We implemented TransEA in PyTorch Geometric10 due to the absence of a
public implementation.
We decided to use the model variants that achieve the overall best perfor-
mance and the model that shows the largest performance gains through incor-
porating literals, which are KGA and KGA according to [29].11
TuckER DistMult
All hyperparameters are reported in App. B. We ran all experiments three
times and computed mean and standard deviation for each metric.
Semi-Synthetic FB15k-237 We apply our dataset enrichment method to the
FB15k-237 dataset. We decided that E is the set of entities of type person.
FB15k-237 contains 4,505 entities of type person, i.e. ≈30% of the entities.12
For evaluation, we create a training, validation, and test split as follows: we
add 70% of the new synthetic relational triples to the original train set, 15% to
the original validation set, and 15% to the original test set. The new synthetic
literal values replace the original literal values. The models are trained for LP
as usual.
9 See https://github.com/SmartDataAnalytics/LiteralE.
10 See https://pytorch-geometric.readthedocs.io. We extended the existing
TransE implementation to TransEA.
11 TheKGAtransformationsapproximatelycreateasmanyadditionalrelationaltriples
as attributive triples. As our proposed attributive features ablation creates a large
numberofliteralswithrandomvalues,thenumberofrelationaltriplesincreasessig-
nificantly.Consequently,wehadtolimitthenumberofattributiverelations.Instead
of relating each entity with each attributive relation, we only replace the numerical
values of attributive triples in the original dataset by a random value. Thereby, the
modelisprovidedwithsomeliteralinformation,i.e.,theexistenceoftheattributive
relation.
12 By assigning numerical literals only to certain entities, we enable further analysis,
such as determining if the model learns that only certain entities have a specific
literal.Numerical Literals in LP: A Critical Examination of Models and Datasets 11
Computing Resources Our evaluation required numerous experiments, due to
the combinations of investigated models and datasets. We used 10 A100 GPUs
for two weeks. The evaluated models have similar sizes, e.g., Literale
DistMult
trained on FB15k-237 has ≈3M parameters.
6 Results
6.1 Synthetic LP dataset with literals
We created a semi-synthetic FB15-237 dataset and used it to investigate the
models’ ability to utilize the necessary numerical literal information for pre-
dicting relational triples. The results are shown in Tab. 1. The accuracy for all
models is shown in the column Acc . A score slightly above 0.5 suggests that
org
the models’ performance is only marginally better than random guess, and a
score closeto 1suggests thatthe modelis capable ofmaking correctpredictions
by using the numerical literals.
As a baseline, we train the models with random features following the intro-
duced literal features ablation method, which we applied after the creation of
the semi-synthetic dataset. Acc is the score of the models when the literals
rand
provide no information, forcing the models to guess randomly.
The variance across runs is small; hence, these values indicate a measure of
reliable performance.
The KGA models are capable of using the provided numerical literals for
their prediction as they achieve Acc ’s of 0.999, both. The Acc scores
org rand
range from 0.482 to 0.510, proving the models’ random guessing. Note that due
totherandomnessofthefeatures,themodelscannotmakeajustifiedprediction.
TheAcc scoresachievedbytheothermodelsaremuchlowerandinthesame
org
range as the Acc scores’, showing that these models do not or do only to a
rand
small extent use the information provided via literals.
Model Acc Acc
org rand
LiteralE
DistMult
0.512±0.003 0.482±0.001
LiteralE
ComplEx
0.493±0.005 0.498±0.020
KBLN 0.482±0.009 0.493±0.005
MTKGNN 0.472±0.006 0.495±0.009
TransEA 0.489±0.022 0.496±0.020
KGA
TuckER
0.999±0.000 0.510±0.007
KGA
DistMult
0.999±0.000 0.487±0.011
Table 1: Scores achieved on the synthetic dataset. Acc denotes the Acc score
org
achieved on the synthetic dataset when we provide the meaningful synthetic
literal values, whereas Acc denotes the Acc score on the synthetic dataset if
rand
we apply the random feature ablation after the dataset creation.12 Blum et al.
LiteralEDistMult TransEA KGATuckER
0.315 0.205 0.3250
0.310 0.200 0.3225
org rand org rand org rand
0.48 0.0850 0.50
0.47
0.0825 0.49
org rand org rand org rand
0.335
0.200 0.40
0.330
0.195
0.325 0.38
org rand org rand org rand
Fig.3: MRR scores over three runs for models and datasets that either include
the original literal features or that include random literal features.
6.2 Literal Features Ablation
The results for our experiments for the random literal features ablation method
are visualized for three models in Fig. 3 as box plots, showing the mean and
variance of the MRR scores across three runs. For each combination of model
and dataset, the plot shows two boxes. The first box shows the score achieved
bythemodeltrainedwiththeoriginalliteralfeaturesandthesecondboxshows
the score achieved by the model trained on the random features.13
In general, as shown in Fig 3, replacing original features by random features
has no significant negative impact on most of the models as the box for the
original features and the box for the random features overlap in many cases and
the differences are very small. The detailed reported in App. C, shows that in 9
of the 21 cases we see the models with random literals outperform the models
that use real literals regarding the MRR score, and only in 10 of the 15 cases
models showed a benefit regarding the MRR score in using the real attributive
triples provided by the datasets. The Hits@k scores follow this trend. When
lookingattheMRscores,thistrendexists,too.TheKGAmodelsshowthebest
usageofliteralsasthepredictionswiththeoriginalfeaturesarebetter,butonly
marginally, than with the random features for all combinations of KGA models
and datasets investigated, except for KGA on the YAGO3-10 dataset.
DistMult
13 The box-plots for all experiments and the scores of all computed metrics for these
experiments are in App. C.
732-k51BF
01-3OGAY
k84DWtiLNumerical Literals in LP: A Critical Examination of Models and Datasets 13
0.3 org
rand
0.2
0 -10% -20% -30% -40% -50% -60% -70% -80% -90%
mod. of GR
Fig.4: KGA ’s MRR scores (mean and variance over three runs) after
TuckER
removing x% relational triples from FB15k-237. The model is provided either
with the original or with random numerical features. The variance is marginally
small and not visually recognizable in the figure.
6.3 Relational Features Ablation
TheablationeffectofrelationaltriplesfromFB15k-237onKGA isshown
TuckER
in Fig. 4.14 We plot the mean and standard deviation of the MRR score while
reducing the amount of relational triples from 100% (representing the original
dataset) to 10% (equivalent to removing 90% of the relational triples) in steps
of 10%. As expected, the MRR score decreases significantly when reducing the
available relational triples, showing that important information is eliminated.
We compared these models against the ones we applied the random literal
feature ablation strategy on. The curves of the models on random features are
very close to the curves of the models on the original features, not showing any
advantages of the original features when reducing the relational triples.
7 Discussion
The synthetic dataset creates a scenario where numerical literals are necessary
for predictions. KGA converts these continuous literals into discrete entities,
allowing models to bypass the need to incorporate the concrete literal values.
Thereby, KGA translates the task created by our semi-synthetic dataset into a
moresimplegraph-structurelearningtask,15 butmightstrugglewithmorecom-
plex synthetic datasets. The other models behaved similar to random guessing,
as the scores are close to 0.5. We assume that these model’s objective function
does not enforce the models to integrate numerical information valuable for LP
into the entity embeddings. Even though TransEA forces the embeddings to
containinformationtoreconstructthenumericalliterals,thisinformationisnot
necessarily valuable for LP.
14 Plots for further models are contained in App. C.
15 Entitieswithsimilarliteralsobtainsimilarembeddingsasentitieswithsimilarliterals
are connected to the same bins.
RRM14 Blum et al.
Even though we proposed our synthetic dataset to overcome a certain issue
with the existing real-world benchmark datasets, we, nevertheless, believe that
real-worlddatasetsarerelevant.Therefore,wealsoevaluatedallmodelsonthese
datasets and compared the scores to the scores of their random feature variant
to confirm the previous results.
One would expect significant performance drops after applying the random
feature ablation methods. We do not observe any significant performance drop,
and in some cases even an improvement. Interestingly, the KGA models do only
show small benefits of using numerical literals even though they showed good
performances on our synthetic dataset. This brings us to the conclusion that
either the models are not capable of making use of literals, or the literals are
not relevant for the prediction task, or the information contained in attributive
triplesisdifficulttouse,ortheinformationrepresentedviatheattributivetriples
is redundantly represented via relational triples.
We are not sure about the reason for the increase in performance after in-
troducing random literals. Possibly, in some cases unintentionally good features
are created which can be used by the models. A similar increase in performance
through random node initialization has been observed by Abboud et al. for
GNNs, which gain additional expressivity in the neighborhood encoding from
random node initialization [1]. However, all models we investigated are shallow
models that do not perform any neighborhood encoding.
WehavetonotethatourscoresoftheLiteralEmodelsslightlydifferfromthe
onesreportedbyKristiadietal.[13],eventhoughweusedtheirimplementation
and hyperparameters. Interestingly, the base ComplEx model achieves higher
MRR and Hits@k scores than the LiteralE model on FB15k-237 in our
ComplEx
experiments. However, the similarity of the results from three runs confirm our
results’ reliability.
Lastly, we investigated if relational and attributive triples redundantly rep-
resent information, which leads to the LP performance to remain similar even
though numerical literals are incorporated. If the attributive triples were redun-
dant, one would expect the model with the real literal features to obtain less
worse results when ablating the relational triples than the one with the random
features, i.e., at some point the literal features should become important. As
Fig. 4 does not show any benefit of incorporating numerical literals when re-
ducing the amount of available relational triples, we conclude that either the
attributive triples are not relevant for the prediction task, or the information
contained in attributive triples is difficult to use by the models.
8 Conclusion & Future Work
In this work, we investigated the capability of LP models that incorporate nu-
merical literal information and the suitability of the corresponding benchmark
datasets. We propose a methodology to create semi-synthetic datasets and a
dataset ablation methodology.Numerical Literals in LP: A Critical Examination of Models and Datasets 15
With a semi-synthetic dataset we showed that many models underutilize
literal information, even in a setting where the numerical data is crucial for
the prediction. We showed that under the established evaluation schema, the
performance gains of many models can be attributed to the additional model
parameters rather than the models’s capabilities to exploit literals.
Future work could investigate real-world KGs regarding their suitability for
evaluatingnumericalLPmoredeeply.Additionally,developingmorechallenging
syntheticdatasetextensionsrequiringthecombinationofliteralinformationand
graphstructureforpredictingmissinglinkscouldoffervaluableinsightsintothe
potentially more advanced LP models proposed in the future.
9 Limitations
We see three limitations of our work:
i) Our synthetic dataset implements one simple learning goal that requires
the model to learn a threshold value to make correct predictions. This learning
goalissimpleanddoesnotprovideanyinformationaboutthemodelscapabilities
inunderstandingmorecomplexscenarios.Morecomplexlearninggoalscouldgo
beyond numerical literals and could also require to combine information from
numericalliteralsandrelationaltriples.However,wedidnotinvestigatecomplex
learninggoals,aswebelievethatifmodelsfailinsimplescenarios,theywillalso
fail in more complex ones.
ii) We did not find a model that consistently shows benefits from the nu-
merical literals provided by the existing benchmark datasets, not even in the
relational triples ablation scenario. Therefore, we can not make any conclusions
aboutthevalueoftheliteralsprovidedforthesedatasets.Thenumericalliterals
are either not relevant for the prediction task, or the information contained is
difficult to use by the existing models.
iii) We exclude the evaluation of Graph Neural Network models, such as
R-GCN [21], which have the ability to process numerical literals as node fea-
tures. This decision is based on the absence of published research specifically
advocating for these models’ application in LP with numerical literal data.
Ethical Statement
We address concerns related to the experimental design and the significance of
results of existing methods. Our objective is not to criticize the creators of the
models and datasets, but rather to assist the community by providing practical
guidance for future research.
Inthiswork,effortsaremadetointerpretandunderstandhowwell-established
models respond to changes in literal data. However, it is important to note that
explainability methods still encounter challenges in interpreting such models.
All datasets utilized in this research adhere to ethical standards and are
obtained from publicly available sources.16 Blum et al.
Supplemental Material Statement
Youcanfindalloursourcecode,datasets,trainingresultlogs,andvisualization
Jupyter Notebooks on GitHub.16
Acknowledgements
This work was supported by: the Ministry of Culture and Science of the State
of North Rhine-Westphalia (Germany) through SAIL, Grant No. NW21-059A;
theDeutscheForschungsgemeinschaft(DFG)throughthepriorityprogramRA-
TIO(SPP-1999),GrantNo.376059226;theResearchCouncilofNorwaythrough
its Centres of Excellence scheme, Integreat – Norwegian Centre for knowledge-
driven machine learning, project number 332645.
References
1. Abboud, R., Ceylan, İ.İ., Grohe, M., Lukasiewicz, T.: The Surprising Power of
Graph Neural Networks with Random Node Initialization. In: Proceedings of the
13th International Joint Conference on Artifical Intelligence (2021)
2. Balazevic, I., Allen, C., Hospedales, T.: TuckER: Tensor factorization for knowl-
edgegraphcompletion.In:Inui,K.,Jiang,J.,Ng,V.,Wan,X.(eds.)Proceedings
ofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingand
the9thInternationalJointConferenceonNaturalLanguageProcessing(EMNLP-
IJCNLP). pp. 5185–5194. Association for Computational Linguistics, Hong Kong,
China (Nov 2019)
3. Blum, M., Ell, B., Cimiano, P.: Exploring the impact of literal transformations
within Knowledge Graphs for Link Prediction. In: Proceedings of the 11th Inter-
national Joint Conference on Knowledge Graphs. p. 48–54. Association for Com-
puting Machinery (2023)
4. Blum, M., Ell, B., Cimiano, P.: Insights from an OTTR-centric ontology engi-
neering methodology. Proceedings of the 14th Workshop on Ontology Design and
Patterns (2023)
5. Bollacker,K.,Evans,C.,Paritosh,P.,Sturge,T.,Taylor,J.:Freebase:acollabora-
tivelycreatedgraphdatabaseforstructuringhumanknowledge.In:Proceedingsof
the ACM SIGMOD International Conference on Management of Data. pp. 1247–
1250 (2008)
6. Bordes,A.,Usunier,N.,Garcia-Duran,A.,Weston,J.,Yakhnenko,O.:Translating
embeddings for modeling multi-relational data. Advances in Neural Information
Processing Systems 26 (2013)
7. Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., Strohmann,
T., Sun, S., Zhang, W.: Knowledge vault: a web-scale approach to probabilistic
knowledge fusion. In: Proceedings of the 20th ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining. p. 601–610. Association for
Computing Machinery (2014)
16 See https://github.com/moritzblum/LiteralEvaluation.Numerical Literals in LP: A Critical Examination of Models and Datasets 17
8. García-Durán, A., Niepert, M.: KBlrn: End-to-End Learning of Knowledge Base
RepresentationswithLatent,Relational,andNumericalFeatures.In:Proceedings
oftheThirty-FourthConferenceonUncertaintyinArtificialIntelligence.pp.372–
381. AUAI Press (2018)
9. Gesese,G.A.,Alam,M.,Sack,H.:Literallywikidata-Abenchmarkforknowledge
graphcompletionusingliterals.In:Proceedingsofthe20thInternationalSemantic
Web Conference. pp. 511–527. Springer (2021)
10. Gesese,G.A.,Biswas,R.,Alam,M.,Sack,H.:Asurveyonknowledgegraphembed-
dingswithliterals:Whichmodellinksbetterliteral-ly?SemanticWeb12,617–647
(2021)
11. Ismaeil, Y., Stepanova, D., Tran, T.K., Blockeel, H.: FeaBI: A Feature Selection-
Based Framework for Interpreting KG Embeddings. In: Proceedings of the 22nd
International Semantic Web Conference. pp. 599–617. Springer (2023)
12. Khajeh Nassiri, A., Pernelle, N., Saïs, F.: REGNUM: Generating Logical Rules
with Numerical Predicates in Knowledge Graphs. In: Proceedings of the 22nd In-
ternational Semantic Web Conference. pp. 139–155. Springer (2023)
13. Kristiadi,A.,Khan,M.A.,Lukovnikov,D.,Lehmann,J.,Fischer,A.:Incorporating
literalsintoknowledgegraphembeddings.In:Proceedingsofthe18thInternational
Semantic Web Conference. pp. 347–363. Springer (2019)
14. Mahdisoltani, F., Biega, J., Suchanek, F.: YAGO3: A Knowledge Base from Mul-
tilingual Wikipedias. In: 7th biennial Conference on Innovative Data Systems Re-
search. CIDR Conference (2014)
15. Nickel,M.,Tresp,V.,Kriegel,H.P.:FactorizingYAGO:scalablemachinelearning
for linked data. In: Proceedings of the 21st International Conference on World
Wide Web. pp. 271–280 (2012)
16. Pan,J.Z.,Razniewski,S.,Kalo,J.C.,,etal.:LargeLanguageModelsandKnowl-
edge Graphs: Opportunities and Challenges. Transactions on Graph Data and
Knowledge (2023)
17. Pezeshkpour, P., Chen, L., Singh, S.: Embedding Multimodal Relational Data for
KnowledgeBaseCompletion.In:ProceedingsoftheConferenceonEmpiricalMeth-
odsinNaturalLanguageProcessing.pp.3208–3218.AssociationforComputational
Linguistics (2018)
18. Ruffinelli,D.,Broscheit,S.,Gemulla,R.:You{can}teachanolddognewtricks!on
training knowledge graph embeddings. In: International Conference on Learning
Representations (2020)
19. Safavi, T., Koutra, D., Meij, E.: Evaluating the Calibration of Knowledge Graph
Embeddings for Trustworthy Link Prediction. In: Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language Processing. pp. 8308–8321.
Association for Computational Linguistics (2020)
20. Saxena, A., Kochsiek, A., Gemulla, R.: Sequence-to-sequence knowledge graph
completion and question answering. In: Proceedings of the 60th Annual Meeting
of the Association for Computational Linguistics (2022)
21. Schlichtkrull, M., Kipf, T.N., Bloem, P., van den Berg, R., Titov, I., Welling, M.:
Modeling Relational Data with Graph Convolutional Networks. In: The Semantic
Web. pp. 593–607. Springer (2018)
22. Shirvani-Mahdavi, N., Akrami, F., Saeef, M.S., Shi, X., Li, C.: Comprehensive
Analysis of Freebase and Dataset Creation for Robust Evaluation of Knowledge
GraphLinkPredictionModels.In:Proceedingsofthe22ndInternationalSemantic
Web Conference. pp. 113–133. Springer (2023)18 Blum et al.
23. Strötgen,J.,Tran,T.K.,Friedrich,A.,Milchevski,D.,Tomazic,F.,Marusczyk,A.,
Adel, H., Stepanova, D., Hildebrand, F., Kharlamov, E.: Towards the Bosch Ma-
terials Science Knowledge Base. In: Proceedings of the ISWC Satellite Tracks co-
located with 18th International Semantic Web Conference. pp. 323–324. Springer
(2019)
24. Tay, Y., Tuan, L.A., Phan, M.C., Hui, S.C.: Multi-Task Neural Network for Non-
discrete Attribute Prediction in Knowledge Graphs. In: Proceedings of the 2017
ACM on Conference on Information and Knowledge Management. p. 1029–1038.
Association for Computing Machinery (2017)
25. Tay, Y., Tuan, L.A., Phan, M.C., Hui, S.C.: Multi-Task Neural Network for Non-
discrete Attribute Prediction in Knowledge Graphs. In: Proceedings of the 2017
ACM on Conference on Information and Knowledge Management. p. 1029–1038.
Association for Computing Machinery (2017)
26. Toutanova, K., Chen, D.: Observed versus latent features for knowledge base and
text inference. In: Proceedings of the 3rd Workshop on Continuous Vector Space
ModelsandtheirCompositionality.pp.57–66.AssociationforComputationalLin-
guistics (2015)
27. Trouillon, T., Welbl, J., Riedel, S., Gaussier, É., Bouchard, G.: Complex Embed-
dings for Simple Link Prediction. In: International Conference on Machine Learn-
ing. pp. 2071–2080 (2016)
28. Vrandečić, D., Krötzsch, M.: Wikidata: a free collaborative knowledgebase. Com-
munications of the ACM 57, 78–85 (2014)
29. Wang, J., Ilievski, F., Szekely, P., Yao, K.T.: Augmenting knowledge graphs for
better link prediction. In: Raedt, L.D. (ed.) Proceedings of the Thirty-First In-
ternational Joint Conference on Artificial Intelligence, IJCAI-22. pp. 2277–2283.
International Joint Conferences on Artificial Intelligence Organization (7 2022),
main Track
30. Wang, L., Zhao, W., Wei, Z., Liu, J.: SimKGC: Simple Contrastive Knowledge
GraphCompletionwithPre-trainedLanguageModels.In:Proceedingsofthe60th
AnnualMeetingof theAssociation forComputationalLinguistics.pp.4281–4294.
Association for Computational Linguistics (2022)
31. Wu,Y.,Wang,Z.:KnowledgeGraphEmbeddingwithNumericAttributesofEnti-
ties.In:ProceedingsoftheThirdWorkshoponRepresentationLearningforNLP.
pp. 132–136. Association for Computational Linguistics (2018)
32. Xue,B.,Li,Y.,Zou,L.:IntroducingSemanticInformationforNumericalAttribute
Prediction over Knowledge Graphs. In: Proceedings of the 21st International Se-
mantic Web Conference. pp. 3–21. Springer (2022)
33. Yang,B.,Yih,S.W.t.,He,X.,Gao,J.,Deng,L.:EmbeddingEntitiesandRelations
forLearningandInferenceinKnowledgeBases.In:ProceedingsoftheInternational
Conference on Learning Representations (2015)
34. Yao, L., Mao, C., Luo, Y.: KG-BERT: BERT for knowledge graph completion.
arXiv preprint arXiv:1909.03193 (2019)
35. Ying, Z., Bourgeois, D., You, J., Zitnik, M., Leskovec, J.: GNNExplainer: Gener-
ating Explanations for Graph Neural Networks. Advances in Neural Information
Processing Systems 32 (2019)
36. Zhang, S., Zhang, J., Song, X., Adeshina, S., Zheng, D., Faloutsos, C., Sun, Y.:
PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous
Link Prediction. In: Proceedings of the ACM Web Conference. pp. 3784–3793
(2023)Numerical Literals in LP: A Critical Examination of Models and Datasets 19
A Dataset Statistics
Tab.2showsthestatisticsoftheevaluatedLPdatasetsFB15k-237,YAGO3-10k,
LitWD48K, and of our Synthetic dataset.
Dataset FB15k-237 YAGO3-10 LitWD48K Synthetic
# entities (|E|) 14,541 123,182 47,998 14,541
# relations (|R |) 237 37 257 237
E
# attributes (|R A|) 121 5
(*291)
246 1
# relational triples (|G |) 310,116 1,089,040 336,745 310,116
E
# attributive triples (|G A|) 70,257 111,406
(*324,418)
148,707 14,541
# entities w/o num. 4600 31,030 8,198 0
(*0)
# train 272,115 1,079,040 303,117 272,115
# test 17,535 5,000 16,838 17,535
# valid 20,466 5,000 16,838 20,466
Table 2: Dataset statistics. For LitWD48K, we only consider the attributive
triples of type xsd:decimal as described in Section 2.2. We show original num-
bers indicated by ∗ in front of the affected numbers.
In FB15k-237, 3/10 of the triples related to the most frequent attributive
relationsholdIDsforotherdatabases,overalldevotingto6.9%oftheattributive
triples in the dataset. Tab. 3 shows the 10 most frequent attributive relations in
FB15k-237.
Relation # triples
topic_server.population_number 52764
people.person.height_meters 2871
location.location.area 2166
film.film.netflix_id 1883
organization.organization.date_founded 844
user.robert.default_domain.rated_film.ew_rating 739
location.location.gnis_feature_id 645
sports.sports_team.founded 643
location.hud_county_place.countyplace_id 568
tv.tv_program.episode_running_time 493
Table 3: Ten most frequent attributive relations in FB15k-237. The original
relation URIs are http://rdf.freebase.com/ns/ + relation name.20 Blum et al.
B Hyperparameters
Weeitherusedthehyperparametersreportedasbestintheoriginalpublications,
orperformedahyperparameteroptimizationincasewere-implementedamodel.
We refrained from performing a new hyperparameter optimization for the
modelstrainedonourablateddatasets,asitiscommonpracticetousethesame
hyperparameters across multiple datasets [13,29]. Further, Ruffinelli et al. show
thattherelativeperformancedifferencebetweenvariousLPmodelarchitectures
oftenshrunkthroughhyperparameteroptimizationandre-implementationwhen
compared to prior results [18].
We use the following hyperparameters:
LiteralE , LiteralE ), KBLN, and MTKGNN We use the best
DistMult ComplEx
hyperparametersreportedintheoriginalpublicationtoensureafaircomparison:
embeddingdim.200,epochs100, learningrate0.001, batchsize 128,embedding
dropoutprob.0.2,andlabelsmoothing0.1.Thesamehyperparametersareused
across all models and datasets.
TransEA Wecarriedoutagrid-searchhyperparameteroptimization:embedding
dim.{50,100},learningrate{0.01,0.001},andα{0.1,0.2,...,0.9}.17 Thebest
hyperparametersarehighlighted.Further,weset:epochs500,andbatchsize128.
KGA WeusedtheQuantileHierarchyaugmentationmethod,whichshowedthe
best results across all models on FB15K-237 according to [29]. For KGA
TuckER
we use the hyperparameters: embedding dim. 200, epochs 500, learning rate
0.003, batch size 128, embedding dropout prob. 0.2, and hidden dropout 0.3.
For KGA we use additional label smoothing 0.1.
DistMult
All models are trained for LP as usual. We applied early stopping by moni-
toring the MRR score on the validation set every three epochs.
C Detailed Results
WereporttheMR,MRR,andHits@10scores(theirmeanandvariance)obtained
over three runs for models and datasets either including original features or
including random features in Tab. 4.
Furthermore, the effect of the relational triples ablation from FB15k-237 on
MTKGNN and LiteralE is shown in Fig. 5.
DistMult
D Further Ablation Experiments: Attributive Value
Feature
In order to provide further insights into the literal features of existing datasets,
weapplyanadditionalliteralablationmethodthatallowstoinvestigatewhether
17 We did not apply dropout or label smoothing, thereby following [31].Numerical Literals in LP: A Critical Examination of Models and Datasets 21
org
rand
0.2
0.1
0 -10% -20% -30% -40% -50% -60% -70% -80% -90%
mod. of GR
(a) MTKGNN
0.30 org
rand
0.25
0.20
0.15
0 -10% -20% -30% -40% -50% -60% -70% -80% -90%
mod. of GR
(b) LiteralE
DistMult
0.30
org
0.25 rand
0.20
0.15
0 -10% -20% -30% -40% -50% -60% -70% -80% -90%
mod. of GR
(c) KGA
DistMult
Fig.5: MRR score after removing some percentage of relational triples from
FB15k-237. The models are provided either with the original numerical features
or with random features. Mean score and variance are shown across three runs.
the concrete literal value is important, or whether only the existence of such an
attributeisimportant,orwhetheronlytheexistenceofanattributecanbetaken
into account by a model.
Therefore, we propose an ablation method that removes the concrete literal
values but adds literal values that indicate whether the attribute exists. Given
G=G ∪G , we create G′ =G ∪G′ where G′ is created as follows: if there
E A E A A
exists a value v such that (e,p,v)∈G , then we add the triple (e,p,1) to G′ .
A A
RRM
RRM
RRM22 Blum et al.
LitWD48k YAGO3-10 FB15k-237
features.
The
variance
is
marginally
small
and
not
visually
recognizable
in
the
figure.
Fig.6:
MRR
scores
obtained
over
three
runs
for
models
and
datasets
either
including
original
features
or
including
random
org
rand
org
rand
org
rand
org
rand
org
rand
org
rand
org
rand
0.26
0.225
0.2875
0.192
0.27
0.325
0.38
0.325
0.2900
0.194
0.250
0.28
0.196
0.275
0.330
0.2925
0.39
0.330
0.29
0.198
0.300
0.30
0.2950
0.335
0.200
0.40
0.325
0.335
0.31
0.2975
0.202
org
rand
org
rand
org
rand
org
rand
org
rand
org
rand
org
rand
0.082
0.474
0.46
0.43
0.4900
0.492
0.470
0.083
0.4925
0.476
0.47
0.44
0.494
0.475
0.478
0.48
0.45
0.084
0 0.
.4 49 95
70
5
0.496
0.480
0.480
0.49
0.46
0.085
0.5000
0.498
0.482
0.50
0.47
0.086
0.5025
org
rand
org
rand
org
rand
org
rand
org
rand
org
rand
org
rand
0.306
0.2825
0.272
0.281
0.303
0.308
0.2850
0.198
0.321
0.310
0.274
0.2875
0.282
0.200
0.322
0.304
0.276
0.2900
0.323
0.305
0.283
0.202
0.312
0.278
0.2925
0.324
0.306
0.314
0.2950
0.284
0.204
0.325
0.307
LiteralEDistMult
LiteralEComplEx
KBLN
MTKGNN
TransEA
KGATuckER
KGADistMultNumerical Literals in LP: A Critical Examination of Models and Datasets 23
Original features Random features
Model MR MRR Hits@1 MR MRR Hits@1
FB15k-237
LiteralE
DistMult
285±001 .310±.003 .224±.003 286±008 .313±.001 .229±.002
LiteralE
ComplEx
429±002 .272±.000 .193±.001 414±022 .278±.001 .198±.001
KBLN 486±004 .295±.000 .213±.001 618±007 .285±.002 .207±.003
MTKGNN 563±006 .282±.001 .202±.001 575±004 .282±.001 .202±.001
TransEA 303±002 .203±.002 .132±.002 305±001 .200±.003 .128±.002
KGA
TuckER
200±004 .324±.001 .234±.000 200±001 .322±.001 .231±.001
KGA
DistMult
372±007 .307±.001 .221±.002 389±004 .304±.001 .220±.002
YAGO3-10
LiteralE
DistMult
1860±018 .479±.003 .400±.004 1925±058 .470±.003 .388±.004
LiteralE
ComplEx
2086±034 .475±.002 .400±.002 2303±116 .480±.004 .408±.004
KBLN 2850±129 .485±.023 .405±.024 4243±057 .483±.001 .401±.001
MTKGNN 3287±048 .449±.017 .362±.016 3235±094 .467±.001 .379±.002
TransEA 2226±041 .084±.002 .048±.001 2325±055 .084±.001 .049±.001
KGA
TuckER
1046±003 .497±.004 .412±.005 1094±020 .492±.002 .407±.002
KGA
DistMult
1554±005 .495±.003 .407±.004 1696±071 .496±.002 .410±.004
LitWD48k
LiteralE
DistMult
886±060 .326±.003 .250±.003 875±041 .330±.004 .250±.001
LiteralE
ComplEx
1489±109 .268±.005 .200±.007 1358±067 .305±.005 .238±.003
KBLN 1741±042 .329±.004 .246±.004 1836±044 .334±.002 .262±.002
MTKGNN 3085±208 .289±.002 .227±.003 2743±137 .297±.001 .235±.001
TransEA 947±019 .197±.003 .131±.003 952±032 .195±.005 .129±.004
KGA
TuckER
353±010 .403±.001 .315±.001 395±007 .376±.001 .293±.001
KGA
DistMult
504±005 .335±.001 .250±.001 1422±094 .227±.004 .169±.003
Table 4: Comparison of scores of models trained on the datasets provided with
theoriginalliteralfeatureversusthosetrainedondatasetsprovidedwithrandom
features.
We evaluate the two models, KGA and KGA , which exhibit
TuckER DistMult
the highest benefits when provided with literals. Tab. 5 displays the scores of
these models on three datasets. The MRR scores show no consistent trend, but
theMRscoresareconsistentlyworseforthemodelsthatareprovidedonlywith
theexistenceofattributesofentitiescomparedtothoseprovidedwithoriginalor
random features. We hypothesize that the lower performance resulting from ab-
stractingtheconcreteliteralvaluesisduetothetransformationsthattransform
attributive triples into relational triples, which create a disadvantageous graph
structure where most entities are connected to the two entities representing the
literal values "0" and "1".24 Blum et al.
features MR MRR Hits@1 Hits@3 Hits@10
KGA
TuckER
original 200±004 .324±.001 .234±.000 .355±.002 .508±.001
random 200±001 .322±.001 .231±.001 .354±.000 .505±.001
relation type 217±002 .319±.001 .229±.001 .351±.001 .502±.001
KGA
DistMult
original 372±007 .307±.001 .221±.002 .336±.001 .478±.001
random 389±004 .304±.001 .220±.002 .333±.001 .472±.001
relation type 401±011 .303±.002 .218±.002 .333±.001 .474±.005
KGA
TuckER
original 1046±003 .497±.004 .412±.005 .546±.005 .651±.001
random 1094±020 .492±.002 .407±.002 .539±.002 .646±.002
relation type 1320±064 .521±.005 .439±.005 .570±.003 .671±.005
KGA
DistMult
original 1554±005 .495±.003 .407±.004 .543±.002 .661±.001
random 1696±071 .496±.002 .410±.004 .543±.002 .655±.002
relation type 1755±061 .509±.002 .423±.002 .559±.004 .668±.002
KGA
TuckER
original 353±010 .403±.001 .315±.001 .435±.002 .584±.000
random 395±007 .376±.001 .293±.001 .403±.002 .545±.002
relation type 672±013 .386±.001 .303±.001 .418±.000 .556±.001
KGA
DistMult
original 504±005 .335±.001 .250±.001 .360±.002 .513±.003
random 1422±094 .227±.004 .169±.003 .243±.005 .339±.006
relation type 786±015 .359±.001 .268±.001 .388±.002 .557±.003
Table5:Comparisonofmodelstrainedandevaluatedondatasets,eachsubjected
to all proposed literal ablations. The model that uses the literals provided with
the dataset is named original. The models that use only the relation type and
not the concrete literal value are are named relation type.
732-k51BF
01-3OGAY
k84DWtiL