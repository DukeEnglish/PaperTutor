Radio-astronomical Image Reconstruction with Conditional
ff
Denoising Di usion Model
M.Drozdova*1,V.Kinakh1,O.Bait2,O.Taran1,E.Lastufka1,M.Dessauges-Zavadsky2,T.
Holotyak1,D.Schaerer2,andS.Voloshynovskiy1
1DepartmentofComputerScience,UniversityofGeneva,7routedeDrize,1227Carouge,
Switzerland
2GenevaObservatory,UniversityofGeneva,51CheminPegasi,1290Versoix,Switzerland
February16,2024
Abstract
Reconstructingskymodelsfromdirtyradioimagesforaccuratesourceextraction,e.g. sourcelocalisationand
flux estimation, is a complex yet critical task. It has important applications in galaxy evolution studies at high
redshift, particularlyindeepextragalacticfieldsusingforexampletheAtacamaLargeMillimetreArray(ALMA).
With the development of large-scale projects like the Square Kilometre Array (SKA), we anticipate the need for
moreadvancedsourceextractionmethods. Existingtechniques,suchasCLEANandPyBDSF,currentlystruggleto
effectivelyextractfaintsources,highlightingthenecessityforthedevelopmentofmorepreciseandrobustmethods.
Thesuccessofsourceextractiontaskcriticallydependsonthequalityandaccuracyofimagereconstruction. Since
theimagingprocessrepresentsaninformation-lossyoperator,thereconstructionischaracterizedbyuncertainty.The
currentstudyproposestheapplicationofstochasticneuralnetworksforthedirectreconstructionofskymodelsfrom
dirtyimages. Thisapproachallowstolocalizeradiosourcesandtodeterminetheirfluxeswiththecorresponding
uncertainties, providinga potential advancementin thefield of radiosource characterization. Weutilize adataset
of 10164 images simulated with the CASA tool simalma based on the ALMA Cycle 5.3 antenna configuration.
WeapplyconditionalDenoisingDiffusionProbabilisticModels(DDPMs)todirectlyreconstructskymodelsfrom
these dirty images, followed by processing through Photutils to extract the coordinates and fluxes of the sources.
To test the robustness of the proposed model which was trained on a fixed water vapour value, we examine its
performanceundervaryinglevelsofwatervapor. Theproposedapproachdemonstratesstate-of-the-artinsource
localisation,achievingover90%completenessatasignal-to-noiseratio(SNR)aslowas2.Additionally,thedescribed
methodoffersaninherentmeasureofpredictionreliabilitythankstothestochasticnatureofthechosenmodel. In
terms of flux estimation, the proposed model excels past PyBDSF performance, accurately extracting fluxes for
96% of the sources in the test set, a notable improvement over CLEAN+ PyBDSF’s 57%. Conditional DDPMs
is a powerful tool for image-to-image translation, yielding accurate and robust characterisation of radio sources,
and outperforming existing methodologies. While this study underscores its significant potential for applications
in radio astronomy, we also acknowledge certain limitations that accompany its usage, suggesting directions for
furtherrefinementandresearch.ThePythonimplementationoftheproposedframeworkispubliclyavailableat
https://github.com/MariiaDrozdova/diffusion-for-sources-characterisation
1 Introduction
TheadventoftheSquareKilometerArray(SKA)willrevolutionizeradioastronomyatcentimeter(cm)andmillimeter
(mm)wavelengths. Already, thevariousSKAprecursors, suchastheAustralianSquareKilometreArrayPathfinder
[ASKAP;Hotanetal.,2021],theMurchisonWidefieldArray[MWA;Tingayetal.,2013],theLOw-FrequencyARray
[LOFAR;vanHaarlemetal.,2013],andtheMeerKATradiotelescope[JonasandMeerKATTeam,2016],havestarted
to produce interesting results. The Atacama Large Millimeter Array (ALMA), owing to its excellent sensitivity, led
*Correspondingauthor:mariia.drozdova@unige.ch
1
4202
beF
51
]MI.hp-ortsa[
1v40201.2042:viXraFigure1: Simplifiedpipelineforrealandsimulatedobservations. Eachpairofantennascollectsskyobservationsthat
yieldUV-visibilitydata. ThesedataarethenaggregatedviaagriddingprocessintoanaggregatedUVgrid. Finally,
aninverseFouriertransformisappliedalongwiththeeffectofaprimarybeamtogeneratethedirtyimage.
toseveralinterestingstudies. Someofthestudiesrelevanttoourcurrentworkarethedeepextragalacticcontinuum
surveys,whichfocusonthegasanddustinhigh-redshiftgalaxies;forexample,theReionizationEraBrightEmission
Line Survey [REBELS; Bouwens et al., 2022], the ALMA SPECtroscopic Survey in the Hubble Ultra-Deep Field
[ASPECS; Walter et al., 2016], the ALMA Large Program to Investigate [CII] at Early times [ALPINE Le Fe`vre
et al., 2020, Be´thermin et al., 2020, Faisst et al., 2020], and the GOODS-ALMA survey at 1.1 mm [Franco et al.,
2018] and the Automated Mining of the ALMA Archive in the COSMOS Field (A3COSMOS) data set1 [Liu et al.,
2019].
Thesemodernradiointerferometerslieatthecuttingedgeofinstrumentationintermsofthereceivers,correlators,
low-noiseamplifiers,high-speeddatalinks,andothertechnologies.Theyarealsoexpectedtoproducedataonexabyte
scales[Scaife,2020],whichwillrequirenovelandefficientdatareductionandanalysistechniques. However,inorder
to convert the observed visibilities to science-ready images, the processing of the resulting data still relies on the
traditionalCLEANalgorithm[Ho¨gbom,1974]forimaginganddeconvolution.
In radio astronomy, images are reconstructed using visibilities measured at discrete locations depending on the
antenna configuration and integration time (aperture synthesis imaging). If the field of view of the antenna is rela-
tivelysmall,thesevisibilitiescanbeconvertedinto“dirtyimages”bytakinganinverseFouriertransform. Thedirty
images are further improved to remove the various artifacts coming from the side lobes using a deconvolution pro-
cess. Thisentireprocessofconstructingthedeconvolvedimagesfromtheobservedvisibilitiesisreferredtoasimage
reconstruction. ThemostpopularalgorithmforsuchanimaginganddeconvolutionprocessistheCLEANalgorithm
[Ho¨gbom,1974,Clark,1980],whichessentiallyreliesonidentifyingintensitypeaksmodeledaspointsourcesinthe
dirtyimage. Thesepeaksareiterativelyremoved(orCLEANED)afterconvolvingthemwiththedirtybeam. Ineach
iteration, peaks of progressively lower intensity are CLEANED until a user-defined threshold is achieved. Several
variants of the CLEAN algorithm have been introduced to mitigate its various limitations; for example, the multi-
frequency synthesis algorithm [mfs; Conway et al., 1990] and multiterm mfs [mtmfs; Rau and Cornwell, 2011] for
wide-bandimaging. Thesearewidelyusedbythecommunitywithradiointerferometers,suchasALMA,VeryLarge
Array(VLA),MeerKAT,andsoon. However,allCLEAN-basedalgorithmsdonotaddressthefundamentalissueof
imagereconstructioninradioastronomy. Asthevisibilitiesareonlymeasuredatdiscretelocations,imaginginradio
astronomy is an ill-posed problem, such that the same visiblities can be mapped to multiple sky models. Further,
the CLEAN algorithm can benefit from prior knowledge of source positions, which usually requires expert human
knowledge.
In addition to the CLEAN method, there exist other methods for reconstruction of sky-model images from dirty
images.Notably,Tikhonovregularization[TikhonovandArsenin,1977]andWienerfiltering[Wiener,1949]represent
twoclassicdeterministicmethods. Theseiterativemethodsoperateinaniterativemannertominimizethefidelityloss
withsomepriorsontheexpectedsolution: L(s) = |z−Hs|2 +λΩ(s), wherezisadirtyimage, λisaregularization
2
constant,andΩ(s)denotestheregularizer. Consideringprobabilisticmethodswithaprior p(s),onecandefineΩ(s)∝
−lnp(s).
Another method used in radio astronomy is based on the maximum entropy method (MEM; see e.g., Gull and
Daniell 1978, Cornwell and Evans 1985, Narayan and Nityananda 1986), whereby the distribution with the greatest
entropyischosenamongallthedistributionsthatfitthedata. Furthertechniquesincludebiasmethods,thetotalvari-
ationprior[Rudinetal.,1992],andGaussianmixturemethods[Bishop,2007]. Thesemethodsareoftenhandcrafted
anddeterministic,complementingtheCLEANmethod.
1https://sites.google.com/view/a3cosmos/home?authuser=0
2Variousdeeplearningmodelshaverecentlybeenproposedtosolvetheproblemofimagereconstructioninradio
astronomy.GhellerandVazza[2022]useanautoencodernetworkto“denoise”thedirtyimages,particularlyfordiffuse
extended emission. Connor et al. [2022] used a feed-forward neural network to achieve super-resolution on already
CLEANED images. Schmidt et al. [2022] used a deep learning(DL)-based approach motivated by super-resolution
models, where they use a series of convolutional layers on the sampled amplitude and phases of the visibilities to
reconstructthemissingvisibilities. Complementingthesedeeplearningmodels,Bluebild[Tolleyetal.,2023]offersa
novelapproach,leveragingfunctionalprincipalcomponentanalysis(PCA)tosynthesizeimagesbydecomposingthe
skyintoeigenimageswithdistinctenergylevels.
At the same time, unprecedented features of DL allow visibilities to be directly translated into estimates of sky
models or source locations. This allows the user to skip the stage of dirty-image computation. Taran et al. [2023]
introduced a method for localizing radio sources from reduced UV samples. The approach taken by these authors
involvesatwo-stagepipeline: initially,afullyconnectednetworkpredictsabinarymapwhereavalueof“1”signifies
the presence of a source and “0” indicates the background. Following this, an autoencoder refines the predictions.
Withthesamedatasetasusedinthepresentstudy,Taranetal.[2023]achievedapurityof91%andacompletenessof
74%. AdetailedcomparisonofourresultsandtheirscanbefoundinSection4.
Inthepresentwork,weproposeanalternativeDL-basedsolution:weuseadenoisingdiffusionprobabilisticmodel
(DDPM;Sohl-Dicksteinetal.2015,Hoetal.2020)toreconstructtheskymodelfromdirtyimagesandthenlocalize
thesources. DDPMsareafamilyofgenerativemodelsthatuseadiffusionprocesstorepresentdatadistribution. Inits
basicunconditionalformulation, thistypeofmodellearnstomapartificiallygeneratednoisewiththedesiredtarget
distribution.
DDPMshaveshownremarkableperformanceonawiderangeoftasks:unconditionalimagegenerationinHoetal.
[2020], conditional image generation in Dhariwal and Nichol [2021], and text-to-image generation in Ramesh et al.
[2022]. DDPMsarealsoapplicabletootherimage-to-imagetranslationtasks,suchassuper-resolution,colorization,
and inpainting (Saharia et al. [2022]). Wang et al. [2023] demonstrate for the first time that DDPM can be used
for image reconstruction for radio astronomical images trained on data generated for the Event Horizon Telescope
[Akiyama et al., 2019]. In summary, the stochastic nature of DDPMs is beneficial in addressing ill-posed problems
wheremultiplesolutionsexistforthesameobservation.
Thepresentpaperisorganizedasfollows. InSection2, weprovideabriefoverviewofthesimulatedradiodata
used in the DDPM training. Section 3 details the proposed pipeline, encompassing preprocessing steps, the DDPM
model, post-processingtechniques, andtherangeofmetricsemployedtoevaluateperformance. Then, inSection4,
wepresentourfindingsintermsoftheperformanceoftheDDPMapproachinreconstruction, localization, andflux
estimation. Additionally,weanalyzetheperformanceinrelationtoS/Nandthevaryingnoiseamplitudescausedby
watervapor.InSections5and6,weconsiderthelimitationsoftheapproachanddiscusspotentialdirectionsforfuture
research.
2 Simulated data
WeperformedtheentiretrainingoftheproposedDDPMmodelonsimulatedALMAdataforthe12marray. These
data are the same as those used in Taran et al. [2023] for their DL model training. We refer to Taran et al. [2023]
for further details of the simulations. All the simulations are produced using the Common Astronomy Software
Applications (CASA) data processing software v6.2 [McMullin et al., 2007, Bean et al., 2022]. Briefly, we chose a
fixedALMAconfiguration,cycle5.3. Thesesimulationsaredesignedtosomewhatmatchtherealobservationsfrom
theA3COSMOSdataset[Liuetal.,2019]withtheaimbeingtoapplytotheminthefuture.Therefore,allthesimulated
pointings are randomly distributed around the COSMOS field (J2000 10h00m28.6s +02d12m21.0s) within a radius
of1deg. Eachpointingcorrespondstoanindependentskymodel. Inthesimulations,askymodelcorrespondstoan
imageof51.2×51.2′′ across. Thevarioussourcesinthisskymodelaremodeledasa2DGaussianoverlaidonazero
background. Thevarioussourceproperties, suchastheirsizes(majorandminoraxisoftheGaussian), positionson
thesky,andfluxesineachskymodelarevariedrandomly. WefixedtheALMAbandtoBand-6(230GHz)splitinto
240 channels with a channel width of 7.8 MHz. We added the effect of noise from water vapor and receivers using
a precipitable water vapor (PWV) parameter value of 1.796. For each sky model, we produced the corresponding
visibilitiesforatotalintegrationtimeof20minswhilethephasecenteroftheskymodelwasundertransit. Wethen
producedthecorrespondingdirtyimagesforeachpointingusingtheCASAtasktcleanbysettingtheniterparameters
equaltozero. ThistaskdoestheappropriateUV-griddingandinverseFouriertransformofthevisibilities,alongwith
3theeffectofprimarybeamtoproducethecorrespondingdirtyimage.Figure1showsablockdiagramofthesimulation
pipeline. Intotal,wehave9164simulatedpointings(skymodels)andthecorrespondingdirtyimages. Thiscomprises
atotalof27632sources,plus1000simulationswithoutsources.
Figure 2: Effect of γ value on sky model preprocessing. The preprocessing of the sky model via Equation 1 is
significantlyaffectedbytheγvalue. Theproposedmethodmodifiestheintensitiesoftheimagepixelstoimprovethe
network’scapacityforaccuratereconstruction. Byemployinganonlinearrootoperation,nonzerovaluesarepushed
closer to one, effectively making the histogram more uniform. However, this modification also impacts the relative
distances. Therefore, an optimal γ value is required to ensure a compromise between these two tendencies. The
histogramy-axislimitsaresetsothattheheightofthethirdbincomprises80%oftheimage.
Inthisstudy,thesedirtyimagesdotheconditioningfortheDDPMmodel,whichpredictsthecorrespondingsky
model. Inordertostudytheeffectofvaryingnoise,wealsoaddsimulationswiththesameconfiguration,butchange
thePWVvaluesfrom0.472to5.186. Wenotethattheseadditionalsimulationsarenotusedfortrainingthemodel,
butsimplyfortestingtheeffectofvaryingnoise,asintheanalysisofTaranetal.[2023].
3 Proposed method
3.1 Preprocessing
Inthiswork,weapplymachinelearningbasedonDDPMtodirtyimagesinordertopredictskymodels. Bothdirty
imagesandskymodelsrequirepreprocessing. Inmachinelearning,naturalimagesareusuallymappedtothe[−1,1]
range by a simple scaling. As we work with measurement data, which have their own properties and statistics, we
needtoadjustthedata-preprocessingstep.
Theskymodelsarenon-negativeandaretypicallyverysparseandofverysmallmagnitude,oforder10−5 Jy. We
would like to not only change the range of values for sky models but make the distribution of the values flatter. A
4sky model is what the model predicts, and so the loss functions will be applied directly to it. In this study, we use
meansquareerror(MSE)duetothemodelchoice. MSElossworksbetterwithdenseimages(theoneswhosevalues
haveflatterhistograms). Wethereforeneedatransformthatmakestheimagehistogramsflatterandisalsoinvertible,
becauseaftergettingpredictions,weneedtoreturntotheoriginalranges.
We take inspiration from the preprocessing techniques used in particle physics Finke et al. [2021] to face the
sparsity and low signal magnitude. These use blur and root functions. As the sky models already contain sources
modeledasGaussians,weretainonlytherootfunction. Weusethefollowingscalingintheexperiments:
(cid:18)s(cid:19)1
s = γ , (1)
tr c
wheresisaskymodel,cisaconstant,andγisavariableparameterforwhichweexplorearangeofvalues,spanning
from1to30. Thevalueofcissetto2.96×10−5,correspondingtothemaximumvalueofimageintensityidentified
empiricallywithinthetrainingset. Thismethodhelpsustoenhancethecontrastoftheimageandmitigatetheissues
arisingfromlowsignalstrength. Tomapthevariablestotherangeof[−1,1],weapplythefollowingformula:
s −0.5
x = tr , (2)
0 0.5
wherex isconsideredasatargetimagefortheDDPMsystem.
0
The transformation in Equation 1 is not linear, and so it does not preserve distances, which means that small
relativevaluesinthetransformedimagecorrespondtoahugegapbetweenvaluesinthecorrespondingoriginalimage.
WeillustratetheinfluenceofpowerγfromEquation1inFigure2. Inthisvisualization,wetakeoneskymodelofthe
generatedsetandweshowhowthesuggestednormalizationinEquation1changestheimageaswellasitshistogram.
Thechoiceofγ = 1correspondstothecasewhereonlylineartransformisapplied. Asγgrows,thesourcesbecome
widerandbrighter,andthehistogrambecomesflatter,indicatingadenserimage.
Intheexperiments,dirtyimageszareobtainedfromaggregatedUVgridsy,where
F−1(y)
−0.5
z= cd , (3)
0.5
where F−1 is a function that maps UV grids to dirty images. In CASA, F−1 includes inverse Fourier and artefact
correction. The0.5factorisusedtomapimagesapproximatelytothe[−1,1]range,asinEquation2.
ImagesafterF−1 arealreadydenseandcontainvaluesoftheorderofc =10−5 Jy. Fortheseimages,weapplya
d
scalingoperationbydividingeachimagebyafactorofc .
d
These preprocessing steps map the sky model and dirty images to be within standard ranges of typical machine
learning models. The described DDPM estimates the sky model denoted xˆ . In order to map variables back to the
0
originalscale,weapplytheinverseoperations:
sˆ =0.5xˆ +0.5, (4)
tr 0
sˆ =csˆγ, (5)
tr
wherecisthesameconstantasinEquation1.
3.2 Imagereconstructionbasedonstochasticmodels
In this study, we address image reconstruction in radio astronomy, which is an inherently ill-posed problem. Infor-
mation is lost due to UV sampling, gridding, and handling of noise coming from the instruments and atmosphere.
Given these limitations, the task of accurately estimating the initial sky model from the measured data is naturally
ambiguous. Mathematically,itmeansthatmanyestimatessˆmightcorrespondtothesamemeasureddataz.
To estimate the sky model, we must inject priors into the model. There are two possible approaches to do this:
deterministic methods and stochastic methods. Deterministic methods —as in CLEAN— use hand-crafted priors,
and traditional machine learning models are based on learnable frameworks; both operate in a straightforward way.
5Theycreateaone-to-onemapping: theyfirstfindoptimalparametersbasedonthetrainingdataandthen,oncethese
parametersarefixed,theyproduceadeterministicoutputforeachuniqueinput. Incontrast,stochasticmethodsallow
one-to-manymapping,meaningtheycangeneratemultipleprobablesolutionsforasingleinput. Thisisachievedby
introducingrandomvariablesormodel-initiationnoiseintothemodelduringthecomputationoftheoutput.Therefore,
the output depends on both the input data and the realization of the model initiation noise. By varying this model-
initiation noise for fixed model parameters, we can get different outputs for the same input data. All such outputs
are the most probable to align with the target data manifold and correspond to the given input data (observations).
This inherent ambiguity is useful, as by inspecting different reconstructions we can quantify the uncertainty on the
predictions.
Figure3: Schematicrepresentationofdiffusionprocess. Theforwardprocessconsistsinprogressivelyaddingnoise
totheskymodel. Theinverseprocessstartswithmodelnoise,whichisprogressivelyrefinedwithaconditioningon
thedirtyimage.
3.3 Denoisingdiffusionprobabilisticmodels
Figure4: Generalizedpipelineofproposedmethod. Thetopbranchrepresentsinference. TheDDPMmodelactsas
a stochastic image-to-image translator, transforming the conditioning z and the model noise ϵ into the target image
xˆ and corresponding sˆ. The predicted sky model is then processed by the localization algorithm, outputting the
0
correspondingcoordinatesandfluxes. Thebottombranchrepresentsthesimplifiedmeasurementprocess.
We use the image-to-image DDPM Palette Saharia et al. [2022]. This diffusion operates in an iterative manner,
asvisualizedinFigure3. Therearetwodirections: forwardandinverse. Duringtheforwarddirectionstage,weadd
modelnoiseϵtothedata. Thisnoise,aninternalstateparameterofthemodel,isdistinctfromtheastronomicalnoise
arisingfromantennas,theatmosphere,andsoon. InDDPMs,thismodelnoiseisgenerallysampledfromazero-mean
Gaussiandistribution.Duringtheinversedirectionstage,theaimistoremovetheaddednoiseusingatraineddenoiser.
This denoiser is a crucial component of the denoising diffusion process and, in this case, is represented by a U-Net
6Figure 5: Schematic representation of training pipeline for time step t. The preprocessed sky model x is corrupted
0
bytheDDPMmodelnoiseϵ. TheU-Net,giventhecorruptedtargetimagex andconditionedwiththedirtyimagez,
t
triestoestimatethemodelnoiseϵˆtodenoisethex. Themodelistrainedtominimizethedistancebetweenϵandϵˆ.
t
[Ronnebergeretal.,2015] withself-attentionlayers[Vaswanietal.,2017]. TheparametersofU-Netaretrainedto
predict the model noise added to the target image. The iterative process of applying this U-Net multiple times for
progressivedenoisingisthefunctionoftheDDPM.
Attheforwardprocessstageforeachiterationt ∈ {1,T},theaddedmodelnoisehasitsownvariance, whichwe
denote α to α , respectively, where each α∀t is between 0 and 1, and each subsequent value is greater than the
1 T t
previous one α > α > ... > α . Variances are chosen in such a way that, after T steps, we have a meaningless
T T−1 1
imagecorrespondingtothenoise,essentiallyasamplefromtheGaussiandistribution. Inthiscase,thereverseprocess
canbeinitiatedfromthenoise.
Mathematically,theforwardprocesscanbewrittenas
(cid:112)
x =αx + 1−αϵ, (6)
t t t−1 t
wherex isanimageproducedbyDDPMatthetimestept,andϵistheaddedmodelstatenoise.
t
Hoetal.[2020]showthatx canberewrittenas
t
√ (cid:112)
x = α¯ x + 1−α¯ ϵ, (7)
t t 0 t
wherex isatargetdatasampleandα¯
:=(cid:81)t
α .
0 t s=1 s
Attheinverseprocessstage,wetrainthemodeltoremovetheaddedinternalnoise(modelnoise). AfterT steps,
weassumethatthemodelwillencodeatargetdatamanifoldtoitself,makingitpossibletogeneratedatasamplesinT
stepsfromarandomlyinitiatedmodelstateϵ. Inourimplementation,eachstepisconditionedonzbyconcatenating
it to the input. z represents the dirty image obtained from the aggregated UV grid y, as shown in Figure 4 (bottom
branch).
The training stage is visualized in Figure 5. The subset of 5082 images is used. During training, we uniformly
select time steps t ∈ [0,1000], which define the noise variance for each instance. The target image (sky model)
x is first normalized, and then we generate an intermediate x using Equation 7 and the model noise ϵ. This x is
0 t t
concatenated with the normalized dirty image z, creating a two-channel tensor fed into the U-Net, which serves as
ourdenoiser. TheU-Netarchitecture, whichisadaptedfromSahariaetal.[2022], hasfourstagesofdownsampling
andfourstagesofupsampling. ThetimestepisencodedusingtwolinearlayerswithSiLUactivationfunctions. The
denoiser consists of residual blocks, which includes Group Normalization (with 32 groups and an epsilon value of
10−5), and Convolutional Layers with kernel size 3. The model uses self-attention mechanisms. The U-Net accepts
a two-channel input and produces a one-channel output. This model contains approximately 95M parameters. The
primarytrainingobjectiveistominimizetheℓ distancebetweentheactualmodelnoiseϵandthenoiseestimatedby
2
theU-Netϵˆ=g (x,z),asdefinedinEquation8.
θ t
7LDDPM(θ)=E (cid:20)(cid:13) (cid:13) (cid:13)ϵ−g (cid:16)√ α¯ x + (cid:112) 1−α¯ ϵ,z,t(cid:17)(cid:13) (cid:13) (cid:13)2(cid:21) , (8)
t,z,x0,ϵ (cid:13) θ t 0 t (cid:13)
2
wherex isatargetimage(skymodel),zisaconditioning(dirtyimage),ϵisGaussianzero-meanunitvariancenoise
0
N(0,I),g isconditionalDDPM,andα¯
=(cid:81)t
α isthenoisevarianceparameter,allatstept,asinEquation7. We
θ t s=1 s
trainthisU-Netover237epochswithabatchsizeof24,andweusetheAdamoptimizerwithalearningrateof10−4.
Weselectthebestmodelbasedonthelossonthevalidationsetconsistingof2541images. Thetrainingprocesswas
completedinapproximately16hoursonaNVIDIARTX3090GPU.
The diffusion model can be seen as a stochastic image-to-image translator whose goal consists in transforming
dirty images z into a sky model xˆ . Therefore, dirty images z can also be referred to as the input z to the DDPM
0
alongsidethemodelnoiseϵ.
Attheinferencestep,webeginwiththeGaussiannoise(noiseofthemodelϵ)andthedirtyimagez. Thisstageis
notmerelyaconsecutiveapplicationofthedenoisertoϵbutratherasophisticatediterativeprocessthatprogressively
refinestheestimateoftheoriginalskymodel,xˆ ,startingwithϵthroughx.EachstepoftheDDPMinvolvespredicting
0 t
andthensubtractingtheaddednoisefromthecurrentimagex eachtimeconcatenatedwithdirtyimageconditioningz.
t
Afterremovingthepredictednoisefromx wegetanestimateofx . Then,anew,smaller-varianceGaussiannoiseis
t 0
introducedtogetx ,whichisthenestimatedandremovedinthesubsequentstep. Duetocomputationallimitations,
t−1
thisprocessisrepeatedforatotalof250stepsinsteadof1000;itgraduallyreducesthenoiseandconvergestowardan
accuratereconstructionofx . Subsequently,withEquations4and5,xˆ ismappedbacktotheoriginalrangeofvalues
0 0
sˆ. Finally, weapplytheextractionalgorithmtogetthepropertiesofthesourcesfromthepredictedskymodel. The
processisshownschematicallyinFigure4(topbranch).
3.4 Sourcelocalization
(a) (b) (c)
(d) (e) (f)
Figure 6: Photutils algorithm behavior on sky models for closely situated sources.Behavior of the Photutils local-
ization algorithm on sky models. Panels (a) and (d) show the sky model; (b) and (e) depict images annotated with
the corresponding catalog sources; and (c) and (f) present images annotated with sources detected using the chosen
photutils algorithm. As demonstrated in these images, the Photutils algorithm occasionally fails to deblend closely
situatedsources. Thishappensforlessthan1%ofthesourcespresentinthedataset.
Thelocations,shapes,andfluxesofthesourcescanberestoredfromthepredictedskymodel. WhilePyBDSFis
commonlyusedforthistask,itcanonlybeappliedtoimagescontainingbackgroundnoise. Asthetargetskymodels
donotcontainanynoise—justpointsources—wefindthisextrastepofaddingnoisetoexecutePyBDSFdestructive.
This is especially true considering the relatively straightforward nature of the sky models, which consist solely of
Gaussian sources with zero background. These challenges prompted us to explore an alternative method of source
localization.
We use an algorithm based on watershedding. We take an implementation of this algorithm from the Photutils
librarybyBradleyetal.[2016]toextractthepropertiesofpointsourcesfrompredictedskymodels. Tovalidatethe
usageofthisalgorithmforsourcelocalization,weevaluateitsperformanceonallskymodelsofthesimulateddataset.
8The achieved scores are close to perfect, as shown in Section 4. The algorithm fails when sources are very close to
eachother(seeFigure6). Giventhesmallamountofdataforwhichitfails,weuseitasafinalpost-processingstepof
thepipeline.
The localization algorithm can be deployed directly on a single output from the diffusion model; however, we
can also use the stochasticity and run the model with different realizations of model state noise to get multiple sky
modelpredictions. Thiscanpotentiallyenhancethemodel’sperformance,butachallengearisesinaggregatingthese
multiple predictions. In this study, we investigate two aggregation techniques to derive a final image from multiple
predictions: themeanandthemedian. Thesemethodsareappliedatthepixellevel,whereweassessthevalueofeach
pixelacrossallpredictionsandcomputeeitheritsmeanormedian. Thisprocessisrepeatedforeverypixel,resulting
inthefinaloutputimage.
3.4.1 Aggregationtechniques
Asmentionedabove,DDPMcanoutputmultiplepredictionsforonephaseofconditioning. Weinvestigatetwoways
toaggregatetheproducedpredictionsviaaggregate-detectanddetect-aggregatestrategies.Theaggregate-detecttech-
niquemeansthatfirstweaggregatetheimagesandthenwelocalizethesources. Thedetect-aggregatemethodmeans
thatwefirstlocalizesourcesfromeachpredictionandthenweaggregatethesourcesintothefinaltable.
Fortheaggregate-detectstrategy,westudythemeanandmedianasanaggregation:
1(cid:88)n
Mean(h,w)= xˆk(h,w), (9)
n 0
k=1
(cid:16) (cid:17)
Median(h,w)=median xˆ1(h,w),xˆ2(h,w),...,xˆn(h,w) , (10)
0 0 0
wherenisthetotalnumberofpredictedimagesforagivenz(20inthiscase),xˆk representsthek-thpredictedimage,
0
and(h,w)representthepixelcoordinates.
The detect-aggregate method consists in aggregating the predicted sources from multiple runs with the same
conditioning.Inthisscenario,thesource-extractionalgorithmisexecutedoneachimageindependently.Subsequently,
the predictions are merged together; two predictions are considered to concern the same source if their coordinates
(rightascension(RA)andDeclination(Dec))arewithinaradiusofr=5×10−5degrees.Inthefinalaggregatedoutput,
each source is listed with its average coordinates and characteristics (such as flux), along with the corresponding
standarddeviationcomputedacrossthemultiplepredictions.
Additionally,wecalculatethenumberofimagesinwhicheachsourceisdetected,avaluewetermthe“reliability”
ofthesource. Forinstance,ifasourceisdetectedinall20imagesoutof20,itisassignedareliabilityof100%;butif
itisonlydetectedin10images,theassociatedreliabilityis50%. Areliabilitythresholdcanbesettodeterminewhich
sourcesshouldbereported. Intuitively,ambiguoussourceswillnotappearinallpredictions,becausetheycanalsobe
classifiedasbackgroundnoise. Thisshouldbeparticularlytrueforveryfaintsources.
We show in Section 4 that as soon as the reliability threshold grows, completeness falls, which means that the
modelstartstomissanincreasingnumberofsources(whilepuritygrows). Reliabilityisexpectedtobeaproxyfor
thesensitivityoftheproposedalgorithmtofaintsources.
3.5 Evaluationmetrics
The task of localization in the described pipeline is divided into two stages: sky model reconstruction from dirty
imagesandsourcelocalization. Weevaluatetheproposedmethodonboth.
3.5.1 Reconstructionmetrics
ToevaluatehowwellthetrainedDDPMpredictstheskymodelfromdirtyimagez,weusemetricsfromnaturalimage
analysissuchaspeakS/N,SSIM,andMSE,whicharedescribedbelow.
Themeansquarederror(MSE)quantifiestheaveragesquareddifferencebetweenthepredictedandoriginalpixel
values:
1 (cid:88)H (cid:88)W (cid:18) (cid:19)2
MSE= xˆ (h,w)−x (h,w) , (11)
H×W 0 0
h=1w=1
9whereH×W representstheimagesize,x correspondstothetargetimage,andxˆ representsthepredictedimage. A
0 0
lowerMSEindicatesbetterperformance.
Thepeaksignal-to-noiseratio(peakS/N)measuresthequalityofthepredictedimagebycomparingittothetarget
image; itisacalculationoftheratioofthemaximumpossiblepixelvalueMAXtoMSEbetweenthepredictedand
originalimages:
peakS/N=20·log (MAX)−10·log (MSE). (12)
10 10
AhigherpeakS/Nindicatesbetterperformance.
Thestructuralsimilarityindex(SSIM)introducedbyWangetal.[2004]assessesthesimilaritybetweenthepre-
dictedxˆ andtargetimagex basedontheirstructuralinformation:
0 0
(2µ µ +c )(2σ +c )
SSIM(x ,xˆ )= x0 xˆ0 1 x0xˆ0 2 , (13)
0 0 (µ2 +µ2 +c )(σ2 +σ2 +c )
x0 xˆ0 1 x0 xˆ0 2
whereµ istheglobalmeanvalueofx ofsize H×W;µ istheglobalmeanvalueofxˆ ofsize H×W;σ isthe
x0 0 xˆ0 0 x0
globalvarianceofx ;σ istheglobalvarianceofxˆ ;σ isthecovariancebetweenx andxˆ ;andc = 10−4 and
0 xˆ0 0 x0xˆ0 0 0 1
c = 9×10−4 are two constants chosen to stabilize the division depending on the dynamic range. The SSIM value
2
rangesbetween0and1, whereahighervalueindicatesbetterperformance. TheSSIMimplementationusedhereis
usedfromtheskimagepackagebyVanderWaltetal.[2014].
3.5.2 Localizationmetrics
Toevaluatetheperformanceofthesourcelocalizationtask,weusepurityandcompletenessmetricsfollowingthesame
protocol as in Taran et al. [2023]. These metrics are essentially the same as precision and recall but we define true
positives(TPs),falsepositives(FPs),andfalsenegatives(FNs)differently.Thepredictedsourcepositionisconsidered
aTPifits(RA,Dec)coordinatesarewithinaradiusofr = 5×10−5 degreesfromthetruesourceposition,whichis
known from the simulation. A predicted source is a FP if there is no true source within the same radius r. A FN is
observediftherearenopredictedsourceswithintheradiusaroundatruesource.
Purity, or precision, measures the accuracy of the predicted sources by computing the ratio of the number of
detectedtruesources(TP)tothetotalnumberofpredictedsources. Itcanbecalculatedusingtheformula:
TP
Purity= . (14)
TP+FP
Completeness, or recall, quantifies the completeness of the predictions by calculating the ratio of the number of
detectedtruesources(TP)tothetotalnumberoftruesourcespresentinthedata:
TP
Completeness= . (15)
TP+FN
Inadditiontopurityandcompleteness,wealsocomputetheF1-score,whichistheirharmonicmean:
Purity·Completeness
F1-score=2· . (16)
Purity+Completeness
TheF1-scorerangesbetween0and1, whereahighervalueindicatesbetterperformanceintermsofbothpurity
andcompleteness.
3.5.3 Sourcecharacterizationmetrics
In the context of source characterization tasks, the goal is to predict the flux values, which represent the integral
brightness of the radio source. The accuracy of the flux estimations is measured by calculating the proportion of
points for which the flux has been accurately predicted. We refer to a flux prediction as accurate if the predicted
valuevariesfromtheactualvalue(establishedthroughthesimulations)byaquantityequaltoorlessthanthenoise
amplitude. Intheexperiments, thenoisemeansquareissetto50mJy. Consequently, weintroduceametricknown
asthe”fraction”,whichisdefinedastheratioofthenumberofpointswherethefluxwasaccuratelypredictedtothe
totalnumberofsourcesinthesimulation.
104 Results
4.1 Imagereconstruction
Thefirststageoftheproposedpipelineisareconstructionofaskymodelfromadirtyimage.
4.1.1 Diffusionpredictions
Dirtyimage Skymodel Median Mean Std
Outputs
Figure 7: Diffusion model workflow: from dirty image to models outputs and uncertainty estimation. Top row: (1)
Originaldirtyimage(conditioning),withtruesourcescircledinwhite.(2)Theskymodelshowingsourcesdetectedby
thePhotutilslocalizationalgorithm. (3)Thepost-processedpredictedskymodel, aggregatedusingthemedianfrom
20networkoutputs,withPhotutils-localizedsources. (4)Anotherversionofthepost-processedpredictedskymodel,
thistimeaggregatedpixel-wiseusingthemeanfromnetworkoutputs,againwithPhotutils-localizedsources. (5)The
standard deviation of multiple predictions before the post-processing step. We refer to this latter as the uncertainty
estimation;itisunitless,withbrightercolors(likeyellow)indicatinggreateruncertainty. Rows2-5present20distinct
outputsofthediffusionmodelforthecorrespondingdirtyimage,eachwithadifferentmodelnoiseinitialization.
The model operates in a stochastic manner, producing multiple outputs for the same conditioning image. This
stochasticity provides advantages when dealing with sources that exhibit low S/N. By running the model multiple
times(20runsintheexperiments),weexpectthefaintsourcestoappearinthefractionofthepredictionsinthesame
positions. It is important to note that each run takes approximately 80 seconds per image on GPU RTX 3090. The
execution time can be further optimized using different generative techniques, which will be the subject of future
investigations.
Figure7showsanexampleofthemodeloutput. Inthetoprow,wepresentsamplesfromthegenerateddataset:
the first image is the conditioning (dirty image) and the second one is the corresponding sky model. The next three
outputsrepresenttheaggregatedmean,theaggregatedmedian,andthestandarddeviationofthepredictions. Theraw
predictions of the model are in the rows 2-5. We note that there exists a particularly faint source that the proposed
model fails to detect in aggregated images. However, in some single runs the source is present. This leads to huge
11valuesofstandarddeviationinthisarea,whichshowsthatthemodelisuncertainaboutitspredictionsandthatfurther
investigationisneeded.
Thisdecisiontoselect20runsperdirtyimageismotivatedbytheobservedbehaviorofreconstructionmetricsin
Figure8forthemedianaggregationprocessacrossmultipleimages. Wenoticeanimprovementinthemetricswithan
increaseinthenumberofaggregatedpredictedimages.However,thisimprovementcomesattheexpenseofadditional
computationtime. Atthepointofn = 20,weassumethatfurtherincreasesdonotsubstantiallyimprovethemetrics.
Consequently, we identify n = 20 as an effective compromise between improved performance and computational
efficiency.
Figure8: Reconstructionmetricswithrespecttonumberofrunsnofdiffusionmodelformedianaggregation.
The reconstruction metrics are presented in Table 1. These metrics are calculated on the direct outputs of the
diffusionmodel; thatis, thenormalizedskymodel. Weexperimentwithdifferentvaluesforthepowerrootγ inthe
normalizationfunctionappliedtotheskymodel(Equation1).
As the original range of values within the images is significantly low, metrics calculated within it would be ex-
ceedingly high, rendering them uninformative. We therefore use normalized values. However, as discussed above,
higher root powers lead to lower contrast in the images. In this case, the contrast is negatively correlated with the
reconstruction metrics —less contrast in images tends to result in better reconstruction metrics for the same model
performance. This relationship is evident in Table 1, where lower powers yield superior results compared to higher
powers.
Aggregating multiple outputs from various runs outperforms the output from a single run within the same nor-
malization. Thisdemonstratesthattheinherentstochasticityoftheprocessassistsindetectingfaintersources,which
indicates the value of using statistics across multiple runs to enhance reconstruction. Through experimentation, we
findthatthemeanandmedianaggregationmethodsdeliververysimilarresults.
An essential takeaway from this analysis is that reconstruction metrics may not be the most adequate indicators
forassessingthequalityofastronomicaldata. Insubsection4.2,weexplorethelocalizationmetricsanddiscusstheir
performanceforthesamesettings.
4.1.2 Uncertaintyestimationintheimagespace
Toquantifytheuncertaintyassociatedwiththeskymodelpredictions,weusetheconceptofuncertaintyestimationin
theimagespace. Wedefinex usingthefollowingformula:
uncertainty
12Table1:Reconstructionresults:MSE,peakS/N,andSSIMmetricscomputedonpreprocessedskymodelsfordifferent
diffusionsettings.
Metrics(±uncertainty)
Normalization Aggregation MSE peakS/N SSIM
(×10−5)
singlerun 5.276±0.138 38.031±1.152 0.977±0.002
γ=1 mean 4.232±0.333 42.243±9.475 0.998±0.001
median 3.941±0.354 41.587±9.156 0.998±0.001
singlerun 1.492±0.146 38.999±0.097 0.830±0.003
γ=2 mean 1.189±0.604 41.251±0.206 0.853±0.003
median 1.190±0.605 42.148±0.260 0.882±0.003
singlerun 1.668±0.171 36.784±0.464 0.814±0.004
γ=10 mean 1.183±0.592 38.008±2.263 0.835±0.005
median 1.185±0.586 38.386±2.550 0.862±0.005
singlerun 2.264±0.242 35.105±0.793 0.892±0.006
γ=20 mean 1.431±0.645 37.457±4.474 0.929±0.011
median 1.442±0.643 37.651±4.807 0.955±0.008
singlerun 2.820±0.313 32.944±1.086 0.985±0.002
γ=30 mean 1.553±0.750 34.844±4.585 0.985±0.008
median 1.569±0.735 34.693±4.906 0.988±0.007
Note:Wevariedthepowerrootusedinthenormalizationduringtraining(Equation1)andtheaggregationmethod(mean,medianover20runs,or
singlerun).SinglerunsignifiesthattheDDPMisrunonceforagivenconditiontogetthepredictedskymodel.Weevaluateperformanceoneach
runindividuallyandthencalculatetheaveragescoreoverall20runs. Theerroriscalculatedbytakingthestandarddeviationoveralloutputsfor
thetestsetforaggregationmethods,andoverallrunstogetasinglerunscore.
x uncertainty(h,w)=
(cid:118)(cid:117)(cid:116)
1
n(cid:88)n 
xˆ
0j(h,w)−
n1(cid:88)n
xˆk
0(h,w) 2
, (17)
j=1 k=1
wherenrepresentsthenumberofruns(n = 20),xˆj denotesapredictionoftheskymodelforthe j-thrun,and(h,w)
0
are the pixel coordinates. This formula denotes the standard deviation visualized in the top right of Figure 7. This
latter displays the variability in the predictions across multiple runs. Intuitively, if the model consistently identifies
thesamesources,theuncertaintyislowandwecanbecertainabouttheirpresence. Conversely,ifthesourcesappear
and disappear from the predictions across runs, the variance in the image space will be high, indicating a region of
theskythatrequiresfurtherinvestigation. Thevarianceinthepredictionscanbejuxtaposedwiththeintensityvalues
estimated in the mean-aggregated image to determine the degree of uncertainty associated with a particular region.
Thiscaninformthefinaldecisionaboutwhetheragivenregionexhibitssignificantuncertainty,therebyguidingfurther
analysis.
4.2 Sourcelocalization
After obtaining a predicted sky model, we try to identify the sources present. We evaluate the performance of our
sourcelocalizationusingthreemetrics: purity,completeness,andF1-score,asdetailedinTable2.
The F1-score is a particularly effective measure of model performance because it simultaneously considers both
purity(themodel’sabilitytolimitFPs)andcompleteness(themodel’sabilitytoidentifyallrealsourcesinthedataset).
WethereforeconsiderF1asthemainindicatorforchoosingthebestmodel.
We provide the scores for a Photutils method of source localization applied directly to the simulated sky model
givenbyCASA(lastlineinTable2). Thisreferencerevealstheleveloferrorthatcomesfromthechosenparameters
of the algorithm from Photutils.2 These parameters stay the same during all experiments, which ensures that any
2The Photutils parameters are: kernelxsize=3, kernelysize=3, sigmaclippedstatssigma=2. detectnpixels=10,
13differencesinoutcomescanbeattributedtothemodelsthemselves,ratherthantovariationsintheprocessingsteps.
WedrawacomparisonwiththemodelpresentedbyTaranetal.[2023]. Thedistinguishingfeatureoftheirmodel
is an additional compression step, which retains only 1450 fixed positions in the UV plane and operates directly in
the frequency domain. Contrasting this with the proposed DDPM, which employs 250 passes, the model in Taran
et al. [2023] accomplishes its task in a single pass. This characteristic exemplifies the common trade-off between
accuracy and computational efficiency. The model in Taran et al. [2023] performs better than PyBDSF [Mohan and
Rafferty,2015],whichcurrentlythoughttobestateoftheart. Consequently,wechosetocompareourresultstothose
of obtained using the model in Taran et al. [2023]. As can be seen from Table 2, all the models achieve very high
F1-scoresexceeding95%,comparedto81%achievedbytheTaranetal.[2023]model.
For the images with lower root functions γ ∈ [1,2], the best aggregation methods are aggregate-detect ones.
The outputs for the model trained with such normalizations are noisy, which is due to the sparsity of the images.
Aggregationontheimagelevelaveragesthenoiseineachprediction,producingahigher-qualityoutput. However,as
γgetslargerandthepredictionqualityrises,thewinningmethodbecomesdetect-aggregate.
The optimal model employs γ = 2. We illustrate the highest localization scores relative to various γ values in
Figure 9. The γ = 2 case demonstrates the effectiveness of the proposed normalization technique compared to the
γ = 1 case. However, as γ increases, the performance falls because of excessive sharpening of the blob borders, as
seeninFigure2.
In Figure 10, we plot the scores for γ = 2 against the number of runs. As n increases, the F1-score saturates,
reachingaplateauatn = 5withnosignificantfurtherimprovement. Thisbehaviorcontrastswiththereconstruction
scenario,wherethemetricscontinuetoimprovewithincreasingn. Thisoccursforreconstructionmetricsbecausethe
moreimageswegenerate,themoreerrorsarecorrectedwhenaveraging,leadingtosmoothimprovement. However,
localizationmetricsoperatedifferently;theirprimaryfocusisonthepositionoftheflux. Consequently,fewerimages
arerequiredforthefluxtoappearinthefinalprediction, andaddingmoreimagesdoesnotsignificantlymodifythe
chosen localization metrics. Essentially, these metrics are only concerned with whether the source was detected or
not,whichiswhytheyexhibitadifferentbehavior.
Figure9: Bestscoresforpurity,completeness,andF1amongallaggregationswithrespecttodifferentrootpowerγ
usedinnormalizationduringtraining.
deblendsourcesnpixels=10,stdconst=120.
14Figure10: Localizationmetricswithrespecttonumberofrunsnofdiffusionmodel.
4.3 Uncertaintyinlocalization
The detect-aggregate technique confers an advantage, in that it suggests a clear way to find uncertainty on the es-
timations. We compute the percentage of images where the source is present and then we aggregate those source
characteristicsthroughaveraging. Thefractionofoutputimageswherethesourceispresentisinterpretedasamea-
sureofsourcereliability: inthisstudy,thesourceisnotretainedifthereliabilityislessthan30%.
Toillustratetherationalebehindthechoiceofthe30%threshold,weplottheF1-score,purity,andcompleteness
againstthereliabilitythresholdforretainingsourcesinFigure11. Allcurvesexcepttheonewithrootpowerγ = 1
reachsaturationaround30%,haveaflatsectionafter,andstarttodiminishintheend. Puritygrowsaswedemandthat
thesourcebemoreconsistentintheimages,andcompletenessfallsasweeliminateanincreasingnumberofsources
thatappearinaninsufficientnumberofimages.
WeplotthedependenceofreliabilityontheS/NofthesourcesinFig. 12. Wefindthatmostofthesourceswith
lowreliabilityhavelow-S/Nvalues. ThisdemonstratesthatthestochasticityoftheDDPMmodelmostlyaffectsthe
low-S/Nsources,andtheythereforehavelowerreliability. Consequently,forsourcesdetectedwithlowS/Nusingthe
proposedmodel, reliabilitycanbeusedasanadditionalmetrictoselectmorerobustsources. Choosingareliability
thresholdof30%isawell-balancedtrade-offforthesimulateddata,allowingthemodeltohavefewFPsandFNseven
atrelativelylowS/N.ThisisdiscussedinfurtherdetailinSection4.4.
4.4 PerformancevsS/N
We study the performance of the model as a function of S/N. We use a definition of normalized injected flux from
Be´therminetal.[2020]:
totalflux b ·b
f norm = σ (cid:113) min (cid:113)maj ,
noise b2 +s2 · b2 +s2
min min maj maj
15Figure11: DependenceofF1,purity,andcompletenessscoresonthereliabilityparameterforallmodels. Reliability
isthefractionofthe20imagesinwhichasourceispresent. Theclosesttooptimalvaluewefindis30%,whichmeans
eachsourceshouldbepresentatleastin6imagesoutof20.
whereb andb aretheminorandmajoraxesofthebeam(0.82”and0.89”respectively)and s ands arethe
min maj min maj
minorandmajoraxesofthesource. TheresultsareshowninFigure13forthebestaggregationmethodamongthe
testeddiffusionmodels(seeTable2;thebestarehighlightedinboldforeachmodelandnormalization). Weconduct
acomprehensivecomparisonwiththemodelfromTaranetal.[2023]. Wealsocomparetheresultstothoseobtained
byBe´therminetal.[2020].
Allofthemodelsshowcasearobustandsignificantperformanceboost,particularlyforlowS/N,incomparisonto
previousmethods. Thisimprovementishighlightedbythefactthatallmodelsreachacompletenessscoreexceeding
90% even at a low S/N of 2, which can be compared to the score of 50% found by Taran et al. [2023] for the same
S/N.ForS/Nvalueshigherthan3,allmodelsreachcloseto100%completeness,whichmeansthattheydonotmiss
anyrealsources.
Thereliabilityassignedthroughthedetect-aggregatemethodisanticipatedtodependontheS/Nofthesource,as
demonstratedinFigure12.WeobserveatrendwheresourceswithlowerreliabilitytendtohavelowerS/Ns.However,
itisnotablethatthemodelisabletoconsistentlyreconstructmanysources,eventhosewithlowS/N.
4.5 Fluxestimation
As the proposed model is trained to recover the full sky, we also attempted to estimate the flux of the sources in
additiontotheirlocations. Heretoo,weusethePhotutilsalgorithmtoestimatethefluxofthesourcesinthepredicted
skymodels.Themodelpredictsanormalizedskymodel.Thenormalizationiseasilyinvertible,allowingustoestimate
the fluxes directly after renormalization of the model outputs. We present the results for all aggregation methods in
Figures 14 and 15. We plot the relative error fluxestimated−fluxtrue on the y-axis and the true flux (flux ) on the x-axis,
fluxtrue true
whereflux istheestimatedfluxfromthepredictedskymodelandflux isknownfromthesimulation.
estimated true
Thegrayarearepresentstheallowableerrorrange:theroot-mean-squared(rms)noiseofthesimulateddatais∼50
µJy. Ifthefluxestimationerrorfallswithinthisrange,itindicatesthatthemodel’sestimationsarerobust.
InFigure14,wecomparedifferentaggregationmethodsandexaminetheirimpactonfluxestimation. Fromthis
16Table2: Purity,completeness,andF1-score.
Metrics
Model Normalization Input Aggregation
Purity Completeness F1
singlerun 100.00 44.97 62.04
detect-aggregate 100.00 53.52 69.72
Diffusion γ=1
dirtyimage mean 99.60 93.11 96.24
median 99.83 90.84 95.12
singlerun 97.45 96.71 97.08
detect-aggregate 98.33 97.88 98.10
Diffusion γ=2 dirtyimage
mean 97.88 97.80 97.84
median 99.30 97.05 98.16
singlerun 98.66 94.66 96.62
detect-aggregate 98.90 95.69 97.27
Diffusion γ=10 dirtyimage
mean 98.51 95.23 96.84
median 99.29 94.78 96.98
singlerun 98.26 94.43 95.81
detect-aggregate 99.52 94.70 97.05
Diffusion γ=20 dirtyimage
mean 99.52 93.64 96.49
median 99.52 93.79 96.57
singlerun 98.58 93.46 94.93
detect-aggregate 99.20 94.10 96.58
Diffusion γ=30 dirtyimage
mean 98.80 93.41 96.03
median 98.81 94.25 96.47
PyBDSF - cleanimage - 72.18 20.82 32.31
Taranetal. (2023) - reduceduv-samples - 91.02 74.14 81.72
Photutilslocalization - skymodel - 99.70 99.10 99.40
Note: The localization is performed on predictions that have been renormalized to be within the same range as the original sky model. The
modelconfigurationsvaryintermsofnormalizationpowerusedduringtraining,andalsointermsoftheaggregationmethodemployed. Forthe
normalizationwithhighrootpowersγ,theoptimalaggregationmethodisdetect-aggregate. Thisapproachoffersagoodtrade-offbetweenpurity
andcompleteness,resultinginthebestF1-score.Forthelowerγ,thebestapproachturnedouttobeaggregate-detect.Wecomparetheresultswith
MohanandRafferty[2015](PyBDSF)andTaranetal.[2023].WerunthePhotutilsalgorithmdirectlyonskymodelstoquantifytheerrorcoming
fromthisstep,denotedasPhotutilslocalization.
plot,itisclearthataggregationsubstantiallyimprovestheestimatesasitaveragesouterrorsacrossallpredictions,fur-
therhighlightingthepromiseofusingstochasticmodels.Notably,thesinglerundoesnotyieldgoodresults,indicating
theimportanceofper-pixelaggregation. Asexpected,medianaggregationhasfeweroutliersthanmeanaggregation.
Aggregatingthroughthemeanismoreefficientthanthroughdetect-aggregate,makingitaviablealternative.
The detect-aggregate method is shown in Figure 15. Here for the flux of each source, we can also estimate the
uncertaintyinthefluxbymeasuringthestandarddeviationofthefluxacrossseveralruns. Weshowthisaserrorbars
onthefluxesinFigure15. Thereliabilityofeachsourceiscolor-coded: inthechosencolormap,bluecorrespondsto
sourcesdetectedinsmallfractionsofpredictions,whereasredcorrespondstosourcesthatwereconsistentlydetected
across all of them, giving a reliability of 100 %. We notice that there are very few outliers in the flux estimation.
Interestingly, their reliability scores are high. It is remarkable that the fluxes of the low-S/N sources are estimated
relativelyaccurately.
InTable3,wecomparetheproposedmethodagainstCLEAN+PyBDSF,measuringthefractionofsourceswiththe
correctfluxestimation(whithin50µJy)amongallsourcesdetected. ThemethodsignificantlyoutperformsPyBDSF
scores. Wealsonoticethatanyaggregationimprovesthescorecomparedtothesinglerunforγ≥2.
Themodeltrainedwithγ=1demonstrateslowscoresforfluxestimationinbothsingle-runanddetect-aggregatemeth-
ods. This underperformance can be attributed to the impulsiveness of the predicted images and the inability of the
17Figure12: Signal-to-noiseratioversusreliability. Lowerreliabilityvaluesarepredominantlyassociatedwithsources
thatshowlowerS/Ns. However,themodeloftenlocalizessourceswithlowS/Nswithhighconfidence.
Table3: Comparativeresultsforthefractionofthedetectedsourceswhoseestimatedfluxiswithin50µJyofthetrue
flux.
Aggregation
Model Normalization
Mean Median Singlerun Detect-aggregate
CLEAN+PyBDSF - 0.57
γ=1 0.85 0.66 0.048 0.015
γ=2 0.96 0.97 0.88 0.97
γ=10 0.92 0.93 0.71 0.89
Diffusion γ=20 0.82 0.83 0.53 0.72
γ=30 0.74 0.75 0.47 0.66
Note:Thedetect-aggregatemethodresultsarereportedforareliabilitythresholdof30%.WecompareourresultswithPyBDSF.
network to effectively reconstruct them in a single run. In this case, the detect-aggregate method also fails, as the
errors from each individual image are considerable. However, the aggregate-detect approach significantly improves
thescores,evenforthecaseofγ=1.Forbothlocalizationandflux-estimationtasks,thebestperformanceisachieved
withthemodeltrainedusingtheskymodelnormalizationapproachwithγ=2andmedianaggregationmethod.
4.6 Sensitivitytothenoise
Thedatasetusedfortrainingthemodelischaracterizedbyanoiselevelof50µJy. Duringrealobservations,thenoise
leveldoesnotremainconstant. Oneofthesourcesofnoiseisthewatervaporpresentintheatmosphere. Toensure
thatthemodelisapplicableinrealsettings,itisvitalthatitperformswellnotonlyundertheconditionsitwastrained
onbutalsowhenexposedtovaryingatmosphericconditions. Toevaluatehowtheperformanceofthemodelvariesin
responsetodifferentnoiselevels,weconductedananalysisinwhichwealtertheamountofwatervapor. Inorderto
dothis,weusedtheadditionalsimulationswithvaryingPWVparameter. Wetestedthemodelonthesedata.
The reconstruction results are shown in Figure 16. We see that all metrics decrease as the noise increases. The
modeldidexperiencedifferentS/Nduringtraining,whichexplainstherelativelysmalldecreaseintheperformance.
The localization results are illustrated in Figure 17, where we plot the model’s completeness and purity as a
functionoftheamountofwatervapor(andthereforenoiselevel). Fromthefigure,itisevidentthatastheamountof
watervaporincreases,themodel’scompletenessdecreases. Thisdeclineincompletenessindicatesthatthemodelis
18Figure13: Completenesscomparisonwithstate-of-the-artmethods. Thesestate-of-the-artmethodsoutperformtradi-
tionalalgorithmssuchasPyBDSF,whichiswhythecomparisonislimitedtothem. Alldiffusionmodelsdemonstrate
significantimprovementatlowS/N.
lesssensitivetofaintsourceswhentheyareaffectedbynoise.
Incontrast,thepurityofthemodeldoesnotexhibitasignificantdecreaseastheamountofwatervaporincreases.
Therelativestabilityofpuritysuggeststhat,eventhoughthemodelfailstodetectanincreasingnumberoftruesources
asthenoiselevelsrise(numberofFNsrises),itdoesnotproducemanyFPsbymisinterpretingnoiseasactualsources.
However,changingthewatervaporhasasignificantinfluenceonfluxestimation. Wepresenttheresultsofthese
experiments in Figure 18. It is evident that the best performance occurs at 1.796 PWV units, which corresponds to
theconditionsofthetrainingset. Amongallthemethods,detect-aggregateprovestobethemostrobusttochangesin
noise. Nevertheless,allmethodsshowasignificantdecreaseinperformanceaswatervaporlevelsincrease. Training
themodelforspecificwatervaporvaluesisneededtomaintainperformance.
5 Discussion
Themethodintroducedinthispaperdemonstratesstate-of-the-artperformanceinlocalizingpointsourcesin“dirty”
radioastronomyimages,evenunderlow-S/Nsconditions. Theresultsshowcasethecapabilityofthepresentedmodel
tooutperformexistingmethodssuchasPyBDSFinbothlocalizationandcharacterizationofthesources,andparticu-
larlyinestimatingthefluxofthesourcesforthesimulateddataset.
The primary limitation of the model is its reconstruction speed. Using an RTX 3090 GPU, the model executes
250DDPMstepsforeachofthe20realizationsandtakesapproximatelyoneminuteandeightsecondstoproducea
singleimage. Thisprocessisconductedwithabatchsizeof20,allowingfortheparallelprocessingof20realizations
simultaneously,therebyoptimizingtheGPU’scapabilities.Wenotethatrunningthese20parallelrealizationsrequires
aGPUwithatleast8GBofmemory.Thisbottleneckpresentsanareaforfuturedevelopment,withaneedtoexplore
more efficient generation techniques from diffusion models. Optimizing the speed of a DDPM is one of the main
problemsfortheengineeringresearchcommunityandseveralsolutionshavealreadybeensuggestedbyKarrasetal.
[2022].
Anadditionaldirectionofinterestistoexplorethetransferabilityoftheproposeddiffusionmodels. Wewouldlike
toseewhetherornotamodeltrainedondatafromonetelescopecansuccessfullybetransferredtoanother. Similarly,
howwellaDDPMmodeltrainedonsimulateddatacanperformwhenappliedtorealdataremainsunexplored. Also,
theportabilityofthemodeltoSKAisunknown. Thesequerieshighlightpotentiallimitationsofthecurrentapproach
19Figure14: Relativeerrorinfluxestimationcomparedtotruefluxforstudiedaggregationtechniquesacrossimages.
The gray area indicates the 1σ range. Per-pixel aggregation methods, such as the mean and median, yield reliable
estimates. Visually,themedianprovidesthemostappealingresultswiththefewestoutliers. Allresultspresentedhere
areforthemodelemployingγ=2. TheoutliersarediscussedinAppendixA.
andweplantoaddresstheminfuturework.
6 Conclusions
In this work, we introduce a new approach for interferometric image reconstruction in astronomy using diffusion
models, inparticulartheconditionaldenoisingdiffusionprobabilisticmodel(DDPM).TheDDPMmodelistrained,
validated, andtestedonsimulateddeepALMAobservationsofextra-galactictargetspreviouslyusedbyTaranetal.
[2023]. In the proposed approach, we take the dirty images produced from simulated UV visibilities as input with
somepreprocessingandreturnasetofdifferentskymodels. GiventheinherentstochasticityofDDPMmodels, the
described model produces multiple sky models for the same dirty image. We propose two different approaches to
aggregate the predictions: aggregate-detect and detect-aggregate. The properties of the sources are extracted from
predicted sky models using the Photutils algorithm. We compare locations and flux values from our DDPM model
withthetrueskymodelfromthesimulations. Wedeviseasimplediagnostictomeasurethereliabilityofasourcein
predicted sky models. We demonstrate that the DDPM model can be used to perform source localization with high
purityandcompleteness. Finally,weshowthatitcanalsobeusedtoaccuratelyestimatesourceflux.
Ourmainresultscanbesummarizedasfollows:
20Figure15: Relativeerrorinfluxestimationascomparedtotrueflux, aggregatedacrosssourcesfromeachpredicted
image(detect-aggregatemethod).Thegrayareaindicatesthe1σrange.Theerrorbarsrepresentthestandarddeviation
ofthefluxestimatesobtainedfromeachprediction. Thecolorscalerepresentsthereliability. Theresultsshowcased
herearebasedonthemodelthatusesγ=2. TheoutliersarediscussedintheAppendixA.
• Aggregatingtheskymodelsfrommultiplerunsofthedescribedmodelusingmeanormediantechniquespro-
duces a good representation of the true sky model. Producing a larger number of such runs (∼ 20) produces
aggregatedskymodelswithlowMSEandhighpeakS/NandSSIM.
• Theproposedmodelfurtherperformsanevenbetterimagereconstructionifwepreprocessthetrueskymodels
whiletrainingwithapowerγ=2inEquation1.
• TheDDPM-basedapproachprovidesasignificantimprovementinsourcelocalizationovertraditionalmethods
intermsofpurityandcompleteness,particularlyatlowS/N.
• ForS/N=2,thedescribedmodeldemonstrates70%accuracywithoutanynormalizationtechniques,outperform-
ingthepreviousstate-of-artalgorithm,PyBDSF,whichachieves55%accuracy.
• Wefindthatn=5runsisoptimal,allowingthemodeltoobtainanF1-scoreofabove98%.
• Weintroduceamethodtoestimatethereliabilityofthepredictedsourcesusingtheinherentstochasticnatureof
DDPM.
• Wealsoproposeaframeworkforestimatingthefluxesofsourcesasthemethodfocusesonreconstructingthe
skymodel. TheperformancesurpassesthatofPyBDSFby32%intermsofthefractionofsourcesforwhichthe
fluxisestimatedwithinthenoiselevel.
• Wealsoexaminetheinfluenceofthenormalizationpower,γ,oftheroottransformationontheefficiencyofthe
method. Ourfindingssuggestthattrainingwithγ=2isoptimalforbothlocalizationandfluxestimation.
• We study the impact of noise magnitude by varying water vapor levels. The model’s completeness drops to
88%, yet its purity stays consistent, suggesting that it identifies few false positives despite increased noise.
Adapting the model to specific water vapor values is crucial when using it for flux estimation, though the
proposedapproachconsistentlyoutperformsPyBDSF.
In summary, we developed a novel DDPM-based method for source detection and flux estimation that operates
directlyondirtyimages. Thisapproachofferssignificantimprovementsoverexistingalgorithmsinsourcedetection
acrossallS/Ns.
21Figure 16: Impact of water vapor on reconstruction metrics. The MSE, SSIM, and peak S/N values are normalized
to highlight trends. As the amount of water vapor in the atmosphere increases, the quality of the reconstruction
diminishes,evidencedbythedecreasingSSIMandpeakS/N,andtheincreasingMSE.
Acknowledgements
M. Drozdova and V. Kinakh are supported by the RODEM: Robust deep density models for high-energy particle
physics and solar flare analysis Sinergia Project funded by the Swiss National Science Foundation, grant number
CRSII5-193716.O.TaranandO.BaitaresupportedbytheAstroSignalsSinergiaProjectfundedbytheSwissNational
ScienceFoundation,grantnumberCRSII5-193826. Wealsowouldliketothanktheeditorandrefereefortheiruseful
comments.
References
Kazunori Akiyama, Antxon Alberdi, Walter Alef, Keiichi Asada, Rebecca Azulay, Anne-Kathrin Baczko, David
Ball, Mislav Balokovic´, John Barrett, Dan Bintley, et al. First m87 event horizon telescope results. ii. array and
instrumentation. TheAstrophysicalJournalLetters,875(1):L2,2019.
Ben Bean, Sanjay Bhatnagar, Sandra Castro, Jennifer Donovan Meyer, Bjorn Emonts, Enrique Garcia, Robert Gar-
wood,KumarGolap,JustoGonzalezVillalba,PamelaHarris,etal. Casa,commonastronomysoftwareapplications
forradioastronomy. PublicationsoftheAstronomicalSocietyofthePacific,134(1041):114501,2022.
M.Be´thermin,Y.Fudamoto,M.Ginolfi,F.Loiacono,Y.Khusanova,P.L.Capak,P.Cassata,A.Faisst,O.LeFe`vre,
D.Schaerer,J.D.Silverman,L.Yan,R.Amorin,S.Bardelli,M.Boquien,A.Cimatti,I.Davidzon,M.Dessauges-
Zavadsky, S. Fujimoto, C. Gruppioni, N. P. Hathi, E. Ibar, G. C. Jones, A. M. Koekemoer, G. Lagache, B. C.
Lemaux,C.Moreau,P.A.Oesch,F.Pozzi,D.A.Riechers,M.Talia,S.Toft,L.Vallini,D.Vergani,G.Zamorani,
and E. Zucca. The ALPINE-ALMA [CII] survey: Data processing, catalogs, and statistical source properties.
Astronomy&Astrophysics,643:A2,oct2020. doi: 10.1051/0004-6361/202037649. URLhttps://doi.org/10.
1051%2F0004-6361%2F202037649.
22Figure17: Impactofwatervaporonlocalizationmetrics. Thepurityexhibitsarelativechangeofabout1%,whilethe
completenessdecreasessignificantlyby4%. ThemodeldoesnotidentifymanyFPsasthenoiselevelsincrease,but
itscapabilitytoaccuratelydetectexistingsourcesdiminishesrapidly. Notably,evenwiththehighestnoiselevels,the
completenessscoreoutperformsthepreviousscoresonthetestsetwiththelowwatervapornoise. Thedashedlineis
at1.796PWVunits,whichcorrespondstothetrainingdata.
M Be´thermin, Y Fudamoto, M Ginolfi, F Loiacono, Y Khusanova, PL Capak, P Cassata, A Faisst, O Le Fe`vre,
DSchaerer,etal. Thealpine-alma[cii]survey: Dataprocessing,catalogs,andstatisticalsourceproperties. Astron-
omy&Astrophysics,643:A2,2020.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and
Statistics). Springer, 1 edition, 2007. ISBN 0387310738. URL http://www.amazon.com/
Pattern-Recognition-Learning-Information-Statistics/dp/0387310738%3FSubscriptionId%
3D13CT5CVB80YFWJEPWS02%26tag%3Dws%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%
26creativeASIN%3D0387310738.
R. J. Bouwens, R. Smit, S. Schouws, M. Stefanon, R. Bowler, R. Endsley, V. Gonzalez, H. Inami, D. Stark,
P.Oesch,J.Hodge,M.Aravena,E.daCunha,P.Dayal,I.deLooze,A.Ferrara,Y.Fudamoto,L.Graziani,C.Li,
T.Nanayakkara,A.Pallottini,R.Schneider,L.Sommovigo,M.Topping,P.vanderWerf,H.Algera,L.Barrufet,
A. Hygate, I. Labbe´, D. Riechers, and J. Witstok. Reionization Era Bright Emission Line Survey: Selection and
CharacterizationofLuminousInterstellarMediumReservoirsinthez¿6.5Universe. ApJ,931(2):160,June2022.
doi: 10.3847/1538-4357/ac5a4a.
Larry Bradley, Brigitta Sipocz, Thomas Robitaille, Erik Tollerud, Christoph Deil, Ze` Vin´ıcius, Kyle Barbary,
Hans Moritz Gu¨nther, Azalee Bostroem, Michael Droettboom, et al. Photutils: Photometry tools. Astrophysics
SourceCodeLibrary,pagesascl–1609,2016.
B.G.Clark. Anefficientimplementationofthealgorithm’CLEAN’. A&A,89(3):377,September1980.
Liam Connor, Katherine L Bouman, Vikram Ravi, and Gregg Hallinan. Deep radio-interferometric imaging with
polish: Dsa-2000andweaklensing. MonthlyNoticesoftheRoyalAstronomicalSociety,514(2):2614–2626,2022.
J.E.Conway,T.J.Cornwell,andP.N.Wilkinson.Multi-frequencysynthesis:anewtechniqueinradiointerferometrie
imaging. MNRAS,246:490,October1990.
TJCornwellandKFEvans.Asimplemaximumentropydeconvolutionalgorithm.AstronomyandAstrophysics(ISSN
0004-6361),vol.143,no.1,Feb.1985,p.77-83.,143:77–83,1985.
23Figure18:Influenceofwatervaporonfractionofpointsourceswhosepredictedfluxfallswithinnoiseamplitudefrom
trueflux. Aswatervaporlevelsrise,thisfractionsignificantlydecreases. ThedashedlinerepresentsaPWVvalueof
1.796units,whichcorrespondstotheconditionsofthetrainingdata.
PrafullaDhariwalandAlexanderNichol. Diffusionmodelsbeatgansonimagesynthesis. Advancesinneuralinfor-
mationprocessingsystems,34:8780–8794,2021.
A. L. Faisst, D. Schaerer, B. C. Lemaux, P. A. Oesch, Y. Fudamoto, P. Cassata, M. Be´thermin, P. L. Capak, O. Le
Fe`vre, J. D. Silverman, L. Yan, M. Ginolfi, A. M. Koekemoer, L. Morselli, R. Amor´ın, S. Bardelli, M. Boquien,
G. Brammer, A. Cimatti, M. Dessauges-Zavadsky, S. Fujimoto, C. Gruppioni, N. P. Hathi, S. Hemmati, E. Ibar,
G. C. Jones, Y. Khusanova, F. Loiacono, F. Pozzi, M. Talia, L. A. M. Tasca, D. A. Riechers, G. Rodighiero,
M.Romano,N.Scoville,S.Toft,L.Vallini,D.Vergani,G.Zamorani,andE.Zucca. TheALPINE-ALMA[CII]
Survey: Multiwavelength Ancillary Data and Basic Physical Measurements. ApJS, 247(2):61, April 2020. doi:
10.3847/1538-4365/ab7ccd.
Thorben Finke, Michael Kra¨mer, Alessandro Morandini, Alexander Mu¨ck, and Ivan Oleksiyuk. Autoencoders for
unsupervisedanomalydetectioninhighenergyphysics. JournalofHighEnergyPhysics,2021(6),jun2021. doi:
10.1007/jhep06(2021)161. URLhttps://doi.org/10.1007%2Fjhep06%282021%29161.
MFranco,DElbaz,MBe´thermin,BMagnelli,CSchreiber,LCiesla,MDickinson,NNagar,JSilverman,Emanuele
Daddi, et al. Goods-alma: 1.1 mm galaxy survey-i. source catalog and optically dark galaxies. Astronomy &
Astrophysics,620:A152,2018.
Claudio Gheller and Franco Vazza. Convolutional deep denoising autoencoders for radio astronomical images.
MonthlyNoticesoftheRoyalAstronomicalSociety,509(1):990–1009,2022.
StephenF.GullandGeoffreyJ.Daniell. Imagereconstructionfromincompleteandnoisydata. Nature,272:686–690,
1978. URLhttps://api.semanticscholar.org/CorpusID:4163124.
JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. Advancesinneuralinformation
processingsystems,33:6840–6851,2020.
J.A.Ho¨gbom. ApertureSynthesiswithaNon-RegularDistributionofInterferometerBaselines. A&AS,15:417,June
1974.
24JA Ho¨gbom. Aperture synthesis with a non-regular distribution of interferometer baselines. Astronomy and Astro-
physicsSupplementSeries,15:417,1974.
AWHotan,JDBunton,APChippendale,MWhiting,JTuthill,VAMoss,DMcConnell,SWAmy,MTHuynh,JRAl-
lison, etal. Australiansquarekilometrearraypathfinder: I.systemdescription. PublicationsoftheAstronomical
SocietyofAustralia,38:e009,2021.
J. Jonas and MeerKAT Team. The MeerKAT Radio Telescope. In MeerKAT Science: On the Pathway to the SKA,
page1,January2016. doi: 10.22323/1.277.0001.
TeroKarras,MiikaAittala,TimoAila,andSamuliLaine. Elucidatingthedesignspaceofdiffusion-basedgenerative
models. AdvancesinNeuralInformationProcessingSystems,35:26565–26577,2022.
OLeFe`vre,MBe´thermin,AFaisst,GCJones,PCapak,PCassata,JDSilverman,DSchaerer,LYan,RAmorin,etal.
Thealpine-alma[cii]survey-surveystrategy,observations,andsamplepropertiesof118star-forminggalaxiesat4¡
z¡6. Astronomy&Astrophysics,643:A1,2020.
DaizhongLiu,EvaSchinnerer,BrentGroves,BMagnelli,PhilippLang,SLeslie,EJime´nez-Andrade,DARiechers,
GergoPopping,GeorgiosEMagdis,etal. Automatedminingofthealmaarchiveinthecosmosfield(a3cosmos).
ii.coldmoleculargasevolutionouttoredshift6. TheAstrophysicalJournal,887(2):235,2019.
Joseph P McMullin, BSDYWGK Waters, Darrell Schiebel, Wei Young, and Kumar Golap. Casa architecture and
applications. InAstronomicaldataanalysissoftwareandsystemsXVI,volume376,page127,2007.
NirujMohanandDavidRafferty. Pybdsf:Pythonblobdetectionandsourcefinder. AstrophysicsSourceCodeLibrary,
pagesascl–1502,2015.
Ramesh Narayan and Rajaram Nityananda. Maximum entropy image restoration in astronomy. Annual review of
astronomyandastrophysics,24(1):127–170,1986.
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image
generationwithcliplatents. arXivpreprintarXiv:2204.06125,1(2):3,2022.
Urvashi Rau and Tim J Cornwell. A multi-scale multi-frequency deconvolution algorithm for synthesis imaging in
radiointerferometry. Astronomy&Astrophysics,532:A71,2011.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image seg-
mentation. In Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International
Conference,Munich,Germany,October5-9,2015,Proceedings,PartIII18,pages234–241.Springer,2015.
LeonidRudin,StanleyOsher,andEmadFatemi. Nonlineartotalvariationbasednoiseremovalalgorithms. Physica
D:NonlinearPhenomena,60:259–268,111992. doi: 10.1016/0167-2789(92)90242-F.
ChitwanSaharia,WilliamChan,HuiwenChang,ChrisLee,JonathanHo,TimSalimans,DavidFleet,andMohammad
Norouzi. Palette: Image-to-imagediffusionmodels. InACMSIGGRAPH2022ConferenceProceedings,pages1–
10,2022.
AMMScaife. Bigtelescope,bigdata: towardsexascalewiththesquarekilometrearray. PhilosophicalTransactions
oftheRoyalSocietyA,378(2166):20190060,2020.
Kevin Schmidt, Felix Geyer, Stefan Fro¨se, P-S Blomenkamp, Marcus Bru¨ggen, Francesco de Gasperin, Dominik
Elsa¨sser,andWolfgangRhode. Deeplearning-basedimaginginradiointerferometry. Astronomy&Astrophysics,
664:A134,2022.
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using
nonequilibrium thermodynamics. In International conference on machine learning, pages 2256–2265. PMLR,
2015.
25O. Taran, O. Bait, M. Dessauges-Zavadsky, T. Holotyak, D. Schaerer, and S. Voloshynovskiy. Challenging inter-
ferometric imaging: Machine learning-based source localization from uv-plane observations. Astronomy & As-
trophysics,may2023. doi: 10.1051/0004-6361/202245778. URLhttps://doi.org/10.1051%2F0004-6361%
2F202245778.
Andrey N. Tikhonov and Vasiliy Y. Arsenin. Solutions of ill-posed problems. V. H. Winston & Sons, Washington,
D.C.: JohnWiley&Sons,NewYork,1977. TranslatedfromtheRussian,PrefacebytranslationeditorFritzJohn,
ScriptaSeriesinMathematics.
Steven John Tingay, Robert Goeke, Judd D Bowman, David Emrich, Stephen M Ord, Daniel A Mitchell, Miguel F
Morales,TomBooler,BrianCrosse,RandallBWayth,etal. Themurchisonwidefieldarray: Thesquarekilometre
arrayprecursoratlowradiofrequencies. PublicationsoftheAstronomicalSocietyofAustralia,30:e007,2013.
Emma Tolley, Simon Frasch, Etienne Orliac, Shreyam Krishna, Michele Bianco, Sepand Kashani, Paul Hurley,
Matthieu Simeoni, and Jean-Paul Kneib. Bipp: An efficient hpc implementation of the bluebild algorithm for
radioastronomy,2023.
StefanVanderWalt,JohannesLScho¨nberger,JuanNunez-Iglesias,Franc¸oisBoulogne,JoshuaDWarner,NeilYager,
EmmanuelleGouillart,andTonyYu. scikit-image: imageprocessinginpython. PeerJ,2:e453,2014.
Michael P van Haarlem, Michael W Wise, AW Gunst, George Heald, John P McKean, Jason WT Hessels, A Ger
deBruyn,RonaldNijboer,JohnSwinbank,RichardFallows,etal. Lofar: Thelow-frequencyarray. Astronomy&
astrophysics,556:A2,2013.
AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,ŁukaszKaiser,andIllia
Polosukhin. Attentionisallyouneed. Advancesinneuralinformationprocessingsystems,30,2017.
Fabian Walter, Roberto Decarli, Manuel Aravena, Chris Carilli, Rychard Bouwens, Elisabete Da Cunha, Emanuele
Daddi, Robert J Ivison, Dominik Riechers, Ian Smail, et al. Alma spectroscopic survey in the hubble ultra deep
field: surveydescription. TheAstrophysicalJournal,833(1):67,2016.
RuoqiWang,ZhuoyangChen,QiongLuo,andFengWang. Aconditionaldenoisingdiffusionprobabilisticmodelfor
radiointerferometricimagereconstruction. arXivpreprintarXiv:2305.09121,2023.
ZhouWang,AlanC.Bovik,HamidR.Sheikh,andEeroP.Simoncelli. Imagequalityassessment:fromerrorvisibility
to structural similarity. IEEE Transactions on Image Processing, 13(4):600–612, 2004. URL http://dblp.
uni-trier.de/db/journals/tip/tip13.html#WangBSS04.
NorbertWiener. Extrapolation,interpolation,andsmoothingofstationarytimeseries,withengineeringapplications.
TechnologyPressoftheMassachusettsInstituteofTechnology,Cambridge,1949.
A Outliers
InFigures14and15,weobservetheoutliersthatpersistirrespectiveoftheaggregationmethodused. Weselectedfive
sources exhibiting the greatest relative error for further analysis. The problematic sources are those that are located
in close proximity to each other. The dataset includes two images where two sources share identical coordinates, a
scenario that the proposed method cannot discern correctly. Instead of distinguishing the two, the model predicts a
singlesourcewithafluxequivalenttothesumofthefluxesfromthecloselysituatedsources. Thefiftherroroccurs
when sources are located near one another, but not with identical coordinates; while the flux of one is accurately
determined,theotherispredictedtobesubstantiallylargerthanitsactualvalue. Thisdiscrepancycanpotentiallybe
influencedbytheproximityoftheneighboringsource,asthepredictedfluxisofacomparablemagnitude. Detailed
resultsarepresentedinTable4.
26Table4: Mostextremeoutliers: sourceswithlargestestimationerrorsinfluxbyDDPM
DataType Ra Dec Flux(µJy)
Real 150.192944 3.995500 309
Real 150.192944 3.995500 429
Predicted 150.192945 3.995501 738
Note:TheseoutliersarefromtheFigures14and15.Theproposed
Real 149.655167 3.643278 238 algorithm fails when sources are overlapping each other. When
Real 149.655167 3.643278 113 there is exact overlap, the prediction is a source with a flux that
isapproximatelyequaltothesumofthefluxesoftheoverlapping
Predicted 149.655165 3.643277 346
truesources(firsttwosections).
Real 148.163222 1.370722 126
Real 148.163222 1.370444 400
Predicted 148.163220 1.370729 399
Predicted 148.163223 1.370444 436
Figure19: S/Nversusreliabilityforγ=1.
B Diffusion without scaling
ThissectionpresentsplotsforaDDPMmodelwithγ = 1inpreprocessingduringtraininginEquation1. Figure19
illustrates the absence of detected low-S/N sources and a more uniformly spread reliability parameter compared to
γ=2.
Figures20and21showthattheproposedmodelconsistentlyunderestimatesfluxvaluesforallrangesinasingle
run.Nevertheless,aggregationmethods,suchasmeanandmedian,significantlyaid,unlikethedetect-aggregatemethod,
which performs poorly, which is likely due to the consistent underestimation of sources in a single run. Thus, di-
rectlyaveragingthesepredictionsdoesnotimprovethevalue. However,averagingoverimagepixels(asaggregate-
detectdoes)increasesthesourcearea,correctingoverallfluxvalues.
Figures22and23demonstratethedependencyoflocalizationandreconstructionmetricsonthenumberofruns
forγ = 1. Thereconstructionmetricsfollowthesamepatternasγ = 2: agreaternumberofimagesequatestobetter
metrics. Thelocalizationmetricsexhibitadifferentbehavior: asinglerunhasverylowcompleteness,lessthan50%
comparedto96%forγ =2. Forγ =1,thecompletesimprovesslowerthanforγ =2,notsurpassing95%evenafter
20runs,contraryto98%forγ=2.
27Figure20: Fluxestimationfordifferentaggregate-detectmethodsγ=1.
Figure21: Fluxestimationfordetect-aggregateforγ=1.
28Figure22: Localizationmetricsforγ=1.
Figure23: Normalizedmetricsforγ=1.
29