Hierarchical State Space Models
for Continuous Sequence-to-Sequence Modeling
RaunaqBhirangi12 ChenyuWang3 VenkateshPattabiraman3 CarmelMajidi1 AbhinavGupta1
TessHellebrekers2 LerrelPinto3
Abstract
Reasoningfromsequencesofrawsensorydatais
aubiquitousproblemacrossfieldsrangingfrom
medicaldevicestorobotics.Theseproblemsoften
involveusinglongsequencesofrawsensordata
CSP
(e.g. magnetometers, piezoresistors) to predict
sequences of desirable physical quantities (e.g. Bench Time (in seconds)
force, inertial measurements). While classical Transformer
LSTM
approachesarepowerfulforlocally-linearpredic-
Mamba
tion problems, they often fall short when using S4
HiSS
real-world sensors. These sensors are typically
Normalized Mean Squared Error
non-linear, areaffectedbyextraneousvariables on CSP-Bench (↓)
(e.g. vibration),andexhibitdata-dependentdrift.
Formanyproblems, thepredictiontaskisexac- Figure1.CSP-Benchisapubliclyaccessiblebenchmarkforcon-
tinuoussequencepredictiononreal-worldsensorydata.Weshow
erbatedbysmalllabeleddatasetssinceobtaining
thatHierarchicalStateSpaceModels(HiSS)improveoverconven-
ground-truthlabelsrequiresexpensiveequipment.
tionalsequencemodelsonsequentialsensorypredictiontasks.
Inthiswork,wepresentHierarchicalState-Space
Models(HiSS),aconceptuallysimple,newtech-
sensorydata-iscentraltoreal-timedecision-makingand
niqueforcontinuoussequentialprediction. HiSS
control(Schu¨tzeetal.,2004;Stetcoetal.,2019). Yet,ithas
stacks structured state-space models on top of
received limited attention compared to discrete sequence
eachothertocreateatemporalhierarchy. Across
problemsindomainslikelanguage(Devlinetal.,2018)and
sixreal-worldsensordatasets,fromtactile-based
computervision(Dengetal.,2009).
state prediction to accelerometer-based inertial
measurement,HiSSoutperformsstate-of-the-art Existingapproachesforpredictionfromsensorydatahave
sequence models such as causal Transformers, largelyreliedonmodel-basedsolutions(Welchetal.,1995;
LSTMs, S4, and Mamba by at least 23% on Daum,2005). However,theseapproachesrequiredomain
MSE.OurexperimentsfurtherindicatethatHiSS expertiseandaccuratemodelingofcomplexsystemdynam-
demonstratesefficientscalingtosmallerdatasets ics, which is often intractable in real-world applications.
andiscompatiblewithexistingdata-filteringtech- Moreover,sensorydatacontainsnoiseandsensor-specific
niques. Code,datasetsandvideoscanbefound driftthatmustbeaccountedfortoachievehighpredictive
onhttps://hiss-csp.github.io. performance(Liuetal.,2020b). Inthiswork,weinvestigate
deepsequence-to-sequencemodelsthatcanaddressthese
challengesbylearningdirectlyfromrawsensorystreams.
1.Introduction
However, to make progress on continuous sequence pre-
Sensors are ubiquitous. From air conditioners to smart- diction(CSP),wefirstneedarepresentativebenchmarkto
phones,automatedsystemsanalyzesensorydatasequences measureperformance. MostpriorworksinCSPfocusona
tocontrolvariousparameters. Thisclassofproblems-con- singleclassofsensors(Herathetal.,2020;Liuetal.,2020b),
tinuous sequence-to-sequence prediction from streaming makingitdifficulttodevelopgeneral-purposealgorithms.
Toaddressthis,wecreatedCSP-Bench,abenchmarkcon-
1CarnegieMellonUniversity,Pittsburgh,USA2FAIR,Meta
sisting of six real-world labeled datasets. This collection
3NewYorkUniversity,NYC,USA.Correspondenceto:Raunaq
Bhirangi<rbhirang@cs.cmu.edu>. consistsofthreedatasetscreatedin-houseandthreecurated
frompriorwork–acumulative40hoursofreal-worlddata.
1
4202
beF
51
]GL.sc[
1v11201.2042:viXra
retemotengaM
noitisop
rekraM
langis
)mc(
x niHiSS:HierarchicalStateSpaceModels
GivendatafromCSP-Bench,anobviousmodelingchoice etal.,2016)andinertialodometry(Aminietal.,2011;Liu
is to use state-of-the-art sequence models like LSTMs or etal.,2020a),oftenprocessnoisysensorydatatodeduce
Transformers. However, sensory data is high-frequency, environmental states. Traditionally, these problems were
leadingtolongsequencesofhighlycorrelateddata.Forsuch solved as estimation and control problems using filtering
data,Transformersquicklyrunoutofmemory,astheyscale techniques, like the Kalman Filter (Mathieu et al., 2012;
quadraticallyincomplexitywithsequencelength(Vaswani Simon, 2006), that still require complex sensor models.
etal.,2017),whileLSTMsrequiresignificantlylargerhid- Deeplearninghasshownpromiseindomainswithoutan-
denstates(Kuchaiev&Ginsburg,2017). DeepStateSpace alyticalmodels,yetmanysolutionscontinuetobesensor-
Models(SSMs)(Guetal.,2021a;Gu&Dao,2023)area specific(Yanetal.,2018;Herathetal.,2020).
promising new class of sequence models. These models
DeepStateSpaceModels(SSMs) (Guetal.,2021a;Poli
havebeenshowntoeffectivelyhandlelongcontextlengths
et al., 2023; Smith et al., 2022; Gu & Dao, 2023) are an
whilescalinglinearlywithsequencelengthintimeandmem-
emergingclassofmodelsthatimproveoverconventional
ory complexity, with strong results on audio (Goel et al.,
sequence models in modeling long-range dependencies –
2022)andlanguagemodeling. OnCSP-Bench,wefindthat
animportantconsiderationforhigh-frequencysensorydata.
SSMs consistently outperform LSTMs and Transformers
However, to the best of the authors’ knowledge, none of
withanaverageof10%improvementonMSEmetrics(see
these models have been evaluated on continuous sensing
Section6). Butcanwedobetter?
data beyond audio (Goel et al., 2022). In this work, we
A key insight into continuous sensor data is that it has a benchmarkdeepSSMsonsixsensorysequence-to-sequence
significantamountoftemporalstructureandredundancies. prediction tasks on sensors such as ReSkin, XELA, ac-
While SSMs are powerful for modeling this type of data, celerometers,andgyroscopes.
theyarestilltemporallyflatinnature,i.e. everysamplein
thesequenceisreasonedwitheveryothersample.Therefore, 2.2.HierarchicalModeling
inspiredbyworkinhierarchicalmodeling(Youetal.,2019;
Incorporatingtemporalhierarchiesintosequencemodeling
Thu & Han, 2021), we propose Hierarchical State-Space
architectureshasbeenshowntoimproveperformanceacross
Models(HiSS).HiSSstackstwoSSMswithdifferenttem-
a number of tasks like recommender systems (You et al.,
poralresolutionsontopofeachother. Thelower-levelSSM
2019),humanactivityrecognition(Thu&Han,2021)and
temporallychunksthelargerfull-sequencedataintosmaller
reinforcementlearning(Suttonetal.,1999;Gardiol,2000;
sequencesandoutputslocalfeatures,whilethehigher-level
Kulkarnietal.,2016). HiSSisinspiredbythislineofwork
SSMoperatesonthesmallersequenceoflocalfeaturesto
andextendsittoSSMsforcontinuousseq-to-seqtasks.
outputglobalsequenceprediction. Thisleadstofurtherim-
provedperformanceonCSP-Bench,outperformingthebest
flatSSMsby23%medianMSEperformanceacrosstasks. 2.3.DataforContinuousSequencePrediction
Wesummarizethecontributionsofthispaperasfollows:
A primary challenge with developing general models for
continuoussequencepredictionisthelackofaconcreteeval-
1. WereleaseCSP-Bench,thelargestpubliclyaccessible
uationbenchmark. Odometry/SLAMdatasets(Geigeretal.,
benchmarkforcontinuoussequence-to-sequencepredic-
2013;Maddernetal.,2017)areviablecandidates(Chang
tionformultiplesensordatasets. (Section4)
etal.,2019;Sunetal.,2020)forCSPdatasets. Butmost
2. WeshowthatSSMsoutperformpriorSOTAmodelslike dataacrosssensorymodalitieslikeaudio(Warden,2018;
LSTMsandTransformersonCSP-Bench. (Section6.1) Gemmekeetal.,2017),ECG(Moody&Mark,2001;Wag-
neretal.,2020), IMU(Chavarriagaetal.,2013;Micucci
3. WeproposeHiSS,ahierarchicalsequencemodelingar-
et al., 2017; Chen et al., 2021) and tactile sensing (Pinto
chitecturethatfurtherimprovesuponSSMsacrosstasks
etal.,2016;Funabashietal.,2019;Bhirangietal.,2023)is
inCSP-Bench. (Section5)
labeledsparselyonlyatthesequencelevel.
4. We show that HiSS increases sample efficiency with
Therecentproliferationofsensorsinsmartphonesandother
smaller datasets, and is compatible with standard sen-
smartdeviceshasresultedinrenewedinterestincreating
sorpre-processingtechniquessuchaslow-passfiltering.
labeleddatasetsforCSP(Chenetal.,2018;Herathetal.,
(Sections6.4,6.5)
2020). Acommonsettingistouseamotioncapturesystem
to obtain dense, sequential labels for sensory data from
2.RelatedWork
inexpensiveIMUsensors(Trumbleetal.,2017;Gaoetal.,
2022). Inthiswork,wecuratethreesuchdatasetsaspartof
2.1.Sequence-to-sequencepredictionforsensorydata
CSP-Bench: acontinuoussequencepredictionbenchmark.
Mostrealworldcontrolsystems,suchaswindturbinecondi-
AnothercategoryofsensorsofsignificantinterestforCSP
tionmonitoring(Stetcoetal.,2019),MRIrecognition(Kong
2HiSS:HierarchicalStateSpaceModels
are touch sensors. Touch sensors capture the dynamics generalform,alinearstatespacemodelmaybewrittenas,
of contact between the robot and its surroundings. Deep
learning and rapid prototyping have driven a rapid surge
x′(t)=A(t)x(t)+B(t)u(t)
acrossarangeoftactilemodalitiesfromoptical(Lambeta y(t)=C(t)x(t)+D(t)u(t),
etal.,2020;Yuanetal.,2017)tocapacitative(Sonaretal.,
2018)andmagneticsensing(Tomoetal.,2018;Bhirangi mapping a 1-D input sequence u(t) ∈ R to a 1-D output
et al., 2021). Most work on continuously reasoning over sequence y(t) ∈ R through an implicit N-D latent state
tactiledataisdirectedtowardspolicylearning(Guzeyetal., sequencex(t) ∈ Rn. Concretely,deepSSMsseektouse
2023a;b;Calandraetal.,2018),wheresmalldatasetsand stacksofthissimplemodelinaneuralsequencemodeling
confoundingfactorsmakeitdifficulttoevaluatetheefficacy architecture,wheretheparameters,A,B,CandDforeach
ofarchitecturesforCSP.Inthiswork,wesetupsupervised layercanbelearnedviagradientdescent.
learningproblemstoinvestigatesequence-to-sequencemod-
SSMshavebeenproventohandlelong-rangedependencies
elsfortwomagnetictactilesensors: ReSkin(Bhirangietal.,
theoretically and empirically (Gu et al., 2021b) with lin-
2021)andXELA(Tomoetal.,2018).
ear scaling in sequence length, but were computationally
prohibitiveuntilStructuredStateSpaceSequenceModels
3.Background
(S4)(Guetal.,2021a). S4andrelatedarchitecturesby(Fu
etal.,2022;Smithetal.,2022;Polietal.,2023)arebasedon
3.1.Sequence-to-sequencePrediction
anewparameterizationthatreliesontime-invarianceofthe
Consideradata-generatingprocessdescribedbytheHid- SSMparameterstoenableefficientcomputation. Recently,
denMarkovModelinFigure2. Theobservableprocesses Mamba(Gu&Dao,2023)improvedonS4-basedarchitec-
–sensor,S,andoutput,Y,representtwomeasurementde- turesbyrelaxingthetime-invarianceconstraintonSSMpa-
vices that capture the evolution of the unobserved latent rameters,whilemaintainingcomputationalefficiency. This
process, X. Generally, S is a noisy, low-cost device like allowsMambatoachievehighperformanceonarangeof
an accelerometer, and Y is a precise, expensive labeling benchmarksfromaudioandgenomicstolanguagemodel-
systemlikeMotionCapture. Thegoalistolearnamodel ing,whilemaintaininglinearscalinginsequencelength. In
thatallowsustoestimateY usingdatasequencesfromS. this paper, we benchmark the performance of SSMs like
S4andMambaonsensoryCSPtasks,andshowthatthey
consistentlyoutperformLSTMsandTransformers.
x x … x
1 2 k 4.CSP-Bench: AContinuousSequence
PredictionBenchmark
s y s y s y
1 1 2 2 k k Weaddressthescarcityofdatasetswithdense,continuous
labels for sequence-to-sequence prediction by collecting
Figure2.HiddenMarkovModelforatwo-sensorsystem. X is threetouchdatasetswith1000trajectorieseachandcombin-
a data-generating process. Sensor, S, and output, Y, are two ingthemwiththreeIMUdatasetsfromliteraturetocreate
observableprocesses. CSP-Bench. For each dataset, we design tasks to predict
labeledsequencesfromsinglesensordatatoavoidconfound-
ingfactors. Wealsoincludedatafromvariedsourceslike
TheCSPprobleminvolvesestimatingtheprobabilityofthe camerasandrobotmovementstofacilitatefutureresearch
t-thoutputobservation,y ,giventhehistoryofinputobser- inmulti-sensorintegrationandmultimodallearning. The
t
vations, s . Fortheexperimentslistedinthispaper, we detailedcharacteristicsofthesedatasetsaresummarizedin
1:t
approximatethisprobabilitybyaGaussianwithconstant Table1,aimingtosupportdiversesensorydataanalysis.
standarddeviation,ie. p(y |s ,...s )=N(µ (s ),σ2I),
t 1 t θ 1:t
where σ is a constant, and parameterize µ θ by a deep se- 4.1.TouchDatasets
quence model. Our goal is to find the maximum likeli-
(cid:80) Ourtouchdatasetsarecollectedontwomagnetictactilesen-
hood estimator for this distribution – argmin ∥y −
µ (s )∥2. Therefore,ourmodelsaretrainedtθ omit nimt ize sordesigns: ReSkin(Bhirangietal.,2021)andXela(Tomo
θ 1:t
etal.,2018). TheReSkinsetupconsistsofa6-DOFKinova
MSElossoverthelengthoftheoutputsequence.
JACOGen1robotwitha1-DOFRG2OnRobotgripperas
shown in Figure 3. Both gripper surfaces are sensorized
3.2.DeepStateSpaceModels
witha32mm×30mm×2mmReSkinsensor. Eachsensor
Deep State Space Models (SSMs) build on simple state hasfive3-axismagnetometerswhichmeasurechangesin
space models for sequence-to-sequence modeling. In its magneticfluxresultingfromthedeformationoftheskinon
3HiSS:HierarchicalStateSpaceModels
ReSkin Marker Writing ReSkin Intrinsic Slip XELA Joystick Control Total Capture
RoNIN VECtor
ReSkin
Skin
Circuit
Figure3.CSP-Benchiscomprisedofsixdatasets.Threedatasets–ReSkinMarkerWriting,ReSkinIntrinsicSlipandXELAJoystick
Controlaretactiledatasetscollectedin-houseontwodifferentrobotsetupsasdemonstratedabove.Threeotherdatasets–RoNIN(Herath
etal.,2020),VECtor(Gaoetal.,2022)andTotalCapture(Trumbleetal.,2017)arecuratedopen-sourcedatasets.
thegrippersurface. AppendixAcontainsmoredetailson 4.1.2.RESKIN: INTRINSICSLIPDATASET
thefabricationandintegrationofReSkinintothegripper.
WeagainusetheKinovasetuptocollect1000trajectoriesof
TheXelasetupconsistsofa7-DOFFrankaEmikarobotfit- intrinsicslip–thegrippergraspingandslippingalongdiffer-
tedwitha16-DOFAllegrohandbyWonikRobotics. Each entboxesclampedtoatable. Atthestartofeveryepisode,
fingeronthehandissensorizedwiththree4x4uSkintactile weclosethegripperatarandomlocationandorientationon
sensors and one curved uSkin tactile sensor from XELA theboxandstartrecordingdata. Wesample8-12random
RoboticsasshowninFigure3. Sensorintegrationwaspro- locationsandorientationswithintheworkspaceoftherobot
videdbyXELArobotics,whichwasdesignedspecifically alongthelengthofthebox,andthencommandtherobot
fortheAllegroHand. Whiletheunderlyingsensorymodeis tomovealongtheboxwhileslippingagainstit. Weuse10
thesameforbothReSkinandXela,theydifferinspatialand boxesofdifferentsizestocollectthisdatasettoimprovedata
temporalresolution,physicallayout,andmagneticsource. diversity in terms of contact dynamics. Example images
anddimensionsareavailableinAppendixC.1.2.
4.1.1.RESKIN: MARKERWRITINGDATASET
Thegoalofthesequentialpredictionproblemistousethe
Wecollect1000Kinovarobottrajectoriesofrandomizedlin- sequenceoftactilesignalsfromthegrippertipstopredict
earstrokesacrossapaper. Initially,themarkerisarbitrarily thetranslationalandrotationalvelocityoftheend-effector
placedbetweenthegrippertips,anddatacollectionbegins (againobtainedfromrobotkinematics)intheplaneofthe
whenthemarkertouchesthepaper. Therobotthenmoves robot’smotion. Inaddition,theabrasivenatureofthetask
linearly between 8-12 random points uniformly sampled causestheskintowearoutovertime. Toaccountforthis
withina10cmx10cmworkspace,pausingforarandomly wear,wechangethegrippertipsandskinsafter25trajecto-
sampleddelayof1-4secondsaftereachmotion. Imagesof riesoneverybox,improvingdatadiversityasaresult.
sampletrajectoriescanbefoundinAppendixC.
4.1.3.XELA:JOYSTICKCONTROLDATASET
The goal of this sequential prediction problem is to use
tactile signal from the gripper to predict the velocity of For our final dataset, we record 1000 trajectories of data
the end-effector in the plane of the table. Velocity labels fromtheAllegrohandinteractingwiththejoystickasshown
areeasilyobtainedfromrobotkinematics,andserveasa in Figure 3. The hand/robot setup is teleoperated using
proxy for the velocity of the marker strokes against the aVR-basedsystemderivedfromHoloDex(Arunachalam
paper. What makes this problem challenging is that the etal.,2023). Joystickinteractionsareloggedsynchronously
sensorpicksupcontactinformationfromboth,therelative withrobotdata,tactilesensingdata,andthecamerafeed.
motionbetweenthemarkerandthegripper,andthemotion Specifically,thisincludesthefullrobotkinematics(7DOF
ofthemarkeragainstthepaper. Themodelmustlearnto Armat50Hz+16DOFHandat300Hz), XELAtactile
disentanglethesetwomotionstomakeaccuratepredictions. output(552dimat100Hz),and2RealsenseD435cameras
(1080pat30Hz). Eachtrajectoryconsistsof25-40seconds
ofinteractionwiththejoystick.
4HiSS:HierarchicalStateSpaceModels
Table1.SummaryofallthemodalitiespresentinCSP-Bench.Modalitiesusedfortrainingareitalicized.Inadditiontothedatausedfor
trainingmodels,wealsoreleasesynchronizedvideoandrobotkinematicsdatatofacilitatefurtherresearchinCSPproblems.
Dataset Modalities ModelInputs ModelOutputs Size
(dim) (dim) (min)
MarkerWriting ReSkin (100 Hz), 2 Cameras (30 Hz), ReSkin(30) End-effector 420
Robot(45Hz) velocity(2)
IntrinsicSlip ReSkin (100 Hz), 3 Cameras (30 Hz), ReSkin(30) End-effector 640
Robot(45Hz) velocity(3)
JoystickControl Xela(100Hz),2Cameras(30Hz),Robot Xela(552) JoystickState(3) 580
(50Hz),Hand(300Hz),Joystick(20Hz)
VECTor IMU(200Hz),2Cameras(30Hz),RGBD IMU(7) Uservelocity(3) 22
(Gaoetal.,2022) (30Hz),Lidar(10Hz),MoCap(120Hz)
TotalCapture IMU(60Hz),8Cameras(60Hz), IMU(39) Jointvelocities(60) 45
(Trumbleetal.,2017) MoCap(60Hz)
RoNIN IMU (200 Hz), 3D Tracking Phone (200 IMU(7) Uservelocity(2) 600
(Herathetal.,2020) Hz)
The goal of the sequential prediction problem is to use 5.1.DataPreparationandSampling
tactilesignalfromtheXela-sensorizedrobothandtopredict
Every sensor in the real world operates at a different fre-
thestateofthejoystick,whichisrecordedsynchronously
quency,anddatafromdifferentsensorsisthereforecollected
withalltheothermodalities. Theextrachallengewiththis
atdifferentnominalfrequencies. Generally,oursensorse-
dataset,inadditiontothesignificantlyhigherdimensionality
quencescomefromaninexpensive,noisysensoroperating
oftheobservationspace,isthenoisiertrajectoriesresulting
atahigherfrequencythananexpensive,highprecisionde-
fromhumandemosinsteadofascriptedpolicy.
vicewhichgivesusoutputsequences. Toemulatethissce-
narioandstandardizeourexperiments,allsensorsequences
4.2.CuratedPublicDatasets
areresampledatafrequencyof50Hz,andoutputsequences
Inadditiontothetactiledatasetswereleasewiththispaper, are resampled at 5Hz for all the datasets under consider-
wealsotestourfindingsondatafromotherdatasets,par- ation, unless specified otherwise. The specific choice of
ticularlyonesusingIMUsensordata(illustratedinFigure thesefrequenciesisdictatedbythesamplingfrequenciesof
3) – the RoNIN dataset (Herath et al., 2020) which con- sensorsintheavailabledata.
tainssmartphoneIMUdatafrom100humansubjectswith
AllthesensorsconsideredinCSP-Bencharepronetodrift;
ground-truth3Dtrajectoriesundernaturalhumanmotions,
therefore,inlinewithpreviouswork(Bhirangietal.,2021;
theVECTordataset(Gaoetal.,2022)–aSLAMdatasetcol-
Guzey et al., 2023b; Herath et al., 2020), we estimate a
lectedacrossthreedifferentplatforms,andtheTotalCapture
restingsignalatthestartofeverysensortrajectoryandde-
dataset–a3Dhumanposeestimationdataset.
viations from this resting signal are passed to the model.
Sincesensordriftcanbecausallydata-dependent,theentire
5.HierarchicalState-SpaceModels(HiSS) sensorytrajectoryispassedtothemodelasinput. Sensor
andoutputsequencesarenormalizedbasedondatastatis-
Inthiswork,wefocusoncontinuoussequence-to-sequence
ticsfortheircorrespondingdatasets,anddetailsarelisted
predictionproblemsforsensorsi.e. problemsthatinvolve
inAppendixB.Additionally,wefindthatappendingone-
mappingasequenceofsensorydatatoasequenceofoutputs.
step differences to every element in the sensor sequence
In the following sections, we describe our preprocessing
helps improve performance, in line with numerous prior
pipelineandHiSS–ourapproachtosequence-to-sequence
works(Chenetal.,2016;Holdenetal.,2016).
reasoningatdifferenttemporalscales.
5.2.ModelArchitecture
HerewedescribeHierarchicalStateSpaceModels(HiSS)–
asimplehierarchicalarchitecturethatusesSSMstoexplic-
5HiSS:HierarchicalStateSpaceModels
Flat SSM Hierarchical SSM (HiSS)
y … y y y … y
1 n 1 2 n
deep SSM high-level deep SSM
s s … s c c … c
1 2 m 1 2 n
…
s t Sensor state at time t low-level SSM low-level SSM low-level SSM
c t Chunk Feature at time t
s 1 … s k s k+1 … s 2k … s m−k+1 … s m
y t Output state at time t
chunk 1 chunk 2 chunk n
Figure4.(Left)FlatSSMdirectlymapsasensorsequencetoanoutputsequence.(Right)HiSSdividesaninputsequenceintochunks
whichareprocessedintochunkfeaturesbyalow-levelSSM.Ahigh-levelSSMmapstheresultingsequencetoanoutputsequence.
itlyreasonoversequentialdataattwotemporalresolutions, 6.ExperimentsandResults
asshowninFigure4. Thesensorsequenceisfirstdivided
Inthissection,weseektoevaluatetheperformanceofHiSS
intoasetofequally-sizedchunksofsizek. Eachchunkis
models on CSP tasks and understand their strengths and
passed through a shared SSM, say S4, which we refer to
limitations. Specifically,ourgoalistoanswerthefollowing
as the low-level SSM. The outputs of the low-level SSM
questions:
correspondingtothek-thelementofeachchunkarethen
concatenatedtoformararifiedchunkfeaturesequence. Fi-
nally,thissequenceispassedthroughahigh-levelsequence • HowdoSSMscomparetoLSTMsandTransformerson
modeltogeneratetheoutputsequence. CSP-Bench?
WhyshouldHiSSwork?Sequentialsensorydataissubject
• CanHiSSprovidebenefitsovertemporallyflatmodels?
tophenomenathatoccuratdifferentnaturalfrequencies.For
instance,anIMUdevicemountedonaquadrotorissubject
• Is HiSS compatible with existing preprocessing tech-
tohigh-frequencyvibrationnoiseandlow-frequencydrift
niqueslikefiltering?
characteristicofMEMSdevices(Koksaletal.,2018). With
HiSS,ourgoalistocreateaneuralarchitecturewithexplicit
structuretooperateatdifferenttemporalscales. Thiswill • HowdoesHiSSperforminlow-dataregimes?
allow the low-level model to learn effective, temporally
localrepresentations,whileenablingthehigh-levelmodel Baselines: Weusetwocategoriesofbaselines: Flatand
tofocusonglobalpredictionsoverashortersequence. Hierarchical. Flat models consist of LSTMs and Causal
TransformersinadditiontoSSMmodelsS4andMamba.
5.3.Trainingdetails HierarchicalbaselinesarevariationsonHiSSmodelswhere
thehigh-levelSSMisanysequencemodeland/orthelow-
We focus on sequence-to-sequence prediction tasks. All
levelmodelisreplacedbyanLSTM.
ourmodelsaretrainedend-to-endtominimizeMSElossas
explainedinSection3.1. ForalltactiledatasetsandVEC-
6.1.PerformanceofFlatsequencemodelson
tor,weusean80-20train-validationsplit. FortheRoNIN
CSP-Bench
dataset, we use the first four minutes of every trajectory
forouranalysis,anduseavalidationsetconsistingoftra- At the outset, we see that SSMs – Mamba and S4, con-
jectoriesfromunseensubjects. ForTotalCapture,weuse sistentlyoutperformthebest-performingTransformerand
thetrain-validationsplitproposedbyTrumbleetal.(2017). LSTMmodelsby10%and14%medianMSErespectively
Hyperparametersweeprangesforeachofourmodelsand acrossCSP-Benchtasks. TheonlyanomalyistheTotalCap-
baselines are listed in Appendix B. We maintain similar turedatasetwheretheLSTMoutperformsallothermodels.
rangesofparametercountsacrossmodelsforthesametask. WeanalyzethislaterinSection6.6.
6HiSS:HierarchicalStateSpaceModels
Table2.ComparisonofMSEpredictionlossesforflatandHiSSmodelsonCSP-Bench.Reportednumbersareaveragedover5seedsfor
thebestperformingmodels.MW:MarkerWriting,IS:IntrinsicSlip,R:RoNIN,V:VECTor,JC:JoystickControl,TC:TotalCapture
Modeltype ModelArchitecture MW IS JC R V TC
(cm/s) (m/s) (m/s) (m/s)
Transformer 2.3750 0.4600 1.0200 - 0.0432 -
LSTM 1.1685 0.3099 1.0740 0.0444 0.0353 0.1767
Flat
S4 1.3190 0.2617 0.9804 0.0382 0.0341 0.3483
Mamba 0.8830 0.1757 1.0640 0.0401 0.0319 0.3645
High-level Low-level
LSTM 0.9958 0.2527 0.9350 0.0421 0.0377 0.3197
Transformer S4 0.6205 0.1574 0.8980 0.0363 0.0374 0.3583
Mamba 1.0268 0.2022 0.9060 0.0472 0.0372 0.4560
LSTM 0.8662 0.2837 1.0760 0.0436 0.0288 0.2522
LSTM S4 0.6370 0.1526 0.9080 0.0481 0.0322 0.3505
Hierarchical Mamba 0.7915 0.1925 1.0610 0.0442 0.0286 0.3638
LSTM 0.8590 0.1805 0.9520 0.0319 0.0293 0.2452
S4 S4 0.6255 0.1551 0.9060 0.0265 0.0303 0.3438
Mamba 0.8257 0.1823 0.9200 0.0322 0.0294 0.4078
LSTM 0.7592 0.1746 0.9640 0.0346 0.0267 0.2428
Mamba S4 0.5663 0.1316 0.9010 0.0302 0.0298 0.2527
Mamba 0.7248 0.1678 0.9050 0.0325 0.0251 0.3762
HiSS improvementoverbestFlat +35.87% +25.10% +8.10% +30.74% +21.30% -37.36%
6.2.ImprovingCSPPerformancewithHiSS theyremainfarbehindHiSSmodels. Thisreinforcesour
hypothesisthatHiSSmodelsdistillmoreinformationfrom
HiSSmodelsperformbetterthanthebest-performingflat
thesensorsequencethannaivedownsampling.
models,SSMorotherwise,withafurtherimprovementof
∼23%medianMSEacrosstasks. Amonghierarchicalmod- Oneadvantageofusinghierarchicalmodelsismemoryef-
els,HiSSmodelscontinuetodoaswellasorbetterthanthe ficiency. Theycansignificantlyreducecomputationalload
otherswitharelativeimprovementof∼9.8%medianMSE. formodelsliketransformerswhichscalequadraticallyinthe
Further,wemaketwokeyobservationswithinmodelsthat lengthofthesequence.UsinganSSMsuchasS4orMamba
useaspecifichigh-levelarchitecture: (1)thesemodelscon- asthelow-levelmodelcansignificantlyreducethecomputa-
sistentlyoutperformcorrespondingflatmodels,indicating
tionalload(cid:0) O(n2)→O(n2/k2)(cid:1)
fork ≪n,wherekand
thattemporalhierarchiesareeffectiveatdistillinginforma- narechunksizeandsequencelengthrespectively. Table2
tionfromcontinuoussensorydata;(2)thebestmodelsuse showsthatsuchamodelconsistentlyimprovesperformance
S4asthelow-levelmodel,indicatingthatS4isparticularly overaflatcausalTransformeracrosstasks.
adeptatcapturinglow-leveltemporalstructureinthedata.
6.4.EffectofSensoryPreprocessingonPerformance
Theseobservationsraiseanaturalquestion:Whatishappen-
ingunderthehood? Inthenexttwosections,weattemptto Acommonapproachtopreprocessingnoisysensordatais
betterunderstandtheworkingofHiSS. to design low-pass filters to process the signal before it’s
passedthroughthemodel. Toanalyzethecompatibilityof
6.3.DoesHiSSSimplydoBetterDownsampling? HiSSmodelswithsuchexistingpreprocessingtechniques,
weseparatelyapplyorder5Butterworthfilterswith3dif-
Thefirstquestionweseektoansweriswhethersimplydown-
ferentcut-offfrequenciestothesensorsequenceandreport
samplingthesensorsequencetothesamefrequencyasthe
modelcorrespondingtothebestcut-offfrequencyinTable
outputwoulddojustaswellasHiSS.AsweseeinTable3,
3. Wemaketwokeyobservations: (1)withtheexception
whilesomeflatmodelswithdownsampledsensorsequences
oftheHiSSmodelforRoNIN,lowpassfilteringimproves
indeed improve performance over flat models in Table 2,
performanceacrosstheboard;(2)HiSSmodelsstillperform
7HiSS:HierarchicalStateSpaceModels
datathanotherdatasets. ResultsarepresentedinTable3.
Table3.Performancecomparisonwith(a)downsampledinputs,(b)
WeonlypresentthebestperformingHiSSmodelherefor
lowpassfilteroninputsequences,and(c)fewertrainingsamples
conciseness. ThefulltablecanbefoundinAppendixD.
MW IS JC R V TC We see that on smaller fractions of the training dataset,
HiSSoutperformsflatbaselinesoneverytaskinCSP-Bench.
Downsampledinputs
ThisindicatesanimportantpropertyofHiSSmodels–data
Trnsfrmr 2.41 0.33 .957 .116 .039 0.34
efficiency. Low-levelmodelsoperateidenticallyonallof
LSTM 1.92 0.27 .975 .094 .034 0.20
thechunksinthedata,allowingthemtolearnmoreeffective
S4 2.22 0.29 .974 .081 .036 0.31
representationsfromsmalldatasetsthanflatmodels.
Mamba 1.96 0.26 .980 .077 .033 0.25
HiSS 0.57 0.13 .901 .027 .025 0.26 6.6.FailureonTotalCapture
LowPassFiltering Themostvisiblefailurecasefortheperformanceofboth
Trnsfrmr 1.79 0.31 1.01 - .034 0.38 flatSSMsaswellasHiSSmodelsisontheTotalCapture
LSTM 1.15 0.26 1.08 .038 .024 0.12 dataset,wheretheflatLSTMsignificantlyoutperformsall
S4 1.19 0.22 0.94 .031 .022 0.25 othermodels. Wehypothesizethatthehighdimensionality
Mamba 0.78 0.14 0.95 .030 .018 0.17 oftheinputandoutputspacespreventsSSMsfromlearn-
ingsufficientlyexpressiverepresentationsthatcanfilterout
HiSS 0.55 0.11 0.87 .036 .020 0.13
highfrequencydata. Thisisalsoevidencedbythehigher
SmallerTrainingDataset performanceofLSTMlow-levelmodelsacrosshierarchical
Fraction 0.3 0.3 0.3 0.3 0.5 0.5 architecturesforthisdataset,whichcorrelateswiththecor-
Trnsfrmr 4.30 0.85 1.237 - .046 0.54 respondinglyhighereffectivenessoftheflatLSTMoverflat
LSTM 1.83 0.54 1.313 .053 .039 0.39 SSMs.FurtherevidenceoftheinabilityofSSMstofilterout
S4 2.31 0.45 1.197 .043 .038 0.43 noisecanbefoundinSection6.4,wheretheperformance
Mamba 1.74 0.37 1.195 .039 .036 0.48 ofHiSSmodelsnearlymatchestheLSTMwhentheinput
sequenceispassedthroughalowpassfilter. Thisindicates
HiSS 1.26 0.29 1.106 .034 .029 0.37
thattheHiSSmodelstrugglestolearnthefilteringbehavior
from data here, unlike other datasets where performance
remainsfairlyconsistentwithandwithoutthelowpassfilter.
comparablywithorbetterthanflatmodels.
7.ConclusionandLimitations
Withrespectto(1),weseethatthebest-performingHiSS
model from Table 2continues to outperform the best flat
WepresentCSP-Bench,thefirstpubliclyavailablebench-
modelusingfiltereddata,implyingthatthelow-passfilter
markforContinuousSequencePrediction,andshowthat
mayhavefilteredusefulinformationcouldhavebeenused
SSMsdobetterthanLSTMsandTransformersonCSPtasks.
toimprovetaskperformance. Thispointstoanimportant
Then,weproposeHiSS,ahierarchicalsequencemodeling
pitfallofhandcraftedpreprocessingtechniques–theycan
architecture that is more performative, data efficient and
oftenfilteroutinformationthatcouldhavebeenexploited
minimizes preprocessing needs for CSP problems. How-
by a sufficiently potent model. Consequently, the ability
ever, sequence-to-sequence prediction from sensory data
ofHiSSmodelstorequirelittletonopreprocessingofthe
continuestobeanopen,relativelyunderexploredproblem,
inputsequencebolsterstheircredentialstoserveasgeneral
andourworkindicatessignificantroomforimprovement.
purposemodelsforCSPdata.
Moreover,whileSSMsshowsignificantpromiseforCSP
tasks,theyarerelativelynewarchitectureswhosestrengths
6.5.HowDoesHiSSPerformonSmallerDatasets?
andweaknessesarefarfrombeingwell-understood. Sec-
The lack of a comprehensive benchmark for continuous tion6.6explainssomeofthechallengesofSSMs,andas
sequence prediction so far speaks to the difficulty of col- a result, HiSS, on high-dimensional prediction problems
lectinglarge,labeleddatasetsofsensorydata. Therefore, withsmalldatasetsofnoisysensordata. Intermsofeaseof
performanceinlow-dataregimescouldbecriticaltowider training,currentHiSSmodelsintroduceanadditionalhy-
applicabilityofdifferentsequencemodelingarchitectures. perparameterofchunksize. Whileourmodelsarerobustto
To benchmark this performance, we compare the perfor- largechunksizes,findingoptimalonesisanexcitingfuture
manceofflataswellasHiSSmodelsonsubsetsofthetrain- direction. Finally,whileCSP-Benchislarge,thenumber
ingdata. WhileTotalCaptureandVECtoraresubstantially of sensors that can benefit from learned models is larger.
smaller than the other datasets (see Table 1), we include Hence, we are committed to supporting CSP-Bench and
theminthisanalysiswhileusingalargerfractionoftraining addingmore,largerdatasetsinthefuture.
8HiSS:HierarchicalStateSpaceModels
8.Acknowledgements Chen,T.-E.,Yang,S.-I.,Ho,L.-T.,Tsai,K.-H.,Chen,Y.-H.,
Chang,Y.-F.,Lai,Y.-H.,Wang,S.-S.,Tsao,Y.,andWu,
NYU authors are supported by grants from Honda, and
C.-C.S1ands2heartsoundrecognitionusingdeepneural
ONRawardnumbersN00014-21-1-2404andN00014-21-
networks.IEEETransactionsonBiomedicalEngineering,
1-2758.LPissupportedbythePackardFellowship.Wealso
64(2):372–380,2016.
thankAadhithyaIyer,GaoyueZhou,IrmakGuzey,Ulyana
Piterbarg and Vani Sundaram for their valuable help and Daum,F. Nonlinearfilters: beyondthekalmanfilter. IEEE
feedbackthroughoutthisproject. AerospaceandElectronicSystemsMagazine,20(8):57–
69,2005.
References
Deng,J.,Dong,W.,Socher,R.,Li,L.-J.,Li,K.,andFei-Fei,
L. Imagenet: Alarge-scalehierarchicalimagedatabase.
Amini, N., Sarrafzadeh, M., Vahdatpour, A., and Xu, W.
In2009IEEEconferenceoncomputervisionandpattern
Accelerometer-based on-body sensor localization for
recognition,pp.248–255.Ieee,2009.
healthandmedicalmonitoringapplications. Pervasive
andmobilecomputing,7(6):746–760,2011. Devlin,J.,Chang,M.-W.,Lee,K.,andToutanova,K. Bert:
Pre-training of deep bidirectional transformers for lan-
Arunachalam, S. P., Gu¨zey, I., Chintala, S., and Pinto, L.
guageunderstanding. arXivpreprintarXiv:1810.04805,
Holo-dex: Teachingdexteritywithimmersivemixedreal-
2018.
ity. In2023IEEEInternationalConferenceonRobotics
andAutomation(ICRA),pp.5962–5969.IEEE,2023. Fu, D. Y., Dao, T., Saab, K. K., Thomas, A. W., Rudra,
A., and Re´, C. Hungry hungry hippos: Towards lan-
Bhirangi, R., Hellebrekers, T., Majidi, C., and Gupta, A.
guagemodelingwithstatespacemodels. arXivpreprint
Reskin: versatile,replaceable,lastingtactileskins. arXiv
arXiv:2212.14052,2022.
preprintarXiv:2111.00071,2021.
Funabashi,S.,Yan,G.,Geier,A.,Schmitz,A.,Ogata,T.,
Bhirangi,R.,DeFranco,A.,Adkins,J.,Majidi,C.,Gupta, andSugano,S. Morphology-specificconvolutionalneu-
A., Hellebrekers, T., and Kumar, V. All the feels: A ralnetworksfortactileobjectrecognitionwithamulti-
dexterous hand with large-area tactile sensing. IEEE fingered hand. In 2019 International Conference on
RoboticsandAutomationLetters,2023. RoboticsandAutomation(ICRA),pp.57–63.IEEE,2019.
Calandra,R.,Owens,A.,Jayaraman,D.,Lin,J.,Yuan,W., Gao,L.,Liang,Y.,Yang,J.,Wu,S.,Wang,C.,Chen,J.,and
Malik, J., Adelson, E. H., and Levine, S. More than Kneip,L. Vector: Aversatileevent-centricbenchmark
a feeling: Learning to grasp and regrasp using vision formulti-sensorslam. IEEERoboticsandAutomation
andtouch. IEEERoboticsandAutomationLetters,3(4): Letters,7(3):8217–8224,2022.
3300–3307,2018.
Gardiol,N.H. Hierarchicalmemory-basedreinforcement
Chang,M.-F.,Lambert,J.,Sangkloy,P.,Singh,J.,Bak,S., learning. In Neural Information Processing Systems
Hartnett,A.,Wang,D.,Carr,P.,Lucey,S.,Ramanan,D., (NIPS),volume13,pp.1047–1053.MITPress,2000.
etal. Argoverse: 3dtrackingandforecastingwithrich
Geiger,A.,Lenz,P.,Stiller,C.,andUrtasun,R.Visionmeets
maps. InProceedingsoftheIEEE/CVFconferenceon
robotics: Thekittidataset. TheInternationalJournalof
computervisionandpatternrecognition,pp.8748–8757,
RoboticsResearch,32(11):1231–1237,2013.
2019.
Gemmeke, J. F., Ellis, D. P., Freedman, D., Jansen, A.,
Chavarriaga,R.,Sagha,H.,Calatroni,A.,Digumarti,S.T.,
Lawrence,W.,Moore,R.C.,Plakal,M.,andRitter,M.
Tro¨ster, G., Milla´n, J. d. R., and Roggen, D. The op-
Audioset: Anontologyandhuman-labeleddatasetfor
portunitychallenge: Abenchmarkdatabaseforon-body
audioevents. In2017IEEEinternationalconferenceon
sensor-basedactivityrecognition. PatternRecognition
acoustics, speech and signal processing (ICASSP), pp.
Letters,34(15):2033–2042,2013.
776–780.IEEE,2017.
Chen,C.,Zhao,P.,Lu,C.X.,Wang,W.,Markham,A.,and Goel,K.,Gu,A.,Donahue,C.,andRe´,C. It’sraw! audio
Trigoni,N.Oxiod:Thedatasetfordeepinertialodometry. generationwithstate-spacemodels. InInternationalCon-
arXivpreprintarXiv:1809.07491,2018. ference on Machine Learning, pp. 7616–7633. PMLR,
2022.
Chen, K., Zhang, D., Yao, L., Guo, B., Yu, Z., and Liu,
Y. Deeplearningforsensor-basedhumanactivityrecog- Gu, A. and Dao, T. Mamba: Linear-time sequence
nition: Overview, challenges, andopportunities. ACM modeling with selective state spaces. arXiv preprint
ComputingSurveys(CSUR),54(4):1–40,2021. arXiv:2312.00752,2023.
9HiSS:HierarchicalStateSpaceModels
Gu, A., Goel, K., and Re, C. Efficiently modeling long Liu,W.,Caruso,D.,Ilg,E.,Dong,J.,Mourikis,A.,Dani-
sequenceswithstructuredstatespaces. InInternational ilidis, K., Kumar, V., Engel, J., Valada, A., and As-
ConferenceonLearningRepresentations,2021a. four, T. Tlio: Tight learned inertial odometry. IEEE
RoboticsandAutomationLetters,PP:1–1,072020a. doi:
Gu, A., Johnson, I., Goel, K., Saab, K., Dao, T., Rudra, 10.1109/LRA.2020.3007421.
A.,andRe´,C. Combiningrecurrent,convolutional,and
continuous-time models with linear state space layers. Liu,W.,Caruso,D.,Ilg,E.,Dong,J.,Mourikis,A.I.,Dani-
Advancesinneuralinformationprocessingsystems,34: ilidis,K.,Kumar,V.,andEngel,J. Tlio: Tightlearned
572–585,2021b. inertialodometry.IEEERoboticsandAutomationLetters,
5(4):5653–5660,2020b.
Guzey, I., Dai, Y., Evans, B., Chintala, S., and Pinto, L.
Maddern,W.,Pascoe,G.,Linegar,C.,andNewman,P. 1
See to touch: Learning tactile dexterity through visual
year,1000km: Theoxfordrobotcardataset. TheInterna-
incentives. arXivpreprintarXiv:2309.12300,2023a.
tionalJournalofRoboticsResearch,36(1):3–15,2017.
Guzey, I., Evans, B., Chintala, S., and Pinto, L. Dex-
Mathieu, J. L., Koch, S., and Callaway, D. S. State esti-
terity from touch: Self-supervised pre-training of tac-
mationandcontrolofelectricloadstomanagereal-time
tile representations with robotic play. arXiv preprint
energyimbalance. IEEETransactionsonpowersystems,
arXiv:2303.12076,2023b.
28(1):430–440,2012.
Herath,S.,Yan,H.,andFurukawa,Y. Ronin: Robustneural
Micucci,D.,Mobilio,M.,andNapoletano,P. Unimibshar:
inertialnavigationinthewild:Benchmark,evaluations,&
Adatasetforhumanactivityrecognitionusingacceler-
newmethods. In2020IEEEInternationalConferenceon
ation data from smartphones. Applied Sciences, 7(10):
RoboticsandAutomation(ICRA),pp.3146–3152.IEEE,
1101,2017.
2020.
Moody,G.B.andMark,R.G. Theimpactofthemit-bih
Holden, D., Saito, J., and Komura, T. A deep learning arrhythmiadatabase. IEEEengineeringinmedicineand
framework for character motion synthesis and editing. biologymagazine,20(3):45–50,2001.
ACMTransactionsonGraphics(TOG),35(4):1–11,2016.
Pinto,L.,Gandhi,D.,Han,Y.,Park,Y.-L.,andGupta,A.
Koksal,N.,Jalalmaab,M.,andFidan,B. Adaptivelinear The curious robot: Learning visual representations via
quadratic attitude tracking control of a quadrotor uav physicalinteractions. InComputerVision–ECCV2016:
basedonimusensordatafusion. Sensors,19(1):46,2018. 14thEuropeanConference,Amsterdam,TheNetherlands,
October11-14,2016,Proceedings,PartII14,pp.3–18.
Kong,B.,Zhan,Y.,Shin,M.,Denny,T.,andZhang,S. Rec- Springer,2016.
ognizing end-diastole and end-systole frames via deep
temporalregressionnetwork. InMedicalImageComput- Poli, M., Massaroli, S., Nguyen, E., Fu, D. Y., Dao, T.,
ingandComputer-AssistedIntervention-MICCAI2016: Baccus, S., Bengio, Y., Ermon, S., and Re´, C. Hyena
19th International Conference, Athens, Greece, Octo- hierarchy:Towardslargerconvolutionallanguagemodels.
ber17-21,2016,Proceedings,PartIII19,pp.264–272. arXivpreprintarXiv:2302.10866,2023.
Springer,2016.
Schu¨tze,M.,Campisano,A.,Colas,H.,Schilling,W.,and
Vanrolleghem,P.A. Realtimecontrolofurbanwastew-
Kuchaiev,O.andGinsburg,B. Factorizationtricksforlstm
ater systems—where do we stand today? Journal of
networks. arXivpreprintarXiv:1703.10722,2017.
hydrology,299(3-4):335–348,2004.
Kulkarni, T. D., Narasimhan, K., Saeedi, A., and Tenen-
Simon, D. Optimal state estimation: Kalman, H infinity,
baum,J. Hierarchicaldeepreinforcementlearning: In-
andnonlinearapproaches. JohnWiley&Sons,2006.
tegrating temporal abstractionand intrinsicmotivation.
Advancesinneuralinformationprocessingsystems,29, Smith, J.T., Warrington, A., andLinderman, S.W. Sim-
2016. plifiedstatespacelayersforsequencemodeling. arXiv
preprintarXiv:2208.04933,2022.
Lambeta, M., Chou, P.-W., Tian, S., Yang, B., Maloon,
B., Most, V. R., Stroud, D., Santos, R., Byagowi, A., Sonar,H.A.,Yuen,M.C.,Kramer-Bottiglio,R.,andPaik,
Kammerer,G.,etal. Digit: Anoveldesignforalow-cost J. Anany-resolutionpressurelocalizationschemeusing
compacthigh-resolutiontactilesensorwithapplication asoftcapacitivesensorskin. In2018IEEEInternational
toin-handmanipulation. IEEERoboticsandAutomation Conference on Soft Robotics (RoboSoft), pp. 170–175.
Letters,5(3):3838–3845,2020. IEEE,2018.
10HiSS:HierarchicalStateSpaceModels
Stetco,A.,Dinmohammadi,F.,Zhao,X.,Robu,V.,Flynn, Yuan, W., Dong, S., and Adelson, E. H. Gelsight: High-
D., Barnes, M., Keane, J., and Nenadic, G. Machine resolutionrobottactilesensorsforestimatinggeometry
learningmethodsforwindturbineconditionmonitoring: andforce. Sensors,17(12):2762,2017.
Areview. Renewableenergy,133:620–635,2019.
Sun,P.,Kretzschmar,H.,Dotiwalla,X.,Chouard,A.,Pat-
naik,V.,Tsui,P.,Guo,J.,Zhou,Y.,Chai,Y.,Caine,B.,
etal. Scalabilityinperceptionforautonomousdriving:
Waymoopendataset. InProceedingsoftheIEEE/CVF
conferenceoncomputervisionandpatternrecognition,
pp.2446–2454,2020.
Sutton, R. S., Precup, D., and Singh, S. Between mdps
andsemi-mdps: Aframeworkfortemporalabstractionin
reinforcementlearning. Artificialintelligence,112(1-2):
181–211,1999.
Thu, N. T. H. and Han, D. S. Hihar: A hierarchical hy-
briddeeplearningarchitectureforwearablesensor-based
human activity recognition. IEEE Access, 9:145271–
145281,2021.
Tomo,T.P.,Regoli,M.,Schmitz,A.,Natale,L.,Kristanto,
H.,Somlor,S.,Jamone,L.,Metta,G.,andSugano,S. A
newsiliconestructureforuskin—asoft,distributed,digi-
tal3-axisskinsensoranditsintegrationonthehumanoid
roboticub. IEEERoboticsandAutomationLetters,3(3):
2584–2591,2018.
Trumble, M., Gilbert, A., Malleson, C., Hilton, A., and
Collomosse,J. Totalcapture: 3dhumanposeestimation
fusingvideoandinertialsensors. InProceedingsof28th
BritishMachineVisionConference,pp.1–13,2017.
Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,
L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. At-
tentionisallyouneed. Advancesinneuralinformation
processingsystems,30,2017.
Wagner,P.,Strodthoff,N.,Bousseljot,R.-D.,Kreiseler,D.,
Lunze,F.I.,Samek,W.,andSchaeffter,T. Ptb-xl,alarge
publiclyavailableelectrocardiographydataset. Scientific
data,7(1):154,2020.
Warden, P. Speech commands: A dataset for
limited-vocabulary speech recognition. arXiv preprint
arXiv:1804.03209,2018.
Welch,G.,Bishop,G.,etal. Anintroductiontothekalman
filter. 1995.
Yan, H., Shan, Q., and Furukawa, Y. Ridi: Robust imu
doubleintegration. InProceedingsoftheEuropeancon-
ferenceoncomputervision(ECCV),pp.621–636,2018.
You, J., Wang, Y., Pal, A., Eksombatchai, P., Rosenburg,
C.,andLeskovec,J. Hierarchicaltemporalconvolutional
networks for dynamic recommender systems. In The
worldwidewebconference,pp.2236–2246,2019.
11HiSS:HierarchicalStateSpaceModels
A.ReSkinfabricationdetails
ReSkinmeasuresthechangesinmagneticfluxinitsX,YandZcoordinatesystem,basedonthechangeinrelativedistance
betweentheembeddedmagneticmicroparticlesinanelastomermatrixandanearbymagnetometer. Theuseofmagnetic
microparticlesenablesfreedominregardtotheshapeanddimensionsofthemoldedskin. Inourusecasehere,weusea
skinofthickness2mm. Thissectionfurtherdetailsthecompletefabricationprocessinvolvedinthesensorizedgrippertips
weuseforourReSkin: OnRobotGripperonaKinovaJACOArmsetup(SeeFigure5).
A.1.Circuitry
DatafromtheReSkinsensorsisstreamedtoacomputerviaUSB.ThetwosensorsareconnectedtoanI2CMUXwhichin
turnisconnectedtoanAdafruitQTPymicrocontrollerasdescribedinBhirangietal.(2021). SeeFigure5.
Figure5. Circuitry
A.2.OnRobotGripperTips
Theskinsareaffixedtothe3D-printedgrippertipsusingsiliconeadhesive,asshowninFigure6. Thedimensionsofthetips
are32mm×30mm×2mm. Thesametipsalsohousetheflex-PCBboards,whichmeasurethechangeinmagneticfluxin
all3axes.
Figure6. GripperTipswithReSkin
B.ModelarchitecturesandTraining
B.1.FlatArchitectures
Foreachoftheflatsequencemodelspresentedinthiswork,theinputsequenceisfirstembeddedintoahiddenstatesequence
byalinearlayer. Thishiddenstateisthenpassedtotherespectivesequencemodel. Theoutputsofthesequencemodel(the
hiddenstatesforLSTM,S4andMamba)arethenmappedtothedesiredoutputspace
B.2.Hierarchicalarchitectures
Thehierarchicalmodelsareobtainedbysimplystackingtwoflatmodelstogether. Theinputsequenceisfirstdividedinto
equalsizedchunksasdescribedinSection5.2. Eachchunkispassedthroughthelow-levelsequencemodelandtheoutputs
correspondingtothelasttimestepofeachchunkareconcatenatedtoformthechunkfeaturesequence. Thissequenceis
passedthroughahigh-levelsequencemodeltoobtaintheoutputsequence
12HiSS:HierarchicalStateSpaceModels
B.3.Hyperparameters
Allmodelsaretrainedfor600epochsataconstantlearningrateof1e-3. Learningrateschedulerswerenotfoundtoimprove
performance by noticeable amounts. Table 4 contains the ranges of hyperparameters used for training the flat models
presentedinthepaper. Wedonotsweepoverallofthesehyperparametersforeachtask. Asubsetoftheseparameters
ischosenforeachtaskdependingontheinputandoutputdimensionalityofthetaskandthebest-performingmodelsare
reported. TheexacthyperparametersforeachexperimentcanbefoundontheGithubrepository. Foranygiventask,we
ensurethatsweepsoverallmodelclassesconsistofmodelsthathavethesameorderofmagnitudeoflearnableparameters.
LSTM Transformer S4 Mamba
Inputsize Modeldim Modeldim Modeldim
16,32,64,128,256 32,64,128,256,512 32,64,128,256,512 32,64,128,256,512
LSTMhiddensize No. ofheads
256,512,1024 2,4
No. oflayers No. oflayers No. oflayers No. oflayers
2 4,6 4,6 4,6
Dropout Dropout Dropout
0.0,0.1 0.0,0.1 0.0,0.1
Table4. Hyperparametersforflatarchitectures
Forthehierarchicalmodels,weuseasmallersubsetoftheparameterslistedinTable4tosweepoverthehighlevelmodels.
Parameterrangessweptoverforlow-levelmodelsarelistedinTable5. Theexacthyperparametersforeachexperimentcan
befoundontheGithubrepository.
LSTM S4 Mamba
Inputsize Modeldim Modeldim
16,32,64 16,32,64,128,256 16,32,64,128,256
LSTMhiddensize
16,32,64,128,256
No. oflayers No. oflayers No. oflayers
1 4,6 3,4
Table5. Hyperparametersforlow-levelmodelsusedinhierarchicalarchitectures
13HiSS:HierarchicalStateSpaceModels
C.ExperimentalSetupandDataCollectiondetails
Figure7.MarkerWritingFrames(Top):Thegrippertipsholdthemarkerandbringitincontactwiththepaperbeforethesequencestarts.
Thearmmaneuversthemarkertoexecuteeightstrokesonthepaper.InstrinsicSlipFrames(Middle):Thegrippertipsholdtheboxto
startthesequence,andslipthroughtherobotworkspacewithdifferentorientations.JoystickControlFrames(Bottom):Afterthesequence
begins,thehandholdsthejoystick,controllingitsmovementthroughvariouspositions.
C.1.ReSkin: OnrobotGripperonaKinovaJACOArm
C.1.1.MARKERWRITING
Forthisexperiment,wefirstgraspthemarkerwith300Nforceinanarbitrarypositionandbringitincontactwiththepaper.
Wethenstartrecordingdataandcommandtherobottomovesequentiallyto8-12randomlysampledlocationswithina
10×10cm2planeworkspace,makinglinearstrikesonthepaper. Figure7illustratesasamplesequencefromthisdataset.
Wenotethatduringthestrikes,thegraspedmarkerundergoesorientationdriftsattimes,whichaddstothecomplexityin
signal. Werecordatotalof1000trajectoriesof15-30secondseach,comprisingof2differentcoloredmarkers.
Thepredictiontaskhereistopredictthestrikevelocity(δx/δt,δy/δt),giventhetactilesignalsthusreconstructingtheoverall
trajectory.
C.1.2.INTRINSICSLIP
InSection4.1.2,weoutlinedourmethodologyforcollectingdatathroughatotalof1000trajectories. Thisinvolvedusing
10distinctboxesand4setsofskinsfor25trajectoriespercombinedpair. Wefirstsamplearandomlocationandorientation
withinthetaskworkspace. Next,weclosethegripperwitharandomforcesampledintherangeof50-75Nandthenstart
recordingdata. Withthegrippergraspingthebox,weuniformlysample8-12locationssequentially,thusslippingthrough
therobotworkspace. Figure7illustratesasamplesequencefromthisdataset. Theworkspaceistheupperregionofthebox,
whichisaspaceofdimensionsBox Length x Tip Size(3cm),showninFigure9. Weclampthewristrotation
limitsat[-π/4,π/4],makingtheoveralllocalsamplingboundsofthegrippertipposition(centeroftip),Y:[0,boxlength],
Z:[0,tipsize],θ:[-π/4,π/4].
14HiSS:HierarchicalStateSpaceModels
Figure8. BoxesintheDataset
Figure9. End-effectorWorkspaceontheBox,&LocalCo-ordinateSystem
15HiSS:HierarchicalStateSpaceModels
Bhirangietal.(2021)characterizetheabilityofReSkinsensormodelsgeneralizetoskinsoutsidethetrainingdistribution,but
theseexperimentsarelimitedtosingle-frame,staticdata.Here,wecollectananalogousdatasetforthesequence-to-sequence
predictionproblem. Toavoidconfoundingeffects,theevaluationsprovidedinthispaperarebasedonarandompartitioning
ofthisdataset. However,wecollectandpublishanadditional100trajectoriesonanunseenboxandanunseensetofskins
totestthegeneralizabilityoftrainedmodels.
Thedimensionsofallboxesusedinthisexperimentaredetailedbelow. SeeTable6andFigure8.
Inthisexperiment,inadditiontopredictingthelinearvelocitiesoftheend-effector,wealsopredicttheangularvelocitiesat
thewrist/theend-effectorrotation(δx/δt,δy/δt,δθ/δt).
BoxNumber Dimensions(LxHxWcm)
1 20x12x4
2 16.5x8.5x3
3 14x9x5
4 17x13x4.5
5 15x10x4.5
6 16.5x13x6
7 17x10x5.5
8 18x19.5x5.5
9 17x11x3.5
10 12x8x6.5
11(unseen) 23x16x5
Table6. DimensionsofBoxesintheDataset
C.2.Xela: AllegroHandonaFrankaEmikaPandaArm
C.2.1.JOYSTICKCONTROL
Forthefinaltactiledataset,weteleoperateanAllegroHandwithXelasensorsmountedonaFrankaarmtointeractwithan
Extreme3DProJoystickshowninFigure10,whichstreamsdatacomprisingof6rotationaxes(X,Y,Rz,Throttle,Hat0X,
Hat0Y)and12buttons(Trigger,2ThumbButtons,2TopButtons,1PinkieButtonand6BaseButtons). Unliketheprior
datasets,whichoriginatedoutofrandomyetscriptedpolicies,thisdatasethasanaddedcomplexityfromtheunstructured
humaninteractivecontrol. Figure7illustratesasamplesequencefromthisdataset. Duetothearmworkspaceandthefinger
sizeconstraints,wefocuson3axes-X,YandZ-twistforourpredictiontask. GiventhereadingsfromtheXelasensors,we
predictthejoystick’sstatesofinterest.
Figure10. Extreme3DProJoystick&Co-ordinateSystem
16HiSS:HierarchicalStateSpaceModels
D.Ablations
D.1.DataPreprocessing
Inthissection,weprovidemoredetailedtablesfortheexperimentsinSections6.4. Table7containsresultsfromseparately
applyingorder3Butterworthfilterstotheinputsequenceswithcutofffrequenciesof0.75Hz,2.5Hzand7.5Hz. Foreach
setting,wepickthesetofmodelscorrespondingtothecutofffrequencywiththebestperformance,andreportaverage
performanceover3seeds.
Table7.ComparisonofMSEpredictionlossesforflatandHiSSmodelsonCSP-Benchwhenpassingtheinputsequencesthrougha
low-passfilter.Reportednumbersareaveragedover5seedsforthebestperformingmodels.MW:MarkerWriting,IS:IntrinsicSlip,JC:
JoystickControl,TC:TotalCapture
Modeltype ModelArchitecture MW BS JC RoNIN VECTor TC
(cm/s) (m/s) (m/s) (m/s)
Transformer 1.7940 0.3096 1.0080 - 0.0346 0.3845
LSTM 1.1498 0.2596 1.0770 0.0382 0.0242 0.1234
Flat
S4 1.1885 0.2209 0.9449 0.0305 0.0228 0.2467
Mamba 0.7823 0.1367 0.9459 0.0297 0.0188 0.1661
High-level Low-level
LSTM 1.0052 0.1883 0.9074 0.0532 0.0284 0.2314
Transformer S4 0.6703 0.1249 0.8652 0.0434 0.0260 0.2908
Mamba 0.8912 0.1251 0.8731 0.0435 0.0243 0.3118
LSTM 0.8063 0.2434 1.0500 0.0430 0.0272 0.1754
LSTM S4 0.6462 0.1477 0.9885 0.0419 0.0288 0.1968
Hierarchical Mamba 0.7515 0.1657 1.0080 0.0420 0.0234 0.1755
LSTM 0.8525 0.1390 0.9269 0.0306 0.0272 0.1905
S4 S4 0.6667 0.1221 0.9296 0.0377 0.0222 0.2284
Mamba 0.7825 0.1180 0.8898 0.0396 0.0207 0.2527
LSTM 0.8143 0.1308 0.9660 0.0369 0.0255 0.1594
Mamba S4 0.5535 0.1074 0.8665 0.0362 0.0272 0.1301
Mamba 1.5657 0.1057 0.8765 0.0367 0.0212 0.1466
D.2.SmallerDatasets
Inthissection,weprovidemoredetailedtablesfortheexperimentsinSections6.5.Table8containsresultsfromsubsampling
thetrainingdatasets–30%ofthedatasetforMW,IS,JCandRoNIN,and50%ofthedatasetforVECtorandTotalCapture.
WeseethatHiSSconsistentlyoutperformsflatmodelsacrosstasksinCSP-Benchwhentrainingonfractionsofthetraining
dataset,indicatingthesampleefficiencyofHiSSmodels.
17HiSS:HierarchicalStateSpaceModels
Table8.ComparisonofMSEpredictionlossesforflatandHiSSmodelsonCSP-Benchwhenusingafractionofthetrainingdataset.
Reportednumbersareaveragedover5seedsforthebestperformingmodels.MW:MarkerWriting,IS:IntrinsicSlip,JC:JoystickControl,
TC:TotalCapture
Modeltype ModelArchitecture MW IS JC RoNIN VECTor TC
(cm/s) (m/s) (m/s) (m/s)
(Fraction) 0.3 0.3 0.3 0.3 0.5 0.5
Transformer 4.2975 0.8509 1.2370 - 0.0460 0.5430
LSTM 1.8322 0.5376 1.3130 0.0533 0.0390 0.3855
Flat
S4 2.3070 0.4450 1.1970 0.0431 0.0379 0.4338
Mamba 1.7443 0.3677 1.1950 0.0394 0.0358 0.4838
High-level Low-level
LSTM 1.5417 0.3428 1.2350 0.0387 0.0331 0.3982
S4 S4 1.5460 0.2931 1.1260 0.0346 0.0337 0.3992
Mamba 2.3302 0.3760 1.1060 0.0412 0.0326 0.4913
LSTM 1.5810 0.3478 1.2410 0.0362 0.0309 0.3530
Mamba S4 1.2600 0.2883 1.1370 0.0378 0.0333 0.3675
Hierarchical Mamba 1.7508 0.3688 1.1140 0.0383 0.0286 0.4320
E.TotalCapturePreprocessing
Thisdatasetprovidesreadingsfrom12IMUsensorsandthegroundtruthposesof21jointsobtainedfromtheViconmotion
capturesystem. Tostandardizethedatawithinaconsistentcoordinatesystem,wetransformedallIMUsensorreadingsfrom
theirnativeIMUframestotheViconframe. Ourtaskistopredictthevelocitiesofthe21jointsgiventheIMUacceleration
dataintheViconreferenceframe.
To convert IMU acceleration data into the Vicon frame, we utilize the calibration results
provided in the files named <subject id> <sequence name> calib imu ref.txt and
<sequence name> Xsens AuxFields.sensors. The acceleration of each IMU sensor in the Vicon frame
iscalculatedasfollows:
a =Rvicon Rinertiala , (1)
vicon inertial imu imu
where Rinertial is the rotation matrix converted from the IMU local orientation quaternion (w, x, y, z) provided in the
imu
<sequence name> Xsens AuxFields.sensors files. This quaternion represents the IMU’s orientation in the
inertialreferenceframe.
Furthermore, Rvicon is obtained by converting the quaternion information (<imu name> x y z w) available in the
inertial
<subject id> <sequence name> calib imu ref.txt files, which encapsulates the transformation from the
inertialframetotheViconglobalframe.
18