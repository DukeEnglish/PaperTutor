An Improved Algorithm for Learning Drifting Discrete Distributions
Alessio Mazzetto
Brown University
Abstract 2015; Kamath et al., 2015; Orlitsky and Suresh, 2015;
Jiao et al., 2015; Cohen et al., 2020). The use of the
total variation metric as a measure of error for this
We present a new adaptive algorithm for
problemis a naturalchoice that is commonly adopted
learning discrete distributions under distri-
intheliterature(Devroye and Lugosi,2001). Itisfolk-
bution drift. In this setting, we observe a
lorethat ifa distributionhas supportsize k,the max-
sequence of independent samples from a dis-
imum likelihood estimator with n i.i.d. samples has
crete distribution that is changing overtime,
anexpectederrorupper boundedby O( k/n), which
andthegoalistoestimatethecurrentdistri-
can be shown to be tight (Anthony et al., 1999).
bution. Since we have access to only a sin- p
glesampleforeachtime step,agoodestima- In numerous applications where samples are col-
tion requires a careful choice of the number lected over time, it is possible that their underly-
ofpastsamplestouse. Tousemoresamples, ing distribution may change. In the distribution
wemustresorttosamplesfurtherinthepast, drift setting, we are interested in estimating the
and we incur a drift error due to the bias in- current distribution, given a sequence of past sam-
troduced by the change in distribution. On ples that could be generated by different distribu-
the other hand, if we use a small number of tions. This setting has been recently studied by
past samples, we incur a large statistical er- Mazzetto and Upfal(2023b),butotherproblemshave
rorastheestimationhasahighvariance. We also been considered in a similar setting, for exam-
present a novel adaptive algorithm that can ple, binary classification (e.g., Barve and Long, 1996;
solve this trade-off without any prior knowl- Long, 1998, and references therein), agnostic learning
edge of the drift. Unlike previous adaptive (Mohri and Mun˜oz Medina,2012;Hanneke and Yang,
results, our algorithm characterizes the sta- 2019; Mazzetto and Upfal, 2023a), or crowdsourcing
tistical error using data-dependent bounds. (Fu et al., 2020).
This technicality enables us to overcome the
Concretely, let X ,...,X denote a sequence of T in-
limitations of the previous work that require 1 T
dependent samples respectively from the discrete dis-
a fixed finite support whose size is known in
tributions µ ,...,µ . Equivalently, we say that the
advance and that cannot change over time. 1 T
sequence of samples is generated over time by a drift-
Additionally, we can obtain tighter bounds
ing discrete distribution. The goal is to estimate the
depending on the complexity of the drifting
currentdistributionµ giventhesequenceofsamples.
distribution, and also consider distributions T
Without loss of generality, it is sufficient to consider
with infinite support.
discrete distributions over the natural numbers, and
givensuch a distribution µ, we let µ(i)=Pr (X =i)
µ
for any i N. The total variation distance be-
1 INTRODUCTION ∈
tween two discrete distributions µ and η is defined
as µ η =(1/2) µ(i) η(i).
k −
kTV i∈N
| − |
Estimating a distribution from a set of samples
is a crucial challenge in data analysis and statis-
Indeed,theestimationPofµ
T
ispossibleonlyifthepre-
vious distributions are related to it. Let ∆ ,...,∆
tics (Devroye and Gy¨orfi, 1987; Silverman, 1986; 1 T
be a non-decreasing sequence of real numbers where
Devroye and Lugosi, 2001). In this work, we focus
.
on the classical setting of estimating the probabil- ∆ = max µ µ . (1)
r T T−t TV
ity mass function of a discrete distribution. A long
t:0≤t<rk − k
list of work characterizedthe error for this estimation The value∆ is the maximumtotalvariationdistance
r
problem given independent and identically distributed from the current distribution µ to any of the most
T
(i.i.d.) samplesfromthesamedistribution(Han et al., recent r distributions µ ,...,µ . In past work
T−r+1 T
4202
raM
8
]GL.sc[
1v64450.3042:viXraAn Improved Algorithm for Learning Drifting Discrete Distributions
(Mazzetto and Upfal, 2023b), it is shown that if the 1.1 Limitations of Existing Work
distributions have the same support of size k, a tight
lower bound on the expected error of any algorithm In recent work, Mazzetto and Upfal (2023a) exhibit
for the estimation of the current distribution µ with a general learning algorithm that solves the trade-off
T
respect to the total variation distance is given by between statistical error and drift error (up to loglog
factors) based on the input samples and without any
priorknowledgeofthedrift. Inoursetting,thisimplies
k that there exists an algorithm that can adaptively at-
Ω min +∆ . (2)
1≤r≤T"rr r
#!
tainthelowerbound(2),whichcannotbeimprovedin
a minimax sense. Precisely, there exists an algorithm
thatobservesthe sequenceX ,...,X fromadrifting
1 T
This lower bound is in a minimax sense. For- distribution with a fixed support of size k, and it re-
mally, given any (possibly adaptive) algorithm, and turns an estimate µˆ of µ T such that with probability
a sufficiently small non-decreasing sequence of val- at least 0.99:
ues ∆ ,...,∆ , there exists a sequence of distribu-
1 T
tions µ ,...,µ with shared support k such that k loglogr
1 T µ µˆ =O min + +∆
T TV r
max t:0≤t<r µ T−t µ T TV ∆ r for any 1 r T, k − k 1≤r≤T"rr r r #!
k − k ≤ ≤ ≤
and the expected estimation error of the algorithm is (3)
at least (2).
While the above error is essentially tight according to
For a fixed integer r, the quantity O( k/r+∆ ) of
r (2), this result has several intertwined weaknesses.
(2) is also an upper bound to the expected error ob-
p
tainedbyonlyusingthe mostrecentr samplesforthe First,thepreviousadaptivealgorithmcanonlybe ap-
estimation, and it is written as the sum of the up- pliedtodriftingdistributionsthathavefinite support,
per bound to two errors: the statistical error and the which cannot change over time. This constraint is
drift error. The statistical error term k/r is related in conflict with the drift setting, where the distribu-
to the variance of the estimation, and it decreases by tion, hence its support, can indeed change over time.
p
consideringmoresamples;whereasthedrifterrorterm For example, consider the drifting distribution of the
∆ is due to the distribution drift, and it can poten- items purchasedovertime fromanonline retailer: the
r
tially increase by using samples further away in time. support of this distribution can repeatedly evolve due
Equation(2)showsthatanoptimalestimationisgiven to changes in inventory, new products, or availability.
by the optimal solution of this trade-off. This trade- Additionally, we are also required to know the value
off determines an optimal number of recent samples k of the support size. Since k cannot be determined
to use as a function of the distribution drift. This is precisely using only the input samples, it is necessary
a significant difference with the i.i.d. setting, where to have prior knowledge of this value, which can be
each sample provides useful information, and the ex- unfeasible in many practical applications.
pected error goes to 0 as the number of samples goes
Second, the aforementioned algorithm has the crucial
to infinity.
shortcomingofusingadistribution-independentupper
The trade-off between the statistical error and bound O( k/r) on the statistical error from using r
the drift error is common in the literature on samples. While this upper bound is indeed tight for
p
learning with drift (Mohri and Mun˜oz Medina, 2012; distributions that are roughly uniform over a support
Mazzetto and Upfal, 2023b). However, the minimiza- of size k, the actual error due to the variance of the
tion of this trade-off is challenging as the values estimationcanbesignificantlysmallerforotherdistri-
∆ ,...,∆ of the drift error are unknown, and they butions. As an example, if we consider a distribution
1 T
cannot be estimated from the data since we only have ofsizek,wheremostoftheprobabilitymassisconcen-
access to a single sample from each distribution. For trated in k′ k elements, we would expect a statisti-
≪
this reason, most of the previous work required prior calerrorwithrateO( k′/r). Furthermore,the useof
knowledge of the magnitude of the drift in order to adistribution-independent upper boundonthe statis-
p
quantify andsolve this trade-off. For example,a com- tical error prevents the consideration of distributions
mon assumption is that the magnitude of the drift is with infinite support (k = ). In the i.i.d. setting,
∞
boundedby∆>0ateachstep(Bartlett,1992),which it is possible to address this issue by using a sharp
implies ∆ (r 1)∆ for all r T. In this case, the distribution-dependent upper bound on the statisti-
r
≤ − ≤
optimal solution of the trade-off gives an estimation cal error, which also allows us to handle distributions
errorequalto Θ((k ∆)1/3) which is achievedby com- with infinite support (Berend and Kontorovich, 2013;
·
puting the empiricaldistribution induced by the most Cohen et al., 2020). In particular, if we assume that
recent Θ((k/∆2)1/3) samples. there is no drift, i.e. µ = µ = ... = µ , the max-
1 TAlessio Mazzetto
imum likelihood estimator µˆ over T samples exhibits or with infinite support. For the special case of drift-
an expected error (Berend and Kontorovich, 2013): ingdistributionswithsharedsupportofsizek,itholds
thatΛ (µ ) k/r,andweindeedachievethelower
r T
1 1 ≤
Λ (µ) E µ µˆ Λ (µ) , (4) bound(2)uptologarithmicterms. However,wehigh-
8 T − 4√T ≤ k − kTV ≤ T lightthatouralp
gorithmusesadistribution-dependent
measure Λ (µ ) to upper bound the statistical error
where r T
of the estimation which could be significantly tighter
. 1 than k/r even for distributions with support size k.
Λ (µ)= µ(i)+ µ(i). (5)
T
√T Thisenablesustoobtaintighterboundsdependingon
i:µ(Xi)<1/T i:µ(Xi)≥1/T
p the
drp
ifting distribution’s complexity.
The value Λ (µ) is a measure of the learning com-
T Since Λ (µ) Λ (µ) for any s < r, in the i.i.d. case,
plexity of µ that provides a tight characterization of r ≤ s
wecanobservethatthetheoremguaranteeswithhigh-
the variance of the estimation of µ with T samples.
probability (e.g., 99/100)an estimation such that
By using the Cauchy-Schwarz inequality, it is simple ≥
to verify that if the support of µ has size k, it holds
that Λ (µ) k/r, recovering the aforementioned
r
≤
distribution-independent upper bound. We highlight loglog2T
p µ µˆ =O Λ (µ )+ ,
that having a tight bound on the statistical error is k T − kTV  T T s T 
especially important in a drift setting as it can signif-
 
icantly impact the quality of the estimation, since the
value ofthis bounddetermines the number ofsamples
retrieving up to logarithmic terms the tight charac-
touseinordertosolvethetrade-offbetweenstatistical
terization of the estimation error depicted in (4) for
error and drift error.
learning with T i.i.d. samples from µ . The addi-
T
tional logarithmic term is the cost of the adaptivity,
2 MAIN RESULT
sincethealgorithmdoesnotknowaprioriwhetherthe
samples are identically distributed.
Inourwork,weaddressthe issuesoutlined inthe pre-
vious section. Our main contribution is to provide an Technical contribution. It is not straightforward
adaptive algorithm for estimating an arbitrary drift- to extend the adaptive strategy of the previous work
ing discrete distribution. The result is formalized as (Mazzetto and Upfal, 2023a) to use a data-dependent
follows. bound on the statistical error. In fact, the proof
strategy of that work relies on knowing the exact
Theorem 2.1. Let δ (0,1). There exists an algo-
∈ rate at which the upper bound on the statistical er-
rithm that given X ,...,X , it outputs a distribution
1 T ror decreases, which is not possible for distribution-
µˆ such that with probability at least 1 δ, it holds that
− dependentupperbounds. Tocircumventthisissue,we
develop a new analysis for learning with drift, whose
µ µˆ =O min Λ (µ )
T TV r T proof of correctness also uses a novel result that ties
k − k 1≤r≤T
(cid:18) (cid:20) themagnitudeofthedriftwiththechangeinthelearn-
log((log2r+1)/δ) ingcomplexityofthe drifting distribution. We believe
+ +∆ ,
s r r that our novel proof strategy for learning with drift
(cid:21)(cid:19)
using data-dependent upper bounds on the statistical
where ∆ r =max 0≤t<r µ T µ T−t TV as in (1). error can also be applied to other learning problems.
k − k
To the best of our knowledge, this is the first adap-
The above theorem shows that there exists an adap-
tivelearningalgorithmfordiscretedistributionstouse
tive algorithm that can achieve (up to loglog factors)
data-dependent bounds in the drift setting.
an optimal solution of the trade-off between statisti-
cal error and drift error, where the statistical error
is quantified using a distribution-dependent measure
of complexity. Compared to the previous adaptive 3 ALGORITHM
result (3), our algorithm works for an arbitrary dis-
crete drifting distribution, and it utilizes a sharper
distribution-dependent upper bound on the statistical Inthis section,we presentthe algorithmthatachieves
error that we estimate from the data. In particular, the guarantee of Theorem 2.1. First, we formally de-
ouralgorithmdoesnot requireanypriorknowledgeof fine the trade-off between statistical error and drift
the drifting distribution, and it also works for drift- errorobtainedbyusingthe mostrecentr samples. To
ing distribution with support that changes over time this end, for any 1 r T, we define the following
≤ ≤An Improved Algorithm for Learning Drifting Discrete Distributions
distributions Proposition 3.2. Let δ (0,1)and 1 r T. With
∈ ≤ ≤
probability at least 1 δ, it both holds:
1 T −
µ[r](i)= µ (i) i N ,
T r t ∀ ∈ log(4/δ)
µˆ[r](i)=
1t=T X T−r+1
1 i N ,
kµˆ[ Tr] −µ[ Tr] kTV ≤Φ r (cid:16)µˆ[ Tr] (cid:17)+3
r
2r
T r {Xt=i} ∀ ∈ and
t=T−r+1
X
w anh dich thear ee mr pe is rp ice ac lti dv ie sl ty ribth ue tioa nve µˆra [rg ]e od veis rtr ti hb eut mio on stµ r[ T er -] Φ r µˆ[ Tr] ≤4Λ r µ[ Tr] + rlog( r4/δ)
T (cid:16) (cid:17) (cid:16) (cid:17)
centrsamples. Followingthemethodologyofprevious
work, the following proposition provides an error de-
Proof. In the appendix.
composition into statistical error and drift error for
the estimation of µ by using the empirical distribu-
T
tion µˆ[r]. This proposition enables us to use the empirical mea-
T
Proposition 3.1. Let 1 r T. We have that sureofcomplexityΦ r µˆ[ Tr] toestimatethestatistical
≤ ≤
error while guaranteei(cid:16)ng th(cid:17)at we obtain a result that
kµ T −µˆ[ Tr] kTV ≤kµ[ Tr] −µˆ[ Tr] kTV + ∆ r . is a tight approximation to using the non-empirical
StatisticalError DriftError measure Λ r µ[ Tr] as in (4). Proposition 3.2 can be
| {z } |{z} seen as a ge(cid:16)nerali(cid:17)zation of the results of Cohen et al.
Proof. By using the triangle inequality, we have that
(2020,Theorem2.1andTheorem2.3)forindependent
but not identically distributed discrete distributions.
µ µˆ[r] µ[r] µˆ[r] + µ µ[r]
k T − T kTV ≤k T − T kTV k T − T kTV
On a high level, the core of our algorithm is a con-
We can upper bound the second addend of the right- dition that allows us to compare the upper bound to
hand side above using the triangle inequality theestimationerrorinducedbydifferentchoicesofthe
number of past samples without explicitly estimating
T .
µ[r] µ = 1 (µ µ ) the drift error. For ease of notation, we let r j = 2j
k T − T kTV (cid:13)r t − T (cid:13) for any j 0. As long as this condition is true, the
(cid:13) (cid:13) t=T X−r+1 (cid:13) (cid:13)TV algorithm≥ iterativelyconsidersalargernumberofpast
1 (cid:13) (cid:13) T µ µ (cid:13) (cid:13) ∆ . (6) samples,alsoreferredto as window size, startingfrom
≤ r k t − T kTV ≤ r r = 1. In particular, at iteration j it considers a
0
t=T−r+1
X window size r (starting from j =0), and it evaluates
j
the condition by comparing the estimation obtained
with r to the estimationobtained with r ,...r . If
j 0 j−1
The first term of the right-hand side of this proposi- the condition is satisfied, we can provably maintain a
tion represents the statistical error of the estimation. solution whose upper bound to the estimation error
Our goal is to measure this error as a function of the is up to a constant factor as good as any previously
distribution-dependentmeasureofcomplexityΛ (µ ) considered window size (Proposition 3.4). Conversely,
r T
ofthecurrentdistributionµ ,whichisunknown. Our if the condition is violated, a non-negligible drift has
T
algorithm relies on the input data to estimate this occurred, thus using more samples cannot yield a sig-
quantity. Following the example of previous work, we nificantly better estimation (Proposition 3.5). As we
use the empirical counterpart of this measure of com- will see, depending on the data, it is possible that we
plexity. Givenanempiricaldistributionµˆ[r],wedefine do not need to consider all the possible window sizes
T
r : j 0 for the evaluation of this condition, and
j
{ ≥ }
only a subset will suffice.
Φ (µˆ[r])=.
kµˆ[ Tr]
k21 = 1 µˆ[r](i) ,
r T s r √r T Thecorrectnessofouralgorithmisconditionedonthe
Xi∈Nq event that the estimation for all window sizes r
j
=2j
for j 0 concentrates around its expectation, i.e. we
and we observe that this quantity can be computed
≥
from the samples. The quantity Φ (µˆ[r]) is an em- wanttoprovideanupperboundtothestatisticalerror
r T as in Proposition 3.2 for all those window sizes. This
pirical measure of complexity that provides an upper
result is formalized in the next proposition and it is
boundtothestatisticalerrorwithrsamples. Thenext
obtained by simply taking a union bound.
propositionisprovenbasedonresultsofpreviouswork
(Cohen et al., 2020). Proposition 3.3. Let δ (0,1). With probability at
∈Alessio Mazzetto
Algorithm 1: Adaptive Learning Algorithm For A The algorithm is looking for the window size r j that
Discrete Drifting Distribution minimizes the upper bound U(r j). We remark that
this is a challenging problem due to the fact that the
L= 0 1
{ } drifterrorisunknownanditcannotbeestimatedfrom
for j =1,..., log T do 2
⌊ 2 ⌋ the data, since we have access to a single sample from
if ξ rj <min ℓ∈Lξ rℓ then 3 each distribution. Additionally, the sequence (ξ )
for ℓ L do 4 j j≥0
∈ is not necessarily strictly decreasing, and it does not
if kµˆ[ Trℓ] −µˆ[ Trj] kTV ≥3ξ rℓ +ξ rj then 5 haveananalyticalclosedformulathatdependsonlyon
return µˆ[rmaxL] 6 r . This is a requirement of the proof strategy of the
T j
end 7 previous adaptive work Mazzetto and Upfal (2023a),
end 8 which exploits the a priori knowledge of how much
L L j 9 thestatisticalerrorisreducedbydoublingthewindow
← ∪{ }
end 10 size. Therefore,their proofstrategydoes not apply to
end 11 our setting.
return µˆ[rmaxL] 12 By an inspection of U(), it is clear that if ξ > ξ
T j+n j
·
for some n 1, then U(r ) < U(r ) since the drift
j j+n
≥
errorisnondecreasingwithrespecttothewindowsize.
least 1 δ, for all j 0 it holds that Thus,wecanonlyconsiderasequenceofwindowsizes
− ≥
forwhichtheupperboundtothestatisticalerrorisde-
log
c(log2rj+1) creasing. Formally,weconsiderthefollowingsequence
kµˆ[ Trj] −µ[ Trj] kTV ≤Φ rj µˆ[ Trj] +3v u (cid:16) r jδ (cid:17) to hf ai tnd isex be us ilL t i= ter( aℓ t1 i, v. e. l. y,ℓ aK s) fow llh oe wre s.K W≤ e l1 et+ ℓlog =2(T 0) .
(cid:16) (cid:17) u 1
t (7) Givenℓ ,...,ℓ ,theelementℓ isadded(ifitexists)
1 i i+1
as the first index j > ℓ such that ξ < ξ , thus we
and i j ℓi
have ξ < ξ for any 1 i K 1. Moreover,
ℓi+1 ℓi
≤ ≤ −
given j 0, we let γ(j)=ℓ be the largest value ℓ L
log
c(log2rj+1)
≥ ∈
Φ rj
µˆ[ Trj]
≤4Λ rj
µ[ Trj]
+3v u (cid:16) r
jδ
(cid:17)
fs ou lc loh wt ih na gt reℓ
la≤
tioj n. hO olb ds se :rve that by construction, the
(cid:16) (cid:17) (cid:16) (cid:17) u
t (8)
U(r ) U(r ) . (10)
γ(j) j
≤
where c is a constant equal to c=4π2/3. Therefore, we have min U(r ) min U(r ),
ℓ∈L ℓ 1≤j≤T j
≤
and we can only consider window sizes r with values
ℓ
Proof. Let δ = δ(6/π2)/(j+1)2. We have that with ℓ L.
j
∈
probabilityatleast1 δ ,theeventofProposition3.2
− j The pseudo-code of the algorithm is reported in Al-
holds with error probability δ and window size r .
j j gorithm 1. The algorithm iteratively builds the list
Thestatementfollowsbysubstitutingthedefinitionof
L. Once a new element j that belongs to this list is
δ , and taking a union bound over all possible events
j found (Line 3), the algorithm compares the empirical
forj 0,since δ =(6/π2)δ 1/j2 =δ.
≥ j≥0 j j≥1 distribution µˆ[rj] with all the empirical distributions
T
The value δ (P 0,1) of the above pP roposition is a pa- µˆ[rℓ] with ℓ L such that ℓ < j. This comparison
rameter of t∈ he algorithm, and it denotes its failure prT ovidesthe i∈ terationconditionthat is the coreof our
probability. Throughout this section, we assume that algorithm. The statistical error ξ rj using r j samples
the eventofProposition3.3holds,otherwise ouralgo- is less than ξ rℓ for all such ℓ, however the drift error
rithm fails (with probability δ). We denote with could be larger. The main idea is that if all those
≤ empirical distributions are sufficiently close (Line 5),
ξ rj
=.
Φ rj
(cid:16)µˆ[ Trj]
(cid:17)+3
slog(c(log2
r
jr j +1)/δ) t
l
oah bre tgn
ae i,
nth
a
ee dni dr bd
w
yi es ut ca
sa
in nnc ge
g
µuw
ˆa
[i rt
r
jh
a
]nr
it
se es
e
ap ste hc gt
a
ott oo
t
dhµ
e
aT sesc
tt
ha imn en
a
eo
t
st
i to
ib mne aet trh
ir
oa
o
nt
r
T
theupperboundtothestatisticalerrorforthewindow achieved with any µˆ[rℓ] for all such ℓ. In this case, we
T
size r j given by the empirical bound (7) in Proposi- can keep iterating. This intuition is formalized with
tion 3.3. By using Proposition 3.1, we have the fol- the following proposition.
lowing upper bound to the error of estimating µ by
T Proposition 3.4. Assume that the event of Proposi-
using the empirical distribution
µˆ[rj]
:
T tion 3.3 holds. Let j L. If
∈
U(r )=. ξ +∆ µ µˆ[rj] , j 0. (9) µˆ[rℓ] µˆ[rj] 3ξ +ξ ℓ<j :ℓ L
j rj rj ≥k T − T kTV ∀ ≥ k T − T kTV ≤ rℓ rj ∀ ∈An Improved Algorithm for Learning Drifting Discrete Distributions
then, we have that: where the last inequality follows from the assumption
that the event of Proposition 3.3 holds. Using the
µ µˆ[rj] 5 minU(r ) . triangle inequality again, we obtain
k T − T kTV ≤ ·ℓ∈L: ℓ
ℓ<j
µ[rℓ] µ[rj] µ[rℓ] µ + µ[rj] µ
k T − T kTV ≤k T − T kTV k T − T kTV
Proof. Letℓ ∈Lsuchthatℓ<j. Byusingthetriangle ≤∆ rℓ +∆ rj ≤2∆ rj ,
inequality, we have that:
where in the last two inequalities we used relation (6)
µ µˆ[rj] µ µˆ[rℓ] + µˆ[rℓ] µˆ[rj] . andthefactthatthedrifterrorisnon-decreasingwith
k T − T kTV ≤k T − T kTV k T − T kTV
the number of past samples. By combining the above
We upper bound the first term of the right-hand side upper bound with (11), we have
using (9), and the second term by using the assump-
tion of this proposition. We obtain: µˆ[rℓ] µˆ[rj] ξ +ξ +2∆ .
k T − T kTV ≤ rj rℓ rj
kµ T −µˆ[ Trj] kTV ≤ξ rℓ +∆ rℓ +ξ rℓ +3ξ rj We use the assumption of the proposition and obtain
5ξ +∆ the following lower bound to the drift error
≤
rℓ rℓ
5 U(r ) .
ℓ
≤ · ∆ ξ .
rj
≥
rℓ
For any n j, we have that
≥
Conversely, we want to show that if one of the condi-
2U(r )=2ξ +2∆ 2∆ ξ +∆ =U(r ) .
tions in Line 5 of the algorithm is violated, then we n rn rn ≥ rj ≥ rℓ rℓ ℓ
can stop iterating. If there exists a distribution µˆ[rℓ]
T
that is far enough from
µˆ[rj]
for a ℓ L such that
T ∈
ℓ < j, then a significant distribution drift must have
occurred. Inparticular,wecanshowalowerboundto Proposition 3.4 and Proposition 3.5 can be used to
∆ rj ≥ξ rℓ, and thus U(r n) ≥ξ rℓ for any n ≥j due to prove that our algorithm finds a window size rˆ = 2j
the drift error. Since U(r ℓ)=ξ rℓ +∆ rℓ, and the drift for some j 0 such that U(rˆ) = min iU(r i). We
errorfromusingr ℓ samplesislessorequaltothe drift can express≥ this upper bound using the measure of
error from using r n samples, we are able to conclude complexity Λ rˆ() thanks to (8). However, this is not
thatU(r n)cannotbe significantlysmallerthanU(r ℓ), sufficienttopro· veTheorem2.1,sinceweareonlycon-
and in particular U(r ℓ) 2U(r n). This provides a sideringwindowsizesr thatarepowersoftwo,andwe
≤
certificatethatwecanstopiteratingsincethe window want to compare against any possible selection of the
size r ℓ provides a value of the upper bound U() that window size 1 r T. For window sizes that are not
isuptoconstantasgoodastheoneobtainedwi· thany power of two, ≤ Prop≤ osition 3.3 does not provide direct
window size r n with n j. This result is formalized informationonthestatisticalerror. Toprovethetheo-
≥
with the following proposition. rem,we needtorelatethe magnitudeofthe drift with
Proposition 3.5. Assume that the event of Proposi- the change in complexity of the drifting distribution.
tion 3.3 holds. Let j L. If there exists ℓ L with The following proposition provides this result.
∈ ∈
ℓ<j such that Proposition 3.6. Let µ and η be two discrete dis-
tributions over N. For any integers 1 r s, the
kµˆ[ Trℓ] −µˆ[ Trj]
kTV ≥3ξ rℓ +ξ rj , following two inequalities hold:
≤ ≤
then U(r ) 2U(r ) for any n j.
ℓ n Λ (µ) Λ (η) 2 µ η ,
≤ ≥ r r TV
| − |≤ k − k
Λ (µ)
r
s/r .
Proof. By the triangle inequality, we have that Λ (µ) ≤
s
p
µˆ[rℓ] µˆ[rj]
k T − T kTV
Proof. We start by proving the first inequality. We
≤ kµˆ[ Trℓ] −µ[ Trℓ] kTV+ kµˆ[ Trj] −µ[ Trj] kTV partition N into four sets: S 00 = i : µ(i) < 1/r
{ ∧
+ kµ T[rℓ] −µ[ Trj] kTV η S(i) =< 1 i/ :r µ}, (iS )01 = 1/r{i : ηµ (i( )i) << 1/1 r/r ,∧ anη d(i S) ≥ =1/r i} :,
ξ +ξ + µ[rℓ] µ[rj] , (11) 10 { ≥ ∧ } 11 {
≤ rj rℓ k T − T kTV µ(i) 1/r η(i) 1/r . We have the following
≥ ∧ ≥ }Alessio Mazzetto
decomposition For any i S , we have that µ(i) µ(i)/r =
1
∈ ≤
s/r µ(i)/s. We obtain the following result:
p
Λ (µ) Λ (η)= (µ(i) η(i))
r r
− − p p µ(i)
i∈ XS00 Λ r(µ)= µ(i)+ µ(i)+
r
+ µ(i)
η(i)
+
µ(i)
η(i)
i X∈S0 i X∈S1 i X∈S2r
− r r ! r r − ! s µ(i) s µ(i)
i∈ XS01 i∈ XS10 µ(i)+ +
+
1
µ(i) η(i) .
≤
i X∈S0
rr
i
X∈S1r s rr
i
X∈S2r s
√r −
s
i∈ XS11(cid:16)p p (cid:17) Λ s(µ) .
≤ r
r
The sum over S is upper bounded simply as
00
(µ(i) η(i)) µ(i) η(i) .
− ≤ | − | We can finally prove Theorem 2.1.
i∈ XS00 i∈ XS00
Proof of Theorem 2.1. We assume that the event of
Proposition 3.3 holds, otherwise we say that our al-
For the sum over S , we have that
11 gorithm fails (with probability δ). The algorithm
≤
returns an empirical distribution
µˆ[rj]
for some j 0,
µ(i) − η(i) 1 (µ(i) η(i)) and it guarantees that T ≥
= −
hp √rp i √r µ(i)+ η(i)
i∈ XS11 i∈ XS11 kµ
T
−µˆ[ Trj]
kTV
≤U(r j) .
√r p p
µ(i) η(i) Consider the function Q(r) : 1,...,T R defined
≤ 2√r | − | { } 7→
i∈ XS11 as
µ(i) η(i)
= | − | , . log(c(log2r+1)/δ)
2 Q(r)=Λ (µ )+ +∆ ,
r T r
i∈ XS11 s r
where c is the same constant in Proposition 3.3. Let
where in the inequality we used the fact that µ(i)
r∗ = argmin Q(r). In order to prove the theo-
and η(i) are both at least 1/r for any i S . 1≤r≤T
Now, observe that for i S , we have that
µ∈p (i)1 =1 rem, it is sufficient to show that U(r j) = O(Q(r∗)).
p ∈ 01p Let γ be defined as in (10), and let i 0 be such that
µ(i) µ(i) µ(i)/r. Using this inequality and ≥
proceed· ingsimi≤ larlytothepreviouscase,wehavethat γ(r∗)=r i. We distinguish two cases: (a) r i ≤r j and
p p p (b) r i > r j. For both cases, we will use the following
result:
η(i) µ(i) η(i)
µ(i) − r r !≤ r r − r r ! U(r i)=O(Q(r∗)) . (12)
i∈ XS01 i∈ XS01
Equation(12)isprovenasfollows. Letnbethelargest
µ(i) η(i) .
≤ | − | integer such that 2n r∗. By construction, we have
i∈ XS01
γ(r )=r
,thusinequ≤
ality (10)showsus thatU(r )
n i i
≤
U(r ). By definition, U(r )=ξ +∆ , and
Fori S 10,weobservethatµ(i)>1/r,hence1/√r< n n rn rn
∈
µ(i). Therefore, it holds that µ(i)/r < µ(i)
pµ(i)<µ(i), and p p · ξ rn =Φ(µˆ[ Trn])+3 slog(c(log2 r nr n+1)/δ)
p
µ(i) log(c(log2r∗+1)/δ)
η(i) (µ(i) η(i)) . 4Λ (µ[rn])+12 , (13)
r r − !≤ − ≤ rn T s r∗
i∈ XS10 i∈ XS10
where we used (8) and the fact that r∗ 2r .
n
We can conclude: ≤
Through, Proposition 3.6 we obtain the following up-
per bound
Λ (µ) Λ (η) µ(i) η(i) 2 µ η .
r r TV
− ≤ Xi∈N| − |≤ k − k Λ rn(µ[ Trn])
Λ (µ )+2∆
≤
rn T rn
To provethe secondinequality,we use insteadthe fol-
lowing partition of N into S = i:µ(i)<1/s , S = ≤
r∗/r
n
·Λ r∗(µ T)+2∆
rj
0 1
i:1/s µ(i)<1/r , and S
{
= i : 1/r
}
µ(i) .
4 pΛ r∗(µ T)+2∆ r∗,
2 ≤
{ ≤ } { ≤ }An Improved Algorithm for Learning Drifting Discrete Distributions
whereinthesecondinequalitywealsoused(6),andin error, or assumes that multiple samples can be ob-
thelastinequalityweusedthefactthatthedrifterror tained from each distribution to estimate the drift er-
is non-decreasing and that r∗ 2r . If we combine ror (Mohri and Mun˜oz Medina, 2012; Awasthi et al.,
n
≤
the above inequality with (13), we have that 2023). There are two work that provide an adaptive
algorithmforlearninga family offunctions with drift:
log
c(log2r∗+1) Hanneke et al. (2015) address the realizable case, and
δ Mazzetto and Upfal(2023a)addresstheagnosticcase.
U(r i) ≤U(r n) ≤16Λ r∗(µ T)+12v
u (cid:16) r∗ (cid:17)
u Recent work characterizes the minimax error for the
+9∆ r∗
=O(Q(r∗)t
) . problem of learning discrete and continuous smooth
distributions with distribution drift, but it assumes
Equipped with (12), We will now show that U(r ) = a prior knowledge of the drift to attain this er-
j
O(Q(r∗)) for both cases (a) and (b). ror (Mazzetto and Upfal, 2023b). In a more spe-
cific setting, Gokcesu and Kozat (2017) provide an
Case (a). Since i L, we have U(r ) 5U(r ) due to
∈ j ≤ i adaptive algorithm for learning a parametric family
Proposition 3.5. We conclude by using equation (12).
of exponential densities, where the parameters can
Case (b). The algorithm chooses the window size slowly drift over time. We finally point out that
r < r . This means that when the algorithm con- several algorithms have been proposed for estimating
j i
siders the next element ℓ L after j, where ℓ i, a density in the online setting (Kristan et al., 2011;
∈ ≤
there exists an index ℓ′ L with ℓ′ j such that the Garc´ıa-Trevin˜oand Barria, 2012), but they do not
∈ ≤
conditionofLine5ofthealgorithmissatisfied. Propo- provide an analysis of the estimation error.
sition 3.5 applies, and we have that U(r ℓ′) 2U(r n)
≤
for any n ℓ > j. By construction, this is also true
≥ 5 CONCLUSION
for n equal to i, and U(r ℓ′) 2U(r i). On the other
≤
hand, since the algorithm returned r , it means that
j
We provide an adaptive algorithm for the problem of
all the If conditions on Line 5 must have been sat-
learning a drifting discrete distribution. Unlike pre-
isfied when considering j L, and Proposition 3.4
givesusU(r ) 5min ∈ U(r ), andinparticular vious work, our method solves this problem for any
j z≤j:z∈L z
≤ drifting discrete distribution, and it does not require
U(r j) U(r ℓ′). Thus, U(r j) 10U(r i). We obtain
≤ ≤ any prior assumption on the support of the distribu-
the statement by using equation (12).
tion. Additionally, our algorithm utilizes the input
data to estimate the statistical error, and it can pro-
4 RELATED WORK
vide a tighter bound than existing methods depend-
ing on the complexity of the drifting distribution. To
The problem of learning with distribution drift
the best of our knowledge, this is the first adaptive
was introduced in the context of binary classi-
methodforlearningadiscretedistributiontousedata-
fication (Helmbold and Long, 1991; Bartlett, 1992;
dependent bounds in a drift setting.
Helmbold and Long, 1994). This line of research led
to the result that if any two consecutive distributions
Acknowledgements
have a bounded L distance ∆, the expected error
1
for learning a family of binary functions with VC di-
TheauthorswouldliketothankEliUpfalforthehelp-
mension ν is O((ν∆)1/3) (Long, 1998), and the upper
ful discussions. This material is based on research
bound is tight (Barve and Long, 1996). Under mild
sponsored by the National Science Foundation (NSF)
assumptions,Mohri and Mun˜oz Medina(2012)extend
under awardIIS-1813444,and by a KanellakisFellow-
theanalysisofagnosticlearningwithdrifttoanyfam-
ship.
ily of functions. In particular, they provide an up-
per bound to the learning error for a given window
References
size that uses the Rademacher complexity to quan-
tify the statistical error, and a problem-dependent Anthony, M., Bartlett, P. L., Bartlett, P. L., et al.
upper bound to the drift error called discrepancy (1999). Neural network learning: Theoretical foun-
that is based on previous work in domain adapta- dations, volume 9. Cambridge University Press.
tion (Mansour et al., 2009; Ben-David et al., 2010).
Awasthi,P.,Cortes,C.,andMohri,C.(2023). Theory
Recent work relaxes the independence assumption
andalgorithmforbatchdistributiondriftproblems.
and provides learning bounds under mixing condition
In Proc. AISTATS, pages 9826–9851.
(Hanneke and Yang, 2019). This previous work ei-
ther requires a priori knowledge of the drift error to Bartlett,P.L.(1992).Learningwithaslowlychanging
solve the trade-off between statistical error and drift distribution. In Proc. COLT, pages 243–252.Alessio Mazzetto
Barve,R.D.andLong,P.M.(1996). Onthecomplex- cretedistributions. IEEE Transactions on Informa-
ity of learning from drifting distributions. In Proc. tion Theory, 61(5):2835–2885.
COLT, pages 122–130.
Kamath, S., Orlitsky, A., Pichapati, D., and Suresh,
Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., A. T. (2015). On learning distributions from their
Pereira,F.,andVaughan,J.W.(2010). Atheoryof samples. In Proc. COLT, pages 1066–1100.
learningfromdifferent domains. Machine Learning,
Kristan, M., Leonardis, A., and Skoˇcaj, D. (2011).
79:151–175.
Multivariate online kernel density estimation with
Berend, D. and Kontorovich, A. (2013). A sharp gaussian kernels. Pattern recognition, 44(10-
estimate of the binomial mean absolute deviation 11):2630–2642.
with applications. Statistics & Probability Letters,
Long, P. M. (1998). The complexity of learning ac-
83(4):1254–1259.
cording to two models of a drifting environment. In
Cohen, D., Kontorovich, A., and Wolfer, G. (2020). Proc. COLT, pages 116–125.
Learningdiscretedistributionswithinfinitesupport.
Mansour, Y., Mohri, M., and Rostamizadeh, A.
In Proc. NeurIPS, pages 3942–3951.
(2009). Domain adaptation: Learning bounds and
Devroye,L.andGy¨orfi,L.(1987).Nonparametricden- algorithms. In Proc. COLT.
sityestimation: the l[1]view. Journal of the Amer-
Mazzetto,A.andUpfal,E.(2023a). Anadaptivealgo-
ican Statistical Association, 82:344.
rithm for learning with unknown distribution drift.
Devroye, L. and Lugosi, G. (2001). Combinatorial In Proc. NeurIPS.
methods in density estimation. Springer Science &
Mazzetto, A. and Upfal, E. (2023b). Nonparametric
Business Media.
densityestimationunderdistributiondrift. InProc.
Fu,D.,Chen,M.,Sala,F.,Hooper,S.,Fatahalian,K., ICML, pages 24251–24270.
and R´e, C. (2020). Fast and three-rious: Speeding
Mohri, M. and Mun˜oz Medina, A. (2012). New anal-
up weak supervision with triplet methods. In Proc. ysis and algorithm for learning with drifting distri-
ICML, pages 3280–3291. butions. In Proc. ALT, pages 124–138.
Garc´ıa-Trevin˜o,E.S.andBarria,J.A.(2012). Online Orlitsky, A. and Suresh, A. T. (2015). Competitive
wavelet-baseddensity estimationfor non-stationary distribution estimation: Why is good-turing good.
streaming data. Computational statistics & data In Proc. NeurIPS.
analysis, 56(2):327–344.
Silverman,B.W.(1986).Densityestimationforstatis-
Gokcesu, K. and Kozat, S. S. (2017). Online density tics and data analysis, volume 26. CRC press.
estimation of nonstationary sources using exponen-
tial family of distributions. IEEE Transactions on
NeuralNetworksandLearningSystems,29(9):4473–
4478.
Han, Y., Jiao, J., and Weissman, T. (2015). Minimax
estimation of discrete distributions. In 2015 IEEE
International Symposium on Information Theory
(ISIT), pages 2291–2295.IEEE.
Hanneke,S.,Kanade,V.,andYang,L.(2015). Learn-
ing with a drifting target concept. In Proc. ALT,
pages 149–164.
Hanneke, S. and Yang, L. (2019). Statistical learn-
ing under nonstationary mixing processes. In Proc.
AISTATS, pages 1678–1686.
Helmbold, D. P. and Long, P. M. (1991). Tracking
drifting concepts using random examples. In Proc.
COLT, pages 13–23.
Helmbold, D. P. and Long, P. M. (1994). Tracking
driftingconceptsbyminimizingdisagreements. Ma-
chine Learning, 14:27–45.
Jiao, J., Venkat, K., Han, Y., and Weissman, T.
(2015). Minimax estimation of functionals of dis-An Improved Algorithm for Learning Drifting Discrete Distributions
A DEFERRED PROOFS
Proof of Proposition 3.2. The proof of this proposition is based on previous work in the literature. The first
inequalityofthepropositionimmediatelyfollowsfromtheproofofCohen et al.(2020,Theorem2.1). Specifically,
with probability at least 1 δ/2, it holds:
−
log(4/δ)
µˆ[r] µ[r] Φ µˆ[r] +3 . (14)
k T − T kTV ≤ r T 2r
r
(cid:16) (cid:17)
The proof of the second inequality of this proposition proceeds as follows. By invoking Fubini’s theorem, we
have that
∞ ∞ ∞
1 1 1
EΦ(µˆ[r])= E µˆ[r](i) = E µˆ[r](i) = E r µˆ[r](i) .
T √r i=1q T ! √r i=1 (cid:18)q T (cid:19) r i=1 (cid:18)q · T (cid:19)
X X X
Consider a value i N, and let C =rµˆ[r](i). The crucial observation is that
∈ i T
T T T
1
EC =rE 1 = E1 = µ (i)=rµ[r](i) .
i r {Xt=i} {Xt=i} t T
!
t=T−r+1 t=T−r+1 t=T−r+1
X X X
The remaining of the proof follows the same argument in previous work (Cohen et al., 2020). Since the square
root is a concave function, we have that E√C √EC by using Jensen’s inequality. Furthermore, we can
i i
exploit that √C C as C 0,1,...,r , to sho≤ w E√C EC . We obtain:
i i i i i
≤ ∈{ } ≤
∞
1
EΦ(µˆ[r])= E C
T r i
i=1
X p
∞
1
min rµ[r](i), rµ[r](i)
≤ r T T
i=1 (cid:26) q (cid:27)
X
1
= µ[r](i)+ µ[r](i)
T √r T
i:µ[ Tr X](i)≤1/r i:µ[ Tr X](i)>1/r
=Λ (µ[r]) .
r T
Since changing a single sample among X ,...,X can change the value of
Φ(µˆ[r]
) by at most 2/r, we
{ T−r+1 T } T
can use McDiarmid’s inequality to show that with probability at least 1 δ/2, it holds that:
−
log(2/δ)
Φ(µˆ[r]) EΦ(µˆ[r])+ . (15)
T ≤ T r
r
We conclude by taking a unionbound so thatboth events (14) and(15)hold withprobability atleast1 δ.
−