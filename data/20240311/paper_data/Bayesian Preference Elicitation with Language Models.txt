Bayesian Preference Elicitation with Language Models
KunalHanda YarinGal ElliePavlick
UniversityofOxford UniversityofOxford BrownUniversity
kunal.handa@cs.ox.ac.uk yarin@cs.ox.ac.uk ellie_pavlick@brown.edu
NoahGoodman JacobAndreas AlexTamkin* BelindaZ.Li‚àó
StanfordUniversity MIT Anthropic MIT
ngoodman@stanford.edu jda@mit.edu atamkin@anthropic.com bzl@mit.edu
Abstract meier,2012). Forexample, whenbuildingacon-
tentrecommendationsystem,relevantfeaturesmay
AligningAIsystemstousers‚Äôinterestsrequires
bedifferentarticletopics‚Äîe.g.science,politics,or
understandingandincorporatinghumans‚Äôcom-
celebrity culture. A user may decide whether or
plex values and preferences. Recently, lan-
nottoreadanarticlebasedonthestrengthoftheir
guagemodels(LMs)havebeenusedtogather
preferencesalongthesedifferentaxes.
information about the preferences of human
users. This preference data can be used to With the widespread use of preference data to
fine-tune or guide other LMs and/or AI sys- align language models (LMs) with human users,
tems. However,LMshavebeenshowntostrug- therehasbeengrowinginterestinusingLMsthem-
gle with crucial aspects of preference learn- selves to elicit information about human prefer-
ing: quantifyinguncertainty,modelinghuman
ences. Past work focused on prompting LMs to
mentalstates,andaskinginformativequestions.
ask questions about user preferences (Li et al.,
Thesechallengeshavebeenaddressedinother
2023; Lin et al., 2023; Piriyakulkij et al., 2023)
areas of machine learning, such as Bayesian
has shown that LMs are capable of identifying
OptimalExperimentalDesign(BOED),which
focusondesigninginformativequerieswithin decision-relevantfeaturesindomainsspanningcon-
awell-definedfeaturespace. Butthesemeth- tent recommendation, software engineering, and
ods,inturn,aredifficulttoscaleandapplyto moral reasoning. Nonetheless, prompting offers
real-worldproblemswheresimplyidentifying
limited control over LMs‚Äô information-gathering
therelevantfeaturescanbedifficult. Weintro-
strategiesandoftenfailstoproducequestionsthat
duceOPEN(OptimalPreferenceElicitation
areusefulorinformative.
withNaturallanguage)aframeworkthatuses
Bycontrast,alonglineofworkonoptimalex-
BOEDtoguidethechoiceofinformativeques-
tionsandanLMtoextractfeaturesandtranslate perimentaldesign,suchasduelingbandits(Heckel
abstractBOEDqueriesintonaturallanguage etal.,2019)andBayesianpreferencelearningap-
questions. BycombiningtheflexibilityofLMs proaches (Foster et al., 2019; Gal et al., 2017;
withtherigorofBOED,OPENcanoptimize Houlsby et al., 2011), has developed methods to
the informativity of queries while remaining
efficiently infer user preferences from a limited
adaptabletoreal-worlddomains. Inuserstud-
number of interactions. But these methods also
ies,wefindthat OPEN outperformsexisting
have their limitations‚Äîthey have primarily been
LM-andBOED-basedmethodsforpreference
appliedtotaskswithsimple,highly-structureddata
elicitation.
where feature spaces are constrained and interac-
1 Introduction tions are short. How can we get the best of both
worlds? Can we learn similarly sample-efficient
Understandingusers‚Äôcomplexpreferencesandre-
modelsofuserpreferencesincomplex,open-ended
quirementsisnecessaryforaccuratelyandsafely
tasks?
automatingreal-worldtasks. Modelingpreferences
Inthispaper,weintroduceOptimalPreference
in a domain of interest requires both understand-
Elicitation with Natural language (OPEN)‚Äîa
ing what features of the domain are relevant to
framework that leverages the complementary ad-
model,andhowimportantthesefeaturesarerela-
vantagesofLMsandBayesianOptimalExperiment
tivetoeachother(Linetal.,2022;Lindneretal.,
Design(BOED)methods(seeFigure1).
2022; Sadigh et al., 2017; F√ºrnkranz and H√ºller-
OPENusesanLMtoselecttherelevantfeatures
*Collaborativeadvising;co-lastauthors. the user likely cares about (Figure 1, steps 1, 2),
4202
raM
8
]LC.sc[
1v43550.3042:viXraELICITATION PREDICTION
RecoC mo mn ete nn dt a tion W a p iu ch ksa e it nr a g mr ae a nt ye on c no p ln io nst i ee d n aet rri t a w icl h lf ee e a n tot u res h[ ah sa -s to-t po ip ci -c s- ps oc ri te sn , c ‚Ä¶e, ] h{ ah sa -ts o- pto icp -i sc p-s oc ri te sn , c ‚Ä¶e, } Lig hA tert ri ,f Sic aia fel rM , Mus oc rl ee s R ‚Äî obust
read? Rank in order of q s.t. maxEIG(q) = [1,0,0,0,0,1,‚Ä¶] vs.
Domain D importance for an average user. q [0,1,0,0,1,0,‚Ä¶] Features œÜ Test Sample x
1. Featurize 1 2. .W d Wish hce eut th hsse eer rs t a h s rce tii cea lnr et c i ec le = Hm (Œ∏qa )x ‚àíùîº Hp( (y Œ∏‚à£q) ‚à£[ y,q)] Pairwise F a y do eo q u sr u c m pe ris ra pett i tf o it e oh n r ni s Oo > fq p f ou to i re or r Om ny p Av ‚Äú te : iW oc <t noo N ur Bl L d :i n to G t so pi p ov i re c tn - ss ,t ch ‚Ä¶ie e } nf ,e c pa e, lt eu h ar ae sss e- t{ goh ip va i es c - -
Domain discusses sports 3. Select comparison <NL description>‚Ä¶‚Äù values for each feature for
3.‚Ä¶. Optimal Query query q the following article: ‚Ä¶
‚Ä¶
Features œÜ 2. In Ui st ei ra lize BP er le if ee fr e pn (c Œ∏e ) 4. V qe ur eb ra ylize 1. F Ie ta et murize h s hca ais se- -nt to ocep p:i i c c1- -.0
Preferences sports: 0.5
{has-topic-science, ‚Ä¶
has-top ‚Ä¶ic }-sports, lN aa nt gu ur aa gl
e
O aW p bto oiou unl td sA cy : io eau nn cp ear e r atf ie ncr dl e sF ae ma pt lu er i œÜz (e xd )
question cooking or Option B:
p(Œ∏)‚Üêp(Œ∏‚à£(q,y))‚àùp(y‚à£q,Œ∏)p(Œ∏) 5. P rU ep fd ea rt ee n cU es ser spoa rn t sa r at nic dl e tr a ab vo elu ?t ... y=Œ∏‚ãÖœï(x) P2 r. e fC eo rm ep nu ct ee
Option B
Particle Filter Pr Se cf oe rr ee n yce
Figure1: Overviewofthe OPEN framework. Inredarethepartswhereweusealanguagemodel. Duringthe
elicitationstage,first,adomainDisfeaturizedintofeatureœïwithalanguagemodel,whichalsogivesusaranking
ofimportanceoverfeatures(whichisusedtoinitializedapriorp(Œ∏)overuserpreferences). Basedontheprior
userpreferences,theoptimalpairwisecomparisonqueryqiscomputed,whichisthenverbalizedusinganLMinto
naturallanguage. Theuserresponseisthentakentoupdatetheprioroverbeliefs. Duringthepredictionstage,aLM
isusedtofeaturizeatestsampleaccordingtothefeaturizationœïderivedfromtheelicitationstage,thenapreference
scoreiscomputedusingtheelicitedpreferencesŒ∏.
and a Bayesian model to select optimal pairwise Houlsby et al., 2011) and has been used across
comparisonqueries(step3),whicharetranslated manydifferentdomainsanddisciplines(Cavagnaro
intonaturallanguagebyaLM(step4). InOPEN, et al., 2009; Dehideniya et al., 2018; Dushenko
weutilizeaLMtoprovidefeaturecoverageanda etal.,2020;Vanlieretal.,2012).
naturalconversationalinterfacewiththeuser(steps InBOED,thegoalistoselectanexperimental
1,2,4),whileleveragingaBayesianmodeltotrack designthatmaximizestheinformationgainforpa-
featureweightingsandselectinformativequestions rameters of interest. We begin with a predictive
(steps3,5). UsingOPENtoelicituserpreferences modelp(y | q,Œ∏)whichdefinestherelationshipbe-
inacontentrecommendationdomain,wefindthat tweenanexperimentq,anexperimentaloutcome
itoutperformsbothLM-andBOED-basedprefer- y,andtheparametersofinterestŒ∏. Thepriorp(Œ∏)
enceelicitationapproaches. describesaninitialbeliefabouttheparameters.
Wecanformalizetheinformationwegainabout
2 Preliminaries&Background
Œ∏ fromeachexperimentas:
We aim to actively model human preferences
IG(q,y) = H[Œ∏]‚àíH[Œ∏ | y,q], (1)
through iterative interactions with a user. Over
thecourseofaconversation,weconstructandup- where H is the Shannon entropy. However, be-
dateamodelthroughaseriesofuserqueries,each cause this notion of information gain relies on y,
designedsuchthatthey(1)maximizeinformation the outcome of the experiment, we cannot select
gainoftheusers‚Äôpreferencesand(2)canreliably theoptimalexperimentuntilaftertheoutcomehas
be answered by users and elicit informative re- beenobserved. Tofindtheoptimaldesign,wein-
sponses. steadtaketheexpectationoftheinformationgain
forthemarginaldistributionofy overallpossible
2.1 BayesianOptimalExperimentalDesign outcomesp(y | q) = E [p(y | Œ∏,q)],1 yielding:
p(Œ∏)
We use Bayesian Optimal Experimental Design
EIG(q) = E [IG(q,y)]. (2)
(BOED; Lindley, 1956, 1972; Rainforth et al., p(y|q)
2023)amathematicalabstractionforselectingopti- Thus,theoptimalexperimentcanbedefinedas:
malqueriesinanactivelearningsetup,asthebasis
q‚àó = argmax (EIG(q)). (3)
for our interaction framework. BOED is a com- q
monapproachtopreferencelearningandfunction
1ThisisequivalenttothemutualinformationbetweenŒ∏
estimation (Foster et al., 2019; Gal et al., 2017; andygivenq.In our preference learning setting, we want to 2. Initializing User Preferences: We prompt
pickthepairwisecomparisonquestion(q)thatwill theLMtoranktheNLfeaturesandsetaprior
allowustolearnabouttheuser‚Äôspreferences(Œ∏)as overuserpreferences,p(Œ∏),accordingtothis
efficientlyaspossible. Ateachinteraction,y isthe ranking.
user‚Äôsresponsetoq. BOEDisuniquelypowerful
inoursequentialsetting‚Äîenablingusto,aftereach 3. Selecting an Optimal Question: The
interaction, incorporate users‚Äô answers ad-hoc to Bayesianmodelsamplesallpossiblepairwise
greedilyupdateourbeliefoftheirpreferences. comparison questions and selects the maxi-
mally informative question, q‚àó using Equa-
2.2 ModelingHumanPreferences
tion(3).
Followingpreviouspreferencelearningliterature
(Linetal.,2022;Lindneretal.,2022;Sadighetal., 4. Verbalizequery: TheLMtranslatesq‚àó into
2017;Candeal-HaroandIndur√°in-Eraso,1995),we a NL question for the user (this can also be
modelhumanpreferencesaboutexamplesxaslin- thoughtofasœï‚àí1).
ear over the features of x. We suppose there is
a feature function œï that maps examples x into a 5. UpdateUserPreferences: Giventheuser‚Äôs
featurespaceRd,overwhichtheuserhasasetof response to the question, we compute the
preferenceweightsŒ∏ ‚àà Rd. Userpreferencescan Bayesianposteriorp(Œ∏ | y,q).
thenbemodeledintermsofŒ∏¬∑œï(x). Specifically,
6. Prediction: TheBayesianmodelpredictsthe
weuseaBradley-Terrymodel(BradleyandTerry,
user‚Äôs response to each test case, using the
1952)ofhumanpairwisepreferences,wheregiven
Bradley‚ÄìTerrymodelofhumanpreferences.
a choice between x and x , the probability the
a b
userchoosesoneovertheotherisgivenby:
Evenforthelinearpreferencemodeldescribedin
p(x | (x ,x ),Œ∏) Section2.2,computationoftheposteriorp(Œ∏ | y,q)
a a b
= œÉ(Œ∏¬∑œï(x )‚àíŒ∏¬∑œï(x )) (and thus computation of EIG(q)) is intractable.
a b
(4) We implement a tractable approximation using
p(x | (x ,x ),Œ∏)
b a b
a Bayesian Particle Filter (Gordon et al., 1993;
= œÉ(Œ∏¬∑œï(x )‚àíŒ∏¬∑œï(x ))
b a Doucet and Johansen, 2008; Elfring et al., 2021).
As each particle can be thought of as a plausible
3 The OPEN Framework
instantiationofuserpreferencesŒ∏,werefertoindi-
Existing Bayesian and bandit-based preference vidualparticlesaspersonasp .
i
learning methods assume that œï is known a pri- Crucially, though, OPEN does not necessi-
ori, and that examples can be straightforwardly tate the use of particle filtering or even BOED.
featurized. How should we apply these methods Ourframeworkfundamentallyprovidesadomain-
in real-world domains like content recommenda- agnostic approach to active and principled pref-
tionwherefeaturesthemselvesaredifficulttoex- erence learning: enabling any uncertainty-based
tract and translate into concrete instances? To preference-learning algorithm to interface with a
operationalizeBOEDandotheruncertainty-based userinNL.
preference learning approaches in complex, real-
An illustration of our approach can be found
world domains, we introduce OPEN: a domain-
inFigure1. Below,wedetailourimplementation
agnosticpreferencelearningframeworkthatcom-
oftheaformentionedcomponentsof OPEN.
binesLMswithBOED. OPEN usesLMstoiden-
tify environment-specific features and interface 3.1 Featurization
withauser,whileusingBOEDtomaintainprinci-
We prompt the LM with a general description of
pledapproachtoquestion-selectionanddecision-
thedomainofinterest(e.g. contentrecommenda-
making.
tionofnewsarticles),andaskittoproducenatural
Atahighlevel, OPEN learnsuserpreferences
languagedescriptionsofpertinentfeaturesinthat
byfollowingthebelowsteps:
domain,F. Forexample,inthecontentrecommen-
1. Featurization: Usingadescriptionofthedo- dationdomain,theLMoutputs‚Äúwhetherthearticle
main,D,theLMextractsasetofNLfeatures discussesscience‚Äùasapertinentfeature. Thislist
whichweusetodefinethefeaturefunctionœï. ofnaturallanguagefeaturescanthenbeconvertedtoafunctionœïthattransformstestsamplestofea- (o‚àó,o‚àó) ‚àà Q that maximizes the EIG about the
a b
turevaluesbypromptinganotherLMwithF and user‚ÄôspreferencesŒ∏.
atestsamplex(seeSection3.6). Recalling Equation 3, the EIG for the optimal
pairwisecomparison(o‚àó,o‚àó)withwhichtoquery
a b
3.2 InitializingUserPreferences
theuseristhengivenby:
WhenpromptingtheLMforfeaturesinSection3.1,
wesimultaneouslyaskittorankfeaturesfrommost (o‚àó a,o‚àó b) = argmax (oa,o b)‚ààQEIG(o a,o b)
toleastimportant. Theserankingsarethenusedto
3.4 QueryingtheUser: MappingPairwise
initializethepriorforOPEN‚Äôsbeliefoftheuser‚Äôs
ComparisonstoNL
preference,p(Œ∏). Atahighlevel,weassumethat
moreimportantfeaturesarealsomoreimpactfulfor Given the optimal pairwise comparison (o a,o b)
humans‚Äôdecisionmakingabouttheirpreferences, and natural language feature descriptions F, we
and thus, we should model greater diversity over promptaLMtoconvertthefeaturevectorso a,o b
themcomparedtolessimportantfeatures. Because into a NL question for the user. We also prompt
we assume that Œ∏ is linear in the feature space, theLMtosynthesizetwoexamplesinaccordance
we model p(Œ∏) as a Bayesian linear model with withthosefeaturevectors,whichisequivalentto
each feature weight parameterized by a normal
takentheinverseofthefeaturizationfunctionœï‚àí1.
distribution: We display these examples in the user interface
alongsideeachoptioninthepairwisecomparison
p(Œ∏ ) ‚àº N(0,œÉ2)¬∑w ,
i i question.
(5)
w = 1.2‚àí0.12i
i
3.5 PosteriorUpdate
whereœÉ2 isthebasevarianceforeachfeaturebe- At each interaction step t, having observed the
fore scaling, and w i captures the relative impor- user‚Äôs selection y t between (o a,o b), we update
tanceoffeaturesfromhighesttolowest. our belief about the user‚Äôs preferences (Œ∏) based
We construct our initial sample of N personas ontheirresponse(y )tothepairwisecomparison
t
bysamplingeachelementofeachpersonaindepen- question(q )bycomputingtheposterior:
t
dentlyfromp(Œ∏ ).
i
p(y | q ,Œ∏)¬∑p(Œ∏ | H)
t t
p(Œ∏ | y ,q ,H) = , (6)
3.3 SelectingtheOptimalQuestion t t p(y ,q ,H)
t t
Toefficientlylearnuserpreferences,weaimtose-
where H = {(q,y)} denotes the conversa-
lectthepairofoptionsthatmaximizetheEIGwith 0¬∑¬∑¬∑t‚àí1
tion history (prior sequence of questions and an-
regardstotheuser‚Äôspreferencesateachinteraction
swers). Weapproximatetheupdatein Equation(6)
step. ThisprocessisgroundedintheBOEDframe-
usingourparticlefilter. Ateachstept,wereweight
work,asdescribedearlier. Givenasetoffeatures,
eachparticlep by
F, we define the space of all possible pairwise i
comparisonquestionsas: w = p(y |o ,o ,p‚ä§)
i t a b i
(7)
Q = {(o a,o b)|o a,o b ‚àà {0,1}|F|, = œÉ(p‚ä§ i œï(o a)‚àíp‚ä§ i œï(o b)).
|F| |F|
Then,wefitaGaussiantothedistributionofw p s.
(cid:88) (cid:88) i i
(o ) = (o ) = K},
a i b j Finally,weresamplenewpersonasfromthisdistri-
i=1 j=1 bution. For a detailed overview of our algorithm,
seeAppendixB.
where each option o and o is represented as a
a b
binary vector indicating the presence (1) or ab-
3.6 Prediction
sence (0) of each feature in the comparison. In
Aftereachuserinteraction,weevaluateourmodel
our experiments, we set total number of features
viaasetoftestcases,whicharealsopresentedto
|F| = 10andthenumberoffeaturescomparedper
theuserattheendofthestudy. Forourtestcases,
query K = 2.2 The goal is to select the question
we use pairwise comparison questions (x ,x ),
a b
2From preliminary testing, we found that including ten where each x ,x are taken from real-world ex-
a b
totalfeatures(|F| = 10)andtwofeatures(K = 2)ineach
amples from the domain (e.g. for content recom-
optionbestbalancedusers‚Äômentaleffortwiththeinformativity
ofthequestion. mendation, the headline and lede of a New YorkTimes news article). For each test-case question, TheLMisprovidedthecompleteconversationhis-
weselecty ‚àà [x ,x ]accordingto: toryoftheinteractionandthefeaturesetfromSec-
a b
tion3.1beforeaskingeachsubsequentquestion. To
maxE [p(y | Œ∏,(x ,x ))] answerthequestion,theuserselectseither‚ÄòOption
Œ∏ a b
y
A‚Äôor‚ÄòOptionB‚Äôbasedontheirpreference.
(where the expectation is taken over our distribu-
UserSelf-MappingPairwiseComparisonstoNL
tionofp(Œ∏)atthatpointintime). Recallpreference
Weprovidetheuserthefeaturevectorsoftheopti-
probabilitiesp(y | Œ∏,(x ,x ))aredefinedfollow-
a b malpairwisecomparisonquestionasdetermined
ing the Bradley-Terry model (Equation (4)). To
fromSection3.3aswellastheNLdescriptionsof
compute œï(x ) and œï(x ) (recall we were given
a b eachfeature. Theusermustusethesedescriptions
a set of natural language descriptions of features
tointerpretthevectorcomparisonquery, thense-
F), we prompt a LM to give us concrete values
lecteither‚ÄòOptionA‚Äôor‚ÄòOptionB‚Äôbasedontheir
for each features, based on the natural language
preference.
featuredescriptionsandthetest-setsample.
4.3 HumanExperimentDetails
4 ExperimentalSetup
Werecruitednative-English-speakinghumanpar-
ticipantsfromProlific(PalanandSchitter,2017).
We use OPEN to investigate how incorporat-
‚àº40 individuals were allocated to each setting.3
ingLMsalongsideexplicitinformation-theoretic
MirroringLietal.(2023),weconductedourpro-
computations (via BOED) can improve existing
lificexperimentsintwosteps: (1)elicitation: par-
preference-learning methodology and provide a
ticipantswereaskedtoanswerquestionsabouttheir
novel NL interface with which to approach per-
preferences for 5 minutes; (2) prediction: partic-
sonalizedmachinelearning.
ipants were then presented with the 15 pairwise
We outline OPEN‚Äôs experimental details, the
comparisonquestionsandaskedwhichofthetwo
threedifferentbaselineswhichwecompareto,the
options they preferred. We recruited new partici-
evaluationframework,andthehumanparticipants‚Äô
pantsforeachtestacrossallexperiments.
interface.
4.4 Domain: ContentRecommendation
4.1 Hyperparameters
Weconsiderthetaskofcontentrecommendation‚Äì
In the featurization step, we query the LM for
recommending news articles for a user to read.
|F| = 10 features to define the domain. When
Eachapproachisevaluatedbasedonitsabilityto
samplingpairwisecomparisonquestions,eachop-
predictwhichnewsarticlestheuserwouldprefer
tioncontainsK = 2features. WeuseGPT-4asthe
on a set of 15 pairwise comparisons. Each com-
LMforallofourexperiments(seeAppendixFfor
parisoncontainstheledeandheadlinefromNew
additionaldetails).
YorkTimesarticles,hand-collectedbytheauthors.
Weselectthistask(1)becausepeople‚Äôspreferences
4.2 Baselines
havealargeamountofvarianceand(2)toperform
Weconsiderthreebaselines: a direct comparison to Li et al. (2023)‚Äôs method-
ology. Further information about the articles is
LM-onlyOpen-EndedQuestions FollowingLi
availableinAppendixC.
et al. (2023)‚Äôs best-performing method in their
content-recommendationsetting,wepromptaLM 4.5 Evaluation
toaskinformative,open-endedquestions,without
Weevaluate OPEN andtheabovebaselinesafter
anyexplicitoptimization. TheLMisprovidedthe
each user interaction on a test set of 15 pairwise
complete conversation history of the interaction
comparisonquestions,eachcomparingtwodiffer-
beforeaskingeachsubsequentquestion. Theuser
entreal-worldnewsarticles.
isabletoanswerthequestioninfree-formnatural
language. Methods Weevaluateusingtwodifferentpredic-
tion methods: in OPEN prediction, we use the
LM-onlyPairwiseComparisonQuestions We
3AllhumansubjectexperimentswereapprovedbytheIRB.
promptaLMtoaskaninformative,pairwisecom-
Additionaldetailsregardingtheuserstudiesareavailablein
parisonquestion,withoutanyexplicitoptimization. AppendixDonlyapproaches. ComparingtheOPENQues-
tions, OPEN Predictionsbarto OPEN Questions,
LMPredictionsbar,wefindthatOPENcanmake
predictions that better align with human prefer-
encesthanapromptedLM,fromthesamesequence
ofquestions. ThisimpliesthatLMsarestillsubpar
atin-context-learningofhumanpreferencesfrom
demonstrations, compared to Bayesian methods
which explicitly keep track of the human‚Äôs pref-
erencefunction;itunderscorestheimportanceof
explicitlytrackinghumanpreferences.
OPEN isbetteratelicitinghumanpreferences
comparedtoLM-onlyapproaches. Comparing
the OPEN Questions, OPEN Predictions bar to
Figure 2: Time-Integrated Delta Accuracy (TIDA)
for each method. We report the integral of the the comparable LM Pairwise Questions, OPEN
deltaaccuracyovertime. OPENimprovesovernaive Predictionsbar,wefindthatOPENPairwiseQues-
prompting-basedapproaches,allwhileimprovingtrans- tionsoutperformsLM-onlyPairwiseQuestionsfor
parencyandreducingcomputationalcost.Errorbarsare elicitation,indicatingthatwhenaskingquestions,
onestandarderror.
there is value in tracking human preferences and
queryingbasedonexplicitnotionsofuncertainty.
Of course, one benefit of LM elicitation ap-
OPEN predictionmethoddescribedinSection3.6
proachesisthatLMsarenotconstrainedtoasking
toanswereachtestsetquestion. InLMprediction,
only a certain type of question. Thus, as a top-
wepromptaLMtoanswerthetestquestion,con-
line,weelicitopen-endedquestionsfromLMs(LM
ditioned on the conversation history (up to some
Open-endedQuestions,LMPredictions). Though
turn),similartotheevaluationapproachtakenby
open-endedquestionsfaroutperformpairwiseques-
Lietal.(2023).
tions (both ones selected by OPEN and selected
Metrics Aftereachconversationturn,weevalu- by the LM) when evaluated with a LM, this im-
atethetest-setaccuracyatthatpointintime,using provementisovershadowedbythebenefitofbeing
oneofthetwomethodsabove. Aftertheconversa- abletouse OPEN prediction,whichisincompat-
tionhasended,wecalculatetheTime-Integrated iblewithLM-onlyelicitationmethods. However,
Delta Accuracy (TIDA), or the integral of the this suggests that future lines of work could ex-
‚Äú‚àÜaccuracyovertimecurve‚Äù,where‚àÜaccuracyis plore eliciting open-ended questions compatible
definedasthedifferencebetweentest-setaccuracy with OPEN predictions.
atthecurrentinteractionstepandtheinitialinterac-
OPENisbetteratelicitinghumanpreferences
tionstep(beforeanyuserresponses). Thismetric
compared to BOED-only approaches. When
rewards eliciting user preferences quickly‚Äîeven
we remove the verbalization step (User Self-
if two elicitation transcripts result in same ‚àÜ ac-
mapping, OPEN Predictions), wefind thatusers
curacy,theonethatarrivesatahigher‚àÜaccuracy
becomesignificantlyworseataccuratelyspecifying
earlierintimeisrewarded.
theirpreferences. Thus,havinganaturalinterface
5 Results forinteractingwiththeuser,whichweaccomplish
byverbalizingquestionswithaLM,isessentialfor
WepresenttheTIDAscoresforOPENagainstfive beingabletoaccuratelyandefficientlyelicituser
differentcombinationsofquestiongenerationand preferences.
predictionin Figure2(refertoSections3and4.2
for question generation methods and Section 4.5 6 Analysis
for prediction methods). Below, we discuss the
TheImportanceofFeatureWeightings Toun-
maintakeawaysfromourresults.
derstand the importance of feature weightings as
OPEN is better at making predictions aligned opposedtoabsoluterankingsoffeatures,weasked
withhumanpreferenceswhencomparedtoLM- userstoorderthesetofNLfeaturesbyimportance.Would you prefer Option A: an article Would you prefer Can you tell me about any specific themes, genres,
featuring Technology and Innovation and Option A: An article about the or subjects that you find particularly engaging or
Travel and Adventure latest advancements in technology intriguing when reading online articles?
OR OR
Option B: an article featuring Health and Option B: An article about recent User: I like to read about things that will help
Wellness and Business and Finance? developments in global politics? me in everyday life, for example how not to
procrastinate, astrology, and perhaps gardening.
For example: User: Option A I also like to do quizzes that help determine
Option A: "Exploring Silicon Valley: A Would you prefer where I fit in in different areas.
Journey Through the Hub of Innovation and Option A: An article about the
Technology" - This article takes you on a latest trends in fashion Besides self-improvement and astrology, are there
virtual tour of Silicon Valley, showcasing ‚úó BOED OR any other topics such as technology, travel,
the latest technological innovations and the Option B: An article about recent health, or arts that you enjoy reading about?
adventurous spirit of the region. ‚úó Preference breakthroughs in medical research?
OR Belief Model User:Yes, travel articles about experiences out of
O Ip nt ti eo rn s eB c: t i" oI nn v oe fs t Wi en lg l ni en s sH e aa nl dt h F: i nT ah ne c e" - This ‚úì Verbalize User: Option B th oe l do er rd i pn ea or py l et h aa nt d p ae ro tp il ce l eh sa v ae b oh ua td . m u sH ie ca il at nh s t fi rp os m f to hr e
a ir nt vi ec sl te i nd gi s ic nu s hs ee as l tt hh e a ng dr o ww ei ln lg n et sr se n id n do uf s tries, Query seventies and eighties
and how it impacts the financial market.
LM Pairwise Questions LM Open-Ended Questions
User: Option A
Would you prefer Option A: an article
featuring Politics and Current Affairs and
S O O Cp R p uo t lr i tt o us n r ea B n : ad n a dR n e Fc a or r oe t da i t c ai l no e dn f Ce oa ot ku ir ni gn ?g Arts and T l w T ih i h h ne s i e d t c ef s h f xo e l ( f a il o e t no n a u w e t r ti u e hn f r ' eg o e s r s lq n iu e a u se a r m ts c e b st h e i p r bo a r en r e c ls t s o o i e r ww c n r :i l t e l e s fl ) i p e n o ao i n tu n e d ut d a s rp i c eu c h w t a i 0 t a t t i r h iw n t so g i t c h tl e he e. W [ O Oo 1 R pu . tl id 0 o . ny o 1 Bu . : p 0 [r . 0e .f 0 e . 1r . 0 O . 0p .t 0 i . 0o .n 0 . 0A .: 0 . 1a . 0 a . 0r ] .t i 0c .l e 0 .w i 0t .h ] ?
F Oo pr t ie ox na m Ap :l e ": T h e Politics of the Olympics: A f si er cs ot n df e fa et au tr ue r ei n i nt h te h el i ls it s, t ,f e ea tt cu .r e T h1 e is the User: Option B
D T p a Oe h o f Re i l f p s i a t iD a i ri r c sv t s e i s c a ui l n rn e d rt oo e s u x p nC p o du l r ir o t nr r s ge e , n s tt f h t o eA h c f e u Of s la i i yi n n mr t g ps e i r o ca s n n e Gd c t a t h mS i e ep o so n c .r u t o rs f r" e n- t ‚úì ‚úì B PO rE eD ference f 0 1 2 3e ) ) ) )a t P T H Bu o e e ur l c a se i h l is t n t n i o h ea c l sr s o a se g n a y d ap n nr d a W do n e v C d l Fi u l id r I n ne r n e ad e n s n n o s cb t v ee a l A to f iw f o: a n i rs W [ O Oo 1 R pu . tl id 0 o . ny o 0 Bu . : p 0 [r . 0e .f 0 e . 0r . 0 O . 1p .t 0 i . 0o .n 1 . 1A .: 0 . 0a . 0 a . 0r ] .t i 0c .l e 0 .w i 0t .h ] ?
Option B: "Culinary Arts: The Culture and Belief Model 4) Sports and Recreation
Craft of Cooking" - This article delves into 5) Arts and Culture User: Option B
the artistry and cultural significance of ‚úó Verbalize 6) Travel and Adventure
various cooking techniques and cuisines. Query 7 8) ) F So co id e na cn ed aC no do k Ei nn vg i ronment
User: Option B 9) Education and Career Development
OPEN Questions User Self-Mapping Questions
Figure3: SampletranscriptsfromOPENvs. Baselines
We tested if a linear or exponential weighting of the model repeated questions: "the chatbot
theirself-reportedrankingswereabletoaccurately continued to ask the same exact question in
predicttheirpreferencesonthetestcases. Wecom- thesameway,itshouldhavedifferentvaria-
paredtheuser‚Äôsabsoluterankingto(1)theabsolute tionsandquestionstodivedeeperratherthan
rankingsofOPENbyaveragingOPEN‚Äôsrankings repeating itself." The transcripts from these
acrossallpersonasatthelastinteractionstepand userscorroboratetheirobservations.
(2)theperformanceofOPENatthelastinteraction
stepwiththelearnedfeatureweights. 2. LM‚Äôs pairwise questions (without an ex-
Our findings, in Figure 4, indicate that the rel- plicitfeatureset)failedtoprobeforfeature
ative weighting of features is critical to OPEN‚Äôs weighting. Ausercommentedthat: "I‚Äômnot
prediction, and that user‚Äôs self-reported rankings surewhatthepurposehereis,butifitwasto
are not a good indicator of their actual prefer- pinpoint my interests than they should have
ences. Thissuggeststhatmethodsthatrelysolely beencomparingmypreviouschoicestogether
onhuman-writtenspecifications,suchasprompts, aswell!"
may not be as useful as methods that are able to
keeptrackofthepreciserelativeweightsbetween 3. Usersstruggledtoself-mapfeaturestoNL
features, as feature weights are typically much questions. Oneuserstated: "Iwasthoroughly
harderforuserstospecifythanfeaturerankings. confused,howeverIthinkIfigureditoutand
clickedaccordingly."
Qualitative Analysis At the end of the study,
wecollectedopen-endedfeedbackfromtheusers
We also collected empirical feedback on partici-
regardingtheirexperienceinteractingwiththesys-
pants‚Äô perceived effort across the different meth-
tem. Acrossthedifferentelicitationmethods,we
ods. Wefoundthattheyreportedconsistentlevels
found:
ofmentaldemandacrossallmethods(includingthe
1. LM‚Äôsopen-endedquestionstoberepetitive LMOpen-endedQuestions),indicatingthatOPEN
andoverreliantontheLM‚Äôsprioroveruser questionswerenotmorechallengingforusersthan
preferences. For example one user noted: othersettings. Furtheranalysisandvisualizationof
"the chat bot did not seem to pick up on users‚ÄôempiricalfeedbackisincludedinAppendix
many parts of my input, as though it had its D.Transcriptsfromeachoursettingscanbefound
own ‚Äôagenda‚Äô." Another user observed that inFigure3.newdatapoints,oftenselectedfromapool(Settles,
2010). Uncertainty-basedactivelearningcomputes
thenextexampletoshowtheuserbasedonexplicit
notionsofuncertainty(LewisandCatlett,1994).
However,theseapproachesareoftenonlyappli-
cabletosimpledomainswithknownfeaturespaces
(or existing pools of examples), and may not be
straightforwardtoderiveforcomplexdomains.
LMPreferenceLearning Morerecently,Lietal.
(2023); Piriyakulkij et al. (2023) introduced ap-
proachestoactiveelicituserpreferenceswithlan-
guagemodels. TheydemonstratedLMsareableto
Figure4: AccuracyforOPEN‚Äôsabsolutefeaturerank- activelyelicituserpreferencesacrossawidevari-
ings,users‚Äôselfreportedabsolutefeaturerankings,and etyofdomainsbeyondcertainclassicalpreference
OPEN‚Äôslearnedweightsoverfeaturesasdescribedin learning baselines. However, our work demon-
Section 6. Our analysis indicates removing access to strates that LMs are still subpar at tracking and
preciseweightshurtsperformance. Errorbarsareone
usingfeatureweightingstoaskinformativeques-
standarderror.
tions.
8 Discussion&FutureWork
7 RelatedWork
We presented OPEN, a domain-agnostic frame-
TaskAmbiguityandUnderspecification Prior
workforcombiningBayesianOptimalExperimen-
research has studied ambiguity in the context of
tal Design with LMs‚Äìusing BOED to guide the
language-guidedtasks(Lakeetal.,2019;Tamkin
choiceofinformativequestions,andtheLMtoex-
etal.,2023). Inparticular,inthecontextofprompt
tract environment-relevant features and translate
engineering(Brownetal.,2020),writingcomplete
abstractfeaturequeriesintorealNLquestions. Be-
and unambiguous task specifications can be dif-
yondtheimprovementsdemonstratedbyourfind-
ficult (Li et al., 2023; IEEE, 1984). Futhermore,
ings, our system has two additional advantages
recentdevelopmentshaveencouragedfine-tuning
overLM-onlymethods: (1)wecanimprovetrans-
approaches such as reinforcement learning with
parency through extracting explicit weights and
human feedback (RLHF) (Ziegler et al., 2019;
uncertainties on NL features. In our framework,
Christiano et al., 2017) and direct preference op-
theNLfeaturesfromtheLMaccompaniedbyan
timization(DPO)(Rafailovetal.,2023)tobetter
externaluncertainty-drivenmodelconditionedon
align LLM behaviors with humans‚Äô (underspeci-
the features provide greater transparency than an
fied)preferences. Thesetechniques,however,all
LM alone. With OPEN, we can understand how
assumeaccesstoexistinghumanpreferencedata.
importanteachfeatureistotheelicitationandpre-
Our goal in this work is to examine how to elicit
dictionprocess. (2)Wecanreducecomputational
suchdataefficiently.
costs. Byrepresentinguserpreferenceswithalin-
Classical Preference Learning Techniques ear model, we can avoid the expensive training
Learninghumanpreferencesisarichareaofwork orinferenceprocedureswithlargelanguagemod-
thathasspannedmanyfieldsoverpastfewdecades. els. In OPEN, the particle filter models a user‚Äôs
Much work has gone into optimally querying for behavior while still incorporating the high-level,
userpreferences. AsidefromBayesianOptimalEx- contextualinformationencodedinLMs. Further-
perimentalDesign,whichweuseinthispaper,ap- more, at test time, conducting inference on this
proacheshaveincludedconjointanalysis(STERN, linearsystemisordersofmagnitudecheaperand
1990;AroraandHuber,2001;Kuhfeldetal.,1994), yieldsbetterresultsthananLM.
polyhedral methods (Toubia et al., 2007), multi- OPEN‚Äôs flexibility allows for the exploration
armed bandits (Lu et al., 2010), and dueling ban- of other, more intensive preference-learning ap-
dits(Heckeletal.,2019),etc.(Vayanosetal.,2021) proaches such as variational Bayesian methods
Active learning is an area of machine learning (e.g. Foster et al., 2019) or multi-armed bandits
focusedoninteractivelyqueryinganexperttolabel (e.g.Lindneretal.,2022). Wearealsoexcitedbythepotentialtofurtherincorporateaspectsofreal- supervision.
worldlearningenvironments. Forexample,future
UserStudy WeusedtheProlificplatform(Palan
work could investigate using OPEN to develop
and Schitter, 2017) to conduct all of our human
an adaptive feature space‚Äìas the model‚Äôs uncer-
subjectexperiments. Wepaidworkersinlinewith
tainty increases, the model could query for and
Prolific guidelines and solicited initial feedback
optimizenewfeaturesthatmightbetterexplainpat-
viapilotstudiestomaketheinteractiveexperience
ternswithinthedata. Additionally,recentadvance-
moreenjoyableforparticipants. Anecdotally,many
mentsinfine-tuningmodelsfromhumanfeedback
participantsexpressedenjoyingthestudy:
(Ouyang et al., 2022; Rafailov et al., 2023; Etha-
yarajhetal.,2024)foundsignificantdifferencesin 1. "Thiswasaveryinterestingexercise. Thank
datacurationandmodelperformancewhenchang- youfortheopportunity."
ingtheexperimentaldesign. OPENenablesfuture
researchtoexploretheimpactofthisparameterin 2. "itwasreallyinteresting. goodjob."
anactivepreferenceelicitationenvironment.
3. "ThetaskwasstraightforwardandIlikedthat
therewerediversetopicstochoosefrom. Itfelt
Limitations
likeIhadthechancetoexpressmypreferences
Although we provide the steps to build towards onvarioussubjects"
betteractiveuncertainty-drivenpreferencelearning
Reproducibility Statement We provide thor-
methods,ourworkhasseverallimitations. Inour
ough experimental details including the user in-
study, OPEN wasconstrainedtopairwisequeries
terfaceandLMpromptsintheAppendix. Wewill
in a content recommendation setting. Also, we
also release our codebase and anonymized user
operated under a fixed feature space and with a
dataonGitHub.
closed-sourceLM.Futureworkcouldexploreex-
panding along each of these axes: investigating
Acknowledgements We would like to thank
otherpreference-learningdomains,incorporating
Muhammed Razzak, Andreas Kirsch, Jannik
open-endedquestions,expandingthefeaturespace
Kossen, and Michael Tamkin for useful conver-
in conversation, and testing other LMs. Futher-
sations as well as Lisa Schut, Gabe Grand, and
more, future research should explore the impact
Mehul Damani for feedback on earlier drafts of
ofOPENacrossadditionalreal-worldsettingsand
the paper. This material is based upon work sup-
populationgroups.
portedbytheNationalScienceFoundationunder
IIS-2238240andIIS-2212310. BZLissupported
EthicalConsiderations
bytheNDSEGFellowship. JAissupportedbythe
SloanResearchFellowship.
Ourworkpresentsbothethicalbenefitsandrisks.
Understandinguserpreferencesinunderspecified
environments is crucial to avoiding real-world
References
issues with AI systems such as spreading hate
speech, generating illicit or copyrighted content, Neeraj Arora and Joel Huber. 2001. Improv-
ing Parameter Estimates and Model Prediction
aswellasperpetuatingbiasandstereotypes. Fur-
by Aggregate Customization in Choice Experi-
thermore, as more systems are deployed without ments. JournalofConsumerResearch,28(2):273‚Äì
expert-supervision, ensuring that they can align 283. _eprint: https://academic.oup.com/jcr/article-
themselveswithusers‚Äôvaluesiscrucialtoensuring pdf/28/2/273/17927222/28-2-273.pdf.
safe and healthy interactions. However, in align-
RalphAllanBradleyandMiltonE.Terry.1952. Rank
ing with user preferences, it is also possible that analysisofincompleteblockdesigns: I.themethod
systemsmayalignwithunwantedordangerousten- of paired comparisons. Biometrika, 39(3/4):324‚Äì
345.
dencies. Developingguidelinesformodels‚Äôvalue-
systemsiscrucialtoensuringthelong-termsuccess TomB.Brown,BenjaminMann,NickRyder,Melanie
ofhuman-AIinteractions. Furthermore, working Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
withpreferencedatainherentlypresentsrisksasit Neelakantan,PranavShyam,GirishSastry,Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
canbeusedmaliciouslytomanipulateindividuals.
Gretchen Krueger, Tom Henighan, Rewon Child,
Itisnecessarytoensurethatpreferencedata,when
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
usedbyAIsystems,iscollectedrobustlyandwith ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess, NeilHoulsby,FerencHusz√°r,ZoubinGhahramani,and
Jack Clark, Christopher Berner, Sam McCandlish, M√°t√© Lengyel. 2011. Bayesian active learning for
Alec Radford, Ilya Sutskever, and Dario Amodei. classificationandpreferencelearning.
2020. Languagemodelsarefew-shotlearners.
IEEE.1984. Ieeeguideforsoftwarerequirementsspec-
JuanCarlosCandeal-HaroandEstebanIndur√°in-Eraso. ifications. IEEEStd830-1984,pages1‚Äì26.
1995. A note on linear utility. Economic Theory,
6(3):519‚Äì522. WarrenF.Kuhfeld,RandallD.Tobias,andMarkGar-
ratt.1994. Efficientexperimentaldesignwithmar-
DanielCavagnaro,JayMyung,MarkPitt,andJanneKu- ketingresearchapplications. JournalofMarketing
jala.2009. Adaptivedesignoptimization: Amutual Research,31(4):545‚Äì557.
information-basedapproachtomodeldiscrimination
incognitivescience. Neuralcomputation,22:887‚Äì BrendenM.Lake,TalLinzen,andMarcoBaroni.2019.
905. Humanfew-shotlearningofcompositionalinstruc-
tions. InAnnualMeetingoftheCognitiveScience
PaulFChristiano,JanLeike,TomBrown,MiljanMar- Society.
tic, Shane Legg, and Dario Amodei. 2017. Deep
Reinforcement Learning from Human Preferences. DavidD.LewisandJasonCatlett.1994. Heterogeneous
InAdvancesinNeuralInformationProcessingSys- UncertaintySamplingforSupervisedLearning. In
tems,volume30.CurranAssociates,Inc. WilliamW.CohenandHaymHirsh,editors,Machine
LearningProceedings1994,pages148‚Äì156.Morgan
MahasenB.Dehideniya,ChristopherC.Drovandi,and Kaufmann,SanFrancisco(CA).
JamesM.McGree.2018. Optimalbayesiandesign
fordiscriminatingbetweenmodelswithintractable BelindaZ.Li,AlexTamkin,NoahGoodman,andJacob
likelihoodsinepidemiology. ComputationalStatis- Andreas. 2023. Eliciting human preferences with
tics&DataAnalysis,124:277‚Äì297. languagemodels.
A. Doucet and A. M. Johansen. 2008. A tutorial on JessyLin,DanielFried,DanKlein,andAncaDragan.
particlefilteringandsmoothing: Fifteenyearslater. 2022. Inferringrewardsfromlanguageincontext.
Sergey Dushenko, Kapildeb Ambal, and Robert D. JessyLin,NicholasTomlin,JacobAndreas,andJason
McMichael. 2020. Sequential bayesian experi- Eisner.2023. Decision-orienteddialogueforhuman-
ment design for optically detected magnetic reso- aicollaboration. arXivpreprintarXiv:2305.20076.
nanceofnitrogen-vacancycenters. Phys.Rev.Appl.,
14:054036. D.V.Lindley.1956. Onameasureoftheinformation
providedbyanexperiment. TheAnnalsofMathemat-
JosElfring,ElenaTorta,andRen√©vandeMolengraft. icalStatistics,27(4):986‚Äì1005.
2021. Particlefilters: Ahands-ontutorial. Sensors,
21(2). D.V.Lindley.1972. BayesianStatistics. Societyfor
IndustrialandAppliedMathematics.
Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff,
DanJurafsky,andDouweKiela.2024. Kto: Model DavidLindner,SebastianTschiatschek,KatjaHofmann,
alignmentasprospecttheoreticoptimization. and Andreas Krause. 2022. Interactively learning
preferenceconstraintsinlinearbandits.
Adam Foster, Martin Jankowiak, Eli Bingham, Paul
Horsfall,YeeWhyeTeh,TomRainforth,andNoah TylerLu,DavidPal,andMartinPal.2010. Contextual
Goodman.2019. Variationalbayesianoptimalexper- multi-armed bandits. In Proceedings of the Thir-
imentaldesign. teenth International Conference on Artificial Intel-
ligence and Statistics, volume 9 of Proceedings of
JohannesF√ºrnkranzandEykeH√ºllermeier.2012. Pref- MachineLearningResearch, pages485‚Äì492, Chia
erence Learning, pages 2669‚Äì2672. Springer US, LagunaResort,Sardinia,Italy.PMLR.
Boston,MA.
OpenAI.2023. Gpt-4technicalreport.
YarinGal,RiashatIslam,andZoubinGhahramani.2017.
Deepbayesianactivelearningwithimagedata. LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car-
rollL.Wainwright,PamelaMishkin,ChongZhang,
N.J. Gordon, D.J. Salmond, and A.F.M. Smith. 1993. SandhiniAgarwal,KatarinaSlama,AlexRay,John
Novelapproachtononlinear/non-gaussianbayesian Schulman,JacobHilton,FraserKelton,LukeMiller,
stateestimation. IEEProc.FRadarSignalProcess. Maddie Simens, Amanda Askell, Peter Welinder,
UK,140(2):107. Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
Traininglanguagemodelstofollowinstructionswith
Reinhard Heckel, Nihar B. Shah, Kannan Ramchan- humanfeedback.
dran,andMartinJ.Wainwright.2019. Activerank-
ingfrompairwisecomparisonsandwhenparametric StefanPalanandChristianSchitter.2017. Prolific.ac‚Äîa
assumptions do not help. The Annals of Statistics, subjectpoolforonlineexperiments. JournalofBe-
47(6):3099‚Äì3126. havioralandExperimentalFinance,17:22‚Äì27.TopPiriyakulkij,VolodymyrKuleshov,andKevinEllis. A Appendix
2023. Active preference inference using language
modelsandprobabilisticreasoning. IntheAppendixbelow,weprovideadditionalde-
tailsregardingourmethodology,userstudies,and
RafaelRafailov,ArchitSharma,EricMitchell,Stefano
LMprompts.
Ermon,ChristopherD.Manning,andChelseaFinn.
2023. Directpreferenceoptimization:Yourlanguage
B ParticleFilterDetails
modelissecretlyarewardmodel.
Thedetailedimplementationofourparticlefilter
TomRainforth,AdamFoster,DesiRIvanova,andFred-
dieBickfordSmith.2023. Modernbayesianexperi- algorithmisbelow:
mentaldesign. Forthei-thpersonap atconversationalturnt:
i
DorsaSadigh,AncaD.Dragan,S.ShankarSastry,and
1. We assume the Bradley-Terry model of hu-
Sanjit A. Seshia. 2017. Active preference-based
man preferences (Bradley and Terry, 1952),
learningofrewardfunctions. InRobotics: Science
andSystems. wheretheprobabilityofpreferringOptionA
overOptionBisdirectlyproportionaltothe
Burr Settles. 2010. Active learning literature survey.
exponentialofthedifferenceinoutcomesbe-
UniversityofWisconsin,Madison,52.
tweenOptionAandOptionB.Wecalculate
HAL STERN. 1990. A continuum of paired com- theutilityofeachoptionforeachpersona:
parisons models. Biometrika, 77(2):265‚Äì273.
_eprint: https://academic.oup.com/biomet/article-
U(o ,p ) = p ¬∑o ,
{a,b} i i {a,b}
pdf/77/2/265/5618454/77-2-265.pdf.
andcomputethepreferenceprobabilitythe
AlexTamkin,KunalHanda,AvashShrestha,andNoah
Goodman. 2023. Task ambiguity in humans and personapreferso a overo b:
languagemodels. InTheEleventhInternationalCon-
ferenceonLearningRepresentations(ICLR). p(y |o ,o ,pi) = œÉ(U(o ,p )‚àíU(o ,p )).
t a b t a i b i
Katherine Tian, Eric Mitchell, Allan Zhou, Archit
Sharma,RafaelRafailov,HuaxiuYao,ChelseaFinn, 2. The weight of each persona is set to the
andChristopherD.Manning.2023. Justaskforcali- posteriorprobability
bration: Strategiesforelicitingcalibratedconfidence
scoresfromlanguagemodelsfine-tunedwithhuman wÀÜi = p(y |o ,o ,pi),
t t a b t
feedback.
Wethennormalizetheweightsoverallper-
OlivierToubia,JohnHauser,andRosannaGarcia.2007.
Probabilisticpolyhedralmethodsforadaptivechoice- sonas:
wÀÜi
based conjoint analysis: Theory and application. wi = t
MarketingScience,26(5):596‚Äì610. t (cid:80)N wÀÜi
i=1 t
Joep Vanlier, Christian Tiemann, Peter Hilbers, and
3. Finally, we fit a Gaussian N(¬µ,œÉ) to the re-
Natal van Riel. 2012. A bayesian approach to tar-
geted experiment design. Bioinformatics (Oxford, weightedpersonas,bysettingitsparameters
England),28:1136‚Äì42. to
(cid:80) wi
PhebeVayanos,YingxiaoYe,DuncanMcElfresh,John ¬µ = i t
N
Dickerson,andEricRice.2021. Robustactivepref-
erenceelicitation.
(cid:114)(cid:80)
(w ‚àí¬µ)2
œÉ = i i
N
Daniel M. Ziegler, Nisan Stiennon, Jeff Wu, Tom B.
Brown, Alec Radford, Dario Amodei, Paul Chris-
WeresamplepersonasfromN(¬µ,œÉ)viasys-
tiano, and Geoffrey Irving. 2019. Fine-tuning lan-
guage models from human preferences. ArXiv, tematicresampling. Thisstepisimportantfor
abs/1909.08593. preventingweightcollapse.
C ContentRecommendationEvaluation
Details
Forevaluationinourcontentrecommendationdo-
main, we collected 30 articles‚Äìthe article titles
andlede‚ÄìfromtheNewYorkTimes(https://www.
nytimes.com/). Articletopicsrangedfrom"WhattoCookThisWeek"to"Barbievs. Oppenheimer" 4. feedback_interaction_coverage_posttest: "Af-
to "Fighting to Govern Myanmar." Articles were terseeingtheexamplesinthe*second*part
randomly paired to create a persistent set of 15 ofthetask,howwelldoyoufeelthechatbot/
pairwise comparison questions which were used theansweryouwrote(inthefirstpartofthe
throughoutallofourevaluations. task)coveredtheimportantissuesoraspects
oftheseexamples?"
D UserStudy
5. feedback_testcase_use_history: "When per-
D.1 ProlificSurvey formingthe*second*partofthetask,towhat
extent did you refer back to your conversa-
ScreenshotsoftheProlificsurveyfromthepartici-
tionhistory/answerfromthefirstpartofthe
pants‚Äôviewpointacrossdifferentstagesofthestudy
task?"
areprovidedinthefollowingpages(Figures5-9).
WerecruitedEnglish-speakingparticipantslocated
6. feedback_lm_experience: "How much expe-
intheUnitedStates. Foreachelicitationandpre-
riencehaveyouhad(ifany)withinteracting
diction setting reported in Figure 2, we recruited
withlanguagemodels(e.g. ChatGPT,GPT4,
roughly40users. Specificallyforeachsettingwe
etc.)?"
had:
As we can see, OPEN was not more challeng-
1. OPEN Questions, OPEN Predictions: 44
ing than the other methods across the different
users
axes. Unsurprsingly, in the User-Self Mapping
case,userswentbacktolookattheirconversation
2. LMQuestions,OPENPredictions: 48users
history much less frequently than other in other
methods. Interestingly,usersfeltthatLMPairwise
3. User Self-Mapping, OPEN Predictions: 39
questions covered their preferences well pre-test,
users
butthisrankingdroppedsignificantlypost-test(and
4. OPENQuestions,LMPredictions: 44users did not translate to a higher accuracy on the test
set).
5. LMPairwiseQuestions,LMPredictions: 41
F LMPrompts
users
Below,weincludethepromptsusedforthediffer-
6. LMOpen-endedQuestions,LMPredictions:
entLM-basedtasks. WequeriedOpenAI‚ÄôsGPT-4
39users
(OpenAI,2023)viatheAPI.Allqueriesweremade
withtemperature0. Ourpromptformattingfollows
E Analysis: UserFeedback previousworkonverbalizingLMconfidence(Tian
etal.,2023).
Figure10visualizestheuserfeedbackacrossmul-
tipledifferentaxis. Eachoftheaxisandtheircor- F.1 LMOpen-endedQuestions
respondingqueryfortheuserisbelow:
Your task is to learn what topics a user is
interested in reading online articles about.
1. feedback_challenge: "Howmentallydemand- People‚Äôs interests are broad, so you should seek
to understand their interests across many
ingwasinteractingwiththechatbot/writing
topics; in other words, go for breadth rather
youranswer?"
than depth. Do not assume a user has given a
complete answer to any question, so make sure to
2. feedback_new_issues_interaction: "To what keep probing different types of interests.
extentdidthechatbotraiseissuesoraspects
Previous questions: {
aboutyourpreferencesthatyouhadn‚Äôtprevi- interaction_history_formatted}.
ouslyconsidered?"
Generate the most informative open-ended
question that, when answered, will reveal the
3. feedback_interaction_coverage_pretest: most about the desired behavior beyond what has
"How comprehensively do you feel the chat- already been queried for above. Make sure your
question addresses different aspects of their
bot‚Äôs questions / your answer characterized
preferences than the questions that have already
yourpreferencesaboutthetask?" been asked. At the same time however, theFigure5: Startscreen
Figure6: Question-answeringprocessFigure7: Collectinguserfeedbackmetrics
Figure8: Evaluation‚ÄìuseransweringpairwisecomparisiontestcasesFigure9: UserreordersNLfeaturesfrommosttoleastimportant
Figure10: Userfeedbackanalysis. EachVariableinthelegendmapstoauserpromptinAppendixE.OPEN
Questionsarenotmorechallengingforuserstoanswercomparedtoothermethods.question should be bite-sized, and not ask for Make sure your question addresses different
too much at once. Phrase your question in a way aspects of their preferences than the questions
that is understandable to non-expert humans; do that have already been asked. At the same time
not use any jargon without explanation. Generate however, the question should be bite-sized, and
the question and nothing else. not ask for too much at once. Phrase your
question in a way that is understandable to non-
Provide your output in the format: expert humans; do not use any jargon without
explanation.
Question: <question>
Then create two specific, real-world examples of
news articles matching the description you
F.2 LMPairwiseQuestions,LMPredictions provided. For each feature you use, make sure
you match the wording of the feature verbatim to
Your task is to learn what topics a user is the list above. Provide your output in the
interested in reading online articles about. format:
People‚Äôs interests are broad, so you should seek
to understand their interests across many Would you prefer Option A: an article with [
topics; in other words, go for breadth rather features for option A]
than depth. Do not assume a user has given a OR
complete answer to any question, so make sure to Option B: an article with [features for option B
keep probing different types of interests. ]?
Previous questions: { For example: [Option A title and simple, one
interaction_history_formatted}. sentence description]
OR
Generate the most informative pairwise Option B: [Option B title and simple, one
comparison question that, when answered, will sentence description]
reveal the most about the desired behavior
beyond what has already been queried for above.
F.4 ExtractingEnvironmentFeatures
Make sure your question addresses different
aspects of their preferences than the questions
Your task is to learn what topics a user is
that have already been asked. At the same time
interested in reading online articles about.
however, the question should be bite-sized, and
Enumerate 10 binary topics (features) that may
not ask for too much at once. Phrase your
impact user‚Äôs decisions when choosing which
question in a way that is understandable to non-
article to read. People‚Äôs interests are broad,
expert humans; do not use any jargon without
so you should seek to understand their interests
explanation. Generate the pairwise comparison
across many topics; in other words, go for
question and nothing else.
breadth rather than depth.
Provide your output in the format:
Only include the most important features in your
list. Do not include features for which the
Would you prefer
user‚Äôs preference would be obvious. Order the
Option A: <first article option>
features from the most to least likely of
OR
interest.
Option B: <second article option>?
Your output should be in the following format:
1) <first feature>
F.3 LMPairwiseQuestion,OPENPredictions
2) <second feature>
Your task is to learn what topics a user is
F.5 MappingBOEDPairwiseComparisionto
interested in reading online articles about.
People‚Äôs interests are broad, so you should seek NL
to understand their interests across many
topics; in other words, go for breadth rather Create two specific, real-world examples of news
than depth. Do not assume a user has given a articles someone might be interested in reading
complete answer to any question, so make sure to based on the following question which
keep probing different types of interests. juxtaposes two different news articles:
"Would you prefer Option A: an article with {
Previous questions: { pairwise_comparison_0}
interaction_history_formatted}. OR
Option B: {pairwise_comparison_1}?".
The following {num_features} features describe This question instantiates two articles based on
people‚Äôs preferences for different kinds of their feature values. Features lie on a
articles: {features}. spectrum ranging from 0.0 to 1.0, where 0.0
corresponds to the absence of that feature and
Generate the most informative pairwise 1.0 indicates an extremely high presence of it.
comparison question that, when answered, will
reveal the most about the desired behavior Make sure to maintain the relative difference
beyond what has already been queried for above. between the two articles when generating the
descriptions.Provide your output in the format:
Option A: [Option A title and simple, one
sentence description]
OR
Option B: [Option B title and simple, one
sentence description]
F.6 LMEvaluation
Provide your best guess and the probability that
it is correct (0.0 to 1.0) for the following
question. Give ONLY the guess and probability,
no other words or explanation. If you are unsure
take your best guess (between Option A and
Option B). For example:
Guess: <most likely guess--either Option A or
Option B--as short as possible; not a complete
sentence!>
Probability: <the probability between 0.0 and
1.0 that your guess is correct, without any
extra commentary whatsoever; just the
probability!>.
A user has a particular set of preferences over
what articles they would like to read. They have
specified their preferences in a conversation
below:
{preferences}
The question is: Based on these preferences,
which of the following two articles would the
user prefer?
Option A: {test_case_0}
OR
Option B: {test_case_1}