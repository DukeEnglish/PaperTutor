IEEESENSORSJOURNAL,VOL.XX,NO.XX,XXXX2017 1
Sparse Wearable Sonomyography
Sensor-based Proprioceptive Proportional
Control Across Multiple Gestures
AnneTryphosaKamatham,Student Member, IEEE,Kavita Sharma,and Srikumar Venkataraman,
Biswarup Mukherjee,SeniorMember, IEEE
Abstract—Sonomyography(SMG)isanon-invasivetechniquethat
uses ultrasound imaging to detect the dynamic activity of mus-
A-mode signal
cles. Wearable SMG systems have recently gained popularity due envelope
to their potential as human-computer interfaces for their supe-
Target
rior performance compared to conventional methods. This paper
demonstrates real-time positional proportional control of multiple
gesturesusingamultiplexed8-channelwearableSMGsystem.The
amplitude-mode ultrasound signals from the SMG system were
Housing
utilized to detect muscle activity from the forearm of 8 healthy Matching Backing
layer
individuals.Thederivedsignalswereusedtocontroltheon-screen network
movementofthecursor.Atargetachievementtaskwasperformed
PZT disc
to analyze the performance of our SMG-based human-machine
interface.OurwearableSMGsystemprovidedaccurate,stable,andintuitivecontrolinreal-timebyachievinganaverage
successrate greater than 80% with all gestures.Furthermore, the wearable SMG system’s abilitiesto detect volitional
movementanddecodemovementkinematicinformationfromSMGtrajectoriesusingstandardperformancemetricswere
evaluated.OurresultsprovideinsightstovalidateSMGasanintuitivehuman-machineinterface.
IndexTerms—Sonomyography,A-modeultrasound,Proportionalcontrol,Prostheticcontrol,Human-machineinterfaces.
I. INTRODUCTION prostheses could be controlled during real-life use [3], pri-
marilydueto the limitationsof EMG. Poorspatialspecificity,
Intuitivecontrolofpoweredupperextremityprostheticsand
muscle cross-talk in EMG measurements, electrode shifts,
assistive devices is essential to restore function in individ-
limb position, and force variations result in poor functional
uals with motor disabilities. Detection of volitional motion
outcomes during real-life usage [4]–[6]. Therefore, exploring
intent is critical to achieving accurate and intuitive control.
alternate non-invasive sensing modalities that could robustly
Surfaceelectromyography(EMG),a techniquethatsenses the
detect the volitional movement from muscles is necessary to
electrical activity in the muscles, is widely used to detect
enable dexterous control of the biomechatronic systems.
motor intent. Modern EMG-based control strategies provide
Sonomyography (SMG) has recently gained importance
control over multiple degrees of freedom (DOFs) utilizing
because of its ability to sense voluntary movement intention,
measurements performed across multiple channels, referred
which is crucial for efficient biomechatronic control. SMG
to as pattern-recognition systems [1], [2]. Despite advances
detects mechanical deformations that occur alongside the
in control strategies, only a few DOFs of the myoelectric
electrical potential changes of the muscles during voluntary
This manuscript was compiled on March 11, 2024. This work has movement.SMG uses ultrasoundimagingtechniquesto sense
beenfunded in partbythe Science and EngineeringResearch Board the anatomical deformations during dynamic activity, unlike
(SERB),DepartmentofScienceandTechnology,GovernmentofIndia,
EMG,whichsenseschangesinelectricalpotentials.Brightness
throughaCoreResearchGrant(CRG/2021/004967,PI:BM),IEEEIn-
strumentationandMeasurementSocietyGraduateStudentFellowship mode (B-mode) ultrasound imaging technique provides spa-
2022 (Recipient: ATK) and by IIT Delhi through a Faculty Interdisci- tiallyresolvedimagesofmusclesandtheiranatomicaldetails.
plinaryGrant(MI02374).
Several studies quantified the changes in anatomical struc-
AnneTryphosaKamathamandKavitaSharmaarewiththeCentrefor
BiomedicalEngineering,IndianInstituteofTechnologyDelhi,NewDelhi tures such as muscle fiber length [7], cross-section [8], and
110016. pennation angle [9]. They found a high correlation with joint
SrikumarVenkataramaniswiththeDepartmentofPhysicalMedicine
angles,muscleforce,andmuscle activationlevels[10],which
and Rehabilitation, All India Institute of Medical Sciences, New Delhi
110029. can be used for human-machineinterfaces. B-mode SMG has
Biswarup Mukherjee is with the Centre for Biomedical Engineering, been widely used to demonstrate gesture classification [11].
Indian Institute of Technology Delhi, New Delhi 110016 and with the
Akhlagi et al. demonstrated the classification of up to 15
Department of Biomedical Engineering, All India Institute of Medical
Sciences,NewDelhi110029. gestureswith92%real-timeclassificationaccuracy[12].SMG
4202
raM
8
]CH.sc[
1v80350.3042:viXra2 IEEESENSORSJOURNAL,VOL.XX,NO.XX,XXXX2017
has also been used to achieve proportional control [13], [14] ity to decode proprioceptive information of various gestures
and perform functional tasks with prostheses [15]. Recently, by quantifying muscle deformation. Additionally, movement
it has also been demonstrated that it is possible to retain kinematicsandmotorcontrolperformanceweredepictedusing
high classification accuracy [16] as well as continuous force various performance metrics.
prediction accuracy [17] with only a small subset of the
scanlines(4to8)chosenfromtheB-modeimages.Therefore, II. METHODS
the current research focuses on developing wearable SMG
A. Wearablesonomyographysensordesign
systemsthatutilizesingle-elementultrasoundsensorstosense
An 8-channel wearable SMG sensor was fabricated from
muscle activity.
Lead Zirconate Titanate (PZT) (SMD063T07R111,Steiner &
Wearable SMG systems consist of a set of single-element
Martins Inc, USA) single-element transducers. An acoustic
ultrasound transducers made of piezoceramic discs [18], [19]
backing layer consisting of 66.7% tungsten powder in an
or PVDF films [20], [21] compared to the large arrays typi-
epoxy resin matrix was fabricated following optimization
cally found in commercial ultrasound probes. Single-element
procedures reported in [19], [23]. Additionally, an electrical
ultrasound transducers receive echoes reflected by tissues at
matching network consisting of a parallel L-C tank circuit
various depths as one-dimensionalamplitude mode (A-mode)
(L= 5µH and C= 511 pF) was connected. Each element was
signals with the amplitude and depth of the reflected echoes
characterized by conducting a pulse-echo test as detailed in
on vertical and horizontal axes, respectively. While B-mode
[19], [23]. The bandwidth of the transducers was approx-
imagesenablevisualizationofstructuraldetailsofthemuscles,
imately 470±88kHz. Additionally, there was a significant
A-modesignalsonlyprovidepeakswhenevertissueinterfaces
reduction in radial mode vibrations with an improvement of
are encountered along the path of the transmitted ultrasound
over 100dB. Fig. 1 shows the fabricated 8-channel SMG
waves. Therefore,computationalmethods relevantto A-mode
sensor and the time and frequency domain characteristics of
signals are necessary to detect dynamic muscle activity and
a single transducer. The 8-channel array comprises the single
quantify biomechanical parameters. Existing algorithms de-
sensor units packaged in a customized 3D printed enclosure
tect muscle activity directly from the A-mode signals or
designedto housethepiezoceramicelementandthe matching
by constructing sparse SMG images. Some algorithms, such
network.Connectionsfromeachsensorwereobtainedfrom50
as cross-correlation, Pearson’s correlation, and peak tracking
ohmRG-174cables(Make:82160101000,BeldenInc.,USA)
algorithms, are applicable for both B-mode images [13], [14]
with an approximate length of 50cm. The individual sensor
and A-mode signals [22]–[24]; these algorithms quantify the
units were attached to a fabric band as shown in Fig. 1(c) for
displacement of the peaks resulting from tissue boundaries to
easy fixation on the forearm.
quantifyjointanglesandmuscle forces.However,the popular
approach is to extract amplitude, and frequency domain fea-
tures,namely,mean[25],standarddeviation,rootmeansquare a) Matchinb g) network d 1) 0 1 F 2requen 3cy (Hz 4) 5 6x 2 21 006
value [26], linear fitting coefficients [27], [28], frequency 6mm Ho Bu as ci kn ig
ng
00 .. 89 12 80 00
spectrum[18],fromA-modesignalsandusemachinelearning Back layer 0.7 160
0.6 140
techniques to quantify muscle activity. 0.5 120
WearableSMGsystemswerealsousedtodemonstratereal- PZT disc 0.4 100
0.3 80
time control of prostheses and virtual tasks successfully. So c)8-channel sonomyography sensor 0.2 60
0.1 40
far, wearable SMG-based has been predominantlyfocused on 0 20
0 1 2 3 4 5 6 7 8 9
Time(us)
gestureclassification.Classificationofupto14fingermotions
with classification accuracies > 80% has been reported [27], Fig.1. a)Piezoceramictransducerelementwithanoptimizedbacking
[29],[30].However,acontinuousproportionalcontrolstrategy layer, b) Exploded rendering of the packaged transducer showing the
matchingnetworkand3Dprintedhousing,c)8-channelsensorarrayon
is critical to achieving natural control of prostheses. The pro-
awearablevelcroband,d)Timeandfrequencydomainresponsefrom
portionalcontrolstrategy maps the degreeof the user’s motor pulse-echotestsofthesensor.
intenttotheposition,force,orvelocityofthe prostheses[31].
This control strategy requires accurate detection of the ac-
tivation levels of the muscles. However, very few attempts B. Studyparticipants
were made to achieve proportional control using wearable
Eightable-bodiedindividualsparticipatedinthestudy(29±
SMG systems. Chen et al. first demonstrated proportional
4). Participants were informedof the protocolsand gave their
controlusingsingle-elementultrasoundtransducersbydirectly
informed consent to participate in the study. The Institute
mapping muscle deformation during wrist extension to the
Ethics Committee (IEC) at the Indian Institute of Technology
opening aperture of the prosthetic hand [32]. In recent years,
Delhiapprovedthestudyprotocols(IITDIECno:P021/P050).
Yangetal.haveimplementedproportionalpatternrecognition
todemonstratethefeasibilityofclassifyinggesturesalongwith
C. Experimentalsetup
the contraction levels [33]. However, achieving proportional
controlfrommuscle contractionlevelmay lead to fatigueand The participants were seated comfortably on a chair with
prolonged use discomfort. Therefore, a real-time proportional their dominant arm on a handrest. The custom-developed
position control of multiple gestures has been presented in wearableSMGsensorarraywasplacedontheforearmapprox-
this paper. This study evaluates the wearable SMG’s abil- imately 5cm from the elbow [19]. The wearable SMG sensor
edutilpma
dezilamroN
Magnitude
(dB)AUTHORetal.:PREPARATIONOFPAPERSFORIEEETRANSACTIONSANDJOURNALS(FEBRUARY2017) 3
Fig.2. a)Experimentalsetup:theparticipantswereinstrumentedwithacustom8-channelSMGsensorconnectedtoacommercialultrasound
pulser-receiversystem. Theparticipantsperformed a real-time target achievementtask. b)A-mode signalpreprocessing:Thepreprocessed A-
modesignalsfromall8channelswerearrangedrow-wisetoformasparseultrasoundframe.c)Generationofcursorcontrolsignal:thecontrol
signalwasgeneratedbyquantifyingthegesturepositionusingPearson’scorrelationcoefficient.
array was connected to a commercial 8-channel multiplexed The target achievement task was designed using MATLAB
ultrasound pulser-receiver system (Leceour 8-channel US- AppDesignerandwasdisplayedonthecomputerscreen.Each
MUX, Lecoeur Electronique,France). The US-MUX was op- experimentsessionconsistsofthreeparts,namely,1)training,
eratedinpulse-echomodetoallowtransmissionandreception 2) calibration, and 3) target achievement tasks.
of ultrasoundsignalsfroma single ultrasoundtransducer.The 1) Trainingphase: Duringtraining,atextcuewasdisplayed
high-voltage pulser was configured to excite the ultrasound on the computer screen instructing the participants to rest
transducerswith aunipolarpulseamplitudeof90V andpulse or perform a specific gesture for 30s. The A-mode signals
width of 49.25ns at a pulse repetition frequency (PRF) of corresponding to the rest and maximum positions of the
15kHz to allow an imaging depth of 10cm. The pulse width specific gesture were preprocessed and saved as rest refer-
was optimized by performing an acoustic reflection test to ence and motion reference ultrasound frames, respectively.
maximize the echo amplitude [19]. The received ultrasound Pearson’s2D correlationcoefficientswere calculated between
echo signals were amplified by a time gain compensation the incoming time averaged ultrasound frame and reference
(TGC) amplifier. The gain of the TGC varied linearly from frames corresponding to rest and maximum motion state (see
0dB to 50dB across the entire depth to compensate for Section II-C). The SMG signal was calculated as,
acoustic attenuation in tissue. The amplified signal was then
digitized at a sampling rate of 80MHz. The RF echo signal
(1−C )
r
was streamed to a PC (Intel Core i7-4790K, 32GB RAM, S = (1)
(1−C )+(1−C )
r m
2GB NVIDIA GeForce GTX 760) by a USB connection and
processed in a custom-developed MATLAB (Version 2022b,
C is the computed correlation coefficient of the incoming
r
Mathworks Inc., Natick MA, USA) software. The MATLAB-
frame with the rest reference frame, and C is the computed
m
basedA-modesignalacquisitionresultedinaframerateof22
correlation coefficient of the incoming frame with the motion
framespersecond(fps)fromall8channels.Thepreprocessing
reference frame.
steps are elaborated in the following section.
2) Calibration phase: During calibration, the participants
were instructed to performthe selected gesture and rest thrice
D. A-modesignalpre-processing
for10seach.TheSMGsignal(S)wascomputedbasedonthe
ThereceivedRFA-modesignalhasasignallengthof4000
referenceframesobtainedduringthetrainingphase.Thelower
points. Firstly, the envelope of the RF echo was extracted
and upper bounds of the SMG signal were captured during
by computing the analytic signal using the Hilbert transform
the 10s periods and were subsequently used to normalize the
over a window size of 1000 samples. The envelopewas then
SMG signal (S) to a range of [0 1]. Therefore, when the
smoothed with a moving average filter having a window size
participants were fully relaxed, the normalized SMG signal
of 25 samples, as shown in Fig. 2. The smoothed envelopes
wouldbe’0’,andwhenthe participantcompletedthegesture,
of all eight channels were then concatenated to form a sparse
the signal would be ’1’. The normalized SMG signal value
ultrasoundframeof8×4000.Thesparseultrasoundframewas
would proportionallyscale between’0’ and ’1’ when the user
further temporally smoothed by averaging three consecutive
performed the gesture partially.
frames. This time-averagedsparse ultrasound frame was used
to generate the SMG signal, as explained in the following
section.4 IEEESENSORSJOURNAL,VOL.XX,NO.XX,XXXX2017
E. Experiment1:Optimizingsensorplacementacross
gestures
An unconstrained proportional control task was performed
todeterminetheoptimalpositionontheforearmforplacement
of the sensor array and to derive the relationship between
the SMG signal and joint angles for each gesture. Five out
of eight participants were recruited for this pilot experi-
ment. The participants wore the wearable SMG sensor as
described in Section II-C. A data glove (5DT Data Glove
Ultra, Fifth Dimension Technologies, USA) measured the
metacarpophalangeal joint (MCP) angle for each finger. On-
screen visual cues were displayed during the task, instructing
the participants to perform the motion or rest. The full-
Fig.3. Exampleofusertrajectoryandpresentedtarget.Theoutcome
range gesture was performed for a duration of 15s during metrics,namely,movementtime(Tm),endpointerror,endpointstability,
motion phases. The duration when from rest state to reach pathefficiency,andmaximumvelocity,werecalculatedfromusertrajec-
the maximum range of motion for each gesture is termed tory.
as upslope. whereas returning from maximum position to
rest is termed as downslope. Each gesture was repeated five
in Fig. 3. The success rate is calculated as,
times,interleavedwith10sofrestingphases.Theparticipants
performedthreegestures:powergrasp(PG),tripodgrasp(TG), Number of successful targets
and index point (IP). This was repeated by shifting the SMG Successrate= ×100%
Number of targets presented
sensor 5cm distal to the initial location. The SMG signal (2)
and the data glove signals were saved for offline analysis. 2) Movementtime: Movementtime(T m)isthetimeelapsed
The SMG signals obtained during the motion phases were between the presentation of the target and time instant when
computedoffline,and a linearfit was consideredto assess the the user successfully remained within the target width (dwell
relationship between SMG signals and gesture-specific joint window) for a contiguous period defined by the dwell time
angles. (T ) as shownin Fig. 3. Fitt’s law predictsthatthe movement
d
time increases linearly with task difficulty for goal-directed
human-machine interactions [34]. The difficulty of the task
F. Experiment2:Targetachievementtask
(ID)ismodulatedbythedistanceofthetargetfromthestarting
The task consists of an on-screen virtual cursor controlled position (D), as well as the width of the target (W), and is
bythenormalizedSMG signal.A virtualtargetwaspresented defined as,
at levels 0.2, 0.4, 0.6, 0.8, and 1 in randomized order inter- D
leaved with 15s of rest. The user was instructed via visual ID =log 2 1+ (3)
W
" #
cues to attain the target by performing the specific gesture
proportionally. On presentation of the target, the user was A linear fit was obtained between the index of difficulty and
instructed to reach the target and stay within its bounds for movement time. The Fitt’s throughput was estimated as the
a continuous period of at least 1.5s for the target to be suc- inverseoftheslopeofthebest-fitline,andthey-axisintercept
cessfullyacquired.Theuserwasprovidedamaximumtimeout wasobtainedasanestimateofthereactiontimeforeachgrasp
period of 15s to attempt to acquire the target. The thickness type.
of the target, or target width (W), was varied to modulate 3) Endpointerror: Endpoint error (E error) provides a mea-
the difficulty of the task. The experimentwas performedwith sure of the average deviation of the user cursor and the
three target widths of 5%, 10%, and 15%. Four different intendedtargetoncethetargethasbeensuccessfullyacquired,
gestures, namely, power grasp (PG), index point (IP), tripod as shown in Fig. 3. It is definedas the differencebetween the
grasp (TG), and wrist rotation (WR), were performed. Each targetpositionandthemeanvalueoftheparticipanttrajectory
testconditionwasrepeatedforthreetrials.Theuser-generated within the dwell time window. It is calculated as,
cursor trajectory for each trial was stored for further analysis.
Tm+Td
P (t)−P (t)
target user
E = (4)
error
N
G. Performancemetrics t= XTm
The task performance of the participants in experiment 2 Here, N is the number of samples of P (t), T < t <
user m
was evaluated using the metrics extracted from the cursor T +T , P (t) is the position of the target presented to
m d target
trajectory as shown in Fig 3. the user at time, t and P (t) is the position of the user’s
user
1) Successrate: The success rate indicates the proportion cursor at time, t.
of the total trials executed successfully by the user. A trial is 4) Endpointstability: Endpointstability(E stability)provides
a success if the participantreachesthe targetand stays within a measure of the jitter of the user’s cursor once the targethas
the target width for at least 1.5s of dwell time (T ) as shown been successfully acquired, as shown in Fig. 3. It is defined
dAUTHORetal.:PREPARATIONOFPAPERSFORIEEETRANSACTIONSANDJOURNALS(FEBRUARY2017) 5
as the standard deviation of the participant trajectory within
Proximal Distal
1 1
the dwell time window. It is calculated as, Power grasp Power grasp
Tm+Td (P (t)−µ )2 0.8 0.8
E = user user (5) 0.6
stability N 0.6
t X=Tm 0.4
0.4
Here, N is the number of samples of P (t), T < t < 0.2
user m
T m+T d and, µ user is defined as in Eq. 6, 0 y = 0.68x + 0.227 0.2 y = 0.71x + 0.173
2 2
R = 89.84 R = 90.69
Tm+Td
P user(t)
-0.2
0 0.2 0.4 0.6 0.8 1
0
0 0.2 0.4 0.6 0.8 1
µ = (6)
user
N
t= XTm
1 Index point 1 Index point
5) Path efficiency: Path efficiency (η) is a measure of the
total path length of the user’s trajectory compared to an 0.8 0.8
idealizedtrajectorydefinedbyinstantaneoustargetacquisition 0.6 0.6
at t=0 as in eq. 7: 0.4
0.4
P −P (0) 0.2
target user
η = T t=m 0|P user(t+1)−P user(t)| ×100% (7) 0 y
R
2=
=
0 8.9 81 .5x
1
- 0.062 0.2 y
R
2=
=
0 8. 89 .0 0x
9
+ 0.176
-0.2 0
6) MaximuPmvelocity: The velocity profile of precision dex- 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
terousgraspsisknowntoscalewithobjectsize,aswellasthe
distance to the object in healthy adults [35], [36], and could 1 Tripod grasp 1 Tripod grasp
providevaluableinsights into the motor behaviorexperienced
0.8 0.8
while controlling the SMG-based muscle computer interface.
0.6
Hence,the maximumvelocityofthe user-generatedtrajectory 0.6
0.4
for each target position was calculated as,
0.4
0.2
v =max dP user(t) ,0≤t≤T (8) 0 y = 0.10x - 0.031 0.2 y = 0.69x + 0.092
max (cid:12) dt (cid:12) m R2 = 85.05 R2 = 83.84
(cid:12) (cid:12) -0.2 0 0.2 0.4 0.6 0.8 1 0 0 0.2 0.4 0.6 0.8 1
(cid:12) (cid:12)
(cid:12) (cid:12) Normalized joint angle
H. Statisticaltests (cid:12) (cid:12)
Upslope Downslope Linear fit
A two-way repeated measures ANOVA was used to deter-
Fig.4. RelationshipbetweenMCPjointangleandSMGsignalforthree
mine whether the interaction and main effects of target po-
gestureswiththesensorarrayplacedatproximalanddistallocationson
sition and width are statistically significant. The Greenhouse- theforearm.PlotsshowthebestR2 valuesobtainedforeachgesture
ateachsensorposition.
GeissercorrectionwasappliedforconditionswhereMauchly’s
sphericity test was violated. IBM SPSS Statistics (Version
28.0, IBM Corp, Armonk, NY, USA) was used for all sta-
= -2.194, p = 0.093). Therefore, subsequent experiments
tistical analyses.
were performed with the sensor array placed at the proximal
location to improve the congruence of the SMG signal with
III. RESULTS
the MCP joint angles.
A. Experiment1:Optimizingsensorplacementacross
gestures
TABLEI
Fig.4showstherelationshipbetweennormalizedjointangle MEANANDSTANDARDDEVIATIONOFR2 VALUESOBTAINEDFOREACH
and the SMG signal for three gestures, PG, IP, and TG, GESTUREATPROXIMALANDDISTALPOSITIONS
for proximal and distal placement of wearable SMG sensor. Proximal Distal
The best case R2 values obtained for each condition were Powergrasp Indexpoint Tripodgrasp Powergrasp Indexpoint Tripodgrasp
consideredforFig. 4. The mean and standarddeviationin R2 Mean 85.89 71.24 78.22 78.67 81.22 70.55
(Standarddeviation) (±2.959) (±17.212) (±6.870) (±9.819) (±9.272) (±9.803)
values for all participants are listed in Table. I. A two-sample
t-test was performed to determine whether the difference in
linearity obtained at the two sensor locations was statistically
B. Experiment2:Targetachievementtask
significant. Results demonstrated that proximal placement of
the sensors on the forearm resulted in significantly higher Fig.5showstheSMGsignaltrajectoriesofarepresentative
linearity for TG (t(4) = 4.241, p = 0.013). For PG, proximal participant for a target presented at 0.6. The participants
placementledto higherlinearitythandistalsensorplacement. performed three trials for each target position. The figure
However, this difference in linearity was not found to be shows the trajectories attained during each trial for all four
statistically significant for PG (t(4) = 1.934, p = 0.125). grasps.
Similarly, for IP, the difference in linearity between the two 1) Success rate: Fig. 6 shows the success rates achieved
positions was not found to be statistically significant (t(4) at all target positions for three different target widths for
langis
GMS
dezilamroN6 IEEESENSORSJOURNAL,VOL.XX,NO.XX,XXXX2017
2) Movementtime: Fig. 7 shows the movementtimes of all
Power grasp Index point the participants for every target position at each target width.
An averagemovementtime of 5.6±2.9 s was attained for all
four grasps and is not significantly different (p = 0.321) for
differentgestures.Themovementtime fortargetsat0.2and1
werelowerthanthoseat0.2,0.4,and0.6.Thiseffectoftarget
positiononmovementtimewassignificantinPG (F(4,44)=
Time (s) Time (s) 4.82,p = 0.003), IP (F(4,60) = 6.45,p < 0.001), and wrist
rotation (F(4,36) = 4.05,p = 0.008) but not statistically
Tripod grip Wrist rotation significant for tripod (F(4,24)=1.86,p=0.15) as indicated
in Table II. However, there was a significant effect of target
widthonthemovementtimeacrossallthegestures(p<0.05)
as shown in Table II
14 Power grasp 14 Index point
Time (s) Time (s) 12 12
Normalized position Target width Trial 1 Trial 2 Trial 3 10 10
Fig.5. Themovementtrajectoriesofarepresentativeparticipantfora 8 8
targetpresentedat0.6achievedusingallgestures 6 6
4 4
2 2
0 0
all the gestures. The participants achieved average success 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
Target position Target position
rates of 76.6(±16.96)%, 73.6(±18.69)%, 68.7(±24.87)%,
69.8(±21.47)% for PG, IP, TG, and wrist rotation respec- 14 Tripod grasp 14 Wrist rotation
12 12
tively. It was observed that participants successfully acquired
10 10
a larger proportion of targets closer to rest (0.2) compared 8 8
to other targets located farther away. However, this effect of 6 6
target position on success rate was only significant for PG 4 4
2 2
(F(4,28)=4.20,p=0.009) and TG (F(4,28)=4.680,p=
0 0
0.005). There was a significant (p < 0.001) improvement in 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
Target position Target position
the success rates when the target width was increased for all
Target width: 5% Target width: 10% Target width: 15%
thegestures.Withatargetwidthof15%,successratesashigh
Fig. 7. Movement times achieved for different gestures for all target
as 100% were achieved. There was no significant difference positions and target widths. A significant reduction in movement time
in the success rate between the gestures for a given target canbeseenwheneasiertargets(15%targetwidth)werepresented.
width, indicating that target width modulates task difficulty
across all gestures (p = 0.101 for 5%, p = 0.898 for 10%, 3) Endpoint error and Endpoint stability: Fig. 8 shows the
and p=0.682 for 15%). endpointerroratalltargetpositionsandwidthsinallgestures.
Forallthegestures,theaveragepositionerrorwas−0.8±2%;
the negative sign indicates that the user cursor is below the
Power grasp Index point
120 120 target. The target position significantly affects the endpoint
100 100 error across all positions (p<0.001). Interestingly, the target
80 80 width had no significant effect on the endpoint error for all
60 60 gestures except TG (F(2,12)=13.96,p<0.001).
40 40
Fig. 9 shows the endpoint stability error achieved for all
20 20
the gestures at all target positions and widths. The average
0 0
0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1 standarddeviationin the user trajectory within the dwelltime
Target Position Target Position
windowwas1.7±1%forallthegestures.Thereisasignificant
120 Tripod grasp 120 Wrist rotation (p < 0.05) effect of target position and width on endpoint
100 100 stability for all gestures.
80 80 4) Path efficiency: Fig. 10 shows the path efficiency of
60 60 the trajectories at all target positions and widths for all the
40 40 gestures. The path efficiency increased significantly (p <
20 20 0.001) with an increase in the target position. Target width
0 0
0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1 hadnosignificanteffectonpathefficiencyforPG(F(2,22)=
Target Position Target Position
1.26,p=0.303), TG (F(2,12)=2.60,p<0.115), and wrist
Target width: 5% Target width: 10% Target width: 15%
rotation (F(1.241,11.168) = 3.02,p < 0.104). However,
Fig.6. Successratesachievedwithdifferentgesturesateachposition
forthreetargetwidths.Theparticipantsachievedhighersuccessrates target width significantly affected path efficiency for the IP
targetwidthof15%. (F(2,30)=5.203,p=0.011).
noitisop
dezilamroN
noitisop
dezilamroN
)%(
etar
sseccuS
)%(
etar
sseccuS
noitisop
dezilamroN
noitisop
dezilamroN
)%(
etar
sseccuS
)%(
etar
sseccuS
)s(
emit
tnemevoM
)s(
emit
tnemevoM
)s(
emit
tnemevoM
)s(
emit
tnemevoMAUTHORetal.:PREPARATIONOFPAPERSFORIEEETRANSACTIONSANDJOURNALS(FEBRUARY2017) 7
TABLEII
P-VALUESOBTAINEDTODETERMINETHESTATISTICALLYSIGNIFICANTEFFECTSOFTARGETPOSITIONANDTARGETWIDTHONVARIOUS
PERFORMANCEMETRICSFORALLGESTURES
Powergrasp Indexpoint Tripodgrasp Wristrotation
TargetPosition Targetwidth TargetPosition Targetwidth TargetPosition Targetwidth TargetPosition Targetwidth
0.009∗ 0.002∗ 0.525 <0.001∗ 0.005∗ <0.001∗ 0.075 <0.001∗,†
Successrate
F(4,28)=4.20 F(2,14)=9.99 F(4,28)=0.82 F(2,14)=21.36 F(4,28)=4.68 F(2,14)=20.50 F(4,28)=2.38 F(1.183,8.284)=24.84
0.003∗ 0.002∗ <0.001∗ 0.007∗ 0.150 0.004∗ 0.008∗ 0.016∗,†
Movementtime
F(4,44)=4.82 F(2,22)=8.43 F(4,60)=6.45 F(2,30)=5.97 F(4,24)=1.86 F(2,12)=9.26 F(4,36)=4.05 F(1.127,10.146)=7.88
<0.001∗ 0.310† <0.001∗ 0.110 0.022∗ <0.001∗ 0.012∗ 0.099†
Endpointerror
F(4,44)=7.90 F(1.337,14.703)=1.19 F(4,60)=14.12 F(2,30)=2.37 F(4,24)=3.51 F(2,12)=13.96 F(4,36)=3.77 F(1.162,10.462)=3.20
<0.001∗ <0.001∗ <0.001∗ <0.001∗ 0.031∗,† <0.001∗ <0.001∗ <0.001∗
Endpointstability
F(4,44)=6.41 F(2,22)=34.95 F(4,60)=10.33 F(2,30)=13.24 F(1.836,11.015)=4.99 F(2,12)=66.32 F(4,36)=7.95 F(2,18)=47.13
<0.001∗ 0.303 <0.001∗ 0.011∗ <0.001∗ 0.115 <0.001∗ 0.104†
Pathefficiency
F(4,44)=14.26 F(2,22)=1.26 F(4,60)=20.26 F(2,30)=5.20 F(4,24)=11.68 F(2,12)=2.60 F(4,36)=14.16 F(1.241,11.168)=3.02
<0.001∗ 0.290 <0.001∗ <0.001∗ <0.001∗ 0.290 <0.001∗ 0.320
Maximumvelocity
F(4,44)=54.28 F(2,22)=1.31 F(4,60)=110.70 F(2,30)=9.07 F(4,24)=11.03 F(2,12)=1.37 F(4,36)=87.27 F(2,18)=1.21
*indicatesstatisticallysignificantp-values,†appliedGreenhouse-Geissercorrection
5) Maximumvelocity: Fig. 11 shows the maximum veloci- approachquantifiesthemuscledeformationfromsparseSMG
ties attained by the users while achieving targets at different signalsandmapsittothepositionoftheon-screenusercursor
positions.The maximumvelocitywas foundto scale approxi- proportionally, as shown in Fig. 5. Experiment 1 confirmed
matelylinearlywiththetargetpositionwithaverageR2values thatthereexistsalinearrelationshipbetweentheSMGcontrol
53±2.1,62±10.1,40±14.4,63±1.6forPG,IP,TG,andWR, signal and the MCP joint angle across all the gestures, as
respectively(averagedR2 of all targetwidths).Targetposition shownin Fig. 4. Thus, ourresults are in agreementwith prior
significantly (p<0.001) affected the maximum velocities. In B-mode imaging-based SMG studies that reported accurate
contrast,targetwidthhadnosignificanteffectforallgestures. estimation of joint angles and finger positions by tracking
Table IIbelow summarizesthep-valuesforall theconditions. changesinmuscleanatomicalstructuresdespitehavingsparse
measurement sites [12]. Therefore, SMG could provide nat-
IV. DISCUSSION uralistic control as it measures muscle deformation during
This paper reports a real-time proportionalposition control dynamic activity.
of multiple gestures using a wearable SMG sensor. The Functionalactivitiesrequireaccurateandstablecontrolover
proposed wearable SMG system could accurately track var- extended periods of time over multiple degrees of freedom
ious levels of muscle deformation to generate a proportional (DoFs). So far, wearable SMG systems have been used to
position control signal. The movement trajectories decoded demonstrateofflineproportionalcontrolusingmusclecontrac-
from the SMG signals exhibited a high degree of congruence tion levels for up to 8 grasps [33]. Yang et al. also achieved
with the MCP joint angles and, therefore, had a one-to- real-time simultaneous proportional position control of the
one correspondence to the user’s volitional motor intent. Our
4 Power grasp 4 Index point
4 Power grasp 4 Index point 3.5 3.5
3 3
2 2
2.5 2.5
0 0 2 2
1.5 1.5
-2 -2 1 1
0.5 0.5
-4 -4
0 0
0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
-6 0.2 0.4 0.6 0.8 1 -6 0.2 0.4 0.6 0.8 1 Target position Target position
Target position Target position 4 Tripod grasp 4 Wrist rotation
4 Tripod grasp 4 Wrist rotation 3.5 3.5
3 3
2 2
2.5 2.5
0 0 2 2
1.5 1.5
-2 -2 1 1
0.5 0.5
-4 -4
0 0
0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
-6 0.2 0.4 0.6 0.8 1 -6 0.2 0.4 0.6 0.8 1 Target position Target position
Target position Target position
Target width: 5% Target width: 10% Target width: 15%
Target width: 5% Target width: 10% Target width: 15% Fig.9. Endpoint stability for each gesture at all target positions and
Fig.8. Endpointerrorsforeachgestureatalltargetpositionsandtarget targetwidths.Thestandarddeviationofthejitterwaswithin5%ofthe
widths.Endpointerrorswerewithin5%oftherange. range.
)%(
rorre
tniopdnE
)%(
rorre
tniopdnE
)%(
rorre
tniopdnE
)%(
rorre
tniopdnE
)%(
ytilibats
tniopdnE
)%(
ytilibats
tniopdnE
)%(
ytilibats
tniopdnE
)%(
ytilibats
tniopdnE8 IEEESENSORSJOURNAL,VOL.XX,NO.XX,XXXX2017
hand and wrist with success rates > 97%. However, the
1 Power grasp 1 Index point
stability of the SMG control was evaluated only for a dwell
0.8 0.8 time of 300ms. On the other hand, our study systematically
evaluatestheeffectivenessofSMGcontrolforfourdegreesof 0.6 0.6
freedom.Wehavenotevaluatedoursystem’sabilitytocontrol 0.4 0.4
the DoFs simultaneously. Fig. 5shows the trajectories for the
0.2 0.2
entire trial duration of 15 sec. The trajectories show that the
0 0
participants remained within the target for at least 2s upon 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
Target position Target position
achievement of the target, resulting in success rates > 80%
1 Tripod grasp 1 Wrist rotation
for higher error tolerance, as seen in Fig. 6. Additionally,
0.8 0.8
the responsiveness of SMG control can be seen in Fig. 7
with an average movement time of 5.6 ± 2s. Furthermore, 0.6 0.6
theparticipants’performancewasevaluatedbymodulatingthe 0.4 0.4
task’sdifficultybychangingthetargetwidth.Thedifficultyof
0.2 0.2
thetasksignificantlyaffectedbothsuccessrateandmovement
0 0
time.Thetargetswith5%widthconstrainedtheparticipantsto 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
Target position Target position
achievefinecontroloverthecursor,whilethetargetswith15%
Target width: 5% Target width: 10% Target width: 15%
width allowed the participants to have higher errors between Fig. 11. Maximum velocity derived from the user trajectories for all
thetargetandtheusercursor.Theparticipantsachievedeasier target positions and widths for all gestures. Maximum velocity scaled
targets, i.e., tasks with a target width of 15%, in significantly linearlywithtargetdistance.
lowertimethandifficulttargets(targetwidthof5%).However,
finer control for lower target widths could be achieved by
A. Limitations andfuturescope
adapting to the system with sufficient training.
There are a few limitations of the presented wearable sys-
For proportional positional control, minimal error between
tem.Firstly,thesystemisnotfullywearableinitscurrentstate.
the target and end-effector is desirable to achieve intuitive
In the future, a custom-developed wearable pulser-receiver
control.TheaccuracyoftheSMGcontrolwasevaluatedusing
system will be used to make the system fully wearable. In
endpoint error and stability. Fig. 8 and Fig. 9 show that the
terms of control technique, the proportional control of each
maximumerrorbetweenthetargetandtheusercursorandthe
gesturewastestedinisolation.Controlstrategieswithrelevant
maximum variance in the user cursor is less than 5%. There-
switching techniques will be developed to achieve sequential
fore, SMG control seems to minimize error and variability as
or simultaneous control over multiple gestures.
the participant reaches close to the target. This also suggests
that the participants adapted to SMG-based control by trying
V. CONCLUSION
to achieve the targets with minimum error and variance while
Awearable8-channelSMGsensorarraywasdevelopedand
learning the non-linearities and inherent noise of the SMG
optimized.Asimpletechniquewasdevelopedtoderiveareal-
control algorithm, thus retaining their natural motor control
time proportional positional sonomyography signal from the
abilities [37].
sensor array. The performance of the optimized sensor array
andthederivedSMGsignalwastestedattwolocationsonthe
forearm,andtheproximallocationwaschosenduetothehigh
degreeoflinearitywithjointanglesacrossthegestures.Target
Power grasp Index point 100 100 achievementtasksperformancestudiesperformedwithhealthy
80 80 individuals demonstrate that the system is able to provide
60 60 accurate and stable sonomyographic control over multiple
40 40 degrees-of-freedom.
20 20
0 0 REFERENCES
-20 -20
0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1
[1] J.M.Hahne,M.A.Schweisfurth,M.Koppe,andD.Farina,“Simultane-
Target position Target position
ouscontrolofmultiplefunctionsofbionichandprostheses:Performance
100 Tripod grasp 100 Wrist rotation androbustnessinendusers,”Science Robotics,vol.3,no.19,2018.
[2] N. Jiang, J. L. Vest-Nielsen, S. Muceli, and D. Farina, “EMG-based
80 80
simultaneous and proportional estimation of wrist/hand kinematics in
60 60 uni-lateral trans-radial amputees,” Journal of NeuroEngineering and
40 40 Rehabilitation, vol.9,no.1,2012.
20 20 [3] L. Resnik, H. H. Huang, A. Winslow, D. L. Crouch, F. Zhang, and
N. Wolk, “Evaluation of EMG pattern recognition for upper limb
0 0
prosthesiscontrol:AcasestudyinComparisonwithdirectmyoelectric
-20 -20
0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1 control,”JournalofNeuroEngineeringandRehabilitation,vol.15,no.1,
Target position Target position pp.1–13,2018.
[4] N.Jiang,K.B.Englehart,andP.A.Parker,“Extractingsimultaneousand
Target width: 5% Target width: 10% Target width: 15%
proportionalneuralcontrolinformationformultiple-dofprosthesesfrom
Fig.10. Pathefficiencyoftheusertrajectoriesforalltargetpositions thesurfaceelectromyographicsignal,”IEEETransactionsonBiomedical
andwidthsforallgestures. Engineering, vol.56,no.4,pp.1070–1080, 2009.
)%(
ycneiciffe
htaP
)%(
ycneiciffe
htaP
)%(
ycneiciffe
htaP
)%(
ycneiciffe
htaP
)s/%(
yticoleV
mumixaM
)s/%(
yticoleV
mumixaM
)s/%(
yticoleV
mumixaM
)s/%(
yticoleV
mumixaMAUTHORetal.:PREPARATIONOFPAPERSFORIEEETRANSACTIONSANDJOURNALS(FEBRUARY2017) 9
[5] E.Scheme andK. Englehart, “Electromyogram pattern recognition for International IEEE/EMBS Conference on Neural Engineering (NER),
controlofpoweredupper-limbprostheses:stateoftheartandchallenges 2017,pp.118–121.
forclinical use.”JournalofRehabilitation ResearchandDevelopment, [25] S. Cai, Z. Lu, L. Guo, Z. Qing, and L. Yao, “The let procedure
vol.48,no.6,pp.643–659, 2011. for gesture recognition with multiple forearm angles,” IEEE Sensors
[6] R. Vinjamuri, Z.-H. Mao, R. Sclabassi, and M. Sun, “Limitations of Journal, vol.22,no.13,pp.13226–13233,2022.
surfaceemgsignalsofextrinsicmusclesinpredictingposturesofhuman [26] J. He, H. Luo, J. Jia, J. T. W. Yeow, and N. Jiang, “Wrist and finger
hand,” in 2006 International Conference of the IEEE Engineering in gesture recognition with single-element ultrasound signals: A compar-
Medicine andBiology Society, 2006,pp.5491–5494. ison with single-channel surface electromyogram,” IEEE Transactions
[7] Q.Zhang,A.Iyer,K.Kim,andN.Sharma,“Evaluationofnon-invasive onBiomedicalEngineering, vol.66,no.5,pp.1277–1284, 2019.
ankle joint effort prediction methods for use in neurorehabilitation [27] W. Xia, Y. Zhou, X. Yang, K. He, and H. Liu, “Toward portable
using electromyography and ultrasound imaging,” IEEE Transactions hybrid surface electromyography/a-mode ultrasound sensing for hu-
onBiomedical Engineering, vol.68,no.3,pp.1044–1055, 2021. man–machine interface,” IEEE Sensors Journal, vol. 19, no. 13, pp.
[8] L.A.Hallock,A.Velu,A.Schwartz,andR.Bajcsy,“Muscledeforma- 5219–5228, 2019.
tioncorrelates withoutputforceduringisometriccontraction,” in2020 [28] X. Yang, X. Sun, D. Zhou, Y. Li, and H. Liu, “Towards wearable a-
8thIEEERAS/EMBSInternationalConferenceforBiomedicalRobotics modeultrasoundsensingforreal-timefingermotionrecognition,”IEEE
andBiomechatronics (BioRob),2020,pp.1188–1195. TransactionsonNeuralSystemsandRehabilitationEngineering,vol.26,
[9] J. Shi, Y. Zheng, and Z. Yan, “The relationship between SEMG and no.6,pp.1199–1208,2018.
change inpennation angle ofbrachialis,” AnnualInternational Confer- [29] L.Guo,Z.Lu,L.Yao,andS.Cai,“Agesturerecognitionstrategybased
ence oftheIEEEEngineering inMedicine andBiology -Proceedings, on a-mode ultrasound for identifying known and unknown gestures,”
pp.4802–4805, 2007. IEEESensorsJournal, vol.22,no.11,pp.10730–10739,2022.
[10] P. W. Hodges, L. H. M. Pengel, R. D. Herbert, and S. C. Gandevia, [30] Z.Yin, H.Chen, X.Yang, Y.Liu,N.Zhang, J.Meng, andH.Liu,“A
“Measurement ofmusclecontraction withultrasoundimaging.”Muscle wearableultrasoundinterfaceforprosthetichandcontrol,”IEEEJournal
&Nerve, 2003. ofBiomedical andHealthInformatics, vol.26,no.11,pp.5384–5393,
[11] J. McIntosh, A. Marzo, M. Fraser, and C. Phillips, “Echoflex: Hand 2022.
gesture recognition using ultrasound imaging,” in Proceedings of the [31] A. Fougner, y. Stavdahl, P. J. Kyberd, Y. G. Losier, and P. A. Parker,
2017 CHI Conference on Human Factors in Computing Systems, ser. “Controlofupperlimbprostheses:Terminologyandproportional myo-
CHI’17. NewYork,NY,USA:AssociationforComputingMachinery, electric control—a review,” IEEETransactions on Neural Systems and
2017,p.1923–1934. Rehabilitation Engineering, vol.20,no.5,pp.663–677,2012.
[12] N. Akhlaghi, C. A. Baker, M. Lahlou, H. Zafar, K. G. Murthy, H. S. [32] X. Chen, Y.-P. Zheng, J.-Y. Guo, and J. Shi, “Sonomyography (smg)
Rangwala, J. Kosecka, W. M. Joiner, J. J. Pancrazio, and S. Sikdar, control for powered prosthetic hand: a study with normal subjects.”
“Real-time classification of hand motions using ultrasound imaging UltrasoundinMedicine andBiology, 2010.
of forearm muscles,” IEEE Transactions on Biomedical Engineering, [33] X.Yang,J.Yan,Z.Chen,H.Ding,andH.Liu,“Aproportionalpattern
vol.63,no.8,pp.1687–1698, 2016. recognition control scheme for wearable a-mode ultrasound sensing,”
[13] J.Shi,Q.Chang,andY.-P.Zheng,“Feasibilityofcontrollingprosthetic IEEE Transactions on Industrial Electronics, vol. 67, no. 1, pp. 800–
hand using sonomyography signal in real-time: Preliminary study,” 808,2020.
JournalofRehabilitation ResearchandDevelopment, 2010. [34] P. M. Fitts, “The information capacity of the human motor system in
[14] A. S. Dhawan, B. Mukherjee, S. Patwardhan, N. Akhlaghi, G. Diao, controllingtheamplitudeofmovement.1954.”Journalofexperimental
G. Levay, R. Holley, W. M. Joiner, M. Harris-Love, and S. Sikdar, psychology. General, vol.121,no.3,pp.262–269, sep1992.
“Proprioceptive SonomyographicControl:Anovelmethodforintuitive [35] B.HoffandM.A.Arbib,“Modelsoftrajectoryformationandtemporal
andproportionalcontrolofmultipledegrees-of-freedom forindividuals interaction of reach and grasp,” Journal of Motor Behavior, vol. 25,
withupperextremitylimbloss,”ScientificReports,vol.9,no.1,p.9499, no.3,pp.175–192,1993.
2019. [36] M. Mon-Williams and J. R. Tresilian, “A simple rule of thumb for
[15] S. M. Engdahl, S. A. Acun˜a, E. L. King, A. Bashatah, and S. Sikdar, elegant prehension,” Current Biology, vol. 11, no. 13, pp. 1058–1061,
“First Demonstration of Functional Task Performance Using a Sono- 2001.
myographicProsthesis:ACaseStudy,”FrontiersinBioengineeringand [37] E. Todorov, “Optimality principles in sensorimotor control,” Nature
Biotechnology, vol.10,no.May,pp.1–20,2022. Neuroscience, vol.7,no.9,pp.907–915, 2004.
[16] N. Akhlaghi, A. Dhawan, A. A. Khan, B. Mukherjee, G. Diao,
C.Truong,andS.Sikdar,“Sparsityanalysisofasonomyographicmus-
cle–computerinterface,”IEEETransactionsonBiomedicalEngineering,
vol.67,no.3,pp.688–696, 2020.
[17] A.T.Kamatham,M.Alzamani,A.Dockum,S.Sikdar,andB.Mukher-
jee, “Sparse sonomyography-based estimation of isometric force: A
comparison of methods and features,” IEEE Transactions on Medical
Robotics andBionics,vol.4,no.3,pp.821–829,2022.
[18] X.Yang,Y.Zhou,andH.Liu,“Wearableultrasound-baseddecodingof
simultaneous wrist/hand kinematics,” IEEE Transactions on Industrial
Electronics, vol.68,no.9,pp.8667–8675, 2021.
[19] A.T.KamathamandB.Mukherjee,“Designandoptimizationofawear-
ablesonomyographysensorfordynamicmuscleactivitymonitoring,”in
2023IEEEAppliedSensingConference (APSCON),2023,pp.1–3.
[20] I. AlMohimeed and Y. Ono, “Ultrasound measurement of skeletal
musclecontractileparametersusingflexibleandwearablesingle-element
ultrasonic sensor.”Sensors,2020.
[21] J.Yan,X.Yang,X.Sun,Z.Chen,andH.Liu,“Alightweightultrasound
probeforwearable human–machine interfaces,” IEEESensors Journal,
vol.19,no.14,pp.5895–5903,2019.
[22] J.-Y.Guo,Y.-P.Zheng,Q.-H.Huang,X.Chen,andJ.-F.He,“Compari-
sonofsonomyographyandelectromyographyofforearmmusclesinthe
guided wristextension,” in20085thInternational Summer School and
Symposium onMedicalDevices andBiosensors,2008,pp.235–238.
[23] A. T. Kamatham, A. Shariati, H. A. Wurdemann, and B. Mukherjee,
“A multiplexed sonomyography system forproprioceptive proportional
controlofbiomechatronicinterfaces,”in2023IEEEInternationalInstru-
mentationandMeasurementTechnologyConference(I2MTC),2023,pp.
1–6.
[24] X. Yang, Y. Li, Y. Fang, and H. Liu, “A preliminary study on the
relationship between grip force and muscle thickness,” in 2017 8thThis figure "jsenga.png" is available in "png"(cid:10) format from:
http://arxiv.org/ps/2403.05308v1