Variational Inference of Parameters in Opinion Dynamics Models
JacopoLenti1,2, FabrizioSilvestri1 and GianmarcoDeFrancisciMorales2
1SapienzaUniversity
2CENTAI
jcp.lenti@gmail.com,fsilvestri@diag.uniroma1.it,gdfm@acm.org
Abstract Original ABM Data
P˜(ε∣ )
Despite the frequent use of agent-based models
(ABMs) for studying social phenomena, parame- t t+1
terestimationremainsachallenge,oftenrelyingon P( ∣ ) P˜(r 1,…,r N∣ )
costlysimulation-basedheuristics. Thisworkuses
t+1 t Approximate posterior
variationalinferencetoestimatetheparametersof Probabilistic Generative ABM Variational Inference macro- and micro-parameters
anopiniondynamicsABM,bytransformingthees- Figure 1: The proposed parameter estimation pipeline.
timationproblemintoanoptimizationtaskthatcan First, we translate the agent-based model into a proba-
besolveddirectly. bilistic generative agent-based model. Then, we apply
Our proposal relies on probabilistic generative variationalinferencetogetanapproximateposteriorof
ABMs(PGABMs):westartbysynthesizingaproba- thetargetparameterswithinagivendataset.
bilisticgenerativemodelfromtheABMrules.Then,
we transform the inference process into an opti- system outcomes can be validated against real-world data.
mization problem suitable for automatic differen- Forexample,inthefieldofopiniondynamics,Fortunatoand
tiation. Inparticular,weusetheGumbel-Softmax Castellano[2007]showthatasimplevotingmodelcanrepro-
reparameterizationforcategoricalagentattributes ducethedistributionofvotesreceivedbypoliticalcandidates
and stochastic variational inference for parameter acrossseveralcountries. Slightlymorecomplexmodelsofthe
estimation. Furthermore,weexplorethetrade-offs samenaturehavebeenusedtoanalyzethenegotiationsaround
ofusingvariationaldistributionswithdifferentcom- theParisAgreementonclimatechange[Bernardoetal.,2021]
plexity: normaldistributionsandnormalizingflows. andtostudytheemergenceofideologicalspacesinUS[Bau-
mannetal.,2021]. However,tuningtheparametersofthese
Wevalidateourmethodonaboundedconfidence
modelsisstillaconsiderablechallenge[Flacheetal.,2017].
modelwithagentroles(leadersandfollowers). Our
Especially in the context of opinion dynamics, both the
approachestimatesbothmacroscopic(boundedcon-
global(macroscopic)andtheindividual(microscopic)level
fidence intervals and backfire thresholds) and mi-
ABM parameters are of great interest, and this is the focus
croscopic(200categorical,agent-levelroles)more
ofthecurrentwork. WhileABMsoffergreatflexibilityand
accuratelythansimulation-basedandMCMCmeth-
aclearrepresentationofthecausalmechanismsthatgovern
ods. Consequently,ourtechniqueenablesexperts
thesystem,theyposesignificantchallengesintheinference
totuneandvalidatetheirABMsagainstreal-world
phase. Theobstaclescomefromseveralfactors,suchasthe
observations, thus providing insights into human
considerablecomputationaleffortrequiredtogeneratedata(a
behaviorinsocialsystemsviadata-drivenanalysis.
completesimulationofthemodel),andthehighdimensional-
ityofmicroscopicparameters,whichscalewiththenumberof
1 Introduction
agents. Additionally,theheterogeneityoftheagentsandthe
Agent-basedmodels(ABMs)arecomputationalframeworks diversityoftherulesintheABMliteratureareanadditional
thatsimulatetheactionsandinteractionsofautonomousagents hindranceinthetractabilityofthesemodels[Platt,2020].
(individualsorcollectiveentities)withinasystem. Theirgoal The current practice for parameter estimation in ABMs
istounderstandhowcomplexphenomenaandpropertiesofa mostlyfocusesonsimulation-basedmethods. Thesemethods
systememergefromtheindividualbehaviorofagents. These compute parameter estimates by running a large amount of
modelsintegrateelementsfromvariousdisciplines,including computationallyexpensivesimulationsofthemodelwithdif-
gametheory,complexsystems,andcomputationalsociology; ferentvaluesoftheparameters,andcomparingtheobserved
andtheyarepopularacrossdiversescientificdomains,such and simulated traces of the system state (a process called
asbiology,ecology,economics,andthesocialsciences. calibration)[Fagioloetal.,2019;LuxandZwinkels,2018].
InABMs,theagentspossessindividualattributesandact Simulation-based approaches rely on summary statistics of
following predefined rules of behavior and interaction, and thesystemstate,primarilyfocusingonthereplicationofsome
4202
raM
8
]YC.sc[
1v85350.3042:viXramacroscopicproperty,ratherthancomparingthemicroscopic is not simulation-based, as it relies on the recovery of the
behaviorsoftheagents. Thesesummarystatisticscauseanin- probabilisticgenerativemodel,andtheparameterestimates
evitablelossofinformationatagranularscale,andpotentially aretheresultofadirectoptimizationprocedure.
causeidentificationissuessincedifferentparameterizations Todemonstratetheviabilityofourapproach,weapplyittoa
of the ABM can lead to indistinguishable summary statis- boundedconfidencemodelwhereeachagentisparameterized
tics[Galloetal.,2022]. Moreover,whentheparametersare byacategoricalrole[Weisbuchetal.,2002]. Whenestimating
high-dimensional,anexhaustiveexplorationoftheparameter theseroles,theVI-basedapproachis3×moreaccuratethan
space is not feasible. For this reason, simulation-based ap- an MCMC baseline, and almost 8× more accurate than a
proacheshavebeenmostlyusedtoestimatelow-dimensional simulation-basedABC.Inaddition,VIisalmostanorderof
parameters, whileignoringthemicroscopicparameters. In- magnitudefasterthanthealternatives.
deed, most of the research on ABM calibration focuses on
(i)aproperestimationchoice,followingthecomparisonof 2 Preliminaries
thesimulatedandobservedsummarystatistics[Grazziniand
Richiardi,2015],(ii)aneffectiverepresentationofthedata 2.1 VariationalInference
trajectories[Lampertietal.,2018],and(iii)anefficientexplo- InthetypicalBayesianframework,theobjectiveistodeter-
rationoftheparameterspace[Quera-Bofarulletal.,2023]. minetheposteriordistributionp(θ |y)ofthemodelparame-
Arecentlineofworkhassuggestedtacklingtheparameter tersθgiventheobserveddatay. Bayes’theoremprovidesthe
estimationprobleminABMsinaradicallydifferentway: via relationshipp(θ |y)=p(y |θ)p(θ)/p(y),wherep(θ)isthe
alikelihood-basedapproach[Montietal.,2020,2022;Lenti priordistributionofthemodelparameterswhichencodesour
etal.,2024]. Theyproposeaparadigmshift,bytranslatingthe initialbeliefsaboutθ,andp(y |θ)isthelikelihoodofobserv-
ABMsintoprobabilisticgenerativemodels,calledProbabilis- ingthedataaccordingtotheunderlyingprobabilisticmodel.
(cid:82)
ticGenerativeABMs(PGABMs). PGABMsexplicitlydefine However,asp(y)= p(θ,y)dθisgenerallyintractable,and
thelatentandobservedvariablesofthesystemaccordingto closed-formsolutionsforp(θ |y)arelimited,Bayesianinfer-
theavailabledata,anddescribetheconditionalprobabilities enceoftenreliesonapproximations.
connectingthem. Thisrepresentationallowsderivingthelike- MCMCisoneofthemaintechniques: itusesasampling
lihoodfunctionofthelatentvariablesofthesystemfromthe routineforθbasedonthepriordistributionandisguaranteed
observeddata,especiallybyleveragingtherigoroustheoryof to converge to the correct posterior, asymptotically. How-
probabilisticgraphicalmodelstoextrapolatetheconditional ever, MCMC algorithms do not scale well to large datasets
independenciesamongthevariablesinplay. Asaresult,this andoftenstruggletoapproximatemultimodalposteriorsef-
approachismoreprincipled,moreaccurate,andfasterthan fectively[Bleietal.,2017]. VariationalInference(VI)isan
simulation-basedalternatives[Lentietal.,2024]. alternativetoMCMCalgorithmsforapproximatingatarget
Nevertheless,thelikelihood-basedapproachrequiresanon- densityviaanoptimizationstep[Bleietal.,2017]. VIapprox-
trivialanalyticalprocesstoderivethelikelihoodfunction. In imatesthetargetposteriorp(θ |y)byusingamoretractable
addition,handlingcategoricalvariablesisstillanopenchal- familyofdensitiesq (θ),calledthevariationaldistribution,
λ
lenge: forinstance, amaximum-likelihoodapproachinour indexedbythevariationalparameterλ.
settingwouldrequireexploringanexponentiallylargecom- Theoptimalvariationalparameterλ∗ istheonethatmin-
bination of agents’ parameter values (up 2200). The main imizes the KL-divergence of q (θ) from p(θ | y). In prac-
λ
contributionofthisworkisatechniquethatcircumventsthe tice, the search for this parameter is done by maximizing
needtowriteanexplicitderivationofthelikelihood,byusing theevidencelowerbound(ELBO),denotedasL(λ),asthe
variationalinference(VI)instead.VIassumesatractable,para- KL-divergenceitselfisintractable
metric,functionalformfortheapproximationoftheposterior
L(λ)=E [logp(y,θ)−q (θ)], (1)
distributionoftheparameterstobeestimated. Then,itdirectly q λ
optimizestheparametersoftheapproximationtominimize
whichisequivalentto
thedistancebetweentheapproximatedandrealposterior. In
sodoing,ourVIapproachcanaddressmodelswithintractable L(λ)=logp(y)−KL(q (θ)∥p(θ |y)). (2)
λ
likelihoodfunctions(e.g.,withalargenumberofcategorical
variables). Figure1depictstheproposedpipeline. So, maximizing the ELBO is equivalent to minimizing the
KL-divergenceofq (θ)fromp(θ |y).
VIapproximatestheposteriordistributionoftheparameters λ
Stochastic Variational Inference (SVI) is a common rou-
andthusrepresentsaBayesianapproach. SeveralBayesian,
tineformaximizingtheELBO[Hoffmanetal.,2013]. SVI
simulation-based methodologies exist to calibrate ABMs:
usesgradientascenttooptimizetheELBO,andestimatesthe
some employ Monte Carlo schemes [Grazzini et al., 2017;
gradientonsubsamplesofthedatainsteadofusingtheentire
Ternes et al., 2022], others use neural approximation tech-
datasetforimprovedspeed.
niques[Dyeretal.,2022]. However,thecomputationalbur-
den of the model simulations often limits the scalability of VariationalInferencewithNormalizingFlows. Thechoice
the inference procedure. In particular, Grazzini et al. com- ofthevariationaldistributionrepresentsacriticalstepinthe
paredifferentBayesianapproaches,includingMarkovChain VIprocess,asitencodesthefunctionalformoftheapprox-
Monte Carlo (MCMC) and Approximate Bayesian Compu- imation of p(θ | y). The family of normal distributions is
tation (ABC), and lament the major obstacle of simulation a common choice, thanks to its simplicity and prevalence
time. Instarkcontrasttotheexistingliterature,ourapproach inBayesianstatistics. However,thenormalfamilyimposesstrongconstraintsonthevariationaldistribution,suchassym- diverge by a divergence rate (µ−). In the other cases, their
metryandunimodality. Arecentandmoreflexiblesolutionis opinionsremainunchanged(s=0).
toadoptnormalizingflows(NFs)asthevariationaldistribu- Letxt betheopinionofagentuattimet,thedynamicsof
u
tion[RezendeandMohamed,2015]. NFsaretransformations theopinionaftertheinteractione =(u,v)areasfollows
t
ofsimpleprobabilitydistributions(e.g.,normal)intoricher  xt+1 =xt +µ+∆xt if |∆xt |<ε+,
andmorecomplexdistributionsthroughasequenceofinvert-  v v uv uv
xt+1 =xt if ε+ ≤|∆xt |<ε−, (4)
ibleanddifferentiablemappings. Theexpressivenessofthese v v uv
 xt+1 =xt −µ−∆xt if |∆xt |≥ε−.
transformationsenablesNFstorepresentarbitrarilycomplex v v uv uv
distributions,whichwecanefficientlysamplefromandcom- Aftereachupdate,theopinionsareclampedto[0,1],
putetheELBOof[Papamakariosetal.,2021]. xt+1 =max(0,min(xt+1,1)). (5)
u u
Categoricalvariables. AstheELBOismaximizedviagradi- Differentchoicesofε+ andε− leadtodifferentfinalcon-
entascent,thecomputationistractableonlyforcontinuous, figurationsoftheopinionsattheendofthesimulation(time
differentiable variables. Categorical variables pose a great stepT),whichcancaptureconsensus,polarization,orfrag-
challenge,bothbecauseoftheirdiscretenatureandbecause mentation[JagerandAmblard,2005].
thereisnoinherentorderingwithintheirsupport.TheGumbel-
Boundedconfidencemodelwithbackfireeffectandroles.
Softmaxreparameterizationoffersaviablesolutionforthese
Weextendthemodeltorepresentasocialcontextwherethe
cases[Maddisonetal.,2016;Jangetal.,2016]. Ratherthan
agentsaredividedintonon-overlappingroles,similartothe
sampling a variable z from a categorical distribution with
modelbyWeisbuchetal.[2002]. Eachagenthasarole(r )
probabilities(π ,...,π ),wesamplefromadistributionthat u
1 k which can be either leader (r = L) or follower (r = F).
u u
smoothly approximates the categorical distribution. Mathe-
Leadersandfollowersadoptdifferentbehaviors: followersare
matically,thisisexpressedas
morepronetochangetheiropinionscomparedtoleaders.
Aninteraction(u,v)inthismodelisasymmetricsinceonly
z =softmax[g +logπ ], (3)
i i i the opinion of v gets updated and the dynamics depend on
the role of v. It follows a bounded confidence model with
whereg isaGumbelnoise.Atemperatureτ parameterizesthe
i backfireeffect withparametersε+andε−ifvisafollower,
softmaxandcontrolshowcloselyitapproximatestheargmax F F
andwithparametersε+ andε− ifv isaleader. Weassume
(closerforτ → 0). Ifk = 2,theGumbel-Softmaxreparam- L L
thatfollowersaremoreinclinedtochangetheiropinions,and
eterizes a Bernoulli distribution. This technique provides a
thus ε+ ≥ ε+, ε− ≤ ε−, µ+ ≥ µ+, and µ− ≥ µ−. For
waytorelaxaprobabilisticgenerativemodelwithcategorical F L F L F L F L
randomvariableswhichallowsforoptimizingtheELBOand, conciseness,wedefineε=(ε+ F,ε+ L,ε− F,ε− L). Insummary,at
consequently,estimatingthetargetparameters. eachtimestep,themodelevolvesaccordingtotheserules:
IntherealmofABMs,differentiableABMshavebeende-
veloped for keeping the gradient of categorical variables in 1: Sampletwoagents(u,v)uniformlyatrandom
simulation-basedinference[Andelfinger,2021]. Inthiscase, 2: Letr v ∈{F,L}betheroleofv
thecategoricalvariablesaremodeledasdeterministicapproxi- 3: if|∆xt |<ε+ then
uv K
mationsofcontinuousvariables,equippedwiththegradientof 4: s:=1
suchcontinuousvariables. WeprefertheGumbel-Softmaxfor 5: xt+1 :=xt +µ+∆xt
v v rv uv
tworeasons. First,itfindsbroaderapplicabilityintheprob- 6: elseif|∆xt |≥ε− then
uv rv
abilisticmachinelearningcommunityasaversatilesolution 7: s:=−1
forhandlingcategoricalvariables. Second,itissupportedby 8: xt+1 :=xt −µ−∆xt
v v rv uv
amorerobusttheoreticalframeworkforincorporatingcategor- 9: else
icalvariablesintoprobabilisticgenerativemodels. 10: s:=0
11: xt+1 :=xt
v v
2.2 OpinionDynamicsModel 12: endif
13: xt+1 :=max(0,min(xt+1,1))
v v
Boundedconfidencemodelwithbackfireeffect. Weana-
lyze the bounded confidence model with backfire effect , a
popular opinion dynamics model that depicts the dynamics
3 ProbabilisticGenerativeABMs
inasocialnetworkwithagreementanddisagreementbehav-
iors[JagerandAmblard,2005]. Eachagenthasanopinion Translating the ABM into its probabilistic generative coun-
in[0,1],where0and1representthetwopolaroppositesona terpartisacrucialstepintheinferenceprocess,asitdefines
giventopic(e.g.,ontheleft–rightpoliticalspectrum). Ateach thegenerativemodelwewishtoapproximate. Wesplitthe
timestep,anagentinteractswithoneofitsneighbors,thusem- variablesintotwovariables, s+ = 1ands− = 0ifs = 1,
ulatingasocialnetwork. Iftheopinionsofthetwointeracting elses+ =0ands− =1ifs=−1,otherwises+ =s− =0.
agentsarecloserthanathreshold—theboundedconfidencein- Then,wedefinetheconditionalprobabilitiesofobservingthe
terval(ε+)—theyhaveapositiveinteraction(s=1)andtheir interactionoutcomess+ands−
opinionsconvergebyaconvergencerate(µ+). Conversely,if P(s+ =1|x ,e ,ε,r )=σ(ρ·(ε+ −|∆xt |)) (6)
theiropinionsarefurtherthanabackfirethreshold(ε−),then
j t j v rv uv
P(s− =1|x ,e ,ε,r )=σ(−ρ·(ε− −|∆xt |)), (7)
theyhaveanegativeinteraction(s=−1)andtheiropinions j t j v rv uvPGMparameterthatisgiven. Similarly,thesameobjectsare
r ε
treatedasABMparametersandPGMlatentvariables,and
thisdistinctionshouldbeclearfromthecontext.
e s
X 0 X t X t+1 4 Inference
After having derived the PGM, we need to infer the target
T
latent variables. We compare 4 different methods to do so:
Figure2: ProbabilisticGraphicalModelassociatedwith twomethodsbasedonvariationalinferencethatrepresentour
theBoundedConfidencemodelwithbackfireeffectandla- proposal,anMCMCmethodthatisamoreclassictakeonthe
tentroles. Circlesrepresentstochasticvariables,diamonds conceptofPGABM,andaBayesiansimulation-basedmethod.
deterministicvariables,andletterswithoutenclosuresare VariationalInference. Thefirsttwomethodsarebasedon
given PGM parameters. Shaded variables are observed VI and differ only in the choice of the family for the vari-
andwhiteonesarelatent.XXX tttistheopinionvectorattime ational distribution. We cast the model into a probabilistic
ttt,eeeisthevectoroftheinteractingagents,sssencodesthe programminglanguage(NumPyroinourcase). Sinceweinfer
interactionsoutcomes,rrraretherolesoftheagents,andεεε a4+N-dimensionalvariable,thevariationaldistributionq
isthelatentvector(εεε+ F+ F+ F,εεε+ L+ L+ L,εεε− F− F− F,εεε− L− L− L)ofABMparameters. hasthesamedimensions. ThetwodistinctVImethodsusλ e
Inourframework,weestimatethelatentvariables,rrrand different q , respectively a multivariate normal distribution
λ
εεε,giventheobservationsonsssandXXX. andnormalizingflows(seeSection2.1).
Uponsamplingfromq ,weneedtorestricttheparameters
λ
whereσ(·)isthesigmoidfunctionandρisitssteepness[Monti intheappropriatedomains,sinceq hassupportinR4+N.We
λ
etal.,2020]. Thisway,wehaveaprobabilisticmodelwhere computeεˆandrˆfromθ ∼q byusingasigmoidtransform.
λ
weobserves+ = 1withahighprobabilityif|∆xt | < ε+,
ands− =1if|∆xt |≥ε−. Asρ→+∞suchprou bv abilitir ev s • εˆ+ F =σ(θ 1)/2 • εˆ− F =σ(θ 3)/2+1/2
goto1,andthemou dv elconr vv ergestotheoneinEquation(4).1 • εˆ+
L
=σ(θ 2)/2 • εˆ−
L
=σ(θ 4)/2+1/2
Note that the samples of s+ and s− are independent, so at
Thisstepensuresthatεˆ+andεˆ+areboundedwithin[0,0.5]
eachinteraction,wecanhavebothapositiveandanegative F L
andεˆ−andεˆ−within[0.5,1].
interaction,resultinginasimultaneousconvergenceanddiver- F L
Theprocedurefortherolevectorrisslightlymorecomplex.
genceoftheopinions. Thisprocessensuresthatanysample
fromtheparameterspacecanbeassociatedwithanon-zero Wefirstdefineϕˆ u =σ(θ u+4),whichrepresentstheposterior
probabilityofhavinggeneratedthedata. probability that u = L. Instead of sampling the role with
Then,weusetheprobabilisticgraphicalmodel(represented a Bernoulli extractions of ϕˆ, we use the Gumbel-Softmax
inFigure2)tocapturetheconditionalindependenciesbetween relaxation, with temperature 0.1. Consequently, we define
therandomvariablesandtherepeatedpatterns. Tothisend, r˜ ∼Gumbel-Softmax(ϕ ,1−ϕ ). Finally,wecanexpress
u u u
weidentifytheobservedvariables,thelatentvariables,and theboundedconfidenceintervalforthenodeastheexpectation
the parameters of the PGM, together with the relationships over its role ε˜ = r˜ ·εˆ +(1−r˜ )·εˆ , in a way that is
u u L u F
thatconnectthem. Inoursetting,weassumethatthepairsof similar to a linear relaxation of an integer program. Note
interactingagents(e), theoutcomesoftheinteractions(s+, thatthisexpressionsimplyrepresentsasuperpositionofthe
s−),theinitialopinions(X ),andtheconvergenceanddiver- beliefsofthemodelgiventhecurrentevidencefortheroleof
0
gence rates (µ = (µ+,µ+,µ−,µ−)) are observed. X is a anagent,butdoesnotrequirechangingthemodeltodefine
L F L F t
deterministicvariable,anditiscomputablefromtheprevious an intermediate chase ‘in-between’ roles. This formulation
observations. Noticethatµandeonlyaffectobservedvari- allowsdeterminingε˜ basedonthesampledGumbel-Softmax
u
ables, so we consider them as parameters of the PGM (we probabilitiesandbuildsaninterpolationthatiseasiertohandle.
omit µ from Figure 2). Instead, ε and the agent roles r are Then,wedefinetheprocessusedtogeneratethedata. Since
latent. Inparticular,weconsiderrasamicro-parameter,asit our goal is to estimate the ELBO, we need to sample from
isavectorofsizeequaltothenumberofagentsN,whileεhas q and from p(s,θ), as outlined in Equation (1). From the
λ
dimension4. SoweneedtoestimateN +4latentvariables. PGABM, we have closed form solutions for P(s+ = 1 |
j
Anoteonnomenclature. InthefieldofABMs,anddynam- ε,X,r) and P(s− = 1 | ε,X,r), representing p(s | θ).
j
icalsystemsingeneral,avariabledependsontimewhilea
Hence, we can directly sample p(s,θ), via p(θ). Thus, this
parameter is independent of time. Conversely, the nomen-
formulationallowsustoautomaticallymaximizetheELBO
clature for PGMs is more concerned about randomness: a by seeking the optimal approximation q of the posterior
λ∗
variable can assume different values, according to either a distributionofεandr.
stochasticordeterministicprocess. Anobservedvariablewith-
Markov Chain Monte Carlo. An alternative approach to
outparentsinthegraphicalmodeliscalledaparameter. It
estimatethelatentvariablesofthePGMissampling-basedin-
shouldbeclearfromthecontextwhenwearereferringtoa
ferenceviaanMCMCalgorithm. WeuseNo-UTurnSampler
latentABMparameterthatweareestimatingvs. anobserved
(NUTS),anadaptiveHamiltonianMonteCarlomethodthatis
1Inourexperimentswesetρ=32,forwhichtheprobabilitiesof knownforitshighefficiencyandflexibility[Hoffmanetal.,
interactionsoutsidestheboundsarealreadynegligible(≤10−5). 2014]. ThePGMisthesameasinthevariationalcase.• MarkovChainMonteCarlo(MCMC)samplingusingNo
SVI - Normal SVI - NF MCMC ABC
01..50 U-Turn Sampler (NUTS). We use 5000 simulations as
burn-inand5000simulationsfortheestimate.
0.25
• ApproximateBayesianComputation(ABC),awell-known
methodintheliteratureofABMcalibration,similartothe
0.80
0 0.25 0.50 0.25 0.50 0.25 0.50 0.25 0.5 work by Grazzini et al. [2017]. The distance between
1
thesimulatedtimeseriesandthedatasummaryistheL2
√
0.75 distance. Wesetanacceptancethresholdof5 T,andwe
0.6 launch1000simulations.
0.5 Werunagridof912experimentswherewesampleεwith
0.5 0.75 10.5 0.75 10.5 0.75 10.5 0.75 1
0.5 the constraint that ε+ ≥ ε+, both in [0,0.5], and ε− ≤ ε−,
F L F L
0.4 both in [0.5,1]. We set µ+ = µ+ = µ− = µ− = 0.02 and
0.25 F L F L
use 10 interactions per time step. We vary the number of
agents N, the length of the simulation T, and the propor-
0
0 0.25 0.50 0.25 0.50 0.25 0.50 0.25 0.5 tion of leaders to have all the possible combinations with
0.21
N ∈ {50,100,200,400}, T ∈ {128,512,2048,8192}, and
leaders proportion ∈ {0.01,0.02,0.04,0.1,0.2}. For each
0.75
combinationofparameters,wesimulatetheABM,thenesti-
matethetargetparameterswiththefourmethods.Forpractical
00..50
00..50 0.75 0.210.5 0.705.4 10.5 0.06.75 100.5.8 0.75 11.0 reasons,weabortanexperimentafter3hours.
Actual values
SincethemethodsunderscrutinyareallBayesian,thepa-
Figure3:Comparisonbetweenactualvaluesεεε(x-axis)and
rameterestimatesaredistributions. Toeaseunderstandingof
estimatesεεεˆˆˆ(y-axis)foreachmacroscopicparameter(rows) the results, we compare the average values of 200 samples
andmethod(columns). Eachexperimentsamplesεεε+++and fromeachposteriordistribution.2
FFF
εεε+++in{{{000...000555,,,000...111555,,,000...222555,,,000...333555,,,000...444555}}},suchthatεεε+++≥≥≥εεε+++,and
LLL FFF LLL Parameter Estimates. Figure 3 compares the estimates of
εεε−−−andεεε−−−in{{{000...555555,,,000...666555,,,000...777555,,,000...888555,,,000...999555}}},suchthatεεε+++≤≤≤
themacroscopicparameterswiththeiractualvaluesforallthe
FFF LLL FFF
εεε+++. Pointsonthediagonalsrepresentexactestimates. experiments. Summarizingtheresults,weobtainanaverage
LLL
root-mean-squareerror(RMSE)of0.044forSVIwithnormal,
of0.036forSVIwithNFs,0.051forMCMCand0.125for
Approximate Bayesian Computation. While the previ-
ABC.TheimprovedperformanceoftheSVI-basedmethods
ous methods are based on PGMs, Approximate Bayesian
isevidentevenbyinspectingthefigurevisually.
Computation (ABC) is a likelihood-free, simulation-based
Themainhurdleintheinferenceisdiscriminatingbetween
method[Csille´ryetal.,2010]. ABCsamplesasetofparam-
leadersandfollowers,bothbecauseofthehighdimensionality
eters from a prior distribution, and for each sample it runs
oftheparameteranditscategoricalnature. Sincemostofthe
theentiresimulationoftheopiniondynamicsmodel. Itthen
users are followers, the leader’s parameters are the hardest
considerssummarystatisticsofthegenerateddatatracetosee
to estimate: when the methods are not able to identify the
how‘close’itistotheoriginaldata. Inthiscase,weusethe leaders they tend to set εˆ+ = εˆ+ and εˆ− = εˆ−. Since ε+
numberofpositiveinteractionsandthenumberofnegative L F L F F
≥ε+,severalobservationsinFigure3(row3)areabovethe
interactionspertimestepassummarystatistics.Ifthedistance L
diagonal. Analogously,sinceε− ≤ε−,mostoftheestimates
betweenthesummarystatisticsoftheobservedandsimulated F L
inFigure3(row4)arebelowthediagonal.
trajectories is lower than an acceptance threshold, then the
simulation is accepted; otherwise it is rejected. Finally, it EstimateRobustness. Figure4showstheaverageerrorfor
derivestheposteriordistributionofthetargetparametersby thefourmacroscopicparametersoftheABM,andtheerror
countingthenumberofacceptancesandrejectionsfromthe rateforthemicroscopicones(theroles),i.e.,theproportionof
differentregionsoftheparameterspaceviaBayes’rule. rolesthatarenotcorrectlyestimated,asfunctionsofthethree
hyperparametersthatwevaryintheexperiments—thenumber
5 Results ofagentsN,thelengthofthedatatraceT,andtheproportion
ofleaders. ThemaininsightsfromFigure4are:
ExperimentalSetting. Werunabroadsetofexperimentsto
• SVIwithNFs,followedbySVIwithnormal,outperforms
comparetheestimatesofε+,ε+,ε−,ε−,andr whenusing
F L F L theothercompetitorsineachscenario.
thefourBayesianmethodsmentionedinSection4.
• ThethreemethodsbasedonPGMs(thetwoSVImethods
• SVI with normal distribution as variational distribution.
andMCMC)showbetterperformancescomparedtothe
The ELBO is maximized via Adam, with learning rate
simulation-basedmethod,ABC.Inparticular,ABCisnot
0.01,runningfor20000epochs.
abletoguesstherolesoftheagents,witherrorrateson
• SVIwithNFs,transformedviaBlockNeuralAutoregres- therolemicroparametersabove40%.
siveflow[DeCaoetal.,2020],with2flows. TheELBO
ismaximizedviaAdam,withlearningrate0.01,running 2Thecodetoreproducetheseresultsisopen-sourceandavailable
for10000epochs. athttps://anonymous.4open.science/r/learning micromacro-1B9C
+
+
F
F
L
LN T Leaders Proportion respectively,0.54,0.38,0.29,and0.
0.10
Runningtime.Theestimationtimesvaryconsiderablyamong
0.05 thetestedmethods(Figure5). First,boththeVImethodsscale
0.00 wellwiththelengthoftheABMstrajectories(T). Thescala-
bilityofVIarisesfromitsoptimization-basedapproach,which
0.10
avoidstheneedtoexplicitlyevaluatetheentiredatasetdur-
inginference. Thiscomputationaladvantagebecomesmore
0.00
evidentasthedatasetsizegrows[Bleietal.,2017]. Second, 0.10
theestimationtimeofSVIwithNFsgrowslinearlywithN.
0.05
Thisreflectstheincreasednumberofparametersunderlying
0.00 theneuralnetworksimplementingtheNFs. Conversely,the
estimationtimeofMCMCincreaseslinearlywithT,reflecting
0.10
the number of samples required to replicate larger datasets.
0.00 Overall,SVIwithnormalisthemostefficientmethod: itre-
0.40 ducestheestimationtimebyafactorof56.0comparedtoSVI
0.20 withNFs,36.9comparedtoMCMC,and36.5comparedto
0.00 ABC.Onaverage,theestimationtimeofSVIwithnormalin
50 100 200 400 27 29 211 2130.010.020.04 0.100.20 thelargestexperiments(N =400,T =8192)is61seconds.
SVI - Normal SVI - NF MCMC ABC TheexperimentshavingSVIwithNFswithN =400,andthe
Figure4: Specificerrorsofεεε+++,εεε+++,εεε−−−,εεε−−−,andrasfunc- oneswithABCandMCMCwithT =8192ranoverthetime
FFF LLL FFF LLL limit.
tions of NNN (left), TTT (center), and proportion of leaders
(right). Theerrorbarsrepresentthestandarderrors. Erroranalysis. Figure6showstheerrorrateoftherolesas
afunctionofsomesummarystatisticsofthegenerateddata
trace. Thisanalysisprovidesnewinsightsintohowtoestimate
N T theparametersbasedontheavailableobservations.
Thefirsttwopanelsshowthatanincreaseinthenumberof
103 positiveoutcomesoftheinteractionsofthefollowersandof
theleadersleadstoalowererror. Highervaluesof|ε+−ε+|
102 F L
and|ε−−ε−|areassociatedwithlowererrors. Suchdiffer-
101 encesdL etermF
inehowdistinguishablearethebehaviorsofthe
50 100 200 400 27 29 211 213 leaders and the followers. In the extreme case where ε+ =
F
SVI - Normal SVI - NF MCMC ABC ε+ andε− =ε− theleadersandfollowersareindistinguish-
L F L
able. ThelastplotofFigure6comparesthevarianceofthe
Figure5: EstimationtimeasafunctionofNNN (left)andTTT
opinionattheendofthesimulationandtheerrorrate. Alow
(right). Theerrorbarsrepresentstandarderrors.
varianceoftheopinionsatthefinaltimeT correspondstoa
convergenceoftheopinions: ascenarioofconsensus. Insuch
scenarios,theprobabilityofobservingnegativeinteractionsis
• AsT grows,wehavemoredata,thustheestimatesofSVI
extremelylowandtheprobabilityofhavingpositiveinterac-
andMCMCimprove.
tionsisextremelyhigh,whichhindersdiscriminatingbetween
• CoherentlytoFigure3,theestimatesofleaders’parame- different values of ε. Moreover, all the agents are likely to
ters,ε+ L andε− L,areworsethanfollowers’ones,ε+ F and havesimilarbehaviordespitethedifferentroles.
ε−. Asmentioned,whentherolesarenotcorrectlyesti- Theseobservationshelptoidentifywhichsettingsprovide
F
matedthemethodsfavorestimatingε+andε−correctly, learnable experiments and help the modeler determine the
F F
whichaffectsthemajorityoftheagents’behaviors. propertiesoftheopiniondynamicsmodelthataffecttheout-
comesoftheestimates. Forinstance,ifwefocusontheexper-
• Theerrorrateoftheroles,andconsequentlyalltheother
imentswith|ε+−ε+| > 0,|ε−−ε−| > 0,and(cid:80) s > 10
errors, grows as N increases. Indeed, as N grows we L F L F L
the error rate of the roles with SVI with NFs drops from
havebothanincreasednumberoftargetparametersanda
0.060to0.029. Moreover,ifwerestricttoexperimentswith
reducednumberofobservationsperagent.
var(X )>0.01,thiserrorratedecreasesto0.018.
• Ahigherproportionofleadersleadstomoreaccurateesti- T
mations. Indeed,moreleadersimplyalargernumberof
interactionsinvolvingε+andε−,whichhelpsinestimat- 6 Discussion
L L
ingthecorrectrolesbydifferentiatingtheagents. ThisworkexplorestheuseofAItechnologyinsynergywith
• The VI methods are the only ones able to estimate the agent-based models (ABMs). On the one hand, ABMs are
roleofmicroparameterswithhighaccuracy. Theaverage behavioralmodelsthatputthehumanatthecenterofthesys-
errorratesforSVIwithNFs,SVIwithnormal,MCMC, tem,byfocusingonthemacroscopicphenomenaarisingfrom
and ABC, are 0.06, 0.09, 0.22, and 0.47, respectively. individual,microscopicchoices. Thisperspectiveprovidesa
The proportion of experiments with 100% accuracy is, mechanisticexplanationofsocialphenomena. Ontheother
|+
F
+ F|
|+
L
+ L|
|F
F|
|L
L|
selor
etar
rorrE
)s(
emiT
noitamitsE0.6 SVI - Normal
SVI - NF
0.4 MCMC
ABC
0.2
0.0
103 104 105 0 101 103 0 0.1 0.2 0.3 0.4 0 0.1 0.2 0.3 0.4 0 0.1 0.2
sF sL | L+ F+| | L F | var(XT)
Figure6: Root-mean-squareerror(RMSE)ofεεεagainstsomefeaturesoftheABMstrajectories,(i)numberofpositive
interactionsoffollowers,(ii)numberofpositiveinteractionsofleaders,(iii)absolutedifferencebetweenεεε+++ andεεε+++,(iv)
FFF LLL
absolutedifferencebetweenεεε−−−andεεε−−−,(v)varianceoftheopinionattheendofthesimulation. Theregressionlinesare
FFF LLL
inlogarithmicscale.
hand,theAIandMLliteratureoffersarichtoolboxtoincorpo- laborationsbetweenAIspecialistsanddomainexperts,thusad-
ratedataintomodels. Moreover,thesetechnologiescanassist vancingknowledgeofhumanbehavioranditsconsequences.
modeldesignbyprovidingnewinsightsintothefeaturesthat LimitationsandFutureWorks. Althoughourstudyfocuses
allowlearningamodel.Theyenableamodelrefinementphase only on one specific model, we underline that the latter is
thatiterativelyadjuststheABMrulestobetterfitthespecific notonlypopularbutalsochallengingbecauseofthehighdi-
data context. Furthermore, model design can benefit from mensionalityandcategoricalnatureofthelatentparameters.
modelselection,wheredifferentmodelsarecomparedinthe Indeed,itwouldbeunfeasibletovisitallthe2200 combina-
analysisofthesamedatasettocomparedifferenthypotheses. tionsofroleswithinasimulation-basedorlikelihood-based
Untilnow,theapplicationsofAIinABMshaveprimarily approach. Additionally,thepresentedpipelinerequiredonly
centeredondevelopingintelligentagents[Zhangetal.,2021], minimalcustomizationinthetranslationfromtheABMtothe
orrepresentingABMswithneuralmeta-models[vanderHoog, PGABM,itsimplementationinNumPyro,andtheoptimiza-
2019]. By properly estimating the parameters of a popular tionoftheELBO.Applyingittoothermodelsshouldbeeasy
opiniondynamicsmodelwithvariationalinference,wepave givenitsflexibilityandgenerality.
thewaytotheapplicationofthebroadtheoryofprobabilistic Whilethemodelwestudyaimstocapturewidesocialbe-
AI in the realm of inference on ABMs. Parameter estima- havior,thescaleofthisstudyisfarsmaller. Real-worldsocial
tioninPGABMshasbeentackledviaexpectationmaximiza- mediastudiesofteninvolvetensofthousandsofusers. How-
tion[Montietal.,2020,2022]orbydirectmaximizationof ever,ourexperimentswereconstrainedto3hoursofrunning
thelikelihood[Lentietal.,2024]. Whileeffective,theseap- timetoaccommodatethepresentationofhundredsofexperi-
proachesmaybelimitedintheirapplicabilityastheyrequire ments. Inpractice,computationaleffortscouldbeallocated
an analytical derivation of the likelihood. In this work, we differentlyonasingledataset. Additionally,probabilisticpro-
offer a proof-of-concept of a general and flexible approach gramming languages support GPU accelerators and can be
abletoestimatehigh-dimensional,categorical,andcontinuous optimizedforgreaterefficiency. Moreover,ifcomputational
parametersinABMs. timeisanissue,SVIwithnormalrepresentsagreatoptionas
Themodelwestudyfocusesonpolarizinghumanbehavior itreachedgoodestimatesinthemostdemandingexperiments
in social media. This area is of great importance, as polar- inonly61secondsandscaleswell.
izationhasbeenidentifiedasamajorsocietalrisk,together Finally,ourworkfocusesonmethodologicaldevelopment,
withmisinformation.3 Thesephenomenaarerelated,asmisin- so a closer inspection of the results was beyond the scope
formationspreadsfasterinpolarizedenvironments[Nikolov ofthispaper. Weacknowledgethatadeeperanalysisofthe
etal.,2021]. Awiderangeofopiniondynamicsmodelsfor posterior distributions returned by the models would be an
thesephenomenahasbeenproposed[DelVicarioetal.,2016; interestingresearchdirection. LeveragingtheBayesiannature
Proskurnikovetal.,2015;To¨rnberg,2018;AzzimontiandFer- of VI, future analyses could explore multimodal posterior
nandes,2023]. However,theyhavefoundlimitedapplicability distributionstoaddressidentifiabilityproblems.
inreal-worldscenariosduetothelackofamethodological
Conclusions. Wepresentedanovelmethodologyforestimat-
frameworktoestimateandvalidatethem. Ourmethodology
ingboththemacroscopicandthemicroscopicparametersofa
offers a data-driven perspective on opinion dynamics, thus
boundedconfidencemodelwithbackfireeffect withleaders
facilitatingtheexplorationofdifferentscenarios,andtheeval-
andfollowers. Ourapproachcanestimatehigh-dimensional,
uationofpotentialpolicyinterventions.
numericalandcategorical,globalandindividualparameters
Moregenerally,weemphasizetheversatilityofPGABMs ofABMswithhighaccuracy. Toachievethisresult,werely
forapplicationstoABMsindifferentfields,suchashumanmo- onstochasticvariationalinferencewithnormalizingflowsas
bility,economics,andepidemiology. Theconnectionbetween variationaldistribution,whichoutperformedotherBayesian
PGABMsandreal-worlddatacanfosterinterdisciplinarycol- baselines. Using a normal variational distribution achieved
goodresultsatafractionofthetime.
3https://www.weforum.org/publications/
global-risks-report-2024
selor
etar
rorrEReferences SantoFortunatoandClaudioCastellano. Scalinganduniver-
salityinproportionalelections. PhysicalReviewLetters,99
PhilippAndelfinger. Differentiableagent-basedsimulationfor
(13):138701,2007. (Citedon1)
gradient-guidedsimulation-basedoptimization. InProceed-
ingsofthe2021ACMSIGSIMConferenceonPrinciplesof LucaGallo,MattiaFrasca,VitoLatora,andGiovanniRusso.
AdvancedDiscreteSimulation,pages27–38,2021. (Cited Lackofpracticalidentifiabilitymayhamperreliablepredic-
on3) tionsincovid-19epidemicmodels. Scienceadvances,8(3):
eabg5234,2022. (Citedon2)
Marina Azzimonti and Marcos Fernandes. Social me-
dia networks, fake news, and polarization. Euro- JakobGrazziniandMatteoRichiardi. Estimationofergodic
pean Journal of Political Economy, 76:102256, January agent-basedmodelsbysimulatedminimumdistance. Jour-
2023. ISSN 0176-2680. doi: 10.1016/j.ejpoleco.2022. nalofEconomicDynamicsandControl,51:148–165,2015.
102256. URL https://www.sciencedirect.com/science/ (Citedon2)
article/pii/S0176268022000623. (Citedon7)
Jakob Grazzini, Matteo G Richiardi, and Mike Tsionas.
Fabian Baumann, Philipp Lorenz-Spreen, Igor M Sokolov, Bayesian estimation of agent-based models. Journal of
andMicheleStarnini. Emergenceofpolarizedideological EconomicDynamicsandControl,77:26–47,2017. (Cited
opinionsinmultidimensionaltopicspaces. PhysicalReview on2,5)
X,11(1):011012,2021. (Citedon1)
MatthewDHoffman,DavidMBlei,ChongWang,andJohn
CarmelaBernardo,LingfeiWang,FrancescoVasca,Yiguang Paisley. Stochasticvariationalinference. JournalofMa-
Hong,GuodongShi,andClaudioAltafini. Achievingcon- chineLearningResearch,2013. (Citedon2)
sensusinmultilateralinternationalnegotiations: Thecase
MatthewDHoffman,AndrewGelman,etal. Theno-u-turn
studyofthe2015parisagreementonclimatechange. Sci-
sampler: adaptively setting path lengths in hamiltonian
enceAdvances,7(51):eabg8068,2021. (Citedon1)
montecarlo. J.Mach.Learn.Res.,15(1):1593–1623,2014.
DavidMBlei,AlpKucukelbir,andJonDMcAuliffe. Varia- (Citedon4)
tionalinference: Areviewforstatisticians. Journalofthe
WanderJagerandFre´de´ricAmblard. Uniformity,bipolariza-
AmericanstatisticalAssociation,112(518):859–877,2017.
tionandpluriformitycapturedasgenericstylizedbehavior
(Citedon2,6)
withanagent-basedsimulationmodelofattitudechange.
KatalinCsille´ry,MichaelGBBlum,OscarEGaggiotti,and Computational&MathematicalOrganizationTheory,10
OlivierFranc¸ois. Approximatebayesiancomputation(abc) (4):295–303,2005. (Citedon3)
inpractice. Trendsinecology&evolution,25(7):410–418,
EricJang,ShixiangGu,andBenPoole. Categoricalreparam-
2010. (Citedon5)
eterizationwithgumbel-softmax. InInternationalConfer-
Nicola De Cao, Wilker Aziz, and Ivan Titov. Block neural enceonLearningRepresentations,2016. (Citedon3)
autoregressiveflow. InUncertaintyinartificialintelligence,
FrancescoLamperti,AndreaRoventini,andAmirSani.Agent-
pages1263–1273.PMLR,2020. (Citedon5)
basedmodelcalibrationusingmachinelearningsurrogates.
MichelaDelVicario,AlessandroBessi,FabianaZollo,Fabio JournalofEconomicDynamicsandControl,90:366–389,
Petroni,AntonioScala,GuidoCaldarelli,H.EugeneStan- 2018. (Citedon2)
ley,andWalterQuattrociocchi. Thespreadingofmisinfor-
Jacopo Lenti, Corrado Monti, and Gianmarco De Fran-
mation online. Proceedings of the National Academy of
cisciMorales. Likelihood-basedmethodsimproveparame-
Sciences,113(3):554–559,January2016. ISSN0027-8424,
terestimationinopiniondynamicsmodels. Proceedingsof
1091-6490. doi: 10.1073/pnas.1517441113. URL https:
the17thACMInternationalConferenceonWebSearchand
//pnas.org/doi/full/10.1073/pnas.1517441113. tex.ids=
DataMining,2024. (Citedon2,7)
del2016spreading tex.date-added: 2019-10-28 15:35:56
+0000tex.date-modified: 2019-10-2815:35:56+0000pub- ThomasLuxandRemcoCJZwinkels. Empiricalvalidation
lisher: NationalAcadSciences. (Citedon7) ofagent-basedmodels. InHandbookofcomputationaleco-
nomics,volume4,pages437–488.Elsevier,2018. (Cited
Joel Dyer, Patrick Cannon, J Doyne Farmer, and Sebastian
on1)
Schmon. Black-boxbayesianinferenceforeconomicagent-
based models. arXiv preprint arXiv:2202.00625, 2022. Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The
(Citedon2) concretedistribution: Acontinuousrelaxationofdiscrete
randomvariables. InInternationalConferenceonLearning
GiorgioFagiolo,MattiaGuerini,FrancescoLamperti,Alessio
Representations,2016. (Citedon3)
Moneta,andAndreaRoventini. Validationofagent-based
modelsineconomicsandfinance. InComputersimulation Corrado Monti, Gianmarco De Francisci Morales, and
validation,pages763–787.Springer,2019. (Citedon1) FrancescoBonchi. Learningopiniondynamicsfromsocial
traces. InProceedingsofthe26thACMSIGKDDInterna-
Andreas Flache, Michael Ma¨s, Thomas Feliciani, Edmund
tionalConferenceonKnowledgeDiscovery&DataMining,
Chattoe-Brown,GuillaumeDeffuant,SylvieHuet,andJan
pages764–773,2020. (Citedon2,4,7)
Lorenz.ModelsofSocialInfluence:TowardstheNextFron-
tiers. JournalofArtificialSocietiesandSocialSimulation, Corrado Monti, Marco Pangallo, Gianmarco De Francisci
20(4):2,2017. (Citedon1) Morales,andFrancescoBonchi. Onlearningagent-basedmodelsfromdata. arXivpreprintarXiv:2205.05052,2022.
(Citedon2,7)
DimitarNikolov,AlessandroFlammini,andFilippoMenczer.
Rightandleft,partisanshippredicts(asymmetric)vulnera-
bilitytomisinformation. HarvardKennedySchoolMisin-
formationReview,2021. doi: 10.37016/mr-2020-55. URL
https://misinforeview.hks.harvard.edu/?p=5702. (Citedon
7)
George Papamakarios, Eric Nalisnick, Danilo Jimenez
Rezende,ShakirMohamed,andBalajiLakshminarayanan.
Normalizingflowsforprobabilisticmodelingandinference.
TheJournalofMachineLearningResearch, 22(1):2617–
2680,2021. (Citedon3)
DonovanPlatt. Acomparisonofeconomicagent-basedmodel
calibrationmethods. JournalofEconomicDynamicsand
Control,113:103859,2020. (Citedon1)
Anton V Proskurnikov, Alexey S Matveev, and Ming Cao.
Opiniondynamicsinsocialnetworkswithhostilecamps:
Consensus vs. polarization. IEEE Transactions on Auto-
maticControl,61(6):1524–1536,2015. (Citedon7)
Arnau Quera-Bofarull, Ayush Chopra, Anisoara Calinescu,
Michael Wooldridge, and Joel Dyer. Bayesian calibra-
tionofdifferentiableagent-basedmodels. arXivpreprint
arXiv:2305.15340,2023. (Citedon2)
DaniloRezendeandShakirMohamed. Variationalinference
with normalizing flows. In International conference on
machinelearning,pages1530–1538.PMLR,2015. (Cited
on3)
PatriciaTernes,JonathanAWard,AlisonHeppenstall,Vijay
Kumar,Le-MinhKieu,andNickMalleson. Dataassimila-
tionandagent-basedmodelling: towardstheincorporation
ofcategoricalagentparameters. OpenResearchEurope,1:
131,2022. (Citedon2)
Petter To¨rnberg. Echo chambers and viral misinformation:
Modeling fake news as complex contagion. PLOS ONE,
13(9):e0203958,September2018. ISSN1932-6203. doi:
10.1371/journal.pone.0203958. URLhttps://dx.plos.org/10.
1371/journal.pone.0203958. (Citedon7)
SandervanderHoog. Surrogatemodellingin(andof)agent-
basedmodels: Aprospectus. ComputationalEconomics,
53(3):1245–1263,2019. (Citedon7)
Ge´rardWeisbuch,GuillaumeDeffuant,Fre´de´ricAmblard,and
Jean-PierreNadal. Meet,discuss,andsegregate! Complex-
ity,7(3):55–63,2002. (Citedon2,3)
WeiZhang,AndreaValencia,andNi-BinChang. Synergis-
ticintegrationbetweenmachinelearningandagent-based
modeling: Amultidisciplinaryreview. IEEETransactions
onNeuralNetworksandLearningSystems,2021. (Cited
on7)