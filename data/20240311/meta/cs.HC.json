[
    {
        "title": "Enabling Developers, Protecting Users: Investigating Harassment and Safety in VR",
        "authors": "Abhinaya S. B.Aafaq SabirAnupam Das",
        "links": "http://arxiv.org/abs/2403.05499v1",
        "entry_id": "http://arxiv.org/abs/2403.05499v1",
        "pdf_url": "http://arxiv.org/pdf/2403.05499v1",
        "summary": "Virtual Reality (VR) has witnessed a rising issue of harassment, prompting\nthe integration of safety controls like muting and blocking in VR applications.\nHowever, the lack of standardized safety measures across VR applications\nhinders their universal effectiveness, especially across contexts like\nsocializing, gaming, and streaming. While prior research has studied safety\ncontrols in social VR applications, our user study (n = 27) takes a\nmulti-perspective approach, examining both users' perceptions of safety control\nusability and effectiveness as well as the challenges that developers face in\ndesigning and deploying VR safety controls. We identify challenges VR users\nface while employing safety controls, such as finding users in crowded virtual\nspaces to block them. VR users also find controls ineffective in addressing\nharassment; for instance, they fail to eliminate the harassers' presence from\nthe environment. Further, VR users find the current methods of submitting\nevidence for reports time-consuming and cumbersome. Improvements desired by\nusers include live moderation and behavior tracking across VR apps; however,\ndevelopers cite technological, financial, and legal obstacles to implementing\nsuch solutions, often due to a lack of awareness and high development costs. We\nemphasize the importance of establishing technical and legal guidelines to\nenhance user safety in virtual environments.",
        "updated": "2024-03-08 18:15:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.05499v1"
    },
    {
        "title": "Comparison of Spatial Visualization Techniques for Radiation in Augmented Reality",
        "authors": "Fintan McGeeRoderick McCallJoan Baixauli",
        "links": "http://dx.doi.org/10.1145/3613904.3642646",
        "entry_id": "http://arxiv.org/abs/2403.05403v1",
        "pdf_url": "http://arxiv.org/pdf/2403.05403v1",
        "summary": "Augmented Reality (AR) provides a safe and low-cost option for hazardous\nsafety training that allows for the visualization of aspects that may be\ninvisible, such as radiation. Effectively visually communicating such threats\nin the environment around the user is not straightforward. This work describes\nvisually encoding radiation using the spatial awareness mesh of an AR Head\nMounted Display. We leverage the AR device's GPUs to develop a real time\nsolution that accumulates multiple dynamic sources and uses stencils to prevent\nan environment being over saturated with a visualization, as well as supporting\nthe encoding of direction explicitly in the visualization. We perform a user\nstudy (25 participants) of different visualizations and obtain user feedback.\nResults show that there are complex interactions and while no visual\nrepresentation was statistically superior or inferior, user opinions vary\nwidely. We also discuss the evaluation approaches and provide recommendations.",
        "updated": "2024-03-08 15:59:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.05403v1"
    },
    {
        "title": "WatChat: Explaining perplexing programs by debugging mental models",
        "authors": "Kartik ChandraTzu-Mao LiRachit NigamJoshua TenenbaumJonathan Ragan-Kelley",
        "links": "http://arxiv.org/abs/2403.05334v1",
        "entry_id": "http://arxiv.org/abs/2403.05334v1",
        "pdf_url": "http://arxiv.org/pdf/2403.05334v1",
        "summary": "Often, a good explanation for a program's unexpected behavior is a bug in the\nprogrammer's code. But sometimes, an even better explanation is a bug in the\nprogrammer's mental model of the language they are using. Instead of merely\ndebugging our current code (\"giving the programmer a fish\"), what if our tools\ncould directly debug our mental models (\"teaching the programmer to fish\")? In\nthis paper, we apply ideas from computational cognitive science to do exactly\nthat. Given a perplexing program, we use program synthesis techniques to\nautomatically infer potential misconceptions that might cause the user to be\nsurprised by the program's behavior. By analyzing these misconceptions, we\nprovide succinct, useful explanations of the program's behavior. Our methods\ncan even be inverted to synthesize pedagogical example programs for diagnosing\nand correcting misconceptions in students.",
        "updated": "2024-03-08 14:10:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.05334v1"
    },
    {
        "title": "Direction of slip modulates the perception of slip distance and slip speed",
        "authors": "Ayesha Tooba KhanDeepak JoshiBiswarup Mukherjee",
        "links": "http://arxiv.org/abs/2403.05316v1",
        "entry_id": "http://arxiv.org/abs/2403.05316v1",
        "pdf_url": "http://arxiv.org/pdf/2403.05316v1",
        "summary": "Purpose: The purpose of this study was to investigate the psychophysical\nunderstanding of the slip stimulus. We emphasized that the perception of slip\nand its characteristics, such as slip distance and slip speed depend on the\ninteraction between slip direction, slip distance as well as slip speed.\nMethods: We developed a novel slip induction device to simulate the artificial\nsense of slip. We conducted a psychophysical experiment on eight healthy\nsubjects. The experiment was designed to evaluate the effect of slip direction\non slip perception as well as on the perception of slip distance and slip\nspeed. A series of psychophysical questions were asked at the end of the slip\nstimulation to record the subjective responses of the participants. The average\nsuccess rate (%) was used to quantify the subject responses. Results: We\ndemonstrated that the perception of slip is independent of slip direction\nhowever, perception of slip distance and slip speed are significantly modulated\nby slip direction. We also observed that a significant interaction exists\nbetween slip distance and slip speed in the upward slip direction. It was also\nobserved that the average success rate was significantly different for various\ncombinations of slip distance and slip speed in the upward slip direction.\nConclusions: Our study clearly establishes a significant interaction between\nthe slip direction, slip distance, and slip speed for psychophysical\nunderstanding of the perception of slip distance and slip speed.",
        "updated": "2024-03-08 13:47:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.05316v1"
    },
    {
        "title": "Sparse Wearable Sonomyography Sensor-based Proprioceptive Proportional Control Across Multiple Gestures",
        "authors": "Anne Tryphosa KamathamKavita SharmaSrikumar VenkataramanBiswarup Mukherjee",
        "links": "http://arxiv.org/abs/2403.05308v1",
        "entry_id": "http://arxiv.org/abs/2403.05308v1",
        "pdf_url": "http://arxiv.org/pdf/2403.05308v1",
        "summary": "Sonomyography (SMG) is a non-invasive technique that uses ultrasound imaging\nto detect the dynamic activity of muscles. Wearable SMG systems have recently\ngained popularity due to their potential as human-computer interfaces for their\nsuperior performance compared to conventional methods. This paper demonstrates\nreal-time positional proportional control of multiple gestures using a\nmultiplexed 8-channel wearable SMG system. The amplitude-mode ultrasound\nsignals from the SMG system were utilized to detect muscle activity from the\nforearm of 8 healthy individuals. The derived signals were used to control the\non-screen movement of the cursor. A target achievement task was performed to\nanalyze the performance of our SMG-based human-machine interface. Our wearable\nSMG system provided accurate, stable, and intuitive control in real-time by\nachieving an average success rate greater than 80% with all gestures.\nFurthermore, the wearable SMG system's abilities to detect volitional movement\nand decode movement kinematic information from SMG trajectories using standard\nperformance metrics were evaluated. Our results provide insights to validate\nSMG as an intuitive human-machine interface.",
        "updated": "2024-03-08 13:38:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.05308v1"
    }
]