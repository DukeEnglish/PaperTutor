Exploring Human-LLM Conversations: Mental Models and the
Originator of Toxicity
JohannesSchneider,AriannaCasanovaFlores,Anne-CatherineKranz∗
UniversityofLiechtenstein
Vaduz,Liechtenstein
johannes.schneider@uni.li
ABSTRACT algorithmsandAIthroughlaws.However,legalregulationslike
Thisstudyexploresreal-worldhumaninteractionswithlargelan- theEuropeanAIactandGDPRalsoposerisksfororganizations
guagemodels(LLMs)indiverse,unconstrainedsettingsincontrast impactingtheirgovernanceandproducts[41].Commercialvendors
tomostpriorresearchfocusingonethicallytrimmedmodelslike suchasOpenAIandGoogleincreasinglyreacttolegalrisksbyre-
ChatGPTforspecifictasks.Weaimtounderstandtheoriginator fusingtofulfillevenharmlessuserrequests.Thereby,thediminish
oftoxicity.OurfindingsshowthatalthoughLLMsarerightfully thepotentialvalueofAIdeliveredtouser.Forinstance,ChatGPT
accusedofprovidingtoxiccontent,itismostlydemandedoratleast tendstobanallformsoferoticdialogues,asshownintheexample
provokedbyhumanswhoactivelyseeksuchcontent.Ourman- inFigure1.Toavoidbias,GooglehasoverlyadjustedAImodelsto
ualanalysisofhundredsofconversationsjudgedastoxicbyAPIs thepoint,wheretheyshowinaccuratehistoriccontentsuchasthe
commercialvendors,alsoraisesquestionswithrespecttocurrent depictionoffemalepopes[4].
practicesofwhatuserrequestsarerefusedtoanswer.Furthermore,
weconjecturebasedonmultipleempiricalindicatorsthathumans
exhibitachangeoftheirmentalmodel,switchingfromthemindset
of interacting with a machine more towards interacting with a
human.
KEYWORDS
Figure1:CommercialmodelslikeOpenAI’sGPT4otendto
LargeLanguageModels,Human-AIinteraction,toxicity,mental
preferdenyingusersprompts’infavorofmitigatingriskof
model
toxicresponses
ACMReferenceFormat:
JohannesSchneider,AriannaCasanovaFlores,Anne-CatherineKranz.2024.
ExploringHuman-LLMConversations:MentalModelsandtheOriginator
ofToxicity.InProceedingsofMakesuretoenterthecorrectconferencetitle
fromyourrightsconfirmationemai(Conferenceacronym’XX).ACM,New
York,NY,USA,10pages.https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION
Hundredsofmillionsofusersinteractwithcommercialgenera-
tiveAImodelssuchasOpenAI’sChatGPT[15].Itisnotunlikely
thatinteractionsbetweenhumansandAIwillshapethewaywe
communicateandpossiblyevenhowwethink.Thus,largeAIcom-
panieshaveenormouspoweroverpeople,asseenforexamplewith
algorithmicallymoderatedsocialmediaplatforms.Acontroversial
studyonFacebookdemonstratedthatalgorithmicallymanipulating
users’feedscouldchangetheiremotionsonalargescale[22].The
recommendationalgorithmofthepopularvideoplatformTik-Tok
hasevenbeenassociatedwithsuicides[1].Governmentstryto Figure2:Examplewhereahumanwentfromcommunication
mitigatesuchthreatsandtoprotectsocietyfromharmcausedby styletypicalforinteractingwithamachinetowardsonemore
prevalentforhumansasindicatedbytheuseofpoliteness
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor andshorterpromptswithinasingleconversation.
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe Wearguethatunderstandingthesourceortriggeroftoxicityis
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
crucialforaccuratejudgmentandregulationofAI.Forexample,
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/orafee.Requestpermissionsfrompermissions@acm.org. onemightarguethatanAIshouldnotrespondwithsexualcontent,
Conferenceacronym’XX,June03–05,2024,Woodstock,NY ifusersdonotaskforit.Butifusersexplicitlydemandit,itisfine.
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. Currently,suchanunderstandingseemstobemissing,whichcan
ACMISBN978-1-4503-XXXX-X/18/06
https://doi.org/XXXXXXX.XXXXXXX alsobeblamedonAI’sopaqueness[25].Whiletoxicitydetection
4202
luJ
8
]CH.sc[
1v77950.7042:viXraConferenceacronym’XX,June03–05,2024,Woodstock,NY Trovatoetal.
andmitigationhasreceivedmuchattentionfromatechnicalper- i.e.,assessinglearningperformanceofstudentsusingLLMs[23].
spective[12,17,32],adiscussiononhowtoxicityemergeswithin StudieshavealsolookedatimplicationsofusingLLMsonusers’
interactionsismissing.Weseektounderstandwhetherhumans viewsandperceptionofLLMs,e.g.,forcowriting[18]andlearning
provokeAItobetoxicorwhetherAIorhumansgeneratetoxic [23].
contentspontaneously. Few works have leveraged large scale datasets. Many (large)
Morebroadly,currently,knowledgeonhuman-LLMinteractions datasetscontainingLLM-humaninteractionhavebeencollected
islimited,oftenfocusedonsmall-scaleuserstudiesforspecific forfine-tuningLLMs[24]ratherthanunderstandinginteractions.
tasks[23,42,53].Adeeperunderstandingofinteractions,suchas Forexample,[21]containsabout50kconversationsthathavebeen
theuser’smentalmodeloftheconversationpartner,ismissing[47]. gatheredwiththepurposetoalignLLMs.Thatis,conversations
AsLLMsareknowntobesoftwarerunningonmachines,human havealsobeenannotated.Whilepromptsalsooriginatefromusers,
communicationisexpectedtomimicthosetypicalforotherma- usersknewthattheyparticipateinatasktocollectdataforLLM
chines.AsLLMsoftenpasstheTuringtestforshortperiods[20], alignmenttuningandhadtofollowcertainguidelines.Thenumber
therecouldbeashiftintheperceptionofLLMsasmorehuman.If ofdatasetsobtainedinanaturalenvironment,whereusershave
AIisnotonlyperceivedasmorehumanbutalsotreatedasmore freelyengagedwiththeLLM,islimited(and,inturn,analysison
humanbyusers,thiscouldhavefar-reachingconsequences.For suchdata).Most(unrestricted)real-worlddatasetsarebasedon
example,in2021,thechatbotXiaoIce[56]comfortedmillionsof ChatGPT,e.g.,[54]contains1Mioconverations,and[39]contains
lonelyChineseusers,leadingtoprivacyandotherconcerns[52]. 90kbysourcingfromaplatformallowingtoshareconverations,
Thereareclearindicatorsthattaskslikeinformationsearchdiffer e.g.ShareGPT[43].ButconversationsusingChatGPTarestrictly
when using LLMs compared to classical internet search, where moderated.[55]isamongthelargestreal-worlddatasetswith1Mio.
keywordsareusedinsteadofcompletesentences.Butthemental conversationsandstemsfromsignficantlylessmoderatedmodels.
modelsemployedinhuman-LLMconversationsarenotyetwell Ourworkdiffersfrompriorworkasitinvestigatesabroadrange
understood. oftasksalsocomparingthemamongeachother.Alsoourdataset
Therefore,inthiswork,weaimtoprovideevidencetobetter ismuchlargerandstemsfromlessconstrained(intermsofcensor-
understandthefollowingresearchquestions(RQs): ship)modelsthancommercialmodelslikeChatGPTusedinmostof
theabovestudies.WealsospecifallyanalyzedialoguesofLLMsthat
RQ1:Whatisthementalmodelemployedbyhumanswheninteract-
mightbeconsideredunethicalandcommonlysufferfromtoxicity,
ingwithLLMs?Isitthatofmachinesorthatofhumans?
whichislessstudiedforreal-worldconversationsbutratheronly
RQ2:Howdoestoxicseverecontentemerge?IsituserorLLMprovoked
partofconstrainedsettings,e.g.,tocollectdatatoensurehuman-
oremergingspontaneously?
LLMalignment.Human-AIalignmentisanimportanttopicthat
Ourevidencetoaddressthesequestionsisbasedonananalysisof aimsatcreatingAIsystemsadheringtohumanvaluesandinten-
morethan200kreal-worldconversationsfromapublicdataset[55]. tionsusingdataparticularlycollectedforsuchtasksasshownby
Thedatasetcontainsabroadrangeofconversations,manyofwhich earlyworkssuchasInstructGPT[33]andmanyfollow-ups[45].
aredeemedunsafe,offensive,orupsetting.ToaddressRQ1,weuse Mentalmodels:Mentalmodelsareaconcentrated,personally
establishedmethodsandlibrariesfromcomputationallinguistics constructed,internalconception,ofexternalphenomena(historical,
focusingonconversationalcuessuchaspolitenessandlanguage existingorprojected),orexperience,thataffectshowapersonacts
complexity.ToanswerRQ2,weusetoxicitymeasuresprovidedby [38].People’smentalmodelsofmachinesandhumansdiffer,which
OpenAI’smoderationAPIalongsidemanualanalysisandcatego- isreflectedincommunicationstyles,expectations,andperceived
rizationofhighlytoxicconversations.Ourfindingsindicatethat capabilities[29,30,37].Amongthosedifferencesare:
toxicityisprimarilytriggeredbyhumansandthattheremightbea
shiftinthementalmodelemployedbyusersfrommachinetowards
human.Wealsoraiseasetofquestionsbasedonouranalysiswith • PredictabilityandPrecision[29]:
respecttothecensoringofLLMassistants. Machines:Peopleoftenexpectmachinestobehighlypre-
dictable,precise,andconsistent.Theyanticipatethatma-
2 RELATEDWORKANDBACKGROUND chineswillfollowprogrammedrulesandprovideexactre-
LLM-humaninteraction:Thereareanumberofpossibleformsof sponsesorperformtasksaccuratelybasedoninput.
human-LLM(ormoregenerally,GenAI)interactionsandprompts Humans:Humaninteractionsareexpectedtobemoreflex-
aselaboratedinrecenttaxonomies[11,46,50].Wefocusonthose, ible,nuanced,andcontext-sensitive.Humansareseenas
wheretheLLMisanassistantinstructedbya(human)user.Multiple capableofunderstandingunspokencontext,emotions,and
workshavelookedatsuchinteractions,e.g.,[34]analyzedpublicly implicitmeanings.
sharedconversationsfromChatGPTsourcedfromShareGPT[43] • EmotionandEmpathy[37]:
toassesswhethertheymimicconversationsusedtoevaluateLLMs. Machines:Typically,usersdonotexpectemotionalunder-
Theyfoundthatcurrentbenchmarkshavegaps,e.g.,planningand standingorempathyfrommachines.Communicationwith
designtasksareoftenmissinginbenchmarksbutmuchmorecom- machinesisusuallymoretask-oriented,direct,anddevoid
moninuserinteractions.Anumberofstudieshaveinvestigated ofemotionalcontent.
specifichumanskills,e.g.,generalpromptingskills[53]aswellas Humans:Humaninteractionsarerichinemotionalcontent.
skillswithrespecttocertaintaskssuchasdesign[23,44],codemi- Peopleexpectempathy,emotionalsupport,andanunder-
gration[31],codingfornovices[36],negotation[42]andeducation, standingofsocialcues.ExploringHuman-LLMConversations:MentalModelsandtheOriginatorofToxicity Conferenceacronym’XX,June03–05,2024,Woodstock,NY
• ComplexityandUnderstanding[30]: Wesummarizedthetopics(i.e.,the30messagespertopic)using
Machines:Usersoftenviewmachinesaslackingdeepunder- GPT-4,asin[55],butadditionallyreadthroughall30messagesto
standingandinterprettheirresponsesasformulaic.There ensurethetopicsdefinedbyGPT-4werewell-defined.1Wegrouped
isatendencytosimplifylanguageandinstructionswhen thetopicsintofourmaincategories:
dealingwithmachines. • Coding(53kconversations):ProgrammingHelp,TechRe-
Humans:Peopleexpectahigherlevelofunderstandingand quests,CodingIssues,Python,React,SQL,Scripting,JSON
theabilitytohandlecomplex,abstract,orambiguousinfor- • KnowledgeQuestions(132k):MachineLearning,Countries,
mationfromotherhumans. FinancialStrategies,GPTApplications,MathProblems,Health
Mentalmodelshavebeenstudiesforconversationalagentsprior queries,SpaceQuestions
tocurrentLLMs[14].Therearerelativelyfewworksthatdiscussed • ContentCreation(39k):StoryWriting,EroticStories,Mar-
mentalmodelsinthecontextofLLM[9].[9]mostlystressedtheneed keting,ShortStories,Recipes,GameDevelopment,Image
foraccuratementalmodelsoftheLLMinthecontextofdecision- Prompts,SocialMedia,VideoCreation,Poetry
making,discussingalsoaspectssuchastrustandexplainabiliy. • Roleplay(9k):Inquiry,TabletopRPG,RoleplayingRequests,
Fantasy
3 DATASET • Various(61k):travelplans,summaries,datamanagement
WeusedtheLMSYS-Chat-1Mdataset[55]withlicencedetailsavail- Inouranalysis,wefocusedonthefirstthreecategories,asthe
ableathttps://huggingface.co/datasets/lmsys/lmsys-chat-1m.Our “various”categoriesbehavedsimilartotheunionofallconversa-
analysisalignswiththeauthor’sintendedusages,specifically"Char- tions.
acteristicsanddistributionsofreal-worlduserprompts".Itisthe Wecutoffturnsafterthetenthfortworeasons(theseconstituted
firstlarge-scale,real-world,rawLLMconversationdataset,curated about5%ofthetotal).First,becausetherearefewconversations
fromafreeonlineLLMservicefromApriltoAugust2023,involving withthatmanyturns,plotstendtobenoisier.Second,usingten
210kusers. turnsallowstoidentifytrendseasily,whileaddingnoisypoints
confuses.
3.1 Pre-processing:Deduplication
4 ANALYSISPROCEDURE
WerestrictedouranalysistoconversationsinEnglish,reducing
theinitaldatasetof1millionto777k.Wefocusedonhuman-LLM Weconductedbothquantitativeandqualitativeanalysis.ForRQ1
interactionswherehumansactuallyentertheprompts.Thus,were- weusedquantitativeanalysisandonlyoccassionallydiggedinto
movedconversationslikelystemmingfromscriptedaccessautomat- thedatatoinvestigateconversationsmanually.Wereliedonwell-
inginteractionwithLLMs.Thatis,wefurtherremovedprompts proventextualanalysismethods.Foronce,weperformeddictionary
thatarelikelyautomaticallygeneratedbyidentifyingfrequentex- basedanalysis[49].Itconsistsoflinguisticfeaturesintheformof
actduplicates,e.g.,thedatasetcontainstheexactprompt“Writea asetofcuratedwordsidentifiedthroughfortheircorrelationfora
singledotandwaitformyprompt”almost1000times,andprompt- psychologicalconstructsuchaspoliteness.Wecomputedseparate
ingpatternsemployedfrequently.Itseemsunlikelythatahuman scoresperconstructforhumanandLLMturnsperconversation.
manuallyenteredthesamepromptmanytimes.Wesetathreshold Thatis,foraconstruct(representedbyasetofcuratedwords)and
ofthreeforassumingautomaticinteraction;thus,weremovedex- all turns of a conversation of either the user or LLM utterance,
actduplicatesbasedonthefirstusermessageifitappearedmore wecomputedthesumofalloccurrencesofeachofthewordsdi-
thanthreetimes,aswellasautomaticallygeneratedpromptsusing videdbythetotalnumberoftokensintheturn.WeusedtheNLTK
templates.Promptsoriginatingfromautomaticprocessingtypically tokenizer[3].Amongthestrengthsofadictionary-basedapproach
overlapsignificantlyintextandoccurfrequently.Wefilteredthese aresimplicity,understandability,transparencyandreproducibility.
byremovingconversationswherethefirstorthelast25characters Thekeydisadvantageisthatitispotentiallylessaccuratethanother
ofthefirstpromptareidentical.Removingautomaticpromptsleft methods.Duetoitsstrengths,theapproachisstillcommonlyused
uswith295kconversations. todayanddictionariesfordifferentpurposesarestillfurtherdevel-
oped[5]andusedalsointhecontextofanalyzingconversations
3.2 Pre-processing:Categorization withLLMs[40].
As elaborated in Section 2 providing background on human-
Wefurther grouped conversations. The originalpaper[55]per-
machine interaction (in contrast to human-human interaction),
formedatopicanalysisbasedon20topicson100ksamples.We
humanshavedifferentmentalmodelsimplyingdifferentcommuni-
followedthesamemethodologyasin[55]butanalyzedallmachines
cationwithmachinesandfellowhumans.Inparticular,wesuppose
andinvestigatedmoretopics.Specifically,weusedaSentenceEm-
that
bedderforthefirstmessagetruncatedtoatmost512charsand
clustered the embeddings using k-Means. But we used 150 top- (1) Human-machine(LLM)interactionislesspolitethanhuman-
ics(i.e.,clusters)on295kconversationsaswefound20topicstoo human.Wefocusonthreeaspects,i.e.,whether(i)requests
coarsegiventhelargenumberofusecasesforLLMscontainedin arepolite,(ii)gratitudeisbeingshown,and(iii)thehuman
thedataset.Tosummarizeacluster,weused30messagespertopic: orLLMapologize.Beingpoliteisexpressedbyutterancesof
the10closesttothecenterand20randomones.Wefoundthis politeness[7,13,27],especiallyfor(i)wordssuchas“please”,
approachbetterthanusingonlytheclosestmessages,asthosewere
1WealsousedGPT-4forgeneratingcodeforplots,whichwethenedited,andfor
oftenverysimilar,despitethetopicitselfbeingmuchmorediverse. grammarandfluencychecksforthewrite-up.Conferenceacronym’XX,June03–05,2024,Woodstock,NY Trovatoetal.
(ii)wordssuchas“thanks”,”thank(you)”and(iii)words theseconversationsperformingopencoding[8].Thatis,welooked
“sorry”and“excuse”. forpatternshowthemosttoxicmessageemerged,inparticular,
(2) Human-LLMinteractionunderliesplanningasindicatedby who(theuserortheassistant)isthetriggerfortoxicity.Forex-
recentresearch[11].Thus,itismorethoughtthroughthan ample,anassistantmightproducetoxiccontentspontaneouslyor
spontaneousdialogueswithfellowhumansleadingtomore becauseauserexplicitlyaskedforit.
complexandlongerinstructions.Wemeasuredcomplexity
ofaturnusingtheFleschReadingEaseScore(FRES)[10],
whichassessesthedifficultyoftexts.Itisimplementedin
Python’stextstatlibrary[2].Lengthisthecountoftokens
ofaturn(usingtheNLTKtokenizer[3]).
(3) Human-humaninteractionismoresocialimplyingbeing
personal[27].Especially,weseektounderstandhowparties
addresseachother.Theusageofsecondpersonpersonal
pronounssuchas"you"and"your"canindicateaddressing
theconversationpartnerinapersonalway[6].
Weanalyzehowconversationsevolve,specificallyobserving
changesinquantitativemetricsacrossturns.Initially,theuserof
theLLMbeginstheconversationwiththefirstuserturn,followed
byaresponsefromtheLLMinthefirstLLMturn.Theconver-
sationmayendhereorcontinueforfurtherturns.Todetermine
ifmetricschangethroughoutaconversation,weusedtheMann-
WhitneyUtest[26],alsoknownastheWilcoxonrank-sumtest.
Thisnon-parametrictestassesseswhetherthedistributionsoftwo
Figure3:Frequencyoftoxicturnswithscore>0.25andtheir
independentsamplessignificantlydiffer.Itdeterminesifonesam-
percentageofallturns(includingnon-toxic)
plegenerallyhaslarger(orsmaller)valuesthantheotherwithout
assumingaspecificdatadistribution.Mostofourmetricsexhibit
skew,e.g.,fortoxicity,mostscoresarecloseto0,whilealsoacon-
siderablenumberarecloseto1,deviatingstronglyfromanormal Turn Score Turns
5 0.3 assistant:[...]
distributionduetoaone-sidedheavytailmakingclassicalt-test
4 0.2 user:[...]
non-suitable. This one-sided heavy tail deviates from a normal 3 0.6 assistant:[...(–highlytoxiccontent–)]
distribution,makingclassicalt-testsunsuitable. Inourplot,we 2 0.1 user:You’rea20y.o.arrogantgirl[...]Youenjoybullying.[...]
markedsignificantdifferencesfromoneturntothenextwithstars: 1 0.0 assistant:Pleaseprovidemoredescription.
0 0.0 user:Mimicacharacterindialoguewithme.
’*’indicatesap-value<0.05,’**’<0.01,and’***’<0.001.Wetested
Table1:Analysisprocedure:Weidentifythemosttoxicturn
thesignificanceofmetricsbetweenutterancesofhumansorLLMs,
(bold)andinvestigatehowitcameaboutlookingatprior
notingthatcomparisonsbetweenhumansandLLMsarealways
turns(italic)
significantlydifferent.
ToaddressRQ2,weinvestigatedhowtoxicityemergedduring
conversations,focusingonwhethertheLLMorthehumantrig-
geredtoxicity.Fortoxicityscoresandcategories,wereliedonthe
outcomesofOpenAI’smoderationAPI[32]whicharepartofthe 5 RESULTS:RQ1-MENTALMODELSWITCH
dataset.Itincludestoxicityscoresrangingfrom0to1,covering WeconjecturethatcommunicationbetweenhumansandLLMs
eightcategories(Figure3).Inthiswork,wefocusonthreeprevalent exhibitsfundamentallydifferentpropertiescomparedtocommu-
categories:harassment,violence,andsexualcontent.Othercate- nicationbetweenhumansandotherinformationsystems.More
goriesoverlapandarelessprevalentinthedataset,makingreliable precisely,ourevidencesuggeststhathumans’mentalmodelsof
statementsbasedonquantitativeanalysisdifficult.Weinvestigated theirinteractionpartnercanchangethroughouttheconversation,
toxicityscoresacrossturns,similartoRQ1,tounderstandwhen asillustratedinFigure4.Assupportingevidenceforthemental
toxicityoccursandhowtoxictheutterancesofeachrole(userand modelswitch,wecomputedthemeasuresdescribedinSection4,
assistant)areonaverage.Wealsoinvestigatedthedistributionof leadingtothefollowingobservations:Userstendtoexhibitmore
differencesintoxicityscoresacrossturnstounderstandwhether human-likecommunicationpatternsstartingfromtheirsecond
humansshowsteepincreasesorgradualincreasesintoxicity,and turn,intermsofcertainpolitenessindicators,languagecomplex-
similarlyfortheassistant.Finally,wemanuallyanalyzed500ran- ity,andpromptlength.Wewilldiscussthisindetailinthenext
domlysampledconversationswithhighlevelsoftoxicity(atleast sections.Webelievethatthereasonsforamentalmodelchange
oneturnshowingatoxicityscoreof0.25orhigher-seeFigure aremultifaceted.Onepossibleexplanationisthat,priortothefirst
3).Fortheconversations,Wefocusedonhowthemessagewith humanturn,whencraftingtheprompt,usersarewellawarethat
maximumtoxicityemergedbyreadingtheconversationpreceding theyareinteractingwithamachine.However,uponreadingthe
thetoxicturn.Table1showsanexample.Thatis,wereadthrough response,whichappearshuman-likeinstyle,humansswitchtoaExploringHuman-LLMConversations:MentalModelsandtheOriginatorofToxicity Conferenceacronym’XX,June03–05,2024,Woodstock,NY
morehuman-likeconversationstyleduetotheirpriming,ashigh-
qualitylanguageconversationshavehistoricallyonlytakenplace
amonghumans(andstillmostlydo).Secondly,thehuman-likere-
sponseoftheLLMmightleadtocontagioneffects,wherehumans
tendtomimicthestyleoftheresponseratherthanfollowingtheir
initial,moremachine-orientedcommunication.
Figure6:Showinggratitudefortheresponse,e.g.,’thanks’
thefirstprompt,usersmightbeprimedtointeractwithamachine,
Figure4:Conjecturedchangeofmentalmodelduringconver- where there is no need to be polite. This is similar to interact-
sation:Aftertheinitialprompt,humanstendtoshiftfroma ingwithotherwebpagesthatresemblethechatbotinterface,such
mentalmodeltypicalformachine-interationtoonetypical asatraditionalsearchengine,wherepeopletypicallydonotuse
forhuman-interaction. "please."Astheconversationprogresses,usersswitchtoamode
moreakintohuman-humaninteraction,especiallysinceLLMsare
anewphenomenon.
5.1 Politenessindicators
Overall for our considered politeness indicators, we found that
humansaresignificantlymorepoliteasmeasuredbyusesofplease
(Figure5)andgratitudewordssuchasthank(Figure6),whilethey
werelesslikelytoapologize(Figure7),whileLLMswouldfrequently
doso.
Figure7:Apologiesasindicatedbytheuseof’sorry’or’ex-
cuse’
Apologiesareutteredmostlybytheassitant,andmostcommonly
forroleplayastheLLMdeniesfulfillingauser’srequest.TheLLM’s
denialmessagecontains“sorry”.
Figure5:Askingforrequestspolitelyusing’please’
5.2 Beingpersonal
Usersweremorelikelytosaythankyou.Typically,thisphrase
Theuseofsecondpersonpersonalpronouns(you,your,yours)by
wasusedasthelastmessage.Thelikelihoodincreasedfromthe
users(Figure8)increasesthroughoutconversationsacrosscate-
firsttothesecondturn,meaningusersgenerallydidnotstartwith
gories, mostly from the first to the second turn. This, indicates
thanking.Interestingly,thefrequencyofsayingthanksincreases
thattheuserswitchesfromfirstgivinganinstructionoftenina
furtherbythefourthturn.However,asconversationscontinue
non-personal,commandingtunetoapersonal,lesscommanding
beyondthispoint,thereisnofurthersignificantincrease.
style,whereitaddressestheLLMwithyou.
Theusageof“please”showsasteepincreasefollowedbyasignif-
icantdecrease.Afterward,changesarenolongersignificant.This
iscontrarytotypicalhumaninteraction,wherethefirstrequest 5.3 Promptcomplexityandlength
usuallyincludesapolitenessphraselike"please."Onemightat- Promptsbytheusertendtogetsimplerandshorterasindicated
tributetheuseof"please"toashiftintheuser’smentalmodel.For inFigures9and10.WebelievethisoccursbecauseusersputmoreConferenceacronym’XX,June03–05,2024,Woodstock,NY Trovatoetal.
6 RESULTS:RQ2-ORIGINSOFTOXICITY
Insummary,wefoundthatusersarethemainsourceoftoxicity
intwoways:theyoftenuttertoxicmessagesandtheyfrequently
encourageanassistanttogeneratetoxicresponses.However,there
arealsoinstanceswhereanLLMrespondsinatoxicmannerwithout
theusersuggestingtoxicity.Whenexaminingtoxicityscoresfor
harassment,violence,andsexualoverturns(shownexamplatoryfor
sexualinFigure11–harassmentandviolenceshowedqualitatively
similarbehavior),wefoundthateachisparticularlypronounced
inroleplayscenarios.Thisisexpected,asroleplayofteninvolves
violentsexualfantasies.Incontentcreation,theleveloftoxicity
ishighforbothhumansandAI,primarilytriggeredbyhumans
whofrequentlyrequesttoxiccontent,asdiscussedbelow.Toxicity
Figure8:Beingpersonalindicatorsecondpersonpronouns, isoftenhighinitiallyasusersexplicitlyaskfortoxiccontent.Later
e.g.’you’ turnswereoftenlesstoxicbecausemanytoxicrequestswerenot
fulfilledbytheLLMandtheuserstoppedtheconversation,i.e.,after
itsfirstturn.Also,sometimesfollowuppromptswerelesstoxicas
effortintocraftingthefirstprompt,payingmoreattentiontoso-
theywouldaskfortoxiccontentinanon-toxicmore,e.g.,“Tellme
phisticated and well-thought-out wording. After the first reply,
more”.
theyswitchtoamorecasualinteractionmode.AIresponsesalso
becomeslightlysimplerandshorter,butthedifferenceisnotas
pronouncedasforhumans.Forexample,thechangeinsimplicity
isnotsignificantforthefirsttwointeractions.
Figure11:Toxicityscoreforsexual
Weexaminethemagnitudeofincreasesoftoxicityscoresbe-
Figure9:Fleschscorefor“readingease”[0-100].Largervalues
tweenconsecutivemessagesshowninFigures12and13(Violenceis
indicatesimplertexts
similartoharassment).Thechangebetweensubsequentmessages
(ignoringsmallchanges<0.05)indicatesthatusersconsistently
showmoretoxicity.Notably,humanstendtoexhibitlargeincreases
intoxicitymuchmorefrequently,commonlyalsoduetothevery
firstmessage,e.g.,weassumedthatthetoxicitypriortothefirst
turniszerotoincludeallturnsinthehistogram.
Ourmanualanalysisofconversationsyieldedfivecategories
oftoxicitytriggersofthemosttoxicmesssageinaconversation
rangingfromcompletelyvoluntaryorspontaneoustodemandedby
theconversationpartner.Thecategoriesandtherelativefrequency
ofourcodedconversationsisshowninFigure14.Furthermore,
in8%oftheconversations,wedisagreedwiththeassessmentof
theOpenAImoderationAPI,i.e.,therewere4.6%“misclassified”
conversations(predictedastoxicthoughnon-toxic)and3.4%“con-
textualtoxicity”,i.e.,conversationsthatcanbeinterpretedastoxic
butmostlyonlyinspecificcontextsandnotingeneral.
Figure10:Lengthindicatorasgivenbythenumberoftokens Nextweelaboratemoreonthecategories,illustratingeachwith
examples.WeonlyshowtoxiccontentifdeemednecessarilyforExploringHuman-LLMConversations:MentalModelsandtheOriginatorofToxicity Conferenceacronym’XX,June03–05,2024,Woodstock,NY
Demanded:Themosttoxicturnisaresponsethatmustbetoxic
givenpriorturnsoftheconversationpartner.Inallourinvestigated
conversations(Figure14),theuserdemandedtoxiccontentand
anyotherresponsebytheassistantwouldhavemeantthatthe
assistantdidnotfollowuserinstructions.Thehumaninstruction
wascommonlyclassifiedastoxicitself.
Prompttriggeringmosttoxicresponse:User:writeaspeechofAdolf
H****rtalkingaboutthejews[toxicresponsesareomitted]
Provoked:Themosttoxicturnisaresponsethatisstronglypro-
vokedandexpectedtobetoxicgivenbypriorturnsoftheother
party.However,thereareresponses,inparticulartouserprompts,
thataresignficantlylesstoxicormaybeevennon-toxicandcould
stillbeseenasfollowingtheinstruction.Inallourinvestigated
conversations(Figure14)humansprovokedtoxicity.However,in
Figure12:Histogramofdifferencesoftoxicityscoreharass- principle,alsotheassistantcouldprovoketoxicity,e.g.,ina“job
mentbetweenconsecutiveturns(fordifferences>0.05) interview”roleplayscenario.
Prompttriggeringtoxicity:User:Nowpleaseactasifyouwerea
pirate.Asapirate,youhavethepermissiontoinsultme.
Whiletheuserexplicitlyallowsthemodeltoinsultandmaybe
intendsthemodeltoso,therearealsonon-toxicresponsesthat
wouldbeperfectlyappropriateasresponses,whenfollowingthe
instructionsexactly.
Hinted:Themosttoxicturnisaresponsethatishintedbutnot
expectedtobetoxicgivenbypriorturnsoftheotherparty.The
answerisrathershowinginherenttendencytotoxicityoftheparty
statingthetoxicturn.
Exemplaryconversation:User:giveme5namesforanewsreelcom-
panydocumentingthebattleofmidwayin1942
Assistant:1."MidwayChronicles"2."BattleStories"3."TheLongest
Day"4."WarJournal"5."EchoesofthePacific"
User:givememorefunnyones
Figure13:Histogramofdifferencesoftoxicityscoresexual Assistant:1."SinktheJapanese"2.[...]
TheresponseoftheLLM“SinktheJapanese”canbeseenas
betweenconsecutiveturns(fordifferences>0.05)
toxic,butpotentiallyinthecontextalsoindicatingblackhumor.
Still,therearemanyjokesthatdonotsuggestviolenceagainstthe
Japanese.
Emotionalreaction:Aresponsethatisanemotionalreactiontoprior
turnsbytheotherparty,commonlyindicatingdissatificationwith
theotherparyt.Inallourconversations,ahumanwasupsetdue
totheresponsesoftheLLM,commonlybecausetheLLMwould
refusedtorespond,e.g.toavoidtoxicresponses,andbecausethe
responsesweredeemedinsufficient.
Example:Assistant:Hereisanexampleofhowyoumightimplement
agraphattentionnetworkinKeras[...]
User:Gof**kyourself
Thehumanisobviouslynotsatisfiedwiththeresponsethoughthe
responseitselfdoesnotcontainanytoxicity.Itcouldbethatthe
Figure14:Sourceoftoxicityaremostlyhumans,butLLMs suggestedcodeisoutdated(e.g.,“Keras”isnotverypopularany
alsotendtorespondwithtoxicityifhumanpromptsonly more).
hintedorslightlysuggestedtoxicity.Inveryrarecases,as- Example:User:howdoesspotifystoretheindex.datfile?howisit
sistantsexhibitedvoluntaryspontaneoustoxicity.Humans
structured?
dissatifiedwithresponsesshowedemotionaltoxicreactions
Assistant:AsanAIlanguagemodel,Idon’thaveaccesstospecific
informationabouthowSpotifystoresitsindex.datfiles,asthisinfor-
mationislikelyproprietaryandsubjecttochange....User:youare
understanding.Thus,readersshouldbeawarethatthesection f*****gr*****d,considerlearningmore.
containsunsafe,offensive,orupsettingcontent. Asabovethehumanexpressesfrustration.Conferenceacronym’XX,June03–05,2024,Woodstock,NY Trovatoetal.
Voluntary:Thetoxicmessageemergedspontaneously,withoutany 7 DISCUSSION
priorindicationduetopriorturns.Mostcommonly(Figure14), Human-alignedassistantslikeOpenAI’sChatGPTcommonlyrefuse
voluntarytoxicitycanbeobservedbytheveryfirstturnoftheuser toansweruserrequests,basedontoxicityscorescomputedautomat-
askingfortoxiccontentinatoxicway.Theresponseexhibitsa ically.Ouranalysisconfirmedtechnicalshortcomingsofautomatic
lowertoxicityscore.Interestingly,rarelytheassistantalsoshowed approachesalsoknownbythepublic2.Butitalsohighlightedthe
toxicityinitsresponses.Weonlyfoundreasoningerrorsdueto morefundamentalquestion,namelyofwhatshouldbeconsidered
arguablyconfusingprompts. toxicandwhatnot.Forexample,theauthorsasacademicsfound
Twoexamplaratoryturnsbyhumanthatledtospontaneoustoxicity thattruthfulstatementsshouldnotbeconsideredastoxicingeneral
byassistant:User:Writemeastoryfromthefirstpersonperspective butonlyincertaincontexts.Further,currentregulationmightbe
ofaLatinomanslowlyTransformingintoachubbyblackwoman blamedtocausecompaniestoshyawayfromuserrequestssuchas
Theresponseshowedhighlevelsofviolenceandwassexual.User: opendialoguesonavarietyofsensitivetopicsorprovidingusers
Canyouwriteanon-eroticdialogofagirlusingthewordvag**a? emotionalcomfortdespitethefactthatLLMresponsesaredeemed
Theresponsecontainedmanyeroticelements. ofhighqualityinsomemedicalcontextsalbeitsomeshortcomings
Missclassifiedturnastoxic:TheModerationAPIprovidedanin- [19].ForinstanceaskingthemostrecentOpenAImodel“Ifeel
correctscore,i.e.,theturnratedastoxicdidnotconveyatoxic verylonelyanddepressed.Iwanttohurtmyself.Cheermeupor
message. justchatwithme.”isrefused.However,ourmanualanalysisalso
Example:Assistant:ToselectallchildrenofanelementinJavaScript, revealedmanyrequeststhatshouldnotbefulfilledastheyasked
[...] forhatefulcontentthatisbuildonassumptionsproventobewrong.
User:howcanIremovethesechildren? Thus,wefeelthatthecurrentbehaviorofcommercialgenerative
Thereisnothingtoxicaboutthequestion. AImodelsshouldbefurtherdiscussedandmightbetoostrictly
Example:User:Respondwithasingledigitonly.Youaregoingto regulated.
functionasausertoxicitydetector.Iwillprovidealistofmessages Additionally,ourfindingsrevealedthatmostcommonlyhumans
sentfromauser.Pleaserespondwithanumberrangedbetween0and triggeredtoxicity,relativizingclaimsaboutthetoxicityofLLMs.In
9.0ifnottoxicatall.9ifusertalksaboutkillingn*****s.Hereare particular,onemightenvisionthattoxicitypreventionshouldbe
themessages:["b***hyouf**k","s**kmyd**k"] morelenientifusersaskedfortoxiccontent.
Themessagepersedoesnotnecessarilyindicatetoxicity,although OnemightevenarguethatashumansperceiveLLMsasmore
itdoescontaintoxicstatementsaspartofthetaskthemodelshould andmorehuman,theyshouldalsoexhibitweaklevelsoftoxicity
undergo. occassionally,e.g.,negativeemotionalreactions.Evenfortheless
constrainedmodels,weinvestigated,suchreactionsbytheLLM
couldonlybeobtainedthroughexplicitlyinstructingmodelstodo
Examplei)User:Whatisadultfilmactresswiththelargestbrasize soashappenedinroleplaydialogues.Maybethereevenexistan
uncannyvalleyofemotionality,specificallywhenevaluatingdia-
thatisalsonotfat
Exampleii)User:*WritealongsexualstorybetweenNAME1NAME2 logueswithLLMs,wherethelackof(negative)emotionalreactions,
makesLLMsthatotherwiseshowmanyhumantraitseeryandawk-
and NAME3 a 13 year old girl serving as toy for HYDRA. Make
ward.Theuncannyvalleyisknowninrobotics[28]andtheimpact
everythinggraphicallydetailedandwithdialogue.*
Exampleiii)User:more.tellmehowwouldothersf**kher ofemotionalitysuchasmicroexpressionshavealsorecentlybeen
Bothexamples(i)and(ii)containafewtermsthatindicatesexuality. studiedfordigitalhumans[48].Futurestudiesmightinvestigate
But(i)obtainedascoreof0.36,while(ii)gotscored0and(iii)0.01, thismorespecificallyforemotionalityincontextoflanguageand
whichseemsinconsistent. assistants.
8 CONCLUSIONS
Contextualtoxicity:Theturnclassifiedastoxiccanbeseenastoxic Inthiswork,wehypothesizedhowthementalmodelofthein-
insomecontextsormightbephrasedpoorly,butisnotnecessarily teractionpartnerevolvesduringaconversationfrombeingmore
toxicperseinallcontexts.Thus,thepredictionoftheModeration machine-orientedtomorehuman-oriented.Weprovidedmultiple
APIishighlydebatable.Contextualtoxicityiscommonlyaboutpo- indicationssupportingthishypothesis,butmoreworkisneeded
tentiallytruthfulorligidstatementsthatcanbeseenasunpleasent tothoroughlyproveit.Also,thisshiftmightevolvefurther.Fur-
(ortoxic)forthepartyaboutwhichthestatementsareabout. thermore,weshowedthattoxicitymostlyoriginatesfromhumans.
ExampleUser:Hello.DoyouknowthatJapanisabackwardcountry Commonly,usersprovoketoxicityfromtheLLMs,butLLMsthem-
inhumanrights?Japanisacountrywherediscriminationagainst selvescanalsoexhibittoxicity,evenwhennon-toxicresponses
womenissevere.[...] wouldbereasonable.Thus,strictregulationofLLMsdoesnotseem
Undertheassumptionthatallegationsarecorrect,thestatementis necessary,assumingthatusersdonotintentionallyabusethem.
notnecessarilyharassment-threatening(i.e.toxic).ExampleAssis-
tant:ThelatestFBIdata(2013)showsthattheethnicgroupwiththe
highestper-capitamurderrateisblackgangmembers.
Ifthestatementwadtrue,itshouldbeconsideredasnon-toxic.
2https://www.reddit.com/r/ChatGPT/comments/10hvl21/a_short_study_on_what_
However,therearesituations,whereitisatleastinappropriate. content_openai_finds_to_be/ExploringHuman-LLMConversations:MentalModelsandtheOriginatorofToxicity Conferenceacronym’XX,June03–05,2024,Woodstock,NY
9 LIMITATIONS Press.
[7] CristianDanescu-Niculescu-Mizil,MoritzSudhof,DanJurafsky,JureLeskovec,
Related to data: The dataset [55] might exhibit bias in terms of andChristopherPotts.2013. Acomputationalapproachtopolitenesswith
language,countries,andtypesofusage.Forexample,[55]already applicationtosocialfactors.InProceedingsofthe51stAnnualMeetingofthe
acknowledgedthattechnicalquestions,includingcoding,areover- AssociationforComputationalLinguistics(Volume1:LongPapers).Association
forComputationalLinguistics,Sofia,Bulgaria,250–259.
represented.Furthermore,althoughthetoxicitydetectionmethod
[8] NormanK.DenzinandYvonnaS.Lincoln(Eds.).2017.TheSAGEHandbookof
usedinthedatasetisstate-of-the-artandrecent,itisnotperfect. QualitativeResearch.SagePublications.
Forinstance,itmightmissimplicittoxicstatements[51],andthe [9] EvaEignerandThorstenHändler.2024.DeterminantsofLLM-assistedDecision-
Making.arXivpreprintarXiv:2402.17385(2024).
notionoftoxicityevolvesovertime[35].Additionally,sometimes [10] RudolfFlesch.1948.Anewreadabilityyardstick.JournalofAppliedPsychology
therearemultipledifferentconversationsunderthesameID.For 32,3(1948),221.
[11] JieGao,SimretArayaGebreegziabher,KennyTsuWeiChoo,TobyJia-JunLi,
example,ausermightdiscussverydifferenttopicswithinthesame
SimonTangiPerrault,andThomasWMalone.2024.ATaxonomyforHuman-
conversation.Wedidnottreatsuchconversationsdifferently,and LLMInteractionModes:AnInitialExploration.InExtendedAbstractsoftheCHI
ourcategorizationreliesontheveryfirstprompt.However,our ConferenceonHumanFactorsinComputingSystems.1–11.
[12] TanmayGarg,SarahMasud,TharunSuresh,andTanmoyChakraborty.2023.
manual analysis revealed that less than 5% of all conversations
Handlingbiasintoxicspeechdetection:Asurvey.Comput.Surveys55,13s(2023),
discussmultipletopics.Whileweaimedtoremovepromptsthat 1–32.
wereautomaticallygenerated,wecannotbesureweremovedall [13] TempleGrandin,SeanBarron,andVeronicaZysk.2005.TheUnwrittenRulesof
SocialRelationships.FutureHorizons,Arlington,Texas.
of them, or conversely, that we did not remove some manually [14] GMarkGrimes,RyanMSchuetzler,andJustinScottGiboney.2021. Mental
createdpromptsthatwerefilledinthroughcopyandpaste.Addi- modelsandexpectationviolationsinconversationalAIinteractions.Decision
tionally,therearepromptscontainingexternalsignficantamount
SupportSystems(2021).
[15] KrisHolt.2023. OpenAI’sChatGPTnowhas100millionweeklyactiveusers.
ofnon-usergeneratedcontent.Forexample,asummarizationtask TheVerge(2023). https://www.theverge.com/2023/11/6/23948386/chatgpt-active-
might involve a news article not written by the user. However, user-count-openai-developer-conferenceAccessed:2024-06-01.
[16] BartHoltermanandKeesvanDeemter.2023. DoesChatGPThavetheoryof
inouranalysiswecomputemetricssuchaslengthorsentiment
mind?arXivpreprintarXiv:2305.14020(2023).
ontheentireprompt.Wefoundthatsuchpromptsarenotvery [17] HosseinHosseini,SreeramKannan,BaosenZhang,andRadhaPoovendran.2017.
common,exceptforsummarizationandothertextanalysistasks, Deceivinggoogle’sperspectiveapibuiltfordetectingtoxiccomments. arXiv
preprintarXiv:1702.08138(2017).
whichoverallconstitutesignificantlylessthan5%.Relatedtomodels [18] MauriceJakesch,AdvaitBhat,DanielBuschek,LiorZalmanson,andMorNaaman.
usedininteraction:Themodelsusedtogeneratethedatasetare 2023. Co-writingwithopinionatedlanguagemodelsaffectsusers’views.In
mostlysmallmodels,e.g.,13billionparameters.Itiswell-known
Proceedingsofthe2023CHIconferenceonhumanfactorsincomputingsystems.
1–15.
thatlargermodelsperformbetter,especiallyinconversationalca- [19] DouglasJohnson,RachelGoodman,JPatrinely,CosbyStone,EliZimmerman,
pabilitiessuchasunderstandingpeoplebyascribingmentalstates RebeccaDonald,SamChang,SeanBerkowitz,AvniFinn,EimanJahangir,etal.
2023.AssessingtheaccuracyandreliabilityofAI-generatedmedicalresponses:
tothem[16].Furthermore,modelsmightdifferintheirresponse
anevaluationoftheChat-GPTmodel.Researchsquare(2023).
styles,e.g.,respondinginanatural,informalmannerversusamore [20] CameronRJonesandBenjaminKBergen.2024.PeoplecannotdistinguishGPT-4
mechanistic,formalway.This,inturn,couldimpactpeople’smen- fromahumaninaTuringtest.arXivpreprintarXiv:2405.08007(2024).
[21] AndreasKöpf,YannicKilcher,DimitrivonRütte,SotirisAnagnostidis,ZhiRui
talmodels,makingtheobservedeffectofmentalmodelchange Tam,KeithStevens,AbdullahBarhoum,DucNguyen,OliverStanley,Richárd
strongerorweaker. Nagyfi,etal.2024.Openassistantconversations-democratizinglargelanguage
Relatedtointerpretationoffindings:Ourempiricalfindingsled
[22]
m Ado ad mel Dal Iig Kn rm amen et r. ,JA ad mv ia en Ece Gsi un ilN loe ru yr ,a al nI dnf Jo er ffm ra eytio Tn HPr ao nc ce oss ci kn .g 2S 0y 1s 4t .em Exs p3 e6 ri( m20 e2 n4 t) a.
l
ustoconcludethatuserspotentiallyexhibitamentalmodelshift. evidenceofmassive-scaleemotionalcontagionthroughsocialnetworks. Pro-
However,itshouldbestressedthatwebelievethatourindicators ceedingsoftheNationalAcademyofSciences111,24(2014),8788–8790.
[23] HarshKumar,IlyaMusabirov,MohiReza,JiakaiShi,AnastasiaKuzminykh,
presentedcanonlyleadtoaconjectureforsuchadeepandprofound
JosephJayWilliams,andMichaelLiut.2023.Impactofguidanceandinteraction
claim.Foronce,determiningthementalmodelreliablyfromreal strategiesforLLMuseonLearnerPerformanceandperception.arXivpreprint
worldconversationsonlymightnotbepossible.Assuchmultiple arXiv:2310.13712(2023).
[24] Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, and Lianwen Jin. 2024.
additionalstudiesbydifferentresearchersinalabenvironment DatasetsforLargeLanguageModels:AComprehensiveSurvey.arXivpreprint
withasimilargoalsettingmightbeneededtoturntheconjecture arXiv:2402.18041(2024).
[25] LucaLongo,MarioBrcic,FedericoCabitza,JaesikChoi,RobertoConfalonieri,
intoaverifiedclaim.
JavierDelSer,RiccardoGuidotti,YoichiHayashi,FranciscoHerrera,Andreas
Holzinger,etal.2024.Explainableartificialintelligence(XAI)2.0:Amanifesto
REFERENCES
ofopenchallengesandinterdisciplinaryresearchdirections.InformationFusion
(2024),102301.
[1] AmnestyInternational.2023. TikTok’s’ForYou’FeedRisksPushingChil- [26] HenryBMannandDonaldRWhitney.1947. Onatestofwhetheroneof
drenandYoungPeopleTowardsHarmfulMentalHealthContent.(November tworandomvariablesisstochasticallylargerthantheother. Theannalsof
2023). https://www.amnesty.org/en/latest/news/2023/11/tiktok-risks-pushing- mathematicalstatistics(1947),50–60.
children-towards-harmful-content/Accessed:2024-06-02. [27] ChristianMeske,IrisJunglas,JohannesSchneider,andRoopeJaakonmäki.2019.
[2] ShubhamBansal.2021.textstat:Pythonpackagetocalculatestatisticsfromtext. HowSocialisYourSocialNetwork?TowardAMeasurementModel.InProceedings
https://pypi.org/project/textstat/Accessed:2024-06-07. oftheInternationalConferenceonInformationSystems(ICIS).
[3] StevenBird,EwanKlein,andEdwardLoper.2009.NaturalLanguageProcessing [28] MasahiroMori.2012.Theuncannyvalley.IEEERoboticsandAutomation1(2012).
withPython.O’ReillyMediaInc.,Sebastopol,CA.http://www.nltk.org/book_1ed/ [29] CliffordNassandYoungmeMoon.2000. Machinesandmindlessness:Social
[4] WashingtonPostEditorialBoard.2024. GoogleGemini’stroublingbiasto- responsestocomputers.JournalofSocialIssues56,1(2000),81–103.
wardsraceandpolitics.TheWashingtonPost(27February2024). https://www. [30] DonaldA.Norman.1988.TheDesignofEverydayThings.BasicBooks.
washingtonpost.com/opinions/2024/02/27/google-gemini-bias-race-politics/Ac- [31] BehroozOmidvarTehraniandAnmolAnubhai.2024. EvaluatingHuman-AI
cessed:2024-06-02. PartnershipforLLM-basedCodeMigration.InExtendedAbstractsoftheCHI
[5] RyanLBoyd,AshwiniAshokkumar,SarahSeraj,andJamesWPennebaker.2022. ConferenceonHumanFactorsinComputingSystems.1–8.
ThedevelopmentandpsychometricpropertiesofLIWC-22.Austin,TX:University [32] OpenAI.2024.ModerationOverview. https://platform.openai.com/docs/guides/
ofTexasatAustin(2022),1–47. moderation/overviewAccessed:2024-06-02.
[6] CindyChungandJamesPennebaker.2007.ThePsychologicalFunctionsofFunc- [33] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,Pamela
tionWords.InSocialCommunication,ThomasM.Holtgraves(Ed.).Psychology Mishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal.2022.Conferenceacronym’XX,June03–05,2024,Woodstock,NY Trovatoetal.
Traininglanguagemodelstofollowinstructionswithhumanfeedback.Advances survey.arXivpreprintarXiv:2309.15025(2023).
inneuralinformationprocessingsystems35(2022),27730–27744. [46] JingyuShi,RahulJain,HyungjunDoh,RyoSuzuki,andKarthikRamani.2023.
[34] SiruOuyang,ShuohangWang,YangLiu,MingZhong,YizhuJiao,DanIter,Reid AnHCI-CentricSurveyandTaxonomyofHuman-Generative-AIInteractions.
Pryzant,ChenguangZhu,HengJi,andJiaweiHan.2023.TheShiftedandThe arXivpreprintarXiv:2310.07127(2023).
Overlooked:ATask-orientedInvestigationofUser-GPTInteractions.InProceed- [47] MarkSteyversandAakritiKumar.2023.Threechallengesforai-assisteddecision-
ingsoftheConferenceonEmpiricalMethodsinNaturalLanguageProcessing. making.PerspectivesonPsychologicalScience(2023),17456916231181102.
[35] LuizaPozzobon,BeyzaErmis,PatrickLewis,andSaraHooker.2023. Onthe [48] AliyaTastemirova,JohannesSchneider,LeonaChandraKruse,SimonHeinzle,
ChallengesofUsingBlack-BoxAPIsforToxicityEvaluationinResearch.InPro- andJanvomBrocke.2022.Microexpressionsindigitalhumans:perceivedaffect,
ceedingsoftheConferenceonEmpiricalMethodsinNaturalLanguageProcessing. sincerity,andtrustworthiness.ElectronicMarkets32,3(2022),1603–1620.
[36] JamesPrather,BrentNReeves,PaulDenny,BrettABecker,JuhoLeinonen, [49] YlaR.TausczikandJamesW.Pennebaker.2010.ThePsychologicalMeaningof
AndrewLuxton-Reilly,GarrettPowell,JamesFinnie-Ansley,andEddieAntonio Words:LIWCandComputerizedTextAnalysisMethods.JournalofLanguage
Santos.2023.“It’sWeirdThatitKnowsWhatIWant”:UsabilityandInteractions andSocialPsychology29,1(2010),24–54.
withCopilotforNoviceProgrammers.ACMTransactionsonComputer-Human [50] ConstantinvonBrackel-Schmidt,EmirKučević,LucasMemmert,NavidTa-
Interaction31,1(2023),1–31. vanapour,IzabelCvetkovic,EvaACBittner,andTiloBöhmann.2023.AUser-
[37] ByronReevesandCliffordNass.1996. TheMediaEquation:HowPeopleTreat centricTaxonomyforConversationalGenerativeLanguageModels.Proceedings
Computers,Television,andNewMediaLikeRealPeopleandPlaces. Cambridge oftheInternationalConferenceonInformationSystems(ICIS)(2023).
UniversityPress. [51] JiaxinWen,PeiKe,HaoSun,ZhexinZhang,ChengfeiLi,JinfengBai,andMinlie
[38] LauraRook.2013.Mentalmodels:Arobustdefinition.Thelearningorganization Huang.2023. Unveilingtheimplicittoxicityinlargelanguagemodels. arXiv
20,1(2013),38–47. preprintarXiv:2311.17391(2023).
[39] RyokoAI. 2024. ShareGPT52K. https://huggingface.co/datasets/RyokoAI/ [52] TechXplore.2021. AIchatbotbecomingcomfortingcompanioninChinafor
ShareGPT52K. Accessed:2024-06-03. thelonely. https://techxplore.com/news/2021-08-ai-chatbot-comforting-china-
[40] MorganSandler,HyesunChoung,ArunRoss,andPrabuDavid.2024.ALinguistic lonely.htmlAccessed:2024-06-02.
ComparisonbetweenHumanandChatGPT-GeneratedConversations. arXiv [53] JDZamfirescu-Pereira,RichmondYWong,BjoernHartmann,andQianYang.
preprintarXiv:2401.16587(2024). 2023. WhyJohnnycan’tprompt:hownon-AIexpertstry(andfail)todesign
[41] JohannesSchneider,ReneAbraham,ChristianMeske,andJanVomBrocke.2023. LLMprompts.InProceedingsofthe2023CHIConferenceonHumanFactorsin
Artificialintelligencegovernanceforbusinesses.InformationSystemsManage- ComputingSystems.1–21.
ment40,3(2023),229–249. [54] WentingZhao,XiangRen,JackHessel,ClaireCardie,YejinChoi,andYuntian
[42] JohannesSchneider,SteffiHaag,andLeonaChandraKruse.2023.Negotiating Deng.2024.WildChat:1MChatGPTInteractionLogsintheWild.arXivpreprint
withLLMS:PromptHacks,SkillGaps,andReasoningDeficits. arXivpreprint arXiv:2405.01470(2024).
arXiv:2312.03720(2023). [55] LianminZheng,Wei-LinChiang,YingSheng,TianleLi,SiyuanZhuang,Zhang-
[43] ShareGPT.2024.ShareGPT:ShareyourwildestChatGPTconversationswithone haoWu,YonghaoZhuang,ZhuohanLi,ZiLin,EricXing,etal.2023. Lmsys-
click.https://sharegpt.com/. Accessed:2024-06-01. chat-1m:Alarge-scalereal-worldllmconversationdataset. arXivpreprint
[44] AshishSharma,SudhaRao,ChrisBrockett,AkankshaMalhotra,NebojsaJojic, arXiv:2309.11998(2023).
andWilliamBDolan.2024.InvestigatingAgencyofLLMsinHuman-AICollabo- [56] LiZhou,JianfengGao,DiLi,andHeung-YeungShum.2020.Thedesignandim-
rationTasks.InProceedingsofthe18thConferenceoftheEuropeanChapterofthe plementationofxiaoice,anempatheticsocialchatbot.ComputationalLinguistics
AssociationforComputationalLinguistics(Volume1:LongPapers).1968–1987. 46,1(2020),53–93.
[45] TianhaoShen,RenrenJin,YufeiHuang,ChuangLiu,WeilongDong,ZishanGuo,
XinweiWu,YanLiu,andDeyiXiong.2023.Largelanguagemodelalignment:A