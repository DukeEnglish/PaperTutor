1
Link Representation Learning for Probabilistic
Travel Time Estimation
Chen Xu, Qiang Wang, and Lijun Sun, Senior Member, IEEE
Abstract—Travel time estimation is a crucial application in is used to predict travel time [1]. The first is the origin-
navigationappsandwebmappingservices.Currentdeterministic destination-based(OD-based)approach(see,e.g.,[2],[3],[4],
andprobabilisticmethodsprimarilyfocusonmodelingindividual
[5], [6], [7], [8]). The key concept of this approach involves
trips, assuming independence among trips. However, in real-
searching for past trips that have origin-destination profiles
world scenarios, we often observe strong inter-trip correlations
due to factors such as weather conditions, traffic management, similarto thequeried trip.Theobtained traveltime valuesare
and road works. In this paper, we propose to model trip-level then used to calculate the mean and variance of the queried
link travel time using a Gaussian hierarchical model, which can traveltime[3].Factorssuchastraveldistance,departuretime,
characterizebothinter-tripandintra-tripcorrelations.Thejoint
road attributes, and other additional information are further
distributionoftraveltimeofmultipletripsbecomesamultivari- introduced to enrich the feature space of OD pairs [4], [6],
ate Gaussian parameterized by learnable link representations.
To effectively use the sparse GPS trajectories, we also propose [8]. The periodic patterns of traffic conditions can also be
a data augmentation method based on trip sub-sampling, which analyzed to account for the temporal dynamics [5], [7], [8].
allowsforfine-grainedgradientbackpropagationinlearninglink The OD-based method relies solely on structured features
representations. During inference, we estimate the probability such as origin, destination, and time of day as covariates, and
distribution of the travel time of a queried trip conditional on
the models typically exhibit low computational complexity.
thecompletedtripsthatarespatiotemporallyadjacent.Werefer
to the overall framework as ProbTTE. We evaluate ProbTTE Nonetheless, since travel time is primarily influenced by the
on two real-world GPS trajectory datasets, and the results specific route taken by a vehicle, the prediction accuracy of
demonstrate its superior performance compared to state-of-the- theseOD-basedmodelsisoftencompromisedduetotheomis-
artdeterministicandprobabilisticbaselines.Additionally,wefind
sion of path information. The presence of high-quality GPS
thatthelearnedlinkrepresentationsalignwellwiththephysical dataandadvancesinsequencemodelingmethodologiesinspire
geometryofthenetwork,makingthemsuitableasinputforother
applications. researchers to use comprehensive trip information for TTE,
resultinginthedevelopmentofroute-focusedapproaches.The
IndexTerms—Probabilistictraveltimeestimation,representa-
keyconceptoftheroute-basedapproachinvolveslearningrep-
tionlearning,uncertaintyquantification,low-rankparameteriza-
tion resentation vectors for road segments [9], [10] or GPS points
[11] in a data-driven way and then combining these vectors
I. INTRODUCTION with deep neural networks to obtain estimates. Most route-
based methods utilize recursive neural networks to model
Travel Time Estimation (TTE) focuses on predicting the
temporal dynamics (see, e.g., [12], [13], [14], [15]) and graph
time it takes a vehicle to traverse a specific path connecting
neural networks to characterize spatial information (see, e.g.,
twolocations(i.e.,originanddestination).Giventhedeparture
[16], [17], [18]), [19]. In addition, attention mechanism [20],
time, TTE is equivalent to predicting the estimated time of
[21] and meta-learning [22], [23] are also incorporated into
arrival (ETA). TTE (or ETA prediction) is a fundamental
this category of methods.
applicationinnavigationservicesandintelligenttransportation
Due to the importance of TTE in travel decision-making,
systems: for example, individual travelers can better sched-
such as when to leave and which path to take, recent research
ule/plantheirtripsbasedonTTE,logisticsanddeliveryservice
has focused on probabilistic TTE, which involves forecasting
operatorscandesignmoreefficientandrobustroutesbytaking
the probabilistic distribution of travel time on a specific
TTE into consideration, and transport agencies can leverage
path [24], [25]. These models generally assume that the
TTE for better operation and management.
travel time τ of a trip i follows a Gaussian distribution
Givenitsimportance,ETApredictionhasbecomeanimpor- i
τ ∼ N (f (X ),f (X )), where X is the input feature of
tant problem in machine learning and has gained considered i µ i σ2 i i
trip i, and f and f are two neural networks that produce
attention in the literature. Most existing studies can be cate- µ σ2
the mean and variance of the distribution, respectively. To
gorized into two groups based on whether path information
facilitate likelihood calculation, trips are assumed to be inde-
We acknowledge the support of the Natural Sciences and Engineering pendent, i.e., Cov(τ i,τ j) = 0,∀i ̸= j. However, considering
ResearchCouncilofCanada(NSERC)throughtheDiscoveryGrant. the spatiotemporal correlation in traffic conditions, the travel
Chen Xu and Qiang Wang are with the National Engineering Research
time for two trips could be correlated if both are influenced
CenterofMobileNetworkTechnologies,SchoolofInformationandCommu-
nication Engineering, Beijing University of Posts and Telecommunications, by unseen factors (e.g., incidents and weather conditions).
Beijing,China(e-mail:xuchen;wangq@bupt.edu.cn). Disregarding this information can result in less effective
LijunSuniswiththeDepartmentofCivilEngineering,McGillUniversity,
representation learning for road segments within the traffic
Montreal,Quebec,Canada(e-mail:lijun.sun@mcgil.ca).
(Correspondingauthor:LijunSun.) network. A natural way to model such correlation is to design
4202
luJ
8
]GL.sc[
1v59850.7042:viXra2
arandomeffectsmodelforsegmenttraveltimes(seee.g.,[1]), likelihoodevaluation.Weevaluatetheproposedmodelontwo
and consider trip travel time as an aggregated observation of real-world datasets in Section V. Finally, we conclude this
segment travel times together with trip-level random effects. study in Section VI.
However, in practice, this is challenging because of the large
dimensionalityoftheproblem:tomodelthespatialcorrelation II. RELATEDWORK
of segment travel time, two large covariance matrices, for
In this section, we survey the work related to travel time
inter-trip segment travel time and intra-trip segment travel
estimation,coveringbothdeterministicandprobabilisticmod-
time, respectively, need to be estimated from the aggregated
els, as the propaedeutics of our work. We summarize the
travel time observations. For a transportation network with N
comparison of the TTE-related work as shown in Table I.
segments, the covariance matrix is of size N ×N, which is
computationally prohibitive for large networks. In addition,
A. Deterministic Travel Time Estimation
due to the sparse nature of GPS data, segment travel time for
an individual trip often cannot be observed directly. Instead, The methods for estimating travel time can mainly be
the observed time interval between two consecutive GPS data divided into two categories based on the difference in input
points often reflects the aggregated travel time over multiple data. The first is based on Origin-Destination (OD) pairs
road segments. This also poses challenges in attributing the [3]–[8]. Wang et al. [3] proposed a neighbor-based approach
variation in total travel time on a path to each individual link to find neighboring trips with exact origin/destination and
on the path. simultaneously consider the dynamics of traffic conditions.
To effectively use GPS trajectories for learning trip travel They aggregate the travel time of neighboring trips to esti-
time distributions, in this paper we propose the ProbTTE mate the travel time of the query trip. To enrich the feature
framework, which models the joint distribution of multiple space of the input data, Li et al. [4] proposed a multi-task
trips as a multivariate Gaussian distribution. In particular, representationlearningmodelforarrivaltimeestimation(MU-
we design the covariance matrix to account for both inter- RAT).Itleveragesmoretrippropertiesandthespatiotemporal
trip correlations and intra-trip correlations through learnable prior knowledge of the underlying road network to produce
link/segment representations. In terms of training, we lever- trip representation based on a multi-task learning framework.
age the low-rank-plus-diagonal structure of the covariance Yuan et al. [5] introduced trajectory information to assist in
matrix, and use negative log-likelihood as a loss function to matchingneighboringtripsduringthetrainingphase,butonly
updatelinkrepresentations.Thelinkrepresentationlearnedby OD information is utilized during the prediction phase. Road
ProbTTE also establishes a unified projection with a contrac- segment embeddings and time slot embeddings are utilized to
tionproperty,whichallowsustobuildefficientrepresentations represent the spatial and temporal properties of trajectories.
fortripsthroughaffinetransformationsoflinkrepresentations. Then, the hidden representation of OD input is trained to be
Additionally, a trip sub-sampling data augmentation method close to the spatiotemporal representation of the trajectory.
is developed to utilize the sparse GPS trajectories more effi- Similarly, Lin et al. [6] also utilized trajectory information
cientlyforlinkrepresentationlearning.Themaincontributions during training. They partitioned the city into multiple pixels
of this paper are summarized as follows: and utilized a Masked Vision Transformer to model the
• We propose a multi-trip joint probabilistic distribution correlations between pixels. Then, they introduced a diffusion
model ProbTTE for estimating travel times. Efficient model for generatively encoding the OD and trajectory of
low-rank parameterizations are introduced to learn inter- the trip based on the spatiotemporal properties of pixels. In
trip and intra-trip correlations among all segments in a addition, Wang et al. [8] started considering constructing a
transportation network. probabilistic model within the OD-based method. They first
• We propose a sub-sampling data augmentation approach infer the transition probability between road segments, then
to balance the samples and enhance the optimization the most possible route can be recovered based on the given
efficiency in learning the link representation vectors. It OD pair. The trip travel time can be obtained by calculating
facilitatesspecificoptimizationatthelinklevel,enabling the sum of the travel times for all road segments on the
fine-grained modeling of link features. recoveredroute.Thismethodhasbroadapplicability,lowdata
• The experimental results on two real datasets validated requirements, and can be applied in scenarios where query
the superiority of our model. Our model relatively out- trip trajectories are not available. However, the fuzzy nature
performs the best deterministic and probabilistic base- of these input data makes it easy to lose key features of the
lines by an average of more than 12.11% and 13.34%, trip, resulting in limited estimation performance.
respectively. Ablation experiments and interpretability The second method is route/path-based. In this approach,
analysis further validate the effectiveness of multi-trip a trip is regarded as a sequence composed of links or GPS
jointmodelingandthelearnedlinkrepresentationvectors. points. Deep neural networks are utilized to capture sequence
features and generate estimations. Regarding GPS point data,
The remainder of this paper is organized as follows. Sec-
Wang et al. [11] proposed embedding GPS points and their
tion II summarizes related work. Section III introduces key
geographic information by incorporating geo-convolution and
definitions and formulations. Section IV presents the key
recurrent units to capture spatial and temporal dependencies.
components of ProbTTE, including parameterization of the
Liao et al. [10] propose a multi-faceted route representation
inter-trip and intra-trip link covariance matrices and efficient
learning framework that divides a route into three sequences:3
TABLEI
COMPARISONOFTRAVELTIMEESTIMATIONMODELS.
ModelName ModelType DataRequirement Probabilistic Inter-tripCorr LinkRepresentation TripRepresentation
MURAT(2018)[4] OD-based ODPair+RoadAttributes GraphLaplacianRegularization ODLinkRepresentationConcat
TEMP(2019)[3] OD-based ODPair — ODTuple
DeepOD(2020)[5] OD-based ODPair+RoadAttributes LinkandAttributeEmbedding ODLinkRepresentationConcat
DOT(2023)[6] OD-based ODPair — MaskedVisionTransformer
MWSL-TTE(2023)[8] OD-based ODPair+RoadAttributes RelationalGCN DirectAddition
DeepTTE(2018)[11] Route-based GPSSequence+TripAttributes Geo-Conv LSTM
WDR(2018)[15] Route-based GPSSequence+TripAttributes Wide&DeepModel LSTM
HetETA(2020)[16] Route-based GPSSequence+RoadAttributes Het-ChebNet GatedCNN
STTE(2021)[16] Route-based GPSSequence+RoadAttributes LinkandAttributeEmbedding LSTM
CatETA(2022)[13] Route-based GPSSequence+RoadAttributes+TripAttributes LinkandAttributeEmbedding BiGRU
HierETA(2022)[21] Route-based GPSSequence+RoadAttributes LinkandAttributeEmbedding BiLSTM
MulT-TTE(2024)[21] Route-based GPSSequence+RoadAttributes LinkandAttributeEmbedding Transformer
DeepGTT(2019)[25] Route-based GPSSequence+RoadAttributes ✓ LinkandAttributeEmbedding LinkRepresentationWeightedAddition
RTAG(2023)[24] Route-based GPSSequence+RoadAttributes+TripAttributes ✓ LinkandAttributeEmbedding Self-attention
GMDNet(2023)[26] Route-based GPSSequence+RoadAttributes ✓ LinkandAttributeEmbedding Self-attentionwithPosition
ProbTTE(ours) Route-based GPSSequence ✓ ✓ LinkEmbedding Path-based-sumofLinkRepresentation
GPS coordinates, the attribute of each road segment, and the B. Probabilistic Regression
IDs of road segments. Then, a transformer encoder is used to
Probabilistic regression, in contrast to deterministic regres-
gettherepresentationsofthreesequences.Theauthorsfusethe
sion, offers the advantage of providing uncertainty estimates
multi-facetedrouterepresentationstogettheestimation.Apart
alongside predictions, enhancing robustness and flexibility in
fromdirectlyprocessingGPSpoints,morestudiesinvolvefirst
modeling complex relationships. In economic analysis scenar-
binding GPS points to the road network and then processing
ios, probabilistic regression based on statistical methods has
the link index. Wang et al. [10] formulated the problem of
been widely researched. For example, ARCH, GARCH, etc.
ETA as a pure regression problem and proposed a Wide-
not only provide mean estimates but also model higher-order
Deep-Recurrent (WDR) learning model to predict travel time
moments such as variance, offering a more comprehensive
along a given link sequence at a given departure time. It
understanding of the data distribution. In recent years, the
jointly trains wide linear models, deep neural networks, and
applicationofneuralnetworkshasprovidednewadvancements
recurrent neural networks together to take full advantage of
in probabilistic regression. In [27], Salinas et al. proposed a
all three models. Considering the potential additional time
recurrentneuralnetwork(RNN)architecture,namedDeepAR,
overhead at intersections between links, Han et al. [9] pro-
for probabilistic forecasting. It incorporates a negative bino-
posed a multi-semantic path representation method. It learns
mial likelihood for count data as well as special treatment
thesemanticrepresentationsoflinksequencesandintersection
for the case where the magnitudes of the time series vary
sequences by considering information in non-Euclidean space
widely. Building upon this, the authors further propose a
and Euclidean space, respectively. Then a sequence learning
probabilistichigh-dimensionalmultivariateforecastingmethod
component aggregates the information along the entire path
[28]toconstructjointdistributionsformultivariatetimeseries
andprovidesthefinalestimation.Inaddition,Hongetal.[16]
and measure the covariance between them. It parameterizes
proposeHetETAtoleverageheterogeneousinformationgraphs
the output distribution based on a low-rank-plus-diagonal
in ETA tasks, translating the road map into a multi-relational
covariance matrix to reduce the number of parameters.
network according to the connection direction at intersections
In TTE, there are also some efforts to explore probabilistic
between links. Temporal convolutions and graph convolutions
modeling. Li et al. [25] proposed a deep generative model to
are utilized to learn representations of spatiotemporal hetero-
learn the travel time distribution by conditioning on the real-
geneous information. Considering travel time estimation as a
timetraffic.Thismodelinterpretsthegenerationoftraveltime
classificationproblemisalsoanovelexploration.Yeetal.[13]
using a three-layer hierarchical probabilistic model, which
proposed a Categorical approximate method to Estimate Time
capturesdynamicallychangingreal-timetrafficconditionsand
of Arrival (CatETA). It formulates the ETA problem as a
static spatial features, and then generates estimation times
classification problem and labels it with the average time of
basedonanattentionmechanism.In[24],Zhouetal.proposed
each category. Deep neural networks are designed to extract
to learn the local representations of road segments over a
the spatiotemporal features of link sequences and obtain the
temporal attributed graph, by jointly exploiting the dynamic
estimation.Thesemethodsachieveexcellentestimationperfor-
traffic conditions and the topology of the road networks.
mance through rich input features and mature sequence/graph
Then a distribution loss based on the negative log-likelihood
neural networks. However, they only provide the mean travel
(NLL) is developed to fulfill the purpose of travel time
time and cannot provide information on the fluctuation or
distribution estimation. Mao et al. [26] introduced GMDNet,
confidence level of the prediction data.
aGraph-basedMixtureDensityNetwork,whichharnessesthe
advantagesofbothgraphneuralnetworksandmixturedensity
networks for estimating travel time distribution. They utilized4
the Expectation-Maximization (EM) framework to enhance network-based mapping function is constructed to learn the
stability during training. In addition, tensor-based methods mean travel time based on the trip representation vectors,
have also been used to construct probabilistic estimation whilethecovarianceisformedusingtheinnerproductofthese
models for travel time. trip representation vectors for simultaneously modeling inter-
These methods attempt to model the travel time of individ- and intra-trip correlations. Additionally, trip sub-sampling is
ual trips probabilistically. They assume that the travel times used to augment the training data, balancing the samples and
of trips are independent, overlooking the potential correlation allowing gradients to differentially impact the representation
among trips. This limits the feature perception range and at the link level within the same trip. Finally, historical trips
impairs the estimation performance. inspatiotemporalproximitytothequerytripareintroducedto
obtainthetraveltimedistributionofaqueriedtripconditional
III. DEFINITIONSANDPROBLEMFORMULATION on those observed trips. The final estimations are obtained by
A. Definition: Road Network random sampling the conditional distribution. We explain the
details of each component in the following subsections.
A road network is defined as the aggregate of all road
segments within a studied area or a city. It is represented
B. Parameterizing Link Travel Time Distribution
as a graph G = (V,E), where V denotes the set of nodes
representing road segments/links, and E denotes the set of In this study, we focus on modeling trip travel time over a
specific time horizon (e.g., 8:00–9:00 AM) of weekdays. In
edges illustrating the topological connections among these
doing so, we restrict our scope to only model the variations
road segments. The terms “link” and “segment” are used
in link travel time resulting from external factors rather than
interchangeably throughout this paper.
traffic demand. Given that the historical data spans several
days, we employ a hierarchical model to describe both daily
B. Definition: Links and Trips
random fluctuations and random effects at the trip level. In
A link l ∈ V refers to a road segment. Each link in the
particular, we model the travel time t for link l, day i, and
l,i,q
road network has a unique index. In this work, we follow
trip q as
OpenStreetMap (OSM) [29] to define links. The trajectory of
t =µ +η +ϵ , (2)
l,i,q l l,i l,i,q
a trip is an ordered sequence of time-stamped GPS records.
For a trip with k GPS data points, we denote its trajectory where µ l represents the overall mean travel time for link
by T = {(l ,c ),...,(l ,c )}, where the time index c is l, which can be produced by link representation and other
g 1 1 k k
monotonically increasing. The total travel time of the trip is available covariates such as time of day and day of week, η l,i
τ =c −c .Notethatitispossiblethat(1)morethanoneGPS accounts for day-specific deviations as a result of the impacts
k 1
data points are located on the same link, and (2) a traversed of global unobserved factors that affects all trips in a day
link is not captured if no GPS records are registered. The but are not used in modeling µ l, such as weather conditions,
link index sequence, after completing the entire sequence and road works and public holidays; and ϵ l,i,q captures the trip-
removing duplicates, is used as model input, denoted by T = specific error (e.g., differences in driver/vehicle profile, or
{l ,...,l }. In other words, a trip T can be regarded as an short-durationdelaysduetotrafficincidentsaffectingmultiple
1 k
ordered set of traveled links. nearby links). This specification is similar to [1], where day-
specific and trip-specific random effects are introduced to
capture travel time variations.
C. Problem Formulation
For day-specific random effects, we assume the covariance
Given a dataset D = {T |i=1,...,N} consisting of N
i Cov(η ,η )=δ(i,i′)×Σ (l,l′), where δ(i,i′)=1 when
l,i l′,i′ d
historical trips in a road network, our objective is to estimate
i = i′ and 0 otherwise, and Σ is a positive semi-definate
d
the probability distribution of the travel time τ for a query
q matrix of size |V|×|V| characterizing inter-trip correlations.
trip T that is not part of D. In this paper, we consider the
q Thus, the joint distribution of travel times on all links on day
travel time τ to follow a Gaussian distribution:
q i can be modeled as
τ ∼N
(cid:0)
µ
,σ2(cid:1)
, (1)
q q q x =µ+η ∼N (µ,Σ ), (3)
i i d
where µ q = f µ(T q) and σ q2 = f σ2(T q), and f µ(·) and f σ2(·) whereµ∈R|V| andη ∈R|V| arevectorizedglobalmeanand
i
are two designed models for estimating the mean and the
dailyrandomeffects,respectively.Thisspecificationalsogives
standard deviation of travel time τ , respectively.
q that x and x are independent if i ̸= i′ (i.e., two different
i i′
days).
IV. METHODOLOGY
Due to the large size of Σ , directly learning the Gaus-
d
A. Overview of ProbTTE sian distribution in Eq. (3) will require a large number of
The overall architecture of ProbTTE is shown in Figure 1. parameters. For computational efficiency, we model Σ d with
A unique property of ProbTTE is that the correlation among a low-rank parameterization
multiple trips is explicitly modeled, and the travel times for
Σ =LL⊤, (4)
d
multiple trips are jointly modeled as a multivariate Gaussian
distribution. Each trip is represented by aggregating the low- where L ∈ R|V|×rL and r
L
≪ |V|. With this assumption,
rank representation of all those links that it covers. A neural Σ is positive semi-definite and we can consider each row of
d5
Mean CC ono dn id tii oti no an la Tl T ripri p
Observations
.............. .............. Observations
Inter-trip
... ... EmbL ein dk d ing . .. .. .. .. .. .. ....... .. .. .. .. .. .. ..................... . .. .. .. .. .. .. ...... . .. .. .. .. .. .. . C CIo onr rtr rre eal l-a atrt tii ipo o n n + JoJ Dio n Di itn s iPt ts rP tr ibror i ubbo tuab iotba i noib l nii tl yit y Cond Eit sio timna al tD ioe nnsity CQ Po rnu ode bir Dt ay io ib sT n i tlr ra iti ip y bl P uDC tr iio o osbn ntrad ibi bt ui io l tit in oya nl
Noise
Variance
Low-rank Representation Matrix
p Maximum
Original Augmented Gradient Backpropagation Likelihood Loss
Data Data
Sharing Process Training Process Inference Process Neural Network Mathematical Calculation Observation Distribution
Fig.1. OverallarchitectureofProbTTE.
in deriving the distribution of trip travel time. We define
2 4 3
the representation of a trip (as a row vector) to be the
3 2
1 5 1 4 path-based-sum of link representation vectors, i.e., ML, with
M ∈ {0,1}1×|V|. The mean travel time on a path becomes
7 Contraction 6
6 5 M(Lw µ)=(ML)w µ can be directly computed from the trip
10 representation ML.
8 9 7 Forthetrip-levelrandomeffectsϵ inEq.(2),weassume
l,i,q
that it has a zero mean, i.e., E(ϵ )=0, and the covariance
l,i,q
Fig.2. Graphnodecontraction. Cov(ϵ ,ϵ ) = δ(i,i′) × δ(q,q′) × Σ (l,l′), where
l,i,q l′,i′,q′ p
δ(q,q′) = 1 when q = q′ and 0 otherwise, and Σ is
p
L as a representation vector of a link/segment. We adopt a a |V| × |V| covariance matrix for modeling intra-trip error
multilayer perceptron f (·) to learn the global mean of travel correlations.Notethatweassumethattrip-levelrandomeffects
µ
time based on the representation matrix L arise from driver/vehicle heterogeneity so that Σ p is universal
and shared for all trips. This assumption posits that the trip-
µ=Lw µ, (5) level random effects are only correlated within the same trip
where w
µ
∈ RrL is a parameter vector to be learned. and are independent between different trips.
For Σ , we propose a parameter-efficient low-rank-plus-
CombiningEqs.(5)and(4),wecanspecifythejointGaussian p
diagonal paramterization to ensure that it is positive definite:
distribution based on the link representation matrix L. It
should noted that the modeling of µ is not limited to the Σ =HH⊤+D, (7)
p
segment feature L. One can also introduce other features that
are available, such as driver/vehicle profile, time of day, day where H ∈ R|V|×rH with r H ≪ |V| and D ∈ R|V|×|V|
of week, public holiday information, and weather conditions. is diagonal matrix with D i,i > 0 for i = 1,...,|V|. In
This will create a more comprehensive mean process. For the neural network, we use a Softplus function nested with
example, Ref. [30] introduces representation learning for rare
multilayerperceptiontomodelthediagonalentriesdiag(D)=
temporal conditions such as events and holidays. log(1+exp(f d(H))) where f d(H) = Hw d and w d is a
In addition to computational efficiency, the proposed spec- vector of length r H. Similar to L, we can also perform
ification also provides excellent contraction properties and contractions on the learned matrix H and the vector diag(D).
facilitates the aggregation of unimportant nodes in V. For
example, the contractions of links {1,2} and {8,9,10} in C. Joint Distribution for Multiple Trips in a Day
Figure 2 can be achieved by introducing a 7 × 10 binary
A key challenge in learning the link representations is that
mapping matrix
trip-level link travel time t is not observable in the raw
l,i,q
 1 1  GPS data. Instead, what we have is the final travel time for
(cid:104) (cid:105)⊤


1 

a trip. Let τ
i
= τ i1,...,τ iQi ∈ RQi be the travel time
M =

...  . (6) observations for all trips on days i, where Q
i
is the total
  number of trips on day i. We define a transformation matrix
 1 
1 1 1
A
i
= [a q,l] ∈ {0,1}Qi×|V|, where a
q,l
= 1 if trip q uses link
l and 0 otherwise, and denote the q-th row in A by Aq. We
i i
Given the affine property of the Gaussian distribution, define B = blkdiag({Aq}) of size Q ×Q |V| as a block
the mean travel time in the simplified network is µ′ = i i i i
diagonal matrix composed of each row in A . Marginalizing
i
Mµ = MLw and the covariance matrix becomes Σ′ =
µ d theday-specificandtrip-specificrandomeffectsinEq.(2),the
ML(ML)⊤. This corresponds to having a new representation
joint distribution of τ can be derived as
i
matrix L′ = ML. This affine property can further help us
τ ∼N (cid:0) A µ,A Σ A⊤+B (I ⊗Σ )B⊤(cid:1) , (8)
i i i d i i Qi p i6
where I Qi is an identity matrix of size Q i and ⊗ is the 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0
Kronecker product operator. As can be seen, the distribution A = 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 i
in Eq. (8) implies that the travel times of two trips (q and q′) 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1
(cid:16) (cid:17)
on the same day are not independent, i.e., Cov τ iq,τ iq′ ̸=0. tn
e
With the distribution in Eq. (8), we can learn the repre- m 1 0 0 0 0 0 0 1 0 0 0 0 0 0
g
sentation matrices (L and H) and the two parameter vectors Au 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0
(w and w ) by maximum likelihood. The total number 1 1 1 0 0 0 0 1 1 1 0 0 0 0
µ d
0 0 1 0 0 0 0 0 0 1 0 0 0 0
of parameters is |V| × (r + r + 2), and the parameters
L H Aˆ = 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0
are shared for all trips on the road network. As mentioned, i
0 0 1 1 1 0 0 0 0 1 1 1 0 0
the parameters are designed for a specific time window of 0 0 0 1 1 0 0 0 0 0 1 1 0 0
the day. Given the dynamic nature of traffic demand, time- 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0
varying link representation matrices {Lt,Ht} are used to 0 0 0 1 1 1 1 0 0 0 1 1 1 1
dynamically model the joint probability distribution. Here,
we employ a simple method to discretize time for temporal Fig.3. Illurstrationforsub-samplingdataaugmentation.
modeling, with one day divided into several time intervals.
Within each interval t, a separate set of embedding vectors
limited GPS accuracy during the sub-sampling process, we
{Lt,Ht,wt,wt} is learned. We omit the time-interval index
µ d only consider samples at the sub-trip granularity rather than
t for the rest of this paper.
at the link granularity. Excessively fine-grained sub-sampling
The parameter θ = {L,H,w ,w } of the model can be
µ d may result in unreliable travel times for the samples.
learnedbymaximizingthelog-likelihoodofalltriptraveltime
WeillustrateinFigure3asimplewayofcreatingsub-trips.
observations. The log-likelihood of observing τ is
i Here, we have 3 full trips that use 7 links. Directly following
L(θ;τ )∝−1(cid:104) logdet(Σ˜)+(τ −µ˜)⊤Σ˜−1(τ −µ˜)(cid:105) , Eq.(8)willresultintheunidentifiabilityissue.Tomakeuseof
i 2 i i those intermediate GPS data points, for each trip we generate
(9)
twosubtripsbyrandomlyselectingtwointermediateGPSdata
where µ˜ = A µ and Σ˜ = A Σ A⊤ + B (I ⊗ Σ )B⊤.
i i d i i Qi p i points andconsider them as theendpoints of thetwo subtrips.
Calculating the log-likelihood requires computing the inverse
We treat the main trip and the two derived sub-trips as a
andthedeterminantofΣ˜ ofsizeQ i×Q i,withtimecomplexity set, and use this entire set to form a selection matrix Aˆq
of O(Q3 i). In practice, the number of trips Q i is often much from the vector Aq. The block diagonal matrix Bˆ can also bei
larger than |V|, and this becomes computationally infeasible. i
constructed accordingly. Through this method, the augmented
The issue can be potentially addressed by using a small batch
dataset now includes 9 trips due to the added intermediate
size, which can still support the learning of all parameters.
GPS points, thus enhancing parameter learning. In this work,
Nevertheless, this still requires the inversion of a matrix that
we sub-sample each original GPS trajectory T0 of a trip into
matchesthebatchsize,andemployingasmallbatchsizecould
k new samples with a stride of rate η ≤ 1:
result in inefficient training. In fact, we can effectively reduce k

the computational cost by leveraging the Woodbury matrix T1 =Sub(T,η)={l ,...,l },
 1 η|T|
identity and the companion matrix determinant lemma: ... (12)
 Tk =Sub(T,ηk)={l ,...,l }.
Σ˜−1 =Λ−1−Λ−1V(I +V⊤Λ−1V)−1V⊤Λ−1, (10) 1 ηk|T|
rL
As can be seen, in this sub-sampling procedure, sub-trip
det(Σ˜)=det(I +V⊤Λ−1V)det(Λ), (11)
rL Tk is created by selecting the first ηk|T| GPS points from
where Λ=B (I ⊗Σ )B⊤ is a diagonal matrix, V =A L the original trip, and we keep the trip start points to be the
i Qi p i i
is a matrix of size Q × r , and VV⊤ = A Σ A⊤. With same for a set of trips. One can also use other approaches
i L i d i
this procedure, the inverse Σ˜−1 and its determinant can be such as randomly selecting the startpoints and endpoints from
calculated from (I+V⊤Λ−1V) of size r ×r . available GPS data in creating sub-trips. For a mini-batch
L L
consisting of b full trips T =
(cid:8) T0,...,T0(cid:9)
, we create
D. Data Augmentation for Link Representation Learning k extra sub-trips (cid:8) T1,...,Tk(cid:9) for e1 ach tripb T0 following
q q q
theaforementionedprocedure.Theaugmentedmini-batchcan
The joint distribution specified in Eq. (8) is designed for
be represented by Tˆ = {{T0,...,Tk},...,{T0,...,Tk}},
modeling overall trip travel time. This implies that only 1 1 b b
with b(k + 1) trips in total. The joint distribution of τˆ =
the initial and the final GPS data points are utilized, while i
[τ0,...,τk,...,τ0,...,τk]⊤ ∈R(k+1)b becomes:
the information in all the intermediate GPS data points is 1 1 b b
disregarded.Consequently,itbecomeschallengingtoinferthe τˆ ∼N (cid:16) Aˆ µ,Aˆ Σ Aˆ⊤+Bˆ (I ⊗Σ )Bˆ⊤(cid:17) , (13)
distribution of day-level and trip-specific random effects, as
i i i d i i Qi p i
they are only accessible through the aggregation by A i. To where Aˆ
i
is composed by stacking {Aˆq i}b
q=1
with Aˆq
i
∈
address this issue, we propose a sub-sampling data augmen- {0,1}(k+1)×|V| being the augmented selection matrix for trip
tation approach of trips to effectively utilize the whole GPS q, and Bˆ = blkdiag({Aˆq}). The distribution of the aug-
i i
trajectory of a trip. The original GPS sequence is subsampled
mented trips (Eq. (13)) allows for more fine-grained gradient
to generate the sub-trips based on the observed GPS points.
backpropagation in learning the representations for individual
Particularly, considering the potential errors introduced by the
B
ˆB
i
i
=
=7
links than the original distribution in Eq. (8). Algorithm 1 ProbTTE Training Process
In terms of computation, the likelihood can still be calcu- Input: batches of trips {T ,...T }
1 b
lated following Eq. (9). However, when applying the Wood- Output: travel time distribution τ ∼N(µ,Σ) of trips
bury matrix identity and the matrix determinant lemma, we
notethatΛˆ =Bˆ (I ⊗Σ )Bˆ⊤ becomesab(k+1)×b(k+1) 1: Initialize link embedding network E_Net1(), E_Net2()
block diagonal
i maQ tri
ix,
fop
r
wi
hich both the inverse and the
2: Initialize multi-layer perceptrons f µ(),f d()
determinant can be efficiently computed by working on each 3: L,H =E_Net1(l),E_Net2(l)
of the (k+1)×(k+1) blocks. 4: A=zeros(b,|V|)
5: B =zeros(b,b×|V|)
E. Conditional Travel Time Estimation based on Joint Prob- 6: for each T i do
ability Distribution 7: for each l∈T i do
The joint distribution of trip travel times in Eq. (8) gives 8: A i,l =1
Cov(cid:16) τq,τq′(cid:17) =AqΣ Aq′ = (cid:88) (cid:88) Σ (l,l′), (14) 9: B i,⌊i/(k+1)⌋∗|V|+l =1
i i i d i d 10: end for
l∈Tql′∈T q′ 11: end for
i.e., the covariance between two trips becomes the applying 12: µ=f µ(AL)∈Rb×1
row-sum for l ∈ T q and then column-sum for l′ ∈ T q′ on 13: D =log(1+exp(f d(H)))∈Rb×b
the covariance matrix Σ . This indicates that any two trips
in a given day are
correld
ated, and the inter-trip correlation is
14: Σ=AL(AL)⊤+B(I b⊗(HH⊤+D))B⊤ ∈Rb×b
15: L=−logN(τˆ|µ,Σ)
determined by the values used in Σ . This result also means
d
that we can make predictions for an unseen trip conditional 16: Backpropagation and update model parameters.
onthecorrelatedtripsthatarefinishedwithinthestudiedtime
window on the same day.
trips. For deterministic prediction, we can simply take the
Toestimatethetraveltimedistributionofaqueriedtrip,we
mean A(µ+µ∗) as the point estimate. The training process
can first explicitly estimate the distribution of η from those
(cid:20) η(cid:21) i is summarized in Algorithms 1.
completed trips. Let be a vector built by stacking the
τ
o
day-specific random effects η and (augmented) travel time τ V. EXPERIMENT
o
of those completed trips on day i. Note that the day index i is A. Datasets and Baselines
omittedforsimplicity.Then,wecanderiveitsjointdistribution
WeevaluateProbTTEontwopubliclyavailableGPStrajec-
as:
tory datasets from taxi/ride-hailing services: Chengdu: With
(cid:20) η(cid:21) ∼N (cid:18)(cid:20) 0 (cid:21) ,(cid:20) Σ d Σ dA⊤ o (cid:21)(cid:19) ,3,186linksand346,074samplesspanning6days,traveltimes
τ o A oµ, A oΣ d A oΣ dA⊤ o +B o(I⊗Σ p)B o⊤ rangefrom420to2880seconds,withameanof786seconds;
(15)
Harbin: With 8,497 links and 1,268,139 samples spanning
and the conditional distribution p(η |τ =v) is also a Gaus-
o 6 days, travel times range from 420 to 2994 seconds, with
sian N (µ∗,Σ∗), where
a mean of 912 seconds. The code and data are available at
µ∗ =Σ A⊤(A Σ A⊤+B (I⊗Σ )B⊤)−1(v−A µ), https://github.com/ChenXu02/ProbTTE.
d o o d o o p o o
Weselectedfivestate-of-the-artmodelsasbaselines,includ-
Σ∗ =Σ −Σ A⊤(A Σ A⊤+B (I⊗Σ )B⊤)−1Σ A⊤.
d d o o d o o p o d o ing three deterministic models and two probabilistic models.
This conditional distribution can be also derived using preci- Deterministic models:
sion matrix (i.e., the inverse of covariance), as η | τ o = v ∼ • DeepTTE[11]isamodelthatlearnsspatialandtemporal
N
(cid:0) µ∗,(Λ∗)−1(cid:1)
, where dependencies from raw GPS sequences through a geo-
based convolutional layer and recurrent neural networks.
Λ∗ =A⊤ o (cid:0) B o(I⊗Σ p)B o⊤(cid:1)−1 A o+Λ d, • HierETA [21] is a model that utilizes segment-view,
µ∗ =(Λ∗)−1(cid:16) A⊤(cid:0) B (I⊗Σ )B⊤(cid:1)−1 (v−A µ)(cid:17) , link-view,andintersectionrepresentationstoestimatethe
o o p o o
time of arrival. It captures local traffic conditions, shared
and Λ =Σ−1. trajectory attributes within links, and indirect factors,
d d
This result is consistent with the estimator derived in [1]; respectively, in a hierarchical manner.
however,ourmodelexplicitlylearnsthespatialstructureofΣ • MulT-TTE [10] is a model that utilizes a multi-
d
and Σ using neural networks, instead of using oversimplified perspective route representation framework. It incorpo-
p
prior specifications. For the travel time τ of a queried trip rates trajectory, attribute, and semantic sequences, to-
with link incident matrix A, we can derive its distribution gether with a path-based module and self-supervised
conditional on observed trip analytically: learning task, to enhance context awareness and improve
segment representation quality for TTE.
τ|τ =v ∼N (cid:0) A(µ+µ∗),A(Σ∗+Σ )A⊤(cid:1) . (16)
o p Probabilistic models:
The conditional distribution obtained above, p(τ |τ o), can • DeepGTT [25] is a model that learns travel time distri-
produce travel time statistics (mean/variance) of the query butions by incorporating spatial smoothness embeddings,8
TABLEII
MODELPERFORMANCECOMPARISONONCHENGDUANDHARBINDATASETS.
Chengdu Harbin
Model
RMSE MAE MAPE(%) CPRS RMSE MAE MAPE(%) CPRS
DeepTTE 181.31 130.10 17.20 — 224.23 162.59 18.36 —
HierETA 155.26 111.34 14.68 — 187.93 136.45 15.62 —
MulT-TTE 149.77 105.63 13.89 — 178.39 129.81 14.86 —
DeepGTT 165.17 118.68 15.65 1.46 191.23 143.97 16.41 1.56
GMDNet 151.43 107.73 13.97 1.31 176.98 128.11 14.65 1.41
ProbTTE† 134.79 95.11 12.31 1.18 156.94 112.15 12.82 1.24
ProbTTE 131.25 93.73 12.14 1.15 153.27 111.14 12.71 1.22
Improvement 12.37% 11.27% 12.60% 12.21% 13.40% 13.25% 13.24% 13.48%
amortization for road segment modeling, and a convo- the probabilistic baselines by over 1.83% in MAPE and over
lutional neural network for real-time traffic condition 0.16inCRPS.Comparedtothebestbaseline,ProbTTEshows
representation learning. a relative average improvement of 12.11%. In the Harbin
• GMDNet[26]isamodelthatestimatestraveltimedistri- dataset, ProbTTE outperforms the deterministic baselines by
bution by employing a graph-cooperated route encoding over 2.15% in MAPE and the probabilistic baselines by over
layertocapturespatialcorrelationsandamixturedensity 1.94% in MAPE and over 0.19 in CRPS, respectively. Our
decoding layer for distribution estimation. model’s performance has a relative average improvement of
We also include a variant of our model, ProbTTE† in the 13.34%. For the variant model ProbTTE†, its performance
comparison,whichremovestheconditionalestimationcompo- in terms of MAPE is slightly lower than the full model
nent and is used to evaluate the naive predictive performance ProbTTE by 0.17% and 0.11% on the Chengdu and Harbin
of our model when conditional information is unavailable. datasets, respectively. However, it still maintains a significant
We randomly select 70% of the dataset as the training set, advantage over the baseline models. This indicates that joint
15%asthevalidationset,and15%asthetestingset.Interms probabilitymodelingacrossmultipletripscaneffectivelylearn
of the model setting of ProbTTE, the batch size is b = 64, correlations between trips, thus improving the accuracy of
andtheembeddingdimensionofthelinkrepresentationvector travel time estimation.
r = r = 36. The time discretization coefficient p = 24. To further investigate the reasons for model superiority, we
L H
All models achieve optimal performance by training for 100 constructed three variants of ProbTTE focusing on Multi-trip
epochs on the 12th Gen Intel(R) Core(TM) i9-12900K CPU Modeling, Data Augmentation, and Time Discretization:
and NVIDIA Tesla V100 GPU. We choose four general • ProbTTE-w/o MT: The multi-trip modeling component
evaluation metrics: Root Mean Square Error (RMSE), Mean is removed. Each batch contains only one trip, and the
AbsoluteError(MAE),MeanAbsolutePercentError(MAPE), correlations between trips are not modeled.
and Continuous Ranked Probability Scores (CRPS): • ProbTTE-w/o DA: The data augmentation component is
(cid:115) removed. The trips are not subsampled, and only the
RMSE= 1 (cid:88) (τ˜ −τˆ)2, (17) original trip samples are used to train the model.
|D| i∈D i i • ProbTTE-w/o TD: The time discretization component is
removed. Only one set of parameters is used to learn the
1 (cid:88) link embedding vector for all time periods.
MAE= |τ˜ −τˆ|, (18)
|D| i∈D i i We conducted ablation experiments on the Chengdu and
Harbin datasets to analyze the effects of those components.
(cid:12) (cid:12)
MAPE=
1 (cid:88) (cid:12) (cid:12)τ˜ i−τˆ i(cid:12)
(cid:12), (19)
The results of the ablation experiments are shown in Ta-
|D| i∈D(cid:12) τˆ
i
(cid:12) ble III. We can see that multi-trip joint modeling is the
primary source of advantage for our model, contributing to a
CRPS= 1 (cid:88) (cid:90) (F(τ )−1 )2dτ , (20) 2.11% and 2.59% improvement in reducing MAPE. The data
|D| i∈D i {τi≥τˆi} i augmentation based on subsampling has reduced MAPE by
0.52%and0.44%,achievingperformanceimprovementsolely
whereF(τ )isthecumulativedistributionfunctionofτ .τ˜ is
i i i through reasonable segmentation of the original data without
arandomlysampledvaluefromthedistributionofτ ofquery
i adding any model parameters. Time discretization resulted in
trip travel time and τˆ is the ground truth.
i gains of 0.48% and 0.32% for the model.
B. Model Evaluation and Ablation Study C. Interpretability Analysis of Link Embedding Vectors
We summarize the experimental results in Table II. As can We analyze the interpretability of link embedding vectors
beseen,theproposedProbTTEframeworkclearlyoutperforms and correlations on the Harbin dataset through data visual-
all baseline models. In the Chengdu dataset, ProbTTE outper- ization. We visualized the learned link correlations Σ and
d
formsthedeterministicbaselinesbyover1.75%inMAPEand Σ in two time periods (9:00-10:00 AM and 9:00-10:00
p9
TABLEIII
ABLATIONEXPERIMENTONCHENGDU/HARBINDATASET.
Model RMSE (s) MAE (s) MAPE (%) CRPS
w/o MT 155.63/187.67 110.06/134.77 14.25/15.30 1.39/1.47
w/o DA 137.82/161.98 97.75/115.34 12.66/13.15 1.20/1.27
w/o TD 135.37/160.10 96.68/113.91 12.62/13.03 1.20/1.26
ProbTTE 131.25/153.27 93.73/111.14 12.14/12.71 1.15/1.23
0 1.00 0 1.00 0 1.00 0 1.00 0 1.00
0.75 0.75 0.75 0.75 0.75
10 0.50 10 0.50 10 0.50 10 0.50 10 0.50
20 0.25 20 0.25 20 0.25 20 0.25 20 0.25
0.00 0.00 0.00 0.00 0.00
30 0.25 30 0.25 30 0.25 30 0.25 30 0.25
0.50 0.50 0.50 0.50 0.50
40 40 40 40 40
0.75 0.75 0.75 0.75 0.75
1.00 1.00 1.00 1.00 1.00
0 20 40 0 20 40 0 20 40 0 20 40 0 20 40
(a) Σ d during9:00-10:00AM (b) Σpduring9:00-10:00AM (c) Σ d during9:00-10:00PM (d) Σpduring9:00-10:00PM (e) Realadjacencymatrix
7 1.00 7 1.00
44 55 .. 77
6
Target Link 0000 .... 10000257 ....0505
0752 0505
44 55 .. 77
6
Target Link 0000 .... 10000257 ....0505
0752 0505
00 0.. .02
2
15 118716 11 94
16
5
432
0
1 8311 02
9
7
11 444 555 ... 777 556 050
14
15 11 36
1 17 211 81
19210
3
49 58 607
1
126.59 126.60 126.61 126.59 126.60 126.61 0.2 0.0 0.2 126.64 126.65 126.66
Longitude Longitude Principal Component 1 Longitude
(f) LinkcorrelationheatmapfromΣ d (g) LinkcorrelationheatmapfromΣp (h) Visualizationofembeddingvectors (i) Visualizationoflinklocations
Fig.4. Linkcorrelationvisualization.
PM), then compared them with the corresponding 2-hop real
Mean w/o Condition
adjacency matrix, as shown in Figure 4(a,b,c,d,e). Despite
40 Mean w/ Condition
not incorporating any network geometry information in the SD w/o Condition
SD w/ Condition
generation of link representations L and H, the derived link Observation
30
correlations still effectively capture the essential geometry in-
formationoftheroadnetwork.Comparedtotherealadjacency
20
matrix, the learned link correlations are more flexible and
can adaptively construct correlations for different links. For
10
example, some link correlations may have weak extensions,
with high correlations lasting only 1 or 2 hops, while other
1 2 3 4 5 6 7 8
links may exhibit stronger extensions, with high correlations Trip Trajectory
persisting over multiple hops. In Σ , the learned correlations
d Fig.5. Cumulativetraveltime(min)estimation:shadedareashowsµ±σ.
are smoother, reflecting global low-frequency characteristics,
while in Σ , the learned correlations are sharper, representing
p
high-frequency characteristics.Additionally, thecorrelation of compared them with their actual map locations. As illustrated
links shows noticeable variations across different periods: it in Figure 4(h,i), vectors that are nearer in the representation
is stronger during peak hours and relatively weaker at night. spacegenerallycorrespondtolinksthatarecloseronthemap.
In Figure 4(f,g), we randomly selected a link and visualized Moreover, link representation vectors that run in the same
its correlations with other links in 9:00-10:00 AM on the direction on the same road tend to have higher similarity,
real map and we can see that Σ indeed demonstrate long- whereas vectors from different roads show lower similarity.
d
range correlations, while the correlation structure in Σ is These results further confirm the effectiveness of {L,H} as
p
more local. Overall, the obtained Σ and Σ are consistent link representations.
d p
with our prior specification in Eq. (2), where Σ and Σ are We next visualize the mean and variance of travel times at
d p
used for modeling inter-trip correlation and intra-trip corre- the link level from one selected trip, which is divided into 8
lation, respectively. Next, we utilized Principal Component segments with equal intervals of GPS points. Two scenarios
Analysis (PCA) to project the comprehensive representations are considered: with condition and without condition. In the
of the link vectors {L,H} into a two-dimensional space, and conditional case, the travel times of 32 completed trips are
edutitaL edutitaL 2 tnenopmoC
lapicnirP
emiT
levarT
edutitaL10
17 Chengdu 14.75 Chengdu 14.0 Chengdu
Harbin Harbin Harbin
14.50
16 14.25 13.5
14.00 13.0
15
13.75
12.5
14 13.50
32 64 128 256 1 2 3 4 5 6 7 12346812 24 72
Batch Size of Joint Distribution Number of Subsampling Samples Time Discretization Coefficient
(a) Thebatchsizeofjointdistribution. (b) Thegranularityofsubsampling. (c) Thegranularityoftimediscretization.
Fig.6. Performancemetricsassociatedwithdifferentconfigurations.
used as conditional information to adjust the distribution of 3) The granularity of time discretization: We conducted a
the travel time for each link in the query trip. In the without- performance evaluation on temporal discretization based on
conditional case, only the learned link representation vectors theparametersdeterminedinthepreliminaryexperiments.We
are used to compute the mean and variance of the link travel divided one day into p = {1,2,3,4,6,8,12,24,72} periods
times. The results, as shown in Figure 5, demonstrate that our and independently learned link embedding vectors for each
model maintains good estimation performance and stability period using separate parameters. As shown in Figure 6(c),
at the link level. The introduction of conditional information the results indicate that the introduction of new trainable
significantly reduces the prediction error and variance, and parameters improved the model performance. Fine-grained
this positive adjustment becomes more apparent as the trip time discretization enables more accurate learning of link
progresses. correlations, thereby enhancing model performance.
D. Analysis of Model Parameters E. Analysis of Time Complexity
1) The batch size of the joint distribution: We conducted The time complexity of ProbTTE mainly comes from
a performance comparison of our model across various batch the mean and diagonal mapping, correlation computation,
sizes of the joint distribution. To isolate the effects of other maximum likelihood estimation, and conditional distribution
factors, we avoided introducing conditional trips, data aug- estimation. The time complexity of mean and diagonal map-
mentation, and time discretization. Therefore, our comparison ping is O(Nr). In correlation computation, the computational
solely reflects the performance achieved through multi-trip complexity is influenced by the number of trips in one joint
joint modeling using the original data. To enhance experi- probability distribution (batch size) b. N samples are divided
mental efficiency, we adopted an exponential increase in the into N/b batches, and the correlation of trips is calculated
batch size, evaluating performance using {1, 2, 4, 8, 16, within each batch. The time complexity for calculating the
32, 64, 128, 256}. As shown in Figure 6(a), the multi-trip inner product pairwise within each batch is O(b2r). So the
jointmodelingsignificantlyimprovedpredictionperformance. total time complexity for correlation computation is N/b ∗
When the batch size in the joint modeling increased, the O(b2r) = O(Nbr), where r ≪ N. The final part of the
MAPE saw a significant decline. However, upon reaching a computational complexity arises from maximum likelihood
specific threshold (approximately 32 trips), this decreasing estimation and conditional distribution estimation. In these
trend slowed, and with additional increases in the number of processes, with the help of the Woodbury Matrix Identity
trips, the MAPE started to increase marginally. We consider and the Matrix Determinant Lemma, the time complexity for
that multi-trip joint modeling offers additional information, invertingthecovariancematrixandcalculatingthedeterminant
allowing the model to identify relationships between trips. is O(rb2), for N/b batches, the total time complexity is
However, an excessively large batch size might strain the O(Nbr). Therefore, the overall time complexity of ProbTTE
model’s optimization, making it more difficult to further is O(Nr)+O(Nbr)+O(Nbr) = O(Nbr), where b ≪ N,
improveperformanceandpotentiallyleadingtoaperformance and r ≪b in general.
plateau. We also conducted a comparison of the actual runtime of
2) The granularity of subsampling in data augmentation: our model and the baselines. We recorded the time it took
We analyzed the impact of data augmentation granularity to train and infer one epoch for each model on the Chengdu
on model performance. The original data was subsampled and Harbin datasets. The device used for execution was an
to generate {2, 3, 4, 5, 6, 7} sub-trips, and the results are NVIDIA Tesla V100 GPU, and the runtime is shown in
shown in Figure 6(b). In this evaluation, we followed the Table IV. The results indicate that our model achieves excel-
previous experiment and used 64 trips for joint modeling. As lentperformancewithoutintroducingexcessivecomputational
thegranularityofdataaugmentationbecomesfiner,themodel overhead.
performance gradually improves. When the granularity is 1
5
(number of subsampling samples is 5) the model performance VI. CONCLUSION
reaches its optimum, and finer granularity does not lead to In this paper, we propose ProbTTE, a probabilistic TTE
further improvement in performance. model designed to capture the joint probability distribution
)%(EPAM )%(EPAM )%(EPAM11
TABLEIV
RUNTIME(S)OFMODELS.
Model DeepTTE HierETA MulT-TTE DeepGTT GMDNet ProbTTE
Chengdu 70.24 104.91 153.30 44.16 115.66 92.31
Harbin 199.67 349.50 491.45 158.91 425.37 315.64
of multiple trips. By introducing a covariance representation [8] H. Wang, Z. Zhang, Z. Fan, J. Chen, L. Zhang, R. Shibasaki, and
paradigmbasedonlow-ranklinkrepresentation,weeffectively X.Song,“Multi-taskweaklysupervisedlearningfororigin-destination
travel time estimation,” IEEE Transactions on Knowledge and Data
modeled correlations between trips with low time complexity
Engineering,2023.
and the learned representation gives favorable contraction [9] L.Han,B.Du,J.Lin,L.Sun,X.Li,andY.Peng,“Multi-semanticpath
properties. The use of subsampling data augmentation fa- representation learning for travel time estimation,” IEEE Transactions
onIntelligentTransportationSystems,vol.23,no.8,pp.13108–13117,
cilitated gradient propagation at the link level, resulting in
2021.
the interpretable optimization of link representation vectors. [10] T.Liao,L.Han,Y.Xu,T.Zhu,L.Sun,andB.Du,“Multi-facetedroute
ProbTTEdemonstratedexceptionalperformanceonreal-world representation learning for travel time estimation,” IEEE Transactions
onIntelligentTransportationSystems,2024.
datasets,outperformingstate-of-the-artdeterministicandprob-
[11] D.Wang,J.Zhang,W.Cao,J.Li,andY.Zheng,“Whenwillyouarrive?
abilistic baselines by 12.11% and 13.34% on average, respec- estimatingtraveltimebasedondeepneuralnetworks,”inProceedings
tively.Ablationexperimentsandvisualanalysesconfirmedthe oftheAAAIconferenceonartificialintelligence,vol.32,no.1,2018.
[12] Y. Sun, K. Fu, Z. Wang, D. Zhou, K. Wu, J. Ye, and C. Zhang, “Co-
effectivenessofeachmodelcomponentandtheinterpretability
driver eta: Combine driver information in estimated time of arrival by
of the learned link representation vectors. Additionally, time drivingstylelearningauxiliarytask,”IEEETransactionsonIntelligent
complexity analysis and runtime comparisons illustrated that TransportationSystems,vol.23,no.5,pp.4037–4048,2020.
[13] Y. Ye, Y. Zhu, C. Markos, and J. James, “Cateta: A categorical
ProbTTE maintainsalowcomputationalburdenwhileachiev-
approximateapproachforestimatingtimeofarrival,”IEEETransactions
ing superior performance in jointly modeling multiple trips. onIntelligentTransportationSystems,vol.23,no.12,pp.24389–24400,
In terms of future work, we plan to further explore the 2022.
[14] J.Qiu,L.Du,D.Zhang,S.Su,andZ.Tian,“Nei-tte:Intelligenttraffic
continuous modeling of link embedding vectors. Specifically,
timeestimationbasedonfine-grainedtimederivationofroadsegments
dynamic graph neural networks can be designed to learn low- for smart city,” IEEE Transactions on Industrial Informatics, vol. 16,
rank temporal feature representations on a graph Laplacian no.4,pp.2659–2666,2019.
[15] Z. Wang, K. Fu, and J. Ye, “Learning to estimate the travel time,”
basis from observed trips. Recurrent neural networks can
inProceedingsofthe24thACMSIGKDDinternationalconferenceon
subsequently be leveraged to capture the evolution of link knowledgediscovery&datamining,2018,pp.858–866.
embedding vectors based on the contextual information of [16] H. Hong, Y. Lin, X. Yang, Z. Li, K. Fu, Z. Wang, X. Qie, and J. Ye,
“Heteta:Heterogeneousinformationnetworkembeddingforestimating
observedtrips.Webelievethattheseenhancementswillenable
timeofarrival,”inProceedingsofthe26thACMSIGKDDinternational
the model to better perceive temporal trends and facilitate conference on knowledge discovery & data mining, 2020, pp. 2444–
the modeling of travel time distributions across multiple time 2454.
[17] X.Fang,J.Huang,F.Wang,L.Zeng,H.Liang,andH.Wang,“Constgat:
horizons.
Contextual spatial-temporal graph attention network for travel time
estimation at baidu maps,” in Proceedings of the 26th ACM SIGKDD
REFERENCES
International Conference on Knowledge Discovery & Data Mining,
2020,pp.2697–2705.
[1] C. Yan, J. Johndrow, D. Woodard, and Y. Sun, “Efficiency of eta [18] Q.Wang,C.Xu,W.Zhang,andJ.Li,“Graphtte:Traveltimeestimation
prediction,”SIAMJournalonMathematicsofDataScience,vol.6,no.2, based on attention-spatiotemporal graphs,” IEEE Signal Processing
pp.227–253,2024. Letters,vol.28,pp.239–243,2021.
[2] Y. Wang, Y. Zheng, and Y. Xue, “Travel time estimation of a path [19] A. Derrow-Pinion, J. She, D. Wong, O. Lange, T. Hester, L. Perez,
using sparse trajectories,” in Proceedings of the 20th ACM SIGKDD M.Nunkesser,S.Lee,X.Guo,B.Wiltshireetal.,“Etapredictionwith
international conference on Knowledge discovery and data mining, graphneuralnetworksingooglemaps,”inProceedingsofthe30thACM
2014,pp.25–34. international conference on information & knowledge management,
[3] H.Wang,X.Tang,Y.-H.Kuo,D.Kifer,andZ.Li,“Asimplebaseline 2021,pp.3767–3776.
fortraveltimeestimationusinglarge-scaletripdata,”ACMTransactions [20] G.Zou,Z.Lai,C.Ma,M.Tu,J.Fan,andY.Li,“Whenwillwearrive?
onIntelligentSystemsandTechnology(TIST),vol.10,no.2,pp.1–22, anovelmulti-taskspatio-temporalattentionnetworkbasedonindividual
2019. preferenceforestimatingtraveltime,”IEEETransactionsonIntelligent
[4] Y. Li, K. Fu, Z. Wang, C. Shahabi, J. Ye, and Y. Liu, “Multi-task TransportationSystems,2023.
representationlearningfortraveltimeestimation,”inProceedingsofthe [21] Z.Chen,X.Xiao,Y.-J.Gong,J.Fang,N.Ma,H.Chai,andZ.Cao,“In-
24thACMSIGKDDinternationalconferenceonknowledgediscovery& terpretingtrajectoriesfrommultipleviews:Ahierarchicalself-attention
datamining,2018,pp.1695–1704. networkforestimatingthetimeofarrival,”inProceedingsofthe28th
[5] H.Yuan,G.Li,Z.Bao,andL.Feng,“Effectivetraveltimeestimation: ACMSIGKDDConferenceonKnowledgeDiscoveryandDataMining,
Whenhistoricaltrajectoriesoverroadnetworksmatter,”inProceedings 2022,pp.2771–2779.
of the 2020 acm sigmod international conference on management of [22] C.Wang,F.Zhao,H.Zhang,H.Luo,Y.Qin,andY.Fang,“Fine-grained
data,2020,pp.2135–2149. trajectory-basedtraveltimeestimationformulti-cityscenariosbasedon
[6] Y. Lin, H. Wan, J. Hu, S. Guo, B. Yang, Y. Lin, and C. S. Jensen, deep meta-learning,” IEEE Transactions on Intelligent Transportation
“Origin-destinationtraveltimeoracleformap-basedservices,”Proceed- Systems,vol.23,no.9,pp.15716–15728,2022.
ingsoftheACMonManagementofData,vol.1,no.3,pp.1–27,2023. [23] X. Fang, J. Huang, F. Wang, L. Liu, Y. Sun, and H. Wang, “Ssml:
[7] I.Jindal,X.Chen,M.Nokleby,J.Yeetal.,“Aunifiedneuralnetwork Self-supervised meta-learner for en route travel time estimation at
approachforestimatingtraveltimeanddistanceforataxitrip,”arXiv baidu maps,” in Proceedings of the 27th ACM SIGKDD Conference
preprintarXiv:1710.04350,2017. onKnowledgeDiscovery&DataMining,2021,pp.2840–2848.
[24] W. Zhou, X. Xiao, Y.-J. Gong, J. Chen, J. Fang, N. Tan, N. Ma,
Q. Li, C. Hua, S.-W. Jeon et al., “Travel time distribution estimation12
by learning representations over temporal attributed graphs,” IEEE nationaljournalofforecasting,vol.36,no.3,pp.1181–1191,2020.
TransactionsonIntelligentTransportationSystems,2023.
[28] D.Salinas,M.Bohlke-Schneider,L.Callot,R.Medico,andJ.Gasthaus,
[25] X.Li,G.Cong,A.Sun,andY.Cheng,“Learningtraveltimedistribu- “High-dimensionalmultivariateforecastingwithlow-rankgaussiancop-
tionswithdeepgenerativemodel,”inTheWorldWideWebConference, ula processes,” Advances in neural information processing systems,
2019,pp.1017–1027. vol.32,2019.
[26] X. Mao, H. Wan, H. Wen, F. Wu, J. Zheng, Y. Qiang, S. Guo,
L. Wu, H. Hu, and Y. Lin, “Gmdnet: A graph-based mixture density [29] M.HaklayandP.Weber,“Openstreetmap:User-generatedstreetmaps,”
network for estimating packages’ multimodal travel time distribution,”
IEEEPervasivecomputing,vol.7,no.4,pp.12–18,2008.
inProceedingsoftheAAAIConferenceonArtificialIntelligence,vol.37, [30] N. Petersen, F. Rodrigues, and F. Pereira, “Representation learning of
no.4,2023,pp.4561–4568. raretemporalconditionsfortraveltimeprediction,”in2023IEEE26th
[27] D. Salinas, V. Flunkert, J. Gasthaus, and T. Januschowski, “Deepar: InternationalConferenceonIntelligentTransportationSystems(ITSC).
Probabilisticforecastingwithautoregressiverecurrentnetworks,”Inter- IEEE,2023,pp.4919–4926.