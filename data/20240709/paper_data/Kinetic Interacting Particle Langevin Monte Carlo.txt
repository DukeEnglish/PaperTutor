Kinetic Interacting Particle Langevin Monte Carlo
Paul Felix Valsecchi Oliva and O. Deniz Akyildiz
Department of Mathematics, Imperial College London
July 9, 2024
Abstract
This paper introduces and analyses interacting underdamped Langevin algorithms, termed Kinetic
Interacting Particle Langevin Monte Carlo (KIPLMC) methods, for statistical inference in latent variable
models. Weproposeadiffusionprocessthatevolvesjointlyinthespaceofparametersandlatentvariables
and exploit the fact that the stationary distribution of this diffusion concentrates around the maximum
marginal likelihood estimate of the parameters. We then provide two explicit discretisations of this
diffusion as practical algorithms to estimate parameters of statistical models. For each algorithm, we
obtain nonasymptotic rates of convergence for the case where the joint log-likelihood is strongly concave
with respect to latent variables and parameters. In particular, we provide convergence analysis for the
diffusion together with the discretisation error, providing convergence rate estimates for the algorithms in
Wasserstein-2 distance. To demonstrate the utility of the introduced methodology, we provide numerical
experiments that demonstrate the effectiveness of the proposed diffusion for statistical inference and the
stability of the numerical integrators utilised for discretisation. Our setting covers a broad number of
applications, including unsupervised learning, statistical inference, and inverse problems.
1 Introduction
Parametric latent variable models (LVMs) are ubiquitous in many areas of statistical science, e.g., complex
probabilistic models for text, audio, video and images [8, 63, 38] or inverse problems [64]. Intuitively, these
models capture the underlying structure of the real data in terms of low-dimensional latent variables -
a structure that often exists in real world [67]. However, latent variable models often require nontrivial
procedures for maximum likelihood estimation as this quantity is often intractable [25]. Our main aim in
this paper is to propose a set of accelerated and stable algorithms for the problem of maximum marginal
likelihood estimation in the presence of latent variables and show convergence bounds for them by studying
their nonasymptotic behaviour.
Let us consider a generic latent variable model as p θ(x,y), parameterised by θ ∈ Rdθ, for fixed data
y ∈Rdy, and latent variables x∈Rdx. This model is considered for fixed observed data y, thus formally we
see the statistical model as a real-valued mapping p θ(x,y):Rdx ×Rdθ →R. The task we are interested in is
to estimate the parameter θ that explains the fixed dataset y. Often, this task is achieved via the maximum
likelihood estimation (MLE). In accordance with this, in our setting, due to the presence of latent variables,
we aim at finding the maximum marginal likelihood estimate (MMLE) [25], more precisely, our problem takes
the form
θ¯ ∈arg max logp (y), (1)
⋆ θ
θ∈Rdθ
where p (y):=(cid:82) p (x,y)dx is the marginal likelihood (also called the model evidence in Bayesian statistics
θ θ
[7]). It is apparent from (1) that the problem cannot be solved via optimisation techniques alone, as the
marginal likelihood contains an intractable integral for most statistical models.
1
4202
luJ
8
]OC.tats[
1v09750.7042:viXraClassically, this problem is solved with the iterative Expectation-Maximisation (EM) algorithm [25],
which provably converges to a local maximum. This algorithm consists of the E and M steps: (1) the E-step
(optimally) produces an estimate for the posterior distribution of latent variables p (x|y) and (2) the M-step
θ
maximises the expected log-likelihood estimate w.r.t. the parameter θ. More compactly, starting at θ , the
0
EM algorithm produces the estimates (θ n) n∈N, solving
θ ∈arg max E [logp (x,y)].
n+1
θ∈Rdθ
pθn(x|y) θ
It is easy to establish that logp (y)≥logp (y), hence the method converges to a local maximum. In this
θn+1 θn
setting, two tasks need to be solved simultaneously: (i) inference, i.e., inferring the distribution of x given
y for θ , in other words, the posterior distribution p (x|y), (ii) estimation, i.e., estimating the maximiser
n θn
θ , whose computation requires the inference step. Often, this recursion is impossible to realise, due to two
n+1
main challenges, namely, the expectation (E) and maximisation (M) steps, which are intractable. These steps
can be approximated with a variety of methods, which, due to the simplicity of this algorithm, have been
extensively explored. For example, Monte-Carlo EM [66] and stochastic EM [14] have been widely studied,
see, e.g., [15, 16, 62, 9, 12, 26].
In the most general case, the EM algorithm is implemented using Markov chain Monte Carlo (MCMC)
techniques for the E-step, and numerical optimisation techniques for the M-step, e.g., [50, 48, 46]. With the
popularityofunadjustedLangevinmethodsinBayesianstatisticsandmachinelearning[30,29,31,20,21,23],
variants of the implementation of expectation-maximisation algorithms using unadjusted chains to perform
the E-step have also been proposed. Most notably, [24] studied an algorithm termed SOUL, which performs
unadjusted Langevin steps for the E-step and stochastic gradient ascent for the M-step, building on the ideas
of [5]. This algorithm required to run a Markov chain for each E-step, resulting in a double-loop algorithm.
The bias incurred by unadjusted chains complicates the theoretical analysis and requires a delicate balance of
the step-sizes of the Langevin algorithm and gradient step to guarantee convergence [24]. An alternative
approach was developed in [45], where instead of running Markov chains to perform E-step, the authors
proposed to use an interacting particle system, consisting of N particles. Particle systems, such as the one
proposed in [45], are often used to accelerate convergence for gradient-based methods or to replace these
entirely ([10, 54, 44, 1, 37] for a review on their advantages and behaviour). In a similar vein, [45] shows that
using an algorithm based on an interacting particle system (IPS), termed particle gradient descent (PGD),
alleviates the need of running interleaving Markov chains, which can also lead to provable guarantees, see,
e.g., [13]. Inspired by the approach in [45], a closely related interacting particle system was proposed in [2],
where a properly scaled noise is injected in the θ-dimension. This seemingly small modification is significant,
making the algorithm an instance of a Langevin diffusion (an observation we build on in this paper). The
authors termed this method interacting particle Langevin algorithm (IPLA) and proved error bounds for
the algorithm. In particular, they showed that the parameter-marginal of IPLA iterates, targets a measure
of the form π ∝exp(−Nlogp (y)), which concentrates around the MMLE estimate with a rate O(N−1/2)
Θ θ
where N is the number of particles. The authors of [2] further provided the exponential convergence rate and
the discretisation error under the within strongly convex setting. The IPLA methodology has been already
utilised in other contexts, see, e.g., [43] for superlinear extensions and [33] for a set of proximal methods
based on IPLA, and [3] for relations between IPLA and multiscale methods.
Finally, targeting this sort of measure to solve optimisation problems, is similar to simulated annealing
techniques from optimisation (see [35, 40, 28, 41] for a discussion of these methods), which is a commonly
proposed approach to MMLE estimation. In particular, [28, 41] consider particle systems and observe
sampling improvements in non-convex optimisation, motivating this alternative approach.
Contributions. In this paper, the overdamped Langevin diffusion proposed by [2] is modified by
considering the underdamped setting - resulting in another stochastic differential equation (SDE) termed,
Kinetic Interacting Particle Langevin Diffusion (KIPLD). In continuous time, our proposed diffusion
correspondstothenoisyversionofthesystemproposedin[47], oranaccelerationoftheoverdampeddiffusion
introduced by [2], see, e.g., [49]. We then propose two underdamped Langevin samplers, which we term
Kinetic Interacting Particle Langevin Monte Carlo (KIPLMC), based on this diffusion. Our contributions
can be summarised as follows:
2• WeproposetheKIPLD,adiffusionprocesstooptimisethemarginallikelihoodinlatentvariablemodels.
Our diffusion process corresponds to θ-noised version of the SDE proposed in [47]. However, in [47], the
authors left the problem of nonasymptotic analysis open. In this paper, we provide a nonasymptotic
analysis and show that the proposed modification enables us to prove that the stationary measure of
this diffusion concentrates around the MMLE (Propositions 1 and 2) and the KIPLD converges to this
measure exponentially fast (Proposition 3).
• We propose two discretisations of this diffusion to obtain practical algorithms, which we term Kinetic
Interacting Particle Langevin Monte Carlo (KIPLMC) methods. Our first algorithm KIPLMC1 corre-
sponds to a similar discretisation provided by [47] for our diffusion. However, we provide discretisation
error bounds for our method, leveraging available results in the literature, showing convergence rates in
both time and step-size (Theorem 1). We then introduce a splitting-based explicit discretisation scheme
within this setting, which leads to a nontrivial algorithm, which we term KIPLMC2. We provide a
nonasymptotic analysis of this method (Theorem 2).
• Finally, we provide numerical results that shows in particular the stability attained by KIPLMC2. We
show in particular that this discretisation (which is based on [51]) is more stable than KIPLMC1 and
MPGD of [47].
The paper is structured as follows: we present the unadjusted Langevin Algorithm, its underdamped sibling
andinteractingparticlesystemsfortheMMLEproblemintheTechnicalBackground,section2. Followingthis
introduction, we propose a new diffusion for the MMLE problem, the Kinetic Interacting Particle Langevin
Diffusion (KIPLD), and present the associated algorithms (KIPLMC1) and (KIPLMC2) in section 3. Finally
we identify the convergence rate for the algorithms to the MMLE target with the nonasymptotic analysis of
section 4 and make some empirical comparisons in the experiments section 5.
Notation
Denote by P(Rd), for d ≥ 1, the space of all probability measures over (Rd,B(Rd)), where B(Rd) denotes
the Borel σ-algebra over Rd. Also consider the Euclidean inner-product space over Rd, with inner product
⟨·,·⟩ and associated norm ∥·∥. We will be using this notation interchangeably over different dimensions d,
assuming that the appropriate inner-product space is chosen. For notational convenience, denote {1,...,N}
as [N] and the set of positive integers as N.
Recall that, under a fixed dataset, our model is parameterised over θ ∈Rdθ and x∈Rdx. Let us consider
an unnormalised probability model U(θ,x), where
U(θ,x)=−logp (x,y).
θ
For any p>0 define the Wasserstein-p metric as
(cid:18)(cid:90) (cid:19)1
p
W (π,ν)= inf ∥x−y∥pdΓ(x,y) ,
p p
Γ∈T(π,ν)
where T(π,ν) denotes the set of couplings over Rd×d, with marginals π and ν.
2 Technical Background
Before presenting our proposed diffusion and algorithms, we introduce some concepts that will be useful to us
in this paper. In particular, we introduce unadjusted Langevin algorithms, kinetic Langevin Monte Carlo
methods, followed by a discussion of the interacting particle Langevin algorithm (IPLA) of [2] for the MMLE
problem.
32.1 Unadjusted Langevin Algorithm
Consider the problem of simulating random variables with a law in P(Rd) of the form
π(dz)∝e−U(z)dz, (2)
where U :Rd →R is a potential function. This is a classical problem in computational statistics literature,
with abundance of Markov chain Monte Carlo (MCMC) methods available, see, e.g., [56] for a book long
treatment. Inthispaper, wefocusonaparticularclassofMCMCalgorithm, termedtheunadjustedLangevin
algorithm (ULA). These methods rely on the fact that the following Langevin diffusion process
√
dZ =−∇U(Z )dt+ 2dB , (3)
t t t
where (B ) is a standard Brownian motion, leaves the target measure (2) invariant. While this idea is
t t≥0
well-known in MCMC literature and exploited for a long time as the proposal of the Metropolis-adjusted
Langevin algorithm (MALA) [58, 57, 68], recently several approaches simply drop the Metropolis step in
this method and use the plain discretisation of the diffusion (3) as a sampling algorithm. This results in the
following discretisation (termed unadjusted Langevin algorithm (ULA) [31, 30] or Langevin Monte Carlo
(LMC) [20])
Zη =Zη−η∇U(Zη)+(cid:112) 2ηW
n+1 n n+1
where (W n) n∈N are standard d-dimensional Normal random variables and η corresponds to the step-size of
the algorithm.
Sampling with unadjusted Langevin algorithm, for convex U, has been extensively studied [30, 23]. The
ULA is an efficient way to sample from these distributions, providing exponential convergence to the unique
stationary measure and only requiring an un-normalised model. This improved computational performance
comes at the expense of inducing a bias of order η1
2
in the stationary measure of the algorithm [31]. Despite
this, the ULA is a natural choice for sampling, as it can be implemented through a variety of discretisations
andhas,asdiscussed,favourabletheoreticalproperties(see,[30,65,29,11,19,58,57]and[22],forconvergence
results under different assumptions on U).
2.2 Kinetic Langevin Monte Carlo
An alternative to the Langevin diffusions given in (3), which are generally termed overdamped Langevin
diffusions, is another class of Langevin diffusions called underdamped diffusions [53]. This class of diffusions
is akin to second-order differential equations and defined over position and momentum variables. The
momentum particle’s dynamics are given by Newton’s Law for the motion of a particle, subject to friction
and a stochastic forcing, acting as the gradient of the position particle [18]. In particular, the underdamped
Langevin diffusion is defined as
dZ =V dt
t t (4)
(cid:112)
dV =−γV dt−∇ U(Z )dt+ 2γdB ,
t t z t t
where γ >0 is called the friction coefficient and (B ) is a Brownian motion. From this equation, one can
t t≥0
recover the overdamped dynamics in (3) by letting γ →∞ and considering the behaviour of the z-marginal
[52, pg. 58]. Under certain regularity conditions [53], this system is known to be invariant w.r.t. an extended
stationary measure of the form
(cid:18) (cid:19)
1
π¯(dz,dv)∝exp −U(z)− ∥v∥2 dzdv. (5)
2
This means that we can recover the samples from our target measure (2) by sampling from (5) where the
z-marginal of π¯ is the target measure we would like to sample from.
4As the update rules are determined by a numerical approximation of a continuous-time process, how this
algorithm performs is dependent on the smoothness of the sample paths and the mixing rate of the system. It
is quite easy to see that the sample paths in the underdamped case are smoother, having an Hölder continuity
of order 1+α, for α∈[0,1/2) (see introduction of [23]). Furthermore, similar to the ULA algorithm, this
system also has exponentially fast convergence to the stationary measure [23]. By using an underdamped,
second-order system, [18] exploit these properties to accelerate the first-order process, connecting this work
to Nesterov acceleration and the growing body of literature dedicated to it. Indeed, [18] show that for certain
choices of γ the underdamped system converges faster to the stationary measure than the overdamped system
andidentifytheregimesinwhichtheunderdampedalgorithmoutperformstheoverdampedfortheirsampling
schemes. This acceleration has not only been noted in W , by [23, 17] and others, but also in KL divergence
2
by [49]. The underdamping leads to some interesting properties, such as an “induced regularisation” and more
damped momentum effects, as well as, convergence with better dependence on dimension and step-size, as
shown in [17]. Hence, the underdamped Langevin diffusion, presents a worthwhile starting point for sampling
algorithms and represents a competitive alternative to the popular ULA.
2.3 MMLE via Interacting Particle Langevin Algorithm
These sampling algorithms, however, are not sufficient for parameter estimation, for which we will need to
introduceoptimisationtechniques. Asmentionedintheintroduction, ourmainaiminthispaperistodevelop
algorithms to solve the maximum marginal likelihood estimation problem (MMLE). Recall that the MMLE
problem is to identify
θ¯ ∈arg max logp (y),
⋆ θ
θ∈Rdθ
for fixed y ∈Rdy and p θ(y)=(cid:82) p θ(x,y)dx. Therefore the MMLE problem is simply the maximisation of an
often intractable integral. With the notation U(θ,x)=−logp (x,y), the θ-gradient of logp (y) is given as
θ θ
−(cid:82) ∇ U(θ,x)p (x,y)dx (cid:90)
∇ logp (y)= θ θ =− ∇ U(θ,x)p (x|y)dx, (6)
θ θ p (y) θ θ
θ
which is easy to prove (see, e.g., [27, Proposition D.4] and [2, Remark 1]). The expression in (6) is the
motivation behind approximate schemes for expectation-maximisation, where one can first sample from
p (x|y) for fixed θ with an MCMC chain and then compute the gradient in (6) with these samples [24, 6].
θ
However, these approaches require non-trivial assumptions on the step-size, as well as having a sample size
that may need to grow to ensure that the gradient approximation does not incur asymptotic bias.
In contrast to this approach, [45] propose an IPS, the particle gradient descent (PGD) algorithm, to
approximate the gradient of the θ-dynamics by running independent particles to integrate out latent variables.
Inspired by this, [2] attempt to solve the MMLE problem with a similar IPS, termed the interacting particle
LangevinAlgorithm(IPLA),whichisamodificationofPGDwhereθ-dynamicscontainacarefullyscalednoise.
This approach produces a system that is akin to an unadjusted Langevin algorithm and makes the theoretical
analysis streamlined. The proposed algorithm is a discretisation of a system of interacting Langevin SDEs for
the parameter θ and N particles X1,...,XN. To be precise, the dynamics of θ and Xi, for the IPLA, are
t t
driven by the system of equations
N (cid:114)
1 (cid:88) 2
dθ =− ∇ U(θ ,Xi)dt+ dB0, (7)
t N θ t t N t
i=1
√
dXi =−∇ U(θ ,Xi)dt+ 2dBi, for i∈[N]. (8)
t x t t t
where(B0 t)
t≥0
isaBrownianmotionevolvingonRdθ and(Bi t)
t≥0
fori∈[N]areBrownianmotionsevolvingon
Rdx. Itisquiteeasytonotethatthedrifttermfortheθ-dynamicscanbeseenastheempiricalapproximation
of the “true” drift (6) with N particles drawn from a measure drifting towards p (x|y). In this case, [2]
θ
5observe that the stationary measure of this system is given as
(cid:32) N (cid:33)
(cid:88)
πN(dθ,dx ,...,dx )∝exp − U(θ,x ) dθdx ...dx .
1 N i 1 N
i=1
It is easy to show that, the θ-marginal of this measure concentrates on the MMLE θ¯ as N grows, similar to
⋆
annealing techniques developed in traditional optimisation [39]. The authors of [2] identify the convergence
rate to the joint stationary measure, as well as, an error bound for the discretisation error, from which an
error can be determined between the θ-iterate of the algorithm and the MMLE. With this nonasymptotic
analysis, [2] identify parameters needed to implement the algorithm and introduce an order of convergence
guarantee in W . The algorithm is empirically shown to be competitive with state-of-the-art models, such as
2
SOUL [24] and the PGD proposed in [45]. Further, the IPLA algorithm lays the foundation for many avenues
for further exploration: such as considering a kinetic Langevin algorithm and considering other numerical
discretisations of proposed SDEs as we will do in this paper.
3 Kinetic Interacting Particle Langevin Monte Carlo
Recall that our goal is to combine the advantages of underdamped Langevin diffusions with the interacting
particle systems proposed by [2, 45, 47], to estimate the MMLE θ¯ . In this section we present a diffusion
⋆
and two algorithms to this end. Indeed, this diffusion will be an underdamped version of the system of
overdamped Langevin diffusions of the IPLA algorithm (7).
3.1 Kinetic Interacting Particle Langevin Diffusion
We introduce the KIPLD system, the diffusion obtained by replacing the overdamped dynamics of the IPLA
with underdamped ones. This is given by
dθ =Vθdt
t t
dXi =Vxidt, (KIPLD)
t t
N (cid:114)
1 (cid:88) 2γ
dVθ =−γVθdt− ∇ U(θ ,Xi)dt+ dB0
t t N θ t t N t
i=1
dVxi =−γVxidt−∇ U(θ ,Xi)dt+(cid:112) 2γdBi, for i∈[N]
t t x t t t
where(Bi t)
t≥0
fori∈[N]isafamilyofRdx-valuedBrownianmotionsand(B0 t)
t≥0
isanRdθ-valuedBrownian
motion. For notational convenience we will say that the particles and momenta have combined dimension of
d = d +Nd each. Similarly to the algorithm proposed by [2], we have a system of N particles for the
z θ x
empirical approximation of latent variable distribution. This system corresponds to relaxing the limit on γ,
the “friction” parameter, for the algorithm proposed by [2]. Adding the friction hyper-parameter γ should
allow for improved regularisation and dampening momentum effects, as discussed in [49]. We will note some
of this behaviour in the experimental section, where the momentum effect can be observed and tuned to
produce optimal convergence behaviour.
An alternative perspective is that, in line with the work done by [2], we consider here an analogue of the
momentum particle gradient descent (MPGD) scheme [47] with noise. In particular, we are injecting the
θ-dynamics with the appropriately scaled (cid:112) 2/NdB0. The advantage of studying this analogue emerges in
t
the numerous results available for Langevin diffusions of kinetic-type, as well as allowing us to recover the
algorithm proposed by [47] by considering this version as a noised version of the MPGD (indeed for large N,
this difference should be more attenuated). However, in contrast to [47], we set both the friction parameters
γ for the θ and x dynamics to be the same. The results presented here should naturally extend to other cases.
63.2 Kinetic Interacting Particle Langevin Monte Carlo Methods
We now introduce two numerical integrators for the KIPLD: firstly, we consider an Exponential Integrator, as
discussed in [23]; secondly, the Splitting scheme is applied, as described in [51]. These algorithms for kinetic
Langevin samplers have two parameters, namely, the step-size η >0, which assumed to be small, and the
friction coefficient γ >0, determining momentum effects.
3.2.1 Exponential Integrator (KIPLMC1)
[18] introduce a variant of the Hamiltonian Monte Carlo, the KLMC, which has improved convergence rate
when compared to the Langevin MCMC proposed by [31]: having W error of order O(n−1), for step-count
2
n, rather than O(n−1 2) [18, Thm. 1]. This method is proposed for sampling from underdamped Langevin
diffusions, as, unlike Euler-Maruyama, this approach seems able to exploit the higher order of convergence of
the underlying process [23]. The bounds on the convergence rate for this algorithm are further improved in
[23], who tighten the bound with respect to the condition number L/µ and improve sensitivity to the initial
choice is reduced. On top of this, [23] identify the cases in which the KLMC outperforms Langevin MCMC,
based on the bounds established for the the two algorithms. In particular, when dn is large relative to L the
KLMC is preferable to the Langevin MCMC. Here d denotes the dimension of the SDE system and n the
total step-count.
Motivated by this we seek to apply this scheme to the diffusion KIPLD and seek to recover favourable
results. Following [23], we begin by defining recursively,
ψ (t)=e−γt
0
(cid:90) t 1
ψ (t)= e−γsds= (e−γt−1)
1 γ
0
1 (cid:90) t 1 t
ψ (t)= (e−γs−1)ds= (e−γt−1)− .
2 γ γ2 γ
0
These terms emerge from the Itô formula used to estimate the expectations and their covariances (see Lemma
11[18]forafullderivation). Thepairsεi,εi,′,fori∈[N],arei.i.d. standardnormalGaussianswithpair-wise
n n
covariance matrix
(cid:90) η(cid:18) ψ (t)2 ψ (t)ψ (t)(cid:19)
C = 0 0 1 dt. (9)
ψ (t)ψ (t) ψ (t)2
0 0 1 1
This covariance matrix is the covariance between the dynamics of the position particle and the momentum
particle, as shown in [18, Lemma 11].
Theschemeisrecoveredbyupdatingtheparticlepositionswiththeexpectationsoftheparticlesconditioned
on the previous time-step and adding Gaussian noise with covariance C. Thus, the scheme produces the same
first and second momenta as the diffusion we seek to target. Formally, the scheme is given by
N (cid:114)
θ =θ +ψ (η)Vθ−
ψ 2(η)(cid:88)
∇ U(θ ,Xi)+
2γ
ε0,′
n+1 n 1 n N θ n n N n+1
i=1
Xi =Xi +ψ (η)Vxi −ψ (η)∇ U(θ ,Xi)+(cid:112) 2γεi,′
n+1 n 1 n 2 x n n n+1 (KIPLMC1)
N (cid:114)
Vθ =ψ (η)Vθ−
ψ 1(η)(cid:88)
∇ U(θ ,Xi)+
2γ
ε0
n+1 0 n N θ n n N n+1
i=1
Vxi =ψ (η)Vxi −ψ (η)∇ U(θ ,Xi)+(cid:112) 2γεi
n+1 0 n 1 x n n n+1
for i ∈ [N], where ε and ε′ are standard Gaussians with pairwise covariance given by C. The scheme
n n
converges for certain choices of η, depending on the assumptions set on U. The full algorithm is given in
Algorithm 1.
7Algorithm 1 KIPLMC1 Algorithm
Require: γ,η >0, N,K ∈N
Draw θ ,Xi,Vθ,Vxi, for i∈[N]
0 0 0 0
for n=0:K−1 do
Draw ε ,ε′ from d +Nd -dimensional Gaussians with covariance C given in (9)
n n θ x
(cid:113)
θ =θ +ψ (η)Vθ− ψ2(η)(cid:80)N ∇ U(θ ,Xi)+ 2γε0,′
n+1 n 1 n N i=1 θ n n N n+1
√
X ni
+1
=X ni +ψ 1(η)V nxi −ψ 2(η)∇ xU(θ n,X ni)+ 2γεi n, +′
1
(cid:113)
Vθ =ψ (η)Vθ− ψ1(η)(cid:80)N ∇ U(θ ,Xi)+ 2γε0
n+1 0 n N i=1 θ n n√ N n+1
V nx +i
1
=ψ 0(η)V nxi −ψ 1(η)∇ xU(θ n,X ni)+ 2γεi
n+1
for i∈[N]
return θ
K
3.2.2 A Splitting Scheme (KIPLMC2)
The KIPLMC splitting algorithm (KIPLMC2) is an adaptation of the underdamped Langevin sampler
introduced by [51], based on classic splitting techniques from MCMC. Specifically, [51] propose an OBABO
scheme as the discretisation scheme, which is a second order scheme only requiring the computation of ∇U.
The idea is to split the numerical scheme into individually solveable components. In our underdamped case
(KIPLD), we have: (A) the update of θ and Xi with known Vθ and Vxi; (B) update Vθ and Vxi with
1 (cid:80)N ∇ U(θ,Xi) and ∇ U(θ,Xi) as gradients respectively; (O) solve the Ornstein-Uhlenbeck equation
N i=1 θ xi
with the terms Vθ and Vxi. Thus, the algorithm “splits” the equation into components with known solutions.
The order in which these steps are taken is critical and in our case we will limit ourselves to considering the
OBABO scheme from [51].
In our case we introduce the KIPLMC2 algorithm based on the OBABO scheme, given as
1 (cid:112) η2 (cid:88)N
θ =θ +η(δVθ+ √ 1−δ2ε0 )− ∇ U(θ ,Xi)
n+1 n n N n+1 2N θ n n
i=1
(cid:112) η2
Xi =Xi +η(δVxi + 1−δ2εi )− ∇ U(θ ,Xi) (KIPLMC2)
n+1 n n n+1 2 x n n
(cid:32) N N (cid:33)
δη 1 (cid:88) 1 (cid:88) 1 (cid:112)
Vθ =δ2Vθ− ∇ U(θ ,Xi)+ ∇U(θ ,Xi ) + √ 1−δ2(δε0 −ε0,′ )
n+1 n 2 N θ n n N n+1 n+1 N n+1 n+1
i=1 i=1
δη (cid:112)
Vxi =δ2Vxi − (∇ U(θ ,Xi)+∇ U(θ ,Xi ))+ 1−δ2(δεi +εi,′ )
n+1 n 2 x n n x n+1 n+1 n+1 n+1
for i∈[N], where δ =e−ηγ/2 and in this case εi and εi,′ are i.i.d. standard Gaussians in this case. The full
algorithm is given in Algorithm 2.
To understand where this system comes from, observe that the (O) and (B) steps produce a half update
of Vθ and Vxi. Note that the first two summands in both equations form the (O) step and the last term the
(B) step. With these estimates θ and Xi are updated: the (A) step. Following this the (O) and (B) steps are
performed in reverse order, using the updated θ , Xi and the half-step value of Vθ and Vxi . Giving
n+1 n+1 n+1 n+1
us the desirable property of being a second-order, explicit scheme, which does not requ2ire compu2tation of
∇2U.
4 Nonasymptotic Analysis
In this section, we provide the convergence results for both the analytic and numerical schemes in the
nonasymptotic regime of γ <∞. In Section 4.3, we identify the stationary measure for KIPLD and show
an exponential convergence rate to it, as well as, its concentration onto the MMLE solution θ¯ as N grows.
⋆
8Algorithm 2 KIPLMC1 Algorithm
Require: γ,η >0, N,K ∈N
Draw θ ,Xi,Vθ,Vxi, for i∈[N]
0 0 0 0
for n=0:K−1 do
Draw ε ,ε′ from d +Nd -dimensional Gaussians
n n θ x
(O+B)
√
V nθ
+1
2
=δV nθ+ √ √1
N
1−δ2ε0 n+1− 2η
N
(cid:80)N i=1∇ θU(θ n,X ni)
V nx +i
1
=δV nxi + 1−δ2εi n+1−η∇ xU(θ n,X ni)
(A)2
θ =θ +ηVθ
n+1 n n+1
2
Xi =Xi +ηVxi
n+1 n n+1
(B+O) 2
√
V nθ
+1
=δ(V nθ
+ 21
− 2η
N
(cid:80)N i=1∇ θU(θ n+1,X ni +1) √+ √1
N
1−δ2ε0 n, +′
1
V nx +i
1
=δ(V nx +i
1
− η 22 ∇ xU(θ n+1,X ni +1)+ √1
N
1−δ2ε n0, +′
1
return θ 2
K
Following this, in Section 4.3.2, the error bounds for the two algorithms are introduced, thus allowing us to
identify the convergence rate of KIPLMC1 and KIPLMC2 to the MMLE solution θ¯ .
⋆
4.1 Assumptions
We first lay out our assumptions to prove the convergence of the numerical schemes outlined in 3. Our
assumptions are generic, i.e., we merely assume strong convexity and L-Lipschitz gradients for the potential
U. These assumptions are akin to the assumptions made in [31, 22] for the unadjusted Langevin algorithm.
As such, the assumptions are necessary for basic building blocks of the theory - but it is possible to relax
them, as can be seen in [69, 4].
We start with the following assumptions on the potential U.
H1. Let z,z′ ∈Rdθ+dx, we suppose that there exists a µ s.t.
⟨z−z′,∇U(z)−∇U(z′)⟩≥µ∥z−z′∥2.
This assumption also implies that ∇2U is positive definite, i.e., ∇2U(z)⪰µI for all z ∈Rdθ+dx.
H2. We suppose U ∈C1 and for any z,z′ ∈Rdθ+dx there exists a constant L>0 s.t.
∥∇U(z)−∇U(z′)∥≤L∥z−z′∥.
4.2 The proof strategy
Given the assumptions above, we aim at bounding the optimisation error of the numerical schemes, i.e., the
difference between the law of the numerical scheme and the optimal MMLE solution θ¯ . Let (θ ) be the
⋆ n n≥0
sequence of iterates generated by a numerical scheme, for example, KIPLMC1 or KIPLMC2. Finally, let π
Θ
denote the θ-marginal of the stationary measure of the diffusion KIPLD, and δ θ¯
⋆
denote the Dirac measure
at θ¯ . We denote the law of θ by L(θ ). The optimisation error is then defined as E[∥θ −θ¯ ∥2]1/2.
⋆ n n n ⋆
θ
.I Tn ho ir sd ie sr dt uo ep tr ooc te he ed f, aw cte tfi hr as tt tn ho ete set tha ot fE co[∥ uθ pn lin− gθ s¯ ⋆ b∥ e2 t] w1/ e2 en= aW m2( eL as( uθ n re), νδ θ¯ a⋆n), dw ah ne or te heL r(θ mn e) ad suen reot δes ct oh ne tl aa iw nso af
n y
single element δ y⊗ν [59, Section 1.4], thus the infimum in W 2 is attained by the coupling δ θ¯ ⋆⊗L(θ n). Using
9this, we can then write
E[∥θ n−θ¯ ⋆∥2]1/2 =W 2(L(θ n),δ θ¯ ⋆)
≤W 2(π Θ,δ θ¯ ⋆)+W 2(L(θ n),π Θ), (10)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
concentration convergence
using the triangle inequality as the Wasserstein distance is a metric. The first term in the right-hand side
of (10) is the concentration of the stationary measure π onto the MMLE solution θ¯ , which is given by
Θ ⋆
Proposition 2 below. The second term is the convergence of the numerical scheme to the stationary measure
π which will be proved for each scheme separately.
Θ
4.3 Nonasymptotic convergence bounds
As outlined above in (10), we will first show the concentration of the stationary measure π onto the MMLE
Θ
solution θ¯ . We then show the convergence of the numerical schemes to the stationary measure π . Finally,
⋆ Θ
we will provide the error bounds for the numerical schemes.
4.3.1 Concentration of the stationary measure
We are interested in the behaviour of the stationary measure of KIPLD. This is a non-standard underdamped
Langevin diffusion, thus, we need to first identify the stationary measure of the system. Recall that we are
only interested in θ-marginal of this stationary measure and we denote it by π . We first have the following
Θ
proposition.
Proposition 1. Let π be the θ-marginal of the stationary measure of the KIPLD. Then, we can write its
Θ
density as
π (θ)∝exp(−Nκ(θ)). (11)
Θ
where κ(θ)=−logp (y).
θ
Proof. See Appendix B.1. □
This result shows that the KIPLD targets the right object: As N grows, π will concentrate on the
Θ
minimisers of κ(θ) by a classical result [39]. This shows that the number of particles N acts as an inverse
temperature parameter in the underdamped diffusion. Since the minimiser of κ(θ) is the maximiser of
logp (y), we can see that the stationary measure of the KIPLD is concentrating on the MMLE solution θ¯ .
θ ⋆
In particular, under the assumption H1, we have the following nonasymptotic concentration result.
Proposition 2. Under H1, the function θ (cid:55)→logp (y) is µ-strongly log concave. Furthermore, we have
θ
(cid:115)
2d
W 2(π Θ,δ θ¯ ⋆)≤ µNθ,
where θ¯ =argmax logp (y), which is unique.
⋆ θ∈Θ θ
Proof. See Appendix B.2. □
This shows that there is an explicit rate of convergence of the θ-marginal of the stationary measure of
KIPLD to the MMLE solution θ¯ . This is a key result, as it shows that the stationary measure of the system
⋆
is concentrating on the MMLE solution as N grows. We note that such results are also potentially possible
under nonconvex settings [69, 4].
104.3.2 Convergence of the KIPLD to the stationary measure
We next demonstrate that the KIPLD converges to its stationary measure π exponentially fast in the
Θ
strongly log-concave case. Indeed, knowing that the system KIPLD is ergodic, we would like to quantify the
rate at which this mixing occurs, specifically at what rate the W distance of the process and its stationary
2
distribution converges for a possibly large range of γ.
Proposition 3. Let (θ ) and (θ′) be θ-marginals of two solutions of the KIPLD SDE, initialised at
t t≥0 t t≥0 √
ν⊗N(0,I ) and ν′⊗N(0,I ) respectively. Then under H1 and H2 and for γ ≥ µ+L, we have
dz dz
√ (cid:18) µ (cid:19)
W (L(θ ),L(θ′))≤ 2exp − t E[∥Z −Z′∥2]1/2.
2 t t γ 0 0
where Zi
0
= N−1/2Xi
0
for i ∈ [N], Z
0
= (θ 0,Z1 0,...,ZN
0
)⊤ ∈ Rdθ+Ndx and similarly for Z′ 0. Z
0
∼ ν and
Z′ ∼ν′, where ν,ν′ ∈P(Rdz) with bounded second moments.
0
Proof. See Appendix B.3. □
This proposition shows that, under the conditions expressed in Prop. 3, the KIPLD SDE defines a
contraction.
4.3.3 Nonasymptotic analysis of KIPLMC1
In this section we present our first main result showing the convergence rate of KIPLMC1. The result is
provided in the following theorem.
Theorem1. Let(θ n) n∈N betheiteratesofKIPLMC1andsupposethattheprocessisinitialisedas(Z 0,V 0z)T ∼
ν ⊗N √(0,I dz), where ν ∈ P(Rdz) has bounded second moments. Under Assumptions H1 and H2 and with
γ ≥ µ+L and η ≤µ/(4γL), we have
√ (cid:18) 3µη(cid:19)n √ Lη(cid:114) d +Nd (cid:115) 2d
E[∥θ −θ¯ ∥2]1/2 ≤ 2 1− E[∥Z −Z¯ ∥2]1/2+ 2 θ x + θ,
n ⋆ 4γ 0 ⋆ µ N µN
where Z =(θ ,N−1/2X1,...,N−1/2XN)⊺, the initialisation step of the KIPLMC1 where Z¯ ∼π˜ and π˜ is
0 0 0 0 ⋆
the extended target measure described in Lemma A.3.
Proof. See Appendix B.4. □
The result follows from the fact that the target measure π of our system concentrates on the maximiser
Θ
whichisgivenbyProposition2andusingtheresultsin[23]forkineticLangevindiffusionsandtheexponential
integrator discretisation. Further, we replicate the choice made in [23] of initialising the momentum particle
according to N(0,I ), the stationary measure under the momentum marginal.
dz
4.3.4 Nonasymptotic analysis of KIPLMC2
In the following section, we present our second main result, showing the convergence rate of KIPLMC2. The
rate is explicitly given in the subsequent theorem.
Theorem2. Let(θ n) n∈N betheiteratesofKIPLMC2andsupposethattheprocessisinitialisedas(Z 0,V 0z)T ∼
ν ⊗N √(0,I dz), where ν ∈ P(Rdz) has bounded second moments. Under Assumptions H1 and H2 and with
γ ≥2 L and η ≤ µ , we have
33γ3
(cid:32)(cid:18) (cid:19)n (cid:33) (cid:115)
E[∥θ −θ¯ ∥2]1/2 ≤C 1− ηµ 2 E[∥Z −Z⋆∥2]1/2+η(cid:112) 2d 6γK + 2d θ,
n ⋆ 3γ 0 z µ µN
11where Z = (θ ,N−1/2X1,...,N−1/2XN)⊺, the initialisation step of the KIPLMC2, Z¯ ∼ π˜ and π˜ is the
0 0 0 0 ⋆
extended target measure described in Lemma A.3. The constants C and K are given as
C
=√ 3(√ L∨√ L−1
), K
=L(cid:18) 1+eLη2(cid:18) η
+
η2L(cid:19)(cid:19)(cid:18)
1+
η √L (cid:19)
.
6 24 2 µ
Note K converges to L as η →0.
Proof. See Appendix B.5. □
Thisisagainisasimpleapplicationofthetriangleinequalityfortheconcentrationofπ fromProposition
Θ
2 and the convergence results for kinetic Langevin diffusions approximated by a second-order splitting scheme
from [51].
5 Experiments
In the following section a comparison will be made between the empirical results of KIPLMC1, KIPLMC2
algorithms, as well as, that of MPGD from [47]. Specifically, we consider a Bayesian logistic regression LVM
for which one can discuss our assumptions in detail.
5.1 Bayesian Logistic Regression on Synthetic Data
We follow the experimental setting in [45] and [2] and start with comparisons between algorithms on a
syntheticdatasetforwhichweknowthetruesolution. Moreprecisely,considertheBayesianlogisticregression
model
dy
p (x)=N(x;θ,σ2I ), p(y|x)= (cid:89) s(v⊺ x)yj(1−s(v⊺ x))1−yj.
θ dx j j
j=1
Here s(u) = eu/(1+eu) is the logistic function and v , j ∈ [d ] are the set of d -dimensional covariates
j y x
with corresponding responses y ∈{0,1}. σ is given and fixed throughout. We generate a synthetic set of
j
covariates, {v j}d j=y
1
⊂Rdx, from which are simulated a synthetic set of observations y j|θ¯ ⋆,x,v j, for fixed θ¯ ⋆,
via a Bernoulli random variable with probability s(v⊺ x). The algorithm is tested on the recovery of this value
j
of θ¯ .
⋆
The marginal likelihood is given as,
 
p θ(y)=
(2πσ1
2)dx/2
(cid:90)
Rdx

j(cid:89)d =y
1s(v j⊺ x)yj(1−s(v j⊺
x))1−yjexp(cid:18) −∥x 2σ− 2θ∥2(cid:19)
dx.
From this it easy to see that the gradients of U are given as,
∇
U(θ,x)=−x−θ
, ∇ U(θ,x)=
x−θ
−(cid:88)dy
(y −s(v⊺ x))v . (12)
θ σ2 x σ2 j j j
j=1
Remark 1 (On H1 and H2). We will discuss this problem and our assumptions. From (12) it is quite
straightforward to observe that,
∥∇U(z)−∇U(z′)∥≤
2
(∥x−x′∥+∥θ−θ′∥)+(cid:88)dy
|s(v⊺ x)−s(v⊺ x′)|∥v ∥
σ2 j j j
j=1
2
1(cid:88)dy
≤( + ∥v ∥2)∥z−z′∥.
σ2 4 j
j=1
12Figure 1: We compare the performance of the MPGD, KIPLMC1, and KIPLMC2 algorithms on the synthetic
dataset with true θ¯ ∈ [1,2,3]. We observe the desired convergence of behaviours for larger values of N.
⋆
For all the algorithms, with the chosen γ, we observe momentum effects, which extend to the noise, as can
be seen in the oscillations in the low particle number regimes. In this example d =d =3, d =500 and
x θ y
γ =1.2. Z is set as δ, the point measure on the origin.
0
This follows from the fact that the logistic function is Lipschitz continuous with constant 1/4 [2]. Hence, H2
is satisfied.
For H1, consider
∇2U(z)= 1
(cid:18)
I dθ −I
dx(cid:19) +(cid:88)dy
s(v⊺ x)(1−s(v⊺ x))v ⊗v .
σ2 −I
dx
I
dθ
j=1
j j j j
The sum is positive definite and the matrix was shown by [45] to have 2d positive eigenvalues and so it
θ
follows that ∇2U is positive definite. Hence U is strictly convex and in theory no lower bound for strong
convexity constant exists. We show however this is not a problem for our practical implementations.
InFig. 1wecanseethedifferenceinthebehavioursbetweenthealgorithms. Mostnotably, theKIPLMC2
algorithm exhibits comparable levels of variance as the MPGD algorithm in the θ-dimension, whilst the
KIPLMC1 algorithm has much greater variance (roughly 100 times greater). It is interesting to note that
the KIPLMC2 algorithm preserves many theoretical properties of the KIPLMC1 algorithm, with empirical
variance reduction properties. As N grows the θ iterates concentrate onto the MMLE θ¯ for all algorithms.
⋆
This behaviour can be seen in more detail in Fig. 2, in which we can observe the variance changing with rate
O(1/N).
13Figure 3: The performance of MPGD, KIPLMC1 and KIPLMC2 algorithms are compared on a logistic
regression experiment for the Wisconsin Cancer Dataset. In (a), we show the behaviour of the θ iterates for
n
the small step-size of η =0.01, where all algorithms converge as desired. (b) shows the behaviour θ iterates
n
for a step-size where all algorithms except for KIPLMC2 explode. In (c) we compare the distributions of the
algorithms over different step-sizes. Observe, that as the step-size η increases, the variance of all algorithms
increases and MPGD fails at η =0.05. The particle number, is chosen to be N =50 and γ =1.2.
NotethatthemomentumeffectsoftheKIPLMC1andKIPLMC2
algorithms has been dampened through a specific choice of γ. In
training it was observed that the convergence rate is very sensitive
to the choice of γ, where choices too small exhibit large momentum
effects and too large lead to slow convergence. The choice of γ here
is far from optimal, but allows us to observe the strength of the
proposed algorithms.
5.2 Wisconsin Cancer Data
Wefollowagainanexperimentalprodecurethatissimilartotheone
outlinedin[45]and[2]andmakecomparisonsbetweenthealgorithms
on a more realistic dataset: the Wisconsin Cancer Data. Again, we
use the logistic regression LVM model, outlined above. This task is
Figure 2: Comparison over 20 Monte
abinaryclassification,todeterminefrom9“features” gatheredfrom
Carlosimulationsofthealgorithms. We
tumors and 693 data points labelled as either benign or malignant.
computethesamplevarianceofthealgo-
The latent variables correspond to the “features” extracted from
rithms, using the last 500 steps of each
the data. The task in this case is to seek to model the behaviour
simulation. The scales are logarithmic
as accurately as possible through the logistic regression LVM.
and gridlines corresponding to 1 are
For this setup we define our probability model as, N
provided to highlight the rate of conver-
gence.
p (x)=N(x;θ1 ,5I )
θ dx dx
and the likelihood as,
dy
p(y|x)= (cid:89) s(v⊺ x)yj(1−s(v⊺ x))1−yj.
j j
j=1
Note that the parameter θ is a scalar in this case, hence, this turns out to be a simplified version of the
setup described above and so the discussion in Remark 1 is still valid. As opposed to the previous case with
synthetic data, here we consider a real dataset, thus we do not have access to the true dataset. Hence, there
is no comparison to a θ¯ , but we can see that different algorithms attain similar values as the estimate of this
⋆
minimum.
Most notably in this experiment, we can observe in Fig. 3 the importance of the discretisation KIPLMC2.
In particular, this algorithm displays great stability w.r.t. the choice of the step-size. For small values
14of the step-size, the MPGD algorithm performs with the lowest variance in all cases where it converges,
until it explodes where step-sizes become too large. Again, we note that the KIPLMC1 algorithm exhibits
more variance in the θ estimation than the KIPLMC2 algorithm, which has more variance than the MPGD.
This is typically an advantage when working with convex problems, but this “sticky” behaviour might prove
detrimental in the non-convex case [36, 2]. The injection of noise into the parameter estimation may help the
method to escape local minima [4].
In these algorithms one can observe the strength of the KIPLMC2 algorithm, with fast convergence and
smoother paths. The latter observation may be related to the differing orders of the algorithms in [51] and
[23].
6 Conclusions
This paper extends a line of work on interacting particle, and more generally diffusion-based, algorithms
for maximum marginal likelihood estimation. This paper has focused on considering alternatives to the
IPSs proposed by [45, 2, 47] for the MMLE problem by considering an accelerated variant. We have shown
that we can leverage the existing literature on underdamped Langevin diffusion for sampling [23, 18, 51, 49]
to produce two algorithms with greater stability, added smoothness and exponential convergence, which
concentrate onto the MMLE with known bounds on the estimation error E∥θ −θ¯ ∥2. These algorithms are
n ⋆
both based on a momentum-based diffusion - which can both be seen as a relaxation of the friction of the
IPLA in [2] or as a noised version of the MPGD in [47]. Empirically, the algorithms perform well compared
to the MPGD (with equal choice of step-sizes and friction coefficients) and the diffusions come equipped with
stronger theoretical guarantees for sampling. Specifically, the induced noise should improve guarantees in the
non-convex setting, as discussed in [2, 55], at a small cost when we consider the variance difference between
the MPGD algorithm and KIPLMC2.
The results presented here, hold under very strict assumptions of gradient-Lipschitzness and strong
log-concavity, however, following the work done in [69] and [42], it should be possible to extend these results
to the non-convex and non-Lipschitz cases. Another interesting direction is to consider the setting in [34].
Similar ideas can be considered within the setting of Stein variational gradient descent as done in [61].
Acknowledgements
PVO is supported by the EPSRC through the Modern Statistics and Statistical Machine Learning (StatML)
CDT programme, grant no. EP/S023151/1.
References
[1] Ö. Deniz Akyildiz, Dan Crisan, and Joaquín Míguez. Parallel sequential Monte Carlo for stochastic
gradient-free nonconvex optimization. Statistics and Computing, 30(6):1645–1663, 2020.
[2] Ö Deniz Akyildiz, Francesca Romana Crucinio, Mark Girolami, Tim Johnston, and Sotirios Sabanis.
Interacting particle langevin algorithm for maximum marginal likelihood estimation. arXiv preprint
arXiv:2303.13429, 2023.
[3] Ö. Deniz Akyildiz, Michela Ottobre, and Iain Souttar. A multiscale perspective on maximum marginal
likelihood estimation. arXiv preprint arXiv:2406.04187, 2024.
[4] Ö. Deniz Akyildiz and Sotirios Sabanis. Nonasymptotic analysis of stochastic gradient hamiltonian
monte carlo under local conditions for nonconvex optimization. Journal of Machine Learning Research,
25(113):1–34, 2024.
[5] Yves F. Atchade, Gersende Fort, and Eric Moulines. On stochastic proximal gradient algorithms.
arXiv:1402.2365, 2014.
15[6] YvesF.Atchadé,GersendeFort,andEricMoulines. Onperturbedproximalgradientalgorithms. Journal
of Machine Learning Research, 18(10):1–33, 2017.
[7] José M Bernardo and Adrian FM Smith. Bayesian theory, volume 405. John Wiley & Sons, 2009.
[8] David M Blei, Andrew Y Ng, and Michael I Jordan. Latent Dirichlet allocation. Journal of Machine
Learning Research, 3(Jan):993–1022, 2003.
[9] James G Booth and James P Hobert. Maximizing generalized linear mixed model likelihoods with an
automated Monte Carlo EM algorithm. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 61(1):265–285, 1999.
[10] AnastasiaBorovykh,NikolasKantas,PanosParpas,andGregPavliotis. OptimizinginteractingLangevin
dynamics using spectral gaps. In Proceedings of the 38th International Conference on Machine Learning
(ICML 2021), 2021.
[11] Nicolas Brosse, Alain Durmus, Éric Moulines, and Sotirios Sabanis. The tamed unadjusted Langevin
algorithm. Stochastic Processes and their Applications, 129(10):3638–3663, 2019.
[12] Olivier Cappé, Arnaud Doucet, Marc Lavielle, and Eric Moulines. Simulation-based methods for blind
maximum-likelihood filter identification. Signal Processing, 73(1-2):3–25, 1999.
[13] Rocco Caprio, Juan Kuntz, Samuel Power, and Adam M. Johansen. Error bounds for particle gradient
descent, and extensions of the log-sobolev and talagrand inequalities, 2024.
[14] Gilles Celeux. The SEM algorithm: a probabilistic teacher algorithm derived from the em algorithm for
the mixture problem. Computational Statistics Quarterly, 2:73–82, 1985.
[15] Gilles Celeux and Jean Diebolt. A stochastic approximation type EM algorithm for the mixture problem.
Stochastics: An International Journal of Probability and Stochastic Processes, 41(1-2):119–134, 1992.
[16] KS Chan and Johannes Ledolter. Monte Carlo EM estimation for time series models involving counts.
Journal of the American Statistical Association, 90(429):242–252, 1995.
[17] Xiang Cheng, Niladri S Chatterji, Yasin Abbasi-Yadkori, Peter L Bartlett, and Michael I Jordan. Sharp
convergence rates for Langevin dynamics in the nonconvex setting. arXiv preprint arXiv:1805.01648,
2018.
[18] Xiang Cheng, Niladri S Chatterji, Peter L Bartlett, and Michael I Jordan. Underdamped Langevin
MCMC: A non-asymptotic analysis. In Conference On Learning Theory, pages 300–323, 2018.
[19] Sinho Chewi, Murat A Erdogdu, Mufan Li, Ruoqi Shen, and Shunshi Zhang. Analysis of Langevin
Monte Carlo from Poincare to Log-Sobolev. In Conference on Learning Theory, pages 1–2. PMLR, 2022.
[20] Arnak Dalalyan. Further and stronger analogy between sampling and optimization: Langevin monte
carlo and gradient descent. In Conference on Learning Theory, pages 678–689, 2017.
[21] Arnak S Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave
densities. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79(3):651–676,
2017.
[22] Arnak S Dalalyan and Avetik Karagulyan. User-friendly guarantees for the Langevin Monte Carlo with
inaccurate gradient. Stochastic Processes and their Applications, 129(12):5278–5311, 2019.
[23] Arnak S Dalalyan and Lionel Riou-Durand. On sampling from a log-concave density using kinetic
langevin diffusions. Bernoulli, 26(3):1956–1988, 2020.
16[24] Valentin De Bortoli, Alain Durmus, Marcelo Pereyra, and Ana F Vidal. Efficient stochastic optimisation
by unadjusted langevin monte carlo. Statistics and Computing, 31(3):1–18, 2021.
[25] Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via
the em algorithm. Journal of the Royal Statistical Society: Series B (Methodological), 39(1):1–22, 1977.
[26] J Diebolt and E HS Ip. A stochastic EM algorithm for approximating the maximum likelihood estimate.
InW.R.Gilks,S.T.Richardson,andD.J.Spiegelhalter,editors,Markov Chain Monte Carlo in Practice.
CRC Publishers, 1996.
[27] RandalDouc,EricMoulines,andDavidStoffer. Nonlinear time series: Theory, methods and applications
with R examples. CRC press, 2014.
[28] Jin-Chuan Duan, Andras Fulop, and Yu-Wei Hsieh. Maximum likelihood estimation of latent variable
models by SMC with marginalization and data cloning. USC-INET Research Paper, (17-27), 2017.
[29] Alain Durmus, Szymon Majewski, and Błażej Miasojedow. Analysis of Langevin Monte Carlo via convex
optimization. Journal of Machine Learning Research, 20(1):2666–2711, 2019.
[30] Alain Durmus and Eric Moulines. Nonasymptotic convergence analysis for the unadjusted Langevin
algorithm. The Annals of Applied Probability, 27(3):1551–1587, 2017.
[31] Alain Durmus and Eric Moulines. High-dimensional Bayesian inference via the unadjusted Langevin
algorithm. Bernoulli, 25(4A):2854–2882, 2019.
[32] Andreas Eberle, Arnaud Guillin, and Raphael Zimmer. Couplings and quantitative contraction rates for
Langevin dynamics. The Annals of Probability, 47(4):1982–2010, 2019.
[33] Paula Cordero Encinar, Francesca R Crucinio, and O. Deniz Akyildiz. Proximal interacting particle
langevin algorithms. arXiv preprint arXiv:2406.14292, 2024.
[34] Zhou Fan, Leying Guan, Yandi Shen, and Yihong Wu. Gradient flows for empirical bayes in high-
dimensional linear models. arXiv preprint arXiv:2312.12708, 2023.
[35] Carlo Gaetan and Jian-Feng Yao. A multiple-imputation Metropolis version of the EM algorithm.
Biometrika, 90(3):643–654, 2003.
[36] Xuefeng Gao, Mert Gürbüzbalaban, and Lingjiong Zhu. Global convergence of stochastic gradient
hamiltonian monte carlo for non-convex stochastic optimization: Non-asymptotic performance bounds
and momentum-based acceleration. Oper. Res., 70:2931–2947, 2018.
[37] Sara Grassi and Lorenzo Pareschi. From particle swarm optimization to consensus based optimization:
stochastic modeling and mean-field limit. Mathematical Models and Methods in Applied Sciences,
31(08):1625–1657, 2021.
[38] Peter D Hoff, Adrian E Raftery, and Mark S Handcock. Latent space approaches to social network
analysis. Journal of the american Statistical association, 97(460):1090–1098, 2002.
[39] Chii-Ruey Hwang. Laplace’s method revisited: weak convergence of probability measures. The Annals
of Probability, pages 1177–1182, 1980.
[40] Eric Jacquier, Michael Johannes, and Nicholas Polson. MCMC maximum likelihood for latent state
models. Journal of Econometrics, 137(2):615–640, 2007.
[41] Adam M Johansen, Arnaud Doucet, and Manuel Davy. Particle methods for maximum likelihood
estimation in latent variable models. Statistics and Computing, 18(1):47–57, 2008.
17[42] Tim Johnston, Iosif Lytras, and Sotirios Sabanis. Kinetic langevin mcmc sampling without gradient
lipschitz continuity-the strongly convex case. Journal of Complexity, 2024.
[43] TimJohnston,NikolaosMakras,andSotiriosSabanis. Tamingtheinteractingparticlelangevinalgorithm–
the superlinear case. arXiv preprint arXiv:2403.19587, 2024.
[44] James Kennedy and Russell Eberhart. Particle swarm optimization. In Proceedings of ICNN’95-
international conference on neural networks, volume 4, pages 1942–1948. IEEE, 1995.
[45] Juan Kuntz, Jen Ning Lim, and Adam M Johansen. Particle algorithms for maximum likelihood training
of latent variable models. In International Conference on Artificial Intelligence and Statistics, pages
5134–5180. PMLR, 2023.
[46] Kenneth Lange. A gradient algorithm locally equivalent to the em algorithm. Journal of the Royal
Statistical Society: Series B (Methodological), 57(2):425–437, 1995.
[47] Jen Ning Lim, Juan Kuntz, Samuel Power, and Adam M Johansen. Momentum particle maximum
likelihood. In Proceedings of 41st International Conference on Machine Learning (ICML), volume 235,
2024.
[48] Chuanhai Liu and Donald B Rubin. The ecme algorithm: a simple extension of em and ecm with faster
monotone convergence. Biometrika, 81(4):633–648, 1994.
[49] Yi-An Ma, Niladri S. Chatterji, Xiang Cheng, Nicolas Flammarion, Peter L. Bartlett, and Michael I.
Jordan. Is there an analog of Nesterov acceleration for gradient-based MCMC? Bernoulli, 27(3):1942 –
1992, 2021.
[50] Xiao-Li Meng and Donald B Rubin. Maximum likelihood estimation via the ecm algorithm: A general
framework. Biometrika, 80(2):267–278, 1993.
[51] Pierre Monmarché. High-dimensional mcmc with a standard splitting scheme for the underdamped
langevin diffusion. Electronic Journal of Statistics, 15(2):4117–4166, 2021.
[52] Edward Nelson. Dynamical Theories of Brownian Motion. Princeton University Press, 1967.
[53] Grigorios A. Pavliotis. Stochastic processes and applications: Diffusion Processes, the Fokker-Planck and
langevin equations. Springer, 2014.
[54] René Pinnau, Claudia Totzeck, Oliver Tse, and Stephan Martin. A consensus-based model for global
optimizationanditsmean-fieldlimit. Mathematical Models and Methods in Applied Sciences, 27(01):183–
204, 2017.
[55] MaximRaginsky, AlexanderRakhlin, andMatusTelgarsky. Non-convexlearningviaStochasticGradient
Langevin Dynamics: a nonasymptotic analysis. In Conference on Learning Theory, pages 1674–1703,
2017.
[56] Christian P Robert and George Casella. Monte Carlo statistical methods. John Wiley & Sons, 2004.
[57] Gareth O Roberts and Osnat Stramer. Langevin diffusions and metropolis-hastings algorithms. Method-
ology and computing in applied probability, 4(4):337–357, 2002.
[58] Gareth O Roberts, Richard L Tweedie, et al. Exponential convergence of Langevin distributions and
their discrete approximations. Bernoulli, 2(4):341–363, 1996.
[59] Filippo Santambrogio. Optimal transport for applied mathematicians. Birkäuser, NY, 55(58-63):94,
2015.
18[60] AdrienSaumardandJonAWellner. Log-concavityandstronglog-concavity: areview. Statistics surveys,
8:45, 2014.
[61] Louis Sharrock, Daniel Dodd, and Christopher Nemeth. Tuning-free maximum likelihood training
of latent variable models via coin betting. In International Conference on Artificial Intelligence and
Statistics, pages 1810–1818. PMLR, 2024.
[62] Robert P Sherman, Yu-Yun K Ho, and Siddhartha R Dalal. Conditions for convergence of Monte
Carlo EM sequences with an application to product diffusion modeling. The Econometrics Journal,
2(2):248–267, 1999.
[63] Paris Smaragdis, Bhiksha Raj, and Madhusudana Shashanka. A probabilistic latent variable model for
acoustic modeling. Advances in Models for Acoustic Processing Workshop, NIPS, 148:8–1, 2006.
[64] Arnaud Vadeboncoeur, Ö. Deniz Akyildiz, Ieva Kazlauskaite, Mark Girolami, and Fehmi Cirak. Fully
probabilisticdeepmodelsforforwardandinverseproblemsinparametricpdes. Journal of Computational
Physics, 491:112369, 2023.
[65] Santosh Vempala and Andre Wibisono. Rapid convergence of the unadjusted Langevin algorithm:
Isoperimetry suffices. Advances in Neural Information Processing Systems, 32, 2019.
[66] Greg CG Wei and Martin A Tanner. A Monte Carlo implementation of the EM algorithm and the poor
man’s data augmentation algorithms. Journal of the American Statistical Association, 85(411):699–704,
1990.
[67] Nick Whiteley, Annie Gray, and Patrick Rubin-Delanchy. Statistical exploration of the manifold
hypothesis. arXiv preprint arXiv:2208.11665, 2022.
[68] Tatiana Xifara, Chris Sherlock, Samuel Livingstone, Simon Byrne, and Mark Girolami. Langevin
diffusions and the metropolis-adjusted langevin algorithm. Statistics & Probability Letters, 91:14–19,
2014.
[69] Ying Zhang, Ö. Deniz Akyildiz, Theodoros Damoulas, and Sotirios Sabanis. Nonasymptotic estimates
for stochastic gradient langevin dynamics under local conditions in nonconvex optimization. Applied
Mathematics & Optimization, 87(2):25, 2023.
19Appendix
A Preliminary results
Lemma A.1 (KIPLD as an underdamped Langevin Diffusion). The KIPLD diffusion can be equivalently
written as a single d +Nd -dimensional underdamped Langevin diffusion given by
θ x
dZ =V¯zdt,
t t
(cid:114) (13)
2γ
dV¯z =−γV¯zdt−∇ U¯ (Z )dt+ dB ,
t t z N t N t
where Zi
t
= N−1/2Xi
t
for i = 1,...,N, Z
t
= (θ t,Z1 t,...,ZN
t
)⊤ ∈ Rdθ+Ndx, V¯ tzi = N−1/2V txi and V¯ tz =
(V tθ,V¯ tz1,...,V¯ tzN)⊤ ∈Rdθ+Ndx, (B t)
t≥0
is a Rdθ+Ndx-valued Brownian motion, and
U¯ (θ,z ,...,z ):=
1 (cid:88)N U(θ,√
Nz ).
N 1 N N i
i=1
Proof. Recall the KIPLD system:
dθ =Vθdt
t t
dXi =Vxidt, for i=1,...,N
t t
N (cid:114)
1 (cid:88) 2γ
dVθ =−γVθdt− ∇ U(θ ,Xi)dt+ dB0
t t N θ t t N t
i=1
dVxi =−γVxidt−∇ U(θ ,Xi)dt+(cid:112) 2γdBi, for i∈[N]
t t x t t t
We note now that, below, we generically use the gradient functions ∇ θU(θ,x) : Rdθ ×Rdx → Rdθ and
∇ xU(θ,x) : Rdθ ×Rdx → Rdx even though their arguments may change. In other words, below ∇ θU(θ,x)
denotes the gradient of U with respect to its first argument and ∇ U(θ,x) denotes the gradient of U with
x
respect to its second argument.
Let us introduce the following function:
√
U (θ,x)=U(θ, Nx),
N
where we note that the (full) gradient is given as,
√
(cid:18) (cid:19)
∇ U(θ, Nx)
∇U (θ,x)= θ √ .
N N−1/2∇ U(θ, Nx)
x
Let us now introduce z
θ
∈Rdθ and z
x
=(z 1,...,z N)T where z
i
∈Rdx for i=1,...,N. We define
N
U¯ (z ,z )= 1 (cid:88) U (z ,z ). (14)
N θ x N N θ i
i=1
The gradients are given as
√
 N−1/2∇ U(z , Nz )
∇ zθU¯ N(z θ,z x)=
N1 (cid:88)N
∇ θU(z
θ,√
Nz xi), ∇ zxU¯ N(z θ,z x)=

x .
. .
θ
√
1
 . (15)
i=1 N−1/2∇ U(z , Nz )
x θ N
20Next, let Zi
t
= N−1/2Xi
t
for i = 1,...,N, Z
t
= (θ t,Z1 t,...,ZN
t
)⊤ ∈ Rdθ+Ndx, V¯ tzi = N−1/2V txi and
V¯z =(Vθ,V¯z1,...,V¯zN)⊤ ∈Rdθ+Ndx. We can rewrite the system KIPLD as
t t t t
dZ =V¯zdt,
t t
1 (cid:88)N √ (cid:114) 2γ
dVθ =−γVθdt− ∇ U(θ , NZi)dt+ dB0,
t t N θ t t N t (16)
i=1
√ (cid:114) 2γ
dV¯zi =−γV¯zidt−N−1/2∇ U(θ , NZi)dt+ dBi, for i∈[N].
t t x t t N t
where B0 is a Rdθ-valued Brownian motion and Bi for i = 1,...,N are Rdx-valued Brownian motions.
t t
Rewriting the system (16) in terms of U¯ , using (15), we obtain the result. □
N
We can also write the KIPLD in the following alternative way which will ease the analysis.
Lemma A.2 (KIPLD as a standard underdamped Langevin Diffusion). The KIPLD diffusion can also be
written as a single d +Nd -dimensional underdamped Langevin diffusion given by
θ x
dZ(cid:101)t =V(cid:101) tzdt,
(17)
dV(cid:101) tz =−γ (cid:101)V(cid:101) tzdt−N∇ zU¯ N(Z(cid:101)t)dt+(cid:112) 2γ (cid:101)dB t,
where Z(cid:101)t,V(cid:101) tz ∈Rdx+Ndθ are given as,
√
Z(cid:101)t =(θ√ Nt,N−1/2X1√ Nt,...N−1/2XN√ Nt)⊺ , V(cid:101) tz =( NV√θ Nt,V√x1 Nt,...,V√xN Nt)⊺ ,
√
(B t)
t≥0
is a Rdθ+Ndx-valued Brownian motion, γ˜ = Nγ and
N
U¯ (θ,z ,...,z ):= 1 (cid:88) U(θ,z ).
N 1 N N i
i=1
Proof. We use [23, Lemma 1] to prove this result. Consider the variables Z(cid:101)t and V(cid:101) tz. It is straightforward to
observe that
dZ(cid:101)t =V(cid:101) tzdt.
Indeed the space rescaling accounts for the time-rescaling in the dynamics of Z(cid:101)t. Now observe that
N (cid:113) √
(cid:88)
dV(cid:101) tθ =−NγV√θ Ntdt−∇
θ
U(θ√ Nt,Xi√ Nt)dt+ 2γ NdB0
t
i=1
√ (cid:113) √
=− NγV(cid:101) tθdt−N∇ θU¯ N(Z(cid:101)t)dt+ 2γ NdB0 t.
Similarly we obtain for i∈[N],
√ (cid:113) √
dV(cid:101) txi =− NγV√i Ntdt−∇ xU(θ√ Nt,Xi√ Nt)dt+ 2γ NdB ti
√ (cid:113) √
=− NγV(cid:101) txidt−∇ xU¯ N(Z(cid:101)t)dt+ 2γ NdB ti,
where we recall our definition of the gradient of U¯ from (15) to obtain the correct scaling in front of
√ N
∇ xU¯ N(Z(cid:101)t). Now, taking γ˜ = Nγ, the result follows. □
Recall that the algorithms proposed seek to target with the nth step the analytic solution at time nη,
where η is the step-size of the algorithm for the rescaled system. Hence, by re-scaling η¯= √η , we can use
N
algorithms for the rescaled system to produce estimates for KIPLMC1 and KIPLMC2. This is discussed
below in B.4 and B.5. Given these results, it is natural to explore the properties of the function U¯ , as this
N
new potential plays a crucial role in both rescalings. We note below some properties of U¯ which will be
N
useful in the proofs.
21Lemma A.3 (Stationary measure for (17)). The measure π˜, left stationary by the dynamics of (17), is given
as
(cid:18) (cid:19)
1
π˜(dz˜,dv˜)∝exp −NU¯ (z˜)− ∥v˜∥2 dz˜dv˜, (18)
N 2
for all z˜,v˜∈Rdz.
This result follows directly by observing the rescaling given in Lemma A.2, both in the parameters and
equation. For a discussion of the stationary measure of a standard underdamped Langevin diffusion see [53,
Chapter 6].
Lemma A.4 (Strong convexity of U¯ N). Under H1, the function U¯
N
:Rdθ+Ndx →R as defined in (14) is
µ-strongly convex
⟨z−z′,∇U¯ (z)−∇U¯ (z′)⟩≥µ∥z−z′∥2,
N N
for all z,z′ ∈Rdθ+Ndx and N ∈N.
Proof. Let z =(z ,z ,...,z ) and z′ =(z′,z′,...,z′ ). We have
θ 1 N θ 1 N
 z −z′   (1/N)(cid:80)N ∇ (cid:16) U(z ,√ Nz )−∇ U(z′,√ Nz′)(cid:17)
⟨z−z′,∇U¯ N(z)−∇U¯ N(z′)⟩=(cid:42)     zθ 1− . . . zθ 1′    ,     N−1/2∇i x= U1 (z θθ , √√ Nzθ 1)− . . . Ni −1/2∇θ xU(zθ θ′,√ √Nzi 1′)     (cid:43)
z N −z N′ N−1/2∇ xU(z θ, Nz N)−N−1/2∇ xU(z θ′, Nz N′ )
1 (cid:88)N (cid:16) √ √ (cid:17)
= ⟨z −z′,∇ U(z , Nz )−∇ U(z′, Nz′)⟩
N θ θ θ θ i θ θ i
i=1
1 (cid:88)N √ √
+ ⟨N1/2z −N1/2z′,∇ U(z , Nz )−∇ U(z′, Nz′)⟩.
N i i x θ i x θ i
i=1
Next, H1 implies that
N
⟨z−z′,∇U¯ (z)−∇U¯ (z′)⟩≥ 1 (cid:88) µ(cid:0) ∥z −z′∥2+N∥z −z′∥2(cid:1) =µ∥z−z′∥2.
N N N θ θ i i
i=1
This completes the proof. □
Next, we show that the function U¯ is L-gradient Lipschitz.
N
Lemma A.5 (Gradient Lipschitzness of U¯ N). Under H2, the function U¯
N
:Rdθ+Ndx →R as defined in (14)
is L-gradient Lipschitz
∥∇U¯ (z)−∇U¯ (z′)∥≤L∥z−z′∥,
N N
for all z,z′ ∈Rdθ+Ndx and N ∈N.
22Proof. Let z =(z ,z ,...,z ) and z′ =(z′,z′,...,z′ ). Then
θ 1 N θ 1 N
√ √
(cid:13) (cid:13) (cid:13) (1/N)(cid:80)N i=1∇ θ√U(z θ, Nz i)−∇ θU(z θ′, √Nz i′) (cid:13) (cid:13) (cid:13)2
∥∇U¯ (z)−∇U¯ (z′)∥2
=(cid:13) (cid:13)

N−1/2∇ xU(z θ, Nz 1)−
.
N−1/2∇ xU(z θ′, Nz 1′)  (cid:13)
(cid:13)
N N (cid:13) . (cid:13)
(cid:13) . (cid:13)
(cid:13) √ √ (cid:13)
(cid:13) N−1/2∇ U(z , Nz )−N−1/2∇ U(z′, Nz′ ) (cid:13)
x θ N x θ N
(cid:13) (cid:13)2
(cid:13) 1 (cid:88)N (cid:16) √ √ (cid:17)(cid:13)
=(cid:13) ∇ U(z , Nz )−∇ U(z′, Nz′) (cid:13)
(cid:13)N θ θ i θ θ i (cid:13)
(cid:13) (cid:13)
i=1
1 (cid:88)N (cid:13) √ √ (cid:13)2
+ (cid:13)∇ U(z , Nz )−∇ U(z′, Nz′)(cid:13) .
N (cid:13) x θ i x θ i (cid:13)
i=1
Using the fact that (·)2 is a convex function and Jensen’s inequality for the first term, we obtain
∥∇U¯ (z)−∇U¯ (z′)∥2 ≤
1 (cid:88)N (cid:13)
(cid:13)∇ U(z
,√
Nz )−∇
U(z′,√ Nz′)(cid:13) (cid:13)2
N N N (cid:13) θ θ i θ θ i (cid:13)
i=1
1 (cid:88)N (cid:13) √ √ (cid:13)2
+ (cid:13)∇ U(z , Nz )−∇ U(z′, Nz′)(cid:13) .
N (cid:13) x θ i x θ i (cid:13)
i=1
Using H2, we have
∥∇U¯ (z)−∇U¯ (z′)∥2 ≤
L2 (cid:88)N
(cid:0) ∥z −z′∥2+N∥z −z′∥2(cid:1)
N N N θ θ i i
i=1
=L2∥z−z′∥2,
which completes the proof. □
B Proofs
B.1 Proof of Proposition 1
GivenLemmaA.1,thesystem(13)hasapositiverecurrentMarkovstationarymeasure,absolutelycontinuous
with respect to the Lebesgue measure, given by the density [32]
(cid:18) (cid:19)
N
π¯N(z,v¯)∝exp −NU¯ (z)− ∥v¯∥2 ,
N 2
where U¯ is given in (14). Note, this follows from eqs. (1.1) and (1.3) in [32] by putting U := NU¯ and
N N
u=N−1. Let z =(θ,z ,...,z ). Using (14), we have
1 N
(cid:32) (cid:88)N √ N (cid:33)
π¯(z,v¯)∝exp − U(θ, Nz )− ∥v¯∥2 .
i 2
i=1
Let us now look at θ-marginal of this density, which can be written as
(cid:90) (cid:90) √
π ΘN(θ)∝ e−(cid:80)N i=1U(θ, Nzi)−N 2∥v¯z∥2 dz xdv¯.
RNdx+dθ RNdx
23√
where z
x
=(z 1,...,z N)∈RNdx. Note now that, integrating out v¯, using a change of variables x′
i
= Nz i,
and setting x′ =(x′,...,x′ ), we have
1 N
(cid:90)
π ΘN(θ)∝N−1/2 e−(cid:80)N i=1U(θ,x′ i)dx′,
RNdx
(cid:18)(cid:90) (cid:19)N
∝
e−U(θ,x′)dx′
=exp(Nlogp (y)),
θ
Rdx
since p (y)=(cid:82) e−U(θ,x)dx by definition where U(θ,x)=−logp (x,y).
θ θ
B.2 Proof of Proposition 2
Note that, by H1, U(θ,x) is jointly µ-strongly convex. Let κ(θ)=−logp (y). Using the Prekopa-Leindler
θ
inequality for strongly log-concave distributions [60, Theorem 3.8], we can see that
⟨θ−θ′,∇κ(θ)−∇κ(θ)⟩≥µ∥θ−θ′∥2.
The bound then follows using an identical proof of Proposition 3 in [2].
B.3 Proof of Proposition 3
The proof follows from Lemma A.1 which shows that we can rewrite the KIPLD system as a single d +Nd -
θ x
dimensional underdamped Langevin diffusion. Then with a suitable time rescaling (see Lemma 1 in [23]),
we can rewrite this diffusion as a standard underdamped diffusion as shown in Lemma A.2. The result
then follows from the exponential convergence of the underdamped Langevin diffusion [23, Theorem 1] with
suitable modifications, e.g., see the proof of [42, Theorem 8.7]. The result then follows from the fact that W
2
between marginals are bounded by the W between joint distributions.
2
B.4 Proof of Theorem 1
By Lemma A.2, we have the standard underdamped diffusion
dZ(cid:101)t =V(cid:101) tzdt,
(19)
dV(cid:101) tz =−γ (cid:101)V(cid:101) tzdt−N∇ zU¯ N(Z(cid:101)t)dt+(cid:112) 2γ (cid:101)dB t.
It is apparent that the stationary measure of this scheme is
π (cid:101)(z,v)∝e−NU¯ N(z)−1 2∥v∥2 .
We will now look at the standard kinetic Langevin Monte Carlo discretisation of the SDE in (19) and show
that this scheme coincides with KIPLMC1. Thus we can utilize the bounds in [23] directly for our scheme.
Let us write the Exponential Integrator discretisation of this scheme (abusing the notation using same
letters) using the step-size η˜
Z(cid:101)n+1 =Z(cid:101)n+ψ(cid:101)1(η˜)V(cid:101) nz −ψ(cid:101)2(η˜)N∇U¯ N(Z(cid:101)n)+(cid:112) 2γ˜ε˜ n+1,
(20)
V(cid:101) nz
+1
=ψ(cid:101)0(η˜)V(cid:101) nz −ψ(cid:101)1(η˜)N∇U¯ N(Z(cid:101)n)+(cid:112) 2γ˜ε˜′ n+1.
√
Since the function z (cid:55)→NU¯ (z) is Nµ strongly convex and NL-gradient-Lipschitz, for γ˜ ≥ Nµ+NL and
N
η˜≤m/(4γ˜L), [23, Theorem 2] directly implies that
√
√ (cid:18) 0.75µη˜(cid:19)n Lη˜ 2d
W (ν ,π¯)≤ 2 1− W (ν ,π¯)+ z,
2 n γ˜ 2 0 µ
24whereν denotesthelawofthediscretisation(20)attimenandπ˜ thestationarymeasuregiveninLemmaA.3.
n
We relate the discretisation (20) to KIPLMC1. It is straightforward to check that, after proper modifications,
√ √
thediscretisation(20)coincideswiththeKIPLMC1withη˜=η/ N andγ˜ = Nγ. Therefore,byspecializing
√ √
this bound to θ-dimension and substituting η˜=η/ N and γ˜ = Nγ, we obtain the convergence bound for
the KIPLMC1. Combining this with the concentration result from Prop. 2, we obtain the result.
B.5 Proof of Theorem 2
Again, recall by Lemma A.2, we consider our rescaled standard underdamped diffusion, given by (19) and
seek to recover from this the behaviour of KIPLMC2. Using this rescaled system we directly apply the results
from [51] for our scheme.
We now write the splitting scheme for the diffusion in Lemma A.2, using step-size η˜,
(cid:113) η˜2
Z(cid:101)n+1 =Z(cid:101)n+η˜(δ˜V(cid:101) nz + 1−δ˜2ε n+1)−
2
N∇U¯ N(Z(cid:101)n)
(21)
η˜δ˜ (cid:113)
V(cid:101) nz
+1
=δ˜2V(cid:101) nz −
2
(N∇U¯ N(Z(cid:101)n)+N∇U¯ N(Z(cid:101)n+1))+ 1−δ˜2(δ˜ε n+1+ε′ n+1),
where δ˜ = e−γ˜η˜/2. Using the NL-gradient-Lipschitzness and Nµ strong convexity of the function z (cid:55)→
√
NU¯ (z), and with the choice of γ˜ ≥2 NL and η˜≤ Nµ , we apply the results of [51, Theorem 1] and [51,
N 33γ˜3
Proposition 11] to obtain
(cid:32)(cid:18) η˜µ˜(cid:19)n
2 (cid:112)
6γ˜K˜(cid:33)
W (ν ,π¯)≤C 1− W (ν ,π¯)+η˜ 2d ,
2 n γ˜ 2 0 z µ˜
where ν is now the law of the discretisation (21) at time n and π˜ the stationary measure from Lemma A.3.
n
Further,
(cid:32) (cid:32) (cid:33)(cid:33)(cid:32) (cid:33)
√ (cid:112) (cid:112) −1 η˜ η˜2L˜ η˜L˜
C = 3( L˜∨ L˜ ), K =L˜ 1+eL˜η˜2 + 1+ √ .
6 24 2 µ˜
√ √
Again, we can recover the behaviour of KIPLMC2 when we set η˜=η/ N and γ˜ = Nγ. It is quite easy
to see that when we set these parameters and consider the θ-marginal, the nth step of this rescaled scheme
will now correspond to the nth step of the KIPLMC2, provided the initial distribution of both is the same.
Combining this with the concentration result from Prop. 2, we obtain the desired result.
C Results
C.1 Variance from (c) Fig. 3 in tabular form
Table 1: We compare the performance of the different algorithms over increasing step-sizes. Observe, despite
the better behaviour at lower step-size η, the MPGD algorithm is the least stable. We compute the sample
variance of the algorithms over 20 Monte Carlo simulations, using the last 500 steps of each simulation.
Sample Variance
η
Algorithms
0.01 0.025 0.05 0.075 0.1
MPGD 2.30×10−2 2.77×10−2 1.75×109 2.34×1050 7.78×10110
KIPLMC1 1.91×10−1 1.30×10−1 1.90×10−1 8.52×10−1 6.06×1017
KIPLMC2 2.63×10−2 3.05×10−2 3.37×10−2 3.03×10−2 3.36×10−2
25