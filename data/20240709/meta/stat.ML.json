[
    {
        "title": "Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning",
        "authors": "Yijun DongHoang PhanXiang PanQi Lei",
        "links": "http://arxiv.org/abs/2407.06120v1",
        "entry_id": "http://arxiv.org/abs/2407.06120v1",
        "pdf_url": "http://arxiv.org/pdf/2407.06120v1",
        "summary": "We revisit data selection in a modern context of finetuning from a\nfundamental perspective. Extending the classical wisdom of variance\nminimization in low dimensions to high-dimensional finetuning, our\ngeneralization analysis unveils the importance of additionally reducing bias\ninduced by low-rank approximation. Inspired by the variance-bias tradeoff in\nhigh dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a\nscalable data selection scheme with two stages. (i) First, the bias is\ncontrolled using gradient sketching that explores the finetuning parameter\nspace for an informative low-dimensional subspace $\\mathcal{S}$; (ii) then the\nvariance is reduced over $\\mathcal{S}$ via moment matching between the original\nand selected datasets. Theoretically, we show that gradient sketching is fast\nand provably accurate: selecting $n$ samples by reducing variance over\n$\\mathcal{S}$ preserves the fast-rate generalization $O(\\dim(\\mathcal{S})/n)$,\nindependent of the parameter dimension. Empirically, we concretize the\nvariance-bias balance via synthetic experiments and demonstrate the\neffectiveness of SkMM for finetuning in real vision tasks.",
        "updated": "2024-07-08 16:57:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.06120v1"
    },
    {
        "title": "Simulation-based Benchmarking for Causal Structure Learning in Gene Perturbation Experiments",
        "authors": "Luka KovačevićIzzy NewshamSach MukherjeeJohn Whittaker",
        "links": "http://arxiv.org/abs/2407.06015v1",
        "entry_id": "http://arxiv.org/abs/2407.06015v1",
        "pdf_url": "http://arxiv.org/pdf/2407.06015v1",
        "summary": "Causal structure learning (CSL) refers to the task of learning causal\nrelationships from data. Advances in CSL now allow learning of causal graphs in\ndiverse application domains, which has the potential to facilitate data-driven\ncausal decision-making. Real-world CSL performance depends on a number of\n$\\textit{context-specific}$ factors, including context-specific data\ndistributions and non-linear dependencies, that are important in practical\nuse-cases. However, our understanding of how to assess and select CSL methods\nin specific contexts remains limited. To address this gap, we present\n$\\textit{CausalRegNet}$, a multiplicative effect structural causal model that\nallows for generating observational and interventional data incorporating\ncontext-specific properties, with a focus on the setting of gene perturbation\nexperiments. Using real-world gene perturbation data, we show that CausalRegNet\ngenerates accurate distributions and scales far better than current simulation\nframeworks. We illustrate the use of CausalRegNet in assessing CSL methods in\nthe context of interventional experiments in biology.",
        "updated": "2024-07-08 15:06:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.06015v1"
    },
    {
        "title": "Link Representation Learning for Probabilistic Travel Time Estimation",
        "authors": "Chen XuQiang WangLijun Sun",
        "links": "http://arxiv.org/abs/2407.05895v1",
        "entry_id": "http://arxiv.org/abs/2407.05895v1",
        "pdf_url": "http://arxiv.org/pdf/2407.05895v1",
        "summary": "Travel time estimation is a crucial application in navigation apps and web\nmapping services. Current deterministic and probabilistic methods primarily\nfocus on modeling individual trips, assuming independence among trips. However,\nin real-world scenarios, we often observe strong inter-trip correlations due to\nfactors such as weather conditions, traffic management, and road works. In this\npaper, we propose to model trip-level link travel time using a Gaussian\nhierarchical model, which can characterize both inter-trip and intra-trip\ncorrelations. The joint distribution of travel time of multiple trips becomes a\nmultivariate Gaussian parameterized by learnable link representations. To\neffectively use the sparse GPS trajectories, we also propose a data\naugmentation method based on trip sub-sampling, which allows for fine-grained\ngradient backpropagation in learning link representations. During inference, we\nestimate the probability distribution of the travel time of a queried trip\nconditional on the completed trips that are spatiotemporally adjacent. We refer\nto the overall framework as ProbTTE. We evaluate ProbTTE on two real-world GPS\ntrajectory datasets, and the results demonstrate its superior performance\ncompared to state-of-the-art deterministic and probabilistic baselines.\nAdditionally, we find that the learned link representations align well with the\nphysical geometry of the network, making them suitable as input for other\napplications.",
        "updated": "2024-07-08 13:01:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.05895v1"
    },
    {
        "title": "Kinetic Interacting Particle Langevin Monte Carlo",
        "authors": "Paul Felix Valsecchi OlivaO. Deniz Akyildiz",
        "links": "http://arxiv.org/abs/2407.05790v1",
        "entry_id": "http://arxiv.org/abs/2407.05790v1",
        "pdf_url": "http://arxiv.org/pdf/2407.05790v1",
        "summary": "This paper introduces and analyses interacting underdamped Langevin\nalgorithms, termed Kinetic Interacting Particle Langevin Monte Carlo (KIPLMC)\nmethods, for statistical inference in latent variable models. We propose a\ndiffusion process that evolves jointly in the space of parameters and latent\nvariables and exploit the fact that the stationary distribution of this\ndiffusion concentrates around the maximum marginal likelihood estimate of the\nparameters. We then provide two explicit discretisations of this diffusion as\npractical algorithms to estimate parameters of statistical models. For each\nalgorithm, we obtain nonasymptotic rates of convergence for the case where the\njoint log-likelihood is strongly concave with respect to latent variables and\nparameters. In particular, we provide convergence analysis for the diffusion\ntogether with the discretisation error, providing convergence rate estimates\nfor the algorithms in Wasserstein-2 distance. To demonstrate the utility of the\nintroduced methodology, we provide numerical experiments that demonstrate the\neffectiveness of the proposed diffusion for statistical inference and the\nstability of the numerical integrators utilised for discretisation. Our setting\ncovers a broad number of applications, including unsupervised learning,\nstatistical inference, and inverse problems.",
        "updated": "2024-07-08 09:52:46 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.05790v1"
    },
    {
        "title": "Dirichlet process mixture model based on topologically augmented signal representation for clustering infant vocalizations",
        "authors": "Guillem BonafosClara BourotPierre PudloJean-Marc FreyermuthLaurence ReboulSamuel TronçonArnaud Rey",
        "links": "http://arxiv.org/abs/2407.05760v1",
        "entry_id": "http://arxiv.org/abs/2407.05760v1",
        "pdf_url": "http://arxiv.org/pdf/2407.05760v1",
        "summary": "Based on audio recordings made once a month during the first 12 months of a\nchild's life, we propose a new method for clustering this set of vocalizations.\nWe use a topologically augmented representation of the vocalizations, employing\ntwo persistence diagrams for each vocalization: one computed on the surface of\nits spectrogram and one on the Takens' embeddings of the vocalization. A\nsynthetic persistent variable is derived for each diagram and added to the\nMFCCs (Mel-frequency cepstral coefficients). Using this representation, we fit\na non-parametric Bayesian mixture model with a Dirichlet process prior to model\nthe number of components. This procedure leads to a novel data-driven\ncategorization of vocal productions. Our findings reveal the presence of 8\nclusters of vocalizations, allowing us to compare their temporal distribution\nand acoustic profiles in the first 12 months of life.",
        "updated": "2024-07-08 09:12:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.05760v1"
    }
]