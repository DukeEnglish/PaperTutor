The Model Arena for Cross-lingual Sentiment Analysis: A Comparative
Study in the Era of Large Language Models
XiliangZhu, ShaynaGardiner, TereRoldán, DavidRossouw
DialpadInc.
{xzhu, sgardiner, tere.roldan, davidr}@dialpad.com
Abstract Besides the research efforts in producing mul-
tilingualdatasetsforsentimentanalysis,multilin-
Sentimentanalysisservesasapivotalcompo-
gualmodelarchitectureshavebecomeincreasingly
nent in Natural Language Processing (NLP).
popularsincetheintroductionofmultilingualpre-
Advancementsinmultilingualpre-trainedmod-
trainedlanguagemodelssuchasmBERT(Devlin
elssuchasXLM-R(Conneauetal.,2020)and
mT5 (Xue et al., 2021) have contributed to et al., 2019), XLM-R (Conneau et al., 2020) and
the increasing interest in cross-lingual senti- mT5(Xueetal.,2021)andBLOOM(BigScience
mentanalysis. TherecentemergenceinLarge Workshop, 2022). Such multilingual pre-trained
LanguageModels(LLM)hassignificantlyad- languagemodelsexploitthepoweroflarge-scale
vancedgeneralNLPtasks,however,thecapa- unsupervisedtextualdatafromamixtureofmany
bilityofsuchLLMsincross-lingualsentiment
languages,facilitatingzero-shotandfew-shotcross-
analysishasnotbeenfullystudied. Thiswork
lingualtransferfromasourcetoatargetlanguage
undertakesanempiricalanalysistocomparethe
on different downstream NLP tasks, albeit with
cross-lingualtransfercapabilityofpublicSmall
MultilingualLanguageModels(SMLM)like varying performance outcomes (Lauscher et al.,
XLM-R, against English-centric LLMs such 2020).
asLlama-3 (AI@Meta,2024), inthecontext
ofsentimentanalysisacrossEnglish,Spanish, Morerecently,LargeLanguageModels(LLM)
FrenchandChinese. Ourfindingsrevealthat
suchasGPT-3(Brownetal.,2020),Llama-2(Tou-
amongpublicmodels,SMLMsexhibitsuperior
vronetal.,2023)andLlama-3(AI@Meta,2024)
zero-shotcross-lingualperformancerelativeto
havecollectedimmenseattentionfortheirunparal-
LLMs. However,infew-shotcross-lingualset-
tings,publicLLMsdemonstrateanenhanced leledperformanceintextgeneration. (Zhangetal.,
adaptive potential. In addition, we observe 2023) shows the strong capability of LLMs with
that proprietary GPT-3.5 1 and GPT-4 (Ope- few-shotin-contextlearninginpublicEnglishsen-
nAIetal.,2024)leadinzero-shotcross-lingual timentanalysistasks. AlthoughmostoftheLLMs
capability,butareoutpacedbypublicmodels
arepre-trainedusingcorporawithadominantpres-
infew-shotscenarios.
enceofEnglish,someresearchhasfoundinterest-
ingmultilingualityinbothpublicandproprietary
1 Introduction
LLMs(Qinetal.,2024)(Zhuetal.,2023). Despite
Sentimentanalysishasreceivedconsiderableatten- thesedevelopments,tothebestofourknowledge,
tionovertheyearsinthefieldofNaturalLanguage the capability of cross-lingual transfer in these
Processing(NLP)duetoitsprofoundvalueinboth LLMshasnotbeenfullystudiedforsentimentanal-
academicresearchandindustryapplications. Tra- ysistasks, anditisstillunclearhowLLMsstand
ditionally, studiesinsentimentanalysishadbeen incomparisontoexistingmultilingualpre-trained
mostly focused on high-resource languages such modelsinthecross-lingualtransferparadigm.
as English due to a deficit of annotated data in
otherlow-resourcelanguages,butrecentresearch Inthiswork,weexamineavarietyofpre-trained
hasemergedtoaddressthisissuebyleveragingma- models and conduct a comprehensive study on
chinetranslationtoaugmentdataresources(Araújo the cross-lingual transfer capability in utterance-
etal.,2020)(Joshietal.,2020). levelsentimentanalysistaskswithhumanspeech
transcript. We classify our candidate public pre-
1https://platform.openai.com/docs/models/
gpt-3-5-turbo trainedmodelsintotwocategories: SmallMultilin-
4202
nuJ
72
]LC.sc[
1v85391.6042:viXragualLanguageModels(SMLM)2 suchasXLM-R performGPT-3.5andGPT-4insentimentanal-
andmT5,andmorerecentLargeLanguageMod- ysistaskswithfew-shotcross-lingualtransfer.
els (LLM)3 primarily focused on English such
as Llama-3 (AI@Meta, 2024) and Mistral (Jiang 2 Background
et al., 2023). In addition, we also include bench-
2.1 Cross-lingualSentimentAnalysis
marking with proprietary LLMs such as GPT-4
(OpenAI et al., 2024), which is widely consid- Sentimentanalysis,asanimportantsubfieldofNat-
ered as the best LLM in terms of general capa- uralLanguageProcessing,concentratesondetect-
bility. Toavoidpotentialdatacontaminationintro- ingandcategorizingemotionsandopinionsinthe
ducedinthepre-trainingprocessofrecentLLMs text. Althoughtheresearchpredominantlyfocused
(Sainz et al., 2023), we curate and annotate pro- ontheEnglishlanguageinitially,subsequentefforts
prietarysentimentdatasetsfromin-househuman haveexpandedtosupportcross-lingualsentiment
conversation transcripts, and assess cross-lingual analysis. Thisapproachaimsatleveragingoneor
sentimentanalysisfromEnglishtothreetargetlan- severallinguistically-richsourcelanguagestoen-
guages: Spanish,FrenchandChinese. Ourevalu- hancetaskperformanceinlow-resourcelanguages
ation results show that with the same supervised (Xuetal.,2022). Earlymethodssuchas(Shanahan
fine-tuning, SMLMs demonstrate superior zero- et al., 2005) used Machine Translation for cross-
shot cross-lingual transfer capability even with lingualsentimentanalysis,whichbecamethemain-
much fewer model parameters. However, public streammethodologyinthefollowingyears. Other
LLMsexhibitrapidimprovementinfew-shotcross- studiesfocusedonbridgingthedatasetdisparities
lingualtransferscenariosandcansurpasstheper- betweensourceandtargetlanguages(Zhangetal.,
formanceofSMLMswhenadditionalsamplesin 2016), as well as generating parallel corpora for
thetargetlanguageareprovided. Ourcontributions sentiment analysis tasks (Lu et al., 2011) (Meng
ofthisresearchcanbesummarizedinthefollowing etal.,2012).
dimensions: The success of pre-trained models like BERT
(Devlin et al., 2019) has spurred adaptations for
1. Weprovideacomprehensivecomparisonon multilingualandcross-lingualapplications,notably
fine-tuning-basedcross-lingualtransfercapa- mBERTandXLM-R,whichutilizeatransformer
bilityacrossaspectrumofpublicpre-trained encoder architecture and demonstrate strong ca-
languagemodels,withupto8billionparam- pability in cross-lingual language understanding.
eters in the sentiment analysis task on three Thesemodelsarepre-trainedwithextensivemul-
humanlanguages. tilingual corpora and subsequently fine-tuned for
specific downstream tasks, thereby significantly
2. Our empirical findings show that some enhancingsentimentanalysistasksacrossdiverse
SMLMs (XLM-R, mT5) beat much larger languages(Barbierietal.,2022). (Xueetal.,2021)
publicLLMsinzero-shotcross-lingualtrans- introduced mT5, which features a transformer
fer. Nevertheless, larger LLMs surpass encoder-decoder architecture and is pre-trained
SMLMsanddemonstratestrongeradaptation acrossover101languages,hasshownsuperiorper-
capabilitywithfew-shotfine-tuninginthetar- formanceinclassificationtaskssuchasXNLI(Con-
get language. The best-performing SMLMs neauetal.,2018)andsurpassedbothmBERTand
stillshowcomparableperformancetoLLMs XLM-R.Morerecently,advancementsinunsuper-
whenmoresamplesfromthetargetlanguage visedcorporaandcomputationalresourceshavefa-
areprovided. cilitatedtheemergenceofLLMswithatransformer
decoder-onlyarchitecture,whichhaveexhibitedex-
3. We demonstrate that although proprietary ceptionalperformanceinvariousNLPtasks(Tou-
GPT-3.5andGPT-4presentthestrongestper- vronetal.,2023)(Jiangetal.,2023)(Brownetal.,
formanceinzero-shotcross-lingualsentiment 2020). Despitetheseadvancements,suchLLMsare
analysis,withsupervisedfine-tuning,several predominantlyEnglish-centric,andtheirmultilin-
public pre-trained language models can out- gualcapabilitiesremainsomewhatambiguousdue
tolimiteddisclosureoftrainingdataspecifics. Fur-
2WeselectSMLMswithfewerthan4Bparametersinthis
thermore,thecapabilitiesofcross-lingualtransfer
work.
3WeselectLLMswithatleast7Bparametersinthiswork. intheseLLMshaveyettobethoroughlystudied.Supervised Fine-tuning In-context learning
Classification-based fine-tuning Instruction-based fine-tuning
Zero-shot cross-lingual Few-shot cross-lingual
Zero-shot cross-lingual Few-shot cross-lingual
Zero-shot cross-lingual Few-shot cross-lingual Fine-tune Predict Fine-tune Predict Predict Predict
F E E Ein N N Ne , , … - E Et Eu N N Nn , , e Pre Fd Rict Fi E E En N N Ne , ,- … t E E Eu N N Nn , , e F FR R, Pr Fe Rdict P P … Pr r ro o om m mp p pt t t { { {E E EN N N} } }, , P {Fr Ro }mpt P P … Pr r ro o om m mp p pt t t P P{ { { r rE E E o oN N N m m} } }, , p
p
t
t
{ {F FR R} }, P {Fr Ro }mpt P I E P }nr rN-o ec , dm o E in cp N ttt , :e { E Fx RNt e , x Ea Nm …p El Nes: P I E P }nr rN-o ec , dm o E in cp N ttt , :e { E Fx RNt e …x Ea Nm , p Fl Res:
Pre-trained Pre-trained
Proprietary Model
Encoder Model Generative Model
Classification layer
Text generation Text generation
Class prediction
Class label Class text Class text
Class label Class text
Class label Class text
Class label Class text
Class label Class text
Figure1: Diagramofzero-andfew-shotcross-lingualsentimentanalysisfromEnglish(EN)toFrench(FR)underSupervised
Fine-tuning(left)andIn-contextlearning(right).
2.2 SentimentAnalysisinConversational ("This is the fifth time I’m calling you guys") in-
Transcripts steadofspeakingupandexpressinghowfrustrated
they are with a simple and straightforward adjec-
Ourworkissituatedwithinthecontextofhuman
tive,suchas"Estoy frustrado"("Iamfrustrated").
conversational transcript data; in our case, these
Whereas the statistical models will easily detect
transcriptdataareobtainedfromourinternalcom-
"frustrado"andlabelitasnegativesentiment,the
pany call centers, consisting of human-to-human
abstractdescriptionthatthespeakerchoosesinor-
conversations that mainly occur between a cus-
dertoexpresstheirfrustrationinthefirstexample
tomerandacustomersupportagent.
willstillpresentachallenge.
Analyzingsuchtranscriptdatacanbechalleng-
ing to work with, even for English NLP mod-
3 Methodology
els: conversational data contain mainly artifacts
of spoken language, such as filler words, dysflu- 3.1 SupervisedFine-tuning
encies, and transcription errors by the automated
Theobjectiveofthisworkistoexplorethecross-
speechrecognition(ASR)model(Fuetal.,2022).
lingual transfer capability of pre-trained models
Adding additional complexity by moving away
withinthecontextofasentimentanalysistask. To
from English-only data into other languages pro-
thisend,weemploySupervisedFine-tuning(SFT)
vides an opportunity to further test the limits of
onpubliclyavailablepre-trainedmodelsusingan-
pre-trainedlanguagemodels: switchingfromone
notatedproprietarysentimentdatasets(detailedin
languagetoanotherdoesnotalwayslenditselftoa
Section 4.1). Each model is fine-tuned to catego-
simple,one-to-onetranslationofeachword–espe-
rize sentiments as Positive, Negative, or Neutral
ciallyindescribingorexpressingabstractconcepts
based on the input provided. Given the diversity
likesentiment.
inpre-trainingobjectivesamongdifferentmodels,
Thiscomplexityincross-lingualsentimentanal- weimplementtwodistinctfine-tuningapproaches
ysisalsocomesfromtheneedofconsideringboth illustrated in Figure 1, which are tailored to the
cultural and linguistic differences. For instance, architectureofthepre-trainedmodels:
oneofourmainobservationsonsentimentclassifi-
cationinrealhumanconversationinSpanishwas • Classification-basedfine-tuning: applicable
thatSpanishspeakersseemtofocusondescribing to transformer encoder-only models such as
theircomplaintorsituationinsteadofdirectlyex- mBERTandXLM-R,weaddaclassification
pressingtheiremotions. Forexample,theywould layerontopofthepre-trainedmodelsandfine-
rathersay"Esta es la quinta vez que los llamo" tunethemodeltodirectlypredictasentimentEnglish(EN) Spanish(ES) French(FR) Chinese(ZH)
We’re busy, we can’t Estamos ocupados, no Noussommesoccupés, 我们很忙，我们没什
complain,we’refine. podemosquejarnos,es- nous ne pouvons pas 么要抱怨的，没事。
tamosbien. nous plaindre, nous al-
Neutral
lonsbien.
There, I don’t know Ahí,noséporqué. Là, je ne sais pas 这个，我不知道为什
why. pourquoi. 么。
I love the first one so Meencantaelprimero, J’adorelepremieralors 我很喜欢第一个，对
I’mexcitedforthisone, así que estoy emo- jesuisexcitépourcelui- 此我感到很兴奋，谢
thanks. cionado por este, ci,merci. 谢。
Positive gracias.
This is great, so pro- Estoesgenial,muypro- C’est génial, tellement 很好这非常专业，我
fessional, I’m sure the fesional, estoy seguro professionnel, je suis 相信客户一定印象非
client was very im- dequeelclientequedó sûr que le client était 常深刻。
pressed. muyimpresionado. trèsimpressionné.
Ithinkhe’sreallypissed Creoquehoyestámuy Je pense qu’il est vrai- 我感觉他今天对我一
atmetoday. enojadoconmigo. menttrèsénervécontre 定非常生气。
moiaujourd’hui.
Negative
Yes but I’m worried Sí, pero ahora me pre- Ouimaisjesuisinquiet 是的，但我对于被
about being charged ocupa que me cobren d’êtrefacturédeuxfois 收两次费用感到很担
twicenow. dosveces. maintenant. 心。
Table1: Examplesofourproprietarysentimentdatasets.
class. dataprivacypolicy,wearenotabletofine-tunepro-
prietaryLLMsusingourproprietarydatasets. Con-
• Instruction-based fine-tuning: used for
sequently,weemployin-contextlearningthrough
transformerencoder-decoder(e.g. mT5)and
the prompt to simulate an experiment setting as
decoder-only (e.g. Llama-3) structures, we
conducting SFT on public models. Nonetheless,
constructaninstructiontopromptthemodel
theinherentlimitationregardingthecontextlength
to generate a text output corresponding to a
in various close source LLMs poses a challenge;
sentimentclass. Thespecificpromptformat
thesemodelsmaynotaccommodateasmanyexam-
isdetailedinAppendixA.1.
pleswithinapromptasisfeasibleforSFTinopen
sourcecounterparts. Figure1showsanillustrative
To comprehensively evaluate the cross-lingual
diagram of in-context learning for this sentiment
transfer capabilities of these pre-trained models
analysistask.
throughfine-tuning,wetargetbothzero-andfew-
To assess cross-lingual transfer capabilities as
shot cross-lingual transfer from a source to a tar-
getlanguage. InZero-shotCross-lingualTransfer Section 3.1 through in-context learning, we con-
structin-contextexampleswithdifferentsourcesof
setting,themodelisfine-tunedexclusivelywithan
languagesaccordingly. Specifically,forZero-shot
annotateddatasetinthesourcelanguageandsubse-
Cross-lingualTransfer,thepromptsincludeexam-
quentlytaskedwithmakingpredictionsinatarget
plessolelyfromthesourcelanguage. Incontrast,
language. Note that for generative tasks, merely
forFew-shotCross-lingualTransfer,additionalsup-
input language alteration is applied while the in-
struction component remains constant. Few-shot plementaryexamplesinthetargetlanguagearealso
Cross-lingualTransferextendsthezero-shotframe- applied. Promptswithin-contextexamplesweuse
to evaluateproprietary LLMs are attached inAp-
workbyadditionallyincorporatingNlabeledexam-
pendixA.2.
plesfromthetargetlanguageintothefine-tuning
process,alongsidethesourcelanguagedataset. The
4 Experiment
formatofthepromptusedremainsconsistentwith
zero-shotforgenerativetasks,detailedinAppendix Inthissection,wefirstpresentadetaileddescrip-
A.1. tionofourinternalproprietarysentimentdatasets
which are used for fine-tuning and evaluation.
3.2 In-contextLearning
Then,weprovidenecessaryintroductionstoadi-
Recentadvancementshavehighlightedin-context verse array of public pre-trained models we will
learning as a viable alternative to the traditional studyforthiswork. Finally,weshowthehardware
fine-tuningapproachforgenerativemodels(Dong andsoftwareresourcesemployedinconductingthe
etal.,2023). Duetotheaccesslimitationandour experiment.Modeltype Name Architecture #ofparam. Claimedlanguagesupport
mBERT encoder 110M 104langs
XLM-R-base encoder 250M 100langs
XLM-R-large encoder 560M 100langs
SMLM
mT5-base encoder-decoder 580M 101langs
mT5-large encoder-decoder 1.2B 101langs
mT5-xl encoder-decoder 3.7B 101langs
Mistral-7B decoder 7B Unclear
Falcon-7B decoder 7B MainlyEN,DE,ES,FR
English-centricLLM
Llama2-7B decoder 7B IntendedforEN
Llama3-8B decoder 8B IntendedforEN
Table2: Listofpublicpre-trainedmodelsevaluatedinourexperiments.
4.1 Dataset to be accurate translations by the speakers of the
targetlanguages.
The proprietary datasets used in this study are
Asourobjectiveistostudythecross-lingualsen-
utterance-levelsentimentdataforfourlanguages:
timent analysis from English to target languages,
English, Spanish, French, Chinese (Table 1). Ut-
weassembleEnglishdatawithamuchlargersize,
teranceboundariesaregeneratedbyourin-house
whileSpanish,FrenchandChinesewithalimited
ASRsystemwhenashortpauseorspeakerchange
amount sufficient only to support few-shot learn-
isdetectedintheaudiostream. Werandomlysam-
ingandtestingpurposes. Asummaryofthetotal
pledEnglishandSpanishutterancesfromthereal
amountofdatausedforthefollowingexperiment
conversational transcript from our call center ap-
isasfollows:
plicationsandeachinstanceislabeledasPositive,
Negative or Neutral by human annotators. The
- English: 30,000 instances for fine-tuning,
annotation was done via a third-party vendor, al-
3,000fordevelopment.
lowingustoconfigureourontologyanddirectthe
annotatorstoselecttheappropriatecategoryforthe - Spanish: 600 instances for fine-tuning and
sentimentdetectedineachutteranceaccordingto 3,000fortesting.
guidelineswedeveloped. Ourguidelinesinclude
definitions for each sentiment as well as a broad - French: 600 instances for fine-tuning and
listofexamples(agolddatasetmanuallyannotated 3,000fortesting.
byourinternalteam). Inter-annotatoragreementis
- Chinese: 600 instances for fine-tuning and
calculatedautomaticallybyourannotationvendor,
3,000fortesting.
andahighagreementthresholdisappliedtoensure
thequalityoftheannotationresults.4
where we ensure sentiment labels are uniformly
Constrained by resources, we are not able to
distributedacrossallsets.
sampleandannotateFrenchandChinesedatasets
Table 1 shows exemplary cases of our propri-
under the same setting. Instead, we leverage ma-
etarydatasetsindifferentlanguages,providingin-
chinetranslation(throughGPT-4,detailedinAp-
sight into domain-specific textual characteristics.
pendixA.3)tocreateparallelFrenchandChinese
It is worth mentioning that these examples have
datasetsbasedontheannotatedEnglishcounterpart.
noidentifyinginformationandareintendedforil-
Allmachine-translateddatasetswerereviewedby
lustrative purposes only. The use of internal call
speakersofthetargetlanguagetoensurethatthe
transcript data ensures that all model evaluations
translations were comparable to the original En-
areimmunefromunintendeddatacontaminationof
glish. Thereweresomeminorissuesidentifiedin
thepre-trainedmodels,whichcouldotherwiselead
themachine-translateddataduringreview: namely,
to an overestimation of their performance (Sainz
occasionallyGPT-4refusestotranslateasample,
etal.,2023).
producingarefusalinthetargetlanguageinstead,
oritproducedacommentaryontheEnglishtran- 4.2 Selectedpre-trainedModels
script in the target language in lieu of translating
In this work, we investigate a variety of public
it directly. These samples were identified and re-
pre-trainedlanguagemodels,witharangeofsizes
moved, and the remaining samples were deemed
and architectures. For SMLM, we have selected
4https://docs.labelbox.com/docs/consensus models from mBERT, XLM-R and mT5 modelPublicSMLM PublicLLM ProprietaryLLM
SupervisedFine-tuning SupervisedFine-tuning In-contextLearning
mBERT XLM- XLM- mT5- mT5- mT5-xl Mistral Falcon Llama- Llama- GPT- GPT-4
R-base R-large base large 2 3 3.5
110M 250M 560M 580M 1.2B 3.7B 7B 7B 7B 8B - -
ES 47.1 54.4 58.7 60.2 63.4 60.0 44.8 55.3 60.1 57.9 75.6 74.8
FR 45.3 71.8 76.8 75.4 79.7 73.8 48.4 70.7 74.5 77.4 80.3 79.3
ZH 54.2 72.3 76.9 74.8 77.3 71.5 40.4 71.9 64.9 73.3 82.3 80.2
Avg 48.9 66.2 70.8 70.1 73.5 68.4 44.5 66.0 66.5 69.5 79.4 78.1
Table3: F1scorecomparisoninzero-shotcross-lingualtransferonourproprietarysentimentanalysisdatasets.ES:Spanish,
FR:French,ZH:Chinese.Top-3averageF1scoresaremarkedinbold.
Figure2: AverageF1scoreperformancecomparison(acrossES,FRandZH)underN-shotsettings.GPT-3.5isnotincludedin
this600-shotduetothecontextlengthlimit.
familieswithupto3.7billionparameters. Allmod- For experiments on proprietary LLMs, we use
els in our SMLM selection are known for their “gpt-3.5-turbo-0125” endpoint for GPT-
support for over 100 human languages and have 3.5and“gpt-4-1106-preview”endpointfor
demonstratedefficacyintasksthatrequiremultilin- GPT-4.
gual and cross-lingual capabilities, as evidenced Inordertoensuredeterministicoutputfromgen-
by references (Doddapaneni et al., 2021) (Xue erativemodels,temperatureissetas0forallpublic
et al., 2021). For English-centric LLMs, the de- andproprietarymodelsinourexperiments.
tails are little disclosed regarding the specific hu-
manlanguagesincorporatedduringthepre-training 5 Results
phase. Therefore,weincludethemostprominent
Tofacilitateacomprehensivecomparisonbetween
andwidelyrecognizedmodelsfromLlamafamily
SMLMsandLLMsoncross-lingualsentimentanal-
andMistralwith7to8billionparameterssizes. In
ysis, we follow the zero-shot and few-shot cross-
additional, Falcon-7B is also added to our analy-
lingualfine-tuningmethodologiesdescribedin3.1
sis as it explicitly claims proficiency in German,
andevaluatethemodelperformancerespectively.
Spanish and French in addition to English. The
TheF1score(micro)isemployedastheaccuracy
specifics of all the pre-trained models utilized in
evaluationmetricinthefollowingsentimentanaly-
ourexperimentsaredetailedinTable2.
sisexperiments.
4.3 ExperimentSetup
5.1 Zero-shotCross-lingualTransfer
The fine-tuning and inference processes for our
modelareconductedusingtheHuggingfaceframe- Wefirstfine-tunepublicpre-trainedmodelsinzero-
work(Wolfetal.,2020)onasingle-nodeLinuxsys- shotcross-lingualtransfersettingthroughSFTas
temequippedwitheightNvidiaA10080GGPUs. detailedinSection3.1,exposedtoonlytheEnglishfine-tuningdatasetdescribedin4.1. Notethatwe sentimentanalysis. Notably,allpublicLLMs
leveragein-contextlearningforproprietaryLLMs exhibitsignificantrelativeimprovementscom-
asdiscussedinSection3.2. However,duetocon- pared to their zero-shot performance. It is
straintsoncontextlength,theseproprietaryLLMs worthpointingoutthatwith60-shotand150-
arenotexposedtotheentiretyoftheEnglishfine- shot, LLMs such as Falcon-7B, Llama2-7B
tuningset;instead,theyarepromptedwithasetof andLlama3-8Bsurpasstheperformanceofall
300examples,carefullybalancedacrossdifferent SMLMs by a considerable margin. The only
classesforthisexperiment. exception is Mistral-7B, which is still outper-
EvaluationresultsarepresentedinTable3. Itis formedbyseveralSMLMswithfew-shot.
clearthatbothGPT-3.5andGPT-4exhibitsignifi-
ii With an increased volume of training data in
cantadvantagesoverfine-tunedpublicmodelson
thetargetlanguage,specificallyunder600-shot
targetlanguagesinzero-shot. Surprisingly,among
condition, mT5-xl with 3.7B parameters has
thepublicmodels,severalSMLMssuchasXLM-
acomparableperformancetothemuchlarger
R-large(560M),mT5-base(580M)andmT5-large
Falcon-7B, Llama2-7B and Llama3-8B mod-
(1.2B), show better zero-shot cross-lingual trans-
els.
fercapabilitycomparedtotheconsiderablylarger
Mistral-7B, Falcon-7B, Llama2-7B and Llama3-
iii Contrary to their dominance in the zero-shot
7Bmodels. Inparticular,mT5-largesurpassesall
cross-lingual setting, GPT-4 and GPT-3.5 ex-
otheropensourcecandidatesbyasubstantialmar-
hibit very limited improvement in few-shot
ginacrossalltestinglanguagesdespitehavingonly
cross-lingualsentimentanalysiswithin-context
1.2billionparameters.
examples. Severalpublicmodelsarecapableof
surpassingtheseprominentproprietaryLLMs
5.2 Few-shotCross-lingualTransfer
followingfine-tuning.
Wethenfine-tuneandevaluatepublicmodelsun-
der the few-shot cross-lingual transfer setting de- 6 Conclusion
scribed in Section 3, where we randomly select
Inthisstudy,weexplorethecapabilitiesofcross-
N trainingsamplesinthetargetlanguageanduse
lingualsentimentanalysisacrossavarietyofpre-
theminfine-tuninginconjunctionwiththeEnglish
trained language models. We show that smaller
fine-tuningdata. Inordertobetterinvestigatethe
XLM-R-large(560M),mT5-base(580M)andmT5-
adaptabilityofthemodels,wevaryNamong{60,
large(1.2B)havesuperiorzero-shotcross-lingual
150,600},therebyconducting60-shot,150-shot
transfer capabilities compared to the consider-
and600-shotexperimentsrespectively. Theselec-
ablylargerMistral-7B,Falcon-7B,Llama2-7Band
tionofthesethreevaluesprovidesawidespectrum
Llama3-8Bmodels. Thishighlightstheefficiency
forcomparativeanalysis,alsoensuresasufficient
andpotentialofSmallMultilingualLanguageMod-
representationwhilemaintainingresource-efficient.
els(SMLM)forsentimentanalysisinlow-resource
ForproprietaryLLMs,anadditionalN samplesin
languages. Ontheotherhand,ourfindingsreveal
targetlanguageareappendedtothepromptduring
thatthelargerEnglish-centricLLMslikeFalcon-
in-contextlearningtoestablishasimilarfew-shot
7B and Llama2-7B can quickly adapt and show
cross-lingualsetup.
muchimprovedperformancewithafew-shotcross-
The evaluation results of average F1 scores
lingual setup, which indicates their robustness in
acrossthreetargetlanguages(ES,FRandZH)are
learningfromlimiteddatafromthetargetlanguage.
presentedinFigure2,underthesettingsof60-shot,
Moreover,proprietaryLLMssuchasGPT-3.5and
150-shotand600-shot. DetailedF1scoresperlan-
GPT-4exhibitthestrongestzero-shotperformance
guage are also provided in Appendix A.4. Our
incross-lingualsentimentanalysistasks,however,
observations and findings can be summarized as
in scenarios involving few-shot learning, several
follows:
fine-tuned public pre-trained models are able to
surpasstheseproprietarygiants.
i Amongpublicpre-trainedmodels,despitetheir
underperformancerelativetoSMLMsinzero-
7 Limitation
shotcross-lingualtransferasevidencedinTa-
ble 3, English-centric LLMs present strong Although our findings in this study appear to
adaptationcapabilityinfew-shotcross-lingual be consistent in all target languages tested, dueto the limitation of our resources, it is still un- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
clearhowthemodelswouldbehaveinotherlow- Kristina Toutanova. 2019. BERT: Pre-training of
deepbidirectionaltransformersforlanguageunder-
resourcelanguageswithevenlessappearancedur-
standing. InProceedingsofthe2019Conferenceof
ing pre-training. In addition, due to the incom-
theNorthAmericanChapteroftheAssociationfor
parable model sizes, we are not able to draw any ComputationalLinguistics: HumanLanguageTech-
conclusionsonwhethermodelarchitecturediffer- nologies,Volume1(LongandShortPapers),pages
4171–4186,Minneapolis,Minnesota.Associationfor
ence(transformerencoder-only,decoder-onlyand
ComputationalLinguistics.
encoder-decoder)couldplayaroleincross-lingual
sentiment analysis capabilities. Further research SumanthDoddapaneni,GowthamRamesh,MiteshM.
couldbeextendedinthesedirections. Khapra,AnoopKunchukuttan,andPratyushKumar.
2021. Aprimeronpretrainedmultilinguallanguage
models. Preprint,arXiv:2107.00676.
References
QingxiuDong,LeiLi,DamaiDai,CeZheng,Zhiyong
AI@Meta.2024. Llama3modelcard. Wu,BaobaoChang,XuSun,JingjingXu,LeiLi,and
ZhifangSui.2023. Asurveyonin-contextlearning.
Matheus Araújo, Adriano Pereira, and Fabrício Ben- Preprint,arXiv:2301.00234.
evenuto. 2020. A comparative study of machine
translationformultilingualsentence-levelsentiment Xue-yong Fu, Cheng Chen, Md Tahmid Rahman
analysis. InformationSciences,512:1078–1102. Laskar, Shayna Gardiner, Pooja Hiranandani, and
Shashi Bhushan Tn. 2022. Entity-level sentiment
Francesco Barbieri, Luis Espinosa Anke, and Jose analysis in contact center telephone conversations.
Camacho-Collados. 2022. XLM-T: Multilingual InProceedingsofthe2022ConferenceonEmpirical
language models in Twitter for sentiment analysis MethodsinNaturalLanguageProcessing: Industry
andbeyond. InProceedingsoftheThirteenthLan- Track,pages484–491,AbuDhabi,UAE.Association
guageResourcesandEvaluationConference,pages forComputationalLinguistics.
258–266,Marseille,France.EuropeanLanguageRe-
sourcesAssociation. AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen-
sch,ChrisBamford,DevendraSinghChaplot,Diego
BigScience Workshop. 2022. BLOOM (revision delasCasas,FlorianBressand,GiannaLengyel,Guil-
4ab0472). laumeLample,LucileSaulnier,LélioRenardLavaud,
Marie-AnneLachaux,PierreStock,TevenLeScao,
TomB.Brown,BenjaminMann,NickRyder,Melanie Thibaut Lavril, Thomas Wang, Timothée Lacroix,
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind andWilliamElSayed.2023. Mistral7b. Preprint,
Neelakantan,PranavShyam,GirishSastry,Amanda arXiv:2310.06825.
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child, PratikJoshi, SebastinSanty, AmarBudhiraja, Kalika
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Bali,andMonojitChoudhury.2020. Thestateand
Clemens Winter, Christopher Hesse, Mark Chen, fateoflinguisticdiversityandinclusionintheNLP
EricSigler,MateuszLitwin,ScottGray,Benjamin world. InProceedingsofthe58thAnnualMeetingof
Chess, Jack Clark, Christopher Berner, Sam Mc- theAssociationforComputationalLinguistics,pages
Candlish, AlecRadford, IlyaSutskever, andDario 6282–6293,Online.AssociationforComputational
Amodei.2020. Languagemodelsarefew-shotlearn- Linguistics.
ers. Preprint,arXiv:2005.14165.
Anne Lauscher, Vinit Ravishankar, Ivan Vulic´, and
AlexisConneau,KartikayKhandelwal,NamanGoyal, Goran Glavaš. 2020. From zero to hero: On the
Vishrav Chaudhary, Guillaume Wenzek, Francisco limitationsofzero-shotlanguagetransferwithmul-
Guzmán, Edouard Grave, Myle Ott, Luke Zettle- tilingualTransformers. InProceedingsofthe2020
moyer,andVeselinStoyanov.2020. Unsupervised Conference on Empirical Methods in Natural Lan-
cross-lingualrepresentationlearningatscale. InPro- guageProcessing(EMNLP),pages4483–4499,On-
ceedings of the 58th Annual Meeting of the Asso- line.AssociationforComputationalLinguistics.
ciationforComputationalLinguistics,pages8440–
8451, Online. Association for Computational Lin- BinLu,ChenhaoTan,ClaireCardie,andBenjaminK.
guistics. Tsou.2011. Jointbilingualsentimentclassification
withunlabeledparallelcorpora. InProceedingsof
AlexisConneau,RutyRinott,GuillaumeLample,Ad- the49thAnnualMeetingoftheAssociationforCom-
inaWilliams,SamuelR.Bowman,HolgerSchwenk, putationalLinguistics: HumanLanguageTechnolo-
andVeselinStoyanov.2018. Xnli: Evaluatingcross- gies,pages320–330,Portland,Oregon,USA.Asso-
lingualsentencerepresentations. InProceedingsof ciationforComputationalLinguistics.
the2018ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing.AssociationforComputa- Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou,
tionalLinguistics. Ge Xu, and Houfeng Wang. 2012. Cross-lingualmixturemodelforsentimentclassification. InPro- Henrique Ponde de Oliveira Pinto, Michael, Poko-
ceedingsofthe50thAnnualMeetingoftheAssocia- rny,MichellePokrass,VitchyrH.Pong,TollyPow-
tionforComputationalLinguistics(Volume1: Long ell, Alethea Power, Boris Power, Elizabeth Proehl,
Papers),pages572–581,JejuIsland,Korea.Associa- RaulPuri,AlecRadford,JackRae,AdityaRamesh,
tionforComputationalLinguistics. CameronRaymond,FrancisReal,KendraRimbach,
Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-
OpenAI,JoshAchiam,StevenAdler,SandhiniAgarwal, der,MarioSaltarelli,TedSanders,ShibaniSanturkar,
Lama Ahmad, Ilge Akkaya, Florencia Leoni Ale- GirishSastry,HeatherSchmidt,DavidSchnurr,John
man,DiogoAlmeida,JankoAltenschmidt,SamAlt- Schulman, Daniel Selsam, Kyla Sheppard, Toki
man,ShyamalAnadkat,RedAvila,IgorBabuschkin, Sherbakov, Jessica Shieh, Sarah Shoker, Pranav
SuchirBalaji,ValerieBalcom,PaulBaltescu,Haim- Shyam,SzymonSidor,EricSigler,MaddieSimens,
ing Bao, Mohammad Bavarian, Jeff Belgum, Ir- JordanSitkin,KatarinaSlama,IanSohl,Benjamin
wanBello,JakeBerdine,GabrielBernadett-Shapiro, Sokolowsky, Yang Song, Natalie Staudacher, Fe-
ChristopherBerner,LennyBogdonoff,OlegBoiko, lipePetroskiSuch,NatalieSummers,IlyaSutskever,
MadelaineBoyd,Anna-LuisaBrakman,GregBrock- Jie Tang, Nikolas Tezak, Madeleine B. Thompson,
man, Tim Brooks, Miles Brundage, Kevin Button, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng,
TrevorCai,RosieCampbell,AndrewCann,Brittany PrestonTuggle,NickTurley,JerryTworek,JuanFe-
Carey, Chelsea Carlson, Rory Carmichael, Brooke lipeCerónUribe,AndreaVallone,ArunVijayvergiya,
Chan,CheChang,FotisChantzis,DerekChen,Sully ChelseaVoss,CarrollWainwright,JustinJayWang,
Chen, Ruby Chen, Jason Chen, Mark Chen, Ben AlvinWang,BenWang,JonathanWard,JasonWei,
Chess,ChesterCho,CaseyChu,HyungWonChung, CJWeinmann,AkilaWelihinda,PeterWelinder,Ji-
Dave Cummings, Jeremiah Currier, Yunxing Dai, ayiWeng,LilianWeng,MattWiethoff,DaveWillner,
Cory Decareaux, Thomas Degry, Noah Deutsch, Clemens Winter, Samuel Wolrich, Hannah Wong,
Damien Deville, Arka Dhar, David Dohan, Steve Lauren Workman, Sherwin Wu, Jeff Wu, Michael
Dowling,SheilaDunning,AdrienEcoffet,AttyEleti, Wu,KaiXiao,TaoXu,SarahYoo,KevinYu,Qim-
TynaEloundou,DavidFarhi,LiamFedus,NikoFelix, ingYuan,WojciechZaremba,RowanZellers,Chong
SimónPosadaFishman, JustonForte, IsabellaFul- Zhang, Marvin Zhang, Shengjia Zhao, Tianhao
ford,LeoGao,ElieGeorges,ChristianGibson,Vik Zheng, Juntang Zhuang, William Zhuk, and Bar-
Goel,TarunGogineni,GabrielGoh,RaphaGontijo- ret Zoph. 2024. Gpt-4 technical report. Preprint,
Lopes, Jonathan Gordon, Morgan Grafstein, Scott arXiv:2303.08774.
Gray,RyanGreene,JoshuaGross,ShixiangShane
Gu,YufeiGuo,ChrisHallacy,JesseHan,JeffHarris, Libo Qin, Qiguang Chen, Yuhang Zhou, Zhi Chen,
YuchenHe,MikeHeaton,JohannesHeidecke,Chris YinghuiLi,LiziLiao,MinLi,WanxiangChe,and
Hesse,AlanHickey,WadeHickey,PeterHoeschele, Philip S. Yu. 2024. Multilingual large language
Brandon Houghton, Kenny Hsu, Shengli Hu, Xin model: Asurveyofresources, taxonomyandfron-
Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, tiers. Preprint,arXiv:2404.04925.
Joanne Jang, Angela Jiang, Roger Jiang, Haozhun
Jin, Denny Jin, Shino Jomoto, Billie Jonn, Hee- Oscar Sainz, Jon Campos, Iker García-Ferrero, Julen
woo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Ka- Etxaniz,OierLopezdeLacalle,andEnekoAgirre.
mali, Ingmar Kanitscheider, Nitish Shirish Keskar, 2023. NLPevaluationintrouble:Ontheneedtomea-
Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, sureLLMdatacontaminationforeachbenchmark.
Christina Kim, Yongjik Kim, Jan Hendrik Kirch- In Findings of the Association for Computational
ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Linguistics: EMNLP2023,pages10776–10787,Sin-
Łukasz Kondraciuk, Andrew Kondrich, Aris Kon- gapore.AssociationforComputationalLinguistics.
stantinidis, Kyle Kosic, Gretchen Krueger, Vishal
Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan James Shanahan, Gregory Grefenstette, Yan Qu, and
Leike, Jade Leung, Daniel Levy, Chak Ming Li, David Evans. 2005. Mining multilingual opinions
Rachel Lim, Molly Lin, Stephanie Lin, Mateusz throughclassificationandtranslation.
Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue,
AnnaMakanju,KimMalfacini,SamManning,Todor Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
Markov, Yaniv Markovski, Bianca Martin, Katie bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Mayer,AndrewMayne,BobMcGrew,ScottMayer Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
McKinney, Christine McLeavey, Paul McMillan, Bhosale,DanBikel,LukasBlecher,CristianCanton
Jake McNeil, David Medina, Aalok Mehta, Jacob Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
Menick, Luke Metz, Andrey Mishchenko, Pamela JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
Mishkin, Vinnie Monaco, Evan Morikawa, Daniel CynthiaGao,VedanujGoswami,NamanGoyal,An-
Mossing,TongMu,MiraMurati,OlegMurk,David thonyHartshorn,SagharHosseini,RuiHou,Hakan
Mély,AshvinNair,ReiichiroNakano,RajeevNayak, Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
ArvindNeelakantan,RichardNgo,HyeonwooNoh, IsabelKloumann,ArtemKorenev,PunitSinghKoura,
LongOuyang,CullenO’Keefe,JakubPachocki,Alex Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
Paino, Joe Palermo, Ashley Pantuliano, Giambat- anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tistaParascandolo,JoelParish,EmyParparita,Alex tinet,TodorMihaylov,PushkarMishra,IgorMoly-
Passos,MikhailPavlov,AndrewPeng,AdamPerel- bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
man,FilipedeAvilaBelbutePeres,MichaelPetrov, stein,RashiRungta,KalyanSaladi,AlanSchelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama- "Positive": The speaker expresses fa-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
vorable emotions and mental states, for
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
example, euphoria and joy, happiness,
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Melanie Kambadur, Sharan Narang, Aurelien Ro- excitement, fascination, satisfaction,
driguez,RobertStojnic,SergeyEdunov,andThomas pride, gratitude, relief, surprise, etc.
Scialom.2023. Llama2: Openfoundationandfine- "Negative": The speaker expresses unfa-
tunedchatmodels. Preprint,arXiv:2307.09288.
vorable emotions and mental states, for
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien example, disgust, sadness, disappoint-
Chaumond,ClementDelangue,AnthonyMoi,Pier- ment, worry, insecurity, annoyance, fury,
ricCistac,TimRault,RémiLouf,MorganFuntow-
anger, fear, depression, frustration,
icz,JoeDavison,SamShleifer,PatrickvonPlaten,
etc.
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame, "Neutral": Statement in which the
QuentinLhoest,andAlexanderM.Rush.2020. Hug- speaker does not express emotions, but
gingface’stransformers: State-of-the-artnaturallan- in which a fact is simply stated and no
guageprocessing. Preprint,arXiv:1910.03771.
explicit emotions or feelings are con-
YuemeiXu,HanCao,WanzeDu,andWenqingWang. veyed.
2022. A survey of cross-lingual sentiment analy- What is the sentiment in the following
sis: Methodologies, modelsandevaluations. Data
utterance? Only respond with the senti-
ScienceandEngineering,7:1–21.
ment without explanation:
LintingXue,NoahConstant,AdamRoberts,MihirKale, ### Input: {utterance text}
RamiAl-Rfou,AdityaSiddhant,AdityaBarua,and ### Output:
ColinRaffel.2021. mT5: Amassivelymultilingual
pre-trainedtext-to-texttransformer. InProceedings
ofthe2021ConferenceoftheNorthAmericanChap-
A.2 PromptFormatforIn-contextLearning
teroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies,pages483–498,On- Thefollowingpromptwithin-contextexamplesis
line.AssociationforComputationalLinguistics. usedforcallingproprietaryLLMAPIs:
Peng Zhang, Suge Wang, and Deyu Li. 2016. Cross-
lingualsentimentclassification: Similaritydiscovery Below is an utterance extracted from
plustrainingdataadjustment. Knowledge-BasedSys- the transcript of a business call, iden-
tems,107:129–141.
tify the speaker’s sentiment in this
WenxuanZhang,YueDeng,BingLiu,SinnoJialinPan, utterance. The sentiment should be one
andLidongBing.2023. Sentimentanalysisintheera of the following:
oflargelanguagemodels: Arealitycheck. Preprint,
"Positive": The speaker expresses fa-
arXiv:2305.15005.
vorable emotions and mental states, for
WenhaoZhu,HongyiLiu,QingxiuDong,JingjingXu, example, euphoria and joy, happiness,
Shujian Huang, Lingpeng Kong, Jiajun Chen, and excitement, fascination, satisfaction,
LeiLi.2023. Multilingualmachinetranslationwith
pride, gratitude, relief, surprise, etc.
largelanguagemodels: Empiricalresultsandanaly-
"Negative": The speaker expresses unfa-
sis. Preprint,arXiv:2304.04675.
vorable emotions and mental states, for
A Appendix example, disgust, sadness, disappoint-
ment, worry, insecurity, annoyance, fury,
A.1 PromptFormatforSupervised
anger, fear, depression, frustration,
Fine-tuning
etc.
We employ the following prompt format in "Neutral": Statement in which the
supervised fine-tuning for public generative speaker does not express emotions, but
models: in which a fact is simply stated and no
explicit emotions or feelings are con-
Below is an utterance extracted from veyed.
the transcript of a business call, iden- Here are some examples:
tify the speaker’s sentiment in this ### Input: {utterance text 1}
utterance. The sentiment should be one ### Output: {sentiment label 1}
of the following:### Input: {utterance text 2}
### Output: {sentiment label 2}
### Input: {utterance text 3}
### Output: {sentiment label 3}
...
What is the sentiment in the follow-
ing utterance? Only respond with the
sentiment without explanation:
### Input: {utterance text}
### Output:
A.3 Machinetranslationdetails
The machine translation process described in
Section 4.1 utilizes GPT-4 endpoint “gpt-4-
1106-preview”. Thepromptusedformachine
translationisasfollows:
Below is a transcribed utterance from
human conversations, translate it from
English to {TARGET_LANG}:
### Input: {English utterance}
### Output:
TARGET_LANGreferstothetargetlanguages
inourmachinetranslationprocess,i.e. Frenchand
Chinese.
A.4 Per-languageEvaluationTablesfor
Few-shotCross-lingual
Supplementary to Section 5.2, detailed per lan-
guageevaluationresultsonfew-shotcross-lingual
arelistedinTable4,Table5,andTable6PublicSMLM PublicLLM ProprietaryLLM
SupervisedFine-tuning SupervisedFine-tuning In-contextLearning
mBERT XLM- XLM- mT5- mT5- mT5-xl Mistral Falcon Llama- Llama- GPT- GPT-4
R-base R-large base large 2 3 3.5
110M 250M 560M 580M 1.2B 3.7B 7B 7B 7B 8B - -
ES 71.0 62.7 67.1 59.7 65.3 73.2 73.1 76.8 77.7 77.6 76.0 76.8
FR 69.3 79.7 82.7 76.1 83.7 83.8 76.1 82.3 84.7 85.2 81.6 80.3
ZH 73.7 80.0 81.7 78.0 80.8 80.7 74.9 84.0 81.2 83.5 80.1 80.4
Avg 71.3 74.1 77.2 71.3 76.6 79.2 74.7 81.0 81.2 82.1 79.2 79.2
Table4: F1scorecomparisonin60-shotcross-lingualtransferonourproprietarysentimentanalysisdatasets.ES:Spanish,FR:
French,ZH:Chinese.Top-3averageF1scoresaremarkedinbold.
PublicSMLM PublicLLM ProprietaryLLM
SupervisedFine-tuning SupervisedFine-tuning In-contextLearning
mBERT XLM- XLM- mT5- mT5- mT5-xl Mistral Falcon Llama- Llama- GPT- GPT-4
R-base R-large base large 2 3 3.5
110M 250M 560M 580M 1.2B 3.7B 7B 7B 7B 8B - -
ES 71.9 71.6 71.8 60.5 69.4 74.7 71.1 76.8 79.7 77.6 76.3 74.5
FR 71.3 82.0 82.9 78.0 83.3 83.0 76.0 86.1 84.2 82.9 81.9 78.7
ZH 76.8 82.7 84.1 78.4 81.7 83.6 78.7 84.5 85.6 85.2 81.7 82.6
Avg 73.3 78.8 79.6 72.3 78.1 80.4 75.3 82.5 83.2 81.9 80.0 78.6
Table5: F1scorecomparisonin150-shotcross-lingualtransferonourproprietarysentimentanalysisdatasets.ES:Spanish,FR:
French,ZH:Chinese.Top-3averageF1scoresaremarkedinbold.
PublicSMLM PublicLLM ProprietaryLLM
SupervisedFine-tuning SupervisedFine-tuning In-contextLearning
mBERT XLM- XLM- mT5- mT5- mT5-xl Mistral Falcon Llama- Llama- GPT- GPT-4
R-base R-large base large 2 3 3.5
110M 250M 560M 580M 1.2B 3.7B 7B 7B 7B 8B - -
ES 74.0 74.0 77.4 64.4 77.9 77.6 76.3 79.0 79.0 76.6 - 73.9
FR 76.1 83.7 83.8 79.9 86.2 87.4 83.6 86.6 86.8 86.1 - 78.8
ZH 81.8 85.8 86.4 80.9 83.8 88.6 87.8 88.3 88.0 89.3 - 81.4
Avg 77.3 81.2 82.5 75.1 82.6 84.5 82.6 84.7 84.6 84.0 - 78.0
Table6: F1scorecomparisonin600-shotcross-lingualtransferonourproprietarysentimentanalysisdatasets.ES:Spanish,FR:
French,ZH:Chinese.Top-3averageF1scoresaremarkedinbold.GPT-3.5isnotincludedinthisevaluationduetothecontext
lengthlimit.