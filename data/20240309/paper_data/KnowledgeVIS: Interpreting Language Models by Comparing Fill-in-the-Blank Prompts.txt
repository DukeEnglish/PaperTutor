1
KnowledgeVIS: Interpreting Language Models
by Comparing Fill-in-the-Blank Prompts
Adam Coscia and Alex Endert
Abstract—Recentgrowthinthepopularityoflargelanguagemodelshasledtotheirincreasedusageforsummarizing,predicting,and
generatingtext,makingitvitaltohelpresearchersandengineersunderstandhowandwhytheywork.WepresentKnowledgeVIS,a
human-in-the-loopvisualanalyticssystemforinterpretinglanguagemodelsusingfill-in-the-blanksentencesasprompts.Bycomparing
predictionsbetweensentences,KnowledgeVISrevealslearnedassociationsthatintuitivelyconnectwhatlanguagemodelslearnduring
trainingtonaturallanguagetasksdownstream,helpinguserscreateandtestmultiplepromptvariations,analyzepredictedwordsusing
anovelsemanticclusteringtechnique,anddiscoverinsightsusinginteractivevisualizations.Collectively,thesevisualizationshelp
usersidentifythelikelihoodanduniquenessofindividualpredictions,comparesetsofpredictionsbetweenprompts,andsummarize
patternsandrelationshipsbetweenpredictionsacrossallprompts.WedemonstratethecapabilitiesofKnowledgeVISwithfeedback
fromsixNLPexpertsaswellasthreedifferentusecases:(1)probingbiomedicalknowledgeintwodomain-adaptedmodels;and(2)
evaluatingharmfulidentitystereotypesand(3)discoveringfactsandrelationshipsbetweenthreegeneral-purposemodels.
IndexTerms—Visualanalytics,Languagemodels,Prompting,Interpretability,Machinelearning.
✦
1 INTRODUCTION
Large language models (LLMs) such as BERT [1] and TABLE1
GPT-3[2]haveseensignificantimprovementsinperfor- ExampleDataSetVisualizedbyKnowledgeVIS
manceonnaturallanguagetasks[3],enablingthemtohelp
people answer questions, generate essays, summarize long prompt prediction probability cluster1
articles, and more. Yet understanding what these models Youarelikelytofindasnake field 0.066 physicalentity
have learned and why they work is still an open challenge ina
Oneeffectofexercising better 0.296 abstraction
[3], [4]. In particular, how learned text representations in
isfeeling
BERT-based language models generalize to natural lan- Youcouldbesickbecause pregnant 0.209 condition
youare
guage tasks remains unclear [5]. For natural language pro-
Ifyouwanttolearnthen teacher 0.122 physicalentity
cessing (NLP) researchers and engineers who increasingly youneeda
trainanddeployLLMsas“blackboxes”forgeneratingtext,
exploring how learned behaviors during training manifest
process of model development [13]. Further, testing one
in downstream tasks can help them improve model de-
prompt at a time can limit the interpretability of LLMs
velopment; e.g., by surfacing harmful stereotypes [6]. To
by failing to surface associations or producing contradic-
helpresearchersandengineersclosethegapbetweenwhat
tory predictions [4], [14], [15]. Guiding the user through
BERT-based models have learned and how they perform
exploringmultiplepromptsatoncecanrevealinsightsand
on downstream tasks, we can use prompts formatted as
patterns that further improve our understanding of BERT-
natural language tasks [7]. For example, Table 1 shows
based models. To realize these goals, a successful solution
BERT’s predictions for multiple fill-in-the-blank sentences
should help users quickly format and test multiple prompt
that test for conceptual reasoning capabilities, connecting
variationssimultaneously,structuresetsofpredictedwords
modelperformancetolearnedtextrepresentations.
tomakethemeasiertoparse,andpresentthedataatseveral
Ouraimistoutilizefill-in-the-blanksentencesforinter-
levelsofdetail.
preting BERT-based language models by revealing learned
We present KnowledgeVIS, a human-in-the-loop visual
associations. Much of the existing work seeks to auto-
analytics system for comparing fill-in-the-blank prompts
matically extract, augment, and test individual template
to uncover associations from learned text representations.
sentences against a manually curated “gold standard” [8],
KnowledgeVIS helps users create effective sets of prompts,
[9],[10],[11].However,thesequantitativebenchmarksmiss
probe multiple types of relationships between words, test
an opportunity for injecting a researcher’s intuition and
for different associations that have been learned, and find
domain expertise into evaluating model performance [12].
insights across several sets of predictions for any BERT-
A human-in-the-loop solution can foster human and LLM
based language model. It does so through a tight integra-
interaction by continuously integrating feedback into the
tion of multiple coordinated views. First, we designed an
intuitive visual interface that structures the query process
• AdamCosciaandAlexEndertarewithGeorgiaInstituteofTechnology. to encourage both creativity and rapid prompt generation
Emails:{acoscia6,endert}@gatech.edu.
ThismanuscriptisaPreprint-Accepted,toAppear:IEEETransactionson 1.We generate clusters based on shared taxonomic and semantic
VisualizationandComputerGraphics,DOI:10.1109/TVCG.2023.3346713 similarityoftokens,describedinSect.4.2.1.
4202
raM
7
]CH.sc[
1v85740.3042:viXra2
and testing. Then, to reduce the complexity of the prompt (masking) tokens in a finite sequence [1]. Thus, we can
predictionspace,wedevelopedanovelclusteringtechnique elicit learned text representations in the attention weights
that groups predictions by semantic similarity. Finally, we of masked language models simply by mirroring their pre-
provided several expressive and interactive text visual- training task using fill-in-the-blank sentences as prompts
izations to promote exploration and discovery of insights [7]. We test the capabilities of our fill-in-the-blank prompt
at multiple levels of data abstraction: a heat map; a set approachwithBERTbaseandfourotherpre-trainedBERT-
view inspired by parallel tag clouds [16]; and scatterplot based models — RoBERTa [20], DistilBERT [21], SciBERT
withdust-and-magnetpositioningofaxes[17].Collectively, [18],andPubMedBERT[19].
these visualizations help the user identify the likelihood
and uniqueness of individual predictions, compare sets of 2.2 ProbingLanguageModelsWithPrompts
predictionsbetweenprompts,andsummarizepatternsand
Transformers are typically pre-trained on various tasks
relationshipsbetweenpredictionsacrossallprompts.
(Sect. 2.1) and then fine-tuned using task-specific objective
To validate our approach, we demonstrate the capabil-
functions. Prompting instead emulates pre-training by for-
ities of KnowledgeVIS with three use cases and an expert
matting the downstream objective as a natural language
evaluation.First,wereveallearnedbiomedicalassociations
task [7]. Consider the example prompts in Table 1. Instead
in two domain-adapted LLMs, SciBERT [18] and PubMed-
of creating an objective function and labeled training data
BERT [19]. Second, we uncover harmful learned identity
for a large language model (LLM) to predict conceptual
stereotypes between two general-purpose LLMs, BERT [1]
relationships, we reformulate the task as one that BERT-
and RoBERTa [20]. Third, we elicit and evaluate different
based language models have seen already — a fill-in-the-
world knowledge (i.e. commonsense relationships) learned
blanksentenceasaprompt.
byalargeandasmallgeneral-purposeLLM,BERT[1]and
Prior work in probing LLMs using prompts involves
DistilBERT [21] respectively. Finally, we conduct an eval-
eliciting and interpreting learned syntactic, semantic, and
uation with six academic NLP researchers and engineers.
world knowledge [4]. For example, Petroni et al. [23]
KnowledgeVISsurfacedseveralnewinsightsforthedomain
showed that LLMs can be queried using fill-in-the-blank
experts, including how BERT-based language models han-
sentences as prompts (e.g., asking BERT to complete the
dle parts of speech, transitivity, and semantic roles, as well
sentence, “The capital of France is ” results in BERT re-
as learned cultural and religious associations that biased
sponding with “Paris”) to elicit relational knowledge (i.e.
predictionsinunexpectedways.Ourparticipantswantedto
the relationship “capital of” between France and Paris).
evaluate their own models using KnowledgeVIS and would
Theypositknowledgeprobingestimatesalower-boundon
recommend our interface to anyone interested in “opening
knowledgecontainedinamodel’sinternalrepresentations.
theblackboxofhow[LLMs]work”.
Researchers have developed both manual and automated
In summary, our paper contributes: (1) an open-
approaches to finding more effective prompts to raise the
source2 visual analytics system, KnowledgeVIS, that imple-
lower bound. Jiang et al. created LPAQA [8] using both
ments text visualization techniques for comparing fill-in-
mining-basedandparaphrasing-basedmethodstogenerate
the-blank prompts that reveal associations from learned
new prompts for existing relations. Shin et al. [9] created a
text representations in BERT-based language models; (2)
model, AUTOPROMPT, that searches for specific discrete
a novel taxonomy-based technique for semantically clus-
tokens to automatically generate better prompts from a
tering prompt predictions; and (3) three use cases and an
template.Zhongetal.[11]developedOPTIPROMPT,which
expert evaluation showing how KnowledgeVIS helps NLP
replacesAUTOPROMPT’sdiscretetokensearchwithacon-
researchersinterpretBERT-basedlanguagemodels.
tinuous vector search. Qin et al [10] relax the constraints
on continuous word embeddings to create “soft prompts”
2 RELATED WORK thatavoidemphasizingmisleadingtokenssuchasgendered
pronouns.Elezaretal.[15]createdPARAREL,abenchmark
2.1 ModelingLanguagewithTransformers
for measuring the consistency of model predictions when
In this paper, we focus on BERT-based language models
promptsareparaphrasedbutthesemanticmeaningremains
becausetheirtransformerarchitectureandmaskedlanguage
constant. We extend this work using a visual analytics
modeling pre-training easily adapt to our fill-in-the-blank
approach to qualitatively evaluating multiple prompts si-
prompts.Languagemodelslearntomodeltheprobabilityof
multaneouslyforinterpretingmodelperformance.
a token occurring in a sequence, e.g., a word in a sentence.
Transformers extend this by encoding and decoding all
2.3 VisualAnalyticsForLLMInterpretability
input words in a sentence, generating weights that map
attention from an output to the most relevant inputs [22]. Visual analytics has become a popular approach for ana-
These attention weights are attributed with storing factual lyzing and interpreting machine learning models [24]. One
and linguistic knowledge needed to perform natural lan- methodofinterpretingmodelperformanceisdirectlyvisu-
guage tasks [5]. With this architecture, transformer-based alizingthemodel’sinternalrepresentationsasaformofex-
language models can pre-train via self-supervised learning planation[25].Indeeplearningmodelsthatperformnatural
using large-scale unlabeled document corpora on a variety language tasks such as Long Short Term Memory (LSTM)
oftasks.BERT-basedlanguagemodelspre-trainonmasked [26] and sequence-to-sequence (seq2seq) models [27], visu-
languagemodeling,orrepeatedlyremovingandpredicting alization techniques have been shown to help debug and
explain how neural layers transform input sequences into
2.https://github.com/AdamCoscia/KnowledgeVIS final predictions [28]. Alternatively, visualizations can help3
users probe models from the outside by structuring the making based on the context of the sentence [4], [14], [15].
input process and supporting interactive analysis of model To enable more effective prompt testing, we can evaluate
outputs. VizSeq is a visual analysis toolkit for interactively multiple prompts simultaneously that isolate dependent
evaluating LLM task benchmarks [29]. Other tools present variables,suchastheboldsubjectsinTable1.Ourinterface
a visual analytics workflow to analyze changes in LLM should encourage users to test multiple prompts through
weights under various task-specific scenarios [30]. These intuitiveinputdesign.
tools share a focus on human-in-the-loop workflows and
C3 Probing different types of relationships.Whilefill-in-
interactivity to integrate valuable feedback during model
the-blank prompts can be designed to elicit a single fact or
validation[13],whichKnowledgeVISmakesheavyuseof.
relationship[23],LLMsalsolearnmultiplecorrectresponses
With transformers, new visual analytics approaches for
to the same prompt, subjective answers, and associations
interpretinghowandwhytheyworkhavebeendeveloped.
such as stereotypes and domain-specific knowledge [4].
Several tools focus on visualizing the internal prediction
Table 1 shows how subjective, open-ended prompts can
processoftransformersasinputsarefedthrougheachlayer
elicitmeaningfulpredictionsthathelpusersinterpretmodel
ofthemodel[31],[32],[33].Inparticular,Dodriovisualizes
performance.Providingseveralpromptexamplescanguide
the connection between attention weights and linguistic
userstomoreeffectivelydesignawidevarietyofprobesfor
knowledge such as syntactic dependencies [34]. However,
elicitingdifferentrelationships.
thereisanactivediscussionastowhetherattentionweights
intransformerscanbeusedasasourceofinterpretationfor C4 Finding insights in a large search space.Asshownin
modelperformance[35],[36],[37].Followingourargument Table1,predictedtokensandtheirprobabilityscorespresent
above,promptscanhelpusersvalidatemodelperformance severalanalyticalchallenges.LLMsoftenhavelargevocab-
byinsteadprobingthemodelfromtheoutside.PromptIDE ularies that lack useful stratification [1]. Tokens themselves
is a visualization interface for experimenting with prompt can be both specific to a prompt and generalizable across
variations,visualizingpromptperformance,anditeratively prompts,duplicatedacrossprompts,and/oruniquewithin
optimizing prompts [38]. LMDiff visually compares the a prompt. Methods for grouping, filtering, searching, and
differenceinrankforalltokensinasinglepromptbetween arranging predictions and their probabilities can aid users
two different LLMs to facilitate comparison of model per- indiscoveringinsights.
formance[39].Wecontributetocurrentresearchonhuman-
in-the-loop workflows using prompts by introducing text 3.2 DesignGoals
visualization techniques for comparing multiple prompts
Wedevelopeddesigngoalsthataddressthekeychallenges
simultaneouslytovalidatemodelperformance.
raisedinSect.3.1andalignwithourinterfacecomponents:
G1 Intuitive visual interfaces for structuring prompt-
3 DESIGN CHALLENGES AND GOALS
ing.Clearlycommunicatinghowtoinputpromptsthrough
Our goal is to build a system for discovering learned asso- visual design can help guide users to more rapidly test
ciations from text representations in BERT-based language for learned associations. “Fill-in-the-blank” prompt inputs
models.Fornaturallanguageprocessing(NLP)researchers should be open-ended to encourage creativity (C1) with
and engineers, interactively exploring model performance flexible formatting rules to enable rapid generation of dif-
across different tasks can help build trust in models be- ferent prompt variations (C3). At the same time, arranging
fore deployment [13]. Fill-in-the-blank sentences can help inputs to facilitate comparison across prompt variations
connect what large language models (LLMs) have learned shouldencouragemorethoughtfulprobing(C2).
with downstream tasks to interpret how they work [5].
G2 Useful grouping of prompts and predictions. Pro-
Yet existing work in this space is primarily based around
viding additional structure to several large sets of predic-
quantitatively evaluating prompts one at a time against an
tions can help reduce their complexity (C4). We aim to
objectivegoldstandard[8],[9],[10],[11],[23].Ourapproach,
differentiate predictions by their semantic relatedness and
a human-in-the-loop solution for qualitatively exploring
communicate this distinction visually while respecting the
multiple prompts simultaneously, overcomes several limi-
input structure of prompts. Highlighting new connections
tationsbyaddressingthefollowingkeydesignchallenges.
could enable domain experts to use their own knowledge
forevaluatingpredictionsmoreeffectively(C2,C3).
3.1 DesignChallenges
G3 Expressive and interactive views for discovering in-
C1 Creating effective prompts. It remains an open chal-
sights.Fluidtransitionsbetweenlevelsofabstractioninthe
lenge to explain how internal text representations in LLMs
datacansurfacepatternsacrossmultiplesetsofpredictions
are translated into natural language understanding for
that connect learned associations to model performance
completing tasks [5]. Using fill-in-the-blank sentences as
(C4). We aim to support several low-level tasks including
prompts for LLMs formats queries intuitively as natural
identifyinghighlysalientoruniquepredictions,comparing
language tasks [7]. For example, Table 1 shows how asso-
both individual and sets of unique and shared predictions
ciationshelpdemonstratelearnedcomplexrelationships.A
between prompt variations, and summarizing groups of
systemshouldenableuserstoeasilycreate,format,andtest
predictions as over/under performing subsets for further
theirownprompts.
investigation.Incorporatingthesetasksacrossseveralcoor-
C2 Testingmultiplepromptsatonce.Asinglepromptcan dinated views can help users connect these low-level tasks
give limited understanding of what association LLMs are withhigh-levelmodelperformance(C2,C3).4
A F
B
C D E
Fig.1.KnowledgeVIS integratesmultipleviewstorevealassociationsthatLLMslearnduringtraining.Above,auserinvestigateswhetherBERT
exhibitsassociationsthatreveallearnedconceptualrelationships(Sect.5.3),helpingtheminterprethowBERTworks.
4 KNOWLEDGEVIS evaluation, and knowledge probing (G1). We explore these
examples in depth in Sect. 5. Prompts are written in open-
BasedonthedesignchallengesandgoalsinSect.3,wede-
endedtextinputsalignedina2-columngrid(G1).Thehori-
veloped KnowledgeVIS (Fig. 1), a human-in-the-loop visual
zontaldimensionpromotescomparisonacrossparaphrased
analyticssystemforcomparingfill-in-the-blankpromptsto
sentences. Users write prompt “templates” in the left col-
uncoverassociationsfromlearnedtextrepresentations.Our
umnthatmustincludeasingleunderscorecharacterforthe
interfacetightlyintegratesmultiplecoordinatedviewswith
LLMtofillin.Userscanthenusetherightcolumntoinput
anovelpredictionclusteringtechnique.Usersstructurethe
any number of “subjects”, to be filled in to the template
prompt generation and testing process using the Prompt
prompt using an additional [subjects] mask anywhere in
Interface (Sect. 4.1). Then, the Predictions View (Sect. 4.2)
theprompt.Thisallowsuserstointuitivelycreatesingle-or
visualizespredictionsatmultiplelevelsofabstractionacross
multi-token variations on the given template prompt, i.e.,
aHeatMap(Sect.4.2.2),SetView(Sect.4.2.3),andScatterPlot
paraphrasing prompts grammatically. The vertical dimen-
(Sect. 4.2.4). Finally, the Filters Panel (Sect. 4.3) allows users
sion provides additional rows for writing template/subject
to fine-tune their analysis. Throughout, we describe how
pairs to compare semantically similar prompts that may
eachdesigngoal(G1-3)isaddressedinourinterface.
differ grammatically. Finally, we mirror the grid structure
hierarchically by template → subject (G2) in the Predictions
4.1 PromptInterface View, described in Sect. 4.2, helping users reflect on how
theycanrefinetheirprompts.
ThePromptInterface(Fig.1A)guidesuserstocreatemultiple
promptsusingagridstructureandintuitivetextformatting Prompts are evaluated in real-time using an API that
that promote structured exploration of different prompt interfaces with a Python Flask server running PyTorch im-
variations. Users start here to begin exploring the capabili- plementationsoftheLLMs.WeusetheHuggingFaceTrans-
tiesofpromptingforelicitingassociations. formers[40]APItoloadmodelsandperformmaskedword
Toguideusersinelicitinginterestingsetsofpredictions, prediction with the user-created prompts. Users can select
we structure prompt inputs in several ways. To help users differentpre-trainedmaskedlanguagemodelsfromadrop-
probe for different types of relationships, we provide but- down list to compare performance and add new models
tons that load examples related to domain adaptation, bias easilythroughtheHuggingFaceTransformersmodellibrary.5
To reduce the complexity of the prediction space, we also 2) Perform hierarchical clustering [44] over the distance
let users choose the top k tokens to retrieve and visualize. matrix using Ward linkage [45]. Affinity propagation
Finally,userscanexporttheextracteddataintheformatof [46], while often used with similarity-based distance
Table1forfurtherinvestigation. metrics, requires unintuitive manual tuning of the
dampingfactortoavoidoverfitting.
4.2 PredictionsView 3) Determine the optimal number of clusters based on
WeprovideseveralfacilitiesinthePredictionsView(Fig.1B- eitherthemaximumsilhouettecoefficient[47]orauser-
E) to promote exploration and discovery of insights about definedcut-offthresholdonhierarchicalclusters.
whatamodelhaslearned.First,wegrouppredictionsbyse- 4) Automaticallylabeleachclusterbycomputingthelow-
mantic similarity using a novel taxonomy-based clustering est common hypernym (LCH) between all words in
technique developed in Sect. 4.2.1. Then, we visualize the the set using WordNet [48]. Hypernyms (words with
prompt,prediction,andclusterdataasshowninTable1at a broad meaning that more specific words fall under
multiple levels of abstraction across three interactive plots. such as “color” and “red”) are an approximate yet
Eachplotprovidesuniqueadvantagesfordifferentanalysis informativelabelforamajorityoftheopen-classword
tasks that the other plots do not, that together help users predictionsreturnedbyLLMssuchasnouns,verbs,etc.
find patterns better than a single plot could. In Sect. 5 we
describehowtheplotsareusedintandemineachusecase 4.2.2 HeatMap
aswellasintheexpertevaluationtohelpguideparticipants’
The Heat Map (Fig. 1C) plots a uniform grid of all unique
analysisprocessandthinking.
predicted tokens vertically as rows and all prompts as
The Heat Map (Sect. 4.2.2) makes it easy to accurately
columns.Eachcelliscoloredbytheprobabilityofthegiven
identifyandcompareindividualprobabilitiesacrossprompt
word (row) occurring in the prompt (column). Much like a
variations(columns)andsemanticclusters(rows).Thegrid
data table, visualizing predictions in this way allows users
structure uniquely highlights words not shared between
to quickly identify and compare small details in the entire
promptstohelpusersfindoutliers.TheSetView(Sect.4.2.3),
datasetataglance,suchasindividualprobabilities,cluster
inspired by parallel tag clouds [16], facilitates in-depth
labels,andhowtheycompareacrossprompts(G3).
comparisonofwordsetsacrossmultipleprompts,aswellas
Several design considerations enhance analysis capabil-
rank order analysis. Selecting a predicted word aligns each
ities. If a given word (row) is not in the set of predictions
occurrence across prompts along a common baseline and
returned for a given prompt (column), that cell is left
shows a novel selected word rank order view. The Scatter
unshaded, and a crosshatch pattern is used to differentiate
Plot (Sect. 4.2.4) projects predictions in a low-dimension
missing values from the background of the interface. We
spaceandusesadust-and-magnetmetaphor[17]toposition
providerowlinestoaidinvisuallyscanningacrosscolumns
prompts as points of interest, revealing new relationships
with unshaded cells. We found that probabilities tended to
between predictions at the data set level. For example,
range non-linearly, with very few high-probability words
common predictions more relevant to a subset of prompts,
relative to many low-probability words. Thus, for broad
aswellasuniquepredictionssharingarelationshipbetween
comparisonacrossallpredictedwords,wechoseasdefault
twoprompts,arevisuallygrouped.
a logarithmic color ramp from light to dark pink applied
to the global extents of the range of probabilities; i.e., the
4.2.1 ClusteringPredictions
darkest shade of pink is the highest probability in the
Users may not have an intuitive sense for seeing patterns
data set, and the lightest shade of pink is the lowest. We
insharedmeaningacrosspredictedtokens,especiallyasthe
providealegendandadrop-downlisttoselectbetweenthe
number of predicted tokens grows. This meta-information
defaultlogarithmicscaleaswellasalinearscale,helpingthe
can be useful to determine, e.g., specific training biases
user more accurately compare probabilities. For example,
towardshigher-levelconceptsthatmayormaynotberele-
whencomparingasmallsubsetofprobabilitiesforasingle
vant to the semantic meaning of the prompt. To help users
prompt, a linear scale is more appropriate. To connect the
discover patterns in prediction sets, we aim to group and
structure of the inputs with output predictions, we label
describesemanticallysimilarpredictions.Whiletopicmod-
the columns of the Heat Map hierarchically (G2). We nest
elling has been used to assign manually-sourced candidate
subjects as column names below sentence templates that
labels to lists of terms based on the co-occurrence of labels
span several columns, to indicate group membership. If no
andterms[41],therearealackofmethodsforautomatically
subjects are put in, i.e., the template is the only prompt to
discovering appropriate labels without frequency data. To
evaluate, then we treat the template as a subject and only
overcomethis,oursolutionusesahierarchicaltaxonomyof
showthetemplateinthelowestlevelofthehierarchy.
word sense, or the meanings of words, to algorithmically
We also implemented interactions that provide addi-
generate and label clusters of words based on their shared
tional details on demand. Hovering over a cell displays
semantic meaning (G2). We color tokens by their cluster
a tooltip showing the prompt (column), prediction (row),
label(G3)ineachvisualization(Fig.1C-E).
cluster, and probability. Rows can be sorted by word top-
1) Compute a distance matrix of pairwise Wu-Palmer down in one of four ways: (1) alphabetically; (2) rank
similarities [42] between all unique predicted words. order (i.e., by probability of occurring in a prompt, from
Compared with other popular measures such as word left to right); (3) grouped by cluster, alphabetically; and (4)
vector similarity [43], Wu-Palmer led to better cluster groupedbycluster,rankorder.Groupsaresortedtop-down
labelsdownstream. alphabeticallybyclusterlabel.6
Set View when selecting a word and sorting by rank to more clearly show a lack of membership of the word
in that set. Finally, selecting a word while sorting by rank
order transitions the view to a stepwise degree of interest
list (Fig. 2), similar to fisheye menus [49]. We arrange the
neighborhood of n words above and below the selected
wordinrankorderequidistantand,fortheremainingwords
outside of that neighborhood, we draw lines above and
below that scale proportionally with the remaining words
from the top and bottom of the list, respectively. Users can
accurately compare line heights along the same baseline to
determinethedifferenceinrankingsbetweencolumns(G3).
Wordsnotoccurringinacolumninthisviewaresettozero
opacitysincenoline(s)willbedrawnforthatcolumn.
AsintheHeatMap,welabelcolumnshierarchically(G2),
provide a legend and drop-down list for logarithmic and
linearfontscales,drawtooltipswhenhoveringoverwords
(showing the prompt, prediction, cluster, and probability),
and let the user sort words top-down (alphabetically, rank
order, and grouped by cluster). Collins et al. found that
ordering words alphabetically offers two main advantages
over rank order: (1) it saves horizontal space, since the
largest words are less likely to occur next to each other;
and(2)ithelpsusersvisuallyscanforwordsofinterest[16].
Thus,wemakethisthedefaultsortingoptionforrows.
4.2.4 ScatterPlot
The Scatter Plot (Fig. 1E) positions predicted tokens as vec-
Fig. 2. The Set View showing our variation on the parallel tag cloud
torsbasedontheirprobabilityofoccurringforeachprompt
layout,astepwisedegreeofinterestlistbasedonfisheyemenus[49]for
aselectedwordwhensortingbyrank,describedinSect.4.2.3. or “point of interest” (POI) in a 2D coordinate space, using
a layout technique derived by Olsen et al. [50]. Predictions
4.2.3 SetView closer to POIs (prompts) indicate a higher probability of
occurringforthatprompt.Groupsofpredictionsinbetween
The Set View (Fig. 1D) arranges sets of the top k predicted POIs reveal a unique relationship between prompts that
tokensreturnedforeachpromptintoparallelcolumns.Sim- cannot be seen in the other two plots. Predictions that
ilartocellcolorintheHeatMap,thefontsizeforeachword occupied the shared axis of two POIs revealed unique
(row)isscaledbytheprobabilityofoccurringintheprompt promptinteractionsthatalignedwithsemanticclusterlabels
(column). Inspired by parallel tag clouds [16], this plot (G2). Because this approach reduces the dimensionality of
shows the degree of overlap between prompts (columns) predictions,weallowuserstodragPOIs,similartoadust-
by drawing edges between shared tokens, making shared and-magnet metaphor [17], to create new arrangements of
predictions more visually salient at a glance. To overcome data marks and avoid visual artifacts based on the ini-
difficulties in interpreting continuous word probabilities, tial layout. Overall, the process of arranging predictions
suchasthecellshadingintheHeatMap,userscanalsosort spatially relative to prompts can help users uncover new
columnsbyrank,encodingprobabilityinsteadonadiscrete patternsandrelatedpredictionsatthedatasetlevel(G3).
scale and making differences between prompt variations To help users read the Scatter Plot, we provide several
moreinterpretable(G3). visual embellishments. Data marks are labeled with the
To help users see new patterns in the data, we im- predictedwordorprompttheyrepresent;weimplemented
plemented hover and select interactions that change the occlusion to show only the top label when several labels
arrangementofthewords.Hoveringonandoffawordwill overlap. Users can hide these labels with a checkbox. For
temporarilydrawaconnectorlinefromthewordtoallother three POIs, we also draw a differently colored background
occurrencesofthatwordinothercolumns,whilehidingthe fortheboundedregioncontainingpointsmostcloselyasso-
connector line if it crosses a column that does not contain ciated with each POI. When predicted words are unique to
the hovered word. While hovering, selecting the word will asingleprompt(POI),thelayoutalgorithmavoidsplotting
shiftthecolumnscontainingotheroccurrencesofthatword themallatthesamepositionofthePOI.Instead,wecollect
to align the words along the same horizontal baseline. The the unique predictions and display each word, cluster, and
connector line will then remain drawn even after hovering probability set in a tooltip when hovering over a POI. We
off. Selecting other words will align the columns along a appendacountofthenumberofuniquepredictionsforeach
newbaselineandautomaticallyadjustthepreviouslydrawn prompttoeveryPOIlabel.Finally,tovisuallydistinguishre-
connector lines. Deselecting a selected word will remove lationshipsbetweenadjacentpointsofinterest,wedrawthe
the connector line and reset the column alignment. If a convex hull around all POIs. Dragging a POI dynamically
word does not occur in one or several columns when it is adjusts the convex hull, to show a shared axis or axes with
selected, each of those columns is set to a lower opacity adjacentneighbors.7
Becausetheplotreducesthedimensionalityofeachpre- usingquantitativemetricsdeterminedapriori,KnowledgeVIS
dicted word, we lose information contained in the original leverages human intuition and domain expertise to guide
vector,i.e.,theprobabilitiesofthepredictedwordoccurring LLM evaluation [13]. This enabled experts to suggest new
in each prompt. We provide three solutions to recover this ways to adapt and improve LLMs in their own research
information. The first is a details-on-demand tooltip when andapplications,towards“closingtheNLPloop”inmodel
hoveringoverapredictedwordthatlistsnon-zeroprobabil- development(Sect.6.1).
ities of the predicted word occurring for each prompt. The Theresultsarebasedoninterpretingwordprobabilities
secondisencodingthemaximumprobabilityofapredicted using visual encodings. This presents analytical trade-offs
word occurring for all prompts as height/width of the when choosing scales (linear and log) as well as encodings
Scatter Plot point, as well as font size of the label, on either (color,fontandmarkersize).Forexample,logscaletended
a logarithmic or linear scale, similar to the Heat Map and tomoreprominentlyshowpatterns,butcanbemisleading.
SetView,andprovidingalegend.Thethirdisdrawinglines PatternsbasedonpositionalencodingintheScatterPlotare
on hover from the predicted word to each of the non-zero alsomorelikelytodrawauser’sattentionthansizeencod-
probabilityprompts(Fig.1E),double-encodingstrokewidth ings. To address this, we detail our method for generating
andopacitytoeachlineusingthesamescale.Forexample, and evaluating prompts in the second paragraph of each
a weak relationship (low probability) between a POI and usecase.Weacknowledgeourqualitativeapproachmaybe
predictedwordisshownwithasmallerpointandlabeland, subjecttopre-attentivebiases.
whenhovering,withafaded-outthinline,whereasastrong First, we tested how grammar and phrasing af-
relationship(highprobability)isshownwithalargerpoint, fected domain-specific LLMs when replicating expert hu-
label,andvibrantthickline. man answers is required. We modified a biomedical
question-answer data set, PubMedQA [51], by formatting
yes/no/maybequestionsasfill-in-the-blanksentences,then
4.3 FiltersPanel
queried SciBERT [18] and PubMedBERT [19], both pre-
With the Filters Panel (Fig. 1F), users can filter prompts trainedonlargeunlabeledscientificdocumentcorpora.
by directly toggling subjects nested under their template Second, current LLMs are regularly fine-tuned on pre-
sentence. Arranging the prompt filter using the template trained general-domain LLMs such as BERT [1] and
→ subject hierarchy (G2) can promote a wider variety RoBERTa [20] and inherit well known stereotypical asso-
of prompt testing, e.g., by subsetting prediction sets with ciations such as gender bias. Yet automated auditing sys-
specific semantic relationships and comparing the results temsrequiringsocialcategoriesandquantitativemetricsto
againstothersubsets.Withinthecurrentlyvisiblesubsetof be predetermined are prone to missing underrepresented
promptsandpredictions,weprovidetwoadditionalglobal stereotypes [12]. We discovered contextualized gender, ori-
prediction filter operations: “shared only” and “unique entation, pronoun, race, religious, and political stereotypes
only” checkboxes. The “shared only” checkbox filters pre- betweenBERTandRoBERTausingsubsetsoftheHONEST
dictions that are shared between all of the currently visible [52],[53]andBOLD[54]datasets.
prompts.ThisremovesallmissingcellsintheHeatMapand Third,asLLMsincreaseinsize,itisusefultounderstand
aligns the words along the same horizontal baseline in the limitationsatdifferentmodelscalesonwhetherassociations
SetView,helpingusersmoreeasilyfindcommonpredictions not explicitly trained for such as membership (belongs,
and quickly compare relative probabilities. Similarly, the causes) and chain of reasoning (goals, prerequisites) are
“uniqueonly”checkboxfilterspredictionsthatareuniqueto learned. We compared complex learned concepts between
eachvisibleprompt.ThisreducestherowsoftheHeatMap the large-scale BERT [1] and small-scale DistilBERT [21]
so that each contains a single shaded cell, and removes all modelsbasedontheLAMAknowledgeprobe[23].
pointsfromtheScatterPlot,asnonesharerelationshipswith Finally, we conducted an expert evaluation with six
the other prompts. The Set View can help compare biases academic NLP researchers and engineers. The experts gen-
in each unique set of predictions across prompts, while erated new examples to uncover insights, including: (1) a
sortingtheHeatMapbyclustercanrevealthedistributionof lackofunderstandingforsemanticrolesinallthreegeneral-
classesofwords,suchasclassesuniquetoaspecificprompt. domainmodels;(2)unexpectedbiasestowardslesscommon
Users can also use the provided search box to highlight all words in general-domain models; and (3) differences in
instancesofaspecificpredictionwordacrossallplots. grammarrobustnessbetweendomain-specificmodels.
5 USE CASES AND EXPERT EVALUATION 5.1 UseCase:BiomedicalKnowledge
In this section, we demonstrate the capabilities of Knowl- Howdodomain-specificmodelscomparebasedonrobust-
edgeVISforpromptengineeringandimmediatevisualanal- nesstogrammarandphrasingwhenexperthumananswers
ysis of fill-in-the-blank sentence predictions with three use areexpected?InFig.3A,weevaluatedtwoPubMedQA[51]
cases (Fig. 3) and an expert evaluation. Our use cases questions(1and2)byformattingtwogrammaticallydiffer-
comprised 114 subject replacements across 15 fill-in-the- entbutsemanticallysimilarpromptsperquestion(1a/band
blank sentences, totaling 289 prompt variations to eval- 2a/b)andusingthePromptInterfacetoreplacekeyphrases.
uate. The use cases were designed for NLP researchers Wemostlyreplacedsubjectsinmultiplelocationswithin
and engineers who are increasingly using LLMs as “black a sentence with a single word (e.g., “short” replaced by
boxes” for downstream tasks [24] such as discourse anal- “long”) in the Prompt Interface. The Heat Map was critical
ysis and classification. Compared to automated methods for finding predictions not shared between prompts. The8
A Biomedical Knowledge B Identity Stereotypes C Knowledge Probing
Testing differences in grammar and phrasing Discovering underrepresented biases Comparing model size for learning concepts
SciBERT (2019) vs PubMedBERT (2021) BERT (2018) vs RoBERTa (2019) BERT (2018) vs DistilBERT (2019)
Question * Answer Gender, Orientation, and Pronouns ** Membership (Belongs/Causes) ****
1 Therapeutic anticoagulation in Studies have shown significant Binary woman, daughter, female, man, son, male, straight, likely unlikely thing snake, cat, keepsake,
the trauma patient: is it safe? complication rates; it is not safe. heterosexual, she, he find see, locate heirloom, idea, strategy
therapeutic anticoagulation anticoagulation therapy LGBTQAI+ person, non-binary, transgender, queer, gay, effect result, consequence doing succeeding, failing,
trauma male / female / middle aged lesbian, bisexual, homosexual, they, xe, ze feeling getting, becoming exercising, sleeping,
patients humans 1 [subject] is a great _. / [subject] is known as a _. thinking, worrying
a Therapeutic anticoagulation is _ for trauma patients to receive. 2 [subject] likes to _. / [subject] is meant to be _. 1 You are likely to find a thing in a _.
b It is _ for trauma patients to receive therapeutic anticoagulation. 21 subject replacements | 84 prompt variations total 2 One effect of doing is feeling _.
25 subject replacements | 50 prompt variations total
8 subject replacements | 16 prompt variations total Race and Religious/Political Ideologies ***
Question * Answer Race Asian Americans, African Americans, European Chain of Reasoning (Prerequisites/Goals) ****
2 A short stay in a general children's Studies have confirmed Americans, Hispanic and Latino Americans could should, would this happy, sad, right, wrong,
hospital: are they effective? their effectiveness. Religion Judaism, Christianity, Islam, Hinduism, Buddhism, are want, will, might healthy, sick
Sikhism, Atheism want to should, must do drive, fly, succeed, fail,
short long children’s adult’s Politics Communism, Socialism, Democracy, Liberalism, need want, like, dislike discover, learn, create
gens et ra ay l w aca ar dd emic hosp tait ka el m hae vd eical center Conservatism, Nationalism, Anarchism, Fascism 3 You could be this because you are _.
3 Many even attribute [subject] for being _. 4 If you want to do then you need a _.
a A short stay in a general children's hospital is _ to take. 4 One fundamental moral quality in/of [subject] is _. 29 subject replacements | 58 prompt variations total
b It is _ to take a short stay in a general children's hospital. 5 The people of [subject] are often known for _.
12 subject replacements | 24 prompt variations total 19 subject replacements | 57 prompt variations total
* Jin et al. 2019 “PubMedQA” | ** Nossa et al. 2021 “HONEST”, Nossa et al. 2022 “Harmful Sentence Completion” | *** Dhamala et al. 2021 “BOLD” | **** Petroni et al. 2019 "Language models as knowledge bases?"
Fig.3.Datasetsandpromptsusedinourusecases(Sect.5)toshowhowKnowledgeVIScanhelpNLPresearchersandengineersinterpretLLMs.
SetViewwasalsousefulforunderstandingrankingpatterns 5.2 UseCase:IdentityStereotypes
that the Heat Map cannot represent, such as when different
How can important yet underrepresented identity stereo-
prompts exhibit similar prediction sets but differently or-
types be discovered in general-purpose LLMs? In Fig. 3B,
dered.Thelogarithmicscalewasmostlyused,asthemodels
we modified prompts from the HONEST [52], [53] data set
generallyreturnedfewhighlyprobablepredictions. (1 and 2) for measuring gender, orientation, and pronoun
For PubMedBERT, key phrases and synonyms changed biases between binary and LGBTQIA+ communities. We
recommendations regardless of the context of the sentence. also modified prompts from the BOLD [54] data set (3, 4,
Forexample,theHeatMapshowedmissingentriesbetween and 5) to further investigate United States racial, religious,
therapeutic anticoagulation (“ideal”, “significant”, “imper- andpoliticalidentitystereotypes.Importantly,thisusecase
ative”, “standard”) and anticoagulation therapy (“costly”, onlyhighlightsasubsetofidentitiesanddoesn’taccountfor
“expensive”, “complex”), while the Set View showed some intersectionality[55](i.e.,identifyingwithmultiplegroups);
positive associations for “patients” and not for “humans”. future work should investigate intersectional identity com-
PubMedBERTalsoassociated“long”withsetsofwordsin- pletionsinmaskedlanguagemodels.
cluding“expensive”,“dangerous”and“bad”,while“short” In contrast to the previous use case, we primarily re-
was“safe”,“convenient”,“simple”.Thisassociationpersists placed subjects in a single location within a sentence with
even when other phrases change, raising concerns that multiple words (e.g., “woman”, “daughter”, etc.) and used
the model is not recognizing important syntax and only rank-order views and set membership in the Set View and
focusing on “short”/“long”, which may be a consequence Scatter Plot. Using a linear scale, we saw few predictions
of its training on PubMed articles. Thus, PubMedBERT more likely than others and high probability, making rank-
can be good for general-purpose recommendations where inganimportantmetrictodistinguishbehavior.Weusedthe
grammar is consistent with the training data. Where key SetViewandScatterPlottosurfacesharedsetsofpredictions
phraseschangeorareimportanttoconsider,itmaybehard and find unique predictions that stand out, e.g., specific
forPubMedBERTtounlearncertainstrongassociations. predictions unique to a single set, or a prediction that is
For SciBERT, key phrase changes are generally ignored higherforapromptthantherest.Theshared/uniquefilters
whilethecontextandgrammarofthesentencemoreheavily were critical for reducing the prediction space in the Set
change predictions than with PubMedBERT. For example, View, such as when few/many predictions are shared and
where SciBERT is consistent (i.e. most rows filled in the uniquepredictionsrevealsharedpromptgroups.
Heat Map) across subject replacements for 1a, it is sim- Gender, orientation, and pronouns. For BERT, as ex-
ilarly consistent yet opposite for 1b (“recommended” vs pected, binary labels were more often associated with gen-
“not”). Similarly, SciBERT finishes the sentence for 2a with dernormsandpositivitycomparedwithLGBTQIA+labels
“difficult”, “easy”, “hard”, and “simple” across almost all being misclassified with stereotypical and negative excep-
variations, not making any recommendation, while using tions (e.g., “beautiful” and “admired”, versus “different”
“take”in2bresultsinrecommendationslike“able”,“possi- and “temporary”). For RoBERTa, we found bias in associ-
ble”,“required”and“likely”.Sentencephrasingaffectshow ations with morality and gender norms to be less frequent
much SciBERT recommends something. This could make and isolated overall. Yet one unexpected and concerning
SciBERTgoodforlearningassociationsonkeyphrases,but association in both models (i.e. high ranking and shared
hardertoadapttonewgrammarsandphrasings. relationships in the Set View and Scatter Plot) is “lesbians”,
Overall, while both models are susceptible to grammar “women”, and “female” with many LGBTQIA+ labels.
and phrasing issues, PubMedBERT tends to associate rec- CouldmoreLGBTQIA+contentbeassociatedwithorwrit-
ommendations with certain key phrases, whereas SciBERT tenforwomen,oristhisamoreingrainedmisclassification
basesitonthewordorder. bias?WhyisthisassociationnotdebiasedinRoBERTagiven9
its performance with other labels? Further, the association We replaced subjects in multiple locations within a sen-
of LGBTQIA+ labels and morality, particularly themes ob- tence with multiple words (e.g., “effect” and “feeling” in
served such as “evil” and “sin”, is then more likely to the same sentence) and used the Scatter Plot to observe
refer to women than men. It is unclear in what direction higher-level patterns across prompts, helping us identify
the association between woman, LGBTQIA+ labels, and clusters of labels. Some labels sit on the line between two
morality is targeted. Another unexpected association was subjects,whichwasveryinteresting.Predictionclustersalso
made between men, sports and sexuality in RoBERTa. In- provided evidence of learned semantic understanding of
terestingly,theinclusionofheterosexual/homosexuallabels knowledge where subject associations matched their pre-
reveals associations with “athletes”, “coaches”, “players”, diction hypernym labels (e.g., snake/cat produced mostly
and“leaders”.Thiscouldrevealamechanismofthetraining “physicalentity”predictions,whilestrategy/ideaproduced
surfacingtodebiasidentitylabelsmissingaparticularasso- mostly“abstraction”predictions).WealsousedtheSetView
ciation.Finally,weobserveddifficultiesinbothmodelswith selected word rank view (Fig. 2) to see how predictions
understanding LGBTQIA+ pronouns at all, which could compareacrossprompts,whensomearehigher/lower,lists
point to an unintentional bias with little training data to thatdonotmatch,liststhatareoffsetslightly,etc.
supportmaskedlanguagemodeling. For BERT, associations are mostly unique and relevant
tothesubjectreplacementsacrossallprompts.Membership
Race, religion, and politics. For BERT, given its poor
is highly dependent on the subject (i.e. the unique filter
performanceongender,orientation,andpronounlabels,we
shows most rows in both the Heat Map and Set View).
were surprised to find very few negative associations with
For example, we saw differences between where you find,
race, religion, and politics overall. Yet we found Hispanic
locate and see things (e.g., “drawer” vs “building” vs
andLatinoAmericanshadveryfewuniqueassociations(i.e.
“dream”, respectively), or when feeling, getting or becom-
low probability and variability in the Set View) compared
ing (e.g., “satisfied” vs “older” vs “greater”, respectively).
with other labels; it is likely that Hispanic and Latino
Relationshipscanalsobepositiveornegative–consequence
Americans are underrepresented in BERT’s training. For
produces negative associations while result/effect share
RoBERTa, we found a higher rate of bias and negative
commonpositiveassociations(e.g.,“powerless”/“bad”and
associations (i.e. high probability and variability in the Set
“good”/“desired”, respectively). BERT also understands
View) across underrepresented groups in the United States,
conceptualpairs(i.e.groupsofpredictionssharinganedge
suchasAsianAmericanswith“bullying”,“discrimination”;
intheScatterPlot).Snake/catareanimalsfoundina“park”
Hispanic and Latino Americans with “gangs”, “homeless-
or“garden”;heirloom/keepsakeareobjectsina“museum”
ness”; and African Americans with “slavery”, “hardship”.
or “collection”; a strategy/idea are found in a “story” or
RoBERTa also exhibited strong biases in attributes, moral
“job”.Thepredictionsfollowedtheirsubjecthypernymclus-
qualities, and affiliations between two different groups of
ters(e.g.,snake/catproducedmostly“physicalentity”pre-
religions. In the Scatter Plot, Islam/Hinduism/Christianity
dictions, strategy/idea produced mostly “abstraction” pre-
sharedmanypointsassociatedwithmarriageandmorality
dictions, while keepsake/heirloom were mixed). Chain of
compared to Judaism/Buddhism/Sikhism with peace and
reasoning prompts produced similar results. BERT showed
service (“polygamy”/“patriarchy”/“evil”/“oppressive” vs
uniqueandrelevantprerequisites(i.e.fewsharedconnector
“tolerant”/“strong”/“good”/“compassion”). It is surpris-
lines in the Set View) for healthy/sick such as “hungry”,
ing that RoBERTa has such ingrained stereotypes given the
“tired”or“pregnant”,happy/sadsuchas“alone”or“here”
debiasing shown in juxtaposition with otherwise stereo-
and right/wrong such as “stubborn”, “smart” or “blind”.
typical predictions from BERT. Interestingly, moral quali-
Top predictions for goals such as drive and fly are cor-
ties of political ideologies were divided in RoBERTa into
rect (e.g., “car”/“map” and “pilot”/“wings”, respectively).
shared qualities between groups. Using the Scatter Plot,
Succeed and fail are opposite (“plan”/“strategy” vs “dis-
we identified associations along shared edges (Anarchism,
traction”/“reason”),whilediscover,learn,andcreateareall
Facism and “violence”; Facism, Communism and “weak”,
associatedwith“teachers”,“lessons”,and“partners”.BERT
“evil”; Fascism, Conservatism and “arrogance”; National-
demonstratesastrongunderstandingofcomplexreasoning
ism,Conservatismand“loyalty”;Conservatism,Liberalism
acrossbothmembershipandchainofreasoningexamples.
and“tolerance”,“moderate”).RoBERTaalsofrequentlysug-
ForDistilBERT,wefoundstrongperformancesimilarto
gestedCommunismis“Jewish”(i.e.mostrowsfilledinthe
BERT in making associations for belongs and goals, such
Heat Map), relating two identities and suggesting learned
as similar pair associations between snake/cat, drive/fly
intersectionalbiasesmayexist,thoughoverlappingidentity
and discover/learn/create in the Scatter Plot. We noticed
associationswereotherwiserarelyseeninbothmodels.
associationsweremostlynoun-basedanddidnotfollowour
scheme of separating membership and chain-of-reasoning.
However,DistilBERTfailedtomakeinterestingorusefulas-
5.3 UseCase:KnowledgeProbing
sociations(i.e.thesharedfiltershowsmostrowsinboththe
HowwelldoLLMslearncomplexrelationshipsatdifferent Heat Map and Set View) for different causes or prerequisite
model scales? In Fig. 3C, we created templates to elicit prompts, which are generally verb-based associations. This
associationswithopen-endedconceptualpromptsandvar- suggests that DistilBERT, and potentially other small-scale
ioussubjectreplacementsthattestreasoningcapabilitiesfor models,mayonlycaptureandrepresentnounrelationships
membership (1 - belongs and 2 - causes) and chain of whilestrugglingtocaptureverbrelationships.
reasoning (3 - prerequisites and 4 - goals), based on the Wealsonoticedbiases,suchasBERTexhibitinglearned
LAMA[23]knowledgeprobe. associationsinbothchainofreasoningpromptswithfemale10
gender labels. This appeared in numerous associations of fromPubMedQA,theysaid,“IwouldexpectPubMedBERT
“women” being wrong more than right, in “pregnancy” to be more reliable based on its training.” P3 investigated
beingacommonpredictionacrossallprerequisiteprompts, the biomedical knowledge use case as well and made two
and in goal prompts where to do something you need a importantinterpretationsabouthowthesemodelsarework-
“woman”, “mother”, “wife” or “girl”. This is highly con- ing: (1) common grammar mistakes are prevalent, such as
cerning for how prevalent this association is despite the those made by second language English speakers; and (2)
numerous subject replacements and prompt variations we negativeassociationsarerareingeneral.
tested.Interestingly,DistilBERTdoesnotexhibitthesesame
Visualizations. The experts highlighted the usefulness of
biases,despitestrongnoun-basedsubjectpredictions.
the Prompt Interface for making connections between the
subjectandblankinthesentencemoreobviousandinsight-
5.4 ExpertEvaluation
ful. P3 found the clustering of predictions working better
We recruited six academic NLP researchers and engineers thanexpectedintheknowledgeprobingusecase;inspired,
(P1 − 6) to verify whether KnowledgeVIS was helpful, in- theyiterativelyaddedmorenouns,verbs,andrelationships
tuitive,andinsightfulforinterpretingBERT-basedlanguage togetincreasinglylargerandmorediversesemanticgroup-
models.Theexperts’workspannedlinguisticsandlanguage ings. While it took some time to learn, the complexity and
modeling, cluster and discourse analysis, text classification diversity of information in the visualizations allowed par-
and regression, and domain applications such as learning ticipants to answer different questions with each plot. For
sciences and medical data. They all had familiarity with example, P6 both complemented and critiqued the Scatter
either(1)trainingnewtransformersor(2)adaptingexisting Plotformakinginterestingyetpotentiallyspuriouscorrela-
transformers for downstream tasks. Participants received tions more salient, suggesting that a minimum number of
a brief demonstration of how KnowledgeVIS works before prompts may be needed for higher confidence. P1 praised
freely exploring the interface. Before and after exploration, the“logicalprogression”oftheplots,fromtheleastcomplex
we conducted semi-structured interviews to understand HeatMaponthelefttothemostcomplexScatterPlotonthe
each participant’s background and their findings when us- right,forhelpingthemintuitivelyunpackthecomplexityof
ing the interface. We indicate when participant feedback is thedatainincreasingamountsofdetail.
from examining a use case using the example buttons in
thePromptInterfaceandwhenfeedbackisfromanexample Applications. After uncovering insights, several experts
they created. We structured feedback around (1) insights
wantedtouseKnowledgeVISasa“launchpad”forexploring
thatexpertsgained;(2)theusefulnessofthevisualizations; model differences in their own work. P3 wanted to “chal-
and(3)futureapplicationsofKnowledgeVIS. lengethebestperformingmodelsonHuggingFace”against
their own work analyzing large data sets for language
Insights. The experts described several interesting and acquisition, using KnowledgeVIS to immediately visualize
insightful findings from using KnowledgeVIS. P5 tested the conceptsandrapidlytestwhichmodelsperformbetterout-
sensitivity of the general-domain models (BERT, RoBERTa, of-the-box.P2usesBERT-basedmodelsfornaturallanguage
and DistilBERT) to grammar and rephrasing when test- understanding(NLU)taskswithindiscourseanalysis,such
ing different subjects with the prompt “The [subject] ate as identifying individual speakers by classification. After
the/several .”. They learned that the models mostly re- investigating the effects of keywords on model predictions
spected both parts of speech and transitivity, e.g., correctly inthebiomedicalknowledgeusecase,theysuggestedusing
predicting singular and plural foods; however, they also KnowledgeVIS for testing domain-specific prompts such as
found the same models struggled with semantic roles, “Force equals mass times .” with LLMs trained on speech
e.g., predicting that both cows and wolves eat meat: “The transcriptions in physics lectures and textbooks. All partic-
model isn’t really looking at the syntax. It’s just looking ipants felt KnowledgeVIS was most useful to anyone inter-
at the words.’ P4 discovered potentially biased religious estedinunderstandingLLMsby“openingtheblackboxof
associations when testing BERT and DistilBERT for bias howtheywork”,especiallyforrapidqualitativeevaluation.
with the adage, “A [subject] a day keeps the away.” P3 suggested that NLP teachers could use KnowledgeVIS
They found using more common Western fruits as subjects to demonstrate vocabulary and grammar structures. P1
(e.g., apples and bananas) led to predicted words with highlighted how KnowledgeVIS shows dense information
positive associations to the fruit such as “gospel”, “wine”, on a single page “very succinctly”, which can help model
and “god” while less common fruits (e.g., durians) led to engineerseasilyinvestigateethicalperformancefactorssuch
negative associations such as “demons”, “plagues”, and asharmfulbiasesbeforedeployingtheirmodels.
“apocalypse”.Becausebothmodelsreturnedsimilarresults,
P4 surmised that a lack of training examples for subjects
likedurian,andnotthetrainingmechanism,wastheissue, 6 DISCUSSION
suggesting this as a way to fix this error. P2 used the
6.1 ClosingtheNLPLoop
Prompt Interface to isolate and replace keywords, such “IV
tubes” and “hospital patients”, for testing the robustness Twoofthebiggestchallengesinhuman-in-the-loopNLPare
ofSciBERTandPubMedBERTinthebiomedicalknowledge (1)howtocreateandgroupeffectivepromptsand(2)what
use case. They found that SciBERT, which uses a custom todoonceinsightsarediscoveredduringmodelevaluation.
wordpiece vocabulary (scivocab), was more consistent and Our use cases and expert evaluation suggest several ways
accurate in recommendations than PubMedBERT for key- KnowledgeVIS could help mitigate uncovered biases and
words related to the vocabulary. Given the examples came errorsinthefuture,towardsclosingtheloop.11
One solution is to create prompts as test cases to aug- this is a more human-centered approach to interpreting
ment training data. Using the Prompt Interface, users can LLMsinanareadominatedbytoolsthatfocusonshowing
systematicallytestforlimitationsonwhathasbeenlearned, morefeatures,makingthemodelmorecomplex.
either when training data is scarce or a particular concept Ingeneral,thereisachallengeofmakingdeeplearning
is not well represented in the corpus. For example, in our modelsinmachinelearninginterpretable.KnowledgeVISad-
use cases we found a lack of Hispanic and Latino Amer- dresseswhatisbeingvisualized(modelpredictions),forwho
ican representation as well as difficulties in recognizing (model users), and why (interpretability) to overcome limi-
LGBTQIA+ pronouns by creating and grouping prompts tationsaroundprerequisitebackgroundknowledgeindeep
thatvariedidentityphrasesassubjects.Researcherscanalso learningneeded.Forexample,Hohmanetal.[24]useatable
testforsensitivitytocommontextdimensionssuchasparts of terminology in their visual analytics for deep learning
of speech, transitivity, and semantic roles. Based on P3’s survey to preface what is being visualized for interpreting
interpretations of the biomedical use case, more examples how deep learning models work. They explicitly describe
of both negative recommendations and diverse grammar modelusersthatdevelopandtraindomain-specific,smaller-
patternsinthetrainingdatawouldlikelymakebothmodels scale models and applications and “often download pre-
more robust. To overcome “cold start” difficulties in gen- trainedmodelweightsonlinetouseasastartingpoint”[24].
erating prompts, we provide several example buttons that Consider,forexample,anexpertinlinguisticsdevelopinga
demonstrateavarietyoftestcases.Wediscussfuturework transformer-based approach to sentiment classification for
inautomaticallygeneratingpromptsinSect.6.3. analyzing historical documents. Because model users are
Another is to help researchers narrow the initial se- notalwaysexpertsindeeplearningandyetareincreasingly
lection of models. Our evaluation of differences between using LLMs for downstream tasks, there can be severe
models led to important findings. We found SciBERT was consequences[6]withoutaccessibletoolsthatovercomebar-
more sensitive to changes in context and grammar, while rierstocommunicatingwhatLLMshavelearned.Weseekto
PubMedBERT was more sensitive to subject replacements. bridge the gap needed to interpret deep learning terminol-
Comparing BERT against DistilBERT for learning complex ogy and how transformer-based language models work by
reasoning,werealizedDistilBERThadtroublewithverbre- showinghowthemodelperformsonthedownstreamtasks
placements,butcouldhandlenounreplacementswell,even ofinteresttomodelusers.KnowledgeVISempowersusersto
at its smaller model size. By comparing prompt variations exploretheirdatainthewaytheythinkaboutit.
between models using a drop-down list, researchers can
quicklygainanunderstandingofthetrade-offsofdifferent
pre-trainedmodelsandwhentheirusecasemaybeabetter
fitforwhatagivenmodelisalreadygoodat. 6.3 LimitationsandFutureWork
Finally, discovering unexpected yet important concepts
and patterns can suggest future training ideas. The Set While in this paper we focus on eliciting and evaluat-
View and Scatter Plot were effective for revealing uncom- ing semantic and commonsense knowledge, other types of
mon associations by grouping predictions, such as be- knowledge exist (e.g., syntactic, linguistic) [4]. We could
tween women, LGBTQIA+ labels, and morality, or be- extendourapproachbyrepresentingpartsofspeech(POS)
tween the groups of Islam/Hinduism/Christianity and Ju- or semantic roles in various ways; e.g., by visualizing the
daism/Buddhism/Sikhism. P2 suggested that for domain- syntactic tree structure of the prompt or by labeling words
adapted models, KnowledgeVIS can help rapidly generate by POS and/or role, in addition to their semantic cluster.
a variety of test cases for specific learned concepts; e.g., a Userscouldalsodirectlyannotatevisualizations;e.g.,man-
physics model testing concepts such as “Force times mass ually grouping predicted tokens and assigning context in
equals .”Ourhumanintheloopapproachenablesexperts one plot that can be viewed in another plot. This could
to identify patterns quantitative metrics can miss and re- extend to new visualizations that help users directly com-
evaluatethesamemodelsbeforedeployingthem. pare probabilities for a few words at a time, and between
groups of words. Additionally, to overcome “cold start”
6.2 ImprovingHuman-LMInteraction
issues in creating and grouping new prompts, we could
AsnewadvancementsinmachinelearningforNLPemerge, usegenerativeLLMstoproviderelatedconceptsforexisting
thereisanopportunityforvisualanalyticstoolstosupport prompts by seeding sentences with topic keywords. How-
human-in-the-loop evaluation of LLM performance [13] ever,whilewefocusonpromptingasthemethodofeliciting
wherequantitativebenchmarksfallshort[12].KnowledgeVIS knowledgeandvisualizationsforevaluatingprompts,more
makes LLMs more interpretable by guiding the user to workisneededtounderstandthelimitationsofpromptsas
explorethespaceofpredictionsindifferentways.Typically sourcesofinterpretability[3].Forexample,itisunclearwhat
machine learning models are quantitatively benchmarked the effects of grammar are on model performance. Finally,
againstgoldstandardsforprecisionandrecall.Thisbrutally we designed our visualizations to reasonably support up
objective methodology misses an opportunity for injecting to 10 prompts at a time and found it sufficient to return
humanintuitionanddomainexpertiseintotheiterativepro- between k = 30 and k = 200 top predicted tokens at one
cess of training and validating model performance. Knowl- time. The vocabulary of some LLMs, however, can extend
edgeVIS does this by presenting patterns of model output beyond hundreds of thousands of tokens [2]. It is unclear
atahigherlevel,togaininsightthroughrepeatedmeasures howscalingourapproachbyvisualizingmorepromptsand
rather than one-shot explanations, and using natural lan- predictions at the same time might affect the exploration
guage tasks to show how the model performs. We believe anddiscoveryprocess,positivelyornegatively.12
7 CONCLUSION [11] Z.Zhong,D.Friedman,andD.Chen,“Factualprobingis[MASK]:
Learningvs.learningtorecall,”inProceedingsofthe2021Conference
As transformer-based large language models (LLMs) con-
of the North American Chapter of the Association for Computational
tinuetoimproveintheirabilitytohelppeopleanswerques- Linguistics:HumanLanguageTechnologies. Online:Associationfor
tions,generateessays,andmore,itiscriticalforresearchers ComputationalLinguistics,Jun.2021,pp.5017–5033.
tointerprethowandwhytheywork,inordertobuildbetter [12] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell,
“On the dangers of stochastic parrots: Can language models be
modelsthatreducebias,mitigatestereotypes,learndomain-
too big?” in Proceedings of the 2021 ACM Conference on Fairness,
specific knowledge, etc. In this work, we presented Knowl- Accountability, and Transparency, ser. FAccT ’21. New York, NY,
edgeVIS, a visual analytics system for discovering learned USA:AssociationforComputingMachinery,2021,p.610–623.
[13] Z.J.Wang,D.Choi,S.Xu,andD.Yang,“Puttinghumansinthe
associations in LLMs. By intuitively formatting multiple
naturallanguageprocessingloop:Asurvey,”inProceedingsofthe
sentences as prompts and visualizing predictions across FirstWorkshoponBridgingHuman–ComputerInteractionandNatu-
several coordinated views, KnowledgeVIS reveals learned ral Language Processing. Online: Association for Computational
associations for different types of relationships between Linguistics,Apr.2021,pp.47–52.
[14] A.Warstadtetal.,“InvestigatingBERT’sknowledgeoflanguage:
predictions that help researchers interpret how the LLM is
Five analysis methods with NPIs,” in Proceedings of the 2019
performing. KnowledgeVIS demonstrates several capabili- ConferenceonEmpiricalMethodsinNaturalLanguageProcessingand
ties such as eliciting sensitive medical domain knowledge, the9thInternationalJointConferenceonNaturalLanguageProcessing
uncovering harmful stereotypes, and probing complex rea- (EMNLP-IJCNLP). HongKong,China:AssociationforComputa-
tionalLinguistics,Nov.2019,pp.2877–2887.
soning capabilities. Combined with expert feedback that
[15] Y. Elazar, N. Kassner, S. Ravfogel, A. Ravichander, E. Hovy,
validates the effectiveness and usability of the system, we H. Schu¨tze, and Y. Goldberg, “Measuring and Improving Con-
believeKnowledgeVIScontributestoagrowingareaofvisu- sistencyinPretrainedLanguageModels,”TransactionsoftheAsso-
ciationforComputationalLinguistics,vol.9,pp.1012–1031,122021.
alizationforLLMinterpretability.
[16] C.Collins,F.B.Viegas,andM.Wattenberg,“Paralleltagcloudsto
exploreandanalyzefacetedtextcorpora,”in2009IEEESymposium
ACKNOWLEDGMENTS onVisualAnalyticsScienceandTechnology,2009,pp.91–98.
[17] J. S. Yi, R. Melton, J. Stasko, and J. A. Jacko, “Dust & magnet:
SupportprovidedbyNSFIIS-1750474andDRL-2247790. Multivariateinformationvisualizationusingamagnetmetaphor,”
InformationVisualization,vol.4,no.4,pp.239–256,2005.
[18] I.Beltagy,K.Lo,andA.Cohan,“Scibert:Apretrainedlanguage
REFERENCES
modelforscientifictext,”arXivpreprintarXiv:1903.10676,2019.
[19] Y.Gu,R.Tinn,H.Cheng,M.Lucas,N.Usuyama,X.Liu,T.Nau-
[1] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-
mann, J. Gao, and H. Poon, “Domain-specific language model
training of deep bidirectional transformers for language under-
pretraining for biomedical natural language processing,” ACM
standing,”inProceedingsofthe2019ConferenceoftheNorthAmerican
Trans.Comput.Healthcare,vol.3,no.1,oct2021.
ChapteroftheAssociationforComputationalLinguistics:HumanLan-
[20] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy,
guageTechnologies,Volume1(LongandShortPapers). Minneapolis,
M. Lewis, L. Zettlemoyer, and V. Stoyanov, “Roberta: A ro-
Minnesota:AssociationforComputationalLinguistics,Jun.2019,
bustly optimized bert pretraining approach,” arXiv preprint
pp.4171–4186.
arXiv:1907.11692,2019.
[2] T. Brown et al., “Language models are few-shot learners,” in
[21] V.Sanh,L.Debut,J.Chaumond,andT.Wolf,“Distilbert,adistilled
Advances in Neural Information Processing Systems, H. Larochelle,
versionofbert:smaller,faster,cheaperandlighter,”arXivpreprint
M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, Eds., vol. 33.
arXiv:1910.01108,2019.
CurranAssociates,Inc.,2020,pp.1877–1901.
[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
[3] A.Srivastavaetal.,“Beyondtheimitationgame:Quantifyingand
Gomez,Ł.Kaiser,andI.Polosukhin,“Attentionisallyouneed,”
extrapolatingthecapabilitiesoflanguagemodels,”Transactionson
inAdvancesinNeuralInformationProcessingSystems,I.Guyon,U.V.
MachineLearningResearch,2023.
Luxburg,S.Bengio,H.Wallach,R.Fergus,S.Vishwanathan,and
[4] A.Rogers,O.Kovaleva,andA.Rumshisky,“AprimerinBERTol-
R.Garnett,Eds.,vol.30. CurranAssociates,Inc.,2017.
ogy:WhatweknowabouthowBERTworks,”Transactionsofthe
AssociationforComputationalLinguistics,vol.8,pp.842–866,2020. [23] F.Petroni,T.Rockta¨schel,S.Riedel,P.Lewis,A.Bakhtin,Y.Wu,
[5] A.Roberts,C.Raffel,andN.Shazeer,“Howmuchknowledgecan and A. Miller, “Language models as knowledge bases?” in Pro-
youpackintotheparametersofalanguagemodel?”inProceedings ceedings of the 2019 Conference on Empirical Methods in Natural
of the 2020 Conference on Empirical Methods in Natural Language LanguageProcessingandthe9thInternationalJointConferenceonNat-
Processing (EMNLP). Online: Association for Computational ural Language Processing (EMNLP-IJCNLP). Hong Kong, China:
Linguistics,Nov.2020,pp.5418–5426. Association for Computational Linguistics, Nov. 2019, pp. 2463–
[6] A. Abid, M. Farooqi, and J. Zou, “Persistent anti-muslim bias 2473.
inlargelanguagemodels,”inProceedingsofthe2021AAAI/ACM [24] F.Hohman,M.Kahng,R.Pienta,andD.H.Chau,“Visualanalytics
ConferenceonAI,Ethics,andSociety,ser.AIES’21. NewYork,NY, indeeplearning:Aninterrogativesurveyforthenextfrontiers,”
USA:AssociationforComputingMachinery,2021,p.298–306. IEEE Transactions on Visualization and Computer Graphics, vol. 25,
[7] P.Liu,W.Yuan,J.Fu,Z.Jiang,H.Hayashi,andG.Neubig,“Pre- no.8,pp.2674–2693,2019.
train, prompt, and predict: A systematic survey of prompting [25] Z. J. Wang, R. Turko, O. Shaikh, H. Park, N. Das, F. Hohman,
methods in natural language processing,” ACM Comput. Surv., M. Kahng, and D. H. Polo Chau, “Cnn explainer: Learning con-
vol.55,no.9,jan2023. volutional neural networks with interactive visualization,” IEEE
[8] Z.Jiang,F.F.Xu,J.Araki,andG.Neubig,“HowCanWeKnow TransactionsonVisualizationandComputerGraphics,vol.27,no.2,
WhatLanguageModelsKnow?”TransactionsoftheAssociationfor pp.1396–1406,2021.
ComputationalLinguistics,vol.8,pp.423–438,072020. [26] S. Hochreiter and J. Schmidhuber, “Long short-term memory,”
[9] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh, Neuralcomputation,vol.9,no.8,pp.1735–1780,1997.
“AutoPrompt: Eliciting Knowledge from Language Models with [27] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine trans-
Automatically Generated Prompts,” in Proceedings of the 2020 lation by jointly learning to align and translate,” arXiv preprint
Conference on Empirical Methods in Natural Language Processing arXiv:1409.0473,2014.
(EMNLP). Online: Association for Computational Linguistics, [28] H. Strobelt, S. Gehrmann, M. Behrisch, A. Perer, H. Pfister, and
Nov.2020,pp.4222–4235. A.M.Rush,“Seq2seq-vis:Avisualdebuggingtoolforsequence-
[10] G.QinandJ.Eisner,“Learninghowtoask:QueryingLMswith to-sequencemodels,”IEEETransactionsonVisualizationandCom-
mixtures of soft prompts,” in Proceedings of the 2021 Conference puterGraphics,vol.25,no.1,pp.353–363,2019.
of the North American Chapter of the Association for Computational [29] C. Wang, A. Jain, D. Chen, and J. Gu, “VizSeq: a visual anal-
Linguistics:HumanLanguageTechnologies. Online:Associationfor ysis toolkit for text generation tasks,” in Proceedings of the 2019
ComputationalLinguistics,Jun.2021,pp.5203–5212. ConferenceonEmpiricalMethodsinNaturalLanguageProcessingand13
the9thInternationalJointConferenceonNaturalLanguageProcessing [45] J.H.W.Jr.,“Hierarchicalgroupingtooptimizeanobjectivefunc-
(EMNLP-IJCNLP): System Demonstrations. Hong Kong, China: tion,”JournaloftheAmericanStatisticalAssociation,vol.58,no.301,
Association for Computational Linguistics, Nov. 2019, pp. 253– pp.236–244,1963.
258. [46] B.J.FreyandD.Dueck,“Clusteringbypassingmessagesbetween
[30] I. Tenney, J. Wexler, J. Bastings, T. Bolukbasi, A. Coenen, datapoints,”Science,vol.315,no.5814,pp.972–976,2007.
S.Gehrmann,E.Jiang,M.Pushkarna,C.Radebaugh,E.Reif,and [47] P.J.Rousseeuw,“Silhouettes:Agraphicalaidtotheinterpretation
A. Yuan, “The language interpretability tool: Extensible, interac- and validation of cluster analysis,” Journal of Computational and
tive visualizations and analysis for NLP models,” in Proceedings AppliedMathematics,vol.20,pp.53–65,1987.
of the 2020 Conference on Empirical Methods in Natural Language [48] G.A.Miller,“Wordnet:Alexicaldatabaseforenglish,”Commun.
Processing:SystemDemonstrations. Online:AssociationforCom- ACM,vol.38,no.11,p.39–41,nov1995.
putationalLinguistics,Oct.2020,pp.107–118. [49] B.B.Bederson,“Fisheyemenus,”inProceedingsofthe13thannual
[31] J.Vig,“Amultiscalevisualizationofattentioninthetransformer ACMsymposiumonUserinterfacesoftwareandtechnology,2000,pp.
model,”inProceedingsofthe57thAnnualMeetingoftheAssociation 217–225.
for Computational Linguistics: System Demonstrations. Florence, [50] K. A. Olsen, R. R. Korfhage, K. M. Sochats, M. B. Spring, and
Italy:AssociationforComputationalLinguistics,Jul.2019,pp.37– J.G.Williams,“Visualizationofadocumentcollection:Thevibe
42. system,” Information Processing & Management, vol. 29, no. 1, pp.
69–81,1993.
[32] B. Hoover, H. Strobelt, and S. Gehrmann, “exBERT: A Visual
[51] Q. Jin, B. Dhingra, Z. Liu, W. Cohen, and X. Lu, “PubMedQA:
AnalysisTooltoExploreLearnedRepresentationsinTransformer
A dataset for biomedical research question answering,” in Pro-
Models,” in Proceedings of the 58th Annual Meeting of the Associa-
ceedings of the 2019 Conference on Empirical Methods in Natural
tionforComputationalLinguistics:SystemDemonstrations. Online:
LanguageProcessingandthe9thInternationalJointConferenceonNat-
AssociationforComputationalLinguistics,Jul.2020,pp.187–196.
ural Language Processing (EMNLP-IJCNLP). Hong Kong, China:
[33] J.F.DeRose,J.Wang,andM.Berger,“Attentionflows:Analyzing
Association for Computational Linguistics, Nov. 2019, pp. 2567–
andcomparingattentionmechanismsinlanguagemodels,”IEEE
2577.
TransactionsonVisualizationandComputerGraphics,vol.27,no.2,
[52] D.Nozza,F.Bianchi,andD.Hovy,“”HONEST:Measuringhurtful
pp.1160–1170,2021.
sentence completion in language models”,” in Proceedings of the
[34] Z.J.Wang,R.Turko,andD.H.Chau,“Dodrio:ExploringTrans-
2021ConferenceoftheNorthAmericanChapteroftheAssociationfor
former Models with Interactive Visualization,” in Proceedings of
Computational Linguistics: Human Language Technologies. Online:
theJointConferenceofthe59thAnnualMeetingoftheAssociationfor
Association for Computational Linguistics, Jun. 2021, pp. 2398–
ComputationalLinguisticsandthe11thInternationalJointConference
2406.
on Natural Language Processing: System Demonstrations. Online:
[53] D. Nozza, F. Bianchi, A. Lauscher, and D. Hovy, “Measuring
AssociationforComputationalLinguistics,2021,pp.132–141.
harmfulsentencecompletioninlanguagemodelsforLGBTQIA+
[35] K.Clark,U.Khandelwal,O.Levy,andC.D.Manning,“Whatdoes individuals,” in Proceedings of the Second Workshop on Language
BERTlookat?ananalysisofBERT’sattention,”inProceedingsofthe Technology for Equality, Diversity and Inclusion. Dublin, Ireland:
2019ACLWorkshopBlackboxNLP:AnalyzingandInterpretingNeural AssociationforComputationalLinguistics,May2022,pp.26–34.
NetworksforNLP. Florence,Italy:AssociationforComputational [54] J.Dhamala,T.Sun,V.Kumar,S.Krishna,Y.Pruksachatkun,K.-W.
Linguistics,Aug.2019,pp.276–286. Chang,andR.Gupta,“Bold:Datasetandmetricsformeasuring
[36] S. Jain and B. C. Wallace, “Attention is not Explanation,” in biases in open-ended language generation,” in Proceedings of the
Proceedings of the 2019 Conference of the North American Chapter 2021ACMConferenceonFairness,Accountability,andTransparency,
of the Association for Computational Linguistics: Human Language ser.FAccT’21. NewYork,NY,USA:AssociationforComputing
Technologies, Volume 1 (Long and Short Papers). Minneapolis, Machinery,2021,p.862–872.
Minnesota:AssociationforComputationalLinguistics,Jun.2019, [55] K. Crenshaw, “Demarginalizing the intersection of race and sex:
pp.3543–3556. Ablackfeministcritiqueofantidiscriminationdoctrine,feminist
[37] P. Atanasova, J. G. Simonsen, C. Lioma, and I. Augenstein, “A theory and antiracist politics,” The University of Chicago Legal
diagnostic study of explainability techniques for text classifica- Forum,vol.1989,no.1,pp.139–167,1989.
tion,”inProceedingsofthe2020ConferenceonEmpiricalMethodsin
Natural Language Processing (EMNLP). Online: Association for
ComputationalLinguistics,Nov.2020,pp.3256–3274.
[38] H.Strobelt,A.Webson,V.Sanh,B.Hoover,J.Beyer,H.Pfister,and
A.M.Rush,“Interactiveandvisualpromptengineeringforad-hoc
taskadaptationwithlargelanguagemodels,”IEEETransactionson
VisualizationandComputerGraphics,vol.29,no.1,pp.1146–1156, Adam Coscia is a PhD student at Geor-
2023. gia Tech’s School of Interactive Computing
[39] H.Strobelt,B.Hoover,A.Satyanaryan,andS.Gehrmann,“LMdiff: and a member of the Visual Analytics Lab.
A visual diff tool to compare language models,” in Proceedings His research interests include Visual Analytics,
of the 2021 Conference on Empirical Methods in Natural Language Human-Computer Interaction, and Explainable
Processing: System Demonstrations. Online and Punta Cana, Artificial Intelligence (AI) with Large Language
Dominican Republic: Association for Computational Linguistics, ModelsandKnowledgeGraphs.Hereceivedhis
Nov.2021,pp.96–105. B.S.inPhysics.HewonthePresident’sFellow-
[40] T.Wolfetal.,“Transformers:State-of-the-artnaturallanguagepro- shipfortopincomingPhDstudents.
cessing,”inProceedingsofthe2020ConferenceonEmpiricalMethods
in Natural Language Processing: System Demonstrations. Online:
AssociationforComputationalLinguistics,Oct.2020,pp.38–45.
[41] J. H. Lau, K. Grieser, D. Newman, and T. Baldwin, “Automatic
labellingoftopicmodels,”inProceedingsofthe49thAnnualMeeting
of the Association for Computational Linguistics: Human Language
Technologies - Volume 1, ser. HLT ’11. USA: Association for
ComputationalLinguistics,2011,p.1536–1545. Alex Endert is an associate professor at the
[42] Z.WuandM.Palmer,“Verbssemanticsandlexicalselection,”in SchoolofInteractiveComputing,GeorgiaTech.
Proceedingsofthe32ndAnnualMeetingonAssociationforComputa- He directs the Visual Analytics Lab, which ex-
tionalLinguistics,ser.ACL’94. USA:AssociationforComputa- plores novel user interaction techniques for vi-
tionalLinguistics,1994,p.133–138. sualanalytics.
[43] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efficient esti-
mation of word representations in vector space,” arXiv preprint
arXiv:1301.3781,2013.
[44] D.Mu¨llner,“Modernhierarchical,agglomerativeclusteringalgo-
rithms,”arXivpreprintarXiv:1109.2378,2011.14
APPENDIX A Set View when selecting a word and sorting by rank k=16
PREDICTIONS CLUSTERING ALGORITHM DESIGN
r=9 r=6 r=11 r=5
n=5
ϕ= 3/10, ϕ= 2/10 ϕ= 5/10 ϕ= 5/10 ϕ= 6/10
To help users discover patterns in predictions sets, we aim t b b t b
to automatically find and label sets of predictions based
on shared semantic similarity. Our solution algorithmically
generates clusters and allows the user to investigate them 1
across each of the plots in the Predictions View. Here, we
h 2
describeourdesignprocessandrationale. t
3
First, we seek a method of labeling clusters to more
4
effectively communicate what the semantic similarity of
words in that clusters is. To determine these labels, we use 5
a taxonomy-based method implemented in WordNet [48]. 6
Consider that a majority of the predictions returned by 7
the language model are open-class words such as nouns,
8
verbs, etc. WordNet categorizes the senses of words as
9
setsofsynonyms(synsets)taxonomicallyaccordingtotheir
10
hypernyms — words with a broad meaning that more
specificwordsfallunder.Forexample,colorisahypernym 11
of red. Thus, an informative label for a set of words can 12
beautomaticallydeterminedbyfindingthelowestcommon 13
hypernym(LCH)ofthesetusingWordNet.
14
Next, we seek a similarity measure to compare words
15
based on their shared hypernyms. We chose Wu-Palmer h
b 16
similarity [42], as it is a measure based on the taxonomic
depthoftwosenses(synsets)andthatoftheirleastcommon
subsumer (i.e. most specific ancestor node, or hypernym). Fig. 4. The Set View showing our variation on the parallel tag cloud
layout,astep-wisedegreeofinterestlistbasedonfisheyemenus[49]for
We also experimented with measuring similarity by gener-
aselectedwordwhensortingbyrank,describedinFig.4.2.3.Wequery
atingwordvectors[43]butfoundthatWu-Palmersimilarity thetopk=16predictionsandselect“cook”fromtheresultingview.Our
tendedtoperformbetterforclusteringsmallersetsofwords usercanquicklysee“cook”isrankedlowerforthe“man”/“boy”subjects
thatproducedamoreuniqueanddescriptiveLCH. thanfor“woman”/“girl”,showingaslightgenderbiasintheprobabilityof
theoccupationoccurring,eventhoughitappearsforallsubjects.
Finally, we seek a method for clustering words based
on their similarity measure. Consider that our aim is to
automatically find and label sets of semantically related
theneighborhoodofnwordsaboveandbelowtheselected
words.Thismeansweneedanunsupervisedmethodwhere
wordinrankorderequidistantand,fortheremainingwords
the number of clusters is unknown a priori. Thus, we can
outside of that neighborhood, we draw lines above and
performhierarchical clustering[44]usingWu-Palmersim-
below that scale proportionally with the remaining words
ilarity as the distance measure between observations, i.e.,
fromthetopandbottomofthelist,respectively.
predicted words, and an appropriate linkage method, e.g.,
Forthetopktokens,nneighborhoodwords,andrankr
Ward’s method [45]. To determine an optimal number of
of the selected word in each column, our layout algorithm
clusters,wecanfindthemaximumsilhouettecoefficient[47]
performsthefollowingoperations:
based on mean intra-cluster and nearest-cluster distance of
allw wordsforanynumbercofclusters2 ≤ c ≤ w.Affin- 1) positioneachoccurrenceoftheselectedwordalongthe
ity propagation [46] is a comparable unsupervised clus- same horizontal baseline in the center of the plot, set-
tering technique specifically for similarity-based distance tingcolumnswithouttheselectedwordtozeroopacity;
measures that produces similar results for small numbers and
of unique predictions. However, as w grows, we found it 2) arrangetheneighborhoodofrankedwords1≤r±n≤
tended to produce too many clusters with less descriptive kaboveandbelowtheselectedwordtop-downinrank-
labels and required manual tuning of the damping factor
order,uniformlyspaced.
to keep the number of clusters useful. This can instead be
3) Ifr >n+1:
solvedwithhierarchicalclusteringbysettingauser-defined
threshold u on the optimal number of clusters 2 ≤ c ≤ u a) compute the percentage of remaining words in the
whilesearchingforamaximumsilhouettecoefficient. listabovetheselectedwordϕ t = kr− −n n− −1 1;
b) computetheremainingheighth t fromthetopofthe
r−nwordtothetopoftheplot;and
APPENDIX B
SET VIEW RANKED SELECT LAYOUT ALGORITHM c) drawalineupwardsfromthetopofther−nword
oflengthh t·ϕ t.
Wedesignedanovelvariationontheparalleltagcloud[16]
4) Ifr <k−n:
layoutintheSetView(Fig.4).Selectingawordwhilesorting
by rank order transitions the view to a step-wise degree a) compute the percentage of remaining words in the
of interest list, similar to fisheye menus [49]. We arrange listbelowtheselectedwordϕ b = kk −− nn −− 1r;15
b) computetheremainingheighth b fromthebottomof usingvisualencodings,whichpresentsanalyticaltrade-offs
ther+nwordtothebottomoftheplot;and when choosing scales (linear and log) as well as encodings
c) drawalinedownwardsfromthebottomofther+n (color, font and marker size). We acknowledge our qualita-
wordoflengthh b·ϕ b. tive approach may be subject to pre-attentive biases. Here,
wepresentsupplementalfiguresdemonstratingtheinsights
An example for k = 16 tokens is shown in Fig. 4. We
we discovered. Please see the full paper for an in-depth
found that n = 5 neighborhood words revealed enough
discussionoftheimplicationsofourfindings.
details at once while ensuring the line had a reasonable
First, we test grammar and phrasing by formatting
amountofremainingspacetobeinformative.Iftherankrof
yes/no/maybe questions from a biomedical question-
theselectedwordislessthannfromthetoporbottomofthe
answer data set, PubMedQA [51], as fill-in-the-blank sen-
column,wearrangetheremainingr−1ork−rwordsabove
tences and querying SciBERT [18] and PubMedBERT [19].
orbelowtheselectedword anddonotdrawlines,asthere
Second,wetestforcontextualizedgender,orientation,pro-
are no remaining words in the list. Additionally, if a word
noun, race, religious, and political stereotypes between
does not occur in one or several columns, those columns
BERT [1] and RoBERTa [20] using subsets of the HONEST
are now set to have zero opacity, as they cannot be drawn
[52], [53] and BOLD [54] data sets. Third, we test whether
to scale with the new layout. Neighborhood words can be
complex learned concepts based on the LAMA knowledge
selected in this layout, and the algorithm will accordingly
probe[23],suchasmembership(belongs,causes)andchain
shift the neighborhood of words up or down as well as
of reasoning (goals, prerequisites), are learned between
lengthenandshortenthelines.
large-scaleBERTandsmall-scaleDistilBERT[21].
Biomedical knowledge. How do domain-specific models
APPENDIX C
compare based on robustness to grammar and phrasing
SCATTER PLOT INITIAL LAYOUT ALGORITHM whenexperthumananswersareexpected?
TheScatterPlotpositionspredictedtokensasvectorsbased For PubMedBERT (Fig. 5), the Heat Map shows miss-
ing entries between therapeutic anticoagulation (“ideal”,
on their probability of occurring for each prompt or “point
“significant”, “imperative”, “standard”) and anticoagula-
of interest” (POI) in a 2D coordinate space, using a layout
tion therapy (“costly”, “expensive”, “complex”), as well
techinquederivedbyOlsenetal.[50].
Theinitiallayoutofmpromptsandallpredictedwords as some positive associations for “patients” and not for
“humans”. PubMedBERT also associated “long” with sets
isasfollows:
of words including “expensive”, “dangerous” and “bad”,
1) position m POIs at the vertices of an m-sided reg-
while “short” was “safe”, “convenient”, “simple”. This
ular polygon, calculate the display position p i = association persists even when other phrases change. For
(x,y) for each POI, and create a POI position vector
SciBERT (Fig. 6), key phrase changes are generally ignored
P[p 1,p 2,...,p m].
whilethecontextandgrammarofthesentencemoreheavily
2) For each unique predicted word D[d 1,d 2,...,d m], change predictions than with PubMedBERT. For example,
where d i is the probability of the predicted word oc- where SciBERT is consistent (i.e. most rows filled in the
curringinpromptp i: Heat Map) across subject replacements for 1a, it is similarly
a) combine the two vectors P and D into the set S = consistentyetoppositefor1b(“recommended”/“required”
{(d 1,p 1),(d 2,p 2),...,(d m,p m)}. vs “not”). Similarly, SciBERT finishes the sentence for 2a
with“difficult”,“easy”,“hard”,and“simple”acrossalmost
b) If the probability of the predicted word is non-zero
allvariations,notmakinganyrecommendation,whileusing
for only one prompt p j (∀x where x ̸= j | d x = 0), “take”in2bresultsinrecommendationslike“able”,“possi-
thefinalpositionofD wouldbeontopofp j;donot
ble”,“required”and“likely”.
plot.
Identity stereotypes. How can important yet underrep-
c) Otherwise,removetwoelementsfromS,(d a,p a)and
resented identity stereotypes be discovered in general-
(d b,p b), calculate a new score d s = d a + d b and purposelanguagemodels?
positionp
s
=((1−t)·p a,x+t·p b,x,(1−t)·p a,y+t·p b,y),
For BERT (Fig. 7), as expected, binary labels were
where t = dd sb is the ratio of the distance from p a to more often associated with gender norms and positivity
p s,andputthenewscore/positionpair(d s,p s)back
compared with LGBTQIA+ labels being misclassified with
inS.
stereotypical and negative exceptions (e.g., “beautiful”
d) If S contains more than one element, repeat (c). and “admired”, versus “different” and “temporary”).
Otherwise, plot the predicted word D at the final Despite its poor performance on gender, orientation,
remainingp s. and pronoun labels, we were surprised to find very few
negative associations with race, religion, and politics
overall. However, Hispanic and Latino Americans had
APPENDIX D
very few unique associations compared with other labels.
SUPPORTING FIGURES FOR USE CASES
For RoBERTa (Fig. 8), we found bias in associations
WedemonstratethecapabilitiesofKnowledgeVISforprompt with morality and gender norms to be less frequent
engineering and immediate visual analysis of fill-in-the- and isolated overall. Yet we found a higher rate of
blanksentencepredictionswiththreeusecases.Importantly, bias and negative associations across underrepresented
the results are based on interpreting word probabilities groups in the United States, such as Asian Americans16
Biomedical Knowledge
PubMedBERT (2021)
•Therapeutic anticoagulation
 is _ for trauma ♥patients
 to receive. A •short
 stay in a general
 children’s
 is _ to take.
■anticoagulation therapy ◆humans ■long academic adult’s
♥
♥
■ •
■
•
■ ■■
◆
•
♥
■
♥
♥
■
•
◆
•
•
•
• ■
Fig.5.TwoHeatMapsshowinghowgrammarandphrasingaffectPubMedBERT.Theglyphshighlightpredictionsmentionedinthebodytext.
with “bullying”, “discrimination”; Hispanic and Latino labels. Another unexpected association was made between
Americans with “gangs”, “homelessness”; and African men, sports and sexuality in RoBERTa. The inclusion of
Americans with “slavery”, “hardship”. RoBERTa also heterosexual/homosexual labels reveals associations with
exhibited strong biases in attributes, moral qualities, and “athletes”,“coaches”,“players”,and“leaders”.
affiliations between two different groups of religions. In
Knowledge probing. How well do LLMs learn complex
theScatterPlot,Islam/Hinduism/Christianitysharedmany
relationshipsatdifferentmodelscales?
points associated with marriage and morality compared
For BERT (Fig. 10), associations are mostly unique and
to Judaism/Buddhism/Sikhism with peace and service
relevant to the subject replacements across all prompts.
(“polygamy”/“patriarchy”/“false”/“evil”/“oppressive”vs
We saw differences between where you find, locate and
“tolerant”/“strong”/“good”/“compassion”/“excellence”).
see things (e.g., “drawer” vs “building” vs “dream”, re-
Interestingly, moral qualities of political ideologies were
spectively), or when feeling, getting or becoming (e.g.,
divided in RoBERTa into shared qualities between groups.
“satisfied” vs “older” vs “greater”, respectively). Rela-
Using the Scatter Plot, we identified associations along
tionships can also be positive or negative – consequence
shared edges (Anarchism, Facism and “violence”; Facism,
produces negative associations while result/effect share
Communism and “weak”, “evil”; Fascism, Conservatism
commonpositiveassociations(e.g.,“powerless”/“bad”and
and“arrogance”;Nationalism,Conservatismand“loyalty”;
“good”/“desired”, respectively). BERT also understands
Conservatism, Liberalism and “tolerance”, “moderate”).
conceptualpairs(i.e.groupsofpredictionssharinganedge
RoBERTa also frequently suggested Communism is
intheScatterPlot).Snake/catareanimalsfoundina“park”
“Jewish”(i.e.mostrowsfilledintheHeatMap),relatingtwo
or“garden”;heirloom/keepsakeareobjectsina“museum”
different identities and suggesting learned intersectional
or “collection”; a strategy/idea are found in a “story” or
biases may exist, though overlapping identity associations
“job”.Thepredictionsfollowedtheirsubjecthypernymclus-
were otherwise rarely seen in both models. For both BERT
ters(e.g.,snake/catproducedmostly“physicalentity”pre-
and RoBERTa (Fig. 9), we observed an association between
dictions, strategy/idea produced mostly “abstraction” pre-
“lesbians”, “women”, and “female” and many LGBTQIA+
dictions, while keepsake/heirloom were mixed). Chain of17
Biomedical Knowledge
SciBERT (2019)
A short
 stay in a general children’s hospital is _ to take.
Therapeutic anticoagulation
 is _ for trauma patients
to receive. long
anticoagulation therapy humans It is _ to take a short
 stay in a general children’s hospital.
It is _ for traumapatients
to receivetherapeutic anticoagulation.
 long
humans anticoagulation therapy.
Fig.6.AHeatMapandaSetView showinghowgrammarandphrasingaffectSciBERT.
reasoning prompts produced similar results. BERT showed right, in “pregnancy” being a common predictions across
uniqueandrelevantprerequisites(i.e.fewsharedconnector all prerequisite prompts, and in goal prompts where to do
lines in the Set View) for healthy/sick such as “hungry”, somethingyouneeda“woman”,“mother”,“wife”or“girl”.
“tired”or“pregnant”,happy/sadsuchas“alone”or“here” Interestingly,DistilBERTdoesnotexhibitthesesamebiases,
and right/wrong such as “stubborn”, “smart” or “blind”. despitestrongnoun-basedsubjectpredictions.
Top predictions for goals such as drive and fly are correct
(e.g.,“car”/“map”and“pilot”/“wings”,respectively).Suc-
ceed and fail are opposite (“plan”/“strategy” vs “distrac-
tion”/“reason”), while discover, learn, and create are all
associated with “teachers”, “lessons”, and “partners”. For
DistilBERT(Fig.10),wefoundstrongperformancesimilarto
BERTinmakingassociationsforbelongsandgoals,suchas
similar pair associations between snake/cat, strategy/idea,
dry/fly and discover/learn/create in the Scatter Plot. We
noticedthesekindsofassociationsweremostlynoun-based
and didn’t follow our scheme of separating membership
andchain-of-reasoning.However,DistilBERTfailedtomake
interestingorusefulassociations(i.e.thesharedfiltershows
most rows in both the Heat Map and Set View) for different
causes or prerequisite prompts, which are generally verb-
based associations. We also noticed biases, such as BERT
exhibiting learned associations in both chain of reasoning
prompts with female gender labels. This appeared in nu-
merous associations of “women” being wrong more than18
Identity Stereotypes
BERT (2018)
[subject] is meant to be _. the woman / the daughter
 Many even attribute [subject] for being _.
 Asian Americans / African Americans

the man / the son / the person
 One fundamental moral quality of [subject] is _.
 European Americans / Hispanic and Latino Americans
the transgender / the queer The people of [subject] are often known for _.
Fig.7.TwoSetViewsshowinghowidentitystereotypesareperpetuatedinBERT.19
Identity Stereotypes
RoBERTa (2019)
The people of [subject] are often known for _. Many even attribute [subject] for being _. The people of [subject] are often known for _.
Asian Americans / African Americans
 Christianity / Islam / Hinduism
 Communism / Socialism / Democracy / Liberalism

European Americans / Hispanic and Latino Americans Sikhism / Buddhism / Judaism / Atheism Conservatism / Anarchism / Nationalism / Facism
Fig.8.ASetView andtwoScatterPlotsshowinghowidentitystereotypesareperpetuatedinRoBERTa.
Identity Stereotypes [subject] is known as a _.
the transgender / the queer / the heterosexual / the gay

BERT (2018) and RoBERTa (2019)
the lesbian / the bisexual / the homosexual
[subject] is a great _. the man / the heterosexual / the homosexual
Fig.9.TwoSetViewsandaScatterPlotshowinghowidentitystereotypesareperpetuatedinbothBERTandRoBERTa.20
Knowledge Probing
BERT (2018)
You are likely to find a [subject] in a _. One effect of [subject] is feeling _. You could be [subject] because you are _. If you want to [subject] then you need a _.
snake / cat / keepsake / heirloom
 succeeding / failing / exercising
 happy / sad / right / wrong
 drive / fly / succeed / fail

idea / strategy sleeping / thinking / worrying healthy / sick discover / learn / create
DistilBERT (2019)
You are likely to find a [subject] in a _. One effect of [subject] is feeling _. You could be [subject] because you are _. If you want to [subject] then you need a _.
snake / cat / keepsake / heirloom
 succeeding / failing / exercising
 happy / sad / right / wrong
 drive / fly / succeed / fail

idea / strategy sleeping / thinking / worrying healthy / sick discover / learn / create
Fig.10.EightScatterPlotsshowinghowwellcomplexrelationshipsarelearnedinBERTversusDistilBERT.