Primal Methods for Variational Inequality Problems with
Functional Constraints
Liang Zhang1,2, Niao He1, and Michael Muehlebach2
1Department of Computer Science, ETH Zurich
2Max Planck Institute for Intelligent Systems
{liang.zhang, niao.he}@inf.ethz.ch, michael.muehlebach@tuebingen.mpg.de
Abstract
Constrained variational inequality problems are recognized for their broad applications across
various fields including machine learning and operations research. First-order methods have
emergedasthestandardapproachforsolvingtheseproblemsduetotheirsimplicityandscalability.
However, they typically rely on projection or linear minimization oracles to navigate the feasible
set, which becomes computationally expensive in practical scenarios featuring multiple functional
constraints. Existing efforts to tackle such functional constrained variational inequality problems
have centered on primal-dual algorithms grounded in the Lagrangian function. These algorithms
along with their theoretical analysis often require the existence and prior knowledge of the optimal
Lagrange multipliers. In this work, we propose a simple primal method, termed Constrained
Gradient Method (CGM), for addressing functional constrained variational inequality problems,
without necessitating any information on the optimal Lagrange multipliers. We establish a
non-asymptotic convergence analysis of the algorithm for variational inequality problems with
monotone operators under smooth constraints. Remarkably, our algorithms match the complexity
ofprojection-basedmethodsintermsofoperatorqueriesforbothmonotoneandstronglymonotone
settings,whileutilizingsignificantlycheaperoraclesbasedonquadraticprogramming. Furthermore,
we provide several numerical examples to evaluate the efficacy of our algorithms.
1 Introduction
Variational inequality problems [60, 35, 38] provide a unified framework for modeling optimization and
equilibrium seeking problems and have been extensively studied across various disciplines. Important
examples include minimax optimization in machine learning [19, 17, 37], Nash equilibrium problems
in game theory and economics [45, 46, 44], and frictional contact problems in physics [25, 9, 59].
For an in-depth presentation of the historical development and broader applications of variational
inequality problems, we recommend the comprehensive books by Kinderlehrer and Stampacchia [30],
and Facchinei and Pang [15].
In variational inequality problems, the objective is to find x∗ ∈ C such that
F(x∗)⊤(x∗−x) ≤ 0, ∀x ∈ C. (1)
Here, the constrained set C ⊆ Rd is compact and convex, and the operator F : C → Rd is continuous,
which ensures a nonempty and compact solution set [15]. In this work, we also assume the operator F
to be monotone, a standard assumption in the literature that encompasses important applications
including convex minimization and convex-concave minimax optimization problems [3, 55, 56, 47].
1
4202
raM
91
]CO.htam[
1v95821.3042:viXraThere has been a growing interest in the development of first-order methods for solving monotone
variational inequality problems, e.g., extragradient [32, 62, 47, 7] and optimistic gradient methods
[54, 41, 40, 20]. These methods, noted for their simplicity and scalability, involve querying the
operator F at specific points and accessing a projection oracle or a linear minimization oracle [24, 16]
for the feasible set C. Such oracles are easy to compute for simple feasible sets such as Euclidean
balls for the projection oracle or polytopes for the linear minimization oracle. However, for general
constrained sets, computing the projection or linear minimization oracle requires solving constrained
optimization problems over the feasible set C. The latter remains challenging even with quadratic or
linear objectives.
In this work, we focus on the general functional constrained setting, where the feasible set C is
described by m convex inequality constraints, that is,
C = {x ∈ Rd|g (x) ≤ 0, ∀1 ≤ i ≤ m}. (2)
i
Note that the feasible set C does not necessarily allow for projection or linear minimization oracles.
This encompasses important applications in machine learning including reinforcement learning with
safety constraints [64], constrained Markov potential games [2, 27], generalized Nash equilibrium
problems with jointly-convex constraints [14, 26], and learning with fairness constraints [67, 36].
Previous works have predominantly focused on primal-dual algorithms based on the (augmented)
Lagrangian function to handle the constraints. These algorithms and their convergence guarantees
crucially depend on information about the optimal Lagrange multipliers. Yang et al. [66] proposed an
ADMM-based interior point method, later refined by Chavdarova et al. [8], and they assumed that
either F is strictly monotone or one of g (x) is strictly convex to ensure the existence of the central
i
path and boudedness of the optimal Lagrange multiplier. Boob and Deng [5] extended the constraint
extrapolation method [6] for constrained minimization problems to functional constrained variational
inequality problems. Their guarantees rely on the existence and boundedness of the optimal Lagrange
multipliers. Meanwhile, the magnitude of the multipliers is essential to determine the stepsize and
affects the convergence rate.
Primal methods serve as an alternative approach to avoid such explicit dependence on the optimal
Lagrange multipliers. They are also simpler to analyze and more straightforward to implement in
practice. In fact, primal first-order methods have been extensively studied for functional constrained
minimization problems. Prominent examples include Polyak’s switching gradient method [52, 33, 22],
cutting-plane methods [29], the level bundle method [34], and the constrained gradient descent method
[42] motivated from nonsmooth dynamical systems, to just name a few. However, primal methods
have been much less explored for functional constrained variational inequality problems.
Our contributions. In this work, we propose a primal method, termed constrained gradient
method (CGM; see Algorithm 1), for solving functional constrained variational inequality problems.
Our algorithm takes inspiration from the constrained gradient descent method [42] and extends its
principles to tackle the more challenging variational inequality problems. Unlike traditional projection-
based methods that project each iterate onto the feasible set to handle constraints, CGM instead
projects the update direction (velocity) onto a local, sparse, and linear approximation of the feasible
set. The latter only requires solving a simple quadratic program with linear constraints.
We establish the global convergence analysis of CGM under two settings: (i) when the operator
F is monotone, and (ii) when F is strongly-monotone. Notably, in both settings, CGM enjoys
(nearly) the same complexity on querying the operator F as the optimal complexity achieved by
projection-based methods, even though the projection oracle is replaced by quadratic programming
solvers. For example, when the operator F(x) is monotone, we show that CGM achieves an ϵ-solution
with O(1/ϵ2) queries to F(x) and O(1/ϵ2) calls to a quadratic programming solver. To the best of our
2knowledge, our algorithm is the first primal method that achieves the optimal complexity on queries
to F for functional constrained monotone variational inequality problems without dependence on the
optimal Lagrange multipliers.
We further illustrate that the quadratic programming at each iteration of CGM allows for efficient
implementation and permits even closed-form solutions in special cases such as simplex constraints
(Algorithm 4) or when there is only one (nonlinear) constraint function (Algorithm 2). This yields a
directimplementationofouralgorithmcomparabletounconstrainedmethods. Empirically,weevaluate
the convergence of CGM through several numerical experiments and demonstrate its effectiveness.
Organization of the paper. Our paper is organized as follows. The notation and background
related to our main results are summarized in Section 2. In Section 3, we present CGM and provide
its convergence analysis for both monotone and strongly-monotone settings in Section 4. In Section 5,
we discuss different ways to solve the quadratic programs in CGM and give several examples where
CGM admits closed-form and direct updates. Numerical results are provided in Section 6. Section 7
concludes the paper and discusses possible future directions.
2 Preliminaries
We rely on the following notation throughout the article. The Euclidean norm is denoted by ∥·∥,
and we use [m] to denote the set {1,2,··· ,m}. An operator F : C → Rd defined on a convex set
C ⊆ Rd is µ–strongly-monotone if ∀x,y ∈ C, (F(x)−F(y))⊤(x−y) ≥ µ∥x−y∥2 with µ > 0 and
monotone if µ = 0. The operator F is ℓ-Lipschitz if ∥F(x)−F(y)∥ ≤ ℓ∥x−y∥, ∀x,y ∈ C. A function
g : X → R defined on a convex set X ⊆ Rd is convex if g(αx+(1−α)y) ≤ αg(x)+(1−α)g(y),
∀α ∈ [0,1],∀x,y ∈ X. The function g(x) is L-Lipschitz if ∀x,y ∈ X, |g(x) − g(y)| ≤ L∥x − y∥,
and equivalently ∥∇g(x)∥ ≤ L,∀x ∈ X if it is differentiable. The function g(x) is ℓ-smooth if it is
differentiable and ∀x,y ∈ X, ∥∇g(x)−∇g(y)∥ ≤ ℓ∥x−y∥.
2.1 Variational Inequality Problems
In our paper, we assume that C is contained in an Euclidean ball with diameter D. This suggests that
the feasible set C is convex and compact. By Corollary 2.2.5 in Facchinei and Pang [15], the solution
set of the variational inequality problem (1) is nonempty and compact. We are interested in finding
the following ϵ-approximate solution of the constrained variational inequality problem (1).
Definition 1. For some ϵ > 0, we call a point xˆ ∈ Rd an ϵ-solution of the variational inequality
problem (1), where the feasible set is of the form (2), if F(x)⊤(xˆ−x) ≤ ϵ, ∀x ∈ C and g (xˆ) ≤ ϵ,
i
∀i ∈ [m].
The above definition is often referred to as the weak ϵ-solution of a variational inequality problem
and is commonly adopted in the related literature [47, 48, 28, 5]. A strong ϵ-solution, xˆ ∈ C, is
characterized by F(xˆ)⊤(xˆ−x) ≤ ϵ, ∀x ∈ C. When ϵ = 0 and F is monotone and continuous, the two
solution sets are equivalent [39, 30]. When ϵ > 0 and F is monotone, every strong ϵ-solution is also a
weak ϵ-solution.
2.2 Constrained Gradient Descent
Ourmainalgorithmdrawsinspirationfromtheconstrainedgradientdescent(CGD)method,introduced
in Muehlebach and Jordan [42] for solving minimization problems min f(x) over the feasible set C.
x∈C
Motivated by analogies to non-smooth mechanics, the algorithm possesses the following distinctive
3feature. Unlike projection-based methods that project each iterate onto the feasible set, CGD projects
the update direction (velocity) onto a local and sparse velocity polytope
V (x) = {v ∈ Rd|αg (x)+∇g (x)⊤v ≤ 0, ∀i ∈ I },
α i i x
where I = {i ∈ [m]|g (x) ≥ 0} is the set of active constraints and α > 0 controls the tradeoff between
x i
optimizing the objective and feasibility. At each iteration, CGD takes the update
1
v = argmin ∥v+∇f(x )∥2,
t t
2
v∈Vα(xt)
x = x +ηv .
t+1 t t
The development of its theoretical understanding centers around the continuous-time case for con-
strained gradient flow [42], with extensions to accelerated methods [43] and online, stochastic, and
nonconvex minimization settings [31, 57, 58]. Recently, convergence guarantees of the discrete-time
algorithm are established for smooth strongly-convex minimization problems in Muehlebach and
Jordan [42] and nonsmooth convex minimization problems in Kolev et al. [31].
3 The Constrained Gradient Method (CGM)
A standard algorithm in the literature on constrained monotone variational inequality problems is the
projected gradient method, which requires access to a projection oracle and performs the following
updates at each iteration t = 0,1,...,T −1:
1
x = argmin ∥x−(x −ηF(x ))∥2,
t+1 t t
2
x∈C
where η > 0 is the stepsize. The projection step onto the feasible set involves solving a constrained
optimization problem. When the feasible set C does not have a simple structure, the above procedure
is not always efficient and implementable.
Instead, we propose the constrained gradient method (CGM; see Algorithm 1) that takes insights
from Muehlebach and Jordan [42] to alternatively project the velocity (search direction −F(x ))
t
onto a local, sparse, and linear approximation of the feasible set. Algorithm 1 requires solving a
sequence of quadratic programs, which can be easily implemented and is more efficient compared to
the evaluation of projection oracles with general (nonlinear) constraints. Here, the velocity polytope
V (x ) only involves active constraints, i.e., constraints that are not strictly satisfied, and thus the
α t
quadratic program is sparse and efficiently solvable even for large scale problems if the number of
active constraints is small. Since V (x ) can be understood as an extension of the tangent cone
α t
to infeasible points, our algorithm shares similarities with the method of feasible directions [51, 4]
that linearize the constraint functions and use linear or quadratic programming to identify update
directions that ensure feasibility of the iterates. In contrast, CGM only involves active constraints
and allows iterates to be infeasible.
In Algorithm 1, we allow for an inexact solution of the quadratic program, where the stopping
criteria can be satisfied using various methods. More details on how this quadratic program can be
solved are discussed in Section 5. The auxiliary constraint g (x) = ∥x∥2 −D2 is used to ensure
m+1
that both the iterate x and the projected velocity v are bounded. It is added specifically to simplify
t t
the theoretical analysis and will not be used in actual implementations.
4Algorithm 1 Constrained Gradient Method (CGM)
Input: Initialization x ∈ C, stepsize {η }T−1 > 0, parameter α > 0, precision ϵ > 0.
0 t t=0
1: for t = 0,1,··· ,T −1 do
2: Build the set of active constraints with the auxiliary constraint g m+1(x) = ∥x∥2−D2,
I = {i ∈ [m+1]|g (x ) ≥ 0}.
xt i t
3: Construct the velocity polytope
V (x ) = {v ∈ Rd|αg (x )+∇g (x )⊤v ≤ 0, ∀i ∈ I }.
α t i t i t xt
4: Solve the quadratic program
1
v ≈ argmin ∥v+F(x )∥2,
t t
2
v∈Vα(xt)
such that v ∈ V (x ) and
t α t
ϵ
(v +F(x ))⊤(v −v) ≤ , ∀v ∈ V (x ).
t t t α t
2
5: Update the parameter
x = x +η v .
t+1 t t t
6: end for
Output: x¯ :=
(1/T)(cid:80)T−1x
(monotone) or x¯ := (2/T(T
−1))(cid:80)T−1tx
(strongly-monotone).
T t=0 t T t=0 t
4 Convergence Analysis
In this section, we provide a convergence analysis of Algorithm 1 for two settings: (i) when operator
F is monotone, and (ii) when operator F is strongly-monotone. We also discuss improved results for
a special instance with functional constrained convex minimization problems.
4.1 The Monotone Setting
We first consider the constrained monotone variational inequality problems (1) and make the following
two standard assumptions on the operator F and the feasible set C.
Assumption 1. The operator F(x) is continuous and monotone on Rd. Moreover, its norm is upper
bounded by L , i.e., ∥F(x)∥ ≤ L , ∀x ∈ Rd.
F F
Assumption 2. Each constraint function g (x) is convex, L -Lipschitz and ℓ -smooth on Rd for
i g g
each i ∈ [m]. The feasible set C is non-empty and contained in an Euclidean ball with radius D, i.e.,
∥x∥ ≤ D, ∀x ∈ C.
Assumption 1 is standard in the analysis of monotone variational inequality problems [47, 28].
Assumption 2 ensures that the feasible set is convex and compact, which guarantees a nonempty and
compact solution set [15]. The smoothness and Lipschitzness assumptions on the constraint functions
are also frequently used in previous works on functional constrained problems [33, 6, 5]. Note that
both assumptions on F(x) and g (x) are made on the entire domain Rd, as opposed to the usual case
i
for projection-based methods where the properties only hold on the feasible set C. This is due to the
5fact that the trajectory of our methods is not guaranteed to be always feasible. However, as we explain
in Lemma 1, the iterates of our algorithms remain in an Euclidean ball with a radius depending on D
and L . A proof is provided in Appendix A. As a result, all properties in Assumptions 1 and 2 can
F
be relaxed to only hold on this ball. We keep the current statement for simplicity of the results.
Lemma 1. Let γ > 1. Under Assumptions 1 and 2, Algorithm 1 with ϵ ≤ 4L2 and the choice of
F
α > 0 such that αη ≤ (γ −1)/(γ +1),∀t = 0,1,··· ,T −1 satisfies ∀t = 0,1,··· ,T −1,
t
(cid:18)
4L
(cid:19)2
∥x ∥2 ≤ γD2+γ(γ −1) D+ F ,
t
α
(cid:18)
4L
(cid:19)2
∥v ∥2 ≤ (γ +1)α2D2+γ(γ +1)α2 D+ F .
t
α
Note that in Algorithm 1, we require the initial point to be feasible, namely, x ∈ C. However,
0
according to Lemma 1, this requirement can be relaxed to ∥x ∥2 ≤ γD2 +γ(γ −1)(D+4L /α)2,
0 F
indicatingthatx isallowedtobeinfeasible. Wekeepthecurrentstatementtosimplifythepresentation.
0
With the fact that ∥v ∥ is bounded, we can use standard techniques for the convergence analysis of
t
CGM, as summarized in Theorem 1.
Theorem 1. Under Assumptions 1 and 2, for ϵ ≤ 4L2, Algorithm 1 with stepsize η ≡ η =
√ F t
D/(5L 2T) and α = L /D satisfies
F F
√
10 2L D ϵ
F(x)⊤(x¯ −x) ≤ √ F + , ∀x ∈ C.
T
T 2
For the constraint violation, we have that for each i ∈ [m+1] and t = 0,1,··· ,T −1,
√
2Dmax{L ,5ℓ D}
g g
g (x ) ≤ √ .
i t
T
Proof. We first show the optimality guarantees. For each i ∈ I such that g (x ) ≥ 0 is active, we
xt i t
conclude that ∀x ∈ C,
g (x )+∇g (x )⊤(x−x ) ≤ g (x)
i t i t t i
≤ 0
≤ g (x ),
i t
where we have used the assumption that g (x) is convex. This gives us ∇g (x )⊤(x−x ) ≤ 0,∀x ∈ C.
i i t t
By the definition of V (x ) = {v ∈ Rd|αg (x )+∇g (x )⊤v ≤ 0,∀i ∈ I }, we obtain that
α t i t i t xt
(v+x−x ) ∈ V (x ), ∀x ∈ C, ∀v ∈ V (x ).
t α t α t
The quadratic programming solver guarantees that v ∈ V (x ) and (v +F(x ))⊤(v −v) ≤ ϵ/2,∀v ∈
t α t t t t
V (x ). For any x ∈ C, we set v = v +x−x ∈ V (x ) and get that
α t t t α t
ϵ
F(x )⊤(x −x) ≤ v⊤(x−x )+
t t t t 2
1 ϵ
= (x −x )⊤(x−x )+
t+1 t t
η 2
t
(3)
1 1 1 ϵ
= ∥x−x ∥2− ∥x−x ∥2+ ∥x −x ∥2+
t t+1 t+1 t
2η 2η 2η 2
t t t
1 1 η ϵ
= ∥x−x ∥2− ∥x−x ∥2+ t ∥v ∥2+ .
t t+1 t
2η 2η 2 2
t t
6√ √
We invoke Lemma 1 with γ = 3/2 and ϵ ≤ 4L2, and set η = η = D/(5 2L T) and α = L /D
√ F t F F
such that αη = 1/(5 2T) < 1/5. This yields
t
5 15
(cid:18)
4L
(cid:19)2
∥v ∥2 ≤ α2D2+ α2 D+ F
t
2 4 α
< 100L2.
F
Summing up from t = 0 to T −1 and dividing both sides by T, we obtain that ∀x ∈ C,
1 T (cid:88)−1
F(x )⊤(x −x) ≤
∥x−x 0∥2
+50ηL2 +
ϵ
T t t 2ηT F 2
t=0
√
10 2L D ϵ
≤ √ F + .
T 2
When F(x) is monotone, it holds that (F(x )−F(x))⊤(x −x) ≥ 0, and we have ∀x ∈ C,
t t
T−1
1 (cid:88)
F(x)⊤(x¯ −x) = F(x)⊤(x −x)
T t
T
t=0
T−1
1 (cid:88)
≤ F(x )⊤(x −x)
t t
T
t=0
√
10 2L D ϵ
≤ √ F + .
T 2
We now show the feasibility guarantees using induction. The base case is true since x ∈ C
0
and then g (x ) ≤ 0 for each i ∈ [m+1]. Assuming the claim holds for some k ≥ 0, i.e., g (x ) ≤
√ i 0 √ i k
2Dmax{L ,5ℓ D}/ T,∀i ∈ [m+1], we now show the same is true for k +1. We consider the
g g
following two cases.
(a) For each i ∈/ I , we know g (x ) < 0. Applying Lemma 1, by convexity and Lipschitz
x k i k
continuity of g (x), we have
i
g (x ) ≤ g (x )+∇g (x )⊤(x −x )
i k+1 i k i k+1 k+1 k
< η∇g (x )⊤v
i k+1 k
≤ 10ηL L (4)
g F
√
2L D
g
= √ .
T
(b) For all i ∈ I , we know g (x ) ≥ 0 and ηαg (x ) + ∇g (x )⊤(x − x ) ≤ 0 from the
x k i k i k i k k+1 k
construction of V (x ). By ℓ -smoothness of g (x), we have that
α k g i
ℓ
g (x ) ≤ g (x )+∇g (x )⊤(x −x )+ g ∥x −x ∥2
i k+1 i k i k k+1 k k+1 k
2
≤ (1−αη)g (x )+50ℓ η2L2
i k g F
√
2Dmax{L ,5ℓ D} ℓ D2 Dmax{L ,5ℓ D} (5)
g g g g g
≤ √ + −
T T 5T
√
2Dmax{L ,5ℓ D}
g g
≤ √ .
T
For both cases, we are able to show that the claim is true for k+1. As a result, the theorem holds
true for every t, which completes the proof.
7The above theorem implies that for CGM to achieve an ϵ-solution, the number of queries to the
operator F(x) is at most O(1/ϵ2), and the number of calls to a quadratic programming solver is at
most O(1/ϵ2). Notably, the complexity of querying the operator F matches that of projection-based
methods [49] or Frank-Wolfe type methods [61], known to be optimal even for simple constraint sets
according to the lower complexity bound (Theorem 3.2.1 in Nesterov [49]).
Instarkcontrast,theconvergenceratesofpreviousprimal-dualmethodsexhibitexplicitdependence
on the optimal Lagrange multipliers. For instance, the ADMM-based interior point method [66, 8]
achieves strong ϵ-solutions with the same O(1/ϵ2) queries to F and requires O(1/ϵ2) calls to a program
that solves a sequence of strongly-convex minimization problems. However, their results require
the strong assumption that either F is strictly-monotone or one of the g (x) is strictly-convex. The
i
constraint extrapolation (ConEx) method [5, 6] achieves an ϵ-solution as in Definition 1 with O(1/ϵ2)
calls to the operator F. However, they also require the existence and boundedness of the optimal
Lagrange multipliers, whose magnitude explicitly appears in the convergence upper bounds for both
optimality and feasibility gaps. To the best of our knowledge, CGM is the first primal method that
achieves the optimal complexity on queries to F for functional constrained monotone variational
inequality problems without dependence on the optimal Lagrange multipliers.
4.2 The Strongly-Monotone Setting
Next, we extend the convergence analysis of CGM (Algorithm 1) to the strongly-monotone setting, as
stated in the theorem below.
Theorem 2. Let γ > 1 and let F(x) be µ–strongly-monotone on Rd. Under Assumptions 1 and 2,
Algorithm 1 with T ≥ 2, ϵ ≤ 4L2, stepsize η = 1/µ(t+1), and α = µ(γ −1)/(γ +1) satisfies
F t
µM2 ϵ
F(x)⊤(x¯ −x) ≤ + , ∀x ∈ C,
T
T −1 2
where M := 2(γ +1)(D+2L /µ). For the constraint violation, we have ∀i ∈ [m+1],
F
max{12ML ,6ℓ M2}+6ℓ M2ζ(1+2/(γ +1))
g g g
g (x¯ ) ≤ ,
i T
(T +1)1−2/(γ+1)
where ζ(p) := (cid:80)∞ 1/np is the Riemann zeta function for p > 1.
n=1
Proof. By applying the same reasoning as in (3), see the proof of Theorem 1, we have that ∀x ∈ C,
1 1 η ϵ
F(x )⊤(x −x) ≤ ∥x−x ∥2− ∥x−x ∥2+ t ∥v ∥2+ .
t t t t+1 t
2η 2η 2 2
t t
When F(x) is µ-strongly-monotone, i.e., (F(x )−F(x))⊤(x −x) ≥ µ∥x −x∥2, we obtain that ∀x ∈ C,
t t t
F(x)⊤(x −x) ≤ F(x )⊤(x −x)−µ∥x −x∥2
t t t t
(cid:18) 1 (cid:19) 1 η ϵ (6)
≤ −µ ∥x−x ∥2− ∥x−x ∥2+ t ∥v ∥2+ .
t t+1 t
2η 2η 2 2
t t
We set η = 1/(µ(t + 1)) and α = µ(γ − 1)/(γ + 1) such that αη ≤ (γ − 1)/(γ + 1) for every
t t
t = 0,1··· ,T −1 and constant γ > 1. By Lemma 1, we know that
(cid:20) (cid:21)
1 (cid:16) (cid:17)2
∥v ∥2 ≤ (γ −1)2µ2D2+γ (γ −1)µD+4(γ +1)L
t F
γ +1
< 4(γ +1)2(µD+2L )2
F
:= µ2M2,
8where we let M = 2(γ +1)(D+2L /µ) for simiplicity of the notation. Inserting the value of η and
F t
∥v ∥2 ≤ µ2M2, (6) becomes ∀x ∈ C,
t
µ(t−1) µ(t+1) µM2 ϵ
F(x)⊤(x −x) ≤ ∥x−x ∥2− ∥x−x ∥2+ + .
t t t+1
2 2 2(t+1) 2
By multiplying both sides by t ≥ 0, we obtain
µ(t−1)t µt(t+1) µM2 tϵ
tF(x)⊤(x −x) ≤ ∥x−x ∥2− ∥x−x ∥2+ + .
t t t+1
2 2 2 2
We recall that x¯ =
(cid:80)T−1tx /((cid:80)T−1t).
Summing up from t = 0 to T −1 and dividing both sides
T t=0 t t=0
by
(cid:80)T−1t,
we then have that ∀x ∈ C,
t=0
T−1
2 (cid:88)
F(x)⊤(x¯ −x) = tF(x)⊤(x −x)
T t
T(T −1)
t=0
2 T (cid:88)−1 µM2 2 T (cid:88)−1 tϵ
≤ +
T(T −1) 2 T(T −1) 2
t=0 t=0
4(γ +1)2µ(D+2L /µ)2 ϵ
F
≤ + .
T −1 2
We proceed by showing the feasibility guarantees. For t = 0, we have that g (x ) ≤ 0 for each
i 0
i ∈ [m+1] since x ∈ C. For iteration t+1 with t ≥ 0, we consider the following cases.
0
(a) When i ∈/ I , we know g (x ) < 0. Applying the same argument as (4), we have
xt i t
g (x ) < η ∇g (x )⊤v
i t+1 t i t+1 t
ML (7)
g
≤ .
t+1
(b) When i ∈ I , we know g (x ) ≥ 0 and η αg (x )+∇g (x )⊤(x −x ) ≤ 0. By a similar
xt i t t i t i t t+1 t
argument to (5), we have that
ℓ
g (x ) ≤ (1−αη )g (x )+ g η2µ2M2
i t+1 t i t 2 t
(cid:18) (cid:19) (8)
c c
γ M
= 1− g (x )+ ,
t+1 i t (t+1)2
where we let c = (γ −1)/(γ +1) and c = ℓ M2/2 for simplicity. Note that 0 < c < 1 when γ > 1
γ M g γ
and c approaches 1 in the limit γ → ∞. By Lemma 4 in Chapter 2 of Polyak [53], it is only possible
γ
to show that g i(x t) = O(1/tcγ), a rate slower than O(1/t) unless γ → ∞. We then formally obtain
the guarantee on g i(x t+1). Multiplying (t+2)cγ on both sides of (8), we have that
(t+2)cγg (x ) ≤
(cid:18)
1−
c
γ
(cid:19)
(t+2)cγg (x )+
c M(t+2)cγ
i t+1 t+1 i t (t+1)2
(cid:18)
c
(cid:19)(cid:18)
1
(cid:19)cγ
c
(cid:18)
1
(cid:19)cγ
= 1− γ 1+ (t+1)cγg (x )+ M 1+
t+1 t+1 i t (t+1)2−cγ t+1
(cid:18) (cid:19)(cid:18) (cid:19) (cid:18) (cid:19)
c c c c
≤ 1− γ 1+ γ (t+1)cγg (x )+ M 1+ γ
t+1 t+1 i t (t+1)2−cγ t+1
2c
≤ (t+1)cγg (x )+ M , (9)
i t (t+1)2−cγ
9whereweuseg i(x t) ≥ 0andthemeanvaluetheoremforthefunctionxcγ ontheinterval(1,1+1/(t+1))
such that (1+1/(t+1))cγ ≤ 1+c γ/(t+1) since 0 < c
γ
< 1. Let κ(t) = max{0 ≤ s < t|g i(x s) ≤ 0},
i.e., the last iterate that is feasible for constraint i. Note that κ(t) ≥ 0 must exist for every t ≥ 1
given that g (x ) ≤ 0. Solving the recursion in (9), we have that
i 0
t
(t+2)cγg (x ) ≤ (κ(t+1)+2)cγg (x )+ (cid:88) 2c M
i t+1 i κ(t+1)+1 (s+1)2−cγ
s=κ(t+1)+1
∞
≤ (κ(t+1)+2)cγg (x )+(cid:88) 2c M
i κ(t+1)+1 n2−cγ
n=1
= (κ(t+1)+2)cγg (x )+2c ζ(2−c ),
i κ(t+1)+1 M γ
where we let (cid:80)t = 0 if κ(t+1) = t. The series (cid:80)∞ 1/n2−cγ converges and is finite since
κ(t+1)+1 n=1
2−c > 1, and ζ(p) = (cid:80)∞ 1/np is the Riemann zeta function. Since g (x ) ≤ 0, applying either
γ n=1 i κ(t+1)
(7) for the strictly feasible case or (8) otherwise, we conclude
(κ(t+1)+2)cγg (x )
i κ(t+1)+1
(cid:26) (cid:27)
ML c
≤ (κ(t+1)+2)cγ max g , M
κ(t+1)+1 (κ(t+1)+1)2
(cid:18)
1
(cid:19)cγ (cid:26)
ML c
(cid:27)
g M
= 1+ max ,
κ(t+1)+1 (κ(t+1)+1)1−cγ (κ(t+1)+1)2−cγ
(cid:26) (cid:27)
ML c
g M
≤ 2max ,
(κ(t+1)+1)1−cγ (κ(t+1)+1)2−cγ
≤ 2max{ML ,c }.
g M
This implies that
2max{ML ,c }+2c ζ(2−c )
g M M γ
g (x ) ≤ ,
i t+1 (t+2)cγ
which is also a valid upper bound of (7) since c < 1.
γ
Given the upper bound on each g (x ), by convexity of g (x), we further have that
i t i
T−1
2 (cid:88)
g (x¯ ) ≤ tg (x )
i T i t
T(T −1)
t=1
T−1
4max{ML g,c M}+4c M ζ(2−c γ) (cid:88) t
≤
T(T −1) (t+1)cγ
t=1
T
≤ 4max{ML g,c M}+4c M ζ(2−c γ) (cid:88) t1−cγ
T(T −1)
t=1
4max{ML ,c }+4c ζ(2−c )
(cid:18)
T
+1(cid:19)1−cγ
g M M γ
≤
(T −1) 2
12max{ML ,c }+12c ζ(2−c )
g M M γ
≤ ,
(T +1)cγ
where we use T ≥ 2 and Jensen’s inequality on the concave function x1−cγ.
10In the strongly-monotone setting, the convergence rate of CGM in terms of the optimality gap is
O(1/T), which matches the rate of projection-based methods [49]. However, it is worth noting that
the rate in terms of the constraint violation approaches O(1/T) only as γ grows large enough. We
leave the task of closing this gap to future work. As a comparison, the primal-dual method in Yang
√
et al. [66] achieves O(1/ T) rate measured by the distance ∥x¯ −x∗∥ and does not provide explicit
T √
feasibility guarantees. If the operator is additionally Lipschitz, the same O(1/ T) rate is attained for
a strong approximate solution.
4.3 The Special Case with Convex Minimization
Inthefollowing, weprovideaspecialinstanceofthestrongly-monotonevariationalinequalityproblems
such that an O(1/T) convergence rate on both the optimality gap and constraint violations can
be attained through a different strategy of setting the stepsizes. To be specific, we consider the
strongly-convex and smooth minimization problem with functional constraints, that is,
min f(x),
x∈Rd
s.t. g (x) ≤ 0, ∀i ∈ [m].
i
This is equivalent to the variational inequality problem associated with the operator F(x) := ∇f(x)
and the feasible set C = {x ∈ Rd|g (x) ≤ 0,∀i ∈ [m]}. The guarantees of CGM in this setting are as
i
follows.
Theorem 3. Suppose f(x) is µ-strongly-convex, ℓ -smooth, and L -Lipschitz, and g (x) is convex,
f f i
ℓ -smooth, and L -Lipschitz for each i ∈ [m] such that the feasible set C is contained in an Euclidean
g g
ball of radius D. Let T be large enough such that T ≥ max{3,κ }(logT), where κ := ℓ /µ denotes
f f f
the condition number. Then CGM with stepsize η = (logT)/(µT) and α = µ satisfies
f(x )−f(x∗)
f(x )−f(x∗) ≤ 0 ,
T
T
where x∗ = argmin f(x). For the constraint violation, we have that for every iteration t and for
x∈C
each i ∈ [m+1],
M max{2L ,ℓ M}logT
g g
g (x ) ≤ ,
i t
2T
where M := 3(D+4L /µ).
f
Proof. We first show the guarantees on the objective function. For the velocity polytope V (x ), we
α t
have that ∀x ∈ C such that g (x) ≤ 0,
i
αg (x )+α∇g (x )⊤(x−x ) ≤ αg (x) ≤ 0,
i t i t t i
since each g (x) is convex and α > 0. This suggests that α(x−x ) ∈ V (x ) for any x ∈ C. By the
i t α t
computationofv ,wethenhavethat∥v +∇f(x )∥2 ≤ ∥α(x∗−x )+∇f(x )∥2 forx∗ = argmin f(x).
t t t t t x∈C
11Using smoothness of f(x), we conclude
ℓ
f(x ) ≤ f(x )+∇f(x )⊤(x −x )+ f ∥x −x ∥2
t+1 t t t+1 t t+1 t
2
ℓ
= f(x )+η∇f(x )⊤v + f η2∥v ∥2
t t t t
2
η η η
= f(x )+ ∥v +∇f(x )∥2− ∥∇f(x )∥2− (1−ηℓ )∥v ∥2
t t t t f t
2 2 2
η η η
≤ f(x )+ ∥α(x∗−x )+∇f(x )∥2− ∥∇f(x )∥2− (1−ηℓ )∥v ∥2
t t t t f t
2 2 2
η η
= f(x )+ α2∥x∗−x ∥2+αη∇f(x )⊤(x∗−x )− (1−ηℓ )∥v ∥2
t t t t f t
2 2
ηα η
≤ f(x )−αη(f(x )−f(x∗))+ (α−µ)∥x∗−x ∥2− (1−ηℓ )∥v ∥2,
t t t f t
2 2
where we use the assumption that f(x) is µ-strongly-convex. When setting α ≤ µ, we obtain
η
f(x )−f(x∗) ≤ (1−αη)(f(x )−f(x∗))− (1−ηℓ )∥v ∥2.
t+1 t f t
2
When η ≤ 1/ℓ , we have that 1−ηℓ ≥ 0 and 0 < αη ≤ µ/ℓ ≤ 1, and thus
f f f
f(x )−f(x∗) ≤ (1−αη)T(f(x )−f(x∗))
T 0
≤ exp(−αηT)(f(x )−f(x∗))
0
f(x )−f(x∗)
0
= ,
T
if η = (logT)/(µT) and α = µ.
We then show the guarantees on the constraint violations by induction. Applying Lemma 1 with
γ = 2, η = (logT)/(µT) and α = µ, this gives that for every t, ∥v ∥2 ≤ 3µ2D2+6µ2(D+4L /µ)2 ≤
t f
µ2M2. The base case is true since x ∈ C. Assuming the claim holds for some k ≥ 0, we prove that
0
the same is true for k+1. For each i ∈/ I , applying the same analysis as (4), we have that
x
k
g (x ) ≤ η∇g (x )⊤v
i k+1 i k+1 k
L M logT
g
≤ .
T
For each i ∈ I , we apply the same argument as in (5), which yields
xt
ℓ
g (x ) ≤ (1−αη)g (x )+ g η2∥v ∥2
i k+1 i k k
2
M max{2L ,ℓ M}logT ℓ M2(logT)2 M max{2L ,ℓ M}(logT)2
g g g g g
≤ + −
2T 2T2 2T2
M max{2L ,ℓ M}logT
g g
≤ .
2T
For both cases, we show that the claim holds for k +1, which completes the proof. Note that we
also assume that T is large enough such that T ≥ max{κ ,3}(logT) to ensure that η ≤ 1/ℓ and
f f
αη ≤ 1/3 as required in the convergence analysis.
We point out that the original analysis of CGM for strongly-convex and smooth minimization
problems in Muehlebach and Jordan [42] achieves O(1/T) rate on the distance min ∥x −x∗∥2.
0≤t≤T t
However, they require the stepsize η ≤ 2/(ℓ∗ + µ), where ℓ∗ is the smoothness parameter of the
Lagrangian function f(x)+(cid:80) λ∗g (x) and has explicit dependence on the optimal multipliers
i∈[m] i i
λ∗. Instead, we provide an improved analysis in Theorem 3 where no prior knowledge on the optimal
i
Lagrange multipliers is required.
125 Solving the Quadratic Program in CGM
This section summarizes different approaches to solving the quadratic program in CGM (Algorithm
1), which determines the update direction. Notably, there are important examples where the solutions
to the quadratic program can be derived in closed form, including the case involving only one
constraint function and simplex constraints. Additional examples, including nonconvex constraints
and constraints arising in optimal transport, can be found in Ibrahim et al. [23] and Schechtman
et al. [58]. The availability of closed-form solutions to the quadratic programs in CGM enables direct
implementations that are as computationally efficient as unconstrained gradient methods.
5.1 Single Constraint Function
Let us consider the variational inequality problems (1) where the feasible set is described by a single
constraint function g(x):
C = {x ∈ Rd|g(x) ≤ 0}.
The quadratic program in CGM reduces to a single linear constraint when g(x) is active, and closed-
form solutions can be achieved by solving the KKT system (details omitted). The resulting algorithm
is summarized in Algorithm 2.
Algorithm 2 Constrained Gradient Method with One Constraint
Input: Initialization x , stepsize η > 0, parameter α > 0.
0
1: for t = 0,1,··· ,T −1 do
2: if g(x t) ≥ 0 and αg(x t)−∇g(x t)⊤F(x t) ≥ 0 then
3: λ = ∥∇g(x t)∥−2(αg(x t)−∇g(x t)⊤F(x t)).
4: else
5: λ = 0.
6: end if
7: x t+1 = x t−ηF(x t)−ηλ∇g(x t).
8: end for
Output: x¯ =
(1/T)(cid:80)T−1x
.
T t=0 t
Algorithm 2 has direct update steps that are easy to implement. Interestingly, it coincides with
the dynamical barrier approach proposed separately by Gong et al. [18] for constrained minimization
problems.
5.2 The Simplex Constraints
Although the simplex involves multiple constraints, the quadratic program in CGM has closed-form
solutions. This allows CGM to perform direct update steps that can be computed in at most O(dlogd)
steps. As detailed in Appendix B, given an index set N ⊆ [d] and a vector q ∈ Rd, the problem
reduces to solving the quadratic program
d
1 (cid:88)
min ∥p−q∥2, s.t. p = 1, p ≥ 0,∀i ∈ N,
i i
p∈Rd 2
i=1
where p denotes the i-th coordinate of p. This is similar to the projection problem onto the simplex,
i
but we only restrict the coordinates in the set N to be non-negative. In Appendix B, we develop a
method proj (q,N), summarized in Algorithm 3, analogous to the projection oracle onto the simplex
v
[13] for solving the above problem.
13Algorithm 3 Velocity Projection Oracle (proj )
v
Input: Vector q ∈ Rd, index set N ⊆ [d] with size 0 ≤ n ≤ d.
1: Compute s N¯ =
(cid:80)d
i=1,i∈/N q i.
2: Sort {q i|i ∈ N} into r 1 ≥ r 2 ≥ ··· ≥ r n.
3: Construct the set J = (cid:8) 1 ≤ j ≤ n(cid:12) (cid:12)r j + d−n1 +j(cid:0) 1−s N¯ −(cid:80)j i=1r i(cid:1) > 0(cid:9) .
4: if J = ∅ then
5: λ = d−1 n(1−s N¯).
6: else
7: Let ρ = maxJ.
8: λ = d−n1 +ρ (1−s N¯ −(cid:80)ρ i=1r i).
9: end if
10: if i ∈ N then
11: p i = max{0,q i+λ}.
12: else
13: p i = q i+λ.
14: end if
Output: p.
The resulting algorithm implementing CGM is provided in Algorithm 4, where x denotes the
t,i
i-th coordinate of the iterate x . Compared to the projection-based methods that require sorting a
t
vector of dimension d [13], Algorithm 4 is provably more efficient when the velocity polytope is sparse,
as the procedure in Algorithm 3 only sorts a vector of dimension n ≤ d. This manifests potential
benefit of CGM even when the projection oracle is computable.
Algorithm 4 Constrained Gradient Method with Simplex Constraint
Input: Initialization x , stepsize η > 0, parameter α > 0.
0
1: for t = 0,1,··· ,T −1 do
2: N t = {i ∈ [d]|x t,i ≤ 0}.
3: x t+1 = (1−αη)x t+αη proj v(cid:0) x t− α1F(x t),N t(cid:1) .
4: end for
Output: x¯ =
(1/T)(cid:80)T−1x
.
T t=0 t
5.3 The General Case
For general problems with multiple constraints C = {x ∈ Rd|g (x) ≤ 0,∀i ∈ [m]}, closed-form updates
i
of CGM may not always exist. A simple solution, akin to how Polyak’s switching gradient method
[52, 22] handles multiple constraints, is to replace C with {x ∈ Rd|g(x) ≤ 0} for g(x) = max g (x).
i∈[m] i
Asouralgorithmrequirestheconstraintfunctiontobesmooth,abetterchoiceistousethelog-sum-exp
(cid:80)
function g(x) = log( exp(g (x))) as a smooth approximation to the maximum. Algorithm 2 can
i∈[m] i
be applied since now there is only one constraint function involved. This strategy is not commonly
preferred, as it overlooks the structure of the feasible set and the velocity polytope. Various methods
[42, 50] can then be applied to actually solve the quadratic program; see Section 7 in Muehlebach and
Jordan [42] for discussions. For example, the Frank-Wolfe method achieves the required guarantees in
Algorithm 1 with O(1/ϵ) calls to a linear programming solver [24].
146 Numerical Experiments
Numerical experiments on minimax problems with quadratic or simplex constraints are provided
to evaluate the effectiveness of CGM. For all settings, we implement CGM with direct updates as
discussed in Section 5.
6.1 2D Examples with Ellipse Constraints
Figure 1: The trajectory of CGM on two 2D examples with varying α. Each marker denotes the
iterate at each iteration. The shaded area represents the feasible set and the black star denotes the
optimal solution. The initialization point is (0.5,1) for both examples.
We first provide the following two 2D examples with minimax objectives and ellipse constraints to
illustrate the trajectory of our algorithm: the Forsaken game [21] and a toy GAN [11]. Both problems
do not have constraints in their original formulation, and we add an ellipse constraint to test our
algorithm. To be specific, the forsaken game has the objective
minmax x(y−0.45)+h(x)−h(y),
x∈R y∈R
s.t. x2+4y2 ≤ 1,
where h(x) = x2/4−x4/2+x6/6. The toy GAN is constructed such that the generator tries to learn
the unknown variance of data sampled from a Gaussian distribution, that is,
minmax E (cid:2) yu2(cid:3) −E (cid:2) yx2u2(cid:3) ,
x∈R y∈R
u1∼N(0,1) 1 u2∼N(0,1) 2
s.t. x2+4y2 ≤ 1.
Both examples are known to exhibit limit cycles, posing challenges in the computation of equilibria.
Theprojectionoperationontogeneralellipsoidconstraintsdoesnothavesimplesolutions, andprevious
15methods rely on an iterative procedure for an approximation [10]. However, since the ellipse constraint
only involves one constraint function, our algorithm has a simple update rule as summarized in
Algorithm 2.
In Figure 1, we plot the trajectory of CGM (Algorithm 2) on the 2D examples. For both examples,
wefixthestepsizeη tobe0.1, thenumberofiterationstobe64, andvarytheparameterα aspresented
in the figure. The optimal solution is inside the feasible set for the Forsaken game, and exactly on the
boundary for the toy GAN. For the toy GAN, we use 1000 independent samples from a zero-mean
Gaussian random variable with unit variance for both u and u to estimate the gradients at each
1 2
iteration. The figure illustrates that CGM exhibits different behaviors as α changes: a larger α results
in more aggressive updates towards minimizing constraint violations, whereas a smaller α leads to
trajectories that are predominantely guided by the objective function. CGM demonstrates the ability
to approach the feasible set and attain convergence to the optimal solution, even when initiated from
infeasible points.
6.2 Matrix Game with Quadratic Constraints
Figure 2: The optimality gap and feasibility of CGM on the matrix game with the quadratic constraint.
Both are measured on the average iterates of the algorithm.
We then turn to problems with higher dimensions. The first example is the matrix game with a
quadratic constraint, i.e.,
minmax (x−a)⊤Ay,
x∈Rdy∈Rd
1
s.t. z⊤Bz ≤ c,
2
where z = (x,y) ∈ R2d is the concatenation of x and y. The problem is equivalent to the con-
strained variational inequality problem associated with F(z) = (Ay,−A⊤(x − a)) and C = {z ∈
R2d|(1/2)z⊤Bz ≤ c}. Here, A ∈ Rd×d is a random matrix with each entry sampled from N(0,1),
a ∈ Rd is a vector with each entry sampled from N(0,0.1), B ∈ R2d×2d is a random positive
16definite matrix with each eigenvalue uniformly sampled from [0.1,10], and c > 0 is sampled uni-
formly from [0.1,10]. For any point zˆ = (xˆ,yˆ), its optimality is measured by the (strong) gap
max F(zˆ)⊤(zˆ−z) = −min z⊤F(zˆ) = (2cF(zˆ)⊤B−1F(zˆ))1/2 through solving the corresponding
z∈C z∈C
KKT system, and its feasibility is measured by the constraint violation max{0,(1/2)zˆ⊤Bzˆ−c}.
Although the constraint function has a simple quadratic form, it is challenging to derive the
projection oracle. Its specific form depends on the spectrum of B and often relies on matrix inversion
and decomposition operations that are computationally expensive, except if B is diagonal. Existing
methods therefore rely on an iterative procedure to derive the projection oracle, see e.g., Dai [10].
However, as there is only one constraint function, an efficient implementation of CGM exists; see
Algorithm 2. Figure 2 shows the performance of CGM (Algorithm 2). The experiments are conducted
with a dimension of d = 1000, an iteration number of T = 1000, stepsize η = 0.01, α = 50, and a
random initialization point with each coordinate sampled from the Gaussian N(0,1). CGM is able to
reduce both the optimality gap and feasibility without knowing the projection oracle, as indicated by
our theoretical analysis.
6.3 Matrix Game with Simplex Constraints
Figure 3: The optimality gap and feasibility of CGM (Algorithm 4) and projected gradient descent
ascent (GDA) on the matrix game with the simplex constraint. Both are measured on the average
iterates of the algorithm.
The last example we explore is a matrix game with simplex constraints. This gives rise to
minmax x⊤Ay,
x∈Rdy∈Rd
d d
(cid:88) (cid:88)
s.t. x + y = 1,
i i
i=1 i=1
x ≥ 0, y ≥ 0, ∀i ∈ [d],
i i
17where A ∈ Rd×d is a random matrix with each entry sampled from N(0,1). Let z = (x,y) ∈ R2d. The
problem is equivalent to the constrained variational inequality problem associated with the operator
F(z) = (Ay,−A⊤x) and the feasible set C = {z ∈ R2d| (cid:80)2d z = 1,z ≥ 0,∀i ∈ [2d]}. For any point
i=1 i i
zˆ = (xˆ,yˆ), its optimality is measured by the (strong) gap max F(zˆ)⊤(zˆ−z) ≤ |max(A⊤xˆ) |+
z∈C i
|min(Ayˆ) |, and its feasibility is measured by the constraint violation
max{0,−zˆ,|(cid:80)2d
z −1|}.
i i i=1 i
Figure 3 shows the performance of CGM (Algorithm 4) and compares with projection-based
method gradient descent ascent (GDA), which suggests that both the optimality gap and feasibility
can be effectively reduced by CGM. In the experiments for both CGM and GDA, we set the dimension
d = 1000, the number of iterations T = 1000, stepsize η = 0.005, and choose a random initialization
point with each coordinate sampled from the Gaussian N(0,1). The parameter α is set to be 100 for
CGM. Since we start with an initial point that may be infeasible, the average iterates of GDA may
not be feasible as well, even with projections applied at each iteration.
7 Conclusion
We present a primal method for solving monotone variational inequality problems with general
functional constraints. Our algorithm achieves the same complexity on querying F as projection-based
methods and does not rely on the optimal Lagrange multipliers unlike existing primal-dual methods.
Several interesting questions have yet to be explored. The current analysis of CGM (Algorithm 1) for
the strongly-monotone setting achieves a rate slightly worse than O(1/T) on the constraint violation,
where T is the number of iterations. It remains unknown whether such guarantees can be improved.
An exploration into the monotone and Lipschitz case is also valuable, particularly to determine if the
improved complexity O(1/ϵ) can be achieved, as observed in the context of projection-based methods,
such as extragradient and optimistic gradient [41, 40]. Furthermore, extensions to stochastic settings
[28, 1] and non-monotone settings [65, 12] are left for future investigations.
Acknowledgements
We thank the Max Planck ETH Center for Learning Systems and the German Research Foundation
for the support.
References
[1] Ahmet Alacaoglu and Yura Malitsky. Stochastic variance reduction for variational inequality
methods. In Conference on Learning Theory, pages 778–816. PMLR, 2022.
[2] Pragnya Alatur, Giorgia Ramponi, Niao He, and Andreas Krause. Provably learning Nash policies
in constrained Markov potential games. arXiv preprint arXiv:2306.07749, 2023.
[3] Heinz H Bauschke and Patrick L Combettes. Convex Analysis and Monotone Operator Theory in
Hilbert Spaces. Springer, Cham, 2011.
[4] Mokhtar S Bazaraa, Hanif D Sherali, and Chitharanjan M Shetty. Nonlinear Programming:
Theory and Algorithms. John Wiley & Sons, New Jersey, 2013.
[5] Digvijay Boob and Qi Deng. First-order methods for stochastic variational inequality problems
with function constraints. arXiv preprint arXiv:2304.04778, 2023.
18[6] Digvijay Boob, Qi Deng, and Guanghui Lan. Stochastic first-order methods for convex and
nonconvex functional constrained optimization. Mathematical Programming, 197(1):215–279,
2023.
[7] Yair Censor, Aviv Gibali, and Simeon Reich. The subgradient extragradient method for solving
variational inequalities in Hilbert space. Journal of Optimization Theory and Applications, 148
(2):318–335, 2011.
[8] Tatjana Chavdarova, Tong Yang, Matteo Pagliardini, and Michael Jordan. A primal-dual
approach to solving variational inequalities with general constraints. In International Conference
on Learning Representations, 2024.
[9] PW Christensen, Anders Klarbring, Jong-Shi Pang, and Niclas Strömberg. Formulation and
comparison of algorithms for frictional contact problems. International Journal for Numerical
Methods in Engineering, 42(1):145–173, 1998.
[10] Yu-Hong Dai. Fast algorithms for projection on an ellipsoid. SIAM Journal on Optimization, 16
(4):986–1006, 2006.
[11] Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng. Training GANs
with optimism. In International Conference on Learning Representations, 2018.
[12] Jelena Diakonikolas, Constantinos Daskalakis, and Michael I Jordan. Efficient methods for
structurednonconvex-nonconcavemin-maxoptimization. InInternational Conference on Artificial
Intelligence and Statistics, pages 2746–2754. PMLR, 2021.
[13] John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra. Efficient projections onto
the l -ball for learning in high dimensions. In International Conference on Machine Learning,
1
pages 272–279. PMLR, 2008.
[14] Francisco Facchinei and Christian Kanzow. Generalized Nash equilibrium problems. Annals of
Operations Research, 175(1):177–211, 2010.
[15] Francisco Facchinei and Jong-Shi Pang. Finite-Dimensional Variational Inequalities and Comple-
mentarity Problems. Springer, New York, 2003.
[16] Gauthier Gidel, Tony Jebara, and Simon Lacoste-Julien. Frank-Wolfe algorithms for saddle point
problems. In International Conference on Artificial Intelligence and Statistics, pages 362–371.
PMLR, 2017.
[17] Gauthier Gidel, Hugo Berard, Gaëtan Vignoud, Pascal Vincent, and Simon Lacoste-Julien. A
variational inequality perspective on generative adversarial networks. In International Conference
on Learning Representations, 2019.
[18] Chengyue Gong, Xingchao Liu, and Qiang Liu. Automatic and harmless regularization with
constrained and lexicographic optimization: A dynamic barrier approach. In Advances in Neural
Information Processing Systems, volume 34, pages 29630–29642, 2021.
[19] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural
Information Processing Systems, volume 27, 2014.
19[20] Eduard Gorbunov, Adrien Taylor, and Gauthier Gidel. Last-iterate convergence of optimistic
gradient method for monotone variational inequalities. In Advances in Neural Information
Processing Systems, volume 35, pages 21858–21870, 2022.
[21] Ya-Ping Hsieh, Panayotis Mertikopoulos, and Volkan Cevher. The limits of min-max optimization
algorithms: Convergence to spurious non-critical sets. In International Conference on Machine
Learning, pages 4337–4348. PMLR, 2021.
[22] Yankun Huang and Qihang Lin. Oracle complexity of single-loop switching subgradient methods
for non-smooth weakly convex functional constrained optimization. In Advances in Neural
Information Processing Systems, volume 36, pages 61327–61340, 2023.
[23] Abdullahi Adinoyi Ibrahim, Michael Muehlebach, and Caterina De Bacco. Optimal transport
with constraints: from mirror descent to classical mechanics. arXiv preprint arXiv:2309.04727,
2023.
[24] MartinJaggi. RevisitingFrank-Wolfe: Projection-freesparseconvexoptimization. InInternational
Conference on Machine Learning, pages 427–435. PMLR, 2013.
[25] Kenneth Langstreth Johnson. Contact Mechanics. Cambridge University Press, Cambridge, 1987.
[26] Michael I Jordan, Tianyi Lin, and Manolis Zampetakis. First-order algorithms for nonlinear
generalized Nash equilibrium problems. Journal of Machine Learning Research, 24(38):1–46,
2023.
[27] Philip Jordan, Anas Barakat, and Niao He. Independent learning in constrained Markov potential
games. arXiv preprint arXiv:2402.17885, 2024.
[28] Anatoli Juditsky, Arkadi Nemirovski, and Claire Tauvel. Solving variational inequalities with
stochastic mirror-prox algorithm. Stochastic Systems, 1(1):17–58, 2011.
[29] James E Kelley, Jr. The cutting-plane method for solving convex programs. Journal of the
Society for Industrial and Applied Mathematics, 8(4):703–712, 1960.
[30] David Kinderlehrer and Guido Stampacchia. An Introduction to Variational Inequalities and
Their Applications. SIAM, Philadelphia, 2000.
[31] PavelKolev,GeorgMartius,andMichaelMuehlebach. Onlinelearningunderadversarialnonlinear
constraints. InAdvances in Neural Information Processing Systems,volume36,pages53227–53238,
2023.
[32] Galina M Korpelevich. The extragradient method for finding saddle points and other problems.
Matecon, 12:747–756, 1976.
[33] Guanghui Lan and Zhiqiang Zhou. Algorithms for stochastic optimization with function or
expectation constraints. Computational Optimization and Applications, 76(2):461–498, 2020.
[34] Claude Lemaréchal, Arkadii Nemirovskii, and Yurii Nesterov. New variants of bundle methods.
Mathematical Programming, 69:111–147, 1995.
[35] Jacques-Louis Lions and Guido Stampacchia. Variational inequalities. Communications on Pure
and Applied Mathematics, 20(3):493–519, 1967.
20[36] Andrew Lowy, Sina Baharlouei, Rakesh Pavan, Meisam Razaviyayn, and Ahmad Beirami. A
stochastic optimization framework for fair risk minimization. Transactions on Machine Learning
Research, 2022. ISSN 2835-8856.
[37] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In International Conference on
Learning Representations, 2018.
[38] Otello Giacomo Mancino and Guido Stampacchia. Convex programming and variational inequali-
ties. Journal of Optimization Theory and Applications, 9:3–23, 1972.
[39] George J Minty. Monotone (nonlinear) operators in Hilbert space. Duke Math. J., 29(1):341–346,
1962.
[40] AryanMokhtari, AsumanOzdaglar, andSarathPattathil. Aunifiedanalysisofextra-gradientand
optimistic gradient methods for saddle point problems: Proximal point approach. In International
Conference on Artificial Intelligence and Statistics, pages 1497–1507. PMLR, 2020.
[41] Aryan Mokhtari, Asuman E Ozdaglar, and Sarath Pattathil. Convergence rate of O(1/k) for
optimistic gradient and extragradient methods in smooth convex-concave saddle point problems.
SIAM Journal on Optimization, 30(4):3230–3251, 2020.
[42] Michael Muehlebach and Michael I Jordan. On constraints in first-order optimization: A view
from non-smooth dynamical systems. Journal of Machine Learning Research, 23(256):1–47, 2022.
[43] Michael Muehlebach and Michael I Jordan. Accelerated first-order optimization under nonlinear
constraints. arXiv preprint arXiv:2302.00316, 2023.
[44] Anna Nagurney. Network Economics: A Variational Inequality Approach. Springer Science &
Business Media, Dordrecht, 1998.
[45] John Nash. Equilibrium points in n-person games. Proceedings of the National Academy of
Sciences, 36(1):48–49, 1950.
[46] John Nash. Non-cooperative games. Annals of Mathematics, pages 286–295, 1951.
[47] Arkadi Nemirovski. Prox-method with rate of convergence O(1/t) for variational inequalities
with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems.
SIAM Journal on Optimization, 15(1):229–251, 2004.
[48] Yurii Nesterov. Dual extrapolation and its applications to solving variational inequalities and
related problems. Mathematical Programming, 109(2-3):319–344, 2007.
[49] Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. Springer Science
& Business Media, New York, 2013.
[50] Robert Nishihara, Laurent Lessard, Ben Recht, Andrew Packard, and Michael Jordan. A general
analysis of the convergence of ADMM. In International Conference on Machine Learning, pages
343–352. PMLR, 2015.
[51] Jorge Nocedal and Stephen J Wright. Numerical Optimization. Springer, New York, 1999.
[52] Boris T Polyak. A general method for solving extremal problems. In Doklady Akademii Nauk,
volume 174, pages 33–36. Russian Academy of Sciences, 1967.
21[53] Boris T Polyak. Introduction to Optimization. Optimization Software, New York, 1987.
[54] Leonid Denisovich Popov. A modification of the Arrow-Hurwicz method for search of saddle
points. Mathematical Notes of the Academy of Sciences of the USSR, 28:845–848, 1980.
[55] RTyrrellRockafellar. Monotoneoperatorsassociatedwithsaddle-functionsandminimaxproblems.
Nonlinear Functional Analysis, 18(part 1):397–407, 1970.
[56] R Tyrrell Rockafellar. Monotone operators and the proximal point algorithm. SIAM Journal on
Control and Optimization, 14(5):877–898, 1976.
[57] Sholom Schechtman, Daniil Tiapkin, Eric Moulines, Michael I Jordan, and Michael Muehle-
bach. First-order constrained optimization: Non-smooth dynamical system viewpoint. IFAC-
PapersOnLine, 55(16):236–241, 2022.
[58] Sholom Schechtman, Daniil Tiapkin, Eric Moulines, and Michael Muehlebach. Orthogonal
directions constrained gradient method: from non-linear equality constraints to Stiefel manifold.
In Conference on Learning Theory, volume 195, pages 1228–1258. PMLR, 2023.
[59] Mircea Sofonea and Andaluzia Matei. Variational Inequalities with Applications: A Study of
Antiplane Frictional Contact Problems. Springer Science & Business Media, New York, 2009.
[60] Guido Stampacchia. Formes bilineaires coercitives sur les ensembles convexes. Comptes Rendus
Academie Sciences Paris, 258:4413–4416, 1964.
[61] Kiran K Thekumparampil, Prateek Jain, Praneeth Netrapalli, and Sewoong Oh. Projection
efficient subgradient method and optimal nonsmooth Frank-Wolfe method. In Advances in Neural
Information Processing Systems, volume 33, pages 12211–12224, 2020.
[62] Paul Tseng. On linear convergence of iterative methods for the variational inequality problem.
Journal of Computational and Applied Mathematics, 60(1-2):237–252, 1995.
[63] Weiran Wang and Miguel A Carreira-Perpinán. Projection onto the probability simplex: An
efficient algorithm with a simple proof, and an application. arXiv preprint arXiv:1309.1541, 2013.
[64] Tengyu Xu, Yingbin Liang, and Guanghui Lan. CRPO: A new approach for safe reinforcement
learning with convergence guarantee. In International Conference on Machine Learning, pages
11480–11491. PMLR, 2021.
[65] Junchi Yang, Negar Kiyavash, and Niao He. Global convergence and variance reduction for a
class of nonconvex-nonconcave minimax problems. In Advances in Neural Information Processing
Systems, volume 33, pages 1153–1165, 2020.
[66] Tong Yang, Michael Jordan, and Tatjana Chavdarova. Solving constrained variational inequal-
ities via a first-order interior point-based method. In International Conference on Learning
Representations, 2023.
[67] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna P Gummadi.
Fairness constraints: A flexible approach for fair classification. Journal of Machine Learning
Research, 20(1):2737–2778, 2019.
22A Proof of Lemma 1
Proof. Since α > 0 and g (x) is convex for any i ∈ [m+1], we have that ∀x ∈ C,
i
αg (x )+α∇g (x )⊤(x−x ) ≤ αg (x)
i t i t t i
≤ 0.
We recall that V (x ) = {v ∈ Rd|αg (x )+∇g (x )⊤v ≤ 0,∀i ∈ I }. The equation above suggests
α t i t i t xt
that α(x−x ) ∈ V (x ) for any x ∈ C. By the guarantee that (v +F(x ))⊤(v −v) ≤ ϵ/2, ∀v ∈ V (x ),
t α t t t t α t
we know that for any v ∈ V (x ),
α t
1 1 1
∥v +F(x )∥2− ∥v+F(x )∥2 = (v +F(x ))⊤(v −v)− ∥v −v∥2
t t t t t t t
2 2 2
ϵ
≤ .
2
Setting v = α(x−x ) for any x ∈ C and ϵ ≤ 4L2, we have that ∀x ∈ C,
t F
√
∥v +F(x )∥ ≤ ∥α(x−x )+F(x )∥+ ϵ
t t t t
≤ α∥x ∥+α∥x∥+∥F(x )∥+2L .
t t F
By the assumptions that ∥F(x)∥ ≤ L and ∥x∥ ≤ D,∀x ∈ C, we have that
F
∥v ∥ ≤ ∥v +F(x )∥+∥F(x )∥
t t t t
≤ α∥x ∥+α∥x∥+2∥F(x )∥+2L (10)
t t F
≤ α∥x ∥+αD+4L .
t F
We prove the bound on ∥x ∥2 using induction, and the bound on ∥v ∥2 directly follows from (10). The
t t
base case is true by the initialization x ∈ C, and thus ∥x ∥2 ≤ D2. Assuming the claim holds for some
0 0
k ≥ 0, we now show the same is true for k+1. We consider the following two cases: (a)∥x ∥2 < D2;
k
(b)D2 ≤ ∥x ∥2 ≤ γD2+γ(γ −1)(D+4L /α)2 for a given γ > 1.
k F
For case (a), we have that ∥v ∥ < 2αD+4L . Using αη ≤ (γ −1)/(γ +1), we obtain
k F k
∥x ∥ ≤ ∥x ∥+η ∥v ∥
k+1 k k k
< D+2αη D+4η L
k k F
3γ −1 γ −1 4L
F
≤ D+ .
γ +1 γ +1 α
Since γ > 1, by basic arithmetic calculations, this suggests that
(cid:18)
3γ
−1(cid:19)2
2(3γ −1)(γ −1) 4L D
(cid:18)
γ
−1(cid:19)2(cid:18)
4L
(cid:19)2
∥x ∥2 ≤ D2+ F + F
k+1 γ +1 (γ +1)2 α γ +1 α
4L D
(cid:18)
4L
(cid:19)2
< γ2D2+2γ(γ −1) F +γ(γ −1) F
α α
(cid:18)
4L
(cid:19)2
= γD2+γ(γ −1) D+ F .
α
For case (b), the constraint g (x ) ≥ 0 and thus enters the velocity polytope. By the definition
m+1 k
of V (x ), we know that α(∥x ∥2−D2)+2x⊤v ≤ 0. This implies that
α k k k k
∥x ∥2−D2 = ∥x ∥2−D2+2x⊤(x −x )+∥x −x ∥2
k+1 k k k+1 k k+1 k
= ∥x ∥2−D2+2η x⊤v +η2∥v ∥2
k k k k k k
≤ (1−αη )(∥x ∥2−D2)+η2∥v ∥2.
k k k k
23Applying the inequality that (a+b)2 ≤ (1+1/γ)a2+(1+γ)b2 for any a,b ∈ R and γ > 0 to (10), we
further have that for γ > 1 and αη ≤ (γ −1)/(γ +1),
k
(cid:18)
4L
(cid:19)2
∥x ∥2−D2 ≤ (1−αη )(∥x ∥2−D2)+(1+γ−1)α2η2∥x ∥2+(1+γ)α2η2 D+ F
k+1 k k k k k α
(cid:18)
4L
(cid:19)2
≤ (1−αη )(∥x ∥2−D2)+(1−γ−1)αη ∥x ∥2+(γ −1)αη D+ F
k k k k k
α
(cid:16) (cid:17)
= 1−αη +(1−γ−1)αη (∥x ∥2−D2)
k k k
(cid:18)
4L
(cid:19)2
+(1−γ−1)αη D2+(γ −1)αη D+ F
k k
α
(cid:18)
αη
(cid:19) (cid:18)
4L
(cid:19)2
= 1− k (∥x ∥2−D2)+(1−γ−1)αη D2+(γ −1)αη D+ F .
k k k
γ α
By the induction assumption, ∥x ∥2 ≤ γD2+γ(γ−1)(D+4L /α)2, which concludes that ∥x ∥2 ≤
k F k+1
γD2+γ(γ −1)(D+4L /α)2 as well.
F
For both cases, we are able to prove that ∥x ∥2 ≤ γD2+γ(γ −1)(D+4L /α)2. As a result,
k+1 F
the bound on ∥x ∥2 holds for every t = 0,1,··· ,T −1. By (10), we also have that
t
(cid:18)
4L
(cid:19)2
∥v ∥2 ≤ α2(1+γ−1)∥x ∥2+α2(1+γ) D+ F
t t
α
(cid:18)
4L
(cid:19)2
≤ (γ +1)α2D2+γ(γ +1)α2 D+ F .
α
This concludes the proof.
B CGM with Simplex Constraints
In this section, we provide details on how to derive the closed-form solutions of the quadratic program
when applying CGM to problems with simplex constraints, which leads to the direct method stated
in Algorithm 4. At each step, CGM solves the following quadratic program to decide the update
direction:
1
min ∥v+F(x)∥2,
v∈Rd 2
d (cid:32) d (cid:33)
(cid:88) (cid:88)
s.t. v = α 1− x ,
i i
i=1 i=1
v ≥ −αx , ∀i ∈ {j ∈ [d]|x ≤ 0},
i i j
where we omit the subscript t for simplicity and x denotes the i-th coordinate of x. Let p = v/α+x
i
and q = x−F(x)/α. The above optimization problem is equivalent to
1
min ∥p−q∥2,
p∈Rd 2
d
(cid:88)
s.t. p = 1,
i
i=1
p ≥ 0, ∀i ∈ N,
i
24where the index set N ⊆ [d] with size n ∈ [0,d] denotes the set {j ∈ [d]|x ≤ 0}. Let the
j
solution of the above problem be denoted by proj (q,N). The actual update direction is then
v
v = α(proj (x−F(x)/α)−x), which gives the update in Algorithm 4.
v
Note that the major difference compared to a projection oracle onto the simplex is that we only
restrict the coordinate in N ⊆ [d] to be non-negative. We then derive Algorithm 3 for solving the
above quadratic program following the analysis in Wang and Carreira-Perpinán [63] for the projection
algorithm on the simplex [13]. The Lagrangian function of the above problem is
(cid:32) d (cid:33)
1 (cid:88) (cid:88)
L(p,λ,β) = ∥p−q∥2−λ p −1 − β p ,
i i i
2
i=1 i∈N
and the corresponding KKT system has the following form:
d
(cid:88)
p = 1,
i
i=1
p −q −λ = 0, ∀i ∈/ N,
i i
p −q −λ−β = 0, ∀i ∈ N,
i i i
p ≥ 0,∀i ∈ N,
i
β ≥ 0,∀i ∈ N,
i
p β = 0,∀i ∈ N.
i i
Theproblemreducestofindingλandβ . Weobservethat∀i ∈ N,β = 0ifp > 0,andq +λ = −β ≤ 0
i i i i i
if p = 0. This means that ∀i ∈ N, p = max{q +λ,0}, and the sequence {p |i ∈ N} shares the same
i i i i
ordering as {q |i ∈ N}. Since ∀i ∈/ N,p = q +λ, the problem left is to determine λ. Without loss of
i i i
generality, we assume
q ≥ q ≥ ··· ≥ q ≥ q ≥ ··· ≥ q ,
1 2 ρ ρ+1 n
p ≥ p ≥ ··· ≥ p > p = ··· = p .
1 2 ρ ρ+1 n
Here, ρ is the index such that p = ··· = p = 0. Otherwise, a sorting of {q |i ∈ N} can be applied.
ρ+1 n i
(cid:80)
Let s = q . By the KKT system, we have that
N¯ i∈/N i
(cid:88) (cid:88)
1 = p + p
i i
i∈N i∈/N
(cid:88) (cid:88)
= (q +λ)+ (q +λ)
i i
i∈N,pi>0 i∈/N
ρ
(cid:88)
= (d−n+ρ)λ+s + q .
N¯ i
i=1
This suggests that the solution of λ is
(cid:32) ρ (cid:33)
1 (cid:88)
λ = 1−s − q .
d−n+ρ
N¯ i
i=1
The value of ρ plays an important role. We then show that
(cid:40)
0, if J = ∅,
ρ =
maxJ, otherwise,
25where the set J is defined to be
(cid:40) (cid:12) (cid:32) j (cid:33) (cid:41)
(cid:12) 1 (cid:88)
J = 1 ≤ j ≤ n(cid:12)q + 1−s − q > 0 .
(cid:12) j d−n+j N¯ i
(cid:12)
i=1
Note that the algorithm includes the cases for n = 0 and n = d. When n = 0, we know J = ∅ and
ρ = 0. When n = d, it is easy to show that J ̸= ∅ and the algorithm reduces to projection onto the
simplex.
If J = ∅, we have that
1 1
q + (1−s −q ) = (1−s +(d−n)q )
1
d−n+1
N¯ 1
d−n+1
N¯ 1
d−n
= (q +λ)
1
d−n+1
≤ 0.
This suggests that q +λ ≤ 0,∀i ∈ N and thus q = 0.
i
If J ̸= ∅, we consider the following two cases. For j ≤ ρ, we have that
(cid:32) j (cid:33) (cid:32) j (cid:33)
1 (cid:88) 1 (cid:88)
q + 1−s − q = 1−s +(d−n+j)q − q
j
d−n+j
N¯ i
d−n+j
N¯ j i
i=1 i=1
 
ρ ρ
1 (cid:88) (cid:88)
=
d−n+j
1−s N¯ − q i+(d−n+j)q j + q i
i=1 i=j+1
 
ρ
1 (cid:88)
= (d−n+ρ)λ+(d−n+j)q j + q i
d−n+j
i=j+1
 
ρ
1 (cid:88)
= (d−n+j)(q
j
+λ)+ (q i+λ)
d−n+j
i=j+1
> 0.
For j > ρ, we have that
 
(cid:32) j (cid:33) ρ j
1 (cid:88) 1 (cid:88) (cid:88)
q j +
d−n+j
1−s N¯ − q i =
d−n+j
1−s N¯ − q i+(d−m+j)q j − q i
i=1 i=1 i=ρ+1
 
j
1 (cid:88)
= (d−n+ρ)λ+(d−n+j)q j − q i
d−n+j
i=ρ+1
 
j
1 (cid:88)
= (d−n+ρ)(q
j
+λ)− (q i−q j)
d−n+j
i=ρ+1
≤ 0.
This suggests that ρ = maxJ and leads to the method described in Algorithm 3. Since the algorithm
onlyrequirestosortmcoordinatesinsteadofd, itisprovablymoreefficientcomparedtotheprojection
oracle. The difference is particularly pronounced if the quadratic program is sparse.
26