1
Detection of Malicious Agents in Social Learning
Valentina Shumovskaia, Mert Kayaalp, and Ali H. Sayed
E´cole Polytechnique Fe´de´rale de Lausanne (EPFL)
Abstract—Social learning is a non-Bayesian framework for that social learning methods are quite robust in the presence
distributed hypothesis testing aimed at learning the true state of of malicious agents (which are defined as agents that feed
theenvironment.Traditionally,theagentsareassumedtoreceive
observations that arise from a different state than the rest
observations conditioned on the same true state, although it is
of the network). Some works suggest defense mechanisms
alsopossibletoexaminethecaseofheterogeneousmodelsacross
the graph. One important special case is when heterogeneity against such agents [23], [24]. The robustness means that the
is caused by the presence of malicious agents whose goal is to maliciousagentsareforcedtoconvergetothesameconclusion
move the agents towards a wrong hypothesis. In this work, we as the rest of the network. This fact makes it impossible to
propose an algorithm that allows to discover the true state of
identify malicious (or dysfunctional) agents, based solely on
every individual agent based on the sequence of their beliefs.
their observed belief. In so doing, the methodology is also able to locate malicious
behavior. In this work, we develop a centralised algorithm for iden-
tifying the true state associated with each agent, even when
IndexTerms—Sociallearning,hypothesestesting,inversemod-
the final belief of an agent may be pointing toward another
eling, diffusion strategy, adaptive learning, anomaly detection,
malicious agent. conclusion due to the interactions over the graph. In this way,
the method is able to identify malicious agents as well. There
is no question that this is an important question that deserves
I. INTRODUCTIONANDRELATEDWORK attention [25]–[38]. For instance, over social networks, it is
Social learning algorithms [1]–[12] solve the distributed critical to identify users that have unwarranted intentions and
hypothesis problem in a non-Bayesian fashion. These algo- aimtoforcethenetworktoreacherroneousconclusions[31]–
rithms learn the underlying true state of nature by observing [33], as well as to discover trolls [34]–[36] and measure their
streaming data arriving at the agents and conditioned on that impactonperformance[25].Thesametechniquescanbeused
state. The key difference with Bayesian solutions [13]–[15] is to locate malfunctioning agents, e.g., [27].
thatsociallearningdoesnotrequireeachnodetoknowthefull
graphtopologyorlikelihoodmodelsusedbyeveryothernode II. SOCIALLEARNINGMODEL
(includingnon-neighboringnodes).Thesefeaturesenablefully A set of agents N builds confidences on each hypothesis θ
decentralizedimplementations.Someapplicationsofthesocial from a finite set Θ through interactions with the environment
learning framework include detection problems by sensor andamongtheagents.Theagentscommunicateaccordingtoa
networks[16],[17]ordistributedmachinelearning[18],[19]. fixedcombinationmatrixA∈[0,1]N×N,whereeachnonzero
The framework can also be used to describe how users form element a > 0 indicates a directed edge from agent ℓ to
ℓ,k
their opinions over social graphs [20]. agent k and defines the level of trust that agent k gives to
Under social learning, and in order to learn the truth, informationarrivingfromagentℓ.Eachagentk assignsatotal
agents update their beliefs (or confidences) on each possible confidence level of 1 to its neighbors. This assumption makes
hypothesis, ensuring that the total confidence adds up to the combination matrix A left stochastic, i.e.,
1. In general, at every time instant, each agent receives an (cid:88)
a =1, ∀k ∈N (1)
observation conditioned on the state of the environment and ℓk
uses the local likelihood model to perform a local Bayesian ℓ∈N
update starting from its current belief vector. This step is Another common assumption, ensuring global truth learning
followed by a communication stage, during which agents for homogeneous environments, is that A is strongly con-
exchange beliefs with their neighbors and fuse the received nected.Thisimpliestheexistenceofatleastoneself-loopwith
information with their own opinions. These two steps of local a positive weight and a path with positive weights between
Bayesian updates and local consultation are repeated until any two nodes [39]. This condition allows us to apply the
convergence is attained. Perron-Frobeniustheorem[40,Chapter8],[41],whichensures
Many existing works on social learning assume that the that the power matrix As converges exponentially to u1T as
observations received by each agent arise from one true state s → ∞. Here, u is the Perron eigenvector of A associated
of the environment. Some other works study the case of with the eigenvalue at 1 and is normalized as follows:
nonhomogeneous models across the agents. For example, the (cid:88)
Au=u, u >0, u =1. (2)
works[21],[22]focusoncommunitystructurenetworkswhere ℓ ℓ
ℓ∈N
each community has its own truth. The main conclusion is
Each agent assigns an initial private belief µ (θ)∈[0,1]
k,0
Emails:{valentina.shumovskaia,mert.kayaalp,ali.sayed}@epfl.ch. toeachhypothesisθ ∈Θ,formingaprobabilitymassfunction
4202
raM
91
]IS.sc[
1v91621.3042:viXra2
(cid:80)
withthetotalconfidencesummingupto1,i.e., µ (θ)= Assumption 1 (Bounded likelihoods). There exists a finite
θ k,0
1. To avoid excluding any hypothesis from the beginning, constant b>0 such that for all k ∈N:
we assume that each component of the belief vector µ is (cid:12) (cid:12)
k,0 (cid:12) L (ζ |θ)(cid:12)
positive. Subsequently, agents iteratively update their belief (cid:12)log k (cid:12)≤b (6)
(cid:12) L (ζ |θ′)(cid:12)
vectors by interacting both with the environment and with (cid:12) k (cid:12)
their neighbors. At each time instance i, agent k receives an for all θ, θ′ ∈Θ and ζ. ■
observationfromtheenvironmentconditionedonitstruestate,
denoted by ζ ∼L (ζ|θ⋆). In this notation, the observation
k,i k k Now, consider a sequence of public beliefs measured closer
ζ arises from the likelihood model L (ζ|θ⋆), which is
k,i k k to the steady state:
parameterized by the unknown model θ⋆. For example, the
k
entire network may be following the same and unique model {ψ } , k ∈N (7)
k,i i≫1
θ⋆,whileafewmaliciousagentsmaybefollowingsomeother
model θ ̸= θ⋆. The observations {ζ } are assumed to be
k,i When an agent cannot distinguish between θ⋆ and another θ
independent and identically distributed (i.i.d.) over time. The k
due to L (θ⋆)=L (θ), we will treat this θ as a valid model
local Bayesian update performed by agent k at time i takes k k k
for the agent as well. To accommodate this possibility, we
the following form [7]:
defineΘ⋆ astheoptimalhypothesessubsetforeachindividual
k
ψ k,i(θ)=
(cid:80)
Lδ k( Lζ δk (,i ζ|θ) |µ θ1 k ′− , )i µ−δ 11 −(θ δ) (θ′), ∀k ∈N, (3) a Tg he en nt ,, wde eno rete fod rmby ulΘ ate⋆ k = the{θ pk⋆ ro} b∪ le{ mθ b̸= yθ sk⋆ tat| inL gk( tθ h) at= ouL rk a( iθ mk⋆)} is.
θ′∈Θ k k,i k,i−1 to recover the optimal hypotheses subset for each agent:
whereδ ∈(0,1)playstheroleofanadaptationparameterand
{Θ⋆}, k ∈N. (8)
it controls the importance of the newly received observation k
relative to the information learned from past interactions. The
denominator in (3) serves as a normalization factor, ensuring We denote the level of informativeness of any pair of
thattheresultingψ isaprobabilitymassfunction.Werefer hypotheses θ,θ′ ∈Θ at each agent k by:
k,i
to ψ as the public (or intermediate) belief due to the next L (ζ |θ)
k,i d (θ,θ′)≜E log k k (9)
communication step, which involves a geometric averaging k ζ k∼Lk(θ k⋆) L k(ζ k|θ′)
computation [2], [4], [9]:
It is clear that this value is equal to zero if both θ and θ′
µ k,i(θ)= (cid:80) (cid:81) ℓ∈ (cid:81)Nkψa ℓ,ℓ i ψk( aθ ℓ) k(θ′), ∀k ∈N. (4) bb eelo pn og sitt io veth fe oro ap nti ym θal ∈/su Θb ⋆se ,t siΘ nc⋆ k e. Additionally, d k(θ k⋆,θ) will
θ′∈Θ ℓ∈Nk ℓ,i k
At each iteration i, each agent k estimates its true state θ⋆ d (θ⋆,θ)=D (L (θ⋆)||L (θ))>0 (10)
k k k KL k k k
basedonthebeliefvector(eitherprivateorpublic)byselecting
and, in turn, d (θ,θ⋆) is always negative:
the hypothesis with the highest confidence: k k
d (θ,θ⋆)=−D (L (θ⋆)||L (θ))<0 (11)
θ(cid:98)k,i ≜argmaxµ k,i(θ). (5) k k KL k k k
θ∈Θ
Here, D denotes the Kullback-Leibler divergence between
KL
In the homogeneous environment case [2], [4], [7], [9], i.e.,
two distributions:
when θ⋆ = θ⋆ for each k, it can be proved that every agent
findsthek truthasymptoticallywithprobability1.Thework[22] D (cid:0) L (θ⋆)||L (θ)(cid:1)≜E logL k(ζ |θ⋆) (12)
KL k k ζ∼Lk(ζ|θ⋆) L (ζ |θ)
considers non-homogeneous environments with community- k
structured graphs; it establishes that, as δ → 0, the entire Properties (10)–(11) allow us to conclude that the optimal
network converges to one solution that best describes the hypotheses subset Θ⋆ consists of all θ for which:
k
data, while in contrast, a larger δ activates the mechanism of
Θ⋆ ={θ: d (θ,θ′)≥0, ∀θ′ ∈Θ} (13)
local adaptivity. Thus, with a larger δ, each individual agent k k
focusesmoreonitsimmediateneighborhoodthanontheentire Our aim is to develop an algorithm that learns Θ⋆ based on
k
network. the available information (7).
In [42, Appendix A], it was shown that the adaptive social
learning iterations (3)–(4) can be expressed in the following
III. INVERSEMODELING
compact linear form:
In this section, we explain how we can identify malicious Λ =(1−δ)ATΛ +δL (14)
i i−1 i
agents (or the true state θ⋆ for each agent) by observing
k
where Λ and L are matrices of size |N|×(|Θ|−1), and
sequences of public beliefs. Importantly, we will not assume i i
for each k and j, their entries take the log-ratio form:
knowledge of the combination matrix A.
Tobeginwith,weintroducethefollowingcommonassump- ψ (θ ) L (ζ |θ )
[Λ ] ≜log k,i 0 , [L ] ≜log k k,i 0 . (15)
tion, essentially requiring the observations to share the same i k,j ψ (θ ) i k,j L (ζ |θ )
k,i j k k,i j
support region [8], [20], [42].
for any ordering Θ = {θ ,...,θ }. The expectation of
0 |Θ|−13
L i, relative to the observations {ζ k,i} k, is given by: Algorithm 1: Inverse learning of heterogeneous states
(cid:8) (cid:9)
[L]
k,j
≜[EL i]
k,j
= D KL(L k(θ k⋆)||L k(θ j)) Data: At each time i: ψ k,i(θ) k∈N, δ
Result: Estimated combination matrix A;
−D (L (θ⋆)||L (θ )), (16)
KL k k k 0 Estimated expected log-likelihood ratios L(cid:98);
and it allows us to rewrite (9) in a slightly different manner: Estimated true state of each agent, Θ(cid:98)k.
initialize A 0, L(cid:98)0
d (θ ,θ )=[L] −[L] (17)
k j1 j2 k,j2 k,j1 repeat
Compute matrices Λ :
Furthermore, it was shown in [20] that we can estimate L i
for k ∈N, j =1,...,|Θ| do
by utilizing the publicly exchanged beliefs with the following
accuracy [20, Theorem 2]: ψ (θ )
[Λ ] =log k,i 0
limsupE∥L(cid:98)i−L∥2
F
i k,j ψ k,i(θ j)
i→∞
≤
1
Tr(R
)+O(µ/δ2)+O(cid:0) 1/δ5M2(cid:1)
(18)
Combination matrix update [20]:
M L i−1
(cid:16) 1 (cid:88) (cid:17)
where µ is a small positive learning rate for a stochastic A =A +µ(1−δ) Λ − Λ
i i−1 i−1 M j−1
gradient implementation, M is a batch size of data used to j=i−M
compute the estimate L(cid:98)i, and R L ≜ E(cid:0) L i−L(cid:1)(cid:0) L i−L(cid:1)T . ×(cid:16) ΛT
i
−(1−δ)ΛT i−1A i−1−δL(cid:98)T i−1(cid:17) .
Thus, the informativeness (17) can be estimated by using
Log-likelihoods matrix update:
d(cid:98)k(θ j1,θ j2)=[L(cid:98)]
k,j2
−[L(cid:98)]
k,j1
(19)
i
1 (cid:88) (cid:16) (cid:17)
where L(cid:98) is the estimate of L from the last available iteration. L(cid:98)i =
δM
Λ
j
−(1−δ)AT iΛ
j−1
Based on (13), we can now identify the optimal hypotheses j=i−M+1
subset Θ⋆ defined in (13) as follows:
k
(cid:88) (cid:110) (cid:111) i=i+1
Θ(cid:98)k ≜argm θja 1x
θj2
I d(cid:98)k(θ j1,θ j2)>0 (20)
until sufficient convergence;
Informativeness estimate for all agents k ∈N and
where I{x} is an indicator function that assumes the value 1
pairs of hypotheses θ , θ ∈Θ:
when its argument is true and is 0 otherwise.
j1 j2
We list the procedure in Algorithm 1, including the part
d(cid:98)k(θ j1,θ j2)=[L(cid:98)i]
k,j2
−[L(cid:98)i]
k,j1
related to estimating (18) by using [20, Algorithm 1].
Optimal hypotheses set estimate for all agents k ∈N:
The following result establishes the probability of error. (cid:88) (cid:110) (cid:111)
T inh geo are wm ron1 g(P hr yo pb oa thb ei sli it sy θof ∈/er Θro ⋆r) f. orTh ae gep nr tob kab ∈ili Nty o if sc uh po po es r-
Θ(cid:98)k ≜argm θja 1x
θj2
I d(cid:98)k(θ j1,θ j2)>0
k
bounded by:
P(cid:110) θ ∈Θ(cid:98)k(cid:111) ≤ M2 Tr(R L) (cid:88) D K− L1(cid:0) L k(θ⋆)||L k(θ)(cid:1)
=1−
P(cid:110)
[L(cid:98)]
k,j⋆
−[L]
k,j⋆
−(cid:16)
[L(cid:98)]
k,j
−[L]
k,j(cid:17)
θ⋆∈Θ⋆ k k
k (cid:111)
+O(µ/δ2)+O(cid:0) 1/δ5M2(cid:1) (21) ≤[L] k,j −[L] k,j⋆
k
(cid:110)(cid:12) (cid:12) (cid:12) (cid:12)
Proof. First, we upper bound the probability using the defini- ≤1−P (cid:12) (cid:12)[L(cid:98)] k,j⋆ −[L] k,j⋆(cid:12) (cid:12)+(cid:12) (cid:12)[L(cid:98)] k,j −[L] k,j(cid:12) (cid:12)
k k
tion of d(·,·) and its estimate from (9) and (19), along with (cid:111)
≤[L] −[L]
the properties of probability. For any θ ∈/ Θ⋆, we have that: k,j k,j⋆
j k k
(cid:110)(cid:12) (cid:12) (cid:111)
P(cid:110) θ
j
∈Θ(cid:98)k(cid:111) ≤P(cid:110) ∃θ k⋆ ∈Θ⋆ k: d(cid:98)k(θ k⋆,θ j)<0(cid:111) ≤1−P (cid:12) (cid:12)[L(cid:98)] k,j k⋆ −[L] k,j k⋆(cid:12) (cid:12)≤[L] k,j −[L] k,j k⋆
(cid:110)(cid:12) (cid:12) (cid:111)
≤ (cid:88) P(cid:110) d(cid:98)k(θ k⋆,θ j)<0(cid:111) (22) ×P (cid:12) (cid:12)[L(cid:98)] k,j −[L] k,j(cid:12) (cid:12)≤[L] k,j −[L] k,j k⋆ (23)
θ k⋆∈Θ⋆ k We can transform the result from [42, Theorem 2] (18) into:
N foe rx st o, mw ee fies xt eim da θte ath ne dp θr ⋆ob ua sb inil gity (1o 9f ),d(cid:98) wk h(θ ilk⋆ e, dθ j e) nob te inin gg jn ⋆eg asat ti hv ee E(cid:12) (cid:12) (cid:12)[L(cid:98)]
k,j
−[L] k,j(cid:12) (cid:12) (cid:12)≤ M1 Tr(R L)+O(µ/δ2)+O(cid:0) 1/δ5M2(cid:1)
j k k
index of θ⋆: (24)
k
(cid:110) (cid:111) (cid:110) (cid:111) By Markov’s inequality [41], for any a>0:
P d(cid:98)k(θ k⋆,θ j)<0 =P [L(cid:98)]
k,j
−[L(cid:98)]
k,j k⋆
<0
(cid:16)(cid:12) (cid:12) (cid:17)
=
P(cid:110)
[L(cid:98)]
k,j⋆
−[L]
k,j⋆
−(cid:16)
[L(cid:98)]
k,j
−[L]
k,j(cid:17) P (cid:12) (cid:12)[L(cid:98)] k,j −[L] k,j(cid:12) (cid:12)≤a
k k
(cid:111) ≥1−
1
Tr(R
)+O(µ/δ2)+O(cid:0) 1/δ5M2(cid:1)
(25)
>[L] k,j −[L] k,j⋆ aM L
k4
(b) Test scheme with the cen-
(a) Training scheme. tral node being malicious.
Fig. 1: Example of images from the MIRO dataset for classes
“bus” and “car”.
Also, by the definition of KL divergence we have that:
[L] k,j −[L] k,j⋆ =D KL(L k(θ k⋆)||L k(θ j))>0. (26)
k
Thus, (23) can be upper bounded by:
(cid:110) (cid:111)
P d(cid:98)k(θ k⋆,θ j)<0
Fig. 2: Observation map of each agent.
(cid:18) 1 Tr(R )+O(µ/δ2)+O(cid:0) 1/δ5M2(cid:1)(cid:19)2
≤1− 1− M L
[L] k,j −[L] k,j⋆ (a) Accuracy of the social (b) Malicious detection accu-
k
≈2M−1Tr(R )D−1(cid:0) L (θ⋆)||L (θ)(cid:1) learning strategy to predict θ 0. racy and learned graph.
L KL k k k
+O(µ/δ2)+O(cid:0) 1/δ5M2(cid:1)
(27)
using the Taylor’s expansion for any small x, namely, (1+
x)2 =2x+O(x2).
Combining(22)with(27)wegetthedesiredstatement. ■
IV. COMPUTEREXPERIMENTS
Inthissection,weconsidertheimagedatasetMIRO(Multi-
view Images of Rotated Objects) [43], which contains objects
of different classes from different points of view – see Fig. 1.
For each class, there are 10 objects, and each of the objects
Fig. 3: Accuracy of the adaptive social learning strategy [7]
has 160 different perspectives.
and Algorithm 1. The colors correspond to the output of the
A network of agents wishes to solve a binary hypotheses
algorithmswithyellowforθ andredforθ .Pereachfold,the
0 1
problem to distinguish between states θ corresponding to
0 accuracyforthesociallearningiscalculatedbasedonaverage
the class “bus” and θ corresponding to the class “car”.
1 over 100 past iterations.
Each agent has its own convolutional neural network (CNN)
classifier. These CNNs are trained to distinguish classes θ
0
and θ 1 by observing only a part of the image, similar to the malicious agent. Thus, we perform a cross-validation proce-
approachin[18],[19].Eachimagemeasures224×224pixels,
dure where at first, we train the CNNs on 9objects from each
and each agent observes a section of size 112×112 pixels, class,leaving1objectfromeachclassfortestingpurposes.On
situated in different regions of the image. We illustrate the average,thecross-validationaccuracyofstandaloneclassifiers
observation map in Fig. 2a. The CNN architecture consists of is 0.68. The value is relatively low due to a small training
three convolutional layers: 6 output channels, 3×3 kernel, set and limited observation available at each agent. Given
followed by ReLU and 2×2 max pooling; 16 channels, 3×3 that many folds had some classifiers with an accuracy below
kernel,ReLU,and2×2maxpooling;32channels,3×3kernel,
0.5, we decided to retain only those folds where each agent
ReLU,and2×1maxpooling.Thisisfollowedbylinearlayers
achieved at least 0.6 accuracy. As a result, we are left with
of sizes 288×64, 64×32, and 32×2, with ReLU activation 72 folds instead of 100 with the mean accuracy of standalone
functioninbetween.Thefinalpredictionlayerislogsoftmax. classifiers equal to 0.81.
Training involves 100 epochs with a learning rate of 0.0001 Finally, we proceed with the adaptive social learning strat-
and negative log-likelihood loss. egy performed at each fold with δ = 0.1. The network
For generating a combination matrix (see Fig. 2a), we ini- observes a moving object from the test set of the class “bus”
tially sample an adjacency matrix following the Erdos-Renyi during480iterations(sothat,onaverage,eachframeisshown
model with a connection probability of 0.2. Subsequently, we 3times),whilstthecentralagentsobservesanobjectofaclass
set the combination weights using the averaging rule [39, “car”–seeFig.2b.Wecanseethatdespitethepresenceofthe
Chapter 14]. During the inference, we let the central agent maliciousagent,theaveragebeliefofeachagenttendstowards
be malicious and to observe an object from the opposite class thecorrecthypothesisθ (seeFig.3a)withthemeanaccuracy
0
than the rest of the network – see Fig. 2b. 0.8. However, as depicted in Fig. 3b, the algorithm is able to
Since we only have 10 objects of each class, having only identifythemaliciousagentachievingthemeanaccuracy0.99.
a handful of objects as a test subset is not enough to provide
a reliable accuracy metrics of how well we can identify the5
REFERENCES [25] H.Zhang,Y.Li,Y.Hu,Y.Chen,andH.V.Zhao,“Measuringthehazard
of malicious nodes in information diffusion over social networks,”
[1] A. Jadbabaie, P. Molavi, A. Sandroni, and A. Tahbaz-Salehi, “Non- in Proc. Asia-Pacific Signal and Information Processing Association
Bayesiansociallearning,”GamesandEconomicBehavior,vol.76,no.1, AnnualSummitandConference(APSIPAASC),2019,pp.476–481.
pp.210–225,2012. [26] H. Zhang, Y. Li, Y. Chen, and H. V. Zhao, “Smart evolution for
[2] X.ZhaoandA.H.Sayed,“Learningoversocialnetworksviadiffusion information diffusion over social networks,” IEEE Transactions on
adaptation,” in Proc. Asilomar Conference on Signals, Systems and InformationForensicsandSecurity,vol.16,pp.1203–1217,2021.
Computers,2012,pp.709–713. [27] V.KrishnamurthyandW.Hoiles,“Afriat’stestfordetectingmalicious
[3] H. Salami, B. Ying, and A. H. Sayed, “Social learning over weakly agents,”IEEESignalProcessingLetters,vol.19,no.12,pp.801–804,
connectedgraphs,”IEEETrans.SignalandInformationProcessingover 2012.
Networks,vol.3,no.2,pp.222–238,2017. [28] C.Zhao,J.He,andJ.Chen,“Resilientconsensuswithmobiledetectors
[4] A. Nedic´, A. Olshevsky, and C. A. Uribe, “Fast convergence rates for againstmaliciousattacks,”IEEETransactionsonSignalandInformation
distributed non-Bayesian learning,” IEEE Transactions on Automatic ProcessingoverNetworks,vol.4,no.1,pp.60–69,2018.
Control,vol.62,no.11,pp.5538–5553,2017. [29] V. P. Illiano and E. C. Lupu, “Detecting malicious data injections in
[5] P. Molavi, A. Tahbaz-Salehi, and A. Jadbabaie, “Foundations of non- wirelesssensornetworks:Asurvey,”ACMComputingSurveys(CSUR),
Bayesian social learning,” Columbia Business School Research Paper, vol.48,no.2,pp.1–33,2015.
no.15-95,2017. [30] T. Pang, C. Du, Y. Dong, and J. Zhu, “Towards robust detection
[6] ——,“Atheoryofnon-Bayesiansociallearning,”Econometrica,vol.86, of adversarial examples,” Advances in Neural Information Processing
no.2,pp.445–490,2018. Systems,vol.31,2018.
[7] V. Bordignon, V. Matta, and A. H. Sayed, “Adaptive social learning,” [31] H.Zhang,M.A.Alim,X.Li,M.T.Thai,andH.T.Nguyen,“Misinfor-
IEEE Transactions on Information Theory, vol. 67, no. 9, pp. 6053– mationinonlinesocialnetworks:Detectthemallwithalimitedbudget,”
6081,2021. ACM Transactions on Information Systems (TOIS), vol. 34, no. 3, pp.
1–24,2016.
[8] ——,“Partialinformationsharingoversociallearningnetworks,”IEEE
[32] S. T. Smith, E. K. Kao, E. D. Mackin, D. C. Shah, O. Simek, and
Transactions on Information Theory, vol. 69, no. 3, pp. 2033–2058,
D.B.Rubin,“Automaticdetectionofinfluentialactorsindisinformation
2023.
networks,” Proc. National Academy of Sciences, vol. 118, no. 4, p.
[9] A.Lalitha,T.Javidi,andA.D.Sarwate,“Sociallearninganddistributed
e2011216118,2021.
hypothesistesting,”IEEETransactionsonInformationTheory,vol.64,
[33] M.Egele,G.Stringhini,C.Kruegel,andG.Vigna,“Compa:Detecting
no.9,pp.6161–6179,2018.
[10] Y.˙Inan,M.Kayaalp,E.Telatar,andA.H.Sayed,“Sociallearningunder compromisedaccountsonsocialnetworks.”inNDSS,vol.13,2013,pp.
83–91.
randomizedcollaborations,”inProc.IEEEInternationalSymposiumon
[34] M.Tomaiuolo,G.Lombardo,M.Mordonini,S.Cagnoni,andA.Poggi,
InformationTheory(ISIT),2022,pp.115–120.
“Asurveyontrolldetection,”FutureInternet,vol.12,no.2,p.31,2020.
[11] J. Z. Hare, C. A. Uribe, L. Kaplan, and A. Jadbabaie, “Non-Bayesian
[35] P. Fornacciari, M. Mordonini, A. Poggi, L. Sani, and M. Tomaiuolo,
social learning with uncertain models,” IEEE Transactions on Signal
“AholisticsystemfortrolldetectiononTwitter,”ComputersinHuman
Processing,vol.68,pp.4178–4193,2020.
Behavior,vol.89,pp.258–268,2018.
[12] C.A.Uribe,A.Olshevsky,andA.Nedic´,“Nonasymptoticconcentration
[36] S.Sadiq,A.Mehmood,S.Ullah,M.Ahmad,G.S.Choi,andB.-W.On,
rates in cooperative learning–part i: Variational non-Bayesian social
“Aggression detection through deep neural model on Twitter,” Future
learning,” IEEE Transactions on Control of Network Systems, vol. 9,
GenerationComputerSystems,vol.114,pp.120–129,2021.
no.3,pp.1128–1140,2022.
[37] L. Xing, K. Deng, H. Wu, P. Xie, H. V. Zhao, and F. Gao, “A survey
[13] D. Gale and S. Kariv, “Bayesian learning in social networks,” Games
ofacrosssocialnetworksuseridentification,”IEEEAccess,vol.7,pp.
andEconomicBehavior,vol.45,no.2,pp.329–346,2003.
137472–137488,2019.
[14] D. Acemoglu, M. A. Dahleh, I. Lobel, and A. Ozdaglar, “Bayesian
[38] B.Qiu,Y.Li,Y.Chen,andH.V.Zhao,“Controllinginformationdiffu-
learninginsocialnetworks,”TheReviewofEconomicStudies,vol.78,
sionwithirrationalusers,”inProc.Asia-PacificSignalandInformation
no.4,pp.1201–1236,2011.
ProcessingAssociationAnnualSummitandConference(APSIPAASC),
[15] J. Hkazla, A. Jadbabaie, E. Mossel, and M. A. Rahimian, “Bayesian
2019,pp.482–485.
decisionmakingingroupsishard,”OperationsResearch,vol.69,no.2,
[39] A. H. Sayed, “Adaptation, learning, and optimization over networks,”
pp.632–654,2021.
FoundationsandTrends®inMachineLearning,vol.7,no.4-5,pp.311–
[16] M. G. Rabbat and R. D. Nowak, “Decentralized source localization 801,2014.[Online].Available:http://dx.doi.org/10.1561/2200000051
and tracking [wireless sensor networks],” in Proc. IEEE International [40] R.A.HornandC.R.Johnson,MatrixAnalysis. CambridgeUniversity
Conference on Acoustics, Speech and Signal Processing (ICASSP),
Press,NY,2013.
vol.3,Montreal,Canada,2004,pp.921–924. [41] A.H.Sayed,InferenceandLearningfromData. CambridgeUniversity
[17] M. Rabbat, R. Nowak, and J. Bucklew, “Robust decentralized source Press,2022,vols.1–3.
localizationviaaveraging,”inProc.IEEEInternationalConferenceon [42] V.Shumovskaia,K.Ntemos,S.Vlaski,andA.H.Sayed,“Explainability
Acoustics,SpeechandSignalProcessing(ICASSP),vol.5,Philadelphia, and graph learning from social interactions,” IEEE Transactions on
PA,2005,pp.1057–1060. SignalandInformationProcessingoverNetworks,vol.8,pp.946–959,
[18] P. Hu, V. Bordignon, M. Kayaalp, and A. H. Sayed, “Non- 2022.
asymptoticperformanceofsocialmachinelearningunderlimiteddata,” [43] A.Kanezaki,Y.Matsushita,andY.Nishida,“Rotationnet:Jointobject
arXiv:2306.09397,2023. categorizationandposeestimationusingmultiviewsfromunsupervised
[19] V.Bordignon,V.Matta,andA.H.Sayed,“Sociallearningwithpartial viewpoints,”inProceedingsoftheIEEEconferenceoncomputervision
information sharing,” in IEEE International Conference on Acoustics, andpatternrecognition,2018,pp.5010–5019.
Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020, pp.
5540–5544.
[20] V.Shumovskaia,M.Kayaalp,M.Cemri,andA.H.Sayed,“Discovering
influencersinopinionformationoversocialgraphs,”IEEEOpenJournal
ofSignalProcessing,vol.4,pp.188–207,2023.
[21] V.Shumovskaia,M.Kayaalp,andA.H.Sayed,“Distributeddecision-
makingforcommunitystructurednetworks,”Proc.IEEEInternational
ConferenceonAcoustics,SpeechandSignalProcessing(ICASSP),pp.
1–5,April2024.
[22] ——, “Social learning in community structured graphs,”
arXiv:2312.12186,2023.
[23] A. Mitra, J. A. Richards, and S. Sundaram, “A new approach for
distributed hypothesis testing with extensions to byzantine-resilience,”
in American Control Conference (ACC), Philadelphia, PA, 2019, pp.
261–266.
[24] L. Su and N. H. Vaidya, “Defending non-bayesian learning against
adversarialattacks,”DistributedComputing,vol.32,pp.277–289,2019.