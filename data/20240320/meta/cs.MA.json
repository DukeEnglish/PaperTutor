[
    {
        "title": "Detection of Malicious Agents in Social Learning",
        "authors": "Valentina ShumovskaiaMert KayaalpAli H. Sayed",
        "links": "http://arxiv.org/abs/2403.12619v1",
        "entry_id": "http://arxiv.org/abs/2403.12619v1",
        "pdf_url": "http://arxiv.org/pdf/2403.12619v1",
        "summary": "Social learning is a non-Bayesian framework for distributed hypothesis\ntesting aimed at learning the true state of the environment. Traditionally, the\nagents are assumed to receive observations conditioned on the same true state,\nalthough it is also possible to examine the case of heterogeneous models across\nthe graph. One important special case is when heterogeneity is caused by the\npresence of malicious agents whose goal is to move the agents towards a wrong\nhypothesis. In this work, we propose an algorithm that allows to discover the\ntrue state of every individual agent based on the sequence of their beliefs. In\nso doing, the methodology is also able to locate malicious behavior.",
        "updated": "2024-03-19 10:40:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.12619v1"
    },
    {
        "title": "Embodied LLM Agents Learn to Cooperate in Organized Teams",
        "authors": "Xudong GuoKaixuan HuangJiale LiuWenhui FanNatalia VélezQingyun WuHuazheng WangThomas L. GriffithsMengdi Wang",
        "links": "http://arxiv.org/abs/2403.12482v1",
        "entry_id": "http://arxiv.org/abs/2403.12482v1",
        "pdf_url": "http://arxiv.org/pdf/2403.12482v1",
        "summary": "Large Language Models (LLMs) have emerged as integral tools for reasoning,\nplanning, and decision-making, drawing upon their extensive world knowledge and\nproficiency in language-related tasks. LLMs thus hold tremendous potential for\nnatural language interaction within multi-agent systems to foster cooperation.\nHowever, LLM agents tend to over-report and comply with any instruction, which\nmay result in information redundancy and confusion in multi-agent cooperation.\nInspired by human organizations, this paper introduces a framework that imposes\nprompt-based organization structures on LLM agents to mitigate these problems.\nThrough a series of experiments with embodied LLM agents and human-agent\ncollaboration, our results highlight the impact of designated leadership on\nteam efficiency, shedding light on the leadership qualities displayed by LLM\nagents and their spontaneous cooperative behaviors. Further, we harness the\npotential of LLMs to propose enhanced organizational prompts, via a\nCriticize-Reflect process, resulting in novel organization structures that\nreduce communication costs and enhance team efficiency.",
        "updated": "2024-03-19 06:39:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.12482v1"
    },
    {
        "title": "Online Multi-Agent Pickup and Delivery with Task Deadlines",
        "authors": "Hiroya MakinoSeigo Ito",
        "links": "http://arxiv.org/abs/2403.12377v1",
        "entry_id": "http://arxiv.org/abs/2403.12377v1",
        "pdf_url": "http://arxiv.org/pdf/2403.12377v1",
        "summary": "Managing delivery deadlines in automated warehouses and factories is crucial\nfor maintaining customer satisfaction and ensuring seamless production. This\nstudy introduces the problem of online multi-agent pickup and delivery with\ntask deadlines (MAPD-D), which is an advanced variant of the online MAPD\nproblem incorporating delivery deadlines. MAPD-D presents a dynamic\ndeadline-driven approach that includes task deadlines, with tasks being added\nat any time (online), thus challenging conventional MAPD frameworks. To tackle\nMAPD-D, we propose a novel algorithm named deadline-aware token passing (D-TP).\nThe D-TP algorithm is designed to calculate pickup deadlines and assign tasks\nwhile balancing execution cost and deadline proximity. Additionally, we\nintroduce the D-TP with task swaps (D-TPTS) method to further reduce task\ntardiness, enhancing flexibility and efficiency via task-swapping strategies.\nNumerical experiments were conducted in simulated warehouse environments to\nshowcase the effectiveness of the proposed methods. Both D-TP and D-TPTS\ndemonstrate significant reductions in task tardiness compared to existing\nmethods, thereby contributing to efficient operations in automated warehouses\nand factories with delivery deadlines.",
        "updated": "2024-03-19 02:40:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.12377v1"
    },
    {
        "title": "MARPF: Multi-Agent and Multi-Rack Path Finding",
        "authors": "Hiroya MakinoYoshihiro OhamaSeigo Ito",
        "links": "http://arxiv.org/abs/2403.12376v1",
        "entry_id": "http://arxiv.org/abs/2403.12376v1",
        "pdf_url": "http://arxiv.org/pdf/2403.12376v1",
        "summary": "In environments where many automated guided vehicles (AGVs) operate, planning\nefficient, collision-free paths is essential. Related research has mainly\nfocused on environments with static passages, resulting in space inefficiency.\nWe define multi-agent and multi-rack path finding (MARPF) as the problem of\nplanning paths for AGVs to convey target racks to their designated locations in\nenvironments without passages. In such environments, an AGV without a rack can\npass under racks, whereas an AGV with a rack cannot pass under racks to avoid\ncollisions. MARPF entails conveying the target racks without collisions, while\nthe other obstacle racks are positioned without a specific arrangement. AGVs\nare essential for relocating other racks to prevent any interference with the\ntarget racks. We formulated MARPF as an integer linear programming problem in a\nnetwork flow. To distinguish situations in which an AGV is or is not loading a\nrack, the proposed method introduces two virtual layers into the network. We\noptimized the AGVs' movements to move obstacle racks and convey the target\nracks. The formulation and applicability of the algorithm were validated\nthrough numerical experiments. The results indicated that the proposed\nalgorithm addressed issues in environments with dense racks.",
        "updated": "2024-03-19 02:39:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.12376v1"
    },
    {
        "title": "Information Compression in Dynamic Information Disclosure Games",
        "authors": "Dengwang TangVijay G. Subramanian",
        "links": "http://arxiv.org/abs/2403.12204v1",
        "entry_id": "http://arxiv.org/abs/2403.12204v1",
        "pdf_url": "http://arxiv.org/pdf/2403.12204v1",
        "summary": "We consider a two-player dynamic information design problem between a\nprincipal and a receiver -- a game is played between the two agents on top of a\nMarkovian system controlled by the receiver's actions, where the principal\nobtains and strategically shares some information about the underlying system\nwith the receiver in order to influence their actions. In our setting, both\nplayers have long-term objectives, and the principal sequentially commits to\ntheir strategies instead of committing at the beginning. Further, the principal\ncannot directly observe the system state, but at every turn they can choose\nrandomized experiments to observe the system partially. The principal can share\ndetails about the experiments to the receiver. For our analysis we impose the\ntruthful disclosure rule: the principal is required to truthfully announce the\ndetails and the result of each experiment to the receiver immediately after the\nexperiment result is revealed. Based on the received information, the receiver\ntakes an action when its their turn, with the action influencing the state of\nthe underlying system. We show that there exist Perfect Bayesian equilibria in\nthis game where both agents play Canonical Belief Based (CBB) strategies using\na compressed version of their information, rather than full information, to\nchoose experiments (for the principal) or actions (for the receiver). We also\nprovide a backward inductive procedure to solve for an equilibrium in CBB\nstrategies.",
        "updated": "2024-03-18 19:40:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.12204v1"
    }
]