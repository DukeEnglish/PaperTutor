Hypergraph-based Motion Generation with Multi-modal
Interaction Relational Reasoning
KeshuWua,b,YangZhoub,∗,HaotianShic,∗,DominiqueLordb,BinRanc,XinyueYea
aCenterforGeospatialSciences,Applications,andTechnologyandDepartmentofLandscapeofArchitectureand
UrbanPlanning,TexasA&MUniversity,788RossSt,CollegeStation,77840,TX,UnitedStates
bZachryDepartmentofCivilandEnvironmentalEngineering,TexasA&MUniversity,201DwightLookEngineering
Building,CollegeStation,77843,TX,UnitedStates
cDepartmentofCivilandEnvironmentalEngineering,UniversityofWisconsin-Madison,1415Engineering
Dr,Madison,53706,WI,UnitedStates
Abstract
The intricate nature of real-world driving environments, characterized by dynamic and diverse
interactions among multiple vehicles and their possible future states, presents considerable chal-
lengesinaccuratelypredictingthemotionstatesofvehiclesandhandlingtheuncertaintyinherent
in the predictions. Addressing these challenges requires comprehensive modeling and reasoning
to capture the implicit relations among vehicles and the corresponding diverse behaviors. This
research introduces an integrated framework for autonomous vehicles (AVs) motion prediction to
address these complexities, utilizing a novel Relational Hypergraph Interaction-informed Neural
mOtiongenerator(RHINO).RHINOleverageshypergraph-basedrelationalreasoningbyintegrating
a multi-scale hypergraph neural network to model group-wise interactions among multiple vehi-
cles and their multi-modal driving behaviors, thereby enhancing motion prediction accuracy and
reliability. Experimental validation using real-world datasets demonstrates the superior perfor-
manceofthisframeworkinimprovingpredictiveaccuracyandfosteringsociallyawareautomated
drivingindynamictrafficscenarios.
Keywords: Interactionrepresentation,hypergraph,relationalreasoning,multi-modalprediction,
motionprediction,motiongeneration
1. Introduction
Understanding traffic interactions and the way they affect future vehicle trajectories is inher-
ently complex [1]. In mixed traffic environments, where human-driven and automated vehicles
coexist, this complexity is amplified, requiring precise interaction representation and behavior
modeling for reliable motion prediction [2, 3, 4]. These scenarios often present dynamic inter-
action topologies with underlying relations, with interaction patterns as well topologies contin-
uously evolving depending on the surrounding context as exampled by lane change maneuvers
∗Correspondingauthors:YangZhou(yangzhou295@tamu.edu),HaotianShi(hshi84@wisc.edu);
PreprintsubmittedtoElsevier September19,2024
4202
peS
81
]OR.sc[
1v67611.9042:viXra[5, 6]. These relationships play a crucial role in guiding each vehicle’s decision-making pro-
cesses. Additionally, each vehicle can display multiple possible modalities in driving intentions
and behaviors, including both longitudinal (e.g., acceleration and braking) and lateral (e.g., lane-
changing and lane-keeping) maneuvers [7, 8]. Furthermore, collective behaviors, arising from
interactions within a group of vehicles and encompassing both cooperative and competitive be-
haviors[9,10,12,11],furthercomplicatetheunderstandingoftheseinteractions[13,14,15]. Fig-
ure 1 describes the interaction among multi-vehicles and the corresponding multi-modal driving
behaviors. Therefore,itisnecessarytomodeltheinteractionandmulti-modalityandreasonthein-
teractionrelationtoaccuratelycaptureinteractionsandforecasttheirfuturebehaviors[16,17,18].
Figure1: Majorchallenges: (a)vehicleinteraction,(b)behaviormulti-modality,and(c)interactionrelationalreason-
ing.
Efforts have been made to address the challenges of vehicle interactions and driving behav-
ior multi-modality. Three primary approaches have been developed: social operation methods,
attention-driven methods, and graph-based techniques. Social operations use pooling mecha-
nismstogeneratesociallyacceptabletrajectoriesbycapturingtheinfluenceofsurroundingagents
[20, 21]. Attention-driven approaches use attention mechanisms to dynamically weigh neighbor-
ing agents’ information [22, 23, 24]. Graph-based methods leverage graph structures to model
non-Euclidean spatial dependencies, effectively handling varying interaction topologies and pre-
dictingdynamicinteractions[25,26,27,28]. Thesecomplexinteractionscreateuncertainty,com-
plicatingtheaccurateforecastingofasinglefuturetrajectorywithhighconfidenceduetovarying
driving behaviors in identical situations [29, 30], driven by individual driver characteristics and
psychological factors. Addressing the multi-modality of driving behaviors often involves intro-
ducing latent variables, categorized into those with explicit semantics and those without. Mod-
els with explicit semantics use latent variables to clearly represent driving intentions, identifying
2specific maneuvers and behaviors for multi-modal trajectory predictions [30, 31, 32]. Conversely,
modelswithoutexplicitsemanticsemploygenerativedeeplearningtechniques,suchasVariational
Autoencoders(VAEs)[33]andGenerativeAdversarialNetworks(GANs)[21,34],toproducedi-
verse trajectories by adding noise to encoded features. While these models generate a wide range
of possible trajectories, they often struggle with issues related to interpretability and identifying
themosteffectivestrategiesforsamplingfromthegeneratedtrajectories.
Despite the advances in modeling vehicle interactions and probabilistically forecasting multi-
modal future trajectories, the inherent complexity of social dynamics in traffic systems continues
to present significant challenges, with limitations arising from the complex nature of agent in-
teractions in two key aspects: First, prevailing methods primarily focus on pair-wise interactions
rather group-wise interactions. In multi-vehicle systems, dynamic interactions among vehicles
often exhibit cooperative and competitive behaviors [9, 10, 35, 36], which have been rarely ex-
plored. Effectively capturing the collective influence of vehicle groups is vital for understanding
complex social dynamics, especially in scenarios where vehicles engage in multi-modal behav-
iors such as lane changes, acceleration, and deceleration. In such contexts, vehicles need to make
decisions based on the actions and intentions of several surrounding agents simultaneously, fur-
ther complicating the task of accurate behavior prediction. For example, competitive behaviors,
such as overtaking and lane-changing, can lead to conflicting objectives between vehicles. In the
lane changing scenario as depicted in Figure 2, vehicle 1 attempts a right lane change (R) while
vehicle 3 maintains lane-keeping (K) and vehicle 4 performs a left lane change (L). Conversely,
cooperative interactions, such as car-following, are illustrated by vehicles 1, 3, and 4 forming a
platoon,allmaintaininglane-keepingwhilepotentiallyrespondingtovehicle2’sleftlanechange.
Theseexampleshighlighttheneedformodelsthatcaneffectivelycapturethecomplexitiesofboth
individualandgroupdynamicsinmulti-modaltrafficscenarios.
Second, while traditional graph-based methods such as [25, 26, 27, 37] excel at capturing
pair-wiserelationships,theyarelimitedinrepresentingthemoreintricategroup-wiseinteractions.
Thislimitationarisesbecausegraph-basedapproachesmodelinteractionsbetweenpairsofagents
with fixed topologies, making it difficult to capture the simultaneous influence of multiple agents
on each other’s behaviors. Unlike standard graphs, where each edge connects only two nodes,
hypergraphs are capable of connecting an entire group of nodes within a shared context through a
single hyperedge [38, 39]. As a result, a hypergraph, which is a generalization of a graph where
hyperedges can connect multiple nodes to represent the higher-order relationships, offers a more
accurate reflection of the group-wise interactions and allows for a more accurate representation
of the collective influence of multiple agents in varying traffic conditions. This adaptability is
essential for addressing the stochastic nature of human behavior, as hypergraph models can more
effectively manage the uncertainty and variability inherent in the interactions resulting from col-
lectivebehaviors,therebyfacilitatingmoresociallyinspiredautomateddriving[40,41,42].
Toaddresstheaforementionedchallenges,thispaperpresentsanovelhypergraph-basedmethod
for multi-modal trajectories prediction with relational reasoning. The proposed framework con-
tainstwoparts: Graph-basedInteraction-awaReAnticipativeFeasibleFutureEstimator(GIRAFFE)
andRelationalHypergraphInteraction-informedNeuralmOtiongenerator(RHINO).GIRAFFEen-
ables multi-agent, multi-modal motion prediction of preliminary multi-vehicle trajectories, based
on while RHINO framework, which utilizes an innovative Agent-Behavior Hypergraph to cap-
3Figure2: Pair-wiseinteractionandgroup-wiseinteractionindifferentscenarios.
ture group-wise interactions among various behavior modalities and motion states. Leveraging
GroupNet [41] as its backbone, RHINO learns a multi-scale hypergraph topology in a data-driven
mannertomodelgroup-wiseinteractions. Throughneuralmessagepassingacrossthehypergraph,
this approach integrates interaction representation learning and relational reasoning, enhancing
the social dynamics of automated driving. Furthermore, a Conditional Variational Autoencoder
(CVAE) framework is employed to generate diverse trajectory predictions by sampling from hid-
4denfeaturedistributions,effectivelyaddressingthestochasticnatureofagentbehaviors.
Tosummarize,thekeycontributionsofthisworkareasfollows:
1. The framework adopts multi-scale hypergraphs to represent group-wise interactions among
different modalities of driving behavior and the corresponding motion states of multiple
agentsinaflexiblemanner.
2. This framework incorporates interaction representation learning and relational reasoning to
generate motions that are plausible and concurrently in a probabilistic manner depicted by
thelearnedposteriordistribution.
The remainder of this paper is structured as follows: Section 2 outlines the problem statement
of this research. Section 3 introduces the methodology. Section 4 details the experimental setup
andanalysisoftheresultsobtained. Section5concludesthispaper.
2. ProblemStatement
2.1. ProblemDefinition
The vehicle trajectory prediction in the dynamic realm of multi-vehicle interaction context
of multi-lane highways involves determining the future movements of a target vehicle based on
historicaldataandmulti-modalpredictionsofitsownstateandthestatesofsurroundingvehicles.
This domain addresses two primary challenges: (i) multi-agent multi-modal trajectory prediction
and(ii)prediction-guidedmotiongenerationafterreasoning.
The objective of trajectory prediction is to estimate the future trajectories of the target vehicle
and its surrounding vehicles, given their historical states. The historical states, spanning a time
horizon [1,...,T], are represented as X = {X ,X ,...,X } ∈ RT×N×C1, where N denotes the
1:T 1 2 T
number of vehicles and C denotes the number of features, including longitudinal and lateral
1
positions and velocities. Each historical state X = {xi|∀i ∈ [1,N],∀t ∈ [1,T]} ∈ RC1 at time step
t t
t captures these details for each vehicle i. Notably, the superscript refers to vehicle indices with
i = 1representingthetargetvehicle,andthesubscripttotimesteps,withC = 4fortheinputdata.
1
Thepredictionmodel,HPred(·),providespreliminarypredictionsofmulti-modaltrajectorycan-
didatesXˆM ∈ RF×N×M×C2 foralltheN vehiclesoverthefuturetimehorizon[T+1,...,T+F]
T+1:T+F
with M modesofdrivingbehaviors. ThismodeltakeshistoricaldataX astheinputandoutputs
1:T
future longitudinal and lateral positions, where C = 2. The forecasted states XˆM = {xm,i|∀m ∈
2 f f
[1,M],∀i ∈ [1,N],∀f ∈ [1,F]} aim to estimate each vehicle’s future trajectory for each behavior
modemattimestepT + f. Thisismathematicallyformulatedas:
XˆM = HPred(X ) (1)
T+1:T+F 1:T
Based on that, the motion generation model HGen(·) is further developed to generate plausible
trajectories considering the implicit group-wise interactions, using both historical states X and
1:T
preliminary multi-modalfuture trajectory candidatesXˆM as theinput. The generation model
T+1:T+F
providesK plausibletrajectoryYˆK = {YˆK ,...,YˆK } ∈ RF×N×K×C2 foralltheN vehiclesfor
T+1:T+F T+1 T+F
the next F time steps. Each generated state YˆK = {yˆk,i |∀k ∈ [1,K],∀i ∈ [1,N],∀f ∈ [1,F]} ∈
T+f T+f
5RC2 represents the k-th generated longitudinal and lateral potisions of the i-th vehicle at time step
T + f. Theformulationforthisgenerationproblemis:
YˆK = HGen(X ,XˆM ) (2)
T+1:T+F 1:T T+1:T+F
3. Methodology
Given the aforementioned problem, we first develop a customized framework architecture.
Then,thevitalcomponentsarefurtherelaborated.
3.1. FrameworkArchitecture
The proposed framework adopts an integrated architecture, as shown in Figure 3, which in-
volvestwomajorcomponents:
• GIRAFFE: Graph-based Interaction-awaRe Anticipative Feasible Future Estimator, which
leverages graph representations to capture pair-wise interactions during both the historical
and future time horizons, providing preliminary multi-modal trajectories prediction candi-
datesforvehicles.
• RHINO: Relational Hypergraph Interaction-informed Neural mOtion generator, which uti-
lizes multi-scale hypergraph representations to model group-wise interactions and reason
theinteractionrelationsamongthemulti-modalbehaviors. Builtuponthepreliminarymulti-
modal trajectories by GIRAFFE, RHINO will further generate plausible future trajectories
forallvehiclesinaprobabilisticmanner.
Thesubsequentsectionswillprovideanin-depthexplanationofthetwoprincipalframeworks.
3.2. GIRAFFE:Graph-basedMotionPredictor
In our context, a graph representation G is adopted by modeling N vehicles as nodes V ∈ RN
and the pair-wise interaction as the edges E ∈ R|N×N|. Further, The feature matrix X ∈ RN×C
containingvehiclestates(i.e.,longitudinalandlateralpositionandspeed)andtheadjacencymatrix
A ∈ RN×N describing the interactions among nodes are further utilized to describe the graph. By
that,wecandefineanAgentGraphas:
Definition1(AgentGraph). LetGa beagraphrepresentingthemotionstatesandinteractionof
N agents,witheachagentrepresentedasanode. Ga isexpressedas
Ga = (Va,Ea;Xa,Aa)
where Va ∈ RN denotes the node set, Ea ∈ R|N×N| denotes the edge set, Xa ∈ RN×C represents the
featuretensor, Aa ∈ RN×N indicatestheadjacencymatrix.
To better represent the interaction and relations of the predicted multi-agent multi-modal tra-
jectory candidates with graphs, we expand each agent node to multiple nodes of the number of
behaviormodesbasedonourpreviouswork[25],whichfurtherrendersanAgent-BehaviorGraph.
6Figure3: Frameworkarchitecture.
Definition2(Agent-BehaviorGraph). LetGb beagraphrepresentationofthemulti-modalmo-
tion states of N agents, with each of M behavior modes for each agent represented as a node. Gb
isexpressedas
Gb = (Vb,Eb;Xb,Ab)
where Vb ∈ R|MN| denotes the node set, Eb ∈ R|MN×MN| denotes the edge set, Xb ∈ R|MN|×C
representsthefeaturetensor, Ab ∈ R|MN|×|MN| indicatestheadjacencymatrix.
The transition from an Agent Graph Ga to an Agent-Behavior Graph Gb is by an expansion
functionFexpand(·)as:
7
Gb = Fexpand(Ga) ⇔
V
Eb
b
=
=
(cid:91)
(cid:91)i i=
=N
N1
1
(cid:91)
(cid:91)m
jM
=N=
11(cid:110)
(cid:110)v
eb
ib
i, jm
,m(cid:111)
n
| Aa
ij
(cid:44) 0andΛ
mn
(cid:44) 0,∀m,n ∈
{1,...,M}(cid:111)
(3)

X Ab
b
=
=
(cid:91) (cid:91)i=N
N1
(cid:91) (cid:91)mM
N=1
(cid:110)X Aia
,
a
im
j
⊗Λ
mn
| ∀m,n ∈
{1,...,M}(cid:111)
i=1 j=1
AsshowninFigure4,inthisprocess,eachagentnodeva ∈ Va intheAgentGraphisexpanded
i
into M behavior-specificnodesvb ∈ Vb,correspondingtothe M potentialbehavioralmodesofthe
i
vehicle. Thesenewlygeneratedbehaviornodes,whichmayexhibitsignificantinterdependencies,
areinterconnectedthroughedgeseb,formingamorecomplexinteractionstructure. Consequently,
ij
theadjacencymatrix Ab isextendedtoaccommodatetheexpandednodeset,resultinginincreased
dimensionality. Here, Λ is a behavior correlation matrix, and each element Λ in the matrix
mn
representsthecorrelationbetweenbehaviormodemofoneagentandbehaviormodenofanother
agent. The feature tensor Xb of the behavior nodes encodes the possible motion states under each
behavioralmode,capturingthemulti-modalnatureofvehiclebehavior.
Figure4: Definitionsofgraphs
Based on that, a deep neural network is designed to capture interactions between the target
vehicle and surrounding vehicles by Ga, and to represent the output, which consists of predicted
multi-agent multi-modal trajectories, by Gb, as illustrated in Figure 5. Three key modules of
GIRAFFEHPred(·)areintroducedbelow:
Interaction Encoder. The Interaction Encoder utilizes a Diffusion Graph Convolution Network
(DGCN)architecturetoencodethedynamicgraphembeddings,asdescribedinAppendix B.The
DGCN captures the bidirectional dependencies among vehicles by applying diffusion convolu-
tions, which consider both forward and reverse processes to model the influence of surrounding
8Figure5: GIRAFFEFramework.
vehiclesandthetargetvehicle’simpactonthem[43,44]. ThisencoderadoptsaDGCN (·)togen-
H
erategraphembeddingsforhistoricalofanda DGCN (·)togeneratefutureembeddings,merging
F
themintoacomprehensiverepresentationthatspanstheentiretimewindowofinterest.
H˜ = DGCN (X ) (4)
T H T
H˜ = DGCN (X ) (5)
F F T
H˜ = [H˜ ,H˜ ] (6)
T F
9Intention Predictor. The Intention Predictor addresses the classification of future driving inten-
tions, both laterally and longitudinally. Using the encoded graph representation, two MLP layers
reduce the dimensions and encode the features into a latent space. The LatMLP layers with soft-
max activation then classify the lateral intentions over the future time horizon. These predictions
help in understanding the potential maneuvers the vehicle might take, such as lane changes or
speedadjustments.
H˜IP = MLP(MLP(H˜)) (7)
mˆlat = softmax(LatMLP(H˜IP)) (8)
Multi-modal Decoder. Finally, the Multi-modal Decoder fuses the predicted intentions of multi-
ple agents with the latent space to produce multiple future trajectory distributions for each agent.
Thisdecoderusesatrainableweightmatrixtocombinefeaturesfromdistincthistoricalandfuture
time steps, emphasizing the importance of sequential motion patterns. The GRU-based decoder
ensurestemporalcontinuityin thepredictedtrajectories,mappingthefused featurestoabivariate
Gaussiandistributionrepresentingthefuturevehiclepositions. Thisapproachallowsthemodelto
generateprobabilisticpredictionsformultipleagents.
W = softmax(W ⊗ Mˆ) (9)
hid map
H = W ·H˜ (10)
dec hid
XˆM = MLP(GRU(MLP(H ,Mˆ))) (11)
T+1:T+F dec
3.3. RHINO:Hypergraph-basedMotionGenerator
Unlike traditional graph representations, which are confined to pair-wise relationships, hy-
pergraphs offer a more sophisticated and comprehensive framework for representing group-wise
interactions. Byconnectingmultiplevehiclesthatexhibitstrongcorrelationsthroughhyperedges,
hypergraphs enable a more robust analysis and optimization of the complex network of interac-
tions. The concept of an Agent Hypergraph to represent agents and their group-wise interactions
isintroducedasfollows:
Definition3(AgentHypergraph). Let Hb be a hypergraph representation of the motion states
of N agents,witheachagentrepresentedasanode. ThehypergraphHa isexpressedas
Ha = (Va,Ua;Xa,Ha)
where Va ∈ RN denotes the node set, Ua ∈ RL denotes the edge set, Xa ∈ RN×C represents the
feature tensor, Ha ∈ RN×L indicates the incidence matrix, where Ha indicates whether node v is
ij i
partofthehyperedgeu .
j
To convert an Agent Graph Ga into an Agent Hypergraph Ha, we introduce a transformation
function Ftransform(·). This function enables the shift from a pairwise interaction framework to
a higher-order interaction model represented by the hypergraph. Formally, the transformation is
expressedas:
10Figure6: Definitionsofgraphsandhypergraphs

Ha = Ftransform(Ga) ⇔
UVa
a
=
=
(cid:91)
(cid:91)i j=
=N
K1
1{ (cid:110)v ua
i
a
j}
| ua
j
⊆ Va,Λ
uj
(cid:44)
0(cid:111)
(12)
HX
aa ==
(cid:91)(cid:91)
i=
NN
1
(cid:91)X Kia
(cid:110)
H ia
j
| va
i
∈ ua
j(cid:111)
i=1 j=1
In this transformation, the node set Va and the feature tensor Xa remain consistent between
the graph and the hypergraph representations. However, the primary modification occurs in the
edge formulation. The transformation replaces the pairwise edges of the original Agent Graph
with hyperedges that can connect multiple nodes simultaneously. This redefinition of edges as
hyperedges within the hypergraph Ha allows for the modeling of group-wise interactions, where
a single hyperedge u ∈ Ua can link more than two nodes, capturing higher-order relationships
among agents. The incidence matrix Ha is updated to reflect this change, where each entry Ha
ij
11indicates whether agent v participates in hyperedge u . As a result, Ha can represent multi-
i j
agentinteractionsthatinvolvemultipleagentssimultaneously,providingaricherandmoreflexible
structureformodelingthedynamicsofthesystem.
Toenhancetheunderstandingofcomplexgroup-wiseinteractionsinmulti-agentsystems,itis
essential to extend the traditional Agent Hypergraph model to account for the diverse behavioral
modes of each agent. This is achieved by decomposing each agent node in the Agent Hypergraph
Ha into multiple behavior-specific nodes, which correspond to the different modes of behavior
each agent can exhibit. The result of this decomposition is the Agent-Behavior Hypergraph, de-
notedasHb.
Definition4(Agent-BehaviorHypergraph). LetHbbeahypergraphrepresentationofthemulti-
modal motion states of N agents, with each of M behavior modes for each agent represented as a
node. ThehypergraphHb isexpressedas
Hb = (Vb,Ub;Xb,Hb)
where Vb ∈ R|MN| denotes the node set, Ub ∈ RL denotes the edge set, Xb ∈ R|MN|×C represents
the feature tensor, Hb ∈ R|MN|×L indicates the incidence matrix, where Hb indicates whether node
ij
v ispartofthehyperedgeu .
i j
To formally describe the process of transitioning from an Agent Hypergraph Ha to an Agent-
Behavior Hypergraph Hb, the expansion function Fexpand(·) is applied. This function decomposes
each agent node into multiple behavior-specific nodes and updates the hyperedge structure ac-
cordingly. The behavior-specific nodes correspond to the different behavior modes, while the
hyperedgesrepresentthehigher-orderinteractionsamongthebehaviormodesofdifferentagents.

Hb = Fexpand(Ha) ⇔
UVb
b
=
=
(cid:91)
(cid:91)i j=
=N
L1
1
(cid:91)
(cid:91)m
mM
M= =1
1(cid:110)
(cid:91)
nv
M
=b
i 1,m
(cid:110)(cid:111)
ub
j,mn
| ua
j
(cid:44) 0andΛ
mn
(cid:44)
0(cid:111)
(13)
HXb
b
=
=
(cid:91) (cid:91)Mi=N
N1
(cid:91) (cid:91)mM
L=1
(cid:110)X Hia
,m
ib
j
| vb
i,m
∈ ub
j,mn(cid:111)
i=1 j=1
The node set Vb expands each agent vb into multiple behavior-specific nodes vb , where each
i i,m
mrepresentsadifferentbehavioralmodeoftheagent. ThehyperedgesUb areformedbetweenthe
behavior-specific nodes based on the group-wise interactions present in the original hypergraph,
with the correlation between behavior modes captured by Λ . The feature tensor Xb captures
mn
the state of each behavior node, inheriting the feature data from the original hypergraph.The in-
cidence matrix Hb records whether a behavior-specific node vb is part of a hyperedge ub . In
i,m j,mn
12thisextendedframework,hyperedgescanrepresenttheseaforementionedcomplexgroup-wisein-
teractions by connecting behaviors of multiple vehicles that are influenced simultaneously by a
shared context, as illustrated in Figure 6. Therefore, an Agent-Behavior Hypergraph is defined to
modelthemulti-agent,multi-modalsystemforreasoningaboutgroup-wiseinteractionrelations.
Inadditiontotheexpansionprocess,thetransformationfunctionFtransform(·)convertsanAgent-
Behavior Graph Gb into an Agent-Behavior Hypergraph Hb. This transformation replaces the
pairwise edges of the graph with hyperedges that capture higher-order interactions between be-
havior modes across multiple agents. The transformation is guided by the adjacency matrix Ab
of the original graph and the behavior-mode correlation matrix Λ . The transformation function
mn
Ftransform(·)isexpressedas:

Hb =
Ftransform(cid:16) Gb(cid:17)
⇔
UVb
b
=
=
(cid:91)
(cid:91)i j=
=N
L1
1
(cid:91)
(cid:91)m
mM
M= =1
1(cid:110)
(cid:91)
nv
M
=b
i 1,m
(cid:110)(cid:111)
ub
j,mn
| Ab
ij
(cid:44) 0andΛ
mn
(cid:44)
0(cid:111)
(14)
HXb
b
=
=
(cid:91) (cid:91)Mi=N
N1
(cid:91)X Lib
(cid:110)
H ib
j
| vb
i,m
∈ ub
j,mn(cid:111)
i=1 j=1
This structure allows for the connection of behavior nodes across different agents, enabling
the representation of interactions among diverse behaviors of multiple agents in a shared context.
Hence,theAgent-BehaviorHypergraphnotonlycapturestheindividualbehaviorofeachagentbut
alsomodelshowthesebehaviorsinteractandinfluenceoneanotherwithinamulti-agentsystem.
3.3.1. RHINOFrameworkArchitecture
ThecoreofRHINOistolearnamulti-scaleAgent-BehaviorHypergraph,wherenodesrepresent
the behaviors of agents and hyperedges capture their group-wise interactions. This hypergraph is
then used to learn agent and interaction embeddings to better understand the underlying interac-
tion relations. We also incorporate a basic multi-agent trajectory generation system based on the
CVAEframeworktohandlethestochasticityofeachagent’spotentialbehaviorsandmotionstates,
generatingplausibletrajectoriesforeachvehicle.
Thus,asillustratedinFigure7,RHINOcomprisesthefollowingmodules:
• Hypergraph Relational Encoder, which transforms both the original historical states and
predicted multi-agent multi-modal trajectories into hypergraphs, modeling and reasoning
theunderlyingrelationbetweenthevehicles.
• PosteriorDistributionLearner,whichcapturestheposteriordistributionofthefuturetra-
jectory given the historical states and the predicted multi-modal future motion states of all
thevehiclesinthevehiclegroup.
13Figure7: RHINOFramework.
• Motion Generator, which decodes the embeddings by concurrently reconstructing the his-
toricalstatesandgeneratingthefuturetrajectories.
3.3.2. HypergraphRelationalEncoder
We employ two Hypergraph Relational Encoder modules: a Historical Hypergraph Relational
Encoder for handling historical states and a Future Hypergraph Relational Encoder for predicted
multi-agentmulti-modaltrajectoriesfromGIRAFFE.FortheHistoricalHypergraphRelationalEn-
coder, the input historical states X form an Agent Hypergraph Ha. For the Future Hypergraph
T T
Relational Encoder, the predicted multi-agent multi-modal trajectories Xˆ form an Agent-
T+1:T+F
Behavior Hypergraph Hb, where each agent node is expanded into three lateral behavior nodes
F
with corresponding predicted future states. Both modules share the same structure regardless of
theinputhypergraphtypes.
Multi-scaleHypergraphTopologyInference. Tocomprehensivelymodelgroup-wiseinteractions
in the hypergraphs at multiple scales, we infer a multi-scale hypergraph to reflect interactions
in groups with various sizes. Let H = {H(0),H(1),··· ,H(S)} be a multi-scale hypergraph, and
V = {v ,v ,··· ,v } be a set of nodes. As shown in Figure 8, at any scale s, H(s) = (V,U(s)) has
1 2 N
ahyperedgesetU(s) = {u(s),u(s),··· ,u(s)}representinggroup-wiserelationswith J hyperedges. A
1 2 J
larger sindicatesalargerscaleofagentgroups,whileH(0) = (V,U(0))modelsthefinestpair-wise
agentconnections. ThetopologyofeachH(s) isrepresentedasanincidencematrix H(s).
Tounderstandandquantifythedynamicinteractionsbetweenagentswithinagivensystem,we
adopt trajectory embedding to distill the motion states of agents into a compact and informative
representation. To infer a multi-scale hypergraph, we construct hyperedges by grouping agents
that have highly correlated trajectories, whose correlations could be measured by mapping the
14Figure8: Hypergraphencoder.
trajectories as a high-dimensional feature vector. For the i-th agent in the system, the trajectory
embedding is denoted as q. This embedding is a function of the agent’s motion states, defined
i
over a temporal window extending from time 1 to time T. The embedding function f , which
q
is a trainable MLP, is responsible for transforming the motion states Xi into a vector q ∈ Rd,
i
where d is the dimensionality of the embedded space. Mathematically, the trajectory embedding
isrepresentedas:
q = f (Xi) (15)
i q
TheaffinitybetweenagentsisrepresentedbyanaffinitymatrixA ∈ RN×N,whichcontainsthe
pairwiserelationalweightsbetweenallagents. Theaffinitymatrixisdefinedas:
A = {A |∀i, j = 1,...,N} (16)
ij
EachelementA iscomputedasthecorrelationbetweenthetrajectoryembeddingsofthei-th
ij
and j-th agents. The correlation is the normalized dot product of the two trajectory embeddings,
expressedas:
q⊤q
A = i j (17)
ij ∥q∥ ∥q ∥
i 2 j 2
Here,∥·∥ denotestheL2norm. TherelationalweightA measuresthestrengthofassociation
2 ij
between the trajectories of the i-th and j-th agents, capturing the degree to which their behaviors
15are correlated. This enables the assessment of interaction patterns and can uncover underlying
socialorphysicallawsgoverningagentdynamics.
Theformulationofahypergraphnecessitatesthestrategicformationofhyperedgesthatreflect
the complex interaction between the nodes in the system. At the outset, the 0-th scale hyper-
graph H(0) is considered, where the construction is based on pair-wise connections. Each node
establishesalinkwithanothernodethathasthehighestaffinityscorewithit.
Asthecomplexityofthesystemisscaledup,beginningatscale s ≥ 1,themethodologyshifts
towardsgroup-wiseconnections. Thisshiftisbasedontheintuitionthatagentswithinaparticular
group should display strong mutual correlations, suggesting a propensity for concerted action.
To implement this, a sequence of increasing group sizes {J(s)}S is established. For every node,
s=1
denoted by v, the objective is to discern a group of agents that are highly correlated, ultimately
i
leading to J(s) groups or hyperedges at each scale s. The hyperedge associated with a node v at
i
a given scale s is indicated by u(s). The determination of the most correlated agents is framed
i
as an optimization problem, aiming to link these agents into a hyperedge that accounts for group
dynamics:
(cid:13) (cid:13)
u( is) = argmax(cid:13) (cid:13)A Γ,Γ(cid:13) (cid:13)
1
(18)
Γ⊆V
s.t. |Γ| = J(s);v ∈ Γ;i = 1,...,N (19)
i
The culmination of this hierarchical structuring is a multi-scale hypergraph, encapsulated by
the set {H(s) ∈ RN×N}S , where each scale s embodies a distinct layer of abstraction in the repre-
s=1
sentationofnoderelationshipswithinthehypergraph.
Hypergraph Neural Message Passing. In order to discern the patterns of agent motion states
from the inferred multi-scale hypergraph, we have tailored a multi-scale hypergraph neural mes-
sage passing technique to construct the hypergraph topology. This method iteratively acquires
the embeddings of vehicles and the corresponding interactions through node-to-hyperedge and
hyperedge-to-nodeprocesses,asdepictedinFigure9.
Thenode-to-hyperedgemappingaggregatesagentembeddingstogenerateinteractionembed-
dings. Initially,foranygivenscale,theinitialembeddingfortheithagent,v = q ∈ Rd. Eachnode
i i
v is associated with a hyperedge u, given that v is an element of u. This mapping facilitates the
j i j i
definitionofthehyperedgeinteractionembedding. Thehyperedgeinteractionembeddingforahy-
peredge u is defined as a function of the embeddings of the nodes contained within it, modulated
i
by the neural interaction strength r and categorized through coefficients c . The per-category
i i,l
function F models the interaction process for each category, which is crucial for capturing the
l
nuances of different interaction types. Each F is a trainable MLP, responsible for processing the
l
aggregated node embeddings within the context of a specific interaction category. The mathemat-
icalformulationis:
 
u
i
= r
i(cid:88)L
c i,lF
l(cid:88)
v
j
(20)
l=1 vj∈ui
16Figure9: Hypergraphencoder.
The neural interaction strength r encapsulates the intensity of the interaction within the hy-
i
peredge and is obtained through a trainable model F , applied to a collective embedding z with a
r i
sigmoid function σ as Eq.(21). This collective embedding z is represented as the weighted sum
i
oftheindividualnodeembeddingswithinthehyperedge,signifyingtheaggregatedinformationof
agents in a group as Eq. (22). The weight w for each node is determined by a trainable MLP F
j w
asEq.23.
r = σ(F (z)) (21)
i r i
(cid:88)
z = w v (22)
i j j
vj∈ui
 
w
j
= F
wv
j,
(cid:88)
v
m
(23)
vm∈ui
The neural interaction category coefficient c represent the model’s reasoning about which
i
type of the interaction is likely for hyperedge u , where c denotes the probability of the l-th
j i,l
neural interaction category within L possible categories. These coefficients are computed using a
softmax function applied to the output of another trainable MLP F , which is further adjusted by
c
ani.i.d. sampleGumbeldistributiongasdescribedinAppendix C.whichaddsomerandomnoise
andatemperatureparameterτwhichcontrollsthesmoothnessofprobabilitydistribution[45]:
17(cid:32) (cid:33)
F (z)+g
c = softmax c i (24)
i
τ
Thesecomponents,includingneuralinteractionstrength,interactioncategorycoefficients,and
per-category functions, provide a comprehensive mechanism for reasoning over complex, higher-
order relationships, allowing the model to adapt its understanding of how agents collectively be-
haveindiversescenarios.
The process of hyperedge-to-node mapping is a pivotal step that allows for the update and
refinement of agent embeddings within the hypergraph framework. Each hyperedge u is mapped
j
back onto its constituent nodes v, assuming every v is included in u . The primary objective of
i i j
thisphaseistoupdatetheembeddingofanagent. ThisisachievedthroughthefunctionF ,which
v
is a trainable MLP. The updated agent embedding v˜ is the result of the function applied to the
i
concatenation of the agent’s current embedding and the sum of the embeddings of all hyperedges
thattheagentispartof. Formally,theupdaterulefortheagentembeddingisrepresentedas:
 
v˜
i
← F
vv
i,
(cid:88)
u
j
(25)
uj∈U
i
where U = {u |v ∈ u } denotes the set of hyperedges associated with the i-th node v, and
i j i j i
[·,·] symbolize the operation of embedding concatenation. This operation fuses the individual
node embedding with the collective information conveyed by the associated hyperedges. This
amalgamation is crucial as it encapsulates the influence exerted by the interactions within the
hyperedgesontotheindividualagent.
The Hypergraph Relational Encoder applies the node-to-hyperedge and hyperedge-to-node
phases iteratively, allowing agent embeddings to be refined and enriched as relationships within
hyperedges evolve. Upon the completion of these iterations, the output is constructed as the con-
catenation of the agent embeddings across all scales. The final agent embedding matrix V˜a is
composed of the embeddings of all agents, where each agent embedding v is a concatenation of
i
theembeddingsfromallscales,expressedas:
V˜a = [v˜ ] ∈ RN×|d(S+1)|, ∀i ∈ [1,...,N] (26)
i
where
v˜ = [v˜(0),v˜(1),...,v˜(S)] (27)
i i i i
3.3.3. PosteriorDistributionLearner
Inourstudy,weincorporatedmulti-scalehypergraphembeddingsintoamulti-agenttrajectory
generationsystemusingtheCVAEframework[46]toaddressthestochasticnatureofeachagent’s
behavior, as shown in Figure 10. Here, we denote the historical trajectories X as X , and
1:T T
denotethepredictedfuturetrajectoriesX asX . Letlogp(X |X )denotethelog-likelihood
T+1:T+F F F T
of predicted future trajectories X given historical trajectories X . The corresponding Evidence
F T
LowerBound(ELBO)isdefinedasfollows:
18Figure10: PosteriorDistributionLearner.
logp(X |X ) ≥ E logp(X |Z,X )
F T q(Z|XF,XT) F T
(28)
−KL(q(Z|X ,X ) ∥ p(Z|XT)),
F T
whereZ ∈ RN×dz representsthelatentcodescorrespondingtoallagents; p(Z|X )istheconditional
T
prior of Z, modeled as a Gaussian distribution. KL represents the Kullback–Leibler divergence
function. In this framework, q(Z|X ,X ) is implemented through an encoding process for em-
F T
bedding learning, and p(X |Z,X ) is realized via a decoding process that forecasts the future
F T
trajectoriesX .
F
Thus, the goal of the Posterior Distribution Learner is to derive the Gaussian parameters for
the approximate posterior distribution. This involves computing the mean µ and the variance
q
σ based on the final output embeddings V˜a and the target embeddings V˜a. These parameters
q F T
are generated through two separate trainable MLPs, F and F , respectively. The latent code Z,
µ σ
representing possible trajectories, is then sampled from a Gaussian distribution parameterized by
thesemeansandvariances. ThefinaloutputembeddingsV˜ p areaconcatenationofthelatentcode
Z,thefinaloutputembeddingsV˜a,andthetargetembeddingsV˜a. Theequationsgoverningthese
F T
processesareasfollows:
µ = F (V˜a,V˜a) (29)
q µ F T
σ = F (V˜a,V˜a) (30)
q σ F T
Z ∼ N(µ ,Diag(σ2)) (31)
q q
V˜ p = [Z,V˜a] (32)
T
In these notations, µ and σ represent the mean and variance of the approximated posterior
q q
distribution. F andF arethetrainableMLPsthatproducetheseparameters. Zdenotesthelatent
µ σ
codeofpossibletrajectories,andV˜ p standsfortheoutputembeddings,whichfusesthelatentcode
andthehistoricalembeddings.
19Figure11: MotionGenerator.
3.3.4. MotionGenerator
The Motion Generator’s objective is dual: to predict future trajectories and to reconstruct past
trajectories from the given embeddings. The decoder accomplishes this by applying successive
processing blocks, each contributing a residual that refines the trajectory estimates, as shown in
Figure 11. The first processing block, F , takes the output embeddings V˜ p and the target past
Res1
trajectoryX togenerateinitialestimatesofthefutureandreconstructedpasttrajectoriesXˆ and
T F,1
Xˆ respectively.
T,1
Xˆ ,Xˆ = F (V˜ p,X ) (33)
F,1 T,1 Res1 T
Subsequently, the second block, F , refines these estimates by considering the output em-
Res2
beddings and the residual of the past trajectory, which is the difference between the target past
trajectory and the initial reconstructed past trajectory X −Xˆ . This results in the second set of
T T,1
residualsXˆ andXˆ :
F,2 T,2
Xˆ ,Xˆ = X (V˜ p,X −Xˆ ) (34)
F,2 T,2 Res2 T T,1
Both F and F are composed of a GRU encoder for sequence encoding and two MLPs
Res1 Res2
serving as the output header. The final predicted future trajectory Yˆ and the reconstructed past
F
trajectoryXˆ areobtainedbysummingtherespectiveresidualsfrombothprocessingblocks:
T
Yˆ = Xˆ +Xˆ (35)
F F,1 F,2
Xˆ = Xˆ +Xˆ (36)
T T,1 T,2
Thisapproachenablesthemodeltoiterativelyrefineitspredictionsandreconstructions,lever-
aging the capability of deep learning models to capture complex patterns in the data through a
seriesofnon-lineartransformations.
204. ExperimentsandResults
4.1. DataPreparations
Thisresearchleveragestwoopen-sourcedatasetsforthepurposeofmodeltrainingandvalida-
tion: theNextGenerationSimulation(NGSIM)dataset[47],[48]andtheHighDdataset[49]. The
NGSIM dataset provides a comprehensive collection of vehicle trajectory data, capturing activity
from the eastbound I-80 in the San Francisco Bay area and the southbound US 101 in Los Ange-
les. This dataset encapsulates real-world highway scenarios through overhead camera recordings
at a sampling rate of 10Hz. The HighD dataset originates from aerial drone recordings executed
at a 25 Hz frequency between 2017 and 2018 in the vicinity of Cologne, Germany. Spanning
approximately 420 meters of bidirectional roadways, it records the movements of approximately
110,000 vehicles, encompassing both cars and trucks, traversing an aggregate distance of 45,000
km. After data pre-processing, the NGSIM dataset encompasses 662 thousand rows of data, cap-
turing 1,380 individual trajectories, while the HighD dataset comprises 1.09 million data entries,
including 3,913 individual trajectories. For the purpose of training and evaluation of the model,
the partition of the data allocates 70% to the training set and 30% to the test set. For the temporal
parameters of the model, we adopt T = 30 frames to represent the historical horizon and F = 50
framestosignifythepredictionhorizon.
4.2. TrainingandEvaluationMetrics
Training loss of GIRAFFE. The training loss function for GIRAFFE is a summation of three
terms:
LPRED = L +L +L (37)
pred int fut
The first component, L , is the mean squared error (MSE) between the fused predicted
pred
trajectoryandthegroundtruthfuturetrajectory:
L = ∥Yˆ −Y ∥2 (38)
pred F F 2
ThesecondcomponentL representsthenegativelog-likelihood(NLL)ofthepredicteddriv-
int
ingintentions,treatingitasaclassificationtask:
(cid:88)
L = NLL(Mˆ;M) = − mlogP(mˆ|X ) (39)
int T
m∈M
The third component L is the loss associated with the inference of the future-guided graph
fut
featurematrix,whichisanintermediateoutput:
L = ∥Hˆ −H ∥2 (40)
fut F F 2
21TraininglossofRHINO. ThetraininglossfunctionforRHINOisalsoasummationofthreecom-
ponents:
LGEN = L +L +L (41)
elbo recon var
The first component, L , corresponds to the ELBO loss [46] commonly used in variational
elbo
autoencoders. It consists of a reconstruction loss term and a regularization term based on the
Kullback-Leiblerdivergencebetweenthelearneddistributionandapriordistribution:
(cid:18) (cid:16) (cid:17) (cid:13) (cid:13) (cid:19)
L = α∥Yˆ −Y ∥2 +βKL N µ ,Diag(σ2) (cid:13)N (0,λI) (42)
elbo F F 2 q q (cid:13)
Thesecondcomponent,L ,representstheHistoricalTrajectoryReconstructionloss,which
recon
measureshowaccuratelythereconstructedhistoricaltrajectoriesmatchthetruehistoricaldata:
L = λ∥Xˆ −X ∥2 (43)
recon T T 2
Thefinalcomponent,L ,istheVarietyloss,inspiredbySocial-GAN[21]. Thislossencour-
var
ages diversity in the predicted future trajectories by minimizing the error across multiple sampled
futuretrajectories:
L = min∥Yˆ(k) −Y ∥2 (44)
var F F 2
k
Table 1 presents the hyperparameter configurations used for the network architecture and the
trainingprocessintheproposedframework.
Table1: HyperparameterSettings
Parameter Value Parameter Value
T 30 decayingfactor 0.6
F 50 α 1
neuron#ofMLPs 128 β 0.8
learningrate 0.001 λ 0.5
Evaluation metrics To ascertain the predictive accuracy of the model, we employ the Root
Mean Square Error (RMSE) as the evaluative criterion. This metric quantitatively measures the
deviation between the predicted position, expressed as (yˆl ,yˆl ), and the ground truth position,
f,lat f,lon
indicated by (yl ,yl ) for all time step f within the predictive horizon prediction horizon [T +
f,lat f,lon
1,T +F].
(cid:118)(cid:117)(cid:116)
1
(cid:88)L T(cid:88)+F
(cid:16) (cid:17)
RMSE = (yˆl −yl )2 +(yˆl −yl )2 (45)
LF f,lat f,lat f,lon lon
l=1 f=T+1
where the superscript l denotes the l-th test sample from the aggregate test sample set with length
L.
224.3. ResultsofTrajectoryGeneration
TheexperimentalresultsfortrajectorygenerationoftheK trajectoriesusingtheHighDdataset
are presented in Figure 12. As can be found that, RHINO demonstrates strong generative capabili-
ties, effectively producing plausible motion in a dynamic interactive traffic environment. To pro-
vide a more quantitative analysis, trajectory generation inaccuracies are illustrated in Figure 13.
The generated longitudinal and lateral trajectories, along with the error box plots and heatmaps,
are displayed. The box plot reveals that errors in both axes increase with the prediction time step
by the natural of error propagation. However, the errors remain within an acceptable range, in-
dicating decent model performance, which demonstrates high precision in trajectory generation.
Notably,themodelmaintainsalowererrormarginforshorterpredictionhorizons,whichiscritical
forshort-termplanningandreactivemaneuversindynamictrafficenvironment.
Figure12: Trajectorygenerationresultsinhighwayscenarios.
The experiment focused on predicting vehicle trajectories within mixed traffic environments
on highways by employing hypergraph inference to model group-based interactions. Through
the application of hypergraph models at varying scales s = 2,3,5, the experiment captured the
evolution of multi-vehicle interactions across both historical and future horizons. The figures
depictthesedynamicsthroughthreedistinctcolumns: thefirstcolumnpresentsvehicletrajectories
23Figure13: Longitudinalandlateraltrajectorygenerationerroranalysis.
and the corresponding hyperedges, visualized as polygons that encapsulate groups of interacting
vehicles. Thesecondcolumnillustratestheaffinitymatrix,wherebothrowsandcolumnsrepresent
vehicles,andthestrengthoftheirrelationshipsisindicatedbythematrixvalues. Thethirdcolumn
shows the incidence matrix, detailing the relationship between nodes and hyperedges, with each
columnrepresentingahyperedgeandeachvehicle’sinvolvementinthathyperedgemarkedbya1
inthecorrespondingrow.
The hypergraph-based approach is particularly effective in modeling complex, higher-order
interactionsthatarebeyondthescopeoftraditionalpairwisemodels. Byforminghyperedgesthat
encompass multiple vehicles, the model captures the collective influence that a group’s behavior
exerts on an individual vehicle. For instance, in the scenario shown in Figure 14, at scale s = 5,
whenthetargetvehicleTARinitiatesalanechange,thehypergraphreflectstheinteractionnotonly
with a single neighboring vehicle but also with multiple surrounding vehicles, such as following
vehicleF,precedingvehicleP,andprecedingvehicleRPintherightlane. Moreexamplesareillus-
trated in Appendix A. This capability to model group-wise interactions across different scales is
24Figure14: Trajectorygenerationwithhypergraphinference.
essential for accurately predicting vehicle trajectories in congested highway environments, where
the actions of one vehicle can trigger ripple effects that influence an entire group. The hyper-
graph’sdynamicformationofhyperedgesensuresthatpredictedtrajectoriesremainadaptableand
responsivetobroadertrafficconditions.
4.4. ComparisonsandAblationStudy
To evaluate the privileges of our proposed method, the state of art methods (i.e., Social-
LSTM (S-LSTM) [20], Convolutional Social-LSTM (CS-LSTM) [31], Planning-informed pre-
diction (PiP) [50], Graph-based Interaction-aware Trajectory Prediction (GRIP) [26], Spatial-
temporaldynamicattentionnetwork(STDAN)[22]arecompared.
The compared results presented in Table 2 and Figure 15. As can be found that, the proposed
frameworkdemonstratesgoodperformancewithrespecttotheRMSEacrossapredictionhorizon
of 50 frames when compared with existing baseline models. It exhibits a reduced loss in com-
parison to C-LSTM, CS-LSTM, PiP, and GRIP. These outcomes suggest that the proposed model
25effectively captures salient features pertinent to long-term predictions. In summary, the proposed
framework outperforms baseline models on the HighD dataset and delivers commendable perfor-
manceontheNGSIMdataset.
Since the RHINO adopts the GIRAFFE, we further compare the trajectory generation capability
of RHINO with our previous work [25] and its enhanced version GIRAFFE. Both RHINO model and
theenhancedGIRAFFEmodelconsistentlyoutperformthebaselinemodels,demonstratingsuperior
performance in various metrics. This suggests that our proposed approaches effectively address
thelimitationspresentinprevailingmodelsbyrobustlycapturingcomplexinteractions.
Table2: PredictionErrorObtainedbyDifferentModelsinRMSE(m)
Horizon S- CS-
Dataset PiP GRIP STDAN GIRAFFE RHINO
(Frame) LSTM LSTM
10 0.65 0.61 0.55 0.37 0.42 0.38 0.32
20 1.31 1.27 1.18 0.86 1.01 0.89 0.78
NGSIM 30 2.16 2.08 1.94 1.45 1.69 1.45 1.34
40 3.25 3.10 2.88 2.21 2.56 2.46 2.17
50 4.55 4.37 4.04 3.16 3.67 3.24 2.97
10 0.22 0.22 0.17 0.29 0.19 0.19 0.19
20 0.62 0.61 0.52 0.68 0.27 0.42 0.26
HighD 30 1.27 1.24 1.05 1.17 0.48 0.81 0.42
40 2.15 2.10 1.76 1.88 0.91 1.13 0.65
50 3.41 3.27 2.63 2.76 1.66 1.56 0.89
Figure15:PredictionerrorobtainedbydifferentmodelsinRMSEonNGSIMdataset(left)andHighDdataset(right).
AblationstudyisconductedtoprovidemoreinsightsintotheperformanceofourRHINOmodel,
especially the impact of different components on the prediction performance by disabling the
26Table3: AblationTestResultsofRHINOinRMSE(m)
Horizon RHINO RHINO RHINO
RHINO
(Frame) w/oHG w/oMM w/oPDL
10 0.21 0.22 0.24 0.19
20 0.31 0.37 0.42 0.26
30 0.68 0.73 0.80 0.42
40 0.97 1.06 1.18 0.65
50 1.25 1.34 1.57 0.89
Figure16: AblationStudyofRHINO.
corresponding component from the entire RHINO. In particular, we consider the following four
variants:
• RHINO w/o HG(hypergraph)variantdoesnotusethemulti-scalehypergraphsrepresentation
butonlyadoptsthepair-wiseconnectedgraphrepresentationsintheHypergraphRelational
Encoder.
• RHINO w/o MM(multi-modal)variantdoesnotadoptthemulti-agentmulti-modaltrajectory
prediction results and only use the single predicted future states for each agent as the input
oftheRHINO.
• RHINO w/o PDL(posteriordistributionlearner)variantskipsthePosteriorDistributionLearner
anddirectlyinputthegraphembeddingintotheMotionGenerator.
Aninvestigationintotheeffectsofmodeldesignvariations,aspresentedinTable3andFigure
16. The removal of various components from RHINO invariably leads to performance degradation
to varying degrees. Compared to the full RHINO, omitting the multi-scale hypergraphs results in
27an evident increase in prediction error across the prediction horizon, indicating that modeling and
reasoninggroup-wiseinteractionsusinghypergraphs,ratherthansolelypair-wiseinteractions,en-
hancespredictionaccuracywhichunderscoresthenecessityofhypergraphs. Further,excludingthe
multi-agentmulti-modaltrajectorypredictioninputleadstoamoresubstantialdegradationinper-
formance, highlighting the importance of incorporating multi-modal motion states and discussing
the corresponding group-wise interactions among multiple driving behaviors of multiple agents.
Lastly, the absence of the Posterior Distribution Learner module emphasizes its critical role in
handlingthestochasticityofeachagent’sbehavior. Alltheseexperimentsjustifytheeffectiveness
ofthefullmodel.
5. Conclusions
In this study, we proposed a hypergraph enabled multi-modal probabilistic motion prediction
framework with reasonings. This framework consists of two main components: GIRAFFE and
RHINO. GIRAFFE focuses on predicting the interactive vehicular trajectories considering modali-
ties. Based on that, RHINO, leveraging the flexibility and strengths on modeling the group-wise
interactions, facilitate relational reasoning among vehicles and multi-modalities to render plausi-
ble vehicles trajectories. The framework extends traditional interaction models by introducing an
agent-behaviorhypergraph. Thisapproachbetteralignswithtrafficphysicswhilebeing grounded
in the mathematical rigor of hypergraph theory. Further, the approach employs representation
learning to enable explicit interaction relational reasoning. This involves considering future rela-
tionsandinteractionsandlearningtheposteriordistributiontohandlethestochasticityofbehavior
for each vehicle. As a result, the framework excels in capturing high-dimensional, group-wise
interactionsacrossvariousbehavioralmodalities.
The framework is tested using the NGSIM and HighD datasets. The results show that the
proposed framework effectively models the interactions among groups of vehicles and their cor-
responding multi-modal behaviors. Comparative studies demonstrate that the framework outper-
forms prevailing algorithms in prediction accuracy. To further validate the effectiveness of each
component,ablationstudieswereconducted,revealingthatthefullmodelperformsbest.
Several potential extensions of the framework include incorporating road geometries, vehicle
types, and real-time weather data to improve trajectory prediction. By integrating weather in-
formation from sources like the OpenWeather API, the system could adjust predictions based on
conditions such as temperature, wind, and precipitation, enhancing safety and route optimization
[51]. Additional enhancements, like traffic signal integration, V2V and V2I communication, and
human driver intent, could further improve accuracy and reliability in dynamic urban environ-
ments,minimizingdisruptionsandfosteringsafer,moreinformedautonomousdriving.
Acknowledgement:
This research is funded by Federal Highway Administration (FHWA) Exploratory Advanced
Research693JJ323C000010. TheresultsdonotreflectFHWA’sopinions.
28References
[1] Gao,J.,Sun,C.,Zhao,H.,Shen,Y.,Anguelov,D.,Li,C.&Schmid,C.Vectornet: Encodinghdmapsandagent
dynamicsfromvectorizedrepresentation.ProceedingsOfTheIEEE/CVFConferenceOnComputerVisionAnd
PatternRecognition.pp.11525-11533(2020)
[2] Li,S.,Wang,Z.,Zheng,Y.,Sun,Q.,Gao,J.,Ma,F.&Li,K.Synchronousandasynchronousparallelcomputa-
tionforlarge-scaleoptimalcontrolofconnectedvehicles.TransportationResearchPartC:EmergingTechnolo-
gies.121pp.102842(2020)
[3] Shi,H.,Zhou,Y.,Wu,K.,Wang,X.,Lin,Y.&Ran,B.Connectedautomatedvehiclecooperativecontrolwitha
deepreinforcementlearningapproachinamixedtrafficenvironment.TransportationResearchPartC:Emerging
Technologies.133pp.103421(2021),https://www.sciencedirect.com/science/article/pii/S0968090X21004150
[4] Shi, H., Zhou, Y., Wu, K., Chen, S., Ran, B. & Nie, Q. Physics-informed deep reinforcement learning-based
integratedtwo-dimensionalcar-followingcontrolstrategyforconnectedautomatedvehicles.Knowledge-Based
Systems.269pp.110485(2023)
[5] Zhou,D.,Hang,P.&Sun,J.Reasoninggraph-basedreinforcementlearningtocooperatemixedconnectedand
autonomoustrafficatunsignalizedintersections.TransportationResearchPartC:EmergingTechnologies.167
pp.104807(2024)
[6] Liu, H., Wu, K., Fu, S., Shi, H. & Xu, H. Predictive analysis of vehicular lane changes: An integrated lstm
approach.AppliedSciences.13,10157(2023)
[7] Suo,S.,Regalado,S.,Casas,S.&Urtasun,R.Trafficsim: Learningtosimulaterealisticmulti-agentbehaviors.
Proceedings Of The IEEE/CVF Conference On Computer Vision And Pattern Recognition. pp. 10400-10409
(2021)
[8] Deo, N. & Trivedi, M. Multi-modal trajectory prediction of surrounding vehicles with maneuver based lstms.
2018IEEEIntelligentVehiclesSymposium(IV).pp.1179-1184(2018)
[9] Wang, H., Meng, Q., Chen, S.&Zhang, X.Competitiveandcooperativebehaviouranalysisofconnectedand
autonomous vehicles across unsignalised intersections: A game-theoretic approach. Transportation Research
PartB:Methodological.149pp.322-346(2021)
[10] Trentin,V.,Artun˜edo,A.,Godoy,J.&Villagra,J.Multi-modalinteraction-awaremotionpredictionatunsignal-
izedintersections.IEEETransactionsOnIntelligentVehicles.(2023)
[11] Ali, Y., Bliemer, M., Zheng, Z. & Haque, M. Cooperate or not? Exploring drivers’ interactions and response
timestoalane-changingrequestinaconnectedenvironment.TransportationResearchPartC:EmergingTech-
nologies.120pp.102816(2020)
[12] Karle, P., Geisslinger, M., Betz, J. & Lienkamp, M. Scenario understanding and motion prediction for au-
tonomous vehicles—review and comparison. IEEE Transactions On Intelligent Transportation Systems. 23,
16962-16982(2022)
[13] Li,G.,Jiang,B.,Zhu,H.,Che,Z.&Liu,Y.Generativeattentionnetworksformulti-agentbehavioralmodeling.
ProceedingsOfTheAAAIConferenceOnArtificialIntelligence.34,7195-7202(2020)
[14] Han,Z.,Fink,O.&Kammer,D.Collectiverelationalinferenceforlearningheterogeneousinteractions.Nature
Communications.15,3191(2024)
[15] Zhong,X.,Zhou,Y.,Ahn,S.&Chen,D.Understandingheterogeneityofautomatedvehiclesanditstraffic-level
impact: Astochasticbehavioralperspective.TransportationResearchPartC:EmergingTechnologies.164pp.
104667(2024)
[16] Kipf, T., Fetaya, E., Wang, K., Welling, M. & Zemel, R. Neural relational inference for interacting systems.
InternationalConferenceOnMachineLearning.pp.2688-2697(2018)
[17] Li,J.,Yang,F.,Tomizuka,M.&Choi,C.Evolvegraph:Multi-agenttrajectorypredictionwithdynamicrelational
reasoning.AdvancesInNeuralInformationProcessingSystems.33pp.19783-19794(2020)
[18] Xu,C.,Wei,Y.,Tang,B.,Yin,S.,Zhang,Y.,Chen,S.&Wang,Y.Dynamic-group-awarenetworksformulti-
agenttrajectorypredictionwithrelationalreasoning.NeuralNetworks.170pp.564-577(2024)
[19] Park, D., Ryu, H., Yang, Y., Cho, J., Kim, J. & Yoon, K. Leveraging future relationship reasoning for vehicle
trajectoryprediction.ArXivPreprintArXiv:2305.14715.(2023)
[20] Alahi, A., Goel, K., Ramanathan, V., Robicquet, A., Fei-Fei, L.&Savarese, S.Sociallstm: Humantrajectory
29predictionincrowdedspaces.ProceedingsOfTheIEEEConferenceOnComputerVisionAndPatternRecogni-
tion.pp.961-971(2016)
[21] Gupta, A., Johnson, J., Fei-Fei, L., Savarese, S. & Alahi, A. Social gan: Socially acceptable trajectories with
generativeadversarialnetworks.ProceedingsOfTheIEEEConferenceOnComputerVisionAndPatternRecog-
nition.pp.2255-2264(2018)
[22] Chen, X., Zhang, H., Zhao, F., Hu, Y., Tan, C. & Yang, J. Intention-aware vehicle trajectory prediction based
onspatial-temporaldynamicattentionnetworkforinternetofvehicles.IEEETransactionsOnIntelligentTrans-
portationSystems.23,19471-19483(2022)
[23] Zhang,K.,Zhao,L.,Dong,C.,Wu,L.&Zheng,L.AI-TP:Attention-basedinteraction-awaretrajectorypredic-
tionforautonomousdriving.IEEETransactionsOnIntelligentVehicles.8,73-83(2022)
[24] Kim, H., Kim, D., Kim, G., Cho, J. & Huh, K. Multi-head attention based probabilistic vehicle trajectory
prediction.2020IEEEIntelligentVehiclesSymposium(IV).pp.1720-1725(2020)
[25] Wu,K.,Zhou,Y.,Shi,H.,Li,X.&Ran,B.Graph-BasedInteraction-AwareMultimodal2DVehicleTrajectory
PredictionUsingDiffusionGraphConvolutionalNetworks.IEEETransactionsOnIntelligentVehicles.9,3630-
3643(2024)
[26] Li,X.,Ying,X.&Chuah,M.Grip: Graph-basedinteraction-awaretrajectoryprediction.2019IEEEIntelligent
TransportationSystemsConference(ITSC).pp.3960-3966(2019)
[27] Zhou,H.,Ren,D.,Xia,H.,Fan,M.,Yang,X.&Huang,H.Ast-gnn: Anattention-basedspatio-temporalgraph
neuralnetworkforinteraction-awarepedestriantrajectoryprediction.Neurocomputing.445pp.298-308(2021)
[28] Huang,Y.,Bi,H.,Li,Z.,Mao,T.&Wang,Z.Stgat:Modelingspatial-temporalinteractionsforhumantrajectory
prediction.ProceedingsOfTheIEEE/CVFInternationalConferenceOnComputerVision.pp.6272-6281(2019)
[29] Amirian,J.,Hayet,J.&Pettre´,J.Socialways:Learningmulti-modaldistributionsofpedestriantrajectorieswith
gans.ProceedingsOfTheIEEE/CVFConferenceOnComputerVisionAndPatternRecognitionWorkshops.pp.
0-0(2019)
[30] Khandelwal, S., Qi, W., Singh, J., Hartnett, A. & Ramanan, D. What-if motion prediction for autonomous
driving.ArXivPreprintArXiv:2008.10587.(2020)
[31] Deo,N.&Trivedi,M.Convolutionalsocialpoolingforvehicletrajectoryprediction.ProceedingsOfTheIEEE
ConferenceOnComputerVisionAndPatternRecognitionWorkshops.pp.1468-1476(2018)
[32] Messaoud,K.,Yahiaoui,I.,Verroust-Blondet,A.&Nashashibi,F.Attentionbasedvehicletrajectoryprediction.
IEEETransactionsOnIntelligentVehicles.6,175-185(2020)
[33] Feng,X.,Cen,Z.,Hu,J.&Zhang,Y.Vehicletrajectorypredictionusingintention-basedconditionalvariational
autoencoder.2019IEEEIntelligentTransportationSystemsConference(ITSC).pp.3514-3519(2019)
[34] Wang,Y.,Zhao,S.,Zhang,R.,Cheng,X.&Yang,L.Multi-vehiclecollaborativelearningfortrajectorypredic-
tionwithspatio-temporaltensorfusion.IEEETransactionsOnIntelligentTransportationSystems.23,236-248
(2020)
[35] Zhou,Y.,Zhong,X.,Chen,Q.,Ahn,S.,Jiang,J.&Jafarsalehi,G.Data-drivenanalysisfordisturbanceampli-
ficationincar-followingbehaviorofautomatedvehicles.TransportationResearchPartB:Methodological.174
pp.102768(2023)
[36] Huang, Z., Wu, J. & Lv, C. Driving behavior modeling using naturalistic human driving data with inverse
reinforcementlearning.IEEETransactionsOnIntelligentTransportationSystems.23,10239-10251(2021)
[37] Sheng,Z.,Xu,Y.,Xue,S.&Li,D.Graph-basedspatial-temporalconvolutionalnetworkforvehicletrajectory
predictioninautonomousdriving.IEEETransactionsOnIntelligentTransportationSystems.23,17654-17665
(2022)
[38] Gao, Y., Zhang, Z., Lin, H., Zhao, X., Du, S. & Zou, C. Hypergraph learning: Methods and practices. IEEE
TransactionsOnPatternAnalysisAndMachineIntelligence.44,2548-2566(2020)
[39] Feng,Y.,You,H.,Zhang,Z.,Ji,R.&Gao,Y.Hypergraphneuralnetworks.ProceedingsOfTheAAAIConfer-
enceOnArtificialIntelligence.33,3558-3565(2019)
[40] Zhou,R.,Zhou,H.,Gao,H.,Tomizuka,M.,Li,J.&Xu,Z.Grouptron:Dynamicmulti-scalegraphconvolutional
networksforgroup-awaredensecrowdtrajectoryforecasting.2022InternationalConferenceOnRoboticsAnd
Automation(ICRA).pp.805-811(2022)
[41] Xu,C.,Li,M.,Ni,Z.,Zhang,Y.&Chen,S.Groupnet:Multiscalehypergraphneuralnetworksfortrajectorypre-
30dictionwithrelationalreasoning.ProceedingsOfTheIEEE/CVFConferenceOnComputerVisionAndPattern
Recognition.pp.6498-6507(2022)
[42] Li, J., Hua, C., Ma, H., Park, J., Dax, V.&Kochenderfer, M.Multi-AgentDynamicRelationalReasoningfor
SocialRobotNavigation.ArXivPreprintArXiv:2401.12275.(2024)
[43] Wu,Y.,Zhuang,D.,Labbe,A.&Sun,L.Inductivegraphneuralnetworksforspatiotemporalkriging.Proceed-
ingsOfTheAAAIConferenceOnArtificialIntelligence.35,4478-4485(2021)
[44] Li, Y., Yu, R., Shahabi, C. & Liu, Y. Diffusion convolutional recurrent neural network: Data-driven traffic
forecasting.ArXivPreprintArXiv:1707.01926.(2017)
[45] Jang, E., Gu, S. & Poole, B. Categorical reparameterization with gumbel-softmax. ArXiv Preprint
ArXiv:1611.01144.(2016)
[46] Pagnoni,A.,Liu,K.&Li,S.Conditionalvariationalautoencoderforneuralmachinetranslation.ArXivPreprint
ArXiv:1812.04405.(2018)
[47] J.ColyarandJ.Halkias,“U.S.Highway101dataset,”2007.
[48] J.ColyarandJ.Halkias,“U.S.Highway80dataset,”2006.
[49] R. Krajewski, J. Bock, L. Kloeker, and L. Eckstein, “The highD Dataset: A Drone Dataset of Natural-
istic Vehicle Trajectories on German Highways for Validation of Highly Automated Driving Systems,” in
IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC, 2018, vol. 2018-November. doi:
10.1109/ITSC.2018.8569552.
[50] Song,H.,Ding,W.,Chen,Y.,Shen,S.,Wang,M.&Chen,Q.Pip: Planning-informedtrajectorypredictionfor
autonomousdriving.ComputerVision–ECCV2020: 16thEuropeanConference,Glasgow,UK,August23–28,
2020,Proceedings,PartXXI16.pp.598-614(2020)
[51] Ye, X., Li, S., Das, S. & Du, J. Enhancing routes selection with real-time weather data integration in spatial
decisionsupportsystems.SpatialInformationResearch.32,373-381(2024)
31Appendix A. Experimentresultsoftrajectorygenerationwithhypergraphinference
FigureA.17: Scenario2ofTrajectorygenerationwithhypergraphinference.
In Scenario 2, at scale s = 5 (Figure A.17), the target vehicle TAR forms a strong historical
interaction with multiple vehicles, including the preceding vehicle P, preceding vehicle LP in the
left lane, and following vehicles LF and F in the left lane. However, in the future states, vehicle
LF exits the interaction group, while the preceding vehicle RP in the left lane joins the group as
thetargetvehicleacceleratestowardRF.
In Scenario 3, at scale s = 3 (Figure A.18), the target vehicle TAR forms a weak historical
interactionwiththeprecedingvehiclesPandLPintheleftlane. Astrafficconditionschangeover
time,theseinteractionsstrengtheninthefuture,highlightingtheneedtoaccountfordynamicshifts
when predicting future states, as historical data alone may not capture the evolving complexity of
vehicle interactions. These findings emphasize the importance of adaptive models in predicting
multi-agenttrafficdynamics.
32FigureA.18: Scenario3ofTrajectorygenerationwithhypergraphinference.
Appendix B. DiffusionGraphConvolutionalNetworks(DGCN)
The Diffusion Graph Convolutional Networks (DGCN) module models bidirectional depen-
dencies between nodes in the graph embedding, following [43, 44]. The DGCN layer, denoted
DGCN(·),appliesdiffusionconvolutiontothegraphsignalinbothforwardandreversedirections:
H = DGCN(H)
l+1 l
(cid:88)K (cid:16) (cid:17) (B.1)
= T (A¯ )·H˜ ·Θk +T (A¯ )·H˜ ·Θk
k f l f,l k b l b,l
k=1
In this equation, H˜ represents the output of the l-th layer, with the input to the first layer be-
l+1
ing the masked feature matrix X. The forward transition matrix A¯ = A/rowsum(A) captures
f
downstream node dependencies, while the backward transition matrix A¯ = AT/rowsum(AT)
b
captures upstream dependencies. The function T (·) represents a Chebyshev polynomial used
k
to approximate convolution with the k-th order neighbors of each node. This is expressed as
33T (X) = 2X · T (X) − T (X). Learnable parameters Θk and Θk assign weights to input data
k k−1 k−2 b,l f,l
in the l-th layer. The forward diffusion process captures the influence of surrounding vehicles on
agivenvehicle,whilethereversediffusionprocessmodelstheinfluencethatthevehicletransmits
toitssurroundings.
Appendix C. GumbelSoftmaxDistribution
TheGumbel-Softmaxdistribution[45]providesadifferentiableapproximationofthecategor-
ical distribution, crucial for neural networks that rely on gradient-based optimization. Traditional
categorical sampling, involving non-differentiable operations like argmax, poses challenges for
backpropagation. Gumbel-Softmax addresses this by replacing argmax with a differentiable soft-
max function, allowing gradients to flow during training. Based on the Gumbel-Max trick, which
addsGumbelnoisetolog-probabilitiesfollowedbyargmax,theGumbel-Softmaxsubstitutessoft-
maxtomaintaindifferentiability. Theformulaofthesamplevectorsd is:
exp(cid:0)(cid:0) log(π)+g(cid:1) /τ(cid:1)
d i = (cid:80)
k
exp(cid:16)(cid:16) logi
(π
)+i
g
(cid:17) /τ(cid:17), fori = 1,...,k (C.1)
j=1 j j
Here, π are categorical probabilities, g is Gumbel noise, and τ controls the distribution’s sharp-
i i
ness. As τ approaches zero, the Gumbel-Softmax approximates a one-hot distribution. Larger
τ values result in a smoother distribution, useful for early training exploration. This property
makes Gumbel-Softmax valuable for tasks like variational autoencoders and reinforcement learn-
ing,wherediscretesamplingwithdifferentiabilityisneeded.
34