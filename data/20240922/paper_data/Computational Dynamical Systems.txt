Computational Dynamical Systems
Jordan Cotler∗ Semon Rezchikov†
Harvard University Princeton University
September 19, 2024
Abstract
We study the computational complexity theory of smooth, finite-dimensional dynamical systems.
Building off of previous work, we give definitions for what it means for a smooth dynamical system to
simulate a Turing machine. We then show that ‘chaotic’ dynamical systems (more precisely, Axiom
A systems) and ‘integrable’ dynamical systems (more generally, measure-preserving systems) cannot
robustly simulate universal Turing machines, although such machines can be robustly simulated by
otherkindsofdynamicalsystems. Subsequently, weshowthatanyTuringmachinethatcanbeencoded
intoastructurallystableone-dimensionaldynamicalsystemmusthaveadecidablehaltingproblem,and
moreover an explicit time complexity bound in instances where it does halt. More broadly, our work
elucidateswhatitmeansforone‘machine’tosimulateanother,andemphasizesthenecessityofdefining
low-complexity ‘encoders’ and ‘decoders’ to translate between the dynamics of the simulation and the
system being simulated. We highlight how the notion of a computational dynamical system leads to
questions at the intersection of computational complexity theory, dynamical systems theory, and real
algebraic geometry.
∗Email: jcotler@fas.harvard.edu
†Email: semonr@princeton.edu
4202
peS
81
]CC.sc[
1v97121.9042:viXraContents
1 Introduction 1
1.1 Motivation and overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Our results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2.1 Universality: existence and obstructions . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2.2 Time complexity bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2 Related work 6
3 Preliminaries 8
3.1 Definitions for simulability and CDSs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.1.1 Simulability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.1.2 A useful example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.1.3 Defining CDSs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.1.4 Robustness and other conditions for CDS encoders and decoders. . . . . . . . . . . . 18
3.2 Overview of dynamical systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
4 Autonomous CDSs 24
4.1 Example of a Turing-complete CDS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
4.2 Non-universality of Axiom A systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
4.2.1 Conjectures about generic diffeomorphisms . . . . . . . . . . . . . . . . . . . . . . . 32
4.3 Non-universality of measure-preserving and integrable systems . . . . . . . . . . . . . . . . 33
4.4 Time complexity bounds in one dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
4.5 Time complexity bounds in many dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . 38
5 Dynamical mechanisms for computation 39
6 Open Problems 41
A Real computation and BSS machines 44
C
B Complexity classes and dynamical systems 46
C Symbolic dynamics 47
D Variations of the stable manifold theorem 49
E Proof of polynomial root separation bound 491 Introduction
1.1 Motivation and overview
Modelsofdigitalcomputation, whichlieatthefoundationofcomputerscience, aretypicallydiscrete, while
most of our fundamental models of the physical world are essentially continuous. Nonetheless, the Church-
Turing thesis [Tur39] and its physical counterparts [Gan80, CS07] state that this difference is illusory: the
discrete computations we can perform reliably in the physical world should be the same as those which
can be performed by a Turing machine, possibly by one having access to random bits. The validity of
the physical Church-Turing thesis is a subject of debate, and a number of variants of the thesis have been
proposed [Cop97]. Furthermore, from the perspective of complexity theory rather than computatibility
theory, the possibility for quantum computers to solve with high probability, in polynomial time, decision
problems which are not in P, is a basic motivation for research on quantum computation [NC10, ACQ22].
In a different (non-quantum) direction, there have been multiple models proposed for a definition
of a computable real function [Grz55, Lac59, Blu98, Sma97, Bra05a], and using this language, it has
been found that simple finite-dimensional continuous dynamical systems defined by polynomial equations
with integral coefficients can exhibit non-computable dynamical properties [Moo90, BY06]. In general
it is known that the existence of natural problems with no computable solution (such as the problem
of recognizing presentations of the trivial group [PS]) forces complex behaviour of various continuous
mathematical objects related to geometry and dynamics [Wei20, Sei08]. In yet a different direction, there
has been a sequence of papers asking whether universal computation can be realized by various ordinary
[Bra94] and partial differential equations, including in single-particle potential energy systems [Tao17] and
in solutions to fluid dynamics equations [CMPSP21]; this was in part motivated by the hope of showing
the existence of blow-up solutions to the Navier-Stokes equations by finding fluid flows which ‘replicate
themselves’atsmallerandsmallerscales[Tao16]. Suchworksonrealizinguniversalcomputationinnatural
continuous physical models can be seen as a continuation of Moore’s earlier work [Moo98, Moo90], which
realized universal computation in a simple 2-dimensional piecewise-linear map, as well as in a Lipschitz
map on the interval and an analytic map on R. The relation between the computational capacity and the
analytic or dynamical properties of a continuous dynamical system, such as its topological entropy or its
regularity, are known to be subtle: for example, depending on the formalization, the topological entropy
of a Turing-universal system can be zero [CMPS23] or can be forced to be nonnegative [BCMPS24].
Researchers in both machine learning and computational neuroscience are often forced to posit that
various continuous systems (recurrent neural networks, transformers, models of brains) implement certain
computations [Sus14, CSY16, MPVL19, KKS+15, KF22, CTH+23], and indeed part of the problem of
neuroscience is to extract, from neuronal measurements, the ‘computations’ implemented by the brain.
Such scientific applications were part of the motivation for the founders of the mathematical field of dif-
ferentiable dynamical systems theory [Sma67, Tho69], who originally tried to extract simple ‘discrete’
descriptions of the dynamics of systems like Axiom A systems. The development of differentiable dynam-
ical systems theory led to a collection of powerful mathematical methods for understanding dynamical
systems. Nonetheless, these methods are rarely used by non-mathematicians, perhaps because they do not
connect straightforwardly with the kinds of questions the researchers in neural network interpretability
and computational neuroscience typically ask.
To ‘do’ complexity theory with continuous dynamical systems, one must know what it means for a
continuous system to ‘implement’ a discrete computation. Unfortunately, this notion is not completely
clear and many of the works cited above do not give precise definitions for this notion. Here we propose
an answer to this question via a perspective which is natural to computer scientists. We will show that
without some definition like the one we propose, computability questions about continuous dynamical
systems become trivialized. Our proposed definition differs from other proposals connected to the Space-
Bounded Church-Turing Thesis [BSR15, BGR12] by not requiring for ‘noise’ to be introduced in the
continuous dynamics. Moreover, our proposed framework naturally leads to interesting questions that
should feel familiar to those interested in the mathematical study of differentiable dynamical systems. In
1particular, we prove several results regarding complexity and computability theory in the context of our
framework by utilizing results from differentiable dynamical systems theory.
To explain our proposal, let us recall how computer scientists ask computational complexity questions
about discrete systems. Given some machine T : S S with discrete configuration space S (where x S
→ ∈
describes the configuration of a machine including all of its tapes at a given moment), we would say that
T is Turing universal if it can do the same computations as any fixed universal Turing machine T . To
univ
establish this property of T, we always need to find some encoder which lets us encode configurations
E
of T into configurations of T, and some decoder which lets us decode a configuration of T from
univ univ
D
a configuration of T. In fact, since there are many definitions of a Turing machine (e.g. with one-sided
or two-sided tapes, with multiple tapes, as well as more exotic variants), such constructions are needed
when setting up the theory of computation; many implicit examples of such encoders and decoders can
be found in basic textbooks like [Sip12, AB09]. For such constructions to make sense, one must require
that the encoder and decoder are themselves computationally simple, e.g. that they can be implemented
by a low-time complexity Turing machine or a uniform family of low-depth circuits. Otherwise, one can
packageallthecomputationintotheencoderanddecoderthemselves(seeSection3.1.2); thus,thenotionof
a Turing-universal system already presupposes the existence of a basic theory of computational complexity
to constrain the encoder and decoder.
Luckily, in the continuous domain there is already a well-developed theory of computable real functions
and uniform real circuits [Blu98, Bra05a]. Thus, to ask if a continuous system f : M M (where M
→
is continuous, e.g. M = [0,1]n) is Turing-universal, we can require for there to be low-time complexity
R–Turing machines , which respectively encode bit strings from the configuration space of the Turing
E D
machineintothedomainoff,anddecoderegionsinthedomainoff toe.g.bitstringsfromtheconfiguration
space of the Turing machine.
Definition 1.1 (informal; see Definition 3.19). A computational dynamical system (or CDS) is a
tuple (f, , ,τ,T) where:
E D
• f : M M is a dynamical system, with M Rk;
→ ⊂
• : S M is a function which can be implemented by a BSS machine (a model of real computation;
C
E →
see Definition 3.13 and Appendix A) that runs in time O(t(n)) for some function t(n) of the length
of the input;
• : M ⇀ S is a partially defined function (i.e. a function M S Error ) which can be implemented
D → ⊔{ }
by a BSS machine that runs in time O(t(n)), for the same function t(n) of the length of the output
C
of ;
D
• τ : M Z is a function which is constant on connected components of −1(s); and
≥0
→ D
• T : S S is a discrete computational system, e.g. a Turing machine (although variants can be
→
defined e.g. for pushdown automata).
This tuple is required to satisfy the condition that = Id, as well as the condition that for s S, we
D◦E ∈
have
fτ −1(s) = T(s).
D◦ ◦D
Here fτ : M M where fτ : x fτ(x)(x). Thus the encoder-decoder pair along with f can simulate T
→ (cid:55)→
with a slowdown determined by τ and t(n).
Remark 1.2. Anequivalentconditiontotheaboveisthatfτ takesallof −1(s)into −1(s). If −1(s) =
D D D
(s) ,thenthisisequivalenttotheconditionthat fτ = T. However,forgeneral forwhich −1(s)
{E } D◦ ◦E D D
may have non-empty interior, this notion corresponds to requiring that the computation be robust: any
perturbation of the ideal input (s) corresponding to s, which still lies in a ‘validity region’ −1(s), will
E D
continue to compute the correct answer. Thus, the above definition encapsulates a model of computation
2which is robust to non-uniform errors, i.e. the amount of error allowed may depend on the input and may
gotozeroincertainregionsofthedomainoff. Itisthenon-uniformityoftheallowedamountoferrorthat
enables universal computation on compact domains (see the discussion regarding robustness in Section 2).
Essentiallyallpreviousworkoncomputationalpropertiesofcontinuousdynamicalsystems(e.g.[Moo98])
can be put into this framework; our definition gives a precise notion of a ‘reasonable’ encoding of states
of T into M, which has thus far been without a definition in the literature. Without such a condition on
and , the notion of simulation becomes essentially trivial (Example 3.23), just as in the case of Turing
D E
machines.
However, with bounds on τ(x) and t(n) (e.g. τ(x) = ( −1(x) ) and t(n) = O(n)) the notion of
O |D |
simulation is nontrivial, and we can say that a continuous dynamical system f is Turing-universal when
there exists a CDS (f, , ,τ,T ) for some universal Turing machine T . Thus universality is an
univ univ
E D
intrinsic property of f; we will see that dynamical systems f which in our sense are both ‘robust’ and
universalexist,eventhoughmanynaturaldynamicalconditionsonf willbeshowntoprecludeuniversality.
It is natural to generalize CDSs to the setting of forced dynamical systems, as would be appropriate
for studying e.g. finite state machines, RNNs, transformers, etc. We develop the theory of forced CDSs
in [CR].
1.2 Our results
One of the benefits of our notion of a CDS is that it is straightforward to define various conditions for the
decoder in order to model different ways of encoding. For instance:
D
Definition 1.3. Let (f, , ,τ,T) be a CDS. We say that the decoder , as well as the CDS, is robust if
E D D
for every s S (where S is the configuration space of T) we have that −1(s) is the closure of its interior,
∈ D
and (s) lies in the interior of −1(s).
E D
Clearly, the notion of a robust CDS models the idea that if a state is encoded via the encoder , then
E
some amount of C0-bounded noise η can be allowed in the encoding (s) of s such that the states
E D ◦
(fτ)k( (s)+η) correctly simulate the dynamics of T starting from s. (Here fτ = f if τ = 1; see Definition
E
3.19.) This is different from other notions of robustness in the literature, which we will discuss in Section
2 below.
1.2.1 Universality: existence and obstructions
The first result of the paper, beyond setting up the definitions, shows that the resulting theory is non-
vacuous:
Theorem 1.4. There exists a robustly Turing-universal CDS (f, , ,τ,T ) with τ(x) = 1, t(n) = O(n),
univ
E D
and f a smooth diffeomorphism of the closed 2-disk.
This construction is modeled off that of Moore [Moo91], using an idea similar to that of [CMPSP21]. The
construction of [Moo91] provides a map of a square that is piecewise linear, as well as an associated smooth
map that, while having correct dynamics for a decoder with −1(s) = (s) for all s S, cannot in
D D {E } ∈
any evident way be upgraded to a robust decoder; the construction of [CMPSP21] shows how to make f
a smooth area-preserving map, but suffers from the same problem as the construction of [Moo91]. In fact,
area-preserving maps can never furnish a robustly Turing-universal CDS:
Theorem 1.5 (see Corollary 4.21). Let f : M M be such that M is a codimension 0 submanifold of
→
Rn, and suppose that there is an an f-invariant Borel measure µ on M which is nonzero on all nonempty
open sets and such that µ(M) < . Then f cannot be extended to a robustly Turing-universal CDS
∞
(f, , ,τ,T ) for any τ or t.
univ
E D
3In particular, the examples of [CMPSP21] and subsequent papers cannot be made into robustly Turing-
universal CDSs in our sense. As a consequence of a general result about measure-preserving dynamics
(Theorem4.24),weproveananalogofTheorem1.5for“integrablesystems”,e.g.f isalineartranslationon
atorus,orafamilyofthesedependingonanadditionalparameter,suchasiff istheHamiltoniandynamics
for a Hamiltonian H : M R where M is a “computable manifold” (see Remark 3.20) with a symplectic
→
form ω such that H is part of a system of pairwise Poisson-commuting Hamiltonians (H ,...,H ) with
1 n
H = H.
1
Integrable systems are among the simplest possible model systems in physics, as their behavior is com-
pletely and efficiently predictable. On the other extreme, we have systems which are ‘completely chaotic’:
their behavior is sensitive to their initial conditions in a strong sense. In differentiable dynamics, these are
axiomatized under the guise of uniformly hyperbolic, or Anosov, diffeomorphisms, and form fundamental
examples in differentiable dynamical systems theory. Another natural class of examples in dynamical sys-
tems theory are time-1-gradient flows of generic Morse functions. Their common generalization is the class
of Axiom A systems, which we review in Section 4.2; a fundamental theorem is that the structurally stable
systems, i.e. thosediffeomorphismsf suchthatanynearbydiffeomorphismf˜hasthesame dynamics(from
a topological perspective) as f, are exactly the Axiom A systems satisfying a transversality assumption
(see Theorem 4.11).
It turns out that just as the least chaotic, i.e. integrable, systems cannot be robustly Turing universal,
the ‘most chaotic’ systems, and more generally the structurally stable systems, likewise cannot be robustly
Turing universal:
Theorem 1.6. Let M be a manifold, and let f : M M be an Axiom A diffeomorphism. Then f cannot
→
be extended to a robustly Turing-universal CDS (f, , ,τ,T ) for any τ or t.
univ
E D
Remark 1.7. The manifold M does not need to be compact; however, by definition (Definition 4.9), the
nonwandering set of f is compact.
The argument used to prove Theorem 1.6 uses deep structural results about the dynamics of f due to
Smale [Sma67] and others [HP70]. Moreover, the arguments proving Theorems 1.5 and 1.6 do not use all
of the structure of the universal Turing machine T . Indeed, we define a notion of a sub-machine of
univ
T such that if f simulates T and N is a sub-machine of T , then f also simulates N (possibly with
univ univ univ
modified t and τ, i.e. with a slowdown).
Theorem 1.8 (see Theorem 4.20). In the setting of Theorem 1.5, in fact f cannot be extended to a
robust CDS (f, , ,τ,T) if T contains as a sub-machine the machine Plus : 1 ∗ 1 ∗ defined by
E D { } → { }
Plus([n] ) = [n+1] , where [n] denotes n expressed in unary. Similarly, in the setting of Theorem 1.6, f
1 1 1
cannot be extended to a robust CDS (f, , ,τ,T) if T contains as sub-machines T for all n > 0, where
n
E D
T : S S is simply the identity map and S = n.
n
→ | |
The method of proof of Theorem 1.5 from earlier is to note that if f simulates the the sub-machine Plus,
then there must be an infinite collection of disjoint regions C
i
such that fri(C i) C
i+1
and such that the
⊂
sumofthemeasuresoftheC isfinite; thusthemeasuresoftheC mustdecreasetozero, whichcontradicts
i i
the requirement that f is measure-preserving.
In contrast, the proof of Theorem 1.6, namely a proof by contradiction, uses the sub-machines T to
n
produce an arbitrarily large finite disjoint collection of closed subsets C with nonempty interiors such that
i
fn(C ) C for each i. Then, one invokes the spectral decomposition of f, decomposing its nonwandering
i i
⊂
set into finitely many basic sets, and then uses stable manifold theory to force each C to contain at least
i
one of the basic sets. Essentially, points in C must be attracted to one of the basic sets, so they lie on the
i
stable manifold of one of the points on the basic sets; perturbing this point a small amount and following
the stable manifold back to C , one finds a new point asymptotic to a point on a basic set with a dense
i
periodic orbit. Thus since C is closed, it must contain that entire basic set; the argument concludes with a
i
contradiction because there are more sets C than there are basic sets, and yet the C are pairwise disjoint.
i i
4Theseresultssuggestfutureresearchdirectionsforexactlycharacterizingthe‘computationalcomplexity
classes’ that can be assigned to various types of dynamical systems. There is an expectation in the
differentiable dynamics literature that as one allows for non-uniform hyperbolicity, and more generally
for mixtures of integrable and chaotic behavior (such as that arising in Henon system [PC10]), then more
complextypesofdynamicalbehaviorcanoccur[PM80]. Itwouldbedesirabletoidentifyprecisedifferences
between the types of computations that can be implemented by such systems. We venture the following
conjecture:
Conjecture 1.9. A C∞ generic f : M M cannot be extended to a robustly Turing-universal CDS.
→
We are able to prove this conjecture under a strong additional assumption on the decoder as well as
D
a constant slowdown function (see Theorem 4.15) via a periodic-point argument and the Kupka-Smale
Theorem (see [KKH95, Chapter 7]). It may be possible to resolve this conjecture under the assumption
of the well known Palis conjectures on the dynamics of generic smooth dynamical systems [Pal00]; any
argument for this conjecture, like the Axiom A argument, is likely to require sophisticated input from
differentiable dynamical systems theory.
1.2.2 Time complexity bounds
Going beyond statements about decidability or universality, it is natural to ask more refined questions
about the computational capacity of smooth dynamical systems. In particular, it is desirable to show that
various natural dynamical conditions on f, e.g. Axiom A, exponential mixing, genericity, etc., bound the
computational capacity of f such that one can identify a comparatively small complexity class of problems
solvablebysuchf. Forexample,itisnaturaltoaskwhethergenericone-dimensionalsystemscanrecognize
languages that are not in P. We formalize such questions in Appendix B, and proceed by proving some
initial time complexity results in this setting:
Theorem 1.10. Let f : [0,1] [0,1] be an Axiom A diffeomorphism (this property is generic and
→
equivalent to structural stability). For any CDS (f, , ,τ,T) where t(n) = n and τ is constant, if T halts
E D
on a configuration then it will halt in time O(F(n)), where
F(n) =
D2n
for some constant D. In other words, in the sense of Appendix B, f can recognize languages in at best
DTIME(O(F(n))).
Remark 1.11. The result actually holds for a much wider class of slowdown functions τ; see Remark 4.34.
The proof relies on the structure theory of one-dimensional Axiom A systems. Standard results [KKH95]
implythatsuchsystemshaveonlyfinitelymanyhyperbolicattractingperiodicpoints, andthecomplement
of their basins of attraction is a (possibly fractal) repelling set. Now, each configuration of T is associated
to some disjoint union of subintervals of [0,1]. One then uses (i) lower bounds from real algebraic geometry
abouttheminimumseparationbetweenrootsofrealpolynomialsasafunctionoftheircoefficients[Rum79],
(ii) the construction of symbolic dynamics controlling the dynamics of the chaotic hyperbolic repeller of
f [KKH95], and (iii) the complexity condition on the decoder, in order to show that one of these [0,1]
subintervals contains a point that must get very close to the hyperbolic periodic point attractor in time
O(F(n)). Subsequently, either one sees that the rest of the interval must still be stuck near the hyperbolic
repelling set for several iterations, which is a contradiction if we do not halt since regions corresponding to
configurations cannot overlap; or the entire interval must have escaped a neighborhood of the hyperbolic
repelling set, in which case waiting another O(F(n)) time will allow us to decide if the computation will
halt or not.
In higher dimensions, analogs of the real algebraic geometry bound [Rum79] seem not to have been
established,whilethedynamicsofAxiomAsystemsarecomparativelymorecomplicated. Thus,werestrict
ourselves to the simplest Axiom A systems, the Anosov ones, and prove an inexplicit complexity bound:
5Theorem 1.12. Let f : M M be Anosov and volume-preserving. Consider a CDS (f, , ,τ,T) where
→ E D
t(n) = n, the decoder is Cantor-like (Definition 4.36), and the encoder and decoder are implemented by
BSS machines with the finite set of computable constants being a ,...,a . Then the CDS halts on all
C 1 ℓ
{ }
configurations in time O( (n)), where (n) is a computable function depending on a ,...,a .
1 ℓ
C C
Note that unlike in the Axiom A case, such systems must always halt. This feature arises from the
topological mixing of Anosov systems, since robust CDSs with topologically mixing dynamics must always
halt (Lemma 4.35). To establish a computable halting time bound, one must know how fast these systems
mix. WedothisviatheSinai-Bowen-RuelletheoryofexponentialmixingofAnosovsystems[Bow78,BR75],
together with some elementary real algebraic geometry counting argument to get a bound on how fast the
sets corresponding to configurations of f can shrink as n increases. In short, exponential mixing means
that the time evolution of the space correlation between fnF and F , where F is a nonnegative function
∗ 1 2 1
supported in a ball inside C := −1(s), and F is a nonnegative function supported inside the halting set,
s 2
D (cid:82) (cid:82)
must converge to a positive number F F at an exponential rate. This gives us an upper bound on how
1 2
long the correlation can be zero, i.e. on how long the images of C (corresponding to input configuration s
s
of the machine T simulated by f) do not intersect the halting set. Since the sets C do not shrink too fast
s
as n increases, we can argue that the bound for the halting time of this CDS is computable.
We expect that the dependence on the computable constants (a ,...,a ) can be removed and a bound
1 ℓ
on (n) can be made explicit, but this depends on a natural problem in real algebraic geometry which we
C
explain in the text. We expect that in fact one can give polynomial time halting bounds. Moreover, the
condition that f is volume-preserving is likely to be inessential, but removing this condition involves more
subtle arguments about the invariant SRB measure for f, which in general is not absolutely continuous
with respect to the Lebesgue measure, even for Anosov systems. We leave these improvements to future
work.
2 Related work
This paper contributes a precise definition that allows one to probe the intrinsic computational capacity
of a continuous dynamical system f. Moreover, the results of Section 1.2 show that the resulting theory is
nontrivial. As mentioned in the introduction, there have been many previous approaches to this problem.
Below, we compare our work with the different perspectives taken previously.
Real computation. One might ask for the dynamical system f to be computable in one of the many
senses of the term [Blu98, Bra05b, Ko12, Wei12], and apply one of the different theories of computable real
functions. Crucially, in our theory, the continuous dynamical system f is not required to be a computable
map, and even for uncomputable f, the theory remains nontrivial. Moreover, using the notion of a robust
decoder means that we are not studying the dynamics of f on a countable set of computable points,
as is done in many previous works [CMPSP21, CMPS22, CMPS23, Moo90, Moo91, Moo98], but instead
studying its behavior on certain open domains of controlled complexity. These two conditions together
forceonetouseresultsaboutf involvingitscontinuous dynamicalproperties(preservingmeasures, Axiom
A-ness, etc.) rather than its properties in terms of some language used to describef. As such, we elucidate
the computational significance of various notions in differentiable dynamics. In particular, probing f only
along the points of (S) rather than over the sets −1(S) means that much of the global behavior of f
E D
is neglected in the analysis. Since we think of f as a ‘natural system’ (i.e. a brain or a neural network),
from this perspective it is unnatural to expect that we can prepare continuous parameters of states in any
experiment without introducing some ‘error tolerance’.
Robustness. There are two flavors of previous perspectives on ‘robust computation’ in continuous dy-
namics. The first is exemplified by [BGR12, BSR15], where one asks that the dynamics is modified by
the addition of some uniform noise. In this case, the system becomes essentially indistinguishable from
6a finite state Markov process, and because of this most properties of the system become computable in
a suitable sense [BGR12]. This makes it difficult to ask computational complexity questions about the
intrinsic dynamics of f.
The other notion of ‘robust computation’ in continuous dynamics is exemplified by [AB01, BGH13,
GCB08], which essentially fix a robust decoder for f and require that there is an ε such that the same
robust decoder suffices to simulate the desired machine for all f˜which are ε-close to f in the C0 norm.
In this formalization, one also finds that universal computation cannot be achieved robustly by finite-
dimensional dynamical systems [BGH13], essentially by approximating the behavior of f by its behavior
viewedthrougha‘pixelatedlens’ofthedomain,whichisagainsimplythebehaviorofafinitestatemachine.
By defining robust computation as an asymptotic condition as the amount of uniform noise added goes to
zero, [BGH13, GCB08] show that systems f can be than finite state machines: in fact, they can robustly
recognize precisely the recursive languages. Moreover, approaches like [BGH13] focus on asking dynamical
systems to recognize languages rather than to simulate machines, as we do. Our approach leads to a
different class of questions, which are entwined with the theory of differentiable dynamical systems and
the notion of simulation, and are less focused on the question of deciding reachability of the halting set.
In our approach, we prove computational restrictions on an individual f, without any perturbations
made to f, and for arbitrary decoders coupled to f. This is a very different setup from results which fix
a decoder; our approach aims to probe the ‘intrinsic’ computational capacity of f. Moreover, our notion
of robustness does not allow for arguments which boil down the dynamics of f to that of a finite state
machine due to the lack of uniformity in the ‘noise’ allowed when simulating f. (Analogously, although
every physical computer is in effect a finite state machine, we do not model them as such in order to
understand the computations they are performing, and so it is appropriate not to turn every continuous
dynamical system into a finite state machine.) Our notion of robustness models the idea of preparing an
initial state of an experiment to ‘sufficiently high precision’, with the precision required described by the
decoder; assuch, itisanalogoustoavariantofthenoisemodelsof[BGR12]withhighlynon-uniformnoise,
or to asking for robustness to perturbations of f where the norm of the perturbation is allowed to depend
on x M (with M the domain of f) in a non-uniform way.
∈
‘Reasonable’ state encodings. There have been many clever constructions of various mechanisms
implementing computation in continuous dynamical systems [Moo90, Moo91, Moo98, CMPSP21, Car23].
Most often, these encode states of some discrete computational system via points of the continuous state
space M, i.e. the decoder satisfies −1(s) = (s) . As mentioned before, this ignores robustness, and
D {E }
only probes the behavior of f on some Cantor set of points, making it difficult to prove upper bounds on
the computational capacity of f.
Moreover, previousworksusuallyaskforthestateencodingtobe‘reasonable’[Moo98], usuallywithout
making precise what this means [CMPSP21]. In this paper we give a precise definition of a ‘reasonable’
state encoding, and also advocate for focusing on dynamics of open sets (or sets with non-empty interior)
ratherthanofindividualpointsinthecontinuousstatespace. Althoughourdefinitionofa‘reasonable’state
encodingmayseemnaturalafterreadingit,ouruseofthetheoryofrealcomputationasabootstraptomake
sense of the computational power of more general continuous dynamical systems is new, and is carefully
designed to avoid many potential issues having to do with the theory of real computation. For example,
BSSR machines(whichweretheonesoriginallydefinedbyBlum-Shub-Smale[BSS89], ratherthanthelater
BSS -machines) are capable of strong super-Turing computation via access to uncomputable constants
C
[Bra05b]. Additionally, decoders defined using non-uniform circuit families also lead to pathologies like
Example 3.23. Finally, formulating the decoding of states in terms of bit complexity either leads to
pathologies involving states encoded in regions which are essentially ‘pixelated’ (if the decoder can be bit-
computed in finite time) or only being able to define the encoder and decoder via an infinite computation,
making it more challenging to state the required complexity constraints on the encoder and decoder. We
do not explicate these alternative problematic formalizations in this work, but it is a central contribution
of this paper to define CDSs such that they formalize previously existing intuitions while avoiding many
7possible technical pitfalls.
Symbolic dynamics. A popular approach in the mathematical literature on continuous dynamical sys-
tems is to study the dynamics of f via symbolic dynamics, namely by discretizing the continuous state
space M by removing a measure zero set M , defining another map σ : M M Σ for some discrete
0 0
\ →
alphabet Σ, and studying f via the induced language L Σ∞ given by the set
f,σ
⊂
L = τσ(x) : x M M , τσ(x) := (σ(x),σ(f(x)),σ(f2(x)),...).
f,σ f 0 f
{ ∈ \ }
Onehopestofindaσ forwhichthemapx τσ(x)isinjectiveonx M M , butforwhichthenumberof
(cid:55)→ f ∈ \ 0
symbols is small, e.g. finite. This approach is reviewed in Appendix C. It turns out that it is often possible
to achieve this, and the method and its variations are very helpful for studying dynamical properties of f.
Thus, one might be tempted to say that one should identify f with the corresponding discrete language
L .
f,σ
However, this approach leads to several challenges. The first is that one might have different discretiza-
tion maps σ and σ such that the resulting languages L and L are of vastly different computational
1 2 f,σ1 f,σ2
complexity. As such, there is no obvious mechanism for upper bounding the computational capacity of
a differentiable dynamical system if one measures computational capacity in terms of the corresponding
language L . The second is that while the symbolic dynamics allows one to associate notions of language
f,σ
complexity to dynamical systems, it does not allow one to discuss the way that f is performing the desired
pattern-recognition problem – one cannot argue that f is simulating any given algorithm. The third is
that for many systems, preferred classes of discretizations σ called Markov partitions have been proven to
exist; however, the resulting maps σ have the property that the boundary of σ−1(s) for s Σ is a fractal
∈
[Bow78], and the computability of these sets is not clear. To arrange for computability, one must certainly
require that f is computable; however, upgrading existing constructions of Markov partitions to a com-
putable analysis setting is laborious (see the thesis [Rob08], which proves some results for two-dimensional
diffeomorphisms).
In this paper, while we use symbolic dynamics in the proof of Theorem 1.10 to study the dynamics
of f, our discretization of the dynamics is instead given by , which is always (efficiently) computable.
D
Tools from symbolic dynamics (see Appendix C for an overview) are naturally adapted to study dynamical
propertiesoff, e.g.mixingandperiodicpointproperties. Thesearehelpfulforunderstandinghowf might
‘compute’, but do not straightforwardly answer computational questions about f in general. Part of the
purpose of this paper is to highlight the gap between a dynamical and a computational understanding of
differentiable dynamical systems.
3 Preliminaries
In this section we set up the definition of a computational dynamical system, motivated by considering a
general theory of simulability of one machine by another. We will explicate how simulability has a subtle
but fundamental relationship with computational complexity, which is neglected in standard textbook
treatments. Next we provide an overview of (differentiable) dynamical systems theory, as appropriate for
ouranalysesinthispaper. Sincedynamicalsystemstheory, includingitstoolsandperspectives, aremostly
unfamiliar to computer scientists, we delve into more detail on these vis-`a-vis other preliminaries.
3.1 Definitions for simulability and CDSs
3.1.1 Simulability
Thefoundationsofcomputersciencearepredicatedonnotionsofsimulability,asmanifestedbytheChurch-
Turing thesis and its variants. Strangely, textbook treatments do not provide a general definition of
‘simulability’ as an answer to the question: “What does it mean for one system to simulate another?”
8While it is standard in textbook treatments (see e.g. [Sip12, AB09]) to give an example of universal Turing
machinethatcanreproducetheoutputsofallotherTuringmachineswithsomeslowdown,thisismerelyan
example of a Turing machine that we might take as being able to ‘simulate’ all others, leaving unanswered
the question of what ‘simulation’ precisely means.
Let us motivate a suitable definition of simulation by exploring two initial desiderata. To do so, we
need some notation. Abstractly, let us denote a machine by a map T : S S where S is the configuration
→
space. For example, T could be a Turing machine and some s S would be the joint description of the
∈
state of the head, location of the head, and the symbols on the tape. (We will provide precise definitions
in the Turing machine setting shortly.) Then Tn(s) describes the configuration of the system after n steps.
This is a type of autonomous system since it merely has an initial condition and no external inputs at
intermediate time steps; as such it does not specialize a standard formulation of e.g. finite state machines
which instead must be viewed as forced systems :S C S where C are some ‘control’ variables. We
× →
will study forced systems in a separate work [CR]. For now, we consider two machines T : S S and
1 1 1
→
T : S S , and we want to understand what it would mean for T to simulate T .
2 2 2 2 1
→
ThefirstdesiderataisthatallrealizableconfigurationsofT , namelyS , shouldcorrespondtosomeset
1 1
of configurations in S . That is, there is a translation protocol between configurations of the system being
2
simulatedandthesimulation. Thiscanbeexpressedasapartial, surjectivefunction : S ⇀ S (here‘⇀’
2 1
D
denotes a partial function). We call this function the decoder. We also use the notation C := −1(s)
s
D D
to denote the configurations in S corresponding to the configuration s in S .
2 1
The second desiderata is that the dynamics of the simulation T should ‘track’ the dynamics of T .
2 1
That is, for some function τ : S N which is constant on connected components of −1(s), we would
2
→ D
want
Tτ(C ) = T (s) (1)
2 s 1
D◦
for all s S . Our above notation Tτ : S S means Tτ : s Tτ(s2) (s ). The ‘slowdown function’ τ
∈ 1 2 2 → 2 2 2 (cid:55)→ 2 2
allows for the possibility that T tracks the dynamics of T with a slowdown for each computational step,
2 1
contingent on the details of the encoded representation at that step. We can equivalently write
(Tτ)n(C ) = Tn(s) (2)
2 s 1
D◦
for all s S and all n 0. As a convenience, we might want a means to select a particular configuration
1
∈ ≥
in C , so we can consider a map : S S such that (s) C for all s S . We call an encoder, and
s 1 2 s 1
E → E ∈ ∈ E
it evidently satisfies (s) = s for all s S . Then (2) implies
1
D◦E ∈
(Tτ)n (s) = Tn(s), (3)
2 1
D◦ ◦E
which as before holds for all s S and all n 0.
1
∈ ≥
We are now prepared to provide a formal definition of simulation. For ease of exposition, we will
take the simulation and system being simulated to both be Turing machines. Our definition will readily
generalize beyond the setting of Turing machines, and we will employ such a generalization when we
consider dynamical systems. To this end, we begin with a suitable definition of a k-tape Turing machine:
Definition 3.1 (Turing machine, adapted from [AB09]). A Turing machine is given by a triple (Q,Γ,δ)
where Q and Γ are finite sets and:
1. Q is the set of states, containing a start state q and at least one halt state q ;
0 halt
2. Γ is the tape alphabet, not containing a blank symbol ; and
⊔
3. δ : Q Γ Q Γ L,R,S .
× ∪{⊔} → × ×{ }
9The configuration space S of a Turing machine is given by S := Γ∗ Q Γ∗, where a configuration is
× ×
denoted by s = x x qx x for x Γ and q Q, with the understanding that all symbols to the
1 m−1 m n i
··· ··· ∈ ∈
left of x are blank and all symbols to the right of x are blank. Our notation expresses that the head is
1 n
above x , and that all of the symbols on the tape to the left of x and to the right of x are blank. We can
m 1 n
define a map T : S S as follows. If δ(q,x ) = (q′,x′ ,a) for a L,R,S , then
m m
→ ∈ { }

x x q′x x′ x if a = L
  1 ··· m−2 m−1 m ··· n
T(s) = x x q′x′ x if a = S , (4)
1 m−1 m n
 ··· ···
x x′ q′x x if a = R
1 m m+1 n
··· ···
which describes one time step of the Turing machine.
The above readily generalizes to the k-tape setting, wherein δ : Q (Γ )k Q Γk L,R,S k. We
× ∪{⊔} → × ×{ }
note that there are many related definitions of Turing machines, but our later analyses will not really be
sensitive to the choice of definition.
We also require an initial definition of encoders, decoders, and slowdown functions, given below.
Definition 3.2 (Encoders, decoders, slowdown functions, and their complexities). Let S and S be the
1 2
configuration spaces of two Turing machines (Q ,Γ ,δ ) and (Q ,Γ ,δ ).
1 1 1 2 2 2
• An encoder is a function : S S that can be instantiated by a 2-tape Turing machine, with one
1 2
E →
tape having symbols in Γ Q and the other having symbols in Γ Q . (Here is the
1 1 2 2
∪{⊔}∪ ∪{⊔}∪ ⊔
blank symbol.) We will additionally allow for the 2-tape Turing machine to write the blank symbol.
The initial state of the first tape is q and the initial state of the second tape is q′ s(2) for s(2) S .
0 0 2
⊔ ∈
Then the machine halts with the first tape in the configuration q (s(2)), where (s(2)) S , and
halt 2
E E ∈
the second tape is all blank symbols. If the machine halts in time O(t( s(2) )), then we say that has
| | E
input time complexity O(t(n)).
• A decoder is a partial function : S S that can be instantiated by 2-tape Turing machine as
2 1
D →
follows, with one tape having symbols in Γ Q and the other having symbols in Γ Q .
1 1 2 2
∪{⊔}∪ ∪{⊔}∪
As before, we will additionally allow for the 2-tape Turing machine to write the blank symbol. The
initialstateofthefirsttapeisq s(1) fors(1) S , andtheinitialstateofthesecondtapeisq′ . Ifs(1)
0 1 0
∈ ⊔
is in the domain of definition of , then the machine halts with the second tape in the configuration
D
q′ (s(1)) for (s(1)) S , and the first tape having all blank symbols. If the machine halts in time
haltD D ∈ 2
O(t( (s(1)) )), then we say that has output time complexity O(t(n)).
|D | D
• A slowdown function is a partial function τ : S ⇀ Z which is defined exactly on the domain of
2 ≥0
definition of , is constant on the connected components of −1, and can be instantiated by a 2-tape
D D
Turing machine (which we allow to write blank symbols) as follows. The initial state of the first tape
of the Turing machine is q s(2) for s(2) S , and the initial state of the second tape is q′ . If s(2)
0 2 0
∈ ⊔
is in the domain of definition of τ, then the machine halts with the second tape in the configuration
q′ τ(s(2)) for τ(s(2)) a binary representation of an element of Z , and the first tape blank. If the
halt ≥0
machine halts in time O(u( (x) )), then we say that τ has slowdown function time complexity
|D |
O(u(n)). We will always assume that u(n) is a computable function.
With the above definitions at hand, we are prepared to define the simulability of one Turing machine
by another.
Definition 3.3 (Simulation of Turing machines). Let T and T be Turing machines with configuration
1 2
spaces S and S , respectively. We say that T (τ,t(n))–simulates T if the exists an encoder : S S
1 2 2 1 1 2
E →
with input complexity O(t(n)), a decoder : S ⇀ S with output complexity O(t(n)), and a slowdown
2 1
D
function τ : S Z such that:
2 ≥0
→
1. (s) C for all s S , where C := −1(s); and
s 1 s
E ∈ ∈ D
102. Tτ(C ) = T (s) for all s S .
2 s 1 1
D◦ ∈
We recall that Tτ : S S means Tτ : s Tτ(s2) (s ).
2 2 → 2 2 2 (cid:55)→ 2 2
Before explaining the significance of this definition and its relation to prior work, several initial remarks
are in order.
Remark 3.4. WemaysaythatT isauniversal Turingmachineifit(τ,t(n))-simulatesT foreveryTuring
2 1
machine T and some (τ,t(n)) which possibly depend on T . While this does not agree with all definitions
1 1
of universal Turing Machines, which often only ask for T to correctly compute recursive functions rather
2
than to simulate other Turing machines, it nonetheless usually holds in constructions of universal Turing
machines. For a definition in the vein of Definition 3.3, see e.g. [Rog96].
Remark 3.5. Above we are tacitly assuming that if some s in S contains a halt state, then T (s) = s.
1 1
This need not be the case; that is, we could instead say that time evolution of T simply ends when we
1
reach the halt state.
Remark 3.6. We can readily generalize Definition 3.3 to the setting where T and T have k and k′ tapes,
1 2
respectively, possibly with k = k′. Then it would be sensible for and to correspond to Turing machines
̸ E D
with (at least) k+k′ tapes. Related generalizations, where the machines T and T in question need not
1 2
even be Turing machines, proceed by analogy with Definition 3.3.
Remark 3.7 (Oblivious simulation). An oblivious simulation is one for which τ(s ) = f( (s ) ); that
2 2
|D |
is, τ only depends on the length of the decoded string. Any Turing machine can be simulated via an
oblivious simulation (see e.g. [AB09]).
AkeyfeatureofDefinition3.3isthatitaccountsforthecomplexityO(t(n))oftheencoderanddecoder.
Wewillshowthatthisaccountingforcomplexityiscompletelyessentialforthedefinitiontobesensibleand
meaningful. Moreover, it was missed in previous work. In particular, there have been a number of previous
works (see [Ros11, Ros91, Bra95, KM99] and specifically [GCB05, GCB08, Car23], as well as examples
in [Tao17, CMPSP21, CMPS22, CMPS23]) which define simulability akin to Definition 3.3, but without
any specification of the complexity of the encoders and decoders. Without such a specification, we can run
into several problems. Specifically, suppose that T simulates T with respect to the encoder and decoder
2 1
, . We might be inclined to say that this relation implies that T in a sense ‘contains’ T , or that T
2 1 2
E D
is at least ‘as powerful’ as T . But these statements may not be true. For suppose that the encoder or
1
decoderaremorecomputationallypowerfulthanthesimulatorT , butaspowerfulasthesimulatedsystem
2
T . As such, even if T has very weak computational capabilities, we could still satisfy conditions akin to
1 2
1 and 2 in Definition 3.3 since the encoder and decoder could do the ‘work’ of simulating the computation
of T . We will give an example of this phenomenon in Section 3.1.2 below. In summary, accounting for
1
the complexity of the encoder and decoder is essentially that we correctly attribute computational power
to T vis-´a-vis the encoder and decoder.
2
There is a useful heuristic that further clarifies the above point. When we say that T simulates T ,
2 1
what we might want is an implication like Complexity(T ) Complexity(T ), for some notion of complexity.
2 1
≥
However, T being able to simulate T using , actually implies a schematic inequality along the lines of
2 1
E D
max Complexity(T ),Complexity( ) Complexity(T ). (5)
2 1
{ D } ≥
As such, if Complexity( ) Complexity(T ), then (5) is automatically satisfied and so we do not learn
1
D ≥
about the computational power of T . On the other hand, if Complexity( ) < Complexity(T ), then (5)
2 1
D
implies Complexity(T ) Complexity(T ), and so we do learn about the computational power of T . As
2 1 2
≥
such, the conceptual lesson is: the encoder and decoder need to be less computationally complex than the
system being simulated if we wish to learn about the computational powers of the simulator. Moreover,
we emphasize that we are always learning about the computational power of the simulator vis-´a-vis the
computational power of T .
1
Before proceeding, let us demonstrate that Definition 3.3 interfaces nicely with standard constructions
of universal Turing machines, which we often say can ‘simulate’ any other Turing machine.
11Theorem 3.8 (Efficient universal Turing machine, adapted from [HS66, AB09]). There is a 3-tape uni-
versal Turing machine that can (τ,t(n))–simulate any k-tape Turing machine for τ(s) O(log (s) ) and
≤ |D |
t(n) = n.
ThestatementandproofofTheorem3.8in[HS66,AB09]discusstheτ(s) O(log (s) )growthexplicitly.
≤ |D |
If the Turing machine being simulated terminates in T steps, then the simulator will terminate in order
T logT steps. The t(n) = n behavior is implicit in the proofs in [HS66, AB09]. We observe that the
t(n) = n dependence is optimal, since the encoder and decoder need to look at every symbol in the input
and output at least once, giving us t(n) = Ω(n). This motivates the following definition, to be used later:
Definition 3.9 (Optimal encoder and decoder). An encoder and decoder pair , are optimal if has
E D E
input time complexity Θ(n) and has output time complexity Θ(n).
D
As we go along, we point out when an encoder and decoder are optimal. We now state a useful and
elementary lemma.
Lemma 3.10. If T : S S is a universal Turing machine then there is an s S which is non-halting
2 2 2 2
→ ∈
and which is a periodic point of T . In fact, for any N, there is an L 0 such that T has at least N
2 2
≫
distinct periodic orbits of period L.
Proof. Let T : S S be the Turing machine which ‘does nothing’; in particular, whenever the head is
1 1 1
→
not in the halting state we have T (s) = s. We must have that T (τ,t(n))-simulates T for some τ and
1 2 1
t(n) and some encoder-decoder pair , . Now we note that −1(s) is finite for every s S ; indeed, the
1
E D D ∈
bound on output time complexity controls the length of the input, as the algorithm computing must
D
erase the input on the first tape (and in particular read all of its symbols). We then claim that for every
s S with the head not in the halting state, the set −1(s) must contain a periodic point for T . Indeed
1 2
∈ D
we must have by condition 2 of Definition 3.3 that Tτ( −1(s)) −1(s); so this set must contain a fixed
2
D ⊂ D
point of Tτ, i.e. a periodic point of T . The second statement follows from the fact that the sets −1(s),
2 2
D
each of which contains a T -periodic point, are disjoint as s runs over the infinitely many configurations
2
s S which are period-1 non-halting configurations for T .
1 1
∈
3.1.2 A useful example
Here we show that a ‘trivial’ Turing machine can simulate a universal Turing machine if we do not put
any complexity restrictions on the encoder and decoder. This example emphasizes that such restrictions
are essential for simulation to be a useful or meaningful notion. Let T with triple (Q,Γ,δ) be some
univ
single-tape universal Turing machine with configuration space S = Γ∗ Q Γ∗. Let us suppose that
× ×
0,1 Γ. Now let us define the ‘trivial’ Turing machine that will simulate T using a complicated
univ
{ } ⊆
encoder and decoder pair.
Let the ‘trivial’ Turing machine T be described by the triple (Q,Q Γ,δ ), where
trivial simple
∪
δ (q , ) = (q ,1,R) (6)
trivial 0 0
⊔
and otherwise δ (q′,b) = (q ,0, S) for q′ = q or b = . On account of (6), for any s S we have
trivial halt 0
̸ ̸ ⊔ ∈
T (s011 1q ) = s011 1q . (7)
trivial 0 0
(cid:124) (cid:123)·(cid:122)··(cid:125) ⊔ (cid:124) (cid:123)·(cid:122)··(cid:125) ⊔
k k+1
Then defining the encoder and decoder by
E D
(s) := s0q , (s011 1q ) := Tk (s), (8)
0 0 univ
E ⊔ D (cid:124) (cid:123)·(cid:122)··(cid:125) ⊔
k
we see that T simulates T with respect to , .
trivial univ
E D
12Inthisexample,weseethatwhileT cannotfurnishTuring-universalcomputationitself,thedecoder
trivial
does furnish Turing-universal computation. Then the only role of T is to serve as a memory and
trivial
D
counter. As such, this example demonstrates that without constraining the complexity of the encoder and
decoder, they can ‘do the work’ of the computation that we would otherwise wish to associate with the
simulator. To connect back with our schematic (5), the decoder in (8) indeed has the same ‘complexity’
as T itself, which renders the simulation property uninteresting.
univ
We emphasize that decoder in (8) does not have any bounded output complexity bound of the form
O(t(n)). To see this, consider a configuration s which is a fixed point of T so that T (s) = s. Then
univ univ
(s011 1q ) = s regardless of the number of 1’s, but its complexity grows with the number of 1’s.
0
D ··· ⊔
Then the output complexity is not a function of s .
| |
Assuch, weseethatmerelyhavinganinputandoutputcomplexityboundfortheencoderanddecoder,
respectively, provides important constraints on what kinds of machines can ‘simulate’ a universal Turing
machine. These same considerations will carry over to our discussions of computational dynamical systems
below.
Remark 3.11. It is natural to require additionally that if T simulates T , then T halts exactly when
2 1 2
T halts. This is not done in Definition 3.3, and the astute reader may notice that including this condition
1
invalidatestheexampledescribedabove. However,thepurposeofDefinition3.3willultimatelybetoclarify
the meaning of what it means for a dynamical system f (which may ultimately be some differentiable map)
to simulate a Turing machine, as per Definition 3.14 below. There is no natural meaning to the ‘halting’
of f, so it makes sense to drop the halting condition here; moreover, the example above forms the basis
for a more interesting example in the next section below.
3.1.3 Defining CDSs
We now turn to defining a computational dynamical system, or CDS. At a high level, our definition will
parallel Definition 3.3; that is, a computational dynamical system is essentially a dynamical system that
simulates a particular machine. In slightly more detail, a CDS will be specified by a tuple (f, , ,τ,T)
E D
where f : M M for some space M (possibly a manifold) and T : S S is a Turing machine, such
→ →
that f (τ,t(n))–simulates T with respect to , . If M is a discrete space, then we reduce to our previous
E D
discussions. However, if M is e.g. a smooth manifold, then the story becomes more interesting. For
instance, notice that : S M, : M ⇀ S, and τ : M Z . As such, if S is a space of finite strings
≥0
E → D →
and M is a smooth manifold, then , , and τ cannot be implemented by ordinary Turing machines.
E D
For our purposes, we will always consider manifolds which are explicitly subsets of Rk, although our
analysescanbereadilyadaptedtomoregeneralmanifolds. Assuch, itisnaturalthat , beimplemented
E D
by Turing machines with Γ = R, i.e. having R-valued symbols on the tapes. An R-Turing machine is essen-
tially a BSS machine [BSS89]. The BSS machines have been used to develop a rich theory of computability
and complexity over the reals, including decidability problems involving fractals, and complexity bounds
for computing features of polynomial inequalities [BSS89, Sma97]. We note that BSS machines can be de-
fined over any field F, with F = Z corresponding to ordinary Turing machines (with Γ = 0,1 ) [Bra05b].
2
{ }
Since we are interested in the F = R setting, we will take ‘BSS machine’ to mean a ‘BSS machine with
F = R’ unless otherwise specified.
BSS machines will serve as our model of encoders and decoders , for CDSs, as well as our slowdown
E D
functions τ. Since the definition for BSS machines is somewhat elaborate, we have put it in Appendix A so
as not to interrupt the flow of the paper. We note that we make a slight modification to the definition of
BSS machines suggested in [Bra05b]. Typically, the head of a BSS machine has access to a finite number of
real-valuedconstants, whicharenotrequiredtobecomputable. In[Bra05b], Bravermansuggestsrequiring
theconstantsinquestiontobecomputablesoastoavoidcertainpathologies,andhecallsthecorresponding
machines BSS machines, where the ‘C’ stands for ‘computable constants’. We will use BSS machines
C C
henceforth. In some cases, our results will depend on the details of the particular finite set of computable
constants to which a BSS machine has access.
C
13It will be notationally convenient to define a hybrid of a BSS machine and ordinary Turing machine.
C
We defer a precise definition to Appendix A, and so give an informal definition here.
Definition 3.12 (Hybrid BSS machine, informal). A hybrid BSS machine is a BSS machine over
C C C
R Z with two tapes. The first tape has symbols valued in R, and the second tape has symbols valued in
d
×
Z . We will let 0 (in either R or Z ) be a proxy for the blank symbol, and will use 0 and interchangeably
d d
⊔
in this context.
While a BSS machine over R is sufficient to capture the power of a hybrid BSS machine, we will
C C
nonetheless find the definition of the latter to be natural and conceptually useful. To this end, we are now
prepared to define R-valued encoders and decoders by direction analog with Definition 3.2.
Definition 3.13 (R-valued encoders, decoders, slowdown functions, and their complexities). Let S be a
language over a finite alphabet Σ of size d, and M be a submanifold of Rk.
• An encoder is a function : S M that can be instantiated by a hybrid BSS machine over R Z
C d
E → ×
as follows. The initial state of the first tape of the hybrid machine is q and the initial state of the
0
⊔
second tape is q′ s for s S. Then the machine halts with the first tape in the configuration q (s),
0 halt
∈ E
where (s) M Rk, and the second tape having all blank symbols. If the machine halts in time
E ∈ ⊂
O(t( s )), then we say that has input time complexity O(t(n)).
| | E
• A decoder is a partial function : M ⇀ S that can be instantiated by a hybrid BSS machine over
C
D
R Z as follows. The initial state of the first tape of the hybrid machine is q x for x M Rk,
d 0
× ∈ ⊂
and the initial state of the second tape is q′ . If x is in the domain of definition of , then the
0
⊔ D
machine halts with the second tape in the configuration q′ (x) for (x) S, and the first tape
haltD D ∈
having all blank symbols. If the machine halts in time O(t( (x) )), then we say that has output
|D | D
time complexity O(t(n)).
• A slowdown function is a partial function τ : M ⇀ Z which is defined exactly on the domain of
≥0
definition of , is constant on the connected components of −1, and can be instantiated by a hybrid
D D
BSS machine over R Z as follows. The initial state of the first tape of the hybrid machine is q x
C d 0
×
for x M Rk, and the initial state of the second tape is q′ . If x is in the domain of definition of
0
∈ ⊂ ⊔
τ, then the machine halts with the second tape in the configuration q′ τ(x) for τ(x) Z , and the
halt ∈ ≥0
first tape having all blank symbols. If the machine halts in time O(u( (x) )), then we say that τ has
|D |
slowdown function time complexity O(u(n)). We will always assume that u(n) is a computable
function.
In the definition above, the hybrid BSS machines serve ‘translators’ between S and M. With the above
C
definition at hand, we can now formulate simulability of a machine by a finite state machine, akin to
Definition 3.3 above.
Definition 3.14 (Simulation of a Turing machine by a dynamical system). Let f : M M for M Rk
→ ⊆
be a dynamical system, and let T : S S be a Turing machine. We say that f (τ,t(n))-simulates T if the
→
exists an encoder : S M with input complexity O(t(n)), a decoder : M ⇀ S with input complexity
E → D
O(t(n)), and a slowdown function τ : M ⇀ Z such that
≥0
1. (Encoding/Decoding) (s) C for all s S, where C := −1(s); and
s s
E ∈ ∈ D
2. (Simulation Condition) fτ(C ) = T(s) for all s S.
s
D◦ ∈
We note that Remark 3.5 for Definition 3.3 generalizes appropriately to Definition 3.14. Moreover Defini-
tion 3.14 readily generalizes to machines beyond Turing machines T, and we will consider such generaliza-
tions later on. We also make several additional remarks.
14Remark 3.15. Notice that in the definition of simulation (Definition 3.19), the encoder plays no role
except to ensure that there is an efficiently computable point inside each set C . However, we wish to
s
think of the encoder as serving the role of encoding the state s of T. In this definition of ‘simulation’,
E
we are imagining f as an ‘unknown’ or ‘natural’ system, and and as experimental apparatuses, where
E D
encodes a computational state into a state of the continuous system underlying f, and reads out the
E D
state. Thus, another natural version of the simulation condition of Definition 3.19 would be the condition
that
fτ (s) = T(s) for all s S. (9)
D◦ ◦E ∈
We instead use the ‘simulation condition’ in Definition 3.14 for technical convenience later; see the discus-
sion in the Section 3.1.4 on robust computation.
Remark 3.16. Theconditionthat and aredefinedbylow-complexitycircuits,besidesavoidingcertain
E D
pathologies (see Example 3.23 below), is meant to model the idea that an experimental apparatus must be
implemented in a ‘known’ way, and so its behavior must be efficiently computable. (See also [ACQ22] for
a related discussion.)
Remark 3.17. In many settings the configuration space S can be thought of as a tuple (S ,S ), where
fin inf
S liesinafinitesetandS liesinaninfiniteset,e.g.S isthestateofthefinitestatemachinecomposing
fin inf fin
the Turing machine head and S is the state of the tapes. We could make the stronger requirement that
inf
the decoder be written as ( , ) where computes the corresponding element of S in O(1)
fin inf fin fin
D D D D
time. This condition often holds in examples, and in the case of the simulation of a Turing machine by a
dynamical system lets us define a semialgebraic halting set −1(q ).
halt
D
Remark 3.18 (Modification for continuous-time dynamical systems). If f is a continuous-time dynamical
system, e.g. a map f : R M M written as f (x), then we can modify Definition 3.14 by letting
≥0 t
× →
τ : M ⇀ R (possibly implemented by a bounded-complexity BSS machine) and modify the second
≥0 C
condition in the definition to be f (C ) = T(s) for all s S.
τ s
D◦ ∈
Finally, we now arrive at our definition of a computational dynamical system.
Definition 3.19 (Computational dynamical system). The tuple (f, , ,τ,T) forms a computational
E D
dynamical system or CDS if f (τ,t(n))–simulates T with respect to the encoder and decoder , .
E D
WeobservethatDefinitions3.14and3.19provideameanstodiscusscomputationinautonomousdynamical
systems.
Remark 3.20 (Computable manifolds). It is natural to generalize Definition 3.19 to a setting where
the dynamics of f take place on a manifold, i.e. f : M M is a diffeomorphism of some manifold
→
M. In that case, we require that M is a computable manifold, namely we fix a finite collection of charts
ϕ : Rn U M for U , i = 1,...,r (such that the ϕ ’s agree on the non-trivial overlaps of the U′s)
i ⊃ i → i i i
and our functions and are now defined as compositions of BSS -computable functions to or from
C
(cid:83) E D
M = U with the charts ϕ .
i i i
Inseveralcasesbelow,wewillconsiderdynamicsonatorusf : (S1)n (S1)n oronaproductofatorus
→
with a Euclidean space; in those cases we will take our charts ϕ to be the usual charts [0,1)n (S1)n.
i
→
What we have achieved so far is a precise way of articulating what it means for a dynamical system
f to instantiate computation. As in our previous discussions, it is essential that we keep track of the
complexity of the encoder and decoder. To this end, we note that Definition 3.9 generalizes to the CDS
setting immediately:
Definition 3.21 (Optimal R-valued encoder and decoder). An R-valued encoder and decoder pair ,
E D
are optimal if has input time complexity Θ(n) and has output time complexity Θ(n).
E D
Moreover, the definition of a CDS allows us to articulate what it means for a dynamical system to be
Turing-universal:
15T<latexit sha1_base64="fgHuNCDYdX9HGtUgydBicwtDhS0=">AAACCnicbVC7TsMwFHV4lvIqMLIEKqSyVEmFCmMFC2OR+pKaEDmu01p1nMi+qaiizCz8CgsDCLHyBWz8De5jgJYjXen4nHvle48fc6bAsr6NldW19Y3N3FZ+e2d3b79wcNhSUSIJbZKIR7LjY0U5E7QJDDjtxJLi0Oe07Q9vJn57RKVikWjAOKZuiPuCBYxg0JJXOHGAPoAK0kbmpc7slSaCjbLsvlJSXuXcKxStsjWFuUzsOSmiOepe4cvpRSQJqQDCsVJd24rBTbEERjjN8k6iaIzJEPdpV1OBQ6rcdHpKZp5ppWcGkdQlwJyqvydSHCo1Dn3dGWIYqEVvIv7ndRMIrtyUiTgBKsjsoyDhJkTmJBezxyQlwMeaYCKZ3tUkAywxAZ1eXodgL568TFqVsl0tV+8uirXreRw5dIxOUQnZ6BLV0C2qoyYi6BE9o1f0ZjwZL8a78TFrXTHmM0foD4zPH6Mxmto=</latexit>u2niv(s2) T<latexit sha1_base64="vrweOFXbCNFKOxOfvUee1HbWr5w=">AAACCHicbVC7TsMwFHXKq5RXgJGBQIVUlipBqDBWsDAWqS+prSLHdVqrjhPZNxVVlJGFX2FhACFWPoGNv8FNO0DLka50fM698r3HizhTYNvfRm5ldW19I79Z2Nre2d0z9w+aKowloQ0S8lC2PawoZ4I2gAGn7UhSHHictrzR7dRvjalULBR1mES0F+CBYD4jGLTkmsddoA+g/KSeukn3JHslsWDjNC0p1z53zaJdtjNYy8SZkyKao+aaX91+SOKACiAcK9Vx7Ah6CZbACKdpoRsrGmEywgPa0VTggKpekh2SWmda6Vt+KHUJsDL190SCA6Umgac7AwxDtehNxf+8Tgz+dS9hIoqBCjL7yI+5BaE1TcXqM0kJ8IkmmEimd7XIEEtMQGdX0CE4iycvk+ZF2amUK/eXxerNPI48OkKnqIQcdIWq6A7VUAMR9Iie0St6M56MF+Pd+Ji15oz5zCH6A+PzB2JAmjQ=</latexit> univ(s0) s <latexit sha1_base64="c2ggoz2xKXc0heCrquZ0NyyNrBs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0oPtuv1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1atVa/eXlfpNHkcRTuAUzsGDK6jDHTSgCQyG8Ayv8OYI58V5dz4WrQUnnzmGP3A+fwAGII2l</latexit> 0
s
T<latexit sha1_base64="s4mXdMcJrdtO+/xDnMj9toDqOnA=">AAACCnicbVC7TsMwFHV4lvIqMLIEKqSyVEmFCmMFC2OR+pLaEDmu01p1nMi+qaiizCz8CgsDCLHyBWz8DW6bAVqOdKXjc+6V7z1exJkCy/o2VlbX1jc2c1v57Z3dvf3CwWFLhbEktElCHsqOhxXlTNAmMOC0E0mKA4/Ttje6mfrtMZWKhaIBk4g6AR4I5jOCQUtu4aQH9AGUnzRSN+nNX0ks2DhN7ysl5drnbqFola0ZzGViZ6SIMtTdwlevH5I4oAIIx0p1bSsCJ8ESGOE0zfdiRSNMRnhAu5oKHFDlJLNTUvNMK33TD6UuAeZM/T2R4ECpSeDpzgDDUC16U/E/rxuDf+UkTEQxUEHmH/kxNyE0p7mYfSYpAT7RBBPJ9K4mGWKJCej08joEe/HkZdKqlO1quXp3UaxdZ3Hk0DE6RSVko0tUQ7eojpqIoEf0jF7Rm/FkvBjvxse8dcXIZo7QHxifP6Gsmtk=</latexit>u2niv(s1) T<latexit sha1_base64="U4t7vnZ5497+xP0zFRDTDWiQcH8=">AAACCHicbVC7TsMwFHXKq5RXgJGBQIVUlipBqDBWsDAWqS+prSLHdVqrjhPZNxVVlJGFX2FhACFWPoGNv8FNO0DLka50fM698r3HizhTYNvfRm5ldW19I79Z2Nre2d0z9w+aKowloQ0S8lC2PawoZ4I2gAGn7UhSHHictrzR7dRvjalULBR1mES0F+CBYD4jGLTkmsddoA+g/KSeukn3JHslsWDjNC0p1zl3zaJdtjNYy8SZkyKao+aaX91+SOKACiAcK9Vx7Ah6CZbACKdpoRsrGmEywgPa0VTggKpekh2SWmda6Vt+KHUJsDL190SCA6Umgac7AwxDtehNxf+8Tgz+dS9hIoqBCjL7yI+5BaE1TcXqM0kJ8IkmmEimd7XIEEtMQGdX0CE4iycvk+ZF2amUK/eXxerNPI48OkKnqIQcdIWq6A7VUAMR9Iie0St6M56MF+Pd+Ji15oz5zCH6A+PzB2PFmjU=</latexit> univ(s1) <latexit sha1_base64="y02YUJ3gvkLzRign/IG63QGWEb4=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0oPtev1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1atVa/eXlfpNHkcRTuAUzsGDK6jDHTSgCQyG8Ayv8OYI58V5dz4WrQUnnzmGP3A+fwAHpI2m</latexit> 1
s
T<latexit sha1_base64="NbQUXL3A2u5kDvSmF8ObDPf8N1E=">AAACCnicbVC7TsMwFHV4lvIqMLIEKqSyVEmFCmMFC2OR+pLaEDmu01p1nMi+qaiizCz8CgsDCLHyBWz8DW6bAVqOdKXjc+6V7z1exJkCy/o2VlbX1jc2c1v57Z3dvf3CwWFLhbEktElCHsqOhxXlTNAmMOC0E0mKA4/Ttje6mfrtMZWKhaIBk4g6AR4I5jOCQUtu4aQH9AGUnzRSN+nNX0ks2DhN7ysl5VrnbqFola0ZzGViZ6SIMtTdwlevH5I4oAIIx0p1bSsCJ8ESGOE0zfdiRSNMRnhAu5oKHFDlJLNTUvNMK33TD6UuAeZM/T2R4ECpSeDpzgDDUC16U/E/rxuDf+UkTEQxUEHmH/kxNyE0p7mYfSYpAT7RBBPJ9K4mGWKJCej08joEe/HkZdKqlO1quXp3UaxdZ3Hk0DE6RSVko0tUQ7eojpqIoEf0jF7Rm/FkvBjvxse8dcXIZo7QHxifP6Anmtg=</latexit>u2niv(s0) T<latexit sha1_base64="TfgiU9AWr9ff/7JQ9vIe1X3l5iU=">AAACCHicbVC7TsMwFHV4lvIqMDIQqJDKUiUVKowVLIxF6ktqoshxndaq40T2TUUVZWThV1gYQIiVT2Djb3AfA7Qc6UrH59wr33v8mDMFlvVtrKyurW9s5rby2zu7e/uFg8OWihJJaJNEPJIdHyvKmaBNYMBpJ5YUhz6nbX94O/HbIyoVi0QDxjF1Q9wXLGAEg5a8wokD9AFUkDYyL3VOp680EWyUZSXlVS68QtEqW1OYy8SekyKao+4VvpxeRJKQCiAcK9W1rRjcFEtghNMs7ySKxpgMcZ92NRU4pMpNp4dk5rlWemYQSV0CzKn6eyLFoVLj0NedIYaBWvQm4n9eN4Hg2k2ZiBOggsw+ChJuQmROUjF7TFICfKwJJpLpXU0ywBIT0NnldQj24snLpFUp29Vy9f6yWLuZx5FDx+gMlZCNrlAN3aE6aiKCHtEzekVvxpPxYrwbH7PWFWM+c4T+wPj8AWVKmjY=</latexit> univ(s2) <latexit sha1_base64="XjsC28/WdZUWrk/mrAk0LRKrDL4=">AAAB6nicbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHoxWNF+wFtKJvtpl262YTdiVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJFIYdN1vZ219Y3Nru7BT3N3bPzgsHR23TJxqxpsslrHuBNRwKRRvokDJO4nmNAokbwfj25nffuLaiFg94iThfkSHSoSCUbTSg+lX+6WyW3HnIKvEy0kZcjT6pa/eIGZpxBUySY3pem6CfkY1Cib5tNhLDU8oG9Mh71qqaMSNn81PnZJzqwxIGGtbCslc/T2R0ciYSRTYzojiyCx7M/E/r5tieO1nQiUpcsUWi8JUEozJ7G8yEJozlBNLKNPC3krYiGrK0KZTtCF4yy+vkla14tUqtfvLcv0mj6MAp3AGF+DBFdThDhrQBAZDeIZXeHOk8+K8Ox+L1jUnnzmBP3A+fwAJKI2n</latexit> 2
. . .
. . .
<latexit sha1_base64="HQd6T1x+DWnCecq/3Xyf1pmmiH4=">AAAB7XicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rGC/YA2lM1m067dZMPupFBK/4MXD4p49f9489+4bXPQ1gcDj/dmmJkXpFIYdN1vZ219Y3Nru7BT3N3bPzgsHR03jco04w2mpNLtgBouRcIbKFDydqo5jQPJW8Hwbua3RlwboZJHHKfcj2k/EZFgFK3U7I5ChaZXKrsVdw6ySryclCFHvVf66oaKZTFPkElqTMdzU/QnVKNgkk+L3czwlLIh7fOOpQmNufEn82un5NwqIYmUtpUgmau/JyY0NmYcB7Yzpjgwy95M/M/rZBjd+BORpBnyhC0WRZkkqMjsdRIKzRnKsSWUaWFvJWxANWVoAyraELzll1dJ87LiVSvVh6ty7TaPowCncAYX4ME11OAe6tAABk/wDK/w5ijnxXl3Phata04+cwJ/4Hz+AM8Bj00=</latexit> <latexit sha1_base64="HQd6T1x+DWnCecq/3Xyf1pmmiH4=">AAAB7XicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rGC/YA2lM1m067dZMPupFBK/4MXD4p49f9489+4bXPQ1gcDj/dmmJkXpFIYdN1vZ219Y3Nru7BT3N3bPzgsHR03jco04w2mpNLtgBouRcIbKFDydqo5jQPJW8Hwbua3RlwboZJHHKfcj2k/EZFgFK3U7I5ChaZXKrsVdw6ySryclCFHvVf66oaKZTFPkElqTMdzU/QnVKNgkk+L3czwlLIh7fOOpQmNufEn82un5NwqIYmUtpUgmau/JyY0NmYcB7Yzpjgwy95M/M/rZBjd+BORpBnyhC0WRZkkqMjsdRIKzRnKsSWUaWFvJWxANWVoAyraELzll1dJ87LiVSvVh6ty7TaPowCncAYX4ME11OAe6tAABk/wDK/w5ijnxXl3Phata04+cwJ/4Hz+AM8Bj00=</latexit> <latexit sha1_base64="HQd6T1x+DWnCecq/3Xyf1pmmiH4=">AAAB7XicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rGC/YA2lM1m067dZMPupFBK/4MXD4p49f9489+4bXPQ1gcDj/dmmJkXpFIYdN1vZ219Y3Nru7BT3N3bPzgsHR03jco04w2mpNLtgBouRcIbKFDydqo5jQPJW8Hwbua3RlwboZJHHKfcj2k/EZFgFK3U7I5ChaZXKrsVdw6ySryclCFHvVf66oaKZTFPkElqTMdzU/QnVKNgkk+L3czwlLIh7fOOpQmNufEn82un5NwqIYmUtpUgmau/JyY0NmYcB7Yzpjgwy95M/M/rZBjd+BORpBnyhC0WRZkkqMjsdRIKzRnKsSWUaWFvJWxANWVoAyraELzll1dJ87LiVSvVh6ty7TaPowCncAYX4ME11OAe6tAABk/wDK/w5ijnxXl3Phata04+cwJ/4Hz+AM8Bj00=</latexit>
. . .
Figure 1: For Example 3.23 we depict M = [0,1]2, and shade in regions that encode configurations of the
Turing machine. Each such region is labelled by the configuration into which it is decoded by the given
D
in the example.
Definition 3.22 (Turing-universal CDS). We say that a CDS (f, , ,τ,T ) is a Turing-universal
univ
E D
CDS if T is a universal Turing machine. Moreover, we also say that f is Turing universal if there
univ
exists a Turing-universal CDS to which f belongs.
Various refinements of the above can be used to define a relationship between complexity classes and
dynamical systems, which we discuss in Appendix B. We emphasize that the above definition importantly
requires that , have bounded input and output complexity, respectively. This precludes examples akin
E D
to the one given in Section 3.1.2.
To be explicit, let us given a CDS generalization of the example in Section 3.1.2 which demonstrates
that trivial dynamical systems can ‘simulate’ universal Turing machines if we put no restrictions on the
encoder and decoder.
Example 3.23 (Unconstrained encoder and decoder). Let M = [0,1]2, and define f : [0,1]2 [0,1]2
→
by f(x,y) = (x/2,y). Now consider a universal Turing machine T with configuration space S. The
univ
S is enumerable, and thus we write it as S = s ,s ,... . Then define (s ) = (1, 1 ) and note that
{ 0 1 } E n 2n
fℓ(s ) = (1, 1 ). We define the decoder by
n 2ℓ 2n
∞
(cid:91) (cid:91) 1 1 1 1 1 1
−1(s ) = C := [ , ] [ , ]. (10)
D n sn 2ℓ − 2ℓ+2 2ℓ × 2n − 2n+2 2n
n=0 ℓ:Tℓ univ(sn)=sm
In Figure 1, we show M = [0,1]2 with regions each labelled by the configuration into which it will be
decoded. It can be checked that can be implemented by a BSS machine that does not have bounded
C
D
output complexity. Moreover, computing involves running the universal Turing machine T . The
univ
D
construction guarantees that fm(C ) = Tm (s) for all s S and all m Z . At a high level,
s univ ≥0
D ◦ ∈ ∈
the decoder takes in a point in its domain in [0,1]2 and by examining the y coordinate determines the
corresponding initial configuration s of the Turing machine. Then the decoder runs the Turing machine
n
for a number of steps ℓ determined by the x-coordinate, and outputs Tℓ (s ). As such, we see that a
univ n
decoder which is ‘too powerful’ makes trivial the notion of Turing universality for a dynamical system.
Our definitions prevent a ‘too powerful’ encoder or decoder from arising.
16
.
.
.
.
.
.
.
.
.
<latexit sha1_base64="HQd6T1x+DWnCecq/3Xyf1pmmiH4=">AAAB7XicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rGC/YA2lM1m067dZMPupFBK/4MXD4p49f9489+4bXPQ1gcDj/dmmJkXpFIYdN1vZ219Y3Nru7BT3N3bPzgsHR03jco04w2mpNLtgBouRcIbKFDydqo5jQPJW8Hwbua3RlwboZJHHKfcj2k/EZFgFK3U7I5ChaZXKrsVdw6ySryclCFHvVf66oaKZTFPkElqTMdzU/QnVKNgkk+L3czwlLIh7fOOpQmNufEn82un5NwqIYmUtpUgmau/JyY0NmYcB7Yzpjgwy95M/M/rZBjd+BORpBnyhC0WRZkkqMjsdRIKzRnKsSWUaWFvJWxANWVoAyraELzll1dJ87LiVSvVh6ty7TaPowCncAYX4ME11OAe6tAABk/wDK/w5ijnxXl3Phata04+cwJ/4Hz+AM8Bj00=</latexit>
<latexit sha1_base64="HQd6T1x+DWnCecq/3Xyf1pmmiH4=">AAAB7XicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rGC/YA2lM1m067dZMPupFBK/4MXD4p49f9489+4bXPQ1gcDj/dmmJkXpFIYdN1vZ219Y3Nru7BT3N3bPzgsHR03jco04w2mpNLtgBouRcIbKFDydqo5jQPJW8Hwbua3RlwboZJHHKfcj2k/EZFgFK3U7I5ChaZXKrsVdw6ySryclCFHvVf66oaKZTFPkElqTMdzU/QnVKNgkk+L3czwlLIh7fOOpQmNufEn82un5NwqIYmUtpUgmau/JyY0NmYcB7Yzpjgwy95M/M/rZBjd+BORpBnyhC0WRZkkqMjsdRIKzRnKsSWUaWFvJWxANWVoAyraELzll1dJ87LiVSvVh6ty7TaPowCncAYX4ME11OAe6tAABk/wDK/w5ijnxXl3Phata04+cwJ/4Hz+AM8Bj00=</latexit>
<latexit sha1_base64="HQd6T1x+DWnCecq/3Xyf1pmmiH4=">AAAB7XicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rGC/YA2lM1m067dZMPupFBK/4MXD4p49f9489+4bXPQ1gcDj/dmmJkXpFIYdN1vZ219Y3Nru7BT3N3bPzgsHR03jco04w2mpNLtgBouRcIbKFDydqo5jQPJW8Hwbua3RlwboZJHHKfcj2k/EZFgFK3U7I5ChaZXKrsVdw6ySryclCFHvVf66oaKZTFPkElqTMdzU/QnVKNgkk+L3czwlLIh7fOOpQmNufEn82un5NwqIYmUtpUgmau/JyY0NmYcB7Yzpjgwy95M/M/rZBjd+BORpBnyhC0WRZkkqMjsdRIKzRnKsSWUaWFvJWxANWVoAyraELzll1dJ87LiVSvVh6ty7TaPowCncAYX4ME11OAe6tAABk/wDK/w5ijnxXl3Phata04+cwJ/4Hz+AM8Bj00=</latexit>We conclude by discussing how Definition 3.14 allows us to reason about what it means for one dy-
namical system to simulate another dynamical system. We begin with an initial remark.
Remark 3.24 (Simulating one dynamical system by another). Suppose we have two dynamical systems
f
1
: M
1
M
1
for M
1
Rk1 and f
2
: M
2
M
2
for M
2
Rk2. Then Definition 3.14 readily generalizes to
→ ⊆ → ⊆
this setting if we let the encoders and decoders be e.g. 2-tape BSS machines over R.
C
Since our Definition 3.3 of the simulation of Turing machines so closely parallels Definition 3.14 of the
simulation of a Turing machine by an R-valued dynamical system, it is sensible to generalize our definition
of a CDS to account for both the discrete and R-valued settings. To this end, we have the following
definition.
Definition 3.25 (Discrete CDSs and sub-machines). Suppose that T (τ,t(n))-simulates T with respect
2 1
to , , in the sense of Definition 3.3. Then we say that the tuple (T , , ,τ,T ) is a (discrete) CDS,
2 1
E D E D
and we further say that T is a sub-machine of T .
1 2
We will often omit the word ‘discrete’ in ‘discrete CDS’ when the context is clear.
There is a very useful relationship between CDSs and sub-machines. We will state one version of this
relationship with the following definition and lemma.
Definition 3.26. Let f : M M by a dynamical system, and let τ ,τ : M ⇀ Z be slowdown functions
1 2 ≥0
→
then we define the τ
1
fτ
2
:= τ
1
fτ2, where f 2τ : x fτ2(x)(x). Then we have fτ1× fτ2 = fτ1 fτ2.
× ◦ (cid:55)→ ◦
We note that if τ and τ are computable by hybrid BSS machines, then τ τ may not be computable
1 2 C 1 f 2
×
contingent on f. This fact will not affect any of our results.
Lemma 3.27 (Fundamental lemma of sub-machines). Let (f, , ,τ,T ) be a CDS with encoder and
2
E D
decoder complexity O(t(n)), and let (T 2, (cid:101), (cid:101),τ˜,T 1) be a discrete CDS with encoder and decoder complexity
E D
O(t˜(n)). Then(f, (cid:101), (cid:101) ,τ fτ˜, T 1)isaCDSwithencoderanddecodercomplexityO(max t(n), t˜(n) ).
E◦E D◦D × { }
On the other hand, suppose that a given f cannot be extended to a CDS for a Turing machine T . Then
1
f likewise cannot be extended to a CDS for any T for which T is a sub-machine.
2 1
Proof. For the first part, suppose that T
1
: S
1
S 1, T
2
: S
2
S 2, and C(cid:101)s := (cid:101)−1(s) for s S 1. Let us
→ → D ∈
show that (f, (cid:101), (cid:101) , τ f τ˜, T 1) is a CDS with encoder and decoder complexity O(max t(n), t˜(n) ).
E◦E D◦D × { }
By composition, (cid:101) C s for all s S 1, where C s := ((cid:101) )−1(s), and
E ◦E ∈ ∈ D◦D
((cid:101) ) fτ× fτ (cid:101)(C s) = (cid:101) Tτ 2˜(C(cid:101)s) = T 1(s) (11)
D◦D ◦ D◦
holdsforalls S 1. Moreover,thecomplexitiesof (cid:101)and (cid:101) areO(max t(n), t˜(n) )sincecomposition
∈ E◦E D◦D { }
of functions corresponds to additivity of complexities. This completes the first part of the proof.
For the second part, suppose by contradiction that f cannot furnish a CDS for a T , but it can furnish
1
a CDS for a T such that T is a sub-machine. These statements imply the existence of CDSs of the form
2 1
(f, (cid:101), (cid:101) , τ f τ˜, T 1) and (T 2, (cid:101), (cid:101), τ˜,T 1), but then by the first part of the proof we can obtain a
E ◦E D◦D × E D
new CDS for which f simulates T , which is a contradiction.
1
The above Lemma 3.27 will be used throughout the paper in the following way. We will often prove
that some dynamical system f cannot be extended to a CDS of a machine T . But then the second part
1
of Lemma 3.27 implies that f likewise cannot be extended to a CDS for any machines T for which T is a
2 1
sub-machine. So, for instance, if an f cannot be extended to a CDS for some Turing machine T , then it
1
certainly cannot be extended to a CDS for a universal Turing machine T for which T is a sub-machine
univ 1
by virtue of universality.
Remark 3.28 (A refinement of Lemma 3.27). Suppose in the second part of Lemma 3.27 that we merely
stipulated that f cannot be extended to a CDS for T with encoder and decoder complexity O(t¯(n)) for
1
some t¯(n). Then a similar argument as in the proof of Lemma 3.27 establishes that if f can furnish
a CDS of a T such that T is a sub-machine, then the encoder and decoder complexity t(n) of any
2 1
(f, (cid:101), (cid:101) , τ f τ˜, T 1) and t¯(n) of any (T 2, (cid:101), (cid:101),τ˜, T 1) satisfies max t(n), t˜(n) Ω(t¯(n)).
E ◦E D◦D × E D { } ≥
173.1.4 Robustness and other conditions for CDS encoders and decoders.
We now turn to a formalization of robust computation. This model of robust computation is different from
other previous works [BGR12, GCB05], as described in Section 2. Recall that, as in Remark 3.15, given
a CDS, we are simulating T by encoding configurations s S using the encoder , running fτ for each
∈ E
computational step, and then decoding the configurations via . In many previous works on implementing
D
computation in continuous dynamical systems (see Section 2), one only requires that the dynamics is
‘correct’ on the image of , in other words, one has that
E
−1(s) = (s) for all s S.
D {E } ∈
We might call such a decoder a ‘point decoder’; if this is the decoder underlying a CDS, then clearly the
simulation of the underlying machine T is not robust in any sense.
One sense of robustness that one might wish for is that a small margin of error in the encoding still
leads to a valid simulation. That is, for every s S, there is some error ε such that for any x M of
s s
∈ ∈
distance at most ε from (s), the simulation equation is satisfied:
s
E
fτ(x ) = T(s) for all s S. (12)
s
D◦ ∈
For technical convenience, it is easier to formulate an analogous property entirely in terms of the behavior
of f on the sets C defined by the decoder , as follows:
s
D
Definition 3.29. We say that a decoder : M ⇀ S is robust when −1(s) is the closure of its own
D D
interior, for every s S. We say that a CDS is robust when the underlying decoder is robust, and when
∈ D
(s) lies in the interior of −1(s) for every s.
E D
It is clear that that given a robust CDS, if we set ε = sup d( (s),x) > 0 then the simulation
s x∈Cs
E
equation (12) is satisfied; and conversely one can show that there exists a metric d on M such that the
closed ball of radius ε around (s) is exactly −1(s). Thus, our model of robustness is analogous to
s
E D
requiring robustness of the simulation after perturbing f by a noise term with magnitude dependent on
x M.
∈
Below, we give two more conditions on decoders that are helpful when formulating certain results:
Definition 3.30. We say that a decoder : M ⇀ S is proper when −1(s) is a compact set for every
D D
s S. We say that the decoder is shrinking when it is proper and when the diameter
∈ D
diam( −1(s)) := sup d(x,y)
D
(x,y)∈D−1(s)2
shrinks to zero as the length of s goes to infinity, i.e. for every sequence of strings s S such that the
i
∈
lengths s diverge to infinity, we have that lim diam( −1(s)) = 0.
i i→∞ i
| | D
If S is the set of configurations of a Turing machine, we say that the decoder is hierarchically shrink-
ing when for every configuration s = (s ,s ) where s is the internal configuration of the turing machine
a b a
and s is the state of the tape, there exist compact subsets C′ M satisfying the following condition. Let
b s
⊂
s′ = (s′,s′) be a configuration of the Turing machine for which the internal state agrees with s (so s′ = s )
a b a a
and the region of the tape around the head agrees with s (so s′ is a substring of s′, and the head of both
b a b
configurations lies in s′ a). Then, the condition is that C s′ C s′; and such that the following two conditions
⊃
hold:
1. diam(C′) 0 as the length of s diverges; and
s b
→
2. Writing s = (s ,s ) and s = (s ,s ) for a pair of configurations of the Turing machine, we
1 a1 b1 2 a2 b2
have that either C′ is disjoint from C′ , or that either C′ C′ or C′ C′ ; and that C′ C′
s1 s2 s1
⊂
s2 s2
⊂
s1 s1
⊂
s2
exactly when s = s and s is is a substring of s with the head of the Turing machine lying in
a1 a2 b2 b1
s .
b2
Remark 3.31. ThedecoderinSection4.1associatedtoarobustlyTuring-universalCDSisbothshrinking
and hierarchically shrinking.
Remark 3.32. It is easy to see that a hierarchically shrinking decoder is shrinking.
183.2 Overview of dynamical systems
In this section, we will review basic notions about continuous and differentiable dynamical systems theory.
These concepts will be used in the subsequent constructions and proofs, and are very helpful for expressing
propertiesofdynamicalsystems. Wewillalsobrieflyreviewseveralstandardexamplesofsimpledynamical
systems which are used as sources of intuition for the possible types of dynamical behavior.
Basic notions. We have repeatedly used the well-known concept of a (discrete-time) dynamical system,
which is simply a map f : M M for some set M. We say f system is reversible when f−1 exists. For any
→
point x M, we can consider the forwards orbit x,f(x),f2(x),f3(x),... of x and if f is reversible, we
∈ { }
canconsideritsorbit ...,f−2(x),f−1(x),x,f(x),f2(x),... oritsbackwardsorbit ...,f−2(x),f−1(x),x .
{ } { }
Taking a union of forwards orbits produces an invariant set: a subset A M such that f(A) A. (Note
⊂ ⊂
that this does not imply that f(A) = A!)
ManyofthebasicquestionsregardingdynamicalsystemsareaboutthedecompositionofM intoorbits,
and the action of f on the orbits themselves. In particular, the simplest kinds of orbits are the orbits of
periodic points, i.e. of x M such that fn(x) = x for some n. One often hopes to understand the global
∈
dynamics of f by first understanding its periodic points.
Usually, the set M carries more structure, and f is compatible with this structure in a natural way.
For example, M may be a topological space or a metric space and f may be continuous, in which case
we are studying topological dynamics; or M may be a manifold and f may be differentiable with some
degree of regularity, i.e. f may be once-differentiable, twice-differentiable, H¨older-continuous, or smooth.
Alternatively, M may be a measurable space and f may preserve a measure µ on this space.
Remark 3.33. A phenomenon that may be surprising to those new to differentiable dynamics is that
smooth dynamical systems produce associated objects which have a much lower degree of regularity. For
example, when studying hyperbolic dynamical systems, as we will in Section 4.2, the stable and unstable
manifoldsassociatedtopointsxinhyperbolicinvariantsetsonlyvaryH¨oldercontinuouslywithx[KKH95],
even when the underlying dynamics are smooth. Similarly, certain fundamental results like the closing
lemma [PR83] are known to be true for C1 small perturbations but not for C∞-small perturbations, and
with energy-conservation constraints on f they may even be false [Her91]. This sensitivity of dynamical
results to the regularity of the mathematical objects under consideration often underlies deep dynamical
structure, but the relevance of such phenomena to scientific and modeling problems is still unclear.
Discrete- and continuous-time dynamics. Instead of the discrete-time systems f : M M defined
→
above, many physical systems are instead specified by a differential equation
dx
= g(x,t), x M, g : M R TM ,
dt ∈ × →
where g is a time-dependent vector field on a manifold M. The analog of the map f above is then the
continuous-time dynamical system f : M M for t R, associated to solutions of the differential
t
→ ∈
equation above. Thus, f is specified by the property that ∂ f (x) = g(x,t). When g is t-independent
∂t t
or 1-periodic (i.e. g(x,t) = g(x,t+1)), one can extract a discrete-time system from this continuous-time
systembyspecifyingf : M M viaf(x) = f(x,1); thiswillsatisfythepropertythatf2(x) = f(x,2), and
→
so forth, and thus we will be studying the behavior of the flow f(x,t) of the defining differential equation
at a discrete set of times. Then the dynamics of f : M M corresponds to viewing the dynamics specified
→
by the ODE viewed at a discrete set of times, as in Remark 3.18.
Remark 3.34. Definitions made for discrete-time systems usually have analogs for continuous-time sys-
tems. In this paper, we will largely stick to discrete-time systems because of their comparative mathe-
matical simplicity. It is worth noting that the behavior of discrete-time systems in n-dimensions models
in many ways resembles the behavior of continuous time-independent systems (i.e. with g(x,t) = g(x)) in
19M<latexit sha1_base64="zEAW6iYTrlnGL/3K/+0e37+hKE0=">AAAB6HicbVDLSgNBEOyNrxhfUY9eBoPgKeyKRI9BL16EBMwDkiXMTnqTMbOzy8ysEEK+wIsHRbz6Sd78GyfJHjSxoKGo6qa7K0gE18Z1v53c2vrG5lZ+u7Czu7d/UDw8auo4VQwbLBaxagdUo+ASG4Ybge1EIY0Cga1gdDvzW0+oNI/lgxkn6Ed0IHnIGTVWqt/3iiW37M5BVomXkRJkqPWKX91+zNIIpWGCat3x3MT4E6oMZwKnhW6qMaFsRAfYsVTSCLU/mR86JWdW6ZMwVrakIXP198SERlqPo8B2RtQM9bI3E//zOqkJr/0Jl0lqULLFojAVxMRk9jXpc4XMiLEllClubyVsSBVlxmZTsCF4yy+vkuZF2auUK/XLUvUmiyMPJ3AK5+DBFVThDmrQAAYIz/AKb86j8+K8Ox+L1pyTzRzDHzifP6ifjNw=</latexit> <latexit sha1_base64="r8W2eYnoFQcqPN4bL6QPXfDdmDA=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cK9gPaUDabTbt2sxt2J0Ip/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZemApu0PO+ncLa+sbmVnG7tLO7t39QPjxqGZVpyppUCaU7ITFMcMmayFGwTqoZSULB2uHodua3n5g2XMkHHKcsSMhA8phTglZq9Wik0PTLFa/qzeGuEj8nFcjR6Je/epGiWcIkUkGM6fpeisGEaORUsGmplxmWEjoiA9a1VJKEmWAyv3bqnlklcmOlbUl05+rviQlJjBknoe1MCA7NsjcT//O6GcbXwYTLNEMm6WJRnAkXlTt73Y24ZhTF2BJCNbe3unRINKFoAyrZEPzll1dJ66Lq16q1+8tK/SaPowgncArn4MMV1OEOGtAECo/wDK/w5ijnxXl3PhatBSefOYY/cD5/ALHpjzo=</latexit> · ·
·
N<latexit sha1_base64="oijmQlfsDrm++Gm4TLQocfg+4Dc=">AAAB6HicbVDLSgNBEOyNrxhfUY9eBoPgKeyKRI9BL54kAfOAZAmzk95kzOzsMjMrhJAv8OJBEa9+kjf/xkmyB00saCiquunuChLBtXHdbye3tr6xuZXfLuzs7u0fFA+PmjpOFcMGi0Ws2gHVKLjEhuFGYDtRSKNAYCsY3c781hMqzWP5YMYJ+hEdSB5yRo2V6ve9Ysktu3OQVeJlpAQZar3iV7cfszRCaZigWnc8NzH+hCrDmcBpoZtqTCgb0QF2LJU0Qu1P5odOyZlV+iSMlS1pyFz9PTGhkdbjKLCdETVDvezNxP+8TmrCa3/CZZIalGyxKEwFMTGZfU36XCEzYmwJZYrbWwkbUkWZsdkUbAje8surpHlR9irlSv2yVL3J4sjDCZzCOXhwBVW4gxo0gAHCM7zCm/PovDjvzseiNedkM8fwB87nD6ojjN0=</latexit>
x
f<latexit sha1_base64="pluf5lSmal7vrsSsWortBxU7ehg=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRahXsquSPVY9OKxgv2Adi3ZNNvGZpMlyYpl6X/w4kERr/4fb/4b03YP2vpg4PHeDDPzgpgzbVz328mtrK6tb+Q3C1vbO7t7xf2DppaJIrRBJJeqHWBNORO0YZjhtB0riqOA01Ywup76rUeqNJPizoxj6kd4IFjICDZWaob3Z+Wn016x5FbcGdAy8TJSggz1XvGr25ckiagwhGOtO54bGz/FyjDC6aTQTTSNMRnhAe1YKnBEtZ/Orp2gE6v0USiVLWHQTP09keJI63EU2M4Im6Fe9Kbif14nMeGlnzIRJ4YKMl8UJhwZiaavoz5TlBg+tgQTxeytiAyxwsTYgAo2BG/x5WXSPKt41Ur19rxUu8riyMMRHEMZPLiAGtxAHRpA4AGe4RXeHOm8OO/Ox7w152Qzh/AHzucPlvCOgA==</latexit> 2(x)
<latexit sha1_base64="vtUhjvouiS6k76ttA9H6+OxdfEI=">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHaNQY9ELx4hkUcCGzI79MLI7OxmZtZICF/gxYPGePWTvPk3DrAHBSvppFLVne6uIBFcG9f9dnJr6xubW/ntws7u3v5B8fCoqeNUMWywWMSqHVCNgktsGG4EthOFNAoEtoLR7cxvPaLSPJb3ZpygH9GB5CFn1Fip/tQrltyyOwdZJV5GSpCh1it+dfsxSyOUhgmqdcdzE+NPqDKcCZwWuqnGhLIRHWDHUkkj1P5kfuiUnFmlT8JY2ZKGzNXfExMaaT2OAtsZUTPUy95M/M/rpCa89idcJqlByRaLwlQQE5PZ16TPFTIjxpZQpri9lbAhVZQZm03BhuAtv7xKmhdlr1Ku1C9L1ZssjjycwCmcgwdXUIU7qEEDGCA8wyu8OQ/Oi/PufCxac042cwx/4Hz+AOnLjQc=</latexit>
f<latexit sha1_base64="Rin3VQQXDyCChoYtAbauwi+y9B8=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRahXsquSPVY9OKxgv2AdinZNNuGJtklyYpl6V/w4kERr/4hb/4bs+0etPXBwOO9GWbmBTFn2rjut1NYW9/Y3Cpul3Z29/YPyodHbR0litAWiXikugHWlDNJW4YZTruxolgEnHaCyW3mdx6p0iySD2YaU1/gkWQhI9hkUlh9Oh+UK27NnQOtEi8nFcjRHJS/+sOIJIJKQzjWuue5sfFTrAwjnM5K/UTTGJMJHtGepRILqv10fusMnVlliMJI2ZIGzdXfEykWWk9FYDsFNmO97GXif14vMeG1nzIZJ4ZKslgUJhyZCGWPoyFTlBg+tQQTxeytiIyxwsTYeEo2BG/55VXSvqh59Vr9/rLSuMnjKMIJnEIVPLiCBtxBE1pAYAzP8ApvjnBenHfnY9FacPKZY/gD5/MHb/GN3A==</latexit> (x)
·
<latexit sha1_base64="r8W2eYnoFQcqPN4bL6QPXfDdmDA=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cK9gPaUDabTbt2sxt2J0Ip/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZemApu0PO+ncLa+sbmVnG7tLO7t39QPjxqGZVpyppUCaU7ITFMcMmayFGwTqoZSULB2uHodua3n5g2XMkHHKcsSMhA8phTglZq9Wik0PTLFa/qzeGuEj8nFcjR6Je/epGiWcIkUkGM6fpeisGEaORUsGmplxmWEjoiA9a1VJKEmWAyv3bqnlklcmOlbUl05+rviQlJjBknoe1MCA7NsjcT//O6GcbXwYTLNEMm6WJRnAkXlTt73Y24ZhTF2BJCNbe3unRINKFoAyrZEPzll1dJ66Lq16q1+8tK/SaPowgncArn4MMV1OEOGtAECo/wDK/w5ijnxXl3PhatBSefOYY/cD5/ALHpjzo=</latexit> ··
Figure 2: A sketch of the Poincar´e section of a map. We consider time-dependent dynamics f : M M
t
→
with f = Id. A Poincar´e section of the map is a submanifold N of M such that for any x N and any
0
∈
k Z , we can define fk(x) as the kth time the trajectory f (x) intersects with N (which we require to
≥0 t
∈
occur for each k).
(n+1)-dimensions, because in many cases one can find a Poincar´e section for the dynamics. A Poincar´e
section is a hypersurface N M such that g(x) is transverse to N for all x. Then one defines a discrete
⊂
dynamical system f : N N by setting f(x) = f t∗(x), where t∗ = inf t > 0 : f t(x) N . See Figure 2
→ { ∈ }
for a depiction.
Notions of transitivity, ergodicity, and chaos. Thereareseveralbasicnotionsthathelptoarticulate
and characterize the behavior dynamical systems, and which we will use repeatedly throughout this paper.
We quickly introduce them here, and then illustrate them with standard examples in the subsequent
section. Specifically, there are various ways of discussing the extent to which the dynamics of f ‘mix up’
certain regions in M, all of which highlight different aspects of the dynamical behavior of f.
Let f : M M be a continuous dynamical system on a metric space M.
→
Definition 3.35 (Topological transitivity). Let C M be closed and f-invariant, i.e. f(C) C. We say
⊂ ⊂
that f is topologically transitive on C if there is an x C such that the orbit of x is dense in C. This
∈
implies that f(C) = C.
With notation as in the previous definition, we write
(cid:110) (cid:111) (cid:110) (cid:111)
Ws(C) = x M : lim d(fn(x),C) = 0 , Wu(C) = x M : lim d(f−n(x),C) = 0 . (13)
∈ n→∞ ∈ n→∞
The set Ws(C) stable set of C; points in Ws(C) are eventually attracted to C. Similarly, Wu(C) is the
unstable set of C. One may want to find invariant sets C which can be thought of as ‘attractors’ [Sma67],
such that the entire dynamics is decomposed, in some sense, into the interaction between the attractors of
the dynamics.
Definition 3.36 (Topologically mixing). Let C M be closed and f-invariant. We say that f is topo-
⊂
logically mixing on C if for every two open sets U and V in C (in the subspace topology) there is an N
such that for all n > N, fn(U) V = .
∩ ̸ ∅
Lemma 3.37 ([KKH95]). If X is compact and f is topologically mixing on C then f is topologically
transitive on C.
There are yet stronger notions of mixing besides the topological ones described above. To define these
oneasksfortheexistenceofaBorelprobabilitymeasureµsuchthatf∗µ = µ, i.e.µisaninvariant measure
for f. In this case, (f,X,µ) is a continuous, measure-preserving system.
20Definition 3.38 (Ergodic). Given a continuous, measure-preserving system (f,X,µ), we say that f is
ergodic if for any A X such that f−1(A) = A we have that µ(A) = 0 or µ(A) = 1.
⊂
Remark 3.39. One can speak of course of discontinuous measure-preserving systems and make such
definitions in that context, but such examples will not be the focus of this work.
It is easily shown that if f is ergodic then µ-almost-all points of X have dense orbits in X, and thus that
f is topologically transitive on X. However, ergodicity does not imply topological mixing of f on X, while
therearevariousmeasure-theoreticnotionsofmixingthatdoimplytopologicalmixingoff onX [KKH95].
Standard examples, reviewed below, show that while mixing and ergodicity arise in chaotic systems,
they are not necessary hallmarks of chaotic behavior. Instead, chaotic behavior is better quantified using
other concepts. One important notion is that of hyperbolicity: the idea that the dynamics of f are sensitive
to initial conditions, i.e. that small errors in initial condition get exponentially larger as time goes on. An
invariant set on which there is a quantitative bound on the amount of such sensitivity is called a hyperbolic
set:
Definition 3.40 (Hyperbolic sets). Let C M be closed and f-invariant. We say that C is hyperbolic
⊂
if there there is a decomposition
TM = T+ T−
|C C ⊕ C
together with constants c,d > 0, λ > 1, such that
dfn(v) > cλn v for v T+, (14)
∥ ∥ ∥ ∥ ∈ C
and dfn(v) < dλ−n v for v T−, where in each of these statements n runs over the natural numbers.
∥ ∥ ∥ ∥ ∈ C
This property does not depend on the choice of Riemannian metric that we are using to measure the lengths
of tangent vectors.
Remark 3.41. Note that if T− = 0, which is allowed in the definition of a hyperbolic set, there is indeed
C
no sensitivity to initial conditions. In particular, if f is the time-1 gradient flow of some Morse function g,
then a minimum of g is a hyperbolic set for f. Nonetheless, in typical examples T+ = .
C ̸ ∅
Clearly if T+ = 0 then the maximal constant λ such that the condition (14) holds is a measure of the
C ̸
instability of the dynamics of f on C. The measure of infinitesimal instability of f along a trajectory of f
is the Lyapunov exponent:
log Dfn(v)
L(f,x) = sup lim ∥ ∥.
v∈Txn→∞ n
Here one uses any Riemannan metric on M to measure the lengths of vectors, and this quantity does not
depend on the metric chosen. It is a fundamental theorem of Oseledets [Ose68] that given an invariant
measure µ for f, the Lyapunov exponents are the same for µ-almost-every x M. (One can define
∈
Lyapunov exponents as functions of v instead, in which case one has several Lyapunov exponents for each
x M; [Ose68] states that this set of exponents is the same for µ-almost everywhere x.)
∈
Fundamental examples. Basic intuition about the behavior of dynamical systems is captured in well-
known examples. Here we give a lightning review of what may be considered from a mathematical per-
spective to be the simplest kinds of dynamical systems; see Figure 3 for a depiction. The rest of this paper
focusesonprovingsomeresultsthattrytoanalyzethecomputational capabilities ofnaturalgeneralizations
of these simplest examples.
1. Circle rotations. This is a dynamical system f : S1 S1 which rotates the circle by a fixed
→
angle. Parameterizing S1 as R/Z, the real numbers modulo 1, a circle rotation is given by the
map t (x) = x + τ for some τ. We can organize circle rotations into the rational rotations for
τ
21(<latexit sha1_base64="FMQ07mDyp4bHdDFF/HFT8o3twL0=">AAAB8XicbVDLSgNBEJz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmS5iddJIhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXdXEEth0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiOdR5JCPdCpgBKRTUUaCEVqyBhYGEZjC6mfrNR9BGROoexzH4IRso0RecoZUeOghPmJbY2aRbKLpldwa6TLyMFEmGWrfw1elFPAlBIZfMmLbnxuinTKPgEib5TmIgZnzEBtC2VLEQjJ/OLp7QU6v0aD/SthTSmfp7ImWhMeMwsJ0hw6FZ9Kbif147wf6VnwoVJwiKzxf1E0kxotP3aU9o4CjHljCuhb2V8iHTjKMNKW9D8BZfXiaN87JXKVfuLorV6yyOHDkmJ6REPHJJquSW1EidcKLIM3klb45xXpx352PeuuJkM0fkD5zPH1JOkLQ=</latexit> a) ✓<latexit sha1_base64="5bCyd0gYv8CeZMXZW/avxKBuZUk=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cK9gPaUDbbTbt2sxt2J0IJ/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZemAhu0PO+ncLa+sbmVnG7tLO7t39QPjxqGZVqyppUCaU7ITFMcMmayFGwTqIZiUPB2uH4dua3n5g2XMkHnCQsiMlQ8ohTglZq9XDEkPTLFa/qzeGuEj8nFcjR6Je/egNF05hJpIIY0/W9BIOMaORUsGmplxqWEDomQ9a1VJKYmSCbXzt1z6wycCOlbUl05+rviYzExkzi0HbGBEdm2ZuJ/3ndFKPrIOMySZFJulgUpcJF5c5edwdcM4piYgmhmttbXToimlC0AZVsCP7yy6ukdVH1a9Xa/WWlfpPHUYQTOIVz8OEK6nAHDWgChUd4hld4c5Tz4rw7H4vWgpPPHMMfOJ8/p4mPMw==</latexit> (<latexit sha1_base64="8dgaeLR4X2FyPbpmDy1pwKzqOhI=">AAAB8XicbVDLSgNBEJz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmS5iddJIhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXdXEEth0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiOdR5JCPdCpgBKRTUUaCEVqyBhYGEZjC6mfrNR9BGROoexzH4IRso0RecoZUeOghPmJaCs0m3UHTL7gx0mXgZKZIMtW7hq9OLeBKCQi6ZMW3PjdFPmUbBJUzyncRAzPiIDaBtqWIhGD+dXTyhp1bp0X6kbSmkM/X3RMpCY8ZhYDtDhkOz6E3F/7x2gv0rPxUqThAUny/qJ5JiRKfv057QwFGOLWFcC3sr5UOmGUcbUt6G4C2+vEwa52WvUq7cXRSr11kcOXJMTkiJeOSSVMktqZE64USRZ/JK3hzjvDjvzse8dcXJZo7IHzifP1PUkLU=</latexit> b) (<latexit sha1_base64="u2TwwKMVTyridKtO0sT6Dd/dTzA=">AAAB8XicbVDLSgNBEJz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmS5iddJIhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXdXEEth0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiOdR5JCPdCpgBKRTUUaCEVqyBhYGEZjC6mfrNR9BGROoexzH4IRso0RecoZUeOghPmJb42aRbKLpldwa6TLyMFEmGWrfw1elFPAlBIZfMmLbnxuinTKPgEib5TmIgZnzEBtC2VLEQjJ/OLp7QU6v0aD/SthTSmfp7ImWhMeMwsJ0hw6FZ9Kbif147wf6VnwoVJwiKzxf1E0kxotP3aU9o4CjHljCuhb2V8iHTjKMNKW9D8BZfXiaN87JXKVfuLorV6yyOHDkmJ6REPHJJquSW1EidcKLIM3klb45xXpx352PeuuJkM0fkD5zPH1VakLY=</latexit> c)
3<latexit sha1_base64="zAYiae0AiBpVJ1FsFEw+B7zCIFA=">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHbVoEeiF4+QyCOBDZkdemFkdnYzM2tCCF/gxYPGePWTvPk3DrAHBSvppFLVne6uIBFcG9f9dnJr6xubW/ntws7u3v5B8fCoqeNUMWywWMSqHVCNgktsGG4EthOFNAoEtoLR3cxvPaHSPJYPZpygH9GB5CFn1FipftkrltyyOwdZJV5GSpCh1it+dfsxSyOUhgmqdcdzE+NPqDKcCZwWuqnGhLIRHWDHUkkj1P5kfuiUnFmlT8JY2ZKGzNXfExMaaT2OAtsZUTPUy95M/M/rpCa88SdcJqlByRaLwlQQE5PZ16TPFTIjxpZQpri9lbAhVZQZm03BhuAtv7xKmhdlr1Ku1K9K1dssjjycwCmcgwfXUIV7qEEDGCA8wyu8OY/Oi/PufCxac042cwx/4Hz+AIE3jMI=</latexit> 4<latexit sha1_base64="j7wS8F7tKFAwj8Nbw54mK7S7CAI=">AAAB5HicbVBNS8NAEJ3Urxq/qlcvi0XwVBKR6rHoxWMF+wFtKJvtpF272YTdjVBCf4EXD4pXf5M3/43bNgdtfTDweG+GmXlhKrg2nvftlDY2t7Z3yrvu3v7B4VHFPW7rJFMMWywRieqGVKPgEluGG4HdVCGNQ4GdcHI39zvPqDRP5KOZphjEdCR5xBk1Vnq4GlSqXs1bgKwTvyBVKNAcVL76w4RlMUrDBNW653upCXKqDGcCZ24/05hSNqEj7FkqaYw6yBeHzsi5VYYkSpQtachC/T2R01jraRzazpiasV715uJ/Xi8z0U2Qc5lmBiVbLooyQUxC5l+TIVfIjJhaQpni9lbCxlRRZmw2rg3BX315nbQva369Vq82boswynAKZ3ABPlxDA+6hCS1ggPACb/DuPDmvzseyseQUEyfwB87nDxg5i5k=</latexit> 2<latexit sha1_base64="2fvfthwg1mRLBhwA3jth0GTm+tU=">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHaJQY9ELx4hkUcCGzI79MLI7OxmZtaEEL7AiweN8eonefNvHGAPClbSSaWqO91dQSK4Nq777eQ2Nre2d/K7hb39g8Oj4vFJS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfju7nffkKleSwfzCRBP6JDyUPOqLFSo9IvltyyuwBZJ15GSpCh3i9+9QYxSyOUhgmqdddzE+NPqTKcCZwVeqnGhLIxHWLXUkkj1P50ceiMXFhlQMJY2ZKGLNTfE1MaaT2JAtsZUTPSq95c/M/rpia88adcJqlByZaLwlQQE5P512TAFTIjJpZQpri9lbARVZQZm03BhuCtvrxOWpWyVy1XG1el2m0WRx7O4BwuwYNrqME91KEJDBCe4RXenEfnxXl3PpatOSebOYU/cD5/AH+zjME=</latexit>
1<latexit sha1_base64="gfDDG5HdC2uj59mXU+2xx3lABwE=">AAAB6HicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rEF+wFtKJvtpF272YTdjVBCf4EXD4p49Sd589+4bXPQ1gcDj/dmmJkXJIJr47rfztr6xubWdmGnuLu3f3BYOjpu6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j+WDmSToR3QoecgZNVZqeP1S2a24c5BV4uWkDDnq/dJXbxCzNEJpmKBadz03MX5GleFM4LTYSzUmlI3pELuWShqh9rP5oVNybpUBCWNlSxoyV39PZDTSehIFtjOiZqSXvZn4n9dNTXjjZ1wmqUHJFovCVBATk9nXZMAVMiMmllCmuL2VsBFVlBmbTdGG4C2/vEpalxWvWqk2rsq12zyOApzCGVyAB9dQg3uoQxMYIDzDK7w5j86L8+58LFrXnHzmBP7A+fwBfi+MwA==</latexit>
<latexit sha1_base64="C5RW14eS04mUW6KyoCXEp/B0R3k=">AAAB+HicbVBNSwMxEM3Wr1o/uurRS7AInsquSPVY9OKxgv2AdinZNNuGZpMlmVXq0l/ixYMiXv0p3vw3pu0etPXBwOO9GWbmhYngBjzv2ymsrW9sbhW3Szu7e/tl9+CwZVSqKWtSJZTuhMQwwSVrAgfBOolmJA4Fa4fjm5nffmDacCXvYZKwICZDySNOCVip75Z7Qsmh5sMREK3VY9+teFVvDrxK/JxUUI5G3/3qDRRNYyaBCmJM1/cSCDKigVPBpqVealhC6JgMWddSSWJmgmx++BSfWmWAI6VtScBz9fdERmJjJnFoO2MCI7PszcT/vG4K0VWQcZmkwCRdLIpSgUHhWQp4wDWjICaWEKq5vRXTEdGEgs2qZEPwl19eJa3zql+r1u4uKvXrPI4iOkYn6Az56BLV0S1qoCaiKEXP6BW9OU/Oi/PufCxaC04+c4T+wPn8AXXKk6E=</latexit>
 ! 4<latexit sha1_base64="j7wS8F7tKFAwj8Nbw54mK7S7CAI=">AAAB5HicbVBNS8NAEJ3Urxq/qlcvi0XwVBKR6rHoxWMF+wFtKJvtpF272YTdjVBCf4EXD4pXf5M3/43bNgdtfTDweG+GmXlhKrg2nvftlDY2t7Z3yrvu3v7B4VHFPW7rJFMMWywRieqGVKPgEluGG4HdVCGNQ4GdcHI39zvPqDRP5KOZphjEdCR5xBk1Vnq4GlSqXs1bgKwTvyBVKNAcVL76w4RlMUrDBNW653upCXKqDGcCZ24/05hSNqEj7FkqaYw6yBeHzsi5VYYkSpQtachC/T2R01jraRzazpiasV715uJ/Xi8z0U2Qc5lmBiVbLooyQUxC5l+TIVfIjJhaQpni9lbCxlRRZmw2rg3BX315nbQva369Vq82boswynAKZ3ABPlxDA+6hCS1ggPACb/DuPDmvzseyseQUEyfwB87nDxg5i5k=</latexit>
1<latexit sha1_base64="gfDDG5HdC2uj59mXU+2xx3lABwE=">AAAB6HicbVBNS8NAEJ34WetX1aOXxSJ4KolI9Vj04rEF+wFtKJvtpF272YTdjVBCf4EXD4p49Sd589+4bXPQ1gcDj/dmmJkXJIJr47rfztr6xubWdmGnuLu3f3BYOjpu6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j+WDmSToR3QoecgZNVZqeP1S2a24c5BV4uWkDDnq/dJXbxCzNEJpmKBadz03MX5GleFM4LTYSzUmlI3pELuWShqh9rP5oVNybpUBCWNlSxoyV39PZDTSehIFtjOiZqSXvZn4n9dNTXjjZ1wmqUHJFovCVBATk9nXZMAVMiMmllCmuL2VsBFVlBmbTdGG4C2/vEpalxWvWqk2rsq12zyOApzCGVyAB9dQg3uoQxMYIDzDK7w5j86L8+58LFrXnHzmBP7A+fwBfi+MwA==</latexit> 2<latexit sha1_base64="2fvfthwg1mRLBhwA3jth0GTm+tU=">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHaJQY9ELx4hkUcCGzI79MLI7OxmZtaEEL7AiweN8eonefNvHGAPClbSSaWqO91dQSK4Nq777eQ2Nre2d/K7hb39g8Oj4vFJS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfju7nffkKleSwfzCRBP6JDyUPOqLFSo9IvltyyuwBZJ15GSpCh3i9+9QYxSyOUhgmqdddzE+NPqTKcCZwVeqnGhLIxHWLXUkkj1P50ceiMXFhlQMJY2ZKGLNTfE1MaaT2JAtsZUTPSq95c/M/rpia88adcJqlByZaLwlQQE5P512TAFTIjJpZQpri9lbARVZQZm03BhuCtvrxOWpWyVy1XG1el2m0WRx7O4BwuwYNrqME91KEJDBCe4RXenEfnxXl3PpatOSebOYU/cD5/AH+zjME=</latexit>
3<latexit sha1_base64="zAYiae0AiBpVJ1FsFEw+B7zCIFA=">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHbVoEeiF4+QyCOBDZkdemFkdnYzM2tCCF/gxYPGePWTvPk3DrAHBSvppFLVne6uIBFcG9f9dnJr6xubW/ntws7u3v5B8fCoqeNUMWywWMSqHVCNgktsGG4EthOFNAoEtoLR3cxvPaHSPJYPZpygH9GB5CFn1FipftkrltyyOwdZJV5GSpCh1it+dfsxSyOUhgmqdcdzE+NPqDKcCZwWuqnGhLIRHWDHUkkj1P5kfuiUnFmlT8JY2ZKGzNXfExMaaT2OAtsZUTPUy95M/M/rpCa88SdcJqlByRaLwlQQE5PZ16TPFTIjxpZQpri9lbAhVZQZm03BhuAtv7xKmhdlr1Ku1K9K1dssjjycwCmcgwfXUIV7qEEDGCA8wyu8OY/Oi/PufCxac042cwx/4Hz+AIE3jMI=</latexit>
(<latexit sha1_base64="IUOYbY/vMmvCz0r+kBqv5b5ADcY=">AAAB8XicbVBNS8NAEN34WetX1aOXYBHqpSQi1WPRi8cK9gPbUDabSbt0swm7E7GE/gsvHhTx6r/x5r9x2+agrQ8GHu/NMDPPTwTX6Djf1srq2vrGZmGruL2zu7dfOjhs6ThVDJosFrHq+FSD4BKayFFAJ1FAI19A2x/dTP32IyjNY3mP4wS8iA4kDzmjaKSHHsITZpXgbNIvlZ2qM4O9TNyclEmORr/01QtilkYgkQmqddd1EvQyqpAzAZNiL9WQUDaiA+gaKmkE2stmF0/sU6MEdhgrUxLtmfp7IqOR1uPIN50RxaFe9Kbif143xfDKy7hMUgTJ5ovCVNgY29P37YArYCjGhlCmuLnVZkOqKEMTUtGE4C6+vExa51W3Vq3dXZTr13kcBXJMTkiFuOSS1MktaZAmYUSSZ/JK3ixtvVjv1se8dcXKZ47IH1ifP1bgkLc=</latexit> d) (<latexit sha1_base64="Fs56sW4XXeu2fZDxJjqKDLOb1Hg=">AAAB8XicbVDLSgNBEJz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmS5iddJIhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXdXEEth0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiOdR5JCPdCpgBKRTUUaCEVqyBhYGEZjC6mfrNR9BGROoexzH4IRso0RecoZUeOghPmJbgbNItFN2yOwNdJl5GiiRDrVv46vQinoSgkEtmTNtzY/RTplFwCZN8JzEQMz5iA2hbqlgIxk9nF0/oqVV6tB9pWwrpTP09kbLQmHEY2M6Q4dAselPxP6+dYP/KT4WKEwTF54v6iaQY0en7tCc0cJRjSxjXwt5K+ZBpxtGGlLcheIsvL5PGedmrlCt3F8XqdRZHjhyTE1IiHrkkVXJLaqROOFHkmbySN8c4L8678zFvXXGymSPyB87nD1hmkLg=</latexit> e) (<latexit sha1_base64="wRKSQjhFiyN/3ZdGQnZOSZ/wdcU=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmIcxOZpMhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXeXH0th0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiGa+zSEa65VPDpVC8jgIlb8Wa09CXvOmPbqZ+85FrIyJ1j+OYd0M6UCIQjKKVHjrInzAtBWeTXqHolt0ZyDLxMlKEDLVe4avTj1gScoVMUmPanhtjN6UaBZN8ku8khseUjeiAty1VNOSmm84unpBTq/RJEGlbCslM/T2R0tCYcejbzpDi0Cx6U/E/r51gcNVNhYoT5IrNFwWJJBiR6fukLzRnKMeWUKaFvZWwIdWUoQ0pb0PwFl9eJo3zslcpV+4uitXrLI4cHMMJlMCDS6jCLdSgDgwUPMMrvDnGeXHenY9564qTzRzBHzifP1nskLk=</latexit> f)
<latexit sha1_base64="C5RW14eS04mUW6KyoCXEp/B0R3k=">AAAB+HicbVBNSwMxEM3Wr1o/uurRS7AInsquSPVY9OKxgv2AdinZNNuGZpMlmVXq0l/ixYMiXv0p3vw3pu0etPXBwOO9GWbmhYngBjzv2ymsrW9sbhW3Szu7e/tl9+CwZVSqKWtSJZTuhMQwwSVrAgfBOolmJA4Fa4fjm5nffmDacCXvYZKwICZDySNOCVip75Z7Qsmh5sMREK3VY9+teFVvDrxK/JxUUI5G3/3qDRRNYyaBCmJM1/cSCDKigVPBpqVealhC6JgMWddSSWJmgmx++BSfWmWAI6VtScBz9fdERmJjJnFoO2MCI7PszcT/vG4K0VWQcZmkwCRdLIpSgUHhWQp4wDWjICaWEKq5vRXTEdGEgs2qZEPwl19eJa3zql+r1u4uKvXrPI4iOkYn6Az56BLV0S1qoCaiKEXP6BW9OU/Oi/PufCxaC04+c4T+wPn8AXXKk6E=</latexit>
 !
(<latexit sha1_base64="JC4UQ7bNWMtNkh3ewki9EgGwpkg=">AAAB8XicbVDLSgNBEJz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmIcxOepMhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXeXH0th0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiOdR5JCPd8pkBKRTUUaCEVqyBhb6Epj+6mfrNR9BGROoexzF0QzZQIhCcoZUeOghPmJYGZ5NeoeiW3RnoMvEyUiQZar3CV6cf8SQEhVwyY9qeG2M3ZRoFlzDJdxIDMeMjNoC2pYqFYLrp7OIJPbVKnwaRtqWQztTfEykLjRmHvu0MGQ7NojcV//PaCQZX3VSoOEFQfL4oSCTFiE7fp32hgaMcW8K4FvZWyodMM442pLwNwVt8eZk0zstepVy5uyhWr7M4cuSYnJAS8cglqZJbUiN1wokiz+SVvDnGeXHenY9564qTzRyRP3A+fwBbcpC6</latexit> g) (<latexit sha1_base64="Ji3SezqAOaU+vudJeB8FxmO5mAQ=">AAAB8XicbVDLSgNBEJz1GeMr6tHLYBDiJeyKRI9BLx4jmAcmIcxOepMhs7PLTK8YlvyFFw+KePVvvPk3TpI9aGJBQ1HVTXeXH0th0HW/nZXVtfWNzdxWfntnd2+/cHDYMFGiOdR5JCPd8pkBKRTUUaCEVqyBhb6Epj+6mfrNR9BGROoexzF0QzZQIhCcoZUeOghPmJaGZ5NeoeiW3RnoMvEyUiQZar3CV6cf8SQEhVwyY9qeG2M3ZRoFlzDJdxIDMeMjNoC2pYqFYLrp7OIJPbVKnwaRtqWQztTfEykLjRmHvu0MGQ7NojcV//PaCQZX3VSoOEFQfL4oSCTFiE7fp32hgaMcW8K4FvZWyodMM442pLwNwVt8eZk0zstepVy5uyhWr7M4cuSYnJAS8cglqZJbUiN1wokiz+SVvDnGeXHenY9564qTzRyRP3A+fwBc+JC7</latexit> h)
Figure 3: Various fundamental examples in dynamical systems theory. (a) A circle map. (b) An integrable
system represented as a base manifold with tori fibered over it. The red curves are either periodic or
irrational orbits, contingent on the corresponding point on the base manifold. (c) The Arnold cat map. (d)
One iteration of the Smale horseshoe map. (e) A member of the quadratic family. Depicted is a cobweb
diagram for an orbit. (f) A gradient flow system, with various flow lines depicted. (g) An orbit of the
Lorenz system, tending towards the Lorenz attractor. (h) An instance of the standard map, with various
orbits displayed.
which τ Q/Z, and the complement of the rational rotations, namely the irrational ones. Rational
∈
rotations are periodic (a power of f is the identity) and so are not topologically transitive; while
irrational rotations are topologically transitive, ergodic (with respect to the uniform measure on S1),
but not topologically mixing.
2. Torus translations and integrable systems. One can generalize circle rotations to torus trans-
lations, which are maps f : (S1)n (S1)n given by f(x) = x+v for some vector v Rn. These
→ ∈
have similar behavior to circle rotations but are higher-dimensional; moreover, they are pieces of
the dynamics of integrable systems, which are the (time-1 flows) of Hamiltonian dynamical systems
associated to H : M R where M is a manifold with a symplectic form ω such that H is part of a
→
system of pairwise Poisson-commuting Hamiltonians (H ,...,H ) with H = H. The latter arise in
1 n 1
many important physical problems, e.g. the Euler equations for a a free rotating body in 3d [Arn13].
The result connecting these two settings is the Liouville-Arnold theorem [Arn13], which states that
if there is a point x M such that (dH ) is nonzero for each H , then there is a neighborhood U of
i x i
∈
x and a diffeomorphism ψ : U (S1)n V where V is some open subset in Rn and the dynamics
→ ×
satisfy ψ f ψ−1(a,b) = a+b. Later in this paper, we will strongly constrain the computations
◦ ◦
that can be robustly performed by integrable systems; see Theorem 1.5. The Lyapunov exponent
computed with respect to any x M when f is a torus translaton or an integrable system is zero.
∈
223. Doublingmap. Aqualitativelydifferenttypeofdynamicalsystemarisesbyreplacingthetranslation
defining a circle map f : S1 S1 with a multiplication of the coordinate. Again parameterizing
→
S1 = R/Z, let f(x) = 2x. This is called the doubling map, and is the simplest Anosov map. Writing
real numbers x [0,1) in their 2-adic expansions x = 0.a a a ..., we have that the 2-adic expansion
1 2 3
∈ N
of f(x) is 0.a a a ...; thus, the dynamics of f is essentially that of the shift map on the set 0,1
2 3 4
{ }
of sequences of binary digits which simply drops the first element of a half-infinite string of digits.
One sees immediately from this description that f is topologically mixing, since fn(I) contains (0,1)
for any nonempty interval I and any sufficiently large n. In fact, all of S1 is an invariant closed
hyperbolic set, the map preserves the uniform measure on S1, and the Lyapunov exponent with
respect to this measure is log2. The description of the dynamics of f in terms of the shift map on
decimal sequences is the simplest instance of symbolic dynamics (further reviewed in Appendix C).
4. Anosov maps. One drawback of the doubling map is that it is not invertible. However, the non-
invertiblitycanberemovedbypassingtohigherdimensions. Forexample, theArnold cat map, which
is a diffeomorphism f : T2 T2 of the two-torus T2, is defined via
→
f(x,y) = (2x+y,x+y), where T2 = S1 S1 = (R/Z)2.
×
This map has a representation via symbolic dynamics, where one divides T2 up into certain blocks
consisting of certain symbols, such that almost all trajectories of the cat map can be understood in
termsoftherestrictionoftheshiftmaptoasimplesubsetof 0,1 Z . AllofT2isahyperbolicinvariant
{ }
set, there is a 1-dimensional stable bundle and a 1-dimensional unstable bundle, and the Lyapunov
exponent (with respect to the area measure on T2, which is an invariant measure) is (3+√5)/2.
More generally, systems for which the entire domain is a single hyperbolic transitive invariant set are
called Anosov, and are the prototypical examples of systems which are strongly chaotic – so chaotic
that their dynamics, while unpredictable, is considered by researchers in dynamical systems theory
to be completely understood [KKH95, Part 4].
5. 1-dimensional dynamics. Beyond Anosov maps, it is fruitful to first study low-dimensional ex-
amples. There is a rich theory describing the dynamics of 1-dimensional maps f : S1 S1 or maps
→
f : [ β,β] [0,1]. Famously, the quadratic family of maps f (x) = a x2 has an invariant interval
a
− → −
[ β,β], and as discovered by Feigenbaum [Fei78] the resulting maps show a transition from periodic
−
dynamics to chaotic dynamics as one increases a past a critical threshold. There is an elaborate
theory of smooth maps of the interval without flat critical points [DMVS12].
6. Gradient flows. Generalizing in a different direction, a simple higher-dimensional example of a
nonlineardynamicalsystemisthetime-1flowofthegradientflowofapotentialfunctionU : M R.
→
The invariant sets are all contained in the locus of critical points Crit(U) of U. Moreover, when U is
Morse, i.e. when the Hessian of U has full rank at every critical point of U, the invariant sets are the
(isolated) critical points, and each critical point comprises a hyperbolic invariant set. In that case,
M becomes decomposed into regions which are attracted to the various critical points: we have
(cid:71)
M = Ws( p ),
{ }
p∈Crit(U)
and there is an associated graph that describes possible gradient flows from one critical point to
another.
In Section 4.2 we will strongly constrain computational properties of the class of systems which
encompass the features of gradient flows and of Anosov diffeomorphisms, called Axiom A systems,
and include both as special cases.
7. Beyond the simplest examples. Outside of mild generalizations of the class of systems described
above, the behavior of differentiable dynamical systems becomes extremely complex and difficult to
23analyze mathematically. For example, there are non-uniformly hyperbolic systems [PC10], which
include famous examples such as the Lorenz system [Lor63], and there is the puzzling behavior of
essentially all non-integrable Hamiltonian systems, even small perturbations of integrable examples.
The latter type of behavior is modeled by the standard map, and the related H`enon family [You98],
which can contain Lorenz-like attractors. Many basic questions, such as the existence of any values
of the parameter of the standard map for which the Lyapunov exponent is nonnegative, are famous
and difficult open problems in the theory of differentiable dynamical systems [PC10].
We wish to use the notion of a computational dynamical system introduced in Section 3.1.3 to ask
questions about the computational capacity of each of these types of dynamical systems.
4 Autonomous CDSs
In this section, we employ our definition of a CDS to examine the topological and geometric characteristics
ofautonomousdynamicalsystemsthateitherfacilitateorpreventtheirabilitytosimulateuniversalTuring
machines. To demonstrate the possibility of robustly Turing-universal CDSs, we begin by constructing an
example on a disk. Next we study Axiom A dynamical systems as a well-studied class of ‘chaotic’ systems,
and prove that they cannot be extended to robustly Turing-universal CDSs. We the prove another non-
universality result for measure-preserving systems and thus for integrable systems. Taken all together,
our non-universality articulate a sense in which ‘chaos’ and ‘order’ are in tension with Turing-universality.
Thereafter we prove more refined statements about how mixing in certain dynamical systems constrains
the computational complexity of the Turing machines it can realize as a CDS.
4.1 Example of a Turing-complete CDS
Here we construct a robustly Turing-universal CDS (f, , ,τ,T ) where f : D2 D2 is a smooth
univ
E D →
map on the disk, τ(x) = 1, and , have optimal complexity Θ(n). Our construction is inspired in part
E D
by [Moo91] and [CMPSP21]. The latter work constructs an area-preserving, smooth map f : D2 D2
→
which forms a Turing-universal CDS, but as discussed previously, their map is not robust in our sense.
(In fact, as we show later in Section 4.3, it is not possible for an area-preserving map to be extended to
a robustly Turing-universal CDS.) To make a robust version of the construction in [CMPSP21], some new
ideas are involved which we will explain shortly.
For our purposes, we will consider a single-tape universal machine T given by the triple (Q,Γ,δ)
univ
where Γ = ,0,1,2 , and Q = 2k for some k. Recalling that is the blank symbol, it will be
∪{⊔} {⊔ } | | ⊔
useful to associate 00, 0 01, 1 10, 2 11, so that we can write Γ = 00,01,10,11 .
⊔ → → → → ∪ {⊔} { }
Moreover we will label each state q Q by a k-bit string z 0,1 k. The Turing machine T can read
univ
∈ ∈ { }
blank symbols, but it cannot write blank symbols. The basic strategy in constructing a CDS for this T
univ
is to re-express T in terms of a generalized shift map. To do so, we need to establish some notation,
univ
following [Moo91].
Z
Let A be some finite alphabet and let Σ = A be the set of bi-infinite sequences of A. We further let
σ : Σ Σ be the shift map, such that for s Σ we have σ(s) denote s shifted one spot to the right. We
→ ∈
will use σ as an ingredient to define ‘generalized shift maps’ below, but first we require a useful definition.
Definition 4.1 (Domain of effect and domain of dependence, adapted from [Moo91]). Let h : Σ Σ
where we write Σ = (cid:81) A . Let Ee be the subset of Z containing all j such that h(s) = s for at→ least
i∈Z i j
̸
j
one s. Here h(s) is the jth coordinates of h(s), and similarly for s . Then the domain of effect of h
j j
is De := (cid:81) A . Informally, the domain of effect of h contains the A ’s in Σ which are affected by the
i∈Ee i i
inputs to h.
Moreover, let Ed be the smallest subset Z containing all j such that h can be written as
h(s) = s for j / Ee, h(s) = h¯ ((s ) ) for j Ee.
j j j j i i∈Ed
∈ ∈
24Then the domain of dependence of h is Dd := (cid:81) A . More informally, the domain of dependence
i∈Ed i
of h contains the A ’s in Σ on which outputs of h depend.
i
Similarly, if h is a map Σ Z then the domain of dependence is (cid:81) A where Ed is the smallest
subset of Z such that h factors→ through the projection to (cid:81) A .
i∈Ed i
i∈Ed i
Having defined the domain of effect and domain of dependence, we can now define generalized shift maps
as follows.
Definition 4.2 (Generalized shift map, adapted from [Moo91]). Let F : Σ Z have a finite domain of
→
dependence which we denote by Dd. Moreover, let G : Σ Σ have a finite domain of dependence Dd and
F → G
a finite domain of effect De. Then we call
G
Φ(a) = σF(s)(G(s)) (15)
a generalized shift map.
ThereisacloseconnectionbetweenTuringmachinesandgeneralizedshiftmaps,articulatedby[Moo91]
in the following theorem:
Theorem 4.3 (Turing machines are conjugate to generalized shift maps, from [Moo91]). For any Turing
machine T, there is a generalized shift Φ = (F,G) conjugate to T.
Let us work out the correspondence explicitly for our universal Turing machine T mentioned above.
univ
Recall that T can be expressed as a map T : S S where S = Γ∗ Q Γ∗. As such a configuration
univ univ
→ × ×
in S can be written as γ qγ for γ ,γ Γ∗ and q Q. Noting that in our setting Γ = 00,01,10,11
1 2 1 2
and Q = 0,1 k where 00 corresponds to∈ the blank∈ symbol, we can treat S as a subset of{ 0,1 Z which}
{ } { }
contains finitely many 1’s. Accordingly, we can re-express an s S by
∈
s = 00s s .s s s s s s 00 (16)
−2m+2 −1 0 1 2 k+1 k+2 k+2n+1
··· ··· ··· ··· ···
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
γ1 q γ2
for all s 0,1 . We have put in a decimal point between s and s for later convenience. If for our
i −1 −0
∈ { }
Turing machine δ(s s , s s ) = (s′ s′ , s′ s′ , a) for a L,R,S , then T acts on s
2 ··· k+1 k+2 k+3 2 ··· k+1 k+1 k+3 ∈ { } univ
as

00s s .s s s′ s′ s s s′ s′ s 00 if a = L
 ··· −2m+2 ··· −3 −2 −1 2 ··· k+1 0 1 k+2 k+3··· k+2n+1 ···
T univ(s) = ···00s
−2m+2
···s −1.s 0s 1s′
0
···s′ k+1s′ k+2s′ k+3···s k+2n+100
···
if a = S . (17)
 00s s s .s′ s′ s′ s′ s s 00 if a = R
··· −2m+2 ··· 0 1 k+2 k+3 2 ··· k+1 k+4 ··· k+n+1 ···
Now let us define the maps F : 0,1 Z Z and G : 0,1 Z Z by
{ } → { } →

2 if a = L

−
F(s) := 0 if a = S , (18)

2 if a = R

00s s .s′ s′ s′ s′ s s s′ s′ s 00 if a = L
 ··· −2m+2 ··· −1 2 3 4 ··· k+1 0 1 k+2 k+3··· k+2n+1 ···
G(s) := 00s s .s s s′ s′ s′ s′ s 00 if a = S . (19)
··· −2m+2 ··· −1 0 1 2 ··· k+1 k+2 k+3··· k+2n+1 ···
 00s s .s s s′ s′ s′ s′ s s 00 if a = R
··· −2m+2 ··· −1 0 1 k+2 k+3 2 ··· k+1 k+4 ··· k+2n+1 ···
We note that the domain of dependence Dd of F and the domain of dependence Dd of G are bits s
F G 2
through s . Similarly, the domain of effect De of G are bits s through s . As such, Dd, Dd, and
k+3 G 0 k+3 F G
25De are all finite. Inspecting (17), (18), and (19), we find that G(s) = σ−F(s)(T (s)), giving us the
G univ
equivalence
T (s) = σF(s)(G(s)). (20)
univ
Thus, we see that T can be written as a generalized shift map in accordance with Theorem 4.3. Note
univ
that while at any finite time step a Turing machine will only act on the subset S which we noted has
finitely many ones (since the initial conditions to the Turing machine are likewise in S), the dynamics of
Z
the Turing machine extends to all of 0,1 by e.g. (20).
{ }
Withtheabovedefinitionsathand, wecannowprovidethepromisedconstructionofarobustlyTuring-
universal CDS.
Theorem 4.4 (Existence of a smooth, robustly Turing-universal CDS). There is a robustly Turing-
universal CDS (f, , ,τ,T ) where f : D2 D2 is a smooth map on the disk, τ(x) = 1, and ,
univ
E D → E D
have optimal complexity Θ(n).
Proof. Let D := Dd Dd De, which consists of the first bit to the left of the decimal in s and first
tot F ∪ G ∪ G
k + 2 bits to the right of the decimal in s. We let the dynamics f : D2 D2 take place on the unit
→
disk centered at (1, 1), containing the square [ 1,1]2. The configurations of the Turing machine will be
3 3 −3
encoded and decoded from this square. Accordingly, let us define the encoder and decoder .
E D
Let ⃗s = s s s and s = s s be half-infinite sequences which we take as having finitely many
0 1 2 −2 −1
··· ···
1’s. We can put a ⃗s and s together to get a bi-infinite string s with the notation s = s.⃗s. Then the
functions
(cid:40)
max k 1 : s = 1 if ⃗s = 000
k−1
⃗s := { ≥ } ̸ ··· , (21)
x
| | 0 if ⃗s = 000
···
(cid:40)
max k 1 : s = 1 if s = 000
−k
s := { ≥ } ̸ ··· , (22)
y
| | 0 if s = 000
···
respectively locate the position of the right-most 1 in ⃗s before there is an infinite string of 0’s to the right,
and the position of the left-most 1 in s before there is an infinite string of zeros to the left. While the
definitions of ⃗s and s in (21) and (22) are clear, it is not obvious as written how to compute them. To
x y
| | | |
remedy this, we write down two manifestly computable (but harder to parse at a glance) formulae below,
which are tailored to our encoding:

min j k+2 : s s s = 000 if s s = 0 0 and s s = 00
 j+1 j+2 j+3 0 k+1 k+2 k+3
 { ≥ } ··· ̸ ··· ̸
⃗s x := max 1 j k+2 : s j−1 = 1 if s 0 s k+1 = 0 0 and s k+2s k+3 = 00 , (23)
| |  { ≤ ≤ } ··· ̸ ···
0 if s s = 0 0
0 k+1
··· ···
s := min j 0 : s s s = 000 . (24)
y −j−3 −j−2 −j−1
| | { ≥ }
These definitions rely on the fact that the initialized part of the tape of our Turing machine must be a
contiguous string of non-blank symbols, and that the Turing machine can only write non-blank symbols.
Assuch, therewillneverbeanon-blanksymbolfollowedbyblanksymbolsfollowedbyanon-blanksymbol.
We further define ternary encodings of ⃗s and s by the functions
|⃗s|x |s|y+1
(cid:88) (cid:88)
X(⃗s) := 2s 3−(j+1), Y(s) := 2s 3−j. (25)
j −j
j=0 j=1
Using (21) and (25), we can define the sets C = −1(s) by
s
D
1 1
C := [X(⃗s) , X(⃗s)] [Y(s) , Y(s)], (26)
s
− 3|⃗s|x+1 × − 3|s|y+1
26
⃗
⃗
⃗⃗
⃗
⃗
⃗
⃗
⃗
⃗
⃗
⃗
⃗
⃗
⃗1<latexit sha1_base64="lguNCwsjmqKdD3AZgTq/+9cFxyk=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55PuuN6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGz41t</latexit>1.0 1<latexit sha1_base64="kVLIWK2oQQJ3aw+X+m3QCzX8QLc=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU8iKtB6LXjxWMG2hDWWz3bRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbTzv2yltbG5t75R3K3v7B4dH1eOTtk4yRZlPE5Gobkg0E1wy33AjWDdVjMShYJ1wcjf3O09MaZ7IRzNNWRCTkeQRp8RYycfY9fCgWvNcbwG0TnBBalCgNah+9YcJzWImDRVE6x72UhPkRBlOBZtV+plmKaETMmI9SyWJmQ7yxbEzdGGVIYoSZUsatFB/T+Qk1noah7YzJmasV725+J/Xy0x0E+Rcpplhki4XRZlAJkHzz9GQK0aNmFpCqOL2VkTHRBFqbD4VGwJefXmdtK9cXHfrD9e15m0RRxnO4BwuAUMDmnAPLfCBAodneIU3RzovzrvzsWwtOcXMKfyB8/kDNsyNqA==</latexit>1.01 1<latexit sha1_base64="8whj6p7yq4vhMBsWASIVu76cm2U=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRbB07IRqR6LXjxWsB/QLiWbZtvQJLskWaGU/gUvHhTx6h/y5r8x2+5Bqw8GHu/NMDMvSgU3Ngi+vNLa+sbmVnm7srO7t39QPTxqmyTTlLVoIhLdjYhhgivWstwK1k01IzISrBNNbnO/88i04Yl6sNOUhZKMFI85JTaXMPbxoFoL/GAB9JfggtSgQHNQ/ewPE5pJpiwVxJgeDlIbzoi2nAo2r/Qzw1JCJ2TEeo4qIpkJZ4tb5+jMKUMUJ9qVsmih/pyYEWnMVEauUxI7NqteLv7n9TIbX4czrtLMMkWXi+JMIJug/HE05JpRK6aOEKq5uxXRMdGEWhdPxYWAV1/+S9oXPq779fvLWuOmiKMMJ3AK54DhChpwB01oAYUxPMELvHrSe/bevPdla8krZo7hF7yPb8hTjW4=</latexit>1.1 1<latexit sha1_base64="sKGc9qdjV1klQ/ErE8s0b2m2IwU=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU8iKtB6LXjxWMG2hDWWz3bRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbTzv2yltbG5t75R3K3v7B4dH1eOTtk4yRZlPE5Gobkg0E1wy33AjWDdVjMShYJ1wcjf3O09MaZ7IRzNNWRCTkeQRp8RYycfYxXhQrXmutwBaJ7ggNSjQGlS/+sOEZjGThgqidQ97qQlyogyngs0q/UyzlNAJGbGepZLETAf54tgZurDKEEWJsiUNWqi/J3ISaz2NQ9sZEzPWq95c/M/rZSa6CXIu08wwSZeLokwgk6D552jIFaNGTC0hVHF7K6Jjogg1Np+KDQGvvrxO2lcurrv1h+ta87aIowxncA6XgKEBTbiHFvhAgcMzvMKbI50X5935WLaWnGLmFP7A+fwBOFGNqQ==</latexit>1.11
1<latexit sha1_base64="oH/zjZu7+dNyrgfjYJevkFDPHKo=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB9/1euWK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBXEI0y</latexit> .0 1<latexit sha1_base64="erdSlbvEHAxwZAkRjNk0OZsY3yE=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55LueP6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGy41t</latexit>.01 1<latexit sha1_base64="fr6rnBT23QG65mqx+aa+YjFW6vw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB9/1e+WK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBYlI0z</latexit> .1 1<latexit sha1_base64="djXm0AJB/IqBadJ4dFtpF+b7n+U=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRbB07IRqR6LXjxWsB/QLiWbZtvQJLskWaGU/gUvHhTx6h/y5r8x2+5Bqw8GHu/NMDMvSgU3Ngi+vNLa+sbmVnm7srO7t39QPTxqmyTTlLVoIhLdjYhhgivWstwK1k01IzISrBNNbnO/88i04Yl6sNOUhZKMFI85JTaXsI/xoFoL/GAB9JfggtSgQHNQ/ewPE5pJpiwVxJgeDlIbzoi2nAo2r/Qzw1JCJ2TEeo4qIpkJZ4tb5+jMKUMUJ9qVsmih/pyYEWnMVEauUxI7NqteLv7n9TIbX4czrtLMMkWXi+JMIJug/HE05JpRK6aOEKq5uxXRMdGEWhdPxYWAV1/+S9oXPq779fvLWuOmiKMMJ3AK54DhChpwB01oAYUxPMELvHrSe/bevPdla8krZo7hF7yPb8hQjW4=</latexit>.11
1<latexit sha1_base64="b84kzvlAvEO2mxrsoWgNho2C9S4=">AAAB63icbVDLSgMxFL2pr1pfVZdugkVwVWZEqsuiG5cV7APaoWTSTBuaZIYkI5Shv+DGhSJu/SF3/o2ZdhZaPZBwOOde7r0nTAQ31vO+UGltfWNzq7xd2dnd2z+oHh51TJxqyto0FrHuhcQwwRVrW24F6yWaERkK1g2nt7nffWTa8Fg92FnCAknGikecEptLvlf3htWa+xfAf4lfkBoUaA2rn4NRTFPJlKWCGNP3vcQGGdGWU8HmlUFqWELolIxZ31FFJDNBtth1js+cMsJRrN1TFi/Unx0ZkcbMZOgqJbETs+rl4n9eP7XRdZBxlaSWKbocFKUC2xjnh+MR14xaMXOEUM3drphOiCbUungqLgR/9eS/pHNR9xv1xv1lrXlTxFGGEziFc/DhCppwBy1oA4UJPMELvCKJntEbel+WllDRcwy/gD6+AcVJjWw=</latexit>0.0 1<latexit sha1_base64="DqtpyMd1By3iNSyl4tzXV/8x7b0=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseiF48VTFtoQ9lsN+3SzSbsToQS+hu8eFDEqz/Im//GbZuDVh8s+3hvhpl5YSqFQdf9ckpr6xubW+Xtys7u3v5B9fCobZJMM+6zRCa6G1LDpVDcR4GSd1PNaRxK3gknt3O/88i1EYl6wGnKg5iOlIgEo2gl33Prrjeo1uy3APlLvILUoEBrUP3sDxOWxVwhk9SYnuemGORUo2CSzyr9zPCUsgkd8Z6lisbcBPli2Rk5s8qQRIm2TyFZqD87chobM41DWxlTHJtVby7+5/UyjK6DXKg0Q67YclCUSYIJmV9OhkJzhnJqCWVa2F0JG1NNGdp8KjYEb/Xkv6R9Ufca9cb9Za15U8RRhhM4hXPw4AqacAct8IGBgCd4gVdHOc/Om/O+LC05Rc8x/ILz8Q01RY2n</latexit>0.01 1<latexit sha1_base64="bFlHL4wuNKNlvHyLSYkiGTRaIek=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55HuuP6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGzY1t</latexit>0.1 1<latexit sha1_base64="rZCZOPcxcckhuKuankZUOQIYWMo=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU8iKtB6LXjxWMG2hDWWz3bRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbTzv2yltbG5t75R3K3v7B4dH1eOTtk4yRZlPE5Gobkg0E1wy33AjWDdVjMShYJ1wcjf3O09MaZ7IRzNNWRCTkeQRp8RYyceei/GgWvNcbwG0TnBBalCgNah+9YcJzWImDRVE6x72UhPkRBlOBZtV+plmKaETMmI9SyWJmQ7yxbEzdGGVIYoSZUsatFB/T+Qk1noah7YzJmasV725+J/Xy0x0E+Rcpplhki4XRZlAJkHzz9GQK0aNmFpCqOL2VkTHRBFqbD4VGwJefXmdtK9cXHfrD9e15m0RRxnO4BwuAUMDmnAPLfCBAodneIU3RzovzrvzsWwtOcXMKfyB8/kDNsqNqA==</latexit>0.11
0<latexit sha1_base64="uo5cZ3GqQ2YOc7akab3j9tZf1lo=">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRbBU9kVqR6LXjxWtB/QLiWbZtvQbHZJZoWy9Cd48aCIV3+RN/+NabsHbX2Q8Hhvhpl5QSKFQdf9dgpr6xubW8Xt0s7u3v5B+fCoZeJUM95ksYx1J6CGS6F4EwVK3kk0p1EgeTsY38789hPXRsTqEScJ9yM6VCIUjKKVHtyq2y9X7D8HWSVeTiqQo9Evf/UGMUsjrpBJakzXcxP0M6pRMMmnpV5qeELZmA5511JFI278bL7qlJxZZUDCWNunkMzV3x0ZjYyZRIGtjCiOzLI3E//zuimG134mVJIiV2wxKEwlwZjM7iYDoTlDObGEMi3sroSNqKYMbTolG4K3fPIqaV1UvVq1dn9Zqd/kcRThBE7hHDy4gjrcQQOawGAIz/AKb450Xpx352NRWnDynmP4A+fzB1WKjTE=</latexit> .0 0<latexit sha1_base64="HajtYLdprCiqTh6UfrgiYcSAP+M=">AAAB63icbVDLSgMxFL2pr1pfVZdugkVwVWZEqsuiG5cV7APaoWTSTBuaZIYkI5Shv+DGhSJu/SF3/o2ZdhZaPRByOOde7r0nTAQ31vO+UGltfWNzq7xd2dnd2z+oHh51TJxqyto0FrHuhcQwwRVrW24F6yWaERkK1g2nt7nffWTa8Fg92FnCAknGikecEptLXt3zh9Wa+xbAf4lfkBoUaA2rn4NRTFPJlKWCGNP3vcQGGdGWU8HmlUFqWELolIxZ31FFJDNBtth1js+cMsJRrN1TFi/Unx0ZkcbMZOgqJbETs+rl4n9eP7XRdZBxlaSWKbocFKUC2xjnh+MR14xaMXOEUM3drphOiCbUungqLgR/9eS/pHNR9xv1xv1lrXlTxFGGEziFc/DhCppwBy1oA4UJPMELvCKJntEbel+WllDRcwy/gD6+AcVEjWw=</latexit>.01 0<latexit sha1_base64="9XSQbZKoHxe7KU7mAINCFwEX8xM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB8/1e+WK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBXDo0y</latexit> .1 0<latexit sha1_base64="Tc/+Jm6ob5mjFAvqVd3Brj4ntP0=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55Lm+P6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGyY1t</latexit>.11
Figure 4: An illustration of the some of the sets C in the square [ 1,1]2. The numerical labels of the sets
s −3
indicate the corresponding s, with the understanding that there are infinitely many zeros to the left and
infinitely many zeros to the right (i.e. 1.01 is shorthand for 01.01⃗0). The sets are organized according to a
thickened version of a Cantor encoding in two dimensions.
which evidently are closed sets with non-trivial interior (and as such, our CDS will be robust in the sense
wepreviouslydefined). MoreoverallC ’sarecontainedinthesquare[ 1,1]2, andaredepictedinFigure4.
s −3
We can think of C as a thickened version of a two-dimensional Cantor set encoding of s. The encoder
s
E
is then given by
1 1 1 1
(s) := (X(⃗s) , Y(s) ), (27)
E − 2 3|⃗s|x+1 − 2 3|s|y+1
and satisfies (s) = s. Moreover, both and can be implemented by hybrid BSS machines with
C
D◦E E D
complexity Θ(n).
Having constructed and , we now turn to constructing appropriate dynamics f : D2 D2. Before
E D →
we proceed, let us define the smooth, monotonic functions
 
ax for x b x for x b
  ≤ −2   ≤ −2
q (x) := ϕ (x) for b x 0 , r (x) := ψ (x) for b x 0 , (28)
a,b  a,b − 2 ≤ ≤ a,b  a,b − 2 ≤ ≤
x for x 0 ax for x 0
≥ ≥
where ϕ (x) and ψ (x) are smooth, monotonic interpolating functions (which can be constructed explic-
a,b a,b
itly or otherwise are guaranteed to exist by the Whitney extension theorem). The functions q (x) and
a,b
r (x) will play important roles in the definition of f.
a,b
Our strategy in the remainder of the proof is to construct smooth maps S and G from a nice subset of
D2 (containing (cid:83) C ) to D2 such that S(C ) = C and G(C ) = C . Then we can compose these
s∈S s s σ(s) s G(s)
maps in an appropriate way and extend the domain to all of D2 to arrive at a mapping f : D2 D2 such
→
that f(C ) = C = C . We begin by constructing G.
s σF(s)(G(s)) Tuniv(s)
Recall from (19) that G only depends on s s s . Let us denote the 2k+4 possible bit strings
0 1 k+3
···
s s s by z ,...,z . It will be convenient to find nice sets B such that C B for all s, with
0 1
···
k+3 1 2k+4 zm s
⊂
zm
s s s = z . If⃗0 := 000 , an example of nice sets B is given by
0 1
···
k+3 m
···
zm
1 1 1
B = [X(z ⃗0) , X(z ⃗0)+ ] [ ,1]. (29)
zm m − 3|zm⃗0|x+1 m 3k+4 × −3
27
⃗
⃗
⃗1<latexit sha1_base64="lguNCwsjmqKdD3AZgTq/+9cFxyk=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55PuuN6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGz41t</latexit>1.0 1<latexit sha1_base64="kVLIWK2oQQJ3aw+X+m3QCzX8QLc=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU8iKtB6LXjxWMG2hDWWz3bRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbTzv2yltbG5t75R3K3v7B4dH1eOTtk4yRZlPE5Gobkg0E1wy33AjWDdVjMShYJ1wcjf3O09MaZ7IRzNNWRCTkeQRp8RYycfY9fCgWvNcbwG0TnBBalCgNah+9YcJzWImDRVE6x72UhPkRBlOBZtV+plmKaETMmI9SyWJmQ7yxbEzdGGVIYoSZUsatFB/T+Qk1noah7YzJmasV725+J/Xy0x0E+Rcpplhki4XRZlAJkHzz9GQK0aNmFpCqOL2VkTHRBFqbD4VGwJefXmdtK9cXHfrD9e15m0RRxnO4BwuAUMDmnAPLfCBAodneIU3RzovzrvzsWwtOcXMKfyB8/kDNsyNqA==</latexit>1.01 1<latexit sha1_base64="8whj6p7yq4vhMBsWASIVu76cm2U=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRbB07IRqR6LXjxWsB/QLiWbZtvQJLskWaGU/gUvHhTx6h/y5r8x2+5Bqw8GHu/NMDMvSgU3Ngi+vNLa+sbmVnm7srO7t39QPTxqmyTTlLVoIhLdjYhhgivWstwK1k01IzISrBNNbnO/88i04Yl6sNOUhZKMFI85JTaXMPbxoFoL/GAB9JfggtSgQHNQ/ewPE5pJpiwVxJgeDlIbzoi2nAo2r/Qzw1JCJ2TEeo4qIpkJZ4tb5+jMKUMUJ9qVsmih/pyYEWnMVEauUxI7NqteLv7n9TIbX4czrtLMMkWXi+JMIJug/HE05JpRK6aOEKq5uxXRMdGEWhdPxYWAV1/+S9oXPq779fvLWuOmiKMMJ3AK54DhChpwB01oAYUxPMELvHrSe/bevPdla8krZo7hF7yPb8hTjW4=</latexit>1.1 1<latexit sha1_base64="sKGc9qdjV1klQ/ErE8s0b2m2IwU=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU8iKtB6LXjxWMG2hDWWz3bRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbTzv2yltbG5t75R3K3v7B4dH1eOTtk4yRZlPE5Gobkg0E1wy33AjWDdVjMShYJ1wcjf3O09MaZ7IRzNNWRCTkeQRp8RYycfYxXhQrXmutwBaJ7ggNSjQGlS/+sOEZjGThgqidQ97qQlyogyngs0q/UyzlNAJGbGepZLETAf54tgZurDKEEWJsiUNWqi/J3ISaz2NQ9sZEzPWq95c/M/rZSa6CXIu08wwSZeLokwgk6D552jIFaNGTC0hVHF7K6Jjogg1Np+KDQGvvrxO2lcurrv1h+ta87aIowxncA6XgKEBTbiHFvhAgcMzvMKbI50X5935WLaWnGLmFP7A+fwBOFGNqQ==</latexit>1.11
1<latexit sha1_base64="oH/zjZu7+dNyrgfjYJevkFDPHKo=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB9/1euWK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBXEI0y</latexit> .0 1<latexit sha1_base64="erdSlbvEHAxwZAkRjNk0OZsY3yE=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55LueP6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGy41t</latexit>.01 1<latexit sha1_base64="fr6rnBT23QG65mqx+aa+YjFW6vw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB9/1e+WK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBYlI0z</latexit> .1 1<latexit sha1_base64="djXm0AJB/IqBadJ4dFtpF+b7n+U=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRbB07IRqR6LXjxWsB/QLiWbZtvQJLskWaGU/gUvHhTx6h/y5r8x2+5Bqw8GHu/NMDMvSgU3Ngi+vNLa+sbmVnm7srO7t39QPTxqmyTTlLVoIhLdjYhhgivWstwK1k01IzISrBNNbnO/88i04Yl6sNOUhZKMFI85JTaXsI/xoFoL/GAB9JfggtSgQHNQ/ewPE5pJpiwVxJgeDlIbzoi2nAo2r/Qzw1JCJ2TEeo4qIpkJZ4tb5+jMKUMUJ9qVsmih/pyYEWnMVEauUxI7NqteLv7n9TIbX4czrtLMMkWXi+JMIJug/HE05JpRK6aOEKq5uxXRMdGEWhdPxYWAV1/+S9oXPq779fvLWuOmiKMMJ3AK54DhChpwB01oAYUxPMELvHrSe/bevPdla8krZo7hF7yPb8hQjW4=</latexit>.11 1<latexit sha1_base64="oH/zjZu7+dNyrgfjYJevkFDPHKo=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB9/1euWK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBXEI0y</latexit> .0 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit> 1<latexit sha1_base64="erdSlbvEHAxwZAkRjNk0OZsY3yE=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55LueP6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGy41t</latexit>.01 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit> 1<latexit sha1_base64="fr6rnBT23QG65mqx+aa+YjFW6vw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB9/1e+WK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBYlI0z</latexit> .1 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit> 1<latexit sha1_base64="djXm0AJB/IqBadJ4dFtpF+b7n+U=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRbB07IRqR6LXjxWsB/QLiWbZtvQJLskWaGU/gUvHhTx6h/y5r8x2+5Bqw8GHu/NMDMvSgU3Ngi+vNLa+sbmVnm7srO7t39QPTxqmyTTlLVoIhLdjYhhgivWstwK1k01IzISrBNNbnO/88i04Yl6sNOUhZKMFI85JTaXsI/xoFoL/GAB9JfggtSgQHNQ/ewPE5pJpiwVxJgeDlIbzoi2nAo2r/Qzw1JCJ2TEeo4qIpkJZ4tb5+jMKUMUJ9qVsmih/pyYEWnMVEauUxI7NqteLv7n9TIbX4czrtLMMkWXi+JMIJug/HE05JpRK6aOEKq5uxXRMdGEWhdPxYWAV1/+S9oXPq779fvLWuOmiKMMJ3AK54DhChpwB01oAYUxPMELvHrSe/bevPdla8krZo7hF7yPb8hQjW4=</latexit>.11 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit>
S<latexit sha1_base64="04E67i89bWH56JZ6V0LuTeSwalE=">AAAB8XicbVDLTgJBEJzFF+IL9ehlIjHxRHaNQY9ELx4xyiMCIbNDL0yYnd3M9BrJhr/w4kFjvPo33vwbB9iDgpV0UqnqTneXH0th0HW/ndzK6tr6Rn6zsLW9s7tX3D9omCjRHOo8kpFu+cyAFArqKFBCK9bAQl9C0x9dT/3mI2gjInWP4xi6IRsoEQjO0EoPHYQnNEF6N+kVS27ZnYEuEy8jJZKh1it+dfoRT0JQyCUzpu25MXZTplFwCZNCJzEQMz5iA2hbqlgIppvOLp7QE6v0aRBpWwrpTP09kbLQmHHo286Q4dAselPxP6+dYHDZTYWKEwTF54uCRFKM6PR92hcaOMqxJYxrYW+lfMg042hDKtgQvMWXl0njrOxVypXb81L1KosjT47IMTklHrkgVXJDaqROOFHkmbySN8c4L8678zFvzTnZzCH5A+fzBww9kS4=</latexit>
<latexit sha1_base64="C5RW14eS04mUW6KyoCXEp/B0R3k=">AAAB+HicbVBNSwMxEM3Wr1o/uurRS7AInsquSPVY9OKxgv2AdinZNNuGZpMlmVXq0l/ixYMiXv0p3vw3pu0etPXBwOO9GWbmhYngBjzv2ymsrW9sbhW3Szu7e/tl9+CwZVSqKWtSJZTuhMQwwSVrAgfBOolmJA4Fa4fjm5nffmDacCXvYZKwICZDySNOCVip75Z7Qsmh5sMREK3VY9+teFVvDrxK/JxUUI5G3/3qDRRNYyaBCmJM1/cSCDKigVPBpqVealhC6JgMWddSSWJmgmx++BSfWmWAI6VtScBz9fdERmJjJnFoO2MCI7PszcT/vG4K0VWQcZmkwCRdLIpSgUHhWQp4wDWjICaWEKq5vRXTEdGEgs2qZEPwl19eJa3zql+r1u4uKvXrPI4iOkYn6Az56BLV0S1qoCaiKEXP6BW9OU/Oi/PufCxaC04+c4T+wPn8AXXKk6E=</latexit>
 !
1<latexit sha1_base64="b84kzvlAvEO2mxrsoWgNho2C9S4=">AAAB63icbVDLSgMxFL2pr1pfVZdugkVwVWZEqsuiG5cV7APaoWTSTBuaZIYkI5Shv+DGhSJu/SF3/o2ZdhZaPZBwOOde7r0nTAQ31vO+UGltfWNzq7xd2dnd2z+oHh51TJxqyto0FrHuhcQwwRVrW24F6yWaERkK1g2nt7nffWTa8Fg92FnCAknGikecEptLvlf3htWa+xfAf4lfkBoUaA2rn4NRTFPJlKWCGNP3vcQGGdGWU8HmlUFqWELolIxZ31FFJDNBtth1js+cMsJRrN1TFi/Unx0ZkcbMZOgqJbETs+rl4n9eP7XRdZBxlaSWKbocFKUC2xjnh+MR14xaMXOEUM3drphOiCbUungqLgR/9eS/pHNR9xv1xv1lrXlTxFGGEziFc/DhCppwBy1oA4UJPMELvCKJntEbel+WllDRcwy/gD6+AcVJjWw=</latexit>0.0 1<latexit sha1_base64="DqtpyMd1By3iNSyl4tzXV/8x7b0=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseiF48VTFtoQ9lsN+3SzSbsToQS+hu8eFDEqz/Im//GbZuDVh8s+3hvhpl5YSqFQdf9ckpr6xubW+Xtys7u3v5B9fCobZJMM+6zRCa6G1LDpVDcR4GSd1PNaRxK3gknt3O/88i1EYl6wGnKg5iOlIgEo2gl33Prrjeo1uy3APlLvILUoEBrUP3sDxOWxVwhk9SYnuemGORUo2CSzyr9zPCUsgkd8Z6lisbcBPli2Rk5s8qQRIm2TyFZqD87chobM41DWxlTHJtVby7+5/UyjK6DXKg0Q67YclCUSYIJmV9OhkJzhnJqCWVa2F0JG1NNGdp8KjYEb/Xkv6R9Ufca9cb9Za15U8RRhhM4hXPw4AqacAct8IGBgCd4gVdHOc/Om/O+LC05Rc8x/ILz8Q01RY2n</latexit>0.01 1<latexit sha1_base64="bFlHL4wuNKNlvHyLSYkiGTRaIek=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55HuuP6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGzY1t</latexit>0.1 1<latexit sha1_base64="rZCZOPcxcckhuKuankZUOQIYWMo=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU8iKtB6LXjxWMG2hDWWz3bRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbTzv2yltbG5t75R3K3v7B4dH1eOTtk4yRZlPE5Gobkg0E1wy33AjWDdVjMShYJ1wcjf3O09MaZ7IRzNNWRCTkeQRp8RYyceei/GgWvNcbwG0TnBBalCgNah+9YcJzWImDRVE6x72UhPkRBlOBZtV+plmKaETMmI9SyWJmQ7yxbEzdGGVIYoSZUsatFB/T+Qk1noah7YzJmasV725+J/Xy0x0E+Rcpplhki4XRZlAJkHzz9GQK0aNmFpCqOL2VkTHRBFqbD4VGwJefXmdtK9cXHfrD9e15m0RRxnO4BwuAUMDmnAPLfCBAodneIU3RzovzrvzsWwtOcXMKfyB8/kDNsqNqA==</latexit>0.11
0<latexit sha1_base64="uo5cZ3GqQ2YOc7akab3j9tZf1lo=">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRbBU9kVqR6LXjxWtB/QLiWbZtvQbHZJZoWy9Cd48aCIV3+RN/+NabsHbX2Q8Hhvhpl5QSKFQdf9dgpr6xubW8Xt0s7u3v5B+fCoZeJUM95ksYx1J6CGS6F4EwVK3kk0p1EgeTsY38789hPXRsTqEScJ9yM6VCIUjKKVHtyq2y9X7D8HWSVeTiqQo9Evf/UGMUsjrpBJakzXcxP0M6pRMMmnpV5qeELZmA5511JFI278bL7qlJxZZUDCWNunkMzV3x0ZjYyZRIGtjCiOzLI3E//zuimG134mVJIiV2wxKEwlwZjM7iYDoTlDObGEMi3sroSNqKYMbTolG4K3fPIqaV1UvVq1dn9Zqd/kcRThBE7hHDy4gjrcQQOawGAIz/AKb450Xpx352NRWnDynmP4A+fzB1WKjTE=</latexit> .0 0<latexit sha1_base64="HajtYLdprCiqTh6UfrgiYcSAP+M=">AAAB63icbVDLSgMxFL2pr1pfVZdugkVwVWZEqsuiG5cV7APaoWTSTBuaZIYkI5Shv+DGhSJu/SF3/o2ZdhZaPRByOOde7r0nTAQ31vO+UGltfWNzq7xd2dnd2z+oHh51TJxqyto0FrHuhcQwwRVrW24F6yWaERkK1g2nt7nffWTa8Fg92FnCAknGikecEptLXt3zh9Wa+xbAf4lfkBoUaA2rn4NRTFPJlKWCGNP3vcQGGdGWU8HmlUFqWELolIxZ31FFJDNBtth1js+cMsJRrN1TFi/Unx0ZkcbMZOgqJbETs+rl4n9eP7XRdZBxlaSWKbocFKUC2xjnh+MR14xaMXOEUM3drphOiCbUungqLgR/9eS/pHNR9xv1xv1lrXlTxFGGEziFc/DhCppwBy1oA4UJPMELvCKJntEbel+WllDRcwy/gD6+AcVEjWw=</latexit>.01 0<latexit sha1_base64="9XSQbZKoHxe7KU7mAINCFwEX8xM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB8/1e+WK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBXDo0y</latexit> .1 0<latexit sha1_base64="Tc/+Jm6ob5mjFAvqVd3Brj4ntP0=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55Lm+P6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGyY1t</latexit>.11 0<latexit sha1_base64="uo5cZ3GqQ2YOc7akab3j9tZf1lo=">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRbBU9kVqR6LXjxWtB/QLiWbZtvQbHZJZoWy9Cd48aCIV3+RN/+NabsHbX2Q8Hhvhpl5QSKFQdf9dgpr6xubW8Xt0s7u3v5B+fCoZeJUM95ksYx1J6CGS6F4EwVK3kk0p1EgeTsY38789hPXRsTqEScJ9yM6VCIUjKKVHtyq2y9X7D8HWSVeTiqQo9Evf/UGMUsjrpBJakzXcxP0M6pRMMmnpV5qeELZmA5511JFI278bL7qlJxZZUDCWNunkMzV3x0ZjYyZRIGtjCiOzLI3E//zuimG134mVJIiV2wxKEwlwZjM7iYDoTlDObGEMi3sroSNqKYMbTolG4K3fPIqaV1UvVq1dn9Zqd/kcRThBE7hHDy4gjrcQQOawGAIz/AKb450Xpx352NRWnDynmP4A+fzB1WKjTE=</latexit> .0 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit> 0<latexit sha1_base64="HajtYLdprCiqTh6UfrgiYcSAP+M=">AAAB63icbVDLSgMxFL2pr1pfVZdugkVwVWZEqsuiG5cV7APaoWTSTBuaZIYkI5Shv+DGhSJu/SF3/o2ZdhZaPRByOOde7r0nTAQ31vO+UGltfWNzq7xd2dnd2z+oHh51TJxqyto0FrHuhcQwwRVrW24F6yWaERkK1g2nt7nffWTa8Fg92FnCAknGikecEptLXt3zh9Wa+xbAf4lfkBoUaA2rn4NRTFPJlKWCGNP3vcQGGdGWU8HmlUFqWELolIxZ31FFJDNBtth1js+cMsJRrN1TFi/Unx0ZkcbMZOgqJbETs+rl4n9eP7XRdZBxlaSWKbocFKUC2xjnh+MR14xaMXOEUM3drphOiCbUungqLgR/9eS/pHNR9xv1xv1lrXlTxFGGEziFc/DhCppwBy1oA4UJPMELvCKJntEbel+WllDRcwy/gD6+AcVEjWw=</latexit>.01 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit> 0<latexit sha1_base64="9XSQbZKoHxe7KU7mAINCFwEX8xM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hEqseiF48V7Qe0oWy2m3bpZhN2J0Ip/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0PO+ncLa+sbmVnG7tLO7t39QPjxqmiTTjDdYIhPdDqnhUijeQIGSt1PNaRxK3gpHtzO/9cS1EYl6xHHKg5gOlIgEo2ilB8/1e+WK53pzkFXi56QCOeq98le3n7As5gqZpMZ0fC/FYEI1Cib5tNTNDE8pG9EB71iqaMxNMJmfOiVnVumTKNG2FJK5+ntiQmNjxnFoO2OKQ7PszcT/vE6G0XUwESrNkCu2WBRlkmBCZn+TvtCcoRxbQpkW9lbChlRThjadkg3BX355lTQvXL/qVu8vK7WbPI4inMApnIMPV1CDO6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBXDo0y</latexit> .1 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit> 0<latexit sha1_base64="Tc/+Jm6ob5mjFAvqVd3Brj4ntP0=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0hEWo9FLx4r2A9oQ9lsN+3S3U3Y3Qgl9C948aCIV/+QN/+NmzYHbX0w8Hhvhpl5YcKZNp737ZQ2Nre2d8q7lb39g8Oj6vFJR8epIrRNYh6rXog15UzStmGG016iKBYhp91wepf73SeqNIvlo5klNBB4LFnECDa55Lm+P6zWPNdbAK0TvyA1KNAaVr8Go5ikgkpDONa673uJCTKsDCOcziuDVNMEkyke076lEguqg2xx6xxdWGWEoljZkgYt1N8TGRZaz0RoOwU2E73q5eJ/Xj810U2QMZmkhkqyXBSlHJkY5Y+jEVOUGD6zBBPF7K2ITLDCxNh4KjYEf/XlddK5cv26W3+4rjVvizjKcAbncAk+NKAJ99CCNhCYwDO8wpsjnBfn3flYtpacYuYU/sD5/AHGyY1t</latexit>.11 ·<latexit sha1_base64="GTunUSAlBTD5TnT8AzXuOQvDKdM=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69BIvgqSQi1WPRi8cKpi20oWw2m3bpZjfsToRS+hu8eFDEqz/Im//GbZuDVh8MPN6bYWZelAlu0PO+nNLa+sbmVnm7srO7t39QPTxqG5VrygKqhNLdiBgmuGQBchSsm2lG0kiwTjS+nfudR6YNV/IBJxkLUzKUPOGUoJWCPo0VDqo1r+4t4P4lfkFqUKA1qH72Y0XzlEmkghjT870MwynRyKlgs0o/NywjdEyGrGepJCkz4XRx7Mw9s0rsJkrbkugu1J8TU5IaM0kj25kSHJlVby7+5/VyTK7DKZdZjkzS5aIkFy4qd/65G3PNKIqJJYRqbm916YhoQtHmU7Eh+Ksv/yXti7rfqDfuL2vNmyKOMpzAKZyDD1fQhDtoQQAUODzBC7w60nl23pz3ZWvJKWaO4Recj2/cnI69</latexit>
Figure 5: A depiction of how the map S in (31) acts on two subsets of the square [ 1,1]2. Some of the sets
−3
C are depicted (akin to Figure 4) to clarify the action of the mapping S. The red rectangle is shifted to
s
the right and nonlinearly compressed in the x-direction, as well as nonlinearly stretched in the y-direction.
The blue rectangle is also nonlinearly compressed in the x-direction as well as nonlinearly stretched in the
y-direction. Hence S is a nonlinear version of the Baker’s map, and indeed acts as a shift map since it
takes C to C .
s σ(s)
These B ’s are pairwise disjoint, and have non-zero distance apart from one another. In a slight abuse of
zm
notation, we can treat G as a map G : z ,...,z z ,...,z . Then we construct the map
1 2k+4 1 2k
{ } → { }
(cid:16) (cid:17)
G(x,y) = q (x X(z ⃗0))+X(G(z )⃗0), y if (x,y) B , (30)
a(zm),b(zm)
−
m m
∈
zm
where a(z ) := 3|zm⃗0|x and b(z ) := 1 . We note several features of the above map G :
m 3|G(zm)⃗0|x m 3|zm⃗0|x+1
(cid:83)2k+4 B D2. The map smoothly rearranges and resizes a finite number of vertical strips in [ 1,1]2
m=1 zm → −3
so that G(C ) = C for all s S. Due to the re-sizing, G is not area-preserving.
s G(s)
∈
We can similarly define a smooth map S satisfying S(C ) = C , namely
s σ(s)
(cid:40)
(r (x), r (x)) for (x,y) [ 1,1] [ 1, 1]
S(x,y) = 31,1 3 3,1 3 ∈ −3 × −3 3 , (31)
(1x+ 2, 3(y 2)) for (x,y) [ 1,1] [2 1,1]
3 3 − 3 ∈ −3 × 3 − 9
which is a nonlinear version of the Baker’s map. The map S is not area-preserving, and is only defined on
the two blocks [ 1,1] [ 1, 1] and [ 1,1] [5,1] which jointly contain all of the C ’s. The two blocks
−3 × −3 3 −3 × 9 s
comprise both the domain and co-domain of S, and so S can be composed with itself. A depiction of
the action of S on [ 1,1]2 is given in Figure 5. It is straightforward to use S to define a smooth map H
−3
satisfying H(C ) = C . To this end we note that, in a slight abuse of notation, F in (18) can be
s σF(a)(s)
viewed as a map F : z ,...,z Z, and we define
1 2k
{ } →
H(x,y) =
SF(zm)(cid:12)
(cid:12) Bzm(x,y) if (x,y)
∈
B zm. (32)
Above, SF(zm) denotes the map SF(zm) restricted to the domain B . Indeed, the above mapping
|Bzm zm
H : (cid:83)2k+4 B D2 is smooth and satisfies H(C ) = C for all s S.
m=1 zm → s σF(a)(s) ∈
Putting (30) and (32) together, we find
H G(C ) = C , (33)
◦
s σF(s)(G(s))
where H and G each are maps from (cid:83)2k+4 B D2. Next we will extend the domain to all of D2 (which
m=1 zm →
we recall we have taken to be the unit disk centered at (1, 1), containing the square [ 1,1]2). We first
3 3 −3
28note that the B ’s each have a non-zero pairwise distance from one another, and from the boundary of
zm
D2. Then we can enlarge each B
zm
slightly into a closed set B(cid:101)zm with smooth boundary (e.g. no corners),
such that the B(cid:101)zm’s each have a non-zero pairwise distance from one another, and non-zero distance to
the boundary of D2. Then we extend the domains of the functions comprising H and G to (cid:83)2 mk =4 1B(cid:101)zm,
(cid:70)2k+4 (cid:70)2k+4
resulting in functions H(cid:101) and G(cid:101) which also satisfy (33). But since H(cid:101)
◦
G(cid:101) : m=1B(cid:101)zm
→
m=1B(cid:101)zm is a
smooth map and (cid:70)2 mk =+4 1B(cid:101)zm is contained in D2 and has finite distance from the boundary of D2, by the
Whitney extension theorem we can extend H(cid:101) G(cid:101) to a smooth function f : D2 D2. This function satisfies
◦ →
f(C ) = C = C (s), (34)
s σF(s)(G(s)) Tuniv
and therefore we have
f(C ) = T (s) (35)
s univ
D◦
foralls S. Evidentlyfromtheaboveequation, τ(x) = 1. Thiscompletestheconstructionofourrobustly
∈
Turing-universal CDS.
Although the previous proof is somewhat elaborate, the basic ingredients are straightforward. The first
idea is that since we need to encode finite strings into regions with non-trivial interior so that the CDS is
robust, the C ’s need to become smaller as the ‘size’ of s becomes larger. These considerations motivate a
s
natural guess for the encoded regions (and hence the encoder and decoder), where the C ’s are thickened
s
version of the Cantor encoding of an infinite binary string into two dimensions. The second idea is that
by appropriately stretching and compressing regions of the disk (in a non-area-preserving manner), we can
implement a proxy for G which acts on a finite number of regions. The third idea is that a nonlinear
generalization of the Baker’s map serves as a proxy for the shift map on the C ’s. By combining the
s
previous ingredients appropriately, we obtain a function on a subset of the disk implementing Turing-
universal dynamics on the C ’s. We then smoothly extend said function into f, which gives us our desired
s
CDS.
Remark 4.5 (GeneralizingTheorem4.3toadiffeomorphism). WecangeneralizeourCDSinTheorem4.3
to a diffeomorphism if we use a Turing machine T which is reversible. The same exact construction
univ
presented in the proof goes through without any other change.
Remark 4.6. Our robustly Turing-universal CDS is defined on a compact set in R2. The work [CMPS23]
gives a fascinating example of a gradient flow on R2 which does not preserve any compact subset and yet is
Turing-universal, althoughunderalessrobustdefinitionofsimulationthanours. However, wesuspectthat
their example, or a slight variation thereof, may also furnish a robustly Turing-universal CDS. The same
paper also gives a related example of a gradient flow on the sphere with zero topological entropy which is
Turing-universal under a less robust definition of simulation. It would be interesting to understand if this
example is a robustly Turing-universal CDS; this would involve a non-trivial slowdown function τ implicit
in the construction in [CMPS23] (arising from the function G of [CMPS23, Section 7]).
4.2 Non-universality of Axiom A systems
We now state another central result of our paper:
Theorem 4.7. Let f : M M be an Axiom A system and assume that M is compact. There is no
→
extension of f to a robustly Turing-universal CDS (f, , ,τ,T).
E D
Below we recall the definition of an Axiom A system (originally due to Smale [Sma67]), as well as its basic
properties. We must first introduce some auxiliary definitions.
Definition 4.8 (Wandering and nonwandering sets). The wandering set of f is the set of points x M
∈
such that there is a neighborhood U of x and an N such that for all n > N, fn(U) U = . The
∩ ∅
nonwandering set Ω of f is the complement of the wandering set.
f
29Clearly, any periodic point of f is in the non-wandering set of f.
Definition 4.9 (Axiom A, Smale [Sma67]). We say that f is Axiom A if its nonwandering set Ω is
f
compact, hyperbolic, and if the periodic points of f are dense in Ω .
f
MuchofthereasonfortheimportanceofAxiomAsystemsisthattheyformarichclassofdifferentiable
dynamical systems with dynamics that can be characterized in great detail. Our proof of Theorem 4.7 will
rely on this precise understanding. As such, we will recall the basic structural results on Axiom A below.
The first result is the spectral decomposition of Axiom A systems:
Proposition 4.10 (Spectral Decomposition of Axiom A systems [Sma67, Bow08]). Let f : M M be an
→
Axiom A system. Then there is a decomposition of the non-wandering set
Ω = Ω Ω
f 1 k
∪···∪
into disjoint closed hyperbolic f-invariant subsets such that f is topologically transitive on each Ω . Each
i
Ω can be written as a union of pairwise disjoint closed sets
i
(cid:71)ri
Ω = Ω
i i,j
j=1
with f(Ω ) = Ω for j = 1,...,r 1, and f(Ω ) = Ω , and such that
i,j i,j+1 i
−
i,ri i,1
fri is topologically mixing.
|Ωi,j
Moreover, there is a decomposition into disjoint subsets
k
(cid:71)
M = Ws(Ω ).
i
i=1
Each of the Ω should be thought of as a kind of ‘attractor’ for f. However, since the expanding part of
i
the tangent bundle T+ (see Definition 3.40) may be nontrivial, points near Ω may not be attracted to Ω
Ωi i i
under the dynamics of f; thus these ‘attractors’ may be ‘unstable’. An illustrative example of an Axiom
A system may be obtained by letting f be a time-1 gradient flow of a proper Morse function g : M R;
→
in this setting, the Ω are exactly the critical points x of g, and the decomposition of TM is exactly the
i |Ωi
decomposition of T M into the positive and negative eigenspaces of the Hessian of g at the critical point
x
x. Note that in contrast to this example, in general the geometry of the Ω may be quite complicated,
i
and possibly fractal: the Cantor set associated to a Smale horsehoe (see Figure 3(d) for a depiction) is an
Axiom A attractor [KKH95]. Moreover, the dynamics on each Ω can be fairly chaotic, as we will discuss
i
below.
AnotherbasicresultregardingAxiomAsystemsisthattheyareessentiallythesameasthestructurally
stable systems:
Theorem 4.11 ([Rob71, Rob76, Man˜87]). Suppose that f is structurally stable: there exists an ε > 0
suchthatforalldiffeomorphismsg : M M whichareε-C1-closetof (i.e.thosesuchthatsup d(f(x),g(x))+
x∈M
→
df dg < ε), g is topologically conjugate to f (i.e. there exists a homeomorphism h : M M such
x x g
∥ − ∥ →
that f = h g h−1). Then f is Axiom A.
g g
◦ ◦
In fact, structural stability is equivalent to the condition that f is Axiom A and that f satisfies the
Strong Transversality condition: for every x,y Ω, the stable manifold Ws(x) is transverse to the unstable
∈
manifold Wu(y).
In part the motivation for the study of Axiom A systems was the hope that generic systems might be
Axiom A, and thus one might be able to give a tractable description of generic dynamics. Unfortunately,
30C<latexit sha1_base64="eRM/FCrxPlRX9AVeGnNlE18Wp0k=">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHaNQY9ELh4hkUcCGzI7NDAyO7uZmTUhG77AiweN8eonefNvHGAPClbSSaWqO91dQSy4Nq777eQ2Nre2d/K7hb39g8Oj4vFJS0eJYthkkYhUJ6AaBZfYNNwI7MQKaRgIbAeT2txvP6HSPJIPZhqjH9KR5EPOqLFSo9YvltyyuwBZJ15GSpCh3i9+9QYRS0KUhgmqdddzY+OnVBnOBM4KvURjTNmEjrBrqaQhaj9dHDojF1YZkGGkbElDFurviZSGWk/DwHaG1Iz1qjcX//O6iRne+imXcWJQsuWiYSKIicj8azLgCpkRU0soU9zeStiYKsqMzaZgQ/BWX14nrauyVylXGtel6l0WRx7O4BwuwYMbqMI91KEJDBCe4RXenEfnxXl3PpatOSebOYU/cD5/AJl3jNI=</latexit>
x
<latexit sha1_base64="ayjEjM+OsX7E9tlmNy+FUBG+l28=">AAAB/HicbVDLSsNAFJ34rPUV7dJNsAiuSiJSXRbduKxgH9CGMpnetEMnD2ZupCHUX3HjQhG3fog7/8ZpmoW2HrhwOOfeuXOPFwuu0La/jbX1jc2t7dJOeXdv/+DQPDpuqyiRDFosEpHselSB4CG0kKOAbiyBBp6Ajje5nfudR5CKR+EDpjG4AR2F3OeMopYGZqWPMMX8ncwTCcyy6WxgVu2ancNaJU5BqqRAc2B+9YcRSwIIkQmqVM+xY3QzKpEzAbNyP1EQUzahI+hpGtIAlJvlS2fWmVaGlh9JXSFaufp7IqOBUmng6c6A4lgte3PxP6+XoH/tZjyME4SQLRb5ibAwsuZJWEMugaFINaFMcv1Xi42ppAx1XmUdgrN88ippX9Sceq1+f1lt3BRxlMgJOSXnxCFXpEHuSJO0CCMpeSav5M14Ml6Md+Nj0bpmFDMV8gfG5w8oaZXE</latexit>
x<latexit sha1_base64="Otg/ej/gTdnNQarIFwGFTsDnnW4=">AAACA3icbVDLSsNAFJ3UV62vqDvdBIvgqiQi1WXRjcsK9gFtKZPJbTt08mDmRlpCwI2/4saFIm79CXf+jdM0C209cOFwzr1z5x43ElyhbX8bhZXVtfWN4mZpa3tnd8/cP2iqMJYMGiwUoWy7VIHgATSQo4B2JIH6roCWO76Z+a0HkIqHwT1OI+j5dBjwAWcUtdQ3j7oIE8zeSSR4adJFLjxIJmnaN8t2xc5gLRMnJ2WSo943v7peyGIfAmSCKtVx7Ah7CZXImYC01I0VRJSN6RA6mgbUB9VLst2pdaoVzxqEUleAVqb+nkior9TUd3WnT3GkFr2Z+J/XiXFw1Ut4EMUIAZsvGsTCwtCaBWJ5XAJDMdWEMsn1Xy02opIy1LGVdAjO4snLpHlecaqV6t1FuXadx1Ekx+SEnBGHXJIauSV10iCMPJJn8krejCfjxXg3PuatBSOfOSR/YHz+APBbmQM=</latexit>˜
⌦<latexit sha1_base64="Mtzif8lUJr23orPzPw39jhC9fJY=">AAAB83icbVBNS8NAEJ34WetX1aOXxSJ4kJKIVI9FL96sYD+gCWWznbZLN5uwuxFK6N/w4kERr/4Zb/4bt20O2vpg4PHeDDPzwkRwbVz321lZXVvf2CxsFbd3dvf2SweHTR2nimGDxSJW7ZBqFFxiw3AjsJ0opFEosBWObqd+6wmV5rF8NOMEg4gOJO9zRo2VfP8+wgHtZt65N+mWym7FnYEsEy8nZchR75a+/F7M0gilYYJq3fHcxAQZVYYzgZOin2pMKBvRAXYslTRCHWSzmyfk1Co90o+VLWnITP09kdFI63EU2s6ImqFe9Kbif14nNf3rIOMySQ1KNl/UTwUxMZkGQHpcITNibAllittbCRtSRZmxMRVtCN7iy8ukeVHxqpXqw2W5dpPHUYBjOIEz8OAKanAHdWgAgwSe4RXenNR5cd6dj3nripPPHMEfOJ8/MkaRJw==</latexit>
W<latexit sha1_base64="zUau+wrTd8OOJyLETvASFNCKXFw=">AAACAXicbVDLSgNBEJz1GeNr1YvgZTEI8RJ2RaLHoBePEcwDkjXMTnqTIbMPZnolYYkXf8WLB0W8+hfe/BsnyR40saChqOqeni4vFlyhbX8bS8srq2vruY385tb2zq65t19XUSIZ1FgkItn0qALBQ6ghRwHNWAINPAENb3A98RsPIBWPwjscxeAGtBdynzOKWuqYh22EIU7fST2RwDht3Kvi8HTcMQt2yZ7CWiRORgokQ7VjfrW7EUsCCJEJqlTLsWN0UyqRMwHjfDtREFM2oD1oaRrSAJSbTjePrROtdC0/krpCtKbq74mUBkqNAk93BhT7at6biP95rQT9SzflYZwghGy2yE+EhZE1icPqcgkMxUgTyiTXf7VYn0rKUIeW1yE48ycvkvpZySmXyrfnhcpVFkeOHJFjUiQOuSAVckOqpEYYeSTP5JW8GU/Gi/FufMxal4xs5oD8gfH5A0ldl28=</latexit> s(x) 1,1
W<latexit sha1_base64="Cii5XaT0KE+Z3h2mnw5wrVz+wYI=">AAACBnicbVDJSgNBEO2JW4zbqEcRBoMQL2EmSPQY9OIxglkgiUNPp5K06VnorhHDMCcv/ooXD4p49Ru8+Td2loMmPih4vFfV1fW8SHCFtv1tZJaWV1bXsuu5jc2t7R1zd6+uwlgyqLFQhLLpUQWCB1BDjgKakQTqewIa3vBy7DfuQSoeBjc4iqDj037Ae5xR1JJrHrYRHnDyTiKhmyaNW1UYucmdW0pPUtfM20V7AmuRODOSJzNUXfOr3Q1Z7EOATFClWo4dYSehEjkTkObasYKIsiHtQ0vTgPqgOslkfWoda6Vr9UKpK0Brov6eSKiv1Mj3dKdPcaDmvbH4n9eKsXfeSXgQxQgBmy7qxcLC0BpnYnW5BIZipAllkuu/WmxAJWWok8vpEJz5kxdJvVR0ysXy9Wm+cjGLI0sOyBEpEIeckQq5IlVSI4w8kmfySt6MJ+PFeDc+pq0ZYzazT/7A+PwBGWWZhw==</latexit> s(y ) W<latexit sha1_base64="kOPf9HEP8CRSHJ4EKvUUmJFyJOA=">AAACBnicbVDJSgNBEO2JW4zbqEcRBoMQL2FGJHoMevEYwSyQxKGnU0na9Cx014jDMCcv/ooXD4p49Ru8+Td2loNGHxQ83qvq6npeJLhC2/4ycguLS8sr+dXC2vrG5pa5vdNQYSwZ1FkoQtnyqALBA6gjRwGtSAL1PQFNb3Qx9pt3IBUPg2tMIuj6dBDwPmcUteSa+x2Ee5y8k0roZWnzRpUSN711R9lR5ppFu2xPYP0lzowUyQw11/zs9EIW+xAgE1SptmNH2E2pRM4EZIVOrCCibEQH0NY0oD6objpZn1mHWulZ/VDqCtCaqD8nUuorlfie7vQpDtW8Nxb/89ox9s+6KQ+iGCFg00X9WFgYWuNMrB6XwFAkmlAmuf6rxYZUUoY6uYIOwZk/+S9pHJedSrlydVKsns/iyJM9ckBKxCGnpEouSY3UCSMP5Im8kFfj0Xg23oz3aWvOmM3skl8wPr4BcHSZwA==</latexit> s(y )
j 2 j k
W<latexit sha1_base64="ILIy1z0gSfK6tgbLvbPKgMqcT3g=">AAACBnicbVDJSgNBEO2JW4zbqEcRBoMQL2FGJXoMevEYwSyQxKGnU0na9Cx014hhmJMXf8WLB0W8+g3e/Bs7y0ETHxQ83qvq6npeJLhC2/42MguLS8sr2dXc2vrG5pa5vVNTYSwZVFkoQtnwqALBA6giRwGNSAL1PQF1b3A58uv3IBUPgxscRtD2aS/gXc4oask191sIDzh+J5HQSZP6rSoM3eTOPUmPUtfM20V7DGueOFOSJ1NUXPOr1QlZ7EOATFClmo4dYTuhEjkTkOZasYKIsgHtQVPTgPqg2sl4fWodaqVjdUOpK0BrrP6eSKiv1ND3dKdPsa9mvZH4n9eMsXveTngQxQgBmyzqxsLC0BplYnW4BIZiqAllkuu/WqxPJWWok8vpEJzZk+dJ7bjolIql69N8+WIaR5bskQNSIA45I2VyRSqkShh5JM/klbwZT8aL8W58TFozxnRml/yB8fkDGuyZiA==</latexit> s(y ) z
j <latexit sha1_base64="4Me5vEDYvM2CB8A3WBjIG3CZNE4=">AAAB/HicbVDLSsNAFJ34rPUV7dJNsAiuSiJSXRbduKxgH9CGMpnetEMnD2ZuxBjqr7hxoYhbP8Sdf+M0zUJbD1w4nHPv3LnHiwVXaNvfxsrq2vrGZmmrvL2zu7dvHhy2VZRIBi0WiUh2PapA8BBayFFAN5ZAA09Ax5tcz/zOPUjFo/AO0xjcgI5C7nNGUUsDs9JHeMD8ncwTCUyzx+nArNo1O4e1TJyCVEmB5sD86g8jlgQQIhNUqZ5jx+hmVCJnAqblfqIgpmxCR9DTNKQBKDfLl06tE60MLT+SukK0cvX3REYDpdLA050BxbFa9Gbif14vQf/SzXgYJwghmy/yE2FhZM2SsIZcAkORakKZ5PqvFhtTSRnqvMo6BGfx5GXSPqs59Vr99rzauCriKJEjckxOiUMuSIPckCZpEUZS8kxeyZvxZLwY78bHvHXFKGYq5A+Mzx8rc5XG</latexit>
3 y
<latexit sha1_base64="2GGgVmOC0iCv7cKzbmmGrbSGtNE=">AAACAXicbVDLSsNAFJ3UV62vqBvBTbAIrkoiUl0W3bisYB/QhjCZ3rZjJw9mbsQS4sZfceNCEbf+hTv/xmnahbYeuHA45965c48fC67Qtr+NwtLyyupacb20sbm1vWPu7jVVlEgGDRaJSLZ9qkDwEBrIUUA7lkADX0DLH11N/NY9SMWj8BbHMbgBHYS8zxlFLXnmQRfhAfN3Ugm9LB176Z03yjLPLNsVO4e1SJwZKZMZ6p751e1FLAkgRCaoUh3HjtFNqUTOBGSlbqIgpmxEB9DRNKQBKDfNN2fWsVZ6Vj+SukK0cvX3REoDpcaBrzsDikM1703E/7xOgv0LN+VhnCCEbLqonwgLI2sSh9XjEhiKsSaUSa7/arEhlZShDq2kQ3DmT14kzdOKU61Ub87KtctZHEVySI7ICXHIOamRa1InDcLII3kmr+TNeDJejHfjY9paMGYz++QPjM8fRwOYFQ==</latexit> j
k
·
W<latexit sha1_base64="ZSg55Ff+37xW/35n0YPCNHuM4DE=">AAACBnicbVDLSgNBEJyNrxhfUY8iLAYhXsKuSPQY9OIxgnlAsi6zk04yZvbBTK8Ylj158Ve8eFDEq9/gzb9xsslBowUNRVX39HR5keAKLevLyC0sLi2v5FcLa+sbm1vF7Z2mCmPJoMFCEcq2RxUIHkADOQpoRxKo7wloeaOLid+6A6l4GFzjOALHp4OA9zmjqCW3uN9FuMfsnURCL01aN6o8dpNb106PUrdYsipWBvMvsWekRGaou8XPbi9ksQ8BMkGV6thWhE5CJXImIC10YwURZSM6gI6mAfVBOUm2PjUPtdIz+6HUFaCZqT8nEuorNfY93elTHKp5byL+53Vi7J85CQ+iGCFg00X9WJgYmpNMzB6XwFCMNaFMcv1Xkw2ppAx1cgUdgj1/8l/SPK7Y1Ur16qRUO5/FkSd75ICUiU1OSY1ckjppEEYeyBN5Ia/Go/FsvBnv09acMZvZJb9gfHwDF96Zhg==</latexit> s(y j 1) y y <latexit sha1_base64="gTLO4rwpaDtZn28hdeekkewI0sk=">AAACAXicbVDLSsNAFJ3UV62vqBvBTbAIrkoiUl0W3bisYB/QljCZ3rZjJw9mbsQS4sZfceNCEbf+hTv/xmmahbYeuHA45965c48XCa7Qtr+NwtLyyupacb20sbm1vWPu7jVVGEsGDRaKULY9qkDwABrIUUA7kkB9T0DLG19N/dY9SMXD4BYnEfR8Ogz4gDOKWnLNgy7CA2bvJBL6aTJxkzv3NE1ds2xX7AzWInFyUiY56q751e2HLPYhQCaoUh3HjrCXUImcCUhL3VhBRNmYDqGjaUB9UL0k25xax1rpW4NQ6grQytTfEwn1lZr4nu70KY7UvDcV//M6MQ4uegkPohghYLNFg1hYGFrTOKw+l8BQTDShTHL9V4uNqKQMdWglHYIzf/IiaZ5WnGqlenNWrl3mcRTJITkiJ8Qh56RGrkmdNAgjj+SZvJI348l4Md6Nj1lrwchn9skfGJ8/8B6X3A==</latexit> j 2 y <latexit sha1_base64="VwinXbVvd3hjxmAMTcxwytNxYfQ=">AAACAXicbVDLSsNAFJ34rPVVdSO4CRbBVUlUqsuiG5cV7APaEibTm3bs5MHMjVhC3Pgrblwo4ta/cOffOE2z0NYDFw7n3Dt37nEjwRVa1rexsLi0vLJaWCuub2xubZd2dpsqjCWDBgtFKNsuVSB4AA3kKKAdSaC+K6Dljq4mfusepOJhcIvjCHo+HQTc44yilpzSfhfhAbN3Egn9NBk7yZ1zmqZOqWxVrAzmPLFzUiY56k7pq9sPWexDgExQpTq2FWEvoRI5E5AWu7GCiLIRHUBH04D6oHpJtjk1j7TSN71Q6grQzNTfEwn1lRr7ru70KQ7VrDcR//M6MXoXvYQHUYwQsOkiLxYmhuYkDrPPJTAUY00ok1z/1WRDKilDHVpRh2DPnjxPmicVu1qp3pyVa5d5HAVyQA7JMbHJOamRa1InDcLII3kmr+TNeDJejHfjY9q6YOQze+QPjM8f8aSX3Q==</latexit> j 3 <latexit sha1_base64="SC3NLOn6QmJ+XLaowjGgZBQQhic=">AAACAHicbVBNS8NAEN3Ur1q/qh48eAkWwVNJRKrHohePFewHtKVsNtN26SYbdidiCbn4V7x4UMSrP8Ob/8ZtmoO2Phh4vDezs/O8SHCNjvNtFVZW19Y3ipulre2d3b3y/kFLy1gxaDIppOp4VIPgITSRo4BOpIAGnoC2N7mZ+e0HUJrL8B6nEfQDOgr5kDOKRhqUj3oIj5i9kyjw06THfIk6HZQrTtXJYC8TNycVkqMxKH/1fMniAEJkgmrddZ0I+wlVyJmAtNSLNUSUTegIuoaGNADdT7LFqX1qFN8eSmUqRDtTf08kNNB6GnimM6A41oveTPzP68Y4vOonPIxihJDNFw1jYaO0Z2nYPlfAUEwNoUxx81ebjamiDE1mJROCu3jyMmmdV91atXZ3Ualf53EUyTE5IWfEJZekTm5JgzQJIyl5Jq/kzXqyXqx362PeWrDymUPyB9bnD0Ryl4A=</latexit> · ·
<latexit sha1_base64="eHi2Xm7UnCaFPW6lpLf1i9i0TKE=">AAACAXicbVDLSsNAFJ3UV62vqBvBTbAIrkoiUl0W3bisYB/QhjCZ3rZjJw9mbsQS4sZfceNCEbf+hTv/xmnahbYeuHA45965c48fC67Qtr+NwtLyyupacb20sbm1vWPu7jVVlEgGDRaJSLZ9qkDwEBrIUUA7lkADX0DLH11N/NY9SMWj8BbHMbgBHYS8zxlFLXnmQRfhAfN3Ugm9LB176Z3nZJlnlu2KncNaJM6MlMkMdc/86vYilgQQIhNUqY5jx+imVCJnArJSN1EQUzaiA+hoGtIAlJvmmzPrWCs9qx9JXSFaufp7IqWBUuPA150BxaGa9ybif14nwf6Fm/IwThBCNl3UT4SFkTWJw+pxCQzFWBPKJNd/tdiQSspQh1bSITjzJy+S5mnFqVaqN2fl2uUsjiI5JEfkhDjknNTINamTBmHkkTyTV/JmPBkvxrvxMW0tGLOZffIHxucP7piX2w==</latexit> j
1
y
<latexit sha1_base64="cQU46vfKSHcUvp1imF/UvWjX9oU=">AAAB+3icbVDLSsNAFJ3UV62vWpdugkVwVRKR6rLoxmUF+4A2lMnkph06eTBzIw0hv+LGhSJu/RF3/o3TtAttPXDhcM69c+ceNxZcoWV9G6WNza3tnfJuZW//4PCoelzrqiiRDDosEpHsu1SB4CF0kKOAfiyBBq6Anju9m/u9J5CKR+EjpjE4AR2H3OeMopZG1doQYYbFO5kEL8/SfFStWw2rgLlO7CWpkyXao+rX0ItYEkCITFClBrYVo5NRiZwJyCvDREFM2ZSOYaBpSANQTlbszM1zrXimH0ldIZqF+nsio4FSaeDqzoDiRK16c/E/b5Cgf+NkPIwThJAtFvmJMDEy50GYHpfAUKSaUCa5/qvJJlRShjquig7BXj15nXQvG3az0Xy4qrdul3GUySk5IxfEJtekRe5Jm3QIIzPyTF7Jm5EbL8a78bFoLRnLmRPyB8bnD1ftlU4=</latexit>
Figure 6: Visual summary of the proof of Theorem 4.7.
this latter statement turns out to be false [New70]. There exists a rich set of conjectures and expectations
regarding the dynamics of a generic differentiable dynamical system due to Palis [Pal00], and an enormous
collection of results and techniques for their study. The analysis of Axiom A systems is the simplest
application of these methods.
In particular, the spectral decomposition for Axiom A systems is proven using another tool, the stable
manifold theorem for hyperbolic sets:
Proposition 4.12 ([Sma67], proven in [HP70]; see also Theorem 3.2 of [Bow08]). Let C be a compact
hyperbolic set for f. Then Ws(C) is a union of sets
Ws(x) = y M : d(fn(y),fn(x)) 0 as n
{ ∈ → → ∞}
over x C. Each of these sets is the image of a smooth injective immersion of a smooth manifold of
dimensi∈ on dimT−, and if y C then the tangent space to Ws(x) at y is (T−) . Moreover, the Ws(x)
C ∈ C y
are a continuous family of smooth submanifolds, i.e. for every x C and any z Ws(x), there exists a
∈ ∈
neighborhood U C and a continuous map ϕ : U C∞(Dr,M) (where r = dimWs(x), and Dr is the
x x
⊂ →
unit disk of degree r) such that ϕ(y) is an equidimensional immersion from Dr into Ws(y) sending 0 to y,
and such that ϕ(x)(Dr) contains z.
Remark 4.13. In fact, the theorem proven in [HP70] is not quite the result above; we explain the
(standard) derivation of the variant above in Appendix D.
To prove Theorem 4.7, we take the heuristic perspective that each ‘attractor’ Ω acts as a ‘memory
i
bank’ which can store only a bounded amount of ‘data’. But the existence of arbitrarily many disjoint
sets C with fL(C ) C suggests that a universal CDS should be able to implement an arbitrarily large
s s s
⊂
‘memory’. Let us imagine that τ(x) = 1. By the spectral decomposition, given a point x C , we have
s s
∈
that fkL(x) Ω for some i; since C is closed, this implies that C contains the closure of an orbit of
i s s
→
a z Ω . We then use the precise form of the stable manifold theorem to show that we can perturb
s i
∈
x a little bit to x˜ C such that the corresponding z˜ Ω C has an orbit dense in Ω . Thus each
s s s s i s i
∈ ∈ ∩
C eats up one unit of ‘memory’; since the C are disjoint but their number is arbitrarily large, this is a
s s
contradiction. A visual summary of the proof is depicted in Figure 6.
Proof of Theorem 4.7. Let k˜ = (cid:80)k r with k and r as in the spectral decomposition theorem. Choose
i=1 i i
N > k˜, and using Lemma 3.10, choose L sufficiently large such that there exist N periodic configurations
31s ,...,s of our universal Turing machine of period L, such that the orbits of these configurations are
1 N
pairwise distinct. The robustly Turing-universal CDS condition then produces N subsets C ,...,C of M
1 N
which are closed and have nonempty interior, and such that fnCi(C i) C
i
for each i = 1,...,N and some
⊂
integers n . Indeed, these sets can be taken to be a choice of connected component of −1(s ) for each
Ci
D
j
s j, for the robust CDS condition implies that (fτ)L(C i) C
i
for each i. Replace f by f((cid:81)N i=1Ci)r1···r k; this
⊂
diffeomorphism is still Axiom A, and its spectral decomposition is simply the decomposition
Ω = Ω Ω .
1,1 k,r
⊔···⊔ k
In particular, N is still greater than the number of basic sets in the spectral decomposition. Moreover, now
f(C ) C . We will show that for each j = 1,...,N, C contains one of the basic sets by the pidgenhole
i i j
⊂
principle, and this is a contradiction. Without loss of generality let us set j = 1.
Choose an x in the interior of C . Then by the spectral decomposition of f, x Ws(Ω ) for some
1 i,j
∈
i,j; without loss of generality let us set i = 1,j = 1. By Proposition 4.12, there is a z Ω such that
1,1
∈
d(fn(x),fn(z)) 0 as n . Now there is a point y Ω such that the orbit of y is dense in Ω . In
1,1 1,1
→ → ∞ ∈
particular,thereisasequencen
i
ofdistinctnaturalnumbersdivergingtoinfinitysuchthaty
i
= fni(y) z
→
as i . For all sufficiently large i, y U with the notation as in Proposition 4.12. Let p Dn be the
i z
→ ∞ ∈ ∈
preimage of z under ϕ(x). By continuity of ϕ, for sufficiently large i, we have that ϕ(y )(p) ϕ(x)(p) = z;
i
→
in particular for sufficiently large i, ϕ(y )(p) C. Fix any such i and write x˜ = ϕ(y )(p), z˜= y .
i i i
∈
The orbit of z˜ under f is dense in Ω . Thus, for any w Ω , there exists a sequence m of natural
1,1 1,1 i
∈
numbers diverging to infinity such that fmi(z˜) w as i . But d(fmi(x˜),fmi(z˜)) 0 as i . So
→ → ∞ → → ∞
w C is in the closure of C . We have thus proven that Ω C . Then there is a relabeling of the Ω
1 1 1,1 1 i,j
∈ ⊂
as Ω = Ω such that Ω C . But the number of C ’s is larger than the number of Ω ’s, so this
k i(k),j(k) k j j i,j
⊂
is not possible. We have proven the theorem.
Proof of Theorem 1.6. The only condition used in the proof of Theorem 4.7 is the existence of, for an
arbitrarily large N, a collection of disjoint sets C that are closed, have non-empty interior, and satisfy
i
fnCi(C i) C
i
for each i = 1,...,N. But this is exactly the condition that f simulates the corresponding
⊂
machine T as defined in the statement of Theorem 1.6.
N
4.2.1 Conjectures about generic diffeomorphisms
We have proven that structurally stable systems cannot robustly implement universal computation (in the
sense of this paper). As mentioned previously, the original motivation for the study of Axiom A systems
was, in part, the hope that they would be generic, that they would form an open and dense subset of the
set of diffeomorphisms. This turns out not to be the case [New70]; however, there are still hopes that
generic diffeomorphisms have nice structure theorems [Pal00].
Conjecture 4.14. For any compact computable manifold M (possibly with boundary), there is a C∞
generic set of diffeomorphisms f : M M such that no diffeomorphism f can be extended to a
S → ∈ S
robustly Turing-universal CDS (f, , ,τ,T ).
univ
E D
Here a C∞-generic set is a set that is the intersection of a countable collection of open dense sets in the
space of smooth diffeomorphisms of M. We now prove this conjecture under a strong condition on the
decoder as well as a condition on the slowdown function, using a periodic point argument:
Theorem 4.15. For any compact computable manifold M (possibly with boundary), there is an open dense
set of diffeomorphisms f : M M such that no diffeomorphism f can be extended to a robustly
S → ∈ S
Turing-universal CDS (f, , ,τ,T ) where satisfies the shrinking condition (see Definition 3.30) and
univ
E D D
the slowdown function is constant.
Remark 4.16. Note that if one drops robustness and genericity [KM99] or one allows oneself to work on
noncompact domains [GZ23], then the above statement is false. The results of [KM99, GZ23] are under
somewhat different formalizations, and we do not explicate the comparison here.
32Proof. Letusassumethattheslowdownfunctionhasconstantvaluea. Wecanchoosethesetofdiffeomor-
phisms in the theorem statement to be the set where all periodic points are hyperbolic; this is open and
dense by the Kupka-Smale theorem [KKH95, Theorem 7.2.6]. Note that T has some periodic configu-
univ
ration s of period n by Lemma 3.10; moreover, we can find such a periodic configuration such that if we
0
append symbols to the input those symbols are never read in the periodic motion of T . Thus for every
univ
finite string t on the alphabet of tape symbols Σ we have a corresponding periodic configuration s of T .
t univ
Moreover, the decoder defines for us a closed (and thus compact) set C M such that fan(C ) C
st
⊂
st
⊂
st
where n is the period of s under the dynamics of T . Since the lengths of the corresponding configu-
t univ
rations of T go to infinity as the length of s goes to infinity, the shrinking condition implies that given an
infinite string sˆon Σ and writing its finite truncations as sˆ , we have that the diameters of C converge
n t
sˆn
to zero. Since each C is closed, it is compact, and so it defines a subspace of the Hausdorff metric
t
sˆn
space of all compact subspaces of M. Since M is compact, this latter space is compact as well, and so
there is a subsequence C converging to some point p M. Since f is continuous, we must have that
t sˆnj sˆ ∈
fan(p ) p , i.e. fan(p ) = p . Thus, if we show that the points p are distinct for different infinite
sˆ s sˆ sˆ sˆ
⊂ { }
stringssˆwewillbedone. Indeed, thehyperbolicityofallperiodicpointsandthecompactnessofM implies
that there are only a countable number of periodic points. (This is because every periodic point of period
k has an open neighborhood containing no other periodic points of period k by the local normal form for
hyperbolic periodic points; so by compactness of M there are finitely many periodic points of period k for
each k, and thus countably many periodic points in general.) But the distinctness of the points p follows
sˆ
from the hierarchical shrinking condition: we have that if sˆa = sˆb, then sˆa = sˆb for some n; and thus we
n n
̸ ̸
have thatforallsufficientlylargej, C t sˆa nj ⊂ C t′ sˆa n andsimilarlyC t sˆb nj ⊂ C t′ sˆb n, sop sˆa ∈ C t′ sˆa n whilep sˆb ∈ C t′ sˆb n.
Since the hierarchical shrinking condition implies that C t′
sˆa
n
∩C t′
sˆa
n
= ∅, we know that the points p sˆa are
disjoint. In other words, we have produced an uncountable number of periodic points of f, which is a
contradiction.
We do not know how to implement an analog of this argument without any conditions on the decoder,
or even for a shrinking decoder. We hope the different flavor of arguments in this section vis-´a-vis the
previous section highlight how changing the condition on the decoder brings out different ways in which
information can be encoded into the dynamics of a smooth dynamical system.
Remark 4.17. Remark 3.31 thus implies that the diffeomorphism underlying the construction of Section
4.1 is highly non-generic.
Remark 4.18. The argument in the proof fails completely when we allow for a non-constant slowdown
function. Attempting the same argument in that setting, the periodic points of constant period n of T
univ
then correspond to periodic points of unbounded period of f. But Kupka-Smale diffeomorphisms typically
have infinitely many periodic points; it is only the number of periodic points of any bounded period which
is finite.
4.3 Non-universality of measure-preserving and integrable systems
Above we showed that Axiom A systems cannot be extended to robustly Turing-universal CDSs. One
interpretation of that result is that certain kinds of chaotic behavior are incommensurate with robust
Turing universality. Below we will pursue a complementary set of results, namely that measure-preserving
systems on compact domains, as well as certain measure-preserving systems on non-compact domains, are
likewise incapable of furnishing robustly Turing-universal CDSs. Such systems are at the opposite end of
the extreme of chaotic systems. As such, we are in total establishing that neither ‘very chaotic’ systems
nor ‘very non-chaotic’ systems are capable of being robustly Turing universality.
For all of the results in this section we need the following lemma.
Lemma 4.19. Let (f, , ,τ,T) be a CDS. If for any n Z ≥0 and any s,s′ S we have (fτ)n(C s) C s′ =
E D ∈ ∈ ∩ ̸
, then (fτ)n(C s) C s′ = C Tn(s).
∅ ⊆
33Proof. By the definition of a CDS we have (fτ)n(C ) = Tn(s), and so applying −1 to both sides
s
D ◦ D
we find (fτ)n(C s) C Tn(s). So to complete the proof, it suffices to show that C Tn(s) = C s′. Since
⊆
(fτ)n(C s) C s′ = , we have C Tn(s) C s′ = . If x is a point in the intersection, then (x) = Tn(s) = s′,
∩ ̸ ∅ ∩ ̸ ∅ D
but by definition the inverse image under is C Tn(s) = C s′.
D
We can use the above Lemma to prove our result about measure-preserving maps:
Theorem 4.20. Let µ be a Borel measure on a compact set M Rn which assigns nonzero measure to all
⊂
nonempty open sets and such that supp(µ) = M and µ(M) < . If f : M M is a measure-preserving
∞ →
map with respect to µ, then f cannot be extended to a robust CDS for the machine Plus : 1 ∗ 1 ∗
{ } → { }
defined by Plus([n] ) = [n+1] , where [n] denotes n in unary.
1 1 1
Proof. By contradiction, let s = 1 be the initial configuration of Plus, which which visits infinitely many
0
distinct configurations {s
n
}∞
n=0
with s
n
:= Plusn(s 0) = [n + 1] 1. Define C(cid:101)sn := (fτ)n(C s0), and notice
that on account of Lemma 4.19 the C(cid:101)sn’s are pairwise disjoint. Since C
s0
has non-trivial interior and
(cid:80)∞
µ is supported o (cid:16)n all of M (cid:17), we have µ(C s0) = µ(C(cid:101)sn) > 0. Consequently n=0µ(C(cid:101)sn) = ∞, but
(cid:80)∞ (cid:83)∞
n=0µ(C(cid:101)sn) = µ n=0C(cid:101)sn
≤
µ(M) <
∞
which is a contradiction.
Since Plus is a sub-machine of every universal Turing machine, using the fundamental theorem of sub-
machines we have the immediate corollary:
Corollary 4.21. Let µ be a Borel measure which compact set M Rn which assigns nonzero measure to
⊂
all nonempty open sets and such that supp(µ) = M and µ(M) < . If f : M M is a measure-preserving
∞ →
map with respect to µ, then f cannot be extended to a robustly Turing-universal CDS.
Recall that a diffeomorphism f : M M when M is a symplectic manifold with symplectic form
→
ω is a symplectomorphism when f∗ω = ω. Such maps thus satisfy f∗ωn = ωn, and hence preserve the
Borel measure associated to the volume form ωn. Thus Corollary 4.21 proves in particular the following
corollary:
Corollary 4.22. Symplectomorphisms of compact symplectic manifolds cannot be extended to a robustly
Turing-universal CDS.
In the next theorem, we partially drop the compactness assumption on the domain. Before we state
the theorem, we will describe a prototypical class of physical dynamical systems which motivate this latter
generalization.
Definition 4.23 (Continuous-time integrable system). Let M be a 2n-dimensional symplectic manifold,
and let f : M M be a Hamiltonian flow generated by the Hamiltonian function H : M R, such that
t 1
→ →
there exists complete system of commuting Hamiltonian functions H ,...,H : M R, i.e. we have that
2 n
→
d
f = X , i ω = dH , ω(X ,X ) = 0 for i,j = 1,...,n.
dt
t H1 XHj j Hj H
k
Here d and i are the exterior derivative and interior product [Arn13]. We suppose that there is a dense
set of points where differentials of the n conserved Hamiltonian functions are linearly independent, and
also that the sets (cid:84)n H−1(c ) are compact for (c )n Rn. The dynamics instantiated by f define a
i=1 i i i i=1 ∈ t
continuous-time integrable system.
A nice feature of continuous-time integrable systems is that due to the condition on the differentials of the
conserved Hamiltonian functions, it is possible to use a diffeomorphism h to locally transform into simple
action-angle variables using the Liouville-Arnold theorem. More formally, for an open dense set of points
p M, there are f -invariant neighborhoods V of p together with diffeomorphisms h : V U Tn for
t
so∈ me open set U Rn, satisfying the following properties. Writing f˜ := h−1 f h, the m→ ap f˜× acts as
t t t
f˜ : (x,y) (x,y⊂ +tω(x)(mod 1)), where ω(x) is a frequency vector depend◦ ing ◦ on the action variables
t
(cid:55)→
34x. In physical terminology, the sets U are the action variables, Tn are angle variables, and the dynamics
translates the angle variables linearly with a rate depending on the action variables, instantiating periodic
or quasiperiodic motion on each Tn.
Recalling Remark 3.18, we can generalize our definition of a CDS to a continuous-time dynamical
system by letting τ be a partial function τ : M ⇀ R instead of M ⇀ Z . With this in mind, we present
≥0 ≥0
the theorem below, which in particular shows that continuous-time integrable systems are not robustly
Turing-universal:
Theorem 4.24 (Integrable systems cannot be extended to a robust CDS for the Plus machine.). Let f
t
be a smooth family of diffeomorphisms of a manifold M, and suppose that f∗µ = µ for a measure µ of
t
the form gdV where g : M M, g > 0, and dV is the volume form on M. Suppose also that M can be
→
written as a union of compact invariant submanifold (with boundary) for the flow of f . Then f cannot be
t t
extended to a robust CDS for the machine Plus : 1 ∗ 1 ∗ defined by Plus([n] ) = [n+1] .
1 1
{ } → { }
Proof. We argue by contradiction. Let s = 1 be an initial configuration of Plus where s ∞ with s :=
0 n n=0 n
{ }
Plusn(s 0) = [n+1]
1
are all distinct. Since C
s0
has a non-trivial interior, we can find a closed set C(cid:101)s0 with
non-trivial interior inside C
s0
such that C(cid:101)s0 is small enough to be contained within some compact invariant
submanifold(withboundary)K fortheflowoff t. DefiningC(cid:101)sn := (fτ)n(C(cid:101)s0), duetoLemma4.19wehave
that the C(cid:101)sn are pairwise disjoint. Then, recapitulating the argument of Theorem 4.20 with f
t
restricted
(cid:80)∞ (cid:83)∞
to K, we find that µ(C(cid:101)s0) = µ(C(cid:101)sn) > 0 for all n, and so n=0µ(C(cid:101)sn) = µ( n=0C(cid:101)sn)
≤
µ(K) <
∞
which
is a contradiction.
Again,usingthatPlusisasub-machineofeveryuniversalTuringmachine,wecanagainusethefundamental
theorem of sub-machines to attain the following corollary:
Corollary 4.25 (Integrable systems cannot be extended to a robustly Turing-universal CDS). If f is an
t
integrable system then it cannot be extended to a robustly Turing-universal CDS.
Remark 4.26. Even though integrable systems cannot furnish even the basic Plus machine, they are
capable of serving as ‘memories’, i.e. they can encode information in the values of their conserved charges.
As such, integrable systems serve as a model of memory without the ability to perform certain forms of
more sophisticated computation.
4.4 Time complexity bounds in one dimension
Wenowproceedtogobeyond obstructionstouniversality, andtoprovetimecomplexityboundsforvarious
kinds of differentiable systems. Indeed, many previous works show that universality is often too strong to
hopeforinthevastmajorityofdifferentiablesystemsundermostformalizations. Therealtaskofatheoryof
computational dynamical systems seems to us to find a correspondence between various complexity classes
in the sense of classical computability theory and various dynamical classes defined in terms of natural
conditions on smooth dynamical systems. Thus, a goal is to be able to say that ‘dynamical systems of
this kind are this computationally powerful’. We discuss how to formalize this notion in Appendix B. The
role of this paper is in part to make precise the gap between what is known in the enormous literature on
differentiable dynamics and what would be a satisfying realization of the above goal.
We first proceed with the one-dimensional setting, where we can prove a relatively strong theorem.
Recall the following definition:
Definition 4.27. A differentiable map f : I I is Axiom A if
→
1. All periodic points of f are hyperbolic (and thus classified into attracting or repelling periodic points),
and
2. Let B(f) = (cid:83) Ws(p) where the union runs over all attracting periodic points. Then [0,1] B(f) is
p \
a hyperbolic set.
35Remark 4.28. Thisisastandardgeneralizationofthenotionof1-dimensionalAxiomAdiffeomorphismto
thecaseofmapswhicharenotnecessarilyinvertible. Notethatdiffeomorphismsoftheintervalarerelatively
simple dynamical objects [KKH95], and in particular, the condition that an interval diffeomoprhism is
Axiom A is extremely restrictive. In contrast, Axiom A maps are generic among all interval maps by
the theorem below. The theory of Axiom A maps of domains of dimension greater than one is much less
developed than the corresponding theory for diffeomorphisms [MT23].
Theorem 4.29 ([KSvS07]). Axiom A maps f : I I of class Ck where I = [0,1] are dense in the space
→
of Ck maps Ck([0,1],[0,1]) for k = 1,2,..., , or even ω (the real analytic maps); this density result even
∞
holds for polynomial maps of the interval. Moreover in each of the cases the Axiom A maps are exactly
the structurally stable maps.
Theorem 4.30. Let f : [0,1] [0,1] be an Axiom A map. Then for any CDS (f, , ,τ, T) where
→ E D
t(n) = n, τ is constant, and the encoder and decoder can be implemented with BSS machines, then if T
C
halts on a configuration then it will halt in time O(F(n)), where
F(n) =
D2n
for some constant D. In other words, in the sense of Appendix B, f can recognize languages at most in
DTIME(O(F(n))).
Before proceeding with the proof of this theorem, we first prove several sublemmas. First, note that by
[KKH95, Theorem 16.1.1] we have that f induces dynamics on R(f) := [0,1] B(f) which are topologically
\
conjugate to a topological Markov chain [KKH95]; thus this subset of the interval is a Cantor set with
the induced topology, and is thus totally disconnected. In particular, any region C associated to a robust
s
decoder for a CDS involving f will contain points outside of B(f), which will thus have dynamics that
asymptote to the attracting hyperbolic periodic points. To get a halting bound we will understand how
long it will take for those points to get there. This will follow from the following two lemmas. The first is
purely dynamical:
Lemma 4.31. There exists a finite collection of closed intervals I r whose union covers R(f) and an
n such that f−kn(I ) is a disjoint union of closed intervals all co{ nj t} aj i= ne1 d in I = (cid:83) I and such that the
j j j
lengths of each of these intervals is bounded by λkC for some λ < 1 and C > 0.
Proof. This is essentially proven in [KKH95, Theorem 16.1.1]; our I ’s are those of this theorem, as is our
j
n. The only point to make is that if we chose the I ’s small enough, so that on each I , we have that fn
j j
is monotone and has (fn)′ lower bounded by λ−1 > 1 on all the I . This is possible by hyperbolicity and
j
| |
the total disconnectedness of R(f). Then, by the derivative bound and and the monotonicity of fn, fn
must stretch the length of each component of f−n(I ) by a factor of at least λ. But then an induction on
j
k proves the lemma.
Beyond this covering lemma, we have the following helpful definition and result from real algebraic
geometry:
Definition 4.32 (Standardized polynomial). We say that a polynomial p(x) = (cid:80) a xi is standardized
i i
if all of its non-zero coefficients are greater than or equal to 1. For any p(x), we let
p := p/min 1,min a : a = 0 , (36)
(cid:101) i i
{ {| | ̸ }}
which is standardized. Indeed, if p is already standardized, then p = p.
(cid:101)
Proposition 4.33 (Generalization of Theorem 3 of [Rum79]). Let p(x) = (cid:80) a xi be a real polynomial
i i
(cid:80)
with integral coefficients. Denote s = a and d = degp. Let rsep (p) be the minimum distance
i| i | [−1,1]
between two real roots of p which are each in the interval [ 1,1]. Then
−
2√2
rsep (p) .
[−1,1] ≥ dd/2+1(s˜(p)+1)d
36This result is proved in Appendix E. We now proceed with the proof of Theorem 1.10.
Proof of Theorem 4.30. Denote the domain of f by M. There is a region M which is a union of
H ⊂
closed nonempty intervals of strictly positive length and should be thought of as the ‘halting region’,
corresponding to the union of all the decoded regions associated to configurations for which the underlying
state of the Turing machine is the halting state.
Let p ,...,p be the attracting periodic points. Choose an ε such that the neighborhood U of size ε
1 k ε
of the attracting periodic points is a union of intervals, one around each p , with standard dynamics given
i
by the local normal forms [KKS+15] for attracting periodic points.
Now let V = (cid:83) I with I as in Lemma 4.31. We know that R(f)c = (cid:83)∞ f−i(U ); in particular, there
i j j i=1 ε
is some L such that f−L(U ) contains Vc. Lemma 4.31 then implies that f−L+k(U ) can be covered by
ε ε
disjoint intervals of size exponentially decreasing in k.
Let s be a configuration of T. Then because C is given by a BSS machine, it is given via a union of
s C
the set of solutions to several equations P (x)/Q (x) 0 for some polynomials P (x) and Q (x) which
si si
≥
si si
can be taken to be standardized (by rescaling). In particular, it is a union of intervals of length bounded
by the distance between the roots of the polynomials P . We will bound the quantities s and d for these
si
polynomials in terms of the length n of s.
The fact that t(n) = n means that the formula for C is computed in O(n) steps. Indeed, the formula
s
for this semialgebraic set is computed by running the BSS -machine defining . At each step the machine
C
D
doingthiscomputationhasin itsregistersseveral realquantitieswhichin termsoftheoriginalquantiesfed
into take the form of ratios of polynomials in these quantities. At each step, either the computation of
D D
branches on the positivity of one of these quantities; or the computation is in the reject state; or otherwise
thecomputationcontinuesadding, multiplying, anddividingtheavailablequantities(whichareallrational
functions of the original inputs). If we have P ,P ,Q ,Q all satisfying degP = O(w),degQ = O(w),
1 2 1 2 i i
while s(P ) and s(Q ) are both Dn for some large D, then P /Q +P /Q = P′/Q′, where degP′ and
i i 1 1 2 2
≤
degQ′ are O(2w), s(P′) and s(Q′) are D2n, and P′ and Q′ are still standardized if P and Q were.
i i
≤
Multiplying the available rational functions gives similar bounds. We can also add a constant or multiply
a rational function by a constant; to preserve standardization of the numerator and denominator, we will
havetorescaleP andQbytherelevantconstant,whichaffectse.g.s(P′)byscalingitbydegP′C = O(w)C.
Finally, if the computation underlying the formula at some point branches on the positivity of some
value of some rational function P /Q of the original inputs to , and while the other quantities available
1 1
D
to the machine computing are of the form P /Q ,..., then the computation of continues, then this
2 2
D D
simply corresponds in the end to considering regions which are a union of regions in between the roots of
(P /Q ) F(P /Q ,...) for some final formula F. Combining these observations together with Proposition
1 1 2 2
·
4.33 tells us that C consists of intervals of length bounded by a constant times
s
2√2((2n)(2n)/2+1(2n(n+1)/2CnD2n +1)D2n +1)−1.
Here the factor 2n(n+1)/2Cn = 2nC2n−1C2n−2C... is a lossy bound associated to the condition that we
might have to to ‘restandardize’ the polynomials at each step. Thus after we iterate f L+k(n) times,
where
k(n) = O(log((2n)(2n)/2+1(22nCnD2n +1)D2n +1)) = O(2nn+D2n 2n) = O(D2n )
there will be a point p of fL+k(n)(C ) which lies in U , say in a neighborhood of a periodic point of period
s ε
ℓ.
At this stage, it is comparatively easy to figure out if T will halt. The first possibility is that for 2ℓ
moreiterationsofT, therewillstillbeapointoffL+k(n)+i(C ), i = 1,...,ℓwhichstaysintheneighborhood
s
V, at which point by the 2ℓ-th iteration we will have that fL+k(n)+2ℓ(C ) overlaps fL+k(n)(C ) which is a
s s
contradiction if we have not yet halted. The other possibility is that if the whole neighborhood leaves V
during these 2ℓ iterations, we can wait another fL iterations to have the whole interval lie in U ; we see in
ε
fact that at this stage, the image of the whole interval must lie in the same component of U as the image
ε
of the original point entering U does, for otherwise the interval will never decrease in size; but this could
ε
37only happen if the interval in fact contained a point of R(f), which would contradict the whole interval
leaving V eventually. In any case, once the whole interval lies in a single component of U , we must halt in
ε
some fixed time and overall bounded time Q depending on how the halting set overlaps U , or never halt
ε
at all. This concludes the proof of the case when τ = 1.
Remark 4.34. Note that much of the proof of Theorem 4.30 goes through for general τ. Indeed, the
proof above really proves that fk(C ) reaches the region near the hyperbolic attracting periodic point once
s
k is greater than the bound in the Theorem for n = s . Thus, if τ 1, we have that iterating f on C
s
| | ≥
reaches the hyperbolic attracting periodic point faster, and subsequently fk(C ) stays near this hyperbolic
s
attracting point. Thus that part of the bound of Theorem 4.30 holds for general τ, as the bound is only
improved byincreasingτ. Thereasonwecannotstatethetheoremforgeneralτ isbecauseofthepossibility
that fk(C ) eventually gets close to the hyperbolic periodic point but the slowdown function τ conspires
s
so that on the collection of iterations k = k of fk(C ) on which we are to evaluate the dynamics of f for
i s
the purposes of simulation, the k always have the wrong value modulo the period of the periodic point.
i
Thus, if one has an oracle which can resolve this challenge (and one can produce one for many slowdown
functions that are much more general than the constant function), then one can continue to conclude the
bound of Theorem 4.30.
4.5 Time complexity bounds in many dimensions
In the theory of Axiom A systems (see Section 4.2), the notion of a ‘topologically mixing’ system occurs.
There is an elementary statement showing that topologically mixing regions cannot encode non-halting
computations:
Lemma 4.35. Let f be topologically mixing. Then any robust CDS with underlying dynamical system f
must halt on all inputs.
Proof. Any configuration s of the machine T underlying the CDS defines a closed set with nonempty
interior, namely C = −1(s). Similarly, there is a set with nonempty interior which corresponds to the
s
D H
configurations of T in the halting state. Let Co denote the interior of C . Since f is topologically mixing,
s s
then there is an N such that for all n > N, fn(Co) = . Suppose that T never halts on s; then,
s
∩ H ̸ ∅
choosing some n large enough we must have that (fτ)n(Co) = , which is a contradiction with the
s
∩H ∅
previous statement.
Now, for Axiom A diffeomorphisms, the spectral decomposition of Proposition 4.10 decomposes the
dynamics into basic sets on which the dynamics are topologically mixing in a highly quantitative way, and
regions where the dynamics flows from one basic set to another. Thus to establish a higher-dimensional
analog of Theorem 1.10 one must understand the ‘amount of computation’ that can be done in a single
basic set. The special case where there is one basic set which is exactly the entire the domain of f is the
setting where f is Anosov. Already in this setting the problem is nontrivial; below we give an inexplicit
computable bound on the halting time of any CDS with underlying Anosov dynamics in order to clarify
the difficulties of the problem. First we must introduce a restriction on the type of decoder allowed which
abstracts away the properties of the robust Cantor decoder of (26).
Definition 4.36. A Cantor-like decoder : M ⇀ S is one that is implemented as follows: there is a
D
semialgebraic map P : M Rk M Rk, a semialgebraic (thus piecewise constant) map : M Rk
0
× → × D × →
Σ p˜ 2 (here p˜ is a new symbol) and an initial condition r Rk, such that
0
∪{ } ∈
(x) = s ...s ...s
D
−k1 0 k2
38is outputted as
x = x
0
(s ,s ) = (x ,r )
−1 0 0 0 0
D
x ,r = P(x ,r )
i i i−1 i−1
(s ,s ) = (x ,r )
−i−1 i 0 i i
D
where if one of s or s is not defined in (x), then outputs p˜ for that value; and the output halts
−i−1 i 0
D D
when one of P or reaches a value for which its output is not defined.
0
D
Note that every Cantor-like decoder is optimal, i.e. it takes at most O(1) = C steps to compute each
next pair of symbols of (x). We call this constant C, the largest number of steps it might take to compute
D
one more symbol of (x), the rate constant of .
D D
Theorem 4.37. Let f : M M be Anosov and volume-preserving. Consider a CDS (f, , ,τ,T) where
→ E D
t(n) = n, the decoder is Cantor-like (Definition 4.36), and the encoder and decoder are implemented by
BSS machines with the finite set of computable constants being a ,...,a . Then the CDS halts on all
C 1 ℓ
{ }
configurations in time O( (n)), where (n) is a computable function depending on a ,...,a .
1 ℓ
C C
Proof. ThisfollowsfromtheergodictheoryofAnosovdiffeomorphisms, togetherwithanelementaryfinite-
ness argument. Knowing the constants used in , there are only a finite number of possible semialgebraic
D
maps P and such that (P, ) can be represented by a formula which takes time at most C to compute
0 0
D D
[Sma97]. Thus the sets −1(s) must each be a union of an explicit finite set of semialgebraic sets with
D
nonempty interior (the finiteness is by the fact that the number of connected components of a semialge-
braic set is bounded by the complexity of the defining formula [Sma97], together with the finiteness of
the number of maps (P, )). In particular, there is a computable lower bound on the inradius of the
0
D
sets C = −1(s) as a function of the length s . For example, for every possible choice of (P, ), one
s 0
D | | D
can compute the cylindrical algebraic decomposition (see [BPR06, Chapter 5] for a textbook treatment,
or [Jir95] for a gentle introduction) of the corresponding set C ; the defining property of the cylindrical
s
algebraic decomposition lets us find a cube in the corresponding cell of the cylindrical algebraic decom-
position of C (which will be of full dimension in the corresponding component), at which point finding
s
a computable lower bound on the inradius is elementary. Now, given a ball B in C of radius r, the
r s
exponential mixing properties of f [Bow08] imply that there are constants C and κ independent of B or
r
r such that fN(B r) = for all N N
0
where N
0
is the minimum quantity such that rn > Ce−N0κ,
∩H ̸ ∅ ≥
i.e. such that
N (log(C) nlogr)/κ
0
≥ −
(note that r 1 so the quantity on the right-hand side grows large with small r). Combining this with
≪
the previous observation proves the theorem.
It is quite interesting to try to get an explicit value for the computable function (n). The primary
C
challenge is to get an explicit bound for the volume (or inradius) of a semialgebraic set (which is the
closure of its interior) defined by polynomial inequalities with integer coefficients, in terms of a bound
on the coefficients of the defining inequalities. Such a bound, which would be the higher-dimensional
generalization of Rump’s bound [Rum79] stated in Proposition 4.33 above, does not appear to have been
established. This is a basic question in real algebraic geometry that must require a fusion of the methods
of [Rum79] with the mathematics of the Fuschian differential equations satisfied by periods which control
the volumes of semialgebraic sets defined by BSSQ machines [LMSED19].
5 Dynamical mechanisms for computation
Throughout the paper, we have used features of families of dynamical systems to constrain the kinds of
computation that they can encode. In doing so, we have identified a number of dynamical ‘mechanisms’
39which facilitate or manifest certain types of computation. In this section we collect and summarize these
mechanisms with the hope that they will be useful in future inquiries, and that the list will be enlarged in
future works.
1. Thickened Smale horseshoes provide robust shift maps for finite strings. In our construc-
tion of robust Turing-universal CDS in Section 4.1, we considered a nonlinear variant of the Baker’s
map giving rise to a modified version of the Smale horseshoe. Ordinarily, the Smale horseshoe pro-
vides a dynamical mechanism for implementing the shift map on bi-infinite string encoded into a
two-dimensional Cantor set (see e.g. [CMPSP21] for an application involving the construction of a
Turing-universal, but not robust, dynamical system on the disk). The problem is that the ordinary
Smale horseshoe does not give rise to robust computation in our sense, since the Cantor encoding
encodes bi-infinite bit strings into individual points, which accordingly do not have a non-trivial in-
terior. However, when it comes to constructing a Turing machine, we only need to consider the set of
two-sidedbitstringswithbounded length, whichisacountableset. Inparticular, ifaTuringmachine
starts with a tape that has a finite number of blank symbols, then at any finite time step it will still
have only a finite number of blank symbols. As such, we constructed an encoding of corresponding
two-sided bit strings into closed sets with non-empty interior associated with the Cantor construc-
tion, and then constructed a thickened version of the Smale horseshoe (via a nonlinear Baker’s map)
which permutes the aforementioned closed sets. As such, the thickened Smale horseshoe provides a
‘robustified’ version of the shift map on finite two-sided strings.
2. Attractors with topologically mixing dynamics limit memory storage. In Section 4.2, we
provedthatAxiomAsystemsarenotrobustlyTuring-universal. Oneofthekeystepsoftheproofisto
usethespectraldecompositionofAxiomAsystems[Sma67,Bow08]todecomposethenon-wandering
set of the dynamics into a finite disjoint union of sets Ω on which (an iterate) of the dynamics is
i
topologicallymixing. The structural stability ofAxiom A systems [Rob71,Rob76, Man˜87] in tandem
with the stable manifold theorem for hyperbolic sets [Sma67, HP70, Bow08] allows us to prove that
if there is a bit string that we want to encode in the dynamics and store for all time, it will encode a
point that gets soaked up into a dense orbit of an Ω ; as such the Ω soaks up one finite bit string’s
i i
worth of memory. Then the number of Ω ’s limits the memory storage capacity of any computation
i
instantiated by an Axiom A system. More broadly, topologically mixing dynamics in a subset of the
configuration space of a dynamical system is highly constrained, forcing any encoded strings within
that subset to dynamically map into one another. So for example, if the halting set overlaps with a
part of the subset of the configuration space that is topologically mixing, any other bit strings which
ultimately land in that subset will at some time land in the halting set.
3. Measure-preserving dynamics on a compact set prevents computation accessing in-
finitely many states. In measure-preserving dynamics, a region of the configuration space which
encodesastringcannevershrink. Iftheconfigurationspaceofthedynamicalsystemiscompact, this
means that the forward orbit of the encoded set can only visit the encoded sets of a finite number
of strings before it exhausts the size of the compact space. Accordingly, in a measure-preserving
system, the computation is such that the forward orbit of every string is a finite set. This prevents
us from encoding e.g. the Plus machine into measure-preserving dynamics (see Theorem 4.20), thus
obstructing Turing-universality as well as other kinds of computations.
4. Periodic orbits can store memory. Part of our intuition in Section 4.3 is that periodic orbits
can be used to store memories. One way is to use the period of the orbit itself to store information.
For instance, consider a family of integrable Hamiltonian systems, such as pendulums with varying
tensions. The tension dictates the period of oscillations in a robust manner in the regime of small
oscillations (i.e. the harmonic oscillator regime), and thus the ‘memory’ stored in the pendulum
could be regarded as its period. Even for fixed tension, in the nonlinear regime of large oscillations
the period of the pendulum depends more strongly on the initial conditions, which can also serve
40to encode the ‘memory’. These considerations generalize to integrable Hamiltonian systems more
broadly, and also to dynamical systems with multiple periodic orbits of varying lengths in their
configuration space.
5. Exponential mixing forgets the initial input to the computation. In Sections 4.4 and 4.5
wherewediscusstimecomplexityboundsofAnosovsystems,weexploitexponentialmixingproperties
toboundthehaltingtimeofencodeddynamics. Inessence, theexponentialmixinggivesquantitative
bounds on the timescale at which an initial encoded region will ultimately overlap with another
encoded region. That is, if we start in a configuration s encoded into a region of known size, we
can bound how quickly that region maps into another one corresponding to s′ with a known size. In
other words, we are bounding how quickly s will be mapped into s′ (e.g. we can imagine s′ being in
the halting set). As such, the exponential mixing mediates how quickly the computation ‘forgets’ the
initial string and maps it onto another arbitrary string s′.
6 Open Problems
In this final section, we describe some natural open problems and research directions in the theory of
computational dynamical systems. The problems we outline below involve an interplay between aspects
of circuit theory or real algebraic geometry, aspects of dynamical systems theory, and questions that are
natural from a computer science perspective. We hope that these problems will be of interest to others.
Quantitative analysis of Anosov diffeomorphisms and related problems. In Section 4.2, we
showed that an Axiom A diffeomorphism, in any dimension, cannot robustly implement machines which
have infinitely many cycles in their state space. In fact, the proof implies a sharp bound on the number
of possible distinct cycles in the state space of any machine implemented by an Axiom A diffeomorphism.
This naturally leads to the question of a more quantitative analysis of the computational power of Axiom
A diffeomorphisms and maps, which we began to investigate in Section 4.4.
Anosov diffeomorphisms, which are the simplest Axiom A diffeomorphisms, constitute an interesting
case for questions in computational dynamical systems theory, because establishing complexity bounds on
Anosov systems is connected to the theory of error correcting codes. On an informal level, the problem is
whether it is possible to efficiently encode and decode states into strongly chaotic systems such that these
chaoticsystems, whichstatisticallybehavelikepurerandomnumbergeneratorswhichrapidly‘forget’their
state, are nonetheless able to perform sophisticated computations. For example: can an ideal hard-ball
gas in a box serve as a computer, given the correct interpretation of its state space? In order to show that
in some sense the answer is no, one can use the language of this paper to formalize this problem, and a
mathematical answer is not straightforward.
Remark 6.1. The formalization of computational dynamical systems in this paper is connected to to
certain discussions in the analytic philosophy literature on the computational theory of mind, referred to
as the ‘computational triviality problem’ of Hinkman, Searle, Putman, Chalmers, and others (e.g. ‘Does
a rock implement every finite-state automaton’ [Cha96]; see also [Spr18] for a review). In some sense this
paper gives a mathematical formalization and partial resolution of this problem. We thank Rosa Cao for
explaining this connection.
As described in Section 4.5, the basic reason we are not able to prove a quantitative complexity bound
for Anosov diffeomorphisms is because the method of Theorem 4.30 relies on a lower bound of the size
of a real-algebraic set in dimension 1 (Proposition 4.33). There appears to be no known analog of this
statement for regions in Rn defined by real algebraic circuits if n > 1.
Problem 6.1. Give a generalization of Proposition 4.33 to the setting of semialgebraic subsets of Rn.
Namely, let K be a connected component of a semialgebraic set defined by m algebraic inequalities of n
41variables p (x) 0, i = 1,...,m, and let w ,...,w be a collection of explicit functions of the coefficients
i 1 ℓ
≥
of the polynomials p . Write B(x,r) for the ball of radius r around x. Give an explicit lower bound
i
C(n,m,w ,...,w ) inrad(K) = sup r
1 ℓ
≤
r>0:B(x,r)⊂K
that holds whenever K has nonempty interior.
Unfortunately, without a methodological improvement, progress on Problem 6.1 will give at best tower-
exponential bounds for the Anosov setting of Theorem 4.37. However, note that this setting, while higher-
dimensional, is in some ways simpler than the setting of 1-dimensional Axiom A maps, since the Anosov
diffeomorphism system is exponentially mixing everywhere. However, even though one has an excellent
understanding of the dynamics of an Anosov diffeomorphism from a symbolic dynamics perspective (Ap-
pendix C), the basic challenge is that the encoding and decoding of states in a CDS does not have to be
compatible with the symbolic dynamics in any elementary fashion.
Remark 6.2 (Decidable halting problem for measure-preserving dynamics). If Problem 6.1 can be solved
with an explicit bound, then it would imply that measure-preserving dynamics on a compact set can only
encode Turing machines with a decidable halting problem. The argument is as follows. Suppose we have a
putative CDS involving f : M M which instantiates measure-preserving dynamics for a measure µ on a
→
compact set M, and let −1(s) = C M for some s. The forward orbit of C under f can only intersect
s s
D ⊂
finitely many C s′’s since M is compact and C
s
has non-trivial interior. As such, in the Turing machine the
forward orbit of any s can only visit a finite number of configurations. Then the Turing machine initialized
with s either halts or enters into a periodic orbit. Contingent on a solution to Problem 6.1, we have an
explicit lower bound on the radius of a ball inside C as a function of s . Let us call the lower bound r .
s
| |
Cs
Then the number of points in the forward orbit of s is at most µ(M)/µ(B ), and as such the halting
rCs
problem is decidable for the CDS.
Problem 6.2. Given a CDS with an underlying differentiable dynamical system f which is Anosov, is there
an efficient algorithm which will predict how long it takes for the system to halt on an input string? For
example, is there a polynomial-time algorithm for this problem? Here, we do not ask that f is computable,
and we are simply asking for the existence of such an algorithm for any f, rather than for an algorithm
for finding this algorithm given f.
Problem 6.3. Given a CDS with an underlying differentiable dynamical system f which is Anosov, will
it halt in polynomial time in the input size?
Relatedly, one would like to improve the bound of Theorem 4.30 to something much better than the
tower-exponential bound given in the theorem statement. This may be difficult without putting additional
restrictictions on the architecture of the encoder and decoder, which we turn to next.
Varyingconditionsonencodersanddecoders. Muchofthedifficultyofthequestionsoftheprevious
section (e.g. Problems 6.2 and 6.3) is that not so much is known about the theory of circuits, whether
Booleanorreal-algebraic. Indeed, evenforaCantor-likedecoder(Definition4.36)asusedinTheorem4.37,
the structure of the encoder and decoder is essentially controlled by an auxiliary high-dimensional real-
semialgebraicdynamicalsystem, whichmayhavearbitrarilycomplexdynamics; thisisoddwhencompared
to the comparatively simple (e.g. Anosov, Axiom-A) dynamics of the system being encoded into! Thus,
while our definition of a optimal complexity encoder-decoder is ‘simple’ from the perspective of computer
science, it still allows for extraordinarily complex dynamical behavior.
In fact, with the current definitions of encoders and decoders used in this paper, Problems 6.2 and 6.3
have corresponding variants where f is an integrable system, and already the corresponding results are
not straightfoward to establish. Although one can can certainly establish such bounds by solving Problem
6.1, a more fruitful strategy may be do modify the definition of a Cantor-like decoder in a natural manner
such that better methods of proof become available.
42Problem 6.4. Find a natural strengthening of the notions of a Cantor-like decoder which forces it to
behave ‘like’ the robust Cantor decoder defined in Theorem 4.4. This notion should not be too ‘specific’,
i.e. it should allow for behavior significantly more general than that of the robust Cantor decoder; however,
using this notion should make it possible to significantly strengthen the bounds in Problems 6.2 and 6.3,
and the other problems of this section.
More generally, varying the condition on the encoders and decoders allowed for any given problem
about computational dynamical systems tends to highlight different aspects of the problem, and can make
a problem either interesting, trivial, or extremely difficult. For example:
Problem 6.5. Prove Theorem 4.15 while dropping the shrinking condition on the decoder.
It is also natural to approach Conjecture 1.9 with various conditions on the encoder-decoder pair.
Finally,onecanconceiveofaweakernotionofrobustnesswhereoneworkswithahierachicallyshrinking
decoder (Definition 3.30), and one only asks (in the notation of that definition) that if Tn(s) = s′ then
((fτ)n(C′ )) = C′ , where s denotes the string s prepended and appended with some number
D s padded s′ padded
of zeros, i.e. there is some amount of ‘zero padding’ around s. This notion encodes the idea that one may
need to ‘encode a string more and more accurately to simulate it for longer and longer’. Modifying the
problems in this paper to utilize this latter notion highlights yet a different aspect of the computational
properties of continuous dynamical systems, which deserves to be explored in future work.
Problems on finite state machines and other complexity classes. Below, a finite state machine
is taken to be a Turing machine that only moves to the right on its tape. We expect that there are positive
answers to the following two problems:
Problem 6.6. Is there an Axiom A diffeomorphism f which is universal for finite state machines, e.g. such
that for any finite state machine F there is a Cantor-like encoder-decoder pair which makes f implement
F?
Problem 6.7. Fix an analog of the Cantor decoder (as well as an analog of the encoder ) of Theorem
D E
4.4. For every finite state machine F, does there exists an Axiom A diffeomorphism f : R2 R2 such
F
→
that (f , , ,τ,F) is a robust CDS for F?
F
E D
These two problems would clarify the more traditional correspondence between Axiom A systems and
finite state machines via symbolic dynamics. From the perspective of computational dynamical systems,
the class of Axiom A systems should be ‘Finite-State-Machine-complete’.
We can generalize these problems to other complexity classes and other classes of dynamical systems.
For example:
Problem 6.8. Does there exist a single Anosov diffeomorphism f : M M (where M is a computable
→
manifold) such that for every decision problem L C (where C is a complexity class like P, NP,
∈
NEXPSPACE, etc.) there exists a Turing machine T solving L and an optimal complexity encoder-
decoder pair , such that f, , implements T? In this case, we may say that f is C-complete. For
E D E D
example, we can also ask if the Arnold cat map in particular is C-complete?
There is an obvious relationship between Problems 6.3 and Problem 6.8; however, the requirement that f
is C-complete is a much stronger property than e.g. a runtime bound, and there may be correspondingly
stronger results. If a given f is not C-complete then there is some problem in C that f cannot implement.
If a given class of dynamical systems D contains no elements which are C-complete, then this gives a
precise meaning to the idea that ‘systems in class D cannot implement computations in class C’, i.e. that
the classical computational complexity class C is ‘more complex’ than the dynamics available in D.
One of the most satisfying aspects of the basic theory of computational complexity is the existence
of various complexity classes and the (only very partially understood) inclusions and separations between
43these classes. In differentiable dynamics, researchers also consider a ‘complexity hierarchy’, but rather
than being governed by computational considerations, this hierarchy is structured largely by ‘infinitesimal’
or ‘dynamical’ conditions, e.g. a loss of uniformity of hyperbolicity (see [HP06] for a textbook review, and
[PM80] for the connections to intermittency and turbulence).
The language above lets us formalize a problem which we feel is particularly interesting:
Problem 6.9. Do there exist natural classes of differentiable dynamical systems which are universal for
finitestatemachines(oranotherintermediatecomplexityclass)butcannotbeextendedtoarobustlyTuring-
universal CDSs?
This problem highlights the significant gap between the dynamical perspective and the computational
perspective. This paper was largely written with the motivation of rephrasing this conceptual gap into a
series of precise mathemtatical problems. We hope that future researchers can help clarify in a rigorous
fashion the correspondence between dynamical and computational notions of complexity.
Acknowledgements
We thank Will Allen, Peter G´acs, Boris Hasselblatt, Felipe Hern´andez, and Jensen Suther for valuable
discussions.
A Real computation and BSS machines
C
In [BSS89] Blum, Shub and Smale introduced what is now known as the BSS machine as a model of
computation over an arbitrary ring R, notably including the reals R = R. In the setting where R is a
finite field, a BSS machine reduces to the usual paradigm of Turing machines. A detailed exposition is
given in the original paper [BSS89] as well as the book [Blu98], where BSS machines are presented in
terms of computational graphs, although some other equivalent formulations are given. For our purposes,
we provide an equivalent formulation that emphasizes the connection with ordinary Turing machines. To
build up the definition, we require some prelimary definitions from real algebraic geometry and the theory
of semialgebraic sets (see e.g. [BCR13, Cos00]).
First let us define semialgebraic subsets of Rn. Since we will consider R to be a finite field, R, or
Cartesian products thereof, we can suppose that R is a real closed field with a canonical ordering. We have
the following definition.
Definition A.1 (Semialgebraic subsets of Rn, adapted from [BCR13]). A semialgebraic subset of Rn
is a subset of the form
(cid:91)s (cid:92)ri
x Rn : f (x)▷ 0 (37)
i,j i,j
{ ∈ }
i=1j=1
where f R[X ,...,X ] and ▷ is either > or =, for i = 1,...,s and j = 1,...,r .
i,j 1 n i,j i
∈
Having defined a semialgebraic subset, we can now define a semialgebraic function.
Definition A.2 (Semialgebraic function, adapted from [BCR13, Cos00]). Let A Rm and B Rn be
⊆ ⊆
two semialgebraic sets. A mapping f : A B is a semialgebraic function if its graph
→
Γ = (x,y) A B : y = f(x) (38)
f
{ ∈ × }
is a semialgebraic subset of Rm Rn.
×
While Definitions A.1 and A.2 may be slightly hard to parse upon an initial glance, they have a simple
interpretation as remarked below.
44Remark A.3. A semialgebraic subset of Rn is one that is carved out be a finite boolean combination of
polynomial equalities and inequalities. Similarly, a semialgebraic function is a function that is built out of
a finite boolean combination of addition, multiplication, and inequality comparisons.
Moreover, we notice the notion of semialgebraic subsets of functions becomes trivial in the setting that
R = Z for some d. We capture this in the following remark.
d
Remark A.4 (Semialgebraic subsets and functions for R = Z ). If R = Z , all subsets of Zn are semial-
d d d
gebraic and thus all functions f : A B for A Zm and B Zn are semialgebraic functions. That is,
→ ⊆ d ⊆ d
the semialgebraic conditions put no constraints on subsets or functions in the setting of finite fields.
Before proceeding, it is useful to consider a refinements of Definition A.1.
Definition A.5 (R′–semialgebraic subsets of Rn). Let R′ R by a real closed subfield of R with an
⊆
ordering induced by that of R. Then an R′–semialgebraic subset of Rn is a subset of the form
(cid:91)s (cid:92)ri
x Rn : f (x)▷ 0 (39)
i,j i,j
{ ∈ }
i=1j=1
where f R′[X ,...,X ] and ▷ is either > or =, for i = 1,...,s and j = 1,...,r .
i,j 1 n i,j i
∈
We are now equipped to define BSS machines and some useful generalizations thereof. Let us first
define the BSS analog of a Turing machine over R, akin to Definition 3.1.
Definition A.6 (R–Turingmachine). An R–Turing machine is given by a triple (Q,Γ,δ) where Q = Rm
and Γ = R and:
1. Q is the set of states, containing a start state labeled q and at least one halt state labeled q ;
0 halt
2. Γ is the tape alphabet; and
3. δ : Q (Γ Z ) Q (Γ Z ) L,R,S is a semialgebraic function, interpreted as one from
2 2
× × → × × ×{ }
Rm (R Z ) Rm (R Z ) Z . We identify Z 0,1 with ,1 and call the blank
2 2 3 2
× × → × × × ≃ { } {⊔ } ⊔
symbol. We additionally require that δ(q,γ, ) = δ(q′,γ′,1) and δ(q,γ,1) = δ(q′′,γ′′,1) for all q,γ.
⊔
In other words, transitions always take blank symbols to non-blank symbols, and non-blank symbols
to non-blank symbols.
The configuration space S of an R–Turing machine is given by S := Γ∗ Q Γ∗, where a configuration is
× ×
denoted by s = x x qx x for x Γ Z and q Q, with the understanding that all symbols
1 m−1 m n i 2
··· ··· ∈ × ∈
to the left of x are equal to (γ , ) for some fixed γ , and all symbols to the right of x are equal to (γ , )
1 0 0 n 0
⊔ ⊔
for the same fixed γ . Our notation expresses that the head is above x , and that all of the symbols on the
0 m
tape to the left of x and to the right of x are (γ , ) which is ‘blank’. We can define a map T : S S
1 n 0 R
⊔ →
as follows. If δ(q,x ) = (q′,x′ ,a) for a L,R,S , then
m m
∈ { }

x x q′x x′ x if a = L
  1 ··· m−2 m−1 m ··· n
T R(s) = x
1
x m−1q′x′
m
x
n
if a = S , (40)
 ··· ···
x x′ q′x x if a = R
1 m m+1 n
··· ···
which describes one time step of the R–Turing machine.
The above immediately generalizes to the k-tape setting. We make the following important remark about
terminology:
Remark A.7 (BSS machine). Definition A.6 is different than the definition of a BSS machine over R
in e.g. [BSS89, Blu98]. However, our R–Turing machine model is computationally equivalent to a BSS
machine over R. As such, we will sometimes refer to an R–Turing machine as a BSS machine over R.
45Moreover, we note that Definition A.6 reduces to the ordinary Turing machine setting of Definition 3.1
when R is a finite field.
Considering the setting of R–Turing machines for R = R, there is a notable feature of Definition A.6.
Since δ : Rm (R Z ) Rm (R Z ) Z is a semialgebraic function, it entails polynomials
2 2 3
× × → × × ×
and polynomial inequalities involving a finite number of arbitrary real numbers (e.g. the coefficients of
the polynomials). As emphasized in [Bra05a], BSS machines over R can have certain pathological features
stemmingfromtheaforementionedarbitraryrealconstants. Asaremedy,Bravermansuggestsconstraining
those real numbers to be computable. Let us make this precise in our language. First, we recall the
definition of computable real numbers.
Definition A.8 (Computable real numbers C). The computable real numbers C are real numbers
x R such that for each x, there exists a (Z –)Turing machine T with Γ = 0,1 that has the following
2 x
∈ { }
property. For each n N, if the Turing machine is given the initial configuration q [n] where [n] is
0 2 2
∈
the representation of n in binary, then the Turing machine halts with the configuration q [a(n)] where
halt 2
a(n)−1 a(n)+1
x .
n ≤ ≤ n
WenotethatCisarealclosedsubfieldofRwiththeorderinginducedbyR. Assuch, wehavethefollowing
definition:
Definition A.9 (BSS machine, after [Bra05a]). A BSS machine is an R–Turing machine (Q,Γ,δ)
C C
such that the graph of δ is a (Cm (C Z ) Cm (C Z ) Z )–semialgebraic subset of Rm (R Z )
2 2 3 2
× × × × × × × × ×
Rm (R Z ) Z , and the distinguished symbol γ is an element of C. This is to say that the (finite
2 3 0
× × ×
number of) real numbers entailed in the definition δ are all computable.
In the above Definition, we can canonically take γ := 0. We use the Definition of a BSS machine
0 C
extensively throughout the paper.
Another useful definition is the one below.
Definition A.10 (Finite state BSS machine). A finite state BSS machine is a map f : M M
C C 1 2
× →
M
2
where M
1
Rn1, M
2
Rn2, and such that the graph of f is a (M
1 C
M
2 C
M
2
C)–semialgebraic
⊆ ⊆ | × | × |
subset of M M M . Here M and M mean the restriction of M and M to their computable
1 2 2 1 C 2 C 1 2
× × | |
points.
Note that we can think of an ordinary BSS as a Turing machine with an R–valued tape, where the ‘head’
C
is a type of finite state BSS machine.
C
B Complexity classes and dynamical systems
In this appendix we explore the relationship between complexity classes and computational dynamical
systems. We focus on deterministic time and space complexity, and do not discuss the non-deterministic
setting here. First we review some standard complexity classes along the lines of [AB09]. Recall that a
language L over a finite alphabet Γ is a subset L Γ∗. Then we have the following definition.
⊆
Definition B.1 (Turing machine deciding a language). Consider a (single tape) Turing machine (Q,Γ,δ)
with two halt states called q and q . We say that the Turing machine decides a language L Γ∗
accept reject
⊆
if, when initiated in the configuration q x, the Turing machine halts with the head in the state q if
0 accept
and only if x L. We further say that a Turing machine which decides L has runtime O(T(n)) if for
∈
each x L such that x = n, the Turing machine halts in time O(T(n)).
∈ | |
With the above definition, we can define the following complexity classes.
Definition B.2 (DTIME complexity classes, adapted from [AB09]). If T : N N is a monotonically
→
increasing function, we say that L is in DTIME(T(n)) if there is a Turing machine that decides L with
runtime O(T(n)).
46While in some cases it is natural to consider e.g. DTIME(n) or DTIME(n2), it is often most useful to
consider the class of languages that is decidable by a Turing machine with any polynomial runtime. To
this end, we define the following:
Definition B.3 (P complexity class). We define P := (cid:83) DTIME(nk).
k∈N
This complexity class P is one of the central objects of study in computational complexity theory. It is
also useful to define:
Definition B.4 (EXPTIME complexity class). We define EXPTIME := (cid:83) DTIME(2nk ).
k∈N
In addition to considering time-bounded complexity, we can also consider space-bounded complexity.
As such, a spatial analog of Definition B.2 is:
Definition B.5 (DTIME complexity classes). Let S : N N be a monotonically increasing function.
→
We say that L is in SPACE(S(n)) if there is a Turing machine that decides L for which the following
condition holds. For each x L with x = n, when the Turing machine is initiated in the configuration
∈ | |
q x, it halts with its head in the state q with the head visiting O(S(n)) cells of the tape during the
0 accept
computation.
Then the spatial analogs of Definitions B.3 and B.4 are:
DefinitionB.6(PSPACEcomplexityclass,adaptedfrom[AB09]). WedefinePSPACE := (cid:83) SPACE(nk).
k∈N
Definition B.7 (EXPSPACE complexity class). We define EXPSPACE := (cid:83) SPACE(2nk ).
k∈N
There are standard relationships between the time and space complexity classes (see e.g. [Sip12, AB09]),
but we will not review them here.
Now we turn to dynamical systems. Let us consider e.g. differentiable maps f : M M for M some
→
fixed manifold M. Then we have the following definitions.
Definition B.8 (Simulation by a collection of dynamical systems). Let C be some collection of languages
and D be some collection of differentiable dynamical systems f : M M for some fixed M. Then we say
→
that C is simulated by D with O(t(n))–complexity if for each language L C, there exists a dynamical
∈
system in D which extends to a O(t(n))–complexity CDS of a Turing machine that decides L.
The above Definition allows us to formulate certain interesting mathematical statements in a compact
manner. For instance, let R be the set of recursive languages, i.e. the set of languages decidable by a
Turing machine. Moreover, let DiffDisk be the set of diffeomorphisms of the disk. Then by Theorem 4.4,
we find that R is simulated by DiffDisk with Θ(n) complexity. We can also formulate questions like:
Question B.9. Let ErgodicDisk be the set of ergodic diffeomorphisms on the disk. Then is P or even
EXPTIME simulated by ErgodicDisk with Θ(n) complexity?
Or similarly we can ask:
Question B.10. Is PSPACE or even EXPSPACE simulated by ErgodicDisk with Θ(n) complexity?
We anticipate that there are many other interesting questions along these lines.
C Symbolic dynamics
In this appendix we give a review of symbolic dynamics. An excellent textbook treatment can be found in
[Kit12]; see also [KKS+15].
Let Σ be a finite alphabet (distinct from the alphabet Σ associated to any CDS with underyling
1
Z
dynamical system f). The set Σ of bi-infinite strings of symbols from Σ has a natural topology that
1 1
47makes it homeomorphic to the Cantor set: one declares a sub-basis of open sets to be the collection U ,
s
where s ranges over Σ∗ of even length, such that writing s = s s s s s (where the length of
−m −1 0 1 m−1
··· ···
s is 2m) one has that
U = s′ ΣZ : s′ = s for i = m,...,m 1 .
s 1 i i
{ ∈ − − }
The shift map
Z Z
σ : Σ Σ , σ(s) = σ(s) ,
1 1 i i+1
→
is a continuous homeomorphism of ΣZ . By the previous description of the topology on Σ1, one sees that
1 Z
closed σ-invariant subsets of Σ1 correspond to those sets of bi-infinite strings which do not contain some
Z
collection of finite substrings.
A closed σ-invariant subset F ΣZ such that F = Uc Uc , i.e. the set of strings which do not
⊂ 1 s1 ∩···∩ s k
contain any of a finite list of banned substrings, is called a shift of finite type.
Now, a map of shift spaces
Z Z
Σ F F Σ
1 1 2 2
⊃ −→ ⊂
is simply a continuous map ϕ : F F that commutes with the shift operations on each side. It is a
1 2
→
theorem [Kit12, Theorem 1.4.9] that a map of shift spaces is defined by a sliding block code: that is, ϕ
takes the form
ϕ(s) = ϕ¯(s ,...,s ) for some ϕ¯: Σn+m+1 Σ .
i i−n i+m 1 −→ 2
A map of shift spaces is a factor map if it is surjective.
Let F = Uc Uc be a shift of finite type. Supposing N = max s , if we know the last N 1
s1
∩···∩
s
k
j
|
j
| −
symbols of a substring of s then we know what the allowed possible current symbols are. Thus, using
a sliding block code which simply introduces a new symbol corresponding to every element of ΣN, we
1
can encode the data of F into a graph, with vertices given by allowed words of length N in F, and edges
givenbyallowedtransitions(correspondingtoforgettingtheearliestsymbolandaddinganallowedcurrent
symbol). We can think of the vertices of this graph as states and the edges of this graph as transitions
betweenstates. Thisdiscussionshowsthatusingtheslidingblockcodeabove, onecanfindanisomorphism
from F to another shift of finite type F = Uc Uc with s′ = 1 for all j.
0 s′ 1 ∩···∩ s′ k | j|
Usingthisrepresentation, weseethatwecanthinkofashiftspaceF (where‘FSM’standsfor‘finite
FSM
state machine’) which is a factor of a shift of finite type as the collection of strings outputted by walks
on such a graph, where we compute the output string via a sliding block code on the sequence of vertices
visited on the walk. In other words, the symbol output at time t corresponds to the vertices visited at
times t n,...,t+m. By building a new graph whose vertices are labeled by sequences of n+m+1
−
vertices of the previous graph and whose transitions correspond to forgetting the earliest vertex and going
to a valid subsequent vertex, we see that this set F is exactly the set of walks on a finite graph with
FSM
certain symbols labeling the vertices where the same symbol may label multiple vertices. Thinking of the
vertices as states and the symbols labeling the vertices as ‘outputs’, we see that we have exactly the set of
possible outputs of a finite state machine with no halting state. Thus factors of shifts of finite type, also
known as ‘sofic systems’, correspond to collections of strings which can be output by a nondeterministic
finite state machine without a distinguished halting state.
This review of symbolic dynamics should convince the reader that factors of shifts of finite type are a
convenient description of a finite state machine. Now, given an Axiom A system f, a theorem of Bowen
gives us an analogous understanding of the dynamics of f on each basic set Ω in terms of an associated
i
shift of finite type, due to the existence of Markov partitions for f. This is a fundamental result of Bowen
which we we state below:
Theorem C.1 (Bowen [Bow70]). Let C be a hyperbolic set for f. There exists a shift of finite type F on
the alphabet Σ , and a continuous map
1
π : F C
→
such that:
481. π is surjective;
2. π is finite-to-one, with the sizes of preimages being finite; and
3. The map π is defined as follows: there are a finite collection of rectangles R ,...R with Σ =
a1 a
k
1
a ,...,a , which are closed subsets of Ω with nontrivial, nonoverlapping interiors, satisfying some
1 k
{ }
axioms (those of a Markov partition, see [Bow70]). Then π is defined to be the map
(cid:92)
s π(x), where π(x) = fk(R ).
s
(cid:55)→ { } −k
i∈Z
Moreover, on the set of x Ω such that fk(x) always lies in the interior of some rectangle, π−1(x)
i
∈
consists of a single element.
Thus we see that although f is a continuous dynamical system rather than a shift space, its dynamics are
in a precise sense a factor of a shift of finite type.
Remark C.2. ThecombinationofthespectraldecompositionandBowen’sresultonMarkovpartitionsfor
f suggestsimmediatelythatf behaveslikeanon-deterministicfinitestatemachine. Oneofourmotivations
forthisworkwastomakethismathematicalresulthaveamorepreciseinterpretationfromacomputational
perspective. Part of the challenge is that the sets R of the Markov partition are generally not computable
j
subsets.
Indeed, if there is only one basic set and it is equal to all of M, we say that f is Anosov. Already in
the relatively simple case of linear Anosov diffeomorphisms of higher-dimensional tori, one can see that the
Markov partition R does not consist of computable subsets [Bow78]. See Problem 6.3 above for questions
j
about the computational complexity of f which existing dynamical results on Axiom A systems do not
immediately resolve.
D Variations of the stable manifold theorem
In this technical appendix we derive the variant of the stable manifold theorem for hyperbolic sets that we
use (Proposition 4.12) from the result of Hirsch-Pugh [HP70]. We will freely use the statement of Theorem
3.2 of [HP70]. First, with notation W as in Hirsch-Pugh, note that x W , so [HP70, Theorem 3.2(c)]
x x
∈
implies that W contains Ws(x) B(x,r ) for some r , where Ws(x) is defined as in our paper. Since the
x x x
∩
W are a continuous family of Ck submanifolds (in the sense of [HP70]), the numbers r can be chosen to
x x
vary continuously with x. By compactness of the hyperbolic set, this means that r achieves a minimum
x
r . But by [HP70, Theorem 3.2(c)] together with the fact that f(Ws(x)) = Ws(f(x)), this implies that
min
f−n(W ) Ws(x) contains Ws(x) B(x,r /(Kλ)n) for some K > 0 and λ < 1. In particular we
fn(x) min
have that (cid:83) ⊂ f−n(W ) = Ws(x). M∩ oreover, the same argument lets us generalize [HP70, Theorem
n fn(x)
3.2(b)] to our notion of the continuity of the manifolds Ws(x). Indeed, fn(z) W for all sufficiently
fn(x)
∈
large n by Theorem [HP70, Theorem 3.2(c)], so we can take our ϕ : U C∞(Dr,M) to be f−n ϕ′ fn
x
→ ◦ ◦
with ϕ′ : U C∞(Dr,M) the map produced by [HP70, Theorem 3.2(b)].
fn(x)
→
E Proof of polynomial root separation bound
In this appendix we give a self-contained treatment of the polynomial root separation bound used in the
proof of Theorem 1.12. Our desired bound is essentially an adaptation Theorem 3 of [Rum79], and we will
follow that proof closely.
Let us begin with some definitions which allow us to state the results and proofs. Denote by P(x) a
polynomial in C[x] of degree n > 0 of the form
n n
(cid:88) (cid:89)
P(x) = a xk = a (x λ ) (41)
k n k
−
k=0 k=1
49where a = 0. Above, the λ ’s are the roots of P. Then we define the minimal root separation as follows.
n k
̸
Definition E.1 (Minimal root separation). We denote by rsep(P) the minimal root separation of P,
namely
rsep(P) := min λ λ for real λ = λ . (42)
i j i j
{| − | ̸ }
We further denote
rsep (P) := min λ λ for real λ = λ and λ , λ 1 . (43)
[−1,1] i j i j i j
{| − | ̸ | | | | ≤ }
We will also need to define a p-seminorm on polynomials.
DefinitionE.2(p-seminormonpolynomials). ForP C[x], wedefinethep-seminorm P := ((cid:80)n a p)1/p.
Additionally consider Q C[x,y], and suppose Q take∈ s the form Q(x,y) = (cid:80)n (cid:80)m | a|p xkyℓ. Tk= h0 en| k w| e
∈ k=0 ℓ=0 k,ℓ
further define the p-seminorm Q := ((cid:80)n (cid:80)m a p)1/p.
| |p k=0 ℓ=0| k,ℓ |
RemarkE.3. NotethatC[x],C[y] C[x,y],andasthatthep-seminormonC[x,y]inducesthep-seminorm
⊂
on C[x] and C[y]. As such, we not distinguish between these seminorms.
We also use the following definitions to simplify notation.
Definition E.4 (Standardized polynomial). We say that a polynomial P is standardized if all of its
non-zero coefficients are greater than or equal to 1. For any P(x), we let
P(cid:101) := P/min 1,min a
i
: a
i
= 0 , (44)
{ {| | ̸ }}
which is standardized. Indeed, if P is already standardized, then P(cid:101) = P.
Definition E.5 (Size of a polynomial). We define the size of P to be s(P) := P . We further let
1
| |
s˜(P) := s(P(cid:101)), noting that s˜(P) s(P).
≥
Finally, we also need to define the resultant of two polynomials.
Definition E.6 (Resultant of two polynomials). Let P,Q C[x] with P(x) = (cid:80)n a xk = a (cid:81)n (x
λ ) and Q(x) = (cid:80)m b xℓ = b (cid:81)m (x µ ) with a ,b ∈ = 0. Then the resultak n= t0 ofk P and n Q isk=1 −
k ℓ=0 ℓ m ℓ=1 − ℓ n m ̸
n m
(cid:89)(cid:89)
res(P,Q) := ambn (λ µ ). (45)
n m k ℓ
−
k=1ℓ=1
The resultant has the equivalent expressions res(P,Q) = am(cid:81)n Q(λ ) = ( 1)mnbn (cid:81)m P(µ ).
n k=1 k − m ℓ=1 ℓ
With the above definitions at hand, we can state the desired bound.
Theorem E.7 (Adapted from Theorem 3 of [Rum79]). Let P C[x] have degree n. Then we have the
∈
root separation bound
2√2
rsep (P) . (46)
[−1,1] ≥ nn/2+1(s˜(P)+1)n
To establish this Theorem, we require a number of lemmas. We begin with a generalization of Hadamard’s
bound.
Lemma E.8 (Adapted from Theorem 1 of [CH74]). Let M be an N N matrix with entries valued in
×
C[x,y] (or just C[x] or C[y]). If M denotes the jth row of M, then we have the bound
j
N
(cid:89)
det(M) M . (47)
1 j 1
| | ≤ | |
j=1
50Proof. We proceed with a proof by induction, noting that the N = 1 case holds automatically. Suppos-
ing (47) holds for N, let us establish the bound for N +1. Letting M′ be the submatrix of M with row i
ij
and column j removed, we have det(M) = (cid:80)N+1 ( 1)i+1M det(M′ ) and so
i=1 − i1 i1
N+1 N+1 N+1
(cid:88) (cid:89) (cid:88)
det(M) M det(M′ ) M M . (48)
1 i1 1 i1 1 j 1 i1 1
| | ≤ | | | | ≤ | | | |
i=1 j=2 i=1
In the first inequality we have used Cauchy-Schwarz, and in the second inequality we applied (47) to
det(M′ ). Since (cid:80)N+1 M = M , we have established the bound for N + 1, which completes the
i1 i=1 | i1 |1 | 1 |1
proof.
Next we use the bound in the previous Lemma to bound a particular resultant of two polynomials.
Lemma E.9 (Adapted from Theorem 2 of [CH74]). Let R(y) := res(Q(x),y P(x)) be the resultant with
−
respect to x, so that R(y) is a polynomial in C[y]. Then we have the inequality
R ( P +1)m Q n. (49)
1 1 1
| | ≤ | | | |
Proof. The resultant R(y) := res(Q(x),y P(x)) with respect to x, namely R(y) = bn (cid:81)m (y P(µ )),
− m ℓ=1 − ℓ
can be expressed as the determinant of the (m+n) (m+n) matrix
×
 
b 0 0 a 0 0
m n
··· − ···
b b 0 a a 0 
m−1 m n−1 n
 ··· − − ··· 

b m−2 b m−1
...
0 a n−2 a n−1
...
0


 − − 


. .
.
. .
.
...
b m
. .
.
. .
.
...
a n


M =   . . − . .   (50)
 b 0 b 1 . y a 0 a 1 . 
 ··· − − ··· 

 0 b 0
... . .
. 0 y a 0
... . .
.


 

. .
.
. .
.
...
b 1
. .
.
− . .
.
...
a 1
 

−
0 0 b 0 0 y a
0 0
··· ··· −
withentriesvaluesinC[y]. Thatis,R(y) = det(M). LetM denotethejthcolumnofM. SinceLemmaE.8
j
(cid:81)m+n
gives det(M) M , examining (50) we have
| |1 ≤ i=1 | i |1
m+n
(cid:89)
R = det(M) M = y P(x) m Q n ( P +1)m Q n, (51)
1 1 j 1 1 1 1 1
| | | | ≤ | | | − | | | ≤ | | | |
j=1
which gives the desired bound.
Additionally, we need a classical result due to Cauchy.
Lemma E.10 (Cauchy’s root bound, see e.g. [HM97]). If λ is a root of P C[x], then λ |P|∞ +1.
∈ | | ≤ an
(cid:12) (cid:12)
Proof. Since λ is a root, we have a λn = (cid:12)(cid:80)n−1 a λk(cid:12). If λ 1, then
| n || | (cid:12) k=0 k (cid:12) | | ≤
(cid:12) (cid:12)
(cid:12)n (cid:88)−1 (cid:12) n (cid:88)−1 λ n
(cid:12) a λk(cid:12) max a λk max a | | (52)
(cid:12) k (cid:12) k k
(cid:12) (cid:12) ≤ k | | | | ≤ k | | λ 1
k=0 k=0 | |−
and so altogether a λn max a |λ|n which implies λ |P|∞ +1. This inequality also holds for
| n || | ≤ k | k ||λ|−1 | | ≤ |an|
λ 1 due to the 1 in the right-hand side.
| | ≤
51The two previous Lemmas are useful to prove the following Lemma, which is central to the proof of
Theorem E.7:
Lemma E.11 (Adapted from Lemma 2 of [Rum79]). Let P(cid:101) and Q(cid:101) be standardized polynomials of degrees
n and m, respectively. If for some µ we have P(cid:101)(µ) = 0 but Q(cid:101)(µ) = 0, then
̸
P(cid:101)(µ) ( P(cid:101) 1+1)n Q(cid:101) m
1
+1 −1. (53)
| | ≥ { | | | | }
Proof. As before, we let R(y) := res(Q(cid:101)(x),y P(cid:101)(x)) be the resultant with respect to x. By Lemma E.8
−
and the inequality between the -seminorm and 1-seminorm we have
∞
R
∞
R
1
( P(cid:101) 1+1)m Q(cid:101)1 n. (54)
| | ≤ | | ≤ | | | |
Writing R(y) = (cid:80)m r yℓ where p = argmin r : r = 0 , we can define the reciprocal polynomial
ℓ=p ℓ ℓ { ℓ ℓ ̸ }
R¯(y) := yn−pR(y−1) whose roots are the inverses of the roots of R(y). Note also that R = R¯ . For
∞ ∞
| | | |
each root α = P(cid:101)(µ) of R, by Cauchy’s root bound in Lemma E.10 we have
R
∞
α | | +1 R +1, (55)
∞
| | ≤ r ≤ | |
m
| |
where in the last inequality we have used that P(cid:101) and Q(cid:101) are standardized. So then for roots α−1 of R¯(y),
we similarly have
R¯
α−1 = P(cid:101)(µ)−1 | |∞ +1 R¯ ∞+1 = R ∞+1, (56)
| | | | ≤ r ≤ | | | |
p
| |
and so using (47) we find
P(cid:101)(µ)−1 ( P(cid:101) 1+1)n Q(cid:101) m
1
+1, (57)
| | ≤ | | | |
which implies our desired inequality.
The above Lemma has the following corollary:
Corollary E.12 (Adapted from Lemma 3 of [Rum79]). Let P(cid:101) be a standardized polynomial of degree
n 2. If some γ satisfies P′(γ) = 0 but P(γ) = 0, then
≥ ̸
P(cid:101)(γ) nn( P(cid:101) 1+1)2n−1 −1. (58)
| | ≥ { | | }
Proof. WecanuseLemmaE.11withQ(cid:101) = P(cid:101)′, whereweobservethatifP(cid:101) isstandardizedthensoisQ(cid:101) = P(cid:101)′.
Using P(cid:101)′
1
n P(cid:101) 1, we find
| | ≤ ·| |
P(cid:101)(γ) nn( P(cid:101) n
1
+1)n−1 P(cid:101) n
1
+1 −1 nn( P(cid:101) 1+1)2n−1 −1, (59)
| | ≥ { | | ·| | } ≥ { | | }
which gives the stated bound.
Finally, we can put together all of the above to prove Theorem E.7.
Proof of Theorem E.7, following Theorems 2 and 3 of [Rum79]. Consider a polynomial P, and its stan-
dardized counterpart P(cid:101). We will show that
2√2
rsep (P(cid:101)) . (60)
[−1,1] ≥ nn/2+1(s˜(P)+1)n
Since rsep (P) = rsep (P(cid:101)), the bound above in (60) implies the desired bound (46).
[−1,1] [−1,1]
52Suppose that P(cid:101)(α) = P(cid:101)(β) = 0 for α,β real, and moreover that rsep(P(cid:101)) = α β . Without loss of
| − |
generality,wecantake 1 α < β 1. ByRolle’sTheoremthereexistsarealγ with 1 α < γ < β 1
− ≤ ≤ − ≤ ≤
such that P(cid:101)′(γ) = 0. Then we consider the expansion
(γ β)2
0 = P(cid:101)(β) = P(cid:101)(γ)+ − P(cid:101)′′(ω) (61)
2
for γ < ω < β. Using Lemma E.11 we have
(γ β)2 P(cid:101)′′(ω) = 2 P(cid:101)(γ) 2 nn( P(cid:101) 1+1)2n−1 −1. (62)
− | | | | ≥ { | | }
Since we have ω < 1, it follows that
| |
(cid:12) (cid:12)
n
(cid:12)(cid:88) (cid:12)
P(cid:101)′′(ω) (cid:12)
(cid:12)
k(k 1)a kωk−2(cid:12)
(cid:12)
n2 P(cid:101)
1
(63)
| | ≤ − ≤ | |
(cid:12) (cid:12)
k=2
and so all together
(γ β)2 2 nn+2( P(cid:101) 1+1)2n −1. (64)
− ≥ { | | }
Repeating the same analysis using α in place of γ, we similarly find
(α γ)2 2 nn+2( P(cid:101) 1+1)2n −1, (65)
− ≥ { | | }
and so combining (64) and (65) we arrive at the bound in (60).
References
[AB01] Eugene Asarin and Ahmed Bouajjani. Perturbed Turing machines and hybrid systems. In
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science, pages 269–278.
IEEE, 2001.
[AB09] Sanjeev Arora and Boaz Barak. Computational complexity: a modern approach. Cambridge
University Press, 2009.
[ACQ22] Dorit Aharonov, Jordan Cotler, and Xiao-Liang Qi. Quantum algorithmic measurement.
Nature Commun., 13(1):887, 2022.
[Arn13] VladimirIgorevichArnol’d. Mathematicalmethodsofclassicalmechanics,volume60. Springer
Science & Business Media, 2013.
[BCMPS24] Renzo Bruera, Robert Cardona, Eva Miranda, and Daniel Peralta-Salas. Topological entropy
of turing complete dynamics. arXiv:2404.07288, 2024.
[BCR13] Jacek Bochnak, Michel Coste, and Marie-Fran¸coise Roy. Real algebraic geometry, volume 36.
Springer Science & Business Media, 2013.
[BGH13] Olivier Bournez, Daniel S Gra¸ca, and Emmanuel Hainry. Computation with perturbed dy-
namical systems. Journal of Computer and System Sciences, 79(5):714–724, 2013.
[BGR12] Mark Braverman, Alexander Grigo, and Cristobal Rojas. Noise vs computational intractabil-
ity in dynamics. In Proceedings of the 3rd Innovations in Theoretical Computer Science
Conference, pages 128–141, 2012.
[Blu98] Lenore Blum. Complexity and real computation. Springer Science & Business Media, 1998.
53[Bow70] Rufus Bowen. Markov partitions for axiom a diffeomorphisms. American Journal of Mathe-
matics, 92(3):725–747, 1970.
[Bow78] Rufus Bowen. Markov partitions are not smooth. Proceedings of the American Mathematical
Society, 71(1):130–132, 1978.
[Bow08] Robert Edward Bowen. Equilibrium states and the ergodic theory of Anosov diffeomorphisms,
volume 470. Springer Science & Business Media, 2008.
[BPR06] Saugata Basu, Richard Pollack, and Marie-Francoise Roy. Algorithms in real algebraic geome-
try. Algorithms and computation in mathematics. Springer, Berlin, Germany, 2 edition, July
2006.
[BR75] Rufus Bowen and David Ruelle. The ergodic theory of axioma flows. Inventiones Mathemat-
icae, 29(3):181–202, October 1975.
[Bra94] Michael S Branicky. Analog computation with continuous odes. In Proceedings Workshop on
Physics and Computation. PhysComp’94, pages 265–274. IEEE, 1994.
[Bra95] Michael S Branicky. Universal computation and other capabilities of hybrid and continuous
dynamical systems. Theoretical computer science, 138(1):67–100, 1995.
[Bra05a] Mark Braverman. On the complexity of real functions. In 46th Annual IEEE Symposium on
Foundations of Computer Science (FOCS’05), pages 155–164. IEEE, 2005.
[Bra05b] Mark Braverman. On the Complexity of Real Functions, 2005.
[BSR15] Mark Braverman, Jonathan Schneider, and Crist´obal Rojas. Space-bounded Church-
Turing thesis and computational tractability of closed systems. Physical Review Letters,
115(9):098701, 2015.
[BSS89] Lenore Blum, Mike Shub, and Steve Smale. On a theory of computation and complexity over
the real numbers: NP-completeness, recursive functions and universal machines. Bulletin of
the American Mathematical Society, 21(1):1–46, 1989.
[BY06] Mark Braverman and Michael Yampolsky. Non-computable Julia sets. Journal of the Amer-
ican Mathematical Society, 19(3):551–578, 2006.
[Car23] Robert Cardona. Hydrodynamic and symbolic models of hypercomputation.
arXiv:2301.11820, 2023.
[CH74] George E Collins and Ellis Horowitz. The minimum root separation of a polynomial. Mathe-
matics of Computation, 28(126):589–597, 1974.
[Cha96] David J Chalmers. Does a rock implement every finite-state automaton? Synthese, 108:309–
333, 1996.
[CMPS22] Robert Cardona, Eva Miranda, and Daniel Peralta-Salas. Turing universality of the incom-
pressible Euler equations and a conjecture of Moore. International Mathematics Research
Notices, 2022(22):18092–18109, 2022.
[CMPS23] Robert Cardona, Eva Miranda, and Daniel Peralta-Salas. Computability and beltrami fields
in euclidean space. Journal de Math´ematiques Pures et Appliqu´ees, 169:50–81, 2023.
[CMPSP21] Robert Cardona, Eva Miranda, Daniel Peralta-Salas, and Francisco Presas. Constructing
TuringcompleteEulerflowsindimension3. Proceedings of the National Academy of Sciences,
118(19):e2026818118, 2021.
54[Cop97] B Jack Copeland. The Church-Turing Thesis. 1997.
[Cos00] Michel Coste. An introduction to semialgebraic geometry, 2000.
[CR] Jordan Cotler and Semon Rezchikov. Forced Computational Dynamical Systems. Work in
progress.
[CS07] BJackCopelandandOronShagrir.Physicalcomputation: HowgeneralareGandy’sprinciples
for mechanisms? Minds and Machines, 17:217–231, 2007.
[CSY16] Logan Chariker, Robert Shapley, and Lai-Sang Young. Orientation selectivity from very
sparse LGN inputs in a comprehensive model of macaque V1 cortex. Journal of Neuroscience,
36(49):12368–12384, 2016.
[CTH+23] Jordan Cotler, Kai Sheng Tai, Felipe Hern´andez, Blake Elias, and David Sussillo. Analyzing
populations of neural networks via dynamical model embedding. arXiv:2302.14078, 2023.
[DMVS12] WelingtonDeMeloandSebastianVanStrien.One-dimensionaldynamics,volume25.Springer
Science & Business Media, 2012.
[Fei78] Mitchell J Feigenbaum. Quantitative universality for a class of nonlinear transformations.
Journal of statistical physics, 19(1):25–52, 1978.
[Gan80] R. Gandy. In H. J. K. Jon Barwise and K. Kunen, editors, The Kleene Symposium, volume
101 of Studies in Logic and the Foundations of Mathematics, page 123, New York, June 1980.
ACM, ACM Press.
[GCB05] Daniel S Gra¸ca, Manuel L Campagnolo, and Jorge Buescu. Robust simulations of turing
machines with analytic maps and flows. In New Computational Paradigms: First Confer-
ence on Computability in Europe, CiE 2005, Amsterdam, The Netherlands, June 8-12, 2005.
Proceedings 1, pages 169–179. Springer, 2005.
[GCB08] Daniel S Gra¸ca, Manuel L Campagnolo, and Jorge Buescu. Computability with polynomial
differential equations. Advances in Applied Mathematics, 40(3):330–349, 2008.
[Grz55] Andrzej Grzegorczyk. Computable functionals. Fundamenta Mathematicae, 42(19553):168–
202, 1955.
[GZ23] Daniel Gra¸ca and Ning Zhong. Analytic one-dimensional maps and two-dimensional ordinary
differential equations can robustly simulate turing machines. Computability, 12(2):117–144,
2023.
[Her91] M-R Herman. Exemples de flots Hamiltoniens dont aucune perturbation en topologie C∞ n’a
d’orbites p´eriodiques sur un ouvert de surfaces d’´energies. CR Acad. Sci. Paris S´er. I Math.,
312:989, 1991.
[HM97] Holly P Hirst and Wade T Macey. Bounding the roots of polynomials. The College Mathe-
matics Journal, 28(4):292–295, 1997.
[HP70] Morris W Hirsch and Charles C Pugh. Stable manifolds and hyperbolic sets. In Global
Analysis (Proc. Sympos. Pure Math., Vol. XIV, Berkeley, Calif., 1968), pages 133–163, 1970.
[HP06] Boris Hasselblatt and Yakov Pesin. Partially hyperbolic dynamical systems. In Handbook of
dynamical systems, volume 1, pages 1–55. Elsevier, 2006.
[HS66] Fred C Hennie and Richard Edwin Stearns. Two-tape simulation of multitape Turing ma-
chines. Journal of the ACM (JACM), 13(4):533–546, 1966.
55[Jir95] Mats Jirstrand. Cylindrical algebraic decomposition – an introduction. Link¨oping University,
1995.
[KF22] MikailKhonaandIlaRFiete. Attractorandintegratornetworksinthebrain. Nature Reviews
Neuroscience, 23(12):744–766, 2022.
[Kit12] BrucePKitchens. Symbolic dynamics: one-sided, two-sided and countable state Markov shifts.
Springer Science & Business Media, 2012.
[KKH95] Anatole Katok, AB Katok, and Boris Hasselblatt. Introduction to the modern theory of
dynamical systems. Number 54. Cambridge university press, 1995.
[KKS+15] SaulKato,HarrisSKaplan,TinaSchr¨odel,SusanneSkora,TheodoreHLindsay,EviatarYem-
ini, Shawn Lockery, and Manuel Zimmer. Global brain dynamics embed the motor command
sequence of Caenorhabditis elegans. Cell, 163(3):656–669, 2015.
[KM99] Pascal Koiran and Cristopher Moore. Closed-form analytic maps in one and two dimensions
can simulate universal Turing machines. Theoretical Computer Science, 210(1):217–223, 1999.
[Ko12] Ker Ko. Complexity theory of real functions. Springer Science & Business Media, 2012.
[KSvS07] OlegKozlovski,WeixiaoShen,andSebastianvanStrien. Densityofhyperbolicityindimension
one. Annals of mathematics, pages 145–182, 2007.
[Lac59] Daniel Lacombe. Classes r´ecursivement ferm´ees et fonctions majorantes. 1959.
[LMSED19] PierreLairez, MarcMezzarobba, andMohabSafeyElDin. Computingthevolumeofcompact
semi-algebraic sets. In Proceedings of the 2019 on International Symposium on Symbolic and
Algebraic Computation, pages 259–266, 2019.
[Lor63] EdwardNLorenz.Deterministicnonperiodicflow.Journalofatmosphericsciences,20(2):130–
141, 1963.
[Man˜87] Ricardo Man˜´e. A proof of the C1 stability conjecture. Publications Math´ematiques de l’IHE´S,
66:161–210, 1987.
[Moo90] CristopherMoore. Unpredictabilityandundecidabilityindynamicalsystems. Physical Review
Letters, 64(20):2354, 1990.
[Moo91] Cristopher Moore. Generalized shifts: unpredictability and undecidability in dynamical sys-
tems. Nonlinearity, 4(2):199, 1991.
[Moo98] Cristopher Moore. Finite-dimensional analog computers: Flows, maps, and recurrent neural
networks. In 1st International Conference on Unconventional Models of Computation-UMC,
volume 98, pages 59–71, 1998.
[MPVL19] Wolfgang Maass, Christos H Papadimitriou, Santosh Vempala, and Robert Legenstein. Brain
computation: a computer science perspective. Computing and Software Science: State of the
Art and Perspectives, pages 184–199, 2019.
[MT23] Seyed Mohsen Moosavi and Khosro Tajbakhsh. Smooth TA-maps with Robust Shadowing
Are Axiom A. Journal of Dynamical and Control Systems, 29(1):43–53, 2023.
[NC10] Michael A Nielsen and Isaac L Chuang. Quantum computation and quantum information.
Cambridge university press, 2010.
[New70] Sheldon E Newhouse. Nondensity of axiom A on S2. Global analysis, 1:191, 1970.
56[Ose68] Valery Iustinovich Oseledets. A multiplicative ergodic theorem. characteristic ljapunov, expo-
nents of dynamical systems. Trudy Moskovskogo Matematicheskogo Obshchestva, 19:179–210,
1968.
[Pal00] Jacob Palis. A global view of dynamics and a conjecture on the denseness of finitude of
attractors. Ast´erisque, 261(xiiixiv):335–347, 2000.
[PC10] Yakov Pesin and Vaughn Climenhaga. Open problems in the theory of non-uniform hyper-
bolicity. Discrete Contin. Dyn. Syst, 27(2):589–607, 2010.
[PM80] Yves Pomeau and Paul Manneville. Intermittent transition to turbulence in dissipative dy-
namical systems. Communications in Mathematical Physics, 74:189–197, 1980.
[PR83] Charles C Pugh and Clark Robinson. The C1 closing lemma, including Hamiltonians. Ergodic
Theory and Dynamical Systems, 3(2):261–313, 1983.
[PS] Novikoff PS. On the Algorithmic Unsolvability of the Word Problem in Group Theory.
Akademiya Nauk SSSR Matematicheskii Institut Trudy, (44).
[Rob71] Joel W Robbin. A structural stability theorem. Annals of Mathematics, 94(3):447–493, 1971.
[Rob76] Clark Robinson. Structural stability of C1 diffeomorphisms. Journal of differential equations,
22(1):28–73, 1976.
[Rob08] Kenny Robert. Orbit complexity and computable Markov partitions. PhD thesis, University
of Western Australia, 2008.
[Rog96] Yurii Rogozhin. Small universal turing machines. Theoretical Computer Science, 168(2):215–
240, 1996.
[Ros91] Robert Rosen. Life itself: a comprehensive inquiry into the nature, origin, and fabrication of
life. Columbia University Press, 1991.
[Ros11] Robert Rosen. Anticipatory systems. In Anticipatory systems: Philosophical, mathematical,
and methodological foundations, pages 313–370. Springer, 2011.
[Rum79] Siegfried M Rump. Polynomial minimum root separation. Mathematics of Computation,
33(145):327–336, 1979.
[Sei08] PaulSeidel.Abiasedviewofsymplecticcohomology.InCurrentdevelopmentsinmathematics,
2006, volume 2006, pages 211–254. International Press of Boston, 2008.
[Sip12] M Sipser. Introduction to the Theory of Computation (Cengage Learning, Boston). 2012.
[Sma67] Stephen Smale. Differentiable dynamical systems. Bulletin of the American mathematical
Society, 73(6):747–817, 1967.
[Sma97] Steve Smale. Complexity theory and numerical analysis. Acta numerica, 6:523–551, 1997.
[Spr18] Mark Sprevak. Triviality arguments about computational implementation. In The Routledge
handbook of the computational mind, pages 175–191. Routledge, 2018.
[Sus14] David Sussillo. Neural circuits as computational dynamical systems. Current opinion in
neurobiology, 25:156–163, 2014.
[Tao16] Terence Tao. Finite time blowup for an averaged three-dimensional Navier-Stokes equation.
Journal of the American Mathematical Society, 29(3):601–674, 2016.
57[Tao17] Terence Tao. On the universality of potential well dynamics. arXiv:1707.02389, 2017.
[Tho69] R. Thom. Topological models in biology. Topology, 8(3):313–335, 1969.
[Tur39] Alan Mathison Turing. Systems of logic based on ordinals. Proceedings of the London Math-
ematical Society, Series 2, 45:161–228, 1939.
[Wei12] Klaus Weihrauch. Computable analysis: an introduction. Springer Science & Business Media,
2012.
[Wei20] Shmuel Weinberger. Computers, Rigidity, and Moduli: The Large-Scale Fractal Geometry of
Riemannian Moduli Space. 2020.
[You98] Lai-Sang Young. Developments in chaotic dynamics. Notices of the AMS, 45(10), 1998.
58