[
    {
        "title": "Putting Data at the Centre of Offline Multi-Agent Reinforcement Learning",
        "authors": "Claude FormanekLouise BeyersCallum Rhys TilburyJonathan P. ShockArnu Pretorius",
        "links": "http://arxiv.org/abs/2409.12001v1",
        "entry_id": "http://arxiv.org/abs/2409.12001v1",
        "pdf_url": "http://arxiv.org/pdf/2409.12001v1",
        "summary": "Offline multi-agent reinforcement learning (MARL) is an exciting direction of\nresearch that uses static datasets to find optimal control policies for\nmulti-agent systems. Though the field is by definition data-driven, efforts\nhave thus far neglected data in their drive to achieve state-of-the-art\nresults. We first substantiate this claim by surveying the literature, showing\nhow the majority of works generate their own datasets without consistent\nmethodology and provide sparse information about the characteristics of these\ndatasets. We then show why neglecting the nature of the data is problematic,\nthrough salient examples of how tightly algorithmic performance is coupled to\nthe dataset used, necessitating a common foundation for experiments in the\nfield. In response, we take a big step towards improving data usage and data\nawareness in offline MARL, with three key contributions: (1) a clear guideline\nfor generating novel datasets; (2) a standardisation of over 80 existing\ndatasets, hosted in a publicly available repository, using a consistent storage\nformat and easy-to-use API; and (3) a suite of analysis tools that allow us to\nunderstand these datasets better, aiding further development.",
        "updated": "2024-09-18 14:13:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.12001v1"
    },
    {
        "title": "XP-MARL: Auxiliary Prioritization in Multi-Agent Reinforcement Learning to Address Non-Stationarity",
        "authors": "Jianye XuOmar SobhyBassam Alrifaee",
        "links": "http://arxiv.org/abs/2409.11852v1",
        "entry_id": "http://arxiv.org/abs/2409.11852v1",
        "pdf_url": "http://arxiv.org/pdf/2409.11852v1",
        "summary": "Non-stationarity poses a fundamental challenge in Multi-Agent Reinforcement\nLearning (MARL), arising from agents simultaneously learning and altering their\npolicies. This creates a non-stationary environment from the perspective of\neach individual agent, often leading to suboptimal or even unconverged learning\noutcomes. We propose an open-source framework named XP-MARL, which augments\nMARL with auxiliary prioritization to address this challenge in cooperative\nsettings. XP-MARL is 1) founded upon our hypothesis that prioritizing agents\nand letting higher-priority agents establish their actions first would\nstabilize the learning process and thus mitigate non-stationarity and 2)\nenabled by our proposed mechanism called action propagation, where\nhigher-priority agents act first and communicate their actions, providing a\nmore stationary environment for others. Moreover, instead of using a predefined\nor heuristic priority assignment, XP-MARL learns priority-assignment policies\nwith an auxiliary MARL problem, leading to a joint learning scheme. Experiments\nin a motion-planning scenario involving Connected and Automated Vehicles (CAVs)\ndemonstrate that XP-MARL improves the safety of a baseline model by 84.4% and\noutperforms a state-of-the-art approach, which improves the baseline by only\n12.8%. Code: github.com/cas-lab-munich/sigmarl",
        "updated": "2024-09-18 10:10:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.11852v1"
    },
    {
        "title": "HARP: Human-Assisted Regrouping with Permutation Invariant Critic for Multi-Agent Reinforcement Learning",
        "authors": "Huawen HuEnze ShiChenxi YueShuocun YangZihao WuYiwei LiTianyang ZhongTuo ZhangTianming LiuShu Zhang",
        "links": "http://arxiv.org/abs/2409.11741v1",
        "entry_id": "http://arxiv.org/abs/2409.11741v1",
        "pdf_url": "http://arxiv.org/pdf/2409.11741v1",
        "summary": "Human-in-the-loop reinforcement learning integrates human expertise to\naccelerate agent learning and provide critical guidance and feedback in complex\nfields. However, many existing approaches focus on single-agent tasks and\nrequire continuous human involvement during the training process, significantly\nincreasing the human workload and limiting scalability. In this paper, we\npropose HARP (Human-Assisted Regrouping with Permutation Invariant Critic), a\nmulti-agent reinforcement learning framework designed for group-oriented tasks.\nHARP integrates automatic agent regrouping with strategic human assistance\nduring deployment, enabling and allowing non-experts to offer effective\nguidance with minimal intervention. During training, agents dynamically adjust\ntheir groupings to optimize collaborative task completion. When deployed, they\nactively seek human assistance and utilize the Permutation Invariant Group\nCritic to evaluate and refine human-proposed groupings, allowing non-expert\nusers to contribute valuable suggestions. In multiple collaboration scenarios,\nour approach is able to leverage limited guidance from non-experts and enhance\nperformance. The project can be found at https://github.com/huawen-hu/HARP.",
        "updated": "2024-09-18 06:54:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.11741v1"
    },
    {
        "title": "Multi-robot connection towards collective obstacle field traversal",
        "authors": "Haodi HuXingjue LiaoWuhao DuFeifei Qian",
        "links": "http://arxiv.org/abs/2409.11709v1",
        "entry_id": "http://arxiv.org/abs/2409.11709v1",
        "pdf_url": "http://arxiv.org/pdf/2409.11709v1",
        "summary": "Environments with large terrain height variations present great challenges\nfor legged robot locomotion. Drawing inspiration from fire ants' collective\nassembly behavior, we study strategies that can enable two ``connectable''\nrobots to collectively navigate over bumpy terrains with height variations\nlarger than robot leg length. Each robot was designed to be extremely simple,\nwith a cubical body and one rotary motor actuating four vertical peg legs that\nmove in pairs. Two or more robots could physically connect to one another to\nenhance collective mobility. We performed locomotion experiments with a\ntwo-robot group, across an obstacle field filled with uniformly-distributed\nsemi-spherical ``boulders''. Experimentally-measured robot speed suggested that\nthe connection length between the robots has a significant effect on collective\nmobility: connection length C in [0.86, 0.9] robot unit body length (UBL) were\nable to produce sustainable movements across the obstacle field, whereas\nconnection length C in [0.63, 0.84] and [0.92, 1.1] UBL resulted in low\ntraversability. An energy landscape based model revealed the underlying\nmechanism of how connection length modulated collective mobility through the\nsystem's potential energy landscape, and informed adaptation strategies for the\ntwo-robot system to adapt their connection length for traversing obstacle\nfields with varying spatial frequencies. Our results demonstrated that by\nvarying the connection configuration between the robots, the two-robot system\ncould leverage mechanical intelligence to better utilize obstacle interaction\nforces and produce improved locomotion. Going forward, we envision that\ngeneralized principles of robot-environment coupling can inform design and\ncontrol strategies for a large group of small robots to achieve ant-like\ncollective environment negotiation.",
        "updated": "2024-09-18 05:30:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.11709v1"
    },
    {
        "title": "Hypergraph-based Motion Generation with Multi-modal Interaction Relational Reasoning",
        "authors": "Keshu WuYang ZhouHaotian ShiDominique LordBin RanXinyue Ye",
        "links": "http://arxiv.org/abs/2409.11676v1",
        "entry_id": "http://arxiv.org/abs/2409.11676v1",
        "pdf_url": "http://arxiv.org/pdf/2409.11676v1",
        "summary": "The intricate nature of real-world driving environments, characterized by\ndynamic and diverse interactions among multiple vehicles and their possible\nfuture states, presents considerable challenges in accurately predicting the\nmotion states of vehicles and handling the uncertainty inherent in the\npredictions. Addressing these challenges requires comprehensive modeling and\nreasoning to capture the implicit relations among vehicles and the\ncorresponding diverse behaviors. This research introduces an integrated\nframework for autonomous vehicles (AVs) motion prediction to address these\ncomplexities, utilizing a novel Relational Hypergraph Interaction-informed\nNeural mOtion generator (RHINO). RHINO leverages hypergraph-based relational\nreasoning by integrating a multi-scale hypergraph neural network to model\ngroup-wise interactions among multiple vehicles and their multi-modal driving\nbehaviors, thereby enhancing motion prediction accuracy and reliability.\nExperimental validation using real-world datasets demonstrates the superior\nperformance of this framework in improving predictive accuracy and fostering\nsocially aware automated driving in dynamic traffic scenarios.",
        "updated": "2024-09-18 03:30:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.11676v1"
    }
]