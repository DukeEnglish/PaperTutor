V2A-Mark: Versatile Deep Visual-Audio Watermarking for
Manipulation Localization and Copyright Protection
XuanyuZhang1,2,YouminXu1,RunyiLi1,JiwenYu1,WeiqiLi1,ZhipeiXu1,JianZhang1,2(cid:66)
1 SchoolofElectronicandComputerEngineering,PekingUniversity
2 PekingUniversityShenzhenGraduateSchool-RabbitpreAIGCJointResearchLaboratory
Video Frame Audio Video Frame Audio
(a)
(b)
(c)
(d)
2
Figure1:TwoapplicationinstancesofV A-Mark.(a):Originalvideo,(b):Watermarkedvideo,(c)Tamperedvideo,(d)Tampered
2
visualareasandaudioperiod.Weproposeaversatiledeepvisual-audioproactiveforensicsframework,dubbedV A-Mark.Our
methodcanembedaninvisiblecross-modalwatermarkintotheoriginalvideoframesandaudio(a),producingwatermarked
videoframesandaudio(b).Iftheyaretamperedbyobjectremoval,copy-and-paste,oranyeditingmethodsduringnetwork
transmission(c),wecanaccuratelygetthepredictedvisualtamperedareas,audiotamperedperiods,andthecopyright(d).
ABSTRACT KEYWORDS
AI-generatedvideohasrevolutionizedshortvideoproduction,film- ManipulationLocalization,CopyrightProtection,Watermarking
making,andpersonalizedmedia,makingvideolocaleditingan
essentialtool.However,thisprogressalsoblursthelinebetween 1 INTRODUCTION
realityandfiction,posingchallengesinmultimediaforensics.To 2024isregardedasaboomyearofAI-generatedvideo.Benefited
solvethisurgentissue,V2A-Markisproposedtoaddressthelimi-
fromdiffusionmodelsandtheinfluxofextensivevideodata,alarge
tationsofcurrentvideotamperingforensics,suchaspoorgeneral- amountofvideogenerationmodelsandeditingmethods[3,7,10,
izability,singularfunction,andsinglemodalityfocus.Combining 12,23,42,43,57]haveemerged,offeringconvenienceinthepro-
thefragilityofvideo-into-videosteganographywithdeeprobust ductionofshortvideos,film-making,advertising,andcustomized
watermarking,ourmethodcanembedinvisiblevisual-audiolocal- media. Specifically, local editing [41, 58, 61] has become a vital
izationwatermarksandcopyrightwatermarksintotheoriginal featureofAIvideogenerationtools.Forinstance,AIdubbingsoft-
videoframesandaudio,enablingprecisemanipulationlocalization ware,capableofalteringthefacialexpressions,lipmovements,and
andcopyrightprotection.Wealsodesignatemporalalignmentand voicesofcharactersinavideo,isextensivelyusedinsimultaneous
fusionmoduleanddegradationpromptlearningtoenhancethe interpretationandmoviedubbing.However,thispowerfulediting
localizationaccuracyanddecodingrobustness.Meanwhile,wein- capability is a double-edged sword. It not only facilitates video
troduceasample-levelaudiolocalizationmethodandacross-modal editorsandcreatorsbutalsoblurstheboundariesbetweenreality
copyrightextractionmechanismtocoupletheinformationofaudio andforgery,posingnewchallengesfortamperforensics.Therefore,
andvideoframes.TheeffectivenessofV2A-Markhasbeenverified
itisurgenttodevelopamethodforvisual-audiotamperlocaliza-
onavisual-audiotamperingdataset,emphasizingitssuperiority tionandcopyrightprotection,whichcanbewidelyusedincourt
inlocalizationprecisionandcopyrightaccuracy,crucialforthe evidence,rumorverification,andbeyond.
sustainabledevelopmentofvideoeditingintheAIGCvideoera. Mostvisual-audiomanipulationlocalizationmethods[28,29,33,
37,47,56]arepassive,whichmainlyrelyonexcavatingthetempo-
ralandspatialanomaloustracesfromthesuspectvideosthemselves
topredicttamperedregions.However,thesemethodsoftenprove
CCSCONCEPTS ineffectiveagainstAIGC-basedvideotampering,whichexhibits
•Computingmethodologies→Computervision. fewerartifactsandmorerealistictexturedetails.Additionally,most
4202
rpA
52
]VC.sc[
1v42861.4042:viXraZhangetal.
passiveblack-boxlocalizationnetworkstypicallyrequiretheintro- generalizationabilities,andcopyrightprecisionwithoutanylabeled
ductionofspecifictypesofmanipulationduringtraining,rendering dataoradditionaltrainingrequiredforspecifictamperingtypes.
themineffectiveagainstpreviouslyunseeneditingmethods.There-
fore,thesemethodshaveobviousshortcomingsingeneralization
2 RELATEDWORKS
abilityandaccuracyofmanipulationlocalization.
Giventheinherentdrawbacksofpassivedetectionandlocaliza- 2.1 ManipulationLocalization
tion,visual-audiowatermarkinghasbecomeaconsensustechnol- Prevalentimageforensictechniqueshavefocusedonlocalizingspe-
ogyforproactiveforensics.However,existingvideowatermarking cifictypesofmanipulationsviaexploringartifactsandanomalies
methodsarefraughtwithsomeissues.1)PoorAccuracy:Although intamperedimages[6,14,20,22,24,29,44,48,50,54–56].Recently,
traditionalfragilewatermarkingmethods[13,26]canachieveblock- HiFi-Net[11]usedmulti-branchfeatureextractorandlocalization
wisemanipulationlocationviahashverification,theiraccuracyis modulesforAIGC-synthesizedandeditedimages.SAFL-Net[44]
unsatisfactoryanddifficulttoreachthepixel-wiselocalization.2) designedafeatureextractionapproachtolearnsemantic-agnostic
SingularFunction:Videomanipulationlocalizationandcopyright featureswithspecificmodulesandauxiliarytasks.IML-ViT[33]
protectiontendtobetreatedastwodistinctandseparatetasks.Tam- firstlyintroducedvisiontransformerforimagemanipulationlo-
peringforensicmethodslackthecapabilityforcopyrightprotection, calizationandmodifiedViTcomponentstoaddressthreeunique
limitingtheapplicativevalueoftheirpredictionresults.Simultane- challengesinhighresolution,multi-scale,andedgesupervision.
ously,robustdeepvideowatermarkingmethods[31,60]canonly MaLP[2]introducedalargenumberofforgeryimagestolearn
providecopyrightprotectionandareunabletopreciselypinpoint thematchedtemplateandlocalizationnetwork.Targetedatvideo
thelocationsoftamperingwithinvideos.3)SingleModality:Most tamperlocalization,[47]exploitedthespatialandtemporaltraces
currentforensicmethodsoftenonlyfocusonasinglevisual[62]or leftbyinpaintingandguidedtheextractionofinter-frameresid-
audiomodality[40]andhavenotestablishedeffectivecross-modal ualwithoptical-flow-basedframealignment.UVL[37]designeda
interactionmechanisms.Howtoeffectivelyutilizecross-modalin- novelhybridmulti-stagearchitecturethatcombinesCNNsandViTs
formationformanipulationlocalizationandcross-verificationof toeffectivelycapturebothlocalandglobalvideofeatures.However,
copyrightsisanurgentissue. theabove-mentionedpassivelocalizationmethodsareoftenlimited
Toaddresstheabove-mentionedissues,weproposeaninno- intermsofgeneralizationandlocalizationaccuracy,whichusually
vativemulti-functionalandmulti-modalwatermarkingmethod, workonknowntamperingtypesthathavebeentrained.
dubbedV2A-Mark.Inthevisualsection,integratingthefragility
ofvideo-into-videosteganographyandtherobustnessofbit-into-
videowatermarking,wesimultaneouslyembedbothlocalization 2.2 VideoWatermarkingandSteganography
andcopyrightwatermarksintothevideoframes,enablingthede- Videowatermarkingisawidelyacceptedforensicmethod,which
codingnetworktoindependentlyextracttamperedareasandcopy- canbebroadlyutilizedfortheverification,authenticity,andtrace-
rightinformation.Intheaudiosection,weinsertaversatilewater- abilityofimages.Intermsofrobustnesslevelsforextraction,video
markintothehostaudioanduseittoassistinthereconstruction watermarkingcanbedividedintofragileandrobustwatermark-
ofvisualcopyrightinformation,whileidentifyingthetampered ing[21,53,62].Althoughclassicalfragilewatermarking[13,15,18,
periodsintheaudio.Thus,ourcontributionsareasfollows. 26,27,35,36,45]canachieveblock-wisetamperlocalization,their
❑(1)Wedesignaninnovativedeepversatile,cross-modalvideo localizationaccuracyandflexibilityareunsatisfactory.Therefore,
watermarking framework, dubbed V2 A-Mark, for visual-audio howtorealizejointpixel-leveltamperlocalizationandcopyright
manipulationlocalizationandcopyrightprotection.Itcanembed protectionhasstillalotofroomforresearch.
invisiblelocalizationandcopyrightwatermarksintovideoframes Thanks to the development of deep learning, learning-based
andaudiosamplessimultaneously,andthenobtainvisualtampered videowatermarkinghasattractedincreasedattention.Fordeep
area,audiotamperedperiod,andexactcopyrightinformationin robustvideowatermarking,anintuitiveapproachistoapplyimage
thedecodingend. watermarkingmethods[16,32,63]framebyframe.Forinstance,
HiDDeN[63]firstlydesignedadeepencoder-decodernetworkto
❑(2)Inthevisualsection,wedevelopatemporalalignmentand
hideandrecoverbitstream.Moreover,manydifferentiabledistor-
fusionmodule(TAFM)andadegradationpromptlearning
tionlayerssuchasJPEGcompression,screen-shooting,andface
(DPL)mechanism,enablingthenetworktofullyleveragetemporal
swaping[1,8,30,49]wereincorporatedtoenhancetherobust-
informationforhigh-fidelityconcealmentandrobustpredictionof
nessoftheencoder-decoderwatermarkingframework.Meanwhile,
localizationandcopyrightresults.
CIN[32]andFIN[9]utilizedflow-basedmodelstofurtherimprove
❑(3)Intheaudiosection,weembedsample-levelversatilewa- thefidelityofcontainerimages.However,thesedeepwatermarking
termarksintothepristineaudiotoidentifythetamperedsamples methodshaveasingularfunctionandcannotaccuratelylocalize
andextractthecopyrightinformation.Furthermore,across-modal thetamperedareas.Moreover,thereareotherexplorationstoad-
extractionmechanismisproposedtoobtainthefinalcopyright dressvideodegradationandtemporalcorrelations.Forinstance,
fromtheinformationofaudioandvideoframes. DVMark[31]usedanend-to-endtrainablemulti-scalenetwork
❑(4)Theeffectivenessofourmethodhasbeenverifiedonour for robustwatermark embedding andextractionacross various
constructedvisual-audiotamperingdataset.Comparedtoother spatial-temporalclues.REVMark[60]focusedonimprovingthe
approaches,ourmethodhasnotablemeritsinlocalizationaccuracy, robustnessagainstH.264/AVCcompressionviathetemporalalign-
mentmoduleandDiffH264distortionlayer.LF-VSN[34]utilizedV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
Pre-defined
watermark
Visual Localization Visual Tamper
Watermarking Visual Locator
Tampering
0 0 1 …0 0 0 1 V Wisu aa tl e rC mop ay rkri ig nh gt Degradation Visu Ea xl t C rao cp ty or right 0 0 1 …0 0 0 1
Audio Versatile Audio Audio Versatile
Watermarking Tampering Decoding
Figure2:OverallFrameworkofourproposedV2A-Mark.Weembedpre-definedvisuallocalizationwatermarkW𝑙𝑜𝑐,copyright
watermarkw𝑐𝑜𝑝 andaudioversatilewatermarkw𝑐′ 𝑜𝑝 intotheoriginalvideoframesandaudiotoproduceV𝑐𝑜𝑛 andA𝑐𝑜𝑛.If
undergoingmalicioustampering,wecanstillextractexactcopyrightwˆ 𝑐𝑜𝑝,visualtamperedmasksMˆ 𝑣𝑖𝑠 andaudiotampered
periodsmˆ 𝑎𝑢𝑑.Notethatwˆ 𝑐𝑜𝑝 isobtainedviaourcross-modalextractionmechanism,combiningw𝑐𝑎 𝑜𝑝 andw𝑐𝑣 𝑜𝑝.
invertibleblocksandtheredundancypredictionmoduletorealize extractsthetamperedvideomasksMˆ
𝑣𝑖𝑠
andcopyrightinformation
large-capacityandflexiblevideosteganography. w𝑐𝑣 𝑜𝑝.Concurrently,asshowninFig.2,thetamperedperiodsmˆ
𝑎𝑢𝑑
andthecopyrightw𝑐𝑎 𝑜𝑝intheaudiowillbeextractedfromtheaudio
3 METHODS versatiledecodingmodule.Thefinalrestoredcopyrightinformation
3.1 OverallFrameworkofV2 A-Mark ofthevideowˆ 𝑐𝑜𝑝 willbeobtainedviacross-modalcombinationof
w𝑐𝑎
𝑜𝑝
andw𝑐𝑣
𝑜𝑝
(Sec.3.5).Finally,thevisual-audiotamperforensics
Toachievemultimodal,versatile,andproactivemanipulationlocal-
process of V2A-Mark can be categorized into several scenarios,
izationandcopyrightprotection,asshowninFig.2,theproposed
V2A-Markconsistsoftwokeysections,namelythevisualhiding
where∧and∨respectivelydenotethe“element-wiseand”and
“element-wiseor”.
anddecoding(Sec.3.3),andtheaudiohidinganddecoding(Sec.3.4).
Inthevisualhidingsection,wesequentiallyembedpre-defined ❑ (1) wˆ 𝑐𝑜𝑝 (cid:48) w𝑐𝑜𝑝: Suspicious V𝑟𝑒𝑐 was not processed via our
visuallocalizationwatermarksW𝑙𝑜𝑐∈R𝐻×𝑊×𝑇×𝐶 andthecopy- V2A-Mark,andwearealsounabletoascertaintheauthenticityof
rightwatermarkw𝑐𝑜𝑝∈{0,1}𝑘 intotheoriginalvideosequences thecorrespondingaudioA𝑟𝑒𝑐.Theycannotbeusedasevidence.
V𝑜𝑟𝑖∈R𝐻×𝑊×𝑇×𝐶 togetthecontainervideoV𝑐𝑜𝑛∈R𝐻×𝑊×𝑇×𝐶.In ❑(2)wˆ 𝑐𝑜𝑝 ≈w𝑐𝑜𝑝 ∧(Mˆ 𝑣𝑖𝑠 (cid:48)0∨mˆ 𝑎𝑢𝑑 (cid:48)0):SuspiciousV𝑟𝑒𝑐 or
theaudiohidingsection,weaddversatilewatermarkw𝑐′ 𝑜𝑝∈{0,1}𝑛 A𝑟𝑒𝑐 hasundergonetampering,disqualifyingitasvalidevidence.
totheoriginalaudioA𝑜𝑟𝑖∈R𝐿 inasample-levelmannertoobtain ❑(3)wˆ 𝑐𝑜𝑝 ≈w𝑐𝑜𝑝 ∧Mˆ 𝑣𝑖𝑠 ≈0∧mˆ 𝑎𝑢𝑑 ≈0:SuspiciousV𝑟𝑒𝑐 and
theA𝑐𝑜𝑛∈R𝐿.Notethat𝑇 and𝐿denotethenumberofvideoframes A𝑟𝑒𝑐arebothcredibleandhavenotbeentamperedwith.V2A-Mark
andlengthoftheaudio,respectively.“Versatile”meansthatthis ensurestheauthenticityandintegrityofthisvideo.
audiowatermarkinganddecodingmodulecanachieveaudioma-
nipulationlocalizationandcopyrightprotectionatthesametime.
3.2 PreliminariesandMotivations
Moreover,thepotentialimpactsoncontainervideosduringnetwork
PreviousworkEditGuard[59]hasalreadyvalidatedthefeasibility
transmissioncanbedividedintotwotypes,namelymalicioustam-
ofusingthefragilityandlocalityofimage-into-imagesteganogra-
peringandcommondegradation.Thus,thenetworktransmission
pipelineofvideoframesandaudioismodeledasfollows.
phyforproactiveimagetamperlocalization.Specifically,fragility
meansthedamagetothecontainerimageresultsincorrespond-
V𝑟𝑒𝑐 =D𝑣(V𝑐𝑜𝑛 ⊙(1−M)+T𝑣(V𝑐𝑜𝑛)⊙M), (1) ingdamagetotherevealedsecretimage.Localityindicatesthat
damagetothecontainerimageandtherevealedsecretimageis
A𝑟𝑒𝑐 =D𝑎(A𝑐𝑜𝑛 ⊙(1−m)+T𝑎(A𝑐𝑜𝑛)⊙m), (2)
essentiallypixel-levelanddirectlycorrelated.Thesetwoproper-
where T𝑣(·) and T𝑎(·) respectively denote the video and audio tiescanalsobeeffectivelyappliedinproactivevideolocalization.
manipulationfunction.D𝑣(·)andD𝑎(·)respectivelydenotethe Meanwhile,EditGuard[59]adoptsa“sequentialembeddingand
videoandaudiodegradationoperation.M∈R𝐻×𝑊×𝑇 andm∈R𝐿 paralleldecoding”structuretorealizeunitedtamperlocalization
respectivelydenotethetemperedvisualmasksandaudioperiods. andcopyrightprotection.Clearly,onedirectapproachistowa-
UponreceivingthevideoV𝑟𝑒𝑐 andaudioA𝑟𝑒𝑐,weattempttore- termarkeachvideoframeviaEditGuard.However,thismethod
coverthepreviouslyembeddedwatermarksondifferentrobustness overlookstheexploitationoftemporalcorrelation,makingitchal-
levelsandconductcorrespondingforensicsbasedontheextracted lengingtoensuretherobustnessofthereconstructedwatermarks
watermarks.Inthevisualdecodingsection,ourframeworkprecisely andthetemporalconsistencyofthewatermarkedvideos.Therefore,
ladom-ssorC noitcartxEZhangetal.
Video Hiding Module Video Revealing Module
… … … …
DPL
Replicate
DPL
1 0 0 …1 0 0 1 1 0 0 …1 0 0 1
Bit Hiding Module Bit Recovery Module
2
Figure3:DetailsofthenetworkstructureandtrainingprocessoftheproposedV A-Mark.Wedesignthetemporalalignment
andfusionmodule(TAFM)anddegradationpromptlearning(DPL)toenhancetherobustnessandfidelityofourmethod.
thekeyissuesaddressedinthispaperare:1)Howtoutilizethe
auxiliaryinformationfromsupportingframesforwatermarkem-
beddinganddecodinginreferenceframes;2)Howtoimprovethe
robustnessofexistingframeworkstovideodegradation;3)Howto
employthewatermarksembeddedinvideoframesforaudiotamper
DWT DWT
localizationandcopyrightprotection.Toaddresstheaboveissues, s Sigmoid
wedesignthevisualhidingmodule(VHM),visualrevealingmodule T Transpose
(VRM),bithidingmodule(BHM),andbitrecoverymodule(BRM).
Meanwhile,wedesignanefficientcross-modalextractionmecha-
nismandintroducetheadvancedaudioversatilewatermarkingand Norm Norm
decodingmethod[40]toachievecross-modaltamperlocalization
Linear Linear Linear Linear
andcopyrightprotection.
T
3.3 VisualHidingandDecoding T
s s
3.3.1 InputandOutputDesignofVisualSection. Toachieve
memory-efficient hiding and decoding, our V2A-Mark employs
amulti-frameinput,single-frameoutputstructure.Asshownin
Fig.3,thevisualhidingisoperatedgroup-by-groupviaasliding
window,traversingeachvideoframefromheadtotail.Wesetthe
lengthofaslidingwindowto3.Giventheoriginalvideogroup
{I 𝑜(𝑖 𝑟) 𝑖}𝑘 𝑘+ −1 1andlocalizationwatermarkgroup{I 𝑙( 𝑜𝑖 𝑐) }𝑘 𝑘+ −1 1,wefirstly Figure4:Detailsoftheproposedtemporalalignmentand
usetheTAFMtopreprocess{I 𝑜(𝑖 𝑟) 𝑖}𝑘 𝑘+ −1 1andadopt𝑁invertibleblocks fusionmodule(TAFM).ItalignsthesupportingframesI 𝑜(𝑘 𝑟𝑖−1) ,
togenerateI 𝑚(𝑘 𝑒)
𝑑
anditsby-productZ𝑣.Thecopyrightwatermark I 𝑜(𝑘 𝑟𝑖+1) tothereferenceframeI 𝑜(𝑘 𝑟𝑖) .
w𝑐𝑜𝑝 isthenembeddedintoI 𝑚(𝑘 𝑒)
𝑑
viaaU-Net[49],producingthe
final container frame I𝑐( 𝑜𝑘 𝑛). For all video frames, we embed the namelyˆ I 𝑜(𝑘 𝑟𝑖) andˆ I 𝑙( 𝑜𝑘 𝑐).Notethatweintroducelearneddegradation
samecopyrightwatermark.Afternetworktransmission,V2A-Mark promptsP𝑣,P𝑏 invideorevealingandbitrecoverymodulesand
decodeseachreceivedvideoframeI𝑟(𝑘 𝑒𝑐) individually.Ononehand, fusethemwithintrinsicfeaturestofurtherenhancetherobustness
ofourmethodagainstcommonvideoandaudiodegradations.
wˆ 𝑐𝑜𝑝isextractedfromI𝑟(𝑘 𝑒𝑐)viaaU-NetandanMLPextractor.Onthe
otherhand,wereplicateI𝑟(𝑘 𝑒𝑐) threefoldandfeeditintotheresidual 3.3.2 TemporalAlignmentandFusionModule. Tofurther
predictionmodule(RPM)[34]toproducethemissingcomponentZˆ 𝑣. enhancethetemporalconsistencyofthecontainervideos,wede-
Then,𝑁 invertibleblocksandtheTAFMareusedtoreconstructthe signatemporalalignmentandfusionmodule(TAFM)toalignthe
videogroupsandonlyselecttheintermediateframesastheresult, supportingframes{I 𝑜(𝑖 𝑟) 𝑖}𝑖≠𝑘 tothereferenceframeI 𝑜(𝑘 𝑟𝑖).Asshown
TAFM
Embedding
InvBlock-1 InvBlock-n InvBlock-N
Common
Visual
Degradation
RPM Fuse
InvBlock-N InvBlock-n
Fuse
InvBlock-1
Extraction
TAFMV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
averagepooling(GAP)layer,a1×1convolution,andasoftmax
operatortoproduceasetofdynamicweightcoefficientsw𝑣/w𝑏,
Prompt Components whichisinspiredby[39].Thesecoefficientsareusedtofuseeach
degradationprompt,resultingindegradation-enhancedfeatures.
Then,weutilizeconvolutionandconcatenationoperationstofuse
s * ↑ thedegradation-enhancedfeatureswiththefeaturesextractedfrom
RPMortheU-NetinBRM.Notethatwelearnedtwodistinctsets
ofdegradationpromptsforvisualandbitdecoding,sinceweaim
fortheBRMtobeabsolutelyrobustagainstdegradation,whilethe
Globa Pl o oA lv ine grage * ComL bin ie na ar t ion s Softmax ↑ Upsampling VRMshouldretainsomefragilityagainsttampering.
Figure5:Detailsoftheproposeddegradationpromptlearn- 3.4 AudioHidingandDecoding
ingmechanism.ItfusestheintrinsicimagefeaturesF𝑣/F𝑏
Consideringthatvideotamperingisoftenaccompaniedbycorre-
withthelearnablepromptcomponentsP𝑣/P𝑏 adaptively.
spondingchangesintheaudio,wetrytosimultaneouslyidentify
thetamperedareasoftheaudio,andutilizetheextractedaudiocopy-
inFig.4,weresorttobidirectionalcross-attentionmechanismsbe- righttocross-verifythecopyrightinthevideoframe.Toensurethe
tweenthesupportingframesandthereferenceframe.Specifically, correspondencebetweenvideoandaudio,wesettheaudioversatile
wedefinethescaleddotproductionoperationasfollows. copyrightwatermarkw𝑐′
𝑜𝑝
aspartofthecopyrightw𝑐𝑜𝑝 inthe
Attention(Q,K,V)=softmax(cid:16) QK𝑇 /√ 𝐷(cid:17) V, (3) v thid ee fio rf sr ta 1m 6e bs i. tF so or fi wns 𝑐t 𝑜a 𝑝n .c Ie n, sw pi𝑐 r𝑜 e𝑝 di bs ya t3 h2 e- ab dit vw ana cte er dm pa rr ok a, ca tin vd ew ta𝑐′ m𝑜𝑝 peis
r
whereQ∈R𝐻×𝑊×𝐷 isthequerymatrixprojectedbythereference localizationtoolAudioseal[40],weintroduceanaudiowatermark
frameI(𝑘),andK,V∈R𝐻×𝑊×𝐷 arethekeyandvaluematrixpro- generatoranddetectortoachieveaudioversatilewatermarking
𝑜𝑟𝑖 anddecodingshowninFig.2.Specifically,weutilizethewatermark
ducedfromthesupportingframes{I 𝑜(𝑖 𝑟) 𝑖}𝑖≠𝑘.Giventhereference generatortopredictanadditivewatermarkwaveformfromtheau-
featureF𝑟 andthesupportingfeatureF𝑠,theyarefirstlylayernor- dioinputA𝑜𝑟𝑖,anduseadetectortooutputtheprobabilitymˆ
𝑎𝑢𝑑
of
malizedintoF𝑟=Norm(F𝑟)andF𝑠=Norm(F𝑠).Then,weuselinear thepresenceofawatermarkateachsampleofthecontaineraudio
layerstoprojectF𝑟,F𝑠 into𝐷-dimensionembeddingspaceandcal- A𝑐𝑜𝑛.Thedetectoristrainedwithmaskaugmentationstrategyto
culatethecross-attentionmapsbetweenreferenceandsupporting ensureitsaccuracyandrobustness.Meanwhile,weaddamessage
framesasfollows. embeddinglayer[40]inthemiddleofthewatermarkgenerator
F𝑟→𝑠 =Attention(cid:16) W𝑟 1F𝑟,W𝑠 1F𝑠,W𝑠 2F𝑠(cid:17) , (4) t ro obe um stb lyed dew c𝑐′ r𝑜 y𝑝 ptin wto
𝑐𝑎
𝑜A 𝑝,𝑜 w𝑟𝑖. hI in chth we ild le bc eo ud si en dg te on cd o, mth be ind eet wec itt hor ww
𝑐𝑣
𝑜i 𝑝ll
F𝑠→𝑟 =Attention(cid:16) W𝑠 1F𝑠,W𝑟 1F𝑟,W𝑟 2F𝑟(cid:17) , (5) togetthefinalcopyrightwˆ 𝑐𝑜𝑝.
where W𝑟 1, W𝑟 2, W𝑠
1
and W𝑠
2
respectively denote the projection
matrices.Finally,weperformtemporalfusionbetweentherefer- 3.5 TrainingandInferenceDetails
enceframeandsupportingframesviatheresidualconnectionand
Training:Thetrainingprocessofthevisualsectionoftheproposed
concatenationoperation. V2A-Markcanbedividedintotwosteps.Givenanarbitraryoriginal
Fˆ(𝑘) =Concat(𝛾1F𝑠→𝑟 +F𝑟,𝛾2F𝑟→𝑠 +F𝑠), (6) imageI 𝑚(𝑘 𝑒)
𝑑
andwatermarkw𝑐𝑜𝑝,wefirsttrainthebithidingand
where𝛾1and𝛾2respectivelydenotethelearnableparameters.With
recoverymoduleviatheℓ2loss.
o acu hr iT eA viF nM g, mV o2 rA e- eM ffa er ck tic va en cb oe nt cte er ale mxp el no tit at ne dm mpo or ra el rc oo br ure sl ta dti eo cn os d, it nh gu .s ℓ 𝑐𝑜𝑝 =∥I𝑐( 𝑜𝑘 𝑛) −I 𝑚(𝑘 𝑒) 𝑑∥2 2+𝜆∥wˆ 𝑐𝑜𝑝 −w𝑐𝑜𝑝∥2 2, (7)
where𝜆issetto10.Furthermore,wefreezetheweightsofBHM
3.3.3 DegradationPromptLearning. Tofurtherimprovethe andBRMandjointlytraintheVHMandVRM.Givenavideogroup
robustnessofV2A-Markindecodingbothvisuallocalizationand {I(𝑖) }𝑘+1,localizationwatermarkgroup{I(𝑖) }𝑘+1 andcopyright
copyrightwatermarks,weembedlearnabledegradationprompts 𝑜𝑟𝑖 𝑘−1 𝑙𝑜𝑐 𝑘−1
P𝑣∈Rℎ1×𝑤1×𝑐1×𝑒1,P𝑏∈Rℎ2×𝑤2×𝑐2×𝑒2 intofeaturesofthebitrecov-
watermarkw𝑐𝑜𝑝,thelossis:
eryandvideorevealingmodules,where𝑐1,𝑐2respectivelydenote ℓ 𝑙𝑜𝑐 =∥ˆ I 𝑜(𝑘 𝑟𝑖) −I 𝑜(𝑘 𝑟𝑖) ∥1+𝛼∥I𝑐( 𝑜𝑘 𝑛) −I 𝑜(𝑘 𝑟𝑖) ∥2 2+𝛽∥ˆ I 𝑙( 𝑜𝑘 𝑐) −I 𝑙( 𝑜𝑘 𝑐) ∥1, (8)
thechannelsofprompt,𝑒1,𝑒2respectivelydenotethenumberof
where𝛼and𝛽arerespectivelysetto100and1.Intheaudiosection,
degradation prompt. The degradation prompt pool comprises a
weuseapre-trainedaudiowatermarkingtool[40]torealizeaudio
seriesoflearnableembeddings,witheachcorrespondingtoatype
hidinganddecoding.
o of fp tho ete Rnt Pi Mald ineg tr ha eda vt ii do en o.S ru ep vp eo als ii nn gg mth oa dt uF l𝑣 ea an nd dF t𝑏 ha ere U-th Ne etou intp tu ht es Inference:AsshowninFig.2and3,wecanconductforensics
viathepre-trainedcomponents.Toextracttamperedmasks,we
bit recovery module in Fig. 3 respectively, we utilize a channel
attentionmechanism(asshowninFig.5)tobetterencouragethe
comparethepre-definedwatermarkW𝑙𝑜𝑐 withthedecodedone
interactionbetweentheinputfeaturesF𝑣/F𝑏 andthedegradation
Wˆ
𝑙𝑜𝑐
toobtainabinarymaskMˆ 𝑣𝑖𝑠∈R𝐻×𝑊×𝑇:
promptP𝑣/P𝑏.Specifically,thefeaturesF𝑣/F𝑏arepassedtoaglobal Mˆ 𝑣𝑖𝑠[𝑖,𝑗,𝑡] =𝜃 𝜏(max(|Wˆ 𝑙𝑜𝑐[𝑖,𝑗,𝑡,:]−W𝑙𝑜𝑐[𝑖,𝑗,𝑡,:]|)), (9)
PAG
PAG vnoC vnoCZhangetal.
ProPainter[61] E2FGVI[25] VideoSlicing
Method
F1-Score AUC IoU BA(%) F1-Score AUC IoU BA(%) F1-Score AUC IoU BA(%)
OSN[48] 0.164 0.404 0.125 - 0.170 0.410 0.126 - 0.382 0.830 0.262 -
PSCC-Net[28] 0.275 0.757 0.186 - 0.273 0.742 0.174 - 0.559 0.876 0.419 -
HiFi-Net[11] 0.517 0.699 0.123 - 0.573 0.763 0.198 - 0.668 0.906 0.347 -
IML-ViT[33] 0.174 0.521 0.112 - 0.162 0.516 0.107 - 0.137 0.509 0.098 -
EditGuard[59] 0.924 0.950 0.866 99.41 0.923 0.950 0.865 99.43 0.922 0.949 0.861 99.73
V2A-Mark(Ours)
0.944 0.990 0.897 99.73 0.943 0.981 0.895 99.61 0.941 0.972 0.891 99.76
Table1:ComparisonwithothercompetitivetamperforensicsmethodsunderdifferentAIGC-basedvideoeditingmethods,such
2
asProPainter,E FGVI,andnaiveslicing.Clearly,ourmethodachievesthebestlocalizationandcopyrightrestorationaccuracy.
where𝑖 ∈ [0,𝐻),𝑗 ∈ [0,𝑊)and𝑡 ∈ [0,𝑇).𝜃 𝜏(𝑧)=1(𝑧 ≥𝜏).𝜏isset
Method Message PSNR(dB) SSIM NIQE(↓)
to0.2.|·|isanabsolutevalueoperation.Theaudiotamperedperiod
MBRS[16] 30bits 26.57 0.908 6.473
m pˆ r𝑎 e𝑢 c𝑑 iseis vd isir ue ac lt cly ope yxt rr igac ht te ,d wv ei ca ot nh de ua cu td bi io twve isr esa vt oil te ind gec oo nd te hr e.T coo pe yx rt ir ga hc tt CIN[32] 30bits 42.41 0.983 5.858
PIMoG[8] 30bits 37.71 0.971 8.129
extractedfromeachframeandselectthemostfrequentlyoccurring
0or1asthefinalresultw𝑐𝑣 𝑜𝑝.Meanwhile,weextractaudiocopy- SepMark[49] 30bits 34.86 0.914 5.321
HiNet[17] animage 36.46 0.940 6.271
rightw𝑐𝑎 𝑜𝑝∈{0,1}𝑛 anduseittocross-verifywithw𝑐𝑣 𝑜𝑝∈{0,1}𝑘,
LF-VSN[34] animage 39.93 0.967 3.827
gettingthefinalresultwˆ 𝑐𝑜𝑝∈{0,1}𝑘.Consideringthattheaudio
EditGuard[59] animage 38.53 0.977 4.919
copyrightwatermarkcanoftenbeextractedmorerobustlyand V2A-Mark animage 40.83 0.983 3.484
isnoteasilydestroyed,wedirectlyuseitasthefirst𝑛bitsinthe
finalmultimediacopyrightwˆ 𝑐𝑜𝑝,whichtypicallyrepresentsthe Table2:Thecomparisonswithotherwatermarkingmethods
ownershipoftheentiremultimediaasset.Theremaining𝑘−𝑛bits onthevisualqualityofthecontainervideoV𝑐𝑜𝑛.
aretakenfromtheextractedvisualwatermarkw𝑐𝑣 𝑜𝑝,whichwillbe
relyonimage-basedtamperlocalizationmethodsonaframe-by-
relatedtotheinformationofvideoframessuchasresolution,time frameprediction.Forvisualtamperlocalization,F1-score,AUC,
length,andframerate.Thecross-modalextractionprocessis: andIoUareusedtoevaluatelocalizationaccuracy.Forcopyright
wˆ𝑐𝑜𝑝 =Concat(w𝑐𝑎 𝑜𝑝,w𝑐𝑣 𝑜𝑝[𝑛:]). (10) protection,bitaccuracy(BA)isusedtoassessthecopyrightrecov-
eryperformance.WeusetwoSOTAdeepvideoinpaintingmethods,
4 EXPERIMENTS
ProPainter[61]andE2FGVI[25],andanaiveslicingapproachto
simulatemalicioustampering.
4.1 ImplementationDetails AsreportedinTab.1,ourV2A-Markachievesimpressivelocal-
WetrainedourV2A-MarkintheVimeo-90K[52]withoutany
izationperformancewithanF1-Scoreofapproximately0.95,an
tampereddata.Wetestourmethodon30testingvideosofDavis AUCof0.99, andanIoUcloseto 0.9.Incontrast, otherpassive
dataset[38].Allvideoframeshavearesolutionof448×256andcon- localizationmethods,whichrelysolelyontamperedvideoclues,
sistof50to100frames.Tosynthesizeaudio,wemanuallyextract performpoorlyinlocalizingunseentypesofmanipulation.Fur-
thevideocaptionsandusethemaspromptswiththeVALLE-E-X thermore,whenusingEditGuardtowatermarkeachvideoframe,
audiosynthesistool[46].TheAdam[19]isusedfortraining250𝐾 althoughitachievessatisfactorylocalizationresults,itfallsshortin
iterationswith𝛽1=0.9and𝛽2=0.5.Thelearningrateisinitialized effectivelyutilizingtemporalinformation.Consequently,theIoU
to 1×10−4 and decreases by half for every 30𝐾 iterations, with ofthepredictedmasksinvarioustamperingmethodsisgenerally
thebatchsizesetto8.𝑁 inVideohidingandrevealingmodule about0.03lowerthanthatachievedbyourV2A-Mark.Additionally,
issetto16.TheshapeoftwodegradationpromptsP𝑣 andP𝑏 are our V2A-Mark achieves an over 99.5% bit accuracy across vari-
36×36×72×2and36×36×16×6.Weembed32-bitcopyrightwater- oustamperingmethods,whichisalsomarginallyhigherthanthat
marksw𝑐𝑜𝑝 andpurebluevisuallocalizationwatermarksW𝑙𝑜𝑐 ofEditGuard.Furthermore,asshowninFig.6,ourmethodhas
tooriginalvideos.Weusereplicationpaddingtoprocessthefirst veryobviousadvantagesoverSOTApassivelocalizationmethod
andlastframeoftheoriginalvideo.Meanwhile,wealsoembeda PSCC-Net[28],whichcanbeattributedtoourproactivetamper
versatilewatermarkw𝑐′ 𝑜𝑝 intotheoriginalaudio. localizationmechanism.Meanwhile,sinceweadoptedamoreef-
fectivetemporalalignmentandfusionmethod,wefoundthatin
4.2 ComparisonwithVisualTamper somesceneswhereEditGuardcanonlylocatetheroughoutline
LocalizationMethods ofthetamperingarea,ourV2A-Markcanstillclearlypredictthe
Toevaluatethevisuallocalizationandcopyrightrecoveryaccu- tamperedtraces.
racy,wecomparedourmethodwithsomeSOTApassivemethods
OSN[48],PSCC-Net[28],HiFi-Net[11],IML-ViT[33]andaproac- 4.3 ComparisonwithWatermarkingMethods
tiveforensicsmethodEditGuard[59].Despitepreviousresearchon To evaluate the visual quality of V𝑐𝑜𝑛, we compared our V2A-
videotamperlocalization[37],wecannotfindmethodswithpub- Markwithotherwatermarkingmethodson30testingvideosfrom
liclyavailablecode.Therefore,ourcomparativemethodsprimarily DAVIS[38].Forafaircomparison,wealsoretrainedourEditGuardV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
2
Figure6:LocalizationaccuracycomparisonwithourV A-MarkandotherlocalizationmethodsPSCC-Net[28],EditGuard[59].
Ourmethodcanpredictmoreaccurateandclearertamperedmasks.Wealsopresentourcontainerandtamperedvideos.
on448×256originalvideosand32bits.Ourcomparisonmethods ROC curve
includetheSOTAbit-hidingwatermarkingmethod[8,16,32,49], 1.0
large-capacitysteganographymethod[17,34],andaversatileimage
watermarkingmethod[59].AsshowninTab.2,thePSNRandSSIM 0.8
ofourcontainervideosfaroutperformmostwatermarkingmeth-
odssuchasMBRS,PIMoG,andSepMark,butiscloseorslightly
0.6
inferiortoCIN.Notethatthesemethodsonlyhide30bitsinthe
videos,butourV2A-MarkhidesbothanRGBimageand32bits.
0.4
Comparedwithhigh-capacitysteganographymethodsEditGuard, EditGuard
LF-VSN,andHiNet,ourmethodalsohasclearadvantagesinvisual LF-VSN
quality.Meanwhile,theperceptualquality(NIQE)ofourwater- 0.2 HiNet
V2A-Mark(Ours)
markedvideossurpassesallothermethods.Toverifythesecurityof
Reference
ourmethod,weperformanti-steganographydetectionviaStegEx- 0.0
0.0 0.2 0.4 0.6 0.8 1.0
pose[4]oncontainervideosofvarioussteganographymethods.
False Positive Rate
Allthemethodsconcealedpurebluevideosintotheoriginalvideos.
Figure7:ROCcurveofdifferentmethodsunderStegExpose.
Notethatthedetectionsetisbuiltbymixingcontainerandorig-
Thecloserthecurveistothereferencecentralaxis(which
inalvideoframeswithequalproportions.Wevarythedetection
meansrandomguess),themethodisbetterinsecurity.
thresholdsinawiderangeinStegExpose[4]anddrawtheROC
curveinFig.7.Theidealcaserepresentsthatthedetectorhasa50%
probabilityofdetectingcontainervideosfromanequallymixed
ofthetamperedaream.WeobservedfromTab.3thatthewater-
detectiontest,thesameasarandomguess.Evidently,thesecurity
markedaudiomaintainshighSNR/PESQon28.29dB/4.50with
of our method exhibits a significant advantage compared to all
theoriginalaudio,indicatingthatourV2A-Markhaslittleimpact
competitivemethods.
onthesemanticfidelityoftheaudio.Meanwhile,ourmethodcan
accuratelylocalizethetamperedareaswith99.63%AUCandobtain
4.4 AudioTamperLocalization
100%bitaccuracyunder“Clean”degradation,whichshowsthat
ToevaluatetheaccuracyofV2A-Markforaudiotamperlocalization, ouraudiolocalizationwatermarkissensitiveenoughtomalicious
werandomlyinsert1s-2stamperedaudiointoourconstructed30 tampering.Furthermore,weadopttwoclassicaldegradationson
originalaudio.SNRandPESQareusedtoevaluatethequantitative thecontaineraudioA𝑐𝑜𝑛,namelyResampleandLowpass.“Resam-
andperceptualqualityofwatermarkedaudio.Bitaccuracyisused ple”denotesresamplingthecontaineraudioata90%samplingrate
toevaluatethebiterrorrateofthepre-definedw𝑐′
𝑜𝑝
andextracted (16000Hz→14400Hz).“Lowpass”meansapplyinglow-passfilterto
w𝑐𝑎 𝑜𝑝.AUCisusedtocalculatethelocalizationaccuracybetween containeraudioA𝑐𝑜𝑛,cuttingfrequenciesaboveacutofffrequency
thepredictedaudiotamperedperiodm𝑎𝑢𝑑 andthegroundtruth (1000Hz).AsplottedinTab.3,althoughthecontaineraudioA𝑐𝑜𝑛
lanigirO
reniatnoC
derepmaT
teN-CCSP
drauGtidE
sruO
TG
etaR
evitisoP
eurTZhangetal.
Degradation SNR(dB) PESQ(↑) Bit.Acc. AUC Case DegradationD𝑣(·) TAFM DPL F1 AUC IoU BA(%)
Clean 28.29 4.50 100% 99.63% (a) Clean ✘ ✔ 0.935 0.962 0.885 99.47
(b) RandomDegradations ✔ ✘ 0.901 0.961 0.832 98.45
Resample - - 100% 98.58%
Clean ✔ ✔ 0.944 0.990 0.897 99.73
Lowpass - - 99.72% 99.41% Ours
RandomDegradations ✔ ✔ 0.912 0.975 0.849 99.43
Table3:Watermarkedaudioqualityandaudiotamperlo- Table5:AbalationstudiesonthecorepartsofV2 A-Mark.
2
calizationperformanceofourV A-Markundercleanand
differentdegradationscenes.
4.7 Applications
GaussianNoise H.264 OurV2A-Markcanprovidefocusedprotectionforvideosbasedon
Methods Metrics Clean Poisson
𝜎=5 𝜎=10 QP=5 QP=10 user-definedareas.ThisallowsourV2A-Marktoapplytosome
F1 0.924 0.891 0.872 0.900 0.881 0.896
globaltamperingsuchasvisual-audiodeepfake.Specifically,weuse
AUC 0.950 0.945 0.922 0.946 0.941 0.947
EditGuard IoU 0.866 0.835 0.812 0.830 0.828 0.842 EfficientSAM[51]tosegmentthefacialregionsthatneedfocused
BA(%) 99.41 99.01 96.90 95.16 92.23 99.31 protection,andaddlocalizationwatermarksonlytotheseparts,
F1 0.944 0.904 0.900 0.915 0.909 0.913 whilestillembeddingaglobalcopyrightwatermark.Asshownin
V2A-Mark AUC 0.990 0.979 0.963 0.978 0.967 0.980 Fig.8,wemanipulatetheidentityinthecontainervideoframes
IoU 0.897 0.842 0.833 0.858 0.850 0.856
viaSimSwap[5],andalterthefirst0.5softhisaudiofrom"there
BA(%) 99.73 99.35 98.51 99.34 99.18 99.71
aremanyjobsforAmerican"to"therearefewjobsforAmerican."
Table4:Localizationandbitrecoveryperformanceofour Subsequently, our V2A-Mark is capable of effectively detecting
2
V A-MarkandEditGuardunderdifferentdegradations. tamperedareasinthefaceregionaswellasalterationsintheaudio.
Fortheaudioportion,wedeterminewhethereachsamplepoint
hasundergonedifferentdegradations,ourV2A-Markstillmain- hasbeentamperedwithbyevaluatingtheprobabilityofalteration.
tainsover98%localizationaccuracyandnearly100%bitaccuracy,
provingitsrobustnessagainstcommonaudiocorruptions. Video Frame Audio
4.5 RobustnessAnalysis
ToanalyzetherobustnessofourV2A-Mark,wecompareourmethod
withEditGuard,thebestcomparativemethodinthecleancase.We
selectedthreetypesofvideodegradation,includingGaussiannoise,
H.264videocoding,andPoissonnoise.AsreportedinTab.4,we
foundthatourV2A-Markhasonlyslightperformancedegrada-
tionundervariousdegradationscomparedtothecleanscene,and
bothsurpassEditGuardinlocalizationaccuracyandcopyrightre-
construction.Specifically,sinceweuseamulti-frameinput,single-
frameoutputstructure,whichbetterexplorestemporalinformation, Figure8:ApplicationsceneoftheproposedV2 A-Markon
ourmethodperformsbetterinhandlinginter-framedegradation theDeepfaketampering[5].OurV2 A-Markcanaccurately
(suchasH.264videocoding)thanEditGuardwhichaddswater- predictvisualtamperedmasksandthetamperedprobability
marks frame by frame. As reported in Tab. 4, the recovered bit ofaudiosamples.
accuracyofourmethodfarsurpassesEditGuardby4.18%and6.95%
inQP=5andQP=10.Meanwhile,ourV2A-Markalsooutperforms
EditGuardby0.028and0.022inlocalizationaccuracy(IoU),which 5 CONCLUSION
provesitssuperiorityindecodingrobustness. ToaddressthechallengesofAI-generatedvisual-audioforensics,
an innovative deep watermarking method with strong general-
4.6 AblationStudies izability, versatile function, and cross-modal properties dubbed
Toevaluatethecontributionofeachcomponent,wemainlycon- V2A-Markisproposed.Itembedsinvisiblevisual-audiolocalization
ductablationstudiesonthetemporalalignmentandfusionmodule andcopyrightwatermarksintotheoriginalvideoframesandaudio.
(TAFM)anddegradationpromptlearning(DPL).Ourresultsare Ifencounteringmalicioustamperingonvisualoraudioinformation,
reportedonTab.5,where“randomdegradation”denotesthatwe wecangetaccuratetamperedvisualmasks,videocopyright,and
randomlyselectonedegradationfromGaussiannoise,H.264,and tamperedaudioperiodsinthedecodingendviaourV2A-Mark.
Poissonnoise.Comparingcase(a)andoursinthe“clean”scene,it FacingtheimminentexplosivegrowthoftheAIGCvideoindus-
demonstratesthattheproposedTAFMcanenhancethelocaliza- try,ourV2A-Markhasthepotentialtosafeguardthesustainable
tionaccuracyandachieve0.012gainsinIoU,whichprovesthat developmentoftheAIGCindustry,andalsoestablishacleanand
theproposedTAFMcanboostthetemporalinteractionandrealize transparentinformationenvironment.
effectivetemporalalignment.Comparingcase(b)andoursinthe Limitations:Sincethereisacertaincontradictionbetweenthe
“randomdegradation”scene,duetothelearneddegradationrepre- fidelityandrobustnessofvideowatermarking,wearestillcom-
sentations,wefindthatourmethodachievessignificantgainson mittedtodesigningadvancedmodulestoachievebettertradeoff.
localizationaccuracyandcopyrightprecision. Additionally,astherearefewvideodiffusion-basededitingmethods
lanigirO
reniatnoC
derepmaT
tluseR
TamperedV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
available,wehavenotconductedexperimentsonlargervideoedit- conferenceoncomputervisionandpatternrecognition.
ingmodels.However,webelieveourmethodisrobustandeffective [22] HaodongLiandJiwuHuang.2019.Localizationofdeepinpaintingusinghigh-
againstallformsoflocalvisual-audiomanipulation.
passfullyconvolutionalnetwork.InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision(ICCV).
[23] WeiqiLi,BinChen,andJianZhang.2022.D3c2-net:Dual-domaindeepconvolu-
REFERENCES
tionalcodingnetworkforcompressivesensing.arXivpreprintarXiv:2207.13560
(2022).
[1] MahdiAhmadi,AlirezaNorouzi,NaderKarimi,ShadrokhSamavi,andAliEmami. [24] YueLi,DongLiu,HouqiangLi,LiLi,ZhuLi,andFengWu.2018. Learninga
2020.ReDMark:Frameworkforresidualdiffusionwatermarkingbasedondeep convolutionalneuralnetworkforimagecompact-resolution.IEEETransactions
networks.ExpertSystemswithApplications146(2020),113157. onImageProcessing28,3(2018),1092–1107.
[2] VishalAsnani,XiYin,TalHassner,andXiaomingLiu.2023.Malp:Manipulation [25] ZhenLi,Cheng-ZeLu,JianhuaQin,Chun-LeGuo,andMing-MingCheng.2022.
localizationusingaproactivescheme.InProceedingsoftheIEEE/CVFConference Towardsanend-to-endframeworkforflow-guidedvideoinpainting.InPro-
onComputerVisionandPatternRecognition(CVPR). ceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.
[3] AndreasBlattmann,TimDockhorn,SumithKulal,DanielMendelevitch,Maciej 17562–17571.
Kilian,DominikLorenz,YamLevi,ZionEnglish,VikramVoleti,AdamLetts, [26] Siau-ChuinLiew,Siau-WayLiew,andJasniMohdZain.2013.Tamperlocaliza-
etal.2023.Stablevideodiffusion:Scalinglatentvideodiffusionmodelstolarge tionandlosslessrecoverywatermarkingschemewithROIsegmentationand
datasets.arXivpreprintarXiv:2311.15127(2023). multilevelauthentication.Journalofdigitalimaging26(2013),316–325.
[4] BenediktBoehm.2014. Stegexpose-AtoolfordetectingLSBsteganography. [27] Chia-ChenLin,Ting-LinLee,Ya-FenChang,Pei-FengShiu,andBohanZhang.
arXivpreprintarXiv:1410.6656(2014). 2023.FragileWatermarkingforTamperLocalizationandSelf-RecoveryBased
[5] RenwangChen,XuanhongChen,BingbingNi,andYanhaoGe.2020.Simswap: onAMBTCandVQ.Electronics12,2(2023),415.
Anefficientframeworkforhighfidelityfaceswapping.InProceedingsofthe28th [28] XiaohongLiu,YaojieLiu,JunChen,andXiaomingLiu.2022. PSCC-Net:Pro-
ACMinternationalconferenceonmultimedia.2003–2011. gressivespatio-channelcorrelationnetworkforimagemanipulationdetection
[6] XinruChen,ChengboDong,JiaqiJi,JuanCao,andXirongLi.2021. Image andlocalization.IEEETransactionsonCircuitsandSystemsforVideoTechnology
manipulationdetectionbymulti-viewmulti-scalesupervision.InProceedingsof 32,11(2022),7505–7517.
theIEEE/CVFInternationalConferenceonComputerVision(ICCV). [29] XuntaoLiu,YuzhouYang,QichaoYing,ZhenxingQian,XinpengZhang,and
[7] PatrickEsser,JohnathanChiu,ParmidaAtighehchian,JonathanGranskog,and ShengLi.2024.PROMPT-IML:ImageManipulationLocalizationwithPre-trained
AnastasisGermanidis.2023.Structureandcontent-guidedvideosynthesiswith FoundationModelsThroughPromptTuning. arXivpreprintarXiv:2401.00653
diffusionmodels.InProceedingsoftheIEEE/CVFInternationalConferenceon (2024).
ComputerVision.7346–7356. [30] YangLiu,MengxiGuo,JianZhang,YueshengZhu,andXiaodongXie.2019.
[8] HanFang,ZhaoyangJia,ZehuaMa,Ee-ChienChang,andWeimingZhang.2022. Anoveltwo-stageseparabledeeplearningframeworkforpracticalblindwa-
PIMoG:Aneffectivescreen-shootingnoise-layersimulationfordeep-learning- termarking.InProceedingsoftheACMInternationalConferenceonMultimedia
basedwatermarkingnetwork.InProceedingsofthe30thACMInternationalCon- (MM).
ferenceonMultimedia(MM). [31] XiyangLuo,YinxiaoLi,HuiwenChang,CeLiu,PeymanMilanfar,andFengYang.
[9] HanFang,YupengQiu,KejiangChen,JiyiZhang,WeimingZhang,andEe- 2023. DVMark:adeepmultiscaleframeworkforvideowatermarking. IEEE
ChienChang.2023.Flow-basedrobustwatermarkingwithinvertiblenoiselayer TransactionsonImageProcessing(2023).
forblack-boxdistortions.InProceedingsoftheAAAIConferenceonArtificial [32] RuiMa,MengxiGuo,YiHou,FanYang,YuanLi,HuizhuJia,andXiaodongXie.
Intelligence(AAAI). 2022.TowardsBlindWatermarking:CombiningInvertibleandNon-invertible
[10] RohitGirdhar,MannatSingh,AndrewBrown,QuentinDuval,SamanehAzadi, Mechanisms.InProceedingsoftheACMInternationalConferenceonMultimedia
SaiSakethRambhatla,AkbarShah,XiYin,DeviParikh,andIshanMisra.2023. (MM).
EmuVideo:FactorizingText-to-VideoGenerationbyExplicitImageConditioning. [33] XiaochenMa,BoDu,XianggenLiu,AhmedYAlHammadi,andJizheZhou.
arXivpreprintarXiv:2311.10709(2023). 2023.IML-ViT:ImageManipulationLocalizationbyVisionTransformer.arXiv
[11] XiaoGuo,XiaohongLiu,ZhiyuanRen,StevenGrosz,IacopoMasi,andXiaoming preprintarXiv:2307.14863(2023).
Liu.2023.Hierarchicalfine-grainedimageforgerydetectionandlocalization.In [34] ChongMou,YouminXu,JiechongSong,ChenZhao,BernardGhanem,andJian
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecogni- Zhang.2023. Large-capacityandflexiblevideosteganographyviainvertible
tion(CVPR). neuralnetwork.InProceedingsoftheIEEE/CVFConferenceonComputerVision
[12] YuweiGuo,CeyuanYang,AnyiRao,YaohuiWang,YuQiao,DahuaLin,and andPatternRecognition(CVPR).
BoDai.2023.Animatediff:Animateyourpersonalizedtext-to-imagediffusion [35] NeenaRajNRandRShreelekshmi.2022.Fragilewatermarkingschemefortamper
modelswithoutspecifictuning.arXivpreprintarXiv:2307.04725(2023). localizationinimagesusinglogisticmapandsingularvaluedecomposition.
[13] AmalHammami,AmalBenHamida,ChokriBenAmar,andHenriNicolas.2024. JournalofVisualCommunicationandImageRepresentation85(2022),103500.
BlindSemi-fragileHybridDomain-BasedDualWatermarkingSystemforVideo [36] RupaliDPatilandShilpaMetkar.2015.Fragilevideowatermarkingfortamper-
AuthenticationandTamperingLocalization.Circuits,Systems,andSignalPro- ingdetectionandlocalization.In2015InternationalConferenceonAdvancesin
cessing43,1(2024),264–301. Computing,CommunicationsandInformatics(ICACCI).1661–1666.
[14] XiaoxiaoHu,QichaoYing,ZhenxingQian,ShengLi,andXinpengZhang.2023. [37] PengfeiPei,XianfengZhao,JinchuanLi,andYunCao.2023. UVL:AUnified
DRAW:DefendingCamera-shootedRAWagainstImageManipulation.InPro- FrameworkforVideoTamperingLocalization.arXivpreprintarXiv:2309.16126
ceedingsoftheIEEE/CVFInternationalConferenceonComputerVision(ICCV). (2023).
[15] NasirNHurrah,ShabirAParah,NazirALoan,JavaidASheikh,Mohammad [38] FedericoPerazzi,JordiPont-Tuset,BrianMcWilliams,LucVanGool,Markus
Elhoseny,andKhanMuhammad.2019. Dualwatermarkingframeworkfor Gross,andAlexanderSorkine-Hornung.2016.Abenchmarkdatasetandeval-
privacyprotectionandcontentauthenticationofmultimedia.Futuregeneration uationmethodologyforvideoobjectsegmentation.InProceedingsoftheIEEE
computerSystems94(2019),654–673. conferenceoncomputervisionandpatternrecognition.724–732.
[16] ZhaoyangJia,HanFang,andWeimingZhang.2021.Mbrs:Enhancingrobustness [39] VaishnavPotlapalli,SyedWaqasZamir,SalmanKhan,andFahadShahbazKhan.
ofdnn-basedwatermarkingbymini-batchofrealandsimulatedjpegcompres- 2023. PromptIR:PromptingforAll-in-OneBlindImageRestoration. arXiv
sion.InProceedingsofthe29thACMInternationalConferenceonMultimedia preprintarXiv:2306.13090(2023).
(MM). [40] RobinSanRoman,PierreFernandez,AlexandreDéfossez,TeddyFuron,Tuan
[17] JunpengJing,XinDeng,MaiXu,JianyiWang,andZhenyuGuan.2021.HiNet: Tran,andHadyElsahar.2024.ProactiveDetectionofVoiceCloningwithLocal-
DeepImageHidingbyInvertibleNetwork.InProceedingsoftheIEEE/CVFInter- izedWatermarking.arXivpreprintarXiv:2401.17264(2024).
nationalConferenceonComputerVision(ICCV). [41] ShellySheynin,AdamPolyak,UrielSinger,YuvalKirstain,AmitZohar,Oron
[18] AsraKamili,NasirNHurrah,ShabirAParah,GhulamMohiuddinBhat,and Ashual,DeviParikh,andYanivTaigman.2023.Emuedit:Preciseimageediting
KhanMuhammad.2020.DWFCAT:Dualwatermarkingframeworkforindustrial viarecognitionandgenerationtasks.arXivpreprintarXiv:2311.10089(2023).
imageauthenticationandtamperlocalization.IEEETransactionsonIndustrial [42] UrielSinger,AdamPolyak,ThomasHayes,XiYin,JieAn,SongyangZhang,
Informatics17,7(2020),5108–5117. QiyuanHu,HarryYang,OronAshual,OranGafni,etal.2022.Make-a-video:
[19] DiederikPKingmaandJimmyBa.2014.Adam:Amethodforstochasticopti- Text-to-videogenerationwithouttext-videodata.arXivpreprintarXiv:2209.14792
mization.arXivpreprintarXiv:1412.6980(2014). (2022).
[20] Myung-JoonKwon,In-JaeYu,Seung-HunNam,andHeung-KyuLee.2021.CAT- [43] XiaopengSun,WeiqiLi,ZhenyuZhang,QiufangMa,XuhanSheng,MingCheng,
Net:Compressionartifacttracingnetworkfordetectionandlocalizationofimage HaoyuMa,ShijieZhao,JianZhang,JunlinLi,etal.2023.OPDN:Omnidirectional
splicing.InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsof position-awaredeformablenetworkforomnidirectionalimagesuper-resolution.
ComputerVision(WACV). InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecog-
[21] GuobiaoLi,ShengLi,ZicongLuo,ZhenxingQian,andXinpengZhang.2024. nition.1293–1301.
PurifiedandUnifiedSteganographicNetwork.InProceedingsoftheIEEE/CVFZhangetal.
[44] ZhihaoSun,HaoranJiang,DandingWang,XirongLi,andJuanCao.2023.SAFL- [54] QichaoYing,XiaoxiaoHu,XiangyuZhang,ZhenxingQian,ShengLi,andXin-
Net:Semantic-AgnosticFeatureLearningNetworkwithAuxiliaryPluginsfor pengZhang.2022.RWN:RobustWatermarkingNetworkforImageCropping
ImageManipulationDetection.InProceedingsoftheIEEE/CVFInternational Localization.InProceedingsoftheIEEEInternationalConferenceonImagePro-
ConferenceonComputerVision(ICCV). cessing(ICIP).
[45] YuliyaVybornova.2020. Anewwatermarkingmethodforvideoauthentica- [55] QichaoYing,ZhenxingQian,HangZhou,HaishengXu,XinpengZhang,and
tionwithtamperlocalization.InComputerVisionandGraphics:International SiyiLi.2021.Fromimagetoimuge:Immunizedimagegeneration.InProceedings
Conference,ICCVG2020,Warsaw,Poland,September14–16,2020,Proceedings. oftheACMinternationalconferenceonMultimedia(MM).
201–213. [56] QichaoYing,HangZhou,ZhenxingQian,ShengLi,andXinpengZhang.2023.
[46] ChengyiWang,SanyuanChen,YuWu,ZiqiangZhang,LongZhou,Shujie LearningtoImmunizeImagesforTamperLocalizationandSelf-Recovery.IEEE
Liu,ZhuoChen,YanqingLiu,HuamingWang,JinyuLi,etal.2023. Neural TransactionsonPatternAnalysisandMachineIntelligence(2023).
codeclanguagemodelsarezero-shottexttospeechsynthesizers.arXivpreprint [57] JiwenYu,XiaodongCun,ChenyangQi,YongZhang,XintaoWang,YingShan,
arXiv:2301.02111(2023). andJianZhang.2023. AnimateZero:VideoDiffusionModelsareZero-Shot
[47] ShujinWei,HaodongLi,andJiwuHuang.2022.DeepVideoInpaintingLocal- ImageAnimators.arXivpreprintarXiv:2312.03793(2023).
izationUsingSpatialandTemporalTraces.InIEEEInternationalConferenceon [58] YanhongZeng,JianlongFu,andHongyangChao.2020.Learningjointspatial-
Acoustics,SpeechandSignalProcessing(ICASSP).8957–8961. temporaltransformationsforvideoinpainting.InComputerVision–ECCV2020:
[48] HaiweiWu,JiantaoZhou,JinyuTian,andJunLiu.2022.Robustimageforgeryde- 16thEuropeanConference,Glasgow,UK,August23–28,2020,Proceedings,PartXVI
tectionoveronlinesocialnetworksharedimages.InProceedingsoftheIEEE/CVF 16.Springer,528–543.
ConferenceonComputerVisionandPatternRecognition(CVPR). [59] XuanyuZhang,RunyiLi,JiwenYu,YouminXu,WeiqiLi,andJianZhang.2024.
[49] XiaoshuaiWu,XinLiao,andBoOu.2023.SepMark:DeepSeparableWatermark- EditGuard:VersatileImageWatermarkingforTamperLocalizationandCopyright
ingforUnifiedSourceTracingandDeepfakeDetection.InProceedingsofthe Protection.InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
ACMinternationalconferenceonMultimedia(MM). patternrecognition.
[50] YueWu,WaelAbdAlmageed,andPremkumarNatarajan.2019. Mantra-net: [60] YulinZhang,JiangqunNi,WenkangSu,andXinLiao.2023.ANovelDeepVideo
Manipulationtracingnetworkfordetectionandlocalizationofimageforgeries WatermarkingFrameworkwithEnhancedRobustnesstoH.264/AVCCompres-
withanomalousfeatures.InProceedingsoftheIEEE/CVFConferenceonComputer sion.InProceedingsofthe31stACMInternationalConferenceonMultimedia.
VisionandPatternRecognition(CVPR). 8095–8104.
[51] YunyangXiong,BalaVaradarajan,LemengWu,XiaoyuXiang,FanyiXiao, [61] ShangchenZhou,ChongyiLi,KelvinCKChan,andChenChangeLoy.2023.
ChenchenZhu,XiaoliangDai,DilinWang,FeiSun,ForrestIandola,etal.2023. ProPainter:Improvingpropagationandtransformerforvideoinpainting.In
Efficientsam:Leveragedmaskedimagepretrainingforefficientsegmentanything. ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.10477–
arXivpreprintarXiv:2312.00863(2023). 10486.
[52] TianfanXue,BaianChen,JiajunWu,DonglaiWei,andWilliamTFreeman.2019. [62] YangmingZhou,QichaoYing,YifeiWang,XiangyuZhang,ZhenxingQian,
Videoenhancementwithtask-orientedflow.InternationalJournalofComputer andXinpengZhang.2022.RobustWatermarkingforVideoForgeryDetection
Vision127(2019),1106–1125. withImprovedImperceptibilityandRobustness.In2022IEEE24thInternational
[53] GuanhuiYe,JiashiGao,YuchenWang,LiyanSong,andXuetaoWei.2023.ItoV: WorkshoponMultimediaSignalProcessing(MMSP).
EfficientlyAdaptingDeepLearning-basedImageWatermarkingtoVideoWater- [63] JirenZhu,RussellKaplan,JustinJohnson,andLiFei-Fei.2018.Hidden:Hiding
marking.arXivpreprintarXiv:2305.02781(2023). datawithdeepnetworks.InEuropeanConferenceonComputerVision(ECCV).