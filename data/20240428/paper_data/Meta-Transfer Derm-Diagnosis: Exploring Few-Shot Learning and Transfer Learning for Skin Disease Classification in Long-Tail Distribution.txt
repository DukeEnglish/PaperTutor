META-TRANSFER DERM-DIAGNOSIS: EXPLORING FEW-SHOT
LEARNING AND TRANSFER LEARNING FOR SKIN DISEASE
CLASSIFICATION IN LONG-TAIL DISTRIBUTION
ZeynepÖzdemir HacerYalimKeles ÖmerÖzgürTanrıöver
AnkaraUniversity HacettepeUniversity AnkaraUniversity
ComputerEngineeringDepartment ComputerEngineeringDepartment ComputerEngineeringDepartment
zynpozdemir@ankara.edu.tr hacerkeles@cs.hacettepe.edu.tr tanriover@ankara.edu.tr
ABSTRACT
Addressingthechallengesofrarediseasesisdifficult,especiallywiththelimitednumberofreference
imagesandasmallpatientpopulation. Thisismoreevidentinrareskindiseases,whereweencounter
long-taileddatadistributionsthatmakeitdifficulttodevelopunbiasedandbroadlyeffectivemodels.
Thediversewaysinwhichimagedatasetsaregatheredandtheirdistinctpurposesalsoaddtothese
challenges. Ourstudyconductsadetailedexaminationofthebenefitsanddrawbacksofepisodic
andconventionaltrainingmethodologies,adoptingafew-shotlearningapproachalongsidetransfer
learning. WeevaluatedourmodelsusingtheISIC2018,Derm7pt,andSD-198datasets. Withminimal
labeledexamples,ourmodelsshowedsubstantialinformationgainsandbetterperformancecompared
topreviouslytrainedmodels. Ourresearchemphasizestheimprovedabilitytorepresentfeatures
in DenseNet121 and MobileNetV2 models, achieved by using pre-trained models on ImageNet
toincreasesimilaritieswithinclasses. Moreover, ourexperiments, rangingfrom2-wayto5-way
classificationswithupto10examples,showedagrowingsuccessratefortraditionaltransferlearning
methods as the number of examples increased. The addition of data augmentation techniques
significantlyimprovedourtransferlearningbasedmodelperformance,leadingtohigherperformances
thanexistingmethods,especiallyintheSD-198andISIC2018datasets. Allsourcecoderelatedto
thisworkwillbemadepubliclyavailablesoonattheprovidedURL.
Keywords Few-shotlearning·Long-taildistribution·Medicalimageclassification·Skindiseaseclassification·
Transferlearning
1 Introduction
Overthepastdecade,thefieldofmedicalimageanalysishaswitnessedremarkableadvancements,primarilydrivenby
thedevelopmentofdeepconvolutionalneuralnetworksandtheavailabilityofextensivelabeledimagedatasets. These
advancementshavenotablyimpactedvarioustasks,includingorgansegmentation[1,2],tumorsegmentation[3,4],
anddiseasedetection[5,6]. Althoughabundantdataexistsforcommondiseases,asignificantgappersistsindata
availability for the over 6,000 known rare diseases, affecting approximately 7% of the global population [7]. The
diagnosisoftheserarediseases,includingsomeskinconditions,presentsuniquechallenges,particularlyduetothe
limitednumberofclinicalexamplesavailablefortrainingdeeplearningmodels. Theautomaticclassificationofskin
lesionsexemplifiesthesechallenges,asitiscomplicatedbythelong-taileddistributionofskindiseasedatasets,the
subtlevariationsinlesionappearances,andtheoverallscarcityofsufficientimagedata[8].
Variousstudieshavebeenconductedtoaddresstheproblemofskindiseaseclassificationusingdeeplearningapproaches.
Recentadvancementsinthisfieldaremainlyinthreecategories: methodsbasedontransferlearning[12,13],those
relyingonfew-shotlearning[8,14–19],andapproachesusingcross-domainfew-shotlearning[20]. Thestateoftheart
modelsinthisdomain,suchasMeta-DermDiagnosis,MetaMed,andPCNmodels[8,14,18],aredesignedtoextract
andlearnhigh-level,domain-specificfeaturesduringtheirtrainingprocess.
4202
rpA
52
]VC.sc[
1v41861.4042:viXraFigure1: Thefigureillustratesthedistributionsofthedatasetsusedinthisstudy,namelySD-198[9],Derm7pt[10]
andISIC2018[11]. Theobserveddatadistributionexhibitsalong-tailednature,andanexaminationrevealsthatsome
classeshaveveryfewinstances. Thebaseclasses(commondiseases)usedduringthetrainingprocessincludethetrain
(green)andvalidation(yellow)classes. Novelclasses(new/rarediseases)areindicatedwiththetestlabel(red). In
theDerm7Ptdataset,classeswithasignificantlylownumberofexamplesaredisplayedasdeleted(grey)anddeemed
unusable.
IntheirstudyontheISIC2018dataset,Lietal. (2020)introducedtheDifficultyAwareMeta-Learning(DAML)model,
recognizing that randomly selected tasks vary in difficulty [15]. They proposed optimizing the meta-optimization
processbydynamicallyassessingthesignificanceofchallengingtasks. Similarly,Mahajanetal. (2020)developed
theMeta-DermDiagnosismodel,experimentingwiththeSD-198,Derm7pt,andISIC2018datasets[8]. Thismodel
innovativelyreplacedtraditionalconvolutionallayersinPrototypicalNetworksandReptilewithGroupEquivariant
Convolutions,enhancingresistancetodatatransformationslikesymmetryandrotation,thusyieldingrobustfeatures.
However, this method received critique for its reliance on datasets with symmetric orientation. On a related note,
Singhetal. (2021)highlightedtheefficacyofMixUp,CutOut,andCutMixasdataaugmentationtechniquesinthe
medical field when integrated with the MAML algorithm in their MetaMed model, particularly on the ISIC2018
dataset[18]. BothMetaMedandMeta-DermDiagnosismodelsaimtoenhancefeaturerepresentationbybroadening
dataaugmentationanddiversification. Further,Prabhuetal. (2019)proposedthePrototypicalClusteringNetworks
(PCN)model,designedtoeffectivelyhandleintra-classvariabilityinfew-shotlearningscenarios[14].
The studies previously discussed have employed episodic learning as a means to acquire knowledge that can be
transferredtonewclasses. Thisapproachinvolvesthearrangementoflearningproblemsintoepisodes,eachcomposed
ofsmalltrainingandvalidationsubsets,designedtosimulatethescenariosencounteredduringevaluation.However,[21]
criticizedthismethod,arguingthattheconstraintsofepisodiclearningareunnecessaryandthatusingtraininggroups
inthismannerisdata-inefficient. Similarly,[22]arguedthatintasksinvolvingrareclasses,theeffectivenessofrapid
adaptationismoreattributabletothequalityofthelearnedrepresentationthantothefew-shotlearningalgorithmitself.
Theyincorporatedself-supervisedlearningintheirmodeltoenhancethisrepresentation. Inasimilarcontext,[23]
proposedtheconceptofMeta-transferlearning,whichisaimedatrefiningthelearnedrepresentation. Theyconducted
variousexperimentstocomparetheeffectivenessoffine-tuningpre-trainedDeepNeuralNetwork(DNN)modelswith
andwithoutepisodiclearning. Theirfindingsunderscorethesignificanceofintegratingtransferlearningwithfew-shot
learningmethodologies.
Theexistingliteratureconsistentlyhighlightstheongoingchallengeofeffectivelymanagingtheissueoflong-tailed
datadistributioninskindiseasestudies[8,24,25]. Althoughcurrentmethodsshowpromiseinspecificdatasetcontexts,
theirabilitytogeneralizebroadlyremainslimited. Mostresearchinthisfieldhasbeendirectedtowardsdeveloping
dataset-specificsolutions,addressingtheuniquechallengesandsensitivitiesarisingfromvariationsinclasscounts,data
formats,andothercriticalcharacteristics.
Inourstudy,weaimtoconductanin-depthanalysisofthebenefitsanddrawbacksofintegratingfew-shotlearning,
episodic learning, and transfer learning. Our main focus is on developing a foundational framework specifically
designedtoutilizetheinherentpropertiesoflong-tailedskindatasets. Whileacknowledgingthepotentialbenefitsof
performance-enhancingmethods,ourbaseapproachdistinctlydivergesfromsuchtechniques.
In this context, we implemented four distinct training methods, each evaluated using consistent metrics for newly
introducedclasses. Ourfirstmethod,Few-ShotEpisodicTransferLearning(FETL),involvesadaptingthemodelfor
thedatasetthroughfine-tuningweightsthatwereinitiallypre-trainedonImageNet,coupledwithepisodicfew-shot
learning. The second strategy, Few-Shot Episodic Learning (FEL), diverges from the first by employing episodic
learningonmodelswithoutanypre-training. Thethirdapproach,DeepTransferLearning(DTL),focusesonfine-tuning
2modelsusingdeepneuralnetworks(DNN)withpre-trainedImageNetweights,butnotablyomitsepisodiclearning.
Lastly,ourfourthmethod,DeepLearning(DL),actsasabaseline,utilizingpre-trainedImageNetweightswithout
additionaladjustmentsorfine-tuning. Followingtheestablishmentofourapproach,weaimedtoenhanceperformance
byincorporatingwell-knowndataaugmentationtechniquessuchasCutMix,MixUp,andResizeMixintotheDTL
model.
Toevaluatetheeffectivenessofourproposedmethodologies,wecarriedoutextensivetestingacrossthreebenchmark
skindiseasedatasets: SD-198,Derm7pt,andISIC2018. Thiscomprehensiveanalysisprovideduswithcriticalinsights
intothemosteffectivestrategiesfortacklingthechallengeoflong-taileddatadistributioninskindiseases. Thekey
contributionsofourstudyaresummarizedasfollows:
• Weintroduceanovelmethodologydesignedtoevaluatevariousmodeltrainingapproaches,usingaconsistent
benchmark test set specifically made for long-tail distributions in rare skin diseases. This evaluation is
conducted through episodic testing. To the best of our knowledge, this is the first time such a thorough
methodologicalanalysishasbeenconductedinthisdomain.
• Bycomparingepisodicandtraditionaltrainingmethods,ourfindingsindicatethattraditionaltrainingbecomes
increasinglybeneficialasthenumberofshots(trainingexamples)grows.
• We demonstrated that combining transfer learning with few-shot learning significantly enhances both the
learnedrepresentationandthetestingperformanceinthecontextofrareskindiseases. Usingourproposed
modelbasedontransferlearning,alongwithaugmentationtechniqueslikeMixUp,CutMix,andResizeMix,
hashelpedussurpassstate-of-the-artresultsinsomesettingsontheSD198andISIC2018datasets.
2 RelatedWorks
2.1 TransferLearningforMedicalImageDomain
Indeeplearning,apowerfultransferlearningmethodinvolvesadaptingapre-trainedmodelforanewtask,commonly
referredtoasfine-tuning(FT).Modelsthathavebeenpre-trainedonextensivedatasetshavedemonstratedsuperior
generalizationperformancecomparedtomodelsinitializedrandomly[26]. Varioustechniquesareemployedtofacilitate
thetransferofknowledgebetweendifferentsource-targetdomains[27–30].
Transferlearning(TL)isfrequentlyappliedinaddressingtheclassificationproblemofskindiseases. Forinstance,[31]
aimed to improve performance on the ISIC2018 dataset by using ISIC2016 and ISIC2017 as source datasets and
EfficientNetB0/B1, SeReNext50 as backboned models. [32] performed transfer from the ImageNet dataset to the
ISIC2018datasetusingResNet50. Similarly,[33]employedImageNet,ResNet,andDenseNetarchitecturesfortransfer
totheISIC2017dataset.[34],withasimilarobjective,experimentedwiththeVGG16architecture. Acommoninference
drawnfromthesestudiesisthattheuseoftransferlearning,particularlywhenImageNetorvariousdermatological
datasetsareusedassourcedatasetsandsupportedbyarchitectureslikeResNetorDenseNet,contributessignificantlyto
addressingthisproblem. Amorecomprehensiveliteraturediscussionisprovidedin[35].
Inadditiontotraditionallearningmethods,transferlearninghasalsobeenexploredintheFew-ShotLearning(FSL)
domain for the classification problem of skin diseases. For instance, the MetaMed study [18], working with FSL
algorithmsontheISIC2018dataset, comparedandinterpretedtheresultsofmodelstrainedthroughTLwiththeir
proposedmethod. Inthisprocess,theyemployedashallow-layeredarchitectureintheTLmodelandconductedtraining
usingonlybaseclasses. Incontrast,asindicatedintheliterature,weadaptedtheMobileNetandDenseNetarchitectures
totheFew-ShotLearningdomainbyutilizingpre-trainedweightsfromImageNet. Wediscusseddetailedcomparison
resultsinSection5.3.
2.2 Few-ShotLearninginComputerVision
Few-shotlearning(FSL)aimstorecognizenovelclasseswithonlyafewlabeledexamples,leveragingasubstantial
numberofexamplesfrombaseclasses.FSLalgorithmscanbebroadlycategorizedintothreegroups:initialization-based
methods,metriclearning-basedmethods,andhallucination-basedmethods.
Inthiscontext,initialization-basedmethodstakealearningtofine-tuneapproach. Theyaimtoacquireaneffective
modelinitialization,specificallytheneuralnetworkparameters. Thisfacilitatestheadaptationofclassifierswithlimited
labeledexamplesthroughafewgradientupdatestepsfornewclasses[36–38]. Anotherstrategyinvolvesdistance
metriclearningmethods,embracingalearningtocompareparadigmforfew-shotclassification. Thesemethodsare
foundationalapproachesutilizingencodedfeaturevectorsandadistancemeasurementmetricbasedonthenearest-
neighborprincipletoassignlabels. Forinstance,PrototypicalNetworks[39]utilizesEuclideandistance,Matching
3Networks[40]employscosinesimilarity,andRelationNetworks[41]utilizesitsownCNN-basedmeasurementmodule
forthispurpose[42]. Additionally,hallucination-basedmethodsdirectlyaddressdatascarcitythroughlearningto
augment. Here, hallucinationinvolvesgeneratingdatanotderivedfromrealexamplesordirectobservations. The
generator’sobjectiveistotransferappearancevariationspresentinthebaseclassestonovelclasses[43,44].
ThementionedFSLmethodsadoptanepisodictrainingapproachduringthetrainingofthedata(baseclasses). However,
some studies have shown that training the data by dividing it into tasks leads to inefficient use of the available
data[21,22]. Additionally,[45]hasdemonstrated,contrarytotheprevailingnotion,throughexperimentsconducted
withbenchmarkdatasetsandfundamentalFSLalgorithms,thatanincreaseintaskdiversity,proportionaltotheincrease
inclassesanddata,doesnotleadtoanimprovementinsuccess. Therefore,wecancategorizeFSLapproachesintotwo
groupsbasedontheirtrainingprocesses: meta-learning-basedandtransfer-learning(TL)-basedmethods. AmongTL
methods,S2M2-R[46],Baseline[47],PT-MAP[48],andMeta-TransferLearning[23]trainonbaseclassesusinga
standardclassificationnetworkandfine-tunetheclassifierheadonepisodesgeneratedfromnewclasses. Thesemethods
aimtotrainapowerfulfeatureextractorthatproducestransferablefeaturesforthenewclass. Experimentalmethods
havedemonstratedthattheseapproachescanachievemoreeffectiveandhigherperformancecomparedtopreviousFSL
methods,utilizingasimplerandmoreefficientprocess. DuetothesuperiorperformanceofTL-basedmethods,we
exploredthisapproachinconjunctionwithPrototypicalNetworksasawaytopredictrareskindiseases.
2.3 Few-ShotLearningforSkinDiseaseClassification
Theimbalanceddistributionofskindiseaseclassesandfactorssuchaslimitedimageavailabilityinrarediseasesneces-
sitatetheapplicationoffew-shotlearningmethods. Asasolutiontothischallenge,[15]proposedtheDifficulty-Aware
Meta-Learning(DAML)modelbasedonMeta-Learning. Thismodeladjuststhelossesforeachtask,increasingthe
weightofchallengingtaskswhiledecreasingthatofeasiertasks,therebyemphasizingandincreasingtheimportanceof
difficulttasks.Thisstudy,aimingtohighlightmoredistinctivefeaturesforeachclass,canbecategorizedasinitialization-
basedFSL.Ontheotherhand,themodelnamedMetaMed,evaluatedinbothinitializationandhallucination-basedFSL
categories,by[18],combinesadvanceddataaugmentationtechniquessuchasmixup,cutout,andcutmixwiththereptile
modelduringtrainingtoenhanceitsgeneralizationcapabilities. WorkingwiththeISIC2018dataset,theycomparedthe
transferlearningapproachoftheirproposedmodelwithotherstudies,reportinganaverageimprovementofupto3%in
performance. Inthemetric-basedbranch,severalmethodshavebeenproposed.[17]advocatedforthesuperiorityofthe
Query-RelativelossovertheCross-EntropylosscommonlyusedinFSL.Additionally,[49]suggestedtheutilization
ofTemperatureNetworksalongsidePrototypeNetworks. Theyadaptedspecifictemperaturesfordifferentcategories
toreduceintra-classvariabilityandenhanceinter-classdispersion. Moreover,theyappliedpenalizationbasedonthe
proximityofqueryexamples.[8]introducedamodelnamedMeta-DermDiagnosis,aimingtoobtaininvariantfeatures
aftervarioustransformationsbyreplacingtraditionalconvolutionallayerswithgroup-equivariantconvolutions,similar
toPrototypicalNetworksandReptile.
Inthecontextoftransfer-learning-basedalgorithms,[25]proposedamodelnamedPFEMed,suggestingadual-encoder
structure. This brings about one encoder with fixed weights pre-trained on large-scale public image classification
datasetsandanotherencodertrainedonthetargetmedicaldataset. Ontheotherhand,[24]designedadual-branch
frameworkandimprovedperformanceusingamodelemployingprototypicalnetworksandcontrastiveloss. Toaddress
thechallengeofobservingdiversesubgroupswithindermatologicaldiseaseclusters,[19]introducedtheSub-Cluster-
AwareNetwork(SCAN)model. SCANutilizesadual-branchstructuretoenhancefeatureexplanation,learningboth
class-specificfeaturesfordiseasedifferentiationandsubgroup-relatedfeatures.
Inthisstudy,weintegratePrototypicalNetworksfromFew-ShotLearning(FSL)algorithmswithtransferlearning
techniques. This fusion involves adapting MobileNetV2 and DenseNet121 backbone architectures, coupled with
pretrainedImageNetweights,specificallytotacklethechallengeofrareskindiseaseidentification. Ourexperimental
analysishighlightsthelimitationsofepisodictraininginoptimallyleveragingdata. Centraltoourapproachisthe
establishment of a foundational framework that relies solely on the inherent properties of the long tailed datasets,
withoutthenecessityforsupplementarydata. Thisincludesstrategiesaimedatenhancingmodelperformance,such
asextensivedataaugmentationtechniqueslikeMixUp,CutMix,andResizeMix. Theutilizationofthesetechniques
contributestoachievingourresearchobjectives.
3 DatasetsandEvaluation
The SD-198 dataset [9] comprises 198 detailed categories of skin diseases, including eczema, acne, rosacea, and
variouscancerconditions. Thesecategoriescontain6584clinicalimagescontributedbypatientsanddermatologists,
showcasingdiversecharacteristicslikecolor,exposure,lighting,andsize. Thedatasetcapturesawiderangeofpatients
intermsofage,gender,diseaselocation,skincolor,anddiseasestage. Originallydividedintoa50%trainingsetanda
4Figure2: Somesampleimagesfromskindiseaseclassificationdatasets
50%testset,theimagesarecapturedat1640×1130pixelsusingdigitalcamerasormobilephones. Toalignwiththe
comparisoncriteriasetbyMeta-DermDiagnosis[8]andSCAN[19],weresizedalldatato224x224pixels. Fortesting,
wefocusedon70classesrepresentingrarediseases,eachhavingfewerthan20images,whiletheremaining128classes
wereusedfortraining. ThedatasetdistributionisvisualizedinFigure1,andsampleimagesareprovidedinFigure2-a.
TheDerm7ptdataset[10]comprisesover2,000clinicalanddermoscopyimagesgroupedinto20distinctclasses. This
dataset,comprisingbothclinicalanddermoscopicimages,providespredictionsbasedona7-pointchecklistforthe
malignancyofskinlesions,makingitsuitablefortrainingandevaluatingcomputer-aideddiagnosis(CAD)systems.The
originalimageshavedimensionsof768×512pixels;however,forthepurposeofourexperimentalstudies,theyhave
beenresizedto224×224pixels. TofacilitatethecomparisonofourexperimentalresultswiththeMeta-DermDiagnosis
andSCANstudy,weadoptedsimilartrain-testsetdifferentiations. WithintheDerm7ptdataset,twocategoriesare
excludedfromourexperiments: ’miscellaneous’(encompassingunspecifiedskindiseases)and’melanoma’(dueto
itssolitaryinstance,preventingatrain-testdivision). Amongthe18lesioncategoriesinthisdataset,13classesare
allocatedfortraining,whiletheremainingcategoriesarereservedfortesting. Thenovelsetconsistsof5classes,with
eachclasscontaining10to34images. Thisdistinctionstrategyaimstomimictheabilitytogeneralizetoinfrequent
skindiseasesbyplacingclasseswithlimiteddatainthetestset. Forvisualreference,selectedexamplesofskinlesion
imagescanbefoundinFigure2-b. ThedatasetdistributionisalsosharedinFigure1.
The ISIC 2018 Skin Lesion dataset [11] comprises 10,015 dermoscopic images that are categorized by expert
pathologistsintosevendistinctskinlesionclasses. Withinthisdataset,7,515imagesareallocatedtothetrainingset,
whiletheremaining2,500imagesconstitutethetestset,followingastandardizedpartition. Dermoscopicimagesoften
positionthetargetlesionatthecenter. WeadheredtosimilarscalinganddatapartitionsastheMeta-DermDiagnosis[8]
andPFEMed[25]studyforourexperiments. Consequently,theimageresizingprocesstransformsimagesfrom600×
450pixelsto224x224pixels,andasubsetcomprisingfourbaseclassesandthreenovelclassesisselectedtoform
few-shotclassificationtasks. RefertoFigure2-cforexemplarimagesdrawnfromthedataset. Fordatadistribution,
pleaseseeFigure1.
4 TheMethodology
Thissectionoutlinesthecoremethodologiesdeployedinourstudy,startingwiththeMeta-TransferDerm-Diagnosis
Framework. Thisframeworkispivotalforassessingfourdistinctmodeltrainingstrategiesthatareparticularlyvaluable
inscenarioswithlimiteddatasamples. ThesestrategiesareFew-ShotEpisodicTransferLearning(FETL),Few-Shot
EpisodicLearning(FEL),DeepTransferLearning(DTL),andStandardDeepLearning(DL).
5Figure3: Overallframeworkofourpipeline: Meta-TransferDerm-Diagnosis. a)Episodiclearningiscombinedwith
DenseNetandMobileNetarchitectureswithouttheuseofImageNetweights. b)ImageNetpre-trainedweightsare
utilizedalongwiththeapplicationofanepisodiclearningstrategy. c)Pre-trainedweightsandallbaseclassdataare
employed for fine-tuning with ImageNet. d) Only ImageNet weights are utilized without fine-tuning. e) Detailed
diagramillustratingtheuseofepisodiclearningandprototypicalnetworks. Itisappliedinthecontinuationofpartsa
andb. f)Commonevaluationschemeusingnoveldataacrosssegmentsa,b,c,andd.
Figure4: TheflowchartillustratingthecomponentsandthetrainingstrategiesoftheFEL,FETL,DTL,andDLmodels
withintheproposedframework.
Weimplementapreciseevaluationprocess,employingacombinationoftheselectedbenchmarkdatasets(Section
3), and a specialized testing approach. This ensures a comprehensive and fair analysis of each training method.
Subsequently,weprovideanoverviewofPrototypicalNetworksandTransferLearning.
4.1 Meta-TransferDerm-DiagnosisFramework
TheproposedMeta-TransferDerm-DiagnosisFrameworkisusedtoeffectivelycombinefew-shottrainingmethods
withtransferlearning. Thisintegrationisspecificallydesignedtoimprovemodelperformancefortailclasses,which
oftenhavelimiteddata,therebyleveragingthecomplementarystrengthsofbothmethodologies.
Few-shotclassificationoperateswithtwodistinctdatasets: thebasedataset,denotedasD ,andthenoveldataset,
base
denotedasD . Thenoveldataset,D ,isutilizedfortheactualclassificationtask,whilethebasedataset,D ,
novel novel base
6helpsintrainingtheclassifierbytransferringessentialknowledgefromit. Additionally,duringtraining,ImageNet
datasetisalsousedandwillbereferredtoasthedomainD .Forclarityandcoherence,letusincludetwodefinitions
imgnet
adaptedtoourframeworkfrompriorliterature[42]thatarerelatedtoourstudy’scontextinfew-shotlearning. These
definitionswillhelpinframingourapproachandmethodology.
Definition1. Forthetrainingandtestingphases,thenoveldatasetD issplitintotwosubsets: thesupportset(D )
novel S
andthequeryset(D ).Inatypicalfew-shotclassificationscenario,thesupportsetD containsonlyafewsamplesper
Q S
class,oftenrangingfrom1to5. Theprimarygoalinfew-shotclassificationistotrainaclassifier,f :X →Y ,
novel novel
usingthelimiteddatainD . ThisclassifiershouldthenbeabletoaccuratelycategorizeinstancesinthequerysetD .
S Q
IfD includesN distinctclasseswithK labeledexamplesperclass,thisscenarioisdefinedasanN-wayK-shot
S
classification. Thecasewithonlyonelabeledexampleperclassistermedone-shotclassification.
Definition2. Afew-shotclassificationtaskisreferredtoascross-domainfew-shotclassificationwhenthetraindataset
D andthenoveldatasetD aresourcedfromdistinctdomains.
train novel
Tofurtherclarifyourmethodology,wedefinethedatasetsused. ThebasedatasetisdefinedasD ={(x ,y );x ∈
base i i i
X ,y ∈Y }Nbase,wherex representsthefeaturevectorofthei-thimage,andy isitscorrespondingclasslabel.
base i base i=1 i i
ThenoveldatasetissimilarlyrepresentedasD = {(x˜ ,y˜ );x˜ ∈ X ,y˜ ∈ Y }Nnovel. Itiscrucialtonote
novel j j j novel j novel j=1
thattheclasslabelsinD andD aremutuallyexclusive,i.e.,Y ∩Y =∅. Inasimilarmanner,D is
base novel base novel imgnet
representedas: {(x¯ ,y¯ );x¯ ∈X ,y¯ ∈Y
}Nimgnet.
k k k imgnet k imgnet k=1
Torigorouslyevaluatetheframeworkwedevised,detailedinFigure3,wemaintainedaconsistentevaluationbykeeping
D fixed. Here,D denotesthedatasetsusedduringtraining. Weformulatedfourdistincttrainingmethodologies,
novel train
eachindependentlydesigned: FETL,whereD = D +D ∗;FEL,whereD = D ∗;DTL,where
train imagenet base train base
D =D +D ;andDL,whereD =D . ThenotationD ∗indicatesepisodictraining,whilethe
train imagenet base train imagenet base
othersinvolvetraditionallarge-scaletrainingapproachesforthecorrespondingdatasetsinthatdomain.
Inaccordancewiththesedefinitions,asissummarizedinFigure4,ourFETL,FEL,andDTLmodelsutilizeD
base
andD classesfromthesamedomainfortrainingandtestingasspecifiedinDefinition1. Ontheotherhand,the
novel
proposedDLmodelutilizestwoseparatedomainsfortrainingandtesting,henceitalignswithDefinition2. Therefore,
threeoutofourfourproposedanalysisincludeadaptedfew-shottrainingandtestingmethodologiesconsideringthedata
extractedcarefullyfromthesamelong-taildistributions(FETL,FELandDTL),whilethelastone(DL)correspondsto
across-domainevaluation.
Algorithm1N-WayK-ShotClassificationEvaluation.
Require: D ={(x ,y );X ∈X ,Y ∈Y }Ntrain.
train i i i train i train i=1
Require: D ={(x˜ ,y˜ );x˜ ∈X ,y˜ ∈Y }Nnovel.
novel j j j novel j novel j=1
Require: NumberofepisodesE
1: fore=1,...,E do
2: RandomlyselectN classesfromY .
novel
3: RandomlyselectK samplesfromeachclassasthesupportsetD(e).
S
4: RandomlyselectM samplesfromtheremainingsamplesofN classesasthequeryset{(x˜(e),y˜(e))}.
5: Recordpredictedlabelsyˆ(e) =f(x˜(e)|D ,D(e)).
train S
6: Computeaccuracya(e) = 1 (cid:80)M 1[yˆ(e) =y˜(e)]
M m=1
7: endfor
8: Compute: Avg_Acc= 1 (cid:80)E a(e)
E e=1
9: return Avg_Acc
TheevaluationofourclassifierinN-wayK-shotclassificationisoutlinedinAlgorithm1. Thisprocessincludesa
seriesofepisodes,eachpresentingauniqueclassificationtask,allowingforathoroughassessmentoftheclassifier’s
performance. Inthisprocedure,astheinitialstep,werandomlyselectN classesfromthenovelset. Followingthis,
werandomlychooseK samplesfromeachoftheseN classestoconstituteasupportset. Concurrently,weselectM
samplesfromtheremaininginstancesintheseclassestoformaqueryset. Foreachepisode,denotedasthee’thepisode,
thequeryset’sinstancesandlabelsarerepresentedasx˜(e)andy˜(e),respectively. Alearningalgorithmisthenapplied,
utilizingthemodelthatispretrainedwithD andtunedtothesupportsetofthee’thepisode,D(e). Thisalgorithm
train S
yieldsaclassifierthatpredictslabelsfortheinstancesinthequeryset. Toquantifytheclassifier’sperformance,we
calculatetheclassificationaccuracyforeachepisode, referredtoasa(e). Theoveralleffectivenessofthelearning
algorithmisthendeterminedbyaveragingtheseclassificationaccuraciesacrossallepisodes.
74.2 PrototypicalNetworks
AsdepictedinFigure3(toprightsection),weusedPrototypicalNetworks[39]forbothepisodictrainingandtesting. It
isameta-learningapproach,whichisdesignedtorepresenteachclassthroughaprototypevector,basedondistance
metrics. Thisvectorisanaverageofembeddedinstancesinasupportset,specificallylinkedtothatclass. Formally,for
asetofN classes,thesupportsetS ={(x ,y ),...,(x ,y )}isconstructed,whereeachx ∈RDisaD-dimensional
1 1 N N i
featurevector,andy isitscorrespondinglabelintherange{1,...,K}.
i
Eachclassprototypec ∈RM iscomputedasthemeanvectorofitsassociatedembeddedinstances,usinganembedding
k
functionf :RD →RM withlearnableparametersϕ. Theprototypeforclasskisderivedas:
ϕ
1 (cid:88)
c = f (x ). (1)
k |S | ϕ i
k
(xi,yi)∈Sk
Thenetworkutilizesadistancefunctiond : RM ×RM → [0,+∞)tocalculatetheprobabilitydistributionacross
classesforaquerypointx,basedonthesoftmaxofdistancesbetweenthequerypointandclassprototypes:
exp(−d(f (x),c ))
p (y =k|x)= ϕ k . (2)
ϕ (cid:80) exp(−d(f (x),c ))
k′ ϕ k′
TraininginvolvesminimizingthenegativeloglikelihoodJ(ϕ)=−logp (y =k|x)ofthetrueclassk,usingStochastic
ϕ
GradientDescent(SGD).
4.3 RegularizationviaImageAugmentation
Regularizationtechniquesareessentialinpreventingoverfittingandenhancingthegeneralizationcapabilitiesofdeep
models. Amongthesetechniques,imageaugmentationstandsoutasacrucialmethodinsupervisedlearning,well-
knownforitsefficacyinregularization. Whileconventionalaugmentationmethodslikerotation,horizontalflips,and
verticalflipsarewidelyused,theyoftenproveinadequateindomainscharacterizedbylimiteddata,suchasmedical
imaging. Consequently,advancedapproachessuchasMixUp[50],CutMix[51],andResizeMix[52]havereceived
significantattentionduetotheirabilitytoaddressthechallengesposedbydatascarcityandvariability.Thesemethods
provideadvancedsolutionsthatextendbeyondconventionaltechniques,facilitatingthegenerationofdiversetraining
samplesandenhancingmodelrobustnessfromvariousperspectives.
MixUp
MixUpgeneratessyntheticsamplesbyblendingfeaturesandlabelsfromtwodifferentimagesusingweightedblending.
Let(x ,y )and(x ,y )representthefeaturesandlabelsoftwoimages, respectively. MixUpcombinesthesetwo
i i j j
imageswithweightedblendingtocreateanewsyntheticsample:
x˜=λx +(1−λ)x
i j
y˜=λy +(1−λ)y
i j
Here,λ∈[0,1]isarandomweightvalue.
CutMix
CutMixcreatessyntheticsamplesbyreplacingregionsofanimagewithpatchesfromanotherimage,controlledbya
cutratio(λ). Let(x ,y )and(x ,y )denotethefeaturesandlabelsoftwoimages,respectively. CutMixblendsthese
i i j j
twoimagesaccordingtothecutratiotocreateanewsyntheticsample:
x˜=M ·x +(1−M)·x
i j
y˜=λy +(1−λ)y
i j
Here,M isamaskmatrix,andλisarandomcutratio.
8ResizeMix
ResizeMixmergesimagesofdifferentsizesbyresizingthemandthenblendingthemusingweightedblending. Let
(x ,y )and(x ,y )representthefeaturesandlabelsoftwoimages,respectively. ResizeMixresizesoneimagetothe
i i j j
sizeoftheotherandblendsthemwithweightedblendingtocreateanewsyntheticsample:
x˜=λx +(1−λ)resize(x ,size(x ))
i j i
y˜=λy +(1−λ)y
i j
Here,resize(x ,size(x ))resizesx tothesizeofx ,andλ∈[0,1]isarandomweightvalue.
j i j i
5 ExperimentsandDiscussion
Figure5: Thegraphcomparestheaccuraciesofthemodelsbasedonthenumberofshots. Itillustratestheresultsfora)
SD-198,b)Derm7pt,andc)ISIC2018.
5.1 ImplementationDetails
TheimplementationofourstudyiscarriedoutusingthePythonprogramminglanguagewiththePyTorchlibrary.Nvidia
1080TiGPUisemployedduringthemodeldevelopment. ToensureafaircomparisonwiththeMeta-DermDiagnosis[8]
model,wealignedthedistinctionsbetweenbaseandnovelclassesinthedatasetsandensuredthesimilarityofdeleted
classes. Alldatasetsareresizedto224x224x3dimensions. ISIC2018consistsof4baseand3novelclasses,Derm7pt
includes 13 base and 5 novel classes, and SD-198 encompasses 128 base and 70 novel classes. In contrast to the
Meta-DermDiagnosisstudy,wepartitionedtheSD-198baseclassesintotrainingandvalidationsets. Classeswithfewer
9Table1: PerformancecomparisonoftheproposedmodelsontheSD-198skinlesiondatasetfor2-wayand5-way
classificationtasks. Accuracy(%)valuesarepresented.
MobileNetV2 DenseNet121
Exp
FEL FETL DTL DL FEL FETL DTL DL
2W-1S 82.66 84.77 82.42 77.77 82.91 82.83 81.21 75.70
2W-2S 87.41 89.57 88.34 85.98 87.77 88.26 87.88 84.39
2W-3S 89.77 91.73 91.43 89.52 90.23 90.82 91.38 88.63
2W-4S 90.72 93.05 93.38 91.44 91.90 92.47 93.16 90.48
2W-5S 91.49 93.66 94.40 92.96 92.95 93.58 94.56 91.86
2W-6S 91.85 93.81 95.09 93.65 93.63 94.19 95.26 92.58
2W-7S 92.61 94.41 95.73 94.68 94.20 94.75 96.02 93.71
2W-8S 92.85 94.79 96.21 95.35 94.55 95.22 96.67 94.27
2W-9S 93.02 94.89 96.46 95.48 94.79 95.56 96.88 94.64
2W-10S 93.19 95.10 96.77 95.69 95.05 95.74 97.07 94.94
5W-1S 61.73 65.85 64.06 56.93 63.61 64.81 62.61 54.25
5W-2S 69.93 75.02 75.72 71.07 72.15 73.95 75.30 68.56
5W-3S 73.97 79.04 80.88 76.81 76.97 78.47 80.73 74.57
5W-4S 76.47 81.48 84.32 80.88 80.06 81.95 84.53 78.51
5W-5S 78.16 83.22 86.67 83.24 82.05 84.02 86.95 81.03
5W-6S 78.84 83.97 88.10 85.31 83.62 85.59 88.78 83.16
5W-7S 79.76 85.04 89.17 86.52 84.68 86.60 90.22 84.58
5W-8S 80.36 85.50 90.09 87.47 85.52 87.35 91.05 85.55
5W-9S 81.14 85.94 90.83 88.55 86.30 88.32 91.91 86.50
5W-10S 81.40 86.36 91.37 89.35 86.77 88.51 92.57 87.33
Table2: PerformancecomparisonoftheproposedmodelsontheDerm7ptskinlesiondatasetfor2-wayand5-way
classificationtasks. Accuracy(%)valuesarepresented.
MobileNetV2 DenseNet121
Exp
FEL FETL DTL DL FEL FETL DTL DL
2W-1S 59.37 61.38 59.65 58.65 61.40 60.99 60.00 59.42
2W-2S 63.87 66.20 65.15 64.53 65.83 66.13 67.45 65.46
2W-3S 66.45 69.22 68.67 68.60 69.21 70.21 71.17 69.88
2W-4S 68.21 71.07 72.27 71.36 70.83 72.24 74.31 72.99
2W-5S 69.18 72.34 75.41 74.15 72.46 74.12 77.25 75.89
2W-6S 70.37 73.57 77.07 75.97 73.34 75.21 79.23 77.56
2W-7S 71.11 74.69 78.81 77.29 74.50 76.83 80.90 79.15
2W-8S 71.40 74.82 80.07 78.44 74.66 76.67 81.69 79.98
2W-9S 72.25 75.81 81.59 79.87 75.21 77.98 83.54 80.99
2W-10S 71.98 76.38 82.43 80.34 75.68 78.28 83.90 81.68
5W-1S 32.38 32.79 31.80 31.70 31.78 33.74 32.04 31.80
5W-2S 39.16 40.39 41.06 40.65 39.73 41.54 42.78 42.34
5W-3S 41.97 43.96 46.89 46.51 43.35 46.44 49.19 48.67
5W-4S 43.88 45.87 51.82 51.19 45.64 49.92 53.77 53.57
5W-5S 45.38 47.81 55.92 54.69 47.05 52.48 57.68 56.83
5W-6S 46.02 48.83 58.67 57.47 47.87 53.96 60.92 59.56
5W-7S 47.24 50.31 61.42 59.97 48.86 55.65 63.65 61.45
5W-8S 47.70 50.71 63.63 61.78 49.31 56.87 65.93 63.22
5W-9S 48.16 51.49 65.12 63.20 49.81 57.46 67.80 64.51
5W-10S 48.58 52.15 66.33 64.38 50.11 58.56 69.28 65.48
Table3: PerformancecomparisonoftheproposedmodelsontheISIC2018skinlesiondatasetfor2-wayand3-way
classificationtasks. Accuracy(%)valuesarepresented.
MobileNetV2 DenseNet121
Exp
FEL FETL DTL DL FEL FETL DTL DL
2W-1S 58.42 58.49 64.83 60.55 57.86 59.04 58.55 60.66
2W-2S 62.62 62.23 73.10 67.99 61.55 62.92 66.60 68.46
2W-3S 63.99 63.86 77.26 71.69 63.63 64.98 71.16 72.34
2W-4S 65.38 65.49 79.81 74.02 64.83 66.55 74.31 74.77
2W-5S 66.94 66.31 81.63 76.42 65.97 67.51 76.69 76.40
2W-6S 67.65 67.01 82.55 77.07 66.17 68.27 78.31 77.24
2W-7S 68.05 67.73 83.52 78.22 67.04 68.49 79.30 78.08
2W-8S 68.08 67.73 84.02 78.55 67.68 68.81 80.27 78.68
2W-9S 68.83 68.13 84.75 79.57 67.54 69.35 80.72 79.45
2W-10S 69.50 68.82 85.18 80.39 68.58 70.07 81.99 80.14
3W-1S 42.33 43.09 49.51 45.61 42.08 42.25 43.63 44.63
3W-2S 45.64 45.85 59.10 52.83 45.44 45.89 52.61 52.89
3W-3S 48.02 48.33 63.98 57.75 47.35 48.68 57.70 57.67
3W-4S 49.65 49.39 67.13 60.55 48.80 50.05 61.93 60.65
3W-5S 50.41 50.92 69.35 63.22 50.39 51.56 64.47 62.72
3W-6S 51.43 51.46 71.06 65.06 50.81 52.49 66.50 64.20
3W-7S 52.04 52.06 72.47 66.54 51.28 53.02 68.27 65.44
3W-8S 52.97 52.56 73.16 67.33 52.09 53.53 69.32 65.99
3W-9S 52.91 52.90 74.21 68.31 52.41 53.61 70.60 67.21
3W-10S 53.76 53.21 75.01 69.07 53.07 53.46 71.38 67.59
10than20datapointsaredesignatedasnovel,whilethosewith20-30datapointsareassignedtothevalidationset. To
ensureastandardizedtestingenvironmentforthefourdifferentlytrainedmodels,weemployedaseedanddeterministic
mode,whichworkedinallowingeachmodeltobetestedontasksofthesamedifficultyandorder. Hyperparameters
suchasbatchsizeusedduringtestingwerestructuredsimilarlyforFETLandFELmodels,withtheonlydifference
beingthequerysetsizesetto5duetodatainsufficiencyinnovelclasses. Dataaugmentationtechniquesarenotapplied
tonovelclasses. AllexperimentsareconductedusingMobileNetV2andDenseNet121backbonedmodels.
ThesoledistinctionbetweentheFEL(Few-ShotEpisodicLearning)andFETL(Few-ShotEpisodicTransferLearning)
models lies in the use of pretrained ImageNet weights for the backbone models in the FETL model. In contrast,
the FEL model is trained on backbone models with random initialization. Data augmentation techniques such as
RandomResizedCrop,RandomFlip,andColorJitterareemployed. Inthisframework,ourmodelsaretrainedwitha
5-way5-shotconfiguration,andalllayersofthebackbonemodelsarefullyopenedfortraining.
BothDTL(DeepTransferLearning)andDL(DeepLearning)modelsutilizeImageNetweights,buttheDTLmodelis
fine-tunedwiththebaseclassesofthedatasets. TheDLmodel,servingasabaseline,ischosentocompareperformance
withoutanyfine-tuning,usingImageNetweights. IntheDTLmodel,traditionaltrainingmethodsareemployedinstead
ofepisodictraining. Forinstance,inthecaseoftheSD-198dataset,10%ofthe128-classbasesectionareallocatedas
thevalidationset. TheMobileNetV2modelwithImageNetweightsarethentrained,aimingforthemodeltolearn
generalizedfeaturesfromthedataset. Duringtesting, thismodelisusedwithProtoNetinanepisodicstructureto
evaluateandcompareitsperformance.
Various augmentation techniques are employed in different training iterations of the DTL model to compare their
effectsandsuccessrates. WhiletheDTL-basemodelutilizesRandomResizeCropand50%HorizontalRandomFlip
intheSD-198andISIC2018datasets,Resizeand45%HorizontalandVerticalRandomFlipareusedintheDerm7Pt
dataset. Subsequently,theDTL-Basesectioniskeptconstant,andbatchaugmentationtechniquessuchasCutMix,
MixUp,andResizeMixareaddedforcomparison. EachaddedtechniqueislabeledintheresulttablesasDTL-CutMix
orDTL-ResizeMix. OurmodelnamedDTL-All-Augmentrepresentsacomprehensivemodelincorporatingallthree
techniquesontopofDTL-Base.
5.2 ExperimentalAnalysis
Inordertoevaluateourframeworkandassesstheeffectivenessofourproposedmethods,weperformedexperiments
using2-Way1-Shotto10-Shotand5-Way1-Shotto10-Shotsetups. Thesetestsareconductedusingthreedatasets:
SD-198, Derm7pt, and ISIC2018. The comprehensive results of our model tests are detailed in Tables 1, 2, and
3. Moreover, we executed additional experiments based on the parameters specified in Tables 4, 5, and 6. These
experiments are designed to compare our model’s performance against benchmarks set in prior research, such as
SCAN[19],MetaMed[18],andPFEMed[25],usingthedatasetsreferredtoinSection[9–11]. Inallthesetables,the
highestaccuracyvaluesarehighlightedinbold,andthesecondhighestresultsareunderlined.
TheSD-198datasetcontains198classesandconsistsonlyofclinicalimages. Incontrast,theDerm7ptdatasethas
18classeswithamixofclinicalanddermoscopicimages. TheISIC2018dataset,withits7classes,mainlyfeatures
dermoscopicimages. Althougheachofthesethreedatasetsshowsalong-taildistribution,theiruniquefeaturesaffect
howmodelsperform. Additionally,thenumberofparametersandtheperformancesofthebackbonemodelsalsoplay
essentialroleintheoverallmodelperformance. Forinstance,MobileNetV2hasapproximately3.4millionparameters,
whileDenseNet121boasts8.1millionparameters. Furthermore,whileepisodiclearningisemployedinFELandFETL
models,transferlearningbasedtrainingisutilizedinDTLandDLmodels,adistinctionthatsignificantlyimpactsmodel
performance. AscanbeobservedinFigure5,inallthreedatasets,FETLmodelsconsistentlyoutperformFELmodels,
whileDTLmodelsdemonstratesuperiorperformancecomparedtoDLmodels. Exceptforsomerarecases,depending
onthenumberofshotsanddatasetconditions,ourexperimentalresultsindicatethatthemostsuccessfulapproachinthe
proposedframeworkisthedeeptransferlearningbasedDTLmodel. Asthenumberofshotsincreases,theperformance
oftransferlearning-basedDTLandDLmodelsimproves.
Whencomparingourmodelswithoututilizingaugmentationtechniques,datasetscontainingrelativelylargenumber
ofclasses,suchasSD-198andDerm7pt,exhibitsimilarbehaviors. Episodiclearning-basedmodelstendtobemore
successfulwhenthenumberofshotsislow(i.e.1or2shots),whileDTLandDLmodelsshowatendencytooutperform
asthenumberofshotsincreases. Forinstance,withMobilNetV2modelontheSD-198dataset,fora5-Way1-Shot
scenario,theFETLmodelachieved65.85%,whereastheDTLmodelachieved64.06%. Fora5-Way10-Shotscenario,
theFETLmodelachieved86.36%,whereastheDTLmodelachieved91.37%(Table1). Thebehaviourofthemodels
aresimilarinDerm7ptdatasetaswell(Table2). Thereasonbehindthisphenomenonliesintheadaptabilityofepisodic
learning,whichperformsbetterinscenarioswithfewershotsduetothelargenumberofclasses. Additionally,clinical
imagesinherentlyencapsulatevariousdifferences, makingmodelstrainedinanepisodicmannermoreinclinedto
11Table4: ComparisonofourmodelsandtheSOTAmethods. ValuesinthetableareF1-scoresofthecorresponding
modelsontheSD-198dataset.
2Way 5Way
Method Backbone
1Shot 5Shot 1Shot 5Shot
PCN 70.78±1.61 85.87±1.12 45.59±1.03 65.70±1.02
Conv4
SCAN 78.00±1.51 91.01±0.90 55.60±1.07 75.65±0.87
SCAN Conv6 77.64±1.50 88.28±1.03 54.07±1.24 74.73±0.92
NCA 71.27±1.50 84.23±1.19 45.91±1.08 62.83±1.01
Baseline 76.64±1.56 89.66±0.97 52.54±1.11 74.71±0.96
S2M2_R 77.15±1.59 90.97±0.89 55.49±1.13 78.17±0.84
NegMargin 77.98±1.45 90.65±0.92 56.04±1.14 77.75±0.87
WRN-28-10
PT+NCM 78.86±1.47 90.90±0.93 56.91±1.11 78.12±0.88
PEMbE-NCM 78.70±1.49 90.94±0.95 57.42±1.11 78.78±0.90
EASY 79.44±1.51 91.43±0.96 57.77±1.12 79.53±0.89
SCAN 81.21±1.46 92.08±0.85 58.75±1.14 81.43±0.77
DTL-Base(Ours) 80.54±0.53 94.10±0.29 61.32±0.40 86.04±0.26
DTL-CutMix(Ours) 81.10±0.53 94.51±0.28 62.78±0.41 87.05±0.26
DTL-MixUp(Ours) MobileNetV2 80.34±0.53 94.20±0.28 61.71±0.41 86.61±0.26
DTL-All-Augment(Ours) 81.44±0.53 94.76±0.28 63.22±0.41 87.48±0.25
DTL-ResizeMix(Ours) 83.06±0.51 95.05±0.27 65.40±0.40 88.08±0.25
Note:(1)TheresultsoftheSOTAmodelsaretakenfromtheSCAN[19].(2)Thecompletereferencesforthementionedworksinthe
tableareasfollows:PCN[14],SCAN[19],NCA[53],Baseline[47],S2M2_R[46],NegMargin[54],PT+NCM[48],PEM
E-NCM[53],EASY[55].
b
toleratethesediversities. Asthenumberofshotsincreases,modelstrainednon-episodicallybecomemoresuccessfulin
classifications.
SincetheISIC2018datasetcomprisesdermoscopicdata,thediscriminativepowerofdomain-specificfeaturesbecomes
morecrucial. Hence,transferlearning-basedDTLandDLmodelsoutperformFETLandFELmodels. Forinstance,
forMobileNetV2,theaccuracyratesare58.49%for2-Way1-ShotwithFETLand64.83%withDTL,and68.82%
for 2-Way 10-Shot with FETL and 85.18% with DTL (Table 3). Episodic learning-based methods tend to remain
superficialintraining. Additionally,inparallelwiththeSD-198dataset,modelstendtobecomemoresuccessfulas
thenumberofshotsincreasesinISIC2018andDerm7pdatasets. TheMobileNetV2andDenseNet121modelstend
toyieldcomplementaryoutcomes. DenseNet121,withitsgreaterparametercount,ismoresusceptibletooverfitting
whiletraining. Conversely,MobileNetV2,withitssimplerarchitecture,isbettersuitedforpracticalapplicationsinthis
setting.
Inallthreedatasetswestudied,transferlearningmethodsgenerallyperformbetterthanepisodicfew-shottrainingin
learningdistinctfeatures,exceptincaseswherethereisonlyoneexampleprovided. Thisobservationsuggeststhateven
thoughepisodicfew-shottrainingisamoreintricateapproach,itmaynotbeaseffectiveastransferlearninginmost
scenarios. Theexceptioniswhenextremelylimiteddataisavailable,whichiswhenepisodicfew-shottrainingcan
bevaluable. Thisfindingisconsistentwithrecentresearch([21])thatquestionsthepracticalityofcomplexfew-shot
trainingmethods.
5.3 ComparisonwithCurrentState-of-the-Art
Wealsoincludedathoroughanalysisaimedatunderstandinghowdifferentskindiseasedatasets,eachwithunique
featuresandconditions,influencethetrainingprocess. Wearrangedthedatasetsinourresearchinamannersimilarto
SCAN[19]andPFEMed[25]studiesforafaircomparisonofthemodelperformances. Specifically,weexaminedthe
performancebenchmarkssetbytheSCANmodelontheSD-198andDerm7ptdatasets,andbythePFEMedmodelon
theISIC2018dataset.
InourresearchwiththeSD-198dataset,weenhancedourDeepTransferLearning(DTL)modelbyintegratingvarious
augmentation techniques, and compared these models with other state-of-the-art models in the field, particularly
focusingontheSCANmodel(Table4). TheSCANmodel,whichincorporatesanunsupervisedclusterbranch,has
beenpreviouslycontrastedwiththeMeta-DermDiagnosisstudy. Ourcomparisonalsoextendedtovarioustransfer
learning-basedFew-ShotLearning(FSL)methods;includingthemodelslikeNCA[53],Baseline[47],S2M2_R[46],
NegMargin[54],PT+NCM[48],PEM E-NCM[53],andEASY[55]. Notably,theSCANmodelreportedbetterresults
b
thantheseapproachesintestsontheSD-198dataset. TheEASYmodel,whichachievedresultscomparabletothe
SCANmodel,usedanensembletechniqueandaugmentedimageswitharandomresizecropmethod. Ourapproach,
however,isdifferent;weemploytheMobileNetV2model,leveragingImageNetpre-trainedweightsinsteadofthe
12Table5: ComparisonofourmodelsandtheSOTAmethods. ValuesinthetableareAccuracies(%)ofthecorresponding
modelsontheISIC2018dataset.
2Way 3Way
Method Backbone
3Shot 5Shot 10Shot 3Shot 5Shot 10Shot
Meta-DermDiagnosis Conv6 64.50 73.50 79,70 - - -
MetaMed-Transf.Learn. 66.88 73.88 81.37 54.83 59.33 69.75
MetaMed-NormalAug. 72.75 75.62 81.37 54.83 59.33 69.75
MetaMed-CutOut Conv4 70.37 77.62 81.87 55.5 65.41 69.75
MetaMed-MixUp 75.37 78.25 84.25 58.5 61.25 71
MetaMed-CutMix 73.25 76.87 80.62 58.66 61.5 66.5
PT-MAP 68.15 70.87 74.19 53.17 55.61 59.57
Baseline+ 64.77 70.27 74.67 53.2 54.16 57.87
NegMargin WRN 71.33 72.67 75.17 60.69 57.58 63.04
Baseline 68.77 71.03 76.97 56.8 59.2 65.22
PFEMed 81.69 83.87 85.14 66.94 69.78 73.81
DTL-Base(Ours) 77.26 81.63 85.18 63.98 69.35 75.01
DTL-CutMix(Ours) 77.71 81.79 85.97 64.37 69.86 75.73
DTL-MixUp(Ours) MobileNetV2 79.02 82.95 86.4 66.84 71.15 76.48
DTL-ResizeMix(Ours) 78,02 82.75 86.69 65.56 70.87 76.97
DTL-All-Augment(Ours) 78,96 83.21 86.83 66.12 71.28 76.94
Note:(1)TheresultsoftheSOTAmodelsaretakenfromthePFEMed[25].(2)Thecompletereferencesforthementionedworksin
thetableareasfollows:Meta-DermDiagnosis[8],MetaMed[18],PT-MAP[48],Baseline[47],NegMargin[54],PFEMed[25].
Table6: ComparisonofourmodelsandtheSOTAmethods. ValuesinthetableareAccuracies(%)ofthecorresponding
modelsontheDerm7ptdataset.
2Way
Method Backbone
1Shot 5Shot
PCN 59.98±1.28 70.62±13
Conv4
SCAN 61.42±1.49 72.58±1.28
Meta-DermDiagnosis 61.8 76.9
Conv6
SCAN 62.80±1.34 76.65±1.21
NCA 56.32±1.29 67.18±1.15
Baseline 59.43±1.34 74.28±1.14
S2M2_R 61.37±1.33 79.83±1.34
NegMargin 58.00±1.44 70.12±1.30
PT+NCM WRN-28-10 60.92±1.68 74.33±1.48
PEMbE_NCM 60.40±1.72 72.63±1.48
EASY 61.02±1.67 75.98±1.41
SCAN 66.75±1.35 82.57±1.13
PFEMed 71.15 80.27
DTL-Base(Ours) 60.00±0.39 77.25±0.41
DTL-CutMix(Ours) 61.57±0.41 78.65±0.40
DTL-MixUp(Ours) DenseNet121 62.56±0.40 81.00±0.39
DTL-ResizeMix(Ours) 61.09±0.38 79.18±0.39
DTL-All-Augment(Ours) 60.88±0.40 78.30±0.40
Note:(1)TheresultsoftheSOTAmodelsaretakenfromtheSCAN[19].(2)Thecompletereferencesforthementionedworksin
thetableareasfollows:PCN[14],Meta-DermDiagnosis[8],SCAN[19],NCA[53],Baseline[47],S2M2_R[46],NegMargin[54],
PT+NCM[48],PEM E-NCM[53],EASY[55],PFEMed[25].
b
13typicallyusedWRN-28-10model. Ouraugmentationstrategyismorevaried;wecombinedtraditionaltechniqueslike
RandomFlipandRandomResizeCropwithadvancedmethodssuchasCutMix,MixUp,andResizeMix(asusedby
MetaMedmodel). Thisapproachenabledourmodelstoexceedtheexistingstate-of-the-artresults. Eventhoughwe
usedsimpletransferlearningbasedmethodology,withthedataaugmentationsourmodelcouldefficientlylearnand
transferfeatureembeddingsfrombaseclassestonovelclasses.
Similarly, the PFEMed study compared its results on the ISIC2018 dataset with benchmarks set by studies like
MetaMed[18],Meta-DermDiagnosis,PT-MAP[48],Baseline,andNegMargin. ThePFEMedapproachinvolveda
comprehensivemodelwithadual-encoderstructurecombinedwithaVariationalAutoencoder,distinguishingbetween
generalandspecificfeatures,andachievingstate-of-the-artresults. Incontrast,theMetaMedstudyexploredmodels
employingaugmentationtechniques(suchasCutOut,CutMix,andMixUp)duringepisodictrainingwithReptilemodel,
andcomparedthesetoMeta-DermDiagnosis. Inthisdataset,observingthepotentialsuccessofourDTLmodeltrained
withMobileNetV2,weappliedsimilaraugmentationtechniquestothetrainingdata. Theexperimentresultsdepictthat
ourmodelperformscomparableresultswiththestate-of-the-artmodels;producingsecondbestresultsin3-Shotand
5-Shotcases. Moreover,weobtainbestresultswhenthenumberofsamplesisincreased(i.e. 10-Shotcase)(Table5).
WealsocomparedourmodelswithleadingmodelsontheDerm7ptdataset. Theuniquefeaturesofthisdatasetplayeda
keyroleinimprovingperformance,especiallythesub-clusteraspectintheSCANmodel. Weincludedfindingsfrom
thePFEMedstudyinourcomparison. ByusingtheDTL-MixUpmodel,basedontheDenseNet121framework,we
achievedresultsthatalignwithexistingbenchmarksinthe2-Way5-Shotscenario,whereourmodelrankedsecondin
accuracy. Similartowhatweobservedinourearlyexperimentswithoutdataaugmentations,inone-shotsettings,the
DTLmodeldidn’tperformaswellcomparedtoothermodels(seeFigure5). It’simportanttonotethatourmethod
reliessolelyontransferlearningtechniquesandenhancesthepretrainedImageNetmodelwithdataaugmentations.
Theseoutcomesindicatethatthisfundamentalapproachremainseffectiveinmanaginglong-taildistributions,without
theneedforintricatetrainingmethods.
6 ConclusionandFutureWork
Inthisstudy,weexploretheeffectivenessofepisodicandtraditionaltrainingmethodscombinedwithfew-shotlearning
throughtransferlearningforclassifyingrareskindiseasesinsituationswithlimiteddata. Currentliteratureemphasize
thatdatasetswithlong-taildistributionspresentspecificchallenges,highlightingthenecessityforspecializedtraining
approachestoachievesuccessfuloutcomes. Butthereisalackofresearchcombiningbasicfew-shottrainingmodels
withwell-knowntransferlearningmethodologiesinthisdomain. Ourstudyseekstofillthisgapbyevaluatingthese
establishedtrainingmethodsonmajordatasetsoftenusedasbenchmarksforlong-taildistributionsinskindiseases.
Inthiscontext,wepresentedevaluationsofthreepubliclyavailableskinimagedatasetsusingtheFETL,FEL,DTL,
andDLmodels. Notably,theDTLmodel,whichintegratestransferlearningwithconventionaltrainingtechniques,
consistentlyoutperformedothersinthesedatasets. ByenhancingourmodelswithMixUp,CutMix,andResizeMix
techniques, asrecommendedinexistingliterature, wewereableto reachleadingperformanceontheSD-198and
comparableperformanceswiththestate-of-the-artmethodsinISIC2018andDerm7ptdatasets.
Thesefindingsunderlinetheeffectivenessoftransferlearning,awell-establishedmethod,inthecontextoffew-shot
learningforlong-taildistributionsinskindiseaseclassification. Wesuggestthatfurtherimprovementsinaccuracyand
robustnesscanbeachievedthroughexpandeddataaugmentationandexploringdifferentmodelarchitectures. Basedon
theinsightsgainedfromthisstudy,webelievethatfurtherresearchiscrucial,especiallyfordermoscopicdatasetsfacing
datascarcity. Moreover,applyingthesefindingstoabroaderrangeofmedicalimagingdatasets,includingX-rays,CT
scans,andMRIs,couldbehelpfulindetectinganddiagnosingnewdiseases.
References
[1] Duowen Chen, Yunhao Bai, Wei Shen, Qingli Li, Lequan Yu, and Yan Wang. Magicnet: Semi-supervised
multi-organsegmentationviamagic-cubepartitionandrecovery. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages23869–23878,2023.
[2] BoWang,QianLi,andZhengYou. Self-supervisedlearningbasedtransformerandconvolutionhybridnetwork
forone-shotorgansegmentation. Neurocomputing,527:1–12,2023.
[3] QixinHu,YixiongChen,JunfeiXiao,ShuwenSun,JienengChen,AlanLYuille,andZongweiZhou. Label-
freelivertumorsegmentation. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
Recognition,pages7422–7432,2023.
[4] IndrajitMazumdarandJayantaMukherjee. Fullyautomaticmribraintumorsegmentationusingefficientspatial
attentionconvolutionalnetworkswithcompositeloss. Neurocomputing,500:243–254,2022.
14[5] Suraj Mishra, Yizhe Zhang, Li Zhang, Tianyu Zhang, X Sharon Hu, and Danny Z Chen. Data-driven deep
supervisionforskinlesionclassification. InMedicalImageComputingandComputerAssistedIntervention–
MICCAI2022: 25thInternationalConference,Singapore,September18–22,2022,Proceedings,PartI,pages
721–731.Springer,2022.
[6] YukunZhou,MarkAChia,SiegfriedKWagner,MuratSAyhan,DominicJWilliamson,RobbertRStruyven,
TimingLiu,MouchengXu,MateoGLozano,PeterWoodward-Court,etal. Afoundationmodelforgeneralizable
diseasedetectionfromretinalimages. Nature,622(7981):156–163,2023.
[7] BrianHonYinChung,JeffreyFongTingChau,andGaneKa-ShuWong. Rareversuscommondiseases: afalse
dichotomyinprecisionmedicine. NPJGenomicMedicine,6(1):19,2021.
[8] KushagraMahajan,MonikaSharma,andLovekeshVig. Meta-dermdiagnosis:Few-shotskindiseaseidentification
usingmeta-learning. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition
Workshops,pages730–731,2020.
[9] XiaoxiaoSun,JufengYang,MingSun,andKaiWang. Abenchmarkforautomaticvisualclassificationofclinical
skindiseaseimages. InComputerVision–ECCV2016: 14thEuropeanConference,Amsterdam,TheNetherlands,
October11-14,2016,Proceedings,PartVI14,pages206–222.Springer,2016.
[10] JeremyKawahara,SaraDaneshvar,GiuseppeArgenziano,andGhassanHamarneh. Seven-pointchecklistandskin
lesionclassificationusingmultitaskmultimodalneuralnets. IEEEjournalofbiomedicalandhealthinformatics,
23(2):538–546,2018.
[11] NoelCodella,VeronicaRotemberg,PhilippTschandl,MEmreCelebi,StephenDusza,DavidGutman,BrianHelba,
AadiKalloo,KonstantinosLiopyris,MichaelMarchetti,etal. Skinlesionanalysistowardmelanomadetection
2018: Achallengehostedbytheinternationalskinimagingcollaboration(isic). arXivpreprintarXiv:1902.03368,
2019.
[12] MdKamrulHasan,MdToufickEElahi,MdAshrafulAlam,MdTasnimJawad,andRobertMartí. Dermoexpert:
Skinlesionclassificationusingahybridconvolutionalneuralnetworkthroughsegmentation,transferlearning,
andaugmentation. InformaticsinMedicineUnlocked,28:100819,2022.
[13] SatinJain,UditSinghania,BalakrushnaTripathy,EmadAbouelNasr,MohamedKAboudaif,andAliKKamrani.
Deeplearning-basedtransferlearningforclassificationofskincancer. Sensors,21(23):8142,2021.
[14] VirajPrabhu,AnithaKannan,MuraliRavuri,ManishChaplain,DavidSontag,andXavierAmatriain. Few-shot
learningfordermatologicaldiseasediagnosis. InMachineLearningforHealthcareConference,pages532–552.
PMLR,2019.
[15] XiaomengLi,LequanYu,YuemingJin,Chi-WingFu,LeiXing,andPheng-AnnHeng. Difficulty-awaremeta-
learningforrarediseasediagnosis. InMedicalImageComputingandComputerAssistedIntervention–MICCAI
2020: 23rdInternationalConference,Lima,Peru,October4–8,2020,Proceedings,PartI23,pages357–366.
Springer,2020.
[16] DelongZhang,MengqunJin,andPengCao. St-metadiagnosis: Metalearningwithspatialtransformforrareskin
diseasediagnosis. In2020IEEEInternationalConferenceonBioinformaticsandBiomedicine(BIBM),pages
2153–2160.IEEE,2020.
[17] Wei Zhu, Haofu Liao, Wenbin Li, Weijian Li, and Jiebo Luo. Alleviating the incompatibility between cross
entropy loss and episode training for few-shot skin disease classification. In Medical Image Computing and
ComputerAssistedIntervention–MICCAI2020: 23rdInternationalConference,Lima,Peru,October4–8,2020,
Proceedings,PartVI23,pages330–339.Springer,2020.
[18] RishavSingh,VandanaBharti,VishalPurohit,AbhinavKumar,AmitKumarSingh,andSanjayKumarSingh.
Metamed: Few-shot medical image classification using gradient-based meta-learning. Pattern Recognition,
120:108111,2021.
[19] ShuhanLi,XiaomengLi,XiaoweiXu,andKwang-TingCheng. Dynamicsubcluster-awarenetworkforfew-shot
skindiseaseclassification. IEEETransactionsonNeuralNetworksandLearningSystems,2023.
[20] YunhuiGuo,NoelCCodella,LeonidKarlinsky,JamesVCodella,JohnRSmith,KateSaenko,TajanaRosing,
andRogerioFeris. Abroaderstudyofcross-domainfew-shotlearning. InComputerVision–ECCV2020: 16th
EuropeanConference,Glasgow,UK,August23–28,2020,Proceedings,PartXXVII16,pages124–141.Springer,
2020.
[21] SteinarLaenenandLucaBertinetto. Onepisodes,prototypicalnetworks,andfew-shotlearning. Advancesin
NeuralInformationProcessingSystems,34:24581–24592,2021.
15[22] YonglongTian,YueWang,DilipKrishnan,JoshuaBTenenbaum,andPhillipIsola. Rethinkingfew-shotimage
classification: agoodembeddingisallyouneed? InComputerVision–ECCV2020: 16thEuropeanConference,
Glasgow,UK,August23–28,2020,Proceedings,PartXIV16,pages266–282.Springer,2020.
[23] QianruSun,YaoyaoLiu,Tat-SengChua,andBerntSchiele. Meta-transferlearningforfew-shotlearning. In
ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,pages403–412,2019.
[24] Junsheng Xiao, Huahu Xu, DiKai Fang, Chen Cheng, and HongHao Gao. Boosting and rectifying few-shot
learningprototypenetworkforskinlesionclassificationbasedontheinternetofmedicalthings.WirelessNetworks,
29(4):1507–1521,2023.
[25] ZhiyongDai,JianjunYi,LeiYan,QingwenXu,LiangHu,QiZhang,JiahuiLi,andGuoqiangWang. Pfemed:
Few-shotmedicalimageclassificationusingpriorguidedfeatureenhancement. PatternRecognition,134:109108,
2023.
[26] DumitruErhan,AaronCourville,YoshuaBengio,andPascalVincent. Whydoesunsupervisedpre-traininghelp
deeplearning? InProceedingsofthethirteenthinternationalconferenceonartificialintelligenceandstatistics,
pages201–208.JMLRWorkshopandConferenceProceedings,2010.
[27] Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. Mask r-cnn. In Proceedings of the IEEE
internationalconferenceoncomputervision,pages2961–2969,2017.
[28] JonathanHuang,VivekRathod,ChenSun,MenglongZhu,AnoopKorattikara,AlirezaFathi,IanFischer,Zbigniew
Wojna,YangSong,SergioGuadarrama,etal. Speed/accuracytrade-offsformodernconvolutionalobjectdetectors.
InProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition,pages7310–7311,2017.
[29] WeiYing,YuZhang,JunzhouHuang,andQiangYang. Transferlearningvialearningtotransfer. InInternational
ConferenceonMachineLearning,pages5085–5094.PMLR,2018.
[30] AmirRZamir,AlexanderSax,WilliamShen,LeonidasJGuibas,JitendraMalik,andSilvioSavarese. Taskonomy:
Disentanglingtasktransferlearning. InProceedingsoftheIEEEconferenceoncomputervisionandpattern
recognition,pages3712–3722,2018.
[31] Amirreza Mahbod, Gerald Schaefer, Chunliang Wang, Georg Dorffner, Rupert Ecker, and Isabella Ellinger.
Transferlearningusingamulti-scaleandmulti-networkensembleforskinlesionclassification. Computermethods
andprogramsinbiomedicine,193:105475,2020.
[32] Zhiwei Qin, Zhao Liu, Ping Zhu, and Yongbo Xue. A gan-based image synthesis method for skin lesion
classification. ComputerMethodsandProgramsinBiomedicine,195:105568,2020.
[33] Lina Liu, Lichao Mou, Xiao Xiang Zhu, and Mrinal Mandal. Automatic skin lesion classification based on
mid-levelfeaturelearning. ComputerizedMedicalImagingandGraphics,84:101765,2020.
[34] AmirrezaMahbod,GeraldSchaefer,IsabellaEllinger,RupertEcker,AlainPitiot,andChunliangWang. Fusing
fine-tuneddeepfeaturesforskinlesionclassification. ComputerizedMedicalImagingandGraphics,71:19–29,
2019.
[35] Sema Atasever, Nuh Azginoglu, Duygu Sinanc Terzi, and Ramazan Terzi. A comprehensive survey of deep
learningresearchonmedicalimageanalysiswithfocusontransferlearning. ClinicalImaging,94:18–41,2023.
[36] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. InInternationalconferenceonmachinelearning,pages1126–1135.PMLR,2017.
[37] AlexNicholandJohnSchulman. Reptile: ascalablemetalearningalgorithm. arXivpreprintarXiv:1803.02999,
2(3):4,2018.
[38] AndreiARusu,DushyantRao,JakubSygnowski,OriolVinyals,RazvanPascanu,SimonOsindero,andRaia
Hadsell. Meta-learningwithlatentembeddingoptimization. arXivpreprintarXiv:1807.05960,2018.
[39] JakeSnell,KevinSwersky,andRichardZemel. Prototypicalnetworksforfew-shotlearning. Advancesinneural
informationprocessingsystems,30,2017.
[40] OriolVinyals,CharlesBlundell,TimothyLillicrap,DaanWierstra,etal. Matchingnetworksforoneshotlearning.
Advancesinneuralinformationprocessingsystems,29,2016.
[41] Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M Hospedales. Learning to
compare: Relationnetworkforfew-shotlearning. InProceedingsoftheIEEEconferenceoncomputervisionand
patternrecognition,pages1199–1208,2018.
[42] XiaoxuLi,XiaochenYang,ZhanyuMa,andJing-HaoXue.Deepmetriclearningforfew-shotimageclassification:
Areviewofrecentdevelopments. PatternRecognition,page109381,2023.
16[43] BharathHariharanandRossGirshick. Low-shotvisualrecognitionbyshrinkingandhallucinatingfeatures. In
ProceedingsoftheIEEEinternationalconferenceoncomputervision,pages3018–3027,2017.
[44] AntreasAntoniou,AmosStorkey,andHarrisonEdwards. Dataaugmentationgenerativeadversarialnetworks.
arXivpreprintarXiv:1711.04340,2017.
[45] RamnathKumar,TristanDeleu,andYoshuaBengio. Theeffectofdiversityinmeta-learning. InProceedingsof
theAAAIConferenceonArtificialIntelligence,volume37,pages8396–8404,2023.
[46] PuneetMangla,NupurKumari,AbhishekSinha,MayankSingh,BalajiKrishnamurthy,andVineethNBalasubra-
manian. Chartingtherightmanifold: Manifoldmixupforfew-shotlearning. InProceedingsoftheIEEE/CVF
winterconferenceonapplicationsofcomputervision,pages2218–2227,2020.
[47] Wei-YuChen,Yen-ChengLiu,ZsoltKira,Yu-ChiangFrankWang,andJia-BinHuang. Acloserlookatfew-shot
classification. arXivpreprintarXiv:1904.04232,2019.
[48] YuqingHu,VincentGripon,andStéphanePateux. Leveragingthefeaturedistributionintransfer-basedfew-shot
learning. InInternationalConferenceonArtificialNeuralNetworks,pages487–499.Springer,2021.
[49] WeiZhu,WenbinLi,HaofuLiao,andJieboLuo. Temperaturenetworkforfew-shotlearningwithdistribution-
awarelarge-marginmetric. PatternRecognition,112:107797,2021.
[50] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk
minimization. arXivpreprintarXiv:1710.09412,2017.
[51] SangdooYun,DongyoonHan,SeongJoonOh,SanghyukChun,JunsukChoe,andYoungjoonYoo. Cutmix:
Regularization strategy to train strong classifiers with localizable features. In Proceedings of the IEEE/CVF
internationalconferenceoncomputervision,pages6023–6032,2019.
[52] JieQin,JieminFang,QianZhang,WenyuLiu,XingangWang,andXinggangWang. Resizemix: Mixingdata
withpreservedobjectinformationandtruelabels. arXivpreprintarXiv:2012.11101,2020.
[53] ZhirongWu,AlexeiAEfros,andStellaXYu. Improvinggeneralizationviascalableneighborhoodcomponent
analysis. InProceedingsoftheeuropeanconferenceoncomputervision(ECCV),pages685–701,2018.
[54] BinLiu,YueCao,YutongLin,QiLi,ZhengZhang,MingshengLong,andHanHu. Negativemarginmatters:
Understandingmargininfew-shotclassification. InComputerVision–ECCV2020: 16thEuropeanConference,
Glasgow,UK,August23–28,2020,Proceedings,PartIV16,pages438–455.Springer,2020.
[55] YassirBendou,YuqingHu,RaphaelLafargue,GiuliaLioi,BastienPasdeloup,StéphanePateux,andVincent
Gripon. Easy—ensembleaugmented-shot-y-shapedlearning: State-of-the-artfew-shotclassificationwithsimple
components. JournalofImaging,8(7):179,2022.
17