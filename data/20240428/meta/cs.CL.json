[
    {
        "title": "Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials",
        "authors": "Ye FangZeyi SunTong WuJiaqi WangZiwei LiuGordon WetzsteinDahua Lin",
        "links": "http://arxiv.org/abs/2404.16829v1",
        "entry_id": "http://arxiv.org/abs/2404.16829v1",
        "pdf_url": "http://arxiv.org/pdf/2404.16829v1",
        "summary": "Physically realistic materials are pivotal in augmenting the realism of 3D\nassets across various applications and lighting conditions. However, existing\n3D assets and generative models often lack authentic material properties.\nManual assignment of materials using graphic software is a tedious and\ntime-consuming task. In this paper, we exploit advancements in Multimodal Large\nLanguage Models (MLLMs), particularly GPT-4V, to present a novel approach,\nMake-it-Real: 1) We demonstrate that GPT-4V can effectively recognize and\ndescribe materials, allowing the construction of a detailed material library.\n2) Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V\nprecisely identifies and aligns materials with the corresponding components of\n3D objects. 3) The correctly matched materials are then meticulously applied as\nreference for the new SVBRDF material generation according to the original\ndiffuse map, significantly enhancing their visual authenticity. Make-it-Real\noffers a streamlined integration into the 3D content creation workflow,\nshowcasing its utility as an essential tool for developers of 3D assets.",
        "updated": "2024-04-25 17:59:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.16829v1"
    },
    {
        "title": "IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages",
        "authors": "Harman SinghNitish GuptaShikhar BharadwajDinesh TewariPartha Talukdar",
        "links": "http://arxiv.org/abs/2404.16816v1",
        "entry_id": "http://arxiv.org/abs/2404.16816v1",
        "pdf_url": "http://arxiv.org/pdf/2404.16816v1",
        "summary": "As large language models (LLMs) see increasing adoption across the globe, it\nis imperative for LLMs to be representative of the linguistic diversity of the\nworld. India is a linguistically diverse country of 1.4 Billion people. To\nfacilitate research on multilingual LLM evaluation, we release IndicGenBench -\nthe largest benchmark for evaluating LLMs on user-facing generation tasks\nacross a diverse set 29 of Indic languages covering 13 scripts and 4 language\nfamilies. IndicGenBench is composed of diverse generation tasks like\ncross-lingual summarization, machine translation, and cross-lingual question\nanswering. IndicGenBench extends existing benchmarks to many Indic languages\nthrough human curation providing multi-way parallel evaluation data for many\nunder-represented Indic languages for the first time. We evaluate a wide range\nof proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5,\nGemma, BLOOM and LLaMA on IndicGenBench in a variety of settings. The largest\nPaLM-2 models performs the best on most tasks, however, there is a significant\nperformance gap in all languages compared to English showing that further\nresearch is needed for the development of more inclusive multilingual language\nmodels. IndicGenBench is released at\nwww.github.com/google-research-datasets/indic-gen-bench",
        "updated": "2024-04-25 17:57:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.16816v1"
    },
    {
        "title": "Make Your LLM Fully Utilize the Context",
        "authors": "Shengnan AnZexiong MaZeqi LinNanning ZhengJian-Guang Lou",
        "links": "http://arxiv.org/abs/2404.16811v1",
        "entry_id": "http://arxiv.org/abs/2404.16811v1",
        "pdf_url": "http://arxiv.org/pdf/2404.16811v1",
        "summary": "While many contemporary large language models (LLMs) can process lengthy\ninput, they still struggle to fully utilize information within the long\ncontext, known as the lost-in-the-middle challenge. We hypothesize that it\nstems from insufficient explicit supervision during the long-context training,\nwhich fails to emphasize that any position in a long context can hold crucial\ninformation. Based on this intuition, our study presents information-intensive\n(IN2) training, a purely data-driven solution to overcome lost-in-the-middle.\nSpecifically, IN2 training leverages a synthesized long-context question-answer\ndataset, where the answer requires (1) fine-grained information awareness on a\nshort segment (~128 tokens) within a synthesized long context (4K-32K tokens),\nand (2) the integration and reasoning of information from two or more short\nsegments. Through applying this information-intensive training on Mistral-7B,\nwe present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of\nFILM-7B for utilizing long contexts, we design three probing tasks that\nencompass various context styles (document, code, and structured-data context)\nand information retrieval patterns (forward, backward, and bi-directional\nretrieval). The probing results demonstrate that FILM-7B can robustly retrieve\ninformation from different positions in its 32K context window. Beyond these\nprobing tasks, FILM-7B significantly improves the performance on real-world\nlong-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while\nmaintaining a comparable performance on short-context tasks (e.g., 59.3->59.2\naccuracy on MMLU). Github Link: https://github.com/microsoft/FILM.",
        "updated": "2024-04-25 17:55:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.16811v1"
    },
    {
        "title": "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning",
        "authors": "Tianhui ZhangBei PengDanushka Bollegala",
        "links": "http://arxiv.org/abs/2404.16807v1",
        "entry_id": "http://arxiv.org/abs/2404.16807v1",
        "pdf_url": "http://arxiv.org/pdf/2404.16807v1",
        "summary": "Generative Commonsense Reasoning (GCR) requires a model to reason about a\nsituation using commonsense knowledge, while generating coherent sentences.\nAlthough the quality of the generated sentences is crucial, the diversity of\nthe generation is equally important because it reflects the model's ability to\nuse a range of commonsense knowledge facts. Large Language Models (LLMs) have\nshown proficiency in enhancing the generation quality across various tasks\nthrough in-context learning (ICL) using given examples without the need for any\nfine-tuning. However, the diversity aspect in LLM outputs has not been\nsystematically studied before. To address this, we propose a simple method that\ndiversifies the LLM generations, while preserving their quality. Experimental\nresults on three benchmark GCR datasets show that our method achieves an ideal\nbalance between the quality and diversity. Moreover, the sentences generated by\nour proposed method can be used as training data to improve diversity in\nexisting commonsense generators.",
        "updated": "2024-04-25 17:52:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.16807v1"
    },
    {
        "title": "Weak-to-Strong Extrapolation Expedites Alignment",
        "authors": "Chujie ZhengZiqi WangHeng JiMinlie HuangNanyun Peng",
        "links": "http://arxiv.org/abs/2404.16792v1",
        "entry_id": "http://arxiv.org/abs/2404.16792v1",
        "pdf_url": "http://arxiv.org/pdf/2404.16792v1",
        "summary": "Although the capabilities of large language models (LLMs) ideally scale up\nwith increasing data and compute, they are inevitably constrained by limited\nresources in reality. Suppose we have a moderately trained LLM (e.g., trained\nto align with human preference) in hand, can we further exploit its potential\nand cheaply acquire a stronger model? In this paper, we propose a simple method\ncalled ExPO to boost LLMs' alignment with human preference. ExPO assumes that a\nmedium-aligned model can be interpolated between a less-aligned (weaker) model,\ne.g., the initial SFT model, and a better-aligned (stronger) one, thereby\ndirectly obtaining this stronger model by extrapolating from the weights of the\nformer two relatively weaker models. On the AlpacaEval 2.0 benchmark, we show\nthat ExPO pushes models trained with less preference data (e.g., 10% or 20%) to\nreach and even surpass the fully-trained one, without any additional training.\nFurthermore, ExPO also significantly improves off-the-shelf DPO/RLHF models and\nexhibits decent scalability across model sizes from 7B to 70B. Our work\ndemonstrates the efficacy of model extrapolation in exploiting LLMs'\ncapabilities, suggesting a promising direction that deserves future\nexploration.",
        "updated": "2024-04-25 17:39:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.16792v1"
    }
]