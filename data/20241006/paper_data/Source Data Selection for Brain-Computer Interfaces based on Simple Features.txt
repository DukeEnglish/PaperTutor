Source Data Selection for Brain-Computer
∗
Interfaces based on Simple Features
Frida Heskebeck†, Carolina Bergeling‡, Bo Bernhardsson§
2024
This work has been submitted to the IEEE for possible
publication. Copyright may be transferred without notice,
after which this version may no longer be accessible.
Abstract
Thispaperdemonstratesthatsimplefeaturesavailableduringthecalibra-
tionofabrain-computerinterfacecanbeutilizedforsourcedataselection
to improve the performance of the brain-computer interface for a new
targetuserthroughtransferlearning. Tosupportthis,apublicmotorim-
agery dataset is usedfor analysis, and amethodcalled theTransfer Per-
formance Predictor method is presented. The simple features are based
on the covariance matrices of the data and the Riemannian distance be-
tween them. The Transfer Performance Predictor method outperforms
other source data selection methods as it selects source data that gives a
better transfer learning performance for the target users.
Keywords: Brain-Computer Interface, Calibration, Cross Sub-
ject,MachineLearning,RiemannianGeometry,SourceDataSe-
lection, Transfer Learning,
1 Introduction
Before a brain-computer interface (BCI) can be used by a new user, referred
to as the target user, the system needs to be calibrated. Calibration involves
collectingtrainingdatafromthetargetuserandtrainingtheunderlyingmachine
learningalgorithm,aprocessthattakesalongtimeandistiresomefortheuser.
∗ThisworkwaspartiallysupportedbytheWallenbergAI,AutonomousSystemsandSoft-
ware Program (WASP) funded by the Knut and Alice Wallenberg Foundation. The authors
aremembersoftheELLIITStrategicResearchAreaatLundUniversity.
†F. Heskebeck is with the Department of Automatic Control, Lund University, Lund,
Sweden
‡C. Bergeling is with the Department of Mathematics and Natural Sciences, Blekinge
TekniskaHo¨gskola,Karlskrona,Sweden
§B. Bernhardsson is with the Department of Automatic Control, Lund University, Lund,
Sweden
1
4202
tcO
3
]CH.sc[
1v06320.0142:viXraThiscalibrationrequirementisoneofthemainobstaclesforeverydayready-to-
use BCIs [1, 2].
One approach to reducing the calibration time is to utilize data from an-
other user, called source data, with transfer learning to train the underlying
machine learning algorithm for the target user. Then, less training data from
the target user needs to be collected, significantly reducing the calibration time
[3, 4]. However, it has been shown that transfer learning does not always work
for any combination of source and target data in BCI applications [5]. Thus,
it is desirable to identify a combination of source and target data that gives
the target user a good transfer learning performance. The success of transfer
learning largely depends on the so-called intra-subject performance—i.e., the
BCI’s performance when only the target user’s data is used—information that
is not available when a new target user begins using the BCI [5]. This leaves us
with the research question of quickly identifying good source data for a target
user, only using features that are available during the calibration of the BCI.
This paper demonstrates that simple features of the target data, available
during the calibration of the BCI system, can be used to select suitable source
datafortransferlearning. Tovalidatethisapproach, theTransfer Performance
Predictor (TPP) method is presented for source data selection, which improves
the BCI performance compared to several baseline methods for source data
selection. As always in processing data for BCIs, details in the processing can
be changed to improve the performance for a specific user or scenario of the
BCI. To avoid getting lost in these case-to-case details, this paper uses a public
datasetwithdatafrommanyusers,afixedprocessingpipeline,andonetransfer
learning method.
Section 2 presents other research on source data identification for BCIs.
Section 3 provides some background to BCI systems and the transfer learn-
ing method for readers unfamiliar with BCIs. Section 4 presents the dataset
and methods used in the paper. Section 5 presents and discusses the results.
Section 6 puts the results into the bigger picture of source data selection for
BCI calibration and outlines future research. Finally, Section 7 summarizes the
paper.
2 Related work
Selecting suitable source data for transfer learning is not a novel idea in itself;
it has been studied before. This paper’s novelty lies in its approach to source
data selection. There are many approaches to source data selection in the
literature. One approach is to evaluate the transfer learning performance for
each combination of source and target users and use the results to determine
if the users are compatible [6]. This corresponds to the baseline source data
selection method called Oracle in this paper. An alternative approach is to
compare the distance between the class means for the target and source data
[7, 8]. This approach is similar to the baseline source data selection method
called Distance in this paper. Yet another approach is to study the power
2spectral densities for resting-state EEG [9]. A different approach used in some
papers,[10,11],istousetheso-calledsequentialforwardfloatingsearchmethod
with different improvement measures for the method. The sequential forward
floating search finds suitable source data by iteratively including and excluding
source data until a set of source data giving a good BCI performance for the
target user has been found. In one paper, [10], an improvement measure based
on the scatter matrices of the class means is used. In another study, [11], an
improvement measure based on the transfer learning accuracy is used. All the
papers mentioned above use source selection as part of a classification pipeline
and aim to improve classification accuracy. However, they are generally not
concernedaboutthecalibrationtimeoftheBCI,andsomeofthemethodstake
a long time to identify the source user, making them unusable in an everyday
BCI setting.
3 Background
Thissectionprovidesbackgroundtoelectroencephalography(EEG)basedbrain-
computerinterfaces(BCI),howBCIdatacanbeclassified,andtheRiemannian
ProcrustesAnalysis(RPA)transferlearningmethodusedinthispaper. Readers
familiar with these topics can skip to Section 4.
3.1 EEG-based motor imagery BCIs
BCIsenabletheuseofthoughtcommandsasinputtocomputersinsteadofother
input modalities, such as moving a computer mouse to control the computer.
Most BCIs use EEG to measure brain activity from electrodes placed on the
scalp of the user. EEG signals are noisy, and extracting the thought commands
from EEG signals requires advanced preprocessing of the signals and machine
learning algorithms to decipher the meaning. The data in this paper is from
the so-called motor imagery (MI) BCI paradigm, which means that the user
imaginesmovingabodypart,andtheaimistodecodewhichbodyparttheuser
imaginedmoving. InaBCIsetting,apredefinedsetofbodymovementsisused,
where each movement corresponds to a specific command, such as ‘right hand
→movecursorright’whencontrollingascreencursor. Athoroughintroduction
to BCIs is given in [2, 12].
3.2 Classification of BCI data using Riemannian Geome-
try
There are many approaches to decoding and classifying BCI data. In recent
years, a common approach for MI data has been to use the covariance matrix
for a trial’s EEG data as a feature representation and then use Riemannian
geometry when comparing covariance matrices from different trials. The term
trial refers to the experimental session where the user imagines the movement
3of one body part. A thorough explanation of Riemannian approaches in BCIs
isgivenin[13]. Here, asummaryispresentedtoprovidecontextforthispaper.
The covariance matrix, C , is found from the EEG data during an MI trial
i
and is a feature representing the imagined movement of one body part during
trial i. A dataset consists of labeled covariance matrices (C ,y ) where y ∈
i i i
{1,...,K} is the label indicating which of the K predefined body parts was
imagined moved during trial i. Let X ∈ Rch×s be the EEG data for trial i
i
recorded with ch electrodes for s time samples. The covariance matrix for that
trial is calculated as
1
C = X X⊤.
i s i i
Covariance matrices are symmetric positive definite (SPD) and live on the
Riemannian space of SPD matrices P . Using the Affine Invariant Riemannian
n
Metric (AIRM), the distance between two covariance matrices on the manifold
P is
n
δ (C ,C )=||log(C−1/2C C−1/2)|| ,
R i j i j i F
which hereafter is called the Riemannian distance. Using the Riemannian dis-
tance, thegeometricmeanM (acovariancematrix)ofthesetC ofLcovariance
matrices is
(cid:88)
M =argmin δ2(X,C ). (1)
R i
X∈Pn
Ci∈C
Assuming that the data belongs to K different classes, we can calculate the
mean for each class, M , using (1) and the covariance matrices with label k,
k
C ={C |y =k}, as
k i i
(cid:88)
M =argmin δ2(X,C ). (2)
k R i
X∈Pn
Ci∈Ck
The dispersion, d, of the data belonging to class k, around its geometric class
mean M will be defined as
k
1 (cid:88)
d = δ2 (M ,C ), (3)
k |C | R k i
k
Ci∈Ck
where |C | is the number of covariance matrices in the set C .
k k
Using this Riemannian framework, a common classification algorithm is the
minimum distance to mean (MDM) classification where a new sample C is
new
classified as the class for the mean M it is closest to,
k
y =argmin δ2 (M ,C ).
new R k new
k∈K
3.3 Transfer learning with the RPA method
The Riemannian Procrustes Analysis (RPA) is introduced and explained in
detail in [13]. The code is implemented in the pyRiemann Python package [14].
Here, a summary is presented to provide context for this paper.
4Assuming that the data for a trial i is represented by the covariance matrix
C withlabely ,asdescribedabove. Thesetofsource dataS withLS covariance
i i
matrices and target data T with LT covariance matrices are
S =(cid:8) (CS,yS) for i=1,...,LS(cid:9) ,
i i
T =(cid:8) (CT,yT) for i=1,...,LT(cid:9) .
i i
For the source and target domain data separately, the mean M for all the data
and the mean for each class M is found with (1) respectively (2) as MS, MS,
k k
MT, and MT. Similarly, the dispersion d for all data and the dispersion d for
k k
eachclassk isfoundwith(3)asdS,dS,dT,anddT. Themeansanddispersions
k k
of the data are used in the RPA method for transfer learning and in this paper
as features for the Transfer Performance Predictor method.
Transfer learning with the RPA method is done in three steps [13]:
1. Re-center the data so that MS and MT become identity.
2. Equalize the dispersions dS and dT by moving the matrices along their
geodesic to the identity matrix.
3. Rotate the data around the geometric mean (identity) to align the class
means MS and MT for each class k.
k k
The first two steps can be done on unlabeled data, the unsupervised part of
the RPA method, but the last step requires labeled data, the supervised part
of the RPA method. After transfer learning, the source data and target data
are aligned in the sense that the data from each class of the two datasets are
matched.
4 Material and Method
This paper uses a motor imagery (MI) dataset where the users in each trial
imagine moving either their hands or feet. The task is to determine which
bodyparttheuserimaginedmoving[15]. Eachtrial’scovariancematrixisused
as a feature, and minimum distance to mean (MDM) classification is used for
the MI classification. The transfer learning of two users’ data, the target and
source user, is done with the Riemannian Procrustes Analysis (RPA) transfer
learning method [16]. In a follow-up paper [5], the authors conclude that the
mostpredictivefeaturefordeterminingwhethertransferlearningwiththeRPA
method will be successful is the target user’s intra-subject MI classification
accuracy. However, as they note, this feature is not available in real calibration
settingswherenopriorinformationaboutthenewtargetuserisknown, raising
the research question of how to identify suitable source data for a target user
[5].
This paper presents the Transfer Performance Predictor (TPP) method for
source data selection in a BCI transfer learning setting. The method predicts
the transfer learning performance for a target and source user based on simple
5data features that are available during the calibration of a BCI. The method
outperforms other source data selection methods and uses features available
duringaBCI’scalibration,thustakingasteptowardimprovingBCIcalibration.
The following subsections present details about the dataset and the data
processing, the MI classification and the transfer learning, the TPP method,
and how the source data selection methods are compared. The source code for
the project is available online1.
4.1 Dataset and Preprocessing
The public Physionet dataset, [15], is used for the analysis in this paper. The
datasetincludeslabeledEEGdataforexperimentswheretheusersconducteda
handsvs. feetmotorimaginarytask,aright-handvs. left-handmotorimaginary
task, a hands vs. feet motor movement task, and a right-hand vs. left-hand
motor movement task. Both motor imaginary tasks were analyzed, but only
the results for the hands vs. feet motor imaginary task is presented in this
paperastheresultissimilarforbothtasks. Thedatasetincludesdatafrom109
users, and each user has data from about 45 trials of the hands vs. feet motor
imaginary task.
The MNE Python toolbox is used for the preprocessing of the data [17, 18].
The nine EEG channels F3, Fz, F4, C3, Cz, C4, P3, Pz, and P4 are used as
theycoverthemotorcortexofthebrain[2]. TheEEGdataisbandpassfiltered
in the range 7-35 Hz as it covers the frequency bands where interesting EEG
featuresareexpectedtoappear[2]. Eachtrialisfrom1secaftercueonsetuntil
2 sec after cue onset to avoid any initial transients from the stimuli onset. The
9×9covariancematrixforeachtrialisusedtorepresentthetrial’sdata. Seethe
providedcode1 forimplementationdetails. Onlyuserswhohadanintra-subject
MI classification accuracy above 65% (98 users) were used in the paper, as it
is known from previous research that the RPA algorithm only works for users
with sufficient intra-subject performance [5].
4.2 MI classification with transfer learning
The MI task is classified with covariance matrices as features using the MDM
classification based on the Riemannian geometry for SPD matrices with the
Affine Invariant Riemannian Metric (AIRM) [13]. The transfer learning is done
withtheRPAmethod[16]. Targetdomaindatareferstodatafromthenewuser
where a limited amount of data and knowledge about the data exist. Source
domaindatareferstoexistingdatafromotherusersthatcanbeusedfortransfer
learning. The analysis in this paper assumes that the mean covariance matrix
foreachMIclassandthedispersionaroundtheseclassmeansareknownforthe
target data. How much training data is needed to estimate these features is a
topic for future research.
For each combination of source–target users, a subset of the data from the
target user, called target training data, and all data from the source user are
1https://gitlab.control.lth.se/FridaH/source-data-selection-public
6usedfortheRPAtransferlearningmethod. Thetargettrainingdataisthedata
thatneedstobecollectedduringthecalibrationphaseoftheBCI.Theremain-
ing data from the target user is used as target test data. We omit the second
stepoftheRPAmethod, asitwasfoundtodistortthedatamorethanimprove
it. Thisdistortionislikelyduetopoorestimationofthedispersioninthetarget
data, given the limited amount of available data. With more target data and,
consequently, a more accurate dispersion estimate, this step should be included
in the RPA method. After transfer learning, the MDM classifier is trained with
the source training data, not the target training data, and tested on the target
test data in order to ensure that it is the cross-subject transfer learning perfor-
mance that is evaluated and not the intra-subject performance. The resulting
cross-subject MI classification accuracy, also called transfer learning accuracy
or cross-subject performance, is stored.
The above-described procedure for splitting the target data into training
and test data, doing RPA transfer learning, and then MDM classification is
hereafter called MI classification. The MI classification is done with 5-fold
cross-validation, meaning that the above procedure is repeated five times for
eachsource–targetcombination,withdifferentsplitsoftargettraining/testdata
ineachfold. Theaveragecross-subjectMIclassificationaccuracyoverthe5-fold
cross-validation is shown in Fig. 1. For the case where the source and target
user are the same (the highlighted cells in Fig. 1), the intra-subject accuracy is
shown. Inthiscase, notransferlearningisdone, andthetargettrainingdatais
used for the MDM classification. The target test data is still used as test data.
4.3 The Transfer Performance Predictor (TPP) method
This paper’s main point is to show that simple features describing the source
andtargetdatacanbeusedtoselectsourcedataforBCItransferlearning. This
is concretely shown with the Transfer Performance Predictor (TPP) method,
which outperforms other source data selection methods described in the fol-
lowing subsection. The TPP method predicts the cross-subject MI classifica-
tion accuracy, also called transfer learning accuracy. In other words, the TPP
method predicts the color for the source–target combinations in Fig. 1. For
source data selection, the source data with the highest predicted cross-subject
MI classification accuracy for the target user is selected.
TheTPP methoduses18featuresforthepredictionofcross-subjectperfor-
mance. The features are listed in Table 1 for target data T, source data S, MI
class 1 and MI class 2. The features are categorized into distances, dispersions,
accuracies, and differences and are mainly based on the distances between the
class means for the source and target data. The observant reader will notice
thatmostofthesefeaturesarethesameasthoseusedintheRPAtransferlearn-
ing algorithm and those used in the MDM classifier; this is not a coincidence.
Thesefeaturesareselectedsincetheyareeasytofindwithlimitedtrainingdata
and are important since both the RPA and MDM classification algorithms are
based on versions of these features. The features are calculated after the data
has been recentered but before the data has been rotated in the RPA transfer
7Table 1: The features for the Transfer Performance Predictor method are cat-
egorized into distances, dispersions, accuracies, and differences.
Distances Dispersions
δ2(MT,MT) dT
R 1 2
δ2(MS,MS) dT
R 1 2 1
δ2(MT,MS) dT
R 1 1 2
δ2(MT,MS) dS
R 1 2
δ2(MT,MS) dS
R 2 1 1
δ2(MT,MS) dS
R 2 2 2
Accuracies Differences
Source data intra-subject δ2(MT,MT)−δ2(MS,MS)
R 1 2 R 1 2
δ2(MT,MS)−δ2(MT,MS)
R 1 2 R 1 1
δ2(MT,MS)−δ2(MT,MS)
R 2 1 R 2 2
dS −dT
1 1
dS −dT
2 2
learning algorithm.
Scikit-learn, [19], is used for the machine learning implementation. The
pipeline for the TPP method is Scikit-learn’s robust scaler followed by a neural
network with two hidden layers (50, 50) with the relu activation function; see
the provided code1 for implementation details. Other pipelines for the TPP
method were also tested and performed well. This one was selected for its
consistent performance across all analyzed datasets (only the results from the
feet vs. hands dataset are presented in the paper, as previously explained).
The result is verified by leave-k-groups-out cross-validation. In each fold,
some users are used as test users, and their data is excluded from the training
set. The test data is used to evaluate the performance of the prediction and, in
particular, the performance of the BCI if the TPP method is used for source
data selection compared to other source data selection methods (described in
the next section). Each user is used as a test target in one of the ten folds.
4.4 Source data selection
As explained before, the overall point of this paper is to show that simple
features available during the calibration of a BCI system can be used to select
source data for transfer learning, which can streamline the calibration of BCIs.
The source data selection task is to identify the source user that gives a target
user the highest cross-subject performance. Looking at Fig. 1, which shows the
transfer learning accuracy for all combinations of source and target users, and
8assuming that the target user is at row i, the source data selection task is to
predict which source user gives the darkest blue value for row i.
The compared methods for source data selection in this paper are:
• Intra-subject –Nosourcedataisused,buttheintra-subjectperformance
is. The intra-subject performance is the accuracy of MI classification
if only the target training data is used. This corresponds to the BCI’s
performance if no transfer learning is done and is a baseline for what a
source selection method should achieve in performance.
• Random source –Thesourcedataisselectedatrandom. Ausefulsource
data selection method should outperform the Random source method.
• Distance – The source data is selected as the source data with class
means closest to the target data. In other words, the source S is selected
as
δ2(MT,MS)+δ2(MT,MS)
S =argmin R 1 1 R 2 2
2
S
This method is similar to what was done in [7]. The distances is divided
by two in order to be the mean distance.
• Best source – The source data is selected as the source user with the
highest intra-subject accuracy. This method is based on the assumption
that the user who, in some sense, is the “best” should be the best to use
as source data.
• Best teacher – The source data is selected as the source user that is the
best for most other target users. This corresponds to selecting the source
user to the left in Fig. 1 as the source user.
• Max of methods – The combined version of the Best source, Best
teacher, and TPP source data selection methods. Each included method
suggestsasourceuserandtheonewithbesttransferlearningperformance
is selected as the source user.
• Transfer Performance Predictor (TPP) – The presented method
in this paper. It uses simple features available during the calibration to
predictthecross-subjectperformanceandselectsthesourceuserwiththe
highest predicted performance; see details in Section 4.3. The method is
abbreviated TransPerfPred in Fig. 2.
• Oracle – The source data is selected as the best source data for each
target user. It represents the best possible performance for the BCI. This
methodissimilartowhattheydidin[6]butisnotaviableoptionduring
the calibration of a BCI as it takes too long time to evaluate all source
users to find the best one.
9Asmentionedabove,evaluatingallavailablesourcedatawiththetarget(the
Oracle method) is impractical during BCI calibration, as it would be too time-
consuming with a large amount of source data. This is primarily because the
rotationstepintheRPAtransferlearningalgorithmistime-intensive,requiring
solving an optimization problem in the Riemannian space of SPD matrices to
find the rotation matrix for each source-target combination [16]. However, it
is possible to evaluate a few source data candidates and then select the best
among them. Assuming that six source candidates can be evaluated, it means
that the source selection methods Distance, Random source, Best source, Best
teacher,andTPP selectsixsourcecandidates. FortheMaxofmethods method,
which is the combination of three source selection methods, it means that each
of the included methods selects two source candidates to get six candidates
in total. For the Oracle and Intra-subject methods, there is always only one
candidate. The result from this analysis is shown in Fig. 2. In Fig. 3, the
methods’ performance is compared to the Oracle method for different numbers
of source data candidates.
5 Results and Discussion
ThissectionpresentstheresultsanddiscussestheMIclassificationusingtransfer
learningandthesourcedataselectionmethods. Thefollowingsection,Section6,
contextualizes the findings within the broader research question of source data
selection and outlines potential future research directions.
5.1 MI classification with transfer learning
ThematrixinFig.1showstheaverage5-foldcross-validationresultsfortransfer
learningMIclassificationforallcombinationsofsource–targetdata. Eachrowin
thematrixcorrespondstoatargetuser,andeachcolumncorrespondstoasource
user. The matrix color at index i,j reflects the cross-subject MI classification
accuracy for combining the target user at row i and the source user at column
j. Cross-subjectMIclassificationaccuracy,ortransferlearningaccuracy,means
the classification accuracy of target test data when the MI classifier is trained
using the target training data and source data after transfer learning. White
color corresponds to a 75% accuracy, blue color to higher than 75% accuracy,
andredcolortolowerthan75%accuracyasshownbythecolorbartotherightof
thematrix. Anaccuracyof100%(darkblue)isthemaximum,andanaccuracy
of 50% (dark red) corresponds to the chance level for the MI classification task.
Thehighlightedcellscorrespondtoindiceswherethetargetandsourceusers
are the same. The color in these cells is the intra-subject MI classification for
that user. Intra-subject MI classification means the classification accuracy of
target test data when the MI classifier is trained on only target training data
without transfer learning. Note that the highlighted cells are not on the main
diagonal since the columns and rows are sorted separately, as explained in the
next paragraph.
10100
90
80
70
60
50
Source user
Figure 1: Accuracy of MI classification after using the RPA transfer learning
method, average over 5-folds. The rows are target users, and the columns are
source users. The colors correspond to the cross-subject MI classification accu-
racy for each combination of target and source users. The highlighted cells are
the intra-subject accuracies. For an arbitrary row, we can see that the transfer
learning accuracy differs a lot depending on which source data is used, which
is the reason why source data selection for BCIs is important. The rows are
sortedindecreasingorderoftherowsum, andcolumnsaresortedindecreasing
order of the column sum. An interpretation of this sorting is that target users
that benefit from many source users are found at the top (good students), and
sourceusersthatarebeneficialformanytargetusersarefoundtotheleft(good
teachers).
The matrix’s rows are sorted in descending order of row summation. This
means a target user with high transfer learning accuracy for many source users
is found at the top, and a user with low transfer learning accuracy for most
source users is found at the bottom. The matrix’s columns are sorted similarly,
in descending order of column summations. This means that a user whose data
is beneficial for many target users is found to the left of the matrix, and a user
whosedataisdisadvantageousformanytargetusersisfoundtotherightofthe
matrix. Thus, the order of users is different in the rows and columns, which is
11
resu
tegraT
)%(
ycarucca
gninrael
refsnarTwhy the highlighted cells, corresponding to indices where the source and target
user are the same, are not found on the main diagonal.
ThereareafewobservationstohighlightfromFig.1. Thefirstisifweinter-
pretthetargetusersasstudentsandthesourceusersasteachers,anassumption
would be that a good teacher, i.e., someone who can teach any student, would
alsobeagoodstudent, i.e., someonewhocanlearnfromanyteacher. However,
this is not the case since the best teachers, placed to the left in the matrix, are
foundtobe“middle-performing”students. Wecanconcludethisfromthehigh-
lighted cells for these users, which are the furthest to the left but in the middle
of the rows. Another observation from Fig. 1 is the cluster of highlighted cells
inthebottomrightcorner. Fromthese,wecangenerallysaythatabadstudent
is often a bad teacher. Besides this, there is no clear clustering of the source
and target users for this matrix sorting. A final observation is that the good
students at the top of the matrix generally have high intra-subject accuracies,
as seen from the highlighted cells, and the worst students at the bottom of the
matrix have low intra-subject accuracies. This is expected from the results of
[5], whichsaidthattheintra-subjectperformanceisthemosttellingfeaturefor
the transfer learning performance.
Looking at a single row, it is clear that a target user benefits from source
data selection for transfer learning since some source data have low transfer
learning accuracy and some have high transfer learning accuracy. For the very
best students, at the top of the matrix, it doesn’t matter as much which source
dataisselected;anysourcedataperformswell. Butforatargetuserinthemid-
dle of the matrix, we see that finding a good source user could give a transfer
learningaccuracyupto80%whileabadsourceusercouldgiveatransferlearn-
ing accuracy down to 60%, which makes a difference for the final performance
oftheBCI.Eventheworstperformingstudent, atthelowestrow, benefitsalot
from source data selection, and it may be for these middle- and less-performing
users that source selection is the most important.
5.2 Source data selection
The matrix in Fig. 2 shows a comparison of the different source data selection
methods. The numbers and colors represent the mean difference in transfer
learning accuracy when the source data is selected with the method in the row
compared to the method in the column. The difference between the transfer
learning accuracies for each target user is calculated before the mean is calcu-
lated. Forexample,themeandifferencebetweentheOracle andRandomsource
methods, located in the lower-left corner of the matrix, is 2.08. This indicates
thattheOracle methodidentifiesasourceuserthatyields,onaverage,2.08per-
centage points higher transfer learning accuracy compared to the source user
selected by the Random source method. The matrix is skew-symmetric since
the value in the matrix shows the difference between the method in the row
and the method in the column, which has the opposite sign when the row and
columnchange. AsdescribedinSection4.4,theresultinFig.2isfromwhenthe
methods select six candidates for source data. All six candidates are evaluated,
12Intra-subject -3.40 -3.44 -3.47 -3.75 -3.85 -4.29 -5.49
Random source 3.40 -0.04 -0.06 -0.34 -0.45 -0.88 -2.08 4
Distance 3.44 0.04 -0.02 -0.30 -0.41 -0.84 -2.04
2
Best source 3.47 0.06 0.02 -0.28 -0.38 -0.82 -2.02
0
Best teacher 3.75 0.34 0.30 0.28 -0.10 -0.54 -1.74
2
Max of methods 3.85 0.45 0.41 0.38 0.10 -0.44 -1.64
TPP 4.29 0.88 0.84 0.82 0.54 0.44 -1.20 4
Oracle 5.49 2.08 2.04 2.02 1.74 1.64 1.20
Figure 2: Comparision of different source data selection methods. The colors
andnumbersrepresentthemeandifferenceintransferlearningaccuracybetween
themethodintherowandthemethodinthecolumn. Thematrixisthusskew-
symmetric. A higher number means that the method in the row, on average,
selectssourcedatathatgiveseachtargetuserahighertransferlearningaccuracy
than the method in the column. The highlighted cells indicate methods where
the difference between the transfer learning accuracies for each target user is
notstatisticallydifferentfrom0, meaningthatonecannotsaythatonemethod
is better. As expected, the Oracle method is the best.
and the best of these is selected as the source data.
The highlighted cells indicate comparisons between methods where the dif-
ference in transfer learning accuracy for the target users is not significantly
different from zero using the Wilcoxon signed-rank test with a p-value of 0.05.
This means that for the highlighted cells, one cannot say that one method is
betterthantheother. LookingatthecomparisonoftheDistance methodtothe
Max of methods method, the cell is highlighted but has a value of -0.41. This
means that, on average, the difference is -0.41 when comparing these methods.
13
tcejbus-artnI
ecruos
modnaR ecnatsiD
ecruos
tseB
rehcaet
tseB
sdohtem
fo
xaM PPT
elcarO
)stinu
%(
ecnamrofrep
ni
ecnereffid
naeMHowever, when looking at the difference for each target user, most differences
arearound0withamedianvalueof0. The-0.41valuecomesfromafewtarget
users where the Max of methods method has found a significantly better source
user than the Distance method, which bumps up the mean value. Thus, based
onthestatisticaltest,wecannotsaythateithermethodfoundsourcedatathat
performed better than the other, even though the value was -0.41. The median
value is not shown here but is zero or close to zero for the highlighted cells.
OneobservationfromtheseresultsisthattheIntra-subjectmethod forsource
selection is the worst compared to all methods. This is due to the minimal
training data for the MI classifier. The low performance of the method implies
that in a calibration setting where there is only a limited amount of target
training data available, using transfer learning is generally better than using
only the target training data. The difference between the Intra-subject method
and the Oracle method tells us how much there is to gain from doing transfer
learning.
A second observation is when comparing the Oracle method with the other
methods, a value closer to zero means that the compared method is closer to
findingasourceuserthatperformsaswellastheOracle sourcedata. Thenum-
bers show that the Transfer Performance Predictor (TPP) method performs
the closest to the Oracle method.
A third observation is that the Random source method puts a baseline for
when a method is better than chance. The highlighted cells show that the
Distance andBest source methodsarenotsignificantlybetterthantheRandom
source method. TheBestsource methodselectssourceuserswiththebestintra-
subject MI classification accuracies. The fact that this method is not better
thanchanceindicatesthatitismoreimportantthatthesourceandtargetusers
are similar to each other than the source user being the “best” BCI user, i.e.,
having good intra-subject MI classification. Measuring the similarity of users is
a fascinating topic and will be explored in future research.
A fourth observation is that the Best teacher method is better than chance,
which is reasonable since it selects source users that benefit most target users.
However, it is not significantly better than the Distance method, as indicated
bythehighlightedcell,eventhoughthemeandifferenceof0.36isrelativelyhigh
betweenthesemethods. Thereasonforthisissimilartotheexamplepreviously;
there are some target users for whom the Best teacher method finds a better
source user than the Distance method, bumping up the mean value, but for
most users, the methods are equally good.
A final observation is that the TPP method is significantly better than all
other methods except for the Oracle method, which is, as expected, better.
Since the TPP method outperforms the other methods, we can conclude that
usingsimplefeaturestoselectsourcedataisaworkingandpromisingapproach.
The TPP method does not find the optimal source data but is a step towards
improving the source selection for transfer learning during BCI calibration.
Fig. 3 shows the methods’ performance compared to the Oracle method
for different numbers of source candidates. The rightmost column in Fig. 2
correspondstoFig.3atsixsourcecandidates. FortheMax of methods method,
140
1
2
3
4 Intra-subject
Random source
5 Distance
Best source
6
Best teacher
Max of methods
7
TPP
Oracle
8
1 3 5 7 9 11 13 15 17 19 21
Number of source candidates
Figure 3: Comparision of the source data selection methods for different num-
bers of source data candidates. The y-axis shows the method’s performance
compared to the Oracle performance. The x-axis shows the number of candi-
datessuggestedbyeachmethodforsourceselection. Thefigureshowsthesame
numbers for six source candidates as the rightmost column in Fig. 2. The more
candidates each method can suggest, the closer to Oracle performance. The
TPP method outperforms the other for three or more suggested candidates.
only results for multiples of three are shown since the Max of methods is a
collection of three methods and thus will have source candidates in multiples
of three. In other words, when the methods included in the Max of methods
method suggest three source candidates each, the Max of methods method will
have nine source candidates to compare and should thus be compared with the
other methods when they suggest nine candidates. When looking at Fig. 3, one
should remember that some methods are not statistically different, as we saw
in Fig. 2. However, general conclusions can still be drawn.
From Fig. 3, we see that the TPP method outperforms the other methods,
except for the Oracle method, for all numbers of source candidates higher than
three. For most BCI settings, it is reasonable to have time to evaluate three
or more source candidates, which means that the TPP method is profitable for
mostBCIapplications. Anotherobservationisthatthemoresourcecandidates,
15
elcarO
ot
derapmoc
ecnamrofrePthe better all the methods perform. This is reasonable since selecting more
source candidates increases the probability of picking a good one. What is a
bit unexpected is that only the TPP method outperforms the Random source
method even when the methods select many source candidates.
6 Conclusions and Future Research
Thissectiondiscusseshowtheresultsrelatetothebiggerpictureofsourcedata
selection for the calibration of BCI and outlines future research directions.
6.1 MI classification with transfer learning
The most important conclusion and takeaway from the results of the MI clas-
sification with transfer learning is that source data selection for BCI is needed
since the transfer learning performance differs quite a lot depending on which
source data is used for a target user. As noted in the Results and Discus-
sion section, the difference between a good and a bad source user is higher for
low-performing target users than high-performing target users. Thus, source
selection is essential for low-performing target users.
Using the interpretation from the Results and Discussion section that a
targetuserisastudentandasourceuserisateacher,wecanfirstconcludethat
if it were the case that a good student is also a good teacher, all highlighted
cells in the matrix in Figure 1 would be placed on the main diagonal of the
matrix. AsstatedaboveintheResultsandDiscussionsection,thebeststudent
(the top row) is a relatively bad teacher, and the best teacher (the left column)
is a relatively bad student. This means that the data from a user that benefits
fromtransferlearningfrommanyotherusersisnotnecessarilygooddatatouse
for transfer learning for other users. This contradicts the intuition of transfer
learning for BCIs, as one would expect that if source user A is good for target
user B, source user B would be good for target user A. The reason why there
is an implication and not an equivalence in the transferability of source and
target data is something to study in future research. Related to this is that
one would assume that there are clusters of users who benefit from each other
in terms of transfer learning. The results of this work can neither confirm nor
contradict the existence of clusters and cannot say anything about how to find
such clusters. That is also a topic for future research.
6.2 FeaturesfortheTransferPerformancePredictor method
AsmotivatedinSection4.3,thefeaturesfortheTransferPerformancePredictor
(TPP) method are chosen because they are accessible during calibration of the
BCI with a limited amount of target training data and are used by both the
RPA transfer learning method and the MDM classification method. Since the
TPP method outperforms other source data selection methods, we conclude
16that these simple features can effectively guide source data selection, which is
the central aim of this paper.
Looking at the features used, see Table 1, one could find more variants of
thedistancemeasurethanthoseinthetable. However, thedistancesinTable1
represent all possible distances between the source and target datasets since
many distances are the same. To be precise, the included distances represent
all possible distances between the class means MT,MT,MS, and MS since for
1 2 1 2
example, δ2(MT,MS) is the same as δ2(MS,MT).
R 1 2 R 2 1
Atthispoint,arelevantquestionishowmuchtargettrainingdataisneeded
to estimate these features. In this paper, these features are assumed to be
known, and we do not study how much data is needed to estimate them accu-
rately; it is a topic for future research.
Afinalnoteonthefeaturediscussionisthattheuseddatasethastwoclasses,
meaningthetargetandsourcedatahavetwomeancovariancematrices, onefor
each class. If the dataset had more than two classes, it would mean more mean
covariance matrices, which in turn would mean more features from distance,
dispersion, and difference measures. The principle for the TPP method would
remain the same.
6.3 Source data selection methods
There are a few interesting observations from the source data selection com-
parison to discuss. Firstly, as expected, the Oracle method is the best source
data selection method. However, in a BCI setting where we aim to reduce the
calibration time for a new target user, doing transfer learning for all available
source data to identify the one with the best performance takes too long to be
a viable approach. This is why source data selection is needed. Apart from
the TPP method outperforming the other source data selection methods, the
strength of the TPP method is that it uses simple features of the target data
that are available during the calibration of the BCI. This means that the TPP
method can select a source user without the heavy computations required for
transfer learning as in the Oracle method. Secondly, picking a random source
for transfer learning is better than doing no transfer learning at all, assuming
that no more target training data can be collected. Since we also know that
it makes a significant difference which source user is used for transfer learning,
this only strengthens the argument that source selection for BCI calibration is
crucial.
Asmentionedintheresultssection,allmethodsperformclosertotheOracle
method when more candidates for source data selection are selected. This is
not too strange if we consider the Random source selection method. If the
Random source method can select nine candidates instead of three, it has a
higher probability of selecting a good one. A similar reasoning applies to all
methods. Whenfewercandidatescanbeselected,morerequirementsareplaced
on the source selection method to make a good selection.
AnalternativetotheTPP methodistotrainalargeneuralnetworkcapable
of handling everything from preprocessing to MI classification, similar to the
17approaches used in image processing. While such networks are beginning to
emerge for BCI data, the current limitation is the lack of sufficient BCI data
to train them to the same level of reliability as image processing networks.
However,asmoreBCIdatabecomesavailable,thesenetworkswilllikelybecome
more prevalent, and the need for source selection may diminish in the future.
As noted in the introduction, BCI research involves tuning hundreds of pa-
rameters in EEG preprocessing, transfer learning, and MI classification. This
paper demonstrates that the TPP method is effective for the studied case, sug-
gesting it could be applicable to other scenarios. However, since all BCI data
isunique, case-specificconsiderationsarenecessary. Nonetheless, thecoreprin-
ciple of the TPP method—predicting transfer learning accuracies from simple
features for source data selection—remains relevant across all BCI cases.
6.4 Future work
In the paper, two main directions for further research have been mentioned.
This section summarizes these to facilitate further research for researchers who
want to continue working on this.
The first research direction concerns how much training data is needed to
accurately estimate the mean covariance matrices. In this paper, it is assumed
that the mean covariance matrix for each class in the target data, MT and
1
MT, is known. The mean covariance matrices are estimated from the target
2
data, and it is important to know how much data is needed to have a good
estimate as it determines how much target training data needs to be collected
from the target user during the calibration of the BCI. It is a tradeoff between
reducing the calibration time by collecting less data and having a sufficiently
good estimate of the covariance matrices.
The second research direction relates to how users can be scored as similar
or dissimilar. An intriguing question raised in the Results and Discussion sec-
tionishowuserscanbeclusteredintogroupsofsimilarindividuals,whereusers
withineachgroupbenefitfromtransferlearningfromoneanother. Thisrequires
identifying a similarity measure between users that can be utilized during BCI
calibration to assign a new target user to an appropriate group. This question
also touches upon how transfer learning effectively can be made using multi-
ple source data. Many of the referenced papers in the Related Works section,
Section 2, have used some weighing function or voting classifier to do multi-
source transfer learning. However, a transfer learning method similar to the
RPAmethodbutbasedonmanysimilaruserswouldbeinterestingtofind. An-
other alluring question related to the similarity of users is why we observe that
user A is beneficial for user B in a transfer learning setting, while user B is not
beneficial for user A, as discussed in a previous subsection of this Conclusions
and Future Research section.
187 Summary
During BCI calibration, there is no time to evaluate all source data candidates
available for transfer learning. Thus, source data selection is needed. Finding
goodsourcedataisimportant,asthefinalperformanceoftheBCIdifferssignif-
icantlydependingonwhichsourcedatawasusedduringtransferlearning. How
to select the source data based on features that are available during the BCI
calibration is an open research question. The results of this paper show that
simplefeaturesofthetargetdata,availableduringBCIcalibration,canbeused
to predict the transfer learning performance for a source-target data combina-
tionandcanthusbeeffectivelyappliedforsourcedataselectioninBCItransfer
learning. The presented Transfer Performance Predictor method outperforms
other source data selection methods on the studied BCI dataset.
Contribution
Frida Heskebeck: Conceptualization, Methodology, Software, Writing-Orig-
inal Draft, Writing - Review & Editing, Visualization, Project administration.
Carolina Bergeling: Conceptualization, Methodology, Supervision.
BoBernhardsson: Conceptualization,Methodology,Writing-Review&Edit-
ing, Supervision, Funding acquisition.
Acknowledgement
Thanks to Pex Tufvesson and Ask H¨allstr¨om for reading the manuscript and
providing feedback on the text.
References
[1] Fabien Lotte. “Signal Processing Approaches to Minimize or Suppress
Calibration Time in Oscillatory Activity-Based Brain–Computer Inter-
faces”. In: Proceedings of the IEEE 103.6 (June 2015), pp. 871–890. issn:
1558-2256. doi: 10.1109/JPROC.2015.2404941.
[2] FridaHeskebeck.“OnCalibrationAlgorithmsforReal-TimeBrain-Computer
Interfaces”. Licentiate Thesis. Lund: Department of Automatic Control,
Lund Institute of Technology, Lund University, Oct. 2023.
[3] Vinay Jayaram et al. “Transfer Learning for BCIs”. In: Brain–Computer
InterfacesHandbook:TechnologicalandTheoreticalAdvances.Ed.byChang
S. Nam, Anton Nijholt, and Fabien Lotte. New York: CRC Press, Jan.
2018,pp.425–441.isbn:978-1-351-23195-4.doi:10.1201/9781351231954.
[4] Zitong Wan et al. “A Review on Transfer Learning in EEG Signal Analy-
sis”. In: Neurocomputing 421 (Jan. 2021), pp. 1–14. issn: 0925-2312. doi:
10.1016/j.neucom.2020.09.017. (Visited on 01/12/2024).
19[5] Pedro Luiz Coelho Rodrigues, Marco Congedo, and Christian Jutten.
“”When Does It Work?”: An Exploratory Analysis of Transfer Learn-
ing for BCI”. In: BCI 2019 - 8th International Brain-Computer Interface
Conference. Graz, Austria, Sept. 2019. (Visited on 04/09/2024).
[6] Fulin Wei et al. “A Multi-Source Transfer Joint Matching Method for
Inter-SubjectMotorImageryDecoding”.In:IEEETransactionsonNeural
Systems and Rehabilitation Engineering 31 (2023), pp. 1258–1267. issn:
1558-0210.doi:10.1109/TNSRE.2023.3243257.(Visitedon07/04/2024).
[7] Toshiki Orihara, Kazi Mahmudul Hassan, and Toshihisa Tanaka. “Active
SelectionofSourcePatientsinTransferLearningforEpilepticSeizureDe-
tection Using Riemannian Manifold”. In: ICASSP 2023 - 2023 IEEE In-
ternationalConferenceonAcoustics,SpeechandSignalProcessing(ICASSP).
June2023,pp.1–5.doi:10.1109/ICASSP49357.2023.10095272.(Visited
on 07/04/2024).
[8] Zizhuo Wu et al. “Multi-Source Online Transfer Algorithm Based on
Source Domain Selection for EEG Classification”. In: Mathematical Bio-
sciences and Engineering 20.3 (Jan. 2023), pp. 4560–4573. issn: 1551-
0018. doi: 10.3934/mbe.2023211. (Visited on 01/31/2024).
[9] Eunjin Jeon, Wonjun Ko, and Heung-Il Suk. “Domain Adaptation with
Source Selection for Motor-Imagery Based BCI”. In: 2019 7th Interna-
tional Winter Conference on Brain-Computer Interface (BCI).Feb.2019,
pp.1–4.doi:10.1109/IWW-BCI.2019.8737340.(Visitedon07/04/2024).
[10] Yilu Xu, Xin Huang, and Quan Lan. “Selective Cross-Subject Transfer
Learning Based on Riemannian Tangent Space for Motor Imagery Brain-
Computer Interface”. In: Front. Neurosci. 15 (Nov. 2021). issn: 1662-
453X. doi: 10.3389/fnins.2021.779231. (Visited on 07/04/2024).
[11] Yan Li et al. “Transfer Learning Based on Hybrid Riemannian and Eu-
clidean Space Data Alignment and Subject Selection in Brain-Computer
Interfaces”. In: IEEE Access 9 (2021), pp. 6201–6212. issn: 2169-3536.
doi: 10.1109/ACCESS.2020.3048683. (Visited on 07/04/2024).
[12] ChangSNametal.“Brain–ComputerInterface:AnEmergingInteraction
Technology”.In:Brain–ComputerInterfacesHandbook:Technologicaland
Theoretical Advances. Ed. by Chang S. Nam, Anton Nijholt, and Fabien
Lotte.NewYork:CRCPress,Jan.2018,pp.12–52.isbn:978-1-351-23195-
4. doi: 10.1201/9781351231954.
[13] FlorianYger,MaximeBerar,andFabienLotte.“RiemannianApproaches
inBrain-ComputerInterfaces:AReview”.In:IEEETransactionsonNeu-
ral Systems and Rehabilitation Engineering 25.10 (Oct. 2017), pp. 1753–
1762. issn: 1558-0210. doi: 10.1109/TNSRE.2016.2627016. (Visited on
01/12/2024).
[14] Alexandre Barachant et al. pyRiemann/pyRiemann: v0.5. Version v0.5.
2024.doi:10.5281/zenodo.8059038.url:https://pyriemann.readthedocs.
io (visited on 03/15/2024).
20[15] Gerwin Schalk et al. “BCI2000: A General-Purpose Brain-Computer In-
terface (BCI) System”. In: IEEE Trans Biomed Eng 51.6 (June 2004),
pp. 1034–1043. issn: 0018-9294. doi: 10.1109/TBME.2004.827072. url:
https://www.physionet.org/content/eegmmidb/1.0.0/ (visited on
03/15/2024).
[16] Pedro Luiz Coelho Rodrigues, Christian Jutten, and Marco Congedo.
“RiemannianProcrustesAnalysis:TransferLearningforBrain–Computer
Interfaces”.In:IEEE Transactions on Biomedical Engineering 66.8(Aug.
2019),pp.2390–2401.issn:1558-2531.doi:10.1109/TBME.2018.2889705.
[17] Alexandre Gramfort et al. “MEG and EEG Data Analysis with MNE-
Python”. In: Frontiers in Neuroscience 7.267 (2013), pp. 1–13. doi: 10.
3389/fnins.2013.00267.
[18] EricLarsonetal.MNE-Python.Versionv1.5.1.Sept.2023.doi:10.5281/
zenodo.8322569. url: https://mne.tools (visited on 03/15/2024).
[19] F. Pedregosa et al. “Scikit-learn: Machine Learning in Python”. In: Jour-
nal of Machine Learning Research 12 (2011), pp. 2825–2830.
21