CHOSEN: Compilation to Hardware Optimization Stack for
Efficient Vision Transformer Inference
MohammadErfanSadeghi ArashFayyazi
UniversityofSouthernCalifornia UniversityofSouthernCalifornia
LosAngeles,California,USA LosAngeles,California,USA
sadeghim@usc.edu fayyazi@usc.edu
SuhasSomashekar MassoudPedram
UniversityofSouthernCalifornia UniversityofSouthernCalifornia
LosAngeles,California,USA LosAngeles,California,USA
ssomashe@usc.edu pedram@usc.edu
ABSTRACT ViTsrelyonaseriesofidenticalencoderblockstoprogressively
VisionTransformers(ViTs)representagroundbreakingshiftinma- extractcomplexfeaturesfromanimage.Theseencoderblockscon-
chinelearningapproachestocomputervision.Unliketraditional sistoftwoprincipalcomponents:Multi-headedAttention(MHA)
approaches,ViTsemploytheself-attentionmechanism,whichhas andFeed-ForwardNetwork(FFN),eachprefacedwithalayernor-
beenwidelyusedinnaturallanguageprocessing,toanalyzeimage malizationblock.EmbeddedwithinMHAandFFNarelinearlayers,
patches.Despitetheiradvantagesinmodelingvisualtasks,deploy- GELU,andsoftmax,integratedviatworesidualconnectionsthat
ingViTsonhardwareplatforms,notablyField-ProgrammableGate bookendthenormalizationstages.Theoutputofthefinalencoder
Arrays(FPGAs),introducesconsiderablechallenges.Thesechal- blockgoesthroughaclassifiertoobtaintheclasspredictions.
lengesstemprimarilyfromthenon-linearcalculationsandhigh ImplementingVisionTransformers(ViTs)andothertransformer-
computationalandmemorydemandsofViTs.Thispaperintroduces basedmodelsonField-ProgrammableGateArrays(FPGAs)presents
CHOSEN,asoftware-hardwareco-designframeworktoaddress uniquechallengesthatstemfromthearchitectures‚Äôcomplexityand
thesechallengesandofferanautomatedframeworkforViTde- resourcedemands.Theprimaryhurdlesincludethehighdemand
ploymentontheFPGAsinordertomaximizeperformance.Our formemoryduetotheextensivenumberofparametersandthe
frameworkisbuiltuponthreefundamentalcontributions:multi- intensivecomputationrequiredforprocessingtheself-attention
kerneldesigntomaximizethebandwidth,mainlytargetingbenefits acrossimagepatches.FPGAs,althoughflexibleandcapableofpar-
ofmultiDDRmemorybanks,approximatenon-linearfunctions allelprocessing,oftenstrugglewithlimitedon-chipmemoryand
thatexhibitminimalaccuracydegradation,andefficientuseofavail- bandwidth,whichcanbottlenecktheperformanceofViTs.Addi-
ablelogicblocksontheFPGA,andefficientcompilertomaximize tionally,thestaticnatureofFPGAarchitecturescomplicatesthe
theperformanceandmemory-efficiencyofthecomputingkernels implementationofthedynamicallyvaryingcomputationalpatterns
bypresentinganovelalgorithmfordesignspaceexplorationto ofViTs.
findoptimalhardwareconfigurationthatachievesoptimalthrough- Awiderangeofmethodshasbeenexploredtoimprovetheeffi-
putandlatency.Comparedtothestate-of-the-artViTaccelerators, ciencyofViTs,includingapproacheslikequantization[6],model
CHOSENachievesa1.5xand1.42ximprovementinthethroughput pruning[7],tokenpruning[8],andlow-rankapproximation[9].
ontheDeiT-SandDeiT-Bmodels. However,deployingViTsinpracticalapplicationsrequiresinnova-
tiveapproachesinhardwareoptimization,suchasstrategicmemory
managementandmulti-kerneldesignforincreasedthroughput.The
CHOSENframeworkintegratesthesestrategieseffectivelyinad-
1 INTRODUCTION
ditiontoitscompilertoofferacompletestackforautomatingthe
Thelandscapeofcomputervisionhasbeenfundamentallytrans- FPGAdeploymentofViTs.Themaincontributionsofthispaper
formed with the advent of deep learning, among which Vision aresummarizedbelow.
Transformers(ViTs)[1‚Äì4]haveemergedasaparticularlypromis-
ingapproach.Unliketraditionalconvolutionalneuralnetworks
(CNNs)thatrelyonlocalreceptivefields,ViTsleveragethepower ‚Ä¢ Wepresentanend-to-endframeworkcalledCHOSEN,which
ofself-attentionmechanismstocaptureglobaldependencieswithin generateshigh-performanceViTacceleratorssuitedtoatarget
animage,enablingamorecomprehensiveunderstandingofvisual FPGAdevicefromahigh-leveldescriptionoftheViTmodelin
data.ThiscapabilityhasplacedViTsattheforefrontofresearch, anymachinelearningframework,suchasPyTorchwhilemaking
demonstratingstate-of-the-artperformanceacrossawiderangeof effectiveuseoftheavailableFPGAresourcesandmemoryband-
tasksincomputervision.Overall,deeplearninghasrevolutionized width.NotethatCHOSENcanhandleanytransformer-based
variousdomainsbyprovidingrobustalgorithmscapableoflearning model,whilethispaperfocusesonViTs.
complexpatternsfromlargedatasets,thusenablingunprecedented ‚Ä¢ WedevelopoptimizedsynthesizableC++templates,achieving
advancementsintheapplicationofartificialintelligence[5]across high-throughputacceleratordesignsonFPGAsbyfocusingon
numerous fields, from healthcare to entertainment to scientific multi-kerneldesigntomaximizebandwidthutilizationandkeep
research. all the used resources busy. The CHOSEN ViT follows static
4202
luJ
71
]VC.sc[
1v63721.7042:viXraschedulingandhasadifferentmemorylayoutforeachoperation generatessynthesizableC-levelcodedescriptionsthatcanbeused
toachievefullburstreaddatafromoff-chipmemorybanks. togenerateanFPGAbitstream.
‚Ä¢ Weintroduceapowerfulcompiler(CHOSENCompiler)formap-
pingagiventransformer-basedmodelrunningonanydataset 4 ACCELERATORDESIGNOPTIMIZATIONS
ontoouroptimizedacceleratordesignbyconvertingthenet- Thissectionfocusesonimprovingtheefficiencyandperformance
workmodeltoacomputationalgraph,schedulingthegraph‚Äôs ofaViTacceleratorusingFPGAdevice-awareoptimizations.Solu-
execution,andoptimizingitsnodesbyleveragingcombining tionsincludedataplacementoptimizationstoreducethenumber
matricesifwehaveenoughresources. ofaccessestoDRAM,theuseoftheon-chipmemorytobalance
‚Ä¢ Comparedtothestate-of-the-artwork,usingouroptimizations computationvs.memorybandwidth,andapproximationsfornon-
focusedonmulti-kerneldesignandmaximizingbandwidthuti- linearitiesfunctions.
lization,weachievesignificantimprovementinthethroughput.
4.1 KernelArchitecture
2 RELATEDWORK Ouracceleratorisamulti-kerneldesignwhereeachkernelper-
ThissectionincludespriorworksonViTarchitectures,compiler formsthesameoperation.Eachkernelcomprises(i)a1Darrayof
optimizations,andapproximationsofnon-linearfunctions. processingelements(PEs),whichareresponsibleforexecutingthe
MACoperationsassociatedwiththematrixmultiplications,(ii)a
2.1 Compiler memoryhierarchyfeedingdatatothesaid1Darraycompromising
ofregisterfiles,theon-chipmemory(BlockRAMsandUltraRAMs
Previouseffortshaveexploredsoftware-hardwareco-designframe-
onFPGAdevices),andexternaloff-chipmemory(DRAM),and(iii)
worksforefficientlydeployingViTs.TheVAQFframework[10]
aprocessingunit(PU)thatperformsapproximatednon-linearity
dynamicallyadjustsweightsprecision,activationsprecision,and
andotherrequiredoperationsliketheadditionofskipandmain
hardwaresettingsbasedonFPGAresourcesandtargetFPS.ViTCoD
pathsasshowninFig.1
[11]proposesmethodsforpruningandreconfiguringtheattention
FPGA FPGA FPGA FPGA
mapsinViTstocreateeitherdenserorsparserpatterns,whichhelps DDR DDR DDR DDR
Memory Memory Memory Memory
inmanagingcomputationalworkloadsmoreeffectively.However, Bank Bank Bank Bank
bothVAQF[10]andViTCoD[11]donotleverageoff-chip(DDR)
memoryparallelismanddonotintroduceasetofapproximations
forefficientlycalculatingnon-linearfunctionsonFPGAs. Controller & Computing Computing Kernel
Scheduler Kernel
Computing 1D PE array
2.2 Hardwarearchitecture Co Km ep rnu eti lng Co Km ep rnu eti lng
Kernel
Ap np or no -x lii nm ea at re d
ssrreeffffuuBB
SeveralarchitectureshavebeenproposedtoaccelerateVisionTrans- SLR0 SLR1 SLR2 functions
former(ViT)andTransformerinferenceonFPGAs,typicallyem- VU9P
ployingquantizationtechniquesthatreducethemodelsizeand Figure1:OverviewofMulti-kernelCHOSEN-ViTarchitecture
computationalrequirementsbyconvertingweightsandactivations ontheVU9PFPGA.
Forour1DarrayofPEs,weadoptthearchitectureproposedin
to8-bitrepresentationssuchasAuto-ViT-Accpresentedin[12].ME-
[14].Theirarchitectureisusedtoperformefficientmultiplication
ViT[13]isastate-of-the-artViTacceleratorthatmitigatesthehigh- ofAandBmatriceswhereA‚ààRùëõ√óùëò andB‚ààRùëò√óùëö
.Theoutput
bandwidthdemandsofVisionTransformers(ViTs)duringinference matrixisC‚ààRùëõ√óùëö
.Thecomputationalresourcesareorganized
byemployingasingle-loadpolicyandutilizesmulti-purposebuffers intoùëÉ ùëõof1Dprocessingelements,whichencapsulateavectoroper-
withinamemory-efficientprocessingelement(ME-PE)tominimize ationofùëÉ ùëöcomputeelements(i.e.,DSPsontheFPGA).Tosupport
memorytrafficforViTacceleratorsonFPGAs.Theyachievethisby
ahierarchicalhardwaredesign,eachmatrixisfurtherdecomposed
avoidingstoringandreloadinginmatrixmultiplicationsandbuffer-
intoseverallevelsoftiling.WetilematrixAandBcolumnand
ingtheintermediateresults.However,ME-ViTdoesnotexplore row-wisewithfactorofùëá ùëõandùëá ùëö,respectively.
multipleDDRbankstoachievehigherbandwidth.
4.2 Non-linearapproximations
3 CHOSENFRAMEWORK
Implementingthenon-linearfunctionsoftheVisionTransformer
CHOSENisacompilationframeworkthatenablestheoptimization (ViT)presentssignificantchallengesduetotheirinherentcomputa-
anddeploymentofViTsonFPGAs.Ittakesahigh-leveldescrip- tionalcomplexity.ToenableanefficientFPGA-basedimplementa-
tionoftheViTmodelspecifiedinPyTorchandgeneratesahigh- tionofViT,weemployedasetofapproximationsfornon-linearities
performanceViTacceleratordesigntailoredtotheFPGAdevice. aspresentedinPEANO-ViT[15].Specifically,theyapproximated
TheCHOSENcompileroptimizestheinferencegraphassociated theinversesquarerootfunctioninlayernormalizationusingbit
withtheViTmodel,aligningitwiththeacceleratordesign.Next, manipulationoperationsandpre-storedfractionalpowersoftwo.
itproduceshardwareparametersfortheacceleratorandastatic Forthesoftmaxfunction,theyutilizedaPad√©-basedapproximation
scheduleforexecutingitsvariousoperations.Adetailedexplana- oftheexponentialfunction,complementedbybitmanipulation
tionofthestatespaceexplorationprocessusedtofindtheopti- techniquestoeliminatedivisionoperations.Additionally,theGELU
malhardwareparametersisprovidedinSection5.Finally,using activationfunctionwasreplacedwithapiece-wiselinearapproxi-
optimizedacceleratorcomponenttemplates,CHOSENcompiler mationthatcloselymimicstheoriginalfunction.Thesestrategic
2DDR Banks
approximations not only facilitate the efficient implementation Original Matrix #1 #2 #3 #4
ofViTsonFPGAsbutalsoexhibitnegligibledegradationinthe
model‚Äôsaccuracy.WeusedalloftheseapproximationsintheCHO-
Fill in DDR banks
SENViTimplementationtoachievehighthroughputandbalance
usageofDSPandLUTsinourdesign.
4.3 MemoryLayoutandDataPlacement
Toutilizetheoff-chipmemorybandwidth,wegroupactivation
(a)StoringamatrixinfourDDRbanks.
data(A)aswellasweights(B)beforesendingthemtotheon-chip
memory.Forbothmatrices(e.g.,AandB),wegroup(cid:106)ùê¥ùëãùêº 2_ √óùëä ùê∑ùêº ùëäùê∑ùëáùêª(cid:107)
Compute Kernel #1
Softmax
oftheminthecolumndimension.Bythispacking,weperformfull
burst read/write of data from/to the memory banks and utilize
Compute Kernel #2
themaximumpossibleburstsize(512-bitwidth)allowableonthe
AdvancedeXtensibleInterface(AXI)busofthetargetFPGAboard.
Compute Kernel #3
WeuseallavailableDDRbankstoloadandstorethedatatomax-
imizethebandwidth.Wedividetheoriginalmatrixcolumn-wise
intoùêµùëÅ,whichdenotesthetotalnumberofavailableDDRbanks Compute Kernel #4
andis4inourcase(seeSection6formoredetailsregardingthe
1 2 3 4 5 6 7 8 9 10 11 12
targetFPGAboard),smallermatricesandstoreeachsmallermatrix Cycle
inoneDDRbankasshowninFig.2a.Intheprovidedexample (b)SchedulingforSoftmaxoperations.
showninFig.2,wehave4DDRbanksand4hardwarekernels.For Gelu
operationsoutsideofthehead,likekey,query,valuematrices,and
Compute Kernel #1
Gelucomputations,webringthedatafromthesamerowbutwith
differentDDRbanksandpassthemtodifferenthardwarekernels
Compute Kernel #2
forcomputation(seeFig.2c).Forthehead-wiseoperations,includ-
ingsoftmax,webringthedatafromthesamebankandthesame
row(cid:108) ùêµùëÅ ùëÅ‚Ñé(cid:109)
timestofinishtherequiredcomputationsforonerow
Compute Kernel #3
whereùëÅ ‚Ñérepresentsthenumberofheads.Forinstance,inthecase Compute Kernel #4
ofViT-B,ittakesthreeroundstofinisharow,asshowninFig.2b.
WithrespecttolayerNorm,whereeachhardwarekernelrequires 1 2 3 4
Cycle
thewholerowtocompleteitscomputation,suchascalculatingthe
meanandvariance,CHOSENoffersefficientrotatingscheduling (c)SchedulingforLayerNormoperations.
LayerNorm
(seeFig.2d).Hardwarekernel#1operatesonthefirstpartofrow
#1fromDDRbank#1,whilehardwarekernel#2performsonthe Compute Kernel #1
secondpartofrow#2fromDDRbank#2.Similarly,otherkernels
accesscorrespondingdata.Inthenextround,Hardwarekernel#1
Compute Kernel #2
operatesonthesecondpartofrow#1fromDDRbank#2,while
hardwarekernel#2performsonthethirdpartofrow#3fromDDR
Compute Kernel #3
bank#3.Inthisapproach,wemaximizetheutilizationofpotential
bandwidthandkeepallhardwarekernelsbusy. Compute Kernel #4
5 CHOSENCOMPILER 1 2 3 4
Cycle
Thissectionelaboratesonourcompilerframework,designedto (d)SchedulingforGeluoperations.
enhancetheexecutionefficiencyoftransformermodelsonFPGAs. Figure2:Schedulingofdifferentoperationswhileusingmultiple
ThecompileradeptlyutilizestheunderlyingFPGAarchitecture, DDRbanks.DifferentpatternsrepresentdifferentDDRmemory
focusingonoptimalscheduling,preciseoperationmappingtohard- banks,whiledifferentcolorsrepresentdifferentrows.
wareresources,andminimizingthedatamovement,therebyfacili-
(1) ModelConversion:Initially,thetransformermodel,developed
tatinghigh-performanceVitaccelerationhardwareonFPGAs.
usingframeworkssuchasPyTorchorTensorFlowistransformed
intoaDirectedAcyclicGraph(DAG).Thisgraphoutlinesthe
5.1 CompilerDesignandExecutionFramework
model‚Äôscomputationaldependenciesanddataflow,providinga
Ourcompilerframeworkstartswithahigh-leveldescriptionofa basisforfurtheranalysisandoptimization.
ViTmodelandconvertsitintoahardware-acceleratedimplementa- (2) GraphAnalysisandOptimization:Thecompilerconductsan
tiontailoredtothetargetFPGA‚Äôsarchitecture.Thetransformation in-depthanalysisoftheDAGtoclassifyoperationsanddeduce
ofaViTmodelintoanFPGA-compatibleformatunfoldsthrough essentialcharacteristicssuchasoperationtypes,datasizes,and
severalsteps,asexplainedbelow. dependencychains.Thisinformationiscrucialforoptimizingthe
3executionscheduleandeffectivelymappingtheoperationsonto Algorithm1ExhaustiveSearchforFindingOptimalTileParame-
theFPGA.ItisworthmentioningthattheCHOSENCompilercan ters
optimizeitsnodesbyleveragingcombiningmatricesifwehave 1: Input:ModelGraphùê∫,DataWidthùê∑ùëä,MemoryConstraints
enoughresources.Forinstance,wecancalculateùëòmatrixinone ùëÄ
shotandthenseparateitcolumn-wiseforeachheadorcalculate 2: Output:Optimaltilesizesùëá ùëõ,ùëá ùëö,ParallelismFactorsùëÉ ùëõ,ùëÉ ùëö
khead-wiseandnamethemùëò_‚Ñématrices.Ifwehaveenough 3: Initializeminimumcost:min_cost‚Üê‚àû
wre es io gu hr tc mes ato rn iceth se oft ùëòar ,g ùëûe ,t anF dPG ùë£A to, iw ne crec aa sn ee tv he en sec co on nc dat de in ma et ne st ioh ne 4: CalculateùëÉ ùëö:ùëÉ ùëö ‚Üê (cid:106)ùê¥ùëãùêº 2_ √óùëä ùê∑ùêº ùëäùê∑ùëáùêª(cid:107) //Fixedvaluebasedon
datawidth
wof eth cae nse ic no cn red am seat tr hi ex bto ata cc hhi se iv zeep toot ae cn ht ii ea vll ey ph oig teh ne tr iùëá aùëö lly.I hn igp har ea rl ùëále ùëõl,
.
5 6:
:
S foet ro ùëáp ùëöti ‚ààm {a fl_ eap sm ib‚Üê leùëáùëÉ ùëöùëö
sizes}do
(3)
A Dl el so igf nth Se pse acc eas Ee xs pre losu ralt tii on nla :r Tg he er cd oe msi pg in les rp aa sc se e.
ssesvarioushard-
7: forùëÉ ùëõ ‚àà{feasibleùëÉ ùëõsizes}whereùëÉ ùëõ < ùëá ùëÉùëö
ùëö
do
8: forùëá ùëõ ‚àà{feasibleùëá ùëõsizes}do
wareconfigurationsandoperationalparametersusingacustom
9:
Cost:cost‚Üêcompute_cost(ùëÉ ùëõ,ùëÉ ùëö,ùëá ùëõ,ùëá ùëö,ùê∫,ùëÄ)
heuristic-based algorithm for design space exploration. This
10:
ifcost<min_costthen
phaseascertainstheoptimaltilingandparallelizationstrategies,
11: Updateminimumcostandoptimalsizes:
ensuringtheyalignwithboththehardware‚Äôscapabilitiesand
12: min_cost‚Üêcost
thecomputationaldemandsofthemodel.
13:
optimal_pn‚ÜêùëÉ
ùëõ
(4) CodeGenerationandDeployment:Thefinalphaseisthegen-
14:
optimal_tn‚Üêùëá
ùëõ
erationofsynthesizableC++templatesandhardwaredescription
15:
optimal_tm‚Üêùëá
ùëö
code,culminatingintheproductionoftheFPGAbitstream.This
16: endif
transformationconvertsthehigh-levelsoftwaremodelintoa
17: endfor
practicalhardwareimplementation.
18: endfor
19: endfor
5.2 CompilerOptimizationforMatrix
20:
returnoptimal_pn,optimal_pm,optimal_tn,optimal_tm
Multiplications
Optimizingmatrixmultiplicationforhardwareimplementations
necessitatesafine-grainedanalysisofcomputationalresourcesand feasiblesizeisevaluatedtofindtheoptimalconfigurationof
datamanagement.Thissectiondescribesourapproachtodeter- computeandmemoryresources.
miningoptimaltileparameters,whichiscrucialforenhancingthe (2) ParallelismFactorùëÉ ùëõ:Reflectsthenumberofprocessingele-
performanceofmatrixmultiplicationcomputations,especiallyin mentsandisconstrainedbyùëÉ ùëõ < ùëá ùëÉùëö ùëö,ensuringthatdataforthe
transformermodels.Wepresentanewalgorithmthatbalancesthe nextroundofcomputationisalreadydistributedtoallPEs.
computationalloadacrossprocessingelementswhileminimizing (3) TilingFactorùëá ùëõ:Correspondstothenumberofelementsfrom
memoryaccesslatenciesandmaximizingthroughput. onecolumnofmatrixùê¥loadedpercycle,which,whencombined
Thealgorithmforcomputingoptimaltileparameters,aspre- withùëá ùëö,shouldnotexceedthetotalmemorycapacityùëÜasùëá ùëõ√ó
sentedinAlgorithm1,outlinesasystematicapproachtoidentifying ùëá ùëö ‚â§ùëÜ.
themosteffectivetilingandparallelizationstrategies.Thealgorithm
5.2.3 CostFunctionforOptimizingMultipleMatrixMultiplications.
exploresadesignspacedefinedbytheconstraintsoftheavailable
Inoptimizingtransformermodels,particularlyformatrixmulti-
hardwareresources,thepropertiesofthematrixoperation,and
plicationswithinattentionmechanisms,thisfunctionisdesigned
thecompiler‚Äôshigh-levelunderstandingofthetransformermodel
tominimizelatencybybalancingthecomputationalloadacross
representedasaDirectedAcyclicGraph(DAG).
processingelements(PEs)andcomputationunitswithinPEs.The
5.2.1 InitializationandFixedParameters. TheparallelismfactorùëÉ ùëö costfunction,Latency,iscalculatedasfollows:
iscomputedasùëÉ ùëö = (cid:106)ùê¥ùëãùêº 2_ √óùëä ùê∑ùêº ùëäùê∑ùëáùêª(cid:107) ,establishingafixednumber ùêøùëéùë°ùëíùëõùëêùë¶=ùëáùëúùë°ùëéùëôùê∂ùë¶ùëêùëôùëíùë†
ofcomputationunitsbasedonthedataandAXIwidth.ForDDR4 ùêπùëüùëíùëûùë¢ùëíùëõùëêùë¶
memory,aminimumof512bitsasAXIwidthmustbetransferred ùëá ùëõ√óùëá ùëö√óùëò√óùëõùë¢ùëöùëáùëñùëôùëíùë†ùëÖùëúùë§√óùëõùë¢ùëöùëáùëñùëôùëíùë†ùê∂ùëúùëô√óùëòùëíùëüùëõùëíùëôùêπùëéùëêùë°ùëúùëü
=
tomakeupfortheI/Oclockmultiplier,andmuchlongerburstsare ùëÉ ùëõ√óùëÉ ùëö√óùêπùëüùëíùëûùë¢ùëíùëõùëêùë¶
requiredtosaturateDDRbandwidthinpractice. (1)
Whereùëáùëúùë°ùëéùëôùê∂ùë¶ùëêùëôùëíùë†isthetotalnumberofcyclesrequiredtoperform
5.2.2 ExplorationofTilingParameters. Theexplorationoftilesizes allmultiplicationoperations.ùêπùëüùëíùëûùë¢ùëíùëõùëêùë¶istheoperatingfrequency
ùëá ùëõ andùëá ùëö andtheparallelismfactorùëÉ ùëõ isconductedwithinfea- ofthehardwareaccelerator.
siblerangesdeterminedbythehardwarespecificationsandthe Thecalculationofùëáùëúùë°ùëéùëôùê∂ùë¶ùëêùëôùëíùë†includesotherparametersthat
natureofthematrixoperations.Thenestedloopsinthealgorithm areoutlinedinthefollowing.i)ComputationofTotalOperations:
reflectanexhaustivesearchwithintheseranges,ensuringthateach Thetotaloperationsrequiredforamatrixmultiplicationbetween
combinationofùëá ùëõ,ùëá ùëö,andùëÉ ùëõisevaluatedforitsperformance: matricesùê¥andùêµaredeterminedbythetilesizesùëá ùëõandùëá ùëö,andthe
(1) TilingFactorùëá ùëö:Representsthenumberofelementsfromone dimensionsofthematricesinvolved.Wemodeledthiscalculationas:
rowofmatrixùêµ thatareloadedintothecomputeunits.Each ùë°ùëúùë°ùëéùëôùëÇùëùùë† =ùëúùëùùë†ùëÉùëíùëüùëáùëñùëôùëí√óùëõùë¢ùëöùëáùëñùëôùëíùë†ùëÖùëúùë§√óùëõùë¢ùëöùëáùëñùëôùëíùë†ùê∂ùëúùëô,whereeach
4tile‚Äôsoperations,ùëúùëùùë†ùëÉùëíùëüùëáùëñùëôùëí =ùëá ùëõ√óùëá ùëö√óùëò,whereùë†‚Ñéùëéùëüùëíùëëùê∑ùëñùëöùëíùëõùë†ùëñùëúùëõ Algorithm2CHOSEN‚ÄôsAlgorithmforFindingOptimalTilePa-
denotedasùëòistheinnerdimensionsharedbetweenmatricesùê¥and rameters
ùêµ.ùëõùë¢ùëöùëáùëñùëôùëíùë†ùëÖùëúùë§(ùëõùë¢ùëöùëáùëñùëôùëíùë†ùê∂ùëúùëô)definehowmanytilesmatrixA(B)
1:
Input:ViTModelGraphùê∫,DataWidthùê∑ùëä,FPGAMemory
aredividedintoalongitsrows(columns).Thisequationreflects ConstraintsùëÄ
themultiplicationoperationsneededtocomputetheproductof 2: Output:Optimaltilesizesùëá ùëõ,ùëá ùëö,ParallelismFactorsùëÉ ùëõ,ùëÉ ùëö
submatricesdefinedbythetiles. 3: Initializesetsize:set_size
ii)DistributionofOperationsAcrossHardwareResources:The 4: Numberofiterations:iterations
divisionofùë°ùëúùë°ùëéùëôùëÇùëùùë†byùëÉ ùëõandùëÉ ùëö reflectsthedistributionofoper- 5: Preservationsize:preservation_size
ationsacrossmultipleprocessingelements(PEs)andcomputation 6: CalculateùëÉ ùëö:ùëÉ ùëö ‚Üê (cid:106)ùê¥ùëãùêº 2_ √óùëä ùê∑ùêº ùëäùê∑ùëáùêª(cid:107) //Fixedvalue
units(CU),respectively:
7:
Extractspecificlayerinformationfromùê∫
ùë°ùëúùë°ùëéùëôùëÇùëùùë†
ùëéùëëùëóùë¢ùë†ùë°ùëíùëë_ùëêùë¶ùëêùëôùëíùë† = √óùëòùëíùëüùëõùëíùëôùêπùëéùëêùë°ùëúùëü 8: InitializesetwithrandomconfigurationstailoredtoFPGAspecs
ùëÉ ùëõ√óùëÉ ùëö 9: foriteration=1toiterationsdo
WhereùëÉ ùëõ(ùëÉ ùëö)isthenumberofprocessingelements(computation 10: Evaluateperformanceofeachconfigurationintermsof
unitsperprocessingelement). latency
Thisdivisioniscriticalbecauseitensuresthatthecomputational 11: Preservehigh-performanceconfigurationsbasedonlatency
loadisbalancedacrossallavailablehardwareresources,thereby improvements
optimizingtheutilizationoftheFPGA‚Äôsresourcesandminimizing 12: Generatenewsetbyadaptivestrategy
thecomputationtime. 13: Replaceoldsetwiththenewone
iii)AdjustmentforMulti-Kernel:Theùëòùëíùëüùëõùëíùëôùêπùëéùëêùë°ùëúùëü incorporates 14: endfor
themulti-kernelnatureofdesignedarchitecture,particularlyperti- 15: Bestconfiguration‚Üêconfigurationfromthefinalsetwiththe
nentfordevicesliketheXilinxUltraScale+FPGA.Fortransformer lowestlatency
models,wherematrixmultiplicationisperformedwithinmultiple 16: returnoptimal_pn,optimal_pm,optimal_tn,optimal_tm
attentionheads,thisparameteriscalculatedasfollows:
(cid:40) ‚åà num_heads ‚åâ ifhead_flagistrue
ùëòùëíùëüùëõùëíùëôùêπùëéùëêùë°ùëúùëü = num_kernels
1 otherwise
num_kernels
ii)PerformanceEvaluation:Eachconfiguration‚Äôseffectiveness
Thisadjustmentisnecessarytoalignthecomputationalloadwith
ismeasuredspecificallybyitsimpactonlatencyreductioninViT
thephysicaldistributionofcomputationalresourcesacrossdifferent
applications.iii)EvaluationCache:Storeslatencyresultsofpre-
kernelsintheFPGA,ensuringefficientdatadistributionandparallel
viously tested configurations to avoid redundant computations,
processing.
optimizingtherefinementprocess.iv)RefinementandPreserva-
Theexhaustivesearchapproachtodeterminingoptimaltilepa-
tion:Ensuresconfigurationsyieldingthebestlatencyresultsare
rameters,asdescribedintheAlgorithm1,exploresallpotential
combinations ofùëá ùëõ,ùëá ùëö, ùëÉ ùëõ, and ùëÉ ùëö that satisfy hardware con- carriedforward.v)AdaptiveRefinementStrategy:Prioritizesad-
straints.Thenumberofvalidconfigurationscanbeexceedingly justmentsinparameterssuchasùëÉ ùëõandùëá ùëö ,whichareempirically
linkedtobetterperformanceinthecurrentapplication,guidingthe
highinpracticalscenarios.Forinstance,evenforsmallmodelslike
settowardspotentiallyoptimalregionsofthedesignspace.
ViTTinyonXilinxUltraScale+VU9PFPGA,wehaveapproximately
Ourapproachsignificantlyreducesthenumberofevaluations
116,144validcombinationsoftilingparameters,anditcangoup
required.Forinstance,inthecaseofViTTiny,theproposedalgo-
to586,554validcombinationsforViTSmallonthesameFPGA.
rithmconvergedtotheoptimalconfigurationwithapproximately
Evaluatingthecostforeachofthesecombinationsdemandsexten-
2,000evaluations,whileforViTSmall,around3,700evaluations
sivecomputationalresourcesandtime,resultinginasignificant
werenecessary.Thisrepresentsadrasticreductioncomparedtothe
overheadonthecompiler.
potentialmillionsofevaluationsrequiredbyanexhaustivesearch,
5.3 CHOSENAlgorithmforEfficientDesign demonstratingouralgorithm‚Äôsefficiencyinfindingnear-optimal
solutionswithinamuchsmallercomputationalbudget.
SpaceExploration
To address the inefficiencies of the exhaustive search, a novel
6 RESULTSANDDISCUSSIONS
heuristic-basedsearchalgorithmisproposedtoreducethenumber
ofevaluationpointsrequiredtoconvergetoanoptimalsolution. Inthisstudy,CHOSEN-ViT‚Äôshardwaremodelwasimplemented
Algorithm2isspecificallytailoredtooptimizetilingparametersfor on a Xilinx UltraScale+ VU9P board running at 200 MHz. This
deployingVisionTransformers(ViTs)onFPGAplatforms,address- FPGAdeviceincludes64GiBDDR4ECC-protectedmemorywith
ingconstraintssuchaslimitedmemoryandparallelprocessing.The adedicatedPCIex16connection.TherearefourDDRbanks.To
algorithmstartswithasetofrandomlygeneratedtilingparameters evaluatetheperformanceofCHOSEN-ViT,weemployedthepub-
thatfitwithintheFPGA‚Äôsspecifications.Ittheniterativelyrefines liclyavailableImageNet-1Kdataset[16]andtwodifferentmodel
theseparameterstominimizelatencyforViTinference. architectures,namelyDeiT[2]andViT[4],acrossvarioussizes
Thekeycomponentsofourimplementationare:i)InitialParam (small,base,andlarge).Itisimportanttopointoutthatourexperi-
Set Creation: Parameters are generated within feasible ranges mentalsetupdoesnotrequireextensiveretrainingfortheproposed
specific to FPGA constraints, ensuring a diverse starting point. approximations.
5Figure 3: Efficiency comparison between exhaustive and
CHOSENsearchmethodsacrossdifferentViTmodels.
Figure5:ParetofrontiercomparisonforViTSmallmodel.
Table1:HardwaremetricsforDeiT-BImplementation.
HWDesign HWModule BRAM36 URAM DSP LUT FF
Auto-Vit-Acc[12] - - - 2066 128K -
ME-PE 288 - 1024 192K 137K
ME-ViT[13]
MultiME-PE 1440 - 5120 960K 685K
1DPEarray 180 192 848 101K 73K
Controller&Scheduler 120 0 9 11K 8K
CHOSEN-ViT
Non-linearfunctions 0 0 116 17K 15K
Total 1440 192 6225 833K 607K
ensuresthatthecompiler‚Äôsresourcesarenotwastedonevaluating
Figure4:ParetofrontiercomparisonforfViTTinymodel.
sub-optimalconfigurations.
6.1 ComparisonofCHOSEN‚ÄôsAlgorithmtothe
6.3 HardwareCost
ExhaustiveSearch
Table1detailsthehardwaremetricsachievedbyimplementing
Theproposedalgorithmforfindingthehardwareparametersgreatly
CHOSEN-ViT.Byutilizingtherapidandhardware-compatibleap-
improvedthesearchperformancecomparedtoexhaustivesearch
proximationsintroducedbyPEANO-ViT[15],theresourceusage
methods.TheleftgraphinFigure3depictsadecreaseinthenumber
associatedwithhardware-intensiveandcostlyiterativemethods
ofevaluationcasesrequiredbytheproposedmethodcompared
forexactnon-linearimplementationhasbeengreatlydiminished.
totheexhaustivesearch.Thisreductionisconsistentacrossall
Furthermore,Table1providestheresourceutilizationbreakdown
modelsizes,highlightingourproposedapproach‚Äôsabilitytotarget
foreachmoduleineachcomputingkernelofCHOSEN-ViT.Please
optimalconfigurationsmoredirectlyandwithfewercomputations.
notethatthehardwaremetricsforDeiT-Baseimplementationare
Similarly,therightgraphinFigure3showsasubstantialdecrease
reported.Weusedeightcomputingkernelsinparallel.Inprocess-
inexecutiontimesfortheproposedmethod.
ingnon-linearfunctionssuchasnormalization,softmax,andGELU,
6.2 EffectivenessofCHOSENCompiler wesimultaneouslyhandle16elements,resultinginaLevelofParal-
lelism(LoP)of16.ThisLoPcanbeadjustedtoalignwithresource
Inthissection,weassessedtheeffectivenessoftheCHOSEN‚Äôsalgo-
availabilityandlatencyobjectives,makingCHOSENaversatile
rithminfindingtheoptimalparametersforthebestperformance
frameworkforenhancingthespeedofmachinelearningtasks.In-
ofourinferenceengine.Theproposedalgorithmdemonstratessub-
creasingtheLoPorthenumberofcomputingkernelsenhances
stantialeffectivenessinoptimizingtransformermodels,particularly
processingspeedbutmayleadtohigherresourceconsumption.As
initsabilitytoidentifyParetooptimalevaluationpointswithfewer
canbeseen,ourimplementationcanusehigherDSPnumbersfor
evaluatedpointscomparedtoexhaustivemethods.Thiscapability
thematrix-matrixmultiplicationwhilehavingfewerLUTsandFFs
isillustratedintheplotsforViTTinyandViTSmallmodels,as
duetotheproposedapproximations.
depictedinFigs.4and5.
Paretofrontier,representedbythemagentalineintheplots,
6.4 PerformanceComparisonwiththe
connectspointsthatofferthebesttrade-offbetweenlatencyand
State-of-the-ArtViTAccelerators
parallelism.Theproposedapproachcapturesnearlyalltheexhaus-
tivesearch‚ÄôsPareto-optimalpoints,demonstratingitsefficiency. WecomparetheperformanceobtainedbyCHOSENondifferent
Theproposedalgorithmsignificantlyreducesthenumberofevalua- ViTmodelswiththoseofthepriorwork.Tohavemeaningfuland
tions,focusingonlyonconfigurationspotentiallyleadingtooptimal faircomparisons,wecompareourresultsonlywithworksthathave
outcomes.Thistargetedexplorationisevidentinthedensityof usedthesameorasimilarFPGAboardasours,withcomparable
pointsalongtheParetofrontiercomparedtothebroaderscatter resources.Table2showstheperformancecomparisonbetween
oftheexhaustivepoints.Byfocusingthesearcharoundthemost CHOSEN-ViT and prior work references on ViT models on the
promisingareasofthesolutionspace,theCHOSEN‚Äôsalgorithm ImageNetdataset.CHOSEN-ViToutperformsthestate-of-the-art
6Table2:PerformanceComparison&CHOSEN-ViTConfigu-
[13] KyleMarinoetal.ME-vit:Asingle-loadmemory-efficientFPGAacceleratorfor
ration. visiontransformers.In30thIEEEHiPC2023,pages213‚Äì223.IEEE,2023.
[14] JohannesdeFineLichtetal.Flexiblecommunicationavoidingmatrixmultipli-
ViTModel HardwareDesign ùëÉùëõ ùëÉùëö ùëáùëõ ùëáùëö FPS cationonFPGAwithhigh-levelsynthesis.InFPGA‚Äô20,pages244‚Äì254.ACM,
2020.
ME-ViT[13] - - - - 298‚Ä† [15] MohammadErfanSadeghietal.Peano-vit:Power-efficientapproximationsof
DeiT-T non-linearitiesinvisiontransformers,2024.
CHOSEN-ViT 35 16 210 576 171
[16] JiaDengetal.Imagenet:Alarge-scalehierarchicalimagedatabase.In2009IEEE
ME-ViT[13] - - - - 88 ComputerSocietyConferenceonComputerVisionandPatternRecognition,2009.
DeiT-S
CHOSEN-ViT 99 16 198 1600 132
ME-ViT[13] - - - - 21
DeiT-B Auto-ViT-Acc[12] - - - - 26
CHOSEN-ViT 102 16 212 3072 37
‚Ä†Theyhaveon-chipmemorystorageforweightsandhaveclaimed300Mhzfrequency.
ViT accelerators by delivering 1.5x and 1.42x higher frame-per-
secondonDeiT-SandDeiT-B.CHOSEN-ViTexecutesatafrequency
of200MHz.Atthesametime,ME-ViT[13]reportedafrequencyof
300MHz.ME-ViT[13]delivershigherFPSinthecaseofDeiT-Tas
theycanbringalltheweightsrequiredforthismodelon-chipand
theydonotneedtotilethememoryforthismodelasitmanually
optimized.Instead,CHOSENpresentedanautomatedframework
thatcanbeusedforanytransformer-basedmodelthatisnotlimited
toViTs.
7 CONCLUSION
ThispaperintroducesCHOSEN-ViT,acompiler-to-hardwareopti-
mizationstackfordeployingVisionTransformers(ViTs)onFPGAs.
CHOSENframeworkfeaturesamulti-kernelacceleratorarchitec-
turethatmaximizesbandwidthbyleveragingmultipleDDRmem-
orybanks.TheCHOSENcompilerenhancescomputingkernelper-
formanceandmemoryefficiencywhilemanagingdatamovements
statically.ComparedtoleadingViTaccelerators,CHOSEN-ViTde-
liversthroughputimprovementsof1.5xforDeiT-Sand1.42xfor
DeiT-Bmodels.
REFERENCES
[1] AlexeyDosovitskiyetal. Animageisworth16x16words:Transformersfor
imagerecognitionatscale.In9thICLR,2021.
[2] HugoTouvronetal.Trainingdata-efficientimagetransformers&distillation
throughattention.InProceedingsofthe38thInt.Conf.onMachineLearning,2021.
[3] ArashFayyazietal. Neuroblend:Towardslow-poweryetaccurateneural
network-basedinferenceengineblendingbinaryandfixed-pointconvolutions.
InProceedingsoftheGLSVLSI2024,pages730‚Äì735.ACM,2024.
[4] ZeLiuetal. Swintransformer:Hierarchicalvisiontransformerusingshifted
windows.In2021IEEE/CVFInternationalConferenceonComputerVision,2021.
[5] BardiaBaraeinejad,MasoodFallahShayan,AmirRezaVazifeh,DibaRashidi,
MohammadSaberiHamedani,HamedTavolinejad,PouyaGorji,ParsaRazmara,
KiarashVaziri,DaryooshVashaee,andMohammadFakharzadeh.Designand
implementationofanultralow-powerECGpatchandsmartcloud-basedplatform.
IEEETrans.Instrum.Meas.,71:1‚Äì11,2022.
[6] ZhenhuaLiuetal.Post-trainingquantizationforvisiontransformer.InAnnual
ConferenceonNeuralInformationProcessingSystems2021,2021.
[7] FangYuetal.Width&depthpruningforvisiontransformers.InThirty-Sixth
AAAIConferenceonArtificialIntelligence,2022.
[8] JungHwanHeoetal. Training-freeaccelerationofvitswithdelayedspatial
merging,2024.
[9] SeyedarminAzizi,MahdiNazemi,andMassoudPedram.Memory-efficientvision
transformers:Anactivation-awaremixed-rankcompressionstrategy,2024.
[10] MengshuSunetal.VAQF:fullyautomaticsoftware-hardwareco-designframe-
workforlow-bitvisiontransformer.2022.
[11] HaoranYouetal.Vitcod:Visiontransformeraccelerationviadedicatedalgorithm
andacceleratorco-design.InIEEEHPCA2023,pages273‚Äì286.IEEE,2023.
[12] ZhengangLietal.Auto-vit-acc:Anfpga-awareautomaticaccelerationframework
forvisiontransformerwithmixed-schemequantization.In32ndFPL2022,pages
109‚Äì116.IEEE,2022.
7