An Evaluation of Continual Learning for
Advanced Node Semiconductor Defect Inspection
Amit Prasad1,∗ Bappaditya Dey1,∗ ((cid:0)) Victor Blanco1 and Sandip Halder2,′
Interuniversity Microelectronics Centre, Kapeldreef 75, 3001, Belgium1
SCREEN SPE Germany GmbH, Germany2
Equal Contribution∗
This research was conducted during Sandip Halder’s tenure at imec′
amit.prasad.ext@imec.be, Bappaditya.Dey@imec.be
Abstract. Deeplearning-basedsemiconductordefectinspectionhasgained
traction in recent years, offering a powerful and versatile approach that
provideshighaccuracy,adaptability,andefficiencyindetectingandclas-
sifying nano-scale defects. However, semiconductor manufacturing pro-
cesses are continually evolving, leading to the emergence of new types
of defects over time. This presents a significant challenge for conven-
tional supervised defect detectors, as they may suffer from catastrophic
forgetting when trained on new defect datasets, potentially compromis-
ing performance on previously learned tasks. An alternative approach
involves the constant storage of previously trained datasets alongside
pre-trained model versions, which can be utilized for (re-)training from
scratchorfine-tuningwheneverencounteringanewdefectdataset.How-
ever,adheringtosuchastoragetemplateisimpracticalintermsofsize,
particularlywhenconsideringHigh-VolumeManufacturing(HVM).Ad-
ditionally,semiconductordefectdatasets,especiallythoseencompassing
stochasticdefects,areoftenlimitedandexpensivetoobtain,thuslacking
sufficient representation of the entire universal set of defectivity. This
work introduces a task-agnostic, meta-learning approach aimed at ad-
dressing this challenge, which enables the incremental addition of new
defect classes and scales to create a more robust and generalized model
forsemiconductordefectinspection.Wehavebenchmarkedourapproach
usingrealresist-waferSEM(ScanningElectronMicroscopy)datasetsfor
twoprocesssteps,ADIandAEI,demonstratingitssuperiorperformance
compared to conventional supervised training methods.
Keywords: Continuallearning·Catastrophicforgetting·Semiconduc-
tor manufacturing · Defect classification · Lithography · Metrology
1 Related Work
Inthesemiconductorprocess(mainly,Litho-Etch)domain,numerousapproaches
have been suggested for defect classification and localisation [2], [3], [1]. To the
bestoftheauthors’knowledge,theconceptofincrementallearning[5]formulti-
class, multi-instance defect detection on SEM images has previously not been
explored.
4202
luJ
71
]VC.sc[
1v42721.7042:viXra2 Amit Prasad and Bappaditya Dey
2 Methodology
2.1 Dataset
Original (resist) wafer SEM (Scanning Electron Microscopy) images were ob-
tainedduringADI(AfterDevelopmentInspection)andAEI(AfterEtchInspec-
tion) stages. Figure 1 illustrates exemplary defect types in both process steps.
The instance distribution per defect class is captured in Table 1.
(b)AEIdefects.Lefttoright:Thinbridge,
(a)ADIdefects.Lefttoright:Microbridge, Singlebridge,Multibridgenon-horizontal,
Gap, Bridge, Line collapse, Probable-gap Multi bridge horizontal, Line collapse
Fig.1: SEM images with a) ADI defects and b) AEI defects
Table 1: Instance distribution per class
ADIInstances AEIInstances
Label Defecttype TrainingValidationTest Label Defecttype TrainingValidationTest
0 Microbridge 380 47 78 5 Thinbridge 241 29 29
1 Gap 1046 156 174 6 Singlebridge 240 29 31
2 Bridge 238 19 17 7 Multibridgenon-horizontal 160 21 19
3 Linecollapse 550 66 76 8 MultibridgeHorizontal 80 10 10
4 Probable-gap 315 49 54 9 Linecollapse 202 40 34
Total 2529 337 399 Total 923 129 123
2.2 Notations and Preliminaries
The following notations have been used in this work.
Definition 1. Task (T ): This is defined as supervised training of a defect
p
detectionframeworkforpclasses(0top−1)inthedatasetoftheform(x ,y )m
i i i=1
(m instances with defect feature x and corresponding label y ). This is denoted
i i
by T .
p
Definition 2. Finetuned task (Fq): This is defined as supervised training of
p
a defect detection framework for next q classes (p to q−1) in the dataset of the
form (x ,y )m , which has previously been trained on the initial p classes (0 to
i i i=1
p−1). However, it’s important to note that identifying these initial p classes is
not guaranteed.This is denoted by Fq.
p
Definition 3. Incremental task (Tq): This is defined as incremental su-
p
pervised training of a defect detection framework for next q classes (p to q−1)
in the dataset of the form (x ,y )m , which has previously been trained on the
i i i=1
initial p classes (0 to p−1), enabling it to identify all (p+q) classes. This is
denoted by Tq.
pTitle Suppressed Due to Excessive Length 3
2.3 Structure of study
In this work we present the following case studies.
1. Case study 1 (see Section 3) examines effectiveness of the framework in
incrementally learning new defect classes and minimizing forgetting of
previously trained defect classes on the ADI dataset.
2. Case study 2(seeSection4)assessesframeworkforincrementally learn-
ing new defect classes in AEI images and minimizing forgetting of previ-
ously trained defect classes across the entire ADI dataset.
3. Case study 3 (see Section 5) compares three training strategies: (i) con-
ventional supervised training strategy with all defect classes at once, (ii)
conventional supervised training with first p defect classes and then fine-
tuneonnewq defectclasses,(iii)proposedincrementalsupervisedtraining
strategywithfirstpdefectclassesandthenfine-tuneonnewq defectclasses.
We use the Faster-RCNN [6] model for all studies. Moreover, for incremental
tasks, the approach utilized is presented in [4] which also uses FRCNN.
3 Case study 1
The model starts training with the task T (initially trained for 2 defect classes,
2
microbridgeandgap),followedbytwoconsecutiveincrementaltrainingtasks:T2
2
(adding 2 more defect classes, bridge and line-collapse), and finally T1 (adding
4
the last defect class as probable gap), using the ADI dataset. For an evaluation
of performance, average precision (AP) per defect class vs iterations is plotted,
markingcheckpointswherenewdefectclasseswereintroducedandwherecontin-
uallearningtakesplace.Theresultsarecomparedtotheconventionalfine-tuning
approach, where the model has been trained on tasks F2 and F1, while keeping
2 4
all experimental conditions constant. In Figure 2 a), it is evident how effective
incremental learning is for progressively learning defect classes and minimizing
catastrophic forgetting. Conversely, in Figure 2 b), it is apparent how swiftly
catastrophic forgetting occurs in the case of fine-tuning.
4 Case study 2
Defect classes from the AEI dataset are incrementally added following training
on the ADI dataset. The model, following task T1, undergoes training on tasks
4
T2 and T3. Similarly, following task F1, the model undergoes fine-tuning for
5 7 4
tasks F2 and F3. The Figure 3 illustrates the comparison between proposed
5 7
incremental learning and conventional fine-tuning (using AP vs iteration plot).
5 Case study 3
Inference results are shown in Figure 4 (with corresponding labels, bounding
boxs and confidence scores) are from 3 training strategies, first is the model4 Amit Prasad and Bappaditya Dey
(a) Model trained incrementally for tasks (b) Model finetuned on tasks F2 and F1
2 4
T2 and T1 after training on task T after task T
2 4 2 2
Fig.2: Comparison between (a) proposed incremental learning and (b) conven-
tional fine-tuning method.
trained on task T (incorporating all defect classes simultaneously) while the
10
other models are derived from tasks T3 and F3. The labels are referenced from
7 7
Table1.Notably,itisobservedthatthemodelaftertaskT3performscomparably
7
to the model trained on task T . However, the model obtained after task F3
10 7
demonstrates forgetfulness or mislabeling of defects it encountered earlier, as it
has only recently been exposed to labels 7, 8, and 9.
(a) Model trained incrementally for tasks (b) Model finetuned on tasks F2 and F1,
2 4
T2, T1, T2, T3 after training on task T F2 and F3 after task T
2 4 5 7 2 5 7 2
Fig.3:(a)Proposedincrementallearningvs(b)conventionalfine-tuningmethod
for incremental learning of AEI defects, after training across the ADI dataset.
6 Conclusion
In this study, we demonstrated the effectiveness of a continual learning strat-
egy in progressively learning the classification and localization of semiconductor
defect classes in aggressive pitches, while mitigating catastrophic forgetting.
References
1. Dehaerne, E., Dey, B., Esfandiar, H., Verstraete, L., Suh, H.S., Halder, S., Gendt,
S.D.: YOLOv8 for defect inspection of hexagonal directed self-assembly patterns:Title Suppressed Due to Excessive Length 5
Fig.4: Upper row: Model trained for defect detection on all classes at once.
Middle row: Model obtained after incremental training on task T3.
7
Lower row: Model obtained after training on task F3
7
Defecttypes(groundtruth),lefttoright:Microbridge,Gap,Bridge,Thinbridge,
Multi bridge non-horizontal.
a data-centric approach. In: Behringer, U.F., Loeschner, H., Finders, J. (eds.) 38th
EuropeanMaskandLithographyConference(EMLC2023).vol.12802,p.128020S.
InternationalSocietyforOpticsandPhotonics,SPIE(2023).https://doi.org/10.
1117/12.2675573, https://doi.org/10.1117/12.2675573
2. Dehaerne, E., Dey, B., Halder, S.: A comparative study of deep-learning ob-
ject detectors for semiconductor defect detection. In: 2022 29th IEEE Interna-
tional Conference on Electronics, Circuits and Systems (ICECS). pp. 1–2 (2022).
https://doi.org/10.1109/ICECS202256217.2022.9971022
3. Dey, B., Goswami, D., Halder, S., Khalil, K., Leray, P., Bayoumi, M.A.: Deep
learning-based defect classification and detection in SEM images. In: Robinson,
J.C., Sendelbach, M.J. (eds.) Metrology, Inspection, and Process Control XXXVI.
vol. PC12053, p. PC120530Y. International Society for Optics and Photonics,
SPIE (2022). https://doi.org/10.1117/12.2622550, https://doi.org/10.1117/
12.2622550
4. Joseph,K.J.,Rajasegaran,J.,Khan,S.,Khan,F.S.,Balasubramanian,V.N.:Incre-
mental object detection via meta-learning. IEEE Transactions on Pattern Analysis
and Machine Intelligence 44(12), 9209–9216 (2022). https://doi.org/10.1109/
TPAMI.2021.3124133
5. Masana, M., Liu, X., Twardowski, B., Menta, M., Bagdanov, A.D., van de Weijer,
J.: Class-incremental learning: survey and performance evaluation on image classi-
fication (2022)
6. Ren,S., He, K., Girshick, R., Sun, J.: Faster r-cnn: towards real-timeobject detec-
tion with region proposal networks. In: Proceedings of the 28th International Con-
ference on Neural Information Processing Systems - Volume 1. p. 91–99. NIPS’15,
MIT Press, Cambridge, MA, USA (2015)