ABSTRACTION ALIGNMENT: COMPARING MODEL AND HUMAN
CONCEPTUAL RELATIONSHIPS
APREPRINT
AngieBoggust HyeminBang
MITCSAIL MITCSAIL
Cambridge,MA,USA Cambridge,MA,USA
aboggust@csail.mit.edu
HendrikStrobelt ArvindSatyanarayan
MIT–IBMWatsonAILab MITCSAIL
IBMResearch Cambridge,MA,USA
Cambridge,MA,USA
ABSTRACT
Abstraction—theprocessofgeneralizingspecificexamplesintobroadreusablepatterns—iscentral
to how people efficiently process and store information and apply their knowledge to new data.
Promisingly,researchhasshownthatMLmodelslearnrepresentationsthatspanlevelsofabstraction,
fromspecificconceptslikeBOLOTIEandCARTIREtomoregeneralconceptslikeCEOandMODEL.
However,existingtechniquesanalyzetheserepresentationsinisolation,treatinglearnedconcepts
as independent artifacts rather than an interconnected web of abstraction. As a result, although
we can identify the concepts a model uses to produce its output, it is difficult to assess if it has
learnedahuman-alignedabstractionoftheconceptsthatwillgeneralizetonewdata. Toaddress
thisgap,weintroduceabstractionalignment,amethodologytomeasuretheagreementbetweena
model’slearnedabstractionandtheexpectedhumanabstraction. Wequantifyabstractionalignment
bycomparingmodeloutputsagainstahumanabstractiongraph,suchaslinguisticrelationshipsor
medicaldiseasehierarchies. Inevaluationtasksinterpretingimagemodels,benchmarkinglanguage
models,andanalyzingmedicaldatasets,abstractionalignmentprovidesadeeperunderstandingof
model behavior and dataset content, differentiating errors based on their agreement with human
knowledge,expandingtheverbosityofcurrentmodelqualitymetrics,andrevealingwaystoimprove
existinghumanabstractions.
1 Introduction
Abstractionistheprocessofdistillingmanyindividualdatainstancesintoasetoffundamentalconceptsandrelationships
thatcaptureessentialcharacteristicsofthedata[Yee,2019,Alexander,2018,Liskovetal.,1986]. Theresultisan
interconnectedwebofconcepts,rangingfromspecificideas,likeSCHNAUZER,toprogressivelymoreabstractnotions,
likeDOGorANIMAL. Abstractionisacentralcharacteristicofhumancognitionasitallowsustoflexiblyreasonat
thelevelofabstractionappropriateforourtask—forexample,incomputerscience,abstractionhelpshidelow-level
implementationconcernsfromclientsLiskovetal.[1986]. Moreover,abstractionallowsustogeneralizeourknowledge
byfittingourabstractedpatternstonew,unseendata[Yee,2019]. Forinstance,overtheircareers,clinicianslearn
abstractionsofdiseasesymptomswhichtheyusetodiagnoseandtreatnewpatients,eventhosewithrareoratypical
diseases[Eva,2005].
Promisingly, existing interpretability and alignment research has shown that machine learning (ML) models learn
conceptsatvaryinglevelsofabstraction. Concept-basedinterpretabilitymethodshavedemonstratedmodelsensitivityto
concepts,rangingfromspecificideas,likeCARTIRE,tohigher-levelconcepts,likeMODEL[Kimetal.,2018,Ghorbani
etal.,2019]. Similarly,researchonneuronactivations,hasfoundthatmodelsencodehuman-likeconceptsacrosslevels
4202
luJ
71
]GL.sc[
1v34521.7042:viXraAbstractionAlignment BOGGUSTETAL.
ofabstraction,suchasSTONE WALL,SKY,andGRADUATE[Hernandezetal.,2021,Bauetal.,2017,Oikarinenand
Weng,2022]. Together,theseresultssuggestthatMLmodelsextracthuman-likeconceptsfromtheirtrainingdataand
usethemtomakeinferencesonnewdata.
However, existing techniques analyze a model’s learned concepts in isolation, ignoring the relationships between
conceptsthatmakeupitsabstraction. Typically,interpretabilitymethodscurateasetofhumanconceptsandquantify
themodel’ssensitivitytoeachconceptindependently. Whilethistestingprocedurequantifiestheimportanceofa
concepttothemodel’sdecision,itdoesnotmeasurethemodel’srelianceonmultipleconcepts,abilitytogeneralize
concepts,orwhatrelationshipsithaslearnedbetweentheseconcepts. Asaresult,whilewecanverifythatamodeluses
human-alignedconceptstomakeitsdecision,welacktoolstotestifithaslearnedahuman-alignedabstractionofthose
concepts. Yet,testingamodel’sabstractionisimportantbecause,evenwiththecorrectsetofconcepts,amodelusinga
misalignedabstractioncanresultinaninabilitytogeneralizetonewdata. Forinstance,amodelthathasonlybeen
exposedtoimagesofCOOKEDCRABSmaylearnanabstractionthatCRABSareFOODandfailtogeneralizetoimages
ofBEACHCRABS.
Toaddressthisgap,weintroduceabstractionalignment,amethodologytomeasuretheagreementbetweenamodel’s
learned abstraction and the expected human abstraction. To quantify abstraction alignment, we represent human
abstractionsasdirectedacyclicgraphs(DAGs),suchasmedicaltaxonomies[WorldHealthOrganization,1978]or
lexicalgraphs[Miller,1995]. Then,wecomparemodeloutputsagainstthehumanabstractiongraphtomeasurehow
well the abstraction accounts for the model’s uncertainty. Through this process, we define metrics of abstraction
alignment including uncertaintyalignment (Equation (2)) and conceptconfusion (Equation (4)), to surface
variousaspectsofamodel’sabstraction.
Wedemonstratehowabstractionalignmentcanbeusedformodelinterpretability,modelbenchmarking,anddataset
analysistasks1 2. Wheninterpretinganimagemodel,weshowthatabstractionalignmentallowsustodifferentiate
errorsbasedontheiragreementwithhumanknowledge,revealingwhenseeminglyproblematicerrorsareactuallymore
benignlackofgranularity. Next,weuseabstractionalignmenttoexpandexistinglanguagemodelqualitybenchmarks
by quantifying model specificity across a breadth of linguistic markers. Finally, in a medical domain, abstraction
alignmentexposesdataqualityissuesbetweenhowdiseasesarecategorizedinformalguidelinesandencodedinthe
dataset,andidentifiesopportunitiestoimproveexistinghumanmedicalabstractions.
2 RelatedWork
AbstractionsinMLdatasetsAbstractionsallowhumanstoefficientlyprocessinformationandformthebasesfor
informationencodingsinlinguistics[Miller,1995,Dewey,2011],biology[Hinchliffetal.,2014,Linnaeus,1758],
andmedicine[WorldHealthOrganization,1978]. Inmachinelearning,abstractionsarebuiltintomanytasks,suchas
imageclassification[Krizhevskyetal.,2009,Dengetal.,2009],medicaldiagnostics[Johnsonetal.,2016a,b],andtext
prediction[Miller,1995]. Evendatasetsthatdonotincludeanabstractioncanbelinkedtoexistingabstractionsby
matchingtheiroutputclasseswithcorrespondingconceptnodes[RedmonandFarhadi,2017]. Weapplyabstraction
alignmenttointerpretimageclassificationmodelsusingtheCIFAR-100hierarchy[Krizhevskyetal.,2009],benchmark
languagemodelsusingWordNetlanguageabstractions[Miller,1995,Fellbaum,1998],andanalyzedatasetabstractions
usingtheICD-9diseaseabstraction[Johnsonetal.,2016a,b,WorldHealthOrganization,1978].
Concepts in model interpretability Aligned with our goal of understanding machine learning model behavior,
interpretabilityresearchfocusesonmeasuringmodelrelianceonknownhumanconcepts[Doshi-VelezandKim,2017,
Rai, 2020]. For instance, saliency methods reveal input features important to the model’s prediction that humans
comparetotheirexpectations[Selvarajuetal.,2017,Carteretal.,2019a,Boggustetal.,2022]. Featurevisualization
methodshelpidentifyconcepts,likepatternsorobjectparts,thatactivatemodellayers[Olahetal.,2017,Erhanetal.,
2009,Bauetal.,2017]. Concept-basedmethodslikeTCAV[Kimetal.,2018,Ghorbanietal.,2019]identifyandtestfor
humanconceptsencodedinamodel’slatentspace. Neuronactivationanalysisidentifieshumanconceptsthatactivate
particularmodelneurons[Hernandezetal.,2021,Bauetal.,2017,OikarinenandWeng,2022]. Recently,workin
mechanisticinterpretabilitydiscoveredsmallnetworkscontainstatemachinesthattransitionbetweenconceptsinhuman
meaningfulways[Brickenetal.,2023]. Togetherthesemethodshaveidentifiedproblematicmodelcorrelations[Carter
etal.,2021],madesenseofcomplexmodelactivations[Olahetal.,2018,Carteretal.,2019b],anddiscoverednovel
conceptsthatadvancehumanknowledge[Schutetal.,2023]. Buildingontheirsuccess,weexpandinterpretability
fromindependentconceptstotherelationshipsbetweenthem,toensurethatmodelslearnhuman-alignedconceptsand
human-alignedabstractions.
1Codeisavailableat:https://github.com/mitvis/abstraction-alignment
2Aninteractiveinterfacetoexploreexperimentalresultsisavailableat:https://vis.mit.edu/abstraction-alignment/
2AbstractionAlignment BOGGUSTETAL.
KnowledgegraphsRelatedtotheabstractionsweworkwithareknowledgegraphs—semanticdatanetworksthat
represententitiesandtheirrelationships[Jietal.,2020]. Whiletheabstractionsencodelevelsofconceptualabstraction,
knowledgegraphsaredirectedgraphsthatencodeanyformofrelationshipbetweenthenodes,likefamilialrelationships
betweenpeopleandassociationsbetweenpeopleandinstitutions. Machinelearningresearchonknowledgegraphs
hasfocusedontrainingmodelstoencode[Linetal.,2018],complete[Yaoetal.,2019],andevenreplace[Sunetal.,
2023]knowledgegraphs. Likeabstractionalignment,thesemodelssuggestwaystoupdateexistinghumantaxonomies;
howeverabstractionalignmentfocusesoninterpretingthehuman-alignmentofexistingmachinelearningmodels.
3 Methodology
Thegoalofabstractionalignmentistomeasurehowwellthemodel’slearnedabstractionalignswithagivenhuman
abstraction. Our methodology is based on the assumption that the model’s confusion is a reflection of its learned
abstraction—i.e.,conceptsthemodelcommonlyconfusesaremoresimilarinthemodel’sabstractionthanconceptsthe
modelperfectlyseparates.
3.1 Representinghumanabstractions
Tocomputeabstractionalignment,wefirstrepresentthehumanabstractionasadirectedacyclicgraph(DAG),where
nodes represent concepts and edges represent child-to-parent relationships between concepts. For example, in the
medicalabstractioninSection4.3,nodesrepresentmedicaldiagnosesandedgesmapfromspecificdiagnoses,like
FRONTALSINUSITIS,tobroaderdiagnosticcategories,likeRESPIRATORYINFECTIONS[WorldHealthOrganization,
1978]. EverynodeintheDAGexistsatalevelofabstraction,rangingfromtheleafleveltotherootlevel,computed
basedonitsshortestpathfromaleafnode.
TheDAGdatastructureiswellsuitedtorepresentingabstractionsbecauseitefficientlyencodesboththeabstraction’s
conceptsandconceptualrelationships. Wecaneasilyaccessaconcept’slevelofabstractionbymeasuringitsheight
andmoveupanddownthelevelofabstractionbygettingitsancestorsordescendants. Sincethegraphisacyclic,it
guaranteesthehierarchicalstructurethatunderpinsabstractionrelationships. FurtherDAGsarecommonlyusedto
representabstractions[WorldHealthOrganization,1978,Miller,1995]andarebuiltintomanyMLdatasets[Krizhevsky
etal.,2009,Dengetal.,2009,Johnsonetal.,2016a,b],allowingabstractionalignmenttoapplytoawidevarietyof
domains.
3.2 Integratingmodeloutputswithhumanabstractions
Thenextstepincomputingabstractionalignmentistocomparethemodel’sbehaviortothegivenhumanabstraction
DAG. To do so, we map the model’s output space (e.g., classes or tokens) to nodes in the DAG. Often the human
abstractionisbuiltintothemodelingtask,sothismappingisstraightforward—e.g.,CIFAR-100includesahuman
abstractionmappingclassestohigher-levelsuperclassesKrizhevskyetal.[2009]. However,evenwhenthehuman
abstractionisseparatefromthemodelingtask,themodel’soutputspacecanoftenbeeasilycomputationallymappedto
theDAG.Forinstance,inSection4.2,wemapwordsinthemodel’svocabularytonodesintheWordNetDAG[Miller,
1995].
Weusethismappingtoanalyzethemodel’sbehaviorbasedonthehumanabstraction. FollowingAlgorithm1,we
createaweightedDAGforeachdatasetinstance,wherenodeshaveavalueandaggregated value. Thevalue
correspondstothemodel’soutputprobability. Ifanodecorrespondstoamodel’soutput,thenthevalueisthemodel’s
predictedprobabilityforthatoutput. Otherwise,thevalueiszero. Theaggregated valueisthemodel’spropagated
probabilityandiscomputedasthesumofvaluesofitsdescendants. Forexample,inCIFAR-100[Krizhevskyetal.,
2009],theaggregated valueoftheFLOWERnodeisthesumofthemodel’sprobabilitiesthattheimageisaORCHID,
POPPY,ROSE,SUNFLOWER,orTULIP. Bypropagatingthemodel’sconfidencesthroughtheabstraction,aggregated
valueprovidesameasureforthemodel’sconfidenceinnon-outputnodes,includinghigh-levelconcepts.
3.3 Measuringabstractionalignment
UsingtheweightedDAG,wecanmeasuretheabstractionalignmentofamodel’sdecisionforaspecificinstanceoran
entiredataset. Whiletherearepotentiallymanymetricsonecouldusetoanalyzeabstractionalignmentpatterns,we
defineaninitialsetoffourmetricsthatwehavefoundusefulfordownstreamtasks. Duringanalysisweassumewe
haveadatasetX,amodeltrainedtopredictclassesortokensc,andanabstractionDAGcontainingnodesnacross
levelsofabstractionl. Weusethemodel’soutputs(e.g.,y forinstancex andclassc )tocomputetheaggregated
ij i j
valuev ofnoden .
ki k
3AbstractionAlignment BOGGUSTETAL.
Algorithm1AbstractionAlignmentPropagation—createaweightedDAGforadatasetinstance
1: Inputs
2: instance←thedatasetinstance
3: model←themodeltoevaluate
4: classes←themodel’soutputspace
5: abstraction←thehumanabstractionDAG
6: fornodeinabstractiondo ▷InitializethevaluesoftheDAG
7: node.value=0 ▷valueisthemodel’sassignedprobability
8: node.aggregated_value=0 ▷aggregated_valueisthepropagatedprobability
9: endfor
10: probabilities=model(instance)
11: fori,probinenumerate(probabilities)do ▷Setnodevaluesbasedonmodeloutputs
12: node=abstraction.get_node(classes[i])
13: node.value=prob
14: endfor
15: forlevelinabstraction.levelsdo ▷PropagatenodevaluesthroughtheDAGstartingattheleaves
16: fornodeinleveldo
17: node.aggregated_value=node.value
18: forchildinnode.childrendo
19: node.aggregated_value+=child.aggregate_value
20: endfor
21: endfor
22: endfor
Accuracyabstractionalignment Onewaytomeasureabstractionalignmentistomeasurehowwellthehuman
abstractionaccountsforthemodel’serrors. Ifamodel’smistakesaresubstantiallyreducedbymovingupalevelof
abstraction,thenthemodel’sbehaviorismoreabstractionalignedthanifitcontinuestomakeerrorsathigher-levelsof
abstraction. Whiletherearecaseswhenthemodel’serrorsmayacceptablynotfittheabstraction,suchasmisclassifying
animagecontainingmultipleobjects,inaggregateweexpectthemodel’serrorstoreflectitsabstractions—i.e.,itwill
confuseoutputclassesortokensthatitconsiderssimilar.
Wemeasureaccuracyalignmentastheproportionoferrorsthatarereducedbymovingfromlevell tol . First,we
i j
computethenumberofcorrectpredictionsateachlevelbycomparingthenodewiththehighestaggregated value
inthatleveltotheexpectedpredictionatthelevel. Then,wecomputetheproportionoferrorsthataremitigatedby
movingupintheabstraction. Ifaccuracyalignmentishigh,thentheabstractionaccountsforalargeamountofthe
model’smistakes,suggestingthemodelisusingasimilarabstraction.
(cid:80)|X|
1[argmax([v ∀n ∈l ])=y
]−(cid:80)|X|
1[argmax([v ∀n ∈l ])=y ]
accuracyalignment=∆A = k=1 a,k a j k,j k=1 a,k a i k,i
li,lj |X|−(cid:80)|X|
1[argmax([v ∀n ∈l ])
k=1 a,k a i
(1)
Uncertaintyabstractionalignment Similarly,wecanmeasureabstractionalignmentbyquantifyinghowwellthe
abstractionaccountsforthemodel’suncertainty. Amodelwhoseconfusioniscontainedwithinasmallportionof
theDAGismoreabstractionalignedthanamodelwhoseconfusionspanstheDAG.Aswithaccuracyalignment,
uncertaintyalignmentappliesinaggregate—e.g.,amodelthatregularlyconfusestypesofFRUITismoreabstrac-
tionalignedthanamodelthatregularlyconfusesFRUITSandBIRDS.
We measure uncertaintyalignment by testing the difference in entropy between levels of the DAG. First, we
computetheShannonentropy(H)entropyofthenodeaggregate valuesforeverylevelintheDAG.Thelarger
theentropyforagivenlevelthemoreconfusedthemodelisacrossconceptsatthatlevelofabstraction. Thenwe
computethemeandifferenceinentropy(H)betweentwolevels(l andl )acrossasetofdatainstances,X. Ifthe
i j
entropydecreasessubstantiallythenthemodel’sbehavioralignswiththeabstractionmappingthelow-levelnodesto
thehigher-levelnodes.
|X| |X|
1 (cid:88) 1 (cid:88)
uncertaintyalignment=∆H = H([v ∀n ∈l ])− H([v ∀n ∈l ]) (2)
li,lj |X| a,k a j |X| a,k a i
k=1 k=1
Subgraph preference Another useful metric when using abstractions to analyze model behavior is to compare
subgraphswithintheabstractionDAG.Forinstance,inSection4.2,wecompareregionsoftheDAGthatrepresent
4AbstractionAlignment BOGGUSTETAL.
Figure 1: We use abstraction alignment to interpret the behavior of a ResNet20 model [He et al., 2016a] on the
CIFAR-100testset[Krizhevskyetal.,2009]usingaccuracyalignment(left)anduncertaintyalignment(right).
Highvaluesofeachmetricindicatesthatthemodelhaslearnedthataspectofthehumanabstractionandthemajorityof
itserrorsanduncertaintyiscontainedwithintheabstraction(e.g.,PEOPLE).
differentconcepts(e.g.,anylocationconceptvs. CANADIANlocationconcepts)anddifferentlevelsofabstraction(e.g.,
conceptsmorespecificthanJOURNALISTtoconceptsmoregeneralthanJOURNALIST). Inaggregate,thesecomparisons
helpusquantifyandcompareabstractionsthemodelusesandprefers.
We compute subgraphpreference by measuring how often the maximum aggregate value of a node in one
subgraph,s ,islargerthanthemaximumaggregate valueofanodeinanothersubgraphs . Thisisanextensionof
i j
thespecificitytestingmetric,p ,proposedbyHuangetal.[2023],wheres isthespecificconceptands isthegeneral
r i j
concept. However,unlikep thatwasdesignedtotesttwooutputtokensofamodel,abstractionalignmentallowsusto
r
testabreadthofconcepts,includingdifferentlevelsofabstraction,multiplesimilarconcepts,andconceptsrelatedto
differentabstractions. Ifourmodel’soutputsspanmanynodesintheabstractionDAG(asinSection4.2),wecanalso
computethismetricusingthenode’svalueasopposedtoaggregate value.
|X|
1 (cid:88)
subgraphpreference=P(s ,s )= 1[max([v ∀n ∈s ])]>max([v ∀n ∈s ]) (3)
i j |X| a,k a i b,k b j
k=1
Concept confusion Finally, the conceptconfusion metric allows us to measure how often a model assigns
probability to pairs of concepts. Identifying these concepts can reveal concepts that the model considers similar
in its abstraction despite being different in the human abstraction. While concept pairs that are direct ancestors
ordescendantsofeachotherwilldefinitionallyhavehighconceptconfusion, unrelatedconceptpairswithhigh
conceptconfusionindicateunrelatedhumanconceptsthatthemodel’sabstractiondeemssimilar.
To compute conceptconfusion for a pair of nodes, we compute the Shannon entropy (H) of their aggregate
values divided by the maximum possible entropy for a pair of nodes. By computing the entropy, we weight the
conceptconfusionbyhowconfusedthetwonodesare. Wecomputeconceptconfusionoveranentiredatasetto
identifyconceptsthatthemodelrepeatedlyconfuses.
(cid:80)|X|
H([v ,v ])
conceptconfusion=C(n ,n )= k=1 i,k j,k (4)
i j (cid:80)|X|
H([0.5,0.5])
k=1
4 Experiments
4.1 Interpretingmodelbehaviorwithabstractionalignment
Abstractionalignmentimprovesmodelinterpretabilitybyexpandingthenumberandcomplexityofconceptswecanuse
tocharacterizemodeldecisionsandcomparingthemtoacceptedhumanabstractions. Acommoninterpretabilitytaskis
understandingamodel’smistakes;howevernotallmistakesareequallyproblematic. Forexample,wewouldbemore
likelytoforgiveamodelthatregularlymistakesCARSforTRUCKSthanamodelthatconsistentlymistakesCARSfor
STOPSIGNS. TheformeralignswithourhumanabstractionsthattreatVEHICLESsimilarlywhiledriving;whereas,the
lattersuggestsmodelabstractionsdonotfollowacceptedhumanreasoningwithpotentiallydangerousconsequences. In
thesecases,abstractionalignmenthelpsdifferentiatetheseverityofamodel’smistakes,distinguishingbenignlow-level
errorsfromproblematichigher-levelmisalignment.
5AbstractionAlignment BOGGUSTETAL.
Confusion resolves at the level 2 (superclass) nodes Confusion across more than three level 2 (superclass) nodes Confusion in two distinct paths
Figure 2: Abstraction alignment provides a structure to identify patterns in model behavior. We query for model
behaviortypesonCIFAR-100[Krizhevskyetal.,2009]—imageswheremodelconfusioniscontainedwithanabstract
concept(left),imageswhereconfusionisspreadacrossmorethanthreeabstractconcepts(middle),andequalconfusion
intwoconceptsindifferentbranches(right).
Todemonstrateabstractionalignment’sabilitytocharacterizemodelbehavior,weuseittointerpretaResNet20[He
etal.,2016a]trainedonCIFAR-100[Krizhevskyetal.,2009]. WeusetheCIFAR-100classandsuperclassstructureas
thehumanabstraction,resultinginaDAGwith121nodesacross3levels(seeSectionA.1)[Krizhevskyetal.,2009].
Wecomputeeachtestimage’sweightedDAGbyapplyingasoftmaxtothemodel’soutputsandmappingtheoutput
probabilitiestothecorrespondingclassnodes(seeSection3.2).
Quantifying abstraction alignment reveals abstraction aligned errors. In Figure 1, we report the model’s
accuracyalignment(Equation(1))anduncertaintyalignment(Equation(2))acrosstheCIFAR-100testset.
ThePEOPLE,TREE,andFLOWERabstractionsresolvealargeproportionofthemodel’serrorswiththeirsubclasses,
indicatingthatthemodelhaslearnedthoseabstractionsForinstance,76%ofpredictionerrorsforimagesofMAPLE,
OAK, PALM, PINE,and WILLOW areresolvedbypredictingatthelevel2concept TREE. Similarly,uncertaintyfor
imagesofBABY, BOY, GIRL, MAN,andWOMANisalmostentirelyresolvedbymovinguponelevelofabstraction
toPEOPLE. Whileourmodelonlyachieves67.7%testaccuracy,seeingthatmanyofitserrorsalignwithourhuman
abstractionmayincreaseourtrustthatitwillbehaveacceptablyonunseendatainthesecategories.
Ourabstractionalignmentmetricsalsorevealareaswherethemodelismisalignedwiththehumanabstraction. For
instance,themodel’serrorsarenotaccountedforbyabstractionslikeVEHICLES2nordoesitappeartolearnanimal
categorizationslikeMEDIUMMAMMALSandLARGECARNIVORES. Inbothcases,wemightconsidertheseresultstobe
acceptablemodelperformanceinlightofpoorlydesignedorill-fittinghumanabstractionsrespectively. Inparticular,the
CIFAR-100hierarchyartificiallyrestrictseachsuperclasstocontainexactly5subclasses—aconstraintthatproduces
twoabstractnodesforVEHICLESthatarbitrarilydistinguishtheirchildrenratherthanmeaningfullycaptureabstracted
patterns. Incontrast,althoughthehigher-levelanimalcategoriesaresemanticallymeaningful,theyreflectabstract
biologicalconceptslikesize(MEDIUM,LARGE),reproduction(MAMMALS),anddiet(CARNIVORES)thatareseemingly
hardforamodeltolearnvisuallyfrom32x32images. Iflearningaccuratebiologicalabstractionsareimportantforour
task,thenwemayprefertotrainonanalternatedatasetormodalitythatmorepreciselyexpressesthesecharacteristics;
ontheotherhand,iflearningvisualabstractionsareacceptable,wemayupdateourhumanabstractionstobetterreflect
whatcanbelearnedfromthedata(i.e.,categorizinganimalsbasedonvisualsimilarity).
Abstractionalignmentalsoprovidesastructuretoexploretypesofmodelbehavior. InFigure2,weusetheweighted
DAGstoqueryforparticulartypesofabstractionalignment. Wecandefinetypesofabstractionalignmentbasedon
thenumberofnodesthemodelconsidersateachlevelandhowitdistributesitsconfidenceacrossnodes. Toexplore
instanceswherethemodel’sdecisionalignsandmisalignswithhumanabstractions,wecompareimageswherethe
model’sconfusionresolvesatthelevel2conceptagainstimageswherethemodel’suncertaintyissplitoverfourlevel2
concepts. Wefindthatwhile15.5%ofinstancesareharmlesslow-levelconfusion,25%ofimagesresultofconfusionat
higherlevelsofabstraction. Wecanalsolookatparticulartypesofmodelbehaviors,queryingforinstanceswherethe
modelisconfusedbetweentwodistinctconcepts. Validatingourquantitativeanalysis,weseeinstanceswheremodel
confusionissplitbetween VEHICLES 1 and VEHICLES 2. Bymeasuringinstancesimilarlybasedonthepatternof
modeldecisionmaking,asopposedtosemanticsimilarity,abstractionalignmentenablesqualitativeanalysisofmodel
alignment.
4.2 Benchmarkinglanguagemodels’abstractionalignment
Benchmarkingthespecificityoflanguagemodelshelpsusdistinguishvaluablemodelsthatoutputpreciseanswers
fromthosethatoutputcorrectbutmeaninglesstext. Forinstance,while“Danteisaperson”and“Danteisapoet”
are both correct, we would prefer a language model that outputs the latter since it is operating at the correct level
ofabstraction[Huangetal.,2023]. Metricsforbenchmarkinglanguagemodelspecificityuseadatasetoflanguage
6AbstractionAlignment BOGGUSTETAL.
Task
Occupation Location Birthplace
Model Acc@10 PPP(((ssssss,,,sssggg))) PPP(((ssssss↓↓↓,,,ssssss↑↑↑) PPP(((ssssss↓↓↓↑↑↑,,,sssttt) Acc@10 PPP(((ssssss,,,sssggg))) PPP(((ssssss↓↓↓,,,ssssss↑↑↑) PPP(((ssssss↓↓↓↑↑↑,,,sssttt) Acc@10 PPP(((ssssss,,,sssggg))) PPP(((ssssss↓↓↓,,,ssssss↑↑↑) PPP(((ssssss↓↓↓↑↑↑,,,sssttt)
bert-base[Devlinetal.,2019] 0.2844 0.7046 0.7902 0.0068 0.4316 0.4909 0.9752 0.2304 0.4142 0.6068 0.9994 0.2450
bert-large[Devlinetal.,2019] 0.2214 0.7176 0.8240 0.0116 0.4564 0.4236 0.9821 0.2744 0.4214 0.5652 0.9975 0.2592
roberta-base[Liuetal.,2019] 0.2450 0.6180 0.7898 0.0751 0.3659 0.4999 0.9854 0.1790 0.2897 0.5448 1.000 0.2042
roberta-large[Liuetal.,2019] 0.2244 0.7144 0.8238 0.0797 0.3905 0.4328 0.9869 0.2242 0.2321 0.4216 0.9992 0.2248
gpt-2[Radfordetal.,2019] 0.1610 0.5728 0.5193 0.1682 0.1702 0.4825 0.6659 0.1348 0.3327 0.5972 0.9879 0.1959
Table 1: Abstraction alignment expands existing language model specificity benchmarks. We compute the
subgraphpreference of language models [Devlin et al., 2019, Liu et al., 2019, Radford et al., 2019] on the S-
TESTdataset’soccupation,location,andbirthplacetasks[Huangetal.,2023]. Wecompareexistingmetricsthattest
modelpreferencebetweenaspecificandgeneralanswer(P(s ,s ))[Huangetal.,2023]toabstractionalignment
s g
metricsmeasuringthemodel’spreferenceforanyspecificanswertoanygeneralanswer(P(s ,s ))anditspreference
s↓ s↑
foracorrectansweratanylevelofabstractiontoanincorrectansweronthesametask(P(s ,s )).
s↓↑ t
promptstotestthemodel’spreferencebetweenaspecificandgeneralresponse[Huangetal.,2023]. However,these
metricsarelimitedtotestingonlytwohuman-definedresponsesattwolevelsofabstraction,eventhroughgenerative
modelsmayoutputavarietyofcorrectanswersspanningmanylevelsofabstraction(e.g.,“writer”or“artist”).
Withabstractionalignment,weexpandexistingspecificitybenchmarkstomorethoroughlytestmodelsagainstavariety
ofcorrectanswersspanningmultiplelevelsofabstraction. Insteadoftestingonespecificandonegeneralanswer,we
canusetheabstractionDAGtocomparemanypossibleanswers,suchasallanswersmorespecificormoregeneralthan
thespecificanswer. UsingtheexpressivityoftheabstractionDAG,wecanalsotestthemodelpreferenceforparticular
topics,suchastestingwhetherthemodelprefersacorrectansweroveranincorrectanswerthatisstillrelatedtothe
topic. Byleveraginganexistinglinguisticabstraction,likeWordNet[Miller,1995,Fellbaum,1998],wecantestthese
additionalaspectsofmodelbehaviorwithouttheneedforadditionalhumanlabeling.
We apply abstraction alignment to benchmark BERT [Devlin et al., 2019], RoBERTa [Liu et al., 2019], and GPT-
2 [Radford et al., 2019] language models. We test the models using the S-TEST dataset which contains sentence
promptsformaskedtokenpredictionofthesentence’ssubject’soccupation,location,andbirthplace[Huangetal.,
2023]. Eachofthepromptsislabeledwithacorrespondingspecificanswerandgeneralanswer. Forinstancetheprompt
“LakeLouiseSkiResortisin”ispairedwiththespecificanswer“Alberta”andthegeneralanswer“Canada”[Huang
etal.,2023]. ForeachofthethreetaskswecreateahumanabstractionDAGbymappingtheS-TESTspecificanswers
tonodesintheWordNetabstractionDAG[Miller,1995,Fellbaum,1998]. Wecomputeedgesbetweennodesusing
WordNet’shypernym/hyponymandholynym/meronymfunctions,creatinganabstractiongraphofpreciseandgeneral
answersrelatedtothetask.
Toquantifythemodel’sspecificity,weusesubgraphpreferencetocomparethemodel’spreferenceforanswersin
differentregionsoftheabstractionDAG.Asabaseline,werecreateHuangetal.[2023]’sspecificitymetric. Their
metriccomparesthemodel’sprobabilityinthespecificanswertoitsprobabilityinthegeneralanswer. Wereplicate
thismetricusingsubgraphpreferencebycomparingthevaluesofthespecificanswernodeandthethegeneral
answernode(P(s ,s )). Next,weextendthismetrictotestspecificityacrossadditionalwordsandlevelsofabstraction.
s g
Insteadoftestingonespecificandonegeneralanswer,wecompareallanswersmorespecificthanthespecificanswer
(specific answer and its children) to all answers more general than the specific answer (specific answer’s parents)
(P(s ,s )). We extend these metrics further, testing whether the model prefers a correct answer at any level of
s↓ s↑
abstractiontoanincorrectanswerbycomparingallanswersrelatedtothespecificanswertoallanswersrelatedtothe
task(e.g.,alloccupationwords)(P(s ,s )).
s↓↑ t
Benchmarking models with abstraction alignment reveals aspects of model behavior overlooked by prior metrics.
Existingmetricsindicatethatlanguagemodelsonlyhaveaslightpreferenceforspecificanswers,withmostP(s ,s )
s g
near50%[Huangetal.,2023]. However,byexpandingtoalargersetofpossibleanswers,abstractionalignmentreveals
thatlanguagemodelshaveastrongpreferenceforspecificanswers. Forexample,bert-largeprefersaspecificanswer
onover80%ofinstancesacrossalltasks. Thisresultsuggeststhatpriormetricsaretoostrictanddonotaccountfor
varietyofmodelpreferences,whereasabstractionalignmentmoreaccuratelyreflectsmodelspecificity.
Beyondmakingspecificitytestingmoreaccurate,abstractionalignmentalsoallowsustotestotheraspectsofspecificity.
UsingP(s ,s ),wecantestthemodel’spreferenceforacorrectansweratanylevelofabstractiontoanincorrect
s↓↑ t
answerrelatedtothetask. Forinstance,whenpredictingtheoccupationfor“EnricoCastellaniisa”wecompareall
answersthataredirectancestorsordescendantsofthecorrectanswerPAINTERtoallotheranswersthatareancestorsor
descendantsofanyotheroccupationinthedataset. Whilepreviouslywefoundmodelspreferaspecificcorrectanswer
toageneralcorrectanswer,here,wefindthatmodelsoftenpreferaincorrectanswertoanycorrectanswer. Thisis
notalwayscorrelatedwithaccuracyorotherspecificitymetrics—forinstance,gpt-2hasthelowestaccuracyand
specificityonoccupationpredictionbutthehighestpreferenceforcorrectness. Byusingtheabstractionalignment
methodology,wehaveexpandedtraditionalbenchmarks,exposingotherwisehiddenaspectsofmodelbehavior.
7AbstractionAlignment BOGGUSTETAL.
Top-Level Node Pairs Codable Node Pairs
DISEASES AND INJURIES & PROCEDURES Disorders of lipoid metab... & Essential hypertension Mean Node Level Disorders of lipoid metab... & Unspecified essential hyp... 3.5
DISEASES AND INJURIES & V: SUPPLEMENTARY CLASSIFI... Essential hypertension & Other and unspecified hyp... 4.0
Nonoperative intubation a... & Other diseases of lung
PROCEDURES & V: SUPPLEMENTARY CLASSIFI... Other and unspecified hyp... & Unspecified essential hyp... 4.5 DISEASES AND INJURIES & E: SUPPLEMENTARY CLASSIFI... Disorders of lipoid metab... & Other forms of chronic is... 5.0
Cardiac dysrhythmias & Essential hypertension
PROCEDURES & E: SUPPLEMENTARY CLASSIFI... Coronary atherosclerosis & Disorders of lipoid metab...
Mean Node Level
Other continuous mechanic... & Other diseases of lung
E: SUPPLEMENTARY CLASSIFI... & V: SUPPLEMENTARY CLASSIFI... 7.5 Cardiac dysrhythmias & Unspecified essential hyp...
0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00
Concept Co-Confusion (C(ni,nj)) Concept Co-Confusion (C(ni,nj))
Figure 3: Abstraction alignment’s conceptconfusion metric applied to the MIMIC-III dataset [Johnson et al.,
2016a,b]revealspairsofmedicalconceptsthatareregularlylabeledonthesamemedicalnotes. Weanalyzethetop
conceptconfusionforpairsoftop-levelnodes(left)andpairsofcodelabels(right).
4.3 Analyzingdatasetsusingabstractionalignment
Abstractionalignmentcanalsobevaluableindatasetanalysisbyrevealingdifferencesintheabstractionsweexpect
ourmodelstolearnandthosecodifiedinthedataset. Modelslearncorrelationsbetweeninputfeaturesandoutput
decisionsfromtheirtrainingdata. However,thecorrelationsinthedatasetarenotalwaystheonesamodeldeveloper
expectstheirmodeltolearn. Often,datasetissuesareonlyidentifiedaftermodelstrainedonthemproduceproblematic
outputs[Zechetal.,2018,Caliskanetal.,2022]. Applyingabstractionalignmenttodatasetscanhelpusunderstandhow
theabstractionstheyimplicitlyencodecorrespondwithexpectedhumanabstractionsbeforethedatasetsarereleasedas
trainingdata.
Todemonstrateabstractionalignmentasadatasetanalysistool,weuseittocomparethemedicalabstractionsencodedin
theMIMIC-IIIdatasettomedicalhierarchystandardssetbyglobalhealthauthorities. TheMIMIC-IIIdatasetcontains
patients’medicalnoteslabeledwithasetofICD-9codesrepresentingthepatient’sdiseasesandprocedures[Johnson
etal.,2016a,b]. ThecodesarepartoftheICD-9medicalhierarchyusedbyhospitalstojustifyhealthcarecoststo
insurance[Alexanderetal.,2003]. However,discrepanciesbetweenclinicalcodeapplicationandtheICD-9guidelines
areknowntooccurduetolackofcoderexperience,complexityofthecodingsystem,andintentionalmisusetoincrease
insurancepayout[O’Malleyetal.,2005]. SinceMIMIC-IIIcontainsreal-worldpatientrecordsthatcouldbeaffectedby
clinicalmisuse,thecodelabelsinthedatasetmaynotreflectICD-9’sintendeduse. Abstractionalignmentcanreveal
howwellMIMIC-IIIalignswiththeICD-9abstractiontoinformmodeldevelopersoftheabstractionstheirmodelsmay
learnandperpetuateindeployment.
Toapplyabstractionalignmentinthissetting,weusetheICD-9hierarchyastheabstractionDAGandthedataset’s
ICD-9codelabelstorepresentthedataset’sencodings. TheICD-9hierarchyMullenbachetal.[2018]contains21,116
nodesover7levelsofabstraction. EachnodesrepresentsanICD-9code(e.g.,FRONTALSINUSITIS)orhigher-level
codegrouping(e.g.,RESPIRATORYINFECTIONS). Tocomputetheabstractionalignmentofeachdatasetinstance,we
mapthedataset’slabelstotheICD-9nodes(Section3.2)tocreateaweightedDAGwheretheaggregate valueofa
noderepresentshowmanylabelswereassignedtoitsdescendants. Tounderstandpossiblediscrepanciesbetweenthe
dataset’sabstractionsandtheICD-9abstraction,weuseconceptconfusiontoanalyzepairsofnodesthatco-occur
across dataset instances. We can think of pairs with high conceptconfusion as concepts the dataset represents
similarlybecausebothconceptsoftenapplytothesamemedicalnote.
We begin our analysis by filtering to nodes representing high-level code groupings (i.e., direct descendants of the
root). InICD-9,therearefourtop-levelgroupings: PROCEDURES,DISEASES AND INJURIES,V SUPPLEMENTARY
HEALTHFACTORS,andESUPPLEMENTARYCAUSESOFINJURYANDPOISONING. InFigure3,weseeitiscommon
forthedatasettocontaincodelabelsfrommultipleofthesehigh-levelcodegroupings. AssigningPROCEDUREcodes
withDISEASEANDINJURYcodesmakessensebecauseadiseasedefinesatreatmentprocedure. However,thedataset
frequentlycontainsDISEASEANDINJURYandVSUPPLEMENTARYHEALTHFACTORScodes. IntheICD-9hierarchy,
VSUPPLEMENTARYHEALTHFACTORScodesare“providedtodealwithoccasionswhencircumstancesotherthana
diseaseorinjuryarerecordedasdiagnosisorproblems”[AmericanSpeech-Lanugage-HearingAssociation,2015].
ThefactthatpatientnotesintheMIMIC-IIIdatasetoftencontainbothDISEASEANDINJURYandVSUPPLEMENTARY
HEALTHFACTORScodeswhentheICD-9hierarchyexpectsthemtobeuseddisjointly,suggestsamisalignmentinthe
dataset’sabstractions.
Next,weanalyzeconfusionbetweenlower-levelnodestounderstandhowspecificdatasetlabelsmaybemisaligned
withtheICD-9abstraction. Oftendiseasesshareamedicalcorrelation,soitisexpectedthatthedatasetcommonly
containsbothlabelsformetabolicfactorslikeDISORDERSOFLIPIDMETABOLISMandESSENTIALHYPERTENSION.
However,wealsoseefrequentco-labelingbetween“other”codes,likeOTHERDISEASEOFLUNGandOTHERAND
UNSPECIFIEDHYPERTENSION. InICD-9,acodegroupingoftencontainssiblingcodesrepresentingspecificvariantsof
8
)jn
&
in(
sriaP
edoNAbstractionAlignment BOGGUSTETAL.
thatcodefollowedbyan“other”catchallcode. Thefrequentoccurrenceof“other”codelabelsintheMIMIC-IIIdataset
couldcausemodelstolearntooverapply“other”codeswhentheyareunwarranted. Itcouldalsosuggestthatthereare
commondiseasesandproceduresmissingfromICD-9ormedicalissuesthathavearisensinceitsdevelopmentin1977.
OurabstractionalignmentanalysisofMIMIC-IIIrevealsdiscrepanciesbetweenhowICD-9codesareappliedinthe
datasetandtheICD-9abstractionexpectationsfordiseaseclassification. Thesediscrepanciessuggestthatevenmodels
thatachievehighperformanceonthedatasetmaynotalignwithmedicalstandardsand,ifdeployedtolabelpatient
clinicalnotesinhospitals,couldperpetuatecodemisapplication,leadingtoinaccurateinsurancebilling. Further,our
abstractionalignmentanalysissuggestswaystheICD-9abstractiondoesnotsupportreal-worldcoding. Infact,the
overuseof“other”codesandjointcodingbetweenDISEASEANDINJURYandVSUPPLEMENTARYcodesthatwefound
inviaabstractionalignmentcorrespondstoreal-worldchangesmadeduringthetransitionfromICD-9toICD-10,such
asincreasingcodespecificityandincorporatingsupplementarycodesintothemainhierarchy[Cartwright,2013,World
HealthOrganization,2022]. Thisresultsuggeststhatbeyonddatasetqualityanalysis,abstractionalignmentcanalso
identifyopportunitiesforimprovinggroundtruthhumanabstractions.
5 DiscussionandFutureWork
Inthispaper,westudyabstractionalignment—theagreementbetweenamodel’slearnedconceptualrelationships
andestablishedhumanabstractions. Ininterpretabilitytasks,abstractionalignmentidentifiesmisalignmentsinmodel
reasoning;inmodelbenchmarking,abstractionalignmentexpandstheexpressivenessofevaluationmetrics;and,in
datasetanalysis,abstractionalignmentrevealsdifferencesbetweentheabstractionswewantmodelstolearnandthose
codifiedinthedataset.
WeconsiderabstractionalignmenttobeaparadigmforunderstandingdatasetsandMLmodelbehaviorand,justas
therearemanywaystomeasuremodels’representationalalignment[Sucholutskyetal.,2023,Terryetal.,2023],we
expecttherearelikelyaplethoraoftechniquestomeasureabstractionalignment. Forinstance,followingresearch
methodsthatrevealandeditmodels’representationofstate[Hernandezetal.,2021,Lietal.,2021,Reifetal.,2019,
HewittandManning,2019],futureworkcouldtestwhethermodels’internalrepresentationsencodehumanabstractions.
Internalabstractionalignmentmetricscouldstudyhowabstractionschangeacrossmodellayers,evolveduringtraining,
andwhethermodifyingmodifyingamodel’sinternalabstractionimprovesitsperformance.
Futureworkonabstractionalignmentshouldalsoconsiderconcepttheoriesfromcognitivepsychology. Ourcurrent
approachappliesAristotelianconcepttheorywhereconceptsdefineexactmembershipconditionstodeterminewhether
aninstanceispartofagivenconcept[Rosch,2011]. Thus,thismeansourconceptsarediscrete—DOGSareanimals
fromthespeciescanislupussoSCHNAUZERandWOLFarebothDOGS. However,ifweweretousegradedconcept
theory[RoschandLloyd,1978],conceptswoulddefineacontinuousdegreeofmembership. Inthissetting,acommon
doglikeSCHNAUZERisastrongexampleofaDOGwhereasWOLFisaweakmemberbecause,whiletechnicallystill
aDOG,weperceivethemdifferentlyfromdomesticateddogs. Thismaysuggestamorecontinuousmeasurementof
abstractionalignmentwhereconceptualrelationshipsareweightedbasedonthedegreeofmembership.
Finally,inmanycases,theremaynotexistauniversalhumanabstractionthatappliestoagiventask. Forexample,
individual doctors often develop slightly differing medical abstractions as a function of their medical training and
clinicalexperiences[Caietal.,2019]. Thus,besidesdevelopingclinicalmodelsthatagreewithmedicalstandards,
abstractionalignmentcanhelpusdevelopmodelsthataremorepersonalizedtoaparticularclinician. Forinstance,
abstractionalignmentcouldbeusedtoimprovehuman-AIcollaborationbyensuringbothhumansandmodelsare
reasoningwiththesameabstractions. Moreinterestingly,byadaptingabstractionalignment,wecouldspecificallytrain
modelstolearnabstractionsthatcomplementadoctor’s—actingasvaluablecollaboratorswithadditionalexpertise
andalternateperspectives.
9AbstractionAlignment BOGGUSTETAL.
References
EilingYee. Abstractionandconcepts: when,how,where,whatandwhy? Language,CognitionandNeuroscience,34
(10):1257–1265,2019.
ChristopherAlexander. Apatternlanguage: towns,buildings,construction. Oxforduniversitypress,2018.
BarbaraLiskov,JohnGuttag,etal. Abstractionandspecificationinprogramdevelopment,volume20. MITpress
Cambridge,1986.
KevinWEva. Whateveryteacherneedstoknowaboutclinicalreasoning. Medicaleducation,39(1):98–106,2005.
BeenKim,MartinWattenberg,JustinGilmer,CarrieCai,JamesWexler,FernandaViegas,andRorySayres. Inter-
pretabilitybeyondfeatureattribution: Quantitativetestingwithconceptactivationvectors(TCAV). InInternational
ConferenceonMachineLearning(ICML),pages2668–2677,Stockholm,Sweden,2018.PMLR.
Amirata Ghorbani, James Wexler, and Been Kim. Automating interpretability: Discovering and testing visual
conceptslearnedbyneuralnetworks. ArXiv,abs/1902.03129,2019. URLhttps://api.semanticscholar.org/
CorpusID:59842921.
EvanHernandez,SarahSchwettmann,DavidBau,TeonaBagashvili,AntonioTorralba,andJacobAndreas. Natural
languagedescriptionsofdeepvisualfeatures. InInternationalConferenceonLearningRepresentations,2021.
DavidBau,BoleiZhou,AdityaKhosla,AudeOliva,andAntonioTorralba. Networkdissection: Quantifyinginter-
pretabilityofdeepvisualrepresentations. InConferenceonComputerVisionandPatternRecognition(CVPR),pages
3319–3327.IEEEComputerSociety,2017.
TuomasOikarinenandTsui-WeiWeng. Clip-dissect: Automaticdescriptionofneuronrepresentationsindeepvision
networks. arXivpreprintarXiv:2204.10965,2022.
WorldHealthOrganization. InternationalClassificationofDiseases,NinthRevision(ICD-9). WorldHealthOrganiza-
tion,Geneva,1978.
GeorgeA.Miller. Wordnet: Alexicaldatabaseforenglish. CommunicationsoftheACM,38(11):39–41,1995.
MelvilDewey. DeweyDecimalClassificationandRelativeIndex. OCLCOnlineComputerLibraryCenter,Inc.,23
edition,2011.
CodyE.Hinchliff,StephenA.Smith,JamesF.Allman,JohnGordonBurleigh,RuchiChaudhary,LyndonM.Coghill,
Keith A. Crandall, Jia bin Deng, Bryan Thomas Drew, Romina Gazis, Karl Gude, David S. Hibbett, Laura A.
Katz,H.DailLaughinghouseIv,EmilyJaneMcTavish,PeterE.Midford,ChristopherL.Owen,RichardH.Ree,
JonathanA.Rees,DouglasE.Soltis,TiffaniL.Williams,TiffaniL.Williams,TiffaniL.Williams,TiffaniL.Williams,
TiffaniL.Williams,TiffaniL.Williams,TiffaniL.Williams,TiffaniL.Williams,andKarenA.Cranston. Synthesis
ofphylogenyandtaxonomyintoacomprehensivetreeoflife. ProceedingsoftheNationalAcademyofSciences,112:
12764–12769,2014.
CarlLinnaeus. SystemaNaturaeperRegnaTriaNaturae,SecundumClasses,Ordines,Genera,Species,cumCharac-
teribus,Differentiis,Synonymis,Locis,volume10. LaurentiusSalvius,1758.
AlexKrizhevsky,GeoffreyHinton,etal. Learningmultiplelayersoffeaturesfromtinyimages. 2009.
JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLiFei-Fei. Imagenet: Alarge-scalehierarchicalimage
database. InConferenceonComputerVisionandPatternRecognition(CVPR),pages248–255.IEEEComputer
Society,2009.
AlistairEWJohnson,TomJPollard,LuShen,Li-weiHLehman,MenglingFeng,MohammadGhassemi,Benjamin
Moody,PeterSzolovits,LeoAnthonyCeli,andRogerGMark. Mimic-iii,afreelyaccessiblecriticalcaredatabase.
Scientificdata,3(1):1–9,2016a.
AlistairJohnson,TomPollard,andRogerMark. Mimic-iiiclinicaldatabase(version1.4),2016b.
JosephRedmonandAliFarhadi. Yolo9000: better,faster,stronger. InProceedingsoftheIEEEconferenceoncomputer
visionandpatternrecognition,pages7263–7271,2017.
ChristianeFellbaum. WordNet: Anelectroniclexicaldatabase. MITpress,1998.
FinaleDoshi-VelezandBeenKim. Towardsarigorousscienceofinterpretablemachinelearning,2017.
ArunRai. ExplainableAI:Fromblackboxtoglassbox. JournaloftheAcademyofMarketingScience,48(1):137–141,
2020.
RamprasaathR.Selvaraju,MichaelCogswell,AbhishekDas,RamakrishnaVedantam,DeviParikh,andDhruvBatra.
Grad-cam: Visualexplanationsfromdeepnetworksviagradient-basedlocalization. InInternationalConferenceon
ComputerVision(ICCV),pages618–626.IEEE,2017.
10AbstractionAlignment BOGGUSTETAL.
Brandon Carter, Jonas Mueller, Siddhartha Jain, and David K. Gifford. What made you do this? Understanding
black-boxdecisionswithsufficientinputsubsets. InInternationalConferenceonArtificialIntelligenceandStatistics
(AISTATS),pages567–576.PMLR,2019a.
AngieBoggust,BenjaminHoover,ArvindSatyanarayan,andHendrikStrobelt. Sharedinterest: Measuringhuman-ai
alignmenttoidentifyrecurringpatternsinmodelbehavior. InSimoneD.J.Barbosa,CliffLampe,CarolineAppert,
DavidA.Shamma, StevenMarkDrucker, JulieR.Williamson, andKojiYatani, editors, ConferenceonHuman
FactorsinComputingSystems(CHI),pages10:1–10:17.ACM,2022.
ChrisOlah,AlexanderMordvintsev,andLudwigSchubert. Featurevisualization. Distill,2(11):e7,2017.
D.Erhan,YoshuaBengio,AaronC.Courville,andPascalVincent. Visualizinghigher-layerfeaturesofadeepnetwork.
2009.
TrentonBricken,AdlyTempleton,JoshuaBatson,BrianChen,AdamJermyn,TomConerly,NickTurner,CemAnil,
CarsonDenison,AmandaAskell,etal. Towardsmonosemanticity: Decomposinglanguagemodelswithdictionary
learning. TransformerCircuitsThread,page2,2023.
BrandonCarter,SiddharthaJain,JonasWMueller,andDavidGifford. Overinterpretationrevealsimageclassification
modelpathologies. AdvancesinNeuralInformationProcessingSystems,34:15395–15407,2021.
ChrisOlah,ArvindSatyanarayan,IanJohnson,ShanCarter,LudwigSchubert,KatherineYe,andAlexanderMordvint-
sev. Thebuildingblocksofinterpretability. Distill,3(3):e10,2018.
Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah. Activation atlas. Distill, 2019b.
doi:10.23915/distill.00015. https://distill.pub/2019/activation-atlas.
LisaSchut,NenadTomasev,TomMcGrath,DemisHassabis,UlrichPaquet,andBeenKim. Bridgingthehuman-ai
knowledgegap: Conceptdiscoveryandtransferinalphazero. arXivpreprintarXiv:2310.16410,2023.
ShaoxiongJi,ShiruiPan,E.Cambria,PekkaMarttinen,andPhilipS.Yu.Asurveyonknowledgegraphs:Representation,
acquisition,andapplications. IEEETransactionsonNeuralNetworksandLearningSystems,33:494–514,2020.
URLhttps://api.semanticscholar.org/CorpusID:211010433.
YankaiLin,XuHan,RuobingXie,ZhiyuanLiu,andMaosongSun. Knowledgerepresentationlearning: Aquantitative
review. arXivpreprintarXiv:1812.10901,2018.
Liang Yao, Chengsheng Mao, and Yuan Luo. Kg-bert: Bert for knowledge graph completion. arXiv preprint
arXiv:1909.03193,2019.
KaiSun,YifanEthanXu,HanwenZha,YueLiu,andXinLunaDong. Head-to-tail: Howknowledgeablearelarge
languagemodels(llm)? akawillllmsreplaceknowledgegraphs? arXivpreprintarXiv:2308.10168,2023.
JieHuang,KevinChen-ChuanChang,JinjunXiong,andWen-MeiHwu. Canlanguagemodelsbespecific? how? In
FindingsoftheAssociationforComputationalLinguistics(ACL),pages716–727.ACL,2023.
KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimagerecognition. InIEEE
ConferenceonComputerVisionandPatternRecognition,(CVPR),pages770–778.IEEEComputerSociety,2016a.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional
transformers for language understanding. In Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 4171–4186. Association for
ComputationalLinguistics,2019.
YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,MandarJoshi,DanqiChen,OmerLevy,MikeLewis,LukeZettlemoyer,
andVeselinStoyanov. Roberta: Arobustlyoptimizedbertpretrainingapproach. arXivpreprintarXiv:1907.11692,
2019.
AlecRadford,JeffWu,RewonChild,DavidLuan,DarioAmodei,andIlyaSutskever.Languagemodelsareunsupervised
multitasklearners. 2019.
JohnRZech,MarcusABadgeley,ManwayLiu,AnthonyBCosta,JosephJTitano,andEricKarlOermann. Variable
generalizationperformanceofadeeplearningmodeltodetectpneumoniainchestradiographs: across-sectional
study. PLoSmedicine,15(11):e1002683,2018.
AylinCaliskan,PimparkarParthAjay,TessaCharlesworth,RobertWolfe,andMahzarinR.Banaji. Genderbiasinword
embeddings: Acomprehensiveanalysisoffrequency,syntax,andsemantics. InVincentConitzer,JohnTasioulas,
Matthias Scheutz, Ryan Calo, Martina Mara, and Annette Zimmermann, editors, AAAI/ACM Conference on AI,
Ethics,andSociety(AIES),pages156–170.ACM,2022.
SherriAlexander,ThereseConner,andTeresaSlaughter. Overviewofinpatientcoding. Americanjournalofhealth-
systempharmacy: AJHP:officialjournaloftheAmericanSocietyofHealth-SystemPharmacists,6021Suppl6:
S11–4,2003.
11AbstractionAlignment BOGGUSTETAL.
KimberlyO’Malley,KaronF.Cook,MattD.Price,KimberlyRaifordWildes,JohnF.Hurdle,andCarolM.Ashton.
Measuringdiagnoses: Icdcodeaccuracy. Healthservicesresearch,405Pt2:1620–39,2005.
JamesMullenbach,SarahWiegreffe,JonDuke,JimengSun,andJacobEisenstein. Explainablepredictionofmedical
codes from clinical text. In Marilyn A. Walker, Heng Ji, and Amanda Stent, editors, Proceedings of the 2018
ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguage
Technologies(NAACL-HLT),pages1101–1111.AssociationforComputationalLinguistics,2018.
AmericanSpeech-Lanugage-HearingAssociation. ModuleTwo: InternationalClassificationofDiseases–9thRevi-
sion–ClinicalModification(ICD-9-CM). https://www.asha.org/practice/reimbursement/module-two/,
2015. Accessed: 2024-01-29.
DonnaJCartwright. Icd-9-cmtoicd-10-cmcodes: what? why? how?,2013.
WorldHealthOrganization.InternationalClassificationofDiseases,10thRevision.WorldHealthOrganization,Geneva,
Switzerland,2022.
IliaSucholutsky,LukasMuttenthaler,AdrianWeller,AndiPeng,AndreeaBobu,BeenKim,BradleyC.Love,ErinGrant,
JaschaAchterberg,JoshuaB.Tenenbaum,KatherineM.Collins,KatherineL.Hermann,KeremOktar,KlausGreff,
MartinN.Hebart,NoriJacoby,QiuyiZhang,RajaMarjieh,RobertGeirhos,SherolChen,SimonKornblith,Sunayana
Rane,TaliaKonkle,ThomasP.O’Connell,ThomasUnterthiner,AndrewK.Lampinen,Klaus-RobertMüller,Mariya
Toneva, andThomasL.Griffiths. Gettingalignedonrepresentationalalignment. CoRR,abs/2310.13018, 2023.
doi:10.48550/ARXIV.2310.13018. URLhttps://doi.org/10.48550/arXiv.2310.13018.
MichaelTerry,ChinmayKulkarni,MartinWattenberg,LucasDixon,andMeredithRingelMorris. AIalignmentinthe
designofinteractiveAI:specificationalignment,processalignment,andevaluationsupport. CoRR,abs/2311.00710,
2023. doi:10.48550/ARXIV.2311.00710. URLhttps://doi.org/10.48550/arXiv.2311.00710.
BelindaZ.Li,MaxwellI.Nye,andJacobAndreas. Implicitrepresentationsofmeaninginneurallanguagemodels.
InAnnualMeetingoftheAssociationforComputational(ACL),pages1813–1827.AssociationforComputational
Linguistics,2021.
EmilyReif,AnnYuan,MartinWattenberg,FernandaB.Viégas,AndyCoenen,AdamPearce,andBeenKim.Visualizing
andmeasuringthegeometryofBERT.InAdvancesinNeuralInformationProcessingSystems32:AnnualConference
onNeuralInformationProcessingSystems2019,NeurIPS2019,December8-14,2019,Vancouver,BC,Canada,
pages8592–8600,2019.
JohnHewittandChristopherD.Manning. Astructuralprobeforfindingsyntaxinwordrepresentations. InConference
oftheNorthAmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,
(NAACL-HLT),pages4129–4138.AssociationforComputationalLinguistics,2019.
EleanorRosch. Slowlettuce: Categories,concepts,fuzzysets,andlogicaldeduction. Conceptsandfuzzylogic,8:
89–120,2011.
EleanorRoschandBarbaraBLloyd. Principlesofcategorization. 1978.
CarrieJ.Cai,SamanthaWinter,DavidSteiner,LaurenWilcox,andMichaelTerry."helloai":Uncoveringtheonboarding
needsofmedicalpractitionersforhuman-aicollaborativedecision-making. Proc.ACMHum.Comput.Interact.,3
(CSCW):104:1–104:24,2019.
AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,GregoryChanan,TrevorKilleen,Zeming
Lin,NataliaGimelshein,LucaAntiga,etal. Pytorch: Animperativestyle,high-performancedeeplearninglibrary.
Advancesinneuralinformationprocessingsystems,32,2019.
KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Identitymappingsindeepresidualnetworks. InComputer
Vision–ECCV2016: 14thEuropeanConference,Amsterdam,TheNetherlands,October11–14,2016,Proceedings,
PartIV14,pages630–645.Springer,2016b.
IlyaSutskever,JamesMartens,GeorgeDahl,andGeoffreyHinton. Ontheimportanceofinitializationandmomentum
indeeplearning. InInternationalconferenceonmachinelearning,pages1139–1147.PMLR,2013.
FabioPetroni,PatrickLewis,AleksandraPiktus,TimRocktäschel,YuxiangWu,AlexanderH.Miller,andSebastian
Riedel. Howcontextaffectslanguagemodels’factualpredictions. InAutomatedKnowledgeBaseConstruction,
2020. URLhttps://openreview.net/forum?id=025X0zPfn.
F.Petroni,T.Rocktäschel,A.H.Miller,P.Lewis,A.Bakhtin,Y.Wu,andS.Riedel. Languagemodelsasknowledge
bases? InIn: Proceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),
2019,2019.
12AbstractionAlignment BOGGUSTETAL.
A Appendix
A.1 Experimentaldetails
HerewedescribetheexperimentaldetailsforeachexperimentinSection4. Codetorecreateourexperimentscan
be found at: https://github.com/mitvis/abstraction-alignment. An interactive interface for exploring
experimentalresultsisprovidedat: https://vis.mit.edu/abstraction-alignment/.
A.1.1 Interpretingmodelbehaviorwithabstractionalignment
In Section 4.1, we use abstraction alignment to interpret a CIFAR-100 image classification model. We train a
PyTorch [Paszke et al., 2019] ResNet20 model [He et al., 2016a] on CIFAR-100 training set [Krizhevsky et al.,
2009]for200epochswithabatchsizeof128. Weapplyrandomcropandhorizontalflipdataaugmentationstothe
imagesfollowingHeetal.[2016b]. Weusecross-entropylossoptimizedviastochasticgradientdescentandNesterov
momentum[Sutskeveretal.,2013](momentum=0.9;weightdecay=5e-4). Weusealearningrateof0.1andreduceit
atepoch60,120,and160usinggammaof0.2. Thetrainedmodelachieves67.7%accuracyontheCIFAR-100testset.
ToapplyabstractionalignmentweusetheCIFAR-100class/superclassmapping[Krizhevskyetal.,2009]toform
anabstractionDAG.TheDAGcontains121nodesacross3levels—100classnodes(level1),20superclassnodes
(level2),andarootnode(level3). WecreateaweightedDAGforeverydatasetinstanceintheCIFAR-100testset,
representingthemodel’sabstractionalignmentforthatinstance. Todoso,foragivenimage,wecomputethemodel’s
softmaxoutputprobabilitiesovertheclasses. FollowingAlgorithm1,weassignclassnodesintheDAGavalueequal
tothemodel’soutputprobabilityforthatclass. Allothernodesrecieveavalueofzero. Wecomputeeverynode’s
aggregate valueasthesumofalloftheirdescendant’svalues. Forinstance,thenodeTULIP’saggregate value
isthemodel’soutputprobabilitythattheimageisatulip,whereasthenodeFLOWER’saggregate valueisthesum
ofthemodel’soutputprobabilityforORCHID,ROSE,TULIP,SUNFLOWER,andPOPPY.
A.1.2 Benchmarkinglanguagemodels
InSection4.2,weapplyabstractionalignmenttobenchmarklanguagemodels. Followingthebenchmarkingprocedure
inHuangetal.[2023],wecomparepretrainedbert-base[Devlinetal.,2019],bert-large[Devlinetal.,2019],
roberta-base[Liuetal.,2019],roberta-large[Liuetal.,2019],andgpt-2[Radfordetal.,2019]modelsfrom
theLAMAbenchmark3 [Petronietal.,2020,2019]. Wetesteachmodelontheoccupation,location,andbirthplace
tasksfromtheS-TESTdataset4[Huangetal.,2023]. EachdatainstanceintheS-TESTdatasetisatextquerypaired
withonespecificandonegeneralanswerlabel. Foreachmodel,wecomputeitstop-10accuracy,measuredasthe
proportionofinstanceswherethespecificanswerwasinthemodel’stop10predictedtokens.
Tomeasureabstractionalignment,wecreateanabstractionDAGforeachoftheoccupation,location,andbirthplace
tasks. Foratask,wemapeachofitsspecificanswerlabelstoitscorrespondingnode(i.e.,synset)inWordNet[Miller,
1995,Fellbaum,1998]. WedothisprocessbysearchingforthespecificanswerlabelintheNLTKWordNetcorpus5.
If there are multiple WordNet nodes that hit for a given search, we select the most appropriate node by manually
inspectingtheirWordNetdefinitions. Then,weexpandtheDAGbyincludingalldirectancestorsanddescendantsof
anyspecificanswernodes. Weonlyconsiderancestorsanddescendantsthatexistinthemodel’svocabulary. Theresult
isaDAGcontainingallthevocabularywordsrelatedtoanyofthedatainstances’specificanswerlabels.
TocreateweightedDAGs,wecomputethemodel’soutputprobabilityacrosseverywordinitsvocabularyforevery
datainstance. Foreachdatainstance,weassignthemodel’soutputprobabilitiestotheircorrespondingnodesinthe
DAG.WeusetheweightedDAGstocomputethreespecificitymetrics,usingthesubgraphpreferencefunction
Equation(3). Ineachmetric,weusethenodevaluescorrespondingtothemodel’spredictedprobabilityoutputs. First,
wecomputereplicatethespecificitytestingmetricfromHuangetal.[2023](originallycalledp ). Wecomputeitas
r
P(s ,s ),wheres isthesingle-nodegraphcontainingthespecificlabelands isthesingle-nodegraphcontainingthe
s g s g
generalanswerlabel. Next,wecomputeP(s ,s )tocompareallwordsatthespecificlabel’slevelofabstractionand
s↓ s↑
lowers (specificlabelanditsdescendants)toallwordsatahigherlevelofabstractionthanthespecificlabels
s↓ s↑
(specificlabel’sancestors). Finally,wecomputeP(s ,s )tocompareancestorsanddescendantsofthespecificlabel
s↑↓ t
s toanyotherwordinthetaskDAGs .
s↑↓ t
3https://github.com/facebookresearch/LAMA
4https://github.com/jeffhj/S-TEST
5https://www.nltk.org/howto/wordnet.html
13AbstractionAlignment BOGGUSTETAL.
A.1.3 Analyzingdatasetsusingabstractionalignment
InSection4.2,weapplyabstractionalignmenttoanlayzetheabstractionsintheMIMIC-IIIdataset[Johnsonetal.,
2016a,b]. ThedatasetcontainstextualmedicalnotespairedwithasetofICD-9codelabels. WeusetheICD-9medical
hierarchyastheabstractionDAG[WorldHealthOrganization,1978]. Wepairthedataset’sICD-9codelabelswiththeir
correspondingcodeintheICD-9abstractionDAG.TocomputeweightedDAGsforeverydatasetinstance,wesetthe
codenode’svalueequaltooneifthecodewaslabeledonthatinstanceandzerootherwise. Forallothernodes(e.g.,
non-codablenodegroupings),weassigntheiraggregate valueasthesumofitschildren. Asaresulttheaggregate
valueofanodeisequivalenttothenumberoftimesitoroneofitschildrenlabeledthemedicalnote. Inthetask,
non-leafnodesarecodable. Forinstance,bothSICKLE-CELLANEMIAanditsdirectparentHEREDITARYHEMOLYTIC
ANEMIAScanbeappliedtothesamemedicalnote.
A.2 Computeresourcesandefficiency
AllabstractionalignmentanalysisisperformedonCPU.TimetobuildtheDAGandcomputeabstractionalignment
dependsonthenumberofnodesintheDAGandtheabstractionalignmentmetric. OntheCIFAR-100DAG(121
nodes)[Krizhevskyetal.,2009],computingtheweightedDAGfor10,000CIFAR-100testimagestakesapproximately
2 minutes, computing accuracyalignment and uncertaintyalignment takes under a minute, and computing
conceptconfusiontakesontheorderof15minutes. OntheMIMIC-IIIDAG(21,166nodes),creatingtheweighted
abstractionDAGsandcomputingconceptconfusiontakesaround30minutes.
Wetrainandevaluatethemodelsusedintheexperimentson1NVIDIAV100GPUwith1TBofmemory. Trainingthe
CIFAR-100ResNet20modeltakesapproximately30minutes. RunninginferenceontheS-TESTdatasettakesroughly
10minutesperlanguagemodel.
A.3 Additionalabstractionalignmentexamples
AdditionalexamplesoftheabstractionalignmentofdatainstancesfromSection4.1andSection4.3areavailableinan
exploratoryinterfacehttps://vis.mit.edu/abstraction-alignment/.
14