RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal
Models
PengkunJiao1,XinlanWu1,
BinZhu2,JingjingChen1,Chong-WahNgo2,YugangJiang1
1FudanUniversity
2SingaporeManagementUniversity
Abstract
FoodRelatedTasks FoodImage
Large Multi-modal Models (LMMs) have significantly ad-
vancedavarietyofvision-languagetasks.Thescalabilityand Food Whatdishisdepictedinthe
availabilityofhigh-qualitytrainingdataplayapivotalrolein Classification image?
thesuccessofLMMs.Intherealmoffood,whilecomprehen-
Ingredient Whatingredientsare
sive food datasets such as Recipe1M offer an abundance of Recognitoin includedinthisdish?
ingredientandrecipeinformation,theyoftenfallshortofpro-
viding ample data for nutritional analysis. The Recipe1M+ Couldyouprovidemewith
Recipe
dataset, despite offering a subset for nutritional evaluation, Generation theinstructionsonhowto
preparethisdish?
is limited in the scale and accuracy of nutrition informa- LMM
tion. To bridge this gap, we introduce Uni-Food, a unified Nutrition Pleaseestimatethecalorie
fooddatasetthatcomprisesover100,000imageswithvarious Estimation contentofthefood.
food labels, including categories, ingredients, recipes, and
ingredient-levelnutritionalinformation.Tomitigatethecon-
flicts arising from multi-task supervision during fine-tuning Figure 1: RoDE’s Emphasis on Food-Related VQA Tasks.
of LMMs, we introduce a novel Linear Rectification Mix- RoDEprimarilytargetsmulti-tasklearningspecifictofood,
ture of Diverse Experts (RoDE) approach. RoDE utilizes a
i.e.,foodclassification,ingredientrecognition,andnutrition
diversearrayofexpertstoaddresstasksofvaryingcomplex-
estimation.
ity,therebyfacilitatingthecoordinationoftrainableparame-
ters,i.e.,itallocatesmoreparametersformorecomplextasks
and, conversely, fewer parameters for simpler tasks. RoDE
implements linear rectification union to refine the router’s a million web-crawled recipes and thousands of food im-
functionality,therebyenhancingtheefficiencyofsparsetask
ages,itlackscomprehensivenutritionalinformation.While
allocation.ThesedesignchoicesendowRoDEwithfeatures
Recipe1M+(Marinetal.2019)includesasubsetcontaining
thatensureGPUmemoryefficiencyandeaseofoptimization.
nutritional information, it suffers from limitations in data
Ourexperimentalresultsvalidatetheeffectivenessofourpro-
scale and annotation quality. Similarly, nutrition-focused
posedapproachinaddressingtheinherentchallengesoffood-
relatedmultitasking. datasets such as Nutrition5k (Thames et al. 2021) are also
limited in scale and may suffer from domain shift issues,
as the labeled data primarily consists of lightly processed
ingredientsratherthanfullycookedmeals.Moreover,previ-
Introduction
ousstudies(Zhouetal.2022;Chen,Jie,andMa2024)have
Food occupies a central position in our daily lives, leading indicated that integrating diverse sources of data for train-
to the emergence of various food-related tasks, e.g., ingre- ingcanleadtodataconflicts.TheperformanceofanLMM
dientrecognition,recipegeneration,andnutritionalestima- onaspecifictaskalsodependsheavilyontherepresentation
tion.Thesetaskshaveattractedconsiderableresearchinter- ofthattask’sdatawithintheoveralltrainingdataset(Chen,
ests over the years (Chen and Ngo 2016a; Zhu et al. 2019; Jie,andMa2024).Thesechallengeshighlighttheneedfora
Panetal.2020;Chenetal.2020;Minetal.2023;Luoetal. unifieddatasetcoveringallfood-relatedtasksfromthesame
2023). Building on the success of Large Language Models source,aimingatmitigatingdataconflictsandensuringbal-
(LLMs) (Radford et al. 2018; Touvron et al. 2023), Large ancedrepresentationacrosstasks.
Multi-modalModels(Liuetal.2023a;Luoetal.2023)have In order to overcome these obstacles, we introduce Uni-
begun to make a significant impact in many specialized ar- Food, a unified dataset that encapsulates various food-
eas,includingthefooddomain(Yinetal.2023). relatedinformation,i.e.,foodcategory,ingredients,recipes,
ThesuccessofLLMsandLMMscanbelargelyattributed and valuable ingredient-level nutritional information for
totheavailabilityoflarge-scaletrainingdata.Inthefooddo- each food image. Specifically, we curate 100,000 sam-
main,whileRecipe1M(Salvadoretal.2017)providesover ples from Recipe1M (Salvador et al. 2017) and employ
4202
luJ
71
]VC.sc[
1v03721.7042:viXraCategory Ingredients Nutrition
h.a.t. sandwich (ham, asparagus & tomato). rustic white bread, tomato slices…
Ingredient Mass Energy Fat Carb Protein
Recipe
rustic white
1. Heat grill pan on high heat. bread 64g 160kcal 1.5g 30g 4g
2. Brush asparagus evenly with 1 tsp. oil; cook 5 to 8 min. or until crisp-tender.
3. Remove from pan. Cut to fit bread. tomato slices 34g 6kcal 0.1g 1.3g 0.4g
4. fill bread slices with cheese, asparagus, spinach, ham and tomatoes. ……
……
Figure2:LabelConstitution.Theannotationconsistsofcategory,ingredientlist,recipeinstructions,andnutritioninformation.
ChatGPT-4 (Achiam et al. 2023) to generate nutritional in- RectifiedLinearUnit(ReLU)torefineitsoutput,whichcon-
formation for each ingredient list. This information is then fers two significant benefits: 1) it enables sparse task-skill
aggregatedtoderivethenutritionaldatafortheentiredish. matching, which has been proved to surpass dense activa-
Furthermore,inordertoensureahigh-qualitygoldstandard tion methods in effectiveness (Zhou et al. 2022; Chen, Jie,
setfortesting,weutilizehumancurationtoisolateasuperior andMa2024);2)thesimplicityoftheReLUfunctionmakes
subsetspecificallydesignatedfortestingpurposes. itinherentlyeasytooptimize.Consequently,thisleadstoa
sparing activation of the diverse expert set. RoDE is engi-
Our proposed dataset facilitates large-scale training of
neered to optimize the allocation and usage of the model’s
LMMs for various food-related tasks within the same
resources, significantly bolstering the capabilities of large-
dataset.Nevertheless,thisendeavoralsopresentsnewchal-
scalemodelsinmulti-tasklearningscenarios.Ourempirical
lengesassociatedwithmulti-tasklearningwhenfine-tuning
findings underscore the superior performance of RoDE in
largemodels.MixtureofExperts(MoE)(Huangetal.2023;
therealmoffoodmulti-tasklearningchallenges,validating
Douetal.2023;Liuetal.2023b;Pontietal.2023)hasbeen
thestrengthofourproposedmethodology.
a common strategy in the field of Natural Language Pro-
Ourcontributionscanbesummarizedasfollows:
cessing(NLP)tohandlemulti-taskfine-tuning.Thismethod
involvestheutilizationofmultipleexpertmodels,eachspe- • WeintroduceUni-Food,anoveldatasetencompassinga
cializedindifferenttaskorsegmentofthedatadistribution. variety of food vision tasks. Building upon the substan-
Recently, there has been a surge in the application of MoE tialingredientandrecipedataset,wefurtherincorporate
toLMMs.MoE-LLaVA(Linetal.2024),forinstance,inte- valuableingredient-levelnutritionalinformationtofacil-
gratesMoEintoitsFeed-ForwardNetwork(FFN)layersto itaterelevantdietaryresearch.
enhancethemodel’sadaptabilityacrosstasks.Ontheother
• WeproposeLinearRectifiedMixtureofDiverseExperts
hand,LLaVA-MoLE(Chen,Jie,andMa2024)incorporates
(RoDE) approach designed to effectively tackle food
the MoE paradigm into the Low-Rank Adaptation (LoRA)
multi-tasks learning. RoDE approach leverages a com-
(Huetal.2021)module,selectingthetop-1expertsforeach
bination of LoRA experts with varying ranks to model
specific task to guarantee the spare activation of experts.
tasksofdifferentcomplexitiesandemployslinearrecti-
However, as MoE-LLaVA incorporates experts throughout
fiedroutertosparselyallocatetheseexpertstoappropri-
theFFNlayer,theresultingincreaseintrainingparameters
atetasks.
canbeprohibitive.Conversely,althoughLLaVA-MoLEuti-
lizesLoRAexperts,whicharemoreparameter-efficient,its • Experimentalresultsdemonstratetheeffectivenessofour
strategy of selecting only the top expert may constrain the proposedapproachonfoodmulti-tasklearning.Andab-
model’sflexibilityonskillleverage.Thisisbecausecertain lationstudieshighlighttheGPUmemoryefficiencyand
tasks might share foundational skills. For example, in the the sparse allocation of experts intrinsic to our RoDE
food domain, both ingredients recognition and recipe gen- model.
eration are sensitive to the composition of ingredients in a
dish. RelatedWork
To address the aforementioned issues, we propose Lin- Large Multimodal Models (LMMs). In recent years, Large
ear Rectified Mixture of Diverse Experts (RoDE). Follow- Language Models (LLMs) have showcased remarkable
ing LLaVA-MoLE (Chen, Jie, and Ma 2024), we design prowessinNaturalLanguageProcessing(NLP),pavingthe
experts from the LoRA perspective to ensure efficient use wayforbreakthroughsinmultimodallearning.LMMstypi-
oftrainableparameters.UnlikeLLaVA-MoLE,whichdedi- callyintegrateapre-trainedvisionencoderwithaLLMar-
cateseachexperttoaparticulartask,LLaVA-RoDEconcep- chitecture.Subsequently,visualfeaturesundergoadaptation
tualizesexpertsasgranularskillmodules,allowingmultiple viaaprojectionmodule,facilitatingtheirintegrationintothe
experts to participate in a single task. This design inspires hidden space of LLMs for joint processing with textual in-
us to develop experts with diverse capabilities—that is, we puts.Throughmultimodaltraining,LMMsacquirethecapa-
allocatevaryingamountsoftrainableparameterstoeachex- bilitytogenerateresponsesbasedonbothvisualandtextual
pertinanefforttoconserveGPUmemory.Tointegratethe inputs. LLaVA (Liu et al. 2023a), for instance, introduces
experts,wethenintroducealinearrectifiedroutertoassign a vision encoder to LLMs and demonstrates significant en-
taskstotheappropriateLoRAexperts.Therouteremploysa hancements across various vision-language tasks. BuildingDataset category ingredient recipe nutrition layers. LoRAHub (Huang et al. 2023) initially trains a se-
ries of LoRA weights on upstream tasks. To adapt these
Food-101 101k 0 0 0
Food2K 1,036,564 0 0 0 toadownstreamtask,itemploysagradient-freemethodto
VireoFood-251 169,673 169,673 0 0 searchforthecoefficientsthatwillcombinethepre-trained
Nutrition5k 0 20k 0 20k LoRAset.MOELoRA(Liuetal.2023b),ontheotherhand,
Recipe1M 887,706 887,706 887,706 0
utilizes a router conditioned on a task identifier to dynam-
Recipe1M+ 13,735,679 13,735,679 887,536 42,713
ically merge multiple LoRA outputs. In contrast, MoCLE
Uni-Food 100k 100k 100k 100k
(Gouetal.2023)designsarouterthatisconditionedonthe
clusteringinformationofeachindividualinputsample.Lo-
Table1:AnnotationDiversityinFoodDatasets.Thevolume
RAMoE(Douetal.2023)partitionstheLoRAexpertsinto
andvarietyofannotationsdiffersignificantlyacrossvarious
two groups and purposefully cultivates different capabili-
fooddatasets.Uni-Foodoffersalarge-scaletrainingdataset,
tieswithineachgroup.Allthesemixture-of-LoRAmethods
accommodatingabroadspectrumoffood-relatedtasks.
havepre-sethyperparametersthatrequiremeticulousselec-
tion, and the LoRA experts are densely combined. (Zhou
etal.2022)conductedacomparisonbetweenthedenseand
upon LLaVA’s advancements, LISA (Lai et al. 2023) fur-
sparse mixtures of LoRA experts for large language mod-
ther enriches multimodal models by incorporating a seg-
els, concluding that a dense mixture yields superior per-
mentation module. This addition augments the model’s ca-
formance. Some studies have migrated MoE designs into
pacity to discern fine-grained details within visual inputs,
LMMs. MoE-LLaVA (Lin et al. 2024) introduces multiple
resultinginmorenuancedandcontextuallyricherrepresen-
FFNsinsteadofasingleoneandintegratesaroutermech-
tations. GPT-4v (Achiam et al. 2023) stands out as one of
anismtosamplepredictions.LLaVA-MoLE(Chen,Jie,and
themostpowerfulLMMs,capableofprovidinginstructional
Ma2024)appliesmultipleLoRAsandactivatesonespecif-
dataacrossnumerousresearchdomains.Itspotencyextends
ically for a task. However, these methods fall short in ef-
beyondNLP,contributingtoadvancementsinvariousinter-
fectivelyhandlingthenuancesofrational,fine-grainedtask-
disciplinaryfields.
skillallocation.Ourpaperaimstoaddressthisgap.
Food Multi-task Learning. With food playing a significant
part in human life, there has been a lot of work carried DatasetConstruction
out doing research in this domain. In the early stage, food
In this paper, we construct a large-scale dataset called
classification (Bossard, Guillaumin, and Van Gool 2014;
Uni-Food. Different from other publicly available food
Qiu et al. 2022) happened to be the most popular task re-
datasets (Bossard, Guillaumin, and Van Gool 2014; Marin
lated,bringingupasurgeinthenumberofrelevantdatasets,
etal.2019;ChenandNgo2016a;Thamesetal.2021),Uni-
like Food-101 (Bossard, Guillaumin, and Van Gool 2014),
Food contains various attributes used in food-related tasks,
UECFood256(KawanoandYanai2014)andFood2K(Min
includingfoodcategory,ingredients,recipeandnutritionfor
etal.2023).Asthetasksinthefooddomaindevelopedinto
each food image. To the best of our knowledge, this is the
greater diversity, from ingredient recognition (Wang et al.
largestdatasetthatprovidesalltheattributesinonedataset.
2022; Gao et al. 2023; Luo et al. 2023), recipe genera-
Table 1 summarizes the tasks and sample sizes of existing
tion (Salvador et al. 2019; Chhikara et al. 2024) to nutri-
primarydatasetsandourUni-Fooddataset.
tionestimation(Andoetal.2019;Thamesetal.2021),food
datasetshavealsogrowntobemorediverseandlarge-scale. Attribution
VireoFood-172(ChenandNgo2016b)and251(Chenetal.
Our objective is to construct a unified and comprehensive
2021)aredatasetscontainingnotonlycategoryinformation
dataset containing rich information relevant to food, en-
butalsoingredientlabels,Recipe1M(Salvadoretal.2017)
compassing the following key attribution for each image.
andRecipe1M+(Marinetal.2019)aredatasetsinvolvinga
Category: Classifying each food item into specific cate-
wealthofrecipedata,andNutrition5K(Thamesetal.2021)
gories to facilitate organization and categorization within
isadatasetspecializedinhighaccuracynutritionalcontent
thedataset.IngredientsInformation:Providingathorough
annotation. While all of the above methods have demon-
breakdown of the ingredients used in each dish, including
strated their performance on food, they were all limited to
theirnamesandquantities.CookingInstructions:Offering
address one or a few tasks, rather than integrating all tasks
step-by-step instructions on how to prepare each dish, en-
into a single multimodal model. To accomplish this, Yin et
suring clarity and completeness for easy reproduction. Nu-
al. came up with FoodLMM (Yin et al. 2023), a versatile
tritionInformation:Incorporatingdetailednutritionaldata
food assistant based on LMMs that could handle a variety
foreachdish,suchasmacronutrientcontent(e.g.,carbohy-
of tasks in the food domain. However, their method might
drates,proteins,fats),micronutrients,andtotalcalories.An
lead to task conflict when several tasks were fine-tuned at
intuitivesampledemonstrationoftheseattributionsisshown
the same time, lacking the capability to efficiently imple-
inFigure2.Thedistributionacrossvariouscategoriesisvi-
mentmulti-tasklearning.
sualizedinFigure3
Mixture of Experts (MoE) dynamically combines the de-
cisions of multiple experts on the same input to improve NutritionLabeling
overallperformance.InLLMs,whichtypicallyadopttrans- As the ingredient and recipe information can be easily col-
formerarchitecture,MoEisoftenimplementedwithinMLP lected fromRecipe1M+ (Marinet al. 2019),we proceed to2.57%1.87% Language Model (LLM), as shown in Figure 4. Normally,
4.70% bread
LMM is initially pre-trained with tremendous amounts of
meat
data,andthenfine-tunedtoadapttodownstreamtasks.The
dessert
8.44% 21.91% utilization of multi-modal documents for Supervised Fine-
sauce
Tuning(SFT)(Radfordetal.2018)isacommonpracticein
vegetables
12.29% thefine-tuningofLMMs.
cereal
18.64% Let us denote the set of multimodal documents as D,
bean product
13.26% where D = {(I ,T )}M , where I signifies the image,
seafood i i i=1 i
16.31% and T represents the associated set of tasks with that im-
beverage i
age.M standsforthetotalnumberofdocuments.Eachtask
(cid:110) (cid:111)T
Figure3:DatasetStatistics.Thecategorydistributionofthe set T encompasses sequence-specific tasks (qj,aj) ,
i i i
dataset. j=1
where qj, aj is the question and answer for task j, and
i i
T is the number of task types. The primary objective of
annotatethenutritioncontent.Toacquireprecisenutritional SFT is to using D to fine-tune the LMM so that it can
information, we feed both the food image and the ingredi- providecorrespondinganswerstogivenquestionsbasedon
entswiththeirrespectiveamountsintoChatGPT4-vision1. an image. More specifically, for an image I i and a ques-
Theoutputtextismeticulouslyprocessedtoextractthenu-
tionqj,thetrainingobjectiveistomaximizetheprobability
i
tritional values. Leveraging the capabilities of ChatGPT4- p(aj|I ,qj,θ), where θ represents the trainable parameters
i i i
vision, we collect detailed nutrition information at the in- ofthelargemodel.
gredientlevel,encompassingmetricssuchasmass,fatcon-
tent,proteincontent,carbohydratecontent,andenergycon-
tent. Importantly, the ingredient list in recipes contains Low-RankAdaptation(LoRA). Fullytuninglargemod-
the quantity for each ingredient, along with the food im- els can be resource-intensive. Parameter-Efficient Fine-
age,ChatGPT4-visioniscapableofgeneratinghigh-quality Tuning (PEFT) (Ding et al. 2023) introduces additional
ingredient-levelnutritioninformationaccordingtoourman- adapters to effectively customize large models for down-
ual check based on USDA 2. The ingredient-level nutrition streamtaskswithminimalresourceoverhead.LetW repre-
informationisthenaggregatedtoderivethecomprehensive
senttheweightofalinearlayerLinthelarge-scalemodel,
nutritionprofileoftheentiredish.Throughthisprocess,we which is initially set as W 0 after pre-training. In PEFT,
obtain a holistic understanding of the nutritional composi- W 0 remains frozen in order to preserve the acquired world
tionofthedish,enablingpreciseestimationandanalysisof knowledge. To facilitate adaptation to downstream tasks, a
itsnutritionalvalue. learnable branch linear adapter, denoted as ∆W, is intro-
duced to modify the initial frozen linear weights W . Con-
0
Goldensetselection sequently, the output of the adapted linear layer L can be
expressedasW = W +∆W.LoRA(Huetal.2021)fur-
To ensure accurate evaluation, we construct a precise gold 0
ther decomposes ∆W into two matrices, A and B, where
standard as the test set. To accomplish this goal, we manu-
theconnectionrankisconsiderablysmallerthanthatofW .
ally filter out inaccurate samples by cross-referencing their 0
LoRAallowsthemodeltoadapttodownstreamtaskswhile
nutritional information with the USDA database. Addi-
reducingthenumberoftrainingparameters.
tionally, we eliminate certain overrepresented categories to
achieveabalanceddistributionofsamplecategories.
Mixture of Experts (MoE). The Mixture of Experts
(MoE)(Douetal.2023)paradigmofLoRAisproposedto
Method
adaptlargemodelstomultipledownstreamtasksbyemploy-
Inthissection,wefirstprovideapreliminaryoverviewofthe ingmultipleLoRAsintheMLPlayers.EachLoRAmodule
problemformulationformulti-tasktuningofLMMs,aswell can be considered as an expert, wherein all experts receive
as the commonly used techniques, i.e., Low-Rank Adapta- thesameinputandcombinetheiroutputstoimproveoverall
tion(LoRA)(Huetal.2021)andMixtureofExperts(MoE) performance.LetR={A ,B }N denoteaseriesofLoRA
i i i=0
(Douetal.2023)foraddressingthisproblem.Subsequently, modules, where N signifies the number of LoRAs. We use
we introduce our Linear Rectified Mixture of Diverse Ex- h(·) to denote the linear router, which takes the dimension
pertsapproachindetail. oftheinputfeaturexandoutputstheallocationvectorofR.
TheoutputoflayerLincorporatingtheMoEmodulecanbe
Preliminary representedas:
Problem Formulation. A Large Multi-modal Model
(LMM)canbeconstitutedbyavisionencoderandaLarge (cid:88)N α
x′ = W x+ σ(h )BrArx. (1)
0 r i i i
1Weintentionallyomitrecipeinformationtoenhanceprocess- i=0
ingefficiency,aswehaveobservedthatincludingrecipesincreases
querytimewithoutconsiderablyimprovingprecision. Here,σstandsforthesoftmaxoperation,αisahyperparam-
2https://fdc.nal.usda.gov/ eter,andx′istheoutputfeature.Transformerblock LinearRectifiedMixtureofDiverseExperts
FFN
Self-attention
🔥 🔥 🔥
W … Rectified 🔥
0
kproject qproject vproject Router
Diverseexperts
Projector
TextTokenizer
LinearRectifiedRouter
CLIPVisionEncoder
🔥
Linear
Question: Pleaseestimatethenutrition
informationofthedish. Linear
1layerFC rectification Allocationvector
Figure 4: The illustration of our proposed Linear Rectified Mixture of Diverse Experts (RoDE) approach. We use LLaVA
(Liuetal.2023a)asthefoundationalLMM.RoDEmoduleisincorporatedintoboththequeryprojectionlayerandthevalue
projectionlayerofeachtransformerblock.
LinearRectifiedMixtureofDiverseExperts
Taskspace
Our proposed RoDE framework incorporates a variety of Taskspace
experts, each with distinct capabilities, and a linear rectifi- Task1 Task2 Task3 …
Task1 Task2 Task3 …
cationroutertointegratethecontributionsoftheseexperts.
The overall structure of the framework is depicted in Fig-
ure4.Acomprehensiveillustrationoftheframeworkispro-
Experts4
videdinthesubsequentsections.
Experts3
DiverseCapabilityExperts Typically,withintheMixture Experts1 Experts2 Experts3 … Experts2 …
of Experts (MoE) framework, all experts share the same
Skillspace Experts1 Skillspace
architecture. In the case of LoRA, for example, each ex-
pert is assigned the same rank. However, this uniformity
Llava-MoLE Ours
assumes equal capabilities across all experts. This implies
thatformorecomplextasks,eachexpertmightneedtopos-
Figure 5: Comparison between LLaVA-MoLE (Chen, Jie,
sessalargenumberofparameterstoadapteffectively.How-
andMa2024)andourproposedRoDE.InourRoDEframe-
ever,thiscouldbeprohibitivelydemandingintermsofGPU
work, experts are utilized across all tasks. For individual
memoryrequirements.
tasks,expertactivationsareoptimizedtoachievesparsity.
TomitigatetheissueofGPUmemoryconstraints,wecon-
ceptualizetheexpertsasfine-grainedskillmodules.Thekey
ideaisthatataskmayactivateacombinationofthesemod-
of various LoRAs, each tailored to accommodate tasks of
ules,andthesemodulescanbesharedacrossvarioustasks.
differentcomplexitylevels.
This modular design intuitively leads us to develop LoRA
expertswithdifferentcapabilitiestailoredtotasksofvarying LinearRectifiedRouter Therouterconsolidatesthecon-
complexity. Drawing inspiration from Low-Rank Adapta- tributions of each expert based on the demands of the spe-
tion(Huetal.2021),whichsuggeststhatalow-rankadapter cific task. Previous research (Zhou et al. 2022) has shown
may be sufficient for certain tasks, we create LoRAs with that the use of sparse mixtures of LoRA experts outper-
varyingranks.Consequently,theresultingskillspacecom- formsdenseexpertsinthecontextoflargelanguagemodels.
prisesbothhigh-rankandlow-rankLoRAexperts,providing LLaVA-MoLE (Chen, Jie, and Ma 2024) presents a top-1
greater flexibility and efficiency in addressing a diverse set selection strategy, which ensures the sparsity of expert se-
oftasks. lectioninLMM.WhilesomemethodologiesintheNatural
To construct such skill space, we configure a heteroge- LanguageProcessing(NLP)fieldadopta’soft’approachto
neous set of experts, represented as R = {Ari,Bri}N , combineexpertoutputs—forinstance,(Douetal.2023)uti-
i i i=0
wheretherankr ofi−thLoRAmodulemayvaryfromthe lizessoftmaxand(Pontietal.2023)employsGumbelsoft-
i
others. Therefore, we can establish a skill space composed max—these techniques are not as sparse and can be chal-lengingtooptimize. Softmax Linear Rectification
Incontrast,ourmethodologyadoptsanovelapproachby
utilizingtheRectifiedLinearUnit(ReLU)(NairandHinton
2010) to rectify the output of the routers, thereby encour-
agingthesparselearningofLoRAexpertactivations.Avi-
sual illustration of our routing strategy is shown in Figure
5.LeveragingtheintrinsicpropertiesoftheRectifiedLinear
Unit (ReLU), ourapproach benefits from a simplified opti-
mizationlandscapeandfosterssparsitywithinthenetwork,
which enables our model to boost both efficiency and effi-
cacy.
Letγ representthelinearrectificationoperation,γ(x) =
max(x,0).WeutilizeReLUtorectifythelinearrouter,re-
sultinginanadjustedlinearoutputthatcanbeexpressedas
Figure 6: Sparsity Heatmap Comparison. This heatmap vi-
follows:
sualizes the disparity in task allocation sparsity between
(cid:88)N α routersusingthesoftmaxstrategyandthoseemployingour
x′ =W 0x+
r
γ(h i)B iriAr iix, (2) proposedlinearrectificationmethod.They-axisdenotesthe
i=0 i middle transformer blocks, while the x-axis represents the
where(Ari,Bri)representstheoperationperformedbythe outputoftherouters.
i i
i-thLoRAexpert.ThesummedoutputfromtheRoDEmod-
uleisthenaddedtothefrozenlinearoutputand forwarded
tothenextmodule. we compare with FoodLMM+MoE, which substitutes the
Thislinearrectificationmechanism,enhancesthesparsity plainLoRAmodulewithaMixtureofExperts(MoE)mod-
ofskillselection,facilitatingefficientutilizationofexpertise ule.EachMoEmoduleconsistsoffourLoRAswitharank
acrossabroadspectrumoftasks.Overall,diverseLoRAex- of8.TheroutingmechanismfortheMoEmoduleisalinear
perts and linear rectified arrangement yield a fine-grained layer followed by a softmax operation, as detailed in Sec-
task-skill arrangement space, contributing to the optimized tion . Importantly, for simplicity, we omit the specialized
allocationandutilizationofresourceswithinthemodel. tokentags andadditional headsused byFoodLMM specif-
ically for nutrition estimation, and instead directly convert
OptimizationObjectsandInference
theoutputtokensfromtheLMMintotexttogeneratenutri-
FollowingpreviousLMM-basedmethods(Liuetal.2023a), tional predictions. For the standardization of the ingredient
theinputimagesaretransformedintoimagetokensandcon- vocabulary,we adoptthesame clusteringprotocolused for
catenatedwithtexttokenstosendtoLLM.Thetrainingpro- ingredientsinInverseCooking(Salvadoretal.2019).
cessadherestotheautoregressivemodel,predictingthenext TasksandEvaluationMetrics.Thetasksandcorrespond-
token based on the input tokens. We employ the standard ing metrics in our experiments are as follows. Ingredient
cross-entropylossastheoptimizationobjectivetotrainour Recognition: The objective here is to identify and list the
model. ingredientspresentinadishshowninanimage.Weassess
Duringinference,foreachtask,weinputtheimagealong performanceusingIntersectionoverUnion(IoU)asthemet-
withthecorrespondingquestionintothemodel.Themodel’s ric.RecipeGeneration:Thegoalofthistaskistogenerate
outputtokensarethenconvertedintowordstoformulatethe cooking instructions for the dish captured in an image. We
answer. measureperformanceusingthecommonlyusedtextgener-
ationmetricsinNLP,SacreBLEU(Post2018)andRouge-L
Experiment
(Lin 2004). Nutrition Estimation: This task involves es-
Inthissection,wefirstpresentourexperimentalsetup.Then timatingarangeofnutritionalparametersfromadish’sim-
we elaborate experimental results of multiple food tasks age,includingthetotalfoodmass,totalenergy,totalfat,total
basedonmulti-tasklearning.Followingthis,weperforman carbohydrates,andtotalproteincontent.Energyismeasured
ablationstudytoevaluatetheimpactandeffectivenessofour in kilocalories, while the remaining parameters are quanti-
maincomponents. fiedingrams.Weemploythemeanabsoluteerrorasaper-
centoftherespectivemeanforthatfield(pMAE)(Thames
ExperimentSetup etal.2021)forthemetricofnutritionestimation.
Our approach commenced by utilizing the pre-trained Implementation Details. In this study, we utilize LLaVA-
weightsoftheLLaVA-Lightning-7B-v1-1(Liuetal.2023a) 7B (Liu et al. 2023a) as the base LMM, wherein a CLIP
model,subsequentlyapplyingSFTontheUni-FoodandNu- ViT-L model serves as the vision encoder, and Llama 7B
trition5kdatasets(Thamesetal.2021).InourRoDEmodel, (Touvron et al. 2023) serves as the Language Model. For
we employ a heterogeneous array of experts with LoRA the CLIP ViT-L encoder, the input image resolution is set
ranks of [2, 4, 8, 16]. Our primary baseline is FoodLMM at 336x336, which is then divided into 14 patches. Subse-
(Yin et al. 2023), which to our knowledge is the only ver- quently, a two-layer MLP is used to transform these image
satile LMM specialized in food-related tasks. Additionally, patchesinto576tokens.Forefficiency,theLoRAmoduleisIngredientrecognition Recipegeneration Nutritionestimation(pMAE)
Method
IoU(↑) SacreBLEU(↑) Rouge-L(↑) Mass(↓) Energy(↓) Fat(↓) Proteins(↓) Carb(↓) Avg.(↓)
FoodLMM(Yinetal.2023) 22.59 7.59 36.44 48.49 47.72 61.49 56.61 51.25 53.11
FoodLMM+MoE 24.54 8.7 38.5 49.23 48.24 60.59 58.37 51.87 53.66
RoDE(ours) 26.86 9.66 40.11 48.18 46.96 60.96 58.16 48.65 52.58
Table 2: Comparative results for ingredient recognition, recipe generation and nutrition estimation on the Uni-Food Dataset.
TheFoodLMM+MoEisderivedbyintegratingaMixtureofExperts(MoE)paradigmintotheFoodLMMmodel.
Nutrition5k Mass(↓) Cal(↓) Fat(↓) Proteins(↓) Carb(↓) Avg.(↓)
FoodLMM(Yinetal.2023) 38.96 54.04 69.84 54.88 51.3 53.8
FoodLMM+MoE 39.31 53.6 67.14 52.99 49.59 52.53
w/o MoE
RoDE(ours) 38.45 52.47 67.1 53.92 47.84 51.96 Top-1
Softmax
40 LR
Table3:NutritionestimationresultsonNutrtion5kdataset.
TheevaluationmetricemployedisthepercentageMeanAb-
30
soluteError(pMAE).
20
addedtothequeryandkeyprojectionlayer.Unlessspecifi-
10
callystated,therankofLoRAissetto8.Hyperparameterα
issetto16,andtheLoRAdropoutrateissetto0.05.
0
During the training process of all our experiments, the Ingredient Recipe Recipe Nutrition
(IoU) (SacreBLEU) (Rouge-L) (100-pMAE)
weightsofvisionencoderandLlamaarekeptconstant,with
onlytheaddedLoRAmodulesbeingtrainable.Weemploy Figure 7: Performance Comparison of Routing Strategies:
the AdamW optimizer (Loshchilov and Hutter 2017) and “Top-1”selectsthetop-1expertaccorardingrouter’sscore.
usetheWarmupDecayLRlearningratescheduler.Theinitial “Softmax” applies a softmax operation to process the
learning rate is set to 0.0003, weight decay is set to 0, and router’s output, while “LR” uses linear rectified router. All
we perform 100 warm-up iterations. In the training stage, thethreestrategiesutilizeaconsistentLoRAranksettingof
weuseabatchsizeof4,andgradientupdatesarecomputed [8,8,8,8].
every 10 batches. The training process is distributed across
4RTX4090GPUs.Thetrainingepochissetto1.
foodmulti-tasklearning.
PerformanceComparison Additionally, we conduct further experiments on Nutri-
tion5k (Thamesetal.2021)dataset,adheringtothemethod-
Weperformacomparativeanalysisbetweenourmodeland
ology established by FoodLMM, where only image infor-
two versions of FoodLMM: a base version equipped with
mation was utilized for training (without depth informa-
plane LoRA, and an enhanced version, FoodLMM+MoE,
tion). The outcomes, as presented in Table 3, unequivo-
equipped with four 8-rank LoRA and a linear router with
callydemonstratethatourmethodsconsistentlysurpassboth
softmax. These methods are evaluated across three tasks:
FoodLMMandtraditionalMoEvariationsinperformance.
ingredient recognition, recipe generation, and nutrition es-
timation. The results are summarized in Table 2. The ta-
ble clearly shows that the MoE design enhances the per- Ablationstudy
formance of FoodLMM. By adopting the traditional MoE
paradigm,i.e.,FoodLMM+MoE,thereisan8.6%improve- Inthissection,weperformanablationstudytoevaluatethe
ment in IoU for ingredients recognition, for recipe genera- contributionandefficacyofthecorecomponentswithinour
tion, there is a 14.6% increase in SacreBLEU and a 1.1% framework. For simplicity, we omit the task names and tag
gaininRouge-Lscores.However,thereisaslightreduction onlythemetrics.
of 1% in nutritional performance. Overall, the comparison
demonstratestheadvantagesofincorporatingMoE. MoEvs.LargerLoRArank AsillustratedinTable4,we
Furthermore,ourmodel,RoDE,significantlyoutperforms firstcomparethestandardLoRA(Var1)withitsMoEvari-
the traditional MoE design, achieving the highest scores ant (Var3). The results indicate a superior performance of
across all evaluated metrics. In the ingredient recognition theMoEdesign.Toascertainwhetherthisperformanceim-
task,RoDEsurpassesFoodLMM+MoEbyanotablemargin provementcanbeattributedtoanincreaseinthenumberof
of9.5%.Forrecipegeneration,RoDEshowsan11%higher trainableLoRAparameters,weaugmenttheLoRArankof
SacreBLEU score and a 4.2% improvement in Rouge-L Var1to32toobtainVar2.AcomparisonbetweenVar2and
score compared to FoodLMM+MoE. In the area of nutri- Var4revealsthesuperiorityoftheMoEdesign,eventhough
tionestimation,RoDEnearlytopsthechartsforallnutrient these two variants have an equivalent number of trainable
elements and secures the leading position in terms of av- LoRAparameters.Thisfindingsuggeststhatthesuccessful
erageperformance.Theseexperimentalresultsconclusively integration of MoE is not simply a result of expanding the
affirm the superiority of our proposed RoDE approach in numberoftrainableparameters.
ecnamrofrePSettings LoRArank Routingstrategy MoE SacreBLEU(↑) Rouge-L(↑) IngredientIoU(↑) pMAE(↓)
Var1 8 - × 7.59 36.44 22.59 53.11
Var2 32 - × 8.39 36.68 22.7 54.14
Var3 8,8,8,8 Top-1 ✓ 8.28 37.2 24.08 53.53
Var4 8,8,8,8 Softmax ✓ 8.7 38.5 24.54 53.66
Table4:AblationStudyonMoE.TheintegrationofMoEcanenhancetheLMM,notsolelyduetotheintroductionofadditional
LoRAparameters
Settings LoRArank Routingstrategy SacreBLEU(↑) Rouge-L(↑) IngredientIoU(↑) pMAE(↓)
Var1 8,8,8,8 Top-1 8.28 37.2 24.08 53.53
Var2 8,8,8,8 Softmax 8.7 38.5 24.54 53.66
Var3 8,8,8,8 LR 9.48 40.03 26.7 52.75
Var4 2,4,6,8 Softmax 8.66 38.15 24.54 53.22
Var5 2,4,6,8 LR 9.4 39.67 26.76 52.63
Table5:ComparisonofThreeRoutingStrategies.OurproposedLinearRectifiedRouterdemonstratessuperiorperformanceon
bothhomogeneousandheterogeneouscombinationsofexperts.
Routing Strategy Then we examine the effects of the reductioninSacreBLEUscore(by0.08)andRouge-Lscore
routing strategy. Our experiment includes three routing (by 0.36), while having 32.5% fewer trainable parameters.
strategies:1)similarto(Chen,Jie,andMa2024),thetop-1 This finding supports the notion that not all LoRA experts
expertisselected,referredtoasTop-1;2)followingtheap- requirehighcapacitytocontributeeffectively.
proachin(Douetal.2023),weemployasoftmaxfunctionto ByadjustingtheranksinVar3tocreateVar4,weobserve
normalizetherouteroutputs,whichisdenotedasSoftmax; improved performance which exceeds that of Var2, despite
3) we introduce our novel linear rectified router, which we Var4 having 6.25% fewer trainable parameters. This out-
denote with the abbreviation LR. The results are summa- come implies that a strategic combination of LoRA expert
rized in Table 5 and visualized in Figure 7. As observed, sizescaneffectivelysupporttheinclusionofsomelargerLo-
while the Top-1 allocation MoE outperforms the standard RAs, potentially enhancing their capability to handle com-
LoRA(Var1),itissurpassedbythe”soft”allocationstrate- plextasksmoreefficiently.
gies (i.e., Var2 and Var3). This indicates the efficiency of
employing an ensemble of experts to address a single task. TrainingParameterEfficiency
Moreover, the comparison between the LR and Softmax We evaluate various rank settings by visualizing the corre-
routers (i.e., Var2 and Var3, Var4 and Var5) suggests that lation between the number of trainable LoRA parameters
theLRroutingstrategyissuperior.Theseresultsfurtherun- and their corresponding task performance on the Uni-Food
derscoretheeffectivenessofourlinearrectificationrouting dataset.Figure8illustratesthisrelationship,withthey-axis
strategy. indicatingtaskperformanceandthex-axisrepresentingthe
In addition, we visualize the heatmaps of router outputs trainableLoRAparametercount.ItisapparentthattheMoE
for both the Softmax and LR routing strategies across sev- architecture incorporates more trainable LoRA parameters,
eralmiddletransformerblocks.Figure6illustratesthiscom- which substantially boosts performance across a range of
parativeanalysis,clearlyindicatingthatourproposedLinear metrics,i.e.,recipeSacreBLEU,recipeRouge-L,andingre-
RectifiedRouterachievesahigherdegreeofsparsityintask dient IoU. When comparing sets of homogeneous experts
allocation. tothoseofheterogeneousexperts(i.e.,comparingranksets
[5,5,5,5] to [2,4,6,8]), the introduction of high rank LoRA
Rank configuration of LoRA We conduct an ablation
canenhancemodelperformancedespitewhenthenumberof
studytoevaluatetheimpactofdifferentLoRArankconfig-
trainable LoRA parameters is the same. These results sug-
urations.Theresults,aspresentedinTable6,spanmultiple
gest that not every expert requires an extensive parameter
expertconfigurations,including:1)Var1-FourLoRAs,each
set; heterogeneous experts can effectively coordinate train-
withauniformrankof5.2)Var2-FourLoRAs,eachwitha
able parameters, resulting in better performance on multi-
uniformrankof8.3)Var3-AheterogeneoussetoffourLo-
tasklearning.
RAswithranksof[2,4,6,7].4)Var4-Anotherdiverseset
offourLoRAswithadistinctrankcompositionfromVar3,
Conclusion
specifically[2,4,8,16].TheanalysisofVar1andVar2sug-
gests that configurations with higher-ranked LoRA experts Inthispaper,wedelveintothebroaderscopeoftaskswithin
aremoreeffective.However,despitehavingthesamenum- therealmoffoodstudies.WeintroduceUni-Food,acompre-
beroftrainableparametersasVar1,Var3demonstratessupe- hensive dataset comprising classification, ingredient recog-
riorperformance,indicatingthatamixofhigherandlower- nition,recipegeneration,andnutritionestimation.Uni-Food
rankedLoRAexpertscanalsobeeffective.Moreover,Var3 servesasafoundationalresourceempoweringawidespec-
shows comparable performance to Var2, with only a slight trum of food-related research endeavors. The expansion ofFigure8:CorrelationbetweentheQuantityofTrainableLoRAParametersandTaskPerformanceAcrossFiveLoRASettings.
Forsimplicity,thetotalLoRAranksinasinglelayerarequantifiedasthetrainableparameters.
Settings LoRArank Routingstrategy SacreBLEU(↑) Rouge-L(↑) IngredientIoU(↑) pMAE(↓)
Var1 5,5,5,5 LR 8.4 38.04 25.02 53.42
Var2 8,8,8,8 LR 9.48 40.03 26.7 52.75
Var3 2,4,6,8 LR 9.4 39.67 26.76 52.63
Var4 2,4,8,16 LR 9.66 40.11 26.86 52.58
Table6:AblationStudyontheRankSettingsofExpertswithinMoE.Theheterogeneouscombinationofexpertsyieldssuperior
performancewhileutilizingareducedparametercount.
training tasks brings about a challenge of task conflict. To of the 24th ACM International Conference on Multimedia,
mitigate these task conflicts during SFT on Large LMMs, MM’16,32–41.NewYork,NY,USA:AssociationforCom-
we introduce the Linear Rectified Mixture of Diverse Ex- putingMachinery. ISBN9781450336031.
perts(RoDE).RoDEconstructsaskillspacethatexpertsare Chen,J.;Zhu,B.;Ngo,C.-W.;Chua,T.-S.;andJiang,Y.-G.
sharable, and arranges a variety of trainable parameters to 2020. Astudyofmulti-taskandregion-wisedeeplearning
establishheterogeneousexpertscapableofadaptingtotasks for food ingredient recognition. IEEE Transactions on Im-
ofdifferentcomplexities.Itemployslinearrectifiedunitsto ageProcessing,30:1514–1526.
refinelinearrouters,encouragingtherouterstolearnsparse
Chen,J.;Zhu,B.;Ngo,C.-W.;Chua,T.-S.;andJiang,Y.-G.
allocation. RoDE is not only GPU memory-efficient but it
2021. AStudyofMulti-TaskandRegion-WiseDeepLearn-
also simplifies the optimization process. Our experimental
ingforFoodIngredientRecognition. IEEETransactionson
resultsclearlydemonstratetheeffectivenessofourproposed
ImageProcessing,30:1514–1526.
method,highlightingitsefficiencyandefficacyinovercom-
ingthemultifacetedchallengesassociatedwiththefooddo- Chen,S.;Jie,Z.;andMa,L.2024. Llava-mole:Sparsemix-
main. tureofloraexpertsformitigatingdataconflictsininstruction
finetuningmllms. arXivpreprintarXiv:2401.16160.
References Chhikara, P.; Chaurasia, D.; Jiang, Y.; Masur, O.; and
Achiam, J.; Adler, S.; Agarwal, S.; Ahmad, L.; Akkaya, I.; Ilievski,F.2024. FIRE:FoodImagetoREcipeGeneration.
Aleman, F. L.; Almeida, D.; Altenschmidt, J.; Altman, S.;
InProceedingsoftheIEEE/CVFWinterConferenceonAp-
Anadkat, S.; et al. 2023. Gpt-4 technical report. arXiv plicationsofComputerVision(WACV),8184–8194.
preprintarXiv:2303.08774. Ding, N.; Qin, Y.; Yang, G.; Wei, F.; Yang, Z.; Su, Y.;
Ando,Y.;Ege,T.;Cho,J.;andYanai,K.2019. DepthCalo- Hu, S.; Chen, Y.; Chan, C.-M.; Chen, W.; et al. 2023.
rieCam: A Mobile Application for Volume-Based Food- Parameter-efficient fine-tuning of large-scale pre-trained
Calorie Estimation using Depth Cameras. In Proceedings language models. Nature Machine Intelligence, 5(3): 220–
of the 5th International Workshop on Multimedia Assisted 235.
Dietary Management, MADiMa ’19, 76–81. New York, Dou, S.; Zhou, E.; Liu, Y.; Gao, S.; Zhao, J.; Shen, W.;
NY, USA: Association for Computing Machinery. ISBN Zhou,Y.;Xi,Z.;Wang,X.;Fan,X.;etal.2023. Loramoe:
9781450369169. Revolutionizing mixture of experts for maintaining world
Bossard, L.; Guillaumin, M.; and Van Gool, L. 2014. In knowledge in language model alignment. arXiv preprint
Computer Vision – ECCV 2014, 446–461. Cham: Springer arXiv:2312.09979.
InternationalPublishing. Gao, J.; Chen, J.; Fu, H.; and Jiang, Y.-G. 2023. Dynamic
Chen, J.; and Ngo, C.-W. 2016a. Deep-based ingredient MixupforMulti-LabelLong-TailedFoodIngredientRecog-
recognition for cooking recipe retrieval. In Proceedings of nition. IEEETransactionsonMultimedia,25:4764–4773.
the24thACMinternationalconferenceonMultimedia,32– Gou, Y.; Liu, Z.; Chen, K.; Hong, L.; Xu, H.; Li, A.; Ye-
41. ung, D.-Y.; Kwok, J. T.; and Zhang, Y. 2023. Mixture of
Chen, J.; and Ngo, C.-w. 2016b. Deep-based Ingredient cluster-conditionalloraexpertsforvision-languageinstruc-
RecognitionforCookingRecipeRetrieval. InProceedings tiontuning. arXivpreprintarXiv:2312.12379.Hu,E.J.;Shen,Y.;Wallis,P.;Allen-Zhu,Z.;Li,Y.;Wang, Qiu, J.; Lo, F. P. W.; Sun, Y.; Wang, S.; and Lo, B. 2022.
S.;Wang,L.;andChen,W.2021.Lora:Low-rankadaptation Mining Discriminative Food Regions for Accurate Food
oflargelanguagemodels.arXivpreprintarXiv:2106.09685. Recognition. arXiv:2207.03692.
Huang,C.;Liu,Q.;Lin,B.Y.;Pang,T.;Du,C.;andLin,M. Radford, A.; Narasimhan, K.; Salimans, T.; Sutskever, I.;
2023. Lorahub: Efficient cross-task generalization via dy- et al. 2018. Improving language understanding by gener-
namicloracomposition. arXivpreprintarXiv:2307.13269. ativepre-training.
Kawano, Y.; and Yanai, K. 2014. Automatic Expansion of Salvador, A.; Drozdzal, M.; Giro´-i Nieto, X.; and Romero,
aFoodImageDatasetLeveragingExistingCategorieswith A.2019. Inversecooking:Recipegenerationfromfoodim-
DomainAdaptation. InProc.ofECCVWorkshoponTrans- ages. InProceedingsoftheIEEE/CVFConferenceonCom-
ferringandAdaptingSourceKnowledgeinComputerVision puterVisionandPatternRecognition,10453–10462.
(TASK-CV). Salvador,A.;Hynes,N.;Aytar,Y.;Marin,J.;Ofli,F.;Weber,
Lai,X.;Tian,Z.;Chen,Y.;Li,Y.;Yuan,Y.;Liu,S.;andJia, I.;andTorralba,A.2017.Learningcross-modalembeddings
J. 2023. Lisa: Reasoning segmentation via large language forcookingrecipesandfoodimages. InProceedingsofthe
model. arXivpreprintarXiv:2308.00692. IEEE conference on computer vision and pattern recogni-
Lin, B.; Tang, Z.; Ye, Y.; Cui, J.; Zhu, B.; Jin, P.; Zhang, tion,3020–3028.
J.; Ning, M.; and Yuan, L. 2024. Moe-llava: Mixture of Thames, Q.; Karpur, A.; Norris, W.; Xia, F.; Panait, L.;
experts for large vision-language models. arXiv preprint Weyand, T.; and Sim, J. 2021. Nutrition5k: Towards au-
arXiv:2401.15947. tomatic nutritional understanding of generic food. In Pro-
Lin,C.-Y.2004.Rouge:Apackageforautomaticevaluation ceedings of the IEEE/CVF conference on computer vision
ofsummaries. InTextsummarizationbranchesout,74–81. andpatternrecognition,8903–8911.
Liu,H.;Li,C.;Wu,Q.;andLee,Y.J.2023a. VisualInstruc- Touvron,H.;Martin,L.;Stone,K.;Albert,P.;Almahairi,A.;
tionTuning. Babaei,Y.;Bashlykov,N.;Batra,S.;Bhargava,P.;Bhosale,
S.; et al. 2023. Llama 2: Open foundation and fine-tuned
Liu, Q.; Wu, X.; Zhao, X.; Zhu, Y.; Xu, D.; Tian, F.; and
chatmodels. arXivpreprintarXiv:2307.09288.
Zheng, Y. 2023b. Moelora: An moe-based parameter ef-
ficient fine-tuning method for multi-task medical applica- Wang,Z.;Min,W.;Li,Z.;Kang,L.;Wei,X.;Wei,X.;and
tions. arXivpreprintarXiv:2310.18339. Jiang, S. 2022. Ingredient-Guided Region Discovery and
Relationship Modeling for Food Category-Ingredient Pre-
Loshchilov,I.;andHutter,F.2017.Decoupledweightdecay
diction. IEEETransactionsonImageProcessing,31:5214–
regularization. arXivpreprintarXiv:1711.05101.
5226.
Luo,M.;Min,W.;Wang,Z.;Song,J.;andJiang,S.2023.In-
Yin, Y.; Qi, H.; Zhu, B.; Chen, J.; Jiang, Y.-G.; and
gredientpredictionviacontextlearningnetworkwithclass-
Ngo, C.-W. 2023. FoodLMM: A Versatile Food As-
adaptiveasymmetricloss.IEEETransactionsonImagePro-
sistant using Large Multi-modal Model. arXiv preprint
cessing.
arXiv:2312.14991.
Marin,J.;Biswas,A.;Ofli,F.;Hynes,N.;Salvador,A.;Ay-
Zhou,Y.;Lei,T.;Liu,H.;Du,N.;Huang,Y.;Zhao,V.;Dai,
tar, Y.; Weber, I.; and Torralba, A. 2019. Recipe1M+: A
A.M.;Le,Q.V.;Laudon,J.;etal.2022. Mixture-of-experts
DatasetforLearningCross-ModalEmbeddingsforCooking
withexpertchoicerouting. AdvancesinNeuralInformation
RecipesandFoodImages. IEEETrans.PatternAnal.Mach.
ProcessingSystems,35:7103–7114.
Intell.
Zhu, B.; Ngo, C.-W.; Chen, J.; and Hao, Y. 2019. R2gan:
Min, W.; Wang, Z.; Liu, Y.; Luo, M.; Kang, L.; Wei, X.;
Cross-modalreciperetrievalwithgenerativeadversarialnet-
Wei,X.;andJiang,S.2023. Largescalevisualfoodrecog-
work.InProceedingsoftheIEEE/CVFConferenceonCom-
nition. IEEETransactionsonPatternAnalysisandMachine
puterVisionandPatternRecognition,11477–11486.
Intelligence.
Nair,V.;andHinton,G.E.2010. Rectifiedlinearunitsim-
proverestrictedboltzmannmachines. InProceedingsofthe
27thinternationalconferenceonmachinelearning(ICML-
10),807–814.
Pan,L.-M.;Chen,J.;Wu,J.;Liu,S.;Ngo,C.-W.;Kan,M.-
Y.; Jiang, Y.; and Chua, T.-S. 2020. Multi-modal cook-
ingworkflowconstructionforfoodrecipes. InProceedings
of the 28th ACM International Conference on Multimedia,
1132–1141.
Ponti, E. M.; Sordoni, A.; Bengio, Y.; and Reddy, S. 2023.
Combining parameter-efficient modules for task-level gen-
eralisation.InProceedingsofthe17thConferenceoftheEu-
ropean Chapter of the Association for Computational Lin-
guistics,687–702.
Post,M.2018. AcallforclarityinreportingBLEUscores.