[
    {
        "title": "Scalable Monte Carlo for Bayesian Learning",
        "authors": "Paul FearnheadChristopher NemethChris J. OatesChris Sherlock",
        "links": "http://arxiv.org/abs/2407.12751v1",
        "entry_id": "http://arxiv.org/abs/2407.12751v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12751v1",
        "summary": "This book aims to provide a graduate-level introduction to advanced topics in\nMarkov chain Monte Carlo (MCMC) algorithms, as applied broadly in the Bayesian\ncomputational context. Most, if not all of these topics (stochastic gradient\nMCMC, non-reversible MCMC, continuous time MCMC, and new techniques for\nconvergence assessment) have emerged as recently as the last decade, and have\ndriven substantial recent practical and theoretical advances in the field. A\nparticular focus is on methods that are scalable with respect to either the\namount of data, or the data dimension, motivated by the emerging high-priority\napplication areas in machine learning and AI.",
        "updated": "2024-07-17 17:19:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12751v1"
    },
    {
        "title": "A Methodology Establishing Linear Convergence of Adaptive Gradient Methods under PL Inequality",
        "authors": "Kushal ChakrabartiMayank Baranwal",
        "links": "http://arxiv.org/abs/2407.12629v1",
        "entry_id": "http://arxiv.org/abs/2407.12629v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12629v1",
        "summary": "Adaptive gradient-descent optimizers are the standard choice for training\nneural network models. Despite their faster convergence than gradient-descent\nand remarkable performance in practice, the adaptive optimizers are not as well\nunderstood as vanilla gradient-descent. A reason is that the dynamic update of\nthe learning rate that helps in faster convergence of these methods also makes\ntheir analysis intricate. Particularly, the simple gradient-descent method\nconverges at a linear rate for a class of optimization problems, whereas the\npractically faster adaptive gradient methods lack such a theoretical guarantee.\nThe Polyak-{\\L}ojasiewicz (PL) inequality is the weakest known class, for which\nlinear convergence of gradient-descent and its momentum variants has been\nproved. Therefore, in this paper, we prove that AdaGrad and Adam, two\nwell-known adaptive gradient methods, converge linearly when the cost function\nis smooth and satisfies the PL inequality. Our theoretical framework follows a\nsimple and unified approach, applicable to both batch and stochastic gradients,\nwhich can potentially be utilized in analyzing linear convergence of other\nvariants of Adam.",
        "updated": "2024-07-17 14:56:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12629v1"
    },
    {
        "title": "Test-Time Adaptation with State-Space Models",
        "authors": "Mona SchirmerDan ZhangEric Nalisnick",
        "links": "http://arxiv.org/abs/2407.12492v1",
        "entry_id": "http://arxiv.org/abs/2407.12492v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12492v1",
        "summary": "Distribution shifts between training and test data are all but inevitable\nover the lifecycle of a deployed model and lead to performance decay. Adapting\nthe model can hopefully mitigate this drop in performance. Yet, adaptation is\nchallenging since it must be unsupervised: we usually do not have access to any\nlabeled data at test time. In this paper, we propose a probabilistic\nstate-space model that can adapt a deployed model subjected to distribution\ndrift. Our model learns the dynamics induced by distribution shifts on the last\nset of hidden features. Without requiring labels, we infer time-evolving class\nprototypes that serve as a dynamic classification head. Moreover, our approach\nis lightweight, modifying only the model's last linear layer. In experiments on\nreal-world distribution shifts and synthetic corruptions, we demonstrate that\nour approach performs competitively with methods that require back-propagation\nand access to the model backbone. Our model especially excels in the case of\nsmall test batches - the most difficult setting.",
        "updated": "2024-07-17 11:18:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12492v1"
    },
    {
        "title": "Why Do You Grok? A Theoretical Analysis of Grokking Modular Addition",
        "authors": "Mohamad Amin MohamadiZhiyuan LiLei WuDanica J. Sutherland",
        "links": "http://arxiv.org/abs/2407.12332v1",
        "entry_id": "http://arxiv.org/abs/2407.12332v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12332v1",
        "summary": "We present a theoretical explanation of the ``grokking'' phenomenon, where a\nmodel generalizes long after overfitting,for the originally-studied problem of\nmodular addition. First, we show that early in gradient descent, when the\n``kernel regime'' approximately holds, no permutation-equivariant model can\nachieve small population error on modular addition unless it sees at least a\nconstant fraction of all possible data points. Eventually, however, models\nescape the kernel regime. We show that two-layer quadratic networks that\nachieve zero training loss with bounded $\\ell_{\\infty}$ norm generalize well\nwith substantially fewer training points, and further show such networks exist\nand can be found by gradient descent with small $\\ell_{\\infty}$ regularization.\nWe further provide empirical evidence that these networks as well as simple\nTransformers, leave the kernel regime only after initially overfitting. Taken\ntogether, our results strongly support the case for grokking as a consequence\nof the transition from kernel-like behavior to limiting behavior of gradient\ndescent on deep networks.",
        "updated": "2024-07-17 06:15:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12332v1"
    },
    {
        "title": "Information-Theoretic Foundations for Machine Learning",
        "authors": "Hong Jun JeonBenjamin Van Roy",
        "links": "http://arxiv.org/abs/2407.12288v1",
        "entry_id": "http://arxiv.org/abs/2407.12288v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12288v1",
        "summary": "The staggering progress of machine learning in the past decade has been a\nsight to behold. In retrospect, it is both remarkable and unsettling that these\nmilestones were achievable with little to no rigorous theory to guide\nexperimentation. Despite this fact, practitioners have been able to guide their\nfuture experimentation via observations from previous large-scale empirical\ninvestigations. However, alluding to Plato's Allegory of the cave, it is likely\nthat the observations which form the field's notion of reality are but shadows\nrepresenting fragments of that reality. In this work, we propose a theoretical\nframework which attempts to answer what exists outside of the cave. To the\ntheorist, we provide a framework which is mathematically rigorous and leaves\nopen many interesting ideas for future exploration. To the practitioner, we\nprovide a framework whose results are very intuitive, general, and which will\nhelp form principles to guide future investigations. Concretely, we provide a\ntheoretical framework rooted in Bayesian statistics and Shannon's information\ntheory which is general enough to unify the analysis of many phenomena in\nmachine learning. Our framework characterizes the performance of an optimal\nBayesian learner, which considers the fundamental limits of information.\nThroughout this work, we derive very general theoretical results and apply them\nto derive insights specific to settings ranging from data which is\nindependently and identically distributed under an unknown distribution, to\ndata which is sequential, to data which exhibits hierarchical structure\namenable to meta-learning. We conclude with a section dedicated to\ncharacterizing the performance of misspecified algorithms. These results are\nexciting and particularly relevant as we strive to overcome increasingly\ndifficult machine learning challenges in this endlessly complex world.",
        "updated": "2024-07-17 03:18:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12288v1"
    }
]