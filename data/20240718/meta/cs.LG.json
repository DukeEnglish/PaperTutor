[
    {
        "title": "AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases",
        "authors": "Zhaorun ChenZhen XiangChaowei XiaoDawn SongBo Li",
        "links": "http://arxiv.org/abs/2407.12784v1",
        "entry_id": "http://arxiv.org/abs/2407.12784v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12784v1",
        "summary": "LLM agents have demonstrated remarkable performance across various\napplications, primarily due to their advanced capabilities in reasoning,\nutilizing external knowledge and tools, calling APIs, and executing actions to\ninteract with environments. Current agents typically utilize a memory module or\na retrieval-augmented generation (RAG) mechanism, retrieving past knowledge and\ninstances with similar embeddings from knowledge bases to inform task planning\nand execution. However, the reliance on unverified knowledge bases raises\nsignificant concerns about their safety and trustworthiness. To uncover such\nvulnerabilities, we propose a novel red teaming approach AgentPoison, the first\nbackdoor attack targeting generic and RAG-based LLM agents by poisoning their\nlong-term memory or RAG knowledge base. In particular, we form the trigger\ngeneration process as a constrained optimization to optimize backdoor triggers\nby mapping the triggered instances to a unique embedding space, so as to ensure\nthat whenever a user instruction contains the optimized backdoor trigger, the\nmalicious demonstrations are retrieved from the poisoned memory or knowledge\nbase with high probability. In the meantime, benign instructions without the\ntrigger will still maintain normal performance. Unlike conventional backdoor\nattacks, AgentPoison requires no additional model training or fine-tuning, and\nthe optimized backdoor trigger exhibits superior transferability, in-context\ncoherence, and stealthiness. Extensive experiments demonstrate AgentPoison's\neffectiveness in attacking three types of real-world LLM agents: RAG-based\nautonomous driving agent, knowledge-intensive QA agent, and healthcare\nEHRAgent. On each agent, AgentPoison achieves an average attack success rate\nhigher than 80% with minimal impact on benign performance (less than 1%) with a\npoison rate less than 0.1%.",
        "updated": "2024-07-17 17:59:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12784v1"
    },
    {
        "title": "Contrastive Adversarial Training for Unsupervised Domain Adaptation",
        "authors": "Jiahong ChenZhilin ZhangLucy LiBehzad ShahrasbiArjun Mishra",
        "links": "http://arxiv.org/abs/2407.12782v1",
        "entry_id": "http://arxiv.org/abs/2407.12782v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12782v1",
        "summary": "Domain adversarial training has shown its effective capability for finding\ndomain invariant feature representations and been successfully adopted for\nvarious domain adaptation tasks. However, recent advances of large models\n(e.g., vision transformers) and emerging of complex adaptation scenarios (e.g.,\nDomainNet) make adversarial training being easily biased towards source domain\nand hardly adapted to target domain. The reason is twofold: relying on large\namount of labelled data from source domain for large model training and lacking\nof labelled data from target domain for fine-tuning. Existing approaches widely\nfocused on either enhancing discriminator or improving the training stability\nfor the backbone networks. Due to unbalanced competition between the feature\nextractor and the discriminator during the adversarial training, existing\nsolutions fail to function well on complex datasets. To address this issue, we\nproposed a novel contrastive adversarial training (CAT) approach that leverages\nthe labeled source domain samples to reinforce and regulate the feature\ngeneration for target domain. Typically, the regulation forces the target\nfeature distribution being similar to the source feature distribution. CAT\naddressed three major challenges in adversarial learning: 1) ensure the feature\ndistributions from two domains as indistinguishable as possible for the\ndiscriminator, resulting in a more robust domain-invariant feature generation;\n2) encourage target samples moving closer to the source in the feature space,\nreducing the requirement for generalizing classifier trained on the labeled\nsource domain to unlabeled target domain; 3) avoid directly aligning unpaired\nsource and target samples within mini-batch. CAT can be easily plugged into\nexisting models and exhibits significant performance improvements.",
        "updated": "2024-07-17 17:59:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12782v1"
    },
    {
        "title": "Jigsaw Game: Federated Clustering",
        "authors": "Jinxuan XuHong-You ChenWei-Lun ChaoYuqian Zhang",
        "links": "http://arxiv.org/abs/2407.12764v1",
        "entry_id": "http://arxiv.org/abs/2407.12764v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12764v1",
        "summary": "Federated learning has recently garnered significant attention, especially\nwithin the domain of supervised learning. However, despite the abundance of\nunlabeled data on end-users, unsupervised learning problems such as clustering\nin the federated setting remain underexplored. In this paper, we investigate\nthe federated clustering problem, with a focus on federated k-means. We outline\nthe challenge posed by its non-convex objective and data heterogeneity in the\nfederated framework. To tackle these challenges, we adopt a new perspective by\nstudying the structures of local solutions in k-means and propose a one-shot\nalgorithm called FeCA (Federated Centroid Aggregation). FeCA adaptively refines\nlocal solutions on clients, then aggregates these refined solutions to recover\nthe global solution of the entire dataset in a single round. We empirically\ndemonstrate the robustness of FeCA under various federated scenarios on both\nsynthetic and real-world data. Additionally, we extend FeCA to representation\nlearning and present DeepFeCA, which combines DeepCluster and FeCA for\nunsupervised feature learning in the federated setting.",
        "updated": "2024-07-17 17:42:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12764v1"
    },
    {
        "title": "A survey and taxonomy of methods interpreting random forest models",
        "authors": "Maissae HaddouchiAbdelaziz Berrado",
        "links": "http://arxiv.org/abs/2407.12759v1",
        "entry_id": "http://arxiv.org/abs/2407.12759v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12759v1",
        "summary": "The interpretability of random forest (RF) models is a research topic of\ngrowing interest in the machine learning (ML) community. In the state of the\nart, RF is considered a powerful learning ensemble given its predictive\nperformance, flexibility, and ease of use. Furthermore, the inner process of\nthe RF model is understandable because it uses an intuitive and intelligible\napproach for building the RF decision tree ensemble. However, the RF resulting\nmodel is regarded as a \"black box\" because of its numerous deep decision trees.\nGaining visibility over the entire process that induces the final decisions by\nexploring each decision tree is complicated, if not impossible. This complexity\nlimits the acceptance and implementation of RF models in several fields of\napplication. Several papers have tackled the interpretation of RF models. This\npaper aims to provide an extensive review of methods used in the literature to\ninterpret RF resulting models. We have analyzed these methods and classified\nthem based on different axes. Although this review is not exhaustive, it\nprovides a taxonomy of various techniques that should guide users in choosing\nthe most appropriate tools for interpreting RF models, depending on the\ninterpretability aspects sought. It should also be valuable for researchers who\naim to focus their work on the interpretability of RF or ML black boxes in\ngeneral.",
        "updated": "2024-07-17 17:33:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12759v1"
    },
    {
        "title": "LookupViT: Compressing visual information to a limited number of tokens",
        "authors": "Rajat KonerGagan JainPrateek JainVolker TrespSujoy Paul",
        "links": "http://arxiv.org/abs/2407.12753v1",
        "entry_id": "http://arxiv.org/abs/2407.12753v1",
        "pdf_url": "http://arxiv.org/pdf/2407.12753v1",
        "summary": "Vision Transformers (ViT) have emerged as the de-facto choice for numerous\nindustry grade vision solutions. But their inference cost can be prohibitive\nfor many settings, as they compute self-attention in each layer which suffers\nfrom quadratic computational complexity in the number of tokens. On the other\nhand, spatial information in images and spatio-temporal information in videos\nis usually sparse and redundant. In this work, we introduce LookupViT, that\naims to exploit this information sparsity to reduce ViT inference cost.\nLookupViT provides a novel general purpose vision transformer block that\noperates by compressing information from higher resolution tokens to a fixed\nnumber of tokens. These few compressed tokens undergo meticulous processing,\nwhile the higher-resolution tokens are passed through computationally cheaper\nlayers. Information sharing between these two token sets is enabled through a\nbidirectional cross-attention mechanism. The approach offers multiple\nadvantages - (a) easy to implement on standard ML accelerators (GPUs/TPUs) via\nstandard high-level operators, (b) applicable to standard ViT and its variants,\nthus generalizes to various tasks, (c) can handle different tokenization and\nattention approaches. LookupViT also offers flexibility for the compressed\ntokens, enabling performance-computation trade-offs in a single trained model.\nWe show LookupViT's effectiveness on multiple domains - (a) for\nimage-classification (ImageNet-1K and ImageNet-21K), (b) video classification\n(Kinetics400 and Something-Something V2), (c) image captioning (COCO-Captions)\nwith a frozen encoder. LookupViT provides $2\\times$ reduction in FLOPs while\nupholding or improving accuracy across these domains. In addition, LookupViT\nalso demonstrates out-of-the-box robustness and generalization on image\nclassification (ImageNet-C,R,A,O), improving by up to $4\\%$ over ViT.",
        "updated": "2024-07-17 17:22:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.12753v1"
    }
]