A Transparency Paradox? Investigating the Impact of Explanation
Specificity and Autonomous Vehicle Perceptual Inaccuracies on
Passengers
DanielOmeizaa,∗, RaunakBhattacharyyaa,c,1, MarinaJirotkaa, NickHawesa and LarsKunzea,b
aUniversityofOxford,Oxford,UnitedKingdom
bUniversityoftheWestofEngland,Bristol,UnitedKingdom
cIndianInstituteofTechnology,Delhi,India
ARTICLE INFO ABSTRACT
Keywords: Transparencyinautomatedsystemscouldbeaffordedthroughtheprovisionofintelligibleexpla-
Explanations nations.Whiletransparencyisdesirable,mightitleadtocatastrophicoutcomes(suchasanxiety),
Transparency thatcouldoutweighitsbenefits?It’squiteunclearhowthespecificityofexplanations(levelof
AutonomousDriving, transparency)influencesrecipients,especiallyinautonomousdriving(AD).Inthiswork,we
PerceivedSafety examinedtheeffectsoftransparencymediatedthroughvaryinglevelsofexplanationspecificity
VisualAttention in AD. We first extended a data-driven explainer model by adding a rule-based option for
explanationgenerationinAD,andthenconductedawithin-subjectlabstudywith39participants
inanimmersivedrivingsimulatortostudytheeffectoftheresultingexplanations.Specifically,
our investigation focused on: (1) how different types of explanations (specific vs. abstract)
affectpassengers’perceivedsafety,anxiety,andwillingnesstotakecontrolofthevehiclewhen
thevehicleperceptionsystemmakeserroneouspredictions;and(2)therelationshipbetween
passengers’ behavioural cues and their feelings during the autonomous drives. Our findings
showedthatpassengersfeltsaferwithspecificexplanationswhenthevehicle’sperceptionsystem
hadminimalerrors,whileabstractexplanationsthathidperceptionerrorsledtolowerfeelings
ofsafety.Anxietylevelsincreasedwhenspecificexplanationsrevealedperceptionsystemerrors
(hightransparency).Wefoundnosignificantlinkbetweenpassengers’visualpatternsandtheir
anxietylevels.Ourstudysuggeststhatpassengerspreferclearandspecificexplanations(high
transparency)whentheyoriginatefromautonomousvehicles(AVs)withoptimalperceptual
accuracy.
1. Introduction
Theautomotiveindustryiswitnessinganincreasinglevelofdevelopmentinthepastdecades,frommanufacturing
manually operated vehicles to manufacturing vehicles with a high level of automation. Despite these technological
strides,accidentsinvolvingAVscontinuetounderminepublictrust[59,5,38,62,44].Ashighlyautomatedvehicles
makehigh-stakedecisionsthatcansignificantlyaffectend-users,thevehiclesshouldexplainorjustifytheirdecisions
tomeetsettransparencyguidelinesorregulations,e.g.,GDPRArticle12[63]andthe [31].
Accompanying AVs’ driving decisions with natural language explanations is one promising approach for better
vehicletransparency[51,26,34].Thistransparency,obtainedthroughintelligibleexplanations,canhelptoreassure
passengers of safety and also assist them in effectively calibrating their trust in an AV [32]. The specificity level of
∗Correspondingauthor
danielomeiza@robots.ox.ac.uk(D.Omeiza);raunak@robots.ox.ac.uk(R.Bhattacharyya);marina.jirotka@ox.ac.uk(M.
Jirotka);nickh@robots.ox.ac.uk(N.Hawes)
ORCID(s):0000-0002-1232-346X(D.Omeiza)
1ThisauthorwaswiththeUniversityofOxfordatthetimethisworkwasdone.Thisauthor’saffiliationisnowtheIndianInstituteofTechnology,
Delhi
D. Omeiza et al.: PreprintsubmittedtoElsevier Page1of28
4202
guA
61
]CH.sc[
1v58780.8042:viXraA Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Figure 1: Driving simulation setup for the study. The setup included a VR headset, steering wheel, brake and acceleration pedals,
screen,andarcadeseat.Thescreenshowsapedestriancrossingatacrosswalk.
explanations is, however, an important factor in achieving the aforementioned benefits. In real-world deployments,
AVsmaynotalwaysachieveperfectsceneunderstandingduetothelimitationsoftheirperceptionsystems.Depending
onthespecificitylevel,explanationsmightreflecttheseflawsevenwhentheyareinconsequential.Informingoperators
abouttheseinherentimperfectionscouldenhancesafetybyhelpingthemrecognisewhentoremotelytakecontrolofthe
vehicle[36]anditwouldequallyhelpdevelopersoptimiseforhigheraccuracy.Whilethistransparencyishelpfulfor
thesegroups,itremainsuncertainwhetherin-vehiclepassengerswouldpreferhighleveltransparency(ifatalluseful)
thatrevealssuchminorerrors(suchasmistakingavanforabus).Thisiswhatwerefertothetransparencyparadox
in this paper. It is therefore important to determine the appropriate level of transparency for in-vehicle passengers,
mediatedthroughthespecificityoftheexplanations.
Furthermore,aspassengersarelikelytoengageinotheractivitiesduringtheirride,relyingsolelyonvisualcues
tocommunicateawarenessmaybeineffectivewhenpassengers’attentionisdesired.Hence,auditoryandvibrotactile
feedback[37]arealsonecessarytoensurepassengersareadequatelyinformedandcanrespondappropriatelyincritical
situations.
In this study, we investigate the effects of explanation specificity on AV passengers’ perceived safety, feeling of
anxiety,anddesiretotakeovercontrol.Wetesttwolevelsofexplanationspecificity:abstractandspecific.Weusethe
term abstract to describe the provisionof vague auditory explanations that concealdetails about a driving situation
(including perception system errors). In contrast, specific refers to the provision of very detailed and fine-grained
explanationsaboutasituation.Wefoundnon-significanteffectofexplanationspecificityonperceivedsafety.However,
we noticed a significant influence with respect to the amount of perception errors unveiled in the explanations (i.e.,
betweenSpecific(5)—Specific(50).PerceptionofsafetydroppedintheSpecific(50)scenariocomparedtoSpecific
(5).Thefeelingofanxietyalsosignificantlyincreasedwiththeincreaseinperceptionerrors.Therewasasignificant
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 2 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
effectofexplanationsspecificityontakeoverfeeling(Abstract—Specific(50)),butnosignificantdifferencenoticed
betweenSpecific(5)andSpecific(50).Lastly,nostrongcorrelationwasobservedbetweentheparticipants’behavioural
cuesandtheaforementionedfactors.
1.1. ContributionStatement
Overall, this research makes three contributions to the fields of explainable autonomous driving and human-
machineinteraction:
1. It sets out a new case study of explanation specificity in the presence of perception systems errors in the
autonomousdrivingcontext;
2. Itprovidesanenhancedinterpretabletechniqueforgeneratingtextualandauditorynaturallanguageexplanations
forAVnavigationactions;
3. ItrevealsexperimentalfindingsonwhetherhighAVtransparency,thoughcriticaltootherstakeholders,ishelpful
toAVpassengers.
2. Background
Thissectionprovidesabackgroundonexplanationsforautomateddecisionsandinautonomousdrivingfromthe
literature.
2.1. ExplanationsforAutomatedDecisions
Theconceptofexplanationshasbeenstudiedextensivelybyamultidisciplinarygroupofscholars,rangingfrom
PhilosophytoPsychology.Eachadoptsanidiosyncraticlens,characterisingexplanationsintermsrelevanttothegoals
oftheirrespectivedisciplines.Therefore,toguideourstudy,wealignwithadefinitionproposedinanextensivesurvey
ofexplanationsinautonomousdriving[51]:explanationsareapieceofinformationpresentedinanintelligibleway
asareasonorpartofareasonforanoutcome,eventoraneffectintext,speech,orvisualforms.
Recent efforts around explanations have been mainly channelled towards complex AI systems (explainable
AI [25, 1, 16]) to understand and communicate the reasons for the systems’ decisions. Techniques developed for
this purpose fall under different categories based on their mode of operation. Some are model-specific [7] in that
theyinvestigatetheunderlyingAIalgorithmindetailtosupportdebuggingtasks[43].Thesetypesofexplainersare
intrinsicandmodelspecificmeaningthattheyareinherentlycoupledwiththeunderlyingalgorithm.Otherexplanation
approachesareclassifiedasmodel-agnosticastheycanassessthepropertiesofanoutputindependentofthealgorithms
usedtorealisetheoutput[55,41].Theseexplainersaimtohelpenhanceuser’sknowledgeofasystemandpotentially
fostertrust.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 3 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Explanations must possess certain properties to be effective to their intended recipients. Mittelstadt et al. [47]
argued that the risk of conflicts in communicating explanations when the explainer (explanation provider) and the
explainee (explanation recipient) have different motives may be mitigated through social, selective, and contrastive
explanations. Social in the sense that the explanation process involves different parties and the explainer is able to
modeltheexpectationsoftheexplainee.Theexplanationisselectiveifitcanselectexplanationsfromseveralcompeting
hypotheses.Itisconsideredcontrastiveifitcandifferentiatethepropertiesoftwocompetinghypotheses.Kment[33]
furtheremphasisedthevalueofcounterfactualexplanationsinenhancingunderstanding.Theseexplanationsdescribe
howchangesininputcanleadtoashiftfromonefacttoacompetinghypothesis(foil)[46].Explanationsshouldbe
intelligible[50]andstrikeadelicatebalancebetweenprovidingsufficientdetailandrespectingthecognitivecapacity
oftheexplainee.Thisbalancepresentsasignificantchallenge,asaccuratelygauginganindividual’sreal-timecognitive
capacityremainsdifficult.
Different methodologies have been adopted in the XAI literature. Wang et al. [64] categorised these research
methodologies into three groups: First, the existence of unvalidated guidelines for the design and evaluations of
explanations was highlighted. The authors claimed that these kinds of guidelines are based on authors’ experiences
withnofurthersubstantialjustification.Second,researcherssuggested(in[66])thatunderstandingusers’requirements
ishelpfulinXAIresearch.Itisonthispremisethatpreviousresearchonexplanationdesignhasbeenthoughttobe
empirically derived. This type of XAI research elicits explanation requirements from user surveys to determine the
rightexplanationforausecasewithexplanationinterfaces.Third,someexplanationdesignmethodsarederivedfrom
psychologicalconstructsfromformaltheoriesintheacademicliterature.Someofthesemethods(e.g.,in[30])draw
ontheoriesfromcognitivepsychologytoinformexplanationdesignforexplanationframeworks.Ourworkisheavily
groundedonempiricalstudies.
2.2. ExplanationsinAutonomousDriving
Explanationshavebeenfoundusefulinenhancinguserexperience[56],trust[34,26],andimprovedsituational
awareness[49,40]inautomateddriving.Recentworkshaveexploredhumanfactorsintheapplicationofexplainable
AI in AD. For instance, in [50, 48], a socio-technical approach to explainability was proposed. An interpretable
representationandalgorithmsforexplanationsbasedonacombinationofactions,observations,androadruleswere
designed.Regardingexplanationsdepths,thenotionthatexplanationswithhigherlevelsofabstractionandcorrectness
are superior has been argued in the literature [6, 24]. Additionally, Ramon et al. (2021) argued that the specificity
of explanations should be tailored to the application context, noting that low-level specificity is often preferred by
individualswithamoredeliberativecognitivestyle.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 4 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
In this paper, the term explanation specificity is used to refer to two specificity levels of explanations, abstract
(lowtransparency)andspecific(hightransparency).ExplanationscanbeusedtoconveydifferentinformationinAD,
e.g., vehicle uncertainties and intentions, and communicated through different modalities. For example, Kunze et
al. [36] conveyed visual uncertainties with multiple levels to operators using heartbeat animation. This information
helpedoperatorscalibratetheirtrustinautomationandincreasedtheirsituationawareness.Similarly,Kunzeetal.[37]
usedperipheralawarenessdisplaytocommunicateuncertaintiestoalleviatetheworkloadonoperatorssimultaneously
observingtheinstrumentclusterandfocusingontheroad.Thisuncertaintycommunicationstyledecreasedworkload
and improved takeover performance. In addition, the effects of augmented reality visualisation methods on trust,
situationawareness,andcognitiveloadhavebeeninvestigatedinpreviousstudiesusingsemanticsegmentation[11],
scenedetectionandprediction[12],andpedestriandetectionandprediction[10].Thesedeepvision-basedtechniques
applied to automated driving videos and rendered in augmented reality mode were a way of calling the attention of
operatorstoriskytrafficagentsinordertoenhancesafety.Whileunder-explored,auditorymeansofcommunicating
explanations are important to calling in-vehicle participants’ attention to critical situations in AD. We thus used
an auditory communication style in this study to convey explanations to passengers. Some existing works around
human-machineinteraction[40]haveleveragedtheoreticalmodels(e.g.,mentalandsituationalmodels[21])tostudy
explanations. We based our work on behavioural cues and subjective feedback from participants while drawing
connectionstosuchexistingworks.
2.3. ResearchQuestions
Fromtheprecedingliteraturereview,wefindtheneedtogainadeeperunderstandingoftheeffectsoftransparency,
brought about by natural language explanations of varying specificity, especially under imperfect AV perception
systems.
1. Givenvaryinglevelsofperceptionsystemerrors,howdonaturallanguageexplanationsinfluencepassengers’
perceivedsafety?
• H1.1-PerceivedSafety.LowtransparencyyieldsahigherperceptionofsafetyinanAVwithperception
system errors. We hypothesise that passengers feel safer in a low transparency AV, despite receiving
abstract explanations. While individuals often seek the truth, many prefer information that aligns with
their expectations [27]. Consequently, specific explanations may reveal perception system errors that
contradict passenger expectations. Additionally, research has shown that placebo explanations can have
similarpositiveeffectsonpeopleasrealexplanations[18].
• H1.2 - Feeling of Anxiety. Passengers’ feeling of anxiety increases with increasing perception system
errors in a highly transparent AV. We posit that there is a connection between perceived safety and the
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 5 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
feelingofanxiety[13,53].Therefore,explanationsthatfrequentlyreferencemisclassifiedactorsarelikely
tocreateasenseofinsecurity,leadingtoincreasedanxiety.
• H1.3-TakeoverFeeling.InhighlytransparentAVs,passengersaremorelikelytodevelopthefeelingto
takeovernavigationcontrolfromtheAVwithhigherperceptionsystemerrors.Althoughpassengersare
not able to take control in this study, we anticipated that they might nurse the thought to do so if they
repeatedlyreceivedillogicalexplanationsfromtheAV.
2. Dopassengers’behaviouralcuescorrelatewiththeirfeelings?
• H2.1 - Visual Feedback Visual feedback from participants correlates with their feeling of anxiety.
Individuals with the feeling of anxiety might be usually hyper-aroused and sensitive to environmental
stimuli. They may have difficulties concentrating, performing tasks efficiently, and inhibiting unwanted
thoughtsanddistractions [28,8].Participants’fixationpointsandsaccadesshouldcorrelatewithanxiety.
3. PassengerStudy
Inthissection,wedescribetheparticipants’demographic,experimentapparatussetup,experimentdesign,andthe
procedureoftheexperiment.ThenecessaryapprovaltoconductthestudywasobtainedfromourUniversity’sResearch
EthicsCommittee.
3.1. Participants
We conducted a power analysis to estimate the number of subjects required for the study. Afterward, calls for
participants were placed on various online platforms, such as the callforparticipants platform, university mailing
groups,universitySlackchannels,theresearchgroupwebsite,andsocialmediatorecruitsubjects.Uponscreening,the
finalsampleconsistedof𝑁 =39participants(28male,11female)ranginginagefrom18to59years.Theparticipants
comprised students, university employees, and members of the callforparticipants platform. Although prior driving
experiences were not required, 28 (71.79 %) of the participants were licensed drivers. Only 2 of the 39 participants
(5.13%) had experience with autonomous drives, however, in a research context. 6 (15.38%) of the participants had
usedavirtualrealityheadsetforadrivinggameordrivingexperimentinthepast.
3.2. Apparatus
3.2.1. Hardware
ThehardwaresetupisshowninFig.1.WeconductedtheexperimentinadrivingsimulatorthatcomprisedaGTR
arcadeseat,LogitechG29steeringwheelwithforcefeedback,turnsignalpaddles,brakeandacceleratorpedals,and
an ultra-wide LG curved screen to display the experiment. A state-of-the-art virtual reality (VR) headset (with an
immersive360◦FoVandaneyetracker)wasalsousedtoprovideanimmersiveexperienceandhighvisualfidelity.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 6 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Table 1
Descriptionofasubsetoftheevents(5outof9)andcorrespondingexplanationsprovidedduringthestudy.Observationsandcausal
explanations are announced to passengers. AV’s action (text in red), other agent’s class & action (text in blue), and the agent’s
location(textingreen)aredeterminedbytheexplaineralgorithmdescribedinAlgorithm1.
Event Description Observation Causal Explanation
FollowLeadingVehicleAV follows a leading actor. At vehicle ahead on my lane. Stopping because cyclist
some point, the leading actor stopped on my lane.
slowsdownandfinallystops.The
AV has to react accordingly to
avoid a collision.
VehicleTurning AV takes a right or a left turn motorbike crossing my Stopping because motor-
from an intersection where an lane. bike is crossing my lane.
actorsuddenlydrivesintotheway
of the AV, AV stops accordingly.
After some time, the actor clears
the road, AV continues driving.
LaneChangeObstacleAV follows a leading actor, and vehicle ahead on my lane. Changing lane to the
at some point, the leading actor [right/left] because vehi-
decelerates. The AV reacts ac- cle stopped on my lane.
cordingly by indicating and then
changing lanes.
StopSignalNoActor No actor ahead of the AV at a red traffic light ahead on Stopping because traffic
signalised intersection with a red my lane. light is red on my lane.
traffic signal. AV decelerates and
stops.
MovSignalNoActor No actor ahead of the AV. AV None Moving because traffic
starts moving from a stop state light is green on my lane.
at a signalised junction or inter-
section.
Figure2:High-levelarchitectureofoursimulationsoftware.DReyeVRusesUnrealengineandextendsCARLAsimulator,whichalso
builds on Unreal engine. DReyeVR extends CARLA by adding VR functionalities, vehicular and ambience sounds, eye tracker data
logging,andadditionalsensors,amongothers.Ourexplainermodel,whichisbothrule-basedanddata-driven,receivesgroundtruth
datafromCARLAorDReyeVRandgeneratesexplanationsforpredictedactions.Thepost-processingscriptallowedustomodifythe
generatedexplanationsaswedesire.
3.2.2. DrivingSoftware
Software architecture is illustrated in ??. We adapted the DReyeVR [57], an open-source VR-based driving
simulation platform for behavioural and interaction research involving human drivers. DReyeVR was built atop
CARLA [17], an open-source driving simulator for AD and Unreal Engine 4. DReyeVR provides a very realistic
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 7 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
experience with naturalistic visuals (e.g., in-vehicle mirrors) and auditory (e.g. vehicular and ambient sounds)
interfacesallowingforanecologicallyvalidsetup.Italsoprovidesanexperimentalmonitoringandloggingsystemto
recordandreplayscenarios,aswellasasign-basednavigationsystem.
3.2.3. ExplainerSoftware
AsshowninFig.2,wedevelopedanexplainersystembasedonpreviouswork[48].Thissystemutilisesatree-based
model trained on an annotated AV driving dataset that we collected in a prior project. While the original algorithm
in [48]isprimarilydata-driven,weincorporatedarule-basedtechniquetoserveasafallbackwhenthedata-driven
methodfailsormakesanincorrectegoactionprediction.Thedata-drivenmethodemploysatrainedtree-basedmodel
to predict and generate explanations from detections obtained from CARLA, a driving simulator. In contrast, the
rule-basedapproachreliesonCARLA’sgroundtruthdataandfollowspredefinedrulestodeterminewhichagentsto
referenceintheexplanations.Bycomparingpredictionsfromthedata-drivenmethodwithgroundtruthobservations
from CARLA, we can identify incorrect predictions. This enhanced explainer system, combining both data-driven
and rule-based approaches, was used to generate preliminary explanations for our created scenarios. Wintersberger
etal.(2020)suggestedtypesoftrafficelementstobeincludedinvisualexplanationsbasedonuserpreferences.Our
proposedexplainer,however,selectstrafficelementsdeemedimportant(featureimportance[2])bythedrivingmodel
foritsdecisions(seeAlgorithm1).
Weperformedpost-processingoperationsonthegeneratedexplanations,includingfine-tuningsomeofthecontent
andadjustingtimestampstoensuretheexplanationsweredeliveredattheappropriatemoments.
Algorithm1:IntelligibleExplanationGeneration
Input:treemodelforego’sactionprediction,inputvector𝐗describingego’senvironment
Output:intelligibleauditoryexplanation
1
Selectarepresentativetree𝑚∈fromtreemodel.
2
Predictaction𝑦∈ given𝐗.
3
Compareprediction𝑦withCARLAgroundtruth𝑦 𝐺𝑇.
4 if 𝑦=𝑦 𝐺𝑇 then
5
Tracethedecisionpath 𝑦fortheprediction𝑦intree𝑚.
6
Computetheimportancescore𝐼(𝐗 𝑖)oftheattributes𝐗 𝑖ineachnode𝑖alongthedecisionpath 𝑦.
7
Selectattributes𝐗 𝑖withimportancescores𝐼(𝐗 𝑖)≥𝑘,where𝑘isapredefinedthreshold.
8
Mergetheconditions/inequalitiesintheselectedattributes𝐗 𝑖.
9
Translatemergedattributes𝐗 𝑖tonaturallanguagefollowingthetemplateinTab.1.
10 else
11
UseCARLAgroundtruthinformation𝑦
𝐺𝑇
andpredefinedrulestogenerateexplanationfollowingthe
templateinTab.1.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 8 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Table 2
Description of Scenarios: The Independent Variables
Scenario Specificity/Transparency PerceptionErrors(%) ScenarioLength ExamplesofEvents Environment
Abstract Low 0 ∼4minutes AlleventsfromTable1 CARLATown10HD
Specific(5) High 5 ∼4minutes AlleventsfromTable1 CARLATown10HD
Specific(50) High 50 ∼4minutes AlleventsfromTable1 CARLATown10HD
4. ExperimentDesign
Beforethestartofthetrials,participantswereaskedtomanuallydriveavehicleforabouttwominutesinCARLA
Town03—a complex town, with a 5-lane junction, a roundabout, unevenness, and a tunnel. 30 vehicles and 10
pedestrians were spawned in this town. This preliminary drive aimed to familiarise participants with the driving
simulationenvironmentandtoallowthemtoexperiencemanualdrivingwithinthesimulation.
Weemployedawithin-subjectdesignduetothelimitedsamplesize,whichwasinsufficientforabetween-subject
study.Additionally,thisdesignhelpedmitigatethepotentialco-foundingfactorofbetween-individualdifferencesina
between-subjectdesign.
4.1. IndependentVariable
Combinationsoftransparencylevel(lowandhigh)andAVperceptionerrors(lowandhigh)weredonetoobtain
theindependentvariableScenarios.Thefirstscenario(Abstractscenario)comprisesabstractexplanationsindicating
low transparency and an undefined amount of perception system errors. The second scenario (Specific(5) scenario)
comprisesspecificexplanationsindicatinghightransparencyand5%amountofperceptionsystemerrorsindicatinglow
errordegree.Thethirdscenario(Specific(50)scenario)comprisesspecificexplanationsindicatinghightransparency
and50%amountofperceptionsystemerrorsindicatinghigherrordegree.Thedrivingeventsthatmadeupthedifferent
Figure 3: Scenario routes. Red: Abstract, Green: Specific(5), Blue: Specific(50). Each route is a loop and overlaps with
others at some points.
scenarios were carefully designed to include different driving conditions that are obtainable in the real world (See
Table1).NotethatscenariosThescenarioroutesareshowninFigure3.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 9 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
i.Abstract AscenarioinCARLATown10HD,whichisabout4minuteslong(330secs).Town10HDisanurbancity
environmentwithdifferentinfrastructures,suchasanavenueorpromenade,andrealistictextures.Drivingconditions
are a combination of the events in Table 1. The perception system in this scenario might contain some errors, but
theexplanationsprovidedinthisscenariowerepost-processedtoalwaysprovidesurfaceinformationwhichisvague
enoughtoconcealperceptionerrors.Therulesgoverningexplanationsforthisscenariowere:
• alltrafficlightsarereferredtoas‘trafficsign’withoutspecifyingthestate(e.g.,red,green,amber,off)ofthe
trafficlight;
• pedestriansarereferredtoas‘roadusers’;
• allnon-humanmovingactorsarereferredtoas‘vehicle’.Thisincludescycles,motorbikes,cars,etc.
Anexampleexplanationis‘stoppingbecauseofthetrafficsignonmylane’.Thisobfuscatesthetypeandcolourofthe
trafficsign.
ii. Specific(5) A scenario in CARLA Town10HD, which was about 4 minutes in length (256 seconds). Driving
conditionsinthisscenariowereacombinationoftheeventsinTable1.Theexplanationsgeneratedinthisscenariowere
specificanddetailed,exposingallerrors.TheperceptionsystemoftheAVinthisscenariowasabout5%inaccurate.
Thiserrorvaluewasestimatedfollowingthedynamictrafficagentclassificationmodelandconfusionmatrixprovided
by [4]andthetrafficlightclassificationmodelandconfusionmatrixby[45].Wewereonlyinterestedintheconfusion
matrices(andnotthemodels).Theconfusionmatriceshelpedustosystematicallyintroducethe5%perceptionsystem
errorsduringthepost-processingstageoftheexplanations.Inthisscenario,the5%errorresultedinoneexplanation
(1outofthe22)beingerroneousastheexplanationexposedthemisclassificationerrorsfromtheperceptionsystem.
Anexampleofanerroneousexplanationis:‘vanaheadonmylane’.Here,acarwasmisclassifiedasavan.
iii.Specific(50) AscenarioinCARLATown10HD,whichwas4minutesinlength(274seconds).Drivingconditions
wereacombinationoftheeventsinTable1.Theexplanationsgeneratedinthisscenariowereasfine-grained/specific
and detailed as those in the Specific(5) scenario. The perception system error of the AV in scenario Specific(5)
was significantly noised to reach a reduced accuracy of 50%. We assumed that this reduction in accuracy might be
sufficienttoinfluencepeoples’behaviour.Therefore,halfoftheexplanationsinthisscenario(12outof24)reflected
misclassificationofactorsoractorstates.Anexampleofanerroneousexplanationis‘movingbecausetrafficlightis
switchedoffonmylane’.Inthiscase,theperceptionsystemfailedtoidentifyagreenlightaccurately.
NotethatallthreescenariosweredesignedsothattheAVperceptionerrorswereinsignificanttotheAV’snavigation
actions.Hence,theAVrespectedallroadrulesandavoidedcollisions.Thiswasimportantasthestate-of-the-artAVs
would likely not make obvious navigation errors. Moreover, we were interested in the effects of the awareness of
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 10 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
inconsequential perceptual errors in AVs. Hence, it was necessary to introduce artificial errors of varying degrees
(lowandhigh).Thenon-influenceofAVperceptionerrorsonnavigationcontrolalsohelpedtoavoidtheconfounding
factorsofroutenavigationproblems.Further,wecounterbalancedtheroutesacrossscenarios.Thatis,theAV’sroute
wasdifferentineachscenario.Thisdesigndecisionwasmadetoreducecarry-overeffectsontheparticipants.With
this setup, the scenarios were still comparable as they were all within the same town, and the routes shared similar
features.EachscenarioalsohadabalancedcombinationoftheeventslistedinTable1.Inallthescenarios,theAV
maintained a speed below 30𝑚𝑝ℎ, the recommended speed limit in urban areas in the UK. See Figure 4 for sample
scenesfromeachscenarioandtheircorrespondingexplanations.
4.2. DependentVariables
Thereweresixdependentvariables:PerceivedSafety,FeelingofAnxiety,TakeoverFeeling,FixationDivergence,
Saccade Difference, and Button Presses. These variables were categorised into two (psychological factors and
behaviouralcues)foreasyanalysisandreporting.
Psychological Factors These factors include Perceived Safety, Feeling of Anxiety, and Takeover Feeling. They
were mainly measured using items from the Autonomous Vehicle Acceptance Model Questionnaire (AVAM) [29].
AVAMisauseracceptancemodelforautonomousvehicles,adaptedfromexistinguseracceptancemodelsforgeneric
technologies. It comprises a 26-item questionnaire on a 7-point Likert scale, developed after a survey conducted to
evaluatesixdifferentautonomyscenarios.
Items24—26wereusedtoassessthePerceivedSafetyfactor,whileitems19—21wereusedtoassesstheFeelingof
Anxietyfactor.Similarto[56],weintroducedanewitemtoassessparticipants’feelingstotakeovernavigationcontrol
fromtheAVduringtheride(TakeoverFeeling).Specifically,participantswereaskedtoratethestatement‘Duringthe
ride,Ihadthefeelingtotakeovercontrolfromthevehicle’ona7-pointLikertscale.Actualnavigationtakeoverby
participantswasnotpermittedbecausewewantedtobeabletocontroltheentireexperimentandhaveallparticipants
experiencethesamescenarios.Moreover,weweredealingwithL4automation.Thoughparticipantswerenotexpected
todriveortakeovercontrol,theymighthavenursedthethoughttodoso.ThisiswhattheTakeoverFeelingvariable
measures.
Weaddedafree-responsequestionrelatedtoexplanationswiththeaimofobtainingqualitativedatafortriangu-
latingquantitativeresults.Participantswereaskedthefollowingquestion:‘Whatisyourthoughtontheexplanations
providedbythevehicle,e.g.,madeyouless/moreanxious,safe,feelingtotakeovercontrol?’.Werefertotheresulting
questionnaireastheAPTQuestionnaire(i.e.,A-Anxiety,P-PerceivedSafety,T-TakeoverFeeling).
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 11 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
(a)Abstract-Observation:‘vehicleis (b)Specific(5)-Observation: ‘motor (c)Specific(50)-CausalExplanation:
crossingonmylane’ bikeaheadonmylane’ ‘stopping because cyclist is crossing
mylane.’
Figure 4: Sample screenshots and the generated explanations (including observations announcement and causal
explanations) from the three driving scenarios. Heatmaps of gaze points from all the participants are plotted over the
images, indicating areas of interest. In the Abstract scenario (Figure 4a), all movable/dynamic non-human actors are
referred to as ‘Vehicle’. Thus, a cyclist was referred to as a vehicle. Figure 4b depicts a scene from the Specific(5)
scenario in which the AV’s perception system accurately identified and classified a motorbike and provided a fine-grained
explanation for this. In the Specific(50) scene (Figure 4c), the AV’s perception system misclassified a pedestrian as a
cyclist. The fine-grained/specific explanation provided exposed this error.
Figure5:Studyprocedure.EyecalibrationwasdonewiththeVRheadset;participantsdrovefortwominutes,participants
experiencedeachofthe 4minsscenariosincounterbalancedorderandcompletedtheFeelingofAnxiety,PerceivedSafety,
and Takeover Feeling Questionnaire (APT Scale) in between each scenario. Participants were debriefed.
BehaviouralCues WealsousedButtonPresses,FixationDivergence,andSaccadeDifferenceasadditionalmetrics.
ButtonPresseswereusedtoexpressunsafe,anxiousorconfusedfeelings.
Fixation Divergence is the Euclidean distance between mean participants’ fixation points and reference fixation
points.Thisprovidesinformationtodrawinferencesaboutparticipants’distractions.
ForSaccadeDifference,weestimatedparticipants’saccadevelocityovertimefollowingthemethodin[23]and
foundthedifferencefromareferencesaccadevelocities.Saccadeistherapidmovementoftheeyebetweenfixation
points.Saccadevelocityisthespeedofsuchmovements.Thefixationandsaccadereferencepoints(orgroundtruths)
werethefixationandsaccaderecordsobtainedfromtheresearcher,whoalsoparticipatedinthestudy.
4.3. Procedure
TheprocedureoftheexperimentisillustratedinFig.5.Afterallpreliminaryformcompletionsandbriefings,we
introducedthephysicaldrivingsimulatorandexplainedthesubsequentsteps,whichinvolvedapre-experimentmanual
drivingsessioninVRmodelastingfor2minutes.Participantswereinformedthatthepurposeofthispre-experiment
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 12 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
exercisewastofamiliarisethemwiththesimulationenvironmentandtoidentifyindividualspronetomotionsickness,
whowouldthenbeexcludedfromthemainexperiment.
Upon completion of the manual driving exercise, the researcher removed the VR headset from the participant
and explained the aim and procedure of the main experiment. The instructions included the following statements:
‘youwouldexperience3autonomousridesbydifferentvehicles,[...]andaftereachride,youwouldcompleteashort
survey.Thevehicledrivesalongapredefinedpathforabout4minutesandprovidesexplanationsforitsplanneddriving
decisionsandannouncesrelevantobjectsinitsenvironment.[...].Thevehicletellsyouitsnextdirectionatajunction
oranintersectionusingitsrightorleftredlightindicatorsonitsdashboardaccordingly.[...]Simplyclickanyofthese
buttonsifthedecisionortheexplanationofthevehiclemakesyoufeelconfused,anxiousorunsafe[...]’.Theresearcher
thenplacedtheVRheadsetbackontheparticipantandinitiatedthescenarios.Completecounterbalancingwasapplied
tothescenariotreatments,resultinginsixdifferentordersofscenarios.Eachparticipantexperiencedthescenariosin
oneofthesesixorders,withapproximatelysixparticipantsperorder.
Participantswereencouragedtorestbrieflyaftereachdrivingexperience,withtheVRheadsetremoved.Ashort
debriefingsessionfollowedthestudy,andparticipantsweregivena£10Amazongiftcard.Theentireexperimentlasted
approximately50minutes.
The researcher also participated in the experiment, experiencing all three scenarios. Throughout, the researcher
focusedonthelaneaheadandtheactorsreferencedbytheexplanations.Neithererroneousnorabstractexplanations
influencedtheresearcher’sfocus,astheresearcherremainedattentivetothelaneandtheactorsorobstaclesimpacting
the AV’s actions, regardless of the explanations. This consistency was due to the researcher’s familiarity with all
scenarios.Thedatafromtheresearcherservedasareferenceorgroundtruth.Notably,theresearcher’seyemovements
matchednormalhumansaccadicvelocity,whichreaches300—400°/seconds[54,65].
5. QuantitativeResults
5.1. PsychologicalFactorsAnalysis
TotestourhypotheseslistedinSection2.3,weanalyzeddatafromthethreeAPTquestionnaires.Wecreatedalatent
variable(FeelingofAnxiety)byaveragingresponsestoAVAMItems19—21,andanotherlatentvariable(Perceived
Safety) by averaging responses to AVAM Items 24—26. We calculated Cronbach’s Alpha (𝛼) for the independent
variables that formed the latent dependent variables to ensure they had adequate internal consistency. Results with
an adjusted p-value less than 0.05 (𝑝 < .05) were considered significant. P-values were adjusted using Bonferroni
corrections,wherethecalculatedp-valuesweremultipliedbythenumberofscenarios,toreducethelikelihoodofType
I errors (false positives). Normality tests, including the Kolmogorov-Smirnov, Shapiro-Wilk, and Anderson-Darling
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 13 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Table 3
Descriptive statistics from APT questionnaire analysis.
Perceived Safety Feeling of Anxiety
Takeover Feeling
Cronbach 𝛼 ∶0.87, Cronbach 𝛼 ∶0.86
𝐻(2) =
𝐻(2) = 𝐻(2) =
6.27,𝒑=.𝟎𝟒𝟒
8.17,𝒑=.𝟎𝟏𝟕 13.32,𝒑=.𝟎𝟎𝟏
Mean SD Mean Rank Mean SD Mean Rank Mean SD Mean Rank
Abstract 4.89 1.35 2.15 2.81 1.34 1.72 2.79 1.91 1.68
Specific(5) 4.93 1.13 2.22 2.79 1.2 1.81 3.31 1.79 2.10
Specific(50) 3.86 1.58 1.63 3.93 1.68 2.47 3.87 1.94 2.22
tests,indicatedaviolationofnormalityintheFeelingofAnxiety,PerceivedSafety,andTakeoverFeelingfactors.Hence,
weperformedaFriedmantestforthesedependentvariables,seeTable3andFigure6.
Figure6:Perceivedsafety,feelingofanxiety,andtakeoverfeelingdistribution.PerceivedsafetyishighestintheSpecific(5)
scenario, the feeling of anxiety is highest in the Specific(50), and takeover feeling is lowest in the Abstract scenario.
H1.1 - Perceived Safety Low transparency yields a higher perception of safety in an AV with perception system
errors.
AFriedmantestwasconducted.Nosignificantdifferencewasfoundinthescenariopair:Abstract—Specific(5),
and the pair: Abstract — Specific(50). In fact, the perceived safety mean rank in the Specific(5) scenario (2.22) was
higherthanthatintheAbstractscenario(2.15),seeTable3.Therefore,therewasnosufficientevidenceinsupportof
hypothesisH1.1.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 14 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
H1.2 - Feeling of Anxiety Passengers’feelingofanxietyincreaseswithincreasingperceptionsystemerrorsina
highly transparent AV. A Friedman test indicated a significant difference in the Feeling of Anxiety across scenarios,
𝐻(2) = 13.32,𝑝 = .001.ThepairwisescenariocomparisonsofAbstract-Specific(50)andSpecific(5)-Specific(50)
resultedinanadjustedp-valueof.003and.01respectively(seeTable3).Hence,thereisstrongevidenceinsupportof
hypothesisH1.2.
H1.3-TakeoverFeeling InhighlytransparentAVs,passengersaremorelikelytodevelopthefeelingtotakeover
navigationcontrolfromtheAVwithhigherperceptionsystemerrors. AFriedmantestshowedasignificantdifference
in Takeover Feeling across scenarios, 𝐻(2) = 6.27,𝑝 = .044. While the pairwise scenario comparison of Abstract
- Specific(50) resulted in an adjusted p-value of .017, the pairwise comparison of Specific(5) - Specific(50) resulted
inanadjustedp-valueof0.61.Hence,thereisnosignificantdifferenceinTakeoverFeelingbetweenSpecific(5)and
Specific(50)scenarios,andtherefore,noevidenceinsupportofhypothesisH1.3(seeTable3).
Figure 7: Fixation divergence across scenarios. While Specific(5) had the highest mean fixation divergence, Specific(50)
had more frequent high fixation divergences. Red vertical bars represent the positions in time where causal explanations
were provided.
5.2. BehaviouralCuesAnalysis
H2.1 - Visual Responses Visualfeedbackfrompassengerscorrelateswithpassengers’anxiety.Atthisstage,we
utilised the reference data from the researcher. We estimated the Euclidean distances between participants’ fixation
pointsandthereferencefixationpointsovertimeforeachparticipant.
ResultsfromSpearmancorrelationshowedthattherewasnosignificantassociationbetweentheFeelingofAnxiety
and Fixation Divergence, 𝑟(115) = −0.07,𝑝 = .442. See the fixation divergence plot in Figure 7. Results from
Spearman correlation showed that there was no significant association between the Feeling of Anxiety and saccade
difference,𝑟(115)=0.1,𝑝=.281.However,therewasasignificantassociationbetweenperceivedsafetyandsaccade
difference,𝑟(115) = −0.25,𝑝 = .007.,indicatingaweaknegativecorrelationbetweenperceivedsafetyandsaccade
difference.HypothesisH2.1,therefore,hasnosufficientsupport.SeethesaccadedifferenceplotinFigure8.
In addition to correlation, we checked for significant differences. There was a significant difference in Fixation
DivergencebetweenAbstractandSpecific(5)withanadjustedp-valueof.028,andbetweenSpecific(5)andSpecific(50)
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 15 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Figure 8: Saccade velocity difference across scenarios. Specific(5) had the lowest mean saccade velocity difference while
the Abstract scenario had the highest. Red vertical bars represent the positions in time where causal explanations were
provided.
Table 4
Descriptive statistics from the haptic and Visual responses.
ButtonPress Fixation Divergence Saccade Difference
𝐻(2) = 𝐻(2) = 𝐻(2) =
15.44,𝒑<.𝟎𝟎𝟏 20.67,𝒑<.𝟎𝟎𝟏 15.35,𝒑<.𝟎𝟎𝟏
Mean SD Mean Rank Mean SD Mean Rank Mean SD Mean Rank
Abstract 2.26 3.35 1.72 4.37 1.84 1.95 1.25 0.43 2.42
Specific(5) 1.64 1.63 1.77 7.66 5.21 2.54 1.06 0.42 1.54
Specific(50) 4.9 4.33 2.51 3.2 1.23 1.51 1.17 0.45 2.04
withanadjustedp-value<.001.SeeTable4fordescriptivestatistics.Also,therewasasignificantdifferencebetween
Abstract and Specific(5) with respect to Saccade Difference (adjusted p-value of < .001). See Figure 4 for sample
scenesfromeachscenariowiththegeneratedexplanations.Alltheparticipants’gazepointsareplottedasheatmaps
overthescreenshots.
5.2.1. HapticResponse
Participants were asked to press a button on the Logitech wheel when they felt confused, anxious, or unsafe by
the explanations or the decision of the AV during the ride. Spearman rank correlation was used as a measure to
investigate monotonic associations. There was a weak negative correlation between the variables Perceived Safety
and ButtonPress (𝑟(115) = −0.31,𝑝 = .001), a weak positive correlation between the Feeling of Anxiety and
ButtonPress(𝑟(115)=0.31,𝑝=.001),andinsignificantcorrelationbetweentheFeelingstoTakeoverandButtonPress
(𝑟(115)=0.15,𝑝=.099).
WealsocheckedforstatisticallysignificantdifferencesinButtonPressesacrossscenarios.Therewasasignificant
differenceinButtonPresses,𝐻(2) = 15.44,𝑝 < .001.Thiswasspecificallyinthepairs:Abstract -Specific(50)with
adjusted p-value .002, and Specific(5) - Specific(50) with adjusted p-value .005. See Figure 9 for behavioural cues
results.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 16 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Figure9:Buttonpresses,fixationdivergenceandsaccadedifferencedistribution.ButtonpressesarefewerintheSpecific(5)
scenario. Fixation divergence is highest in the Specific(5) scenario, and saccade difference is lowest in the Specific(5).
6. QualitativeResults:ThemesandReflections
WeobtainedqualitativedatafromtheAPTquestionnaireadministeredaftereveryscenario.Participantswereasked
todescribetheirfeelingsregardingtheexplanationstheyreceivedduringtheride.Table5andFigure10describethe
themesobtainedfromtheinductivethematicanalysisofthecomments.Themesarebroadlycategorisedbasedonthe
participants’feelings,theirassessmentoftheexplanations,andthevehicledynamics.
PerceptualerrorsintheSpecific(50)scenarioevokednegativeemotionsofanxiety,feelingtotakeovernavigation
controlanddistrust.CAND1expressedafeelingofanxiety:‘Theexplanationsmademefeelabitanxious,itsaysmany
thingsthatwerenotrightandmisleading.Ihadtheurgetolookatthebuildingsandtheenvironmentbutcouldnot
really do that because I wanted to be sure the vehicle is taking the right decision.’. CAND39 expressed the urge to
takeover navigation control: ‘When the explanations are false, e.g. ’a cyclist is crossing my lane’, and it is actually
apedestrian,itmademeslightlyanxiousandlikelytowanttotakeover.Butnevertheless,Ifeltsafeinthevehicle’.
CAND5 expressed distrust in the AV: ‘anxious as the vehicle did not correctly understand the environment and the
typesofvehiclesaroundit,whichmademetrustitsjudgementless’.Moreparticipantsexpressedafeelingofsafetyin
theSpecific(5)scenario:‘feltsafethatthevehicleunderstoodtheroadandwhatwasgoingonaroundus’.Aboutthe
samenumberofparticipantsexpressedadeclineintheirfeelingofanxietyintheAbstractandSpecific(5)scenarios.
AnexampleisCAND34’scommentabouttheabstractscenario:‘Whentheexplanationsprovidedaremoregeneral,
e.g.’vehicle’insteadof’van’and’roaduser’insteadof’cyclist’,itfeelslikethevehiclehasabetterunderstandingof
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 17 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Table 5
Themesderivedfromthethematicanalysisofthequalitativedatafromparticipants.Freq.=Frequencyofoccurrence,SP
= Scenario Percentage
Abstract Specific(5) Specific(50)
Category Theme Freq. SP (%) Freq. SP (%) Freq. SP (%)
Feelings Anxious 2 5 2 5 8 21
Less Anxious 5 13 5 13 1 3
Safe 9 23 12 31 7 18
Unsafe 0 0 1 3 1 3
Takeover 2 5 2 5 7 18
Confident 2 5 5 13 3 8
Trust 2 5 1 3 2 5
Distrust 1 3 0 0 6 15
Reassuring 5 13 2 5 0 0
Uncomfortable 2 5 1 3 0 0
Explanations Good Timing 1 3 0 0 0 0
Bad Timing 7 18 1 3 1 3
Plausible 2 5 10 26 1 3
Implausible 5 13 3 8 25 64
Unintelligible 6 15 0 0 0 0
Repetitive 3 8 4 10 2 5
Vague 5 13 0 0 0 0
Vehicle Dynamics Careful Manoeuvre 3 8 2 5 4 13
Aggressive Manoeuvre 1 3 3 8 5 13
Vehicle Feature 0 0 3 8 1 3
Figure10:Themesderivedfromthethematicanalysisofthequalitativedatafromparticipants.Frequencyisexpressedinpercentage
ofthetotalnumberofresponsesineachscenario.
thesurroundingsbecauseitgivesacorrectexplanation,soIfeltlessanxiousandunsafe’.Theabstractexplanations
mighthaveconcealedsomeerrors,inturn,reducingthefeelingofanxiety.
Therewerespecificcommentsabouttheexplanationsacrossthethreescenarios.Manyparticipantsthoughtthat
theexplanationsintheSpecific(5)wereplausibleinthattheysoundedcorrectandalignedwithwhattheparticipants
saw. For example: ‘Explanations were clear and made sense. Still don’t feel some of the reactions were as quick as
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 18 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Imighthavemadethem’—CAND14.Therewereagoodnumberofcommentsaroundtheimplausiblenatureofthe
explanations in the Specific(50) scenario. For example, CAND20 said, ‘The vehicle this time had difficulty giving
the correct reason for stopping/going. Couldn’t tell the difference between a pedestrian and a cyclist sometime or
thoughtthattrafficlightswereoffinsteadofgreen.IfeelthatthistimeIwouldhavewantedmorecontroloverthecar,
particularlyattrafficlightsasIcoulddeterminebetterifatrafficlightwas’working’ornot’.
A couple of candidates thought that the explanations in the Abstract scenarios were either too early or late. For
example,‘Theexplanationsshouldhavearrivedabitearlier,likeafewmetersbeforethevehicleactuallystopssothat
Iwillknowthatitisplanningtostop.Also,Iwouldbemorecomfortableiftheexplanation’trafficsign’was’traffic
lightisred/green’.whenreferringtoatrafficlight.’—CAND19.
Some interesting comments were made about the vehicle’s driving style and its interior. For example, CAND31
madeacommentaboutthecarefulmanoeuvreofthevehicleintheSpecific(50)scenario:‘Iwascalmthroughoutthe
journey.Therewasnofeelingofanxietyasthevehicledidnotspeedtoomuchtomakemefeelthatway.’—CAND31.
There was a comment relating to aggressive manoeuvre in the Abstract scenario: ‘Seemed like oncoming vehicles
weregoingtocollidewithme.Itseemstosometimedriveonpavementswhennegotiatingcorners.’—CAND35.The
rotating steering wheel of the vehicle made some of the participants uncomfortable: ‘The steering wheel moving
abruptlystartledmesometimes.’—CAND21(Specific(5)scenario).Someparticipantslikedthevehicleindicatorsand
the sound they made when indicating the next directions. ‘The indicator sound was nice to hear. [...]’—CAND6
(Specific(50)scenario).
7. GeneralDiscussion
We examined the effects of explanation specificity (abstract and specific) in AD, while accounting for varying
degrees of perception system errors (low and high). We focused on how this setup would impact passengers’
perceived safety and related factors, such as the feeling of anxiety and the thought to takeover control. Our results
notonlycorroboratebutalsoextendpreviousfindingsinthefield,amongothers,demonstratingthatwhileintelligible
explanationsgenerallycreatepositiveexperiencesforAVusers[50,26,56,42],thiseffectispredominantlyobserved
whentheAV’sperceptionsystemerrorsarelow.
7.1. PsychologicalEffects
Hypothesis1.1-Lowtransparencyyieldshigherperceptionofsafety Contrarytoexpectations,participants
expressed a greater sense of safety in the Specific(5) scenario, indicating a preference for specific explanations in
an AV with notably reduced perception system errors. This finding challenges our initial hypothesis and suggests a
morenuancedrelationshipbetweentransparencyandperceivedsafety.Itappearsthatusersmayprefermoredetailed
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 19 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
informationwhenthesystemdemonstrateshighreliability.However,overlydetailedexplanationswereperceivedas
verboseandrepetitivebysomeparticipantsinthespecificscenarios.Therefore,achievingabalancedapproachbetween
explanation specificity (or transparency in general) and the cognitive load imposed on passengers is crucial [52].
This observation underscores the importance of carefully calibrating the level of transparency to optimise user
comprehensionandtrust.
AsobservedfromFigure6,AVscharacterisedbyhightransparencyandhighperceptionsystemerrorsgenerally
elicited lower perceptions of safety among passengers. This result aligns with previous work suggesting that
transparency can sometimes amplify the negative effects of errors on trust in automated systems [14]. In our study,
the combination of detailed explanations and frequent errors may have heightened passengers’ awareness of the
system’s limitations, potentially exacerbating their safety concerns. Nonetheless, qualitative responses revealed that
aminorityofparticipantsreportedpositivesentimentsdespitetheseerrors.Theypraisedthevehicleforitsabilityto
detect obstacles and respond appropriately, suggesting that for these individuals, the AV’s correct decision-making
outweighedconcernsaboutthespecifictypeofobstacleencountered.
Thediversereactionsweobservedhighlightthecomplexnatureofhuman-AVinteractionandunderscoretheneed
for personalised approaches to transparency and explanation design. Adaptive explanation strategies that consider
individualdifferencesininformationprocessingandriskperceptionmaybenecessarytooptimiseuserexperienceand
safetyperceptionsinautonomousvehicles.
Hypothesis1.2-FeelingofAnxietyincreaseswithincreasingperceptionsystemerrors Drivers’anxietyhas
beennotedtoincreasewhenutilisingAVs[35].Inourstudy,weanticipatedthatpassengers’feelingsofanxietywould
correspondinglyincreasewithhigherlevelsofperceptionsystemerrorsinanAV.Thishypothesiswassupportedbya
significantdifferenceinanxietylevelsobservedbetweentheSpecific(5)andSpecific(50)scenarios.Inthecontextof
AVs,perceptionsystemerrorsrepresentacriticalfactorthatcandirectlyimpactpassengersafetyand,consequently,
their psychological state. As the frequency of errors increases, passengers may experience a heightened sense of
uncertaintyandlossofcontrol.Thismightbecontributorstothereportedanxiousfeelings.
Given that participants perceived the highest safety in the Specific(5) scenario (as seen Hypothesis 1.1), we
expectedthelowestlevelsofanxietyinthisscenario,assumingarelationshipbetweenperceivedsafetyandanxiety,
as suggested by prior research [15]. This inverse relationship between perceived safety and anxiety aligns with the
broader psychological concept of risk perception and its impact on emotional states [60, 58]. Our findings extend
beyond the mere confirmation of this relationship, highlighting the nuanced interplay between system transparency,
error frequency, and the feeling of anxiety. The significant difference in anxiety levels between the Specific(5) and
Specific(50)scenariossuggeststhattheremaybeathresholdoferrorfrequencybeyondwhichanxietylevelssharply
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 20 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
increase.Thisnotionissupportedbyresearchinriskperception,whichindicatesthatindividualsoftenhaveanon-linear
responsetoincreasingrisklevels[22].Investigatingthisthresholdisaninterestingtopicforfutureresearch.
WhileDillenetal.,[15]primarilyexaminedhowAVdrivingstylesaffectdriveranxietyandcomfort,theynoted
that certain in-vehicle features, such as a rotating steering wheel, could also influence feelings of anxiety among
participants.Thisexperiencewasreportedbyparticipants(e.g.,CAND21)inourstudy.Thisobservationunderscores
themultifacetednatureofanxietyinAVcontexts,wherebothsystemperformanceandphysicaldesignelementsplay
crucialroles.
Furthermore, our results suggest that the relationship between perception system errors and anxiety may be
moderated by the level of explanation specificity. In scenarios with high transparency (i.e., specific explanations),
the impact of errors on anxiety might be more pronounced, as passengers are more acutely aware of the system’s
limitations.Ontheotherhand,uncertaintyabouttheworkingsofalgorithmsandperceivedlackofcontrolhasbeen
notedtocausewhatresearchersterm‘algorithmicanxiety’[19].ThisisalsoobservedfromourresultinTable6asthe
feelingofAnxietyishigherintheAbstractscenariocomparedtoSpecific(5).
Itisworthnotingthatindividualdifferencesintechnologyacceptanceandrisktolerancemayalsoinfluencethe
anxietyresponsetoperceptionsystemerrors[9].Futureresearchcouldexploretheseindividualfactorstodevelopa
morecomprehensivemodelofanxietyinAVcontexts.
Hypothesis 1.3 - Takeover feeling increases with the increase in perception system error Contrary to
our hypothesis, the data did not support an increase in takeover feeling with increased perception system errors.
While we observed a significant difference between the Abstract and Specific(50) scenarios, the lack of significant
differencebetweenSpecific(5)andSpecific(50)scenariossuggestsacomplexrelationshipbetweensystemerrorsand
userresponses.Thisfindingindicatesthatmeredisclosureofperceptionsystemerrorsdoesnotnecessarilyescalate
passengers’ desire for control, pointing to a possible threshold effect in how passengers perceive and respond to
AV errors. These results challenge the notion that awareness of system imperfections automatically erodes trust in
automation[39],suggestinginsteadthatpassengersmaybemoretolerantofdisclosederrorsthanpreviouslythought,
especiallywithregardstoseizingcontrolinautonomousdriving.
Ourempiricalfindingscontrastwiththeconceptualanalysispresentedby[61],whoadvocatedforsharedcontrol
betweenvehicleanduser.Ourresultssuggestthatusersmightbemorecomfortablewithfullautomationthantheoretical
analyses have predicted, even when aware of system limitations. It is crucial to reconcile these findings with our
previous results showing increased anxiety levels as error rates increased. This apparent contradiction suggests a
complex interplay between emotional responses and behavioural intentions in AV contexts. While passengers may
experienceheightenedanxietyfeelingswhenawareofhighererrorrates,thisemotionalresponsedoesnotnecessarily
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 21 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
translate into a stronger desire to take control of the vehicle. This disconnect between anxiety and takeover feeling
could be attributed to factors such as perception of one’s own ability to manage the situation, cognitive dissonance
betweenacknowledgingrisksandmaintainingcomfortwithautomation[3],ortrustinthesystem’soverallcapability.
Itisimportanttonoteontheotherhandthatourqualitativeresults(Table5)indicatehighernumberofcomments
relatingtotakeoverintentsinSpecific(50)comparedtoSpecific(5).Itmightbethecasethatparticipantsmighthave
struggledtocalibratetheirthoughtsorfeelingsona5-pointLikertscale.Itmightalsobethecasethatthisdifference
infrequencyofthesaidcommentsarestatisticallyinsignificant.Thiswouldbeinvestigatedinfuturework.
7.2. BehaviouralCues
Hypothesis 2.1 - Visual signal correlates with anxiety Our study’s findings challenge the established link
betweenanxietyandvisualdistractionproposedbyHepsomalietal.[28].Wefoundnosignificantcorrelationbetween
fixationpointdivergencesandanxietylevelsacrossthedifferentscenarios.Thissurprisingoutcomemightbeattributed
to the varied individual priorities in visual attention. For instance, while some participants might have focused on
the cityscape, others may have concentrated on areas highlighted by the explanations. The Specific(50) scenario
exhibited higher divergences in fixation points compared to the Specific(5) and Abstract scenarios, possibly due to
misclassifications in explanations directing attention to incorrect elements. However, the Specific(5) and Abstract
scenarios showed similar fixation effects, suggesting that explanations might have been more effective in these
scenariosthanintheSpecific(50)scenario.ContrarytoDillenetal.,[15]’sfindingsontherelationshipbetweeneye
movement entropy and anxiety, our study did not reveal a significant correlation between saccade differences and
anxietylevels.Interestingly,theSpecific(5)scenariodemonstratedthelowestsaccadedifference,potentiallyindicating
reduced distraction or confusion. This assumption is based on the understanding that saccade velocity reflects the
speedofgazeshiftsbetweenfixationpoints.Incontrast,theAbstractscenarioexhibitedthehighestsaccadedifference,
whichcouldbeinterpretedasmoreactivevisualsearchingduetothenon-specificnatureoftheexplanationsfailingto
effectivelyguideparticipants’gaze.
Thesefindingsamplifiestheexistingcomplexitiesintherelationshipbetweenvisualbehaviour,anxiety,andthe
nature of explanations in automated driving scenarios. Further research to better understand the interplay between
cognitivestates,visualattention,andtheeffectivenessofdifferenttypesofexplanationsinautomateddrivingcontexts
isinorder.Additionally,investigatingthepotentialimpactofindividualdifferencesinvisualprocessingandattention
allocation could provide valuable insights into designing more effective and personalised explanation systems for
automatedvehicles.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 22 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
7.3. PracticalImplications
Ourfindingschallengetheinitialassumptionthatpassengersmaynotdesirespecificexplanationsdetailingerror
information from automated vehicles (AVs). Contrary to this presupposition, the study reveals a preference among
passengersforspecificexplanations,particularlywhentheAV’sperceptionsystemdemonstratesnear-perfectaccuracy.
ThisinsighthassignificantimplicationsforbothmanufacturersandregulatorsintheAVindustry.Theobservedinverse
relationshipbetweenperceptionsystemerrorsandpassengeranxietyunderscoresthecriticalneedforhighlytransparent
AVs with exceptional perception and decision-making capabilities. This finding aligns with the broader literature
on trust in automation, which emphasises the importance of system reliability and transparency in fostering user
acceptance[39].Manufacturersshouldprioritisethedevelopmentofrobustperceptionsystemsthatminimiseerrors,
while simultaneously implementing transparent communication mechanisms to convey system status and decision-
makingprocessestopassengers.Regulators,inturn,shouldconsiderestablishingorstrengtheningexistingstandards
forAVperceptionaccuracyandmandatingclearandusableinterfacesforconveyingthisinformationtopassengers.
While our study did not observe direct consequences of misclassification errors on AV actions, it is crucial to
recognisethepotentialramificationsofsucherrorsinmorecomplex,real-worldscenarios.Theaccurateclassification
ofobstacletypesisparamountindeterminingappropriatevehicleresponses,particularlywhendealingwithdynamic
obstaclespossessingvariedmanoeuvrabilitycharacteristics.Thisalignswithresearcheffortsonsituationawareness
inautomatedsystems,whichemphasisestheimportanceofaccurateenvironmentalperceptionforeffectivedecision-
making [20]. In intricate traffic scenarios, even minor perceptual inaccuracies could lead to sub-optimal navigation
decisions, potentiallycompromising safety. Therefore,AV developersmust strive forhighly accurateenvironmental
estimationstoensureappropriateresponsestodiverseobstacletypes,suchasbicyclesormotorcycles,withverysimilar
attributesbutdifferingcapabilities.
Thestudy’sfindingshighlightsthelinkbetweentransparencyandaccuracyinAVsystems.Thisrelationshipechoes
theconceptof‘calibratedtrust’inautomation,whereusertrustisappropriatelyalignedwithsystemcapabilities[39].
To foster this calibrated trust, AV interfaces should not only provide accurate information but also communicate
thesystem’sconfidencelevelsandpotentiallimitations.Thisapproachcanhelpmanagepassengerexpectationsand
maintainappropriatelevelsofsituationalawareness.
Whilevisualfeedbackfromexperimentalstudiesprovidesvaluableinsightsintoparticipants’psychologicaland
behaviouralresponses,itisusefultosimultaneouslyimplementmultiplemethodologies(e.g.,mixedmethods)formore
accurate conclusions. Complementing observational data with other measurement techniques, such as standardised
surveys,physiologicalmeasurements,orqualitativeinterviews,canprovideamorecomprehensiveunderstandingof
user experiences and perceptions. This multi-faceted approach allows for triangulation of data and more confident
interpretationsofcomplexhuman-machineinteractions.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 23 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Futureresearchshouldexplorethelong-termeffectsofexposuretoAVexplanationsonpassengertrust,anxiety,
and overall acceptance. Longitudinal studies could reveal how user preferences and responses evolve over time,
informingthedesignofadaptiveexplanationsystemsthatcatertochanginguserneedsandexpectations.Additionally,
investigating the impact of cultural differences and individual variability in risk perception on AV explanation
preferencescouldyieldinsightsfordevelopinggloballyapplicable,yetlocallytailored,AVcommunicationstrategies.
In conclusion, these findings have far-reaching implications for AV design, regulation, and user experience. By
prioritising both transparency and accuracy, and adopting a holistic approach to user research, the AV industry can
work towards creating systems that not only meet technical performance standards but also address the complex
psychologicalneedsoftheirusers,therebyavoidingthetransparencyparadoxandultimatelyfosteringgreaterpublic
acceptanceandtrustinautomatedtransportationtechnologies.
8. Conclusion
In this study, we conducted a rigorous within-subject laboratory investigation (𝑁 = 39) utilising an immersive
driving simulator to examine passengers’ preferences for explanation specificity levels and the impact of varying
perceptionsystemerrorsonperceivedsafety,andrelatedconstructsinautonomousvehicles(AVs).Ourfindingsreveal
a link between explanation specificity, perception system errors, and passenger anxiety, contributing to the growing
bodyofliteratureontrustcalibrationandtransparencyinautomatedvehicles.Weobservedasignificantincreasein
anxietylevelswhenfine-grained,intelligibleexplanationsexposedperceptionsystemerrors.Interestingly,passengers
preferredhighlydetailed(orspecific)explanationswhenAVperceptionsystemerrorswerelow,despitethepotential
for vague explanations to conceal such errors. Hence, as desirable as transparency is, the more we have it beyond
certain thresholds, the more anxious we might be. We refer to this phenomenon as the transparency paradox in the
context of this paper. While our study provides valuable insights, we acknowledge its limitations, particularly, the
absenceofexplanationpersonalisation,andtheinabilitytoselectanAVdrivingstyle.Futureresearchshouldaddress
theselimitationsbyinvestigatingtheimplicationsofprovidingpassengerswithpersonalisationoptions,drawingupon
theoriesofuser-centreddesignandadaptiveinterfaces.Additionally,longitudinalstudiesandexplorationofindividual
differencescouldyieldvaluableinformationfortailoringAVexplanationstodiverseuserpopulations.Ourfindings
havesignificantimplicationsforAVexplanationinterfacedesign,emphasisingtheneedforadaptive,context-sensitive
explanationsystemsthatbalancetransparencywithusercomfort,ultimatelyfosteringgreaterpublicacceptanceand
trustinautonomoustransportationsystems.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 24 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
CRediTauthorshipcontributionstatement
Daniel Omeiza: Conceptualisation of idea, writing and editing the original draft, software implementation, lab
experiment, data collection, data analysis. Raunak Bhattacharyya: Writing and editing, review, data collection,
lab experiment. Marina Jirotka: Conceptualisation, bi-weekly supervision and guidance, resources. Nick Hawes:
Supervision, provision of resources. Lars Kunze: Conceptualisation of idea, weekly supervision, and guidance,
resourcesprovision,review.
Acknowledgements
ThisworkwassupportedbytheEPSRCRAILSproject(grantreference:EP/W011344/1)andtheEPSRCproject
RoboTIPS(grantreference:EP/S005099/1).
References
[1] Adadi,A.,Berrada,M.,2018.Peekinginsidetheblack-box:asurveyonexplainableartificialintelligence(XAI).IEEEAccess6,52138–52160.
[2] Anjomshoae,S.,Omeiza,D.,Jiang,L.,2021.Context-basedimageexplanationsfordeepneuralnetworks.ImageandVisionComputing116,
104310.
[3] Aronson,E.,1969. Thetheoryofcognitivedissonance:Acurrentperspective,in:Advancesinexperimentalsocialpsychology.Elsevier.
volume4,pp.1–34.
[4] BinIssa,R.,Das,M.,Rahman,M.S.,Barua,M.,Rhaman,M.K.,Ripon,K.S.N.,Alam,M.G.R.,2021. DoubledeepQ-learningandfaster
R-Cnn-basedautonomousvehiclenavigationandobstacleavoidanceindynamicenvironment.Sensors21,1468.
[5] Board,N.T.S.,2018.Collisionbetweenasportutilityvehicleoperatingwithpartialdrivingautomationandacrashattenuatormountainview,
california.URL:https://www.ntsb.gov/investigations/AccidentReports/Reports/HAR2001.pdf.Accessed:Oct.30,2020.
[6] Buijsman,S.,2022.DefiningexplanationandexplanatorydepthinXAI.MindsandMachines32,563–584.
[7] Chakraborti,T.,Sreedharan,S.,Kambhampati,S.,2020.TheEmergingLandscapeofExplainableAutomatedPlanning&DecisionMaking,
in:Bessiere,C.(Ed.),ProceedingsoftheTwenty-NinthInternationalJointConferenceonArtificialIntelligence,IJCAI-20,InternationalJoint
ConferencesonArtificialIntelligenceOrganization.pp.4803–4811.
[8] Chen,N.T.,Clarke,P.J.,Watson,T.L.,Macleod,C.,Guastella,A.J.,2014. Biasedsaccadicresponsestoemotionalstimuliinanxiety:An
antisaccadestudy.PloSOne9,e86474.
[9] Choi,J.K.,Ji,Y.G.,2015.Investigatingtheimportanceoftrustonadoptinganautonomousvehicle.InternationalJournalofHuman-Computer
Interaction31,692–702.
[10] Colley,M.,Bräuner,C.,Lanzer,M.,Walch,M.,Baumann,M.,Rukzio,E.,2020.EffectofVisualizationofPedestrianIntentionRecognition
onTrustandCognitiveLoad,in:12thInternationalConferenceonAutomotiveUserInterfacesandInteractiveVehicularApplications,pp.
181–191.
[11] Colley,M.,Eder,B.,Rixen,J.O.,Rukzio,E.,2021. EffectsofSemanticSegmentationVisualizationonTrust,SituationAwareness,and
CognitiveLoadinHighlyAutomatedVehicles,in:Proceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems,pp.
1–11.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 25 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
[12] Colley,M.,Rädler,M.,Glimmann,J.,Rukzio,E.,2022.EffectsofSceneDetection,ScenePrediction,andManeuverPlanningVisualizations
onTrust,SituationAwareness,andCognitiveLoadinHighlyAutomatedVehicles.ProceedingsoftheACMonInteractive,Mobile,Wearable
andUbiquitousTechnologies6,1–21.
[13] Davidson,M.M.,Butchko,M.S.,Robbins,K.,Sherd,L.W.,Gervais,S.J.,2016. Themediatingroleofperceivedsafetyonstreetharassment
andanxiety.PsychologyofViolence6,553.
[14] DeVisser,E.J.,Pak,R.,Shaw,T.H.,2018. From‘automation’to‘autonomy’:theimportanceoftrustrepairinhuman–machineinteraction.
Ergonomics61,1409–1427.
[15] Dillen,N.,Ilievski,M.,Law,E.,Nacke,L.E.,Czarnecki,K.,Schneider,O.,2020. Keepcalmandridealong:Passengercomfortandanxiety
asphysiologicalresponsestoautonomousdrivingstyles,in:Proceedingsofthe2020CHIconferenceonhumanfactorsincomputingsystems,
pp.1–13.
[16] Došilović,F.K.,Brčić,M.,Hlupić,N.,2018.Explainableartificialintelligence:Asurvey,in:201841stInternationalConventiononInformation
andCommunicationTechnology,ElectronicsandMicroelectronics(MIPRO).
[17] Dosovitskiy,A.,Ros,G.,Codevilla,F.,Lopez,A.,Koltun,V.,2017. CARLA:Anopenurbandrivingsimulator,in:ConferenceonRobot
Learning.
[18] Eiband,M.,Buschek,D.,Kremer,A.,Hussmann,H.,2019a.Theimpactofplacebicexplanationsontrustinintelligentsystems,in:Extended
abstractsofthe2019CHIconferenceonhumanfactorsincomputingsystems,pp.1–6.
[19] Eiband,M.,Völkel,S.T.,Buschek,D.,Cook,S.,Hussmann,H.,2019b. Whenpeopleandalgorithmsmeet:User-reportedproblemsin
intelligenteverydayapplications,in:Proceedingsofthe24thinternationalconferenceonintelligentuserinterfaces,pp.96–106.
[20] Endsley,M.R.,1995.Towardatheoryofsituationawarenessindynamicsystems.Humanfactors37,32–64.
[21] Endsley,M.R.,2000.Situationmodels:Anavenuetothemodelingofmentalmodels,in:ProceedingsoftheHumanFactorsandErgonomics
SocietyAnnualMeeting,SAGEPublicationsSageCA:LosAngeles,CA.pp.61–64.
[22] Fischhoff,B.,Bostrom,A.,Quadrel,M.J.,etal.,1993.Riskperceptionandcommunication.Annualreviewofpublichealth14,183–203.
[23] Gibaldi,A.,Sabatini,S.P.,2021. Thesaccademainsequencerevised:Afastandrepeatabletoolforoculomotoranalysis. BehaviorResearch
Methods53,167–187.
[24] Guidotti,R.,Monreale,A.,Ruggieri,S.,Turini,F.,Giannotti,F.,Pedreschi,D.,2018.Asurveyofmethodsforexplainingblackboxmodels.
ACMcomputingsurveys(CSUR)51,1–42.
[25] Gunning,D.,2017.ExplainableArtificialIntelligence(XAI).DefenseAdvancedResearchProjectsAgency(DARPA),ndWeb2,1.
[26] Ha,T.,Kim,S.,Seo,D.,Lee,S.,2020. Effectsofexplanationtypesandperceivedriskontrustinautonomousvehicles. Transportation
ResearchPartF:TrafficPsychologyandBehaviour73,271–280.
[27] Hart,W.,Albarracín,D.,Eagly,A.H.,Brechan,I.,Lindberg,M.J.,Merrill,L.,2009. Feelingvalidatedversusbeingcorrect:ameta-analysis
ofselectiveexposuretoinformation.PsychologicalBulletin135,555.
[28] Hepsomali,P.,Hadwin,J.A.,Liversedge,S.P.,Garner,M.,2017. Pupillometricandsaccadicmeasuresofaffectiveandexecutiveprocessing
inanxiety.BiologicalPsychology127,173–179.
[29] Hewitt,C.,Politis,I.,Amanatidis,T.,Sarkar,A.,2019.Assessingpublicperceptionofself-drivingcars:Theautonomousvehicleacceptance
model,in:Proceedingsofthe24thInternationalConferenceonIntelligentUserInterfaces.
[30] Hoffman,R.R.,Klein,G.,2017.Explainingexplanation,part1:Theoreticalfoundations.IEEEIntelligentSystems32,68–73.
[31] Information Commissioner’s Office, . What goes into an explanation? URL: https://ico.org.uk/for-organisations/
guide-to-data-protection/key-dp-themes/explaining-decisions-made-with-artificial-intelligence/
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 26 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
part-1-the-basics-of-explaining-ai/what-goes-into-an-explanation/.Accessed:Jul,2021.
[32] Khastgir,S.,Birrell,S.,Dhadyalla,G.,Jennings,P.,2018. Calibratingtrustthroughknowledge:Introducingtheconceptofinformedsafety
forautomationinvehicles.TransportationResearchPartC:EmergingTechnologies96,290–303.
[33] Kment,B.,2006.Counterfactualsandexplanation.Mind115,261–310.
[34] Koo,J.,Kwac,J.,Ju,W.,Steinert,M.,Leifer,L.,Nass,C.,2015.Whydidmycarjustdothat?Explainingsemi-autonomousdrivingactionsto
improvedriverunderstanding,trust,andperformance.InternationalJournalonInteractiveDesignandManufacturing(IJIDeM)9,269–275.
[35] Koo,J.,Shin,D.,Steinert,M.,Leifer,L.,2016. Understandingdriverresponsestovoicealertsofautonomouscaroperations. International
journalofvehicledesign70,377–392.
[36] Kunze,A.,Summerskill,S.J.,Marshall,R.,Filtness,A.J.,2019a.AutomationTransparency:ImplicationsofUncertaintyCommunicationfor
Human-AutomationInteractionandInterfaces.Ergonomics62,345–360.
[37] Kunze, A., Summerskill, S.J., Marshall, R., Filtness, A.J., 2019b. Conveying Uncertainties using Peripheral Awareness Displays in the
ContextofAutomatedDriving,in:Proceedingsofthe11thInternationalConferenceonAutomotiveUserInterfacesandInteractiveVehicular
Applications,pp.329–341.
[38] Lavrinc, D., 2016. This is how bad self-driving cars suck in rain. URL: https://www.wired.com/2016/02/
googles-self-driving-car-may-caused-first-crash/.Accessed:Jul.,2020.
[39] Lee,J.D.,See,K.A.,2004.Trustinautomation:Designingforappropriatereliance.Humanfactors46,50–80.
[40] Liu,H.,Hirayama,T.,Watanabe,M.,2021. Importanceofinstructionforpedestrian-automateddrivingvehicleinteractionwithanexternal
humanmachineinterface:Effectsonpedestrians’situationawareness,trust,perceivedrisksanddecisionmaking,in:2021IEEEIntelligent
VehiclesSymposium(IV),pp.748–754.
[41] Lundberg,S.M.,Lee,S.I.,2017. Aunifiedapproachtointerpretingmodelpredictions,in:Proceedingsofthe31stInternationalConference
onNeuralInformationProcessingSystems.
[42] M.Faas,S.,Kraus,J.,Schoenhals,A.,Baumann,M.,2021.CalibratingPedestrians’TrustinAutomatedVehicles:DoesanIntentDisplayin
anExternalHMISupportTrustCalibrationandSafeCrossingBehavior?,in:Proceedingsofthe2021CHIConferenceonHumanFactorsin
ComputingSystems.
[43] Magnaguagno,M.C.,FragaPereira,R.,Móre,M.D.,Meneguzzi,F.R.,2017.Webplanner:Atooltodevelopclassicalplanningdomainsand
visualizeheuristicstate-spacesearch,in:2017WorkshoponUserInterfacesandSchedulingandPlanning(UISP@ICAPS).
[44] McFarland,M.,2016.Who’sresponsiblewhenanautonomouscarcrashes?URL:https://money.cnn.com/2016/07/07/technology/
tesla-liabilityrisk/index.html.Accessed:Jul.24,2020.
[45] Michael,M.,Schlipsing,M.,2015. Extendingtrafficlightrecognition:Efficientclassificationofphaseandpictogram,in:2015International
JointConferenceonNeuralNetworks(IJCNN).
[46] Miller,T.,2019.Explanationinartificialintelligence:Insightsfromthesocialsciences.ArtificialIntelligence267,1–38.
[47] Mittelstadt,B.,Russell,C.,Wachter,S.,2019. ExplainingexplanationsinAI,in:Proceedingsoftheconferenceonfairness,accountability,
andtransparency.
[48] Omeiza,D.,Anjomshoae,S.,Webb,H.,Jirotka,M.,Kunze,L.,2022a. Fromspokenthoughtstoautomateddrivingcommentary:Predicting
andexplainingintelligentvehicles’actions,in:2022IEEEIntelligentVehiclesSymposium(IV).
[49] Omeiza, D., Kollnig, K., Webb, H., Jirotka, M., Kunze, L., 2021a. Why not explain? effects of explanations on human perceptions of
autonomousdriving,in:IEEEInternationalConferenceonAdvancedRoboticsanditsSocialImpacts.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 27 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
[50] Omeiza,D.,Web,H.,Jirotka,M.,Kunze,L.,2021b. Towardsaccountability:Providingintelligibleexplanationsinautonomousdriving,in:
2021IEEEIntelligentVehiclesSymposium(IV).
[51] Omeiza,D.,Webb,H.,Jirotka,M.,Kunze,L.,2022b. Explanationsinautonomousdriving:Asurvey. IEEETransactionsonIntelligent
TransportationSystems23,10142–10162.doi:10.1109/TITS.2021.3122865.
[52] Poursabzi-Sangdeh,F.,Goldstein,D.G.,Hofman,J.M.,WortmanVaughan,J.W.,Wallach,H.,2021. Manipulatingandmeasuringmodel
interpretability,in:ProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems.
[53] Quansah,F.,HaganJr,J.E.,Sambah,F.,Frimpong,J.B.,Ankomah,F.,Srem-Sai,M.,Seibu,M.,Abieraba,R.S.K.,Schack,T.,2022.Perceived
safetyoflearningenvironmentandassociatedanxietyfactorsduringCOVID-19inGhana:Evidencefromphysicaleducationpractical-oriented
program.EuropeanJournalofInvestigationinHealth,PsychologyandEducation12,28–41.
[54] Raab,E.L.,1985.Normalsaccadicvelocities.JournalofPediatricOphthalmology&Strabismus22,20–22.
[55] Ribeiro,M.T.,Singh,S.,Guestrin,C.,2016. "WhyshouldItrustyou?"Explainingthepredictionsofanyclassifier,in:Proceedingsofthe
22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining.
[56] Schneider,T.,Hois,J.,Rosenstein,A.,Ghellal,S.,Theofanou-Fülbier,D.,Gerlicher,A.R.,2021. Explainyourself!transparencyforpositive
uxinautonomousdriving,in:ProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems.
[57] Silvera,G.,Biswas,A.,Admoni,H.,2022. DReyeVR:DemocratizingVirtualRealityDrivingSimulationforBehavioural&Interaction
Research,in:ACM/IEEEHumanRobotInteractionConference.
[58] Slovic,P.,2010.Thefeelingofrisk,.earthscan.
[59] Stanton,N.A.,Salmon,P.M.,Walker,G.H.,Stanton,M.,2019. Modelsandmethodsforcollisionanalysis:acomparisonstudybasedonthe
ubercollisionwithapedestrian.SafetyScience120,117–128.
[60] Stapel,J.,Gentner,A.,Happee,R.,2022. On-roadtrustandperceivedriskinLevel2automation. TransportationresearchpartF:traffic
psychologyandbehaviour89,355–370.
[61] Terken,J.,Pfleging,B.,2020.Towardsharedcontrolbetweenautomatedvehiclesandusers.AutomotiveInnovation3,53–61.
[62] Tilley,A.,2016. Google’sself-drivingcarcauseditsfirstcrash. URL:https://www.forbes.com/sites/aarontilley/2016/02/29/
googles-self-driving-car-caused-its-first-accident/?sh=5ae097b0538d.Accessed:Jun.21,2021.
[63] Voigt,P.,VondemBussche,A.,2017. TheEUGeneralDataProtectionRegulation(GDPR). APracticalGuide,1stEd.,Cham:Springer
InternationalPublishing.
[64] Wang,D.,Yang,Q.,Abdul,A.,Lim,B.Y.,2019.Designingtheory-drivenuser-centricexplainableAI,in:ProceedingsoftheCHIConference
onHumanFactorsinComputingSystems.
[65] Wilson,S.J.,Glue,P.,Ball,D.,Nutt,D.J.,1993.Saccadiceyemovementparametersinnormalsubjects.ElectroencephalographyandClinical
Neurophysiology86,69–74.
[66] Zhu,J.,Liapis,A.,Risi,S.,Bidarra,R.,Youngblood,G.M.,2018. ExplainableAIfordesigners:Ahuman-centeredperspectiveonmixed-
initiativeco-creation,in:IEEEConferenceonComputationalIntelligenceandGames(CIG).
A. OnlineSurveyQuestionnaire
Notethatthesamequestionnairewasadministeredinallscenarios.
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 28 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Explainable Autonomous Driving 1
Page 1
Can you please carefully read and respond to the questions? Your responses are valuable to
our research. Thank you!
Can you please evaluate the following statements based on your experience from the just
concluded driving exercise?  Required
Please don't select more than 1 answer(s) per row.
Please select at least 3 answer(s).
Neither
Strongly Somewhat Agree Somewhat Strongly
Disagree Agree
Disagree Disagree Nor Agree Agree
Disagree
I would have
concerns
about using
the vehicle.
The vehicle
would be
somewhat
frightening to
me.
I am afraid
that I would
not
understand
the vehicle.
1 / 4
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 29 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Can you please evaluate the following statements based on your experience from the just
concluded driving exercise?  Required
Please don't select more than 1 answer(s) per row.
Please select at least 3 answer(s).
Neither
Strongly Somewhat Agree Somewhat Strongly
Disagree Agree
Disagree Disagree Nor Agree Agree
Disagree
I believe that
using the
vehicle
would be
dangerous.
I would feel
safe while
using the
vehicle.
I would trust
the vehicle.
Can you please evaluate the following statements based on your experience from the just
concluded driving exercise?  Required
Please don't select more than 1 answer(s) per row.
Please select at least 1 answer(s).
Neither
Strongly Somewhat Agree Somewhat Strongly
Disagree Agree
Disagree Disagree Nor Agree Agree
Disagree
During the
ride, I had the
feeling to
take over
control from
the vehicle.
2 / 4
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 30 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
What is your thought on the explanations provided by the vehicle, e.g., made you less/more
anxious, safe, feeling to take over control?
3 / 4
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 31 of 28A Transparency Paradox? Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies
Page 2: Final page
Thank you for completing this survey!
4 / 4
D. Omeiza et al.: PreprintsubmittedtoElsevier Page 32 of 28