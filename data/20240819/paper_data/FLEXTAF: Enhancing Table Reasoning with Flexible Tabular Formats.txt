FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats
XuanliangZhang1,DingziruiWang1,LongxuDou1,BaoxinWang2,
DayongWu2,QingfuZhu1,WanxiangChe1
1HarbinInstituteofTechnology2iFLYTEKResearch
{xuanliangzhang,dzrwang,lxdou,qfzhu,car}@ir.hit.edu.cn,
{bxwang2,dywu2}@iflytek.com
Abstract (a) Input Information
Question What is the first player name?
Thetablereasoningtaskaimstoanswerthequestionaccording
tothegiventable.Currently,usingLargeLanguageModels List Database
[ CREATE TABLE information (Name
(LLMs)isthepredominantmethodfortablereasoning.Most
[“Name”, “Nation”, …] text, Nation text, …);
existingmethodsemployafixedtabularformattorepresent [“Liv”, “U.S.A.”, …] /*
… values in columns: Name: Liv…; …
thetable,whichcouldlimittheperformance.Giventhateach ] */
instance requires different capabilities and models possess
varyingabilities,weassertthatdifferentinstancesandmodels Reason with List Reason with Database
def solver (table): SELECT Name FROM information
suitdifferenttabularformats.Weprovetheaforementioned
for row in table[1:]: … ORDER BY Name LIMIT 1;
claimthroughquantitativeanalysisofexperimentalresults, Answer is Liv Answer is Ava
wheredifferentinstancesandmodelsachievedifferentper-
formances using various tabular formats. Building on this (b) Input Information
discussion,weproposeFLEXTAF-SingleandFLEXTAF-Vote
Question What is the area of the stadium named Bin?
toenhancetablereasoningperformancebyemployingflexi-
bletabularformats.Specifically,(i)FLEXTAF-Singletrains List Database
[ CREATE TABLE information (…,
aclassifiertopredictthemostsuitabletabularformatbased […, , “Stadium”, “Area”, …], Stadium text, Area int, …);
ontheinstanceandtheLLM.(ii)FLEXTAF-Voteintegrates […, “Bin”, “340”, …], /*
… values in columns: …Stadium: Bin… theresultsacrossdifferentformats.OurexperimentsonWik- ] */
iTableQuestionsandTabFactrevealsignificantimprovements,
withaveragegainsof2.3%and4.8%comparedtothebest Reason with List Reason with Database
def solver (table): SELECT Area FROM information
performanceachievedusingafixedtabularformatwithgreedy
… return table[i][7] WHERE Stadium = ‘Bin’;
decodingandself-consistencydecoding,therebyvalidating Answer is Bin Answer is 340
theeffectivenessofourmethods1.
Figure1:Thetablereasoningperformancevarieswithdiffer-
enttabularformats.TheListformatisconvenientforsequen-
1 Introduction
tialindexing,whiletheDatabaseformatfacilitatesthesearch
Tablereasoningisacrucialtaskinnaturallanguageprocess- forcolumnsthatmeetspecificconditions.
ingthataimstoautomaticallyextractandinferinformation
fromtables(Dongetal.2022).Inthistask,amodelneedsto
answerquestionsbasedontheinformationcontainedinthe
tasksbypromptingtheLLMtoiterativelyreasonwithnatural
table,witheachquestion-tablepairreferredtoasaninstance.
languageandprograms.Whiletheabovemethodsprovide
Giventhesuperiorcommonsenseandlogicalreasoningca-
a fixed tabular format in their prompts, Sui et al. (2024);
pabilities of Large Language Models (LLMs), researchers
Singha et al. (2023); Deng et al. (2024) argue that differ-
increasinglyutilizethemfortablereasoning,whichhasbe-
enttablereasoningtaskshavedifferentmostsuitabletabular
comethemainstreammethod(Chen2023;Zhangetal.2024c;
formats.However,existingworksprimarilyanalyzefrom
DongandWang2024).Therefore,wefocusonhowtosolve
the task aspect without considering that solving different
thetablereasoningtaskwithLLMsinthispaper.
instancesdemandsdistinctreasoningskills(Shietal.2020;
Somepreviousworksenhancethetablereasoningperfor-
Chenetal.2023;Chengetal.2023;Liu,Wang,andChen
mance by designing prompts (Cheng et al. 2023; Ye et al.
2024;Chenetal.2024b).Forexample,asshowninFigure1,
2023;Zhangetal.2024e;Leeetal.2024),suchasChain-
solving instance (a) involves reasoning with sequential in-
of-Table (Wang et al. 2024), which solves table reasoning
dexing,whichisfacilitatedbytheListformat.Incontrast,
solving instance (b) requires identifying columns that sat-
Copyright©2025,AssociationfortheAdvancementofArtificial
Intelligence(www.aaai.org).Allrightsreserved. isfyspecificconditions,makingtheDatabaseformatmore
1Ourcodeandpromptsareavailableathttps://github.com/zhxlia/ suitable. Therefore, using a fixed tabular format for all in-
FLEXTAF. stancescouldlimitperformance.Additionally,modelsvary
4202
guA
61
]LC.sc[
1v14880.8042:viXraintheirreasoningcapabilities(Caoetal.2023;Bhandarietal. formatsforeachinstanceaccordingly.Additionally,thecapa-
2024;Zhangetal.2024a),thereforethemostsuitabletabular bilitiesofdifferentmodelsvary(Caoetal.2023;Bhandari
formatcoulddifferforeachmodel. etal.2024;Zhangetal.2024a),resultingindifferenttabular
Basedontheabovediscussion,wefocusontheimpactof formatssuitablefordifferentLLMs.Wefurtherdiscussfrom
tabularformatsonthetablereasoningperformanceofLLMs theperspectiveofexperimentalresultsinthissection.
fromthefollowingtwoaspects.(i)Weclaimthatdifferent Weselectfivepopularformats,includingMarkdown,Dict,
instancesanddifferentLLMsrequiredistinctmostsuitable List,Pandas,andDatabaseformats,followingpreviousworks
tabularformats2.(ii)Weproposetoenhancethetablerea- (Singhaetal.2023;Chengetal.2023;Wangetal.2024;Liu,
soningperformancebypredictingthemostsuitableformat Wang,andChen2024).Detaileddescriptionsoftheseformats
orassemblingtheresultsfrommultipletabularformats. are provided in the supplementary material. Subsequently,
First of all, we discuss that distinct tabular formats are wequantitativelyanalyzehowtabularformataffectsthetable
suitablefordifferentinstancesandLLMs.Weconductex- reasoning performance of LLMs from the aspects of the
ploratoryexperimentsutilizingdifferenttabularformatsand instanceandthemodelrespectively.
LLMsontablereasoningdatasets.Theexperimentalresults
presentthattablereasoningperformancevariessignificantly 2.1 TheRelationshipbetweenInstanceand
withdifferentformatsandLLMs.Basedontheaboveanaly- TabularFormat
sis,weproposeFLEXTAF,whichincludesFLEXTAF-Single Wefirstclaimthatdifferentinstancessuitdifferenttabular
andFLEXTAF-Vote,toenhancetablereasoningperformance formats.Table4presentsthepercentageofinstancesthatcan
throughflexibletabularformats.FLEXTAF-Singleidentifies onlybecorrectlyresolvedbyeachtabularformat.Itcanbe
themostsuitabletabularformatbasedontheinstanceandthe observedthat,withthesamefixedLLM,eachtabularformat
LLMbytrainingtheclassifier.FLEXTAF-Votedetermines is uniquely suited to certain instances, with some formats
thefinalanswerbyvotingonresultsobtainedfrommultiple correctlysolvingover20%oftheinstancesexclusively.The
formats.Incomparison,althoughFLEXTAF-Singlerequires results indicate that, for a given LLM, the most suitable
trainingdatabutonlyinfersonce,FLEXTAF-Voteistraining- tabularformatsvaryaccordingtothespecificinstances.
freebutwithexpensiveinferencecosts.
Todemonstratetheeffectivenessofourmethods,wecon- 2.2 TheRelationshipbetweenModelandTabular
ductexperimentsontwomainstreamtablereasoningdatasets: Format
WikiTableQuestions (Pasupat and Liang 2015) and Tab-
Inthissubsection,wediscussthatdifferentmodelssuitdif-
Fact(Chenetal.2020).Comparedtothebestperformances
ferenttabularformats.Table2demonstratesthatthemost
achievedbyusingafixedformatwithgreedydecodingand
suitable tabular format varies across models and the per-
self-consistency decoding (Wang et al. 2023), FLEXTAF-
formancegaparisesduetodifferentformats.Forinstance,
SingleandFLEXTAF-Voteshowaverageimprovementsof
Llama3(Meta2024)exhibitssignificantlybetterperformance
2.3%and4.8%respectivelywithcomparableinferencecosts,
withtheMarkdownformatcomparedtootherformats,while
confirmingtheeffectivenessofourmethods.Furtheranalysis
DeepSeek-Coder(Guoetal.2024)performsbetterwithDict
experimentsrevealthatsomeinstancescanonlybecorrectly
and Database formats than with Markdown. We employ a
solvedusingaspecificformat,provingthatthemostsuitable
Chi-squaretesttodemonstratesignificantdifferencesinthe
tabularformatsfordifferentinstancesaredistinct.
distributionofthemostsuitabletabularformatsacrossdiffer-
Ourcontributionsareasfollows:
entmodels,asdetailedinthesupplementarymaterial.
1. Weclaimthatthemostsuitabletabularformatsfordiffer-
entinstancesandLLMsaredistinct. 3 Methodology
2. WeproposeFLEXTAF,whichincludesFLEXTAF-Single In this section, we introduce FLEXTAF, which consists
and FLEXTAF-Vote,toenhancetablereasoningperfor- ofFLEXTAF-SingleandFLEXTAF-Vote.Theoverviewof
mancebyutilizingflexibletabularformats. FLEXTAFisshowninFigure2.
3. OurexperimentalresultsindicatethatFLEXTAF-Single
3.1 TaskDefinition
and FLEXTAF-Vote achieve average improvements of
2.3% and 4.8% respectively, over the best results ob- FLEXTAF focuses on the table reasoning task, which can
tained using fixed formats with greedy decoding and be formally defined as follows: Given an instance I com-
self-consistencydecodingatcomparableinferencecosts, prising a natural language question Q and a table T, the
demonstratingtheeffectivenessofourmethods. table reasoning task aims to derive the corresponding an-
swer Aˆ = M(F(T),Q), where M represents the model and
2 DiscussiononImpactofTabularFormats Fdenotesthetabularformat.Toeffectivelysolvethetable
reasoningtask,theprobabilitythatthegeneratedanswerAˆ
Wefirstclaimthatthemostsuitabletabularformatsfordiffer-
matchesthegoldanswerA∗shouldbemaximized.
entinstancesandLLMsaredistinct.Sinceresolvingdifferent
instancesrequiresdiverseabilities(Chenetal.2023;Cheng
3.2 FLEXTAF-Single
etal.2023;Chenetal.2024b),itisnecessarytotailortabular
As discussed in §2, it is essential to determine the most
2Werefertothesuitabletabularformatastheonethatenables suitable tabular format, so FLEXTAF-Single achieves this
themodeltocorrectlysolveagiveninstance. bytrainingaclassifiertoidentifythemostsuitableformat.Input Information FLEXTAF-Single
Question Dict Answer
how many cities have an area [ {“#”: 1, ...}, {“#”: 2, ...}, …] 1
of more than 1000?
Classification Reasoning
Database
CRPEaAnTdEa sTABLE FLEXTAF-Vote
i / *n * /nfop cu ]r
o
,d mm l[.L [ ]u"D :a 1 i
m
sat [ [D [ ]"…i “
“
t ,t no #
1
a i M snc
{
{” ”M
| |
|F
: "
",
,
t
# - 1=
l(
#
#r "a -“ “na ] -N
M" "|
|r [, |u
:
:m "k
: N
Ma l"-m
"
"”de
-,1
2m
,a -
l]; o(
"" "-,m
[ e
", ,-
w
} }]-
”
), ,e
-,n -] ||,
| : 6A -- ,r - 0e -- 9a - 4- - | |
| Reasoning
D 0P 0a
L
1ata
D
1in sb
M
1d ita
c
a a✓s ts re
✓
k× ×
down ✓
Vote
A 1nswer
| 2 | Am | 359 |
Figure2:TheoverviewofFLEXTAF.FLEXTAF-Singleconsistsoftwosteps:(i)Classification:Aclassifierwetrainedpredicts
themostsuitabletabularformatbasedonthegiveninstanceandmodel.(ii)Reasoning:Usingthepredictedformat,theLLM
solvestheinstancebyrepresentingthetableaccordingly.FLEXTAF-Voteconsistsoftwosteps:(i)Reasoning:Variousformats
areemployedtorepresentthetableandfacilitatereasoningwiththeLLM,resultinginmultipleanswers.(ii)Vote:Thefinal
answerisdeterminedusingavotingmechanism.
Classification Classificationaimstopredictthemostsuit- thepredictedscoresofallformatsandselecttheformatwith
abletabularformatfromasetofcandidateformatsbasedon thehighestprobabilityasourclassificationresultFˆ.
theinstanceandthemodel.Itcanbeformallyexpressedas
Fˆ =CLS (I),Fˆ ∈F∗ ={F|M(F(T),Q)=A∗}. Reasoning Afterpredictingthemostsuitabletableformat
M M,I Fˆ,weutilizethepredictedformatfortablereasoning.Specif-
TrainingDataCollection Totraintheclassifiertopredict ically,werepresentthetablewiththepredictedformatFˆin
themostsuitabletabularformatforthegiveninstanceI and thepromptandemploytheLLMtoderivethefinalanswer.
theLLMM,weannotatethetrainingdatawithM.Specifically,
for each instance in the training set, we utilize all candi- 3.3 FLEXTAF-Vote
datetabularformatstoreasonrespectivelyandevaluatethe
FLEXTAF-Single requires manual data annotation, which
correctnessofeachanswer.Wethencollectthesetofmost
couldbedifficulttoobtain,soweproposeFLEXTAF-Vote
suitabletabularformatsforeachinstanceinthetrainingdata,
to obtain the final answer by integrating the results from
denoted as {F∗ }, for which M can correctly reason with
M,It multipletabularformats,inspiredbyWangetal.(2023);Qin
theformatontheinstanceI ,andusetheseasthetraining
t etal.(2023);Luoetal.(2024).
dataforourclassifier.Additionally,wetakeadatafiltering
strategytoremoveinstancesfromthetrainingsetwheremore Reasoning We first construct multiple table reasoning
thanhalfofthecandidateformatsarecorrectorwherenone prompts,representingthetablewithdifferentformatsineach
are correct, as such instances do not effectively highlight prompt.Thenweemploythesepromptstoreasonwiththe
differencesbetweenthetabularformats. LLM,obtainingmultipleanswersaccordingly.
LearningObjective Sincetherecouldbemultipleformats Vote Weretainthemostconsistentresultacrossmultiplere-
inF∗ ,weapplyamulti-labelclassificationtrainingmethod sultsbyadoptingavotingmechanism,whichcanbeformally
M,I
(GodboleandSarawagi2004;TsoumakasandKatakis2007; expressedasthefollowingequation.
Herreraetal.2016),whereeachlabeldenotesatabularfor-
m boa lt e. aM ndor Se ao rv ae wr a, gw ie 20u 0ti 4li )z fe ora mbi un la tir -y lar be el le cv la an sc sie fim cae tit oh no .d S( pG eco id f-
- Aˆ=argmax
A(cid:88)|F|
1(A r =A) (2)
ically,thetabularformatsareserializedandtransformedinto r=1
binaryvectorsforeachinstance.Duringtraining,weadopt
Here,|F|isthetotalnumberofcandidateformats,A isthe
r
Binary Cross-Entropy Loss, normalized by the number of
answerobtainedfromthetabularformatF ,andAiseach
r
instancesN,asfollows: possibleanswer.Thefunction1(f)returns1iff istrueand0
N |F| otherwise.Intheeventofatie,weselecttheanswerwiththe
1 (cid:88)(cid:88)
L(yˆ,y)=−
N
[y irlog(yˆ ir)+(1−y ir)log(1−yˆ ir)] highestlogarithmicprobabilityfollowingLuoetal.(2024).
i=1r=1
(1) 3.4 Comparison
Among them, |F| refers to the total number of candidate
Tobetteremployourtwomethods,weexaminetheirappli-
tabularformats,y indicatesthegoldvaluefortheinstance
ir cationscenarios.(i)FLEXTAF-Singleisidealforscenarios
i on tabular format r, with possible values of 0 or 1, and
wherehigh-efficiencyonlinereasoningisrequired,although
yˆ representsthepredictedprobabilityforinstanceionthe
ir it necessitates prior training data annotation and classifier
tabularformatr.
training.(ii)FLEXTAF-Votesuitsscenarioswhereannotated
PredictingTabularFormat Afterobtainingtheclassifier, dataisunavailablewhilemaintainingacertaintolerancefor
wepredictthemostsuitabletabularformatFˆ.Weregularize real-timereasoningefficiency.WikiTQ TabFact
TabularFormat Llama3 DeepSeek-Coder Llama3 DeepSeek-Coder
8B 70B 6.7B 33B 8B 70B 6.7B 33B
Markdown 47.7 63.3 32.2 31.2 75.2 86.4 60.4 63.6
Dict 43.0 56.4 25.6 53.6 65.5 80.0 63.9 78.0
List 30.5 56.3 19.2 50.8 57.4 77.5 63.7 75.4
Pandas 39.2 52.3 39.7 48.8 47.8 73.6 62.5 75.9
Database 31.0 48.2 41.8 45.5 65.0 75.0 70.7 76.3
FLEXTAF-Single 50.5 69.1 46.3 54.5 77.0 87.1 70.9 78.3
∆ +2.8 +5.8 +4.5 +0.9 +1.5 +0.7 +2.2 +0.3
Table1:TheaccuracyofreasoningusingafixedtabularformatwithgreedydecodingandFLEXTAF-Single,acrossfourLLMs
onWikiTableQuestions(WikiTQ)andTabFact.ThebestperformanceforeachLLManddatasetismarkedinbold.∆denotes
theimprovementofFLEXTAF-Singlerelativetothebestperformanceofusingafixedformatwithgreedydecodingforeach
LLManddataset.
4 Experiments questionsinWikiTableQuestionsaremorechallenging.To
improvetheperformanceonWikiTableQuestions,weusedif-
4.1 Settings
ferentdemonstrationsforeachtabularformat,andweexplore
Datasets WeuseWikiTableQuestions(PasupatandLiang theperformanceofFLEXTAFwithunifieddemonstrations
2015) and TabFact (Chen et al. 2020) datasets to evaluate in§4.3.Detailedpromptsareprovidedinthesupplementary
FLEXTAF.WikiTableQuestionsisamainstreamdatasetfor material.WetrainatabularformatclassifierforeachLLM
thetableQuestionAnsweringtask,containingdiverseques- oneachdataset.Weprovidedetailedtraininginformationin
tionsacrossvariousdomains,whichrequiresansweringthe thesupplementarymaterial.Forsamplinginself-consistency
questionbasedonthetable.TabFactisaprominentdataset decoding (Wang et al. 2023), we set temperature = 0.1
forthetablefactverificationtask,whichneedstodetermine whichcanbringoptimalperformanceacrossmostformats
whetheraclaimisentailedorrefutedbythetable. within temperature ≤ 0.8. To ensure a fair comparison
withFLEXTAF-Vote,wesetsampling n=5.
Metric Weemployaccuracyastheevaluationmetricfor
WikiTableQuestions and TabFact, following the previous
4.2 MainExperiment
works(PasupatandLiang2015;Chenetal.2020),anduse
accuracytoevaluatetheperformanceofclassification.Ac- Table1andTable2compare FLEXTAF-Singlewithusing
curacy measures the model ability to generate the correct a fixed format with greedy decoding, and FLEXTAF-Vote
answer, which is achieved only when the predicted result withusingafixedformatwithself-consistency(Wangetal.
exactlymatchesthecorrectanswer.SinceFLEXTAF-Single 2023),respectively.Weobservethat:(i) FLEXTAF-Single
aimstoidentifythemostsuitableformat,weadoptaccuracy andFLEXTAF-Votesurpassthebestresultsachievedbythe
toassesswhetherthetopformatpredictedbytheclassifieris fixedformatwithgreedydecodingandself-consistency,by
inthesuitableformatsoftheinstance.
anaverageof2.3%and4.8%respectively,withcomparable
computational costs. (ii) Compared to flexible tabular for-
Models For reasoning, we employ Llama3 (Meta 2024) mats,thefixedformatrestrictstablereasoningperformance
andDeepSeek-Coder(Guoetal.2024),andforclassification, evenwithself-consistency.Moreover,self-consistencywith
we use ELECTRA-Large (Clark et al. 2020). Llama3 and Markdown improves slightly or even decreases compared
DeepSeek-Coder are popular open-source LLMs for their togreedydecoding.Thisisattributedtoself-consistencyin-
outstanding performance across various tasks. We choose stability in CoT prompting (Chen et al. 2024a; Renze and
ELECTRA-Largeduetoitssuperiorperformanceinlanguage Guven2024),anddiminishedinstructionfollowingabilityat
comprehensionandquestion-answeringtaskscomparedto highersamplingtemperatures(Zengetal.2024;Peeperkorn
otherpre-trainedmodelsofsimilarsize(Clarketal.2020). etal.2024).Additionally,thetablesrevealthat:
ImplementationDetails FortheWikiTableQuestionsand TheimprovementofFLEXTAFonthemorechallenging
TabFact datasets, we adopt Markdown, Dict, List, Pandas, dataset is more significant. Both FLEXTAF-Single and
andDatabaseastabularformats,whicharecommonlyused FLEXTAF-Vote achieve performance improvement across
in previous works (Singha et al. 2023; Cheng et al. 2023; datasets,underscoringtheirefficacy.Specifically,theperfor-
Ye et al. 2023; Wang et al. 2024) and generally have high mance on WikiTQ is significantly better compared to the
performance across datasets with different models. To en- simplerTabFact.Despitehigherclassificationaccuracyon
hancetablereasoningperformance,weutilizetheChain-of- TabFact(Table5),FLEXTAF-Singleshowslimitedimprove-
Thought(CoT)prompt(Weietal.2022)forMarkdownand mentduetothealreadyhigh-performancebaseline.More-
the Program-of-Thought (PoT) prompt (Chen et al. 2023; over,FLEXTAF-VoteexhibitslessimprovementonTabFact
Gao et al. 2023) for other formats. In addition, we apply duetothegreateroverlapbetweensimperinstancescorrectly
4-shot prompts and 2-shot prompts respectively, since the solvedbydifferentformats(seesupplementarymaterial).WikiTQ TabFact
TabularFormat Llama3 DeepSeek-Coder Llama3 DeepSeek-Coder
8B 70B 6.7B 33B 8B 70B 6.7B 33B
Markdown 49.1 62.8 32.1 29.7 75.2 86.7 60.9 63.6
Dict 44.8 58.1 28.7 59.7 67.9 80.9 71.9 82.4
List 35.4 59.7 27.5 55.6 59.8 78.0 66.9 78.0
Pandas 41.4 56.2 43.9 54.4 56.0 74.7 67.2 79.2
Database 35.2 48.6 42.5 46.4 69.5 76.0 70.7 77.2
FLEXTAF-Vote 55.7 69.9 51.4 60.9 80.3 88.5 77.9 84.4
∆ +6.6 +7.1 +7.5 +1.2 +5.1 +1.8 +7.2 +2.0
Table2:Theaccuracyofreasoningusingafixedtabularformatwithself-consistencydecoding(Wangetal.2023)andFLEXTAF-
Vote,acrossfourLLMsonWikiTQandTabFact.ThebestperformanceforeachLLManddatasetismarkedinbold.∆denotes
theimprovementofFLEXTAF-Voterelativetothebestperformanceofusingafixedformatwithself-consistencyforeachLLM
anddataset.
FLEXTAF-Single shows superior performance on the
1.0
generalmodelcomparedtothecodemodel. FLEXTAF-
1.00 0.57 0.41 0.52 0.41
Singleand FLEXTAF-Votedemonstrateefficacyacrossdi-
0.9
verse models. Notably, FLEXTAF-Single exhibits greater
improvementonthegeneralmodelsthanonthecodemodels. 0.63 1.00 0.54 0.68 0.52 0.8
Thetabularformatssuitableforthecodemodelareclosely
relatedtocode,resultinginsmallerdifferencesandconse- 0.64 0.77 1.00 0.70 0.52 0.7
quentlylimitedclassifierperformance.
FLEXTAF-VoteconsistentlysurpassesFLEXTAF-Single. 0.63 0.74 0.54 1.00 0.51 0.6
AlthoughtheperformanceofFLEXTAF-Singleisconstrained
0.5
byclassificationaccuracy(seeTable5),itdemonstrateshigh 0.63 0.72 0.51 0.64 1.00
reasoning efficiency which only infers once. In contrast,
FLEXTAF-Vote achieves superior table reasoning perfor- MD Dict List PD DB
manceacrossvariousLLMsanddatasets,becauseinstances
couldberesolvedcorrectlybymultipleformats,anderrors Figure3:Theoverlapbetweeninstancessolvedbytabular
producedbydifferenttabularformatsexhibitdiversity.How- formats achieved by Llama3-8B on WikiTQ. The values
ever,FLEXTAF-Voteislessefficientinreasoning. representtheproportionofinstancesthatcanbesolvedby
thetabularformatcorrespondingtotheverticalaxis,within
4.3 Analysis theinstancessolvablebytheformatonthehorizontalaxis.
WeselectLlama3-8Bforsubsequentanalyticalexperiments
duetoitshighreasoningefficiency.Moreover,weconduct
Detailed prompts are present in the supplementary mate-
mostexperimentsonWikiTQ,becauseitencompassesmore
rial. Table 3 indicates that the tabular formats continue to
diversequestions(PasupatandLiang2015;Chenetal.2020;
significantlyaffectperformance,withtheperformancegap
Dongetal.2022;Shietal.2020).
wideningwhenusingunifieddemonstrations.
Arethetabularformatssuitablefordifferentinstances
MD Dict List PD DB Acc −Acc
max min different? Weanalyzetheoverlapbetweeninstancescor-
47.7 43.0 30.5 39.2 16.1 31.6 rectlysolvedbyeachformatandtheproportionofinstances
thatcanonlybesolvedbyaspecificformat,asshowninFig-
Table3:TheaccuracyontheWikiTQdatasetusingLlama3- ure3andTable4.Figure3illustratesthat:(i)Theoverlaps
8Bwithgreedydecoding,employingunifieddemonstrations between instances correctly solved by each format are all
intheprompts,whicharedifferentfromthepromptsusedin ≤80%,indicatingthedistinctionsamongformats.(ii)The
themainexperiments.MDdenotesMarkdown,PDdenotes DictandPandasformatsexhibithigheroverlapduetotheir
Pandas,andDBdenotesDatabase. superiorperformance(seeTable2),whiletheDBandList
formatshaveloweroverlap.Theoverlapsbetweeninstances
Is the impact of tabular formats due to the different solvedbydifferentformatsusingfourLLMsonWikiTQand
demonstrations? We conduct experiments with unified TabFactareprovidedinthesupplementarymaterial.
demonstrationsinthepromptsforeachformatandpresent Table 4 presents that: (i) Certain instances can only be
theresultsinTable3.Specifically,weadoptthedemonstra- accurately solved using a specificformat, highlighting the
tionsofthesamequestionacrossdifferenttabularformats, differencesbetweenformats.(ii)MarkdownandDatabase
manually annotating the rationale or program accordingly. formatsresolveagreaterproportionofinstancescomparedto
DM
tciD
tsiL
DP
BDModel Scale MD Dict List PD DB AccuracyofClassification AccuracyofFLEXTAF-Single
8B 24.6 7.1 4.6 5.9 8.3 71 53
Llama3
70B 16.0 1.7 2.2 1.8 4.3
69 51
6.7B 24.7 6.7 3.7 11.0 13.6
DeepSeek-Coder
33B 15.6 3.9 3.3 4.4 7.5
67 49
Table4:Thepercentageofinstancesthatcanonlybecorrectly 65 47
solvedbyonetabularformat,inallinstancesthatthetabular
formatcancorrectlysolve. 63 45
61 43
FLEXTAF-Single FLEXTAF-Vote
60 59 41
1 2 3 4 5
56.2 Maximumthresholdofthenumberoflabels
55.7
55 53.9
Figure 5: The accuracy of classification and FLEXTAF-
50.1 50.4 50.4 50.5 Single, with the change of the maximum threshold of the
50
48.5 numberoflabelsinthetrainingdata.
4477..77
45
MD +Dict +PD +DB +List
isbetterthanthatofsmaller-scaleLLMs.Thisisattributed
Figure4:TheaccuracyofFLEXTAF-SingleandFLEXTAF- tothegreaterrobustnessoflarger-scaleLLMs(Howeetal.
VoteusingLlama3-8BonWikiTQwithdifferentnumbers 2024),whichresultsinmoreconsistentfeaturesininstances
ofcandidatetabularformats,asadditionalcandidatetabular correctly solved with the same format. (ii) The classifica-
formatsareaddedfromlefttoright. tionperformanceofeachformatispositivelycorrelatedwith
thesizeofitstrainingdata(seethesupplementarymaterial).
Therefore,futureimprovementsinclassificationperformance
Dict,List,andPandasformatsduetotheirdistinctstructures canbeachievedbyreducingnoiseinthedataandincreasing
comparedtotheprogrammingformats.Figure3andTable4 thescaleofthetrainingdata.
claimthatdifferentinstancessuitdifferenttabularformats.
How does the data filtering strategy affect FLEXTAF-
How does the number of candidate tabular formats af-
Single? We compare various strategies by adjusting the
fect FLEXTAF? Weperformexperimentsusingvarying
maximumthresholdofthenumberoflabelsineachtraining
numbers of candidate formats and present results in Fig-
datainstance.TheexperimentalresultsareshowninFigure5.
ure4,whereformatsareaddedindescendingorderofper-
Wefindthat:(i)Asthemaximumlabelcountrises,overall
formance. We observe the following: (i) The performance
performance improves, peaking at 3 labels, which demon-
of FLEXTAF-Single gradually stabilizes as the number of
stratesthattrainingwith≤3labelsperinstanceworksbest,
candidateformatsincreases.Theclassificationperformance
becausetheincreasedamountoftrainingdataaidsthemodel
doesnotalwaysimproveduetotheincreaseddifficultywitha
training.(ii)Whenthelabelcountgoesabove3,performance
highernumberoflabels(Wangetal.2021;Audibert,Gauffre,
drops.Thisshowswhyfilteringtrainingdataisimportant,as
andAmini2024).(ii)FLEXTAF-Votevariesgreatlywiththe
instanceseasilyresolvedbymosttabularformatsareoften
increaseinthenumberofformatsduetoitsrelianceonthe
simplerandfailtoeffectivelycapturetheuniquefeaturesof
performanceofeachformat.Inparticular, FLEXTAF-Vote
eachlabel,thusnegativelyimpactingmodeltraining.
doesnotexceedFLEXTAF-SinglewhenMarkdownandDict
arecandidates,asitselectsfromtwodifferentanswersonly
bycomparingprobabilities,whichdonotaccuratelyindicate 4.4 CaseStudy
correctness(Wangetal.2023;PortilloWightman,Delucia,
andDredze2023;Quevedoetal.2024).Therefore,weselect Tobetterillustratethatdifferentinstancesaresuitablefordif-
5formatsascandidatesinthemainexperiments,considering ferenttabularformats,wepresentaninstancefromWikiTQ.
theperformanceofourtwomethods. As illustrated in Figure 6, when utilizing the Dict format,
Llama3-70B (Meta 2024) generates an incorrect program
Howtofurtherimprovetheclassificationperformanceof thatprocessesalltablerowswithoutexcludingaspecial”-”
FLEXTAF-Single? Weanalyzeboththeoverallaccuracy row.Conversely,whensolvingtheinstancewithMarkdown,
andtheaccuracyoninstancesthatcanbecorrectlysolved themodelsuccessfullyignoresthe”-”lineandcorrectlyiden-
byonlyoneformat,astheseinstancesmostdistinctlyhigh- tifiesthecountrythatwonthemostgoldmedals.Therefore,
lighttheuniquefeaturesofeachformat.Theclassification forthisinstance,theMarkdownformatprovesmoresuitable
results are presented in Table 5. We observe that: (i) The thanDictwhenemployingLlama3-70B.Additionalinstances
classificationperformanceofpredictinglarger-scaleLLMs areprovidedinthesupplementarymaterial.
ycarucca
noitacfiissalCfoycaruccA
elgniS-FATXELFfoycaruccAWikiTQ TabFact
Format Llama3 DeepSeek-Coder Llama3 DeepSeek-Coder
8B 70B 6.7B 33B 8B 70B 6.7B 33B
Markdown 78.7 73.8 47.1 20.3 64.3 67.1 25.3 36.0
Dict 27.9 23.8 35.1 46.7 25.0 14.3 37.5 36.0
List 3.4 29.6 9.7 19.4 20.0 25.0 0.0 0.0
Pandas 2.1 10.0 28.6 30.1 0.0 11.1 22.7 7.7
Database 14.3 15.6 50.6 29.7 18.5 26.7 31.3 29.6
Overall 69.6 82.2 68.5 73.1 79.6 88.8 74.3 80.6
Table5:TheoverallclassificationaccuracyofFLEXTAF-SingleusingfourLLMsontwodatasets,andtheclassificationaccuracy
forinstancesthatcanonlybecorrectlysolvedbyasingleformat,withthebestperformancemarkedinbold.
Input Information etal.2024;Zhaoetal.2024)oraggregatingdiverseresults
(Ni et al. 2023; Liu, Wang, and Chen 2024). For instance,
Question who won the most gold medals?
MixSelf-Consistency(Liu,Wang,andChen2024)proposes
Table combiningtextualandsymbolicreasoningresults.
Previousworksgenerallyemployafixedtabularformat
Rank Nation Gold … Total
acrossvaryinginstances,regardlessofthespecificLLMused,
1 Brazil 7 … 15
whichcouldlimittheperformance.SinceSuietal.(2024)
… demonstrate that the performance of table understanding
- Total 16 … 62 tasks,suchasCellLookupandSizeDetection,varieswithdif-
ferenttabularformats,andproposeself-augmentedprompt-
Reason with Dict ing.ToaidLLMsinunderstandingtables,self-augmented
def solver(table): promptingemploysLLMstoextractcriticaltablecontents
max_gold = 0; winner = ""
andsummarizethemintonaturallanguagedescriptionsfor
for row in table:
LLMs. Building on this, Singha et al. (2023) evaluate the
gold = int(row["Gold"])
performanceofadditionaltabularformatsandinvestigatethe
if gold > max_gold:
max_gold = gold; winner = row["Nation"] effectsofnoiseoperationslikeShuffleColumnsandTrans-
return winner pose Table on table understanding. They analyze that the
Answer is Total LLM adopts different tabular formats, causing varying ro-
bustnessintableunderstandingtasks.Similarly,Dengetal.
Reason with Markdown
(2024)examinethedifferentperformanceoftext-basedand
To find out who won the most gold medals, we need to
image-basedformatsintablereasoningtasks.
look at the "Gold" column of the table provided.
However, existing studies primarily discuss the impact
According to the table, Brazil won the most gold medals
with 7, so the answer is: Brazil of different tabular formats from the perspective of tasks,
Answer is Brazil ignoringtheimpactoftheinstancesandLLMs.Therefore,we
claimthatdifferentinstancesandmodelssuitdifferenttabular
Figure6:AninstancefromtheWikiTQtestsetusingLlama3- formatsbyanalyzingtheexperimentalresults.Basedonthe
70BwithMarkdownandDicttabularformats. claim,weproposeFLEXTAFtoimprovethetablereasoning
performancebyflexiblyemployingtabularformats.
5 RelatedWorks 6 Conclusion
In this paper, we explore the impact of tabular format on
The table reasoning task aims to answer the natural lan-
tablereasoningperformancefromtwoaspects.(i)Weclaim
guagequestionbasedonprovidedtabulardata(Dongetal.
from the perspective of experimental results that different
2022; Zhang et al. 2024c; Dong and Wang 2024). LLM-
instances and models have different most suitable tabular
basedmethodshavebecomepredominantinthisfielddue
formats.(ii)Weproposeourmethods.FLEXTAF-Singleuse
totheirsuperiorperformanceoftableunderstanding,com-
theclassifiertopredictthemostsuitabletabularformatac-
monsensereasoning,andlogicalreasoning(Weietal.2022;
cordingtotheinstanceandtheLLM.FLEXTAF-Voteobtains
Chen 2023; Zhao et al. 2023; Chen et al. 2023; Gao et al.
the results from multiple formats and employs the voting
2023). Some existing works focus on enhancing table rea-
mechanismtogetthefinalresult.Webuildexperimentson
soning ability by fine-tuning LLMs (Zhang et al. 2024b;
WikiTableQuestionsandTabFactdatasets.Comparedwith
Bian et al. 2024; Zhang et al. 2024d; Patnaik et al. 2024;
the best performance of using a fixed tabular format with
WuandFeng2024;Gardner,Perdomo,andSchmidt2024;
greedydecodingandself-consistency,FLEXTAF-Singleand
Lietal.2024).Also,someworksimprovetablereasoning
FLEXTAF-Voteincreaseby2.3%and4.8%onaveragere-
performance by designing prompts (Zhao et al. 2023; Ye
spectively,demonstratingtheeffectivenessofourmethods.
etal.2023;NahidandRafiei2024a,b;Leeetal.2024;WangReferences oftheThirty-FirstInternationalJointConferenceonArtifi-
Audibert,A.;Gauffre,A.;andAmini,M.-R.2024. Explor-
cialIntelligence,IJCAI-22,5426–5435.InternationalJoint
ingContrastiveLearningforLong-TailedMulti-LabelText ConferencesonArtificialIntelligenceOrganization. Survey
Classification. arXiv:2404.08720. Track.
Dong,H.;andWang,Z.2024. LargeLanguageModelsfor
Bhandari, K. R.; Xing, S.; Dan, S.; and Gao, J. 2024. On
TabularData:ProgressesandFutureDirections. InProceed-
the Robustness of Language Models for Tabular Question
ings of the 47th International ACM SIGIR Conference on
Answering. arXiv:2406.12719.
ResearchandDevelopmentinInformationRetrieval,SIGIR
Bian,J.;Qin,X.;Zou,W.;Huang,M.;Luo,C.;Zhang,K.;
’24,2997–3000.NewYork,NY,USA:AssociationforCom-
and Zhang, W. 2024. HeLM: Highlighted Evidence aug-
putingMachinery. ISBN9798400704314.
mentedLanguageModelforEnhancedTable-to-TextGener-
Gao,L.;Madaan,A.;Zhou,S.;Alon,U.;Liu,P.;Yang,Y.;
ation. arXiv:2311.08896.
Callan,J.;andNeubig,G.2023. PAL:program-aidedlan-
Bowman, S. R. 2023. Eight Things to Know about Large
guage models. In Proceedings of the 40th International
LanguageModels. arXiv:2304.00612.
ConferenceonMachineLearning,ICML’23.JMLR.org.
Cao, Y.; Chen, S.; Liu, R.; Wang, Z.; and Fried, D. 2023.
Gardner, J.; Perdomo, J. C.; and Schmidt, L. 2024. Large
API-AssistedCodeGenerationforQuestionAnsweringon
ScaleTransferLearningforTabularDataviaLanguageMod-
VariedTableStructures. InProc.ofEMNLP.
eling. arXiv:2406.12031.
Chen,A.;Phang,J.;Parrish,A.;Padmakumar,V.;Zhao,C.;
Godbole,S.;andSarawagi,S.2004. DiscriminativeMethods
Bowman,S.R.;andCho,K.2024a. TwoFailuresofSelf-
for Multi-labeled Classification. In Dai, H.; Srikant, R.;
ConsistencyintheMulti-StepReasoningofLLMs. Transac-
andZhang,C.,eds.,AdvancesinKnowledgeDiscoveryand
tionsonMachineLearningResearch.
Data Mining, 22–30. Berlin, Heidelberg: Springer Berlin
Chen, W. 2023. Large Language Models are few(1)-shot Heidelberg. ISBN978-3-540-24775-3.
TableReasoners. InVlachos,A.;andAugenstein,I.,eds.,
Guo,D.;Zhu,Q.;Yang,D.;Xie,Z.;Dong,K.;Zhang,W.;
FindingsoftheAssociationforComputationalLinguistics:
Chen,G.;Bi,X.;Wu,Y.;Li,Y.K.;Luo,F.;Xiong,Y.;and
EACL2023,1120–1130.Dubrovnik,Croatia:Associationfor
Liang,W.2024.DeepSeek-Coder:WhentheLargeLanguage
ComputationalLinguistics.
ModelMeetsProgramming–TheRiseofCodeIntelligence.
Chen,W.;Ma,X.;Wang,X.;andCohen,W.W.2023. Pro- arXiv:2401.14196.
gramofThoughtsPrompting:DisentanglingComputation Herrera, F.; Charte, F.; Rivera, A. J.; and del Jesus, M. J.
fromReasoningforNumericalReasoningTasks. Transac- 2016. Multilabel Classification, 17–31. Cham: Springer
tionsonMachineLearningResearch. InternationalPublishing. ISBN978-3-319-41111-8.
Chen,W.;Wang,H.;Chen,J.;Zhang,Y.;Wang,H.;Li,S.; Howe,N.;Zajac,M.;McKenzie,I.;Hollinsworth,O.;Tseng,
Zhou,X.;andWang,W.Y.2020. TabFact:ALarge-scale T.; Bacon, P.-L.; and Gleave, A. 2024. Exploring Scaling
DatasetforTable-basedFactVerification. InProc.ofICLR. TrendsinLLMRobustness. arXiv:2407.18213.
Chen,Y.;Yuan,Y.;Zhang,Z.;Zheng,Y.;Liu,J.;Ni,F.;and Lee, Y.; Kim, S.; Rossi, R. A.; Yu, T.; and Chen, X. 2024.
Hao,J.2024b. SheetAgent:AGeneralistAgentforSpread- Learning to Reduce: Towards Improving Performance of
sheetReasoningandManipulationviaLargeLanguageMod- LargeLanguageModelsonStructuredData. InFirstWork-
els. arXiv:2403.03636. shoponLong-ContextFoundationModels@ICML2024.
Cheng,Z.;Xie,T.;Shi,P.;Li,C.;Nadkarni,R.;Hu,Y.;Xiong, Li,P.;He,Y.;Yashar,D.;Cui,W.;Ge,S.;Zhang,H.;Rifin-
C.;Radev,D.;Ostendorf,M.;Zettlemoyer,L.;Smith,N.A.; skiFainman,D.;Zhang,D.;andChaudhuri,S.2024. Table-
and Yu, T. 2023. Binding Language Models in Symbolic GPT:TableFine-tunedGPTforDiverseTableTasks. Proc.
Languages. In The Eleventh International Conference on ACMManag.Data,2(3).
LearningRepresentations.
Liu,T.;Wang,F.;andChen,M.2024. RethinkingTabular
Clark,K.;Luong,M.-T.;Le,Q.V.;andManning,C.D.2020. DataUnderstandingwithLargeLanguageModels. InDuh,
ELECTRA: Pre-training Text Encoders as Discriminators K.; Gomez, H.; and Bethard, S., eds., Proceedings of the
Rather Than Generators. In International Conference on 2024ConferenceoftheNorthAmericanChapteroftheAs-
LearningRepresentations. sociationforComputationalLinguistics:HumanLanguage
Deng,N.;Sun,Z.;He,R.;Sikka,A.;Chen,Y.;Ma,L.;Zhang, Technologies (Volume 1: Long Papers), 450–482. Mexico
Y.;andMihalcea,R.2024. TablesasTextsorImages:Eval- City,Mexico:AssociationforComputationalLinguistics.
uatingtheTableReasoningAbilityofLLMsandMLLMs. Liu,Y.;He,H.;Han,T.;Zhang,X.;Liu,M.;Tian,J.;Zhang,
InKu,L.-W.;Martins,A.;andSrikumar,V.,eds.,Findings Y.;Wang,J.;Gao,X.;Zhong,T.;Pan,Y.;Xu,S.;Wu,Z.;Liu,
oftheAssociationforComputationalLinguisticsACL2024, Z.;Zhang,X.;Zhang,S.;Hu,X.;Zhang,T.;Qiang,N.;Liu,
407–426.Bangkok,Thailandandvirtualmeeting:Associa- T.;andGe,B.2024.UnderstandingLLMs:AComprehensive
tionforComputationalLinguistics. OverviewfromTrainingtoInference. arXiv:2401.02038.
Dong,H.;Cheng,Z.;He,X.;Zhou,M.;Zhou,A.;Zhou,F.; Luo, X.; Zhu, Q.; Zhang, Z.; Qin, L.; Zhang, X.; Yang,
Liu, A.; Han, S.; and Zhang, D. 2022. Table Pre-training: Q.; Xu, D.; and Che, W. 2024. Python is Not Always the
ASurveyonModelArchitectures,Pre-trainingObjectives, BestChoice:EmbracingMultilingualProgramofThoughts.
andDownstreamTasks. InRaedt,L.D.,ed.,Proceedings arXiv:2402.10691.Meta.2024. IntroducingMetaLlama3:Themostcapable SemanticParsingtoSQLQueries. InCohn,T.;He,Y.;and
openlyavailableLLMtodate. Technicalreport,Meta. Liu,Y.,eds.,FindingsoftheAssociationforComputational
Nahid,M.M.H.;andRafiei,D.2024a. NormTab:Improv- Linguistics:EMNLP2020,1849–1864.Online:Association
ing Symbolic Reasoning in LLMs Through Tabular Data forComputationalLinguistics.
Normalization. arXiv:2406.17961. Singha,A.;Cambronero,J.;Gulwani,S.;Le,V.;andParnin,
Nahid, M. M. H.; and Rafiei, D. 2024b. TabSQLify: En- C.2023. TabularRepresentation,NoisyOperators,andIm-
hancing Reasoning Capabilities of LLMs Through Table pactsonTableStructureUnderstandingTasksinLLMs. In
Decomposition. arXiv:2404.10150. NeurIPS2023SecondTableRepresentationLearningWork-
shop.
Ni,A.;Iyer,S.;Radev,D.;Stoyanov,V.;Yih,W.-t.;Wang,
S.I.;andLin,X.V.2023.Lever:Learningtoverifylanguage- Sui,Y.;Zhou,M.;Zhou,M.;Han,S.;andZhang,D.2024.
to-codegenerationwithexecution. InProc.ofICML. TableMeetsLLM:CanLargeLanguageModelsUnderstand
StructuredTableData?ABenchmarkandEmpiricalStudy.
Pasupat, P.; and Liang, P. 2015. Compositional Semantic
InProceedingsofthe17thACMInternationalConference
ParsingonSemi-StructuredTables. InProc.ofACL.
on Web Search and Data Mining, WSDM ’24, 645–654.
Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.;
NewYork,NY,USA:AssociationforComputingMachinery.
Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga,
ISBN9798400703713.
L.;Desmaison,A.;Kopf,A.;Yang,E.;DeVito,Z.;Raison,
M.;Tejani,A.;Chilamkurthy,S.;Steiner,B.;Fang,L.;Bai, Tsoumakas,G.;andKatakis,I.2007. Multi-labelclassifica-
J.; and Chintala, S. 2019. PyTorch: An Imperative Style, tion:Anoverview. InternationalJournalofDataWarehous-
High-PerformanceDeepLearningLibrary. InWallach,H.;
ingandMining(IJDWM),3(3):1–13.
Larochelle,H.;Beygelzimer,A.;d'Alche´-Buc,F.;Fox,E.; Wang,R.;Su,X.;Long,S.;Dai,X.;Huang,S.;andChen,J.
andGarnett,R.,eds.,AdvancesinNeuralInformationPro- 2021. Meta-LMTC:Meta-LearningforLarge-ScaleMulti-
cessingSystems,volume32.CurranAssociates,Inc. LabelTextClassification. InMoens,M.-F.;Huang,X.;Spe-
Patnaik, S.; Changwal, H.; Aggarwal, M.; Bhatia, S.; Ku- cia,L.;andYih,S.W.-t.,eds.,Proceedingsofthe2021Con-
mar,Y.;andKrishnamurthy,B.2024. CABINET:Content ference on Empirical Methods in Natural Language Pro-
Relevance-based Noise Reduction for Table Question An- cessing, 8633–8646. Online and Punta Cana, Dominican
swering. InTheTwelfthInternationalConferenceonLearn- Republic:AssociationforComputationalLinguistics.
ingRepresentations. Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V.; Chi, E. H.;
Peeperkorn, M.; Kouwenhoven, T.; Brown, D.; and Jor- Narang, S.; Chowdhery, A.; and Zhou, D. 2023. Self-
danous,A.2024. IsTemperaturetheCreativityParameterof ConsistencyImprovesChainofThoughtReasoninginLan-
LargeLanguageModels? arXiv:2405.00492. guageModels. InTheEleventhInternationalConferenceon
LearningRepresentations.
Portillo Wightman, G.; Delucia, A.; and Dredze, M. 2023.
StrengthinNumbers:EstimatingConfidenceofLargeLan- Wang,Z.;Zhang,H.;Li,C.-L.;Eisenschlos,J.M.;Perot,V.;
guage Models by Prompt Agreement. In Ovalle, A.; Wang,Z.;Miculicich,L.;Fujii,Y.;Shang,J.;Lee,C.-Y.;and
Chang, K.-W.; Mehrabi, N.; Pruksachatkun, Y.; Galystan, Pfister,T.2024. Chain-of-Table:EvolvingTablesintheRea-
A.;Dhamala,J.;Verma,A.;Cao,T.;Kumar,A.;andGupta, soningChainforTableUnderstanding. arXiv:2401.04398.
R.,eds., Proceedingsofthe 3rdWorkshopon Trustworthy Wei,J.;Wang,X.;Schuurmans,D.;Bosma,M.;ichter,b.;
Natural Language Processing (TrustNLP 2023), 326–362. Xia, F.; Chi, E.; Le, Q. V.; and Zhou, D. 2022. Chain-of-
Toronto,Canada:AssociationforComputationalLinguistics. Thought Prompting Elicits Reasoning in Large Language
Qin,L.;Chen,Q.;Feng,X.;Wu,Y.;Zhang,Y.;Li,Y.;Li, Models. InKoyejo,S.;Mohamed,S.;Agarwal,A.;Belgrave,
M.;Che,W.;andYu,P.S.2024. LargeLanguageModels D.;Cho,K.;andOh,A.,eds.,AdvancesinNeuralInforma-
MeetNLP:ASurvey. arXiv:2405.12819. tionProcessingSystems,volume35,24824–24837.Curran
Qin, L.; Chen, Q.; Wei, F.; Huang, S.; and Che, W. 2023. Associates,Inc.
Cross-lingual Prompting: Improving Zero-shot Chain-of- Wolf,T.;Debut,L.;Sanh,V.;Chaumond,J.;Delangue,C.;
ThoughtReasoningacrossLanguages. InBouamor,H.;Pino, Moi,A.;Cistac,P.;Rault,T.;Louf,R.;Funtowicz,M.;Davi-
J.;andBali,K.,eds.,Proceedingsofthe2023Conferenceon son,J.;Shleifer,S.;vonPlaten,P.;Ma,C.;Jernite,Y.;Plu,
EmpiricalMethodsinNaturalLanguageProcessing,2695– J.;Xu,C.;LeScao,T.;Gugger,S.;Drame,M.;Lhoest,Q.;
2709.Singapore:AssociationforComputationalLinguistics. andRush,A.2020. Transformers:State-of-the-ArtNatural
Quevedo, E.; Yero, J.; Koerner, R.; Rivas, P.; and LanguageProcessing. InLiu,Q.;andSchlangen,D.,eds.,
Cerny, T. 2024. Detecting Hallucinations in Large Lan- Proceedingsofthe2020ConferenceonEmpiricalMethods
guage Model Generation: A Token Probability Approach. in Natural Language Processing: System Demonstrations,
arXiv:2405.19648. 38–45.Online:AssociationforComputationalLinguistics.
Renze, M.; and Guven, E. 2024. The Effect of Sampling Wu, Z.; and Feng, Y. 2024. ProTrix: Building Models for
TemperatureonProblemSolvinginLargeLanguageModels. PlanningandReasoningoverTableswithSentenceContext.
arXiv:2402.05201. arXiv:2403.02177.
Shi,T.;Zhao,C.;Boyd-Graber,J.;Daume´ III,H.;andLee, Ye,Y.;Hui,B.;Yang,M.;Li,B.;Huang,F.;andLi,Y.2023.
L.2020. OnthePotentialofLexico-logicalAlignmentsfor LargeLanguageModelsAreVersatileDecomposers:Decom-posingEvidenceandQuestionsforTable-BasedReasoning.
InProc.ofSIGIR.
Zeng,Z.;Yu,J.;Gao,T.;Meng,Y.;Goyal,T.;andChen,D.
2024. EvaluatingLargeLanguageModelsatEvaluatingIn-
structionFollowing. InTheTwelfthInternationalConference
onLearningRepresentations.
Zhang, B.; Ye, Y.; Du, G.; Hu, X.; Li, Z.; Yang, S.; Liu,
C.H.;Zhao,R.;Li,Z.;andMao,H.2024a. Benchmarking
theText-to-SQLCapabilityofLargeLanguageModels:A
ComprehensiveEvaluation. arXiv:2403.02951.
Zhang, T.; Yue, X.; Li, Y.; and Sun, H. 2024b. TableL-
lama: Towards Open Large Generalist Models for Tables.
arXiv:2311.09206.
Zhang,X.;Wang,D.;Dou,L.;Zhu,Q.;andChe,W.2024c.
ASurveyofTableReasoningwithLargeLanguageModels.
arXiv:2402.08259.
Zhang, X.; Zhang, J.; Ma, Z.; Li, Y.; Zhang, B.; Li, G.;
Yao, Z.; Xu, K.; Zhou, J.; Zhang-Li, D.; Yu, J.; Zhao, S.;
Li, J.; and Tang, J. 2024d. TableLLM: Enabling Tabular
DataManipulationbyLLMsinRealOfficeUsageScenarios.
arXiv:2403.19318.
Zhang, Y.; Henkel, J.; Floratou, A.; Cahoon, J.; Deep, S.;
and Patel, J.M. 2024e. ReAcTable: EnhancingReAct for
Table Question Answering. Proc. VLDB Endow., 17(8):
1981–1994.
Zhao, B.; Ji, C.; Zhang, Y.; He, W.; Wang, Y.; Wang, Q.;
Feng,R.;andZhang,X.2023. LargeLanguageModelsare
ComplexTableParsers. InProc.ofEMNLP.
Zhao,Y.;Chen,L.;Cohan,A.;andZhao,C.2024. TaPERA:
Enhancing Faithfulness and Interpretability in Long-Form
TableQAbyContentPlanningandExecution-basedReason-
ing. InKu,L.-W.;Martins,A.;andSrikumar,V.,eds.,Pro-
ceedingsofthe62ndAnnualMeetingoftheAssociationfor
ComputationalLinguistics(Volume1:LongPapers),12824–
12840.Bangkok,Thailand:AssociationforComputational
Linguistics.A IntroductiontoFiveTabularFormats wefindthecorrespondingP-valuefromthesquaredistribu-
tion table, which is less than 0.05, proving that there is a
In this section, we introduce the five tabular formats used
distinctdifferenceinthedistributionofthecorrecttabular
inFLEXTAF:Markdown,Dict,List,Pandas,andDatabase.
formatsondifferentmodels.
The Markdown format refers to the representing tables
in the Markdown language. The Dict format employs
List[Dict: [str, Any]]toindexthetable,inwhich D DetailsofTrainingtheClassifierin
eachrowisstoredinadictionary,andthecolumnnameof
FLEXTAF-Single
eachcolumnisindexedasthekeyofthedictionary.TheList
format adopts List[List[Any]] to index the table, in
Inthissection,weintroducethedetailsoftrainingtheclas-
whicheachrow,includingtheheader,isstoredinthelist,and
sifierinFLEXTAF-Single.Ourmodelisimplementedwith
eachcolumnneedstobeindexedwiththeserialnumberof
PyTorch(Paszke etal. 2019) and transformers (Wolf et al.
thecolumn.ThePandasformatisaPythoncodesnippetthat
2020).WepresenttrainingdetailsinTable17,andwesumma-
usesthePandasDataFrameAPItodefinethetable,which
rizethetrainingdatasizeemployedfortrainingtheclassifier
pointsouteachlineofthetableandtheheader.Databasefor-
topredicteachLLMacrossvariousdatasetsinTable18.We
matreferstotheformatofrepresentingatableasadatabase,
counttheproportionofeachtabularformatinthetraining
describingthecolumnnamewithaCREATEstatement,and
datafordifferentLLMsanddatasets,asshowninFigure7.
listingspecificvalues.
Specifically,tocomparetheproportionsofdifferenttabular
formatsinthetrainingdata,wecalculatetheproportionof
B PromptswithEachTabularFormat
eachformattoalllabelsofallinstancesinthetrainingdata.
Wepresentthepromptsusedinexperimentsinthissection.
E OverlapbetweenTabularFormats
B.1 PromptsforMainExperiments
ThepromptsforWikiTQ(PasupatandLiang2015)inmain Inthissection,weanalyzetheoverlapbetweeninstancescor-
experimentswithasingletabularformatareshowninTable6, rectlysolvedbydifferenttabularformats,whichisshownin
Table7,Table8,Table9,andTable10.Andthepromptsfor Figure8.Theoverlapbetweeninstancessolvedbydifferent
TabFact(Chenetal.2020)inmainexperimentswithasingle tabularformatsisall≤ 100%,whichprovesthatdifferent
tabular format are shown in Table 11, Table 12, Table 13, instancesaresuitablefordifferenttabularformats.Wecan
Table14,andTable15.Itcanbefoundthatonlythedemon- findthat:(i)TheoverlapcausedbyusingDeepSeek-Coderis
strationswiththeDatabaseformataredifferentamongthe greaterthanthatcausedbyLlama3becauseDeepSeek-Coder
promptsforWikiTQ.Ifweusethesamedemonstrationsas isbetteratcodeformats.Thedifferencebetweencodefor-
otherprompts,theSQLgiveninthepromptistoocompli- matssuchasDictandListissmallerthanthatbetweencode
catedtoreducethereasoningperformanceofthemodel. formats and natural language formats, such as Markdown.
(ii)Theoverlapcausedbyemployinglarge-scaleLLMsis
B.2 PromptsforExperimentsofUnifying moreseriousthanthatofsmall-scaleLLMsbecausethelarge-
Demonstrations scaleLLMshavehighertablereasoningperformance,lead-
ing to more instances correctly solved by tabular formats.
Wepresentthepromptwiththeunifieddemonstrationsinthis
(iii)TheoverlaponTabFactisgreaterthanthatonWikiTQ
subsection.FromTable6,Table7,Table8andTable9,itcan
becausethequestionsofTabFactaresimplerandeasierto
beseenthatthedemonstrationsusedintheMarkdown,Dict,
solvebymoretabularformats.
List,andPandasareunified,soweonlychangetheprompt
withtheDatabaseformat,whichisshowninTable16.
F Comparison FLEXTAF withOracle
C TabularFormatDistributionsonModels
Inthissection,wecomparetheperformanceof FLEXTAF
Inthissection,weshowthespecificprocessofprovingthat
withthatofOracle,asshowninTable19.Weobservethat:
the tabular format is distributed differently on the model,
(i)Theexcellentoracleperformanceshowsthatthereexist
whichisdiscussedin§2.
differencesbetweendifferentformats,whichfurthersuggests
Specifically, we take the number correctly represented
that different instances have their suitable tabular formats.
oneachmodelastheobservedfrequencyO ,calculatethe
i (ii)TheperformanceofFLEXTAF-Singleislimitedbyclas-
averagecorrectnumberofeachformatunderdifferentmodels
sificationandhasagapwiththeoracleperformance,since
astheexpectedfrequencyE ,andcalculatetheChi-square
i thePre-trainedLanguageModel(PLM)cannotpredictthe
statisticsasEquation3.
behavior of LLMs well (Qin et al. 2024; Liu et al. 2024;
X2
=(cid:88)(O i−E i)2
(3)
B too fiw nm e-a tn un2 e02 L3 L) M.H so fw orev ce lar, ssw ifie cd ao tion not lic mo in td educ bt yex cp oe mri pm ue tin nt gs
E
i resources.(iii)TheperformanceofFLEXTAF-Votealsohas
Thecorrespondingdegreeoffreedomdof isdof =(N − agapwiththeoracleperformance,becausethevotingmech-
m
1)∗(N −1),whereN isthenumberofmodels,andN anismweadoptdoesnotmakefulluseoftherichsemantic
r m r
isthenumberoftabularformats.Accordingtothecalculated information in the LLM solutions, causing the limited im-
Chi-squareX2andthecorrespondingdegreeoffreedomdof, provement(Nietal.2023).DB DB PD DB DB
PD PD
15.3% 14.8% 14.4% 28.0% 17.0%
20.5% 19.2%
MD
14.4%
MD 28.2% 14.0% List 33.8% 19.1% List MD 24.0% 25.8% PD 23.3%
MD
22.0% 18.0% 13.5%8.7% 26.0% List
Dict
Dict Dict Dict List
(a) Llama3-8B, WikiTQ (b) Llama3-70B, WikiTQ (c) Deepseek-Coder-6.7B, WikiTQ (d) Deepseek-Coder-33B, WikiTQ
DB DB DB DB
PD PD
PD
20.1% 18.0% 23.7% 19.5%
11.8% 14.7% PD
18.0%
17.4%
15.8% List 16.8% MD 21.6% MD 20.6%
30.8% 32.1% List
MD MD 17.7% 18.2%
21.5% 18.4% 19.6% 23.7% List
List
Dict Dict Dict Dict
(e) Llama3-8B, TabFact (f) Llama3-70B, TabFact (g) Deepseek-Coder-6.7B, TabFact (h) Deepseek-Coder-33B, TabFact
Figure7:Theproportionofeachtabularformatinthetrainingdata.
G CasesStudy
Toclearlyshowtheimpactofthetable,weshowmorein-
stancesinWikiTQinthissection,asshowninFigure9.We
observethat:(i)Forthefirstinstancewiththequestion”what
is the highest points scored by an opponent?”, DeepSeek-
Coder-33BcorrectlysolvestheinstancewiththeDictformat,
whileLlama3-70BissuitableforMarkdownandPandasfor-
mats.(ii)WhenweusethesamemodelLlama3-70B,thelast
instancewiththequestion”incycle4,howmanycontestants
areolderthan20?”issolvedcorrectlywithDict,whichis
different from the previous instance. The cases claim that
different instances and LLMs have different most suitable
tabularformats.1.0 1.0 1.0 1.0
1.00 0.57 0.41 0.52 0.41 1.00 0.68 0.67 0.63 0.55 1.00 0.23 0.19 0.54 0.55 1.00 0.67 0.66 0.64 0.58
0.9 0.9
0.9 0.8
0.63 1.00 0.54 0.68 0.52 0.8 0.76 1.00 0.85 0.77 0.68 0.29 1.00 0.57 0.66 0.68 0.39 1.00 0.82 0.75 0.67 0.8
0.8 0.64 0.77 1.00 0.70 0.52 0.7 0.75 0.85 1.00 0.77 0.67 0.31 0.76 1.00 0.66 0.71 0.6 0.40 0.86 1.00 0.77 0.68 0.7
0.63 0.74 0.54 1.00 0.51 0.6 0.76 0.83 0.83 1.00 0.71 0.7 0.44 0.43 0.32 1.00 0.69 0.41 0.83 0.80 1.00 0.68 0.6
0.4
0.5 0.5 0.63 0.72 0.51 0.64 1.00 0.72 0.79 0.79 0.77 1.00 0.6 0.42 0.42 0.32 0.65 1.00 0.40 0.79 0.76 0.73 1.00
0.2 0.4
MD Dict List PD DB MD Dict List PD DB MD Dict List PD DB MD Dict List PD DB
(a) Llama3-8B, WikiTQ (b) Llama3-70B, WikiTQ (c) Deepseek-Coder-6.7B, WikiTQ (d) Deepseek-Coder-33B, WikiTQ
1.0 1.00 1.0 1.00
1.00 0.67 0.60 0.50 0.67 1.00 0.82 0.79 0.76 0.77 1.00 0.64 0.66 0.67 0.73 1.00 0.84 0.79 0.80 0.80
0.95
0.9 0.95 0.77 1.00 0.68 0.56 0.73 0.88 1.00 0.89 0.82 0.80 0.61 1.00 0.74 0.69 0.74 0.9 0.65 1.00 0.84 0.83 0.82 0.90
0.8 0.90 0.85 0.79 0.77 1.00 0.56 0.71 0.88 0.92 1.00 0.82 0.81 0.63 0.74 1.00 0.72 0.78 0.8 0.67 0.91 1.00 0.84 0.83
0.7 0.85 0.80 0 0. .7 78 8 0 0. .7 76 4 0 0. .6 67 2 1 0. .0 50 4 0 1. .7 03 0 0.6 0 0. .8 89 9 0 0. .8 89 6 0 0. .8 86 3 1 0. .0 80 0 0 1. .8 02 0 0.80 0 0. .6 65 5 0 0. .7 61 9 0 0. .7 73 2 1 0. .0 70 1 0 1. .7 08 0 0.7 0 0. .6 67 7 0 0. .8 89 8 0 0. .8 84 2 1 0. .0 80 3 0 1. .8 04 0 00 .. 77 05
0.5
MD Dict List PD DB MD Dict List PD DB MD Dict List PD DB MD Dict List PD DB
(e) Llama3-8B, TabFact (f) Llama3-70B, TabFact (g) Deepseek-Coder-6.7B, TabFact (h) Deepseek-Coder-33B, TabFact
Figure8:TheoverlapamonginstancesthatarecorrectlysolvedwitheachtabularformatusingfourLLMsontwodatasets.The
valuerepresentstheproportionthatcanbesolvedbythetabularformatcorrespondingtotheverticalaxisintheinstancesthatare
solvedbytheformatcorrespondingtothehorizontalaxis.
Question Question Question
what is the highest points scored by an opponent? what is the highest points scored by an opponent? in cycle 4,how many contestants are older than 20?
Table Table Table
Opponent Score … Opponent Score … Contestant Age …
at Toronto Argonauts 13–6 at Toronto Argonauts 13–6 Isabelle Raisa 16 …
… … …
vs. Montreal Alouettes 14–12 … vs. Montreal Alouettes 14–12 … Nadine Trinker 21 …
DeepSeek-Coder-33b Llama3-70b Llama3-70b
Dict Dict Dict
def solver(table): def solver(table): def solver(table):
max_points = 0 max_points = 0 count = 0
for row in table: for row in table: for row in table:
points = int(row["Score"].split("–")[0]) score = row["Score"].split("-") if int(row["Age"]) > 20:
if points > max_points: opponent_points = int(score[1]) count += 1
max_points = points if opponent_points > max_points: return count
return max_points max_points = opponent_points Answer
Answer return max_points 5
45 Answer
17 Pandas
Pandas def solver(table):
def solver(table): Pandas import pandas as pd
import pandas as pd def solver(table): contestants_over_20 = table[table["Age"] >
table[['Team_Score', 'Opponent_Score']] = import pandas as pd 20].shape[0]
table['Score'].str.split('–', expand=True) max_points_scored = table['Score'].apply(lambda x: return contestants_over_20",
table['Team_Score'] = table['Team_Score'].astype(int) int(max(x.split('–')[0], x.split('–')[1]))).max()
return table['Opponent_Score'].astype(int).max() return max_points_scored Answer
Error occurred
Answer Answer
17 45 Markdown
To find out how many contestants were older than 20 in
Markdown Markdown Cycle 4, we need to look at the "Age" column of the
To find out the highest amount of points scored in a To find out what is the highest amount of points scored table provided. According to the table, the contestants
game by an opponent, we need to look at the "Score" in a game by an opponent, we need to look at the "Score" older than 20 are Sabrina Angelika Rauch(21), Katharina
column of the table provided. According to the table, the column of the table provided. According to the table, the Mihalovi(23), Michaela Schopf(21), Christine
highest amount of points scored in a game by an highest amount of points scored in a game by an Riener(20), Bianca Ebelsberger(24), Nadine
opponent is 38, which was scored against Hamilton opponent is 45, so the answer is: 45 Trinker(21), and Dzejlana Lana(20), so the answer is: 7
Tiger-Cats, so the answer is: 38 Answer Answer
Answer 45 7
38
Figure9:TwoinstancesofWikiTQtestsetusingLlama3-70BandDeepSeek-Coder-33BwithMarkdownandDicttabular
format.
DM
tciD
tsiL
DP
BD
DM
tciD
tsiL
DP BD
DM
tciD
tsiL
DP
BD
DM
tciD
tsiL
DP BD
DM
tciD
tsiL
DP
BD
DM
tciD
tsiL
DP BD
DM
tciD
tsiL
DP
BD
DM
tciD
tsiL
DP BDThepromptwiththeMarkdownformatforWikiTQ.
Pleaseanswerthequestionwiththegiventable,presentthefinalresultintheformat”...,sotheansweris:(answer)”:
Pleasenotethatutilizetheformat,donotincludeperiods.Herearesomeinstancesyoumayreferto:
—
table:
|Aircraft|Description|MaxGrossWeight|Totaldiskarea|MaxdiskLoading|
|:−−−|:−−−|:−−−|:−−−|:−−−|
|RobinsonR−22|Lightutilityhelicopter|1,370lb(635kg)|497ft(46.2m)|2.6lb/ft(14kg/m)|
|Bell206B3JetRanger|Turboshaftutilityhelicopter|3,200lb(1,451kg)|872ft(81.1m)|3.7lb/ft(18kg/m)|
|CH−47DChinook|Tandemrotorhelicopter|50,000lb(22,680kg)|5,655ft(526m)|8.8lb/ft(43kg/m)|
|MilMi−26|Heavy−lifthelicopter|123,500lb(56,000kg)|8,495ft(789m)|14.5lb/ft(71kg/m)|
|CH−53ESuperStallion|Heavy−lifthelicopter|73,500lb(33,300kg)|4,900ft(460m)|15lb/ft(72kg/m)|
utterance:
WhatisthemaxgrossweightoftheRobinsonR-22?
answer:
TofindoutwhatisthemaxgrossweightofRobinsonR-22,weneedtolookatthe”MaxGrossWeight”columnofthetable
provided.Accordingtothetable,themaxgrossweightoftheRobinsonR-22is1,370lb(635kg),sotheansweris:1,370lb(635
kg)
—
table:
|Player|No.|Nationality|Position|YearsinToronto|School/ClubTeam|
|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|
|MarkBaker|3|UnitedStates|Guard|1998−99|OhioState|
|MarcusBanks|3|UnitedStates|Guard|2009−10|UNLV |
|LeandroBarbosa|20|Brazil|Guard|2010−2012|Tilibra/Copimax(Brazil)|
|RasualButler|9|UnitedStates|Guard−Forward|2011−12|LaSalle|
utterance:
HowmanyplayerswerewiththeschoolorclubteamLaSalle?
answer:
TocountthenumberofplayerswiththeschoolorclubteamLaSalle,weneedtolookatthe”School/ClubTeam”columnofthe
tableprovided.Accordingtothetable,thereare1playerwhoseSchool/ClubTeamisLaSalle,sotheansweris:1
—
table:
|Model|1991|1995|1996|1997|1998|1999|2000|2001|2002|2003|2004|
|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|
|SkodaFelicia|172,000|210,000|−|288,458|261,127|241,256|148,028|44,963|−|
|SkodaOctavia|−|−|−|47,876|102,373|143,251|158,503|164,134|164,017|165,635|181,683|
|SkodaFabia|−|−|−|−|−|823|128,872|250,978|264,641|260,988|247,600|
|SkodaSuperb|−|−|−|−|−|−|−|177|16,867|23,135|22,392|
utterance:
isthenumberonskodafabiafor1999moreorlessthan1000?
answer:
TofindoutifthenumberontheSkodaFabiafor1999ismoreorlessthan1000,weneedtolookatthedataprovidedforthe
”SkodaFabia”in”1999”,whichis823,thatis,thenumberfortheSkodaFabiain1999islessthan1000,sotheansweris:less
—
table:
|Place|Rider|Country|Team|Points|Wins|
|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|
|1|SylvainGeboers|Belgium|Suzuki|3066|3|
|2|AdolfWeil|Germany|Maico|2331|2|
|3|JohnBanks|UnitedKingdom|CZ |971|0|
|4|MarkBlackwell|UnitedStates|Husqvarna|604|0|
|5|BradLackey|UnitedStates|CZ |603|0|
|6|GaryJones|UnitedStates|Yamaha|439|0|
|7|JohnDeSoto|UnitedStates|Suzuki|425|0|
utterance:
whichcountryhadthemostridersthatplacedinthetop20ofthe1971trans-amafinalstandings?
answer:
Tofindoutwhichcountryhadthemostridersinthetop20,weneedtolookatthe”Country”columnofthetableprovidedand
countthenumberoftimeseachcountryappears.Accordingtothetable,UnitedStateshadthemostriders,sotheansweris:
UnitedStates
—
table:
<table>
utterance:
<utterance>
answer:
Table6:ThepromptwiththeMarkdownformatusedinthemainexperimentsforWikiTQ.ThepromptwiththeDictformatforWikiTQ.
Answerthequestionwiththegiventableusingpythoncode.
Youshouldgenerateafunctionwiththefollowingsignaturewithoutanyotherparameters.Herearesomeinstancesyoumay
referto:
—
table = [
{
"Aircraft": "Robinson R-22",
"Description": "Light utility helicopter",
"Max Gross Weight": "1,370 lb (635 kg)",
...
},
...
]
utterance: What is the max gross weight of the Robinson R-22?
def solver(table):
for row in table:
if row["Aircraft"] == "Robinson R-22":
return row["Max Gross Weight"]
—
table = [...]
utterance: How many players were with the school or club team La Salle?
def solver(table):
players_la_salle = set()
for row in table:
if row["School/Club Team"] == "La Salle": players_la_salle.add(row["Player"])
return len(players_la_salle)
—
table = [...]
utterance: is the number on skoda fabia for 1999 more or less than 1000?
def solver(table):
for row in table:
if row["Model"] == "Skoda Fabia": num_1999 = row["1999"].replace(",", "")
if int(num_1999) > 1000: return "more"
else: return "less"
return "less"
—
table = [...]
utterance: which country had the most riders that placed in the top 20 of the 1971
trans-ama final standings?
def solver(table):
country_counts = {}
for row in table:
country = row["Country"]
if country in country_counts: country_counts[country] += 1
else: country_counts[country] = 1
max_riders = max(country_counts.values())
countries_with_max_riders = [country for country, count in country_counts.items()
if count == max_riders]
return countries_with_max_riders[0]
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingtableusingPythoncode.
table=<table>
utterance:<utterance>
defsolver(table):
#Yourcodehere
Table7:ThepromptwiththeDictformatusedinthemainexperimentsforWikiTQ.Duetothelimitedlengthofthepaper,wedo
notlistthecontentsofallthetablesinthedemonstrations,whicharethesametablesinTable6.Wewillreleasethefullprompt
upontheacceptance.ThepromptwiththeListformatforWikiTQ.
Answerthequestionwiththegiventableusingpythoncode.
Youshouldgenerateafunctionwiththefollowingsignaturewithoutanyotherparameters.Herearesomeinstancesyoumay
referto:
—
table = [
[
"Aircraft",
"Description",
"Max Gross Weight",
...
],
[
"Robinson R-22",
"Light utility helicopter",
"1,370 lb (635 kg)",
...
],
...
]
utterance: What is the max gross weight of the Robinson R-22?
def solver(table):
for row in table[1:]:
if row[0] == "Robinson R-22": return row[2]
—
table = [...]
utterance: How many players were with the school or club team La Salle?
def solver(table):
players_la_salle = set()
for row in table[1:]:
if row[5] == "La Salle": players_la_salle.add(row[0])
return len(players_la_salle)
—
table = [...]
utterance: is the number on skoda fabia for 1999 more or less than 1000?
def solver(table):
for row in table[1:]:
if row[0] == ’Skoda Fabia’:
if row[6] == "-" or int(row[6].replace(",", "")) < 1000: return "less"
else:mreturn "more"
—
table = [...]
utterance: which country had the most riders that placed in the top 20 of the 1971
trans-ama final standings?
def solver(table):
country_counts = {}
for row in table[1:]:
country = row[2]
if country in country_counts: country_counts[country] += 1
else: country_counts[country] = 1
max_riders = max(country_counts.values())
countries_with_max_riders = [country for country, count in country_counts.items()
if count == max_riders]
return countries_with_max_riders[0]
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingtableusingPythoncode.
table=<table>
utterance:<utterance>
defsolver(table):
#Yourcodehere
Table8:ThepromptwiththeListformatusedinthemainexperimentsforWikiTQ.Duetothelimitedlengthofthepaper,wedo
notlistthecontentsofallthetablesinthedemonstrations,whicharethesametablesinTable6.Wewillreleasethefullprompt
upontheacceptance.ThepromptwiththePandasformatforWikiTQ.
Answerthequestionwiththegiventableusingpythoncode.
Youshouldgenerateafunctionwiththefollowingsignaturewithoutanyotherparameters.Herearesomeinstancesyoumay
referto:
—
table = pd.DataFrame([
[
"Robinson R-22",
"Light utility helicopter",
"1,370 lb (635 kg)",
...
],
...
], columns = [
"Aircraft",
"Description",
"Max Gross Weight",
...
]
)
utterance: What is the max gross weight of the Robinson R-22?
def solver(table):
import pandas as pd
max_gross_weight_r22 = table[table["Aircraft"] == "Robinson R-22"]
["Max Gross Weight"].iloc[0]
return max_gross_weight_r22
—
table = [...]
utterance: How many players were with the school or club team La Salle?
def solver(table):
import pandas as pd
la_salle_count = table[table["School/Club Team"] == "La Salle"].shape[0]
return la_salle_count
—
table = [...]
utterance: is the number on skoda fabia for 1999 more or less than 1000?
def solver(table):
import pandas as pd
fabia_row = table[table[’Model’] == ’Skoda Fabia’]
fabia_1999_sales = fabia_row[’1999’].values[0]
if fabia_1999_sales == ’-’ or int(fabia_1999_sales.replace(",", "")) < 1000:
return ’less’
else:
return ’more’
—
table = [...]
utterance: which country had the most riders that placed in the top 20 of the 1971
trans-ama final standings?
def solver(table):
import pandas as pd
most_riders_country = table[’Country’].value_counts().idxmax()
return most_riders_country
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingtableusingPythoncode.
table=<table>
utterance:<utterance>
defsolver(table):
#Yourcodehere
Table9:ThepromptwiththePandasformatusedinthemainexperimentsforWikiTQ.Duetothelimitedlengthofthepaper,
wedonotlistthecontentsofallthetablesinthedemonstrations,whicharethesametablesinTable6.Wewillreleasethefull
promptupontheacceptance.ThepromptwiththeDatabaseformatforWikiTQ.
Pleasecompletethesqlbelowtosolvethequestionwiththegivendatabase.
Herearesomeinstancesyoumayreferto:
—
database:
CREATE TABLE information (
year int ,
division int ,
...
);
/*
Columns and instances in each column :
year: 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, ... ;
...
*/
utterance:
when was the first time the kansas city brass qualified for the playoffs?
sql:
SELECT year FROM information WHERE playoffs != ’Did not qualify’ ORDER
BY year ASC LIMIT 1;
—
database:
CREATE TABLE information (...);
/*...*/
utterance:
what was the next episode after \"do-si-do?\"
sql:
SELECT episode FROM information WHERE num = (SELECT num FROM information
WHERE episode = ’Do-Si-Do’) + 1;
—
database:
CREATE TABLE information (...);
/*...*/
utterance:
which dino album yielded the most songs on the billboard hot 100?
sql:
SELECT album FROM information WHERE chart = ’Billboard Hot 100’ GROUP BY album
ORDER BY COUNT(*) DESC LIMIT 1;
—
database:
CREATE TABLE information (...);
/*...*/
utterance:
when was the last year team penske finished first?
sql:
SELECT MAX(year) FROM information WHERE team = ’Team Penske’ AND finish = 1;
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingdatabaseusingSQL.
database:
<table>
utterance:
<utterance>
sql:
SELECT
Table10:ThepromptwiththeDatabaseformatusedinthemainexperimentsforWikiTQ.Duetothelimitedlengthofthepaper,
wedonotlistthecontentsofallthetablesinthedemonstrations.Wewillreleasethefullpromptupontheacceptance.ThepromptwiththeMarkdownformatonTabFact.
Verifytheconsistencybetweenthetableandtheutterance.
Pleasepresentthefinalresultintheformat”...,sotheansweris:(answer)”andthe”(answer)”is”True”or”False”.
Pleasenotethatutilizetheformat,donotincludeperiods.
Herearesomedemonstrationsyoumayreferto:
—
table:
|tournament|wins|top−5|top−10|top−25|events|cutsmade|
|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|:−−−|
|masterstournament|0|1|2|4|4|4|
|usopen|0|2|3|4|6|5|
|theopenchampionship|1|2|2|2|3|3|
|pgachampionship|0|0|1|2|5|4|
|totals|1|5|8|12|18|16|
utterance:
tonylemabeinthetop5forthemastertournament,theusopen,andtheopenchampionship
answer:
Toverifywhethertonylemabeinthetop5forthemastertournament,theusopen,andtheopenchampionship,weneedto
lookatthe”top-5”columnofthetableprovided.Accordingtothetable,the”top-5”columnofthe”masterstournament”,”us
open”,and”theopenchampionship”areallmorethanzero,sotheansweris:True
—
table:
|year|competition|venue|position|event|
|:−−−|:−−−|:−−−|:−−−|:−−−|
|2006|worldcrosscountrychampionships|fukuoka,japan|10th|individualjuniorrace|
|2006|worldcrosscountrychampionships|fukuoka,japan|3rd|teamjuniorrace|
|2006|africanchampionshipsinathletics|bambous,mauritius|5th|10000m|
|2006|worldroadrunningchampionships|debrecen,hungary|7th|individual20km|
|2006|worldroadrunningchampionships|debrecen,hungary|3rd|team20km|
|2007|worldcrosscountrychampionships|mombasa,kenya|7th|individual|
|2007|all−africagames|algiers,algeria|2nd|10000m|
|2007|worldchampionshipsinathletics|osaka,japan|13th|10000m|
|2009|worldcrosscountrychampionships|amman,jordan|17th|individual|
|2013|worldchampionships|moscow,russia|3rd|marathon|
utterance:
japanandhungaryhostthecompetition3timeeach
answer:
Toverifywhetherjapanandhungarybothhostthecompetition3time,weneedtolookatthe”venue”columnofthetable
provided.Accordingtothetable,”japan”hoststhecompetition3times,but”hungary”hoststhecompetition2times,sothe
answeris:False
—
Basedontheabovedemonstrations,Verifytheconsistencybetweenthefollowingtableandutterance.
table:
<table>
utterance:
<utterance>
answer:
Table11:ThepromptwiththeMarkdownformatusedinthemainexperimentsforTabFact.ThepromptwiththeDictformatforTabFact.
Verifytheconsistencybetweenthetableandtheutterancewith”True”or”False”usingpythoncode.
Youshouldgenerateafunctionwiththefollowingsignaturewithoutanyotherparameters:
Herearesomedemonstrationsyoumayreferto:
—
table = [
{
"tournament": "masters tournament",
"wins": "0",
"top - 5": "1",
"top - 10": "2",
"top - 25": "4",
"events": "4",
"cuts made": "4"
},
{
"tournament": "us open",
"wins": "0",
"top - 5": "2",
"top - 10": "3",
"top - 25": "4",
"events": "6",
"cuts made": "5"
},
...
]
utterance: tony lema be in the top 5 for the master tournament , the us open ,
and the open championship
def solver(table):
top_5_tournament = [row["tournament"] for row in table if int(row["top - 5"]) > 0]
if "masters tournament" not in top_5_tournament:
return False
if "us open" not in top_5_tournament:
return False
if "the open championship" not in top_5_tournament:
return False
return True
—
table = [
{
"year": "2006",
"competition": "world cross country championships",
"venue": "fukuoka , japan",
"position": "10th",
"event": "individual junior race"
},
...
]
utterance: japan and hungary host the competition 3 time each
def solver(table):
japan_host_time = 0
hungary_host_time = 0
for row in table:
if "japan" in row["venue"]:
japan_host_time += 1
elif "hungary" in row["venue"]:
hungary_host_time += 1
return (japan_host_time == 3 and hungary_host_time == 3)
—
Basedontheabovedemonstrations,Verifytheconsistencybetweenthefollowingtableandutterance.
table=<table>
utterance:<utterance>
defsolver(table):
#Yourcodehere
Table12:ThepromptwiththeDictformatusedinthemainexperimentsforTabFact.ThepromptwiththeListformatforTabFact.
Verifytheconsistencybetweenthetableandtheutterancewith”True”or”False”usingpythoncode.
Youshouldgenerateafunctionwiththefollowingsignaturewithoutanyotherparameters:
Herearesomedemonstrationsyoumayreferto:
—
table = [
[
"tournament",
"wins",
"top - 5",
"top - 10",
"top - 25",
"events",
"cuts made"
],
[
"masters tournament",
"0",
"1",
"2",
"4",
"4",
"4"
],
...
]
utterance: tony lema be in the top 5 for the master tournament , the us open ,
and the open championship
def solver(table):
top_5_tournament = [row[0] for row in table[1:] if int(row[2]) > 0]
if "masters tournament" not in top_5_tournament:
return False
if "us open" not in top_5_tournament:
return False
if "the open championship" not in top_5_tournament:
return False
return True
—
table = [
[
"year",
"competition",
"venue",
"position",
"event"
],
...
]
utterance: japan and hungary host the competition 3 time each
def solver(table):
japan_host_time = 0
hungary_host_time = 0
for row in table[1:]:
if "japan" in row[2]:
japan_host_time += 1
elif "hungary" in row[2]:
hungary_host_time += 1
return (japan_host_time == 3 and hungary_host_time == 3)
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingtableusingPythoncode.
table=<table>
utterance:<utterance>
defsolver(table):
#Yourcodehere
Table13:ThepromptwiththeListformatusedinthemainexperimentsforTabFact.ThepromptwiththePandasformatforTabFact.
Verifytheconsistencybetweenthetableandtheutterancewith”True”or”False”usingpythoncode.
Youshouldgenerateafunctionwiththefollowingsignaturewithoutanyotherparameters:
Herearesomedemonstrationsyoumayreferto,andyoudon’tneedtoanswerthedemonstrations:
—
table = pd.DataFrame([
[
"masters tournament",
"0",
"1",
"2",
"4",
"4",
"4"
],
...
], columns = [
"tournament",
"wins",
"top - 5",
"top - 10",
"top - 25",
"events",
"cuts made"
]
)
utterance: tony lema be in the top 5 for the master tournament , the us open ,
and the open championship
def solver(table):
tournaments = ["masters tournament", "us open", "the open championship"]
for tournament in tournaments:
row = table[table[’tournament’] == tournament]
if row.empty or int(row[’top - 5’].values[0]) == 0:
return False
return True
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingtableusingPythoncode.
table=<table>
utterance:<utterance>
defsolver(table):
#Yourcodehere
Table14:ThepromptwiththePandasformatusedinthemainexperimentsforTabFact.ThepromptwiththeDatabaseformatforTabFact.
Pleasecompletethesqlbelowtosolvethequestionwiththegivendatabase.
Herearesomeinstancesyoumayreferto:
—
CREATE TABLE information (
tournament text ,
wins int ,
top_5 int ,
top_10 int ,
top_25 int ,
events int ,
cuts_made int
);
/*
Columns and instances in each column :
tournament: masters tournament, us open, the open championship, pga championship, totals ;
wins: 0, 0, 1, 0, 1 ;
top_5: 1, 2, 2, 0, 5 ;
top_10: 2, 3, 2, 1, 8 ;
top_25: 4, 4, 2, 2, 12 ;
events: 4, 6, 3, 5, 18 ;
cuts_made: 4, 5, 3, 4, 16 ;
*/
utterance:
tony lema be in the top 5 for the master tournament , the us open ,
and the open championship
SQL:
SELECT CASE WHEN (SELECT COUNT(*) FROM information WHERE tournament IN
(’masters tournament’, ’us open’, ’the open championship’) AND top_5 > 0) = 3
THEN ’True’ ELSE ’False’ END AS result;
—
CREATE TABLE information (
year int ,
competition text ,
venue text ,
position text ,
event text
);
/*
Columns and instances in each column :
year: 2006, 2006, 2006, 2006, 2006, 2007, 2007, 2007, 2009, 2013 ;
competition: world cross country championships, world cross country championships, ... ;
venue: fukuoka , japan, fukuoka , japan, bambous , mauritius, debrecen , hungary, ... ;
position: 10th, 3rd, 5th, 7th, 3rd, 7th, 2nd, 13th, 17th, 3rd ;
event: individual junior race, team junior race, 10000 m, ... ;
*/
utterance:
japan and hungary host the competition 3 time each
SQL:
SELECT CASE WHEN (SELECT COUNT(*) FROM information WHERE venue LIKE ’%japan%’) = 3 AND
(SELECT COUNT(*) FROM information WHERE venue LIKE ’%hungary%’) = 3 THEN ’True’
ELSE ’False’ END AS result;
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingdatabaseusingSQL.
database:
<table>
utterance:
<utterance>
sql:
SELECT
Table15:ThepromptwiththeDatabaseformatusedinthemainexperimentsforTabFact.ThepromptwiththeDatabaseformatusingunifieddemonstrations.
Pleasecompletethesqlbelowtosolvethequestionwiththegivendatabase.
Herearesomeinstancesyoumayreferto:
—
database:
CREATE TABLE information (
aircraft text ,
...
);
/*
Columns and instances in each column :
aircraft: Robinson R-22, Bell 206B3 JetRanger, CH-47D Chinook, ... ;
...
*/
utterance:
What is the max gross weight of the Robinson R-22?
sql:
SELECT max_gross_weight FROM information WHERE aircraft = ’Robinson R-22’;
—
database:
CREATE TABLE information (
player text ,
...
);
/*...*/
utterance:
How many players were with the school or club team La Salle?
sql:
SELECT COUNT(*) FROM information WHERE school_club_team = ’La Salle’;
—
database:
CREATE TABLE information (
model text ,
...
);
/*...*/
utterance:
is the number on skoda fabia for 1999 more or less than 1000?
sql:
SELECT CASE WHEN CAST(column_1999 AS INTEGER) < 1000 THEN ’less’ ELSE ’more’
END AS result FROM information WHERE model = ’Skoda Fabia’;
—
CREATE TABLE information (
...
);
/*...*/
utterance:
which country had the most riders that placed in the top 20?
sql:
SELECT country, COUNT(rider) as rider_count FROM information WHERE place <= 20
GROUP BY country ORDER BY rider_count DESC LIMIT 1;
—
Basedontheabovedemonstrations,answerthefollowingutterancewiththefollowingdatabaseusingSQL.
database:
<table>
utterance:
<utterance>
sql:
SELECT
Table16:ThepromptwiththeDatabaseformatwiththeunifieddemonstrations.Duetothelimitedlengthofthepaper,wedo
notlistthecontentsofallthetablesinthedemonstrations,whicharethesametablesinTable6.WikiTQ TabFact
batchsize 128 128
epoch 200 400
learningrate 1e−5 5e−6
maxtokens 512 512
trainingdevice 2×NVIDIAA10040GGPU 2×NVIDIAA10040GGPU
trainingtime 16h 36h
Table17:ClassificationtrainingdetailsinFLEXTAF-SingleonWikiTQandTabFact.
WikiTQ TabFact
Llama3 DeepSeek-Coder Llama3 DeepSeek-Coder
8B 70B 6.7B 33B 8B 70B 6.7B 33B
DataSize 7,247 5,649 7,848 5,944 48,073 26,050 45,194 29,619
Table18:ThetrainingdatasizeemployedfortrainingtheclassifierinFLEXTAF-Single.
WikiTQ TabFact
TabularFormat Llama3 DeepSeek-Coder Llama3 DeepSeek-Coder
8B 70B 6.7B 33B 8B 70B 6.7B 33B
FLEXTAF-Single 50.5 69.1 46.3 54.5 77.0 87.1 70.9 78.3
FLEXTAF-Vote 55.7 69.9 51.4 60.9 80.3 88.5 77.9 84.4
Oracle 71.8 83.5 67.7 74.6 96.9 98.1 95.4 97.1
Table19:TheperformanceofFLEXTAF-Single,FLEXTAF-Vote,andOracle,whichdenotestheresultthateachinstanceuses
thetabularformatthatcangetthecorrectanswer.