HISTOGYM: A REINFORCEMENT LEARNING ENVIRONMENT FOR
HISTOPATHOLOGICAL IMAGE ANALYSIS
Zhi-BoLiu1∗ XiaoboPang1 JizhaoWang2 ShuaiLiu1† ChenLi1†
1Xi’anJiaotongUniversity
2FirstAffiliatedHospitalofXi’anJiaotongUniversity
ABSTRACT
In pathological research, education, and clinical practice, the decision-making process based on
pathological images is critically important. This significance extends to digital pathology image
analysis: itsadequacyisdemonstratedbytheextensiveinformationcontainedwithintissuestructures,
which is essential for accurate cancer classification and grading. Additionally, its necessity is
highlightedbytheinherentrequirementforinterpretabilityintheconclusionsgeneratedbyalgorithms.
Forhumans,determiningtumortypeandgradetypicallyinvolvesmulti-scaleanalysis,whichpresents
a significant challenge for AI algorithms. Traditional patch-based methods are inadequate for
modeling such complex structures, as they fail to capture the intricate, multi-scale information
inherentinwholeslideimages. Consequently,thereisapressingneedforadvancedAItechniques
capableofefficientlyandaccuratelyreplicatingthiscomplexanalyticalprocess. Toaddressthisissue,
weintroduceHistoGym,anopen-sourcereinforcementlearningenvironmentforhistopathological
imageanalysis. FollowingOpenAIGymAPIs,HistoGymaimstofosterwholeslideimagediagnosis
bymimickingthereal-lifeprocessesofdoctors. LeveragingthepyramidfeatureofWSIsandthe
OpenSlideAPI,HistoGymprovidesaunifiedframeworkforvariousclinicaltasks,includingtumor
detectionandclassification. Wedetailtheobservation, action, andrewardspecificationstailored
forthehistopathologicalimageanalysisdomainandprovideanopen-sourcePython-basedinterface
forbothcliniciansandresearchers. Toaccommodatedifferentclinicaldemands,weoffervarious
scenarios for different organs and cancers, including both WSI-based and selected region-based
scenarios,showcasingseveralnoteworthyresults.
Keywords Deepreinforcementlearning·Computationalpathology·Medicalimageanalysis
1 Introduction
Pathologydataanalysisplaysacriticalroleinthediagnosis,treatment,andprognosisofcancer[1]. Inclinicalpractice,
pathologistsprimarilyrelyonwholeslideimages(WSIs)forcancerdiagnosis[2]. However,duetothevastamount
ofinformationinWSIsandthelimitedfieldofviewunderamicroscope,theprocessofexaminingtissuesamples
reflectsthediagnosticapproachofpathologists,whichismirroredinteachingpracticesaswell. Pathologistsadjust
themagnificationandnavigatethroughdifferentregionsofaslidetomakeadiagnosis,aprocessthatcanbemodeled
algorithmicallybyactionssuchaszoomingin,zoomingout,andshiftingthefieldofviewindigitalpathology.
Thispaperaddressesthequestion: Isthediagnosticprocessofdoctorsbettermodeledasadecision-makingtask
ratherthanaclassificationtask? Weexplorewhetherprovidingareinforcementlearning(RL)environmenttosimulate
thisdiagnosticprocessisaworthwhileendeavor. Themotivationforthisworkisstraightforward: tocreateanRL
environmentthatmodelsthecancerdiagnosisprocessusinghistopathologicaldata.
Recent advancements in large language models (LLMs), including customized and fine-tuned models, along with
theMixtureofExpertsmodel,areincreasinglyinfluentialinthedecision-makingprocessforcancerdiagnosis[3,4].
∗http://zhibo-liu.com
†Co-correspondingauthors
Thecodeforthisprojectisavailableathttps://github.com/XjtuAI/HistoGym.
4202
guA
61
]VI.ssee[
1v74880.8042:viXraFigure1: AnillustrationoftheHistoGymEnvironment. ThisfigureillustratesthecorecomponentsoftheHistoGym
environment, including the agent’s interaction with the whole slide image (WSI) through a series of actions. The
environment leverages tile-based processing and multi-scale navigation, allowing the agent to effectively analyze
high-resolutionhistopathologyimages.
Multi-modalapproaches,incorporatingbothtextandimages,arecrucialfortreatmentandprognosis[5]. Ourliterature
reviewandstudiessuggestthatexploringtheapplicationofRLinthisfieldisbothnecessaryandfeasible. Oncecancer
diagnosisisframedasadecision-makingtask,explainability,whichhaslongchallengedcomputervisionduetoits
"black-box" nature, can be addressed more intuitively. By illustrating the diagnostic trajectory, experts can easily
interprettheprocess,despitethetime-consumingnatureofthisapproach.
Micro-environmentalfactorsarecriticalincancerdiagnosis[6]. GiventhegigapixelscaleofWSIs,patch-basedmethods
havebeenastraightforwardsolution,withseveralworksintroducinghierarchicalapproachesbycombiningfeaturesfrom
differentscales[7,8,9,10]. Reinforcementlearningoffersanovelwaytomodelthesecomplexmicro-environments,
capturinginformationfromtheorgandowntothecellularlevelwithoutloss[11].
Although various RL environments exist, few focus on medical image tasks. While some environments, such as
those used in gaming[12], robotics[13], and autonomous driving[14], may be too simple or resource-intensive for
state-of-the-artalgorithms,medicalimagingtaskspresenttheoppositechallenge—demandingtasksthatpushthelimits
ofcurrentalgorithms.
Inthispaper,weproposeHistoGym,anovelopen-sourceRLenvironmentdesignedtomodelthediagnosticprocess
inhistopathology. Unlikeotherenvironmentsthatservemerelyastestbeds,HistoGymaimstopromotethestudyof
treatingdiagnosisasanRLdecision-makingproblem.
Contributions:
• WeintroduceHistoGym,areinforcementlearningenvironmentwhereagentslearntoidentifytumorregionsat
variousscales—fromorgantotissuetocelllevel—fullyutilizingthepyramidstructureofWSIs.
• HistoGymoffersalosslessvirtualenvironment,whereagentscontroltheirfieldofviewandlearntodiagnose
slidesthroughactions,mirroringthereal-lifepracticesofpathologists. Theenvironmentprovidesconfigurable
featureembeddingsandrewards,supportingtaskssuchasdetectionandclassification.
• Weevaluatestate-of-the-artalgorithmsacrosspubliclyavailablemulti-organdatasets,providinganextensive
setofreferenceresultsforfutureresearch.
22 MotivationandRelatedWork
2.1 MimickingandExplainability
ExplainabilityiscrucialinmedicalAIalgorithms,impactingresearch,education,andclinicaldecisionsupportsystems.
Fromanimageanalysisperspective,twoprimarylevelsareconsidered: patchlevelandWSIlevel. Atthepatchlevel,
techniquessuchasGradCAM[15]andLRP[16],asappliedtoMILPLE[17],areusedtohighlightkeypixelswithinthe
patch. AttheWSIlevel,multipleinstancelearning(MIL)methodsaregenerallycategorizedintoinstance-level[7,8]
andembedding-level[9,10]approaches,withembedding-levelmethodsbeingmoreprevalentduetotheirabilityto
handlelargedatavolumes, despiteweakergeneralizationcapabilities. Inthesemethods, WSIsaretreatedasbags,
withcroppedpatchesservingasinstances. Interpretabilityisprimarilyachievedthroughattentionmechanismsthat
highlightsignificantpatcheswithintheWSI.Somemethodscombinegraph-basedapproacheswithtransformers,such
aspatch-GCN[18]andcgc-Net[19],toscoretheentireWSI.However,thesemethodsoftenfailtoexplicitlyidentify
salientregions.
Fromavisual-textualperspective,recentstudieshaveexploredtaskinferencethroughtextualdescriptionspairedwith
visual-linguisticsimilarities,proposingnewmethodsofinterpretability[3,4,5]. However,theseapproachesarenot
well-suited for gigapixel images[20]. Additionally, in current pathology practices, most paired image-text data is
availableonlyatthepatchlevel[4,21]. ThislimitationcomplicatesthedesignofWSI-levelinterpretablepredictive
modelsbasedsolelyonpatch-leveldescriptions. Pathologyreportdescriptionsareoftenincomplete,andtheimage-text
dataintextbooksisbothlimitedandprimarilypedagogical.
2.2 ComputationalEfficiency
Currently,WSIclassificationispredominantlyperformedusingmulti-instancelearning(MIL)[22],whichnecessitates
thecomputationofembeddingsforeachpatch. However,thelargenumberofpatchesperWSImakesthisapproach
computationallyexpensive,evenwhenfeatureextractorsarepre-trainedonauxiliarytasks[23]. Somemethods[24,25]
attempttoreducecomputationalburdenbyrandomlysamplingpatchesfromaWSIduringtraining; however, this
inevitably leads to information loss. Gao et al.[26] proposed a prediction rejection strategy based on efficiency
uncertainty,whichreducescomputationalburdenwhileefficientlyutilizingcriticalinformation.
2.3 ReinforcementLearningEnvironmentsintheMedicalDomain
Reinforcementlearningalgorithmshavefoundsuccessindiversedomains,includingboardgameslikeGo[27],video
gamessuchasAtari[28]andHonorofKings[12],aswellasinautonomousdriving[14]. However,extendingtheir
applicationtothemedicaldomainintroducesuniquechallenges. Historically,RLalgorithmshavebeeneffectivein
structured environments, such as Backgammon[29], Chess[30], and Go[27], where the rules are well-defined and
easilyencodedintoalgorithms. ThisspecificitymayconstraintheexplorationofRLalgorithmsinenvironmentsthat
requirelearningthroughinteraction. TheintroductionofOpenAIGymAPIshasfacilitatedthecreationofGYM-style
environmentsacrossvariousdomains,includingGym-preCICE[31]forphysicalAFCapplications,ScenarioGym[32]
forsafeautonomousdriving,OpenAIGym-like[33]environmentsforroboticsapplications,andPowerGym[34]for
powerdistributionsystems.
Indigitalpathologyfiled,Qaiseretal.[35]werethefirsttoapplyRLtothediscriminationofdiagnosticallyrelevant
regions in WSI, using immunohistochemical (IHC) scores of HER2 as a continuous learning task. Xu et al.[36]
optimizedthedeephybridattentionapproachwithreinforcementlearningtoachievehighclassificationaccuracywhile
significantlyreducingthenumberofrawpixelsused. Zhaoetal.[37]subsequentlydevelopedRLogist,enablingthe
agenttoexploredifferentresolutionstoproduceaconciseobservationpath. Buildingontheseadvancements,itis
crucialtoestablishastandardizedbenchmarkingenvironmentinpathology.
3 ProblemFormulation: FromClassificationtoReinforcementLearning
In whole slide image (WSI) analysis, traditional machine learning techniques like supervised learning[38], multi-
instance learning (MIL)[39, 40, 41, 42], and reinforcement learning (RL)[43] offer diverse approaches to address
medicalimagingchallenges. Thissectionoutlinesthetransitionfromclassification-basedmethodstoRL,highlighting
theadvantagesforWSIanalysis.
33.1 SupervisedLearning
SupervisedlearningisfoundationalinWSIanalysis[44],wheremodelsmapinputimagesXtolabelsY. Givena
datasetD ={(X ,Y )}N ,theobjectiveistominimizetheempiricalrisk:
i i i=1
N
1 (cid:88)
min L(f (X ),Y ), (1)
θ N θ i i
i=1
whereListypicallybinarycross-entropy. Thisparadigm,thougheffective,isstaticandreliesheavilyonlabeleddata.
3.2 Multi-instanceLearning
MILaddressesthechallengeoflabelinglargeWSIsbytreatingeachWSIasabagB ={x }Mi ofinstances(small
i i,j j=1
patches),withthebaglabeledpositiveifanyinstanceispositive:
Y = max f (x ), (2)
i θ i,j
j=1,...,Mi
MILoptimizesbag-levelpredictionsusingsmallpatchestogenerateslide-levelrepresentations,eliminatingtheneed
fordetailedinstancelabelingandreducingannotationburden[45].
3.3 ReinforcementLearningforWSIAnalysis
RLintroducesadynamicapproachtoWSIanalysis,framingitasanagent-environmentinteraction. TheWSIisthe
environment, and the agent’s goal is to maximize cumulative rewards through sequential actions. The problem is
modeledasaMarkovDecisionProcess(MDP)(S,A,P,R,γ):
• S: states,representingtheagent’spositionwithintheWSI.
• A: actions,suchaszoomingorpanning.
• P(s |s ,a ): statetransitions,deterministicinHistoGym.
t+1 t t
• R(s ,a ): rewards,basedondecisionaccuracy.
t t
• γ: discountfactor.
Theobjectiveistolearnapolicyπ (a |s )thatmaximizesexpectedcumulativerewards:
θ t t
(cid:34) T (cid:35)
(cid:88)
maxE γtR(s ,a ) , (3)
θ
πθ t t
t=0
RL’sactivelearningprocessoffersadaptivestrategiesforreal-timeWSIanalysis.
3.4 TransitiontoRL
TransitioningfromclassificationtoRLrepresentsashiftfrompassivepredictiontoactivedecision-making,wherethe
modelinteractsdynamicallywiththeWSIenvironment,optimizinglong-termoutcomesforimprovedanalysis.
4 HistoGymEnvironment
TheHistoGymenvironmentisaspecializedreinforcementlearningenvironmentdesignedfortheanalysisofwhole
slideimages,providingacomprehensiveplatformfordevelopingandtestingRLalgorithmsinmedicalimageanalysis.
ThissectionintroducesthecorecomponentsandfunctionalitiesofHistoGym,detailingitsintegrationwiththeFarama
Gymnasiumframework,thecustomizationofitsRLenvironmentclass,andtheflexibilityitoffersindefiningvarious
scenariosandobservationspaces,thusfacilitatingadvancedexperimentationandresearchindigitalpathology.
44.1 TheRLEnvironmentClass
GymEnvironmentClasses: TheFaramaGymnasium[46],originallyknownasOpenAI’sGymtoolkit[47],providesa
standardizedinterfacefordevelopingandtestingRLalgorithmsinPython. Thisstandardizationfacilitatestheseamless
integrationofvariousRLenvironments,includingHistoGym,intoestablishedresearchworkflows,enablingconsistent
andreproducibleexperimentation.
4.2 HistoGymEnvironmentClass
The HistoGym environment is a custom-designed RL environment tailored for the analysis of WSIs. It leverages
theOpenSlide[48]libraryforWSIprocessingandtheDeepZoomGeneratorfortilegeneration,allowingtheagentto
interactwiththeimagedataatmultiplemagnificationlevels.
Implementedasasubclassofgym.Env,HistoGymadherestothestandardGyminterface,whichensurescompatibility
withexistingRLframeworkssuchasStableBaselines3[49]andTianshou[50]. Thisdesignallowstheagenttonavigate
theWSIthroughaseriesofdiscreteactions,includingdirectionalmovements(up,down,left,right)andzoominginor
out.
TheHistoEnvclassisdesignedwithseveralkeyfeaturesthatarefundamentaltoitsfunctionality:
• StateandObservationSpace
• ActionSpace
• RewardMechanism
• EpisodeDynamics
Thesecomponentsarediscussedindetailinthefollowingsubsections,whereweexplorehoweachelementcontributes
totheoveralleffectivenessoftheHistoEnvframework.
4.3 RLFramework
To effectively implement and experiment with reinforcement learning algorithms in the HistoGym environment,
we employ several state-of-the-art RL frameworks, including stable_baselines3 [49], Tianshou [50]. These
frameworksofferarangeofpre-builtalgorithmsandtoolsfortrainingandevaluatingRLagents,facilitatingseamless
experimentationandbenchmarkingacrossdifferentRLstrategieswithinHistoGym.
4.4 EnvironmentComplexity&ScenarioofDifferentLevels
HistoGymsupportsmultiplescenarioswithvaryinglevelsofdetail,enablingresearcherstotailorexperimentstospecific
researchquestionsorapplicationneeds. Thesescenariosrangefrombasicsetupsfocusedonsimplenavigationand
scanningtaskstomorecomplexconfigurationsthatrequiresophisticateddecision-makingprocessesasshowninFigure
2. Designedtofacilitateacademicresearch,thesescenariosprovideacontrolledenvironmentwherehypothesesabout
RLstrategiesinWSIanalysiscanberigorouslytestedandvalidated.
Forexample,onescenariomightinvolvetheagentlearningtoprioritizeregionsoftheWSIthataremorelikelyto
containpathologicalfeatures,whileanothermightrequiretheagenttooptimizethescanningprocesstominimizethe
timerequiredfordiagnosis. Theflexibilityinscenariodesignallowsresearcherstoexploreawiderangeofchallenges
andsolutionswithintheRLframework.
4.5 State&Observations
IntheHistoGymenvironment,thestaterepresentsthecompletesetofinformationreturnedbytheenvironmentafteran
actionistaken. Thisincludesdatasuchastheagent’scurrentx,ypositionontheslide,thezoomlevelz,thetypeof
tissuebeinganalyzed,andthecurrentpixeldatafromtheWSI.
Anobservation,ontheotherhand,referstoanytransformationofthestatethatservesasinputtothecontrolalgorithms.
Observationsarecriticalforguidingtheagent’sdecision-makingprocess,anddifferentrepresentationscanbeemployed
dependingontheresearchfocus. Weproposethreedistinctobservationrepresentations:
• PixelSpace: Thisrepresentationutilizesrawpixeldatanormalizedfrom[0,255]toR∈[0,1],makingitthe
mostintuitivebutcomputationallyintensivemethod. Pixelspaceobservationsarevaluableforresearchthat
involvesfine-grainedanalysis,astheyprovideadirectviewoftheWSI.
5Figure2: HistoGymEnvironmentComplexity
• FeatureSpace: Inadditiontohigh-dimensionalRGBpixels,low-dimensionalembeddingfeaturesarealso
supported. WeleveragepretrainedfeatureextractorssuchasResNet[51]andCLAM[52]togeneratecompact
featurerepresentations:
– ResNetEmbedding: FeaturemapsgeneratedbyResNet[51]encodestructuralandtexturalinformation
aboutthetissue,capturingessentialcharacteristicsnecessaryforaccurateanalysis.
– CLAMEmbedding:TheCLAM[52]embeddingprovidesacompactvectorsummarizingvariousaspects
oftheWSI,includingtissuetype,celldensity,andspecificbiomarkers,makingitsuitableforscenarios
requiringmoreabstractrepresentations.
4.6 ActionSpace
TheHistoGymenvironmentdefinesaversatileactionspace,categorizedintotwoprimarytypes:discreteandcontinuous
actions.
• DiscreteActions: Theseincludestandardmovementactions(e.g.,up,down,left,right)withinthesamezoom
level, as well as actions to zoom in or out. In the initial version of the environment, actions were strictly
constrained,requiringtheagenttofollowdiscretesteps. Forexample,aftermovinginadirection,theagent
scanstheadjacentregion,andafterzoomingin,itfocusesonthenextlevelofdetailwithintheWSI.
• ContinuousActions: Toovercomethelimitationsofdiscreteactionsandbetterexploretheexpansivestate
space,weextendedtheactionspacetoincludecontinuousactions. Thisallowstheagenttoperformmore
granularadjustments,suchassmoothlyzoominginoroutandmakingfine-grainedmovementsacrossthe
slide. Continuousactionsareparticularlyusefulinoptimizingthescanningprocessandimprovingtheagent’s
overallperformance[53].
4.7 EpisodeDynamics
AnepisodeintheWSIanalysistaskisdefinedbythesequenceofactionstakenbytheagentfromthestartoftheslide
analysistothecompletionofthetask. Theepisodeconcludeswhentheagentsuccessfullyidentifiesthetargetregion
(e.g.,acancerousarea)orwhenapredefinedscanninglimit(e.g.,maximumnumberofsteps)isreached. Theagent’s
performanceacrossdifferentepisodescanbeanalyzedtoassessitslearningprogressandtheeffectivenessoftheRL
strategiesemployed[27].
4.8 Rewards
HistoGymsupportsbothsparseanddenserewardconfigurations,eachtailoredtodifferentanalysistasksandtissue
types. TherewardfunctionismanagedbytheCoor.check_overlapmodule,whichcalculatestherewardscorebased
ontheoverlapratiobetweentheagent’sboundingboxandthetargetregionwithintheWSI.Sparserewardsaregiven
6forachievingsignificantmilestones,suchasidentifyingthetargetregion,whiledenserewardsprovidecontinuous
feedbackbasedontheagent’sproximitytothetarget. Theseconfigurationsallowresearcherstoexploredifferentreward
structuresandtheirimpactontheagent’slearningprocess.
5 Example&Experiments
5.1 PythonExample
TheHistoGymenvironmentfollowsthewidelyusedFaramaGymnasiumAPI[46]. Belowweshowanexamplecode
thatrunsarandomagentonourenvironment. WeprovideanexampleforusingourenvironmentinListing1.Formore
detail,pleaserefertoAppendixandthegithubdocumentationpage.
5.2 ExperimentalSetup
Inthissection,wedetailtheexperimentalvalidationofstate-of-the-artdeepreinforcementlearningalgorithmswithin
theHistoGymenvironment. Wespecificallyfocusontwowidelyrecognizedalgorithms: ProximalPolicyOptimization
(PPO)[54],apolicygradientmethodknownforitsrobustness,andApe-XDQN[55],adistributedversionoftheDeep
Q-Network(DQN)[56]thatleveragesmodernadvancesindeeplearningforenhancedperformance.
All experiments utilized ResNet-based feature representations as inputs for observation and discrete actions. The
experiments were conducted using the stable-baselines3 [49] library, a widely used framework that ensures
consistencyandreproducibilityinreinforcementlearningresearch. Forfulldetailsonthetrainingsetup,including
architectureandhyperparameters,wereferthereadertoourGitHubrepository.
1 import numpy as np
2 import numpy as np
3 from gym_histo import HistoEnv
4
5 # Initialize Arguments
6 img_path =’/path/to/wsi.tif’
7 xml_path = ’/path/to/annotaion.xml’
8 tile_size = 128
9 result_path = ’./results’
10
11 env = HistoEnv(img_path, xml_path, tile_size, result_path)
12 obs = env.reset()
13
14 done = False
15 while not done:
16 action = env.action_space.sample()
17 obs, reward, done, info = env.step(action)
18 print(’action=’, action, ’info=’, info, ’reward=’, reward, ’done=’, done)
19 env.render(mode="human")
20 if done:
21 print("Episode Terminated", "reward=", reward)
22 break
Listing1: ExampleCodeforRunningaRandomAgentinHistoGym
5.3 ImpactofEnvironmentalComplexity
Theexperimentalresults,asdetailedinTable1,underscoretheprofoundinfluenceofenvironmentalcomplexityon
both training dynamics and the performance of agents in detecting cancerous regions within WSIs. We quantify
environmentalcomplexitybythenumberoflevelsintheWSI,utilizingopenslidetodefinetheeasy,medium,and
hardsettings,correspondingto3,5,and7levels,respectively. AsshowninFigure2,increasingthenumberoflevels
reducesthemagnificationbetweenlayers,therebyexpandingthesearchspaceandincreasingthedifficultyofthetask.
Inourstudy,wealsoinvestigatedtheperformanceofagentsunderdiscreteandcontinuousactionspaces. Notably,our
findingsrevealthatasenvironmentalcomplexitysurpassesthesimplelevel,vanillaPPOandDQNmodelsstruggleto
convergewhenoperatingwithcontinuousactions. Thisdivergencehighlightsacriticalareaforfurtherresearch,asit
suggeststhatthesemodelsmaybeill-suitedforhandlingcomplex,continuousdecisionspacesinWSIanalysis.
7Inscenarioscharacterizedbysimplerenvironmentsanddiscreteactionspaces,bothPPOandApe-XDQNwereable
to successfully identify cancerous regions within a reasonable number of timesteps. However, as the complexity
increased,neitherDQNnorPPOachievedconvergence. Thisperformancedegradationlikelystemsfromtheexpanded
searchspaceandthechallengesassociatedwithsparserewardsignalsinmoreintricateenvironments. Theinabilityof
thesemodelstoconvergeunderhighcomplexityconditionsindicatesthatcurrentapproachesmayrequiresubstantial
modificationsornovelstrategiestoeffectivelynavigateandanalyzecomplexWSIs."
Table1: Performanceunderdifferentenvironmentalcomplexities.
Env. Complexity Reward(PPO) Reward(DQN)
Cont. Discrete Cont. Discrete
Easy 0 18.4 0 8.7
Medium 0 11.3 <0 <0
Hard <0 <0 <0 <0
5.4 RepresentationLearningfromRawObservations
Anintriguingresearchdirectioninvolvestrainingreinforcementlearningagentsdirectlyfromrawpixeldata,amethod
thathasdemonstratedsuccessinsimplerenvironmentslikeAtari[56],butremainsparticularlychallenginginmore
complex domains such as histopathological image analysis. Within the HistoGym environment, we compared the
effectivenessofusingrawpixeldataagainstmoreabstractfeaturerepresentations,suchasthoseextractedbyResNet
andCLAM,asdetailedinTable2. Ourfindingssuggestthatsimultaneouslylearningthepolicyalongsidethefeature
extractorisdemandingandintroducesinstabilityintothemodel,whichwarrantsfurtherinvestigation.
Table2: ComparisonofrepresentationlearningapproachesinHistoGymusingCAMELYON16
Representation Reward(PPO) Reward(DQN)
Pixels <0 <0
ResNetFeatures 13.2 8.3
CLAMFeatures 16.2 8.5
6 Conclusion
Inthispaper,weintroducedHistoGym,anopen-sourcereinforcementlearningenvironmenttailoredforhistopathological
imageanalysis. Byreframingthediagnosticprocessasadecision-makingtask,HistoGymprovidesanovelplatformfor
exploringtheapplicationofRLinmedicalimaging,effectivelymirroringthereal-worldpracticesofpathologists. This
environmentnotonlyaddresseskeychallengesinWSIanalysis,suchashandlinghigh-dimensionaldataandintegrating
multi-scaleinformation,butalsolaysthegroundworkforfutureresearchinRLmethodologies. WebelieveHistoGym
willserveasavaluabletoolforadvancingthefieldofcomputationalpathology.
References
[1] MiaoCuiandDavidZhang. Artificialintelligenceandcomputationalpathology. LaboratoryInvestigation;a
JournalofTechnicalMethodsandPathology,101:412–422,2021.
[2] MuhammadKhalidKhanNiazi,AnilV.Parwani,andMetinN.Gurcan.Digitalpathologyandartificialintelligence.
TheLancet.Oncology,205:e253–e261,2019.
[3] Ming Y Lu, Bowen Chen, Andrew Zhang, Drew FK Williamson, Richard J Chen, Tong Ding, Long Phi Le,
Yung-SungChuang,andFaisalMahmood. Visuallanguagepretrainedmultipleinstancezero-shottransferfor
histopathologyimages. InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,
pages19764–19775,2023.
[4] Zhi Huang, Federico Bianchi, Mert Yuksekgonul, Thomas J Montine, and James Zou. A visual–language
foundationmodelforpathologyimageanalysisusingmedicaltwitter. Naturemedicine,29(9):2307–2316,2023.
8[5] EstelleAflalo,MengDu,Shao-YenTseng,YongfeiLiu,ChenfeiWu,NanDuan,andVasudevLal. Vl-interpret:
Aninteractivevisualizationtoolforinterpretingvision-languagetransformers. InProceedingsoftheIEEE/CVF
Conferenceoncomputervisionandpatternrecognition,pages21406–21415,2022.
[6] MikhailBinnewies,EdwardW.Roberts,KellyKersten,VincentChan,DouglasFearon,MiriamMerad,LisaM.
Coussens,DmitryI.Gabrilovich,SuzanneOstrand-Rosenberg,SuzanneOstrand-Rosenberg,CatherineC.Hedrick,
RobertH.Vonderheide,MikaelJ.Pittet,RakeshK.Jain,WeipingZou,ThomasK.Howcroft,ElisaC.Woodhouse,
RobertA.Weinberg,andMatthewF.Krummel. Understandingthetumorimmunemicroenvironment(time)for
effectivetherapy. NatureMedicine,24:541–550,2018.
[7] PhilipChikontwe,MeejeongKim,SooJeongNam,HeounjeongGo,andSangHyunPark. Multipleinstance
learningwithcenterembeddingsforhistopathologyclassification. InMedicalImageComputingandComputer
AssistedIntervention–MICCAI2020:23rdInternationalConference,Lima,Peru,October4–8,2020,Proceedings,
PartV23,pages519–528.Springer,2020.
[8] Fahdi Kanavati, Gouji Toyokawa, Seiya Momosaki, Michael Rambeau, Yuka Kozuma, Fumihiro Shoji, Koji
Yamazaki,SadanoriTakeo,OsamuIizuka,andMasayukiTsuneki. Weakly-supervisedlearningforlungcarcinoma
classificationusingdeeplearning. Scientificreports,10(1):9297,2020.
[9] ZeyuGao,BangyangHong,YangLi,XianliZhang,JialunWu,ChunbaoWang,XiangrongZhang,TieliangGong,
YefengZheng,DeyuMeng,etal. Asemi-supervisedmulti-tasklearningframeworkforcancerclassificationwith
weakannotationinwhole-slideimages. MedicalImageAnalysis,83:102652,2023.
[10] Jiangbo Shi, Chen Li, Tieliang Gong, Yefeng Zheng, and Huazhu Fu. Vila-mil: Dual-scale vision-language
multipleinstancelearningforwholeslideimageclassification. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages11248–11258,2024.
[11] Bolei Xu, Jingxin Liu, Xianxu Hou, Bozhi Liu, Jon Garibaldi, Ian O. Ellis, Andy Green, Linlin Shen, and
GuopingQiu. AttentionbySelection: ADeepSelectiveAttentionApproachtoBreastCancerClassification.
IEEETransactionsonMedicalImaging,39(6):1930–1941,2020.
[12] HuaWei,JingxiaoChen,XiyangJi,HongyangQin,MinwenDeng,SiqinLi,LiangWang,WeinanZhang,Yong
Yu,LiuLinc,etal. Honorofkingsarena: anenvironmentforgeneralizationincompetitivereinforcementlearning.
AdvancesinNeuralInformationProcessingSystems,35:11881–11892,2022.
[13] JacopoPanerati,HehuiZheng,SiqiZhou,JamesXu,AmandaProrok,AngelaP.SchoelligUniversityofToronto
Institute for A Studies, Vector Institute for Artificial Intelligence, and University of Cambridge. Learning to
fly—agymenvironmentwithpybulletphysicsforreinforcementlearningofmulti-agentquadcoptercontrol. 2021
IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS),pages7512–7519,2021.
[14] B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, Ahmad A Al Sallab, Senthil Yogamani, and
PatrickPérez. Deepreinforcementlearningforautonomousdriving: Asurvey. IEEETransactionsonIntelligent
TransportationSystems,23(6):4909–4926,2021.
[15] RamprasaathRSelvaraju,MichaelCogswell,AbhishekDas,RamakrishnaVedantam,DeviParikh,andDhruv
Batra. Grad-cam: Visualexplanationsfromdeepnetworksviagradient-basedlocalization. InProceedingsofthe
IEEEinternationalconferenceoncomputervision,pages618–626,2017.
[16] Grégoire Montavon, Sebastian Lapuschkin, Alexander Binder, Wojciech Samek, and Klaus-Robert Müller.
Explainingnonlinearclassificationdecisionswithdeeptaylordecomposition. Patternrecognition,65:211–222,
2017.
[17] ArioSadafi,OleksandraAdonkina,AshkanKhakzar,PeterLienemann,RudolfMatthiasHehr,DanielRueckert,
NassirNavab,andCarstenMarr. Pixel-levelexplanationofmultipleinstancelearningmodelsinbiomedicalsingle
cellimages. InInternationalConferenceonInformationProcessinginMedicalImaging,pages170–182.Springer,
2023.
[18] RichardJChen,MingYLu,MuhammadShaban,ChengkuanChen,TiffanyYChen,DrewFKWilliamson,and
FaisalMahmood. Wholeslideimagesare2dpointclouds: Context-awaresurvivalpredictionusingpatch-based
graphconvolutionalnetworks. InMedicalImageComputingandComputerAssistedIntervention–MICCAI2021:
24thInternationalConference,Strasbourg,France,September27–October1,2021,Proceedings,PartVIII24,
pages339–349.Springer,2021.
[19] YanningZhou, SimonGraham, NavidAlemiKoohbanani, MuhammadShaban, Pheng-AnnHeng, andNasir
Rajpoot. Cgc-net: Cell graph convolutional network for grading of colorectal cancer histology images. In
ProceedingsoftheIEEE/CVFinternationalconferenceoncomputervisionworkshops,pages0–0,2019.
[20] ChunyuanLi,CliffWong,ShengZhang,NaotoUsuyama,HaotianLiu,JianweiYang,TristanNaumann,Hoifung
Poon,andJianfengGao. Llava-med: Trainingalargelanguage-and-visionassistantforbiomedicineinoneday.
AdvancesinNeuralInformationProcessingSystems,36,2024.
9[21] MingYLu,BowenChen,DrewFKWilliamson,RichardJChen,IvyLiang,TongDing,GuillaumeJaume,Igor
Odintsov,LongPhiLe,GeorgGerber,etal. Avisual-languagefoundationmodelforcomputationalpathology.
NatureMedicine,30(3):863–874,2024.
[22] AndrewHSong,GuillaumeJaume,DrewFKWilliamson,MingYLu,AnuragVaidya,TiffanyRMiller,and
FaisalMahmood. Artificialintelligencefordigitalandcomputationalpathology. NatureReviewsBioengineering,
1(12):930–949,2023.
[23] MuhammadShaban,RuqayyaAwan,MuhammadMoazamFraz,AyeshaAzam,Yee-WahTsang,DavidSnead,
andNasirMRajpoot. Context-awareconvolutionalneuralnetworkforgradingofcolorectalcancerhistology
images. IEEEtransactionsonmedicalimaging,39(7):2395–2405,2020.
[24] ElleryWulczyn,DavidFSteiner,ZhaoyangXu,ApaarSadhwani,HongwuWang,IsabelleFlament-Auvigne,
Craig H Mermel, Po-Hsuan Cameron Chen, Yun Liu, and Martin C Stumpe. Deep learning-based survival
predictionformultiplecancertypesusinghistopathologyimages. PloSone,15(6):e0233678,2020.
[25] Ellery Wulczyn, David F Steiner, Melissa Moran, Markus Plass, Robert Reihs, Fraser Tan, Isabelle Flament-
Auvigne,TrissiaBrown,PeterRegitnig,Po-HsuanCameronChen,etal. Interpretablesurvivalpredictionfor
colorectalcancerusingdeeplearning. NPJdigitalmedicine,4(1):71,2021.
[26] ZeyuGao,AnyuMao,JialunWu,YangLi,ChunbaoWang,CaixiaDing,TieliangGong,andChenLi.Uncertainty-
basedmodelaccelerationforcancerclassificationinwhole-slideimages. In2022IEEEInternationalConference
onBioinformaticsandBiomedicine(BIBM),pages1534–1538.IEEE,2022.
[27] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Hubert
Thomas,TimothyLillicrap,AndrzejMadry,andDemisHassabis. Masteringthegameofgowithdeepneural
networksandtreesearch. Nature,529(7587):484–489,2016.
[28] LukaszKaiser,MohammadBabaeizadeh,PiotrMilos,BlazejOsinski,RoyHCampbell,KonradCzechowski,
DumitruErhan,ChelseaFinn,PiotrKozakowski,SergeyLevine,etal. Model-basedreinforcementlearningfor
atari. arXivpreprintarXiv:1903.00374,2019.
[29] GeraldTesauro. Td-gammon,aself-teachingbackgammonprogram,achievesmaster-levelplay. Neuralcomputa-
tion,6(2):215–219,1994.
[30] Feng-HsiungHsu. BehindDeepBlue: Buildingthecomputerthatdefeatedtheworldchesschampion. Princeton
UniversityPress,2002.
[31] JohanLarsson,HansWestergren,BirgittaHäggman-Henrikson,AurelijaIlgunas,AndersWänman,andEva-Maj
Malmström. Thefeasibilityofgym-basedexercisetherapyforpatientswithpersistentneckpain. Scandinavian
JournalofPain,20(2):261–272,2020.
[32] HamishScott,LorenzoNiccolini,ChessStetson,NilsGoldbeck,IoannisSouflas,NoyanSongur,AlirezaAhrabian,
EduardoCandela,andPanagiotisAngeloudis. Scenariogym: Ascenario-centriclightweightsimulator. In2023
IEEE26thInternationalConferenceonIntelligentTransportationSystems(ITSC),pages5216–5222.IEEE,2023.
[33] JacopoPanerati,HehuiZheng,SiQiZhou,JamesXu,AmandaProrok,andAngelaPSchoellig. Learningtofly—a
gymenvironmentwithpybulletphysicsforreinforcementlearningofmulti-agentquadcoptercontrol. In2021
IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS),pages7512–7519.IEEE,2021.
[34] Ting-HanFan,XianYeowLee,andYuboWang. Powergym: Areinforcementlearningenvironmentforvolt-var
controlinpowerdistributionsystems. InLearningforDynamicsandControlConference,pages21–33.PMLR,
2022.
[35] TalhaQaiserandNasirMRajpoot. Learningwheretosee: anovelattentionmodelforautomatedimmunohisto-
chemicalscoring. IEEEtransactionsonmedicalimaging,38(11):2620–2631,2019.
[36] BoleiXu,JingxinLiu,XianxuHou,BozhiLiu,JonGaribaldi,IanOEllis,AndyGreen,LinlinShen,andGuoping
Qiu. Look,investigate,andclassify: adeephybridattentionmethodforbreastcancerclassification. In2019IEEE
16thinternationalsymposiumonbiomedicalimaging(ISBI2019),pages914–918.IEEE,2019.
[37] BoxuanZhao,JunZhang,DehengYe,JianCao,XiaoHan,QiangFu,andWeiYang. Rlogist: fastobservation
strategyonwhole-slideimageswithdeepreinforcementlearning. InProceedingsoftheAAAIConferenceon
ArtificialIntelligence,volume37,pages3570–3578,2023.
[38] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.
deeplearningbook.org.
[39] MingY.Lu,DrewF.K.Williamson,TiffanyY.Chen,RichardJ.Chen,MatteoBarbieri,andFaisalMahmood.
Data-efficient and weakly supervised computational pathology on whole-slide images. Nature Biomedical
Engineering,5:555–570,2020.
10[40] RuiAguiarandJonBraatz. SelectingRegionsofInterestinLargeMulti-ScaleImagesforCancerPathology.
arixv,2020.
[41] MaximilianIlse, JakubM.Tomczak, andMaxWelling. Attention-baseddeepmultipleinstancelearning. In
InternationalConferenceonMachineLearning,2018.
[42] BinLi,YinLi,andKevinW.Eliceiri. Dual-streammultipleinstancelearningnetworkforwholeslideimage
classificationwithself-supervisedcontrastivelearning. 2021IEEE/CVFConferenceonComputerVisionand
PatternRecognition(CVPR),pages14313–14323,2020.
[43] RichardSSuttonandAndrewGBarto. Reinforcementlearning: Anintroduction. MITpress,2018.
[44] GeertLitjens,ThijsKooi,BabakEhteshamiBejnordi,ArnaudArindraAdiyosoSetio,FrancescoCiompi,Mohsen
Ghafoorian,JeroenAWMVanDerLaak,BramVanGinneken,andClaraISánchez. Asurveyondeeplearningin
medicalimageanalysis. Medicalimageanalysis,42:60–88,2017.
[45] Oded Maron and Tomas Lozano-Perez. A framework for multiple-instance learning. In Neural Information
ProcessingSystems,1997.
[46] MarkTowers,ArielKwiatkowski,JordanTerry,JohnUBalis,GianlucaDeCola,TristanDeleu,ManuelGoulão,
AndreasKallinteris,MarkusKrimmel,ArjunKG,etal. Gymnasium: Astandardinterfaceforreinforcement
learningenvironments. arXivpreprintarXiv:2407.17032,2024.
[47] GregBrockman,VickiCheung,LudwigPettersson,JonasSchneider,JohnSchulman,JieTang,andWojciech
Zaremba. Openaigym. 2016.
[48] Adam Goode, Benjamin Gilbert, Jan Harkes, Drazen Jukic, and Mahadev Satyanarayanan. Openslide: A
vendor-neutralsoftwarefoundationfordigitalpathology. JournalofPathologyInformatics,4,2013.
[49] AntoninRaffin,AshleyHill,AdamGleave,AnssiKanervisto,MaximilianErnestus,andNoahDormann. Stable-
baselines3:Reliablereinforcementlearningimplementations.JournalofMachineLearningResearch,22(268):1–8,
2021.
[50] JiayiWeng,HuayuChen,DongYan,KaichaoYou,AlexisDuburcq,MinghaoZhang,YiSu,HangSu,andJun
Zhu. Tianshou:Ahighlymodularizeddeepreinforcementlearninglibrary. JournalofMachineLearningResearch,
23(267):1–6,2022.
[51] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimagerecognition. In
ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition,pages770–778,2016.
[52] MingY.Lu,DrewF.K.Williamson,TiffanyY.Chen,RichardJ.Chen,MatteoBarbieri,andFaisalMahmood.
Data-efficient and weakly supervised computational pathology on whole-slide images. Nature Biomedical
Engineering,5:555–570,2020.
[53] VolodymyrMnih,AdriaPuigdomenechBadia,MehdiMirza,AlexGraves,TimHarley,TimothyLillicrap,David
Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International
ConferenceonMachineLearning,pages1928–1937.PMLR,2016.
[54] JohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov. Proximalpolicyoptimization
algorithms. ArXiv,abs/1707.06347,2017.
[55] DanHorgan,JohnQuan,DavidBudden,GabrielBarth-Maron,MatteoHessel,H.V.Hasselt,andDavidSilver.
Distributedprioritizedexperiencereplay. ArXiv,abs/1803.00933,2018.
[56] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and
MartinA.Riedmiller. Playingatariwithdeepreinforcementlearning. ArXiv,abs/1312.5602,2013.
Appendix
classHistoEnv(gym.Env)
Customenvironmentforhistologyimageanalysis.
Parameters:
• img_path (str): Pathtothehistologyimagefile.
• xml_path (str): PathtotheXMLfilecontainingannotations.
• tile_size (int): Sizeofthetilesusedforanalysis.
• result_path (str): Pathtosavetheresultingimages.
11Attributes:
• UP (int): Actioncodeformovingup.
• DOWN (int): Actioncodeformovingdown.
• LEFT (int): Actioncodeformovingleft.
• RIGHT (int): Actioncodeformovingright.
• ZOOM_IN (int): Actioncodeforzoomingin.
• ZOOM_OUT (int): Actioncodeforzoomingout.
• STAY (int): Actioncodeforstayinginthesameposition.
• img_path (str): Pathtothehistologyimagefile.
• xml_path (str): PathtotheXMLfilecontainingannotations.
• tile_size (int): Sizeofthetilesusedforanalysis.
• result_path (str): Pathtosavetheresultingimages.
• plt_size (int): Sizeoftheplot.
• slide (openslide.OpenSlide): OpenSlideobjectforreadingthehistologyimage.
• dz (DeepZoomGenerator): DeepZoomGeneratorobjectforgeneratingtiles.
• dz_level (int): InitialDeepZoomlevel.
• OBS_W (int): Observationwidth.
• OBS_H (int): Observationheight.
• STATE_W (int): Statewidth.
• STATE_H (int): Stateheight.
• coor_xml (Coor): CoorobjectforparsingXMLannotations.
• coor_dz_all (Coor): CoorobjectforgettingDeepZoomcoordinates.
• segment_dz_all (Coor): Coorobjectforgettingsegmentcoordinates.
• if_overlap (bool): Flagindicatingifthereisoverlap.
• overlap_seg_index (int): Indexoftheoverlappingsegment.
• overlap_ratio (float): Ratioofoverlap.
• n_actions (int): Numberofactions.
• action_space (gym.spaces.Discrete): Actionspace.
• observation_space (gym.spaces.Box): Observationspace.
• agent_pos (list): Agentpositionintheform[z,x,y].
• STATE_D (int): InitialDeepZoomlevelforsettingbounds.
• state (numpy.ndarray): Currentstate.
• count (int): Stepcountwithintheepisode.
• max_step (int): Maximumnumberofstepsperepisode.
• bound (list): Listofbounds.
Methods:
• __init__(self, img_path, xml_path, tile_size, result_path): Initializestheenvironment.
• reset(self): Resetstheenvironmentandreturnstheinitialstate.
• step(self, action): Takesastepintheenvironmentbasedonthegivenaction.
• render(self, mode="save"): Rendersthecurrentstateoftheenvironment.
12