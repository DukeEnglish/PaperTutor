PEDAL: Enhancing Greedy Decoding with Large Language Models using
Diverse Exemplars
SumanthPrabhu
sumanth@parsimoai.com
Abstract further improvement in LLM reasoning, (Wang
et al., 2022) proposed a self-ensembling tech-
Self-ensembling techniques with diverse rea-
nique termed “Self-Consistency”(SC) where di-
soning paths such as Self-Consistency have
verse“Chain-of-Thought”(CoT)(Weietal.,2022)
demonstratedremarkablegainsinaccuracyfor
Large Language Models (LLMs). However, reasoning paths were generated and then aggre-
suchtechniquesdependontheavailabilityof gatedtoconstructanaccurateandreliableresponse.
anaccurateanswerextractionprocesstoaggre- This approach has been successfully extended to
gateacrossmultipleoutputs. Moreover, they various use-cases such as LLM hallucination de-
acquire higher inference cost, in comparison
tection (Chen et al., 2024), medicine(Zhou et al.,
toGreedyDecoding,duetogenerationofrel-
2024)andcodegeneration(Huangetal.,2024).
atively higher number of output tokens. Re-
WhileSCbasedapproachescansignificantlyim-
search has shown that the free form text out-
putsfromSelf-Consistencycanbeaggregated provetherobustnessofLLMoutputs,oneoftheir
reliablyusingLLMstoproducethefinalout- commondrawbacksisthattheyperformbestona
put.Additionally,recentadvancementsinLLM fixedanswerset(Wangetal.,2022)orrelyontrain-
inferencehavedemonstratedthatusageofdi- ing custom aggregation methods to measure con-
verse exemplars in prompts have the ability
sistency across multiple text outputs. To address
toinducediversityintheLLMoutputs. Such
this,(Chenetal.,2023b)proposed“UniversalSelf
proven techniques can be easily extended to
Consistency”(USC), an extension of SC, that ag-
self-ensemblingbasedapproachestoachieve
gregatedthetextoutputsbyre-invokingtheLLM.
enhancedresultsintextgeneration. Inthispa-
per,weintroducePEDAL(Promptsbasedon Essentially,USCpromptedtheLLMtoselectthe
ExemplarDiversityAggregatedusingLLMs), mostconsistentresponseamongthedifferentcan-
ahybridself-ensemblingapproach,thatcom- didateanswersgeneratedbySCanddemonstrated
binesthestrengthsofdiverseexemplarbased that it can achieve improved performance. How-
promptsandLLMbasedaggregationtoachieve
ever,thisstillleavesuswithanotherdrawbackof
improvementinoverallperformance. Onthe
SCwhichisthecostinvolvedingeneratingtheout-
publiclyavailableSVAMPandARCdatasets,
puts. Concretely,SCinvolvesgeneratinglongand
ourexperimentsrevealthatPEDALcanachieve
better accuracy than Greedy Decoding based diverse reasoning paths which results in a higher
strategieswithlowerinferencecostcompared numberofoutputtokenscomparedtoGreedyDe-
toSelfConsistencybasedapproaches. codingbasedapproaches. Thecostofoutputtoken
generationwithLLMsistypicallymorethaninput
1 Introduction
tokenprocessingduetothedifferenceinthenum-
Large Language Models (LLMs) (Brown et al., berofforwardpasses(Shazeer,2019;Chng,2024)
2020;Raffeletal.,2020;Chowdheryetal.,2022; resultinginahigherinferencecostwithSC.
Touvron et al., 2023) have been proven to show (Li et al., 2023b) experimented with usage of
remarkable performance in a wide range of Nat- diverse exemplars in the LLM prompts and com-
ural Language Understanding tasks (Zhao et al., binedthemwithdiversereasoningpathsinSCto
2023) as a result of their outstanding reasoning achieve more accurate results in text generation.
capabilities (Wei et al., 2022; Zhou et al., 2022). Weobservethatifweleveragediverseexemplars
However, they still rely on carefully designed withGreedyDecodingfortextgenerationandag-
promptstoachieveoptimalperformance(Khattab gregatetheresponsesasinUSC,weachievebetter
et al., 2023; Fernando et al., 2023). To achieve performancethantraditionalGreedyDecodingin
4202
guA
61
]LC.sc[
1v96880.8042:viXratermsofaccuracywhilealsoachievinglowercost todiversereasoningpaths.
ofinferenceincomparisontoSCbasedapproaches.
2.2 PromptEnsemblingStrategies
In this paper, we present a hybrid self-
ensemblingapproach,PEDAL(Promptsbasedon With the advent of LLMs, lot of research fo-
Exemplar Diversity Aggregated using an LLM), cused on developing effective prompting tech-
thatoffersatrade-offbetweentheGreedyDecod- niques (Bach et al., 2022; Lu et al., 2022) that
ing and SC in terms of accuracy and cost effi- have been extended by multiple prompt ensem-
ciency. We leverage diverse exemplars in LLM bling techniques (Zhang et al., 2023; Pitis et al.,
promptstogeneratemultiplecandidateresponses 2023) to achieve further improvement. (Singh
usingGreedyDecodingandthenaggregatethem et al., 2023) built a decision tree of prompts that
usinganLLMtogeneratethefinalresponse. On links multiple LM calls to solve a task. (Arora
two publicly available datasets, we demonstrate et al., 2022) used multiple prompt templates to
thatPEDALachievesbetteraccuracythanGreedy reformat few-shot example inputs into an open
Decodingbasedstrategiesandofferslowercostin endedquestion-answeringformatandthenleverage
inferencecomparedtoSCbasedstrategies. WeakSupervision(Ratneretal.,2017)toaggregate
Rest of the paper is organized as follows: In the LLM predictions. (Hou et al., 2023) applied
Section2,wedescribepreviousworkforsolving AdaBoost (Schapire, 2013) algorithm over a pre-
similarproblems. Section3explainsourproposed definedpromptsetfortextclassificationbypairing
strategyindetailfollowedbySection4wherewe prompts with the corresponding output distribu-
describe the data and the experiment settings to tiontoconstructalargepoolofweaklearners. (Li
validatePEDAL.Wethenpresentourresultsand etal.,2023b)enhancedSCwithdiversepromptsby
analyses in Section 5. Finally, in Section 6, we randomlyselectingdifferentexemplarsforprompt
summarizeourfindingsanddiscusspotentialfuture construction,followedbysamplingreasoningpaths
work. foreachsuchpromptandthenscoringthequalityof
eachreasoningpathusingacustomtrainedmodel.
2 RelatedWork While our work also leverages a similar prompt
constructionstrategy,weaggregatethepredictions
LLMshavebeenwidelystudiedandappliedin a
withoutrelyingonexplicitlytrainingatask-specific
varietyoftasksincludingcodegeneration(Zheng
model. Additionally,wefocusonleveragingsuch
etal.,2024),finance(Lietal.,2024),law(Yuetal.,
promptbasedstrategiestoreduceLLMinference
2022)andsoon. However,noneoftheLLMsseem
costratherthanenhancingSCbasedapproaches.
to consistently outperform the rest of the models
across all tasks (Jiang et al., 2023). This led to 2.3 LLMInferenceCost
exploringensemblingapproacheswithLLMs. Re-
Tosolvetheproblemofinferencecost,researchers
searchfocusedonPromptChaining(Chase,2022),
havecommonlyexploredmodelcompressiontech-
Fusion(Lietal.,2023a),MixtureofExperts(Cai
niques(Zhuetal.,2024)suchasmodelquantiza-
etal.,2024)andmanymorehaveshownpromising
tion (Jacob et al., 2018), model pruning (Cheng
resultsincombiningLLMstoenhancetheoverall
et al., 2024) and model distillation (Gou et al.,
performance.
2021)aimedatreducingthesizeofthemodelwith-
outhurtingtheperformancesignificantly. (Shazeer,
2.1 SelfEnsemblingStrategies
2019)proposedsharingkeysandvaluesacrossall
(Long, 2023; Yao et al., 2023) generalized CoT ofthedifferentattentionheadsinthetransformer
toorganizelanguagemodelgenerated“thoughts” architecture,thus,reducingthememorybandwidth
intoatreestructureforsolutionsearch. However, requirementsofincrementaldecoding. (Wuetal.,
similarto(Wangetal.,2022),theyrelyoncustom 2024) explored decoding multiple successive to-
aggregationmethodstoconstructthefinaloutput. kens simultaneously in a single forward pass to
(Chenetal.,2023b)addressedthisissuebylever- reducetheinferencetime. FrugalGPT(Chenetal.,
agingLLMstoperformmajorityconsensusbased 2023a)proposedacascadeofLMsthatstopswhen
aggregationwithoutanyspecificmodelfine-tuning. anintermediateoutputisconsideredreliable,result-
Inourwork,weleverageasimilarstrategytoag- inginbettercomputationalefficiency. Inourwork,
gregate multiple candidates with a focus on the wefocusonreducingthenumberofoutputtokens
impactofusingdiverseLLMpromptsasopposed duringLLMinferenceincomparisontoSCwhilePrompts with Diverse Exemplars Candidate Responses Final Response
Greedy Decoding Aggregation using
using LLM LLM
Figure1: HighleveloverviewofPEDAL(PromptsbasedonExemplarDiversityAggregatedusinganLLM)
achievingbetteraccuracythanGreedyDecoding. science exams from grade 3 to grade 9 and
isfurthersplitintwopartitions-‘ARC-Easy’
3 Methodology
and‘ARC-Challenge’where‘ARC-Challenge’
partition contains relatively more difficult
Figure 1 shows the high level overview of our
questionsthatrequirereasoning
proposed system. The LLM generates multiple
candidateresponsesusingGreedyDecodingwith
Wereportresultsonthevalidationsplitofeach
prompts based on diverse exemplars. The candi-
dataset. We restrict the ARC dataset to ‘ARC-
dateresponsesarethenaggregatedusingthesame
Challenge’ only and work with 30% of the data
LLMtogeneratethefinaloutput.
sampled at random. Table 1 captures the corre-
spondingdetailsofthevalidationdatasetsconsid-
3.1 PromptswithDiverseExemplars
eredfortheexperimentsinthepaper.
TraditionalCoTbasedapproachesrelyonasingle
promptcomprisedofafixedsetofexemplars. (Li DatasetName Number of Validation
et al., 2023b) showed that constructing multiple Samples
prompts, by modifying the exemplars chosen for SVAMP 300
thepurposeofIn-Context-Learning(ICL),further ARC 345
enhancesthereasoningcapabilityoflanguagemod-
els. Onsimilarlines,weconstructmultipleLLM Table1: ValidationdatasetsizeforSVAMPandARC
promptsbyrandomlysamplingtheexemplarsfor datasets
ICL multiple times using different seed settings.
ForeachsuchLLMprompt,wegenerateacandi-
4.2 BaselineStrategies
dateresponseusingGreedyDecoding.
Tobenchmarkourapproach,PEDAL,weinclude
3.2 LLM-basedAggregation thefollowingbaselines
USC(Chenetal.,2023b)thathasbeenshowntoac-
• GreedyDecoding-WeruntheLLMtoselect
curatelyselectthemostconsistentresponseamong
thetokenwiththehighestprobabilityateach
multiple SC responses using majority consensus.
steptogeneratethefinaloutput.
WefollowUSCandextractthefinalresponsefrom
multiplecandidateresponsesaccordingly.
• USC - We run SC with CoT prompting and
select the most consistent answer among all
4 Experiments
candidateresponsesusingthesameLLM.
4.1 Dataset
• UnifiedDiverseExemplars-Tounderstand
Weconsidertwopubliclyavailabledatasetsforthe
the impact of multiple candidate responses
purposeofourexperiments-
generated in PEDAL using diverse prompts,
we combine all such diverse exemplars di-
• SVAMP (Patel et al., 2021) Comprises of
rectly into a single ICL prompt and run
elementary-levelMathWordProblems. Each
GreedyDecoding. Werefertothisbaselineas
problemconsistsofashortnaturallanguage
“UnifiedDiverseExemplars”(UDE).
narrative that describes a state of the world
and poses a question about some unknown
4.3 ExperimentSetting
quantities.
Each of the strategies were run using Qwen2-
• AI2 Reasoning Challenge (ARC) (Clark 7B-Instruct (Yang et al., 2024) and Llama-3-8B-
et al., 2018) is a multiple-choice question- Instruct (Touvron et al., 2023). We measure the
answeringdataset,containingquestionsfrom performance using accuracy and the number ofoutputtokens. Forpurposesofreporting,wealso Model Approach TokenCount
sharethenumberofinputtokensconsumedbythe Input Output
strategies. The LLMs were run using 4-bit quan- USC 902.89 ± 502.75 ±
Qwen2
tization(Dettmersetal.,2023). Eachexperiment 2.16 1.43
isrununderthreerandomseedsettingsforrepro- PEDAL 1342.18 191.99 ±
ducibility. Wepickthreeexemplarsperexperiment ±86.87 0.22
fortheIn-ContextLearning(ICL)promptconstruc- USC 693.46 ± 923.56 ±
Llama3
tionwitheachdataset. Foreachexperiment,USC 8.79 1.51
is run to generate three intermediate outputs and PEDAL 1261.51 197.72 ±
PEDALisrunwiththreediverseinputprompts. ±64.95 0.2
Model Approach Accuracy Table3: PerformancecomparisonofUSCandPEDAL
forSVAMPdatasetusingthenumberofoutputtokens.
Greedy 76.0±1.52
Averagedcountsacross3seedsarereportedalongwith
USC 80.33±0.98
Qwen2 the standard deviation. Best performing strategy per
UDE 75.67±0.0
modelhasbeenhighlightedinbold
PEDAL 77.89±1.28
Greedy 70.22±1.03
USC 72.99±0.47 lesser than PEDAL while UDE achieves an ac-
Llama3
UDE 70.67±0.0 curacy70.67%marginallyoutperformingGreedy
PEDAL 74.11±0.57 Decoding.
As shown in Table 3, with Qwen2, USC pro-
Table2: PerformancecomparisonofGreedyDecoding, cesses approximately 903 input tokens and 503
USC,UDEandPEDALforSVAMPdatasetusingAccu-
outputtokenswhilePEDALprocesses1,343input
racy. Averagedscoresacross3seedsarereportedalong
tokenswith192outputtokensmakingourapproach
withthestandarddeviation. Bestperformingstrategy
evidentlymorecostefficient. WithLlama3,USC
permodelhasbeenhighlightedinbold
processesanaverageof694inputtokensand924
outputtokenswhilePEDALprocesses1,262input
5 ResultsandAnalysis tokensand198outputtokens. WhileUSCrelieson
lesserinputtokensthanPEDAL,thecostofoutput
Table 2 and Table 3 show the performance met- tokenswithUSCismorethan4timestheoutput
ricsfordifferentstrategiesusingSVAMPdataset. tokencostwithPEDALmakingourapproachmore
Similarly,Table4andTable5capturetheperfor- costefficient.
mance metrics for the ARC dataset. We observe
thatourproposedapproachconsistentlyperforms 5.2 Multiple-ChoiceQuestionAnswering
betterthanGreedyDecodingintermsofaccuracy
As shown in Table 4, the strategies show a simi-
and outperforms USC in terms of the number of
larrelationshipwithexperimentsrunontheARC
outputtokens.
5.1 ArithmeticReasoning Model Approach Accuracy
Greedy 83.38±0.55
As shown in Table 2, PEDAL displays improve-
USC 84.35±0.62
mentoverGreedyDecodingontheSVAMPdataset. Qwen2
UDE 84.06±0.0
With Qwen2, PEDAL achieves an average accu-
PEDAL 83.77±0.47
racyof77.89%whileGreedyDecodingachieves
Greedy 76.52±1.44
anaverageaccuracyof76%implyinga1.89%im-
USC 71.88±0.71
provement. PEDALalsooutperformsUDEwhich Llama3
UDE 76.52±0.0
achieves an accuracy of 75.67%. USC achieves
PEDAL 78.55±0.47
the accuracy of 80.33%. Similarly, with Llama3,
weobservethatPEDALachievesanaverageaccu-
Table4: Performancecomparisonofgreedydecoding,
racyof74.11%whileGreedyDecodingachieves USC,UDEandPEDALforARCdatasetusingAccu-
a score of 70.22% resulting in 3.89% improve- racy. Averagedscoresacross3seedsarereportedalong
ment. However, with Llama3, we observe that withthestandarddeviation. Bestperformingstrategy
USC achieves an accuracy of 72.99% which is permodelhasbeenhighlightedinbolddataset. WithQwen2,PEDALachievesamarginal Number SVAMP ARC
improvement of 0.39% over Greedy Decoding of
withanaverageaccuracyof83.77%whileGreedy Prompts
Decoding has an average accuracy of 83.38%. 2 77.0±0.98 83.96±0.36
UDE outperforms PEDAL with an accuracy of 3 77.89±1.28 83.77±0.47
84.06% while USC still achieves the best perfor- 4 78.22±1.34 83.87±0.49
mancewithanaccuracyof84.35%. WithLlama-3,
Table6: Effectofnumberofpromptsonperformance
PEDALshowsa2.03%improvementwithascore
using Qwen2 with SVAMP and ARC datasets. Aver-
of78.55%andgreedydecodingachieves76.52%.
agedscoresacross3seedsarereportedalongwiththe
UDE achieves an accuracy of 76.52% matching
standarddeviation.
theperformanceofGreedyDecoding. Surprisingly,
USCachievesanaccuracyof71.88%whichisrel-
ativelytheleastamongthestrategies. WithUSC, gleintermediateoutputinSC(equivalenttoCoT)
themaingoalofthepaperistobenchmarkthepro- withthenumberofoutputtokensinPEDAL.With
posedapproachintermsoftokencount. Toprevent Llama3, weobservethatPEDALwouldbemore
diverging from the primary focus area, we leave costefficientforbothdatasets. WithQwen2,weob-
deeperanalysisofthisbehaviourtofuturework. servethatPEDALwouldbemorecostefficientfor
AsshowninTable5,withQwen2,ourapproach theARCdatasetbutmayprovetobemoreexpen-
outperforms USC where USC processes roughly sivefortheSVAMPdatasetincomparisontoCoT.
1,154inputtokensand669outputtokensonanav- WhilePEDALseemstobemorereliablyconsistent,
eragewhilePEDALprocesses1,180inputtokens it would be interesting to further investigate and
with 100 output tokens. With Llama3, USC pro- arriveatdefinitiveconclusions. Weintendtoeval-
cesses 1,073 input tokens and 929 output tokens uatethemeritsanddrawbacksofbothapproaches
whilePEDALprocesses1,186inputtokensand197 inapracticalsettinginfuturework.
outputtokens. Ourapproachisthebetterchoicein
5.4 ImpactofNumberofDiversePrompts
termsofthenumberofoutputtokensprocessedby
We re-run the experiments for both datasets with
theLLM.
our best performing model, Qwen2, by varying
5.3 ComparisontoCoT thenumberofpromptstostudyhowitaffectsthe
performance. As shown in Table 6, we addition-
SimilartoPEDAL,CoThasbeenshowntobemore
allyruntheexperimentsfortwoandfourdiverse
accuratethanGreedyDecodingandlessexpensive
prompts under three seed settings. We observe
in terms of inference compared to SC. Based on
slightimprovementsasweincreasethenumberof
pre-liminary interpolation of the number of out-
promptswiththeSVAMPdataset. However,wedo
puttokensusingTable3andTable5,wecompare
notobserveanysuchspecificpatternwiththeARC
the number of output tokens consumed in a sin-
dataset.
Model Approach TokenCount 6 Conclusion
Input Output
In this paper, we explored self-ensembling with
USC 1153.04 668.71 ±
Qwen2 LLMs using diverse exemplars with LLM based
±1.96 7.19
outputaggregation. Weobservedthatthiscombi-
PEDAL 1179.76 99.47 ±
nationcanperformbetterthanGreedyDecodingin
±100.10 10.05
termsofaccuracyandachievebettercostefficiency
USC 1072.96 928.1 ±
Llama3 thanSCbasedmethods. However,werestrictedthe
±5.67 1.31
experimentstosmalldatasetsthatallowedbench-
PEDAL 1185.27 196.83 ±
markingapproachesusingexactmatchwithoutad-
±115.08 0.11
ditionalmanualannotationefforts. Infuturework,
weplantoexplorepossibilitiesonextendingsuch
Table5: PerformancecomparisonofUSCandPEDAL
for ARC dataset using the number of output tokens. ensemblingstrategiestoawiderrangeofproblem
Averagedcountsacross3seedsarereportedalongwith settingsinvolvingfree-formtextgenerationtofur-
the standard deviation. Best performing strategy per therdeepdiveintostrengthsandweaknessesofour
modelhasbeenhighlightedinbold proposedsystem.References AakankshaChowdhery,SharanNarang,JacobDevlin,
MaartenBosma,GauravMishra,AdamRoberts,Paul
SimranArora,AvanikaNarayan,MayeeF.Chen,Laurel
Barham,HyungWonChung,CharlesSutton,Sebas-
Orr,NeelGuha,KushBhatia,InesChami,Frederic
tian Gehrmann, Parker Schuh, Kensen Shi, Sasha
Sala,andChristopherRé.2022. Askmeanything: A
Tsvyashchenko, Joshua Maynez, Abhishek Rao,
simplestrategyforpromptinglanguagemodels.
Parker Barnes, Yi Tay, Noam M. Shazeer, Vinod-
kumarPrabhakaran,EmilyReif,NanDu,BentonC.
Stephen Bach, Victor Sanh, Zheng Xin Yong, Albert
Hutchinson, Reiner Pope, James Bradbury, Jacob
Webson, Colin Raffel, Nihal V. Nayak, Abheesht
Austin,MichaelIsard,GuyGur-Ari,PengchengYin,
Sharma, Taewoon Kim, M Saiful Bari, Thibault
Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
Fevry, ZaidAlyafeai, MananDey, AndreaSantilli,
Sunipa Dev, Henryk Michalewski, Xavier García,
Zhiqing Sun, Srulik Ben-david, Canwen Xu, Gun-
VedantMisra,KevinRobinson,LiamFedus,Denny
jan Chhablani, Han Wang, Jason Fries, Maged Al-
Zhou,DaphneIppolito,DavidLuan,HyeontaekLim,
shaibani,ShanyaSharma,UrmishThakker,Khalid
Barret Zoph, Alexander Spiridonov, Ryan Sepassi,
Almubarak, XiangruTang, DragomirRadev, Mike
DavidDohan,ShivaniAgrawal,MarkOmernick,An-
Tian-jianJiang,andAlexanderRush.2022. Prompt-
drew M. Dai, Thanumalayan Sankaranarayana Pil-
Source: Anintegrateddevelopmentenvironmentand
lai,MariePellat,AitorLewkowycz,EricaMoreira,
repositoryfornaturallanguageprompts. InProceed-
Rewon Child, Oleksandr Polozov, Katherine Lee,
ingsofthe60thAnnualMeetingoftheAssociation
ZongweiZhou,XuezhiWang,BrennanSaeta,Mark
forComputationalLinguistics: SystemDemonstra-
Díaz,OrhanFirat,MicheleCatasta,JasonWei,Kath-
tions,pages93–104,Dublin,Ireland.Associationfor
leenS.Meier-Hellstern,DouglasEck,JeffDean,Slav
ComputationalLinguistics.
Petrov,andNoahFiedel.2022. Palm: Scalinglan-
TomB.Brown,BenjaminMann,NickRyder,Melanie guagemodelingwithpathways. J.Mach.Learn.Res.,
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind 24:240:1–240:113.
Neelakantan,PranavShyam,GirishSastry,Amanda
PeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
AshishSabharwal,CarissaSchoenick,andOyvind
Gretchen Krueger, Tom Henighan, Rewon Child,
Tafjord.2018. Thinkyouhavesolvedquestionan-
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
swering? tryarc,theai2reasoningchallenge.
ClemensWinter,ChristopherHesse,MarkChen,Eric
Sigler,MateuszLitwin,ScottGray,BenjaminChess, Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
Jack Clark, Christopher Berner, Sam McCandlish, LukeZettlemoyer.2023. Qlora: Efficientfinetuning
Alec Radford, Ilya Sutskever, and Dario Amodei. ofquantizedllms.
2020. Language models are few-shot learners. In
Proceedingsofthe34thInternationalConferenceon Chrisantha Fernando, Dylan Banarse, Henryk
Neural Information Processing Systems, NIPS’20, Michalewski, Simon Osindero, and Tim Rock-
RedHook,NY,USA.CurranAssociatesInc. täschel. 2023. Promptbreeder: Self-referential
self-improvementviapromptevolution.
Weilin Cai, Juyong Jiang, Fan Wang, Jing Tang,
Sunghun Kim, and Jiayi Huang. 2024. A survey JianpingGou,BaoshengYu,StephenJ.Maybank,and
onmixtureofexperts. Dacheng Tao. 2021. Knowledge distillation: A
survey. International Journal of Computer Vision,
HarrisonChase.2022. LangChain. 129(6):1789–1819.
Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, BairuHou,JoeO’Connor,JacobAndreas,ShiyuChang,
Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024. andYangZhang.2023. Promptboosting: black-box
Inside: Llms’internalstatesretainthepowerofhal- textclassificationwithtenforwardpasses. InPro-
lucinationdetection. ceedings of the 40th International Conference on
MachineLearning,ICML’23.JMLR.org.
LingjiaoChen,MateiZaharia,andJamesZou.2023a.
Frugalgpt: Howtouselargelanguagemodelswhile Baizhou Huang, Shuai Lu, Weizhu Chen, Xiaojun
reducingcostandimprovingperformance. Wan, and Nan Duan. 2024. Enhancing large lan-
guage models in coding through multi-perspective
Xinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Ke- self-consistency.
fanXiao,PengchengYin,SushantPrakash,Charles
Sutton,XuezhiWang,andDennyZhou.2023b. Uni- Benoit Jacob, Skirmantas Kligys, Bo Chen, Meng-
versalself-consistencyforlargelanguagemodelgen- longZhu,MatthewTang,AndrewHoward,Hartwig
eration. ArXiv,abs/2311.17311. Adam, and Dmitry Kalenichenko. 2018. Quanti-
zationandtrainingofneuralnetworksforefficient
HongrongCheng,MiaoZhang,andJavenQinfengShi. integer-arithmetic-onlyinference. InProceedingsof
2024. A survey on deep neural network pruning- theIEEEConferenceonComputerVisionandPat-
taxonomy,comparison,analysis,andrecommenda- ternRecognition(CVPR).
tions.
DongfuJiang,XiangRen,andBillYuchenLin.2023.
PeterChng.2024. Whydollminputtokenscostless Llm-blender: Ensembling large language models
thanoutputtokens? withpairwiserankingandgenerativefusion.Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, ChandanSingh,JohnMorris,AlexanderRush,Jianfeng
Zhiyuan Zhang, Keshav Santhanam, Sri Vard- Gao,andYuntianDeng.2023. Treeprompting: Effi-
hamanan,SaifulHaq,AshutoshSharma,ThomasT. cienttaskadaptationwithoutfine-tuning. InProceed-
Joshi, Hanna Moazam, Heather Miller, Matei Za- ingsofthe2023ConferenceonEmpiricalMethods
haria,andChristopherPotts.2023. Dspy: Compiling inNaturalLanguageProcessing,pages6253–6267,
declarativelanguagemodelcallsintoself-improving Singapore.AssociationforComputationalLinguis-
pipelines. tics.
WeishiLi,YongPeng,MiaoZhang,LiangDing,Han HugoTouvron,ThibautLavril,GautierIzacard,Xavier
Hu, and Li Shen. 2023a. Deep model fusion: A Martinet,Marie-AnneLachaux,TimothéeLacroix,
survey. BaptisteRozière,NamanGoyal,EricHambro,Faisal
Azhar,AurelienRodriguez,ArmandJoulin,Edouard
YifeiLi,ZeqiLin,ShizhuoZhang,QiangFu,BeiChen, Grave,andGuillaumeLample.2023. Llama: Open
Jian-GuangLou,andWeizhuChen.2023b. Making and efficient foundation language models. ArXiv,
language models better reasoners with step-aware abs/2302.13971.
verifier. In Proceedings of the 61st Annual Meet-
ingoftheAssociationforComputationalLinguistics XuezhiWang,JasonWei,DaleSchuurmans,QuocLe,
(Volume1: LongPapers),pages5315–5333,Toronto, Ed Huai hsin Chi, and Denny Zhou. 2022. Self-
Canada.AssociationforComputationalLinguistics. consistencyimproveschainofthoughtreasoningin
languagemodels. ArXiv,abs/2203.11171.
YinhengLi,ShaofeiWang,HanDing,andHangChen.
2024. Largelanguagemodelsinfinance: Asurvey. JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and
Denny Zhou. 2022. Chain of thought prompting
JieyiLong.2023. Largelanguagemodelguidedtree-of-
elicits reasoning in large language models. ArXiv,
thought.
abs/2201.11903.
YaoLu,MaxBartolo,AlastairMoore,SebastianRiedel,
Pengfei Wu, Jiahao Liu, Zhuocheng Gong, Qifan
and Pontus Stenetorp. 2022. Fantastically ordered
Wang,JinpengLi,JingangWang,XunliangCai,and
promptsandwheretofindthem: Overcomingfew-
DongyanZhao.2024. Paralleldecodingviahidden
shotpromptordersensitivity. InProceedingsofthe
transferforlosslesslargelanguagemodelaccelera-
60thAnnualMeetingoftheAssociationforCompu-
tion.
tationalLinguistics(Volume1: LongPapers),pages
8086–8098,Dublin,Ireland.AssociationforCompu-
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng,
tationalLinguistics.
BowenYu,ChangZhou,ChengpengLi,Chengyuan
Li,DayihengLiu,FeiHuang,GuantingDong,Hao-
Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
ran Wei, Huan Lin, Jialong Tang, Jialin Wang,
2021. AreNLPmodelsreallyabletosolvesimple
Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin
math word problems? In Proceedings of the 2021
Ma,JianxinYang,JinXu,JingrenZhou,JinzeBai,
Conference of the North American Chapter of the
JinzhengHe,JunyangLin,KaiDang,KemingLu,Ke-
AssociationforComputationalLinguistics: Human
qinChen,KexinYang,MeiLi,MingfengXue,NaNi,
LanguageTechnologies,pages2080–2094,Online.
Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize
AssociationforComputationalLinguistics.
Gao,RunjiLin,ShijieWang,ShuaiBai,SinanTan,
TianhangZhu,TianhaoLi,TianyuLiu,WenbinGe,
Silviu Pitis, Michael R. Zhang, Andrew Wang, and
Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren,
Jimmy Ba. 2023. Boosted prompt ensembles for
XinyuZhang,XipinWei,XuanchengRen,Xuejing
largelanguagemodels.
Liu,YangFan,YangYao,YichangZhang,YuWan,
YunfeiChu,YuqiongLiu,ZeyuCui,ZhenruZhang,
ColinRaffel,NoamShazeer,AdamRoberts,Katherine ZhifangGuo,andZhihaoFan.2024. Qwen2techni-
Lee,SharanNarang,MichaelMatena,YanqiZhou, calreport.
WeiLi,andPeterJ.Liu.2020. Exploringthelimits
oftransferlearningwithaunifiedtext-to-texttrans-
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,
former. J.Mach.Learn.Res.,21(1).
Thomas L. Griffiths, Yuan Cao, and Karthik
Narasimhan. 2023. Tree of thoughts: Deliberate
AlexanderRatner,StephenH.Bach,HenryEhrenberg, problemsolvingwithlargelanguagemodels.
Jason Fries, Sen Wu, and Christopher Ré. 2017.
Snorkel: rapidtrainingdatacreationwithweaksu- FangyiYu,LeeQuartey,andFrankSchilder.2022. Le-
pervision. Proc.VLDBEndow.,11(3):269–282. galprompting: Teachingalanguagemodeltothink
likealawyer.
Robert E Schapire. 2013. Explaining adaboost. In
Empiricalinference,pages37–52.Springer. ChenruiZhang,LinLiu,JinpengWang,ChuyuanWang,
XiaoSun,HongyuWang,andMingchenCai.2023.
NoamShazeer.2019. Fasttransformerdecoding: One Prefer: Prompt ensemble learning via feedback-
write-headisallyouneed. reflect-refine.Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
XiaoleiWang,YupengHou,YingqianMin,Beichen
Zhang,JunjieZhang,ZicanDong,YifanDu,Chen
Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,
Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,
PeiyuLiu,Jian-YunNie,andJi-RongWen.2023. A
surveyoflargelanguagemodels.
Zibin Zheng, Kaiwen Ning, Yanlin Wang, Jingwen
Zhang, Dewu Zheng, Mingxi Ye, and Jiachi Chen.
2024. Asurveyoflargelanguagemodelsforcode:
Evolution,benchmarking,andfuturetrends.
Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei,
Nathan Scales, Xuezhi Wang, Dale Schuurmans,
Olivier Bousquet, Quoc Le, and Ed Huai hsin
Chi. 2022. Least-to-most prompting enables com-
plex reasoning in large language models. ArXiv,
abs/2205.10625.
HongjianZhou,FenglinLiu,BoyangGu,XinyuZou,
JinfaHuang,JingeWu,YiruLi,SamS.Chen,Peilin
Zhou, Junling Liu, Yining Hua, Chengfeng Mao,
ChenyuYou,XianWu,YefengZheng,LeiClifton,
Zheng Li, Jiebo Luo, and David A. Clifton. 2024.
A survey of large language models in medicine:
Progress,application,andchallenge.
XunyuZhu,JianLi,YongLiu,CanMa,andWeiping
Wang. 2024. A survey on model compression for
largelanguagemodels.