Stochastic Bandits Robust to Adversarial Attacks
XuchuangWang JinhangZuo XutongLiu
CICS,UMassAmherst CS,CityU CSE,CUHK
Amherst,MA01003 Kowloon,HongKong NewTerritories,HongKong
xuchuangwang@cs.umass.edu jinhangzuo@gmail.com liuxt@cse.cuhk.edu.hk
JohnC.S.Lui MohammadHajiesmaili
CSE,CUHK CICS,UMassAmherst
NewTerritories,HongKong Amherst,MA01003
cslui@cse.cuhk.edu.hk hajiesmaili@cs.umass.edu
Abstract
Thispaperinvestigatesstochasticmulti-armedbanditalgorithmsthatarerobust
to adversarial attacks, where an attacker can first observe the learner’s action
andthenaltertheirrewardobservation. Westudytwocasesofthismodel,with
or without the knowledge of an attack budget C, defined as an upper bound of
the summation of the difference between the actual and altered rewards. For
bothcases,wedevisetwotypesofalgorithmswithregretboundshavingadditive
or multiplicative C dependence terms. For the known attack budget case, we
prove our algorithms achieve the regret bound of O((K/∆)logT +KC) and
√
O˜( KTC) for the additive and multiplicative C terms, respectively, where K
isthenumberofarms,T isthetimehorizon,∆isthegapbetweentheexpected
rewardsoftheoptimalarmandthesecond-bestarm,andO˜ hidesthelogarithmic
factors. Fortheunknowncase,weproveouralgorithmsachievetheregretbound
√ √
ofO˜( KT +KC2)andO˜(KC T)fortheadditiveandmultiplicativeC terms,
respectively. Inadditiontotheseupperboundresults,weprovideseverallower
boundsshowingthetightnessofourboundsandtheoptimalityofouralgorithms.
Theseresultsdelineateanintrinsicseparationbetweenthebanditswithattacksand
corruptionmodels[Lykourisetal.,2018].
1 Introduction
Onlinelearningliterature[BorodinandEl-Yaniv,2005,§7.1.2]usuallyconsiderstwotypesofnon-
obliviousadversarymodels: themediumadversaryandthestrongadversary.1 Themediumadversary
choosesthenextinstancebeforeobservingthelearner’sactions,whilethestrongadversarychooses
instances after observing the learner’s actions. When it comes to the multi-armed bandits (MAB)
learningwithanadversary,themediumadversarycorrespondstothebanditswithcorruption[Lykouris
etal.,2018],andthestrongadversarycorrespondstoadversarialattacksonbandits[Junetal.,2018].
Banditalgorithmsrobusttocorruptionaredevelopedforthemediumadversarymodelsinbandits
literature,e.g.,Aueretal.[2002],AudibertandBubeck[2010],Lykourisetal.[2018],Guptaetal.
[2019]. However,forthestrongadversarymodel,i.e.,theadversarialattackmodelonMAB,most
previouseffortsfocusondevisingattackingpoliciestomisleadthelearnertopullasuboptimalarm
andthussufferalinearregret,e.g.,Junetal.[2018],LiuandShroff[2019],Zuo[2024]. Developing
robustalgorithmsfortheadversarialattackmodelandachievingregretwithbenigndependenceon
thetotalattackisstilllargelyunexplored(foradetaileddiscussion,seetheendof§1).
1Thereisathirdadversarymodel,calledtheweakadversary,whichisoblivious.Themediumadversaryis
alsocalledtheadaptive-onlineadversary,whilethestrongadversaryiscalledtheadaptive-offlineadversary.
Preprint.Underreview.
4202
guA
61
]GL.sc[
1v95880.8042:viXra1.0
0.9 (1,5) (4 9,8 9)
3 6
0.8
0.7
O( KT+KC2)
0.6 O( KCT2 3)
O(KC T)
0.5
0.0 0.2 0.4 0.6 0.8 1.0
Attack parameter of C=O(T )
Figure1: Algorithmdesignoverview: onlySE-WRhasa Figure2: ComparisonofunknownC
gap-dependentbound;othersareallgap-independent. regrets(seeRemark12fordetail)
StochasticMABwithadversarialattacksInthispaper,westudythestochasticMABunderadversarial
attacksanddeveloprobustalgorithmswhoseregretboundsdegradegracefullyinthepresenceof
suchattacks. DenotebyK ∈N+asthenumberofarmsinMAB,andeacharmkisassociatedwith
arewardrandomvariableX withanunknownmeanµ . Denotebyk∗ asthearmindexwiththe
k k
highest mean reward, and ∆ := µ −µ the reward gap between the optimal arm k∗ and any
k k∗ k
suboptimalarmk. Thelearneraimstominimizetheregret,definedasthedifferencebetweenthe
highesttotalrewardsofpullingasinglearmandtheaccumulatedrewardsoftheconcernalgorithm.
Ineachtimeslot,thelearnerfirstpullsanarm. Then,theadversaryobservesthepulledarmandits
realizedrewardandchoosesanattackedrewardforthelearnertoobserve. DenotebyC asthetotal
amountofattacksthattheadversaryusestoaltertherawrewardstotheattackedrewardsoverall
rounds. Wepresenttheformalmodeldefinitionsin§2.
ContributionsThispaperproposesrobustalgorithmswithtightregretboundsfortheadversarial
attackmodelonMAB.Toachievethat,wefirstdeveloprobustalgorithmswiththeknownattackbudget
asanintermediatesteptowardsdevelopingrobustalgorithmsfortheunknownattackbudgetcase.
Lateron,wecalltheformertheknownattackcaseandthelattertheunknownattackcase.
Known attack budget case. For the known attack case (§4), we first investigate the successive
elimination with wider confidence radius (SE-WR) algorithm, which was initially proposed for
bandits with corruptions [Lykouris et al., 2018]. In §4.1, we show SE-WR can be applied to the
banditswithknownadversarialattackbudgetandprovethatthisalgorithmenjoysatighterregret
(cid:80)
upperboundO( logT/∆ +KC)(underbothattackandcorruptionmodels)thanprevious
k̸=k∗ k
analysis[Lykourisetal.,2018]underthecorruptionmodel. Thisimprovementremovestheoriginal
(cid:80)
additiveterm C/∆ ’sdependenceof∆ andreducesittoKC. Toachievegap-independent
k̸=k∗ k k
regretboundsin§4.2,weproposetwostoppingconditionsforthesuccessiveeliminationtomodify
theSE-WRalgorithmtotwoSE-WR-Stopalgorithms(see⃝1 inFigure1).Weprovethattheregretsof
√
(cid:112)
thesetwomodifiedalgorithmsareO( KT logT +KC)andO( KT(logT +C))respectively.
Unknownattackbudgetcase. ToaddresswithMABwithunknownattackcase(§5),weusealgorithms
proposed for known attacks as building blocks to devise algorithms for unknown attacks. We
consider two types of algorithmic techniques. In §5.1, we apply a multi-phase idea to extend
the SE-WR algorithm to a phase elimination algorithm (PE-WR, see ⃝2 in Figure 1). The PE-WR
algorithmutilizesamulti-phasestructure—eachphasewithcarefullychosenattackbudgetsandphase
lengths—todefendagainstunknownattacks. WeshowthattheregretofPE-WRisupperboundedby
√
O( KT+KC2). In§5.2,weapplyamodelselectiontechnique,whichtreatstheunknownattackC
asaparameterinmodelselection(see⃝3 inFigure1). Specifically,weconsiderlog T baseinstances
2
of SE-WR-Stop with different input attack budgets and then use the model selection technique
to “corral” these base instances, composing the model-selection SE-WR-Stop (called MS-SE-WR)
√ √
algorithm. WeupperboundtheregretofMS-SE-WRbyO˜( KCT2 3)orO˜(KC T)dependingon
thechoiceofthemodelselectionalgorithm. Figure1summarizestherelationsofalgorithmdesign,
andFigure2showsthatwhichtypeofalgorithmperformsbetter,thosewithadditiveboundsorthose
withmultiplicativebounds,variesdependingonthetotalattacks.
Lowerbounds. In§3,wealsoprovidelowerboundresultstoshowthetightnessofourupperbounds.
We first show a general Ω(KC) lower bound for any algorithm under attack. Based on this, we
(cid:80)
propose the gap-dependent lower bound Ω( logT/∆ +KC) (informal expression) and
k̸=k∗ k
2
)T(O=TR
fo
retemarap
tergeRTable1: Resultsoverview: upperboundswith†areforpseudoregretinexpectation,whileallother
upperboundsareforrealizedregretwithhighprobability;lowerboundswith‡areonlyforspecial
classesofalgorithms(seePropositions4and5),andthelowerboundwith††holdswhenT →∞.
Wereportbothadditiveandmultiplicativeboundsbecausewhichoneisbettercoulddependonthe
valueofC (seeFigure2forunknownC caseandthedetaileddiscussioninRemark12).
RegretBounds KnownAttackC(§4) UnknownAttackC(§5)
(cid:16) (cid:17) √ (cid:16)√ (cid:17)
AdditiveC O (cid:80) logT +KC ,O( KTlogT +KC) O˜ KT +KC2
MultiplicativeC k̸=k∗ ∆ Ok ((cid:112) KT(logT +C)) O˜(√ KCT2 3)†,O˜(KC√ T)†
LowerBounds(§3)
Ω(cid:16)
(cid:80)
k̸=k∗
lo ∆g kT
+KC(cid:17)†† ,Ω(√
KT +KC) Ω(Tα+Cα1)‡,Ω(Cα1−1Tα)‡
√
gap-independent lower bound Ω( KT +KC). Our refined upper bound of SE-WR matches the
gap-dependentlowerbounduptosomeprefactors,andoneofourproposedSE-WR-Stopalgorithms
matchesthegap-independentlowerbounduptosomelogarithmicfactors. Toshowthetightnessof
ourupperboundsfortheunknownattackalgorithms,wederivelowerbounds,Ω(Tα+Cα1)and
Ω(Cα1−1Tα)withα∈[1,1),fortwoclassesofalgorithmswhoseregretupperboundsfollowcertain
2
additive and multiplicative forms respectively. With α = 1, these two lower bounds, becoming
√ √ 2
Ω( T +C2)andΩ(C T),matchtheupperboundsofPE-WRandMS-SE-WRintermsofT andC.
WesummarizeouranalysisresultsinTable1.
Resultseparationbetweencorruptionandattack.Withtheresultsinthispaper,wedemonstrateaclear
separationbetweencorruption(mediumadversary)andattack(strongadversary)modelsintermsof
theadditiveregretbounds. DenotebyC′thetotalcorruptiontodistinguishfromthetotalattackC,
andwediscussthemodeldifferentinmoredetailin§2.Inthecaseofknowncorruption/attackbudget,
(cid:80)
whilebothachievingthegap-dependentregretbounds (1/∆ )logT inT-dependentterms,
k̸=k∗ k
weshowthattheregretduetoattackisΘ(KC)whichhasafactorofK worsethantheadditional
Θ(C′) regret due to corruption. That implies, with the same amount of budget, an attacker can
produceK timeslargerimpactonregretthanthatunderthecorruptionmodel. Forunknownbudget
(cid:16) (cid:17)
cases,whilebanditswithcorruptionshavetheregretboundsofO (cid:80) log2(KT/δ) +C′ [Gupta
k̸=k∗ ∆k
etal.,2019,Liuetal.,2021],itisimpossibleforattackcasetoachievearegretupperboundinthe
formofO(ploylog(T)+Cα)foranyα>0(contradictswithTheorem3). Instead,weshowthatthe
√
regretwithunknownattackscanattainO˜( KT +KC2)wheretheC2additivetermistight. Even
ifignoringtheworseorderofthefirstT-relatedterms,thesecondregrettermduetoattackO(C2)is
stillafactorofC worsethantheadditionalO(C′)regretduetocorruption. Thatis,anattackwith
√
O( T)budgetisenoughtomakethealgorithmsufferalinearregretintheattackmodel,2whileone
needsalinearO(T)corruptionbudgettoachievethesameeffectinthecorruptioncase.
Extended literature review Robustness against corruption. Lykouris et al. [2018] propose the
bandits with corruption model and devised algorithms with O((KlogT + KC′)/∆) regret for
known corruption C′ case and algorithms with O(C′K2logT/∆) regret for unknown C′ case,
where∆denotesthesmallestnon-zerorewardgap. Later,Guptaetal.[2019]studythesamemodel
andproposeanalgorithmthatimprovesthemultiplicativeC′dependenceofregretforunknownC′
casetoadditiveC′,i.e.,O(Klog2T/∆+KC′).However,therobustdesignofbothalgorithmsabove
reliesonrandomlypullingarms,whichisnotfeasibleinourattacksetting. Besidesbanditsrobustto
corruption,thereisanotherlineofworksonbest-of-both-worldbanditalgorithmdesign,e.g.,Seldin
andLugosi[2017],WeiandLuo[2018],ZimmertandSeldin[2021],wheretheiralgorithmscanbe
appliedtothebanditwithcorruptionbutdonotworkintheadversarialattackmodeleither.
Attacksonbandits. AttackpolicydesignforMABalgorithmshasbeenstudiedbyJunetal.[2018],
LiuandShroff[2019],Xuetal.[2021],Zuoetal.[2024],Zuo[2024]andmanyothers. Theyaimto
designattackingpoliciestomisleadthelearner,typicallywithlogarithmicregretswhenthereisno
√
2ThisstatementisforthealgorithmwithO˜( KT +KC2)mentionedabove.Ourlowerboundresultsdo
notexcludethepossibleexistenceofotheralgorithmswithupperboundsO˜(Tα+Cα1)forα∈[1,1),inwhich
2
caseasublinearO(Tα)budgetcanmakethealgorithmsufferlinearregret.
3Procedure1DecisionunderAttacks
1: foreachroundt=1,2,...,T do
2: ThelearnerpullsanarmI t
3: AstochasticrewardX It,tisdrawnfromthisarmI t
4: TheadversaryobservesthepulledarmI tanditsrealizedrewardX It,t
5:
TheadversarychoosesanattackedrewardX˜
It,t
6: ThelearneronlyobservestheattackedrewardX˜ It,t,andnotX It,t
attack,topullasuboptimalarmandthussufferalinearregret. Thisistheoppositeofourobjective
fordesigningrobustalgorithmstoachievesublinearregretunderanyattacks.
Robustnessagainstattacks. TheonlyexistingresultonrobustalgorithmsforMABunderattacksis
byZuo[2024,Section6],wheretheauthorusescompetitiveratioastheobjective—oftenusedwhen
onecannotachievesublinearregret,insteadofthefiner-grainedregretmetricstudiedinthispaper.
ApartfromtheMABmodel,thereareworksstudyingrobustalgorithmsonstructuredbanditsunder
attacks,e.g.,linearbandits[Bogunovicetal.,2020,Heetal.,2022]andLipchitzbandits[Kangetal.,
2024]. Althoughtheirlinear/LipchitzbanditsresultscanbereducedtoMAB,thisreductiondoesnot
providealgorithmswithtightregretsasinTable1ofthispaper. Wewillelaborateonthisin§5.
2 Model: MABwithAdversarialAttacks
WeconsideraMABmodelwithK ∈N+arms. Eacharmk ∈K:={1,2,...,K}isassociatedwitha
rewardrandomvariableX ∈[0,1]withanunknownmeanµ . Denotetheuniquearmwithhighest
k k
rewardmeanask∗,i.e.,k∗ =argmax µ . WeconsiderT ∈N+decisionrounds. Ateachround
k∈K k
t∈T :={1,2,...,T},thelearnerselectsanarmI ∈K,andthearmgeneratesarewardrealization
t
X (notdisclosedtothelearneryet). TheadversaryobservesthepulledarmI anditsrealized
It,t t
rewardX andthenchoosesanattackedrewardX˜ forthelearnertoobserve. Thetotalattackis
It,t It,t
thesumoftheabsolutedifferencesbetweentherawrewardsandtheattackedrewardsoverallrounds,
i.e.,C :=(cid:80)T |X −X˜ |. WesummarizethedecisionprocessinProcedure1.
t=1 It,t It,t
RegretobjectiveTheadversaryaimstomaximizethelearner’sregret, whilethelearneraimsto
minimizetheregret.Wedefinethe(realized)regretasthedifferencebetweenthehighesttotalrealized
rawrewardsofasinglearmandtheaccumulatedrawrewardsofthelearningalgorithmasfollows,
(cid:88)
R :=max (X −X ). (1)
T
k∈K t∈T
k,t It,t
Besidestherealizedregretin(1),anothercommonregretdefinitionisthepseudo-regret,definedas
R¯ :=maxE(cid:104)(cid:88) (X −X )(cid:105) =E(cid:104) Tµ −(cid:88) µ (cid:105) . (2)
T
k∈K t∈T
k,t It,t k∗
t∈T
It
ByJensen’sinequality,wehaveR¯ ⩽ E[R ],implyingthatthepseudo-regretisaweakermetric
T T
thantherealizedregret. Thispaper’sresultsareprimarilyonrealizedregret,butwealsoprovide
resultsonthepseudo-regretwhennecessary.
Comparison between corruption and attack models Different from the above attack model
(strongadversary),thereispriorliteratureonrobustbanditalgorithmsagainstcorruption(medium
adversary)[Lykourisetal.,2018,Guptaetal.,2019],wheretheadversarychoosesthecorruption
rewardsbeforeobservingthelearner’sactions(seeAppendixAformoredetails),andthetotalamount
of corruption is defined as C′ :=(cid:80)T max |X (k)−X˜ |. While comparing the definition of
t=1 k t k,t
corruptionC′ withattackC mayleadtotheimpressionthatC ⩽ C′ andbothmodelsonlydiffer
slightly,weemphasizethatthetwomodelsarefundamentallydifferentduetothesequenceofthe
adversaryattacking(corrupting)rewardsafter(before)observingthelearner’sactions.
Tohighlightthecrucialdifferencebetweenthetwosequences,weillustratethat,togeneratethesame
degreeofimpactonabanditalgorithm,therequiredbudgetunderthecorruptionmodelcanbemuch
largerthanthatundertheattackmodel. Forexample,onenaiveattackpolicy,forcingthelearnerto
sufferlinearregrets,couldbethatwheneverthealgorithmpullstheoptimalarmk∗,theadversary
alterstherewardrealizationtobesmallerthanthemeanofthebestsuboptimalarm. Astheadversary
4observes the learner’s action before choosing the attack, this attack policy may cost O(logT) or
sublinear O(Tα) budget for some α < 1, depending on the specific algorithm. However, in the
corruptionmodel,astheadversarydoesnotknowwhicharmispulledbeforecorruptingtherewards,
theadversaryhastocorrupttheoptimalarm’srewardrealizationinallT roundstoachievethesame
effect, resulting in O(T) cost. From an abstract perspective, the attack model is more powerful
thanthecorruptionmodelbecausethesequenceofobservingthepulledarmbeforeattackingmakes
therandomizedstrategy(widelyusedinbandits)invalid, forexample, randomlypullingarmsin
EXP3[Aueretal.,2002]andBARBAR[Guptaetal.,2019]. Withoutrandomization,devisingrobust
algorithmsforattacksismuchmorechallengingthanthatforcorruptions.
3 LowerBounds
Thissectionfirstpresentsanewgenerallowerboundfortheadversarialattackmodelonstochastic
multi-armedbandits(Theorem1)andtwoofitsvariants. Later,wederivetwolowerboundsfortwo
specialclassesofbanditalgorithms(Propositions4and5). AllproofsaredeferredtoAppendixB.
3.1 AGeneralLowerBound
WefirstpresentagenerallowerboundΩ(KC)inTheorem1. Togetherwithknownlowerboundsof
MAB,wederiveProposition2. §4presentsalgorithmsmatchingtheselowerbounds.
Theorem1. Givenastochasticmulti-armedbanditgamewithK arms,underattackwithbudgetC,
andT >KC decisionrounds,3foranybanditsalgorithm,thereexistsanattackpolicywithbudget
C thatcanmakethealgorithmsufferΩ(KC)regret.
Proposition2. Forgap-dependentregretboundsandanyconsistentbanditalgorithm4,thelower
(cid:16) (cid:17)
boundisroughlyΩ (cid:80) logT +KC ,orformally,forsomeuniversalconstantξ >0,
k̸=k∗ ∆k
liminf R¯ T −ξKC ⩾ (cid:88) 1 . (3)
T→∞ logT 2∆ k
k̸=k∗
Forgap-independentcases,thelowerboundis
√
R¯ ⩾Ω( KT +KC). (4)
T
3.2 TwoLowerBoundsforSpecialAlgorithmClasses
Inthissubsection,wefirstrecallresultsfromadversarialattacksonbanditsliterature[LiuandShroff,
2019,Zuo,2024]inTheorem3. Then,basedontheseresults,wederivetwolowerboundsforbandit
algorithmswithadditiveandmultiplicativeregretboundsrespectively. In§5,wepresentalgorithms
thatmatchtheselowerbounds.
Theorem3(Adaptedfrom[Zuo,2024,Fact1]and[Heetal.,2022,Theorem4.12]). Ifanalgorithm
achievesregretR whentotalattackC =0,thenthereexistsanattackpolicywithC =Θ(R )that
T T
canmakethealgorithmsufferlinearregret.
Proposition4(Achievableadditiveregretbounds). Givenanyparameterα∈[1,1),foranybandit
2
algorithmthatachievesanadditiveregretupperboundoftheformO(Tα+Cβ),wehaveβ ⩾ 1.
α
Proposition5(Achievablemultiplicativeregretbounds). Givenparameterα∈[1,1),foranybandit
2
algorithmthatachievesamultiplicativeregretboundoftheformO(TαCβ),wehaveβ ⩾ 1 −1.
α
4 AlgorithmswithKnownAttackBudget
Inthissection,westudythestochasticmulti-armedbanditproblemwithaknownattackbudget. In
§4.1,wefirstpresentanalgorithmwithanadditivegap-dependentupperboundontheattackbudget.
Then,in§4.2,wemodifythisalgorithmtotwovariantswithgap-independentupperbounds,onewith
anadditiveC termandanotherwithamultiplicativeC term.
3NotethatT ⩽KCimpliesthatC =Ω(T)whichtriviallyresultsinalinearregret.
4WhenC =0,aconsistentbanditsalgorithmhasregretR¯ ⩽O(Tα)foranyα∈(0,1).
T
5Algorithm2SE-WR:SuccessiveEliminationwithWideConfidenceRadius
Input: totalattackC (orbudgetC ),numberofarmsK,decisionroundsT,parameterδ
Input
1: InitializecandidatearmsetS ←K,numberofarmpullsN k ←0,rewardestimatesµ˜ k ←0
2: whilet⩽T do
3: UniformlypulleacharminS onceandobservesX˜ k forallarmsk ∈S
4: Updateparameters: t←t+|S|,N k ←N k+1,µ˜ k ← µ˜k(Nk N− k1)+X˜ k forallarmsk ∈S
5: µ˜ max ←max kµ˜ k
(cid:26) (cid:18)(cid:113) (cid:19)(cid:27)
6: S ← k ∈S :µ˜ k ⩾µ˜ max−2 log(2 NK kT/δ) + NC
k
4.1 SE-WR:AnAlgorithmwithGap-DependentUpperBound
Given the knowledge of attack budget C, one is able to predict the worst-case attack and design
an algorithm to defend against it. Here, the robustness is achieved by widening the confidence
radius of the reward estimate to account for the C attack such that the corresponding widened
confidenceintervalcontainsthetruerewardmeanwithahighprobability(asiftherewardswere
notattacked). Denoteµ˜ astheempiricalmeanoftheattackedrewardobservationsofarmk. The
k
(cid:112)
widenedconfidenceintervaliscenteredatµ˜ andhasaradiusof log(2/δ)/N +C/N ,where
k k k
N isthenumberoftimesarmkispulledandδistheconfidenceparameter. Then,weutilizethe
k
successiveelimination(SE)algorithm[Even-Daretal.,2006]todevisearobustbanditalgorithmin
Algorithm2. ThealgorithmmaintainsacandidatesetofarmsS,initializedasthesetofallarmsK,
andsuccessivelyeliminatesuboptimalarmsaccordingtothewidenedconfidenceintervals(Line6),
calledsuccessiveeliminationwithwideradius(SE-WR).Asimilaralgorithmdesignideawasalso
usedinLykourisetal.[2018]forthestochasticbanditproblemwithcorruptionattacks. Theorem6
providestheregretupperboundofAlgorithm2.
Theorem6. GiventhetotalattackoritsupperboundC,Algorithm2’stherealizedregretisupper
(cid:16) (cid:17)
boundedbyR ⩽ O (cid:80) log(KT/δ) +KC withprobability1−δ,and, withδ = K/T, its
T k̸=k∗ ∆k
(cid:16) (cid:17)
pseudoregretisupperboundedasR¯ ⩽O (cid:80) logT +KC .
T k̸=k∗ ∆k
The regret upper bound in Theorem 6 matches the lower bound in (3) in terms of both the
first classic regret term and the second additive attack Ω(KC) term. This shows that the re-
gret upper bound is nearly optimal up to some prefactors. Our regret upper bounds improve the
(cid:16) (cid:17)
O (cid:80) log(KT/δ) +(cid:80) C inLykourisetal.[2018,Theorem1]byremovingthemulti-
k̸=k∗ ∆k k̸=k∗ ∆k
plicativedependenceof1/∆ onthetotalattackC term. Thisimprovementcomesfromatighter
k
analysisforsufficientpullingtimesforeliminatingasuboptimalarm(seeLemma15inAppendixD).
Thisimprovementiscrucialforachievingourtightmultiplicativeregretboundsforbothknownand
unknownattackbudgetcases(Sections4.2and5.2).
4.2 SE-WR-Stop: AnAlgorithmwithGap-IndependentUpperBounds
Wefollowtheapproachofstochasticbanditsliterature[LattimoreandSzepesvári,2020,Chapter6]to
transferthealgorithmwithagap-dependentupperboundtoanotheralgorithmwithgap-independent
bounds. ThemainideaistoreplacethewhileloopconditioninLine2inAlgorithm2withnuanced
stoppingconditions. IfthestoppingconditionistriggeredbeforetheendoftheMABgame,i.e.,t=T,
thealgorithmwilluniformlypulltheremainingarmsinthecandidatesetS untiltheendofthegame.
Asthepseudo-codeofthisalgorithmissimilartoSE-WR,wedeferittoAlgorithm6inAppendixC.
Weconsidertwokindsofstoppingconditions. Thefirstconditionaimstotransferthegap-dependent
bound to an independent one while keeping the additive KC term in the upper bound. We start
fromastoppingconditionN ⩽ log(KT/δ) + C,whereϵisaparametertobedetermined. Withthis
k ϵ2 ϵ
conditionandtheproofdetailsofTheorem6,wecanupperboundtherealizedregretasfollows,
(cid:18) Klog(KT/δ) (cid:19) (cid:16)(cid:112) (cid:17)
R ⩽O +ϵT +KC ⩽O KT log(KT/δ)+KC ,
T ϵ
(cid:112)
wherewechooseϵ= Klog(KT/δ)/T inthelastinequality.
6Thesecondstoppingcondition,whiletransferringthegap-dependenttoindependent,alsoconverts
the additive KC term to multiplication. To derive it, we start from a stopping condition N ⩽
k
log(KT/δ)+C,whereϵisaparametertobedetermined. Withthisconditionandtheproofdetailsof
ϵ2
Theorem6,wecanupperboundtherealizedregretasfollows,
(cid:18) Klog(KT/δ)+KC (cid:19) (cid:16)(cid:112) (cid:17)
R ⩽O +ϵT ⩽O KT(log(KT/δ)+C)
T ϵ
(cid:112)
whereϵ = (Klog(KT/δ)+KC)/T inthelastinequality. Wesummarizetheaboveresultsin
thefollowingtheorem.
Theorem7. GiventhetotalattackoritsupperboundC,SE-WR-Stop(Algorithm6)withstopping
(cid:113)
conditionN ⩽ T +C T hastherealizedregretupperboundedasfollows,
k K Klog(KT/δ)
(cid:16)(cid:112) (cid:17)
R ⩽O KT log(KT/δ)+KC withprobability1−δ, (5)
T
andSE-WR-StopwithstoppingconditionN ⩽ T hastherealizedregretupperboundedasfollows,
k K
(cid:16)(cid:112) (cid:17)
R ⩽O KT(log(KT/δ)+C) withprobability1−δ. (6)
T
√
(cid:0) (cid:1)
Letδ = K/T,theregretin(5)becomesO KT logT +KC ,matchingwiththelowerbound
in(4)uptologarithmicfactors. Thisimpliestheregretupperboundisnearlyoptimal. Letδ =K/T,
(cid:112)
theregretin(6)becomesO( KT(logT +C)). Althoughthisboundcannotmatchthelowerbound
in(4),itsdependenceontotalattackC issquareroot,betterthanthelineardependencein(5). This
betterdependencewillshinewhendevisingalgorithmsforunknownattackbudgetin§5.2.
Remark8(AlgorithmselectionforknownC case). Althoughthissectionproposesthreealgorithms
forknownC—oneSE-WRandtwoSE-WR-Stop,thelattertwoSE-WR-Stopalgorithmsaremainly
forthetheoreticalinterestofderivinggap-independentandmultiplicativeC bounds. Practically,
SE-WRshouldhavebetterempiricalperformancethanthatof SE-WR-Stop,asSE-WR-Stopmay
stopeliminatingrelativelygoodsuboptimalarmsearlierthanSE-WR,causingaslightlyhigherregret.
5 AlgorithmswithUnknownAttackBudget
Thissectionpresentsalgorithmsthatcandefendagainstadversarialattackswithunknownattack
budgets. Wefirstpresentanalgorithmwithanadditiveupperboundin§5.1andthenanalgorithm
withamultiplicativeupperboundin§5.2.
Beforedivingintothedetailedalgorithmdesigns,werecallthattheinputattackbudgetC for
Input
SE-WRandSE-WR-Stopcanbeinterpretedasthelevelofrobustnessthatthealgorithmshave. For
anyactualattackC ⩽C ,thealgorithmsachievetheregretupperboundsinTheorems6and7
Input
respectively;forattackC >C ,thealgorithmsmaybemisledbytheattackerandsufferlinear
Input
regret. This“robust-or-not”separationdemandstheknowledgeoftheactualattackC forSE-WR
andSE-WR-Stoptoperformwell. Inthissection,weapplytwotypesof“smoothing”algorithmic
techniquesto“smooth”this“robust-or-not”separationofSE-WRandSE-WR-Stopsoastoachieve
robustnessagainstunknownattacks. AnoverviewofalgorithmdesignisinFigure1.
Ontheotherhand,robustalgorithmsdesignedforunknowncorruptions,e.g.,Lykourisetal.[2018],
Guptaetal.[2019],donotapplytotheunknownattacksetting. Becausetheserobustalgorithmsall
relyonsomerandomizedactionmechanismtodefendagainstcorruption,whichisinvalidforthe
attackastheattackercanmanipulatetherewardsofthearmsafterobservingthelearner’sactions.
5.1 PE-WR:AnAlgorithmwithAdditiveUpperBound
Thefirst“smoothing”algorithmictechniqueisapplyingthemulti-phasestructuretomodifySE-WR
(Algorithm2),yieldingthephaseeliminationwithwideconfidenceradiusalgorithm,PE-WR(Algo-
rithm3)forunknownattackbudget. ThisalgorithmconsidersmultiplephasesofSE-WR,eachwitha
differentassumedattackbudgetC ,andthecandidatearmsetS isupdatedconsecutivelyamong
Input
phases,thatis,thearmseliminatedinpreviousphasesarenotconsideredinlaterphases.
7Algorithm3PE-WR:PhaseEliminationwithWideConfidenceRadius
Input: numberofarmsK,decisionroundsT,confidenceparameterδ
1: InitializecandidatearmsetS ←K,thenumberofarmpullsN k ←0,rewardmeanestimates
µˆ ←0,phaseh←0,phaseupperboundH ←⌈log T⌉−1,initialpullingtimesL ←K
k 2 0
2: foreachphaseh=0,1,...do
√
3: Cˆ h ←min{ T/K,2H−h−1}
4: PulleacharminS forL h/|S h|times
5: Updatearmempiricalmeansµˆ k,hforallarmsk ∈S
(cid:26) (cid:16)(cid:113) (cid:17)(cid:27)
6: S h+1 ← k ∈S h :µˆ k,h ⩾ km ′∈a Sx hµˆ k′,h−2 log L( h2 /K |CH h/ |δ) + LhC /ˆ |h Ch|
7: L h+1 ←2L h
Specifically,PE-WRseparatesthetotaldecisionroundsintomultiplephasesh∈{1,2,...},eachwith
alengthdoubledfromthepreviousphase(Line7). Inphaseh,theeliminationassumesthepotential
attackisupperboundedbyCˆ ,whichishalvedineachphase(Line3). Thismechanismresultsin
h
twokindsofphases. Denoteh′asthefirstphasewhosecorrespondingCˆ issmallerthanthetrue
h′
attackbudgetC. Then,forphasesh<h′,wehaveCˆ ⩾C,and,therefore,thealgorithmeliminates
h
armsproperlyasSE-WR;forphasesh ⩾ h′, asCˆ < C, thealgorithmmayfalselyeliminatethe
h
optimalarmandsufferextraregret. Buteventhoughtheoptimalarmiseliminated,thealgorithmin
thesephasesstillhasthelevelofCˆ robustness,whichguaranteessomerelativelygoodsuboptimal
h
arms—withameanclosetotheoptimalarm—remaininginthecandidatesetS suchthatthetotal
regretduetolosingtheoptimalarminthesephasesisnotlarge(boundedbyKC2intheproof). We
presentthepseudo-codeofPE-WRinAlgorithm3anditsregretupperboundinTheorem9.
Theorem9. Algorithm3hasarealizedregretupperbound, withaprobabilityofatleast1−δ,
R ⩽
O(cid:16)(cid:112)
KT
log(KlogT/δ)+√
T logT +KClogT
+KC2(cid:17)
as well as a pseudo regret
T
upperboundasfollows,withδ =K/T,
R¯
⩽O(cid:16)(cid:112)
KT log(T
logT)+√
T logT +KClogT
+KC2(cid:17) =O˜(cid:16)√
KT
+KC2(cid:17)
.
T
Comparing our upper bound in Theorem 9 to the lower bound in Proposition 4 with α = 1/2,
√
Ω( T +C2),weknowthatourupperboundistightintermsofbothT andC. Comparedwiththe
√
lowerboundΩ( KT +KC)inTheorem2,ourupperboundisalsotightintermsofK.
This multi-phase elimination idea is widely used in bandit literature, e.g., batched bandits [Gao
etal.,2019],multi-playerbandits[Wangetal.,2019],andlinearbandits[Bogunovicetal.,2020].
ThemostrelatedtooursisthephaseeliminationalgorithmproposedinBogunovicetal.[2020]for
linearbandits. However, directlyreducingtheirresultstoourstochasticbanditcasewouldyield
√ √
aO˜(K KT +C2)upperboundforC ⩽ T only,and,forgeneralC,theirresults
√ (KloglogK)logT
wouldbecomeO˜(K KT +K2C2). OurresultinTheorem9istighterthantheirsbyafactorofthe
√
numberofarmsK onthefirst T term,and,forthegeneralC case,ourresultistighterbyafactor
ofK onthesecondC2 termaswell. Thisimprovementcomesfromthetighterconfidencebound
employedinLine6ofAlgorithm3andthecorrespondingtighteranalysisforthenecessarynumber
ofobservationsforthealgorithmtoeliminatearms(Lemma15)in§4.1.
5.2 MS-SE-WR:AnAlgorithmwithMultiplicativeUpperBound
√
WhiletheadditiveboundinTheorem9canbetransferredtoamultiplicativeboundO˜(KC2 T),this
√
boundcannotmatchthelowerboundinProposition5,e.g.,Ω(C T)forα= 1. Inthissection,we
2
deployanotheralgorithmictechnique,modelselection,toSE-WR-Stop(Algorithm2)toachievetight
multiplicativeupperboundsfortheunknownattackbudgetcase. Unlikethemulti-phasetechnique,
whereeachphaseassumesadifferentattackbudget,weconsidermultiplealgorithminstanceswith
differentattackbudgetinputs,eachofwhichisa“model.” Modelselectionmeansselectingthemodel
(algorithminstance)thatperformsbestintheunknownenvironment. Inourscenario,itistoselect
theinstancewiththesmallestattackbudgetinputC thatislargerthantheactualattackbudgetC.
Input
8Algorithm4MS-SE-WR:ModelSelectionwithWideConfidenceRadius
Input: numberofarmsK,decisionroundsT,modelselectionalgorithmModSelAlg
1: ConstructG:=⌈log T⌉basealgorithminstancesas
2
B ←{SE-WR-Stop(C =2g,K,T,δ =K/T):g =1,2,...,G}.
2: ModSelAlg(B)forT decisionrounds
Specially,weconsiderG:=⌈log T⌉instancesofSE-WR-Stop,eachwithadifferentattackbudget
2
input C = 2g, g = 1,2,...,G. Among these instances, the best is g∗ = ⌈log C⌉, as 2g∗ ∈
Input 2
[C,2C)isthesmallestattackbudgetlargerthantheactualattackC. Wethenapplyamodelselection
algorithm,e.g.,CORRAL[Agarwaletal.,2017]orEXP3.P[Aueretal.,2002],toselectthebestone
amongtheGinstances. Algorithm4presentsthepseudo-code. Toprovetheregretupperbound,we
recallasimplifiedversionofPacchianoetal.[2020,Theorem5.3]inthefollowinglemma.
Lemma10. IfbasealgorithminstancehasregretupperboundR¯ ⩽Tαc(δ)withprobability1−δ
T
forknownconstantα∈[1,1)andtheunknownfunctionc:R→R,thentheregretsof CORRALand
2
EXP3.PareR¯
T
⩽O˜(c(δ)α1Tα)andR¯
T
⩽O˜(c(δ)2−1 αTα)respectively.
To apply this lemma to our case, we first convert the gap-independent upper bound in (6) of
SE-WR-Stop(Algorithm6)inTheorem7toamultiplicativeupperbound: Whenthestopcondition
isN ⩽ T,therealizedregretupperboundisR¯ ⩽O((cid:112) KTClog(KT/δ))withaprobabilityof
k K T
atleast1−δ. PluggingthisintoLemma10withα = 1 andc(δ) = (cid:112) Clog(KT/δ)andletting
2
δ =K/T,wehavethepseudoregretupperboundsforMS-SE-WRasfollows:
Theorem11. DeployingSE-WR-Stop(stopconditionN ⩽T/K)asthebasealgorithminstance,
k √
Algorithm4withCORRALhaspseudoregretupperboun √dR¯
T
⩽O˜( KCT2 3),andAlgorithm4with
EXP3.PhaspseudoregretupperboundR¯ ⩽O˜(KC T).
T
The bounds in Theorem 11 are tight in terms of the trade-off of T and C, as they respectively
√ √
match the lower bounds in Proposition 5, Ω( CT2 3) when α = 2 and Ω(C T) when α = 1.
3 2
ThechallengeofachievingthesetightregretboundsinTheorem11isindiscoveringtherightbase
algorithminstanceswithsuitablemultiplicativeupperbounds. Forexample,thefirstupperboundin
Theorem7canalsobeconvertedtothemultiplicativeR¯ ⩽O(C(cid:112) KT log(KT/δ))boundwitha
T
probabilityofatleast1−δ. However,applyingthemodelselectiontechniquetothisboundonly
√ √
resultsinO˜(C KT2 3)andO˜(C2K T)bounds,whicharenotastightastheonesinTheorem11.
ThismodelselectiontechniquewasalsousedinKangetal.[2024]toboostthealgorithmforLipchitz
banditswithaknownattackbudgettoanalgorithmwithanunknownattackbudget. However,their
regretupperbounds,mappingtoourMABsetting,areO˜(CK1 +2TK K+ +2 3)andO˜(CK1 +1TK K+ +1 2),which
haveamuchworsedependenceonT thantheonesinTheorem11,especiallywhenK islarge. This
isbecausetheregretupperboundsoftheirbasealgorithmshaveamuchworsedependenceonT
thanourbaseSE-WR-Stopalgorithm. Thishighlightstheimportanceofdevisingthesuitablebase
algorithminstancesforMABwiththeknownattackbudgetin§4.2.
Remark12(RegretcomparisonforunknownCcaseinFigure2). Thesectionpresentsthreedifferent
√
upperboundsforunknownattacks,oneadditiveO˜( KT +KC2)byPE-WRandtwomultiplicative
√ √
O˜(C KT2 3),O˜(C2K T)bytwotypesof MS-SE-WR.GivingattackC =Tβ forsomeparameter
β ∈[0,1],thesethreeboundscanbewrittenintheformofO˜(Tγ)forcorrespondingexponentsγ.
Figure2comparestheseboundsintermsoftheexponentγbyvaryingβ. Comparingallthreebounds,
√
theadditiveboundisbetterthanbothmultiplicativeoneswhenβ ⩽ 4,andtheO˜(C KT2 3)bound
9
isbetterthantheadditiveonewhenβ > 4. Comparingamongthetwomultiplicativebounds,the
√ √ 9
O˜(C2K T)isbetterthanO˜(C KT2 3)whenβ ⩽ 1,andviceversa. SinceFigure2suggeststhat
3
nosinglealgorithmconsistentlyoutperformstheothers,andwithoutpriorknowledgeofC,thereis
nodefinitiveruleforselectingaspecificalgorithminpractice.
Conclusion Remark This paper presents a comprehensive study of bandit algorithms robust to
adversarialattacks,examiningtwoscenarios: attackswithorwithoutknowledgeoftheattackbudget,
andtwotypesofregretbounds—additiveandmultiplicativedependenceonthetotalattackC. For
9eachofthesefourcases,weproposecorrespondingalgorithmsandestablishtheirregretupperbounds,
whicharesubsequentlydemonstratedtobetightbyprovidingregretlowerbounds.
References
AlekhAgarwal,HaipengLuo,BehnamNeyshabur,andRobertESchapire. Corrallingabandof
banditalgorithms. InConferenceonLearningTheory,pages12–38.PMLR,2017.
Jean-Yves Audibert and Sébastien Bubeck. Regret bounds and minimax policies under partial
monitoring. TheJournalofMachineLearningResearch,11:2785–2836,2010.
PeterAuer,NicoloCesa-Bianchi,YoavFreund,andRobertESchapire.Thenonstochasticmultiarmed
banditproblem. SIAMjournaloncomputing,32(1):48–77,2002.
Ilija Bogunovic, Andreas Krause, and Jonathan Scarlett. Corruption-tolerant gaussian process
banditoptimization. InInternationalConferenceonArtificialIntelligenceandStatistics,pages
1071–1081.PMLR,2020.
AllanBorodinandRanEl-Yaniv. Onlinecomputationandcompetitiveanalysis. cambridgeuniversity
press,2005.
EyalEven-Dar, ShieMannor, YishayMansour, andSridharMahadevan. Actioneliminationand
stoppingconditionsforthemulti-armedbanditandreinforcementlearningproblems. Journalof
machinelearningresearch,7(6),2006.
ZijunGao,YanjunHan,ZhimeiRen,andZhengqingZhou. Batchedmulti-armedbanditsproblem.
AdvancesinNeuralInformationProcessingSystems,32,2019.
Anupam Gupta, Tomer Koren, and Kunal Talwar. Better algorithms for stochastic bandits with
adversarialcorruptions. InConferenceonLearningTheory,pages1562–1578.PMLR,2019.
JiafanHe,DongruoZhou,TongZhang,andQuanquanGu. Nearlyoptimalalgorithmsforlinear
contextualbanditswithadversarialcorruptions.Advancesinneuralinformationprocessingsystems,
35:34614–34625,2022.
Kwang-SungJun,LihongLi,YuzheMa,andJerryZhu. Adversarialattacksonstochasticbandits.
Advancesinneuralinformationprocessingsystems,31,2018.
Yue Kang, Cho-Jui Hsieh, and Thomas Chun Man Lee. Robust lipschitz bandits to adversarial
corruptions. AdvancesinNeuralInformationProcessingSystems,36,2024.
TorLattimoreandCsabaSzepesvári. Banditalgorithms. CambridgeUniversityPress,2020.
FangLiuandNessShroff. Datapoisoningattacksonstochasticbandits. InInternationalConference
onMachineLearning,pages4042–4050.PMLR,2019.
JunyanLiu,ShuaiLi,andDapengLi. Cooperativestochasticmulti-agentmulti-armedbanditsrobust
toadversarialcorruptions. arXivpreprintarXiv:2106.04207,2021.
ThodorisLykouris,VahabMirrokni,andRenatoPaesLeme. Stochasticbanditsrobusttoadversarial
corruptions. InProceedingsofthe50thAnnualACMSIGACTSymposiumonTheoryofComputing,
pages114–122,2018.
AldoPacchiano,MyPhan,YasinAbbasiYadkori,AnupRao,JulianZimmert,TorLattimore,and
CsabaSzepesvari. Modelselectionincontextualstochasticbanditproblems. AdvancesinNeural
InformationProcessingSystems,33:10328–10337,2020.
Yevgeny Seldin and Gábor Lugosi. An improved parametrization and analysis of the exp3++
algorithm for stochastic and adversarial bandits. In Conference on Learning Theory, pages
1743–1759.PMLR,2017.
YuanhaoWang,JiachenHu,XiaoyuChen,andLiweiWang.Distributedbanditlearning:Near-optimal
regretwithefficientcommunication. arXivpreprintarXiv:1904.06309,2019.
10Chen-YuWeiandHaipengLuo. Moreadaptivealgorithmsforadversarialbandits. InConferenceOn
LearningTheory,pages1263–1291.PMLR,2018.
YinglunXu,BhuveshKumar,andJacobDAbernethy. Observation-freeattacksonstochasticbandits.
AdvancesinNeuralInformationProcessingSystems,34:22550–22561,2021.
JulianZimmertandYevgenySeldin. Tsallis-inf: Anoptimalalgorithmforstochasticandadversarial
bandits. TheJournalofMachineLearningResearch,22(1):1310–1358,2021.
JinhangZuo,ZhiyaoZhang,ZhiyongWang,ShuaiLi,MohammadHajiesmaili,andAdamWierman.
Adversarialattacksononlinelearningtorankwithclickfeedback. AdvancesinNeuralInformation
ProcessingSystems,36,2024.
ShiliangZuo. Nearoptimaladversarialattackonstochasticbanditsanddefenseswithsmoothed
responses. InThe27thInternationalConferenceonArtificialIntelligenceandStatistics,2024.
11A OtherModelDetails: CorruptionProcess,RegretDiscussion
Inthissection,weprovidemoredetailsonthecorruptionprocess. Ateachroundt∈{1,2,...,T},
theadversaryobservestherealizedrewardsX forallarmsk,aswellastherewardsandactions
k,t
ofthelearnerinpreviousrounds. TheadversarythenchoosesthecorruptedrewardsX˜ forall
k,t
armsk. ThelearnerpullsanarmI (mayberandomly)andobservestheattackedrewardX˜ . We
t It,t
summarizethedecisionprocessinProcedure5. Wedenotethetotalamountofcorruptionas
T
C′ :=(cid:88) max|X −X˜ |,
k,t k,t
k
t=1
whereI isthepulledarmattimeslott.
t
Procedure5DecisionunderCorruptions
1: foreachroundt=1,2,...,T do
2: StochasticrewardsX k,taredrawnfromallarmsk
3: TheadversaryobservestherealizedrewardsX k,t
aswellastherewardsandactionsofthelearnerinpreviousrounds
4: TheadversarychoosesthecorruptionrewardsX˜ k,tforallarmsk
5: ThelearnerpullsanarmI t(mayberandomly)andobservestheattackedrewardX˜ It,t
Remark13(Regretdefinedbycorruptedrewards). Besidetheregretdefinedonrawrewardin(1),one
canalsodefinetheregretbasedonthecorruptedrewardsasfollows,R˜ :=max (cid:80) (X˜ −
T k∈K t∈T k,t
X˜ ).ThisdefinitionisconsideredinZimmertandSeldin[2021],Bogunovicetal.[2020]. Asthe
It,t
adversarycanmanipulateatmostC rewards,onecaneasilyshowthat,|R˜ −R |⩽2C.Wewill
T T
focusontheregretdefinedbyrawrewards(1)inthefollowing,asmostresultsinthispaperhaveat
leastalineardependenceonC.
B ProofforLowerBound
Theorem1. Givenastochasticmulti-armedbanditgamewithK arms,underattackwithbudgetC,
andT >KC decisionrounds,5foranybanditsalgorithm,thereexistsanattackpolicywithbudget
C thatcanmakethealgorithmsufferΩ(KC)regret.
ProofofTheorem1. We consider K instances of a MAB game where for instance I for any k ∈
k
{1,2,...,K},thearmkhasrewardϵ>0andallotherarmshavereward0withoutanynoise.
The adversary’s policy is that whenever the algorithm pulls an arm with a non-zero reward, the
adversaryattacksthealgorithmbychangingtherewardofthearmto0. Theadversarycanconceal
theoptimalarmfor⌊C⌋pulls.
ϵ
After⌊C⌋⌊K⌋timeslots,thereexistsatleast⌊K⌋armsthatarepulledatmost⌊C⌋times. Thatis,if
ϵ 2 2 ϵ
theoptimalarmisamongthese⌊K⌋arms,thealgorithmcannotidentifytheoptimalarm. Letuspick
2
theinstancewhoseoptimalarmisamongthese⌊K⌋arms. Then,duringthese⌊C⌋⌊K⌋timeslots,
2 ϵ 2
thealgorithmneedstopaytheregretof
(cid:22) (cid:23)(cid:18)(cid:22) (cid:23) (cid:19)
C K
−1 ϵ=Ω(KC).
ϵ 2
Proposition2 Forgap-dependentregretboundsandanyconsistentbanditalgorithm6,thelower
(cid:16) (cid:17)
boundisroughlyΩ (cid:80) logT +KC ,orformally,forsomeuniversalconstantξ >0,
k̸=k∗ ∆k
liminf R¯ T −ξKC ⩾ (cid:88) 1 .
T→∞ logT 2∆ k
k̸=k∗
5NotethatT ⩽KCimpliesthatC =Ω(T)whichtriviallyresultsinalinearregret.
6WhenC =0,aconsistentbanditsalgorithmhasregretR¯ ⩽O(Tα)foranyα∈(0,1).
T
12Forgap-independentcases,thelowerboundis
√
R¯ ⩾Ω( KT +KC).
T
ProofofProposition2. Frombanditsliterature,e.g.,LattimoreandSzepesvári[2020,Chapter16],
weknowthatthepseudoregretofanyconsistentbanditalgorithmcanbelowerboundedasfollows,
liminf R¯ T ⩾ (cid:88) 1 .
T→∞ logT ∆ k
k̸=k∗
Ontheotherhand,wecanrewritetheΩ(KC)lowerboundinTheorem1asfollows,
R¯ −ξKC
liminf T ⩾0,
T→∞ logT
whereξ >0isauniversalconstant. Addingtheabovetwoinequalitiesanddividingbothsideby2,
wehave
liminf R¯ T −(ξ/2)KC ⩾ (cid:88) 1 .
T→∞ logT 2∆ k
k̸=k∗
Forthegap-independentcase,recallinbanditsliterature[LattimoreandSzepesvári,2020,Chapter
√
15], we have the R¯ ⩾ Ω( KT) lower bound. Combining it with the Ω(KC) lower bound in
T √ √
Theorem1yieldsR¯ ⩾Ω(max{ KT,KC})=Ω( KT +KC)lowerbound.
T
Proposition4(Achievableadditiveregretbounds)Givenanyparameterα∈[1,1),foranybandit
2
algorithmthatachievesanadditiveregretupperboundoftheformO(Tα+Cβ),wehaveβ ⩾ 1.
α
Proposition5(Achievablemultiplicativeregretbounds)Givenparameterα∈[1,1),foranybandit
2
algorithmthatachievesamultiplicativeregretboundoftheformO(TαCβ),wehaveβ ⩾ 1 −1.
α
ProofofPropositions4and5. We use contradiction to prove both propositions. We first prove
Proposition4. GivenTheorem3,weknowthatthereexistsanattackpolicywithC =Θ(R )that
T
canmakethealgorithmsufferlinearregret. Thus,ifthealgorithmachievesanadditiveregretupper
boundoftheformO(Tα+Cβ)withβ < 1,thenthealgorithmonlysuffersasublinearregretwhen
α
C =Tα,whichcontradictsTheorem3. Thus,theparameterβ ⩾ 1. Proposition5canbeprovedvia
α
asimilarcontradictionargument.
C DeferredAlgorithmPseudo-Code
Algorithm6SE-WR-Stop:SuccessiveEliminationwithWideConfidenceRadiusandStopCondition
Input: totalattackC,numberofarmsK,decisionroundsT,confidenceparameterδ
1: InitializecandidatearmsetS ←K,thenumberofarmpullsN k ←0,andrewardmeanestimates
µˆ ←0
k
(cid:113)
2: whileN k ⩽ KT andt⩽T do ▷or N k ⩽ KT +C Klog(T KT/δ)
3: UniformlypulleacharminS onceandobservesX k forallarmsk ∈S
4: Updateparameters: t←t+|S|,N k ←N k+1,µˆ k ← µˆk(Nk N− k1)+Xk
5: µˆ max ←max kµˆ k
(cid:26) (cid:18)(cid:113) (cid:19)(cid:27)
6: S ← k ∈S :µˆ k ⩾µˆ max−2 log(2 NK kT/δ) + NC
k
7: UniformlypullarmsinS tilltheendofthegame
13D ProofforUpperBoundswithKnownAttack
Theorem6. GiventhetotalattackoritsupperboundC,Algorithm2’stherealizedregretisupper
(cid:16) (cid:17)
boundedbyR ⩽ O (cid:80) log(KT/δ) +KC withprobability1−δ,and, withδ = K/T, its
T k̸=k∗ ∆k
(cid:16) (cid:17)
pseudoregretisupperboundedasR¯ ⩽O (cid:80) logT +KC .
T k̸=k∗ ∆k
ProofofTheorem6. WefirstrecallthefollowinglemmafromLykourisetal.[2018].
Lemma14(Lykourisetal.[2018,Lemma3.1]). Withaprobabilityofatleast1−δ,theoptimalarm
k∗isnevereliminated.
Next,weprovealemmashowsthesufficientnumberofpullingthatarenecessaryforasuboptimal
armtobeeliminated. ThislemmaistighterthantheoneinLykourisetal.[2018,Lemma3.2](proved
forN ⩾ 36log(2KT/δ)+36C),and,basedonit,wederivetighterregretbounds.
k ∆2
k
Lemma15. Withaprobabilityofatleast1−δ,allsuboptimalarmsk ̸=k∗ areeliminatedafter
pullingeacharmN ⩾ 36log(2KT/δ) + 6C times.
k ∆2
k
∆k
ProofforLemma15. WithLemma14,weknowthattheoptimalarmk∗isnevereliminated. Thus,
inthefollowing,weshowthatthesuboptimalarmkwillbeeliminatedbytheoptimalarmk∗onor
beforeN ⩾ 64log(2KT/δ) + 8C.
k ∆2
k
∆k
Denoteµˆ astheempiricalmeanoftherawstochasticrewardobservationofarmk. ByHoeffding’s
k
inequality,wehave,withaprobabilityofatleast1− δ ,
KT
(cid:115)
log(2KT/δ)
|µˆ −µ |⩽ (7)
k k N
k
∆
⩽ k,
8
wherethelastinequalityisduetoN ⩾ 64log(2KT/δ).
k ∆2
k
Comparingthetrueempiricalmeanµˆ withtheattackedempiricalmeanµ ,wehave
k k
C ∆
|µ˜ −µˆ |⩽ ⩽ k,
k k N 8
k
wherethelastinequalityisduetoN ⩾ 8C. Combiningthetwoinequalities,wehave
k ∆k
∆
|µ˜ −µ |⩽ k.
k k 4
Last, we show that the elimination condition for arm k would have been trigger before N ⩾
k
64log(2KT/δ) + 8C asfollows,
∆2
k
∆k
(cid:115) 
(cid:18) (cid:19)
log(2KT/δ) C ∆ ∆
µ˜
k∗
−2
N
+
N
⩾µ˜
k∗
−2 8k + 8k
k k
∆ 2∆
⩾µ − k −
k∗
4 4
∆
=µ +
k 4
⩾µ˜ .
k
14(cid:80)
Asthepseudoregretisupperboundedatmost ∆ N ,wehave
k k k
R¯ ⩽ (cid:88) ∆ N
T k k
k̸=k∗
(cid:18) (cid:19)
(cid:88) 64log(2KT/δ) 8C
⩽ ∆ +
k ∆2 ∆
k̸=k∗ k k
 
(8)
(cid:88) log(KT/δ)
=O +KC
∆
k
k̸=k∗
 
(cid:88) logT
⩽O +KC,
∆
k
k̸=k∗
wherethelastinequalityisbychoosingδ = K.
T
Transferpsudoe-regrettorealizedregret.Next,weshowthehighprobabilityboundfortherealized
regretR . MultiplyingN tobothsideof(7),wehavethat,foranyarmk,thedifferencebetween
T k
(cid:112)
theactualaccumulatedrewardanditsexpectedcounterpartisupperboundedby N log(2KT/δ)
k
withaprobabilityofatleast1−δ/KT. Theprobabilityofanyofaboveeventdoesnotholdisat
most1−δ.
Foranysuboptimalarmk,weboundthedifferenceasfollows,
(cid:115) (cid:115)
(cid:112) N log(2KT/δ)⩽N log(2KT/δ) ⩽N ∆ log(2KT/δ) ⩽ N k∆ k.
k k N k k 64log(2KT/δ)+8C∆ 8
k k
In case that the arm k′ with highest empirical mean is not the optimal arm k∗, for example, this
armk′hasasmallerrewardgap∆
⩽O((cid:112)
1/T),theregretreductionduetothiseventisatmost
k
N ∆ .
k′ k′
Puttingthepotentialimpactofdifferentkindsofrewardrealizationabove,wecanboundtherealized
(cid:80)
regretbyO( N ∆ )still. Thus,withsimilarderivationas(8),wehavetherealizedregretof
k̸=k∗ k k
thealgorithmisatmost
 
(cid:88) log(KT/δ)
O +KC withprobability1−δ.
∆
k
k̸=k∗
E ProofforUpperBoundswithunknownAttack
Theorem9. Algorithm3hasarealizedregretupperbound, withaprobabilityofatleast1−δ,
R ⩽
O(cid:16)(cid:112)
KT
log(KlogT/δ)+√
T logT +KClogT
+KC2(cid:17)
as well as a pseudo regret
T
upperboundasfollows,withδ =K/T,
R¯
⩽O(cid:16)(cid:112)
KT log(T
logT)+√
T logT +KClogT
+KC2(cid:17) =O˜(cid:16)√
KT
+KC2(cid:17)
.
T
√ √
ProofofTheorem9. ForC > T/K,theO˜( KT +KC2)=O(T)upperboundholdstrivially.
√
Hence,weonlyconsiderC ⩽ T/K inthisproof.
NotethattheeliminationconditioninAlgorithm3failswithaprobabilityofatmostδ/KH.Applying
aunionboundtosumallpotentialfailureprobabilitiesshowthat,withaprobabilityofatleast1−δ,
theeliminationconditionworksproperlyforallarmsinallphases.Intherestoftheproof,weexclude
thisfailureprobabilityandassumethattheeliminationonlyfailswhenC >Cˆ .
h
DenoteH′astheactuallynumberofphases,whilerecallH =⌈log T⌉−1istheupperboundof
2
thenumberofphases. AstheanalysisofAlgorithm2shows,forphasehwithCˆ >C,theoptimal
h
15armk∗ isinthecandidatesetS withhighprobability. Denoteh′ asthefirstphasewithCˆ ⩽C,
h h′
implyingH −h′ ⩽log C.
2
Denotek∗ asthearmwithhighestrewardmeaninphaseh. Then,wehavek∗ =k∗forh<h′. Next,
h h
weuseinductiontoshow,forh⩾h′,theremainingbestarmk∗ isclosetotheoptimalarmk∗ as
h
follows,
2C
µ −µ ⩽ .
k∗ k h∗ L h/|S h|
Iftheoptimalarmiseliminatedinphaseh′,thenwehave
(cid:32)(cid:115) (cid:33)
log(2KH/δ) Cˆ
µˆ ⩽ max µˆ −2 + h′ .
k∗,h′
k∈S h′
k,h′
L h′/|S h′| L h′/|S h′|
Denotekˆ∗ =argmax µˆ . Wehave
h′ k∈S h′ k,h′
(cid:32)(cid:115) (cid:33)
(a) log(2KH/δ) C
µ ⩾ µˆ − +
kˆ h∗ ′ kˆ h∗ ′,h′ L h′/|S h′| L h′/|S h′|
(cid:32)(cid:115) (cid:33) (cid:32)(cid:115) (cid:33)
(b) log(2KH/δ) Cˆ log(2KH/δ) C
⩾ µˆ +2 + h′ − +
k∗,h′
L /|S | L /|S | L /|S | L /|S |
h′ h′ h′ h′ h′ h′ h′ h′
(cid:32)(cid:115) (cid:33) (cid:32)(cid:115) (cid:33)
(c) log(2KH/δ) Cˆ log(2KH/δ) C
⩾ µ +2 + h′ −2 +
k∗
L /|S | L /|S | L /|S | L /|S |
h′ h′ h′ h′ h′ h′ h′ h′
2(C−Cˆ )
=µ −
h′
k∗
L /|S |
h′ h′
2C
⩾µ −
k∗
L /|S |
h′ h′
2CK
⩾µ −
k∗
L
h′
whereinequalities(a)and(c)comefromtheHoeffding’sinequalityandtheattackC,inequality(b)
isduetotheeliminationconditioninroundh′. Thatis,
2CK
µ −µ ⩽ .
k∗ kˆ h∗ ′ L h′
Withsimilaranalysis,wecanshow,µ −µ ⩽ 2CK , foralli=1,...,H−h′−1.Based
kˆ h∗ ′+i kˆ h∗ ′+i+1 L h′+i
ontheinequality,wefurtherhave,foranyh⩾h′,
h−h′ h−h′
(cid:88) 2CK (cid:88) 2CK 2CK
µ −µ ⩽ = ⩽ . (9)
k∗ kˆ h∗ L
h′+i
L 02h′+i L 02h′+1
i=0 i=0
16Next,wedecomposethepseudoregretasfollows,
T H′
R¯ =(cid:88) (µ −µ )= (cid:88) N (µ −µ )=(cid:88) (cid:88) L h (µ −µ )
T k∗ It k,T k∗ k |S | k∗ k
h
t=1 k∈K h=0k∈Sh
h′ H′
⩽L +(cid:88) (cid:88) L h (µ −µ )+ (cid:88) (cid:88) L h (µ −µ )
0 |S | k∗ k |S | k∗ k
h h
h=1k∈Sh h=h′+1k∈Sh
h′ H′
=L +(cid:88) (cid:88) L h (µ −µ )+ (cid:88) (cid:88) L h (µ −µ )
0 |S h| k∗ k |S h| k h∗ k
h=1k∈Sh h=h′+1k∈Sh
(cid:124) (cid:123)(cid:122) (cid:125)
PartI
H′
+ (cid:88) (cid:88) L h (µ −µ ).
|S h| k∗ k h∗
h=h′+1k∈Sh
(cid:124) (cid:123)(cid:122) (cid:125)
PartII
ToboundPartI,wenoticethatallarmsinS arenoteliminatedintheendofthepreviousphase,
h
implying,forh<h′,
(cid:32)(cid:115) (cid:33)
(a) log(2KH/δ) C
µ ⩾ µˆ − +
k k L /|S | L /|S |
h−1 h−1 h−1 h−1
(cid:32)(cid:115) (cid:33)
(b) log(2KH/δ) Cˆ
⩾ max µˆ −2 + h−1
k′∈Sh−1
k′,h−1
L h−1/|S h−1| L h−1/|S h−1|
(cid:32)(cid:115) (cid:33)
log(2KH/δ) C
− +
L /|S | L /|S |
h−1 h−1 h−1 h−1
(cid:32) (cid:115) (cid:33)
(c) log(2KH/δ) 2Cˆ +C
⩾ µˆ − 3 + h−1
k∗,h−1
L /|S | L /|S |
h−1 h−1 h−1 h−1
(cid:32) (cid:115) (cid:33)
(d) log(2KH/δ) 2Cˆ +2C
⩾ µ − 4 + h−1 ,
k∗
L /|S | L /|S |
h−1 h−1 h−1 h−1
whereinequalities(a)and(d)areduetotheHoeffding’sinequalityandtheattackC,inequality(b)is
duetotheeliminationcondition,andinequality(c)isduetok∗ ∈S . Thatis,forarmsk ∈S ,
h−1 h
wehave
(cid:115)
log(2KH/δ) 2(Cˆ +C)
µ −µ ⩽4 + h−1 . (10)
k∗ k L /|S | L /|S |
h−1 h−1 h−1 h−1
Aswehavek∗ ∈S ,andwiththesamederivationas(10),wealsohave
h h
(cid:115)
log(2KH/δ) 2(Cˆ +C)
µ k h∗ −µ k ⩽4 L h−1/|S h−1| + L h−h 1− /1 |S h−1|. (11)
17Therefore,wehave
h′ H′
(cid:88) (cid:88) L h ∆ + (cid:88) (cid:88) L h (µ −µ )
|S h| k |S h| k h∗ k
h=1k∈Sh h=h′+1k∈Sh
( ⩽a)(cid:88)H′
L
·4(cid:115) log(2KH/δ)
+
2(Cˆ h−1+C)
.
h L /|S | L /|S |
h−1 h−1 h−1 h−1
h=1
=(cid:88)H′ (cid:32) 4(cid:115) L2 hlog(2KH/δ)
+
2L h(Cˆ h−1+C)(cid:33)
L /|S | L /|S |
h−1 h−1 h−1 h−1 (12)
h=1
H′
⩽(cid:88)(cid:16) 4(cid:112) 2L Klog(2KH/δ)+4K(Cˆ +C)(cid:17)
h h−1
h=1
H′ H′
=4(cid:112) 2Klog(2KH/δ)(cid:88)(cid:112) L +4K(cid:88) (Cˆ +C)
h h−1
h=1 h=1
(a) (cid:112) √
⩽ 4g 2KL log(2KH/δ)T +4 T log T +4KClog T.
0 2 2
√ √
whereinequality(a)isdueto(10)and(11),andinequality(b)isbecause(cid:80)H′ L ⩽g T since
√ h=1 h
thesummationofageometricincreasingseriesisupperboundedbyg L , forsomeuniversal
H′
constantg >0,andL ⩽T.
H′
Next,weboundPartIIasfollows,
H′ H′
(cid:88) (cid:88) L h (µ −µ )( ⩽a) (cid:88) (cid:88) L h 2CK
|S h| k∗ k h∗ |S h|L 02h′+1
h=h′+1k∈Sh h=h′+1k∈Sh
H′
= (cid:88) 2CKL h
L 2h′+1
h=h′+1 0 (13)
H′
=2CK
(cid:88) 2h−(h′+1)
h=h′+1
(b)
⩽ KC2,
whereinequality(a)isdueto(9),andinequality(b)isbecauseH′−h′ ⩽H −h′ ⩽log C.
2
Hence, substituting (12) and (13) into the regret bound, we have the pseudo-regret bound with a
probabilityofatleast1−δasfollows,
√
R¯ ⩽L +4g(cid:112) 2Klog(2KH/δ)T +4 T log T +4KClog T +KC2
T 0 2 2
(cid:32)(cid:115) (cid:18) KlogT(cid:19) √ (cid:33)
=O KT log + T logT +KClogT +KC2 .
δ
WithasimilaranalysisasintheproofinTheorem6,wecanshowthattherealizedregretR also
T
hasthesameupperbound(inorder)withaprobabilityofatleast1−δ.
18