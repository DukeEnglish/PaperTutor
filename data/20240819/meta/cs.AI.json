[
    {
        "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models",
        "authors": "Le XueManli ShuAnas AwadallaJun WangAn YanSenthil PurushwalkamHonglu ZhouViraj PrabhuYutong DaiMichael S RyooShrikant KendreJieyu ZhangCan QinShu ZhangChia-Chih ChenNing YuJuntao TanTulika Manoj AwalgaonkarShelby HeineckeHuan WangYejin ChoiLudwig SchmidtZeyuan ChenSilvio SavareseJuan Carlos NieblesCaiming XiongRan Xu",
        "links": "http://arxiv.org/abs/2408.08872v1",
        "entry_id": "http://arxiv.org/abs/2408.08872v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08872v1",
        "summary": "This report introduces xGen-MM (also known as BLIP-3), a framework for\ndeveloping Large Multimodal Models (LMMs). The framework comprises meticulously\ncurated datasets, a training recipe, model architectures, and a resulting suite\nof LMMs. xGen-MM, short for xGen-MultiModal, expands the Salesforce xGen\ninitiative on foundation AI models. Our models undergo rigorous evaluation\nacross a range of tasks, including both single and multi-image benchmarks. Our\npre-trained base model exhibits strong in-context learning capabilities and the\ninstruction-tuned model demonstrates competitive performance among open-source\nLMMs with similar model sizes. In addition, we introduce a safety-tuned model\nwith DPO, aiming to mitigate harmful behaviors such as hallucinations and\nimprove safety. We open-source our models, curated large-scale datasets, and\nour fine-tuning codebase to facilitate further advancements in LMM research.\nAssociated resources will be available on our project page above.",
        "updated": "2024-08-16 17:57:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08872v1"
    },
    {
        "title": "GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms",
        "authors": "Yuhao JiaZile WuShengao YiYifei Sun",
        "links": "http://arxiv.org/abs/2408.08852v1",
        "entry_id": "http://arxiv.org/abs/2408.08852v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08852v1",
        "summary": "Recent advancements have focused on encoding urban spatial information into\nhigh-dimensional spaces, with notable efforts dedicated to integrating\nsociodemographic data and satellite imagery. These efforts have established\nfoundational models in this field. However, the effective utilization of these\nspatial representations for urban forecasting applications remains\nunder-explored. To address this gap, we introduce GeoTransformer, a novel\nstructure that synergizes the Transformer architecture with geospatial\nstatistics prior. GeoTransformer employs an innovative geospatial attention\nmechanism to incorporate extensive urban information and spatial dependencies\ninto a unified predictive model. Specifically, we compute geospatial weighted\nattention scores between the target region and surrounding regions and leverage\nthe integrated urban information for predictions. Extensive experiments on GDP\nand ride-share demand prediction tasks demonstrate that GeoTransformer\nsignificantly outperforms existing baseline models, showcasing its potential to\nenhance urban forecasting tasks.",
        "updated": "2024-08-16 17:26:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08852v1"
    },
    {
        "title": "Optimal Symmetries in Binary Classification",
        "authors": "Vishal S. NgairangbamMichael Spannowsky",
        "links": "http://arxiv.org/abs/2408.08823v1",
        "entry_id": "http://arxiv.org/abs/2408.08823v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08823v1",
        "summary": "We explore the role of group symmetries in binary classification tasks,\npresenting a novel framework that leverages the principles of Neyman-Pearson\noptimality. Contrary to the common intuition that larger symmetry groups lead\nto improved classification performance, our findings show that selecting the\nappropriate group symmetries is crucial for optimising generalisation and\nsample efficiency. We develop a theoretical foundation for designing group\nequivariant neural networks that align the choice of symmetries with the\nunderlying probability distributions of the data. Our approach provides a\nunified methodology for improving classification accuracy across a broad range\nof applications by carefully tailoring the symmetry group to the specific\ncharacteristics of the problem. Theoretical analysis and experimental results\ndemonstrate that optimal classification performance is not always associated\nwith the largest equivariant groups possible in the domain, even when the\nlikelihood ratio is invariant under one of its proper subgroups, but rather\nwith those subgroups themselves. This work offers insights and practical\nguidelines for constructing more effective group equivariant architectures in\ndiverse machine-learning contexts.",
        "updated": "2024-08-16 16:15:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08823v1"
    },
    {
        "title": "EasyRec: Simple yet Effective Language Models for Recommendation",
        "authors": "Xubin RenChao Huang",
        "links": "http://arxiv.org/abs/2408.08821v1",
        "entry_id": "http://arxiv.org/abs/2408.08821v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08821v1",
        "summary": "Deep neural networks have become a powerful technique for learning\nrepresentations from user-item interaction data in collaborative filtering (CF)\nfor recommender systems. However, many existing methods heavily rely on unique\nuser and item IDs, which limits their ability to perform well in practical\nzero-shot learning scenarios where sufficient training data may be unavailable.\nInspired by the success of language models (LMs) and their strong\ngeneralization capabilities, a crucial question arises: How can we harness the\npotential of language models to empower recommender systems and elevate its\ngeneralization capabilities to new heights? In this study, we propose EasyRec -\nan effective and easy-to-use approach that seamlessly integrates text-based\nsemantic understanding with collaborative signals. EasyRec employs a\ntext-behavior alignment framework, which combines contrastive learning with\ncollaborative language model tuning, to ensure a strong alignment between the\ntext-enhanced semantic space and the collaborative behavior information.\nExtensive empirical evaluations across diverse real-world datasets demonstrate\nthe superior performance of EasyRec compared to state-of-the-art alternative\nmodels, particularly in the challenging text-based zero-shot recommendation\nscenarios. Furthermore, the study highlights the potential of seamlessly\nintegrating EasyRec as a plug-and-play component into text-enhanced\ncollaborative filtering frameworks, thereby empowering existing recommender\nsystems to elevate their recommendation performance and adapt to the evolving\nuser preferences in dynamic environments. For better result reproducibility of\nour EasyRec framework, the model implementation details, source code, and\ndatasets are available at the link: https://github.com/HKUDS/EasyRec.",
        "updated": "2024-08-16 16:09:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08821v1"
    },
    {
        "title": "Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge",
        "authors": "Ravi RajuSwayambhoo JainBo LiJonathan LiUrmish Thakkar",
        "links": "http://arxiv.org/abs/2408.08808v1",
        "entry_id": "http://arxiv.org/abs/2408.08808v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08808v1",
        "summary": "Large Language Models (LLMs) have revolutionized the landscape of machine\nlearning, yet current benchmarks often fall short in capturing the diverse\nbehavior of these models in real-world applications. A benchmark's usefulness\nis determined by its ability to clearly differentiate between models of varying\ncapabilities (separability) and closely align with human preferences. Existing\nframeworks like Alpaca-Eval 2.0 LC\n\\cite{dubois2024lengthcontrolledalpacaevalsimpleway} and Arena-Hard v0.1\n\\cite{li2024crowdsourced} are limited by their focus on general-purpose queries\nand lack of diversity across domains such as law, medicine, and multilingual\ncontexts. In this paper, we address these limitations by introducing a novel\ndata pipeline that curates diverse, domain-specific evaluation sets tailored\nfor LLM-as-a-Judge frameworks. Our approach leverages a combination of manual\ncuration, semi-supervised learning to generate clusters, and stratified\nsampling to ensure balanced representation across a wide range of domains and\nlanguages. The resulting evaluation set, which includes 1573 samples across 14\ncategories, demonstrates high separability (84\\%) across ten top-ranked models,\nand agreement (84\\%) with Chatbot Arena and (0.915) Spearman correlation. The\nagreement values are 9\\% better than Arena Hard and 20\\% better than AlpacaEval\n2.0 LC, while the Spearman coefficient is 0.7 more than the next best\nbenchmark, showcasing a significant improvement in the usefulness of the\nbenchmark. We further provide an open-source evaluation tool that enables\nfine-grained analysis of model performance across user-defined categories,\noffering valuable insights for practitioners. This work contributes to the\nongoing effort to enhance the transparency, diversity, and effectiveness of LLM\nevaluation methodologies.",
        "updated": "2024-08-16 15:41:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08808v1"
    }
]