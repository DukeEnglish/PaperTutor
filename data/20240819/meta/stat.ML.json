[
    {
        "title": "Shapley Marginal Surplus for Strong Models",
        "authors": "Daniel de MarchiMichael KosorokScott de Marchi",
        "links": "http://arxiv.org/abs/2408.08845v1",
        "entry_id": "http://arxiv.org/abs/2408.08845v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08845v1",
        "summary": "Shapley values have seen widespread use in machine learning as a way to\nexplain model predictions and estimate the importance of covariates. Accurately\nexplaining models is critical in real-world models to both aid in decision\nmaking and to infer the properties of the true data-generating process (DGP).\nIn this paper, we demonstrate that while model-based Shapley values might be\naccurate explainers of model predictions, machine learning models themselves\nare often poor explainers of the DGP even if the model is highly accurate.\nParticularly in the presence of interrelated or noisy variables, the output of\na highly predictive model may fail to account for these relationships. This\nimplies explanations of a trained model's behavior may fail to provide\nmeaningful insight into the DGP. In this paper we introduce a novel variable\nimportance algorithm, Shapley Marginal Surplus for Strong Models, that samples\nthe space of possible models to come up with an inferential measure of feature\nimportance. We compare this method to other popular feature importance methods,\nboth Shapley-based and non-Shapley based, and demonstrate significant\noutperformance in inferential capabilities relative to other methods.",
        "updated": "2024-08-16 17:06:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08845v1"
    },
    {
        "title": "Optimal Symmetries in Binary Classification",
        "authors": "Vishal S. NgairangbamMichael Spannowsky",
        "links": "http://arxiv.org/abs/2408.08823v1",
        "entry_id": "http://arxiv.org/abs/2408.08823v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08823v1",
        "summary": "We explore the role of group symmetries in binary classification tasks,\npresenting a novel framework that leverages the principles of Neyman-Pearson\noptimality. Contrary to the common intuition that larger symmetry groups lead\nto improved classification performance, our findings show that selecting the\nappropriate group symmetries is crucial for optimising generalisation and\nsample efficiency. We develop a theoretical foundation for designing group\nequivariant neural networks that align the choice of symmetries with the\nunderlying probability distributions of the data. Our approach provides a\nunified methodology for improving classification accuracy across a broad range\nof applications by carefully tailoring the symmetry group to the specific\ncharacteristics of the problem. Theoretical analysis and experimental results\ndemonstrate that optimal classification performance is not always associated\nwith the largest equivariant groups possible in the domain, even when the\nlikelihood ratio is invariant under one of its proper subgroups, but rather\nwith those subgroups themselves. This work offers insights and practical\nguidelines for constructing more effective group equivariant architectures in\ndiverse machine-learning contexts.",
        "updated": "2024-08-16 16:15:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08823v1"
    },
    {
        "title": "Explore-then-Commit Algorithms for Decentralized Two-Sided Matching Markets",
        "authors": "Tejas PagareAvishek Ghosh",
        "links": "http://arxiv.org/abs/2408.08690v1",
        "entry_id": "http://arxiv.org/abs/2408.08690v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08690v1",
        "summary": "Online learning in a decentralized two-sided matching markets, where the\ndemand-side (players) compete to match with the supply-side (arms), has\nreceived substantial interest because it abstracts out the complex interactions\nin matching platforms (e.g. UpWork, TaskRabbit). However, past works assume\nthat each arm knows their preference ranking over the players (one-sided\nlearning), and each player aim to learn the preference over arms through\nsuccessive interactions. Moreover, several (impractical) assumptions on the\nproblem are usually made for theoretical tractability such as broadcast\nplayer-arm match Liu et al. (2020; 2021); Kong & Li (2023) or serial\ndictatorship Sankararaman et al. (2021); Basu et al. (2021); Ghosh et al.\n(2022). In this paper, we study a decentralized two-sided matching market,\nwhere we do not assume that the preference ranking over players are known to\nthe arms apriori. Furthermore, we do not have any structural assumptions on the\nproblem. We propose a multi-phase explore-then-commit type algorithm namely\nepoch-based CA-ETC (collision avoidance explore then commit) (\\texttt{CA-ETC}\nin short) for this problem that does not require any communication across\nagents (players and arms) and hence decentralized. We show that for the initial\nepoch length of $T_{\\circ}$ and subsequent epoch-lengths of $2^{l/\\gamma}\nT_{\\circ}$ (for the $l-$th epoch with $\\gamma \\in (0,1)$ as an input parameter\nto the algorithm), \\texttt{CA-ETC} yields a player optimal expected regret of\n$\\mathcal{O}\\left(T_{\\circ} (\\frac{K \\log T}{T_{\\circ} \\Delta^2})^{1/\\gamma} +\nT_{\\circ} (\\frac{T}{T_{\\circ}})^\\gamma\\right)$ for the $i$-th player, where $T$\nis the learning horizon, $K$ is the number of arms and $\\Delta$ is an\nappropriately defined problem gap. Furthermore, we propose a blackboard\ncommunication based baseline achieving logarithmic regret in $T$.",
        "updated": "2024-08-16 12:06:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08690v1"
    },
    {
        "title": "Misclassification excess risk bounds for PAC-Bayesian classification via convexified loss",
        "authors": "The Tien Mai",
        "links": "http://arxiv.org/abs/2408.08675v1",
        "entry_id": "http://arxiv.org/abs/2408.08675v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08675v1",
        "summary": "PAC-Bayesian bounds have proven to be a valuable tool for deriving\ngeneralization bounds and for designing new learning algorithms in machine\nlearning. However, it typically focus on providing generalization bounds with\nrespect to a chosen loss function. In classification tasks, due to the\nnon-convex nature of the 0-1 loss, a convex surrogate loss is often used, and\nthus current PAC-Bayesian bounds are primarily specified for this convex\nsurrogate. This work shifts its focus to providing misclassification excess\nrisk bounds for PAC-Bayesian classification when using a convex surrogate loss.\nOur key ingredient here is to leverage PAC-Bayesian relative bounds in\nexpectation rather than relying on PAC-Bayesian bounds in probability. We\ndemonstrate our approach in several important applications.",
        "updated": "2024-08-16 11:41:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08675v1"
    },
    {
        "title": "A new perspective on Bayesian Operational Modal Analysis",
        "authors": "Brandon J. O'ConnellMax D. ChampneysTimothy J. Rogers",
        "links": "http://arxiv.org/abs/2408.08664v1",
        "entry_id": "http://arxiv.org/abs/2408.08664v1",
        "pdf_url": "http://arxiv.org/pdf/2408.08664v1",
        "summary": "In the field of operational modal analysis (OMA), obtained modal information\nis frequently used to assess the current state of aerospace, mechanical,\noffshore and civil structures. However, the stochasticity of operational\nsystems and the lack of forcing information can lead to inconsistent results.\nQuantifying the uncertainty of the recovered modal parameters through OMA is\ntherefore of significant value. In this article, a new perspective on Bayesian\nOMA is proposed: a Bayesian stochastic subspace identification (SSI) algorithm.\nDistinct from existing approaches to Bayesian OMA, a hierarchical probabilistic\nmodel is embedded at the core of covariance-driven SSI. Through substitution of\ncanonical correlation analysis with a Bayesian equivalent, posterior\ndistributions over the modal properties are obtained. Two inference schemes are\npresented for the proposed Bayesian formulation: Markov Chain Monte Carlo and\nvariational Bayes. Two case studies are then explored. The first is benchmark\nstudy using data from a simulated, multi degree-of-freedom, linear system.\nFollowing application of Bayesian SSI, it is shown that the same posterior is\ntargeted and recovered by both inference schemes, with good agreement between\nthe posterior mean and the conventional SSI result. The second study applies\nthe variational form to data obtained from an in-service structure: The Z24\nbridge. The results of this study are presented at single model orders, and\nthen using a stabilisation diagram. The recovered posterior uncertainty is\npresented and compared to the classic SSI result. It is observed that the\nposterior distributions with mean values coinciding with the natural\nfrequencies exhibit lower variance than values situated away from the natural\nfrequencies.",
        "updated": "2024-08-16 11:11:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.08664v1"
    }
]