[
    {
        "title": "A Large-Scale Exploration of $μ$-Transfer",
        "authors": "Lucas Lingle",
        "links": "http://arxiv.org/abs/2404.05728v1",
        "entry_id": "http://arxiv.org/abs/2404.05728v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05728v1",
        "summary": "Large neural network models have become a mainstay of natural language\nprocessing and computer vision, yet their initialization and learning rates are\nset in a largely heuristic fashion, potentially varying from paper to paper and\none model size to the next. The $\\mu$-Parameterization ($\\mu$P) offers a\npotential solution to these challenges, yielding scaling rules for model\ninitialization and learning rates, and reportedly enabling zero-shot\nhyperparameter transfer from small to large models in a variety of cases.\n  Despite the evident promise, the $\\mu$P scaling rules are not yet widely\nadopted, perhaps due to higher implementation complexity, many variations, or\ncomplex theoretical background. This work investigates $\\mu$P empirically,\nfocusing on the ubiquitous transformer architecture, and aims to answer a\nsimple question: does $\\mu$-Transfer yield optimal learning rates in practice?\nFrom models with 2M to 10B parameters, we show that $\\mu$-Transfer works as\nintended for the majority of important cases, but also identify some surprising\ncases where it may not.",
        "updated": "2024-04-08 17:59:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05728v1"
    },
    {
        "title": "Predicting Overtakes in Trucks Using CAN Data",
        "authors": "Talha Hanif ButtPrayag TiwariFernando Alonso-Fernandez",
        "links": "http://arxiv.org/abs/2404.05723v1",
        "entry_id": "http://arxiv.org/abs/2404.05723v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05723v1",
        "summary": "Safe overtakes in trucks are crucial to prevent accidents, reduce congestion,\nand ensure efficient traffic flow, making early prediction essential for timely\nand informed driving decisions. Accordingly, we investigate the detection of\ntruck overtakes from CAN data. Three classifiers, Artificial Neural Networks\n(ANN), Random Forest, and Support Vector Machines (SVM), are employed for the\ntask. Our analysis covers up to 10 seconds before the overtaking event, using\nan overlapping sliding window of 1 second to extract CAN features. We observe\nthat the prediction scores of the overtake class tend to increase as we\napproach the overtake trigger, while the no-overtake class remain stable or\noscillates depending on the classifier. Thus, the best accuracy is achieved\nwhen approaching the trigger, making early overtaking prediction challenging.\nThe classifiers show good accuracy in classifying overtakes (Recall/TPR > 93%),\nbut accuracy is suboptimal in classifying no-overtakes (TNR typically 80-90%\nand below 60% for one SVM variant). We further combine two classifiers (Random\nForest and linear SVM) by averaging their output scores. The fusion is observed\nto improve no-overtake classification (TNR > 92%) at the expense of reducing\novertake accuracy (TPR). However, the latter is kept above 91% near the\novertake trigger. Therefore, the fusion balances TPR and TNR, providing more\nconsistent performance than individual classifiers.",
        "updated": "2024-04-08 17:58:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05723v1"
    },
    {
        "title": "Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer",
        "authors": "Xinyang GuYen-Jen WangJianyu Chen",
        "links": "http://arxiv.org/abs/2404.05695v1",
        "entry_id": "http://arxiv.org/abs/2404.05695v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05695v1",
        "summary": "Humanoid-Gym is an easy-to-use reinforcement learning (RL) framework based on\nNvidia Isaac Gym, designed to train locomotion skills for humanoid robots,\nemphasizing zero-shot transfer from simulation to the real-world environment.\nHumanoid-Gym also integrates a sim-to-sim framework from Isaac Gym to Mujoco\nthat allows users to verify the trained policies in different physical\nsimulations to ensure the robustness and generalization of the policies. This\nframework is verified by RobotEra's XBot-S (1.2-meter tall humanoid robot) and\nXBot-L (1.65-meter tall humanoid robot) in a real-world environment with\nzero-shot sim-to-real transfer. The project website and source code can be\nfound at: https://sites.google.com/view/humanoid-gym/.",
        "updated": "2024-04-08 17:26:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05695v1"
    },
    {
        "title": "Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding",
        "authors": "Ahmad Idrissi-YaghirAmin DadaHenning SchäferKamyar ArzidehGiulia BaldiniJan TrienesMax HasinJeanette BewersdorffCynthia S. SchmidtMarie BauerKaleb E. SmithJiang BianYonghui WuJörg SchlöttererTorsten ZeschPeter A. HornChristin SeifertFelix NensaJens KleesiekChristoph M. Friedrich",
        "links": "http://arxiv.org/abs/2404.05694v1",
        "entry_id": "http://arxiv.org/abs/2404.05694v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05694v1",
        "summary": "Recent advances in natural language processing (NLP) can be largely\nattributed to the advent of pre-trained language models such as BERT and\nRoBERTa. While these models demonstrate remarkable performance on general\ndatasets, they can struggle in specialized domains such as medicine, where\nunique domain-specific terminologies, domain-specific abbreviations, and\nvarying document structures are common. This paper explores strategies for\nadapting these models to domain-specific requirements, primarily through\ncontinuous pre-training on domain-specific data. We pre-trained several German\nmedical language models on 2.4B tokens derived from translated public English\nmedical data and 3B tokens of German clinical data. The resulting models were\nevaluated on various German downstream tasks, including named entity\nrecognition (NER), multi-label classification, and extractive question\nanswering. Our results suggest that models augmented by clinical and\ntranslation-based pre-training typically outperform general domain models in\nmedical contexts. We conclude that continuous pre-training has demonstrated the\nability to match or even exceed the performance of clinical models trained from\nscratch. Furthermore, pre-training on clinical data or leveraging translated\ntexts have proven to be reliable methods for domain adaptation in medical NLP\ntasks.",
        "updated": "2024-04-08 17:24:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05694v1"
    },
    {
        "title": "Evaluating the Efficacy of Cut-and-Paste Data Augmentation in Semantic Segmentation for Satellite Imagery",
        "authors": "Ionut M. MotoiLeonardo SaraceniDaniele NardiThomas A. Ciarfuglia",
        "links": "http://arxiv.org/abs/2404.05693v1",
        "entry_id": "http://arxiv.org/abs/2404.05693v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05693v1",
        "summary": "Satellite imagery is crucial for tasks like environmental monitoring and\nurban planning. Typically, it relies on semantic segmentation or Land Use Land\nCover (LULC) classification to categorize each pixel. Despite the advancements\nbrought about by Deep Neural Networks (DNNs), their performance in segmentation\ntasks is hindered by challenges such as limited availability of labeled data,\nclass imbalance and the inherent variability and complexity of satellite\nimages. In order to mitigate those issues, our study explores the effectiveness\nof a Cut-and-Paste augmentation technique for semantic segmentation in\nsatellite images. We adapt this augmentation, which usually requires labeled\ninstances, to the case of semantic segmentation. By leveraging the connected\ncomponents in the semantic segmentation labels, we extract instances that are\nthen randomly pasted during training. Using the DynamicEarthNet dataset and a\nU-Net model for evaluation, we found that this augmentation significantly\nenhances the mIoU score on the test set from 37.9 to 44.1. This finding\nhighlights the potential of the Cut-and-Paste augmentation to improve the\ngeneralization capabilities of semantic segmentation models in satellite\nimagery.",
        "updated": "2024-04-08 17:18:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05693v1"
    }
]