[
    {
        "title": "Language-Independent Representations Improve Zero-Shot Summarization",
        "authors": "Vladimir SolovyevDanni LiuJan Niehues",
        "links": "http://arxiv.org/abs/2404.05720v1",
        "entry_id": "http://arxiv.org/abs/2404.05720v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05720v1",
        "summary": "Finetuning pretrained models on downstream generation tasks often leads to\ncatastrophic forgetting in zero-shot conditions. In this work, we focus on\nsummarization and tackle the problem through the lens of language-independent\nrepresentations. After training on monolingual summarization, we perform\nzero-shot transfer to new languages or language pairs. We first show naively\nfinetuned models are highly language-specific in both output behavior and\ninternal representations, resulting in poor zero-shot performance. Next, we\npropose query-key (QK) finetuning to decouple task-specific knowledge from the\npretrained language generation abilities. Then, after showing downsides of the\nstandard adversarial language classifier, we propose a balanced variant that\nmore directly enforces language-agnostic representations. Moreover, our\nqualitative analyses show removing source language identity correlates to\nzero-shot summarization performance. Our code is openly available.",
        "updated": "2024-04-08 17:56:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05720v1"
    },
    {
        "title": "SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing",
        "authors": "Jing GuYilin WangNanxuan ZhaoWei XiongQing LiuZhifei ZhangHe ZhangJianming ZhangHyunJoon JungXin Eric Wang",
        "links": "http://arxiv.org/abs/2404.05717v1",
        "entry_id": "http://arxiv.org/abs/2404.05717v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05717v1",
        "summary": "Effective editing of personal content holds a pivotal role in enabling\nindividuals to express their creativity, weaving captivating narratives within\ntheir visual stories, and elevate the overall quality and impact of their\nvisual content. Therefore, in this work, we introduce SwapAnything, a novel\nframework that can swap any objects in an image with personalized concepts\ngiven by the reference, while keeping the context unchanged. Compared with\nexisting methods for personalized subject swapping, SwapAnything has three\nunique advantages: (1) precise control of arbitrary objects and parts rather\nthan the main subject, (2) more faithful preservation of context pixels, (3)\nbetter adaptation of the personalized concept to the image. First, we propose\ntargeted variable swapping to apply region control over latent feature maps and\nswap masked variables for faithful context preservation and initial semantic\nconcept swapping. Then, we introduce appearance adaptation, to seamlessly adapt\nthe semantic concept into the original image in terms of target location,\nshape, style, and content during the image generation process. Extensive\nresults on both human and automatic evaluation demonstrate significant\nimprovements of our approach over baseline methods on personalized swapping.\nFurthermore, SwapAnything shows its precise and faithful swapping abilities\nacross single object, multiple objects, partial object, and cross-domain\nswapping tasks. SwapAnything also achieves great performance on text-based\nswapping and tasks beyond swapping such as object insertion.",
        "updated": "2024-04-08 17:52:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05717v1"
    },
    {
        "title": "Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer",
        "authors": "Xinyang GuYen-Jen WangJianyu Chen",
        "links": "http://arxiv.org/abs/2404.05695v1",
        "entry_id": "http://arxiv.org/abs/2404.05695v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05695v1",
        "summary": "Humanoid-Gym is an easy-to-use reinforcement learning (RL) framework based on\nNvidia Isaac Gym, designed to train locomotion skills for humanoid robots,\nemphasizing zero-shot transfer from simulation to the real-world environment.\nHumanoid-Gym also integrates a sim-to-sim framework from Isaac Gym to Mujoco\nthat allows users to verify the trained policies in different physical\nsimulations to ensure the robustness and generalization of the policies. This\nframework is verified by RobotEra's XBot-S (1.2-meter tall humanoid robot) and\nXBot-L (1.65-meter tall humanoid robot) in a real-world environment with\nzero-shot sim-to-real transfer. The project website and source code can be\nfound at: https://sites.google.com/view/humanoid-gym/.",
        "updated": "2024-04-08 17:26:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05695v1"
    },
    {
        "title": "Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding",
        "authors": "Ahmad Idrissi-YaghirAmin DadaHenning SchäferKamyar ArzidehGiulia BaldiniJan TrienesMax HasinJeanette BewersdorffCynthia S. SchmidtMarie BauerKaleb E. SmithJiang BianYonghui WuJörg SchlöttererTorsten ZeschPeter A. HornChristin SeifertFelix NensaJens KleesiekChristoph M. Friedrich",
        "links": "http://arxiv.org/abs/2404.05694v1",
        "entry_id": "http://arxiv.org/abs/2404.05694v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05694v1",
        "summary": "Recent advances in natural language processing (NLP) can be largely\nattributed to the advent of pre-trained language models such as BERT and\nRoBERTa. While these models demonstrate remarkable performance on general\ndatasets, they can struggle in specialized domains such as medicine, where\nunique domain-specific terminologies, domain-specific abbreviations, and\nvarying document structures are common. This paper explores strategies for\nadapting these models to domain-specific requirements, primarily through\ncontinuous pre-training on domain-specific data. We pre-trained several German\nmedical language models on 2.4B tokens derived from translated public English\nmedical data and 3B tokens of German clinical data. The resulting models were\nevaluated on various German downstream tasks, including named entity\nrecognition (NER), multi-label classification, and extractive question\nanswering. Our results suggest that models augmented by clinical and\ntranslation-based pre-training typically outperform general domain models in\nmedical contexts. We conclude that continuous pre-training has demonstrated the\nability to match or even exceed the performance of clinical models trained from\nscratch. Furthermore, pre-training on clinical data or leveraging translated\ntexts have proven to be reliable methods for domain adaptation in medical NLP\ntasks.",
        "updated": "2024-04-08 17:24:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05694v1"
    },
    {
        "title": "Automated discovery of symbolic laws governing skill acquisition from naturally occurring data",
        "authors": "Sannyuya LiuQing LiXiaoxuan ShenJianwen SunZongkai Yang",
        "links": "http://arxiv.org/abs/2404.05689v1",
        "entry_id": "http://arxiv.org/abs/2404.05689v1",
        "pdf_url": "http://arxiv.org/pdf/2404.05689v1",
        "summary": "Skill acquisition is a key area of research in cognitive psychology as it\nencompasses multiple psychological processes. The laws discovered under\nexperimental paradigms are controversial and lack generalizability. This paper\naims to unearth the laws of skill learning from large-scale training log data.\nA two-stage algorithm was developed to tackle the issues of unobservable\ncognitive states and algorithmic explosion in searching. Initially a deep\nlearning model is employed to determine the learner's cognitive state and\nassess the feature importance. Subsequently, symbolic regression algorithms are\nutilized to parse the neural network model into algebraic equations. The\nexperimental results of simulated data demonstrate that the proposed algorithm\ncan accurately restore various preset laws within a certain range of noise, in\ncontinues feedback setting. Application of proposed method to Lumosity training\ndata demonstrates superior performance compared to traditional and latest\nmodels in terms of fitness. The results indicate the discovery of two new forms\nof skill acquisition laws, while some previous findings have been reaffirmed.",
        "updated": "2024-04-08 17:15:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.05689v1"
    }
]