VietMed: A Dataset and Benchmark for Automatic
Speech Recognition of Vietnamese in the Medical Domain
Khai Le-Duc∗
UniversityofToronto,Canada
duckhai.le@mail.utoronto.ca
Abstract
Duetoprivacyrestrictions,there’sashortageofpubliclyavailablespeechrecognitiondatasetsinthemedicaldomain.
Inthiswork,wepresentVietMed-aVietnamesespeechrecognitiondatasetinthemedicaldomaincomprising16h
oflabeledmedicalspeech,1000hofunlabeledmedicalspeechand1200hofunlabeledgeneral-domainspeech. To
ourbestknowledge,VietMedisbyfartheworld’slargestpublicmedicalspeechrecognitiondatasetin7aspects:
totalduration,numberofspeakers,diseases,recordingconditions,speakerroles,uniquemedicaltermsandaccents.
VietMedisalsobyfarthelargestpublicVietnamesespeechdatasetintermsoftotalduration. Additionally,wearethe
firsttopresentamedicalASRdatasetcoveringallICD-10diseasegroupsandallaccentswithinacountry. Moreover,
wereleasethefirstpubliclarge-scalepre-trainedmodelsforVietnameseASR,w2v2-VietandXLSR-53-Viet,along
withthefirstpubliclarge-scalefine-tunedmodelsformedicalASR.Evenwithoutanymedicaldatainunsupervised
pre-training,ourbestpre-trainedmodelXLSR-53-Vietgeneralizesverywelltothemedicaldomainbyoutperforming
state-of-the-artXLSR-53,from51.8%to29.6%WERontestset(arelativereductionofmorethan40%). Allcode,
dataandmodelsaremadepubliclyavailablehere.
Keywords:medicalspeechrecognition,dataset,semi-supervisedlearning
1. Introduction onrespiratorydiseases. Thissituationrestrictsin-
vestigations to a single disease topic, hindering
Machinelearningmodelsrequirelargeamountsof
researchersfromexploringexperimentsrelatedto
trainingdata. However,thescarcityoflanguagere-
othermedicalconditions. Also,aspointedoutby
sourcesforVietnameseandespeciallyforthemedi-
the authors, this dataset collected speech exclu-
caldomainhasbeenhinderingtheadvancementof
sively from the West England population, which
correspondingautomaticspeechrecognition(ASR)
mighthurtgeneralizabilitytootheraccents.
systems. Also,thelackofpubliclyavailablespeech
Regarding Vietnamese ASR, to the best of our
datasetsandmodelsinthesedomainshasledto
knowledge, there are currently no public large-
difficultiesinreproducingexperiments.
scale pre-trained models that are peer-reviewed
Recently,researcheffortshavebeendirectedto-
andreproducible2. TheXLSR-53model(Conneau
wardsASRtasksinthemedicalfield,suchasthe
etal.,2021),wasunsupervisedpre-trainedon56k
works(Lüscheretal.,2023;Vietingetal.,2023)fo-
hours of 53 languages, but it includes only 200
cusedonthedevelopmentofhybridASRsystems
hours of Vietnamese data. Therefore, the con-
to transcribe multilingual telephone speech data
strainedperformancewhenfine-tuningtheXLSR-
frompatient-physicianconversations. Besides,the
53modelonVietnameseisconceivable(Le-Duc,
works(Edwardsetal.,2017;Chiuetal.,2018)tack-
2023).
leddifficultacousticconditionsandtheabsenceof
Tohandletheconcernsabove,wepresentahigh-
domain-specificdata. Nevertheless,noneofthese
quality dataset for Vietnamese medical speech
studiesreleasedtheirowndatasetsorpre-trained
recognition. Tothebestofourknowledge,VietMed
models.
isbyfartheworld’slargestpublicmedicalspeech
Outofthelimitednumberofpublicmedicalspeech
datasetintermsoftotalduration,numberofspeak-
datasets we identified, to the best of our knowl-
ers,diseases,recordingconditions,speakerroles,
edge,oneofthemoffersatotalof8hoursofEn-
uniquemedicaltermsandaccents. Also,VietMed
glishspeechdata;however,thedataset’squalityis
low,asindicatedbytheauthorsontheirwebpage1, is by far the largest public Vietnamese speech
dataset in terms of total duration. Moreover, Vi-
wheretheymentionedissuessuchasincorrectla-
etMed is the first medical ASR dataset covering
bels and audio files. The second public English
all ICD-10 disease groups and all accents within
medicalspeechdataset(Fareezetal.,2022)com-
acountry. Wethenempiricallyevaluatebaseline
prises simulated data, with a predominant focus
modelsonourdataset. Ourkeycontributionsare:
(*)WorkdoneduringthebachelorthesisatLehrstuhl
Informatik6-MachineLearningandHumanLanguage 2Several pre-trained models for Vietnamese ASR
TechnologyGroup,RWTHAachenUniversity,Germany are available on HuggingFace and GitHub, but none
1https://www.kaggle.com/datasets/paultimothy- ofthemhaveundergonepeerreview. Theirresultsare
mooney/medical-speech-transcription-and-intent self-reported,andwewereunabletoreproducethem.• WepresentVietMed dataset,whichincludes and Consent are in the Appendix). We man-
16 hours of labeled medical speech, 1000 ually removed non-speech elements like music,
hoursofunlabeledmedicalspeechand1200 noise, long silences, and any parts that could re-
hoursofunlabeledgeneral-domainspeech. vealspeakeridentities. Specifically,weremoved
speakernames,locationswheretheylive,organi-
• We release the first public large-scale pre-
zationswheretheywork,personalcontacts(phone
trained models for Vietnamese ASR, which
numbers,emails,etc.),personalidentifier(dateof
arepeer-reviewedandreproducible.
birth,bankaccount,idnumber,etc.),etc. Wecon-
• We release the first public large-scale fine- vertedMP3audiofilesto8kHzwavformat,creating
tunedmodelsformedicalASR. 10-30secondsegmentsforVietMed-U andViet-U,
and<10secondsegmentsforVietMed-L.Also,we
Given the transferability of medical terms across
encoded segment names, retaining only ICD-10
languagesatsomedegree,ouraimistocontribute
code tags to enhance privacy. Finally, we shuf-
to future research in medical ASR for other lan-
fledallsegmentsofVietMed-U andViet-U,making
guages. Allcode,dataandmodelsarepublished
online3,4. about500kmeaninglesssegments. Thepurpose
here is to prevent immoral users from concate-
2. Data natingsegmentsintomeaningfulconversationsto
learnmoreaboutspeakers.
VietMeddatacomprisesof3sets,namelyVietMed-
L for labeled medical speech, VietMed-U for un-
2.3. Annotation Process
labeledmedicalspeech,andViet-U forunlabeled
generaldomainspeech. WethensplitVietMed-L Manualannotationofmedicalspontaneousspeech
into3subsets,train(VietMed-Train),dev(VietMed- ischallengingforhumans(Edwardsetal.,2017).
Dev)andtest(VietMed-Test)withdurationbeing5 Annotatorsmayproducevaryingtranscripts. Also,
hours,5hours,and6hoursrespectively,avoiding applyingthefullyautomatedapproach(Chenetal.,
speaker overlap between the train, dev and test 2021)requireslarge-scaleASRmodels,whichare
sets. unavailableinthemedicaldomainandsufferfrom
lowqualityduetolimitedhumansupervision. We
2.1. Metadata
thereforeimplementedacomputer-assistedwork-
flowformedicalannotation,outlinedasfollows:
Audioname Rec. Role Accent
VietMed_001 Tel. Doctor North 1. Weinitiallygatheredtranscriptsgeneratedby
YouTube.
SpeakerID ICD-10 Gender Hours
VietMed_001_a J00-J99 Male 0.06
2. A native Vietnamese with a Biomedical En-
gineeringdegreecorrectedtheautomatically
Table1: ExampleofMetadata_labeled.xlsx. Rec.
generatedtranscriptsmanually. Thisreduced
standsforRecordingcondition,inthisexampleis
annotation time by 70% and improved tran-
Tel. (Telephone). Details of ICD-10 codes are
script quality, as it could address issues like
shown in Table 7 of the Appendix. The speaker
stutteringwordsandspeakingratevariations
role is defined by common roles of speakers in
commoninreal-worldconversations.
conversations,whichtypicallyare: doctor,patient,
host,broadcaster,etc.
3. AnothernativeVietnameseindependentlyan-
notatedusingthesameapproach.
We saved all the metadata information to
files named Metadata_labeled.xlsx and Medi- 4. Theresultingtwocomputer-assistedannota-
cal_terms.txt. AsshowninTable1,wedesigned tion versions were merged and compared.
metadatainawaythatcansupportmultipletasks Segments with large differences were ex-
apartfromASR,forexample: speakerrecognition, cluded.
keywordrecognition,oraccentrecognition.
5. Finally, we divided the merged transcripts
2.2. Data Collection into 3 small validation subsets, where three
WefirstlegallycrawledaudiodatafromYouTube otherVietnamesewithmedicalbackgrounds
under Fair Use Policies5,6 (Details of Fair Use assessedqualitythroughmanualannotation
withoutassistancebyautomatictranscription.
3https://github.com/leduckhai/MultiMed We then merged the computer-assisted and
4https://github.com/rwth-i6/returnn-experiments non-computer-assistedversionsasinstep4.
5https://support.google.com/youtube/an-
swer/9783148 Detailed concerns about the noisy speech in our
6https://www.copyright.gov/fair-use/ datasetareshownintheAppendix.Labeled Unlabeled
Medical General
Length[hours] 16 966 1204
#Speakers 61 2352 202
#Record. cond. 8 9 1
#Med. terms 978 - -
#Accents 6 6 2
#Roles 6 6 2
Table2: StatisticsofVietMed-L,VietMed-U,Viet-
U,retrievedfromfile”Metadata”inthedataset.
2.4. Data Statistics
2.4.1. LabeledMedicalDataVietMed-L
InTable2,VietMed-Lcontains16hoursofanno-
tatedaudio,surpassingotherprivatemedicalASR
datasets (Qorib and Adriani, 2018; Chung et al.,
2021). Also, VietMed-L has a much higher num-
berofspeakersanduniquemedicalterms. Unlike
most datasets that only use simulated scenarios
(Lüscheretal.,2023;Fareezetal.,2022),VietMed-
L captures real-life situations across 8 recording
conditions,includingtelephone(e.g. telemedicine),
lectures(e.g. inuniversityhospitals),news(e.g. in
Figure1: DistributionofICD-10codesandaccents
medical centers), audiobooks (e.g. medical text-
inVietMed-L.
books),where85%ofthecontentisspontaneous
speech. Additionally,weincludespeechfromvar-
iousrolessuchaslecturers,hosts,broadcasters, NorthernMale SouthernMale
beyondjustdoctorsandpatients. Furthermore,we 213h 183h
ensurediversitybygathering6accentsrepresent- NorthernFemale SouthernFemale
ingallregions. 518h 290h
In Figure 1, rather than primarily focusing on the
respiratorydiseasegroup(J00-J99)asin(Fareez Table3: GendersandaccentsinViet-U.
et al., 2022), VietMed-L has data from 22/22 dis-
ease groups as per World Health Organization
(WHO)’s ICD-10 code7, supporting the dataset’s 2.5. Extra Text Data ExtraText
generalizability. Also, the accents closely match
In Table 4, besides VietMed-Train for language
the real accent distribution8 (see Table B.2 in
model (LM), we used extra text data ExtraText
theAppendix),andthemale/femaleratio(54.7%-
to gain lower PPLs. Sources are: VIVOS9 (Lu-
45.3%)isquitebalanced.
ong and Vu, 2016), BABEL10, CommonVoice11
(Ardilaetal.,2020),FOSD12 (Tran,2020),VNTC-
2.4.2. UnlabeledMedicalDataVietMed-U Health13,VLSP202014,ViHealthBERT-FAQ(Minh
In Table 2, we collected VietMed-U in a manner etal.,2022)andPhoNER-Covid19(Truongetal.,
similartoVietMed-L,assuringacomparablegen- 2021).
eralizabilityasinFigure1. DistributionofICD-10
codesandaccentsisinFigure2andFigure3of 2.6. Lexicon
theAppendix. We used the BABEL project’s seed lexicon and
augmenteditwitheitherVietMed-TrainorVietMed-
2.4.3. UnlabeledGeneralDomainDataViet-U
In real world, audiobooks are typically recorded 9http://ailab.hcmus.edu.vn/vivos
using major Northern and Southern accents. In 10https://www.iarpa.gov/research-programs/babel
Table3,statisticsofViet-U isshown.
11https://commonvoice.mozilla.org/
12https://www.kaggle.com/datasets/thinh127/fpt-open-
speech-dataset-fosd-vietnamese
7https://www.icd10data.com/ICD10CM/Codes 13https://github.com/duyvuleo/VNTC
8https://www.gso.gov.vn/en/population/ 14https://vlsp.org.vn/Trainedlexicon LM VietMed-Dev VietMed-Test
#words #vocab #words Size[MB] OOV PPL OOV PPL
VietMed-Train(70k) 1 149 210
VietMed-Train(70k) 5295 0.76% 0.66%
VietMed-Train 98 66 84
VietMed-Train +ExtraText (8.5M)
33904 103 - 69 - 87
+ExtraText (8.5M)
Table4: Resultsof4-gramLMsfor2lexica.
Train + ExtraText. Using the toolkit Sequitur WER[%]onVietMed-Dev
Grapheme-To-Phoneme15 (BisaniandNey,2008) Mono Tri SAT VTLN SAT+VTLN
-theconversiontoolonthesepronunciationlexica, 71.7 61.3 52.6 61.3 52.2
theseedlexiconwasextended,creatingthelexica
fortraining. Table5: Word-Error-Rates(WERs)[%]ofGMM-
HMMonVietMed-Dev. StepsgofromMonophone,
Triphone to Speaker Adaptive Training + Vocal
3. Experimental Setups TractLengthNormalization.
ForlanguagemodellingandinitialGaussianMix-
ture - Hidden Markov Model (GM-HMM), we fol-
WER[%]
lowedthesamesetupsandhyperparametersasin Pre-trainedmodel
dev test
(Lüscheretal.,2023). Theacousticmodellabels
None Non-converged
weregeneralizedtriphonestatesobtainedbyclassi-
XLSR-53 45.2 51.8
ficationandregressiontreeswith4501labels. For
w2v2-Viet 45.3 49.5
unsupervisedwav2vec2.0training(Baevskietal.,
XLSR-53-Viet 26.8 29.6
2020) and fine-tuning, we used the same vanilla
setupsandhyperparametersin(Le-Duc,2023). All
Table 6: WERs of wav2vec 2.0 baselines on
models had 118M parameters including 7 CNN
VietMed-Dev and VietMed-Test. w2v2-Viet was
layers and 8 Transformer layers. The last CNN
pre-trainedfromscratchonViet-U.XLSR-53-Viet
layer had a stride halved for the 8kHz data. We
waspre-trainedwithXLSR-53 asinitializationon
thenchosethepre-trainingepochtofine-tunewith
Viet-U.Allmodelshavethesamearchitectureand
FramewiseCross-Entropy(fCE)lossthatledtothe
hyperparameters.
bestWERsondev. TheSpecAugment(Parketal.,
2019)wasusedduring33fine-tuningepochs.
WeusedRETURNN(Zeyeretal.,2018)forsuper-
visedtrainingandFairseq(Ottetal.,2019)forunsu- 4.3. Hybrid wav2vec 2.0 Baselines
pervisedwav2vec2.0training. Decodingwasper-
formedwithRASR(Rybachetal.,2011). Fairseq As shown in Table 6, training from scratch did
modelswereconvertedtoRETURNNmodelswith not converge, possibly due to the limited 5-hour
ourPyTorch-to-RETURNNtoolkit16. fine-tuning data. XLSR-53 is a state-of-the-art
modelpre-trainedon56khoursof53languages.
Fine-tuningXLSR-53onVietMed-Trainhelpedre-
4. Experimental Results duceWERfrom52.6%to45.2%onVietMed-Dev.
Ourw2v2-Viet modelwascompetitivetoXLSR-53
4.1. Language Model despite using 46 times less data for pre-training.
We obtained further improvements by applying
InTable4,augmentingtheseedlexiconwithonly ourXLSR-53-Viet model,whichreducedWERsto
VietMed-TraintotrainVietMed-Train+ExtraTextfor 26.8%and29.6%ondevandtestsetrespectively,
LMyieldsthebestPPLs. equivalenttorelativeWERRof41.8%comparedto
theXLSR-53model. Inbothourmodels,wedidn’t
adapt the in-domain data VietMed-U during the
4.2. GM-HMM Alignments
unsupervised pre-training, although we believed
In Table 5, understanding that WER isn’t always doingsocouldfurtherenhanceWERsandweleave
aprecisemetricforalignmentqualityassessment, itforfuturework.
we found that WER of SAT was quite similar to
SAT+VTLN.Therefore,wechoseSATalignments
asinputforhybridwav2vec2.0trainingtobypass 15https://github.com/sequitur-g2p/sequitur-g2p
somestepsinGM-HMMprocess. 16https://github.com/rwth-i6/pytorch-to-returnn5. Conclusion 7. Bibliographical References
In this work, we present VietMed - a medical
speech recognition dataset for Vietnamese. We
Rosana Ardila, Megan Branson, Kelly Davis,
introduce a high-quality annotation approach for
MichaelKohler,JoshMeyer,MichaelHenretty,
medicalASRdatasetthatsaves70%oftime. Also,
ReubenMorais,LindsaySaunders,FrancisTy-
weoutlineourworkoncreatingaLMwithaccept-
ers,andGregorWeber.2020. Commonvoice:
able PPL and a compact size. Finally, our best
Amassively-multilingualspeechcorpus. InPro-
pre-trainedmodelXLSR-53-Viet outperformsthe
ceedings of the Twelfth Language Resources
vanillastate-of-the-artXLSR-53byreducingWERs
andEvaluationConference,pages4218–4222.
from51.8%to29.6%WERontestset(arelative
reduction of more than 40%) without using any Alexei Baevski, Henry Zhou, Abdelrahman Mo-
medicaldatainunsupervisedpre-training. hamed,andMichaelAuli.2020. Wav2vec2.0: A
frameworkforself-supervisedlearningofspeech
6. Acknowledgements
representations. InProceedingsofthe34thIn-
This work was partially supported by the project ternational Conference on Neural Information
HYKISTfundedbytheGermanFederalMinistryof ProcessingSystems,NIPS’20.
Health on the basis of a decision of the German
Maximilian Bisani and Hermann Ney. 2008.
FederalParliament(Bundestag)underfundingID
Joint-sequence models for grapheme-to-
ZMVI1-2520DAT04A.
phonemeconversion. Speechcommunication,
WethankMinh-NghiaPhan,PeterVieting,Robin
50(5):434–451.
Schmitt,MoritzGunz,JulianDierkesfortheirpre-
ciousassistanceinexperimentalsetups. GuoguoChen,ShuzhouChai,GuanboWang,Ji-
We also appreciate Christoph Lüscher, Ralf ayuDu,WeiQiangZhang,ChaoWeng,DanSu,
Schlüter,HermannNeyfortheirvaluablefeedback DanielPovey,JanTrmal,JunboZhang,Mingjie
onthiswork. Jin,SanjeevKhudanpur,ShinjiWatanabe,Shuai-
jiangZhao,WeiZou,XiangangLi,XuchenYao,
Yongqing Wang, Zhao You, and Zhiyong Yan.
2021. Gigaspeech: An evolving, multi-domain
asrcorpuswith10,000hoursoftranscribedau-
dio. Proc.Interspeech2021,pages4376–4380.
Chung-ChengChiu,AnshumanTripathi,Katherine
Chou, Chris Co, Navdeep Jaitly, Diana Jaun-
zeikare,AnjuliKannan,PatrickNguyen,Hasim
Sak,AnanthSankar,JustinTansuwan,Nathan
Wan,YonghuiWu,andXuedongZhang.2018.
SpeechRecognitionforMedicalConversations.
InProc.Interspeech2018,pages2972–2976.
Sheng-LuenChung,Yi-ShiuanLi,andHsien-Wei
Ting. 2021. Data centric approach to chinese
medicalspeechrecognition. InProceedingsof
the33rdConferenceonComputationalLinguis-
ticsandSpeechProcessing(ROCLING2021),
pages72–80.
Alexis Conneau, Alexei Baevski, Ronan Col-
lobert,AbdelrahmanMohamed,andMichaelAuli.
2021. UnsupervisedCross-LingualRepresenta-
tionLearningforSpeechRecognition. InProc.
Interspeech2021,pages2426–2430.
ErikEdwards,WaelSalloum,GregPFinley,James
Fone, Greg Cardiff, Mark Miller, and David
Suendermann-Oeft. 2017. Medical speech
recognition: reaching parity with humans. In
SpeechandComputer: 19thInternationalCon-
ference, SPECOM 2017, Proc. 19, pages
512–524.FaihaFareez,TishyaParikh,ChristopherWavell, opensourcespeechrecognitiontoolkit. In2011
SabaShahab,MeghanChevalier,ScottGood, IEEEWorkshoponAutomaticSpeechRecogni-
Isabella De Blasi, Rafik Rhouma, Christopher tion&Understanding.
McMahon,Jean-PaulLam,etal.2022.Adataset
DucChungTran.2020. FPTopenspeechdataset
ofsimulatedpatient-physicianmedicalinterviews
(FOSD)-vietnamese.
withafocusonrespiratorycases.ScientificData,
9(1):313.
ThinhHungTruong,MaiHoangDao,andDatQuoc
Nguyen.2021. COVID-19NamedEntityRecog-
KhaiLe-Duc.2023. Unsupervisedpre-trainingfor
nition for Vietnamese. In Proceedings of the
vietnameseautomaticspeechrecognitioninthe
2021ConferenceoftheNorthAmericanChapter
hykistproject. arXivpreprintarXiv:2309.15869.
oftheAssociationforComputationalLinguistics:
BachelorthesisatFHAachenUniversityofAp-
HumanLanguageTechnologies.
pliedSciences.
Peter Vieting, Christoph Lüscher, Julian Dierkes,
Hieu-Thi Luong and Hai-Quan Vu. 2016. A
Ralf Schlüter, and Hermann Ney. 2023. Effi-
non-expertkaldirecipeforvietnamesespeech
cient utilization of large pre-trained models for
recognition system. In Proceedings of the
low resource asr. In 2023 IEEE International
ThirdInternationalWorkshoponWorldwideLan-
Conference on Acoustics, Speech, and Signal
guageServiceInfrastructureandSecondWork-
ProcessingWorkshops(ICASSPW).
shop on Open Infrastructures and Analysis
FrameworksforHumanLanguageTechnologies AlbertZeyer,TamerAlkhouli,andHermannNey.
(WLSI/OIAF4HLT2016),pages51–55. 2018. RETURNN as a generic flexible neural
toolkitwithapplicationtotranslationandspeech
ChristophLüscher,MohammadZeineldeen,Zijian
recognition. InAnnualMeetingoftheAssoc.for
Yang,PeterVieting,KhaiLe-Duc,WeiyueWang,
ComputationalLinguistics.
RalfSchlüter,andHermannNey.2023.Develop-
mentofhybridasrsystemsforlowresourcemed-
icaldomainconversationaltelephonespeech. In
ITGSpeechCommunication.
NguyenMinh,VuHoangTran,VuHoang,HuyDuc
Ta, Trung Huu Bui, and Steven Quoc Hung
Truong. 2022. Vihealthbert: Pre-trained lan-
guagemodelsforvietnameseinhealthtextmin-
ing. InProceedingsoftheLanguageResources
andEvaluationConference,pages328–337.
MyleOtt,SergeyEdunov,AlexeiBaevski,Angela
Fan, Sam Gross, Nathan Ng, David Grangier,
andMichaelAuli.2019. fairseq: Afast,extensi-
ble toolkit for sequence modeling. In Proceed-
ingsofthe2019ConferenceoftheNorthAmeri-
canChapteroftheAssociationforComputational
Linguistics(Demonstrations),pages48–53.
Daniel S Park, William Chan, Yu Zhang, Chung-
Cheng Chiu, Barret Zoph, Ekin D Cubuk, and
Quoc V Le. 2019. Specaugment: A simple
dataaugmentationmethodforautomaticspeech
recognition. Interspeech.
MuhammadRezaQoribandMirnaAdriani.2018.
Building medisco: Indonesian speech corpus
formedicaldomain. In2018InternationalCon-
ferenceonAsianLanguageProcessing(IALP),
pages133–138.
DavidRybach,StefanHahn,PatrickLehnen,David
Nolden,MartinSundermeyer,ZoltánTüske,Si-
monWiesler,RalfSchlüter,andHermannNey.
2011. RASR - the RWTH Aachen UniversityA. Ethical Statements Accordingtothelaw,weassertourdefenseunder
the Fair Use doctrine with the help of Fair Use
A.1. Fair Use
explanation18 bycopyrightalliance.organdELRC
We strictly followed the criteria of Fair Use by Reportonlegalissuesinwebcrawling19 byPawel
The U.S. Copyright Office17, which also applies Kamockiasfollows:
to YouTube platform. Section 107 of the Copy-
• (1) Obviously we crawled the data and pub-
rightActprovidesthestatutoryframeworkforde-
lishedonlyfornon-commercialandresearch
terminingwhethersomethingisafairuseandiden-
purposes.
tifiescertaintypesofuses—suchascriticism,com-
ment,newsreporting,teaching,scholarship,and
• (1)Wedidnotdirectlyusevideoscrawledfrom
research—asexamplesofactivitiesthatmayqual-
YouTube. Instead,wetransformedtheminto
ifyasfairuse. Section107callsforconsideration
audio files with a predefined sampling rate.
ofthefollowingfourfactorsinevaluatingaquestion
Additionally,wedividedlengthyaudiofiles,ap-
offairuse:
proximatelyonehourinduration,intoshorter
segmentslastingbetween10to30seconds.
• (1) Purpose and character of the use, in-
Thesesegmentswerethenrandomlyshuffled,
cludingwhethertheuseisofacommercial
makingitimpossibleforuserstopiecethem
natureorisfornonprofiteducationalpur-
togethertocomprehendtheentiretyoftheorig-
poses: Courtslookathowthepartyclaiming
inallycrawledvideos. Therefore,ourworkis
fairuseisusingthecopyrightedwork,andare
transformative and we do not substitute the
more likely to find that nonprofit educational
originaluseofthecrawledvideos.
andnoncommercialusesarefair. Additionally,
“transformative”usesaremorelikelytobecon-
• (2)Ourmedicalconversationsarefactual(non-
sidered fair. Transformative uses are those
fiction)andhencequalifiedasfair.
thataddsomethingnew,withafurtherpurpose
ordifferentcharacter,anddonotsubstitutefor • (2) Videos on YouTube platform are univer-
theoriginaluseofthework. sallyaccessiblearoundtheworld,thereforewe
satisfythecriteriaforthecopyrightedwork’s
• (2) Nature of the copyrighted work: This publicationstatus.
factoranalyzesthedegreetowhichthework
thatwasusedrelatestocopyright’spurposeof • (3) There is no quantitative test to evaluate
encouragingcreativeexpression. Thus,using whetheragivenuseisfair. Therandomlyshuf-
amorecreativeorimaginativework(suchasa fled10-30secondsegmentswehavecreated
novel,movie,orsong)islesslikelytosupport donotprovidethecompletecontextandmean-
aclaimofafairusethanusingafactualwork ingofeachvideo,thusmakingthemincapable
(suchasatechnicalarticleornewsitem). In ofrepresentingthe”heart”ofthecopyrighted
addition, use of an unpublished work is less work.
likelytobeconsideredfair.
• (4)Wedon’tutilizeourpubliclyavailabledata
to compete with the copyright owners’ busi-
• (3)Amountandsubstantialityoftheportion
ness. Furthermore, our 10-30 second seg-
usedinrelationtothecopyrightedworkas
mentshavenoimpactontheviewershipcount
awhole: Underthisfactor,courtslookatboth
on YouTube. As a result, our efforts do not
thequantityandqualityofthecopyrightedma-
underminethepotentialmarketbeingpursued
terialthatwasused. Thatsaid, somecourts
bythecopyrightowners.
havefounduseofanentireworktobefairun-
dercertaincircumstances. Andinothercon-
Besidesourwork,severalsimilarworksexistthat
texts, using even a small amount of a copy-
involve the extraction of YouTube videos and
rightedworkwasdeterminednottobefairbe-
their conversion into audio files for research and
causetheselectionwasanimportantpart—or non-commercialintentions,suchasGigaSpeech20
the“heart”—ofthework. (China&USA),VoxCeleb21 (UK),VoxLingua10722
(UK).
• (4)Effectoftheuseuponthepotentialmar-
ket for or value of the copyrighted work:
18https://copyrightalliance.org/faqs/what-is-fair-use/
Here,courtsreviewwhether,andtowhatex-
19http://www.elra.info/media/filer_pub-
tent,theunlicenseduseharmstheexistingor
lic/2021/02/12/elrc-legal-analysis-webcrawling_report-
futuremarketforthecopyrightowner’soriginal
v11.pdf
work. 20https://github.com/SpeechColab/GigaSpeech
21https://www.robots.ox.ac.uk/vgg/data/voxceleb/
17https://www.copyright.gov/fair-use/ 22https://bark.phon.ioc.ee/voxlingua107/A.2. Data Consent a Vietnamese company authorized by Viet-
namese government, and the right to pub-
Accordingtotheexistinglawonthedataconsent,
lish this data for research purposes is pro-
weareallowedto publishresearchdata. Wede-
tectedunderVietnameseLaw(shownabove),
scribeinshortasfollows:
sinceGoogle(Youtube)mustcomplywithViet-
• Firstofall,137/194countriessignedDataPro- namese law on content in Vietnamese cy-
tectionandPrivacyLegislationWorldwide23by berspace,asshowninArticle26,Cybersecu-
the United Nations, including USA, EU, Ger- rityLaw,ConstitutionoftheSocialistRepublic
many,Vietnam. SoVietnameselawondata ofVietnam: “Domesticandforeignenterprises
protectioncomplieswithinternationallaw,as providingservicesontelecommunicationsnet-
Article6ofthePersonalDataProtectionAct works,theInternet,andvalue-addedservices
by the Vietnamese government says: “The incyberspaceinVietnamhaveactivitiesofcol-
protection of personal data is carried out in lecting,exploiting,analyzing,andprocessing
accordancewithinternationaltreatiestowhich informationdata(...) createdbyserviceusers
the Socialist Republic of Vietnam is a mem- inVietnammuststorethisdatainVietnam(...)
ber”. asprescribedbytheGovernment.”
• Researchers have the right to freely publish • Internationalresearchershavetherighttopub-
sensitive medical data for research without lish and process Vietnamese personal data
the consent of the data subject (speakers in without consent. Also they are both encour-
speech data), as Article 20, Section 4 says: aged to publish Vietnamese research data
“Thepartyprocessingpersonaldataisnotre- andareprotectedunderVietnameselawbe-
quiredtoregisterforprocessingsensitiveper- causetheymustcomplywithVietnameselaw
sonaldatainthecaseofresearchpurposes.” ongenerated-by-Vietnamdata,accordingto
Article2and10,theVietnameseCivilCodeon
• Oncemore,researchersdonotneeddirector Civil Relations with Foreign Elements: “The
indirectconsentfromthedatasubjecttopub- provisionsofVietnamesecivillawapplytocivil
lish research papers, as the Article 16 says: relations involving foreign elements (...). In
“Datadeletionwillnotapplyattherequestof casetheapplicationorconsequencesofthe
the data subject in the following cases: Per- applicationofforeignlawarecontraryto(...)
sonaldataisprocessedtoservelegalrequire- theVietnamCivilCodeandotherbasicprinci-
ments,scientificresearch,andstatistics.” plesofVietnameselaw,thenVietnameselaw
applies.”
• Again, researchers do not need consent, as
Article9oftheEuropeanGeneralDataProtec-
TheYouTubecontentinourdatasetisaboutmedi-
tionRegulation(GDPR)permitsresearchers
calshows,interviews,lectures,etc.,whereallpar-
inMemberStatestopublishpersonaldatafor
ticipants talked to camera and were aware that
scientificresearchpurposeswithoutconsent.
the videos are publicly accessible in an attempt
toprovidemedicalknowledgetoYouTubeusers.
• Researchersarestronglyencouragedtopub-
ThesevideosarepublishedbynationalTVchan-
lish research on sensitive medical data, ac-
nels,notbysomeamateurcontentcreators. There
cording to Law on Medical Examination and
are some YouTube videos that speakers are not
Treatment,ConstitutionoftheSocialistRepub-
awareofbeingrecorded,publishedbyamateurs,
lic of Vietnam, Article 22: “Practitioners (…)
butwedidnotincludetheminourdataset.
areresponsibleforupdatingrelevantmedical
knowledge(...) including(...) c)Publishscien-
tificresearch(...).” B. Additional Details of VietMed
Dataset
• Incaseofunexpectedissuesduringpublish-
ing research, researchers are “Protected by B.1. Description of ICD-10 Codes
thelawandnotresponsiblewhenamedical
Table7showsthedetaileddescriptionofICD-10
incidentstilloccursaftercomplyingwithregu-
codes. Theaudiofilesinourdatasetareclassified
lations.”,asstatedinArticle42.
basedontheseICD-10codes.
• Wecrawledgenerated-by-Vietnamdatausing
Vietnamese IP address and a crawler from B.2. Real Distribution of Accents in
Vietnam
23https://unctad.org/page/data-protection-and-privacy- TableB.2showstherealdistributionofaccentsin
legislation-worldwide Vietnam,whichourVietMed datasetfollows.ICD-10Code Descriptionofdiseases
A00-B99 Certaininfectiousandparasiticdiseases
C00-D49 Neoplasms
D50-D89 Diseasesofthebloodandblood-formingorgansandcertaindisordersinvolvingtheimmunemechanism
E00-E89 Endocrine,nutritionalandmetabolicdiseases
F01-F99 Mental,BehavioralandNeurodevelopmentaldisorders
G00-G99 Diseasesofthenervoussystem
H00-H59 Diseasesoftheeyeandadnexa
H60-H95 Diseasesoftheearandmastoidprocess
I00-I99 Diseasesofthecirculatorysystem
J00-J99 Diseasesoftherespiratorysystem
K00-K95 Diseasesofthedigestivesystem
L00-L99 Diseasesoftheskinandsubcutaneoustissue
M00-M99 Diseasesofthemusculoskeletalsystemandconnectivetissue
N00-N99 Diseasesofthegenitourinarysystem
O00-O9A Pregnancy,childbirthandthepuerperium
P00-P96 Certainconditionsoriginatingintheperinatalperiod
Q00-Q99 Congenitalmalformations,deformationsandchromosomalabnormalities
R00-R99 Symptoms,signsandabnormalclinicalandlaboratoryfindings,notelsewhereclassified
S00-T88 Injury,poisoningandcertainotherconsequencesofexternalcauses
U00-U85 Codesforspecialpurposes
V00-Y99 Externalcausesofmorbidity
Z00-Z99 Factorsinfluencinghealthstatusandcontactwithhealthservices
Table7: DescriptionofICD-10codeswhichourdatasetfollows,accordingtothe2024versionbyWorld
HealthOrganziation. EachICD-10Code,e.g. A00-B99,couldbeinsmallercodespartitioned. However,
inourdatasetweonlyused22ICD-10Codessincepartitioningintosmallercodesmakestheannotation
toocomplicatedandunnecessary.
Region Subregion TypicalProvinces Population
CaoBằng
Northest HàGiang 8M
North ...
ĐiệnBiên
Northwest HòaBình 4M
...
HàNội
RedRiverDelta HảiPhòng 20M
...
HàTĩnh
NorthCentralCoast NghệAn 10M
Central ...
ĐàNẵng
SouthCentralCoast BìnhThuận 9M
...
GiaLai
CentralHighland KonTum 5M
...
TP.HồChíMinh
Southeast ĐồngNai 16M
South
...
LongAn
Southwest CầnThơ 18M
...
Table8: RealdistributionofVietnameseaccents. Thestatisticswasretrievedin2015fromVietnamese
GeneralStatisticsOffice. Inourdataset,wedidnotsplittheNorthaccentintosubregionalaccentssince
itwastoodifficultforourannotatorstocorrectlyrecognizesubregionalaccentsoftheNorthregion.B.3. Concerns about Noisy Speech in thedecreasedaccuracyofanASRsystem. There-
VietMed fore,collectingconfusionpairswhichtheASRsys-
temoftenmisrecognizedgivesresearchersanop-
Real-worldspeechdatashouldcontainreal-world
portunitytoanalyzecommonASRerrorsandim-
acousticconditions(e.g. backgroundnoises,mu-
provetheASRaccuracy.
sic, etc.). To enhance the quality of a speech
Asshowninthetable,wordsthatarepartsofmed-
dataset,especiallyforareadspeechdataset,peo-
ical terms and fillers contribute greatly to the de-
pleoftenuseaSignal-to-NoiseRatio(SNR)tomea-
creasedaccuracyoftheASRsystemusingthepre-
surethebackgroundnoisesanddiscardsegments
trained model XLSR-53-Viet. This difficulty was
withahighlevelofSNR.However,usinganSNR
confirmed by our annotators during the dataset
thresholdtoobtainonlygoodspeechsignals,dis-
annotation,sinceitwasveryhardtocorrectlytran-
cardingnoisysegments,wouldviolatereal-world
scribemedicaltermsandfillersinreal-worldmedi-
scenarios,makingourVietMed datasetnolonger
calconversations.
realworldbutrather”simulated”.
Actually, we only removed audio segments that
C.3. Error Analysis of OOV
havenospeech. Westillkeptoverlappedspeech
Table14showsthelistofOOVsloanwordsfound
segments,aslongasthemainspeaker’sspeechis
in VietMed-Train. In this table, we used the BA-
stillcomprehensible. Thequalityassuranceforreal-
BELproject’sseedlexiconandautomaticallyaug-
worldASRdatasetsshouldfocusontranscription,
menteditwithVietMed-Train. Weusedthetoolkit
which we have already addressed in the paper,
Sequitur Grapheme-To-Phoneme24 (Bisani and
instead of focusing on the quality of the speech
Ney,2008)-theconversiontoolonthesepronun-
signal.
ciationlexica,toextendtheseedlexicon,creating
thelexiconfortraining.
B.4. Extra Data Statistics for Labeled
First,wefoundthattheseedlexiconbyBABELwas
Medical Data VietMed-L
overwhelmedbyNorthandNorthCentralCoastac-
Table9showsthestatisticsof3train-dev-testsub- cents,leavingalmostnootheraccentslikeSouth
setsinVietMed-L.Wesplitthese3subsetsinaway Central Coast, Central Highland, Southwest and
thatmadeVietMed-Traintheleastgeneralizability Southeast. Therefore, this lexicon hurts the ac-
by having the least number of speakers, record- curacyofASRsystemsonageneralizeddataset
ingconditions,accentsandroles,whileprioritizing like VietMed. Second, VietMed has a very large
VietMed-Dev and VietMed-Test more generaliz- numberofmedicalterms,whichoftencomefrom
ability. Notethatnospeakeroverlapoccuredinthe Englishloanwords. Soautomaticextensionofthe
3subsets. seedlexiconwithouthumancorrectionledtowrong
phoneme mapping of medical terms, which also
B.5. Extra Data Statistics for Unlabeled hurtstheaccuracyofASRsystems.
Medical Data VietMed-U
Figure 2 shows the distribution of ICD-10 code
andFigure3showsthedistributionofaccentsin
VietMed-U.WecollectedVietMed-U inamanner
similartoVietMed-L,assuringacomparablegen-
eralizabilityasinVietMed-L.
C. ASR Error Analysis
C.1. Error Analysis of Pre-trained Model
Table10showstheerroranalysisofourpre-trained
modelXLSR-53ontheVietMed-Test set.
Table11showstheerroranalysisofourpre-trained
modelw2v2-Viet ontheVietMed-Test set.
Table12showstheerroranalysisofourbestpre-
trainedmodelXLSR-53-Viet ontheVietMed-Test
set.
C.2. Error Analysis of Confusion Pairs
Table 13 shows the statistics of confusion pairs
inVietMed-Test usingthebestpre-trainedmodel
XLSR-53-Viet. Closelysimilarwordscouldleadto 24https://github.com/sequitur-g2p/sequitur-g2pVietMed-Train VietMed-Dev VietMed-Test
Dur. [hours] 5 5 6
#Speakers 13 21 27
#Words 70k 69k 76k
#Rec. cond. 2 4 6
#Accents 3 4 5
#Roles 3 4 6
Table9: DatastatisticsofVietMed-L,retrievedfromfile”Metadata”inthedataset.
Figure2: DistributionofICD-10codeinVietMed-U.
Figure3: DistributionofaccentsinVietMed-U.SpeakerID Rec. ICD-10 Role Gend Acc. #Snt #Wrd Corr Sub Del Ins Err S.Err
vietmed_002 N00-N99 Lec. F SCC 363 7631 30.7 54.4 14.9 5.6 74.9 100.0
vietmed_004 M00-M99 Doc. M SCC 446 10575 51.7 34.8 13.5 6.8 55.0 100.0
vietmed_014_a Host F N 18 491 63.7 23.4 12.8 3.7 39.9 100.0
K00-K95
vietmed_014_b Tel. Doc. M N 164 4034 59.6 28.5 11.9 5.2 45.6 100.0
vietmed_015_a Host F N 73 1779 68.8 20.3 10.9 4.2 35.4 100.0
vietmed_015_b O00-O9A Doc. F N 297 5669 58.8 28.3 12.9 4.4 45.6 100.0
vietmed_015_c Pat. F N 55 1010 43.0 37.3 19.7 3.7 60.7 100.0
vietmed_017_a Doc. F SW 47 1104 50.0 37.2 12.8 5.4 55.4 100.0
U00-U85
vietmed_017_b Doc. M N 86 2061 62.8 26.9 10.2 5.0 42.2 100.0
vietmed_018_a Host F SW 63 1527 54.3 32.5 13.2 19.6 65.3 100.0
vietmed_018_b Doc. M SW 192 5293 59.8 26.2 14.0 7.2 47.4 100.0
vietmed_018_c Doc. F SW 118 2761 55.3 31.4 13.2 8.7 53.3 100.0
Talk. K00-K95
vietmed_018_d Pat. F SW 20 412 33.3 36.9 29.9 6.1 72.8 100.0
vietmed_018_e Pat. M SW 5 76 31.6 40.8 27.6 10.5 78.9 100.0
vietmed_018_f Doc. M SW 25 639 41.2 42.9 16.0 5.0 63.8 100.0
vietmed_019_a Host F SW 58 1490 55.1 31.9 13.0 6.9 51.8 100.0
L00-L99
vietmed_019_b Doc. F SW 116 2776 56.5 30.5 13.0 7.7 51.3 100.0
vietmed_023 P00-P96 Pod. F SW 390 7414 55.4 35.8 8.8 4.9 49.6 99.7
Pod.
vietmed_024 O00_O99 Pod. F SE 376 7425 61.2 28.8 10.0 4.7 43.5 99.7
vietmed_025_a Host F SW 101 2280 60.3 29.1 10.7 5.0 44.7 100.0
Diag. H60-H95
vietmed_025_b Doc. M SE 91 1838 65.7 24.8 9.5 6.6 40.9 100.0
vietmed_026 Lec. A00-B99 Lec. M NCC 21 355 31.8 47.6 20.6 6.5 74.6 100.0
vietmed_027_a Host F SW 29 710 70.8 20.8 8.3 6.2 35.4 100.0
S00-T88
vietmed_027_b Brc. M SE 64 1454 49.5 39.1 11.3 5.6 56.1 100.0
vietmed_028_a News Host F SE 106 2617 52.7 34.7 12.6 4.1 51.5 100.0
vietmed_028_b V00-Y99 Brc. M SE 21 475 47.6 41.5 10.9 6.7 59.2 100.0
vietmed_029 Brc. F SE 92 2240 60.4 30.0 9.6 5.4 45.1 100.0
Sum/Avg 3437 76136 54.2 33.5 12.3 6.0 51.8 99.9
Mean 127.3 2819.9 53.0 33.2 13.8 6.4 53.3 100.0
StandardDeviation 129.6 2743.3 11.4 8.0 5.2 3.1 12.1 0.1
Median 86.0 1838.0 55.3 31.9 12.8 5.6 51.5 100.0
Table10: AnalysisofASRerrorsonVietMed-Test setusingthebaselinemodelXLSR-53(WER=51.8).
Column from left to right is: Speaker ID, Recording Condition, ICD-10 Code, Speaker Role, Gender,
Accent,Numberofsentences,Numberofwords,Corrections,SubstitutionErrors,DeletionErrors,Insertion
Errors,Word-Error-Rate,Sentence-Error-Rate.
ForRecordingCondition,thereare: Telephone(Tel.),Talkshow(Talk.),Podcast(Pod.),Diagnosis(Diag.),
Lectures(Lec.),News.
For Speaker Role, there are: Lecturer (Lec.), Doctor (Doc.), Talkshow Host (Host), Patient (Pat.),
Podcaster(Pod.),Broadcaster(Brc.).
ForGender,thereare: Male(M)andFemale(F).
ForAccent,thereare: SouthCentralCoast(SCC),North(N),Southwest(SW),Southeast(SE),North
CentralCoast(NCC).SpeakerID Rec. ICD-10 Role Gend Acc. #Snt #Wrd Corr Sub Del Ins Err S.Err
vietmed_002 N00-N99 Lec. F SCC 363 7631 33.8 50.7 15.5 5.6 71.8 100.0
vietmed_004 M00-M99 Doc. M SCC 446 10575 52.1 34.1 13.8 6.5 54.3 100.0
vietmed_014_a Host F N 18 491 72.3 15.9 11.8 5.1 32.8 100.0
K00-K95
vietmed_014_b Tel. Doc. M N 164 4034 57.8 28.6 13.6 4.6 46.8 100.0
vietmed_015_a Host F N 73 1779 70.8 18.1 11.1 4.5 33.7 100.0
vietmed_015_b O00-O9A Doc. F N 297 5669 60.1 26.7 13.2 4.7 44.6 99.7
vietmed_015_c Pat. F N 55 1010 44.4 37.5 18.1 5.4 61.1 100.0
vietmed_017_a Doc. F SW 47 1104 51.6 36.2 12.1 6.3 54.6 100.0
U00-U85
vietmed_017_b Doc. M N 86 2061 62.4 26.7 10.9 4.9 42.4 100.0
vietmed_018_a Host F SW 63 1527 59.2 27.5 13.3 19.6 60.4 100.0
vietmed_018_b Doc. M SW 192 5293 59.5 26.3 14.3 6.7 47.2 100.0
vietmed_018_c Doc. F SW 118 2761 57.7 29.6 12.7 9.0 51.4 100.0
Talk. K00-K95
vietmed_018_d Pat. F SW 20 412 34.7 34.5 30.8 4.9 70.1 100.0
vietmed_018_e Pat. M SW 5 76 42.1 34.2 23.7 7.9 65.8 100.0
vietmed_018_f Doc. M SW 25 639 44.0 38.2 17.8 7.0 63.1 100.0
vietmed_019_a Host F SW 58 1490 58.6 28.7 12.7 6.8 48.2 100.0
L00-L99
vietmed_019_b Doc. F SW 116 2776 58.9 28.4 12.7 7.4 48.5 100.0
vietmed_023 P00-P96 Pod. F SW 390 7414 63.0 29.6 7.4 4.8 41.8 99.7
Pod.
vietmed_024 O00_O99 Pod. F SE 376 7425 65.4 25.9 8.6 5.8 40.3 99.5
vietmed_025_a Host F SW 101 2280 65.3 24.5 10.2 4.6 39.3 100.0
Diag. H60-H95
vietmed_025_b Doc. M SE 91 1838 67.2 23.2 9.5 7.1 39.8 100.0
vietmed_026 Lec. A00-B99 Lec. M NCC 21 355 26.5 47.3 26.2 4.8 78.3 100.0
vietmed_027_a Host F SW 29 710 68.7 22.5 8.7 5.5 36.8 100.0
S00-T88
vietmed_027_b Brc. M SE 64 1454 41.5 44.6 13.9 5.2 63.7 100.0
vietmed_028_a News Host F SE 106 2617 59.7 28.8 11.5 4.4 44.7 99.1
vietmed_028_b V00-Y99 Brc. M SE 21 475 48.8 39.2 12.0 5.1 56.2 100.0
vietmed_029 Brc. F SE 92 2240 64.4 26.1 9.6 5.9 41.6 100.0
Sum/Avg 3437 76136 56.5 31.2 12.3 6.0 49.5 99.9
Mean 127.3 2819.9 55.2 30.9 13.9 6.3 51.1 99.9
StandardDeviation 129.6 2743.3 12.0 8.3 5.4 2.9 12.2 0.2
Median 86.0 1838.0 58.9 28.7 12.7 5.5 48.2 100.0
Table11: AnalysisofASRerrorsonVietMed-Testsetusingthebaselinemodelw2v2-Viet(WER=49.5).
Column from left to right is: Speaker ID, Recording Condition, ICD-10 Code, Speaker Role, Gender,
Accent,Numberofsentences,Numberofwords,Corrections,SubstitutionErrors,DeletionErrors,Insertion
Errors,Word-Error-Rate,Sentence-Error-Rate.
ForRecordingCondition,thereare: Telephone(Tel.),Talkshow(Talk.),Podcast(Pod.),Diagnosis(Diag.),
Lectures(Lec.),News.
For Speaker Role, there are: Lecturer (Lec.), Doctor (Doc.), Talkshow Host (Host), Patient (Pat.),
Podcaster(Pod.),Broadcaster(Brc.).
ForGender,thereare: Male(M)andFemale(F).
ForAccent,thereare: SouthCentralCoast(SCC),North(N),Southwest(SW),Southeast(SE),North
CentralCoast(NCC).SpeakerID Rec. ICD-10 Role Gend Acc. #Snt #Wrd Corr Sub Del Ins Err S.Err
vietmed_002 N00-N99 Lec. F SCC 363 7631 57.8 31.2 11.0 6.3 48.5 100.0
vietmed_004 M00-M99 Doc. M SCC 446 10575 68.8 18.7 12.5 5.4 36.6 100.0
vietmed_014_a Host F N 18 491 87.8 3.5 8.8 4.7 16.9 100.0
K00-K95
vietmed_014_b Tel. Doc. M N 164 4034 77.2 12.2 10.5 4.6 27.4 100.0
vietmed_015_a Host F N 73 1779 85.2 5.8 9.0 3.6 18.4 97.3
vietmed_015_b O00-O9A Doc. F N 297 5669 82.4 7.7 9.8 4.2 21.8 97.3
vietmed_015_c Pat. F N 55 1010 70.1 14.9 15.0 5.8 35.7 100.0
vietmed_017_a Doc. F SW 47 1104 76.6 13.1 10.2 4.2 27.5 100.0
U00-U85
vietmed_017_b Doc. M N 86 2061 80.1 10.4 9.6 4.8 24.7 100.0
vietmed_018_a Host F SW 63 1527 73.7 13.2 13.2 18.7 45.1 100.0
vietmed_018_b Doc. M SW 192 5293 75.3 12.1 12.6 6.5 31.2 100.0
vietmed_018_c Doc. F SW 118 2761 74.3 12.4 13.3 7.3 33.0 100.0
Talk. K00-K95
vietmed_018_d Pat. F SW 20 412 55.1 20.6 24.3 5.6 50.5 100.0
vietmed_018_e Pat. M SW 5 76 57.9 19.7 22.4 7.9 50.0 100.0
vietmed_018_f Doc. M SW 25 639 64.9 20.3 14.7 6.1 41.2 100.0
vietmed_019_a Host F SW 58 1490 75.2 12.6 12.2 6.7 31.5 100.0
L00-L99
vietmed_019_b Doc. F SW 116 2776 75.7 11.9 12.5 6.2 30.5 100.0
vietmed_023 P00-P96 Pod. F SW 390 7414 83.3 10.6 6.0 4.1 20.8 97.4
Pod.
vietmed_024 O00_O99 Pod. F SE 376 7425 85.0 8.0 7.1 5.0 20.1 98.4
vietmed_025_a Host F SW 101 2280 80.4 10.6 9.0 4.8 24.4 100.0
Diag. H60-H95
vietmed_025_b Doc. M SE 91 1838 81.8 10.0 8.3 5.1 23.3 98.9
vietmed_026 Lec. A00-B99 Lec. M NCC 21 355 57.7 27.9 14.4 7.3 49.6 100.0
vietmed_027_a Host F SW 29 710 83.5 8.0 8.5 4.6 21.1 100.0
S00-T88
vietmed_027_b Brc. M SE 64 1454 74.8 15.8 9.4 5.2 30.4 100.0
vietmed_028_a News Host F SE 106 2617 82.7 8.8 8.6 4.2 21.6 99.1
vietmed_028_b V00-Y99 Brc. M SE 21 475 74.3 14.9 10.7 5.3 30.9 100.0
vietmed_029 Brc. F SE 92 2240 83.9 7.5 8.5 5.6 21.7 97.8
Sum/Avg 3437 76136 75.9 13.8 10.3 5.6 29.6 99.1
Mean 127.3 2819.9 75.0 13.4 11.6 5.9 30.9 99.5
StandardDeviation 129.6 2743.3 9.3 6.4 4.1 2.8 10.5 1.0
Median 86.0 1838.0 75.7 12.2 10.5 5.3 30.4 100.0
Table 12: Analysis of ASR errors on VietMed-Test set using the best baseline model XLSR-53-Viet
(WER=29.6).
Column from left to right is: Speaker ID, Recording Condition, ICD-10 Code, Speaker Role, Gender,
Accent,Numberofsentences,Numberofwords,Corrections,SubstitutionErrors,DeletionErrors,Insertion
Errors,Word-Error-Rate,Sentence-Error-Rate.
ForRecordingCondition,thereare: Telephone(Tel.),Talkshow(Talk.),Podcast(Pod.),Diagnosis(Diag.),
Lectures(Lec.),News.
For Speaker Role, there are: Lecturer (Lec.), Doctor (Doc.), Talkshow Host (Host), Patient (Pat.),
Podcaster(Pod.),Broadcaster(Brc.).
ForGender,thereare: Male(M)andFemale(F).
ForAccent,thereare: SouthCentralCoast(SCC),North(N),Southwest(SW),Southeast(SE),North
CentralCoast(NCC).Index Occurrences Confusionpair Type
1 75 bé=⇒béo MedTable13continuedfrompreviouspage
Index Occurrences Confusionpair Type
2 75 cung=⇒công -
3 49 các=⇒cái -
4 34 trẻ=⇒sẽ Med
5 33 bú=⇒bốn Med
6 31 implant=⇒lên Med
7 30 thai=⇒hai Med
8 28 cái=⇒các Fill
9 26 là=⇒mà Fill
10 25 tử=⇒bệnh Med
11 25 vì=⇒thì Fill
12 24 răng=⇒đang Med
13 23 cấy=⇒cái Med
14 23 làm=⇒là -
15 21 là=⇒và Fill
16 20 đó=⇒nó Fill
17 19 và=⇒là Fill
18 19 và=⇒mà Fill
19 19 âm=⇒ăn Med
20 18 là=⇒làm Fill
21 18 mình=⇒mà Fill
22 18 trồng=⇒trong Med
23 17 bú=⇒bố Med
24 17 chị=⇒chỉ -
25 17 có=⇒cái -
26 17 là=⇒lại Fill
27 17 mà=⇒và Fill
28 17 sẽ=⇒phải Fill
29 17 đi=⇒đây Fill
30 16 nó=⇒đó Fill
31 16 tử=⇒về Med
32 15 con=⇒còn Med
33 15 progesterone=⇒cholesterol Med
34 15 rong=⇒năm Med
35 15 thủ=⇒phẫu Med
36 14 implant=⇒selen Med
37 14 que=⇒quen Med
38 13 còn=⇒có Fill
39 13 có=⇒các Fill
40 13 có=⇒đó Fill
41 13 lại=⇒là Fill
42 12 như=⇒nhưng Fill
43 11 bà=⇒mà -
44 11 bình=⇒bệnh Med
45 11 cung=⇒trong Med
46 11 là=⇒nó Fill
47 11 mình=⇒bệnh -
48 11 răng=⇒gan Med
49 11 răng=⇒ăn Med
50 11 vào=⇒và -
51 10 anh=⇒ăn -
52 10 bà=⇒ba -
53 10 chú=⇒chúng -
54 10 cách=⇒các -
55 10 cô=⇒của -Table13continuedfrompreviouspage
Index Occurrences Confusionpair Type
56 10 da=⇒ra Med
57 10 khi=⇒thì -
58 10 lạ=⇒là -
59 10 tóc=⇒tác Med
60 10 vòng=⇒phòng -
61 10 đo=⇒đó Med
62 10 đại=⇒tại -
63 9 cổ=⇒của Med
64 9 dặm=⇒giảm Med
65 9 hay=⇒hai -
66 9 ngừa=⇒là Med
67 9 nói=⇒nó -
68 9 răng=⇒rằng Med
69 9 sau=⇒sao -
70 9 tai=⇒tay Med
71 9 thì=⇒cái Fill
72 9 tràng=⇒trạm Med
73 9 tóc=⇒tắt Med
74 9 ốc=⇒cái Med
75 8 chị=⇒thì -
76 8 cong=⇒công Med
77 8 em=⇒xem -
78 8 estrogen=⇒selen Med
79 8 kinh=⇒cân Med
80 8 nhi=⇒như Med
81 8 nè=⇒này Fill
82 8 quy=⇒quá Med
83 8 ruột=⇒rồi Med
84 8 răng=⇒năng Med
85 8 tai=⇒ta Med
86 8 thật=⇒thực -
87 8 thể=⇒thế Med
88 8 trồng=⇒chọn Med
89 8 tóc=⇒tốt Med
90 8 tự=⇒từ Med
91 8 và=⇒vào Fill
92 8 để=⇒đến Fill
93 7 an=⇒ăn -
94 7 bạn=⇒bệnh -
95 7 canxi=⇒xây Med
96 7 cho=⇒cái -
97 7 cái=⇒có Fill
98 7 có=⇒tốt Fill
99 7 cơn=⇒cân Med
100 7 dày=⇒dài Med
101 7 ghép=⇒kết Med
102 7 già=⇒ra Med
103 7 kinh=⇒đến Med
104 7 kỹ=⇒cái -
105 7 là=⇒ta Fill
106 7 nữ=⇒nữa -
107 7 qua=⇒quá -
108 7 siêu=⇒thức Med
109 7 thì=⇒vì FillTable13continuedfrompreviouspage
Index Occurrences Confusionpair Type
110 7 thì=⇒để Fill
111 7 tử=⇒thành Med
112 7 vậy=⇒mà Fill
113 7 vắcxin=⇒sĩ Med
114 7 âm=⇒tâm Med
115 7 đó=⇒nữa Fill
116 7 để=⇒cái Fill
117 6 buồng=⇒buồn Med
118 6 bà=⇒và -
119 6 cho=⇒chất -
120 6 cho=⇒ra -
121 6 con=⇒có Med
122 6 cung=⇒không Med
123 6 cách=⇒cái -
124 6 cái=⇒với Fill
125 6 có=⇒của Fill
126 6 có=⇒nó -
127 6 cấy=⇒thấy Med
128 6 của=⇒có -
129 6 d=⇒b -
130 6 dịch=⇒việc Med
131 6 f0=⇒không Med
132 6 ghép=⇒biết Med
133 6 hợp=⇒hai -
134 6 khiếm=⇒khiến -
135 6 khá=⇒khác -
136 6 lý=⇒lấy -
137 6 lạ=⇒lại -
138 6 mãn=⇒mạn Med
139 6 ngày=⇒này -
140 6 nhổ=⇒nhỏ Med
141 6 nín=⇒đến Med
142 6 nó=⇒là Fill
143 6 phải=⇒cái -
144 6 ra=⇒da -
145 6 rong=⇒tâm Med
146 6 sợ=⇒sở -
147 6 sữa=⇒sự Med
148 6 thì=⇒bị Fill
149 6 thì=⇒chúng Fill
150 6 thì=⇒thể Fill
151 6 thú=⇒thuốc Med
152 6 thấy=⇒cái -
153 6 thể=⇒sẽ Med
154 6 trẻ=⇒kể Med
155 6 trẻ=⇒để Med
156 6 trồng=⇒viêm Med
157 6 u=⇒ung Med
158 6 viện=⇒vị Med
159 6 với=⇒cái Fill
160 6 xơ=⇒thư Med
161 6 âm=⇒vitamin Med
162 6 đo=⇒đau MedTable13continuedfrompreviouspage
Index Occurrences Confusionpair Type
163 6 đây=⇒này Fill
164 6 đấy=⇒đây Fill
165 6 đầu=⇒đau Med
166 6 đầy=⇒đây -
167 6 đủ=⇒đúng -
168 5 cho=⇒cao -
169 5 cho=⇒trong -
170 5 chân=⇒nhân Med
171 5 chín=⇒chính Med
172 5 chỉ=⇒cái -
173 5 covid19=⇒chính Med
174 5 còn=⇒và -
175 5 có=⇒bác Fill
176 5 có=⇒là Fill
177 5 do=⇒ra -
178 5 dạng=⇒giảm -
179 5 dự=⇒nhiều -
180 5 gây=⇒cái -
181 5 hoặc=⇒họ -
182 5 hư=⇒hơn Med
183 5 không=⇒trong -
184 5 khỏe=⇒khoẻ Med
185 5 kinh=⇒cái Med
186 5 kết=⇒cái Med
187 5 là=⇒người Fill
188 5 là=⇒này Fill
189 5 là=⇒đã Fill
190 5 mà=⇒là Fill
191 5 mái=⇒máy Med
192 5 mất=⇒mức -
193 5 mặt=⇒mạch Med
194 5 nang=⇒năng -
195 5 nhân=⇒nhắn Med
196 5 nhũ=⇒nhiều Med
197 5 này=⇒ngày Fill
198 5 nó=⇒cái Fill
199 5 nó=⇒có Fill
200 5 nền=⇒nên Med
201 5 phụ=⇒phẫu Med
202 5 que=⇒quá Med
203 5 quên=⇒khuyên -
204 5 răng=⇒căn Med
205 5 sao=⇒ra -
206 5 sâu=⇒sau Med
207 5 sẽ=⇒sĩ -
208 5 sức=⇒rất Med
209 5 thanh=⇒thành Med
210 5 thuyên=⇒nguyên Med
211 5 thì=⇒người Fill
212 5 thì=⇒này Fill
213 5 thính=⇒tính Med
214 5 thể=⇒để Med
215 5 tiêm=⇒tim Med
216 5 truyền=⇒trì MedTable13continuedfrompreviouspage
Index Occurrences Confusionpair Type
217 5 tránh=⇒trình Med
218 5 trên=⇒chân -
219 5 trắng=⇒tháng Med
220 5 tức=⇒rất -
221 5 tử=⇒công Med
222 5 và=⇒giảm Fill
223 5 vâng=⇒vân -
224 5 xơ=⇒oxy Med
225 5 áp=⇒tác Med
226 5 âm=⇒năm Med
227 5 ăn=⇒anh Med
228 5 đeo=⇒đều -
229 5 đâu=⇒đau -
230 5 đó=⇒đã -
231 5 đầu=⇒nào Med
232 5 để=⇒thì -
233 5 để=⇒đấy -
234 5 đợt=⇒được -
235 5 ở=⇒của -
Table13: StatisticsofconfusionpairsinVietMed-Test usingthe
bestpre-trainedmodelXLSR-53-Viet (WER=29.6).
Inthistable,wedivideinto2typesofconfusionpairs: Medical(a
wordthatisapartofamedicalterm)andFiller(awordthatisapart
of a filler in real-world conversations). Only confusion pairs that
haveatleast5occurrencesintherecognitionoftheVietMed-Test
areincludedinthistable.
OOV Phonemes Correct
acenocoumarol a:_2kE_1no_1ka_1u_1ma:_1zO_1n N
alo a:_1lO_1 Y
amin a:_1mi_1n Y
amylase a:_1mi_1la:_1 N
apomorphine a:_2po_1mo_1fi_1n Y
ascorbic a:_1skO_1b_&amp;lt;i_2k Y
aspirin a:_1spi_1zi_1n N
betacarotene b_&amp;lt;E_1ta:_2ka:_1zO_1tE_1n N
betaglucan b_&amp;lt;E_1ta:_1lu_1ka:_1n Y
canxi ka:_1nsi_1 Y
catecholamine ka:_2tE_1ts\O_1la:_1mi_1n N
cbt kb_&amp;lt;t N
cholesterol ts\O_1lE_1st@:_1O_1n N
clohidric k@:_3lo_1a_1zi_2k N
collagen ko_1lla:_1zE_1n Y
cologen ko_1lo_1GE_1n Y
corticoid kO_1ti_1kO_1i_1 Y
cortisol kO_1ti_1sO_1n Y
covid ko_1vi_1 N
ct kt N
dbs zb_&amp;lt; N
gen GE_1n Y
google GO_1o_1Go_1 N
gút Gu_2t Y
hdl hd_&amp;lt;n N
hemoglobin hE_1mo_1G@:_3lO_1b_&amp;lt;i_1n YTable14continuedfrompreviouspage
OOV Phonemes Correct
hormone hO_1mO_1n Y
inr i_1n N
insulin i_1nsu_1li_1n Y
internet i_1nt@:_1nE_2t Y
iod i_1o_2t Y
kcal kka:_1n N
kilogam ki_1lo_1Ga:_1m Y
laser la:_1@:_1 N
ldl ld_&amp;lt;n N
levodopa lE_1vo_1d_&amp;lt;O_2pa:_1 Y
liraglutide li_1za:_1lu_1ti_1d_&amp;lt;E_1 N
livestream la:_1i_1sts\i_1m Y
mc mk N
mililit mi_1li_1li_2t Y
milimet mi_1li_1mE_2t Y
monitor mO_1ni_1tO_1 Y
mri mzi_1 N
multivitamin mu_1nti_1vi_1ta:_1mi_1n Y
natri na:_1tzi_1 N
niu ni_1u_1 Y
noark nO_1a:_1k Y
orlistat O_1li_2ta:_2t N
pacemaker pa:_2kE_1ma:_1k@:_1 N
parkinson pa:_2ki_1nsO_1n N
pepsin pE_2psi_1n Y
phytoncide fi_1tO_1nsi_1d_&amp;lt;E_1 N
pp pp N
protein p@:_3zo_1ti_1n N
qr k N
radiography za:_1d_&amp;lt;i_1o_1G@:_3za:_1fi_1 N
run zu_1n N
selen sE_1lE_1n Y
show s@_1u_1 N
sulfonylurea su_1lfO_1ni_1lu_1i_2 N
sunfuric su_1nfu_1i_2k N
test tE_2t N
umami u_1ma:_1mi_1 Y
vitamin vi_1ta:_1mi_1n Y
vitamina vi_1ta:_1mi_1na:_1 Y
vắcxin va_2ksi_1n Y
ôliu o_1li_1u_1 Y
Table 14: List of OOVs found in VietMed-Train. In this table,
only loan words are included together with their corresponding
phonemes(inBABELIARPAformat). Sincetheuseoftheauto-
matic toolkit Sequitur Grapheme-To-Phoneme (Bisani and Ney,
2008),someOOVsarecorrectlyorincorrectlymapped,whichwe
denoteasYes(Y)orNo(N).