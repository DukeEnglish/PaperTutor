Eye Tracking on Text Reading with Visual Enhancements
FranziskaHuth MauriceKoch MiriamAwad
franziska.huth@vis.uni-stuttgart.de maurice.koch@visus.uni-stuttgart.de miriam.awad@hotmail.de
UniversityofStuttgart UniversityofStuttgart UniversityofStuttgart
Germany Germany Germany
DanielWeiskopf KunoKurzhals
weiskopf@visus.uni-stuttgart.de kuno.kurzhals@visus.uni-
UniversityofStuttgart stuttgart.de
Germany UniversityofStuttgart
Germany
ABSTRACT interpretdifferentvisualstimuli[Rayner1998].Oneimportantcat-
Theinterplaybetweentextandvisualizationisgainingimportance egoryofsuchstimuliisdatavisualizationsandinfographics,often
formediawheretraditionaltextisenrichedbyvisualelementsto containingtextandgraphicstocommunicateinformation[Gold-
improvereadabilityandemphasizefacts.Intwocontrolledeye- bergandHelfman2011;Netzeletal.2017].
trackingexperiments(ùëÅ =12),weapproachanswerstotheques- Asimplewayofenhancingtextwithvisualelementsrelieson
tion: How do visualization techniques influence reading behav- highlightingspecificwordsandpassages,forinstance,toemphasize
ior?Wecompareplaintexttothatmarkedwithhighlights,icons, importantfactsduringstudiesandtoguideattentiontoresultsof
and word-sized datavisualizations. We assess quantitativemet- keywordsearchesintextdocuments.Alternatively,symbolicrepre-
rics(eyemovement,completiontime,errorrate)andsubjective sentationsofkeywordscanbeembeddedintotext.Earlyexamples
feedback(personalpreferenceandratings).Theresultsindicatethat canbefoundinthebookTheElementsofEuclidbyByrne[1847],
visualizationtechniques,especiallyinthefirstexperiment,show wheregeometricshapeswereintegratedintothetextofthebook
promisingtrendsforimprovedreadingbehavior.Theresultsalso ‚Äú...forthegreatereaseoflearners.‚ÄùModernpublicationsalsousethis
showtheneedforfurtherresearchtomakereadingmoreeffective technique,forinstance,todifferentiatebetweenexperimentalcon-
andinformsuggestionsforfuturestudies. ditions[Abdelaaletal.2023].Furthermore,visualizationresearch
investigatedhowtoencodedatainword-sizedgraphicstocommu-
CCSCONCEPTS nicateinformation,e.g.,temporalchangeswithsparklines[Tufte
2006].Thoseword-sizedgraphicshavebeensuccessfullyused,for
‚Ä¢Human-centeredcomputing‚ÜíEmpiricalstudiesinvisual-
example,toaugmenttextsthatexplaineye-trackingdata[Becketal.
ization.
2016,2015],aspartofscientifictexts[LatifandBeck2018],orfor
betterawarenessofdiscussiontopicsinsocialmediafeeds[Huth
KEYWORDS
etal.2021a,b].Goffinetal.[2017,2015]discusseddesignconsider-
Eyetracking,reading,visualization,visualhighlighting,word-sized ationsofword-sizedgraphicsintextandperformedastudythat
graphics findspositiveeffectsoninformationgain.
Aconsiderablebodyofworkexistsontexthighlightingandits
ACMReferenceFormat:
effectsoncomprehensionandmemory[Ben-YehudahandEshet-
FranziskaHuth,MauriceKoch,MiriamAwad,DanielWeiskopf,andKuno
Alkalai2018;FowlerandBarker1974;Lorch1989],butonlyafew
Kurzhals.2024.EyeTrackingonTextReadingwithVisualEnhancements.
In2024SymposiumonEyeTrackingResearchandApplications(ETRA‚Äô24), eye-trackingstudiesinvestigatedtheeffectoftexthighlightingon
June4‚Äì7,2024,Glasgow,UnitedKingdom.ACM,NewYork,NY,USA,7pages. reading behavior. Chi et al. [2007] found validation for the von
https://doi.org/10.1145/3649902.3653521 Restorffisolationeffect[VonRestorff1933],whichstatesthathigh-
lightedareasdrawtheattentionofthereader,whethertheyare
1 INTRODUCTION importantornot.Theirstudycomprisedthreeconditions;Nohigh-
lights,keywordhighlights,andScentHighlights[Chietal.2005],
Theinvestigationofreadingbehaviorhasalongtraditioninpsy-
whichisanautomaticapproachforhighlightingrelevantkeywords
chologyresearch[Huey1908].Foreyetrackingresearch,thesemi-
intexts.Theyfoundthatapproximatelyhalfofthefixationswere
nalworkofRayner[1977]helpedidentifycommoneyemovements
inhighlightedareas,suggestingastrongeffectonreadingbehavior.
duringreadingandinformationprocessing.Sincethen,manyex-
Similarly,Yearietal.[2017]studiedifthelevelofinformationcen-
perimentshavebeenconductedtoidentifyhowpeoplereadand
trality,whichreferstotheimportanceoftextsegments,impacts
onlineprocessingandofflinememory.Thisspecificstudyfound
ETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom thatattentionisdrivenbybothhighlightsandthelevelofcentrality,
¬©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
meaningthatreadersdirectedtheirattentiontoimportantwords
Thisistheauthor‚Äôsversionofthework.Itispostedhereforyourpersonaluse.Not
forredistribution.ThedefinitiveVersionofRecordwaspublishedin2024Symposium eveniftheywerenothighlighted.Interestingly,highlightinghad
onEyeTrackingResearchandApplications(ETRA‚Äô24),June4‚Äì7,2024,Glasgow,United nosignificanteffectontheabilitytorecallinformationacquired
Kingdom,https://doi.org/10.1145/3649902.3653521.
byreadingthetext.Thesestudiesonlylookedattexthighlighting,
4202
rpA
8
]CH.sc[
1v27550.4042:viXraETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom Huth,etal.
whileourworkalsoinvestigatesreadingbehaviorontextwith
iconsandword-sizedgraphics.Sofar,thereisnoconsensuson
whetherthosevisualenhancementsaidpeopleinrecallinginforma-
tionfromtextdocuments[RuchikachornandRattanawicha2018]
oriftheydistracttheirreadingflow.Inthiswork,weaimtofillthis
researchgapbyaddressingthefollowingquestion:
How do visual enhancements (i.e., high-
lighting,icons)andword-sizedgraphicsin-
fluence reading behavior with respect to
gazepatterns,readingspeed,andinforma-
tionassimilation?
Wehypothesizethattherearedifferencesinthereadingbehavior
ofvisuallyenhancedtextversusplaintext,andthattaskperfor-
manceincreases,i.e.,peoplecangraspmoreinformationquicker.
Our contributions in this work are two experiments to explore
differencesinviewingbehaviorwhenreadingtextwithdifferent
visualenhancements.Weinvestigatedeviationsfromthebaseline
(plaintext)foramemorytaskoffactsinashortdescriptiontext.
OurresultsarealsoavailableviaOSF[OSF2024]andindicatedif-
ferencesinviewingbehavior,especiallyfortextswithhighlighted
words.
Figure1:Excerptsfromstimulifortheexperimentconditions
2 EYETRACKINGOFVISUALLYENHANCED highlight (top)andicons (bottom).
TEXT
To find out how visual enhancement of text influences reading participantsratedtaskdifficulty,confidenceintheiranswer,and
behavior,weconductedasmall-scalestudycomprisingtwoexperi- theirstresslevelwhensolvingthetaskaftereachstimulus-question
mentsinvestigatingtheinfluenceof(1)highlightingandsymbols pair.Attheendofeachexperiment,weaskedaboutparticipant‚Äôs
and(2)word-sizedgraphics. readingstrategiesandpreferencesregardingthevisualizationtech-
niques.Allstimuliandquestionscanbefoundinthispaper‚ÄôsOSF
2.1 ParticipantsandExperimentalSetup repository[OSF2024].
Theexperimentswereconductedinacontrolledlabenvironment
isolatedfromoutsidedistractions.Forremoteeyetracking,weused 2.2 Experiment1:HighlightingandSymbolsin
aTobiiProSpectrumwitharesolutionof1920√ó1080pixels.Gaze Text
wasrecordedat1200HzandprocessedintofixationsbytheTobii
Thefirstexperimentcomparedthreeconditions:(1)plaintext(as
I-VTfilterwithdefaultsettings.Weuseda9-pointcalibrationand
baseline ),(2)highlighting ,and(3)symbols .Inawithin-
displayedthestimulihorizontallyandverticallycentered.
subjectsdesign,wetestedtextaugmentedwitheachvisualization
Weinvited12participantswhovolunteeredtoperformboth
typeagainstthebaselinewithoutvisualenhancements.Highlight-
experimentsinconsecutiveorder.Participationwascompletely
ingspecifictermsinatextcansteerreaders‚Äôattentiontoimportant
voluntarywithoutfurthercompensation.3oftheparticipantswere
aspectsandmayhelpthemgraspinformationquickly.Similarly,
between18and24,7between25and35,and2participantswere
symbolsthataugmentimportanttermscatchtheattentiontothese
olderthan35.4participantsidentifyasfemale,and8asmale.Allbut
termsandmayeasetextunderstanding.Ourgoalwastomeasure
oneparticipanthadgoodorverygoodEnglishlanguageskills.Most
thestrengthofthoseeffects.
participantsfrequentlyusediconsoremojisandhadhighorvery
highexperiencewithbarcharts,linecharts,andpiecharts.After Stimuli and Task. We created short texts with Chat GPT 3.5
givingtheirinformedconsentandansweringsomedemographic [2023]aboutdifferentanimalsinthestyleofalexiconarticle.The
questions,participantswereintroducedtoeachexperiment.They textscontainedinformationabouthabitats,foodsources,etc.Some
conductedonetesttaskwithashorttextforeachcondition,before examplesaredepictedinFigure1.
startingtheexperimentrecording.Thetwoexperimentstookabout Inpilotstudieswithinourlab,weiterativelyrefinedthetext
60minutestogetherperparticipant. lengthtoavoidfatiguethroughouttheexperiment,butstillhave
Wemeasuredtaskperformanceasaccuracyinansweringthe enoughinformationtochallengeshort-termmemory.Weedited
questions for each stimulus, time to read the texts and time to thetextstothesameformattingandlengthof95to115words,
answerthequestions.Intermsofcompletiontimes,wedidnot sothateachstimuluscontainedasimilarnumberoffactsabout
limitthetimeforparticipantstoreadthetext,norwhenaskedthe therespectiveanimal.Weevenlyemphasizedabout50percentof
respectivequestiontorememberthefactsofatext.Wealsomea- thesefactswiththevisualenhancementssoparticipantscouldnot
suredgazedatawithfixationsandsaccades.Inbothexperiments, relyonlearningwhichtypeoffactwasasked.BecausethefactsinEyeTrackingonTextReadingwithVisualEnhancements ETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom
Figure3:Workflowoftheexperiments.ùê∂1ùëñareselected(Latin
square balanced) from the conditions baseline , high-
light , and icon , andùê∂2ùëñ from the baseline 2 and
word-sized-graphics conditions.
familiarityandeaseofunderstanding.Wegaveeachparticipantfive
texts,againinbalancedorderofconditions.SimilartoExperiment1,
weaskedparticipantstoreadthetext,andwhentheyweredone,
weaskedaboutoneofthefactsinthetext.Here,weaskedabout
percentages,forexample:‚ÄúHowmuchofthetotalcowpopulation
inhabittropicalandsubtropicalareas?‚Äù,towhichthecorrectanswer
was‚Äú30%.‚ÄùWeexcludedoneofthestimuliintheevaluation,because
onlyaftertheexperimentwenoticedthattherewasnohighlighted
textthatcorrespondedtothevisualizationthatweaskedabout.
Figure3showsthetemporalsetupofbothexperiments.The
independentvariableistheexperimentcondition,andasdepen-
dentvariables,wemeasuredreadingandquestionansweringtime,
answeraccuracy,AOIfixations,saccadeamplitude,aswellasqual-
Figure2:Excerptsfromthestimulifortheexperimentcon- itativeratings.Wechosenottoprimetheparticipants,aswedid
ditionword-sizedgraphics . notseeanybenefitanddidnotwanttoincreasethecomplexityof
theexperiments.
thetextswereAI-generated,wewarnedtheparticipantsthatthey
3 RESULTS
maynotbeentirelycorrect.Thisfeaturealsohelpedtobalance
againstpriorknowledgethatparticipantsmighthavehadaboutthe Weinvestigatetheresultsofbothexperimentswithtraditionalper-
animals.Theparticipantsweregivenfivetextspercondition,with formanceanalysis,i.e.,correctnessandcompletiontimes.Further,
theorderoftheconditionsbasedonabalancedLatinsquare.Before weanalyzedifferencesinfixationsandsaccadesbetweenconditions.
eachtextappearedonthescreen,webrieflyshowedan‚ÄúX‚Äùatthe Weevaluatesignificancebasedontheconfidenceintervalsofpair-
toplefttoguidethegazetothebeginningpositionofthetext.When wisedifferences[Besan√ßonandDragicevic2017;Cumming2013;
participantsindicatedtheyweredonereadingatext,weswitched Dragicevic2016].Ifthosedonotoverlapwith0,thereisevidence
theviewtotherespectivequestionaboutthetext,inwhichwe ofadifference.Thiscanbeseenasequivalenttousingp-value
askedaboutoneofthefacts.Thereweremultiplecorrectanswer tests[KrzywinskiandAltman2013].Thefurtherawaytheinterval
options,forexample,correctanswersto‚ÄúWhatmakesbaldeagles isfrom0,thestrongertheevidence.Inthispaper‚ÄôsOSFreposi-
skilledhunters?‚Äùcouldbe‚Äúgoodeyesight‚Äùor‚Äúdivingabilities‚Äù. tory [OSF2024], there is data from the experiments, additional
figures,allunderlyingdataofthefigures,aswellasthescriptswe
2.3 Experiment2:Word-sizedGraphics used.Wefurtherperformedstatisticalinferenceonthedata,details
canbefoundintheOSFsupplementalmaterial.
Thesecondexperimentconsidershowparticipantsreadtextcon-
tainingword-sizedgraphics.Suchvisualizationsdepictdataandare
3.1 Performance
morecomplexthansymbols.Consequently,peoplehavetoinvesti-
gatesuchvisualelementsintextlongerandmoreintenselythan Figure4showstheresultsfortextreadingtime,questionanswering
symbolsandhighlighting,wherepreattentivevisualfeaturesare time,andaccuracy.Sincetimewasnotlimited,arelativeincrease
oftensufficienttoconveytheirpurpose.AnalogoustoExperiment1, intaskdurationbetweenconditionsforeachparticipantmightbe
Experiment2wasperformedinawithin-subjectsdesignwiththe anindicatorthattheyhadproblemsrememberingthestimulus.
sameparticipants.
Experiment1. Participantstookasimilaramountoftimetoread
StimuliandTask. Weonlyincludedoneconditioninadditionto thestimulustextsforeachoftheconditionsinExperiment1,be-
thesecondbaseline ofplaintext.Thetextwascreatedsimilarly tween50and55secondsonaverage(Figure4,left).Thereading
to Experiment 1, including statistical information enhanced by timeisslightlyhigherinthebaseline condition,andlowestfor
word-sizedgraphics (Figure2).Weaddedsimplediagrams,such textwithicons ,buttherearenosignificantdifferences.The
asbarcharts,linecharts,andpiecharts,andhighlightedtheterms averagequestionansweringtime(Figure4,center)showsasimilar
thatcorrespondtotheelementsofthechartintherespectivecolors. pattern.Again,participantstookthelongestforthebaseline
Again,about50percentofthefactsineachtextwereemphasized. condition,andleastfortheicon condition,butwithoutsignifi-
We chose basic visualization types because of their widespread cantdifferences.Theaccuracyoftheresponses(Figure4,right)isETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom Huth,etal.
readingtime(s) questionansweringtime(s) accuracy(%)
Figure4:Readingtimeinsecondsperstimulus,thetimeittookparticipantstoanswerthequestionforeachstimulus,and
answeraccuracyinpercent.Averagewithstandarddeviations(leftchart,respectively).Pairwisedifferencesbetweenthe
studyconditions(rightchart,respectively),with95%bootstrapconfidenceintervalsandredlinesindicatingtheBonferroni
correctionsfor3pairwisecomparisonsinthefirstexperiment.
highestfortextswithicons ataround50%onaverage,lowest saccadeamplitudeasindicatorforjumpsinreadinginadditionto
fortextswithhighlights at40%,withnosignificantdifferences. thetypicallineregressions.
Experiment2. Thereadingtimeforeachstimulustext(Figure4, Experiment1. Inrelationtothereadingtime,thepercentageof
left)inExperiment2issignificantlyhigherinthebaseline2 fixationsonvisualelementsissignificantlyhigherforhighlights
condition(64secondsonaverage)thanfortextswithword-sized thanforicons andplaintext (Figure6,left).Thedurationof
graphics (wsg , 52 seconds). In contrast, question answering fixationsonvisualelements(orfactualterms)isalsosignificantly
time(Figure4,center)isslightlyhigherinthewsg condition. higherforplaintexts thanfortextswithicons .Regarding
Theaccuracy(Figure4,right)issimilarforbothconditionsinExper- saccades(Figure6,right),theaverageamplitudewassimilarfor
iment2ataround65%.Overall,wefoundnosignificantdifferences thehighlight andicon conditions,butsignificantlylower
inansweringtimeandaccuracy. betweenthebaseline andhighlights .
Experiment2. Inthesecondexperiment(Figure6),theaverage
3.2 FocusonVisualElements
relativefixationdurationonAOIswassignificantlyhigherwith
We defined the visualization elements as individual areas of in- visual enhancements than for the baseline . The saccade
terest(AOIs)toinvestigatetransitionsfromtextreadingtovisual amplitudewasslightlyhigherinthebaseline conditionthanfor
elements.ExamplesoftheseAOIscanbefoundinFigure5.For word-sizedgraphics withnosignificantdifference.
thebaseline conditions,wedefinedAOIsonfactsthatare
3.3 SubjectiveFeedback
equivalenttotheonesthatwereaugmentedwithvisualelements
intheotherconditions.Weinvestigatedtherelativedurationof Further,wecollectedsubjectivefeedbackwithrespecttodifficulty,
fixationsonAOIstoidentifypotentialdistractionandtheaverage confidence,andtheimpressionsofbeingrushedandannoyed.Fig-
ure7showstheparticipants‚Äôratingsofeachcondition,whichwere
givenona1to7Likertscale.Theperceiveddifficultyishighestfor
thebaseline conditionsinbothexperimentsandinExperi-
ment1lowestfortextswithicons .Theconfidenceintheanswers
wasratedhighestfortextswithhighlights inExperiment1,and
for texts with wsg in Experiment 2. For the baseline
conditions,theconfidenceratingwaslowestinbothexperiments.
Thesedifferencesare,however,notsignificant.
Participantsratedthattheyfeltrushedorhurriedsignificantly
morefortextswithhighlights thanfortheotherconditions
inExperiment1.InExperiment2,participantsfeltslightlymore
rushedinthebaseline thanthewsg condition.Theyalso
feltsignificantlymoreannoyedorstressedinthebaseline than
wsg condition. In Experiment 1, participants reported most
annoyancewiththebaseline conditionandleastwithtextswith
icons ,butwithoutasignificantdifference.
Experimentconditionpreferences. Almostallparticipantsreported
thattheypreferredtextswithvisualelements overplain
texts ,inbothexperiments,asthey‚Äúmakeiteasiertoidentify
Figure5:ExampleoftheAOIswedefinedforstimuliforthe
relevantparts‚Äùandare‚Äúhelpfulformemorization‚Äù.Twopartici-
experimentconditions(top)highlight ,and(bottom)word-
pantsfoundthehighlighted textsorthetextswithword-sized
sizedgraphics . graphics toodistracting,butstilllikedicons morethanplainEyeTrackingonTextReadingwithVisualEnhancements ETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom
fixationonAOIs(%) averagesaccadeamplitude(¬∞)
Figure6:Durationoffixationsonvisualelements(andforthebaselineconditions,equivalentfactsinthetexts)inrelationto
thereadingtimeperstimulus,andtheaverageamplitudeofsaccades.Averagewithstandarddeviations(leftchart,respectively).
Pairwisedifferencesbetweenthestudyconditions(rightchart,respectively),with95%bootstrapconfidenceintervalsandred
linesindicatingtheBonferronicorrectionsfor3pairwisecomparisonsinthefirstexperiment.
difficulty confidence
rushed annoyed
Figure7:Qualitativeratingsofparticipants‚Äôperceivedtaskdifficulty,confidenceinanswers,howrushedandhowannoyed
theyfelt,fromlow(1)tohigh(7).Averagewithstandarddeviations(leftchart,respectively).Pairwisedifferencesbetweenthe
studyconditions(rightchart,respectively),with95%bootstrapconfidenceintervalsandredlinesindicatingtheBonferroni
correctionsfor3pairwisecomparisonsinthefirstexperiment.
text .InExperiment1,abouthalfoftheparticipantspreferred elements ,mostparticipants‚Äôself-reportedreadingstrate-
icons overhighlights ,whiletheotherslikedhighlights gieschanged.Theysaidtheyfocusedmoreonthevisualelements
more.InExperiment2,participantsespeciallylikedthebarcharts thanontherestofthetext,and,afterreadingthewholetext,went
bestandfoundthemeasiesttoread. backtothevisualelementsagaintohelpwithmemorizinginforma-
tion.Forexample,they‚Äútriedtolinkthewordwiththeicon‚Äù ,
Readingstrategies. Mostparticipantsclaimedthattheyusually or were ‚Äúskimming over it [the text] and focused on the high-
donotfollowaspecificreadingstrategy.Somesaidthattheysome-
lights/icons‚Äù .InExperiment2,someparticipantsstatedthat
times skim over filler words, or read quickly and not word-for-
theyinspectedtheword-sizedgraphics morecloselyafterread-
word. For the baseline conditions, some participants re-
ingthetext,tobettermemorizethefacts.
portedreadingthetextandthengoingthroughitagainand‚Äútrying
torememberpossiblekeyinformation‚Äù,and‚Äúafterafewstimuli,
started focusing more on the fact lists in the text‚Äù. With visualETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom Huth,etal.
Figure8:GazePlotsofparticipantsP4(left)andP9(right)ontheword-sizedgraphics condition.Participantsreceivedthe
followingquestion:HowmuchofthetotalredpandapopulationdoestheWesternredpandamakeup?P4readthehighlighted
partsfrequentlyandansweredthequestioncorrectly,whereasP9didnot.
3.4 Correlations forsomepeoplefeelingdistracted,butitmightalsohelpthemre-
As is to be expected, we found an inverse correlation between membertheseparticularelementsbetter(Figure8,left).Further
thedifficultyandconfidenceratings.Thereisalsoacorrelation experimentswillbenecessarytoconfirmtheseassumptions.
betweentheratingsfordifficultyandlevelofannoyance.Thereare,
Hypothesesforfurtherstudies. Wesummarizedourresultsinthe
however,noremarkablecorrelationsbetweentaskperformanceand
formofhypothesesweplantoevaluateinfuturestudiesthatfocus
anyotherfactors.Weincludedfurtherdetailsinoursupplemental
lessontheexploratoryaspectsoftextenhancementsandmoreon
material.
hypothesis-driventestingwithspecifiedtasksandstimuli.
H : Thefixationsfortextsaugmentedwithiconsarelowerthan
4 DISCUSSION 1
forplaintexts.
Ourpreliminaryresultsindicatethattherearedifferencesinreading H : Saccadeamplitudesfortextwithvisualenhancementsare
2
behaviorwhentextisenhancedwithadditionalinformation.Some higherduetomorefrequentlooksontheseelements.
resultsconfirmcommonexpectationsfromexperienceandfrom H : Informationmemorizationandreadingspeedarehigherfor
3
theliterature.Others,suchasdifferencesinresultsbetweenthe textswithvisualelementsthanforplaintexts.
highlightandiconconditions,aremoresubtle.
Further,thereisasubjectivepreferencefortextswithvisualen-
VisualElements:Distractionorhelp? Ourresultsshowedthates- hancementsoverplaintextswhichwealsoplantoquantifyand
peciallyhighlightsintextattractattention.Thisresultwasexpected; investigateinmoredetailinthefuture.
highlightedtexthasapop-outeffect,makingitpre-attentivelyper-
5 CONCLUSION
ceivableandlookedatmorefrequentlythanwordsinplaintext.
Themainquestioninthiscaseis:Isthisgoodorbad?Highlighted Wepresentedtheresultsofasmall-scalestudyinvestigatingthe
texts(alsowithword-sizedgraphics)werefounddistractingby influence of highlighting, symbols, and word-sized graphics on
someparticipants,whichisreflectedinthehigherfixationduration readingbehaviorfortextdocuments.Tothispoint,theconducted
forhighlight andword-sizedgraphics thanforicon .Text experimentswereexploratorytoobservedifferencesbetweencon-
thatwasaugmentedwithicons overallreceivedthebestratings, ditionsandbuildhypotheses.Weperformedtheexperimentswith
andparticipantstendedtoperformbest.Thebaselinecondition just12participantstoquicklyachievethosefirstresults.Forfuture
showslongerfixationsthanicon ,whichcouldindicatethatwith work,weplantoconductalargerstudywithmorestatisticalpower
iconsitwaseasiertograspthefactualterms,whilenotbeingasdis- toconfirmourfindings.
tractingashighlights .Wefurthernoticedfrequentsaccadesto Thepresentedresultssupportfindingsfromtheliterature[Ben-
thevisualelements ,whichisalsoreflectedbythelower YehudahandEshet-Alkalai2018;FowlerandBarker1974;Goffin
saccadeamplitudesforplaintext .Thiscouldbeonereason etal.2015;Lorch1989]thatvisualenhancementshelprememberEyeTrackingonTextReadingwithVisualEnhancements ETRA‚Äô24,June4‚Äì7,2024,Glasgow,UnitedKingdom
factsofatextbetter.Byinvestigatingtheeyemovementsduring JosephGoldbergandJonathanHelfman.2011.Eyetrackingforvisualizationevaluation:
reading,wecouldseethatpeopletendtolookattheaddedele- Readingvaluesonlinearversusradialgraphs.InformationVisualization10,3(2011),
182‚Äì195. https://doi.org/10.1177/1473871611406623
mentsfrequently,whichcandisturbaconsistentreadingflowand
EdmundBurkeHuey.1908.Thepsychologyandpedagogyofreading:Withareview
isperceivedasannoyingbysomeparticipants.Hence,theuseof ofthehistoryofreadingandwritingandofmethods,texts,andhygieneinreading.
visualenhancements,especiallyhighlightsandword-sizedgraph- Macmillan.
FranziskaHuth,MiriamAwad-Mohammed,JohannesKnittel,TanjaBlascheck,and
ics,shouldbeconsideredcarefully,focusingonthemostimportant PetraIsenberg.2021a.OnlineStudyofWord-SizedVisualizationsinSocialMedia.
elementswithoutoverloadingthetextwithadditionalelements. InEuroVis2021-Posters.TheEurographicsAssociation,13‚Äì15. https://doi.org/10.
Further, there are challenges for choosing suitable icons. They 2312/evp.20211069
FranziskaHuth,TanjaBlascheck,SteffenKoch,SonjaUtz,andThomasErtl.2021b.
shouldbeclearinthetermsandconceptstheydepict,aswellas Word-sizedVisualizationsforExploringDiscussionDiversityinSocialMedia.In
respectculturaldifferences. IVAPP2021-12thInternationalConferenceonComputerVision,ImagingandComputer
GraphicsTheoryandApplications.SCITEPRESS,256‚Äì265. https://doi.org/10.5220/
0010328602560265
ACKNOWLEDGMENTS MartinKrzywinskiandNaomiAltman.2013.Errorbars:themeaningoferrorbars
isoftenmisinterpreted,asisthestatisticalsignificanceoftheiroverlap. Nature
Wethankallparticipantsofthestudy.Thisresearchwasfunded methods10,10(2013),921‚Äì923. https://doi.org/10.1038/nmeth.2659
bytheDeutscheForschungsgemeinschaft(DFG,GermanResearch ShahidLatifandFabianBeck.2018. VisuallyAugmentingDocumentsWithData.
Foundation) ‚Äì project 314647693 (VA4VGI) as part of the Prior- ComputinginScienceEngineering20,6(2018),96‚Äì103. https://doi.org/10.1109/
MCSE.2018.2875316
ityProgramVGIscience(SPP1894),byDFGproject449742818,and RobertF.Lorch.1989.Text-signalingdevicesandtheireffectsonreadingandmemory
underGermany‚ÄôsExcellenceStrategy-EXC2075-390740016.Addi- processes. EducationalPsychologyReview1(1989),209‚Äì234. https://doi.org/10.
1007/BF01320135
tionally,weacknowledgethefundingbytheDeutscheForschungs-
RudolfNetzel,BettinaOhlhausen,KunoKurzhals,RobinWoods,MichaelBurch,and
gemeinschaft(DFG,GermanResearchFoundation)‚ÄìProject-ID DanielWeiskopf.2017.Userperformanceandreadingstrategiesformetromaps:
251654672‚ÄìTRR161(ProjectB01).WethankPetraIsenbergfor Aneyetrackingstudy. SpatialCognition&Computation17,1-2(2017),39‚Äì64.
https://doi.org/10.1080/13875868.2016.1226839
earlydiscussionsonthetopic. OSF2024. OSF‚ÄìEyeTrackingonTextReadingwithVisualEnhancements. https:
//osf.io/utw7b/.
REFERENCES KeithRayner.1977. Visualattentioninreading:Eyemovementsreflectcognitive
processes. Memory&Cognition5,4(1977),443‚Äì448. https://doi.org/10.3758/
MoatazAbdelaal,NathanD.Schiele,KatrinAngerbauer,KunoKurzhals,MichaelSedl- BF03197383
mair,andDanielWeiskopf.2023.ComparativeEvaluationofBipartite,Node-Link, KeithRayner.1998.Eyemovementsinreadingandinformationprocessing:20yearsof
andMatrix-BasedNetworkRepresentations. IEEETransactionsonVisualization research.PsychologicalBulletin124,3(1998),372‚Äì422. https://doi.org/10.1037/0033-
andComputerGraphics29,1(2023),896‚Äì906. https://doi.org/10.1109/TVCG.2022. 2909.124.3.372
3209427 PuripantRuchikachornandPimmaneeRattanawicha.2018.AnEye-TrackingStudy
FabianBeck,YasettAcurana,TanjaBlascheck,RudolfNetzel,andDanielWeiskopf.2016. onSparklineswithinTextualContext..InEuroVis2018-Posters.TheEurographics
Anexpertevaluationofword-sizedvisualizationsforanalyzingeyemovement Association,17‚Äì19. https://doi.org/10.2312/eurp.20181119
data.InWorkshoponEyeTrackingandVisualization.Springer,50‚Äì54. https: EdwardR.Tufte.2006.BeautifulEvidence(1ed.).GraphicsPress.
//doi.org/10.1109/ETVIS.2016.7851166 HedwigVonRestorff.1933.√úberdieWirkungvonBereichsbildungenimSpurenfeld.
FabianBeck,TanjaBlascheck,ThomasErtl,andDanielWeiskopf.2015.Word-SizedEye- PsychologischeForschung18(1933),299‚Äì342. https://doi.org/10.1007/BF02409636
TrackingVisualizations.InWorkshoponEyeTrackingandVisualization.Springer, MenahemYeari,MarjaOudega,andPaulvandenBroek.2017.Theeffectofhighlighting
113‚Äì128. https://doi.org/10.1007/978-3-319-47024-5_7 onprocessingandmemoryofcentralandperipheraltextinformation:evidence
GalBen-YehudahandYoramEshet-Alkalai.2018.Thecontributionoftext-highlighting fromeyemovements.JournalofResearchinReading40,4(2017),365‚Äì383. https:
tocomprehension:Acomparisonofprintanddigitalreading.JournalofEducational //doi.org/10.1111/1467-9817.12072
MultimediaandHypermedia27,2(2018),153‚Äì178. https://www.learntechlib.org/p/
174353
LonniBesan√ßonandPierreDragicevic.2017. Thesignificantdifferencebetweenp-
valuesandconfidenceintervals.InConferenceonl‚ÄôInteractionHomme-Machine.
AssociationforComputingMachinery,53‚Äì62. https://hal.inria.fr/hal-01562281v2
OliverByrne.1847. ThefirstsixbooksoftheElementsofEuclid:inwhichcoloured
diagramsandsymbolsareusedinsteadoflettersforthegreatereaseoflearners.
WilliamPickering.
ChatGPT3.52023.GPT3.5turbo. platform.openai.com/docs/models/gpt-3-5.
EdHuai-hsinChi,MichelleGumbrecht,andLichanHong.2007. VisualForaging
ofHighlightedText:AnEye-TrackingStudy.In12thInternationalConferenceon
HCIIntelligentMultimodalInteractionEnvironments.Springer,589‚Äì598. https:
//doi.org/10.1007/978-3-540-73110-8_64
EdH.Chi,LichanHong,MichelleGumbrecht,andStuartK.Card.2005.ScentHighlights:
highlightingconceptually-relatedsentencesduringreading.In10thInternational
ConferenceonIntelligentUserInterfaces.AssociationforComputingMachinery,
272‚Äì274. https://doi.org/10.1145/1040830.1040895
GeoffCumming.2013.Understandingthenewstatistics:Effectsizes,confidenceintervals,
andmeta-analysis.Routledge.
PierreDragicevic.2016. FairstatisticalcommunicationinHCI. Springer,291‚Äì330.
https://doi.org/10.1007/978-3-319-26633-6_13
RobertLHFowlerandAnneS.Barker.1974.Effectivenessofhighlightingforretention
oftextmaterial. JournalofAppliedPsychology59,3(1974),358‚Äì364. https:
//doi.org/10.1037/h0036750
PascalGoffin,JeremyBoy,WesleyWillett,andPetraIsenberg.2017.AnExploratory
StudyofWord-ScaleGraphicsinData-RichTextDocuments.IEEEtransactionson
visualizationandcomputergraphics23,10(2017),2275‚Äì2287. https://doi.org/10.
1109/TVCG.2016.2618797
PascalGoffin,WesleyWillett,AnastasiaBezerianos,andPetraIsenberg.2015.Exploring
theeffectofword-scalevisualizationsonreadingbehavior.InConferenceonHuman
FactorsinComputingSystems.AssociationforComputingMachinery,1827‚Äì1832.
https://doi.org/10.1145/2702613.2732778