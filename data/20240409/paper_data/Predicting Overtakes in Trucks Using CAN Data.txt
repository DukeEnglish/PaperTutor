Predicting Overtakes in Trucks Using CAN Data
1 1 1
Talha Hanif Butt , Prayag Tiwari and Fernando Alonso-Fernandez
Abstract—Safe overtakes in trucks are crucial it.Knowingthedriver’sintentionisanintegralpart
to prevent accidents, reduce congestion, and ensure of the system, to determine if the ADAS should
efficient traffic flow, making early prediction es-
activate,providingopportuneaidsoralerts,oreven
sential for timely and informed driving decisions.
overriding the driver’s inputs [1].
Accordingly, we investigate the detection of truck
overtakesfromCANdata.Threeclassifiers,Artificial Among the most important driving manoeuvres
Neural Networks (ANN), Random Forest, and Sup- is the overtaking manoeuvre in particular. Lane
port Vector Machines (SVM), are employed for the changes, acceleration and deceleration, and esti-
task. Our analysis covers up to 10 seconds before
mation of the speed and distance of the vehicle
the overtaking event, using an overlapping sliding
ahead or in the lane it is travelling in are all part
window of 1 second to extract CAN features. We
observe that the prediction scores of the overtake of the process. Though there is a lot of work
class tend to increase as we approach the overtake in the literature that aims at predicting driving
trigger, while the no-overtake class remain stable or manoeuvres, very few address overtaking [2], [3],
oscillates depending on the classifier. Thus, the best
[4], and no real-world dataset is available due to
accuracy is achieved when approaching the trigger,
theriskassociatedwithovertaking[5].Mostworks
making early overtaking prediction challenging. The
classifiersshowgoodaccuracyinclassifyingovertakes addresstheestimationoflanechange[1]orturning
(Recall/TPR ≥ 93%), but accuracy is suboptimal intention at intersections [6]. In doing so, different
in classifying no-overtakes (TNR typically 80-90% data sources are typically used, including infor-
and below 60% for one SVM variant). We further
mation from the driver (via cameras or biosensors
combine two classifiers (Random Forest and linear
capturingEEG,ECG,etc.),fromthevehicle(CAN
SVM)byaveraging theiroutputscores. Thefusionis
observed to improve no-overtake classification (TNR bussignals),or the traffic(GPS positionorrelative
≥92%)attheexpenseofreducingovertakeaccuracy position or velocity of surrounding vehicles via
(TPR).However,thelatteriskeptabove91%nearthe cameras or lidar).
overtake trigger. Therefore, the fusion balances TPR
In this paper, we present ongoing work on over-
and TNR, providing more consistent performance
takedetection,inparticularfortrucks.Truckscarry
than individual classifiers.
heavier loads than cars, so a truck accident can be
I. INTRODUCTION way more devastating. Accidents involving trucks
can also lead to traffic congestion and delays due
ThedevelopmentofAdvancedDriverAssistance
to their bigger size, and economic losses due to
Systems (ADAS) has emerged as one of the most
cargo being transported. Ensuring driving security
popular areas of research in artificial intelligence.
fortrucksisthuscrucial,especiallywhencompared
Throughseveralsensors,ADASisdesignedtoalert
tolightervehicleslikecars.Weperformthetaskvia
thedriverofpotentialhazardsorcontrolthevehicle
CAN bus signals. We favour such signals because
toultimatelyavoidcollisionsoraccidents.Forthose
theyarereadilyavailableonboardwithouttheneed
tasks, thevehiclemustgatherinformationaboutits
for additional hardware like cameras or biosen-
surroundings to decide what to do and how to do
sors. This also avoids privacy concerns related to
1Talha Hanif Butt, Prayag Tiwari and Fernando Alonso- cameras looking inside or outside the cabin, or
Fernandez is with School of Information Technology, sensors capturing data from the driver. We employ
Halmstad University, Sweden talha-hanif.butt
real CAN data from real operating trucks provided
at hh.se, prayag.tiwari at hh.se,
fernando.alonso-fernandez at hh.se by Volvo Group participating in this research. The
4202
rpA
8
]GL.sc[
1v32750.4042:viXraTABLE I: Files employed per truck and class
Afterwards, a person manually labels the files by
for training and testing. t1, t2, t3 denotes truck1,
watching the videos and determines if it is an
truck2andtruck3,respectively.class0=noovertake.
overtake or not. With this procedure, we obtained
class1=overtake.
264 files labelled as no overtakes and 448 files as
class0 class1 overtakes.
t1 t2 t3 total t1 t2 t3 total
train 74 38 4 116 74 38 4 116
B. Classifiers
test 33 113 2 148 312 17 3 332
To detect overtakes, we have used 3 classifiers:
Artificial NeuralNetworks (ANN), Random Forest
contribution of this paper is that, to the best of (RF), and Support Vector Machines (SVM, with
our knowledge, we are the first to study overtake linear and rbf kernels). They are based on dif-
detectionin trucks,particularlyfromrealCAN bus ferent strategies and are a popular choice in the
data.We also demonstratethatthefusionof classi- related literature [7]. An ANN consists of several
fiers can help to obtain a balanced performance in interconnected neurons that are arranged in layers
detecting the two classes (overtake, no overtake). (i.e., input, hidden, and output layers). Nodes in
one layer are interconnected to all nodes in the
II. EXPERIMENTALFRAMEWORK
neighbouring layers. Two design parameters of
A. Database
ANNs are the number of intermediate layers and
Our database consists of data from 3 real op- the amount of neurons per layers. An extension of
erating trucks normally driving around Europe, the standard classification tree algorithm, the RF
provided by Volvo Group participating in this re- algorithmis an ensemble methodwhere the results
search. The trucks are equipped with a data logger of many decision trees are combined. This helps
that captures CAN signals at 10 Hz. The signals to reduce overfitting and to improve generalization
employed in this work include: capabilities. The trees in the ensemble are grown
1) Position of the accelerator pedal by using bootstrap samples of the data. Finally,
2) Distance to the vehicle ahead SVM searches for an optimal hyperplane in a
3) Speed of the vehicle ahead high dimensionalspace that separates the data into
4) Relativespeeddifferencebetweenthevehicle two classes. SVM uses different kernel functions
and the left wheel to transform data that can be used to form the
5) Vehicle speed hyperplane,such as linear,gaussianor polynomial.
6) Vehicle lateral acceleration Inthiswork,theavailablefilesarecroppedfrom
7) Vehicle longitudinal acceleration -10 seconds to +1 around the precondition trigger,
8) Lane change status of the vehicle following [6]. At 10 Hz, this gives 110 samples
9) Status of the left turn indicator per file. The CAN signals are then analyzed via a
10) Status of the right turn indicator sliding window of 1 second with 50% overlap, re-
To avoid running out of storage, the data logger sultingin21samplesperfile.Forsignals1-7(non-
is programmedto record only when a precondition categorical), we compute the mean and standard
trigger to detect potential overtakes is met. Such deviation of the samples inside the window [8],
triggerisactivatedbasedoncertainsignalsreaching whereas for signals 8-10 (categorical) we extract
specificthresholds:signal8(active),signal5(more the majorityvalue amongthe windowsamples. All
than 50 km/h), signal 2 (less than 200 m), and samples from overtake files are labelled as class1
signal 4 (more than 0.1 km/h). When the trigger is (positiveclassorovertake),whereasallsamplesfor
activated, the logger saves the CAN signals from no-overtake files are labelled as class0 (negative
20 seconds before the trigger up to 45 seconds class orno-overtake).Thetrainingdatais balanced
thereafter. Data also includes video from a camera perclass.Itmeansthatwecheckhowmanyfilesof
placed in the dashboard looking ahead the vehicle. each class are available per truck, then we take theFig. 1:Boxplotofscorestowardsclass0 (leftcolumn,noovertakeclass) andclass1 (right,overtake)from
-10 to +1 seconds around the trigger. From top to bottom row: ANN, RF, SVM linear and SVM rbf
classifiers.
1 ANN: score towards class0 (v starttriger -10, v endtriger 1, window 1) 1 ANN: score towards class1 (v starttriger -10, v endtriger 1, window 1)
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0 1-10 -9.5 -9 -8.5 -8 -7.5 RF: sco-7 re tow- a6 r.5 ds clas- s6 0 (v st- a5 r. t5 trigSeerc o-- 15n0d, sv en-4 d.5 triger 1-4 , wind- o3 w.5 1) -3 -2.5 -2 -1.5 -1 -0.5 0 0 1-10 -9.5 -9 -8.5 -8 -7.5 RF: sco-7 re tow- a6 r.5 ds clas- s6 1 (v st- a5 r. t5 trigSeerc o-- 15n0d, sv en-4 d.5 triger 1-4 , wind- o3 w.5 1) -3 -2.5 -2 -1.5 -1 -0.5 0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0 1-10 -9.5 -9 -8.5 -8 S- V7 M.5 linear- :7 score - t6 o. w5 ards c-6 lass0 (v-5 s.5 tarSttercigo-5 enrd -s10, - v4 . e5 ndtrig-4 er 1, w- i3 n. d5 ow 1)-3 -2.5 -2 -1.5 -1 -0.5 0 0 1-10 -9.5 -9 -8.5 -8 S- V7 M.5 linear- :7 score - t6 o. w5 ards c-6 lass1 (v-5 s.5 tarSttercigo-5 enrd -s10, - v4 . e5 ndtrig-4 er 1, w- i3 n. d5 ow 1)-3 -2.5 -2 -1.5 -1 -0.5 0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0 1-10 -9.5 -9 -8.5 -8 - S7 V.5 Mrbf: - s7 core to-6 w.5 ards cl- a6 ss0 (v - s5 t. a5 rttSreigceo-5 rn -d1s0, v- 4 e. n5 dtrige-4 r 1, win-3 d.5 ow 1)-3 -2.5 -2 -1.5 -1 -0.5 0 0 1-10 -9.5 -9 -8.5 -8 - S7 V.5 Mrbf: - s7 core to-6 w.5 ards cl- a6 ss1 (v - s5 t. a5 rttSreigceo-5 rn -d1s0, v- 4 e. n5 dtrige-4 r 1, win-3 d.5 ow 1)-3 -2.5 -2 -1.5 -1 -0.5 0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0-10 -9.5 -9 -8.5 -8 -7.5 -7 -6.5 -6 -5.5Seco-5nds-4.5 -4 -3.5 -3 -2.5 -2 -1.5 -1 -0.5 0 0-10 -9.5 -9 -8.5 -8 -7.5 -7 -6.5 -6 -5.5Seco-5nds-4.5 -4 -3.5 -3 -2.5 -2 -1.5 -1 -0.5 0
Fig.2:Precision-Recallcurvesoftheclassifiersatdifferentmomentsbeforetheovertakemaneuverstarts.
AUC (Area under the curve) values are given in Table II.
ANN RF SVMlinear SVMrbf
1 1 1 1
0.9 0.9 0.9 0.9
0.8 0.8 0.8 0.8
0.7 0.7 0.7 0.7
0s before
0.6 1s before 0.6 0.6 0.6
2s before
3s before
all samples
0.5 0.5 0.5 0.5
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Recall Recall Recall Recall
noisicerP
eulaV
eulaV
eulaV
eulaV
noisicerP
eulaV
eulaV
eulaV
eulaV
noisicerP noisicerPFig. 3: F1-score vs. threshold at different moments before the overtake maneuver starts.
ANN RF SVMlinear SVMrbf
0.95 0.95 0.95 0.95
0.9 0.9 0.9 0.9
0.85 0.85 0.85 0.85
0.8 0.8 0.8 0.8
0.75 0.75 0.75 0.75
0.7 0s before 0.7 0.7 0.7
1s before
0.65 2 3s s b be ef fo or re e 0.65 0.65 0.65
all samples
0.6 0.6 0.6 0.6
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Threshold Threshold Threshold Threshold
70% of the minimum. All other files are used for III. RESULTS
testing.Thisresultsintheamountoffilesindicated
In Figure 1, we present the boxplots of the
in Table I.
decision scores of each classifier towards the two
ExperimentsareconductedusingMatlabr2023b. classes.Noticethattheclassifiersaresettoproduce
Allclassifiersareleftwiththedefaultvalues(ANN: the probability that a sample belongs to a specific
onehiddenlayerwith10neurons;RF:100decision class (i.e. belonging to [0,1]). It can be observed
trees), except: that the output probability of class1 (overtake)
usually increases as the precondition trigger ap-
• ANN and SVM use standardization (subtract
proaches(x-axis=0), whereas class0 keeps a stable
the mean, and divide by std of training data)
or oscillating probability, depending on the classi-
• TheANNiterationlimitisraisedto1e6(from
fier. Thus,fromtherightplotofFigure1,itcan be
1e3) to facilitate convergence
seen thatit willbe easier to detectovertakescloser
• Similarly, the SVMrbf iteration limit is raised
to the trigger.
to 1e8 (from 1e6)
We then report in Figure 2 the Precision-Recall
(PR) curves of the classifiers at different moments
before the precondition trigger. We also provide
TABLE II: AUC-PR of the classifiers at different
results considering all samples of the files at any
moments before the overtake manoeuvre starts (t
given instant from -10 seconds to +1 seconds
corresponds to the precondition trigger, t-1 to one
around the trigger. Table II gives the AUC (Area
secondearlier,andsoon).ThePRcurvesareshown
under the curve) values. Precision measures the
in Figure 2. The row variation shows the differ-
proportion of detected positives which are actually
ence between RF+SVML and the best AUC (Area
overtakes, quantified as:
under the curve) of the RF and SVML classifiers.
The bold number in each column indicates the TP
P = (1)
resultsofthebestindividualclassifier.Ifthefusion TP +FP
RF+SVML improves the best individual classifier,
Recall, on the other hand, measures the amount
such a cell is also marked in bold.
of overtakes that are actually detected, as:
all
classifier t t-1 t-2 t-3 samples TP
R= (2)
ANN 0.931 0.914 0.907 0.890 0.880 TP +FN
RF 0.896 0.885 0.890 0.900 0.902
SVML 0.952 0.950 0.946 0.949 0.951 A summarizing measure of P and R is the F1-
SVMrbf 0.914 0.915 0.903 0.906 0.897
score, defined as:
RF+SVML 0.981 0.981 0.975 0.974 0.973
variation +0.029 +0.031 +0.029 +0.025 +0.022
P ×R
F1=2 (3)
P +R
erocs
1F
erocs
1F
erocs
1F
erocs
1FTABLE III:Precision, recall and F1-score (valuesin %) of the classifiers at differentmomentsbefore the
overtakemanoeuvrestarts(tcorrespondstothepreconditiontrigger,t-1toonesecondearlier,andso on).
We use the threshold (th) which gives the maximum F1-score (Figure 3). The row variation shows the
difference between RF+SVML and the best of the RF and SVML classifiers. The bold number in each
column indicates the results of the best individual classifier. If the fusion RF+SVML improves the best
individual classifier, such a cell is also marked in bold.
t t-1 t-2 t-3 allsamples
classifier Prec Rec F1 th Prec Rec F1 th Prec Rec F1 th Prec Rec F1 th Prec Rec F1 th
ANN 90.12 94.51 92.26 0.13 91.12 93.90 92.49 0.24 84.27 96.34 89.90 0.00 84.97 94.82 89.63 0.01 84.52 94.72 89.33 0.00
RF 95.05 92.47 93.74 0.56 88.35 98.19 93.01 0.33 91.82 91.27 91.54 0.47 88.45 94.58 91.41 0.37 86.84 94.75 90.62 0.33
SVML 90.80 93.29 92.03 0.48 91.32 92.99 92.15 0.52 89.38 92.38 90.85 0.46 91.13 90.85 90.99 0.48 87.11 93.13 90.02 0.36
SVMrbf 83.38 96.34 89.39 0.18 81.94 95.43 88.17 0.17 83.29 94.21 88.41 0.18 83.06 94.21 88.29 0.18 82.25 91.49 86.63 0.18
RF+SVML 97.12 91.27 94.10 0.59 95.91 91.87 93.85 0.57 97.00 87.65 92.09 0.59 96.99 87.35 91.92 0.59 92.99 88.45 90.66 0.51
variation +2.07 -2.03 +0.36 +4.59 -6.33 +0.84 +5.18 -4.73 +0.55 +5.86 -7.23 +0.51 +5.88 -6.30 +0.04
TABLE IV: TPR/TNR of the classifiers at different moments before the overtake manoeuvre starts (t
corresponds to the precondition trigger, t-1 to one second earlier, and so on). The row variation shows
the difference between RF+SVML and the best of the RF and SVML classifiers. The bold number in
each column indicates the results of the best individual classifier. If the fusion RF+SVML improves the
best individual classifier, such a cell is also marked in bold.
classifier t t-1 t-2 t-3 allsamples
TPR TNR TPR TNR TPR TNR TPR TNR TPR TNR
ANN 94.51% 76.39% 93.90% 79.17% 96.34% 59.03% 94.82% 61.81% 94.72% 60.48%
RF 92.47% 89.19% 98.19% 70.95% 91.27% 81.76% 94.58% 72.30% 94.75% 67.79%
SVML 93.29% 78.47% 92.99% 79.86% 92.38% 75.00% 90.85% 79.86% 93.13% 68.62%
SVMrbf 96.34% 56.25% 95.43% 52.08% 94.21% 56.94% 94.21% 56.25% 91.49% 55.03%
RF+SVML 91.27% 93.92% 91.87% 91.22% 87.65% 93.92% 87.35% 93.92% 88.45% 85.04%
variation -2.03% 4.73% -6.33% 11.36% -4.73% 12.16% -7.23% 14.06% -6.30% 16.42%
Figure 3 providesthe F1-scorefordifferentval-
TN
ues of the threshold applied to the decision scores. TNR= (5)
The mentionedcurvesconfirm the observationthat TN +FP
“the closer to the trigger, the better”. It can be TPR measuresthe amountof overtakesthat are
seen that orange curves (0s before the trigger) and actually labelled as overtakes,whereasTNR mea-
red curves (1s before the trigger) usually appear sures the amount of no overtakes that are actually
above the others. The black curves (which use labelled as no overtakes. Notice that TPR = R.
samples in the entire range of -10 seconds to The bold values in the tables show that Random
+1 seconds around the trigger) always show the Forest(RF)usuallystandsoutasthebestindividual
worstbehaviour.Thisconfirmsthatsamplesearlier classifier, consistently obtaining the highest F1 at
than 3 seconds before the trigger actually provide any given moment in time. To better observe the
worse detection capabilities, making more difficult evolution of TPR/TNR, we graphically show in
to predict overtakes earlier. Figure 4 their values at different moments before
We then select the threshold of each classifier the trigger. TPR stands above 90% for all clas-
and moment that provides the highest F1-score. sifiers, even when using all samples within 10
Table III reports P, R and F1, whereas Table IV seconds before the trigger, meaning that actual
reports the true positive rate (TPR) and false overtakes can be well detected. Random Forest
positive rate (FPR), calculated as follows: gives the best accuracy (>98% at t-1), although
its performance is somehow more erratic across
time. ANN is the classifier with the most stable
TP TPRatanytime(above94%).Interestingly,notall
TPR= (4)
TP +FN classifiers have their bestTPRat t (exactmomentof the trigger). As it was observed in the boxplots (RF), and SupportVector Machines(SVM). To the
of Figure 1, the score towards the positive class best of our knowledge, we are the first to apply
(right columns) tends to decrease abruptly exactly machine learningtechniquesfor overtakedetection
at the trigger. This could be because the window of trucks from CAN bus data. The classifiers em-
is capturing a portion of samples after the trigger, ployed performedwell for the overtake class (TPR
which is shown to actually be detrimental to the ≥ 93%),althoughtheirperformanceisnotasgood
detection. Regarding TNR (left plot of Figure 4), in the no overtakeclass. With the help of classifier
its values can diminish to as low as the 50-60% fusion, the accuracy of the later class is observed
range, meaning that a substantial percentage of no to increase, at the cost of some decrease in the
overtakes would be actually labelled as overtakes. overtake class. Overall, the fusion balances TPR
Here, RF and ANN show better numbers (TNR and TNR, providing more consistent performance
above 70-80%). Also, in this case, it is actually than individual classifiers.
observedthatthe fartherawayfromthe trigger,the As future work, we are exploring the optimiza-
lower the TNR. tion of classifiers beyond their default values [9].
From the results above, we observe that TNR Parameters like the size of the sliding window
is not as high, so the classifiers are not as good in employed or the time ahead of the precondition
classifying no overtakes. Also, ANN and SVMrbf triggerarealsosubjecttodiscussionintheliterature
show some strange behaviour, such as that the [1], [7]. There is the possibility of capturing large
thresholdofmaximumF1istoolow(TableIII),or amounts of continuous unlabeled data from Volvo
the P-R curves are too “shaky”. This suggests that Group participating in this research. We are also
the default values of these classifiers may not be consideringtheimprovementofthedevelopedclas-
the best choice. We thus take RF and SVM linear sifiersbytrainingthemonalargerdatasetobtained
further and fuse their output scores by taking their viapseudo-labeleddata[10],forexample,selecting
mean.TheAUC,P,R,F1,TNRandTPRofthe samples with high prediction probability as given
fusion have been also provided in Tables II-IV. It by the classifiers trained with labelled data. This
can be observedthatAUC, Precision, F1 and True would avoid the time-consuming manual labelling
Negative Rates improve for all moments before issue. A bigger dataset would also enable the use
the trigger. On the other hand, Recall and True ofdata-hungrypopularmodelssuchasLongShort-
Positive Rates are seen to decrease. The observed Term Memory (LSTM) networks [11].
effectof the fusion is that the ability to classify no
overtakesisincreased,atthecostofreducingover- ACKNOWLEDGEMENTS
take detection capabilities. However, the increase The authors thank the BigFun project of the
in TNRis muchbiggerthanthe decreaseinTPR Swedish InnovationAgency(VINNOVA)forfund-
(Tables IV). Overall, the fusion provides a more ing their research.
balanced accuracy of these two metrics, situating
them beyond 91%. For example, at t-1 or earlier, REFERENCES
TNRwasbelow80%,butafterthefusion,asearly
[1] Yang Xing, Chen Lv, Huaji Wang, Hong Wang, Yun-
as3secondsbeforethetrigger,bothclasseshavean feng Ai, Dongpu Cao, Efstathios Velenis, and Fei-Yue
accuracyof87%orhigher.Suchstabilityandwell- Wang, “Driver lane change intention inference for intel-
ligentvehicles:Framework,survey,andchallenges,”IEEE
balancedaccuracycanalsobeobservedinFigure4.
Transactions onVehicular Technology, vol.68,no.5,pp.
4377–4390, 2019.
IV. CONCLUSIONS [2] Elis Stefansson, Frank J Jiang, Ehsan Nekouei, Hakan
Nilsson, and Karl Henrik Johansson, “Modeling the
We demonstrate the suitability of CAN bus data decision-making in human driver overtaking,” IFAC-
to detect overtakes in trucks. We do so via tra- PapersOnLine, vol.53,no.2,pp.15338–15345, 2020.
[3] Christoph Blaschke, Josef Schmitt, and Berthold Farber,
ditional widely used classifiers [7], including Ar-
“Predictingovertakingmanoeuvresviacan-busdata,”ATZ
tificial Neural Networks (ANN), Random Forest worldwide, vol.110,no.11,pp.47–51,2008.Fig. 4: Graphical plot of TPR/TNR at different moments before the overtake manoeuvre starts (t
corresponds to the precondition trigger, t-1 to one second earlier, and so on).
True Positive Rate True Negative Rate
100 100
90
95
80
70
90 ANN
RF
SVM linear 60
SVM rbf
85 Fusion: RF+SVML 50
all t-3 t-2 t-1 t all t-3 t-2 t-1 t
Time before the trigger Time before the trigger
[4] Yu-Chen Lin, Chun-Liang Lin, Shih-Ting Huang, and
Cheng-Hsuan Kuo, “Implementation of an autonomous
overtaking system basedontimetolanecrossingestima-
tion and model predictive control,” Electronics, vol. 10,
no.18,pp.2293,2021.
[5] MarianaPinto,InesDutra,andJoaquimFon-^seca,“Data
and knowledge for overtaking scenarios in autonomous
driving,” Journal of Autonomous Vehicles and Systems,
pp.1–30,2023.
[6] HailunZhangandRuiFu,“Ahybridapproachforturning
intention prediction based on time series forecasting and
deeplearning,” Sensors,vol.20,no.17,pp.4887,2020.
[7] Anik Das, Md Nasim Khan, and Mohamed M Ahmed,
“Detecting lane change maneuvers using shrp2 naturalis-
tic driving data: A comparative study machine learning
techniques,”AccidentAnalysis&Prevention,vol.142,pp.
105578,2020.
[8] Il-HwanKim,Jae-HwanBong,JooyoungPark,andShin-
sukPark,“Prediction ofdriver’s intention oflane change
byaugmentingsensorinformationusingmachinelearning
techniques,” Sensors,vol.17,no.6,pp.1350,2017.
[9] Michael A. Gelbart, Jasper Snoek, and Ryan P. Adams,
“Bayesianoptimizationwithunknownconstraints,”inPro-
ceedings of the Thirtieth Conference on Uncertainty in
Artificial Intelligence, Arlington, Virginia, USA, 2014,
UAI’14,p.250–259,AUAIPress.
[10] Zhun Li, ByungSoo Ko, and Ho-Jin Choi, “Naive semi-
superviseddeeplearningusingpseudo-label,”Peer-to-Peer
Networking and Applications, vol. 12, pp. 1358–1368,
2019.
[11] Dong-Fan Xie, Zhe-Zhe Fang, Bin Jia, and Zhengbing
He, “A data-driven lane-changing model based on deep
learning,”TransportationResearchPartC:EmergingTech-
nologies, vol.106,pp.41–60,2019.
)%(
ycaruccA
)%(
ycaruccA