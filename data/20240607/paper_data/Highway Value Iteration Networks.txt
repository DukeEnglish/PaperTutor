Highway Value Iteration Networks
YuhuiWang*1 WeidaLi*2 FrancescoFaccio13 QingyuanWu4 Ju¨rgenSchmidhuber13
Abstract 1.0
Value iteration networks (VINs) enable end-to- 0.8
end learning for planning tasks by employing
0.6 300-layer Highway VIN (ours)
adifferentiable“planningmodule”thatapprox- 30-layer VIN
0.4 300-layer VIN
imates the value iteration algorithm. However,
long-termplanningremainsachallengebecause 0.2
trainingverydeepVINsisdifficult. Toaddress
0.0
thisproblem,weembedhighwayvalueiteration— 0 100 200
arecentalgorithmdesignedtofacilitatelong-term Shortest Path Length
credit assignment—into the structure of VINs. Figure1: Successratesofreachingthegoalina25×25
Thisimprovementaugmentsthe“planningmod- maze problem. The success rate of a 30-layer VIN con-
ule”oftheVINwiththreeadditionalcomponents: siderably decreases as the shortest path length increases,
1)an“aggregategate,”whichconstructsskipcon- andtraininga300-layerVINisdifficultandexhibitspoor
nectionstoimproveinformationflowacrossmany performance.
layers; 2) an “exploration module,” crafted to
increase the diversity of information and gradi-
entflowinspatialdimensions; 3)a“filtergate”
designedtoensuresafeexploration. Theresult- However, VIN encounters significant challenges in long-
ingnovelhighwayVIN canbetrainedeffectively termplanning. Forexample,inpathplanningtaskswhere
withhundredsoflayersusingstandardbackprop- the shortest path length exceeds 120, the success rate of
agation. In long-term planning tasks requiring VINsinreachingthegoaldrasticallydecreasesbelow10%
hundredsofplanningsteps,deephighwayVINs (Fig.1). Apromisingapproachtoimprovethelong-term
outperformbothtraditionalVINsandseveralad- planningcapabilitiesofVINisincreasingthedepthofits
vanced,verydeepNNs. embedded “planning module.” A deeper planning mod-
ulecanintegratemoreplanningstepsinVINs,potentially
improvingtheirabilitytoperformlong-termplanning.
1.Introduction
Nonetheless,increasingthedepthofanNNcanintroduce
Planningisasearchforactionsequencesthatarepredicted complications, such as vanishing or exploding gradients,
toachievespecificgoals. Thevalueiterationnetwork(VIN) whichisafundamentalproblemindeeplearning(Hochre-
(Tamaretal.,2016)isaneuralnetwork(NN)architecture iter, 1991). Although very deep NNs can be effectively
thatenablesend-to-endtrainingforplanningtasksusingan trainedinclassificationtasksusingdifferentmethods(Sri-
embedded“planningmodule,”adifferentiableapproxima- vastavaetal.,2015b;a;Heetal.,2016;Huangetal.,2017),
tionofthevalue-iterationalgorithm(Bellman,1966). VINs thesemethodshavenotbeenequallysuccessfulinplanning
haveexhibitedremarkableproficiencyinvarioustasks,in- tasks(Table1inSection5). Thisdisparitymayarisefrom
cludingpathplanning(Pfluegeretal.,2019;Jinetal.,2021), theuniquearchitectureoftheVIN,particularlyitsplanning
autonomousnavigation(Wo¨hlkeetal.,2021),andcomplex module,whichincorporatesaspecificinductivebiasfromre-
decision-makingindynamicenvironments(Lietal.,2021b). inforcementlearning(RL).Thisinductivebiasisgrounded
in the value iteration algorithm, known for its theoretical
*Equalcontribution 1AIInitiative,KingAbdullahUniversityof
soundness(Bellman,1966;Sutton&Barto,2018). Herein,
ScienceandTechnology2NationalUniversityofSingapore3The
additionalRL-relevantpriorknowledgeisintegratedinto
SwissAILabIDSIA/USI/SUPSI4TheUniversityofLiverpool.
Correspondenceto:YuhuiWang<yuhui.wang@kaust.edu.sa>. theVINarchitecturetoaddressthesechallenges.
This study aims to integrate well-established techniques
Proceedings of the 41st International Conference on Machine
Learning,Vienna,Austria.PMLR235,2024.Copyright2024by fromboththefieldsofNNsandRLtocreateaneffective
theauthor(s). andtheoreticallysoundmethod. Centraltothefoundation
1
4202
nuJ
5
]GL.sc[
1v58430.6042:viXra
etaR
sseccuSHighwayValueIterationNetworks
ofthisproposedapproachishighwayvalueiteration(Wang existingmethodsareconsiderablylimitedtoextendtoreal-
et al., 2024). This method was designed to facilitate effi- worldandlarge-scaleplanningproblemsasshallowNNs
cientlong-termcreditassignmentinthecontextofRL.We lacklong-termplanningability.
alsoleveragethearchitecturalinnovationsofhighwaynet-
works(Srivastavaetal.,2015b;a)andtheirvariantsresidual
NeuralNetworkswithDeepArchitectures. Deeplearn-
networks (He et al., 2016) and DenseNets (Huang et al.,
inginvolvesassigningcreditstoNNcomponentsthataffect
2017),particularlytheiruseofskipconnections,whichare
the performance of the NN across multiple layers, or in
advantageousfortrainingexceptionallydeepNNs.
the case of sequential data, over several time steps. In
Buildingonthisfoundation, theVINisenhancedbyem- 1965,Ivakhnenko&Lapa(1965)introducedthefirstlearn-
beddingthehighwayvalueiterationalgorithmintoitscore ingalgorithmsfordeepfeedforwardNNs(FNNs)withany
“planning module.” This integration introduces three key number of hidden layers. However, training FNNs with
innovations: (1)an“aggregategate”forcreatingskipcon- morethansixlayersbygradientdescentremainedachal-
nectionsandimprovinginformationflowbetweenlayers;(2) lengeuntiltheearly2010s(Ciresanetal.,2010). Similarly,
an“explorationmodule”thatinjectscontrolledstochasticity inthe1980s,recurrentneuralnetworks(RNNs)werelim-
duringtraining,therebydiversifyinginformationandgra- itedtoproblemsspanningfewerthantentimestepsdueto
dientflowacrossspatialdimensions;(3)anda”filtergate” the“vanishinggradientproblem”(Hochreiter,1991), the
designedto“filterout”uselessexplorationpaths,ensuring fundamentalproblemofdeeplearning. InverydeepNNs,
safeandefficientexploration. Theseimprovementsresultin and in RNNs processing sequences with significant time
thehighwayvalueiterationnetwork(highwayVIN),anew lagsbetweenrelevantevents,thebackpropagatedgradients
VINvariantspecificallytailoredforlong-termplanning. Re- tendtoeitherexplodeorvanish. In1991,advancesinhis-
markably,highwayVINscanbeefficientlytrainedwithhun- tory compression and neural sequence chunking through
dredsoflayersusingstandardbackpropagationtechniques. self-supervised pre-training enabled training RNNs over
ThisstudyhighlightstheconnectionsbetweenhighwayRL hundredsorthousandsofsteps(Schmidhuber,1991;1992).
andhighwaynetworksandtheircombinedpotentialtoad- However,thisworkedonlyforsequenceswithpredictable
vancethecapabilitiesofdeeplearningmodelsincomplex regularities. Thislimitationwasovercomeusingresidual
planning tasks. Notably, in scenarios requiring extensive recurrentconnections(Hochreiter,1991)inlongshort-term
planning,highwayVINsoutperformtraditionalVINsand memory(LSTM)RNNs(Hochreiter&Schmidhuber,1997).
severaladvanceddeepNNmodels. Thisshowcasestheir ThisandthelatergatedLSTMversion(Gersetal.,2000)
superiorcapabilityinhandlingcomplex,long-termplanning informedthefirstverydeepFNNscalledhighwaynetworks
challenges. ThesourcecodeofhighwayVINisavailableat (Srivastava et al., 2015b). LSTM RNNs are particularly
https://github.com/wangyuhuix/HighwayVIN. well-suitedfortasksinvolvingcreditassignmentoverthou-
sandsofsteps,whereassimilarhighwaynetworkswerethe
earliestFNNswithhundredsoflayers(previousFNNshad
2.RelatedWork
atmosttensoflayers). Followingthesameprinciple,the
Variants of Value Iteration Networks. VINs (Tamar popularResNetFNNarchitecture(Heetal.,2016)keepsthe
etal.,2016)areimportantarchitecturesthatintegrateplan- highwaygatespermanentlyopen, allowinguninterrupted
ning capabilities directly into NNs. VINs have a notable informationflowfromthefirsttothelastlayer. Residual
advantage over classical RL methods, as they learn poli- connections(Hochreiter,1991)havebecomeessentialfor
ciesthatgeneralizebetteronnoveltasks. However,VINs manysuccessfuldeep-learningarchitectures(Huangetal.,
are challenged by issues such as training instability, hy- 2017),includinggraphneuralnetworkswithhundredsof
perparameter sensitivity, and overestimation bias. These layers(Lietal.,2019;2021a).
issuescanbeaddressedusinggatedpath-planningnetworks
(GPPN)(Leeetal.,2018),arecurrentversionoftheVIN, 3.Preliminaries
whichreplacesconvolutionalnetworkswithgatedrecurrent
networks, resulting in more stable and effective learning. Reinforcement Learning. RL is usually formalized as
For higher-dimensional planning tasks, AVINs (Schleich a Markov decision process (MDP) problem (Puterman,
etal.,2019)extendVINswithmulti-levelabstractionmod- 2014). An MDP comprises states s ∈ S, actions a ∈
ules. These modules can capture various types of useful A, a reward function R(s,a,s′), and a transition func-
informationduringlearning. Anothersignificantchallenge
tionT(s′|s,a)thatrepresentsthelikelihoodoftransition-
arisesingeneralizingVINstotargetdomainswithlimited ing to the next state s′ from the current state and ac-
data. TransferVINs(Shenetal.,2020)tacklethisissueby tion (s,a). We assume that the action space is finite
proposingatransferlearningapproach,effectivelyadapting and the state space is countable. A policy π(a|s) de-
VINs to different, unseen target domains. Unfortunately, finesaprobabilitydistributionoveractionsforeachstate.
The value function Vπ(s) is defined as the expected dis-
2HighwayValueIterationNetworks
countedsumofrewardsforfollowingpolicyπ fromstate
s, i.e., Vπ(s) ≜ E[(cid:80)∞ γtR(s ,a ,s )|s =s;π],
t=0 t t t+1 0
where γ ∈ [0,1) is a discount factor. It is also con-
venient to define the action-value function Qπ(s,a) ≜
(cid:80) T (s′|s,a)[R(s,a,s′)+γVπ(s′)].Theobjectiveof
s′
RL is to find a policy yielding the maximum expected
sum of rewards. To achieve this, the optimal value func-
tion is defined as follows: V∗(s) = max Vπ(s) and
π
Q∗(s,a) = max Qπ(s,a), which allow us to construct
π
anoptimalpolicyπ∗(s)=argmax Q∗(s,a)thatsatisfies
a
Vπ∗(s)=V∗(s)∀s. TheBellmanoptimalityoperatorand
Bellmanexpectationoperatorarecommonlyusedtoobtain
thesevaluefunctionsasfollows:
(BV)(s)≜max(cid:88)
T
(cid:0) s′|s,a(cid:1)(cid:2) R(cid:0) s,a,s′(cid:1)
+γV
(cid:0) s′(cid:1)(cid:3)
, (1)
a
s′
(BπV)(s)≜(cid:88) π(a|s)(cid:88)
T
(cid:0) s′|s,a(cid:1)(cid:2) R(cid:0) s,a,s′(cid:1)
+γV
(cid:0) s′(cid:1)(cid:3)
.(2)
a s′ (a)VIN/HighwayVIN (b)PlanningModuleofVIN
IterativelyapplyingB andBπ toanyinitialvaluefunction Figure2: (a): ArchitectureofVINandhighwayVIN.(b):
V(0) willresultintheconvergencetoV∗ andVπ,respec-
ArchitectureoftheplanningmoduleofVIN,whichincludes
tively. The value iteration (VI) algorithm is a concrete N layersofvalueiterationmodules. Thearchitectureofthe
exampleofsuchaconvergence, whichiterativelyapplies valueiterationmoduleisdetailedinFig.4(a).
theBellmanoptimalityoperatorasV(n+1) =BV(n).
ValueIterationNetworks. VINsareNNsthatintegrate RL(Wangetal.,2024),whichisaframeworkforimprov-
theprocessofplanningintothelearningarchitecture. VINs ing the efficiency of long-term credit assignment. This
featurea“planningmodule”, whichapproximatestheVI approachintroducesamulti-stepoperator,whichaverages
process based on a learned latent MDP M. Below, we n-stepbootstrappingvaluesusingvariouspolicies,termed
willuse · todenoteallthetermsassociatedwiththelatent lookaheadpolicies,eachexecutedfordifferentntimesteps.
MDPM. VINsuselearnablemappingfunctionstotransit Here, n represents the lookahead depth. This operator is
anobservationϕ(s)toalatentMDPbyR=fR(ϕ(s))and formallydefinedasfollows:
T=fT(ϕ(s)).Then,itimplementstheVIupdateinEq.(1)
(cid:110) (cid:111)
using a Value Iteration module, which applies a convolu- GΠ,α(cid:101)V ≜smaxα(cid:101)smaxαmax (Bπ)◦(n−1)BV,BV . (5)
N,α
π∈Π n∈N
tionaloperationalongwithamax-poolingoperation:
In this formula, Π denotes the set of lookahead policies
Q( an ,i) ,j
=(cid:88)(cid:16)
T a,i′,j′R i−i′,j−j′ +T a,i′,j′V( i−n− i′1 ,j)
−j′(cid:17)
, (3) and N denotes the set of lookahead depths. The soft-
i′,j′ max function, with a softmax temperature α, is defined
as: smaxαf(x) ≜ (cid:80) exp(αf(x)) f(x). Here,
(n) (n)
x∈X
x∈X (cid:80) x′∈Xexp(αf(x′))
V =maxQ . (4) (·)◦k indicatesthecompositionofoperator(·)forktimes.
i,j a,i,j
a
Basedonthisoperator,thealgorithmhighwayVIiteratively
Here,theindicesi,j correspondtothecoordinatesofthe updates the value function as V(n+1) = GΠ,α(cid:101)V(n). Two
latent state, and a is the index of the action in the latent N,α
criticalaspectsofhighwayVIarehighlighted:
MDPM. Eq.(3)sumsoveramatrixpatchcenteredaround
Remark 1. (ConvergencetotheOptimalValueFunction)
position (i,j). Fig. 4(a) shows the computation process
ThehighwayVIalgorithmisprovedtoconvergetotheopti-
oftheVImodule. BystackingtheVImoduleforseveral
∗ malvaluefunctionV∗regardlessofthechoiceoflookahead
layers,itapproximatestheoptimalvaluefunctionV ,which
policiesΠ,lookaheaddepthsN,andsoftmaxtemperatures
is then mapped to a policy applicable to the actual MDP
α˜ and α. For a detailed formal statement, please refer to
M. Fig.2showstheVINarchitecture. Aseachcomponent
theirTheoremA.2(Wangetal.,2024).
of the architecture is differentiable, VINs can be trained
Remark 2. (Importance of the Maximization Operation)
end-to-end.
(cid:110) (cid:111)
Themaximizationoperation,max (Bπ)◦(n−1)BV,BV ,
HighwayValueIteration. Highwayvalueiteration(high- is crucial for ensuring convergence to V∗. Convergence
wayVI)isanalgorithmderivedfromthetheoryofhighway isnotguaranteedwithoutthiscomponent. Foradetailed
3HighwayValueIterationNetworks
formalstatement,pleaserefertotheirTheorem1,2(Wang
etal.,2024).
4.Method
Motivation. NNswithincreaseddepthhavesuperiorrep-
resentationalandgeneralizationcapabilities(Szegedyetal.,
2014;Ciresanetal.,2011;2012;Telgarsky,2016).Building
onthisknowledge,weproposethatincreasingthedepthof
VINcanconsiderablyboosttheirlong-termplanningabili-
tiesinthecontextofRL.Thispropositionisgroundedinthe
intrinsicdesignofVINs,whichincludesavalueiteration
planningmodule. Atheoreticalstudy(seeTheorem1.12,
(Agarwaletal.,2019))indicatesthatincreasediterationsin
thismodulecanresultinamoreaccurateestimationofthe
optimalvaluefunction,subsequentlyimprovingthepolicy
performance.
Overview. The traditional VIN (Section 3) propagates
information layer-by-layer, based on the step-by-step ap-
proachoftheVIprocess. Theproposednovelmethod,i.e.,
highwayVINs,enhancesVINsbyincorporatingadistinct
planningmoduleinspiredbyhighwayVI.AsdetailedinSec-
tion3,highwayVIusesinformationfromvariouspolicies
andmultiplestepsahead,forminganewVINarchitecture
that facilitates the information flow from various dimen-
sions. TheplanningmoduleofhighwayVINsfollowsthe
computational process of highway VI in Eq. (5). Below,
(n)
wedetailthetransitionfromthen-thactivationV ,repre- Figure 3: Planning module of highway VIN. Here, we
sentativeoftheiterativeprocessoftheproposedplanning demonstratetheplanningmoduleofhighwayVINusinga
module. highwayblockofdepthN =4andincorporatingN =2
b p
(n) embeddedpolicies.
First,V isfedintothevalueiterationmoduletogenerate
(n+1)
a new activation V , as in VINs (Eq. 3 and 4). This
stepcorrespondstotheBellmanoptimalityoperatorB(·)in
modulesarecombinedusinganaggregategateandafilter
highwayVI(seeEq. 5).
gate.Thiscombinationformsaskipconnectionarchitecture,
Then,tofacilitateinformationflowoverspatialdimensions, which eases the training of very deep NNs. These gates
weintroduceanewvalueexploration(VEmodule)module. mirror the operations smaxα(cid:101)smaxαmax{·} in highway
EachVEmoduleisequippedwithanembeddedpolicyπ, π n
VI.
definedonthelatentMDPManddeterminingthepathof
theinformationflow. Conceptually,itcorrespondstoone We term the above four procedures as a highway block.
applicationoftheBellmanExpectationoperatorBπ(·)in TheplanningmoduleofhighwayVINcomprisesN B such
highwayVI. highway blocks. Fig. 3 overviews this planning module.
ThesubsequentsectionsdetailthecomponentsoftheVE
Then,tofurtherfacilitatespatialinformationflowindepth,
module,filtergate,andaggregateGate.
westackN parallelVEmodulesforN −1layers,corre-
p b
spondingtomultiplecompositions(Bπ)◦(Nb−1)(·)inhigh-
4.1.ValueExplorationModules
wayVI.ThesestackedandparallelVEmodulesprocessthe
inputV(n) ,leadingtonewactivations{V(n+nb) } for ThevalueiterationmoduleinVINsgreedilytakesthelargest
various indexes of the parallel modules nnp = 1,n ·p ·, ·nb ,N Qvalue,asshowninEq.(4). Consequently,thismechanism
p p
and various depths n = 1,··· ,N , where the initial canresultinadistinctiveinformationflowforeachlayer,
b b
(n+1) (n+1) thereby channeling gradients toward certain specific neu-
V =V foreachn .
np p rons. Tofacilitatetheinformationandgradientflowacross
Finally, the outputs from these parallel and stacked VE spatialdimensions,weintroduceanewVEmodule. Each
4HighwayValueIterationNetworks
(cid:16) (cid:17)
functionπ(n+nb) =fπ Q(n+nb) ,ϕ(s);W(n+nb) ,where
np np np
W(n+nb) are learnable parameters. Drawing inspiration
np
fromthedropouttechnique,whichintroducesstochasticity
intotheactivationstoincreaserobustness(Srivastavaetal.,
2014;Hanson,1990;Hertzetal.,1991;Baldi&Sadowski,
2013),werandomlygeneratemultipleembeddedpolicies
asfollows:
π(n+nb)
=(cid:40) 1, a=(cid:98)a∼P (cid:16) ·;Q( nn p+ ,·,n i,b j) ,ϵ(cid:17)
(8)
np,a,i,j
0, otherwise,
where ϵ is the embedded exploration rate, and (cid:98)a is
a sampled action drawn from the ϵ-greedy distribution
(cid:16) (cid:17)
P
·;Q(n+nb)
,ϵ ,definedas:
np,·,i,j
P
(cid:16) a;Q(n+nb) ,ϵ(cid:17) = 1−ϵ+ |Aϵ |, a=arg am
′
axQ( nn p+ ,an ′,b i) ,j
np,·,i,j
 ϵ , otherwise.
(a)ValueIterationModule (b)ValueExplorationModule |A|
Figure4: ArchitectureofthevalueiterationmoduleandVE Duringthetrainingphase,theembeddedpoliciesaregen-
module,respectively. Theoperationmax denotesa eratedrandomlyfor eachiteration. Incontrast, weadopt
A×1×1
maxoperationovertheactionaxis,asshowninEq.(4). The greedypoliciesduringtheevaluationphase,wheretrained
operationlinear representsalinearcombinationof models are applied in realistic environments, defined as
A×1×1
theinputQmatrixQ andthepolicymatrixπ overthe follows:
np np
actionaxis,asshowninEq.(7). (cid:40)
1, a=argmax
Q(n+nb)
π(n+nb) = a′ np,a′,i,j
np,a,i,j
0, otherwise.
VE module is equipped with an embedded policy, which
This equation indicates that, during the evaluation phase,
determinesthepathoftheinformationflow.TheVEmodule
VEmodulesfunctioninthesamewayasVImodules. In
computesvaluesaccordingtoBellmanexpectationoperator
practice,weobservethatincorporatingthisstochasticmech-
Bπ(·)inhighwayVI:
anismsubstantiallyimprovesrobustnessandisessentialfor
achievinghighperformance. Moreover,thisstochasticity
doesnotimpacttheconvergencetotheoptimalvaluefunc-
Q( πn ,a+ ,n i,b j)= (cid:88)(cid:16) T a,i′,j′R i−i′,j−j′+T a,i′,j′V( πn ,i+ −n ib ′,− j−1) j′(cid:17) (6) tion. AsstatedbythetheoryofhighwayVIinRemark1,
i′,j′
convergenceisguaranteedirrespectiveofanychosenem-
beddedpolicies,eveniftheyarefullystochastic.
V(n+nb) =(cid:88) π(n+nb)Q(n+nb)
(7)
np,i,j np,a,i,j np,a,i,j
4.2.AggregateandFilterGates
a
whereπ(n+nb) ∈ R|A|×m×m representsthen -thembed- Weaimtointegratetheprovenefficacyofskipconnections
np p
dedpolicyfor(n+n )-thlayer. Here,thevaluefunctions intrainingverydeepNNs(Srivastavaetal.,2015b;Heetal.,
b
aredenotedasV andQtodistinguishthemfromthevalue 2016). However,theoreticallyvalidatingthisarchitecture
functionsV andQoftheVImodule. AsimpliedbyEq.(7), within the RL framework and ensuring its compatibility
insteadoftakingmaximizationovertheactionsasintheVI with the stochasticity in the VE modules are challenging.
module(seeEq. 4),theproposedVEmoduletakesexpecta- The highway VI algorithm offers a guiding principle for
tionoveractionsbasedonthedistributionoftheembedded this design. By implementing the smaxα(cid:101)smaxαmax{·}
π n
policyπ . ThecomputationprocessoftheVEmoduleis operationsofhighwayVI,theactivationsareaggregatedas
np
showninFig.4(b). follows:
Notethat,asstatedinRemark1,convergenceinhighway V′( nn p+ ,in ,jb)
V ThI ei ss ea ps osu lir ce id esr ce og ra rr ed sl pe os ns dof toth ee mc bh eo ds de en dl po oo lk ica ih ee sa wd ip tho il nic si ee vs -.
V( i,n j+Nb)=
(cid:88)Np
A(cid:101)( nn p+ ,iN ,jb)
(cid:88)Nb
A( nn p+ ,in
,jb)(cid:122) max(cid:26)
V( nn p+ ,in
,(cid:125) jb(cid:124)
) ,V( i,n
j+1)(cid:27)(cid:123)
.
eral VE modules of highway VINs. Generally, the em- np=1 nb=1
(cid:124) (cid:123)(cid:122) (cid:125)
beddedpolicycanbegeneratedusingalearnablemapping V′′( nn p+ ,iN ,jb)
5HighwayValueIterationNetworks
Here, A(cid:101)(n+Nb) and A(n+nb) are termed as the aggregate VINs,ithasnotshowneffectivenessinimprovinglong-term
np,i,j np,i,j
gate,reflectingthedegreetowhichactivationscontribute planningcapabilities(Table1inSection5). HighwayVINs
totheoutput,similartotheconceptinhighwaynetworks includetwoadditionalcriticalcomponents: aVEmodule
(Srivastavaetal.,2015b;a). Theaforementionedequation thatimprovesthediversityofinformationandgradientflow,
illustratestheaggregationofactivationsfromvariouslayers andaninnovativefiltergatedesignedtoeliminateuseless
(cid:110) (cid:111)
acrossmultipleparallelVEmodules,i.e.,
V(n+nb)
,
informationgeneratedbytheVEmodules. Thisstudyalso
np
np,nb reveals the underlying connections between the highway
forn =1,··· ,N andn =1,··· ,N . Fig.3illustrates
p p b b RLandhighwaynetworks,whichwereinitiallyproposed
theinformationflowofthiscomputationprocess.Aggregate
underdifferentcontextsandpurposesbutsharefundamental
gatescanbegenerallygeneratedusingmappingfunctionsas
similarities.
follows: A(n+nb) = fA(cid:18)(cid:110) V(n+n′ b)(cid:111) ,ϕ(s);U(n+nb)(cid:19) .
np np
n′
np
b 5.Experiments
Here,U(n+nb)arelearnableparameters. Forsimplicityand
np
consistencywithhighwayVI,weusesoftmaxweightsin Weconductaseriesofexperimentstoevaluatehowhighway
thefollowingform: VINs can improve the long-term planning capabilities of
(cid:18) (cid:19) VINsforcomplextasks. Wealsoexplorethesignificance
exp α
V′′(n+Nb)
ofeachcomponentwithinthehighwayVINs.
A(cid:101)( nn p+ ,iN ,jb) =
(cid:80)
exp(cid:18)
αA(cid:101) Vn ′′p (, ni +,j
Nb)(cid:19),forvariousn p,
5.1.2DMazeNavigation
n′
A(cid:101) n′ p,i,j
p We evaluate the algorithms on 2D maze navigation tasks
(cid:18) (cid:19)
exp α V′(n+nb) of various sizes m × m, specifically 15 × 15 and 25 ×
A(n+nb) =
A np,i,j
,forvariousn , 25. In these tasks, the agent can move forward, turn 90
np,i,j (cid:80) exp(cid:18)
α
V′(n+n′ b)(cid:19) b degreesleftorright,andhasfourorientations. Wefollow
A np,i,j the experimental setup described in the paper on GPPN
n′
b (Leeetal.,2018). Wetrainthemodelsfor30epochsusing
whereα
A(cid:101)
andα Aarethesoftmaxtemperaturesthatvaryfor imitationlearningonalabeledtrainingdataset,selectthe
eachhighwayblockandlearnableviabackpropagation. best model based on validation dataset performance, and
test it on a separate test dataset. Each dataset contains
Themaximizationoperationmax{·},whichwetermfilter
gate, compares the (n + n )-th activation
V(n+nb)
with
numerousplanningtasks,eachinvolvingamazewithastart
b np position,animageofthem×mmap,andagoalposition
(n+1)
the(n+1)-thoneV ,selectingthemaximumvalue. representedbya4×m×mmatrix(where4correspondsto
This filter gate is essential for discarding any activations thefourorientations).Thesedatasetsinvolvetasksrequiring
V(n+nb) that are lower than V(n+1) , effectively filtering planning over hundreds of steps to reach the goal. For
oun tp explorations in VE modules that do not contribute to moredetailedinformationaboutthedataset,pleasereferto
convergence. Furthermore,assuggestedinRemark2,this AppendixA.
operationiscrucialforensuringconvergence.
Wemeasuretheplanningabilitiesofanagentbasedonthe
successrate(SR),whichisdefinedastheratioofthenumber
4.3.RelationtoHighwayNetworks ofsuccessfullycompletedtaskstothetotalnumberofplan-
ningtasks. Theagentisconsideredtosucceedinataskifit
Section 4.2 and Fig. 3 illustrate the planning module of
generatesapathfromthestartpositiontothegoalposition
highwayVIN,whichfeaturesanarchitecturewithskipcon-
within a limited number of steps. To assess the planning
nections similar to those found in established NNs such
abilityofthealgorithmsacrossdifferentscales,weevaluate
ashighwaynetworks(Srivastavaetal.,2015b;a)andtheir
themonnavigationtaskswithvaryingshortestpathlengths
variantsresidualnetworks(Heetal.,2016)andDenseNets
(SPLs)fromstarttogoal. Theselengthsarecalculatedinad-
(Huangetal.,2017). Astraightforwardapproachistodi-
vanceusingDijkstra’salgorithmwithaccesstothemaze’s
rectlyimplementskipconnectionsinVINsasfollows:
underlyingstructure. TaskswithlongerSPLstypicallyde-
V(n+Nb)
=
(cid:88)Nb
A(n+nb)V(n+nb)
. (9)
m thean Gd Pg Pr Nea pte ar pelo r’n sg s- ete ttr im ng,p ela vn an luin atg inc gap eaa cb hili at li ge os. ritW hmef wo il tl how
3
i,j i,j i,j
nb=1 randomseeds. Wereportthemeanandstandarddeviation
onthetestdataset.
Here,V(n+nb)
isderivedfromtheVImodule(Eqs. 3and
i,j
Subsequently,wecomparethehighwayVINsagainstsev-
4),usingV(n+nb−1)
astheinput. Whilethismethodhelps
i,j eraladvancedNNsforplanningtasks. Thebaselinemodel
to address optimization challenges in training very deep
6HighwayValueIterationNetworks
Table1: Thesuccessratesforeachalgorithmwithvariousdepthsunder2Dmazenavigationtaskswithdifferentrangesof
shortestpathlength. PleasealsorefertoAppendixTable4fortheresultsofalltheotherdepths.
MazeSize 15×15 25×25
ShortestPathLength [1,30] [30,60] [60,100] [1,60] [60,130] [130,230]
N=20 99.83±0.11 96.48±0.58 63.03±3.20 N=30 98.84±0.16 49.25±4.16 2.96±0.66
VIN N=40 99.79±0.10 95.84±0.69 76.16±1.87 N=60 96.47±1.33 48.26±4.21 7.87±3.54
(Tamaretal.,2016) N=100 0.80±0.03 0.00±0.00 0.00±0.00 N=150 0.22±0.08 0.00±0.00 0.00±0.00
N=200 0.56±0.00 0.00±0.00 0.00±0.00 N=300 0.24±0.00 0.00±0.00 0.00±0.00
N=20 99.98±0.01 92.68±1.07 51.12±5.00 N=30 98.98±0.25 25.98±5.78 2.76±1.68
GPPN N=40 99.99±0.01 96.16±3.56 65.17±12.4 N=60 99.09±0.19 28.87±1.47 1.32±0.55
(Leeetal.,2018) N=100 99.95±0.05 93.34±4.16 60.57±13.6 N=150 98.51±0.31 21.62±3.50 0.73±0.68
N=200 99.98±0.01 92.79±1.28 50.88±3.59 N=300 95.38±2.01 6.29±4.35 0.02±0.03
N=40 99.65±0.17 96.04±0.63 75.86±10.0 N=60 97.93±0.56 62.95±8.79 17.46±5.45
Highwaynetwork
N=100 99.36±0.32 91.11±2.64 60.32±8.87 N=150 85.42±4.20 12.55±3.89 0.35±0.23
(Srivastavaetal.,2015b)
N=200 0.73±0.12 0.00±0.00 0.00±0.00 N=300 0.24±0.00 0.00±0.00 0.00±0.00
N=40 99.77±0.09 98.83±0.25 90.00±2.12 N=60 97.87±0.60 77.02±6.30 20.68±9.89
HighwayVIN
N=100 99.93±0.03 99.52±0.12 98.61±0.66 N=150 97.77±0.48 89.56±0.95 75.42±10.1
(ours)
N=200 99.94±0.01 99.13±0.12 98.20±1.75 N=300 98.73±0.50 92.28±3.50 90.06±3.13
istheoriginalVIN(Tamaretal.,2016). Wealsocompare 15×15 Maze 25×25 Maze
1.0 1.0
highway VINs against GPPNs (Lee et al., 2018), which
0.8 0.8
improvethetrainingstabilityofVINsusinggatedrecurrent
0.6 0.6 operatorssuchasLSTMupdatesandthehighwaynetworks
0.4 Highway VIN (ours) 0.4
(Srivastavaetal.,2015b),whichincorporateskipconnec- VIN
0.2 Highway Net 0.2
tionsfortrainingofverydeepNNs(adaptedhereforVINs, GPPN
0.0
Section4.3). Wefollowthehyperparametersettingslisted 0.0 0 50 100 0 100 200
Shortest Path Length Shortest Path Length
inthepaperonGPPNs(Leeetal.,2018). Toensureafair
comparison,wesetthenumberofparallelVEmodulesof Figure5: Successratesofthealgorithmsarepresentedasa
highway VINs to N = 1 unless stated otherwise. The functionofvaryingshortestpathlength. Foreachalgorithm,
p
embeddedexplorationrateissettoϵ=1(definedinEq. 8). theoptimalresultfromarangeofdepthsisselected. Fora
Notethatthissettingdoesnotresultinasub-optimalsolu- comprehensiveviewoftheresultsacrossalldepths,please
tionofthelatentvaluefunctionduetothefiltergate,which seeFig.9intheAppendix.
excludesactionsdetrimentaltoconvergence. Thebaseline
usesa20-layerVINandGPPNforthe15×15Maze,and
a30-layerVINandGPPNforthe25×25Maze. Forboth
highway networks and highway VINs, we set N = 20
B
highwayblocksforthe15×15mazeandN =30forthe
B
25×25maze.WesetvarioushighwayblockdepthsN ≥2,
b
whichyieldsvarioustotaldepths: N = N ∗N ,specifi-
b B
callyN ∈{40,60,80,120,160,200}forthe15×15maze (a)25×25Maze (b)VIN (c)HighwayVIN
andN ∈{60,90,120,150,180,240,300}forthe25×25
Figure 6: (a) An example of 25×25 Maze. (b) and (c)
maze. ThebaselinesVINandGPPNarealsotestedusing
learnedfeaturemapsofVINandhighwayVIN,respectively.
thesamedepths.
PeformancewiththeBestNNDepth. Fig.5showsthe
200inthe25×25Maze.
SRsofvariousalgorithmsundertaskswithdifferentSPLs.
Toensureafaircomparison,weselectthebestresultsfrom Additionally,Fig.6showsthefeaturemapoftheVINand
varying NN depths for each algorithm as each algorithm highwayVIN,whichcanconceptuallybeunderstoodasthe
mayperformoptimallyatdifferentdepths(pleasereferto learnedvaluefunction. Thefigurerevealsthatthelearned
Fig.9inAppendixforacomprehensiveviewoftheresults valuesofhighwayVINforstatesdistantfromthegoalare
acrossalldepths). TheresultsdemonstratethattheSRsfor largerthanthoseofVIN,implyingthathighwayVINlearns
allcomparedmethodsconsiderablydecreasewithincreasing aneffectivevaluefunctionforlong-termplanning.
SPLs.Remarkably,whentheSPLexceeds200inthe25×25
Maze,theSRsofallmethodsnearlydropto0%.Incontrast, Peformance with Various Depths. Table 1 shows the
highwayVINmaintainsanimpressive98%SRwithanSPL SRsofeachalgorithmacrossvariousdepthsandtaskswith
of100inthe15×15Mazeand90%SRwithanSPLof differentSPLranges(seeTable4intheAppendixforresults
7
etaR
sseccuS
etaR
sseccuSHighwayValueIterationNetworks
acrossalldepths). ThetableshowsthatthehighwayVINs 15×15 Maze 25×25 Maze
1.0 1.0
generallyperformbetterwithincreaseddepth. Notably,we
0.8 0.8
observe a +69.38% improvement in the SR of the 25×
0.6 0.6 25 maze with an SPL range of [130,230] as the depth N
0.4 0.4
increasesfrom60to300.
0.2 w/ filter gate 0.2
w/o filter gate
The performance of the VIN decreases with increasing 0.0
0.0
0 50 100 0 100 200
depth. Specifically, the SR of VINs drops to nearly 0% Shortest Path Length Shortest Path Length
foralltasksatadepthofN >150. Thehighwaynetwork,
Figure7: SuccessratesofhighwayVINwithandwithout
incontrast,maintainsitsperformanceevenatgreaterdepths.
thefiltergate.
However, an increase in depth does not considerably im-
proveitslong-termplanningcapabilities. Wehypothesize
thatintegratingtheskipconnectionsofhighwaynetworks
theuseofdiverselatentactions,whichcouldfacilitatein-
intoVINsdoesnotintroduceadditionalarchitecturalinduc-
formationflowamongvariousneuronsintheNN.Table2
tivebiasbeneficialforplanning.
liststheentropyoftheselectedlatentactionsofVINand
TheGPPNeffectivelymitigatesthechallengesoftraining highway VIN. For VIN, it always selects the action that
very deep models and performs robustly across various leadstothemaximumQvalue. Althoughtheselectedlatent
depths. Inparticular,theGPPNexcelsintaskswithshort actionsgenerallyvaryforeachlayerbecausetheQvalues
SPLs,achievinga99.09%SRona25×25mazewithan dynamically change for each layer, they will converge to
SPLrangeof[1,30]. However, theGPPNdoesnotshow thesameactionswhentheQvaluesconverge. Therefore,
anotableimprovementinlong-termplanningcapabilities thediversityoftheselectedactionsforVINismuchmore
withanincreaseddepth. Forinstance,theSRoftheGPPN limited. Instead,intheproposedhighwayVIN,weemploy
dropstolessthan3%ona25×25mazewithanSPLrange thevalueexplorationmoduletomaintaindiversity.
of[130,230]. ThismightbebecausetheGPPN,asablack
box method with less inductive bias towards planning, is 15×15 Maze 25×25 Maze
1.0 1.0
more suited to learning patterns for short-term planning 0.8 0.8
tasksratherthanthoserequiringlong-termplanningskills.
0.6 0.6
0.4 0.4
5.2.AblationStudy 0.2 w/ VE modules 0.2
w/o VE modules
0.0
Severalablationstudieswereconductedtoevaluate: 1)the 0.0 0 50 100 0 100 200
Shortest Path Length Shortest Path Length
effectivenessofthefiltergate(Section4.2);2)theimpactof
theVEmodule(Section4.1). Wealsoevaluatetheinfluence Figure8: SuccessratesofhighwayVINwithandwithout
ofthenumberofparallelVEmodulesinAppendixB.2. In theVEmodules,
thehighwayVINexperiments,thedefaulthyperparameters
include an exploration rate ϵ of 1, a single parallel VE
module(N =1),anddepthconfigurationsof200forthe
p Table 2: The entropy of the selected latent actions of
15×15mazesand300forthe25×25mazes.
VINandhighwayVINwithvariousdepths. Theentropy
(cid:80)
is computed by [−p(a)logp(a)], where p(a) =
a∈A
FilterGate. TheSRsofhighwayVINs,withandwithout cnt(a) and cnt(a) is the number of selected latent
thefiltergate,areshowninFig.7. Theperformancecon- (cid:80) a∈Acnt(a)
actionsequalstoaoverthelatentactionsacrossallhidden
siderablydecreaseswhenthefiltergateisabsent. Thisis
layers.
because,withoutafiltergate,highwayVINscouldeasily
MazeSize 15×15 25×25
suffer the adverse effects of exploration in VE modules,
Depth 40 100 200 60 150 300
whichcouldpreventconvergence.
VIN 0.51 0.14 0.00 0.63 0.07 0.00
HighwayVIN(ours) 2.04 3.53 4.17 2.27 3.77 4.35
VEModules. WealsoevaluateavariantofhighwayVIN
without the VE module (referred to as w/o VE modules),
5.3.3DViZDoomNavigation
whichmeansthatallVEmodulesarereplacedwithVImod-
ules. Fig.8showstheSRsforthevariantswithandwithout Weevaluatetheproposedapproachin3DViZDoomenviron-
the VE module. Without VE modules, the performance ments(Wydmuchetal.,2019). Followingtheexperimental
ofhighwayVINsnotablydiminishesinthe25×25maze. settingoftheGPPNpaper(Leeetal.,2018),theinputtothe
Incomparison,thevariantequippedwiththeVEmodules model consists of RGB images capturing the first-person
performsmuchbetter. Thisimprovementislikelydueto view, ratherthanthetop-down2Dmaze. Basedonthese
8
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuSHighwayValueIterationNetworks
observations,aCNNisemployedtopredictthemazemap, Acknowledgement
whichistheninputtedintotheplanningmodel(suchasVIN
WesincerelythanktheauthorsoftheGPPNpaper(Leeetal.,
orhighwayVIN),usinganarchitectureandhyperparame-
2018) for providing experimental details and Prof. Chao
ters similar to the 2D maze setup. We select the optimal
Huang for his valuable suggestions. This work was sup-
depthfromN =40,100,200foreachalgorithm. Highway
portedbytheEuropeanResearchCouncil(ERC,Advanced
VINperformsoptimallyatdepth100,whileothermethods
Grant Number 742870) and the Swiss National Science
performbestatdepth40. Table3showstheSRsin15×15
Foundation(SNF,GrantNumber200021192356).
3DViZDoommazenavigation. OurhighwayVINsexcelin
taskswithSPLsexceeding30.
ImpactStatement
Thispaperintroducesresearchaimedatadvancingthefield
ofmachinelearning. Whileacknowledgingnumerouspo-
Table3:Successratesofeachalgorithmwithvariousdepths
tentialsocietalconsequences,webelievethatnoneneedto
under3DViZDoommazenavigationtaskswithdifferent
bespecificallyemphasizedhere.
rangesofSPLs.
[1,30] [30,60] [60,100]
References
VIN 98.57±1.54 92.03±2.03 69.37±2.63
GPPN 99.91±0.10 89.95±9.21 44.42±8.14 Agarwal,A.,Jiang,N.,Kakade,S.M.,andSun,W. Rein-
Highwaynetwork 97.82±1.01 91.99±2.54 63.78±11.49
forcement learning: Theory and algorithms. CS Dept.,
HighwayVIN(ours) 99.43±0.18 98.70±0.38 96.98±1.20
UWSeattle,Seattle,WA,USA,Tech.Rep,32,2019.
Baldi,P.andSadowski,P.J. Understandingdropout. Ad-
vances in neural information processing systems, 26,
5.4.ComputationalComplexity 2013.
Theproposedapproachintroducesaminimalnumberofad- Bellman,R. Dynamicprogramming. Science,153(3731):
ditionalparameterstotheexistingVINarchitecture,specifi- 34–37,1966.
callythesoftmaxtemperaturesforeachhighwayblockde-
Ciresan,D.C.,Meier,U.,Gambardella,L.M.,andSchmid-
notedas{(α A( (cid:101)nB),α A(nB))}N nBB =1.NotethatN Bindicatesthe huber,J.Deepbigsimpleneuralnetsforhandwrittendigit
totalnumberofhighwayblocks,whicharesettoN B =20 recogntion. Neural Computation, 22(12):3207–3220,
forthe15×15mazeandN B = 30forthe25×25maze. 2010.
Additionally,thefollowingtabledetailstheGPUmemory
consumptionandtrainingdurationforeachmethodwhen Ciresan,D.C., Meier, U.,Masci,J.,Gambardella, L.M.,
employing300layersonNVIDIAA100GPUs. and Schmidhuber, J. Flexible, high performance con-
volutionalneuralnetworksforimageclassification. In
VIN GPPN Highwaynetwork HighwayVIN(ours)
Intl.JointConferenceonArtificialIntelligenceIJCAI,pp.
GPUMemory 3.1G 103.0G 3.3G 15.0G
TrainingTime 7.5hours 6.5hours 7.7hours 9.0hours 1237–1242,2011.
Ciresan, D. C., Meier, U., Masci, J., and Schmidhuber,
6.Conclusions
J. Multi-column deep neural network for traffic sign
Thispaperpresentsageneralframeworkbasedonhighway classification. NeuralNetworks,32:333–338,2012.
RLtoimprovethelong-termplanningabilityofVINs. We
Gers,F.A.,Schmidhuber,J.,andCummins,F. Learningto
improvetraditionalVINsbyincorporatingthreekeycompo-
forget: ContinualpredictionwithLSTM. NeuralCompu-
nents:anaggregategate,whichestablishesskipconnections
tation,12(10):2451–2471,2000.
andfacilitateslong-termcreditassignment;anexploration
module,craftedtodiversifyinformationandgradientflow Hanson,S.J. Astochasticversionofthedeltarule. Physica
between neurons; and a filter gate, designed to eliminate D:NonlinearPhenomena,42(1):265–272,1990.
non-essential information. Our experiments demonstrate
He,K.,Zhang,X.,Ren,S.,andSun,J. Deepresiduallearn-
thathighwayVINsenablelong-termplanningbytraining
ingforimagerecognition. InProceedingsoftheIEEE
neuralnetworkswithhundredsoflayers,surpassingtheper-
conferenceoncomputervisionandpatternrecognition,
formanceofseveraladvancedmethods. Futureresearchwill
pp.770–778,2016.
investigatetheintegrationofmultipleparallelVEmodules
withvarioustypesofembeddedpoliciestoimproveperfor- Hertz,J.,Krogh,A.,andPalmer,R. IntroductiontotheThe-
mance. Additionally,futureworkwillfocusonscalingup oryofNeuralComputation. Addison-Wesley,Redwood
tolargertasks. City,1991.
9HighwayValueIterationNetworks
Hochreiter,S. Untersuchungenzudynamischenneuronalen Schmidhuber, J. Learning complex, extended sequences
Netzen.Diplomathesis,Institutfu¨rInformatik,Lehrstuhl usingtheprincipleofhistorycompression. NeuralCom-
Prof.Brauer,TechnischeUniversita¨tMu¨nchen,1991. Ad- putation,4(2):234–242,1992.
visor: J.Schmidhuber.
Shen,J.,Zhuo,H.H.,Xu,J.,Zhong,B.,andPan,S.Transfer
Hochreiter,S.andSchmidhuber,J. LongShort-TermMem- valueiterationnetworks.InProceedingsoftheAAAICon-
ory. NeuralComputation,9(8):1735–1780,1997. ferenceonArtificialIntelligence,volume34,pp.5676–
5683,2020.
Huang,G.,Liu,Z.,VanDerMaaten,L.,andWeinberger,
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I.,
K. Q. Densely connected convolutional networks. In
andSalakhutdinov,R. Dropout: asimplewaytoprevent
ProceedingsoftheIEEEconferenceoncomputervision
neuralnetworksfromoverfitting. Thejournalofmachine
andpatternrecognition,pp.4700–4708,2017.
learningresearch,15(1):1929–1958,2014.
Ivakhnenko,A.G.andLapa,V.G. CyberneticPredicting
Srivastava,R.K.,Greff,K.,andSchmidhuber,J. Highway
Devices. CCMInformationCorporation,1965.
networks. arXivpreprintarXiv:1505.00387,2015a.
Jin, X., Lan, W., Wang, T., and Yu, P. Value iteration Srivastava,R.K.,Greff,K.,andSchmidhuber,J. Training
networkswithdoubleestimatorforplanetaryroverpath very deep networks. Advances in neural information
planning. Sensors,21(24):8418,2021. processingsystems,28,2015b.
Lee,L.,Parisotto,E.,Chaplot,D.S.,Xing,E.,andSalakhut- Sutton,R.S.andBarto,A.G. Reinforcementlearning: An
dinov, R. Gated path planning networks. In Interna- introduction. MITpress,2018.
tionalConferenceonMachineLearning,pp.2947–2955.
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
PMLR,2018.
Anguelov,D.,Erhan,D.,Vanhoucke,V.,andRabinovich,
Li,G.,Muller,M.,Thabet,A.,andGhanem,B. Deepgcns: A. Going deeperwith convolutions. Technical Report
Can gcns go as deep as cnns? In Proceedings of the arXiv:1409.4842[cs.CV],Google,2014.
IEEE/CVFinternationalconferenceoncomputervision,
Tamar,A.,Wu,Y.,Thomas,G.,Levine,S.,andAbbeel,P.
pp.9267–9276,2019.
Valueiterationnetworks. Advancesinneuralinformation
processingsystems,29,2016.
Li, G., Mu¨ller, M., Ghanem, B., andKoltun, V. Training
graphneuralnetworkswith1000layers. InInternational
Telgarsky, M. Benefits of depth in neural networks. In
conferenceonmachinelearning,pp.6437–6449.PMLR,
Conferenceonlearningtheory,pp.1517–1539.PMLR,
2021a.
2016.
Li,W.,Yang,B.,Song,G.,andJiang,X. Dynamicvalue Wang,Y.,Strupl,M.,Faccio,F.,Wu,Q.,Liu,H.,Grudzien´,
iterationnetworksfortheplanningofrapidlychanging M.,Tan,X.,andSchmidhuber,J. Highwayreinforcement
uavswarms. FrontiersofInformationTechnology&Elec- learning. arXivpreprintarXiv:2405.18289,2024.
tronicEngineering,22(5):687–696,2021b.
Wo¨hlke,J.,Schmitt,F.,andvanHoof,H. Hierarchiesof
Pflueger,M.,Agha,A.,andSukhatme,G.S. Rover-irl: In- planningandreinforcementlearningforrobotnavigation.
versereinforcementlearningwithsoftvalueiterationnet- In2021IEEEInternationalConferenceonRoboticsand
worksforplanetaryroverpathplanning. IEEERobotics Automation(ICRA),pp.10682–10688.IEEE,2021.
andAutomationLetters,4(2):1387–1394,2019.
Wydmuch, M., Kempka, M., and Jas´kowski, W. ViZ-
DoomCompetitions: PlayingDoomfromPixels. IEEE
Puterman, M. L. Markov decision processes: discrete
Transactions on Games, 11(3):248–259, 2019. doi:
stochasticdynamicprogramming. JohnWiley&Sons,
10.1109/TG.2018.2877047.
2014.
Schleich, D., Klamt, T., and Behnke, S. Value iteration
networksonmultiplelevelsofabstraction. arXivpreprint
arXiv:1905.11068,2019.
Schmidhuber, J. Neural sequence chunkers. Technical
ReportFKI-148-91,Institutfu¨rInformatik,Technische
Universita¨tMu¨nchen,April1991.
10HighwayValueIterationNetworks
A.ExperimentalDetails
OurexperimentalsettingsfollowthoseoutlinedinthepaperonGPPN(Leeetal.,2018). Formazenavigationtasks,the
training,validation,andtestdatasetscomprise25K,5K,and5K mazes,respectively.
Allmodelsaretrainedfor30epochsusingtheRMSpropoptimizerwithalearningrateof0.001andabatchsizeof32. We
alsospecifyakernelsizeof5forconvolutionaloperationsintheplanningmodule,asmentionedinEq.(3). Fortheneural
networkthatmapstheobservationtothelatentMDP,wesetthehiddendimensionto150.
B.AdditionalExperimentalResults
B.1.VariousDepthsofHighwayVIN
Table4andFig.9showtheSRsofvariousalgorithmsacrossdifferentdepths. Foreachalgorithm,wealsoprovidetherate
atwhichitcanplantheoptimalpaththatyieldstheshortestpathlength,summarizedinTable5.
B.2.NumberofParallelVEModules
WeevaluatehighwayVINwithvaryingnumbersofparallelVEmodulesN undervaryingdepthsN. AsshowninFig.10,
p
underdifferentdepthsN,thenumberofparallelVEmoduleshasadifferenteffectontheperformanceofhighwayVIN.
Forexample,underdepthN =300,withfewerparallelVEmodules,i.e.,N =1,highwayVINperformsthebest. While
p
underdepthN = 100, withmoreVEmodules, N = 3, highwayVINperformsthebest. Theseresultsimplythatthe
p
additionalparallelVEmodulesmaybedetrimentaltotheperformanceofverydeepnetworks.
B.3.Examplesof2DMazeNavigation
InFig.11,weshowexampleswherehighwayVINsucceeds,butothermethodsfail.
11HighwayValueIterationNetworks
Table 4: Success rates of each algorithm with various depths under 2D maze navigation tasks with different ranges of
shortestpathlengths.
MazeSize 15×15 25×25
ShortestPathLength [1,30] [30,60] [60,100] [1,60] [60,130] [130,230]
N=20 99.83±0.11 96.48±0.58 63.03±3.20 N=30 98.84±0.16 49.25±4.16 2.96±0.66
N=40 99.79±0.10 95.84±0.69 76.16±1.87 N=60 96.47±1.33 48.26±4.21 7.87±3.54
N=60 99.83±0.03 92.53±1.33 66.18±6.91 N=90 0.21±0.08 0.00±0.00 0.00±0.00
VIN N=80 0.65±0.16 0.00±0.00 0.00±0.00 N=120 0.21±0.08 0.00±0.00 0.00±0.00
(Tamaretal.,2016) N=100 0.80±0.03 0.00±0.00 0.00±0.00 N=150 0.22±0.08 0.00±0.00 0.00±0.00
N=120 0.80±0.03 0.00±0.00 0.00±0.00 N=180 0.24±0.00 0.00±0.00 0.00±0.00
N=160 0.64±0.12 0.00±0.00 0.00±0.00 N=240 0.24±0.00 0.00±0.00 0.00±0.00
N=200 0.56±0.00 0.00±0.00 0.00±0.00 N=300 0.24±0.00 0.00±0.00 0.00±0.00
N=20 99.98±0.01 92.68±1.07 51.12±5.00 N=30 98.98±0.25 25.98±5.78 2.76±1.68
N=40 99.99±0.01 96.16±3.56 65.17±12.4 N=60 99.09±0.19 28.87±1.47 1.32±0.55
N=60 99.96±0.02 91.47±3.50 54.52±7.32 N=90 98.59±0.06 25.35±2.66 0.86±0.59
GPPN N=80 99.97±0.03 95.44±4.48 66.85±15.5 N=120 98.67±0.37 25.60±4.87 1.35±0.98
(Leeetal.,2018) N=100 99.95±0.05 93.34±4.16 60.57±13.6 N=150 98.51±0.31 21.62±3.50 0.73±0.68
N=120 99.99±0.01 95.57±3.27 66.99±15.2 N=180 90.49±8.62 7.40±8.56 0.41±0.58
N=160 99.96±0.01 95.51±3.13 66.74±12.8 N=240 93.98±2.48 8.64±5.21 0.15±0.11
N=200 99.98±0.01 92.79±1.28 50.88±3.59 N=300 95.38±2.01 6.29±4.35 0.02±0.03
N=40 99.65±0.17 96.04±0.63 75.86±10.0 N=60 97.93±0.56 62.95±8.79 17.46±5.45
N=60 99.69±0.11 94.31±0.55 64.94±5.61 N=90 94.59±1.51 49.91±11.8 13.98±5.86
N=80 99.70±0.05 93.50±1.15 62.22±5.87 N=120 93.65±0.81 38.79±2.68 4.05±0.61
Highwaynetwork
N=100 99.36±0.32 91.11±2.64 60.32±8.87 N=150 85.42±4.20 12.55±3.89 0.35±0.23
(Srivastavaetal.,2015b)
N=120 99.51±0.17 88.45±2.60 51.88±4.24 N=180 0.23±0.01 0.00±0.00 0.00±0.00
N=160 99.50±0.05 90.11±0.93 60.57±3.33 N=240 0.25±0.04 0.00±0.00 0.00±0.00
N=200 0.73±0.12 0.00±0.00 0.00±0.00 N=300 0.24±0.00 0.00±0.00 0.00±0.00
N=40 99.77±0.09 98.83±0.25 90.00±2.12 N=60 97.87±0.60 77.02±6.30 20.68±9.89
N=60 99.83±0.10 98.53±0.72 94.35±4.15 N=90 95.31±1.69 80.57±7.40 34.72±6.27
N=80 99.76±0.02 98.03±0.02 94.79±0.67 N=120 96.37±1.82 84.81±2.12 61.09±3.50
HighwayVIN
N=100 99.93±0.03 99.52±0.12 98.61±0.66 N=150 97.77±0.48 89.56±0.95 75.42±10.1
(ours)
N=120 99.88±0.04 98.62±0.35 96.72±1.76 N=180 95.99±1.75 85.18±2.28 75.40±4.05
N=160 99.86±0.04 98.81±0.24 96.76±1.02 N=240 97.64±1.49 90.12±3.68 82.40±8.95
N=200 99.94±0.01 99.13±0.12 98.20±1.75 N=300 98.73±0.50 92.28±3.50 90.06±3.13
12HighwayValueIterationNetworks
Table5: Optimalityratesofeachalgorithmwithvariousdepthsunder2Dmazenavigationtaskswithdifferentrangesof
shortestpathlengths. Theoptimalityrateisdefinedbytheratiooftaskscompletedwithinthestepsoftheshortestpath
lengthtothetotalnumberoftasks.
MazeSize 15×15 25×25
ShortestPathLength [1,30] [30,60] [60,100] [1,60] [60,130] [130,230]
N=20 99.15±0.20 90.50±0.59 53.31±2.28 N=30 93.94±0.33 38.32±3.64 2.25±0.35
N=40 98.54±0.13 86.71±0.56 69.49±2.77 N=60 88.64±2.81 33.74±3.27 6.16±2.38
N=60 98.29±0.23 81.58±2.57 61.12±6.42 N=90 0.20±0.09 0.00±0.00 0.00±0.00
VIN N=80 0.61±0.16 0.00±0.00 0.00±0.00 N=120 0.20±0.09 0.00±0.00 0.00±0.00
(Tamaretal.,2016) N=100 0.72±0.06 0.00±0.00 0.00±0.00 N=150 0.21±0.09 0.00±0.00 0.00±0.00
N=120 0.72±0.06 0.00±0.00 0.00±0.00 N=180 0.24±0.00 0.00±0.00 0.00±0.00
N=160 0.58±0.04 0.00±0.00 0.00±0.00 N=240 0.24±0.00 0.00±0.00 0.00±0.00
N=200 0.56±0.00 0.00±0.00 0.00±0.00 N=300 0.24±0.00 0.00±0.00 0.00±0.00
N=20 99.35±0.12 83.42±2.24 46.97±5.81 N=30 96.33±0.33 19.94±4.66 2.46±1.50
N=40 99.64±0.16 90.47±6.65 62.09±12.1 N=60 96.53±0.65 21.20±1.05 1.01±0.58
N=60 99.36±0.18 82.08±4.75 49.27±7.18 N=90 94.78±0.21 17.96±2.25 0.66±0.66
GPPN N=80 99.41±0.24 88.89±7.41 61.21±13.3 N=120 95.44±0.38 18.97±3.67 1.22±0.89
(Leeetal.,2018) N=100 99.27±0.27 84.47±5.51 55.82±12.6 N=150 95.05±0.66 15.52±2.88 0.70±0.65
N=120 99.48±0.12 88.22±4.97 64.14±14.6 N=180 82.70±11.6 5.40±6.49 0.40±0.56
N=160 99.26±0.19 85.70±3.63 60.75±11.1 N=240 87.76±3.64 5.82±3.55 0.12±0.08
N=200 99.38±0.08 84.65±2.02 47.10±3.90 N=300 88.50±4.61 4.10±2.93 0.02±0.03
N=40 98.98±0.12 89.37±0.73 71.27±9.95 N=60 92.57±1.68 46.95±6.95 13.72±4.40
N=60 98.85±0.06 85.92±0.31 59.57±6.76 N=90 85.25±3.39 35.28±9.05 10.88±4.04
N=80 98.62±0.19 83.36±0.17 56.04±4.09 N=120 83.27±0.19 26.71±2.02 2.48±0.57
Highwaynetwork
N=100 97.88±0.24 80.06±3.08 55.21±9.75 N=150 71.57±5.70 7.47±2.58 0.10±0.10
(Srivastavaetal.,2015b)
N=120 97.89±0.33 78.04±2.05 46.05±4.48 N=180 0.23±0.01 0.00±0.00 0.00±0.00
N=160 97.88±0.42 78.57±0.95 54.11±3.72 N=240 0.25±0.04 0.00±0.00 0.00±0.00
N=200 0.65±0.09 0.00±0.00 0.00±0.00 N=300 0.24±0.00 0.00±0.00 0.00±0.00
N=40 98.78±0.04 92.81±0.74 85.49±2.83 N=60 93.47±0.67 62.70±7.87 17.15±8.31
N=60 98.47±0.12 91.46±1.55 88.67±3.33 N=90 89.72±2.16 63.87±8.26 27.84±5.12
N=80 98.62±0.23 91.29±0.50 90.99±0.41 N=120 90.41±1.76 64.20±0.79 49.63±2.57
HighwayVIN
N=100 98.43±0.05 90.67±0.51 94.64±1.61 N=150 92.00±0.58 71.91±2.37 64.70±9.88
(ours)
N=120 98.37±0.16 90.24±1.31 93.16±3.63 N=180 90.65±1.93 66.42±1.83 66.25±2.94
N=160 98.30±0.11 89.15±1.30 92.00±0.44 N=240 91.32±2.24 70.78±4.28 71.09±8.04
N=200 98.26±0.10 89.33±0.92 92.76±2.08 N=300 93.36±1.85 73.35±4.15 81.08±2.87
15×15 Maze 25×25 Maze 15×15 Maze 25×25 Maze
1.0 N=20 1.0 N=30 1.0 1.0 N=60
0.8 N N= =4 60
0
0.8 N N= =6 90
0
0.8 N N= =4 60
0
0.8 N N= =9 10
20
0.6 N=80 0.6 N=120 0.6 N=80 0.6 N=150 0.4 N N= =1 10 20 0 0.4 N N= =1 15 80 0 0.4 N N= =1 10 20 0 0.4 N N= =1 28 40 0
0.2 N=160 0.2 N=240 0.2 N=160 0.2 N=300
N=200 N=300 N=200
0.0 0.0 0.0 0.0
0 50 100 0 100 200 0 50 100 0 100 200
Shortest Path Length Shortest Path Length Shortest Path Length Shortest Path Length
(a)VIN (b)Highwaynetwork
15×15 Maze 25×25 Maze 15×15 Maze 25×25 Maze
1.0 N=20 1.0 N=30 1.0 1.0
0.8 N=40 0.8 N=60 0.8 N=40 0.8 N=60
N=60 N=90 N=60 N=90
0.6 N=80 0.6 N=120 0.6 N=80 0.6 N=120
0.4 N N= =1 10 20 0 0.4 N N= =1 15 80 0 0.4 N N= =1 10 20 0 0.4 N N= =1 15 80 0
0.2 N=160 0.2 N=240 0.2 N=160 0.2 N=240
N=200
0.0
N=300 N=200
0.0
N=300
0.0 0.0
0 50 100 0 100 200 0 50 100 0 100 200
Shortest Path Length Shortest Path Length Shortest Path Length Shortest Path Length
(c)GPPN (d)HighwayVIN(our)
Figure9: Successratesofeachalgorithmasafunctionofvaryingshortestpathlengthson2Dmazenavigationtasks.
13
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuSHighwayValueIterationNetworks
15×15 Maze 25×25 Maze
1.0 1.0
0.8 0.8
0.6 0.6
Np=1
0.4 Np=3 0.4
0.2
Np=5
0.2
Np=10
0.0 0.0
0 50 100 0 100 200
Shortest Path Length Shortest Path Length
(a)DepthN =200 (b)DepthN =300
15×15 Maze 25×25 Maze
1.0 1.0
0.8 0.8
0.6 0.6
Np=1
0.4 Np=3 0.4
0.2
Np=5
0.2
Np=10
0.0 0.0
0 50 100 0 100 200
Shortest Path Length Shortest Path Length
(c)DepthN =100 (d)DepthN =150
Figure10: SuccessratesofhighwayVINswithvaryingnumbersofparallelVEmodulesN undervaryingdepthsN ofthe
p
network.
14
etaR
sseccuS
etaR
sseccuS
etaR
sseccuS
etaR
sseccuSHighwayValueIterationNetworks
(a)HighwayVIN (b)VIN (c)GPPN
(d)HighwayVIN (e)VIN (f)GPPN
Figure11: Examplesof2DmazenavigationtaskswherehighwayVINsucceeds,butothermethodsfail.
15