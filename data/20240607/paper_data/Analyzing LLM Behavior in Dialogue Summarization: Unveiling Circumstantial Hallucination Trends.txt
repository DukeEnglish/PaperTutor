Analyzing LLM Behavior in Dialogue Summarization:
Unveiling Circumstantial Hallucination Trends
SanjanaRamprasad♢ ElisaFerracane♣ ZacharyC.Lipton♣
♢NortheasternUniversity
♣ AbridgeAI
{ramprasad.sa}@northeastern.edu
{elisa,zack}@abridge.com
Abstract Dialogue Snippet
Greg: Hi, honey. I need to stay after hours :-(
Recentadvancementsinlargelanguagemod- Betsy: Again?
els (LLMs) have considerably advanced the Greg: I''m sorry!
Betsy: What about Johnny?
capabilitiesofsummarizationsystems. How-
Greg: Well, could you pick him up?
ever,theycontinuetofaceconcernsabouthal- Betsy: What if I can't?
lucination. While prior work has evaluated Greg: Betsy?
Betsy: What if I can't?
LLMsextensivelyinnewsdomains,mosteval- Greg: Can't you, really?
uationofdialoguesummarizationhasfocused Betsy: I can’t. Today I need to work long hours as well.
Tuesdays are your days in the kindergarten.
onBART-basedmodels,leavingagapinour
understandingoftheirfaithfulness. Ourwork Summary:
benchmarks the faithfulness of LLMs for di- GPT-4: Greg informs Betsy he needs to stay after work,
alogue summarization, using human annota- leading to a conflict as their son Johnny has to be picked up
from kindergarten, which usually falls on Greg's tionsandfocusingonidentifyingandcatego-
responsibility on Tuesdays. Betsy also can't do it as she's
rizingspan-levelinconsistencies. Specifically, working long hours.
wefocusontwoprominentLLMs: GPT-4and
Alpaca-13B.Ourevaluationrevealssubtleties Figure1: Intheexampleprovided, GPT-4infersthat
astowhatconstitutesahallucination: LLMs thespeakersarediscussing"theirson."Althoughthis
oftengenerateplausibleinferences,supported inferenceseemsplausiblegiventhecircumstantialevi-
bycircumstantialevidenceintheconversation, denceintheconversation,itlacksdirectevidence.
thatlackdirectevidence,apatternthatisless
prevalent in older models. We propose a re-
finedtaxonomyoferrors,coiningthecategory thatdonothavedirectevidenceinthesourcemate-
of"CircumstantialInference"tobucketthese rialpersists. Asaresult,evaluationofthesesum-
LLMbehaviors. Usingourtaxonomy,wecom- mariesisanactiveareaofresearch.
parethebehavioraldifferencesbetweenLLMs
In prior research, news articles have been the
andolderfine-tunedmodels. Additionally,we
maintestbedforLLM-generatedsummaryevalu-
systematicallyassesstheefficacyofautomatic
ation (Zhang et al., 2023; Yang et al., 2023). Di-
error detection methods on LLM summaries
aloguesummarizationremainlessexplored,with
andfindthattheystruggletodetectthesenu-
ancederrors. Toaddressthis,weintroducetwo priorworksmostlyfocusedonsmallerfine-tuned
prompt-based approaches for fine-grained er- models(Zhuetal.,2023;Gaoetal.,2023;Wang
rordetectionthatoutperformexistingmetrics, etal.,2022). Inthiswork,weclosetheevaluation
particularlyforidentifying"CircumstantialIn- gap,focusingouranalysisonLLMsummariesof
ference."1
chit-chat style dialogues. We obtain fine-grained
inconsistencyannotationsforsummariesgenerated
1 Introduction
(zero-shot)bytwoprominentLLMs(GPT-4(Luo
Considerable progress has been made in sum- etal.,2023)andAlpaca-13B(Taorietal.,2023))
marization using large language models (LLMs) andacrosstwosummarizationdatasets(SAMSum
(Goyaletal.,2022;Zhangetal.,2023). However, Gliwa et al. (2019) and DialogSum Chen et al.
thechallengeofso-called“hallucinations”,charac- (2021)).
terizedinthiscontextasstatementsinsummaries Inthedomainofdialogues,afurthergapexistsin
understandingthedifferencesbetweensummaries
1The dataset can be downloaded from https:
generatedbyLLMsandthosegeneratedbysmaller
//github.com/sanjanaramprasad/circumstantial_
inference.git fine-tunedmodels. Inthenewsdomain,priorwork
4202
nuJ
5
]LC.sc[
1v78430.6042:viXrahas found that LLM-generated summaries have particularly in identifying the newly introduced
fewer inconsistencies (Goyal et al., 2022; Zhang errortype,"CircumstantialInference."
etal.,2023). WorkdonebyTangetal.(2022),also
in the news domain, notes varying error distribu- In summary, our primary contributions are as
tionsacrossdifferentmodelcategories. Inourwork follows:
inthedialoguedomain,wecomparedifferencesin
errorratesandanalyzethecategoriesoferrorsfor 1. WebridgeagapinunderstandingLLMeffec-
summariesofdialogueswithfine-tunedmodelsver- tiveness for dialogue summarization by col-
sussummarieswithLLMs. Asinthenewsdomain, lecting fine-grained human annotations that
wefindthatLLM-generatedsummarieshavefewer highlightinconsistenciesandmakethebench-
inconsistencies. Surprisingly,ouranalysisreveals markpubliclyavailable.
thatover30%ofLLM-generatedsummariescon-
taininconsistencies,contrastingsharplywiththein- 2. Weproposearefinedtaxonomyforerrorcate-
consistencyrateoflessthan5%inGPT-generated gorizationofLLM-generatedsummaries,in-
newssummaries(Zhangetal.,2023). cludinganewerrorcategorycalled"Circum-
stantialInference"thatcapturesthetendency
To further elucidate the differences between
ofLLMstoproduceplausiblehallucinations
LLMs and fine-tuned models, we annotate spans
basedonconversationcontext.
with error categories. Previous work has primar-
ily relied on part-of-speech-based tags for error
3. We examine differences in behavior in dia-
classification(Wangetal.,2022;Zhuetal.,2023;
loguesummarizationbetweenLLMsandfine-
Gaoetal.,2023). However,complexitiesinherent
tuned models by comparing error rates and
inLLM-generatedsummaries,oftenlengthierand
types.
moreintricate,donotneatlyalignwitherrorcate-
goriesbasedsolelyonpartofspeech,warranting
4. Weintroducetwoprompt-basedmethodsfor
alternativestrategiesforamoremeaningfulcatego-
fine-grained error detection, which notably
rization. Hence, ourworkproposesarefinedtax-
outperformexistingmetrics. Thesemethods
onomyintegratingexistingerrortypes. Wefurther
excelevenindetectingtherecentlyidentified
introduceanewerrorcategoryspecifictoLLMbe-
error type "Circumstantial Inference." Addi-
havior: "CircumstantialInference."Thiscategory
tionally,weevaluatestate-of-the-arterrorde-
stemsfromtheobservationthatLLMsfrequently
tectorsonmodel-generatedsummariesacross
producestatementsthatappearplausiblebasedon
model categories and error types unveiling
circumstantial(butnotdirect)evidenceinthedia-
theireffectivenessandlimitations.
logues,anaspecthithertounexplored. Inparticular,
LLMstendtoproducestatementsthatmaybecir-
2 HumanEvaluation: Zero-shot
cumstantiallyimpliedbasedoncontextualcuesin
PromptedDialogueSummaries
theconversationbutnotexplicitlystatedasseenin
Figure1. Althoughtheseinferencesarenotdirectly Weaimtocomparethedifferenceinconsistencyof
statedandcanbeinherentlyunsupported,theycan zero-shotpromptedLLM-generateddialoguesum-
stillbeusefulinsomeinstances,especiallywhen maries with smaller fine-tuned model-generated
summarizingambiguousdialogues. However,the summaries.2 To accomplish this, we conduct hu-
appropriatenessofsuchinferreddetailsvariesde- manannotationstoidentifyinconsistentspansgen-
pending on context and domain, highlighting the erated by both GPT-4 (OpenAI et al., 2023) and
needforfurtherinvestigation. Alpaca-13b (Taori et al., 2023). Specifically, we
direct annotators to spot inconsistencies in sum-
In addition, there is limited understanding
maries,markedbyspansthatlackevidenceinthe
regardingtheautomaticdetectionofthementioned
sourcetextordistortinformationfromit. Oureval-
errortypes. Therefore,wesystematicallyevaluate
uation is carried out on dialogue summarization
theperformanceofstate-of-the-arterrordetectors
datasets previously used for benchmarking fine-
on LLM-generated dialogue summaries. We
tunedsummarizationmodels.
also introduce two prompt-based methods for
fine-grained error detection, which notably
2Wedeliberatelychoosezero-shotinsteadoffew-shotto
outperformallpriorstate-of-the-arterrordetectors, betterunderstandthemodel’sinherentcapabilities.Linguistic SummaryExcerpt DialogueExcerpt
Category
Circumstantial Cameronisunabletobringavideogamefor Peyton:Ihavebeenaskingyoutobringthatvideogame
Inference theirdaughterPeyton. forme
Cameron:Honey,Iamnothavingenoughtimetocome
home.
LogicalError Janeisworriedaboutthetraveltimeand Steven:theroadisnew,wewillmakeit
suggeststheymeetlater Jane:Idon’twanttostressout,let’smeetat4:30instead
of5,ok?
World #Person1#planstovoteforJoeBiden #Person1#:IwillvoteforBidenanyway.
Knowledge instead.
Referential #Person2#:Pleasecallmeorsende-mail.
Error Person1saidthatPerson2couldcalloremail
them.
Figurative AlyssalikesFergie’snationalanthem. Alyssa:HaveyouseenFergiesnationalanthem?
Misinterpre- Derek:Thisisnotnormal.Isawitlastweek
tation Alyssa:Thebestpartisthatsheactslikeshenailedit.
Table1: ExamplesoflinguisticcategoriesforinconsistenciesinredbetweentheLLM-generatedsummariesandthe
dialogues.
2.1 Datasets 2.2 Models
WeassesstheperformanceoftwoprevalentLarge
Weperformhumanannotationsontwoprominent Language Models (LLMs) in the context of dia-
summarization datasets: SAMSum (Gliwa et al., loguedialoguesummarization: (1)GPT-4(OpenAI
2019)andDialogSum(Chenetal.,2021). SAM- etal.,2023)utilizingthegpt-4-32k-0613snapshot,
Sumcomprisesartificiallygenerated,concisewrit- and(2)Alpaca-13b(Taorietal.,2023). Forboth
ten conversations crafted by linguists, centering models, we use the default settings and prompt
around everyday topics. Conversely, DialogSum zero-shotusingthefollowingtemplatetogenerate
presents a corpus of naturally occurring spoken summaries:
dialoguesreflectingreal-lifecontexts.
Tofacilitatecomparisonswithearlierfine-tuned Generate a summary of the following dia-
models, we annotate the same set of data points loguesnippet: {{Dialogue}}
frompreviousbenchmarkstudies,asoutlinedbe-
low: Our evaluation compares our collected annota-
tions against the inconsistency annotations from
a)ReferenceMatters(RefMatters): Introduced
previousbenchmarks. Specifically,weuseannota-
by Gao et al. 2023, this dataset offers factual an-
tionsforBART(Lewisetal.,2020),UniLM(Dong
notations for summaries generated on dialogues
et al., 2019), MV-BART (Chen and Yang, 2020),
inSAMSumandDialogSum. Theannotatedsum-
andCODS(Wuetal.,2021)fromtheRefMatters
mariesincludeoutputsfromfourfine-tunedsum-
Benchmark. Additionally,weconsiderannotations
marizationmodels,addressingeightdistincttypes
forBART(Lewisetal.,2020),MV-BART(Chen
offactualerrors: Entity,Predicate,Circumstance,
and Yang, 2020), CondigSum-BART (Liu et al.,
Coreference,DiscourseLink,OutofArticle,Gram-
2021a),andCoref-BART(Liuetal.,2021b)inthe
matical,andOthers.
FacEvaldataset.
b) FacEval Dataset: Detailed by Wang et al. Henceforth, we refer to the above models as
2022,thisdatasetprovidesannotationsforBART- FT-Summ, representing smaller fine-tuned sum-
basedmodelsappliedtotheSAMSumdataset. It marizationmodels,andthezero-shotprompt-based
delineatessixerrortypes,namelySubjectObject modelsGPT-4andAlpaca-13BasLLM.
Error, PronounError, NegationError, Particulars
2.3 Fine-grainedinconsistencyannotation
Error, Hallucination Error, and Other Error. No-
tably, there exists a small overlap in data points Weperformtworoundsofannotationstoidentify
withRefMatters. inconsistenciesindialoguesummaries.ErrorAnnotation contributions that are sufficiently but not overly
informative(Grice,1975). Speakersintentionally
In the first phase, we enlist two linguist fact-
checkersfromUpwork3 toassesssummaryconsis- omitinformationdeemedsharedknowledge. When
thelanguagemodeldrawsinferencesbasedoncir-
tency. Inconsistentsummarysectionsareidentified
cumstantialbutnotdirectevidenceintheconver-
asthosethatconflictwithorinaccuratelyrepresent
sation,welabelthisasacircumstantialinference
dialogue information or lack sufficient evidence.
error. While traditionally viewed as an inconsis-
Thisdefinitionalignswithcriteriafrompriorstud-
tency, we contend that in open-domain conversa-
ies on news summarization (Huang et al., 2020;
tions, such circumstantial inferences may be rea-
Maynezetal.,2020;GoyalandDurrett,2021;Cao
sonable. IntheexamplelistedinTable1,Cameron
etal.,2022). Inter-annotatoragreement,measured
addresses Peyton as "Honey" plausibly because
usingpairwiseF-1metric,resultsinasubstantial
theybothknowPeytonisCameron’sdaughter(and
agreementof66.94%. Furtherannotationinstruc-
explicitlystatingthatwouldviolatethemaximof
tionsaredetailedinAppendixA.
Quantity).
ErrorCategorization Theimportanceoftheseinconsistenciesdepends
In the second round of annotations, an author of onthecontext. Forexample,indoctor-patientcon-
the paper who is an expert linguist meticulously versations, inferring a patient has diabetes from
categorized the errors to attain more granularity. bloodsugardiscussionsismoreconsequentialthan
We find that traditional methods of error catego- inferringgeneralfamilialrelationships.
rizationthathavereliedheavilyonpart-of-speech WorldKnowledge: Thiserrortypeconstitutes
tags(Wangetal.,2022;Zhuetal.,2023;Gaoetal., adistinctsubsetofOut-of-ArticleErrors,wherein
2023)provelesseffectivewhendealingwithsum- the inaccuracies involve real-world facts. For in-
mariesgeneratedbyLLMsduetotheirtendencyto stance, thesummarymightincludethefullname
exhibit increased abstraction and inference. This of a public figure not explicitly mentioned in the
makes it challenging to align inconsistent spans dialogue(seeTable1).
withspecificpart-of-speech-basedcategories. Con- Referential Errors: This error resembles
sequently,weproposeataxonomyoferrorswhich subject-objecterrorsinpriorresearch(Wangetal.,
weoutlineinthesubsequentsection. 2022; Gao et al., 2023). However, LLMs show
intricatemisattributions,unlikeFT-Summmodels,
TaxonomyofErrors
where referential errors involve swapped entities.
We describe the taxonomy of errors identified in This complexity challenges previous straightfor-
thisworkbelowandprovideexamplesinTable1. wardcategorizations.
Logical Error: This category identifies inac- FigurativeMisrepresentationThiscategoryof
curaciesindialoguesummaries. Ourannotations erroroccurswhenmetaphors,sarcasm,orjokesin
highlight three main types of logical errors com- the content are mistaken for literal statements in
monlyfoundinsummariesgeneratedbyLLMs: a) summaries,alteringtheintendedmeaning.
Event misordering, where the summary presents Nonsensicalerrors: Weconsidergrammatical
anincorrectchronologicalsequenceduetowrong errorsinBART-generatedsummaries,aswellasin-
wordusageorsentenceorder. b)Lackofcommon- stanceswherelanguagemodelscontinueaprompt
sense, where models incorrectly reason through orrepeatinstructionsaftergeneratingasummary
informationthatshouldbeobvious. c)Missedde- asNonsensical.
tail,wherethesummarywouldbecorrectifnotfor
theomissionofimportantinformation. FT-Summ 2.4 EvaluationResults
modelsalsoexhibitlogicalerrorsinthiscategory,
ErrorRates
including inaccurate negations, wrong verbs, or
Figure2depictserrorratesforfine-tunedmodels
incorrectwordsenses.
(FT-Summ) and large language models (LLMs)
Circumstantial Inference: We introduce this
applied to dialogue summarization datasets. Our
new category not explored in prior work and in-
results indicate that GPT-4 exhibits fewer incon-
spiredbyGrice’sMaximofConversationforQuan-
sistenciesindialoguesummarizationcomparedto
tity, which states that cooperative speakers make
fine-tuned models. However, this improvement
3https://www.upwork.com/ issmallerthanobservedinpriorresearchonnews0.46 0.45 0.47 0.46
0.40 0.42
0.35
0.23
GPT-4 Alpaca-13B BART MV-BART Coref-BAR CT ondigSum-BART UniLM CODS
Figure 2: Each bar in this plot depicts the proportion of total summaries with inconsistencies across different
model-generatedsummarieswhereGPT-4performsthebest(lowermeansfewerinconsistencies).
0.5 GPT-4
Alpaca-13B
0.4 BART
0.3
0.2
0.1
0.0
Circumstantial
Inference
Logical
Error
World
Knowledge
Referential
Error
Figurative
Misinterpretation Nonsensical
Figure3: Errorcategoryproportionsforeachmodelinthedataset(lowervaluesindicatefeweroccurrencesof
specificcategories). ThemorechallengingcircumstantialinferenceerrorsarecommoninGPT-4buthardlypresent
inBART.
summarization,whereGPT-3achievedanerrorrate dencedbyitsperformanceacrossvariousdatasets
oflessthan5%(Zhangetal.,2023). Conversely,in (seeFigure2).
ourcaseapproximately23%ofGPT-4summaries One key discovery (shown in Figure 3) is the
acrossalldialoguedatasetsdisplayinconsistencies. prevalence of Circumstantial Inferences in LLM-
Furthermore,Alpaca-generatedsummariesgener- generatedsummaries. Roughly38%oferrorsfall
ally show lower inconsistency compared to most into this category, which describes cases where
fine-tunedmodels,butaresurpassedbyBART. assumptionsaremadebasedoncircumstantialevi-
Onfurtheranalysis(showninAppendixB),we dencewithintheconversation. Interestingly,these
findthatAlpacaoutperformsthefine-tunedmodels errorsarerareinBART-generatedsummaries,con-
(including BART) on the DialogSum benchmark stitutingonly1%ofallerrors.
(Gao et al., 2023), but the opposite is true on the We also observe several error categories with
SAMSum benchmarks (Gao et al., 2023; Wang lowerprevalenceinLLMscomparedtoFT-Summ.
etal.,2022). DifferencesinAlpaca-generatedsum- Notably,LLMsummariesconsistentlylackgram-
maryqualityacrossdatasetsmaystemfromvari- matical errors, presenting coherent and well-
ancesindialogueandsummaryfeatures,towhich written summaries. However, we note a simi-
largerlanguagemodelsmaybelesssensitive. Di- lar error type specific to LLMs—prompt errors.
alogSum uses real spoken dialogues with multi- WegroupbothLLM-basedprompterrorsandFT-
pleturns,potentiallyresemblingpre-trainingdata, Summ-basedgrammaticalerrorsas"Nonsensical"
whileSAMSuminvolvessyntheticwrittenconver- inFig3. Interestingly,GPT-4exhibitsnoinstances
sations. ofnonsensicaltext,whereasBARTshowsahigher
prevalenceofsuchcasescomparedtoAlpaca.
Fine-grainedErrorCategoryDistribution
Our analysis (shown in Fig 3) also uncovers a
Intheinvestigationoffine-grainedcategories,we considerablereductioninlogicalerrors,specifically
conduct annotations on summaries generated by 17%,inthecaseofLLMerrors,incontrasttoFT-
GPT-4andAlpaca-13bforLargeLanguageModel Summ,whereover50%oferrorsmanifestaslog-
(LLM)modelsandBARTwithintheframeworkof icalerrors. Thisnoticeabledecreasesignifiesthe
FT-Summ. WechooseBARTforannotationdueto superiorproficiencyofLLMsoverFT-Summmod-
itsconsistentsuperiorityinconsistencycompared elsinderivinglogicalinferencesfromdialogues.
tootherfine-tunedsummarizationmodels,asevi- Despiteadvancements,persistentchallengesin
srorrE
fo noitroporPspecificerrortypesremainprevalentwithinLLMs.
Inconsistency Detection (Binary)
Both FT-Summ and LLMs exhibit a similar fre-
quency of referential errors across all error cat- 0.8
egories. Notably, Alpaca-generated summaries
0.6
showahigherprevalenceofreferentialerrorscom-
0.4 QA
paredtoBART-generatedones,elucidatingtheele- NLI
0.2 Prompt
vatederrorrateinAlpacasummaries. Furtherex- Prompt-Span
Prompt-SpanMoE
aminationrevealstwodistincttypesofreferential 0.0
errors: coreference and misattributions. Corefer-
FT-Summ LLM
Model Type
ence errors arise from the inability to accurately
establishthereferenceofapronounornounwithin
Figure 4: Automatic error detectors exhibit varying
a sentence, whereas misattributions involve erro- performance when applied to FT-Summ versus LLM.
neouslyattributinginformationorstatementstothe WhileQA/NLImetricsindicateaslightimprovement,
wrongsource. Notably,inBARTsummaries,ref- prompt-basedmetricsarebetterindetectinginconsisten-
erentialerrorsmainlyconsistofcoreferenceerrors ciesgeneratedbytheFT-Summmodelincomparison
toLLMs.
(95%),withmisattributionsconstitutingonly5%.
Conversely, referential errors in LLMs are char-
acterizedbyahigherfrequencyofmisattributions
(58%)comparedtocoreferenceerrors(42%). thenonfactualspan).
3 AutomaticErrorDetection
3.1.1 BinaryClassification
Priorresearchhasdemonstratedashiftinerrorcat-
Binaryclassificationmetricsassesswhetherasum-
egorydistributionswhensummarizingwithmodels
maryisfaithfulornotbyprovidingasingleoverar-
ofdifferentgenerations,resultinginvariedtrends
chingscorerelativetothesource.
in the performance of automatic error detectors
(Tang et al., 2022). This section aims to address Weincorporatefourmetricsintoourevaluation
thefollowingkeyquestions: framework: two question-answering-based met-
a) Do factuality metrics perform similarly on rics,namelyQAFactEval(Fabbrietal.,2021)and
summariesgeneratedbyLargeLanguageModels QuestEval (Scialom et al., 2021), alongside two
(LLMs)comparedtooldermodels(inourstudy,FT- natural language inference (NLI) based metrics,
Summ)? Specifically, we investigate whether de- SummaC-ZS and SummaC-Conv (Laban et al.,
tectingfactualerrorsinLLM-generatedsummaries 2022),whichserveasourbaselinemeasures. Both
posesgreaterchallenges. question-answering(QA)andnaturallanguagein-
b)Whicherrortypesacrossvariousmodelcate- ference (NLI) metrics provide continuous scores
goriescanfactualitymetricsidentify,andwhatare for summarization. To translatethese scores into
theassociatedfailuremodes? Drawinguponour binaryfactualitylabels,weestablishthresholdsus-
errortaxonomy,weanalyzetheabilityofmetrics ingasubsetof10%oftheevaluationdata. Scores
todetectdifferenterrorcategories,withaspecific exceeding the designated threshold are classified
focusontheirperformanceinidentifyingcircum- asnonfactual. Distinctthresholdsaredetermined
stantialinferences,anaspectnotpreviouslyevalu- foreachmetricandmodeltypeacrossalldatasets.
ated. Furtherelaborationonthisprocesscanbefoundin
c)Furthermore,weintroduceanovelapproach AppendixC.
aimedatenhancingthedetectionofdifferenterror Recentstudieshavealsoinvestigatedtheeffec-
categoriesatthespan-levelwhichweintroducein tivenessofintegratingChatGPTpromptsinerror
section3.1.2. detection, demonstrating promising results com-
paredtoconventionalmetrics. Consequently, we
3.1 Metrics
includetheestablishedpromptChatGPT-Direct
To include a wider range of metrics, we assess Assessment(ChatGPT-DA)(Luoetal.,2023)and
metricperformanceinthefollowingtwospecific evaluateitsperformanceacrossbothzero-shotand
contexts: binaryclassification(labeltheentiresum- few-shot scenarios. The prompt is shown in Ap-
maryasfactualornot)andspandetection(identify pendixD.1.
ycaruccA
decnalaB0.8
0.6
0.4
QA
NLI
0.2 Prompt
Prompt-Span
Prompt-SpanMoE
0.0
Circumstantial Inference Logical Error World Knowledge Referential Error Figurative Misinterpretation
Figure5: Inconsistencybinaryclassificationpererrorcategory
0.8
QAFactSpan
ChatGPT-Span(ZS)
0.6 ChatGPT-Span(FS)
ChatGPT-SpanMoE(ZS)
ChatGPT-SpanMoE(FS)
0.4
0.2
0.0
Circumstantial Inference Logical Error World Knowledge Referential Error Figurative Misinterpretation
Figure6: SpanbasedF1scorespererrorcategory
3.1.2 SpanDetection Toenhancethepreviousstrategy,weintroducea
Baseline "mixtureofexperts"conceptforspanidentification
(a). Thismethodinvolvesusingdistinctpromptsfor
Spandetectioninvolvesthemeticulousidentifica-
eacherrortypeoutlinedinourtaxonomy(Section
tionofnonfactualorinconsistentspanswithinthe
2.3). Each error type has a unique prompt (see
summarywhencomparedtothesourcedocument.
AppendixD.3)giventoGPT,allowingittotarget
Asastandardbaseline,weintegrateQAFactEval
each error type. After experts identify all error
anddesignateallspanslabeled"unanswerable"by
types,spansundergoverification(step2)usingthe
themetricasinconsistent.
sameprocedureasbefore. Thisapproachiscalled
OurApproach ChatGPT-MoE.
In addition to the aforementioned baseline ap-
3.2 EvaluationSetup
proach, we introduce two new prompt-based
methodologies. These approaches are structured Metrics
aroundtwodistinctsubtasks. We use balanced accuracy as a metric for binary
a)Identification: Thispromptfocusessolelyon classification. Itcalculatesthearithmeticmeanof
extracting inconsistent spans based on provided sensitivityandspecificity,givingequalimportance
definitions. b)Verification: Inthisphase,sentences to minority and majority classes making it bene-
containing these nonfactual spans are compared ficial for imbalanced data. We use F-1 scores to
withthesourcetextusingaprompt,thatasksGPT comparepredictedspanswithannotatedones.
toprovideaconsistencyratingfrom1to5(detailed Forbinaryclassification,wealsoincludespan-
in Appendix D.2.2). Spans are classified as non- level automated metrics. We predict a summary
factualonlyiftheyreceivearatingbelow5during asconsistentifnoinconsistentspansarepredicted,
verification. Considering that summaries gener- and inconsistent if at least one is predicted. In
ated by LLMs tend to be more abstract and may prompt-basedfew-shotsetups,weuseafour-shot
involveinference,weaimtoavoidextractingspans approach,withtwoshotsindicatinginconsistency
as nonfactual that rely solely on common sense, andtwoindicatingconsistency.
evenifnotexplicitlysupportedbyevidence. Our
DatasetsandModels
objectiveistoidentifyspanswhereinformationis
either entirely fabricated or ambiguous based on Tocomparemetricsacrossbenchmarks,weutilize
thecontent. allannotatedFT-SummmodelsfromSection2.2to
Forourfirstapproach,weuseagenericprompt computebalancedaccuracy. It’simportanttonote
foridentification(AppendixD.2)followedbyver- thattheFacEvalbenchmarkdoesn’tinvolvespans
ification and call this approach ChatGPT-Span but focuses solely on error types. Therefore, our
. evaluation of span-level F1 scores on this bench-
ycaruccA
decnalaB
1FFT-Summ LLM
F1 Precision Recall F1 Precision Recall
QAFactEval 10.16 7.55 15.52 8.54 7.49 9.91
Prompt-based(OurApproaches)
ChatGPT-Span(ZS) 23.55 24.79 22.44 30.59 33.47 28.17
ChatGPT-Span(FS) 24.31 27.54 23.59 30.51 33.37 28.10
ChatGPT-MoE(ZS) 28.04 27.62 28.46 31.29 33.93 29.04
ChatGPT-MoE(FS) 29.04 27.90 30.27 33.22 35.60 31.14
Table2: F1-scoresforfine-grainederrordetectorsareshownforbothFT-SummandLLMmodels. TheChatGPT-
MoEpromptmetricexhibitssuperiorperformance,particularlyindetectingcircumstantialinferenceerrorswhich
leads to superior performance on LLMs compared to FT-Summ models. ZS and FS indicate Zero- Shot and
Few-Shotsettings,respectively
mark is restricted to our LLM span annotations. Metric FT-Summ LLM
Forassessingperformanceacrosserrorcategories,
QuestEval 47.54 49.47
weexclusivelyusesummariesgeneratedbyBART,
QAFactEval 45.00 39.84
referredtoasFT-Summ. Usingourtaxonomy,we
SummaC-ZS 43.29 49.70
classifyannotatedspansfrompreviousbenchmarks
SummaC-Conv 51.18 46.92
withinBARTsummaries,enablingustoevaluate
ChatGPT-DA(ZS) 73.00 60.34
performancemetricsonaper-categorybasis.
ChatGPT-DA(FS) 72.06 61.61
Wealsofindthatapproximately1%ofourdataset
containsnonsensicalerrors,includinggrammatical OurApproaches
andpromptinaccuracies. Sincetheseerrorsmainly
ChatGPT-Span(ZS) 73.48 63.89
affectcoherenceratherthanconsistency,wehave
ChatGPT-Span(FS) 72.18 64.84
chosentoexcludethissubsetfromouranalysis.
ChatGPT-SpanMoE(ZS) 73.77 67.96
ChatGPT-SpanMoE(FS) 75.61 70.27
3.3 Results
BinaryClassification Table3:Binaryaccuracyscorescomparingfactuallabel
We start by discussing binary inconsistency de- predictionsofdifferentmetricsagainsthumanannota-
tions. ChatGPT-SpanandChatGPT-SpanMoEoutper-
tection results. Table 3 presents balanced accu-
formChatGPT-DAandstandardmetrics,especiallyon
racyscoresforFT-SummandLLMmodels. Inter-
LLM-generatedsummaries. ZSandFSindicateZero-
estingly, prompt-based approaches, including di-
ShotandFew-Shotsettings,respectively.
rectassessmentandspan-basedmethods,perform
lesseffectivelyinidentifyingLLMerrorsthanFT-
Summ errors (Figure 4). Overall, prompt-based
methods outperform standard QA and NLI met-
ricsforbothmodeltypes,thoughtheimprovement
is less substantial for LLM models compared to for FT-Summ models, primarily enhancing pre-
FT-Summmodels. Wealsoshowpercategoryper- cision. Moreover, incorporating ChatGPT-MoE
formanceinFigure5. yields a further improvement of nearly 5 points
for FT-Summ and nearly 3 points for LLM sum-
SpanDetection
maries. Specifically,forFT-Summ,themostcon-
Table2showsspan-levelF1scores,comparingpre- siderable enhancement lies in span recall, while
dicted spans with annotated ones. Results reveal forLLMmodels,theMoEpromptmethodaffects
that QAFactEval struggles with detecting incon- both precision and recall. When examining span
sistentspans. Incontrast,ChatGPT-Spandemon- basedmetricspererror-category,weobservethat
stratesnotablysuperiorperformanceinbothZero- ChatGPT-MoEnotablyenhancesthedetectionof
Shot(ZS)andFew-Shotscenarios(FS).WithFew- CircumstantialInferenceErrorsasdepictedinFig-
Shot, it exhibits a 1-point increase in F1 scores ure6.4 Conclusion Yulong Chen, Yang Liu, Liang Chen, and Yue
Zhang. 2021. Dialogsum: A real-life scenario
In summary, our work is the first to comprehen- dialogue summarization dataset. arXiv preprint
sivelyassessLargeLanguageModel(LLM)perfor- arXiv:2105.06762.
manceindialoguesummarization,revealingcon-
Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-
siderableinconsistenciesthatunderscoretheongo- aodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,
ing challenges in this area. Our findings empha- andHsiao-WuenHon.2019. Unifiedlanguagemodel
pre-trainingfornaturallanguageunderstandingand
sizetheprevalenceofcircumstantialinferences,in
generation. Advancesinneuralinformationprocess-
summaries generated by GPT-4 and Alpaca-13b,
ingsystems,32.
indicating LLMs’ proficiency in language under-
standing but their tendency to introduce concep- Alexander R Fabbri, Chien-Sheng Wu, Wenhao Liu,
and Caiming Xiong. 2021. Qafacteval: Improved
tual inferences. Moreover, we demonstrate that
qa-basedfactualconsistencyevaluationforsumma-
existing metrics struggle to detect these nuanced
rization. arXivpreprintarXiv:2112.08542.
errorseffectively. Consequently,weadvocatefor
MingqiGao,XiaojunWan,JiaSu,ZhefengWang,and
performanceevaluationsonbenchmarksutilizing
BaoxingHuai.2023. Referencematters:Benchmark-
newermodelstobettercapturethecapabilitiesand
ingfactualerrorcorrectionfordialoguesummariza-
limitationsofautomaticmetrics, giventheevolv- tionwithfine-grainedevaluationframework. arXiv
ing error distributions and types of newer LLMs preprintarXiv:2306.05119.
comparedtoFT-Summmodels. Furthermore,our
BogdanGliwa,IwonaMochol,MaciejBiesek,andAlek-
incorporationoftwoprompt-basedmethodsshows sander Wawer. 2019. Samsum corpus: A human-
promisingprogressinidentifyingcircumstantialin- annotated dialogue dataset for abstractive summa-
ferenceerrors,althoughfurtherresearchisrequired rization. arXivpreprintarXiv:1911.12237.
toimproveperformance.
TanyaGoyalandGregDurrett.2021. Annotatingand
modeling fine-grained factuality in summarization.
5 LimitationsandEthics InProceedingsofthe2021ConferenceoftheNorth
AmericanChapteroftheAssociationforComputa-
This study has limitations that should be noted. tionalLinguistics: HumanLanguageTechnologies,
Firstly,theannotationprocessisresource-intensive pages1449–1462,Online.AssociationforComputa-
tionalLinguistics.
and time-consuming. Consequently, we only
benchmarkedandannotatedtwoLargeLanguage TanyaGoyal, JunyiJessyLi, andGregDurrett.2022.
Models(LLMs),whichmaynotfullyrepresentthe News summarization and evaluation in the era of
gpt-3. arXivpreprintarXiv:2209.12356.
behavior of all LLMs. Additionally, ethical con-
siderations arise regarding the use of GPT-4 for Herbert P Grice. 1975. Logic and conversation. In
prompt-based metrics. Being closed-source and Speechacts,pages41–58.Brill.
expensive,itsaccessibilitymightberestricted,pos-
Dandan Huang, Leyang Cui, Sen Yang, Guangsheng
sibly widening the gap in research resources and
Bao, Kun Wang, Jun Xie, and Yue Zhang. 2020.
impedingthereproducibilityofourmethodology. Whathaveweachievedontextsummarization? In
Proceedings of the 2020 Conference on Empirical
5.1 Citations MethodsinNaturalLanguageProcessing(EMNLP),
pages 446–469, Online. Association for Computa-
References tionalLinguistics.
MengCao,YueDong,andJackieCheung.2022. Hal- PhilippeLaban,TobiasSchnabel,PaulNBennett,and
lucinated but factual! inspecting the factuality of Marti A Hearst. 2022. Summac: Re-visiting nli-
hallucinationsinabstractivesummarization. InPro- basedmodelsforinconsistencydetectioninsumma-
ceedingsofthe60thAnnualMeetingoftheAssocia- rization. TransactionsoftheAssociationforCompu-
tionforComputationalLinguistics(Volume1: Long tationalLinguistics,10:163–177.
Papers),pages3340–3354,Dublin,Ireland.Associa-
tionforComputationalLinguistics. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad,AbdelrahmanMohamed,OmerLevy,
JiaaoChenandDiyiYang.2020. Multi-viewsequence- Veselin Stoyanov, and Luke Zettlemoyer. 2020.
to-sequencemodelswithconversationalstructurefor BART:Denoisingsequence-to-sequencepre-training
abstractivedialoguesummarization. InProceedings fornaturallanguagegeneration,translation,andcom-
of the 2020 Conference on Empirical Methods in prehension. InProceedingsofthe58thAnnualMeet-
NaturalLanguageProcessing(EMNLP),pages4106– ingoftheAssociationforComputationalLinguistics,
4118, Online. Association for Computational Lin- pages7871–7880,Online.AssociationforComputa-
guistics. tionalLinguistics.Junpeng Liu, Yanyan Zou, Hainan Zhang, Hongshen Łukasz Kondraciuk, Andrew Kondrich, Aris Kon-
Chen,ZhuoyeDing,CaixiaYuan,andXiaojieWang. stantinidis, Kyle Kosic, Gretchen Krueger, Vishal
2021a. Topic-awarecontrastivelearningforabstrac- Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan
tivedialoguesummarization. InFindingsoftheAsso- Leike, Jade Leung, Daniel Levy, Chak Ming Li,
ciationforComputationalLinguistics:EMNLP2021, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz
pages1229–1243,PuntaCana,DominicanRepublic. Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue,
AssociationforComputationalLinguistics. AnnaMakanju,KimMalfacini,SamManning,Todor
Markov, Yaniv Markovski, Bianca Martin, Katie
Zhengyuan Liu, Ke Shi, and Nancy Chen. 2021b. Mayer,AndrewMayne,BobMcGrew,ScottMayer
Coreference-awaredialoguesummarization. InPro- McKinney, Christine McLeavey, Paul McMillan,
ceedingsofthe22ndAnnualMeetingoftheSpecial Jake McNeil, David Medina, Aalok Mehta, Jacob
Interest Group on Discourse and Dialogue, pages Menick, Luke Metz, Andrey Mishchenko, Pamela
509–519, Singapore and Online. Association for Mishkin, Vinnie Monaco, Evan Morikawa, Daniel
ComputationalLinguistics. Mossing,TongMu,MiraMurati,OlegMurk,David
Mély,AshvinNair,ReiichiroNakano,RajeevNayak,
Zheheng Luo, Qianqian Xie, and Sophia Ananiadou. ArvindNeelakantan,RichardNgo,HyeonwooNoh,
2023. Chatgptasafactualinconsistencyevaluator LongOuyang,CullenO’Keefe,JakubPachocki,Alex
for abstractive text summarization. arXiv preprint Paino, Joe Palermo, Ashley Pantuliano, Giambat-
arXiv:2303.15621. tistaParascandolo,JoelParish,EmyParparita,Alex
Passos,MikhailPavlov,AndrewPeng,AdamPerel-
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and man,FilipedeAvilaBelbutePeres,MichaelPetrov,
Ryan McDonald. 2020. On faithfulness and factu- Henrique Ponde de Oliveira Pinto, Michael, Poko-
alityinabstractivesummarization. InProceedings rny, Michelle Pokrass, Vitchyr Pong, Tolly Pow-
of the 58th Annual Meeting of the Association for ell, Alethea Power, Boris Power, Elizabeth Proehl,
Computational Linguistics, pages 1906–1919, On- RaulPuri,AlecRadford,JackRae,AdityaRamesh,
line.AssociationforComputationalLinguistics. CameronRaymond,FrancisReal,KendraRimbach,
Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-
OpenAI,:,JoshAchiam,StevenAdler,SandhiniAgar- der,MarioSaltarelli,TedSanders,ShibaniSanturkar,
wal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAle- GirishSastry,HeatherSchmidt,DavidSchnurr,John
man,DiogoAlmeida,JankoAltenschmidt,SamAlt- Schulman, Daniel Selsam, Kyla Sheppard, Toki
man,ShyamalAnadkat,RedAvila,IgorBabuschkin, Sherbakov, Jessica Shieh, Sarah Shoker, Pranav
SuchirBalaji,ValerieBalcom,PaulBaltescu,Haim- Shyam,SzymonSidor,EricSigler,MaddieSimens,
ing Bao, Mo Bavarian, Jeff Belgum, Irwan Bello, JordanSitkin,KatarinaSlama,IanSohl,Benjamin
Jake Berdine, Gabriel Bernadett-Shapiro, Christo- Sokolowsky, Yang Song, Natalie Staudacher, Fe-
pherBerner,LennyBogdonoff,OlegBoiko,Made- lipePetroskiSuch,NatalieSummers,IlyaSutskever,
laineBoyd,Anna-LuisaBrakman,GregBrockman, JieTang,NikolasTezak,MadeleineThompson,Phil
TimBrooks,MilesBrundage,KevinButton,Trevor Tillet, Amin Tootoonchian, Elizabeth Tseng, Pre-
Cai,RosieCampbell,AndrewCann,BrittanyCarey, ston Tuggle, Nick Turley, Jerry Tworek, Juan Fe-
Chelsea Carlson, Rory Carmichael, Brooke Chan, lipeCerónUribe,AndreaVallone,ArunVijayvergiya,
CheChang,FotisChantzis,DerekChen,SullyChen, ChelseaVoss,CarrollWainwright,JustinJayWang,
Ruby Chen, Jason Chen, Mark Chen, Ben Chess, AlvinWang,BenWang,JonathanWard,JasonWei,
ChesterCho,CaseyChu,HyungWonChung,Dave CJWeinmann,AkilaWelihinda,PeterWelinder,Ji-
Cummings, Jeremiah Currier, Yunxing Dai, Cory ayiWeng,LilianWeng,MattWiethoff,DaveWillner,
Decareaux,ThomasDegry,NoahDeutsch,Damien Clemens Winter, Samuel Wolrich, Hannah Wong,
Deville, Arka Dhar, David Dohan, Steve Dowl- Lauren Workman, Sherwin Wu, Jeff Wu, Michael
ing, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Wu,KaiXiao,TaoXu,SarahYoo,KevinYu,Qim-
Tyna Eloundou, David Farhi, Liam Fedus, Niko ingYuan,WojciechZaremba,RowanZellers,Chong
Felix, Simón Posada Fishman, Juston Forte, Is- Zhang, Marvin Zhang, Shengjia Zhao, Tianhao
abella Fulford, Leo Gao, Elie Georges, Christian Zheng,JuntangZhuang,WilliamZhuk,andBarret
Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Zoph.2023. Gpt-4technicalreport.
Rapha Gontijo-Lopes, Jonathan Gordon, Morgan
Grafstein, ScottGray, RyanGreene, JoshuaGross,
ThomasScialom,Paul-AlexisDray,PatrickGallinari,
ShixiangShaneGu,YufeiGuo,ChrisHallacy,Jesse
SylvainLamprier,BenjaminPiwowarski,JacopoSta-
Han, Jeff Harris, Yuchen He, Mike Heaton, Jo-
iano,andAlexWang.2021. Questeval: Summariza-
hannesHeidecke,ChrisHesse,AlanHickey,Wade
tion asks for fact-based evaluation. arXiv preprint
Hickey,PeterHoeschele,BrandonHoughton,Kenny
arXiv:2103.12693.
Hsu,ShengliHu,XinHu,JoostHuizinga,Shantanu
Jain,ShawnJain,JoanneJang,AngelaJiang,Roger
Jiang,HaozhunJin,DennyJin,ShinoJomoto,Billie LiyanTang,TanyaGoyal,AlexanderRFabbri,Philippe
Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Laban,JiachengXu,SemihYavuz,WojciechKrys´-
Ali Kamali, Ingmar Kanitscheider, Nitish Shirish cin´ski, Justin F Rousseau, and Greg Durrett. 2022.
Keskar,TabarakKhan,LoganKilpatrick,JongWook Understandingfactualerrorsinsummarization: Er-
Kim, ChristinaKim, YongjikKim, HendrikKirch- rors, summarizers, datasets, error detectors. arXiv
ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, preprintarXiv:2205.12854.Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann B ErrorRateperDataset
Dubois,XuechenLi,CarlosGuestrin,PercyLiang,
andTatsunoriB.Hashimoto.2023. Stanfordalpaca: Infigure7weprovidetheinconsistencyratesfor
An instruction-following llama model. https:// allmodelsacrosseachdataset. GPT-4exhibitsthe
github.com/tatsu-lab/stanford_alpaca.
highest consistency across all datasets. However,
BinWang,ChenZhang,YanZhang,YimingChen,and Alpaca-13b shows similar performance to BART
HaizhouLi.2022. Analyzingandevaluatingfaith- onthedialogsumdatasetbutissurpassedbyBART
fulnessindialoguesummarization. arXivpreprint
ontheSAMSumdatasets.
arXiv:2210.11777.
Chien-Sheng Wu, Linqing Liu, Wenhao Liu, Pontus C ThresholdingforBinaryClassification
Stenetorp,andCaimingXiong.2021. Controllable
abstractivedialoguesummarizationwithsketchsu- We use a subset of the evaluation data and apply
pervision. InFindingsoftheAssociationforCom- thresholdingtoconvertcontinuousscoresintobi-
putational Linguistics: ACL-IJCNLP 2021, pages
narylabels. Thissubsetcomprisesapproximately
5108–5122,Online.AssociationforComputational
150source-summarypairs. Thethresholdsarein-
Linguistics.
dividuallydeterminedforeachmetric,dataset,and
XianjunYang,YanLi,XinluZhang,HaifengChen,and
model category. The thresholds are displayed in
Wei Cheng. 2023. Exploring the limits of chatgpt
Figure8
forqueryoraspect-basedtextsummarization. arXiv
preprintarXiv:2302.08081.
D PromptDetails
TianyiZhang,FaisalLadhak,EsinDurmus,PercyLiang,
Kathleen McKeown, and Tatsunori B Hashimoto. D.1 ChatGPT-DirectAssessment
2023. Benchmarkinglargelanguagemodelsfornews
summarization. arXivpreprintarXiv:2301.13848.
Decide if the Summary is consistent with
Rongxin Zhu, Jianzhong Qi, and Jey Han Lau. 2023. thecorrespondingContent. Notethatcon-
Annotating and detecting fine-grained factual er- sistencymeansallinformationinthesum-
rors for dialogue summarization. arXiv preprint
maryissupportedbytheContent. Answer
arXiv:2305.16548.
"yes" for consistent and "no" for inconsis-
A Annotation tent:
Content: {{Dialogue}}
A.1 AnnotatorRecruitment
Summary: {{Summary}}
WehiredannotatorsthroughUpWork. Candidates Answer
underwent a qualifying round and an interview
where they had to explain marked errors. Ulti-
D.2 ChatGPT-Span
mately,weselectedtwoexpertproofreaderswho
D.2.1 Identification
werepaid$18USDand$22USDperhour,respec-
tively.
Identify and list spans in the summary
whicharenotsupportedbyevidencefrom
A.2 AnnotatorInstruction
the content; if there are no unsupported
The following were the instructions provided to
spans,respondwith"None"
annotatorstomarkspansasinconsistent.
Content: {{Dialogue}}
Identifyminimalspansinthesummarythat:
Summary: {{Summary}}
a) Misrepresent information from the source: If
Answer
aspancontradictsordistortsinformationwithre-
specttothesource,annotatetheevidencesentences
D.2.2 Verification
fromthesourcethatdemonstratethisinconsistency
andselectthespanasinconsistent. Content: {{Dialogue}}
b)Introducenewinformationnotsupportedbyevi- Assess the extent to which the specified
denceinthesource: Ifthesummaryincludesnew spaninthefollowingsentenceissupported
informationthatisneithercommonknowledgenor byevidencefromthecontent,usingascale
a logical inference but relies on external facts or of 1 to 5, where 1 indicates no supporting
deductions, mark these spans as inconsistent. In evidenceand5indicatesfullsupportfrom
thiscase,evidencesentencesmaynotbeavailable theevidenceprovidedwithinthecontent
forannotation.1.0
GPT-4 GPT-4 GPT-4
Alpaca-13B Alpaca-13B Alpaca-13B
0.8 BART BART BART
MV-BART MV-BART MV-BART
UniLM UniLM Coref-BART
0.6 CODS CODS CondigSum-BART
0.4
0.2
0.0
RefMatters (DialogSum) RefMatters (SAMSum) FacEval (SAMSum)
Figure7: Inconsistencyrateofallmodelsperdataset. WeseethatAlpaca-13BiscompetitivewithBARTwith
respecttoconsistencyontheDialogSumdatasetbutisoutperformedontheSAMSumdatasets
QAFactEval QuestEval
5 1.0
FT-Summ FT-Summ
LLM LLM
4 Median 0.8 Median
3 0.6
2 0.4
1 0.2
0 0.0
SAMSum FacEval DialogSumSAMSum FacEval DialogSum
SummaC-ZS SummaC-Conv
1.0 1.0
FT-Summ FT-Summ
LLM LLM
Median 0.8 Median
0.5
0.6
0.0
0.4
0.5
0.2
1.0 0.0
SAMSum FacEval DialogSumSAMSum FacEval DialogSum
Figure8: Thresholdsaredisplayedforeachmetriconeachdatasetandmodelcategory.
Span: {{Span}} Summary: {{Summary}}
Sentence: {{SummarySentence}} Answer
Answer:
LogicalError
D.3 ChatGPT-SpanMoE
D.3.1 Identification
ErrorDefinition: Logicalinferenceerrorsin
CircumstantialInference
summariesarisefromdrawingconclusions
ormakingdeductionsthatdeviatefromthe
ErrorDefinition: Circumstantialinference
logicalflowofcontent,leadingtoinaccura-
insummariesisinferredsupplementalinfor-
ciesormisunderstandingsintherepresenta-
mation,notexplicitlystatedinthecontent
tionofinformationorideas.
but derived from circumstantial evidence,
Task Definition: Extract spans from the
often intentionally omitted in the content
summarythatarelogicalerrors.
andassumedtobesharedknowledgeamong
Ensurethespansaretheminimalerroneous
participantsinadherencetotheprincipleof
spans. Listeachspaninanewline;ifthere
providingsufficientinformationwithoutun-
arenosuchspansrespondwithNoneCon-
necessarydetails.
tent: {{Dialogue}}
Task Definition: Extract spans from the
Summary: {{Summary}}
summarythatarecircumstantialinferences.
Answer
Ensurethespansaretheminimalerroneous
spans. Listeachspaninanewline;ifthere
arenosuchspansrespondwithNoneCon-
WorldKnowledge
tent: {{Dialogue}}
)noitroporp(
seirammuS
tnetsisnocnIErrorDefinition: Factualextrapolationsare Summary: {{Summary}}
real-world facts added in a summary, not Answer
explicitlymentionedintheoriginalconver-
sation. The verification step that follows the spans ex-
Task Definition: Extract spans from the tractedfromtheabovepromptsisthesameasdis-
summarythatintroducesadditionaldetails, playedinD.2.2
constituting general facts or world knowl-
edgenotexplicitlystatedintheoriginalcon-
tent.
Ensurethespansaretheminimalerroneous
spans. Listeachspaninanewline;ifthere
arenosuchspansrespondwithNoneCon-
tent: {{Dialogue}}
Summary: {{Summary}}
Answer
ReferentialError
ErrorDefinition: Toidentifyreferentialer-
rors,checkforinconsistencieswithrespect
tothecontentinlinkingpronouns,terms,or
entitiestotheircorrectreferents. Alsolook
forinstancesofmisattributionswherestate-
mentsoractionsareinaccuratelyassigned
tothewrongspeakerorparticipant,result-
ingincontentrepresentationinaccuracies.
Task Definition: Extract spans from the
summarythatarereferentialerrors.
Ensurethespansaretheminimalerroneous
spans. Listeachspaninanewline;ifthere
arenosuchspansrespondwithNoneCon-
tent: {{Dialogue}}
Summary: {{Summary}}
Answer
FigurativeError
Error Definition: Figurative misrepresen-
tationoccurswhennon-literalinformation
in the content is inaccurately portrayed or
misunderstood as literal statements in the
summary,distortingtheintendedmeaning
ormessage.
Task Definition: Extract spans from the
summarythatfigurativelymisrepresentin-
formationinthecontent.
Ensurethespansaretheminimalerroneous
spans. Listeachspaninanewline;ifthere
arenosuchspansrespondwithNoneCon-
tent: {{Dialogue}}