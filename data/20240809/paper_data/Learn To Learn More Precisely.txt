Learn To Learn More Precisely
RunxiCheng1,YongxianWei1,XianglongHe1,WanyunZhu2
SongsongHuang3,FeiRichardYu4,FeiMa4,ChunYuan1,†
1TsinghuaShenzhenInternationalGraduateSchool,TsinghuaUniversity;2CUHK-Shenzhen;
3FudanUniversity;3GuangdongLaboratoryofArtificialIntelligenceandDigitalEconomy(SZ)
*crx23@mails.tsinghua.edu.cn;†yuanc@sz.tsinghua.edu.cn
Abstract
Meta-learninghasbeenextensivelyappliedinthedomainsoffew-shotlearning
and fast adaptation, achieving remarkable performance. While Meta-learning
methodslikeModel-AgnosticMeta-Learning(MAML)anditsvariantsprovidea
goodsetofinitialparametersforthemodel,themodelstilltendstolearnshortcut
features,whichleadstopoorgeneralization. Inthispaper,weproposetheformal
conception of “learn to learn more precisely”, which aims to make the model
learnprecisetargetknowledgefromdataandreducetheeffectofnoisyknowledge,
such as background and noise. To achieve this target, we proposed a simple
and effective meta-learning framework named Meta Self-Distillation(MSD) to
maximizetheconsistencyoflearnedknowledge,enhancingthemodels’abilityto
learnprecisetargetknowledge. Intheinnerloop,MSDusesdifferentaugmented
viewsofthesamesupportdatatoupdatethemodelrespectively. Thenintheouter
loop, MSD utilizes the same query data to optimize the consistency of learned
knowledge,enhancingthemodel’sabilitytolearnmoreprecisely. Ourexperiment
demonstratesthatMSDexhibitsremarkableperformanceinfew-shotclassification
tasksinbothstandardandaugmentedscenarios,effectivelyboostingtheaccuracy
andconsistencyofknowledgelearnedbythemodel.
1 Introduction
Meta-learning, also known as “learning to learn”, aims to endow models with rapid learning
capabilities[17;9]. Thisincludestheabilitytorecognizeobjectsfromafewexamplesortoquickly
acquire new skills after minimal exposure. Meta-learning can be broadly categorized into two
main factions: metric-based[28; 37; 33; 31; 29] and optimize-based meta-learning[9; 2; 35; 15].
Metric-basedapproachestypicallystrivetolearngeneralizedfeaturesthatperformwellontasks
suchasfew-shotlearning. However,duringthemeta-testingphase,metric-basedmeta-learningdoes
notusuallyinvolvefine-tuning, implyingthatthemodellearnsmoregeneralfeaturesratherthan
learninghowtolearn. Optimization-basedmeta-learning,ontheotherhand,isprimarilyconsidered
toembodytheconceptoflearningtolearn.ThemainstreammethodinthisdomainisModel-Agnostic
Meta-Learning(MAML)[9]anditsnumerousvariants[24;35;2;16;22]. DespiteMAMLandits
derivativesdemonstratingimpressiveperformanceonfew-shottasks,theystillexhibitcertainflaws.
Currentresearch[18;37]indicatesthatmodelstendtolearnshortcutfeatures(e.g.,color,background,
etc.) thatareexclusivelysufficienttodistinguishveryfewclassesinthemeta-trainingphase. Models
trainedwithMAMLinevitablyencountertheseissues,andmostimprovementstoMAMLfocuson
optimizingthemethodwithoutaddressingthebiasinmodellearning. Poodle[18]hasproposeda
regularizationapproachusingadditionaldata,butthisdoesnotenhancethemodel’sabilitytolearn
invariantfeaturesinthefew-shotscenario. Therefore,thechallengeofhowtolearnmoreprecisely
remainsacriticalprobleminmeta-learning.
Preprint.Underreview.
4202
guA
8
]GL.sc[
1v09540.8042:viXraSelf-Distillation Meta Self-Distillation (ours)
view logits view encoder
update
consistency of
encoder similarity image encoder
learned knowledge
update
view logits view encoder
Figure1: ThecoreideabetweenSelf-DistillationandMetaSelf-Distillation. Self-Distillation
aimstomakethedeeprepresentationofdifferentviewscloser,whileMetaSelf-Distillationaimsto
learnthesameknowledgefromthedifferentviewsofthesameimage.
Inthispaper,weproposetheconceptof“learntolearnmoreprecisely”. Ourgoalistoenablemodels
tolearnmoreaccurateknowledgefromtrainingdata. Infew-shottasks,duetothescarcityofsamples,
modelsmayconsidernoiseandbackgroundintheinputasthecorefeaturesrelatedtoclassification,
inevitablyleadingtooverfitting. Drawingontheknowledgeconceptintroducedby[14],wepropose
the formal concept of “ knowledge” and “the change of knowledge”. Based on this, we further
definedtheproblemtargetof“learntolearnmoreprecisely”. Weproposethatmodelsshouldlearn
theaccuratetargetknowledgeinsteadofthenoisyknowledge,whichmeanswhenamodellearns
knowledgefromacertainimagewithdifferentnoises, “thechangeofknowledge”shouldbethe
same.
Fromtheperspectiveoflearntolearnmoreprecisely, weproposeMetaSelf-Distillation(MSD),
a simple and effective meta-learning framework for few-shot classification. Specifically, given
randommini-batchdata,weupdatetheinitialparameterwithdifferentaugmentedviewsofthedata
respectivelyintheinnerloop,thenusethesamequerydatatomeasuretheconsistencyoflearned
knowledgeamongeachupdatedmodelintheouterloop. Bymaximizingtheconsistencyinoutputs
forthesamequerydataacrossdifferentupdatedmodels,weenhancetheinitialparameters’ability
to learn more precisely. Throughout extensive experiments, we demonstrate the effectiveness of
MSD.Inbothstandardandaugmentedfew-shotclassificationproblems,MSDoutperformsmany
recentfew-shotclassificationalgorithms,andintheaugmentedscenarioforfew-shottasks,MSD
achievedanaverageimprovementof7.42%and4.03%inthe5way1shotand5way5shotproblems,
respectively. Also,wedefinetousecosinesimilaritybetweenthepredictionsandmeanpredictions
tomeasuretheconsistencyoflearnedknowledge,andweachieveremarkableperformanceinthis
metric
Insummary,thecontributionsofourworkarethreefold:
• Based on the knowledge concept proposed by [14], we introduce the formal notion of
“knowledge”and“thechangeofknowledge”andfurtherproposetheoptimizationgoalof
“learntolearnprecisely”,whichaimstolearnprecisetargetknowledgeandreducetheeffect
ofnoisyknowledge.
• DrawinginspirationfromMAMLandself-distillation,weproposeMetaSelf-distillation
toenabletheinitialparameterstohavetheabilitytolearnmoreprecisely. Bymaximizing
theconsistencyofknowledgelearnedfromdifferentviewsofthesameinstance,themodel
gainstheabilitytolearnmoreprecisely.
• Ourexperimentsdemonstratethatourmethodeffectivelyenhancesthemodel’sperformance
in few-shot learning and exhibits a superior ability to learn precisely in more complex
few-shotclassificationproblemscomparedtoexistingmeta-learningalgorithms.
22 RelatedWork
2.1 Meta-Learning
Meta-learning, also known as learning to learn, endows models with strong learning capabilities
after the meta-training phase. It is mainly divided into metric-based meta-learning, represented
byProtoNet[28],andoptimization-basedmeta-learning,representedbyMAML[9]. Metric-based
meta-learningimprovesmodelrepresentationbybringingthedeeprepresentationbetweenthesupport
dataandthequerydatathatbelongtothesamecategorycloser,typicallynotrequiringfine-tuning
duringthemeta-testphase. Optimize-basedmeta-learningaimstoprovidethemodelwithgoodinitial
weights, offering better generalization performance when fine-tuning on novel category samples.
ThiscategoryincludesalgorithmslikeMAML[9]anditsvariants, suchas[35], whichutilizesa
singlevectortoreplacethenetwork’sclassificationheadweight,thuspreventingthepermutation
in the meta-test phase. MAML++ [2] enhances MAML’s performance by addressing multiple
optimizationissuesencounteredbyMAML,whileANIL[24]improvesMAML’sperformanceby
freezingthebackboneduringtheinnerloop. However,thesealgorithmsmainlyimproveMAML
fromanoptimizationperspective,whiletheydonotfurtheradvanceMAMLintermsofincreasing
themodel’slearningcapabilities. Recentstudiesalsosuggestthatmeta-learningismoreconcerned
withlearningmoregeneralfeaturesfromthetrainingdataset.[24]demonstratethattheeffectiveness
ofMAMLisattributedtofeaturereuseratherthanrapidlearning.[21]discussthecloserelationship
betweencontrastivelearningandmeta-learningunderacertaintaskdistribution. [16]arguesthat
MAML is essentially noisy, supervised contrastive learning. These studies indicate that existing
meta-learningalgorithmsmayfocusmoreonobtainingmoregeneralizedrepresentationsfromthe
training dataset rather than on how to enhance the model’s learning capabilities, while our work
focusesprimarilyonhowtoenhancethemodel’slearningcapabilitiestolearnmoreprecisely.
2.2 Self-Distillation
Self-distillationisavariantofcontrastivelearning[3;7;5;13;20]thattrainsthemodelbybringing
therepresentationsofdifferentviewsofthesameimagecloserwithoutnegativepairs. BYOL[11]
first proposed contrastive learning without negative samples, i.e., self-distillation. SimSiam [7]
furtherexploredhowself-distillationavoidscollapseinaself-supervisedsetting,and[1]suggests
thatself-distillationcanserveasanimplicitensembledistillation,allowingthemodeltodistinguish
moreviewfeatures. Self-distillationisanexcellentmethodtoenhancethemodel’sfeatureextraction
capabilitiesandcanbeeffectivelycombinedwithmeta-learning[20]. Typically,self-distillationaims
tomaximizethesimilarityoftherepresentationsacrossdifferentviewsofthesamedata,whileinour
proposedmethod,weenhancethemodel’sabilitytolearnpreciselybymaximizingtheconsistency
ofoutputfromdifferentupdatedmodelsforthesameimage.
3 ProblemDefinitionForLearnToLearnMorePrecisely
3.1 PreliminaryOnMAMLForFew-shotLearning
3.1.1 Few-shotLearning
Few-shotlearningaimstoenableamodeltoachieveremarkableclassificationperformanceinnovel
classesafterthemeta-trainingphasebylearningfromonlyasmallsubsetofsamplesfromthesenew
classes.Following[33;6;34],Wedefinethefew-shotclassificationproblemasanN-wayK-shottask,
wherethereareNclasses,eachcontainingK-labeledsupportsamples. Typically,Kissmall,suchas
1or5. ThedatausedtoattempttoupdatethemodelisdefinedasthesupportsetS(x,y),whereeach
xrepresentsthemodel’sinput,andydenotesthecorrespondinglabelforx,withybelongingtothe
set[1,n]. Thedatausedtoevaluatetheeffectivenessofthemodelupdatesisdefinedasthequery
setQ,whichhasacompositionalstructureandclassinclusionconsistentwiththesupportset,but
thesamplescontainedinthequerysetarecompletelyorthogonaltothoseinthesupportset. Inthe
meta-testingphase,multipletasksaresamplesfromthenovelclassestoassessthemodel’slearning
abilitybyaveragingtheaccuracyofeachtask. Thenovelclassesdonotoverlapwiththebaseclass
categories,andtheentirebaseclassdatasettypicallycontainsmoredatathanthenovelclasses.
3… … …
Figure2: AnoverviewoftheproposedMSD.Intheinnerloop,MSDfirstusesdifferentaugmented
supportdatatoupdatethef . Intheouterloop,thenmaximizestheconsistencyamongtheoutputsof
θ
thesamequerydatawithdifferentupdateversionsoftheinitialmodel
3.1.2 Model-AgnosticMeta-Learning(MAML)
TheobjectiveofMAML[9]istolearnaninitialparametersetΦ,suchthatwhenpresentedwitha
randomtaskandaspecifiedlossfunction,itcanachievealowerlossafterkstepsofoptimization.
Thiscanbeformallyexpressedas:
E(cid:2) L(Uk(ϕ))(cid:3)
(1)
ϕ
whereUk denoteskupdatesoftheparameterϕusingtaskssampledfromthetaskdistribution,which
correspondstoaddingasequenceofgradientvectorstotheinitialvector:
U(ϕ)=ϕ+g +g +···+g . (2)
1 2 k
Infew-shotlearningscenarios,optimizationalgorithmslikeAdamorSGDaretypicallyemployed
toupdateparameters. Typically,MAMLutilizesadatasetS forupdatingparameterswithinU,a
processalsoreferredtoastheinnerloop. Subsequently,aseparatedatasetQisusedtoevaluateL,
withLdirectlyupdatingtheoriginalparametersϕ,astepknownastheouterloop. Theouterloop
commonlyemploysSGDforupdates,anditsgradientcanbecomputedasfollows:
∂
g = L(U(ϕ))
MAML ∂ϕ (3)
=U′(ϕ)L′(ϕ˜), whereϕ˜=U(ϕ)
InEquation(2),U′(ϕ)istheJacobianmatrixoftheupdateoperationU. WhenoptimizedwithAdam,
the gradients are also rescaled element-wise, but this does not alter the conclusions. First-order
MAMLconsidersthesegradientsasconstants,therebyreplacingtheJacobianU′(ϕ)withtheidentity
operation.
3.2 ProblemDefinitionForLearnToLearnMorePrecisely
MAMLrepresentsapromisinglearningparadigmforacquiringgeneralizationcapabilities. However,
duringthefine-tuningphase,duetothelimitednumberofsamplesinfew-shotclassification,the
modelstilltendstolearnshortcutfeaturesandmultiplereasonablehypothesescanleadtoambiguous
4classifications. Therefore,weproposetheconceptof’LearningtoLearnMorePrecisely,’enabling
themodeltoacquiremoreprecisetargetknowledgefromdata.
First,weneedtoprovideaformaldefinitionofknowledge. WeFollowedHinton’sdefinition[14],
thatknowledgeisalearnedmappingfrominputvectorstooutputvectors. Foragivenparameterset
θ,thecorrespondingknowledgeisdenotedasf ,whichcanbeexpressedas:
θ
f :x(cid:55)→y x∈X where y =f (x) (4)
θ θ
wherexrepresentstheinputvector,yrepresentsthecorrespondingoutputvector,andX denotesthe
domainofinputs. Expandingonthis,fortwoparametersetsθ andθ ,wedefinetheknowledge
1 2
change ∆k with respect to θ relative to θ as the mapping of the change in input vectors to the
2 1
changeinoutputvectors,expressedas:
∆k(θ ,θ ):x(cid:55)→∆y x∈X where ∆y =∆k(θ ,θ )(x)=f (x)−f (x) (5)
1 2 1 2 θ2 θ1
wheref andf representtheknowledgecorrespondingtoθ andθ ,respectively. Weassumethat
θ2 θ1 2 1
theknowledgeofdatacontainsthetargetknowledgerelevanttothecorefeaturesforclassification
and the noisy knowledge. Assuming θ is the initial parameters and θ′ represents the parameters
post-learning,theacquiredknowledgecanbedividedintotwocomponents:
∆k(θ,θ′)=∆k(θ,θ′) +∆k(θ,θ′) (6)
target noise
∆k(θ,θ′) signifiesthetargetknowledge,while∆k(θ,θ′) denotesthenoisyknowledge. The
target noise
corresponding changes in output are ∆y and ∆y , respectively. Thus, ∆k(θ,θ′) can be
target noise
reformulatedas:
∆k(θ,θ′)=x(cid:55)→∆y +∆y x∈X (7)
target noise
Theobjectiveofpreciselearningistominimizetheinfluenceofnoisyknowledge. Thisobjectivecan
bedefinedas:
(cid:90) (cid:90)
min |∆y |dx= |∆k(θ,θ′) (x)|dx (8)
noise noise
x∈X x∈X
Thegoalof"learningtolearnmoreprecisely"istolearnasetofmore"intelligent"initialparameters
θforthemodelsothatwhenfacedwithanytrainingdataforaspecifiedtask,themodelcanlearn
moreprecisetargetknowledgeandreducetheeffectofnoisyknowledge. Thegoalcanbeformulated
as:
(cid:90) (cid:90) (cid:90) (cid:90)
argmin |∆k(θ,θ′) (x)|dxdθ′ = |∆y |dxdθ′ (9)
noise noise
θ
4 MetaSelf-Distillation
Baseonthetargetof“learntolearnmoreprecisely”introducedinsection3.2,weaspireformodels
toacquiremorepreciseknowledgefromimages. AsindicatedinEq.9,learningpreciselyaimsto
disregardthenoiseknowledgeintrainingdata. Fordifferentaugmentedviewsandnoise-induced
variantsofthesameimagedata, weassumethatthetargetknowledgeoftheimagesisthesame.
Therefore,wetrainthemodelwithdifferentaugmentedviewsofimagestogetthevariantsofthe
model. Thenbymaximizingtheconsistencyofthevariants’outputofthesamequerydata,wecan
enhancetheabilityoftheinitialparametertolearnmoreprecisely. Tothisend,weproposeMeta
Self-Distillation. Thisapproachenablesthemodeltolearnconsistentknowledgefromdifferentviews
ofthesameimage,whichcanbecalculatedthroughtheoutputsofthequerydata.
Specifically,wesampletasksfromadistributiontoobtainsupportandquerydata. Unliketraditional
meta-learning,whichsamplesmultipletasks,wesampleasingletaskandcreatemultipleaugmented
viewsassubstitutes. Augmentedtasksonlyaugmentedthesupportdata,andallaugmentedtasks
5sharethesamequerydata. Therationalebehindthisistohavethesamestandardwhenassessingthe
knowledgelearnedbythemodel. LetataskbedenotedasT =(S,Q)∼P(T),andthetasksetas
{S(i),Q},whereS(i)representthei-th. Aftersampling,intheinnerloop,weupdatethemodel
withdifferentaugmentedviewsofthedatatoobtainvariedmodels:
θ =U(θ,S(i)) (10)
i
In the outer loop, we test the query with different updated versions of the parameters. Since we
desirethemodeltoextractthesameknowledgefromdifferentaugmentedviewsofsupportdata,we
measuretheconsistencyoftheirqueryoutputstoassessiftheknowledgelearnedisidentical:
(cid:18) (cid:19)
1 (cid:88) 1 (cid:88)
L = f f (x ), (f (x )) (11)
Knowledge-Consistency n sim θi Query n θi Query
Here,f representsthefunctionmeasuringoutputsimilarity. Here,weusecosinesimilarity.We
sim
alsoproofthatwhenuseconsinesimilarityasf ,outmethodminimizetheupperboundofthe
sim
modulusofnoisyknowledgewhichwasdefinedinEq.6,whichenablesthemodelhavetheabilityto
learnprecisely.
Furthermore,toensurethemodelfullyutilizeslabelinformationandlearnspreciseclassification,we
computetheclassificationlossforeachupdatedparameterbyquerydata:
1 (cid:88)
L = (L (f (x ),y )) (12)
cls n ce θi Query Query
L denotesthecross-entropylossfunction. Themodel’stotallossisexpressedas:
ce
L =L +α·L . (13)
total Knowledge-Consistency cls
whereαrepresentsthecoefficientofclassificationloss. Theupdateintheouterloopiscomputedas:
θ′ =θ−β·L (θ,S,Q) (14)
total
whereβ representsthelearningrateintheouterloop.
Table 1: 5way1shot and 5way5shot classification accuracy in standard few-shot classification
taskand95%confidenceintervalonMiniImageNetandTieredImageNet(over2000tasks),using
ResNet-12asthebackbone.
MiniImageNet TieredImageNet
Methods Backbone Venue 1-Shot 5-Shot 1-Shot 5-Shot
ProtoNet[28] ResNet-12 NeurIPS’17 62.39±0.20 80.53±0.20 68.23±0.23 84.03±0.16
MAML[9] ResNet-12 ICML’17 64.42±0.20 83.44±0.14 65.72±0.20 84.37±0.16
MetaOptNet[19] ResNet-12 CVPR’19 62.64±0.35 78.63±0.68 65.99±0.72 81.56±0.53
ProtoMAML[32] ResNet-12 ICLR’20 64.12±0.20 81.24±0.20 68.46±0.23 84.67±0.16
DSN-MR[27] ResNet-12 CVPR’20 64.60±0.72 79.51±0.50 67.39±0.82 82.85±0.56
Meta-Baseline[8] ResNet-12 ICCV’21 63.17±0.23 79.26±0.17 68.62±0.27 83.29±0.18
Unicorn-MAML[35] ResNet-12 ICLR’22 65.17±0.20 84.30±0.14 69.24±0.20 86.06±0.16
Meta-AdaM[30] ResNet-12 NeurIPS’23 59.89±0.49 77.92±0.43 65.31±0.48 85.24±0.35
MSD ResNet-12 OURS 65.41±0.47 84.88±0.29 69.73±0.48 86.25±0.29
5 Experiment
5.1 ExperimentSetting
Datasets. Ourmethodologywasprimarilyevaluatedontwobenchmarkdatasets: MiniImageNet[33]
andTiered-ImageNet[25],bothwidelyusedforfew-shotlearningassessments.
TheMiniImageNetdatasetcomprises100classes,eachcontaining600samples. Samplesarecolor
imageswitharesolutionof84×84pixels. Followingpriorwork,wedevidethe100classesinto
training,validation,andtestsets,containing64,16,and20classes,respectively.TheTiered-ImageNet
dataset encompasses 608 classes with a total of 779,165 images. These fine-grained classes are
categorizedinto34higher-levelclasses. Inalignmentwithpreviousstudies,wedividedthesehigher-
level classes into training, validation, and test sets, comprising 20, 6, and 8 higher-level classes,
6respectively. Tiered-ImageNetisdesignedtoconsiderclasssimilaritywhensegmentingthedataset,
ensuringasignificantdistributionaldifferencebetweentrainingandtestdata.
BackboneModel. Forourmodelevaluation,following[19],weemployedaResNet-12[12]architec-
ture,notedforitsbroaderwidthsandDropblockmodulesasintroducedby[10]. Thisbackboneis
broadlyusedacrossnumerousfew-shotlearningalgorithms. Additionally,wefollowtheoriginal
MAMLapproach,utilizinga4-layerconvolutionalneuralnetwork(Conv4)[33]. Followingtherecent
practice[36;23;26],Themodels’weightsarepre-trainedontheentiremeta-trainingsettoinitialize.
Table2: 5way1shotand5way5shotclassificationaccuracyinstronglyaugmentedfew-shotclassifi-
cationtaskand95%confidenceintervalonMiniImageNetandTieredImageNet(over2000tasks),
usingResNet-12asthebackbone.
MiniImageNet TieredImageNet
Methods Backbone 1-Shot 5-Shot 1-Shot 5-Shot
MAML ResNet-12 49.94±0.43 73.46±0.36 46.35±0.47 71.28±0.42
MSD+MAML ResNet-12 57.31±0.44 78.32±0.33 52.88±0.44 75.06±0.43
Unicorn-MAML ResNet-12 50.57±0.43 73.68±0.35 46.19±0.46 70.35±0.43
MSD+Unicorn-MAML ResNet-12 57.75±0.44 77.25±0.33 54.80±0.49 74.24±0.41
Table3: 5way1shotand5way5shotclassificationaccuracyinaugmentedfew-shotclassification
taskand95%confidenceintervalonMiniImageNetandTieredImageNet(over2000tasks),using
Conv4asthebackbone.theterms“strong”and“weak”denotethevaryinglevelsofaugmentation
appliedtothesupportdatainthemeta-testphase.
MiniImageNet(Strong) MiniImageNet(Weak)
Methods Backbone 1-Shot 5-Shot 1-Shot 5-Shot
MAML Conv4 28.13±0.29 37.77±0.31 35.89±0.35 49.54±0.36
MSD+MAML Conv4 30.64±0.30 40.79±0.33 37.11±0.37 50.38±0.37
Unicorn-MAML Conv4 29.26±0.30 40.58±0.33 36.07±0.36 51.43±0.37
MSD+Unicorn-MAML Conv4 31.37±0.32 42.59±0.33 38.94±0.38 54.11±0.37
5.2 Results
5.2.1 StandardFew-shotLearningProblems.
TheresultsinTab.1demonstratetheperformanceofMSDandseveralmainstreamfew-shotalgorithms
onfew-shottasks. MSDexhibitsasignificantimprovementoverMAMLintraditionalfew-shottasks.
OnMiniImageNet,ourmethodachievedanincreaseof0.99%in5way1shotand1.44%in5way5shot
tasks,respectively. OnTieredImageNet,theimprovementsfor5way1shotand5way5shottaskswere
4.11%and1.61%,respectively. MSDshowsexcellenteffectivenessinfew-shottasks,withbetter
performancecomparedtotherecentmeta-learningalgorithmsandMAML’svariants.
5.2.2 AugmentedFew-shotLearningProblems.
TofurtherinvestigatetheenhancementofmodelprecisionlearningcapabilitiesthroughMSD,we
employedaugmentedtaskstotestthemodel. Specifically,duringthemeta-testphase,weaugmented
thesupportdatatofine-tunethemodelandthenclassifiedthequerydatausingtheupdatedmodel.We
reporttheaccuracyofmodelclassificationandtheconsistencyofknowledgelearnedacrossdifferent
methods. Conv4andResnet12wereutilizedtovalidatethatMSDcanimprovetheprecisionlearning
abilitiesofmodelsofvaryingscales.
Augmentedfew-shotaccuracy. Tab.3presentstheperformanceofConv4ontheMiniImageNet
datasetundervaryinglevelsofaugmentation. MSDhasanapproximate2%increaseinclassifica-
tion accuracy on query data, irrespective of whether the perturbations are weak or strong. Tab.2
demonstratestheperformanceofResNet-12understrongaugmentationonbothMiniImageNetand
TieredImageNetdatasets. ItisevidentthatMSDconfersgreaterimprovementsonmodelswithlarger
7Table4: 5way1shotand5way5shotconsistencyoflearnedknowledgeinstrongaugmentedfew-
shotclassificationtaskonMiniImageNetandTieredImageNet(over2000tasks),usingResNet-12as
thebackbone.
MiniImageNet TieredImageNet
Methods Backbone 1-Shot 5-Shot 1-Shot 5-Shot
MAML ResNet-12 85.88 94.03 86.79 93.87
MSD+MAML ResNet-12 98.58 99.00 99.63 99.80
Unicorn-MAML ResNet-12 87.55 94.60 87.81 95.41
MSD+Unicorn-MAML ResNet-12 99.91 99.92 99.94 99.96
Figure3: The5way1shotand5way5shotclassificationaccuracyandtheconsistencyoflearned
knowledgewithdifferentnumbersofinnerstepswith95%confidenceinterval,averagedover
2000tasks
capacities. Specifically,MSDcontributestoanapproximate7%increaseinaccuracyfor5way1shot
tasksandabouta4%increasefor5way5shottasks.
Consitencyoflearnedknowledge. Tab.4presentstheconsistencyofknowledgeacquiredbythe
modelvariantsforthesamesupportdata,asquantifiedbythecosinesimilarityamongtheoutputs
of different model versions for the same query data, as shown in Eq.9. It is observed that both
MAMLanditsvariant,MAML-Unicorn,tendtolearnbiasedknowledgeinthe5way1shotscenario,
resulting in a lower consistency of approximately 86%. In the 5way5shot scenario, the models
exhibitreducedhypothesisredundancy,therebyincreasingtheconsistencyoflearnedknowledgeto
approximately94%. OurproposedMetaSelf-Distillation(MSD)approachsignificantlyenhancesthe
model’sextractionofpreciseknowledge,achievingaround99%consistencyinknowledgeacross
bothdatasetsfor5way1shotand5way5shotproblems.
Table 5: Ablation study on MiniImageNet. All models are trained on the full training set of
MiniImageNet.
MiniImageNet
SecondOrder Augmentation L
Knowledge-Consistency 1-shot 5-shot
. ✗ ✓ ✓ 64.51±0.48 84.45±0.28
✓ ✗ ✗ 64.43±0.46 83.90±0.29
✓ ✓ ✗ 64.31±0.48 84.14±0.28
✓ ✓ ✓ 65.41±0.47 84.88±0.29
5.3 AblationStudy
The impact of each component. Tab.5 demonstrates three principal factors influencing model
performance during the optimization process of MSD: the use of second-order derivatives, data
augmentation on support data, and the employment of MSD’s knowledge consistency loss. It is
observedthatMSDoptimizedwithfirst-orderderivativescanachievesuccessfuloptimization,albeit
attheexpenseoflittlefew-shotlearningperformance. TheefficacyofMSD’sknowledgeconsistency
lossiscontingentupondataaugmentationappliedtosupportdataduringthemeta-trainingphase;
hence,intheabsenceofdataaugmentation,theknowledgeconsistencylossisrenderedineffective.
Rowstwoandthreeofthetableindicateamarginalperformanceenhancementattributedtodata
8Black-footedferret Vase Nematode King crab Golden retriever
Origin
MAML
MSD(ours)
Figure4: TheresultsofthevisualanalysisonthetestsetofMiniImageNetwithMAMLandMSD.
augmentation, though the improvement is not substantial. The main contribution to the MSD’s
performanceenhancementisderivedfromtheknowledgeconsistencyloss.
Theimpactoftheinnerstep. Concurrently,wefurtherinvestigatedtheimpactofdifferentinner
stepsduringthemeta-testphaseonthemodel’sfew-shotclassificationaccuracyandpreciselearning
capabilities.Fig.3illustratestheimpactofthenumberofinnerstepsduringthemeta-testphaseonthe
performanceoftheMSDalgorithm. Theresultsindicatethatforanygivennumberofinnersteps,
themodelstrainedusingMSDconsistentlyoutperformedthosetrainedwithMAML.Specifically,
inthe5way1shotand5way5shottasks,MSDachievedanaccuracyofapproximately7%and4%
higherthanMAML,respectively. Concerningtheconsistencyoftheknowledgelearned,therewasa
trendofdecreasingconsistencyforbothMAMLandMSDasthenumberofinnerstepsincreased.
Thissuggeststhatanexcessivenumberofinnerstepsduringthemeta-testphasemayleadtothe
modellearningshortcutfeatures. However, MSDmaintainedapproximately99%consistencyin
theknowledgelearnedforboththe5way1shotand5way5shottasks, significantlysurpassingthe
performanceofMAML.
5.4 Visualization
TofurtheranalyzetheMSDonthelearningcapabilitiesofmodels,wevisualizedthemodelsupdated
byaugmenteddataasshowninFig.4. Specifically,duringthemeta-testphase,wevisualizedmodels
trainedwithModel-AgnosticMeta-Learning(MAML)andMSD.Themodelwasfirstfine-tuned
using augmented support data, with the number of inner steps set to 20. Then, query data was
employedastheevaluatedata. Grad-CAM++[4]wasutilizedtovisualizethecriticalregionsthatthe
modelsfocusedonforunderstandingthequerydata. Thevisualizationsrevealthatthemodeltrained
withMAMLtendstoallocatemoreattentiontothesurroundingenvironment,potentiallyprioritizing
itovertheclassifiedobjects,whilethemodeltrainedwithMSDfocusesmoreontheobjectsusedfor
classification.
6 Conclusion
Inthiswork,weproposetheobjectiveofenablingmodelstolearnwithprecision,aspiringforthe
modeltoacquirecategory-relatedinvariantfeaturesfromthetrainingdatawhilediminishingattention
to biased or shortcut features. Building on this foundation, we introduce a meta self-distillation
optimizationframework. Thisframeworkupdatesthemodelvariantsbyutilizingdifferentvariantsof
supportdatainaninnerloop. Theinitialparameters’precisionlearningcapabilityisthenassessed
based on the consistency of their outputs for the same query data. Experiments demonstrate the
9effectivenessofouralgorithmonfew-shottasks,andnotably,onperturbedfew-shottasks,MSD
significantlyenhancestheperformanceofalgorithmssuchasMAML.
Theabilityformodelstolearnwithgreaterprecisionisofparamountimportance. Webelieveour
proposedalgorithmrepresentsastepforwardinenhancingmodels’abilitytolearnmoreprecisely.
Futureresearchcouldextendsuchaframeworktothedomainofself-supervisedlearningandapplyit
tolarger-scalemodels.
References
[1] Z. Allen-Zhu and Y. Li. Towards understanding ensemble, knowledge distillation and self-
distillationindeeplearning. arXivpreprintarXiv:2012.09816,2020.
[2] A.Antoniou,H.Edwards,andA.Storkey. Howtotrainyourmaml. InInternationalconference
onlearningrepresentations,2018.
[3] M.Caron,I.Misra,J.Mairal,P.Goyal,P.Bojanowski,andA.Joulin. Unsupervisedlearningof
visualfeaturesbycontrastingclusterassignments. Advancesinneuralinformationprocessing
systems,33:9912–9924,2020.
[4] A.Chattopadhay,A.Sarkar,P.Howlader,andV.N.Balasubramanian.Grad-cam++:Generalized
gradient-based visual explanations for deep convolutional networks. In 2018 IEEE winter
conferenceonapplicationsofcomputervision(WACV),pages839–847.IEEE,2018.
[5] T.Chen,S.Kornblith,M.Norouzi,andG.Hinton. Asimpleframeworkforcontrastivelearning
ofvisualrepresentations. InInternationalconferenceonmachinelearning,pages1597–1607.
PMLR,2020.
[6] W.-Y.Chen, Y.-C.Liu, Z.Kira, Y.-C.F.Wang, andJ.-B.Huang. Acloserlookatfew-shot
classification. arXivpreprintarXiv:1904.04232,2019.
[7] X.ChenandK.He. Exploringsimplesiameserepresentationlearning. InProceedingsofthe
IEEE/CVFconferenceoncomputervisionandpatternrecognition,pages15750–15758,2021.
[8] Y.Chen,Z.Liu,H.Xu,T.Darrell,andX.Wang.Meta-baseline:Exploringsimplemeta-learning
forfew-shotlearning. InProceedingsoftheIEEE/CVFinternationalconferenceoncomputer
vision,pages9062–9071,2021.
[9] C.Finn,P.Abbeel,andS.Levine. Model-agnosticmeta-learningforfastadaptationofdeep
networks. InInternationalconferenceonmachinelearning,pages1126–1135.PMLR,2017.
[10] G. Ghiasi, T.-Y. Lin, and Q. V. Le. Dropblock: A regularization method for convolutional
networks. Advancesinneuralinformationprocessingsystems,31,2018.
[11] J.-B. Grill, F. Strub, F. Altché, C. Tallec, P. Richemond, E. Buchatskaya, C. Doersch,
B. Avila Pires, Z. Guo, M. Gheshlaghi Azar, et al. Bootstrap your own latent-a new ap-
proachtoself-supervisedlearning. Advancesinneuralinformationprocessingsystems, 33:
21271–21284,2020.
[12] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In
ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition,pages770–
778,2016.
[13] K.He,H.Fan,Y.Wu,S.Xie,andR.Girshick. Momentumcontrastforunsupervisedvisual
representationlearning. InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
patternrecognition,pages9729–9738,2020.
[14] G.Hinton,O.Vinyals,andJ.Dean.Distillingtheknowledgeinaneuralnetwork. arXivpreprint
arXiv:1503.02531,2015.
[15] M.A.JamalandG.-J.Qi. Taskagnosticmeta-learningforfew-shotlearning. InProceedingsof
theIEEE/CVFconferenceoncomputervisionandpatternrecognition,pages11719–11727,
2019.
[16] C.-H.Kao,W.-C.Chiu,andP.-Y.Chen. Mamlisanoisycontrastivelearnerinclassification.
arXivpreprintarXiv:2106.15367,2021.
[17] B. M. Lake and M. Baroni. Human-like systematic generalization through a meta-learning
neuralnetwork. Nature,623(7985):115–121,2023.
10[18] D.Le,K.D.Nguyen,K.Nguyen,Q.-H.Tran,R.Nguyen,andB.-S.Hua. Poodle: Improving
few-shotlearningviapenalizingout-of-distributionsamples. AdvancesinNeuralInformation
ProcessingSystems,34:23942–23955,2021.
[19] K.Lee, S.Maji, A.Ravichandran, andS.Soatto. Meta-learningwithdifferentiableconvex
optimization. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition,pages10657–10665,2019.
[20] J.Li,W.Qiang,C.Zheng,B.Su,andH.Xiong. Metaug: Contrastivelearningviametafeature
augmentation. InInternationalConferenceonMachineLearning,pages12964–12978.PMLR,
2022.
[21] R. Ni, M. Shu, H. Souri, M. Goldblum, and T. Goldstein. The close relationship between
contrastivelearningandmeta-learning. InInternationalconferenceonlearningrepresentations,
2021.
[22] A.Nichol,J.Achiam,andJ.Schulman. Onfirst-ordermeta-learningalgorithms. arXivpreprint
arXiv:1803.02999,2018.
[23] S.Qiao,C.Liu,W.Shen,andA.L.Yuille.Few-shotimagerecognitionbypredictingparameters
from activations. In Proceedings of the IEEE conference on computer vision and pattern
recognition,pages7229–7238,2018.
[24] A.Raghu, M.Raghu, S.Bengio, andO.Vinyals. Rapidlearningorfeaturereuse? towards
understandingtheeffectivenessofmaml. arXivpreprintarXiv:1909.09157,2019.
[25] M. Ren, E. Triantafillou, S. Ravi, J. Snell, K. Swersky, J. B. Tenenbaum, H. Larochelle,
andR.S.Zemel. Meta-learningforsemi-supervisedfew-shotclassification. arXivpreprint
arXiv:1803.00676,2018.
[26] A. A. Rusu, D. Rao, J. Sygnowski, O. Vinyals, R. Pascanu, S. Osindero, and R. Hadsell.
Meta-learningwithlatentembeddingoptimization. arXivpreprintarXiv:1807.05960,2018.
[27] C.Simon,P.Koniusz,R.Nock,andM.Harandi. Adaptivesubspacesforfew-shotlearning. In
ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,pages
4136–4145,2020.
[28] J.Snell,K.Swersky,andR.Zemel. Prototypicalnetworksforfew-shotlearning. Advancesin
neuralinformationprocessingsystems,30,2017.
[29] Q.Sun,Y.Liu,Z.Chen,T.-S.Chua,andB.Schiele. Meta-transferlearningthroughhardtasks.
IEEETransactionsonPatternAnalysisandMachineIntelligence,44(3):1443–1456,2020.
[30] S. Sun and H. Gao. Meta-adam: An meta-learned adaptive optimizer with momentum for
few-shotlearning. AdvancesinNeuralInformationProcessingSystems,36,2024.
[31] F.Sung,Y.Yang,L.Zhang,T.Xiang,P.H.Torr,andT.M.Hospedales. Learningtocompare:
Relationnetworkforfew-shotlearning. InProceedingsoftheIEEEconferenceoncomputer
visionandpatternrecognition,pages1199–1208,2018.
[32] E.Triantafillou, T.Zhu, V.Dumoulin, P.Lamblin, U.Evci, K.Xu, R.Goroshin, C.Gelada,
K.Swersky,P.-A.Manzagol,etal. Meta-dataset: Adatasetofdatasetsforlearningtolearn
fromfewexamples. arXivpreprintarXiv:1903.03096,2019.
[33] O.Vinyals,C.Blundell,T.Lillicrap,D.Wierstra,etal. Matchingnetworksforoneshotlearning.
Advancesinneuralinformationprocessingsystems,29,2016.
[34] Y.Wang,Q.Yao,J.T.Kwok,andL.M.Ni. Generalizingfromafewexamples: Asurveyon
few-shotlearning. ACMcomputingsurveys(csur),53(3):1–34,2020.
[35] H.-J.YeandW.-L.Chao. Howtotrainyourmamltoexcelinfew-shotclassification. arXiv
preprintarXiv:2106.16245,2021.
[36] H.-J.Ye,H.Hu,D.-C.Zhan,andF.Sha. Few-shotlearningviaembeddingadaptationwith
set-to-setfunctions.InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpattern
recognition,pages8808–8817,2020.
[37] F.Zhou,P.Wang,L.Zhang,W.Wei,andY.Zhang. Revisitingprototypicalnetworkforcross
domainfew-shotlearning. InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition,pages20061–20070,2023.
11A Appendix/supplementalmaterial
A.1 Limitations
Inthispaper, weonlydiscussthestandardandaugmentedfew-shotscenarios, whilethemethod
proposedcanbeusedinmanyotherexistingfields. Also,duetothecostlysecond-orderderivative
involved,itiscomputation/memoryexpensivetoapplythemethodtoalargermodel.
A.2 HyperparametersAndCodeEnvironmentOfExperiment
Hyperparameters.
ThehyperparametershasshownintheTab.6Tab.7Tab.A.3
Calculate resources and Environment. Our experiment is conducted on NVIDIA A800 80GB
PCIe. ThesoftwareenvironmentconsistedofPythonversion3.10.14,andPyTorchversion2.3.0,
withCUDAtoolkit12.1
A.3 BroaderImpact
Themethodweproposedenhancesthemodel’sabilitytolearnmoreprecisely. Indomainssuchas
healthcare,thisallowsforgoodperformancewithonlyasmallamountofdata,whichbringspositive
socialimpact.
Table6: ExperimentalSetup
Parameter Value
TaskBatchSize 2
InnerStepCount 20
InnerLoopLearningRate 0.05
OuterLoopLearningRate 0.001
QueryDataPoints 15
OuterLoopLearningRateDecay 1/10every10epochs
Coefficientα(Eq.14) 1
Table7: AugmentationsforStrong-AugmentedFew-ShotScenario
Augmentation Parameters Probability
RandomResize (scale: 0.5–1) -
ColorJitter (0.8,0.8,0.8,0.2) 0.8
GrayscaleConversion - 0.2
GaussianBlur Expectation: 0.1,Variance: 2 0.5
RandomHorizontalFlip - 0.5
Table8: AugmentationsforWeak-AugmentedFew-ShotScenario
Augmentation Parameters Probability
CenterCrop 84×84 -
ColorJitter (0.4,0.4,0.4,0.1) 0.8
GrayscaleConversion - 0.2
GaussianBlur Expectation: 0,Variance: 1 0.5
RandomHorizontalFlip - 0.5
12