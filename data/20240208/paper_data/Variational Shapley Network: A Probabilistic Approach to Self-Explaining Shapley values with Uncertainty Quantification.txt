Variational Shapley Network: A Probabilistic Approach to
Self-Explaining Shapley values with Uncertainty Quantification
MertKetenci1 IñigoUrteaga2 VictorAlfonsoRodriguez3 NoémieElhadad13 AdlerPerotte3
Abstract tionoffeaturej acrossallcoalitions,whereacoalitionsis
definedasanysubsetoffeaturesin (thetypicalcasesets
Shapleyvalueshaveemergedasafoundational
C C toallindices )excludingj.Weusex todenotethesubset
tool in machine learning (ML) for elucidating s
A
offeaturevaluescorrespondingtothecoalitions;fors= ,
modeldecision-makingprocesses. Despitetheir
A
we simply write x. For instance, for d = dim(x) = 25
widespreadadoptionanduniqueabilitytosatisfy
andcoalitions= 1,21,6 ,x denotes[x ,x ,x ]. The
essential explainability axioms, computational s 1 21 6
{ }
Shapleyvalueoffeaturej ismathematicallydefinedas:
challenges persist in their estimation when (i)
evaluating a model over all possible subset of (cid:88)
SV := p(s )(v(s j) v(s)). (1)
inputfeaturecombinations,(ii)estimatingmodel j |C ∪ −
s⊆C\j
marginals,and(iii)addressingvariabilityinex-
planations. Weintroduceanovel,self-explaining Thefunctionv(s)denotesthevalueofeachcoalition,math-
methodthatsimplifiesthecomputationofShap- ematicallydefinedinEqn.(2). Theprobabilityp(s )=
|C
ley values significantly, requiring only a single |s|!(|C|−|s|−1)! quantifiesthelikelihoodofformingacoali-
|C|!
forwardpass. Recognizingthedeterministictreat- tions. TheShapleyvalueconsidersthejthelement’scon-
ment of Shapley values as a limitation, we ex-
tributiontoacoalition,byconsideringthedifferenceinthe
ploreincorporatingaprobabilisticframeworkto
outcomeinitsabsence. Mathematically,thevaluefunction
capturetheinherentuncertaintyinexplanations. v(s)isdefinedas
Unlikealternatives,ourtechniquedoesnotrely
(cid:90) (cid:90)
directly on the observed data space to estimate (cid:0) (cid:1)
v(s)= f(x)p x x dx f(x)p(x)dx.
A\s s A\s
marginals;instead,itusesadaptablebaselineval- | −
uesderivedfromalatent,feature-specificembed- (2)
dingspace,generatedbyanovelmaskedneural
Typically, when explaining ML models, f(x) is defined
networkarchitecture. Evaluationsonsimulated
asthemodeloutput. Consequently,v(s)encapsulatesthe
andrealdatasetsunderscoreourtechnique’sro-
disparityinthemodel’soutputscomputedbymarginalizing
bustpredictiveandexplanatoryperformance.
overtheset sincontrasttotheentireset .
A\ A
1.IntroductionandRelatedWork Shapley values are the unique attribution method to sat-
isfyfourkeyexplainabilityaxioms: Efficiency,NullPlayer
Shapleyvalues(Shapleyetal.,1953)—rootedincoopera-
(Dummy),Symmetry,andLinearity;underpinningtheirap-
tivegametheoryandthefieldoftransferableutility—have
pealinmodelexplanation(Merrick&Taly,2020). Werefer
gainedsignificantattentionintheMLcommunity,emerg-
to(Rozemberczkietal.,2022)fordetailsontheirtheoretical
ingasaprominenttechniqueforexplainingmodeldecision
foundation. Despiteitsdesirablepropertiesandwidespread
making (Lundberg & Lee, 2017; Lundberg et al., 2020;
application, estimating Shapley values remains challeng-
Covert&Lee,2021).
ing,mainlywhen(i)summingoverallpossiblecoalitions,
For a supervised model f : , the Shapley value i.e.,Eqn. (1)(VandenBroecketal.,2022);(ii)estimating
X → Y
of feature j with respect to a reference set = modelmarginals(Covertetal.,2021), i.e., Eqn. (2); and
C ⊆ A
1,2,...,d = dim(x) is the expected marginal contribu- (iii)generatingreliableexplanationswhenthereisconsid-
{ }
erablevariabilityinhowfeaturesaffecttheresponse,i.e.,
1DepartmentofComputerScience,ColumbiaUniversity,New
accountingforpotentialrandomnessinf(x).
York, USA 2Basque Center for Applied Mathematics, Basque
FoundationforScience,Basque,Spain3DepartmentofBiomedical
Recent research on the first challenge involves solving a
Informatics,ColumbiaUniversity,NewYork,USA.Correspon-
post-hocweighted-leastsquaresproblem(Lundberg&Lee,
denceto:MertKetenci<mk4139@columbia.edu>.
2017; Covert et al., 2020; Adebayo et al., 2021). While
these techniques provide insight into black-box models,
1
4202
beF
6
]GL.sc[
1v11240.2042:viXraAProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
theycomewithcertaindrawbacks. Specifically,theymay Slacketal.,2021). Therefore,theymisstheinherentuncer-
beoverlysensitivetoslightinputchanges(Ghorbanietal., taintyinmodeloutputs, vitalforrobustexplanationsand
2019), may not always align with the original black-box understandingwhyexplanationsmaydifferforsimilardata.
model’sdecisions(Rudin,2019),andmightrequireexten-
Reasoning about explanation uncertainty is important in
sivesamplingforpreciseexplanations(Jethanietal.,2021).
real-worldapplications. Take,forexample,thetaskofde-
FastSHAPproposedanapproachtolearnShapleyvaluesin
ducingShapleyvaluesfromanMLmodeltrainedtodetect
asingleforwardpass(Jethanietal.,2021). However,itre-
dolphinsinimages. Thismodelislikelytoassociateblue
quirestrainingmultipleneuralnetworkssequentially,which
pixelswithdolphins,sincetheyrelatetowater.Yet,bluepix-
is computationally demanding. In this work, we propose
elsarealsoindicativeofthesky,leadingtohighpredictive
aself-explainingprocedurethatrequirestrainingasingle
variance. Thequestionthenarises:CanwerelyontheShap-
network.
leyvaluesofsuchuncertainfeatures? Thisissueechoesthe
ThesecondmainchallengewithShapleyvaluecomputation observationsofAlvarez-Melis&Jaakkola(2018).Ourwork
isonmodelmarginalestimation,asrequiredbythedefini- exploresthereasonsbehindthisphenomenon,andproposes
(cid:0) (cid:1)
tioninEqn. (1). Inpractice, p x x isanalytically aframeworktoaddressit. Namely,weask: Whatiff(x)
A\s s
|
unavailableandoften,theempiricaldatadistributionisem- inEqn.(2)isarandomfunction(e.g.,aGaussianprocess)?
ployed. However, thisapproachisproblematicwhenever ShouldwethenalsotreatSV asrandom? Weanswerthis
j
inputfeaturesarecontinuous;hence,theempiricaldistribu- questionpositively. Weprovideanillustrativeexamplein
tionsparse. Commonsolutionsestimatemodelmarginals Appx. 5.1ofhow,inthepresenceofrandomnes,comput-
usingvariousapproximatedistributions,rangingfromthe ingShapleyvaluesbasedonadeterministicMLmodelis
productofinputmarginalstothejointoruniformdistribu- insufficient. Hence, we utilize a probabilistic framework
tionoverinputs(Dattaetal.,2016;Lundberg&Lee,2017; toaccountfortheuncertaintyindatageneratingprocesses
Strumbelj & Kononenko, 2010). However, these can be (DGPs), quantifying how much to trust a given feature’s
misleadingwheninputfeaturesarecorrelated. Wereferthe Shapleyvalue.
reader to Covert et al. (2021) for a detailed overview on
Ourcontributionsareasfollows:
marginalizationtechniquesandtheirchallenges.
1. We model Shapley values as random variables:
Morerecently,Sundararajan&Najmi(2020)proposedto
We define stochastic Shapley values (SSVs) φ
use baseline values to replace marginalized variables for j ∼
p(φ x),andwriteϕ fortheexpectationovertheir
Shapleyvaluecomputation.Covertetal.(2021)showedthat condj it| ionalprobabilityj : ϕ =E φ .1 Inwhat
trainingamodelbyreplacingfeatureswithbaselinevalues, j p(φj|x) { j }
follows,werefertoϕ asdefinedhereastheexpected
independently,allowsforlearningmodelsmarginalizedby j
Shapleyvalue(ESV).
theinputconditionaldistribution. Jethanietal.(2021)used
baselinevaluesthatareoutsideoftheobservedinputspace 2. Self-explaining, probabilistic SSV inference: We
tomakedistinguishingmarginalseasier. Yet,Covertetal. positper-feature,conditionalGaussianpriordensities
(2021)emphasizedthechallengesinherenttobaselinesin overSSVsφ and,tolearnthegenerativeparameters
j
continuousdomains,duetothepotentialmisrepresentations oftheSSVprior,deviseavariationalobjectivefortheir
inducedbythem, skewingShapleyvaluesbecauseofthe regularizedinference—guidingpriorSSVparameters
estimated poor marginals. We address this challenge by forittodistributearoundeachESV,ϕ . Tothebestof
j
definingfeatureembeddingsandbaselinevalueswithina ourknowledge,ourworkisthefirstattempttomod-
latent,learnedembeddingspace. Wedemonstratethatthis eling and learning Shapley values in a probabilistic,
approachleadstobetterperformancecomparedtoformer self-explainingmanner.
alternatives.
3. Explaininguncertaintyinmodeloutputs: Weposit
ThethirdchallengerelatestothefactthattheShapleyvalues aSSVconditionallikelihoodthatallowsforcapturing
are commonly treated as deterministic entities. This per- theuncertaintyinmodeloutputsacrossφ js,producing
spectivelargelystemsfromthepracticeofnon-probabilistic uncertaintyestimatesoverSSVsthatadduptothetotal
MLmodelsdeliveringsingulardeterministicoutputs. Our predictiveuncertainty. Weachievesobyutilizingan
researchdemonstratesthatthissimplificationmayoverlook additiveSSVresponselikelihood,withanamortized
criticalinsights, emphasizingtheimportanceofacknowl- varianceoftheconditionalSSVprior.
edgingtheuncertaintyinherentinexplanations(Chanetal.,
4. Efficient modeling and processing of variable-
2020;Alaa&VanDerSchaar,2020;Leeetal.,2020).While
lengthinputs: Weintroduceamaskedneuralnetwork
somepost-hoctechniquesquantifytheuncertaintyoftheir
architectureforefficientprocessingandmarginalizaion
Shapleyvalueestimates, theymainlyaddressuncertainty
ofvariable-length,continuousdata.Inaddition,weuse
from Monte Carlo approximations (Covert & Lee, 2021;
1Notethat,ϕ =SV ,whenf(x)isdeterministic.
j j
2AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
baseline values in a learned embedding space rather dictivedistributionanalytically(seeAppx. 5.2):
thanininputspace ,foraccuratemarginalization.
X y(i) x(i) (cid:0) µ (x(i)),σ2 (x(i))(cid:1) , (3)
| C ∼N tot C tot C
5. AccurateShapleyvalueestimationanduncertainty
quantification: Weshowinsyntheticandrealdatasets
where (cid:80)wedefinethetotalpriorpredictivemeanµ tot(x( Ci))=
ϕ + µ (x(i)),andthetotalpriorpredictivevariance
howtheproposedmethodlearnsSSVdistributionscen- σ0
2
(x(ij ))∈A =σθ 2j +(cid:80)C
σ2 (x(i)). ESVsquantifythede-
teredaroundtheESVs,withinformativeuncertainty tot C 0 j∈A ψj C
viationofaspecificpredictionfromtheaveragepredictions
quantificationofthestochasticeffectsobservedindata.
acrossthedataset. Hence,incorporationoftheϕ termin
0
theDGPlikelihoodisessentialtoembodythisaverage.
2.VariationalShapleyNetwork(VSN)
2.2.InferenceandLearning
2.1.VSN’sGenerativeStory Weargueherewhyavariationalinference-basedapproachis
Let = x(i),y(i) N beasetofpartiallyobservedinput neededtolearntheSSVsofinterest,i.e.,tolearngenerative
D { Ci }i=1
andresponsepairs. Weassumethatx(i) =[x(i),x(i) ]where model’spriorsthatarecenteredaroundtheESVofeachfea-
Ci Mi
Ciand Mirefertoconditioned(observed)andmarginalized ture: µ θj(x( Ci))
→
ESV j(i) = ϕ( ji). Webeginbydiscussing
(missing) indices. Hence, x(i) can be of variable length whymaximumlikelihoodinferencedoesnotsuffice.
Ci
acrossinstances,and = .2 WeposeaShapley
i i Maximum likelihood. The joint data likelihood of the
C ∪M A (cid:2) (cid:3)
value-based probabilistic model, where Φ(i) = φ(i)
j j∈A DGPoverrandomvariablesyandΦ,givenX ,is:
C
denotesthesetofSSVs. Forinputdatainstancex(i)andthe
C N
observedresponsey(i),VSNassumesthefollowingDGP: (cid:89) (cid:89) (cid:0) (cid:1)
ℓ=p(y,Φ X )= p(y(i) Φ(i)) p φ(i) x(i) . (4)
| C | j | C
i=1 j∈A
There is a parametric, data-conditional SSV prior (cid:124) (cid:123)(cid:122) (cid:125)
per input-feature j, N(cid:16) µ θj(x C),σ ψ2 j(x C)(cid:17) , where When possible, we integrate out theℓ( li) atent SSV random
{θ j,ψ j} j∈Aarelearnableparametersofperfeaturemean variablestoattainthemarginallog-likelihood
andvariancedata-dependentfunctions.
N (cid:90)
Foreachinputdatapointx( Ci),i={1,··· ,N}: =(cid:88) log ℓ(i)dΦ(i) , (5)
L
1. DrawperfeaturejstochasticShapleyvalues,each i=1
whichisanalyticallytractable,e.g.,fortheGaussianadditive
fromitsconditionalSSVprior:
linearSSVcase:
φ( ji)|x( Ci)∼N(cid:16) µ θj(cid:0) x( Ci)(cid:1) ,σ ψ2 j(cid:0) x( Ci)(cid:1)(cid:17) , ∀j ∈A (cid:88)N
log (cid:0) µ (x(i)),σ2 (x(i))(cid:1) . (6)
2. Drawaresponsefromthedataemissiondistribution, N tot C tot C
conditionedonSSVs: i=1
y(i)|Φ(i) ∼p(cid:0) y(i) |Φ(i)(cid:1) . WhiledirectmaximizationofEqn. (5)enablesdata-driven
estimationofallmodelparametersΘ= ϕ , θ ,ψ ,
0 j j j∈A
{ { } }
nothing enforces φ(i)’s to distribute around ESVs ϕ(i). In
j j
With VSN’s DGP, we accommodate flexible, non-linear otherwords, thereisnoincentivewithin tofindΘthat
functionsµ θj(x C)andσ ψ2 j(x C)(e.g.,neuralnetworks)with enforcesφ( ji)todistributearoundtheESVsL ofinterest.
variable-length input features. The rationale for defining
theSSVpriorbasedonpartiallyobserveddatax (i.e.,with Weovercomethislimitationwithvariationalinference(Blei
C et al., 2016), where we restrict the search space of learn-
variablelengthinputs)stemsfromthenecessitytolearnthe
ableparametersΘviavariationalregularization,anefficient
marginalsforcomputingShapleyvalues,anapproachalso
strategythathelpswithself-explainability(AlvarezMelis&
discussedbyCovertetal.(2021)andJethanietal.(2021).
Jaakkola,2018).
By inspection of the DGP, we observe the following: (i)
Variationalinference. Variationalmethodslower-bound
µ (x ) corresponds the expected value of the SSV, i.e.,
θj C the marginal log-likelihood for any variational fam-
E p(φj|x( Ci)) {φ j };and(ii),σ ψ2 j(x C)correspondstothevari- ily q ; or equivalently,L minimize the distance be-
ance(uncertaintymeasure)ofSSVs. ∈ Q
tween the assumed variational distribution q and the
For certain data-likelihood choices, e.g., for the true target p. In our case, a variational solution
(cid:81) (cid:0) (cid:1)
Ga (cid:16)ussian additive line (cid:17)ar SSV case with y(i) |Φ(i)
∼
q sol(Φ(i) |x( Ci))= j∈Aq sol φ( ji) |x( Ci) andthetruemodel
ϕ +(cid:80) φ(i),σ2 , we can compute the prior pre- posteriorp(Φ(i) x(i),y(i)),whereweenforcethevariational
N 0 j∈A j 0 familytocenter| aroC undtheDGP’sper-featureESVs,ϕ(i). In
j
2Moving forward, we omit the subscript i in C , and use C, ordertoaccomplishthis, we(i)enforcetheinferredvari-
i
althoughwenotethattheyaredistinctforeachindividualexample. ational solution to be aligned with the ESVs of the DGP,
3AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
and(ii)pullthepositpriorclosetothisinferredESVs,for ESVs. Consequently,theexpectationacross ofthesum
D
whichweturnintothevariationalmachinery. ofthemeansoftheSSVpriorsconvergesto0(adetailed
We (cid:16)chooseaGaussianva (cid:17)riationalfamilyq sol(cid:0) φ( ji) |x( Ci)(cid:1) = d toe wri av ra dt sio thn eis exp pr eo cv ti ed de md oin deA lp pp rex d. ic5 t. i4 o) n. sT ah cre or se sfo thre e, eϕ m0 pt ie rn icd as
l
N
µ solj(x( Ci)),σ ψ2 j(x( Ci)) ,whereweenforcetheexpected datadistribution D. Thisobservationprovidesusefulmodel
valueofthevariationalsolutiontoobey convergencediagnostics,e.g.,asshowininFig. 2.
(cid:88)
µ solj(x( Ci))= p(s |C)(v sol(s ∪{j }) −v sol(s)), Fortheassumedgenerativeprocessandvariationalfamilies,
s⊆C\{j} ij inEqn. (8)obeystheanalyticalsolution:
R
with v (s):=µ (x(i)). (7)
sol tot s (cid:0) (cid:1)2
µ solj(x( Ci)) −µ θj(x( Ci))
. (9)
We constrain the variational solution’s per-feature j ex- 2σ2 (x(i))
ψj C
pectedvaluestobedistributedaroundeachper-featureESV
This regularization term may seem similar to the loss
of the assumed DGP, with uncertainty determined by the
prior’svarianceσ2 (x(i)).Namely,thej-thmeanofthevari- in kernel-based Shapley value algorithms (Lundberg &
ψj C Lee, 2017; Covert & Lee, 2021), and in particular, Fast-
ationalsolutionµ solj(x( Ci))isequaltotheDGP’sj-thESV.
SHAP(Jethanietal.,2021). Onthecontrary,unlikeinpre-
BasedonthetheoryofCovertetal.(2021)andthetraining
viousworks,ourvalueandexplanatoryfunctionsaredefined
procedurewedescribeinAlg. 1,v representsthevalue
sol
by a shared network, learned jointly via variational infer-
functionthatdescribestheDGP’sexpectedmodeloutputs
ence. Moreimportantly,ourKL-divergencetermdoesnot
marginalizedbydataconditionals,andµ solj(x( Ci))—which
imposeaweighted-leastsquaresproblem,avoidingcoalition
canbecomputedinasingleforwardpass—convergesto
samplingoveranL2loss. Finally,ourregularizationincor-
ESV(i)(Appx. 5.3).
J poratestheuncertaintyinoutputs;hence, —weighted
∇θj
Westrategicallyalignthevariationaldistribution’svariance byσ2 —willbesmallerforhigh-uncertaintyregions.
ψ
withtheDGPprior,amortizingthesesharedlearnablepa-
rametersσ2 (x(i)). Thischoiceleadstosmallerdivergence, 2.3.ATigtherandComputationallyMoreEfficient
ψj C VariationalInferenceforVSN
andtightensthelower-bound. Toenforceeachσ2 (x(i))to
modelitscorrespondingjthSSVuncertainty,wψ ej limC
itits
Implementing Eqn. (8) is computationally challenging,
inputasdescribedinSec. 2.5. as (cid:0)it 2|r Ce |q (cid:1)u —ire ts oc co am lcup lu at ti en Egq sol(Φ(i) |x( C li) o) g— p(yo (f i)co Φm (ip ))lex .i Tt oy
Sinceq sol isdefinedintermsoftheSSVprior’ssufficient O circumventsuchcomputaq ts io ol( nΦ a( li) c|x o( Ci m)) p{ lexity,we| form} ulate
statistics—thesolution’sexpectedvaluedependsonthe thefollowing:
prior’spredictivemean,andthesolution’svarianceisequal
(cid:110) (cid:16) (cid:17)(cid:111)
totheprior’svariance—ouruseofvariationalinferencecan Proposition 2.2. E qsol(Φ(i)|x( Ci)) f ϕ 0+(cid:80) j∈Aφ( ji) is
beunderstoodasaregularizationofthepositprior. Namely, equaltoE (cid:110) f(cid:16) ϕ +(cid:80) φ(i)(cid:17)(cid:111) .
weregularizetheDGPmodelfamily,whichistiedtothe p(Φ(i)|x( Ci)) 0 j∈A j
data-conditionalSSVprior,toensurethatlearned(latent)
SSVvariablescenteraroundtheDGP’sESVs.
Proof. PleaseseeAppx. 5.6foradetailedproof.
Evidencelower-bound. Usingtheproposedvariational
family,wederivethevariationalinferenceobjective,with
Using Proposition 2.2 and Jensen’s inequality, we can
fulldetailsprovidedinAppx. 5.5:
rewrite(seeAppx. 5.7foradetailedderivation):
N
L≥(cid:88) i=1E qsol(Φ(i)|x( Ci)) {logp(y(i) |Φ(i)) }−R, and L≥V =L−bR≥(cid:88)N E qsol(Φ(i)|x(Ci))(cid:8) logp(cid:0) y(i) |Φ(i)(cid:1)(cid:9) −R
i=1
(8)
R=(cid:88) i=N 1j(cid:88) ∈A(cid:124)D KL(cid:0) q sol(cid:0) φ( ji)
|
(cid:123)x (cid:122)( Ci)(cid:1) ∥p(cid:0) φ( ji) |x( Ci)(cid:1)(cid:1)
(cid:125)
. =(cid:88) i=N 1E p(Φ(i)|x(Ci))(cid:8) logp(cid:0) y(i) |Φ(i)(cid:1)(cid:9) −R
Rij
for0 b 1. (10)
≤ ≤
Remark 2.1. Although the SSV prior is defined so that
it’sexpectationmatchestheESV,themaximumlikelihood Remark 2.3. Forb = 0, theabovelower-boundbecomes
solution of the first loss term above — in the absence of exact, with = . However, this is not desired due to
V L
variationalconstraint —wouldnotnecessarilyenforce aforementionedreasons. Whilemaximizing encourages
alignmentoftheSSVR priormeanswiththeESVvaluesof findingamodelthatexplainsyanditsvarianL ce, guides,
R
interest,leavingtheDGPasameredata-generationanalogy. viaKLminimizationofthevariationalsolution,eachSSV
Notably,as goesto0,theSSVpriorsdistributearoundthe priortodistributearoundESVsϕ( ji).
R
4AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
2.4.VSNLearningviaStochasticGradientDescent Algorithm1Mini-batchSGDlearningofVSN.
To maximize the lower-bound in Eqn. (10), we must Input: Dataset , andhyperparametersβ,p,M
V D
compute gradients of both of its terms. and already Θ Initializeparameters
L R ←
allowformini-batchingoverthedataset,andforthecases whilenotconvergeddo
where isanalyticallytractable,wecanreadilycomputeits Draw i = j 1 j =1, j 1 j Ber(p), i
unbiasL edgradientsefficiently(Bishop&Nasrabadi,2006). DrawC x(i),y{ (i)| M ∀ ∈A}| ∼ ∀
{ C }i=1 ∼D
Draw sˆ(i),sˆ(i) M p(s )foreach x(i),y(i)
H s et sio tl iw l me s acv tae elr e, osc fa µil nc su
oO
lla jt (cid:0) (i 2 xn |g
(
CC i))|µ (cid:1) is . sol aNj v( o ax it la( C ai b) b) l lyi en , (aR Cn aij su tr n re obq i eu a ti sr aee lds .,a s 2t 0s ou 0cm 9h )a :t sh tia ct gD Θ←raw ∇{ { Uj
Θ
p(
V
dˆi) a(}
tΘ
eM i=}
|
u{1i s=
x
i∼ n1
( Ci)
g,∼ U
y g(
r(
i)
a1
}
d,
M i=
id e| )
1
nC
,
tf s{o sˆr g(e i),a sˆc (h
i)
}{
M
ix ={ ( C 1i) ,, {C y j(i) (}
i)
}}
M i=1,β)
µˆ (x(i), sˆ K )
(cid:80)K
k=1µ tot(x( sˆi k),x( ji)) −µ tot(x( sˆi k))
,
endw←
hile
solj C { k }k=1 ≈ K Output: ExplainableVSNmodel,withparametersΘ
(11)
wheresˆ p(s )fork = 1, ,K. Forthegradients
k
∼ |C ···
of ,onemaybetemptedtousethesamplebasedversion
R Overallarchitecture. Webeginbymappingtheinputs
oftheanalyticalsolutioninEqn.(11),i.e.,
x to Z IRd×dZ, where each row of Z represents
∆ij({sˆk}K k=1)
z
∈ =X
emb(x
∈
), calculatedinparallelviaourmaskednet-
(cid:122) (cid:125)(cid:124) (cid:123) j j
R(cid:100)ij(x( Ci), {sˆ
k
}K k=1)=
(µˆ solj(x( Ci),
{
2sˆ
σk
2}K
k=
(x1) (i))−µ θj(x( Ci)))2
,
w ovo er rk xa jr ,ch wi ete rc et pu lr ae c( ese the ed ee mta bil es db de il no gw z). jW ofh xe jn wm ia thrg li en aa rl niz ai bn lg
e
ψj C
(12) baselinevectorb j. Then,wetakealinearcombinationof
which,unfortunately,leadstobiasedgradients. Weinstead theseembeddingswithanaffinetransformationmatrixW,
proposeasurrogate,unbiasedalternative—inwhichforno- andfeedtheresultintoafeedforwardnetworktoobtainµ θj.
tationclarity,andbecauseweuseasinglecoalitionsample
Formodelingσ , weonlyconsiderthedetachedz and
inpracticesˆ p(s ),K =1,weomitsubscriptk.
ψj j
k thedetachedoutputfromµ . Bydetachingthegradients,
∼ |C θj
Proposition2.4. Thesurrogatefunction we prevent information flow to the embedding from the
varianceparameter,whichweempiricallyfoundbeneficial.
R(cid:100)ij(x( Ci),sˆ,sˆ)=d∆ ij 2(i σ) ψ2(sˆ j() i∆ )(xij (( Cii )))(sˆ) , (13) T tah ce hec dho feic ae tuo rf esre zs jtr aic nt din µg θt jh ,e isin topu pt reto vet nh te inσ fψ oj rmne at tw ioo nrk le, at ko ad ge e-
fromotherfeatures. Thisstepistakendueto(contraryto
wherej(i) (1,d),sˆandsˆaresampledindependently µ )thelackofvarianceregularizationpresentintermR
sol ij
∼U
(sˆ sˆ),andthegradientsof∆ (sˆ)aredetached,pro- ofEqn.(9). Specifically,because isadditiveintheuncer-
ij(i)
⊥⊥ L
videsunbiasedestimatesfor . taintyvariables,amodelwithallfeaturestoσ asinputs
∇Θ
R
ψj
wouldnothaveaprinciplewaytoallocatetheuncertainty
Proof. PleaseseeAppx. 5.8foradetailedproof.
acrosseachSSVs’varianceparameters. Onewaytoprevent
Bycombinationofourpropositionsandtheobjective ,we suchaninformationleakageistoonlyusex tomodelthe
V j
introduceamini-batchedvariationalobjectivetomaximize,3 correspondingSSVuncertainty. However,notethatx can
j
havemultipleSSVmeanparameters(i.e.,ESVs)depending
ˆ(Θ x(i),y(i) M , sˆ(i),sˆ(i) M , j(i) M ,β) onotherfeaturesthatparticipateincoalitions. Therefore,
V |{ C }i=1 { }i=1 { }i=1
=
N (cid:32) (cid:88)M β∆ ij(i)(sˆ( ii))∆ ij(i)(sˆ( ii))(cid:33)
,
(14) w toe σuse .in Wfo er fm oa ut nio dn thfr ao tm oux rj aa rcn hd iti ets ctp ur re edi ac lt le od wE sS foV ra res li in ap bu let
M Li − σ2 (x(i)) ψj
i=1 ψj(i) C varianceallocation,asshowninFig. 4. Weillustratedetails
oftheproposedarchitectureinFig. 1.
whichenablesthedesignofamini-batch-basedstochastic
gradient descent (SGD) learning algorithm for VSN, de- Rationaleforembeddedbaselines. State-of-the-arttech-
scribedinAlgorithm1. niquesusedata-spacebaselinevaluestomodelmarginals.
For example, Yoon et al. (2018) uses a baseline of 0 on
2.5.NetworkArchitecture
inputstoenforcemodelmarginalization. However,usinga
In this section, we describe how we leverage neural
fixedvalueintheinputspacecanbemisleading,especially
networks to model SSV prior parameters, µ (x(i)) and
θj C forstructureddata. Analternativeistoappendamasking
σ2 (x(i)),therationaleofourframework,andtheproposed
ψj C vectorξ4alongwiththefeatures,thatarereplacedbybase-
maskedneuralnetworkarchitecturethatenablestheireffi-
cientcomputationacrossfeatures. 4In our case, ξ is a matrix repeated (the number of embed-
3Weshortlydenote bd =β,andnotethateach{sˆ(i),sˆ(i)}pair dingsizetimes)alongthesecondaxis,sincewereplaceanentire
2 i i
aresampledindependentlyforeachx(i). embeddingwithalearnablebaselinevector.
C
5AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
em ma bsk ee dd ding baseline adetaileddescriptionofthemasking-basednetworkbelow,
network replacement
andanillustrativeexampleinAppx. 5.9.
x Z ⊙ξ + Z′ · W
Masking-basedneuralnetwork. AnL-layerneuralnet-
work can be represented by z = act (z W ), where
k k k−1 k
linearcombination z 0 = x⊤ andz L = yˆ. WedefineeachW k = W′ k M k,
B ⊙(1−ξ) ofembeddings whereM arebinarydk dkmaskingmatriceswithd⊙ k d.
k 1× 2 2 ≥
1 1 ... 1 V
A µθrchitectureof ξ=  m0 1 ask1 i... ng.. . m. .. atr0 1 ix  nfe ee td wf oo rr kward µ θ(x) T z Meh re op e (e ilr ,em jm )e ea n >b ti sli 0t oy ,fo thMf et n1h :e L thn ee = rt ewo i(cid:81) srk L k a= nis 1 id M ne ft oke r.r mm aIi nn tie opd nab r fly ti oct wuh le a fn r r, oo mn if-
1:L
ithfeaturetojthoutputneuron(Germainetal.,2015).
detachedµθ(x) concatenate
WebeginbydefiningourinitialmaskingmatrixM as
O 1
(cid:40)
1, if1+(i 1)e j ie 1 +d11
nem m ea tbs wk e oe d rd d king
Z
M 1(ij)=
0,
otherwise−
;
1 ≤ ≤ 1 i̸=d 2 i=d
σ (x)
ψ
Architectureof andM ,fork >1,ascol (M )=sgn(row (M )⊤),
σψ detachedZ
for 1
+k
(i 1)e
jj k
ie 1 +
dki
1
1: ,k− w1
here
− k ≤ ≤ k i̸=d 2 i=d
Figure1.Ournovel,maskednetworkarchitecture. Weindepen- sgn() is the sign function, e = nint(dk/d) for i ,
· k 2 ∈ A
dently generate latent embedding vectors for each feature, and k 1,2,...,L ,anddLisanintegermultipleofd. Here,
replaceabsentfeatureswithabaselinevectorinthisembedding ni∈ nt{ (.)refersto} thenear2 estintegerfunction. Themultipli-
space.Wecomputealinearcombinationoftheseembeddingsto
cationofasequenceofsuchmatriceshavethefollowing
arriveatasinglevector,whichweuseasmodeloutputs.Tocom-
recursion:
putethevariance,weutilizetheinformationinmodelpredictions
andfeaturerepresentationsonly,andletthemodellearnthebest
col (M )=α col (M ), (15)
varianceparametersthatutilizethesetwoinformationsources.
j 1:k i 1+(i−1)ek−1 1:k−1
linevalues(Jethanietal.,2021),whichhasbeenshownto where1+(i 1)e j ie 1 +dk1 ,andα N+
− k ≤ ≤ k i̸=d 2 i=d i ∈
bebeneficial(Miscouridouetal.,2018). fori 1,2,...,d . SincedL isanintegermultipleofd,
∈ { } 2
the columns of M repeat col (M ) e
We, rather than using baseline values in , map each 1:L 1+(i−1)eL−1 1:L−1 L
X numberoftimes.
x to a high-dimensional embedding space, defined as
j
z j = emb(x j); and when x j is marginalized, replace z j Then,d de LmatrixM 1:Lobeys:
with a learnable baseline embedding b . We empirically ×
j (cid:40)
demonstrate the superior performance of these approach γ , forγ >0, if1+(i 1)e j ie
M (ij)= i i − L ≤ ≤ L
withresultsinTable2andmarginalsinFig. 3. 1:L 0, otherwise.
Toembedstructuredfeaturesbeforeinputingthemtoanet-
Forinstance,ford=3,dL =6(i.e.,d =e =2),M
work,weapplyadistinctneuralnetwork-basedembedding 2 Z L 1:L
is(seeastep-by-stepexampleinAppx. 5.9):
toeachinputfeature,independently;contrarytoprevious
workadvocatingforpiece-wiselinearfunctions(Gorishniy  
etal.,2022). Iteratingovereachj toproducefeature
(cid:89)L γ 1 γ 1 0 0 0 0
∈A M k = 0 0 γ 2 γ 2 0 0 .
embeddingsiscomputationallyexpensive,sowepropose
k=1 0 0 0 0 γ 3 γ 3
amaskingtechniquetoexploittheinherentparallelismof
neuralnetworks.
3.Results
Maskedneuralarchitectureshavebeenwidelyadoptedfor
InSec. 3.1,wedemonstrateausefuldiagnostictomonitor
variousapplications,suchasnaturallanguageprocessing
VSN’slearningofESVs. InSec. 3.2,wecompareournovel
anddensityestimation(Vaswanietal.,2017;Devlinetal.,
maskednetworkarchitecture’scapabilitytolearnmarginals
2018;Papamakariosetal.,2017).Ourobjectiveandmethod-
tostandardbaseline-basedfeedforwardapproaches. InSec.
ology diverge here, as our focus is not on sequential or
3.3, we compare VSN’s predictive performance to vari-
auto-regressiveinput-outputmodeling,butonconstructing
ousbenchmarkmodelsonseveralreal-worldandsimulated
high-dimensionalembeddingscontingentuponasingular
datasets. InSec. 3.4, wedemonstratethatVSNprovides
feature. Themaskedneuralnetworkframewokwepropose
meaningfuluncertaintyestimatesforexplanations. Finally,
ensuresanoptimalinformationpropagationacrossthenet-
weassesVSN’sexplainabilityonareal-worldICUmortal-
work’s neurons, enabling the simultaneous generation of
itypredictiondataset,wheremedicallytrainedcollaborators
continuousembeddingsper-feature,inparallel. Weprovide
interpretedVSN’soutput,inAppx. 5.14.
6AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
synthetic1 synthetic2 synthetic3 synthetic4 synthetic5
10 7.5
10 β0.001 β0.001 β0.001 β0.001 10 β0.001 β β0 0. .0 11 5.0 β β0 0. .0 11 β β0 0. .0 11 5.0 β β0 0. .0 11 β β0 0. .0 11
5 β1.0 2.5 β1.0 5 β1.0 2.5 β1.0 5 β1.0
0 0.0 0 0.0
0
0 5000 0 10000 20000 0 10000 0 2500 5000 0 10000 20000
6 β0.001 4 β0.001 β0.001 4 β0.001 10 β0.001
β0.01 β0.01 4 β0.01 β0.01 β0.01
4 β0.1 2 β0.1 β0.1 β0.1 β0.1
β1.0 β1.0 β1.0 2 β1.0 5 β1.0
2
2
0
0 0 0
0
2
0 10000 20000 − 0 25000 50000 0 10000 0 5000 10000 0 10000 20000
Figure2.TheaverageoftheESVsovertheempiricaldataset,E D{µ tot(x(i))−ϕ 0},overtrainingepochs.Shadedregionsaretheerror
valuesfromdifferentcross-validationfolds.Itisclearthattheestimatesconvergetozeroasthemodellearns—thisismostprominentfor
β =1.TheVSNobjectiveenableslearningESVsforbothmaskedandsimplefeedforwardnetworkarchitectures.
synthetic1 synthetic2 synthetic3 synthetic4 synthetic5
2.25 1.0
1.50 3
2.00 10
1.25 2 0.9
1.75
1.00 1 5
masked vanilla masked vanilla masked vanilla masked vanilla masked vanilla
synthetic1 synthetic2 synthetic3 synthetic4 synthetic5
0.50 1.35 1.5
1.14
0.45 1.30 1.6
1.4
1.12 0.40 1.25
1.5
masked vanilla masked vanilla masked vanilla masked vanilla masked vanilla
Figure3.DistancemeasuresofVSN’smarginalstoempiricaldata: comparisonoftheproposedmethodandafeedforwardNNwith
baselinereplacements.▲isthemeanand-isthemedianofresultsacrossfolds,errorbarsdenotethe1.5interquartilerange.
3.1.VSN’sESVLearningDiagnostics thedistancemeasuresfromeachmarginalbythefrequency
WedetermineifVSNiseffectivelylearningESVsbyexam- thattheyappearinEqn.(1),andsumthemtopresentasin-
iningtheevolutionofE
D
µ tot(x(i)s) ϕ
0
overtraining glecomparisonmetric(seeAppx. 5.10fordetails). InFig.
epochs. As highlighted i{ n Sec. 2.2 an− d pr} oved in Appx. 3,wereporttheinterquartilerangesofthesemetricsover
5.4,theaverageoftheESVsovertheempiricaldatashould fivedatasplits,andobservethatthedistanceofthemasked
convergeto0. ResultsdepictedinFig. 2demonstratethat, network’smarginals(bothinitsmeanandmedianstatistics)
duringVSNtraining, E
D
µ tot(x(i)s) ϕ
0
0across isclosertotheempiricalmarginalsforbothmetrics. The
differentnetworkdesignsa{ ndfordiffere− ntβ} va→ lues. These differenceismostapparentforsynthetic1,2,3&5.
experimentssupportVSN’sefficacyandaccuracy,withthe 3.3.PerformanceComparisonstoOtherMLModels
trendbeingespeciallypronouncedwhenβ =1,i.e.,when
WehereassessthepredictiveperformanceofVSNbycom-
thevariationalregularizationismostprominent.
paringittosixbaselines,across11real-worlddatasets: 7
3.2.MarginalDistributionQualityoverDifferent regressionand4classificationtasksusedintheliterature.
Architectures Weprovideacomprehensivedescriptionofbaselinemodels,
We assess the quality of model marginals learned by our datasetsandtheexperimentalsetupinAppx. 5.11. Aver-
novel(masked)networkarchitecturecomparedtoa(vanilla) agedtest-setresultsarepresentedinTable1,withstandard
feedforward network that accepts input masking indica- errordetailsprovidedinAppx. 5.12.
torsandfeaturesreplacedbybaselinevalues. Tomeasure
FromTable1,weconcludethatVSNisarobustcompetitor
thequalityofcomputedmarginals,weconsider(i)Jensen-
towell-knownblack-boxMLmodels,bothforregression
Shannon(JS-),and(ii)Wasserstein(W-)distances. Both
andclassificationtasks. Notably,VSNsurpassesotherself-
determinehowcloselythemodel’smarginalsalignwiththe
explanatorycounterparts(highlighedwithinthedarkgrey
empiricaldatamarginals,wheresmallervaluesarebetter.
area),withaclearadvantageoverEBM.Wecontendthis
Wegeneratesamplesfrombotharchitectures,andmeasure
superioritytoVSN’scapacitytoaccommodateallpotential
thedistancetogroundtruthempiricalmarginals. Weweight
7
krowtendeksaM
krowtenallinaV
ecnegreviD-SJ
ecnatsiD-WAProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
DGP ESV DGP SSV Samples
2 2 5
0 0
0
2 5
2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5
x1 x2 x3
Figure4.ThetrueDGP’sESVvalues(redline),trueSSVvaluesascomputedinAppx.5.13(bluescatter),andtheESVlearnedbyVSN
(greenscatter)withtheircorrespondinguncertaintyintervals(shadedregion,2.5standarddeviations).VSN’svariationalsolutionnotonly
capturestheaveragecontributionofeachx (theexpectedShapleyvaluesoftheDGP)accurately,butalsoprovidescredibleintervals
j
informingaboutthefullrangeofthepotentialattributionofx ontheDGP’soutputs.
j
featureinteractionsatonce,contrarytoEBM’snecessityof NoticeinTable2howariseinβ correlateswithenhanced
incorporatingadifferentflexiblefunctionapproximatorfor performanceforthemaskednetworkstrategy. Wepositthat
eachpotentialfeatureinteraction. by establishing a high-dimensional embedding for every
feature, the model’s capacity is amplified, which, when
Self-explaining Black-box aptlyregularized,translatestobetteroutcomes.
Data VSN LIN EBM RF LGBM XGB DNN
PKSN 0.031 0.867 0.195 0.040 0.072 0.063 0.111 3.4.VSNExplainabilityandUncertaintyQuantification
MED 0.447 0.608 0.447 0.448 0.447 0.454 0.467
BIKE 0.010 0.518 0.038 0.008 0.017 0.013 0.019 WeillustratetheimportanceofmodelingSSVsviaasimu-
PUMA 0.285 1.005 0.326 0.303 0.334 0.345 0.225 latedregressiondataset,withoutputsydefinedbyadditive
GAS 0.273 60.93 0.153 0.151 0.152 0.150 0.256 functionalformsthatallowfortheiranalyticalESVderiva-
WINE 0.474 0.561 0.508 0.478 0.439 0.433 0.444
tions,accordingtothegroundtruthDGP(seeAppx.5.13).
ELEV 0.350 0.593 0.385 0.457 0.373 0.373 0.341
The corresponding SSVs and ESVs are illustrated in Fig.
FICO 0.774 0.766 0.771 0.770 0.773 0.773 0.771
SPAM 0.977 0.946 0.977 0.983 0.982 0.981 0.967 4,alongwithVSN’sestimatedsolution,wherewenotethe
ICU 0.869 0.851 0.872 0.869 0.874 0.874 0.860 stochasticnatureoftheShapleyvaluesofx andx ,incom-
1 2
CENS 0.795 0.768 0.825 0.800 0.830 0.831 0.788
parisontox .WerecallthatESVsdonotmeasurethecontri-
3
Table1.Averagedresultson11real-worlddatasets–seeAppx. butionofanindividualfeaturex onthestochasticoutcome
j
5.12forstandarderrors.WereportRMSEforregression(purple) y,butcapturehowx contributestoy,onaverage—ascal-
j
andPR-AUCforclassification(pink)datasets.LowerRMSEand culatedoverconditionalsp(φ x). Hence,theeffectofan
j
higherPR-AUCscoresarebetter. Weindicatebestperforming individualfeaturex ontheoutc| omecanhavehighvariance,
j
modelsinbold,bestperformingexplainablemodelsinblue.
asexemplifiedbytheDGPdepictedinFig. 4:therearehigh
uncertaintyregionsfor 2.5 x 2.5, 2.5 x and
1 2
Net β synth1 synth2 synth3 synth4 synth5 − ≤ ≤ − ≥
x 2.5. Onthecontrary,thelowuncertaintyregionfor
0.001 0.647 0.003 0.104 0.675 0.430 2 ≥
x impliesthattheeffectofx onyisexactlytheESVfor
0.01 0.637 0.004 0.097 0.674 0.421 3 3
Masked 0.1 0.637 0.003 0.114 0.668 0.414 anydatapoint: i.e.,p(φ 3 x) δ(φ 3 f(x 3)).
| ∼ −
1 0.595 0.006 0.265 0.665 0.389
Fig. 4showcasesthatVSNsuccessfullyidentifiestheSSV
0.001 0.718 0.004 0.462 0.679 0.448
that has no uncertainty (x ), while outputing high uncer-
0.01 0.666 0.004 0.358 0.678 0.444 3
Vanilla
0.1 0.650 0.007 0.231 0.670 0.439 taintyregions—mid-rangeofx 1values,andextremevalues
1 0.640 0.018 0.782 0.670 0.523 ofx —forthecaseswherethetrueeffectofthefeatures
2
(x andx )ontheoutputyvarieswidelyaroundtheESV.
Table2.RMSEresultsofVSNoverdifferentmodelarchitectures 1 2
Knowledge of this uncertainty is critical for trusting the
andβvalues.Thebestresultsareshowninbold.Weobservethat
themaskednetworkoutperformsthewidelyusedbaselinemethods providedexplanations: whileconclusionsdrawnbyVSN
onalldatasets(seeAppx.5.11.2forDGPs). ontheoutputattributionoffeaturex 3 iscertainandtrust-
worthy,thereisuncertaintyonhoweachobservedx and
1
WeadditionallyscrutinizeVSN’sperformanceacrossvari- x feature value may impact y. We emphasize that VSN
2
ousβ valuesandarchitecturesusingfivesimulateddatasets. correctly identifies the deterministic dependencies of the
ResultsinTable2showcasethattheproposedmaskednet- DGP(x )and,atthesametime,quantifiestheuncertainty
3
workdesignexcelsincomparisontotheconventionalap- aroundthestochasticeffects(x andx ).
1 2
proachofhandlingfeatureabsence—specifically,substi-
4.Conclusion
tutingmarginalizedvalueswithbaselinevariablesinputted
toastandardfeedforwardnetwork,accompaniedbytheir WeintroducedVariationalShapleyNetwork(VSN),aself-
maskingindicators. explanatoryprobabilisticmodelwithavariationalinference
8AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
proceduretoestimatedistributionsoverShapleyvalues.The Castro,J.,Gómez,D.,andTejada,J.Polynomialcalculation
modelaccommodatesneuralnetwork-basedlearningona oftheshapleyvaluebasedonsampling. Computers&
latentembeddingspacetoimprovemarginalcomputations, OperationsResearch,36(5):1726–1730,2009.
for which we developed an innovative, efficient masked
Chan,A.,Alaa,A.,Qian,Z.,andVanDerSchaar,M. Un-
networkarchitecture. VSNprovidesadiagnosticmetricto
labelleddataimprovesbayesianuncertaintycalibration
monitor the learning evolution of ESVs through training.
under covariate shift. In International conference on
OurexperimentsindicatethatVSNimprovesmarginaldis-
machinelearning,pp.1392–1402.PMLR,2020.
tributioncomputation,henceenhancingoverallpredictive
performance,whencomparedtovariousbenchmarksacross
Chen,T.andGuestrin,C. Xgboost: AScalableTreeBoost-
arangeofreal-worlddatasets. Importantly,weshowcase
ingSystem. InProceedingsofthe22ndACMSIGKDD
thatVSN’ssolutiondistributionaccuratelycentersaround
InternationalConferenceonKnowledgeDiscoveryand
trueShapleyvalues,andprovidesusefuluncertaintyquan-
DataMining,pp.785–794,2016.
tificationofthestochasticeffectsinherentinobserveddata.
Cortez,P.,Cerdeira,A.,Almeida,F.,Matos,T.,andReis,J.
5.Broaderimpactandethicalaspects.
Modelingwinepreferencesbydataminingfromphysic-
Ourworkpresentsadvancementstothefieldofexplainable ochemicalproperties. Decisionsupportsystems,47(4):
machinelearning. Therearemanypotentialsocietalcon- 547–553,2009.
sequences of our work, specially those related to the use
Covert, I. and Lee, S.-I. Improving kernelshap: Practi-
ofMLforelucidatingmodeldecision-makingprocessesin
calshapleyvalueestimationusinglinearregression. In
real-lifeapplications. However,theimpactisbroadenough
InternationalConferenceonArtificialIntelligenceand
tohighlightanyspecificonehere.
Statistics,pp.3457–3465.PMLR,2021.
References Covert, I., Lundberg, S. M., and Lee, S.-I. Understand-
ingglobalfeaturecontributionswithadditiveimportance
Adebayo, J., Muelly, M., Abelson, H., andKim, B. Post measures. AdvancesinNeuralInformationProcessing
hoc explanations may be ineffective for detecting un- Systems,33:17212–17223,2020.
knownspuriouscorrelation. InInternationalconference
onlearningrepresentations,2021. Covert, I.C., Lundberg, S., andLee, S.-I. Explainingby
removing: Aunifiedframeworkformodelexplanation.
Alaa,A.andVanDerSchaar,M. Discriminativejackknife: TheJournalofMachineLearningResearch,22(1):9477–
Quantifyinguncertaintyindeeplearningviahigher-order 9566,2021.
influencefunctions. InInternationalConferenceonMa-
chineLearning,pp.165–174.PMLR,2020. Datta,A.,Sen,S.,andZick,Y. Algorithmictransparency
viaquantitativeinputinfluence: Theoryandexperiments
Alvarez Melis, D. and Jaakkola, T. Towards robust in- with learning systems. In 2016 IEEE symposium on
terpretabilitywithself-explainingneuralnetworks. Ad- securityandprivacy(SP),pp.598–617.IEEE,2016.
vances in neural information processing systems, 31,
2018. Devlin,J.,Chang,M.-W.,Lee,K.,andToutanova,K. Bert:
Pre-training of deep bidirectional transformers for lan-
Alvarez-Melis, D. and Jaakkola, T. S. On the ro- guageunderstanding. arXivpreprintarXiv:1810.04805,
bustness of interpretability methods. arXiv preprint 2018.
arXiv:1806.08049,2018.
Fanaee-T, H. Bike Sharing Dataset. UCI
Bishop, C.M.andNasrabadi, N.M. Patternrecognition Machine Learning Repository, 2013. DOI:
andmachinelearning,volume4. Springer,2006. https://doi.org/10.24432/C5W894.
Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. FICO. Fico explainable machine learning chal-
Variational Inference: A Review for Statisticians. lenge. https://community.fico.com/s/
https://arxiv.org/abs/1601.00670v9,January2016. explainable-machine-learning-challenge,
2018.
Caruana,R.,Lou,Y.,Gehrke,J.,Koch,P.,Sturm,M.,and
Elhadad,N. IntelligibleModelsforHealthcare: Predict- Flamary,R.,Courty,N.,Gramfort,A.,Alaya,M.Z.,Bois-
ingPneumoniaRiskandHospital30-dayReadmission. bunon,A.,Chambon,S.,Chapel,L.,Corenflos,A.,Fatras,
InProceedingsofthe21thACMSIGKDDinternational K.,Fournier,N.,Gautheron,L.,Gayraud,N.T.,Janati,
conferenceonknowledgediscoveryanddatamining,pp. H.,Rakotomamonjy,A.,Redko,I.,Rolet,A.,Schutz,A.,
1721–1730,2015. Seguy,V.,Sutherland,D.J.,Tavenard,R.,Tong,A.,and
9AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Vayer,T. Pot: Pythonoptimaltransport. JournalofMa- ConferenceonKnowledgeDiscoveryandDataMining,
chineLearningResearch,22(78):1–8,2021. URLhttp: pp.623–631,2013.
//jmlr.org/papers/v22/20-451.html.
Lucas, D. Greenhouse Gas Observing Network.
Germain, M., Gregor, K., Murray, I., and Larochelle, H. UCI Machine Learning Repository, 2015. DOI:
Made: Maskedautoencoderfordistributionestimation. https://doi.org/10.24432/C5JK5M.
InInternationalconferenceonmachinelearning,pp.881–
889.PMLR,2015. Lundberg,S.M.andLee,S.-I. Aunifiedapproachtointer-
pretingmodelpredictions. Advancesinneuralinforma-
Ghahramani, Z. The pumadyn datasets. J. Complex, pp. tionprocessingsystems,30,2017.
1–6,1996.
Lundberg,S.M.,Erion,G.,Chen,H.,DeGrave,A.,Prutkin,
Ghorbani,A.,Abid,A.,andZou,J. Interpretationofneural J. M., Nair, B., Katz, R., Himmelfarb, J., Bansal, N.,
networksisfragile. InProceedingsoftheAAAIconfer- andLee,S.-I. Fromlocalexplanationstoglobalunder-
enceonartificialintelligence,volume33,pp.3681–3688, standingwithexplainableaifortrees. Naturemachine
2019. intelligence,2(1):56–67,2020.
Goldberger, A. L., Amaral, L. A., Glass, L., Hausdorff,
Meredith, M., Raffa, J., Ghassemi, M., Pollard, T.,
J.M.,Ivanov,P.C.,Mark,R.G.,Mietus,J.E.,Moody,
Kalanidhi,S.,Badawi,O.,Matthys,K.,andCeli,L.A.
G.B.,Peng,C.-K.,andStanley,H.E. Physiobank,Phys-
Wids(WomeninDataScience)Datathon2020: IcuMor-
iotoolkit,andPhysionet: componentsofanewresearch talityPrediction. JournalofStatisticsEducation,2020.
resource for complex physiologic signals. circulation,
101(23):e215–e220,2000. Merrick,L.andTaly,A. Theexplanationgame: Explaining
machinelearningmodelsusingshapleyvalues. InMa-
Gorishniy,Y.,Rubachev,I.,andBabenko,A. Onembed-
chineLearningandKnowledgeExtraction: 4thIFIPTC
dingsfornumericalfeaturesintabulardeeplearning. Ad-
5,TC12,WG8.4,WG8.9,WG12.9InternationalCross-
vances in Neural Information Processing Systems, 35:
DomainConference,CD-MAKE2020,Dublin,Ireland,
24991–25004,2022.
August25–28,2020,Proceedings4,pp.17–38.Springer,
2020.
Hopkins, M., Reeber, E., Forman, G., and Suermondt, J.
Spambase. UCI Machine Learning Repository, 1999.
Miscouridou,X.,Perotte,A.,Elhadad,N.,andRanganath,
DOI:https://doi.org/10.24432/C53G6X.
R. Deepsurvivalanalysis: Nonparametricsandmissing-
ness. InMachineLearningforHealthcareConference,
Jethani,N.,Sudarshan,M.,Covert,I.C.,Lee,S.-I.,andRan-
pp.244–256.PMLR,2018.
ganath,R. Fastshap: Real-timeshapleyvalueestimation.
InInternationalConferenceonLearningRepresentations,
Nori,H.,Jenkins,S.,Koch,P.,andCaruana,R. Interpretml:
2021.
AUnifiedFrameworkforMachineLearningInterpretabil-
ity. arXivpreprintarXiv:1909.09223,2019.
Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma,
W.,Ye,Q.,andLiu,T.-Y. Lightgbm: Ahighlyefficient
Papamakarios, G., Pavlakou, T., and Murray, I. Masked
gradientboostingdecisiontree. Advancesinneuralinfor-
autoregressiveflowfordensityestimation. Advancesin
mationprocessingsystems,30,2017.
neuralinformationprocessingsystems,30,2017.
Kohavi,R. CensusIncome. UCIMachineLearningReposi-
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V.,
tory,1996. DOI:https://doi.org/10.24432/C5GP7S.
Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,
Lantz,B. MachineLearningwithR:Experttechniquesfor Weiss,R.,Dubourg,V.,etal. Scikit-learn:Machinelearn-
predictivemodeling. Packtpublishingltd,2019. inginPython. JournalofMachineLearningResearch,
12:2825–2830,2011.
Lee,H.-S.,Zhang,Y.,Zame,W.,Shen,C.,Lee,J.-W.,and
van der Schaar, M. Robust recursive partitioning for Rozemberczki,B.,Watson,L.,Bayer,P.,Yang,H.-T.,Kiss,
heterogeneoustreatmenteffectswithuncertaintyquan- O.,Nilsson,S.,andSarkar,R. Theshapleyvalueinma-
tification. AdvancesinNeuralInformationProcessing chinelearning. arXivpreprintarXiv:2202.05594,2022.
Systems,33:2282–2292,2020.
Rudin, C. Stop explaining black box machine learning
Lou, Y., Caruana, R., Gehrke, J., and Hooker, G. Accu- models for high stakes decisions and use interpretable
rate Intelligible Models with Pairwise Interactions. In modelsinstead. Naturemachineintelligence,1(5):206–
Proceedings of the 19th ACM SIGKDD International 215,2019.
10AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Shapley,L.S.etal. Avalueforn-persongames. 1953.
Slack, D., Hilgard, A., Singh, S., and Lakkaraju, H. Re-
liable post hoc explanations: Modeling uncertainty in
explainability. Advancesinneuralinformationprocess-
ingsystems,34:9391–9404,2021.
Strumbelj,E.andKononenko,I. Anefficientexplanationof
individualclassificationsusinggametheory. TheJournal
ofMachineLearningResearch,11:1–18,2010.
Sundararajan,M.andNajmi,A. Themanyshapleyvalues
for model explanation. In International conference on
machinelearning,pp.9269–9278.PMLR,2020.
Tsanas,A.,Little,M.,McSharry,P.,andRamig,L.Accurate
telemonitoringofparkinson’sdiseaseprogressionbynon-
invasivespeechtests. NaturePrecedings,pp.1–1,2009.
Van den Broeck, G., Lykov, A., Schleich, M., and Suciu,
D. Onthetractabilityofshapexplanations. Journalof
ArtificialIntelligenceResearch,74:851–886,2022.
Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,
L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. At-
tentionisallyouneed. Advancesinneuralinformation
processingsystems,30,2017.
Yoon,J.,Jordon,J.,andvanderSchaar,M.Invase:Instance-
wisevariableselectionusingneuralnetworks. InInterna-
tionalConferenceonLearningRepresentations,2018.
11AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Appendix
5.1.AMathematical,MotivatingExample
Inthissection,weprovideamathematicalexampleforderivingShapleyvaluesintwocomplementaryways: (i)usingthe
trueDGP,and(ii)assumingapost-hocsupervisedMLmodel,trainedonthisDGP.Wethencomparethesetwoexplanations,
andexplainwhy(i)isdesirable.
(cid:16) (cid:17)
Data generating process. Mathematically, we formulate an example DGP as follows: f (x ) x , 1 ,
1 1 ∼ N 1 (x1−10)2
(cid:16) (cid:17)
f (x ) 2x , 1 ,x ( 10,10),x ( 10,10),andy =f(x)=f (x )+f (x ).
2 2 ∼N 2 x2 2 1 ∼U − 2 ∼U − 1 1 2 2
DerivationsbasedonthetrueDGP. WecalculateSV usingthetrueDGP.WebeginbywritingtheequationforSV :
1 1
1 1
SV = (v( 1,2 ) v( 2 ))+ (v( 1 ) v( )) (16)
1 2 { } − { } 2 { } − {}
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(i) (ii)
Thefirstterm:
v( 1,2 ) v( 2 )
{ } − { }
(cid:90) (cid:18) 1 (cid:19)
=y y x , ( 10,10)df dx
− N 1 (x 10)2 U − 1 1
1
−
=f (x )+f (x ) f (x )
1 1 2 2 2 2
−
=f (x ) (17)
1 1
Thesecondterm:
v( 1 ) v( )
{ } − {}
(cid:90) (cid:18) 1 (cid:19)
= y 2x , ( 10,10)df dx
N 2 x2 U − 2 2
2
(cid:90) (cid:18) 1 (cid:19) (cid:18) 1 (cid:19)
y x , ( 10,10) 2x , ( 10,10)df dx df dx
− N 1 (x 10)2 U − N 2 x2 U − 1 1 2 2
1 − 2
=f (x ) 0
1 1
−
=f (x ) (18)
1 1
Hence,
1
SV = (f (x )+f (x ))=f (x ) (19)
1 2 1 1 1 1 1 1
(cid:16) (cid:17)
NoticethattheSV israndom. Precisely,SV =f (x ) x , 1 .
1 1 1 1 ∼N 1 (x1−10)2
WerefertothisvariableasthestochasticShapleyvalue(SSV),asitdefinesanentiredistributionratherthanasinglevalue.
WedenoteSSVswithφ . Inthiscase,φ .
j 1
WithSSVsatourdisposal,wecanreadilycomputetheexpectedShapleyvalue(ESV),denotedwithϕ.
(cid:16) (cid:17)
Inthiscase,ϕ =E φ ,wherep(φ x )isdefinedbytheSSVderivedusingtheDGP:φ x , 1 .
1 p(φ1|x1) { 1 } 1 | 1 1 ∼N 1 (x1−10)2
Hence,ϕ =x .
1 1
TheESVonlyinformsabouttheexpectedvalueoftheSSVratherthanitsentiredistribution.
Post-hocexplanationsbasedonadeterministic,supervisedMLmodel. SupervisedMLmodelsusesummarystatistics
—typically,themodelmean—todescribetheresponse(y),oftenreferredtoasthemodeloutput. Forexample,asupervised
MLmodeltrainedusingthemeansquarederror(MSE)losswouldapproximatetheexpecteddatastatistics.
12AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Letusassumethereexistsasupervisedmodelf′ =f′ +f′ ,thatissufficientlyflexibleandtrainedwithMSElosson
1 2 ∈F
sufficientlylargedata(generatedusingtheaboveDGP).
Wedenotedeterministicfunctionswithf′. Wethenhavef′(x ) δ(f′(x ) x ),f′(x ) δ(f′(x ) 2x ),where
1 1 ∼ 1 1 − 1 2 2 ∼ 2 2 − 2
y′ =f′(x)=f′(x )+f′(x ).
1 1 2 2
Withoutlossofgenerality,weassumethatwehaveaccesstox ( 10,10)andx ( 10,10),andcalculateSV
1 2 1
∼U − ∼U −
usingtheMLmodelasfollows:
1 1
SV = (v( 1,2 ) v( 2 ))+ (v( 1 ) v( )) (20)
1 2 { } − { } 2 { } − {}
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(i) (ii)
Thefirstterm:
v( 1,2 ) v( 2 )
{ } − { }
(cid:90)
=y′ y′δ(f′(x ) x ) ( 10,10)df′dx
− 1 1 − 1 U − 1 1
=f′(x )+f′(x ) f′(x )
1 1 2 2 − 2 2
=f′(x )
1 1
=x sincef′(x ) δ(f′(x ) x ) (21)
1 1 1 ∼ 1 1 − 1
Thesecondterm:
v( 1 ) v( )
{ } − {}
=y′δ(f′(x ) 2x ) ( 10,10)df′dx
2 2 − 2 U − 2 2
(cid:90)
y′δ(f′(x ) x ) ( 10,10)δ(f′(x ) 2x ) ( 10,10)df′dx df′dx
− 1 1 − 1 U − 2 2 − 2 U − 1 1 2 2
=f′(x ) 0
1 1 −
=f′(x )
1 1
=x (22)
1
Hence,
1
SV = (x +x )=x (23)
1 2 1 1 1
Namely,SV δ(x ),whereδistheDiracfunction.
1 1
∼
WecanalsocomputetheESVforthiscase,whichresultsinϕ =E φ =x ,wherep(φ x )isdefinedbythe
1 p(φ1|x1)
{
1
}
1 1
|
1
delta-functionSSVderivedusingtheMLmodel: φ δ(x ). ThisESVmatchestheESVcomputedusingtheDGP.
1 1
∼
Remarks. Post-hocexplanationsofMLmodelstypicallyignoretheinherentrandomnessintheDGP,andrelyonasingle
(cid:16) (cid:17)
pointestimate,whilethereisanentiredistributiontobeleveraged. Weclearlyseethiscomparingφ x , 1
1 ∼N 1 (x1−10)2
derivedusingthetrueDGP,andϕ =x derivedusingpost-hocexplanationoftheMLmodel. Recallthattheliterature
1 1
primarilyfocusesonESVs,whichareequalinbothcases.
TakingonlypointestimatescanbemisleadinginvariousMLsettings. Returningbacktoouroriginalexampleofimage
classificationinSec. 1: Let’sassumex =10representsabluepixel. Usingpost-hocexplanationofthesupervisedML
1
modeloutput,onemightthinkϕ =10hasthehighestpossibleShapleyvalue(recallthatsupp(x ) [ 10,10]). However,
1 1
(cid:16) (cid:17) ∈ −
SSVshowsthatφ x , 1 ,exhibitinghighoutputuncertaintywhenx =10,cautioningusaboutthevalidity
1 ∼N 1 (x1−10)2 1
ofthisexplanation. Hence,wearguethatdistributionalinferenceisimportantforrobustandtrustworthyexplanations.
NotethatthetrueDGPisoftenunknown. Thequestionthenis: Canwederiveflexibleprobabilisticmodelsthatcan
approximatethetrueDGP,andleveragethemtoinferSSVdistributions?
13AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.2.MarginalLog-likelihood
(cid:16) (cid:17) (cid:16) (cid:17)
Webeginbydefining(cid:80) φ(i) (cid:80) µ (x(i)),(cid:80) σ2 (x(i)) using(cid:81) µ (x(i)),σ2 (x(i)) .
j∈A j ∼N j∈A θj C j∈A ψj C j∈AN θj C ψj C
Foranormallikelihood,
   
(cid:90) (cid:90)
(cid:88) (cid:88) (cid:88)
ℓ idΦ(i) =
N
ϕ 0+ φ( ji),σ2 
N
 µ θj(x( Ci)), σ ψ2 j(x( Ci))dΦ(i), (24)
j∈A j∈A j∈A
themarginaloftwonormaldistributionisagainnormalwithmean:
   
(cid:90)
(cid:88) (cid:88) (cid:88) (cid:88)
y(i)
N
ϕ 0+ φ( ji),σ2 
N
 µ θj(x( Ci)), σ ψ2 j(x( Ci))dΦ(i) =ϕ 0+ µ θj(x( Ci)), (25)
j∈A j∈A j∈A j∈A
andvariance
     2
(cid:90)
y(i)2
N
ϕ 0+(cid:88) φ( ji),σ2 
N
(cid:88) µ θj(x( Ci)),(cid:88) σ ψ2 j(x( Ci))dΦ(i) −ϕ 0+(cid:88) µ θj(x( Ci)) (26)
j∈A j∈A j∈A j∈A
 2    2
(cid:90)
(cid:88) (cid:88) (cid:88) (cid:88)
=σ2+  φ( ji)
N
 µ θj(x( Ci)), σ ψ2 j(x( Ci))dΦ(i) − µ θj(x( Ci)) (27)
j∈A j∈A j∈A j∈A
(cid:88)
=σ2+ σ2 (x(i)). (28)
ψj C
j∈A
5.3.TheVSNValueFunction
The expected model output is defined by the prior predictive mean i.e., f(x) = µ (x), hence is a natural choice for
tot
derivingESVs. Wewrite:
(cid:90) (cid:90)
(cid:0) (cid:1)
v(s)= µ (x)p x x dx µ (x)p(x)dx. (29)
tot A\s s A\s tot
| −
Covertetal.(2021)showedthattrainingmodelsbyrandomlyremovingfeaturesindependentlyallowsforlearningpredictions
(cid:0) (cid:1) (cid:82) (cid:0) (cid:1)
marginalizedbydataconditionalp x x . Hence, µ (x)p x x dx =µ (x ). Assuchwewrite,
A\s s tot A\s s A\s tot s
| |
v(s)=µ (x ) µ ( ). (30)
tot s tot
− {}
Giventhat,foradeterministicoutputµ (x ),
tot s
(cid:88)
ESV := p(s )(v(s j) v(s)) (31)
j
|C ∪ −
s⊆C\j
=
(cid:88)
p(s
)(cid:0)
µ (x )
(cid:24)µ(cid:24)(cid:24)
(
(cid:24)
) µ (x
)+(cid:24)µ(cid:24)(cid:24) ((cid:24) )(cid:1)
(32)
tot s∪{j} tot tot s∪{j} tot
|C − {} − {}
s⊆C\j
(cid:88)
= p(s )(v(s j) v(s)) (33)
|C ∪ −
s⊆C\j
(cid:88) (cid:0) (cid:1)
= p(s ) µ (x ) µ (x ) . (34)
tot s∪{j} tot s
|C −
s⊆C\j
Wesimplydefinev (s)=µ (x )andwriteESV succinctlyas:
sol tot s∪{j} j
(cid:88)
p(s )(v (s j) v (s)). (35)
sol sol
|C ∪ −
s⊆C\j
14AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.4.ExpectationofESVsare0
IfSSVsdistributearoundtheESV,thenwecanwriteµ (x(i))=ϕ ,whichis(followingAppx. 5.3):
θj C j
(cid:88)
ϕ = p(s )(v (s j) v (s)). (36)
j sol sol
|C ∪ −
s⊆C\j
Thevaluefunctionisdefinedbymodelpredictionsµ . Theexpectedvalueconcerninginput-features:
tot
(cid:90)
(cid:88)
E ϕ = p(s )(v (s j) v (s))p(x)dx (37)
p(x) j sol sol
{ } |C ∪ −
s⊆C\j
(cid:18)(cid:90) (cid:90) (cid:19)
(cid:88)
= p(s ) µ (x )p(x)dx µ (x )p(x)dx (38)
tot s∪{j} tot s
|C −
s⊆C\j
(cid:88)
= p(s )(µ ( ) µ ( )) (39)
tot tot
|C {} − {}
s⊆C\j
=0 (40)
Inpractice,wedonothaveaccesstop(x). Hence,weapproximateitusingtheempiricaldatadistribution. Inthispaper,we
useheldoutvalidationsetswhengeneratingFig. 2todemonstrateVSN’sgeneralizability.
5.5.VariationalBound
In variational methods, we minimize the KL-divergence distance between two distributions. In our case, a variational
(cid:81) (cid:0) (cid:1)
solutionposteriorq sol(Φ(i) |x( Ci))= j∈Aq sol φ( ji) |x( Ci) andmodelposteriorp(Φ(i) |x( Ci),y(i)):
(cid:32)N N (cid:33)
(cid:89) (cid:89)
minD q (Φ(i) x(i)) p(Φ(i) x(i),y(i)) (41)
KL sol | C ∥ | C
i=1 i=1
(cid:40) N N (cid:41)
(cid:89) (cid:89)
minE (cid:81)N i=1qsol(Φ(i)|x( Ci)) log q sol(Φ(i) |x( Ci)) −log p(Φ(i) |x( Ci),y(i)) (42)
i=1 i=1
N
(cid:88)
min E logq (Φ(i) x(i)) logp(Φ(i) x(i),y(i)) (43)
qsol(Φ(i)|x( Ci)) { sol | C − | C }
i=1
N (cid:26) (cid:27)
(cid:88) p(Φ(i) x(i))p(y(i) Φ(i))
min E
qsol(Φ(i)|x( Ci))
logq sol(Φ(i) |x( Ci)) −log p| (yC
(i)
x(i))| (44)
i=1 | C
N N
(cid:88) (cid:88)
min E logq (Φ(i) x(i)) logp(Φ(i) x(i))p(y(i) Φ(i)) logp(y(i) x(i)) (45)
qsol(Φ(i)|x( Ci)) { sol | C − | C | }− | C
i=1 i=1
Therefore,we
N N N
(cid:88) (cid:88) (cid:88)
max E logp(y(i) Φ(i)) D (q (Φ(i) x(i)) p(Φ(i) x(i))) logp(y(i) x(i)) (46)
qsol(Φ(i)|x( Ci)) { | }− KL sol | C ∥ | C ≤ | C
i=1 i=1 i=1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
R L
N
(cid:88)
max E logp(y(i) Φ(i)) (47)
qsol(Φ(i)|x( Ci))
{ | }−R≤L
i=1
15AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.6.InterchangingExpectedValues
WefirstusetheefficiencypropertyofShapleyvalues,andthedesignchoiceofequivalenceofvariancesbetweenposterior
andprior,toderive
   
(cid:88) (cid:88) (cid:88)
q sol φ( ji) |x( Ci)=
N
 µ θj(x( Ci)), σ ψ2 j(x( Ci)), (48)
j∈A j∈A j∈A
 
(cid:88)
=
N
µ tot(x( Ci)) −ϕ 0, σ ψ2 j(x( Ci)), (49)
j∈A
 
(cid:88)
=p φ(i) x(i) (50)
j | C
j∈A
Now,wecanderive
     
 (cid:88)   (cid:88) 
E
qsol(Φ(i)|x( Ci))
logfϕ 0+ φ( ji) =E
qsol((cid:80) j∈Aφ( ji)|x( Ci))
logfϕ 0+ φ( ji)

(51)
j∈A j∈A
  
 (cid:88) 
=E
p((cid:80) j∈Aφ( ji)|x( Ci))
logfϕ 0+ φ( ji)

(52)
j∈A
  
 (cid:88) 
=E
p(Φ(i)|x(i))
logfϕ 0+ φ( ji) (53)
C  
j∈A
5.7.DerivingaTighterLower-bound
Sincelogisaconcavefunctionweknowthat
     
 (cid:88)   (cid:88) 
E
p(Φ(i)|x( Ci))
logfϕ 0+ φ( ji) ≤logE
p(Φ(i)|x( Ci))
fϕ 0+ φ( ji) . (54)
j∈A j∈A
Since 0,
R≥
N N
(cid:88) (cid:88)
E logp(y(i) Φ(i)) logE p(y(i) Φ(i)) , (55)
p(Φ(i)|x( Ci))
{ | }−R≤
p(Φ(i)|x( Ci))
{ | }−R≤L
i=1 i=1
Notethat,since(cid:80)N logE p(y(i) Φ(i)) = ,wecanscale withb 0. Therefore,thefinallosswemaximize
i=1 p(Φ(i)|x( Ci)) { | } L R ≥
is
= b , (56)
V L− R
ToensureInequality55,weuse0 b 1.
≤ ≤
16AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.8.UnbiasedSurrogateRegularizationFunction
ToshowthatoursurrogateregularizerisunbiasedwetaketheexpectedvalueofitsgradientswithrespecttoΘ:
(cid:40) (cid:40) (cid:40) (cid:41)(cid:41)(cid:41)
∆ (sˆ)∆ (sˆ)
E E E d ij(i) ij(i) (57)
U(1,d) p(s|C) p(s|C) ∇θj(i) 2σ2 (x(i))
ψj(i) C
Sincesˆ sˆ
⊥⊥
(cid:40) E (cid:8) ∆ (sˆ)(cid:9)E (cid:8) ∆ (sˆ)(cid:9)(cid:41)
=E d∇θj(i) p(s|C) ij(i) p(s|C) ij(i) (58)
U(1,d) 2σ2 (x(i))
ψj(i) C
Sincethegradientsof∆ (sˆ)aredetached
ij(i)
=E
(cid:40) d(cid:0) ∇θj(i)E p(s|C)(cid:8) µˆ
sol
j(i)(x( Ci),sˆ)(cid:9) −∇θj(i)µ θj(i)(x( Ci))(cid:1)(cid:0)E p(s|C)(cid:8) µˆ
sol
j(i)(x( Ci),sˆ)(cid:9) −µ θj(i)(x( Ci))(cid:1)(cid:41)
(59)
U(1,d) 2σ2 (x(i))
ψj(i) C
SinceE (cid:8) µˆ (x(i),sˆ)(cid:9) =µ (x(i))
p(s|C) sol j(i) C solj C
(cid:40) (cid:0) (cid:1)(cid:0) (cid:1)(cid:41)
=E d
∇θj(i)µ
sol
j(i)(x( Ci)) −∇θj(i)µ θj(i)(x( Ci)) µ
sol
j(i)(x( Ci)) −µ θj(i)(x( Ci))
(60)
U(1,d) 2σ2 (x(i))
ψj(i) C
(cid:88) 1 (cid:0) (cid:0) (cid:1) (cid:0) (cid:1)(cid:1)
=d D q ϕ x(i) p ϕ x(i) (61)
d∇θj(i) KL sol j(i) | C ∥ j(i) | C
j(i)∈A
(cid:88)
= D (q (ϕ x(i)) p(ϕ x(i))) (62)
∇θj KL sol j | C ∥ j | C
j∈A
Therefore,oursurrogateregularizationfunctionyieldsunbiasedgradientswithrespecttoθ .
j
Notethat hasthesamestepsasabove. Movingforward,wecalculatetheexpectedgradientsofψ :
∇ϕ0 j(i)
(cid:40) (cid:40) (cid:40) (cid:41)(cid:41)(cid:41)
∆ (sˆ)∆ (sˆ)
E E E d ij(i) ij(i) (63)
U(1,d) p(s|C) p(s|C) ∇ψj(i) 2σ2 (x(i))
ψj(i) C
(cid:40) E (cid:8) ∆ (sˆ)(cid:9)E (cid:8) ∆ (sˆ)(cid:9)(cid:41)
=E d p(s|C) ij(i) p(s|C) ij(i) (64)
U(1,d) ∇ψj(i) 2σ2 (x(i))
ψj(i) C
=E
(cid:40) d(cid:0)E p(s|C)(cid:8)
µˆ
sol
j(i)(x(
Ci),sˆ)(cid:9)
−µ θj(i)(x(
Ci))(cid:1)(cid:0)E p(s|C)(cid:8)
µˆ
sol
j(i)(x(
Ci),sˆ)(cid:9)
−µ θj(i)(x(
Ci))(cid:1)(cid:41)
(65)
U(1,d) 2σ2 (x(i))
ψj(i) C
(cid:40) (cid:0) (cid:1)2(cid:41)
=E d
µ
sol
j(i)(x( Ci)) −µ θj(i)(x( Ci))
(66)
U(1,d) ∇ψj(i) 2σ2 (x(i))
ψj(i) C
(cid:88) 1 (cid:0) (cid:0) (cid:1) (cid:0) (cid:1)(cid:1)
=d D q ϕ x(i) p ϕ x(i) (67)
d∇ψj(i) KL sol j(i) | C ∥ j(i) | C
j(i)∈A
(cid:88)
= D (q (ϕ x(i)) p(ϕ x(i))) (68)
∇ψj KL sol j | C ∥ j | C
j∈A
Therefore,oursurrogateregularizationfunctionyieldsunbiasedgradientswithrespecttoψ .
j
Sinceoursurrogatefunctiongivesunbiasedgradientsforθ ,ψ andϕ ,oursurrogatefunctionisunbiasedfor
j j 0
thegradients .
Θ
∇
17AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.9.MaskingOperationsExample
Inthissection,wedemonstrateexamplemaskingmatricesandoperations. Forillustrativepurposes,weusea4layerneural
networkwithhiddendimensions[3,10,10,10,6]. WebeginbydefiningourinitialmaskingmatrixM asdescribedinSec.
1
2.5:
 
1 1 1 0 0 0 0 0 0 0
M 1 = 0 0 0 1 1 1 0 0 0 0 
0 0 0 0 0 0 1 1 1 1
Movingforward,wedefinetheintermediatemaskingmatricesM byrepeatingtherowsofM asdescribedattheend
k 1:k−1
ofSec.2.5inthemainmanuscript:
 
1 1 1 0 0 0 0 0 0 0
 1 1 1 0 0 0 0 0 0 0 
 
 1 1 1 0 0 0 0 0 0 0 
 
 0 0 0 1 1 1 0 0 0 0 
 
 0 0 0 1 1 1 0 0 0 0 
M 2 =  0 0 0 1 1 1 0 0 0 0  
 
 0 0 0 0 0 0 1 1 1 1 
 
 0 0 0 0 0 0 1 1 1 1 
 
 0 0 0 0 0 0 1 1 1 1 
0 0 0 0 0 0 1 1 1 1
 
1 1 1 0 0 0 0 0 0 0
 1 1 1 0 0 0 0 0 0 0 
 
 1 1 1 0 0 0 0 0 0 0 
 
 0 0 0 1 1 1 0 0 0 0 
 
 0 0 0 1 1 1 0 0 0 0 
M 3 =  0 0 0 1 1 1 0 0 0 0  
 
 0 0 0 0 0 0 1 1 1 1 
 
 0 0 0 0 0 0 1 1 1 1 
 
 0 0 0 0 0 0 1 1 1 1 
0 0 0 0 0 0 1 1 1 1
and
 
1 1 0 0 0 0
 1 1 0 0 0 0 
 
 1 1 0 0 0 0 
 
 0 0 1 1 0 0 
 
 0 0 1 1 0 0 
M 4 =  0 0 1 1 0 0  
 
 0 0 0 0 1 1 
 
 0 0 0 0 1 1 
 
 0 0 0 0 1 1 
0 0 0 0 1 1
Nowwecomputethefollowingmatrixmultiplicationwithnon-zeroelementsofM denotingtheinformationflowuntil
1:k
layerk(Germainetal.,2015):
 
3 3 3 0 0 0 0 0 0 0
M 1:2 = 0 0 0 3 3 3 0 0 0 0 
0 0 0 0 0 0 4 4 4 4
NoticethatthecolumnsofM havebeenconstructedbyrepeatingtherowsofM (compare)asdescribedinthemain
3 1:2
manuscript. WenowcomputeM :
1:3
 
9 9 9 0 0 0 0 0 0 0
M 1:3 = 0 0 0 9 9 9 0 0 0 0 
0 0 0 0 0 0 16 16 16 16
18AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
NoticethatthecolumnsofM hasbeenconstructedbyrepeatingtherowsofM .ObservethatM distributes2embedding
4 1:3 4
dimensionsperfeature:
 
27 27 0 0 0 0
M 1:4 = 0 0 27 27 0 0 
0 0 0 0 64 64
 
γ γ 0 0 0 0
1 1
= 0 0 γ 2 γ 2 0 0 
0 0 0 0 γ γ
3 3
NoticethatM allowsforcreatingtwodimensionalembeddingsasitpermitsinformationflowtotwodisjointoutput
1:4
neuronsforeachinputfeature(i.e.,outputsoneandtwoonlydependonx ,outputsthreeandfouronlydependonx ,and
1 2
soforth).
γ valuesdependonhowthe1saredistributedinmaskingmatrices;anequaldistributionwouldresultinmoreuniformγ
i i
values. Inpractice,insteadofusingasinglenint(.)function,wechoosetoroundupordown,randomly. Anexampleof
suchamethodisalsoillustratedbelow:
Wefirstdefinetheinitialmaskingmatrixasfollows
 
1 1 1 1 1 0 0 0 0 0
M 1 = 0 0 0 0 0 1 1 1 0 0 
0 0 0 0 0 0 0 0 1 1
WethendefineM fork >1
k
 
1 1 1 0 0 0 0 0 0 0
 1 1 1 0 0 0 0 0 0 0 
 
 1 1 1 0 0 0 0 0 0 0 
 
 1 1 1 0 0 0 0 0 0 0 
 
 1 1 1 0 0 0 0 0 0 0 
M 2 =  0 0 0 1 1 1 1 0 0 0  
 
 0 0 0 1 1 1 1 0 0 0 
 
 0 0 0 1 1 1 1 0 0 0 
 
 0 0 0 0 0 0 0 1 1 1 
0 0 0 0 0 0 0 1 1 1
 
1 1 1 1 0 0 0 0 0 0
 1 1 1 1 0 0 0 0 0 0 
 
 1 1 1 1 0 0 0 0 0 0 
 
 0 0 0 0 1 1 1 1 0 0 
 
 0 0 0 0 1 1 1 1 0 0 
M 3 =  0 0 0 0 1 1 1 1 0 0  
 
 0 0 0 0 1 1 1 1 0 0 
 
 0 0 0 0 0 0 0 0 1 1 
 
 0 0 0 0 0 0 0 0 1 1 
0 0 0 0 0 0 0 0 1 1
 
1 1 0 0 0 0
 1 1 0 0 0 0 
 
 1 1 0 0 0 0 
 
 1 1 0 0 0 0 
 
 0 0 1 1 0 0 
M 4 =  0 0 1 1 0 0  
 
 0 0 1 1 0 0 
 
 0 0 1 1 0 0 
 
 0 0 0 0 1 1 
0 0 0 0 1 1
19AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Finally,weconfirmthatthemaskmultiplicationsresultindesiredinformationflow
 
5 5 5 0 0 0 0 0 0 0
M 1:2 = 0 0 0 3 3 3 3 0 0 0 
0 0 0 0 0 0 0 2 2 2
 
15 15 15 15 0 0 0 0 0 0
M 1:3 = 0 0 0 0 12 12 12 12 0 0 
0 0 0 0 0 0 0 0 6 6
 
60 60 0 0 0 0
M 1:4 = 0 0 48 48 0 0 
0 0 0 0 12 12
 
γ γ 0 0 0 0
1 1
= 0 0 γ 2 γ 2 0 0 
0 0 0 0 γ γ
3 3
5.10.DistanceMeasures
Inthissection,wedescribeourapproachtomeasurethedistancebetweenthemarginals(namely,p(y,x ))ofournovel
s
maskednetworkarchitectureandfeedforwardarchitecturewithmarginalization(missingness)indicators,ξ.
5.10.1.JENSEN-SHANNONDIVERGENCE
Themetricthatweareinterestedinis 1 (cid:80) (cid:80) p(s )JSD(ModelMarginals,EmpiricalMarginals),which
|A| j∈A s∈A\{j} |A
calculates the distance between marginals for every possible coalition can be made for any given feature j weighted
accordingtoitsShapleyvalueweightsthatareusedduringShapleyvaluecalculations. Thisallowsforarrivingatasingle
metriccalculatedbyweightingthedistancebetweengroundtruthmarginalsandmodelmarginalsbytheiroccurrencein
Shapleyvaluecalculations. Wefollowthebelowsteps.
Definedist=0.
Foreveryfeaturej ands s j :
∈A ∈ ∈A\{ }
1. Empiricalsampling: Sample[y,X] pˆ(y,X)fromempiricaljoint.
∼
2. Empiricalmarginals: Removethecolumnsk / sfrom[y,X]toobtainempiricalmarginals[y,X ].
s
∈
3. Samplefrommodelmarginals: Sampleyˆ p(y X )frommodelusingmaskedand/orvanillanetworkanddefine
s
∼ |
[yˆ,X ]asmodelmarginalsamples.
s
4. Measuredistance: Computedist=dist+ 1 p(s j )JSD(p([y,X ]),p([yˆ,X ])).
|A| |A\{ } s s
Computing JSD(p([y,X ]),p([yˆ,X ])). In order to measure the JS-Divergence between two samples, we arrive at
s s
p([y,X ])andp([yˆ,X ])discretizingtheempiricaldistributionbyfittingahistogramofdifferentbinsizestoboth[y,X]
s s
and[yˆ,X ]. Givensuchadiscretized(multinomial)distribution,JS-Divergencehasaclosed-formsolutionandcanbe
s
computedeasily. Weapplythisforvariousbinsizesbysampling20binsizesfromU(10,200). Wetaketheaverage,which
givesasinglenumber,toapproximateJS-Divergencemetric.
TheerrorbarsinFig. 3aregeneratedbyapplyingtheaboveprocedureto5differentmodelstrainedofdifferenttrain-test
splitsets(5foldcross-validation).
5.10.2.WASSERSTEINDISTANCE
WefollowthesameproceduredescribedinAppx. 5.10.1,withamodificationonStep4whereweuseWD(.,.)instead
ofJSD(.,.). WeusePOT:PythonOptimalTransportsoftwarepackagetocalculatetheWassersteinDistancebetweentwo
empiricalsamplesandreferreaderto(Flamaryetal.,2021)fordetails.
20AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.10.3.COMPARISONTOVANILLANETWORKWITHOUTMISSINGESSINDICATORS(ξ)
InFig. 5,wecomparethequalityofmarginalsofourmaskedapproachandvanillaapproachwithoutmissingnessindicators
(ξ)asinputs. Asexpected,thevanillanetworkwithoutξasinputperformsworsethanthevanillanetworkwithξasinput.
synthetic1 synthetic2 synthetic3 synthetic4 synthetic5
4 4 1.0 20
3 2 0.9
2 10
2 0.8
1
masked vanilla masked vanilla masked vanilla masked vanilla masked vanilla
synthetic1 synthetic2 synthetic3 synthetic4 synthetic5
1.26
1.4
0.6
1.6 1.75
1.24
1.2 1.50
0.4 1.22 1.5
masked vanilla masked vanilla masked vanilla masked vanilla masked vanilla
Figure5.DistanceofVSN’smarginalstotheempiricaldatasamples:comparisonoftheproposedmaskedapproachandafeedforward
approachwithbaselinereplacementwithoutmissingnessindicatorsasinputstovanillanetwork.▲representsthemeanand-represents
themedianfoldresults.Errorbarsdenotethe1.5interquartilerange.
5.11.ExperimentalSetup: BaselinesModels,DatasetsandHyperparameterselection
Inthissectionwedescribethedatasetsandbaselinemodelsusedinourexperiments,aswellasthehyperparameterselection
procedureused.
5.11.1.REAL-WORLDDATASETS
RegressionDatasets. Below,wedescribethedatasetsusedforclassificationtask:
1. Parkinsonstelemonitoring(PKSN):Thedatasetfeaturesvoicedatafrom42Parkinson’spatientsintheearlystages,
capturedoversixmonthsusingatelemonitoringdevicefordistantsymptommonitoring. Theseautonomousrecordings,
takenattheirhomes,total5875datapoints. ThetaskistopredictClinician’smotorUPDRSscore(Tsanasetal.,2009).
2. Medicalexpenses(MED):1,338patientsfromUnitedStates(Lantz,2019). Thetaskistopredictmedicalexpenses.
Here,theunitofmeasurementisUnitedStatesDolars(USD).
3. Bike sharing (BIKE): The dataset of 17,389 entries aims to predict total bike rentals, covering both casual and
registeredusers(Fanaee-T,2013).
4. Pumadyn(PUMA):Thedataset,derivedfromasimulatedUnimationPuma560robotarm’sdynamics,comprises
8,192instances(Ghahramani,1996).
5. Greenhousegasobservingnetwork(GAS):Thedatasetfeaturestimeseriesofgreenhousegasconcentrationsacross
2,921gridcellsinCalifornia,generatedusingtheWRF-Chemsimulationmodel. Thegoalistopredictthegreenhouse
gasconcentration(Lucas,2015).
6. Winequality(WINE):1599redwineinstances. Thetaskistopredictwinequality(Cortezetal.,2009).
7. Elevators(ELEV):ThisdatasetisderivedfromtheF-16aircraftcontroltaskpredictingthestatusofaircraftelevators.
ClassificationDatasets. Below,wedescribethedatasetsusedforclassificationtask:
1. Heloc (FICO): 9,861 credit applications (FICO, 2018). The task is to classify risk performance. The good risk
performanceisrepresentedby1.
21
ecnatsiD-W
ecnegreviD-SJAProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
2. Spambase(SPAM):Theclassificationtaskinvolves4601instancesaimedatdeterminingwhetheragivenemailis
classifiedasspamornot(Hopkinsetal.,1999). Spamemailsarerepresentedby1.
3. Intensivecareunit(ICU):15,830intensivecareunit(ICU)casesfromArgentina,Australia,NewZealand,SriLanka,
Brazil,andUnitedStates(Goldbergeretal.,2000;Meredithetal.,2020). ThetaskistoclassifyICUmortality. The
ICUmortalityisrepresentedby1.
4. Censusincome(CENS):Demographic(suchasage,educationetc.) informationof48,842people. Thetaskisto
predictifthepersonearnsmorethan50,000USDayear(Kohavi,1996). Incomeofmorethan50,000USDayearis
representedby1.
5.11.2.SIMULATEDDATASETS
Inthissectionwedescribethedatageneratingprocessesofthesimulateddatasets. Weemploynon-trivialfunctionswith
heteroscedasticnoiseandcomplexinteractions. Wegenerate8000examplesforeachsyntheticdataset.
Synthetic1. DGP is as described in Sec. 3.4: (i) Draw x(i),x(i),x(i) U( 4,4), (ii) Draw f(i)
(cid:16) (cid:110) (cid:111) (cid:17) (cid:16) 1 2 3 (cid:17) ∼ − 1 ∼
2+exp x(i)2 ,0.6cos(0.03x(i))800 ,f(i) 1+sin( x(i)2 ),0.2x(i) ,andf(i) = 3cos(3x(i))+4sin(5x(i)),
N − 1 1 2 ∼ N − 2 | 2| 3 3 3
(iii)Calculatey(i) =f(i)+f(i)+f(i).
1 2 3
(cid:110) (cid:111)
Synthetic2. (i) Draw x(i),x(i),x(i) U( 4,4), (ii) Calculate f(i) = exp x(i)2 x(i), f(i) = 0.5x(i)sin(x(i)), f(i) =
1 2 3 ∼ − 1 − 1 1 2 2 2 3
cos(3x(i))sin(x(i)),(iii)Calculatey(i) =f(i)+f(i)+f(i).
3 3 1 2 3
Synthetic3. (i)Drawx(i),x(i),x(i) U( 4,4),(ii)Calculatef(i) =4sin(x(i))+2sin(2x(i)),f(i) =3cos(3x(i))sin(5x(i)),
f(i) =cos(2x(i))+x(i)2 /71 ,f(i)2 =3 ex∼ p(cid:8) (− x(i)+x(i))2(cid:9) ,f(i) =(x1 (i) 3)x(i)si1 n(x(i))cos(x(i)1 )/2,f2 (i) =x(i)x(i)/22 ,(iii)Dr2 aw
3 3 3 12 − 1 2 13 1 − 3 1 3 23 2 3
y(i) (f(i)+f(i)+f(i)+f(i) +f(i) +f(i),0.01).
∼N 1 2 3 12 13 23
(cid:110) (cid:111)
Synthetic4. (i) Draw x(i),x(i),x(i) U( 4,4), (ii) Calculate f(i) = exp 1/x(i)2 + sin(100/x(i))), f(i) =
1 2 3 ∼ − 1 − 1 1 2
exp cos(x(i) )+1/2sin(2x(i)) + x(i)/4, f(i) = tanh(x(i)2 ), f(i) = sin(x(i)2 + x(i)2 )/2, (iii) Calculate y(i) =
{−| | 2| 2 |} 2 3 3 12 1 2
f(i)+f(i)+f(i)+f(i).
1 2 3 12
Synthetic5. (i)Drawx(i),x(i),x(i) U( 4,4), (ii)Calculatef(i) = x(i) /10+x(i)2 /10+sin(x(i)), f(i) = cos(5x(i))+
1 (cid:110)2 3 ∼(cid:111) − 1 | 1| 1 1 2 2
sin(2x(i))+x(i), f(i) = exp x(i)100 , f(i) = 5(x(i)10 +x(i)10 )1/10/2, f(i) = 5 sin(x(i)x(i))cos(x(i)x(i))/2, (iii) Draw
2 2 3 − 3 12 1 2 23 | 3 2 3 2 |
y(i) (f(i)+f(i)+f(i)+f(i),0.01).
∼N 1 2 3 12
Theobserveddataareonly x(i),y(i) N pairsforallsimulateddatasets.
{ }i=1
5.11.3.BASELINEMODELS
1. BayesianLinear/LogisticRegression(LIN):Thesimplest,yetthemostexplainablemodel. Linearmodelsquantify
thefeatureimportanceandfeatureimportanceuncertaintythroughthemodelcoefficients. WeuseBayesianlinear
regression for regression and Bayesian logistic regression for classification tasks. We use the implementation by
Pedregosaetal.(2011).
2. ExplainableBoostingMachines(EBM):Thestate-of-the-artexplainableadditivemodelwhichusesanensemble
shallowtreeswithboostingtomodeleachcomponent(Louetal.,2013;Caruanaetal.,2015).Weusetheimplementation
byNorietal.(2019).
3. RandomForest(RF):Anotherensemblelearningalgorithmthatworksbybuildingmultipletreesindependentlyusing
bagging,andaveragingthepredictionsofeachindividualtree. WeusetheimplementationbyPedregosaetal.(2011).
4. LightGradientBoostingMachines(LGBM):LGBMusesaleaf-wisegrowthstrategy,prioritizingsplitsthatresult
inthelargestdecreaseinloss,whereasmosttraditionaltree-basedalgorithmsgrowtreeslevel-wise. Whileleaf-wise
growth can achieve better accuracy, it might also lead to overfitting, especially on smaller datasets. Thus, careful
hyperparametertuning,includingregularization,isessentialwhenusingLGBM(Keetal.,2017).
22AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5. GradientBoostedTrees(XGB):Awell-knownensemblelearningalgorithmthatcombinesseveralweeklearners. In
particular,eachweaklearneristrainedtoimprovetheensembleperformance,oneatatime. Weusetheimplementation
byChen&Guestrin(2016).
6. DeepNeuralNetwork(DNN):Universalfunctionapproximator. DNNsrelateinputandoutputthroughnon-linear
mappings.
5.11.4.HYPERPARAMETERSETTINGS
We sample 100 hyperparameters, train each model on test set and evaluate on the validation set to find the optimum
parametersforlearningatrain-testsplit. Wethentestthemodelsontheremainingtestfold. Wedothis5times. Weuse
NVIDIARTX2080graphicscardfortrainingneuralmodels.
Thehyperparaemtersearchspaceofthemodelsareasfollows:
LIN
• Regressor • Classsifier
param_grid={ param_grid={
"C": [5e-2,1e-1,5e-1,1], "C": [5e-2,1e-1,5e-1,1],
"max_iter":[5000] "max_iter":[5000]
} }
EBM
• Regressor • Classsifier
param_grid={ param_grid={
"outer_bags": [8,25,75,100], "outer_bags": [8,25,75,100],
"inner_bags":[0,1,2,5,10] "inner_bags":[0,1,2,5,10]
} }
RF
• Regressor • Classsifier
param_grid={ param_grid={
"ccp_alpha": [0.0,1e-1,1e-2], "ccp_alpha": [0.0,1e-1,1e-2],
"max_depth": [None,4,8,16,40,100], "max_depth": [None,4,8,16,40,100],
"min_samples_leaf": [1,3,5,10], "min_samples_leaf": [1,3,5,10],
"min_samples_split": [2,4,6,12], "min_samples_split": [2,4,6,12],
"n_estimators": [100,200,600,800] "n_estimators": [100,200,600,800]
} }
23AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
LGBM
• Regressor • Classsifier
param_grid={ param_grid={
"num_leaves": [31,50,70,100], "num_leaves": [31,50,70,100],
"max_depth": [-1,5,7,10], "max_depth": [-1,5,7,10],
"learning_rate": [0.001,0.01,0.05,0.1], "learning_rate": [0.001,0.01,0.05,0.1],
"n_estimators": [100,200,500], "n_estimators": [100,200,500],
"subsample_for_bin": [200000,500000], "subsample_for_bin": [200000,500000],
"min_split_gain": [0.0,0.1,0.5], "min_split_gain": [0.0,0.1,0.5],
"min_child_weight": [1e-3,1e-2,1e-1,1], "min_child_weight": [1e-3,1e-2,1e-1,1],
"min_child_samples": [20,30], "min_child_samples": [20,30],
"subsample": [0.8,0.9,1.0], "subsample": [0.8,0.9,1.0],
"colsample_bytree": [0.7,0.8,0.9,1.0], "colsample_bytree": [0.7,0.8,0.9,1.0],
"reg_alpha": [0,1,2], "reg_alpha": [0,1,2],
"reg_lambda": [0,1,2], "reg_lambda": [0,1,2],
"boosting_type": [’gbdt’,’dart’], "boosting_type": [’gbdt’,’dart’],
} }
XGB
• Regressorparam_grid={ • Classsifier
"learning_rate": [0.05,0.10,0.15,0.30], param_grid={
"max_depth": [3,5,8,15], "learning_rate": [0.05,0.10,0.15,0.30],
"min_child_weight": [1,3,7], "max_depth": [3,5,8,15],
"gamma": [0.0,0.1,0.3], "min_child_weight": [1,3,7],
"colsample_bytree": [0.3,0.4,0.5], "gamma": [0.0,0.1,0.3],
’ccp_alpha’: [0.0,1e-3,1e-2], "colsample_bytree": [0.3,0.4,0.5],
"min_impurity_decrease": [0,1e-1] ’ccp_alpha’: [0.0,1e-3,1e-2],
} "min_impurity_decrease": [0,1e-1]
}
DNN
• Regressor • Classsifier
param_grid={"batch_size": [1024,512], param_grid={"batch_size": [1024,512],
"lr":[5e-4,1e-3,2e-3], "lr":[5e-4,1e-3,2e-3],
"act": [’relu’,’snake’,’elu’], "act": [’relu’,’snake’,’elu’],
"norm":[None,’layer’,’batch’], "norm":[None,’layer’,’batch’],
"n_layers":[2,3,4,5], "n_layers":[2,3,4,5],
"d_hid":[25,50,75,100,200], "d_hid":[25,50,75,100,200],
"weight_decay": [0,1e-10,1e-8,1e-6], "weight_decay": [0,1e-10,1e-8,1e-6],
"dropout": [0,0.2,0.4,0.5], "dropout": [0,0.2,0.4,0.5],
} }
24AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
VSN
• Regressor • Classsifier
param_grid={"batch_size": [1024], param_grid={"batch_size": [1024],
"lr":[1e-3], "lr":[1e-3],
"act": [’relu’,’snake’,’elu’], "act": [’relu’,’snake’,’elu’],
"norm":[None,’layer’], "norm":[None,’layer’],
"n_layers":[4], "n_layers":[4],
"d_hid":[150], "d_hid":[150],
"weight_decay": [0], "weight_decay": [0],
"dropout": [0], "dropout": [0],
"p_missing":[1/2,2/3,’shapley’], "p_missing":[1/2,2/3,’shapley’],
"train_phi0":[True,False] "train_phi0":[True,False]
} }
ForourVSNarchitecture,weemploya4-layermaskedembeddingnetwork,followedbya4-layerfeedforwardneural
network,eachwith150-dimensionallayers. Theembeddingdimensionsarefixedat50. Weconductexperimentsinvolving
thetuningofactivationfunctionsandinvestigatingmissingdatahandling. Specifically,wesettheparameterptovaluesof
1/2,2/3,oralignitwiththeShapleypermutationdistributiondenotedasp(s ). Additionally,wemakeachoicebetween
|C
trainingϕ orkeepingitfixedattheaveragedatasety. Therationaleforthelatterchoiceisthatthelearnedϕ isexpected
0 0
tonaturallyconvergetowardthisvalue,orclosetoit. Therefore,byinitializingitwiththisaveragedatasetresponse,we
facilitatethisconvergenceprocess.
5.12.Results: PredictivePerformanceAveragesandStandardErrors
Inthissection,wepresenttheaveragepredictiveresultswiththeircorrespondingstandarderrorvaluesforbothrealworld
andsimulateddata.
Self-explaining Black-box
Data VSN LIN EBM RF LGBM XGB DNN
PKSN 0.031±0.003 0.867±0.009 0.195±0.002 0.040±0.006 0.072±0.009 0.063±0.002 0.111±0.005
MED 0.447±0.018 0.608±0.015 0.447±0.021 0.448±0.018 0.447±0.020 0.454±0.016 0.467±0.005
BIKE 0.010±0.001 0.518±0.004 0.038±0.001 0.008±0.001 0.017±0.002 0.013±0.001 0.019±0.001
PUMA 0.285±0.003 1.005±0.005 0.326±0.004 0.303±0.005 0.334±0.015 0.345±0.009 0.225±0.003
GAS 0.273±0.043 60.93±60.060 0.153±0.016 0.151±0.015 0.152±0.012 0.150±0.021 0.256±0.019
WINE 0.474±0.021 0.561±0.561 0.508±0.018 0.478±0.019 0.439±0.019 0.433±0.018 0.444±0.015
ELEV 0.350±0.003 0.593±0.100 0.385±0.002 0.457±0.004 0.373±0.002 0.373±0.001 0.341±0.003
FICO 0.774±0.004 0.766±0.004 0.771±0.004 0.770±0.003 0.773±0.005 0.773±0.004 0.771±0.007
SPAM 0.977±0.003 0.946±0.006 0.977±0.003 0.983±0.002 0.982±0.002 0.981±0.003 0.967±0.005
ICU 0.869±0.004 0.851±0.004 0.872±0.004 0.869±0.004 0.874±0.003 0.874±0.003 0.860±0.004
CENS 0.795±0.003 0.768±0.003 0.825±0.003 0.800±0.002 0.830±0.003 0.831±0.004 0.788±0.003
Table3. VSNandbaselinecomparisonacrossreal-worlddatasets.
25AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Net β synth1 synth2 synth3 synth4 synth5
0.001 0.647±0.020 0.003±0.000 0.104±0.004 0.675±0.016 0.430±0.008
0.01 0.637±0.017 0.004±0.001 0.097±0.004 0.674±0.020 0.421±0.007
Masked
0.1 0.637±0.018 0.003±0.000 0.114±0.014 0.668±0.017 0.414±0.005
1 0.595±0.012 0.006±0.001 0.265±0.019 0.665±0.020 0.389±0.010
0.001 0.694±0.012 0.005±0.000 0.590±0.037 0.674±0.013 0.442±0.003
0.01 0.685±0.026 0.004±0.000 0.379±0.113 0.680±0.017 0.437±0.007
Vanilla
0.1 0.668±0.018 0.071±0.062 0.444±0.089 0.687±0.017 0.471±0.043
1 1.258±0.572 0.209±0.070 0.752±0.108 0.680±0.016 1.088±0.423
Table4. Comparisontovanillanetworkwithoutmissingnessindicators(ξ)insimulateddatsets.
Net β synth1 synth2 synth3 synth4 synth5
0.001 0.647±0.020 0.003±0.000 0.104±0.004 0.675±0.016 0.430±0.008
0.01 0.637±0.017 0.004±0.001 0.097±0.004 0.674±0.020 0.421±0.007
Masked
0.1 0.637±0.018 0.003±0.000 0.114±0.014 0.668±0.017 0.414±0.005
1 0.595±0.012 0.006±0.001 0.265±0.019 0.665±0.020 0.389±0.010
0.001 0.718±0.023 0.004±0.000 0.462±0.090 0.679±0.017 0.448±0.005
0.01 0.666±0.016 0.004±0.000 0.358±0.108 0.678±0.017 0.444±0.007
Vanilla
0.1 0.650±0.009 0.007±0.001 0.231±0.073 0.670±0.016 0.439±0.009
1 0.640±0.019 0.018±0.003 0.782±0.296 0.670±0.017 0.523±0.086
Table5. Comparisontovanillanetworkwithmissingnessindicators(ξ)insimulateddatsets.
5.13.ADGPwithStochasticShapleyValues
Weconsidersynthetic1datasetwithbelowgenerativeprocess.
Fori=1,2,...,N:
(i) Drawx(i),x(i),x(i) U( 4,4),
1 2 3 ∼ −
(cid:16) (cid:110) (cid:111) (cid:17) (cid:16) (cid:17)
(ii) Draw φ(i) 2+exp x(i)2 ,0.6cos(0.03x(i))800 , φ(i) 1+sin( x(i)2 ),0.2x(i) , and φ(i) =
1 ∼ N − 1 1 2 ∼ N − 2 | 2| 3
3cos(3x(i))+4sin(5x(i)),
3 3
(iii) Calculatey(i) =φ(i)+φ(i)+φ(i).
1 2 3
Theobserveddataare x(i),y(i) N pairs.
{ }i=1
Given the functional forms of the true DGP and the additive nature of y, ESVs can be easily computed via ϕ =
j
E (cid:8) y E y (cid:9) . Forexample,theESVofx isexp(cid:8) x2(cid:9) (cid:82) U( 4,4)exp(cid:8) x2(cid:9) dx =exp(cid:8) x2(cid:9)
√p(yj|xj) j − p(xj) { j } 1 − 1 − −√ (cid:113) − 1 1 − 1 −
πerf(4),x is1+sin( x2) (cid:82) U( 4,4)(cid:0) 1+sin( x2)(cid:1) dx =sin( x2)+ 2πS(4 2),whereS(.)istheFresnel
8 2 − 2 − − − 2 2 − 2 8 π
(cid:82)
integral, and the ESV of x is 3cos(3x ) + 4sin(5x ) U( 4,4)(3cos(3x )+4sin(5x ))dx = 3cos(3x ) +
3 3 3 3 3 3 3
4sin(5x ) 1sin(12). − −
3 − 4
Asdemonstratedbytheaboveequations,ESVsdonotgivetheexactcontributionofanindividualfeaturex ,ontherandom
j
outcomey,butinformsonaveragehowx contributestoy,wheretheaverageiscalculatedviap(y x )(whichcorresponds
j j j
|
tothelocationparameterofthenormaldistributionsdescribedabove)andshiftedusingthemarginalp(x )=U( 4,4).
j
−
However,thevarianceofy canbehigh,asexemplifiedinourgenerativeprocessandFig. 4,andtherefore,eachindividual
j
contributionofexamplesmightvary. Inthispaper,weshowthatVSNcapturesthisvariabilityincontributions.
26AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
5.14.ExplainabilityonReal-worldDataset: ACaseStudyonIntensiveCareUnitPatients
Gloabalexplanations. Fig. 6showsestimatedShapleyvaluesfor21clinicalfeaturesusedtopredictpatientmortality.
Medicallytrainedcollaboratorsassistedininterpretingthisfigure.
glucose fio2 map paco2 sodium
0.1 0.2 0.2
0.1 0.1
0.0 0.0 0.0
0.0 0.0
0.1 0.1
0.04
40 0.4
0.010
0.2
0.005 20 0.02 0.2
0.000 0 0.00 0.0 0.0
200 400 600 0.25 0.50 0.75 1.00 50 100 150 200 25 50 75 120 140 160
urineoutput gcs eyes gcs verbal intubated bun
0.1
0.2
0.0 0.0 0.0
0.0
0.0
0.2
0.2 0.2
10
0.10
5.0
0.002 5 2.5 20 0.05
0.000 0 0.0 0 0.00
0 2500 5000 7500 1 2 3 4 2 4 0.0 0.5 1.0 0 50 100
wbc age heartrate bilirubin creatinine
0.1 0.2 0.2 0.1
0.0 0.0 0.0
0.0
0.1 0.0 0.1
0.2
1.0
0.050
1.0
0.2
0.025 0.01 0.5 0.5
0.0 0.000 0.00 0.0 0.0
0 20 40 25 50 75 50 100 150 0 20 40 0 5 10
temp ph lactate inr resprate
0.2 0.2 0.1 0.2
0.25
0.00 0.0
0.0 0.0 0.0
0.25 0.1
2
1.0 40 4 0.05
1
0.5 20 2
0.0 0 0 0 0.00
32.5 35.0 37.5 40.0 7.0 7.2 7.4 7.6 0 5 10 15 2 4 6 20 40 60
spo2
0.2
0.0
0.1
0.0
25 50 75 100
Figure6.Location(Shapleyvalues,µ )andscaleparameters(1standarddeviationaroundthemean,σ )ofSSVprior.Thehighervalues
θ Ψ
implyhigherchancesofmortality.Wefitasmoothcurve(black)aroundtheShapleyvaluestodemonstratethetrendandshadetheareas
arounditwithrespecttothestandarddeviationgivenbySSVprior.Largershadedregionsimplymoreuncertainfeaturecontributions,
whilelessshadedregionsimplycertaintyregardingfeaturecontribution.Asanexample,whilemeanarterialbloodpressure(map)and
bilirubinarestrongindicatorsofmortality(withlessuncertainty),thecontributionoffractionalconcentrationofoxygen(fio2)andglucose
tomortalityexhibitshighvariance.
SeveralfeaturessuchasWBC,lactate,INR,andBUNdisplaymontonicallyincreasingShapleyvalues. Thisissensible,
since higher values for these variables confer worse patient state (infection, inflammation, reduced coaguability, renal
27
tnuoC
tnuoC
tnuoC
tnuoC
tnuoCAProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
insufficiency,respectively). Similarly,ShapleyvaluesforGlascowcomascale(GCS)variablesdecreasemonotonically.
ThisisconsistentaslowerGCSscoresimplythepatientislessconcious.
Otherfeaturesdisplaynon-monotonicShapleyvalues. Thesevariableshavearelativelynarrownormalrangeoutsideof
whichpatientstatemaydecline. Forexample,normaltemperatureis36.5◦-37.5◦ CandcorrespondstoaShapleyvalue
nadir. SimilarShapleyvaluenadirsareobservedatthenormalrangesforheartrate(60-100BPM),respiratoryrate(15-20
BPM),pH(7.32-7.42),urineoutput(.8-2L),andsodium(135-145mEq/L).
Localexplanations. Fig. 7presentsthemortalitypredictionforfouruniquepatients,highlightingboththepriorpredictive
mean(labeledasPred’)andtheassociateduncertainty(labeledasErr’)alongwithfeaturespecificSSVuncertainties.
The uncertainty embedded in these predictions is vital for clinicians to understand the potential severity of a patient’s
condition. Forexample,patientsthatareseeminglyingoodconditionscanunexpectedlyturncritical. Thisvarianceis
capturedinVSNthroughthepredictiveuncertainty. Suchinsightsareinvaluable,particularlyinhigh-stakesenvironments
liketheICU,wheretheycanguideclinicaldecisionsbyacknowledgingtheinherentvariabilityinpatientoutcomes.
TheuncertaintyinSSVsinformscliniciansonhowcriticaleachfeatureisforpatientoutcomevariability. Forexample,
predictionsofFalsepositivepatientsexhibithighvariabilityduetolactate,raisingimportantquestions: Whydoesthis
biomarkerexhibithighoutcomevariabilityforthispatient? Howdowereducethevariabilitycausedbythisbiomarker?
28AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
True: 0.0 Pred: 0.4614 Err: 0.2695 True: 1.0 Pred: 0.2448 Err: 0.5709
\phi_0 0.5 \phi_0 0.5
lactate (6.8) 0.18 gcs-verbal (1.0) 0.28
map (40.0) 0.15 bun (19.0) 0.04
ph (7.25) 0.09 lactate (2.0) 0.03
gcs-verbal (1.0) 0.07 glucose (133.0) 0.03
intubated (1.0) 0.06 paco2 (40.0) 0.01
heart rate (120.0) 0.03 wbc (10.4) 0.01
bun (23.0) 0.02 creatinine (0.98) 0.01
wbc (18.0) 0.01 ph (7.36)
creatinine (1.55) 0.0 inr (1.3)
spo2 (100.0) bilirubin (0.6)
resprate (20.0) heart rate (102.0)
inr (1.5) intubated (0.0)
paco2 (38.7) temp (35.9)
sodium (140.0) sodium (138.0)
temp (36.0) resprate (18.0)
bilirubin (0.6) fio2 (0.5)
fio2 (0.5) spo2 (97.0)
glucose (89.0) map (113.0)
gcs-eyes (1.0) urineoutput (1534.032)
urineoutput (2353.968) gcs-eyes (3.0)
age (31.0) age (50.0)
0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
True: 0.0 Pred: 0.5501 Err: 0.5304 True: 1.0 Pred: 1.1781 Err: 0.2
\phi_0 0.5 \phi_0 0.5
gcs-verbal (1.0) 0.26 spo2 (81.5) 0.17
resprate (23.5) 0.03 map (40.0) 0.14
glucose (133.0) 0.03 lactate (9.6) 0.1
age (71.0) 0.03 temp (32.8) 0.1
bun (19.0) 0.03 gcs-verbal (1.0) 0.09
urineoutput (1386.202) 0.02 bun (37.0) 0.05
creatinine (0.98) 0.01 wbc (45.8) 0.03
paco2 (40.0) 0.01 inr (3.0) 0.03
bilirubin (0.6) 0.01 gcs-eyes (4.0) 0.03
lactate (1.7) 0.0 creatinine (1.77) 0.02
wbc (10.4) age (65.0) 0.01
ph (7.36) urineoutput (1386.202) 0.01
intubated (0.0) ph (7.36) 0.01
sodium (138.0) glucose (240.0) 0.0
temp (35.77) intubated (0.0)
heart rate (97.0) fio2 (0.5)
spo2 (98.0) resprate (15.5)
inr (1.0) sodium (132.0)
fio2 (0.5) bilirubin (0.6)
map (66.0) heart rate (50.0)
gcs-eyes (4.0) paco2 (40.0)
0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.0 0.1 0.2 0.3 0.4 0.5
Figure7.AssessmentofVSN’sinterpretabilityacrossfourdistinctICUpatientsformortalitypredictiononaconfusiontable. ‘True’
representsactualoutcomes,‘Pred’standsformodelpredictivemean(sumofESVsandϕ ),and’Err’reflectstheoveralluncertaintyin
0
predictions.ESVsforspecificfeaturesaredenotedbycoloredbars,whereastheuncertaintyinthesevariablesismarkedbyblacklines.
Elevateduncertaintyinexplanatoryvariablesshouldpromptpractitionerstoreconsiderboththesignificanceofthesefeaturesandthe
reliabilityofthepredictions.
5.14.1.RELEVANCEANDAPPLICATIONS
Importanceoftheglobalview. Theplotsmentionedpreviouslyplayacrucialroleinmodeldiagnostics. Forinstance,
Caruanaetal.(2015)discoveredthatinpredictingtheriskofpneumonia,modelstendtoallocatelowerriskscorestopatients
withasthmausingsuchglobalviewplots. Thisphenomenonarisesfromtheintensivetreatmentstypicallyadministeredto
patientswiththesecoexistingconditions. Uncriticallyacceptingtheselow-riskscoresfrommodelsforpatientscouldresult
ininappropriatenon-hospitalizationofpatientswhoareactuallyinpoorhealth.
Inourcase,weobservethatthemodelcannotcaptureoptimumcreatininevalues: Themodelassignslowermortalitytohigh
creatininevalues,whichiscounterintuitive. Thismightbeduetoaconfounderaffectingthecontributionsofcreatininethat
needfurtherinvestigation. VSNinformspractitionersregardingsuchpathologiesindata.
29AProbabilisticApproachtoSelf-ExplainingShapleyValueswithUncertaintyQuantification
Reasoning about trusthworthy features. While we observe that features like map, sodium, bilirubin, gcs-verbal
demonstratesmallervariancevalues,glucose,fio2,inr,gcs-eyedemonstrateshighervariancevalues.
Forexample, glucoseisnotareliableindicatorofICUmortality, ashighglucoselevelscanbeassociatedwithseveral
non-fatalpathologiessuchasdehydration,over-treatinghypoglycemia,anddiabetes. Whiletheseconditionsarenotdirectly
lethal, they may lead to more serious complications like heart-related problems. Elevated glucose levels should thus
beinterpretedwithinabroaderclinicalcontext,takingintoaccountapatient’soverallhealthandmedicalhistory. This
comprehensiveapproachiscrucialbecause,althoughnotdirectlyfatal,theseconditionscancontributetolong-termhealth
issuesthatincreasemortalityrisk,makingglucoseasignificantbutnotsolitaryindicatorofhealthstatus.
Asanotherexample,theinternationalnormalizedratio(INR),akeymeasureofbloodclottingusedparticularlyforpatients
onanticoagulantslikewarfarin,isinfluencedbyarangeoffactorsincludingdiet,certainmedications,alcoholconsumption,
andliverfunction. ThesefactorscontributetothevariabilityofINRvalues,makingthemlessreliableassoleindicators
ofICUmortality. Diet,especiallyfoodsrichinvitaminK,canaffectINRlevels,ascaninteractionswithvariousdrugs.
Alcohol use has a complex relationship with INR; chronic use may increase it, while acute use can have the opposite
effect. Additionally,liverhealthiscrucial,asitplaysavitalroleinproducingclottingfactors. Thisvariability,alongwith
theinfluenceofexternalfactors,underscoresthechallengeofusingINRvaluesalonetoaccuratelyinferICUmortality,
reflectingtheneedforacomprehensiveassessmentofapatient’soverallhealthandmedicalhistoryincriticalcaresettings.
Knowing the variability of explanations is important to summarize/filter the information ( i.e., what to present to the
practitioners)wheresummarizingaccurateinformationinashorttimeperiodsiscrucialintime-sensitivesettingssuchas
treatingICUpatients.
30