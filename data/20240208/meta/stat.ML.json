[
    {
        "title": "Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification",
        "authors": "Mert KetenciIñigo UrteagaVictor Alfonso RodriguezNoémie ElhadadAdler Perotte",
        "links": "http://arxiv.org/abs/2402.04211v1",
        "entry_id": "http://arxiv.org/abs/2402.04211v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04211v1",
        "summary": "Shapley values have emerged as a foundational tool in machine learning (ML)\nfor elucidating model decision-making processes. Despite their widespread\nadoption and unique ability to satisfy essential explainability axioms,\ncomputational challenges persist in their estimation when ($i$) evaluating a\nmodel over all possible subset of input feature combinations, ($ii$) estimating\nmodel marginals, and ($iii$) addressing variability in explanations. We\nintroduce a novel, self-explaining method that simplifies the computation of\nShapley values significantly, requiring only a single forward pass. Recognizing\nthe deterministic treatment of Shapley values as a limitation, we explore\nincorporating a probabilistic framework to capture the inherent uncertainty in\nexplanations. Unlike alternatives, our technique does not rely directly on the\nobserved data space to estimate marginals; instead, it uses adaptable baseline\nvalues derived from a latent, feature-specific embedding space, generated by a\nnovel masked neural network architecture. Evaluations on simulated and real\ndatasets underscore our technique's robust predictive and explanatory\nperformance.",
        "updated": "2024-02-06 18:09:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04211v1"
    },
    {
        "title": "Scaling Laws for Downstream Task Performance of Large Language Models",
        "authors": "Berivan IsikNatalia PonomarevaHussein HazimehDimitris PaparasSergei VassilvitskiiSanmi Koyejo",
        "links": "http://arxiv.org/abs/2402.04177v1",
        "entry_id": "http://arxiv.org/abs/2402.04177v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04177v1",
        "summary": "Scaling laws provide important insights that can guide the design of large\nlanguage models (LLMs). Existing work has primarily focused on studying scaling\nlaws for pretraining (upstream) loss. However, in transfer learning settings,\nin which LLMs are pretrained on an unsupervised dataset and then finetuned on a\ndownstream task, we often also care about the downstream performance. In this\nwork, we study the scaling behavior in a transfer learning setting, where LLMs\nare finetuned for machine translation tasks. Specifically, we investigate how\nthe choice of the pretraining data and its size affect downstream performance\n(translation quality) as judged by two metrics: downstream cross-entropy and\nBLEU score. Our experiments indicate that the size of the finetuning dataset\nand the distribution alignment between the pretraining and downstream data\nsignificantly influence the scaling behavior. With sufficient alignment, both\ndownstream cross-entropy and BLEU score improve monotonically with more\npretraining data. In such cases, we show that it is possible to predict the\ndownstream BLEU score with good accuracy using a log-law. However, there are\nalso cases where moderate misalignment causes the BLEU score to fluctuate or\nget worse with more pretraining, whereas downstream cross-entropy monotonically\nimproves. By analyzing these observations, we provide new practical insights\nfor choosing appropriate pretraining data.",
        "updated": "2024-02-06 17:31:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04177v1"
    },
    {
        "title": "Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains",
        "authors": "Ashok Vardhan MakkuvaMarco BondaschiAdway GirishAlliot NagleMartin JaggiHyeji KimMichael Gastpar",
        "links": "http://arxiv.org/abs/2402.04161v1",
        "entry_id": "http://arxiv.org/abs/2402.04161v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04161v1",
        "summary": "In recent years, attention-based transformers have achieved tremendous\nsuccess across a variety of disciplines including natural languages. A key\ningredient behind their success is the generative pretraining procedure, during\nwhich these models are trained on a large text corpus in an auto-regressive\nmanner. To shed light on this phenomenon, we propose a new framework that\nallows both theory and systematic experiments to study the sequential modeling\ncapabilities of transformers through the lens of Markov chains. Inspired by the\nMarkovianity of natural languages, we model the data as a Markovian source and\nutilize this framework to systematically study the interplay between the\ndata-distributional properties, the transformer architecture, the learnt\ndistribution, and the final model performance. In particular, we theoretically\ncharacterize the loss landscape of single-layer transformers and show the\nexistence of global minima and bad local minima contingent upon the specific\ndata characteristics and the transformer architecture. Backed by experiments,\nwe demonstrate that our theoretical findings are in congruence with the\nempirical results. We further investigate these findings in the broader context\nof higher order Markov chains and deeper architectures, and outline open\nproblems in this arena. Code is available at\n\\url{https://github.com/Bond1995/Markov}.",
        "updated": "2024-02-06 17:18:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04161v1"
    },
    {
        "title": "Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process",
        "authors": "Sandipp Krishnan RaviYigitcan ComlekWei ChenArjun PathakVipul GuptaRajnikant UmretiyaAndrew HoffmanGhanshyam PilaniaPiyush PanditaSayan GhoshNathaniel MckeeverLiping Wang",
        "links": "http://arxiv.org/abs/2402.04146v1",
        "entry_id": "http://arxiv.org/abs/2402.04146v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04146v1",
        "summary": "With the advent of artificial intelligence (AI) and machine learning (ML),\nvarious domains of science and engineering communites has leveraged data-driven\nsurrogates to model complex systems from numerous sources of information\n(data). The proliferation has led to significant reduction in cost and time\ninvolved in development of superior systems designed to perform specific\nfunctionalities. A high proposition of such surrogates are built extensively\nfusing multiple sources of data, may it be published papers, patents, open\nrepositories, or other resources. However, not much attention has been paid to\nthe differences in quality and comprehensiveness of the known and unknown\nunderlying physical parameters of the information sources that could have\ndownstream implications during system optimization. Towards resolving this\nissue, a multi-source data fusion framework based on Latent Variable Gaussian\nProcess (LVGP) is proposed. The individual data sources are tagged as a\ncharacteristic categorical variable that are mapped into a physically\ninterpretable latent space, allowing the development of source-aware data\nfusion modeling. Additionally, a dissimilarity metric based on the latent\nvariables of LVGP is introduced to study and understand the differences in the\nsources of data. The proposed approach is demonstrated on and analyzed through\ntwo mathematical (representative parabola problem, 2D Ackley function) and two\nmaterials science (design of FeCrAl and SmCoFe alloys) case studies. From the\ncase studies, it is observed that compared to using single-source and source\nunaware ML models, the proposed multi-source data fusion framework can provide\nbetter predictions for sparse-data problems, interpretability regarding the\nsources, and enhanced modeling capabilities by taking advantage of the\ncorrelations and relationships among different sources.",
        "updated": "2024-02-06 16:54:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04146v1"
    },
    {
        "title": "SCAFFLSA: Quantifying and Eliminating Heterogeneity Bias in Federated Linear Stochastic Approximation and Temporal Difference Learning",
        "authors": "Paul MangoldSergey SamsonovSafwan LabbiIlya LevinReda AlamiAlexey NaumovEric Moulines",
        "links": "http://arxiv.org/abs/2402.04114v1",
        "entry_id": "http://arxiv.org/abs/2402.04114v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04114v1",
        "summary": "In this paper, we perform a non-asymptotic analysis of the federated linear\nstochastic approximation (FedLSA) algorithm. We explicitly quantify the bias\nintroduced by local training with heterogeneous agents, and investigate the\nsample complexity of the algorithm. We show that the communication complexity\nof FedLSA scales polynomially with the desired precision $\\epsilon$, which\nlimits the benefits of federation. To overcome this, we propose SCAFFLSA, a\nnovel variant of FedLSA, that uses control variates to correct the bias of\nlocal training, and prove its convergence without assumptions on statistical\nheterogeneity. We apply the proposed methodology to federated temporal\ndifference learning with linear function approximation, and analyze the\ncorresponding complexity improvements.",
        "updated": "2024-02-06 16:06:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04114v1"
    }
]