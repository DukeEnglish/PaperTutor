Autonomous Agents for Collaborative Task under
Information Asymmetry
WeiLiu⋆† ChenxiWang⋆† YifeiWang⋆ ZihaoXie⋆ RennaiQiu⋆ YufanDang⋆
ZhuoyunDu⋆ WeizeChen⋆ ChengYang♣(cid:66) ChenQian⋆(cid:66)
⋆TsinghuaUniversity ♣BeijingUniversityofPostsandTelecommunications
thinkwee2767@gmail.com yangcheng@bupt.edu.cn qianc62@gmail.com
Abstract
LargeLanguageModelMulti-AgentSystems(LLM-MAS)haveachievedgreat
progressinsolvingcomplextasks.Itperformscommunicationamongagentswithin
thesystemtocollaborativelysolvetasks,underthepremiseofsharedinformation.
However,whenagents’communicationisleveragedtoenhancehumancooperation,
anewchallengearisesduetoinformationasymmetry,sinceeachagentcanonly
accesstheinformationofitshumanuser. PreviousMASstruggletocompletetasks
underthiscondition. Toaddressthis,weproposeanewMASparadigmtermed
iAgents,whichdenotesInformativeMulti-AgentSystems. IniAgents,thehuman
socialnetworkismirroredintheagentnetwork,whereagentsproactivelyexchange
humaninformationnecessaryfortaskresolution,therebyovercominginformation
asymmetry. iAgents employs a novel agent reasoning mechanism, InfoNav, to
navigateagents’communicationtowardseffectiveinformationexchange. Together
withInfoNav,iAgentsorganizeshumaninformationinamixedmemorytoprovide
agentswithaccurateandcomprehensiveinformationforexchange. Additionally,
weintroduceInformativeBench,thefirstbenchmarktailoredforevaluatingLLM
agents’task-solvingabilityunderinformationasymmetry. Experimentalresults
show that iAgents can collaborate within a social network of 140 individuals
and 588 relationships, autonomously communicate over 30 turns, and retrieve
informationfromnearly70,000messagestocompletetaskswithin3minutes.
“A friend is someone with whom there is mutual understanding, emotional support, and shared
experiences.”
—–Joey’sandChandler’sagents’discussionontheword"friend",
afterexperiencingthewholeFriendsseasononestory.
1 Introduction
There has been notable progress in autonomous agents driven by the Large Language Model
(LLM) [42, 5, 6, 41], especially in developing communicative agents for completing collabora-
tivetasks[51,43,11,36,15,39,26,60],asshowninFigure1a. Inthesemulti-agentsystems(MAS),
multipleagentsarecreatedthroughrole-playprompting[25]toimitatetheabilityofhumanexperts
andformavirtualentity(e.g.,anagentcompanyorhospital)toprovidesolutionsderivedfromagents’
communication. Agentssharecontextinthevirtualentitytofacilitatecollectivedecision-making.
Giventhatautonomouscommunicationamongagentshasachievedsignificantsuccessindiscussing,
decomposing,andresolvingvariouscomplextasks,anaturalideaistointroducesuchautonomous
†:EqualContributions.
(cid:66):CorrespondingAuthors.
Preprint.Underreview.
4202
nuJ
12
]IA.sc[
1v82941.6042:viXraBefore Agentization Before Agentization
CEO Charlie Bob
“I want a software of …….” CFO CTO DirA er ct tor CPO as HumBo ab n User “ aL ne dt ’ ms c ah ke ec ak sw chit eh d a ul ll e c o foll re mag eu ee ts in g ” Alice
Bob Dave
as Human User Emily
AccountantProgrammer Programmer PM PM PM Alice Kent
as Human User
Agentization Agentization
“YoR uol e- aPl ray e Pr aom p Cti Eng O……” Alice Assign Alice’s Agent
Kn io nw Ll Le Mdge “You are a CFO……” Dave Assign Dave’s Agent
“You are a CTO……” Assign
Emily Emily’s Agent
Agents Serve as a Entity Virtual Company AC gE eO nt Agents Ser Sv ue mm w oni At gh eni tn Networ “k Let’sworkonbehalfofAlice Ch Aa gr eli ne t’s Bob’s Agent
andBobtocheckwithall
Bob
“I want a software of …….” AC gF eO nt AC gT eO nt D AirA ger ect nt o tr AC gP eO nt as HumBo ab n User B Ao geb n’s t c sco hll ee da ugu lee fs orman ed etinm g”ake a E Am gi ely n’ ts D Aa gv ee n’s t
as Human User Summon Agent Alice’s
Agent
Acc Ao gu en nt tantPro Agr ga em ntmerPro Agr ga em ntmer AP gM en tAP gM en tAP gM en t as HuA mli ac ne User A Al gic ee n’ ts Kent’s Agent
a) Previous multi-agent system forms a virtual entity to provide b) iAgentsmirrors the human network where agents work on behalf of human
solutions to human user. users within the network.
Figure 1: Comparison between previous MAS and iAgents. The visibility range of information
for each agent is highlighted with a colored background. In the previous MAS, all agents share
allinformation(coloredbackgroundofVirtualCompany), soitonlyworksunderthepremiseof
sharedcontext. IniAgents,eachagentonlyseesinformationofitshumanuser(differentcolored
backgroundsofcartooncharacters),andiAgentsisdesignedtodealwithinformationasymmetry.
communicationintohumansocietytoenhancecollaborationefficiencyamonghumans. However,
whenwemanagetoassigneachhumanwithanagent,establishingamappingfromthehumansocial
networktotheagentnetworksoautonomouscommunicationamongagentscanfacilitatehuman
cooperation,anewchallengearises. Thischallengeinvolvesdealingwithasymmetry[44,40]in
varioustypesofinformation(environment,goals,andmindstate)[63,62,34,6,52]sinceeachagent
canonlyobservetheinformationofitshumanuser. PreviousLLM-MASarenotsuitableforhandling
thisscenario,because1)humaninformationissensitiveandprivate,sotheasymmetrycannotbe
resolvedbydirectlycollectingallinformationintooneplaceandsharingitasthecontextforMAS.
2)Humaninformationisdynamicsoitcannotbeeasilymemorizedduringpre-trainingandactivated
accuratelythroughrole-playpromptinginMAStoavoidasymmetry. Essentially,agents’cooperation
inpreviousMAShasadoptedanintrospectiveapproachwithinthevirtualentity,whichstrugglesto
dealwithasymmetryinhumaninformation.
Tobridgegapsinsuchasymmetry,agentsneedtoretrieveinformationfromhumans,andproactively
exchangeinformationwitheachother,creatinganewecosystemcombiningthehumannetworkand
theagentnetwork. Therefore,weproposetheconceptofiAgents(InformativeMulti-AgentSystems)1
for achieving this kind of collaboration, as shown in Figure 1b. iAgents utilizes a new method
foragentreasoning(InfoNav)whichmodelstheagents’mindsandnavigatesagents’autonomous
communicationtowardproactiveinformationexchange. Furthermore,anewmemorymechanismis
designedtoprovideagentswithaccurateandcomprehensiveinformationforexchange. Additionally,
we introduced InformativeBench, the first benchmark evaluating agents’ collaboration in social
networkswithinformationasymmetry. Itincludesbothinformation-seekingtasksforevaluating
agents’abilitytoresolveasymmetryinalargeamountofinformation,andcomplexalgorithm-like
tasksthatfocusonevaluatingagents’abilitytocollaborativelyreasonunderinformationasymmetry.
We found that iAgents could perform effective communication and collaboration within a social
networkof(showninFigure5)140individualsand588relationships,andacrossover30dialogues
theysearchednearly70,000messagesandresolvedthetaskwithin3minutes. Despitesuchcases
where iAgents exhibit impressive performance, agents with some state-of-the-art LLM backends
achieved an average accuracy of 50.48% on InformativeBench, with the most challenging task
achievingonly22.8%accuracy,whichrevealsbothpotentialpromiseandchallengesinthisdirection.
1Availableonhttps://github.com/thinkwee/iAgents
2Alice’s SubNet Resolved Task
Mixed Memory for Alice’s Agent Agents’ Planning
Human Relationship
Charlie Distinct Memory
Bob Alice’s Agent Fuzzy Memory
Alice
Dave “ tale st k’ ss fc oo rm Am licu en aic na dte Boa bn !d ”solve “ i cn oI fg uoo lr dt m yn a oo t u io tn e, l l “ i ts eO … llf … mco , eau …nrs d …e .p! ” lH ee ar se e “ ag no dt … it …! ” “ inN foo rw m I ak tn ioo nw I a nl el eth de … …” ✅✅
me……” ✅✅
Emily Bob’s Agent
Kent
: Session 1 with EmilySession 2 with EmilySession 3 with Emily
: Session 1 with Charlie Session 2 with Charlie
Bob’s SubNet Mixed Memory for Bob’s Agent
HumanSocialNetwork Humanssummonagentsonbehalf Agentscommunicateforsolvingtaskbyseekingandexchanging Agents check the plan,
ofthemforsolvingtask. information.ThecommunicationisdrivenbyInfoNav. makeconsensustodraw
conclusion.
Figure 2: Overall architecture of iAgents. From left to right, 1) each individual in the social
networkisequippedwithanagent,and2)twoindividualssummontheiragentstosolveatask,each
initiallyholdingtheinformationthatisvisibletoitshumanuser. Then3)agentsautomaticallyraise
communicationandexchangenecessaryinformationonbehalfofhumanusers. Finally,4)agents
performaconsensuscheckontheirplanningcompletedbyInfoNavtosolvethetask.
2 Method
2.1 ProblemFormulation
Withoutlossofgenerality,weformalizetasksinsocialnetworksthatrequireinformationexchangefor
collaborationasaQuestionAnswer(QA)task. TherationalesRnecessaryforansweringthequestion
Qaredistributedindifferenthumaninformation(I ,I )acrossthesocialnetwork,whichleadsto
1 2
informationasymmetry. Consequently,agents(A ,A )oftwoindividualsarerequiredtocollaborate,
1 2
updatetherationaleset(R ,R )thattheyholdthroughcommunicationC,andbycombiningtheir
1 2
rationales,theycanreasonandobtaintheanswer. Thewholeprocesscanbeformulatedas:
Ans=Reasoning(Q,R) (1)
R=R ∪R (2)
1 2
R ,R =C(I ,I ,A ,A ) (3)
1 2 1 2 1 2
2.2 Overview
AsshowninFigure2,agentsneedtoactivelyretrieveinformationfromhumansandexchangeitwith
otheragents. Thecommunicationcanberepresentedas:
C ={U ,U ,...,U } (4)
n 1 2 n
whereU denotesanutteranceinthecommunicationC,andnisthemaximumnumberofcommu-
nicationturns. Agentstaketurnsmakingutterancestoadvancetowardstaskresolution. Following
theclassicaldefinition[57,51],whereagentsobservetheenvironment,thinktomakedecisions,and
thentakeaction,wecanorganizeagents’communicationsimilarly. Eachagent’sbehaviorinone
communicationturninvolvesapipelineof1)observingthecurrentcommunicationprogressC and
theirheldrationalesR,2)thinkingabouthowtoupdatetherationaletoRnew andwhatquery to
makeforretrievinginformationfromhumans,and3)actingbyretrievinginformationandmakingan
utterancebasedonit. Thispipelinecanbeformalizedas:

Act (Think (Obsi )) i%2==1
 A1 A1 A1
U = (5)
i
 Act (Think (Obsi )) else
A2 A2 A2
where
Obsi ={R,C } (6)
A i−1
Think (Obsi )={query,Rnew} (7)
A A
Act (Think )=A(query(I))=U (8)
A A
3( o2 n) CU op md ma ut ne i cP al ta in o nT e Px rt o gB ra es se sd (3) Perform Consensus Check on Plan Text of two Agents
(1) InfoNavInitilizesPlanning Agent1:Toeffectivelycompletethetask Agent 1: To effectively complete the A …g …e fn rt om2: ouT ro ca oc nc so im dp el ri as th iot nhe at na dsk ido ef ntf ii fn ydin …g …
offindingout……[comprehensive list of task of finding out …… we must gather This process involves gathering,
A t c t a c Sg a o o l o pe s l l n e n k l t cct a a iiob c fno mo t idf1 p r ci: ia avf lt lii eT e ldn wo yud i ,aaci tllne hsogf ][ sf ,c eee o o alc wu m cyt et p h.i r av t e o le Th h f ol he e ny i mn gus… us s…c si o tr v hm ew e a wp qe s il u l te in bi ht re e gse ee e atsd n t t ht u o i …h eo s f n …e r a c C i l i ml o n i s e5l n f s d, t o t i Ba r e ti D oc m d an 5 ot a t d , kt i ii i onv w o n Ei Ci n 5d lt t s,u uh ho e a b] en sl ( iF ss S r5 M i o [ ) e ol ee s, e nv aa c t e cc h id h i.h e n, s. d g . ua o . lc 2wf . et i h . si si hwu v ] c oes i (h u1 t S r y oh smi ' la ,hus s vs os e ut Edd rAb 5,u ,5e ' rg ,e saa w n tt h E ih iB 5 doe c oi 5 'nr h gn s, i l i m w sn i s e a ef s d l s o t i k sBr e t i iom d a n ooa t g n kt i i i o an ao n t cCn t tlt es iuh no e vbe dn s i i es tr dM i y[ e o e s be na c i yt c h s ih e i Bn d s 5g 2ua lc 2 ihet i sosi s h uv ] 2o ri ( u1 st S hr ,y o os ' l uh ,s v m ro e e su Ed dd )r 5, iu ., ' tr s aa w tt h E ii i 5 d oo c o' nn h gs c v d C S C n to a i l e a o hm r f u s m t ap i f b s p t a o e i i sr u r o n lpi s e n g aM en n s e cg t tTa e i2, rc t f tit ip i hpa i n he e e n v g oo dsd i up ) ltt rl oaia se nr1en t,] gt-sa o ( e 1 l S st.y Dof ti5z dolr .m i egvo en t em g ehd 1W ro, 7t a mut :h l irh 0e k nw se 0 i eh , ni s[ bgccd u t hhu tM h er e 2 eda ed iut nisli dt h o eo a o nsn t u eB t i r (o io s so mo o n , )k ef f
i d …n u …f ro ar tm ia ot n io ln isteo dn in [ te ha ec ih r sa cc ht ei dv ui lt ey s' ].s w sa el sk si in og n aa tc tt ei nv di et dy bi ys B52 ih so u 2r s h, o urm se )d .i t …a …tion • •❌ ✅B Eo 5o 'k
s
C ml eu db
i
tM ae te it oi nn g
s
ei ss
s
i1
o
nh o iu sr 2< h- o- u- r- s- > <B -o -o -k
-
-C >l u Mb
e
dM ie te at ti in og
n
1 Se- s1 s. i5
o
nh o 2u r hs
ours
•✅E5's dog walking activity is 2 hours <-----> Dog Walking 2 hours
•u an lk ln o iw nn d: i vc io dm up ar le sh e en as ci hv e o fl i us st ho af s •u ip nd da it ve id: u ac lo sm p er ae ch he n os fi v ue s l hi as st bo ef e na l il n • •✅ ❌m Ne od ni et a <t -i -o -n - -s >e s Cs ai mo pn i na gt t Te rn id pe d s tb ay r tB 5 t ii ms e 2 1 7h :o 0u 0r s b ut< - e- n- d- - t> i mM ee d ni ot ta t si po en c iS fe is es dion 2 hours
•b u d se n u ce k r hn n a e o t di w i un n o l: n e c seo lan ict sha t c eat dc tw iii nvt ih tt hy e' is r •c u i i ho p n s on d ut a t 1 ra t h sc e e h ,t i o : r u E w r 5ei s , 'at c sch h E h e 5 d d ' oa- u s gc- l t> e m wi s e avA d li5 i kt, - t iy - a n'B > t gs5 i , B o ad o n cuC o tr5 k s ia, e vt C s iiD l s to5 u i yn, b o n ilE M si5 e i s, e s 2t t eF i 2d5 n g (4) Get the Answer
hours, meditation session attended by B5
is 2 hours Meditation Session 2 hours, Dog Walking 2 hours
Figure 3: A case of the task asking two agents to find the longest activity among all schedules.
InfoNav navigates the communication by providing a plan to the agent. It first 1) asks the agent
to make a plan on what information is needed, then 2) fills the placeholder in this plan during
communication. Finallyit3)performsaconsensuscheckonthecompletedplanto4)gettheanswer.
Toensureeachgeneratedutteranceprovidesvaluableinformationandeliminatesasymmetry,howto
exchangeinformationandwhatinformationtoexchangeiscrucial. Todealwiththesetwoquestions,
weusetheInfoNavmechanismtoguidecommunicationtowardseffectiveinformationexchange.
Furthermore,weintroducetheMixedMemorymechanismwhichorganizeshumaninformationinto
FuzzyandDistinctMemoryforaccurateandcomprehensiveretrieval. Additionally,eachagentcan
initiatenewcommunicationCnew withintheirsubnetwork,whichmeansthecommunicationC may
berecursiveandcandiffuseamongthesocialnetwork:
C ={Cnew,Cnew,...,Cnew,U ,U ,...,U } (9)
n 1 2 m 1 2 n
Forexample,ifAlice’sagentwantstocollaboratewithBob’sagent,Bob’sagentmightrespond"Hold
on,IcanaskCharlie’sagentforhelp."
2.3 InfoNav
AsshowninEquation6,theagentneedstobeawareofitsrationalesetandongoingcommunication
toeffectivelyadvancetheconversation. Whilethestatusoftherationalesetcanbeimplicitlyinferred
fromutterances,thisinferenceisoftenunreliableforLLMAgents. Thisunreliabilitycanleadto
incorrectstatesandthengeneratemeaninglessutterances,suchasrepetitivequestioningorredundant
thanking, which makes it harder to infer rationale and creates a vicious cycle. To address this,
weproposetheInfoNavmechanism. InfoNavexplicitlyrecordstherationalesetusingtheagent’s
planningtextandnavigatestheautonomouscommunication. Beforeeachutterance,theagentreviews
itsplantoidentifywhichunknownrationaletoinquireaboutandthenupdatestheplanbasedonthe
responsesreceived. Figure3showsanexampleofInfoNavinaction. Initially,weprompttheagent
togenerateaplanP outliningtherationalesneededtoanswerquestionQ. Sincetheagenthasno
informationatthebeginning,allrationalesintheplanaremarkedasunknown:
P(ru,...,ru)=Prompt(Q) (10)
1 m
where ru denotes unknown rationales. During communication, these rationales can updated to
"known"andfilledwithconcretecontentasinformationisprovided. Theplaniswritteninfluent
naturallanguage,makingitexplicitandeffectiveforpromptingthemodel. Therefore,usingInfoNav,
therationalesetRinequation6isrewrittentoplanP,andtheupdatedrationaleRnew isreplacedto
theplanwithfilledrationalesP(rk),whererk representsknownrationales:
Obs ={P(ru),C} (11)
A
P(rk)=Think (Obs ) (12)
A A
Aftermultipleturnsofcommunication,bothsidesfinishtheupdateoftheirplans. Theagentsthen
perform consensus reasoning, which unifies collected rationales and discards conflicting ones to
reachananswer. Thus,equations1to3rewriteto:
Ans=Reasoning(Q,R) (13)
R=Consensus(P (R ),P (R )) (14)
1 1 2 2
P (R ),P (R )=C(I ,I ,A ,A ) (15)
1 1 2 2 1 2 1 2
4Previousreasoningmethods[45,56,3,8]focusedonprovidingaccurateplans. Incontrast,InfoNav
emphasizesnavigatingcommunicationandinformationexchangewithplans. TheplaninInfoNav
can be seen as a generalization of Dialogue Status Tracking (DST)[14, 49, 13] in conventional
task-orienteddialoguesystems. Italsogeneralizestheconceptofsoftwareinmulti-agentsoftware
generationframeworkslikeChatDev[36]orMetaGPT[15]. Theplanmaintainsprogressintask-
solving,guidingagentstoshareinformationduringcommunication.
2.4 MixedMemory
IniAgents,agentsarenavigatedbyInfoNavtoretrievehumaninformationandshareitwithother
agents for collaboration. Retrieval of human information is challenging due to it being diverse
informatandcomplextoorganize. Weproposeorganizinghumaninformationintotwotypesof
agentmemories: DistinctMemoryandFuzzyMemory. Thesememoriesfacilitatereactiveretrieval,
ensuringaccurateandcomprehensiverationaleextraction,asshowninFigure2.
Distinct Memory (Mem ) stores human information in a structured format, allowing for exact
D
matches such as structured query language. Distinct memory faithfully preserves the original
information(I)andsupportsaccurateretrieval. Additionally,itenablesinformationretrievalfrom
multiplespansacrossdifferentchatsessions(s),capturingevolvingchangesinrationales.
However, distinct memory’s strict exact-match requirements complicate the retrieval process. It
alsostrugglestoprovidecohesivecontext. Toaddresstheseissues,weintroduceFuzzyMemory
(Mem ). Fuzzymemorystoressummarizedsessiontexts(I )andusesembedding-basedANN
F s
retrieval [21]. Although both fuzzy memory and reflection [31] produce more abstract text, we
emphasize an objective summary of information to facilitate session-level retrieval, rather than
subjectivegeneralizationstoaidinplanning. Whilethisapproachmaylosesomedetails,itoffersa
comprehensivecontextandenablesrobust,semantic-basedretrieval. Therefore,theretrievalactionin
Equation8canberewrittentoinvolvebothmemorytypes:
Act (Think )=A (query (I )) (16)
Ak Ak k k k
=A (SQL(Mem ),ANN(Mem )) (17)
k D F
What’smore,thequeryofthesetwokindsofmemoriesisdecidedbyagentsbasedonobservationsof
previousexecutions,whichmeansagentscanreactivelyadjusttheirqueries. Combiningthesetwo
kindsofmemoryfacilitatesagentstocross-verifytheretrievedinformationandprovidesInfoNav
withcomprehensiveandaccuraterationales.
3 InformativeBench
Split
𝑨𝒏𝒔𝒘𝒆𝒓
Combine
Agent Needle
Information
Insert Insert
Algorithm Human
Information
Human User Agents’
Let’s find the ! Relationship communication Let’s get the 𝑨𝒏𝒔𝒘𝒆𝒓!
1) Needle-Type Task 2) Algorithm-Type Task
Figure 4: Two kinds of tasks in the InformativeBench. Each agent can only see the information
(markedwithdifferentcolors)ofthehumanthatitworksonbehalfof,whichgeneratesinformation
asymmetry. Agentsare1)askedtofindtheneedleinformationwithinthenetworkor2)reasontoget
ananswerwhichistheoutputofanalgorithmrunningondistributedinformationinthenetwork.
3.1 Pipelines
Currently,thereexistsnobenchmarkordatasetspecificallydesignedtoaddressinformationasymme-
tryincollaborativetasksamongcommunicativeagents. Inthispaper,weconstructInformativeBench,
5rachel
bobmeln terry mrs. bing joey
sandy's kids sal no tw osell
man
waiterteacher danielllueisa
dr. mitchell joey's father fireman 3 dr.j ooabnenreman pizza guy dick clark (tv)
janitor mitchell susan pmar. geller script nurse
flg at ngl carol robbsiheelley
ben
girlsmindy frnzlizzie
carol's baby
phoebe mf ru s.n t rb ibo bb iab niy guy
wpfe itirt rhre
o
ie tm nenla ein
sc
2
ope
sandykri as tt min
mr.f r ka on stn m ei le a icr s (b oho na y ps hoj nill e's
)
mop maul
mm ra .x hecm ka lr ec se wl aitb ree sr snice
ir nis indab aa vr ir dy
celiaa mu rn st .s gyl
e
( lo len
r
phone)
chandler
julie andrgeiarl nanh ais cg aiwr rl o ifine the bar jill paulacustomer c ho em lea nt po es re s b om obn ba a bon b yny pho mn re . douglasuv ris sa u lc aa jr ad m re iepresentative receptionca ieu snn tttr alillr l io pas er np oi rna kgo e alo r udja it ev y n l ce ed nlyr od. ib aa 'sld mh ca o ur t ta h ee dr octors
fran heck wife
eva
ew to hm anan k[f ia kk ie mo ln ei sc la ie]coma guy rac gh ae nl's
g
wf r [i o ie nmn d kas iw tn co hm ea nn
]
at party fjiarenmicaenf r 1ie kmn id donica's mother guly yd aia ctor carl da irl ea cn tordr.
v
r oo is cei ln obrso
rre
ail ad
c innu
m erita yn r a pc eh
rson gpn uheo yle
s ross
monicafake mon raic ca hel's father phoebe's assistant gerston mr. tribbiani aurorasteve
Figure5: ThevisualizationofsocialnetworkinFriendsTVdataset. Theconnectionofthesixmain
charactersislabeledwithdifferentcolors.
thefirstbenchmarktoevaluateagentcollaborationtasksfeaturinginformationasymmetryinsocial
networks. Itcontainsfivedatasetstoassessagents’variouscapabilities. What’smore,recentstudies
havefoundthatLLMcontinuouslyingestsinternetdatasostaticbenchmarkscanbeeasilymemorized
andoverfitted[61,53,59]. HencewesharetwopipelinesforconstructingInformativeBenchwhich
areeasytorealizeandcanbegeneralizedtomoredomainsforconstantanddynamicevaluations.
TheyareNeedle-TypeandAlgorithm-Typepipelines,asshowninFigure4.
Needle-TypePipelineA"needle"[10]isinsertedintothesocialnetwork,andagentsaretaskedwith
findingthis"needle"information. Thisevaluatestheirabilitytoshareandlocateinformation. The
datasetcanbecreatedeitherbysplittingtheneedleandspreadingitintothenetwork,orbycombining
informationpiecesfromthenetworktogenerateaneedle. Forthesplitmethod,theNeedleinthe
Persona(NP)datasetmodifiesthedialogueintheSPCdataset[19]byaddingacommonoropposite
personatotwoindividuals’personas. Agentsareaskedtofindthispersona. Forthecombination
method,theFriendsTVdatasetreconstructsthesocialnetworkbasedontheentireseasononescript
ofFriends[47],involving140characterswith588relationships(asshowninFigure5),andcombines
twoquestionsintheFriendsQAdataset[55,24]as"needlepieces"togeneratenewquestion. This
dataset,thelargestinInformativeBench,featuressarcasm,plottwists,andcomplexrelationshipsfor
simulatingreal-worldchallenges.
Algorithm-TypePipelineHumansareassigneddifferentpiecesofinformation,whichserveasinputs
foranalgorithm. Agentsmustsolvetaskswheretheansweristhealgorithm’soutput,evaluating
theirreasoningabilitiesbasedoninformationexchange. InInformativeBench,thisisrepresented
bytheScheduledataset,whichdevelopsaprogramforassigningdifferentschedulestoindividuals.
Agentsarepresentedwithalgorithmicproblemsofvaryingdifficulties,andthealgorithmprogram
automaticallyverifiesthecorrectnessoftheirsolutions. Thedatasetsincludequestionsofthreelevels
ofdifficulty: Easy)calculatethenumberofconflictingschedulesbetweentwopeople,Medium)find
thelongestactivityamongsixpeople,andHard)findthelongestcommonfreeperiodamongsix
people.
3.2 QuestionDistribution
Figure6presentsthedistributionofproblemtypesinInformativeBench. Itisevidentthatthemajority
ofthequestionsinInformativeBenchareofthe"What"and"Who"types,whichhaveobjectiveground
truthandlackambiguity. IntheScheduledataset,questionsarecategorizedintothreedifficultylevels,
6FriendsTV
Who
What
Where
How Long
Who
What How Many e
Needle
in
the
Persona
W hereWhat
Schedul
Figure6: ThedistributionofquestiontypesintheInformativeBench.
witheachdifficultylevelcorrespondingtoadifferenttypeofquestion: "What","HowMany",and
"HowLong".
3.3 QuestionSample
Dataset QuestionSample
NeedleinthePersona WhatfantasyseriesdoesAliceenjoythatDaveisindifferentabout?
Calculatehowmanyactivitiesneedtobedeletedatleastsothatthereareno
ScheduleEasy
overlappingactivitiesbetweenyouandme?
ScheduleMedium Pleasefindouttheactivitywithlongestdurationonthescheduleofallpeople
Pleasefindoutwhenallourfriendscanjointogethertodayandlistallfreetime
ScheduleHard
spans.
Whoisconcernedabouttheimpactoftheblackoutontheirfamily,giventhe
FriendsTV
contextofawidespreadpoweroutageaffectingManhattan?
Table1: QuestionsampleintheInformativeBench.
Table1providesexamplesofproblemsfromfivedatasets.
NeedleinthePersona. Inasegmentofmulti-partycasualconversationamongAlice,Bob,Charlie,
andDave,"needleinformation"relatedtoafantasyseriesisinserted. Questionsarethenposedto
BobandDave’sagentstoidentifythisneedleinformation.
Schedule. Eachpersonisassignedadailyschedule. Questionsofvaryingdifficultyrequireagents
tocollaboratetodiscussoverlappingschedulesfortwohumanusers,thelongestscheduleamong
multiplehumanusers,andcommonfreetimeformultiplehumanusers.
FriendsTV. Based on questions from the FriendsQA data, new questions are synthesized. For
instance, as shown in Table 1, there is a scene in the third act of the seventh episode of the first
seasonofFriendswhereablackoutoccurs. Agentsneedtocombinetherationalesandanswersto
theoriginalquestionsinFriendsQA,whichare"Wheredidtheblackouthappen?"and"Whowas
worriedaboutgrandmotherbeingaffectedbytheblackout?",tolocatethissceneinthescriptofthe
firstseasonandfindtherelevantcharacters.
3.4 BenchmarkStatistic
Table 2 presents detailed statistics of five datasets in InformativeBench, including the number of
question-answerpairsandthescaleofsocialnetworks. WeutilizetheFriendsTVdatasettosimulate
real-worldchallenges,providingalarge-scalesocialnetworktotestagents’writingabilities. The
otherdatasetssimulatesmallersocialnetworks,focusingonenablingagentstoexchangeinformation
tosolvecomplexreasoningtasks. Thedifficultyforagentsincollaboratingwithinhumansocial
7Dataset NeedleinthePersona ScheduleEasy ScheduleMedium ScheduleHard FriendsTV
Pipeline Needle Algorithm Algorithm Algorithm Needle
#QA 100 30 30 30 222
#Individuals 4 4 6 6 140
#Relationships 5 3 5 5 588
NeedExternalMemory No No No No Yes
Metrics Precision Precision F1 IoU Precision
Table2: StatisticofInformativeBench.
networks lies not only in the scale of the social network (information acquisition) but also in
effectivecommunication(informationexchange). Therefore,wedesigneddatasetsofvaryingscales
anddifficultiestocomprehensivelyevaluateagents. Asthesocialnetworksindatasetsotherthan
FriendsTV are relatively simple with limited information, we did not enable the MixedMemory
mechanisminexperimentswiththesedatasets.
4 ExperimentalSetup
We generically treat chat histories as human information. This approach simplifies modeling in-
formation asymmetry in social networks. Other types of information, such as knowledge bases,
documents, orwebcontent, canallbeorganizedinmixedmemorysoiAgentsisadaptabletoall
these kinds of information. We conduct all experiments with a maximum of 10 communication
turns for agents. The experiments use GPT4 (gpt-4-0125-preview), GPT3.5 (gpt-3.5-turbo-16k),
Gemini(gemini-1.0-pro-latest),andClaude(claude-sonnet)2asLLMbackends. Thetemperatureis
setto0.2. ForFuzzyMemory,weusegpt-4-0125-previewtosummarizesessiontextandOpenAI
text-embedding-3-smalltogenerateembeddingsforANNembeddingsearch. Weuseprecisionas
themetricforquestionsintheNP,ScheduleEasy,andFriendsTVdatasets. FortheScheduleMedium
andScheduleHarddatasets,weuseF1andIoUasthemetrics,correspondingtothealgorithmused.
FortheScheduleandNPdatasets,wedonotactivatemixedmemorysincetheinformationscaleis
smallandcanbefullyloadedintheLLMcontext. Additionally,fortheScheduledataset,wedonot
activatetheagent’sabilitytoinitiatenewcommunicationduetothesmallscaleofthesocialnetwork.
5 Result
5.1 InformativeBenchEvaluations
Needle-Type Algorithm-Type
LLMBackend
NP FriendsTV ScheduleEasy ScheduleMedium ScheduleHard
GPT4 64.00% 57.94% 56.67% 51.00% 22.80%
GPT3.5 51.00% 35.71% 36.67% 18.00% 12.25%
ClaudeSonnet 50.00% 34.13% 43.33% 17.44% 18.66%
Gemini1.0 40.00% 28.57% 26.67% 22.33% 14.40%
Table3: EvaluationresultsofiAgentsonInformativeBenchwithdifferentLLMbackends.
WefirstcomprehensivelyassessedtheperformanceofiAgentsusingsomestate-of-the-artLLMson
InformativeBench,asshowninTable3. GPT-4achievesover50%accuracyacrossmostdatasets,
indicatingitspotentialtoworkonbehalfofhumansforcooperation. However,smaller-scaleLLMs
stillfacesignificantchallengesinsolvingcooperationproblemsininformationasymmetry. TheNP
datasetisthesimplest,requiringagentstofindrelevantinformationwithinthecontextandexchange
opinions. Most models could only achieve about 50% precision on the easiest NP task. This is
consistentwithrecentresearchfindings[16]thatsimplylocatinginformationisinsufficienttoassessa
model’sabilitytoanalyzein-context/long-contextinformation. IntheNPdataset,agentsarerequired
tolocateinformationwithinarelativelyshortcontextlength,buttheinformationisdispersedbetween
2asof20240501.
8twoparties,creatinganasymmetry. ThisremainsachallengingtaskforcurrentLLMagents. For
theScheduledataset,agentsmustlocateinformationandenhancetheircommunicationskillsfor
further reasoning and computation. As questions become harder, performance drops, with most
modelssolvinglessthan20%ofthehardestquestions. TheFriendsTVdatasetintroducesalarge
socialnetwork,requiringagentstouseexternalmemorytoretrieverationalefromextensivehuman
information. MostLLMsstruggleto exceed40%accuracy inthisdataset. Thus, whileprevious
studies show impressive performance when agents are omniscient, collaborating in information
asymmetryremainschallenging.
5.2 AblationStudy
a) Ablation experiments on MindNav across five datasets b) Ablation experiments on other components
Figure7: Ablationstudyona)InfoNavandb)othermechanismsincludingDistinctMemory,Fuzzy
Memory,andRecursiveCommunication. ExperimentsareconductedusingGPT3.5asthebackend.
WeconductedablationexperimentsonseveralkeydesignsoftheiAgentsframework,asdetailed
in Figure 7. Analyzing the FriendsTV dataset revealed that incorporation of the mixed memory
mechanism led to a performance increase ranging from 2.38% to 6.34%, surpassing the impact
of InfoNav, which resulted in only a 0.8% performance increase. This discrepancy underscores
thegreatersignificanceofeffectiveretrievaloverreasoningduringcommunicationinlargesocial
networkswithmassinformation. Notably,theablationofbothmemorymechanismsemphasizedthe
indispensabilityofmixedmemory. Theintroductionofrecursivecommunicationexhibitedthemost
significantperformancegain(12.7%),primarilyduetothechallengesposedbythevastsocialnetwork
intheFriendsTVdataset. Byactivelyintroducingnewcommunicationswithinongoingdialogues,
agentscouldacquireandcorroborateinformation,thussignificantlyenhancingperformance. This
highlightstheimperativeofscalabilityinourproposedframeworkforaddressingreal-worldproblems.
FortheNPandScheduledatasets,themainchallengeliesinfacilitatingeffectivemulti-turncommu-
nicationtoexchangeinformationforreasoning. Therefore,InfoNavemergedaspivotalinenhancing
performance,resultinginperformanceincreasesrangingfrom15%to26%.Whenagentsreliedsolely
oninitializedpromptstonavigatemulti-turncommunication,theystruggledtoexchangeinformation
effectivelytoaccomplishtasks. ThisdeficiencywasparticularlyevidentindatasetslikeSchedule,
whichemphasizelogicalreasoningandcomputation. Acrossalldifficultylevels,agentswithoutthe
InfoNavmechanismfailedtoachieveaccuracyexceeding10%.
5.3 AnalysisonAgents’Behaviour
InfoNav Behaviour We examined how agents utilize InfoNav for information exchange during
multi-turncommunication. Notably,wecalculatedtheaveragenumberofunknownrationalessolved
eachtimeInfoNavupdatedtheplanandtheproportionofrationalespassedinconsensusreasoning.
Moreover,somerationalesweresolvedina"FakeSolved"hallucination,whereagentsfilledinthe
rationaleas"solved,whichisunknown". Wealsodocumentedthefrequencyofsuchoccurrences.
Table4showsthatagentswhoproposefewerrationalestoseekandachieveahighersolvedratioare
morelikelytoaccomplishthetask. Interestingly,agentsoftenfillmultiplerationalesconcurrently
ratherthansequentially. Thoseagentswithhigherinstancesofsynchronouscompletionssuggest
a deeper understanding of the task and greater confidence in filling rationales. Furthermore, the
occurrenceofFakeSolvedinstancesisloweramongagentswhopredicttaskscorrectly.Theconsensus
ratio is also higher when agents successfully complete the task. It denotes that the information
9#Rationales #RationalesSolved RationalesSolved FakeSolved Consensus
Sample
inInfoNav perUpdate Ratio Ratio Ratio
PredictRight 5.29 2.04 84.75% 3.49% 70.52%
PredictWrong 5.63 1.69 67.23% 5.40% 62.70%
All 5.45 1.87 76.22% 4.42% 66.20%
Table4: AnalysisInfoNavbehaviouronthetrajectoryofiAgentsusingGPT4asbackend. When
agents successfully complete the task, the static collected from their trajectory proves that they
betterutilizetheInfoNavmechanism,sincetherationalesolvedratio,synchronouscompletionsof
rationales,andconsensusratioarehigher,andpresentfewerfakesolvedhallucinations.
obtained by the two collaborating agents is relatively accurate and free of contradictions, thus
increasingthelikelihoodofarrivingatthecorrectconclusionthroughtheirfinalreasoning. Besides,
weobservedthatagentsnotonlyproposerationalesbutalsotaskstates,suchasthecompletionstatus
ofspecificactions. Thecompletionratesoftheserationalesandstatesarepositivelycorrelatedwith
tasksuccess. Inessence,theutilizationofInfoNavbyagentsmirrorshumanintuition,emphasizing
firstcarefulplanning,thenproactiveandaccurateinformationexchange.
a) Agents’ Behaviour Distribu9on on Dis9nct Memory b) Agents’ Behaviour Distribution on Fuzzy Memory
Figure8: Thefiguredepictsthedistributionofdifferentbehaviorsofagentsinadjustingmemory
retrievalbasedontheprogressofcommunication. Differentcolorsdenotedifferentbehaviorssuchas
maintaining,increasing,ordecreasingparameters,whiledifferenttexturesindicatewhethertheagent
ultimatelycompletesthetask. Agentspredominantlytendtomaintainparametersunchanged,but
whenchangesoccur,theytendtoincreaseparameterstogainmoreinformation.
MemoryBehaviourSimilarly,weexploredhowagentsadapttheirmemoryretrievalstrategiesduring
communication. Weexaminedthreeparametersindistinctmemoryqueries: thecontextwindow,
whichdeterminesthebreadthofcontextualmessages;thetotalmessageretrievallimit;andthesize
ofthequerykeywordsset. Forfuzzymemory,weanalyzedtwoparameters: thenumberofqueried
responses(topk)andthelengthofthequerytext. ThesefindingsareillustratedinFigure8. Our
analysisrevealedseveralnotabletrends. Themajorityofagentsdonotchangetheirbehaviorduring
communication. However,whenagentsdecidetochangetheirbehavior,weobservedthattheytended
toincreasetheamountofretrievedinformationovertime. Thisaugmentationtrendwasparticularly
pronouncedontheoverallmessageretrievallimit,wherethefrequencyofincreaseactionssurpassed
thatofdecreaseactionsbynearlythreefold. Furthermore, agentswhocompletedtasksexhibited
amoreconservativeapproach,withalowerproportionofbehavioralchangescomparedtoagents
unable to complete tasks. This phenomenon may be attributed to the difficulty of certain tasks,
makingagentscontinuouslyrefinetheirstrategiesinpursuitoftherequiredinformation.
5.4 AnalysisonRealWorldConcern
WestudiedtwosignificantchallengesinextendingtheiAgentstoreal-worldapplications,asshown
inTable5. Firstly,weinvestigatedwhethertheagentcaneffectivelyrespondtohumaninputwithout
beingoverlyinfluencedbyfactualknowledgeobtainedduringpre-training[50,35]. Secondly,we
10Study Experiments FriendsTV
Base iAgents 35.71%
PriorKnowledgeDistraction Anonymous 32.54%
PrivacyStudy PrivacyPrompt 30.95%
Table5: Analysisexperimentsonpriorknowledgeandprivacy. UseGPT3.5asLLMbackend.
explored the agent’s ability to engage in communication while upholding human privacy. Our
experimentswereconductedusingtheGPT3.5modelontheFriendsTVdataset.
PriorDistractionTheFriendsTVcontainsinformationthatcouldbememorizedbyLLMfromthe
Internet,henceitisperfectforanalyzingpriordistractions. Weanonymizedthenamesoftheprimary
charactersinthedataset,forexample,renaming"Rachel"to"Alice". Theperformanceoftheagents
onthisanonymizeddatasetdecreasedfrom35.71%to32.54%,suggestingthattosomeextent,agents
canreasonbasedonuser-providedinformationratherthansolelyrelyingonknowledgememorized
inpre-training. Itmayneedfurtheradvancements,suchasmodelunlearning[58],tofullyaddress
thisissue.
PrivacyConcernIninvestigatingwhetheragentscancommunicatewithoutcompromisingprivacy,
weconductedanexperimentinvolvingmodificationstotheagent’ssystemprompt,emphasizingthe
importanceofprivacypreservationinutterances. Theagentthenutilizedvagueexpressionssuchas
"somebody/somewhere"anddisclosedonlyentityinformationrelevanttothetask. Thisadjustment
ledtoaperformancedropfrom35.71%to30.95%,indicatingtheongoingchallengeofachieving
collaborationwhileensuringprivacy. It’simportanttonotethatwesolelyadjustedprivacysettings
ontheoutputside,ratherthanrestrictingagentaccesstohumaninformationontheinputside. This
decisionwasmadebecausesettingaccesspermissionsmightinadvertentlyrevealpriortask-related
information. Thus,therealchallengeliesinappropriatelyregulatingaccesstoinformationbasedon
taskrequirements,akintoteachingtheagenttoretrievenecessaryinformationaccurately. What’s
more,humanusercancustomizetheirpersonalfilepermissionsinreal-lifeapplications,whichis
morelikeanengineeringissue. Lastly,absoluteprivacyprotectionisimpractical,asabsoluteprivacy
protectionamountstoforgoingproblem-solvingthroughcollaboration.
6 RelatedWork
LLM Agents Originating from ancient Greek philosophy, the concept of an "agent" referred to
abeingthatpossessesthecapacitytoactwithintentionality,oftendrivenbythemanifestationof
certainmentalstatesandevents, suchasdesires, beliefs, andintentions[37]. AsAIevolves, the
"agent"conceptisincorporatedtofacilitatethesimulationandcomprehensionofintelligentbehavior.
Inthiscontext,anagentistypicallydefinedasacomputersystemthatisautonomous,interactive,
reactive, and proactive [48]. Prior to the advent of Large Language Models (LLM), most agent
researchconcentratedonaugmentingparticularabilities,suchassymbolicreasoning,orexcelling
inspecifictaskslikeGo[18][23][38]. However,withtheemergenceofLLM,thefocusofagent
research has shifted. In the evaluation by [6], GPT-4 is considered to have achieved a form of
general intelligence, thus equipping LLMs with agency and intrinsic motivation is an intriguing
and important direction. Building on this, [51]introduces a framework for LLM-based agents,
encompassingabrainfordecision-making,aperceptionmoduleforsensoryinput,andanaction
moduleforenvironmentalinteraction. AgrowingnumberofstudieshavebeguntoutilizeLLMas
aprimarycomponentofthebraintoconstructartificialintelligenceagents[46],andapplythemin
variousreal-worldscenarios. ThisislargelyduetotheinherentcharacteristicsofLLMs,suchas
theirdemonstratedautonomy,reactivity,pro-activeness,andsocialability,whichalignwellwiththe
keyattributesofanagent[51]. Forinstance, [36]createsavirtualsoftwaredevelopmentcompany
usingLLM-basedagents,whocollaboratethroughachatchaintobreakdown,propose,andvalidate
solutionsforatomicsubtasks,therebyefficientlycompletingtheentiresoftwaredevelopmentprocess.
[4]presentsanagentsystemdesignedforconductingscientificexperiments. However,thesestudies
primarilyfocusonthecapabilitiesofagents,overlookingtheinteractionandcooperationparadigms
ofagentsasconsciousentities. Thisresearchgapwarrantsfurtherexploration.
11ParadigmsofHuman-AgentandMulti-AgentCooperationToensuretheactionsofagentsalign
withhumanobjectives[22],upholdthesafety,legality,andmoralityofagentbehaviors,aswellas
addressdataprivacyissuesandcompensatefordatascarcityinspecificdomains[32],human-agent
interactionisindispensable. Currently,therearetwomainparadigmsofhuman-agentinteraction.
Thefirst,theEqualPartnershipParadigm,viewsagentsascommunicatorswhounderstandhuman
emotions and collaborate from a human perspective [12]. The second, the Instructor-Executor
Paradigm, emphasizes the human’s guiding role, with agents interpreting and executing human
instructions[9]. AlthoughLLM-basedagentspossessexceptionalcapabilitiesinsolvingcomplex
tasks, they exhibit significant limitations when operating as isolated entities. Specifically, single
LLM-basedagentsarelimitedbytheirinabilitytocollaborate,learnfromsocialinteractionsand
multi-turn feedback [28], and function effectively in complex, multi-agent scenarios [51]. Many
studieshaveshownthattheinteractionofmultiplesingleagents[30],eachwithspecificfunctions,
canstimulatestrongerintelligence[2].Ononehand,allowingmultipleintelligentagentstocollaborate
canhandlecomplextasksmoreefficiently. Forinstance,basedonmulti-agentcooperation, [29]
utilizesmulti-agentsystemstocollectivelyreasonabouttaskstrategies,anddecomposetasksduring
planningtoacceleratetrajectoryplanning. Ontheotherhand,introducinggametheoryconceptsinto
multi-agentsystems[1],whereeachagentadjustsitsstrategybasedonthebehaviorsandpotential
responsesofotheragentsinacompetitiveenvironment,canleadtomorepowerfulbehaviors[27].
Some of the latest research has begun to focus on multi-agent simulation scenarios where there
existsinformationasymmetry[63,62]. Theyfoundthatthedialogueparticipantssimulatedinan
omniscientenvironmentweremoresuccessfulinachievingsocialgoalsthanthoseinanon-omniscient
environment,despitethelatterbeingclosertoreality.Inaddition,theyalsodemonstratedthatlearning
from omniscient simulations can enhance the naturalness of interactions, but it hardly improves
theachievementofgoalsincooperativescenarios. Mostreal-worldapplicationscenariosinvolve
informationasymmetry. Therefore,howtoenableagents,eachpossessingprivateuserinformation,
tocooperateinassistinghumansinproblem-solving,isanecessaryissuetobeaddressedforthe
real-worldapplicationofagentsinhumansociety.
LLMAgentReasoningInpreviousresearch,agentsandLLMshavebeentaskedwithproviding
accurateinformationtohumanusersinhuman-machinecollaboration. Duetothenatureoflanguage
models, the output of information relies on the user’s input and the previously decoded content
servingasrationalecontext. Therefore,someworkonreasoninghasexploredhowtoimprovethe
organizationandexpressionofthisrationalecontext[45,56,3,8],toenhancetheaccuracyofoutput
information. However, someresearchhasalsofoundthatthereasoningprocessofLLMsdiffers
fromthatofhumans[54,20,7,33]. ForquestionsrelyingoninternalknowledgewithinLLMsto
answer,agentsdonotnecessarilysolveproblemsstepbysteplikehumans. Instead,comparedto
steps,havingcontextwithsufficientinformationcontentismoreimportant. Inthispaper,wefocus
onmachine-to-machinecommunication,relyingonexternalinformationofLLMstocollaboratively
answerquestions. ThisposesdifferentrequirementsforLLMreasoning,especiallyintermsofhow
topromoteinformationflowsosufficientinformationisincludedinthecontextprovidedtoLLM.
Agentsneedtoactively[17]andaccuratelyacquire,provide,andaskforinformation.
7 Conclusion
Thispaperrevisitstheecologicalroleofagentswithinhumansociety,whereagentsactonbehalfof
humansincommunicationtocompletecollaborativetasks. Aprimaryfocusliesinaddressingthe
challengeofinformationasymmetry,whichispivotalwhenintroducingagentsystemsintohuman
socialnetworks. Weintroduceanovelparadigmfordesigningmulti-agentsystems,termediAgents,
for addressing information asymmetry. Furthermore, we introduce a benchmark to thoroughly
evaluatetheagents’collaborationabilityunderinformationasymmetry. Itrepresentsjusttheinitial
phase of research in this domain and faces some challenges and limitations. Going forward, we
aimtoconfrontseveralkeychallengestosuccessfullyimplementthissystemintherealworldfor
augmenting human productivity, including deploying lightweight models at the edge to address
privacyconcernsanddevisingnewHuman-ComputerInteractionparadigmsforautonomousand
controllablecommunicationamongagents,etc. ComparedwithpreviousMAS,iAgentsdoesnot
role-playtoreplacehumanexpertsbutconsistentlyattributesthevalueofinformationtohumans
andwebelieveitcanfacilitatetheproductivityofhumansocietywithinasecureandcontrollable
framework.
12References
[1] HarisAziz. Multiagentsystems: algorithmic, game-theoretic, andlogicalfoundationsbyy.
shohamandk.leyton-browncambridgeuniversitypress,2008. SIGACTNews,41(1):34–37,
mar2010.
[2] P.G.BalajiandD.Srinivasan. AnIntroductiontoMulti-AgentSystems,pages1–27. Springer
BerlinHeidelberg,Berlin,Heidelberg,2010.
[3] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas
Gianinazzi,JoannaGajda,TomaszLehmann,HubertNiewiadomski,PiotrNyczyk,etal. Graph
ofthoughts: Solvingelaborateproblemswithlargelanguagemodels. InProceedingsofthe
AAAIConferenceonArtificialIntelligence,volume38,pages17682–17690,2024.
[4] DaniilABoiko,RobertMacKnight,andGabeGomes.Emergentautonomousscientificresearch
capabilitiesoflargelanguagemodels. arXivpreprintarXiv:2304.05332,2023.
[5] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,
ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,Ariel
Herbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielZiegler,
Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
Gray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,Ilya
Sutskever, andDarioAmodei. LanguageModelsareFew-ShotLearners. InH.Larochelle,
M.Ranzato, R.Hadsell, M.F.Balcan, andH.Lin, editors, AdvancesinNeuralInformation
ProcessingSystems(NeurIPS),volume33,pages1877–1901,2020.
[6] SébastienBubeck,VarunChandrasekaran,RonenEldan,JohannesGehrke,EricHorvitz,Ece
Kamar,PeterLee,YinTatLee,YuanzhiLi,ScottLundberg,etal. Sparksofartificialgeneral
intelligence: Earlyexperimentswithgpt-4. arXivpreprintarXiv:2303.12712,2023.
[7] ChangyuChen,XitingWang,Ting-EnLin,AngLv,YuchuanWu,XinGao,Ji-RongWen,Rui
Yan,andYongbinLi. Maskedthought: Simplymaskingpartialreasoningstepscanimprove
mathematicalreasoninglearningoflanguagemodels. arXivpreprintarXiv:2403.02178,2024.
[8] RuomengDing,ChaoyunZhang,LuWang,YongXu,MinghuaMa,WeiZhang,SiQin,Saravan
Rajmohan,QingweiLin,andDongmeiZhang. Everythingofthoughts: Defyingthelawof
penrosetriangleforthoughtgeneration. arXivpreprintarXiv:2311.04254,2023.
[9] DifeiGao,LeiJi,LuoweiZhou,KevinQinghongLin,JoyaChen,ZihanFan,andMikeZheng
Shou. Assistgpt: Ageneralmulti-modalassistantthatcanplan, execute, inspect, andlearn.
CoRR,abs/2306.08640,2023.
[10] Kamradt Greg. Llmtest_needleinahaystack. https://github.com/gkamradt/LLMTest_
NeedleInAHaystack,2023. NeedleInAHaystack-PressureTestingLLMs.
[11] TaichengGuo,XiuyingChen,YaqiWang,RuidiChang,ShichaoPei,NiteshVChawla,Olaf
Wiest,andXiangliangZhang. Largelanguagemodelbasedmulti-agents: Asurveyofprogress
andchallenges. arXivpreprintarXiv:2402.01680,2024.
[12] Masum Hasan, Cengiz Ozel, Sammy Potter, and Ehsan Hoque. Sapien: Affective virtual
agentspoweredbylargelanguagemodels*. In202311thInternationalConferenceonAffective
ComputingandIntelligentInteractionWorkshopsandDemos(ACIIW).IEEE,September2023.
[13] MichaelHeck,CarelvanNiekerk,NurulLubis,ChristianGeishauser,Hsien-ChinLin,Marco
Moresi,andMilicaGašic. Trippy: Atriplecopystrategyforvalueindependentneuraldialog
statetracking. In21thAnnualMeetingoftheSpecialInterestGrouponDiscourseandDialogue,
page35,2020.
[14] MatthewHenderson,BlaiseThomson,andSteveYoung. Word-baseddialogstatetrackingwith
recurrentneuralnetworks. InProceedingsofthe15thannualmeetingofthespecialinterest
groupondiscourseanddialogue(SIGDIAL),pages292–299,2014.
[15] SiruiHong, XiawuZheng, JonathanChen, YuhengCheng, JinlinWang, CeyaoZhang, Zili
Wang,StevenKaShingYau,ZijuanLin,LiyangZhou,etal. Metagpt: Metaprogrammingfor
multi-agentcollaborativeframework. arXivpreprintarXiv:2308.00352,2023.
[16] Cheng-PingHsieh,SimengSun,SamuelKriman,ShantanuAcharya,DimaRekesh,FeiJia,and
BorisGinsburg. Ruler: What’stherealcontextsizeofyourlong-contextlanguagemodels?
arXivpreprintarXiv:2404.06654,2024.
13[17] ZhiyuanHu,ChuminLiu,XidongFeng,YilunZhao,See-KiongNg,AnhTuanLuu,Junxian
He, PangWeiKoh, andBryanHooi. Uncertaintyofthoughts: Uncertainty-awareplanning
enhances information seeking in large language models. arXiv preprint arXiv:2402.03271,
2024.
[18] FrancoisF.Ingrand, MichaelP.Georgeff, andAnandS.Rao. Anarchitectureforreal-time
reasoning and system control. IEEE Expert: Intelligent Systems and Their Applications,
7(6):34–44,dec1992.
[19] Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, and Hakim Sidahmed. Faithful
persona-basedconversationaldatasetgenerationwithlargelanguagemodels. arXivpreprint
arXiv:2312.10007,2023.
[20] MingyuJin,QinkaiYu,HaiyanZhao,WenyueHua,YandaMeng,YongfengZhang,Mengnan
Du, et al. The impact of reasoning step length on large language models. arXiv preprint
arXiv:2401.04925,2024.
[21] JeffJohnson,MatthijsDouze,andHervéJégou. Billion-scalesimilaritysearchwithgpus. IEEE
TransactionsonBigData,7(3):535–547,2019.
[22] ZacharyKenton,TomEveritt,LauraWeidinger,IasonGabriel,VladimirMikulik,andGeoffrey
Irving. Alignmentoflanguageagents. CoRR,abs/2103.14659,2021.
[23] DouglasBLenat. Enablingagentstoworktogether. CommunicationsoftheACM,37(7):126–
142,1994.
[24] Changmao Li and Jinho D Choi. Transformers to learn hierarchical contexts in multiparty
dialogueforspan-basedquestionanswering. InProceedingsofthe58thAnnualMeetingofthe
AssociationforComputationalLinguistics,pages5709–5714,2020.
[25] GuohaoLi,HasanHammoud,HaniItani,DmitriiKhizbullin,andBernardGhanem. Camel:
Communicativeagentsfor"mind"explorationoflargelanguagemodelsociety. Advancesin
NeuralInformationProcessingSystems,36,2024.
[26] JunkaiLi,SiyuWang,MengZhang,WeitaoLi,YunghweiLai,XinhuiKang,WeizhiMa,and
YangLiu. Agenthospital: Asimulacrumofhospitalwithevolvablemedicalagents. arXiv
preprintarXiv:2405.02957,2024.
[27] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang,
ZhaopengTu, andShumingShi. Encouragingdivergentthinkinginlargelanguagemodels
throughmulti-agentdebate. arXivpreprintarXiv:2305.19118,2023.
[28] RuiboLiu,RuixinYang,ChenyanJia,GeZhang,DiyiYang,andSoroushVosoughi. Training
sociallyalignedlanguagemodelsonsimulatedsocialinteractions. InTheTwelfthInternational
ConferenceonLearningRepresentations,2023.
[29] ZhaoMandi,ShreeyaJain,andShuranSong. Roco: Dialecticmulti-robotcollaborationwith
largelanguagemodels. arXivpreprintarXiv:2307.04738,2023.
[30] MarvinMinsky. Societyofmind. SimonandSchuster,1988.
[31] JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,and
MichaelSBernstein. Generativeagents: Interactivesimulacraofhumanbehavior. InProceed-
ingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology,pages
1–22,2023.
[32] MettyPaul,LeandrosMaglaras,MohamedAmineFerrag,andImanAlmomani. Digitizationof
healthcaresector: Astudyonprivacyandsecurityconcerns. ICTExpress,9(4):571–588,2023.
[33] JacobPfau,WilliamMerrill,andSamuelRBowman.Let’sthinkdotbydot:Hiddencomputation
intransformerlanguagemodels. arXivpreprintarXiv:2404.15758,2024.
[34] DavidPremackandGuyWoodruff. Doesthechimpanzeehaveatheoryofmind? Behavioral
andbrainsciences,1(4):515–526,1978.
[35] SiyaQi,YulanHe,andZhengYuan.Canwecatchtheelephant?theevolvementofhallucination
evaluationonnaturallanguagegeneration: Asurvey. arXivpreprintarXiv:2404.12041,2024.
[36] ChenQian,WeiLiu,HongzhangLiu,NuoChen,YufanDang,JiahaoLi,ChengYang,Weize
Chen,YushengSu,XinCong,JuyuanXu,DahaiLi,ZhiyuanLiu,andMaosongSun. Commu-
nicativeagentsforsoftwaredevelopment. InThe62ndAnnualMeetingoftheAssociationfor
ComputationalLinguistics,2024.
14[37] MarkusSchlosser.Agency.InEdwardN.Zalta,editor,TheStanfordEncyclopediaofPhilosophy.
MetaphysicsResearchLab,StanfordUniversity,Winter2019edition,2019.
[38] Richard S Sutton, Andrew G Barto, et al. Reinforcement learning. Journal of Cognitive
Neuroscience,11(1):126–134,1999.
[39] XiangruTang,AnniZou,ZhuoshengZhang,YilunZhao,XingyaoZhang,ArmanCohan,and
Mark Gerstein. Medagents: Large language models as collaborators for zero-shot medical
reasoning. arXivpreprintarXiv:2311.10537,2023.
[40] MichaelTomasello. Theculturaloriginsofhumancognition. Harvarduniversitypress,2009.
[41] HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-
théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal. Llama: Open
andEfficientFoundationLanguageModels. InarXivpreprintarXiv:2302.13971,2023.
[42] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,
ŁukaszKaiser,andIlliaPolosukhin. AttentionisAllYouNeed. InI.Guyon,U.VonLuxburg,
S.Bengio,H.Wallach,R.Fergus,S.Vishwanathan,andR.Garnett,editors,AdvancesinNeural
InformationProcessingSystems(NeurIPS),volume30,2017.
[43] LeiWang,ChenMa,XueyangFeng,ZeyuZhang,HaoYang,JingsenZhang,ZhiyuanChen,
JiakaiTang,XuChen,YankaiLin,etal. Asurveyonlargelanguagemodelbasedautonomous
agents. FrontiersofComputerScience,18(6):1–26,2024.
[44] MaxWeber. MaxWeber: SelectionsinTranslation. CambridgeUniversityPress,1978.
[45] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,brianichter,FeiXia,EdChi,
QuocVLe,andDennyZhou. Chain-of-thoughtpromptingelicitsreasoninginlargelanguage
models. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors,
AdvancesinNeuralInformationProcessingSystems,volume35,pages24824–24837.Curran
Associates,Inc.,2022.
[46] LilianWeng. Llm-poweredautonomousagents. lilianweng.github.io,Jun2023.
[47] Wikipediacontributors. Friends(tvseries)—Wikipedia,thefreeencyclopedia,2024.
[48] MichaelWooldridgeandNicholasR.Jennings. Intelligentagents: theoryandpractice. The
KnowledgeEngineeringReview,10(2):115–152,1995.
[49] Chien-ShengWu,AndreaMadotto,EhsanHosseini-Asl,CaimingXiong,RichardSocher,and
PascaleFung. Transferablemulti-domainstategeneratorfortask-orienteddialoguesystems.
InProceedingsofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics,
pages808–819,2019.
[50] KevinWu,EricWu,andJamesZou. Howfaithfulareragmodels? quantifyingthetug-of-war
betweenragandllms’internalprior. arXivpreprintarXiv:2404.10198,2024.
[51] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang,
Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong,
Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin,
Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng,
XipengQiu,XuanjingHuan,andTaoGui. Theriseandpotentialoflargelanguagemodelbased
agents: Asurvey. CoRR,abs/2309.07864,2023.
[52] HainiuXu,RuncongZhao,LixingZhu,JinhuaDu,andYulanHe. Opentom: Acomprehensive
benchmarkforevaluatingtheory-of-mindreasoningcapabilitiesoflargelanguagemodels.arXiv
preprintarXiv:2402.06044,2024.
[53] RuijieXu,ZengzhiWang,Run-ZeFan,andPengfeiLiu. Benchmarkingbenchmarkleakagein
largelanguagemodels. arXivpreprintarXiv:2404.18824,2024.
[54] SoheeYang,ElenaGribovskaya,NoraKassner,MorGeva,andSebastianRiedel. Dolarge
language models latently perform multi-hop reasoning? arXiv preprint arXiv:2402.16837,
2024.
[55] ZhengzheYangandJinhoDChoi. Friendsqa: Open-domainquestionansweringontvshow
transcripts. InProceedingsofthe20thAnnualSIGdialMeetingonDiscourseandDialogue,
pages188–197,2019.
15[56] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik
Narasimhan. Treeofthoughts: Deliberateproblemsolvingwithlargelanguagemodels. In
A.Oh,T.Naumann,A.Globerson,K.Saenko,M.Hardt,andS.Levine,editors,Advancesin
NeuralInformationProcessingSystems,volume36,pages11809–11822.CurranAssociates,
Inc.,2023.
[57] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuan
Cao. React: Synergizingreasoningandactinginlanguagemodels. InInternationalConference
onLearningRepresentations(ICLR),2023.
[58] Yuanshun Yao, Xiaojun Xu, and Yang Liu. Large language model unlearning. In Socially
ResponsibleLanguageModellingResearch,2023.
[59] HughZhang,JeffDa,DeanLee,VaughnRobinson,CatherineWu,WillSong,TiffanyZhao,
Pranav Raja, Dylan Slack, Qin Lyu, et al. A careful examination of large language model
performanceongradeschoolarithmetic. arXivpreprintarXiv:2405.00332,2024.
[60] ZhilingZheng,OufanZhang,ChristianBorgs,JenniferTChayes,andOmarMYaghi. Chatgpt
chemistryassistantfortextminingandthepredictionofmofsynthesis. JournaloftheAmerican
ChemicalSociety,145(32):18048–18062,2023.
[61] KunZhou,YutaoZhu,ZhipengChen,WentongChen,WayneXinZhao,XuChen,YankaiLin,
Ji-RongWen,andJiaweiHan. Don’tmakeyourllmanevaluationbenchmarkcheater. CoRR,
abs/2311.01964,2023.
[62] XuhuiZhou,ZheSu,TiwalayoEisape,HyunwooKim,andMaartenSap. Isthisthereallife?
isthisjustfantasy? themisleadingsuccessofsimulatingsocialinteractionswithllms. arXiv
preprintarXiv:2403.05020,2024.
[63] Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-
PhilippeMorency,YonatanBisk,DanielFried,GrahamNeubig,andMaartenSap. SOTOPIA:
Interactiveevaluationforsocialintelligenceinlanguageagents. InTheTwelfthInternational
ConferenceonLearningRepresentations,2024.
16