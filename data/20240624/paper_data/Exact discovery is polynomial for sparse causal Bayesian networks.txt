Exact discovery is polynomial for
sparse causal Bayesian networks
FelixL.Rios GiusiMoffa JackKuipers
DepartmentofMathematics DepartmentofMathematics D-BSSE
andComputerScience andComputerScience ETHZurich
UniversityofBasel UniversityofBasel Basel,Switzerland
Basel,Switzerland Basel,Switzerland jack.kuipers@bsse.ethz.ch
Abstract
CausalBayesiannetworksarewidelyusedtoolsforsummarisingthedependencies
between variables and elucidating their putative causal relationships. Learning
networksfromdataiscomputationallyhardingeneral. Thecurrentstate-of-the-art
approachesforexactcausaldiscoveryareintegerlinearprogrammingovertheun-
derlyingspaceofdirectedacyclicgraphs,dynamicprogrammingandshortest-path
searchesoverthespaceoftopologicalorders,andconstraintprogrammingcombin-
ingboth. Fordynamicprogrammingoverorders,thecomputationalcomplexity
isknowntobeexponentialbase2inthenumberofvariablesinthenetwork. We
demonstratehowtousepropertiesofBayesiannetworkstoprunethesearchspace
andlowerthecomputationalcost,whilestillguaranteeingexactdiscovery. When
includingnewpath-searchanddivide-and-conquercriteria,weproveoptimality
inquadratictimeformatchings,andpolynomialtimeforanynetworkclasswith
logarithmically-boundlargestconnectedcomponents. Insimulationstudieswe
observethepolynomialdependenceforsparsenetworksandthat,beyondsomecrit-
icalvalue,thelogarithmofthebasegrowswiththenetworkdensity. Ourapproach
thenout-competesthestate-of-the-artatlowerdensities. Theseresultstherefore
pavethewayforfasterexactcausaldiscoveryinlargerandsparsernetworks.
1 Introduction
CausalBayesiannetworkshaveinthelastdecadesbecomestandardmodelsfordescribingcausal
relationshipsamongasetofrandomvariablessincetheirdirectededgesmayprovideapowerful
handleforcomplexcausalqueries. Inlinewithincreasedgeneralinterestincausality,theinterest
inautomaticproceduresforlearningthestructureofBayesiannetworksencodingtheprobabilistic
dependencies of causal mechanisms, so-called causal discovery, has also increased. Although
finding the best tree is polynomial [Chow and Liu, 1968], there is no guarantee that the optimal
treeisalsooptimalamongstallnetworksandcausaldiscoveryisingeneralNP-hard[Chickering,
1996,Chickeringetal.,2004]. Forthisreason,mostexistingalgorithmsarebasedonheuristicor
approximatemethods,andaplethoraofdifferentapproachesandimplementationsexist[Scutarietal.,
2019,Riosetal.,2021]. Theseareusuallyeitherscore-based,whereeachnetworkhasagoodness
offitscoretothedata,constrained-based,wherenetworksarelearnedbyindependencetesting,or
hybridcombiningbothaspects. Withtherecentdevelopmentofsoftwarepackages[Riosetal.,2021]
forusingandcomparingalgorithms,wecanexpectthepaceofadvancestocontinuetoincrease.
Inthispaper,wewishtoexaminetheNP-hardnessindetailandfocusonexactscore-basedcausal
discovery. Thecurrentstate-of-the-artapproaches[Maloneetal.,2018]areintegerlinearprogram-
ming(ILP)overtheunderlyingspaceofdirectedacyclicgraphs(DAGs)[BartlettandCussens,2017,
Cussensetal.,2017,Cussens,2020],dynamicprogramming[KoivistoandSood,2004,Silanderetal.,
2006]andpathsearches[YuanandMalone,2013]overthespaceoftopologicalorders[Friedman
4202
nuJ
12
]OC.tats[
1v21051.6042:viXraandKoller,2003,TeyssierandKoller,2005]. Finallyconstraintprogrammingapproachesuseboth
spaces[vanBeekandHoffmann,2015,Trösseretal.,2021],andcomparedtodynamicprogramming,
theyprunenetworksthatcanneverbeoptimal.
Here,wepresentanalgorithmforexactcausaldiscoverywithnewpruningrulesforsequentially
eliminatingsuborders. Alsoincludedarealternativeboundsonpathsearches[YuanandMalone,
2013],computableatlowcomplexity,furtherallowingustoproveoptimalityinpolynomialtime
for matchings (graphs with at most one neighbour for each node). Combining our pruning rules
withanewdivide-and-conqueralgorithm,wecanextendpolynomialexactdiscoverytoclassesof
sparsegraphs. Therestofthepaperisstructuredasfollows. Section2reviewsorder-basedexact
structurelearning. Section3describesournewpruningapproach,whichweusetoproveoptimality
formatchingsandcertainclassesofsparsegraphsinpolynomialtimeinSection4. InSection5we
empiricallydemonstratethepolynomialdependenceofourmethod,andhowthehardnessdepends
onthenetworkdensitybeyondsomecriticalpoint. Section6providesadiscussionofourresults.
1.1 Preliminaries
Let =(V,E)beaDAGwithvertexsetV = 1,...,p andedgesetE. Theverticescorrespond
G { }
totherandomvariablesinaBayesiannetworkandtheedgestothedirectdependencebetweenpairs
ofnodes. FollowingthefactorisationofthejointprobabilitydistributionofaBayesiannetworkas
P(V)=(cid:81)p
P(i Pa ),wherePa aretheparentsofnodei,thelog-scoreofanetworkis
i=1 | i i
p
(cid:88)
σ( )= σ(i,Pa D) (1)
i
G |
i=1
whereσ isafunctionofthedataD dependingonlyonanodeanditsparents. Examplesinclude
penalisedlikelihoods,liketheBIC,ormarginalisedlikelihoods,liketheBDeforcategoricaldata
[HeckermanandGeiger,1995]andtheBGeforlinear-Gaussiandata[GeigerandHeckerman,2002,
Kuipersetal.,2014].
ThetaskofexactcausaldiscoveryistofindaDAGthatmaximisesthescore: argmax σ( ). Each
G G
DAGbelongstoatleastonetopologicalorder,v = v ,...,v ,ofthenodeswheretheedgesare
1:p 1 p
⟨ ⟩
pointingtotheleft. Thescoreofanodev inanorderdependsonasubsetofthenodesfurtherright,
j
referredtoaspotentialparents. Wedenotethemaximumpossiblenodescoreby
s(v v )= max σ(v ,Pa D) (2)
j
|
j+1:p
Pavj⊆{vj+1:p}
j vj
|
Asaconsequence,morepotentialparentsforaspecificnodecannotdecreaseitsscore. Next,we
assigntoeachorderthescoreofanoptimalDAGconsistentwiththatorder
p
(cid:88)
S(v ):= s(v v ). (3)
1:p j j+1:p
|
j=1
FindinganorderwithanoptimalscorethenprovidesamaximallyscoringDAG[KoivistoandSood,
2004,TeyssierandKoller,2005]. Notethatdifferentordersofthesamesetofnodesmightgivethe
samescore,implyingthattheremightbemorethanoneoptimalordering. Sinceweonlyneedto
findone,wedistinguishanoptimalorder(OO)fromanorderedoptimalorder(OOO)whereany
neighbouringnodesinanOOwiththesamescoreontranspositionareinnumericalorder.
OurtaskistofindtheOOO,andhenceaDAG,withthemaximumscore. Wefocusonfindingthe
highest-scoringnetworkinarestrictedsearchspacewhereeachnodehasapreselectedsetofparents,
uptototalsizeK andoneadditionalparentoutsidethatset. Onewaytoobtainthesearchspaceis
withahybridapproach,startingfromaconstraint-basedskeletonanditerativelyimprovingitwith
search-and-score[Kuipersetal.,2022]. Wefocusonthissettingsinceaccessingtherelevantscoresis
highlyefficient,whiletheiterativeapproachofupdatingthesearchspace,andsubsequentsampling
of DAGs [Kuipers et al., 2022], has been shown to offer good performance in causal discovery
benchmarks[Riosetal.,2021]aswellasenablingBayesiananalyses.
We distinguish between two types of suborders of length n, left and right orders, denoted as
⇀ ↼
v = v ,[...] and v = [...],v ,respectively. Fortidyness,weremovebracketsinthe
1:n 1:n n:1 n:1
⟨ ⟩ ⟨ ⟩
subscriptssov =:v . Thesquarebracketnotationsymbolisesthesetofthenodes
(a+b):(c+d) a+b:c+d
2∅
+1 +3 +4
1 2 3 4
+1 +1
+2
+3
+4 +1 +3
+2 +2
+3
+4 +4
1,2 3,1 1,4 3,2 4,2 3,4
++ 34 2+ +4
+1
+2
+3 +1 +4
3+ + +1
2
3,1,2 1,4,2 3,1,4 3,4,2
+4 +3 +2 +1
3,1,4,2
Figure1: Theorderedpowersetrepresentationofpruningallp!ordersto2porderedsubsets.
Movingdownthediagramweappendthenewnodeindicatedontheedgetothefront(back)ofthe
previousright(left)suborders. Wecomparetheincomingsubordersateach(orange)nodeandonly
keepthebest. ArrivingatthebottomofthediagramwehavetheOOO.Thedashedpathsarriveatthe
OOOwhenappendingatthefront(red)orback(blue).
outsidetheorder, V v n ,whichwerefertoashidden. Eachsuborderrepresentsthesetof
ordersmatchingthes\ pe{ cij fi} cj= or1 deringofthevisible(i.e. nothidden)nodes,thusforanorderv∗we
maywritestatementslikev∗ [...],v . Thehiddennodeshavenointernalorder. However,
n:1
∈ ⟨ ⟩
whenneededwemayexplicitlylabeltheminthenotationas [h],v . Finally,wecalltheleft-and
n:1
⟨ ⟩
right-mostnodesinasuborderthefrontandback,respectively.
Definition1. Thescoreofa(sub)orderisthesumofthescoresfortheindividualvisiblenodes.
Forleftorders,say,wetruncatethesumin(3)toj n. Lets ( A B)denotethemaximalscore
max
≤ { }|
amongtheorderingsofasetofnodesAwhereBarepotentialparentsofallnodesinA.
2 Exactcausaldiscovery
Here we present a version of the exact causal discovery algorithm of Koivisto and Sood [2004],
rephrasedintermsofright(left)ordersthatwewillneedlater.
2.1 Permutationtrees
Sincethescoreofeachnodeonlydependsonpotentialparents,wecancomputethescoreofeach
right(left)orderbyaddingnewnodestothefront(back)oneattime. Thiscreatesatreeofallp!
orders,fromwhichwecanexhaustivelyfindanoptimalorder. Toreducecomplexity,onecanusethe
factthatoptimalityofanorderisinheritedbyitssuborders:
↼ ⇀
Theorem1. Foragivenoptimalright(left)order v (v )ofU V,theright(left)suborder
n:1 1:n
↼ ⇀ ⊂
v (v )isanoptimalright(left)suborderofU v .
n−1:1 1:n−1 n
\{ }
↼
Proof. Suppose v isnotanoptimalrightsuborderofU v . Thenthereexistsasuborder
n−1:1 n
↼ ↼ ↼ \{ }
w withS(w )>S(v ). Appendingv infront
n−1:1 n−1:1 n−1:1 n
↼ ↼ ↼
S( [...],v ,w )=s(v w )+S(w )>s(v w )+S(v )=S(v )
n n−1:1 n n−1:1 n−1:1 n n−1:1 n−1:1 n:1
⟨ ⟩ | |
↼
then v isnotoptimal,whichisacontradiction. Theproofforleftsubordersisanalogous.
n:1
↼ ⇀
Corollary1. Foragivenoptimalright(left)suborder v (v )ofU V,theright(left)suborder
n:1 1:n
↼ v (⇀ v )for1 k nisanoptimalright(left)suborderofU⊂ v n .
n−k:1 1:n−k ≤ ≤ \{ j }j=n−k+1
Proof. ApplyTheorem1severaltimes.
3
2+2.2 Orderedpowerset
Toreducethecomplexityfromfactorial,KoivistoandSood[2004]essentiallyusedTheorem1to
prunesuborderswiththesamesetofnodesbycomparingtheirscoresandkeepingonlyonewiththe
highestscore. WeillustratethisinFigure1whereweprojectthepermutationtreeontotheordered
powersetorHassediagramofthenodesubsets.
At stage n, we have the (cid:0) p (cid:1) orders from stage (n 1) each appended with (p n+1) new
elementstocreate(p n+n− 11 )(cid:0) p (cid:1) =p(cid:0)p−1(cid:1) =n(cid:0)p−(cid:1) subordersoflengthn. −
− n−1 n−1 n
Pruning1(Suborderpruning). Atstagen,wegothrougheachgroupofnsuborderswiththesame
setofnodesandkeeponlyonewiththehighestscore. Ifseveralsubordershavethesamescore,we
retaintheonewiththelasttwonodesinnumericalorder(lowernodenumbertotheleft).
Theorem2. TheOOOwillnotbepruned.
Proof. ByTheorem1,anysuborderoftheOOOwillbeamongstthehighestscoringonthatsetof
nodes,whilethetransposablenodesoftheOOOareinnumericalorderbyconstruction.
Corollary2. TheresultingorderatthelaststageofthetreepruningistheOOO.
Thisis,forexample,theorderedsubsetatthebottomofthepowersetofFigure1.
2.3 Complexity
In the setting of Koivisto and Sood [2004], since the power set is complete we can compare the
scoresofallthen(cid:0)p(cid:1)
subordersatstageninlineartimeusingtheirindexingintheHassediagram,
n
givingatotalcomplexityof (p2p)forthetreepruning. Inaddition,thelookupofeachscorewhen
appending a new node is
asO
sumed to be (1), so scoring all the
n(cid:0)p(cid:1)
new suborders at stage n
O n
alsoleadstoatotalcomplexityof (p2p). ThealternativeapproachofSilanderetal.[2006]which
O
exhaustivelychecksforthebestsinkstobuildupanOOfromthefrontlikewisehascomplexityof
(p2p).
O
Koivisto and Sood [2004] showed how to use the Möbius transform to reduce the complexity
to (2p), however this relies on precomputing various score tables. They allowed each node to
O
have up to K possible parents from any of the p available and computing the score table takes
(C(m,p,K)pK+1),whereC isthetimeofeachlocalscorecomputation,possiblydependingon
O thedatasizem. Thereafterscoresarecombinedgivinganoverallcomplexityof (p2p).
O
InoursettingweallowK parentsfromapreselectedsetsothatcreatingtheoriginalscoretablesis
(C(m,p,K)p2K)andcomputingcombinedscoretablesis (p2K)[Kuipersetal.,2022]. Inorder
O O
tonotfullytrustthepreselectedsearchspace,weallowoneadditionalparentoutside. Appendinga
newnodetoasuborderinvolveslookingup (p)scores,sothebaselinecomplexitywillbe (p22p).
O O
3 Loweringthecomplexityofexactcausaldiscovery
Inthefollowingweshowthatwecanbuildthefulloptimalorderstartingwiththeemptyorder,and
thatateachstepnwecanprunethesubordersoflengthnthatwillnotleadtotheoptimalorder. In
particular,whenweaddnodesweonlyneedtokeepthosewhoseplacementisoptimal.
Theorem3. LetM =([...])andletforeachn p,M bethesetofright(left)ordersoflength
0 n
≤
ncreatedbyaddinganodeatthefront(back),onlyifthatnodeisoptimalthere,ofsomeorderin
M . TheneachM containsthesuborderofanoptimalorderv∗ M .
n−1 n p
∈
Proof. WeproveinductivelythateachM containsthesuborderofanoptimalorderv∗ M . For
n p
n=1,everynodeisoptimalatthebacksoM = [...],j p anditisclearthatsom∈ eelement
1 {⟨ ⟩}j=1
hereisasuborderoftheoptimalorder. Forn > 1weassumeinductivelythatM containsthe
n−1
suborderoftheoptimalfullorder. Let↼ v beasuborderofv∗. Thenweneedtoprovethatitcanbe
n:1
↼ ↼
constructedfromsomeorderinM . Clearly, v iscreatedfrom v byaddingv attheback.
n−1 n:1 n−1:1 n
Since↼ v isasuborderofv∗weknowbyCorollary1thatitisoptimalon v n . ByTheorem1,
n:1 { j }j=1
↼ v isoptimalon v n−1sobytheinductionhypothesisitmustbecontainedinM .
n−1:1 { j }j=1 n−1
4Corollary3. AfullOOcanbebuiltbyonlyaddingnewnodestothefront(back),startingfromthe
emptyorder.
Proof. ByTheorem3,M willcontaintheoptimalorder.
p
3.1 Pruningrightorders
Wefocusonpruningspecificallyforrightsuborders. Ifanodeaddedtothefrontofarightorderwere
tofitbetterfurtheralongtheorder,thenwecanprunebyTheorem3.
↼ ↼
Pruning2(Optimalfront). Weprune v ifwehaveS( [...],v ,v ,v )>S(v )for
n:1 n−1:k n k−1:1 n:1
⟨ ⟩
somek <n.
Wecanfurtherensurenumericalorderinginthecaseofequalscoreundertransposition.
↼ ↼
Pruning 3 (Ordered front). We prune v if v > v and S(v ) =
n:1 n n−1 n:1
S( [...],v ,v ,v ).
n−1 n n−2:1
⟨ ⟩
Boththesepruningruleshavebeenemployedpreviously[vanBeekandHoffmann,2015]. Forfurther
pruning,however,weusethefollowingobservation:
↼
Lemma1. Foranypartitiona bofthehiddennodesinarightsuborder v itholdsthat
n:1
∪
s ( a b v ) s ( a b,v )+s ( b a,v ). (4)
max n:1 max n:1 max n:1
{ ∪ }| ≤ { }| { }|
Proof. Ontherightthenodesinaandbareallowedallthenodesinbandaasparentsrespectively,
whileonthelefttherearerestrictionsinducedbytheorderingofa b,sothosescorescanonlybe
∪
lowerorequal.
↼
Theorem4. IfS(v )=S( v ,[...],v )then max S(v) max S(v).
n:1 n n−1:1
⟨ ⟩ v∈⟨[...],vn−1:1⟩ ≤v∈⟨[...],vn:1⟩
Proof. Wedenotebyh=V v n thehiddennodesof↼ v . Themaximalscoreofanorderin
\{ j }j=1 n:1
↼
v is
n−1:1
↼
max S(v)=s ( h,v v )+S(v )
max n n−1:1 n−1:1
v∈⟨[...],vn−1:1⟩ { }|
↼
s ( h v )+s(v h,v )+S(v )/by(4)
max n:1 n n−1:1 n−1:1
≤ { }| |
↼
=s ( h v )+S( v ,[...],v )=s ( h v )+S(v )= max S(v).
max n:1 n n−1:1 max n:1 n:1
{ }| ⟨ ⟩ { }| v∈⟨[...],vn:1⟩
Theorem4meansthatifthescoreofv isindependentofthehiddennodes,thetotalorderscore
n
cannotbeimprovedbyputtingsomeothernodeatthefront. Sincewehaveanumericalordering
constraintinthecaseofequalscores,wecanpruneforanynodewithalowernumberthanthose
whosescoreisindependentofthehiddennodes.
Pruning4(Norightgaps). Consideralltherightordersoflengthncreatedfrom↼ v . Letv′
n−1:1 n
bethemaximalnodenumbersuchthatS( [...],v′,v )=S( v′,[...],v ). Wepruneall
suborders↼ v wherev <v′. ⟨ n n−1:1 ⟩ ⟨ n n−1:1 ⟩
n:1 n n
Inordertoprunefurther,weconsiderthehiddennodesinmoredetail.
Theorem5. Let↼ v M andv∗ beanoptimalorderofV. Thenv∗ / ↼ v ifforanyhidden
n:1 n n:1
∈ ∈
nodehandk nwehaveS( [...],v ,h,v )>S( h,[...],v ).
n:k k−1:1 n:1
≤ ⟨ ⟩ ⟨ ⟩
Proof. Withhasinglehiddennodeandh = V h v n thesetofotherhiddennodes, we
\ ∪{ j }j=1
showthatthemaximalscoreofanorderin [h],v ,h,v isgreaterthanthemaximalscorein
n n−1:1
⟨ ⟩
[h,h],v . Fromthesettingwehave
n:1
⟨ ⟩
↼
S( h,[...],v )=S( h,[...] )+S(v )<S( [...],v ,h,v ). (5)
n:1 n:1 n−k k−1:1
⟨ ⟩ ⟨ ⟩ ⟨ ⟩
5↼
Themaximalscoreofanorderin v is
n:1
↼ ↼
max S(v)=s ( h,h v )+S(v ) s(hh,v )+s ( h h,v )+S(v )/by(4)
max n:1 n:1 n:1 max n:1 n:1
v∈⟨[...],vn:1⟩ { }| ≤ | { }|
=s ( h h,v )+S( h,[...],v )<s ( h h,v )+S( [...],v ,h,v )/by(5)
max n:1 n:1 max n:1 n:k k−1:1
{ }| ⟨ ⟩ { }| ⟨ ⟩
= max S(v),
v∈⟨[...],vn:k,h,vk−1:1⟩
whichisthemaximalscoreofanorderin [...],v ,h,v ,sov∗ / ↼ v .
n:k k−1:1 n:1
⟨ ⟩ ∈
↼
Pruning5(Removinghiddenrightgaps). Weprune v ifforanyhiddennodeh,andforsome
n:1
k n,wehaveS( [...],v ,h,v )>S( h,[...],v ).
n:k k−1:1 n:1
≤ ⟨ ⟩ ⟨ ⟩
Inotherwords,wecheckifv ispushedasfartotherightaspossible,orifthetotalscorecould
n
beimprovedbyinsertinganothernode(h)asapotentialparent. Ifso,weprune. Iftheyhaveequal
score,weimposethefollowingsortingcriteria.
↼
Pruning6(Orderinghiddenrightgaps). Weprune v ifthereisahiddennodeh>v suchthat
n:1 n
S( [...],v ,h,v )=S( h,[...],v ).
n n−1:1 n:1
⟨ ⟩ ⟨ ⟩
3.2 Globalpruning
Alongwiththepruningrulesforright(left)orders,wehavetheglobalsuborderpruning(Pruning1)
whichwerestateforpotentiallydifferingnumbersofsuborders:
Pruning7(Removingduplicates). Atstagen,wehaveN orders,MN,oflengthn. Wegothrough
n
alltheorderswiththesamesetofnodesandkeeponlyonewiththehighestscore,orinnumerical
orderwiththesamescore.
One can also consider left orders of length n as subject for pruning, which we discuss in the
SupplementaryMaterial(SectionS.1),wherewealsodetailthecomputationalcomplexityofthe
scheme(SectionS.2). WeoutlinethemainorderpruningstepsinSupplementaryAlgorithms1and2,
whilethepseudocodeforeachPruningisalsodetailedintheSupplementaryMaterial.
3.3 Path-searchpruning
IntheA∗searchalgorithmofYuanandMalone[2013],subordersareprunedwhenanupperbound
oftheirscoresincludingthehiddennodesislessthan(orequal)tothecurrentbestorderscore. We
willdenotethecurrentbest(full)orderv∗withscoreS∗ =S(v∗),andg(↼ v )astheupperbound
n:1
↼
scoreofthehiddennodesof v .
n:1
Pruning8(A∗). Weprune↼ v ifS(↼ v )+g(↼ v ) S∗.
n:1 n:1 n:1
≤
Thetaskthenistofindaslowanupperboundaspossibleinlowcomputationaltime. Toproceedwe
usetheobservation(Lemma1andYuanandMalone[2013])thatforanypartitionΛofthehidden
nodesU =V v n inarightsuborder↼ v wehave
\{ j }j=1 n:1
m
(cid:88)
s ( U V U) s ( Λ V Λ ) (6)
max max i i
{ }| \ ≤ { }| \
i=1
where the Λ are the m parts of Λ. In Yuan and Malone [2013] they considered separating into
i
setsofsizekandfindingtheoptimalsetsthatminimisetherighthandsideabove. Fork = 2this
isequivalenttofindingoptimalmatchings,whichcanbeachievedincubictimewithavariantof
Edmond’sblossomalgorithm. However,fork >2theproblemiscomputationallyhardandinYuan
andMalone[2013]theyfocussedonheuristicapproachestofindbounds.
Alongwithpruning,wecanalsoupdateourcurrentbestorderv∗ifwecanfindabetterone. Here,
guidedbythecomplexity,wefollowadifferentheuristicapproachfortheupperbound,thatwilllater
allowustoproveoptimalityinpolynomialtimeformatchings. Weconsiderthebestscoringtreeon
↼
thehiddennodes,whichwedenote (v ). ToobtainthistreewedefinethematrixF withentries
n:1
T
F =S( [...],v ,v ) S( [...],v ) S( [...],v ) (7)
ij i j i j
⟨ ⟩ − ⟨ ⟩ − ⟨ ⟩
6whichisthedifferenceinscorebetweenallowinganedgebetweennodesv andv andexcludingsuch
i j
anedge. ThematrixF issymmetric,sincepairwiseedgesarescore-equivalent,andtheminimum
valuewillbe0inthecaseexcludingtheedgefitsthedatabetter.
ThehighestscoreofatreenetworkonthehiddennodesU =V v n ofarightorder↼ v is
\{ j }j=1 n:1
↼ (cid:88) (cid:88)
f(v )= F + S( [...],u ) (8)
n:1 e
⟨ ⟩
e∈T(↼vn:1) u∈U
↼
whereearetheedgesintheundirectedmaximumspanningtree (v )foundfromtherelevant
n:1
T
submatrixofF,forexample,withPrim’salgorithm[Prim,1957]. Sincetreesarescore-equivalent
anydirectionimposedonthetreeand,moreimportantly,anyorderingofthehiddennodescompatible
↼
withthebestscoringtreewillhaveanequalorhigherscorethanf(v ).
n:1
Update1.
Weupdatev∗ifforanyrightorder↼
v
n:1
f(↼ v )+S( [...],↼ v )>S∗ (9)
n:1 n:1
⟨ ⟩
Inadditionwecanalsocomparetothecurrentbestorder
Update2.
Weupdatev∗ifforanyrightorder↼
v
n:1
S( v∗ ↼ v ,↼ v )>S∗ (10)
n:1 n:1
⟨ \ ⟩
wherev∗ ↼ v denotesremovingtheelementsof↼ v fromv∗ andkeepingtherestinthesame
n:1 n:1
\
order.
Fortheupperboundinstead,givenatreewecanfindtheoptimalmatchinginlineartime. Wethen
↼
usethismatchingforourupperboundg(v ). ForthecomputationweusethesymmetricmatrixG
n:1
whichrecordsthemaximalrelativescoreofanypairofnodes
G =s ( v ,v V v ,v ) S( v ,[...] ) S( v ,[...] ) (11)
ij max i j i j i j
{ }| \{ } − ⟨ ⟩ − ⟨ ⟩
↼ ↼
Ifwedefine (v )tobetheoptimalmatchingobtainedfrom (v ),theupperboundis
n:1 n:1
M T
↼ (cid:88) (cid:88)
g(v )= G + S( u,[...] ) (12)
n:1 e
⟨ ⟩
e∈M(↼vn:1) u∈U
↼
If the best tree score matches the upper bound g(v ), the tree network on the hidden nodes is
n:1
optimalandwedonotneedtocontinueexpandingthesuborder:
↼ ↼ ↼
Pruning9(Optimality). Iff(v )=g(v ),weprune v .
n:1 n:1 n:1
Aneatcorollaryisthat,ifthebestnetworkisamatching,wecanproveoptimalityinquadratictime
(seeSection4.2). Finally,iftheactualscoreofthehiddennodeswithinanyoftheupdaterulesis
↼ ↼
largerthanf(v )butmatchestheupperboundg(v ),wecanalsoprune.
n:1 n:1
3.4 Divide-and-conquer
Theresultformatchingssuggeststhatifthebestnetworkisdisconnectedwecouldleveragethisto
furtherspeedupthecausaldiscovery. Toextendpairwisedisconnectiontogeneralnetworkswefirst
considerhoweachparentaffectsthescoresforeachchild.
WedefinematricesH,whoseentriesfornodev arethebiggestincreaseinscorefromincludingv
i j
asaparentofv ,comparedtoexcludingit,foranypossibleparentset:
i
Hmax =max σ(v ,Pa v D) σ(v ,Pa v D) (13)
i,j Pavi { i vi ∩ j | − i vi \ j | }
andthebiggestdecreaseinscore(mostnegativechange)whenincludingv asaparentofv :
j i
Hmin =min σ(v ,Pa v D) σ(v ,Pa v D) (14)
i,j Pavi{ i vi ∩ j | − i vi \ j | }
ThenexttheoremstatesthatifallparentsetsofanynodeinasetA V gethigher(orequal)scores
⊂
whenexcludinganynodefromasetB V,andviceversa,thenAandBmustbedisconnectedin
⊂
theoptimalDAG.
7Theorem 6. If for any subsets A,B V we have Hmax 0 and Hmax 0, then A,B are
⊂ A,B ≤ B,A ≤
disconnectedinanoptimalDAG.
Proof. Assumethereisanedgefroma Atob B intheoptimalDAG, . SinceHmax 0,
∈ ∈ G b,a ≤
removingthatedgewouldnotdecreasethescore,soeither wasnotoptimalwhichisacontradiction,
G
orthereisanotheroptimalnetworkwithouttheconnection. Likewise,ifthereisanedgefromb B
∈
toa A.
∈
Corollary4. Fordisconnectedcomponents,denoted ,ofthegraphinducedbyHmax >0,wecan
u
C
runtheordersearchindependently.
This allows us to separate the network into sets of corresponding random variables which are
independent. However,itmaynotfindalldisconnectedcomponentsintheoptimalnetwork,soto
proceedwealsoconsiderHmin. IfA V andB V areindifferentcomponentsofanoptimal
⊂ ⊂
DAG,weknowthataddinganyedgefromb Btoa Awouldreduce(orleaveequal)thescoreof
theparentsetofa,soHmin 0. Likewisef∈ oredgesf∈ romAtoB. Thisargumentleadsto:
a,b ≤
Theorem7. IfsubsetsA,B V aredisconnectedinanoptimalDAGthen a A,b B,wehave
Hmin 0andHmin 0. ⊂ ∀ ∈ ∈
a,b ≤ b,a ≤
Disconnected subcomponents from the matrix Hmin might not be disconnected in the optimal
network. Instead
Corollary5. Disconnectedsubcomponents,denoted ,inthegraphinducedbythebooleanmatrix
l
Hmin >0arepotentiallydisconnectedinanoptimalC DAG.
Each subcomponent from Corollary 5 is contained in one component of from Corollary 4,
l u
C C
whichcanbetreatedindependently. Thereforewefirstorganizethemaccordinglyandthenfindthe
optimalDAGasfollows:
Divide-and-conqueralgorithm.
1. RuntheordersearchindependentlyforeachcomponentA withallothernodesas
l
∈↼C
potentialparents. LetthisoptimalorderingofAbedenotedby v andthecorresponding
A
optimalDAGby .
A|V\A
G
2. Treatthecomponents asthenodesetofanetwork . ForanypairofnodesA,Bin ,
l
C N N
drawanedgeA BifanynodeinG hasaparentinB.
A|V\A
←
3. Find the cycles in . Merge nodes along cycles and intersecting cycles to form a new
N
componentset . Ifnocycleswerefoundgotostep4,otherwisereturntostep1andrerun
l
C
theordersearchformodifiedcomponents.
↼
4. AnOOisobtainedbyconcatenatingeachoptimalorder v correspondingtothenodes
A
Ain accordingtoatopologicalorderof . TheunionoftheDAGs givesthe
A|V\A
N N G
correspondingoptimalDAG.
4 Polynomialcausaldiscovery
Hereweusecomponentsofthepruningrulesabovetoprovepolynomialexactcausaldiscoveryfor
certainclassesofcausalBayesiannetworks.
4.1 Theemptygraph
Fortheemptygraph,wetriviallyhavethateachorderhasthesamescore,andthescoreofeachnode
doesnotdependontheplacementoftheothers. Sinceweusetheorderingrestrictions,forexample
inPruning3and6,thenwewouldpruneeveryorderapartfromthenumericallyorderedoneand
haveasingleparticleateachiteration. Overall,thisleadstoacubicalgorithm,oncewehavethe
scoretables. Thisresultishoweversubsumedbythefollowing.
84.2 Matchings
For the lower bound from the maximum spanning tree in Equation (8) there may be edges with
F =0. Inthiscase,thebestnetworkwouldnothaveanedgebetweenv andv . Ifthebesttreeisa
ij i j
matching,wecanonlyhaveedgesbetweendisconnectedpairsofnodes. Ifv andv arepairedinthe
i j
matching,thenwemusthaveF =0forallk =j andF =0forallk =i. IfnottheMSTwould
ik kj
̸ ̸
haveplacedanedgebetweenv orv andanothernode. Notethatthiswouldnothavecreatedacycle
i j
sincetheothernodewouldbepartofadistinctdisconnectedpair.
Boundsformatchings
Ifthebestnetworkisamatching,foreachconnectedpairv andv wemusthave
i j
S( v ,v ,[...] )=S( [...],v ,v ) (15)
i j i j
⟨ ⟩ ⟨ ⟩
and
S( v ,v ,[...] )=S( [...],v ,v ) (16)
j i j i
⟨ ⟩ ⟨ ⟩
sinceotherwisewecouldincludeotherparentsforoneofthenodes,increasethescoreandnolonger
haveamatching. Combinedthisis
s ( v ,v V v ,v )=S( [...],v ,v )=S( [...],v ,v ) (17)
max i j i j i j j i
{ }| \{ } ⟨ ⟩ ⟨ ⟩
Lookingatoneofthenodes
S( v ,[...] )=S( v ,v ,[...] ) S( [v ],v ,[...] )=S( [...],v ,v ) S( [...],v ) (18)
i i j i j i j j
⟨ ⟩ ⟨ ⟩ − ⟨ ⟩ ⟨ ⟩ − ⟨ ⟩
comparingtoEquations(7)and(11)wehave
G = F (19)
ij ij
−
Ontheotherhand,ifv andv aredisconnectedinthematching,
i k
s ( v ,v V v ,v )=S( v ,[...] )+S( v ,[...] ) (20)
max i k i k i k
{ }| \{ } ⟨ ⟩ ⟨ ⟩
sincetheirrelativeorderdoesnotmatter. Therefore
G =0= F (21)
ik ik
−
andoverallG= F whenthebestnetworkisamatching.
−
Equalityformatchings
SinceGandF areoppositeofeachother,theminimumspanningtreeforGisamaximumspanning
treeforF,andsothesamematchingisanMSTforG. Asafinalstep,weneedtoshowequalityof
thelowerandupperbounds:
↼ (cid:88) (cid:88)
f(v )= F + S( [...],v )
n:1 e
⟨ ⟩
e∈M(↼vn:1) v∈V
↼ (cid:88) (cid:88)
=g(v )= G + S( v,[...] ) (22)
n:1 e
⟨ ⟩
e∈M(↼vn:1) v∈V
Proof. Foranydisconnectednodeinthematching,sayv ,includinganyadditionalparentscannot
k
improvethescore,sinceonecouldincludeedgestothoseparentsandhaveatree,contradictingthat
ourbesttreeisamatching. Fordisconnectednodeswehave
S( [...],v )=S( v ,[...] ) (23)
k k
⟨ ⟩ ⟨ ⟩
andnocontributionsfromF orG. Otherwise,forconnectedpairs,v andv ,wehave
i j
F +S( [...],v )+S( [...],v )
ij i j
⟨ ⟩ ⟨ ⟩
=S( [...],v ,v )=S( v ,v ,[...] )
i j i j
⟨ ⟩ ⟨ ⟩
=G +S( v ,[...] )+S( v ,[...] ) (24)
ij i j
⟨ ⟩ ⟨ ⟩
fromthedefinitioninEquations(7)and(11),andtheresultin(15). Thetermsagreefordisconnected
nodesandpairsofconnectednodesinthematching,andsoagreefortheentirematching.
9Polynomialoptimalitytesting
IncomputingthescoretablesforF tofindthebesttree,weonlyneedtoconsidereachnodewithno,
oroneparent,andbuildingthematrixF canbedoneinquadratictimeforusualscoresliketheBDe
orBGe[HeckermanandGeiger,1995,GeigerandHeckerman,2002,Kuipersetal.,2014]. Finding
thebesttreenetworkiswell-knowntobepolynomial[ChowandLiu,1968],andwecandosofrom
F inquadratictime[Prim,1957].
ForthematrixG,however,weneedthebestscoringparentsetforeachnode,andthebestsubset
selectionproblemisgenerallyNP-hard[Natarajan,1995]. Witharestrictedsearchspace[Kuipers
etal.,2022],orarestrictedin-degree[FriedmanandKoller,2003],computingthescoretablesforG
becomespolynomial.
FindingtheoptimalDAGisNP-hardevenforarestrictedin-degree(ofatleast2,Chickering,1996,or
atleast3,Chickeringetal.,2004),soweconsiderthatcasewhereconstructingGisstillpolynomial.
FindingtheupperboundfromGislinearandcanlikewisebecomputedinpolynomialtime.
Overall,ifthebestcausalBayesiannetworkinasearchspacewithrestrictedin-degreeisamatching
thenthingssimplify. Wecanfindit(fromF)andproveitsoptimality(fromG)inpolynomialtime,
and,oncethescoretableshavebeencomputed,inquadratictime.
4.3 Sparsenetworks
Forsparsenetworks,ourdivide-and-conquerapproachtofindingdisconnectedcomponentswilllower
thecomplexitytothatofthelargestcomponent. Forexample,ifweconsidergraphswithamaximum
numberofedgesE,thelargestcomponentisboundbyE. Aslongaswecanfindthecomponentsin
polynomialtimethewholealgorithmispolynomialinp. Sincethenumberofcomponentsisbound
byp,thenumberofmergingpotentialcomponentsandre-runningtheoptimalsearchisalsoatmost
p,followingthedivide-and-conqueralgorithm. WhilefindinganetworkforeachisexponentialinE,
itisnotexponentialinpandtheexactcausaldiscoveryremainspolynomial.
Moregenerally,formanyrandomsparsenetworks,likeErdös–Rényigraphswithadensity≲1,there
isahighprobabilitythereisnogiantcomponentandthatthelargestcomponentsareoforderlog(p)
[MolloyandReed,1995,Newmanetal.,2001]. Findingthecomponentsinvolvesatmostlinear(in
p)networksearches, whileeachsearchisnowexponentialinlog(p), andhencepolynomialinp.
Therefore,foranysparsenetwork,aslongasthelargestconnectedcomponentremainslogarithmic
inpwehaveapolynomialalgorithmforexactcausaldiscovery.
ThesesubsetsofcausalBayesiannetworksthenconstituteanexceptionfromthegeneralNP-hardness
ofexactcausaldiscovery[Chickering,1996,Chickeringetal.,2004].
5 Simulationstudies
Toexaminethecomputationalcomplexityinpractice,weperformedsimulationstudiesfornetworks
ofsizesp 10,...,30 withasamplesizeof300. Foreachnetworksize,randomgraphswere
∈ { }
generatedusingthedefaultrandDAGfunctionfromtheR-packagepcalg[Kalischetal.,2012]with
averagedensity(neighbourhoodsize)ofd 0,0.1,...,2 . Continuousdataweregeneratedfroma
∈{ }
linearGaussianstructuralequationmodel,wherestrengthsoftheedges(regressioncoefficients)were
sampleduniformlyintherange[0.25,1]. Thisprocesswasrepeatedwith1000differentseeds.
Asapreliminarysteptorunouralgorithm,wefirstcalculatedthescoretablesusingtheBGescore
[Geiger and Heckerman, 2002, Kuipers et al., 2014] with mean hyper-parameter α = 0.1. We
µ
estimatedaDAGsearchspaceusingtheiterativeMCMCprocedure[Kuipersetal.,2022],which
includestheskeletonfromconstraint-basedtestingandoftheestimatedDAG,andwhereeachnode
is allowed an additional parent outside that core set. The procedure used the R-package BiDAG
Suter et al. [2023] and exported the output to our C++ program (available at https://github.
com/felixleopoldo/dncDagger). Totrackthecomplexity,werecordthenumberofsuborders
remainingafterpruning,N ,ateachstageofthemainalgorithm(SupplementaryAlgorithm1)and
n
(cid:80)
thetotalruntime. WealsocomputethetotalnumberofsubordersΣ = N . Sincethistotalis
N n n
boundby2p,thisisthemaincomponentwhereweexpectexponentialcomplexity.
10Figure2: ThelogarithmofthetotalnumberofsubordersΣ andtheoverallcomputationalruntimet
N
(inseconds)asafunctionofthenetworksizepandstratifiedbythenetworkdensityd.
Figure3: Theregressioncoefficientsofthelogarithmofthetotalnumberofsuborderslog (Σ )
2 N
against p and log (p), with standard errors, as a function of the network density d (the expected
2
neighbourhoodsize).
Theresults(Figure2andSupplementaryFigure1)showuptolinearbehaviourinthegrowthof
thelogarithmofthetotalnumberofsubordersforincreasingnetworkdimension, butalsothatit
dependsheavilyonthenetworkdensity. Infactford=0andnoedges,whentheemptygraphhas
thehighestscore,ourorderingconstraintmeansthatweonlykeeponesuborderateachstageso
Σ =p,andwegetsub-linearbehaviourwiththelogarithm. Ford=0.5themajorityofcasesalso
N
havealownumberofparticles,aswetypicallyexpectsmallcomponentsatthisdensity,butsome
outliersrequiringsignificantlymorestarttoappear.
Toexaminethismorecarefully,wefitaregressionlineforthetotalnumberofsuborders:log (Σ )=
2 N
ap+blog (p)+cforeachdensity.Thefittedcoefficients(Figure3)showthatwehavenoexponential
2
term(a=0)uptoadensityofaround0.4(andalinearterm,b=1),andthenthelogarithmofthe
baseoftheexponentialtermincreasesslowlyuptoadensityofaround1.2(inlinewiththeincreasing
spreadofoutliersinFigure2)andthenmorelinearlyforhigherdensities,whilethepolynomialterm
decreasestoaroundb=0. Forthedensitiesupto2considered,thecomplexityremainssubstantially
belowthetheoreticalmaximumofa=1(andb=0,whenallpossible2psubordersarekept). The
factthatmostexamplesrequirefewerparticlesatlowerdensityisclearerwhenweperformamedian
regression(SupplementaryFigure2)withlowerexponentialterma.
Intermsofruntime(Figure2),themajorityofcasesevenwithd=1completeveryquickly,though
someexamplestakemuchlonger,andthetypicaltimealsoincreasesatthehigherdensities. For
the runtime per suborder (Supplementary Figure 3), we would expect up to quadratic behaviour
inpaccordingtothecomplexityanalysis, theactualtimeseemsmorelinearforhigherdensities
suggestingthecomplexitymaybesub-quadraticinpractice. Takentogether,thepracticalruntimeis
muchlowerthantheworstcase (p22p). Asthisisthebestcasewithoutpruning,ourpruningrules
O
doseemtoallowustosignificantlylowerthecomplexityofexactcausaldiscovery.
WeadditionallycomparedtotheILPapproachofGOBNILP[BartlettandCussens,2017,Cussens
etal.,2017,Cussens,2020]bypassingitthetablesofscoresfromthesamesearchspace. Though
GOBNILP uses highly optimised solvers, it only has a runtime advantage at the higher density
11(SupplementaryFigure4),whileinlinewithFigure3,ourpolynomialandthenlowerexponential
complexityatlowerdensitiesprovidesuswithbetterruntimesforsparsernetworks.
6 Discussion
We present an algorithm for exact causal discovery which improves on dynamic programming
methods[KoivistoandSood,2004,Silanderetal.,2006]bypruningorderswhichcannotpossibly
leadtotheglobaloptimum,andwhichexpandsuponpreviouspruningapproaches[vanBeekand
Hoffmann, 2015]. We also include pruning rules similar to the A∗ search approach of Yuan and
Malone[2013],whichfindstheshortest(leastcostlyintermsofnegativescore)paththroughthe
orderedpowersetofnodeorders(Figure1)andprunesthepowersetbyremovingpathsthatcannot
possiblyimprovethescore. Whiletheyrelyonvariousheuristicstoprune, basedonscoreswith
potentialcyclesandthenonavoidingcycles,wefocussedonboundsatlowercomputationalcost.
Whentheoptimalsolutionisamatching,ouralgorithmonlyneedstokeeptrackofonesuborder
at each stage and can exit immediately, while the total complexity is polynomial. Although it is
wellknownthatfindingthebestmatchingpolynomial,asisfindingthebesttree[ChowandLiu,
1968],ourstudyadditionallycontributesapolynomialoptimalitytestforsuchnetworksamongst
allDAGs. Wefurtherextendedourapproachwithanoveldivide-and-conqueralgorithmtodetect
disconnected components in the optimal DAG in an effective manner. For sparse networks with
alogarithmiclargestcomponent,wecanalsoproveoptimalityinpolynomialtime. Theseresults
constitutearemarkableexceptiontothegeneralNP-hardnessofcausaldiscovery,evenwithasearch
spacewithlimitedin-degree[Chickering,1996,Chickeringetal.,2004].
Wedesignourpruningruleswithnocomplexityoverheadsothatourworst-casecomplexityisthe
currentbestcase(withoutpruning). Simulationstudiesshowthattheactualruntimeandcomplexity
canbemuchlower. Inparticular,beyondthepolynomialbehaviourforsparsenetworks,wefinda
slowlyandthenroughlylinearlyincreasingtrendbetweenthelogarithmofthebaseoftheexponential
terminthecomplexityandthedensityofthesimulatednetworks. Inoursimulations,westartseeing
someoutlierswithexponentialruntimeatadensityof0.5. Aymptoticallyweexpectasharpphase
transitionforrandomgraphswithalmostsurelynogiantcomponentbelowacriticalvalue(adensity
of1inourcase),andalmostcertainlyagiantcomponentabove. Likewise,wewouldexpectasharp
transitionfrompolynomialtoexponentialcomplexityasymptoticallyatthiscriticalvalue. Inpractice,
andawayfromasymptotics,ourapproachscaleswellforlargersparsernetworks.
WeworkedonthesearchspaceusedbytheiterativehybridschemeofKuipersetal.[2022]where
eachnodemayhaveparentsfromwithinpreselectedsets, plusanadditionaloneoutsidethatset.
Moretypicalforsamplinghadbeentoconsiderallpossibleparentsetsuptoamaximumin-degree
[FriedmanandKoller,2003,KuipersandMoffa,2017],orfordiscoverytoprunefurthertotablesof
candidateparentsets[Friedmanetal.,1999,TeyssierandKoller,2005]. Thisisthestandardinputto
currentstate-of-the-artexactcausaldiscoveryalgorithms[Maloneetal.,2018]. Thehybridsetting
offersseveraladvantages. First,ittypicallyoffersgoodperformanceincausaldiscovery[Riosetal.,
2021]. Second,iftheinitialsearchspaceisfoundwithaconsistentmethod,likethepc-algorithm,
andifthescorefunctionisconsistent,likewithapenalisedlikelihood,thenweretainconsistencyin
ourexactcausaldiscovery. Third,thehybridapproachallowsustoprecomputeallscoresneededfor
thesearch,ratherthanpotentiallyneedingtolookthroughtablesofcandidateparents’scores. As
suchwecanremovethisfactorfrominfluencingthealgorithmruntime. Inparticular,weobserve
cleartrendsoftheruntimeasafunctionofthedensityofthenetworkanditssize,whichseemsmuch
morepredictablethanforotherexactsolvers[Maloneetal.,2018]. Wecanthereforeexaminethe
hardnessofexactcausaldiscoverymoreprecisely.
At lower densities, our order-based pruning algorithm is generally faster than the ILP approach
ofGOBNILP[BartlettandCussens,2017,Cussensetal.,2017,Cussens,2020], whichwasalso
typicallyfoundtobethefastestcomparedtootherexactalgorithms[Maloneetal.,2018],especially
forsmallerandsparserinstances[Trösseretal.,2021]. Ournewdivide-and-conquerandpruning
rulesmighthelpimproveILPapproaches,whilethesemaysuggestotheravenuesforbetterpruning
oursearch. Overall,ourapproachoffersausefulframeworkforfurtherloweringthecomplexityof
exactcausaldiscoveryandextendingitsuseforlargerandsparsernetworks.
12References
MarkBartlettandJamesCussens. IntegerLinearProgrammingfortheBayesiannetworkstructure
learningproblem. ArtificialIntelligence,244:258–271,2017.
DavidM.Chickering. LearningBayesiannetworksisNP-complete. Learningfromdata: Artificial
intelligenceandstatisticsV,pages121–130,1996.
David M. Chickering, David Heckerman, and Chris Meek. Large-sample learning of Bayesian
networksisNP-hard. JournalofMachineLearningResearch,5:1287–1330,2004.
C.K.ChowandC.N.Liu. Approximatingdiscreteprobabilitydistributionswithdependencetrees.
IEEEtransactionsonInformationTheory,14:462–467,1968.
JamesCussens. GOBNILP:LearningBayesiannetworkstructurewithintegerprogramming. In
InternationalConferenceonProbabilisticGraphicalModels,pages605–608,2020.
JamesCussens,MattiJärvisalo,JanneH.Korhonen,andMarkBartlett. Bayesiannetworkstructure
learning with integer programming: Polytopes, facets and complexity. Journal of Artificial
IntelligenceResearch,58:185–229,2017.
NirFriedmanandDaphneKoller. BeingBayesianaboutnetworkstructure.ABayesianapproachto
structurediscoveryinBayesiannetworks. MachineLearning,50:95–125,2003.
NirFriedman,IftachNachman,andDanaPe’er. LearningBayesiannetworkstructurefrommassive
datasets: The “sparse candidate” algorithm. In Proceedings of the Fifteenth Conference on
UncertaintyinArtificialIntelligence,pages206–215,1999.
DanGeigerandDavidHeckerman. Parameterpriorsfordirectedacyclicgraphicalmodelsandthe
characterizationofseveralprobabilitydistributions. TheAnnalsofStatistics,30:1412–1440,2002.
David Heckerman and Dan Geiger. Learning Bayesian networks: A unification for discrete and
Gaussian domains. In Proceedings of the Eleventh Conference on Uncertainty in Artificial
Intelligence,pages274–284,1995.
MarkusKalisch,MartinMächler,DiegoColombo,MarloesH.Maathuis,andPeterBühlmann.Causal
inferenceusinggraphicalmodelswiththeRpackagepcalg. JournalofStatisticalSoftware,47:
1–26,2012.
MikkoKoivistoandKismatSood. ExactBayesianstructurediscoveryinBayesiannetworks. The
JournalofMachineLearningResearch,5:549–573,2004.
JackKuipersandGiusiMoffa. PartitionMCMCforinferenceonacyclicdigraphs. Journalofthe
AmericanStatisticalAssociation,112:282–299,2017.
JackKuipers,GiusiMoffa,andDavidHeckerman. AddendumonthescoringofGaussiandirected
acyclicgraphicalmodels. TheAnnalsofStatistics,42:1689–1691,2014.
JackKuipers,PolinaSuter,andGiusiMoffa. EfficientsamplingandstructurelearningofBayesian
networks. JournalofComputationalandGraphicalStatistics,31:639–650,2022.
BrandonMalone,KustaaKangas,MattiJärvisalo,MikkoKoivisto,andPetriMyllymäki. Empir-
icalhardnessoffindingoptimalBayesiannetworkstructures: Algorithmselectionandruntime
prediction. MachineLearning,107:247–283,2018.
MichaelMolloyandBruceReed. Acriticalpointforrandomgraphswithagivendegreesequence.
Randomstructures&algorithms,6:161–180,1995.
BalasKausikNatarajan.Sparseapproximatesolutionstolinearsystems.SIAMJournalonComputing,
24:227–234,1995.
MarkE.J.Newman,StevenH.Strogatz,andDuncanJ.Watts. Randomgraphswitharbitrarydegree
distributionsandtheirapplications. PhysicalReviewE,64:026118,2001.
RobertC.Prim. Shortestconnectionnetworksandsomegeneralizations. TheBellSystemTechnical
Journal,36:1389–1401,1957.
13FelixL.Rios,GiusiMoffa,andJackKuipers. Benchpress: Ascalableandversatileworkflowfor
benchmarkingstructurelearningalgorithmsforgraphicalmodels. arXiv:2107.03863,2021.
MarcoScutari,CatharinaElisabethGraafland,andJoséManuelGutiérrez.WholearnsbetterBayesian
networkstructures: Accuracyandspeedofstructurelearningalgorithms. InternationalJournalof
ApproximateReasoning,115:235–253,2019.
TomiSilander,PetriKontkanen,andPetriMyllymäki. Asimpleapproachforfindingthegloballyop-
timalBayesiannetworkstructure. InProceedingsoftheTwenty-SecondConferenceonUncertainty
inArtificialIntelligence,pages445–452,2006.
PolinaSuter,JackKuipers,GiusiMoffa,andNikoBeerenwinkel. Bayesianstructurelearningand
samplingofBayesiannetworkswiththeRpackageBiDAG. JournalofStatisticalSoftware,105:
1–31,2023.
Marc Teyssier and Daphne Koller. Ordering-based search: A simple and effective algorithm for
learningBayesiannetworks. InProceedingsoftheTwenty-FirstConferenceonUncertaintyin
ArtificialIntelligence,pages584–590,2005.
FulyaTrösser,SimondeGivry,andGeorgeKatsirelos. ImprovedacyclicityreasoningforBayesian
networkstructurelearningwithconstraintprogramming. arXiv:2106.12269,2021.
Peter van Beek and Hella-Franziska Hoffmann. Machine learning of Bayesian networks using
constraintprogramming.InPrinciplesandPracticeofConstraintProgramming:21stInternational
Conference,pages429–445,2015.
ChangheYuanandBrandonMalone. LearningoptimalBayesiannetworks: Ashortestpathperspec-
tive. JournalofArtificialIntelligenceResearch,48:23–65,2013.
14S Supplementarymaterial
S.1 Pruningleftorders
Hereweconsiderleftordersoflengthnassubjectforpruning. Thesimpleststrategyisagainwhen
thelastnodeaddedcouldfitbetterearlierintheorder.
⇀
Pruning 10 (Optimal back). We prune v if for some k < n we have
1:n
⇀
S( v ,v ,v ,[...] )>S(v ).
1:k−1 n k:n−1 1:n
⟨ ⟩
AnalogouslytoPruning3,weensurethetwonodesinthebackareinnumericalorderiftheycanbe
swappedwithoutaffectingthescore.
⇀ ⇀
Pruning 11 (Ordered back). We prune v if v < v and S(v ) =
1:n n n−1 1:n
S( v ,v ,v ,[...] ).
1:n−2 n n−1
⟨ ⟩
WealsoconsidertheanalogueofTheorem4forleftorderswhenappendingnewnodestotheback.
⇀
Theorem 8. If S(v ) = S( v ,[...],v ), then we have max S(v)
1:n 1:n−1 n
⟨ ⟩ v∈⟨v1:n−1,h,[...]⟩ ≥
max S(v)foranyhiddennodeh.
v∈⟨v1:n,h,[...]⟩
Proof. Theequalitymeansthatthescoreofv isindependentoftheothernodes. However,thescore
n
ofsomeofthehiddennodeshmaydependonv . Inparticularforanyhwehavethat
n
max S(v) max S(v) max S(v).
v∈⟨v1:n,h,[...]⟩ ≤v∈⟨v1:n−1,h,vn,[...]⟩ ≤v∈⟨v1:n−1,h,[...]⟩
Theorem8impliesthat,withequalscores,aslongasthereisahiddennodewithalowernumber
thanv thenitisnotnecessarytokeepv atstagen,asitcouldbeaddedlaterequallywellorbetter.
n n
⇀ ⇀
Pruning12(Noleftgaps). Weprune v ifS(v )=S( v ,[...],v )andforanyhidden
1:n 1:n 1:n−1 n
⟨ ⟩
nodehwehaveh<v .
n
Theorem8istheanalogueofTheorem4andallowsustoprunefortheleftorderssimilarlytothe
rightordersinPruning4. Sincescoresdependonpossibleparents,however,thepruningconditions
differduetothisasymmetry,andtheanalogueofTheorem5doesnotseemtoimmediatelyleadto
anotherpruningrule.
ThetotalcomplexityofPruning10and11is,analogouslyfortherightsuborders,boundby (p2p).
O
ForremovingleftgapswithPruning12wecanchecktheconditionin (1)foreachpotentialnew
O
additionatthebackbylookinguptherelevantinsertionscores. Tocheckthenumericalordering
conditionweshouldadditionallytrackthelowestnumberofthenodesoutsidethesubordertoavoid
anyextracomputationalcosts. Asfortheoptimalbackpruning,thetotalcomplexityisboundby
(p2p).
O
S.2 Computationalcomplexity
Forthecomplexityconsiderations,eachscorecomputationforasinglenodecanbeupto (p)inour
↼ O
setting. Toaidthecomputations,foreachsuborder v wekeeptrackofthehighestscoreofthe
n:1
remaininghiddennodesh V v n inthefront,furtheralongtheorder,orcompletelyatthe
∈ \{ j }j=1
frontwithagap:S( [...],h,v ),max S( [...],v ,h,v )andS( h,[...],v ).
n:1 k=1...n−1 n:k k−1:1 n:1
⟨ ⟩ ⟨ ⟩ ⟨ ⟩
Eachsuborderatstagenisthenstoredastheorderedlistofthennodesalreadyincludedandthe
tableof3(p n)scores.
−
Afterstage(n 1),saywehaveN
subordersONn−1
oflength(n 1). Foreachofthesewetry
− n−1 n−1 −
toappendtheremaining(p n+1)nodestothefrontforPruning2and3. Withthetabulatedscores,
theoptimalfrontcondition− canbecheckedin (1). SinceN (cid:0) p (cid:1) thetotalcomplexityof
O n−1 ≤ n−1
thispruningisboundby (p2p).
O
15For removing right gaps with Pruning 4, we can check the condition in (p) from the tabulated
O
scoresandalreadyprunesomeofthe(p n+1)nodeswhichcouldbeaddedtothefront. Thetotal
complexityislikewiseboundby
(p2p)−
.
O
ThemorecomplicatedtaskistheremovinghiddenrightgapswithPruning5and6. Hereweneed
thescoreforeachpotentialhiddennodeofwhichthereare (p)andeachnewscorecomputation
O
isalso (p)inoursetting. Withthe (p)nodeswetrytoappendtothefrontthiscouldnaïvely
meanaO complexityof (p3N ),hoO weverwecanavoidthisoverheadandreducethecomplexity
n−1
O
byreorganisingouralgorithmandfirstrunningtheglobalpruning,asfollows.
FortheglobalPruning7,aftertheoptimalfrontandrightgappruningwehaveN (p n+1)N
n−1
≤ −
potentialsuborders. Oftheseweremoveanyduplicateswiththesamenodeset,keepingthehighest
scoringorinnumericalorder. Tocomparethesetsis (pN)sincewealsoneedtocheckthesuborder
setelements. BysummingovernthetotalcomplexO ityofthisstepisboundby (p22p). Notethat
fortheequivalentpruninginSection2.3thecomplexitywasonly
(p2p)sincewO
ealreadyknowthe
O
subordersetelementsfromtheHassediagram.
AftertheglobalpruningwehaveN′ (cid:0)p(cid:1) subordersremaining. Foreachofthesewenowupdate
≤ n
theirinsertionscoretables. Foreachsuborder [...],v oflengthn,foreachofthehiddennodes
n:1
h V v n we compute S( [...],h,v ⟨ ), S( h,⟩ [...],v ) and S( [...],v ,h,v ).
∈ \{ j }j=1 ⟨ n:1 ⟩ ⟨ n:1 ⟩ ⟨ n n−1:1 ⟩
Sincetheseareallupdatesofonenodecomparedtothescorespreviouslycomputedfor [...],v ,
n−1:1
eachonetakes (p)andthewholeprocesstakes (p2). Forthemaximumscore ⟨ ⟩
O O
max S( [...],v ,h,v )=s(v h,v )+ max S( [...],v ,h,v )
n:k k−1:1 n n−1:1 n−1:k k−1:1
k=1...n−1 ⟨ ⟩ | k=1...n−1 ⟨ ⟩
(25)
themaximumonthesecondlineiscomputedbytakingthelargestscorewiththehiddennodeatthe
↼
frontorfurtheralongtheorderpreviouslycomputedfor v andhenceis (1). Updatingthe
n−1:1
scoretablesthereforeis (p2N′)andthetotalcomplexityisagainboundby O (p22p).
O O
Withtheupdatedscoretablesforthesubordersoflengthn,checkingtheconditionfortheremovalof
hiddenrightgapswithPruning5and6takes (1)perhiddennodeandhence (p)foreachsuborder.
Thetotalcomplexityisthenboundby
(p2Op). InparticularwecancheckthO
egapconditionaswe
O
areupdatingthescoretables.
Forthepath-searchPruning8,computingthelowerboundwithPrim’salgorithm[Prim,1957]for
undirectedmaximumspanningtrees,andalsoextractingamatchingfortheupperboundforPruning
9,is (p2). Foreachupdateruleforthebestsuborder,weneedtoscorespecificleftsubordersofthe
hiddeO nnodes,againwithcomplexity (p2). Thetotalcomplexityofthepath-searchbasedpruning
andupdatesisthereforeboundby
(pO22p).
O
Theoverallworstcasetotalcomplexityof (p22p)isthesameasthebaselinecomplexityofSection
O
2.3. Whenincludingthedivide-and-conquerrules, weruntheaboveschemeoneachpotentially
disconnectedcomponent,butafterdiscoveringtheoptimalnetworkoneachcomponentwemayneed
tomergecomponentsandrerun. Thenumberofcomponentsislimitedbyp,andhencesoisthe
numberoftimeswecouldmergeandrerun. However,thesizesofthecomponentsarealsosmaller
thanp,soforexampletheschemewhereweaddonenodeatatimeandrerunwouldhavecomplexity
termsinvolving(cid:80)p k22k,againleadingtoanoverallcomplexityof (p22p).
k=1 O
Including all the pruning rules does not therefore worsen the complexity class of the algorithm.
Becauseweprunesuborders,however,wemaybeabletoachievelowercomplexityinpracticethan
withthedynamicprogrammingapproach.
16S.3 Supplementaryalgorithms
SupplementaryAlgorithm1Mainalgorithm
1: M p
←{}
2: forn=1,...,pdo
3: M n
←{}
4: ifn=1then
5: forj V do
∈
6: m¯ [...],j
←⟨ ⟩
7: ifhasGap(m¯)then
8: continue
9: endif
10: Updateinsertionscoresform¯ ▷ (p2)
O
11: M n M n m¯
← ∪{ }
12: endfor
13: else
14: M n mainTransition(M n−1)
←
15: endif
16: endfor
17: returnM p
17SupplementaryAlgorithm2mainTransition
Require: M listofordersoflengthn 1
n−1
−
1: M n
2: form¯← ={}↼ v n−1:1 ∈M n−1do ▷ O((cid:0) n−p 1(cid:1) )
3: R noRightGaps(m¯) ▷ (p)
4: for← j ∈V \{v j }n j=− 11do ▷O O(p)
5: ifj / Rthen ▷ (1)
∈ O
6: continue
7: endif
8: if!optimalFront(m¯,j)then ▷ (1)
O
9: continue
10: endif
11: ifunordFront(m¯,j)then
12: continue
13: endif
14: u¯ [...],j,v n−1:1
←⟨ ⟩
15: ComputeS(u¯) ▷ (1)
O
16: M n M n u¯
← ∪{ }
17: endfor
18: endfor
1 29 0:
:
M forn
m¯←
∈pr Mu nne dE oqualSets(M n) ▷
O((cid:0) ▷np(cid:1)
On
(×(cid:0)
npp
(cid:1)
))
21: Updateinsertionscoresform¯ ▷ (p2)
O
22: endfor
23: form¯ ∈M ndo ▷
O((cid:0) np(cid:1)
)
24: ifhasHiddenGap(m¯)then ▷ (p)
O
25: M n M n m¯
← \{ }
26: endif
27: ifunordHiddenGap(m¯)then ▷ (p)
O
28: M n M n m¯
← \{ }
29: endif
30: endfor
31: returnM n
SupplementaryAlgorithm3noRightGaps
↼
Require: Arightorderm¯ = v
n−1:1
1: R=
{}
2: m 1
3: for← h ∈− V \{v j }n j=− 11do
4: ifS( h,[...],v n−1:1 )=S( [...],h,v n−1:1 )then
⟨ ⟩ ⟨ ⟩
5: ifh>mthen
6: m h
←
7: endif
8: endif
9: endfor
10: forh ∈V \{v j }n j=− 11do
11: ifh mthen
≥
12: R R h
← ∪{ }
13: endif
14: endfor
15: returnR
18SupplementaryAlgorithm4optimalFront
↼
Require: Arightorderm¯ = v
n−1:1
Require: Anewfrontnodej
Require: Pre-calculatedmaxinsertscoresform¯.
1: m S( [...],j,v n:1 )
← ⟨ ⟩
2: s max k≤nS( [...],v n:k,j,v k−1:1 ) ▷ (1)
← ⟨ ⟩ O
3: ifs>mthen
4: returnFalse
5: endif
6: returnTrue
SupplementaryAlgorithm5unordFront
↼
Require: Arightorder v
n:1
↼
1: ifS(v n:1)=S( [...],v n−1,v n,v n−2:1 )then
⟨ ⟩
2: ifv n <v n−1then
3: returnTrue
4: endif
5: endif
6: returnFalse
SupplementaryAlgorithm6hasHiddenGap
↼
Require: Arightorderm¯ = v .
n:1
Require: Pre-calculatedmaxinsertscoresform¯.
1: m S( h,[...],v n:1 ) ▷ (1)
2: for← h ∈V⟨ \{v j }n j=1d⟩ o ▷ OO (p)
3: s max kS( [...],v n:k,h,v k−1:1 ) ▷ (1)
← ⟨ ⟩ O
4: ifs>mthen
5: returnTrue
6: endif
7: endfor
8: returnFalse
SupplementaryAlgorithm7unordHiddenGap
↼
Require: Arightorderm¯ = v .
n:1
Require: Pre-calculatedmaxinsertscoresform¯.
1: m S( h,[...],v n:1 ) ▷ (1)
2: for← h ∈V⟨ \{v j }n j=1d⟩ o ▷ OO (p)
3: s S( [...],v n,h,v n−1:1 ) ▷ (1)
← ⟨ ⟩ O
4: ifs=m & h<v nthen
5: returnTrue
6: endif
7: endfor
8: returnFalse
19SupplementaryAlgorithm8pruneEqualSets
Require: A 0,1 N×panN pbinaryrowmatrixindicatingelementsinorders
∈{ } ×
Require: order_scores RN
∈
1: start_inds [1,1,2,...,N] ▷Firstelement(1)indicatesthecolumntobeusedinA
←
2: L= ▷Listofindicesforthemaximalscoringorderofsamesets
{}
3: Q= ▷Indicestoconsider
{}
4: Q.push_back(start_inds)
5: whileQ= do
̸ {}
6: inds Q.pop_back()
←
7: k inds[1]
←
8: one_inds [k+1] ▷Tobeusedincolk+1ofA
←
9: zero_inds [k+1]
←
10: fori indsdo
∈
11: ifA ik =0then
12: zero_inds.push_back(i)
13: else
14: one_inds.push_back(i)
15: endif
16: endfor
17: ifk =pthen ▷Lastcolumn,wherescoresareused
18: ifzero_inds.size()=0then
19: i∗ argmax o̸ rder_scores[i]
←
i∈zero_inds
20: L.push_back(i∗)
21: endif
22: ifone_inds.size()=0then
23: i∗ argmax ̸ order_scores[i]
←
i∈one_inds
24: L.push_back(i∗)
25: endif
26: else
27: ifzero_inds.size()>1then
28: Q.push_back(zero_inds)
29: endif
30: ifone_inds.size()>1then
31: Q.push_back(one_inds)
32: endif
33: endif
34: endwhile
35: returnL
20S.4 SupplementaryFigures
Supplementary Figure 1: More complete version of Figure 2 showing the logarithm of the total
number of suborders Σ and runtime t (in seconds) for all the network sizes p 10,...,30 ,
N
∈ { }
stratifiedbythenetworkdensityd.
21SupplementaryFigure2: Theregressioncoefficientsforamedianregressionofthelogarithmofthe
totalnumberofsuborderslog (Σ )againstpandlog (p),withstandarderrors,asafunctionofthe
2 N 2
networkdensityd.
SupplementaryFigure3: Theratioofthetotalruntimetothetotalnumberofsuborders: t/Σ for
N
networksofdifferentdensityd. Wewouldexpectuptoquadraticbehaviourinp,thoughitappears
morelinearforhigherdensities. Withthesquareroottransform(rightpanel),theapparentsub-linear
behaviourforhigherdensitiessuggestsanoverallsub-quadraticdependency.
Supplementary Figure 4: The logarithm of the relative runtime of our approach (D&C pruner)
comparedtoGOBNILPfornetworksofsizep=30alongwiththecomparisonofthelogruntimes
(inseconds)ofthetwoapproaches,colouredbydensity.
22