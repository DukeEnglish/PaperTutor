Probabilistic and Differentiable Wireless Simulation
with Geometric Transformers
ThomasHehn,MarkusPeschl,TribhuvaneshOrekondy,ArashBehboodi,JohannBrehmer
QualcommAIResearch‚àó
Abstract
Modellingthepropagationofelectromagneticsignalsiscriticalfordesigningmod-
erncommunicationsystems. Whilethereareprecisesimulatorsbasedonraytrac-
ing,theydonotlendthemselvestosolvinginverseproblemsortheintegrationin
anautomateddesignloop. Weproposetoaddressthesechallengesthroughdiffer-
entiableneuralsurrogatesthatexploitthegeometricaspectsoftheproblem. We
firstintroducetheWirelessGeometricAlgebraTransformer(Wi-GATr),ageneric
backbonearchitectureforsimulatingwirelesspropagationina3Denvironment. It
usesversatilerepresentationsbasedongeometricalgebraandisequivariantwith
respecttoE(3),thesymmetrygroupoftheunderlyingphysics. Second,westudy
twoalgorithmicapproachestosignalpredictionandinverseproblemsbasedon
differentiable predictive modelling and diffusion models. We show how these
letuspredictreceivedpower,localizereceivers,andreconstructthe3Denviron-
mentfromthereceivedsignal. Finally,weintroducetwolarge,geometry-focused
datasetsofwirelesssignalpropagationinindoorscenes. Inexperiments,weshow
thatourgeometry-forwardapproachachieveshigher-fidelitypredictionswithless
datathanvariousbaselines.
1 Introduction
Moderncommunicationiswireless: moreandmore,wecommunicateviaelectromagneticwaves
throughtheantennasofvariousdevices,leadingtoprogressinandadoptionofmobilephones,auto-
motive,AR/VR,andIoTtechnologies[12,16]. Alltheseinnovationsbuilduponelectromagnetic
wavepropagation. Therefore,modellingandunderstandingwavepropagationinspaceisacorere-
searchareainwirelesscommunication,andremainscrucialaswearemovingtowardnewgenerations
ofmoreefficientandspatially-awarewirelesstechnologies.
WirelesssignalpropagationfollowsMaxwell‚Äôsequationsofelectromagnetismandisoftenaccurately
modelledbystate-of-the-artray-tracingsimulationsoftware. However,thesesimulatorstakesubstan-
tialtimetoevaluateforeachscene,cannotbefine-tunedonmeasurements,andare(usually[29])not
differentiable. Thislimitstheirusefulnessforsolvinginverseproblems.
Incontrast, neuralmodelsofsignalpropagationcanbeevaluatedcheaply, canbetrainedonreal
measurements in addition to simulation, and are differentiable and thus well-suited for solving
inverseproblems. Severalsuchapproacheshavebeenproposedrecently,oftenusingimage-based
representationsoftheinputsandoutputsandoff-the-shelfvisionarchitectures[6,23,34,35,44,46,
51, 52]. However, wireless surrogate modelling faces various challenges. Realistic training data
isoftenscarce,requiringsurrogatemodelstobedataefficient. Wirelessenvironmentscanconsist
ofcomplexmeshes. Finally,inputandoutputdataconsistofavarietyofdatatypes,includingthe
shapeofextended3Dobjects,pointcoordinatesandspatialorientationofantennas,andinformation
associatedwiththetransmittedsignal.
‚àóQualcommAIResearchisaninitiativeofQualcommTechnologies,Inc.
Preprint.Underreview.
4202
nuJ
12
]GL.sc[
1v59941.6042:viXraWireless scene Wi-GATr Backbone Channels ‚Ñé!"
Receiver ùëü! Tokenizer GATr
Transmitter ùë°"
3D Geometry ùêπ Wireless Ray Tracer
(a) Wi-GATr as a predictive model
Wi-GATr: Diffusion model
‚Ä¶ -66.0 dBm
-45.8 dBm
‚Ä¶
ùêπ‚àºùëù(ùêπ|‚Äôloor,ceiling,ùë°!,ùëü",‚Ñé!") ùëü"‚àºùëù(ùëü|ùêπ,ùë°!,‚Ñé!")
(b) Generative model formulation (c) Conditional generation: 3D geometry (d) Conditional generation: Receiver location
Figure1: Geometricsurrogatesformodellingwirelesssignalpropagation. (a): Predictivemodellingof
channelsfrom3Dgeometry,transmitter,andreceiverproperties.Wi-GATrisafastanddifferentiablesurrogate
forraytracers.(b):Aprobabilisticapproachwithdiffusionmodelsletsusreconstruct3Denvironments(c)and
antennapositions(d)fromthewirelesssignal.
Inthiswork,wepresentanewapproachtomodellingwirelesssignalpropagation. Itisgroundedin
theobservationthatwirelesspropagationisinherentlyageometricproblem: adirectionalsignalis
transmittedbyanorientedtransmittingantenna,thesignalinteractswithsurfacesintheenvironment,
and the signal eventually impinges an oriented receiving antenna. We argue that it is critical for 14
neuralsurrogatestomodelandflexiblyrepresentgeometricaspects(e.g.orientations,shapes)in
thepropagationenvironment. Wethereforedevelopsurrogatemodelsbasedonflexiblegeometric
representationandstronggeometricinductivebiases.
WefirstproposetheWirelessGeometricAlgebraTransformer(Wi-GATr),abackbonearchitecturefor
wirelesssignalpropagationproblems. Akeycomponentisanewtokenizerforthediverse,geometric
dataofwirelessscenes. ThetokensareprocessedwithaGeometricAlgebraTransformer(GATr)
network [9]. This architecture is equivariant with respect to the symmetries of wireless channel
modelling,butmaintainsthescalabilityofatransformerarchitecture.
Second, westudyWi-GATrmodelsasdifferentiable, predictivesurrogatesforthesimulator(see
Fig.1a).Herethenetworkpredictsobservablessuchasthereceivedpowerasafunctionoftransmitter
position,receiverposition,and3Denvironment. Weshowhowthisenablesforwardmodelling,and
inaddition,inverseproblemsolvingduetoWi-GATr‚Äôsdifferentiability.
Next,weproposeanalternative,moreversatileprobabilisticapproachtopredictionandinference
tasks: trainingWi-GATrdiffusionmodels(Fig.1b)onthejointdistributionoftransmitter,receiver,
channelinformation,and3Denvironment. Attesttime,themodelcanbeflexiblyconditionedonany
availableinformationtopredictthereceivedpower,localizeatransmitterorreceiver(Fig.1c),or
evenreconstructthe(fullorpartial)3Dgeometryfromthewirelesssignal(Fig.1d).
Toenablemachinelearningdevelopmentforwirelessproblems,wefinallyintroducetwonewdatasets,
Wi3RandWiPTR.Eachdatasetconsistsofthousandsofindoorscenesofvaryingcomplexityand
includeallthegeometricinformationthatcharacterizesawirelessscene.
Finally,wedemonstratethepredictiveandtheprobabilisticmodelsonthesedatasets. Ourexperi-
mentsshowthattheWi-GATrapproachgivesusahigher-fidelitypredictionsthanvariousbaselines,
generalizesrobustlytounseensettings,andrequiresupto20timeslessdataforthesameperfor-
mancethanatransformerbaseline.
2 Backgroundandrelatedwork
Wireless signal propagation. How do wireless signals propagate from a transmitting antenna
(Tx)toareceiverantenna(Rx)ina(static)3Denvironment? Whilethesystemisfundamentally
describedbyMaxwell‚Äôsequations,formanyrealisticproblemstherayapproximationofgeometric
opticssuffices[31]. ItapproximatesthesolutiontoMaxwell‚Äôsequationsasasumofplanarwaves
propagatinginalldirectionsfromTx. Eachplanarwaveisrepresentedasaray,characterizedby
variousattributes(e.g.,power,phase,delay)sincetransmission. Asarayreachesanobject‚Äîthatis,
2itintersectswithitsmesh‚Äîtheinteractionismodelledasreflection,refraction,ordiffraction. During
suchinteractions,thepower,phase,polarization,andpropagationdirectionofthewavecanchangein
complex,material-dependentways. Inaddition,newrayscanemanatefromthepointofinteraction.
Aftermultipleinteractions,therayseventuallyreachthereceivingantenna. TheTxandRxarethen
linkedbyaconnectedpathpofmultiplerays. Theeffectsonthereceivedsignalaredescribedbythe
channelimpulseresponse(CIR)h(œÑ)=(cid:80) a Œ¥(œÑ ‚àíœÑ ),wherea ‚ààCisthecomplexgainandœÑ
p p p p p
thedelayoftheincomingrays[53].
Maxwell‚Äôsequationsandinextensionraypropagationarehighlysymmetric.Thereceivedsignaldoes
notchangeunderrotations,translations,andreflectionsofthewholescene,aswellastheexchange
oftransmitterandreceiver. Thelatterpropertyisknownasreciprocity[37].
Wireless simulators. Wireless propagation models play a key role in design and evaluation of
communicationsystems,forinstancebycharacterizingthegainofcompetitivedesignsinrealistic
settingsorbyoptimizingsystemsperformanceasinbasestationplacementformaximalcoverage.
Statisticalapproaches[2]representpropagationasagenerativemodelwheretheparametersofa
probabilisticmodelarefittedtomeasurements. Ontheotherhand,wirelessray-tracingapproaches
[1, 5, 29] are increasingly popular due to their high accuracy and because they do not require
expensivefieldmeasurementcollectioncampaigns.
Neuralwirelesssimulations. Bothstatisticalandray-tracingsimulationtechniquesareaccompanied
bytheirownshortcomings,subsequentlymitigatedbytheirneuralcounterparts. Neuralsurrogatesfor
statisticalmodels[19,40,42,56]reducetheamountandcostofmeasurementsrequired. Neuralray
tracers[29,41,58]addressthenon-differentiabilityofsimulatorsusingaNeRF-likestrategy[38]by
parameterizingthesceneusingaspatialMLPandrenderingwirelesssignalsusingclassicray-tracing
orvolumetrictechniques. Whilethesetechniquesarefasterthanprofessionalraytracers,theyare
similarlybottleneckedbyexpensivebookkeepingandrenderingsteps(involvingthousandsofforward
passes). Incontrast,weproposeaframeworktosimulatewirelesssignalswithasingleforwardpass
throughageometrictransformerthatisbothsample-efficientandgeneralizestonovelscenes.
Geometricdeeplearning. Thegrowingfieldofgeometricdeeplearning[11]aimstoincorporate
structuralpropertiesofaproblemintoneuralnetworkarchitecturesandalgorithms. Acentralconcept
is equivariance to symmetry groups [15]: a network f(x) is equivariant with respect to a group
G if its outputs transform consistently with any symmetry transformation g ‚àà G of the inputs,
f(g¬∑x)=g¬∑f(x),where¬∑denotesthegroupaction. OfparticularinteresttousistheEuclidean
groupE(3)ofisometriesof3Dspace,thatis,transformationsthatleaveEuclideandistancesinvariant.
Thisgroupincludesspatialtranslations,rotations,reflections,andtheircombinations. Asweargued
above,thephysicsofwirelesssignalpropagationareinvariantunderthisgroup.
GATr. TheGeometricAlgebraTransformer(GATr)[9]isanE(3)-equivariantarchitectureforgeo-
metricproblems. Amongequivariantarchitectures,itstandsoutintwoways. First,itusesgeometric
(orClifford)algebras[14,22]asrepresentations. Forarigorousintroductiontothesealgebras,we
referthereadertoDorst[20]. Fromapracticalmachinelearningperspective,thesealgebrasdefine
embeddingsforvariousgeometricprimitiveslike3Dpoints,planes,orE(3)transformations. We
willshowthatthisrepresentationisparticularlywell-suitedforwirelesschannelmodelling. Second,
GATrisatransformerarchitecture[54]. Itcomputestheinteractionsbetweenmultipletokensthrough
scaleddot-productattention. WithefficientbackendslikeFlashAttention[17],thearchitectureisscal-
abletolargesystems,withoutanyrestrictionsonthesparsityofinteractionslikeinmessage-passing
networks.
Diffusionmodels. Diffusionmodels[25,48,50]areaclassofgenerativemodelsthatiteratively
invertanoisingprocess. Theyhavebecomethede-factostandardinimageandvideogeneration
[26, 45]. Recently, they have also shown to yield promising results in the generation of spatial
andsequentialdata,suchasinplanning[30]andpuzzlesolving[28]. Asidefromtheirgenerative
modellingcapabilities,diffusionmodelsprovideaflexiblewayforsolvinginverseproblems[13,36]
through multiplication with an appropriate likelihood term [48]. Furthermore, by combining an
invariantpriordistributionwithanequivariantdenoisingnetwork,oneobtainsequivariantdiffusion
models [33]. These yield a sampling distribution that assigns equal probability to all symmetry
transformations of an object, which can improve performance and data efficiency in symmetry
problemslikemoleculegeneration[27]andplanning[10]. Wewilldemonstratesimilarbenefitsin
modellingwirelesssignalpropagation.
33 TheWirelessGeometricAlgebraTransformer(Wi-GATr)
3.1 Problemformulation
Ourgoalistomodeltheinterplaybetween3Denvironments,transmittingandreceivingantennas,and
theresultingtransmittedwirelesssignals. Moreprecisely,weconsiderwirelessscenesconsistingof:
‚Ä¢ The3DgeometryF oftheenvironment. Wespecifyitthroughatriangularmeshwithadiscrete
materialclassassociatedwitheachmeshface.
‚Ä¢ Asetoftransmittingantennast fori=1,...,n . Eacht ischaracterizedbya3Dposition,
i t i
anorientation,andanyantennacharacteristics. WewilloftenfocusonthecaseofasingleTx
andthenomittheindexi.
‚Ä¢ Analogously,asetofreceivingantennasr fori=1,...,n .
i r
‚Ä¢ Thechannelorsignalh betweeneachtransmitteriandeachreceiverj,whichcanbeany
ij
observablefunctionoftheCIR.
Inthissetting,weconsidervariousdownstreamtasks:
‚Ä¢ Signal prediction is about predicting the signal received at a single antenna from a single
receiver, p(h|F,t,r)withn = n = 1. Thisisexactlythetaskthatray-tracingsimulators
t r
solve. Often,thesignalismodelleddeterministicallyasafunctionh(F,t,r).
‚Ä¢ Receiverlocalization: inferringthepositionandpropertiesofareceivingantennafromoneor
multipletransmitters,r ‚àºp(r|F,{t },{h }),withn =1.
i i r
‚Ä¢ Geometry reconstruction or sensing: reconstructing a 3D environment partially, inferring
p(F |F ,t,r,h),whereF andF aretheunknownandknownsubsetsofF,respectively.
u k u k
Thelattertwoproblemsareexamplesofinverseproblems,astheyinvertthegraphicalmodelthat
simulatorsaredesignedfor. Theyarenotstraightforwardtosolvewiththesimulatorsdirectly,butwe
willshowhowneuralsurrogatestrainedonsimulatordatacansolvethem.
3.2 Backbone
Core to our approach to this family of inference problems is the Wireless Geometric Algebra
Transformer(Wi-GATr)backbone. Itconsistsofanoveltokenizerandanetworkarchitecture.
WirelessGAtokenizer. Thetokenizertakesasinputsomesubsetoftheinformationcharacterizing
a wireless scene and outputs a sequence of tokens that can be processed by the network. A key
challengeintheneuralmodellingofwirelessproblemsisthediversityoftypesofdatainvolved. As
wearguedabove,awirelesssceneconsistsofthe3DenvironmentmeshF,whichfeaturesthree-
dimensional objects such as buildings and trees, antennas t and r characterized through a point-
like position, an antenna orientation, and additional information about the antenna type, and the
characteristicsofthechannelh.
Datatype Inputparameterization Tokenization Channels(G embedding)
3,0,1
3DenvironmentF ‚Ä¢Triangularmesh 1tokenpermeshface ‚Ä¢Meshfacecenter(point)
‚Ä¢Vertices(points)
‚Ä¢Meshfaceplane(orientedplane)
‚Ä¢Materialclasses ‚Ä¢One-hotmaterialemb.(scalars)
Antennat /r ‚Ä¢Position 1tokenperantenna ‚Ä¢Position(point)
i i
‚Ä¢Orientation ‚Ä¢Orientation(direction)
‚Ä¢Receiving/transmitting ‚Ä¢One-hottypeembedding(scalars)
‚Ä¢Additionalcharacteristics ‚Ä¢Characteristics(scalars)
Channelh ‚Ä¢Antennas 1tokenperlink ‚Ä¢Txposition(point)
ij
‚Ä¢Rxposition(point)
‚Ä¢Tx-Rxvector(direction)
‚Ä¢Receivedpower ‚Ä¢Normalizedpower(scalar)
‚Ä¢Phase,delay,... ‚Ä¢Additionaldata(scalars)
Table1: WirelessGAtokenizer. Wedescribehowthemeshparameterizingthe3Denvironmentandthe
informationaboutantennasandtheirlinksarerepresentedasasequenceofgeometricalgebratokens. The
mathematicalrepresentationofG primitiveslikepointsororientatedplanesisdescribedinAppendixA.
3,0,1
4Tosupportallofthesedatatypes,weproposeanewtokenizerthatoutputsasequenceofgeometric
algebra (GA) tokens. Each token consists of a number of elements (channels) of the projective
geometricalgebraG inadditiontotheusualunstructuredscalarchannels. WedefinetheGA
3,0,1
preciselyinAppendixA.Itsmaincharacteristicsarethateachelementisa16-dimensionalvector
and can represent various geometric primitives: 3D points including an absolute position, lines,
planes,andsoon. Thisrichlystructuredspaceisideallysuitedtorepresentthedifferentelements
encounteredinawirelessproblem. OurtokenizationschemeisspecifiedinTbl.1.
Network. After tokenizing, we process the input data with a Geometric Algebra Transformer
(GATr)[9]. ThisarchitecturenaturallyoperatesonourG parameterizationofthescene. Itis
3,0,1
equivariantwithrespecttopermutationsoftheinputtokensaswellasE(3),thesymmetrygroup
of translations, rotations, and reflections. These are exactly the symmetries of wireless signal
propagation, with one exception: wireless signals have an additional reciprocity symmetry that
specifiesthatthesignalisinvariantunderanroleexchangebetweentransmitterandreceiver. Wewill
latershowhowwecanincentivizethisadditionalsymmetrypropertythroughdataaugmentation.2
Finally,becauseGATrisatransformer,itcanprocesssequencesofvariablelengthsandscaleswell
tosystemswithmanytokens. Bothpropertiesarecrucialforcomplexwirelessscenes,whichcanin
particularinvolvealargernumberofmeshfaces.
3.3 Predictivemodelling
TheWi-GATrbackbonecanbeusedeitherinapredictiveorprobabilisticansatz. Webeginwiththe
predictivemodellingofthemeasuredchannelinformationasafunctionofthecomplete3Denvi-
ronmentandtheinformationcharacterizingthetransmitterandreceiver,h (F,t,r). Thisregression
Œ∏
modelistrainedinasupervisedwayonsimulatedormeasuredwirelessscenes.
Forward prediction. The network thus learns a differentiable, deterministic surrogate for the
simulatormodelh (F,t,r). Attesttime,wecanusethenetworkinsteadofasimulatortopredict
sim
the signals in unseen, novel scenes. Compared to a simulator based on ray tracing, it has three
advantages: itcanbeevaluatedinmicrosecondsratherthansecondsorminutes,itcanbefinetuned
onrealmeasurements,anditisdifferentiable.
Inverse problems. This differentiability makes such a surrogate model well-suited to solve
inverseproblems. Forinstance,wecanuseitforreceiverlocalization. Givena3DenvironmentF,
transmitters{t },andcorrespondingsignals{h },wecanfindthemostlikelyreceiverpositionand
i i
orientationasrÀÜ=argmin (cid:80) ‚à•h (F,t ,r)‚àíh‚à•2. Theminimizationcanbeperformednumerically
r i Œ∏ i
throughgradientdescent,thankstothedifferentiabilityoftheWi-GATrsurrogate.
3.4 Probabilisticmodelling
Whileapredictivemodelofthesignalcanserveasapowerfulneuralsimulator,ithastwoshortcom-
ings. Solvinganinverseproblemthroughgradientdescentrequiresasizablecomputationalcostfor
everyprobleminstance. Moreover,predictivemodelsaredeterministicanddonotallowustomodel
stochasticforwardprocessesorexpresstheinherentuncertaintyininverseproblems.
Equivariantdiffusionmodel. Toovercomethis,wedrawinspirationfromtheinverseproblem
solvingcapabilitiesofdiffusionmodelsusingguidance[13]. Inthiscase,weformulatethelearning
problemasagenerativemodellingtaskofthejointdistributionp (F,t,r,h)between3Denvironment
Œ∏
meshF,transmittert,receiverr,andchannelh,forasingletransmitter-receiverpair. Concretely,
wefollowtheDDPMframeworkanduseaWi-GATrmodelasscoreestimator(denoisingnetwork).
By using an invariant base density and an equivariant denoising network, we define an invariant
generativemodel.SeeAppendixBforadetaileddescriptionofourdiffusionmodelandthediscussion
ofsomesubtletiesinequivariantgenerativemodelling.
Unifyingforwardpredictionandinverseproblemsasconditionalsampling. Adiffusionmodel
trained to learn the joint density p (F,t,r,h) does not only allow us to generate unconditional
Œ∏
samplesofwirelessscenes,butalsoletsussamplefromvariousconditionals: givenapartialwireless
scene,wecanfillintheremainingdetails,inanalogytohowdiffusionmodelsforimagesallowfor
2Wealsoexperimentedwithareciprocity-equivariantvariationofthearchitecture,butthatledtoamarginally
worseperformancewithoutasignificantgaininsampleefficiency.
5Ground truth Wi-GATr
40 40
50 50
60 60
70 70
Transformer PLViT
40 40
50 50
60 60
70 70
Figure2:Qualitativesignalpredictionresults.WeshowasinglefloorplanfromtheWiPTRtestset.Theblack
linesindicatethewallsanddoors,thecolorsshowthereceivedpowerasafunctionofthetransmitterlocation
(brightercoloursmeanastrongersignal).Thetransmittingantennaisshownasablackcross.Thezcoordinates
oftransmitterandreceiverareallfixedtothesameheight.Wecomparetheground-truthpredictions(topleft)to
thepredictionsfromdifferentpredictivemodels,eachtrainedononly100WiPTRfloorplans.Wi-GATrisableto
generalizetothisunseenfloorplanevenwithsuchasmalltrainingset.
inpainting. Toachievethis,weusetheconditionalsamplingalgorithmproposedbySohl-Dickstein
etal.[48]: ateachstepofthesamplingloop,wefixtheconditioningvariablestotheirknownvalues
beforefeedingthemintothedenoisingnetwork.
Thisalgorithmletsussolvesignalprediction(samplingfromp (h|F,t,r)), receiverlocalization
Œ∏
(fromp (r|F,t,h)),geometryreconstruction(fromp (F |F ,t,r,h)),oranyotherinferencetask
Œ∏ Œ∏ u k
inwirelessscenes. Wethusunify‚Äúforward‚Äùand‚Äúinverse‚Äùmodellinginasinglealgorithm. Each
approachisprobabilistic,enablingustomodeluncertainties. Thisisimportantforinverseproblems,
wheremeasurementsoftenunderspecifythesolutions.
In principle, the unconditional diffusion objective should suffice to enable test-time conditional
sampling. Inpractice,wefindthatwecanimprovetheconditionalsamplingperformancewithtwo
modifications. First,wecombinetrainingontheunconditionaldiffusionobjectivewithconditional
diffusion objectives. For the latter, we randomly select tokens to condition on and evaluate the
diffusion loss only on the remaining tokens. Second, we provide the conditioning mask as an
additionalinputtothedenoisingmodel. SeeAppendixBfordetails.
4 Newdatasets
Whileseveraldatasetsofwirelesssimulationsandmeasurementsexist[3,4,41,57],theyeitherdo
notincludegeometricinformation,arenotdiverse,areatasmallscale,orthesignalpredictionsare
notrealistic. Tofacilitatethedevelopmentofmachinelearningmethodswithafocusongeometry,
wegeneratetwonewdatasetsofsimulatedwirelessscenes.3 Bothfeatureindoorscenesandchannel
informationgeneratedwithastate-of-the-artray-tracingsimulator[1]atafrequencyof3.5GHz.
TheyprovidedetailedcharacteristicsforeachpathbetweenTxandRx,suchasgain,delay,angle
ofdepartureandarrivalatTx/Rx,andtheelectricfieldatthereceiveritself,whichallowsusersto
computevariousquantitiesofinterestthemselves. SeeAppendixCformoredetails.
Wi3Rdataset. Ourfirstdatasetfocusesonsimplicity: eachof5000floorplanshasthesamesizeand
numberofrooms,andallwallshavethesamematerialacrosslayouts.Theydifferonlyintheirlayouts,
whichwetakefromWi3Rooms[41],Txpositions,andRxpositions.InAppendixCwedefinetraining,
validation,andtestsplitsaswellasanout-of-distributionsettotesttherobustnessofdifferentmodels.
3Wearepreparingthepublicationofthedatasets.
6
]mBd[
rewop
devieceR
]mBd[
rewop
devieceR
]mBd[
rewop
devieceR
]mBd[
rewop
devieceRWi3Rdataset WiPTRdataset
Wi-GATr Wi-GATr
Transf. SEGNN PLViT Transf. PLViT
(ours) (ours)
Indistribution
Rxinterpolation 0.63 1.14 0.92 4.52 0.39 0.62 1.27
Unseenfloorplans 0.74 1.32 1.02 4.81 0.41 0.69 1.28
Symmetrytransformations
Rotation 0.74 78.68 1.02 4.81 0.41 38.51 1.28
Translation 0.74 64.05 1.02 4.81 0.41 4.96 1.28
Permutation 0.74 1.32 1.02 4.81 0.41 0.69 1.28
Reciprocity 0.80 1.32 1.01 10.15 0.41 0.69 1.28
Outofdistribution
OODlayout 7.03 14.06 2.34 5.89 0.43 0.86 1.23
Table2:Signalpredictionresults.WeshowthemeanabsoluteerroronthereceivedpowerindBm(loweris
better,bestinbold).Top:In-distributionperformance.Middle:Generalizationundersymmetrytransformations.
Bottom:Generalizationtoout-of-distributionsettings.Inalmostallsettings,Wi-GATristhehighest-fidelity
surrogatemodel.
WiPTR dataset. Next, we generate a more varied, realistic dataset based on the floor layouts in
the ProcTHOR-10k dataset for embodied AI research [18]. We extract the 3D mesh information
including walls, windows, doors, and door frames and assign 6 different dielectric materials for
differentgroupsofobjects. Ourdatasetconsistsof12kdifferentfloorlayouts,splitintotraining,
test,validation,andOODsetsasdescribedinAppendixC.NotonlydoesWiPTRstandoutamong
wirelessdatasetsintermsofitslevelofdetailandscale,butbecauseitisbasedonProcTHOR-10k,it
isalsosuitedfortheintegrationwithembodiedAIresearch.
5 Experiments
5.1 Predictivemodelling
We focus on the prediction of the time-averaged non-coherent received power h = (cid:80) |a |2,
p p
disregardingdelayordirectionalinformationthatmaybeavailableinrealmeasurements. Wetrain
predictivesurrogatesh (F,t,r)thatpredictthepowerasafunctionoftheTxpositionandorientation
Œ∏
t,Rxpositionandorientationr,and3DenvironmentmeshF,onboththeWi3RandWiPTRdatasets.
Allmodelsaretrainedwithreciprocityaugmentation,i.e.,randomlyflippingTxandRxlabelsduring
training. Thisimprovesdataefficiencyslightly,especiallyforthetransformerbaseline.
In addition to our Wi-GATr model, described in Sec. 3, we train several baselines. The first is a
vanillatransformer[54],basedonthesameinputsandtokenizationofthewirelessscene,butwithout
thegeometricinductivebiases. Next,wecomparetotheE(3)-equivariantSEGNN[8],thoughwe
wereonlyabletofitthismodelintomemoryfortheWi3Rdataset. Inaddition, wetrainaPLViT
model, a state-of-the-art neural surrogate for wireless scenes [24] that represent wireless scenes
as an image centered around the Tx position. Finally, we attempt to compare Wi-GATr also to
WiNeRT[41],aneuralraytracer. However,thisarchitecture,whichwasdevelopedtobetrained
onseveralmeasurementsonthesamefloorplan,wasnotabletoachieveusefulpredictionsonour
diversedatasetswiththeirfocusongeneralizationacrossfloorplans. Ourexperimentsetupandthe
baselinesaredescribedindetailinAppendixD.
Signalprediction. InFig.2weillustratethepredictiontaskonaWiPTRfloorplan. Weshowsignal
predictionsforthesimulatoraswellasforsurrogatemodelstrainedononly100floorplans. Despite
thisfloorplannotbeingpartofthetrainingset,Wi-GATrisabletocapturethepropagationpattern
well,whilethetransformerandViTshowmemorizationartifacts.
InTbl.2wecomparesurrogatemodelstrainedonthefullWi3RandWiPTRdatasets. Bothwhen
interpolating Rx positions on the training floor plans as well as when evaluating on new scenes
unseenduringtraining,Wi-GATroffersthehighest-fidelityapproximationofthesimulator. Wi-GATr
aswellastheequivariantbaselinesarebyconstructionrobusttosymmetrytransformations,while
73
10 Wi3R WiPTR 5 WiPTR
2
5
2
1 2
1
PLViT
1 Transformer
SEGNN 0.5 0.5 Transformer
Wi-GATr (ours) Wi-GATr (ours)
0.5
10 100 1000 4500 10 100 1000 10k 1 2 3 5 10
Training rooms Training rooms Number of transmitters
Figure 3: Signal prediction. We show the mean absolute error on Figure 4: Rx localization error,
the received power as a function of the training data on Wi3R (left) asafunctionofthenumberofTx.
andWiPTR(right). Wi-GATroutperformsthetransformerandPLViT Linesanderrorbandshowmeanand
baselinesatanyamountoftrainingdata,andscalesbettertolargedata itsstandarderrorover240measure-
ormanytokensthanSEGNN. ments.
theperformanceofavanillatransformerdegradessubstantially. AllmethodsbutSEGNNstruggle
togeneralizetoanOODsettingontheWi3Rdataset. Thisisnotsurprisinggiventhatthetraining
samplesaresosimilartoeachother. OnthemorediverseWiPTRdataset,Wi-GATrisalmostperfectly
robustunderdomainshift.
Dataefficiency. Next,westudythedataefficiencyofthedifferentsurrogatesinFig.3. Wi-GATris
moredata-efficientthananyothermethodwiththeexceptionoftheE(3)-equivariantSEGNN,which
performssimilarlywellforasmallnumberoftrainingsamples. Thisconfirmsthatequivarianceisa
usefulinductivebiaswhendataisscarce. ButWi-GATrscalesbetterthanSEGNNtolargernumber
ofsamples,showingthatourarchitecturecombinesthesmall-dataadvantagesofstronginductive
biaseswiththelarge-dataadvantagesofatransformerarchitecture.
Inferencespeed. Oneoftheadvantagesofneuralsurrogatesistheirtest-timespeed. BothWi-GATr
andatransformerareoverafactorof20fasterthantheground-truthraytracer(seeAppendixD).
Receiverlocalization. Next,weshowhowdifferentiablesurrogatesletussolveinverseproblems,
focusing on the problem of receiver localization. We infer the Rx position with the predictive
surrogatemodelsbyoptimizingthroughtheneuralsurrogateofthesimulatorasdiscussedinSec.3.3.
The performance of our surrogate models is shown in Fig. 4 and Appendix D.4 The two neural
surrogatesachieveasimilarperformancewhenonlyoneortwotransmittersareavailable,asettingin
whichthereceiverpositionishighlyambiguous. Withmoremeasurements,Wi-GATrletsuslocalize
thetransmittermoreprecisely.
5.2 Probabilisticmodelling
Next,weexperimentwithourprobabilisticapproach. WetraindiffusionmodelsontheWi3Rdataset.
InadditiontoaWi-GATrmodel,westudyatransformerbaseline,aswellasatransformertrainedon
thesamedataaugmentedwithrandomrotations. BothmodelsaretrainedwiththeDDPMpipeline
with1000denoisingstepsandsamplesfromwiththeDDIMsolver[49]. Oursetupisdescribedin
detailinAppendixD.
Signalprediction,receiverlocalization,andgeometryreconstructionasconditionalsampling.
Inourprobabilisticapproach,signalprediction,receiverlocalization,andgeometryreconstruction
areallinstancesofsamplingfromconditionaldensities: h ‚àº p (h|F,t,r),r ‚àº p (r|F,t,h),and
Œ∏ Œ∏
F ‚àº p (F |F ,t,r,h), respectively. We qualitatively show results for this approach in Figs. 1
u Œ∏ u k
and5. Allofthesepredictionsareprobabilistic,whichallowsourmodeltoexpressuncertaintyin
ambiguousinferencetasks. WheninferringRxpositionsfromasinglemeasurement,themodellearns
multimodaldensities,asshowninthemiddleofFig.5. Whenreconstructinggeometry,themodel
willsamplediversefloorplansaslongastheyareconsistentwiththetransmittedsignal,seetheright
panelofFig.5. AdditionalresultsonsignalandgeometrypredictionaregiveninAppendixD.2.
4NeithertheSEGNNnorPLViTbaselinesarefullydifferentiablewithrespecttoobjectpositionswhenusing
theofficialimplementationsfromRefs.[7,24].Wewerethereforenotabletoaccuratelyinferthetransmitter
positionswiththesearchitectures.
8
]mBd[
EAM
]mBd[
EAM
]m[
rorre
noitazilacol
xR
naeM(a) Unconditional generation (b) Receiver localization (c) Geometry reconstruction
Signal strength = -45.8 dBm -37.0 dBm -45.8 dBm
Transmitter Receiver Sampled
GT receiver receiver
locations Predicted geometry
-26.7 dBm -66.0 dBm -62.7 dBm
Figure5:Probabilisticmodelling.Weformulatevarioustasksassamplingfromtheunconditionalorconditional
densitiesofasinglediffusionmodel.(a):Unconditionalsamplingofwirelessscenesp(F,t,r,h).(b):Receiver
localization as conditional sampling from p(r|F,t,h) for two different values of h and r. (c): Geometry
reconstructionasconditionalsamplingfromp(F |F ,t,r,h)fortwodifferentvaluesofh,keepingt,r,F fixed.
u k k
We quantitatively evaluate these mod-
Transformer
elsthroughthevariationallowerbound Wi-GATr(ours)
13
ontheloglikelihoodoftestdataunder default dataaugm.
the model. To further analyze the ef- Canonicalizedscenes
fectsofequivariance,wetestthemodel Signalpred. 1.62 3.00 15.66
bothoncanonicalizedscenes,inwhich Receiverloc. 3.64 8.28 14.42
all walls are aligned with the x and y Geometryreco. -3.95 -3.61 -2.10
axis, andscenesthatarearbitrarilyro-
Scenesinarbitraryrotations
tated. The results in Tbl. 3 show that
Signalpred. 1.62 9.57 17.65
Wi-GATr outperforms the transformer Receiverloc. 3.64 105.68 14.45
baselineacrossallthreetasks, evenin Geometryreco. -3.95 389.34 -2.34
the canonicalized setting or when the
transformeristrainedwithdataaugmen- Table3:Probabilisticmodellingresults.Weshowvariational
tation. ThegainsofWi-GATrarepartic- upperboundsonthenegativeloglikelihoodfordifferentcondi-
tionalinferencetasks(lowerisbetter,bestinbold).
ularlyclearonthesignalpredictionand
receiverlocalizationproblems.
6 Discussion
Wirelesssignaltransmissionthroughelectromagneticwavepropagationisaninherentlygeometric
andsymmetricproblem. Wedevelopedaclassofneuralsurrogatesgroundedingeometricrepresenta-
tionsandstronginductivebiases. TheyarebasedontheWi-GATrbackbone,consistingofanew
tokenizationschemeforwirelessscenestogetherwithanE(3)-equivarianttransformerarchitecture.
Theproposedbackboneisappliedintwowaystowirelesstasks: first,asadifferentiable‚Äúforward‚Äù
predictionmodelthatmapsthefeaturestothesignals;second,asaprobabilisticdiffusionmodelthat
capturesthejointandconditionaldistributionsoffeaturesandchannels. Weemployedthesedesigns
in experiments on received power prediction, receiver localization, and geometry reconstruction,
whereourWi-GATrmodelsenabledprecisepredictions,outperformingvariousbaselines.
Ouranalysisisinmanywaysafirststep. Therangeofmaterialsinourdatasetsislimitedandweonly
experimentedwithmeasurementsofthenon-coherenttotalreceivedpower,whichisastablesignal,
butofferslessspatialinformationthanmeasurementsofthetimedelayorangularinformation. More
importantly,weonlyconsideredidealizedinferencetasks. Forinstance,ourreceiverlocalization
problemassumedperfectknowledgeoftheroomgeometryandmaterials.
Nevertheless,wehopethatwewereabletohighlightthebenefitsofageometrictreatmentofwave
propagationmodelling. Augmentingorreplacingtheimage-basedorgeneral-purposerepresentations
andarchitecturesprevalentinwirelessmodellingwithgeometricapproacheshasthepotentialof
improvingdataefficiency,performance,androbustness.
Acknowledgements. We thank Suresh Sharma, Pim de Haan, and Jens Petersen for fruitful
discussions.
9References
[1] RemcomWirelessInSite¬Æ.https://www.remcom.com/wireless-insite-propagation-
software. [Accessed10-05-2024]. (Citedonpages3and6)
[2] 3GPPTR38.901. Studyonchannelmodelforfrequenciesfrom0.5to100ghz. Standard,3GPP,
Valbonne,FR,March2022. (Citedonpage3)
[3] A.Alkhateeb. DeepMIMO:Agenericdeeplearningdatasetformillimeterwaveandmassive
MIMOapplications. InITA,2019. (Citedonpage6)
[4] AhmedAlkhateeb,GourangaCharan,TawfikOsman,AndrewHredzak,JoaoMorais,Umut
Demirhan,andNikhilSrinivas. Deepsense6g: Alarge-scalereal-worldmulti-modalsensing
andcommunicationdataset. IEEECommunicationsMagazine,2023. (Citedonpage6)
[5] NicolasAmiot,MohamedLaaraiedh,andBernardUguen. Pylayers: Anopensourcedynamic
simulatorforindoorpropagationandlocalization. InICC,2013. (Citedonpage3)
[6] StefanosBakirtzis,KehaiQiu,JieZhang,andIanWassell. DeepRay: DeepLearningMeets
Ray-Tracing. InEuCAP,2022. (Citedonpage1)
[7] JohannesBrandstetter,RiannevandenBerg,MaxWelling,andJayeshKGupta. Cliffordneural
layersforPDEmodeling. arXiv:2209.04934,2022. (Citedonpage8)
[8] JohannesBrandstetter, RobHesselink, ElisevanderPol, ErikJBekkers, andMaxWelling.
GeometricandphysicalquantitiesimproveE(3)equivariantmessagepassing. InICLR,2022.
(Citedonpages7and15)
[9] JohannBrehmer,PimdeHaan,S√∂nkeBehrends,andTacoCohen. GeometricAlgebraTrans-
former. InNeurIPS,2023. (Citedonpages2,3,5,13,and14)
[10] JohannBrehmer,JoeyBose,PimDeHaan,andTacoSCohen. Edgi: Equivariantdiffusionfor
planningwithembodiedagents. NeurIPS,2024. (Citedonpage3)
[11] MichaelMBronstein,JoanBruna,TacoCohen,andPetarVelicÀákovic¬¥. Geometricdeeplearning:
Grids,groups,graphs,geodesics,andgauges. 2021. (Citedonpage3)
[12] Wanshi Chen, Peter Gaal, Juan Montojo, and Haris Zisimopoulos. Fundamentals of 5G
communications: connectivityforenhancedmobilebroadbandandbeyond. McGraw-Hill,New
York,2021. (Citedonpage1)
[13] Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L Klasky, and Jong Chul Ye.
Diffusion posterior sampling for general noisy inverse problems. arXiv:2209.14687, 2022.
(Citedonpages3and5)
[14] WilliamKingdonClifford. ApplicationsofGrassmann‚ÄôsExtensiveAlgebra. Amer.J.Math.,1
(4):350‚Äì358,1878. (Citedonpage3)
[15] TacoCohen. EquivariantConvolutionalNetworks. PhDthesis,UniversityofAmsterdam,2021.
(Citedonpage3)
[16] ErikDahlman,StefanParkvall,andJohanSkold. 5GNR:TheNextGenerationWirelessAccess
Technology. ElsevierScience,October2020. (Citedonpage1)
[17] TriDao,DanFu,StefanoErmon,AtriRudra,andChristopherR√©. FlashAttention: Fastand
memory-efficientexactattentionwithIO-awareness. NeurIPS,2022. (Citedonpage3)
[18] MattDeitke,EliVanderBilt,AlvaroHerrasti,LucaWeihs,JordiSalvador,KianaEhsani,Winson
Han,EricKolve,AliFarhadi,AniruddhaKembhavi,andRoozbehMottaghi. ProcTHOR:Large-
ScaleEmbodiedAIUsingProceduralGeneration. InNeurIPS,2022. (Citedonpages7and14)
[19] SebastianD√∂rner,MarcusHenninger,SebastianCammerer,andStephantenBrink. Wgan-based
autoencodertrainingover-the-air. InSPAWC,2020. (Citedonpage3)
[20] Leo Dorst. A guided tour to the plane-based geometric algebra pga. 2020. URL https:
//geometricalgebra.org/downloads/PGA4CS.pdf. (Citedonpages3and13)
10[21] YilunDu,ConorDurkan,RobinStrudel,JoshuaBTenenbaum,SanderDieleman,RobFergus,
JaschaSohl-Dickstein,ArnaudDoucet,andWillSussmanGrathwohl. Reduce,reuse,recycle:
Compositional generation with energy-based diffusion models and mcmc. In ICML, 2023.
(Citedonpage17)
[22] HermannGrassmann. DielinealeAusdehnungslehre. OttoWigand,Leipzig,1844. (Citedon
page3)
[23] AnkitGupta,JinfengDu,DmitryChizhik,ReinaldoAValenzuela,andMathiniSellathurai. Ma-
chinelearning-basedurbancanyonpathlosspredictionusing28ghzmanhattanmeasurements.
IEEETransactionsonAntennasandPropagation,2022. (Citedonpage1)
[24] ThomasMHehn,TribhuvaneshOrekondy,OriShental,ArashBehboodi,JuanBucheli,Akash
Doshi,JuneNamgoong,TaesangYoo,AshwinSampath,andJosephBSoriaga. Transformer-
basedneuralsurrogateforlink-levelpathlosspredictionfromvariable-sizedmaps. InIEEE
Globecom,2023. (Citedonpages7,8,and15)
[25] JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. NeurIPS,
2020. (Citedonpages3and13)
[26] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko,
DiederikPKingma,BenPoole,MohammadNorouzi,DavidJFleet,etal. Imagenvideo: High
definitionvideogenerationwithdiffusionmodels. arXiv:2210.02303,2022. (Citedonpage3)
[27] EmielHoogeboom,Vƒ±ctorGarciaSatorras,Cl√©mentVignac,andMaxWelling. Equivariant
diffusionformoleculegenerationin3d. InICML,2022. (Citedonpages3and14)
[28] Sepidehsadat Sepid Hossieni, Mohammad Amin Shabani, Saghar Irandoust, and Yasutaka
Furukawa. Puzzlefusion: Unleashingthepowerofdiffusionmodelsforspatialpuzzlesolving.
NeurIPS,2024. (Citedonpage3)
[29] Jakob Hoydis, Sebastian Cammerer, Fay√ßal Ait Aoudia, Avinash Vem, Nikolaus Binder,
GuillermoMarcus,andAlexanderKeller. Sionna: Anopen-sourcelibraryfornext-generation
physicallayerresearch. arXiv,2022. (Citedonpages1and3)
[30] MichaelJanner,YilunDu,JoshuaBTenenbaum,andSergeyLevine. Planningwithdiffusion
forflexiblebehaviorsynthesis. arXiv:2205.09991,2022. (Citedonpage3)
[31] JosephBKeller. Geometricaltheoryofdiffraction. J.Opt.Soc.Am.,JOSA. (Citedonpage2)
[32] DiederikPKingmaandMaxWelling. Auto-encodingvariationalbayes. ICLR,2014. (Citedon
page13)
[33] Jonas K√∂hler, Leon Klein, and Frank No√©. Equivariant flows: exact likelihood generative
learningforsymmetricdensities. InICML,2020. (Citedonpages3and14)
[34] JunG-YongLee,MinYoungKang,andSeong-CheolKim. PathLossExponentPredictionfor
OutdoorMillimeterWaveChannelsthroughDeepLearning. InWCNC,2019. (Citedonpage1)
[35] RonLevie,√áagÀòkanYapar,GittaKutyniok,andGiuseppeCaire. Radiounet: Fastradiomap
estimationwithconvolutionalneuralnetworks. IEEETWC,2021. (Citedonpage1)
[36] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc
VanGool. Repaint: Inpaintingusingdenoisingdiffusionprobabilisticmodels. InCVPR,2022.
(Citedonpage3)
[37] TLMarzettaandBMHochwald. Fasttransferofchannelstateinformationinwirelesssystems.
IEEETransactionsonSignalProcessing,2006. (Citedonpage3)
[38] BenMildenhall,PratulP.Srinivasan,MatthewTancik,JonathanT.Barron,RaviRamamoorthi,
andRenNg. Nerf: Representingscenesasneuralradiancefieldsforviewsynthesis. InECCV,
2020. (Citedonpage3)
[39] AlexanderQuinnNicholandPrafullaDhariwal. Improveddenoisingdiffusionprobabilistic
models. InICML,2021. (Citedonpage17)
11[40] TribhuvaneshOrekondy,ArashBehboodi,andJosephBSoriaga. Mimo-gan: Generativemimo
channelmodeling. InICC,2022. (Citedonpage3)
[41] TribhuvaneshOrekondy,PratikKumar,ShreyaKadambi,HaoYe,JosephSoriaga,andArash
Behboodi. Winert: Towardsneuralraytracingforwirelesschannelmodellinganddifferentiable
simulations. InICLR,2022. (Citedonpages3,6,7,and14)
[42] Timothy J O‚ÄôShea, Tamoghna Roy, and Nathan West. Approximating the void: Learning
stochasticchannelmodelsfromobservationwithvariationalgenerativeadversarialnetworks. In
ICNC,2019. (Citedonpage3)
[43] William Peebles and Saining Xie. Scalable diffusion models with transformers.
arXiv:2212.09748,2022. (Citedonpages14and17)
[44] KehaiQiu,StefanosBakirtzis,HuiSong,JieZhang,andIanWassell.PseudoRay-Tracing:Deep
LeaningAssistedOutdoormm-WavePathLossPrediction. IEEEWirelessCommunications
Letters,2022. (Citedonpage1)
[45] AdityaRamesh,PrafullaDhariwal,AlexNichol,CaseyChu,andMarkChen. Hierarchicaltext-
conditionalimagegenerationwithcliplatents. arXiv:2204.06125,1(2):3,2022. (Citedonpage3)
[46] VishnuVRatnam,HaoChen,SameerPawar,BingwenZhang,CharlieJianzhongZhang,Young-
JinKim,SoonyoungLee,MinsungCho,andSung-RokYoon. Fadenet: Deeplearning-based
mm-wavelarge-scalechannelfadingpredictionanditsapplications. IEEEAccess,2020. (Cited
onpage1)
[47] DavidRuhe, JayeshKGupta, StevendeKeninck, MaxWelling, andJohannesBrandstetter.
Geometriccliffordalgebranetworks. InICLR,2023. (Citedonpage13)
[48] JaschaSohl-Dickstein,EricWeiss,NiruMaheswaranathan,andSuryaGanguli. Deepunsuper-
visedlearningusingnonequilibriumthermodynamics. InICML,2015. (Citedonpages3and6)
[49] JiamingSong,ChenlinMeng,andStefanoErmon. Denoisingdiffusionimplicitmodels. ICLR,
2021. (Citedonpage8)
[50] YangSong,JaschaSohl-Dickstein,DiederikPKingma,AbhishekKumar,StefanoErmon,and
BenPoole. Score-basedgenerativemodelingthroughstochasticdifferentialequations. ICLR,
2021. (Citedonpages3and13)
[51] MarcoSousa,PedroVieira,MariaPaulaQueluz,andAnt√≥nioRodrigues. AnUbiquitous2.6
GHzRadioPropagationModelforWirelessNetworksusingSelf-SupervisedLearningfrom
SatelliteImages. IEEEAccess,2022. (Citedonpage1)
[52] YuTian,ShuaiYuan,WeishengChen,andNaijinLiu. Transformerbasedradiomapprediction
modelfordenseurbanenvironments. InISAPE,2021. (Citedonpage1)
[53] David Tse and Pramod Viswanath. Fundamentals of wireless communication. Cambridge
universitypress,2005. (Citedonpage3)
[54] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,
≈Åukasz Kaiser, and IlliaPolosukhin. Attention IsAll You Need. NeurIPS, 2017. (Citedon
pages3and7)
[55] PascalVincent. AConnectionBetweenScoreMatchingandDenoisingAutoencoders. Neural
computation,23(7):1661‚Äì1674,2011. (Citedonpage13)
[56] HaoYe,GeoffreyYeLi,Biing-HwangFredJuang,andKathiravetpillaiSivanesan. Channel
Agnostic End-to-End Learning Based Communication Systems with Conditional GAN. In
IEEEGlobecomWorkshops,2018. (Citedonpage3)
[57] LihaoZhang,HaijianSun,JinSun,andRoseQingyangHu. WiSegRT:DatasetforSite-specific
IndoorRadioPropagationModelingwith3DSegmentationandDifferentiableRay-Tracing.
arXiv:2312.11245,2023. (Citedonpage6)
[58] XiaopengZhao,ZhenlinAn,QingruiPan,andLeiYang. NeRF2: NeuralRadio-Frequency
RadianceFields. InACMMobiCom,2023. (Citedonpage3)
12A Geometricalgebra
Asrepresentation,Wi-GATrusestheprojectivegeometricalgebraG . Herewesummarizekey
3,0,1
aspectsofthisalgebraanddefinethecanonicalembeddingofgeometricprimitivesinit. Foraprecise
definitionandpedagogicalintroduction,wereferthereadertoDorst[20].
Geometricalgebra. AgeometricalgebraG consistsofavectorspacetogetherwithabilinear
p,q,r
operation,thegeometricproduct,thatmapstwoelementsofthevectorspacetoanotherelementof
thevectorspace.
Theelementsofthevectorspaceareknownasmultivectors. Theirspaceisconstructedbyextending
abasevectorspaceRdtolowerorders(scalars)andhigher-orders(bi-vectors,tri-vectors,...). The
algebracombinesalloftheseorders(orgrades)inone2d-dimensionalvectorspace. Fromabasis
forthebasespace,forinstance(e ,e ,e ),onecanconstructabasisforthemultivectorspace. A
1 2 3
multivectorexpressedinthatbasisthenreads,forinstanceford=3,x=x +x e +x e +x e +
‚àÖ 1 1 2 2 3 3
x e e +x e e +x e e +x e e e .
12 1 2 13 1 3 23 2 3 123 1 2 3
Thegeometricproductisfullydefinedbybilinearity,associativity,andtheconditionthatthegeometric
productofavectorwithitselfisequaltoitsnorm. Thegeometricproductgenerallymapsbetween
differentgrades. Forinstance,thegeometricproductoftwovectorswillconsistofascalar,theinner
productbetweenthevectors,andabivector,whichisrelatedtothecross-productofR3. Inparticular,
theconventionalbasiselementsofgradek >1areconstructedasthegeometricproductofthevector
basis elements e . For instance, e = e e is a basis bivector. From the defining properties of
i 12 1 2
thegeometricproductsitfollowsthatthegeometricproductbetweenorthogonalbasiselementsis
antisymmetric,e e =‚àíe e .
Thus,forad-dimensionalbasisspace,thereare(cid:0)d(cid:1)
independentbasis
i j j i k
elementsatgradek.
Projectivegeometricalgebra. Torepresentthree-dimensionalobjectsincludingabsolutepositions,
weuseageometricalgebrabasedonabasespacewithd = 4,addingahomogeneouscoordinate
to the 3D space.5 We use a basis (e ,e ,e ,e ) with a metric such that e2 = 0 and e2 = 1 for
0 1 2 3 0 i
i = 1,2,3. The multivector space is thus 24 = 16-dimensional. This algebra is known as the
projectivegeometricalgebraG .
3,0,1
Canonicalembeddingofgeometricprimitives. InG ,wecanrepresentgeometricprimitives
3,0,1
asfollows:
‚Ä¢ Scalars(datathatdonottransformundertranslation,rotations,andreflections)arerepresented
asthescalarsofthemultivectors(gradek =0).
‚Ä¢ Orientedplanesarerepresentedasvectors(k =1),encodingtheplanenormalaswellasthe
distancefromtheorigin.
‚Ä¢ Linesordirectionsarerepresentedasbivectors(k =2),encodingthedirectionaswellasthe
shiftfromtheorigin.
‚Ä¢ Pointsorpositionsarerepresentedastrivectors(k =3).
Formoredetails,wereferthereadertoTbl.1inBrehmeretal.[9],ortoDorst[20].
B Probabilisticmodel
Formally, we employ the standard DDPM framework [50] to train a latent variable model
(cid:82)
p (x ) = p (x )d , where x = [rsrp,tx,rx,mesh] denotes the joint vector of vari-
Œ∏ 0 Œ∏ 0:T x1:T 0
ables following the dataset distribution p (x ). In DDPM, the latent variables x are
data 0 1:T
noisy versions of the original data, defined by a discrete forward noise process q(x |x ) =
‚àö t t‚àí1
(cid:0) (cid:1)
N x ; 1‚àíŒ≤ x ,Œ≤ I and Œ≤ > 0. We approximate the reverse distribution q(x x ) with
t t t‚àí1 t i t‚àí1 t
(cid:80)
p (x |x )= q(x |x ,xÀÜ )p (xÀÜ |x ,t),whereq(x |x ,x )isanormaldistributionwith
clŒ∏ oset d‚àí -f1 ormt paramxÀÜ e0 ters[2t‚àí 5]1 . Tt hef0 orwŒ∏ ard0 ant dbackwarddistt r‚àí ib1 utiot ns0 qandpformavariationalauto-
encoder[32]whichcanbetrainedwithavariationallowerboundloss. Usingtheaboveparametriza-
tionofp (x |x ),however,allowsforasimpleapproximationofthislowerboundbytrainingon
Œ∏ t‚àí1 t
anMSEobjectiveL=E (cid:2) ||f (x ,t)‚àíx ||2(cid:3) whichresemblesdenoisingscorematching[55].
xt,x0 Œ∏ t 0
5Athree-dimensionalbasespaceisnotsufficienttorepresentabsolutepositionsandtranslationsactingon
theminaconvenientform.SeeBrehmeretal.[9],Dorst[20],Ruheetal.[47]foranin-depthdiscussion.
13Toparametrizep (xÀÜ |x ,t),wepasstherawrepresentationofx throughthewirelessGAtokenizer
Œ∏ 0 t t
ofWi-GATrand,additionally,weembedthescalartthroughalearnedtimestepembedding[43]. The
embeddedtimestepscanthenbeconcatenatedalongthescalarchannelsintheGArepresentationin
astraightforwardmanner. SimilartoGATr[9],theneuralnetworkoutputsapredictionintheGA
representation,whichissubsequentlyconvertedtotheoriginallatentspace. Notethatthispossibly
simplifiesthelearningproblem,astheGArepresentationisinherentlyhigherdimensionalthanour
diffusionspacewiththesamedimensionalityasx .
0
Equivariant generative modelling. A diffusion model with an invariant base density and an
equivariantdenoisingnetworkdefinesaninvariantdensity,butequivariantgenerativemodellinghas
somesubtleties[33]. Becausethegroupoftranslationsisnotcompact,wecannotdefineatranslation-
invariantbasedensity. Previousworkshavecircumventedthisissuebyperformingdiffusioninthe
zerocenterofgravitysubspaceofeuclideanspace[27]. However,wefoundthatdirectlyproviding
theoriginasanadditionalinputtothedenoisingnetworkalsoresultedingoodperformance,atthe
costoffullE(3)equivariance. Wealsochoosetogeneratesamplesintheconventionwherethez-
axisrepresentsthedirectionofgravityandpositivezis‚Äúup‚Äù;wethereforeprovidethisdirectionof
gravityasanadditionalinputtoournetwork.
Maskingstrategies. Toimprovetheperformanceofconditionalsampling,werandomlysample
conditioning masks during training which act as an input to the model, as well as a mask on
the loss terms. Namely, we sample masks from a discrete distribution with probabilities p =
(0.2,0.3,0.2,0.3)correspondingtomasksforunconditional,signal,receiverandmeshprediction
respectively. If we denote this distribution over masks as p(m), the modified loss function then
reads as L = E (cid:2) ||m‚äôf (xm,t,m)‚àím‚äôx ||2(cid:3) , where xm is equal to x along
m‚àºp(m),xt,x0 Œ∏ t 0 t 0
themaskedtokensaccordingtom.
C Datasets
Table 4 summarizes major characteristics of the two datasets. In the following we explain more
detailsondatasplitsandgeneration.
Wi3R dataset. Based on the layouts of the Wi3Rooms dataset by Orekondy et al. [41], we run
simulationsfor5000floorlayoutsthataresplitintotraining(4500),validation(250),andtest(250).
Thesevalidationandtestsplitsthusrepresentgeneralizationacrossunseenlayouts,transmitter,and
receiverlocations. Fromthetrainingset,wekeep10Rxlocationsasadditionaltestsettoevaluate
generalizationonlyacrossunseenRxlocations. Toevaluatethegeneralizationperformance,wealso
introduceanout-of-distribution(OOD)setthatfeaturesfourroomsineachofthe250floorlayouts.
Inalllayouts,theinteriorwallsaremadeofbrickwhileexteriorwallsaremadeofconcrete. TheThe
TxandRxlocationsaresampleduniformlywithintheboundsofthefloorlayouts(10m√ó5m√ó3m).
WiPTR dataset. Based on the floor layouts in the ProcTHOR-10k dataset for embodied AI re-
search[18],weextractthe3Dmeshinformationincludingwalls,windows,doors,anddoorframes.
Thelayoutscomprisebetween1to10roomsandcancoverupto600m2. Weassign6different
dielectricmaterialsfordifferentgroupsofobjects(seeTbl.5). The3DTxandRxlocationsareran-
domlysampledwithintheboundsofthelayout. Thetrainingdatacomprises10kfloorlayouts,while
testandvalidationsetseachcontain1kunseenlayouts,Tx,andRxlocations. Again,weintroducean
OODvalidationsetwith5layoutswherewemanuallyremovepartsofthewallssuchthattworooms
becomeconnected. Whilethemulti-modalityincombinationwiththeProcTHORdatasetenables
furtherresearchforjointsensingandcommunicationinwireless,ourdatasetsetisalso,tothebestof
ourknowledge,thefirstlarge-scale3DwirelessindoordatasetssuitableforembodiedAIresearch.
D Experiments
D.1 Predictivemodelling
Models. WeuseanWi-GATrmodelthatis32blocksdeepand16multivectorchannelsinaddition
to32additionalscalarchannelswide. Weuse8attentionheadsandmulti-queryattention. Overall,
themodelhas1.6¬∑107parameters. Thesesettingswereselectedbycomparingfivedifferentlysized
networksonanearlierversionoftheWi3Rdataset,thoughsomewhatsmallerandbiggernetworks
143 Wi3R
2
1
Transformer
Wi-GATr (ours)
0.5
1 2 3 5 10
Number of transmitters
Figure6:Rxlocalizationerror,asafunctionofthenumberofTx.Linesanderrorbandshowmeanandits
standarderrorover240measurements.
achievedasimilarperformance.
OurTransformermodelhasthesamewidth(translatingto288channels)anddepthastheWi-GATr
model, totalling 16.7¬∑106 parameters. These hyperparameters were independently selected by
comparingfivedifferentlysizednetworksonanearlierversionoftheWi3Rdataset.
ForSEGNN,weuserepresentationsofupto‚Ñì =3,8layers,and128hiddenfeatures. Themodel
max
has2.6¬∑105parameters. Weselectedtheseparametersinascanoverallthreeparameters,withinthe
rangesusedinBrandstetteretal.[8].
ThePLViTmodelisbasedontheapproachintroducedbyHehnetal.[24]. Weemploythesame
centeringandrotationstrategyasintheoriginalapproacharoundtheTx. Further,weextendthe
originalapproachto3dimensionsbyprovidingthedifferenceinz-directionconcatenatedwiththe
2Dx-y-distanceasonetoken. Sincetrainingfromscratchresultedinpoorperformance,wefinetuned
aViT-B-16modelpretrainedonImageNetandkeepingonlytheredchannel. Thisresultedinamodel
with85.4¬∑107parametersandalsorequiredustouseafixedimagesizeforeachdatasetthatensures
theentirefloorlayoutisvisibleintheimagedata.
Optimization. Allmodelsaretrainedonthemeansquarederrorbetweenthemodeloutputand
thetotalreceivedpowerindBm. Weuseabatchsizeof64(unlessforSEGNN,whereweusea
smallerbatchsizeduetomemorylimitations),theAdamoptimizer,aninitiallearningrateof10‚àí3,
andacosineannealingscheduler. Modelsaretrainedfor5¬∑105 stepsontheWi3Rdatasetandfor
2¬∑105stepsontheWiPTRdataset.
Inferencespeed. Toquantifythetrade-offbetweeninferencespeedandaccuracyofsignalprediction,
wecomparetheraytracingsimulationwithourmachinelearningapproaches. Forthispurpose,we
evaluatethemethodsonasingleroomofthevalidationsetwith2differentTxlocationsandtwo
Wi3R WiPTR
TotalChannels 5M >5.5M
Materials 2 6
Transmittersperlayout 5 1-15
Receiversperlayout 200 Upto200
Floorlayouts 5k 12k
Simulatedfrequency 3.5GHz 3.5GHz
Reflections 3 6
Transmissions 1 3
Diffractions 1 1
Strongestpathsretained 25 25
Antennas Isotropic Isotropic
Waveform Sinusoid Sinusoid
Table4:Datasetdetailsandsimulationsettingsfordatasetgeneration.
15
]m[
rorre
noitazilacol
xR
naeMWireless InSite
4 Transformer
Wi-GATr (ours)
3
2
1
0
10 2 10 1 100
Time per link [s]
Figure7:InferencewalltimevssignalpredictionerrorperTx/RxpredictiononthefirstroomoftheWiPTR
validationset.
equidistantgridsatz ‚àà{2.3,0.3}witheach1637Rxlocations. Figure7summarizestheaverage
inferencetimesperlinkwiththecorrespondingstandarddeviation. WhileWirelessInSite(6/3/1,
i.e.,6reflections/3transmissions/1diffraction)representsourmethodthatwasusedtogeneratethe
groundtruthdata,itisalsobyfartheslowestapproach. Notethatweonlymeasuretheinference
speedofWirelessInSiteforeachTxindividuallywithoutthepreprocessingofthegeometry. By
reducingthecomplexity,e.g.,reducingthenumberofallowedreflectionsortransmissions,oftheray
tracingsimulationtheinferencetimecanbereducedsignificantly. Forexample,theconfiguration
3/2/1showsasignificantincreaseininferencespeed,butatthesametimewecanalreadyseethatthe
simulationresultsdonotmatchthegroundtruthanymore.Thiseffectisevenmorepronouncedforthe
caseofWirelessInSite3/1/1. Ourmachinelearningsolutionsoutperformalltestedconfigurationsof
WirelessInSiteintermsofinferencespeed,whileatthesametimekeepingcompetitiveperformance
intermsofpredictionaccuracy(MAE)comparedtothedatagenerationsimulationitselfinasimpler
configurationsetting.
Inaddition,thedifferentiabilityofMLapprochesenablesthemtosolveinverseproblemsandsuch
asfinetuningtoreal-worldmeasurementdata. Finetuning,oftenreferredtoascalibration,remains
challengingforsimulationsoftwareandwilllikelyleadtoincreasedMAEasthegroundtruthisnot
givenbyWirelessInSiteitselfanymore.
D.2 Probabilisticmodelling
Experiment setup. For all conditional samples involving p(F |F ,t,r,h), we always choose
u k
tosetF tobethefloorandceilingmeshfacesonlyandF tobetheremaininggeometry. This
k u
amountstocompletelypredictingtheexteriorwalls,aswellastheseparatingwalls/doorsofthethree
rooms,whereastheconditioningonF actsonlyasameantobreakequivariance. SinceF isalways
k
canonicalizedinthenon-augmentedtrainingdataset,thisallowsfordirectcomparisonofvariational
lowerboundsinTbl.3withthenon-equivarianttransformerbaseline.
Models. ForbothWi-GATrandthetransformerbaseline,wefollowsimilararchitecturechoicesas
Object Materialname Rel.Permittivity[1] Conductivity[S/m] Thickness[cm]
Ceiling ITUCeilingBoard 1.5 0.002148 0.95
Floor ITUFloorBoard 3.66 0.02392 3.0
Exteriorwalls Concrete 7.00 0.0150 30.0
2.94 0.028148 1.30
ITULayeredDrywall
Interiorwalls 1 0 8.90
(3layers)
2.94 0.028148 1.30
Doorsanddoorframes ITUWood 1.99 0.017998 3.0
Windows ITUGlass 6.27 0.019154 0.3
Table5:DielectricmaterialpropertiesofobjectsinWiPTR.
16
]mBd[
EAM10
Wi3R
5
2
Transformer
1 Wi-GATr (ours)
10 100 1000 4500
Training rooms
Figure8:Meanabsoluteerrorsofreceivedpowerasafunctionofnumberoftrainingroomsforconditional
diffusionmodelsamples.
forthepredictivemodels,usinganequalamountofattentionlayers. Tomakethemodelstimestep-
dependent, we additionally employ a standard learnable timestep embedding commonly used in
diffusiontransformers[43]andconcatenateittothescalarchanneldimension.
Optimization. WeusetheAdamoptimizerwithalearningrateof10‚àí3fortheWi-GATrmodels.
The transformer modelsrequired a smaller learning rate fortraining stability, and thus we chose
3¬∑10‚àí4. Inbothcases,welinearlyannealthelearningrateandtrainfor7¬∑105stepswithabatchsize
of64andgradientnormclippingsetto100.
Evaluation. We use the DDIM sampler using 100 timesteps for visualizations in Fig. 5 and
for the error analysis in Fig. 8. To evaluate the variational lower bound in Tbl. 3, we fol-
low [39] and evaluate L := L + L + ...L , where L := ‚àílogp (x |x ), L :=
vlb 0 1 T 0 Œ∏ 0 1 t‚àí1
D (q(x |x ,x )||p (x |x )) and L := D (q(x |x ),p(x )). To be precise, for each
KL t‚àí1 t 0 Œ∏ t‚àí1 t T KL T 0 t
samplex onthetestset,wegetasinglesamplex fromqandevaluateL accordingly. Table3
0 t vlb
reportsthemeanofallL evaluationsoverthetestset.
vlb
Additionalresults. Fig.8, showsthequalityofsamplesfromp (h|F,t,r)asafunctionofthe
Œ∏
amountofavailabletrainingdata,whereweaverageover3samplesforeachconditioninginput. It
isworthnotingthatdiffusionsampleshaveaslightlyhighererrorthanthepredictivemodels. This
showsthatthejointprobabilisticmodellingofthewholesceneisamorechallenginglearningtask
thanadeterministicforwardmodel.
Tofurtherevaluatethequalityofgeneratedrooms,weanalyzehowoftenthemodelgenerateswalls
betweenthereceiverandtransmitter,comparedtothegroundtruth. Precisely,weplotthedistribution
of received power versus the distance of transmitter and receiver in Fig. 9 and color each point
accordingtoalineofsighttest. Wecanseethat,overall,Wi-GATrhasanintersectionerrorof0.26,
meaningthatin26%ofthegeneratedgeometries,lineofsightwasoccluded,whilethetruegeometry
didnotblocklineofsightbetweenreceiverandtransmitter. Thisconfirmsthatthediffusionmodel
correctlycorrelatesthereceivedpowerandreceiver/transmitterpositionswithphysicallyplausible
geometries. Whileanerrorof26%isnon-negligible,wenotethatthistaskinvolvesgeneratingthe
wholegeometrygivenonlyasinglemeasurementofreceivedpower,makingtheproblemheavily
underspecified. Techniquessuchascompositionalsampling[21]couldovercomethislimitationby
allowingtoconditiononmultiplereceiverandreceivedpowermeasurements.
E Discussion
Progressinwirelesschannelmodellingislikelytoleadtosocietalimpact. Notallofitispositive.
Theabilitytoreconstructdetailsaboutthepropagationenvironmentmayhaveprivacyimplications.
Wirelessnetworksareubiquitousandcouldquiteliterallyallowtoseethroughwalls.Atthesametime,
webelievethatprogressinthedevelopmentofwirelesschannelmodelsmayhelptoreduceradiation
exposureandpowerconsumptionofwirelesscommunicationsystems,andgenerallycontributeto
betterandmoreaccessiblemeansofcommunication.
17
]mBd[
EAMWi-GATr: Intersection Error: 0.264 Transformer: Intersection Error: 0.261 True distribution
1.75 1.75 1.75 O Lic nc el u od f e Sd ight
1.50 1.50 1.50
1.25 1.25 1.25
1.00 1.00 1.00
0.75 0.75 0.75
0.50 0.50 0.50
0.25 Occluded 0.25 Occluded 0.25
Line of Sight Line of Sight
0.00 0.00 0.00
6 4 2 0 2 4 2 0 2 6 4 2 0 2
RSRP RSRP RSRP
Figure 9: A scatter plot of normalized received power versus normalized distance between receiver and
transmitter.Eachpointiscoloreddependingonhavinglineofsightbetweenthereceiverandtransmittergiven
theroomgeometry. Left: Thegeometryusedforcalculatinglineofsightisgivenbyconditionaldiffusion
samplesusingWi-GATr. Middle: Thegeometryusedforcalculatinglineofsightisgivenbytransformer
samples.Right:Thegeometryusedforcalculatinglineofsightistakenfromthetestdatadistribution.
18
ecnatsid
kniL
ecnatsid
kniL
ecnatsid
kniL