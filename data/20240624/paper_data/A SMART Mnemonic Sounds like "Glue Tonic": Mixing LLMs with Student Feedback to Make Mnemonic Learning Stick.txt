A SMART Mnemonic Sounds like “Glue Tonic”:
Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick
NishantBalepur1 MatthewShu2 AlexanderHoyle1 AlisonRobey3
ShiFeng4 SeraphinaGoldfarb-Tarrant5 JordanBoyd-Graber1
1UniversityofMaryland 2YaleUniversity 3SUNYEmpireStateUniversity
4NewYorkUniversity 5Cohere
nbalepur@umd.edu jbg@umiacs.umd.edu
Abstract masteringhundredsofterms(Al-Jarf,2016). De-
spitetheirutility,writingmnemonicsistedious,re-
Keywordmnemonicsarememorableexplana-
quiringvocabularyexpertiseandcreativitytomake
tionsthatlinknewtermstosimplerkeywords.
memorablekeywordlinks(Siriganjanavong,2013).
Priorworksgeneratemnemonicsforstudents,
buttheydonotguidemodelstowardmnemon- Toeasetheseburdens,priorworkhasautomati-
icsstudentspreferandaidlearning. Webuild callygeneratedkeywordmnemonics(Savvaetal.,
SMART,amnemonicgeneratortrainedonfeed-
2014). However,mostworkstestkeywordextrac-
backfromrealstudentslearningnewterms. To
tion(Anonthanasapetal.,2015),omittingtheex-
trainSMART,wefirstfine-tuneLLaMA-2on
planationslinkingkeywordstotermsthatenableef-
acuratedsetofuser-writtenmnemonics. We
fectivemnemonicuse(RaughandAtkinson,1975).
thenuseLLMalignmenttoenhance SMART:
wedeploymnemonicsgeneratedbySMARTin LargeLanguageModels(LLMs)areaptforwriting
aflashcardapptofindpreferencesonmnemon- explanations,adifficulttaskthattestsifLLMscan
icsstudentsfavor. Wegather2684preferences combinevocabulary(Huangetal.,2022a),phonol-
from45studentsacrosstwotypes: expressed ogy(Suvarnaetal.,2024),commonsense(Davis,
(inferredfromratings)andobserved(inferred
2023),andcreativity(Tianetal.,2023)tohelpstu-
fromstudentlearning),yieldingthreekeyfind-
dentslearn(§6.3). Whilepromising,existingworks
ings. First,expressedandobservedpreferences
onlypromptLLMs(LeeandLan,2023)andlack
disagree; what students think is helpful does
notfullycapturewhatistrulyhelpful. Second,
trainingonstudentfeedbacktoguideLLMstoward
Bayesian models can synthesize complemen- mnemonicsstudentspreferandbenefitlearning.
tarydatafrommultiplepreferencetypesinto Inpursuitofstudent-guidedmnemonics,wepro-
asingleeffectivenesssignal. SMARTistuned
poseSMART,whichemploysStudentMnemonic
viaDirectPreferenceOptimizationonthissig-
Alignment to generate keyword mnemonics that
nal,whichweshowresolvestiesandmissing
aidtheRecallofvocabTerms. (Figure1). Totrain
labelsinthetypicalmethodofpairwisecompar-
isons,augmentingdataforLLMoutputquality
SMART,wefirstcollectdatafromMnemonicDic-
gains. Third,mnemonicexpertsassessSMART tionary(Memliapp,2007),asitewhereuserssub-
asmatchingGPT-4,atmuchlowerdeployment mitmnemonicstheyfindhelpful. Wecurateahigh-
costs,showingtheutilityofcapturingdiverse qualitysubsetofthisdataandfine-tuneLLaMA-2
studentfeedbacktoalignLLMsineducation.1
70B (Figure 1, left) as our initial model (§2). To
1 MnemonicsAidVocabularyLearning
enhance SMART, we draw from LLM alignment,
whichimprovesLLMsviatuningtopreferencela-
Keywordmnemonicspromoteefficientandengag- belsthatcapturewhichoftwoLLMoutputsusers
ingvocabulary(vocab)learning(BengeandRob- favor(Casperetal.,2023). Wegatherpreferences
bins,2009). Thesetoolshelpstudentslearnanew bysamplingmnemonicsfromourinitialmodeland
term’smeaning(e.g. Benevolent)byrelatingittoa deployingthemtostudentsinaflashcardapp(§3).
simplerkeyword(e.g. Benevolentsoundslikeben-
Therearemanywaystocollectpreferences,and
efit),andexplaininghowthekeywordandtermare
Bansal et al. (2024) show that pairwise rankings
linked(e.g. Abossgivingemployeebenefitsiskind,
andLikertratingsyieldconflictinglabelsonwhich
whichisthemeaningofbenevolent)(Pressleyetal.,
LLMoutputisfavored. Tostudypreferenceagree-
1982). Studentsusemnemonicstoprepareforex-
mentineducation(Figure1,mid),wealsogather
amsliketheGRE(Fairbanks,1977)whichinvolve
pairwiseandLikertannotations,whichwedefine
1https://github.com/nbalepur/Mnemonic asexpressedpreferences: thoseinferredfromuser
4202
nuJ
12
]LC.sc[
1v25351.6042:viXraSupervised Fine-Tuning (§2) Preference Collection (§3) Bayesian Modeling (§5.1) DPO (§5.2)
1) Pairwise Comparison Preferences
Term: Benevolent Overall Mnemonic Effectiveness
Mnemonic A Mnemonic B
... ... Mnemonic A
...
A Wins Tie B Wins
2) Likert Rating Preferences Mnemonic B
Mnemonic A Mnemonic B ...
... ...
Mnemonic A DPO Loss
Benevolent sounds like “benefit”. A Likert Counts
boss giving workers benefits is kind 3) Learning Preferences
Mnemonic A Mnemonic B
Mnemonic B
... ...
Benevolent sounds like “Benjamin
Franklin”, who was a kind individual
Iterations until Correct
Figure1: SMARToverview. Wefine-tuneLLaMA-270BfortheinitialSMARTmodel(§2). Wethencollectthree
preferencetypes: pairwise,rating,andlearning(§3). Finally,aBayesianmodelsynthesizesmnemoniceffectiveness
fromallthreepreferences(§5.1)andweusethissignaltoalignSMARTviaDirectPreferenceOptimization(§5.2).
ratings. Expressedpreferencesmeasurewhatusers Lastly,twomnemonicexpertsassessmnemonics
thinkaremorehelpful,buttoseeifthisagreeswith (§6.3)fromSMART,GPT-4,andanexperthuman
whattrulyhelpsusers,weintroduceobservedpref- writer,finding: 1)SMARTmatchestheSOTALLM
erences: thoseinferredfromobservableoutcomes GPT-4,showingtheutilityofstudentfeedback;and
asusersinteractwithoutputs. Wecollectobserved 2)Ourwriterlargelysurpassesmodelsatcreating
preferencesviathemeantimeusersneedtolearna simplekeywordsandimageableexplanations,mo-
termwhilestudyingwithitsmnemonic,servingas tivatingmnemonicgenerationasadifficulttaskand
aproxyformnemonicshort-termlearningefficacy. giving insights into feedback that can be used to
Overthreemonths,45studentsgiveus2684pref- guideLLMsinsimilartasks. Ourcontributionsare:
erencesonmnemonicpairs. Todecidehowtoalign 1)Wedesign SMART,anLLMmnemonicgenera-
SMART,westudytherelationofpreferencetypes. torguidedbyfeedbackfromreal-worldstudents.
Expressedandobservedpreferencesdisagree(§4), 2)Weanalyzeexpressedandobservedpreferences,
sowhatstudentsthinkhelpsthemlearndiffersfrom findingthatstudentscannotpredicttheirlearning.
whattrulyhelpsthemlearn. Weintuitthesepref- 3)WealignSMARTwithmultiplepreferencesvia
erencetypesrepresentequally-valuablegoals(§5): BayesianmodelingandDPO,resultinginkeyword
aneffectivemnemonicshouldbenon-harmfuland mnemonicsthatmatchtheSOTALLMGPT-4.
likedbyusers(expressed),butalsoaidlearning(ob- 4) We release the first fine-tuning and preference
served). Thus,wedesignaBayesianmodel(Gel- datasetstoaidresearchinmnemonicgeneration.
manandHill,2006)thatlearnsmnemoniceffective-
2 AnInitial SMART MnemonicModel
nessviafeedbackfromallpreferencetypes(§5.1).
Wecomparemnemonicsbyeffectivenesstoelecta Given a vocabulary (vocab) term v (e.g. Benevo-
winningmnemonicinthepair(Figure1,right)and lent),wedesireakeywordmnemonicmstudents
tune SMART withDirectPreferenceOptimization canusetorememberthemeaningofv. Foroptimal
(Rafailovetal.,2024,DPO)onthissignal(§5.2). benefits(McDanielandPressley,1984),mshould
Weconductseveralexperimentstotest SMART. linktoasimilarlysoundingandsimplerkeywordk
Fine-tuningandDPOenhanceSMART,soaligning (e.g. Benevolentsoundslikebenefit),andthenex-
LLMstostudentpreferencesimproveseducational plainhowkandvarelinked(e.g. Abosswhogives
text(§6.1). Further,combiningallpreferencesvia theiremployeesbenefitsiskind—orbenevolent).
Bayesianmodelingcanresolvetiesormissingla- WenowtrainaninitialSMARTmodeltogener-
belsinthetypicalmethodofpairwisecomparisons, atekeywordmnemonics. Wecollectahigh-quality
augmentingDPOdataformnemonicqualitygains datasetofuser-writtenmnemonics(§2.1,§2.2)and
(§6.2). Multiplepreferencescanbegatheredinone fine-tuneSMARTonthismnemonicdataset(§2.3).
app,sometimeswithnoextraannotations(§3.2.2).
2.1 DataCollection
Soifresourcesallow,weadvisecollectingmultiple
preferencestostudytherelationofcomplementary Theredoesnotexistadatasetofvocabtermsand
alignmentobjectives,whichcanthenbecombined mnemonics,sowecuratenewdatasetstofacilitate
fordataaugmentationtoimproveLLMoutputs. mnemonicresearch. WeusevocabwordsfromtheGraduateRecordsExamination(GRE),agraduate vron et al., 2023) to minimize the cross-entropy
admissionsexamthatstudentsprepareforbylearn- lossL ofpredictingtokensm ∈ mgivenP:
CE j
inghundredsofvocabterms(Nayaketal.,2017).
|m|
Mnemonicshavebeenusedtohelpstudentslearn (cid:88)
L = logp(m |m ,...,m ,P) (3)
CE j 1 j−1
GREvocabulary(Fairbanks,1977;Pietal.,2021).
j=1
Webaseourdataseton2380publicEnglishGRE
termsV fromseventutoringsites(Kotchian,2019). WeuseQLoRA(Dettmersetal.,2024)tominimize
WefindamnemonicforeachtermfromMnemon- L CE. AllparametersarelistedinAppendixB.1.
icDictionary(Memliapp,2007),asitewhereusers
3 CollectingMnemonicPreferences
submitkeywordmnemonicsforvocabterms. Users
canalsovoteonmnemonics,whichwelateruseto Onlyfine-tuningdoesnotexplicitlyguide SMART
findhigh-qualitymnemonics(§2.2). Withpermis- towardmnemonicsthatuserspreferandhelpthem
sionfromtheowners,wecollect13955candidate learn—our overall goal. Thus, we use alignment
MnemonicDictionarymnemonicsforourdataset. (Ziegleretal.,2019),whichtunesLLMstoprefer-
encelabelscapturingwhichoutputsusersfavor. To
2.2 IdentifyingHigh-QualityMnemonics
align SMART,weneedapreferencedatasetD
pref
Theuser-submittedmnemonicscollectedfrom§2.1 withentriesofatermv,mnemonicpair(m ,m )
A B
are noisy, but using a subset of high-quality data forvcreatedbytheinitialmodelp (m|v),andpref-
0
canbettertrain SMART formnemonicgeneration erencelabely ∈ {A,B,tie}notingthemnemonic
(Xiaetal.,2024). MnemonicDictionaryusersup- inthepairusersfavor. TobuildD , wecreate
pref
voteordownvotemnemonics,soupvoteratiocould mnemonicpairs(§3.1),defineourpreferencelabels
findhigh-qualitydata,butthismetricdoesnotcon- (§3.2),anddescribeouruserstudydetails(§3.3).
siderallupvotesgiven(Powelletal.,2017). Thus,
3.1 GeneratingMnemonicPairs
followingHoffartetal.(2019),weuseaBayesian
modeltolearntheprobabilityq ofmnemonicm ForD ,wefirstneedmnemonicpairs(m ,m )
i i pref A B
being high-quality, based on the upvote ν and createdbymodelp (m|v)formanytermsv. For
u,i 0
downvoteν countsonm . Weassumemnemon- optimalresults,weseekdiversemnemonicswith
d,i i
icswithhigherq havemoreupvotes,sowemodel highprobabilityinp (m|v). Thisensuresthepair
i 0
ν asaBinomialdistributionwithprobabilityq : reflects the distribution of p (m|v) and gives the
u,i i 0
userdistinctchoices,yieldingclearerpreferences.
q i ∼ Beta(α = 2,β = 8) (1) Wedothisviabest-of-nsampling(Nakanoetal.,
ν ∼ Binomial(ν +ν ,q ) (2) 2021),whichsamplesnLLMoutputsandpicksthe
u,i u,i d,i i
onewiththebestscorefromarewardmodel. We
q i hasthepriorα = 2,β = 8,asourbriefmanual definearewardπ pair(m A,m B,v)thatreturnsthe
assessmentfoundthat∼20%ofthemnemonicsare sum of m and m sequence probabilities from
A B
high-quality. Weestimateq i viaNoU-TurnSam- p 0(m|v),minustheROUGE-1(Lin,2004)ofm A
pling(Hoffmanetal.,2014,NUTS).Pairs(v i,m i) andm B. Therewardfavorsmnemonicswithhigh
withthe1000-highestq ivaluesformthefine-tuning sequenceprobabilityandlowwordoverlap. Tocre-
datasetD ft for SMART(detailsinAppendixA). atemnemonicpairs,wetake1000termsV pref ⊂ V
notusedinD . Foreachv ∈ V ,wesample
train pref
2.3 ModelFine-Tuning
fivemnemonicsM = {m}5 ∼ p (m|v)with0.3
0
ThedatasetD ft hasterm/mnemonicpairs(v,m), temperature. Wetake(m A,m B) ∈ M×Mwith
sowecanuseD fttotrainaninitialseq2seqSMART thebestπ pair(m A,m B,v)scoreasthepairforv.
modelp (m|v)togeneratemfromv. Uponinspec-
0
3.2 PreferenceLabelCollection
tion,wefindsomequalityissuesinthemnemonics,
soweuseGPT-4tocleangrammarerrorsinmviaa Whilepreferencesareoftenelicitedthroughcrowd-
0-shotprompt,anddiscardanymwithoffensiveor workersites,wedecidetocollectpreferencesfrom
overlyculturally-specifictext(seeAppendixA.1). studentswhocandirectlybenefitfrommnemonics.
Weendupwith889pairsforfine-tuning SMART. Flashcard software can aid mnemonic use (Tuite
Each (v,m) ∈ D becomes the prompt P = etal.,2012),sowehostouruserannotationschema
ft
“Term:v\nMnemonic:”andoutputm. Ourini- withinaflashcardapptogatherstudentpreferences
tialmodelp (m|v)fine-tunesLLaMA-270B(Tou- y ∈ {A,B,tie}forthemnemonicpairsin§3.1.
0Figure2: Screenshotfromourweb-basedflashcardapp
afterauserispresentedaGREvocabularyflashcard.
Figure4: ScreenshotofUIforpairwisecomparisons.
Wecallthispreferencey andsetittothemost
pair
votedoption. Orderisshuffledforpositionbiases.
3.2.2 ObservedPreferences
Expressedpreferencesmeasuretheoutputsusers
thinkaremorehelpful,buttheydonotcapturewhat
Figure3: ScreenshotofUItocollectLikertratings.
istrulymorehelpfulforusergoals(e.g. learning).
Suchpreferencesareundefined,soweproposeob-
Inourapp,usersstudyflashcardsf withaterm
v
servedpreferences—thoseinferredfromobserved
vasthefrontofthecardandtypeitsdefinition(Fig-
outcomesofuserinteractionswithmodeloutputs.
ure2). Ifauseranswersf incorrectly,theyseea
v
Askeywordmnemonicscanimproveshort-term
mnemonicfromthepair(§3.1)forvtoaidlearning
recall(Wangetal.,1992),webaseobservedpref-
(Figure3). Userskeepstudyingwithf untilthey
v
erencesonthemeanturnst usersstudyingwith
answer f correctly (after n turns). We use the X
v
m needtocorrectlyansweritscardf , aproxy
KAR3L(Shuetal.,2024)modeltoschedulecards. X v
forshort-termlearning. Foreachpair(m ,m ),
Researchersoftenuseonemethodtocollectpref- A B
ift < t ,wecallthispreferencelabely and
erences. Butdiversemethods,likepairwisecom- A B learn
sety = A,asm helpsuserslearnthedefini-
parisonsandLikertratings,canyieldconflictson learn A
tion of v quicker than m (same for B and tie).
whichoutputsarefavored(EthayarajhandJurafsky, B
y iscollectedautomaticallyasusersstudy.
2022;Bansaletal.,2024),andmayalsogivecom- learn
plementarysignalsforLLMoutputquality(§5). To
3.3 UserStudyDetails
seehowdiverseschemaimpactpreferencesinedu-
WedeploymnemonicsfromD andhave47stu-
cation,wecollectthreedifferentpreferencelabels pref
dentsfromexampreparationforums,Googleads,
groupedintotwotypes: expressedandobserved.
anduniversitycoursesstudyinourapp. Weaddran-
3.2.1 ExpressedPreferences domqualitychecksinpairwisecomparisons,where
onemnemonicisclearlylow-quality. Allusers,in-
Wedefineexpressedpreferencesasthoseinferred
cludingthetwousersthatfailedthequalitychecks,
fromexplicituserratings—themostcommonpref-
are given $50. In three months, 45 students gave
erencetype(Casperetal.,2023). Wecollecttwo
2684preferencesfor752mnemonicpairsand472
expressedpreferences: Likertratings(Harpe,2015)
uniquepairs(Table5,detailsinAppendixA.2). We
andpairwisecomparisons(Bozókietal.,2013).
omitpairswithtwoorfewerlabelssothemeanla-
ForLikertratings,whenauserseesamnemonic
belsperpairis3.57,followingthemethodofusing
m afteransweringcardf incorrectly,theyrate
X v
threeormorepreferencestocurbnoise(Baietal.,
m on a 5-Likert scale (Figure 3). We call this
X
2022;Jietal.,2024). UsersarereferredtobyID.
preferencelabely andsety = Aiftheaver-
rate rate
ageLikertratingofm ishigherthanm across
A B 4 PreferenceAnalysis
users(sameforBandtie). Foreachf ,userssee
v
only one of m or m , so their rating cannot be Westudytherelationofourthreepreferences(§3.2)
A B
biasedbyhavingalreadyseentheotherinthepair. anduncoverthatstudentscannotfullypredictwhat
Forpairwisepreferences,iff isansweredcor- helpsthemlearn(§4.1,§4.2). Thisleadsustointuit
v
rectly,theuserpicksthemnemonicin(m ,m ) thatourpreferencescapturecomplementaryfacets
A B
they think would help them learn best (Figure 4). ofmnemoniceffectiveness,inspiringthedesignof
Userscanpickonemnemonicormarkthemequal. ourfinalmodelthatcombinesallpreferences(§5).PreferencePairs RawAgreement SampleSize outputs. Butaspreferencetypesdisagree(§4),how
(y ,y ) 0.675 80 shouldweidentifymoreeffectivemnemonics?
pair rate
(y rate,y learn) 0.507 73 Pairwisecomparisonsaretypicallyusedforthis
(y ,y ) 0.407 59
pair learn
purpose,buttheydonotalwaysmatchourgoalof
Table1: Rawagreementofpreferencelabeltypes.
aidinglearning(§4.1). Further,whenpairwisepref-
6 erencesaremissingorhaveatie,wecoulddraw
Pearon's r = -0.06
5 fromotherpreferencestobreakthesetiesandiden-
4 tifythebettermnemonic,insteadofdiscardingthe
3 pairfortraining(§6.2). Conversely,usingobserved
preferencestoselectmoreeffectivemnemonicsis
2
promisingasitmatchesourlearninggoal,butalso
1
1 2 3 4 5 using expressed preferences could help us avoid
5-Likert Rating of the Mnemonic
bizarreoroffensive(KrollandTu,1988)mnemon-
Figure5: Correlationbetweenausermnemonicrating
icsthatmaystillaidlearning(seeAppendixD.1).
andtheiterationsneededforthesameusertorecallthe
termwhilestudyingwithsaidmnemonic(jittered). Giventhemulti-facetednatureofmnemonicef-
fectiveness,wedevelopaBayesianmodeltolearn
4.1 ArePreferenceTypesEquivalent?
effectivenessfromallpreferencesandtuneSMART
viaDirectPreferenceOptimization(Rafailovetal.,
Toseeifourpreferencelabelscaptureequivalent
2024)onthislearnedeffectivenesssignal(§5.2).
information,wecomputetheagreementofprefer-
ences(e.g. y vsy )forthesamemnemonics. 5.1 LearningMnemonicEffectiveness
pair rate
Weexcludelabelsdenotingatie,focusinginstead
Formnemonicpairs(m ,m ) ∈ D ,weseek
A B pref
onlabelsthatshowaclearpreferencetowardsone
tofindthemoreeffectivemnemonic. Weintuitthat
mnemonic. Table1showsthattheexpressedpref-
mnemoniceffectivenessisalatentvaluethatcanbe
erencesy andy havemoderateagreement
pair rate modeledviafeedbackfromallthreeofourprefer-
(0.675), aligning with Bansal et al. (2024), who
ences. Bayesianmodelsarewell-suitedforthistask
alsouncoverdisagreementinpairwiseandrating
astheycaptureannotatornoiseinfeedbackmore
preferences. Butnotably,theagreementbetween
effectivelythanaggregation(Wangetal.,2023a).
expressedandobservedpreferencesismuchlower
Thus,wedesignaHierarchicalBayesianmodel
(0.507 and 0.407), meaning that asking students
(Hoyleetal.,2019)toestimatemnemoniceffective-
whichmnemonicstheythinkaremorehelpfulcan-
ness. WeaimtolearnIP(θ > θ ),theprobability
A B
notcapturewhatistrulymorehelpfulforlearning.
mnemonic m is more effective than mnemonic
A
m . Todoso,weindividuallymodelmnemonics
4.2 CanUsersPredicttheirLearning? B
m andm bylatenteffectivenessparameters
A,i B,i
To study preference type disagreement at the stu-
θ andθ ,whichareassigneduniformpriors:
A,i B,i
dentlevel,weseeifauser’sratingofamnemonic
predictsthetotalturnsneededfortheusertolearn θ A,i,θ B,i ∼ Beta(1,1) (4)
thevocabtermlinkedtothatmnemonic. Ifusers
Weassumeθ andθ influenceobservedfeed-
A,i B,i
canpredictthiswell,wewouldseeastrongnega-
backinourthreepreferences: pairwisey ;rating
pair
tivecorrelation,withlowerratingsindicatingmore
y ;andlearningy ,whichweoutlinebelow.
rate learn
turnsneeded,butwefindlittle(r = −0.06)corre-
Forpairwisepreferences,letC = {c ,...,c }
i 1 n
lation (Figure 5). Prior work shows that students
bethepairwiseratingsof(m ,m ),wherec ∈
A,i B,i i
struggle to identify study strategies that best aid
{A,B,tie}. Ifθ > θ ,weassumethatC has
A,i B,i i
learning(McCabe,2011;Yanetal.,2016),andwe
moreAratings. TomodelC fromθ andθ ,we
i A,i B,i
uncover that students struggle to do the same for
firstcomputethesigmoid(σ)ofalineartransform
studyitems,furthershowcasingthatexpressedpref-
ofθ astheprobabilityppair = IP(A ∈ C ):
erencescannotfullycapturelearningoutcomes. A,i A,i i
α ,β ∼ Normal(0,1), (5)
pair pair
5 Traininga SMART-erMnemonicModel
ppair = σ(α ·θ +β ), (6)
A,i pair A,i pair
Ourgoalofcollectingstudentpreferencelabelsfor
mnemonicpairsistoidentify“better”ormoreeffec- andsameforppair . WethenmodelC asaBradley-
B,i i
tivemnemonics,usingthissignaltoguideSMART’s Terry model with ties (Davidson, 1970), where
llaceR
litnU
snoitaretIIP(tie ∈ C )dependsonauniformlatentvalueτ: vsθ from§5.1),andtheotherisy . Withthisdata,
i B l
weupdateourinitialmodelp (m|v)(π below)to
0 0
τ ∼ Beta(1,1), (7)
alignabetter SMART modelp dpo(m|v)(π below)
[ppair;ppair;τ] withDPO,whichminimizesthelossL dpo:
ppair = A,i B,i , (8)
i ppair +ppair +τ (cid:104) (cid:16) π(y |x) π(y|x) (cid:17)(cid:105)
A,i B,i L = −E lnσ βln w −βln l .
C
i
∼ Multinomial(n,pp iair). (9) dpo ∼x, Dyw pr, ey fl π 0(y w|x) π 0(y l|x)
(16)
Forratingpreferences,letR
A,i
= {r 1,...,r 5}be SMARTminimizesL
dpo
usingQLoRA(Dettmers
cumulativecountsofLikertratingsform ,where etal.,2024). AppendixB.1listsallparameters.
A,i
m hasr voteslessthanorequaltoratingj. We
A,i j
assumeanm withhighereffectivenessθ has
6 HowSmartAre SMART’sMnemonics?
A,i A,i
higher ratings. We model R as a multinomial
A,i Wenowassess SMART’smnemonicsfor500terms
distribution,parameterizedbyalineartransforma- V
test
⊂ V not used in D
train
or D pref. SMART
tionofθ toa5-lengthprobabilitydistribution:
A,i isalignedusingacombinationofthreepreference
metrics: pairwisecomparisons,Likertratings,and
α ,β ∼ Normal(0,1)5, (10)
rate rate learning. Duetospaceanddatalimits,wemainly
prate = σ(α ·θ +β ), (11)
A,i rate A,i rate evaluateviathemostpopularofthethreemetrics:
R ∼ Multinomial(ΣR ,prate), (12) pairwisecomparisons(Casperetal.,2023). Thus,
A,i A,i A,i
our evaluation reveals how using multiple prefer-
andsameforR B,i. Forlearningpreferences,let encelabels(MPLs)affectspairwiseoutputquality.
T A,i = {t 1,...,t m}beadistributionofturnsusers Weacknowledgethatanevaluationacrossallpref-
needtorecallthetermwithm A,i,wheret j ∈ Z+. erencemetricswouldbeinsightful(§9)andhope
Weassumeanm A,i withhighereffectivenessθ A,i futureworksextendthisdirectionwithourdatasets.
yieldslesst j needed. t j isthetriesuntilasuccess, Giventhecostsofhumanpairwiseevaluations,
so we model each t j as a Geometric distribution weadoptastandardpracticeofhavingGPT-4judge
parameterizedbyalineartransformationofθ A,i: whichoftwomodel-createdmnemonicsishigher
quality(Chiangetal.,2023;Liuetal.,2023). GPT-
α ,β ∼ Normal(0,1), (13)
learn learn 4shows80%agreementwithuserson200held-out
pl Ae ,a irn = σ(α learn·θ A,i+β learn), (14) mnemonicpairs(AppendixB.3),nearthe81%hu-
t ∼ Geometric(plearn), (15) managreementinMT-bench(Zhengetal.,2024),
j A,i
soGPT-4agreeswithuserpairwisemnemonicrat-
andsameforT . WelearnparametersviaNUTS ings. Tocurbpositionbias(Wangetal.,2023b),we
B,i
(Hoffmanetal.,2014)for1000epochs. Parameters comparemnemonicsinbothorders,onlymarking
convergeacrossfivechains(AppendixB.4),mean- that one model wins if GPT-4 picks the model’s
ingourmodelconsistentlyestimateseffectiveness. mnemonicinbothorders,otherwisemarkingatie.
WefirstuseGPT-4tocomparemnemonicqual-
5.2 AligningSMARTwithStudentPreferences
ityofSMARTversions(§6.1,§6.2). Wethenhave
Wenowusethelearnedeffectivenessofmnemon- mnemonicexpertsevaluate SMART’smnemonics
ics (m A,m B) in the preference dataset D
pref
to toinformfuturework(§6.3). Wealsopresentex-
alignSMART. Amongmanymethods,weadoptDi- amplesof SMART’smnemonicsinAppendixD.4.
rectPreferenceOptimization(Rafailovetal.,2024,
6.1 AblationStudy
DPO),whichoptimizesonpreferenceswithoutre-
wardmodelingorreinforcementlearning. Alterna- We ablate SMART (Figure 1) to verify each step
tiveslikeProximalPolicyOptimization(Schulman improvesmnemonicquality. Ourfine-tunedmodel
etal.,2017)needextensiveparametertuningand p (m|v)createshigher-qualitymnemonicsversus
0
arethushardertoreproduce(Huangetal.,2022b). few-shotLLaMAp (m|v)promptedusingthe10
fs
DPO requires dataset entries with a prompt x D exampleswiththehighestlatentquality(§2.2),
ft
andwinning/losingoutputsy /y ,wherey /y are andsameforp (m|v)versusp (m|v)(Table2).
w l w l dpo 0
“good”/“bad”outputsforx. Wesetxtothetermv Bothofthestepsimprovepairwisemnemonicqual-
inD withitsmnemonics(m ,m )asoutputs. ity,confirmingDPOcanalignLLMswithstudent
pref A B
y isthemnemonicwithhighereffectiveness(θ preferencestoenhanceLLMoutputsineducation.
w AModelA/BPair AWins Tie BWins
Smart/Transphoner Smart/GPT/Human Smart/GPT/Human
p 0(m|v), p fs(m|v) 0.76* 0.13 0.11 1.0 (Keyword Qual) 1.0 (Keyword Qual) 4(Explanation Qual)
p (m|v), p (m|v) 0.29* 0.53 0.18
dpo 0
0.8 0.8 3
Table2: GPTjudgementofourablations. Significantly
bettermodels(Binomial,p<0.005)areboldwith*.
0.6 0.6 2
ModelA/BPair AWins Tie BWins
0.4 0.4 1
P.S. Simplicity P.S. Simplicity Clarity Str. Image.
p (m|v), p (m|v) 0.19 0.60 0.21
bayes pair Smart Transphoner GPT-4 Human
p (m|v), p (m|v) 0.28* 0.54 0.18
dpo pair
Figure6: Expertqualitativeevaluationofmnemonics.
Table3: GPTjudgementofDPOmodels. Significantly
bettermodels(Binomial,p<0.005)areboldwith*.
oftencheaperthananotheruserstudytobreakties,
especiallyassomelabels(e.g. y )canbegath-
learn
6.2 DPOwithMultiplePreferenceLabels
eredwithoutexplicitannotations. Sucheffortscan
WestudytheeffectsofusingDPOwithMPLsfor helpresearchersstudycomplementaryalignment
pairwisemnemonicqualitythroughtwoquestions: objectives(§4)andevenboostLLMoutputquality.
Q1—DoMPLsharmpairwisemetrics? Onecon-
cernofusingMPLsforDPOisthatthemodelwill 6.3 QualitativeEvaluation
producelower-qualitymnemonicscomparedtoa Foradetailedevaluation,wehavetwomnemonic
modelusingpairwiselabels,asthelatteroptimizes researchersassessourmnemonics, splitintokey-
justontheevaluationmetric. Totestthis,wetake wordandexplanationquality. Forkeywordquality,
a subset of preference data D pair ⊂ D pref2 with weasktwoyes/noquestions: 1)Doesthekeyword
thepairwisepreferencey pair. WetraintwoDPO sound like the term? (Phonetic Similarity); 2) Is
modelsonD pair wheny pair ̸= tie: p bayes(m|v), thekeywordsimpler3 thantheterm? (Simplicity).
training on the Bayesian label y bayes from §5.1, Forexplanationquality,weratemnemonicexpla-
and p pair(m|v), training on y pair. Despite 20% nationsoutoffiveon: 1)Clarity: Easeofunder-
disagreement in y pair and y bayes on the winning standing;2)Strength: Theobviousnessoftheex-
mnemonic,themodelsarejudgedtogenerateequal- planation’sassociationofthekeywordandtheterm
quality mnemonics on V test (Table 3, top). Thus, (Halletal.,1981);3)Imageability: Theabilityto
DPOtrainingwithMPLsdoesnotalwaysdegrade evokementalimagery(Camposetal.,2011). Wear-
LLMoutputqualityonsingularpreferencemetrics. gueclarityandstrengtharemostimportantforex-
Q2—CanMPLsaugmentdata? IfwetrainDPO planationquality,ensuringstudentscanunderstand
with just y pair, we must omit data where y pair = andcreatestrongmemorylinksfromtermstokey-
tieornoy pair exists. Whilewecouldgainmore words. Weuseimageabilityasitcanaffectmemory
y pairlabelswithanotheruserstudy,weseeify bayes (Groninger,1971),butanimageableexplanationis
canresolvemissingortiedy
pair
labelsusingother stillunmemorableifunclearorlowstrength.4
preferencestoelectwinningmnemonics,augment- Weassessmnemonickeywordandexplanation
ingdatawithoutmorepairwiselabels. Wecompare qualityfor50V termscreatedbyaprofessional
test
p pair(m|v),whichtrainson348y pair labels,toour writerfromUpwork,10-shotGPT-4,andSMART
full model p dpo(m|v), which trains on 117 extra (p dpo(m|v)). WealsocompareSMART’skeyword
pairs when y bayes breaks a tie in y pair and 12 ex- qualitytoTransphoner(Savvaetal.,2014),aSOTA
trapairswithnoy pair label. p dpo(m|v)generates mnemonickeywordextractor. Transphonerishard
significantly better (p < 0.005) mnemonics than toreproduce,soweuse50termsandTransphoner
p pair(m|v)(Table3,bottom),meaningthatMPLs outputsreleasedbytheauthorsforthiscomparison.
can effectively augment DPO training data over KeywordQuality: SMARThasslightlybetterkey-
pairwisepreferencesforLLMoutputqualitygains. wordsthanTransphoner(highersimplicity,equal
Takeaway: Since optimizing on y bayes matches PS),meaningLLMsarestrongalternativesforkey-
y pair in non-ties and improves output quality by word extractors (Figure 6, left). SMART also has
resolvingtiesandmissingy pair labels,weadvise muchsimplerkeywordsthanGPT-4,butwithlower
collectingMPLsifresourcesallow. Thisisfeasible PS(Figure6,middle). Suvarnaetal.(2024)findsa
asMPLscanbecollectedinasingleapp,whichis
3Akeywordissimplerifausernotknowingthetermcould
2Tohaveenoughlabeldisagreement,D inthisanalysis likelyknowthekeyword(torporisnotsimplerthantorpid).
pref
alsoaddsmnemonicswithtwolabels(seeAppendixA.3). 4Forexample,BenFranklinforbenevolentinFigure1.largegap(37%accuracy)whenpromptingLLaMA- tuningandpreferencedatasetstotrainamnemonic
2andGPT-4forrhymegenerationwhichalsotests generatorguidedbyreal-worldstudentfeedback.
PS;ourgapisjust8%,sofine-tuninganduserfeed- HumanPreferences: RecentworksalignLLMs
backhelpLLMsaddressphoneticweaknesses. Our withpreferencedata,whichcapturewhathumans
writerbestsbothmodelsinkeywordquality,with prefer(Stiennonetal.,2020). Alignmentmethods
largesimplicitygaps. Thus,modelsthatsimplify includereinforcementlearningwithrewardmodels
textwithLLMs(summarizers,topicmodels)may (Christiano et al., 2017; Ziegler et al., 2019), se-
benefitfromexplicitfeedbackonwordsimplicity. lectinghigh-qualitydata(Sanhetal.,2022;Zhou
ExplanationQuality: SMARTmatchestheexpla- etal.,2024),andaugmentingLMlosswithreward
nations of GPT-4 (lower clarity, higher strength), models (Yuan et al., 2023; Rafailov et al., 2024).
meaningstudentfeedbackenablessmallerLLMs Preferenceshavebeenusedinsentimentgeneration
like SMART to compete with SOTA LLMs (Fig- (Maasetal.,2011),summarization(Völskeetal.,
ure6, right). Ourwriteragainhasthebestexpla- 2017), and dialogue safety (Bai et al., 2022), but
nations,especiallyinimageabilityoverSMART,as wearethefirsttostudypreferencesinmnemonics.
SMARTisnotguidedtowardimageablemnemon- Ourworkalsofollowsrecenteffortstomeasure
ics. Imageabilitydoesnotentailmemorability,but issuesinpreferences,suchaspreferenceagreement
itmaybeusefulfortasksinmemorability(story- (EthayarajhandJurafsky,2022;Bansaletal.,2024)
telling,advertising)touseimageabilityfeedback, andannotatorbiases(Pengetal.,2022;Wanetal.,
asevenGPT-4showsaweaknessinimageability. 2023). In contrast, we discern expressed and ob-
Takeaway: TrainingLLMswithstudentfeedback servedpreferencesandshowexpressedpreferences
resultsinmnemonicswithkeywordqualitymatch- donotcapturewhattrulyhelpsusers. Wearealso
ing SOTA extractive methods while also generat- similartoworksusingdiversehumanpreferences
ingexplanations. Italsoallows SMART,asmaller (Xueetal.,2023;Kirketal.,2024),whichweex-
LLM,tocompetewithGPT-4,sousingsuchfeed- ploreviaBayesianmodeling(Yangetal.,2024).
backwithGPT-4couldyieldevenbettermnemon-
ics. Lastly,ourexpertwritesbettermnemonicsthan 8 Conclusion
LLMs,specificallyinkeywordsimplicityandim-
ageability. Thismotivatesmnemonicgenerationas
We design SMART, the first keyword mnemonic
achallengingtaskandgivesinsightsintofeedback
generatorguidedbystudentfeedback. SMART is
trainedonnewfine-tuningandpreferencedatasets
thatcouldbeusedtoguideLLMsinsimilartasks.
whichwillbothbereleased. Whilecuratingdata,
we find low agreement in expressed preferences
7 RelatedWork
andourintroducedobservedpreferences,showing
MnemonicGeneration: Mnemonicdeviceshelp thatstudentscannotpredicttheirlearning. Combin-
userslearninformation,suchaspasswords(Yang ingexpressedandobservedpreferencesviaDPO
etal.,2016;Songetal.,2019),vocabulary(Dundes, andBayesianmodelingyieldsasmaller,moreeffi-
1961;Levinetal.,1992),andmedicalfacts(Ajayi cientmnemonicmodelmatchingGPT-4. However,
etal.,2019;Leedsetal.,2020). Thereareseveral ourhumanwritersurpassesbothmodels,especially
typesofmnemonics,includingsong(Hayes,2009; inkeywordsimplicityandexplanationquality,mo-
Werner,2018),acronym(McCabeetal.,2013;Li tivatingmnemonicgenerationasadifficulttask.
et al., 2021), and keyword mnemonics (Campos Whileexpressedpreferencesarecurrentlyused
etal.,2004,2011). Westudykeywordmnemonics, foralignment,theydonotmeasurewhattrulyhelps
whichlinkcomplextermstosimplerkeywords. users. Thus,thereisaneedformoreworkincaptur-
Theeffortofmanuallywritingmnemonicshas ingobservedpreferencesandusergoals. Ensuring
ledtomnemonicgenerationresearch. Earlyworks LLMspursuesuchgoalssafelyrequiresalignment
usephoneticsimilarityandmulti-scorerankingto methodstosteerLLMstowardbothexpressedand
findkeywords(Savvaetal.,2014;Anonthanasap observedpreferences,andwedesignamethodto
andLeelanupab,2015;Anonthanasapetal.,2015), combinethem; ourmethodalsoresolvestiesand
butthesemethodsdonotexplainhowthekeyword missinglabelstoaugmentdatasets. Wehopeour
islinkedtothefact. RecentworkspromptLLMs studyofthedisagreementsandbenefitsofdiverse
toproducetheseexplanations(LeeandLan,2023; mnemonic preferences will motivate future work
WongandWolf,2024). Conversely,wecollectfine- insafelyaligningLLMoutputstotrueuserneeds.9 Limitations viseresearcherstotakecautionfordeployingsuch
modelsinawaythatimpactsusers. Wefoundthat
One limitation is that our fine-tuning and prefer-
evenourrelativelyharmlessobjectiveofoptimiz-
encedatasetsarerelativelysmall. Despitethis,our
ingonlearningcanresultinbizarremnemonicsthat
datasets both improve the quality of mnemonics
perpetuateharms(AppendixD.1),andweimagine
fromSMART(§6.1),followingtherecentparadigm
that in other domains, these consequences could
of LIMA (Zhou et al., 2024) which suggests that
bemoresevere. Forexample,traininganLLMin
small, high-quality datasets can be used to align
thenewsdomainoptimizedonuserclickscanre-
and improve LLMs. Further, regardless of size,
sultinmisinformation(Milanoetal.,2020),while
ourpreferencedatasetallowsustoconductanin-
optimizing directly on time spent looking at an
sightfulanalysisontherelationbetweenexpressed
advertisementcanyieldharmful,addictivecontent.
andobservedpreferences(§4). Asmorestudents
Wetookprecautionstoavoidtheseharms,such
study in our app, we will update and release our
as filtering out offensive mnemonics before fine-
preferencedatasetsaccordingly,resultinginmore
tuning (§2.3), and our protocols were approved
datatofacilitatemnemonicresearch.
by an Institutional Review Board to mitigate any
WealsonotethatusingGPT-4asajudgecanre-
harms in our user study. Thus, while we advo-
sultinbiases. OurdecisiontouseGPT-4wasmoti-
cateforresearchinobservedpreferencesforLLM
vatedbythehighcostofhumanannotations,which
alignment, we also urge researchers to consider
hasalsobecomeastandardpractice(Chiangetal.,
theconsequencesofoptimizingontheseobjectives
2023;Liuetal.,2023;Touvronetal.,2023;Chiang
beforedeploymentinuser-facingapplications.
andLee,2023;Dettmersetal.,2023). Whileusing
GPT-4,weadoptseveralbestpracticesforrobust
11 Acknowledgements
evaluation: 1)onlyevaluatingonSMARTtoavoid
self-recognition(Panicksseryetal.,2024);2)using WewouldliketothankmembersoftheCLIPlab
DSPy to help limit the sensitivity of prompt per- attheUniversityofMarylandandexternalcollabo-
turbations(Khattabetal.,2024);3)ensuringGPT- ratorsfortheirdiscussionsofthiswork,including
4 has high agreement with humans on held-out DavidMartinez,NainaBalepur,SandraSandoval,
mnemoniccomparisons(Zhengetal.,2024);and4) Yoo Yeon Sung, and Rachel Rudinger. We also
runninginferenceonbothordersofthemnemonic thankGregMat,GMATClub,andMemliAppfor
pairstocurbpositionalbiases(Wangetal.,2023b). theirfeedbackonouruserstudydesignandallow-
Lastly, our final model for SMART optimizes ingustousetheireducationalmaterialsinourre-
on a combination of multiple preference labels: search. Thismaterialisbaseduponworksupported
pairwisecomparisons,Likertratings,andlearning. bytheNationalScienceFoundationGraduateRe-
WhiletrainingandevaluatingDPOmodelsonall searchFellowshipProgramunderGrantNo. DGE
threeobjectivesindependentlywouldbeinsightful, 2236417. Anyopinions,findings,andconclusions
wearelimitedbyourdata. Thus,wefocusonthe orrecommendationsexpressedinthismaterialare
mostpopularofthethree—pairwisepreferences— thoseoftheauthor(s)anddonotnecessarilyreflect
and our evaluation reveals how optimizing with theviewsoftheNationalScienceFoundation.
multiplepreferencelabelscanimpactmetricsbased
onjustonepreferencelabel. Weencouragefuture
works to use our preference data to explore how References
optimizingonmultiplepreferencesimpactsmetrics
ToluwalaseAAjayi,DavidShaw,andKylePEdmonds.
based on each type of preference. To further mo-
2019. Feasibilityandeffectivenessofamnemonic
tivateworksinthisdirection,wehavemnemonic approach to teach residents how to assess goals of
experts evaluate SMART’s mnemonics to inform care. JournalofPalliativeMedicine,22(6):696–701.
whichtypesoffeedback(e.g. keywordsimplicity,
ReimaAl-Jarf.2016. HowIstudiedfortheGREtest.
explanation imageability) could be collected and
trainedwithtoimprovemnemonics(§6.3).
OrapinAnonthanasap,MontichaKetna,andTeerapong
Leelanupab. 2015. Automated english mnemonic
10 EthicalConsiderations
keyword suggestion for learning japanese vocabu-
lary. In 2015 7th International Conference on In-
Whileoptimizingdirectlyonobservedpreferences
formation Technology and Electrical Engineering
fordownstreamapplicationsispromising,wead- (ICITEE),pages638–643.OrapinAnonthanasapandTeerapongLeelanupab.2015. 2023. Vicuna: Anopen-sourcechatbotimpressing
Imnem: Interactivemnemonicwordsuggestionus- gpt-4with90%*chatgptquality. Seehttps://vicuna.
ingphoneticalgorithms. InProceedingsofthe20th lmsys.org(accessed14April2023),2(3):6.
InternationalSocietyonArtificialLifeandRobotics,
ser.AROB’15,pages316–321. PaulFChristiano,JanLeike,TomBrown,MiljanMar-
tic, Shane Legg, and Dario Amodei. 2017. Deep
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda reinforcementlearningfromhumanpreferences. Ad-
Askell, AnnaChen, NovaDasSarma, DawnDrain, vancesinneuralinformationprocessingsystems,30.
StanislavFort,DeepGanguli,TomHenighan,etal.
2022. Trainingahelpfulandharmlessassistantwith Roger R Davidson. 1970. On extending the bradley-
reinforcementlearningfromhumanfeedback. arXiv terrymodeltoaccommodatetiesinpairedcompari-
preprintarXiv:2204.05862. sonexperiments. JournaloftheAmericanStatistical
Association,65(329):317–328.
Hritik Bansal, John Dang, and Aditya Grover. 2024.
Peering through preferences: Unraveling feedback
ErnestDavis.2023. Benchmarksforautomatedcom-
acquisition for aligning large language models. In
monsense reasoning: A survey. ACM Computing
The Twelfth International Conference on Learning
Surveys,56(4):1–41.
Representations.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
CindyBengeandMERobbins.2009. Usingkeyword
LukeZettlemoyer.2023. Qlora: Efficientfinetuning
mnemonicstodevelopsecondarystudents’vocabular-
ofquantizedllms. arXivpreprintarXiv:2305.14314.
ies:Ateacher’sactionresearch. JournalofLanguage
andLiteracyEducation,6(1):93–104.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
SándorBozóki,LindaDezso˝,AttilaPoesz,andJózsef LukeZettlemoyer.2024. Qlora: Efficientfinetuning
Temesi.2013. Analysisofpairwisecomparisonma- ofquantizedllms. AdvancesinNeuralInformation
trices: anempiricalresearch. AnnalsofOperations ProcessingSystems,36.
Research,211:511–528.
AlanDundes.1961. mnemonicdevices. MidwestFolk-
Alfredo Campos, Angeles Amor, and María Angeles lore,11(3):139–147.
González. 2004. The importance of the keyword-
generationmethodinkeywordmnemonics. Experi- KawinEthayarajhandDanJurafsky.2022. Theauthen-
mentalpsychology,51(2):125–131. ticity gap in human evaluation. In Proceedings of
the2022ConferenceonEmpiricalMethodsinNat-
Alfredo Campos, Estefanía Camino, and María José uralLanguageProcessing,pages6056–6070,Abu
Pérez-Fabello.2011. Usingthekeywordmnemonics Dhabi,UnitedArabEmirates.AssociationforCom-
methodamongadultlearners. EducationalGerontol- putationalLinguistics.
ogy,37(4):327–335.
Marilyn M Fairbanks. 1977. Vocabulary instruction
Stephen Casper, Xander Davies, Claudia Shi,
at the college/adult levels: A research review. In
Thomas Krendl Gilbert, Jérémy Scheurer, Javier
ProceedingsoftheAnnualConferenceoftheWestern
Rando, Rachel Freedman, Tomasz Korbak, David
CollegeReadingAssociation,volume10,pages19–
Lindner, Pedro Freire, Tony Tong Wang, Samuel
29.Taylor&Francis.
Marks, Charbel-Raphael Segerie, Micah Carroll,
Andi Peng, Phillip Christoffersen, Mehul Damani,
AndrewGelmanandJenniferHill.2006. Dataanalysis
Stewart Slocum, Usman Anwar, Anand Siththa-
usingregressionandmultilevel/hierarchicalmodels.
ranjan, Max Nadeau, Eric J Michaud, Jacob Pfau,
Cambridgeuniversitypress.
DmitriiKrasheninnikov,XinChen,LauroLangosco,
Peter Hase, Erdem Biyik, Anca Dragan, David
Lowell D Groninger. 1971. Mnemonic imagery and
Krueger,DorsaSadigh,andDylanHadfield-Menell.
forgetting. PsychonomicScience,23(2):161–163.
2023. Openproblemsandfundamentallimitations
of reinforcement learning from human feedback.
James W Hall, Kim P Wilson, and Richard J Patter-
TransactionsonMachineLearningResearch. Survey
son.1981. Mnemotechnics: Somelimitationsofthe
Certification.
mnemonickeywordmethodforthestudyofforeign
Cheng-HanChiangandHung-yiLee.2023. Canlarge language vocabulary. Journal of Educational Psy-
languagemodelsbeanalternativetohumanevalua-
chology,73(3):345.
tions? InProceedingsofthe61stAnnualMeetingof
theAssociationforComputationalLinguistics(Vol- SpencerEHarpe.2015. Howtoanalyzelikertandother
ume1: LongPapers),pages15607–15631,Toronto, ratingscaledata. Currentsinpharmacyteachingand
Canada.AssociationforComputationalLinguistics. learning,7(6):836–850.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, OrlaCHayes.2009. Theuseofmelodicandrhythmic
ZhanghaoWu,HaoZhang,LianminZheng,Siyuan mnemonicstoimprovememoryandrecallinelemen-
Zhuang,YonghaoZhuang,JosephEGonzalez,etal. tarystudentsinthecontentareas. OnlineSubmission.JanineChristinHoffart,SebastianOlschewski,andJörg Neal EA Kroll and Shi-Fen Tu. 1988. The bizarre
Rieskamp. 2019. Reaching for the star ratings: A mnemonic. PsychologicalResearch,50(1):28–37.
bayesian-inspired account of how people use con-
sumer ratings. Journal of Economic Psychology, JaewookLeeandAndrewLan.2023. Smartphone: Ex-
72:99–116. ploringkeywordmnemonicwithauto-generatedver-
bal and visual cues. In International Conference
MatthewDHoffman,AndrewGelman,etal.2014. The onArtificialIntelligenceinEducation,pages16–27.
no-u-turn sampler: adaptively setting path lengths Springer.
in hamiltonian monte carlo. J. Mach. Learn. Res.,
15(1):1593–1623. FStuartLeeds,KareemMAtwa,AlexanderMCook,
Katharine A Conway, and Timothy N Crawford.
Alexander Miserlis Hoyle, Lawrence Wolf-Sonkin, 2020. Teaching heuristics and mnemonics to im-
HannaWallach,RyanCotterell,andIsabelleAugen- provegenerationofdifferentialdiagnoses. Medical
stein. 2019. Combining Sentiment Lexica with a educationonline,25(1):1742967.
Multi-View Variational Autoencoder. In Proceed-
ingsofthe2019ConferenceoftheNorthAmerican JoelRLevin,MaryELevin,LynetteDGlasman,and
Chapter of the Association for Computational Lin- MargaretBNordwall.1992. Mnemonicvocabulary
guistics: Human Language Technologies, Volume instruction: Additionaleffectivenessevidence. Con-
1 (Long and Short Papers), pages 635–640, Min- temporaryEducationalPsychology,17(2):156–174.
neapolis,Minnesota.AssociationforComputational
Linguistics. BinLi,FeiXia,YixuanWeng,XiushengHuang,Bin
Sun, and Shutao Li. 2021. Psg: prompt-based se-
JieHuang,HanyinShao,KevinChen-ChuanChang,Jin- quence generation for acronym extraction. In The
junXiong,andWen-meiHwu.2022a. Understand- AAAI-22 Workshop on Scientific Document Under-
ingjargon: Combiningextractionandgenerationfor standing.
definitionmodeling. InProceedingsofthe2022Con-
ferenceonEmpiricalMethodsinNaturalLanguage Chin-YewLin.2004. Rouge: Apackageforautomatic
Processing, pages 3994–4004, Abu Dhabi, United evaluation of summaries. In Text summarization
ArabEmirates.AssociationforComputationalLin- branchesout,pages74–81.
guistics.
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang,
Shengyi Huang, Rousslan Fernand Julien Dossa, Ruochen Xu, and Chenguang Zhu. 2023. G-eval:
Antonin Raffin, Anssi Kanervisto, and Weixun NLGevaluationusinggpt-4withbetterhumanalign-
Wang. 2022b. The 37 implementation details of ment. In Proceedings of the 2023 Conference on
proximalpolicyoptimization. InICLRBlogTrack. EmpiricalMethodsinNaturalLanguageProcessing,
Https://iclr-blog-track.github.io/2022/03/25/ppo- pages2511–2522,Singapore.AssociationforCom-
implementation-details/. putationalLinguistics.
Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Zhang,CeBian,BoyuanChen,RuiyangSun,Yizhou DanHuang, AndrewY.Ng, andChristopherPotts.
Wang, and Yaodong Yang. 2024. Beavertails: To- 2011. Learningwordvectorsforsentimentanalysis.
wardsimprovedsafetyalignmentofllmviaahuman- In Proceedings of the 49th Annual Meeting of the
preferencedataset. AdvancesinNeuralInformation AssociationforComputationalLinguistics: Human
ProcessingSystems,36. Language Technologies, pages 142–150, Portland,
Oregon, USA. Association for Computational Lin-
Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, guistics.
Zhiyuan Zhang, Keshav Santhanam, Sri Vard-
hamananA,SaifulHaq,AshutoshSharma,ThomasT. Jennifer McCabe. 2011. Metacognitive awareness of
Joshi, Hanna Moazam, Heather Miller, Matei Za- learning strategies in undergraduates. Memory &
haria, and Christopher Potts. 2024. DSPy: Com- cognition,39:462–476.
piling declarative language model calls into state-
of-the-art pipelines. In The Twelfth International JenniferAMcCabe,KelseyLOsha,JenniferARoche,
ConferenceonLearningRepresentations. andJonathanASusser.2013. Psychologystudents’
knowledgeanduseofmnemonics. Teachingofpsy-
HannahRoseKirk,AlexanderWhitefield,PaulRöttger, chology,40(3):183–192.
AndrewBean,KaterinaMargatina,JuanCiro,Rafael
Mosquera, Max Bartolo, Adina Williams, He He, MarkAMcDanielandMichaelPressley.1984. Putting
etal.2024. Theprismalignmentproject: Whatpar- thekeywordmethodincontext. JournalofEduca-
ticipatory,representativeandindividualisedhuman tionalPsychology,76(4):598.
feedbackrevealsaboutthesubjectiveandmulticul-
tural alignment of large language models. arXiv Memliapp.2007. Mnemonicdictionary. Online.
preprintarXiv:2404.16019.
Silvia Milano, Mariarosaria Taddeo, and Luciano
VinceKotchian.2019. Vince’sGREVocabCompilation Floridi.2020. Recommendersystemsandtheirethi-
andCuration. Online. calchallenges. Ai&Society,35:957–967.ReiichiroNakano,JacobHilton,SuchirBalaji,JeffWu, ThomasWolf,andAlexanderMRush.2022. Multi-
Long Ouyang, Christina Kim, Christopher Hesse, taskpromptedtrainingenableszero-shottaskgener-
ShantanuJain,VineetKosaraju,WilliamSaunders, alization. InInternationalConferenceonLearning
et al. 2021. Webgpt: Browser-assisted question- Representations.
answering with human feedback. arXiv preprint
arXiv:2112.09332. ManolisSavva, AngelXChang, ChristopherDMan-
ning,andPatHanrahan.2014. Transphoner: Auto-
NihalV.Nayak,TanmayChinchore,AishwaryaHanu- matedmnemonickeywordgeneration. InProceed-
manth Rao, Shane Michael Martin, Sagar Nagaraj ingsoftheSIGCHIConferenceonHumanFactorsin
Simha,G.M.Lingaraju,andH.S.Jamadagni.2017. ComputingSystems,pages3725–3734.
Vforvocab: AnintelligentFlashcardapplication. In
ProceedingsofACL2017, StudentResearchWork- JohnSchulman,FilipWolski,PrafullaDhariwal,Alec
shop,pages24–29,Vancouver,Canada.Association Radford,andOlegKlimov.2017. Proximalpolicy
forComputationalLinguistics. optimizationalgorithms. ArXiv,abs/1707.06347.
ArjunPanickssery,SamuelRBowman,andShiFeng.
MatthewShu,NishantBalepur,ShiFeng,andJordan
2024. Llmevaluatorsrecognizeandfavortheirown
Boyd-Graber. 2024. Karl: Knowledge-aware re-
generations. arXivpreprintarXiv:2404.13076.
trievalandrepresentationsaidretentionandlearning
instudents. arXivpreprintarXiv:2402.12291.
AndiPeng,BesmiraNushi,EmreKiciman,KoriInkpen,
andEceKamar.2022. Investigationsofperformance
VanleeSiriganjanavong.2013. Themnemonickeyword
andbiasinhuman-aiteamworkinhiring. InProceed-
method: Effectsonthevocabularyacquisitionand
ingsoftheAAAIConferenceonArtificialIntelligence,
retention. EnglishLanguageTeaching,6(10):1–10.
volume36,pages12089–12097.
JianhuaSong,DegangWang,ZhongyueYun,andXiao
Zhongling Pi, Fangfang Zhu, Yi Zhang, and Ji-
Han. 2019. Alphapwd: A password generation
umin Yang. 2021. An instructor’s beat ges-
strategy based on mnemonic shape. IEEE Access,
tures facilitate second language vocabulary learn-
7:119052–119059.
ingfrominstructionalvideos: Behavioralandneu-
ral evidence. Language Teaching Research, page
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
13621688211039023.
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
DarioAmodei,andPaulFChristiano.2020. Learn-
DerekPowell,JingqiYu,MelissaDeWolf,andKeithJ.
ing to summarize with human feedback. In Ad-
Holyoak.2017. Theloveoflargenumbers: Apop-
vances in Neural Information Processing Systems,
ularitybiasinconsumerchoice. PsychologicalSci-
volume 33, pages 3008–3021. Curran Associates,
ence,28(10):1432–1442. PMID:28825874.
Inc.
MichaelPressley,JoelRLevin,andHaroldDDelaney.
Ashima Suvarna, Harshita Khandelwal, and Nanyun
1982. Themnemonickeywordmethod. Reviewof
Peng.2024. Phonologybench: Evaluatingphonolog-
EducationalResearch,52(1):61–91.
icalskillsoflargelanguagemodels. arXivpreprint
arXiv:2404.02456.
RafaelRafailov,ArchitSharma,EricMitchell,Christo-
pherDManning,StefanoErmon,andChelseaFinn.
2024. Directpreferenceoptimization:Yourlanguage YufeiTian, AbhilashaRavichander, LianhuiQin, Ro-
modelissecretlyarewardmodel. AdvancesinNeu- nanLeBras,RajaMarjieh,NanyunPeng,YejinChoi,
ralInformationProcessingSystems,36. ThomasLGriffiths,andFaezeBrahman.2023. Mac-
gyver: Arelargelanguagemodelscreativeproblem
Michael R Raugh and Richard C Atkinson. 1975. A solvers? arXivpreprintarXiv:2311.09682.
mnemonic method for learning a second-language
vocabulary. Journal of Educational Psychology, Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
67(1):1. bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Victor Sanh, Albert Webson, Colin Raffel, Stephen Bhosale, et al. 2023. Llama 2: Open founda-
Bach, Lintang Sutawika, Zaid Alyafeai, Antoine tion and fine-tuned chat models. arXiv preprint
Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, arXiv:2307.09288.
M Saiful Bari, Canwen Xu, Urmish Thakker,
ShanyaSharmaSharma,ElizaSzczechla,Taewoon KathleenTuite,TimothyPavlik,SandraB.Fan,Tyler
Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Robison,AlexanderJaffe,Yun-EnLiu,ErikAnder-
Datta,JonathanChang,MikeTian-JianJiang,Han sen,andStevenTanimoto.2012. Picard: acreative
Wang,MatteoManica,ShengShen,ZhengXinYong, and social online flashcard learning game. In Pro-
HarshitPandey,RachelBawden,ThomasWang,Tr- ceedingsoftheInternationalConferenceontheFoun-
ishala Neeraj, Jos Rozen, Abheesht Sharma, An- dationsofDigitalGames,FDG’12,page231–234,
dreaSantilli,ThibaultFevry,JasonAlanFries,Ryan New York, NY, USA. Association for Computing
Teehan,TevenLeScao,StellaBiderman,LeoGao, Machinery.Michael Völske, Martin Potthast, Shahbaz Syed, and SIGSAC conference on computer and communica-
BennoStein.2017. TL;DR:MiningReddittolearn tionssecurity,pages1216–1229.
automatic summarization. In Proceedings of the
WorkshoponNewFrontiersinSummarization,pages Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Wei Wang,
59–63,Copenhagen,Denmark.AssociationforCom- SongfangHuang,andFeiHuang.2023. RRHF:Rank
putationalLinguistics. responsestoalignlanguagemodelswithhumanfeed-
back. InThirty-seventhConferenceonNeuralInfor-
Alexander Wan, Eric Wallace, Sheng Shen, and Dan mationProcessingSystems.
Klein.2023. Poisoninglanguagemodelsduringin-
structiontuning. InInternationalConferenceonMa- LianminZheng,Wei-LinChiang,YingSheng,Siyuan
chineLearning,pages35413–35425.PMLR. Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.
AlvinYWang,MargaretHThomas,andJudithAOuel- Judging llm-as-a-judge with mt-bench and chatbot
lette. 1992. Keyword mnemonic and retention of arena. AdvancesinNeuralInformationProcessing
second-languagevocabularywords. JournalofEdu- Systems,36.
cationalPsychology,84(4):520.
ChuntingZhou,PengfeiLiu,PuxinXu,SrinivasanIyer,
JiashuoWang,HaozhaoWang,ShichaoSun,andWen- JiaoSun,YuningMao,XuezheMa,AviaEfrat,Ping
jie Li. 2023a. Aligning language models with hu- Yu,LiliYu,etal.2024. Lima: Lessismoreforalign-
manpreferencesviaabayesianapproach. InThirty- ment. AdvancesinNeuralInformationProcessing
seventhConferenceonNeuralInformationProcess- Systems,36.
ingSystems.
DanielMZiegler,NisanStiennon,JeffreyWu,TomB
PeiyiWang,LeiLi,LiangChen,DaweiZhu,Binghuai Brown, Alec Radford, Dario Amodei, Paul Chris-
Lin,YunboCao,QiLiu,TianyuLiu,andZhifangSui. tiano, and Geoffrey Irving. 2019. Fine-tuning lan-
2023b. Largelanguagemodelsarenotfairevaluators. guage models from human preferences. arXiv
arXivpreprintarXiv:2305.17926. preprintarXiv:1909.08593.
Riah Werner. 2018. Music, movement and memory:
Pedagogicalsongsasmnemonicaids. TESOLJour-
nal,9(4):1–11.
Keith A Wollen and Matthew G Margres. 1987.
Bizarrenessandtheimagerymultiprocessmodel. In
Imageryandrelatedmnemonicprocesses: Theories,
individualdifferences,andapplications,pages103–
127.Springer.
Heidi Wong and Elissa Wolf. 2024. Large language
model(llm)generatedpersonalizedmnemonics.
MengzhouXia,SadhikaMalladi,SuchinGururangan,
SanjeevArora,andDanqiChen.2024. LESS:Select-
inginfluentialdatafortargetedinstructiontuning. In
ICLR2024WorkshoponNavigatingandAddressing
DataProblemsforFoundationModels.
WanqiXue,BoAn,ShuichengYan,andZhongwenXu.
2023. Reinforcementlearningfromdiversehuman
preferences. arXivpreprintarXiv:2301.11774.
VeronicaXYan,ElizabethLigonBjork,andRobertA
Bjork.2016. Onthedifficultyofmendingmetacog-
nitiveillusions:Aprioritheories,fluencyeffects,and
misattributionsoftheinterleavingbenefit. Journalof
ExperimentalPsychology: General,145(7):918.
AdamXYang,MaximeRobeyns,ThomasCoste,Jun
Wang,HaithamBou-Ammar,andLaurenceAitchi-
son. 2024. Bayesian reward models for llm align-
ment. arXivpreprintarXiv:2402.13210.
WeiningYang,NinghuiLi,OmarChowdhury,Aiping
Xiong,andRobertWProctor.2016. Anempirical
studyofmnemonicsentence-basedpasswordgener-
ation strategies. In Proceedings of the 2016 ACMA DatasetDetails GRE vocabulary words and mnemonics from
MnemonicDictionary, and both were used as in-
A.1 CleaningNoisyMnemonics
tendedbytheoriginalauthors. Noneofourdatasets
Warning: Thissubsectioncontainsanexample containpersonalinformation,asusersarereferred
ofanoffensivemnemonic. tojustbyID.AllcollectedmnemonicsareinEn-
We use Bayesian modeling to obtain a high- glish.
qualitysubsetofstudent-submittedmnemonicson
MnemonicDictionaryforfine-tuning(§2.2),butwe A.3 ExperimentDatasetSplits
stillfindgrammarmistakesinthemnemonics,and When conducting the analysis of human prefer-
some of the mnemonics can be considered offen- encesandtrainingmostDPOmodels,wefilterall
siveortooculturallyspecific. Tofixthegrammar mnemonicpairswithlessthantwohumanprefer-
issues, we ask GPT-4 (web interface) to “Fix the enceannotationstoformD . Forthepairwise
pref
spellingandgrammarmistakesinthesemnemon- preferences,thismeansthatwefilteredmnemonics
ics [paste 50 mnemonic devices]”. This converts wherethesumofvotesforAandBwaslessthan
mnemonics like “when two gender’s male & fe- orequaltotwo. However,forthecomparisonbe-
male end up together .. they produce or give rise tweenp (m|v)andp (m|v)in§6.2,wealso
bayes pair
toaCHILD..” tothemorestructuredform“When usemnemonicpairswithexactlytwovotes. Wedid
twogenders,maleandfemale,cometogether,they this because otherwise, the Bayesian label y
bayes
produceorgiverisetoachild.” andpairwiselabely hadveryhighagreement
pair
We also manually remove the 111 mnemonics inwhichmnemonicinthepairwaswinning,sowe
we thought could be harmful to users or less un- wouldnotbeabletomeaningfullystudythediffer-
derstoodduetobeingtoospecifictobeingrelated encesbetweenoptimizingonjustpairwiseormul-
to a certain culture. For example, we consider tiplepreferences. Essentially,ourfilteringstrategy
themnemonic: Spurnsoundslike’s+porn.’ The removedtheannotatornoiseinthepairwisepref-
mnemonicimpliesdisdainfulrejectionofinappro- erences,sotheclearpairwisepreferencetowards
priate content. offensive, while the mnemonic: one mnemoniccaused y to nearlyalways be
bayes
Glower can be associated with Gulshan Grover, inagreementwithy . However,byaddingback
pair
imagining him glaring angrily at the hero is too noisyannotations,wewereabletobetterstudythe
culturallyspecific. Infutureworksonmnemonic differencesbetweeny andy ,asthesetwo
bayes pair
generation,itcouldbeinterestingtopersonalizethe labelsendedupwith20%disagreement.
generatedmnemonicsthroughaspectslikeculture.
B ModelandExperimentDetails
A.2 D andD DatasetDetails
ft pref
B.1 TrainingSetup
InTables4and6, weprovidedescriptionsofthe
Allofourmodelsaretrainedforamaximumof24
columnsinD andD ,respectively. ForD ,
ft pref pref
hoursusingeightNVIDIARTX:A5000GPUs. In
wefilterouttermsandmnemonicswithlessthan
practice, wefindthatbothfine-tuningandDirect
two annotations, resulting in the summary statis-
PreferenceOptimization(DPO)convergeinaround
ticsdescribedin§3.3,andsummarizedinTable5.
6hours. Parametersweremanuallyselected. Fine-
Alongwiththefilteredsubset,wewillreleasethe
tuningandDPOwerebothimplementedusingthe
entiredatasetofhumanpreferences. Wewillalso
trl library5 using a 90/10 train/evaluation split
continuetoreleasedataasusersstudyvocabulary
ontheirrespectivedatasets. Bothfine-tuningand
withmnemonicsinourapp. Thelistof500vocab
DPOuseQLoRAwithLLaMA-2(70B)with8-bit
termsV usedfortestingwillalsobereleased.
test
quantization, α = 32, a dropout of 0.05, a bias
Finally,inTable7,wequantifythenoiseofan-
of 0, and update the default attention query and
notatorratingsinD . Weuseaverageentropy
pref
valueprojectionlayers. Weuse5trainingepochs
andvarianceaseachinstanceinourdatasetcanbe
forfine-tuning. WeperformDPOwithatraining
annotatedbyadifferentnumberofannotators,and
batch size of 1, a beta value of 0.1, a maximum
thereisnoguaranteethatthesameannotatorwill
prompt length of 16 tokens, a maximum output
beratingeachofthemnemonics. Wefindthatthe
length of 64 tokens, and use the accuracy of the
averagevarianceandentropyofourannotationsis
rewardmodelasthemetricforthebestmodel. We
significantlylowerthanrandomchance.
Our datasets are based on publicly available 5https://huggingface.co/docs/trluse5trainingepochsforeachDPOmodel(Table3) latenteffectivenessofmnemonics,wefirstassess
All unspecified hyperparameters are the default theconvergenceofourlearnedparametersacross
values. Allevaluationsarefromasinglerun. chains. All of our learned parameters have an rˆ
valueunder1.01andaneffectivesamplesizeover
B.2 DecodingStrategy 1000,indicatingstrongconvergence. Further,our
We use greedy decoding (no sampling) when finalBayesianpreferencelabel(whichmnemonic
generating mnemonics in §6. For a vocabu- hasahighereffectivenessscore)acrosschainshasa
lary word v, we generate its mnemonic with Krippendorff’sαover0.75,indicatingstrongagree-
the prompt: ### Term:v\n### Mnemonic: ment and convergence. Finally, in Figure 9, we
v sounds like to ensure the mnemonic fol- displaytheloglikelihoodvaluesforourobserved
lowsthetwo-stepprocessof: 1)linkingv toasim- dataacrossiterations,findingthattheyconverge.
plerkeywordk;and2)generatinganexplanation Whileconvergenceismoreimportanttoassess
thatrationalizeshowv andk areconnected. thequalityofaBayesianmodelthatlearnslatent
values, we also assess the generalizability of our
B.3 GPT-4ClassifierImplementation model. Wefirsttrainourmodelon80%ofourdata
andruninferenceontheremaining20%forevalu-
Our classifier to judge the quality of mnemonics
isimplementedwithDSPy6 (Khattabetal.,2024) ation. InFigure10,wecomparetheloglikelihood
ofpredictingtheobserveddataonthetrainingand
andbasedongpt-4-turbo-2024-04-09. To
evaluationsplits. For3/5ourobserveddatatypes,
trainandevaluatethisclassifier,weselect250pairs
we find a non-significant difference between the
ofmnemonicsforthesamevocabularytermfrom
loglikelihoods(2-samplet-test). Theonlysignif-
MnemonicDictionary with the highest difference
icant difference is in the data associated with the
inourlatentqualityscores(§2.2),indicatingaset
learningpreferencesy ,furthersuggestingthat
ofmnemonicswithclearhumanpreferences. We learn
modelingobservedpreferencesisachallengingand
use25randomtrainingexamplesand25random
interestingdirectionforfuturework.
validationexamplestooptimizethispromptwith
DSPyandafteroptimization,weruninferencewith
B.5 ObtainingBayesianPreferenceLabels
theclassifieronaheld-outsetofthe200remaining
To obtain the final latent overall mnemonic ef-
examples. Thepromptisoptimizedusingbootstrap
fectiveness values for training the DPO model
few-shotwithrandomsearchwithamaximumof
p (m|v), we average the latent variables over
3bootstrappeddemos,amaximumof3labeledde- dpo
all five chains post-burn-in. For the ablation
mos,and10candidateprograms. Asfeatures,the
studywherewecompareoptimizingony ver-
classifierusesthetwomnemonicstochoosefrom, pair
sus y , we similarly obtain the final latent
the vocab term, and a sample sentence contain- bayes
ingthevocabularywordfromWordsAPI7.This mnemoniceffectivenessvaluesbyaveragingthela-
tentvariablesoverallfivechainspost-burn-in,but
choiceofinputswasselectedbyassessingvalida-
thistimewejustusearandomsampleoftheepochs
tion set accuracy while adding different vocabu-
(i.e. thinning). Bytakingasampleofeachchainin-
laryfeatures,includingthedefinitionoftheword,
steadofusingtheentirechains,weintroducemore
synonyms,antonyms,andpart-of-speechinforma-
variabilityanddisagreementinthelabels,allowing
tion. TheinstructiongivenintheDSPysignature
is: Givenavocabularyterm,asentenceusingthe us to more meaningfully study the difference be-
term,andtwocandidatemnemonics(MnemonicA tween optimizing on pairwise preferences versus
andMnemonicB),classifywhetherMnemonicAor allpreferencelabels.
MnemonicBisabettermnemonicdevice. Output
C UserStudyDetails
justtheletterofthebettermnemonic("A"or"B").
Ourclassifierpromptwillbereleased. C.1 AnnotatorInstructions
Duringouruserstudies,weensuretoprovideam-
B.4 BayesianModelEvaluation
pleinstructionstoannotators. Onthehomepage
In this section, we evaluate the quality of our
of our flashcard learning app, users can view our
Bayesianmodel. Sinceourgoalwastoestimatethe
InstitutionalReviewBoarddocuments,whichde-
6https://dspy-docs.vercel.app/ tail the purpose of the study and how user data
7https://www.wordsapi.com/ will be collected and used. Further, we provideusersinstructionstohelpthemratethequalityof LLMalignmentmethodsfordialoguesafetyrely
mnemonicdevices(Figure7),whichcanbeviewed onexpressedpreferencesastrainingdata.
atanytimethroughouttheuserstudy. Allannota- Toillustratethispoint,wepresentthefollowing
tors are English speakers. Users were aware that mnemonicgeneratedbytheinitial SMARTmodel
they were participants in a research study and as during the user study, which was flagged as one
participationwasvoluntary,compensationisfair. of two offensive mnemonics: Obtuse soundslike
"abuse". If you abuse someone, they may not un-
C.2 QualitativeEvaluationDetails
derstand the situation, just like an obtuse person
Inourqualitativeevaluation,wecompareourfull whoisslowtounderstand. Asnotedbyourannota-
modeltrainedwithDPOonBayesianlabelsversus tor,thismnemonic: “maybeinsensitivetopeople
10-shotGPT-4(gpt-4-turbo-2024-04-09), who have felt abuse in their lives and feel as if
whereexampleswerechosenaccordingtothehigh- themnemoniciscallingthemslow”. Throughex-
estlatentqualityscoresinD (§2.2). Wealso pressedpreferences,thismnemonicreceivedaLik-
train
compareagainstexperthuman-writtenmnemonics ertratingof1andreceived0votesinthepairwise
to serve as an upper bound on mnemonic quality. comparison. However,withobservedpreferences,
Thesemnemonicswerewrittenbyaprofessional the student studying with this mnemonic learned
copyeditorandcreativewriterwithaBachelor’sof theterminjustoneiteration. Thus,whileobserved
SciencedegreethatwehiredonUpwork. Aspart preferences would suggest that this mnemonic is
of the interview, we asked the writer to produce highlyeffectiveforlearning,theexpressedprefer-
twosamplemnemonicstoensurethemnemonics encesshowthatthismnemonicmaybeoffensive
wouldbehighquality,andtheannotatorwaspaid orharmfultousers,motivatingouruseofallpref-
a high rate of $3 per mnemonic (around $60/hr), erencelabelsforenhancingmnemonicgeneration.
whichisfairfortheparticipantdemographic.
D.2 AreBayesianTie-BreaksGood?
Our annotators who rated the keyword and ex-
planationqualityofthesemnemonicsarebothre- We previously found that using multiple prefer-
searchersinmemoryandmnemonicresearch(one encelabelstobreaktieswithinsingularpreference
post-docandoneassistantprofessor). Theinstruc- labels, improving LLM output quality with DPO
tions given to these annotators are shown in Fig- (§6.2). Toensurethatthesetiesarebetterthanran-
ure 8. Annotators were paid at a rate of $50/hr, domtiebreaks,weuseourGPT-4classifiertocom-
whichisfairfortheparticipantdemographic. Our parethewinningandlosingmnemonicsfromour
annotators showcase moderate agreement, high- Bayesianlabels(i.e. mnemonicswithhigherand
lightingthesubjectivenatureofmnemonicgener- lowereffectiveness)wherethemajorityvoteinthe
ation(Table8). Numericaltabularversionsofthe pairwisesettingisTie. Onthesetofties,GPT-4
resultsfromFigure6areinTables9and10. statesthatour“winning”mnemonicsisbetter40%
ofthetime,tiedwiththelosingmnemonic31%of
D DetailedAnalysisandResults thetime,andisworse29%ofthetime. Thus,even
thoughhumansmarkedtheseLLMoutputsastied,
D.1 OffensiveMnemonicscanAidLearning
wewereabletodrawfromotherpreferencelabels
Warning: Thissubsectioncontainsanexample toidentifyawinningmnemonic,andGPT-4also
ofanoffensivemnemonic. tendstoagreethatthismnemonicishigher-quality.
In§5,wedescribeourrationaleforusingboth For context, when students mark a mnemonic
expressed and observed preferences; while ob- as“winning”frompairwisecomparisons(i.e. non-
served preferences often reflect our downstream tie),GPT-4statesthismnemonicishigher-quality
goal,expressedpreferencesensurethatthisgoalis thanthealternativein51%ofcases,tiedin22%of
achievedinasafemanner. Forexample,ifwewere cases,andislower-qualityin26%ofcases.
tooptimizemnemonicsjustonlearning,whichis
D.3 DPOModelsversusFine-Tuning
ourdownstreamgoal,wemayproducebizarreor
offensivemnemonics,sincethesemnemonicshave InTable11,weuseGPT-4tojudgethemnemon-
beenshowntohelpstudentslearn(WollenandMar- ics from each of the DPO configurations used
gres, 1987). However, expressed preferences are in §6.2 versus the SMART model just using fine-
a more reliable method to detect these offensive tuning p (m|v). We find that DPO improves the
0
mnemonics,andisthuslikelywhythemajorityof mnemonicqualityofeachofthesemodels.D.4 MnemonicExamples
InTable12,weprovideexamplesofhigh-quality
keyword mnemonic devices generated by our fi-
nal model. We also show some examples of low-
qualitymnemonicsfromourmodelandhighlight
areasforimprovementinTable13.Column Description NumUnique
term Vocabularyterm 822
mnemonic Mnemonicforthevocabularyterm 889
Table4: DescriptionsofcolumnsinD .
train
Examples of Good and Bad Mnemonics
Good Mnemonic ● Good keyword link
● Clear explanation
Pithy sounds like "pity." When you pity
● Easy to understand
someone, you give them a short,
● Memorable
meaningful message. Pithy means brief
● Correct definition
and meaningful.
Incorrect Definition Unclear Circular Keyword
Pithy sounds like "witty." Thus, pithy Pithy sounds like "pity." A person who is Pithy sounds like "pith"...
means clever or smart pitied is often pitied and pitied people
are given short messages
Poor Keyword Explanation
Low Memorability (Subjective)
Pithy sounds like "pity." People are often
Keyword Doesn’t “Sound Like” Term
Pithy sounds like "pit." Pits can be short. pitied when they mess up. Pithy means
Pithy means brief. Pithy sounds like "short"... brief and meaningful.
Figure7:Instructionsgiventostudentstohelpthemratethequalityofmnemonicdevicesforverbalizedpreferences.
Figure8: Instructionstoexperteducatorswhenratingthekeywordandexplanationqualityofmnemonicdevices.Figure9: LoglikelihoodconvergenceofobserveddatainourBayesianmodel.PreferenceType #Annotations #Pairs AverageAnnotations/Pair
Pairwise(y ) 1693 460 3.68
pair
Rating(y ) 389 121 3.21
rate
Learning(y ) 602 170 3.54
learn
Table5: Summarystatisticsofpreferenceannotations.
Column Description NumUnique
term Vocabularyterm 472
mnemonic_A MnemonicAforthevocabularyterm 472
mnemonic_B MnemonicBforthevocabularyterm 472
pairwise_A_votes NumberofuserswhopickedMnemonicAinthepairwisecomparison 11
pairwise_B_votes NumberofuserswhopickedMnemonicBinthepairwisecomparison 9
pairwise_tie_votes Numberofuserswhopicked“tie”inthepairwisecomparison 5
A_likert_ratings ListofLikertratingsfrom1-5denotingthequalityofMnemonicA 5
B_likert_ratings ListofLikertratingsfrom1-5denotingthequalityofMnemonicB 5
A_learn_iterations Listofturnsfrom1to∞thestudentneededtolearnthetermwithMnemonicA 7
B_learn_iterations Listofturnsfrom1to∞thestudentneededtolearnthetermwithMnemonicB 8
Table6: DescriptionsofcolumnsinD .
pref
Feedback MetricUsed PreferenceAgreement RandomAgreement
Comparison AverageEntropy 0.802 1.222
Rating AverageVariance 0.778 1.331
Learning AverageVariance 0.323 2.179
Table7: QuantifyingannotationnoiseinD .
pref
ModelQualitativeComparison Cohen’sκ
SMARTvsTransphoner(PS) 0.381
SMARTvsTransphoner(Simplicity) 0.526
SMARTvsGPT-4vsHuman(PS) 0.497
SMARTvsGPT-4vsHuman(Simplicity) 0.538
SMARTvsGPT-4vsHuman(Clarity) 0.428
SMARTvsGPT-4vsHuman(Strength) 0.356
SMARTvsGPT-4vsHuman(Imageability) 0.681
Table 8: Agreement of our annotators across all qualitative evaluations (model comparisons and aspects). We
measureagreementthroughCohenκ,usingquadraticweightingfortheLikertscaleratings.
KeywordQuality
Model PhoneticSimilarity Simplicity
SMART 0.87 0.75
Transphoner 0.87 0.73
Table9: NumericaltabularversionofqualitativeevaluationofSMARTversusTransphonerfromTable6.KeywordQuality ExplanationQuality
Model PhoneticSimilarity Simplicity Clarity Strength Imageability
SMART 0.86 0.67 3.10 2.86 1.91
GPT-4 0.94 0.58 3.17 2.74 2.52
Human 0.96 0.91 3.64 2.99 3.38
Table10: NumericaltabularversionofqualitativeevaluationofSMARTversusGPT-4versusHumansfromTable6.
Train vs Validation Log Likelihood
Train LL
3.0 Val LL
2.5
2.0
1.5
1.0
0.5
0.0
ratings_A ratings_B learn_A learn_B comparison_votes
Categories
Figure10: ComparisonofBayesianmodelloglikelihoodofobserveddataontrainingversusvalidationset.
ModelA/BPair AWins Tie BWins
p (m|v)(Table3,top), p (m|v) 0.26 0.54 0.20
pair 0
p (m|v)(Table3,top), p (m|v) 0.22 0.58 0.20
bayes 0
p (m|v)(Table3,bottom), p (m|v) 0.24 0.58 0.18
pair 0
p (m|v)(Table3,bottom), p (m|v) 0.29 0.53 0.18
dpo 0
Table11: GPTjudgementofDPOmodelsversusfine-tuning. Thebettermodelisinbold.
seulaVTerm GeneratedKeywordMnemonic
Lionizedsoundslike"lion-eyes,"envisioningalionbeingadmiredforitseyes.
Lionized
Lionizedmeanstobeadmiredortreatedlikeacelebrity.
Empiricismsoundslike"emperor";
Empiricism anemperormayrelyonexperienceratherthantheorytorule.
Empiricismisbasedonexperienceratherthantheory.
Dwindlingsoundslike"wind"+"lingering";
Dwindling whenthewindlingers,itgraduallydecreasesinstrength.
Thisrelatestodwindling,whichmeansdecreasinginsize,amount,orstrength.
Gloweredsoundslike"glow"+"red".
Glowered
Imaginearedglowingface,whichcouldrepresentangeroragloweredexpression.
Staticsoundslike"stick",whichisstationaryorunmoving.
Static Staticelectricityisalsostationary,asitdoesnotmove.
Bothrelatetotheconceptofbeingstationaryorunmoving.
Sanctimonysoundslike"saint"+"money";
Sanctimony saintsaresupposedtobeholy,butsomemaybehypocriticalandgreedyformoney.
Thishypocrisyandfalsepietyissanctimony.
Goosebumpssoundslike"ghostbumps,"whichcanhappenwhenyouseeaghost.
Goosebumps
Goosebumpsarebumpsontheskincausedbyfearorcold.
Resurgencesoundslike"re-surgery";
Resurgence afterasurgery,onemayexperiencearesurgenceofpain.
Resurgencereferstoarenewedincreaseorrise..
Mootsoundslike"mute";
Moot whensomethingismute,it’sdebatablewhetherit’sonoroff.
Similarly,amootpointisdebatable.
Subordinatesoundslike"sub-order",implyingalowerrankorposition.
Subordinate
Subordinatesarelowerinrankorposition,andaresubjecttotheauthorityofothers.
Upbraidedsoundslike"up"+"braid".
Upbraided Imagineateacherscoldingastudentfornotbraidingherhairproperly.
Thisscoldingorreprimandingisupbraiding.
Despoiledsoundslike"despitespoiled."
Despoiled
Imaginesomeonespoilingyourplansdespiteyourefforts,leavingyoufeelingdespoiled.
Caterwaulingsoundslike"cat+war+yelling,"imaginingacatyellingduringwar.
Caterwauling
Caterwaulingreferstoloud,unpleasantnoise.
Escalatesoundslike"escalator,"whichgoesup,representinganincreaseorrise.
Escalate
Escalatemeanstoincreaseorriseinintensityorseverity.
Compromisesoundslike"com+promise".
Whenyoumakeapromise,youmayhavetocompromiseonsomethingtokeepit.
Compromise
Forexample,youmayhavetocompromiseonyoursleeptokeepapromise
tomeetsomeoneearlyinthemorning.
Deftnesssoundslike"leftness,"whichcanbeassociatedwithleft-handedpeople
Deftness whoareoftenknownfortheirdexterityordeftness.
Thiscanhelprememberthemeaningofdeftnessasskillfuloradroit.
Hapticsoundslike"happytic",whichcanbeassociatedwithahappytickle,relatingtotouch.
Haptic
Hapticreferstothesenseoftouch.
Parentheticalsoundslike"parenthesis,"whichisusedtoaddextrainformationinasentence.
Parenthetical
Parentheticalmeansprovidingadditionalinformationinasentence.
Fillipsoundslike"fillup";
Fillip whenyoufillupaglass,itgivesasuddenpushtotheliquid,similartoafillip.
Afillipisasuddenpushorstimulus.
Kowtowsoundslike"cowtow"—imagineacowtowingacar,symbolizingsubmissionorobeisance.
Kowtow
Kowtowmeanstoshowrespectorsubmissionbybowingorkneeling.
Table12: Examplesof20high-qualitykeywordmnemonicsgeneratedbyourfinalmodelp (m|v).
dpoTerm GeneratedKeywordMnemonic
Affiliatedsoundslike"affiliation,"
Affiliated whichisaconnectionorassociationwithagroupororganization.
Beingaffiliatedmeansbeingconnectedorassociatedwithsomething.
Evincedsoundslike"evidence";
Evinced evidenceisproof,whichiswhatevincedmeans.
Evidenceisalsoasynonymofevinced
Complicitsoundslike"compliant"+"licit"(licitmeanslegal).
Complicit Ifsomeoneiscompliantwithlegalactions,theyareinvolvedinthem.
Complicitmeansinvolvedinawrongdoing.
Quintessentialsoundslike"quint"(five)+"essential".
Quintessential
Fiveessentialsarerequiredtomakeaperfectdish,representingthequintessential.
Peonssoundslike"pions"(pionsaresubatomicparticles).
Peons
Pionsaresubatomicparticles,sopeonsaresubordinateworkers.
Table13: Examplesoflow-qualitykeywordmnemonicsgeneratedbyourfinalmodelp (m|v). Prominentissues
dpo
andareasforimprovementarehighlightedinred.