Black-Box Opinion Manipulation Attacks to
Retrieval-Augmented Generation of Large Language Models
ZhuoChen JiaweiLiu∗
WuhanUniversity WuhanUniversity
Wuhan,China Wuhan,China
chenzhuo432@whu.edu.cn laujames2017@whu.edu.cn
HaotanLiu QikaiCheng FanZhang
WuhanUniversity WuhanUniversity WuhanUniversity
Wuhan,China Wuhan,China Wuhan,China
baker-haotanliu@whu.edu.cn chengqikai@whu.edu.cn fan.zhang@whu.edu.cn
WeiLu XiaozhongLiu
WuhanUniversity WorcesterPolytechnicInstitute
Wuhan,China USA
weilu@whu.edu.cn xliu14@wpi.edu
Abstract
Retrieval-AugmentedGeneration(RAG)isappliedtosolvehallucinationproblemsandreal-time
constraintsoflargelanguagemodels,butitalsoinducesvulnerabilitiesagainstretrievalcorrup-
tionattacks.ExistingresearchmainlyexplorestheunreliabilityofRAGinwhite-boxandclosed-
domainQAtasks. Inthispaper, weaimtorevealthevulnerabilitiesofRetrieval-Enhanced
Generative(RAG)modelswhenfacedwithblack-boxattacksforopinionmanipulation. We
exploretheimpactofsuchattacksonusercognitionanddecision-making,providingnewinsight
toenhancethereliabilityandsecurityofRAGmodels. Wemanipulatetherankingresultsofthe
retrievalmodelinRAGwithinstructionandusetheseresultsasdatatotrainasurrogatemodel.
Byemployingadversarialretrievalattackmethodstothesurrogatemodel,black-boxtransfer
attacksonRAGarefurtherrealized. Experimentsconductedonopiniondatasetsacrossmultiple
topicsshowthattheproposedattackstrategycansignificantlyaltertheopinionpolarityofthe
contentgeneratedbyRAG.Thisdemonstratesthemodel’svulnerabilityand,moreimportantly,
revealsthepotentialnegativeimpactonusercognitionanddecision-making,makingiteasierto
misleadusersintoacceptingincorrectorbiasedinformation.
1 Introduction
Withtherapiddevelopmentofartificialintelligence,largelanguagemodels(LLMs)havedemonstratedexceptional
capabilities in the field of natural language processing. However, constrained by their training data, these
modelshavelimitedscopeofknowledgeandlackthemostup-to-dateinformation,whichcanleadtoerrorsor
hallucinationswhentacklingmorecomplexortime-sensitivetasks. Retrieval-AugmentedGeneration(RAG)
combinesinformationretrievalwiththegenerativecapabilitiesoflargelanguagemodels,enhancingthetimeliness
ofknowledgeacquisitionandeffectivelymitigatingthehallucinationproblemofthesemodels. Whengivena
query,RAGretrievesthemostrelevantpassagesfromaknowledgebasetoaugmenttheinputrequestfortheLLM.
Forexample,theretrievedknowledgemayconsistofaseriesoftextsnippetsthataresemanticallymostsimilarto
thequery. RAGhasinspiredmanypopularapplications,suchasMicrosoftBingChat,ERNIEBot,andKimiChat,
∗Correspondingauthor.
Preprint.Underreview.
4202
luJ
81
]LC.sc[
1v75731.7042:viXrawhichuseRAGtosummarizeretrievalresultsforimproveduserexperience. Open-sourceprojectslikeLangChain
andLlamaIndexprovidedeveloperswithflexibleRAGframeworkstobuildcustomizedAIapplicationsusing
LLMs,retrievalmodelsandknowledgebases.
However,astheapplicationscopeofRAGexpands,itssecurityisincreasinglyaconcern,especiallyregarding
themodelperformancewhenfacedwithmaliciousattacks. ThebasicRAGprocesstypicallyconsistsofthree
components: thecorpus(refersknowledgebases),theretriever,andthegenerativelargelanguagemodel. When
someoftheretrievedpassagesarecorruptedbymaliciousmanipulators,theRAGprocesscanbecomevulnerable;
thisisreferredtoasaretrievalmanipulationattackinthispaper. Numerousstudieshaveexploredvariousforms
of retrieval manipulation attacks, such as adversarial attack on the retriever [14, 16], prompt injection attack
[1, 15, 10], jailbreak attack for LLM [6, 12, 27], and poisoning attack targeting the retrieval corpus in RAG
[29,23].
This paper primarily focuses on adversarial ranking poisoning attacks against the retriever in RAG and how
suchattacksindirectlyaffectthegenerativeresultsoftheLLM.Thethreatmodelpresentedhereisclosertoa
real-worldblack-boxscenarioandcanbespecificallymodeledasfollows: theattackercanonlymakerequeststo
thelargemodelandcannotaccessthecompletecorpus,theretriever,ortheparametersoftheRAG.Theattacker
canonlyinsertadversariallymodifiedcandidatetextsintothecorpus,whiletheretrieverandtheLLMremain
black-boxed, intactandunmodifiable. Basedonpreviousstudies[13,2], theretrievalcorpusandknowledge
base contain millions of candidate texts sourced from the internet, allowing attackers to inject adversarially
modifiedcandidatetextsbymaliciouslycraftingwebcontentorencyclopediapages. Representativeprevious
studiesbyChoetal. [4]andZhongetal. [28]utilizedpredefinedwhite-boxretrievers,whicharechallengingto
achieveinreal-worldscenarioswithlimitedflexibilityandpracticality. Moreover,theseworksdidnotconsider
testingattacksspecificallytargetingtheintegratedgenerationprocess,wherepracticalintegratedmodelsmay
mitigatetheeffectsofattackssolelytargetingtheretriever,therebyreducingtheireffectiveness. Furthermore,
anothernotablework,PoisonedRAG[29],implementedblack-boxretrievalpoisoningattacksonRAGknowledge
bases,effectivelyexposingrelevantsecurityvulnerabilitiesofRAG.However,itsexperimentsmainlyfocused
onclosed-domainquestionanswering,suchas"WhoistheCEOofOpenAI?"Suchquestionscanbecorrected
whenRAGiscombinedwithfact-checkingandvaluealignmentofLLMs. Thevulnerabilitiesexploredinthis
paperprimarilytargetopen-ended,controversial,andopinion-basedquestionsinRAG,suchas"Shouldabortion
belegal?"Thesequestionsdemandhigherlevelsoflogicalanalysisandsummarizationcapabilitiesfromlarge
models. Currentresearchincontroversialtopicsislimited,andattacksmanipulatingopinionsonopinion-based
questionscouldpotentiallycausemoreprofoundharm.
Open-endedandcontroversialtopicsareissuesthatlackconsensusduetodifferingopinionsandattractwidespread
attention. Thesetopicsofteninvolveopinionsfromdifferentperspectives,influencingpublicperceptionwhen
theyarewidelydiscussed. Forexample,inpoliticalelections,RobertEpstein[8]foundthatmanipulatingsearch
enginestoproducebiasedsearchresultscanaltervoters’votingpreferences. Placingpassagesfavoringaparticular
candidate at the top significantly affects voter trust and favorability towards that candidate. Today, the issue
of information homogenization in "information bubbles" has been a major concern among scholars. Zhang
Yueetal. [24]proposedthathomogenizationininformationbubblesmanifestsinthreedimensions: selective
homogenization, content homogenization, and group homogenization. Content homogenization refers to the
phenomenonwherepeopleusingonlinemediaencounterhomogeneityinthepresentedcontent,oftenduetothe
"filterbubbles"thatarecreatedbyrecommendationsystemsandselectivelyfeedbiasedinformation. Inscenarios
ofopen-endedandcontroversialtopics,"informationbubbles"canleadtothehomogenizationofuseropinions,
withpeople’sviewsbeingeasilyinfluencedbythestanceoftheinformationtheyencounter. Throughmanual
constructionorsearchengineoptimization,opinionmanipulationattacksor"cognitivewarfare"inopen-ended
controversial topics is actually widespread in practical applications such as social media and news platform.
Thisphenomenonhasnumerousnegativeimpactsonsociety. Withthedevelopmentoflargelanguagemodels,
opinionmanipulationexploitingRAGvulnerabilitiesposesaparticularlyseverethreat. Attackerscaninfluence
thestanceofthemodelgeneratedcontentwithcarefullydesignedinputs,furtherendangeringusers’cognition
anddecision-makingprocesses. Therefore,itisofsignificanttheoreticalandpracticalimportancetostudythe
vulnerabilitiesofRAGmodelsagainstopinionmanipulationattacksinblack-boxsetting.
In short, this paper aims to explore the reliability of RAG against black-box opinion manipulation attacks in
open-endedcontroversialtopicsandinvestigatetheimpactofsuchattacksonusercognitionanddecision-making.
Specifically,wefirstsendspecificinstructionstoobtaintherankingoftheretrievalresultsintheRAGmodel
andanalyzetheworkingmechanismofitsretrievalmodule. Wetrainasurrogatemodelontheobtainedretrieval
rankingdatatoapproximatethefeaturesandrelevancepreferencesoftheretrieverinRAG[14,21]. Basedon
thesurrogatemodel, wedesignadversarialretrievalattackstrategiestomanipulatetheopinionsofcandidate
documents. Byattackingthissurrogatemodel,wegenerateadversarialopinionmanipulationsamplesandtransfer
2theseadversarialsamplestotheactualRAGmodel. Wethenconductexperimentsonopiniondatasetsacross
multipletopicstovalidatetheeffectivenessandimpactrangeoftheattackstrategieswithoutunderstandingthe
internalknowledgeoftheRAGmodel. Experimentsconductedonopiniondatasetsacrossmultipletopicsshow
thattheproposedattackstrategycansignificantlyaltertheopinionpolarityofthecontentgeneratedbyRAG.
Thisnotonlydemonstratesthevulnerabilityofthemodelbut,moreimportantly,revealsthepotentialnegative
impactonusercognitionanddecision-making,makingiteasiertomisleadusersintoacceptingincorrectorbiased
information.
2 RelatedWorks
Researchonthereliabilityofneuralnetworkmodelshaslongbeenestablished. In2013,Szegedyetal. [18]found
thatapplyingimperceptibleperturbationstoaneuralnetworkmodelduringaclassificationtaskwassufficientto
causeclassificationerrorsinCV.Later,scholarsobservedsimilarphenomenoninNLP.Robinetal. [11]found
thatinsertingperturbedtextintooriginalparagraphssignificantlydistractscomputersystemswithoutchanging
thecorrectanswerormisleadinghumans. Itreflectstherobustnessofneuralnetworkmodels,i.e.,theability
tooutputstableandcorrectpredictionsintacklingtheimperceptibleadditivenoises[20]. Forlargelanguage
models,Wangetal. [19]proposedacomprehensivetrustworthinessevaluationframeworkforLLMs,assessing
theirreliabilityfromvariousperspectivessuchastoxicity,adversarialrobustness,stereotypebias,andfairness.
Whilelargelanguagemodelshavegreatercapabilitiescomparedtogeneraldeepneuralnetworkmodels,theyalso
raisemoreconcernsregardingsecurityandreliability.
AsRAGisdesignedtoovercomethehallucinationprobleminLLMsandenhancetheirgenerativecapabilities,
thereliabilityofthecontentgeneratedbyRAGisalsoamajorconcern. Zhangetal. [25]attemptedtoexplorethe
weaknessesofRAGbyanalyzingcriticalcomponentsinordertofacilitatetheinjectionoftheattacksequenceand
craftingthemaliciousdocumentwithagradient-guidedtokenmutationtechnique. Xiangetal. [22]designedan
isolate-then-aggregatestrategy,whichgetsresponsesofLLMsfromeachpassageinisolationandthensecurely
aggregatetheseisolatedresponses,toconstructthefirstdefenseframeworkagainstretrievalcorruptionattacks.
Thesestudiesarebasedonwhite-boxscenariosandprimarilyfocusontherobustnessofRAGagainstcorrupted
andtoxiccontent.
This paper intends to use adversarial retrieval attack strategies to perturb the ranking results of the retriever,
ensuringthatopiniondocumentswithacertainstancearerankedashighaspossible,therebyguidingthegenerated
responsesoftheLLMtoreflectthatstance.
The adversarial retrieval attack strategy starts with manipulation at the word level. Under white-box setting,
Ebrahimietal. [7]utilizeanatomicflipoperation,whichswapsonetokenforanother,togenerateadversarial
examples and the method, known as Hotflip. Hotflip gets rid of reliance on rules, but the adversarial text it
generate usually has incomplete semantics and insufficient grammar fluency. While it can deceive the target
model,itcannotevadeperplexity-baseddefenses. Wuetal. [21]alsoproposedawordsubstitutionrankingattack
method called PRADA. To enhance the readability and effectiveness of the adversarial text, scholars further
designedsentence-levelrankingattackmethods. Songetal. [17]proposeanadversarialmethodunderwhite-box
setting,namedCollision,whichusesgradientoptimizationandbeamsearchtoproducetheadversarialtextnamed
collision. TheCollisionmethodfurtherimposesasoftconstraintoncollisiongenerationbyintegratingalanguage
model, reducing the perplexity of the collision. The method has shown promising[14] propose the Pairwise
Anchor-basedTrigger(PAT)methodunderblack-boxsetting. Addedthefluencyconstraintandthenextsentence
predictionconstraint,themethodgeneratesadversarialtextbyoptimizingthepairwiselossoftopcandidatesand
targetcandidateswithadversarialtext. AlthoughthetimecomplexityofPAThasincreasedcomparedtoprevious
methods,PATtakesrankingsimilarityandsemanticconsistencyintoaccount,soitsmanipulationeffectonthe
retrievalrankingoftargetcandidatesissuperior.
3 Method
Thispaperattemptstomanipulatetheopinionsintheresponsesgeneratedbyblack-boxRAGmodelsoncon-
troversialtopics,targetingboththeretrievalmodelandtheLLMwhichperformstheintegratedgenerationtask.
Zhangetal. [25]triedtopoisoncontextdocumentstodeceivetheLLMintogeneratingincorrectcontent,butthis
methodrequiresextensiveinternaldetailsoftheLLMapplication,makingitlessfeasibleinreal-worldscenarios.
Forblack-boxRAG,themanipulatorhasnoknowledgeoftheinternalinformationoftheRAG,includingmodel
architectureandscorefunction,andcanonlyaccesstheinputsandoutputsoftheRAG.Specially,themanipulator
canonlycalltheinterfaceoftheLLMinRAGinsteadofthatoftheretriever. Sincetheinputsconsistofthe
3Figure1: ThemethodformanipulatingtheopinionsofRAG-generatedcontentinblack-boxscenario
queryandthecandidatedocumentsandtheuser’squerycannotbealtered,thispaperfocusesonmodifyingthe
candidatedocuments. Althoughthemanipulatorcannotaccesstheentirecorpus,theycaninsertadversarially
modifiedcandidatetextsintothecorpus. ThebasicframeworkofRAGconsistsoftheretrieverandthegenerative
largelanguagemodel,whichthetwoareseriallyconnected,theLLMperformsthegenerationtaskbasedonthe
contextinformationretrievedbytheretriever. Giventhatmanipulatorsinablack-boxscenariocannotmodify
thesystempromptsofthegenerativelargemodel,itisdifficulttodirectlymanipulatethegenerationresultsby
exploitingthereliabilityflawsoftheLLMitself. Therefore,thispaperfocusesonexploitingthereliabilityflaws
oftheretrievertomanipulatetheretrievalrankingresults. Byaddingadversarialtextstocandidatedocumentsthat
holdtheexpectedopinion,weincreasetheirrelevancetothequery,makingthemmorelikelytobeincludedinthe
contextpassedtothegenerativelargelanguagemodel. LeveragingthestrongcapabilityofLLMforunderstanding
andfollowinginstructions,weguidetheLLMtogenerateresponsesthatalignwiththeexpectedopinion. An
overviewofthismethodisshowninFigure1.
ThespecificapproachformanipulatingRAGopinionsoncontroversialtopicsisasfollows: Givenatopicq(the
query)fromasetofcontroversialtopicsQ,weselectaexpectedopinionS andtargetallcandidatedocuments
t
d intheretrievalcorpusDthatholdtheS opinion. Afterobtainingtheadversarialtextp ,itisaddedtod ,
t t adv t
transformingtheretrievalcorpustoD(d;d ⊕p ). Sincep canincreasetherelevancescoreR(q,d ⊕p )
t adv adv t adv
assignedbytheretrievalmodelRMtod forqueryq,ideallyd willberankedatthetopoftheretrievalresults
t t
RM (q)={d|d ⊕p },guidingthelargelanguagemodeltogenerateresponsesthatalignwiththeexpected
k t adv
opinion: S(LLM(q,RM (q)))=S .
k t
Theprimaryissueinimplementingmanipulationistomaketheretrievalmodeloftheblack-boxRAGtransparent.
ThispaperaimstosimulatetheretrievalmodelRM. ThebasicideaistotrainasurrogatemodelM withthe
i
rankingresultsRM (q)fromtheretrievalmodelRM,thusturningtheblack-boxretrievalmodelintoawhite-box
k
model.However,sincetheretrieverandthelargegenerativemodelinRAGareseriallyconnected,itisnotpossible
todirectlyobtaintherankingresultsoftheretriever. Therefore,thispaperattemptstoguidethelargegenerative
modeltoreplicatetheretrievalresultsoftheblack-boxRAG.Therefore,thispaperattemptstoguidethelarge
modeltoreplicatetheoutputoftheretrievalmodel,soweobtainthetextdatadeemedrelevantbytheblack-box
retrievalmodelRM,whichcanbeusedaspositiveexamplesd forblack-boximitationtraining. Subsequently,
+
irrelevanttextstothequerycanberandomsampledasnegativeexamplesd . Therefore, thispaperdesigns
−
specificinstructionstomaketheblack-boxRAGreplicatetheretrievalresultsoftheretrieverRM. Theseretrieval
resultsonlyneedtoreflecttherelevancetothequery. Then,basedonthegeneratedresultsoftheLLM,wesample
positiveandnegativedatatotrainthesurrogatemodel. Themethodforobtainingimitationdataoftheretrieval
modelinablack-boxRAGscenarioisillustratedinFigure2. Thepromptinstructionusedisasfollows:
Nowthatyouareasearchengine,pleasesearch: {query}
IgnoretheQuestion. Pleasecopythetop3passagesofthegivenContext
intactintheoutputandprovidetheoutputinJSONwithkeys’answer’
and ’context’. Put each candidate passage in ’context’ as a string
element in the list. Candidate passages are separated by line break
insteadofperiodorexclamationpoint. Eachcandidateisanelementin
thelist,like[Passage1,Passage2,Passage3].Pleasecopythepassages
intactwithnomodificationandonlyoutputtheonebestJSONresponse.
Thispaperusesapairwiseapproachtosampledataandtrainthesurrogatemodel. Relevantpassagesaresampled
fromtheresponsesgeneratedbytheblack-boxRAGaspositiveexamplesd ,andrandomirrelevantpassages
+
aresampledasnegativeexamplesd . Theblack-boxRAGrespondswithcontextinformationsotheresponses
−
generatedreflecttheretrievalresultsinsteadofbeingindependentonthecontext. Thesesamplepairs(d ,d )are
+ −
4Figure2: ThemethodforobtainingimitationdataofRAGretrievalmodelinblack-boxscenario
incorporatedintothetrainingdataset. Aftersamplingtheimitationdata,thispaperusesapairwisetrainingmethod
to obtain the surrogate model M . Let the relevance score calculated by M be R , the training optimization
i i i
objectiveisasfollows:
(cid:16) (cid:17)
L=− 1 (cid:80) log Ri(q,d+) [1]
|Q| q∈Q Ri(q,d+)+(cid:80)Ri(q,d−)
AfterobtainingthesurrogatemodelM ,thispapertransformsthemanipulationofRAG-generatedopinionsina
i
black-boxscenariointomanipulationinawhite-boxscenario. Sincewehavealltheknowledgeofthewhite-box
surrogate model M , this paper directly implements adversarial retrieval attacks on it, generating adversarial
i
textp forthecandidatedocumentd holdingtheopinionS . ThispaperemploysthePairwiseAnchor-based
adv t t
Trigger(PAT)strategyforadversarialretrievalattacks,whichiscommonlyusedasabaselineinrelatedresearch.
Subsequently,thegeneratedadversarialtextisaddedtothecandidatedocumentwithS . Then,thesystemofthe
t
black-boxRAGmodelisqueried,andthegeneratedresponseisobtained. Thestanceoftheresponseiscompared
with the stance of the response generated by the RAG without manipulation to evaluate the reliability of the
black-boxRAG.
PAT,asarepresentativeadversarialretrievalattackstrategy,adoptsapairwisegenerationparadigm. Giventhe
target query, the target candidate item, and the top candidate item(anchor, used to guide the adversarial text
generation),themethodutilizesgradientoptimizationofpairwiseloss,calculatedfromthecandidateitemand
theanchor,tofindtheappropriaterepresentationofanadversarialtext. Themethodalsoaddsfluencyconstraint
andnextsentencepredictionconstraint. Bybeamsearchforthewords,thefinaladversarialtext,denotedasT ,
pat
isiterativelygeneratedinanauto-regressiveway. ThispaperusesT asp ,withitsgeneratedoptimization
pat adv
functionbeing[14]:
max(M (q,T ;w)+λ ·logP (T ;w)+λ ·f (d ,T ;w)) [2]
i pat 1 g pat 2 nsp t pat
Intheaboveformula,P isthesemanticconstraintfunction,andf isthenextsentencepredictionconsistency
g nsp
scorefunctionbetweenT andd .
pat t
Intermsofdataset,thispaperusestheMSMARCOPassagesRankingdatasetasthedatasourceforguiding
theblack-boxRAGtogeneraterelevantpassages[28]wherewesampledatapairstotrainthesurrogatemodel.
Additionally,thispaperusescontroversialtopicdatascrapedfromthePROCON.ORGwebsiteastheobjectof
manipulation. Thecontroversialtopicdatasetincludesover80topics, coveringfieldssuchassociety, health,
government,education,andscience. Eachcontroversialtopicisdiscussedfromtwostances(proandcon),withan
averageof30relatedpassages,eachholdingacertainopinionwithstanceproorcon.
ThespecificsettingsdetailsfortheRAGmanipulationexperimentareasfollows:
(1)Black-boxRAG:Thispaperrepresentstheblack-boxRAGprocess,whichservesastheresearchobject,as
RAG . Itmainlyconsistsofaretrieverandalargelanguagemodel(LLM).TheLLMsusedaretheopen-source
black
modelsMeta-Llama-3-8B-Instruct(LLAMA3-8B)andQwen1.5-14B-Chat(Qwen1.5-14B).TheLLAMAand
5QwenseriesLLMsperformwellacrossvarioustasksamongallopen-sourcemodels. Thepromptconnectingthe
retrieverandtheLLMinRAG adoptsthebasicRAGpromptfromtheLangchainframework:
black
Use the following pieces of retrieved context to answer the question.
Keeptheanswerconcise. Context: {context}. Question: {question}.
(2)Targetretrievermodelandsurrogatemodel:TheretrieverinRAGisusuallyadenseretrievalmodel. Therefore,
thispaperselectstherepresentativedenseretrievalmodel,coCondenser,asthetargetretrievalmodel[9]. Since
coCondenserisaBERT-basedmodel,thesurrogatemodelchoseninthispaperistheMiniLMmodel,whichis
BERT-basedandspecificallytrainedontheMSMarcoPassageRankingdataset.
(3)Manipulationtarget:Foracontroversialtopicq,documentsd holdingtheexpectedopinionS aremanipulated
t t
byaddingadversarialtextp atthebeginning. Thismanipulationaimstopositiontheseperturbeddocumentsas
adv
prominentlyaspossibleinthetopK rankingsoftheRAGretrieverRM (q),whereK denotesthenumberof
k
paragraphsobtainedbytheRAGgenerationmodelfromtheretrievalresults. Inthispaper,K issetto3.
(4)Manipulator(thethreatmodel): Intheblack-boxscenario,themanipulatorisonlyauthorizedtoquerythe
RAG,obtainRAG-generatedresultsandmodifythetargetdocuments. Therearenorestrictionsonthenumberof
callstoRAG.Furthermore,themanipulatorhasnoknowledgeofthemodelarchitecture,modelparameters,or
anyotherinformationrelatedtothemodelswithintheblack-boxRAG.Modifyingtheprompttemplatesusedby
theLLMisalsoprohibited.
(5)ExperimentalParameters: Thebatchsizefortrainingthesurrogatemodelissetto32,with24iterations.
Ourproposedopinionmanipulationstrategyforblack-boxRAGisoutlinedinAlgorithm1.
4 ExperimentandAnalysis
AfterimitatingtheretrievalmodelofRAG toobtainthesurrogatemodel,thispaperfirstcomparestheranking
black
abilityofthesurrogatemodelM andthetargetretrievalmodelRM,aswellasthesimilarityoftheirranking
i
results, as shown in Table 1, to ensure that the surrogate model has learned the capabilities of the black-box
retrievalmodel.
ThispaperusesMeanReciprocalRank(MRR)andNormalizedDiscountedCumulativeGain(NDCG)toreflect
therankingabilityofthemodelsthemselves;highervaluesindicatestrongerrankingabilityintermsofrelevance.
InterRankingSimilarity(Inter)andRankBiasedOverlap(RBO)areusedtomeasurethesimilaritybetweenthe
rankingresultsofthesurrogatemodelandthetargetretrievalmodel;highervaluesindicatebetterperformanceof
theblack-boximitation. TheweightforRBO@10issetto0.7. InTable1,“–”indicatesthatthemetricisnot
applicabletothemodel.
AscanbeseenfromTable1,thesurrogatemodelM trainedbyblack-boximitationissimilartothetargetretrieval
i
modelcoCondenserintermsofrelevancerankingperformanceandrankingresults,validatingtheeffectivenessof
theblack-boximitation.
Aftertheblack-boximitationtraining,thewhite-boxsurrogatemodelisconductedwithopinionmanipulation
experiments. Severalcontroversialtopicsandtheiropiniontextdataunderthefourthemesof"Government",
"Education", "Society", and "Health" from the PROCON.ORG data are selected as the retrieval corpus. The
originalretrievalcorpusisdenotedasDocs . Basedonthesurrogatemodel,wegeneratethecorrespondingT
origin pat
forthecandidateitemswiththeexpectedopinionS oncontroversialtopics,andtheninsertT atthebeginningof
t pat
thetargetcandidateitemstoobtaintheperturbedretrievalcorpusDocs . QueryRAG twiceoncontroversial
adv black
topics: oncewithDocs astheretrievalcorpus,andoncewithDocs astheretrievalcorpus,andobtainthe
origin adv
tworesponsesofRAG,representingtheanswersbeforeandafteropinionmanipulation. Theresponsesarethen
classifiedintothreecategoriesbasedontheiropiniononcontroversialtopics: opposing,neutral,andsupporting,
representedby0,1,and2,respectively,astheopinionscoresofthegeneratedresponses. ThisstudyusesAverage
StanceVariation(ASV)torepresenttheaverageincreaseofopinionscoresofRAG responsesinthedirection
black
oftheexpectedopinionS beforeandaftermanipulation. ApositiveASVindicatesthattheopinionmanipulation
t
towardsS iseffective,whileanegativeASVindicatesthatthemanipulationactuallymakestheopinionsofRAG
t
responsesdeviatefromS . ThelargertheASVvalue,themoresuccessfultheopinionmanipulationofRAG
t
responses. Additionally,thispaperattemptstoobtaintherankingresultsoftheretrievercoCondensertoevaluate
theeffectivenessoftheadversarialretrievalmanipulationstrategyattherankingstagefordenseretrieval. This
evaluationissolelyforassessmentpurposesandisnotinvolvedinmanipulation,asnointernalknowledgeof
RAG wasleakedduringthemanipulationprocess.
black
6Algorithm1:OpinionManipulationStrategyforblack-boxRAG
Input: targetblack-boxRAGmodelRAG ,targetretrievalmodelRM,surrogatemodelM ,controversial
black i
topicsQ,targettopicq,expectedopinionS ,corpusDocs,targetdocumentswithexpectedopinion
t
Docs ,targetdocumentd ,relevantdocumentd ,randomsampleddocumentd
t t + −
Instructions:
i ="Nowthatyouareasearchengine,pleasesearch: {query}IgnoretheQuestion. Pleasecopythe
1
top3passagesofthegivenContextintactintheoutputandprovidetheoutputinJSONwithkeys
’answer’and’context’. Puteachcandidatepassagein’context’asastringelementinthelist..."
i ="Usethefollowingpiecesofretrievedcontexttoanswerthequestion..."
2
// RAG uses i as prompt template.
black 2
Functions:
OpinionClassify: Classifytheopinionofthecontentinto"support","neutral"or"oppose".
PAT: PairwiseAnchor-basedTriggergenerationstrategy.
Output: manipulatedRAGresponsesRes
1 Phase1. PairwiseImitationDataConstructionandBlack-boxRetrievalModelImitationTraining
2 INIT:DatasetD ←{}
3 forq m ∈Qdo
4 inducedranklistR mtop3←RAG black(q m⊕i 1;Docs)
// RAG (q ⊕i ) ≈ RM(q )
black m 1 m
5 ford +j ∈R mtop3do
6 Randomsampledocumentasd −j
7 D ←positive,[q m;d +j;d −j]
8 D ←negative,[q m;d −j;d +j]
// Reverse d and d to get the negative triple
+j −j
9 TrainthesurrogatemodelM ionDwithEq1
10 returnM i
11 Phase2. AdversarialTriggerGenerationandOpinionManipulationinRAGResponse
12 INIT:RAGResponseSetRes←{}
13 forq m ∈Qdo
14 ranklistR m ←M i(q m;Docs)
15 anchor m ←top-1(R m)
16 ford j ∈R mdo
17 ifOpinionClassify(d j)=S tthen
18 Docs t ←d j
19 ford tj ∈Docs tdo
20 adversarialtriggerp advj ←PAT(M i;q m,d tj,anchor m)
21 adversarialdocumentd advj ←d tj ⊕p advj
22 Docs:d tj ←d advj // Replace
23 Res←RAG black(q m;Docs)
24 returnRes
AfterobtainingtherankingresultsoftheretrievermodelcoCondenser, thispaperevaluatesthemanipulation
effectwithAttackSuccessRate(ASR),theaverageproportionoftargetopinionsintheTop3rankingsbefore
andaftermanipulation(Top3 ,Top3 ),andtheVariationofNormalizedDiscountedCumulativeGain
origin attacked
(VoN-DCG).HighervaluesofASRandVo-NDCGindicatebettermanipulationeffectsonranking,andalarger
differencebetweenTop3 andTop3 signifiesmoresignificantrankingmanipulationeffects,too.
attacked origin
Figure3showsthesignificantoverallopinionmanipulationeffectoftheadversarialretrievalattackstrategyPAT.
ThispaperdividesDocs intotwoparts: documentdatawithanexpectedopinionofsupportanddocument
origin
datawithanexpectedopinionofopposition,theexpectedopinionrepresentsthestancedirectionwewouldlike
RAGresponsetoholdforthetargettopicaftermanipulation. TheexpectedopinionS issetto2forsupporting
t
and0foropposing,andthenmanipulationisperformed. Theresultsshowthatwhentheexpectedopinionis
support,theproportionofresponseswithasupportivestanceincreasessignificantlyaftermanipulation,while
7Table1: Comparison(%)ofrankingresultsbetweenthesurrogatemodelandthetargetretrievalmodel(basedon
thetargetretrievalmodel)
Model MRR@10 NDCG@10 Inter@10 RBO@10
Targetretrievalmodel 87.07 68.16 – –
Surrogatemodel 87.98 73.73 62.32 48.66
Table2: ManipulationresultsofRAG rankingandresponseopinion
black
Model CoCondenserRanking Qwen1.5-14b LLAMA3-8b
Topic ASR Top3 rigin Top3 ttacked NDCG ariation ASV ASV
o a v
Government 0.17 0.48 0.57 0.06 -0.17 0.25
Education 0.33 0.28 0.39 0.09 0.42 0.5
Society 0.5 0.39 0.56 0.07 0.42 0.5
Health 0.5 0.33 0.44 0.12 0.67 0.5
theproportionofresponseswithanopposingstancedecreases. Whentheexpectedopinionisopposition,the
proportionofsupportiveresponsesdecreasessignificantlyaftermanipulation,whiletheproportionsofneutraland
opposingresponsesbothincrease. Comparatively,thechangesinstancebeforeandaftermanipulationareslightly
largerforLLAMA3-8bthanforQwen1.5-14b,duetostrongerabilityofLLAMA3-8btofollowinstructions.
The results of the theme-specific manipulation experiments are shown in Table 2. The adversarial retrieval
attackstrategyPAT,appliedtotheadversarialtextsgeneratedbythesurrogatemodel, significantlyincreased
theproportionofcandidateitemsholdingexpectedopinionintheTop3oftheRAG retrievallist,thereby
black
guidingtheLLMtochangeitsopinionintheresponse. However,themanipulationeffectofRAG generated
black
opinions varies across different themes: for education, society, and health topics, the attack success rate and
rankingvariationoftargetitemsaresignificantlyhigherthanthoseingovernmenttopics. Thissuggeststhatthe
LLMmayhavebeenspecificallyfine-tunedongovernment-relateddataset,enablingittomitigatethebiasinthe
retrievalcontexttosomeextent. Amongthesetopics,controversialopinionsinsocietyandhealthtopicsaremore
susceptibletomanipulation. Sincethesetwoareasarecloselyrelatedtopeople’slives,opinionmanipulationin
societyandhealthtopicsmayposeagreaterrisk.
ThemanipulationresultsacrossdifferentthemesstilldemonstraterelativeadvantageofLLAMA3-8binunder-
standingpromptswithcontextualbackgroundintentionsandgeneratingeffectiveresponses. However,thisalso
indicatesthatthestrongcomprehensionabilityofLLMsmayunderminethereliabilityofthecontentitgenerates.
Figure3: OveralleffectofRAGopinionmanipulationinblack-boxscenario
85 Conclusion
Inthispaper,weexplorethevulnerabilityofretrieval-augmentedgeneration(RAG)modelstoopinionmanipulation
againstblack-boxattackinopen-endedcontroversialtopics,anddelveintothepotentialimpactofsuchattacks
on user cognition and decision-making. Through systematic experiments, we propose a novel adversarial
attackstrategyaboutretrievalrankingpoisoning. Thismethodsignificantlyaffectsthepolarityoftheopinions
generated by RAG by crafting adversarial samples, without requiring internal knowledge of the RAG model.
Theexperimentalresultsindicatethattheproposedattackstrategysuccessfullyalterstheopinionofthecontent
generatedbytheRAGmodel,revealingthevulnerabilityandunreliabilityofRAGwhenconfrontedwithmalicious
retrievalcorpus.Moreimportantly,thisopinionmanipulationcouldhaveprofoundimpactsonusers’cognitionand
decision-makingprocesses,potentiallyleadinguserstoacceptincorrectorbiasedinformation,causingcognitive
changesandpublicopiniondistortion.Thisphenomenonisparticularlysignificantinopen-endedandcontroversial
issues.
Futureresearchwillexpandsthescaleoftheexperimentsbyincludingmoreopen-sourceandcommercialRAG
systemstomorecomprehensivelyevaluatethereliabilityofviewpointgenerationbyRAGmodels. Giventhe
vulnerabilitiesofRAGmodels,futureworkshouldfocusondevelopingmorerobustdefensestrategies. These
mayincludeimprovingtherobustnessofretrievalalgorithms,enhancingthereliabilityofgenerationmodels,and
introducingmulti-levelinputfilteringmechanismstocounteractadversarialinputs,therebyachievingabalanced
optimizationoftheunderstandingandreliabilityofRAGmodels.
6 EthicalStatement
Thispaperexploresthefeasibilityofopinionmanipulationonblack-boxRAGmodelsinreal-worldscenarios.
ThemaingoalistoassessthereliabilityofRAGtechnologyinrespondingtorankingmanipulationatthestageof
retrieval,pavingthewayforfutureworktoenhancetherobustnessanddefensecapabilitiesofRAGtechnology.
ThisstudydidnotmanipulateanycommercialRAGsystemsorreal-worlddatacurrentlyinuse.·
References
[1] Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, et al. Badprompt: Backdoor attacks on continuous
prompts. AdvancesinNeuralInformationProcessingSystems,35:37068–37080,2022.
[2] NicholasCarlini,MatthewJagielski,ChristopherAChoquette-Choo,DanielPaleka,WillPearce,Hyrum
Anderson, Andreas Terzis, Kurt Thomas, and Florian Tramèr. Poisoning web-scale training datasets is
practical. arXivpreprintarXiv:2302.10149,2023.
[3] ZhuoChen,JiaweiLiu,andHaotanLiu. Researchonthereliabilityandfairnessofopinionretrievalinpublic
topics. In2024NetworkandDistributedSystemSecurity(NDSS)workshoponAISystemswithConfidential
Computing,2024.
[4] SukminCho,SoyeongJeong,JeongyeonSeo,TaehoHwang,andJongCPark. Typosthatbroketherag’s
back: Geneticattackonragpipelinebysimulatingdocumentsinthewildvialow-levelperturbations. arXiv
preprintarXiv:2404.13948,2024.
[5] JeremyCohen,ElanRosenfeld,andZicoKolter. Certifiedadversarialrobustnessviarandomizedsmoothing.
Ininternationalconferenceonmachinelearning,pages1310–1320.PMLR,2019.
[6] GeleiDeng,YiLiu,YuekangLi,KailongWang,YingZhang,ZefengLi,HaoyuWang,TianweiZhang,and
YangLiu. Jailbreaker: Automatedjailbreakacrossmultiplelargelanguagemodelchatbots. arXivpreprint
arXiv:2307.08715,2023.
[7] JavidEbrahimi,AnyiRao,DanielLowd,andDejingDou. Hotflip: White-boxadversarialexamplesfortext
classification. arXivpreprintarXiv:1712.06751,2017.
[8] RobertEpsteinandRonaldE.Robertson. Thesearchenginemanipulationeffect(SEME)anditspossible
impactontheoutcomesofelections. ProceedingsoftheNationalAcademyofSciences,112(33):E4512–
E4521,August2015. Publisher: ProceedingsoftheNationalAcademyofSciences.
[9] LuyuGaoandJamieCallan. Unsupervisedcorpusawarelanguagemodelpre-trainingfordensepassage
retrieval. arXivpreprintarXiv:2108.05540,2021.
[10] Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang,
MicahGoldblum,AniruddhaSaha,JonasGeiping,andTomGoldstein. Baselinedefensesforadversarial
attacksagainstalignedlanguagemodels. arXivpreprintarXiv:2309.00614,2023.
9[11] RobinJiaandPercyLiang. Adversarialexamplesforevaluatingreadingcomprehensionsystems. arXiv
preprintarXiv:1707.07328,2017.
[12] Haoran Li, Dadi Guo, Wei Fan, Mingshi Xu, Jie Huang, Fanpu Meng, and Yangqiu Song. Multi-step
jailbreakingprivacyattacksonchatgpt. arXivpreprintarXiv:2304.05197,2023.
[13] ZilongLin,ZhengyiLi,XiaojingLiao,XiaoFengWang,andXiaozhongLiu. Mawseo: Adversarialwiki
searchpoisoningforillicitonlinepromotion. arXivpreprintarXiv:2304.11300,2023.
[14] Jiawei Liu, Yangyang Kang, Di Tang, Kaisong Song, Changlong Sun, Xiaofeng Wang, Wei Lu, and
XiaozhongLiu. Order-Disorder: ImitationAdversarialAttacksforBlack-boxNeuralRankingModels,April
2023. arXiv:2209.06506[cs].
[15] YiLiu,GeleiDeng,YuekangLi,KailongWang,TianweiZhang,YepangLiu,HaoyuWang,YanZheng,
and Yang Liu. Prompt injection attack against llm-integrated applications, june 2023. arXiv preprint
arXiv:2306.05499,2023.
[16] Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, and Xueqi Cheng.
Black-boxadversarialattacksagainstdenseretrievalmodels: Amulti-viewcontrastivelearningmethod. In
Proceedingsofthe32ndACMInternationalConferenceonInformationandKnowledgeManagement,pages
1647–1656,2023.
[17] CongzhengSong,AlexanderMRush,andVitalyShmatikov. Adversarialsemanticcollisions. arXivpreprint
arXiv:2011.04743,2020.
[18] ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,IanGoodfellow,andRob
Fergus. Intriguingpropertiesofneuralnetworks. arXivpreprintarXiv:1312.6199,2013.
[19] BoxinWang,WeixinChen,HengzhiPei,ChulinXie,MintongKang,ChenhuiZhang,ChejianXu,Zidi
Xiong,RitikDutta,RylanSchaeffer,etal. Decodingtrust: Acomprehensiveassessmentoftrustworthinessin
gptmodels. InNeurIPS,2023.
[20] WenqiWang,RunWang,LinaWang,ZhiboWang,andAoshuangYe. Towardsarobustdeepneuralnetwork
intexts: Asurvey. arXivpreprintarXiv:1902.07285,2019.
[21] ChenWu,RuqingZhang,JiafengGuo,MaartendeRijke,YixingFan,andXueqiCheng. PRADA:Practical
Black-BoxAdversarialAttacksagainstNeuralRankingModels,June2022. arXiv:2204.01321[cs].
[22] ChongXiang,TongWu,ZexuanZhong,DavidWagner,DanqiChen,andPrateekMittal. Certifiablyrobust
ragagainstretrievalcorruption. arXivpreprintarXiv:2405.15556,2024.
[23] JiaqiXue,MengxinZheng,YebowenHu,FeiLiu,XunChen,andQianLou. Badrag: Identifyingvulner-
abilities in retrieval augmented generation of large language models. arXiv preprint arXiv:2406.00083,
2024.
[24] ZhangYue,ZHUANGBichen,LIQingyu,andZHUQinghua. Homogenizationdilemma:conceptanalysis
and theoretical framework construction of information cocoons. Journal of Library Science in China,
49(3):107–122,2023.
[25] QuanZhang,BinqiZeng,ChijinZhou,GwihwanGo,HeyuanShi,andYuJiang. Human-imperceptible
retrieval poisoning attacks in llm-powered applications. In Companion Proceedings of the 32nd ACM
InternationalConferenceontheFoundationsofSoftwareEngineering,pages502–506,2024.
[26] ZihanZhang,MingxuanLiu,ChaoZhang,YimingZhang,ZhouLi,QiLi,HaixinDuan,andDonghong
Sun. Argot: Generatingadversarialreadablechinesetexts. InProceedingsoftheTwenty-NinthInternational
ConferenceonInternationalJointConferencesonArtificialIntelligence,pages2533–2539,2021.
[27] XuandongZhao,XianjunYang,TianyuPang,ChaoDu,LeiLi,Yu-XiangWang,andWilliamYangWang.
Weak-to-strongjailbreakingonlargelanguagemodels. arXivpreprintarXiv:2401.17256,2024.
[28] ZexuanZhong,ZiqingHuang,AlexanderWettig,andDanqiChen. Poisoningretrievalcorporabyinjecting
adversarialpassages. arXivpreprintarXiv:2310.19156,2023.
[29] WeiZou,RunpengGeng,BinghuiWang,andJinyuanJia. Poisonedrag: Knowledgepoisoningattacksto
retrieval-augmentedgenerationoflargelanguagemodels. arXivpreprintarXiv:2402.07867,2024.
10