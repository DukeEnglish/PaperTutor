Information Compression in Dynamic Games
Dengwang Tang1*, Vijay Subramanian2 and
Demosthenis Teneketzis2
1Ming Hsieh Department of Electrical and Computer Engineering,
University of Southern California, Los Angeles, CA, 90089-2560, USA.
2Electrical and Computer Engineering Division, Electrical Engineering
and Computer Science Department, University of Michigan, Ann
Arbor, MI, 48109, USA.
*Corresponding author(s). E-mail(s): dwtang@umich.edu;
Contributing authors: vgsubram@umich.edu; teneket@umich.edu;
Abstract
One of the reasons why stochastic dynamic games with an underlying dynamic
system are challenging is because strategic players have access to enormous
amountofinformationwhichleadstotheuseofextremely complexstrategiesat
equilibrium.Oneapproachtoresolvethischallengeistosimplifyplayers’strate-
gies by identifying appropriate compression of information maps so that the
playerscanmakedecisionssolelybasedonthecompressedversionofinformation,
called theinformationstate.Suchmapsallowplayerstoimplement theirstrate-
gies efficiently. For finite dynamic games with asymmetric information, inspired
bythenotionofinformationstate forsingle-agentcontrolproblems, wepropose
twonotionsofinformationstates, namely mutuallysufficient information(MSI)
and unilaterally sufficient information (USI). Both these information states are
obtained by applying information compression maps that are independent of
thestrategyprofile.WeshowthatBayes-NashEquilibria (BNE)andSequential
Equilibria (SE) exist when all players use MSI-based strategies. We prove that
when all players employ USI-based strategies the resulting sets of BNE and SE
payoff profiles are the same as the sets of BNE and SE payoff profiles result-
ing when all players use full information-based strategies. We prove that when
all players use USI-based strategies the resulting set of weak Perfect Bayesian
Equilibrium (wPBE) payoff profiles can be a proper subset of all wPBE pay-
off profiles. We identify MSI and USI in specific models of dynamic games in
the literature. We end by presenting an open problem: Do there exist strategy-
dependentinformationcompressionmapsthatguaranteetheexistenceofatleast
one equilibrium or maintain all equilibria that exist under perfect recall? We
1
4202
luJ
71
]TG.sc[
1v81321.7042:viXrashow, by a counterexample, that a well-known strategy-dependent information
compression mapused intheliteraturedoesnotpossessanyofthepropertiesof
thestrategy-independent compression maps that result in MSI or USI.
Keywords:Non-cooperative Games,DynamicGames,InformationState,Sequential
Equilibrium,MarkovDecisionProcess
JEL Classification: C72,C73,D80
MSC Classification: 90C40,91A10,91A15,91A25,91A50
Acknowledgements: TheauthorswouldliketothankYiOuyang,HamidrezaTavafoghi,
AshutoshNayyar,TilmanB¨orgers,andDavidMillerforhelpfuldiscussions.
1 Introduction
The model of stochastic dynamic games has found application in many engineering
and socioeconomic settings, such as transportation networks, power grid, spectrum
markets, and online shopping platforms. In these settings, multiple agents/players
makedecisions overtime ontopofanever-changingenvironmentwith playershaving
differentgoalsandasymmetricinformation. Forexample,intransportationnetworks,
individual drivers make routing decisions based on information from online map ser-
vices in order to reach their respective destinations as fast as possible. Their actions
thencollectivelyaffecttrafficconditionsinthefuture.Anotherexampleinvolvesonline
shopping platforms, where buyers leave reviews to inform potential future buyers,
whilesellersupdatepricesandmakelistingdecisionsbasedonthefeedbackfrombuy-
ers. In these systems, players’ decisions are generally not only interdependent, but
also affect the underlying environment as well as future decisions and payoffs of all
players in complex ways.
Determining the set of equilibria, or even solving for one equilibrium, in a given
stochastic dynamic game can be a challenging task. The main challenges include: (a)
thepresenceofanunderlyingenvironment/systemthatcanchangeovertimebasedon
theactionsofallplayers;(b)incompleteandasymmetricinformation;(c)largenumber
of players, states, and actions; and (d) growing amount of information over time
which results in a massive strategy space. As a result of the advances in technology,
stochastic dynamic games today are often played by players (e.g. big corporations)
that have access to substantial computational resources along with a large amount
of data for decision making. Nevertheless, even these players are computationally
constrained, and they must make decisions in real-time, hence complicated strategies
maynotbefeasibleforthem.Therefore,itisimportanttodeterminecomputationally
efficientstrategiesforplayerstoplayatequilibria.Compressionofplayers’information
and then use of the strategies based on the compressed information is a well-heeled
methodology that results in computationally efficient strategies. In this paper we
address some of the above-mentioned challenges. We concentrate on the challenges
associated with information compression, namely the existence of equilibria under
2information compression,and the preservationofallequilibrium payoffprofiles under
information compression. We leave as a topic of future investigation the discovery
of efficient algorithms for the computation of equilibria based on strategies that use
compressed information.
Specifically,ourgoalistoidentify appropriatestrategy-independent 1 information
compressionmapsindynamicgamessothattheresultingcompressedinformationhas
properties/features sufficient to satisfy the following requirements: (R1) existence of
equilibria when all players use strategies based on the compressed information; (R2)
equality of the set of all equilibrium payoff profiles that are achieved when all players
usefullinformationbased-strategieswiththesetofallequilibriumpayoffprofilesthat
are achieved when all players use strategies based on the compressed information.
Inspired by the literature on single-agent decision/control problems, particularly
the notion of information state, we develop notions of information state (compressed
information) that satisfy requirements (R1) and (R2). Specifically, we introduce the
notions of Mutually Sufficient Information (MSI) and Unilaterally Sufficient Infor-
mation (USI). We show that MSI has properties/features sufficient to satisfy (R1),
whereasUSIhaspropertiessufficienttosatisfy(R2)underseveraldifferentequilibrium
concepts.
Theremainderofthepaperisorganizedasfollows:InSection1.1webrieflyreview
related literature in stochastic control and game theory. In Section 1.2 we list our
contributions. In Section 1.3 we introduce our notation. In Section 2 we formulate
our game model. In Section 3.1 and Section 3.2 we introduce the notion of mutually
sufficient information and unilaterally sufficient information respectively. We present
our main results in Section 4. We discuss these results in Section 5. We discuss an
openproblem,primarilyassociatedwithstrategy-dependentinformationcompression,
in Section 6. We provide supporting results in Appendix A. We present alternative
characterizations of sequential equilibria in Appendix B. We provide proofs of the
results of Sections 3 and 4 in Appendix C. We present the details of the discussions
in Section 5 and Section 6 in Appendix D.
1.1 Related Literature
We first present a brief literature survey on information compression in single-agent
decision problems because it has inspired several of the key ideas presented in this
paper.
Single-agent decision/control problems are problems where one agent chooses
actions over time on top of an ever-changing system to maximize their total reward.
These problems have been extensively studied in the control theory (Kumar and
Varaiya, 2015), operations research (Powell, 2007), computer science (Russell and
Norvig,2002),andmathematics(Bellman,1966)literature.ModelslikeMarkovDeci-
sion Process (MDP) and Partially Observable Markov Decision Process (POMDP)
havebeen analyzedand applied widely in real-worldsystems.It is wellknownthat in
1Strategyindependentinformationcompressionmapsaremapsthatarenotparameterizedbyastrategy
profile. Examples of strategy-independent information compression maps include those that use a fixed-
subsetofthegame’shistory(e.g.themostrecentobservation)orsomestatisticsbasedonthegame’shistory
(e.g.thenumberoftimesplayeritakesacertainaction).Strategy-dependentmapsareparameterizedby
astrategyprofile(seeSection6).
3an MDP, the agent can use a Markov strategy—making decisions based on the cur-
rent state—without loss of optimality. A Markov strategy can be seen as a strategy
based on compressed information: the full information—state and action history—is
compressed into only the current state. Furthermore, in finite horizon problems, such
optimal Markov strategies can be found through a sequential decomposition proce-
dure.ItisalsowellknownthatanyPOMDPcanbetransformedintoanMDPwithan
appropriate belief acting as the underlying state (Kumar and Varaiya,2015,Chapter
6). As a result, the agent can use a belief-based strategy without loss of optimal-
ity. A belief-based strategy compresses the full information into the conditional belief
of the current state. Critically, this information compression is strategy-independent
(˚Astro¨m, 1965; Smallwood and Sondik, 1973; Sondik, 1978; Kumar and Varaiya,
2015). For general single-agent control problems, sufficient conditions that guarantee
optimalityofcompression-basedstrategieshavebeenproposedunderthenamesofsuf-
ficientstatistic(Shiryaev,1964;Striebel,1965;Whittle,1969;Hinderer,1970;Striebel,
1975) and information state (Kumar and Varaiya, 2015; Mahajan and Mannan,
2016; Subramanian et al, 2022). In these works, the authors transform single-agent
control problems with partial observations into equivalent problems with complete
observations with the sufficient statistic/information state acting as the underlying
state.
Multi-agent dynamic decision problems are either teams where all agents have
the same objective, or games where agents have different objectives and are strate-
gic. Information compression in dynamic teams has been investigated in Varaiyaand
Walrand(1978);Nayyaretal(2011,2013b);MahajanandMannan(2016);Tavafoghi
etal(2022);Subramanianetal(2022);KaoandSubramanian(2022),andmanyother
works(seeTavafoghietal(2022)andSubramanianetal(2022)foralistofreferences).
Dynamic games can be divided into two categories: those with a static underlying
environment (e.g. repeated games), and those with an underlying dynamic system.
Over the years, economics researchers have studied repeated games extensively (e.g.
see (Myerson, 2013, Chapter 7)). As our focus is on dynamic games with an under-
lying dynamic system, we will not discuss the literature on repeated games. Among
models for dynamic games with an underlying dynamic system, the model of zero-
sumgames,asaparticularclasswhichpossessesspecialproperties,hasbeenanalyzed
in Shapley (1953); Mertens and Neyman (1981); Rosenberg (1998) and many others
(see Ouyang et al (2024)for a list of references). Non-zero-sumgames with anunder-
lying dynamic system and symmetric information have also been studied extensively
(Ba¸sar and Olsder, 1999; Filar and Vrieze, 2012). For such dynamic games with per-
fect information, the authors of Maskin and Tirole (2001) introduce the concept of
Markov Perfect Equilibrium (MPE), where each player compresses their information
into a Markov state. Dynamic games with asymmetric information have been ana-
lyzed in Mertens and Parthasarathy (2003); Maskin and Tirole (2013); Nayyar and
Ba¸sar (2012); Nayyar et al (2013a); Gupta et al (2014, 2016); Ouyang et al (2015,
2016);Tavafoghi et al(2016); Tavafoghi (2017);Vasalet al(2019); Tang et al (2023);
Ouyang et al (2024). In Nayyar et al (2013a), the authors introduce the concept of
Common Information Based Markov Perfect Equilibrium (CIB-MPE), which is an
extension of MPE in partially observable systems. In a CIB-MPE, all players choose
4their actions at each time based on the Common-Information-Based (CIB) belief (a
compressionofthecommoninformation)andprivateinformationinsteadoffullinfor-
mation. The authors establish the existence of CIB-MPE under the assumption that
the CIB belief is strategy-independent. Furthermore, the authors develop a sequen-
tial decomposition procedure to solve for such equilibria. In Ouyang et al (2016), the
authors extend the result of Nayyar et al (2013a) to a particular model where the
CIB beliefs are strategy-dependent. They introduce the concept of Common Infor-
mation Based Perfect Bayesian Equilibrium (CIB-PBE). In a CIB-PBE all players
choosetheiractionsbasedontheCIBbeliefandtheirprivateinformation.Theyshow
that such equilibria can be found through a sequential decomposition whenever the
decomposition hasasolution. Theauthorsconjecture theexistenceofsuchequilibria.
The authors of Tang et al (2023) extend the model of Ouyang et al (2016) to games
among teams. They consider two compression maps and their associated equilibrium
concepts. For the first compression map, which is strategy-independent, they estab-
lishpreservationofequilibriumpayoffs.Forthesecondinformationcompressionmap,
which is strategy-dependent, they propose a sequential decomposition of the game. If
thedecomposition admits a solution,then thereexists a CIB-BNEbasedonthecom-
pressedinformation.Furthermore,theyprovideanexamplewhereCIB-BNEbasedon
this specific compressed information do not exist. The example also proves that the
conjecture about the existence of CIB-PBEs, made in Ouyang et al (2016), is false.
In addition to the methods on information compression that appear in Maskin
and Tirole (2001); Nayyar et al (2013a); Ouyang et al (2016); Tang et al (2023),
therearetwolinesofworkongameswheretheplayers’decisions arebasedonlimited
information. In the first line of work, players face exogenous hard constraints on
the information that can be used to choose actions (Piccione and Rubinstein, 1997;
Battigalli,1997;GroveandHalpern,1997;Halpern,1997;Aumannetal,1997).Inthe
secondlineofwork,playerscanutilizeanyfiniteautomatonwithanynumberofstates
to choose actions, however more complex automata are assumed to be more costly
(Abreu and Rubinstein, 1988;Banks and Sundaram, 1990).In our work,we also deal
with finite automatonbasedstrategies.However,thereis acriticaldifferencebetween
our work and both lines of literatureboth of the above-mentioned lines of work: Our
primary interest is to study conditions under which a compression based strategy
profilecanformanequilibrium understandardequilibriumconcepts whenunbounded
rationality and perfect recall are allowed. Under these equilibrium concepts, we do
not restrict the strategy of any player, nor do we impose any penalty on complicated
strategies. In other words, a compression based strategy needs to be a best response
compared to all possible strategies with full recall in terms of the payoff alone. The
methodology for information compression presented in this paper is similar in spirit
tothatofMaskinandTirole(2001);Nayyaretal(2013a);Ouyangetal(2016);Vasal
et al (2019); Ouyang et al (2024). However, this paper is significantly different from
those works as it deals with the discovery of information compression maps that lead
notonlytotheexistence(ingeneral)ofvarioustypesofcompressedinformationbased
equilibria but also to the preservation of all equilibrium payoff profiles (a topic not
investigated in Maskin and Tirole (2001); Nayyar et al (2013a); Ouyang et al (2016);
Vasal et al (2019); Ouyang et al (2024)). This paper builds on Tang et al (2023); it
5identifiesembodimentsofthetwoinformationcompressionmapsstudiedinTangetal
(2023) for a much more general class of games than that of Tang et al (2023), and a
broader set of equilibrium concepts.
1.2 Contributions
Our main contributions are the following:
1. We propose two notions of information states/compressed information for
dynamic games with asymmetric information that result in from strategy-
independent compression maps: Mutually Sufficient Information (MSI) and
Universally Sufficient Information (USI) — Definitions 4 and 5,respectively. We
present an example that highlights the differences between MSI and USI.
2. We show that in finite dynamic games with asymmetric information, Bayes–
NashEquilibria (BNE)andSequential Equilibria (SE)existwhen allplayersuse
MSI-based strategies — Theorems 1 and 3, respectively.
3. We provethat when all players employ USI-basedstrategies the resulting sets of
BNE and SE payoff profiles are same as the sets of BNE and SE payoff profiles
resulting when all players use full information based strategies — Theorems 2
and 4, respectively.
4. WeprovethatwhenallplayersuseUSI-basedstrategiestheresultingsetofweak
Perfect Bayesian Equilibrium (wPBE) payoff profiles can be a proper subset of
the set of all wPBE payoff profiles — Proposition 1. A result similar to that of
Proposition 1 is also true under Watson’s PBE (Watson, 2017).
Figure 1 depicts the results stated in Contributions 3 and 4 above.
USI-based BNE = All BNE
All wPBE
USI-based wPBE
USI-based SE = All SE
Fig. 1 AVenndiagramshowingtherelationshipofthesetsofpayoffprofilesfordifferentequilibrium
conceptsusingeitherunilateralsufficientinformation(USI)basedstrategyprofilesorgeneralstrategies.
5. We present several examples — Examples 3 through 6 — of finite dynamic
games with asymmetric information where we identify MSI and USI.
Additional contributions of this work are:
61. Asetofalternativedefinitions ofSE—AppendixB.Thesedefinitionsareequiv-
alent to the original definition of SE given in Kreps and Wilson (1982) and help
simplify some of the proofs of the main results in this paper.
2. A new methodology for establishing existence of equilibria. The methodology
is based on a best response function defined through a dynamic program for a
single-agent control problem.
3. A counterexample showing that a well-known strategy-dependent compression
map, resulting in sufficient private information along with common information-
basedbeliefs,doesnotguaranteeexistenceofequilibriabasedontheabove-stated
compressed information.
1.3 Notation
Wefollowthenotationalconventionofstochasticcontrolliterature(i.e.usingrandom
variables to define the system, representing information as random variables, etc.)
insteadoftheconventionofgametheoryliterature(i.e.gametrees,nodes,information
sets,etc.)unlessotherwisespecified.Thisallowsustoapplytechniquesfromstochastic
control, which we rely heavily upon, in a more natural way. We use capital letters
to represent random variables, bold capital letters to denote random vectors, and
lower case letters to represent realizations. We use superscripts to indicate players,
and subscripts to indicate time. We use i to represent a typical player and −i to
representallplayersotherthani.Weuset :t toindicatethecollectionoftimestamps
1 2
(t ,t +1,··· ,t ). For example, Xi stands for the random vector (X1,Xi,Xi,Xi).
1 1 2 1:4 1 2 3 4
For random variables or random vectors represented by Latin letters, we use the
correspondingscriptcapitalletterstodenotethespaceofvaluestheserandomvectors
can take. For example, Hi denotes the space of values the random vector Hi can
t t
take. The products of sets refers to Cartesian products. We use P(·) and E[·] to
denote probabilities and expectations, respectively. We use ∆(Ω) to denote the set
of probability distributions on a finite set Ω. For a distribution ν ∈ ∆(Ω), we use
supp(ν) to denote the support of ν. When writing probabilities, we will omit the
random variables when the lower case letters that represent the realizations clearly
indicate the random variable it represents. For example, we will use P(yi|x ,u ) as a
t t t
shorthand for P(Yi = yi|X =x ,U =u ). When λ is a function from Ω to ∆(Ω ),
t t t t t t 1 2
with some abuse of notation we write λ(ω |ω ):=(λ(ω ))(ω ) as if λ is a conditional
2 1 1 2
distribution. We use 1 to denote the indicator random variable of an event A.
A
In general, probability distributions of random variables in a dynamic system are
onlywelldefinedafteracomplete strategyprofileisspecified. Wespecify thestrategy
profile that defines the distribution in superscripts, e.g. Pg(xi|h0). When the condi-
t t
tional probability is independent of a certain part of the strategy (gi) , we may
t (i,t)∈Ω
omit this partof the strategy inthe notation, e.g. Pg1:t−1(x t|y 1:t−1,u 1:t−1), Pgi (ui t|hi t)
orP(x |x ,u ).Wesaythat arealizationofsomerandomvector(for example hi)is
t+1 t t t
admissible under a partially specified strategy profile(for example g−i) if the realiza-
tion has strictly positive probability under some completion of the partially specified
strategy profile (In this example, that means Pgi,g−i (hi)>0 for some gi). Whenever
t
we write a conditional probability or conditional expectation, we implicitly assume
thattheconditionhasnon-zeroprobabilityunderthespecifiedstrategyprofile.When
7only part of the strategy profile is specified in the superscript, we implicitly assume
that the condition is admissible under the specified partial strategy profile. In this
paper, we make heavy use of value functions and reward-to-go functions. Such func-
tions will be clearly defined within their context with the following convention: Q
stands for state-action value functions; V stands for state value functions; and J
stands for reward-to-go functions for a given strategy profile (as opposed to Q or V,
both of which are typically defined via a maximum over all strategies).
2 Game Model and Objectives
2.1 Game Model
In this section we formulate a general model for a finite horizon dynamic game with
finitely many players.
DenotethesetofplayersbyI.DenotethesetoftimestampsbyT ={1,2,··· ,T}.
At time t, player i ∈ I takes action Ui, obtains instantaneous reward Ri, and then
t t
learns new information Zi. Player i may not necessarily observe the instantaneous
t
rewards Ri directly. The reward is observable only if it is part of Zi. Define Z =
t t t
(Zi) ,U =(Ui) ,andR =(Ri) .Weassumethatthereisanunderlyingstate
t i∈I t t i∈I t t i∈I
variable X and
t
(X ,Z ,R )=f (X ,U ,W ), t∈T, (1)
t+1 t t t t t t
where (f ) are fixed functions. The primitive random variable X represents the
t t∈T 1
initial moveof nature. The primitive random vector H =(Hi) represents the ini-
1 1 i∈I
tial information of the players. The initial state and information X and H are, in
1 1
general, correlated. The random variables (W )T are mutually independent prim-
t t=1
itive random variables representing nature’s move. The vector (X ,H ) is assumed
1 1
to be mutually independent with W ,W ,··· ,W . The distributions of the primitive
1 2 T
random variables are common knowledge to all players.
Define X ,U ,Z ,W ,H to be the sets of possible values of X ,U ,Z ,W ,H
t t t t 1 t t t t 1
respectively.ThesetsX ,U ,Z ,W ,H areassumedto becommonknowledgeamong
t t t t 1
allplayers.Inthiswork,inordertofocusonconceptualdifficultiesinsteadoftechnical
issues, we make the following assumption.
Assumption 1 Xt,Ut,Zt,Wt,H1 arefinite sets, and R ti is supported on [−1,1].
We assume perfect recall, i.e. the information player i has at time t is Hi =
t
(Hi,Zi ),andplayeri’sactionUi iscontainedinthenewinformationZi.Abehav-
1 1:t−1 t t
ioral strategy gi = (gi) of player i is a collection of functions gi: Hi 7→ ∆(Ui),
t t∈T t t t
where Hi is the space where Hi takes values. Under a behavioral strategy profile
t t
g =(gi) , the total reward/payoff of player i in this game is given by
i∈I
T
Ji(g):=Eg Ri . (2)
t
" #
t=1
X
8Remark 1 This is not a restrictive model: By choosing appropriate state representation Xt
andinstantaneousreward vectorRt,it canbeused tomodel anyfinite-nodeextensive form
sequential gamewith perfect recall.
We initially consider two solution concepts for dynamic games with asymmetric
information: Bayes–Nash Equilibrium (BNE) and Sequential Equilibrium (SE). We
define BNE and SE below.
Definition 1 (Bayes-Nash Equilibrium) A behavioral strategy profile g is said to form a
Bayes-Nashequilibrium (BNE)ifforanyplayeriandanybehavioralstrategyg˜i ofplayeri,
wehaveJi(g)≥Ji(g˜i,g−i).
Definition 2 (SequentialEquilibrium) Letg=(gi)i∈I beabehavioralstrategyprofile.Let
Q=(Qi t)i∈I,t∈T beacollectionofhistory-actionvaluefunctions,i.e.Qi t: Hi t×U ti 7→R.The
strategyprofileg issaidtobesequentially rationalunderQifforeachi∈I,t∈T andeach
hi ∈Hi,
t t
i i i i i
supp(gt(ht))⊆argmax Qt(ht,ut). (3)
ui
t
Q is said to be fully consistent with g if there exist a sequence of pairs ofstrategies and
history-action valuefunctions(g(n),Q(n))∞ such that
n=1
(1) g(n) is fully mixed, i.e. every action is chosen with positive probability at every
information set.
(2) Q(n) is consistent with g(n), i.e.,
T
Qτ(n),i (hi τ,ui τ)=Eg(n) Rti hi τ,ui
τ , (4)
"t X=τ (cid:12) #
(cid:12)
foreach i∈I,τ ∈T,hi τ ∈Hi τ,ui τ ∈Uτi. (cid:12)
(3) (g(n),Q(n))→(g,Q) as n→∞.
Atuple(g,Q)issaidtobeasequentialequilibriumifg issequentiallyrationalunderQand
Q is fully consistent with g.
Whereas Definition 2 of SE is different from that of Kreps and Wilson (1982), we
show in Appendix B that it is equivalent to the concept in Kreps and Wilson (1982).
We use Definition 2 as it is more suitable for the development of our results.
In this paper, we are interested in analyzing the performance of strategy profiles
that are based on some form of compressed information. Let Ki be a function of Hi
t t
that can be sequentially updated, i.e. there exist functions (ιi) such that
t t∈T
Ki =ιi(Hi), (5)
1 1 1
Ki =ιi(Ki ,Zi ), t∈T\{1}. (6)
t t t−1 t−1
Write Ki = (Ki) and K = (Ki) . We will refer to Ki as the compres-
t t∈T i∈I
sion of player i’s information under ιi = (ιi) . A Ki-based (behavioral) strategy
t t∈T
9ρi = (ρi) is a collection of functions ρi: Ki 7→ ∆(Ui). A strategy profile where
t t∈T t t t
each player i uses a Ki-based strategy is called a K-based strategy profile. If a K-
based strategy profile forms an Bayes-Nash (resp. sequential) equilibrium, then it is
calledaK-basedBayes-Nash(resp.sequential)equilibrium.NotethatunlikePiccione
and Rubinstein (1997); Battigalli (1997); Groveand Halpern (1997); Halpern (1997);
Aumann et al (1997), we require the K-based BNE and K-based SE to contain no
profitable deviation among all full-history-based strategies.
2.2 Objectives
Ourgoalistodiscoverproperties/features ofthecompressedinformationK sufficient
to guarantee that (i) there exists K-based BNE and SE; (ii) the set of K-based BNE
(resp. SE) payoff profiles is equal to the set of (general strategy based) BNE (resp.
SE) profiles under perfect recall.
To achieve the above-stated objectives we proceed as follows: First, we intro-
duce two notions of information state, namely MSI and USI (Section 3). Then, we
investigate the existence of MSI-based and USI-based BNE and SE, as well as the
preservation of the set of all BNE and SE payoff profiles when USI-based strategies
are employed by all players (Section 4).
Remark 2 A key challenge in achieving the above-stated goal is the following: Unlike the
case of perfect recall, one may not be able to recover Ki from Ki. Therefore, Ki-based
t−1 t
(behavioral) strategies are not equivalent to mixed strategies supported on the set of Ki-
based purestrategies. Thisfactcreatesdifficulty foranalyzingKi-basedstrategies since the
standard technique of using Kuhn’s Theorem (Kuhn, 1953) to transform mixed strategies
to behavioral strategies does not apply. To resolve this challenge, we developed stochastic
control theory-based techniques that allow us to work with Ki-based behavioral strategies
directly rather thantransforming froma mixed strategy.
Remark 3 In the following sections, when referring to the compressed information Ki, we
t
will consider the compression mappings ιi to be fixed and given, so that Ki is fixed given
t
Hi.ThespaceofcompressedinformationKi isafixed,finitesetgivenιi.Whenweuseki to
t t t
represent a realization of Ki, we assume that it corresponds to the compression of Hi =hi
t t t
under the fixed ιi.
3 Two Definitions of Information State
Before we define notions of information state in dynamic games we introduce the
notion of information state for one player when other players’ strategies are fixed.
The following definition is an extension of the definition of information state in
Subramanian et al (2022).
Definition 3 Let g−i be a behavioral strategy profile of players other than i. We say that
Ki isaninformationstate under g−i ifthereexistfunctions(P ti,g−i )t∈T,(r ti,g−i )t∈T,where
Pi,g−i : Ki×Ui 7→∆(Ki ) and ri,g−i : Ki×Ui 7→[−1,1], such that
t t t t+1 t t t
10(1) Pgi,g−i (ki |hi,ui)=Pi,g−i (ki |ki,ui) forall t∈T\{T};
t+1 t t t t+1 t t
(2) Egi,g−i [Ri|hi,ui]=ri,g−i (ki,ui) forall t∈T,
t t t t t t
forallgi,andall(hi,ui)admissibleunder(gi,g−i).(BothPi,g−i andri,g−i
maydependon
t t t t
g−i, but they do not depend on gi.)
In the absence of other players, the above definition is exactly the same as the
definition of information state for player i’s control problem. When other players
are present, the parameters of player i’s control problem, in general, depend on the
strategy of other players. As a consequence, an information state under one strategy
profile g−i may not be an information state under a different strategy profile g˜−i.
3.1 Mutually Sufficient Information
Definition 4 (Mutually Sufficient Information) We say that K = (Ki)i∈I is mutually
sufficient information (MSI) if forall players i∈I and all K−i-based strategy profiles ρ−i,
Ki is an information state underρ−i.
In words, MSI represents mutually consistent compression of information in a
dynamicgame:PlayericouldcompresstheirinformationtoKi withoutlossofperfor-
mance when other players are compressing their information to K−i. Note that MSI
imposes interdependent conditions onthe compressionmaps ofallplayers:It requires
the compression maps of all players to be consistent with each other.
The following lemma provides a sufficient condition for a compression maps to
yield mutually sufficient information.
Lemma 1 If for all i ∈ I and all K−i-based strategy profiles ρ−i, there exist functions
(Φ ti,ρ−i )t∈T where Φ ti,ρ−i : K ti 7→∆(Xt×K t−i) such that
Pgi,ρ−i
(xt,k
t−i |hi
t)=Φ
ti,ρ−i
(xt,k
t−i |kti
), (7)
for all behavioral strategies gi, all t ∈ T, and all hi admissible under (gi,ρ−i), then K =
t
(Ki)i∈I is mutually sufficient information.
Proof See Appendix C.1. (cid:3)
Inwords,the conditionofLemma 1means thatKi hasthe samepredictive power
t
as Hi in terms of forming a belief on the current state and other players’compressed
t
informationwhenever otherplayers areusingcompression-basedstrategies.Thisbelief
is sufficient for player i to predict other player’s actions and future state evolution.
Since other players are using compression-based strategies, player i does not have
to form a belief on other player’s full information in order to predict other players’
actions.
113.2 Unilaterally Sufficient Information
Definition 5 (Unilaterally Sufficient Information) We say that Ki is unilaterally sufficient
i,gi i,g−i
information (USI)forplayeri∈I ifthereexistfunctions(F
t
)t∈T and(Φ
t
)t∈T where
F ti,gi : K ti 7→∆(Hi t),Φ ti,g−i : K ti 7→∆(Xt×H−
t
i) such that
Pg (xt,ht|kti )=F ti,gi (hi t|kti )Φ ti,g−i (xt,h−
t
i |kti ), (8)
forall behavioralstrategy profiles g,all t∈T, and all ki admissible under g.2
t
ThedefinitionofUSIcanbeseparatedintotwoparts:Thefirstpartstatesthatthe
conditional distribution of Hi, player i’s full information, given Ki, the compressed
t t
information,doesnotdependonotherplayers’strategies.Thisissimilartotheideaof
sufficient statistics inthestatistics literature(Kay,1993):Ifplayeriwouldliketo use
their “data” Hi to estimate the “parameter” g−i, then Ki is a sufficient statistic for
t t
this parameter estimationproblem.Thesecondpartstates thatKi hasthe samepre-
t
dictivepowerasHi intermsofformingabeliefonthecurrentstateandotherplayers’
t
full information. In contrast to the definition ofmutually sufficient information, if Ki
isunilaterallysufficientinformation,thenKiissufficientforplayeri’sdecisionmaking
regardless of whether other players are using any information compression map.
3.3 Comparison
Using Lemma 1 it can be shown that if Ki is USI for each i ∈ I, then K = (Ki)
i∈I
is MSI. The converse is not true. The following example illustrates the difference
between MSI and USI.
Example1 Consideratwostagestateless(i.e.Xt =∅)gameoftwoplayers:Alice(A)moves
first and Bob (B) moves afterwards.There is no initial information (i.e. HA=HB =∅).
1 1
Attimet=1,Alice choosesUA ∈{0,1}.Theinstantaneousrewardsofbothplayersare
1
given by
A A B A
R =U ,R =−U . (9)
1 1 1 1
The new information of both Alice and Bob at time 1 is ZA = ZB = UA, i.e. Alice’s
1 1 1
action is observed.
At time t = 2, Bob chooses UB ∈ {−1,1}. The instantaneous rewards of both players
2
are given by
A B B
R =U ,R =0. (10)
2 2 2
Set KA = HA and KB = ∅ for both t ∈ {1,2}. It can be shown that K is mutu-
t t t
ally sufficient information. However, KB is not unilaterally sufficient information: We have
Pg(hB|kB) = Pg(uA) = gA(uA|∅), while the definition of USI requires that Pg(hB|kB) =
2 2 1 1 1 2 2
FB,gB (hB|kB) forsome function FB,gB that doesnot depend on gA.
t 2 2 t
2In the case where random vectors Xt, H ti and H t−i share some common components, (8) should be
interpreted in the following way: xt, hi
t
and h− ti are three separate realizations that are not necessarily
congruent with each other (i.e. they can disagree on their common parts). In the case of incongruency,
the left-hand side equals0. The equation needsto betrue for all combinationsof xt ∈Xt, hi
t
∈Hi
t
and
h−i∈H−i.
t t
124 Information-State Based Equilibrium
In this section, we formulate our result on MSI and USI based equilibria for two
equilibrium concepts: Bayes–Nash equilibria and sequential equilibria.
4.1 Information-State Based Bayes–Nash Equilibrium
Theorem 1 If K is mutually sufficient information, then there exists at least one K-based
BNE.
Proof See Appendix C.2. (cid:3)
The main idea for the proof of Theorem 1 is the definition of a best-response
correspondence through the dynamic program for an underlying single-agent control
problem.
Theorem 2 If K = (Ki)i∈I where Ki is unilaterally sufficient information for player i,
then the set of K-based BNE payoffs is the same as that of all BNE.
Proof See Appendix C.3. (cid:3)
TheintuitionbehindTheorem2isthatonecanthinkofplayeri’sinformationthat
isnotincludedintheunilaterallysufficientinformationKi asaprivaterandomization
t
deviceforplayeri:Whenplayeriisusingastrategythatdependsontheirinformation
outsideofKi,itisasiftheyareusingarandomizedKi-basedstrategy.Themainidea
t
for the proof of Theorem 2 is to show that for every BNE strategy profile g, player
i can switch to an “equivalent” randomized Ki-based strategy ρi while maintaining
theequilibrium andpayoffs.3 Thetheoremthen followsfromiteratively switching the
strategy of each player.
Example 1 can also be used to illustrate that when K is an MSI but not an USI,
K-based BNE exist but K-based strategies do not attain all equilibrium payoffs.
Example 1 (Continued) In this example, KA =HA,KB =∅ fort=1,2 is MSI. Further-
t t t
more, it can be shown that the following strategy profiles are BNE of the game: (E1) Alice
plays UA =1 at time 1 and Bob plays UB =1 irrespective of Alice’s action at time 1; and
1 2
(E2) Alice plays UA =0 at time 1; Bob plays UB =1 if UA =0 and UB =−1 if UA =1.
1 2 1 2 1
Equilibrium (E1) is a K-based equilibrium. However, (E2) cannot be attained by K-based
strategy profile for the following reason: In any K-based equilibrium, Bob plays the same
mixed strategy irrespective ofAlice’s action and his expected payoffat the end of the game
is −1. At (E2), Bob’s expected payoff at the end of the game is 0. Therefore, the payoff at
(E2) cannotbe attained by any K-based strategy profile.
3BesidestheconnectionofUSItosufficientstatistics,theideabehindtheconstructionoftheequivalent
Ki-basedstrategyisalsocloselyrelatedtotheideaoftheRao–Blackwellestimator(Kay,1993),wherea
new estimator is obtained by takingthe conditional expectationof the old estimator given the sufficient
statistics.
134.2 Information-State Based Sequential Equilibrium
Theorem 3 If K is mutually sufficient information, then there exists at least one K-based
sequential equilibrium.
Proof See Appendix C.4. (cid:3)
The proofofTheorem 3 followssteps similar to that of Theorem1.The difference
isthatweexplicitlyconstructasequenceofconjecturedhistory-actionvaluefunctions
Q(n) (as defined in Definition 2) using the dynamic program of player i’s decision
problem. Then we arguethat the strategies and the conjectures satisfies Definition 2.
Theorem 4 If K = (Ki)i∈I where Ki is unilaterally sufficient information for player i,
then the set of K-based sequential equilibrium payoffs is the same as that of all sequential
equilibria.
Proof See Appendix C.5. (cid:3)
The proof of Theorem 4 mostly follows the same ideas for Theorem 2: for each
sequentialequilibriumstrategyprofileg,weconstructan“equivalent”Ki-basedstrat-
egy ρi for player i with similar construction as in Theorem 2. The critical part is to
show that ρi is still sequentially rational under the concept of sequential equilibrium.
5 Discussion
In this section we first investigate if USI can preserve the set of equilibrium payoffs
achievable under perfect recall when refinements of BNE other than SE, namely,
various versons of Perfect Bayesian Equilibrium (PBE), are considered. Then, we
identify MSI and USI in specific models that appeared in the literature.
5.1 Other Equilibrium Concepts
We first present Example 2 to show that the result of Theorem 4 is not true when
we replace SE with the concept of weak Perfect BayesianEquilibrium (wPBE) (Mas-
Colell et al, 1995) which is a refinement of BNE that is weaker than SE. Then, we
discuss howtheresultofProposition1,thatis,partofExample 2andappearsbelow,
applies or does not apply to other versions of PBE, namely, those defined in Watson
(2017) and Battigalli (1996).
The concept of wPBE is defined as follows: Let (g,µ) be an assessment, where g
is a behavioral strategy profile as specified in Section 2 and µ is a system of func-
tions representing player’s beliefs in the extensive-form game representation. Then,
(g,µ) is said to be a weak perfect Bayesian equilibrium (Mas-Colell et al, 1995) if g
is sequentially rational to µ and µ satisfies Bayes rule with respect to g on the equi-
librium path. The concept ofwPBE does not impose any restriction onbeliefs off the
equilibrium path.
14Example2 Consideratwo-stagegamewithtwoplayers:Bob(B)movesatstage1;Alice(A)
andBobmovesimultaneouslyatstage2.LetXA,XB beindependentuniformrandomvari-
1 1
ables on {−1,+1} representing thetypes of the players. Thestate satisfies X1 =(X 1A,X 1B)
and X2 = X 1B. The set of actions are U 1B = {−1,+1}, U 2A = U 2B = {−1,0,+1}. The
information structure is given by
A A B B
H =X , H =X ; (11)
1 1 1 1
A A B B B B
H =(X ,U ), H =(X ,U ), (12)
2 1 1 2 1 1
i.e. types are privateand actions areobservable.
TheinstantaneouspayoffsofAlice are given by
RA
=
−1, if U 1B =−1;
RA
=
1, if U 2A =X2 or U 2A =0;
.
1 2
(0, otherwise, (0, otherwise.
TheinstantaneouspayoffsofBob are given by
0.2, if UB =−1; −1, if UA =UB;
RB = 1 RB = 2 2 .
1 2
(0, otherwise, (0, otherwise.
Define KA = XA and KA = UB. It can be shown that KA is unilaterally sufficient
1 1 2 1
informationforAlice.4 SetKB =HB,i.e. nocompressionforBob’sinformation.Then,KB
t t
is trivially unilaterally sufficient informationforBob.
Proposition 1 In the game defined in Example 2, the set of K-based wPBE payoffs is a
proper subset of that of all wPBE payoffs.
Proof See Appendix D.1. (cid:3)
Note that since any wPBE is first and foremost a BNE, by Theorem 2, any general
strategybasedwPBEpayoffprofilecanbeattainedbyaK-basedBNE.However,Proposition
1 implies that there exists a wPBE payoff profile such that none of the K-based BNEs
attaining this payoffprofile arewPBEs.
Intuitively, the reason for some wPBE payoff profiles to be unachievable under
K-based wPBE payoffs in this example can be explained as follows. The state XA
1
in this game can be thought of as a private randomization device of Alice that is
payoffirrelevant(i.e. a privatecoin flip) that shouldnot play a rolein the outcomeof
the game. However,under the concept of wPBE, the presence of XA facilitates Alice
1
to implement off-equilibrium strategies that are otherwise not sequentially rational.
This holds due to the following: For a fixed realization of UB, the two realizations
1
of XA give rise to two different information sets. Under the concept of wPBE, if the
1
two information sets are both off equilibrium path, Alice is allowed to form different
beliefs andhencejustify the useofdifferentmixed actions under differentrealizations
of XA. Therefore, the presence of XA can expand Alice’s set of “justifiable” mixed
1 1
actions off-equilibrium. By restricting Alice to use KA-based strategies, i.e. choosing
4Infact,thisexamplecanbeseenasaninstanceofthemodeldescribedinExample6whichweintroduce
later.
15her mixed action not depending on XA, Alice loses the ability to use some mixed
1
actionsoff-equilibriumina“justifiable”manner,andhencelosingherpowertosustain
certainequilibriumoutcomes.Thisphenomenon,however,doesnothappenunderthe
concept of sequential equilibrium, since SE (quite reasonably) would require Alice to
usethesamebeliefontwoinformationsetsiftheyonlydifferintherealizationofXA.
1
With similar approaches, one can establish the analogue of Proposition 1 for the
perfect Bayesian equilibrium concept defined in Watson (2017) (which we refer to as
“Watson’s PBE”). Simply put, this is since Watson’s PBE imposes conditions on the
belief update for each pair of successive information states in a separated manner.
There exist no restrictions across different pairs of successive information states. As
a result, for a fixed realization of UB, Alice is allowed to form different beliefs under
1
tworealizations ofXA justlikeunder wPBEaslong asbothbeliefs arereasonableon
1
theirown.Infact,intheproofofProposition1,thetwooff-equilibriumbeliefupdates
both satisfy Watson’s condition of plain consistency (Watson, 2017).
Approaches similar to those in the proof of Proposition 1, however, do not apply
tothePBEconceptdefinedwiththeindependencepropertyofconditionalprobability
systemsspecifiedinBattigalli(1996)(whichwerefertoas“Battigalli’sPBE”).Infact,
Battigalli’s PBE is equivalent to sequential equilibrium if the dynamic game consists
of only two strategic players (Battigalli, 1996). We conjecture that in general games
with three or more players, if K is USI, then the set of all K-based Battigalli’s PBE
payoffs is the same as that of all Battigalli’s PBE payoffs. However, establishing this
result can be difficult due to the complexity of Battigalli’s conditions.
5.2 Information States in Specific Models
In this section, we identify MSI and USI in specific game models studied in the
literature. Whereas we recover some existing results using our framework, we also
develop some new results.
Example 3 Consider stateless dynamic games with observable actions, i.e. Xt = ∅,H 1i =
∅,Z ti =Utforalli∈I.Oneinstanceofsuchgamesistheclassofrepeatedgames(Fudenberg
and Tirole, 1991a). In this game, H ti = U1:t−1 for all i ∈ I. Let (ι0 t)t∈T be an arbitrary,
common update function and let Ki =K0 be generated from (ι0 t)t∈T. Then K is mutually
sufficient information since Lemma 1 is trivially satisfied. As a result, Theorem 1 holds for
K, i.e. there exist at least one K-based BNE.
However, in general, K is not unilaterally sufficient information. To see that, one can
consider the case when player j 6=i is using a strategy that chooses different mixed actions
fordifferentrealizationsofU1:t−1.InthiscasePgi,g−i (k˜ ti +1|hi t,ui t)wouldpotentiallydepend
onU1:t−1 asawhole.ThismeansthatKi isnotaninformationstateforplayeriunderg−i,
which violates Lemma 5.
Furthermore forK, the result of Theorem 2 does not necessarily hold, i.e. the set of K-
basedBNEpayoffsmaynotbethesameasthatofallBNE.Example1canbeusedtoshow
this.
16Example 4 Themodelof(Maskin andTirole, 2001)is aspecial case ofourdynamicgame
modelwhereZ ti =(Xt+1,Ut),i.e. the(pastandcurrent)statesandpastactionsareobserv-
able. In this case, K = (K ti)t∈T,i∈I with K ti = Xt is mutually sufficient information; note
that H ti = (X1:t,U1:t−1). Consider a K−i-based strategy profile ρ−i, i.e. ρj t: Xt 7→ ∆(U tj )
fort∈T,j ∈I\{i}. We have
Pgi,ρ−i (x˜t,k˜ t−i |hi t)=Pgi,ρ−i (x˜t,k˜ t−i |x1:t,u1:t−1) (13)
=1 1 (14)
{x˜t=xt} {k˜ tj=xt}
j Y6=i
=:Φ ti,ρ−i (x˜t,k˜ t−i |xt). (15)
HenceK ismutuallysufficientinformationbyLemma1.Asaresult,thereexistsatleast
oneK-based BNE.
SimilartoExample3,ingeneral,K isnotunilaterallysufficientinformation,andtheset
of K-based BNE payoffs may not be the same as that of all BNE. The argument for both
claims can be carried out in an analogousway to Example 3.
Example 5 The model of Nayyar et al (2013a) is a special case of our dynamic model
satisfying the following conditions.
(1) TheinformationofeachplayericanbeseparatedintothecommoninformationH0 and
t
privateinformationLi,i.e.thereexistsastrategy-independentbijectionbetweenHiand
t t
(H0,Li) forall i∈I.
t t
(2) The common information H0 can be sequentially updated,i.e.
t
Ht0 +1=(Ht0,Zt0), (16)
whereZ0 = Zi isthecommonpartofthenewinformationofallplayersattimet.
t i∈I t
(3) TheprivateiTnformationLi tcanbesequentiallyupdated,i.e.thereexistfunctions(ζ ti)T t=− 01
such that
i i i i
Lt+1 =ζt(Lt,Zt). (17)
In Nayyaret al (2013a),the authorsimpose the followingassumption.
Assumption 2 (Strategy independence of beliefs) There exist a function P0 such that
t
Pg(xt,lt|h0 t)=Pt0(xt,lt|h0 t), (18)
forall behavioralstrategy profiles g whenever Pg(h0 t)>0, where lt=(l ti)i∈I.
Inthismodel,ifweset K ti =(Πt,Li t)whereΠt ∈∆(Xt×St)isafunctionofH t0 defined
through
Πt(xt,lt):=Pt0(xt,lt|Ht0), (19)
thenK =(Ki)i∈I ismutuallysufficient information.First notethatK ti canbesequentially
updated as Πt can be sequentially updated using Bayesrule. Then
Pgi,ρ−i (x˜t,˜l t−i |hi t)=Pgi,ρ−i (x˜t,˜l t−i |h0 t,lti ) (20)
=
Pgi,ρ−i (x˜t,l ti,˜l t−i|h0 t)
(21)
Pgi,ρ−i(li|h0)
t t
17=
P t0(x˜t,(l ti,˜l t−i)|h0 t)
(22)
xˆt,ˆl−
tiP t0(xˆt,(l ti,ˆl t−i)|h0 t)
=
P πt(x˜t,(l ti,˜l t−i))
(23)
xˆt,ˆl−
tiπt(xˆt,(l ti,ˆl t−i))
=:PΦ˜ ti,ρ−i (x˜t,˜l t−i |kti ), (24)
for some function Φ˜ ti,ρ−i , where πt is the realization of Πt corresponding to H t0 = h0 t. In
steps (21) and (22) we apply Bayes rule on the conditional probabilities given h0, and we
t
use Assumption 2 to express thebelief with thestrategy-independent functionP0.
t
Note that K−i is contained in the vector(Ki,L−i), hence weconclude that
t t t
Pgi,ρ−i (x˜t,k˜ t−i |hi t)=:Φ ti,ρ−i (x˜t,k˜ t−i |kti ), (25)
i,ρ−i
forsomefunctionΦ .ByLemma1weconcludethatK ismutuallysufficientinformation.
t
Therefore there exists at least one K-based BNE.
SimilartoExamples3and4,ingeneral,K isnotunilaterallysufficient information,and
the set of K-based BNEpayoffsmay notbe thesame asthatofall BNE.Theargumentfor
both claims can be carried out in an analogouswayto Examples 3 and 4.
Example 6 ThefollowingmodelisavariantofOuyangetal(2016)andVasaletal(2019).
• Each player i is associated with a local state Xi, and X =(Xi) .
t t t i∈I
• Each player i is associated with a local noise process Wi, and W =(Wi) .
t t t i∈I
• There is no initial information, i.e. Hi =∅ for all i∈I.
1
• There is a public noisy observation Yi of the local state. The state transitions,
t
observation processes, and reward generation processes satisfy the following:
(Xi ,Yi)=fi(Xi,U ,Wi), ∀i∈I, (26)
t+1 t t t t t
Ri =ri(X ,U ), ∀i∈I. (27)
t t t t
• Theinformationplayerihasattime tisHi =(Y ,U ,Xi )fori∈I,where
t 1:t−1 1:t−1 1:t
Y =(Yi) .
t t i∈I
•
All the primitive random variables, i.e. the random variables in the collection
(Xi) ∪(Wi) , are mutually independent.
1 i∈I t i∈I,t∈T
Proposition 2 In the model of Example 6, K ti = (Y1:t−1,U1:t−1,X ti) is unilaterally
sufficient information.5
Proof See Appendix D.2. (cid:3)
5Ki-basedstrategiesinthissettingarecloselyrelatedtothe“strategiesoftypes”definedinVasaletal
(2019).InVasaletal(2019),theauthorsshowedthatstrategyprofilesoftypescanattainallequilibrium
payoffsattainablebygeneralstrategyprofiles.However,theauthorsdidnotshowthatstrategyprofilesof
typescandosowhilebeinganequilibrium.
18Finally, we note that the concept of USI is useful in the context of games among
teams as well. We omit the details of the following example due to its complicated
nature.
Example7 Inthemodelofgamesamongteamswithdelayedintra-teaminformationsharing
analyzed in Tang et al (2023), the authors defined the notion of sufficient private informa-
tion (SPI). It can be shown (through the arguments in (Tang et al, 2023, Section 4.3) and
(Tang, 2021, Chapters 4.6.1 and 4.6.2)) that Ki = (H0,Si), which consists of the common
t t t
information H0 and the SPI Si, is unilaterally sufficient information.
t t
6 An Open Problem
Identifying strategy-dependent compressionmaps thatguaranteeexistenceofatleast
oneequilibrium (BNE orSE) or maintain allequilibria that existunder perfect recall
is an open problem.
Aknownstrategy-dependentcompressionmapisonethatcompressseparatelyfirst
each agent’s private information, (resulting in “sufficient private information”), and
thentheagents’commoninformation(resultingin“commoninformationbased(CIB)
beliefs” on the system state and the agents’ sufficient private information (Ouyang
et al, 2015, 2016; Vasal et al, 2019; Tang et al, 2023; Ouyang et al, 2024)). Such
a compression does not possess any of the properties of the strategy-independent
compression maps that result in MSI or USI. The following example presents a game
where belief-based equilibria, i.e. equilibrium strategy profiles based on the above-
described compression, do not exist.
Example 8 Consider the following two-stage zero-sum game. The players are Alice (A)
and Bob (B). Alice acts at stage t = 1 and Bob at stage t = 2. The game’s initial state
X1 is distributed uniformly at random on {−1,+1}. Let H tA,H tB denote Alice’s and Bob’s
informationatstaget,andUA,UB denoteAlice’s andBob’sactionsatstaget,t=1,2.We
t t
assumethatH 1A=X1,H 1B =∅,i.e.AliceknowsX1 andBobdoesnot.Atstaget=1,Alice
choosesU 1A ∈{−1,1},andthestatetransitionisgivenbyX2 =X1·U 1A.Atstaget=2,we
assume that H 2A = (X1:2,U 1A) and H 2B = U 1A, i.e. Bob observes Alice’s action but not the
statebeforeorafterAlice’s action.At time t=2,Bobpicksanaction UB ∈{U,D}.Alice’s
2
instantaneousrewardsare given by
c if UA=+1;
2 if X2 =+1,U 2B =U;
R 1A = (0 if U1 1A=−1, and R 2A =  01 oif thX e2 rw= is− e,1,U 2B =D; (28)
where c∈(0,1/3).The stagereward forBob is R tB =−R tA fort=1,2.
The above game is a signaling game which can be represented in extensive form as in
Figure 2.
In order to define the concept of belief based equilibrium for this game, we specify
the common information H0, along with Alice’s and Bob’s private information, denoted by
t
LA,LB, respectively, fort=1,2 asfollows:
t t
H 10=∅, LA
1
=X1, LB
1
=∅, (29)
19(2,−2) (c,−c)
U U
Alice
−1 +1
(0,0) D −1[0.5] D (1+c,−1−c)
Bob N Bob
(0,0) +1[0.5] (2+c,−2−c)
U U
−1 +1
Alice
(1,−1) D D (c,−c)
Fig. 2 ExtensiveformofthegameinExample8.
H 20 =U 1A , LA
2
=X2, LB
2
=∅. (30)
We prove the following result.
Proposition 3 In the game of Example 8 belief-based equilibria do not exist.
Proof See Appendix D.3. (cid:3)
7 Conclusion
In this paper, we investigated sufficient conditions for strategy-independent compres-
sion maps to be viable in dynamic games. Motivated by the literature on information
states for control problems (Kumar and Varaiya, 2015; Mahajan and Mannan, 2016;
Subramanian et al, 2022), we provided two notions of information state, both result-
ing in from strategy-independent information compression maps for dynamic games,
namely mutually sufficient information (MSI) and unilaterally sufficient information
(USI).WhileMSIguaranteestheexistenceofcompression-basedequilibria,USIguar-
anteesthatcompression-basedequilibriacanattainallequilibriumpayoffprofilesthat
areachievedwhenallagentshaveperfectrecall.Weestablishedtheresultsunderboth
theconceptsofBayes-Nashequilibriumandsequentialequilibrium.Wediscussedhow
USIdoes notguaranteethepreservationofpayoffprofilesunder certainotherequilib-
rium refinements. We considered a strategy-depedent compression map that results
in sufficient private information, for each agent, along with a CIB belief. We showed,
by an example, that this information compression map does not possess any of the
properties of the strategy-independent compression maps that result in MSI or USI.
The discovery of strategy-dependent information compression maps that lead to
results similar to those ofTheorem 1 and3 or to those ofTheorems 2and 4 is a chal-
lenging open problem of paramount importance. Another important open problem is
the discovery of information compression maps under which certain subsets of equi-
libriumpayoffprofilesareattainedwhenstrategiesbasedontheresulting compressed
20information are used. The results of this paper have been derived for finite-horizon
finitegames.Theextensionoftheresultstoinfinite-horizon gamesandtogameswith
continuous action and state spaces are other interesting technical problems.
Author Contributions
This work is a collaborative intellectual effort of the three authors, with Dengwang
Tangbeingtheleader.Duetotheinterconnectednatureoftheresults,itisimpossible
to separate the contributions of each author.
Funding
This work is supported by National Science Foundation (NSF) Grant No. ECCS
1750041, ECCS 2025732, ECCS 2038416, ECCS 1608361, CCF 2008130, CMMI
2240981,ArmyResearchOffice(ARO)AwardNo.W911NF-17-1-0232,andMichigan
Institute for Data Science (MIDAS) Sponsorship Funds by General Dynamics.
Data Availability
Not applicable since all results in this paper are theoretical.
Declarations
Conflict of Interest
The authors have no competing interests to declare that are relevant to the content
of this article.
Ethical Approval
Not applicable since no experiments are involved in this work.
Appendix A Information State of Single-Agent
Control Problems
In this section we consider single-agent Markov Decision Processes (MDPs) and
developauxiliaryresults.This sectionisarecapofMahajanandMannan(2016)with
more detailed results and proofs.
Let X be a controlled Markov Chain controlled by action U with initial distri-
t t
bution ν ∈ ∆(X ) and transition kernels P = (P ) ,P : X ×U 7→ ∆(X ). Let
1 1 t t∈T t t t t+1
r = (r ) ,r : X ×U 7→ R be a collection of instantaneous reward functions. An
t t∈T t t t
MDP is denoted by a tuple (ν ,P,r).
1
For a Markov strategy g = (g t) t∈T,g t: X
t
7→ ∆(U t), we use Pg,ν1,P and Eg,ν1,P
to denote the probabilities of events and expectations of random variables under the
distributionspecifiedbycontrolledMarkovChain(ν ,P)andstrategyg.When(ν ,P)
1 1
is fixed and clear from the context, we use Pg and Eg respectively.
21Define the total expected reward in the MDP (ν ,P,r) under strategy g by
1
T
J(g;ν 1,P,r):=Eg,ν1,P r t(X t,U t) . (A1)
" #
t=1
X
Define the value function and state-action quality function by
T
V τ(x τ;P,r):=maxEgτ:T,P r t(X t,U t)|x
τ
, ∀τ ∈[T +1], (A2)
gτ:T "
t=τ
#
X
Q (x ,u ;P,r):=r (x ,u )+ V (x˜ )P (x˜ |x ,u ), ∀τ ∈[T]. (A3)
τ τ τ τ τ τ τ+1 τ+1 τ τ+1 τ τ
x˜ Xτ+1
Note that V (·;P,r)≡0.
T+1
Definition 6 (Mahajan and Mannan, 2016) Let Kt = Ψt(Xt) for some function Ψt.
Then, Kt is called an information state for (P,r) if there exist functions P tK: Kt×Ut 7→
∆(Kt+1),r tK: Kt×Ut 7→R such that
(1) Pt(kt+1|xt,ut)=P tK(kt+1|Ψt(xt),ut); and
(2) rt(xt,ut)=r tK(Ψt(xt),ut).
If K is an information state, then K is also a controlled Markov Chain with
t t
initial distribution νK ∈∆(K ) and transition kernel PK =(PK) , where
1 1 t t∈T
νK(k )= 1 ν (x ).
1 1 {k1=Ψ1(x1)} 1 1
Xx1
The tuple (νK,PK,rK) defines a new MDP. For a K-based strategy ρ =
1
(ρ ) ,ρ : K 7→ ∆(U ), the J,V,Q functions can be defined as above for the new
t t∈T t t t
MDP.
Westatethefollowingstandardresult(see,forexample,Section2ofSubramanian
et al (2022)).
Lemma 2 Let Kt =Ψt(Xt) be an information state for (P,r). Then
(1) Vt(xt;P,r)=Vt(Ψt(xt);PK,rK) for all xt;
(2) Qt(xt,ut;P,r)=Qt(Ψt(xt),ut;PK,rK) for all xt,ut.
Definition 7 Let g be a Markov strategy, an K-based strategy ρ is said to be associated
with g if
ρt(kt)=Eg,ν1,P
[gt(Xt)|kt], (A4)
whenever Pg,ν1,P(kt)>0.
22The following lemma will be used in the proofs in Appendix C.
Lemma 3(PolicyEquivalenceLemma) Let (ν1,P,r)beanMDP.LetKt beaninformation
state for (P,r). Let an K-based strategy ρ be associated with a Markov strategy g, then
(1) Pg,ν1,P(kt)=Pρ,ν1,P(kt) for all kt ∈Kt and t∈T;
(2) J(g;ν1,P,r)=J(ρ;ν1,P,r).
Proof Inthisproofallprobabilitiesandexpectationsareassumedtobedefinedwith(ν1,P).
Given a Markovstrategy g,let ρ be an informationstate-based strategy that satisfies (A4).
First, we have
Pg (ut|kt)=Eg
[gt(ut|Xt)|kt]=ρt(ut|kt), (A5)
forall kt such that Pg(kt)>0.
(1) Proof by induction:
Induction Base: We have Pg(k1) = Pρ(k1) since the distribution of K1 = Ψ1(X1) is
strategy-independent.
Induction Step: Supposethat
Pg (kt)=Pρ
(kt), (A6)
for all kt ∈ Kt. We prove the result for time t+1. Combining (A5) and (A6), and
incorporatingtheinformationstatetransitionkernelPK definedinDefinition6,wehave
t
Pg(kt+1)= Pg(kt+1|k˜ t,u˜t)Pg(u˜t|k˜ t)Pg(k˜ t) (A7)
k˜ Xt,u˜t
= PtK (kt+1|k˜ t,u˜t)ρt(ut|k˜ t)Pρ (k˜ t) (A8)
k˜ Xt,u˜t
=Pρ
(kt+1). (A9)
Therefore wehaveestablished theinduction step.
(2) Using (A5)(A6) along with the result of part (1),we obtain
Eg [rt(Xt,Ut)]=Eg [rtK
(Kt,Ut)] (A10)
= rtK (k˜ t,u˜t)Pg (u˜t|k˜ t)Pg (k˜ t) (A11)
k˜ Xt,u˜t
= rtK (k˜ t,u˜t)ρt(u˜t|k˜ t)Pρ (k˜ t) (A12)
k˜ Xt,u˜t
=Eρ
[rt(Xt,Ut)], (A13)
foreach t∈T. The result then followsfrom linearity of expectation.
This concludes the proof. (cid:3)
23Appendix B Alternative Characterizations of
Sequential Equilibria
This section deals with the game model introduced in Section 2. We provide three
alternative definitions of sequential equilibria that are equivalent to the original one
given by Kreps and Wilson (1982). These definitions help simplify some of the proofs
in Appendix C.
Wewouldliketonotethatseveralalternativedefinitionsofsequentialequilibriaare
alsogiveninKrepsandWilson(1982);Halpern(2009).Thedefinitionofweakperfect
equilibrium in Proposition 6 of Kreps and Wilson (1982) is close to our definitions in
spirit in terms of using sequences of payoff functions instead of beliefs as a vehicle to
define sequential rationality.
Notice that fixing the behavioral strategies g−i of players other than player i,
player i’s best response problem (at every information set) can be considered as a
Markov Decision Process with state Hi and action Ui, where the transition kernels
t t
and instantaneous reward functions depend on g−i. Inspired by this observation, we
introduce an alternative definition of sequential equilibrium for our model, where we
form conjectures of transition kernels and reward functions instead of forming beliefs
on nodes. This allows us for a more compact representation of the appraisals and
beliefs of players. We will later show that this alternative definition is equivalent to
the classical definition of sequential equilibrium in Kreps and Wilson (1982).
For player i ∈ I, let Pi = (Pi) ,Pi: Hi × Ui 7→ ∆(Zi) and ri =
t t∈T\{T} t t t t
(ri) ,ri: Hi ×Ui 7→ [−1,1] be collections of functions that represent conjectures
t t∈T t t t
of transition kernels and instantaneous reward functions. For a behavioral strategy
profile gi, define the reward-to-go function Ji recursively through
t
Ji(gi ;hi ,Pi,ri):= ri (hi ,u˜i )gi (u˜i |hi ); (B14a)
T T T T T T T T T
Xu˜i
T
Ji(gi ;hi,Pi,ri) (B14b)
t t:T t
:= ri(hi,u˜i)+ Ji (gi ;(hi,z˜i),Pi,ri)Pi(z˜i|hi,u˜i) gi(u˜i|hi). (B14c)
 t t t t+1 t+1:T t t t t t t  t t t
Xu˜i
t
Xz˜ ti
 
Definition 8 (“Model-based” Sequential Equilibrium) Let g = (gi)i∈I be a behavioral
strategy profile. Let (P,r) = (Pi,ri)i∈I be a conjectured profile. Then, g is said to be
sequentially rationalunder(P,r) if foreach i∈I,t∈T and each hi ∈Hi,
t t
i i i i i i i i i i
Jt(g t:T;ht,P ,r )≥Jt(g˜ t:T;ht,P ,r ), (B15)
forallbehavioralstrategiesg˜i .Conjecturedprofile(P,r)issaidtobefullyconsistentwith
t:T
g ifthereexistasequenceofbehavioralstrategyandconjectureprofiles(g(n),P(n),r(n))∞
n=1
such that
(1) g(n) is fully mixed, i.e. every action is chosen with positive probability at every
information set.
24(2) For each i ∈I, (P(n),i,r(n),i) is consistent with g(n),−i, i.e. for each i ∈I,t ∈T,hi ∈
t
Hi,ui ∈Ui,
t t t
P
t(n),i (zti |hi t,ui t)=Pg(n),−i (zti |hi t,ui
t), (B16)
r
t(n),i (hi t,ui t)=Eg(n),−i [Rti |hi t,ui
t]. (B17)
(3) (g(n),P(n),r(n))→(g,P,r) as n→∞.
A triple (g,P,r) is said to be a “model-based” sequential equilibrium6 if g is sequentially
rationalunder (P,r) and (P,r) is fully consistent with g.
One can also form conjectures directly on the optimal reward-to-go given a state-
action pair (hi,ui).
t t
Definition 9 (“Model-free”SequentialEquilibrium, Definition2revisited) Let g=(gi)i∈I
be a behavioral strategy profile. Let Q = (Qi t)i∈I,t∈T be a collection of functions where
Qi: Hi×Ui 7→[−T,T]. The strategy profile g is said to be sequentially rationalunder Q if
t t t
foreach i∈I,t∈T and each hi ∈Hi,
t t
i i i i i
supp(gt(ht))⊆argmax Qt(ht,ut). (B18)
ui
t
ThecollectionoffunctionsQissaidtobefullyconsistentwithg ifthereexistasequence
of behavioralstrategy and conjectured profiles (g(n),Q(n))∞ such that
n=1
(1) g(n) is fully mixed, i.e. every action is chosen with positive probability at every
information set.
(2) Q(n) is consistent with g(n), i.e.,
T
Qτ(n),i (hi τ,ui τ)=Eg(n) Rti hi τ,ui
τ , (B19)
"t X=τ (cid:12) #
foreach i∈I,τ ∈T,hi τ ∈Hi τ,ui τ ∈Uτi. (cid:12) (cid:12)
(3) (g(n),Q(n))→(g,Q) as n→∞.
Atuple(g,Q)issaidtobea“model-free”sequentialequilibriumifg issequentiallyrational
under Q and Q is fully consistent with g.
A slightly different definition is also equivalent:
Definition 10 (“Model-free” Sequential Equilibrium, Version 2) A tuple (g,Q) is said to
bea“model-free”sequentialequilibrium(version2)ifitsatisfiesDefinition9withcondition
(2) forfull consistency replaced by the followingcondition:
(2’) For each i, Q(n),i is consistent with g(n),−i, i.e.
T
Q τ(n),i(hi τ,ui τ)=Eg(n),−i [R τi|hi τ,ui τ]+ max Eg˜ τi +1:T,g(n),−i R ti hi τ,ui
τ
,
g˜i " #
τ+1:T t= Xτ+1 (cid:12)
(cid:12)
(cid:12)
6Hereweborrowtheterms“model-based”(resp.“model-free”)fromthereinforcementlearningliterature:
“Model-based”meansthatanalgorithmconstructstheunderlyingmodel(P,r),while“model-free”usually
meansthatthealgorithmdirectlyconstructsstate-actionvaluefunctionsQ.
25for each τ ∈T,hi ∈Hi,ui ∈Ui.
τ τ τ τ
To introduce thelastdefinition ofSE,whichcorrespondsto the originaldefinition
proposed in Kreps and Wilson (1982), we first describe the game in Section 2 as an
extensive-form game tree as follows: To convert the game from a simultaneous move
game to a sequential game, we set I = {1,2,··· ,I}, where the index indicates the
order of movement. For convenience, for i ∈ I, we use the superscript < i (resp.
> i) to represent the set of players {1,··· ,i−1} (resp. {i+1,··· ,I}) that moves
before (resp. after) player i in any given round. At time t = 0, nature takes action
w = (x ,h ) and the game enters t = 1. For each time t ∈ T, player 1 takes
0 1 1
action u1 first, then followed by player 2 taking action u2, and so on, while nature
t t
takes action w after player I takes action uI. In this extensive form game, there
t t
are three types of nodes: (1) a node where some player i ∈ I takes action (at some
time t ∈ T), (2) a node where nature takes action (at some time t ∈ {0} ∪ T),
and (3) a terminal node, where the game has terminated. We denote the set of the
first type of nodes corresponding to player i and time t as Oi. A node oi ∈ Oi
t t t
can also be represented as a vector oi = (x ,h ,w ,u ,u<i) which contains
t 1 1 1:t−1 1:t−1 t
all the moves (by all players and nature) before it. As a result, oi also uniquely
t
determines the states x and information increment vectors z . We denote the
1:t 1:t−1
set of the terminal nodes as O . A terminal node o ∈ O also has a vector
T+1 T+1 T+1
representation o =(x ,h ,w ,u ).
T+1 1 1 1:T 1:T
Given a terminal node o , all the actions of players and nature throughout the
T+1
game are uniquely determined, hence the realizations of (R ) defined in Section 2
t t∈T
are also uniquely determined. Let Λ=(Λi) ,Λi: O 7→R be the mappings from
i∈I T+1
terminal nodes to total payoffs,i.e. Λi(o )= T ri, where ri is the realization of
T+1 t=1 t t
Ri corresponding to o . Also define Λi(o )= T ri for each τ ∈T.
t T+1 τ T+1P t=τ t
Now, as we have constructed the extensive-form game, it is helpful to view the
nodes in the game tree as a stochastic process. DeP fine Oi to be a random variable
t
with support on Oi that represents the node player i is at before taking action at
t
time t. Let O be a random variable with support on O that represents the
T+1 T+1
terminal node the game ends at. If we view (T ×I)∪{T +1} as a set of time indices
withlexicographicordering,therandomprocess(Oi) ∪(O )isacontrolled
t (t,i)∈T×I T+1
Markov Chain controlled by action Ui at time (t,i).
t
Definition 11 (ClassicalSequentialEquilibrium(KrepsandWilson,1982)) Anassessment
is a pair (g,µ), where g is a behavioral strategy profile of players (excluding nature) as
described in Section 2, and µ=(µi t)t∈I,i∈I,µi t: Hi
t
7→ ∆(O ti) is a belief system. Then, g is
said to be sequentially rationalgiven µ if
Eg ti :T,g t>i,g t− :Ti [Λi (OT+1)|oi t]µi t(oi t|hi
t)≥
Eg˜ ti :T,g t>i,g t− :Ti [Λi (OT+1)|oi t]µi t(oi t|hi
t), (B20)
Xoi
t
Xoi
t
foralli∈I,t∈T,hi ∈Hi,andallbehavioralstrategiesg˜i .Thebelief systemµissaid to
t t t:T
be fully consistent with g if there exist a sequence of assessments (g(n),µ(n))∞ → (g,µ)
n=1
such that g(n) is a fully mixed strategy profile and
(1) g(n) is fully mixed.
26(2) µ(n) is consistent with g(n), i.e. µ(n),i (oi|hi)=Pg(n) (oi|hi) for all t∈T,i∈I,hi ∈Hi,
t t t t t t t
and oi ∈Oi.
t t
(3) (g(n),µ(n))→(g,µ) as n→∞.
An assessment (g,µ) is said to be a (classical) sequential equilibrium if g is sequentially
rationalgiven µ and µ is fully consistent with g.
Remark 4 Since the instantaneous rewards Ri have already been realized at time t,
1:t−1
replacing the total reward Λ with reward-to-go Λt in (B20) would result in an equivalent
definition.
Theorem 5 Definitions 8, 9, 10, and 11 are equivalent for strategy profiles.
Proof We complete the proof via four steps: In each step, we show that if g is a strategy
profile satisfying one definition of SE, then it satisfy one of the other definitions of SE
as well. We follow the following diagram: Definition 11 ⇒ Definition 8 ⇒ Definition 9 ⇒
Definition 10⇒ Definition 11.
Step 1: Classical SE (Definition 11) ⇒ “Model-based”SE (Definition 8)
Let(g,µ)satisfyDefinition11.Let(g(n),µ(n))beasequenceofassessmentsthatsatisfies
conditions (1)-(3)of fully consistency in Definition 11.
Set P(n),i (zi|hi,ui) = Pg(n) (zi|hi,ui) and r(n),i (hi,ui) = Eg(n) [Ri|hi,ui] for all hi ∈
t t t t t t t t t t t t t t
Hi,ui ∈Ui.
t t t
Recall that we can write O ti = (X1,H1,W1:t−1,U1:t−1,U t<i), and (X1:t,Z1:t−1) can
be expressed as a function of Oi. Therefore there exist fixed functions fi,Z ,fi,R such that
t t t
Z ti = f ti,Z (O ti,U ti,U t>i,Wt), R ti = f ti,R (O ti,U ti,U t>i,Wt). Furthermore, for all j > i, there
also exists functions fj,i,H such that Hj = fj,i,H (Oi) (since Hj = (Hi,Zi )). Since
t t t t t 1 1:t−1
µ(n),i (oi|hi)=Pg(n) (oi|hi) we have
t t t t t
(n),i i i i
P
t
(zt|ht,ut)
I (B21)
= 1 {z ti=f ti,Z(oi t,ui t,u˜> ti,w˜t)}P(w˜t)  g t(n),j (u˜j t|f tj,i,H (oi t)) µ t(n) (oi t|hi t),
oi t,u˜X> ti,w˜t j= Yi+1
 
(n),i i i
r
t
(ht,ut)
I (B22)
= f ti,R (oi t,ui t,u˜>
t
i ,w˜t)P(w˜t)

g t(n),j (u˜j t|f tj,i,H (oi t)) µ t(n) (oi t|hi t).
oi t,u˜X> ti,w˜t j= Yi+1
 
Therefore, asµ(n) →µ, g(n)→g, wehave(P(n),r(n))→(P,r) forsome (P,r).
Let τ ∈ T and g˜i be an arbitrary strategy. First, observe that one can represent the
τ:T
conditionalreward-to-goEg(n) [ T t=τR ti|hi τ] using µ(n) or(P(n),r(n)). Hence we have
Eg˜ τi :T,g τ(n),>i,g τ(n +) 1,− :Ti [Λi τ(OP T+1)|oi τ]µτ(n),i (oi τ|τti)=Jti(g˜ τi :T;hi τ,P(n),i,r(n),i),
(B23)
Xoi
τ
27where Ji is asdefined in (B14).
t
(n),>i (n),−i (n),i
Observethattheleft-handsideof (B23)iscontinuousin(gτ ,g τ+1:T,µτ )sinceit
(n),>i (n),−i (n),i
is a sum of products of components of (gτ ,g τ+1:T,µτ ). Also observe that the right-
handsideof (B23)iscontinuousin(P(n),i,r(n),i)sinceitisasumofproductsofcomponents
of(P(n),i,r(n),i)bythedefinitionin(B14).Thereforebytakinglimitasn→∞,weconclude
that
Eg˜ τi :T,g−i [Λi τ(OT+1)|oi τ]µi τ(oi τ|hi τ)=Jτi
(g˜
τi :T;hi τ,Pi ,ri
), (B24)
Xoi
τ
for all strategies g˜i . Using sequential rationality of g with respect to µ and (B24) we
τ:T
conclude that
i i i i i i i i i i
Jt(g τ:T;hτ,P ,r )≥Jt(g˜ τ:T;hτ,P ,r ), (B25)
forall τ ∈T,i∈I,hi τ ∈Hi τ, i.e. g is also sequentially rationalgiven (P,r).
Step 2: “Model-based”SE (Definition 8) ⇒ “Model-free”SE version 1 (Definition 9)
Let (g,P,r) be a sequential equilibrium under Definition 8, and let (g(n),P(n),r(n))
satisfy conditions (1)-(3)of full consistency in Definition 8. Set
T
Qτ(n),i (hi τ,ui τ)=Eg(n) Rti hi τ,ui
τ , (B26)
"t X=τ (cid:12) #
(cid:12)
forall τ ∈T,i∈I,hi τ ∈Hi τ,ui τ ∈Uτi. Then Q(n),i satisfi(cid:12)es the recurrence relation
(n),i i i (n),i i i
Q (h ,u )=r (h ,u ), (B27a)
T T T T T T
V t(n),i (hi t):= Q t(n),i (hi t,u˜i t)g t(n),i (u˜i t|hi t), ∀t∈T, (B27b)
Xu˜i
t
(n),i i i (n),i i i
Q
t
(ht,ut)=r
t
(ht,ut) (B27c)
(n),i i i (n),i i i i
+ V
t+1
((ht,z˜t))P
t
(z˜t|ht,ut), ∀t∈T\{T}. (B27d)
Xz˜ ti
Since(g(n),P(n),r(n))→(g,P,r)asn→∞,wehaveQ(n)→QwhereQ=(Qi t)t∈T,i∈I
satisfies
i i i i i i
Q (h ,u )=r (h ,u ), (B28a)
T T T T T T
i i i i i i i i
Vt(ht):= Qt(ht,u˜t)gt(u˜t|ht), ∀t∈T, (B28b)
Xu˜i
t
i i i i i i
Qt(ht,ut)=rt(ht,ut)
+ V ti +1((hi t,z˜ti))Pti(z˜ti|hi t,ui t), ∀t∈T\{T}. (B28c)
Xz˜ ti
Comparing (B28)with thereward-to-gofunction Ji defined in (B14), weobserve that
t
i i i i i i i
Vt(ht)=Jt(g t:T;ht,P ,r ), (B29)
forall t∈T,i∈I,hi τ ∈Hi τ.
Let g˜i be a strategy such that gˆi(hi)=η∈∆(Ui), then
t t t t
i i i i i i
Jt((g˜t,g t+1:T);ht,P ,r ) (B30)
28i i i i i i i i i i i i i i
= rt(ht,u˜t)+ J t+1(g t+1:T;(ht,z˜t),P ,r )Pt(z˜t|ht,u˜t) η(u˜t) (B31)
Xu˜t Xz˜ ti
 
i i i i i i i i i i i
= rt(ht,u˜t)+ V t+1((ht,z˜t))Pt(z˜t|ht,u˜t) η(u˜t) (B32)
 
Xu˜t Xz˜ ti
 
= Qi t(hi t,uˆi t)η(u˜i t), (B33)
Xu˜t
where wesubstitute (B14)in (B31), (B29)in (B32), and (B28c)in (B33).
By sequential rationality of g with respect to (P,r), wehave
i i i i i i i i i i i
Jt(g t:T;ht,P ,r )≥Jt((g˜t,g t+1:T);ht,P ,r ),
which means that
i i i i i i i i i i
Qt(ht,u˜t)gt(u˜t|ht)≥ Qt(ht,u˜t)η(u˜t), (B34)
Xu˜t Xu˜t
for all η ∈ ∆(U ti) for all t ∈ T,i ∈ I,hi τ ∈ Hi τ. Hence g is sequentially rational given Q.
Therefore(g,Q) is a sequential equilibrium under Definition 9.
Step 3: “Model-free” SE version 1 (Definition 9) ⇒ “Model-free” SE version 2 (Defini-
tion 10)
Let (g,Q) be a sequential equilibrium under Definition 9 and let (g(n),Q(n)) satisfies
conditions (1)-(3)of full consistency in Definition 9. Then Q(n),i satisfies
Q(n),i (hi ,ui )=Eg(n),−i [Ri |hi ,ui
], (B35a)
T T T T T T
(n),i i (n),i i i (n),i i i
V
t
(ht):= Q
t
(ht,u˜t)g
t
(u˜t|ht), ∀t∈T, (B35b)
Xu˜i
t
Q
t(n),i (hi t,ui t)=Eg(n),−i [Rti |hi t,ui
t]
+ V
t( +n 1),i ((hi t,z˜ti ))Pg(n),−i (z˜ti |hi t,ui
t), ∀t∈T\{T}, (B35c)
Xz˜ ti
and Q(n)→Q asn→∞. Set
T
Qˆ τ(n),i (hi τ,ui τ)=Eg(n),−i [Rτi |hi τ,ui τ]+ max Eg˜ τi +1:T,g(n),−i Rti hi τ,ui τ , (B36)
g˜i  
τ+1:T t= Xτ+1 (cid:12)
(cid:12)
foreach τ ∈T,hi τ ∈Hi τ,ui τ ∈Uτi. Then Qˆ(n),i satisfies the recu rrence rela(cid:12) tion 
Qˆ(n),i (hi ,ui )=Eg(n),−i [Ri |hi ,ui
], (B37a)
T T T T T T
Vˆ t(n),i (hi t):=maxQˆ t(n),i (hi t,u˜i t), ∀t∈T, (B37b)
u˜i
t
Qˆ t(n),i (hi t,ui t)=Eg(n),−i [Rti |hi t,ui t]
+ Vˆ t( +n 1),i ((hi t,z˜ti ))Pg(n),−i (z˜ti |hi t,ui t), ∀t∈T\{T}. (B37c)
Xz˜ ti
Claim: Qˆ(n) →Qi asn→∞.
t t
29Given the claim, we have (g(n),Qˆ(n)) satisfying conditions (1)(2’)(3) of full consistency
in Definition 10. Therefore (g,Q) is also a sequential equilibrium under Definition 10, and
we complete this part of theproof.
Proof of Claim: By induction on time t∈T.
Induction Base: ObservethatQˆ T(n) =Q T(n) byconstruction. SinceQ T(n) →QT wealso
haveQˆ( Tn)
→QT.
Induction Step: Supposethat the result is true fortime t.We proveit fortime t−1.
By induction hypothesis and g(n)→g,we have
Vˆ t(n),i (hi t)=maxQˆ t(n),i (hi t,u˜i t)−n −→ −−∞ →maxQi t(hi t,u˜i t). (B38)
u˜i u˜i
t t
Since Q(n)→Q and g(n)→g, wehave
V t(n),i (hi t)= Q t(n),i (hi t,u˜i t)g t(n),i (u˜i t|hi t) (B39)
Xu˜i
t
n→∞ i i i i i i i i
−−−−→ Qt(ht,u˜t)gt(u˜t|ht)=:Vt(ht). (B40)
Xu˜i
t
Since g is sequentially rationalgiven Q,we have
i i i i i i i i i
Qt(ht,u˜t)gt(u˜t|ht)=maxQt(ht,u˜t). (B41)
u˜i
Xu˜i
t
t
Combining (B38)(B40)(B41)we haveVˆ(n),i (hi)→Vi(hi) forall hi ∈Hi. Since Hi is a
t t t t t t t
finite set, we have
max|Vˆ t(n),i (h˜i t)−V t(n),i (h˜i t)|−n −→ −−∞ →0. (B42)
h˜i
t
We then have
|Qˆ t( −n) 1,i (hi t,ui t)−Q t( −n) 1,i (hi t,ui t)| (B43)
=
(cid:12)
Vˆ t(n),i ((hi t−1,z˜ti −1))−V t(n),i ((hi t−1,z˜ti −1)) Pg t( −n) 1,−i (z˜ti −1|hi t−1,ui t−1)
(cid:12)
(B44)
(cid:12) (cid:12)
(cid:12) (cid:12)z˜Xti −1h i (cid:12)
(cid:12)
≤m(cid:12) (cid:12)
(cid:12)
z˜iax|Vˆ t(n),i ((hi t−1,z˜ti −1))−V t(n),i ((hi t−1,z˜ti −1))|−n −→ −−∞ →0, (cid:12) (cid:12)
(cid:12)
(B45)
t−1
where we substitute (B35c)(B37c) in (B44). Since Q(n),i (hi,ui) → Qi (hi,ui), we con-
t−1 t t t−1 t t
clude that Qˆ(n),i (hi,ui)→Qi (hi,ui), establishing theinduction step.
t−1 t t t−1 t t
Step 4: “Model-free” SE version 2 (Definition 10)⇒ Classical SE(Definition 11)
Let (g,Q) be a sequential equilibrium under Definition 10 and let (g(n),Qˆ(n)) satisfies
conditions (1)(2’)(3) offull consistency in Definition 10.
Define the beliefs µ(n) on the nodes of the extensive-form game through µ(n)(oi|hi) =
t t
Pg(n) (oi|hi). By taking subsequences, without lost of generality, assume that µ(n) →µ.
t t
Let gˆi be an arbitrary strategy, then by condition (2’) of Definition 10,wecan write
t
Qˆ t(n),i (hi t,u˜i t)gˆti (u˜i t|hi t)
Xu˜i
t
(B46)
= max
Egˆ ti,g˜ ti +1:T,g t(n),>i,g t( +n) 1, :− Ti [Λi t(OT+1)|oi
t] µ
t(n),i (oi t|hi
t).
g˜i
t+1:T Xoi
t
30Foreachoi t,Eg˜ t≥i,g˜t+1:T[Λi t(Ot+1)|oi t]iscontinuousin (g˜ t≥i ,g˜t+1:T)since it is thesumof
product of componentsof (g˜
t≥i
,g˜t+1:T). Therefore,
Egˆ ti,g˜ ti +1:T,g t(n),>i,g t( +n) 1, :− Ti [Λi t(Ot+1)|oi
t] µ
t(n),i (oi t|hi
t)
Xoi
t
−n −→ −−∞ → Egˆ ti,g˜ ti +1:T,g t>i,g t− +i 1:T[Λi t(Ot+1)|oi t] µi t(oi t|hi t), (B47)
Xoi
t
for each behavioral straetegy g˜i . Applying Berge’s Maximum Theorem (Sundaram,
t+1:T
1996),and taking the limit on both sides of (B46), we obtain
Qi t(hi t,u˜i
t)
gˆti (u˜i t|hi
t)= max
Egˆ ti,g˜ ti +1:T,g t>i,g t− +i 1:T[Λi t(OT+1)|oi
t]
µi t(oi t|hi
t), (B48)
g˜i
Xu˜i
t
t+1:T Xoi
t
forall t∈T,i∈I,hi ∈Hi, and all behavioralstrategy gˆi.
t t t
Sequential rationality ofg to Q means that
i i i i i i i
gt ∈argmax Qt(ht,u˜t) gˆt(u˜t|ht)
gˆ ti Xu˜i
t
(B49)
=argmax max
Egˆ ti,g˜ ti +1:T,g t>i,g t− +i 1:T[Λi t(OT+1)|oi
t]
µi t(oi t|hi
t),
gˆ ti g˜ ti +1:T Xoi
t
forall t∈T,i∈I, andall hi ∈Hi.
t t
RecallthatthenodeO ti uniquelydetermines(X1,W1:t−1,U1:t−1).Therefore,theinstan-
taneous rewards Rτi for τ ≤ t−1 are uniquely determined by O ti as well. For τ ≤ t−1,
let rτi be realizations of Rτi under O ti = oi t. Recall that Λi is the total reward func-
tion and Λi is the reward-to-go function starting with (and including) time t. We have
t
Egˆ ti,g˜ ti +1:T,g t>i,g t− +i 1:T[Λi(OT+1)−Λi t(OT+1)|oi t]= t τ− =1 1rτi tobeindependentofthestrategy
profile. Therefore wehave
P
gti
∈argmax max
Egˆ ti,g˜ ti +1:T,g t>i,g t− +i 1:T[Λi (OT+1)|oi
t]
µi t(oi t|hi
t). (B50)
gˆ ti g˜ ti +1:T Xoi
t
Fixing hi τ, the problem ofoptimizing
Jτi
(g˜
τi :T;hi τ,µi
τ):=
Eg˜ τi :T,g τ>i,g τ− +i 1:T[Λi (OT+1)|oi
τ]
µi τ(oi τ|hi
τ), (B51)
Xoi
τ
overall g˜i is a POMDP problem with
τ:T
• Timestamps T˜={τ,τ +1,··· ,T,T +1};
• State process (O ti)T
t=τ
∪(OT+1);
• Controlactions (Ui)T ;
t t=τ
• Initial state distribution µi τ(hi τ)∈∆(Oτi);
• State transition kernel Pg t>i,g t< +i 1(oi t+1|oi t,ui t) fort<T and Pg T>i (oT+1|oi T,ui T) fort=T;
• Observation history: (Hi)T ;
t t=τ
• Instantaneousrewardsare 0. Terminalreward is Λi(OT+1).
The belief µ is fully consistent with g by construction. From standard results in game
theory,weknowthatµi (hi )canbeupdatedwithBayesrulefromµi(hi)andgwhenever
t+1 t+1 t t
applicable.Therefore,(µt)T
t=τ
representthetruebeliefsofthestategivenobservationsinthe
31above POMDP problem. Therefore, through standard control theory (Kumar and Varaiya,
2015,Section6.7),(B50)isasufficientconditionforgi tobeoptimalfortheabovePOMDP
t:T
problem, which means that g is sequentially rationalgiven µ.
Therefore weconclude that (g,µ) is a sequential equilibrium underDefinition 11.
(cid:3)
Appendix C Proofs for Sections 3 and 4
C.1 Proof of Lemma 1
Lemma4 (Lemma1,restated) Ifforalli∈I andallK−i-based strategy profilesρ−i,there
exist functions (Φ ti,ρ−i )t∈T where Φ ti,ρ−i : K ti 7→∆(Xt×K t−i) such that
Pgi,ρ−i
(xt,k
t−i |hi
t)=Φ
ti,ρ−i
(xt,k
t−i |kti
), (C52)
for all behavioral strategies gi, all t ∈ T, and all hi admissible under (gi,ρ−i), then K =
t
(Ki)i∈I is mutually sufficient information.
Proof Let gi be an arbitrary behavioral strategy for player i and ρ−i be any K−i-based
strategy profile. Let hi be admissible under (gi,ρ−i). Wehave
t
Pgi,ρ−i (x˜t,u˜−
t
i |hi t)= Pgi,ρ−i (u˜−
t
i |x˜t,h˜−
t
i ,hi t,ui t)Pgi,ρ−i (x˜t,h˜−
t
i |hi t,ui t) (C53)
Xh˜− ti
=

ρj t(u˜j t|k˜ tj ) Pgi,ρ−i (x˜t,h˜−
t
i |hi t) (C54)
Xh˜− ti j Y6=i
 
=

ρj t(u˜j t|k˜ tj ) Pgi,ρ−i (x˜t,k˜ t−i |hi t) (C55)
Xk˜ t−i j Y6=i
 
=

ρj t(u˜j t|k˜ tj ) Φ ti,ρ−i (x˜t,k˜ t−i |kti ), (C56)
Xk˜ t−i j Y6=i
 
wherein(C53)weappliedtheLawofTotalProbability.In(C55)wecombinedtherealizations
ofh˜−i correspondingtothesamecompressedinformationk˜−i.Inthefinalequation,weused
t t
the condition of Lemma 1.
By the definition of the model, Z ti =f ti,Z (Xt,Ut,Wt) forsome fixed functionf ti,Z inde-
pendentofthestrategyprofile.Sincethecompressedinformationcanbesequentiallyupdated
as K ti
+1
= ιi t+1(K ti,Z ti), this means that we can write K ti
+1
= ξ ti(K ti,Xt,Ut,Wt) for some
fixedfunctionξ ti.SinceWtisaprimitiverandomvariable,weconcludethatP(k ti +1|k ti,xt,ut)
is independent ofany strategy profile. Therefore,
Pgi,ρ−i (kti +1|hi t,ui
t) (C57)
= P(k ti +1|kti ,x˜t,(u˜−
t
i ,ui t))Pgi,ρ−i (x˜t,u˜−
t
i |hi t) (C58)
x˜tX,u˜− ti
= P(kti +1|kti ,x˜t,(u˜−
t
i ,ui t))

ρj t(u˜j t|k˜ tj ) Φ ti,ρ−i (x˜t,k˜ t−i |kti )

(C59)
x˜tX,u˜− ti

Xk˜ t−i j Y6=i

   
32i,ρ−i i i i
=:P
t
(kt+1|kt,ut), (C60)
i,g−i
for some function P , where in (C58) we used the Law of Total Probability, and we
t
substituted (C56) in (C59).
Since R ti =f ti,R (Xt,Ut,Wt) for some fixed function f ti,R and Wt is a primitive random
variable, we have E[R ti|Xt,Ut] to be independent of the strategy profile g. By an argument
similar to the one that leads from(C57)to (C60) weobtain
Egi,ρ−i [Rti |hi t,ui
t] (C61)
= E[Rti |x˜t,(ui t,u˜−
t
i )]

ρj t(u˜j t|k˜ tj ) Φ ti,ρ−i (x˜t,k˜ t−i |kti )

(C62)
x˜tX,u˜− ti

Xk˜ t−i j Y6=i

i,ρ−i
i i
  
=:r
t
(kt,ut), (C63)
i,ρ−i
for some function r . With (C60) and (C63), we have shown that K satisfies Definition
i
4 and hence K is MSI.
(cid:3)
C.2 Proof of Theorem 1
Theorem 6 (Theorem1,restated) IfK ismutuallysufficientinformation,thenthere exists
at least one K-based BNE.
Proof The proof will proceed as follows: We first construct a best-response correspondence
using stochastic control theory, and then we establish the existence of equilibria by apply-
ing Kakutani’s fixed-point theorem to this correspondence. For technical reasons, we first
consider only behavioralstrategies where each action has probability at least ǫ>0 ofbeing
played at each informationset. We then takeǫ to zero.
Fixing a K−i-based strategy profile ρ−i, we first argue that Ki is a controlled Markov
t
process controlled by player i’s action Ui.
t
Fromthe definition of an informationstate (Definition 3) we knowthat
Pg˜i,ρ−i (kti +1|hi t,ui
t)=P
ti,ρ−i (kti +1|kti ,ui
t). (C64)
Since (Ki ,Ui ) is a function of (Hi,Ui), by the smoothing property of conditional
1:t 1:t t t
probability we have
Pg˜i,ρ−i
(k
ti
+1|k
1i :t,ui
1:t)=P
ti,ρ−i
(k
ti +1|kti ,ui
t). (C65)
ThereforewehaveshownthatKi isacontrolledMarkovprocesscontrolledbyplayeri’s
t
action Ui.
t
Fromthe definition of informationstate (Definition 3) we knowthat
Eg˜i,ρ−i Rti |kti ,ui
t =r
ti,ρ−i (kti ,ui
t), (C66)
forall (ki,ui) admissible under(g˜i,ρh−i). i
t t
Therefore, using the Law of TotalExpectation we have
T T
Ji (g˜i ,ρ−i )=Eg˜i,ρ−i Rti =Eg˜i,ρ−i Eg˜i,ρ−i Rti |Kti ,Uti
(C67)
" # " #
Xt=1 Xt=1 h i
33T
=Eg˜i,ρ−i
r
ti,ρ−i (Kti ,Uti
) . (C68)
" #
t=1
X
By standard MDP theory, there exist Ki-based strategies ρi that maximize Ji(g˜i,ρ−i)
over all behavioral strategies g˜i. Furthermore, optimal Ki-based strategies can be found
through dynamicprogramming.
Assume ǫ > 0, let Pǫ,i denote the set of Ki-based strategies for player i where each
action ui ∈ Ui is chosen with probability at least ǫ at any information set. To endow Pǫ,i
t t
with a topology,weconsider it as a product of sets ofdistributions, i.e.
ǫ,i ǫ i
P = ∆ (Ut), (C69)
t Y∈T k ti Y∈Ki
t
where
ǫ i i i i i
∆ (Ut)={η∈∆(Ut):η(ut)≥ǫ ∀ut ∈Ut}. (C70)
Define Pǫ = Pǫ,i. Denotethe set ofall Ki-based strategy profiles by P0.
i∈I
For the rest of the proof, assume that ǫ is small enough such that ∆ǫ(Ui) is non-empty
Q t
forall t∈T and i∈I.
Foreacht∈T,i∈I andki ∈Ki,definethecorrespondenceBRǫ,i [ki]:Pǫ,−i7→∆ǫ(Ui)
t t t t t
sequentially through
Qǫ,i (ki ,ui ;ρ−i ):=ri,ρ−i (ki ,ui
), (C71a)
T T T T T T
BRǫ t,i [kti ](ρ−i
):= argmax
Qǫ t,i (kti ,u˜i t;ρ−i )η(u˜i
t), (C71b)
η∈∆ǫ(U ti) Xu˜i
t
V tǫ,i (kti;ρ−i):= max Qǫ t,i (kti,u˜i t;ρ−i)η(u˜i t), (C71c)
η∈∆ǫ(Ui)
t Xu˜i
t
Qǫ t−,i 1(kti −1,ui t−1;ρ−i
):=r
ti −,ρ 1−i (kti −1,ui
t−1)+ (C71d)
+ V
tǫ,i (kti ;ρ−i
)P
ti −,ρ 1−i (kti |kti −1,ui
t). (C71e)
k ti X∈Ki
t
Define BRǫ :Pǫ 7→Pǫ by
BRǫ
(ρ)=
BRǫ t,i [kti ](ρ−i
). (C72)
i Y∈It Y∈T k ti Y∈Ki
t
Claim:
(a) Pi,ρ−i (ki |ki,ui) is continuousin ρ−i onPǫ,−i forallt∈T andallki ∈Ki ,ki ∈
t t+1 t t t+1 t+1 t
Ki,ui ∈Ui.
t t t
(b) ri,ρ−i (ki,ui) is continuousin ρ−i on Pǫ,−i forall t∈T and all ki ∈Ki,ui ∈Ui.
t t t t t t t
Given the claims we prove by induction that Qǫ,i (ki,ui;ρ−i) is continuous in ρ−i on
t t t
Pǫ,−i foreach ki ∈Ki,ui ∈Ui.
t t t t
Induction Base: Qǫ,i (ki ,ui ;ρ−i)=ri,ρ−i (ki ,ui ) is continuous in ρ−i on Pǫ,−i due
T T T T T T
to part (a) of theclaims.
Induction Step:Supposethattheinductionhypothesisistruefort.ThenVǫ,i (ki;ρ−i)
t t
is continuous in ρ−i on Pǫ,−i due to Berge’s Maximum Theorem (Sundaram, 1996). Then,
Qǫ,i (ki ,ui ;ρ−i) is continuousin ρ−i on Pǫ,−i due to the claims.
t−1 t−1 t−1
34Applying Berge’s Maximum Theorem (Sundaram, 1996) once again, we conclude that
BRǫ,i [ki] is upper hemicontinuous on Pǫ,−i. For each ρ−i ∈ Pǫ,−i, BRǫ,i [ki](ρ−i) is non-
t t t t
empty and convex since it is thesolution set of a linear program.
As a product of compact-valued upper hemicontinuous correspondences, BRǫ is upper
hemicontinuous. For each ρ ∈ Pǫ, BRǫ(ρ) is non-empty and convex. By Kakutani’s fixed
point theorem, BRǫ hasa fixed point.
The above construction provides an approximate K-based BNE for small ǫ. Next, we
show that we can take ǫ to zero to obtain an exact BNE: Let (ǫn)∞
n=1
be a sequence such
that ǫn >0,ǫn →0. Let ρ(n) be a fixed point ofBRǫn. Then foreach i∈I wehave
ρ(n),i ∈argmax Ji(ρ˜i,ρ(n),−i). (C73)
ρ˜i∈Pǫn,i
Let ρ(∞) ∈ P0 be the limit of a sub-sequence of (ρ(n))∞ . Since Ji(ρ) is continuous
n=1
in ρ on P0, and ǫ 7→ Pǫ,i is a continuous correspondence with compact, non-empty value,
through applyingBerge’s MaximumTheorem (Sundaram,1996)one last time, we conclude
that foreach i∈I
ρ(∞),i
∈argmax
Ji (ρ˜i ,ρ(∞),−i
), (C74)
ρ˜i∈P0,i
i.e. ρ(∞),i isoptimalamongKi-basedstrategiesin responsetoρ(∞),−i.Recallthatwehave
shownthatthereexist Ki-basedstrategiesρi thatmaximizes Ji(g˜i,ρ−i)overallbehavioral
strategies g˜i. Therefore, we conclude that ρ(∞) forms a BNE, proving the existence of
K-based BNE.
Proof of Claim:Weestablish thecontinuityofthetwofunctionsbyshowingthatthey
can be expressed with basic functions(i.e. summation, multiplication, division).
Let gˆi be a behavioral strategy where player i chooses actions uniformly at random at
everyinformationset.Forρ−i∈Pǫ,−i,wehavePgˆi,ρ−i (ki)>0forallki ∈Ki since(gˆi,ρ−i)
t t t
is a strategy profile that alwaysplays strictly mixed actions. Thereforewe have
P ti,ρ−i (kti +1|kti ,ui t)=Pgˆi,ρ−i (kti +1|kti ,ui t)= Pgˆi P,ρ gˆ− i,i ρ( −k iti (+ k1 i, ,k uti i, )ui t) , (C75)
t t
r
ti,ρ−i (kti ,ui t)=Egˆi,ρ−i [Rti |kti ,ui
t] (C76)
= E[Rti |xt,ut]Pgˆi,ρ−i (xt,u−
t
i |kti ,ui t), (C77)
xt∈XtX,u− ti∈Ut
where E[R ti|xt,ut] is independent of thestrategy profile.
WeknowthatbothPgˆi,ρ−i (ki ,ki,ui)andPgˆi,ρ−i (ki,ui)aresumsofproductsofcom-
t+1 t t t t
ponents of ρ−i and gˆi, hence both are continuous in ρ−i. Therefore Pi,ρ−i (zi|ki,ui) is
t t t t
continuous in ρ−i on Pǫ,−i. The continuity of ri,ρ−i (ki,ui) in ρ−i on Pǫ,−i can be shown
t t t
with an analogousargument.
(cid:3)
C.3 Proof of Theorem 2
Theorem 7 (Theorem 2, restated) If K = (Ki)i∈I where Ki is unilaterally sufficient
informationforplayeri,thenthesetofK-based BNEpayoffsisthesameasthatofallBNE.
35ToestablishTheorem2,wefirstintroduceDefinition12,anextensionofDefinition
3, for the convenience of the proof. Then, we establish Lemmas 5, 6, 7. Finally, we
conclude the proof of Theorem 2 from the three lemmas.
In the following definition, we provide an extension of the definition of the infor-
mation state where not only player i’s payoff are considered. This definition allows
us to characterize compression maps that preserve payoff profiles, as required in the
statement of Theorem 2.
Definition 12 Let g−i be a behavioral strategy profile of players other than i and J ⊆I
be a subset of players. We say that Ki is an information state under g−i for the payoffs of
J if there exist functions (P ti,g−i )t∈T,(r tj,g−i )j∈J,t∈T, where P ti,g−i :K ti×U ti 7→∆(K ti +1)
and rj,g−i :Ki×Ui 7→[−1,1], such that
t t t
(1) Pgi,g−i (ki |hi,ui)=Pi,g−i (ki |ki,ui) forall t∈T\{T}; and
t+1 t t t t+1 t t
(2) Egi,g−i [Rj |hi,ui]=rj,g−i (ki,ui) forall j ∈J andall t∈T,
t t t t t t
forall gi, and all (hi,ui) admissible under(gi,g−i).
t t
Notice that condition (2) of Definition 12 means that the information state Ki
is sufficient for evaluating other agents’ payoffs as well. This property is essential in
establishing the preservation of payoff profiles of other agents when player i switches
to a compression-based strategy.
Lemma5 IfKi isunilaterallysufficientinformation,thenKi isaninformationstateunder
g−i for the payoffs of I under all behavioral strategy profiles g−i.
i,g−i
Proof of Lemma 5 Let Φ be as in the definition of USI (Definition 5), we have
t
Pg(xt,h−
t
i|hi t)=Φ ti,g−i (xt,h−
t
i|kti). (C78)
Applying the Law of TotalProbability,
Pg (x˜t,u˜−
t
i |hi t)= Pg (u˜−
t
i |x˜t,˜h−
t
i ,hi t)Pg (x˜t,h˜−
t
i |hi t) (C79)
Xh˜− ti
=

g tj (u˜j t|h˜j t) Φ ti,g−i (x˜t,h˜−
t
i |kti ) (C80)
Xh˜− ti j Y6=i
 
=:P˜ ti,g−i (x˜t,u˜−
t
i |kti ). (C81)
WeknowthatK ti
+1
=ιi t+1(K ti,Z ti)=ξ ti(K ti,Xt,Ut,Wt)forsomefixedfunctionξ ti inde-
pendent ofthe strategyprofile g.Since Wt is a primitive randomvariable, P(k ti +1|k ti,xt,ut)
is independent ofthe strategy profileg. Therefore,
Pg (kti +1|hi t,ui t)= P(kti +1|kti ,x˜t,(u˜−
t
i ,ui t))P˜ ti,g−i (x˜t,u˜−
t
i |kti ) (C82)
x˜tX,u˜− ti
36i,g−i i i i
=:P
t
(kt+1|kt,ut), (C83)
establishing part (1) of Definition 12.
j
Consider any j ∈ I. Since R
t
is a strategy-independent function of (Xt,Ut,Wt),
E[R tj |xt,ut] is independent of g.Therefore
Eg [R tj |hi t,ui t]= E[R tj |x˜t,(ui t,u˜−
t
i )]P˜ ti,g−i (x˜t,u˜−
t
i |kti ) (C84)
x˜tX,u˜− ti
j,g−i i i
=:r
t
(kt,ut), (C85)
establishing part (2) of Definition 12. (cid:3)
In Lemma 6, we show that any behavioral strategy of player i can be replaced by
an equivalent randomized USI-based strategy while preserving payoffs of all players.
Lemma 6 Let Ki be unilaterally sufficient information. Then for every behavioral strategy
profile gi, if the Ki based strategy ρi is given by
ρi t(ui t|kti
)=
gti (ui t|h˜i
t)F
ti,gi (h˜i t|kti
), (C86)
h˜i tX∈Hi
t
where Fi,gi (h˜i|ki) is defined in Definition 5, then
t t t
Jj(gi,g−i)=Jj(ρi,g−i),
for all j ∈I and all behavioral strategy profiles g−i of players other than i.
Proof of Lemma 6 Let j ∈ I. Consider an MDP with state Hi, action Ui and instanta-
t t
neous reward r˜i,j (hi,ui) := Eg−i [Rj |hi,ui]. By Lemma 5, Ki is an information state (as
t t t t t t
definedinDefinition6)forthisMDP.HenceJj(gi,g−i)=Jj(ρi,g−i)followsfromthePolicy
Equivalence Lemma (Lemma 3). (cid:3)
In Lemma 7, we proceed to show that a behavioral strategy can be replaced with
an USI-based strategy while preserving not only the payoffs of all players, but also
the equilibrium.
Lemma7 IfKi isunilaterallysufficientinformationforplayeri,thenforanyBNEstrategy
profile g =(gi)i∈I there exists a Ki-based strategy ρi such that (ρi,g−i) forms a BNE with
the same expected payoff profile as g.
Proof of Lemma 7 Let ρi be associated with gi as specified in Lemma 6. Set g¯= (ρi,g−i).
SinceJi(ρi,g−i)=Ji(gi,g−i) andgi is abest responseto g−i,ρi isalso a best response to
g−i.
Consider j 6=i. Let g˜j be an arbitrary behavioralstrategy of playerj. By using Lemma
6 twice we have
Jj (g¯j ,g¯−j )=Jj (ρi ,g−i )=Jj (g)≥Jj (g˜j ,g−j
) (C87)
37=Jj (g˜j ,(ρi ,g−{i,j}))=Jj (g˜j ,g¯−j
). (C88)
Therefore g¯j is a best response to (ρi,g−{i,j}). We conclude that g¯ = (ρi,g−i) is also a
BNE. (cid:3)
Proof of Theorem 2 GivenanyBNEstrategyprofileg,applyingLemma7iterativelyforeach
i∈I, we obtain a K-based BNEstrategy profileρ with the same expected payoffprofile as
g. Thereforethe set of K-based BNEpayoffsis the same as that of all BNE. (cid:3)
C.4 Proof of Theorem 3
Theorem 8 (Theorem3,restated) IfK ismutuallysufficientinformation,thenthere exists
at least one K-based sequential equilibrium.
Proof TheproofofTheorem3followssimilarstepstothatofTheorem1,whereweconstruct
a sequenceofstrictly mixed strategyprofiles viathefixedpointsofdynamicprogrambased
bestresponsemappings.Inaddition,weshowthesequentialrationalityofthestrategyprofile
constructed.
Let (ρ(n))∞ be a sequence of K-based strategy profiles that always assigns strictly
n=1
mixed actions asconstructed in theproofof Theorem1. By takinga sub-sequence, without
loss of generality,assume that ρ(n)→ρ(∞) forsome K-based strategy profile ρ(∞).
Let Q(n) be conjectures of reward-to-go functions consistent (in the sense of Definition
9) with ρ(n), i.e.
T
Qτ(n),i (hi t,ui t):=Eρ(n) Rti hi τ,ui τ . (C89)
"t X=τ (cid:12) #
(cid:12)
LetQ(∞) bethelimitofasub-sequenceof(Q(n))∞ (cid:12)(suchalimitexistssincetherange
n=1
of each Qτ(n),i is a compact set). We proceed to show that (ρ(∞),Q(∞)) forms a sequential
equilibrium (as defined in Definition 9). Note that by construction, Q(∞) is fully consistent
with ρ(∞). We only need to show sequential rationality.
ǫ,i
Claim: Let Q be asdefined in (C71)in the proofof Theorem 1, then
t
Q
t(n),i (hi t,ui t)=Qǫ tn,i (kti ,ui t;ρ(n),−i
), (C90)
forall i∈I,t∈T,hi ∈Hi, and ui ∈Ui.
t t t t
By construction in the proof of Theorem 1, ρ(n),i (ki) ∈ BRǫn,i [ki](ρ(n),−i). Given the
t t t t
claim, this means that
ρ t(n),i (kti)∈ argmax Q t(n),i (hi t,u˜i t)η(u˜i t), (C91)
η∈∆ǫn(U ti) Xu˜i
t
forall i∈I,t∈T and hi ∈Hi.
t t
ApplyingBerge’sMaximumTheorem(Sundaram,1996)inasimilarmannertotheproof
of Theorem 1 we obtain
(∞),i i (∞),i i i i
ρ
t
(kt)∈argmax Q
t
(ht,u˜t)η(u˜t), (C92)
η∈∆(U ti) Xu˜i
t
forall i∈I,t∈T and hi ∈Hi.
t t
38Therefore, we have shown that ρ(∞) is sequentially rational under Q(∞) and we have
completed the proof.
Proof of Claim:Forclarityofexpositionwedropthesuperscript (n)ofρ(n).Weknow
(n),i
that Q satisfies the followingequations:
t
Q(n),i (hi ,ui )=Eρ [Ri |hi ,ui
], (C93a)
T T T T T T
(n),i i (n),i i i i i i
V
t
(ht):= Q
t
(ht,u˜t)ρt(u˜t|kt), (C93b)
Xu˜i
t
Q
t( −n) 1,i (hi t−1,ui t−1):=Eρ [Rti −1|hi t−1,ui
t−1]+ V
t(n),i (h˜i t)Pρ (h˜i t|hi t−1,ui
t). (C93c)
h˜i tX∈Hi
t
Since K is mutually sufficient information,we have
Pρ (kti +1|hi t,ui
t):=P
ti,ρ−i (kti +1|kti ,ui
t), (C94)
Eρ [Rti |hi t,ui
t]:=r
ti,ρ−i (kti ,ui
t), (C95)
i,ρ−i i,ρ−i
where P and r areas specified in Definition 3.
t t
Therefore,through aninductive argument,onecan show then Q(n),i (hi,ui) depends on
t t t
hi only through ki, and
t t
(n),i i i i,ρ−i i i
Q (k ,u )=r (k ,u ), (C96a)
T T T T T T
V
t(n),i (kti
):=
Qi t(kti ,u˜i t;ρ−i )ρi t(u˜i t|kti
), (C96b)
Xu˜i
t
Q t( −n) 1,i (kti −1,ui t−1):=r ti −,ρ 1−i (kti −1,ui t−1)+ V t(n),i (k˜ ti )P ti −,ρ 1−i (k˜ ti |kti −1,ui t). (C96c)
k˜ tiX∈Ki
t
The claim is then established by comparing (C96) with (C71) and combining with the
fact that ρi(ki)∈BRǫ,i [ki](ρ−i). (cid:3)
t t t t
C.5 Proof of Theorem 4
Theorem9 (Theorem4,restated) IfK =(Ki)i∈I whereKi isunilaterallysufficientinfor-
mationforplayer i,thenthe setof K-based sequential equilibriumpayoffs isthe sameasthat
of all sequential equilibria.
To provethe assertion of Theorem 4 we establish a series of technical results that
appearinLemmas8-12below.Thetwokeyresultsneededfortheproofofthetheorem
are provided by Lemmas 10 and 12. Lemma 10 asserts that a player can switch to
a USI-based strategy without changing the dynamic decision problems faced by the
other players. The result of Lemma 10 allows to establish the analogue of the payoff
equivalenceresultofLemma3undertheconceptofsequentialequilibrium.Lemma12
asserts that any one player can switch to a USI-based strategy without affecting the
sequential equilibrium (under perfect recall) and its payoffs. The proof of Lemma 10
is based on two technical results provided by Lemmas 8 and 9. The proof of Lemma
12 is based on Lemmas 10 and 11 which states that the history-action value function
of a player i∈I can be expressed with their USI.
39Lemma 8 Suppose that Ki is unilaterally sufficient information. Then
Pg (hi t|hj t)=Pg (hi t|kti )Pg (kti |hj
t), (C97)
whenever
Pg(ki)>0,Pg(hj
)>0.
t t
Proof From the definition of unilaterally sufficient information (Definition 5) wehave
Pg (h˜i t,h˜j t|kti
)=F
ti,gi (h˜i t|kti
)F
ti,j,g−i (h˜j t|kti
), (C98)
where
F
ti,j,g−i (hj t|kti
):= Φ
ti,g−i (x˜t,(hj t,h˜−
t
{i,j} )|kti
). (C99)
x˜t,h˜Xt−{i,j}
Therefore, we conclude that Hi and Hj are conditionally independent given Ki. Since
t t t
Ki is a function of Hi, wehave
t t
Pg (hi t|hj t)=Pg (hi t,kti |hj t)=Pg (hi t|kti )Pg (kti |hj
t). (C100)
(cid:3)
Lemma 9 Suppose that Ki is unilaterally sufficient information for player i ∈ I. Then
j,i,g−{i,j} i,j,g−{i,j} i,j,g−{i,j}
there exist functions (Π ) , (r ) , where Π :
t j∈I\{i},t∈T t j∈I\{i},t∈T t
Ki×Hj ×Ui×Uj 7→∆(Hj
),
ri,j,g−{i,j} :Ki×Hj ×Ui×Uj
7→[−1,1] such that
t t t t t+1 t t t t t
(1)
Pg(h˜j |hi,hj ,ui,uj )=Πj,i,g−{i,j} (h˜j |ki,hj ,ui,uj
) for all t∈T\{T}; and
t+1 t t t t t t+1 t t t t
(2)
Eg[Rj |hi,hj ,ui,uj ]=ri,j,g−{i,j} (ki,hj ,ui,uj
) for all t∈T,
t t t t t t t t t t
for allj ∈I\{i} andall behavioral strategy profiles g whenever the left-hand sideexpressions
are well-defined.
Proof of Lemma 9 Let gˆl besome fixed,fully mixed behavioralstrategy forplayerl∈I.
Fix j 6=i. First,
Pg(xt,h−
t
{i,j} |hi t,hj t)=Pgˆ{i,j},g−{i,j} (xt,h−
t
{i,j} |hi t,hj t) (C101)
=
Φ ti,(gˆj,g−{i,j}) (xt,h−
t
i|k ti)
(C102)
x˜t,h˜
t−{i,j}Φ ti,(gˆj,g−{i,j}) (x˜t,(h˜−
t
{i,j} ,hj t)|k ti)
=:P
Φ
ti,j,g−{i,j} (xt,h−
t
{i,j} |kti,hj
t), (C103)
foranybehavioralstrategyprofileg,wherein(C101)weusedthefactthatsince(hi,hj
)are
t t
included in the conditioning, the conditional probability is independent of the strategies of
player i and j (Kumar and Varaiya, 2015, Section 6.5). In (C102) we used Bayes rule and
the definition ofUSI (Definition 5).
Therefore, using the Law ofTotalProbability,
Pg (x˜t,u˜−
t
{i,j} |hi t,hj
t)=
Pg (u˜−
t
{i,j} |x˜t,h˜−
t
{i,j} ,hi t,hj t)Pg (x˜t,h˜−
t
{i,j} |hi t,hj
t) (C104)
h˜ t−X{i,j}
40=

gtl (u˜l t|h˜l
t) Φ
ti,j,g−{i,j} (x˜t,h˜−
t
{i,j} |kti ,hj
t) (C105)
h˜ t−X{i,j} l∈IY\{i,j}
 
=:P˜ ti,j,g−{i,j} (x˜t,u˜−
t
{i,j} |kti,hj t), (C106)
foranybehavioralstrategy profileg.
j j j j
We know that H
t+1
= ξ t(Xt,Ut,H t) for some function ξ
t
independent of the strategy
profile g,hence using the Law ofTotalProbability wehave
Pg (h˜j t+1|hi t,hj t,ui t,uj
t) (C107)
= 1
{h˜j t+1=ξ ti(x˜t,(u t{i,j},u˜ t−{i,j}),hj
t)}P˜ ti,j,g−{i,j} (x˜t,u˜−
t
{i,j} |kti ,hj t) (C108)
x˜t,u˜Xt−{i,j}
=:Π
tj,i,g−{i,j} (h˜j t+1|kti ,hj t,ui t,uj
t), (C109)
establishing part (1) of Lemma 9.
Since E[R tj |xt,ut] is strategy-independent, for j ∈ I\{i}, using the Law of Total
Expectation wehave
Eg [R tj |hi t,hj t,ui t,uj t]= E[R tj |x˜t,(u t{i,j} ,u˜−
t
{i,j} )]P˜ ti,j,g−{i,j} (x˜t,u˜−
t
{i,j} |kti ,hj t)
x˜tX,u˜− ti
(C110)
i,j,g−{i,j} i j i j
=:r
t
(kt,h t,ut,u t), (C111)
establishing part (2) of Lemma 9. (cid:3)
Lemma10 SupposethatKi isunilaterallysufficientinformation.Letg=(gj)j∈I beafully
mixed behavioral strategy profile. Let a Ki-based strategy ρi be such that
ρi t(ui t|kti
)=
gti (ui t|h˜i
t)F
ti,gi (h˜i t|kti
). (C112)
Xh˜i
t
Then
(1)
Pg(h˜j |hj ,uj )=Pρi,g−i (h˜j |hj ,uj
) for all t∈T\{T}; and
t+1 t t t+1 t t
(2)
Eg[Rj |hj ,uj ]=Eρi,g−i [Rj |hj ,uj
] for all t∈T,
t t t t t t
j j j j
for all j ∈I\{i} and all h ∈H ,u ∈U .
t t t t
Proof Fixing g−i, Hi is a controlled Markov Chain controlled by Ui and player i faces a
t t
MarkovDecision Problem. ByLemma 5,Ki isaninformationstate(asdefinedin 6)ofthis
t
MDP. Therefore,by thePolicy Equivalence Lemma (Lemma 3) we have
Pgi,g−i (kti )=Pρi,g−i (kti
). (C113)
Furthermore, from thedefinition of USI wehave
Pgi,g−i (hj t|kti
)= Φ
ti,g−i (x˜t,(hj t,h−
t
{i,j} )|kti
) (C114)
x˜t,h˜Xt−{i,j}
i,j,g−i j i
=:F
t
(h t|kt). (C115)
41Using BayesRule, we then have
Pgi,g−i (kti |hj t)= Pgi P,g g− i,i g( −h ij t (| hk jti |) k˜P ig )i P,g g− i,i g( −k iti ()
k˜i)
(C116)
k˜i t t t
t
PFi,j,g−i (hj |ki)Pgi,g−i (ki)
= t t t t . (C117)
Fi,j,g−i (hj |k˜i)Pgi,g−i(k˜i)
k˜i t t t t
t
Note that (C117)applies forall straPtegies gi. Replacing gi with ρi wehave
Pρi,g−i (kti |hj t)= F ti F,j, ig ,j− ,i g( −h ij t (| hk jti |) k˜P iρ )i P,g ρ− i,i g( −k iti () k˜i). (C118)
k˜i t t t t
t
Combining (C113), (C117), and (CP118)weconclude that
Pgi,g−i (kti |hj t)=Pρi,g−i (kti |hj
t). (C119)
Using (C112), Lemma 8,and Lemma 9 we have
Pg (h˜j |hj ,uj
) (C120)
t+1 t t
=
Pg (h˜j t+1|h˜i t,hj t,u˜i t,uj t)Pg (u˜i t|h˜i t,hj t,uj t)Pg (h˜i t|hj t,uj
t) (C121)
h˜i t:Pg(Xh˜i t,hj t)>0Xu˜i
t
= Π tj,i,g−{i,j} (h˜j t+1|k˜ ti ,hj t,u˜i t,uj t)gti (u˜i t|h˜i t)Pg (h˜i t|hj t) (C122)
h˜ Xi t,u˜i
t
= Π tj,i,g−{i,j} (h˜j t+1|k˜ ti ,hj t,u˜i t,uj t)gti (u˜i t|h˜i t)Pg (h˜i t|k˜ ti )Pg (k˜ ti |hj t) (C123)
h˜ Xi t,u˜i
t
= Π tj,i,g−{i,j} (h˜j t+1|k˜ ti,hj t,u˜i t,uj t)

gti(u˜i t|hˆi t)Pg(hˆi t|k˜ ti) Pg(k˜ ti|hj t) (C124)
k˜ Xti,u˜i
t
Xhˆi
t 
= Π tj,i,g−{i,j} (h˜j t+1|k˜ ti ,hj t,u˜i t,uj t)ρ i t(u˜i t|k˜ ti )Pg (k˜ ti |hj t),  (C125)
k˜ Xti,u˜i
t
j,i,g−{i,j}
where in (C122) we utilized Lemma 9 and the function Π defined in it. In (C123)
t
we applied Lemma 8.In the last equationwe used (C112)and the definition of USI.
Following a similar argument,wecan show that
Pρi,g−i (h˜j |hj ,uj
) (C126)
t+1 t t
= Π tj,i,g−{i,j} (h˜j t+1|k˜ ti ,hj t,u˜i t,uj t)ρi t(u˜i t|k˜ ti )Pρi,g−i (k˜ ti |hj t). (C127)
k˜ Xti,u˜i
t
Using (C119)and comparing (C125)with (C127), weconclude that
Pg (h˜j |hj ,uj )=Pρi,g−i (h˜j |hj ,uj
), (C128)
t+1 t t t+1 t t
proving statement (1) of the Lemma.
Following an analogousargument,we can show that
Eg[R tj |hj t,uj t]= r ti,j,g−{i,j} (k˜ ti,hj t,u˜i t,uj t)ρi t(u˜i t|k˜ ti)Pg(k˜ ti|hj t) (C129)
k˜ Xti,u˜i
t
42Eρi,g−i [R tj |hj t,uj t]= r ti,j,g−{i,j} (k˜ ti ,hj t,u˜i t,uj t)ρi t(u˜i t|k˜ ti )Pρi,g−i (k˜ ti |hj t), (C130)
k˜ Xti,u˜i
t
i,j,g−{i,j}
where r is defined in Lemma 9.We similarly conclude that
t
Eg [Rj |hj ,uj ]=Eρi,g−i [Rj |hj ,uj
], (C131)
t t t t t t
provingstatement (2) ofthe Lemma. (cid:3)
Lemma 11 Suppose that Ki is unilaterally sufficient information for player i. Let g−i be a
fully mixed behavioral strategy profile for players other than i. Define Qi τ through
T
Qi τ(hi τ,ui τ)=Eg−i [Rτi |hi τ,ui
τ]+ max
Eg˜ τi +1:T,g−i Rti hi τ,ui
τ . (C132)
g˜i  
τ+1:T t= Xτ+1 (cid:12)
(cid:12)
Then there exist a function Qˆi τ :Kτi ×Uτi 7→[−T,T] such  that (cid:12) 
Qi τ(hi τ,ui τ)=Qˆi τ(kτi ,ui
τ). (C133)
Proof By Lemma 5, Ki is an information state for the payoff of player i under g−i. Fixing
g−i, Hi is a controlled Markov Chain controlled by Ui. Through Definition 6, Ki is an
t t t
information state of this controlled Markov Chain. The Lemma then follows from a direct
application of Lemma 2. (cid:3)
Lemma 12 Suppose that Ki isunilaterally sufficient information for player i. Let g be (the
strategy part of) a sequential equilibrium. Then there exist a Ki-based strategy ρi such that
(ρi,g−i)is(thestrategy partof)asequentialequilibriumwiththesameexpected payoffprofile
as g.
Proof of Lemma 12 Recall that in Theorem 5 we established the equivalence of a variety of
definitionsofSequentialEquilibrium forstrategyprofiles.Let (g,Q)beasequentialequilib-
rium under Definition 10. Let (g(n),Q(n)) be a sequence of strategy and conjecture profiles
that satisfies conditions (1)(2’)(3)of Definition 10.
Set ρ(n),i through
ρ
t(n),i (ui t|kti
)= g
t(n),i (ui t|h˜i
t)F
ti,g(n),i (h˜i t|kti
), (C134)
Xh˜i
t
i,g(n),i
where F is defined in Definition 5. By replacing the sequence with one of its sub-
t
sequences, without loss ofgenerality, assume that ρ(n),i→ρi forsome ρi.
For the ease of notation, denote g¯(n) = (ρ(n),i,g(n),−i) and g¯ = (ρi,g−i). We have
g¯(n)→g¯. In the rest of the proof,wewill show that (g¯,Q) is a sequential equilibrium.
We only need to show that g¯ is sequentially rational to Q and (g¯(n),Q(n)) satisfies
conditions(2’)ofDefinition10,asconditions(1)(3)ofDefinition10aretruebyconstruction.
Since g¯−i = g−i, we automatically have g¯j to be sequentially rational given Qj for all
j ∈I\{i}, and Q(n),i to be consistent with g¯(n),−i foreach n. It suffices to establish
(i) ρi is sequentially rationalwith respect to Qi; and
43(ii) Q(n),j is consistent with g¯(n),−j foreach j ∈I\{i}.
Toestablish(i),wewillusetheLemma11toshowthatQi(hi,ui)isafunctionof(ki,ui),
t t t t t
and hence one can use an ki based strategy to optimize Qi.
t t
Proof of (i): Byconstruction,
ρ
t(n),i (kti
)= g
t(n),i (h˜i
t)·η
t(n) (h˜i t|kti
), (C135)
h˜i t:Xk˜ ti=k ti
forsomedistributionη t(n) (k ti)∈∆(Hi t).Letηt(k ti)beanaccumulationpointofthesequence
[η(n) (ki)]∞ . We have
t t n=1
ρi t(kti
)=
gti (h˜i t)·ηt(h˜i t|kti
). (C136)
h˜i t:Xk˜ ti=k ti
As a result, wehave
supp(ρi t(kti
))⊆
supp(gti (h˜i
t)). (C137)
h˜i t:k˜ [ti=k ti
By Lemma 11 we have Q(n),i (hi,ui) = Qˆ(n),i (ki,ui) for some function Qˆ(n),i . Since
t t t t t t t
Q(n),i →Qi,wehaveQi(hi,ui)=Qˆi(ki,ui)forsomefunctionQˆi.Bysequentialrationality
t t t t t t
we have
supp(gti (h˜i
t))⊆argmax
Qˆi t(kti ,ui
t), (C138)
ui
t
for all ˜hi whose corresponding compression k˜i satisfies k˜i = ki. Therefore, by (C137) and
t t t t
(C138)we conclude that
supp(ρi t(kti
))⊆argmax
Qˆi t(kti ,ui
t), (C139)
ui
t
establishing sequential rationality of ρi with respect to Qi.
To establish (ii), we will use the Lemmas 6 and 10 to show that when player i switches
their strategy from g(n),i to ρ(n),i, other players face the same control problem at every
information set. As a result, their Q(n),j functionsstays thesame.
Proof of (ii):Consider player j 6=i. Through standard control theory, we know that a
collection of functions Q˜j is consistent (in the sense of condition (2’) of Definition 10) with
a fully mixed strategy profile g˜−j if and only if it satisfies the followingequations:
Q˜j (hj ,uj )=Eg˜−j [Rj |hj ,uj
], (C140a)
T T T T T T
V˜j (hj )=maxQ˜j (hj ,u˜j
), ∀t∈T, (C140b)
t t t t t
u˜j
t
Q˜j (hj ,uj )=Eg˜−j [Rj |hj ,uj
]+
V˜j (h˜j )Pg˜−j (h˜j |hj ,uj
), ∀t∈T\{T}.
t t t t t t t+1 t+1 t+1 t t
h˜ Xj
t+1
(C140c)
By Lemma 10, wehave
Pg(n),−j (h˜j |hj ,uj )=Pρ(n),i,g(n),−{i,j} (h˜j |hj ,uj
), (C141)
t+1 t t t+1 t t
Eg(n),−j [Rj |hj ,uj ]=Eρ(n),i,g(n),−{i,j} [Rj |hj ,uj
], (C142)
t t t t t t
and hence we conclude that Q(n),j is also consistent with g¯(n),−j =(ρ(n),i,g(n),−{i,j}).
44Now we have shown that (g¯,Q) forms a sequential equilibrium. The second half of the
Lemma, which states that g¯ yields the same expected payoff as g, can be shown with the
followingargument:ByLemma6,g¯(n) yieldsthesameexpected payoffprofileasg(n).Since
theexpectedpayoffofeachplayerisacontinuousfunctionofthebehavioralstrategyprofile,
weconclude that g¯yields the same expected payoffas g. (cid:3)
Finally, we conclude Theorem 4 from Lemma 12.
Proof of Theorem 4 GivenanySEstrategyprofileg,applyingLemma12iterativelyforeach
i∈I, weobtainaK-based SEstrategyprofileρwith thesameexpected payoffprofileasg.
Thereforethe set ofK-based SE payoffsis the same asthat of all SE. (cid:3)
Appendix D Proofs for Section 5 and Section 6
D.1 Proof of Proposition 1
Proposition 4 (Proposition 1, restated) In the game defined in Example 2, the set of K-
based wPBE payoffs is a proper subset of that of all wPBE payoffs.
Proof Set gB to be the strategy of Bob where he always chooses UB = +1, and gA :
1 1 2
XA×UB 7→∆(UA) is given by
1 1 2
0 w.p. 1, if uB =+1;
gA (xA ,uB )= 1
2 1 1 (xA
1
w.p. 32, 0 w.p. 31, otherwise,
and gB : XB ×UB 7→ ∆(UB) is the strategy of Bob where he always chooses UB = −1
2 1 1 2 2
irrespective of UB.
1
ThebeliefsµB :XB 7→∆(XA),µA :XA×UB 7→∆(XB),andµB :XB×UB 7→∆(XA)
1 1 1 2 1 1 1 2 1 1 1
are given by
B B A
µ (x )=the prior ofX ,
1 1 1
−1 w.p. 1, +1 w.p. 1, if uB =+1;
µA (xA ,uB )= 2 2 1
2 1 1 (xA
1
w.p. 1, otherwise,
B B B A
µ (x ,u )=the prior ofX .
2 1 1 1
One can verify that g is sequentially rationalgiven µ, and µ is “preconsistent” (Hendon
etal,1996)withg,i.e.thebeliefscanbeupdatedwithBayesruleforconsecutiveinformation
sets on and off-equilibrium paths. In particular, (g,µ) is a wPBE. (It can also be shown
that (g,µ) satisfies Watson’s PBE definition (Watson, 2017). However, (g,µ) is not a PBE
in the sense of Fudenberg and Tirole (Fudenberg and Tirole, 1991b), since µ violates their
“no-signaling-what-you-don’t-know”condition.)
We proceed to show that no K-based wPBEcan attain the payoffprofile of g.
Suppose that ρ= (ρA,ρB) is a K-based weak PBE strategy profile. First, observe that
at t = 2, Alice can only choose her actions based on UB according to the definition of
1
KA-based strategies. Let α,β ∈ ∆({−1,0,1}) be Alice’s mixed action at time t = 2 under
UA = −1 and UA = +1 respectively under strategy ρA. With some abuse of notation,
2 2
denote ρA = (α,β). There exists no belief system under which Alice is indifferent between
all of her three actions at time t = 2. Therefore, no strictly mixed action at t = 2 would
besequentially rational.Therefore,sequential rationallyofρA (with respect to some belief)
implies that min{α(−1),α(0),α(+1)}=min{β(−1),β(0),β(+1)}=0.
45To respond to ρA =(α,β), Bob can alwaysmaximizes his stage 2 instantaneousreward
to 0 by using a suitable response strategy. If Bob plays −1 at t = 1, his best total payoff
is given by 0.2; if Bob plays +1 at t = 1, his best total payoff is given by 0. Hence Bob
strictly prefers−1to+1.Therefore,inanybestresponse(intermsoftotalexpectedpayoff)
to Alice’s strategy ρA,BobplaysUB =−1 irrespective ofhis privatetype.Therefore, Alice
1
has an instantaneouspayoffof −1 at t=1 and a totalpayoff≤0 underρ, proving that the
payoffprofile of ρ is different fromthat of g. (cid:3)
D.2 Proof of Proposition 2
Proposition 5 (Proposition 2, restated) In the model of Example 6, Ki =
t
(Y1:t−1,U1:t−1,X ti) is unilaterally sufficient information.
We first prove Lemma 13, which establish the conditional independence of the
state processes given the common information.
gi gi
Lemma 13 In the model of Example 6, there exists functions (ξ
t
) gi∈Gi,i∈I,ξ
t
:Y1:t−1×
U1:t−1 7→∆(X 1i :t) such that
Pg
(x1:t|y1:t−1,u1:t−1)= ξ
tgi (xi
1:t|y1:t−1,u1:t−1), (D143)
i∈I
Y
for all strategy profiles g and all (y1:t−1,u1:t−1) admissible under g.
Proof of Lemma 13 Denote H t0 = (Y1:t−1,U1:t−1). We prove the result by induction on
time t.
Induction Base: The result is true for t = 1 since H0 = ∅ and the random variables
1
(X 1i)i∈I are assumed to be mutually independent.
Induction Step:SupposethatwehaveprovedLemma13fortimet.Wethenprovethe
result fortime t+1.
We have
Pg (x1:t+1,yt,ut|h0 t)=Pg (xt+1,yt|x1:t,ut,h0 t)Pg (ut|x1:t,h0 t)Pg (x1:t|h0 t) (D144)
= P(xi t+1,yti |xi t,ut)gti (ui t|xi 1:t,h0 t)ξ tgi (xi 1:t|h0 t) (D145)
i Y∈I(cid:16) (cid:17)
=: ν tgi (xi 1:t+1,yt,ut,h0 t)= ν tgi (xi 1:t+1,h0 t+1), (D146)
i∈I i∈I
Y Y
where the induction hypothesisis utilized in (D145).
Therefore, using Bayesrule,
Pg (x1:t+1|h0 t+1)= y˜t,P u˜tg( Px g1 (: x˜t+ 1:1 t+,y 1t ,, yu tt ,| uh t0 t |)
h0 t+1)
(D147)
P νgi (xi ,h0 )
= i∈I t 1:t+1 t+1 (D148)
x˜1Q
:t+1
i∈Iν tgi (x˜i 1:t+1,h0 t+1)
P Qνgi (xi ,h0 )
= i∈I t 1:t+1 t+1 (D149)
i∈QI x˜i ν tgi (x˜i 1:t+1,h0 t+1)
1:t+1
Q P
46=: ξ tg +i 1(xi 1:t+1|h0 t+1), (D150)
i Y∈I
where
ξ tg +i 1(xi 1:t+1|h0 t+1):= x˜iν tgi (x
ν
ti 1 g: it (+ x˜1
i
1, :th +0 t 1+ ,1 h)
0
t+1), (D151)
1:t+1
establishing the induction step. P (cid:3)
Proof of Proposition 2 DenoteH t0=(Y1:t−1,U1:t−1). Then K ti =(H t0,X ti). Given Lemma
13,we have
Pg (xi 1:t−1|kti )= P Pg g( (x xi 1
i
t:t |h|h
0
t0 t )) =
x˜i
ξ ξtg tgi i( (x (i 1 x˜:
i
1t :| th −0 t 1)
,xi t)|h0 t)
(D152)
1:t−1
=:F˜ ti,gi (xi 1:t−1|ktiP ). (D153)
Since Hi =(Ki,Xi ), we conclude that
t t 1:t−1
Pg (h˜i t|kti
)=F
ti,gi (h˜i t|kti
), (D154)
i,gi
forsome function F .
t
Given Lemma 13, wehave
Pg (x˜− 1:i t|hi t)= Pg P(x˜ g− 1 (: xi t i,xi 1 |h:t 0|h )0 t) = ξ tgj (x˜j 1:t|h0 t). (D155)
1:t t j Y6=i
As a result, we have
Pg (x˜− 1:i t,k˜ ti |hi t)=1
{k˜i=ki}
ξ tgj (xj 1:t|h0 t) (D156)
t t
j Y6=i
=:Φ˜ ti,g−i (x˜− 1:i t|kti ). (D157)
Since (Xt,H t−i) is a fixed function of(X− 1:i t,K ti), weconclude that
Pg (x˜t,˜h−
t
i |hi t)=Φ ti,g−i (x˜t,h˜−
t
i |kti ), (D158)
i,g−i
forsome function Φ .
t
Combining(D154)and(D158)whileusingthefactthatKi isafunctionofHi,weobtain
t t
Pg (x˜t,h˜ t|kti )=F ti,gi (h˜i t|kti )Φ ti,g−i (x˜t,h˜−
t
i |kti ). (D159)
We conclude that Ki is unilaterally sufficient information. (cid:3)
D.3 Proof of Proposition 3
Proposition 6 (Proposition3,restated) Inthe gameofExample8belief-based equilibriado
not exist.
47Proof WefirstcharacterizealltheBayes-NashequilibriaofExample8inbehavioralstrategy
profiles.Thenwewill showthatnoneoftheBNEcorrespondstoabelief-based equilibrium.
Let α=(α1,α2)∈[0,1]2 describe Alice’s behavioralstrategy: α1 is theprobability that
Alice playsU 1A =−1given X 1A =−1;α2 is theprobability thatAlice playsU 1A=+1given
X 1A =+1. Let β =(β1,β2)∈[0,1]2 denote Bob’s behavioral strategy: β1 is the probability
that Bob plays U 2B = U when observing U 1A = −1, β2 is the probability that Bob plays
UB =U when observing UA =+1.
2 1
Claim:
α∗ = 1 ,1 , β∗ = 1 +c,1 −c , (D160)
3 3 3 3
(cid:18) (cid:19) (cid:18) (cid:19)
is the uniqueBNE ofExample 8.
Given the claim, one can conclude that a belief based equilibrium does not exist in this
game:Bob’struebeliefb2onX2atthebeginningofstage2,givenhisinformationH 2B =U 1A,
would satisfy
b−(+1)= α1 , if α6=(0,1); (D161)
2 α1+1−α2
b+(+1)=
α2
, if α6=(1,0), (D162)
2 α2+1−α1
whereb− representsthebeliefunderUA=−1andb+ representsthebeliefunderUA =+1.
2 1 2 1
If Alice plays α∗ = 1,1 , then b− = b+. Under a belief-based equilibrium concept (e.g.
3 3 2 2
Ouyanget al(2016);Vasalet al(2019)),Bob’sstage behavioralstrategy β should yield the
(cid:0) (cid:1)
sameactiondistributionunderthesamebelief,whichmeansthatβ1 =β2.Howeverwehave
β∗ = 1 +c,1 −c . Therefore, (α∗,β∗), the unique BNE of the game, is not a belief-based
3 3
equilibrium. We conclude that a belief-based equilibrium does not exist in Example 8.
(cid:0) (cid:1)
Proof of Claim: Denote Alice’s totalexpected payoffto be J(α,β). Then
J(α,β)
1 1 1 1 1
= c(1−α1+α2)+ α1·2β1+ (1−α1)(1−β2)+ (1−α2)(1−β1)+ α2·2β2
2 2 2 2 2
1 1 1 1
= c(1−α1+α2)+ (2−α1−α2)+ (2α1+α2−1)β1+ (2α2+α1−1)β2.
2 2 2 2
Define J∗(α) = min J(α,β). Since the game is zero-sum, Alice plays α at some
β
equilibrium if and only if α maximizes J∗(α). We compute
1 1
J∗(α)= c(1−α1+α2)+ (2−α1−α2)+
2 2
1 1
+ min{2α1+α2−1,0}+ min{α1+2α2−1,0}.
2 2
SinceJ∗(α)isacontinuouspiecewiselinearfunction,thesetofmaximizerscanbefound
by comparing the values at the extreme points of the pieces. We have
1 1 1 1
J∗(0,0)= c+1− − = c;
2 2 2 2
J∗ 1 ,0 = 1 c· 1 + 1 · 3 + 1 ·0− 1 · 1 = 1 c+ 1 ;
2 2 2 2 2 2 2 2 4 2
(cid:18) (cid:19)
1 1 3 1 3 1 1 1 3 1
J∗ 0, = c· + · − · − ·0= c+ ;
2 2 2 2 2 2 2 2 4 2
(cid:18) (cid:19)
1 1 1 1 1
J∗(1,0)= c·0+ ·1+ ·0+ ·0= ;
2 2 2 2 2
48J∗(0,1)= 1 c·2+ 1 ·1+ 1 ·0+ 1 ·0=c+ 1 ;
2 2 2 2 2
J∗ 1 ,1 = 1 c+ 1 · 4 + 1 ·0+ 1 ·0= 1 c+ 2 ;
3 3 2 2 3 2 2 2 3
(cid:18) (cid:19)
J∗(1,1)= 1 c+ 1 ·0+ 1 ·0+ 1 ·0= 1 c.
2 2 2 2 2
α
2
(0,1) (1,1)
(0,1)
2 (1,1)
3 3
(0,0)
(1,0) (1,0) α 1
2
Fig.D1 Thepieces(polygons)forwhichJ∗(α)islinearon.Theextremepointsofthepiecesarelabeled.
Sincec< 1,wehave(1,1)tobetheuniquemaximumamongtheextremepoints.Hence
3 3 3
we have argmaxαJ∗(α) = {(1 3, 31)}, i.e. Alice always plays α∗ = (1 3, 31) in any BNE of the
game.
Now, consider Bob’s equilibrium strategy. β∗ is an equilibrium strategy of Bob only if
α∗ ∈argmaxαJ(α,β∗).
Foreach β, J(α,β) is a linear function ofα and
1 1 1 1 1 1
∇αJ(α,β)= − c− +β1+ β2, c− + β1+β2 , ∀α∈(0,1)2.
2 2 2 2 2 2
(cid:18) (cid:19)
We need ∇αJ(α,β∗) =(0,0). Hence
α=α∗
(cid:12)
(cid:12) (cid:12) −1 2c− 1
2
+β 1∗+ 21 β 2∗ =0;
1 c− 1 + 1 β∗+β∗ =0,
2 2 2 1 2
which implies that β∗ =(1 +c,1 −c), proving theclaim. (cid:3)
3 3
References
Abreu D, Rubinstein A (1988) The structure of Nash equilibrium in repeated games
with finite automata. Econometrica: Journal of the Econometric Society pp 1259–
1281. Available at https://doi.org/10.2307/1913097
49˚Astro¨m KJ (1965) Optimal control of Markov processes with incomplete state infor-
mation.Journalofmathematicalanalysisandapplications10(1):174–205.Available
at https://doi.org/10.1016/0022-247x(65)90154-x
AumannRJ,HartS,PerryM(1997)Theabsent-mindeddriver.GamesandEconomic
Behavior 20(1):102–116.Available at https://doi.org/10.1006/game.1997.0577
Banks JS, Sundaram RK (1990) Repeated games, finite automata, and
complexity. Games and Economic Behavior 2(2):97–117. Available at
https://doi.org/10.1016/0899-8256(90)90024-o
Ba¸sar T, Olsder GJ (1999) Dynamic noncooperative game theory, vol 23. SIAM
Battigalli P (1996) Strategic independence and perfect Bayesian equi-
libria. Journal of Economic Theory 70(1):201–234. Available at
https://doi.org/10.1006/jeth.1996.0082
Battigalli P (1997) Dynamic consistency and imperfect recall. Games and Economic
Behavior 20(1):31–50. Available at https://doi.org/10.1006/game.1997.0535
Bellman R (1966) Dynamic programming. Science 153(3731):34–37
Filar J, Vrieze K (2012) Competitive Markov decision processes. Springer Science &
Business Media
Fudenberg D, Tirole J (1991a) Game theory. MIT press
Fudenberg D, Tirole J (1991b) Perfect Bayesian equilibrium and sequen-
tial equilibrium. Journal of Economic Theory 53(2):236–260. Available at
https://doi.org/10.1016/0022-0531(91)90155-w
Grove AJ, Halpern JY (1997) On the expected value of games with
absentmindedness. Games and Economic Behavior 20(1):51–65. Available at
https://doi.org/10.1006/game.1997.0558
Gupta A, Nayyar A, Langbort C, et al (2014) Common information based
Markov perfect equilibria for linear-Gaussian games with asymmetric infor-
mation. SIAM Journal on Control and Optimization 52(5):3228–3260. URL
https://doi.org/10.1137/140953514
Gupta A, Langbort C, Ba¸sar T (2016) Dynamic games with asymmetric information
andresourceconstrainedplayerswith applications to security of cyberphysicalsys-
tems. IEEE Transactions on Control of Network Systems 4(1):71–81. Available at
https://doi.org/10.1109/tcns.2016.2584183
HalpernJY(1997)Onambiguitiesintheinterpretationofgametrees.GamesandEco-
nomic Behavior 20(1):66–96. Available at https://doi.org/10.1006/game.1997.0557
50Halpern JY (2009) A nonstandard characterization of sequential equilibrium, per-
fect equilibrium, and proper equilibrium. International Journal of Game Theory
38(1):37–49. Available at https://doi.org/10.1007/s00182-008-0139-0
Hendon E, Jacobsen HJ, Sloth B (1996) The one-shot-deviation principle for
sequential rationality. Games and Economic Behavior 12(2):274–282. Available at
https://doi.org/10.1006/game.1996.0018
Hinderer K (1970) Sufficient statistics, Markovian and stationary models, vol 33,
Springer Berlin Heidelberg, Berlin, Heidelberg, chap 18, pp 118–126
Kao H, Subramanian V (2022) Common information based approximate state rep-
resentations in multi-agent reinforcement learning. In: International Conference on
Artificial Intelligence and Statistics, PMLR, pp 6947–6967
Kay SM (1993) Fundamentals of statistical signal processing: Estimation theory.
Prentice-Hall, Inc.
Kreps DM, Wilson R (1982) Sequential equilibria. Econometrica: Journal of the
Econometric Society pp 863–894.Available at https://doi.org/10.2307/1912767
KuhnH(1953)Extensivegamesandtheproblemofinformation.In:Contributionsto
the Theory of Games (AM-28), Volume II. Princeton University Press, p 193–216
Kumar PR, Varaiya P (2015) Stochastic systems: Estimation, identification and
adaptive control. SIAM
MahajanA,MannanM(2016)Decentralizedstochasticcontrol.AnnalsofOperations
Research 241(1):109–126.Available at https://doi.org/10.1007/s10479-014-1652-0
Mas-Colell A, Whinston MD, Green JR (1995) Microeconomic theory, vol 1. Oxford
university press New York
Maskin E, Tirole J (2001) Markov perfect equilibrium: I. Observable
actions. Journal of Economic Theory 100(2):191–219. Available at
https://doi.org/10.1006/jeth.2000.2785
Maskin E, Tirole J (2013) Markov equilibrium, J. F. Mertens Memorial Conference.
Available at https://youtu.be/UNtLnKJzrhs
Mertens JF, Neyman A (1981) Stochastic games. International Journal of Game
Theory 10(2):53–66. Available at https://doi.org/10.1007/bf01769259
Mertens JF, Parthasarathy T (2003) Equilibria for discounted stochastic games. In:
Stochastic games and applications. Springer, p 131–172
Myerson RB (2013) Game theory. Harvard university press
51Nayyar A, Ba¸sar T (2012) Dynamic stochastic games with asymmetric information.
In: 2012 IEEE 51st IEEE Conference on Decision and Control (CDC), IEEE, pp
7145–7150,available at https://doi.org/10.1109/cdc.2012.6426857
NayyarA,MahajanA,TeneketzisD(2011)Optimalcontrolstrategiesindelayedshar-
ing information structures. IEEE Transactions on Automatic Control 56(7):1606–
1620. Available at https://doi.org/10.1109/tac.2010.2089381
Nayyar A, Gupta A, Langbort C, et al (2013a) Common information based
Markovperfectequilibriaforstochasticgameswithasymmetricinformation:Finite
games. IEEE Transactions on Automatic Control 59(3):555–570. Available at
https://doi.org/10.1109/tac.2013.2283743
Nayyar A, Mahajan A, Teneketzis D (2013b) Decentralized stochastic con-
trol with partial history sharing: A common information approach.
IEEE Transactions on Automatic Control 58(7):1644–1658. Available at
https://doi.org/10.1109/tac.2013.2239000
Ouyang Y, Tavafoghi H, Teneketzis D (2015) Dynamic oligopoly games
with private Markovian dynamics. In: 2015 54th IEEE Conference
on Decision and Control (CDC), IEEE, pp 5851–5858, available at
https://doi.org/10.1109/cdc.2015.7403139
Ouyang Y, TavafoghiH, Teneketzis D (2016)Dynamic games with asymmetric infor-
mation: Common information based perfect Bayesian equilibria and sequential
decomposition. IEEE Transactions on Automatic Control 62(1):222–237.Available
at https://doi.org/10.1109/tac.2016.2544936
Ouyang Y, Tavafoghi H, Teneketzis D (2024) An approach to stochastic dynamic
games with asymmetric information and hidden actions. Dynamic Games and
Applications pp 1–34. Available at https://doi.org/10.1007/s13235-024-00558-7
Piccione M, Rubinstein A (1997) On the interpretation of decision problems
with imperfect recall. Games and Economic Behavior 20(1):3–24. Available at
https://doi.org/10.1016/0165-4896(96)81573-3
Powell WB (2007) Approximate Dynamic Programming: Solving the curses of
dimensionality, vol 703. John Wiley & Sons
RosenbergD(1998)DualityandMarkovianstrategies.InternationalJournalofGame
Theory 27(4). Available at https://doi.org/10.1007/s001820050091
Russell S, Norvig P (2002) Artificial intelligence: A modern approach. Prentice Hall
ShapleyLS(1953)Stochasticgames.ProceedingsoftheNationalAcademyofSciences
39(10):1095–1100.Available at https://doi.org/10.1073/pnas.39.10.1095
52Shiryaev AN (1964) On Markov sufficient statistics in non-additive Bayes prob-
lems of sequential analysis. Theory of Probability & Its Applications 9(4):604–618.
Available at https://doi.org/10.1137/1109082
SmallwoodRD,SondikEJ(1973)TheoptimalcontrolofpartiallyobservableMarkov
processes over a finite horizon. Operations research 21(5):1071–1088. Available at
https://doi.org/10.1287/opre.21.5.1071
Sondik EJ (1978) The optimal control of partially observable Markov processes over
theinfinitehorizon:Discountedcosts.Operationsresearch26(2):282–304.Available
at https://doi.org/10.1287/opre.26.2.282
Striebel C (1965) Sufficient statistics in the optimum control of stochastic systems.
Journal of Mathematical Analysis and Applications 12(3):576–592. Available at
https://doi.org/10.1016/0022-247X(65)90027-2
Striebel C (1975) Statistics Sufficient for Control, Springer Berlin Heidelberg, Berlin,
Heidelberg, chap 3, pp 38–58
Subramanian J, Sinha A, Seraj R, et al (2022) Approximate information state for
approximate planning and reinforcement learning in partially observed systems.
Journal of Machine Learning Research 23:12–1
SundaramRK(1996)Afirstcourseinoptimizationtheory.Cambridgeuniversitypress
Tang D (2021) Games in multi-agent dynamic systems: Decision-making with
compressed information. PhD thesis, University of Michigan
Tang D, Tavafoghi H, Subramanian V, et al (2023) Dynamic games among teams
with delayed intra-team information sharing. Dynamic Games and Applications
13:353–411.Available at https://doi.org/10.1007/s13235-022-00424-4
Tavafoghi H (2017) On design and analysis of cyber-physical systems with strategic
agents. PhD thesis, University of Michigan, Ann Arbor
Tavafoghi H, Ouyang Y, Teneketzis D (2016) On stochastic dynamic games
with delayed sharing information structure. In: 2016 IEEE 55th Confer-
ence on Decision and Control (CDC), IEEE, pp 7002–7009, available at
https://doi.org/10.1109/cdc.2016.7799348
Tavafoghi H, Ouyang Y, Teneketzis D (2022) A unified approach to dynamic
decision problems with asymmetric information: Nonstrategic agents.
IEEE Transactions on Automatic Control 67(3):1105–1119. Available at
https://doi.org/10.1109/tac.2021.3060835
Varaiya P, Walrand J (1978) On delayed sharing patterns. IEEE
Transactions on Automatic Control 23(3):443–445. Available at
53https://doi.org/10.1109/TAC.1978.1101739
Vasal D, Sinha A, Anastasopoulos A (2019) A systematic process for evaluat-
ing structured perfect Bayesian equilibria in dynamic games with asymmetric
information. IEEE Transactions on Automatic Control 64(1):81–96. Available at
https://doi.org/10.1109/tac.2018.2809863
Watson J (2017) A general, practicable definition of per-
fect Bayesian equilibrium. unpublished draft Available at
https://econweb.ucsd.edu/∼jwatson/PAPERS/WatsonPBE.pdf
WhittleP(1969)Sequentialdecisionprocesseswithessentialunobservables.Advances
inApplied Probability 1(2):271–287.Available athttps://doi.org/10.2307/1426220
54