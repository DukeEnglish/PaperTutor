[
    {
        "title": "KNOWNET: Guided Health Information Seeking from LLMs via Knowledge Graph Integration",
        "authors": "Youfu YanYu HouYongkang XiaoRui ZhangQianwen Wang",
        "links": "http://arxiv.org/abs/2407.13598v1",
        "entry_id": "http://arxiv.org/abs/2407.13598v1",
        "pdf_url": "http://arxiv.org/pdf/2407.13598v1",
        "summary": "The increasing reliance on Large Language Models (LLMs) for health\ninformation seeking can pose severe risks due to the potential for\nmisinformation and the complexity of these topics. This paper introduces\nKNOWNET a visualization system that integrates LLMs with Knowledge Graphs (KG)\nto provide enhanced accuracy and structured exploration. Specifically, for\nenhanced accuracy, KNOWNET extracts triples (e.g., entities and their\nrelations) from LLM outputs and maps them into the validated information and\nsupported evidence in external KGs. For structured exploration, KNOWNET\nprovides next-step recommendations based on the neighborhood of the currently\nexplored entities in KGs, aiming to guide a comprehensive understanding without\noverlooking critical aspects. To enable reasoning with both the structured data\nin KGs and the unstructured outputs from LLMs, KNOWNET conceptualizes the\nunderstanding of a subject as the gradual construction of graph visualization.\nA progressive graph visualization is introduced to monitor past inquiries, and\nbridge the current query with the exploration history and next-step\nrecommendations. We demonstrate the effectiveness of our system via use cases\nand expert interviews.",
        "updated": "2024-07-18 15:37:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.13598v1"
    },
    {
        "title": "CookAR: Affordance Augmentations in Wearable AR to Support Kitchen Tool Interactions for People with Low Vision",
        "authors": "Jaewook LeeAndrew D. TjahjadiJiho KimJunpu YuMinji ParkJiawen ZhangJon E. FroehlichYapeng TianYuhang Zhao",
        "links": "http://arxiv.org/abs/2407.13515v1",
        "entry_id": "http://arxiv.org/abs/2407.13515v1",
        "pdf_url": "http://arxiv.org/pdf/2407.13515v1",
        "summary": "Cooking is a central activity of daily living, supporting independence and\nboth mental and physical health. However, prior work has highlighted key\nbarriers for people with low vision (LV) to cook, particularly around safely\ninteracting with cooking tools, such as sharp knives or hot pans. Drawing on\nrecent advancements in computer vision (CV) and robotics, we present CookAR, a\nhead-mounted AR system with real-time object affordance augmentations to\nsupport safe and efficient interactions with kitchen tools. To design and\nimplement CookAR, we manually collected and annotated the first egocentric\ndataset of kitchen tool affordances, fine-tuned an affordance segmentation\nmodel, and leveraged a stereo camera attached to an AR headset to generate the\nvisual augmentations. To validate CookAR, we conducted a technical performance\nevaluation and a three-part qualitative lab study with ten LV participants. Our\ntechnical evaluation demonstrates that our fine-tuned model outperforms the\nbase model on our class-specific dataset, while our user study indicates a\npreference for affordance augmentations over the traditional whole object\naugmentations. Code is available at: https://github.com/makeabilitylab/CookAR",
        "updated": "2024-07-18 13:46:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.13515v1"
    },
    {
        "title": "Empirical Analysis of Sri Lankan Mobile Health Ecosystem: A Precursor to an Effective Stakeholder Engagement",
        "authors": "Kenneth ThilakarathnaSachintha PitigalaJayantha FernandoPrimal Wijesekera",
        "links": "http://arxiv.org/abs/2407.13415v1",
        "entry_id": "http://arxiv.org/abs/2407.13415v1",
        "pdf_url": "http://arxiv.org/pdf/2407.13415v1",
        "summary": "Sri Lanka recently passed its first privacy legislation covering a wide range\nof sectors, including health. As a precursor for effective stakeholder\nengagement in the health domain to understand the most effective way to\nimplement legislation in healthcare, we have analyzed 41 popular mobile apps\nand web portals. We found that 78% of the tested systems have third-party\ndomains receiving sensitive health data with minimal visibility to the\nconsumers. We discuss how this will create potential issues in preparing for\nthe new privacy legislation.",
        "updated": "2024-07-18 11:38:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.13415v1"
    },
    {
        "title": "DISCOVER: A Data-driven Interactive System for Comprehensive Observation, Visualization, and ExploRation of Human Behaviour",
        "authors": "Dominik SchillerTobias HallmenDaksitha Withanage DonElisabeth AndréTobias Baur",
        "links": "http://arxiv.org/abs/2407.13408v1",
        "entry_id": "http://arxiv.org/abs/2407.13408v1",
        "pdf_url": "http://arxiv.org/pdf/2407.13408v1",
        "summary": "Understanding human behavior is a fundamental goal of social sciences, yet\nits analysis presents significant challenges. Conventional methodologies\nemployed for the study of behavior, characterized by labor-intensive data\ncollection processes and intricate analyses, frequently hinder comprehensive\nexploration due to their time and resource demands. In response to these\nchallenges, computational models have proven to be promising tools that help\nresearchers analyze large amounts of data by automatically identifying\nimportant behavioral indicators, such as social signals. However, the\nwidespread adoption of such state-of-the-art computational models is impeded by\ntheir inherent complexity and the substantial computational resources necessary\nto run them, thereby constraining accessibility for researchers without\ntechnical expertise and adequate equipment. To address these barriers, we\nintroduce DISCOVER -- a modular and flexible, yet user-friendly software\nframework specifically developed to streamline computational-driven data\nexploration for human behavior analysis. Our primary objective is to\ndemocratize access to advanced computational methodologies, thereby enabling\nresearchers across disciplines to engage in detailed behavioral analysis\nwithout the need for extensive technical proficiency. In this paper, we\ndemonstrate the capabilities of DISCOVER using four exemplary data exploration\nworkflows that build on each other: Interactive Semantic Content Exploration,\nVisual Inspection, Aided Annotation, and Multimodal Scene Search. By\nillustrating these workflows, we aim to emphasize the versatility and\naccessibility of DISCOVER as a comprehensive framework and propose a set of\nblueprints that can serve as a general starting point for exploratory data\nanalysis.",
        "updated": "2024-07-18 11:28:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.13408v1"
    },
    {
        "title": "How Private is Low-Frequency Speech Audio in the Wild? An Analysis of Verbal Intelligibility by Humans and Machines",
        "authors": "Ailin LiuPepijn VunderinkJose Vargas QuirosChirag RamanHayley Hung",
        "links": "http://arxiv.org/abs/2407.13266v1",
        "entry_id": "http://arxiv.org/abs/2407.13266v1",
        "pdf_url": "http://arxiv.org/pdf/2407.13266v1",
        "summary": "Low-frequency audio has been proposed as a promising privacy-preserving\nmodality to study social dynamics in real-world settings. To this end,\nresearchers have developed wearable devices that can record audio at\nfrequencies as low as 1250 Hz to mitigate the automatic extraction of the\nverbal content of speech that may contain private details. This paper\ninvestigates the validity of this hypothesis, examining the degree to which\nlow-frequency speech ensures verbal privacy. It includes simulating a potential\nprivacy attack in various noise environments. Further, it explores the\ntrade-off between the performance of voice activity detection, which is\nfundamental for understanding social behavior, and privacy-preservation. The\nevaluation incorporates subjective human intelligibility and automatic speech\nrecognition performance, comprehensively analyzing the delicate balance between\neffective social behavior analysis and preserving verbal privacy.",
        "updated": "2024-07-18 08:16:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.13266v1"
    }
]