[
    {
        "title": "Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions",
        "authors": "Hua ShenTiffany KnearemReshmi GhoshKenan AlkiekKundan KrishnaYachuan LiuZiqiao MaSavvas PetridisYi-Hao PengLi QiweiSushrita RakshitChenglei SiYutong XieJeffrey P. BighamFrank BentleyJoyce ChaiZachary LiptonQiaozhu MeiRada MihalceaMichael TerryDiyi YangMeredith Ringel MorrisPaul ResnickDavid Jurgens",
        "links": "http://arxiv.org/abs/2406.09264v1",
        "entry_id": "http://arxiv.org/abs/2406.09264v1",
        "pdf_url": "http://arxiv.org/pdf/2406.09264v1",
        "summary": "Recent advancements in general-purpose AI have highlighted the importance of\nguiding AI systems towards the intended goals, ethical principles, and values\nof individuals and groups, a concept broadly recognized as alignment. However,\nthe lack of clarified definitions and scopes of human-AI alignment poses a\nsignificant obstacle, hampering collaborative efforts across research domains\nto achieve this alignment. In particular, ML- and philosophy-oriented alignment\nresearch often views AI alignment as a static, unidirectional process (i.e.,\naiming to ensure that AI systems' objectives match humans) rather than an\nongoing, mutual alignment problem [429]. This perspective largely neglects the\nlong-term interaction and dynamic changes of alignment. To understand these\ngaps, we introduce a systematic review of over 400 papers published between\n2019 and January 2024, spanning multiple domains such as Human-Computer\nInteraction (HCI), Natural Language Processing (NLP), Machine Learning (ML),\nand others. We characterize, define and scope human-AI alignment. From this, we\npresent a conceptual framework of \"Bidirectional Human-AI Alignment\" to\norganize the literature from a human-centered perspective. This framework\nencompasses both 1) conventional studies of aligning AI to humans that ensures\nAI produces the intended outcomes determined by humans, and 2) a proposed\nconcept of aligning humans to AI, which aims to help individuals and society\nadjust to AI advancements both cognitively and behaviorally. Additionally, we\narticulate the key findings derived from literature analysis, including\ndiscussions about human values, interaction techniques, and evaluations. To\npave the way for future studies, we envision three key challenges for future\ndirections and propose examples of potential future solutions.",
        "updated": "2024-06-13 16:03:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.09264v1"
    },
    {
        "title": "Evaluating Privacy, Security, and Trust Perceptions in Conversational AI: A Systematic Review",
        "authors": "Anna LeschanowskySilas RechBirgit PoppTom Bäckström",
        "links": "http://arxiv.org/abs/2406.09037v1",
        "entry_id": "http://arxiv.org/abs/2406.09037v1",
        "pdf_url": "http://arxiv.org/pdf/2406.09037v1",
        "summary": "Conversational AI (CAI) systems which encompass voice- and text-based\nassistants are on the rise and have been largely integrated into people's\neveryday lives. Despite their widespread adoption, users voice concerns\nregarding privacy, security and trust in these systems. However, the\ncomposition of these perceptions, their impact on technology adoption and usage\nand the relationship between privacy, security and trust perceptions in the CAI\ncontext remain open research challenges. This study contributes to the field by\nconducting a Systematic Literature Review and offers insights into the current\nstate of research on privacy, security and trust perceptions in the context of\nCAI systems. The review covers application fields and user groups and sheds\nlight on empirical methods and tools used for assessment. Moreover, it provides\ninsights into the reliability and validity of privacy, security and trust\nscales, as well as extensively investigating the subconstructs of each item as\nwell as additional concepts which are concurrently collected. We point out that\nthe perceptions of trust, privacy and security overlap based on the\nsubconstructs we identified. While the majority of studies investigate one of\nthese concepts, only a few studies were found exploring privacy, security and\ntrust perceptions jointly. Our research aims to inform on directions to develop\nand use reliable scales for users' privacy, security and trust perceptions and\ncontribute to the development of trustworthy CAI systems.",
        "updated": "2024-06-13 12:20:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.09037v1"
    },
    {
        "title": "Beyond Recommendations: From Backward to Forward AI Support of Pilots' Decision-Making Process",
        "authors": "Zelun Tony ZhangSebastian S. FegerLucas DullenkopfRulu LiaoLukas SüsslinYuanting LiuAndreas Butz",
        "links": "http://arxiv.org/abs/2406.08959v1",
        "entry_id": "http://arxiv.org/abs/2406.08959v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08959v1",
        "summary": "AI is anticipated to enhance human decision-making in high-stakes domains\nlike aviation, but adoption is often hindered by challenges such as\ninappropriate reliance and poor alignment with users' decision-making. Recent\nresearch suggests that a core underlying issue is the recommendation-centric\ndesign of many AI systems, i.e., they give end-to-end recommendations and\nignore the rest of the decision-making process. Alternative support paradigms\nare rare, and it remains unclear how the few that do exist compare to\nrecommendation-centric support. In this work, we aimed to empirically compare\nrecommendation-centric support to an alternative paradigm, continuous support,\nin the context of diversions in aviation. We conducted a mixed-methods study\nwith 32 professional pilots in a realistic setting. To ensure the quality of\nour study scenarios, we conducted a focus group with four additional pilots\nprior to the study. We found that continuous support can support pilots'\ndecision-making in a forward direction, allowing them to think more beyond the\nlimits of the system and make faster decisions when combined with\nrecommendations, though the forward support can be disrupted. Participants'\nstatements further suggest a shift in design goal away from providing\nrecommendations, to supporting quick information gathering. Our results show\nways to design more helpful and effective AI decision support that goes beyond\nend-to-end recommendations.",
        "updated": "2024-06-13 09:44:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08959v1"
    },
    {
        "title": "Human-Robot Interface for Teleoperated Robotized Planetary Sample Collection and Assembly",
        "authors": "Lorenzo PagliaraVincenzo PetroneEnrico FerrentinoPasquale Chiacchio",
        "links": "http://dx.doi.org/10.1109/MetroAeroSpace57412.2023.10189984",
        "entry_id": "http://arxiv.org/abs/2406.08946v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08946v1",
        "summary": "As human space exploration evolves toward longer voyages farther from our\nhome planet, in-situ resource utilization (ISRU) becomes increasingly\nimportant. Haptic teleoperations are one of the technologies by which such\nactivities can be carried out remotely by humans, whose expertise is still\nnecessary for complex activities. In order to perform precision tasks with\neffectiveness, the operator must experience ease of use and accuracy. The same\nfeatures are demanded to reduce the complexity of the training procedures and\nthe associated learning time for operators without a specific background in\nrobotic teleoperations. Haptic teleoperation systems, that allow for a natural\nfeeling of forces, need to cope with the trade-off between accurate movements\nand workspace extension. Clearly, both of them are required for typical ISRU\ntasks. In this work, we develop a new concept of operations and suitable\nhuman-robot interfaces to achieve sample collection and assembly with ease of\nuse and accuracy. In the proposed operational concept, the teleoperation space\nis extended by executing automated trajectories, offline planned at the control\nstation. In three different experimental scenarios, we validate the end-to-end\nsystem involving the control station and the robotic asset, by assessing the\ncontribution of haptics to mission success, the system robustness to consistent\ndelays, and the ease of training new operators.",
        "updated": "2024-06-13 09:17:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08946v1"
    },
    {
        "title": "NICER: A New and Improved Consumed Endurance and Recovery Metric to Quantify Muscle Fatigue of Mid-Air Interactions",
        "authors": "Yi LiBenjamin TagShaozhang DaiRobert CrowtherTim DwyerPourang IraniBarrett Ens",
        "links": "http://dx.doi.org/10.1145/3658230",
        "entry_id": "http://arxiv.org/abs/2406.08875v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08875v1",
        "summary": "Natural gestures are crucial for mid-air interaction, but predicting and\nmanaging muscle fatigue is challenging. Existing torque-based models are\nlimited in their ability to model above-shoulder interactions and to account\nfor fatigue recovery. We introduce a new hybrid model, NICER, which combines a\ntorque-based approach with a new term derived from the empirical measurement of\nmuscle contraction and a recovery factor to account for decreasing fatigue\nduring rest. We evaluated NICER in a mid-air selection task using two\ninteraction methods with different degrees of perceived fatigue. Results show\nthat NICER can accurately model above-shoulder interactions as well as reflect\nfatigue recovery during rest periods. Moreover, both interaction methods show a\nstronger correlation with subjective fatigue measurement (r = 0.978/0.976) than\na previous model, Cumulative Fatigue (r = 0.966/ 0.923), confirming that NICER\nis a powerful analytical tool to predict fatigue across a variety of\ngesture-based interactive applications.",
        "updated": "2024-06-13 07:22:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08875v1"
    }
]