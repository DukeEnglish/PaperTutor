Multi-Agent Software Development through Cross-Team Collaboration
ZhuoyunDu†♣ ChenQian†⋆ WeiLiu⋆ ZihaoXie⋆
YifeiWang⋆ YufanDang⋆ WeizeChen⋆ ChengYang♠(cid:66)
♣ZhejiangUniversity ⋆TsinghuaUniversity
♠BeijingUniversityofPostsandTelecommunications
duzy.zju@outlook.com qianc62@gmail.com yangcheng@bupt.edu.cn
Abstract 1989;SawyerandGuinan,1998). Thiscollabora-
tiveprocessinvolvesextensivecommunicationto
The latest breakthroughs in Large Language interpretandanalyzeprojectrequirementsthrough
Models(LLMs),e.g.,ChatDev,havecatalyzed natural language, complemented by the develop-
profoundtransformations,particularlythrough
mentanddebuggingphasesexecutedinprogram-
multi-agent collaboration for software devel-
minglanguages(Ernst,2017;Bankeretal.,1998).
opment. LLMagentscancollaborateinteams
Recentadvancementsindeeplearningtechniques
like humans, and follow the waterfall model
havemotivatedresearcherstoexploretheirapplica-
tosequentiallyworkonrequirementsanalysis,
development,review,testing,andotherphases tioninsoftwareengineering,toenhanceeffective-
to perform autonomous software generation. ness, and efficiency while reducing costs (Ezzini
However, for an agent team, each phase in a etal.,2022;López-MartínandAbran,2015). Prior
singledevelopmentprocessyieldsonlyonepos-
studiesindeeplearning-basedsoftwareengineer-
sibleoutcome. Thisresultsinthecompletion
ing have addressed a variety of tasks, including
ofonlyonedevelopmentchain,therebylosing
phasesinthedevelopmentchainlikesoftwarere-
the opportunity to explore multiple potential
quirements, design, implementation, testing, and
decisionpathswithinthesolutionspace. Con-
sequently, this may lead to obtaining subop- maintenance(Pudlitzetal.,2019;Nijkampetal.,
timal results. To address this challenge, we 2022). However, the methods used in these dif-
introduce Cross-Team Collaboration (CTC), ferent phases have typically been isolated due to
ascalablemulti-teamframeworkthatenables inconsistenciesintheirapplication.
orchestratedteamstojointlyproposevarious
TherapidadvancementofLargeLanguageMod-
decisionsandcommunicatewiththeirinsights
els(LLMs)hasyieldedremarkableachievements
inacross-teamcollaborationenvironmentfor
acrossvariousdomainslikenaturallanguagepro-
superiorcontentgeneration. Experimentalre-
cessing(Vaswanietal.,2017;Brownetal.,2020),
sultsinsoftwaredevelopmentrevealanotable
increase in quality compared to state-of-the- textgeneration(Bubecketal.,2023)andprogram-
artbaselines,underscoringtheefficacyofour ming (Richards, 2023; Dong et al., 2023). How-
framework. Thesignificantimprovementsin ever,limitationslikehallucinationsinherentintheir
story generation demonstrate the promising
standalonecapabilities(Richards,2023;Agnihotri
generalizationabilityofourframeworkacross
and Chug, 2020), impede LLM’s ability to gen-
variousdomains. Weanticipatethatourwork
erate usable content for task solving when con-
will guide LLM agents towards a cross-team
frontedwithcomplexitiessurpassingmerechatting.
paradigm and contribute to their significant
growth in but not limited to software devel- Recent progress in autonomous agents, with the
opment. Thecodeanddatawillbeavailableat integration of sophisticated features like context-
https://github.com/OpenBMB/ChatDev. sensitive memory (Park et al., 2023), multi-step
planning(Weietal.,2022b),andeffectiveutiliza-
1 Introduction tion of external tools (Schick et al., 2024), has
enhanced their collaborative abilities. Through
Inthefieldofsoftwaredevelopment,thecomplex-
linguisticinteraction,differentagentscannowef-
ityisprofound,requiringasynergisticeffortfrom
fectivelytackleabroaderrangeofcomplextasks
professionalswithaspectrumofexpertise(Basili,
includebutisnotlimitedto,mathematicalreason-
ing (Wei et al., 2022b; Lu et al., 2022), software
†EqualContribution.
(cid:66)CorrespondingAuthor. development (Osika, 2023; Qian et al., 2024c),
4202
nuJ
31
]LC.sc[
1v97980.6042:viXragameplaying(Wangetal.,2023a;Zhuetal.,2023; outcome? In this paper, we propose Cross-Team
Wangetal.,2023c;Gongetal.,2023),socialsim- Cooperation(CTC),aframeworkthatcarefullyor-
ulation (Park et al., 2023; Li et al., 2023b; Zhou chestratesagentsintomultipleteams,eachwiththe
et al., 2023b; Hua et al., 2023), and scientific re- same task assignment to communicate in a coop-
search(Huangetal.,2023;Liangetal.,2023). erativeenvironment. Specifically,ourframework
When tackling complex tasks, great perfor- enablesdifferentteamstoconcurrentlyproposevar-
mance often necessitates collaboration (Hardin, ioustask-orienteddecisionsasinsightsforcontent
1968;RandandNowak,2013;Hutteretal.,2011; generation(single-teamproposal)andthencommu-
Wangetal.,2023e;Woolleyetal.,2010;Fehrand nicateforinsightsinterchangeinsomeimportant
Gächter,2000;Chenetal.,2023b;Kaddouretal., phases(multi-teamaggregation). Differentagent
2023). Anoteworthybreakthroughincollaborative teamsutilizeagreedypruningmechanismtoelimi-
autonomousagentsliesintheintegrationofinter- natelow-qualitycontentandthencarryoutasolu-
actionsamongmultipleagents(Parketal.,2023; tionaggregationmechanismtoaggregatevarious
Li et al., 2023a; Qian et al., 2024c,a,b). Typical contentintoasuperioroutcomecollaboratively.
methods (Qian et al., 2024c; Hong et al., 2023) Through our experiments with 15 tasks from
decomposetaskintoseveraldistinctsubtasks. An different categories and styles randomly selected
instructoragentandanassistantagentareassigned fromtheSRDDdataset(Qianetal.,2024c)forsoft-
tosolveeachsubtask. Theinstructorgivesinstruc- waregeneration(programming-language-oriented
tionsonthesubtaskandtheassistantrespondswith reasoning),wedemonstrateasignificantimprove-
asolution. Throughmulti-turnautonomouscom- mentinsoftwarequalityusingtheproposedframe-
munication between agents, they collaboratively work. We highlight the importance of diversity
generatecontent(e.g.,software,mathresults,sci- acrossteamsandemphasizetheimportanceoffos-
entificconclusion)forthetask. Itisnoteworthythat tering a cross-team collaboration environment in
thecontentproducedcanvaryacrossmultipleiter- bolstering teams’ performance through our prun-
ationsgiventhesametask,reflectingthedynamic ing mechanism. Furthermore, to further demon-
nature of the problem-solving process (Achiam strate the generalizability of our framework, we
et al., 2023). In the field of multi-agent systems extendeditsapplicationtothedomainofstorygen-
forsoftwaredevelopment,aseriesofautonomous eration(natural-language-orientedreasoning),ran-
agentsinteractthroughadevelopmentchainwith domlyincorporating10tasksfromtheROCStories
multipleconfigurabletask-orientedphasescanbe dataset (Chen et al., 2019). The results revealed
regardedasasingle-team. Theteamcompletesthe anotableimprovementinstoryquality. Ourfind-
developmentchainthroughchatchain(Qianetal., ingsunderscoretheefficacyandpromisinggener-
2024c)andgeneratesthesequential,task-oriented alization of our framework in complex tasks. In
data(suchasrequirementdocuments, codes, test summary,ourcontributionsarethreefold:
cases,andusermanuals),whichcanberegardedas
adecisionpathwithinthesolutionspace. • We propose Cross-Team Collaboration (CTC),
However, one agent team can only execute all ascalablemulti-teamcollaborationframework
phases sequentially according to its pre-defined that efficiently orchestrates LLM agents into
team configuration (e.g., the number of agents, multiple teams to perform multi-team interac-
agentprofiles,LLMhyperparameters),anditsde- tions, which facilitates seamless content ex-
cisionpathisfixed(Qianetal.,2024c;Hongetal., changeamongagentteamsandeffectivelysup-
2023;Qianetal.,2024a,b). Thisdesignmaylead ports the generation of diverse content forms,
torepetitiveerrorsbyanagentteamwithapartic- includingprogramminglanguageandnaturallan-
ular configuration when facing a certain type of guage.
problem,preventingself-correction. Additionally,
itrestrictstheagentsfromexploringmoreandbet- • Our approach involves concurrent reasoning
ter decision paths. Therefore, it is necessary to within each team, followed by the aggregation
introduce multiple agent teams that are aware of ofdiversecontentfrommultipleteamsintoasu-
eachother,enablingthemtocollaborateeffectively perioroutcomethroughgreedypruning,which
toexploremorepotentialpaths. Thenthechallenge effectivelyincorporatesmultidimensionalsolu-
becomes: Howcanmulti-agentsystemsobtainand tionsbyretainingtheirstrengthsandeliminating
utilize insights from others to achieve a superior theirdrawbacks.• Weconductedextensiveexperimentsdemonstrat- Caietal.,2023;Qinetal.,2023a;Ruanetal.,2023;
ingtheeffectivenessandgeneralizabilityofour Yang et al., 2024), thus enabling independent op-
frameworkinsoftwaredevelopment,indicating erationwithinintricatereal-worldcontexts(Zhao
thatmulti-teamcollaborationoutperformsindi- et al., 2024; Zhou et al., 2023a; Ma et al., 2023;
vidualefforts. Zhangetal.,2023;Wangetal.,2023b;Dingetal.,
2023;Weng,2023). Additionally,LLMshaveex-
Organization. Thesubsequentsectionsofthispa- hibitedformidablerole-playingcapabilitiesinvar-
per is organized as follows. We highlight some iousdesignatedroles(Lietal.,2023a;Parketal.,
worksrelatedtothispaperinSection2. Section3 2023; Hua et al., 2023; Chan et al., 2023; Zhou
providespreliminariesofourwork. Thenwepro- et al., 2023b; Chen et al., 2023b; Cohen et al.,
vide the methodology of our framework in Sec- 2023;Lietal.,2023b). Recentexplorationofau-
tion 4, detailing the formation of a single agent tonomousinteractionsamongmultipleagentsher-
team and the method to orchestrate these teams. aldsapromisingparadigmshifttowardscollabora-
Section5describesthedatasetusedinourexperi- tivemulti-agenttask-solving(Lietal.,2023a;Qian
mentandshowstheexperimentalresultsandanal- etal.,2024a;Parketal.,2023;Zhouetal.,2023b;
ysis. Thelimitationsofourworkarediscussedin Chenetal.,2023b;Chanetal.,2023;Chenetal.,
Section6. Finally, weconcludethepaperinSec- 2023a; Cohen et al., 2023; Li et al., 2023b; Hua
tion7, andsuggestpotentialdirectionsforfuture etal.,2023). Thesesystems,whichassigndistinct
research. roles to an instructor and an assistant, foster col-
laborativeinteractionsamongautonomousagents.
2 RelatedWork
Thiscollaborationefficientlydecomposescomplex
tasksintomanageablesubtasks(Qianetal.,2024c;
Softwareengineering(SE)isthesystematic,rigor-
Hongetal.,2023;Wuetal.,2023). Theinstructor
ous,andmeasurableprocessofdesigning,develop-
provides directional instructions, while the assis-
ing,testing,andmaintainingsoftware1. Thecom-
tantofferspertinentresponses. Thisapproachnot
plexityinherentinSEoftennecessitatesdecision-
onlyenhancesproductivitybutalsofacilitateswell-
makingthatisheavilyreliantonintuitionand,in
orchestratedworkflowfortaskcompletion,thereby
the best-case scenario, consultation with experi-
significantlyreducingthenecessityforhumanin-
enceddevelopers. Previousresearchondeeplearn-
tervention (Li et al., 2023a; Qian et al., 2024c;
ing(DL)hasshownremarkablepromisewhenap-
Chen et al., 2023b). An exemplary instance is
pliedtoSE(Pudlitzetal.,2019;López-Martínand
ChatDev (Qian et al., 2024c), a virtual software
Abran, 2015; Alahmadi et al., 2020; Wang et al.,
company powered by LLMs. It leverages agents
2021;Wanetal.,2022,2018;Naharetal.,2022).
inrolessuchasreviewerandprogrammerwithin
The emergence of LLMs has yielded novel solu-
a chat-chain workflow, breaking the isolation of
tions. Trainedonvastdatasetswithextensivepa-
stepsinthesoftwareengineering(SE)processand
rameters,LLMshaverevolutionizedthelandscape
substantiallyenhancingtheefficiencyofsoftware
ofnaturallanguageprocessing(Brownetal.,2020;
development.
Bubecketal.,2023;Vaswanietal.,2017;Radford
Recentstudieshavehighlightedthesignificance
etal.,2019;Touvronetal.,2023;Weietal.,2022a;
of multi-agent collaboration and competition in
Shanahan et al., 2023; Chen et al., 2021; Brants
enhancingtheirperformanceinscenarioslikepro-
etal.,2007;Ouyangetal.,2022;Yangetal.,2023;
gramming, game playing, and reasoning (Wang
Qin et al., 2023b; Kaplan et al., 2020; Achiam
etal.,2024;Lightetal.,2023;Lietal.,2024;Duan
et al., 2023). Their impact is particularly signifi-
etal.,2024;Xuetal.,2023;Piattietal.,2024;Dong
cantwithintherealmofautonomousagents(Zhou
etal.,2023). Additionally,researchonscalingthe
etal.,2023a;Wangetal.,2023a;Parketal.,2023;
numberofagentspointedoutthattheuseofsimple
Wangetal.,2023c;Richards,2023;Osika,2023;
votingmechanismsandstraightforwardtopological
Wang et al., 2023d), where these agents exhibit
communicationstrategiescanenhancethequality
proficiencyintaskdecompositionplanning(Chen
ofcontentgeneratedbymultipleagents(Lietal.,
etal.,2023b;Liuetal.,2023),retrieval-augmented
2024; Yin et al., 2023). Research on Graph-like
memory (Park et al., 2023; Sumers et al., 2023),
multi-agent systems has introduced a novel per-
and strategic tool utilization (Schick et al., 2024;
spectiveonthestructuringofcommunicationnet-
1www.computer.org/sevocab works (Hu et al., 2023; Zhuge et al., 2024; BestaPhases Design Coding Testing
Subtasks Design Code Writing Code Complete Code Review System Testing
CEO CTO CTO Reviewer Tester
Instructor
Chat Chain {task} {ideas} {code} {code} {code} {code}
Assistant
CTO Programmer Programmer Programmer Programmer
Figure1: Asingle-teamintegratesLLMagentsassignedtovariousrolessuchasrequirementsanalysts,professional
programmers,andtestengineers. Uponreceptionofaninitialtaskrequirement(e.g.,“DevelopaTetrisgame”),
theagentsengageinmulti-turncommunicationandsequentiallycompletesubtasksalongachatchain. Through
autonomouscollaborationonaseriesofsubtasks,theycollectivelydeviseacomprehensivesolution.
etal.,2024;Jiangetal.,2023),endowingthecom- Tomitigatecommunicationhallucinations,a"role
municationarchitecturewithenhanceddynamism reversal"mechanismisimplemented. Inthismech-
andfacilitatingmoreefficaciouscontentexchange anism,theassistantassumesaninstructor-likerole,
amongtheconstituentagents. Nonetheless,anin- actively seeking more detailed information (e.g.,
crease in agent calls may engender diminishing theexactnameofanexternaldependencyandits
returns,andinsomeinstances,mayevendegrade associatedclass)beforeprovidingaconclusivere-
modelperformance(Chenetal.,2024;Piattietal., sponse. Oncetheinstructoroffersaspecificmodi-
2024). Suggesting that it is not viable for further ficationsuggestion,theassistantthencarriesout
improvementintheperformanceofamulti-agent preciseoptimization,asillustrated:
systembysolelyincreasingthescaleoftheagents.
⟨I → A, ⟨A → I, I (cid:59) A⟩⟲, A (cid:59) I⟩⟲ (3)
3 Preliminaries
Thismechanismaddressesonespecificissueata
Before delving into the main idea, we introduce
time,necessitatingmultiplerounds(⟲)ofcommu-
somebackgroundknowledge: ChainasTeamand
nication to refine and optimize various potential
AgentCommunication(Qianetal.,2024c;Lietal.,
problems.
2023a). Theseconceptsserveasthefoundational
componentsofourproposedarchitecture. 4 Methodology
Definition1(ChainasTeam) As illustrated in
Inthissection,wefocusonstudyingcollaborative
Figure 1, a single-team (C) is conceptualized as
behavioramongmulti-teamsthatsharewithsame
achain-likestructurecomposedofaseriesoftask-
task objective. In the single-team that performs
orientedphases(⟨P1,P2,...,P|C|⟩)thatsequen-
intra-teamcollaboration(Single-TeamExecution),
tiallyaddresstheresolutionoftaskswhichcanbe
apreliminaryideaisgivenatthestart,andagents
formulatedas:
arrangedinachain-likestructuredteamwillcom-
C = ⟨P1,P2,...,P|C|⟩ (1) plete it autonomously through conversations. To
transcendtheisolatednatureofSingle-TeamExecu-
We refer to such a chain-like structure as a team tionandharnessinsightseffectivelyfrommultiple
thatcouldparticipateinourCTCframework. teams, it is crucial to devise a framework that fa-
cilitateseffectivecross-teaminteractions,enabling
Definition2(AgentCommunication) In each
teamstoengagecollaboratively,culminatingina
phase, agent communications occur between the
consensusthatyieldssuperiorcontent.
Instructor (I) and the Assistant (A), adhering to
astraightforwardinstruction-responseformat,as
4.1 Single-TeamExecution
depicted:
The direct generation of complex content us-
⟨I → A, A ← I⟩⟲ (2) ing LLMs could lead to hallucinations (Mannet al., 2020). These hallucinations may manifest streamlined, lacks the diversity ofinsights neces-
as incomplete content, misinformation, and non- sarytoexploreawiderrangeofdecisionpathways
compliantresponses. Thehallucinationsprimarily forsuperiorcontent. Astraightforwardapproachis
stemfromtwoaspects. Firstly,thelackofguidance torunnteamssimultaneouslygiventhesametask
in tasks confuses LLMs when generating entire andensembletheresultsfromthesenteams. How-
contentatonce(Azamfireietal.,2023). Secondly, ever,thissimpleanddirectensemblingofresults
the absence of cross-examination in the content- overlooks the mutual awareness between teams
generatingprocessexposesconsiderablevulnera- duringintermediatephases,leadingtoinsufficient
bilities. Individualmodelinstancespresentavar- collaboration. Thisisakintoexploringnpathsin
ied spectrum of responses, throwing the need to parallel,whereascrossingtheintermediatephase
debateorexaminetheresponsesfromothermodel nodesofthesepathscanpotentiallyexploremore
instances to reach a unified and refined consen- paths. Yet, this introduces new issues, such as a
sus (Du et al., 2023; Yin et al., 2023; Li et al., significantincreaseincommunicationbandwidth
2023a; Qian et al., 2024c; Chan et al., 2023; Du andthepossibilityofincorporatingnoisefromun-
etal.,2023). derperformingteams. Toaddressthis,wepropose
Single-TeamExecutionaddressestheaforemen- anewcross-teamcooperativeframework. Inthis
tionedissuestoacertainextentbyformingagents setup,intermediatephasenodesinvolvebothintra-
intoachain-liketeamthatperformsintra-teamcol- team and inter-team collaboration. Within each
laborationtodividethetaskintomanageablesub- team,membersworktogetherharmoniously,while
tasks and conquer them through phases various betweenteams,strengthsfromothersareleveraged
from decision making, and designing to content tocompensateforweaknesses. Essentially,thisap-
writingalongthechain. InspiredbyChatDev(Qian proachallowsfortheexplorationofmorepotential
etal.,2024c),aSingle-TeamExecution(C)iscom- paths through intermediate node crossover while
posed of multiple phases (P), each divided into alsopruningtoensurethequalityofthecandidate
atomicsubtasksfocusedonrole-playingwithtwo paths.
roles: instructor(I)andassistant(A). Theinstruc- We propose Cross-Team Collaboration (CTC),
tor initiates dialogues by providing instructions which is denoted by N. CTC orchestrates par-
(→) to guide the subtask (T), while the assistant allel executions of Single-Team Execution (S =
followstheseinstructionsandrespondswith((cid:59)) {C1,C2,··· ,Cn}) with configurable temperature
solutions. Throughamulti-turndialogue(C),they and length of chains2, and each team is assigned
collaboratetoreachaconsensus,extracting(τ)so- the same task objective. These teams jointly pro-
lutionsrangingfromtexttocode,thuscompleting posevarioustask-orienteddecisionsbasedontheir
the subtask. The comprehensive process of the different perspectives. After key phases (K) like
task-solving process along the chat chain can be designingandwritingwhereimportantdecisionsor
formulatedas: significantcontentchangesaremade,teamswould
"wait"andextractthecontentsforcommunications
C = ⟨P1,P2,...,P|C|⟩ (E = {e ,e ,··· ,e }) and facilitate a greedy
1 2 |K|
Pi = ⟨T1,T2,...,T|Pi|⟩ pruningmechanismtoeliminatelow-qualitycon-
(4)
Tj = τ(cid:0) C(I,A)(cid:1) tent. Afterthatcontentsarepartitionedintogroups
andcollaborativelyaggregatedintomoresuperior
C(I,A) = ⟨I → A, A (cid:59) I⟩
⟲ content. Thiscommunicativedynamiccanbenatu-
Achatchaincorrespondstoadecisionpathway rallymodeledas:
insolutionspace,offeringatransparentviewofthe
contentgenerationprocessbytheagentsinateam.
N = {Ci | Ci ∈ S}∪E E = {e | Pi ∈ K}
i
4.2 Cross-TeamCollaboration
(5)
Facingdiversetasks,Single-TeamExecutionoften Through Cross-Team Collaboration, a cross-
tacklestasksinisolation. Thequalityandtendency team network is established, driving teams to be
ofcontentproducedbyaSingle-TeamExecutionin
aphasearepredominantlydeterminedbythedeci- 2Length Diversity can be induced manually and au-
tonomously.Evenaftertheconfigurationofvariousphasesfor
sionsmadebypriorphases,whicharethen"baton
theteams,thelengthofthechatchainscancontinuetovary
passed"toasubsequentphase. Thisprocess,while autonomouslyalongthedecision-makingprocess.Team1 Agent
Content
Team2
Team3
Feature
Team4 Collaborate
Figure2: TheaggregationprocessinCross-TeamCollaborationinvolvesmultipleagents( )fromdifferentteams
contributingavarietyofcontent( ). Thesecontentsarepartitionedintogroupsandcooperatively( )integrated
throughcommunications,highlightingthedistinctivefeatures( )ofeachteam. Ultimately,thisprocessresultsina
superioroutcomethatembodiesthefeaturesofallparticipatingteams.
moreinnovativeandeffectiveintheproductionof ined. After pruning a proportion of content, we
superiorcontent. proposetouseafirst-partition-then-aggregatepro-
cess for the filtered content which makes diverse
4.2.1 GreedyPruning pathwayseventuallyconvergeintoasingular,co-
hesiveoutcome.
Intherealmofreal-worldscenarios,thepursuitof
optimal outcomes often necessitates the strategic
4.2.2 HierarchyPartitioning.
placementofmultipleteamswithinacompetitive
andcollaborativeenvironment(Hardin,1968;Rand Topreventlong-contextissuesrootedintheover-
andNowak,2013;Hutteretal.,2011;Piattietal., whelming amount of simultaneous content com-
2024;Chenetal.,2023b). Asthenumberofteams municationsburdenonanagent,WeproposeaHi-
initially configured in Cross-Team Collaboration erarchyPartitioningmechanismwhereteamsare
increases, wider insights are proposed, causing a dividedintogroupstocollaborateandmerge. The
significant expansion in generating pathways of outcomeofeachgroupadvancestothenextlevel,
thefinalcontent. Meanwhile,weobservethatnot continuingtheprocessuntilonlyoneteamisleft.
all content as insights that participate in commu- Throughuniformpartitioningwithexpectedquan-
nications contributes positively to the optimized tityuofcontentpercommunication,weobtaina
content,low-qualitycontentcanharmthequality setofcommunicativegroupsG = {g 1,g 2,...,gn}.
u
of content and increase the communication bur- Each element g comprises a subset of content
i
den. Therefore, we introduce a Greedy Pruning R = {r ,r ,...,r }participatesincollaboration.
1 2 n
mechanism to filter out some teams early on, al- Afterpartitioning,theaggregationmechanism(↣)
lowingonlythemostpromisingonestoproceedto isconducted, generatinganoptimizedsetofcon-
engage in inter-team collaboration. This process tent R1 = {r1,r1,...,r1 }. These optimized
1 2 |G|
involvesarigorousqualityassessmentconducted contentundergoasubsequentpartitioningintonew
on content, which results in the elimination of a groups. Thisprocesscanbeformalizedasfollows:
predefinedproportionofthecontentitemswithlow
qualityfromteams,greedilyelectinghigh-quality (cid:110) (cid:111)
Gk+1 = gk+1 | gk+1 ⊆ Rk
content for the following processes. This quality i i (6)
assessmentandpruningmechanismaredesigned Gk+1 ↣ Rk+1
tobalancethequantityandqualityofcontent,en-
suringthatthemostvaluablecontributionsarecar- whereGkisthesetofcommunicativegroupsand
ried forward while the communication burden is Rk isthesetofcontentsthatparticipatesincom-
bearable. A comprehensive breakdown of the as- municationsataggregateiterationk. Thisiterative
sessment methodology can be found in Evalua- process persists until the cardinality of R is one,
tion5section,wherethedetailsandefficacyofour whichisthefinalaggregatedcontent,leadingtothe
GreedyPruningmechanismarethoroughlyexam- formationofhierarchicalcommunicativegroups.4.2.3 GreedyAggregation. andthetemperatureparameteris0.2. Weconducta
In Hierarchy Partitioning, the teams within each GreedyPruningmechanismonlyon8-teamCTCin
group need to collaborate and determine the best ourexperiments. Weintroduceawaitingphasefor
in the group. This process is not simply about
theCross-TeamCollaborationafterthecodingand
eliminatingteamstoselectthebestone,butrather codecompletionphases3 forcodegenerationtasks
about combining the strengths of all teams while and after the writing phase for story generation
eliminatingtheirweaknesses,asshowninFigure2. tasks. Our software generation experiments ran-
Essentially,itisaprocessofsynthesizingmultiple domlydraw15tasksfromtheSRDDdataset(Qian
decision paths into a single, optimal path. To ag- et al., 2024c), a specialized open-source collec-
gregatevariouspathwaysintoasuperiorone, we tion tailored for the "Natural Language to Soft-
introduce an aggregation mechanism harnessing ware Generation" domain, and 10 tasks for story
thefeaturesofcontent. InoneGreedyAggregation generation from ROCStories (Chen et al., 2019),
process,arole-assignedagentMmeticulouslyex- a collection of commonsense 5 sentences short
tractsthestrengthsanddrawbacksofeachcontent stories can be used for longer stories generation.
withineachcommunicativegroup. Itthencollab- Inestablishingourbaselines,wecompareagainst
orativelyaggregates(↣)arewrittencontentthat GPT-Engineer (Osika, 2023), a single-agent ap-
greedilyintegratesstrengthsandeliminatesdraw- proachtosoftwaredevelopment, aswellasChat-
backs. Subsequently,outlinesthechangesmadein Dev (Qian et al., 2024c), MetaGPT (Hong et al.,
the rewritten content explicitly. This comprehen- 2023),andAgentVerse(Chenetal.,2023b),which
sivereportfacilitatesabetterunderstandingofthe represent the state-of-the-art multi-agent single-
rewrittencontentandsupportsfurtheroptimization team paradigms for software development. We
andimprovementefforts,boostingtheperformance alsoincorporateGPTSwarm(Zhugeetal.,2024),
ofM. Thisaggregationprocesscanberepresented agraph-likemulti-agentsingle-teamagentframe-
as: workasastrongbaseline. Theperformancemetrics
aretheaverageacrossalltaskswithinthetestset.
(cid:26) M(gk) ↣ rk+1 |gk| ≠ 1 All baseline evaluations adhere to our proposed
i i i (7)
gk → rk+1 |gk| = 1 framework’ssamehyperparametersandsettingsto
i i i
ensureafaircomparison.
Where r represent a rewritten content from an
agent, and gk represents a communicative group Metrics for Software Evaluation Evaluating
i
comprising{rk,rk ,...,rk }. Ifacommunica- softwaregeneratedbyLLMisachallengingtask,
j j+1 j+u
tivegroupcontainsonlyasinglepieceofcontent,it especiallywhenassessingitonaholisticlevel. As
isdirectlytransferred(→)tobecometherewritten asolution,weusefourfundamentaldimensionsto
content without undergoing the aggregation pro- assessspecificaspectsofthesoftwareproposedby
cess. previousworks(Qianetal.,2024a,c).
• Completeness4 (α ∈ [0,1]) measures the soft-
5 Evaluation
ware’scapacityforcomprehensivecodefulfill-
Inthissection,wescrutinizetheintriguingobser- ment during development. It is measured by
vations,challengingissues,andseveralexamples theproportionofthesoftwarethatisfreefrom
encounteredintheexperimentsofCross-TeamCol- "TODO"-likeplaceholders. Ahigherscoreim-
laboration. We also give detailed analysis across pliesagreaterlikelihoodofthesoftwarebeing
different hyperparameters and settings like team
3ASingle-TeamExecutioninCTCmainlycomprisesde-
sizes,temperatures,andmechanismconfigurations.
mandanalysis,coding,codecompletion,reviewing,andtest-
ingphases.Thecodingphaseinvolvesasingleroundofagents’
5.1 OverallPerformance cooperativecommunication,whilethecodecompletion,re-
viewing,andtestingphaseseachentailmultiplerounds.
ExperimentSetup Inourexperiments,weem- 4Significantly different from traditional function-level
ployGPT-3.5-Turboasthefoundationalmodel,uti- codegeneration,aprevalentobservationinagents’software
developmentisthefrequentuseofnumerous"placeholder"
lizing the Cross-Team Collaboration framework
fragments,suchasPython’spassstatement. Thispractice,
described in Section 4.2. We limit communica- whichindicatesasignificantlevelofincompletenesswithin
tionroundsbetweenagentstoamaximumof5per thesoftware,isaprobleminfrequentlynotedinpreviouswork.
Giventhesechallenges,completenessshouldberegardedasa
phaseineachSingle-TeamExecution. Bydefault,
primarymetricforevaluatingthequalityofsoftwaregenerated
thenumberofteamsengagedinthetasksissetto8 byagents.Method Paradigm Completeness Executability Consistency Quality
GPT-Engineer 0.502† 0.358† 0.768† 0.543†
MetaGPT 0.483† 0.415† 0.739† 0.545†
ChatDev 0.744† 0.813† 0.781† 0.779†
AgentVerse 0.650† 0.850† 0.776† 0.759†
GPTSwarm 0.800 0.550† 0.779† 0.710†
CTC 0.795 0.928 0.796 0.840
Table1: Overallperformancecomparisonofvariousrepresentativesoftwaredevelopmentmethods,encompassing
single-agent( ),Single-TeamExecution( ),Graph-likeExecution( )andCross-TeamCollaboration( )
framework. Theperformancemetricsaretheaverageacrossalltaskswithinthetestset. Thehighestscoresare
highlightedinbold,andthesecond-highestscoresarepresentedwithunderline. †indicatessignificantstatistical
differences(p<0.05)betweenbaselinesandours.
capable of automated completion without the compared to the Graph-like Execution paradigm
needforfurthermanualcoding. butsignificantlyhigherinExecutability. Thecon-
trastwithChatDev,anpowerfulmulti-agentframe-
• Executability(β ∈ [0,1])assessesthesoftware’s work,isespeciallynoteworthy,theCompleteness
abilitytoruncorrectlywithinagivencompila- scoreescalatesfrom0.744to0.795,andtheExe-
tionenvironment. Itismeasuredbythepercent- cutabilityscorewitnessesasubstantialleapfrom
ageofsoftwarethatcompileswithouterrorsand 0.813to0.928,andtheConsistencyscoreimproves
is ready to execute. A higher score indicates a from0.781to0.796,theoverallqualityofthegen-
higher likelihood of the software running suc- eratedsoftwaresignificantlyimprovesfrom0.779
cessfullyasintended. to0.840. Theseenhancementsunderscorethead-
vantagesoftheCTCframework,wherecollabora-
• Consistency(γ ∈ [0,1])evaluatesthealignment
tions among teams lead to mutual correction and
betweenthegeneratedsoftwareandtheoriginal
enlightenment, subsequent enhancement in soft-
natural language requirements. It is quantified
warequality,reducingthelikelihoodofexecutable
asthecosinedistancebetweentheembeddings
errors,andelevatingthedegreeofcodecompletion
ofthetextrequirementsandthesourcecode. A
andalignmentwithuserrequirements.
higherscoreindicatesagreaterdegreeofcom-
pliancewiththerequirements. 5.2 HyperparameterAnalysis
• Quality (α+β+γ ∈ [0,1]) is a comprehensive TheNumberofTeams Ourinvestigation,asde-
3
metric that integrates the dimensions of com- lineatedinFigure3,uncoversanintriguinginverse
pleteness, executability, and consistency. It relationship between the executability and com-
serves as a holistic indicator of the software’s pletenessofthesoftwaregeneratedbyourframe-
overallquality. Ahigherscoreindicatessuperior work. Thisfiguresuccinctlycapturestheessence
generationquality,suggestingthatthesoftware ofthetrade-offthatisinherentinthesystem’sper-
islesslikelytorequireadditionalmanualinter- formance. Initially, we observe an ascent in the
ventions. alignmentofgeneratedcodewithspecifiedrequire-
ments,plateauingaroundthe4-teamCTCconfig-
Table 1 illustrates a detailed comparative anal- uration,withminorfluctuationsasthenumberof
ysisofourCross-TeamCollaborationframework teamsincreases. Thezenithofsoftwarequalityis
(CTC)andallbaselines. TheSingle-TeamExecu- achievedwiththe4-teamCTCconfiguration. This
tion paradigm outperforms the GPT-Engineer in configurationstrikesadelicatebalance,optimizing
termsofoverallperformance,highlightingtheben- thesystemtoproducesoftwarethatisnotonlyexe-
efitsofamulti-agentsystemindecomposingcom- cutablebutalsofunctionallyrich. However,upon
plextask-solvingintomanageablesubtasks,asop- furtherincreasingthenumberofteams,weobserve
posedtoasingle-stepsolutionapproach. Acrossall adeclineinthequalityofthegeneratedsoftware.
metrics,CTCdemonstratesaremarkableimprove- Despite this decrement, it is noteworthy that the
ment over the Single-Team Execution, showing software’s quality remains superior to that of the
onlyaslightlylowerscoreinCompletenesswhen baselineSingle-TeamExecutionconfiguration. WeFigure 3: Visualization of Result Trends concerning Team Size Variations in our Framework without Greedy
Pruning. Anupwardtrendinconsistencyisobserved,alongwithaninverserelationshipbetweenexecutabilityand
completeness. Thehighestqualityofcontentisachievedwithateamsizeoffour.
hypothesizethatthediminishingreturnsandpoten- GreedyPruning Toenhancethescalabilityand
tial decline in performance are due to the agents’ performance of the Cross-Team Collaboration
inabilitytoprocessanexcessivevolumeofcontent framework, the Greedy Pruning mechanism de-
simultaneously. To further enhance the number tailed in Section 4.2.1 is essential. The Greedy
ofteamswithoutcompromisingquality,theimple- Pruning mechanism is applied to reduce commu-
mentationofagreedypruningmechanismbecomes nicationcostsandimprovecontentqualityforag-
indispensable. gregations between teams. As indicated in Table
2, the application of the Greedy Pruning mech-
anism within the 8-team CTC context results in
anoptimizationofallmetricsdimensions,achiev-
Temperature A central focus of our investiga-
ingthehighestvaluesacrossallCTCexperimen-
tionistheefficacyofvariedtemperatureconfigura-
tal outcomes. Thus its’ quality scores exhibit a
tionsforteamstogeneratecontentwithdifferent
remarkable improvement, rising from a previous
inclinationsincreativityandrequirementcompli-
peak of 0.789 in the 4-team CTC to a more re-
ance. Table 2 demonstrates that an appropriate
fined 0.840. These results show that the mecha-
level of diversity significantly enhances software
nism can handle the challenges of larger teams.
quality. Whenthetemperatureforeachteamisset
It selects high-quality content to improve overall
to the same level, the performance improvement
performancebyoptimizingthegenerationprocess.
broughtbyCTCislimited. Thisisbecausethereis
This makes it more useful and effective for soft-
nodifferentiationamongtheteams;theyeitherall
waretasks. ItsupportstheideaofusingtheGreedy
leantowardsgeneratingcreativecontent(hightem-
PruningmechanisminCross-TeamCollaboration
perature)orstrictlyadheringtorules(lowtempera-
tosupportscalableapplications.
ture). Inthisscenario,thenewinformationgained
throughcross-teamcollaborationisminimal. Con-
5.3 AblationStudy
versely,wheneachteamisassignedadifferenttem-
perature(suchassimplyemployingatemperature In our ablation study illustrated in Table 3, we
configurationof(0.2,0.2,0.4,0.4),whichbalances foundthatremovingHierarchicalPartitioningfrom
teamdiversitywithafocusonrules),CTCresults 4-team and 8-team CTC configurations reduced
insignificantperformanceenhancement. qualityscoresfrom0.789to0.756andfrom0.775Mechanism Completeness Executability Consistency Quality and Single-Team Execution. This improvement
4-teamCTC 0.660 0.915† 0.793 0.789† underscores the versatility and robustness of our
(0.20.40.60.8) 0.575 0.875† 0.790 0.747†
(0.10.10.10.1) 0.700 0.794† 0.791 0.762† approachacrossdifferentdomains.
(0.40.40.40.4) 0.583 0.773† 0.792 0.716†
(0.20.20.40.4) 0.670 0.925 0.790 0.795 Metrics for Story Evaluation Inspired by (Li
8-teamCTC 0.706† 0.828† 0.792† 0.775† etal.,2018),weevaluatestoryqualityacrossfour
+Prune 0.795 0.928 0.796 0.840
criticaldimensionsbyusinganLLMtorateeach
Table 2: Investigation of mechanisms in 4-team and story,whichisproventobeeffective(Chhunetal.,
8-teamCTC.Thetemperaturesforeachteamareindi- 2024).
catedas(t ,t ,t ,t ). The’+’symbolrepresentsthe
1 2 3 4
addingoperation. Thehighestscoresarehighlightedin • Grammar and Fluency (ω ∈ [0,4]): Assesses
bold,andthesecond-highestscoresarepresentedwith
naturallanguage use, grammaticalcorrectness,
underline. †indicatessignificantstatisticaldifferences
andfluencyforacoherentanderror-freenarra-
(p<0.05)betweenthescenarioswithandwithoutthe
tiveflow.
additionofthemechanism.
Mechanism Completeness Executability Consistency Quality • Context Relevance (ψ ∈ [0,4]): Analyzes the
4-teamCTC 0.660 0.915 0.793 0.789 contextual appropriateness and interrelation of
-HierarchyPartitioning 0.683 0.800 0.786 0.756
-FeatureExtraction 0.680 0.783 0.739 0.735 names,pronouns,andphrasestoensurenarrative
8-teamCTC 0.706 0.828 0.791 0.775 integrityanddepthinplots.
-HierarchyPartitioning 0.728 0.804 0.787 0.773
-FeatureExtraction 0.658 0.783 0.790 0.744
• Logic Consistency (ξ ∈ [0,4]): Examines the
Table3: Ablationstudyon4TeamsCTCand8Teams logicalprogressionofeventsandcharacterrela-
CTC. The ’-’ denotes the removing operation. The
tionshipsfornarrativecoherenceandplausibil-
highestscoresarehighlightedinbold,andthesecond-
ity.
highestscoresarepresentedwithunderlineineachsub-
table. • Quality(ω+ψ+ξ ∈ [0,4]): Aggregatesindividual
3
dimension scores to provide a comprehensive
to0.773. Withoutthispartitioning,theagentstrug-
measureofnarrativequality,reflectingthesyn-
gledtohandlediverseteamcontentinoneaggre-
thesisoflanguage,context,andlogic.
gation, making it harder to extract features and
lowering content quality. Besides, we conducted
TeamNumberAnalysis Inourexperimentalin-
ablation experiments on Content Feature Extrac-
vestigationusingtheCTCframeworkforstorygen-
tion,whereagentsdonothavearoleassignment,
eration,asdepictedinTable4,weobservedaposi-
and there is no feature extraction performed by
tivecorrelationbetweenthenumberofparticipat-
theassessmentagentM. Theperformancefurther
ingteamsandtheresultantqualityofthegenerated
droppedthequalityfrom0.789to0.735andfrom
stories. Notably,thequalitymetricsdemonstrateda
0.775to0.744. ThisablationmakesCTCperform
substantialimprovementoveroutputsfromindivid-
poorlyandsometimesevenfailtocompletetasks.
ualagentsandSingle-TeamExecutionsetups,with
Thelackofstructuredguidanceandgroupingsled
scoresrisingfrom2.193and2.358to3.083,respec-
to disorganized content and poor task resolution,
tively. However,asthenumberofteamsincreased,
with rewritten content quality dropping. In some
diminishing returns began to set in. To counter-
cases,theagentwouldrespond: "Icannotprocess
act this trend, we introduced the Greedy Pruning
this task." These results show the importance of
mechanism. Thisinterventionledtoanotableen-
our framework’s mechanisms in managing com-
hancement in story quality when the number of
plexcontentandensuringhigh-qualityoutputsin
teamswaseight,withthequalityscoreimproving
multi-teamscenarios.
from3.083to3.642. Thesefindingsunderscorethe
5.4 GeneralizabilityAnalysisofStory efficacyoftheCTCframeworkinstorygeneration,
Generation suggesting that it is not only beneficial for soft-
waredevelopmenttasksbutalsogeneralizeswell
Todemonstratethegeneralizationcapabilityofour
tocreativedomainssuchasnarrativegeneration.
framework,wehaveconductedexperimentsinthe
domainofstorygeneration. Ourfindingsindicate AblationStudy Similartotheablationstudyin
thatourframeworksignificantlyenhancesthequal- software generation, we conduct experiments re-
ityofstoriesgeneratedbybothindividualagents gardingtheimpactofHierarchicalPartitioningandMechanism Paradigm GrammarandFluency ContextRelevance LogicConsistency Quality
Single-Agent 2.150† 2.005† 2.425† 2.193†
Single-TeamExecution 2.250† 2.325† 2.500† 2.358†
2-teamCTC 2.725 2.800 3.000 2.842
3-teamCTC 2.967 2.767 2.967 2.900
4-teamCTC 2.967 2.850 2.908 2.908
5-teamCTC 2.980 2.880 2.960 2.940
6-teamCTC 2.983 2.900 2.983 2.956
7-teamCTC 3.000 3.171 3.014 3.062
8-teamCTC 3.000† 3.250† 3.000† 3.083†
8-teamCTC+Prune 3.625 3.750 3.250 3.642
Table4: ResultTrendsconcerningTeamSizeVariationsinourFrameworkinStoryGeneration,encompassing
single-agent( ),Single-TeamExecution( )andCross-TeamCollaboration( )frameworkwithandwithout
pruningmechanism( ). Theperformancemetricsaretheaverageacrossalltaskswithinthetestset. Thehighest
scoresarehighlightedinbold,andthesecond-highestscoresarepresentedwithunderline. †indicatessignificant
statisticaldifferences(p<0.05)betweenbestresultsandbaselines
Grammar Context Logic and-error process, the resulting program had sig-
Mechanism Quality
andFluency Relevance Consistency
nificantlimitations. Specifically,thesquareblock
4-teamCTC 2.967 2.850 2.908 2.908
-HierarchyPartitioning 1,906 2.219 2.688 2.271 remainedstationaryinitsinitialpositionandwas
-FeatureExtraction 2.096 2.183 2.621 2.300
unabletoperformanyoperations,highlightingthe
8-teamCTC 3.000 3.250 3.000 3.083
-HierarchyPartitioning 2.255 2.354 2.758 2.456 challengesoftheChatDevparadigmingenerating
-FeatureExtraction 2.115 2.256 2.653 2.341 ausableprogram.
Table5: Ablationstudyon4TeamsCTCand8Teams
CTC.The’+’symbolrepresentstheaddingoperation 6 Limitations
and - denotes the removing operation. The highest
scoresarehighlightedinbold,andthesecond-highest Ourstudyhasexploredthecooperativebehaviors
scoresarepresentedwithunderlineineachsub-table. of multiple autonomous agent teams in software
development and story generation, yet both re-
Content Feature Extraction on story generation. searchersandpractitionersmustbemindfulofcer-
Our findings, as detailed in Table 5, reveal sig- tainlimitationsandriskswhenusingtheapproach
nificantdecrementsinstoryquality. Theabsence todevelopnewtechniquesorapplications.
ofthesemechanismsledtoanotablestrugglefor Firstly,theframework’sdependenceonagreedy
agentstoassimilatediverseteamstorieswithina pruningmechanismcouldinadvertentlyleadtothe
singleaggregation. Withoutarole-assignedagent discarding of potentially valuable insights. This
forfeatureextraction,itweakenedtheoverallop- isduetotheimperfectionsinherentinevaluation
timization of story quality. These results demon- metrics. While the mechanism aims to eliminate
stratetheindispensablenatureandgeneralization low-quality content, it may also prematurely ex-
capabilityofthesemechanismsacrossdifferentdo- cludecreativesolutionsthatcouldevolveintohigh-
mains. qualityoutcomeswithfurtherdevelopment. There
isatrade-offbetweentheefficiencyofthepruning
5.5 CaseStudy
processandthepotentiallossofinnovativeideas,
Figures 4 and 5 present the graphical user inter- which suggests the need for more effective auto-
faces (GUIs) of a Tetris game generated by CTC matedevaluationmethodsinthefuture,notlimited
and ChatDev. The Tetris game created using the tothedomainsofsoftwaredevelopmentandstory
CTCframeworksuccessfullygeneratedaplayable generation.
gameonitsfirstattempt. Inthisversion,theblocks Secondly, when evaluating the capabilities of
canbemoved,rotated,andaccelerated. Blocksthat autonomousagentsfromasoftwaredevelopment
reachthebottomofthegamematrixchangefrom standpoint, it is prudent to avoid overestimating
redtoblueandareeliminatedifthebottomrowis their software production abilities. Our observa-
filled,indicatingasuccessfulgamemechanic. In tions indicate that while Cross-Team Collabora-
contrast,thegamegeneratedbyChatDevstruggled tion (CTC) significantly improves the quality of
toproduceafunctionalprogram. Evenafteratrial- both software development and story generationFigure4: Thescreenshotofthesoftwaregeneratedby Figure5: Thescreenshotofthesoftwaregeneratedby
ChatDev. ourmethod.
tasks, autonomous agents often default to imple- of detailed software requirements. This includes
mentingthemoststraightforwardlogicduringthe specifyingwhetherauserinterfaceisessential,if
software creation process. In the absence of ex- thereisaneedfortheautomaticgenerationofgame
plicit and clear requirements, agents struggle to characterassets,orifanexternaldatabaseisneces-
autonomouslydiscerntheunderlyingconceptsand sary. Giventhecurrentcapabilitiesofautonomous
nuances of the task requirements. For example, agents, fulfilling highly detailed requirements is
when developing a Flappy Bird game, if the task notalwaysassured,underscoringtheimportanceof
guidelinesarenotmeticulouslydefined,agentsmay strikingabalancebetweenspecificityandpractical
default to representing the bird and tubes with a feasibilityintherequirements. Inthefieldofstory
rudimentary rectangular shape. Similarly, in the generation,duetoitsliterarynature,complextask
construction of an information management sys- relationships,scenedescriptions,andbackground
tem,agentsmayopttohard-codetheinformation settings are often required. However, providing
tobequeriedinabasickey-valueformatdirectly agentswithoverlycomplexrequirementscanlead
into the code, rather than employing a more so- to suboptimal narrative outcomes, as agents may
phisticatedandflexibleexternaldatabasesolution. find it challenging to effectively manage and pri-
Therefore, we advocate for the precise definition oritize the various narrative elements during thewritingprocess. Inconclusion,theresearchonau- troduced effectively addresses this issue. 3) Our
tonomousagentsforsoftwareandstorygeneration CTCframeworkhasthepotentialfordevelopment
isstillinitsearlystages, andtheassociatedtech- inbroadercontentgenerationdomains,including
nologiesarenotyetreadilyadaptabletocomplex naturallanguagegenerationandprogramminglan-
real-worldscenarios. Asaresult,thecurrentappli- guagegeneration.
cationofthesetechnologiesismoresuitedtothe Future research will delve into exploring a
developmentofprototypesystemsratherthanfully- broader range of configurations, including both
fledged,real-worldsoftwareandnarrativesystems. greedyandnon-greedymethodsforpartition. Ad-
Thirdly,thecomplexityofcoordinatingmultiple ditionally,wewillaimtorefineandoptimizeour
teams and managing the communication load in- evaluation metrics to ensure more precise assess-
creaseswiththenumberofteamsinvolved. Asthe mentsofautomaticsoftwaredevelopment. Interms
frameworkscales,thecomputationalandlogistical of inter-group communication, we plan to intro-
demandsrise,whichmayimpactthepracticalityof duce and evaluate a variety of communication
applyingourframeworktoverylarge-scaleprob- paradigms, such as Debate, to foster richer and
lemsorinresource-constrainedenvironments. Fu- moredynamicinteractions. Furthermore,weaspire
tureworkisneededtooptimizethescalabilityof toapplyourapproachtoenhanceawiderarrayof
theframeworkwhilemaintainingitsefficacy. contentgenerationtasksacrossvariousreal-world
applications,therebydemonstratingtheversatility
7 Conclusion andefficacyofourmethodsinpracticalsettings.
Recognizing the inherent limitation of a single-
References
team in obtaining and leveraging insights from
other teams when completing complex tasks like JoshAchiam,StevenAdler,SandhiniAgarwal,Lama
softwaredevelopment,weintroduceanovelmulti- Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
DiogoAlmeida,JankoAltenschmidt,SamAltman,
team framework termed Cross-Team Collabora-
ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
tion. This framework carefully orchestrates mul-
arXivpreprintarXiv:2303.08774.
tiple teams with the same software requirement
that allows different teams to jointly propose di- MansiAgnihotriandAnuradhaChug.2020. Asystem-
aticliteraturesurveyofsoftwaremetrics,codesmells
versetask-orienteddecisions,communicateatkey
andrefactoringtechniques. JournalofInformation
phases, and collaboratively aggregate into a final
ProcessingSystems,16(4):915–934.
superior software. Our quantitative analysis has
Mohammad Alahmadi, Abdulkarim Khormi, Biswas
effectivelydemonstratedsignificantimprovements
Parajuli,JonathanHassel,SoniaHaiduc,andPiyush
inthesoftwarequality. Weanticipatethatourin-
Kumar. 2020. Code localization in program-
sightswillinitiateaparadigmshiftinshapingthe mingscreencasts. EmpiricalSoftwareEngineering,
designofLLMagentsintomulti-team,propelling 25:1536–1572.
agents towards achieving greater software gener-
Razvan Azamfirei, Sapna R Kudchadkar, and James
ation quality, and extend it in a broader range of
Fackler.2023. Largelanguagemodelsandtheperils
complex tasks, including both programming lan- oftheirhallucinations. CriticalCare,27(1):120.
guagegenerationandnaturallanguagegeneration.
RajivDBanker,GordonBDavis,andSandraASlaugh-
Here, we list several main findings as follows.
ter.1998. Softwaredevelopmentpractices,software
1) Cross-team communication for insights inter- complexity,andsoftwaremaintenanceperformance:
changesignificantlyimprovessoftwarequality,in- Afieldstudy. Managementscience,44(4):433–450.
dicatingtheeffectivenessofmulti-teamtaskhan-
Victor R Basili. 1989. Software development: A
dling. It mainly contributes to an appropriate in- paradigmforthefuture. In[1989]Proceedingsofthe
crease in the diversity and effective grouping of ThirteenthAnnualInternationalComputerSoftware
&ApplicationsConference,pages471–485.IEEE.
content. 2)Asthenumberofparticipatingteams
increases, the quality of software is subject to di- MaciejBesta,NilsBlach,AlesKubicek,RobertGersten-
minishing returns and may even deteriorate. In berger,MichalPodstawski,LukasGianinazzi,Joanna
our study, this is primarily attributed to the in- Gajda,TomaszLehmann,HubertNiewiadomski,Pi-
otrNyczyk,etal.2024. Graphofthoughts: Solving
creased probability of low-quality software with
elaborateproblemswithlargelanguagemodels. In
moreteams,whichadverselyaffectstheaggregated
Proceedings of the AAAI Conference on Artificial
software quality. The pruning mechanism we in- Intelligence,volume38,pages17682–17690.Thorsten Brants, Ashok Popat, Peng Xu, Franz Josef RoiCohen,MayHamri,MorGeva,andAmirGlober-
Och,andJeffreyDean.2007. Largelanguagemodels son. 2023. Lm vs lm: Detecting factual errors via
inmachinetranslation. InProceedingsofthe2007 crossexamination. arXivpreprintarXiv:2305.13281.
JointConferenceonEmpiricalMethodsinNatural
Language Processing and Computational Natural Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu,
Language Learning (EMNLP-CoNLL), pages858– Yiwu Qiu, and Chunlei Chai. 2023. Designgpt:
867. Multi-agentcollaborationindesign. arXivpreprint
arXiv:2311.11591.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023.
Neelakantan,PranavShyam,GirishSastry,Amanda
Self-collaborationcodegenerationviachatgpt. arXiv
Askell,etal.2020. Languagemodelsarefew-shot
preprintarXiv:2304.07590.
learners. Advancesinneuralinformationprocessing
systems,33:1877–1901.
YilunDu,ShuangLi,AntonioTorralba,JoshuaBTenen-
Sébastien Bubeck, Varun Chandrasekaran, Ronen El- baum,andIgorMordatch.2023. Improvingfactual-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar, ityandreasoninginlanguagemodelsthroughmultia-
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund- gentdebate. arXivpreprintarXiv:2305.14325.
berg,etal.2023. Sparksofartificialgeneralintelli-
gence: Earlyexperimentswithgpt-4. arXivpreprint Jinhao Duan, Renming Zhang, James Diffenderfer,
arXiv:2303.12712. BhavyaKailkhura,LichaoSun,EliasStengel-Eskin,
MohitBansal,TianlongChen,andKaidiXu.2024.
TianleCai, XuezhiWang, TengyuMa, XinyunChen, Gtbench: Uncoveringthestrategicreasoninglimita-
andDennyZhou.2023. Largelanguagemodelsas tionsofllmsviagame-theoreticevaluations. arXiv
toolmakers. arXivpreprintarXiv:2305.17126. preprintarXiv:2402.12348.
Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,
MichaelDErnst.2017. Naturallanguageisaprogram-
Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan
minglanguage: Applyingnaturallanguageprocess-
Liu.2023. Chateval: Towardsbetterllm-basedeval-
ingtosoftwaredevelopment. In2ndSummitonAd-
uators through multi-agent debate. arXiv preprint
vancesinProgrammingLanguages(SNAPL2017).
arXiv:2308.07201.
Schloss-Dagstuhl-LeibnizZentrumfürInformatik.
DakeChen,HanbinWang,YunhaoHuo,YuzhaoLi,and
HaoyangZhang.2023a. Gamegpt: Multi-agentcol- Saad Ezzini, Sallam Abualhaija, Chetan Arora, and
laborativeframeworkforgamedevelopment. arXiv Mehrdad Sabetzadeh. 2022. Automated handling
preprintarXiv:2310.08067. of anaphoric ambiguity in requirements: a multi-
solutionstudy. InProceedingsofthe44thInterna-
JiaaoChen,JianshuChen,andZhouYu.2019. Incorpo-
tional Conference on Software Engineering, pages
ratingstructuredcommonsenseknowledgeinstory
187–199.
completion. InProceedingsoftheAAAIConference
on Artificial Intelligence, volume 33, pages 6244–
ErnstFehrandSimonGächter.2000. Cooperationand
6251.
punishmentinpublicgoodsexperiments. American
LingjiaoChen,JaredQuincyDavis,BorisHanin,Peter
EconomicReview,90(4):980–994.
Bailis, Ion Stoica, Matei Zaharia, and James Zou.
2024. Are more llm calls all you need? towards RanGong,QiuyuanHuang,XiaojianMa,HoiVo,Zane
scalinglawsofcompoundinferencesystems. arXiv Durante, Yusuke Noda, Zilong Zheng, Song-Chun
preprintarXiv:2403.02419. Zhu, Demetri Terzopoulos, Li Fei-Fei, et al. 2023.
Mindagent: Emergent gaming interaction. arXiv
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming preprintarXiv:2309.09971.
Yuan,HenriquePondedeOliveiraPinto,JaredKa-
plan, HarriEdwards, YuriBurda, NicholasJoseph, GarrettHardin.1968. Thetragedyofthecommons: the
Greg Brockman, et al. 2021. Evaluating large populationproblemhasnotechnicalsolution;itre-
language models trained on code. arXiv preprint quiresafundamentalextensioninmorality. science,
arXiv:2107.03374. 162(3859):1243–1248.
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang,
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng
Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia
Cheng,JinlinWang,CeyaoZhang,ZiliWang,Steven
Qin, Yaxi Lu, Ruobing Xie, et al. 2023b. Agent-
KaShingYau,ZijuanLin,LiyangZhou,etal.2023.
verse: Facilitatingmulti-agentcollaborationandex-
Metagpt:Metaprogrammingformulti-agentcollabo-
ploringemergentbehaviorsinagents. arXivpreprint
rativeframework. arXivpreprintarXiv:2308.00352.
arXiv:2308.10848.
Cyril Chhun, Fabian M Suchanek, and Chloé Clavel. ShengchaoHu,LiShen,YaZhang,andDachengTao.
2024. Dolanguagemodelsenjoytheirownstories? 2023. Learning multi-agent communication from
promptinglargelanguagemodelsforautomaticstory graphmodelingperspective. InTheTwelfthInterna-
evaluation. arXivpreprintarXiv:2405.13769. tionalConferenceonLearningRepresentations.Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue,
Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Shelby Heinecke, Rithesh Murthy, Yihao Feng,
YongfengZhang.2023. Warandpeace(waragent): ZeyuanChen,JuanCarlosNiebles,DevanshArpit,
Largelanguagemodel-basedmulti-agentsimulation etal.2023. Bolaa: Benchmarkingandorchestrating
ofworldwars. arXivpreprintarXiv:2311.17227. llm-augmentedautonomousagents. arXivpreprint
arXiv:2308.05960.
QianHuang,JianVora,PercyLiang,andJureLeskovec.
2023. Benchmarking large language models as ai Cuauhtémoc López-Martín and Alain Abran. 2015.
researchagents. arXivpreprintarXiv:2310.03302. Neuralnetworksforpredictingthedurationofnew
softwareprojects. JournalofSystemsandSoftware,
KatjaHutter,JuliaHautz,JohannFüller,JuliaMueller,
101:127–135.
and Kurt Matzler. 2011. Communitition: The
tension between competition and collaboration in
Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,
community-based design contests. Creativity and
Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark,
innovationmanagement,20(1):3–21.
andAshwinKalyan.2022. Dynamicpromptlearning
viapolicygradientforsemi-structuredmathematical
DongfuJiang,XiangRen,andBillYuchenLin.2023.
reasoning. arXivpreprintarXiv:2209.14610.
Llm-blender: Ensembling large language models
withpairwiserankingandgenerativefusion. arXiv
KaixinMa, HongmingZhang, HongweiWang, Xiao-
preprintarXiv:2306.02561.
manPan,andDongYu.2023. Laser: Llmagentwith
state-space exploration for web navigation. arXiv
JeanKaddour,JoshuaHarris,MaximilianMozes,Her-
preprintarXiv:2309.08172.
bieBradley,RobertaRaileanu,andRobertMcHardy.
2023. Challengesandapplicationsoflargelanguage
models. arXivpreprintarXiv:2307.10169. Ben Mann, N Ryder, M Subbiah, J Kaplan, P Dhari-
wal, ANeelakantan, PShyam, GSastry, AAskell,
JaredKaplan,SamMcCandlish,TomHenighan,TomB SAgarwal, etal.2020. Languagemodelsarefew-
Brown,BenjaminChess,RewonChild,ScottGray, shotlearners. arXivpreprintarXiv:2005.14165.
AlecRadford,JeffreyWu,andDarioAmodei.2020.
Scaling laws for neural language models. arXiv NadiaNahar,ShuruiZhou,GraceLewis,andChristian
preprintarXiv:2001.08361. Kästner.2022. Collaborationchallengesinbuilding
ml-enabled systems: Communication, documenta-
Guohao Li, Hasan Abed Al Kader Hammoud, Hani tion,engineering,andprocess. InProceedingsofthe
Itani, Dmitrii Khizbullin, and Bernard Ghanem. 44thinternationalconferenceonsoftwareengineer-
2023a. Camel: Communicative agents for" mind" ing,pages413–425.
exploration of large scale language model society.
arXivpreprintarXiv:2303.17760. ErikNijkamp,BoPang,HiroakiHayashi,LifuTu,Huan
Wang,YingboZhou,SilvioSavarese,andCaiming
Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, and Xiong. 2022. Codegen: An open large language
DehengYe.2024. Moreagentsisallyouneed. arXiv model for code with multi-turn program synthesis.
preprintarXiv:2402.05120. arXivpreprintarXiv:2203.13474.
YuanLi,YixuanZhang,andLichaoSun.2023b. Metaa-
Anton Osika. 2023. Gpt-engineer. In
gents: Simulating interactions of human behav-
https://github.com/AntonOsika/gpt-engineer.
iors for llm-based task-oriented coordination via
collaborative generative agents. arXiv preprint
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
arXiv:2310.06500.
CarrollWainwright,PamelaMishkin,ChongZhang,
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
ZhongyangLi,XiaoDing,andTingLiu.2018. Gener-
2022. Training languagemodelsto followinstruc-
atingreasonableanddiversifiedstoryendingusing
tionswithhumanfeedback. Advancesinneuralin-
sequencetosequencemodelwithadversarialtraining.
formationprocessingsystems,35:27730–27744.
InProceedingsofthe27thInternationalConference
onComputationalLinguistics,pages1033–1043.
JoonSungPark,JosephO’Brien,CarrieJunCai,Mered-
Weixin Liang, Yuhui Zhang, Hancheng Cao, Binglu ithRingelMorris,PercyLiang,andMichaelSBern-
Wang,DaisyDing,XinyuYang,KailasVodrahalli, stein.2023. Generativeagents: Interactivesimulacra
SiyuHe,DanielSmith,YianYin,etal.2023. Can ofhumanbehavior. InProceedingsofthe36thAn-
large language models provide useful feedback on nual ACM Symposium on User Interface Software
research papers? a large-scale empirical analysis. andTechnology,pages1–22.
arXivpreprintarXiv:2310.01783.
GiorgioPiatti,ZhijingJin,MaxKleiman-Weiner,Bern-
Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu. hard Schölkopf, Mrinmaya Sachan, and Rada Mi-
2023. Avalonbench: Evaluating llms playing the halcea.2024. Cooperateorcollapse: Emergenceof
gameofavalon. InNeurIPS2023FoundationModels sustainability behaviors in a society of llm agents.
forDecisionMakingWorkshop. arXivpreprintarXiv:2404.16698.FlorianPudlitz,FlorianBrokhausen,andAndreasVogel- MurrayShanahan,KyleMcDonell,andLariaReynolds.
sang.2019. Extractionofsystemstatesfromnatural 2023. Roleplaywithlargelanguagemodels. Nature,
languagerequirements. In2019IEEE27thInterna- 623(7987):493–498.
tionalRequirementsEngineeringConference(RE),
pages211–222.IEEE. TheodoreRSumers,ShunyuYao,KarthikNarasimhan,
and Thomas L Griffiths. 2023. Cognitive ar-
ChenQian,YufanDang,JiahaoLi,WeiLiu,ZihaoXie, chitectures for language agents. arXiv preprint
Yifei Wang, Weize Chen, Xin Cong, Xiaoyin Che, arXiv:2309.02427.
ZhiyuanLiu,andMaosongSun.2024a. Experiential
co-learning of software-developing agents. In The HugoTouvron,ThibautLavril,GautierIzacard,Xavier
62ndAnnualMeetingoftheAssociationforCompu- Martinet,Marie-AnneLachaux,TimothéeLacroix,
tationalLinguistics. Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et al. 2023. Llama: Open and effi-
Chen Qian, Jiahao Li, Yufan Dang, Wei Liu, YiFei
cient foundation language models. arXiv preprint
Wang,ZihaoXie,WeizeChen,ChengYang,Yingli
arXiv:2302.13971.
Zhang, Zhiyuan Liu, et al. 2024b. Iterative ex-
periencerefinementofsoftware-developingagents. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
arXivpreprintarXiv:2405.04219. Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser,andIlliaPolosukhin.2017. Attentionisall
ChenQian,WeiLiu,HongzhangLiu,NuoChen,Yufan
youneed. Advancesinneuralinformationprocessing
Dang,JiahaoLi,ChengYang,WeizeChen,Yusheng
systems,30.
Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu,
andMaosongSun.2024c. Communicativeagentsfor
Chengcheng Wan, Shicheng Liu, Sophie Xie, Yifan
softwaredevelopment. InThe62ndAnnualMeeting
Liu,HenryHoffmann,MichaelMaire,andShanLu.
oftheAssociationforComputationalLinguistics.
2022. Automatedtestingofsoftwarethatusesma-
chinelearningapis. InProceedingsofthe44thInter-
YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,Lan
nationalConferenceonSoftwareEngineering,pages
Yan,YaxiLu,YankaiLin,XinCong,XiangruTang,
212–224.
BillQian, etal.2023a. Toolllm: Facilitatinglarge
languagemodelstomaster16000+real-worldapis.
Yao Wan, Zhou Zhao, Min Yang, Guandong Xu,
arXivpreprintarXiv:2307.16789.
HaochaoYing,JianWu,andPhilipSYu.2018. Im-
Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, proving automatic source code summarization via
Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, deepreinforcementlearning. InProceedingsofthe
Donald Metzler, Xuanhui Wang, et al. 2023b. 33rd ACM/IEEE international conference on auto-
Large language models are effective text rankers matedsoftwareengineering,pages397–407.
with pairwise ranking prompting. arXiv preprint
arXiv:2306.17563. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-
dlekar,ChaoweiXiao,YukeZhu,LinxiFan,andAn-
AlecRadford,JeffreyWu,RewonChild,DavidLuan, imaAnandkumar.2023a. Voyager: Anopen-ended
DarioAmodei,IlyaSutskever,etal.2019. Language embodiedagentwithlargelanguagemodels. arXiv
modelsareunsupervisedmultitasklearners. OpenAI preprintarXiv:2305.16291.
blog,1(8):9.
LeiWang,JingsenZhang,XuChen,YankaiLin,Rui-
David G Rand and Martin A Nowak. 2013. Human huaSong,WayneXinZhao,andJi-RongWen.2023b.
cooperation. Trendsincognitivesciences,17(8):413– Recagent: Anovelsimulationparadigmforrecom-
425. mendersystems. arXivpreprintarXiv:2306.02552.
Toran Bruce Richards. 2023. AutoGPT. In
QinengWang,ZihaoWang,YingSu,HanghangTong,
https://github.com/Significant-Gravitas/AutoGPT.
andYangqiuSong.2024. Rethinkingtheboundsof
llmreasoning: Aremulti-agentdiscussionsthekey?
JingqingRuan,YihongChen,BinZhang,ZhiweiXu,
arXivpreprintarXiv:2402.18272.
Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu
Mao,XingyuZeng,andRuiZhao.2023. Tptu: Task
Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan
planning and tool usage of large language model-
Qi, Shuo Chen, Qisen Yang, Andrew Zhao,
basedaiagents. arXivpreprintarXiv:2308.03427.
ChaofeiWang,ShijiSong,andGaoHuang.2023c.
SteveSawyerandPatriciaJ.Guinan.1998. Softwarede- Avalon’s game of thoughts: Battle against decep-
velopment:Processesandperformance. IBMsystems tionthroughrecursivecontemplation. arXivpreprint
journal,37(4):552–569. arXiv:2310.01320.
TimoSchick,JaneDwivedi-Yu,RobertoDessì,Roberta SongWang,NishthaShrestha,AbarnaKucheriSubbu-
Raileanu,MariaLomeli,EricHambro,LukeZettle- raman, Junjie Wang, Moshi Wei, and Nachiappan
moyer,NicolaCancedda,andThomasScialom.2024. Nagappan.2021. Automaticunittestgenerationfor
Toolformer: Languagemodelscanteachthemselves machinelearninglibraries: Howfararewe? In2021
to use tools. Advances in Neural Information Pro- IEEE/ACM43rdInternationalConferenceonSoft-
cessingSystems,36. wareEngineering(ICSE),pages1548–1560.IEEE.Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, AnZhang,LehengSheng,YuxinChen,HaoLi,Yang
Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P Deng,XiangWang,andTat-SengChua.2023. On
Xing, and Zhiting Hu. 2023d. Promptagent: generativeagentsinrecommendation. arXivpreprint
Strategic planning with language models enables arXiv:2310.10108.
expert-level prompt optimization. arXiv preprint
arXiv:2310.16427. Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu
Lin, Yong-Jin Liu, and Gao Huang. 2024. Expel:
Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Llmagentsareexperientiallearners. InProceedings
Tao Ge, Furu Wei, and Heng Ji. 2023e. Unleash- of the AAAI Conference on Artificial Intelligence,
ing cognitive synergy in large language models: volume38,pages19632–19642.
A task-solving agent through multi-persona self-
collaboration. arXiv preprint arXiv:2307.05300, Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou,
1(2):3. RobertLo,AbishekSridhar,XianyiCheng,Yonatan
Bisk,DanielFried,UriAlon,etal.2023a. Webarena:
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Arealisticwebenvironmentforbuildingautonomous
Barret Zoph, Sebastian Borgeaud, Dani Yogatama, agents. arXivpreprintarXiv:2307.13854.
MaartenBosma,DennyZhou,DonaldMetzler,etal.
Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li,
2022a. Emergentabilitiesoflargelanguagemodels.
JialongWu,TiannanWang,ShiQiu,JintianZhang,
arXivpreprintarXiv:2206.07682.
Jing Chen, Ruipu Wu, Shuai Wang, et al. 2023b.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten Agents: Anopen-sourceframeworkforautonomous
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou, languageagents. arXivpreprintarXiv:2309.07870.
etal.2022b. Chain-of-thoughtpromptingelicitsrea-
XizhouZhu,YuntaoChen,HaoTian,ChenxinTao,Wei-
soninginlargelanguagemodels. Advancesinneural
jieSu,ChenyuYang,GaoHuang,BinLi,LeweiLu,
informationprocessingsystems,35:24824–24837.
XiaogangWang,etal.2023. Ghostintheminecraft:
Generallycapableagentsforopen-worldenviroments
LilianWeng.2023. Llm-poweredautonomousagents.
vialargelanguagemodelswithtext-basedknowledge
AnitaWilliamsWoolley,ChristopherFChabris,Alex andmemory. arXivpreprintarXiv:2305.17144.
Pentland, Nada Hashmi, and Thomas W Malone.
Mingchen Zhuge, Wenyi Wang, Louis Kirsch,
2010. Evidence for a collective intelligence fac-
Francesco Faccio, Dmitrii Khizbullin, and Jurgen
tor in the performance of human groups. science,
Schmidhuber.2024. Languageagentsasoptimizable
330(6004):686–688.
graphs. arXivpreprintarXiv:2402.16823.
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,
Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,
Xiaoyun Zhang, and Chi Wang. 2023. Auto-
gen: Enabling next-gen llm applications via multi-
agent conversation framework. arXiv preprint
arXiv:2308.08155.
Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xi-
aolong Wang, Weidong Liu, and Yang Liu. 2023.
Exploring large language models for communica-
tiongames: Anempiricalstudyonwerewolf. arXiv
preprintarXiv:2309.04658.
ChengrunYang,XuezhiWang,YifengLu,HanxiaoLiu,
QuocVLe, DennyZhou, andXinyunChen.2023.
Largelanguagemodelsasoptimizers. arXivpreprint
arXiv:2309.03409.
RuiYang,LinSong,YanweiLi,SijieZhao,YixiaoGe,
XiuLi,andYingShan.2024. Gpt4tools: Teaching
largelanguagemodeltousetoolsviaself-instruction.
AdvancesinNeuralInformationProcessingSystems,
36.
Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng
Guo,JunqiDai,Xuan-JingHuang,andXipengQiu.
2023. Exchange-of-thought: Enhancing large lan-
guagemodelcapabilitiesthroughcross-modelcom-
munication. InProceedingsofthe2023Conference
onEmpiricalMethodsinNaturalLanguageProcess-
ing,pages15135–15153.