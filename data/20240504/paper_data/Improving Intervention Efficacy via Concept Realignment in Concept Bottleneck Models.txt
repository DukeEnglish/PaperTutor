Improving Intervention Efficacy via Concept Realignment
in Concept Bottleneck Models
Nishad Singhi1 Jae Myung Kim1 Karsten Roth1 Zeynep Akata2
1Tu¨bingen AI Center, University of Tu¨bingen 2Helmholtz Mu¨nchen, TU Mu¨nchen
Primary contact: nishadsinghi@gmail.com
Abstract
Concept Bottleneck Models (CBMs) ground image classification on human-understandable concepts
to allow for interpretable model decisions. Crucially, the CBM design inherently allows for human
interventions, in which expert users are given the ability to modify potentially misaligned concept choices
to influence the decision behavior of the model in an interpretable fashion. However, existing approaches
often require numerous human interventions per image to achieve strong performances, posing practical
challenges in scenarios where obtaining human feedback is expensive. In this paper, we find that this
is noticeably driven by an independent treatment of concepts during intervention, wherein a change of
one concept does not influence the use of other ones in the model’s final decision. To address this issue,
we introduce a trainable concept intervention realignment module, which leverages concept relations to
realign concept assignments post-intervention. Across standard, real-world benchmarks, we find that
concept realignment can significantly improve intervention efficacy; significantly reducing the number
of interventions needed to reach a target classification performance or concept prediction accuracy. In
addition, it easily integrates into existing concept-based architectures without requiring changes to the
models themselves. This reduced cost of human-model collaboration is crucial to enhance the feasibility
of CBMs in resource-constrained environments.
1 Introduction
Despite tremendous progress of Deep Learning (DL) techniques in research and applications, their adoption
to high-stakes scenarios has been limited [17, 40, 42]. This is in large part due to unpredictable biases and
failure cases of deep models when transferring to unseen data or complex & ambiguous cases grounded in the
numerous model parameters, architecture designs and training choices [10, 7, 13, 12, 24, 8, 3, 29, 5]. The
black-box nature of typical DL models and their representation spaces [33, 20, 4, 28, 5] further exacerbate
this problem, as it makes understanding and debugging the decision-making process of these models difficult.
Consequently, it becomes hard for human practitioners to trustworthily operate these models in scenarios
with significant legal [11, 34] or ethical [9, 27] constraints.
To foster trust, transparency in the decision-making process, and the ability to operate alongside expert
feedback are required. In order to incorporate these desiderata into the design space of deep models, Koh et
al. [17] introduced Concept Bottleneck Models (CBMs). These models break the decision process into the
extraction of human-interpretable concepts (such as ”white wings” and ”orange beak” when classifying a
seagull) from a given input, and a subsequent concept-grounded classifier operating on top of these concept
predictions. While this allows users to peek into the model decision process - maybe even more importantly,
it also uniquely allows for human-guided intervention and feedback integration at test time. This is done
through concept interventions, wherein an expert user analyses predicted concepts and optionally replaces
those they deem incorrect with ground-truth information (Fig. 1).
Such interventions can significantly raise the performance and reliability of these models [17, 40, 32, 42],
while offering a natural interface for human-AI collaboration. However, human annotation is expensive,
1
4202
yaM
2
]GL.sc[
1v13510.5042:viXraIntervention Sequence
Observe concept Further interventions
and intervene
1.0
Concept …
0.5
Encoder
… … …
Concept Scores Concept Scores Concept Scores
Final Concept-based
Classification Classifier
Figure1: Concept-basedclassificationmodelsallowforhumanintervention,whereahumanexpertcancorrect
specifically assigned concepts. However, to achieve satisfactory performance, concept-based classification
models often require a large number of interventions, where each additional intervention requires costly
human interaction.
especially when resources and access to expert knowledge are limited. Ideally, such concept models should
operate well with minimal human input. This becomes particularly prevalent as CBMs (as well as follow-up
extensions such as Concept Embedding Models (CEMs, [40])) often require numerous interventions in order
to significantly boost model performance [17, 40, 42], as the set of concepts these models operate on can often
be rather extensive. For example, on the widely used CUB benchmark (bird classification, [35]), it takes 13
interventions per image on overage to raise the accuracy of a baseline CBM model from around 68% to 90%
(Fig. 4).
In this work, we posit that a large part of this limited intervention efficacy can be traced back to the
independent nature of how concept interventions are treated. This means that correcting for one concept
(or a set of concepts) does not affect which other concepts are predicted for the same image. However, the
occurrence of concepts in real life is often correlated, and informing the model about one concept should
consequently influence the use of related ones. Not doing so means that we do not leverage human feedback
to its full extent - intervening on one specific concept naturally gives additional context about the potential
occurrence of other concepts, which should be taken into account in the final classification process. In
particular, we study the extent of this crucial aspect when operating with concept-based models. Our
study highlights how the use of a simple concept intervention realignment module, which learns from
statistical concept relations, can effectively and automatically realign concept values after an intervention
(or multiple) have been performed. Our experiments reveal how our concept intervention realignment can
seamlessly integrate into and improve any existing concept-based approach (e.g. default CBMs [17], advanced
CEMs [40] or recently introduced intervention-aware CEMs [42]), and can be deployed both jointly during
the initial training of the concept model, and as a post-hoc trained realignment mechanism. Across three
standard, real-world benchmarks (CUB [35], CelebA [19] and AwA2 [36]), we showcase consistent, in parts
very significant improvements in intervention efficacy. Across both concept prediction accuracy as well
as overall classification accuracy, performance increases more rapidly with interventions as compared to a
baseline where concepts are not realigned (in parts reducing the number of interventions needed to reach a
target performance by over 70%). Combined with its versatile usage and the minimal additional resource
requirements, we believe our insights into concept intervention realignment to be of high practical relevance,
helping to drive down the cost of human-model collaboration and facilitate the corresponding practical
deployment of concept-based models.
22 Related Works
Concept Bottleneck Models (CBMs) have been extensively studied since their introduction by [17]. [40]
proposed Concept Embedding Models as a generalization, utilizing embedding vectors for concepts rather
than scalar probabilities, thus enhancing task performance while maintaining interpretability. Recent efforts
have explored methods to enhance CBMs without requiring explicit concept supervision during training,
leveraging pre-trained vision backbones and language guidance [25, 38, 39]. [2] introduced Self-explaining
Neural Networks (SENNs) for unsupervised concept learning, while [30] proposed CBM-AUC combining
SENNs with CBMs. Probabilistic CBMs [16] were proposed to model uncertainty in concepts and final
predictions. [21, 23] addressed concept leakage, while techniques proposed by [22, 14] aimed to alleviate it.
Our work complements these efforts by enabling CBMs to update predictions of all concepts after human
intervention.
Interventions on CBMs. [17] showed that intervening on randomly selected concepts enhances
classificationperformanceinCBMs. [6]and[31]proposeduncertainty-basedstrategiesforexpertinterventions.
[32] extensively studied concept selection strategies, focusing on task performance and execution cost. [42]
introduced interventions during training to enhance model receptiveness to test-time interventions. Our
approachcomplementsexistingmethodsbyupdatingpredictionsofallconceptsfollowingexpertinterventions,
allowing integration with prior strategies. Concurrently, [37] proposed Energy-based CBMs to automate
conceptpredictionupdates. Incomparison,ourmethodbenefitsfromhighersimplicity,improvedperformance,
and seamless integration with existing CBM approaches.
3 Methods
3.1 Background and Preliminaries
Concept Bottleneck Models. A Concept-Bottleneck Model (CBM) can be viewed as a composition of
two models, h=f(g(x)):X →Y, with concept encoder g :X →C, and concept-based classification head
f : C → Y. X,Y, where C denote input, class label, and concept sets, respectively. CBMs get their name
from an inherently bifurcated optimization process: While the concept encoder g(x) is trained to predict
concepts cˆ∈Rk from the concept set with ∥C∥=k concepts given an image x∈Rd, the classification head
f(·) is optimized to predict final target labels y ∈Y ∈RM solely based on concept assignments produces by g.
CBM training data is thus given as D :={x(i),c(i),y(i)}N , where x(i),c(i),y(i) are the inputs, ground-truth
i=1
concepts, and ground-truth labels, respectively. Following existing works [17, 40, 42, 41], the concept encoder
g istrainedusinga(weighted)binarycross-entropyloss(L (cˆ,c)), whiletheclassificationheadf utilizes
concept
a cross-entropy classification objective (L (yˆ,y)=L (yˆ,y)).
task CE
Overall, there are three established schemes [17] for training CBMs: (1) Independent training: the concept
encoder and classification head are trained entirely independently, with ground-truth concepts c provided as
inputs to the classification head during training. (2) Sequential training: the concept encoder g is trained
first, followed by the classification head f trained using the concepts predicted by g. (3) Joint training: both
the concept encoder g and the classification head f are trained together using a combination of L
concept
and L , respectively. In all cases, this means that the classification head leverages only information on
task
concept (co-)occurences to predict final class labels, making it easy to ground the final classification decision
on interpretable concept assignments.
Concept Embedding Models. TheflowofinformationinaCBMisbottleneckedbythesetofuser-defined
concepts. This can potentially limit the processing capacity of the model, especially when the concepts do
not contain all the information that is needed to perform the downstream task. To overcome this issue,
[40] proposed Concept Embedding Models (CEMs) as a generalization of CBMs wherein every concept i
is represented by a pair of high-dimensional vectors, cˆ+ and cˆ− (as opposed to scalar concepts in CBMs).
i i
These embeddings are generated by passing x through concept-specific networks ϕ+ and ϕ−, and represent
i i
the concept being present and absent, respectively.
3The probability pˆ of the concept i being in x is then simply computed by passing cˆ+ and cˆ− to a scoring
i i i
function s as pˆ =s([cˆ+,cˆ−]). Similarly, both embeddings can also be combined as cˆ =pˆcˆ++(1−pˆ)cˆ−
i i i i i i i i
to parameterize a joint embedding for concept i. The final concept embedding which represents the full
image x and is passed to the classification head is then given as cˆ:=[cˆ ,cˆ ,...,cˆ ]. Notice the much higher
1 2 k
dimensionality of the concept embedding, which concatenates k concept-specific embeddings (as opposed to
producing just a single k-dimensional concept vector).
Concept Interventions. Both CBMs and CEMs allow users to intervene on concepts at test time.
Concretely, starting from the concept predictions of the model, cˆ, the user sequentially intervenes on T ≤k
concepts. As a human expert has to both investigate concept predictions and compare against input data,
interventionsaredifficulttoparallelize,effectivelyequatingconceptinterventionintoatrajectoryofT concept
intervention steps [32] (see also Fig. 1 for intuition).
Let S represent the set of concepts that have been intervened on up to time t≤T. The corresponding
t
conceptembeddingattimetisthengivenasc˜ ={c ,cˆ },wherec denotesthegroundtruthvaluesofthe
t St \St St
intervened concepts, and cˆ are the model’s predictions of non-intervened concepts. Intervening on concepts
\St
in this way updates the final prediction of the model from yˆto y˜=f(c˜). In the case of a CEM, intervening
on concept i to update its value from pˆ to p changes its embedding from cˆ to c˜ =p cˆ++(1−p )cˆ−.
i i i i i i i i
After each intervention t, we use a concept intervention policy π(c˜) to decide which concept to intervene
t
on next. While π can simply suggest random concepts for intervention, it is often much better to leverage
heuristics that rank concepts in the order of importance (by some measure). A commonly deployed, effective
intervention policy is UCP [18, 32], which utilizes the uncertainty of concepts. In particular, UCP selects
concepts with the highest uncertainty, i.e. concept predictions closest to 0.5.
Intervention-aware CEMs. While test-time interventions typically improve performance, this is not
always guaranteed. In fact, recent works have shown that concept interventions can in some cases even
hurt the model’s performance [41, 32]. [42] noted that this stems from the lack of training incentive for
the model to perform well under intervention. To address this, they proposed Intervention-aware CEMs
(IntCEMs), which introduce interventions during the training process to improve the model’s receptiveness to
interventions at test time, outperforming all existing methods in the intervention setting. In particular, they
train a CEM to minimize the following objective:
L (x,c,y,T)=L (x,c,y,cˆ,c˜)+λ L (cˆ,c)+λ L (x,c,y,T) (1)
IntCEM pred t conc conc roll roll
CE(f(cˆ,y)+γTCE(f(c˜),y)
L (x,c,y,c˜ ,κ )= t
pred 0 t 1+γT
L is the prediction loss for y, L the concept prediction loss, L the rollout loss incentivizing
pred conc roll
the model to predict the most informative concept for intervention. λ and λ are user-defined weights
conc roll
corresponding to L and L respectively, while T denotes the intervention trajectory. L penalizes
conc pred pred
the model for incorrect predictions both before and after the intervention, and γ ≥1 is a scaling term that
prioritizes correct predictions after intervention.
3.2 Concept Intervention Realignment
Previous works incrementally improve on predecessor methods by better parameterizing concept representa-
tions or introducing an intervention-aware training objective. However, all these works still treat concept
interventions independently. This means that an intervention on one specific concept has no effect on the
assignment of other concepts. This disregards relationships between concepts, which in practice do not occur
independently (e.g., ”white wing” and ”white belly” are more likely to co-occur). As a result, the existing
intervention process does not utilize human feedback optimally, as information about the verified existence of
one concept should naturally guide the prediction of other concepts. While this aspect is naturally important
to ensure that an accurate concept representation is passed to the label classifier, it is also crucial when
4Intervention Realignment Module
Score for Concept Concept Realignment Model
+
Concept
Concept GT GT GT Class.
Encoder
Selection - Head
e.g. CBM, CEM, …
Policy -
Input Image e.g. Rand, UCP, … Realigner Network + GT
e.g. MLP, LSTM, …
Concept Weight:decreased increased
Intervention t
Intervention Sequence Step t+1
Figure 2: Illustration of the concept intervention realignment module. Given the concept encoding
g(x), we intervene on the concept i selected by a concept selection policy π. This concept is replaced
with a ground-truth (GT) value (∈ {0,1} depending on whether it is present in a given image or not) to
obtain c˜ (representing intervention step t ∈ {1,...,T}). This intervened concept representation is then
t
passed into the concept realignment module (leveraging e.g. an MLP or LSTM reweighting mode), which
outputs the realigned u(c˜). To ensure that the ground-truth values provided by the user are not overwritten
t
during realignment, u(c˜) retains ground-truth corrections. The final concept vector is then based into a
t
concept-based classifier f.
utilizing concept-selection criteria such as UCP because intervening on one concept should consequently
reduce the chances of intervening on other closely related, likely co-occurring concepts, while also raising the
probability that uncertain and unrelated concepts get intervened on.
Intervention Realignment Module. Toaddressthis, weproposeaconcept intervention realignment
module (CIRM), which consists of two interdependent components: (a) a concept realignment model
(CRM),u:C →C. AfterauserintervenesonasubsetofconceptsS,theremainingconcepts(\S)areupdated
byarealignernetwork; and(b)anintervention policy π. Theconceptspredictedbytherealignmentmodel
are fed to the policy to suggest which concept to intervene on next. Both components are interdependent,
and together form the overall concept intervention realignment module, as also visualized in Figure 2. The
training of the full CIRM comprising both selection policy and concept realignment model aims to simulate
the complete intervention process. It thus starts from the concept predictions of the base model, cˆ, where we
sequentially intervene on concepts for T ≤k time steps by following a policy of choice, π (in our case UCP
by default, which we experimentally find to outperform random intervention significantly).
As in §3.1, let S denote the set of intervened concepts and c˜ ={c ,cˆ } denote the concepts at time t,
t t St \St
respectively. At every intervention time step, we feed c˜ to the realignment model to obtain updated concept
t
predictions as κ =u(c˜), which in turn are utilized by π(κ ) to produce intervention recommendations for
t t t
t+1. Finally, we train u with the ground-truth labels as targets using the loss
L(u)=((cid:80)T
CE(u(c˜),c))/T.
t=0 t
Using this simple objective, the concept realignment model u learns to take concept representations and
leverage intervened concepts S to predict an updated concept distribution, i.e., p(i;cˆ,S ). Note that this
t t
training objective utilizes standard CBM training information (i.e., concept annotations, [17, 40, 41, 42, 32]);
so no additional information beyond the standard CBM pipeline is required.
The overall training pipeline can still follow the standard CBM training paradigms (see previous section),
with the intervention realignment module being trained independently on top of a pre-trained frozen
CBM/CEM as a posthoc realignment method, or jointly with the CBM/CEM to introduce an explicit
realignment objective during training. For posthoc realignment, we first train the backbone f and the
classification head g. Subsequently, we freeze those components and train the realignment model u.
5Realignment Models. As shown in Fig. 2, we parameterize our concept realignment model with a neural
network v. To ensure that u does not overwrite the ground-truth concepts provided by the user, we also keep
track of the already intervened concepts S . Using this information, we replace the output of the realigned
t
concept embedding with the user-provided values for concepts in S . Hence, the final output of u for the ith
t
concept is given as
(cid:40)
v(c˜)(i) if i∈/ S
u(c˜,S )(i) = t t
t t c˜(i) if i∈S .
t t
Depending on the assumptions made on the realignment process, v is either a simple MLP or a recurrent
model (such as an LSTM [15]). The former parametrizes our default concept intervention realignment model,
which only passes the set of intervened and un-intervened concepts at intervention step t to the concept
realignment model consisting of a simple MLP. The set of concepts fed into the MLP may either be the
original concept embedding c˜ , where all intervened concepts up to and including step t have been replaced
0
with ground-truth values, or the previously realigned κ with similarly updated intervened concepts (c.f.
t−1
Fig. 2, ”GT”). Note that in either case, κ informs the selection process of the subsequent concept to
t−1
intervene on. After all interventions, the final concept embedding fed into the classifier is always u(c˜ ).
T
Practically, we found using c˜ to work slightly better than κ . Both cases above however only pass the final
t t−1
set of concepts at time t to the realignment model. Given the sequential nature of interventions, however, it
may also be beneficial to account for the entire intervention history to inform future concept realignment. As
a result, we also introduce a recurrent realignment variant, u , which employs an LSTM model to retain the
rec
entire history of interventions until time t.
End-to-End Realignment. In order to jointly train the CIR module and the base model f ◦g, we
will perform interventions while also training the base model. This naturally combines with the IntCEM
framework [42], which incorporates train-time interventions, and as such is our default choice for joint model
and realignment module training.
Concretely, wemodifyIntCEMs such thatafter t interventions, concepts c˜ are correctedpost-intervention
t
to obtain κ =u(c˜), which is then fed to the classifier f. The new training objective, then, is:
t t
L (x,c,y,T)=L (x,c,y,c˜ ,κ )+λ L (cˆ,c,κ ,κ )+λ L (2)
IntCEM-ReA pred 0 t conc conc-ReA 0 t roll roll
1(cid:18) CE(κ ,c)+γTCE(κ ,c)(cid:19)
L (cˆ,c,κ ,κ )= L (cˆ,c)+ 0 T (3)
conc-ReA 0 t 2 conc 1+γT
where L is the modified concept prediction loss which trains both the backbone g of the base model
conc-ReA
(first term) as well as the CRM (second term). We use the same γ as in L to prioritize correct predictions
pred
by the CRM after intervention, and the same λ and λ as in Eq. 1.
conc roll
4 Experiments
4.1 Preliminaries
Datasets. We perform experiments on three datasets: (1) Caltech-UCSD Birds-200-2011 (CUB) [35]
containing n = 11,788 bird images over 200 classes. Following the original CBM paper [17], we use 112
concepts grouped into 28 concept groups with the same splits. (2) Large-scale CelebFaces Attributes
(CelebA) [19] contains over 200,000 celebrity images annotated with 40 attribute labels, including noisy
characteristics such as gender and age. Following [40, 42], we use only the most balanced 8 concepts in our
experiments, resulting in 28 =256 classes. (3) Animals with Attributes 2 (AwA2) [36] is a collection of
n=37,322 animal images over 50 classes annotated with 85 attributes such as species, color, and behavior.
6Sequential CBM on CUB Dataset Sequential CBM on CelebA Dataset Sequential CBM on AwA2 Dataset
0.6 W Wi it th ho Cu ot n C co en pc te Rp et a R lie ga nl mig en nm te (n Ot urs) 0.5 W Wi it th ho Cu ot n C co en pc te Rp et a R lie ga nl mig en nm te (n Ot urs) 0.15 W Wi it th ho Cu ot n C co en pc te Rp et a R lie ga nl mig en nm te (n Ot urs)
0.4
0.4
0.10 0.3
0.2 0.2
0.05
0.1
0.0 0.0 0.00
0 10 20 0 2 4 6 8 0 20 40 60 80
Number of Intervened Concepts Number of Intervened Concepts Number of Intervened Concepts
Figure3: Conceptpredictionlossvs. thenumberofintervenedconceptswithandwithoutconceptrealignment.
Concept realignment consistently improves concept predictions.
Sequential CBM on CUB Dataset Sequential CBM on CelebA Dataset Sequential CBM on AwA2 Dataset 95 100
90 36 98
85 34 96
80 32 94
75 92
30
70 Without Concept Realignment Without Concept Realignment 90 Without Concept Realignment
With Concept Realignment (Ours) 28 With Concept Realignment (Ours) With Concept Realignment (Ours)
0 10 20 0 2 4 6 8 0 20 40
Number of Intervened Concepts Number of Intervened Concepts Number of Intervened Concepts
Figure4: Classificationaccuracyvs. thenumberofintervenedconceptswithandwithoutconceptrealignment.
Realignment consistently improves classification accuracy.
Implementation Details. We perform experiments on CEMs, IntCEMs, and three types of CBMs
(sequential, independent, and joint). For all models and datasets, we follow the hyperparameters used in
[42]. During CIRM training, we sequentially intervene on concepts T =k times. By default, we use UCP
both during training and inference, and if not stated otherwise, use a multi-layered perceptron (MLP) for
concept realignment. We use the predictions of the base CBM (c˜) as its input for un-intervened concept
t
representations. We perform a small, standard hyperparameter using Optuna [1] with 50 trials to search
over the number of hidden layers ∈{1,2,3} and units ∈{k,2k,k/2}, the learning rate ∈[10−5,10−1] and
weight decay ∈[10−6,5×10−5], and use the same batch size as used to train the base model. We employ
early stopping and learning rate decay on the validation loss. For joint training, we instantiate the realigner
MLP 2 hidden layers containing k neurons each. Experiments are conducted using PyTorch [26].
4.2 Concept Realignment Improves Intervention Efficacy
To probe the efficacy of our concept intervention realignment module, we evaluate both the change in concept
prediction loss as well as overall classification accuracy as a function of intervened concept counts. These
are visualized in Fig. 3 and Fig. 4 for sequentially trained CBMs (see §3.1), respectively, for all benchmark
test sets - CUB, CelebA and AwA2. Note that for AwA2, we only show the first 50 interventions for visual
clarity, as performance beyond that heavily plateaus since sufficient concepts have been intervened on to
perfectly solve the test data. Table 1 numerically summarizes these results via AUC scores and provides
additional scores for independently trained CBMs, jointly trained CBMs as well as Concept Embedding
Models (CEMs). Runs in Tab. 1 and Figs. 3, 4 all utilize the stronger UCP concept selection policy as
opposed to the weaker random selection policy to measure intervention efficacy at the highest level, and train
the concept realignment module on top of already trained concept models.
7
ssoL
tpecnoC
)%(
ycaruccA
noitacifissalC
ssoL
tpecnoC
)%(
ycaruccA
noitacifissalC
ssoL
tpecnoC
)%(
ycaruccA
noitacifissalCTable 1: Area Under Curve (AUC) of Concept Prediction Loss and Classification Accuracy with/without
CIRM.WeusethesamebackboneforsequentialandindependentCBMs. CIRMimprovesperformanceacross
all models and datasets. Intervention curves share long saturation plateaus for high intervention counts.
Accuracy AUC scores are thus saturated, and best combined with performance graphs in Figs. 3, 4.
Concept Loss AUC ↓ Accuracy AUC ↑
Base Model Realigned
CUB CelebA AwA2 CUB CelebA AwA2
× 6.71 1.59 4.26 2460.8 280.7 8364.0
Sequential CBM
✓ 3.15 1.52 1.13 2510.9 284.3 8397.6
× 6.71 1.59 4.26 2653.4 280.2 8403.4
Independent CBM
✓ 3.15 1.52 1.13 2678.3 282.1 8437.0
× 5.93 3.06 4.77 2580.3 273.1 8276.4
Joint CBM
✓ 3.67 1.76 1.48 2609.0 273.9 8327.4
× 5.99 1.61 4.90 2521.4 396.3 8429.3
CEM
✓ 3.20 1.46 1.69 2558.4 400.1 8433.9
Improved concept attribution through intervention. Across all datasets, we can observe a consistent,
in parts vast reduction in concept prediction loss, which measures the correct assignment of concepts for
each input (using the concept loss described in §3.1). For example on CUB, a tenfold reduction of the
original unintervened concept loss (∼0.6 to ∼0.06) can be achieved with half the number of interventions (11
with concept realignment, 23 without). This effect becomes even more prevalent on AwA2, where a tenfold
reduction (∼0.17→∼0.017) is achieved after around 16 interventions with realignment versus more than 60
without; marking a more than 70% reduction in intervention efforts. This is also reflected in Tab. 1, where
concept loss AUC drops by in parts more than half for CUB and from 4.26 to 1.13 on AwA2. We find this
significant improvement in concept attribution persists across all CBMs and CEMs.
We do find that for CelebA with a much more restrictive concept bottleneck than e.g. CUB and AwA2,
due to significantly fewer (note that in CUB concepts are already grouped, see §4.1) and noisier concepts,
that the overall gain in concept accuracy is smaller. This is also reflected in the notably weaker performance
of the base CBM (c.f. Fig. 4, middle - less than 38% accuracy when intervening on all concepts), which
strongly points towards overall insufficient concept information provided in the CelebA training data. Overall,
however, we find very clear evidence that the concept intervention realignment module allows practitioners to
leverage human intervention feedback to a much larger extent to attribute the correct concepts to respective
inputs. This means that the subsequent classifier will operate on a much more accurate set of concepts,
thereby improving the overall interpretability of the final classification decision.
Improved overall classification through intervention. On top of that, we also find that the significant
gain in intervention efficacy on a concept attribution level also translates to subsequent gains in intervention
efficacy for the overall classification performance (Fig. 4). For example on CUB, the final classification
accuracy after intervening on all concepts is 93.9%, which is achieved already after ∼16 intervention steps. A
comparableperformancewithoutconceptinterventionrealignmentrequiresnearlycomplete,∼24intervention
steps, marking a 50% increase. The same can be seen on CelebA and AwA2 as well, where the upper-bound
performance can be achieved with much fewer interventions (particularly without the need to intervene on all
concepts). Even intermediate performance targets are achieved much earlier; a classification accuracy target
of e.g. 98% on AwA2 requires only 12 concept interventions with realignment, while the non-aligned baseline
needs 19 interventions on average. We find these results to be also reflected numerically in Tab 1, where
accuracy AUC increases from e.g. 2460.8 to 2510.9 on CUB. We do point towards high numerical saturation
given the larger performance plateaus at higher intervention counts, and high starting accuracies (e.g. ∼90%
on AwA2). Numerical results are thus best considered alongside the intervention trajectories in Figs. 3 and 4.
Together, our experiments provide strong evidence that concept intervention realignment is crucial to
best leverage human feedback in concept-based decision systems; allowing to significantly reduce intervention
budgets by in parts over 70% to achieve a desired target performance. These gains can also be achieved after
8IntCEM on CUB Dataset IntCEM on CUB Dataset
100
0.5
95
0.4
0.3 90
0.2 85
0.1 IntCEM
80
IntCEM + End-to-end Realignment
0.0 IntCEM + Posthoc Realignment
0 10 20 0 10 20
Number of Intervened Concepts Number of Intervened Concepts
Figure 5: Concept Intervention Realignment in intervention-aware CEMs. (a) Concept prediction loss and
(b) classification accuracy with jointly and post-hoc trained CIRMs. In both cases, significant benefits can
be seen, especially for correct concept attribution after intervention - both for jointly and posthoc trained
realignment modules.
concept models have been trained, allowing for versatile applicability.
4.3 Intervention Realignment for Intervention-aware CEMs
In this section, we investigate training the CIRM during the training process of an already intervention-
regularized concept model; namely the recently proposed, state-of-the-art intervention-aware CEM [42] (see
also §3.1). Following the objective described in Eq. 2, we operate and train the concept intervention module
in conjunction with the intervention objective proposed by [42].
Our results are shown in Fig. 5. First, we find that explicit concept intervention realignment can
significantly improve correct concept attribution, even in intervention-aware training setups (c.f. Fig. 5a).
While not as significant as improvements over standard CBM models, for specific target concept prediction
losses (such as a fivefold reduction from 0.5 to 0.1), half the number of intervention steps are needed (11
versus 20). The improved concept attribution is also reflected in higher intervention accuracies as seen in
Fig. 5b, albeit the overall (still notable!) improvement is less reflective of the significant gains on a concept
level. Overall, however, our experiments highlight that even when applied to state-of-the-art approaches that
specifically simulate the intervention process during training, improved intervention efficacy can be found.
Importantly, the consistently significant improvements on a concept attribution level mean that classification
decisionsaremuchbettergroundedoncorrectconceptattributions,whichiscrucialforinterpretability[17,40]
of classification results. Finally, we find that concept intervention realignment can be applied both as a
regularization mechanism during training, as well as adapted entirely posthoc, while still offering consistent
benefits. This supports the high versatility of CIRMs as a general-purpose tool to increase intervention
efficacy.
4.4 Realignment Module Ablations
Realignment Model Architectures. In this section, we study the effect of various design choices for
the realignment module along two dimensions: (1) Recurrent vs. Feedforward Networks: Since we
intervene on concepts sequentially, it is possible that the realignment module can benefit from the overall
order and history of interventions to make more accurate concept predictions. To do this, we instantiate the
concept realignment network using an LSTM [15]. We compare this against our default MLP. (2) Previous
Output vs. Original Concepts: By default, the realignment module takes as input a combination of
ground-truth concepts provided by the user and values predicted by the base model at t=0 for the concepts
9
ssoL
tpecnoC
)%(
ycaruccA
noitacifissalCSequential CBM on CUB Dataset Sequential CBM on CUB Dataset
UCP Interventions UCP Interventions
90
0.6
0.4 80
MLP + Original Concepts
0.2
70 MLP + Previous Output
LSTM + Original Concepts
LSTM + Previous Output
0.0
0 10 20 0 10 20
Number of Intervened Concepts Number of Intervened Concepts
Figure6: (a)Conceptpredictionlossand(b)classificationaccuracyforvariousrealignerarchitecturesalongside
UCP policy. Using an MLP with concept predictions of the base model works better than compounding
refinements and accounting for intervention trajectories using LSTMs.
Sequential CBM on CUB Dataset Sequential CBM on CUB Dataset
Random Interventions Random Interventions 95
0.6
90
0.4 85
80
0.2 75
Without Concept Realignment
70 Realignment trained w/ Random
Realignment trained w/ UCP
0.0
0 10 20 0 10 20
Number of Intervened Concepts Number of Intervened Concepts
Figure 7: Concept prediction loss and classification accuracy under random interventions for realignment
modules trained with random and UCP policy, respectively. Results indicate that alignment of policy used
during training and deployment is important.
that have not been intervened on (see also §3.2). Due to the sequential nature of interventions, one may also
directly feed the output of the realignment module at time t−1 as input to it at time t in order to compound
the refinements over multiple time steps. Combining both axes results in four recombinations, which we
compareinFig. 6. Ascanbeseen, thereislimitedgainwhenaccountingforthecompleteinterventionhistory
using an LSTM realigner network. Similarly, we find that applying the MLP primarily for concept selection
alongside UCP and as final input to the classification head works better than compounding refinements over
intervention steps.
Intervention Policy Transfer. In this section, we study the importance of aligning intervention policies
used during training with those deployed at test time. In particular, we operate on the base setup, which
deploys the CBM and the concept intervention realignment module using only the much weaker random
intervention policy at test time. However, we change the policy used to train the concept intervention
realignment module. Our results are visualized in Fig. 7. As can be seen, while a realignment module trained
with UCP can still be effective when deployed with a random intervention policy, it is notably outperformed
by the weaker random policy at test-time when the realignment module has been trained on the same random
10
ssoL
tpecnoC
ssoL
tpecnoC
)%(
ycaruccA
noitacifissalC
)%(
ycaruccA
noitacifissalCPredicted Labels: Original: Common Raven Original: Red-winged Blackbird Original: Groove-billed Ani
Realigned: Common Raven Realigned: Groove-billed Ani Realigned: Groove-billed Ani 1) Bill length: shorter than head
Groove-billed Ani 0.6 2) Bill length: same as head
3) Head pattern: plain
4) Leg color: black
0.4
5) Belly color: black
6) Leg color: grey
0.2 7) Bill shape: all-purpose
8) Size: small (5 - 9 in)
0 9) Wing shape: rounded-wings
t = 1 t = 4 t = 6 10) Wing pattern: solid
Concept Error Original Concept
After Intervention Realigned Correct Original Correct
without Re-Alignment Prediction Errors
Concept Error
with Re-Alignment t = 1 t = 4 t = 10
Original: Parakeet Auklet Original: Parakeet Auklet Original: Crested Auklet
Predicted Labels:
Realigned: Parakeet Auklet Realigned: Crested Auklet Realigned: Crested Auklet 1) Belly color: black
1.0 2) Breast color: black
0.8 3) Eye color: black
4) Belly color: grey
0.6 5) Breast color: grey
0.4 6) Underparts color: grey
7) Underparts color: white
0.2 8) Nape color: black
Crested Auklet 0 9) Throat color: black
1 2 3 4 5 6 7 8 910 Original and Updated 10) Throat color: white
Concepts with highest errors
Concept Error for Concept 1
Figure 9: Qualitative examples for the improved intervention efficiency of CIRM. We show the change in
concept prediction errors of the ten worst predicted concepts, as a function of concept intervention steps
t. As can be seen, concept realignment allows concept error even for strongly mispredicted concepts to be
significantly reduced with interventions, achieving correct label classification after much fewer interventions
compared to a non-realigned baseline.
policy as well. This means that the realignment module adapts to the selection policy used during training.
Thus to get the most benefits out of concept intervention realignment, selection policies should align during
training and deployment.
Alignment b/w Realignment Module Components. Fi-
nally, we study how important the alignment between the con- Sequential CBM on CUB Dataset
95
cept realignment model and intervention policy (i.e., UCP) is
to form the overall concept intervention realigment module.
90
To accomplish this, we employ two module variations: (a) an
original policy denoted as π(cˆ ), which only applies the UCP 85
0
criterion to the original concept predictions generated by the
80 base model without any concept realignment (i.e., the policy
does not change over time), and (b) our default setup (updated
75
policy), which informs the intervention policy using realigned Without Concept Realignment
concept values (π(κ )). Note that in both cases, the classifica- 70 Realignment w/ Original Policy
t
Realignment w/ Updated Policy
tionheadstillreceivesrealignedconceptembeddings,asweonly
wanttostudytheimportanceofalignmentbetweentheconcept 0 10 20
realignmentmodelandtheinterventionpolicy. ResultsinFig.8 Number of Intervened Concepts
clearly reveal that while simple realignment on its own can Figure 8: Classification accuracy vs concept
already help improve intervention efficacy, much larger efficacy interv. counts, showing our updated selec-
gainsareunlockedwhenbothpolicyandtherealignmentmodel tion policies improving over the static one.
are utilized in conjunction.
A Closer Look at Concept Realignment. To understand the impact of the realignment process
qualitatively, we also provide examples in Fig. 9. In this figure, we showcase the impact of interventions on
the top 10 concepts with the highest prediction errors, and the specific number of interventions required to
predict the correct label. For both examples, we find that intervention on a single concept is insufficient to
11
rorrE
noitciderP
tpecnoC
rorrE
noitciderP
tpecnoC
)%(
ycaruccA
noitacifissalCflip incorrect class predictions. However, as we intervene on more concepts, we can clearly see that concept
realignment jointly allows concept prediction error - even on the initially worst predicted concepts - to be
significantly reduced, while also reaching correct image classification with in parts less than half the number
of interventions (for Crested Auklet). These results conceptually support the quantitative benefits of concept
realignment seen in previous benchmark experiments.
5 Conclusion
In this work, we identify the independent treatment of concepts during test-time interventions in CBMs
as a cause for reduced intervention efficacy. To remedy this problem, we propose a concept intervention
realignment module - a simple and lightweight technique to automatically update concept assignments after
human intervention on one or multiple concepts. Our experiments demonstrate significant gains in concept
attribution as well as overall classification accuracy of concept-based models under intervention. We show
that our approach is versatile and can be applied to a wide range of concept-based models, intervention
policies, and training schemes. We believe that the reduction in required human interventions to reach
performance targets facilitates the practical deployment of concept-based models even in resource-constrained
environments.
Acknowledgements
Karsten Roth and Jae Myung Kim thank the European Laboratory for Learning and Intelligent Sys-
tems (ELLIS) PhD program and the International Max Planck Research School for Intelligent Systems
(IMPRS-IS) for support. This work was supported by DFG project number 276693517, by BMBF FKZ:
01IS18039A, by the ERC (853489 - DEXIM), by EXC number 2064/1 – project number 390727645. The
authors would like to thank Shyamgopal Karthik and Leander Gerrbach for their helpful feedback on the
manuscript.
References
[1] TakuyaAkiba,ShotaroSano,ToshihikoYanase,TakeruOhta,andMasanoriKoyama. Optuna: Anext-generation
hyperparameter optimization framework. In Proceedings of the 25th ACM SIGKDD international conference on
knowledge discovery & data mining, pages 2623–2631, 2019. 7
[2] David Alvarez Melis and Tommi Jaakkola. Towards robust interpretability with self-explaining neural networks.
Advances in neural information processing systems, 31, 2018. 3
[3] Alexander Brown, Nenad Tomasev, Jan Freyberg, Yuan Liu, Alan Karthikesalingam, and Jessica Schrouff.
Detecting shortcut learning for fair medical ai using shortcut testing. Nature Communications, 14(1), July 2023.
ISSN 2041-1723. doi: 10.1038/s41467-023-39902-7. URL http://dx.doi.org/10.1038/s41467-023-39902-7. 1
[4] VanessaBuhrmester,DavidMu¨nch,andMichaelArens. Analysisofexplainersofblackboxdeepneuralnetworks
for computer vision: A survey, 2019. 1
[5] StephenCasper,CarsonEzell,CharlotteSiegmann,NoamKolt,TaylorLynnCurtis,BenjaminBucknall,Andreas
Haupt, Kevin Wei, J´er´emy Scheurer, Marius Hobbhahn, Lee Sharkey, Satyapriya Krishna, Marvin Von Hagen,
Silas Alberti, Alan Chan, Qinyi Sun, Michael Gerovitch, David Bau, Max Tegmark, David Krueger, and Dylan
Hadfield-Menell. Black-box access is insufficient for rigorous ai audits, 2024. 1
[6] Kushal Chauhan, Rishabh Tiwari, Jan Freyberg, Pradeep Shenoy, and Krishnamurthy Dvijotham. Interactive
concept bottleneck models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages
5948–5955, 2023. 3
[7] Alexandra Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction
instruments, 2016. 1
12[8] Natalie Dullerud, Karsten Roth, Kimia Hamidieh, Nicolas Papernot, and Marzyeh Ghassemi. Is fairness only
metric deep? evaluating and addressing subgroup gaps in deep metric learning. In International Conference on
Learning Representations, 2022. URL https://openreview.net/forum?id=js62_xuLDDv. 1
[9] Juan Manuel Dura´n and Karin Rolanda Jongsma. Who is afraid of black box algorithms? on the epistemological
and ethical basis of trust in medical ai. Journal of Medical Ethics, 47(5):329–335, 2021. ISSN 0306-6800. doi:
10.1136/medethics-2020-106820. URL https://jme.bmj.com/content/47/5/329. 1
[10] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness.
In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ITCS ’12, page 214–226, New
York,NY,USA,2012.AssociationforComputingMachinery.ISBN9781450311151.doi: 10.1145/2090236.2090255.
URL https://doi.org/10.1145/2090236.2090255. 1
[11] EUGDPR. Gdpr. general data protection regulation, 2017. 1
[12] Elias Eulig, Piyapat Saranrittichai, Chaithanya Kumar Mummadi, Kilian Rambach, William Beluch, Xiahan Shi,
and Volker Fischer. Diagvib-6: A diagnostic benchmark suite for vision models in the presence of shortcut and
generalization opportunities. In Proceedings of the IEEE/CVF International Conference on Computer Vision
(ICCV), October 2021. 1
[13] Robert Geirhos, Jo¨rn-Henrik Jacobsen, Claudio Michaelis, Richard S. Zemel, Wieland Brendel, Matthias Bethge,
and Felix Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2:665 – 673, 2020.
1
[14] Marton Havasi, Sonali Parbhoo, and Finale Doshi-Velez. Addressing leakage in concept bottleneck models.
Advances in Neural Information Processing Systems, 35:23386–23397, 2022. 3
[15] Sepp Hochreiter and Ju¨rgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.
6, 9
[16] Eunji Kim, Dahuin Jung, Sangha Park, Siwon Kim, and Sungroh Yoon. Probabilistic concept bottleneck
models. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and
Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume
202 of Proceedings of Machine Learning Research, pages 16521–16540. PMLR, 23–29 Jul 2023. URL https:
//proceedings.mlr.press/v202/kim23g.html. 3
[17] Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, and Percy Liang.
Concept bottleneck models. In International conference on machine learning, pages 5338–5348. PMLR, 2020. 1,
2, 3, 5, 6, 9
[18] David D Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning. In Machine
learning proceedings 1994, pages 148–156. Elsevier, 1994. 4
[19] ZiweiLiu,PingLuo,XiaogangWang,andXiaoouTang. Deeplearningfaceattributesinthewild. InProceedings
of the IEEE international conference on computer vision, pages 3730–3738, 2015. 2, 6
[20] Francesco Locatello, Gabriele Abbati, Tom Rainforth, Stefan Bauer, Bernhard Sch¨olkopf, and Olivier Bachem.
On the fairness of disentangled representations. Curran Associates Inc., Red Hook, NY, USA, 2019. 1
[21] AnitaMahinpei,JustinClark,IsaacLage,FinaleDoshi-Velez,andWeiweiPan. Promisesandpitfallsofblack-box
concept learning models. arXiv preprint arXiv:2106.13314, 2021. 3
[22] Emanuele Marconato, Andrea Passerini, and Stefano Teso. Glancenets: Interpretable, leak-proof concept-based
models. Advances in Neural Information Processing Systems, 35:21212–21227, 2022. 3
[23] Andrei Margeloiu, Matthew Ashman, Umang Bhatt, Yanzhi Chen, Mateja Jamnik, and Adrian Weller. Do
concept bottleneck models learn as intended? arXiv preprint arXiv:2105.04289, 2021. 3
[24] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A survey on bias
and fairness in machine learning, 2022. 1
13[25] Tuomas Oikarinen, Subhro Das, Lam M Nguyen, and Tsui-Wei Weng. Label-free concept bottleneck models. In
The Eleventh International Conference on Learning Representations, 2022. 3
[26] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito,
MartinRaison,AlykhanTejani,SasankChilamkurthy,BenoitSteiner,LuFang,JunjieBai,andSoumithChintala.
Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information
ProcessingSystems32,pages8024–8035.CurranAssociates,Inc.,2019. URLhttp://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf. 7
[27] Samuele Lo Piano. Ethical principles in machine learning and artificial intelligence: cases from the field and
possible ways forward. Palgrave Communications, 7(1):1–7, 2020. URL https://EconPapers.repec.org/RePEc:
pal:palcom:v:7:y:2020:i:1:d:10.1057_s41599-020-0501-9. 1
[28] Karsten Roth, Mark Ibrahim, Zeynep Akata, Pascal Vincent, and Diane Bouchacourt. Disentanglement of
correlated factors via hausdorff factorized support. In The Eleventh International Conference on Learning
Representations, 2023. URL https://openreview.net/forum?id=OKcJhpQiGiX. 1
[29] Karsten Roth, Lukas Thede, A. Sophia Koepke, Oriol Vinyals, Olivier J Henaff, and Zeynep Akata. Fantastic
gains and where to find them: On the existence and prospect of general knowledge transfer between any
pretrained model. In The Twelfth International Conference on Learning Representations, 2024. URL https:
//openreview.net/forum?id=m50eKHCttz. 1
[30] YoshihideSawadaandKeigoNakamura. Conceptbottleneckmodelwithadditionalunsupervisedconcepts. IEEE
Access, 10:41758–41765, 2022. 3
[31] Ivaxi Sheth, Aamer Abdul Rahman, Laya Rafiee Sevyeri, Mohammad Havaei, and Samira Ebrahimi Kahou.
Learningfromuncertainconceptsviatesttimeinterventions.InWorkshoponTrustworthyandSociallyResponsible
Machine Learning, NeurIPS 2022, 2022. 3
[32] Sungbin Shin, Yohan Jo, Sungsoo Ahn, and Namhoon Lee. A closer look at the intervention procedure of
concept bottleneck models. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan
Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning,
volume 202 of Proceedings of Machine Learning Research, pages 31504–31520. PMLR, 23–29 Jul 2023. URL
https://proceedings.mlr.press/v202/shin23a.html. 1, 3, 4, 5
[33] Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information, 2017. 1
[34] Sandra Wachter, Brent Mittelstadt, and Chris Russell. Counterfactual explanations without opening the black
box: Automated decisions and the gdpr, 2018. 1
[35] CatherineWah,SteveBranson,PeterWelinder,PietroPerona,andSergeBelongie.Thecaltech-ucsdbirds-200-2011
dataset. 2011. 2, 6
[36] Yongqin Xian, Christoph H Lampert, Bernt Schiele, and Zeynep Akata. Zero-shot learning—a comprehensive
evaluation of the good, the bad and the ugly. IEEE transactions on pattern analysis and machine intelligence, 41
(9):2251–2265, 2018. 2, 6
[37] Xinyue Xu, Yi Qin, Lu Mi, Hao Wang, and Xiaomeng Li. Energy-based concept bottleneck models. In The
Twelfth International Conference on Learning Representations, 2023. 3
[38] YueYang,ArtemisPanagopoulou,ShenghaoZhou,DanielJin,ChrisCallison-Burch,andMarkYatskar. Language
in a bottle: Language model guided concept bottlenecks for interpretable image classification. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 19187–19197, 2023. 3
[39] Mert Yuksekgonul, Maggie Wang, and James Zou. Post-hoc concept bottleneck models. In The Eleventh
International Conference on Learning Representations, 2022. 3
[40] MateoEspinosaZarlenga,PietroBarbiero,GabrieleCiravegna,GiuseppeMarra,FrancescoGiannini,Michelangelo
Diligenti, Zohreh Shams, Frederic Precioso, Stefano Melacci, Adrian Weller, et al. Concept embedding models.
arXiv preprint arXiv:2209.09056, 2022. 1, 2, 3, 5, 6, 9
14[41] Mateo Espinosa Zarlenga, Pietro Barbiero, Zohreh Shams, Dmitry Kazhdan, Umang Bhatt, Adrian Weller, and
Mateja Jamnik. Towards robust metrics for concept representation evaluation. arXiv preprint arXiv:2301.10367,
2023. 3, 4, 5
[42] Mateo Espinosa Zarlenga, Katherine M Collins, Krishnamurthy Dj Dvijotham, Adrian Weller, Zohreh Shams,
and Mateja Jamnik. Learning to receive help: Intervention-aware concept embedding models. In Thirty-seventh
Conference on Neural Information Processing Systems, 2023. 1, 2, 3, 4, 5, 6, 7, 9
15