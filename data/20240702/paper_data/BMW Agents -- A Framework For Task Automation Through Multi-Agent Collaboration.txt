BMW Agents - A Framework For Task Automation
Through Multi-Agent Collaboration
NoelCrawford EdwardB.Duffy ImanEvazzade TorstenFoehr
GregoryRobbins DebbrataKumarSaha JiyaVarma MarcinZiolkowski†∗
BMWGroup
InformationTechnologyResearchCenter
2ResearchDrive,Greenville,SC29607
†marcin.ziolkowski@bmwgroup.com
Abstract
AutonomousagentsdrivenbyLargeLanguageModels(LLMs)offerenormous
potentialforautomation. Earlyproofofthistechnologycanbefoundinvarious
demonstrationsofagentssolvingcomplextasks,interactingwithexternalsystems
toaugmenttheirknowledge,andtriggeringactions. Inparticular,workflowsin-
volvingmultipleagentssolvingcomplextasksinacollaborativefashionexemplify
theircapacitytooperateinlessstrictandlesswell-definedenvironments. Thus,
a multi-agent approach has great potential for serving as a backbone in many
industrialapplications,rangingfromcomplexknowledgeretrievalsystemstonext
generationroboticprocessautomation. Giventhereasoningabilitieswithinthe
current generation of LLMs, complex processes require a multi-step approach
thatincludesaplanofwell-definedandmodulartasks. Dependingonthelevelof
complexity,thesetaskscanbeexecutedeitherbyasingleagentoragroupofagents.
Inthiswork,wefocusondesigningaflexibleagentengineeringframeworkwith
carefulattentiontoplanningandexecution,capableofhandlingcomplexusecase
applicationsacrossvariousdomains. Theproposedframeworkprovidesreliability
inindustrialapplicationsandpresentstechniquestoensureascalable,flexible,and
collaborativeworkflowformultipleautonomousagentsworkingtogethertowards
solvingtasks.
1 Introduction
Intherapidlyevolvinglandscapeofartificialintelligence(AI),thedeploymentofgenerativeAImod-
elsmarksasignificanttechnologicaladvancement,transforminghowbusinessesandorganizations
recognizethevalueofAIanditspotentialforautomationofcomplextasks. Whiletheemerging
capabilitiesofLargeLanguageModels(LLMs)areimpressive,theirapplicationsinindustrialsettings
are limited within this current generation of models. By themselves, LLMs do not have access
toconfidentialandproprietarybusinessinformationwhichisnecessaryfordevelopingrobustand
highqualityAI-poweredapplications. Whileitispossibletofine-tunethesemodelswithcompany-
specificdata,onemustcarefullyconsiderthechallengesassociatedwiththisapproach,suchasdata
preparationandmaintainability. Additionally,thereisalargeITecosystemwhereexistingtoolsand
applicationscanbeleveragedwithouttheneedtoduplicatedata. Theselimitationshighlightthe
needofamoredynamicapproachtoAIapplicationdesignusingAIagents[1]. Thisworkexplores
∗Authorsinalphabeticalorder.
Preprint.July2,2024
4202
luJ
1
]AM.sc[
2v14002.6042:viXraanapproachthatleveragesthecapabilitiesofAIagentstosignificantlyenhanceproductivityand
innovationthroughcollaborativemulti-agentworkflows.
TheintegrationofmultipleAIagentsinacohesiveworkflowpresentsaparadigmshiftfromtraditional,
singular AI applications to a more dynamic, interconnected framework. This method not only
amplifiestheindividualcapabilitiesofeachagent,whichcannowhavenarrowexpertiseandoperate
robustly,italsoorchestratesaworkflowofinteractionsthatdrivecomplextaskcompletion[2,3].This
documentwilldetailthefoundationalprinciplesofdesigningandimplementingarobustmulti-agent
engineeringframework[4]. Itwilldiscussthearchitecturalconsiderations,chosenalgorithms,and
methodsforrealizingcomplexgenerativeAIapplications.
ThetrajectoryofAIagentsresearch,particularlywithafocusonLLMs,tookanotableturnwiththe
adventofspecializedframeworksaimedatthecompletionofverygenerictasks.Withtheintroduction
ofprojectslikeAutoGPT[5]andBabyAGI[6],theinterestinAIagentsexpandedfromacademic
researchsettingsintoabroadercommunity. Bothprojectswereabletodemonstratethatcomplex
taskscanbedecomposedintosimplersteps. Byprogrammaticallyorchestratingthesolutionofeach
individual step, a solution to the more complex task can be achieved. In the scope of AI agents
poweredbyLLMs,theideassurroundingtaskdecomposition,planning,andtaskexecutionusing
toolshaveemergedtoovercomethelimitationsobservedintheexistinggenerationofLLMs[3].
Inthisworkweturnourattentiontomulti-agentsystems[7–15]andthepotentialofsolvingcomplex
tasksthroughthecollaborativeworkofAIagents. Ourperspectiveisrootedintheobservationsthat
1)AI agentsperform wellif theirscopeof responsibilityis narrowed toa welldefinedrole [16],
2) complex problems require the expertise of several narrowly defined AI agents to successfully
mimichumansolutionswithstep-by-stepreasoninganddeliberation[17–19],3)simpletaskscanbe
completedwithmorecomplexpromptingstrategieslikeReAct[20],and4)impactfuladoptionofAI
applicationscannotbeachievedinisolationfromexistingdevelopmentecosystems[21,22]. Based
ontheseobservations,wehavedevelopedanagentengineeringframeworktoenabletaskautomation
throughmulti-agentcollaborationinenterprisesettings. Theframeworkismeanttointeractwithinan
ITlandscapethatisamixtureofmodernandlegacyapplications. ItservesasatemplateforstableAI
applicationsthatenabletheautomationofcomplexprocesses,eitherashumanorprogrammatically
triggeredworkflows. Thisframeworkisdesignedtobemodular,extendable,andstayagnostictothe
dynamicLLMlandscape.
Thisreportservesasatechnicalintroductionofmethodologyandanexampleblueprintforindus-
trial applications of multi-agent workflows. It aims to offer valuable insights and guidelines for
organizationslookingtoleveragetheseadvancedAIsystemstoachievescalability,resilience,anda
competitiveedge. Itmayalsoserveasadidacticresourceforappliedresearchersnewtothefieldof
AIdrivenautomationandAIagents. Thisdocumentisorganizedinthefollowingway: Afterthe
introduction,wehighlightthecurrentAIagentlandscapeinSection2. InSection3wepresentour
agentworkflowdesignandthedefinitionofcomponents. Section4coversapproachesforutilizing
groupsofAIagents,architectureofsolution,andcommunicationstrategies. Wefocusonexamples
inSection5andconcludewiththelessonslearnedinSection6.
2 ExistingFrameworks
Table1includesalistofexistingagentframeworksorprojectscloselyrelatedtoagentworkflows.
The list is not all-inclusive as the landscape is rapidly growing. Detailed discussions of existing
approachesarecoveredinrecentlypublishedsurveys[23–27].
3 AgentWorkflow
Specialattentionisgiventocreatingaflexiblestructureforagentworkflowswhichcansupportboth
singleandmulti-agentexecution. Theagentworkflowinourimplementationwillfollowthethree
mainstages:
1. Planning-Decompositionoftheinputintosimplelogicalstepswithaclearlydefinedorder
ofoperations.
2. Execution-CompletionoftheworkplannedinStep(1)byagentssolvingsimpletasksand
creatingresults.
2Table 1: Sample of existing approaches to agent and multi-agent frameworks. Our view of their
uniquecontributionsismentionedintheFeaturescolumn. ReferencetoprojectwebsiteandGitHub
repositoryareincludedintheProjectspacescolumnifavailable.
Name Features Projectspaces
AutoGen[7] Multi-agent, flexible commu- ProjectandGitHub
nicationstrategies
AutoGPT Autonomousagents,dynamic ProjectandGitHub
agentcreation,multipleLLMs
LangChain Toolusage,interactionwithex- ProjectandGitHub
istingapplications
LangGraph Multi-agent generalization of ProjectandGitHub
LangChain
LlamaIndex KnowledgeretrievalandRAG ProjectandGitHub
methods
ChatDev[28] Multi-agent,softwaredevelop- ProjectandGitHub
ment,agentdialog
RAISE[29] ReAct-likepromptstrategyfor
multi-agentworkflow
GPT-Engineer Softwaredevelopment GitHub
MetaGPT[30] Multi-agent,softwaredevelop- ProjectandGitHub
ment
DyLAN[8] Agent team optimization, in- GitHub
ferencetimeagentselection
AgentVerse[9] Dynamic agent group selec- ProjectandGitHub
tion
EmbodiedAgents[10] Agent team organization and
communicationpatterns
AgentLite[31] Multi-agent,hierarchicalagent GitHub
orchestration,taskdecomposi-
tion
LLMArena[11] Multi-agent logic game play-
ing
LLMHarmony[12] CAMEL [13] prompt exten- GitHub
siontomanyagents
AgentGPT No-codeagentsetup GitHub
crewAI Multi-agent with sequential ProjectandGitHub
andhierarchicalstrategy
SuperAGI Pausingandresumingagents GitHub
BabyAGI Reference concepts of AI GitHub
agentworkflow
OpenAgents[32] Discussionofrobustnessofim- ProjectandGitHub
plementation,dynamicplugin
selection
HuggingFace Long-memory, multi-agent Project
TransformersAgents collaboration,richecosystem
andactivecommunity
33. Verification-Independentcheckiftheoriginalobjectivehasbeenachievedinstep(2).
Theflow,whichstartswithuser-provided(oringeneral,externally-provided)inputisillustratedin
Figure1.
User Input
Agent Workflow
Agents
Get Task 1 Planner
Unit of
Coordinator 2
Task Queue Executing Agents
Populate
3 Verifier
Workflow 
Output
Figure1:Genericagentworkflowstartingwithuserinputandendingwithprovidingworkflowoutput.
AgentWorkflowhighlightsmajorcomponentsandlevelsoftheworkflowwith(1)Planning,(2)
Execution,and(3)Verificationdonebydedicatedagents.
Forreadability,Figure1includesaunitofexecutingagents,withoutadetailedcompositionofthisunit,
directlyconnectedtoCoordinator. Theabove-mentionednoteabout“externalinput”generalizesto
agentworkflowsthatmaybetriggeredprogrammaticallyasopposedtohumanprovidedinput.
Theindividualcomponentsinvolvedinourgenericagentworkflowmaybedefinedas:
An Agent is an object that makes LLM calls with a specified prompt strategy
inordertoachieveaspecificresult. Agentincludesapersonawhichdefinesits
scopeofknowledgeandactions. Potentially,anAgentcanhaveaccesstoasetof
tools,eachcapableoftakingspecificactions. Anyavailabletoolwillhaveabrief
descriptionalongwithinstructionsfortheinputschemaincludedintheAgent’s
prompt.
AnAgentUnitisacontainerthatholdsoneormoreAgentsthataremeanttowork
togethertosolveatask. TheAgentUnitisresponsibleforselectinganindividual
Agent in each iteration of solving a task. Selection strategies can range from
simplepatternstomoredynamicapproachesusingAI.Withinaworkflow,multiple
Agent Units may be employed to facilitate intricate and specialized patterns of
collaboration.
AMatcherisanabstractionlayerthatisusedtoenablevariousmethodsofselecting
an item based on some criteria. One potential use of a Matcher is selecting an
appropriate Agent Unit for a given task. Matching can happen through simple
methodssuchaslistiterationorthroughmoreadvancedmethodsinvolvingAI.
TheExecutoristhecomponentwhichorchestratesallAgentrelevantoperations
throughinteractionswithanAgentUnit. Itisalsoresponsibleforbringinginfor-
mationrelatedtothecurrentrunningtasktotheAgentintheUnit.
4ToolsareexternalfunctionsthataremadeavailabletoanAgenttocompleteatask.
Thiscanincludeaccesstodatabases,filesystems,andAPIs. Together,thesetof
ToolsformtheAgent’sToolbox.
The Toolbox Refiner is responsible for filtering a set of Tools into a relevant
subsetduringtheexecutionofanAgentloop. Thiscanimprovetheaccuracyand
performanceofanAgentbylimitingthenumberofTooloptions.
TheCoordinatororchestratestheagentworkflowandexecutesallcomponents
neededfortheplanning,execution,andverificationofthedataflow.
ThePlannerisaninstanceofanAgentspecializedtodecomposeauserinstruction
intoseveralsimplertasks. Itprovidesasetoftasksandtheirdependenciesina
structuredformat.
TheTaskQueueisacontainerforholdingthetasksthatarecreatedbythePlanner.
Astasksarecompleted, theTaskQueueisresponsibleforpropagatingrelevant
resultsbetweentasks. Itisalsoresponsibleforreleasingtasksforexecutiononce
alloftheirdependencieshavebeenresolved.
TheVerifierisaninstanceofanAgenttaskedwithindependentverificationofthe
agentworkflowresultagainsttheoriginaluserinstructionandtheoverallobjective.
TheoutputfromtheVerifierAgentisabooleanvalueindicatingiftheworkflow
result satisfies the request. If the result is deemed unsatisfactory, the workflow
entersareplanningphasetoimprovetheresult.
ThecoreofanyAgentisanLLM,apromptstrategy,andahistoryofitspastactionsknownasshort
memory,whichwillbedescribedindetailinSection3.4.2. Figure2illustratesthecomponentsthat
makeanAgentobjectandareinvolvedinitsexecution. Althoughthisdiagramdisplaysasingle
agent,thisstructureextendstomultipleagentsthroughtheAgentUnit.
Persona and
Tools
Objective
ToolBox Prompt Strategy
LLM Short Memory
Agent
Agent Unit Agent Unit Agent Unit
Executor
Coordinator
Figure 2: Components contributing to initialization of an Agent. Dashed lines indicate optional
components.
Ourpromptstrategiesareabstractedsothatwecanusebothsimpleanditerativestrategieswithout
modificationtoanAgent. Todemonstratethestandardizationofprompts,inSubsections3.1–3.3we
5willdiscussasampleofnon-iterativeprompts,introducetoolusageandshowthetransitiontothe
iterativeReActpromptstrategy[20],anditsderivatives.
3.1 Non-iterativePromptStrategies
Ourmostbasicpromptstrategyisasimpleone-offLLMcall. Inallofourstrategiesweincludea
templatesystemmessagewithvariablesthatcanbemodified. Thedefaulttemplateincludespersona
andobjectivevariablesandisstoredinaplaintexttemplatefilethatisrenderedwhentheprompting
strategyisinvoked.
Figure3(a)displaysmessagetypesusedinthesimplepromptstrategy. The“system”and“user”
messagesareinputsand“assistant”messagerepresentstheresponsefromtheLLM.Weincludea
post-processingstepthatisresponsibleforparsingtherawmodeloutputbasedonthestrategyand
constructingarevisedassistantmessage. Thisrevisedassistantmessageensuresthattheiterative
promptstrategieshaveconsistentstructurewithinshortmemoryforthefollowingiterationofLLM
calls.
The basic strategy can be sufficient for components of the agent workflow which do not require
iterative processing with an LLM. Two examples of such Agents that can utilize basic strategies
arethePlannerandVerifierAgents. TheseAgentscanhavespecializedtemplatesfortheirunique
objectivesandpost-processingfunctions. Inthefollowingsubsectionswedescribebothcasesin
moredetail.
3.1.1 Planner
Anexamplethatusesthenon-iterativepromptstrategyissimpletaskplanning. Taskdecomposition
is a crucial element within a successful agent workflow. The purpose of the Planner Agent is to
takeintheuser’sinstruction,decomposeitintosimpletasks,andidentifydependenciesbetween
tasksintheformofaDirectedAcyclicGraph(DAG).Thissimple,non-interactivepromptstrategy
makesasingleLLMcallanddoesnotfurtherrefineitstasklist. TheLLMisinstructedtogenerate
aresponseinstructuredJSONformatthatwillbeparsedtoextractalltasksandpopulatetheTask
Queue. Thedataflowofthispromptstrategy,fromuserinstruction,tothetaskDAG,tothefinal
resultisdisplayedinFigure3(b).
Input Input Input
System: Pre-prompt Including Persona
System: Task Decomposition Prompt System: Result Verification Prompt
and Objective
Previous Messages Previous Messages Previous Messages
User: User’s Instruction With Relevant User: User Instruction User: Main Objective and 
Data Included Result of Agent Workflow
Assistant Assistant Assistant
Raw response from the Structured JSON following Step-by-step reasoning whether provided
LLM. the data model of a Task. result is fulfilling the objective together with
boolean answer.
Process Response Process Response Process Response
Result Result Result
Processed Assistant Response Task 1 Task 2 True or False
Task 3 Task 4
Task 5
(a) Basic (b) Planner (c) Verifier
Figure3: Structureof(a)Basicnon-iterativeprompt,anditsvariationsasappliedin(b)Plannerand
(c)Verifieragents.
63.1.2 Verifier
Evenwithaplanningstage,wecannotguaranteethattheagentworkflowwillbesuccessful. Aplan
maynotbecompletedproperlyorthecreatedplanmaynotbesufficientlysimpletobereliable. To
provideasafeguardmechanismforautonomoustaskexecution,weincludeaVerifierAgentwhich
istaskedwithensuringthatthefinalresultsufficientlyaddressestheuser’sinstruction. Figure3(c)
displaysthestructureoftheVerifierAgentpromptwhenemployingthesimplepromptstrategy. The
Agentreasonsthroughtheresultoftheworkflowandreturnsatrue/falsevalue. Topreventbiasinthe
verification,itisdonewithoutknowledgeofthecreatedplanorpartialresultscompletedduringthe
execution.
3.2 Tools
It has been shown that LLMs can generate actions and automate tasks through the use of tools
[33–35]. These early demonstrations have focused on web browsing or robotics but have been
quicklygeneralizedandareincorporatedintothecoherentReActpromptstrategy[20]. Alternative
approacheswithextensivetoolusagehavebeenproposedinGorilla[22]andothers[21,36,37].
Toolusageisacrucialelementofanagentworkflowandourfocusisonscalableandreliableusage.
Inthissection,wediscussourapproachesforensuringarobustinclusionoftoolswithinanagent’s
promptstrategy.
3.2.1 ToolAbstraction
Thepresentationandexecutionoftoolsareimplementedthroughastandardizedinterfacethatenables
uniform agent interactions. In our work, we do not utilize the function calling feature of LLMs
providedbyalimitednumberofAPIs,suchasOpenAIandAnthropic. Rather,wefullyrelyonthe
schemadescriptionforinputandoutputaspartofthesystemprompt. Wedonotimposeanysimple
commoninputschemaforallthetools. Insteadwedefineanexactlistofparametersthatagiventool
requiresaspartoftheprompt. Everytoolinourimplementationisequippedwithafunctionthat
providesitsinputandoutputschema. EachtoolalsoincludesadescriptionthatprovidestheLLM
withtheabilitytoidentifythecapabilitiesandpurposeofatool.
3.2.2 ToolboxRefiner
While LLMs are capable of making an appropriate selection based on criteria, the accuracy can
decreaseasthenumberofoptionsgrowsandlimitthescalabilityofasystem. Consideringtherange
of tasks we wish to automate, the number of tools may be quite large. To maintain accuracy in
theselectionprocess, anagentshouldbepresentedaminimal, relevantsubsetoftoolsduringits
execution.
Ourapproachtakesaphilosophyofprovidinganagentwithawideselectionoftools,andatthesame
timeminimizingtheamountofinformationprovidedinthesystempromptforagiventask. This
reductionofinformationisachievedbyrefiningthesetoftoolsusedbytheagentinagiventask
bymeansofaToolboxRefiner. Thetaskoftherefineristostartwithasetoftoolsand,basedon
somespecificcriteria,returnasubsetthatwillbepresentedtoanagentforusage. Becausetheexact
refiningconditionmaydifferbasedontheworkflow,weutilizedaninterfacefortherefinementof
tools. OursetofimplementationsincludesIdentityRefinerwhichalwaysreturnstheoriginalset,
HierarchicalRefinerwhichtakesadvantageofahierarchywithintoolsthroughatreesearch,and
SemanticRefinerwhichutilizesthesemanticsimilaritybetweentools’descriptionsandtask.
3.3 IterativePromptStrategies
Thenon-iterativepromptsareusefulfortasksthatdonotrequireanyadditionalinformationfrom
external sources to be completed. The main part of any agent workflow, however, will require
interactionwiththeexternalworldthroughtheuseoftools. Theresultofthetoolexecutionwillbe
broughtbackasnewinformationtotheAgentbeforemakinganotherLLMcall. Inthissection,we
discussReActanditsderivativestointroduceiterativepromptstrategies,toolusage,andbringing
resultsbacktotheAgent.
73.3.1 ReActandPlanReAct
TheReActpromptstrategy[20]providesanexcellentexampleofemployinganLLMtoreflectona
giventaskandinteractwithasetofexternalactions. Aftertheinitialinstruction,theReActstrategy
loopsthroughThought,ActionandObservationstages,eachservingaspecificpurpose.TheThought
stageprovidesaplacefortheLLMtoreflectonthegiventaskandnecessarymeasures. IntheAction
stage,theLLMdefinestheselectedtoolandappropriateinputtothistoolinJSONstructure. The
ObservationstagedoesnotoccurinsideofanLLMcall,ratheritisresultofthetoolexecutionwith
specifiedinputandisreturnedtotheLLMintheformofaUsermessage. Afterthis,themodelgoes
backtotheThoughtstage,equippedwithmoreinformationasaresultoftoolexecution,toprepare
forthenextlogicalsteps.
Figure4illustratesthestepsemployedintheiterativestructureoftheReActprompt. Startingwiththe
SystemMessageandaninitialInstructionasthefirstUserMessage,weentertheloopofThought
andActionastheAssistantMessageandObservationasaUserMessage. WemarkUserMessage
andAssistantMessagespacestodenotewhichsectionsofthestrategyaregeneratedbyanLLMand
whichareplaceholdersforprovidingexternalinformation.
Input User Message
System Message Observation
User Message:
Instruction
Tool

Assistant Message
Execution
Planning
Thought
Action
Process Response after

Termination Sequence
Result
Figure4:GenericReActpromptstrategywithThought,ActionandObservationsteps.Wedistinguish
stepsdoneasmodelresponses(AssistantMessage)andasauser(includingObservationasUser
Message). PlanReActincludesanadditionalPlanningstepmarkedinorange.
IntheSystemMessage,wedescribehowthemodelshouldrespondiftheiterativesequencehas
endedandthefinalresultisready.Inthiscasethemodelisinstructedtogenerateadefinedtermination
sequenceaspartoftheresponseinsteadofnewaction. Ateveryiterationwewillprogrammatically
checkifthisterminationsequenceispresentandiffound,breaktheexecutionloop.Thefinalresponse
isthecontentaftertheterminationsequence.
WealsoimplementedaspecializedversionoftheReActpromptstrategythatexplicitlyincludesa
planningstepaspartoftheiterativesequence. ThePlanReAct[38]strategydiffersfromtheoriginal
ReActbyanadditionalstepresponsibleforcreatinganexplicitplanandreplanningateverystep.
ThispromptingstrategyisnotmeanttoreplacethePlannerAgent,butratherworksintandemby
providinganadditionalleveloftaskdecompositionincasetheoriginaltaskisstilltoocomplex.
83.3.2 ProgrammablePrompt
WegeneralizedtheReActandPlanReActstrategiesbyintroducingaconfigurablepromptingstrategy
knownasaProgrammablePrompt. Theconfigurationwillincludeaniterativesequenceconsistingof
predefinedstepsA...XwhereeachletterrepresentsastagethattheLLMshouldtakee.g.Thought,
Action, Observation for ReAct or Plan, Thought, Action, Observation for PlanReAct. This
generalizedpromptingstrategyisdisplayedonthediagraminFigure5.
Input User Message
System Message Observation
or
User Message:
Instruction Continue
Assistant Message
Description of
 Optional Tool

A
Steps A ... X Execution
B
...
X
Process Response after

Termination Sequence
Result
Figure5: GenericiterativepromptstrategywithuserdefinedstepsA...Xthatconstitutetheiteration
sequence. TheAssistantMessageandUserMessageshowthecombinationofreasoningstepsbythe
LLMandinclusionofexternalinformation.
TheintentionofthisProgrammablePromptstrategy,throughtheuseofaconfigurablesequence,isto
enabletheemploymentofdifferentdecisionmakingstrategies. Thesestrategiesmaymimichuman
decisionmakingstrategiessuchasObserve,Orient,Decide,Act(OODA)2,Plan,Do,Check,Act
(PDCA)3,orsimilarderivativesandanalogues.
3.4 DataPropagationandMemoryLevels
Inordertohaveafullpictureofhowtheinitialinstructionissolved,weneedtoconsiderhowthe
instructionisdecomposedintosimplertasksandhowinformationpropagatesthroughtheworkflow.
Inthefollowingsubsectionsweconsideranexampleplanandtracethedataneededtosuccessfully
completealltasks. Wewillintroducetypesoftaskdependenciesandthemethodologytohandle
them. Wealsodiscusshowweemploymemoryconcepts[39–42]anddistinguishtheroleandscope
ofshortandepisodicmemory.
The sequence diagram in Figure 6 illustrates the order of operations in the Plan-Execute-Verify
modelintroducedbeforeinSection3. Wedisplaymajorelementsoftheworkflowstartingwiththe
Instruction passed from the user to the Coordinator which orchestrates the entire workflow and
providesthefinalresultbacktotheuser.
2https://en.wikipedia.org/wiki/OODA_loop
3https://en.wikipedia.org/wiki/PDCA
9Instruction
Coordinator
USER
Matcher Agent Unit Task Queue Planner Verifier
Create Plan
Return Tasks Task decomposition
Populate Task Queue
loop Request
Unblocked Task
Task
Match Task to
Agent Unit
Unit Choice
Task
Solve Task
Updated Task
with Results
Update
Update Task and 
Relevant Information of Child Tasks
Check Final Result
Verify Final Result
Against Instruction
and Objective
True / False
Matcher Agent Unit Task Queue Planner Verifier
Final result
Coordinator
USER
Figure6:Sequencediagramofoperationsinagenericagentworkflow. Wedisplaymajorcomponents
asverticalthreadsandtypeofoperationsbetweenthemasanhorizontalarrow. Threedistinctblocks
correspondingtoPlanning(top),Execution(middle),andVerification(bottom)aredisplayedonthe
diagram. Forsimplicity,wedonotdepictthereplanningandre-executionthatwouldoccurifthe
Verifierreturnsfalse.
3.4.1 TaskDependencies
ThePlannerAgent’sgoalistodecomposetheinitialinstructionintoasetofsimplertasksthatareheld
intheTaskQueue. Inourimplementation,theTaskobjectcarriesinformationaboutitsdependencies
andresultsofthosedependenciesastheyarecompleted. ThisapproachissimilartotheGraphof
ThoughtsmethodbyBestaetal. [2].
InFigure7(a)anexampleplanisdisplayed,startingwithauser’sInstructionleadingtotheResult.
The initial instruction is decomposed into a set of tasks depicted as a DAG. Task dependencies
aregeneratedbythePlannerduringtaskdecomposition. Directdependenciesareillustratedforan
exampletask8,whichdependsontasks6and7. Resultsoftasks6and7aremadeavailabletoan
agentwhensolvingtask8.
However,wemaydefineanindirectdependencyasaresultofanyprecedingtasksintheplanthat
arenotdirectlyconnectedinthegraphtothecurrenttask. Thisindirectdependencyisdisplayed
on the diagram in Figure 7(b) for the task 7 as a result of the task 1. Task 1 has been chosen as
randomonefromthecurrentplanthatisnotdirectlyconnectedandprecedesthetask7. Weneeda
specialmechanismofincludingtheresultsofindirectdependenciesforacurrenttask. Thismaybe
accomplishedbysemanticsimilarityofthepreviousresults(and/ortaskdescription)tothedescription
10
GNINNALP
NOITUCEXE
NOITACIFIREVDirect Dependency
1
4 7
Instruction 2 8 Result
6
3 5
(a) Directdependency
Indirect Dependency
1 7
4
Instruction 2 8 Result
6
3 5
(b) Indirectdependency
Figure7: DiagramshowingaplandisplayedasaDAG.(a)Rectanglemarksanexampletask8with
directdependenciesas6and7. (b)Rectanglemarksanexampletask7andtask1whichisnota
directdependencybutisinthepathoftheexecutionleadingtotask7.
of the task at hand. In Subsection 3.4.3, we introduce the concept of an Episodic Memory that
providesasolutionforcarryingoverindirectdependenciesthroughthecurrentplan.
Theexecutionofeachtaskisanindependentactionandnoinformation,otherthantheresultsof
directdependencies,areprovidedtoanagent. Inourimplementationalltasksthatarereadytobe
executed,(alloftheirdependencieshavebeencompleted)arecompletedasynchronously.
3.4.2 ShortMemory
Dependingontheemployedpromptingstrategy,wemayinvokeasinglecalltoanLLM(non-iterative
prompt)orseveralcalls(iterativeprompts). Tomanageiterativeprompts,weintroduceahistoryof
User(U)andAssistant(A)exchangesasShortMemory(SM)whereeachgeneratedmessageis
storedintheorderofcreation. TheSMoperateswithintheconfinesofasingletask,remainsisolated
toeachagent,andispurgedupontaskcompletion. Thismeansthateachagent’sSMonlycontains
messagesthatweregeneratedforthatagent. Optionally,wecanenforceamaximummemorylength
bydroppingoldestmessagesafterthecapacityofthememoryisexceeded.
Figure8showsthesequenceofmessagesintheordertheyarecreated. Thesquarewithellipses
markstherepeatedpatternU->AdenotingUser(U)andAssistant(A)typemessages. TheSMscope
ismarkedwithagreyrectangle.
3.4.3 EpisodicMemory
Inourimplementation,EpisodicMemory(EM)isacontainerthatkeepsrecordsofcompletedtasks
acrossapplications. Thiscontainerisavectordatabasetoenablesemanticretrieval. Interactions
11Short Memory
U: Task Description A ... U A: Task Result
Figure8: Sequenceofmessagesfromthetaskdescriptiontothetaskresultincludingallintermediate
messages. RectanglemarkstheelementscontributingtotheShortMemoryofanagent. Messages
aremarkedinorderofuserinputsUandLLMresponsesA(assistant).
Episodic Episodic
U: Task Description A ... U A: Task Result
Figure9: Sequenceofmessagesfromthetaskdescriptiontothetaskresultincludingallintermediate
messages.RectanglesmarktheelementscontributingtotheEpisodicMemoryofanagent.Messages
aremarkedinorderofuserinputsUandLLMresponsesA(assistant).
withEMaredoneattheleveloftheExecutor,whichhasaccesstoataskobjectfortheentiretyof
itsexecutioncycle. Uponcompletionofatask,theExecutorwillpackageanEpisodeconsisting
ofthetask’sdescription,result,anddependencies,inadditiontodescriptionandresultembedding
vectors,andsaveittoEM.Whenhandlingsubsequenttasks,theExecutorcansemanticallysearch
forrelevantEpisodesfromEMandprovidethemtoanagentduringtaskexecution.
EpisodicMemoryattributescanbeconfiguredinseveralwaystosupporttheneedsofthecurrent
workflow. Forexample, EMcanbescopedtoonlyretrieveEpisodesfrompreviouslycompleted
projects or only from indirect dependencies of the current project. Similarly, one can decide to
retrieveonlythesuccessfullycompletedepisodesaswellasotheruser-definedfilters.
InasimilarfashiontotheSMdiagram,wevisualizetheEMcontentofasingletaskonthediagram
inFigure9. ThescopeofEM,however,doesnotendwithcompletionofthetask.
EpisodicMemorybringstwoimportantpoints:
1. IndirectDependencyResults-Inprevioussectionswehavenotedtheneedforbringing
relevantresultsofpreviouslycompletedtasksfromthecurrentplan. EMprovidesasolution
tobringsemanticallyrelevantresultsfromallpreviouslycompletedtasks.
2. ExperientialLearning-Wecanexpandsearchestoallpreviouslycompletedtasks,bringing
resultsthataresemanticallyrelevantfromthelifespanofallapplications. Thiscanenablea
shortenedpathtothefinalresult,reducingexecutiontime[43].
4 Multi-AgentWorkflow
Theneedforreliabilitymotivatesageneralizationofworkflowsfromasingleagenttomultipleagents.
LLMsperformspecializedtasksmorereliablyiftheyareinstructedtoimitatecertainpersonalities
withspecializedexpertise. ThespecificationofexpertiseinthesystempromptofanLLMremoves
any ambiguity when interpreting a given task. This observation holds for simple human driven
interactionsanddirectlytranslatesintoagent-basedapplications. Specifyingthepersonalityofan
agent,withfocusonanarrowdomain,leadstomorereliableperformancethatalignwithhuman
preferences.
Afterdefiningasetofagentstailoredforsolvingaparticulartask,wemayconsiderseveralstrategies
forhowaworkflowmaybeorchestrated. Thechoiceswillindirectlymimichumanworkorganization
forcomplexproblems.
124.1 AgentUnitandAgentMatching
Inthegeneralcaseofmulti-agentworkflowswefacethreeissues,firsttheselectionoftheAgent
Unitforagiventask,secondtheselectionoftheagenttostarttheworkonagiventask,andthird
thedynamicselectionoftheagentthatwillcontinuewithnextiteration. Thecrucialcomponent
for solving these issues has been briefly mentioned in Section 3 as a matching mechanism. The
Matcherisageneralizedcomponentthatperformsselectionusingacriteriadedicatedtotheworkflow
e.g.iterativematching,semanticmatching,ormentionmatching(asdescribedindetailsbelowusing
@notation). AfterthePlannercreatesasetoftasks,weuseamatchingfunctiontodeterminewhich
Agent Unit should solve a given task. Because each Agent Unit consists of one or more agents,
wealsoneedamechanismforselectinganagentforeachiterationofthetaskexecution. Before
executinganiterationoftheagentpromptstrategy,weagaininvokeamatchingfunctiontoselectthe
agentthatwillbeusedforthisiteration.
TheintroductionofanAgentUnitandaMatcherallowsustohaveaflexiblemethodforconsidering
singleandmulti-agentworkflowsusingthesameimplementation. Althoughsingleagentworkflows
couldbeaccomplishedwithoutthesecomponents,theyarecrucialformulti-agentapplications. All
ofthedescribedmulti-agentstrategiesbecomeaparticularcombinationofpromptstrategy,Agent
Unit, andmatchingfunction. Forexample, atwoagentactor/criticworkflowmayberealizedby
introducingaunitoftwoagentsi.e. actorandcritic,andaniterativematchingfunctionthatcycles
throughtheAgentUnit.
InSubsection4.3wewillintroducedynamicselectionofthenextagentbyexplicitlymentioning
itsnameinthecurrentagentresponsewith@AgentNamenotation. Thisnotationgivesanindication
whichagentshouldbeselectednextandamentionmatchingfunctionwillprovidethecorrectagent
fromtheavailableAgentUnit.
4.2 WorkflowswithMultipleAgents
Inthissection,weconsiderfivedifferentstrategiesformulti-agentworkflowsthatareenabledthrough
thecomponentsAgentUnitandMatcherandareapplicabletothePlan-Execute-Verifyfashionof
solvingacomplextask,1)Independent,2)Sequential,3)Joint,4)Hierarchical,and5)Broadcast. In
each,weconsideronlytheExecutepartoftheworkflowandassumethattheCoordinatorissolving
asetoftasksorganizedasaDAG.AllstrategiesareillustratedwithanexampleinFigures10,11,
and12.
4.2.1 Independent
Inthisstrategy,weconsidertaskstobeexecutablebyasingleagent. Thecoordinatororchestratesthe
solutiontoasetoftasksorganizedinaDAGusinganAgentUnitcomposedofseveralagents,each
withadistinctpurpose. Ifthesetoftasksissufficientlysimpleandmatchesthenarrowexpertiseofa
singleagentfromtheunit,wemayassumethatthisagentwillbeabletosolvethegiventask.
WithinanAgentUnit,ataskwillbeassignedtoasingleagentusingsomematchinglogicwhichwas
detailedintheprevioussection. Eachtaskwillbeexecutedbyasingleagentinisolationofother
agentsandnointer-agentcommunicationwilltakeplaceduringthetaskexecution. However,the
agentsmaystillhaveaccesstotheresultsofothercompletedtasksbasedonthedirectandindirect
resultspropagation,byeitherexplicitpassageofresultsasdirectdependencyorusageofEM.
Figure10illustratestheIndependentmodelonpanel(1)withanexampleofagraphwithseven
tasksandthreeagents. Dependenciesoftasksarenotdisplayedastaskswillonlybeexecutedwhen
alldependenciesaresolved.
4.2.2 Sequential
Inmanycircumstances,wemayconsideraworkflowthatrequiresconsecutivestepswhereseveral
distinctagentswouldperformbetterthanasingleone. Anexampleofthismaybestudent/teacher
workflow where one agent performs the task and the second provides constructive feedback and
suggestions. We may generalize this example to include more than two agents and a workflow
consistingofmorethantwoconsecutivesteps.
13TheSequentialstrategyconsidersasingletaskwhichisexecutedbyanAgentUnitconsistingoftwo
ormoreagents. Thisexecutionwillbeperformedinasequenceofconsecutivestepswhereeachmay
bedonebyadifferentagent. Thestudent/teacherexamplewouldcorrespondtoaunitoftwoagents
withalternatingorder. TheSequentialstrategyimposesapredefinedsequenceofagentsratherthan
anautonomousdecisiononwhichagenttopasstonext.
InFigure10panel(2),weillustrateaTaskXbeingsolvedbytheunitofthreeagentsinthepredefined
orderof[Agent1,Agent2,Agent3,Agent2,Agent1]. Asinglestepiscompletedbyagivenagent
bygeneratinganLLMresponse. Thefollowingiterationiscompletedbythenextagentfromthe
AgentUnitbasedonthesequenceimposedbythematchingstrategy.
(2) Sequential
Task
Execution Sequence 
[Agent 1, Agent 2, Agent 3, Agent 2, Agent 1]
(1) Independent
Agent 1

Task #1, #4, #5 Task #2, #3 Task #6, #7 Start Agent
a d
Agent 1 Agent 2 Agent 3
Agent 2
Final Final Final
b
Task Result Task Result Task Result c
Agent 3
Task Result
Figure10: Multi-agentstrategies. (1)Independentwithindividualtasks(numberedfrom#1to#7)
amongthreeagentsnamedAgent1,Agent2,andAgent3. Eachtaskisconsideredtobecompleted
byasingleagentwithnocommunicationduringthetaskexecution. Resultsofagentworkareonly
sharedthroughthedirectandindirectdependenciesandresultspropagation. (2)Sequentialwitha
singletaskexecutedbyaunitofagentsconsistingofAgent1,Agent2,andAgent3withaspecific
sequenceofexecution. Inthedisplayedexamplethesequenceofexecutionis[Agent1,Agent2,
Agent3, Agent2, Agent1]. ThetaskexecutionstartswithAgent1andafteritcompleteswork,
Agent2startswiththepartialresultofAgent1.
4.2.3 Joint
TheJointpatternresemblesthecollaborationbetweenagroupofpeers. Inthispattern,allagents
haveknowledgeofallotheragentsandareallowedtotriggerthefinalresultofaworkflow. The
executionofataskbeginswithapredefinedagent. However,ineachiterationofthepromptstrategy,
anagentsolvesacomponentofthetaskandthendecideswhethertopasstheexecutionortriggerthe
finalresult. Ifexecutionispassed,thecurrentagentwillselectthefollowingagentfromallagents
available(includingitself). Inthiswayeveryagentcancommunicatewitheveryotheragentwithout
aprescribedorder.
InFigure11,weillustratetheJointworkflow. TheexampleshowshowTaskXcanbesolvedbyan
autonomousteam. TheexampletaskisstartedbyAgent1whichhasbeendeterminedtobethemost
relevantagenttostartworkingonthistask. Inthenextiteration,Agent1willdecidewhichagent
shouldtakeover. Thismayincludeself-selection. Inourexample,Agent3terminatesandprovides
thefinalresult.
144.2.4 Hierarchical
TheHierarchicalstrategymimicsamanager/workerpatternwhereaparticularagentisincharge.
Onlythisagentmaydistributetheworkbutitisalsoallowedtocompletepartsofitbyitself. We
definealeadagentforagiventaskthatinitiallyreceivesthetaskandisawareofallotheragentsin
theunit. TheleadagentisresponsibleforsolvingthetaskwiththeaidofotheragentsintheAgent
Unitbypassingtheexecutiontoanotheragentforoneormorestepsoftheoriginaltask. Non-lead
agentsareonlyinformedabouttheexistenceoftheleadagentandarenotallowedtotriggerthe
completionofatask. Therefore,anynon-leadagentintheunitmayonlyreporttheresultsoftheir
workbacktotheleadagent.
InFigure11wedisplayanexampleworkflowwhereaunitofthreeagentsisworkingonTaskX.
Agent1isselectedastheleadagentandpassestheexecutionoftaskcomponentstoAgents2and3.
Inthisprocess,thetargetagentsareautonomouslydecidedbyAgent1. Theresultsofeachtaskstep
arepassedbacktoAgent1,whichdecideswhentotriggerthecompletionofthefulltask.
(3) Joint Task
Agent 1

Start Agent
(4) Hierarchical
Task
a d
Agent 1

Lead Agent
c
Component 
Agent 2
of Task Result Component  Final
e of Task Result
b
Agent 2 Agent 3 Task Result
Agent 3
Final
Task Result
Figure11: Multi-agentstrategies. (3)JointwithTaskXbeingexecutedbyanAgentUnitconsisting
of three agents named Agent 1, Agent 2, and Agent 3. Agent 1 is selected as the starting agent.
All agents in the unit are allowed to communicate with each other and each agent is allowed to
endtheworkflowwhencomplete. InbothHierarchicalandJointcases,thenextagentisselected
dynamicallyandnofixedsequenceofexecutionisimposed. (4)HierarchicalwithTaskXbeing
executedbyanAgentUnitconsistingofthreeagentsnamedAgent1,Agent2,andAgent3. Agent1
istheleadagentinthisunitandisawareoftheothertwoagents. Agent1isalsotheonlyonethatis
allowedtoterminatetheworkflowandprovidethefinalresult. Agent2andAgent3cancommunicate
onlywithAgent1andarenotallowedtoterminate.
4.2.5 Broadcast
TheBroadcastmethodisaderivativeoftheHierarchicalapproach. Themaindifferenceisthatthe
leadagentcarriesindividualconversationswithallotheragentsbybroadcastingthesamemessage
to the whole Agent Unit. Non-lead agents are not aware of the existence of others and operate
independently,providingindividualresponsesbacktotheleadagent. Theleadagentwaitsforall
responsestoproceedwiththenextiteration. Atthefollowingiterations,theleadagentmaybroadcast
anothermessageorterminatewithafinalresult. AsillustratedinFigure12,onlytheleadagenthas
fullinformationaboutallresponsesandcanseethefullgroupconversation. Allnon-leadagents
carryindependentconversations.
15(5) Broadcast
Task
Agent 1

Lead Agent
Message to All Agents
Agent 2 Agent 3
Response Response
Agent 2 Agent 3 Final
Task Result
Figure 12: Multi-agent strategies. (5) The Broadcast method is similar with the Hierarchical
approachwiththedifferencethattheleadagentbroadcaststhesamemessagetoallotheragentsin
theunitandthoserespondindependentlytotheleadagent. Inthisexample,Agent1isawareofall
otheragentsandsolicitstheresponsefromalloftheminthesamefashion.
4.3 ConversationalPromptStrategy
LLMs,andinparticulartheirchatoptimizedversions,areinherentlydesignedtofollowpairwise
interactions. Thispairwiseinteractionhasbeengeneralizedtoenableautomatedinteractionwiththe
externalworldusingpromptstrategieslikeReAct[20]thatincludesAction/Observationpairs. While
ReActandPlanReActenableinteractionwithexternalfunctions,theydonotenableanydialogatthe
ActionandPlanningstepssuchasthetechniquesproposedtoenablemulti-agentdialog[12–15,29].
Toaddressthisissue,weemployastrategythataimstogeneralizePlanReActpromptingandenable
a dynamic dialog between many agents, illustrated in Figure 13. We select an iterative method
thatbuildsonReActforafewreasons. First,theReActloopprovidesastableexecutionpattern
thatisreliablyfollowedbyLLMsinconsecutiveiterations. Second,itenablesthenaturalformof
Action/Observationandtheabilitytoexecuteexternalfunctions. Third, theiterativesequenceis
resilienttosmalldeviationssuchasmissingnewdataintheObservationstageorusing“Continue”
statementsinsteadofprovidingadditionalinformation. Fourth,generalizationofReActtoPlanReAct
makesitcapabletoworkonmorecomplextaskswithlongerexecutionsequences. Tofurtherextend
capabilitiestoincludedialog,weintroducethefollowingchanges:
• TheThoughtstageissplitintotwosub-stagesseparatingthereflectionsrelatedtoTaskand
Dialog. WeintroducetheTaskThoughtstagethatencouragestheagenttoreflectonthe
currenttaskandthenextsteptosolveit,andtheDialogThoughtstagewheretheagent
canreflectonhowtobestutilizeotheragentsforsolvingthecurrentproblem. Information
aboutotheravailableagentsisprovidedtotheagentaspartofthesystemprompt,insimilar
syntaxtotheonementionedbeforefortoolusageinSection3.2.
• APlanningstageisincluded,andthenextstepstosolvethecurrenttaskarereviewedand
re-plannedineveryiteration.
• TheNextstageisaddedtotheiterativesequencetoindicatewhichagentfromtheavailable
AgentUnitshouldcontinuesolvingthecurrenttask. WeinstructtheLLMtouse@Selfif
thecurrentagentisbestchoice,orindicatethenameofanotheragentusingthenotation
@OtherAgent.
• TheActionstageisonlyincludedifthenextagentis@Self.
16Input User Message
System Message Observation
or
User Message:
Instruction Continue
Assistant Message
Planning
Optional Tool

Task Thought Execution
Dialog Thought
Next
@Self @OtherAgent
Action Message to
@OtherAgent
Process Response after

@OtherAgent
Termination Sequence
OtherAgent: Start Iterative
Result
Sequence
Figure13: IterativesequenceofConvPlanReActpromptingstrategy. TheReActandPlanReAct
strategies are generalized to include additional steps related to dialog with another agents. The
ThoughtstageissplitintoTaskThoughtandDialogThoughtstages. TheNextstageisintroduced
forindicatingwhichagentshouldcontinuewiththeexecutionofthecurrenttaskusing@AgentName
notation.
4.4 HumanFeedback
Inmulti-agentstrategiesweneedtoconsideramethodforincludinghumanfeedbacktoagentswhile
taskexecutionisinprogress. Weconsidertwotypesofhumanfeedbackfromtheperspectiveofthe
autonomousagentswork:
• Intentional-TheAgentUnitmayincludeaHumanProxyagentthatisresponsiblefor
passingarequestfromtheagentstoahumanproxywhileworkingonatask. Fromthe
agent’sperspectivethisisnodifferentthanpassingtheexecutiontoanotheragentinthe
AgentUnit. Thecurrentagentmaydecidetorequestadditionalinformationandpassthe
requesttoaHumanProxybymentioning@HumanProxyinthegeneratedresponse.However,
fromtheprogrammaticview,thisrequiresconsiderationofthehumanresponsetimeanda
potentialpauseoftheAgentUnitexecution.
• Incidental-Whiletheexplicitrequestforfeedbackishandledinthepromptstrategyby
including a HumanProxy agent, there may be occasions when a human monitoring the
workflowdecidesthattheworkflowexecutiondeviatesfromthedesiredoutcome. There
needstobeadifferentmechanismforprovidingthisinsitufeedbacktotheexecutingagent
as an unsolicited message from the HumanProxy agent. The prompt strategy does not
haveanaturalplacetobringsuchaninteractionotherthantheObservationstage. Atthat
stagewemaybringadditionalinformationabouttheexternalworldtotheagentsuchas
theresultoftherequestedaction. However,thepromptstrategyisresilienttodeviations
fromtheassumedflow. Forexample,thestrategycanincludethephraseContinueasthe
observationwhichleadstoacontinuationofthesequence’snextstage.Theincidentalhuman
feedbackmaybebroughttotheagentintheinsitufashionasoneoftheobservationsand
theadditionalinformationwillbeavailableatthenextiterationofthecurrenttaskexecution.
175 ExampleApplications
Todemonstratetheflexibilityofourapproach,wehighlightthreedifferentexampleapplicationsand
howeachcanbeachievedusingthecomponentsdescribedinprevioussections. Wewillstartwitha
Question&Answerworkflowcapableofansweringcomplexmultipartquestions. Thisworkflowis
basedonasingleagentutilizingasemanticsearchtool. Second,wewilldescribeadocumentediting
workflow with two agents in an actor/critic iterative mode. Third, we will show how a software
developmentworkflowmaybeorganizedutilizingthreeagentseachusingdifferenttoolstointeract
withexternalsystems.
Inthediagramsusedinthefollowingsections,weusesolidlinestoshowprogrammaticallyimposed
flowsanddashedlinestodisplayoptionalflowsthataredecidedbytheagents.
5.1 Question&Answer-RetrievalAugmentedGeneration
RetrievalAugmentedGeneration(RAG)systemshaveprovedtobeapromisingsolutiontobring
additionalinformationtoanLLM.RAGmethodsareparticularlybeneficialtoindustrialapplications
astheyprovideasolutionforinternalknowledgewithouttheneedtofine-tuneorretrainanLLM.
Thisensuresthatthemodelmayalwaysaccessrelevantinformationwithminimalmaintenancefor
productivedeployment.
TherehavebeenmanyRAGalgorithmsproposedtoimproveonthenaiveRAGapproach. Inthis
example,wefocusonanagent-basedrealizationoftheRAGmethodforquestion-answeringsystems.
TheworkflowdisplayedinFigure14isrealizedwithasingleagent,basedoneithertheReActorthe
PlanReActpromptstrategy.
Coordinator
Planner
Question Decomposition
Task Queue
Task 1
Task 3
Task 2
User Input Identity Matching Final Answer
Agent Unit
BMW Assistant Agent
Semantic Search Tool
DB
Verifier
Figure14: AgentworkflowforRetrievalAugmentedGenerationforaQuestion&Answersystem.
Theworkflowengagesasingleagentwithaccesstoasemanticsearchtool. Thisagentexecutesall
tasksfromtheplanthatconsistsofsimplequestionsoriginatingfromthetaskdecompositionofthe
originaluserquestion.
18TheworkflowstartswithauserquestiontotheCoordinatorwhopassesittothePlannerfortask
decomposition,breakingthecomplexquestionintoasetofsimplertaskswithdependencymapping.
The decomposition of the initial user question ensures that complex questions are first reasoned
through and simplified into set of questions that contribute to the final answer. Tasks are then
executedbyasingleagentdenotedasBMWAssistantwhohasaccesstoaSemanticSearchtool
foridentifyingrelevantinformation. However,thistoolboxcanbeextendedwithtoolsforaccessing
otherinternalsystemssuchaswebsitesorenterpriseknowledgemanagementsystems. Thefinal
answeroftheagentisverifiedattheendoftheworkflowbytheVerifieragenttoensurethefinal
responseaddressestheoriginaluserquestion.
5.2 DocumentEditing-Actor/Critic
In this example, we consider document editing via two agents, Editor and Critic, following the
actor/criticexecutionmodel. WedonotutilizeaPlanneragent,insteadweexecuteaplanthathas
beenpredefinedasasetofrulesforeditingthedocument. Thesetofruleswillbeconvertedinto
taskswithalineardependencytobeexecutedoneafteranother. Thedetailedworkflowisdisplayed
inFigure15.
Coordinator
User
Predefined Editing Rules
Task Queue
Task 1
Task 3
Task 2
Sequence Matching
Input Document Final Document
Agent Unit
Critic Editor
Initial Document 
+ Final Version of Document 
+ Set of Editing Rules
Verifier
Figure15: Actor/criticworkflowfordocumenteditingwithtwoagentsanduserdefinededitingrules.
TheAgentUnitalternatesbetweenEditorandCriticagentsviaasequentialmatchingfunction.
WecreateanAgentUnitwithtwoagents,Editortaskedwitheditingthedocumentaccordingtothe
givenrule,andCriticwhichchecksiftherulehasbeenfullyapplied. TheAgentUnitisiteratedwith
theSequenceMatcherwhichchoosesthenextagentbasedonaprovidedsequence,whichinour
caseisEditorandCriticalternating. ThissequenceisrepeateduntiltheCritic’smessageindicates
thattherearenofurthereditsrequired. Thisprocessisrepeatedforthealltasks. Theworkflowends
withtheVerifierreceivingoriginalandfinaldocumenttogetherwiththesetofuserprovidedrulesto
ensureallruleshavebeenfullyappliedtotheoriginaldocument.
195.3 CodingTasks-JointCollaboration
Inthefinalexample,weconsiderasoftwaredevelopmentexample. Thisworkflowstartswiththe
userrequestpassedtothePlannerAgenttocreateasetoftasksthatpopulatestheTaskQueue.
TheAgentUnitconsistsofthreeagentswithdistinctresponsibilities: 1)Coderisresponsiblefor
allsoftwareengineeringtasksusingaFileI/Otool, 2)Architectcreatesthearchitectureforthe
development using a Web Search tool, and 3) Tester is responsible for testing the code using a
CodeExecutiontool. Allagentsareawareoftheexistenceandexpertiseoftheotheragents. The
AgentUnitisiteratedthroughacombinationofthesemanticandmentionmatchingfunctionswhich
selectsthenextagent. SemanticMatcherpicksthemostappropriateagentforagiventask,Mention
Matcherensuresthattheconversationalstrategyisexecutedcorrectlyviamessagepassing. Figure
16illustratestheworkflowforthisexample. Weemploytheconversationalstrategydescribedin
Section4, illustratedwithdashedlinesbetweenallagents. Theagentsworktogethertoproduce
functioningcodethatsatisfiesthecode-relatedtask. TheworkflowendswiththeVerifierAgentthat
checksthefinalresultagainsttheoriginaluserrequest.
Coordinator
Planner
Task Decomposition
Task Queue
Task 1
Task 3
Task 2
Semantic Matching 
Final Set of
User Request + Mention Matching
Files
Agent Unit
File 
File I/O
System
Developer 
Coder Architect Web Search Resources
Kuberbetes 
Tester Code Execution Sandbox
Verifier
Figure16: Basicworkflowforsoftwaredevelopmentwiththreeagentsinaconversationalworkflow.
TheAgentUnitconsistsofCoder,ArchitectandTesterAgentsthatcanengageinadialogwith
eachother. TheAgentUnitisiteratedthroughacombinationoftheSemanticandMentionmatching
functionswiththegoalofselectingthebestagenttostartandthenextagentviaexplicitmessage
passing. EachAgenthasadistincttooltoaccomplishitsresponsibilities.
6 Summary
Inthisreport,wedetailablueprintforamulti-agentengineeringframeworkthataimstoaddress
the gaps in existing agent frameworks that may hinder production scale applications [32]. We
havepresentedthemainconceptsofourmulti-agentengineeringframeworkandprovidedexample
workflowstoillustratetheflexibilityofourapproach.
Toclosethegapbetweenexistingworkandourimplementation,wehaveconsideredthefollowing:
• StableConversationalPromptingStrategy-WehaveintroducedtheConvPlanReActas
anapproachtobringdialogcapabilitytotheReActtypeprompt. Wehighlighttheabilityto
20includeallstagesoftheoriginalapproachaugmentedwithstagesdirectlyrelatingtothe
multi-agentnatureoftaskexecution.
• Tools-Wehighlightscalableandaccurateusageoftoolsbyincorporatingtheconceptof
refiningthetotallistavailableatagivenstep. Therefinementmechanismsiscoupledwith
implicit schema for input and output of the tool providing ability for accurate usage of
underlyingfunctions.
• ExperientialLearning-WeincludetheconceptofEpisodicMemorywithitsdirectusage
duringtaskexecutiontoretrievetheresultsofprevioustasksthatarerelevanttothecurrent
one. Thisretrievalcanbescopedtothecurrentplanaswellasallpreviouslyexecutedplans
intheexistingapplication. Thisenablesagentstohaveaccesstorelevantpreviousworkthat
hasbeencompleted.
• HumanInteraction-Wediscusstheinclusionofbothintentionalandincidentalhuman
feedback provided back to the agents. In that discussion, we give details on how the
additionalfeedbackmaybeprovidedintheproposedConvPlanReactstrategy.
• RestartLimitations-Ourapproachallowsforafullrestartofanyworkflowuptothelast
executedtaskusingtheinformationprovidedintheEpisodicMemory. Wehaveintroduced
afunctionalitythatallowsforresumingtheworkflowsthathavebeenpausedduetoanerror,
aninternaltrigger,oranexternaltrigger.
Ourframeworkaimstoprovideascalableandhighlyconfigurableenvironmentformulti-agentwork-
flows,enablingstableandproductionreadyagentapplications. Wehavegivenspecialconsideration
toimprovingmulti-agentcollaboration,robusttoolimplementations,extendedlearningcapabilities,
incorporatinghumaninteractions,andresumingofworkflows. Thesefunctionalitiesnotonlyenable
higherqualityresults,theyallowustomovebeyondexperimentationintoenterprisesettings.
References
[1] JoonSungPark,JosephC.O’Brien,CarrieJ.Cai,MeredithRingelMorris,PercyLiang,and
Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior, 2023,
2304.03442. URLhttps://arxiv.org/abs/2304.03442.
[2] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas
Gianinazzi,JoannaGajda,TomaszLehmann,HubertNiewiadomski,PiotrNyczyk,andTorsten
Hoefler. Graphofthoughts: Solvingelaborateproblemswithlargelanguagemodels. Proceed-
ingsoftheAAAIConferenceonArtificialIntelligence,38(16):17682–17690,March2024. ISSN
2159-5399. URLhttp://dx.doi.org/10.1609/aaai.v38i16.29720.
[3] BinfengXu,ZhiyuanPeng,BowenLei,SubhabrataMukherjee,YuchenLiu,andDongkuan
Xu. Rewoo: Decouplingreasoningfromobservationsforefficientaugmentedlanguagemodels,
2023,2305.18323. URLhttps://arxiv.org/abs/2305.18323.
[4] JimingLiu,YuanYTang,NingZhong,andPatrickSPWang. AgentEngineering. WORLD
SCIENTIFIC, 2001, https://www.worldscientific.com/doi/pdf/10.1142/4642. URL https:
//www.worldscientific.com/doi/abs/10.1142/4642.
[5] SignificantGravitas. Autogpt. URLhttps://agpt.co.
[6] YoheiNakajima. Babyagi. URLhttps://github.com/yoheinakajima/babyagi.
[7] QingyunWu,GaganBansal,JieyuZhang,YiranWu,BeibinLi,ErkangZhu,LiJiang,Xiaoyun
Zhang,ShaokunZhang,JialeLiu,AhmedHassanAwadallah,RyenWWhite,DougBurger,and
ChiWang. Autogen: Enablingnext-genllmapplicationsviamulti-agentconversation,2023,
2308.08155. URLhttps://arxiv.org/abs/2308.08155.
[8] ZijunLiu, YanzheZhang, PengLi, YangLiu, andDiyiYang. Dynamicllm-agentnetwork:
Anllm-agentcollaborationframeworkwithagentteamoptimization,2023,2310.02170. URL
https://arxiv.org/abs/2310.02170.
21[9] WeizeChen,YushengSu,JingweiZuo,ChengYang,ChenfeiYuan,Chi-MinChan,HeyangYu,
YaxiLu,Yi-HsinHung,ChenQian,YujiaQin,XinCong,RuobingXie,ZhiyuanLiu,Maosong
Sun,andJieZhou. Agentverse: Facilitatingmulti-agentcollaborationandexploringemergent
behaviors,2023,2308.10848. URLhttps://arxiv.org/abs/2308.10848.
[10] XudongGuo,KaixuanHuang,JialeLiu,WenhuiFan,NataliaVélez,QingyunWu,Huazheng
Wang, ThomasL.Griffiths, andMengdiWang. Embodiedllmagents learntocooperatein
organizedteams,2024,2403.12482. URLhttps://arxiv.org/abs/2403.12482.
[11] JunzheChen, XumingHu, ShuodiLiu, ShiyuHuang, Wei-WeiTu, ZhaofengHe, andLijie
Wen. Llmarena: Assessing capabilities of large language models in dynamic multi-agent
environments,2024,2402.16499. URLhttps://arxiv.org/abs/2402.16499.
[12] Sumedh Rasal. Llm harmony: Multi-agent communication for problem solving, 2024,
2401.01312. URLhttps://arxiv.org/abs/2401.01312.
[13] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard
Ghanem.Camel:Communicativeagentsfor"mind"explorationoflargelanguagemodelsociety,
2023,2303.17760. URLhttps://arxiv.org/abs/2303.17760.
[14] ZhenhailongWang,ShaoguangMao,WenshanWu,TaoGe,FuruWei,andHengJi. Unleashing
theemergentcognitivesynergyinlargelanguagemodels: Atask-solvingagentthroughmulti-
personaself-collaboration,2024,2307.05300. URLhttps://arxiv.org/abs/2307.05300.
[15] YaoFu,HaoPeng,TusharKhot,andMirellaLapata. Improvinglanguagemodelnegotiation
with self-play and in-context learning from ai feedback, 2023, 2305.10142. URL https:
//arxiv.org/abs/2305.10142.
[16] JunyouLi,QinZhang,YangbinYu,QiangFu,andDehengYe. Moreagentsisallyouneed,
2024,2402.05120. URLhttps://arxiv.org/abs/2402.05120.
[17] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,BrianIchter,FeiXia,EdChi,
QuocLe,andDennyZhou. Chain-of-thoughtpromptingelicitsreasoninginlargelanguage
models,2023,2201.11903. URLhttps://arxiv.org/abs/2201.11903.
[18] BenfengXu,AnYang,JunyangLin,QuanWang,ChangZhou,YongdongZhang,andZhendong
Mao. Expertprompting: Instructinglargelanguagemodelstobedistinguishedexperts,2023,
2305.14688. URLhttps://arxiv.org/abs/2305.14688.
[19] Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr, and Mario Fritz. Llm-
deliberation: Evaluatingllmswithinteractivemulti-agentnegotiationgames,2023,2309.17234.
URLhttps://arxiv.org/abs/2309.17234.
[20] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuan
Cao. React: Synergizingreasoningandactinginlanguagemodels,2023,2210.03629. URL
https://arxiv.org/abs/2210.03629.
[21] QiaoyuTang,ZiliangDeng,HongyuLin,XianpeiHan,QiaoLiang,BoxiCao,andLeSun.
Toolalpaca: Generalizedtoollearningforlanguagemodelswith3000simulatedcases,2023,
2306.05301. URLhttps://arxiv.org/abs/2306.05301.
[22] ShishirG.Patil,TianjunZhang,XinWang,andJosephE.Gonzalez. Gorilla: Largelanguage
model connected with massive apis, 2023, 2305.15334. URL https://arxiv.org/abs/
2305.15334.
[23] LeiWang,ChenMa,XueyangFeng,ZeyuZhang,HaoYang,JingsenZhang,ZhiyuanChen,
JiakaiTang,XuChen,YankaiLin,WayneXinZhao,ZheweiWei,andJirongWen. Asurveyon
largelanguagemodelbasedautonomousagents. FrontiersofComputerScience,18,2024.
[24] TaichengGuo,XiuyingChen,YaqiWang,RuidiChang,ShichaoPei,NiteshV.Chawla,Olaf
Wiest,andXiangliangZhang. Largelanguagemodelbasedmulti-agents: Asurveyofprogress
andchallenges,2024,2402.01680. URLhttps://arxiv.org/abs/2402.01680.
22[25] TulaMasterman,SandiBesen,MasonSawtell,andAlexChao. Thelandscapeofemergingai
agentarchitecturesforreasoning,planning,andtoolcalling: Asurvey,2024,2404.11584. URL
https://arxiv.org/abs/2404.11584.
[26] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang,
Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong,
Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin,
Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng,
XipengQiu,XuanjingHuang,andTaoGui. Theriseandpotentialoflargelanguagemodel
basedagents: Asurvey,2023,2309.07864. URLhttps://arxiv.org/abs/2309.07864.
[27] HungDu,SrikanthThudumu,RajeshVasa,andKonMouzakis. Asurveyoncontext-aware
multi-agentsystems: Techniques,challengesandfuturedirections,2024,2402.01968. URL
https://arxiv.org/abs/2402.01968.
[28] ChenQian,XinCong,WeiLiu,ChengYang,WeizeChen,YushengSu,YufanDang,Jiahao
Li,JuyuanXu,DahaiLi,ZhiyuanLiu,andMaosongSun. Communicativeagentsforsoftware
development,2023,2307.07924. URLhttps://arxiv.org/abs/2307.07924.
[29] NaLiu, LiangyuChen,XiaoyuTian, WeiZou, KaijiangChen,andMingCui. Fromllmto
conversational agent: A memory enhanced architecture with fine-tuning of large language
models,2024,2401.02777. URLhttps://arxiv.org/abs/2401.02777.
[30] SiruiHong,MingchenZhuge,JonathanChen,XiawuZheng,YuhengCheng,CeyaoZhang,
JinlinWang,ZiliWang,StevenKaShingYau,ZijuanLin,LiyangZhou,ChenyuRan,Lingfeng
Xiao,ChenglinWu,andJürgenSchmidhuber. Metagpt: Metaprogrammingforamulti-agent
collaborativeframework,2023,2308.00352. URLhttps://arxiv.org/abs/2308.00352.
[31] ZhiweiLiu,WeiranYao,JianguoZhang,LiangweiYang,ZuxinLiu,JuntaoTan,PrafullaK.
Choubey, Tian Lan, Jason Wu, Huan Wang, Shelby Heinecke, Caiming Xiong, and Silvio
Savarese. Agentlite: Alightweightlibraryforbuildingandadvancingtask-orientedllmagent
system,2024,2402.15538. URLhttps://arxiv.org/abs/2402.15538.
[32] TianbaoXie,FanZhou,ZhoujunCheng,PengShi,LuoxuanWeng,YitaoLiu,TohJingHua,
JunningZhao,QianLiu,CheLiu,LeoZ.Liu,YihengXu,HongjinSu,DongchanShin,Caiming
Xiong, and Tao Yu. Openagents: An open platform for language agents in the wild, 2023,
2310.10634. URLhttps://arxiv.org/abs/2310.10634.
[33] ReiichiroNakano,JacobHilton,SuchirBalaji,JeffWu,LongOuyang,ChristinaKim,Christo-
pherHesse,ShantanuJain,VineetKosaraju,WilliamSaunders,XuJiang,KarlCobbe,Tyna
Eloundou,GretchenKrueger,KevinButton,MatthewKnight,BenjaminChess,andJohnSchul-
man. Webgpt: Browser-assistedquestion-answeringwithhumanfeedback,2022,2112.09332.
URLhttps://arxiv.org/abs/2112.09332.
[34] MichaelAhn,AnthonyBrohan,NoahBrown,YevgenChebotar,OmarCortes,ByronDavid,
ChelseaFinn,ChuyuanFu,KeerthanaGopalakrishnan,KarolHausman,AlexHerzog,Daniel
Ho,JasmineHsu,JulianIbarz,BrianIchter,AlexIrpan,EricJang,RosarioJaureguiRuano,
KyleJeffrey,SallyJesmonth,NikhilJJoshi,RyanJulian,DmitryKalashnikov,YuhengKuang,
Kuang-HueiLee,SergeyLevine,YaoLu,LindaLuu,CarolinaParada,PeterPastor,Jornell
Quiambao,KanishkaRao,JarekRettinghouse,DiegoReyes,PierreSermanet,NicolasSievers,
ClaytonTan,AlexanderToshev,VincentVanhoucke,FeiXia,TedXiao,PengXu,SichunXu,
Mengyuan Yan, and Andy Zeng. Do as i can, not as i say: Grounding language in robotic
affordances,2022,2204.01691. URLhttps://arxiv.org/abs/2204.01691.
[35] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as
zero-shotplanners: Extractingactionableknowledgeforembodiedagents,2022,2201.07207.
URLhttps://arxiv.org/abs/2201.07207.
[36] SiyuYuan, KaitaoSong, JiangjieChen, XuTan, YongliangShen, RenKan, DongshengLi,
andDeqingYang. Easytool: Enhancingllm-basedagentswithconcisetoolinstruction,2024,
2401.06201. URLhttps://arxiv.org/abs/2401.06201.
23[37] Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo Song, Hailiang
Huang,ChengLi,KeWang,RongYao,YeTian,andSujianLi. Restgpt: Connectinglarge
languagemodelswithreal-worldrestfulapis,2023,2306.06624. URLhttps://arxiv.org/
abs/2306.06624.
[38] ZhiweiLiu,WeiranYao,JianguoZhang,LeXue,ShelbyHeinecke,RitheshMurthy,Yihao
Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang,
CaimingXiong,andSilvioSavarese. Bolaa: Benchmarkingandorchestratingllm-augmented
autonomousagents,2023,2308.05960. URLhttps://arxiv.org/abs/2308.05960.
[39] Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G. Patil, Ion Stoica, and
JosephE.Gonzalez. Memgpt: Towardsllmsasoperatingsystems,2024,2310.08560. URL
https://arxiv.org/abs/2310.08560.
[40] AdyashaMaharana,Dong-HoLee,SergeyTulyakov,MohitBansal,FrancescoBarbieri,and
YuweiFang.Evaluatingverylong-termconversationalmemoryofllmagents,2024,2402.17753.
URLhttps://arxiv.org/abs/2402.17753.
[41] HangGaoandYongfengZhang. Memorysharingforlargelanguagemodelbasedagents,2024,
2404.09982. URLhttps://arxiv.org/abs/2404.09982.
[42] Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, and Furu
Wei. Augmentinglanguagemodelswithlong-termmemory,2023,2306.07174. URLhttps:
//arxiv.org/abs/2306.07174.
[43] ChenQian,YufanDang,JiahaoLi,WeiLiu,ZihaoXie,YifeiWang,WeizeChen,ChengYang,
XinCong,XiaoyinChe,ZhiyuanLiu,andMaosongSun. Experientialco-learningofsoftware-
developingagents,2024,2312.17025. URLhttps://arxiv.org/abs/2312.17025.
24