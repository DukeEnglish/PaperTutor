IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2024 1
Multi-UAVs end-to-end Distributed Trajectory Generation over Point
Cloud Data
Antonio Marino, Claudio Pacchierotti, Paolo Robuffo Giordano
Abstract—Thispaperintroducesanend-to-endtrajectoryplan- Thus, communication emerges as a critical element in realiz-
ning algorithm tailored for multi-UAV systems that generates ing distributed solutions for multi-agent systems. Within this
collision-free trajectories in environments populated with both
context, one of the focuses of this article is to integrate local
static and dynamic obstacles, leveraging point cloud data. Our
sensing and communication strategies to achieve end-to-end
approachconsistsofa2-branchneuralnetworkfedwithsensing
and localization data, able to communicate intermediate learned distributed multi-UAV motion planning.
features among the agents. One network branch crafts an For UAV navigation, learning-based control from point
initialcollision-freetrajectoryestimate,whiletheotherdevisesa clouds or images offers computational advantages [10], [11],
neuralcollisionconstraintforsubsequentoptimization,ensuring
[12]. Recently, distributed learning methods for multi-agent
trajectory continuity and adherence to physical actuation limits.
scenarios have emerged, using reinforcement learning [13],
Extensive simulations in challenging cluttered environments,
involving up to 25 robots and 25% obstacle density, show a [14], [15] and Graph Neural Networks (GNNs) [16], [17].
collision avoidance success rate in the range of 100 − 85%. GNNs, by exploiting the communication graph, excel in en-
Finally,weintroduceasaliencymapcomputationmethodacting coding distributed policies, as demonstrated by Blumenkamp
on the point cloud data, offering qualitative insights into our
et al. [18], who showed multi-robot coordination in narrow
methodology.
passages. However, learning-based control needs additional
Index Terms—distributed control, graph neural network, tra- safety guarantees, as seen in GLAS [19], which uses a
jectory generation
local safety function to ensure stability and safety. Most
results apply to static environments without considering real
robot dynamics. A recent work [20] combines safety control
I. INTRODUCTION
strategies with learning over a graph of agents and obstacles,
Thedomainofmulti-agentUnmannedAerialVehicle(UAV)
using a GNN-based network to predict control estimates and
trajectory planning has garnered significant attention, given
a constraint function for Control Barrier Function (CBF)
its diverse range of applications [1], [2], [3]. In these set-
optimization from LiDAR data.
tings, planning algorithms play a pivotal role in calculating
However, all these methods are susceptible to trapping
trajectories that are both safe and directed towards a defined
robots in local minima as they compute only a local control
goal. These algorithms have to consider the dynamic state
action. To explicitly tackle this problem, a contribution of
of the environment and the presence of neighbouring agents.
this work is to propose a trajectory planning algorithm that
In practical applications involving drones, trajectory planning
takes into account spatio-temporal predictions and can avoid
is crucial to navigate around obstacles and accommodate
trapping the robots in deadlocks. Planning for multi-drone
limitations in the drone’s actuators [4], [5], [6].
coordination inherently poses a high-dimensional challenge,
Despite possessing more theoretical guarantees, centralized
even when safety is the sole requirement. Moreover, planning
approaches are often less appealing than decentralized coun-
algorithms often necessitate access to map data for obstacle
terparts due to their computationally intensive nature and
information, as noted in prior work [21]. This map should
the dependence on full-state information of each robot at
be updated online to tackle environmental changes which
every algorithm iteration which renders them impractical for
in large-scale environments can become cumbersome, bring-
real-world execution [7]. In contrast, decentralized planning
ing a computational bottleneck. Furthermore, optimization-
not only demonstrates enhanced scalability but also provides
based approaches may need to relax collision constraints
robustness against potential failures in a centralized architec-
as team density increases. Potentially, this relaxation leads
ture [8].
to collisions, as discussed in [22] which reports real-time
Formoreeffectivecoordinatedplanning,theplanningalgo-
motion planning for a swarm of up to 20 drones. The recent
rithm must consider not only local sensing data but also the
literature [23], [24], [25], [26] has presented notable results
planning decisions of a few neighbouring team members [9].
for robust multi-drone large-space travelling that take into
account physical size, actuator limitations, alongside track-
Manuscript received: February 26, 2024; Revised: April 23, 2024; Ac-
ing disturbances, communication delay, and asynchronous
cepted:June15,2024.
This paper was recommended for publication by Giuseppe Loianno upon communication. However, these algorithms typically rely on
evaluationoftheAssociateEditorandReviewers’comments. perfect sensing and tracking of obstacles at all times or a
A. Marino is with Univ Rennes, CNRS, Inria, IRISA – Rennes, France.
pre-available obstacle map, which, generally, is unavailable
E-mail:antonio.marino@irisa.fr
C. Pacchierotti and P. Robuffo Giordano are with CNRS, Univ Rennes, in real-world scenarios. Furthermore, these algorithms require
Inria,IRISA–Rennes,France.E-mail:{claudio.pacchierotti,prg}@irisa.fr tuning the map grid size to find collision-free paths and,
This work was supported by the ANR-20-CHIA-0017 project “MULTI-
despite implementing a decentralized approach, each drone
SHARED”
DigitalObjectIdentifier(DOI):seetopofthispage. must communicate with all other drones in the team, which
4202
nuJ
82
]AM.sc[
1v24791.6042:viXra2 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2024
reduces scalability. • physical limitations: The generated trajectory must sat-
In this paper, we present a novel data-driven approach for isfythedrone’svelocityandaccelerationlimitsandmust
distributedtrajectorygenerationandsafetycollisionavoidance be smooth and continuous relative to the actual state.
underLiDAR-basedobservations.Ourmaincontributionsare:
• A decentralized and asynchronous end-to-end trajectory III. METHOD
planning method using attention-based GNNs to learn This section presents the proposed policy as a neural net-
a decentralized policy from point cloud data. Unlike workthatfulfilstheaboverequirements.Westartbypresenting
existing methods requiring prior knowledge of the en- the trajectory encoding used by the proposed approach. Then,
vironment, our approach allows each drone to plan its we present the privileged expert used for training and how
trajectory directly from sensed data. we process the input features. Subsequently, we describe the
• An optimization process that generates collision-free tra- neuralnetworkarchitecturedepictedinFig.1anddeployedon
jectories by predicting collision constraints from point the drone composed of input features processing, communi-
cloud data and inter-drone communication. This method cated variables aggregation and the optimization layer to cope
allowsreal-timeupdatesandadjustments,ensuringhigher withphysicallimitations.Finally,wedescribethealgorithmto
reliabilityandsafetyindynamic,uncertainenvironments. computethesaliencymap,usedtoanalyzetheneuralnetwork
• Leveraging the point cloud saliency map computed by a behaviour in the results.
variation of VisBackProp [27], we propose a qualitative
analysis of the predicted trajectories and how the point
A. Trajectory Representation
cloud contributes to it.
The trajectory used by each drone is a polynomial-based
curve,e.g.,B-Splines,whichallowsustoimposevelocityand
II. PROBLEMSTATEMENT
higher derivatives limitation through linear constraints on the
Consider a distributed trajectory generation problem for trajectory Control Points (CP). In fact, the convex hull of the
a set of UAVs V := {1,...N} modelled at time t in curve CP leads to the representation of the outer trajectory
SE(3) with second-order dynamics. The UAV team operates polyhedronand,byimposingconstraintsontheCP,weensure
within a three-dimensional workspace containing static and they are satisfied throughout the trajectory.
dynamic obstacles O . Each drone’s objective is to navigate In this paper, we adopted a MINVO basis [28] expression
t
the environment toward its target without colliding with other for the curve. MINVO bases are recently introduced in the
agents.Ateammissionisthecollectivetraversingofthespace literature and, compared to B-spline or Bernstein bases, form
such that every drone satisfies its objective. We make the a simplex M enclosing the given polynomial curve with min-
following assumptions imum volume by construction. Hence, these bases lead to less
conservative polyhedron representations. Given a polynomial
Assumption 1. Each drone is controlled via a trajectory- order, we can pass from MINVO to B-Spline CP and vice-
trackingalgorithmandequippedwitha3Drangesensor,such versa by a linear transformation. For these reasons, it is ideal
as a LiDAR, with 360◦ field of view. togenerateandapplyconstraintsonMINVOCPfortrajectory
descriptions. In particular, we define two linear mappings,
Assumption 2. At time t, we assume perfect state estimation,
h (·) and h (·), to pass from MINVO CPs position to their
i.e. the quaternion orientation quat (t) and the triplets of v a
i
velocity and acceleration, respectively.
position r (t), velocity v (t) in world frame are available to
i i
agent i.
B. Privileged Expert
Assumption 3. Each drone can communicate with a limited
number of neighbours at a given frequency without communi- Ourtrajectoryplanneristrainedviaprivilegedlearning[29].
cation loss Specifically, we generate a dataset from an expert controller:
MADER [23]. MADER employs a decentralized and asyn-
The observation data for a drone i is denoted by pc ∈
i chronous approach to generate feasible and safe trajectories,
Rm×3, which includes the relative positions of the m “hit”
leveraginga combinationof pathplanningand QuadraticPro-
points in the scanned environment. The trajectory generated
gramming (QP) optimization. We can consider this algorithm
must comply with the following constraints:
as a privileged expert for two reasons: first, MADER exploits
• collision avoidance: each pair of drones and drone- comprehensive knowledge of the physical dimensions of ob-
obstacle maintains a safety distance of 2d throughout the stacles and drones, as well as the trajectories of both, which
whole trajectory, where d > 0 is the radius of a sphere is a piece of information typically unavailable in real-world
containing the physical body of the agents. scenarios;second,MADERensurestofindfeasibletrajectories
• limited sensing and communication: each agent has only for unlimited time budget available in simulation. The
a limited sensing and communication range radius R. optimizationproposedbyMADERfocusesondeterminingthe
We define the neighbours of agent i as N = {j ∈ separation planes between the drone and potential obstacles
i
V | ∥r −r ∥ ≤ R,j ̸= i}; therefore, the agents can throughout the trajectory, facilitating motion within a safe
i j 2
only sense other agents or obstacles inside a sphere of region.Moreover,thesamereasoningisappliedtotrajectories
radius R originating on the agent. committed by the other drones, leveraging the trajectory outerMARINOetal.:MULTI-UAVSEND-TO-ENDDISTRIBUTEDTRAJECTORYGENERATION 3
Fig.1. neuralnetworkarchitecturedeployedoneachdrone.
simplex as a cluttered area. However, the growth of the data [goal ,v ,a ], and communicate features to compute a
i i i
decision variables is proportional to the number of obstacles trajectory guess vector q∗ (described by MINVO CPs) and a
i
and other drones within the decision horizon. This renders vectorofcollisioncoefficientsg fordronei.Thelatterisused
i
the optimization more difficult to solve within a limited time to define a linear combination of CPs composing q , thereby
i
budget, leading to potential infeasibility and hazardous halts. classifying its safety. Specifically,
However, in simulation where full obstacle information is
Definition III.1. Givenpc:=[pcT ...pcT]T,thejoinedpoint
available and no time constraints are present, we can fully 1 N
clouds from N drones, for drone i, the scalar value gTq is
exploit MADER to generate a dataset of safe trajectories. i i
gTq < 0 if and only if the control points vector q belongs
In our approach, to construct a dataset, we chose MADER i i i
to the safe set S , where S = {q | ∥p −p ∥ > 2d ,p ∈
over centralized alternatives as its features of asynchrony and i i i i j 2 i
M(q ),p ∈pc} and M(q ) is the outer simplex of q .
decentralizationalignwellwiththeobjectivesofourtrajectory i j i i
planner. Moreover, learning over an already decentralised The term gTq can be used as a linear constraint to
i i
expert policy eases the training process. After the training generate a safe trajectory. The collision coefficients g serve
i
process, at execution time, the learned policy does not rely to fortify the learned policies against collisions but also to
on any privileged information and synthesizes the trajectory ensure their applicability and reliability in unseen scenarios
from sensor inputs only. where the expert policy is unavailable or not included in the
dataset. We formulate a QP layer as the final stage within
C. Neural Network Input Features the neural network that optimizes q i to closely align with
the initial guess q∗, while concurrently ensuring adherence to
Every drone i in the team shares the same neural network i
predefined maximum drone velocity (v ) and acceleration
architecture that accepts as input raw point clouds normalized max
(a ) constraints. This combination not only refines trajec-
inaunitarysphereandtransformedintotheworldframeusing max
tory predictions but also strengthens the system’s resilience in
quat .Additionally,theproposedneuralnetworkusesalsothe
i navigating complex environments. The QP formulation is the
current velocity, v , and the current desired acceleration, a ,
i i following:
normalizedbythemaximumvelocityv andthemaximum
max
acceleration a max allowed. We also include the goal location min∥q i−q i∗∥2 2
(goal ) in the drone i frame, projected on the sensing sphere qi
i
s.t.
with radius R if the distance to the goal is greater than R.
x (t )=x
Then, the goal is divided by R to have coordinates in the i 0 i0 (1)
i
range [−1,1]. Drone i can communicate intermediate neural abs(v)≤v max ←−∀v∈h v(q i)
network features with drones in its neighbourhood N i. We abs(a)≤a max ←−∀a∈h a(q i)
enclose the drone initial conditions in x i0 = [0 3,v i,a i] for g iTq i ≤0
a generated trajectory starting from the ego location, 0 =
3
ThepointcloudisprocessedbyaPointNetlayer[30]compris-
[0,0,0]. In the final deployment, we add to the learnt control
ingthreefiltersof64,128,256,respectively.PointNetemploys
pointq thecurrentdronelocationr (t)totrackthetrajectory.
i
sequences of point transformations through a compact trans-
formation network and 1D-CNN with a unitary kernel size to
D. Neural Network Structure
generatespatially-permutationinvariantfeatures.Theoutputof
The neural network consists of two main branches that this layer, m×256 with m points, splits to serve distinct pur-
process the point cloud pc , combine it with localization poseswithinthecollisioncoefficientsbranchandthetrajectory
i4 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2024
generationbranch.Togenerateg ,i.e.,assigningasafetyscore wise learnable encoding and decoding functions, denoted as
i
to trajectories crossing the environment, we require global e (·):RF →RG and d (·):RG →RF, respectively:
θ θ
features extracted from the point cloud. Consequently, the
K
PointNet output is transformed into a 256-dimensional vector H (x)=(cid:88) d ((E ◦A)ke (x))H . (4)
Aed θ θ k
through global max pooling over the features.
k=0
Conversely, within the trajectory generation branch, our ap-
Here, G << F reduces the number of communicated vari-
proach involves further clustering of the point cloud based on
ables, with e and d functions implemented as MLP with
the features learned by PointNet. Clusters prove advantageous θ θ
ReLU activation functions. The resulting GNNed layer,
in classifying spatial regions that hold crucial information
for trajectory generation. Clustering was already adopted in x=ReLU(H (x)) (5)
Aed
the design of PointNet++, which consists of spatial cluster-
ization coupled with smaller PointNet modules. We adopted is employed 3 times in the trajectory generation branch (with
DMoN[31],aclusteringmethodologybasedonagraphneural filter dimensions 512,256,30) and twice in the collision
network, approximating spectral modularity maximization to branch (with filter dimensions 512,256), totalling L = 5
recoverhigh-qualityfeaturesandspatial-basedclusters.Unlike layers. Set parameters include K =1 and G=5. We can use
PointNet++, DMoN’s approach does not solely rely on spatial the unit-delay communication model [32] and communicate
displacement and does not require a nested architecture of unit-time delayed signals to compute the graph filters in (4)
PointNets. The adjacency matrix required by DMoN is repre- in one shot, by sending [x i(t),...,AK i −1x(t−K−1)] for
sentedasabinarysparsemapencodingthespatialproximityof each agent. This model allows releasing a new output at each
the points. This strategic combination of PointNet and DMoN communication iteration but at the cost of more communi-
very well captures intricate spatial structures for trajectory cated variables. Therefore, each drone communicates LGK
generationtasks,asweshowintheresultsofSec.V.Wechose variables, i.e. 25 in our implementation.
a number of clusters (51) that, together with the localization
data, form a 64-dimensional vector for the next layer. E. Point Cloud Saliency Map
Both branches exchange the local features with the neigh-
A saliency or attention map, denoted as s = [0,1]m,
bouringagentsusingamessage-awaregraphattentionnetwork
serves as a feature map unveiling the relevance of input data
(MAGAT)[16].Assumingthateachdroneicancommunicate
in the decision-making process. This map is instrumental
withitssetofneighboursN ,thecommunicationgraphcanbe
i in inspecting and interpreting neural networks, particularly
represented by a binary sparse matrix A. We let A∈RN×N
under distribution shifts. Existing studies on point cloud
be the adjacency matrix of the communication graph. Given a
saliencymaps[33],[34]predominantlyrelyongradient-based
graph signal x ∈ RN×F distributed over the drones, we can
methods or incorporate additional neural network modules.
define a graph filter as
As highlighted by the authors of VisBackProp [27], for au-
K tonomousnavigation,itisconvenienttodisposeofagradient-
(cid:88)
H (x)= AkxH . (2) free method that can be evaluated online. Addressing this
A k
k=0 gap, we applied the same reasoning of VisBackProp to the
PointNet layer in our architecture, proposing a variation of
which combines the elements of x over the adjacency matrix
VisBackProp that can handle point cloud. We focus on the
of the communication graph and applies the graph filter
PointNet layer in our architecture, as it processes the point
weights H ∈ RF×F′. The quantity K ≥ 1 represents the
k cloud and is dynamically shaped during training to enhance
filter length, which implies repeated 1-hop communications
the representation of points for trajectory generation. The 1D-
over the graph. Therefore, the filter can be executed distribu-
CNNs composing the PointNet draw a direct parallelism with
tivelyoverthegraph.Thefilterineq.(2)transformsthegraph
VisBackPropthatisappliedto2D-CNNs.ForaPointNetmade
signalfromanF-featuresspaceintoasignalofanF′-features
of P sequences of feature transformations and 1D-CNN, we
space. MAGAT enhances this framework by incorporating an savetheaveragemaph¯ computedoverthefeaturesgenerated
attentionmechanismtoweightherelativeimportanceofdrone aftereachsequence.Stai rtingfromh¯ ,weloopoverthelistof
features. Specifically: h¯ bymultiplyingtheactualelementP withpreviouselementof
i
K the list and normalize between [0,1] after each multiplication.
H AE(x)=(cid:88) (E◦A)kxH k. The algorithm is summarized in Algorithm 1.
k=0 (3)
exp(LeakyReLU(xTWx ))
E = i j IV. TRAINING
ij (cid:80) exp(LeakyReLU(xTWx ))
k∈Ni i k Our model training dataset D encompasses UAV around
where E is the matrix of attention weights. Considering the 16k trajectories under the control of the expert controller
need to communicate graph signals over the network, the size within a simulated environment. The simulation environment
of F affects network congestion. To address this, we extend incorporates a 10% obstacle density organized in a forest-like
the scheme by introducing an encoding-decoding mechanism setting and confined within a sphere of 10m radius centred
tocompressthegraphsignalbeforecommunicationandrecon- in the world origin. The obstacles are partitioned equally
struct its original dimension afterwards. This involves point- into static and dynamic elements, with the dynamic obstaclesMARINOetal.:MULTI-UAVSEND-TO-ENDDISTRIBUTEDTRAJECTORYGENERATION 5
Algorithm 1 PointBackProp
Require: point cloud (pt∈Rm×3), PointNet
h ,h ,...,h ←gettheP intermediatefeaturescomputed
1 2 P
by PointNet
h¯ ,h¯ ,...,h¯ ← compute average of the features
1 2 P
s:=h¯ ▷ saliency map s=[0,1]m
P
for i = P-1 ... 1 do
s:=h¯ · s
i
Normalize s between {0,1}
end for
Fig. 2. Experimental environments: dynamic corridor (right) and dynamic
compose point cloud values {s,pt}
forest(left).
Algorithm 2 Training Algorithm In addition, we generate 560k random trajectories qˆ offline,
Require: D batch size b originatingfromtheinitialrobotlocation,andcategorizethem
for point cloud in D do as successful or unsuccessful based on definition III.1 within
Combine point clouds of the N drones thejointpointcloudspace,i.e.successfulifthetrajectorydoes
Generate random trajectories qˆ not collide with obstacles or agent. Moreover, we introduce
Solve QP to constraint qˆwith the initial conditions and a diminishing safety distance d along the trajectory, ranging
physical limitations from the drone’s actual size at the trajectory’s initiation to
add qˆto S i according to the Definition III.1 0 at its termination. This approach optimizes the safe set by
Append trajectories and collision indexes to the dataset progressively reducing conservatism, thereby prioritizing the
Dˆ ←Dˆ∪{qˆ}
safety of the trajectory’s initial location:
end for
(cid:88) 1
calculate adjacency matrix of drones A ▷ This step is only L q = 30||q i−q i∗||2 2 q i ∈D, (6)
needed in centralized training i∈V
calculate adjacency of point clouds A pt L =(cid:88) (cid:88) [gTqˆ]+ (cid:88) [−gTqˆ]+, (7)
for i=1... epochs do g i i i i
collect b batches {pt,v,a,quat,goal,q}←D i∈V qˆi∈Si qˆi∈/Si
compute q∗,g ← model where [·]+ = Softplus(·) stands for a continuous ReLU
if i>epochs then function ensuring strict constraint satisfaction. We split the
i
prepare QP in eq (1) with constraint gTq∗<0 datasetintotraining,validation,andtestingatratiosof0.6,0.3,
Solve QP →− q and 0.1 respectively. We solve the imitation learning problem
if QP feasible then by using behavioural cloning with ADAM optimizer [35]
q →− q∗ employing a learning rate 1e−3 and forgetting factors 0.9
end if and 0.999. We trained for 200 epochs of which in the first
end if 50=epochs thelossofeq.(6)iscomputedonthetrajectory
i
extract {qˆ} in Dˆ guess, without solving the QP. This solution helps to ease the
Compute constraint L (g,qˆ) using eq (7) learning and predict a good initial guess. The rest of the 150
g
Compute loss L (q,q∗) in eq (6) epochs use the QP optimization as last layer as explain in
q
Update model weights Sec. III. If the QP is unfeasible, we used the initial guess to
end for train our neural network. We exploit OptNet [36] to realize
a differentiable quadratic programming layer and use classic
backpropagation methods during training. We summarize the
training process in the Algorithm 2.
following a three-dimensional trefoil knot motion spanning a
width of 1m. For each mission, we randomly placed 8 drones
around the surface of the 10-m sphere, with each drone target V. EXPERIMENTS
located on the opposite side of the sphere surface, forcing All simulations and training were conducted on a machine
the traversal of the sphere centre. The sensing/communication running Ubuntu 22.04. with Intel Core i7-9750H @ 2.60GHz
radius is fixed at R = 4 m. At a sampling rate of 15Hz, CPU,NvidiaRTX2080Tiand32GRAM.Thecommunication
we capture point cloud data, localization information, and between the drones is employed through ROS with a commu-
current control trajectory in MINVO control points, starting nication rate of 100Hz while a new trajectory is calculated
from the current drone location. The trajectories are saved whenanewpointcloudissensedat15Hz.Asspecifiedinthe
as clamped spline with 10 equally spaced internal knots assumption,wedonotconsidercommunicationlossbut,being
for each axis starting from the current timestamp t to t . the trajectory computation at a lower rate, we can guarantee
0 f
Therefore, the trajectories are defined solely by 10 CPs for a communication delay margin of 0.056 s. We first provide
eachaxisforsegmentpolynomialsofdegree3.Thishelpsthe an ablation study and analysis results for a general quadrotor
training process by focusing on learning the control points. model with a perfect controller tracking trajectories with a6 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2024
Fig.5. Saliencymap(ontheleft)ofcollisioncaseusingourapproachfora
trajectorystartingfromthedroneandtraversingtheobstacle.
conditions, we evaluate the average success rate and average
travel time for the agents to reach their respective targets. We
testedtheapproachintwosettingsshowninFig.2:theforest-
likeusedduringtrainingandacorridor-likeenvironment8m×
20m including also horizontal pillars. In the second setting,
the drones are required to traverse the corridor from end to
end. For each experimental condition (number of drones in
team, obstacle density), we carried out 50 repetitions of the
travellingmission,equallydistributedinthetwoscenarios.We
Fig. 3. Success rate and safety rate increasing obstacles and agents in the
consideramissiontobesuccessfulifalltheagentsreachtheir
rangeofobstacledensity[5%−25%]andnumberofrobotsbetween[5−25]
forourapproach,ourswithoutGNN,ourswithoutcollisionconstraint,ours target without colliding. We proceeded with an ablation study
withPointnet++,ourswithoutDMoNandMADERalgorithm. to evaluate our approach:
• ours w/o GNN: we replaced GNN layers with normal
MLP, to evaluate the impact of communication over the
predictions.
• ours w/o opt: we did not use the predicted constraint g
to test the impact of this introduced feature.
• Pointnet++: we replaced our solution ofPointnet-DMoN
with Pointnet++ and max pooling.
• oursw/oDMoN:weremovedDMoNclusteringandused
max pooling to predict the trajectory guess, as for the
constraint prediction branch.
Fig. 4. Saliency map in a scenario with two drones for our approach and Additionally, for comparison, we also consider MADER, pro-
ourswithoutGNN.Thetwodrones(blackandblue)senseeachotheranda
viding full obstacle trajectories but a limited time budget of
pilarthroughtheirpointcloudwhilemovingtowardthetarget.Thesaliency
mapisdisplacedbythealphachannelofthepoints. 0.35s for each optimization according to the original paper
to guarantee a real-time execution. Our approach reaches an
average computational time of 1.3ms with a maximum of
maximum twist equal to 3.5 m/s in any directions and maxi- 1500 points sensed. The computational time in real scenarios
mum acceleration equal to [20,20,9.6] m/s2. We assume the can change based on the LiDAR sensor resolution and the
quadrotorsizetobeconfinedinasphereofradiusd=0.15m. solver used for the last optimization layer which might be
Moreover,wechoset =1swhichoffersagoodcompromise different from OptNet as, after the training, there is no need
f
between knots resolution and prediction horizon. in this set- fortheoptimizationtobedifferentiable.Notethat,thesensing
ting,theobstaclereachesamaximumvelocityof2m/s.Then, frequency dominates the computational time.
we provide experimental results using Crazyflies drones in a
physicalsimulationwithmaximumvelocity[1.0,1.0,1.0]m/s
and maximum acceleration [2.0,2.0,2.0] m/s2. We leveraged A. Results
a simulator built in Unity+Mujoco and software in the loop We present an analysis of the average success rate and
(SITL)1 to mimic the real drone behaviour. In this setting, we average travel time on successful trajectories, as illustrated
reduce the obstacle maximum velocity to 1 m/s and t =3s in Fig. 3. Our proposed neural network consistently achieves
f
because of the drone’s reduced velocity. a remarkable success rate of 100% for obstacle densities up
Weconsidertwoexperimentalconditions:avariablenumber to 15% and 16 robots, gradually decreasing to 85% for the
ofagentsinarangeof[4,25],withdynamicandstaticobstacle highest obstacle density of 25%. Notably, the effectiveness
density of 10% of the space; a fixed number of agents to of our model is closely tied to point cloud processing, as
8 and increasing obstacle density from 5% to 25%. In both evidenced by the success rates of Pointnet++ and ours w/o
DMoN, ranging from 90% to 40%. The clustering capabilities
1https://gitlab.inria.fr/amarino/crazyswarm2 unity sim of Pointnet++ contribute to an average 8.3% higher successMARINOetal.:MULTI-UAVSEND-TO-ENDDISTRIBUTEDTRAJECTORYGENERATION 7
influenced by its distance from the drone, as the network
predicts spatio-temporal commands and potential collisions
around the drone, independent of the goal location. Initially,
we focus our analysis on a scenario involving two drones
and a static obstacle, as illustrated in Fig. 4. To highlight
the contribution of different observations, we assign distinct
colours(blueandblack)topointssensedbyindividualdrones,
with the alpha channel representing saliency values—more
transparent points indicate less impact on predictions. It is
evident from the saliency map that each drone perceives the
Fig. 6. Distance from points sensed in a range of 4 m for flight tests with obstacle from only one side. As expected, points closer to
Crazyfliedrones.Thereddashedlinesdenotethephysicalsafedistance. the drones are more transparent since the first part of the
trajectory is predefined by the continuity with the current
motion. Compared to ours w/o GNN, the saliency map for
rate compared to ours w/o DMoN, emphasizing its impact on
our approach shows a balanced distribution of points between
the environment processing.
the two drones, resulting in more uniform trajectories across
When the model does not exploit the learnt collision con-
the environment. In contrast, when deploying ours w/o GNN,
straint g, it encounters difficulties in finding collision-free
we note an unbalanced use of the drone point cloud with the
trajectories, especially in high-constraint spaces populated by
blackdronerelyingmoreheavilyonitssensedpointsthanthe
bothcooperativeandnon-cooperativeagentswherethesuccess
blue drone, leading to distinct behaviours. This discrepancy
rate diminishes to 80% for an obstacle density of 25% and
indicates more potential conflicts between the drones due
25 robots. The integration of GNN enhances the model’s
to differences in the perceptions of the environment, while
resilience to collisions and traversal time as the number of
GNN helps to reach coherent observations across different
drones increases, showcasing the advantages of cooperative
viewpoints.Additionally,saliencymapsserveasvaluabletools
trajectory predictions. Our approach shows advantages also
for analyzing failure cases. Figure 5 showcases a collision
compared to MADER with a high density of obstacles and
scenario with ours. The trajectory intersects a pillar, with its
robots primarily because when the optimization in MADER
points appearing transparent in the saliency map, suggesting
doesnotfindafeasibletrajectorythealgorithmkeepsusingthe
that the network is ”blind” to the obstacle, although perceived
previously computed trajectory. When the drone reaches the
throughthepointcloud.Conversely,otherobstaclesareclearly
end of the trajectory, it breaks remaining exposed to obstacle
visible and incorporated into the trajectory planning.
collisionuntiltheoptimizationbecomesfeasibleagainbecause
of the dynamical changes in the environment. Notably, ours
B. Physical Simulation
w/ooptandMADERreachthesamesuccessrateof85%with
25% obstacle density which we speculate is due to the drone In a physical simulator, We tested our approach with
coordination through GNN. Crazyfliedrones.Werecordedamissionforeachexperimental
Our approach exhibits the lowest average travel time of scenario: obstacle density ranging from 5% to 25% and
11.8s with 25 robots even if MADER and ours w/o opt find numbers of agents ranging from 4 to 25. Moreover, as for
faster trajectories to traverse the space with fewer drones the non-physical simulation, the missions were conducted for
([5 − 10]) and travel times comparable to ours as obstacle the two scenarios of a dynamic forest and a dynamic corridor.
densityincreases.Moreoveroursw/oopt hasthelowesttravel Figure 6 illustrates the distribution of accumulated drone-to-
time when the obstacle increases with 12.4s ± 2.1, at the obstacle distances during the flights. Notably, no collisions
expense of less safe trajectories. In contrast, Pointnet++ and were observed, as all recorded distances remained above the
oursw/oDMoN havesimilartraveltimes,approximately17.3s safety threshold of 0.1 meters.
with a high variance of 2s, facing drone deadlock situations
or predicting longer paths to reach the goal. VI. CONCLUSION
Our approach reaches a similar average time to MADER This work introduces a decentralized end-to-end trajectory
as we used it to generate the dataset. However, we note that plannerthataddressesstaticobstacles,dynamicobstacles,and
MADER does not generate global optimal time trajectories other agents. By learning a collision constraint alongside the
due to its asynchronous communication strategy, aiding the trajectory, we ensure the safety and dynamic feasibility of
first drone committing the trajectory. As a result, subsequent the trajectories in a QP framework. We extensively validate
dronesmustadapttoavoidcollisions,resultinginnon-optimal our approach in simulation against variations of our approach
trajectories. and demonstrate robustness to team scalability and varying
We use Algorithm 1 to generate saliency maps, which help obstacledensitiesintheenvironment.Additionally,wederived
interpret the network’s behaviour and provide insights into an algorithm to compute the saliency map of the point cloud,
the point cloud’s contribution to trajectory prediction. The which we used as a tool to interpret and understand both
saliency map allows us to qualitatively assess how well the failure and success cases. Future work could explore how to
neural network uses the sensing data for decision-making. exploit the saliency map to enhance prediction performance
We expect that the relevance of each point in the cloud is and consider alternative learning frameworks that do not8 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2024
rely on privileged experts. Furthermore, future research will [20] S.Zhang,K.Garg,andC.Fan,“Neuralgraphcontrolbarrierfunctions
examine additional robustness metrics under conditions such guided distributed collision-avoidance multi-agent control,” in Confer-
enceonRobotLearning. PMLR,2023,pp.2373–2392.
as sensor noise, tracking deviations, dynamic environmental
[21] B. Sabetghadam, R. Cunha, and A. Pascoal, “A distributed algorithm
changes, and hardware experiments. for real-time multi-drone collision-free trajectory replanning,” Sensors,
vol.22,no.5,p.1855,2022.
[22] C. E. Luis, M. Vukosavljev, and A. P. Schoellig, “Online trajectory
REFERENCES generation with distributed model predictive control for multi-robot
motionplanning,”IEEERoboticsandAutomationLetters,vol.5,no.2,
pp.604–611,2020.
[1] J. Gu, T. Su, Q. Wang, X. Du, and M. Guizani, “Multiple moving
[23] J. Tordesillas and J. P. How, “Mader: Trajectory planner in multiagent
targetssurveillancebasedonacooperativenetworkformulti-uav,”IEEE
and dynamic environments,” IEEE Transactions on Robotics, vol. 38,
CommunicationsMagazine,vol.56,no.4,pp.82–89,2018.
no.1,pp.463–476,2021.
[2] P. Peng, W. Dong, G. Chen, and X. Zhu, “Obstacle avoidance of
[24] K.Kondo,R.Figueroa,J.Rached,J.Tordesillas,P.C.Lusk,andJ.P.
resilient uav swarm formation with active sensing system in the dense
How,“Robustmader:Decentralizedmultiagenttrajectoryplannerrobust
environment,”in2022IEEE/RSJInternationalConferenceonIntelligent
tocommunicationdelayindynamicenvironments,”IEEERoboticsand
RobotsandSystems(IROS). IEEE,2022,pp.10529–10535.
AutomationLetters,2023.
[3] Y.Gao,Y.Wang,X.Zhong,T.Yang,M.Wang,Z.Xu,Y.Wang,Y.Lin,
[25] Z. Wang, C. Xu, and F. Gao, “Robust trajectory planning for spatial-
C.Xu,andF.Gao,“Meeting-merging-mission:Amulti-robotcoordinate
temporal multi-drone coordination in large scenes,” in 2022 IEEE/RSJ
frameworkforlarge-scalecommunication-limitedexploration,”in2022
International Conference on Intelligent Robots and Systems (IROS).
IEEE/RSJ International Conference on Intelligent Robots and Systems
IEEE,2022,pp.12182–12188.
(IROS). IEEE,2022,pp.13700–13707.
[26] J.Park,D.Kim,G.C.Kim,D.Oh,andH.J.Kim,“Onlinedistributed
[4] A.Alca´ntara,J.Capita´n,R.Cunha,andA.Ollero,“Optimaltrajectory
trajectoryplanningforquadrotorswarmwithfeasibilityguaranteeusing
planning for cinematography with multiple unmanned aerial vehicles,”
linear safe corridor,” IEEE Robotics and Automation Letters, vol. 7,
RoboticsandAutonomousSystems,vol.140,p.103778,2021.
no.2,pp.4869–4876,2022.
[5] H.-J.KimandH.-S.Ahn,“Realizationofswarmformationflyingand
[27] M.Bojarski,A.Choromanska,K.Choromanski,B.Firner,L.J.Ackel,
optimal trajectory generation for multi-drone performance show,” in
U. Muller, P. Yeres, and K. Zieba, “Visualbackprop: Efficient visu-
2016IEEE/SICEInternationalSymposiumonSystemIntegration(SII).
alization of cnns for autonomous driving,” 2018 IEEE International
IEEE,2016,pp.850–855.
ConferenceonRoboticsandAutomation(ICRA),pp.4701–4708,2018.
[6] C. Zhao, J. Liu, M. Sheng, W. Teng, Y. Zheng, and J. Li, “Multi-
[28] J.TordesillasandJ.P.How,“Minvobasis:Findingsimplexeswithmin-
uavtrajectoryplanningforenergy-efficientcontentcoverage:Adecen-
imum volume enclosing polynomial curves,” Computer-Aided Design,
tralized learning-based approach,” IEEE Journal on Selected Areas in
vol.151,p.103341,2022.
Communications,vol.39,no.10,pp.3193–3207,2021.
[29] D.Chen,B.Zhou,V.Koltun,andP.Kra¨henbu¨hl,“Learningbycheating,”
[7] Y. Chen, U. Rosolia, and A. D. Ames, “Decentralized task and path
inConferenceonRobotLearning. PMLR,2020,pp.66–75.
planning for multi-robot systems,” IEEE Robotics and Automation
[30] R. Q. Charles, H. Su, M. Kaichun, and L. J. Guibas, “Pointnet: Deep
Letters,vol.6,no.3,pp.4337–4344,2021.
learning on point sets for 3d classification and segmentation,” in 2017
[8] J. Corte´s and M. Egerstedt, “Coordinated control of multi-robot sys-
IEEEConferenceonComputerVisionandPatternRecognition(CVPR).
tems: A survey,” SICE Journal of Control, Measurement, and System
IEEEComputerSociety,2017,pp.77–85.
Integration,vol.10,no.6,pp.495–503,2017.
[31] A.Tsitsulin,J.Palowitch,B.Perozzi,andE.Mu¨ller,“Graphclustering
[9] ——, “Coordinated control of multi-robot systems: A survey,” SICE with graph neural networks,” Journal of Machine Learning Research,
JournalofControl,Measurement,andSystemIntegration,vol.10,no.6,
vol.24,no.127,pp.1–21,2023.
pp.495–503,2017.
[32] F.Gama,Q.Li,E.Tolstaya,A.Prorok,andA.Ribeiro,“Synthesizing
[10] A. Loquercio, E. Kaufmann, R. Ranftl, M. Mu¨ller, V. Koltun, and decentralized controllers with graph neural networks and imitation
D. Scaramuzza, “Learning high-speed flight in the wild,” Science learning,”IEEETransactionsonSignalProcessing,vol.70,pp.1932–
Robotics,vol.6,no.59,p.eabg5810,2021. 1946,2022.
[11] D. Palossi, A. Loquercio, F. Conti, E. Flamand, D. Scaramuzza, and [33] Z.Jiang,L.Ding,G.K.Tam,C.Song,F.W.Li,andB.Yang,“C2spoint:
L.Benini,“A64-mwdnn-basedvisualnavigationengineforautonomous Aclassification-to-saliencynetworkforpointcloudsaliencydetection,”
nano-drones,”IEEEInternetofThingsJournal,vol.6,no.5,pp.8357– Computers&Graphics,vol.115,pp.274–284,2023.
8371,2019. [34] T. Zheng, C. Chen, J. Yuan, B. Li, and K. Ren, “Pointcloud saliency
[12] P.Miera,H.Szolc,andT.Kryjak,“Lidar-baseddronenavigationwith maps,” in Proceedings of the IEEE/CVF International Conference on
reinforcementlearning,”arXivpreprintarXiv:2307.14313,2023. ComputerVision,2019,pp.1598–1606.
[13] S.El-Ferik,M.Maaruf,F.Al-Sunni,A.A.Saif,andM.M.AlDhaifal- [35] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
lah, “Reinforcement learning-based control strategy for multi-agent in International Conference on Learning Representations (ICLR), San
systems subjected to actuator cyberattacks during affine formation Diega,CA,USA,2015.
maneuvers,”IEEEAccess,2023. [36] B.AmosandJ.Z.Kolter,“Optnet:Differentiableoptimizationasalayer
[14] X. Liu, Y. Liu, and Y. Chen, “Reinforcement learning in multiple-uav inneuralnetworks,”inInternationalConferenceonMachineLearning.
networks: Deployment and movement design,” IEEE Transactions on PMLR,2017,pp.136–145.
VehicularTechnology,vol.68,no.8,pp.8036–8049,2019.
[15] S. Batra, Z. Huang, A. Petrenko, T. Kumar, A. Molchanov, and G. S.
Sukhatme, “Decentralized control of quadrotor swarms with end-to-
end deep reinforcement learning,” in Conference on Robot Learning.
PMLR,2022,pp.576–586.
[16] Q.Li,W.Lin,Z.Liu,andA.Prorok,“Message-awaregraphattention
networksforlarge-scalemulti-robotpathplanning,”IEEERoboticsand
AutomationLetters,vol.6,no.3,pp.5533–5540,2021.
[17] Q. Li, F. Gama, A. Ribeiro, and A. Prorok, “Graph neural networks
for decentralized multi-robot path planning,” in 2020 IEEE/RSJ Inter-
nationalConferenceonIntelligentRobotsandSystems(IROS). IEEE,
2020,pp.11785–11792.
[18] J.Blumenkamp,S.Morad,J.Gielis,Q.Li,andA.Prorok,“Aframework
for real-world multi-robot systems running decentralized gnn-based
policies,”in2022InternationalConferenceonRoboticsandAutomation
(ICRA). IEEE,2022,pp.8772–8778.
[19] B. Riviere, W. Ho¨nig, Y. Yue, and S.-J. Chung, “Glas: Global-to-local
safe autonomy synthesis for multi-robot motion planning with end-to-
endlearning,”IEEERoboticsandAutomationLetters,vol.5,no.3,pp.
4249–4256,2020.