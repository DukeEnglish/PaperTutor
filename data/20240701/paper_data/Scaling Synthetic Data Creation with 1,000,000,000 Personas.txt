TechnicalReport
Scaling Synthetic Data Creation with 1,000,000,000 Personas
XinChan,XiaoyangWang,DianYu,HaitaoMi,DongYu
TencentAILabSeattle
https://github.com/tencent-ailab/persona-hub
Abstract
Weproposeanovelpersona-drivendatasynthesismethodologythatleveragesvarious
perspectives within a large language model (LLM) to create diverse synthetic data.
To fully exploit this methodology at scale, we introduce Persona Hub – a collection
of 1 billion diverse personas automatically curated from web data. These 1 billion
personas(∼13%oftheworld’stotalpopulation),actingasdistributedcarriersofworld
knowledge,cantapintoalmosteveryperspectiveencapsulatedwithintheLLM,thereby
facilitating the creation of diverse synthetic data at scale for various scenarios. By
showcasingPersonaHub’susecasesinsynthesizinghigh-qualitymathematicaland
logicalreasoningproblems,instructions(i.e.,userprompts),knowledge-richtexts,game
NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis
isversatile,scalable,flexible,andeasytouse,potentiallydrivingaparadigmshiftin
syntheticdatacreationandapplicationsinpractice,whichmayhaveaprofoundimpact
onLLMresearchanddevelopment.
DISCLAIMER:PersonaHubcanfacilitatesyntheticdatacreationatabillion-scaletosimulate
diverseinputs(i.e., usecases)fromawidevarietyofreal-worldusers. Ifthisdataisusedas
inputtoqueryatargetLLMtoobtainitsoutputsatscale,thereisahighriskthattheLLM’s
knowledge,intelligenceandcapabilitieswillbedumpedandeasilyreplicated,therebychallenging
theleadingpositionofthemostpowerfulLLMs(e.g.,ourapproachallowsa7BLLMtoachieve
65% on MATH, matching the performance of gpt-4-turbo-preview). This tech report is
forresearchpurposesonly. Itiscrucialtoavoidmisuseandensureethicalandresponsible
application. WediscussitsbroadimpactandpotentialconcernsindetailinSection5.
Create {data} with
{persona}
a math problem a logical reasoning problem a user prompt to an LLM
John, a moving company driver, needs to You are a moving company driver with a Could you provide step-by-step instructions
deliver furniture to three locations. The truck that has limited space. You need to for safely moving a grand piano from a
distances are: 50 miles to the first location; 70 load a large couch, a tall bookshelf, and a third-floor apartment to a ground-floor
miles to the second location; 80 miles to the wide dining table. The couch must be laid location?
third location. John's truck gets 20 miles per flat and loaded first, the bookshelf must stay Please include all necessary equipment
a moving company gallon and has a 15-gallon tank. upright, and the dining table must be the and best practices for navigating stairs,
last item loaded.
driver Will he need to refuel during the trip? ensuring both the piano and property How do you arrange the items in the truck? remain undamaged during the move.
Dr. Smith, a chemist, is studying a reaction You are analyzing the spatial arrangement of Investigate the effect of temperature on the
where compound X decomposes into molecules in a reaction chamber. There are rate constant of H₂O₂ decomposition with
products Y and Z. The reaction follows first- three types: A, B, and C. Molecule A is MnO₂ catalyst. Determine the activation
order kinetics with a rate constant k of 0.5 always adjacent to B, but never to C. energy (Ea) and pre-exponential factor (A)
min−1. Molecule B can be adjacent to both A and C. using the Arrhenius equation.
a chemical kinetics If the initial concentration of compound X is If molecule C is surrounded by other Provide an experimental procedure and
researcher 1.0 M, how long will it take for the molecules, which ones must be present data analysis method to extract these
concentration of X to decrease to 0.25 M? around it? parameters.
… … … …
A musician is studying an audio signal You are setting up a surround sound system Can you briefly explain the differences
composed of two sine waves. The audio with five speakers labeled A, B, C, D, and E. between various types of audio filters, such signal f(t) is given by: To achieve the best spatial audio effect, you as low-pass, high-pass, band-pass, and
f(t)=sin(2π⋅440t)+sin(2π⋅660t) n ae rre ad n gto e mpl ea nc te . them equidistantly in a circular n po rotc vh id efi l ete xr as m? pA led sd i otio f n ha ol wly , e c ao cu hl d ty pyo eu o fp ale ua ds ie o
a musician interested Determine the period of this combined audio If speaker A is directly opposite speaker D, filters can be used creatively in music
in audio processing signal f(t). who is directly opposite speaker B? production to enhance or modify sound?
Figure 1: Personas can work with a wide range of data synthesis prompts (e.g., create a math
problemorauserprompt)toguideanLLMtosynthesizedatawithcorrespondingperspectives.
The1billionpersonasinPersonaHubcanfacilitatesyntheticdatacreationforvariousdatasynthesis
scenariosatabillionscale.
1
4202
nuJ
82
]LC.sc[
1v49002.6042:viXra
buH
anosreP
morf
sanosrep
000,000,000,1
1,000,000,000
synthetic
instances
created
by
LLMsTechnicalReport
1 Introduction
Assyntheticdata(Baueretal.,2024;Liuetal.,2024),typicallyreferringtodatageneratedbymodels
oralgorithmsratherthandirectlybyhumans, becomesincreasinglyvalued(Lietal.,2023b)for
traininglargelanguagemodels(LLMs),thereisagrowinginterestindatasynthesisusingLLMs: by
simplyspecifyingadatasynthesisprompt,anLLMisexpectedtoproducedesirablesyntheticdata.
Inpractice,however,itisnon-trivialtocreatesyntheticdataatscale:whilewecaneasilyscaleupthe
quantityofsyntheticdata,itisdifficulttoensureitsdiversityscalesupaswell. Withoutconsidering
sampling1,anLLMcanonlyproduce1instancegivenadatasynthesisprompt. Therefore,tocreate
diversesyntheticdataatscale(e.g.,1billiondiversemathproblems),alargenumberofdiverse
promptsareneeded.
Previousresearchtendstodiversifythedatasynthesispromptthroughthefollowingtwoparadigms,
butunfortunately,neithercanpracticallyachievescalablesyntheticdatacreation:
• Instance-driven: This approach diversifies the data synthesis prompt by leveraging a seed
corpus(i.e.,creatingnewinstancesbasedontheinstancesintheseedcorpus). Representative
studies include Wang et al. (2022) and Yu et al. (2023). However, under this paradigm, the
diversityofthesynthesizeddatamainlycomesfromtheseedinstances,makingitdifficultto
trulyextendbeyondtheseedcorpus. Giventhelimitedsizeofaseedcorpusinmostpractical
scenarios,itischallengingforthisparadigmtoscaleupthecreationofsyntheticdata.
• Key-point-driven: Thisapproachdiversifiesthedatasynthesispromptwithacuratedcompre-
hensivelistofkeypoints(orconcepts)thatcanbeatopic,asubject,oranyknowledgeweexpect
syntheticdatatoencompass. RepresentativestudiesincludeLietal.(2024b)andHuangetal.
(2024). However,thismethodologyalsofacesdifficultiesinscalingsyntheticdatacreation: it
ispracticallyprohibitivetocurateacomprehensivelistbyenumeratingallkeypointsacross
differentlevelsofgranularity,unlesslimitedtoanarrowandspecificdomain(e.g.,mathematics).
Topracticallyachievediversesyntheticdatacreationatscale,weproposeanovelpersona-driven
datasynthesismethodology. Thisisinspiredbytheobservationthatsimplyaddingapersonatoa
datasynthesispromptcansteertheLLMtowardsthecorrespondingperspectivetocreatedistinctive
synthetic data, as shown in Figure 1. Since almost any LLM use case can be associated with a
specificpersona,wecancreateall-encompassingsyntheticdataatscaleaslongasweconstructa
comprehensivepersonacollection.
Persona Hub
(1 billion personas)
World Knowledge World Knowledge
Compress Decompress
Represented by Generate texts with
…
distributed carriers their knowledge
Public Web Text Public Web Text
(~1014 tokens) (~1014 tokens)
~1010 tokens
Figure2:Fromacompressionperspective(Dele´tangetal.,2023;Geetal.,2024),PersonaHub(∼1010
tokens)canbeseenasthecompressedformofworldknowledge(publicwebtextfortrainingLLMs,
∼1014tokens)intodistributedcarriers. Ontheotherhand,thepublicwebtextcanbeseenasthe
decompressedcontentcreatedbythesepersonaswiththeirknowledgeandexperiences.
1Samplingisorthogonaltothiswork. Thediversityitintroduceswhensolelyusedfordatasynthesisis
usuallylimited.
2TechnicalReport
Fortunately,personasareveryeasytoscaleup. Frommassivewebdata,weautomaticallyconstruct
PersonaHub—apersonacollectioncontaining1billiondiversepersonas(∼13%oftheworld’stotal
population). AsFigure2shows,these1billionpersonascanberegardedasdistributedcarriersof
worldknowledge,andeachindividualcanbeassociatedwiththeiruniqueknowledge,experience,
interest,personalityandprofession;thus,theycantapintoalmosteveryperspectiveencapsulated
withintheLLMtocreatediversesyntheticdataatscale,withoutbeinglimitedbythesizeofaseed
corpus. Moreover,incontrasttokeypointsthattypicallyworkwithspecificdatasynthesisprompts,
personascanbecombinedwithalmostanydatasynthesisprompt,benefitingfromanLLM’sstrong
roleplayability(Shanahanetal.,2023;Lietal.,2023a;Choi&Li,2024;Wangetal.,2024),making
themgenerallyapplicabletoavarietyofdatasynthesisscenarios.
WeshowcasePersonaHub’susecasesinlarge-scalecreationofmathandlogicalreasoningproblems,
instructions(i.e.,userprompts),broad-coverageknowledge-richtexts,gameNPCs,andtool(func-
tion)development. Wedemonstratethatpersona-drivendatasynthesisisversatile,scalable,flexible,
andeasytouse,potentiallydrivingaparadigmshiftinsyntheticdatacreationandapplicationsin
practice,whichmayhaveaprofoundimpactonLLMresearchanddevelopment.
Tofacilitateresearchinpersona-drivendatasynthesis,weinitiallyrelease200,000personasfrom
PersonaHubandfollowingsyntheticdatasampleswecreatedwithvariouspersonas,including:
• 50,000mathproblems • 50,000logicalreasoningproblems
• 50,000instructions • 10,000knowledge-richtexts
• 10,000gameNPCs • 5,000tools(functions)
We are open to releasing more data when we can better assess the potential risks and concerns,
whichwillbediscussedindetailinSection5.
Note: OurproposedmethodologyisapplicabletoalmostanypopularLLM2.Thepromptsshown
inthefiguresthroughoutthispaperarenotexactlythepromptstringsweusedinourexperiments;
instead,theyaresimplifiedtofitthespaceandbetterillustratetheconcepts. Interestedreaderscan
easilyverifyourmethodologyusingthepersonasampleswehavereleased. Itisalsoworthnoting
thatthemainfocusofthisworkisoncreatingnewsyntheticdata,unlikemuchpreviousresearch
thatfocusesongeneratingsyntheticoutputsforspecificinputs(e.g.,amathproblem). Therefore,we
usetheterms“create”and“synthesize”interchangeablythroughoutthepaper.
2 PersonaHub
We propose two scalable approaches to derive diverse personas to construct Persona Hub from
massivewebdata: Text-to-PersonaandPersona-to-Persona.
2.1 Text-to-Persona
Apersonwithspecificprofessionalexperiencesandculturalbackgroundswillhaveuniqueinterests
inreadingandwriting. Therefore,fromaspecifictext,wecaninferaspecificpersonawhoislikely
to[read|write|like|dislike|...] thetext. Giventhattextdataonthewebisvirtuallyunlimited
andall-encompassing,wecanobtainawide-rangingcollectionofpersonassimplybypromptingan
LLMwiththesewebtexts,asshowninFigure3.
Therearemanyformats(e.g., plaintextorstructuredtext)torepresentapersona, whichcanbe
controlledwithintheprompt. Thegranularityofanoutputpersonadescriptioncanalsobeadjusted
throughtheprompt. Forexample,inthefirstcase,acoarse-grainedpersonamightbe“acomputer
scientist”,whereasthefine-grainedpersonais“amachinelearningresearcherfocusedonneuralnetwork
architecturesandattentionmechanisms”. Inourpractice,weasktheLLM(intheprompt)tooutput
2WemainlyusepubliclyavailableLLMssuchasGPT-4(Achiametal.,2023),Llama-3andQwen(Team,
2024;qwe,2024)inourexperiments.
3TechnicalReport
Text
Persona
An a_en7on func7on can be described as mapping a query
and a set of key-value pairs to an output, where the query, A machine learning researcher focused on neural
keys, values, and output are all vectors … network architectures and a_en7on mechanisms.
Text
Persona
Clinical Guideline: Administra7on of Injec7ons in Pediatric
LLM A pediatric nurse, who is responsible for
Pa7ents
administering injec7ons to children and ensuring
Purpose: To provide standardized care for pediatric pa7ents
their safety and comfort during the procedure.
requiring injec7ons, ensuring safety, …
Text
Persona
Which is your favorite mobile MOBA? !
A mobile gaming enthusiast who enjoys compe77ve
- Honor of Kings
mul7player online ba_le arena (MOBA) games and
- Pokemon UNITE
is interested in exploring different 7tles within the
- Mobile Legends: Bang Bang
genre.
- Wild Rih
Figure3: TheText-to-Personaapproach: itcanuseanytextasinputtoobtaincorrespondingpersonas
justbypromptingtheLLM“Whoislikelyto[read|write|like|dislike|...] thetext?”
Text Persona
To prove that a set of vectors v1,v2,…,vn is linearly independent, we need to verify that A mathema7cs enthusiast with a solid
the equa7on c 1v1+c 2v2+⋯+cnvn=0 has only the trivial solu7on understanding of linear algebra
c 1=c 2=⋯=cn=0. concepts, par7cularly vector spaces and
linear independence. She is likely
Example 118 Consider the vectors in ℝ3: engaged in studying or reviewing the
0 2 1 proper7es of vectors in ℝ3 and is
v1= (0 2), v2= (2 1), v3= (4 3). f sa ym steil miar
s
w ofit lh
in
s eo al rv i en qg
u
h ao 7m ono sg e ton eous
determine linear independence.
Are they linearly independent? …
LLM
Text Persona
For the first 7me, we synthesized a room-temperature superconductor (Tc ≥ 400 K, 127°C) A condensed ma_er physicist
that works at ambient pressure using a modified lead-apa7te (LK-99) structure. LK-99's specializing in superconduc7vity. He is
superconduc7vity is confirmed by its cri7cal temperature (Tc), zero-resis7vity, cri7cal deeply interested in the mechanisms
current (Ic), cri7cal magne7c field (Hc), and the Meissner effect. This superconduc7vity and materials that enable
arises from a slight volume shrinkage (0.48%) due to Cu²⁺ subs7tu7ng Pb²⁺(2) ions in the superconduc7vity, par7cularly at
Pb(2)-phosphate network, causing stress that distorts the cylindrical column interface and higher temperatures and ambient
creates superconduc7ng quantum wells (SQWs). Heat capacity results support this model, pressures, and would be keen to
highligh7ng that the unique structure of LK-99 maintains these distor7ons, enabling follow the development and
superconduc7vity at room temperature and ambient pressure. implica7ons of the LK-99 structure
and its unique proper7es.
Figure4: Personadescriptionswillbefine-grainedifinputtextsinvolvemanydetailedelements.
persona descriptions as specifically as possible. Besides specifying the granularity of persona
descriptionsintheprompt,inputtextscanalsoinfluencethegranularityofpersonadescriptions. As
showninFigure4,ifaninputtext(e.g.,fromamathematicaltextbookoranacademicpaperabout
superconductivity)containsmanydetailedelements,theresultingpersonadescriptionwillalsobe
specificandfine-grained. Therefore,byapplyingtheText-to-Personaapproachtomassivewebtext
data,wecanobtainbillions(oreventrillions)ofdiversepersonas,encompassingawiderangeof
aspectsacrossdifferentgranularities.
2.2 Persona-to-Persona
Asdiscussedabove,Text-to-Personaisahighlyscalablemethodthatcansynthesizepersonascovering
almosteveryaspect. However,itmaystillmisssomepersonasthathavelowvisibilityontheweb
andthusarelesslikelytoobtainviaText-to-Persona,suchasachild,abeggar,orabehind-the-scenescrew
memberofamovie. TosupplementthepersonasthatText-to-Personamighthardlyreach,wepropose
Persona-to-Persona,whichderivespersonaswithinterpersonalrelationshipsfromthoseobtained
throughText-to-Persona.
AsshowninFigure5,thepersonaabout“achild”canbederivedfromthepersonaofanurseata
children’shospital(patient-caregiverrelationship). Similarly,“abeggar”canbederivedfromthe
4TechnicalReport
Relation: Medical supplier
A pharmaceu7cal company representa7ve ensuring
that a clinic has the needed supplies for pediatric
care.
Persona
Relation: Patient
A pediatric nurse, who is responsible
for administering injec7ons to children LLM A child with a chronic illness who regularly receives
injec7ons and relies on the pediatric nurse for
and ensuring their safety and comfort
comfort and care during medical procedures.
during the procedure.
Relation: Colleague
A child life specialist who supports young pa7ents
and families through medical procedures with
therapeu7c play and emo7onal support.
Figure5: Persona-to-Personaobtainsdiversepersonasviainterpersonalrelationships,whichcanbe
easilyachievedbypromptingtheLLM“Whoisincloserelationshipwiththegivenpersona?”
personaofashelterworker(assistancerelationship),and“abehind-the-scenesmoviecrewmember”can
bederivedfromthepersonaofthemovie’sleadactor(co-workerrelationship). Accordingtothe
sixdegreesofseparationtheory(Travers&Milgram,1977),weperformsixiterationsofpersona
relationshipexpansionforeachpersonaobtainedthroughText-to-Persona,therebyenrichingour
personacollectionevenfurther.
2.3 Deduplication
WefirstrunText-to-PersonaontheRedPajamav2dataset(Computer,2023)andthenperformPersona-
to-Persona,asdescribedinSections2.1and2.2. Afterobtainingbillionsofpersonas,itisinevitable
thatsomeofthepersonaswillbeidenticalorextremelysimilar. ToensurethediversityofPersona
Hub,wededuplicatethesepersonasintwoways:
MinHash-based Deduplication We use MinHash (Broder, 1997) to deduplicate based on the
n-gramfeaturesofpersonadescriptions. Sincepersonadescriptionsareusuallyjust1-2sentences,
muchshorterthanadocument,wesimplyused1-gramandasignaturesizeof128forMinHash
deduplication. Wededuplicateatthesimilaritythresholdof0.9.
Embedding-based Deduplication After deduplication based on surface forms (i.e., MinHash
withn-gramfeatures),wealsoadoptembedding-baseddeduplication. Weuseatextembedding
model(e.g.,thetext-embedding-3-smallmodelfromOpenAI)tocomputeanembeddingforeach
persona,andthenfilteroutpersonaswithacosinesemanticsimilaritygreaterthan0.9.
Notethatalthoughweselect0.9asthethresholdhere,wecanflexiblyadjustitaccordingtospecific
needsforfurtherdeduplication. Forinstance,whentherequirementforthenumberofinstancesis
nothigh(e.g.,onlyneeding1millioninstances)butthedemandfordiversityishigh,wecanfurther
applyastricterdeduplicationstandard(e.g.,discardingpersonaswithasimilaritygreaterthan0.5).
Afterdeduplicationandusingsimpleheuristicmethodstofilteroutlow-qualitypersonadescriptions,
wehaveharvestedatotalof1,015,863,523personas,finallyformingourPersonaHub.
3 Persona-drivenSyntheticDataCreation
Our proposed persona-driven data synthesis approach is straightforward and effective, which
involvesintegratingapersonaintotheappropriatepositioninadatasynthesisprompt. Simple
asitappears, itcansignificantlyinfluencetheLLMtoadoptthepersona’sperspectivetocreate
syntheticdata. Drivenbythe1billionpersonasinPersonaHub,thisapproachcaneasilycreate
diversesyntheticdataatabillionscale.
5TechnicalReport
0-shot prompting persona-enhanced few-shot prompting
Create a challenging math problem with the following persona:
Example 1:
a chemical kinetics researcher
Persona: A dedicated volleyball player who believes that volleyball
requires more skill and strategy than soccer
few-shot prompting Math problem: Let V and S denote the vector spaces of strategies
in volleyball and soccer respec7vely. Assume that these vector
Example 1: spaces are finite-dimensional and that the dimension of V is larger
Let V and S denote the vector spaces of strategies in volleyball than the …
and soccer respec7vely. Assume that these vector spaces are
finite-dimensional and that the dimension of V … Example 2:
Persona: A mathema7cian specializing in numerical simula7ons of
Example 2: black hole dynamics
Given the following metric which describes the Schwarzschild Math problem: Given the following metric which describes the
black hole in general rela7vity: Schwarzschild black hole in general rela7vity:
2GM 1 2GM 1
ds2=−(1− )dt2+ dr2+r2dΩ2 ds2=−(1− )dt2+ dr2+r2dΩ2
c2r 1−2GM c2r 1−2GM
c2r c2r
where G is the gravita7onal constant, M is the mass of the … where G is the gravita7onal constant, M is the mass of the …
Your task: Create a challenging math problem similar to the Your task: Create a challenging math problem similar to the examples
examples above with the following persona: above with the persona:
a chemical kinetics researcher a chemical kinetics researcher
Figure6: 0-shot,few-shotandpersona-enhancedfew-shotpromptingmethods.
Justaswecanuseeitherzero-shotorfew-shotmethodstopromptanLLM,thepersona-driven
methodologyisalsoflexibleandcompatiblewithvariousformsofpromptstocreatesyntheticdata.
AsshowninFigure6,weproposethreepersona-drivendatasynthesispromptingmethods:
• Zero-shotpromptingdoesnotleverageanyexistingexamples(i.e.,demonstrations),thereby
fullyexploitingthemodel’screativitywithoutbeingconstrainedbyspecificexamples.
• Few-shot prompting can better ensure that the synthesized data meets the requirements by
providingsomedemonstrations.
• Persona-enhancedfew-shotpromptingismoreeffectiveinenhancingtheLLM’spersona-driven
datasynthesiscapabilities. However,itsdrawbackisthatitrequiresderivingthecorresponding
personaforeachdemonstrationinthefew-shotpromptbeforehand.
4 UseCases
WedemonstratetheusecasesofPersonaHubinvariousdatasynthesisscenarios,includingthelarge-
scalecreationofmathandlogicalreasoningproblems,instructions(i.e.,userprompts),knowledge-
richtexts,gameNPCs,andtool(function)development.
Asmentionedearlier,thepersona-drivenapproachisgeneralandversatile,makingiteasilyadapt-
abletodifferentdatasynthesisscenariossimplybyadjustingthedatasynthesisprompt. Therefore,
wewillprovideadetailedtechnicaldiscussiononlyformathproblemsynthesis(Section4.1)and
skipthedetaileddiscussionforotherusecases.
4.1 MathProblems
4.1.1 Demonstrations
Astheinitialexample(Figure1)shows,whenpromptinganLLMtocreateamathproblem,adding
apersonaleadstheLLMtocreatemathproblemsrelatedtothatpersona. TheexampleinFigure
7(left)furtherconfirmsthis: whenpresentedwithalinguistpersona,theLLMwillcreateamath
probleminthecontextofcomputationallinguistics. Moreover,addingapersonadoesnothinder
6TechnicalReport
Math Prompt 1 Math Prompt 2 Math Prompt 3
Create a math problem with the following Create a geometry problem with the following Create an Olympiad-level math problem with
persona: persona: the following persona:
A linguist with a particular interest in the A linguist with a particular interest in the A linguist with a particular interest in the
intersection of language and social interaction intersection of language and social interaction intersection of language and social interaction
Synthesized Text Synthesized Text Synthesized Text
Dr. Elena, a linguist fascinated by the
Dr. Smith, a linguist fascinated by the dynamics intersec7on of language and social interac7on, In a community of n linguists, each linguist
of language in social interac7ons, is studying is studying the layout of a conference room speaks exactly two of the k languages. Any two
the frequency of certain phrases in where a round-table discussion on linguists who share a language can
conversa7ons. In a sample of 100 sociolinguis7cs will take place. The round table communicate directly, and all linguists can
conversa7ons, she finds that the phrase "How has a diameter of 10 feet, and she wants to communicate either directly or indirectly
are you?" appears 60 7mes, while the phrase ensure that each par7cipant can see and hear through others.
"Thank you" appears 45 7mes. She also notes
each other clearly, which she believes is best
that in 20 of these conversa7ons, both phrases
appear. achieved if the par7cipants are evenly spaced Prove that the number of languages k must
around the table. sa7sfy:
How many conversa7ons contain at least one
If there are 8 par7cipants, how far apart will
k≤⌈ 2n
⌉
of the two phrases: "How are you?" or "Thank
you"?
each par7cipant be from their nearest where ⌈x⌉ is the ceiling func7on.
neighbors along the circumference of the
table?
(a) (b) (c)
Figure7: Alinguistpersonawithdifferentmathproblemcreationpromptsthatspecifythefocus
(e.g.,geometry)orthedifficulty(e.g.,Olympiad-level)
theflexibilityoftheprompt–wecanstilleasilyspecifythefocus(Figure7(middle))ordifficulty
(Figure7(right))ofourdesiredmathproblemintheprompt.
Math Prompt 4 Math Prompt 5
Create a math problem with the following persona: Create a math problem with the following persona:
A high school math teacher is teaching students the concepts of A mathematics professor who specializes in the study of group
linear functions and definite integrals, helping them understand the theory, particularly the concepts and theorems related to subgroups
relationships between functions and the methods for calculating the and isomorphisms. His research interests include, but are not limited
area of regions enclosed by curves. to, the structure of finite groups, representation theory of groups,
isomorphism problems, and the theory of group automorphisms.
Synthesized Text Synthesized Text
Consider the linear func7ons f(x)=2x+3and g(x)=−x+5. 1. Let G be a finite group and H a subgroup of G. Suppose ϕ:G→G is
an automorphism of G. Prove that ϕ(H) is also a subgroup of G and that
1. Intersec;on Points: |ϕ(H)|=|H|.
- Find the points of intersec7on of the two func7ons f(x) and g(x).
2. Let G=S
4
(the symmetric group on 4 elements) and H=A
4
(the
2. Area Between Curves: alterna7ng group on 4 elements). Determine whether there exists an
- Calculate the area of the region enclosed by the curves f(x) and g(x). automorphism ϕ of S
4
such that ϕ(A 4)≠A 4. Prove your conclusion.
Figure8: Examplesofmathproblemscreatedwithpersonasofprofessionalsrelatedtothefieldof
mathematics. Theytendtobemorechallengingthanthosecreatedwithgeneralpersonasbecause
they usually require a deeper and more fine-grained understanding of advanced mathematical
knowledgeandskills.
TheexamplesinFigure7demonstratetheuseofgeneralpersonastocreatemathproblems. Wecan
certainlyemployprofessionalsrelatedtomathematicstocreatemathproblemsaswell. Asshownin
Figure8,personasofmathprofessionals3 oftenmentionmoreadvancedandgranularmathematics
knowledgeandskills(asdiscussedearlierinSection2.1andFigure4),whichinturnallowsthe
createdmathproblemstocoverthesemathematicalconcepts,makingthemmorechallenging.
3WecaneasilyharvestalargenumberofsuchpersonaswhenrunningText-to-Persona(Section2.1)onpublic
webtexts,particularlywhenprocessingtextsinthefieldofmathematics.
7TechnicalReport
4.1.2 Evaluation
Data Weselect41.09millionpersonasfromPersonaHubandemploythe0-shotpromptingmethod
usingGPT-4tocreatemathproblemswiththesepersonas,whichdoesnotleverageanyinstances
frombenchmarkslikeMATH(Hendrycksetal.,2021)duringthecreationofmathproblems. This
approachallowedustosynthesize1.09Mmathproblems. Sincethisworkfocusesoncreatingnew
syntheticdataratherthansynthesizingsolutions,wesimplyusedgpt-4o(assistant5)togenerate
solutionstothecreatedproblems. Amongthese1.09Mmathproblems,werandomlyholdout20k
asasynthetictestsettofacilitateevaluation. Theremaining1.07Mproblemsareusedfortraining.
Testsets Weusethefollowingtwotestsetsforevaluation:
• SyntheticTestSet(In-distribution): Sincethesetoftheheld-out20Kproblemsisproducedin
thesamewayasthe1.07Mtraininginstances,itcanbeconsideredanin-distributiontestset. To
ensuretheaccuracyoftheanswersinthistestsetforincreasingthereliabilityoftheevaluation,
weadditionallygeneratesolutionsusinggpt-4o(PoT6)andgpt-4-turbo(assistant)inaddition
tothesolutiongeneratedbygpt-4o(assistant). Weretainonlythetestinstanceswhereatleast
twosolutionsareconsistent. Theremainingtestsetconsistsof11.6Ktestinstances.
• MATH(Out-of-distribution): Themostwidelyrecognizedbenchmarkfortestingthemathemati-
calreasoningabilityofLLMs. Itstestsetcontains5,000competitive-levelmathproblemswith
referenceanswers. SincewedonotuseanyinstancesfromtheMATHdatasetfordatasynthesis
ortraining,weregardtheMATHtestsetasanout-of-distributiontestset.
EqualityChecking WefollowthesameevaluationprotocolasOpenAI7tocheckanswerequality
on the MATH benchmark. For the synthetic test set, we use a similar method, except we use
Llama-3-70B-Instructinsteadofgpt-4-turbo-previewastheequalitychecker.
Wesimplyfine-tunethelatestopen-sourced7BLLM–Qwen2-7B(qwe,2024)withoursynthesized
1.07millionmathproblemsandevaluateitsgreedydecodingoutputsontheabovetwotestsets.
Model ModelSize Accuracy(%)
Open-sourcedLLMs
DeepSeekLLM67BChat(Bietal.,2024) 67B 53.2
Phi-3-Mini-4K-Instruct(Abdinetal.,2024) 3.8B 68.3
Yi-1.5-34B-Chat(Youngetal.,2024) 34B 70.4
Qwen1.5-72B-Chat(Team,2024) 72B 60.7
Qwen1.5-110B-Chat(Team,2024) 110B 73.0
Qwen2-7B-Instruct(qwe,2024) 7B 72.1
Qwen2-72B-Instruct(qwe,2024) 72B 77.2
Llama-3-8B-Instruct 8B 39.8
Llama-3-70B-Instruct 70B 63.5
GPT-4
gpt-4-turbo-2024-04-09 ? 88.1
gpt-4o-2024-05-13 ? 91.2
Thiswork
Qwen2-7B(fine-tunedw/ the1.07Msynthesizedinstances) 7B 79.4
Table1: In-distributionevaluationresultsonthe11.6Ksynthetictestinstances.
4Technically,ifweusethefullversionofPersonaHub,wecanobtain1billionmathproblemssynthesized
byanLLM.However,duetothecostofGPT-4APIs,welimitourscalingto1.09Mpersonasforthisexperiment.
5AssistantsystemmessageinOpenAIAPIdoc:“Youareahelpfulassistant.”
6Programofthoughtprompting(Chenetal.,2022)
7https://github.com/openai/simple-evals
8TechnicalReport
Model ModelSize Accuracy(%)
State-of-the-artLLMs
gpt-4o-2024-05-13 ? 76.6
gpt-4-turbo-2024-04-09 ? 73.4
gpt-4-turbo-0125-preview ? 64.5
gpt-4-turbo-1106-preview ? 64.3
gpt-4 ? 52.6∗
Claude3.5Sonnet ? 71.1∗
Claude3Opus ? 63.8
GeminiPro1.5(May2024) ? 67.7∗
GeminiUltra ? 53.2∗
DeepSeek-Coder-V2-Instruct(Zhuetal.,2024) 236B/21B 75.7∗
Llama-3-70B-Instruct 70B 52.8
Qwen2-72B-Instruct 72B 59.7∗
Qwen2-7B-Instruct 7B 49.6∗
Thiswork
Qwen2-7B(fine-tunedw/ the1.07Msynthesizedinstances) 7B 64.9
Table2: Out-of-distributionevaluationonMATH.Resultsmarkedwithanasterisk(*)maynotuse
theOpenAI’sevaluationmethod. Themodelfine-tunedwithoursynthesized1.07Mmathproblems
achieves64.9%onMATH,matchingtheperformanceofgpt-4-turbo-previewatonlya7Bscale.
Table 1 presents the in-distribution (ID)
evaluation results on the 11.6K syn-
thetic test instances. Among the tested
open-source LLMs, Qwen2-72B-Instruct
achieves the best result, and the rank-
ing of the other models is generally con-
sistent with their reported performance
onothermathematicalbenchmarks. Our
model,withthehelpofthe1.07Msynthetic
mathproblems,achievesnearly80%accu-
racy,surpassingalltheopen-sourceLLMs.
However,consideringthattheanswersin
thesynthetictestarenotabsolutelyreliable
andthatourmodelmightbetheonlyone
usingIDtrainingdata,thisIDevaluation
resultsshouldbetakenasareferenceonly.
We present the evaluation results on
Figure9:AccuracyonMATHwithscalingthesynthetic
MATHinTable2.The7Bmodelfine-tuned
instancesusedfortrainingQwen2-7B
withthesynthetictrainingdataachieved
an impressive 64.9% accuracy on MATH
simplyusinggreedydecoding,outperformedonlybygpt-4o,gpt-4-turbo-2024-04-09,Claude
3.5Sonnet,GeminiPro1.5(May2024)andDeepSeek-Coder-V2-Instruct.
Figure 9 presents the performance of the model on MATH when trained with synthetic math
problemsatdifferentscales. Itsperformancetrendgenerallyalignswiththescalinglaw(Kaplan
etal.,2020). Unlikepreviousresearch(Yuetal.,2023;Wangetal.,2023;Lietal.,2024a)thatperforms
scalingonin-distributiondata(e.g.,heavilyrelyingonMATHtraindatatoaugmentin-distribution
data),wedidnotuseanyinstancesfromMATHduringdatasynthesisortraining. Therefore,in
thisout-of-distribution(OOD)evaluationsetting,achievingperformanceonMATHthatsurpasses
gpt-4-turbo-preview (1106/0125)isindeedimpressiveandpromisingfora7Bmodel.
Weexaminethequalityofoursynthesizedmathproblems: wesample200challengingproblems
(involvinghighschoolanduniversity-levelmathknowledgepointsinChina),andhavetwomath
9TechnicalReport
(a) (b) (c)
Figure10:Similaritiesofmathproblemscreatedbypersonaswithdifferentsimilarities:(a)Similarity
ofmathproblemswhennospecificfocusisgiven;(b)Similarityofmathproblemswhentheprompt
specifiestheymustberelatedtofinanceandprobability;(c)Similarityofmathproblemssynthesized
bygpt-4oandgpt-35-turbowithpersonasimilarityof0.9.
experts evaluate their validity. Only 7 out of 200 problems are marked as invalid (e.g., due to
insufficientorconflictingconditions),yieldingareliablevalidityrateof96.5%.
Moreover,wespecificallyexaminetheimpactofdifferencesinpersonaswithinthepromptsonthe
synthesizedmathproblems. Wefirstsample100pairsofpersonaswithsemanticsimilarities8of0.4,
0.6,and0.8,respectively. Foreachpairofpersonas,weusethemtocreateapairofmathproblems
usinggreedydecoding(i.e.,temperature=0). Then,wecomputethesemanticsimilarityofthese
mathproblempairsandshowtheresultsinFigure10.
Wecanclearlyobservethatthesemanticsimilaritybetweensynthesizedmathproblemstendsto
becorrelatedwithbutlowerthanthesimilaritybetweentheircorrespondingpersonas. Whenwe
addmorespecificconstraintstotheprompts(e.g.,mathproblemsaboutfinanceandprobability),
thesimilaritybetweenthesynthesizedmathproblemstendstobecomehigher(Figure10(b)). In
Figure 10(c), we also test the similarity of math problems created by gpt-4o and gpt-35-turbo
usinghighlysimilarpersonas(similarity=0.9). Theresultsindicatethatthesemanticsimilarityof
themathproblemscreatedbygpt-4oandgpt-35-turboseemsnotsignificantlydifferent: most
synthesizedmathproblems’similarityfallswithintherangeof0.6to0.75,whichismuchlowerthan
thesimilarityofthepersonas(0.9). Giventheseobservations,webelievethatusingthepersonasin
PersonaHubcanensurethediversityofsynthesizeddata–evenatabillionscale.
4.2 LogicalReasoningProblems
Similartomathproblems,logicalreasoningproblemscanalsobeeasilysynthesized. Wepresent
examplesoftypicallogicalreasoningproblemssynthesizedusingourproposedpersona-driven
methodologyinFigure11.
Moreover,wealsoshowseveralRuozhiba-style9 logicalreasoningproblemscreatedwithpersonas
inFigure12. Alltheexamplesdemonstratethataslongaswecanclearlydescribetherequirements
forthelogicalreasoningproblemtobecreated,wecanusealargevarietyofpersonastosteerthe
LLMtogeneratediverselogicalreasoningproblemsthatnotonlymeettherequirementsbutare
alsohighlyrelevanttothepersonas,evenforwhimsicalRuozhiba-styleproblems.
8WeuseOpenAI’stext-embedding-3-small(dim=512)toobtainthesemanticrepresentationandcompute
cosinesimilarityinthisexperiment. Here, apersonasimilarityof0.4meansthatapairofpersonashasa
semanticsimilaritywithintherangeof0.39to0.41.
9RuozhibaisasubforumonBaiduTieba,featuringnumerousintricateandchallengingquestionsposted
byChinesenetizens. Thesequestionscombineelementssuchaspuns,polysemy,causalinversion,andho-
mophones,embeddinglogicaltrapsthatrigorouslytesttheabilitytounderstandcomplexChineselanguage
constructs.Recentresearch(Baietal.,2024)hasdemonstratedthatthesedatasignificantlybenefittheimprove-
mentofLLMs’logicalreasoningabilities.
10TechnicalReport
Logical Prompt 1 Logical Prompt 2
Create a logical reasoning problem with the following persona Create a spa;al reasoning problem with the following persona
An enthusiastic amateur golfer who is passionate about A senior software engineer who encourages the undergraduate
combining sports with philanthropic causes. to consider the social impact of their algorithms
Synthesized Text Synthesized Text
Alex, an enthusias7c amateur golfer, par7cipated in three charity
golf tournaments last year, each suppor7ng a different cause: Context: A senior sohware engineer is working on a 5x5 grid of
Educa7on, Health, and Environment. Each tournament was held interconnected servers. Each server is a node connected by
in a different month: April, July, and October. Addi7onally, Alex lines.
finished in a different posi7on in each tournament: 1st, 2nd, and
3rd. Challenge: Send a message from the top leh to the bo_om
right server, avoiding servers connected to more than 3 other
Using the following clues, determine which cause was supported servers to prevent overload.
in each month and Alex's finishing posi7on in each tournament:
Ques;on: What is the minimum number of servers the
The tournament suppor7ng Educa7on was held in April. message needs to pass through to reach its des7na7on without
Alex finished 1st in the tournament held in July. overloading any server?
Alex finished 3rd in the tournament suppor7ng Environment.
Figure11: Logicalreasoningproblemscreatedbyourproposedpersona-drivenmethodology
Logical Prompt 3
Create a Ruozhiba-style logical reasoning problem with the following persona
An IT consultant specializing in A local business owner interested A soccer fan who believes in toughing A cynical musician interested in the
network configuration in economic trends it out rather than making excuses business side of music streaming
Synthesized Text Synthesized Text Synthesized Text Synthesized Text
如果经济趋势决定的零售价格是商 如果球员在比赛中把脚踝扭了，然 如果我把⼀首歌反复播放达到⼀亿
如果我把路由器放在冰箱里，会不 品售价，那么在经济趋势反转的⼀ 后他把球鞋换成另⼀只脚，他的脚 次，我是不是就可以成为自⼰的首
会提⾼Wi-Fi的冷却效率？ 瞬间，商品售价会是负数吗？ 踝还会疼吗？ 位百万流量歌⼿了？
(If I put the router in the refrigerator, (If the retail price is determined by (If a player twists their ankle during a (If I play a song on repeat un7l it
will it improve the Wi-Fi cooling economic trends, will the price of game and then switches their shoe to reaches 100 million plays, can I
efficiency?) goods be nega7ve at the moment the the other foot, will their ankle s7ll consider myself my own first million-
economic trend reverses?) hurt?) stream ar7st?)
Figure 12: Ruozhiba-style logical reasoning problems created with various personas. Note that
LogicalPrompt3inthisfigureisasimplifiedprompt. Inpractice,weneedtospecificallydefinea
Ruozhiba-stylelogicalreasoningprobleminthispromptinordertoobtaindesiredsyntheticdata.
Formoreexamples,pleaserefertothe50,000syntheticreasoningproblemswehavereleased.
4.3 Instructions
TheendusersofLLMsareultimatelyhumans. WecanusePersonaHubtosimulateavarietyof
userstounderstandtheirtypicalrequestsforLLMassistance,resultingindiverseinstructions(i.e.,
userprompts).
Figure13showstwotypicalpersona-drivenpromptsforsynthesizinginstructions,correspondingto
thezero-shotpromptingandpersona-enhancedfew-shotpromptingmethodsdescribedinSection
3. The zero-shot method does not rely on any existing instruction dataset and allows the LLM
11TechnicalReport
Instruction Prompt (0 shot)
You are a helpful assistant. Guess a prompt (i.e., instruc7on) that the following persona may ask you to do:
{persona}
Instruction Prompt (persona-enhanced few shot)
You are a helpful assistant.
===Example 1===
Persona: A curious and analy;cal individual, likely with a background in mathema;cs or science, who enjoys
exploring intriguing "what if" scenarios and
is fascinated by the intersec;on of popula;on demographics and geography.
Prompt: Is it possible for the global popula;on to stand on Jeju Island?
===Example 2===
Persona: An astronomy enthusiast or a professional astronomer, likely with a strong interest in peculiar galaxy
structures and a good understanding of celes;al objects, seeking to gather specific informa;on about the
unique Hoag's object galaxy.
Prompt: Name the actual galaxy inside Hoag's object galaxy
———
Your task: Guess a prompt (i.e., instruc7on) that the following person may ask you to do: {persona}
Figure13: Twotypicalpromptsusedforcreatinginstructions(i.e.,userprompts).
togeneratevariousinstructionsbasedondifferentpersonas. Incontrast, thepersona-enhanced
few-shotmethodrequiresexistinginstructiondatasets(e.g.,weuseWildChat(Zhaoetal.,2024)
in our experiments) to sample some instructions as demonstrations and involves inferring the
associatedpersonasoftheseinstructionsthroughtheText-to-PersonamethoddescribedinSection
2.1. Whilethisapproachismorecomplex,itresultsinsynthesizedinstructionsthatmoreclosely
resemblesinstructionsfromrealusers.
With diverse instructions created using Persona Hub, which typically represent the first turn of
auser-LLMconversation,wecaneasilygeneratetheirsubsequentconversationalturnsusingan
LLM,resultinginalargenumberofsimulateduser-LLMconversations,whichwillbevaluablefor
enhancingtheLLM’sinstruction-followingandconversationalabilities. Furthermore,wecaneven
adoptasimilarapproachbyselectingtwopersonasfromPersonaHubandhavingLLMsrole-play
both,therebysimulatingconversations(Jandaghietal.,2023)betweentworealpeople.
AsFigure1hasalreadyshownsomeinstructionscreatedusingthismethodology,weskipshowing
exampleshere. Readersinterestedinmoreexamplescanrefertothereleased50,000instructions
synthesizedthrough0-shotandpersona-enhanced2-shotprompting.
4.4 Knowledge-richTexts
In addition to synthesizing instructions that can enhance the instruction tuning of LLMs, the
persona-drivenmethodologycanbeeasilyadaptedtocreateknowledge-richplaintextthatbenefits
pre-trainingandpost-trainingofLLMs. AsillustratedinFigure14,wecanpromptanLLMtowrite
aQuora10 article11 usingapersonasampledfromPersonaHub. ThisapproachelicitstheLLM’s
correspondingknowledgeandperspective, resultinginhighlyinformativeandknowledge-rich
content. Byscalingthisprocesswith1billionpersonasinPersonaHub,wecaneasilyobtainavast
arrayofknowledge-richtextsthatcoveralmostanytopicacrossvariouslevelsofgranularity.
10Quoraisapopularquestion-and-answerwebsitewhereuserscanaskquestionsandprovideanswersona
widerangeoftopics.Articles(i.e.,posts)onQuoraareoftenwrittenbyknowledgeableindividuals,including
expertsinvariousfields,ensuringhigh-quality,well-researched,andinformativecontent.
11Themethodsforsynthesizingknowledge-richplaintextarenotlimitedtohavingtheLLMwriteQuora
articles.Forinstance,wecanalsoprompttheLLMtosynthesize(educational)readingmaterialthatapersona
maybeinterestedin,therebyobtainingalargeamountofknowledge-richtext.
12TechnicalReport
Knowledge Prompt
Assume you are the persona described as follows. Write a Quora ar;cle using your knowledge, skills, experience, or insights.
A horticulturist interested in native Australian flora, exploring the introduction and An architect or construction engineer interested in
cultivation of drought-resistant plants in arid and semi-arid landscapes historical buildings and their preservation
Synthesized Text Synthesized Text
Unlocking the Secrets of Drought-Resistant Na;ve Australian Flora: A Guide to Cul;va;ng Unveiling the Secrets of Historical Building Preserva;on: A Comprehensive Guide for Architects
Resilient Plants in Arid and Semi-Arid Landscapes and Engineers
As a hor7culturist with a passion for na7ve Australian flora, …. I’ll share my knowledge and As an architect and construc7on engineer … I’ll share my knowledge and experience to provide a
insights on how to introduce and cul7vate these incredible plants, … comprehensive guide for architects and engineers interested in historical building preserva7on…
Understanding Drought-Resistant Plants Assessing the Condi;on of Historical Buildings
Drought-resistant plants have evolved … Na7ve Australian flora is par7cularly well-suited to our The first step in any historical building preserva7on project is to assess the condi7on of the
dry climate, with many species exhibi7ng remarkable drought tolerance. structure … look for signs of deteriora7on, such as cracks, corrosion, and water damage…
Choosing the Right Plants Preserva;on Techniques for Historical Buildings
When selec7ng drought-resistant plants for your landscape, it's essen7al to consider the specific Once you've assessed the condi7on of the building, it's 7me to develop a preserva7on plan. Here
climate and soil condi7ons of your region. Here are some of my top picks for arid and semi-arid are some essen7al techniques to consider:
landscapes:
1. Consolida;on: This involves stabilizing the building's structure …
1. Eucalyptus (Eucalyptus spp.): These iconic Australian trees are renowned for their ability to 2. Cleaning: …
thrive in dry condi7ons. With over 700 species to choose from, you're sure to find one that
suits your landscape. Historical building preserva7on is not without its challenges. Here are some common issues to
2. Kangaroo Paw (Anigozanthos spp.): … consider:
3. …
4. Spinifex Grass (Triodia spp.): This tough, spiny grass is a common sight in arid landscapes 1. Balancing Preserva;on and Moderniza;on: Finding a balance between …
across Australia. It's an excellent choice for stabilizing soil and crea7ng a natural, rus7c look. 2. Working with Limited Budgets: Historical preserva7on projects ohen …
3. …
By following these guidelines and incorpora7ng drought-resistant na7ve Australian flora into
your landscape, you'll be well on your way to crea7ng a resilient and beau7ful outdoor space Remember, historical building preserva7on is not just about saving old buildings; … we can ensure
that thrives in even the harshest of climates. that these iconic structures con7nue to inspire and enrich our communi7es for years to come.
Figure14: Examplesofknowledge-richplaintextsynthesiswithpersonas
4.5 GameNPCs
AstraightforwardandpracticalapplicationofPersonaHubiscreatingdiverseNPCs(Non-Player
Characters)atscaleforgames. Aslongaswecanprovideagame’sbackgroundandworld-building
informationtotheLLM,wecanprompttheLLMtoprojectpersonasfromPersonaHub(which
are typically real-world personas) into characters within the game’s world. In this way, we can
significantlyreducetheeffortrequiredforbrainstormingNPCsduringthegamedesignprocess.
NPC Prompt (Wow)
World of Warcrah (WoW) is a massively mul7player online role-playing game (MMORPG) developed by Blizzard Entertainment. It is set in the high-fantasy world of
Azeroth … Below is a detailed overview of the game's worldview, story background, and some key characters and NPCs.
Azeroth is a world steeped in ancient history, powerful magic, and epic conflicts … The main con7nents include:
…
———
Above is the introduc7on and background story of the game "World of Warcrah (WoW)".
Your task is to consider what NPC the following persona will become aher they come to the world of WoW:
A nomadic photographer capturing the beauty of different A local restaurant owner who values the cultural heritage A retired war veteran who understands the
cities, inspired by the diary writer's poetic musings of Fuzhou and wants to incorporate it into their business challenges and sacrifices of life
Synthesized Text Synthesized Text Synthesized Text
Name: Lyraea Moonwhisper Name: Mei Lin Name: Gorvoth Ironfist
Race: Night Elf Race: Pandaren Race: Dwarf
Class: Druid (Balance specialization) Class: Chef (neutral class, similar to a profession) Class: Warrior
B t a n I S u t p innh on a n lha sae t c t ceec iy u gmi ob rk e er ha voe e en rg tsec ffa nt sr a rtu eo t o n i tm aNt rou ondy s llnan i y g iwo fi ng d q hwf g sai: u c ct c h pli e k at EL i t iht i s s rpiny li n efte , tr sPg usa pm aA l r e o pa a ta ez aoa ig pyen ng a er rd ttipw o ec ihi r nn crtl s ea a oh gss i: s an et, t L oe tbd ci is yt c ua oes rsh r et t nc a a e d tn n a ue t s f eo h ap ota .d y s em t re Pe u ce s Ada l rac al a. ea zd i nr ryc… 'na eoi s eac dbt ru ri o t do ,eD s ne tp e n dd hr rf mh tea . o ' a so sw u ah h i t lt yn be sno eo r d e rg r n a .t e a or l o nii a n uf S dte etp tih c h M y ch s .e e et o he oo sNr aho , my repi n isgc nrr ag t h ea ge p ylt asp m a pe dEt u iu or s nel svvr , ev, i iie n nn ti… o ts ig gg cer' B U v e I N c S L N cni x o uuha p b P Ptp so neec o r C C ta e ak rk n o sn r a i rp…g n mt t ci aa gr Fs t stao r r e o ei A tr .t cou i i sm cwv s hnn t lii ia epon i s vpd t l aasg h a ll: ea rw p t l n,et nyM i h h in se gt we e h e r mer sA hi i e sA n oP ez ,pl L a l rre li rr c eeaani eorn u o ynd wg plet ac trhw as u lr bee a, ra s rsa … o d yaw : ss s u ei ln, M h tr a g seMea en v A ui e cew zor niL ane epa iLi ntn q rns p si o o n u o i tiw e nc s har m tta n 'n eu i sa tp a de re n yt ad f mii d rtv cf oy i e ia e s t vr ff se t n t ee wo e o ts d rid r v r st ils ta y a es r hh u b e l p s aar py e t, ha nr r ue c en ad sS t i r dt aah u t w itlo e c a t o i iodrr he n ow m nil c d nscn auw s ho ge sl oemi i ar n n ts a i htd a i n nn h… o er' s dg es y r r. B r I I w I G s t b sr r ne hk uo o ea a on ot i pcn n e lc r ro slr pv oe f rk eiw od oo a d m og rwn tr c rgr hs eb twe tao e …… si ld r c hao,u v a c on n w ase n k sd e sa s er : b vwr m a v ar aeinG i i rn io l t t und fg ho hr o a ,r ti u b Pv n h ha hno l lse i eea st dt h h yB a ce i a e rn au e li rd l ms nr ys stnw h p:e ci a ena aen r g ar nct Wvr o f dte te L .r a t n e pi rr ma A rg oe c in oi swd eol da r n n e' n s tpw . ra os f lA Gd ua a, r ,r l yvf fi u t ei wg e oisv l rdh r ffo e se t er ar t i i ee n n rp pt itr g no oia rIr r go nin a on y gs g ng o r g… a f a, eu o ui n shn n r isd dges gH , a et as e n,dt e r Gh c… mwtew o et al o rea D A vr rd as v oa s f n e o t r i dhn n aa k r
Figure15: NPCcreationforthegame“WorldofWarcraft”usingpersonasinPersonaHub
13TechnicalReport
NPC Prompt (MOONLIGHT BLADE)
《天涯明月⼑》是腾讯北极光⼯作室研发的⼀款武侠题材的3D⼤型多⼈在线角⾊扮演电脑客户端国产游戏，于2016年7月1日在中国⼤陆正式公测，由古龙所著武侠小说《天涯·明
月·⼑》改编⽽成。游戏拥有丰富的社交系统，玩家可拜师和收徒，参加帮会和联盟，体验不同阵营之间的战⽃。由本作改编的⼿游《天涯明月⼑⼿游》于2020年10月16日上线。
背景设定
青龙会曾是天下间最神秘、最强⼤的组织，但其残暴不仁、滥杀⽆辜，令武林中⼈⼈自危。⼆⼗年前，少年公⼦⽻独闯青龙会，……
———
Above is the introduc7on and background story of the game "MOONLIGHT BLADE".
Your task is to consider what NPC the following persona will become aher they come to the world of MOONLIGHT BLADE:
An avant-garde painter who experiments with A solo backpacker with a similar interest in photography, A young aspiring firefighter who is inspired by their grandparent's
unconventional materials and techniques eager to capture unique perspectives stories and seeks guidance
Synthesized Text Synthesized Text Synthesized Text
NPC名字: 萧墨痕 NPC名字: 江南镜客·陆⾏⾈ NPC名字: ⽕云⼦·烈风
萧墨痕，江湖⼈称“墨狂”，是⼀位游⾛于江湖与艺术边缘的前卫画 陆⾏⾈，⼀位游历四⽅的背包客，自幼痴迷于光影交错的瞬间之 在《天涯明月⼑》的世界里，⽕云⼦·烈风是⼀位年轻⽽充满激情
家。他不拘⼀格，以天地为纸…… 美，擅长以⼿中的相机捕捉世间万物的灵韵。在《天涯明月⼑》的 的NPC，他的故事源自于对家族传统的深深敬仰。他的祖⽗，⼀位
在游戏中，萧墨痕是⼀位隐居于寒江城附近的艺术家，他与各路武 世界里，他成为了闻名遐迩的江南镜客，以独特的视角记录下⾦陵 在江湖中名声赫赫的⽕⼯头陀……
林⾼⼿交流……玩家可以在特定的时间和地点遇见他，参与“墨狂 （即游戏中的南⾦陵）的繁华与变迁。 在青龙会肆虐江湖的年代，⽕云⼦·烈风目睹了太多由⽕焰引发的
雅集”活动，通过完成⼀系列与艺术、武学结合的任务，获取萧墨 …… 悲剧……他踏上了寻访江湖中各路⽕器⼤师的旅程，希望能够学习
痕的亲笔画作，这些画作不仅具有观赏价值，还能为玩家带来⼀定 到最精湛的⽕器制作与使用技巧，同时探寻如何在⽕势失控时有效
的属性加成。 陆⾏⾈时常出现在⾦陵的街头巷尾，或是郊外的名胜古迹，与玩家 扑灭的⽅法。
互动，提供摄影任务，比如捕捉特定时间的风景、寻找隐秘的拍摄
萧墨痕还开设了⼀门独特的职业身份——“画师”，玩家可以选择成 角度等，完成任务后可获得独特的奖励，如特殊的相机、滤镜或是 ⽕云⼦·烈风最终在《天涯明月⼑》的世界中定居下来，成为了⼀
为画师，学习如何在江湖中寻找灵感，收集特殊材料，创作艺术 与摄影相关的装备。此外，陆⾏⾈还可能引导玩家解锁⼀些隐藏剧 位独特的NPC，他不仅能够教授玩家如何制作和使用各种⽕器，还
品，甚⾄可以将画作售卖给游戏中的收藏家，获取丰厚的回报…… 情，涉及古代诗词、历史事件或是⼀些江湖轶事，为玩家的江湖之 在玩家完成特定任务后，……。通过这些任务，玩家不仅能够提升
旅增添⼀抹⽂艺与历史的⽓息。 自⼰在⽕器使用和灭⽕技能上的熟练度……
Figure16: NPCcreationforthegame“MoonlightBlade(天涯明月刀)”usingPersonaHub
Figure15and16showconcreteexampleswhereweusepersonasinPersonaHubtocreategame
NPCsforthegame“WorldofWarcraft12”and“MoonlightBlade13”.
4.6 Tool(Function)Development
Tool Prompt
Develop a tool (i.e., a high-level interface) for the given persona to help them access complex func7onali7es that an LLM struggles with.
As the first step, you only need to define the tool (i.e., interface).
A cab driver who frequently drives along N82 A retired professor in Linguistics who studied A marine wildlife photographer capturing mesmerizing
in the Philippines together with Celso Alvarez Caccamo images of vulnerable marine creatures
Synthesized Text Synthesized Text Synthesized Text
{ g p t t r a } h h o i r vv e eo u a" " " " " "e v tn d f i r dii s enun leni aa e ed t ,p n tat bm ps r e e u ouo rc lc es r t r r ee u tt if nr nna _i at" ti o fh "ge dp: c a o : n me e " r "t rau "T i : _ gi Ao e tr r nsr "hn se s na ri Gd en sa "o t sf " :u t g ofi mu e : ar r" rc oi ot n" gn r nt e e T h o gud eC s g "eh u lt( : e eo ps t i r i t nh "s G e e .n t o Mg "a de pd i ,i o e ( nr in ar cti t to tt tu et i r pa_i ne ago op s sttgr fln ir eflef fi ne a a D ntp c gI hfMcn o tfi i o riece tnt c r eia he on _ gr clr p ar int oe c s tf s tt ia da uot t oh u nc inD tn o net er oe id d fon s i ) r t" "t in ts re, e t Aw r, ai s ac n ot Pfo h t ffid nai fi Ioe c s" "l cp o ,n t t cro n isr i noa ni g nA fnf g o fi t t dP ) s rhc i m I a te r. ic e os aTo r p n toihn in r ou ae ed p nt l si eu ot u ei i.to ns s", n n g,e a t r in nf t o hd gr e a { l a s i }a n h cn t c o o" " " " } " "g ,n d f i r du u nu e tu a e er hl" "p dn taa i tm ps eun a utg cc b ee rp re te tt g nr e n a_i u" t i o e "r rt dp: a t to : a g_n t r " r "t _ a "n etL i :_ ga e Ao l ns ta a "n sn x n Gl s ln n sa a " ao t l" ": tg g a ot m nt : : rih { u uo t oi g" " nee eTa an gT ugdr "g g.h lh a. : e " . oe e "i e, gI "s t Tf "t e T r :tli t r e a e .n er a" "a v n xt T ,x ne e tn s th s r r l ss f tea laa h atl a t rgc a tte i eat nee ti _o rgs Ait gt sn e r t Pet a x hh tI t h In n t a e "" l et s at, e G l nna tr rgf o et aa e uo e nc s ag d se gl st l" ee a e, tx tT o iit onr bf a ntr oen o o sm wt fl r a ta h ho t n ie ecn s h e A l ia n P tt pheI ue df t o . t" ter e, x xt t { i m I }m m a a a" " " " " "pn d f i r dg gnu e pa e ee epn t em ps u Nuu c dc er ee s tt nr nt_ii t" i oon ." dp: a ": ng , " tr "t " hS i : _ g To a e [np s " hn p te a " ae e" :rc m : c e n[ ii t"" ne - sue pT t ds or a" ah a : e rlI ti flid "s h x sn i o e d _ pei o wnn e t ed fot " t n c e ti _ ,mfi h it r ei i "c f f em to sa ya e d _c g pt nni ee s " ro sae]pl n , o mi dfd e rr iI fle co ecn oin m tet uee wt si sdr fi T _"f i e , na e c hs gc n l ua e s bt tsh" o h "s, e ]r e,F s w ll aop h bwe i ecc H lhi se u cs fib a li e.n n" , fa b ro eg m iv en
Figure17: Examplesoftool(function)creationwithPersonaHub
AsSection4.3demonstrates,PersonaHubcanbeusedtosimulateawidevarietyofrealusersto
anticipatetheirpossiblerequests(i.e.,instructions)toanLLM.Similarly,wecanusePersonaHubto
predictthetools(Caietal.,2023;Schicketal.,2024)thatusersmightneed,sothatwecanpre-build
thesetools(functions)beforehand. Whenarealusermakesasimilarrequest,theLLMcandirectly
callthesepre-builttoolstoreturnresultswithouthavingtobuildtoolsfromscratcheachtime. This
12WorldofWarcraft,developedbyBlizzardEntertainment,isahighlyinfluentialMMORPGwithmillionsof
activeplayersworldwide,spanningover100countriessinceitsreleasein2004.
13MoonlightBlade(天涯明月刀)isa3Dmartialarts-themedMMORPGdevelopedbyTencent,officially
launchedinChinaonJuly1,2016.
14TechnicalReport
paradigm,introducedbyPersonaHub,isacompletelynewsolutionthatallowsLLMstobetter
serveusers. WebelieveitwillhavegreatpotentialinthefutureasLLMsbecomemoredemocratized
andmultifunctional.
Figure17showsexamplesoftoolscreatedwithvariouspersonas. Thesetoolsprovidefunctionalities
that the personas may need (e.g., a cab driver needs to check traffic conditions) but cannot be
accessed by an LLM, greatly expanding the range of services provided by the LLM. Note that
althoughthetoolsinFigure17arejustinterfacedefinitions,thesedefinitionscanbeeasilyconverted
intocodeimplementations,asshowninFigure18.
Code Implementation for the Species Identification Interface
1import tensorflow as tf
2import tensorflow_hub as hub
3import numpy as np
4from PIL import Image
5
6class SpeciesIdentificationInterface:
7 def __init__(self):
8 self.model = hub.load("https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5")
9 self.labels = self.load_labels()
10
11 def load_labels(self):
12 labels_path = tf.keras.utils.get_file(
13 'ImageNetLabels.txt',
14 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'
15 )
16 with open(labels_path, 'r') as f:
17 labels = f.read().splitlines()
18 return labels
19
20 def preprocess_image(self, path_to_img):
21 img = Image.open(path_to_img).resize((224, 224))
22 img = np.array(img) / 255.0
23 img = np.expand_dims(img, axis=0)
24 return img
25
26 def identify_species(self, path_to_img):
27 img = self.preprocess_image(path_to_img)
28 predictions = self.model(img)
29 predicted_class = np.argmax(predictions, axis=-1)[0]
30 return predicted_class
31
32# Example usage:
33if __name__ == "__main__":
34 interface = SpeciesIdentificationInterface()
35 path_to_img = "path/to/your/image.jpg" # Replace with your image path
36 predicted_class_index = interface.identify_species(path_to_img)
37 print(f"Predicted class index: {predicted_class_index}")
38 print(f"Predicted species: {interface.labels[predicted_class_index]}")
39
Figure18: Theinterfacedefinitions(e.g., thespeciesidentificationinterface)inFigure17canbe
easilyconvertedintocodeimplementationsbycallinganLLMtoimplementthem. Theresulting
pre-builttoolscanthenbedirectlyutilizedbytheLLMinthefuture,eliminatingtheneedtobuild
themfromscratcheachtime.
5 BroadImpactandEthicalConcerns
5.1 BroadImpact
5.1.1 ParadigmShiftinDataCreationbyHumansandLLMs
Traditionally,ithasbeenwidelyacceptedthatwhileLLMsexcelatprocessingdata(e.g.,rewriting,
annotation,orgeneratingoutputs/solutionstospecificinputs),theyarenotparticularlyadeptat
creating new data. Consequently, the task of data creation has still largely been the domain of
humans, and the collaboration paradigm between humans and LLMs has always been humans
creatingdataandLLMsprocessingit(Mainietal.,2024). However,theintroductionofourproposed
15TechnicalReport
persona-drivenmethodologypotentiallyrevolutionizesthisparadigm. WithPersonaHub,LLMs
arenolongerconfinedtoprocessingexistingdata;theycannowcreatevarioustypesofnewdata
fromamultitudeofperspectives,muchlikethediversepopulationoftheworld.
WhilethecurrentcapabilitiesofLLMsmaynotyetfullyreplacehumansinfulfillingthemissionof
datacreation—whetherintermsofdataqualityorbreadth—theongoingadvancementsinLLM
capabilitiessuggestafuturewhereLLMswillincreasinglyexcelindatacreation. AsLLMscontinue
toimprove,boththequalityandbreadthofthedatatheycancreatewillalsolikelyenhance,leading
ustoapointwhereLLMsmayfullytakeontheroleofdatacreation. Whenthisdayarrives,we
willnolongerbeconstrained(Villalobosetal.,2024)bythelimitedhigh-qualityhuman-produced
real-worlddata14. PersonaHubensuresthediversityandcoverageofsyntheticdata,significantly
mitigating concerns about the negative impacts (Shumailov et al., 2023; Dohmatob et al., 2024)
ofsyntheticdataonmodeltraining. Thismayeffectivelyeliminatethedatabottleneck, thereby
pushingthescalinglawtoitslimit.
5.1.2 RealitySimulation
InSection4.3and4.6,wehavedemonstratedthatPersonaHubcanrepresentavastarrayofreal-
worldindividualswithits1billionpersonas. Byemployingthesepersonastosimulateandinferthe
potentialneedsandbehaviorsofrealusers,wecannotonlyallowLLMstoautonomouslyprepare
forupcomingusecases(queries),butalsopavethewayforLLMstoeffectivelymimictherealworld,
therebycreatingmanynewopportunities. Forinstance,companiescanusethismethodtopredict
how different types of users might react to a new product launch; governments can foresee the
public’sresponsetonewlegislation,consideringvariouspopulationgroup;inonlineservicesthat
requireuserprofilingandbehaviormodeling,PersonaHubcanfacilitatethesimulationofdiverse
userbehaviors,significantlyalleviatingthecoldstartchallenge.
RecentresearchonLLMroleplay,agentcollaboration(Liuetal.,2023;Wangetal.,2024),strategic
reasoning(Gandhietal.,2023;Zhangetal.,2024),andrelatedareascan,ofcourse,befacilitatedby
thevastanddiversepersonasinPersonaHub. Moreambitiously,the1billionpersonascaneven
sustainawell-organizedsocietywithinavirtualworld,suchassandboxenvironments(Parketal.,
2023),onlinegames,parallelworlds,orthemetaverse,usingthemethoddiscussedinSection4.5
tosimulateoperationswithpowerfulLLMs. Thisvirtualsocietycanserveasatestinggroundfor
newpolicies,radicalinitiatives,andsocialdynamics,providingvaluableinsightsbeforereal-world
implementation. Bycreatingacontrolledenvironmentwherediversepersonasinteract, wecan
observeemergentbehaviors,testhypotheses,andrefinestrategiesinarisk-freesetting. Thiscannot
onlyhelpdeepenourunderstandingofcomplexsystemsbutalsospeedupinnovationbyfacilitating
rapiditerationandexperimentation.
5.1.3 FullMemoryAccessofLLMs
WhenweinteractwithanLLMinaspecificscenario,wecanonlyelicitafractionofitsmemoryand
capabilities,andweareunabletofullyaccessthevastknowledgeencapsulatedwithintheLLM.
However,PersonaHubpotentiallyoffersaccesstothefullmemoryofanLLMbecausethe1billion
personasinPersonaHubcantapintoalmosteveryperspectiveandpieceofinformationencoded
withintheLLM.
Byleveragingthese1billionpersonas,wecancreatediversequeriesandobtainsolutionsfroma
targetLLM,therebytransformingtheLLM’scomprehensivememory(parameters)intosynthetic
dataintextualform. IfweconsideranLLMasaparameterizedcompressionofworldknowledge,
thenPersonaHubcanbeviewedasadistributedcarrier-basedcompression15ofworldknowledge,
as demonstrated in Figure 2. This distributed carrier-based compression provides us with an
14https://lilianweng.github.io/posts/2024-02-05-human-data-quality/
15AsFigure2illustrates,PersonaHubhasontheorderof1010tokens,equivalenttoa10,000×compression
ofthepublicwebtext(1014tokens).
16TechnicalReport
opportunitytodecompresstheLLM’sparametersbackintoworldknowledgeandinformationit
haseverlearned(e.g.,usingthemethoddiscussedinSection4.4).
However, considering that the current Persona Hub is still in a very preliminary stage and that
today’sLLMsarenotyetcapableoflosslesslyconvertingtheirmemoryintosyntheticdatadueto
inevitablehallucination(Xuetal.,2024),thebreadthandqualityofthesyntheticdatagenerated
throughthismethodologyarestilllimited. Nevertheless,asPersonaHubcontinuestoimproveand
scale,andasLLMsbecomemorepowerful(withlesshallucination),wecanlookforwardtoaday
whenitwillbepossibletonearlylosslesslyextractthefullmemoryofanLLMintoplaintext.
5.2 EthicalConcerns
5.2.1 TrainingDataSecurityandThreatstoCurrentLLMDominance
AsdiscussedinSection5.1.3, PersonaHuboffersanopportunitytoaccessthefullmemoryofa
targetLLM.However,thisalsointroducesasignificantissue: thesecurityofthetrainingdata. All
data synthesized through the target LLM essentially represents a form of its seen training data.
Therefore,theprocessofextensivelyextractingatargetLLM’smemoryisessentiallydumpingits
trainingdata,eventhoughthisprocessisgenerallylossy.
Moreover,ifweemploythemethoddescribedinSection4.3tosynthesizeinstructions(i.e.,user
prompts)thatnearlycoversallusecasestoqueryatargetLLMtoobtainitsoutputsatscale,thereis
ahighriskthatthetargetLLM’sknowledge,intelligence,andcapabilitiescouldbeextractedand
replicated. ThisposesachallengetotheleadingpositionofthemostpowerfulLLMs,aswehave
alreadyvalidatedinSection4.1throughmathematicalreasoning.
GiventhatcurrentLLMsgenerallysharesimilararchitecturesandtheirperformanceadvantage
primarilyliesintheirdata,thisworkislikelytoimpactthecurrentpracticesandmaypotentially
serveasaturningpoint,acceleratingtheshiftinthecompetitivelandscapeofLLMsfromonethat
heavilydependsondataadvantagetoonethatfocusesonmoreadvancedtechnologies.
5.2.2 Miscellaneous
Syntheticdatapresentsageneralconcernofmisinformationandfakenews,whichhasbeenfre-
quentlydiscussedinpreviousresearch(Panetal.,2023). PersonaHubpotentiallyamplifiesthis
issue,asdiversepersonasbringdiversewritingstyles,makingmachine-generatedtextsharderto
distinguishfromhuman-generatedcontent(Chakrabortyetal.,2023). Thisincreaseddifficultyin
detectionmayworsenissuesrelatedtodatacontamination,wheresyntheticdataismixedwithreal
data,potentiallyskewingresearchresultsandpublicinformation.
6 ConclusionandFutureWork
Weproposeanovelpersona-drivendatasynthesismethodologyandpresentPersonaHub,acol-
lection of 1 billion diverse personas automatically curated from web data. We show that this
methodologycanfacilitatethescalingofsyntheticdatacreationacrossvariousscenarios,demon-
stratingitspotentialtorevolutionizecreationandapplicationsofsyntheticdata,anditsprospectsas
ageneraldatasynthesisengineforbothresearchandpractice.
AsthefirstversionofPersonaHub,althoughitalreadycontains1billionpersonas,thedescriptions
ofthesepersonasarefocusedonlyonmajoraspectsandlackfine-graineddetails(e.g.,preferences
forcolorsandnumbers;specificfamilybackgrounds,historicalcontexts,andlifeexperiences). We
plantorefinethepersonasinsubsequentversionsofPersonaHub,aimingfortheirdescriptionsto
beasdetailedasthosefoundinWikipediaarticlesaboutindividuals. Thesemoredetailedpersona
descriptionswillmakeeachpersonamoreunique,therebyscalingupPersonaHubandfostering
moreopportunitiesforsyntheticdatacreation,whilealsoempoweringpracticalapplicationssuch
aspersonalizedconversations(e.g.,character.ai).
17TechnicalReport
Also,whilethisworkonlyexploresdatasynthesiswithtext-basedLLMs,themethodologyshould
also be applicable to multimodal LLMs. Therefore, we will explore multi-modal synthetic data
creation as a future direction. Moreover, given that specific personas can elicit corresponding
perspectivesfromLLMs,wearecuriousaboutthepossibilitiesofusingsomesuperpersonasto
guideLLMstoexplorebeyondthescopeofexistingknowledge. Thismayprovideanewapproach
totappingintothesuperintelligenceofLLMs,whichwillbestudiedinthefuture.
References
Qwen2technicalreport. 2024.
Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany
Awadalla,NguyenBach,AmitBahree,ArashBakhtiari,HarkiratBehl,etal. Phi-3technicalreport:
Ahighlycapablelanguagemodellocallyonyourphone. arXivpreprintarXiv:2404.14219,2024.
JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAleman,
DiogoAlmeida,JankoAltenschmidt,SamAltman,ShyamalAnadkat,etal. Gpt-4technicalreport.
arXivpreprintarXiv:2303.08774,2023.
Yuelin Bai, Xinrun Du, Yiming Liang, Yonggang Jin, Ziqiang Liu, Junting Zhou, Tianyu Zheng,
Xincheng Zhang, Nuo Ma, Zekun Wang, et al. Coig-cqia: Quality is all you need for chinese
instructionfine-tuning. arXivpreprintarXiv:2403.18058,2024.
Andre´ Bauer,SimonTrapp,MichaelStenger,RobertLeppich,SamuelKounev,MarkLeznik,Kyle
Chard,andIanFoster. Comprehensiveexplorationofsyntheticdatageneration: Asurvey. arXiv
preprintarXiv:2401.02524,2024.
XiaoBi,DeliChen,GuantingChen,ShanhuangChen,DamaiDai,ChengqiDeng,HonghuiDing,
KaiDong,QiushiDu,ZheFu,etal. Deepseekllm: Scalingopen-sourcelanguagemodelswith
longtermism. arXivpreprintarXiv:2401.02954,2024.
AndreiZBroder. Ontheresemblanceandcontainmentofdocuments. InProceedings.Compression
andComplexityofSEQUENCES1997(Cat.No.97TB100171),pp.21–29.IEEE,1997.
TianleCai,XuezhiWang,TengyuMa,XinyunChen,andDennyZhou. Largelanguagemodelsas
toolmakers. arXivpreprintarXiv:2305.17126,2023.
SouradipChakraborty,AmritSinghBedi,SichengZhu,BangAn,DineshManocha,andFurong
Huang. Onthepossibilitiesofai-generatedtextdetection. arXivpreprintarXiv:2304.04736,2023.
WenhuChen,XueguangMa,XinyiWang,andWilliamWCohen. Programofthoughtsprompt-
ing: Disentangling computationfromreasoningfor numerical reasoning tasks. arXiv preprint
arXiv:2211.12588,2022.
HyeongKyuChoiandYixuanLi. Picle: Elicitingdiversebehaviorsfromlargelanguagemodels
withpersonain-contextlearning. InForty-firstInternationalConferenceonMachineLearning,2024.
TogetherComputer. Redpajama: anopendatasetfortraininglargelanguagemodels,2023. URL
https://github.com/togethercomputer/RedPajama-Data.
Gre´goireDele´tang,AnianRuoss,Paul-AmbroiseDuquenne,ElliotCatt,TimGenewein,Christo-
pherMattern,JordiGrau-Moya,LiKevinWenliang,MatthewAitchison,LaurentOrseau,etal.
Languagemodelingiscompression. arXivpreprintarXiv:2309.10668,2023.
ElvisDohmatob,YunzhenFeng,PuYang,FrancoisCharton,andJuliaKempe. Ataleoftails: Model
collapseasachangeofscalinglaws. arXivpreprintarXiv:2402.07043,2024.
KanishkGandhi,DorsaSadigh,andNoahDGoodman. Strategicreasoningwithlanguagemodels.
arXivpreprintarXiv:2305.19165,2023.
18TechnicalReport
TaoGe,HuJing,LeiWang,XunWang,Si-QingChen,andFuruWei. In-contextautoencoderfor
contextcompressioninalargelanguagemodel. InTheTwelfthInternationalConferenceonLearning
Representations,2024. URLhttps://openreview.net/forum?id=uREj4ZuGJE.
DanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,
andJacobSteinhardt. Measuringmathematicalproblemsolvingwiththemathdataset. arXiv
preprintarXiv:2103.03874,2021.
YimingHuang,XiaoLiu,YeyunGong,ZhibinGou,YelongShen,NanDuan,andWeizhuChen.
Key-point-drivendatasynthesiswithitsenhancementonmathematicalreasoning. arXivpreprint
arXiv:2403.02333,2024.
Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, and Hakim Sidahmed. Faithful
persona-based conversational dataset generation with large language models. arXiv preprint
arXiv:2312.10007,2023.
JaredKaplan,SamMcCandlish,TomHenighan,TomBBrown,BenjaminChess,RewonChild,Scott
Gray,AlecRadford,JeffreyWu,andDarioAmodei. Scalinglawsforneurallanguagemodels.
arXivpreprintarXiv:2001.08361,2020.
ChenLi, WeiqiWang, JingchengHu, YixuanWei, NanningZheng, HanHu, ZhengZhang, and
HouwenPeng. Common7blanguagemodelsalreadypossessstrongmathcapabilities. arXiv
preprintarXiv:2403.04706,2024a.
HaoranLi, QingxiuDong, ZhengyangTang, ChaojunWang, XingxingZhang, HaoyangHuang,
ShaohanHuang,XiaolongHuang,ZeqiangHuang,DongdongZhang,etal.Syntheticdata(almost)
fromscratch: Generalizedinstructiontuningforlanguagemodels. arXivpreprintarXiv:2402.13064,
2024b.
JunyiLi,NinarehMehrabi,CharithPeris,PalashGoyal,Kai-WeiChang,AramGalstyan,Richard
Zemel, and Rahul Gupta. On the steerability of large language models toward data-driven
personas. arXivpreprintarXiv:2311.04978,2023a.
YuanzhiLi,Se´bastienBubeck,RonenEldan,AllieDelGiorno,SuriyaGunasekar,andYinTatLee.
Textbooksareallyouneedii: phi-1.5technicalreport. arXivpreprintarXiv:2309.05463,2023b.
RuiboLiu,JerryWei,FangyuLiu,ChengleiSi,YanzheZhang,JinmengRao,StevenZheng,Daiyi
Peng, Diyi Yang, Denny Zhou, et al. Best practices and lessons learned on synthetic data for
languagemodels. arXivpreprintarXiv:2404.07503,2024.
Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. Dynamic llm-agent network: An
llm-agentcollaborationframeworkwithagentteamoptimization. arXivpreprintarXiv:2310.02170,
2023.
PratyushMaini,SkylerSeto,HeBai,DavidGrangier,YizheZhang,andNavdeepJaitly. Rephras-
ing the web: A recipe for compute and data-efficient language modeling. arXiv preprint
arXiv:2401.16380,2024.
YikangPan,LiangmingPan,WenhuChen,PreslavNakov,Min-YenKan,andWilliamYangWang.On
theriskofmisinformationpollutionwithlargelanguagemodels. arXivpreprintarXiv:2305.13661,
2023.
JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,andMichaelS
Bernstein. Generativeagents: Interactivesimulacraofhumanbehavior. InProceedingsofthe36th
AnnualACMSymposiumonUserInterfaceSoftwareandTechnology,pp.1–22,2023.
TimoSchick,JaneDwivedi-Yu,RobertoDess`ı,RobertaRaileanu,MariaLomeli,EricHambro,Luke
Zettlemoyer,NicolaCancedda,andThomasScialom. Toolformer: Languagemodelscanteach
themselvestousetools. AdvancesinNeuralInformationProcessingSystems,36,2024.
19TechnicalReport
Murray Shanahan, Kyle McDonell, and Laria Reynolds. Role play with large language models.
Nature,623(7987):493–498,2023.
Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Ander-
son. The curse of recursion: Training on generated data makes models forget. arXiv preprint
arXiv:2305.17493,2023.
QwenTeam. Introducingqwen1.5,February2024. URLhttps://qwenlm.github.io/blog/qwen1.
5/.
JeffreyTraversandStanleyMilgram. Anexperimentalstudyofthesmallworldproblem. InSocial
networks,pp.179–197.Elsevier,1977.
PabloVillalobos,AnsonHo,JaimeSevilla,TamayBesiroglu,LennartHeim,andMariusHobbhahn.
Position: Will we run out of data? limits of llm scaling based on human-generated data. In
Forty-firstInternationalConferenceonMachineLearning,2024.
KeWang,HouxingRen,AojunZhou,ZimuLu,SichunLuo,WeikangShi,RenruiZhang,LinqiSong,
MingjieZhan,andHongshengLi. Mathcoder: Seamlesscodeintegrationinllmsforenhanced
mathematicalreasoning. arXivpreprintarXiv:2310.03731,2023.
YizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,NoahASmith,DanielKhashabi,and
HannanehHajishirzi. Self-instruct: Aligninglanguagemodelswithself-generatedinstructions.
arXivpreprintarXiv:2212.10560,2022.
ZhenhailongWang,ShaoguangMao,WenshanWu,TaoGe,FuruWei,andHengJi. Unleashing
theemergentcognitivesynergyinlargelanguagemodels: Atask-solvingagentthroughmulti-
personaself-collaboration. InProceedingsofthe2024ConferenceoftheNorthAmericanChapterofthe
AssociationforComputationalLinguistics: HumanLanguageTechnologies(Volume1: LongPapers),pp.
257–279,2024.
ZiweiXu,SanjayJain,andMohanKankanhalli. Hallucinationisinevitable: Aninnatelimitationof
largelanguagemodels. arXivpreprintarXiv:2401.11817,2024.
AlexYoung,BeiChen,ChaoLi,ChengenHuang,GeZhang,GuanweiZhang,HengLi,Jiangcheng
Zhu, Jianqun Chen, Jing Chang, et al. Yi: Open foundation models by 01. ai. arXiv preprint
arXiv:2403.04652,2024.
LonghuiYu,WeisenJiang,HanShi,JinchengYu,ZhengyingLiu,YuZhang,JamesTKwok,Zhenguo
Li,AdrianWeller,andWeiyangLiu. Metamath: Bootstrapyourownmathematicalquestionsfor
largelanguagemodels. arXivpreprintarXiv:2309.12284,2023.
YadongZhang,ShaoguangMao,TaoGe,XunWang,AdriandeWynter,YanXia,WenshanWu,Ting
Song,ManLan,andFuruWei. Llmasamastermind: Asurveyofstrategicreasoningwithlarge
languagemodels. arXivpreprintarXiv:2404.01230,2024.
Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng. Wildchat:
1m chatGPT interaction logs in the wild. In The Twelfth International Conference on Learning
Representations,2024. URLhttps://openreview.net/forum?id=Bl8u7ZRlbM.
QihaoZhu,DayaGuo,ZhihongShao,DejianYang,PeiyiWang,RunxinXu,YWu,YukunLi,Huazuo
Gao,ShirongMa,etal. Deepseek-coder-v2: Breakingthebarrierofclosed-sourcemodelsincode
intelligence. arXivpreprintarXiv:2406.11931,2024.
20