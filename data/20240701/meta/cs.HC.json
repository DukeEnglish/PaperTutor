[
    {
        "title": "ProgressGym: Alignment with a Millennium of Moral Progress",
        "authors": "Tianyi QiuYang ZhangXuchuan HuangJasmine Xinze LiJiaming JiYaodong Yang",
        "links": "http://arxiv.org/abs/2406.20087v1",
        "entry_id": "http://arxiv.org/abs/2406.20087v1",
        "pdf_url": "http://arxiv.org/pdf/2406.20087v1",
        "summary": "Frontier AI systems, including large language models (LLMs), hold increasing\ninfluence over the epistemology of human users. Such influence can reinforce\nprevailing societal values, potentially contributing to the lock-in of\nmisguided moral beliefs and, consequently, the perpetuation of problematic\nmoral practices on a broad scale. We introduce progress alignment as a\ntechnical solution to mitigate this imminent risk. Progress alignment\nalgorithms learn to emulate the mechanics of human moral progress, thereby\naddressing the susceptibility of existing alignment methods to contemporary\nmoral blindspots. To empower research in progress alignment, we introduce\nProgressGym, an experimental framework allowing the learning of moral progress\nmechanics from history, in order to facilitate future progress in real-world\nmoral decisions. Leveraging 9 centuries of historical text and 18 historical\nLLMs, ProgressGym enables codification of real-world progress alignment\nchallenges into concrete benchmarks. Specifically, we introduce three core\nchallenges: tracking evolving values (PG-Follow), preemptively anticipating\nmoral progress (PG-Predict), and regulating the feedback loop between human and\nAI value shifts (PG-Coevolve). Alignment methods without a temporal dimension\nare inapplicable to these tasks. In response, we present lifelong and\nextrapolative algorithms as baseline methods of progress alignment, and build\nan open leaderboard soliciting novel algorithms and challenges. The framework\nand the leaderboard are available at\nhttps://github.com/PKU-Alignment/ProgressGym and\nhttps://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard\nrespectively.",
        "updated": "2024-06-28 17:55:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.20087v1"
    },
    {
        "title": "Concept Lens: Visually Analyzing the Consistency of Semantic Manipulation in GANs",
        "authors": "Sangwon JeongMingwei LiMatthew BergerShusen Liu",
        "links": "http://dx.doi.org/10.1109/VIS54172.2023.00053",
        "entry_id": "http://arxiv.org/abs/2406.19987v1",
        "pdf_url": "http://arxiv.org/pdf/2406.19987v1",
        "summary": "As applications of generative AI become mainstream, it is important to\nunderstand what generative models are capable of producing, and the extent to\nwhich one can predictably control their outputs. In this paper, we propose a\nvisualization design, named Concept Lens, for jointly navigating the data\ndistribution of a generative model, and concept manipulations supported by the\nmodel. Our work is focused on modern vision-based generative adversarial\nnetworks (GAN), and their learned latent spaces, wherein concept discovery has\ngained significant interest as a means of image manipulation. Concept Lens is\ndesigned to support users in understanding the diversity of a provided set of\nconcepts, the relationship between concepts, and the suitability of concepts to\ngive semantic controls for image generation. Key to our approach is the\nhierarchical grouping of concepts, generated images, and the associated joint\nexploration. We show how Concept Lens can reveal consistent semantic\nmanipulations for editing images, while also serving as a diagnostic tool for\nstudying the limitations and trade-offs of concept discovery methods.",
        "updated": "2024-06-28 15:18:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.19987v1"
    },
    {
        "title": "BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5",
        "authors": "Zhehuai ChenHe HuangOleksii HrinchukKrishna C. PuvvadaNithin Rao KoluguriPiotr ŻelaskoJagadeesh BalamBoris Ginsburg",
        "links": "http://arxiv.org/abs/2406.19954v1",
        "entry_id": "http://arxiv.org/abs/2406.19954v1",
        "pdf_url": "http://arxiv.org/pdf/2406.19954v1",
        "summary": "Incorporating speech understanding capabilities into pretrained\nlarge-language models has become a vital research direction (SpeechLLM). The\nprevious architectures can be categorized as: i) GPT-style, prepend speech\nprompts to the text prompts as a sequence of LLM inputs like a decoder-only\nmodel; ii) T5-style, introduce speech cross-attention to each layer of the\npretrained LLMs. We propose BESTOW architecture to bring the BESt features from\nTwO Worlds into a single model that is highly efficient and has strong\nmultitask capabilities. Moreover, there is no clear streaming solution for\neither style, especially considering the solution should generalize to speech\nmultitask. We reformulate streamable SpeechLLM as a read-write policy problem\nand unifies the offline and streaming research with BESTOW architecture. Hence\nwe demonstrate the first open-source SpeechLLM solution that enables Streaming\nand Multitask at scale (beyond ASR) at the same time. This streamable solution\nachieves very strong performance on a wide range of speech tasks (ASR, AST,\nSQA, unseen DynamicSuperb). It is end-to-end optimizable, with lower\ntraining/inference cost, and demonstrates LLM knowledge transferability to\nspeech.",
        "updated": "2024-06-28 14:40:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.19954v1"
    },
    {
        "title": "Interactive Topic Models with Optimal Transport",
        "authors": "Garima DhananiaSheshera MysoreChau Minh PhamMohit IyyerHamed ZamaniAndrew McCallum",
        "links": "http://arxiv.org/abs/2406.19928v1",
        "entry_id": "http://arxiv.org/abs/2406.19928v1",
        "pdf_url": "http://arxiv.org/pdf/2406.19928v1",
        "summary": "Topic models are widely used to analyze document collections. While they are\nvaluable for discovering latent topics in a corpus when analysts are unfamiliar\nwith the corpus, analysts also commonly start with an understanding of the\ncontent present in a corpus. This may be through categories obtained from an\ninitial pass over the corpus or a desire to analyze the corpus through a\npredefined set of categories derived from a high level theoretical framework\n(e.g. political ideology). In these scenarios analysts desire a topic modeling\napproach which incorporates their understanding of the corpus while supporting\nvarious forms of interaction with the model. In this work, we present EdTM, as\nan approach for label name supervised topic modeling. EdTM models topic\nmodeling as an assignment problem while leveraging LM/LLM based document-topic\naffinities and using optimal transport for making globally coherent\ntopic-assignments. In experiments, we show the efficacy of our framework\ncompared to few-shot LLM classifiers, and topic models based on clustering and\nLDA. Further, we show EdTM's ability to incorporate various forms of analyst\nfeedback and while remaining robust to noisy analyst inputs.",
        "updated": "2024-06-28 13:57:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.19928v1"
    },
    {
        "title": "The Relationship Between Time and Distance Perception in Egocentric and Discrete Virtual Locomotion (Teleportation)",
        "authors": "Matthias WölwerDaniel Zielasko",
        "links": "http://arxiv.org/abs/2406.19895v1",
        "entry_id": "http://arxiv.org/abs/2406.19895v1",
        "pdf_url": "http://arxiv.org/pdf/2406.19895v1",
        "summary": "Traveling distances in the real world inherently involves time, as moving to\na desired location is a continuous process. This temporal component plays a\nrole when estimating the distance covered. However, in virtual environments,\nthis relationship is often changed or absent. Common teleportation techniques\nenable instantaneous transitions, lacking any temporal element that might aid\nin distance perception. Since distances are found to be commonly underestimated\nin virtual environments, we investigate the influence of time on this\nmisperception, specifically in target-selection-based teleportation interfaces.\nOur first experiment explores how introducing a delay proportional to the\ndistance covered by teleportation affects participants' perception of\ndistances, focusing on underestimation, accuracy, and precision. Participants\nare required to teleport along a predefined path with varying delays. A second\nexperiment is designed to determine whether this effect manifests in a more\napplication-specific scenario. The results indicate a significant reduction in\ndistance underestimation, improving from 27% to 16.8% with a delayed\nteleportation method. Other sub-scales of distance estimation hardly differ.\nDespite targeted adaptations of previous study designs, participants have again\nfound strategies supporting them in estimating distances. We conclude that time\nis a factor affecting distance perception and should be considered alongside\nother factors identified in the literature.",
        "updated": "2024-06-28 13:03:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.19895v1"
    }
]