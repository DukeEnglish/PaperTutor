UV-free Texture Generation with
Denoising and Geodesic Heat Diffusions
SimoneFoti StefanosZafeiriou TolgaBirdal
DepartmentofComputing
ImperialCollegeLondon
Figure1: Randomtexturesgeneratedbyourmethod,Uv3-TeD,onthesurfaceofgeneralobjects
fromtheAmazonBerkeleyObjectdatasetandofchairsfromShapeNet(miniaturesontheshelves).
Abstract
Seams,distortions,wastedUVspace,vertex-duplication,andvaryingresolution
overthesurfacearethemostprominentissuesofthestandardUV-basedtexturing
ofmeshes. TheseissuesareparticularlyacutewhenautomaticUV-unwrapping
techniquesareused. Forthisreason,insteadofgeneratingtexturesinautomatically
generatedUV-planeslikemoststate-of-the-artmethods,weproposetorepresent
textures as coloured point-clouds whose colours are generated by a denoising
diffusionprobabilisticmodelconstrainedtooperateonthesurfaceof3Dobjects.
Our sampling and resolution agnostic generative model heavily relies on heat
diffusionoverthesurfaceofthemeshesforspatialcommunicationbetweenpoints.
Toenableprocessingofarbitrarilysampledpoint-cloudtexturesandensurelong-
distancetextureconsistencyweintroduceafastre-samplingofthemeshspectral
properties used during the heat diffusion and introduce a novel heat-diffusion-
basedself-attentionmechanism. Ourcodeandpre-trainedmodelsareavailableat
github.com/simofoti/UV3-TeD.
Preprint.Underreview.
4202
guA
92
]VC.sc[
1v26761.8042:viXra1 Introduction
Meshesaresurfacediscretisationsintentionallydesignedtorepresentthegeometryof3Dobjects.
Sincerealobjectsaremorethanjusttheirgeometry,meshesarefrequentlyaugmentedwithtextures,
representingappearances. Currently,texturesaremostlyrepresentedasimagesthatcanbewrapped
onthemeshviaaUV-mappingprocedurethatmapseverypointonthesurfaceofthemeshintoa
pointontheUV-image-planewheretextureinformationarestored. Texturesarethereforemostly
generated on images, but considering that UV-maps intrinsically suffer from distortions, seams,
wastedUV-space,vertex-duplication,andvaryingresolution[19],isUV-mappingreallythebest
approach? In this work, we wonder: what if instead of generating a texture on a plane and then
wrappingitontoashapewecoulddirectlygenerateatextureonthecurvedsurfaceoftheobject?
ThecapabilityofgeneratingtexturesbyavoidingUV-unwrappingandmappingaltogetheralleviates
thepost-processingissuescausedbytheUV-mappingandcansavetimeandresourcesformany
3D artists, while generally improving the realism of the textures by avoiding distortions, seams,
orstretchingartefacts. Inaddition,itcouldenablethecreationofpriorsforavarietyofcomputer
visiontasksrangingfromshapeandappearancereconstructiontoobjectdetection,identification,
andtracking. Moregenerally,atexturerepresentationadheringtotheactualgeometryofthesurface
couldresultinsmallermemoryfootprintswithoutcompromisingontherenderingquality.
Whilemoststate-of-the-artmethodsfocusongeneratingtexturesinUV-space[23,7,62,56,13,34,
12,42,41]andthusinheritallthedrawbacksofUV-mapping(Fig.2,left),weproposetorepresent
textureswithunstructuredpoint-cloudssampledonthesurfaceofanobjectanddeviseatechniqueto
renderthemwithoutgoingthroughUV-mapping(Fig.2,right). Wegeneratepoint-cloudtextures
withadenoisingdiffusionprobabilisticmodeloperatingexclusivelyonthesurfaceofthemeshes.
Thisisfundamentallydifferentfromgeneratingcolouredpoint-clouds[58]ortriplane-basedimplicit
textures[8]:whileourworkrespectsthegeodesicinformationprovidedbythemeshes,theyoperatein
theEuclideanspaceandignorethetopologyoftheobjectstheyseektotexturise. Whencomparedto
methodslike[49],whichcangeneratetexturesdirectlyonthesurface,ourmethodhastheadvantage
ofnotrequiringanyremeshingoperationandbeingadaptabletodifferentsamplingresolutions. In
addition,unlikemanyothertexturegenerationmethods[7,12,42,49],wegeneratealbedotextures
thatbynotfactoringintheenvironmentcanberenderedwithdifferentlightingconditionstoachieve
morephotorealisticresults(Fig.1). Finally,whilemostmethodsareclass-specific,ourmethodcan
betrainedondatasetscontainingobjectsofdifferentclasses(Fig.1). Ourkeycontributionsare:
1. Wecreateadenoisingdiffusionprobabilisticmodelgeneratingpoint-cloudtexturesbyoperating
onlyonthesurfaceofthemeshes,
2. Weintroduceanovelattentionlayerbasedonheatdiffusionandfarthestpointsamplingtoimprove
therecentlyproposedDiffusionNetblocks[48]byfacilitatingglobalcommunicationacrossthe
entiresurfaceoftheobject,
3. We propose a mixed Laplacian operator to ensure that heat diffusion can spread even in the
presence of topological errors and disconnected components while still mostly relying on the
providedtopologicalinformation,
4. Wedeviseanonlinesamplingstrategythatallowsustosamplepoint-cloudsandtheirspectral
propertiesduringtrainingwithoutrequiringtorecomputethemfromscratch.
2 RelatedWork
TextureRepresentationsandRendering. Texturesaretraditionallyrepresentedbyimageswhich
aremappedonto3DshapesviaaUV-mapping. SincemanualUV-mappingiscomplexandlabour-
intensive, many methods tried to perform it automatically while attempting to address some of
the most common artefacts: seams and distortion [44, 39]. Other texture representations such
as[19,50,2,61]havebeenproposedwithoutfindingalevelofadoptioncomparabletotheoneof
UV-textures,whicharestillthedefactostandardformodellingtheappearanceofmeshes. Although
arguablythemostconvenientshaperepresentationforcomputergraphicsapplications,meshesare
not the only data structure used to represent 3D shapes. In fact, point-clouds are equally spread
andtheycanalsobeassociatedwithappearanceinformation,storedascolourvaluesassociatedto
eachpoint. Manytechniqueshavetriedtoreducetheirsparsitywhilerendering[46,45,10], but
whenphoto-realismisrequired,texturedmeshesarestillasuperiorrepresentationwhichcanbetter
approximatecontinuoussurfaces. Giventhestrengthsandlimitationsofbothrepresentations,we
proposetoadoptahybridapproachwherethegeometryisrepresentedbyameshanditsappearance
2Figure2: Qualitativecomparisonbetweenpoint-cloud-textures(top-righthalves)andautomatically
wrappedUV-textures(bottom-lefthalves). AlltexturesweregeneratedbyPoint-UVDiffusionin
ordertoshowcasesomeofthemostcommonissuesofUV-mapping. Althoughthemethodgenerated
goodqualitytexturesaspoint-clouds,projectingtheminUV-spaceintroducessignificantartefacts.
byanunstructuredpoint-cloudtexture. Thiscanpreventseams,distortions,unusedUV-space,and
varying resolution while still enabling the rendering of continuous surfaces. Hybrid approaches
mixingmeshesandpoint-cloudshavealsobeenproposedby[18]and[60,59]. However,in[18]the
appearancewaspresentinbothrepresentations,whichwerebothrendered,and[60,59]usedhighly
structuredpoint-cloudswithpointsregularlypositionedonthemeshfaces. Therepresentationof
[60,59]canbeusedonlyforhigh-resolutiontexturesrequiringsignificantlymorepointsthanthe
numberofvertices,thusmakingitincompatiblewithcurrentgeometricdeeplearningmodels. For
thisreason,weuseunstructuredpoint-cloudtexturesarbitrarilysampledatanyrequiredresolution.
Texture Generation. Many texture generation techniques have been proposed, each relying on
a different representation. Considering the wide adoption of UV-textures, and the maturity of
deep-learning techniques operating on the image domain, it is not surprising that most methods
still rely on UV-mapping and generate UV-images to wrap on meshes [23, 7, 62, 56, 13], or
simultaneouslyoptimisemeshesandtexturetoachievethedesiredresult[34]. Alternatively,another
commonapproachconsistsinusingagenerativemodeltogeneratedepth-conditionedimagesfrom
multiple viewpoints. These images are then projected onto a mesh, refined, and stored as UV-
textures[12,42,41]. OthermethodstrytomaptexturesonUV-spheres[14], tri-planes[22,53],
NeRFs [1, 32], or implicit functions [35], but they either fail to operate on the real geometry of
the object or they end up-projecting the textures on a UV-plane. Even Point-UV Diffusion [58],
whosecoarsestageisconceptuallysimilartooursbecauseitgeneratescolouredpoint-cloudsusing
point-cloudoperators,effectivelyprojectspointsinUV-texturesthatarerefinedwithimagediffusion
models. Unfortunately,especiallyatthecoarsestage,thisoftenresultsinthevisibleartefactsthatare
typicalofthisparametrisation(Fig.2). Amethodcapableofoperatingdirectlyonthesurfaceofthe
objectsisTexturify[49],whichshowsremarkableresultsadoptingashape-conditionedStyle-GAN
convolvingcolouredquad-faces. Themainlimitationofthismethodisitsneedtouniformlyre-mesh
theinputshapestoafixedresolution,potentiallyaffectingthequalityoftheoriginalmesh. Mostof
thesemethodsaretrainedonclass-specificshapessuggestingtheirdifficultiesindealingwithmulti-
classdatasets. Whileourmethodcanactuallyoperateondatasetswithshapesbelongingtodifferent
classes,somemethodsexacerbatethesingle-classlimitation,focusingexclusivelyontrainingtheir
modelsonsingleshapestothengeneratetexturevariations[54,33]. Similarly,manifolddiffusion
fields [20] are capable of generating continuous functions –such as textures– over Riemannian
manifolds. Unfortunately, theygeneratefunctionsonlyonmanifoldmeshesandtheyarealways
trainedonsingle-shapedatasetswithmultiplefunctionvariations. Itisunclearwhethertheirmethod
wouldbecapableofgeneralisingtodifferentgeometries.
3 NotationandBackground
WedefineameshasM = {V,F},withV ∈ RV×3 representingthepositionsoftheV vertices
sampled on the surface (S) of a shape, and F ∈ NF×3 the set of triangular faces describing the
connectivity of the vertices. Throughout this work, we assume that the vertex positions and the
meshtopologyaregiven,butdifferentforeveryshapewewanttotexturise. Wethinkoftextuersas
continuousfunctionsx : S → X mappingpointsonS toasignalspaceX that,withoutanyloss
ofgenerality,correspondstothealbedocolours,i.e.,X =R3. Inpractice,weoperateontextures
definedascolouredpoint-cloudswithcoloursX=x(P)∈RP×3,whereP∈RP×3representsthe
P 3DcoordinatesofthepointssampledonS. Notethat,ingeneral,weassumeP̸=V(andP ̸=V)
asthetexturepoint-cloudsdonotnecessarilyneedtofollowthesamevertexdistribution.
3BeforeintroducingthemaincontributionsofourworkinSec.4,weformalisetwopillarsonwhich
webaseourmethod: thedenoisingdiffusionmodelsandtheLaplaceBeltramioperator.
DenoinsingDiffusionProbabilisticModel.DenoisingDiffusionProbabilisticModels[26](DDPMs)
arenowawell-establishedclassofgenerativemodelsthatrapidlyfoundadoptionacrossdifferent
fields[11,31]. TheyareparameterisedbyaMarkovchaintrainedusingvariationalinferenceand
are essentially characterised by three steps: a forward noising procedure, a backward denoising,
and a sampling procedure that is used during inference. During the forward process, a training
sample X ∼ p(X ) corresponding to a point-cloud texture and coming from the original tex-
0 0
turesdistributionattimestep0isiterativelyperturbedto{X }T byprogressivelyaddingasmall
t t=1 √
amountofisotropicGaussiannoiseϵ ∼N(0,I). Beingp(X |X ):=N(X ; 1−β X ,β I)
0 t t−1 t t t t
a single step in the discrete forward chain with noise schedule β , we represent the full chain
t
as p(X |X ) =
(cid:81)T
p(X |X ). Similarly, a generic step in the chain can be obtained as
T 0 t=√1 t t−1
p(X |X ):=N(X ; α¯ X ,(1−α¯ )I),whereIistheidentitymatrix,α¯
=(cid:81)t
α ,andα =
t 0 t t t√ t √ t s=1 s t
1−β .ThisimpliesthatX = α¯ X + 1−α¯ ϵ .InDDPMmodelslikeours,thereverseprocessis
t t t 0 t 0
parameterisedbyaneuralnetworktrainedtopredictthenoisethatneedstobeprogressivelyremoved.
Thisprocessisformulatedasp θ(X t−1|X t):=N(cid:16) X t−1;√1 αt(cid:0) X t− √1 1− −α α¯t tϵ θ(X t,t)(cid:1) ,β tI(cid:17) ,where
thevarianceisempiricallyfixedandthemeanisleveragingthenoisepredictionnetworkϵ (X ,t).
θ t
ThevariationalinferenceobjectivecanthusbesimplifiedtoL=E (cid:2) ∥ϵ −ϵ (X ,t)∥2(cid:3) . Finally,
Xt,t t θ t 2
thesamplingprocessfollowsthereverseprocesswherethetrainednetworktransformsnoisesamples
comingfromtheterminaldistributionX ∼p(X )intothedenoisedXˆ ∼p (X )≈p(X ).
T T 0 θ 0 0
EigenpropertiesofLaplaceBeltramiOperator. TheLaplaceBeltramioperator(LBO)playsan
essentialroleingeometryprocessing. Fortrianglemeshes,theLBOisusuallybasedonacotangent
formulation[38,63]derivedfromfiniteelementanalysis. ThecotangentLaplacianL∈RV×V is
asparsematrixwithelementsproportionaltothecotangentoftheanglessubtendedbytheedges,
anditisassociatedtoadiagonalmassmatrixM∈RV×V whosediagonalelementsareproportional
to the total area of the faces surrounding each vertex [47]. The eigendecomposition of the LBO,
LΦ=ΛMΦ,determinesasetoforthonormaleigenvectorsΦ:=[ϕ ]K ∈RV×K corresponding
k k=1
totheK smallesteigenvaluesΛ:=[λ ]K ∈RK oftheweakLaplaciananditsmassmatrix. These
k k=1
eigenvaluesandeigenvectorshavebeenintensivelystudiedinspectralgeometrybecausenotonlycan
theybeusedasglobalandlocalshapedescriptors,buttheycanalsobeusedtoformulatesurface
operationssuchasheatdiffusion [63]. Asthenamesuggests,heatdiffusionregulatesthephysical
heatdispersion. Thisphenomenoncanbemodelledonanydiscretesurfacerepresentationwitha
Laplacianoperatoranditisresolution,sampling,andrepresentationindependent.
4 UV-freeTextureDiffusion(UV3-TeD)
WenowdescribeUV3-TeD,ourgenerativemodelforlearningpoint-cloudtexturesbuiltuponheat-
diffusion-basedoperatorsspecificallydesignedtooperateonthesurfaceoftheinputshapes(detailed
inSec.4.1anddepictedinFig.4). OurdiffusionmodelUV3-TeDoperatesonanoisedversionof
thecolours,X ,andpredictsadenoisedX throughaU-Net[43]shapedarchitecture(Fig.9),
t t−1
backedbynovelattention-enhancedheatdiffusionblocks(Sec.4.1). Werepresenteverymesh,M,
byanovelmixedLBO,informedbothbythegeometryandthetopologyofM(Sec.4.2). Wefurther
introduceanonlinesampling,inordertoobtainapoint-cloudPwithcorrespondingalbedocolours
Xandtailoredspectraloperators(Sec.4.3). UV3-TeDistrainedwithadenoisingobjectivedescribed
inSec.3,usingheterogeneousbatching. Mesheswithapoint-cloudtexturecanfinallyberendered
bythenearest-neighbourinterpolationwedetailinSec.4.4.
4.1 Attention-enhancedHeatDiffusionBlocks
DiffusionBlocks(DB).OurblocksareinspiredbyDiffusionNet[48],consistingofthreeseparate
learnableparts: heatdiffusion,spatialgradientfeatures,andavertex-wisemulti-layerperceptron
(MLP).Theheatdiffusionprocessisusedtodisperseandaggregateinformationonasurfaceandit
hasaclosed-formsolutionleveragingthespectralpropertiesoftheLBO.Sinceweaimtooperate
on point-cloud textures while leveraging topological and geometric information provided by the
mesh,weuseourtailoredversionsofMandΦlaterdescribedinSec.4.3andnamedΦ andM
p p
4PRECOMPUTE ONLINE SAMPLING
{V, F} LR
mix
{P, X} fps(P)
Λ’
X X
T 0
Λ M
p
UV3-TeD
Φ Φp sihks
Figure3: FrameworkofUV3-TeD.GivenameshM={V,F}weprecomputetheproposedmixed
Laplacian(LR )anditseigendecomposition(ΛandΦ). Duringtheonlinesamplingwecompute
mix
acolouredpoint-cloud{P,X}alongsideitsspectralquantitiesandotherinformationusedbyour
network(Fig.9). Inparticular,eigenvaluesΛ,sampledeigenvectorsΦ ,andapproximatemassM
p p
areusedtocomputetheheatdiffusionoperations(Eq.(1));thefarthestpointsamplesfps(P)are
usedintheproposeddiffusedfarthest-sampledattentionlayers(Fig.4),andthescaleinvariantheat
kernelsignaturessihksandslope-adjustedeigenvaluesΛ′areusedasshapeconditioning. UV3-TeD
leveragestheseinformationtogeneratecolouredpoint-clouds(X )fromnoise(X ).
0 T
respectively. BeingY ∈RP×Y agenericfielddefinedonP,theheatdiffusionlayerisdefinedas:
p
 e−λ1h
.
diffuse(Y p,h):=Φ p . . ⊙(ΦT pM pY), (1)
e−λKh
where⊙istheHadamardproduct,Tisthetransposeoperator,andhisthechannel-specificlearnable
parameter indicating the heat diffusion time and effectively regulating the spatial support of the
operator,whichcanrangefromlocal(h→0)toglobal(h→+∞). Sincethisblocksupportsonly
radiallysymmetricfiltersabouteachpoint, itiscombinedwithaspatialgradientsfeaturesblock
thatexpandsthespaceofpossiblefiltersbycomputingtheinnerproductbetweenpairsoffeature
gradientsundergoingalearnableper-vertexrotationandscalingtransformationinthetangentbundle
(see[48]formoredetails). Thespatialgradientsarecomputedonlineonthesampledpoint-cloud
withourfasterimplementation(seeApp.A.1). Then,theinputisconcatenatedwiththeoutputof
thesetwoblocksandpassedtoaper-vertexMLP(seeFig.4,bottom).
WefurtheraddatimeembeddingrepresentingthedenoisingstepoftheDDPMandintroduceagroup
normalisation[55]tostabilisetrainingafterthetimeinjection. Wealsoaddalinearlayerontheskip
connectionwheninputandoutputchannelsdiffer.,e.g.,whenskipconnectionsfromthedownstream
branchoftheU-Netareconcatenatedwiththefeaturesoftheupstreambranch.
Enhancing DB via Farthest-Sampled Attention. As depicted in Fig. 4, each of our Attention-
enhancedHeatDiffusionBlocksconcatenatethreeDiffusionBlocksandcombinethemwithour
diffusedfarthest-sampledattentionlayer. EventhoughwiththeDiffusionBlocksaloneitistheo-
reticallypossibletoachieveglobalsupportwhenh→+∞,thelongertheheatdiffusiontime,the
closer the diffused features become to the average of the input over the domain. This can result
in less meaningful features causing texture inconsistencies between distant regions. To improve
long-rangeconsistencyweintroduceattentionlayersineachnetwork’sblockalongsidetheother
operators.Sincedirectlyperformingthescaleddotproductoperationcharacterisingattentionmodules
onfull-resolutionpoint-cloudtextureswouldbeprohibitive,webuildupontheheatdiffusionconcept
anddefineamoreefficientattentionoperator(Fig.4,top).
We start by heat-diffusing the Y(i−1) features predicted by the previous layers over P to spread
p
information across the surface geodesically. Then, we collect the spread information (i.e.,
diffuse(Y(i−1),h)) on a subset of the diffused features, S ∈ RS×C, which is obtained by se-
p
lectingthediffusedfeatureswithC channelscorrespondingtotheS farthestsamples[40]ofP. Sis
thenfedtoamulti-headedself-attentionlayer[51],whereasetoflinearlayersfirstcomputesqueries,
keys,andvaluesforeachhead,thencomputesascaleddot-productattention,concatenatestheresults
acrossthedifferentheadsand,aftergoingthroughanadditionallinearlayer,producesanewsetof
featuresoverthefarthestsamples. Thesefeaturesstillresideonthefarthestsamples. Tospreadthem
5HEAT DIFFUSION HEAT DIFFUSION
FARTHEST-SAMPLED
MULTI-HEADED
SELF-ATTENTION
Λ’ e
sihks
e
Y(i-1) + + Yi
p p
HEAT SPATIAL cat + gn
DIFFUSION GRADIENTS
t
e
Figure4: Attention-enhancedHeatDiffusionblock. ThreeconsecutiveDiffusionblocks(bottom)
inspiredby[48]andconditionedwithadenoisingtimeembeddingarecombinedwithadiffused
farthest-sampledattentionlayer(top). Theproposedattention,conditionedwithlocalandglobal
shapeembeddings(sihks andΛ′),firstspreadsinformationtoallthepointsonthesurface,before
e e
computing a multi-headed self-attention on the features of the farthest samples (red points), and
finallyspreadsthembacktoallthepointswithanotherheatdiffusion.
acrosstheentiresurface,wesetthefeaturesoftheotherpointstozeroandperformanotherheat
diffusion. Theoutputofthediffusedfarthest-sampledattentionisre-combinedwiththeoutputofthe
otherblockslearningaper-channelweightingconstant.
Conditioning. Whileotherpoint-cloudnetworksrequireadditionalinputstorepresentthepositions
of the input points alongside their features, we just provide noised colours as inputs because the
diffusionprocessintrinsicallyoperatesonthesurfaceoftheshapeswewanttotexturise.Nevertheless,
wedoprovidegeometricandpositionalconditioningtothediffusedfarthest-sampledattentionlayers,
whichareotherwiseunawareoftherelativepositionoftheirinputs. InsteadofusingPtocompute
thepositionalconditioningdirectly,werelyonthescale-invariantheatkernelsignatures(sihks)[6],
intrinsiclocalshapedescriptorsthatarenotonlysamplingandformatagnosticbutalsoisometryand
scale-invariant. ThegeometryconditioningisobtainedfromtheeigenvaluesΛ,which,likein[24],
arenormalisedbyArea(M)anddeprivedoftheirslopeas:
(cid:110) (cid:12) λ (cid:111)
Λ′ = λ′ (cid:12)λ′ = k −4π∗k, fork =1,...,K . (2)
k (cid:12) k Area(M)
EigenvaluesprocessedasinEq.(2)canstillbeusedasglobalshapedescriptorsthatbesideshaving
theadvantageofbeingscaleinvariantalsofluctuateoverastraightline,becomingeasiertoprocess
foraneuralnetwork. Intuitively,sihkstellustheintrinsiccoordinatesofapoint,whileΛ′whether
wearesupposedtogenerateatextureonachair,asofa,avase,orsomethingelse. Bothareembedded
withaMLPandtheresultinggeometryembeddingsareconcatenatedwiththepointfeatures.
4.2 MixedRobustLaplacian
Tooperateonreal-worlddatasetsweproposeamixedLaplacianoperatorwhichisrobusttoany
triangle mesh and can better diffuse heat in the presence of complex topological structures (see
Fig.5,left). OurmixedrobustLBO(LR )isdefinedas:
mix
LR =(1−ϱ)LR +ϱLR, withϱ∈R. (3)
mix m p
Insteadofusingthecotan-LBOdirectly,weusetherobustmeshLaplacianLR [47],computedonthe
m
verticesofthemesh,asitprovidesrobustnesstonon-orientableandnon-manifoldmeshes.LR ensures
m
thatheatisgeodesicallydiffused, whileLR, itspoint-cloudcounterpart, enablescommunication
p
betweendistinctordisconnectedcomponentsofamesh. Asmallϱvalueleadstodiffusingheaton
thesurfacewhileallowingforsomeheattransmissiontoneighbouringregions(seeFig.5,right).
4.3 OnlineSamplingofPoints,Colours,andSpectralOperators
Oursamplingstrategyisatthecoreofourmethodasitprovidesanefficientsamplingstrategythat
canbeusedonlinewithouthinderingtrainingspeeds. Inparticular,PoissonDiskSamplingproduces
a point-cloud with regularly-spaced points, enabling us to approximate the mass matrix quickly.
6
tach h
Figure5: HeatdiffusiononTedslicedonthebellyandonatopologicallydisconnectedbirdhouse.
UsingthemeshLBOpreventsheatfromspreadingtodisconnectedregions,thisisparticularlyvisible
on Ted as heat does not spread over the nose, mouth, and legs. Similarly, on the birdhouse heat
spreadsonlyontheright-handsideoftheroof. UsingourmixedLBOformulationheatcanspread
overtheentireshapeeveninthepresenceoftopologicalerrorsanddisconnectedcomponents.
To avoid recomputing the eigendecomposition of our Laplacian operator (LR ) on the sampled
mix
point-cloud,werecyclethespectraloperatorsprecomputedontheverticesofthemeshes. Finally,we
describehowcoloursaresampledduringtraining.
PoissonDiskSampling(PSD)[5]. PDSproducesapoint-cloudP∈RP×3,byuniformlysampling
pointsonthesurfaceofamesh. Thisisachievedwithaparalleldart-throwingalgorithmthatusesa
uniformradiusracrossthesurface. Thesamplesp ∈Parerandomlydistributedonthesurfacebut
i
remainaminimumdistanceofrawayfromeachother. SincePDSisdesignedtooperategivena
radiusratherthanadesirednumberofpointsP∗,theradiuscanbeestimatedfromtheidealquality
measureexpectedfromtheradiusstatisticsintroducedin[5](seealso[4]):
√
r(cid:16) 2 3P∗ (cid:17)1
ρ= 2 ≈0.7 (4)
2 Area(M)
MassMatrix. Sincethepoint-cloudtextureshavebeensampledusingPDS,wehypothesisethat
thedistancebetweenneighbouringpointswillequaltheradiusrusedbyPDS.Atriangulationof
√
suchpointswouldresultinequilateralfaceswithareaArea(F )= r2sin(π)= r2 3. Therefore,
ijk 2 3 4
saidQthenumberoffacesincidenttoeachvertexp andcomputingtheradiuswithEq.(4)wecan
i
approximatethemassmatrixas:
√
1 (cid:88) Q 3 (0.7)2Q
M = Area(F )≈ r2 ≈ Area(M), ∀i. (5)
ii 3 ijk 3 4 6P∗
ijk∈F
Sinceweneverexplicitlycomputeatriangulationofthepoint-cloudtexture,weestimateQonM.
Also,consideringthatthemassmatrixderivedinEq.(5)hasthesamevalueonthediagonalelements,
werepresentitwithascalar,M .
p
EigenvaluesandEigenvectors. TheeigenvaluesofLBOareconsideredglobalshapedescriptors,as
such,theyaresampling-independent. Eigenvectorsareontheotherhanddefinedontheverticesof
themeshonwhichLBOwascomputed. However,asmentionedinSec.3,ameshMiseffectively
discretisingacontinuoussurfaceS. Similarly,asignalontheverticesofthemeshcanbethought
ofasadiscretisationofthecontinuousfunctiondefinedonS. Forthisreason,eigenvectorscanbe
resampledbyinterpolatingthevaluesoftheeigenvectorsdefinedattheverticesofthemesh. We
indicatethesewithΦ ∈RP×K.
p
ColourSampling. Althoughweadvocateforanewtexturerepresentationbasedonpoint-clouds,the
mostwidelyadoptedrepresentationisstillbasedonUV-mapping. Hence,foreverypointsampled
withPDS,wealsoquerythecolourstoredintheUVimageplaneatitscorrespondingUVcoordinates.
WhenUVtexturesarenotprovided,wesamplethebasecolourinstead. Followingthisprocedure,we
obtaincolouredpoint-clouds{P,X}thatweuseaspoint-cloudtexturesduringtraining.
Whenimageshaveasignificantlyhigherresolutionthanthedesiredpoint-cloudtextureresolution,
we resize the image texture before sampling. We assume that properly textured meshes should
intentionallyhavebigUVtriangleswhereahightextureresolutionisrequired. Being△uv theN
biggest triangles in UVspace and △3D the corresponding triangles on the mesh, to estimate the
scalingfactor(s)neededtoobtainthedesiredimagetexturesize,wecomputethesquarerootofthe
7
OBL
HSEM
OBL
DEXIMratiobetweenthenumberofsampleson△3D andthenumberofpixelsin△uv:
s=(cid:104) N1 (cid:80)N n=1Area(△3D)/Area(Fijk) (cid:105)1
2. (6)
(W×H)(cid:0) N1 (cid:80)N n=1Area(△uv)(cid:1)/12
Thenumberofsamplesin△3D isestimateddividingtheiraverageareabytheapproximatearea
ofthePDsampledpoint-cloudtexture. Thenumberofpixelsin△uv byestimatingthefractionof
UVspaceoccupiedbythebiggesttrianglesandmultiplyingitbythenumberofpixelsintheimage
plane,whichiscomputedastheproductbetweenimagewidthandheight(W ×H). Inpractice,
wesetN =250toconsiderasignificantnumberoftrianglesanduse3sinsteadofstoaccountfor
non-perfectlytexturedmesheswhichretainusefulhigh-resolutioncontentinsmallUVtriangles.
4.4 RenderingPoint-CloudTextures Z O
OM ON
R
A
Y
WerelyonMitsuba3[27],aphysically-baseddifferentiable - M
renderer,andimplementanewclassoftextures: thepoint- RAY E S H
c {l Pou ,Xd }te px atu irr .e Ws t hh ea nt aw re aypr ie nv teio rsu es cl ty ioc nh oa cra cc ut re sri as ne dd thw eit ph ot ih ne
t- NI
T
cloudtextureisqueried,wecomputethethreenearestpoint- E
R
cloudneighbourstothehitpointandinterpolatetheircolour NOITCE S
values. Thisisanalogoustothestandardtexturequerying
thatwouldoccurinUVspace. Notethatthenearestneigh- Figure6: renderingapoint-cloudtex-
boursarecomputedusingEuclideanratherthangeodesic turedcow[16]. Whenarayintersects
distances. Whenenoughpointsaresampled,thisisarea- themesh,weinterpolatethecoloursof
sonableassumptionthatkeepsrenderingtimeslow. thethreenearesttexturepoints.
5 Experiments
Datasets. We conduct experiments on two datasets, the chairsof ShapeNet [9] andthe Amazon
BerkeleyObjects(ABO)dataset[15]. ThechaircategoryofShapeNethasoftenbeenusedfortexture
generationon3Dshapesbecause,comparedtotheothercategories,ithasahighnumberofsamples
withrelativelyhightextureresolutions. ThismotivatedustotrainUV3-TeDonthesedata. However,
drivenbytheobjectiveofbuildingamodelcapableofoperatingacrossmultiplecategories,wealso
decidedtoleveragethelesswidelyusedABO.Despiteitsmorelimitedadoption,thisdatasetcontains
multipleobjectcategorieswithgood-qualitymeshesandtextures.
SincewithUV3-TeDmeshandtextureresolutionareindependent,wepre-filterdatawithmorethan
60,000vertices. Thischoicedoesn’thinderthequalityofthegeneratedpoint-cloudtexturesbut
reducestheGPUmemoryconsumptionduringtraining. Asweareinterestedingeneratingtextures,
wealsodiscardmeshesthathavecolouredparts,butnotextures. Inbothcases,weoperatea90:5:5
splitbetweentrain,test,andvalidationsets. Thefilteringanddatasplitleaveuswith4,633chairsfor
training,266forvalidation,and317fortesting. OnABOwehave6,476shapesfortraining,364for
validation,and443fortesting.
ImplementationDetails.WeimplementourmethodusingPyTorch[37],PytorchGeometric[21]and
Diffusers[52]. Weuse32sihks,K =128eigenvalues,andamixed-LBOweightingofϱ=0.05.
WetrainourmodelsusingtheAdamW[30]optimiserfor400epochsonchairsand250onABO,with
alearningrateof1e−4andacosineannealingwith500warmupiterationsteps. WeuseT =1,000
DDPMtimesteps,S =250farthestpointsamplesintheattentionlayers,andP∗ =5,000targetPDS
samples. SinceP∗isusedtoestimatethemesh-specificPDSradiusr,ourpoint-cloudtexturesoften
haveaslightlydifferentamountofpointsP. Thus,wemadeallourlayerssuitableforheterogeneous
batching. Ourbatchsizeissetto8onShapeNetchairsandto6onABO.
UnconditionalTextureGeneration. InFig.7topweshowcaseourtexturegenerationresultson
chairsfromShapeNet,inFig.8wedepictresultsonobjectsfromABO,andinFig.1wecombine
texturedobjectfrombothdatasetsrenderedwithmoreadvancedlighting(moretexturedsamplesare
providedinApp.A.2). Then,weproceedtocompareourmethodagainstthestate-of-the-art.
Althoughweacknowledgethatmanystate-of-the-artmethodsoperatinginUV-spacehavegenerated
impressiveresults, wewanttohighlightthattheyoperateonimages, adatatypewhichhasbeen
vastlyexploredbytheDeepLearningcommunityandwheremodelsarewell-engineered,maturein
8Figure 7: Qualitative comparison between PointUVDiff (pcl-texture) and UV3-TeD (ours). Our
texturesaremorediverseandmoresemanticallymeaningful. Allshapesbelongedtothetestset.
termsofefficiencyandquality,andtrainedonlargerdatasets. Wefinditimportanttonotethatwedo
notaimtocompeteagainstUVtechniques,butratherattempttopromptaparadigmshifttowardsa
directionthatwillnotrequireUV-mapping,withitsmanyunsolvedissues. AsdetailedinSec.2,we
considerthecoarsestageofPoint-UVDiffusion[58]andTexturify[49]tobethebestnon-UV-based
methodcurrentlyavailableaswellasthemostrelevantworkstoours. Theformeralreadyextensively
proveditssuperiorityoverTexturifyand[35]onthechairsofShapeNet. Onthesamedata,Texturify
madeadditionalcomparisonsagainstUV([57]andaUVBaseline),Implicit[35],Tri-plane[8],and
sparsegrid[17]methods,outperformingallofthemacrossallmetrics. Forthisreason,wefocus
ourcomparisononPoint-UVDiffusion,whichdoesnothaveshadowsbakedinthetextureandis
thereforebettersuitedtoberenderedwithourpipeline(Sec.4.4). Becauseweadoptphysically-based
renderingtechniquesratherthanrasterisation,were-computeFIDandKIDscores[25,36,3]for
Point-UVDiffusion. Eachshapeisrenderedfrom5randomviewpointswiththecamerapointing
attheobjectatanazimuthanglesampledfromU[0,2π]andanelevationsampledfromU[0,π/3].
WealsocomputetheLPIPS[64]metric,measuringthediversityofthegeneratedtextures. Forthis,
wegenerate3texturevariationsforeachshape,renderthem,andcomputetheLPIPSvaluesforall
thepossiblepairsofimageswiththesameunderlyingshape. Theresultsarethenaveragedforeach
method. Wealsoevaluatetwodifferentscenarios: oneinwhichweemulatetheoriginalformulation
andrendershapeswhosepoint-cloudtextureshavebeenprojectedinUV-space,andonewherewedo
notprojecttheirpoint-cloudsinUV-spaceusingourrenderingtechniqueinstead. Aswecanobserve
from the quantitative results reported in Tab. 1, our method significantly outperforms Point-UV
Diffusionacrossallmetrics. Inaddition,aswecanobservefromthesamplesreportedinFig.1and
Fig.7,ourmethodcangeneratemorediversesamples,whicharealsomorecapableofcapturingthe
semanticsofthedifferentobjectparts. Interestingly,thisisachievedwithoutprovidinganysemantic
segmentation. UV3-TeDalsosignificantlyoutperformsaDiffusionNetDDPMinsamplequality
while maintaining comparable diversity (Tab. 1). This baseline mimics UV3-TeD by leveraging
aDDPMmodelwithaU-Net-likearchitecturehavingasmanylayersasours, butwithoutshape
conditioningandusingthepointoperatorsof[48].Therefore,notonlytherewerenofarthest-sampled
attentionlayers,butnoonlinesamplingstrategywasusedandthepoint-cloudLaplacianandmass
matrixwereusedinstead. ColourswerestillsampledlikeforUV3-TeD.Allthehyperparameters
matchedours.
Table1: QuantitativecomparisononthechairsofShapeNet.
Method FID(↓) KID×10−4(↓) LPIPS(↑)
PointUVDiff[58](uv) 63.35 83.19 0.08
PointUVDiff[58](pcl-texture) 65.09 126.18 0.09
DiffusionNet[48]DDPM 116.58 468.09 0.24
UV3-TeD(ours) 54.20 42.17 0.21
AblationStudies. Wehereperformmultipleablationstoexaminehowmucheachmodelcomponent,
conditioning,andchoicecontributestotheoverallperformance. Theablationsareperformedtraining
themodelfor50epochsontheABO(multi-class)dataset. Ablationsarequantitativelyevaluatedon
100testshapesusingthethreemainmetricspreviouslyusedduringthecomparisons: theFID,KID,
andLPIPSscores. ResultsarereportedinTab.2. Overall,ourfinalmodel(UV3-TeD)reportsthe
bestqualityscoreswhilemaintaininggooddiversityscores. Adetaileddiscussionofthedifferent
ablationsisprovidedinApp.A.2.
9Table2: AblationstudiesonourUV3-TeDonABO.Modelsweretrainedfor50epochs.
FID(↓) KID×10−4(↓) LPIPS(↑)
UV3-TeD(ours) 77.14 58.59 0.14
w/ofarthest-sampledattention 83.16 103.42 0.10
w/oΛ′ 79.96 66.29 0.15
w/osihks 78.46 70.90 0.14
Φ insteadofsihks 79.62 65.17 0.14
p
ϱ=0(LR insteadofLR ) 78.07 62.64 0.15
m mix
ϱ=1(LR insteadofLR ) 78.47 64.53 0.14
p mix
w/oGT-textureresizing 83.72 97.00 0.16
6 Conclusion
WeintroducedUV3-TeD,anewmethodforrepresentingandgeneratingtexturesonsparseunstruc-
tured point-clouds constrained to lie on the surface of an input mesh. Our framework is based
upondenoisingdiffusionoversurfaces,inwhichweintroduceanewfarthest-sampledmulti-headed
attentionlayerdiffusingandcapturingfeaturesoverdistantregions,requiredforcoherenttexture
synthesis. Toperformdiffusiononmeshesofarbitrarytopologies,weproposedamixedLaplacian,
fusingbothgeometricandtopologicalcues. Inaddition, weproposedonlinesamplingstrategies
forefficientlyworkingwithdifferentquantitiesrelatedtotheshapespectra. Acknowledgingthat
renderingisasequallyimportantasthetexturerepresentation,weproposedapath-tracingrenderer
tailoredforourpoint-cloudtextureslivingonshapesurfaces.
Limitations&FutureWork. ExistingUV-basedtexturingpipelinesareheavilyengineered,leverag-
ingtherecentadvancesinimagegeneration. Weexpectthatourapproachwillsimilarlybenefitfrom
theadvancesin3Dfoundationmodels. Learninghigh-frequencytexturedetailsrequiressignificant
trainingeffort,usuallyexceedingthousandsofepochs. Moreefficientarchitectures,utilisingpooling
are required to overcome the drawback and increase the resolution of the generated textures. To
enhancequalityevenfurther,werecommendextendingourmethodtosupportBRDFsgeneration
andencourageadditionalresearchintosamplingstrategiescapableofensuringcrisptextureborders
betweenparts. WithUV3-TeDanditspromisingresults,weinvitethecommunitytore-thinkefficient
texturerepresentations,andpavethewaytoseam-freehigh-qualitycodingofappearancesonsurfaces.
Assuch,webelieveourworkopensupampleroomforfuturestudiesintexturegenerationandother
applicationsrequiringthegenerationofsignalsthatresideonsurfaces. Forinstance,ourframework
could be easily adapted to applications ranging from HDRI environment map generation, shape
matching,andweatherforecasting,tomolecularshapeanalysisandgeneration.
BroaderImpact. Webelieveourapproachwillhaveapredominantlypositiveimpact, fostering
researchingeneratingUV-freetexturesandultimatelyimprovingcreativeprocessesacrossvarious
industriesandempoweringindividualswithlimitedartisticskillstoparticipateincontentcreation.
Also,wedonotexpectnorwishtoreplaceartistsduetoadvancementsinthefield. Instead,weaim
tomaketheirworkmoreefficient,allowingthemtounlocktheircreativityfaster.
Figure8: RandomsamplesgeneratedbyUV3-TeD(ourmethod)onABOtestset.
10AcknowledgmentsandDisclosureofFunding
ThisworkwassupportedbytheUKEngineeringandPhysicalSciencesResearchCouncil(EPSRC)
ProjectGNOMON(EP/X011364)forImperialCollegeLondon,DepartmentofComputing.
References
[1] H.Baatz,J.Granskog,M.Papas,F.Rousselle,andJ.Novák. Nerf-tex: Neuralreflectancefield
textures. ComputerGraphicsForum,41(6):287–301,2022.
[2] D.BensonandJ.Davis.Octreetextures.ACMTransactionsonGraphics(TOG),21(3):785–790,
2002.
[3] M.Bin´kowski,D.J.Sutherland,M.Arbel,andA.Gretton. Demystifyingmmdgans. arXiv
preprintarXiv:1801.01401,2018.
[4] T.BirdalandS.Ilic. Apointsamplingalgorithmfor3dmatchingofirregulargeometries. In
2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages
6871–6878.IEEE,2017.
[5] J.Bowers,R.Wang,L.-Y.Wei,andD.Maletz. Parallelpoissondisksamplingwithspectrum
analysisonsurfaces. ACMTransactionsonGraphics(TOG),29(6):1–10,2010.
[6] M.M.BronsteinandI.Kokkinos. Scale-invariantheatkernelsignaturesfornon-rigidshape
recognition. In 2010 IEEE computer society conference on computer vision and pattern
recognition,pages1704–1711.IEEE,2010.
[7] T.Cao,K.Kreis,S.Fidler,N.Sharp,andK.Yin. Texfusion: Synthesizing3dtextureswith
text-guidedimagediffusionmodels. InProceedingsoftheIEEE/CVFInternationalConference
onComputerVision,pages4169–4181,2023.
[8] E.R.Chan,C.Z.Lin,M.A.Chan,K.Nagano,B.Pan,S.DeMello,O.Gallo,L.J.Guibas,
J.Tremblay,S.Khamis,etal. Efficientgeometry-aware3dgenerativeadversarialnetworks. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages
16123–16133,2022.
[9] A.X.Chang,T.Funkhouser,L.Guibas,P.Hanrahan,Q.Huang,Z.Li,S.Savarese,M.Savva,
S.Song,H.Su,J.Xiao,L.Yi,andF.Yu. ShapeNet:AnInformation-Rich3DModelRepository.
TechnicalReportarXiv:1512.03012[cs.GR],StanfordUniversity—PrincetonUniversity—
ToyotaTechnologicalInstituteatChicago,2015.
[10] J.-H.R.Chang,W.-Y.Chen,A.Ranjan,K.M.Yi,andO.Tuzel. Pointersect: Neuralrendering
withcloud-rayintersection. InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition,pages8359–8369,2023.
[11] Z.Chang,G.A.Koulieris,andH.P.Shum. Onthedesignfundamentalsofdiffusionmodels: A
survey. arXivpreprintarXiv:2306.04542,2023.
[12] D.Z.Chen,Y.Siddiqui,H.-Y.Lee,S.Tulyakov,andM.Nießner. Text2tex: Text-driventexture
synthesisviadiffusionmodels. ICCV,2023.
[13] Z.Chen,K.Yin,andS.Fidler. Auv-net: Learningaligneduvmapsfortexturetransferand
synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition,pages1465–1474,2022.
[14] A.-C.Cheng,X.Li,S.Liu,andX.Wang. Tuvf: Learninggeneralizabletextureuvradiance
fields. ICLR,2024.
[15] J.Collins,S.Goel,K.Deng,A.Luthra,L.Xu,E.Gundogdu,X.Zhang,T.F.YagoVicente,
T. Dideriksen, H. Arora, M. Guillaumin, and J. Malik. Abo: Dataset and benchmarks for
real-world3dobjectunderstanding. CVPR,2022.
[16] K. Crane, U. Pinkall, and P. Schröder. Robust fairing via conformal curvature flow. ACM
TransactionsonGraphics(TOG),32(4):1–10,2013.
11[17] A.Dai,Y.Siddiqui,J.Thies,J.Valentin,andM.Nießner. Spsg: Self-supervisedphotometric
scenegenerationfromrgb-dscans. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages1747–1756,2021.
[18] A.DevauxandM.Brédif. Realtimeprojectivemulti-texturingofpointcloudsandmeshesfora
realisticstreet-viewwebnavigation. InProceedingsofthe21stInternationalConferenceon
Web3DTechnology,pages105–108,2016.
[19] D.Dolonius,E.Sintorn,andU.Assarsson.Uv-freetexturingusingsparsevoxeldags.Computer
GraphicsForum,39(2):121–132,2020.
[20] A.A.Elhag,J.M.Susskind,andM.A.Bautista. Manifolddiffusionfields. InICLR,2024.
[21] M.FeyandJ.E.Lenssen. FastgraphrepresentationlearningwithPyTorchGeometric. InICLR
WorkshoponRepresentationLearningonGraphsandManifolds,2019.
[22] J.Gao,T.Shen,Z.Wang,W.Chen,K.Yin,D.Li,O.Litany,Z.Gojcic,andS.Fidler. Get3d: A
generativemodelofhighquality3dtexturedshapeslearnedfromimages. AdvancesInNeural
InformationProcessingSystems,35:31841–31854,2022.
[23] L. Gao, T. Wu, Y.-J. Yuan, M.-X. Lin, Y.-K. Lai, and H. Zhang. Tm-net: Deep generative
networksfortexturedmeshes. ACMTransactionsonGraphics(TOG),40(6):1–15,2021.
[24] Z. Gao, Z. Yu, and X. Pang. A compact shape descriptor for triangular surface meshes.
Computer-AidedDesign,53:62–69,2014.
[25] M.Heusel,H.Ramsauer,T.Unterthiner,B.Nessler,andS.Hochreiter. Ganstrainedbyatwo
time-scaleupdateruleconvergetoalocalnashequilibrium. Advancesinneuralinformation
processingsystems,30,2017.
[26] J.Ho,A.Jain,andP.Abbeel. Denoisingdiffusionprobabilisticmodels. Advancesinneural
informationprocessingsystems,33:6840–6851,2020.
[27] W.Jakob,S.Speierer,N.Roussel,andD.Vicini.Dr.jit:ajust-in-timecompilerfordifferentiable
rendering. ACMTransactionsonGraphics(TOG),41(4):1–19,2022.
[28] A.Lacoste, A.Luccioni,V.Schmidt, andT.Dandres. Quantifyingthecarbonemissionsof
machinelearning. arXivpreprintarXiv:1910.09700,2019.
[29] Z.Liu,P.Luo,X.Wang,andX.Tang. Deeplearningfaceattributesinthewild. InProceedings
ofInternationalConferenceonComputerVision(ICCV),December2015.
[30] I.LoshchilovandF.Hutter.Decoupledweightdecayregularization.InInternationalConference
onLearningRepresentations,2018.
[31] C. Luo. Understanding diffusion models: A unified perspective. arXiv preprint
arXiv:2208.11970,2022.
[32] G.Metzer,E.Richardson,O.Patashnik,R.Giryes,andD.Cohen-Or. Latent-nerfforshape-
guidedgenerationof3dshapesandtextures. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages12663–12673,2023.
[33] T.W.Mitchel,C.Esteves,andA.Makadia. Singlemeshdiffusionmodelswithfieldlatentsfor
texturegeneration. arXivpreprintarXiv:2312.09250,2023.
[34] N.MohammadKhalid,T.Xie,E.Belilovsky,andT.Popa. Clip-mesh: Generatingtextured
meshesfromtextusingpretrainedimage-textmodels. InSIGGRAPHAsia2022conference
papers,pages1–8,2022.
[35] M.Oechsle,L.Mescheder,M.Niemeyer,T.Strauss,andA.Geiger. Texturefields: Learning
texture representations in function space. In Proceedings of the IEEE/CVF International
ConferenceonComputerVision,pages4531–4540,2019.
[36] G. Parmar, R. Zhang, and J.-Y. Zhu. On aliased resizing and surprising subtleties in gan
evaluation. InCVPR,2022.
12[37] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison,
L.Antiga,andA.Lerer. Automaticdifferentiationinpytorch. InNIPS2017WorkshopAutodiff
Submission,2017.
[38] U.PinkallandK.Polthier. Computingdiscreteminimalsurfacesandtheirconjugates. Experi-
mentalmathematics,2(1):15–36,1993.
[39] R.Poranne,M.Tarini,S.Huber,D.Panozzo,andO.Sorkine-Hornung. Autocuts: simultaneous
distortionandcutoptimizationforuvmapping. ACMTransactionsonGraphics(TOG),36(6):
1–11,2017.
[40] C.R.Qi,L.Yi,H.Su,andL.J.Guibas. Pointnet++: Deephierarchicalfeaturelearningon
pointsetsinametricspace. Advancesinneuralinformationprocessingsystems,30,2017.
[41] A. Raj, C. Ham, C. Barnes, V. Kim, J. Lu, and J. Hays. Learning to generate textures on
3d meshes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
RecognitionWorkshops,pages32–38,2019.
[42] E. Richardson, G. Metzer, Y. Alaluf, R. Giryes, and D. Cohen-Or. Texture: Text-guided
texturingof3dshapes. InACMSIGGRAPH2023ConferenceProceedings,SIGGRAPH’23,
NewYork,NY,USA,2023.AssociationforComputingMachinery. ISBN9798400701597. doi:
10.1145/3588432.3591503. URLhttps://doi.org/10.1145/3588432.3591503.
[43] O.Ronneberger,P.Fischer,andT.Brox. U-net: Convolutionalnetworksforbiomedicalimage
segmentation. In Medical Image Computing and Computer-Assisted Intervention–MICCAI
2015: 18thInternationalConference,Munich,Germany,October5-9,2015,Proceedings,Part
III18,pages234–241.Springer,2015.
[44] N. Schertler, D. Panozzo, S. Gumhold, and M. Tarini. Generalized motorcycle graphs for
imperfectquad-dominantmeshes. ACMTransactionsonGraphics,37(4),2018.
[45] M.Schütz,K.Krösl,andM.Wimmer. Real-timecontinuouslevelofdetailrenderingofpoint
clouds. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), pages
103–110.IEEE,2019.
[46] M.Schütz,B.Kerbl,andM.Wimmer. Renderingpointcloudswithcomputeshadersandvertex
orderoptimization. ComputerGraphicsForum,40(4):115–126,2021.
[47] N.SharpandK.Crane. Alaplacianfornonmanifoldtrianglemeshes. InComputerGraphics
Forum,volume39,pages69–80.WileyOnlineLibrary,2020.
[48] N. Sharp, S. Attaiki, K. Crane, and M. Ovsjanikov. Diffusionnet: Discretization agnostic
learningonsurfaces. ACMTransactionsonGraphics(TOG),41(3):1–16,2022.
[49] Y.Siddiqui,J.Thies,F.Ma,Q.Shan,M.Nießner,andA.Dai. Texturify: Generatingtextureson
3dshapesurfaces. InEuropeanConferenceonComputerVision,pages72–88.Springer,2022.
[50] M.Tarini,K.Hormann,P.Cignoni,andC.Montani. Polycube-maps. ACMtransactionson
graphics(TOG),23(3):853–860,2004.
[51] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and
I.Polosukhin. Attentionisallyouneed. Advancesinneuralinformationprocessingsystems,
30,2017.
[52] P.vonPlaten,S.Patil,A.Lozhkov,P.Cuenca,N.Lambert,K.Rasul,M.Davaadorj,D.Nair,
S.Paul,W.Berman,Y.Xu,S.Liu,andT.Wolf. Diffusers: State-of-the-artdiffusionmodels.
https://github.com/huggingface/diffusers,2022.
[53] J. Wei, H. Wang, J. Feng, G. Lin, and K.-H. Yap. Taps3d: Text-guided 3d textured shape
generationfrompseudosupervision. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages16805–16815,2023.
[54] R.Wu,R.Liu,C.Vondrick,andC.Zheng. Sin3dm: Learningadiffusionmodelfromasingle
3dtexturedshape. arXivpreprintarXiv:2305.15399,2023.
13[55] Y.WuandK.He. Groupnormalization. InECCV,pages3–19,2018.
[56] K. Yin, J. Gao, M. Shugrina, S. Khamis, and S. Fidler. 3dstylenet: Creating 3d shapes
withgeometricandtexturestylevariations. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,pages12456–12465,2021.
[57] R.Yu,Y.Dong,P.Peers,andX.Tong. Learningtexturegeneratorsfor3dshapecollections
frominternetphotosets. InBritishMachineVisionConference,2021.
[58] X.Yu,P.Dai,W.Li,L.Ma,Z.Liu,andX.Qi. Texturegenerationon3dmesheswithpoint-uv
diffusion. In Proceedings of the IEEE/CVF International Conference on Computer Vision,
pages4206–4216,2023.
[59] C.Yuksel. Meshcolortextures. InProceedingsofHighPerformanceGraphics,pages1–11.
ACMNewYork,NY,USA,2017.
[60] C.Yuksel,J.Keyser,andD.H.House. Meshcolors. ACMTransactionsonGraphics(TOG),
29(2):1–11,2010.
[61] C.Yuksel,S.Lefebvre,andM.Tarini. Rethinkingtexturemapping. InComputergraphics
forum,volume38,pages535–551.WileyOnlineLibrary,2019.
[62] X.Zeng. Paint3d: Paintanything3dwithlighting-lesstexturediffusionmodels. arXivpreprint
arXiv:2312.13913,2023.
[63] H.Zhang,O.VanKaick,andR.Dyer. Spectralmeshprocessing. InComputergraphicsforum,
volume29,pages1865–1894.WileyOnlineLibrary,2010.
[64] R.Zhang,P.Isola,A.A.Efros,E.Shechtman,andO.Wang. Theunreasonableeffectivenessof
deepfeaturesasaperceptualmetric. InProceedingsoftheIEEEconferenceoncomputervision
andpatternrecognition,pages586–595,2018.
14A Appendix
ThisdocumentsupplementsourpaperentitledUV-freeMeshTextureGenerationwithDenoising
andHeatDiffusionbyprovidingfurtherinformationonourarchitectureanddesignchoices,addi-
tionalexperimentsandablationsforourmeshdiffusionframeworkaswellasqualitativeresultsin
theformoftexturemeshrenderings. WealsoprovidethefailurecasesofUV3-TeD.
A.1 AdditionalInformationonUV3-TeD
Λ’ sihks
Λ’ e cat e sihks
X
t
E DN IFH FA UN SC IOE ND E DN IFH FA UN SC IOE ND E DN IFH FA UN SC IOE ND E DN IFH FA UN SC IOE ND E DN IFH FA UN SC IOE ND ε
BLOCK BLOCK BLOCK BLOCK BLOCK
t
e
t
Figure9: ArchitectureoftheproposedUV3-TeD.Thenoisedinputcolours(X )gothroughaU-Net-
t
shapednetworkwithmultipleAttention-enhancedHeatDiffusionBlocks(detailedinFig.4). Blue
arrowsdepicthowtheblocksareconnectedinaU-Netfashion. EachDiffusionblockisconditioned
onatimeembeddingobtainedbyembeddingthetimestepandprocessingitwithanMLPandmultiple
block-specificlinearlayers. Theattentionpartoftheattention-enhancedblocksisconditionedonthe
signalobtainedbyprocessingΛ′andsihswithtwoseparateMLPs. Alltheconditioningisdepicted
inpinkarrows.
Architecture. AsmentionedinSec.4,althoughwedonothavepoolingandunpoolingoperators,
theskip-connectionsofourUV3-TeDareinspiredbyU-Net. Therefore,theoutputofthefirstblock
willbefedtothelastblockalongsidethefeaturescomingfromthepreviouslayer,theoutputofthe
secondblockwillbefedtothepenultimateblock,etcetera. GiventheresemblancetoU-Net,werefer
tothefirsthalfofthenetworkasthedownstreambranchandtothesecondhalfastheupstreamone.
Theblockbetweenthesetwobranchesissimplyreferredtoasthemiddleblock,whichistheonlyone
justreceivingasetoffeaturesfromthepreviousblockandpassingitsoutputfeaturestothefollowing
block. Inourexperiments,weuseasinglemiddleblockaswellas5blocksinboththedown-and
up-streambranches(Fig.9). Eachblockisbuiltasanattention-enhancedheatdiffusionblock,which
waspreviouslydepictedinFig.4anddescribedinSec.4.1. Eachattention-enhanceddiffusionblock
receivesthreeconditioningsignals: aDDPMtimestep,aglobalshapedescriptorandalocalsetof
intrinsiccoordinates. Eachtimestepisfirstconvertedintoasinusoidalembedding[26],thenitgoes
throughaMLPandablock-specificlinearlayeranditisusedtoconditiontheDiffusionNetblock
partofourenhancedblocks(seeFig.4). Theglobalshapedescriptorconditioningisobtainedby
processingthenormalisedandstraightenedeigenvaluesΛ′(Eq.(2))withaMLP,whiletheintrinsic
coordinate conditioning by passing the scale-invariant heat kernel signatures (sihks) through a
per-pointMLP.ThesetwogeometricembeddingsareconcatenatedandpassedontoeveryDiffused
Farthest-SampledAttentionlayer(Sec.4.1). Point-wiselinearlayersarealsousedasfirstandlast
layersofthewholearchitecture.
Thenoisedinputcolours(X )andthepredictednoiseϵ=ϵ (X ,t,Λ′,sihks)have3colourchannels
t θ t
each(R,G,B). Thefirstlinearlayerconvertsthe3channelsinto256features,whilethelastone
doestheopposite. AlltheMLPsintheattention-enhanceddiffusionblockshaveReLUactivation
functionsand3layersofsize256. Intheupstreambranch,thelinearlayerintheskipconnection
(Fig.4)reducesthe512incomingfeaturesto256. Thisisnotnecessaryforthedownstreamblocksas
theydonotreceiveadditionalinputs. Thefarthest-sampledmulti-headedself-attentionlayershave
8headswith64channelseachandoperateon250farthestsamples. Thetimeembeddingmodule
producestimeembeddingsofsize256andgoesthroughaMLPwithSiLUactivationsand3layersof
size[256,1024,1024]. TheMLPsforthegeometricembeddingsalsouseSiLUactivations,butthe
oneprocessingΛ′has3layersofsize[128,64,16],whiletheoneprocessingthesihkshas3layers
ofsize[32,64,16].
15
BME-t
tac tacFigure10: Visualrepresentationofthemeanlearneddiffusiontimesfortheheatdiffusionoperations
ineachblockofourNetwork. Conditioninginformationwereomittedforsakeofclarity. Referto
Fig.9foramoredetailedrepresentationofthearchitectureandtoFig.4forthecontentofeachblock.
Theorangepartofeachblockillustratesthediffusedfarthest-sampledattentionlayerwithitstwoheat
diffusions. Thelight-bluepartsillustratethethreeDiffusionNetblockswiththeirdiffusionoperations.
These mean diffusion times are referred to UV3-TeD trained on ABO and they are displayed by
diffusingheatalwaysonthesameshape.
Learned Diffusion Times. As mentioned in Sec. 3, each heat diffusion operation is performed
channel-wise with a learned diffusion time that controls the support of the neural operator. In
Fig.10wevisualisethelearneddiffusiontimesofeachheatdiffusion. Inparticular, weaverage
the learned time across channels and diffuse heat using the mean time from 8 farthest sampled
sources. Interestingly,mostDiffusionblockshaveasimilarsupport,withtheexceptionofthelast
twooperators,whichhaveaslightlybiggersupport. Inaddition,thefirstdiffusionofeachdiffused
farthest-sampled attention layer has a support that is comparable to the Diffusion blocks, while
theseconddiffusionlearnslongerdiffusiontimes. Theselongerdiffusiontimesprovethecorrect
operationoftheproposeddiffusedfarthest-sampledattentionlayer(Sec.4.1)whichissupposedto
spreadtheoutputofthemulti-headedself-attentionfromthefarthestsamplestoalltheneighbouring
points.
FastGradientComputation. AsbrieflymentionedinSec.4.1,weproposeafastgradientcomputa-
tionimplementationleveragingbatchedtensoroperations. Ourefficientimplementation,avoiding
theusageofmultiplenestedloops,ismoresuitableforonlinecomputationanddoesnotrequireto
precomputegradientslikeintheoriginalDiffusionNet[48].
Withtheobjectiveofconstructingasparsematrixthatrepresentsthespatialgradientsofthemesh,
westartbycreatingabatchedtensorcontaininginformationabouttheneighboursofeachvertexand
thetangentvectorsoftheedgesconnectingthem. Sinceweoperateonapoint-cloud,theneighbours
areestimatedwithakNNsearchwithk =30(likein[48]). Havingafixednumberofneighbours
facilitatesthecreationofabatchedtensor.
Next,weconstructthecolumnandrowindicesforthesparsematrix. Thecolumnindicesarecreated
byconcatenatinganarrayofvertexindiceswiththeindexoftheirneighboursretrievedfromthe
batched tensor previously computed. The row indices are created by repeating vertex indices k
times. Wethencalculatethevaluestobestoredinthesparsematrix. Thisinvolvescomputingthe
leastsquaressolutionofalinearsystembetweenthebatchedtensorandamatrixconstructedby
concatenatingacolumnvectorof-1’stoanidentitymatrix. Theresultissplitintotwopartsthatare
storedasasparsecomplextensorrepresentingthegradientsofthemesh,whereeachrowcorresponds
toavertex,eachcolumncorrespondstoaneighbouringvertex,andthevalueataspecificrowand
columnrepresentsthegradientsoftheedgeconnectingthetwovertices.
Thecomputationalspeedupwithrespecttotheoriginalimplementationleveragingthemultiplenested
loopsissignificant: withapproximately100kpointsourimplementationisonaverage35×faster,
whilewithapproximately25kpointsitisonaverage38×faster.
RuntimesandComputationalResources. WerunourmodelsonasingleNvidiaA100with40GB
ofdedicatedmemory. Thetimerequiredtogenerateasinglepoint-cloudtexture(P∗ = 5,000)is
approximately1minuteand30seconds. Onetrainingepochtakesapproximately23minuteswith
theABOdatasetand10minuteswiththechairsofShapeNet. Notethatinordertokeepaconstant
GPUutilisationandpreventdataloadingandprocessingbottlenecksduringonlinesamplingitis
advisabletousemultipleworkers. Weuse12workersonacomputerwithanAMDEPYC7763
64-CoreProcessor,whichhasamaxCPUfrequencyof3.5GHz.
16
tac tac tac tacExperimentswereconductedusingaprivateinfrastructure,whichhasacarbonefficiencyof0.166
kgCO eq/kWh. Acumulativeof2,640hours(110GPU-days)ofcomputationwasperformedon
2
hardware of type A100 PCIe 40GB (TDP of 250W). Total emissions are estimated to be 109.56
kgCO eqofwhich0percentwasdirectlyoffset. EstimationswereconductedusingtheMachine-
2
LearningImpactcalculatorpresentedin[28]whilethecarbonefficiencywasestimatedusingthe
followingelectricitymaps.
A.2 AdditionalExperiments
MESH LBO MIXED LBO PCL LBO
MESH LBO MIXED LBO PCL LBO
Figure11: Top: heatdiffusiononachairwhoselegsaredisconnectedfromtherestofthestructure.
DiffusingheatwiththemeshLBO,heatcannotspreadbeyondthelegwhereheatwasapplied. With
thepoint-cloudLBOheatdiffusesalsoacrosstherestofthestructure, butitquicklytravelsalso
horizontallyacrosstheverticalbars. WithourmixedLBOformulationheatcorrectlyspreadover
therestofthestructureanditappearstobetterfollowgeodesicpaths. Bottom: Heatdiffusionon
anobjectwiththinstructuresusingdifferentLBOformulations. UsingtheproposedmixedLBO
heatdiffusesgeodesically,closelymimickingthebehaviourofheatdiffusionwiththemeshLBO.
Onthecontrary,withthepoint-cloudLBOheatwouldbeimmediatelytransferredfromthebackof
thehangertoitsfrontbecauseoftheEuclideanproximityofthetwoparts. Thisisanundesirable
behaviournotshownbyourmethod.
MoreonHeatDiffusionwiththeMixedLaplacian. AsdetailedinSec.4.2,weproposeahybrid
formulationoftheLaplaceBeltramiOperatorthatwecalltheMixedLBOandwhichisobtainedas
aconvexcombinationofthemeshandpoint-cloudLBOs(computedontheverticesofthemesh).
Aswealreadyexplained,byleveragingourLBOwecandiffuseheatonsurfaceswithtopological
errorsanddisconnectedcomponents(Fig.5). Fig.11(top)showsanotherexamplewherethelegs
ofachairwerenottopologicallyconnectedtotherestofthestructure. UnlikethemeshLBO,our
mixedLBOformulationallowsheattospreadovertherestofthechair. Inaddition,whencompared
tothepoint-cloudLBO,ourformulationretainsthetopologicalinformationprovidedbythemesh
andletstheheatdiffusegeodesically. ThisisparticularlyevidentinFig.11(bottom),wheresome
heatisdiffusedstartingfromtheback-sideofacoathanger. WiththemeshLBOheatdiffusesmostly
onthebackoftheobject,andpartiallystartstodiffusetowardsthefront. Onthecontrary,withthe
point-cloudLBOheatisequallydiffusedonthefrontandonthebackoftheobject. Therefore,inthe
presenceofthinstructures,itisclearthatheatisnotgeodesicallydiffused. Ontheotherhand,with
ourformulation,weavoidspreadingheatonthefrontoftheobjectandwecloselymimicthecorrect
behaviourofheatdiffusionwiththemeshLBO.ItcanalsobenotedthatwithourMixedLBOsome
smallproportionofheatspreadsoverascrewplacedclosetotheheatsource. Weconsiderthisto
beanacceptablebehaviour. Intuitively,thisinformation-sharingmaycarrysomeusefulinsightson
howthescrewmaybecolouredwithrespecttothesurroundingmaterialusedtobuildthehanger.
Yet,theamountofheatislowerthanintheportionofthehangertouchingthescrew,facilitatingthe
distinctionbetweendifferentstructures.
TestOnlineSamplingStrategies. InSec.4.3weintroducedasetofsamplingstrategiestore-use
asmuchaspossiblepre-computedoperators, makepossibletheonlinesamplingofpoint-clouds,
17Φ
Figure12: Comparisonbetweentheeigenvectorsofthesameshapewithtwodifferentsampling
densities. Theeigenvectorsoftheoriginalmesharerepresentedascoloursonthesurfaceofthemesh,
whiletheeigenvectorsofameshobtainedsubdividingthefacesoftheoriginalmesharereportedon
apoint-cloud. Thepointcoloursmatchthoseoftheunderlyingmesh,suggestingthatsamplingthe
eigenvectorsofthemeshatthepointlocationswouldproducethesameresult.
andensurethatheatcanbediffusedfollowingtheknownsurfaceinformationofthemesh. After
computingandeigendecomposingourMixedLBO,westoreitseigenvectors,eigenvalues,andmass
matrix. Theeigenvaluesremainunchangedwhensamplingandthereforearere-usedwithoutany
modification. Themassmatrix,beingproportionaltothedistancebetweenthesampledpoints,canbe
approximatedasdescribedinSec.4.3fromthePDSradius. Finally,theeigenvectorsarerecomputed
byinterpolatingtheirvaluesontheverticesofthemesh. InFig.12,weempiricallyshowthatthis
interpolationoperationispossibleandproducesthesameresultsasrecomputingtheeigenvectors. In
particular,aftercomputingtheeigenvectorsofamesh,wesubdivideitandcomputetheeigenvectors
ofthesubdividedmesh,whicharedisplayedasacolouredpoint-cloud. Asitcanbeobservedin
Fig.12,thevaluesofthecolouredpoint-cloudareinagreementwiththecoloursonthesurfaceof
themesh,whichareobtainedasalinearinterpolationbetweenthevertexcolours. Forthisreason,
itisnotnecessarytore-computetheeigenvectorsforeverypoint-cloudthatwesampleandwecan
interpolatethemeshvaluesinstead.
Establishedthatwecaninterpolatetheeigenvectors,westillneedtoprovethatdiffusingheatona
point-cloudsampledwithPDS,whoseeigenvectorshavebeeninterpolatedandthemasshasbeen
approximatedfromthePDSradius,producesthesameresultsasdiffusingheatonthesurfaceof
themesh. Therefore,wecomparetheheatdiffused–fromthesamesource–onameshandonan
online-sampledpoint-cloud. AswecanobservefromFig.13,thetwodiffusionprocessesproduce
thesameresults.
AdditionalSamples. MoretexturesgeneratedontestshapesbyourmethodarereportedinFig.14
andFig.15top. Fig.16showsmoretexturesgeneratedbyUV3-TeDonABOobjectsandrendered
frommultipleviewpoints. Thisproveshow,unlikemethodsrelyingonmulti-viewimagesfortexture
generation,UV3-TeDgeneratestexturesdirectlyonthesurfaceoftheobjects,makingthemmulti-
viewconsistentbyconstruction. WealsoreportmorechairsgeneratedbyPoint-UVDiffusion[58]
andrenderedwithourrenderingmethod(Sec.4.4)forfairnessofcomparison. Finally,Fig.19reports
somefailurecasesofourmethod.
h
Figure13: Heatdiffusioncomputedontheverticesofameshandwithouronlinesamplingona
point-cloud. Theheatdepictedonthesurfaceofthemeshiscomputedwiththetraditionalmethod
usingEq.(1)andourMixedLBO(Sec.4.2). Theheatdepictedonthepoint-cloudwascomputed
usingtheonlinesampledoperatorslikedescribedinSec.4.3. Heatdiffusesinthesamewaywith
bothtechniquesprovingthecorrectnessofoursamplingstrategy.
18Figure14: AdditionalrandomsamplesgeneratedbyourUV3-TeDtrainedonABO.
19UUVV33--TTeeDD
PPooiinntt--UUVV DDiiffff
Figure15: AdditionalrandomsamplesgeneratedbyourUV3-TeD(top),andPoint-UVDiffusion
(bottom)trainedonchairsfromShapeNet. Thepoint-cloudsgeneratedbyPoint-UVDiffusionwere
rendered with our method for a more fair comparison with no projection artefacts. Our method
generatesmorediversetexturesandbetterdistinguishesthedifferentparts.
20Figure16: Multi-viewconsistencyofABOshapestexturedwithUV3-TeD
HigherFrequencyPoint-cloudTexturesonCelebA.The
low-frequencynatureoftheresultsonShapeNetchairsand
ABO mostly stem from the datasets used. In fact, most
objects in ShapeNet have plain per-part colours and can
beconsideredmostlylow-frequencytextures. ABOonthe
otherhandhasmoredetailedtextures,butthesetexturesare
muchhigherinfrequencythanoursamplingresolution(e.g.
woodgrain,rubberpours,etc.).Todemonstratetheabilityof
ourmethodtohandlemorecomplexhigh-frequencydetails,
Figure 17: Plane perturbed by a rip-
wehavetrainedUV3-TeDonCelebAimages[29]projected
ple effect and textured with point-
onaplanedeformedbya3Drippleeffect. UV3-TeDwas
cloudtexturesgeneratedbyUV3-TeD
trainedfor50epochs, withalearningrateof5e−4, anda
trainedonCelebAforonly50epochs.
batchsizeof4. Thefarthestpointsampleswerereducedto
S =200andthechannelsinthefarthest-sampledself-attentionlayersto64. ThetargetPDSsamples
(P∗ =5,000)aswellasalltheotherhyperparameterswerethesameasthosepreviouslydetailedin
theImplementationDetails(Sec.5)andArchitecture(App.A.1)paragraphs. Thisexperimentshows
promisingresults(Fig.17)consideringthatitiscapableofgeneratingdiverseCelebAtextureseven
priortoreachingfullconvergence.
Considering that our Diffusion Blocks resemble the original operators of [48], we believe our
resultsalsoprovetheunprovenclaimofheat-diffusion-basedoperatorsbeingcapableofoperatingat
high-frequencies.
AblationStudiesDetailedDiscussion. InSec.5weperformedmultipleablationsstudiestoexamine
howmucheachmodelcomponent,conditioning,andchoicecontributestotheoverallperformance.
Ablationswerequantitativelyevaluatedusingthreemainmetrics: theFID,KID,andLPIPSscores.
Thefirsttwoevaluatethevisualqualityofgeneratedsamplesrenderedfromrandomviewpoints,
whileLPIPSevaluatestheperceptualdissimilaritybetweendifferentobjectsconsistentlyrendered
fromthesameviewpoint. ResultswerereportedinTab.2.
We started by investigating the effects of the pro-
posedfarthest-sampledattentionlayers,removingthe
proposedattentioncausesthemostsignificantdrop
inperformanceacrossmetrics,showingthepositive
impact of our proposed attention mechanism. The
benefitsprovidedbytheattentionmechanismcanbe
observedalsoinFig.18. Itisclearthatthismecha-
nismmakesthegeneratedtexturesmorerealisticand
uniformacrossdifferentparts.
Figure 18: ABO shapes textured by UV3- We then proceeded to remove the normalised and
TeDwithandwithouttheproposedfarthest- straightened eigenvalue (Λ′) conditioning as well
sampledattentionlayer. asthescale-invariantheatkernelsignatures(sihks)
conditioning. Both cause a drop in visual quality.
However,theabsenceofΛ′,whichholdsclass-relatedinformation,appearstoslightlyimprovethe
diversityofthegeneratedpoint-cloudtexturesattheexpenseofsamplequality. Webelievethatthis
resultstillsignalstheimportanceofprovidingbothconditioningsignals. Alsodirectlyusingthe
online-sampledeigenvectorsΦ insteadofsihkscausesasmalldropinperformance. Notethat
p
21Figure19: FailurecasesofrandomsamplesgeneratedbyourUV3-TeDtrainedonShapeNetchairs
(top)andABO(bottom). Mostfailuresexhibitissuesincorrectlyrecognisingthedifferentobject
parts,long-rangeinconsistencies,uniformyetunreasonablecolours,orblotchypatterns.
thediffusedfarthest-sampledattentionlayerscontainagroupnormalisationlayerafterthefirstheat
diffusion. Sinceitexpectsaspecificnumberofchannels,wheneithersihksorΛ′areremoved,to
maketheablationmorecontrollable,insteadofmodifyingthegroupnormalisationlayerweduplicate
theremainingconditioningthusprovidingredundantinformation.
AlthoughwehaveextensivelyprovedthevalidityandtheadvantagesofourmixedLBOoperator
(e.g., Fig.5andFig.11), wecomparetheperformanceofournetworkwiththemodeltrainedto
compute heat diffusions with our online sampling and using the mesh (LR) or point-cloud (LR)
m p
LBOs. OurmethodperformsslightlyworseintermsofLPIPSwhencomparedtousingthemesh
Laplacian,butitalsoexhibitsafargreaterperformanceimprovementintermsofFIDandKID.This,
andthepreviousgeometricalevaluationsofthemixedLBO,maketheadoptionofourmixedoperator
preferable. Similarly,wecanreachthesameconclusionbyobservingtheresultswiththepoint-cloud
operator,whichisalsonotimprovingoverthefinalUV3-TeDmodelintermsofLPIPSscore. It
isworthnotingthatABOisawellcurateddatasetwithareducednumberoftopologicaldefects.
Therefore,weexpectperformancetodeteriorateevenfurtheronlesscurateddatasets.
Finally,weevaluatetheeffectsofourtextureresizingSec.4.3. AlthoughtheLPIPSscoreimproves,
showinganincreaseddiversityofthegeneratedsamples,theblotchypatchesdepictedinsomeofthe
failurecasesonFig.19becomepresentonmostgeneratedpoint-cloudtextures. Thisresultsinworse
FIDandKIDscoreswhencomparedtoourfullmodel.
AsalreadymentionedinSec.5,ourfinalmodel(UV3-TeD)reportsthebestqualityscoreswhile
maintaininggooddiversityscores.
ANoteonPhotorealism. Alltheresultimagesofthispaper
exceptFig.1wererenderedwithaconstantemittertobetter
showcasethegeneratedalbedos. Nevertheless,ourgenerated
albedotexturesareintrinsicallyrelightableandcanbephoto-
realisticallyrendered. Morephotorealisticrenderingscanbe
obtainedbyrenderingobjectswithenvironmentmapsandtrain-
ingourmodeltogeneratefullBRDFs. Fig.20showshowjust
Figure 20: Chair rendered with a
usinganenvironmentmapcanimprovetherealismofoneof
constantemitter(left)andanenvi-
ourchairs.
ronmentmap(right).
22
sriahc
teNpahS
OBA