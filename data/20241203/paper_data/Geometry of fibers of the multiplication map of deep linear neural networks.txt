GEOMETRY OF FIBERS OF THE MULTIPLICATION MAP
OF DEEP LINEAR NEURAL NETWORKS
SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
Abstract. Westudythegeometryofthealgebraicsetoftuplesofcomposablematrices
whichmultiplyto afixedmatrix, usingtools fromthe theoryof quiver representations.
Inparticular, we determine its codimensionC andthe number θ of its top-dimensional
irreducible components. Our solution is presented in three forms: a Poincar´e series
in equivariant cohomology, a quadratic integer program, and an explicit formula. In
thecourseoftheproof,weestablishasurprisingproperty: C andθ areinvariantunder
arbitrarypermutationsofthedimensionvector. Wealsoshowthatthereallog-canonical
threshold of the function taking a tuple to the square Frobenius norm of its product is
C/2. Theseresultsaremotivatedbythestudyofdeeplinearneuralnetworksinmachine
learning and Bayesian statistics (singular learning theory) and show that deep linear
networksareinacertainsense“mildlysingular”.
1. Introduction
In this paper we study the possible ways for a tuple of matrices to multiply to zero (or
more generally a fixed matrix). This elementary linear algebra problem leads to some rich
geometryandcombinatorics,andhasapplicationstodeeplinearneuralnetworksinstatistics
and machine learning.
1.1. Mathematical setting. Fix nonnegativeintegersd ,d ,...,d andconsiderthe vec-
0 1 N
tor space Rep = Rep d, consisting of tuples of matrices A
1
∈ kd1×d0, A
2
∈ kd2×d1, ...,
A
N
∈ kdN×dN−1, where k is an arbitrary field (say, R or C for the purpose of this intro-
duction). Define Σ = Σ0 as the subvariety of Rep consisting of tuples whose product is
d
zero:
Σ={(A ,A ,...,A )∈Rep : A A ···A A =0}.
1 2 N N N−1 2 1
The variety Σ generally has many irreducible components. For example, when d = d =
0 1
d =1, we have two components: {A =0} and {A =0}. For more complex sequences of
2 1 2
d , the variety Σ typically has numerous components of varying dimensions (see Example
i
4.3).
DescribingΣ’scomponentsoreventhemultisetoftheirdimensionsseemstobeachalleng-
ingcombinatorialproblem. Inthispaper,wedeterminethecodimensionC =codim Σof
Rep
ΣinRep—orequivalentlythecodimensionofitslargestdimensionalirreduciblecomponents—
and the number θ of such top-dimensional components.
To study Σ, we borrow ideas and results from the theory of quiver representations. The
vector space Rep has natural symmetries coming from change of bases, which yields an
N
action of the group G = GL . The starting point of our proofs is that this action of
i=0 di
GonRephas finitely many orbitsandthat the orbitsareclassifiedby simple combinatorial
Q
data called Kostant partitions (Corollary 2.9). This is a special case of Gabriel’s theorem
on representations of Dynkin quivers. Moreover, Σ is G-invariant and so it is the union of
some of those orbits. Our main task is thus to understand the geometry and combinatorics
of which G-orbits occur in Σ.
In fact, throughout the paper we study and solve the same questions for the variety Σr
d
of tuples whose product has rank equal to a given number r, as well as for the variety
mult−1(B) of tuples whose product is a fixed matrix B. Here, mult is the multiplication
1
4202
voN
92
]GA.htam[
1v02991.1142:viXra2 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
map.
mult:Rep →Mat ,(A ,...,A )7→A ·A ...A
d dN,d0 1 N N N−1 1
Those problems easily reduce to the case r = 0 and the variety Σ above (Lemmas 4.5 and
4.6).
1.2. The results. The main results of the paper are formulas for C and θ. We have three
in the main body of the paper, (Theorems 5.5, 6.1, and 7.10) and one in the appendix
(Theorem A.1).
Theorem 5.5 uses Poincar´e series calculations in equivariant cohomology, and produces
an explicit formal power series in q whose lowest-degree term is θqC. The resulting for-
mula implies, in particular, that neither C nor θ depend on the ordering of the integers
d ,d ,...,d . This is a priori surprising, since reordering the d ’s can change the dimen-
0 1 N i
sion of Rep and drastically alter both the number of components of Σ and the multiset of
their codimensions. We expect there should be an elementary algebraic proof of this in-
variance, without topology. However, we do not provide such a proof here, relying instead
on Theorem 5.5 (an alternative argument, still relying on equivariant cohomology, is given
in Appendix A). A key component of our Poincar´e series calculation is a remarkable result
from Gabriel’s theory of quivers: the indecomposable module corresponding to the longest
root in equioriented type A quivers is both projective and injective.
In Theorem 6.1, we present C as the optimal solution of a quadratic integer program
and θ as the number of such optimal solutions. The proof relies on the combinatorics and
algebra of quivers, as well as the crucial invariance of C and θ with respect to the ordering
of the integers d ,d ,...,d , as discussed earlier.
0 1 N
InTheorem7.10,weprovideourmostexplicitformulasforC andθ,whicharewell-suited
for asymptotic analysis. The proof hinges on reinterpreting the quadratic integer program
asaminimaldistanceproblem: findingtheclosestlatticepointinasimplextoagivenpoint
inEuclideanspace. Centralto this problemis the solutionto the closestvectorproblemfor
type A root lattices, where the Voronoi cells of these lattices have the expected structure.
1.3. Deep linear networks in Bayesian statistics and Machine Learning. One mo-
tivation for studying the geometry of composable tuples of matrices is deep linear (neural)
networks and specifically their statistical properties in Bayesian statistics. We give a quick
overview here and refer to the introduction of Section 8 for more context.
Deep linear networks (DLNs) are obtained from standard (feedforward, fully-connected)
deep neural networks by replacing their non-linear activation functions by identity maps.
Despite their simplicity, they are a useful “toy model” in modern deep learning theory (see
Section 1.4). By definition, the weights of a DLN form a tuple of composable matrices, and
thefunctioncomputedbythenetworkistheirproduct,sotheparameterspaceofthemodel
is our friend Rep where d ∈ NN+1 records the widths of the layers and N is the depth of
d
the network.
A fundamental problem in statistics and machine learning is density estimation: given a
fixed parametric statistical model and data generated from an unknown “true” probability
distribution, infer the “optimal” parameter(s), for which the model is as close as possible
to the true distribution. A natural way to measure the quality of this approximation is
the relative entropy (or Kullback-Leibler divergence) K(w) between the true distribution
andthe model, consideredasa function ofthe parametersw. For regressionmodels suchas
neuralnetworks,K(w)isthemeansquareerrorpopulationlossfunction. Classicalstatistical
learningtheoryoftenfocusesonregular statisticalmodels,inwhichthereisauniqueoptimal
parameter w∗ where K(w) has a unique non-degenerate minimum. However, deep neural
networks(linearornot)andotherparametricmodelsinmodernmachinelearningarealmost
always singular. For a DLN where the true distribution is given by a matrix B, we write
KDLN :Rep→R for the corresponding relative entropy function:
B
KDLN(A )=kmult(A)−Bk2.
B ∗ 2GEOMETRY OF LINEAR NEURAL NETWORKS 3
The set of optimal parameters is (KDLN)−1(0) = mult−1(B), so the results of this paper
B
precisely describe the geometry of the bottom of the loss landscape of DLNs.
Singular Learning Theory, a theory established by S. Watanabe [Wat09, Wat18, Wat24],
studies the asymptotic performance of (real analytic) singular models for Bayesian density
estimation. A key role is played by the real log-canonical threshold rlct(K) of the real
analyticfunctionK atits optimalparameters. Singularlearningtheoryalsoprovidesatool
to estimate rlct(K) from data, the local learning coefficient [LFW+24]. The local learning
coefficienthasrecentlyleadtoveryinterestingapplicationstodevelopmentalinterpretability
of deep learning models throughout training [CLM+23, HWFR+24, WHvW+24].
The exact, theoretical computation of rlct(K) in realistic machine learning scenarios is
generally impossible. However, for deep linear networks, rlct(K) has been calculated by
M. Aoyagi [Aoy24] and this was used in [LFW+24] to calibrate the accuracy of the local
learning coefficient. The original formula of Aoyagi is complicated, and we started this
projectinordertounderstanditbetter. Combinedwithourresults,ittakesarathersimple
form (Theorem 8):
codim(KDLN)−1(0) codimmult−1(B)
rlct(KDLN)= B = .
B 2 2
For a general real analytic function F, we only have the inequality
codimF−1(0)
rlct(F)≤ .
2
This shows that the singularities of K are in some sense quite mild. Statistically speaking,
this means that deep linear networks are “mildly singular”.
1.4. Related works. The geometry and combinatorics of representations of Dynkin quiv-
ers, and especially equioriented type A quivers, is a rich topic in combinatorial algebraic
geometry and representation theory [AD85, ADK81, AD80, FR02, BFR05, RWY18], in-
cluding connections with Schubert varieties and standard monomial theory [Zel85, LM98,
KR15, KMS06]. These works mainly focus on the geometry of individual orbit closures
and not on possibly reducible unions of orbits like Σ. Interesting exception are the papers
[CS81, MS83] on the variety of complexes, consisting of tuples of matrices such that the
product of any two consecutive matrices is 0.
Deep linear networks have been studied extensively in machine learning. The papers
[TKB20] and [SB24] are closely related to ours. In [TKB20], the authors start the study
of the geometry of the fibers mult−1(B). The paper [SB24] goes much further, including
proofs using linear algebra of a number of results on the geometry of mult−1(B) which in
the perspective of this paper are part of the basic representation theory of the quiver Q
(which we collected in Sections 2, 3, 4).
A large part of the literature on DLNs is concerned with other critical points of the
loss functions [Kaw16, LK17, AMG24] and with the training dynamics by gradient descent
[ZLM22, JT19, DAP+24, ACGH19, SMG14, JGc+22, ML24]. Our results do not directly
bear on these problems, but we hope that the quiver representation approach will prove
helpful to study them.
Acknowledgments. This papergrewoutofacollaborationthatstartedwhenthe authors
visitedthe IsaacNewtonInstitute forMathematicalSciencesinthe Springof2024. The au-
thorsaregratefultotheorganizersofthespecialsemesteronNewequivariant methods in al-
gebraic and differential geometry,whichwassupportedbyEPSRCgrantnoEP/R014604/1,
aswellasthe NewtonInstitute fortheir hospitality. This firstnamedauthorwassupported
by the European Research Council (ERC), grant 864145. The second named author was
partially supported by NSF grant 2152309.4 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
2. Tuples of matrices as quiver representations
2.1. The equioriented quiver of type A. Consider the oriented graph Q
0 1 2 3 N−1 N
• • • • ... • •
,
with vertices labeled by 0,1,...,N. The length N will be fixed for the whole paper. In
representationtheory, such an orientedgraphis called a quiver. The quiver Q (the “type A
equioriented quiver”) is the only one we will study in this paper.
Inthenextfewsections2,3and4wewillrecalltherelevantgeometry,algebra,andcom-
binatoricsfor Q,with generalreference [Kir16, Ch. 1-3]. We do not claimto any originality
untilSection 5. While many resultsin those sectionsextend ina straightforwardmanner to
arbitrary Dynkin graphs with arbitrary orientations. We do not seek that generality, since
our main results in later sections only apply to Q.
Equiorientedtype Aquiversareamongthe simplestofallquivers(Dynkin orotherwise).
Consequently, the results recalled in Sections 2, 3 and 4 can be proven without reference
to the theory of quivers—just using elementary linear algebra, an approach adopted in
[SB24]. However, the quiver perspective and appealing to Gabriel’s theorem 2.5 makes the
structureoftheargumentsandtheresultingcombinatoricsrathertransparent,andconnects
our results to the rich literature on Dynkin quivers.
Remark 2.1. It is also worthwhile to point out that the underlying reason behind Theo-
rem3.7 (a key point of what follows)is that there exists an indecomposable Q-module that
is both injective and projective, namely the module M where every vector space is k and
0N
every map is id . This does not occur for any other Dynkin quiver. Curiously, this fact is
k
behind other geometric theorems in seemingly unrelated areas,see e.g. [FR02, Rem. 4.6].
2.2. Quiver geometry. Let k be a field—we are mostly interested in k = R and k = C.
For our quiver Q and a fixed dimension vector d=(d ,d ,...,d )∈NN+1, define
0 1 N
N
Rep (k)= Mat (k)= Hom(kt(a),kh(a))
d di,di−1
i=1 a
Y Y
whereMat (k)isthevectorspaceofd×d′matriceswithentriesinkanda=(t(a)→h(a))
d,d′
runs through the arrows of Q.
We consider Rep (k) as an algebraic variety over k, or, more precisely, as the set of k-
d
N
points of the k-algebraic variety Rep = Mat , which is isomorphic to the affine
d i=1 di−1,di
space AD with
k Q
N
(1) dim Rep = d d .
k d i−1 i
i=1
X
When the role of the field k is not important we will simply write Rep =Rep (k).
d d
Remark 2.2. In general, when X is an algebraic variety defined over R (or over any non
algebraically closed field), it is important to distinguish between X and the real algebraic
set X(R) of real points of X. For instance, X(R) may well be empty. Think of X ={x2 =
−1}⊂A1. However,inthesituationofinterestinthispaper,thisdistinctionwillbemostly
R
immaterial,inasensethatismadepreciseinSection3.2(seehoweverRemark4.7). Forthis
reason, we encourage readers less familiar with algebraic geometry over non-closed fields to
ignore this distinction at first pass.
N
The algebraicmatrix groupG=G := GL acts onthe representationspaceRep
d i=0 di d
as follows: for g =(P ,...,P )∈G and A =(A ,...,A )∈Rep , we have
0 N Q∗ 1 n d
g·A :=(P A P−1 , P A P−1 ,..., P A P−1 ).
∗ 1 1 0 2 2 1 N N N−1GEOMETRY OF LINEAR NEURAL NETWORKS 5
Remark 2.3. The group G has two natural subgroups
N−1
G := GL ⊂G G :=GL ×GL .
in di out d0 dN
i=1
Y
We have G = G ×G and we write π : G → G ,(P ,...,P ) 7→ (P ,P ) for the
in out out out 0 N 0 N
projection onto the outer factors. The action of G corresponds to change of bases of the
in
vector spaces kdi. Note that G
out
also naturally acts on Mat
dN,d0
by
(P ,P )·B :=P BP−1.
0 N N 0
2.3. Quiver algebra. A Q-module, or Q-representation, is a chain of finite dimensional
vector spaces and linear maps
V −f →1 V −f →2 V −f →3 ...−f −N−−→1 V −f −N→V .
0 1 2 N−1 N
Itsdimensionvectorisdefinedtobed=(dim(V )) . Inotherwords,Q-modulesareto
i i=0,...,N
elements of Rep what linear maps between finite dimensional vector spaces are to matrices.
A morphism between Q-modules (V ,f ) and (V′,f′) is a collection of linear maps φ :
∗ ∗ ∗ ∗ i
V →V′ that commute with f and f′:
i i ∗ ∗
f′◦φ =φ ◦f .
i i−1 i i
Many standard notions of linear algebra (of vector spaces and modules over rings) extend
to Q-modules and their morphisms, such as: exact sequence, isomorphism, direct sum,
subspace, irreducibility (no non-trivial subspace), indecomposability (not a direct sum in a
non-trivial way), Ext(−,−):=Ext1(−,−), injective module, projective module. Moreover,
Ext, injective and projective behave quite simply (compared e.g. to modules over general
rings).
In more abstract terminology, the category of Q-modules is a k-linear abelian category
which is Hom-finite, hereditary (no higher Ext). Injective and projective objects can also
be completely classified (we will not need this).
The reader may develop familiarity with these concepts by verifying
id
• that k −→k is indecomposable but not irreducible;
• Ext((k →0),(0→k))=k; and
• V =k, A =id (∀i) is both an injective Q-module and a projective Q-module.
i i
The Krull–Schmidt theorem holds for Q-modules: every Q-module is the direct sum of
indecomposable ones, in a unique (up to permutation) way.
2.4. Quiver geometry vs algebra. Gabriel’s theorem. Notice that elements of Rep
d
can be made into Q-modules with V
i
= kdi. We call the following well known and easy
statement a theorem because of its importance.
Theorem 2.4.
• Every Q-module is isomorphic with an element of Rep for some d.
d
• Two elements of Rep are isomorphic as Q-modules if and only if they are in the
d
same G-orbit.
Hence, listing the G-orbits of Rep is the same as listing the isomorphism types of Q-
d
modules with dimension vector d.
Forageneralquiver,this setofisomorphismtypesisinfinite; forexample,fortheJordan
quiver with one vertex and one loop, this is precisely the set of normal forms for matrices
under conjugation. However, for Dynkin quivers, this set is finite and can be described
explicitly. This is the content of Gabriel’s theorem which we state in our special case:
Theorem 2.5. For 0≤i≤j ≤N let M be the Q-module
ij
id id id id
0→0→...0→k −→k −→...−→k −→k →0→0...→0,6 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
where the first and last k’s are V and V . The M ’s form a complete set of indecomposable
i j ij
Q-modules (up to isomorphism).
Definition 2.6. Define
M :={m=(m ) | ∀i≤j, m ∈Z and ∀k, d = m },
d ij 0≤i≤j≤N ij k ij
i≤k≤j
X
M+ :={m=(m ) | ∀i≤j, m ∈N and ∀k, d = m }.
d ij 0≤i≤j≤N ij k ij
i≤k≤j
X
Elements of the M+ are called Kostant partitions for d. (We think of an m as an upper
d
triangular matrix whose rows and columns are indexed by 0,...,N.). Note that the set M+
d
of Kostant partitions is finite (unlike M ).
d
We also use the notation m⊢d for “m is a Kostant partition of d”.
Example 2.7. The set M+ has 6 elements:
(2,2,2)
2 0 0 1 1 0 2 0 0 0 2 0 2 0 0 1 1 0
0 2 0 , 0 1 0 , 0 1 1 , 0 0 0 , 0 0 2 , 0 0 1 .
           
0 0 2 0 0 2 0 0 1 0 0 2 0 0 0 0 0 1
           
Remark 2.8. There are alternative terminologies for Kostant partitions in the literature
on quiver representations: lace arrays, multiplicity patterns.
Corollary 2.9. The sets of the following objects are in bijection:
• isomorphism classes of Q-modules with dimension vector d;
• G-orbits of Rep ;
d
• Kostant partitions for d.
Explicitly, the Kostant partition m corresponds to the isomorphism class of the Q-module
m M , and to the G-orbit O ⊂Rep consisting of all representations isomor-
0≤i≤j≤N ij ij m d
phic to this Q-module.
L
Proof. FollowsfromtheKrull-SchmidttheoremforQ-modulestogetherwithTheorems2.4,2.5.
(cid:3)
To make this corollary concretely useful, we need to solve two basic problems:
• Given a Kostant partition m ∈ M+, construct explicitly tuples in the G-orbit
d
O ⊆Rep .
m d
• GivenA ∈Rep ,determinetheKostantpartitioncorrespondingtotheorbitG·A .
∗ d ∗
We solve the first one in the next section and the second in Section 3.
2.5. Lace diagrams and orbit representatives. Let m ∈ M+ be a Kostant partition.
d
WewanttoproduceanorbitrepresentativeinO ,i.e.,constructanexplicittupleofmatrices
m
A ∈Rep (k), with the right isomorphism class as a Q-module. It turns out that there are
∗ d
several natural choices, corresponding to combinatorial objects called lace diagrams.
A lace diagram is an arrangement of dots in columns 0,1,...,N, partitioned into a col-
lection of [i,j] intervals with i≤j (laces) - including intervals [i,i], i.e. isolated points. For
example
0 1 2 3
• • • •
• • • •
(2) • • • •
• • • •
• • • •
• •
is a lace diagram with N =3.GEOMETRY OF LINEAR NEURAL NETWORKS 7
Write Lace for the set of all lace diagrams with d dots in column i. A lace diagram
d i
L ∈ Lace encodes a Kostant partition m(L) of d with m(L) the number of intervals of
d ij
type [i,j]. For example, diagram (2) encodes the Kostant partition
2 1 1 1
0 2 0 1
m=  .
0 0 0 2
0 0 0 2
 0...3,0...3
 
AsinCorollary2.9,alacediagramthusdeterminesanisomorphismclass[⊕ m M ]ofQ-
ij ij ij
modules. Forexample,thelacediagram(2)aboveisassociatedtotheclassoftheQ-module
2M ⊕M ⊕M ⊕M ⊕2M ⊕2M ⊕2M ⊕2M .
00 01 02 03 11 13 23 33
LetS bethepermutationgrouppermutingkletters. ThegroupS :=S ×S ×...S
k d d0 d2 dN
acts on Lace by permuting the dots in each columns. The lace diagram above is in the
d
orbit of
0 1 2 3
• • • •
• • • •
(3) • • • • .
• • • •
• • • •
• •
Kostant partitions can be thought of as equivalence classes of lace diagrams:
Lemma 2.10. The map m(−) : Lace → M+ is invariant under the action of S and
d d d
induces a bijection
S \Lace ≃M+.
d d d
Proof. The map m(−) is clearly invariant under the action and thus induces a map
S \Lace →M+.
d d d
Given a Kostant partition, one can construct a lace diagram by adding inductively in-
tervals of length m to the diagram in any order, using the first dots still available in each
ij
column. This shows that the map is surjective. Given two lace diagrams with the same
Kostant partition, one can first choose a length-preserving bijection between their inter-
vals, and then permute the dots according to that bijection. This shows that the map is
injective. (cid:3)
We can interpret the choice of a lace diagram as the choice of a base point for the
associated orbit.
Definition 2.11. Let L be a lace diagram. Identify the N +1 columns of dots of L as
the standard basis vectors in the N +1 vector spaces kd0,...,kdN. The line segments of L
then encode linear transformations between these spaces by specifying how a basis vector is
mapped to another basis vector to the right. If a dot has no segment coming out of it to the
right, then that basis vector is mapped to 0. The corresponding matrices yield an element
A (L)∈O ⊂Rep .
∗ m(L) d
Note that the resulting matrices are very special: they are partial permutation matrices:
• all coefficients are 0 or 1, and
• every line and column has at most one 1.
The combinatorics of lace diagrams are quite rich (see for instance [BFR05, KMS06,
RWY18]). In this paper, we use them in an elementary way in the proof of Theorem 6.1,
see in particular Lemma 6.4 and Figure 1.8 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
3. Rank patterns and combinatorics of orbits
3.1. Rankpatterns. KostantpartitionsarethenaturalcombinatorialcodesforG-orbitsof
Rep —infactthisholdsforanarbitraryorientedDynkinquiverifwereplace“intervals”with
d
“positive roots of the same named root system” in Theorem 2.5. However, for equioriented
type A quivers there is another natural combinatorial code: rank patterns. Define
R :={r=(r ) | ∀i≤j,r ∈N and r =d }
d ij 0≤i≤j≤N ij ii i
tobethesetofuppertriangulararraysofsizeN+1withnon-negativeintegerentries,whose
diagonal encodes our fixed dimension vector. We call elements r ∈R rank patterns.
d
Proposition 3.1.
• The maps R →M and M →R defined by
d d d d
m (r)= r −r −r +r
ij ij i,j+1 i−1,j i−1,j+1
(with the convention r =0 if i<0 or j >N),
ij
r (m)= m
ij k≤i≤j≤l kl
are well defined, anPd are inverses of each other.
• Let m and r correspond to each other at the bijection above, and assume that m ∈
M+. The G-orbit in Rep (k) corresponding to m∈M+ is
d d d
O :={(A ,...,A )∈Rep | ∀ 0≤i<j ≤N, rank(A ···A )=r }.
rk=r 1 N d j i+1 ij
That is, the G-orbits of Rep are determined by rank conditions of the possible compo-
d
sitions in Q, and the rank conditions which occur are exactly the ones that correspond to
M+ under the bijection. We leave the easy combinatorial proof to the reader. Write
d
Rorb ={r∈R | ∀i,j, r −r −r +r ≥0}
d d ij i,j+1 i−1,j i−1,j+1
for the set of rank patterns corresponding to Kostant partitions and hence giving an alter-
native parametrization of orbits.
The characterization of the rank in terms of vanishing of minors, which are polynomials
inthecoefficients,impliesthattherankislowersemi-continuousintheZariskitopologyand
so that R is a Zariski locally closed subvariety of Rep . Note that the condition defining
r d
O does not involve the diagonal r = d , which is only used to encode the dimension
rk=r ii i
vector d into r and to make some formulas cleaner.
Example 3.2. The rank pattern corresponding to the lace diagram (2) and the Kostant
partition in Section 2.5 is
5 3 2 1
0 6 3 2
r =  .
0 0 5 4
0 0 0 6
 0...3,0...3
 
The orbit O is not empty, of dimension 72 (as follows from Equation 4 below). If we
rk=r
changedr =2 to r′ =1 in this rank pattern (recall that the row and column indices run
13 13
from 0 to 3), then it would not correspondto a Kostantpartition since we wouldthen have
r −r −r +r′ =5−4−3+1<0
22 23 12 13
and hence we would have O =∅.
rk=r
Notation. Since Kostant partitions and corresponding rank patterns are equivalent combi-
natorial codes; both parametrize orbits. When we name an orbit with its rank pattern, we
usethenotationO ,whenwenameanorbitwiththeKostantpartitionmwewillsimply
rk=r
call it O .
mGEOMETRY OF LINEAR NEURAL NETWORKS 9
3.2. The choice of base field. WeclarifyRemark2.2aboutthechoiceofbasefieldk,and
show in particular that the geometry we are interested is essentially the same over k = R
and k = C (see however Remark 4.7 for an interesting difference). In this section only, we
let Rep (resp. O ) stand for the corresponding k-variety and distinguish it from its set
d rk=r
of rational points Rep (k) (resp. O (k)).
d rk=r
Theorem 3.3.
(1) For any field k and r∈R , we have
d
r ∈Rorb ⇔ O 6=∅ ⇔ O (k)6=∅.
d rk=r rk=r
(2) For every r ∈Rorb, the k-rational points O (k) are Zariski dense in O .
d rk=r rk=r
(3) When k =R (resp. k =C), the real algebraic set O (R) is a real analytic (resp.
rk=r
complex analytic) manifold of dimension equal to the dimension of O as an
rk=r
algebraic variety.
Proof. We prove Claim (1). The implication O 6= ∅ ⇐ O (k) 6= ∅ is obvious. If
rk=r rk=r
O 6= ∅, then O (k¯) 6= ∅ so by Proposition 3.1 applied over k¯ we have r ∈ Rorb.
rk=r rk=r d
Finally, if r ∈Rorb, then m(r)∈M+ by Proposition 3.1. Then by choosing a lace diagram
d d
L encoding m(r) and following Section 2.5, we obtain a collection of partial permutation
matricesA (L)inthe G-orbitcorrespondingtom(r). Since 0,1∈k,this showsO (k)=
∗ rk=r
O (k)6=∅.
m(r)
Claim (1) then implies that O ≃G/H as k-varieties,where H is the stabilizer group
rk=r
of the orbit. This implies the other statements and finishes the proof. (cid:3)
3.3. Voight lemma and the codimension of orbits. [Voi77]. Another crucial relation
between the geometry and algebra of quivers is
Lemma 3.4. Let M, considered as a Q-module, be an element of a G-orbit O ⊂ Rep (k).
d
Then a normal slice to O at M in Rep (k) is isomorphic to Ext(M,M).
d
While the isomorphism holds as an isomorphism of representations of the G-stabilizer
group of M, we will only use the statement as isomorphism of vector spaces.
The first consequence of Lemma 3.4 is that a formula for the codimension of an orbit is
a (non-symmetric) bilinear form, in the components of the Kostant partition.
Corollary 3.5. Letm∈M+ beaKostantpartition andr=r(m)∈Rorb thecorresponding
d d
rank pattern. Then
(4) codim (O )= m m
Rep m (i−1)(j−1) uv
1≤i≤u≤j≤v≤N
X
Proof. Let M be a Q-module in O then by Lemma 3.4 we have
m
codim (O )=dimExt(M,M)=dimExt(⊕ m M ,⊕ m M )
Rep m ij ij ij uv uv uv
= m m dimExt(M ,M ),
ij uv ij uv
ij uv
XX
where an easy calculation (cf. [FR02, Lemma 4.4]) gives
1 if i+1≤u≤j+1≤v,
(5) dimExt(M ,M )=
ij uv
(0 otherwise.
The formula in terms of r =r(m) follows from the definition of r(−) (Proposition 3.1). (cid:3)
Remark 3.6. Alternatively, one can explicitly compute the Lie algebra of the stabilizer
group of a point in O and deduce equation (4) [ADK81, Lemma 3.2].
rk=r10 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
3.4. The effect of additional longestroots. Foradimensionvectord,orarankpattern
r let d+p, r +p be defined by adding p to every component. Consider O ⊂ Rep ,
rk=r d
O ⊂Rep . NotethattheKostantpartitioncorrespondingtor+pisobtainedfrom
rk=r+p d+p
the Kostant partition m of r by adding p to m and not changing the other components.
0N
In terms of lace diagrams, this consists of adding p longest intervals.
Theorem 3.7. The normal slices of O and O are isomorphic. In particular, the
rk=r rk=r+p
codimensions of these two orbits (in different representation spaces) are equal.
Proof. Using Lemma 3.4, we have that the normal slice of O is
rk=r+p
(6) Ext(M ⊕pM ,M ⊕pM )
0N 0N
=Ext(M,M)⊕pExt(M,M )⊕pExt(M ,M)⊕p2Ext(M ,M )
0N 0N 0N 0N
=Ext(M,M),
whichisthenormalslicetoO . ThelastequalityholdsbecauseM isbothaninjective
rk=r 0N
and a projective Q-module [FR02]. (cid:3)
3.5. Orbit hierarchy. We equip R with the partial order induced by entry-wise compar-
d
ison: for r,s∈R , we write
d
def
s≤r ⇔ ∀ i≤j, s ≤r .
ij ij
Inparticular,0istheminimalelementofR forthispartialorder. Thelowersemi-continuity
d
of the rank implies that O ⊂ O ⇒ s ≤ r. The converse also holds, and can be
rk=s rk=r
established using the combinatorics of lace diagrams:
Theorem 3.8. [AD80] If r,s∈Rorb, then O ⊂O if and only if s≤r.
d rk=s rk=r
Remark 3.9. Theorem 3.8 is also proven in [SB24]. It is generalized to the case of non
equioriented type A quivers in [AD85] and to equioriented type D quivers in [AD84]. The
remaining Dynkin cases seem to be open.
ThealgebraicgeometryandthesingularitiesoftheorbitclosuresO havebeenstudied
rk=r
extensively, see Section 1.4 for references.
4. Multiplication map and related loci
Consider the multiplication map
mult:Rep →Mat ,(A ,...,A )7→A ·A ...A
d dN,d0 1 N N N−1 1
We are interested in the geometry of the map mult and its fibers. Note that, for g =
(P ,...,P )∈G and A ∈Rep , we have
0 N ∗ d
(7) mult(g·A )=(P A P−1 )·(P A P−1 )...(P A P−1)=π (g)·mult(A )
∗ N N N−1 N−1 N−1 N−2 1 1 0 out ∗
In other words, the map mult is equivariant with respect to the actions of G on the source
(resp. G on the target) and the homomorphism π : G → G . In particular, when
out out out
g ∈ G , we have mult(g·A ) = mult(A ). The G -orbits on Mat are parametrized
in ∗ ∗ out dN,d0
by rank, which suggests the following definition.
Definition 4.1. For r∈N, define
Σr :={A ∈Rep | rkmult(A )=r}.
d ∗ d ∗
and
r
Σ :={A ∈Rep | rkmult(A )≥r}
d ∗ d ∗
Lemma 4.2. Σr 6=∅ if and only if 0≤r ≤mind.
d
Proof. The direct implication is clear. For the converse, consider a lace diagram L with r
horizontal intervals at the top. Then A (L)∈Σr. (cid:3)
∗ dGEOMETRY OF LINEAR NEURAL NETWORKS 11
We are interested in the algebraic geometry of Σr and Σr .
d d
r
Example 4.3. The sets Σ are a natural object in linear algebra.
d
r
• Σ is a determinantal variety.
a,b
• Σ0 isthecollectionofpairsof2×2matrices(A,B)forwhichBA=0. Thisvari-
(2,2,2)
etyturnsouttohavethreecomponents: (i){A=0}(ofcodimension4),(ii){B =0}
(of codimension 4), (iii) {det(A)=det(B)=0,BA=0} (of codimension 3).
• Σ0 isthecollectionofpairsofmatrices(A∈k3×2,B ∈k2×3)forwhichBA=0.
(2,3,2)
It has two components: (i) {rk(A) ≤ 1,BA = 0}, (ii) {rk(B) ≤ 1,BA = 0}. Both
have codimension 4.
• Σ0 isthecollectionofpairsofmatrices(A∈k4×2,B ∈k2×4)forwhichBA=0.
(2,4,2)
It is irreducible of codimension 4.
• Let d = (5,5,6,6,6,6). The variety Σ0 has five codimension 19 components and
d
many smaller dimensional components. One of the top dimensional components is
{(A ,A ,A ,A ,A ):rk(A )≤3,rk(A )≤4,rk(A )≤4,
1 2 3 4 5 1 2 4
rk(A A )≤2,rk(A A A )≤2,A A A A =0}.
2 1 4 3 2 4 3 2 1
This, and other similar examples, can be verified using Theorem 6.1 below.
By equivariance of mult, we have stratifications by G-orbits
Σr = O = O
d rk=r m
r∈Rr m∈Mr
ad ad
and
r
Σ = O = O
d rk=r m
r∈aR≤ dr m∈aM≤ dr
where
Rr :={r∈Rorb | r =r}, R≤r :={r∈Rorb | r ≤r}
d d 0N d d 0N
and
Mr :={m∈M+ | m =r}, M≤r :={m∈M+ | m ≤r}.
d d 0N d d 0N
Theorem 3.8 then implies
Corollary 4.4. Let 0≤r ≤mind.
(a) Σr is the Zariski closure of Σr.
d d
(b) The irreducible components of Σr are in bijection with the minimal elements of R≤r
d d
(or M≤r) under the partial order introduced in Section 3.5.
d
r
We can also reduce the study of the combinatorics of Σ to the case r =0 for a different
d
dimension vector.
Lemma 4.5. Let d∈NN+1 and 0≤r ≤mind. Then the injective map
Σ0 ֒→Σr ,C 7→ I r 0
d−r d ∗ 0 C
∗
(cid:18) (cid:19)
induces a bijection of irreducible components and we have
codim Σr =codim Σr =codim Σ0
Rep d d Rep d d Rep d−r d−r
or equivalently
N
dimΣr =dimΣr =dimΣ0 + 2 d −d −d r−Nr2.
d d d−r i 0 N
! !
i=0
X
Proof. We have
Rr :={r+r | r ∈R0 }
d d−r
hence the result follows from Corollary 4.4, Theorem 3.7 and Formula (1). (cid:3)12 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
This also gives information about the geometry of the fibers of mult, because of the
following elementary observation.
Lemma 4.6. Let d∈NN+1 and 0≤r ≤mind. Then (when k =C) the restriction of mult
to Σr is a locally trivial bundle over the manifold Matrk=r .
d dN,d0
Hence for every k and every B ∈ Matrk=r , there is a bijection between the irreducible
dN,d0
components of Σr and of mult−1(B), and we have
d
codim mult−1(B)=codim Σr +r(d +d −r)
Rep d Rep d d 0 N
or equivalently
dimmult−1(B)=dimΣr −r(d +d −r).
d 0 N
Proof. We are free to assume k = C by Theorem 3.3. As mentioned above, Matrk=r is an
dN,d0
orbit of the action of G on Mat . Fix B ∈ Matrk=r and A ∈ mult−1(B) as base
out dN,d0 dN,d0 ∗
points. Let GB be the stabilizer of B, so that the action map induces an isomorphism
out
Matrk=r . Then local sections of the induced smooth submersion G → Matrk=r induce
dN,d0 out dN,d0
local trivialisations of mult:Σr →Matrk=r by G -equivariance. (cid:3)
d dN,d0 out
r
Remark4.7. Whenk =R,onecanalsoaskabouttheirreduciblecomponentsofΣ asareal
d
analytic set. Those are not in generalthe same as the algebraicallyirreducible components,
because the real points of the orbits O can be disconnected. So in particular one should
m
be careful about how to interpret the number θ over R. However by Theorem 3.3, we know
that all algebraically irreducible components have real points, and that those real points
havethe same codimension as the algebraiccodimension, so the number C is unambiguous.
Note that the connected components of mult−1(B)(R) are known [TKB20, Theorem 5].
Corollary 4.8. Let d ∈ NN+1 and B ∈ Matrk=mind . Then Σmind and mult−1(B) are
dN,d0 d
smooth and (algebraically) connected varieties.
Proof. This follows from Lemma 4.5 and Lemma 4.6 together with the observation that,
when mind=0, we have Σ0 =Rep . (cid:3)
d d
5. Poincar´e series
In this section we present a Poincar´e series calculation that results in calculating the
dimension and the number of top-dimensional components of Σr. We will use freely some
d
tools from algebraic topology, namely equivariant cohomology of topological spaces acted
uponby Lie groups. Those arestandardtools inthe study ofquiverrepresentations[Rei10,
Rim13].
5.1. Pochammer symbols and the main statement.
Definition 5.1. For a non-negative integer s define
1
P = ,
s (1−q)(1−q2)···(1−qs)
the inverse of the q-Pochhammer symbol. We will identify this function with its |q| <
1 formal power series. For a multiset h = {h ,h ,...} of nonnegative integers (i.e., a
1 2
dimension vector or a Kostant partition), define
P = P .
h hi
i
Y
Given an evenly graded vector space V =⊕ V , its Poincar´e series is the formal power
n 2n
series P(V) = dim(V )qn. The inverse Pochammer symbol has an interpretation the
n 2n
PGEOMETRY OF LINEAR NEURAL NETWORKS 13
generating series of the number of partitions with at most s parts, and consequenctly as a
Poincar´eseries in equivariant cohomology:
P = q|µ| =P(C[c ,...,c ])=P(H∗(BGL (C)))=P(H∗ (pt)).
s 1 s s GLs
µ1≥. X..≥µs≥0
Here we have deg(c )=2i.
i
For later purposes we recall the infinite series expansion of the infinite Pochhammer
symbol (x;q) = ∞ (1−xqs) and its inverse [AAR99, Cor. 10.2.2]:
∞ s=1
∞
Q 1 = P xs
s
(x;q)
∞
s=0
X
∞
(8) (x;q)
∞
= (−1)sq( 2s) P sxs.
s=0
X
We encode the codimensions of the orbits into a power series as follows:
Definition 5.2. Let d∈NN+1 and r∈N.
Qr := qcodim(Om)P
d m
m⊢d
mX 0N=r
The role of Qr in our study is clarified by:
d
r
Lemma 5.3. Let 0≤r ≤mind, let C be the codimension of Σ ⊂Rep and θ the number
d d
of its top-dimensional irreducible components. Then
Qr =θqC +higher order terms.
d
Proof. LetthelowestdegreetermofQr benqc (temporarynotation). SinceP =1+higher
d m
degree terms, the definition of Qr implies that c is the codimension of O . As we
d m⊢d m
saw in Section 4, this union is precisely Σr, and we have moreover codSimm0 ΣN r=r = codimΣr .
d d d
Moreover, n is the number of orbits whose codimension is minimal. However, if an orbit
closureis nota component, then it cannothave minimalcodimension amongorbitclosures.
Therefore, n is also the number of the minimal codimensional irreducible components. (cid:3)
Remark 5.4. In the theory of characteristic classes of singularities—not discussed in this
paper except in Appendix A—the sum r Qs is the Poincar´eseries of the ideal of coho-
s=0 d
r
mology classes “universally supported” on Σ .
P d
The main result of this section is then a purely algebraic formula for Qr.
d
Theorem 5.5. We have
mind−r
(9) Qr
d
=P r· (−1)sq(s 2) P sP d−r−s.
s=0
X
WewillproveTheorem5.5inSection5.3. CombinedwithLemma5.3,thisTheorempro-
videsformulasforC andθwhicharenoteasytowriteinclosedformbutcanbeimplemented
efficiently in a computer algebra system.
Example 5.6. The series
Q0 =q3+6q4+..., Q0 =2q4+7q5+..., Q0 =q4+4q5+...
(2,2,2) (2,3,2) (2,4,2)
correspond to the special cases discussed in Example 4.3. We have
Q0 =2q7+8q8+27q9+67q10+151q11+...,
(3,3,3)
and hence Σ0 has 2 top-dimensional components, of codimension 7 (and hence, dimen-
(3,3,3)
sion 18−7=11). We have
Q0 =28q12+508q13+5129q14+37424q15+...,
(4,4,4,5,5,5,5,5,5,6,6,6)14 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
andhenceΣ0 has28top-dimensionalcomponents,ofcodimension12. The
(4,4,4,5,5,5,5,5,5,6,6,6)
statement is the same for any permutation of (4,4,4,5,5,5,5,5,5,6,6,6),cf. Section 5.4.
5.2. The spectral sequence. TheessenceoftheproofofTheorem5.5inSection5.3isthe
understanding of a spectral sequence. We introduce this spectral sequence and the relevant
arguments in the following known easier setting.
Theorem 5.7. We have
(10) P = qcodim(Om)P .
d m
m⊢d
X
This innocent-looking result is a special case of general combinatorial identities in the
Donaldson-Thomastheoryofarbitraryfinitequivers[Rei10,Theorem2.1],[Rim13,RWY18].
For N =1 (i.e. Q=(•→•)), it is equivalent to the well-known Durfee square identity, or,
the pentagon identity of quantum dilogarithms.
Proof of Theorem 5.7, following [Rim13]. WesawinSection2.3thatthegroupG = N GL (C)
d i=0 di
acts on Rep (C) with finitely many orbits O indexed by Kostant partitions. Let F de-
d m i
Q
note the union of orbits with codimension at most i. Let us apply the Borel construction
(B X =BG× X) to the filtration
G G
F ⊂F ⊂F ⊂...⊂F =Rep (C).
0 1 2 dim(Rep d) d
Wewillstudythe(Z-coefficient)cohomologyspectralsequenceassociatedwiththisfiltration
[AB83, Kaz97, Rim13].
Stabilizer subgroups of different points in the same orbit O are conjugate, hence iso-
m
morphic. It is known ([FR02, Prop 3.6]) that these stabilizers are homotopy equivalent to
G = GL (C).
m ij mij
LemmQa 5.8. [Kaz97, Rim13] The spectral sequence Epq degenerates at E , it converges to
∗ 1
H∗(BG ), and
d
Epq = Hq(BG ).
1 m
codimRMep,ROm=p
(where codimR =2codimC is the real codimension).
Proof of the Lemma. The convergence claim follows from the fact that Rep is (equivari-
d
antly) contractible. The formula for Epq follows from the usual description of the E page
1 1
asrelativecohomologies,ifoneappliesexcisionandtheThomisomorphismtotheserelative
cohomologies, see details in [Kaz97, Rim13]. The degeneration claim follows from the fact
that all orbits have even real codimension and that BG has no odd cohomology—hence
m
all differentials of the spectral sequence are 0. (cid:3)
Lemma 5.8 implies that
rk H2n(BG ) = rk(Epq).
d 1
p+q=2n
(cid:0) (cid:1) X
Multiplying this identity with qn and summing for all n—using Lemma 5.8—we obtain
(11) P(H∗(BG ))= qcodim(Om)P(H∗(BG )),
d m
m⊢d
X
and the statement of Theorem 5.7 follows. (cid:3)
5.3. Proof of Theorem 5.5.
Lemma 5.9. For 0≤r≤s we have
Qs−r =(1−qs−r+1)(1−qs−r+2)···(1−qr)·Qs.
d−r dGEOMETRY OF LINEAR NEURAL NETWORKS 15
Proof. There is a bijection between Kostant partitions m of d−r with m = s−r and
0N
Kostant partitions m′ of d with m =s. The bijection is just adding r to the component
0N
m , cf. Section 3.4. We obtain
0N
(12) Q ds− −r
r
= qcodim(Om)P
m
= qcodim(O m′)P m′.
m X⊢d−r mX′⊢d
m0N=s−r m′ =s
0N
According to Theorem 3.7 (based on Lemma 3.4) we have codim(O )=codim(O ), and
m m′
P =P ·(1−qs−r+1)(1−qs−r+2)···(1−qr).
m m′
Hence, (12) is further equal
(1−qs−r+1)(1−qs−r+2)···(1−qr) qcodim(O m′)P
m′
mX′⊢d
m′ =s
0N
=(1−qs−r+1)(1−qs−r+2)···(1−qr)Qs,
d
as we wanted to prove. (cid:3)
Observe that if we prove Theorem 5.5 for r = 0, then the r > 0 cases follow using
Lemma 5.9. So, from now on we focus on the r =0 case.
We now use Theorem 5.7, which by definition of Qs can be rewritten as
d
mind
(13) P = Qs.
d d
s=0
X
Apply Lemma 5.9 for each term of the right hand side with r=s. We obtain
mind
(14) P = P Q0 .
d s d−s
s=0
X
Using the temporary notation
d′ 0 =mind, a i =P d−d′ 0+i b i =Q0 d−d′ 0+i
equations (14) for d,d−1,d−2,... together are equivalent to the single equation
∞ ∞ ∞
b xs P xs = a xs,
s s s
! !
s=0 s=0 s=0
X X X
of power series in a new formal variable x. From this, using (8) we obtain
∞ ∞ ∞ −1 ∞ ∞
b sxs = a sxs P sxs = a sxs (−1)sq(s 2) P sxs .
! ! ! !
s=0 s=0 s=0 s=0 s=0
X X X X X
For the coefficient of
xd′
0 this yields
d′
0
b d′ = a
r−s(−1)sq(s 2)
P s,
0
s=0
X
which—unfoldingourtemporarydefinitions—isthestatementofTheorem5.5forr =0. (cid:3)16 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
5.4. Permutation invariance. Theorem 5.5 has the following consequence, which we
found quite surprising (cf. Remark 5.11).
Corollary 5.10. The numbers C, θ are invariant under permutations of d.
Proof. All ingredients on the right hand side of (9) are invariant under such permutations.
(cid:3)
In Appendix A we will give another proof of this invariance. We do not know of a proof
relying solely on equation (4) and the combinatorics of Kostant partitions. Note that given
a permutation σ(d) of d, the sets of Kostant partitions M+ and M+ do not necessarily
d σ(d)
have the same cardinality, and in particular σ does not induce a bijection between them.
r
Remark 5.11. One reason that Corollary 5.10 is surprising is that the geometry of Σ
d
undergoes significant changes when the components of d are permuted. First of all, it is
clear from equation (1) that the dimension of Rep is not permutation invariant, so that it
d
r
is only the codimension of Σ which is invariant and not its dimension. For example,
d
dim(Rep )=106=12=dim(Rep ).
(2,2,3) (2,3,2)
r
Moreover, the total number of irreducible components of Σ is not permutation invariant.
d
UsingCorollary4.4,onecaneasilycheckthatΣ0 has2irreduciblecomponents(bothof
(2,3,2)
codimension 4) while Σ0 and Σ0 have 3 irreducible components (2 of codimension
(2,2,3) (3,2,2)
4 and 1 of codimension 6).
6. Reducing the problem to a quadratic integer program
While Theorem 5.5 is a very effective way of calculating the number of top-dimensional
components of Σ0, it is useless for asymptotic analysis. Hence, it is desirable to have more
d
explicitformulas. Towardssuch,wefirstreducetheproblemofcalculatingC andθ toaqua-
dratic integer program. The argument is almost independent of Section 5; almost, because,
inthe case whenthe dimension vectordis notweaklyincreasing,we use Corollary5.10. As
we saw above, it is enough to treat the case r =0 and we do so in this section.
6.1. Top-dimensional components of Σ0 and a QIP. For a dimension vector d =
d
(d ,d ,...,d ) let d′ =(d′ ≤d′ ≤... ≤d′ ) be the same multiset, but arranged (weakly)
0 1 N 0 1 N
increasingly. Consider N-tuples ofnon-negativeintegerse=(e ,e ,...,e )andthe follow-
1 2 N
ing quadratic integer program for them:
min G (e)= e (e +d′ −d′ )
d i j j j−1
1≤j≤i≤N
(QIP) NX
s.t. e ∈N, e =d′.
i i 0
i=1
X
Theorem 6.1. The codimension of the top-dimensional components of Σ0 is the minimal
d
value of (QIP). The number of top-dimensional components of Σ0 is the number of times
d
(QIP) attains its minimum value.
Example 6.2. For d = (2,2,3) the (QIP) is minimizing the function G (e) = e2+e e +
d 1 1 2
e2 +e on the three-element set {(0,2),(1,1),(2,0)}. The minimum is 4, attained at the
2 2
second and third element of the set. Hence θ =2, λ=4, cf. Examples 4.3, 5.6.
Example 6.3. For d = (8,8,11,11,11,13,13,13,15) the minimal value of (QIP) is 55,
and it is achieved at four points: e = (4,2,1,1,0,0,0,0), e = (4,1,2,1,0,0,0,0), e =
(4,1,1,2,0,0,0,0),e=(5,1,1,1,0,0,0,0). We will use this dimension vector d to illustrate
some combinatorial phenomena below (cf. Figure 1).GEOMETRY OF LINEAR NEURAL NETWORKS 17
6.2. Proof of Theorem 6.1. In view of Corollary 5.10 it is sufficient to prove Theorem
6.1 for the dimension vector d′ whose components are weakly increasing.
We need to establish a useful fact about lace diagrams in the weakly increasing case.
Recallthat a lace diagramis an arrangementsof dots in columns 0,1,...,N, partitionedto
anumberof[i,j]intervals(laces)andthatKostantpartitionsareequivalenceclassesoflace
diagrams under permutations (Lemma 2.10).
Given a Kostant partition, it is not always possible to choose a lace diagram with only
horizontal laces. For example, the lace diagrams attached to a certain Kostant partition in
M+ are
(1,2,1)
(15) • • • • • • • • .
Lemma 6.4. Assume that the dimension vector d is weakly increasing. Then for any
Kostant partition m ∈ M+ there is a lace diagram L with m(L) = m and only horizontal
d
laces.
Proof. Induction on N (the number of columns). (cid:3)
Let L be a lace diagram representing the orbit O of Rep whose closure is a top-
m d′
dimensional component of Σ0 . We choose L to have only horizontal laces by Lemma 6.4.
d′
For our next arguments the reader is advised to look at Figure 1. We will call the
horizontallines of dot positions in L “rows”. Since the orbit O is in Σ0 , none of the rows
m d′
in L can be the full [0,N] interval. The top d′ rows have dots in all columns, hence we
0
obtain that in the top d′ rows at least one of the [i−1,i] intervals is not part of the lace
0
diagram.
We claim that in all these rows exactly one [i−1,i] interval is missing and all the others
arelaces. Assumetothecontrarythattherearetwosuchintervalsmissinginarow. Adding
one of them back, the orbit of this new lace diagram would contain O in its closure, and
m
it would still belong to Σ0 . This contradicts the fact that O is a component of Σ0 .
d′ m d′
An analoguous argument shows that in the rows below the top d′ rows all possible
0
horizontalintervals arelaces ofL. In effect L has the structure indicated by the example in
Figure 1.
What we found about the structure of L translates to algebra as follows: the Q-module
corresponding to L is of the form
M = e (I +I ) + e (I +I ) + ... + e (I +I )
1 00 1N 2 01 2N N 0,N−1 NN
+ f ( I ) + f ( I ) + ... + f ( I )
1 1N 2 2N N NN
for some integers e and f , see again Figure 1. In fact f are determined by the dimension
i i i
vectord′ as f =d′ −d′ , while e canbe any non-negativeintegers whose sum is d′. The
j j j−1 i 0
codimensionof O is dimExt(M,M) (see Lemma 3.4). Using the bilinearity of Ext and (5)
d
we obtain
dimExt(M,M)= e (e +f )dimExt(I ,I )
i j j 0,i−1 jN
1≤j≤i≤N
X
= e (e +f )= e (e +d′ −d′ )=G (e),
i j j i j j j−1 d
1≤j≤i≤N 1≤j≤i≤N
X X
and the theorem follows. (cid:3)
Remark 6.5. When d is weakly increasing, the proof of Theorem 6.1 provides an explicit
bijection between the set of top-dimensional components of Σ0 and the solutions of (QIP).
d
The combinatorial description of the θ top dimensional components of Σ0 for arbitrary d
d
(not necessarily weakly increasing) will be given in [KR24].18 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
0 1 2 3 4 5 6 7
• • • • • • • •
• • • • • • • • e 1 =2
• • • • • • • •
d′ 0 • • • • • • • • • • • • • • • • e 2 =3
• • • • • • • •
• • • • • • • • ee 55 ==22
• • • • • • • • e =1
• • • • • • 7
• • • • • • f =3
• • • • • • 2
• • • •
• • • • f 4 =2
•
• f 7 =2
(e =e =e =f =f =f =f =0)
3 4 6 1 3 5 6
Figure 1. A lace diagram with weakly increasing dimension vector and
horizontal laces, cf. Example 6.3
7. Explicit formulas for the codimensions of loci
In this section, we make use of the rather simple structure of (QIP) and give an explicit
solution to it. The final result is stated in Theorem 7.10 below, but this requires some
additional notation.
Lemma 7.1. The function
l
l∈{0,2,...,N}7→ d′ −ld′
i l
!
i=0
X
is weakly decreasing and positive for l=1.
Proof. This follows from
l l
d′ −(l+1)d′ − d′ −ld′ =l(d′−d′ )≤0
i l+1 i l l l+1
! ! !
i=0 i=0
X X
since d′ is weakly decreasing. The value for l=1 is d′ >0. (cid:3)
0
Depending of d, this function may or may not become negative for l = N. We can,
however,always make the following definition.
Definition 7.2. Define
l
m=max l | d′ ≥ld′ ∈{1,2,...,N}.
i l
( )
i=0
X
To solve (QIP), we first define an integer D and vectors s,ˆs associated with the weakly
increasing dimension vector d′ = (d′ ≤ d′ ≤ ... ≤ d′ ). The reader may find Figure 2 and
0 1 N
Example 7.7 useful to understand these definitions.
Definition 7.3. Consider the points
s:=(d′ −d′,d′ −d′,d′ −d′,.........,d′ −d′ )∈ZN,
0 1 0 2 0 3 0 N
ˆs:=(d′ −d′,d′ −d′,d′ −d′,...,d′ −d′ )∈Zm,
0 1 0 2 0 3 0 m
and let ˆv ,vˆ ,...,vˆ be the set of integer points in the hyperplane { m x = d′} closest
1 2 k i=1 i 0
to ˆs in the Euclidean distance.
P
Definition 7.4. Define
Dˆ :=kˆs−vˆ k2
i
(which is independent of i by definition). Define v to be the image of vˆ under the standard
i i
embedding Zm ⊂ZN, (x ,...,x )7→(x ,...,x ,0,...,0) and D :=ks−v k2.
1 m 1 m iGEOMETRY OF LINEAR NEURAL NETWORKS 19
By construction we have
N
(16) D =Dˆ + (d′ −d′)2.
i 0
i=m+1
X
Theorem 7.5. For d′ =(d′ ≤d′ ≤...≤d′ ) the solution of the quadratic integer program
0 1 N
(QIP) (ie. the codimension of Σ0) is
d
m
1
(17) Dˆ +d′2 − (d′ −d′)2 ,
2 0 i 0
!
i=1
X
and this minimum is attained at k points (ie. Σ0 has k largest dimensional components).
d
Proof. Consider the (QIP). Denoting the objective function e (e +d′ − d′ ) by
j≤i i j j j−1
G (e), we have
d
P
2
2G
(e)−d′2
= 2G (e)− e
d 0 d i
= e (d′
−(cid:16)X
d′
)(cid:17)
+ e2
i j j−1 i
j≤i i
X X
= 2e (d′ −d′)+e2
i i 0 i
i
X
= (e −(d′ −d′))2 − (d′ −d′)2
i 0 i i 0
!
i i
X X
Therefore, using the notations from Definitions 7.2-7.4, for the optimal solution Gopt of
d
(QIP) we get
N
2Gopt−d′2 + s2 =D,
d 0 i
i=1
X
where D is the smallest distance-square between s and integer points of the simplex
N
e =d′, e ≥0,
i 0 i
i=1
X
cf. the left picture in Figure 2. The projection of s to the hyperplane N e =d′ is
i=1 i 0
s+
d′ 0− N i=1s i
(1,1,...,1).
P
N
P !
Because of our choices the components of this vector are weakly decreasing; and possibly
thefewlastcomponentsarenegative. Inthosecoordinatestheoptimalchoicefore mustbe
i
0, and our task reduces to the analogous “smallest distance-square” problem in the smaller
dimensional space with coordinates e ,...,e . We can drop the last few coordinates and
1 l
keep only the first l coordinates, until the vector
d′ − l s
(s ,s ,...,s )+ 0 i=1 i (1,1,...,1).
1 2 l
l
P !
has all non-negative coordinates. The condition for the latter is
d′ − l s
s + 0 i=1 i ≥0.
l
l
P !
Substitutingthedefinitions =d′−d′,thisconditionreducestotherelationinDefinition7.2:
l 0 l
l d′ ≥ld′. That is we can drop all but the first m coordinates.
i=0 i l
Together with equation 16, this completes the proof of Theorem 7.5, both about the
eP xtreme value of (QIP) and about the number of times the extreme value is attained. (cid:3)20 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
e
2 RN
•
e
2
Rm
Ne =d′ •
i 0 •
e ≥0 •
i
P me =d′
e i 0
distance2 =D 3
• P k=2
• ••
••
• •vˆ 1
vˆ
••• • 2
•• • e
• e 1 • • 1
s
• v 1,v 2 ˆp
ˆs
•
Figure 2. Illustration of the concepts in Section 7.
To get more explicit formulas from Theorem7.5, it remains to find the integer vectors in
the { m e =d′} hyperplane closest to a given vector ˆs in Zm. Luckily, this problem has
i=1 i 0
an explicit solution [CS88, Ch. 20], that we describe now, for our special case.
P
Consider
d′ − m ˆs
ˆp=ˆs+ 0 j=1 j (1,1,...,1) ∈Rm,
m
P !
this is the projection of ˆs to the hyperplane m e =d′. Writing
i=1 i 0
m
P
S := d′
j
j=0
X
we have for every 1≤i≤m
d′ − m (d′ −d′)
0 j=1 0 j S
ˆp =(d′ −d′)+ =d′ − .
i 0 i (cid:16) P m (cid:17) i m
Rounding it to the closestinteger coordinate-wisewill be denoted by r(pˆ)=(r(pˆ)) ,
i i=1,...,m
where r(x)=⌊x+ 1⌋, so that
2
S 1
0
r(pˆ )=−d + + .
i i m 2
(cid:22) (cid:23)
This vector may not be in the hyperplane and we need to correct for this. Let
m
S 1
(18) δ =d′ − r(pˆ)=S−m +
0 i m 2
i=1 (cid:22) (cid:23)
X
andletǫ=sgn(δ)∈{−1,0,1}beitssign. Let∆ ,∆ ,...∈{−1,0,1}mbethesetofvectors
1 2
with |δ| coordinates being ǫ, and the rest of the coordinates being 0.
Proposition 7.6. [CS88, Ch. 20] With the notations above, the vˆ ,vˆ ,...,vˆ vectors are
1 1 k
r(pˆ)+∆ ,r(pˆ)+∆ ,r(pˆ)+∆ ,....
1 2 3
In particular, the number of top-dimensional components of Σ0 is
d
m m
(19) k = = .
δ S−m S + 1
(cid:18) (cid:19) (cid:18) m 2 (cid:19)
(cid:4) (cid:5)GEOMETRY OF LINEAR NEURAL NETWORKS 21
Example 7.7. Let d′ =(7,7,8,9,12,13). Definition 7.2 gives m=3, and we obtain
10 7 4
s=(0,−1,−2,−5,−6), ˆs=(0,−1,−2), ˆp= , , , r(pˆ)=(3,2,1).
3 3 3
(cid:18) (cid:19)
We have δ =1, ǫ=1, and the collection of ∆ vectors is (1,0,0),(0,1,0),(0,0,1). Therefore
k = 3 and vˆ = (4,2,1), vˆ = (3,3,1), vˆ = (3,2,2). We obtain that (QIP) takes its
1 2 3
minimum at the vectors
v =(4,2,1,0,0), v =(3,3,1,0,0), v =(3,2,2,0,0).
1 2 3
Further, we have Dˆ = kˆs−vˆ k2 = kˆs−vˆ k2 = kˆs−ˆv k2 = 34, and the optimal solution
1 2 3
of (QIP) according to (17) is Gopt = 39. We conclude that Σ0 has 3 top-dimensional
d d′
components, each of codimension 39.
It remains to compute Dˆ more explicitly. We write {x}=x−⌊x⌋ for the fractionalpart
of x∈R.
Lemma 7.8. If δ ≥0, we have
S S 1 S S
δ =m and + = − .
m m 2 m m
(cid:26) (cid:27) (cid:22) (cid:23) (cid:26) (cid:27)
If δ <0, we have
S S 1 S S
δ =m −m and + = − +1.
m m 2 m m
(cid:26) (cid:27) (cid:22) (cid:23) (cid:26) (cid:27)
Proof. Write S =mT +S¯ with T ∈N and 0≤S¯<m. Then by equation (18), we have
m
δ ≥0⇔S¯< .
2
Moreover,
S 1 2S¯+m
m + =mT +m
m 2 2m
(cid:22) (cid:23) (cid:22) (cid:23)
which together with equation (18) concludes the proof. (cid:3)
Proposition 7.9. We have
S S S2
Dˆ =m 1− + +md2−2d S
m m m 0 0
(cid:26) (cid:27)(cid:18) (cid:26) (cid:27)(cid:19)
Proof. We only treat the case δ ≥0, the other one is analoguous. We have
Dˆ = kˆs−vˆ k2
1
S 1 2 S 1 2
= δ d − + −1 +(m−δ) d − +
0 0
m 2 m 2
(cid:18) (cid:22) (cid:23) (cid:19) (cid:18) (cid:22) (cid:23)(cid:19)
2 2
S S S S S S
= m d − + −1 +m 1− d − +
0 0
m m m m m m
(cid:26) (cid:27)(cid:18) (cid:26) (cid:27) (cid:19) (cid:18) (cid:26) (cid:27)(cid:19)(cid:18) (cid:26) (cid:27)(cid:19)
S S S2
= m 1− + +md2−2d S
m m m 0 0
(cid:26) (cid:27)(cid:18) (cid:26) (cid:27)(cid:19)
where we have used Lemma 7.8 in the third equality. (cid:3)
We have finally arrived at the explicit formulas.
Theorem 7.10. Let d ∈ NN+1 and 0 ≤ r ≤ mind. As above, let d′ = (d′ ≤ d′ ≤ ... ≤
0 1
d′ )∈NN+1 betheweaklyincreasingreorderingofdandletmbedefinedasinDefinition7.2.
N
Finally, let S = m d′ and S˜=S−(m+1)r. We have
i=0 i
2
codim Σr =Pm S˜ 1− S˜ − m(m−1) S˜ + (d′ −r)(d′ −r)
Rep d d 2 m m 2 m i j
( ) ( )! !
0≤i<j≤m
X22 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
Let B ∈Matrk=r . Then we have
dN,d0
2
m S˜ S˜ m(m−1) S˜
(20) codim mult−1(B)= 1− −
Rep
d 2 m m 2 m
( ) ( )! !
+ (d′ −r)(d′ −r)+r(d +d −r).
i j 0 N
0≤i<j≤m
X
Both Σr and mult−1(B) have the same number m of top-dimensional irreducible
d S˜−m jmS˜+1
2k
components.
(cid:0) (cid:1)
Proof. By Lemmas 4.5 and 4.6, it suffices to prove the common case r = 0 of the claims
above, namely
2
m S S m(m−1) S
codimΣ0 = 1− − + d′d′
d 2 m m 2 m i j
(cid:26) (cid:27)(cid:18) (cid:26) (cid:27)(cid:19) (cid:18) (cid:19) 0≤i<j≤m
X
which follows from Theorem 7.5, Proposition 7.9 and an elementary computation, and
m
k= .
S−m S + 1
(cid:18) m 2 (cid:19)
which is equation (19). (cid:4) (cid:5) (cid:3)
Remark 7.11. It is not immediate from the formulas that those codimensions are in-
tegers. However one can easily show that, for any positive integers S˜,m, the quantity
2
m S˜ 1− S˜ − m(m−1) S˜ is an integer. It is also possible to rewrite things to
2 m m 2 m
manke tohi(cid:16)s appnareont(cid:17), but the res(cid:16)ulti(cid:17)ng formula is a bit more complicated and we omit it.
Example 7.12. Let d = (d,d,...,d) ∈ NN+1 be a constant dimension vector and r = 0.
We have m=N and S˜=S =(N +1)d. Theorem 7.10 then implies
N d d (N +1)d2
codimΣ0 = 1− + .
d 2 N N N 2
(cid:26) (cid:27)(cid:18) (cid:26) (cid:27)(cid:19)
When N >d, we have d = d so that
N N
(cid:8) (cid:9) d(d+1)
codimΣ0 = .
d 2
which is in particular independent of N. On the other hand, for fixed N and d → ∞, we
see that
(N +1)d2
codimΣ0 ∼ .
d d→∞ N 2
Informally we see in both cases that the magnitude of codimΣ0 is not too sensitive to N
d
(“the depth”), only to d (“the width”) of the quiver (“network”), cf. Section 8.
8. Real-log canonical threshold of deep linear networks
The initial motivation of this work was to better understand the work of Aoyagi[Aoy24]
and to relate it to the theory of quiver representations. Aoyagi’s work takes place in the
context of singular learning theory, the Bayesian statistics of singular statistical models
[Wat09, Wat18, Wat24]. In singular learning theory, the real log-canonical threshold (rlct),
a geometric invariant of singularities of real analytic functions, plays a central role because
it controls the asymptotic performance of Bayesian inference.
Definition 8.1. Let X be a real analytic manifold and F :X →R a real analytic function.
(i) The real log canonical threshold (RLCT) of F is
rlct(F):=sup{s∈R | |F|−s is locally integrable }∈R∪{∞}GEOMETRY OF LINEAR NEURAL NETWORKS 23
(ii) Let x∈X. The local real log canonical threshold of F at x is
rlct (F):=sup{s∈R | |F|−s is locally integrable at x}∈R∪{∞}.
x
The rlct comes with a secondary invariant, the real log-canonical multiplicity (rlcm),
which we only define in the local case for simplicity. This is an opportunity to introduce
archimedeanzetafunctions, whichplayanimportantroleinsingularitytheoryandsingular
learning theory.
Proposition-Definition 8.2. Let X be a real analytic manifold, F : X → R a real an-
alytic function and x ∈ X. Fix a volume form dvol on X and a relatively compact open
neighbourhood U of x The local archimedean zeta function
ζ (s):= |F|sdvol
F,U
ZU
which is a priori defined for Re(s) ≫ 0 extends to a meromorphic function. The poles of
ζ (s) are independent of U small enough and are negative real numbers. The largest pole is
F
−rlct (F), and we define the reallog-canonicalmultiplicity rlcm (F)∈N to be the order of
x x
that pole.
This proposition goes back to Atiyah [Ati70] and the proof is based on (real analytic)
resolution of singularities.
Remark 8.3. As the name suggests, the rlct and the rlcm are the real counterparts of
the log-canonical threshold (lct) and the associated multiplicity in complex (algebraic and
analytic) geometry. The lct plays an important role in complex singularity theory and bira-
tional geometry, and has been studied much more intensively than its real counterpart (see
[Mus11, Kol97].
Herearesomefundamentalpropertiesoftherlctwhichweneedtoputourresultsincon-
text. Wereferto[Lin11]andtotheupcomingpaper[Leh24]foracomprehensivetreatment.
Proposition 8.4. Let X be a real analytic manifold, F : X → R a real analytic function
and x∈X.
(i) 0<rlct (F)<∞ ⇔ F(x)=0 and rlct(F)<∞ ⇔ F−1(0)6=∅.
x
Moreover, when F(x)=0, we have
codim F−1(0)
(21) rlct (F)∈ 0, X,x ∩Q.
x
2
(cid:18) (cid:21)
(ii) The function x7→rlct (F) is lower semi-continuous.
X,x
(iii)
rlct(F)= inf rlct (F)
x
x∈X
This inf is not always attained in the general real analytic case because of potential
issues “at infinity”, but it is in many cases f.(e.g., when X is compact or when X,F
are algebraic). When it is attained, we have
codim F−1(0)
(22) rlct(F)∈ 0, X ∩Q.
2
(cid:18) (cid:21)
(iv) Let G:X →R be another real analytic function. Then we can consider F +G and
F ·G as functions on X ×Y. Then
rlct(FG)= min(rlct(F),rlct(G)) and
rlcm(F) if rlct(F)<rlct(G)
rlcm(FG)= rlcm(G) if rlct(F)>rlct(G)

rlcm(F)+rlcm(G) if rlct(F)=rlct(G).

Assume F,G≥0. Then

rlct(F +G)=rlct(F)+rlct(G) and rlcm(F +G)=rlcm(F)+rlcm(G)−124 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
Example 8.5. The definition immediately implies, for any n∈N
1
rlct(xn)= .
n
Using Statement (iv) above, we deduce that, for X =Rd and e≤d
1
rlct(xn1...xne)=min
1 d n
i
and
1 1
rlct(x2n1 +...+x2ne)= +...+
1 e 2n 2n
1 e
In particular, if F =x2+...+x2 then
1 e
e codim F−1(0)
X
rlct(F)= =
2 2
saturates the inequality (22).
In singular learning theory, the rlct and the rlcm of a certain function K control the
asymptotic performance of Bayesian inference in a large class of statistical models as the
size of the dataset increases. More precisely, K arises as the relative entropy (or Kullback-
Leibler divergence) between the true distribution and the model, considered as a function of
model parameters.
In[Aoy24],Aoyagicomputesthereallog-canonicalthresholdoftherelativeentropyfunc-
tionofdeep linear neural networks. Deeplinear networksare obtainedfromstandard(feed-
forward,fully-connected)deeplinearnetworksbyreplacingtheirnon-linearactivationfunc-
tionsbylinearmaps. Despitetheirsimplicity,theyareauseful“toymodel”inmoderndeep
learning theory, as we discussed in Section 1.4. By definition, the weights of a deep linear
networks are a tuple of composable matrices, and the function computed by the network is
their product, so the parameter space of the model is Rep where d ∈ NN+1 records the
d
widths of the layers and N is the depth of the network. We also need a “true distribution”
generating the data, or rather in this context a “true function”. Aoyagimakes the assump-
tion that this true function is linear and given by some B ∈ Matrk=r with 0 ≤ r ≤ mind.
dN,d0
This condition onthe rank emsures that B ∈Im(mult); in statisticalterminology,we are in
the realisable or well-specified case.
We now define directly the function K = KDLN for our deep linear model, referring to
B
[Aoy24] for a derivation of how it arises as a relative entropy. As it turns out, in this case,
KDLN is algebraic:
B
(23) KDLN(A ):=kmult(A)−Bk2 =Tr((mult(A)−B)t(mult(A)−B)))
B ∗ 2
We have KDLN(A )≥0 and
B ∗
(KDLN)−1(0)=mult−1(B)
B
so that by Equation 21 we find
codimmult−1(B)
rlct(KDLN)≤ .
B 2
The main result of [Aoy24] is then the computation of rlct(KDLN), which thanks to our
B
results we can reformulate cleanly as
Theorem 8.6.
codimmult−1(B)
rlct(KDLN)= .
B 2
and, with the notations of Section 7,
S˜ S˜
rlcm(KDLN)=m2 1−
B m m
( ) ( )!GEOMETRY OF LINEAR NEURAL NETWORKS 25
Proof. This follows from a comparison between Formula (20) in Theorem 7.10 and [Aoy24,
Theorem 1]. To see this requires some translations between our notations and the ones in
loc.cit (Note the shift by one and reverse ordering of the dimensions):
[Aoy24] This paper
Dimension vector (H(L+1),...,H(1)) (d ,...,d )
0 N
Reduced dimension vector (ML+1,...,M(1)) (d −r,...,d −r)
0 N
Number of “relevant” dimensions l m
Set of “relevant” reduced dimensions (M(S1),...,M(Sl+1)) (d′ −r,...,d′ −r)
0 m
Inparticular,theintegersM andadefinedin[Aoy24,Theorem1]translateinournotation
to
S˜
M =
m
& '
and
S˜
a=S˜−m +m
m
& '
so that
a(l−a) S˜ S˜ S˜ S˜
=m 1+ − − +
l m m m m
& '! & '!
Nowwe makethe followingelementaryobservationaboutceilingandfloorfunctions: forall
x∈R,
(⌈x⌉−x)(1+x−⌈x⌉)={x}(1−{x}).
and conclude that
a(l−a) S˜ S˜
=m 1− .
l m m
( ) ( )!
Using this, we now recognize that Formula (20) in Theorem 7.10 is exactly (twice) the
first formula for λ = rlct(KDLN) in [Aoy24, Theorem 1]. There is also a formula for the
B
multiplicity in [Aoy24, Theorem 1], which we simply translate into our notations. (cid:3)
Remark 8.7. As far as we now, there is no simple relationship between rlcm(KDLN) =
B
m2 S˜ 1− S˜ andthenumberk = m ofirreduciblecomponentsofmult−1(B).
m m S˜−m jmS˜+1
2k
n o(cid:16) n o(cid:17)
(cid:0) (cid:1)
WeexpectthattheformulaofTheoremforglobalrlctsalsoextendstolocal rlctsandcodi-
mensions, i.e., that for every A ∈ mult−1(B) we have rlct (KDLN) = codimA∗mult−1(B).
∗ A∗ B 2
We plan to come back to this question in future work.
Appendix A. Another algebraic characterization of λ and θ.
Weshowedthreeefficientwaystocalculatethedimensionoftop-dimensionalcomponents
of Σr: Theorems 5.5, 6.1, and 7.10. In this section—as an added bonus—we give another
d
characterization(of both C and θ) that is less calculationally efficient than the other three.
However,itsuggestssomerelationswiththeso-calledinterpolationmethodforcharacteristic
classes of singularities.
For a dimension vector d and an integer r, consider the degree 1 variables y ,...,y
1 r+1
and x for 0≤i≤N,1≤j ≤d . Define
ij i
R =Z[x :0≤i≤N,1≤j ≤d ], and H =RSd
d ij i d d26 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
where S = S ×S ×...×S , and the symmetric group S permutes the variables
d d0 d1 dN di
x ,...,x . The map ψ in the diagram
i1 idi r
R
ψr
Z[y ,...,y ,x :0≤i≤N,r+1<j ≤d ]
d 1 r+1 ij i
φr
H
d
is defined by
y if j ≤r+1
j
x 7→
ij
(x
ij
if j >r+1.
Themapφ istherestrictionofψ toH . LetAr bethekernelofφ —ahomogeneousideal.
r r d d r
As before, the number and codimension of the top-dimensional components of Σr are
d
denoted by θ and C.
Theorem A.1. The degree and rank of the lowest degree part of Ar are C and θ.
d
Proof. Here we just sketchthe proof. The elements of H G∗(Rep d)(∼ =H d) that aresupported
on Σr form an ideal, the so-called avoiding ideal. On the one hand, this ideal can be
d
calculated as a kernel of the restriction map to Rep −Σr (namely, the map φ ). On the
d d r
other hand, the fundamental classes of the largest dimensional components of Σr form a
d
basis for the lowest-degree part of Ar, and the theorem follows. Details on avoiding ideals
d
in general are in [FR04], and details on restriction maps for Rep are in [FR02]. (cid:3)
d
Example A.2. (Cf. Examples 4.3, 5.6, 6.2.) For d = (2,2,3) let us use the following
notation: let a ,a ; b ,b ; c ,c ,c be the elementary symmetric polynomials of x ,x ;
1 2 1 2 1 2 3 11 12
x ,x ; x ,x ,x , respectively. Hence deg(a ) = deg(b ) = deg(c ) = i. By definition,
21 22 31 32 33 i i i
the ideal A0 is the kernel of the ring homomorphism
d
φ :Z[a ,a ,b ,b ,c ,c ,c ] → Z[y,x ,x ,x ,x ]
0 1 2 1 2 1 2 3 12 22 32 33
x ,x ,x 7→ y.
11 21 31
Calculation shows that the lowest degree part of this ideal is of degree 4, and of rank 2. In
fact, it is spanned by the two (⇒θ =2) degree four (⇒C =4) polynomials
a b b −a b c −a b2+a b c +a c +a b −a c −b c −b2+b c , and
1 1 2 1 2 1 2 1 2 1 1 1 3 2 2 2 2 1 3 2 2 2
a2b −a a b −a b b +a b2+a2−2a b +b2
1 2 1 2 1 1 1 2 2 1 2 2 2 2
=(x −x )(x −x )(x −x )(x −x ),
21 11 22 11 21 12 22 12
that are the fundamental classes of the orbit closures corresponding to the lace diagrams
• • • • • • and • • • • • • .
• •
Clearly,TheoremA.1 is less computationally efficientthan our earliertheorems calculat-
ing C and θ. Nevertheless, it (just like Theorem 5.5) also displays the a priori non-obvious
fact that C and θ are invariant under the permutation of the components of d (cf. Corol-
lary 5.10).
References
[AAR99] G. E. Andrews, R. Askey, and R. Roy. Special Functions. Number 71 in Enc. of Math. and
Appl.CUP,1999.
[AB83] M.Atiyahand R.Bott. TheYang-Millsequation over Riemann surfaces.Phil. Trans. of the
Royal Soc. London, 308(1505):523–615, 1983.
[ACGH19] SanjeevArora,NadavCohen,NoahGolowich,andWeiHu.Aconvergenceanalysisofgradient
descentfordeeplinearneuralnetworks,2019.
[AD80] S.AbeasisandA.DelFra.Degenerations fortherepresentations ofanequiorientedquiverof
typeAm.Boll. Unione Mat. Ital., Suppl.,2:157–171, 1980.GEOMETRY OF LINEAR NEURAL NETWORKS 27
[AD84] S.AbeasisandA.DelFra.Degenerations fortherepresentations ofanequiorientedquiverof
typeDm.Adv. Math.,52(2):81–172, 1984.
[AD85] S. Abeasis and A. Del Fra. Degenerations for the representations of a quiver of type Am.
Journal of Algebra,93:376–412, 1985.
[ADK81] S. Abeasis, A. Del Fra, and H. Kraft. The geometry of representations of Am. Math. Ann.,
256:401–418, 1981.
[AMG24] E.MehdiAchour,F.Malgouyres,andS.Gerchinovitz.Thelosslandscapeofdeeplinearneural
networks: asecond-orderanalysis,2024.
[Aoy24] M.Aoyagi. Consideration on the learningefficiency of multiple-layered neural networks with
linearunits.Neural Networks,172(106132):1–11, 2024.
[Ati70] M.Atiyah.Resolutionofsingularitiesanddivisionofdistributions.Communications on pure
and applied mathematics,23(2):145–150, 1970.
[BFR05] A.S.Buch,L.Feh´er,andR.Rima´nyi.PositivityofquivercoefficientsthroughThompolyno-
mials.Adv. Math.,197:306–320, 2005.
[CLM+23] Z.Chen, E.Lau,J.Mendel,S.Wei, andD.Murfet.Dynamicalversusbayesianphasetransi-
tionsinatoymodelofsuperposition,2023.
[CS81] C. De Concini and E. Strickland. On the variety of complexes. Advances in Mathematics,
41(1):57–77, 1981.
[CS88] J.ConwayandN.Sloane.SpherePackings,LatticesandGroups,volume290ofGL.Springer,
1988.
[DAP+24] C.C.J.Domin´e,N.Anguita,A.M.Proca,L.Braun,D.Kunin,P.A.M.Mediano,andA.M.
Saxe.Fromlazytorich: Exactlearningdynamics indeeplinearnetworks,2024.
[FR02] L.Feh´erandR.Rima´nyi.Classesofdegeneracylociforquivers—theThompolynomialpoint
ofview.Duke Math. J.,114(2):193–213, 2002.
[FR04] L.M. Feh´er and R.Rima´nyi. Calculation of Thom polynomials and other cohomological ob-
structionsforgroupactions.InT.GaffneyandM.Ruas,editors,RealandComplex Singular-
ities(Sao Carlos, 2002), number354inContemp. Math.,pages 69–93.AMS,2004.
[HWFR+24] J.Hoogland,G.Wang,M.Farrugia-Roberts,L.Carroll,S.Wei,andD.Murfet.Thedevelop-
mentallandscapeofin-contextlearning,2024.
[JGc+22] A.Jacot, F.Ged, B. S¸im¸sek, C.Hongler, and F. Gabriel.Saddle-to-saddle dynamics indeep
linearnetworks: Smallinitializationtraining,symmetry,andsparsity,2022.
[JT19] Z.JiandM.Telgarsky.Gradientdescent alignsthelayersofdeeplinearnetworks,2019.
[Kaw16] K. Kawaguchi. Deep learning without poor local minima. Advances in neural information
processing systems,29,2016.
[Kaz97] M. E. Kazarian. Characteristic classes of singularity theory. In The Arnold-Gelfand mathe-
matical seminars,pages 325–340. Birkhauser,1997.
[Kir16] A.Kirillov.Quiverrepresentations and quivervarieties.Number174inGSM.AMS,2016.
[KMS06] A.Knutson,E.Miller,andM.Shimozono.Fourpositiveformulaefortypeaquiverpolynomials.
Inv. Math.,166(2):229–325, 2006.
[Kol97] J.Koll´ar.Singularitiesofpairs.InProceedings ofSymposia inPure Mathematics,volume62,
pages221–288. AmericanMathematical Society,1997.
[KR15] R.KinserandJ.Rajschot.Typeaquiverlociandschubertvarieties.JournalofCommutative
Algebra,7(2):265–301, 2015.
[KR24] J.KonckiandR.Rima´nyi.Themainreasonsformatricesmultiplyingtozero.Inpreparation,
2024.
[Leh24] S. P. Lehalleur. Real jet schemes, real contact loci and the real log-canonical threshold. to
appear,2024.
[LFW+24] E. Lau, Z. Furman, G. Wang, D. Murfet, and S. Wei. The local learning coefficient: A
singularity-awarecomplexitymeasure,2024.
[Lin11] Sh.Lin.Algebraic methods for evaluating integrals in Bayesian statistics.UniversityofCali-
fornia,Berkeley,2011.
[LK17] H.LuandK.Kawaguchi.Depthcreates nobadlocalminima,2017.
[LM98] V.LakshmibaiandPeterMagyar.Degeneracyschemes,quiverschemes,andschubertvarieties.
International Mathematics Research Notices,1998(12):627–640, 011998.
[ML24] P. Marion and Ch. L´ena¨ıc. Deep linear networks for regression are implicitly regularized to-
wardsflatminima,2024.
[MS83] Ch.MusiliandC.S.Seshadri.Schubertvarietiesandthevarietyofcomplexes.InArithmetic
andGeometry: PapersDedicatedtoIRShafarevichontheOccasionofHisSixtiethBirthday.
Volume II: Geometry,pages 329–359. Springer,1983.
[Mus11] M.Mustata. Impangalecturenotes onlogcanonical thresholds,2011.
[Rei10] M.Reineke.Poissonautomorphismsandquivermoduli.JournaloftheInstituteofMathemat-
icsof Jussieu,9(3):653–667, 2010.
[Rim13] R.Rimanyi.Onthecohomologicalhallalgebraofdynkinquivers,2013.28 SIMONPEPINLEHALLEURANDRICHA´RDRIMA´NYI
[RWY18] R.Rima´nyi,A.Weigandt, andA.Yong.Partitionidentities andquiver representations.J. of
Alg. Comb.,47:129–169, 2018.
[SB24] J. R. Shewchuk and S. Bhattacharya. The geometry of the set of equivalent linear neural
networks,2024.arXiv:2404.14855.
[SMG14] A. M. Saxe, J. L. McClelland, and S. Ganguli. Exact solutions to the nonlinear dynamics of
learningindeeplinearneuralnetworks,2014.
[TKB20] M. Trager, K. Kohn, and J. Bruna. Pure and spurious critical points: a geometric study of
linearnetworks,2020.
[Voi77] D. Voigt. Endliche algebraische Gruppen. Number 592 in Lecture Notes in Math. Springer,
1977.
[Wat09] S.Watanabe. Algebraic Geometry and StatisticalLearning Theory.CUP,2009.
[Wat18] S.Watanabe. Mathematical theory of Bayesian statistics.Chapman&Hall,2018.
[Wat24] SumioWatanabe.Recentadvancesinalgebraicgeometryandbayesianstatistics.Information
Geometry,7(Suppl 1):187–209, 2024.
[WHvW+24] G. Wang, J. Hoogland, S. van Wingerden, Z. Furman, and D. Murfet. Differentiation and
specializationofattention heads viatherefinedlocallearningcoefficient,2024.
[Zel85] A. V. Zelevinskii. Two remarks on graded nilpotent classes. Russian Mathematical Surveys,
40(1):249, 1985.
[ZLM22] L.Ziyin,B.Li,andX.Meng.Exactsolutionsofadeeplinearnetwork.arXiv,2022.
Universiteit van Amsterdam,Netherlands
Departmentof Mathematics,UNCChapelHill, ChapelHill, NC, USA