A Multi-Loss Strategy for Vehicle Trajectory Prediction:
Combining Off-Road, Diversity, and Directional Consistency Losses
Ahmad Rahimi1 and Alexandre Alahi1
Abstract—Trajectory prediction is essential for the safety
and efficiency of planning in autonomous vehicles. However,
current models often fail to fully capture complex traffic
rules and the complete range of potential vehicle movements.
Addressing these limitations, this study introduces three novel
loss functions: Offroad Loss, Direction Consistency Error, and
Diversity Loss. These functions are designed to keep predicted
paths within driving area boundaries, aligned with traffic
directions, and cover a wider variety of plausible driving
scenarios. As all prediction modes should adhere to road
rules and conditions, this work overcomes the shortcomings of
traditional “winner takes all” training methods by applying
the loss functions to all prediction modes. These loss func-
tions not only improve model training but can also serve as Fig. 1: Trajectory predictions by Wayformer [1], a state-of-
metrics for evaluating the realism and diversity of trajectory the-art model, highlighting errors such as off-road move-
predictions.ExtensivevalidationonthenuScenesandArgoverse
ments, incorrect traffic direction adherence, and missed pre-
2 datasets with leading baseline models demonstrates that
our approach not only maintains accuracy but significantly dictions for other plausible maneuvers at the intersection,
improves safety and robustness, reducing offroad errors on suchascontinuingstraight.Ourproposedlossfunctionsaim
average by 47% on original and by 37% on attacked scenes. to correct these prediction errors.
This work sets a new benchmark for trajectory prediction
in autonomous driving, offering substantial improvements in
navigating complex environments. Our code is available at the closest prediction receives updates from the gradients.
https://github.com/vita-epfl/stay-on-track.
This can result in suboptimal predictions of less frequent
I. INTRODUCTION yet feasible trajectories, thus limiting the model’s ability to
Trajectory prediction plays a crucial role in autonomous handle rare or complex maneuvers effectively.
systems,particularlyinenhancingthesafetyandreliabilityof In this work, we address this gap by focusing on the
self-drivingvehicles.Recentadvancementshavesignificantly quality of all generated trajectories. This study introduces
improvedthecapabilitiesofpredictivemodels,enablingthem threelossfunctionsaimedatembeddingmoretargetedinduc-
togeneratemultimodaltrajectorypredictionsthataccountfor tive biases into trajectory prediction models. Our proposed
uncertaintiesindrivers’intentionsanddrivingstyles.Despite losses — Offroad Loss, Direction Consistency Error, and
theseadvancements,significantchallengesremain,including Diversity Loss — operate across all prediction modes. They
accurately understanding scenes and predicting all possible are designed to deepen the model’s scene comprehension,
trajectory modes. ensure adherence to traffic regulations, and enhance the
Current models often struggle with fully grasping scene diversity of trajectory predictions.
dynamics and accurately forecasting every potential move- Specifically,theOffroadLossensuresthattrajectoriesstay
ment, as evidenced in Figure 1. Even advanced models withindrivableboundaries,imposingincreasingpenaltiesfor
may incorrectly predict trajectories that go off-road, oppose deviations further from these zones to encourage accurate
traffic flow, or overlook viable maneuvers at intersections navigation. The Direction Consistency Error loss aligns
and in complex urban settings. This highlights the need predicted trajectories with the expected traffic flow and road
for enhanced models capable of better interpreting and layouts.Itisparticularlybeneficialincomplexenvironments
navigating various traffic situations for improved safety and such as intersections and multi-lane roads with opposing
dependability. traffic flows, where it plays a crucial role in guiding the
Moreover, traditional objective functions used in model vehiclesafelythroughthecorrectpath.Finally,theDiversity
training often fall short in enhancing the mentioned aspects Loss encourages the model to generate a varied set of
of prediction. Typically, these training methods adopt a predictions that cover all plausible outcomes, crucial for
“winnertakesall”approachwheretheyfocusonminimizing dynamic traffic situations where multiple routes may be
the prediction errors for the trajectory closest to the ground feasible. It selectively filters out infeasible predictions, and
truth observation. This method neglects other viable trajec- calculates the sum of pairwise distance between remaining
tory predictions during the model’s learning phase, as only predictions.
In summary, this work introduces three novel loss func-
*ThisworkwasfundedbyHaslerFoundationundertheResponsibleAI.
1EPFL,Lausanne,Switzerland;Email:firstname.lastname@epfl.ch tions devised to address key shortcomings in recent trajec-
4202
voN
92
]VC.sc[
1v74791.1142:viXratory prediction models. Each function specifically targets recentmodels.WeaddressthisbyimplementingourOffroad
a distinct aspect of prediction quality, from adherence to loss in a vectorized form, being more fine-grained and suit-
drivablepathsandalignmentwithtrafficflow,tothediversity ableformoderntransformer-basedmodels,andimplementit
of outcomes. These functions are uniformly applied across using computational geometry algorithms on GPU for better
all modes, overcoming the constraints of “winner takes performance.
all” methods and ensuring comprehensive refinement of all [30] introduced a Yaw Loss that aligns vehicle head-
potential trajectories during training, thereby improving the ings with the nearest centerline, which proved suboptimal
precision and safety of the model’s predictions. for complex scenarios like intersections involving multiple
We conducted extensive experiments using two leading centerlines with varying directions. Their method had to
baseline models on the nuScenes and Argoverse 2 datasets define certain exceptions and excluded intersection cases
to assess the effectiveness of our proposed loss functions. completely. In contrast, our approach considers all potential
The results confirm that these functions enhance the robust- centerline paths, applying penalties based on a blend of
ness and safety of the trajectory prediction models without 2D positioning and heading distances, thus offering greater
sacrificing prediction accuracy. Notably, we have achieved a flexibility and applicability than prior methods.
significantreductionintheoffroadmetricbyhalfonoriginal Reinforcement learning-based methods, such as [31], op-
dataset scenarios, and 37% when adding natural turns in the timize motion prediction using reward signals to guide tra-
scene, underscoring the effectiveness of our approach. jectory generation. However, these approaches suffer from
high computational cost and instability during training due
II. RELATEDWORK
to the non-differentiable nature of their reward functions. In
Recentadvancementsinvehicletrajectorypredictionhave contrast, our proposed loss functions are fully differentiable,
led to significant improvements in modeling techniques. ensuring lower computational overhead and more stable
Inspired by breakthroughs in convolutional neural networks training.
(CNNs)andcomputervision,earlymodelsutilizedrasterized
III. METHOD
bird’s-eye view images, incorporating static map elements
andagenttrajectoriesasinputrepresentations.Thisapproach This section formally defines the vehicle trajectory pre-
leveraged CNNs to predict future paths [2], [3], [4], [5], diction problem to establish a mathematical framework. It
[6].However,rasterizedinputsarecomputationallyintensive then reviews the challenges inherent in the commonly used
and memory-heavy, suffer from a limited field of view, “winner takes all” training approach in recent models. Fi-
and burden the model with extracting already available 2D nally,thesectionpresentsthreenovelauxiliarylossfunctions
positional information — challenges that complicate agent designed to enrich models with greater scene understanding
interaction modeling and scene comprehension. and promote diversity in predictions.
Addressing these limitations, more recent models have
A. Formulation
adopted fully vectorized map representations, initially em-
ploying graph neural networks [7], [8], [9], [10] and Recur- Consider the trajectory prediction problem involving an
rentNeuralNetworks[11],[12],[13],[14].Theintroduction ego agent surrounded by N neighbouring agents within
oftransformersinthefieldhasfurtherenhancedmodelcapa- a scene. Let si = (xi,yi) define the state of agent i at
t t t
bilities, integrating attention mechanisms to refine trajectory timestep t. We have access to the observed trajectories
predictions [1], [15], [16], [17], [18]. xxxi=[si ,···,si ,si] for all agents over the pastt timesteps,
−t −1 0
Althoughtherehavebeenadvancesinmodelarchitectures aggregatedasxxx=[xxx0,xxx1,···,xxxN]∈RN×t×2.Additionally,the
aimed at enhancing prediction accuracy, the quality and input includes the drivable area Ω, represented as a union
safety of the diverse predicted trajectories have not been as of several closed polygons, and the centerlines ccc∈RS×K×3,
thoroughly addressed. State-of-the-art models often produce with each of S centerline segments containing K points
undesirable results, such as trajectories that deviate off-road characterizedbytheir2Dpositionandyaw(x,y,θ).Thepre-
or violate traffic directions, as demonstrated in Figure 1. diction model f aims to predict the ego agent’s ground truth
Some models have incorporated explicit road structures trajectory yyyˆ =[s0,···,s0] over the next T timesteps. Given
1 T
to enhance scene feasibility [19], [20], [21], and impose themultimodalnatureofthepredictiontask,stemmingfrom
higher diversity [22], [23], [11]. yet their dependency on uncertainties in drivers’ intentions, the model f generates M
specificmapstructureslimitstheiradaptabilityacrossvarious distinct possible trajectories, thus yyy= f(xxx,Ω,ccc)∈RM×T×2.
datasets.Insteadofdevelopingnewarchitecturalframeworks,
B. Previous objective functions
our work introduces simple universal loss functions that en-
hance prediction quality and diversity across any prediction Multimodal predictions are a fundamental aspect of cur-
model. renttrajectorypredictionmodels,witheachmodelgenerating
A significant body of work related to ours has also Mdistincttrajectories.Traditionally,thesemodelsaretrained
introduced an Offroad metric [24], [25], [26], [27], [28], using objective functions like minADE, defined as:
[29], with some employing it directly as an auxiliary loss
1 T
function[25],[26],[27],[29].Thesestudiestraditionallyrely minADE= min ∑∥yyym−yyyˆm∥ . (1)
on rasterized offroad masks, which are less compatible with
1≤m≤MT
i=1
t t 2(cid:5)(cid:7)
(cid:5)(cid:6)
(cid:5)(cid:4)
(cid:11)
(cid:10)
(cid:9)
(cid:8)
(cid:7)
(cid:5)
(cid:4)
(a) Offroad Loss (b) Road Direction Consistency (c) Mode Diversity
Fig. 2: An illustration for our proposed loss functions. The colors in (a) show the Offroad Loss values for areas around the
bluevehicle,withtheredoffroadtrajectoryhavingahighpenalty.Panel(b)illustratesRoadDirectionConsistency,showing
centerline points and directions; the incorrect red trajectory fails to align with the proper road direction. In (c), we compare
three prediction sets: red trajectories demonstrate diversity but are infeasible due to straying off the drivable area; yellow
trajectories are feasible but lack diversity, missing a potential right turn; green trajectories successfully combine diversity
with feasibility, accurately reflecting viable path options.
This function focuses on minimizing the error for the tra- loss sums across all prediction points, with zero indicating
jectory closest to the ground truth, effectively prioritizing presence within the drivable area (including a margin of m
the most likely outcome while allowing other predictions to meters) and increasing as predictions move further from Ω.
representalternativepossiblescenarios.However,suchanap- To compute the signed distance function φ(ppp,Ω), we
proachhasasignificantdrawback:onlytheclosesttrajectory calculate the distance from point ppp to all polygon edges
tothegroundtruthreceivesgradientupdatesduringtraining, in Ω and select the minimum distance to determine the
leaving other predicted trajectories largely unrefined. This closest boundary. For determining whether ppp is inside Ω,
method of sparse supervision can lead to unsatisfactory a ray casting algorithm is utilized, where a ray extending
modeling of less common but plausible behaviors, thereby from ppp along the x-axis is used to count the intersections
limiting the model’s ability to fully capture the diverse with the polygon’s edges. Then, point ppp is in or out of
possibilities inherent in real-world driving scenarios. Ω if the number of crossings is odd or even, respectively.
This method, commonly used for point-in-polygon tests, is
C. Proposed objective functions
adaptedfromcomputationalgeometryprinciplesoutlinedby
To address the limitations of common “winner takes all” [32]. All computations are efficiently implemented on the
training objectives, we propose three new loss functions. GPU to minimize the performance overhead and accelerate
Unlike traditional methods, these functions supervise all the loss evaluation process.
predictionmodes,enhancingdifferentaspectsofthemodel’s
2) Direction Consistency Error: Given that road cen-
performance. Each function is designed to infuse the model
terlines are part of the map context for prediction mod-
with deeper knowledge, targeting specific shortcomings in
els, maintaining the correct directional alignment is crucial.
existingapproaches.Figure2illustratestheselossfunctions.
To address instances where models may align with these
1) Offroad Loss: The first proposed loss function directs centerlines in the incorrect direction, we propose the Road
predictions toward the drivable area and penalizes off-road DirectionConsistencylossfunction.AsFigure2billustrates,
deviations by employing a signed distance function between this function imposes a significant penalty on trajectories
the predicted trajectory yyy and the drivable area Ω. This deviatingfromcorrespondingcenterline’sdirection,ensuring
function is continuous and differentiable, with its gradient alignment not just in position but also in orientation.
directedtowardthenearestpointwithinΩ.Figure2avisually
To implement it, we calculate the heading direction γi
demonstrates the offroad function, where the penalty values t
of each predicted trajectory yyyi at timestep t. The difference
are depicted across different areas around the vehicle. Math-
δ(c,yi) between a centerline point c=(x,y,θ) and a trajec-
ematically, the signed distance function φ for Ω is defined t
tory point yi =(x′,y′,γi) is defined as:
such that it returns the shortest distance from any point x to t t
the boundary ∂Ω of Ω, being negative if x is inside Ω and
positive otherwise. We define our Offroad loss function as:
δ(c,y ti)=max(cid:0) ∥(x,y)−(x′,y′)∥ 2−m d,0(cid:1)
+max(cid:0) |θ−γi|−m ,0(cid:1) ,
1 M T t θ
Offroad Loss(yyy,Ω)= ∑∑max(φ(yyyi,Ω)+m,0), (2)
M t
i=1t=1 wherem and m representtheallowabledistanceandangle
d θ
where yyyi represents the position at timestep t of the ith margins, respectively.
t
prediction, φ is the signed distance function, and m is a The Road Direction Consistency loss then aggregates the
margin that maintains a buffer from Ω’s boundary. This minimum δ value between each trajectory point and all
(cid:17)(cid:23)(cid:19)(cid:15)(cid:14)(cid:3)(cid:22)(cid:22)(cid:20)(cid:12)(cid:3)(cid:16)(cid:15)(cid:20)(cid:21)(cid:18)(cid:18)(cid:13)centerline points, summed across all trajectory points: Additionally, we explore how varying the weight α of the
auxiliary loss affects overall model performance, providing
1 M T
Direction Consistency(yyy,ccc)= ∑∑ min δ(cccs,yyyi). (3) insightsintotheoptimalconfigurationforbalancingbetween
M i=1t=11≤s≤S k t
the baseline and proposed modifications. Finally, we show
1≤k≤K
the improved robustness of our models through evaluations
The flexibility of this loss function is particularly important
usingtheSceneAttackbenchmark[33],inrealisticscenarios
in complex environments like intersections, where many
that include synthetically introduced turns.
centerlines are close together but may have very different
directions. Matching the trajectory strictly to the nearest A. Experimental setup
centerline can sometimes lead to incorrect alignments. Our
Our experiments leverage the UniTraj framework [34]
approach allows for matching with any centerline while in-
to integrate our proposed loss functions with two state-
troducingapenaltyforthedistance,ensuringamoreaccurate
of-the-art trajectory prediction models: Wayformer [1] and
match. This means the model might align a trajectory with
AutoBots [15]. Wayformer is known for its superior predic-
a centerline that is not the closest one but has a more
tion capabilities within UniTraj, whereas AutoBots provides
suitableheading.Thismethodensureseachtrajectorypointis
a performant yet lightweight alternative. The experiments
evaluated against the most appropriate centerline, effectively
are conducted on two prominent datasets: nuScenes [35], a
improvingaccuracyinbothpositionanddirection,especially
smaller and more challenging dataset, and Argoverse 2 [36],
in challenging scenarios.
which offers a broader range of scenarios.
3) Mode Diversity: Ensuring a diverse set of predictions
We adopt UniTraj’s setup, where the models are trained
is critical for robust and safe route planning, particularly
using a history of 2 seconds and make predictions over
to capture all highly probable and plausible trajectories. To
6 seconds, with each model outputting M = 6 possible
support this, we introduce the Mode Diversity loss, which
trajectories, using UniTraj’s hyperparameters.
promotesaspreadofpredictionsandisdepictedinFigure2c,
In terms of evaluation metrics, we introduce three novel
that favours more spread predictions over the concentrated
measures — Offroad, Direction Error, and Diversity — to
ones, as long as the predictions are feasible. This function
assessspecificaspectsofpredictionquality.Additionally,we
first excludes any trajectories that are off-road by employing
utilize standard metrics from the field which evaluate pre-
an indicator function 1(i) which assesses whether trajectory
diction accuracy, including minimum Average Displacement
yyyi remains within drivable area. The diversity loss is then
Error(minADE),aspreviouslydefinedinEquation(1),along
calculated as the sum of pairwise distances between all
withminimumFinalDisplacementError(minFDE)andMiss
remaining feasible trajectories:
Rate (MR). MinFDE is calculated as:
1 T
Mode Diversity(y,1)= ∑ ∑
T
∑∥yyy ti−yyy tj∥ 2, (4) minFDE= 1≤m mi ≤n M∥yyym
T
−yyyˆm T∥ 2. (5)
1≤i≤M i≤j≤M t=1
1(i)=1 1(j)=1 Miss Rate (MR) is defined as the ratio of the samples where
where 1(i)=1 indicates that trajectory yyyi is within drivable theminFDEexceeds2meters,andisusefulwheredeviations
area.ThisselectiveapproachensuresthattheModeDiversity up to 2 meters are acceptable.
loss only considers trajectories that are practical and safe, Trainingstrategy:Wetrainthebaselinemodelsandthose
therebyavoidinganundesiredincreaseinthelossvaluefrom incorporatingOffroadandDirectionConsistencylossesfrom
trajectories pushed outside of road boundaries. scratch to achieve optimal results. However, the Diversity
lossisappliedthroughfinetuningthebaselinemodelover10
IV. EXPERIMENTS
epochs, as introducing it from the start tends to destabilize
Inthissection,wedetailourexperimentalsetup,including training.Whenemployingallourlossfunctionstogether,we
a description of the vehicle trajectory prediction datasets alsooptforfinetuningbecauseoftheDiversityloss’simpact,
and the baseline models utilized. We enhanced the base- although this approach might slightly limit improvements in
line models by integrating our proposed loss functions as Offroad and Direction Consistency metrics.
auxiliary components. Specifically, the total loss for train-
B. Quantitative results
ing is formulated as L = L +αL , where α
final original aux
is a hyperparameter that balances the contributions of the Thequantitativeperformanceofourmethod,asdetailedin
original and auxiliary losses. For experiments that utilize all Tab. I, demonstrates significant enhancements when training
introduced loss functions, we calculate the total auxiliary Wayformer and AutoBots on the nuScenes and Argoverse 2
loss using a weighted sum of each function, where the datasets. We observe several key improvements:
weights are derived from the optimal α values determined • The implementation of our proposed loss functions
during individual training with each specific loss function, consistently leads to substantial reductions in their tar-
and adjusted for optimal performance. geted metrics. For instance, applying the Offroad loss
We present both quantitative results demonstrating the typically cuts the offroad metric nearly in half. By
performance improvements achieved with our auxiliary loss integratingallthreeproposedlossfunctions,ourmethod
functions and qualitative examples that illustrate specific en- improves performance across all assessed quality met-
hancements in trajectory prediction due to our methodology. rics compared to baseline models.TABLE I: Performance of AutoBots and Wayformer on nuScenes and Argoverse 2 datasets with integration of our proposed
loss functions alongside the original objective functions. The results show marked improvements in targeted metrics without
compromising accuracy. Incorporating all three loss functions, our method shows a balanced improvement over all quality
metrics compared to the baseline models.
nuScenes Argoverse2
minADE↓ minFDE↓ MR↓ Offroad↓ Direction↓ Diversity↑ minADE↓ minFDE↓ MR↓ Offroad↓ Direction↓ Diversity↑
Wayformer 1.08 2.47 0.42 2.73 7.68 57 0.87 1.79 0.30 0.68 4.24 57
+Offroad 1.07 2.54 0.43 1.58 6.46 70 0.87 1.78 0.28 0.28 3.65 60
+Direction 1.13 2.60 0.43 1.56 5.27 57 0.87 1.80 0.28 0.34 1.89 58
+Diversity 1.10 2.55 0.46 2.83 8.22 74 0.88 1.81 0.31 0.69 4.29 64
+All 1.13 2.61 0.43 1.67 5.47 67 0.89 1.85 0.30 0.44 2.54 63
Autobots 1.27 2.70 0.43 1.93 5.80 64 0.92 1.86 0.30 0.30 3.67 58
+Offroad 1.26 2.65 0.41 1.09 4.94 65 0.86 1.68 0.25 0.21 3.75 59
+Direction 1.26 2.64 0.41 1.04 4.21 67 0.88 1.73 0.26 0.20 1.70 60
+Diversity 1.27 2.69 0.49 1.81 5.96 93 0.87 1.72 0.27 0.31 3.79 62
+All 1.26 2.70 0.43 1.01 4.27 74 0.95 1.99 0.33 0.19 1.94 63
Baseline
Ours
(a) Offroad Loss (b) Direction Error (c) Mode Diversity
Fig. 3: Comparative visualization of model predictions on the Argoverse 2 dataset using Wayformer as the baseline. Each
panelillustratesenhancementsfromapplyingadistinctauxiliarylossfunctiontothebaselinemodel:(a)OffroadLosscorrects
four off-road predictions by enhancing adherence to drivable areas; (b) Direction Error adjusts a potentially hazardous right
turn against traffic flow; (c) Mode Diversity introduces a new left turn and increases the spacing between trajectories.
• Although we observe a slight increase in minADE/ those achieved with the Offroad loss.
minFDE in certain settings, this is offset by the sig-
nificant reduction in scene compliance errors like off- C. Qualitative results
road, which is critical for ensuring safe and feasible
We present qualitative results of our proposed auxiliary
predictions. This trade-off highlights the importance of
lossfunctionsinFigure3,demonstratingsignificantimprove-
prioritizing safety over minor decreases in accuracy in
ments in model predictions across various scenarios. In the
real-world autonomous driving scenarios.
first panel, the baseline model generates multiple off-road
• The Offroad and Direction Error metrics benefit each
predictions, failing to align with the ground truth. Incorpo-
other. Using one as an auxiliary loss not only improves
rating the Offroad loss during training teaches the model
its own performance but also enhances the other. This
to recognize and avoid such errant paths, leading to more
mutual boost is especially notable with the Direction
accuratetrajectorypredictions.Inthesecondpanel,anotable
Error loss, which often shows improvements similar to
error in the baseline predictions includes a dangerous right0.880
Baseline 0.96 Baseline Baseline
0.88 + Offroad + Direction 0.878 + Diversity
0.94
Selected Model Selected Model Selected Model 0.876
0.92
0.87 0.90 0.874
0.88 0.872
0.86 0.86 0.870
0.3 0.4 0.5 0.6 0.7 1.0 1.5 2.0 2.5 3.0 3.5 4.0 58 59 60 61 62 63 64
Offroad Direction Consistency Error Diversity
(a) Offroad Loss α Curve (b) Direction Consistency α Curve (c) Diversity α Curve
Fig.4:PerformanceimpactofintegratingourlossfunctionsonWayformer’sminADEacrosstheArgoverse2dataset.Theblue
curvesdemonstratethetrade-offbetweenincreasingauxiliarylossweightsandpredictionaccuracy,withreddotsmarkingthe
baseline performance. Yellow dots represent the selected models, showing regions where enhanced losses maintain similar
accuracy compared to the baseline. Similar patterns are observed across different models and dataset configurations.
TABLE II: Offroad metrics for baseline and our enhanced
turn against traffic flow. The application of our Direction
modelsunderSceneAttack,demonstratingresilienceagainst
Error loss corrects this, aligning the predictions with the
naturalistic scene perturbations.
correct traffic direction, thus enhancing safety and compli-
ance with traffic rules. The third panel showcases the effects
nuScenes Argoverse2
of our Mode Diversity loss, which significantly increases Original Attacked Original Attacked
the spread of predicted trajectories. This loss function not
Autobots 1.93 4.69 0.30 1.19
only introduces additional plausible maneuvers, such as a +Offroad 1.09 3.34 0.21 1.01
new left turn that was absent in the baseline predictions but +All 1.01 3.09 0.19 0.80
also ensures that the predicted trajectories are better spaced, Wayformer 2.73 8.89 0.68 4.16
reducing the likelihood of missing behaviors and increasing +Offroad 1.58 7.41 0.28 1.69
+All 1.67 6.93 0.44 3.53
the overall prediction diversity.
D. Metric weight study
lower Offroad metrics, showing superior resilience to these
In this study, we explore how combining the original loss out-of-distribution scenarios and highlighting their robust-
function with our auxiliary loss affects model performance. ness against realistic scene perturbations.
We illustrate this relationship in Figure 4, where we adjust
V. CONCLUSIONS
the weight of the auxiliary loss, α. Starting with a high
auxiliary weight α close to the selected model in each This study has demonstrated the efficacy of integrating
curve, we gradually decrease this weight, moving towards novel loss functions — Offroad Loss, Direction Consistency
baseline, which typically worsens the auxiliary metrics but Error,andDiversityLoss—intotrajectorypredictionmodels
can improve the main prediction accuracy. to significantly enhance their quality and robustness across
Interestingly, there is a sweet spot along these curves diverse driving scenarios. Our comprehensive evaluation on
wherethepredictionaccuracy,specificallyminADE,isclose thenuScenesandArgoverse2datasets,utilizingstate-of-the-
to that of the baseline model, while simultaneously im- art baseline models Wayformer and Autobots, has substan-
proving on the auxiliary metrics. This balance demonstrates tiated that these functions not only reduce undesirable be-
that it’s possible to enhance certain aspects of a model’s haviors such as off-road trajectories and direction violations
predictionswithoutdegradingoverallaccuracy.Theseresults butalsoimprovetheoveralldiversityandplausibilityofpre-
showthatadvancedmodelsarecapableofachievingadesir- dictedtrajectories.Theproposedlossfunctionsstandoutfor
able balance between accuracy and specific improvements, theirabilitytobeapplieduniversallyacrossdifferentmodels
validatingtheeffectivenessofourproposedlossfunctionsas and datasets without necessitating specialized architectural
discussed in §IV-B. adaptations.Asautonomoustechnologiescontinuetoevolve,
the methodologies developed in this work provide a scalable
E. Robustness to scene attack
andefficientapproachtoimprovingthesafetyandreliability
We evaluate the enhanced robustness of our models using of trajectory predictions in complex urban environments.
the Scene Attack benchmark [33], which simulates natural- A possible extension to this work would be the addition
istic attacks by introducing varying turns in the road ahead of other differential loss functions to this suite to further en-
of the ego agent. Tab. II displays the Offroad metric for hancethequalityofpredictions.Exampleswouldbecollision
predictions made by our baseline models on both original avoidance and kinematic feasibility of predictions. Another
andmanipulatedscenesacrosstheArgoverse2andnuScenes possibility for future investigation is the integration of a
datasets. These metrics are averaged across different types adaptive weight assigning algorithm to these loss functions,
and degrees of introduced road changes. Notably, models possibly based on model’s state during training.
trained with our proposed loss functions consistently have
EDA
niM
EDA
niM
EDA
niMREFERENCES [19] N.Deo,E.Wolff,andO.Beijbom,“MultimodalTrajectoryPrediction
Conditioned on Lane-Graph Traversals,” in Proceedings of the 5th
Conference on Robot Learning. PMLR, Jan. 2022, pp. 203–212,
[1] N. Nayakanti, R. Al-Rfou, A. Zhou, K. Goel, K. S. Refaat, and
iSSN: 2640-3498. [Online]. Available: https://proceedings.mlr.press/
B. Sapp, “Wayformer: Motion forecasting via simple & efficient
v164/deo22a.html
attentionnetworks,”2023IEEEInternationalConferenceonRobotics
[20] T. Gilles, S. Sabatini, D. V. Tsishkou, B. Stanciulescu, and
and Automation (ICRA), pp. 2980–2987, 2022. [Online]. Available:
F. Moutarde, “Gohome: Graph-oriented heatmap output for future
https://api.semanticscholar.org/CorpusID:250493056
motion estimation,” 2022 International Conference on Robotics
[2] X. Ren, T. Yang, L. E. Li, A. Alahi, and Q. Chen, “Safety-aware
and Automation (ICRA), pp. 9107–9114, 2021. [Online]. Available:
motion prediction with unseen vehicles for autonomous driving,” in
https://api.semanticscholar.org/CorpusID:237263205
ProceedingsoftheIEEE/CVFInternationalConferenceonComputer
[21] J. Gu, C. Sun, and H. Zhao, “Densetnt: End-to-end trajectory pre-
Vision(ICCV),2021.
diction from dense goal sets,” in Proceedings of the IEEE/CVF
[3] Y. Biktairov, M. Stebelev, I. Rudenko, O. Shliazhko, and B. Yangel,
International Conference on Computer Vision, 2021, pp. 15303–
“Prank: motion prediction based on ranking,” Advances in Neural
15312.
InformationProcessingSystems(NeurIPS),2020.
[22] J. Wang, T. Ye, Z. Gu, and J. Chen, “Ltp: Lane-based trajectory
[4] Y.Chai,B.Sapp,M.Bansal,andD.Anguelov,“Multipath:Multiple predictionforautonomousdriving,”inProceedingsoftheIEEE/CVF
probabilistic anchor trajectory hypotheses for behavior prediction,” ConferenceonComputerVisionandPatternRecognition(CVPR),June
ConferenceonRobotLearning,2019.
2022,pp.17134–17142.
[5] J.Hong,B.Sapp,andJ.Philbin,“Rulesoftheroad:Predictingdriving [23] S.Kim,H.Jeon,J.W.Choi,andD.Kum,“Diversemultipletrajectory
behavior with a convolutional model of semantic interactions,” in predictionusingatwo-stagepredictionnetworktrainedwithlaneloss,”
Proceedings of the IEEE/CVF Conference on Computer Vision and IEEERoboticsandAutomationLetters,vol.8,no.4,pp.2038–2045,
PatternRecognition(CVPR),2019. 2023.
[6] S. Casas, W. Luo, and R. Urtasun, “Intentnet: Learning to predict [24] D.Ridel,N.Deo,D.Wolf,andM.Trivedi,“Scenecomplianttrajectory
intention from raw sensor data,” in Conference on Robot Learning. forecastwithagent-centricspatio-temporalgrids,”IEEERoboticsand
PMLR,2018. AutomationLetters,vol.5,no.2,pp.2816–2823,2020.
[7] M. Liang, B. Yang, R. Hu, Y. Chen, R. Liao, S. Feng, and R. Urta- [25] M. Niedoba, H. Cui, K. Luo, D. Hegde, F.-C. Chou, and N. Djuric,
sun,“Learninglanegraphrepresentationsformotionforecasting,”in “Improving movement prediction of traffic actors using off-road
EuropeanConferenceonComputerVision(ECCV). Springer,2020. loss and bias mitigation,” in Workshop on’Machine Learning for
[8] J.Gao,C.Sun,H.Zhao,Y.Shen,D.Anguelov,C.Li,andC.Schmid, AutonomousDriving’atConferenceonNeuralInformationProcessing
“Vectornet: Encoding hd maps and agent dynamics from vectorized Systems,2019.
representation,”inProceedingsoftheIEEE/CVFConferenceonCom- [26] F.A.Boulton,E.C.Grigore,andE.M.Wolff,“Motionpredictionus-
puterVisionandPatternRecognition(CVPR),2020. ingtrajectorysetsandself-drivingdomainknowledge,”arXivpreprint
[9] S. Ha and H. Jeong, “Learning heterogeneous interaction strengths arXiv:2006.04767,2020.
by trajectory prediction with graph neural network,” in The [27] K.Messaoud,N.Deo,M.M.Trivedi,andF.Nashashibi,“Multi-head
EleventhInternationalConferenceonLearningRepresentations,2023. attentionwithjointagent-maprepresentationfortrajectoryprediction
[Online].Available:https://openreview.net/forum?id=qU6NIcpaSi- inautonomousdriving,”arXivpreprintarXiv:2005.02545,2020.
[10] L. Li, M. Pagnucco, and Y. Song, “Graph-based spatial transformer [28] M.-F.Chang,J.W.Lambert,P.Sangkloy,J.Singh,S.Bak,A.Hartnett,
withmemoryreplayformulti-futurepedestriantrajectoryprediction,” D.Wang,P.Carr,S.Lucey,D.Ramanan,andJ.Hays,“Argoverse:3d
inProceedingsoftheIEEE/CVFConferenceonComputerVisionand trackingandforecastingwithrichmaps,”inConferenceonComputer
PatternRecognition,2022,pp.2231–2241. VisionandPatternRecognition(CVPR),2019.
[11] S.H.Park,G.Lee,J.Seo,M.Bhat,M.Kang,J.Francis,A.Jadhav, [29] H. Cui, H. Shajari, S. Yalamanchi, and N. Djuric, “Ellipse loss
P. P. Liang, and L.-P. Morency, “Diverse and admissible trajectory for scene-compliant motion prediction,” in 2021 IEEE International
forecasting through multimodal context understanding,” in European Conference on Robotics and Automation (ICRA), 2021, pp. 8558–
ConferenceonComputerVision(ECCV). Springer,2020. 8564.
[12] L. Chiara, P. Coscia, S. Das, S. Calderara, R. Cucchiara, and [30] R. Greer, N. Deo, and M. Trivedi, “Trajectory prediction in au-
L.Ballan,“Goal-drivenself-attentiverecurrentnetworksfortrajectory tonomousdrivingwithalaneheadingauxiliaryloss,”IEEERobotics
prediction,” in 2022 IEEE/CVF Conference on Computer Vision and andAutomationLetters,vol.PP,pp.1–1,032021.
Pattern Recognition Workshops (CVPRW). Los Alamitos, CA, [31] S. Casas, C. Gulino, S. Suo, and R. Urtasun, “The importance
USA: IEEE Computer Society, jun 2022, pp. 2517–2526. [Online]. of prior knowledge in precise multimodal prediction,” 2020
Available:https://doi.ieeecomputersociety.org/10.1109/CVPRW56347. IEEE/RSJ International Conference on Intelligent Robots and
2022.00282 Systems (IROS), pp. 2295–2302, 2020. [Online]. Available: https:
[13] L.Lin,W.Li,H.Bi,andL.Qin,“Vehicletrajectorypredictionusing //api.semanticscholar.org/CorpusID:219303686
LSTMswithspatial-temporalattentionmechanisms,”IEEEIntelligent [32] J. O’Rourke, Computational Geometry in C, 2nd ed. Cambridge,
TransportationSystemsMagazine,vol.14,no.2,pp.197—-208,2022. UK:CambridgeUniversityPress,1998.
[33] M. Bahari, S. Saadatnejad, A. Rahimi, M. Shaverdikondori, A.-
[14] A. Ip, L. Irio, and R. Oliveira, “Vehicle trajectory prediction based
H. Shahidzadeh, S.-M. Moosavi-Dezfooli, and A. Alahi, “Vehicle
on lstm recurrent neural networks,” in 2021 IEEE 93rd Vehicular
trajectorypredictionworks,butnoteverywhere,”inProceedingsofthe
TechnologyConference(VTC2021-Spring),2021,pp.1–5.
IEEE/CVF Conference on Computer Vision and Pattern Recognition
[15] R. Girgis, F. Golemo, F. Codevilla, M. Weiss, J. A. D’Souza,
(CVPR),2022.
S. E. Kahou, F. Heide, and C. Pal, “Latent variable sequential set
[34] L. Feng, M. Bahari, K. M. B. Amor, E. Zablocki, M. Cord, and
transformersforjointmulti-agentmotionprediction,”inInternational
A. Alahi, “UniTraj: A Unified Framework for Scalable Vehicle
Conference on Learning Representations, 2022. [Online]. Available:
Trajectory Prediction,” Aug. 2024, arXiv:2403.15098 [cs]. [Online].
https://openreview.net/forum?id=DupdDqkZC5
Available:http://arxiv.org/abs/2403.15098
[16] M.Liu,H.Cheng,L.Chen,H.Broszio,J.Li,R.Zhao,M.Sester,and
[35] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong,
M.Y.Yang,“Laformer:Trajectorypredictionforautonomousdriving
Q. Xu, A. Krishnan, Y. Pan, G. Baldan, and O. Beijbom,
with lane-aware scene constraints,” in Proceedings of the IEEE/CVF
“nuscenes: A multimodal dataset for autonomous driving,” 2020
Conference on Computer Vision and Pattern Recognition, 2024, pp.
IEEE/CVF Conference on Computer Vision and Pattern Recognition
2039–2049.
(CVPR), pp. 11618–11628, 2019. [Online]. Available: https:
[17] S. Shi, L. Jiang, D. Dai, and B. Schiele, “Motion transformer with
//api.semanticscholar.org/CorpusID:85517967
global intention localization and local movement refinement,” Ad-
[36] B. Wilson, W. Qi, T. Agarwal, J. Lambert, J. Singh, S. Khandelwal,
vancesinNeuralInformationProcessingSystems,2022.
B. Pan, R. Kumar, A. Hartnett, J. K. Pontes, D. Ramanan, P. Carr,
[18] Z.Huang,H.Liu,andC.Lv,“Gameformer:Game-theoreticmodeling and J. Hays, “Argoverse 2: Next generation datasets for self-driving
andlearningoftransformer-basedinteractivepredictionandplanning perceptionandforecasting,”inProceedingsoftheNeuralInformation
for autonomous driving,” in Proceedings of the IEEE/CVF Interna- Processing Systems Track on Datasets and Benchmarks (NeurIPS
tional Conference on Computer Vision (ICCV), October 2023, pp. DatasetsandBenchmarks2021),2021.
3903–3913.