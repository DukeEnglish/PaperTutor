Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection
ShuaiZeng1 WenzhaoZheng2,3,* JiwenLu2 HaibinYan1,†
1BeijingUniversityofPostsandTelecommunications,
2TsinghuaUniversity,3UCBerkeley
{zengshuai,eyanhaibin}@bupt.edu.cn;
wenzhao.zheng@outlook.com; lujiwen@tsinghua.edu.cn
Abstract
Ground Truth
Pseudo-objects
3Dobjectdetectionaimstorecoverthe3Dinformation
of concerning objects and serves as the fundamental task
Difficult to Synthesize Realistic Scenes in 2D Easy to Synthesize Realistic Scenes in 3D
ofautonomousdrivingperception. Itsperformancegreatly Pseudo-Car Pseudo-Ped Car Ped Cyc
dependsonthescaleoflabeledtrainingdata,yetitiscostly
to obtain high-quality annotations for point cloud data. Ped
Pseudo-Cyc Cyc Car Ped While conventional methods focus on generating pseudo- Car Extend Distribution Distance
Cyc Car Ped Cyc labels for unlabeled samples as supplements for training,  Car

the structural nature of 3D point cloud data facilitates the Car
Car
composition of objects and backgrounds to synthesize re-
Diverse Sample Distance
alistic scenes. Motivated by this, we propose a hardness- Figure 1. An illustration of constructing a synthetic 2D image
aware scene synthesis (HASS) method to generate adap- sampleanda3DLiDARsample. Weexemplifythedifficultyof
tive synthetic scenes to improve the generalization of the constructinga2Dimageanda3Dscenewithobjectsfromunla-
detection models. We obtain pseudo-labels for unlabeled beleddata.Itisdifficulttosynthesizearealistic2Dimageyeteasy
objects and generate diverse scenes with different compo- tosynthesizeunlabeledobjectsatdifferentpositionstogeneratea
diverse3Dsampletoextendthelaserbeamdistribution.
sitions of objects and backgrounds. As the scene synthe-
sis is sensitive to the quality of pseudo-labels, we further
pseudo-labels [2, 14, 34] to propagate information from
propose a hardness-aware strategy to reduce the effect of
the labeled to the unlabeled data, rendering filtering noisy
low-qualitypseudo-labelsandmaintainadynamicpseudo-
pseudo-labels a critical procedure. This motivates many
database to ensure the diversity and quality of synthetic
semi-supervisedobjectdetectionmethodstodevelopmore
scenes. Extensive experimental results on the widely used
effective filtering strategies to obtain high-quality pseudo-
KITTI and Waymo datasets demonstrate the superiority of
labels with supervisory information. These methods typi-
the proposed HASS method, which outperforms existing
callydesignevaluationmetrics[22,34,40],suchasuncer-
semi-supervised learning methods on 3D object detection.
tainty[22],confidence[34]orestimatedIoU[40],andthen
Code: https://github.com/wzzheng/HASS.
filter the predictions according to the metric scores. How-
ever, it is difficult for manually designed evaluation met-
ricstoaccuratelymeasurethequalityofpseudo-labels, re-
1.Introduction
sultinginmanyfalsepseudo-labelstosupervisethemodel
andmanyaccuratepseudo-labelsdiscarded. Someexisting
3D object detection [44, 60] is an important task for au-
semi-supervised 3D object detection methods [40, 50, 57]
tonomousdriving[11,42,59,62],yetthehighcostofman-
followthepseudo-label-based2Dmethods[22,35,45,46,
uallylabelingdataimpedesitsapplications[9,12,23–25].
49] and achieve good results. Still, most of them ignore
Toimprovetheperformancewhentrainingsamplesarein-
thespatialcharacteristicsofpointcloudsandcannotmodify
sufficient, semi-supervised learning methods [1, 2, 14, 29,
thedistributionofdatafeatures,limitingthegeneralization
31, 34, 37] aim to utilize additional unlabeled samples to
ability of the trained model. Compared with 2D images,
improvethegeneralizationperformanceofthemodel.
the point cloud scenes are not grid-structured and can be
Semi-supervised learning methods usually generate
moreeasilysynthesizedbymixingtwosamples. Asshown
*Projectleader.†Correspondingauthor. inFigure1, itismoredifficulttoconstructrealisticscenes
1
4202
yaM
72
]VC.sc[
1v22471.5042:viXra
rebmuN
maeB
rebmuN
maeB
Scene
Synthesiswith2Dimagesyetmucheasierwithpointclouds. abundantunlabeleddata.ThemainstreamSSLmethodscan
Motivated by this, we propose a hardness-aware scene be divided into two categories: consistency regularization
synthesis(HASS)methodtogeneratemorediversesamples [1,29,31,37,55]andpseudo-labeling[2,14,34,41]. The
that can improve model generalization through scene syn- consistency regularization methods applied different aug-
thesis. We maintain an online pseudo-database containing mentations to the input samples and enforced the consis-
bothgroundtruthandpseudo-labelsandprogressivelyadd tencyofthemodelpredictionsbetweentheaugmentedsam-
thepseudo-labelsthatsatisfythethresholdconditionsgen- ples. [1] added perturbations to the model to enforce con-
eratedintraining.Wethenrandomlysampletheforeground sistency. Mean Teacher [37] used an exponential moving
point clouds from the pseudo-database and concatenate average(EMA)teachermodelwiththesamearchitectureas
them with the labeled point clouds to synthesize diverse the student model to improve robustness. Pseudo-labeling
samples. To alleviate the influence of low-quality pseudo- methods[2,14,34,41]explicitlygeneratepseudo-labelson
labels, we employ harder (i.e., more difficult) synthetic unlabeleddataforsupervising,whichcanberegardedasa
samplestotrainthemodelwhenitisbetterlearned[58]and typeofconsistencyregularizationasitusesthepredictions
maintainthepseudo-databaseprogressivelyandadaptively. ofonemodeltosupervisetheoutputofanothermodel. Dif-
We use a dynamic pseudo-database to progressively chal- ferently,theproposedHASSmethodgeneratesdiversesyn-
lengethemodelbyaddingthepseudo-objectstothepseudo- theticdatatoimprovethegeneralization.
database. ExtensiveexperimentsonthewidelyusedKITTI 3D Object Detection. Voxel-based representation [5,
[10]andWaymo[36]datasetsdemonstrate that ourHASS 13,30,47,51,56,61]isacommonpointcloudprocessing
improves the performance of existing methods by a large methodindeeplearningandhasbeenwidelyusedin3Dob-
margin. Wealsoprovideanin-depthanalysisoftheperfor- jectdetection. VoxelNet[61]groupedpointclouddatainto
mancesofHASSunderdifferentsettingstodemonstratethe voxelsandusedavoxelfeaturecodinglayertoobtainvoxel
effectivenessofeachmodule. features.PV-RCNN[32]integratedboth3DvoxelConvolu-
tionalNeuralNetwork(CNN)andPointNet-based[27]set
2.Relatedwork abstractiontolearnfeatures. MV3D[4]isthefirstmethod
to convert point cloud data into a BEV representation for
Semi-Supervised 3D Object Detection. While conven-
3Ddetection, whichbecamepopularamong3Dobjectde-
tional methods focused on semi-supervised 2D object de-
tection methods due to its high efficiency [4, 18, 33, 48].
tection from images [3, 7, 19, 22, 35, 45, 46, 49], recent
However, 3D object detection is usually limited by the la-
methods exploited the characteristics of point clouds and
beled training data which are laborious to annotate. Our
developed various techniques for 3D object detection to
method aims at effectively utilizing the unlabeled samples
utilized additional unlabeled data [26, 39, 40, 50, 52, 57].
toimprovetheperformance.
SESS[57]introducedacomprehensiveperturbationstrategy
andusedasymmetricdataaugmentationtoimprovemodel
3.ProposedApproach
generalization. 3DIoUMatch [40] designed a network to
estimate locations for pseudo-label localization. Proficient 3.1.Overview
Teachers [50] obtained bounding box features via a pre-
trainedRoInetwork[8]andenhancedtherecallofpseudo- Given a labeled point clouds sample xl i ∈ RN×4 con-
labelsbymanuallydevisingSpatial-temporalEnsemble. taining a set of objects y i = {y i1,y i2,··· ,y ij} and each
Recent work [15, 20, 43] explored applying data aug- y ij containing a class code l j, bounding box parameters
mentationtoimprovesemi-supervisedobjectdetection.For b j = {c j,d j,h j}. c j, d j, and h j represent the center co-
example, PseudoAugment [15] devised data augmentation ordinates,dimensions,androtationanglesofthebounding
strategies based on pseudo-labels to fuse both labeled and boxy ij,respectively. Furthermore,assumewehaveaccess
pseudo-labeleddatatomineunlabeleddata.SS3D[20]pro-
toanunlabeledpointcloudssamplexu
i
∈RN×4.
posedasparse-supervisedmethodanddesignedaninstance Fully-supervisedlearningonlyuses{xl}Nl assupervi-
i i=1
mining module with a filter to mine positive instances. sion, where N l is the number of labeled samples. Semi-
However,directscenesynthesiscannotachievesatisfactory supervised learning aims to mine effective features from
resultsduetothelowqualityofpseudo-labels, whichmay the unlabeled data {xu}Nu without reliable supervision,
i i=1
corrupt the pseudo-database and mislead the model. Con- where N u is the number of unlabeled samples. Pseudo-
sidering this, we propose a HASS framework to progres- labeling-based semi-supervised detection predicts y˜ from
i
sivelygenerateharderyetmoreaccuratesyntheticsamples the xu i point clouds which contains a set of objects y˜ i =
fortraining. Wefurtherdesignadynamicpseudo-database {y˜ i1,y˜ i2,··· ,y˜ ij}. Each y˜ ij consists of class code ˜l j,
toimprovethequalityanddiversityofscenesynthesis. ˜b = {c˜ ,d˜,h˜ }. y˜ isnotcompletelyaccuratebutcanre-
j j j j i
Semi-Supervised Learning. Semi-supervised learning flectsemanticfeaturesofxupointclouds.Pseudo-labeling-
i
(SSL)isdesignedtotrainmodelswithfewlabeleddataand basedsemi-superviseddetectionmethodsusuallyleveragea
2Hardness-aware Scene Synthesis Hard-synthesis Stage
Easy-synthesis Stage
Weak
Augment Trained Dynamic Pseudo-labels
Teacher Filter
Original
Teacher Filter
Unlabeled
Dense
EMA
Scene Synthesis

Strong Trained
Augment Student
Sparse to Dense
Original Scene Synthesis

Student   ∪  
Labeled
Pseudo-labels


Database Pseudo-database
Figure2.OverviewoftheHASSframework.Theproposedarchitectureconsistsoftwostages:(a)EasySynthesisand(b)HardSynthesis.
Weusebluearrowsandlightreddashedarrowstorepresenttheeasy-synthesisstageandhard-synthesisstagerespectively. Intheeasy-
synthesis stage, we only synthesize ground truth objects (light blue arrow), where the database is generated offline before training and
containsonlygroundtruth. Asthetrainingproceeds,themodelismoretolerantofhardpseudo-labels. Wemaintainapseudo-database
andupdatethepseudo-databasewiththeappropriatepseudo-labelsinthehard-synthesisstage(lightpinkdashedarrow).Thegreenarrow
represents the dense synthesis strategy for the easy-synthesis stage, and the red dashed arrow represents the sparse to dense synthesis
strategyforthehard-synthesisstage.
teacher-student framework to propagate information in the constructapointcloudscenewithanyforegroundorback-
formofpseudo-labelsy˜. groundobjectswithoutrendering[28],facilitatingefficient
i
The teacher model can aggregate information and pro- mining of unlabeled data {xu}Nu. In this paper, we pro-
i i=1
duceamoreaccuratemodelthanusingtheweightsdirectly. poseahardness-awarescenesynthesis(HASS)framework
The predictions y˜ of the teacher model are more reliable. togenerateadaptivesyntheticscenestoimprovethegener-
i
Weusetheteachermodeltopredict{y˜}Nu: alization,asshowninFigure2.
i i=1
{y˜}=f(xu,θ ),∀i=1,··· ,N , (1)
i i t u 3.2.Objects&BackgroundComposition
where θ is the parameters of the teacher model at time t.
t We synthesize the labeled point clouds xl and the fore-
Thefinallosscanbeformulatedas: i
ground point clouds p˜ from the unlabeled samples
j
L=L l({xl i}N i=l 1,{y i}N i=l 1)+λ uL u({xu i}N i=u 1,{y˜ i}N i=u 1), {xu i}N i=u 1intoascene,asshowninFigure3. Wethenobtain
(2) asetofobjectsinxl:
i
whereλ istheunsupervisedlossweight.
u
Mostexistingpseudo-labelingsemi-supervisedmethods y ={y ,y ,··· ,y ,y˜ ,y˜ ,··· ,y˜ }, (3)
i i1 i2 ij i1 i2 ik
for 3D detection follow the semi-supervised 2D detection
methods. They usually define a pseudo-label quality eval- wherey i = {y i1,y i2,··· ,y ij}ismanuallylabeled. Given
uation metric, and then filter the pseudo-labels y˜ accord- an unlabeled data set {xu}Nu, we use the teacher model
i i i=1
ing to the metric. Despite good performance, they ignore to predict each sample in the set to generate foreground
the unstructured nature of the point clouds, which are dif- pseudo-labels{y˜ }Nu. Inaddition,wemaintainapseudo-
i i=1
ferentfromplanar-likeimagesthatcannotreflecttheactual database D˜ of pseudo-labels y˜, and the qualified pseudo-
i
geometry of objects. The spatial structure of pixels is dif- labels will be added to the database. We obtain a pseudo-
ficult to change, and point clouds faithfully reflect the dis- databaseD˜ = {y˜ ,y˜ ,··· ,y˜ }thatiscontinuallyupdated
1 2 n
tribution of the physical world. Therefore, we can easily and contains a lot of foreground information about unla-
3
SupervisionRaw Scene Raw Scene Raw Scene
Synthetic Scenes
Synthetic Scene Flipped Scene Cutted&Mixed Scene
Ground Truth
Pseudo-objects
(a) (b) (c)
Figure3. Anillustrationoftheproposed(a)SceneSynthesisand(b)theFlip, (c)PointCutMixdataaugmentationmethods. (a): Blue
boundingboxesrepresentexistinggroundtruthboxes,andredboundingboxesrepresentsyntheticobjects.Scenesynthesisistosynthesize
theforegroundpseudo-labelsfromthepseudo-databaseonthelabeledpointclouds,wherethesyntheticscenescontainabundantunseen
foregroundinformation. Weavoidobjectcollisiontosynthesizethecorrectscenes. (b): Flipaugmentationisthestraightforwardprocess
offlippingthepointcloudtoobtainsimilardata. (c): PointCutMixinvolvesreplacingpartsofitsownpointcloudwithpointcloudsfrom
otherscenes.Pointcloudsofdifferentcolorsrepresentdatafromdifferentscenes.
beled data {xu}Nu. Specifically, we concatenate fore- y˜ produced by less trained teacher models are mostly of
i i=1 i
groundpseudo-labelsy˜ fromthepseudo-databaseD˜ with lower quality. As shown in Figure 4, low-quality pseudo-
n
manually labeled objects y . The synthesis of foreground labels generated by the original model y˜ commonly con-
i i
objectsy˜ onthelabeledbackgroundxl willnotcauseob- tain only a fraction of the ground truth, which cannot sin-
n i
jectcollision,whichensuresthatthesyntheticpointclouds cerely reflect the geometry of ground truth, so the use of
x˜l is the correct reflection of the real world as the annota- low-quality pseudo-labels y˜ can easily damage the preci-
i i
tion information specifies the location of all objects y in sion of training data. These low-quality pseudo-labels are
i
thelabeledscenes. Beforesynthesizingascene,weremove hardtouseasinputsyntheticsamplesfortraining.Thismay
backgroundpointcloudsxl inthelabeledscenetoprevent cause the model to be trained in the wrong direction from
i
collisionsamongthesynthesizedobjectsy˜ . thebeginning,resultinginlowerqualitypseudo-labelsy˜.
n i
Whiletheexistingmethods[40]onlyusesxl iwithy i,we Astrainingprogresses,themodelbecomesbetterathan-
synthesizepowerfulx˜l i containingy˜ i asinputtothemodel. dling hard pseudo-labels, and the trained teacher model
Theunsupervisedlossisformulatedas: generates higher-quality pseudo-labels y˜. Therefore, the
i
L ({x˜l}Nl ,{y˜l}Nl ), (4) hard pseudo-labels can be synthesized in the input sam-
l i i=1 i i=1 ples,andpseudo-labelsy˜ generatedbythetrainedteacher
i
where {y˜l}Nl are manual labels and the predictions of model are more suitable for scene synthesis. We propose
i i=1
othertemporalteachermodels. Comparedtotheotherdata a hardness-aware scene synthesis to handle low-quality
syntheticmethods[6,21],ourproposedHASShasdifferent pseudo-labels y˜ from the trained teacher model, mak-
i
synthesizedcontentandissimplertogeneralize. ing them usable for scene synthesis. The difference be-
tweenthe“easy-synthesis”and“hard-synthesis”stageslies
3.3.Hardness-AwareSceneSynthesis
in whether pseudo-labels are used for synthesis, as learn-
Notallpseudo-labelsy˜ canbeusedforeffectivescenesyn- ing from pseudo-labels presents challenges for the model.
i
thesis. Therefore, the proposed method has strict require- When to enter the “hard-synthesis” stage depends on the
mentsonthequalityofpseudo-labelsy˜,andpseudo-labels level of training hardness for the model, and we proceed
i
4Densescenesynthesisisnotmeaningfulforthemodelwhen
Ground Truth New Pseudo-labels
Refined Pseudo-labels thequalityofthepseudo-databaseD˜ isnothigh. However,
Pseudo-labels
withahigh-qualitypseudo-database,sparsescenesynthesis
Training
cannotachieveefficientminingofunlabeleddata.
To solve these issues, we introduce a dynamic pseudo-
database D˜ method. The threshold for filtering objects
intothepseudo-databasevariesfromhightolow,whilethe
(a) Easy Synthesis Stage: (b) Hard Synthesis Stage: scenesynthesisdensityrangesfromsparsetodense. Mod-
insufficient training. sufficient training.
erate threshold filtering with either estimated IoU or con-
Figure 4. The visualization of detection with different models.
fidence inevitably leads to low-quality pseudo-labels y˜ in
Blueboxesrepresentgroundtruthboxesandredboxesrepresent i
pseudo-labels. Wevisualizethedetectionofteachermodelsgen-
thepseudo-databaseD˜.Atthebeginningofaddingpseudo-
eratedindifferentepochsonthesamesample. (a)showsthelow labelsy˜ itopseudo-databaseD˜,themodelrecognitionaccu-
recallrateoftheoriginalteachermodelatthebeginningoftrain- racyisstillrelativelylow. Wethenavoidmisleadingmod-
ing.Theorangecirclepointsoutafalsepseudo-label:apedestrian elswithtoomanylow-qualitypseudo-labelsbyimproving
identifiedasacyclist. (b)showsthattherecallrateofthetrained the entry threshold. As the model becomes more tolerant
teachermodelishigherthantheoriginalmodel.Thetrainedmodel of difficult samples, the quality of pseudo-labels y˜ with
i
predictshardsamplesbetterthantheoriginalmodel.
the same score increases. To maintain a high learning ef-
ficiency,welowertheentrythresholdtoimprovethediver-
tothe“hard-synthesis”stagewhenthehardnessoftraining
sityofpseudo-databaseD˜ information.
samplessufficientlydecreases.
Figure 4 shows the detection result of the same sam- With the improvement of pseudo-database D˜ quality, it
ple by different teacher models. The recognition accuracy isnecessarytoadoptaflexiblesynthesisstrategy. Wethen
of the teacher model increases using more training sam- adopt a sparse synthesis strategy at the beginning of up-
ples. Weonlyaddpseudo-labelsy˜ generatedbythetrained dating the pseudo-database D˜. We do not add too many
teacher model to the pseudo-datai base D˜. For the under- foregroundobjectsfromthepseudo-databaseD˜ ineachla-
trainedmodel,thedifficultsamplesaremorelikelytopro- beled point cloud to avoid more low-quality pseudo-labels
duce low-quality pseudo-labels y˜ i. For the better-trained y˜ i and mitigate the influence of low-quality pseudo-labels
m ino gd de il f, fit ch ue ltqu saa mlit py leo sf ip ns ce ru ed ao se-l sa ab ne dls cy˜ ai ng be ene er na ote ud ghby fop rre sd ceic nt e- y d˜ i ato an bam seod D˜el wtr ia li ln bin eg h. igH ho ew re wve hr e, nth te hequ ma oli dty elo hf at she lep as re nu ed do a-
synthesis. Although there will inevitably be low-quality large number of hard samples at later stages of training.
pseudo-labels, the trained model tolerates these hard low- More foreground objects from the pseudo-database D˜ can
qualitypseudo-labelsmorethantheoriginalmodel. Inthe be synthesized in the annotated background point clouds,
easy-synthesis stage, we only use the manual labels in the andweadoptamoredensesynthesisstrategytosufficiently
grounddatabaseD = {y ,y ,··· ,y }forscenesynthe- minethefeaturesofunlabeleddata.
i1 i2 ij
sis without adding the pseudo-labels y˜ generated by the Our method can be seen as a training strategy which
i
originalmodeltothepseudo-databaseD˜. Onlyusingthese leveragesadditionalunlabelleddatatoimprovetheperfor-
ground-truth labels y for scene synthesis also accelerates mance of 3D object detection in autonomous driving. The
i
theconvergenceofthemodel. Inthehard-synthesisstage, proposed framework can be applied to existing detectors
the model learns a large amount of data and can produce duringtrainingtoincorporateunlabelleddataanddoesnot
moreaccuratepseudo-labelsy˜ fromdifficultsamples. The introduceadditionalcomputationduringinference.
i
pseudo-labels y˜ generated by the trained model are then
i
filteredaccordingtothethresholdandaddedtothepseudo- 4.Experiments
databaseD˜ toincreasethediversity.
4.1.ExperimentalSettings
3.4.DynamicPseudo-database
In this section, we conducted various experiments on the
The estimated IoU [40] and the confidence can accurately widelyusedKITTI[10]andWaymodatasets[36]toverify
reflect the quality of the pseudo-labels y˜. The relation- thevalidityofourmethod. Wealsoprovidein-depthexper-
i
ship between pseudo-labels IoU and filtering threshold is imentalanalysisanddiscussionsaboutourframework.
giveninSection4.3. Ifthefilteringthresholdistoohigh,a KITTIDataset. Weexperimentedon1%,2%,and10%
largeamountofforegroundinformationofunlabeledsam- labeled data proportions. In this experiment, we start up-
pleswillbelost.Ifthethresholdforfilteringissettoolow,a datingthepseudo-databaseat45thepochandincreasingthe
low-qualitypseudo-databasewillbeobtainedandthemodel synthesisdensityincreasesfrom5to15.
will be trained on the wrong training data. The density of WaymoDataset. Weexperimentedonlabeleddatapro-
scene synthesis is also crucial in different training stages. portionsof5%,10%,and20%. Weproceededtothehard-
5Table 1. Comparisons with the 3DIoUMatch [40] and DDS3D [16] on the KITTI val set with different labeled ratios. The results are
formoderatedifficultylevelevaluatedbythemAPwith40recallpositionswitharotatedIoUthresholdof0.7,0.5,and0.5forthethree
classes,respectively.*denotesreproducedresults.
1% 2% 10%
Method
Overall Car Pedestrian Cyclist Overall Car Pedestrian Cyclist Overall Car Pedestrian Cyclist
PV-RCNN[1][32] 44.3 73.8 28.2 30.8 53.3 76.4 39.6 43.9 62.7 79.7 49.1 59.2
3DIoUMatch[40] 45.6 75.2 28.8 32.9 54.9 77.2 37.8 49.7 63.1 79.4 50.7 59.2
3DIoUMatch* 47.8 76.0 30.7 36.8 59.0 78.6 45.3 53.0 – – – –
DDS3D[16] 49.8 76.0 34.8 38.5 60.7 78.9 49.4 53.9 – – – –
HASS 51.4 75.9 31.0 47.2 61.7 79.0 44.5 61.7 65.9 79.8 52.8 65.1
Improvements +5.8 +0.7 +2.2 +14.3 +6.8 +1.8 +6.7 +12.0 +2.8 +0.4 +2.1 +5.9
Table2.Comparisonswiththe3DIoUMatch[40]andProficientTeachers[50]ontheWaymovalsetwithdifferentlabeledratios.mAPand
mAPHunderLEVEL2metricareusedtoevaluatethe3Dobjectdetectionperformanceonthefullvalidationsetwith3DIoUthresholds
of0.7,0.5,and0.5forVehicle,Pedestrian,andCyclist,respectively.
3DAP/APH@0.7(LEVEL2)
LabelAmounts Model Improvements
Overall Vehicle Pedestrian Cyclist
3DIoUMatch[40] -/- 48.85/43.91 52.41/51.26 46.05/35.85 48.10/44.63
5%(∼4kLabels) ProficientTeachers[50] +2.25/+1.84 51.10/45.75 53.04/52.54 50.33/38.67 49.92/46.03
HASS +3.79/+4.36 52.64/48.27 53.36/52.73 50.15/39.63 54.42/52.46
3DIoUMatch[40] -/- 53.39/48.25 56.43/55.65 51.11/40.10 52.63/49.01
10%(∼8kLabels) ProficientTeachers[50] +1.62/+2.18 55.01/50.43 57.59/56.92 54.28/43.19 53.15/51.18
HASS +2.15/+2.83 55.54/51.08 57.68/56.12 53.83/42.75 55.11/54.36
3DIoUMatch[40] -/- 57.2/52.35 59.37/58.22 55.59/44.38 56.63/54.46
20%(∼16kLabels) ProficientTeachers[50] +1.39/+1.81 58.59/54.16 59.97/59.36 57.88/46.97 57.93/56.15
HASS +1.89/+1.87 59.09/54.22 59.19/58.38 57.75/46.87 60.32/57.41
synthesisstageatthe15thepoch,wherethedensityofsyn- hardness-aware scene synthesis produces data containing
thesizingpseudo-objectsincreasedfrom10to30. raresamplestoextenddatadistributionandimproveperfor-
Weprovidemoredetailsaboutdatasets,implementation, manceeffectively.Wealsotestedtheinferencespeedofour
andevaluationmetricsinSectionsB,D,andC. model on a single NVIDIA GeForce RTX 3090 GPU and
achieved an FPS of 5.9. Note that our method introduced
4.2.MainResults noadditionalcomputationsduringinference.
The experimental results in Table 2 indicate that our
We compared our HASS with DDS3D [16] and
method also exhibits strong generalization on the large-
3DIoUMatch [40] on the KITTI [10] val set. We also
scaleWaymodataset. Ourmethodshowssignificantperfor-
report comparisons between Proficient Teachers [50] and
manceimprovementonasmallproportionoflabeleddata.
ourproposedframeworkontheWaymovalidationdataset.
In experiments with a 5% proportion of labeled data, our
Table 1 shows that the proposed method achieves com-
method achieved an overall performance gain of 3.79/4.36
petitive results on the KITTI dataset. We see that our
forAP/APH.Inthe10%and20%settings,theperformance
HASSachievesthebestperformanceinallsettings. Specif-
gains were 2.15/2.83 and 1.89/1.87, respectively. We also
ically, in the 2% 3DIoUMatch experiment reproduced by
maintainaleadingpositioninoverallperformancegainPro-
DDS3D[16], the Pedestrian detection performance differs
ficientTeachers[50].
from ours by 7.5. Our overall performance in the 1% pro-
portion experiment is 1.6 higher than DDS3D [16], and in
4.3.AblationandAnalysis
the 2% proportion experiment, it is 1.0 higher than theirs.
Since the filter modules are difficult to filter the predic- Extending the Data Distribution. We conducted experi-
tions of the original teacher model at the beginning, the ments with fully-supervised PV-RCNN [32] on the KITTI
predictionsofthetrainedteachermodelarerelativelyaccu- dataset. We followed gt-sampling [47] to use a database
rate,andthefiltermodulesareabletofilteroutlow-quality composed entirely of labeled samples for scene synthe-
pseudo-labels. Withthetrainedteachers,thefiltersareable sis. Compared with the general method, scene synthesis
toobtainhigh-qualitypseudo-labels. Theproposedmethod achieves superior performance. This demonstrates the ef-
slightly improved performance for common samples such fectivenessofusingscenesynthesistoextendthedatadis-
asCarandsignificantlyimprovedperformanceforraresam- tributioneven withoutintroducing unlabeleddata. Table 3
plessuchasPedestrianandCyclist. Theresultsverfiesthat showsthatextendingdatadistributionbringsimprovements
6Table3.Ablationstudyontheeffectofextendingdatadistributionon10%labeled-onlydata.
Car Pedestrian Cyclist
Method
Easy Mod. Hard Easy Mod. Hard Easy Mod. Hard
PV-RCNN 89.0 75.1 72.0 26.2 23.5 21.3 12.6 7.9 7.8
PV-RCNN-Extend 91.2 79.4 76.6 56.2 49.2 44.5 77.1 55.7 52.3
Improvements +2.2 +4.3 +4.6 +30 +25.7 +47.8 +64.5 +47.8 +44.5
Table4. Comparisonsofdirectscenesynthesiswithdifferentfil- Table5. Ablationstudyforexploringtheeffectofpseudo-labels
teringthresholdsontheKITTIvalset. producedbytrainedteachermodelinofflinescenesynthesis.
τ Car Pedestrian Cyclist Methods Car Pedestrian Cyclist
thresholds
Baseline 79.4 49.2 55.2 Baseline 79.4 49.2 55.2
0.4 77.3 48.6 65.5 Offline 79.9 52.5 66.3
Conf
0.5 77.7 50.6 62.1 Improvements +0.5 +3.3 +11.1
Conf
0.6 78.0 51.4 61.8
Conf
Car: +18% Ped: +43% Cyc: +28%
8
Car Ped Cyc 6
4
2
0
-2
-4
-6
-8
-10
0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0
IoU
Figure6. Thequalityimprovementintheofflinepseudo-database
IoU generatedbyamodeltrainedfor60epochs,comparedtothedi-
Figure5. ThevisualizationoftherelationshipbetweenIoUand rectlygeneratedpseudo-databasefilteredwithaconfidencethresh-
confidenceofpseudo-labels. oldof0.6.Theresultsdidnotcountgroundtruthobjects.
of 4.3, 25.7, and 47.8 AP on moderate difficulty of Car, obtainhigh-qualitypseudo-labels(IoU>0.8).
Pedestrian, and Cyclist, respectively. We observe that the Effect of the Dynamic Pseudo-database. We verify
extended data distribution greatly improved the detection the effectiveness of the pseudo-labels produced by trained
performanceofraresamplessuchasPedestrianandCyclist. teacherfilteringbasedontheconfidencethresholdfordirect
DirectSceneSynthesis.Weconducteddirectscenesyn- scene synthesis. We maintain an offline pseudo-database
thesis experiments in different confidence filtering thresh- generated by the fully trained 60 epochs teacher traverse
oldsontheKITTIdataset. Basedon3DIoUMatch[40],we unlabeleddatabasedona0.6confidencethreshold.Pseudo-
maintainanonlinepseudo-database.Weexperimentedwith labels in the offline database are not updated during train-
thresholds of 0.4, 0.5, and 0.6, respectively. We observe ing. Table5showsthatofflinescenesynthesisoutperforms
animprovementinPedestrianandCyclist,butadeclinein 3DIoUMatch baseline by 0.5, 3.3, and 11.1 AP on Car,
Car, asshowninTable4. Wearguethatthepseudo-labels Pedestrian, and Cyclist, respectively. This advocates the
produced by the original teacher filtering based on confi- trainedteachermodelinsteadoftheoriginalteachermodel
dence threshold are not suitable for all types directly used to produce a pseudo-database. Figure 6 shows the quality
forscenesynthesis. improvement of the offline pseudo-database. We observe
In Figure 5, we show the relationship between the IoU thatthequalityanddiversityoftheofflinepseudo-database
and the confidence of the pseudo-labels generated by the arebetterthanthepseudo-databasegeneratedbytheorigi-
original teacher. Confidence cannot accurately reflect the nalmodelbasedona0.6threshold.
IoU of pseudo-labels. We observe that many high-quality Evaluation of Different Filtering Methods. We com-
pseudo-labels have low confidence, so these pseudo-labels pare the pseudo-label quality generated by different filter-
will be discarded in training, leading to a lack of unla- ing methods and thresholds. We conducted pseudo-label
beled data information. However, there exist some low- filtering experiments on 10% labeled data based on confi-
quality pseudo-labels with high confidence. These low- dence[32]andestimatedIoU[40]ontheKITTIdataset.As
qualitypseudo-labelswillbeaddedtothepseudo-database shown in Figure 7, the number of pseudo-labels decreases
during trainingand supervise themodel. A high threshold withahigherthresholdandalargerproportionofIoU.IoU-
(0.8)cannotcompletelyfilteroutlow-qualitypseudo-labels based and confidence-based filtering has worked well for
(IoU<0.6),andwecannotonlyrelyonahighthresholdto bothcarandcyclistpseudo-labels. Withsimilarquality,the
7
erocS
ecnedifnoC
）%（htworG
egatnecrePCar_0.4: 7414 Car_0.5: 7113 Car_0.6: 4410 Ped_0.4: 403 Ped_0.5: 308 Ped_0.6: 124 Cyc_0.4: 281 Cyc_0.5: 190 Cyc_0.6: 165
70 70 80
60 60 70
50 50 60
50
40 40
40
30 30
30
20 20 20
10 10 10
0 0 0
0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0 0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0 0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0
IoU IoU IoU
(a)CarConf (b)PedConf (c)CycConf
Car_0.4: 10923 Car_0.5: 7043 Car_0.6: 4664 Ped_0.4: 2142 Ped_0.5: 979 Ped_0.6: 128 Cyc_0.4: 888 Cyc_0.5: 574 Cyc_0.6: 346
60 70 70
50 60 60
40 50 50
40 40
30
30 30
20 20 20
10 10 10
0 0 0
0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0 0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0 0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0
IoU IoU IoU
(d)CarIoU (e)PedIoU (f)CycIoU
Figure7.Comparisonsofpseudo-labelqualitywithdifferentfilteringmethodsandthresholds.
Table6. Ablationstudyofsemi-supervisedon10%labeleddataandfullunlabeleddataofWaymoandKITTIdatasets. TTheKITTI
resultsareformoderatedifficultylevelevaluatedbythe3dmAPwith40recallpositions. WeadopttheAPunderLEVEL2metricto
evaluatethe3DobjectdetectionperformanceontheWaymodataset.
SynthesizedDensity Hardness-awarelevel KITTI10%/Waymo10%
Exp. Threshold
sparse. dense. sparsetodense. 25th/5th 35th/10th 45th/15th Car/Vehicle Pedestrian Cyclist
Baseline 79.4/56.43 49.2/51.11 55.2/52.63
(a) ✓ ✓ 79.5/56.85 52.9/53.36 61.1/54.51
(b) ✓ ✓ 79.4/56.79 49.8/52.82 57.2/54.92
(d) ✓ ✓ 79.2/55.89 50.2/51.16 58.3/53.25
(e) ✓ ✓ 79.4/57.32 51.0/53.58 61.5/54.75
(f) ✓ ✓ 79.6/57.66 52.9/53.78 64.2/55.01
(g) ✓ ✓ ✓ 79.9/57.75 53.5/54.77 64.8/55.31
Car: +14% Ped: +44% Cyc: +64% pedestrianpseudo-labelsisreduced,butthenumberisalso
8 greatlyreduced.Therearestillmanylow-qualityPedestrian
6 pseudo-labels (IoU < 0.6 account for more than 30%) fil-
4 teredbythetwomethods,whichisrelatedtotheprincipleof
2 estimatingIoU.Thepointsofthepedestrianarelikeacylin-
0 der,andthepredictedboundingboxisacuboid. Theoutput
-2 estimated IoU of the module is likely to be similar for the
-4 boundingboxwithdifferentrotationangles. Bothmethods
-6 filterCarwell,andhigh-qualitypseudo-labels(IoU>0.8)
-8
0~0.2 0.2~0.4 0.4~0.6 0.6~0.8 0.8~1.0 account for nearly 50%. However, the detection perfor-
IoU manceofthecardeclinesintheexperimentofdirectscene
Figure8. Ablationofthedynamicpseudo-databasecomparedto
synthesis.Wearguethatthequalityofpseudo-labelsshould
thedirectlygeneratedpseudo-databasefilteredwithaconfidence
behigherforsuchcommonobjectsascars.
thresholdof0.6.Theresultsdidnotincludegroundtruthobjects.
Ablation Study of Dynamic Pseudo-database. We
IoU-based method gets more cyclists, while the quality of compared hardness-aware scene synthesis using different
cars filtered by the confidence-based method is better than synthesis strategies on the KITTI and Waymo datasets. In
thatoftheIoU-basedmethod. TheIoU-basedmethodbet- the KITTI dataset experiments, the sparse synthesis strat-
ter filters Pedestrian pseudo-labels with low quality, but it egy is to synthesize 5 objects per batch during the whole
does not achieve the expected results. Pedestrian pseudo- scene synthesis stage, while the dense strategy is to syn-
labelswithIoUoflessthan0.6stillaccountforabout35% thesize15objects. Thenumberofsynthesizedsamplesin-
after0.5IoU-basedthresholdfiltering. Afterfilteringbased creases with the model learning process. Scene synthesis
ona0.6IoU-basedthreshold,theproportionoflow-quality from sparse to dense is dynamically adjusted the synthe-
8
）%（egatnecreP
）%（egatnecreP
）%（htworG
egatnecreP
）%（egatnecreP
）%（egatnecreP
）%（egatnecreP
）%（egatnecrePGround Truth
Pseudo-labels
Figure9.Qualitativeresultsof3DobjectdetectiononKITTIwiththe10%labeledset.Blueandredboundingboxesdenotegroundtruths
andpredictions,respectively.
sized density throughout the synthesized phase from 5 to is because the better-trained models can generate samples
15. IntheWaymodataset,eachsamplecontainsmorefore- that are easier to learn with scene synthesis relying on the
ground objectscompared to the KITTIdataset. Therefore, trainedteacher.
intheWaymoexperiments,wedoubledthenumberofsyn- Visualizations. We provided qualitative comparisons
thesizedpseudo-objectscomparedtothatoftheKITTIex- with3DIoUMatch[40]inFigure9. WeseethatHASSpro-
periments. Table6showsthatthesparse-to-densesynthesis ducespseudo-labelswithbetterquality. Thisisbecausewe
strategy achieves better results, which is active when the employthehardness-awarescenesynthesismethodandthe
pseudo-database samples are more accurate and conserva- dynamic synthesis strategy, which gradually increases the
tivewhentheyarelessaccurate. Thefilteringthresholdof densityofscenesynthesistoalleviatetheimpactoftheini-
experimentswithoutdynamicthresholdstrategyis0.5and tialpseudo-databaseonsyntheticsamples.
the dynamic filtering thresholds on the KITTI dataset and
Waymodatasetwerechangedfrom0.6to0.4andfrom0.8
5.Conclusion
to 0.4, respectively. Figure 8 shows that dynamic pseudo-
databaseachieveshigherqualityanddiversityincontrastto
In this paper, we have presented a hardness-aware scene
Figures7a,7b,and7c.
synthesis(HASS)frameworkforsemi-supervised3Ddetec-
Ablation Study of Hardness-aware Level. We tested tion.Weproposetomineunlabeleddatatogeneratediverse
theeffectofhardness-awareonperformanceontheKITTI data to supplement training and extend the data distribu-
andWaymodatasets. Wecomparedtheeffectofscenesyn- tiontoimprovethegeneralizationability. Asscenesynthe-
thesis based on the pseudo-database produced by different sis requires high-quality pseudo-labels, we further use the
trained models. The total training process for the KITTI pseudo-labelsgeneratedbythetrainedmodelinsteadofthe
and Waymo dataset experiments is terminated at the 60th original teacher for scene synthesis to reduce the number
epoch and the 30th epoch, respectively. The three groups of low-quality pseudo-labels. We have adopted a sparse-
ofexperimentsontheKITTIandWaymodatasetsstartup- to-dense scene synthesis strategy to produce more high-
dating the pseudo-database at the 25th and 5th epochs, re- quality pseudo-labels while reducing the impact of low-
spectively,withintervalsof10epochsand5epochs. Table qualitypseudo-labels. Wehaveconductedextensiveexper-
6 shows that the hardness-aware scene synthesis method iments on the widely used KITTI and Waymo datasets to
based on a pseudo-database produced by the 45th or 15th demonstratethesuperiorityofourframeworkandprovided
epoch-trained model achieves the best performance. This anin-depthanalysisoftheeffectivenessofeachmodule.
9
segamI
hctaMUoID3
sruOA.MoreRelatedWork ground information for nearly every scenario and offers
annotations encompassing the entire scene rather than just
Semi-Supervised Object Detection. The ability to learn
specificviewpoints.
from additional unlabeled data is appealing for 2D ob-
ject detection [3, 7, 19, 22, 35, 45, 46, 49]. STAC [35]
C.EvaluationMetrics
proposes an SSOL framework based on self-training and
augmentation-drivenconsistencyregularization. MixPL[7]
According to the conventional KITTI experiments, we re-
addressedtheissueoffailingtodetectsmallandtailobjects
port the mAP for 3D boxes with 40 recall positions. The
forconventionalimage-basedmethodsbyusingthemixup
performancesontheCar,Pedestrian,andCyclistclassesare
strategy. Unbiased Teacher [22] followed the student-
evaluated with IoU thresholds of 0.7, 0.5, and 0.5, respec-
teacher mutual learning paradigm to address the pseudo-
tively. We use the 3DIoUMatch [40] as our baseline. We
labelingbiasissue. Tobalancetheeffectofpseudo-labels,
usemAPandmAPHundertheLEVEL2metrictoevaluate
SoftTeacher[46]proposedasoftteachermechanismwhere
the3Dobjectdetectionperformanceinexperimentsonthe
the classification loss of each unlabeled bounding box is
Waymodatasetwith3DIoUthresholdsof0.7,0.5,and0.5
weighedbyitsclassificationscore.
for”Vehicle,””Pedestrian,”and”Cyclist,”respectively.
Data Augmentation. Deep learning tasks often uti-
lize small perturbations such as scaling, jittering, points
dropout, flipping, and rotation to enhance the diversity of D.ImplementationDetails
the training set [17, 38, 53, 54]. The benefits of these
smallperturbationsdiminishasdatasetsbecomelarger,mo- KITTI Dataset. Following existing methods [40], we
tivating the exploration of more effective data augmenta- adopted PV-RCNN [32] as our detector. We conducted
tion strategies. CutMix [53] proposed to crop an image pre-trainingon1%,2%labeled-onlydataandincreasedthe
andblendpatchesfromotherimagestocreateanewimage numberoflabeleddatatraversalofeachepochto10times
sample for training. PointCutMix [54] extended the con- that of PV-RCNN [32]. Before pre-training, we initialized
cept of CutMix by establishing correspondences between a database of labeled data points with ground truths [47].
point clouds and then swapping them. PointAugment [17] During the easy-synthesis stage, the database remains un-
automatically selected data augmentation strategies (rota- changed,ensuringthatallobjectswithinitareentirelyman-
tion,scaling,andtranslation)byiterativelynarrowingdown ually annotated. In the hard-synthesis stage, at the end of
the search space in an end-to-end manner. PointAugment- eachepoch,weaddedfilteredpseudo-labelstothedatabase.
ing [38] further enhanced 3D object detection by decorat- Forthepre-trainingstage,thedetectorwasoptimizedbyan
ingpointcloudswithpoint-wiseCNNfeaturesextractedby ADAM optimizer with an initial learning rate of 0.01 for
pretrained2Dimagedetectionmodels. 80 epochs. For the semi-supervised learning stage, 98 %
or99%oftrainingdataareunlabeleddataandtherestare
Dataaugmentationgenerallyperformswellintaskswith
labeleddata. Wetrainedthedetectorfor60epochswiththe
labeleddatatopreventoverfitting. Itinvolvesaddingnoise
sametrainingsettingaspre-training. Wesetthebatchsize
to existing labeled samples, generating similar but not en-
as 2 (labeled: unlabeled, 1:1). We adopted the same data
tirelyidenticalsamples. Differently,ourapproachinvolves
pre-processing strategy as PV-RCNN. Due to the random-
synthesizing a new sample using data from unseen unla-
nessof1%and2%dataproportions,werandomlyselected
beledscenes,wherethekeychallengeistoensuredataau-
three groups in proportion from the training set and pre-
thenticity due to the quality of pseudo-labels. We address
sentedtheaverageresultsofthethreegroups. Additionally,
thisbyusingthehardness-awareadaptationtochallengethe
we expanded the evaluation of our method on the 10% la-
modelwithsamplesofadaptivedifficulty.
beleddata. Unlikethe1%and2%labeleddata,wedidnot
increasethenumberoftraversaloflabeleddata.
B.Datasets
Waymo Dataset. Following existing works [50], we
KITTIDataset. TheKITTIdatasetcontains7,481scenes evenly divided the 158K training samples into labeled and
as training samples and 7,518 scenes as testing samples. unlabeled sets. We randomly sampled 5%, 10%, and 20%
The 7,481 training samples were divided into a training sequencesfromthelabeledsetaslabeleddata. Thetraining
setcontaining3712samplesandavalidationsetcontaining dataconsistsofsampledlabeleddataandthefullunlabeled
3769 samples. KITTI contains point clouds of eight types set.Thepre-trainingprocessinvolvedtraversingthelabeled
ofobjects. dataonlyonceperepoch. Forsemi-supervisedtraining,we
Waymo Dataset. The Waymo dataset is composed of setthebatchsizeto4(labeled:unlabeled,1:3),whilekeep-
798 sequences for training and 202 sequences for vali- ingtheotherconfigurationsthesameastheKITTI.Boththe
dation, and each sequence consists of approximately 198 pre-training and semi-supervised training phases consisted
frames of data. Importantly, it provides abundant fore- of30epochs.
10References semi-supervised3dobjectdetection. InICRA,pages9245–
9252,2023. 6
[1] PhilipBachman,OuaisAlsharif,andDoinaPrecup. Learn-
[17] RuihuiLi,XianzhiLi,Pheng-AnnHeng,andChi-WingFu.
ing with pseudo-ensembles. In NeurIPS, page 3365–3373,
PointAugment: Anauto-augmentationframeworkforpoint
2014. 1,2,6
cloudclassification. InCVPR,pages6378–6387,2020. 10
[2] DavidBerthelot,NicholasCarlini,IanGoodfellow,Nicolas
[18] MingLiang,BinYang,YunChen,RuiHu,andRaquelUrta-
Papernot, AvitalOliver, andColinARaffel. Mixmatch: A
sun. Multi-taskmulti-sensorfusionfor3dobjectdetection.
holisticapproachtosemi-supervisedlearning. InNeurIPS,
InCVPR,pages7345–7353,2019. 2
page5050–5060,2019. 1,2
[19] Sihao Lin, Wenhao Wu, Si Wu, Yong Xu, and Hau-San
[3] CongChen,ShouyangDong,YeTian,KunlinCao,LiLiu,
Wong. Unreliable-to-reliableinstancetranslationforsemi-
and Yuanhao Guo. Temporal self-ensembling teacher for
supervised pedestrian detection. TMM, pages 728–739,
semi-supervisedobjectdetection. TMM,pages3679–3692,
2021. 2,10
2021. 2,10
[20] Chuandong Liu, Chenqiang Gao, Fangcen Liu, Jiang Liu,
[4] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia.
DeyuMeng,andXinboGao. Ss3d: Sparsely-supervised3d
Multi-view 3d object detection network for autonomous
object detection from point cloud. In CVPR, pages 8428–
driving. InCVPR,pages1907–1915,2017. 2
8437,2022. 2
[5] Yilun Chen, Shu Liu, Xiaoyong Shen, and Jiaya Jia. Fast
[21] LanlanLiu,MichaelMuelly,JiaDeng,TomasPfister,andLi-
pointr-cnn. InICCV,pages9775–9784,2019. 2
JiaLi. Generativemodelingforsmall-dataobjectdetection.
[6] ZheChen,WanliOuyang,TongliangLiu,andDachengTao.
InICCV,pages6073–6081,2019. 4
A shape transformation-based dataset augmentation frame-
[22] Yen-Cheng Liu, Chih-Yao Ma, Zijian He, Chia-Wen Kuo,
work for pedestrian detection. IJCV, pages 1121–1138,
KanChen,PeizhaoZhang,BichenWu,ZsoltKira,andPeter
2021. 4
Vajda. Unbiased teacher for semi-supervised object detec-
[7] Zeming Chen, Wenwei Zhang, Xinjiang Wang, Kai Chen,
tion. arXivpreprintarXiv:2102.09480,2021. 1,2,10
andZhiWang.Mixedpseudolabelsforsemi-supervisedob-
ject detection. arXiv preprint arXiv:2312.07006, 2023. 2, [23] Jiageng Mao, Minzhe Niu, Chenhan Jiang, Hanxue Liang,
Jingheng Chen, Xiaodan Liang, Yamin Li, Chaoqiang Ye,
10
Wei Zhang, Zhenguo Li, et al. One million scenes
[8] Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou,
for autonomous driving: Once dataset. arXiv preprint
Yanyong Zhang, and Houqiang Li. Voxel r-cnn: Towards
arXiv:2106.11037,2021. 1
highperformancevoxel-based3dobjectdetection. InAAAI,
pages1201–1209,2021. 2 [24] Qinghao Meng, Wenguan Wang, Tianfei Zhou, Jianbing
Shen,LucVanGool,andDengxinDai. Weaklysupervised
[9] JinFang,DingfuZhou,FeilongYan,TongtongZhao,Feihu
3dobjectdetectionfromlidarpointcloud. InECCV,pages
Zhang,YuMa,LiangWang,andRuigangYang.Augmented
515–531,2020.
lidarsimulatorforautonomousdriving. RAL,pages1931–
1938,2020. 1 [25] Qinghao Meng, Wenguan Wang, Tianfei Zhou, Jianbing
[10] AndreasGeiger, PhilipLenz, ChristophStiller, andRaquel Shen,YundeJia,andLucVanGool. Towardsaweaklysu-
Urtasun. Vision meets robotics: The kitti dataset. IJRR, pervisedframeworkfor3dpointcloudobjectdetectionand
pages1231–1237,2013. 2,5,6 annotation. TPAMI,2021. 1
[11] YuanhuiHuang,WenzhaoZheng,YunpengZhang,JieZhou, [26] Jinhyung Park, Chenfeng Xu, Yiyang Zhou, Masayoshi
andJiwenLu. Tri-perspectiveviewforvision-based3dse- Tomizuka,andWeiZhan.Detmatch:Twoteachersarebetter
manticoccupancyprediction. InCVPR,pages9223–9232, than one for joint 2d and 3d semi-supervised object detec-
2023. 1 tion. InECCV,pages370–389,2022. 2
[12] Yuanhui Huang, Wenzhao Zheng, Borui Zhang, Jie Zhou, [27] CharlesRQi,HaoSu,KaichunMo,andLeonidasJGuibas.
andJiwenLu. Selfocc: Self-supervisedvision-based3doc- Pointnet: Deep learning on point sets for 3d classification
cupancyprediction. InCVPR,2024. 1 andsegmentation. InCVPR,pages652–660,2017. 2
[13] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, [28] Yongming Rao, Benlin Liu, Yi Wei, Jiwen Lu, Cho-Jui
JiongYang,andOscarBeijbom. Pointpillars: Fastencoders Hsieh, and Jie Zhou. Randomrooms: unsupervised pre-
for object detection from point clouds. In CVPR, pages training from synthetic shapes and randomized layouts for
12697–12705,2019. 2 3dobjectdetection. InICCV,pages3283–3292,2021. 3
[14] Dong-HyunLeeetal.Pseudo-label:Thesimpleandefficient [29] Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri
semi-supervisedlearningmethodfordeepneuralnetworks. Valpola, and Tapani Raiko. Semi-supervised learning with
InICML,page896,2013. 1,2 laddernetworks. InNeurIPS,page3546–3554,2015. 1,2
[15] Zhaoqi Leng, Shuyang Cheng, Benjamin Caine, Weiyue [30] Zhile Ren and Erik B Sudderth. Three-dimensional object
Wang, Xiao Zhang, Jonathon Shlens, Mingxing Tan, and detectionandlayoutpredictionusingcloudsoforientedgra-
DragomirAnguelov. Pseudoaugment:Learningtouseunla- dients. InCVPR,pages1525–1533,2016. 2
beleddatafordataaugmentationinpointclouds. InECCV, [31] Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen.
pages555–572,2022. 2 Regularizationwithstochastictransformationsandperturba-
[16] Jingyu Li, Zhe Liu, Jinghua Hou, and Dingkang Liang. tionsfordeepsemi-supervisedlearning. InNeurIPS,pages
Dds3d: Dense pseudo-labels with dynamic threshold for 1171–1179,2016. 1,2
11[32] ShaoshuaiShi,ChaoxuGuo,LiJiang,ZheWang,Jianping end semi-supervised object detection with soft teacher. In
Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point- ICCV,pages3060–3069,2021. 1,2,10
voxel feature set abstraction for 3d object detection. In [47] YanYan,YuxingMao,andBoLi. Second:Sparselyembed-
CVPR,pages10529–10538,2020. 2,6,7,10 dedconvolutionaldetection.Sensors,page3337,2018.2,6,
[33] Martin Simony, Stefan Milzy, Karl Amendey, and Horst- 10
Michael Gross. Complex-yolo: An euler-region-proposal [48] Bin Yang, Wenjie Luo, and Raquel Urtasun. Pixor: Real-
forreal-time3dobjectdetectiononpointclouds. InECCV, time3dobjectdetectionfrompointclouds. InCVPR,pages
pages0–0,2018. 2 7652–7660,2018. 2
[34] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao [49] Lei Yang, Xinyu Zhang, Li Wang, Minghan Zhu, Chuang
Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Zhang, and Jun Li. Mix-teaching: A simple, unified and
AlexeyKurakin,andChun-LiangLi.Fixmatch:Simplifying effectivesemi-supervisedlearningframeworkformonocular
semi-supervised learning with consistency and confidence. 3dobjectdetection.arXivpreprintarXiv:2207.04448,2022.
InNeurIPS,pages596–608,2020. 1,2 1,2,10
[35] Kihyuk Sohn, Zizhao Zhang, Chun-Liang Li, Han Zhang, [50] JunboYin,JinFang,DingfuZhou,LiangjunZhang,Cheng-
Chen-YuLee,andTomasPfister. Asimplesemi-supervised Zhong Xu, Jianbing Shen, and Wenguan Wang. Semi-
learning framework for object detection. arXiv preprint supervised 3d object detection with proficient teachers. In
arXiv:2005.04757,2020. 1,2,10 ECCV,pages727–743,2022. 1,2,6,10
[36] Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien [51] TianweiYin,XingyiZhou,andPhilippKrahenbuhl. Center-
Chouard,VijaysaiPatnaik,PaulTsui,JamesGuo,YinZhou, based 3d object detection and tracking. In CVPR, pages
YuningChai,BenjaminCaine,etal.Scalabilityinperception 11784–11793,2021. 2
for autonomous driving: Waymo open dataset. In CVPR, [52] Jiakang Yuan, Bo Zhang, Xiangchao Yan, Botian Shi, Tao
pages2446–2454,2020. 2,5 Chen,YikangLi,andYuQiao. Ad-pt: Autonomousdriving
[37] AnttiTarvainenandHarriValpola. Meanteachersarebetter pre-training with large-scale point cloud dataset. NeurIPS,
role models: Weight-averaged consistency targets improve 2024. 2
semi-supervised deep learning results. In NeurIPS, page [53] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk
1195–1204,2017. 1,2 Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regu-
[38] ChunweiWang,ChaoMa,MingZhu,andXiaokangYang. larizationstrategytotrainstrongclassifierswithlocalizable
Pointaugmenting: Cross-modal augmentation for 3d object features. InICCV,pages6023–6032,2019. 10
detection. InCVPR,pages11794–11803,2021. 10 [54] JinlaiZhang, LyujieChen, BoOuyang, BinbinLiu, Jihong
[39] ChuxinWang,WenfeiYang,andTianzhuZhang. Notevery Zhu,YujinChen,YanmeiMeng,andDanfengWu.Pointcut-
sideisequal: Localizationuncertaintyestimationforsemi- mix: Regularization strategy for point cloud classification.
supervised3dobjectdetection. InCVPR,pages3814–3824, Neurocomputing,2022. 10
2023. 2 [55] NingZhang,YangZhao,ChaoWang,andRonggangWang.
[40] HeWang,YezhenCong,OrLitany,YueGao,andLeonidasJ A real-time semi-supervised deep tone mapping network.
Guibas. 3dioumatch: Leveraging iou prediction for semi- TMM,pages2815–2827,2021. 2
supervised 3d object detection. In CVPR, pages 14615– [56] YunpengZhang,WenzhaoZheng,ZhengZhu,GuanHuang,
14624,2021. 1,2,4,5,6,7,9,10 JiwenLu,andJieZhou. Asimplebaselineformulti-camera
[41] Weining Wang, Tianwei Lin, Dongliang He, Fu Li, Shilei 3dobjectdetection. InAAAI,pages3507–3515,2023. 2
Wen,LiangWang,andJingLiu. Semi-supervisedtemporal [57] Na Zhao, Tat-Seng Chua, and Gim Hee Lee. Sess: Self-
actionproposalgenerationviaexploiting2-dproposalmap. ensemblingsemi-supervised3dobjectdetection. InCVPR,
TMM,pages3624–3635,2021. 2 pages11079–11087,2020. 1,2
[42] Yi Wei, Linqing Zhao, Wenzhao Zheng, Zheng Zhu, Jie [58] WenzhaoZheng, JiwenLu, andJieZhou. Hardness-aware
Zhou,andJiwenLu. Surroundocc: Multi-camera3doccu- deepmetriclearning. TPAMI,2020. 2
pancy prediction for autonomous driving. In ICCV, pages [59] WenzhaoZheng,RuiqiSong,XiandaGuo,andLongChen.
21729–21740,2023. 1 Genad: Generative end-to-end autonomous driving. arXiv
[43] XiaopeiWu, YangZhao, LiangPeng, HuaChen, Xiaoshui preprintarXiv:2402.11502,2024. 1
Huang, Binbin Lin, Haifeng Liu, Deng Cai, and Wanli [60] WujieZhou,JunweiWu,JingshengLei,Jenq-NengHwang,
Ouyang. Boostingsemi-supervised3dobjectdetectionwith andLuYu. Salientobjectdetectioninstereoscopic3dim-
semi-sampling. arXivpreprintarXiv:2211.07084,2022. 2 agesusingadeepconvolutionalresidualautoencoder.TMM,
[44] ZhihaoWu,JieWen,YongXu,JianYang,andDavidZhang. pages3388–3399,2020. 1
Multipleinstancedetectionnetworkswithadaptiveinstance [61] YinZhouandOncelTuzel. Voxelnet: End-to-endlearning
refinement. TMM,2021. 1 forpointcloudbased3dobjectdetection. InCVPR,pages
[45] BowenXu,MingtaoChen,WenlongGuan,andLuluHu.Ef- 4490–4499,2018. 2
ficientteacher:Semi-supervisedobjectdetectionforyolov5. [62] Sicheng Zuo, Wenzhao Zheng, Yuanhui Huang, Jie Zhou,
arXivpreprintarXiv:2302.07577,2023. 1,2,10 and Jiwen Lu. Pointocc: Cylindrical tri-perspective view
[46] MengdeXu,ZhengZhang,HanHu,JianfengWang,Lijuan for point-based 3d semantic occupancy prediction. arXiv
Wang,FangyunWei,XiangBai,andZichengLiu. End-to- preprintarXiv:2308.16896,2023. 1
12