Conditioning on Time is All You Need
for Synthetic Survival Data Generation
Mohd Ashhad1 RicardoHenao1,2
1BESE,KAUST,KSA
2B&B,DukeUniversity,USA
mohammad.ashhad@kaust.edu.sa
ricardo.henao@{kaust.edu.sa,duke.edu}
Abstract
Syntheticdatagenerationholdsconsiderablepromise,offeringavenuestoenhance
privacy,fairness,anddataaccessibility. Despitetheavailabilityofvariousmethods
forgeneratingsynthetictabulardata,challengespersist,particularlyinspecialized
applicationssuchassurvivalanalysis. Onesignificantobstacleinsurvivaldata
generation is censoring, which manifests as not knowing the precise timing of
observed(target)eventsforcertaininstances. Existingmethodsfacedifficulties
inaccuratelyreproducingtherealdistributionofeventtimesforbothobserved
(uncensored)eventsandcensoredevents,i.e.,thegeneratedevent-timedistributions
donotaccuratelymatchtheunderlyingdistributionsoftherealdata. Somotivated,
weproposeasimpleparadigmtoproducesyntheticsurvivaldatabygenerating
covariatesconditionedoneventtimes(andcensoringindicators),thusallowing
onetoreuseexistingconditionalgenerativemodelsfortabulardatawithoutsignifi-
cantcomputationaloverhead,andwithoutmakingassumptionsaboutthe(usually
unknown)generationmechanismunderlyingcensoring. Weevaluatethismethod
viaextensiveexperimentsonreal-worlddatasets. Ourmethodologyoutperforms
multiplecompetitivebaselinesatgeneratingsurvivaldata, whileimprovingthe
performanceofdownstreamsurvivalmodelstrainedonitandtestedonrealdata.
1 Introduction
Syntheticdatagenerationistheprocessofcreatingartificialdatathatmimicsthestatisticalproperties
andpatternsofreal-worlddata. Thistechniquehasgainedsignificantimportanceinvariousmachine
learningsettingsincludingdataprivacyanddataaugmentation[23]. Theprimarymotivationbehind
syntheticdatagenerationistoaddresschallengesassociatedwithlimitedavailability,privacyconcerns,
orimbalanceindistributionsoftenprevalentinreal-worlddata[49,45]. Forinstance,researchers,
practitioners and organizations could train and evaluate machine learning models by leveraging
syntheticdatawithoutcompromisingsensitiveorproprietaryinformation. Further,syntheticdatacan
augmentexistingdatasets,enablingmorerobustandgeneralizedmodelperformance. Alternatively,it
canprotectdataprivacybyprovidingameanstoshareandexchangedatawithoutrevealingsensitive
information,facilitatingcollaborationandresearchacrossdifferentdomains[13].
Survivalanalysis,alsoknownastime-to-eventanalysis,isafamilyofstatisticalmethodsusedto
analyzeandmodelthetimeuntiltheoccurrenceofaspecificevent(oroutcome)ofinterest. These
methodsarewidelyemployedinvariousfields,includingbiomedicalresearch,operationsresearch,
engineering,economics,andsocialsciences[26,33,12,18]. Forinstance,assessingtheeffectiveness
of medical treatments [42], predicting equipment failure rates [14], or analyzing customer churn
in the business domain [12]. The primary goal of survival analysis is to estimate the probability
(distribution)ofaneventoccurringovertime,givenasetofcovariatesorriskfactors. Oneofthe
key challenges in survival analysis involves dealing with censored data, which occurs when the
Preprint.Underreview.
4202
yaM
72
]LM.tats[
1v33371.5042:viXraFigure1: Blockdiagramoftheproposedmethodology.First,aconditionaltabulardatageneratoristrainedto
learntosamplecovariatesfromp(x|t,e).Aftertraining,botheventtimest˜,andtypee˜,aresampledfromtheir
jointdistributionviap(t|e)andp(e)usingtheirempiricaldistributionsandpassedintothetrainedgenerator
alongwithu∼p(u),wherep(u)isasimpledistribution.Thegeneratorthenrepeatedlygeneratesthesynthetic
covariatesthuscompletingthesyntheticdatasetD={(x˜,t˜,e˜)}N .
n=1
eventofinterestisnotprecisely,butonlypartially,observedforsomeindividualswithinthestudy
period. Thiscanhappenduetovariousreasons,suchaslosstofollow-up,measurementfailure,study
termination, ortheoccurrenceofcompetingrisks[40]. Handlingcensoreddatarequirestailored
statisticalmethodstoavoidbiasedsurvivalestimates. Anotherchallengeisthatoftentimes,sample
sizesinsurvivaldataarerelativelysmall,ortheproportionofobservedeventsrelativetothosewith
censoringissmall,thuscausingoverfittingissueswhichnegativelyimpactgeneralizationability.
Inmostdomains,suchasclinicaltrialsorengineeringstudies,collectinglargeamountsofsurvivaldata
canbechallenging,time-consuming,andcostly.Syntheticdatagenerationallowsresearcherstocreate
largedatasetswithdesiredcharacteristics,enablingmorerobustmodelprototyping,development
and evaluation. Synthetic survival data, which is predominantly tabular (or structured), can be
generatedusinggenerativemodelsthatarespecificallydevelopedfortabulardata,e.g.,autoencoders
[47],adversarialgenerators[48],diffusiongenerators[30],andevenlargelanguagemodels(LLMs)
[6]. However,apartfromthewell-knownchallengesassociatedwithgeneratingtabulardatasuch
asappropriatelyhandlingcategoricalandcontinuousdata,mixeddatatypes,aswellastheirjoint
distributions[47], survivaldatageneration, especiallyinthemedicaldomain, facessomeunique
challenges. Theseareduetomainlyunavoidabledifferencesinthedistributionsforobservedand
censoredevents, andtheir(unknown)underlyinggenerationmechanismgiventhecovariates. In
practicethischallengecausesmismatchesbetweenthesedistributionswhencomparingreal-world
andsyntheticdatageneratedfromit[36]. Consequently,suchmismatchesarelikelytocausesurvival
modelstrainedonsuchsyntheticdatatounderperformrelativetothereal-worlddataintermsof
discriminationandcalibration. Somotivated,ourworkoffersthefollowingcontributions:
• Weproposeasimplemethodologyforgeneratingsurvivaldatabyconditioningthegenerationof
covariatesontheeventtimesandcensoringindicatorsaftersamplingthesefromtheempiricalreal-
worlddatadistributionsasshowninFigure1,thusi)readilyresultinginmatchingobservedand
censoringdistributions;andii)allowingtheusertochoosefromexistingmethodsforconditional
generationoftabulardatawithoutcomputationaloverhead.
• We show that our generator-agnostic methodology can be easily extended to use LLM-based
tabulardatageneratorsforthegenerationofhigh-qualitysyntheticsurvivaldata,anapplication
thattothebestofourknowledgehasnotbeenexploredsofar.
• Extensiveexperimentsonfivereal-worldsurvivalanalysisdatasetsdemonstratethecapabilities
oftheproposedmethodologyintermsofthequalityofthegeneratedobserved,censoredand
covariate distributions, as well as the discrimination and calibration performance of survival
analysismodelstrainedonsyntheticdataandevaluatedonreal-worlddata.
2 RelatedWork
Generative models have emerged as powerful tools for synthesizing realistic data across various
domains,includingimages,text,andtabulardata. Thesemodelsaimtolearntheunderlyingproba-
2bilitydistributionsofthetrainingdataandgeneratenewsamplesthatexhibitsimilarcharacteristics.
Threeprominentclassesofgenerativemodelshavegainedsignificanttraction: generativeadversarial
networks(GANs),variationalautoencoders(VAEs),anddiffusion-basedmodels. GANsemployan
adversarialtrainingparadigm,whereageneratornetworklearnstoproducesyntheticdatasamples,
whileadiscriminatornetworkaimstodistinguishbetweenrealandgeneratedsamples[17]. This
adversarialtrainingprocessdrivesthegeneratortoproduceincreasinglyrealisticsamples. VAEs,on
theotherhand,leveragevariationalinferencetechniquestolearnalatentrepresentationofthedata,en-
ablingthegenerationofnewsamplesbysamplingfromthelearnedlatentspace[28]. Diffusion-based
models,suchasthedenoisingdiffusionprobabilisticmodel(DDPM)[21],adoptadifferentapproach
bygraduallyaddingnoisetothedataandthenlearningtoreversethisprocess,effectivelygenerating
newsamplesbydenoisingrandomlysampledpoints. Thesegenerativemodelshavedemonstrated
remarkablesuccessinvariousapplications,includingimagesynthesis[24],textgeneration[43],and
videogeneration[22]. Beyonddatasynthesis,generativemodelshavealsobeenusedinsurvival
analysis. TheDATEmodelin[8]utilizesadversarialtrainingtoestimatethedistributionsofevent
timesandcensoringinanon-parametricfashionwhileconditioningoncovariates. Further,[50]takes
anon-parametricapproachtoestimateconditionalsurvivalandhazardfunctionsusingaconditional
generatortolearnthejointdistributionofobservedtimeandcensoringindicatorgiventhecovariates.
Tabulardatastandsoutasaprevalentdataformatinmachinelearning(ML),withmorethan65%of
datasetsfoundintheGoogleDatasetSearchplatform1comprisingtabularfiles,typicallyincomma-
separatedorspreadsheetformats[5]. Conventionalimplementationsofgenerativemethodsarenot
optimallytailoredfortabulardataprimarilybecauseofthemixtureofcontinuousandcategorical
variables[47].However,modifiedversionshavebeensuggestedspecificallytailoredtooperatewithin
thetabulardomain. Oneofthewidelyusedmodelsfortabulardatagenerationistheconditional
tabular generative adversarial network (CTGAN) [47], which leverages the GAN framework to
generatesyntheticdatathatpreservesthemultivariatedistributionsandrelationshipspresentinthe
originaldata. Thisisachievedwithatabularencodingwhichusesamode-specificnormalization
for continuous variables using a variational Gaussian mixture model and training by sampling.
The tabular variational autoencoder (TVAE) is a model that utilizes a variational autoencoder
architecturetogeneratesynthetictabulardata[47]. Anothermodel, anonymizationthroughdata
synthesisusinggenerativeadversarialnetwork(ADS-GAN),extendsCTGANbyintroducingan
auxiliary discriminator to improve the quality of the generated data and preserve the privacy of
theoriginaldata[48]. Thetabulardenoisingdiffusionprobabilisticmodel(TabDDPM)isarecent
approachthatleveragesdenoisingdiffusionprobabilisticmodelstogeneratehigh-fidelitysynthetic
tabulardata[30].Thismodelhasshownpromisingresultsincapturingcomplexdatadistributionsand
handlingmixeddatatypes. Further,largelanguagemodels(LLMs)haverecentlyshownpromising
potentialfortabulardatageneration,leveragingtheirabilitytolearnandmodelcomplexdistributions
fromunstructuredtextdata. Oneapproachinvolvesfine-tuningLLMsontabulardatarepresentedas
sequencesoftokens,enablingthemodeltolearntheunderlyingpatternsandrelationshipswithinthe
data. Duringgeneration,theLLMcanthengeneratenewtokensequencesthatcanbeparsedand
transformedintotabularformat,effectivelyproducingsynthetictabulardatasamples[6].
Onlyafewworksexistintherealmofsyntheticsurvivaldatageneration.Earlystatisticalmodels,such
asthosepresentedin[3]and[1],transformedsamplesfromauniformdistributionintosurvivaltimes
byinvertingthecumulativehazardfunction,conditionedonthecovariates. However,thesemodels
donotgeneratethecovariatesthemselves,limitingtheirapplicabilityincreatingcompletesynthetic
survivaldatasets. Morerecenttechniqueshaveincorporateddeeplearningintothegenerativeprocess.
[39]proposedusingdeepexponentialfamiliestogeneratesurvivaldata, butthisapproachlimits
theflexibilityofthelearneddistribution. [34]and[50]relaxedthisassumptionbutstillfocusedon
generatingsurvivaltimesandcensoringstatusesconditionedonthecovariates,ratherthangenerating
thecovariatesthemselves. Morerecently,aspecializedapproachforsurvivaldatagenerationwas
developed[36]. Theapproach,whichtheycallSurvivalGAN,generatessyntheticdatainthreesteps:
i)aconditionalGAN(ADS-GAN)isusedtogeneratethecovariates(x)andtheeventindicator(e)is
sampledfromtheempiricaldistribution,i.e.,accordingtothetrainingdatafrequency;ii)asurvival
functionmodel(DeepHit[31])istrainedtopredictsurvivalfunctionsforthegeneratedcovariates;
andiii)thegeneratedcovariates,eventindicatorandoutputofthesurvivalfunctionarethenusedas
aninputtoaregressionmodel(XGboost[9])tofinallypredicttheeventtime(t),thusgenerating
thecompletetriplet(x,t,e). Thismethodwhileeffective,iscomplexandrequiresdifferentmodels
1https://datasetsearch.research.google.com/.
3whichareeachsusceptibletotheirownassumptionsandlimitations. Alternatively,ourworkexplores
amuchsimplermethodthatadoptsexistingtabulardatageneratorsforsurvivaldatawithouttheneed
fordedicatednetworksforthepredictionofthesurvivalfunctionorevent/censoringdistributions.
3 Methods
Problem definition Instances (or subjects) from survival data can be represented in general as
thetripletz = (x,t,e). Here, x ∈ X denotesm-dimensionaltabularcovariatesthatdescribean
instance’sstateataninitial(orindex)time,encompassingbothcontinuousandcategoricalcovariates.
Then, t ∈ T represents the time of a specific event relative to the initial time, thus t ≥ 0 and
i
T ≡R . Lastly,e ∈E standsfortheeventindicator,commonlyE ={0,1},wheree=1indicates
+ i
theeventofinterestoccursattimet,wherease=0signifiestheeventofinteresthasnotoccurredup
totimet. Inthisworkweonlyconsiderrightcensoringasitisthepredominantforminreal-world
datasets,however,theproposedmethodcanbereadilyextendedtoleftorintervalcensoring.
Background Survivalanalysisisastatisticalframeworkusedtoanalyzeandmodelthetimeuntilthe
occurrenceoftheeventofinterest,alsoknownasthesurvivaltimeortime-to-event. Survivalanalysis
involvesmodelingtheconditionalprobabilitydensityfunctionp(t|x),toestimatethelikelihoodof
theeventofinterestoccurringattimetgiventhecovariatesx. Fromthis,thesurvivalfunctionis
derived,representingtheprobabilitythattheeventhasnottakenplacebytimet,i.e.,
(cid:90) ∞
S(t|x)= p(t′ |x)dt′, (1)
t
whereS(t|x)isanestimateoftheproportionofinstances(subjects)withcovariatesxwhohave
survived up to time t. When the initial time is zero and given that events cannot occur at t ≤ 0,
thusS(0|x)=1. Additionally,sincep(t|x)isavalidprobabilitydistribution(non-negative),then
S(t|x)isamonotonicallydecreasingfunction. Time-to-eventapproximationinvolvesestimatingthe
expectedlifetimeforanygivencovariatevalue,denotedasµ(x). Specifically,thisisobtainedas
µ(x)=(cid:82)∞ t′p(t′|x)dt′,which,throughintegrationbyparts,simplifiestotheareaunderthesurvival
0
(cid:82)∞
curve: µ(x)= S(t|x)dt. Survivalmodelstypicallyfallintooneoftwocategories: i)parametric
0
suchastheacceleratedfailuretime[46],andlog-logistic[37]models;orii)non-parametricsuchas
theKaplan-Meierestimator[25]andCoxproportionalhazardsmodel[10]. Moreover,deep-learning
versionsofthesehavebeenproposed,e.g.,DeepSurv[27],DeepHit[31],DATE[8],etc.
3.1 ConditioningonEventTimeandType
Synthetic survival data generation involves the generation of samples from the complete joint
distribution p(x,t,e). In practice, one can either sample from it directly (and unconditionally)
usinggenerativemodelsfortabulardata,orviaconditioningusingforinstancep(t|x,e)p(x)p(e)
orp(x|t,e)p(t|e)p(e). Theformeristheapproachusedin[36],whichsamplesx˜ande˜,fromthe
marginals p(x) and p(e), are obtained using a conditional GAN (ADS-GAN) generator and the
empiricaldistributionfortheeventindicators,respectively,andsubsequently,samplest˜fromthe
conditional p(t|x,e) are generated (deterministically) using a regression model. One important
drawbackofthisapproachisthatthequalityofthesamplesforeventtimest˜fromp(t|x,e)isboth
dependentonthequalityoftheapproximationt˜∼p (t|x,e)(withparametersϕ)andthatofp(x)
ϕ
viax˜ ∼p (x|u)parameterizedbyψ,andubeingsampledfromasimpledistribution,e.g.,uniform
ψ
orGaussian. Asaresult,approximationerrorincovariatesxcompoundswiththatfortresultingin
eventandcensoringdistributionsthatdonotnecessarilymatchtherealdata. Inrecognitionofthis,
[36]alsoproposedmetricstoquantifythequalityofthesedistributions(seeSection4).
Inanefforttoalleviatethesekeyissue,wereversetheconditioningandinsteadsamplebothevent
timesandtypefromtheirjointdistributionviap(t|e)andp(e),usingtheirempiricaldistributions.
Notethatthisispossiblebyassumingwithoutlossofgeneralitythatt⊥⊥e|x. Then,wesamplethe
covariatesfromp(x|t,e)usingaconditionalgeneratorasfollows
e˜∼p(e), t˜∼p(t|e˜), u∼p(u), x˜ ∼p (x|t˜,e˜,u), (2)
θ
wherep (x|t˜,e˜,u)isaconditionalgeneratorparameterizedbyθ,whilep(u)isasimpledistribution.
θ
Repeatedly sampling from the mechanism in (2) allows one to obtain a synthetic dataset D =
4{(x ,t ,e )}N whose empirical conditionals for event and censoring times readily match the
n n n n=1
ground-truth distributions, p(t|e = 1) and p(t|e = 0), respectively, and synthetic covariates that
acknowledgetheirassociationwiththeeventofinterestwhileaccountingforcensoring. Importantly,
using(2): i)eliminatestheneedforaseparatemodeltogenerateeventtimes(XGboostin[36]);ii)
eliminatestheneedforaseparatemodeltogeneratesurvivaldistributions(DeepHitin[36]),and
iii)guaranteesthequalityoftheobservedandcensoredeventdistributions. Moreover,andfrom
apracticalperspective,(2)offersflexibilitysincep (x|t˜,e˜,u)canbemodeled,inprinciple,with
θ
anyconditionalgenerator. Intheexperiments(seeSection4), wewillconsiderTVAE,CTGAN,
ADS-GAN,TabDDPMandLLMs. Notethatin(2)wearenotrequiredtosamplefromtheempirical
distributions for p(t) and p(e), for instance one may alternatively fit univariate (kernel) density
estimatorsandthendrawt˜ande˜accordingly.
3.2 AdaptingConditionalTabularGeneratorstoSurvivalData
Existingtabulargenerators(seeSection2)usedistinctstrategiestoimplementconditioning. Below
webrieflydescribehowtheyareadaptedtotheconsideredsurvivaldatagenerationproblem.
CTGAN Thismodelbeingaconditionaladversarialgenerator, synthesizesdatausingG(u,c),
where G(·) is the generator specified as a neural network, u is a vector sampled from a simple
distribution, e.g., a standard Gaussian distribution, e.g., u ∼ N(0,I), and c is a one-hot vector
representingadiscreteconditioningcovariate. See[47]foradditionaldetails. InordertouseG(u,c)
asasamplingmechanismforp (x|t˜,e˜,u)in(2)wesimplysetc = E (t˜)⊕e˜,whereE (·)isan
θ t t
m-dimensional sinusoidal time embedding [44] and ⊕ is the concatenation operator. In all our
experimentswesetm=4.
TVAE Theautoencodingformulationin[47]doesnotspecifyexplicitlyhowtoperformconditional
generation for the tabular VAE. However, the simplest strategy involves setting the encoder and
decoderpairasu∼N(µ(x),σ2(x))andx˜ ∼p (x|c,u),respectively,wherehereuisthelatent
θ
representationforcovariatesx,µ(x)andσ2(x)aretwoneuralnetworksforthemeanandvariance
functionsofthelatentrepresentationu,p (x|c,u)isaprobabilisticdecoderspecifiedusingneural
θ
networks(see[47]fordetails),cisaone-hotvectorasaboveforCTGAN,andtheinputtothedecoder
convenientlyimplementedbyconcatenatingzandc. SimilartoCTGAN,wemakec=E (t˜)⊕e˜in
t
ourimplementationtosamplefromp (x|t˜,e˜,u)in(2)viap (x|c=E (t˜)⊕e˜,u).
θ θ t
ADS-GAN Thisalternativeadversarialmodelspecificationencouragesde-identifiabilitybyletting
thegeneratorbex˜ =G(u,x,c),i.e.,covariatesxarealsousedasinputstothegenerationfunction
G(·),toencouragethemodeltogeneratesamplesx˜thataredistinctfromxtopreserveprivacy. See
[48]foradditionaldetails. ConsistentwithCTGANandTVAEabove,wesimplysetc=E (t˜)⊕e˜.
t
TabDDPM ThismodeldesignedspecificallyfortabulardataemploysacombinationofGaussian
and multinomial diffusion processes to handle numerical and categorical features, respectively.
Notably,eachcovariateusesaseparateforwarddiffusionprocesses. Thereversediffusionfunctionin
[30]issetasx =g (x ,x ,s),whereg (·)ismodeledusingneuralnetworkswithidentityand
is i is i0 i
softmaxactivationsforcontinuousanddiscretecovariates,respectively,x =h (x )+h (E (s))+
is x is s t
E (c)istherepresentationofthei-thcovariateinxatdiffusionsteps,h (x )isafullyconnected
c x i
layerwithlinearactivation, h (·)iscomposedoftwofullyconnectedlayerswithsigmoidlinear
s
activations, E (·)isastandard(trainable)categoricalembedding, ands = 0,...,S, issuchthat
c
x ∼N(0,I)orx ∼Cat(1/K ),forK categories(distinctvalues),forcontinuousordiscrete
iS iS i i
covariates,respectively. Notethateffectively,g (·)modelstheresidualsofx atdiffusionsteps
i is
ratherthanx itself[35]. Foradditionaldetailsoftheformulationandandcomponentsofthemodel
is
architecturesee[30]. Forourimplementation,wesetc = E (t˜)+E (e˜)andsetm = 128asthe
t s
embeddingdimension.
4 Experiments
Baselinesandsetup Wecompareourmethodologyagainstthefollowingbaselines: generative
adversarialnetworksforanonymization(ADS-GAN)[48];conditionalgenerativeadversarialnet-
worksfortabulardata(CTGAN)[47];variationalautoencoderfortabulardata(TVAE)[47];tabular
5denoisingdiffusionprobabilisticmodels(TabDDPM)[30];andSurvivalGAN[36]. Notethatonly
thelatterisspecifictosurvivaldata,whereasalltheothersgeneratetabulardataunconditionally,
i.e.,fromthejointp(x,t,e). ForCTGAN,TVAE,ADS-GAN,andTabDDPMmodels,wereport
metricsbothdirectlyusingthemodelsforsurvivaldatagenerationaswellasourmethodology,i.e.,
usingthemasconditionalgeneratorsgiveneventtimesandcensoringindicatorssampledfromthe
empiricaldistributionoftherealdataasdescribedinSection3.2. Togaugedownstreamperformance,
acollectionofsurvivalmodelsaretrainedonthesyntheticdataandevaluatedonrealdata,employing
theTrainonSyntheticTestonReal(TSTR)paradigm[16]. Weconsidervariouscategories,namely
linearmodels(CoxPH)[10],gradientboosting(SurvivalXGBoost)[2],andneuralnetworks(Deep-
Hit) [31]. Performance evaluation utilizes 3-fold cross-validation on real data and we report the
metricsonlyforthebest-performingsurvivalmodel. Foreachdataset(describedbelow),benchmark,
andexperimentalsetting,themeanandstandarddeviationoftheperformancemetricsarereported
using5differentrandomseeds. Tostreamlinethebenchmarking,weutilizedtheSynthcitylibrary
[38],whichprovidesimplementationsofavarietyofsynthetictabulardatagenerationmodelsand
benchmarkingutilities. Comprehensivedetailsoftheexperimentalsettingsandhyperparametersused
arepresentedinAppendixB.3. Thesourcecodeforreproducingallexperimentscanbefoundat
https://github.com/anonymous-785/synthetic_survival_data.
Datasets Webenchmarkourmethodologyonavarietyofreal-worldmedicaldatasets. Specifically:
i)Studytounderstandprognosespreferencesoutcomesandrisksoftreatment(SUPPORT)[29];ii)
Moleculartaxonomyofbreastcancerinternationalconsortium(METABRIC)[11];iii)ACTG320
clinicaltrialdataset(AIDS)[19];iv)Rotterdam&Germanbreastcancerstudygroup(GBSG)[41];
andv)Assayofserumfreelightchain(FLCHAIN)[15]. SeeAppendixB.2foradditionaldetails.
Metrics Toevaluatethequalityofthegeneratedsyntheticsurvivaldata,variousmetricsareem-
ployed,whichcanbecategorizedintothreegroups:covariatesquality,event-timedistributionquality,
anddownstreamperformance. Forassessingthequalityofthegeneratedcovariatesx˜,theJensen-
Shannon(JS)distanceandWassersteindistance(WS)areusedtomeasurethedivergencebetweenthe
generatedandoriginalcovariatedistributions.Wealsomeasurethedifferencesbetweenthecovariates
inanunivariatefashionusinghypothesistesting,namely,Wilcoxonrank-sumandChisquaredtests
forcontinuousanddiscretecovariatesrespectively,andthensummarizetheobtainedp-valuesforall
covariatesastheproportion(PVP)belowthestandardsignificancethresholdα=0.05aftercorrec-
tionformultipletestingviaBenjamini-Hochberg[4]. Forthequalityoftheeventtimedistributions
wequantifythealignmentbetweenground-truthandgeneratedtemporalmarginals,namely,p(t,e)
isevaluatedusingtheKaplan-Meier(KM)divergence,optimism,andshort-sightednessmetricsas
previouslydescribedin[36]. TheKMdivergencecomparesthemeanabsolutedifferencebetween
thesyntheticandrealsurvivalfunctionestimates,whileoptimismandshort-sightednessareaproxy
fortheirbiasandvariance,respectively. Thesethreemetricscapturetheaccuracyofthegenerated
censoringandeventdistributions. Finally,toassessdownstreamperformance,survivalmodelsare
trainedonthesyntheticdataandevaluatedonrealdataset. Specifically,weconsidertheconcordance
index(C-index)[20]andtheBrierscore[7]. Theformermeasuresthediscriminativeabilityofthe
survivalmodel,whilethelatterquantifiesthecalibrationoftheprobabilisticpredictions.
4.1 SyntheticSurvivalDataGenerationBenchmark
Covariatequalitymetrics: ResultsinTable1comparethesimilaritybetweenthedistributionof
syntheticsamplesandtheoriginaldata. First, weassesstheoverall(covariance)structureofthe
synthetic covariates relative to the original data via the JS and WS distances. Then, we perform
hypothesistestingtocomparethe(univariate)marginaldistributionsofeachcovariaterelativeto
theoriginaldata. Specifically,weuseWilcoxonrank-sumandChisquaredtestsforcontinuousand
discretecovariates,respectively,asdescribedabove. Importantly,sincewesamplet˜andE˜ directly
fromtheempirical(training)distributionsitisclearthatthesyntheticandoriginaldistributionsfor
eventtimesaccountingforcensoringmatch,thuswedonotreportKMdivergence,optimismand
short-sightednessinTable1,however,theyarereportedinAppendixCforcompleteness. Weobserve
that the models trained using the proposed methodology outperform the baseline models across
alldatasetsintermsoftheJSandWSdistances. Notably,PVPforourmodelsiseitherbetteror
comparabletothebaselines. InFigure2,wedirectlycomparethedistributionofp-valuesforthe
best-performingconditionalmodelwiththatofthebestunconditionalmodelforagivendatasetusing
quantile-quantile(Q-Q)plots. Weobservethatourmethodologyleadstobetterp-valuedistributions,
6Table1: Quality(JSDistance,WSDistance,andPVP)anddownstream(C-IndexandBrierScore)metrics.
ModelsconditioningontandE arehighlighted(†),UMreferstothebest-performingunconditionalmodel
amongTVAE,TabDDPM,CTGANandADS-GAN,andOriginalisforthesurvivalmodeltrainedonthereal
(training)data.Errorbarsarestandarddeviationsfor5repetitions.
Metric Method AIDS METABRIC SUPPORT GBSG FLCHAIN
SurvivalGAN 0.013±0.00 0.009±0.00 0.008±0.00 0.008±0.00 0.009±0.00
TVAE† 0.007±0.00 0.008±0.00 0.004±0.00 0.005±0.00 0.002±0.00
TabDDPM† 0.007±0.00 0.007±0.00 0.013±0.00 0.005±0.00 0.001±0.00
JSdistance(↓)
CTGAN† 0.013±0.00 0.020±0.01 0.005±0.00 0.003±0.00 0.004±0.00
ADS-GAN† 0.006±0.00 0.009±0.00 0.005±0.00 0.004±0.00 0.010±0.01
UM 0.006±0.00 0.007±0.00 0.005±0.00 0.005±0.00 0.002±0.00
SurvivalGAN 0.112±0.01 0.039±0.00 0.043±0.00 0.019±0.00 0.052±0.00
TVAE† 0.061±0.00 0.028±0.00 0.032±0.00 0.013±0.00 0.016±0.00
TabDDPM† 0.159±0.02 0.089±0.00 0.308±0.02 0.056±0.00 0.028±0.00
WSdistance(↓)
CTGAN† 0.095±0.00 0.133±0.01 0.034±0.00 0.013±0.00 0.019±0.00
ADS-GAN† 0.082±0.00 0.037±0.00 0.036±0.00 0.011±0.00 0.018±0.00
UM 0.069±0.00 0.031±0.00 0.036±0.00 0.013±0.00 0.016±0.00
SurvivalGAN 0.181±0.00 0.555±0.00 0.571±0.00 0.485±0.00 0.555±0.00
TVAE† 0.090±0.00 0.444±0.00 0.457±0.06 0.142±0.00 0.222±0.04
TabDDPM† 0.181±0.06 0.222±0.00 0.528±0.03 0.199±0.07 0.222±0.04
PVP(↓)
CTGAN† 0.272±0.00 0.555±0.00 0.428±0.00 0.571±0.00 0.511±0.06
ADS-GAN† 0.309±0.04 0.555±0.00 0.600±0.03 0.428±0.00 0.422±0.04
UM 0.096±0.04 0.000±0.00 0.171±0.08 0.200±0.00 0.244±0.00
SurvivalGAN 0.735±0.00 0.625±0.00 0.602±0.00 0.668±0.00 0.870±0.00
TVAE† 0.737±0.00 0.612±0.00 0.583±0.00 0.672±0.00 0.872±0.00
TabDDPM† 0.660±0.07 0.589±0.01 0.536±0.00 0.663±0.00 0.876±0.00
C-Index(↑) CTGAN† 0.746±0.00 0.628±0.01 0.577±0.00 0.665±0.01 0.874±0.00
ADS-GAN† 0.797±0.01 0.655±0.00 0.623±0.00 0.684±0.00 0.880±0.00
UM 0.779±0.00 0.649±0.00 0.625±0.00 0.679±0.00 0.879±0.00
Original 0.760±0.00 0.636±0.00 0.616±0.00 0.695±0.00 0.870±0.00
SurvivalGAN 0.068±0.00 0.205±0.00 0.202±0.00 0.212±0.00 0.096±0.00
TVAE† 0.059±0.00 0.199±0.00 0.207±0.00 0.214±0.00 0.095±0.00
TabDDPM† 0.063±0.00 0.212±0.00 0.217±0.00 0.215±0.00 0.096±0.00
BrierScore(↓) CTGAN† 0.061±0.00 0.199±0.00 0.205±0.00 0.215±0.01 0.089±0.00
ADS-GAN† 0.059±0.00 0.197±0.00 0.198±0.00 0.213±0.00 0.084±0.00
UM 0.060±0.00 0.200±0.00 0.199±0.00 0.207±0.00 0.086±0.00
Original 0.062±0.00 0.200±0.00 0.195±0.00 0.205±0.00 0.095±0.00
i.e.,oursyntheticdatasetsaremoreconsistentwiththenull(uniform)p-valuedistribution. Inthe
casewhereourmethodologyunderperformsshowninFigure2b,theperformanceisnotsubstantially
worsethanthebaseline(unconditional)TabDDPMmodel. FullresultsareshowninAppendixC.
(a)AIDS (b)METABRIC (c)FLCHAIN
Figure2: Q-Qplotscomparingthep-valuedistributionsofthebest-performingconditionalmodel(†)withthat
ofthebestunconditionalmodel(UM).Thedashedlinerepresentstheexpected(uniform)distribution.
Downstream Performance We conduct a comparative analysis of survival models trained with
syntheticdatageneratedbyourmethodologyagainstmodelstrainedwithdatafrombaselinemethods.
7(d)
(a)
(b) (e)
(f)
(c)
Figure3: TrainingandsamplingprocedureforsurvivaldatagenerationusingLLMs.
Table 2: Quality(JSdistance,WSdistanceandPVP)anddownstream(C-IndexandBrierScore)metrics.
ModelsconditioningontandEarehighlighted(†).BMreferstothebest-performingmodelfromTable1.
Dataset Method C-Index BrierScore JSdistance WSDistance PVP
SurvivalGAN 0.735±0.00 0.068±0.01 0.013±0.00 0.12±0.00 0.181±0.00
GReaT† 0.790±0.00 0.063±0.00 0.003±0.00 0.036±0.00 0.000±0.00
AIDS
GReaT 0.725±0.01 0.063±0.00 0.004±0.00 0.046±0.00 0.090±0.00
BM 0.797±0.01 0.059±0.00 0.006±0.00 0.061±0.00 0.090±0.00
SurvivalGAN 0.870±0.00 0.096±0.00 0.009±0.00 0.052±0.00 0.555±0.00
GReaT† 0.880±0.00 0.082±0.00 0.001±0.00 0.015±0.00 0.111±0.00
FLCHAIN
GReaT 0.878±0.00 0.090±0.00 0.001±0.00 0.020±0.00 0.222±0.00
BM 0.880±0.00 0.084±0.00 0.001±0.00 0.016±0.00 0.222±0.04
Afavorableoutcomeisachievedwhenamodeltrainedwithsyntheticdataperformscomparablytoor
occasionallyevenbetterthanamodeltrainedwithrealdata,whilealsooutperformingmodelstrained
withalternativesyntheticdatasources. Forreference,wealsoreporttheC-IndexandBrierScore
forsurvivalmodelstrainedontheoriginaldata. ResultsinTable1demonstratethattheproposed
methodologyachieveseithernoticeablybetterorcomparableperformancerelativetothebaseline
methodsbothintermsofdiscriminationandcalibration. Further,inmostcases,wewerealsoableto
achievebetterperformancethansurvivalmodelstrainedontheoriginaldata.
4.2 FineTuninganLLMforSurvivalDataGeneration
Generationofrealistictabulardata(GReaT)isarecentlyproposedapproachtogeneratinghigh-quality
synthetictabulardatausingLLMs[6]. Thisisachievedbyrepresentingthetabulardataasasequence
of text and training the language model to generate new sequences that correspond to valid and
plausibletabulardatainstances. WeadaptGReaTtogeneratesyntheticsurvivaldatabyconditioning
the generation on time-to-event and event-type. The fine-tuning of a pre-trained auto-regressive
LLMontheencodedtabulardatafordatagenerationasproposedin[6]involvesthefollowingsteps.
Textualencodingandfeaturepermutation: ThetabulardatawithM columnnames{f }M and
m m=1
thus,M-dimensionalrows{x }N areconvertedintotextualrepresentation. Eachrow(sample)
n n=1
x isencodedasasentencewithelementst = {t }M , wheret = [f ,“is”,x ,“, ”]
n n nm m=1 nm m nm
contains the column name f and its value x . Model training: The LLM is trained using
m nm
DistilGPT2[32]onthetextuallyencodeddataset{t }N ,withelementsoft permutedatrandom
n n=1 n
toremovepseudo-positionalinformationascolumnorderinatabulardatasetisinprinciplenon-
informative. Sampling: Featurepermutationsduringtrainingenablethemodeltostartgeneration
withanycombinationoffeaturesandvalues. Togeneratesyntheticdataconditionally,wepromptthe
trainedmodelwithconditioningsequencessampledfromtheempiricalmarginalp(t,e),andletit
generatetheremainingtokenstocompletethetextualfeaturevector,whichisthenconvertedbackto
tabularformat. Unconditionalgenerationfollows[6]. Thetrainingandsamplingprocedureisshown
inFigure3. Table2comparestheperformanceofGReaTwithandwithoutconditionalgeneration,
againstthebestgeneratorfromTable1(resultsshownfortwodatasets). SeeAppendixCforfull
resultsincludingQ-Qplots. WeobservethatconditionalgenerationconsistentlyenhancesGReaT’s
performanceovertheunconditionalvariantandbaselinegenerators. Further,PVPalsoimproves
significantly, underscoring the effectiveness of the LLM in modeling univariate marginals. Note
howeverthatGReaTismuchmorecostlycomparedtoothermodelsasshowninAppendixB.1.
8Table3: Downstream(C-IndexandBrierScore)performancemetricsforsurvivalmodelstrainedonRealData,
Synthetic,andSynthetic(Balanced).ModelsconditioningontandEarehighlighted(†).
Synthetic Synthetic(Balanced)
Method Race
C-index BrierScore C-index BrierScore
All 0.722±0.01 0.071±0.00 0.745±0.02 0.065±0.01
Race1 0.722±0.00 0.066±0.00 0.729±0.00 0.062±0.00
ADS-GAN†
Race2 0.722±0.00 0.070±0.00 0.729±0.00 0.063±0.00
Race3 0.763±0.01 0.070±0.00 0.758±0.01 0.063±0.00
All 0.663±0.00 0.100±0.02 0.683±0.01 0.076±0.01
Race1 0.663±0.00 0.092±0.00 0.676±0.00 0.072±0.01
SurvivalGAN
Race2 0.663±0.00 0.095±0.01 0.676±0.01 0.073±0.02
Race3 0.668±0.01 0.095±0.01 0.698±0.01 0.073±0.01
RealData
Method Race
C-index BrierScore
All 0.735±0.01 0.075±0.01
Race1 0.724±0.00 0.069±0.00
Original
Race2 0.724±0.00 0.072±0.00
Race3 0.778±0.02 0.072±0.00
4.3 Sub-populationLevelEvaluationofSyntheticData
Inthisexperiment,weevaluatetheperformanceoftheproposedmethodologyatthesub-population
levelusingtheAIDSdataset,usingrace(White,BlackandHispanic)todefinethesub-populations.
Performanceevaluationiscarriedoutviarace-stratifiedK-foldcross-validation.Weconsidersurvival
modelsinthreescenarios: i)trainedontherealdata; ii)trainedonsyntheticdatawiththesame
raceproportionastheoriginaldata(Synthetic);andiii)trainedonsyntheticdatawithbalancedrace
sampleswhilepreservingthedistributionofobservedandcensoredeventsforeachrace(Synthetic
(Balanced)). ForthesurvivalmodelstrainedontheoriginalAIDSdataset,theC-indexdiffersacross
races,withthemodelperformingbetteronHispanic(0.778)whencomparedtoWhite(0.724)and
Black(0.724),witha0.778/0.724≈1.07ratio. Whentrainingusingoursyntheticdata(ADS-GAN
conditionedontimeandevent)withthesamedistributionastheoriginaldata,theC-indexvalues
reflectasimilarperformanceratioof1.06betweenraces. Forthebalanceddistributionscenario,all
performancemetricsimproveattheexpenseofreducingtheperformanceratiobetweenHispanic
and White/Black observed in the original data to 1.04. Further, the proposed model consistently
outperformsSurvivalGAN,whichislessabletocapturetheraceperformancedifferencewithratios
1.01and1.03forSyntheticandSynthetic(Balanced),respectively.
5 Conclusion
Thisworkproposedasimpleyeteffectivemethodologyforgeneratinghigh-qualitysyntheticsurvival
databyconditioningthegenerationofcovariatesontheeventtimesandcensoringindicatorssampled
fromtheempiricaldistributions. Throughextensiveexperimentsonmultiplereal-worlddatasets,we
demonstratedthatourapproachoutperformsseveralcompetitivebaselinesacrossvariousevaluation
metricsassessingthequalityofthegeneratedcovariatedistributions,alignmentwiththeground-truth
eventtimedistributions,aswellasthedownstreamperformanceofsurvivalmodelstrainedonthe
syntheticdata. Moreover,weshowcasedtheapplicabilityofLLMsforsurvivaldatagenerationby
fine-tuningtheminaconditionalmanneronthetextualrepresentationsoftabulardataandhowthe
proposedmethodpreservesthesub-population-levelperformancecharacteristicsofreal-worlddata.
LimitationsDespiteitspromisingresults,ourworkhaslimitations. First,thequalityofthegenerated
dataheavilydependsontherepresentativenessanddiversityoftheoriginaldatasetusedfortraining
thegenerativemodels. Ifthetrainingdataexhibitsbiasesorlackssufficientvariability,theselikely
willpropagatetothesyntheticdata. Second,whileourapproachensuresaccuratereproductionof
theeventtimeandcensoringdistributions,itdoesnotexplicitlyconsidertime-varyingcovariates,
whichmayberelevantincertainapplications. Finally,furtherresearchisneededtoaddressbiasand
equityinsurvivaldata. Thoughweattempttounderstandthebehaviorofsurvivalmodelstrained
onsyntheticdataatasub-populationlevel,weacknowledgethatbiasandequityaremultifaceted
challengesextendingbeyondthescopeofthisstudy. Theseareexcitingavenuesforfurtherresearch.
9References
[1] PeterC.Austin. Generatingsurvivaltimestosimulatecoxproportionalhazardsmodelswithtime-varying
covariates. Statisticsinmedicine,31(29):3946–3958,2012.
[2] AvinashBarnwal,HyunsuCho,andTobyHocking.Survivalregressionwithacceleratedfailuretimemodel
inxgboost. JournalofComputationalandGraphicalStatistics,31(4):1292–1302,2022.
[3] RalfBender,ThomasAugustin,andMariaBlettner.Generatingsurvivaltimestosimulatecoxproportional
hazardsmodels. Statisticsinmedicine,24(11):1713–1723,2005.
[4] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practical and powerful
approachtomultipletesting.JournaloftheRoyalstatisticalsociety:seriesB(Methodological),57(1):289–
300,1995.
[5] OmarBenjelloun,ShiyuChen,andNatashaNoy. Googledatasetsearchbythenumbers. InInternational
SemanticWebConference,pages667–682.Springer,2020.
[6] VadimBorisov, KathrinSeßler, TobiasLeemann, MartinPawelczyk, andGjergjiKasneci. Language
modelsarerealistictabulardatagenerators. arXivpreprintarXiv:2210.06280,2022.
[7] GlennW.Brier. Verificationofforecastsexpressedintermsofprobability. Monthlyweatherreview,
78(1):1–3,1950.
[8] PaidamoyoChapfuwa,ChenyangTao,ChunyuanLi,CourtneyPage,BenjaminGoldstein,LawrenceCarin
Duke,andRicardoHenao. Adversarialtime-to-eventmodeling. InInternationalConferenceonMachine
Learning,pages735–744.PMLR,2018.
[9] TianqiChenandCarlosGuestrin. Xgboost:Ascalabletreeboostingsystem. InProceedingsofthe22nd
acmsigkddinternationalconferenceonknowledgediscoveryanddatamining,pages785–794,2016.
[10] DavidR.Cox. Regressionmodelsandlife-tables. JournaloftheRoyalStatisticalSociety: SeriesB
(Methodological),34(2):187–202,1972.
[11] ChristinaCurtis,SohrabP.Shah,Suet-FeungChin,GulisaTurashvili,OscarM.Rueda,MarkJ.Dunning,
DougSpeed,AndyG.Lynch,ShamithSamarajiwa,andYinyinYuan. Thegenomicandtranscriptomic
architectureof2,000breasttumoursrevealsnovelsubgroups. Nature,486(7403):346–352,2012.
[12] Daniela-EmanuelaDanacicaandAna-GabrielaBabucea. Usingsurvivalanalysisineconomics. survival,
11:15,2010.
[13] JuandeBenedetti,NamirOues,ZhenchenWang,PujaMyles,andAllanTucker. Practicallessonsfrom
generatingsynthetichealthcaredatawithbayesiannetworks.InECMLPKDD2020Workshops:Workshops
oftheEuropeanConferenceonMachineLearningandKnowledgeDiscoveryinDatabases(ECMLPKDD
2020):SoGood2020,PDFL2020,MLCS2020,NFMCP2020,DINA2020,EDML2020,XKDD2020
andINRA2020,Ghent,Belgium,September14–18,2020,Proceedings,pages38–47.Springer,2020.
[14] FranciscoJavierdeCosJuez,P.J.GarcíaNieto,J.MartínezTorres,andJ.TaboadaCastro. Analysisof
leadtimesofmetalliccomponentsintheaerospaceindustrythroughasupportedvectormachinemodel.
Mathematicalandcomputermodelling,52(7-8):1177–1184,2010.
[15] AngelaDispenzieri,JerryA.Katzmann,RobertA.Kyle,DirkR.Larson,TerryM.Therneau,ColinL.
Colby,RaynellJ.Clark,GrahamP.Mead,ShajiKumar,andL.JosephMeltonIII. Useofnonclonalserum
immunoglobulinfreelightchainstopredictoverallsurvivalinthegeneralpopulation. InMayoClinic
Proceedings,volume87,pages517–523.Elsevier,2012.
[16] CristóbalEsteban,StephanieL.Hyland,andGunnarRätsch. Real-valued(medical)timeseriesgeneration
withrecurrentconditionalgans. arXivpreprintarXiv:1706.02633,2017.
[17] IanGoodfellow,JeanPouget-Abadie,MehdiMirza,BingXu,DavidWarde-Farley,SherjilOzair,Aaron
Courville,andYoshuaBengio.Generativeadversarialnetworks.CommunicationsoftheACM,63(11):139–
144,2020.
[18] Samuel R. Gross, Barbara O’brien, Chen Hu, and Edward H. Kennedy. Rate of false conviction of
criminal defendants who are sentenced to death. Proceedings of the National Academy of Sciences,
111(20):7230–7235,2014.
10[19] ScottM.Hammer,KathleenE.Squires,MichaelD.Hughes,JanetM.Grimes,LisaM.Demeter,JudithS.
Currier,JosephJ.EronJr,JudithE.Feinberg,HenryH.BalfourJr,andLawrenceR.Deyton. Acontrolled
trialoftwonucleosideanaloguesplusindinavirinpersonswithhumanimmunodeficiencyvirusinfection
andcd4cellcountsof200percubicmillimeterorless.NewEnglandJournalofMedicine,337(11):725–733,
1997.
[20] FrankE.Harrell,RobertM.Califf,DavidB.Pryor,KerryL.Lee,andRobertA.Rosati. Evaluatingthe
yieldofmedicaltests. Jama,247(18):2543–2546,1982.
[21] JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. Advancesinneural
informationprocessingsystems,33:6840–6851,2020.
[22] YumingJiang,ShuaiYang,TongLiangKoh,WayneWu,ChenChangeLoy,andZiweiLiu.Text2performer:
Text-driven human video generation. In Proceedings of the IEEE/CVF International Conference on
ComputerVision,pages22747–22757,2023.
[23] James Jordon, Lukasz Szpruch, Florimond Houssiau, Mirko Bottarelli, Giovanni Cherubin, Carsten
Maple, Samuel N. Cohen, and Adrian Weller. Synthetic data–what, why and how? arXiv preprint
arXiv:2205.03257,2022.
[24] MingukKang,Jun-YanZhu,RichardZhang,JaesikPark,EliShechtman,SylvainParis,andTaesungPark.
Scalingupgansfortext-to-imagesynthesis. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages10124–10134,2023.
[25] EdwardL.KaplanandPaulMeier. Nonparametricestimationfromincompleteobservations. Journalof
theAmericanstatisticalassociation,53(282):457–481,1958.
[26] AbdeneWeyaKaso,GebiAgero,ZewduHurissa,TahaKaso,HelenAliEwune,HabtamuEndashaw
Hareru,andAlemayehuHailu. Survivalanalysisofcovid-19patientsinethiopia:ahospital-basedstudy.
PLoSOne,17(5):e0268280,2022.
[27] JaredL.Katzman,UriShaham,AlexanderCloninger,JonathanBates,TingtingJiang,andYuvalKluger.
Deepsurv: personalizedtreatmentrecommendersystemusingacoxproportionalhazardsdeepneural
network. BMCmedicalresearchmethodology,18:1–12,2018.
[28] DiederikP.KingmaandMaxWelling. Auto-encodingvariationalbayes. arXivpreprintarXiv:1312.6114,
2013.
[29] WilliamA.Knaus,FrankE.Harrell,JoanneLynn,LeeGoldman,RussellS.Phillips,AlfredF.Connors,
NealV.Dawson,WilliamJ.Fulkerson,RobertM.Califf,andNormanDesbiens. Thesupportprognostic
model:Objectiveestimatesofsurvivalforseriouslyillhospitalizedadults. Annalsofinternalmedicine,
122(3):191–203,1995.
[30] AkimKotelnikov,DmitryBaranchuk,IvanRubachev,andArtemBabenko. Tabddpm:Modellingtabular
data with diffusion models. In International Conference on Machine Learning, pages 17564–17579.
PMLR,2023.
[31] ChangheeLee,WilliamZame,JinsungYoon,andMihaelaVanDerSchaar. Deephit: Adeeplearning
approachtosurvivalanalysiswithcompetingrisks. InProceedingsoftheAAAIconferenceonartificial
intelligence,volume32,2018.
[32] Tianda Li, Yassir El Mesbahi, Ivan Kobyzev, Ahmad Rashid, Atif Mahmud, Nithin Anchuri, Habib
Hajimolahoseini,YangLiu,andMehdiRezagholizadeh. Ashortstudyoncompressingdecoder-based
languagemodels. arXivpreprintarXiv:2110.08460,2021.
[33] ChristianMariusLillelund,FernandoPannullo,MortenOpprudJakobsen,andChristianFischerPedersen.
Predictingsurvivaltimeofballbearingsinthepresenceofcensoring. arXivpreprintarXiv:2309.07188,
2023.
[34] Xenia Miscouridou, Adler Perotte, Noémie Elhadad, and Rajesh Ranganath. Deep survival analysis:
Nonparametricsandmissingness.InMachineLearningforHealthcareConference,pages244–256.PMLR,
2018.
[35] AlexanderQuinnNicholandPrafullaDhariwal. Improveddenoisingdiffusionprobabilisticmodels. In
Internationalconferenceonmachinelearning,pages8162–8171.PMLR,2021.
[36] AlexanderNorcliffe,BogdanCebere,FergusImrie,PietroLio,andMihaelavanderSchaar. Survivalgan:
Generatingtime-to-eventdataforsurvivalanalysis. InInternationalConferenceonArtificialIntelligence
andStatistics,pages10279–10304.PMLR,2023.
11[37] RossL.Prentice. Ageneralizationoftheprobitandlogitmethodsfordoseresponsecurves. Biometrics,
pages761–768,1976.
[38] ZhaozhiQian,RobDavis,andMihaelavanderSchaar. Synthcity:abenchmarkframeworkfordiverseuse
casesoftabularsyntheticdata. AdvancesinNeuralInformationProcessingSystems,36,2024.
[39] RajeshRanganath,AdlerPerotte,NoémieElhadad,andDavidBlei. Deepsurvivalanalysis. InMachine
LearningforHealthcareConference,pages101–114.PMLR,2016.
[40] StephenSalernoandYiLi. High-dimensionalsurvivalanalysis:Methodsandapplications. Annualreview
ofstatisticsanditsapplication,10:25–49,2023.
[41] M.Schumacher,G.Bastert,H.Bojar,K.Hübner,M.Olschewski,W.Sauerbrei,C.Schmoor,C.Beyerle,
R. L. Neumann, and H. F. Rauschecker. Randomized 2 x 2 trial evaluating hormonal treatment and
thedurationofchemotherapyinnode-positivebreastcancerpatients.germanbreastcancerstudygroup.
JournalofClinicalOncology,12(10):2086–2093,1994.
[42] RiteshSinghandKeshabMukhopadhyay. Survivalanalysisinclinicaltrials:Basicsandmustknowareas.
Perspectivesinclinicalresearch,2(4):145–148,2011.
[43] Yixuan Su, Tian Lan, Yan Wang, Dani Yogatama, Lingpeng Kong, and Nigel Collier. A contrastive
frameworkforneuraltextgeneration. AdvancesinNeuralInformationProcessingSystems,35:21548–
21561,2022.
[44] Yu-AnWangandYun-NungChen. Whatdopositionembeddingslearn?anempiricalstudyofpre-trained
languagemodelpositionalencoding. arXivpreprintarXiv:2010.04903,2020.
[45] ZhenchenWang,PujaMyles,andAllanTucker. Generatingandevaluatingcross-sectionalsyntheticelec-
tronichealthcaredata:Preservingdatautilityandpatientprivacy. ComputationalIntelligence,37(2):819–
851,2021.
[46] WaloddiWeibull. Astatisticaldistributionfunctionofwideapplicability. Journalofappliedmechanics,
1951.
[47] LeiXu,MariaSkoularidou,AlfredoCuesta-Infante,andKalyanVeeramachaneni. Modelingtabulardata
usingconditionalgan. Advancesinneuralinformationprocessingsystems,32,2019.
[48] JinsungYoon,LydiaN.Drumright,andMihaelaVanDerSchaar. Anonymizationthroughdatasynthesis
usinggenerativeadversarialnetworks(ads-gan). IEEEjournalofbiomedicalandhealthinformatics,
24(8):2378–2388,2020.
[49] JunZhang,GrahamCormode,CeciliaM.Procopiuc,DiveshSrivastava,andXiaokuiXiao. Privbayes:
Privatedatareleaseviabayesiannetworks. ACMTransactionsonDatabaseSystems(TODS),42(4):1–41,
2017.
[50] XingyuZhou,WenSu,ChangyuLiu,YulingJiao,XingqiuZhao,andJianHuang.Deepgenerativesurvival
analysis:Nonparametricestimationofconditionalsurvivalfunction. arXivpreprintarXiv:2205.09633,
2022.
12Table4: Trainingandgenerationtimeforsyntheticsurvivaldatageneration(inseconds).Modelsconditioning
ontandEarehighlighted(†).
Metric Method AIDS METABRIC SUPPORT GBSG FLCHAIN
SurvivalGAN 0.178±0.00 0.260±0.00 1.234±0.01 0.283±0.00 1.024±0.01
TVAE† 0.079±0.00 0.129±0.00 0.717±0.00 0.137±0.00 0.520±0.00
TabDDPM† 0.055±0.00 0.049±0.00 0.208±0.00 0.066±0.00 0.182±0.00
CTGAN† 0.165±0.00 0.240±0.00 1.209±0.01 0.246±0.00 0.894±0.01
TTPI(↓) ADS-GAN† 0.143±0.00 0.239±0.00 1.148±0.01 0.256±0.00 0.825±0.01
TVAE 0.136±0.00 0.186±0.00 1.023±0.01 0.187±0.00 0.735±0.00
TabDDPM 0.046±0.00 0.050±0.00 0.215±0.00 0.070±0.00 0.183±0.00
CTGAN 0.193±0.00 0.282±0.00 1.312±0.01 0.287±0.00 1.028±0.01
ADS-GAN 0.214±0.00 0.291±0.00 1.404±0.01 0.306±0.00 1.061±0.01
SurvivalGAN 0.396±0.01 0.421±0.02 0.896±0.08 0.407±0.05 0.715±0.05
TVAE† 0.089±0.00 0.105±0.00 0.376±0.05 0.119±0.02 0.251±0.01
TabDDPM† 11.875±0.16 9.477±0.35 48.985±0.37 17.451±0.22 37.216±0.38
CTGAN† 0.075±0.01 0.088±0.01 0.152±0.00 0.066±0.01 0.102±0.01
GT(↓) ADS-GAN† 0.075±0.01 0.084±0.01 0.148±0.00 0.065±0.00 0.102±0.01
TVAE 0.128±0.02 0.135±0.00 0.468±0.09 0.124±0.00 0.281±0.11
TabDDPM 11.785±0.36 9.466±0.33 50.017±0.81 18.085±0.56 34.937±0.85
CTGAN 0.079±0.00 0.087±0.00 0.192±0.03 0.073±0.00 0.124±0.11
ADS-GAN 0.089±0.00 0.098±0.01 0.212±0.04 0.085±0.01 0.111±0.00
Table5: TrainingandgenerationtimeforsyntheticsurvivaldatagenerationusingLLMs(inseconds).Models
conditioningontandEarehighlighted(†).
Metric Method AIDS METABRIC SUPPORT GBSG FLCHAIN
TTPI GReaT† 5.154±0.11 9.600±0.19 49.800±0.00 6.660±0.21 23.400±0.10
GReaT 14.237±0.15 121.451±0.20 270.798±0.99 23.516±0.05 77.154±0.18
GT
GReaT† 623.156±2.00 912.126±1.76 5520±5.57 812.366±0.25 1140.520±2.59
A BroaderImpact
The ability to generate realistic synthetic survival datasets can have far-reaching impacts across
variousdomains,especiallyinprivacy-sensitiveapplicationslikehealthcareandclinicalresearch.
Syntheticdatacanenablemodeldevelopment,benchmarking,andcollaborationwhilepreserving
patientconfidentialityandcomplyingwithdataprotectionregulations.Furthermore,ourmethodology
canpotentiallyaddressthecommonchallengeoflimiteddataavailabilityinsurvivalanalysisby
augmentingexistingdatasetsorcreatingentirelynewsyntheticdatasetstailoredtospecificrequire-
ments. Whilesyntheticsurvivaldataisspecifictothedomaintowhichitisbeingapplied,limiting
thepotentialformisuse,itisimportanttoacknowledgethepossibilityofreinforcingbiasespresentin
thetrainingdata,asisthecasewithanygenerativemodel. Thoughweaimtounderstandthebehavior
ofsurvivalmodelstrainedonsyntheticdataacrosssub-populations,werecognizethataddressing
biasandensuringequityarecomplexchallengesthatextendbeyondthescopeofthisstudy. Itisthus
crucialtoexercisecautionandimplementappropriatesafeguardstomitigatepotentialbiasesand
promotefairnessinthedevelopmentanddeploymentofsuchmodels.
B ExperimentalDetails
B.1 ComputationalCost
Allexperiments,exceptfortheLLMfine-tuning(seeSection4),wereconductedonGoogleColab
ProusingaT4GPU.FortheLLMfine-tuningexperiments,anNVIDIAA100GPUwasutilized
onColab. InTable4wereportthetrainingtimeperiteration(TTPI)alongwiththetimetakenfor
syntheticdatageneration(GT)forallmodelsusedinSection4.1,whilethetrainingandgeneration
timeforSection4.2)arereportedinTable5.
13Table6: Summarystatisticsofthedatasetsusedinthestudy.
Dataset No.instances No.censoredinstances No.features
AIDS 1151 96 11
METABRIC 1904 801 9
FLCHAIN 7874 5705 9
GBSG 2232 965 7
SUPPORT 8873 2837 14
B.2 Datasets
WebenchmarkourmethodologyonavarietyofmedicaldatasetssummarizedinTable6. Specifically:
i)Studytounderstandprognosespreferencesoutcomesandrisksoftreatment(SUPPORT)[29];ii)
Moleculartaxonomyofbreastcancerinternationalconsortium(METABRIC)[11];iii)ACTG320
clinicaltrialdataset(AIDS)[19];iv)Rotterdam&Germanbreastcancerstudygroup(GBSG)[41];
andv)Assayofserumfreelightchain(FLCHAIN)[15]. Pre-processedversionsofMETABRIC,
SUPPORT, and GBSG can be found at: https://github.com/havakv/pycox. AIDS and
FLCHAIN datasets can be downloaded from https://github.com/sebp/scikit-survival/
tree/master/sksurv/datasets/data. For the FLCHAIN dataset, missing values in continu-
ous covariates were imputed to the mean, while in discrete covariates they were imputed to the
mode. All of these datasets are publicly available hence the experiments can be readily repro-
duced. In parts of our code (see Section 3.2 and 4), we utilize and modify the Synthcity library
(https://github.com/vanderschaarlab/synthcity)whichisprotectedundertheApache-2.0
license. AllrightstoSynthcityarereservedbytheoriginalauthors[38].
14B.3 Hyperparameters
Forreproducibilitypurposes,allhyperparametersarespecifiedbelow. Table7liststhehyperparame-
tersforthedownstreamsurvivalmodelsusedinthebenchmarks. Further,Tables8and9providethe
hyperparametersforallgenerativemodelsemployedinthestudy.
Table7: HyperparametersforthesurvivalmodelsusedinSection4.
Method Parameter ParameterValue
EstimationMethod Breslow
CoxPH Penalizer 0.0
L1Ratio 0.0
Objective Survival:AFT
EvaluationMetric AFTNegativeLogLikelihood
AFTLossDistribution Normal
AFTLossDistributionScale 1.0
SurvivalXGBoost
No.Estimators 100
ColumnSubsampleRatio(bynode) 0.5
MaximumDepth 5
SubsampleRatio 0.5
LearningRate 5×10−2
MinimumChildWeight 50
TreeMethod Histogram
Booster Dart
No.Durations: 1000
BatchSize 100
Epochs 2000
LearningRate 1×10−2
Deephit
HiddenWidth 300
α 0.28
σ 0.38
DropoutRate 0.2
Patience 20
Table8: HyperparametersusedfortheLLMinSection4.2.
Method Parameter ParameterValue
BatchSize 32
No.Iterations 1000
LearningRate 5×10−5
GReaT(DistilGPT2)
Optimizer AdamW
SamplingTemperature 0.7
SamplingBatchSize 100
15Table9: HyperparametersofthegenerativemodelsusedinsyntheticbenchmarksinSection4.1.
Model Parameter ParameterValue
No.Iterations 10000
Generatorno.HiddenLayers 2
GeneratorHiddenUnits 500
GeneratorNon-linearity ReLU
GeneratorDropoutRate 0.1
DiscriminatorNo.HiddenLayers 2
ADS-GAN DiscriminatorHiddenUnits 500
DiscriminatorNon-linearity LeakyReLU
DiscriminatorDropoutRate 0.1
LearningRate 1×10−3
WeightDecay 1×10−3
BatchSize 200
GradientPenalty(λ) 10
IdentifiabilityPenalty 0.1
EncoderMaxClusters 5
EarlyStoppingPatience 5
No.Iterations 2000
GeneratorNo.HiddenLayers 2
GeneratorHiddenUnits 500
GeneratorNon-linearity ReLU
LearningRate 1×10−3
WeightDecay 1×10−3
CTGAN
DiscriminatorNo.HiddenLayers 2
DiscriminatorHiddenUnits 500
DiscriminatorNon-linearity LeakyReLU
GradientPenalty(λ) 10
BatchSize 200
EarlyStoppingPatience 5
UncensoringModel SurvivalFunctionRegression
Time-to-eventstrategy SurvivalFunction
SurvivalGAN
CensoringStrategy Random
DataloaderSamplingStrategy ImbalanceTimeCensoring
No.Iterations 1000
BatchSize 200
LearningRate 1×10−3
WeightDecay 1×10−5
EncoderNo.HiddenLayers 3
EncoderHiddenUnits 500
EncoderNon-linearity LeakyReLU
TVAE EncoderDropoutRate 0.1
DecoderNo.HiddenLayers 3
DecoderHiddenUnits 500
DecoderNon-linearity LeakyReLU
DecoderDropoutRate 0
EarlyStoppingPatience 5
DataEncoderMaxClusters 10
EmbeddingWidth 500
No.Iterations 1000
BatchSize 1024
LearningRate 2×10−3
TabDDPM WeightDecay 1×10−4
No.ofTime-Steps 1000
Scheduler Cosine
GaussianLossType MSE
16C AdditionalPerformanceMetrics
Belowweprovidethecomprehensivescoresofallmodelsevaluatedinthepaper. Table10presents
thecovariatequalityanddownstreamperformancemetricsforallmodelsassessedinSection4.1. In
Table11,wereporttheevent-timedistributionqualitymetrics,includingoptimism,short-sightedness,
andKMDivergence,forbothconditionalandunconditionalmodels. Table12summarizesallmetrics
acrossalldatasetsfortheLLMexperiment,asdiscussedinSection4.2. Lastly,Figure4showsQ-Q
plotsfortheLLMexperiment.
Table10: Quality(JSDistance,WSDistance,andPVP)anddownstream(C-IndexandBrierScore)metrics.
ModelsconditioningontandE arehighlighted(†),UMreferstothebest-performingunconditionalmodel
amongTVAE,TabDDPM,CTGANandADS-GAN,andOriginalisforthesurvivalmodeltrainedonthereal
(training)data.Errorbarsarestandarddeviationsfor5repetitions.
Metric Method AIDS METABRIC SUPPORT GBSG FLCHAIN
SurvivalGAN 0.013±0.00 0.009±0.00 0.008±0.00 0.008±0.00 0.009±0.00
TVAE† 0.007±0.00 0.008±0.00 0.004±0.00 0.005±0.00 0.002±0.00
TabDDPM† 0.007±0.00 0.007±0.00 0.013±0.00 0.005±0.00 0.001±0.00
CTGAN† 0.013±0.00 0.020±0.01 0.005±0.00 0.003±0.00 0.004±0.00
JSdistance(↓) ADS-GAN† 0.006±0.00 0.009±0.00 0.005±0.00 0.004±0.00 0.010±0.01
TVAE 0.011±0.00 0.009±0.00 0.007±0.00 0.007±0.00 0.003±0.00
DDPM 0.006±0.00 0.007±0.00 0.006±0.00 0.005±0.00 0.002±0.00
CTGAN 0.007±0.00 0.012±0.00 0.005±0.00 0.008±0.00 0.005±0.00
ADS-GAN 0.006±0.00 0.007±0.00 0.007±0.00 0.005±0.00 0.005±0.00
SurvivalGAN 0.112±0.01 0.039±0.00 0.043±0.00 0.019±0.00 0.052±0.00
TVAE† 0.061±0.00 0.028±0.00 0.032±0.00 0.013±0.00 0.016±0.00
TabDDPM† 0.159±0.02 0.089±0.00 0.308±0.02 0.056±0.00 0.028±0.00
CTGAN† 0.095±0.00 0.133±0.01 0.034±0.00 0.013±0.00 0.019±0.00
WSdistance(↓) ADS-GAN† 0.082±0.00 0.037±0.00 0.036±0.00 0.011±0.00 0.018±0.00
TVAE 0.075±0.00 0.031±0.00 0.037±0.00 0.013±0.00 0.017±0.00
DDPM 0.079±0.00 0.031±0.00 0.049±0.00 0.015±0.00 0.016±0.00
CTGAN 0.069±0.00 0.041±0.00 0.036±0.00 0.017±0.00 0.021±0.00
ADS-GAN 0.065±0.00 0.035±0.00 0.038±0.00 0.013±0.00 0.017±0.00
SurvivalGAN 0.181±0.00 0.555±0.00 0.571±0.00 0.485±0.00 0.555±0.00
TVAE† 0.090±0.00 0.444±0.00 0.457±0.06 0.142±0.00 0.222±0.04
TabDDPM† 0.181±0.06 0.222±0.00 0.528±0.03 0.199±0.07 0.222±0.04
PVP(↓)
CTGAN† 0.272±0.00 0.555±0.00 0.428±0.00 0.571±0.00 0.511±0.06
ADS-GAN† 0.309±0.04 0.555±0.00 0.600±0.03 0.428±0.00 0.422±0.04
TVAE 0.127±0.04 0.333±0.00 0.400±0.03 0.200±0.06 0.377±0.06
DDPM 0.096±0.04 0.000±0.00 0.171±0.08 0.285±0.00 0.244±0.07
CTGAN 0.181±0.00 0.555±0.00 0.428±0.03 0.285±0.00 0.444±0.00
ADS-GAN 0.272±0.00 0.422±0.04 0.571±0.00 0.571±0.00 0.444±0.00
SurvivalGAN 0.735±0.00 0.625±0.00 0.602±0.00 0.668±0.00 0.870±0.00
TVAE† 0.737±0.00 0.612±0.00 0.583±0.00 0.672±0.00 0.872±0.00
TabDDPM† 0.660±0.07 0.589±0.01 0.536±0.00 0.663±0.00 0.876±0.00
CTGAN† 0.746±0.00 0.628±0.01 0.577±0.00 0.665±0.01 0.874±0.00
C-Index(↑) ADS-GAN† 0.797±0.01 0.655±0.00 0.623±0.00 0.684±0.00 0.880±0.00
Original 0.760±0.00 0.636±0.00 0.616±0.00 0.695±0.00 0.870±0.00
TVAE 0.735±0.00 0.646±0.00 0.604±0.00 0.671±0.00 0.878±0.00
TabDDPM 0.759±0.00 0.649±0.00 0.625±0.00 0.679±0.00 0.879±0.00
CTGAN 0.779±0.00 0.647±0.00 0.606±0.00 0.679±0.00 0.878±0.00
ADS-GAN 0.776±0.00 0.636±0.00 0.601±0.00 0.663±0.00 0.878±0.00
SurvivalGAN 0.068±0.00 0.205±0.00 0.202±0.00 0.212±0.00 0.096±0.00
TVAE† 0.059±0.00 0.199±0.00 0.207±0.00 0.214±0.00 0.095±0.00
TabDDPM† 0.063±0.00 0.212±0.00 0.217±0.00 0.215±0.00 0.096±0.00
CTGAN† 0.061±0.00 0.199±0.00 0.205±0.00 0.215±0.01 0.089±0.00
BrierScore(↓) ADS-GAN† 0.059±0.00 0.197±0.00 0.198±0.00 0.213±0.00 0.084±0.00
Original 0.062±0.00 0.200±0.00 0.195±0.00 0.205±0.00 0.095±0.00
TVAE 0.061±0.00 0.204±0.00 0.206±0.00 0.210±0.00 0.093±0.00
DDPM 0.060±0.00 0.200±0.00 0.199±0.00 0.207±0.00 0.087±0.00
CTGAN 0.064±0.00 0.202±0.00 0.203±0.00 0.210±0.00 0.086±0.00
ADSGAN 0.061±0.00 0.207±0.00 0.201±0.00 0.208±0.00 0.088±0.00
17Table11: Event-timedistributionqualitymetrics. ModelsconditioningontandEarehighlighted(†),UM
referstothebest-performingunconditionalmodelamongTVAE,TabDDPM,CTGANandADS-GAN,and
Originalisforthesurvivalmodeltrainedonthereal(training)data. Errorbarsarestandarddeviationsfor5
repetitions.
Metric Method AIDS METABRIC SUPPORT GBSG FLCHAIN
SurvivalGAN 0.021±0.00 0.011±0.00 0.016±0.00 0.006±0.00 0.134±0.00
TVAE† 0.000±0.00 0.000±0.00 0.000±0.00 0.003±0.00 0.001±0.00
DDPM† 0.000±0.00 0.000±0.00 0.000±0.00 0.003±0.00 0.001±0.00
CTGAN† 0.000±0.00 0.000±0.00 0.000±0.00 0.003±0.00 0.001±0.00
Optimism ADSGAN† 0.000±0.00 0.000±0.00 0.000±0.00 0.003±0.00 0.001±0.00
(→0) TVAE 0.023±0.00 -0.003±0.00 -0.014±0.00 0.004±0.00 0.022±0.00
DDPM 0.021±0.00 0.001±0.00 0.001±0.00 0.026±0.00 0.005±0.00
CTGAN -0.005±0.00 0.017±0.00 -0.038±0.00 0.060±0.00 -0.037±0.00
ADSGAN 0.001±0.00 -0.033±0.00 -0.007±0.00 0.010±0.00 0.005±0.00
SurvivalGAN 0.007±0.00 0.124±0.00 0.020±0.00 0.019±0.00 0.005±0.00
TVAE† 0.001±0.00 0.000±0.00 0.000±0.00 0.010±0.01 0.002±0.00
DDPM† 0.001±0.00 0.000±0.00 0.000±0.00 0.010±0.01 0.002±0.00
Short CTGAN† 0.001±0.00 0.000±0.00 0.000±0.00 0.010±0.01 0.002±0.00
Sightedness ADS-GAN† 0.001±0.00 0.000±0.00 0.000±0.00 0.010±0.01 0.002±0.00
(→0) TVAE 0.058±0.00 0.148±0.00 0.002±0.00 0.017±0.00 0.018±0.00
DDPM 0.002±0.00 0.000±0.00 0.002±0.00 0.015±0.00 0.003±0.00
CTGAN 0.071±0.00 0.056±0.00 0.010±0.00 0.019±0.00 0.017±0.00
ADSGAN 0.040±0.00 0.188±0.00 0.000±0.00 0.014±0.00 0.006±0.00
SurvivalGAN 0.021±0.00 0.082±0.00 0.064±0.00 0.049±0.00 0.134±0.00
TVAE† 0.002±0.00 0.008±0.00 0.002±0.00 0.005±0.00 0.002±0.00
DDPM† 0.002±0.00 0.008±0.00 0.002±0.00 0.005±0.00 0.002±0.00
KM CTGAN† 0.002±0.00 0.008±0.00 0.002±0.00 0.005±0.00 0.002±0.00
Divergence ADS-GAN† 0.002±0.00 0.008±0.00 0.002±0.00 0.005±0.00 0.002±0.00
(↓) TVAE 0.031±0.00 0.042±0.00 0.025±0.00 0.027±0.00 0.031±0.00
DDPM 0.021±0.00 0.019±0.00 0.011±0.00 0.026±0.00 0.007±0.00
CTGAN 0.015±0.00 0.028±0.00 0.038±0.00 0.061±0.00 0.037±0.00
ADSGAN 0.016±0.00 0.039±0.00 0.020±0.00 0.030±0.00 0.012±0.00
Table12: Quality(JSdistance,WSdistanceandPVP)anddownstream(C-IndexandBrierScore)metrics.
ModelsconditioningontandEarehighlighted(†).BMreferstothebest-performingmodelfromTable1.
Dataset Method C-Index BrierScore JSdistance WSDistance PVP
SurvivalGAN 0.735±0.00 0.068±0.01 0.013±0.00 0.12±0.00 0.181±0.00
GReaT† 0.790±0.00 0.063±0.00 0.003±0.00 0.036±0.00 0.000±0.00
AIDS
GReaT 0.725±0.01 0.063±0.00 0.004±0.00 0.046±0.00 0.090±0.00
BM 0.797±0.01 0.059±0.00 0.006±0.00 0.061±0.00 0.090±0.00
SurvivalGAN 0.625±0.00 0.205±0.00 0.009±0.00 0.039±0.00 0.555±0.00
GReaT† 0.640±0.00 0.195±0.00 0.005±0.00 0.000±0.00 0.000±0.00
METABRIC
GReaT 0.623±0.00 0.201±0.00 0.006±0.00 0.000±0.00 0.111±0.00
BM 0.655±0.00 0.197±0.00 0.007±0.00 0.028±0.00 0.000±0.00
SurvivalGAN 0.602±0.00 0.202±0.00 0.008±0.00 0.043±0.00 0.571±0.00
GReaT† 0.630±0.00 0.198±0.00 0.002±0.00 0.000±0.00 0.071±0.00
SUPPORT
GReaT 0.627±0.00 0.200±0.00 0.003±0.00 0.020±0.00 0.071±0.00
BM 0.625±0.00 0.198±0.00 0.004±0.00 0.032±0.00 0.171±0.08
SurvivalGAN 0.668±0.00 0.212±0.00 0.008±0.00 0.019±0.00 0.485±0.00
GReaT† 0.686±0.00 0.207±0.00 0.006±0.00 0.012±0.00 0.142±0.00
GBSG
GReaT 0.672±0.00 0.207±0.00 0.007±0.00 0.011±0.00 0.142±0.00
BM 0.684±0.00 0.207±0.00 0.003±0.00 0.011±0.00 0.142±0.00
SurvivalGAN 0.870±0.00 0.096±0.00 0.009±0.00 0.052±0.00 0.555±0.00
GReaT† 0.880±0.00 0.082±0.00 0.001±0.00 0.015±0.00 0.111±0.00
FLCHAIN
GReaT 0.878±0.00 0.090±0.00 0.001±0.00 0.020±0.00 0.222±0.00
BM 0.880±0.00 0.084±0.00 0.001±0.00 0.016±0.00 0.222±0.04
18(a)AIDS (b)FLCHAIN
(c)METABRIC (d)SUPPORT
(e)GBSG
Figure4:Q-Qplotscomparingthep-valuedistributionsofallconditionalmodels(†)fromSection4.1
and4.2. Thedashedlinerepresentstheexpected(uniform)distribution.
19