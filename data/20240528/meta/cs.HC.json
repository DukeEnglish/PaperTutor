[
    {
        "title": "The Peripatetic Hater: Predicting Movement Among Hate Subreddits",
        "authors": "Daniel HickeyDaniel M. T. FesslerKristina LermanKeith Burghardt",
        "links": "http://arxiv.org/abs/2405.17410v1",
        "entry_id": "http://arxiv.org/abs/2405.17410v1",
        "pdf_url": "http://arxiv.org/pdf/2405.17410v1",
        "summary": "Many online hate groups exist to disparage others based on race, gender\nidentity, sex, or other characteristics. The accessibility of these communities\nallows users to join multiple types of hate groups (e.g., a racist community\nand misogynistic community), which calls into question whether these\nperipatetic users could be further radicalized compared to users that stay in\none type of hate group. However, little is known about the dynamics of joining\nmultiple types of hate groups, nor the effect of these groups on peripatetic\nusers. In this paper, we develop a new method to classify hate subreddits, and\nthe identities they disparage, which we use to better understand how users\nbecome peripatetic (join different types of hate subreddits). The hate\nclassification technique utilizes human-validated LLMs to extract the protected\nidentities attacked, if any, across 168 subreddits. We then cluster\nidentity-attacking subreddits to discover three broad categories of hate:\nracist, anti-LGBTQ, and misogynistic. We show that becoming active in a user's\nfirst hate subreddit can cause them to become active in additional hate\nsubreddits of a different category. We also find that users who join additional\nhate subreddits, especially of a different category, become more active in hate\nsubreddits as a whole and develop a wider hate group lexicon. We are therefore\nmotivated to train an AI model that we find usefully predicts the hate\ncategories users will become active in based on post text read and written. The\naccuracy of this model may be partly driven by peripatetic users often using\nthe language of hate subreddits they eventually join. Overall, these results\nhighlight the unique risks associated with hate communities on a social media\nplatform, as discussion of alternative targets of hate may lead users to target\nmore protected identities.",
        "updated": "2024-05-27 17:57:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.17410v1"
    },
    {
        "title": "Socially-Aware Shared Control Navigation for Assistive Mobile Robots in the Built Environment",
        "authors": "Yifan XuQianwei WangVineet KamatCarol Menassa",
        "links": "http://arxiv.org/abs/2405.17279v1",
        "entry_id": "http://arxiv.org/abs/2405.17279v1",
        "pdf_url": "http://arxiv.org/pdf/2405.17279v1",
        "summary": "As the number of Persons with Disabilities (PWD), particularly those with one\nor more physical impairments, increases, there is an increasing demand for\nassistive robotic technologies that can support independent mobility in the\nbuilt environment and reduce the burden on caregivers. Current assistive\nmobility platforms (e.g., robotic wheelchairs) often fail to incorporate user\npreferences and control, leading to reduced trust and efficiency. Existing\nshared control algorithms do not allow the incorporation of the user control\npreferences inside the navigation framework or the path planning algorithm. In\naddition, existing dynamic local planner algorithms for robotic wheelchairs do\nnot take into account the social spaces of people, potentially leading such\nplatforms to infringe upon these areas and cause discomfort. To address these\nconcerns, this work introduces a novel socially-aware shared autonomy-based\nnavigation system for assistive mobile robotic platforms.\n  Our navigation framework comprises a Global Planner and a Local Planner. To\nimplement the Global Planner, the proposed approach introduces a novel User\nPreference Field (UPF) theory within its global planning framework, explicitly\nacknowledging user preferences to adeptly navigate away from congested areas.\nFor the Local Planner, we propose a Socially-aware Shared Control-based Model\nPredictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) to\nadjust movements in real-time, integrating user preferences for safer, more\nautonomous navigation. Evaluation results show that our Global Planner aligns\nclosely with user preferences compared to baselines, and our Local Planner\ndemonstrates enhanced safety and efficiency in dynamic and static scenarios.\nThis integrated approach fosters trust and autonomy, crucial for the acceptance\nof assistive mobility technologies in the built environment.",
        "updated": "2024-05-27 15:40:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.17279v1"
    },
    {
        "title": "From Text to Blueprint: Leveraging Text-to-Image Tools for Floor Plan Creation",
        "authors": "Xiaoyu LiJonathan BenjaminXin Zhang",
        "links": "http://arxiv.org/abs/2405.17236v1",
        "entry_id": "http://arxiv.org/abs/2405.17236v1",
        "pdf_url": "http://arxiv.org/pdf/2405.17236v1",
        "summary": "Artificial intelligence is revolutionizing architecture through text-to-image\nsynthesis, converting textual descriptions into detailed visual\nrepresentations. We explore AI-assisted floor plan design, focusing on\ntechnical background, practical methods, and future directions. Using tools\nlike, Stable Diffusion, AI leverages models such as Generative Adversarial\nNetworks and Variational Autoencoders to generate complex and functional\nfloorplans designs. We evaluates these AI models' effectiveness in generating\nresidential floor plans from text prompts. Through experiments with reference\nimages, text prompts, and sketches, we assess the strengths and limitations of\ncurrent text-to-image technology in architectural visualization. Architects can\nuse these AI tools to streamline design processes, create multiple design\noptions, and enhance creativity and collaboration. We highlight AI's potential\nto drive smarter, more efficient floorplan design, contributing to ongoing\ndiscussions on AI integration in the design profession and its future impact.",
        "updated": "2024-05-27 14:51:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.17236v1"
    },
    {
        "title": "InsigHTable: Insight-driven Hierarchical Table Visualization with Reinforcement Learning",
        "authors": "Guozheng LiPeng HeXinyu WangRunfei LiChi Harold LiuChuangxin OuDong HeGuoren Wang",
        "links": "http://arxiv.org/abs/2405.17229v1",
        "entry_id": "http://arxiv.org/abs/2405.17229v1",
        "pdf_url": "http://arxiv.org/pdf/2405.17229v1",
        "summary": "Embedding visual representations within original hierarchical tables can\nmitigate additional cognitive load stemming from the division of users'\nattention. The created hierarchical table visualizations can help users\nunderstand and explore complex data with multi-level attributes. However,\nbecause of many options available for transforming hierarchical tables and\nselecting subsets for embedding, the design space of hierarchical table\nvisualizations becomes vast, and the construction process turns out to be\ntedious, hindering users from constructing hierarchical table visualizations\nwith many data insights efficiently. We propose InsigHTable, a mixed-initiative\nand insight-driven hierarchical table transformation and visualization system.\nWe first define data insights within hierarchical tables, which consider the\nhierarchical structure in the table headers. Since hierarchical table\nvisualization construction is a sequential decision-making process, InsigHTable\nintegrates a deep reinforcement learning framework incorporating an auxiliary\nrewards mechanism. This mechanism addresses the challenge of sparse rewards in\nconstructing hierarchical table visualizations. Within the deep reinforcement\nlearning framework, the agent continuously optimizes its decision-making\nprocess to create hierarchical table visualizations to uncover more insights by\ncollaborating with analysts. We demonstrate the usability and effectiveness of\nInsigHTable through two case studies and sets of experiments. The results\nvalidate the effectiveness of the deep reinforcement learning framework and\nshow that InsigHTable can facilitate users to construct hierarchical table\nvisualizations and understand underlying data insights.",
        "updated": "2024-05-27 14:47:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.17229v1"
    },
    {
        "title": "Collage is the New Writing: Exploring the Fragmentation of Text and User Interfaces in AI Tools",
        "authors": "Daniel Buschek",
        "links": "http://dx.doi.org/10.1145/3643834.3660681",
        "entry_id": "http://arxiv.org/abs/2405.17217v1",
        "pdf_url": "http://arxiv.org/pdf/2405.17217v1",
        "summary": "This essay proposes and explores the concept of Collage for the design of AI\nwriting tools, transferred from avant-garde literature with four facets: 1)\nfragmenting text in writing interfaces, 2) juxtaposing voices (content vs\ncommand), 3) integrating material from multiple sources (e.g. text\nsuggestions), and 4) shifting from manual writing to editorial and\ncompositional decision-making, such as selecting and arranging snippets. The\nessay then employs Collage as an analytical lens to analyse the user interface\ndesign of recent AI writing tools, and as a constructive lens to inspire new\ndesign directions. Finally, a critical perspective relates the concerns that\nwriters historically expressed through literary collage to AI writing tools. In\na broad view, this essay explores how literary concepts can help advance design\ntheory around AI writing tools. It encourages creators of future writing tools\nto engage not only with new technological possibilities, but also with past\nwriting innovations.",
        "updated": "2024-05-27 14:35:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.17217v1"
    }
]