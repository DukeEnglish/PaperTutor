GRAB: A Challenging GRaph Analysis Benchmark for Large Multimodal Models
JonathanRoberts1,KaiHan2,SamuelAlbanie
1UniversityofCambridge,2TheUniversityofHongKong
jdr53@cam.ac.uk, kaihanx@hku.hk, samuel.albanie.academic@gmail.com
https://grab-benchmark.github.io
Abstract
Largemultimodalmodels(LMMs)haveexhibitedprofi-
cienciesacrossmanyvisualtasks. Althoughnumerouswell-
known benchmarks exist to evaluate model performance,
theyincreasinglyhaveinsufficientheadroom. Assuch,there
isapressingneedforanewgenerationofbenchmarkschal-
lengingenoughforthenextgenerationofLMMs. Onearea
thatLMMsshowpotentialisgraphanalysis,specifically,the
tasksananalystmighttypicallyperformwheninterpreting
figuressuchasestimatingthemean,interceptsorcorrela-
tionsoffunctionsanddataseries. Inthiswork,weintroduce
GRAB,agraphanalysisbenchmark,fitforcurrentandfu-
ture frontier LMMs. Our benchmark is entirely synthetic,
ensuringhigh-quality,noise-freequestions. GRABiscom-
prisedof2170questions,coveringfourtasksand23graph
properties. We evaluate 20 LMMs on GRAB, finding it to Figure1.OverallperformanceonGRAB.Ourbenchmarkproves
be a challenging benchmark, with the highest performing challenging for frontier LMMs. The highest performing LMM
attainsanaccuracyofjust21.7%onGRAB.
modelattainingascoreofjust21.7%. Finally,weconduct
variousablationstoinvestigatewherethemodelssucceed
andstruggle. WereleaseGRABtoencourageprogressin
room for improvement. Moreover, label inaccuracies are
thisimportant,growingdomain.
reportedlypervasive[26]eveninthemostusedbenchmarks,
furtherreducingpossibleheadroom.
1.Introduction
Oneparticulartaskofinterestandimportanceistheinter-
Driven by the union of increased compute resources, a pretationofscientificandmathematicalfiguresandcharts,
rapidly growing research community, and competition fu- whichiscentraltomanyanalyticalendeavours. Specifically,
elledbyburgeoningcommercialopportunities,thecapabili- we target use cases where the underlying data of a figure
tiesoffrontierlargemultimodalmodelsareswiftlyimprov- is not accessible, for example in documents, sketches, or
ingandexpanding. Furthermore,thetimelinesforadvances, otherimagetypes,andquantitiescanonlybededucedfrom
especiallyamongclosed-sourcemodels,appeartobeshort- visual interpretation. Given their prevalence, the insights
ening, with the time between model releases diminishing. gainedfromunderstandingandreasoningoverthesetypesof
Thishasimportantimplicationsforevaluationandbench- figuresmakethistaskanimportantandvaluablecapability
marking,whicharecriticaltogaugetherelativestrengths for LMMs. Various forms of chart evaluation have been
and weaknesses of models. In particular, as performance presentinmachinelearningliteratureforquitesometime
increases,commonbenchmarksbecomesaturatedandstale– throughestablishedbenchmarks[15,25]andmorerecent
forexample,GPT-4o[28]scores90.5%,90.2%,and88.7% works[40,46]. However,thesebenchmarksneedanuplift
on the widely used MGSM, HumanEval, MMLU bench- forthecurrentandfuturegenerationsoffrontiermodels.
marks,respectively. Theusefulnessofabenchmarkindis- To this end, we introduce GRaph Analysis Benchmark
tinguishingmodelcapabilitydiminisheswhenthereislittle (GRAB),consistingof2170questions. AllfiguresinGRAB
1
4202
guA
12
]VC.sc[
1v71811.8042:viXraProperties Functions Series Transforms
What is the equation of the function? Estimate the mean y-intercept of Estimate the mean Pearson Estimate the gradient of the function after
(in the form y = <m>x + <c> the functions in the plot. correlation coefficient of the data it has been transformed by the following:
1. reflection in the line x=-10;
Answer: y = -3x + 1 Answer: 2.0 (1 d.p.) series in the plot.
2. translation by -7 in y;
Answer: -0.4 (1 d.p.) Answer: 2 (integer)
Figure2.TheGRaphAnalysisBenchmarkconsistsof2170syntheticallygeneratedgraphanalysisquestionsthatprovechallengingfor
frontierLMMs.Thequestionscover23graphpropertiesorganisedintofourcoretasks:(i)Propertiesfocusesontheanalysisoffeaturesof
individualfunctionsandseries;(ii)Functionsand(iii)Seriesrequirecomputingthemeanofpropertiesacrossmultiplefunctionsandseries;
and(iv)Transformsinvolvesdeterminingthepropertiesofafunctionafterithasundergoneaseriesoftransforms.
aregeneratedsyntheticallyusingtheMatplotliblibrary[13]. conductadetailederroranalysisandsetofablationstogain
Althoughsomerealismmightbelostwhensolelyconsider- insightsintowhichtasksandcategorieswerethemostchal-
ingsyntheticallygenerateddata,therearenumerousbenefits lenging, as well as investigations of how question format
totakingthisapproach: (1)Difficulty–thecomplexityof andprecisionimpactperformance.
questionscanbecontrolledandtuned;(2)Noise–ground Wesummarisethecontributionsofthisworkasfollows:
truthisdeterminedautomaticallyduringcuration,avoiding (i) We introduce GRAB (GRaph Analysis Benchmark), a
theneedforpotentiallyerroneousposthocannotation;(3) challenging 2170 question benchmark for graph analysis,
Composition–wecandirectlyselectthecharacteristicsof (ii)Wecomprehensivelycharacterisethecapabilitiesof20
questionsinourbenchmarkandarbitrarilycontrolthescale; currentgenerationfrontierLMMsonGRAB,and(iii)We
and,(4)Contamination–whilethesamefigurestylewillal- provideinsightsintomodelstrengthsandlimitationsthrough
mostcertainlyhavebeenseenduringthepretrainingofmost numerousablations.
LMMs, it is unlikely that the exact figures and questions
generatedforourbenchmarkhave. 2.RelatedWork
Leveraging the control enabled by our synthetic gen-
2.1.FigureInterpretationBenchmarks
eration, we optimise our benchmark for usefulness and
longevity. Specifically, we include challenging questions Motivatedbythelastdecadeofprogressincomputervision,
thatfrontierLMMsstruggletoanswer(seeFig.1)andwe arangeofpriorworkhassoughttoevaluatefiguretheinter-
control the aesthetic parameters of each graph to ensure pretationcapabilitiesofleadingmodels. Onefamilyofwork
allrelevantfeaturesareclearandquestionsareanswerable. has focused on synthetic data generation pipelines, profit-
We restrict the size of our benchmark to 2170 questions, ingfromthereliablegroundtruthandfine-grainedcontrol
balancingstreamlinedevaluationandrobustness. enabledbythisapproach.Thishasyieldedfigurebinaryclas-
Weaimforacomprehensiveevaluationoftheabilitiesof sificationtasks[15],captioning[7],andvariousstructural
frontiermodelstoanalysefiguresbyincludingabroadrange understanding, retrieval and reasoning tasks with limited
of chart types and question formats. The tasks in GRAB vocabularies[14]. Syntheticfiguregenerationhasalsobeen
involvedeterminingkeydataproperties,suchasmean,vari- combinedwithcorporaofonlinestatistics[6,25,42]and
ance,andinterquartilerange,aswellasfunctionproperties Kaggledatasets[46]toachievegreaterfigurediversity. A
like gradients, stationary points, and function parameters. secondlineofworkhassoughttoconstructdatasetsbycu-
Questioncomplexityisincreasedbyincorporatingmultiple rating‘real’figuresdirectlyfromonlinesourcesandparsing
functionsandseries(seeFig.2)andincreasingtherequired theirmetadata. Forthispurpose,figureshavebeensourced
answerprecision. Weevaluate20closedsourceLMMson from research papers [40, 41] and online sources such as
ourbenchmark,whichprovesextremelychallengingforthe OurWorldinData[23].
currentgenerationofmodels,withthebestperformingattain- GRAB draws particular inspiration from the family of
ingascoreof21.7%.Whilesomemodelsexhibitamodicum syntheticbenchmarks,towhichitalsobelongs. However,a
ofsuccessontheeasiestquestionset,thevastmajorityof keydistinctionbetweenourtasksandpriorbenchmarksis
ourbenchmarkisbeyondthecapabilitiesofallmodels. We GRAB’ssignificantlygreaterdifficulty,asevidencedbyour
2empiricalresultsillustratingthateventhestrongestfrontier fromdataorfunctionsingraphsandcharts. Wegroupthese
LMMsstruggletomakeheadway(Sec.4). propertiesintothecategoriesshowninTab.2. Weconsider
thissetofpropertiestocovermostrealusecasesandrequire
2.2.LMMEvaluationandBenchmarks
some measure of visual analytical reasoning. We refrain
SincetheemergenceofLMMs,numerousbenchmarkshave fromincluding‘easier’OCR-centeredquestions–suchas
beencreatedtoevaluateandcharacterisetheircapabilities legend,title,axis-labelinterpretation–inourbenchmarkto
across many domains. Interpreting and answering ques- keepthefocusonvisualanalyticalreasoning,andinstead
tionsofnaturalimagesisakeytask,withbenchmarkssuch onlyincludequestionsofthistypeasanablation(seeAp-
asMMBench[19],SEEDBench[17],SEEDBench-2[16], pendix). Furthermore,asoutlinedinSec.2,numerousprior
MME[9],MM-Vet[47],LVLM-eHub[45],ScienceQA[21] benchmarkshaveincludedthistypeofquestion.
andMMMU[48]findingprominence. However,asoutlined
in [8], although widely used, some of these most popular 3.3.Tasks
benchmarkscontainproblematicquestions,includingthose
WestructureGRABintothefollowingtaskscoveringdif-
that do not require visual content to be answered. Unlike
ferent aspects of graph analysis. Example questions and
olderdatasetsdevelopedtocatertothesupervisedlearning
answersforeachtaskcanbefoundinFig.4.
paradigmthattypicallyrequiredmuchlargerscales,morere-
centLMM-focusedbenchmarkscontainsignificantlysmaller
testsetsofafewthousandquestionsorafewhundred(e.g.
3.3.1 Properties
[35]).
Variousbenchmarkscanbefoundinmorenichedomains, This initialtask aimsto provide abroad evaluationof the
suchasgeographicandgeospatialevaluation[39],hallucina- capabilitytounderstandanddetermineorderiveproperties
tions[12]andOCR[20]. AcloselyrelatedworktoGRAB ofgraphs,includingbothbasicfundamentalpropertieslike
isMathVista[22],whichevaluatesmathematicalreasoning numberofseriesormoreadvancedpropertiesrequiringcal-
in visual contexts. MathVista is a metadataset (similar to culations, liketotalareabounded. Asidefromnumberof
[38])consistingofabroadrangeofmostlymultiple-choice seriesquestions,thegraphsinvolvejustasinglefunctionor
questionsfrom31multimodaldatasetscoveringadiverseset dataseries.
offiguretypesandmathematicaltasksrangingfromtable
interpretationtopuzzles. Thoughsimilar,thefocusofMath-
Vista on general mathematical reasoning, is distinct from 3.3.2 Functions
ours,whichiscenteredonthemorenarrowtaskofderiving
FunctionsbuildsonPropertieswithincreasedcomplexity
andanalysinggraphproperties. Moreover,ourbenchmark
byaddinguptoatotalof10functionspergraph. Questions
isconsiderablymorechallenging: GPT-4oscores>60%on
requireanadditionalstepofaveragingacrossallfunctions.
MathVista1comparedto13.6%onGRAB.
Forexample,‘Estimatethemeantotalareaboundedbythe
3.GRaphAnalysisBenchmark functionandthex-axisofthefunctionsshownintheplot’.
Addeddifficultyisintroducedbyfunctionsoverlapping.
OurGRaphAnalysisBenchmarkconsistsof2170questions
covering four core tasks and 23 graph properties. In the
followingsection,weprovideanoverviewofthebenchmark, 3.3.3 Series
includingdescriptionsofthecategoriesandtasks,example
Similar to Functions, Series builds on the initial task by
questions and answers, and an overview of our synthetic
adding up to 10 data series per graph, with questions re-
curationprocess. High-levelstatisticscanbefoundinTab.1.
quiringestimatesofthemeanofspecificpropertiesacross
3.1.Questionformat theobservableseries,forexample,‘EstimatethemeanPear-
son correlation coefficient of the data series shown in the
Allquestionsinourbenchmarkfollowasingle-answerfor-
plot’. Theadditionalseriesintroduceschallenges suchas
mat, in which each question asks for a specific property
overlappingandclusteredpoints.
of the function(s) or data present in the graph along with
requiredprecisionlevels.
3.2.Categories 3.3.4 Transforms
QuestionsinourGRABbenchmarkcover23graphproper- QuestionsintheTransformstaskincludesasinglefunction
tiesfromwhichanalyticalinsightscancommonlybederived and require computing a graph property after performing
1https://huggingface.co/spaces/opencompass/ a sequence of up to 10 transforms (rotations, translations,
open_vlm_leaderboard scalesandreflections).
3Category Properties
Intercepts&Gradi- x-intercept,y-intercept,gra- Category
Correlation InterceptsandGradients
ents dient Trigonometric Range
Statistic Number StationaryPoints stationary point(s) coordi- MeasuresofSpread Counting
Questions 2170 nates S At ra et aio Bn oa ury ndP eo dints E Fux ntr ce tm ioa ns
Tasks 4 Trigonometric amplitude,verticalshift,pe- 700
riod
Graphproperties 23
Functions functionequations 600
Propertiesquestions 660 Counting numberofpoints,numberof
Functionsquestions 710 series 500
Correlation {Pearson’s,Spearman’srank,
Seriesquestions 490 400
Kendallrank}correlationco-
Transformsquestions 310 efficient 300
10sprecisionquestions 30 AreaBounded totalareabounded,netarea
bounded 200
Integerprecisionquestions 1575
MeasuresofSpread mean,median,interquartile
1d.p.precisionquestions 565 range,variance 100
Table1.GRABstatistics Range&Extrema min/max values, domain 0
length,range Properties Functions Series Transforms
Task
Table2.Categoriesandproperties Figure3.GRABcategorydistribution
3.4.Curation 3.4.1 Qualitycontrol
Thecurationprocessunderwentnumerousiterationsofhu-
WeleveragetheMatplotlib[13]librarytosyntheticallycre-
manreviewthatsoughttotunethehyperparametersinvolved
ate the graphs used in our core benchmark and ablations
increatingthegraphs. Thisactivitywasprimarilyfocused
studies. The following provides a brief overview of the
onjointlyensuring(i)thequestionswereanswerablefroma
methodologyusedtogeneratethefiguresandquestions. For
technicalperspective,(ii)theground-truthanswerswerecor-
eachtask,weinitiallycreatedalonglistof250questionsper
rectandthat(iii)therenderedfiguresweresuitablyreadable.
property. Wethenperformeddownsamplingtoselectafinal
Similarspot-checkswerecarriedoutonthefinaldataset.
questionsetwithuniformlydistributedanswers.Thisdowns-
election aimed to increase the question diversity, reduced
4.Experiments
biasinthegenerationprocessandavoidanoverabundance
ofquestionswithanswersconvergingtowards0,especially 4.1.Baselines
fortheFunctions,SeriesandTransformstasks.
Weevaluate20LMMsonGRAB,coveringabroadrange
Weassociateeachgraphproperty(Tab.2)withasetof of both open- and closed-source models. We use chat or
data generation functions and function parameter ranges. instruction-tunedvariantsratherthanbasemodels,ofeach
ForcategoriessuchasIntercepts&GradientsorFunctions, model evaluated, as they are typically better at following
we sample values for the property of interest and then fit taskandoutputinstructions. Webenchmark4familiesof
thegenerationparameterstoproducefunctions/seriesthat frontier closed-source LMMs, specifically the GPT-4 [27,
matchthevalue. Fortheothercategories,suchasCorrela- 28], Gemini [10, 37] Claude 3 [3], and Reka [34] series.
tionorAreaBounded,werandomlysamplethegeneration Additionally,weselectthefollowingopen-sourcemodelsfor
parametersandthencalculatethepropertyvaluefromthe evaluation: Qwen-VL[5],TransCore-M[36],OmniLMM
data. Ineachcase,weensurequestionsareunique. Foreach [32],Yi[1],CogVLM[43],andLLaVA-1.5[18].
graphinthePropertiestask,aestheticparameters(e.g.figure
4.2.Experimentalsettings
size,fontsize,andlinestyle)arerandomlysampledfroma
definedsetofoptions. Fortheothertasks(Series,Functions 4.2.1 Inference
andTransforms), welimitthevariabilityofthegraphsby
We evaluate the closed-source models via the Vertex AI
configuringtheappearancetoadefinedschema. Assuch,all
API[11]{Gemini,Claude},OpenAIAPI[30]{GPT},and
graphshavethesamexandy-limits,gridlines,ticklabels,
Reka API [2] {Reka}. Following benchmarking conven-
fontandresolution(2251x2171). Asinglefunctiontypeis
tions, we set model hyperparameters that result in deter-
usedforeachgraph,irrespectiveofthenumberofseries.
ministic and reproducible generation. This entails utilis-
Most questions require answers to integer precision, ing a greedy search decoding strategy in which the most
though to increase difficulty, approximately 25% of ques- probabletokenisselectedfromthemodelvocabularyV at
tions require 1 decimal place precision. Questions in the eachstep,conditionalontheprecedingtokensi.e.,w =
n+1
Area Bounded and Functions categories are evaluated to argmax P(w|w ,w ,...,w ). Weachievethisbyset-
w∈V 1 2 n
eitherintegerornearest10precision. ting the temperature and topk parameters to zero and 1,
4
snoitseuqforebmuNProperties
What is the interquartile range of What are the x-values of the two stationary What is the amplitude of the
the data? Answer: 25 points of the function? Answer: [4, 10] function?’ Answer: 5
Functions
Estimate the mean period of the functions. Estimate the mean x-intercept of the Estimate the mean variance of the
Answer: 3.1 (1 dp) functions. Answer: -2 (integer) functions. Answer: 1 (integer)
Series
Estimate the mean maximum value Estimate the mean Kendall rank Estimate the mean domain length of
of the data series. correlation coefficient of the data series. the data series.
Answer: 5 (integer) Answer: 0.0 (1 dp) Answer: 11 (integer)
Transforms
Estimate the domain length of the function Estimate the domain length of the Estimate the maximum value of the
after it has been transformed by the function after it has been transformed function after it has been
following operations: by the following operations: transformed by the following:
1. reflection in the line y=x; 1. scale by 0.5 in y; 1. reflection in the line y=x;
Answer: 5 (integer) 2. rotation by 180°about the origin; 2. rotation by 270° about the origin;
Answer: 1 (integer) 3. translation by -10 in y;
Answer: -9.7 (1dp)
Figure4.ExamplequestionsforthefourtasksintheGRABbenchmark.
5respectively,andspecifyingrandomseeds. Weruntheopen- higheraccuracyonthefunctionstaskcomparedtotheseries
sourcemodelsusingHuggingFaceTransformers[44]and task,possiblyduetotheirregularityintroducedbythenoise
theOpenCompasstoolkit[33]. inthedata. Significantlyloweraccuracyisattainedonthe
Transformstask. Acontributingfactortothesescoresisthe
4.2.2 Prompting degree to which the models follow output format instruc-
tions. Givenourexactstringmatchingevaluationprotocol,
Weadoptasimplepromptingstrategythroughoutourevalu- anydeviationfromtheexpectedoutputisdeemedincorrect.
ation,similartothatusedbythepopularrepositorysimple-
Despitepotentiallyhavingsuperiormathematicalreasoning
evals[31]. Concretely,weuseasinglebasicuser prompt abilities, models that struggle to precisely follow instruc-
consisting of the question and output format instructions. tionsorhaveproclivitiestogenerateverboseanswerssuffer
Wedonotmodifythesystempromptortailortheprompt severeperformancedegradation. WiththeexceptionofReka
foreachmodel. Althoughmodelperformanceisknownto Core(whichshowedpooroutputformatinstructionfollow-
besensitivetotheseinputconfigurations,ourinvestigation ingcapabilities),allclosed-sourcemodelsoutperformedthe
focusesonchatorinstruction-tunedmodels,whichareopti- leadingopen-sourcemodel. However,theopen-sourcemod-
misedforinstructionfollowing: ifamodelcanonlyperform elsdidconsistentlygenerateanswersinthecorrectformat.
ataskwhenaspecificphraseisincludedintheprompt,this
Inthislow-scoringregimewhereeventhebestmodels
is a clear weakness. Being able to answer questions in a
struggle, a comparison of model performance should be
realisticsetting(i.e.asahumanwouldbepresentedwiththe
madewiththecaveatthatallmodelscanbarelyperformthe
questions)offersamoregeneralisedevaluation.
tasksinthebenchmark. Weanticipateourbenchmarkwill
yieldmostbenefitwhenevaluatingthenextgenerationof
4.2.3 Evaluation LMMs.
Our core evaluation protocol is exact matching between 4.4.Categoryanalysis
modeloutputandthegroundtruthanswers. Theonlypost-
processingstepwetakeisremovingleadingwhitespace. An Adecompositionofmodelperformanceintoquestioncat-
answer is only scored as correct if the output characters egoryisprovidedinTab.4. Significantvarianceisshown
ateachpositionmatchthoseoftheexpectedanswer. This acrosscategories,withsomemodelsmuchbettersuitedfor
meansthatalthoughverboseanswersoftheform‘Thean- certaincategoriesthanothers. Overall,thehighestaccura-
sweris...’ or‘<Reasoning><Answer>’mightcontainthe cies are attained on the Counting category, which encom-
correct answer, they will be markedincorrect. While this passessimplequestionsdeterminingthenumberofseries
maylowermodelscorescomparedtohumanorLLMevalu- shownineachplot,ortheapproximatenumberofdatapoints.
ation(e.g.[35,40]),weconsiderthisabetterevaluationas Ontheotherhand,nomodelcorrectlyansweredasingle
itjointlyassessestaskproficiencyandinstruction-following questionfromtheFunctionscategory. Thischallenging
ability. Furthermore,thismethodologydoesnotnecessitate categoryrequirescorrectderivationofmultipleparameters
(potentially) timely human scoring or the means to run a (e.g.thegradientandinterceptforlinearfunctions)andcor-
strongLLMevaluator. Asmentionedpreviously,whencon- rectformattingoftheoutput. Inspectionofthemodeloutput
sideringpotentialdownstreamusage,amodelisnotuseful suggests adherence to the strict output format was not an
ifitcanperformagivenreasoningtaskperfectlybutfails issue: the models were unable to correctly determine the
to reliably follow output instructions. As an ablation, we functionparameters. However, inanumberofcases, pro-
compare this strict exact matching protocol to automatic posedfunctionswereclosetothecorrectanswers,e.g.,with
evaluationusingbothclosed-sourceandopen-sourceLLMs. all parameters correct apart from one that was off by one.
Minorperturbationstothegraphappearancedidresultina
4.3.Overallresults
verysmallnumberofcorrectanswers.
WepresenttheoverallresultsonGRABinTab.3. Aclear
4.5.Evaluationprotocols
observationisthatourbenchmarkproveschallengingfor
frontier models, with low overall performances from all Inadditiontotheexactmatchingevaluationprotocol(see
models(seealsoFig. 1). Thehighestperformingmodel, Sec.4.2.3),weexploremodelperformancescoreswithmore
Claude 3.5 Sonnet, achieves a score of just 21.7%. As lenient automatic evaluation protocols. Specifically, we
expected,thehighestscoresareattainedontheProperties utilised an LLM to parse the generated output from the
task,whichincludesquestionsthatjustrequirethederiva- LMMsandextracttheanswertext,beforeevaluatingitvia
tionofasinglegraphproperty. Lowerscoresareachieved exact matching as before. We carried out this evaluation
ontheFunctionsandSeriestasks,likelyduetotheadded method using both a frontier LLM (Gemini 1.5 Pro) and
complexityofcomputingthemeanofagivenpropertyover a small open-source LLM (LLaMA 3.1 8b-instruct [24]).
multiplefunctions/series. Thereisamacro-trendofslightly DetailsofthepromptsusedcanbefoundintheAppendix.
6Accuracy(%)
Task Properties Functions Series Transforms Overall
Model (660) (710) (410) (310) (2170)
Closed-sourceLMMs
Claude3Haiku[3] 14.2 6.6 8.8 3.9 9.0
Claude3Sonnet[3] 15.3 8.6 4.5 4.8 9.2
Claude3.5Sonnet[4] 41.8 15.5 11.0 10.0 21.7
GPT-4Turbo[27] 18.5 8.5 4.9 3.5 10.0
GPT-4omini[29] 15.8 6.8 5.7 2.9 8.7
GPT-4o[28] 24.7 10.8 9.2 3.5 13.6
Gemini1.0ProVision[10] 20.2 5.8 6.9 6.1 10.5
Gemini1.5Flash[37] 28.5 11.5 8.4 9.0 15.6
Gemini1.5Pro[37] 34.2 11.4 13.3 6.5 18.1
RekaEdge[34] 11.8 8.7 11.6 1.9 9.4
RekaFlash[34] 13.2 10.1 6.3 3.9 9.3
RekaCore[34] 1.7 0.0 4.3 0.3 1.5
Open-sourceLMMs
CogVLM-Chat[43] 7.0 4.9 5.1 3.9 5.4
Qwen-VL-Chat[5] 10.2 6.6 5.1 2.9 6.8
OmniLMM-3b[32] 6.7 4.9 4.1 4.5 5.2
TransCore-M[36] 7.9 9.2 7.6 3.9 7.6
Yi-VL-6b[1] 5.6 8.6 7.1 4.2 6.7
Yi-VL-34b[1] 7.6 5.9 5.5 2.3 5.8
LLaVA-1.57b[18] 4.7 7.5 6.5 4.8 6.0
LLaVA-1.513b[18] 5.0 7.7 8.4 3.9 6.5
Table3.OverallresultsontheGRABtasks.Thehighestopenandclosed-sourcemodelscoresforeachtaskare highlighted andbold.
Accuracy(%)
Category Range Measuresof Area Intercepts& Stationary Functions Correlation Extrema Counting Trigonometric
Spread Bounded Gradients Points
Model (360) (370) (150) (290) (160) (30) (120) (360) (60) (270)
Closed-sourceLMMs
Claude3Haiku[3] 4.7 11.9 2.7 11.4 10.6 0.0 20.8 5.8 13.3 10.0
Claude3Sonnet[3] 4.7 10.0 4.0 13.8 8.1 0.0 9.2 8.9 18.3 11.9
Claude3.5Sonnet[4] 13.6 28.6 2.7 25.5 25.6 0.0 9.2 24.7 30.0 29.3
GPT-4Turbo[27] 6.7 13.0 0.0 13.1 11.9 0.0 5.0 8.6 18.3 14.8
GPT-4omini[29] 3.3 10.8 2.0 10.7 8.1 0.0 2.5 8.1 26.7 15.6
GPT-4o[28] 9.2 18.6 2.0 14.1 16.2 0.0 15.8 8.1 30.0 21.5
Gemini1.0ProVision[10] 4.7 16.2 1.3 7.9 13.1 0.0 12.5 13.1 23.3 10.4
Gemini1.5Flash[37] 11.7 18.9 2.7 16.2 16.9 0.0 8.3 22.2 25.0 16.3
Gemini1.5Pro[37] 9.4 23.2 4.7 17.9 24.4 0.0 26.7 19.4 33.3 19.3
RekaEdge[34] 2.8 9.7 3.3 10.0 8.1 0.0 38.3 4.7 18.3 13.3
RekaFlash[34] 6.7 11.6 3.3 15.5 7.5 0.0 7.5 5.3 18.3 12.6
RekaCore[34] 0.0 0.0 0.0 0.0 1.2 0.0 25.0 0.3 0.0 0.0
Open-sourceLMMs
CogVLM-Chat[43] 6.9 5.4 2.7 4.1 5.6 0.0 0.8 4.7 16.7 7.4
Qwen-VL-Chat[5] 3.6 8.6 1.3 6.6 10.6 0.0 1.7 6.7 18.3 10.4
OmniLMM-3b[32] 8.9 3.2 2.7 5.9 3.1 0.0 0.0 5.0 11.7 6.7
TransCore-M[36] 8.6 4.1 2.7 10.0 8.8 0.0 15.8 5.8 8.3 10.4
Yi-VL-6b[1] 5.0 6.5 3.3 7.9 5.6 0.0 12.5 5.6 1.7 11.5
Yi-VL-34b[1] 2.8 7.8 2.7 8.3 1.9 0.0 8.3 4.2 6.7 10.0
LLaVA-1.57b[18] 9.7 4.9 3.3 4.8 5.6 0.0 9.2 5.3 5.0 6.3
LLaVA-1.513b[18] 8.3 4.6 2.7 7.9 4.4 0.0 18.3 5.3 8.3 5.2
Table4. GRABper-categoryperformanceacrossalltasks. Thehighestopenandclosed-sourcemodelscoresforeachcategoryare
highlighted andbold.
7Exactmatching LLaMA3.1answerextraction+exactmatching Gemini1.5Proanswerextraction+exactmatching
100
75
50
25
0
Claude3 ClH aai uk du e3 ClS ao un dn eet 3.5Son Gne Pt T-4Tur Gb Po T-4o mini miG niP 1T .- 04o Pro GeVis mi io nin 1.5F Gl eas mih ni1.5Pro RekaEdge RekaFlash Reka CC oo gre VLM- QC wh eat n-VL-C Oh mat niLM M- T3 rab nsCore-M Yi-VL-6b Yi-VL- L3 L4 ab VA-1. L5 La7b VA-1.513b
Ge
Figure5.GRABaccuracywithdifferentautomaticevaluationprotocols.Performancescoresareshownforeachmodelfor(i)exact
matching,(ii)answerextractionwithanopen-sourceLLMthenexactmatching,and(iii)answerextractionwithaclosed-sourceLLMthen
exactmatching.Accuracydifferencesrelativetotheexactmatchingprotocolareannotated.
50
Claude3.5Sonnet Gemini1.5Pro GPT-4omini RekaFlash
40 alltasks alltasks alltasks alltasks
30
20
10
0
50
function
40 series
30 transform
20
10
0
0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9
Complexityscore(num.transformsoradditionalseries/functions)
Figure6.PerformanceontheFunction,SeriesandTransformstaskswithincreasingcomplexity(numberoftransformsoradditional
series/functions).Toprow:accuracyacrossall3taskswithshadedregiondisplaying95%Wilsonconfidenceintervals(eachpointonthe
plotrepresents151questions).Bottomrow:accuracypertaskdecomposition.
Basedonrandomsampling,theLLMscouldextractspecific 4.6.Complexityanalysis
answersfromverboseoutputwithhighaccuracy,however,
performed poorly when provided the correct answer and
TheFunctions,SeriesandTransformstasksweredesignedto
promptedtoactuallydeterminethecorrectnessofagiven
includequestionsspanningacontrollablecomplexityscale.
answer. Acomparisonofthedifferentevaluationprotocols
FortheFunctionsandSeriestasks,complexityreferstothe
canbefoundinFig.5. Onthewhole,thereisalmostno
numberofadditionalfunctionsorseriespresentonthegraph,
difference between the exact matching and automatic
while for the Transforms task, complexity represents the
evaluation protocols. Similarly, there is little difference
numberoftransformationsappliedtothefunction. Inboth
betweenextractionwithafrontierclosed-sourceandasmall
cases,thecomplexityscorerangesfrom0(graphswithasin-
(8Bparameter)open-sourcemodel,suggestingthisapproach
glefunctionorseriesandnotransformations)to9. InFig.6,
canfeasiblybeconductedwithlittlecompute. However,we
wepresentperformancedecomposedalongthiscomplexity
advocatefortheadoptionofexactmatchingwithoutthe
scale for a representative selection of models. Intuitively,
useofanLLMasthestandardevaluationapproachgo-
weexpectperformancetodecreaseascomplexityincreases
ingforwardsasmostmodelsareclearlyabletosufficiently
duetotheaddedchallengeofdeterminingthequantityof
followoutputinstructionsanditprovidesabettersignalof
interestfromadditionalfunctions/seriesorafteradditional
model capabilities. Cases where there are differences be-
transforms. However,thecomplexityplotsfortheevaluated
tween the performance protocols indicate models that are
modelsfollowtwodistinctpatterns. Forthebetterperform-
thepoorestinstructionfollowers.
ingmodels,suchasClaude3.5SonnetandGemini1.5Pro,
8
)%(ycaruccaBARG
)%(ycaruccA
%1.1+ %1.1+ %6.2+ %7.2+ %1.0+ %1.0- %5.4+ %8.5+
%3.0-
%3.0+ %1.0+ %1.0+ %2.0+ %3.0+ %2.0+ %1.0+performancedoesclearlydecreaseascomplexityincreases 5.Conclusions
from0to3,beforeremainingaround10%. Fortheweaker
We introduce GRAB, a GRaph Analysis Benchmark for
models,however,theresultsfluctuatearound10%acrossthe
LMMs. Weleveragesyntheticdatagenerationtocreatehigh-
entirecomplexitydomain. Inthesecases,eventhelowest
quality,difficultquestionsthatprovechallengingforfrontier
complexityquestionsaretoochallenging. Asexpected,the
LMMs, with the best-performing model attaining a score
questionsrequiringdecimalprecisionprovedmuchharder
of21.7%. OnGRAB,weevaluateasuiteof20closedand
thanintegerprecisionquestions.
open-source models, attaining a broad profile of the abili-
tiesofthecurrentgenerationofLMMs. Duringinference,
wepromptthemodelsusinglightweightpromptswithclear
4.7.Questionformat
outputformatinstructionsandassessanswercorrectnessby
comparingtheoutputstringwiththegroundtruth. Thisap-
We carry out an ablation analysing the effect of question
proachjointlyassessestheabilitiesofmodelstoperformthe
formatonmodelperformancebyre-evaluatingthequestions
GRABreasoningtasksandreliablyfollowoutputinstruc-
fromthePropertiestaskinamultiple-choicesettingwith
tions,enablingstraightforwardevaluationwithouttheneed
5 candidate answers. The results of this comparison are
forhumanorautomaticevaluationusingLLMs. Aconse-
displayedinTab.5. Multiple-choiceoptionsweregenerated
quenceofthisharshevaluationprotocolisthatsomemodels
adversariallybysamplingvaluesclosetothecorrectanswer.
commonlyregardedas‘frontier’–thatarepronetoverbose
Forthemajorityofmodels,accuracyscoresarehigherin generation–performrelativelypoorly. Wedirectlycompare
themultiple-choicesetting,andmostmodelsscoreabovethe performanceresultsusingexactmatchingevaluationwith
randomchancescore. However,thehighestattainedscore automatic LLM evaluation and find little difference, sug-
isonly32.3%,furtherreflectingthedifficultyoftheGRAB gestingmostcurrentmodelsareabletosufficientlyfollow
benchmark. For a few models, including the two leading outputinstructions,andthereforevalidatingexactmatching
models, the opposite is true. In these cases, it is possible asasuitableevaluationprotocol. Additionally,weconducta
thatthepresenceofplausibleincorrectanswers(i.e.,close seriesofstudiesrevealingthecategoriesthemodelsstruggle
tothetrueanswer)cancauseconfusionandleadthemodels withandtheimpactofdifferentquestiontypes. Werelease
tomakeincorrectselections. ourdatasetandevaluationcodebaseforthecommunityto
useandhopeourworkencouragesresearchtowardsthenext
generationsofLMMs.
Accuracy(%)
Model Single-answer Multiple-choice
Acknowledgements
Randomchance - - 20.0
Closed-sourceLMMs
ThisworkwassupportedbytheUKRICentreforDoctoral
Claude3Haiku[3] 14.2 +9.4 23.6
Claude3Sonnet[3] 15.3 +10.5 25.8 TraininginApplicationofArtificialIntelligencetothestudy
Claude3.5Sonnet[4] 41.8 -10.0 31.8 ofEnvironmentalRisks(referenceEP/S022961/1),anIsaac
GPT-4Turbo[27] 18.5 +11.3 29.8
Newton Trust grant, a research gift from Google, an EP-
GPT-4omini[29] 15.8 +12.2 28.0
GPT-4o[28] 24.7 +3.0 27.7 SRCHPCgrant,theHongKongResearchGrantCouncil-
Gemini1.0ProVision[10] 20.2 -7.5 12.7 EarlyCareerScheme(GrantNo. 27208022),andHKUSeed
Gemini1.5Flash[37] 28.5 +2.4 30.9
Fund for Basic Research. Samuel would like to acknowl-
Gemini1.5Pro[37] 34.2 -1.9 32.3
edgethesupportofZ.NovakandN.Novakinenablinghis
RekaEdge[34] 11.8 +11.5 23.3
RekaFlash[34] 13.2 +7.6 20.8 contribution.
RekaCore[34] 1.7 +5.6 7.3
Open-sourceLMMs References
CogVLM-Chat[43] 7.0 +14.1 21.1
Qwen-VL-Chat[5] 10.2 +11.3 21.5 [1] 01-ai. Yi. https://github.com/01-ai/Yi,2023. 4,
OmniLMM-3b[32] 6.7 +13.6 20.3
7,9
TransCore-M[36] 7.9 +12.9 20.8
Yi-VL-6b[1] 5.6 -1.5 4.1 [2] Reka AI. Reka AI API. https://platform.reka.
Yi-VL-34b[1] 7.6 +5.6 13.2 ai/dashboard,2024. 4
LLaVA-1.57b[18] 4.7 +14.2 18.9 [3] Anthropic. IntroducingthenextgenerationofClaude,2024.
LLaVA-1.513b[18] 5.0 +17.4 22.4 4,7,9
Table5.AccuracyonthePropertiestaskwithdifferentquestion [4] Anthropic. Claude3.5Sonnet,2024. 7,9
formats. Score differences between the formats are shown as [5] JinzeBai, ShuaiBai, ShushengYang, ShijieWang, Sinan
colouredtext. Thehighestopenandclosed-sourcemodelscores Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren
foreachformatare highlighted andbold. Zhou. Qwen-VL: A frontier large vision-language model
with versatile abilities. arXiv preprint arXiv:2308.12966,
2023. 4,7,9
9[6] RitwickChaudhry,SumitShekhar,UtkarshGupta,Pranav [20] YuliangLiu,ZhangLi,HongliangLi,WenwenYu,Mingxin
Maneriker,PrannBansal,andAjayJoshi. Leaf-qa: Locate, Huang,DezhiPeng,MingyuLiu,MingruiChen,Chunyuan
encodeandattendforfigurequestionanswering. InProceed- Li,LianwenJin,etal. Onthehiddenmysteryofocrinlarge
ingsoftheIEEE/CVFWinterConferenceonApplicationsof multimodalmodels. arXivpreprintarXiv:2305.07895,2023.
ComputerVision,pages3512–3521,2020. 2 3
[7] Charles Chen, Ruiyi Zhang, Eunyee Koh, Sungchul Kim, [21] PanLu,SwaroopMishra,TanglinXia,LiangQiu,Kai-Wei
Scott Cohen, Tong Yu, Ryan Rossi, and Razvan Bunescu. Chang,Song-ChunZhu,OyvindTafjord,PeterClark,and
Figurecaptioningwithreasoningandsequence-leveltraining. AshwinKalyan. Learntoexplain:Multimodalreasoningvia
arXivpreprintarXiv:1906.02850,2019. 2 thoughtchainsforsciencequestionanswering. Advancesin
[8] LinChen,JinsongLi,XiaoyiDong,PanZhang,YuhangZang, NeuralInformationProcessingSystems,35:2507–2521,2022.
ZehuiChen,HaodongDuan,JiaqiWang,YuQiao,Dahua 3
Lin,etal. AreWeontheRightWayforEvaluatingLarge [22] PanLu,HritikBansal,TonyXia,JiachengLiu,ChunyuanLi,
Vision-LanguageModels? arXivpreprintarXiv:2403.20330, HannanehHajishirzi,HaoCheng,Kai-WeiChang,Michel
2024. 3 Galley,andJianfengGao. Mathvista:Evaluatingmathemati-
[9] ChaoyouFu,PeixianChen,YunhangShen,YuleiQin,Meng- calreasoningoffoundationmodelsinvisualcontexts. arXiv
dan Zhang, Xu Lin, Jinrui Yang, Xiawu Zheng, Ke Li, preprintarXiv:2310.02255,2023. 3
XingSun,etal. Mme: Acomprehensiveevaluationbench- [23] Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty,
markformultimodallargelanguagemodels. arXivpreprint and Enamul Hoque. Chartqa: A benchmark for question
arXiv:2306.13394,2023. 3 answering about charts with visual and logical reasoning.
[10] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui arXivpreprintarXiv:2203.10244,2022. 2
Wu,Jean-BaptisteAlayrac,JiahuiYu,RaduSoricut,Johan [24] Meta. Meta-Llama-3.1-8B-Instruct. https://
Schalkwyk,AndrewMDai,AnjaHauth,etal. Gemini: a huggingface.co/meta-llama/Meta-Llama-3.
familyofhighlycapablemultimodalmodels. arXivpreprint 1-8B-Instruct,2024. 6
arXiv:2312.11805,2023. 4,7,9
[25] Nitesh Methani, Pritha Ganguly, Mitesh M Khapra, and
[11] Google. Vertex AI. https://cloud.google.com/
Pratyush Kumar. Plotqa: Reasoning over scientific plots.
vertex-ai/,2024. 4 InProceedingsoftheIEEE/CVFWinterConferenceonAp-
[12] TianruiGuan,FuxiaoLiu,XiyangWuRuiqiXianZongxiaLi, plicationsofComputerVision,pages1527–1536,2020. 1,
XiaoyuLiuXijunWang,LichangChenFurongHuangYaser 2
Yacoob,andDineshManochaTianyiZhou. HALLUSION-
[26] CurtisGNorthcutt,AnishAthalye,andJonasMueller. Per-
BENCH:AnAdvancedDiagnosticSuiteforEntangledLan-
vasivelabelerrorsintestsetsdestabilizemachinelearning
guage Hallucination & Visual Illusion in Large Vision-
benchmarks. arXivpreprintarXiv:2103.14749,2021. 1
LanguageModels. arXive-prints,pagesarXiv–2310,2023.
[27] OpenAI. GPT-4V(ision)SystemCard. 2023. 4,7,9
3
[28] OpenAI. HelloGPT-4o,2024. 1,4,7,9
[13] J.D.Hunter. Matplotlib:A2Dgraphicsenvironment. Com-
[29] OpenAI. GPT-4omini:advancingcost-efficientintelligence,
putinginScience&Engineering,9(3):90–95,2007. 2,4
2024. 7,9
[14] Kushal Kafle, Brian Price, Scott Cohen, and Christopher
[30] OpenAI. APIReference. https://platform.openai.
Kanan. Dvqa:Understandingdatavisualizationsviaquestion
com/docs/api-reference,2024. 4
answering. InProceedingsoftheIEEEconferenceoncom-
putervisionandpatternrecognition,pages5648–5656,2018. [31] OpenAI. simple-evals,2024. Accessed:15-05-2024. 6
2 [32] OpenBMB. OmniLMM. https://https://github.
[15] SamiraEbrahimiKahou, VincentMichalski, AdamAtkin- com/OpenBMB/OmniLMM,2024. 4,7,9
son,ÁkosKádár,AdamTrischler,andYoshuaBengio. Fig- [33] OpenCompass Contributors. OpenCompass: A Universal
ureqa:Anannotatedfiguredatasetforvisualreasoning.arXiv Evaluation Platform for Foundation Models. https://
preprintarXiv:1710.07300,2017. 1,2 github.com/open-compass/opencompass, 2023.
[16] BohaoLi,YuyingGe,YixiaoGe,GuangzhiWang,RuiWang, 6
RuimaoZhang,andYingShan. SEED-Bench-2:Benchmark- [34] AitorOrmazabal,CheZheng,CypriendeMassond’Autume,
ingMultimodalLargeLanguageModels,2023. 3 DaniYogatama,DeyuFu,DonovanOng,EricChen,Eugenie
[17] BohaoLi,RuiWang,GuangzhiWang,YuyingGe,YixiaoGe, Lamprecht,HaiPham,IsaacOng,etal.RekaCore,Flash,and
andYingShan. SEED-Bench: BenchmarkingMultimodal Edge: ASeriesofPowerfulMultimodalLanguageModels.
LLMswithGenerativeComprehension,2023. 3 arXivpreprintarXiv:2404.12387,2024. 4,7,9
[18] HaotianLiu, ChunyuanLi, YuhengLi, andYongJaeLee. [35] PiotrPadlewski,MaxBain,MatthewHenderson,Zhongkai
Improvedbaselineswithvisualinstructiontuning. InPro- Zhu,NishantRelan,HaiPham,DonovanOng,KaloyanAlek-
ceedingsoftheIEEE/CVFConferenceonComputerVision siev, Aitor Ormazabal, Samuel Phua, et al. Vibe-Eval: A
andPatternRecognition,pages26296–26306,2024. 4,7,9 hardevaluationsuiteformeasuringprogressofmultimodal
[19] YuanLiu,HaodongDuan,YuanhanZhang,BoLi,Songyang languagemodels. arXivpreprintarXiv:2405.02287,2024. 3,
Zhang,WangboZhao,YikeYuan,JiaqiWang,ConghuiHe, 6
ZiweiLiu,etal. Mmbench: Isyourmulti-modalmodelan [36] PCIResearch. TransCore-M. https://github.com/
all-aroundplayer? arXivpreprintarXiv:2307.06281,2023. 3 PCIResearch/TransCore-M,2023. 4,7,9
10[37] Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry [48] XiangYue,YuanshengNi,KaiZhang,TianyuZheng,Ruoqi
Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Liu,GeZhang,SamuelStevens,DongfuJiang,WeimingRen,
Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrit- YuxuanSun,etal. MMMU:Amassivemulti-disciplinemul-
twieser, et al. Gemini 1.5: Unlocking multimodal under- timodalunderstandingandreasoningbenchmarkforexpert
standingacrossmillionsoftokensofcontext. arXivpreprint AGI. arXivpreprintarXiv:2311.16502,2023. 3
arXiv:2403.05530,2024. 4,7,9
[38] JonathanRoberts,KaiHan,andSamuelAlbanie. SATIN:A
Appendix
multi-taskmetadatasetforclassifyingsatelliteimageryusing
vision-languagemodels. arXivpreprintarXiv:2304.11619,
WestructurethisAppendixinto4parts. In(1),weinclude
2023. 3
examplesofthepromptsusedforinferenceandLLMevalua-
[39] JonathanRoberts,TimoLüddecke,RehanSheikh,KaiHan,
tion. Then,in(2)weincludedetailsofthecomputecostsof
andSamuelAlbanie.ChartingNewTerritories:Exploringthe
geographicandgeospatialcapabilitiesofmultimodalLLMs. ourwork. Next,in(3)wepresentresultsonanOCR-based
arXivpreprintarXiv:2311.14656,2023. 3 graph analysis question set. Finally, in (4) we detail the
[40] JonathanRoberts,KaiHan,NeilHoulsby,andSamuelAl- specificversionsoftheAPImodelsusedinthiswork,aiding
banie.SciFIBench:BenchmarkingLargeMultimodalModels reproducibility.
forScientificFigureInterpretation,2024. 1,2,6
[41] NoahSiegel,ZacharyHorvitz,RoieLevin,SantoshDivvala, A.Prompts
andAliFarhadi.Figureseer:Parsingresult-figuresinresearch
papers. In Computer Vision–ECCV 2016: 14th European Inferenceprompt:
Conference,Amsterdam, TheNetherlands, October11–14,
<question>\n Only provide the answer, no
2016, Proceedings, Part VII 14, pages 664–680. Springer,
reasoning steps. If you are unsure, still
2016. 2
provide an answer. Answer:\n ’
[42] Hrituraj Singh and Sumit Shekhar. STL-CQA: Structure-
basedtransformerswithlocalizationandencodingforchart LLMevaluationprompt:
question answering. In Proceedings of the 2020 Confer-
A generative model has been asked this
enceonEmpiricalMethodsinNaturalLanguageProcessing
question: "<question>" about a plot.\n The
(EMNLP),pages3275–3284,2020. 2
output from the model answering the question
[43] WeihanWang,QingsongLv,WenmengYu,WenyiHong,Ji is: "<output>"\n Extract just the answer
Qi, YanWang, JunhuiJi, ZhuoyiYang, LeiZhao, Xixuan from the generative model output. Maintain
Song,JiazhengXu,BinXu,JuanziLi,YuxiaoDong,Ming the same precision given by the model.
Ding,andJieTang. CogVLM:VisualExpertforPretrained Convert any numbers to digits (e.g., "one"
to "1"). Remove any additional terms like
LanguageModels. arXivpreprintarXiv:2311.03079,2023.
’approximately’. Return only the extracted
4,7,9
numeric answer, without any additional text or
[44] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chau- explanation. If no answer is provided, return
mond,ClementDelangue,AnthonyMoi,PierricCistac,Tim "None".
Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam
Shleifer,PatrickvonPlaten,ClaraMa,YacineJernite,Julien B.Compute
Plu,CanwenXu,TevenLeScao,SylvainGugger,Mariama
Drame, QuentinLhoest, andAlexanderM.Rush. "Trans- Aswerestrictedthesizeofourbenchmarktojust2170,the
formers:State-of-the-ArtNaturalLanguageProcessing". In totalcomputerequiredforthisworkisrelativelylow. Neg-
Proceedingsofthe2020ConferenceonEmpiricalMethods ligiblecomputewasneededtocreatethesyntheticimages.
in Natural Language Processing: System Demonstrations, Inference with the closed-source models was carried out
pages38–45,Online,2020.AssociationforComputational viaAPIcalls. UsingasingleNVIDIAA100-80GBGPU,
Linguistics. 6
inferenceontheentireGRABbenchmarkusingLLaVA-1.5
[45] Peng Xu, Wenqi Shao, Kaipeng Zhang, Peng Gao, Shuo
7bcanbecarriedoutinapproximately30minutes,usinga
Liu, Meng Lei, Fanqing Meng, Siyuan Huang, Yu Qiao,
singleprocess(inferencetimeissignificantlyreducedwith
and Ping Luo. Lvlm-ehub: A comprehensive evaluation
multiprocessing).
benchmarkforlargevision-languagemodels. arXivpreprint
arXiv:2306.09265,2023. 3
C.OCRexperiments
[46] Zhengzhuo Xu, Sinan Du, Yiyan Qi, Chengjin Xu, Chun
Yuan,andJianGuo. Chartbench:Abenchmarkforcomplex
Weconstructasmallsetof35OCRquestionsbasedontext
visualreasoningincharts. arXivpreprintarXiv:2312.15915,
inthelegend,title,andaxislabels. Thegraphsarecreated
2023. 1,2
usingasimilarpipelinetothePropertiestaskexceptrather
[47] Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang,
KevinLin,ZichengLiu,XinchaoWang,andLijuanWang. than using purely randomly selected data generation pro-
Mm-vet:Evaluatinglargemultimodalmodelsforintegrated cesses,weuseplausibledatarangesandfunctionsforthe
capabilities. arXivpreprintarXiv:2308.02490,2023. 3 axislabel. WeleverageGPT-4Turbotoconstructadatabase
11of‘realistic’dependentandindependentvariablesalongwith • Claude3.5Sonnet:
theirranges,distributionsanddirections(e.g.linear,increas- claude-3-5-sonnet@20240620
ing).Weevaluatethesequestionsinamultiple-choicesetting • RekaEdge:
with5optionsandpresenttheresultsinTab6. Comparedto reka-edge-20240208
performanceonthePropertiestaskwithmultiple-choiceop- • RekaFlash:
tions(Tab.5),themodelsattainmuchhigherscoresonthese reka-flash-20240226
OCR-style questions, with many models achieving either • RekaCore:
100%orcloseto100%accuracy. Thesehighscoressuggest reka-core-20240501
thisparticularquestiontypeistooeasyforcurrentfrontier • Gemini-Pro:
LMMs,thereforewerefrainfromincludingitinGRAB. gemini-1.0-pro-001
Model Accuracy(%)
Randomchance 20.0
Closed-sourceLMMs
Claude3Haiku 42.9
Claude3Sonnet 91.4
Gemini1.0ProVision 100.0
Gemini1.5Flash 100.0
Gemini1.5Pro 100.0
GPT-4Turbo 97.1
GPT-4V 97.1
GPT-4o 82.9
RekaCore 97.1
RekaEdge 88.6
RekaFlash 100.0
Open-sourceLMMs
TransCore-M 80.0
Yi-VL-6b 51.4
OmniLMM-3b 65.7
Qwen-VL-Chat 71.4
Table6.AccuracyscoresonOCRexperiments.
D.APImodelversions
ThesearethespecificversionsoftheAPImodelsusedin
thiswork:
• GPT-4Turbo:
gpt-4-turbo-2024-04-09
• GPT-4omini:
gpt-4o-mini-2024-07-18
• GPT-4o:
gpt-4o-2024-05-13
• GeminiProVision:
gemini-1.0-pro-vision-001
• Gemini1.5Flash:
gemini-1.5-flash-preview-0514
• Gemini1.5Pro:
gemini-1.5-pro-preview-0514
• Claude3Haiku:
claude-3-haiku@20240307
• Claude3Sonnet:
claude-3-sonnet@20240229
12