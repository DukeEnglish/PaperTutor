Great Memory, Shallow Reasoning: Limits of kNN-LMs
ShangyiGeng WentingZhao AlexanderMRush
CornellUniversity
{sg2323, wz346, arush}@cornell.edu
Abstract Thisincreasingneedfordatatotrainlanguage
models has led to significant challenges. On one
K-nearest neighbor language models (kNN-
hand,includingasmuchhigh-qualitydataaspossi-
LMs),whichintegrateretrievalwithnext-word
bleresultsinimproveddownstreamperformance.
prediction, have demonstrated strong perfor-
Ontheotherhand, thisdataisoftenprotectedby
manceinlanguagemodelingaswellasdown-
licenses or copyright, which means training on
stream NLP benchmarks. These results have
ledresearcherstoarguethatmodelstrainedon suchdatabringslegalissues. Forexample,there-
poor quality or outdated data could perform centhigh-profilelawsuitfromtheNewYorkTimes
well by employing a kNN extension that has notes the clear use of their data in OpenAI mod-
access to a higher-quality datastore. In this els(GrynbaumandMac,2023).
work,weaskwhetherthisimprovedabilityto
It would be ideal to circumvent this issue en-
recallinformationreallytranslatesintodown-
tirelywithalternativeapproaches. Ifamodelcould
streamabilities. WeextensivelyevaluatekNN-
betrainedonlower-qualitydatabutadaptedtoper-
LMs on a diverse set of tasks, ranging from
sentimentclassificationandcommonsenserea- formwellonrealtasks,itmightprovideatechnical
soningtomulti-hopreasoning. Resultsshow workaround. Non-parametric Language Models
thatkNN-LMsexcelatmemory-intensivetasks, (NPLMs), such as kNN-LMs, have emerged as
whereutilizingthepatternsintheinputissuf- a promising approach in this space (Khandelwal
ficientfordeterminingtheoutput,butstruggle
etal.,2020). kNN-LMsextendneuralLMsbylin-
with reasoning tasks that require integrating
earlyinterpolatingwithsimplek-nearestneighbor
multiple pieces of information to derive new
LMs. Thisapproachcanimprovelanguagemodel-
knowledge. We further demonstrate through
ingwithitsmemoryoveramassivecollectionof
oracleexperimentsandqualitativeanalysisthat
evenwithperfectretrieval,kNN-LMsstillfail texts,usuallyreferredtoasadatastore. Khandelwal
to determine the correct answers, placing an etal.(2021)andShietal.(2022)validatethatkNN-
upper bound on their reasoning performance. LMs achieve better performance on downstream
Code and datastores are released at https: taskscomparedtostandardLMs. TheSILOmodel
//github.com/GSYfate/knnlm-limits/.
ofMinetal.(2024)appliesthisapproachfurther
bytrainingaLMexclusivelyonlicense-permissive
1 Introduction
data, and using a non-parametric datastore to im-
A foundational property of pretrained language provethemodelsduringinference.
modeling(Petersetal.,2018;Devlinetal.,2019) In this work, we study the limits of how kNN-
has been that improvements to the perplexity of LMscanbeusedtoimproveLLMs. Specifically,
the model lead to improvements on downstream weareinterestedinwhethertheimprovementsin
tasks. Thispropertyiscentraltothescalingoflarge perplexity seen with kNN-LMs are equivalent to
languagemodels(LLMs)whereresearchersfocus other improvements in LM ability, or if improve-
nearly exclusively on perplexity as a proxy met- mentsinnon-parametricmemoryareorthogonalto
ricforimprovedgeneralpurposeabilities(Kaplan standardlanguagemodeling. Thisquestionrelates
etal.,2020). Inrecentyears,thisresearchhascen- todebatesaboutwhethermemoryisseparablefrom
teredprimarilyonhigh-qualitytextdataatgreater other language abilities and how they interact in
and greater quantities as the limiting component NLPbenchmarks.
forproducingbetterlanguagemodels(Hoffmann Tostudythisquestion,weimplementlarge-scale
etal.,2022). kNN-LMsontopofmodernopenLLMswithtwo
4202
guA
12
]LC.sc[
1v51811.8042:viXraQuestion: When Copsi was made earl of Northumbria he went to reside in a town at the
confluence of which two rivers? The two rivers are ____
LM kNN-LM
Ouse 0.02 + founded 0.15 = founded 0.08
founded 0.01 Ouse 0.04 Ouse 0.03
• Top 1: In return, William made Copsi earl of Northumbria and sent him
back to York. Copsi's rule lasted five weeks, when he was murdered
• Top 2: York is a historic walled city at the confluence of the rivers
Ouse and Foss in North Yorkshire, England. The municipality is the
• Top 3: Two Rivers Press is an independent publishing house,
based in the English town of Reading. Two Rivers Press was founded
Figure1: Inthismulti-hopquestionanswering(QA)example,theLMisveryuncertainaboutthenextwordand
couldbenefitfromretrieval. ThekNNapproachfindsseveraldocument, bothirrelevantandrelevant, thatmay
help. However,twoissuesoccur: first,anirrelevantdocumentincreasestheprobabilityofarandomwronganswer;
second,eventhougharelevantdocumenthasbeenfound,itmaynotupweighttheactualanswer(Ouse). Westudy
howtheseissuesmayimpacttaskperformanceascomparedtoperplexity.
datastoresindifferentdomains. Wereplicatepast tasks, they often produce hallucinations, strug-
resultsthatdemonstratesignificantdecreasesinper- gle with integrating new knowledge, and expose
plexity acrossdomains. Thisperplexity decrease private information present in the training data.
transferstosimilarbenefitsintaskaccuracyacross Recently, research interest has shifted towards
severalNLPbenchmarks. Thesebenchmarksare retrieval-basedLMs,whichcombineaparametric
rather simple, where recognizing the patterns in neuralmodelandanon-parametricexternaldata-
the input and matching them with the patterns in store (Guu et al., 2020; Karpukhin et al., 2020).
memory is sufficient for determining the output. These retrieval-based LMs naturally incorporate
Werefertotheseasmemory-basedtasks. new knowledge, enhance the factuality of gener-
However, we see a different story when apply- atedtexts,andreduceprivacyconcerns(Asaietal.,
ing these models to tasks that require significant 2024). Furthermore,studies(Borgeaudetal.,2022)
reasoning ability. These tasks often require inte- have demonstrated that employing retrieval aug-
grating multiple pieces of information to derive mentationduringlarge-scalepre-trainingcanout-
new knowledge. In our experiments, the use of perform standard LMs while requiring fewer pa-
kNN-LMs does not improve performance in rea- rameters.
soning,andinfactseemstohurtreasoningability Amongretrieval-basedLMs,kNN-LMs(Khan-
acrosstaskssignificantly. Thisbehaviorisrobust delwal et al., 2020) emerge as a popular choice
andoccursevenindomainsthatareexplicitlytar- (Min et al., 2024). Unlike other retrieval models
getedbythedatastoreusedbythenon-parametric thatencodeandretrievedocuments,kNN-LMsen-
model. Theseexperimentsleadustoconcludethat code and retrieve tokens. At every token, kNN-
whilekNN-LMsmaybeusefulinsettingswhere LMs search for the k most similar tokens from
data is constrained, they should not be seen as a the datastore based on contextualized token em-
remedyforlow-qualitytrainingdata,andthatper- beddings,whicharethenturnedintoanext-token
plexityscoresshouldnotbeseenasacorollaryfor distribution. kNN-LMslinearlyinterpolatethere-
LMabilityoutsideofparametrictrainingsettings. trievedkNNdistributionwiththeoutputofabase
LM. They do not require additional training but
2 RelatedWork introducecomputationalandmemoryoverhead.
Retrieval Models Although Large Language Reasoning Retrieval. Little research has been
Models(LLMs)achievesuperhumanperformance conductedonconstructingretrievalmodelsforrea-
on a wide range of natural language processing soningtasks. Leandojo(Yangetal.,2023)investi-gatestheuseofretrieval-basedLMstoassistwith ingtheneedforhigh-qualitylicensedtrainingdata
theoremproving,andLevonianetal.(2023)exper- inLLMs. FormallykNN-LMsaredefinedas
iment with retrieving content from mathematical
(cid:89)
textbooks to generate responses to student ques- p(x 1:T;D) = p(x t+1 | x 1:t;D)
tions. Inourstudy,wecreateareasoning-specific t
(cid:89)
datastore to assist LMs in performing reasoning- = (λp (x |x ;D)+(1−λ)p(x |x ))
kNN t+1 1:t t+1 1:t
intensivetasks. t
EvaluationofkNN-LMs. WhilekNN-LMsex- Let(k i,v i)betheith(key,value)pairinD,f(·)
cel at language modeling and have demonstrated mapsatokensequencetoitscontextualrepresenta-
enhanced performance in machine translation tion,andd(·)measuresthedistancebetweentwo
(Khandelwal et al., 2021) and simple NLP tasks vectors.
(Shietal.,2022),thequestionofwhethertheyare
p (x | x ;D)
kNN t+1 1:t
thoughtful reasoners remains open. Wang et al.
(cid:88)
(2023a)demonstratethatkNN-LMsstrugglewith ∝ 1 xt+1=vi ×exp(−d(k i,f(x 1:t))).
open-ended text generation as they only provide (ki,vi)∈D
benefitsforanarrowsetoftokenpredictionsand
WhenusingaTransformerlanguagemodel,we
producelessreliablepredictionswhengenerating
define the distance metric d(·) as the squared ℓ
2
longertext. BehnamGhaderetal.(2023)showed
distance. To assemble the datastore we run the
thatwhenretrievalisconductedbasedonthesimi-
languagemodeloverallthedocumentstocollect
laritybetweenqueriesandstatements,kNN-LMs
thenecessaryhiddenstatesandcorrespondingnext
often fail to identify statements critical for rea-
word.
soning. Even when these crucial statements are
retrieved, it is challenging for kNN-LMs to ef- Experimental Setup. The hyperparameters in-
fectively leverage them to infer new knowledge. cludeλ,k,andσ. λdeterminestheweightofthe
These studies, however, are limited to a narrow datastore,andweconsiderλ ∈ {0.1,0.2,0.3}. Ad-
setoftasks. Ourworkseekstoprovideacompre- ditionally,weretrievek ∈ {1600,2048}neighbors
hensiveevaluationofthereasoningcapabilitiesof andsmooththekNNdistributionwithatempera-
kNN-LMs and provides an extensive analysis of tureσ ∈ {1,3,5,10}.
thesourcesoftheirfailures. For each inference model, we use Math and
Wikidatastoresforlanguagemodelingonthecor-
3 k-NearestNeighborLargeLanguage respondingevaluationdatasets: wikitextandmath
Models textbooks. Eachdatastorerepresentsaspecificdo-
main, and we evaluate the performance of kNN-
Non-parametric language models are variants of
LM on a domain by measuring the perplexity of
standardlanguagemodelsthatgivethemodelthe
eachevaluationdataset. Weconductagridsearch
abilitytoutilizeanadditionaldatastoreD during
to find the hyperparameters that yield the lowest
inference to determine the next word prediction,
PPLforeachdatastore. Theoptimalhyperparame-
p(x |x ;D). Thisdatastoremaybepartofthe
t+1 1...t tersforeachdatastorearelaterappliedacrossall
originaltrainingdata,dataforadaptationtoanew
downstreamtasksinourexperiments.
domain,orbeusedtoincorporatecontinualupdates
We provide eight demonstrations for GSM8K
orprotecteddata. Asthesedatastoresaretypically
and three demonstrations for BBH. For the other
quite large, this process requires a retrieval com-
datasets, we all perform zero-shot inference. We
ponentinthelooptofindthesparsesubsetofthe
present full details of the experiments in the Ap-
datastore that can best inform the current predic-
pendixA.
tion. Several popular approaches exist including
DPR(Karpukhinetal.,2020)andREALM(Guu Inference and Retrieval Models. We use
etal.,2020). Llama-2-7b (Touvron et al., 2023), Llama-3-8B
Inthiswork,wefocusonkNN-LMsduetotheir (AI@Meta, 2024), and Mistral-7B (Jiang et al.,
popularityasanapproachtodirectlyimproveLM 2023)asourinferencemodels. Foreachinference
perplexity on fixed models without a need for re- model,webuildthecorrespondingdatastores. The
training. As noted in the intro, this approach has keysarethe4096-dimensionalhiddenrepresenta-
alsobeenputforwardasamethodforcircumvent- tionsbeforethefinalMLPwhichpredictsthetokenD TextSize Tokens Mem on these tasks, we construct a datastore compris-
ing3.94Kmathematicaltextbooks,sourcedfrom
Wiki 2.2GB 610M 44G
(Wangetal.,2023b). Thesetextbookscontainboth
Math 0.6GB 200M 15G
theorems and practice questions, from which hu-
mansacquiremathematicalknowledge. Thisdatas-
Table 1: Overview of the two datastores. Tokens are
toreconsistsof200Mtokens. Wewillrefertothis
producedbyLlama2tokenizers. Memisthememory
datastoreasMath. Wesummarizethestatisticsof
sizeofthedatastore.
eachdatastoreinTable1.
WebeginbyvalidatingpastresultsofkNN-LMs
LMPerformance
on language modeling. We present results in Ta-
Model Wiki Math
ble 2. To facilitate meaningful comparisons be-
Llama2-7b 10.63 7.90
tweenmodelswithdifferenttokenizersandvocabu-
+Wiki 9.74 8.75
larysizes,wereportword-levelperplexities. These
+Math 11.33 7.23
resultsshowthathavingaccesstoanon-parametric
Llama-3-8b 9.70 5.36 datastore leads to lower perplexity compared to
+Wiki 9.32 6.03 using a standalone LM across all datasets. This
+Math 10.37 5.22 improvement in perplexity is observed when the
corpususedtoconstructthedatastoreandtheone
Mistral-7B 9.72 5.64
usedforinferencesharethesamedatasource. For
+Wiki 9.29 6.41
instance,sincethetrainingsplitofWikitext103is
+Math 10.49 5.59
inWiki,theLM+Wikisettingachievesthelowest
perplexityonWikitext103’svalidationset. Utiliz-
Table2:Perplexitycomparison.Rowsvarythedatastore
ingtheotherdatastoreresultsinperformanceworse
Dused. Columnsrepresentdifferentheld-outtestsets.
thanthatofthestandaloneLM.
Lowernumbersindicatebetterperformance.
5 kNN-LMsCanHelpMemory-Intensive
distribution at each generation step, produced by Tasks
executing forward passes over the datastore cor-
Webeginbylookingatasetofmemory-intensive
pora. For efficient similarity search, we create a
tasks, which we believe can be solved by pattern
FAISSindex(Johnsonetal.,2019)andsearchfor
matchingatscalewithoutcomplexreasoning. We
nearest-neighbortokensusingEuclideandistance.
incorporatethreetypesoftasks: sentimentclassi-
Duetothescaleofthedatastores,weperformap-
fication, which aims to predict whether the senti-
proximatesearchinsteadofexactsearch. Webase
mentofatextispositiveornegative;textualentail-
our implementation on RetoMaton (Alon et al.,
ment,whichassessestherelationshipbetweentwo
2022).
sentences,determiningifitconstitutesentailment,
4 kNN-LMsHelpIn-DomainPerplexity contradiction,orneutrality;andtopicclassification,
whichinvolvesidentifyingthemaintopicofatext.
Toexplorehowdifferentsourcesofexternalknowl-
Thedatasetsincludedforthesetasksareasfollows:
edgeimpactdownstreamtaskperformance,weex-
perimentwithtwodatastores. First,wefollowthe • For sentiment classification, we include SST-2
choicemadebyShietal.(2022),wheretheyiden- (Socheretal.,2013),moviereview(MR)(Pang
tify heterogeneous data sources that are broadly andLee,2005),customerreview(CR)(Huand
relevanttocommondownstreamNLPtasks. Inpar- Liu,2004),RottenTomatoes(RT),andavariant
ticular,theymixWikitext103(Merityetal.,2017), ofhyperpartisannewsdetection(HYP)(Kiesel
withothersourcesincludingtheEnglishportionof etal.,2019).
AmazonReview(HeandMcAuley,2016),andCC-
• Fortextualentailment,weuseCommitmentBank
NEWS(Hamborgetal.,2017)andIMDB(Maas
(CB)(DeMarneffeetal.,2019)andRecognizing
etal.,2011). WecallthisdatastoreWiki.
TextualEntailment(RTE)(Daganetal.,2010).
Then, we hypothesize that the commonly ex-
ploredcorporaforbuildingdatastoresdonotcon- • Fortopicclassification,ourdatasetsareAGNews
tain relevant knowledge to assist with math rea- (AGN)(Zhangetal.,2015)andYahoo! Answers
soning tasks. To maximize the performance gain (Yahoo)(Zhangetal.,2015).RTE RT CB Yahoo CR AGN HYP MR SST2
Llama2-7B 66.06 79.74 50.00 59.37 74.55 81.30 64.15 83.10 84.02
+Wiki 66.43 79.46 51.79 58.83 76.95 81.46 64.15 82.85 84.68
+Math 65.70 82.55 51.79 59.10 73.70 81.79 50.39 82.90 84.62
Llama3-8B 70.76 79.46 64.29 58.87 79.10 79.17 59.30 83.80 86.54
+Wiki 61.37 79.55 71.43 58.93 80.45 79.33 59.30 83.50 87.04
+Math 70.76 77.39 66.07 56.83 79.40 80.11 59.30 84.30 87.10
Mistral-7B 76.17 75.32 71.43 56.63 81.90 73.57 56.59 79.35 81.82
+Wiki 76.17 75.05 67.86 56.63 82.15 73.55 56.78 79.30 81.77
+Math 76.17 75.05 75.00 56.63 81.85 73.59 56.78 79.10 81.77
Table3: Accuracycomparisononvariousmemory-intensivetasks.
Forclassificationandmultiple-choicequestion- • For commonsense reasoning, we examine Hel-
answering (QA) tasks, we utilize Domain Con- laSwag (Zellers et al., 2019) and Winogrande
ditional Pointwise Mutual Information (DCPMI) (Sakaguchietal.,2021),whichtestthemodel’s
(Holtzman et al., 2021) to predict answers. We understandingofsocialnormsandphysicallaws.
thencalculateaccuracymetricstocompareperfor-
mance across different models. We measure the • For mathematical reasoning, we utilize DROP
performanceusingF1scoresatthetokenlevelfor (Duaetal.,2019),GSM8K(Cobbeetal.,2021),
text generation. Additionally, whenever feasible, andBigBenchHard(BBH)(Suzgunetal.,2022)
we employ fuzzy verbalizers (Shi et al., 2022) to to evaluate the model’s capacity for complex
maximizetheperformanceofkNN-LMs. arithmetic, logical deductions, and handling of
The results of these tasks are summarized in discreteconcepts.
Table 3. On these tasks, kNN-LMs exhibit im-
proved performance. Incorporating an external Wepresenttheresultsforknowledge-intensive
datastore outperforms a standalone LM on eight tasks in Table 6. In stark contrast to the earlier
datasets while showing comparable performance findings,usingastandaloneLMconsistentlyout-
ontheremainingdataset. Wefurtherexplainthis performskNN-LMsonthesetasks. Mostsurpris-
performance gap through qualitative analysis in ingly,onNaturalQuestionsandHotpotQA,which
AppendixB. consist of QA pairs constructed from Wikipedia
documents, performance does not improve even
6 kNN-LMsHurt ReasoningPerformance
though Wiki contains several million Wikipedia
tokens. RetrievingfromWikileadstoathree-point
For reasoning tasks, we consider three types:
decreaseinperformance.
knowledge-intensivereasoning,whichfocuseson
Resultsforcommonsensereasoningandmathe-
utilizingworldknowledgeformaking(potential)
maticalreasoningtasksareshowninTable5. The
multi-hop inferences; commonsense reasoning,
standaloneLMonceagainoutperformskNN-LMs
which involves leveraging commonsense knowl-
modelsonfouroutofthefivedatasets. Themost
edgetounderstandsocialandphysicalinteractions;
significant differences in performance occur on
andmathematicalreasoning,whichincludesarith-
GSM8K.Althoughincorporatinganexternaldata
metic,logical,anddiscretereasoningabilities. The
store results in a slight performance increase on
datasetsselectedforthesecategoriesareasfollows:
Mistral,thisdoesnotdemonstratetheeffectiveness
• Forknowledge-intensivereasoning,weexplore ofkNN-LMsonGSM8K.UnderMistral’sparame-
Natural Questions (NQ) (Kwiatkowski et al., tersettings,kNN-LMshasminimalchangesonthe
2019),HotpotQA(Yangetal.,2018),ARCEasy predictionsofthestandaloneLM,merelyintroduc-
andChallenge(Clarketal.,2018),OpenbookQA ingsomerandomness. Finally,althoughkNN-LMs
(OBQA) (Mihaylov et al., 2018), and MMLU do not improve GSM8K and Drop over standard
(Hendrycks et al., 2020) to assess the model’s LMs,wefindthatretrievingfromMathimproves
abilitytoapplyextensiveworldknowledge. overretrievingfromWiki.NQ HotpotQA Arc-Challenge Arc-Easy OBQA MMLU
Llama2-7B 23.18 22.72 41.81 57.49 57.00 39.22
+Wiki 22.53 22.53 38.31 57.41 56.20 38.68
+Math 21.14 21.26 41.04 56.82 56.20 38.53
Llama3-8B 23.64 25.14 44.88 58.83 55.80 42.67
+Wiki 24.00 24.48 43.94 58.59 53.80 42.32
+Math 23.04 24.63 43.26 58.59 54.60 42.46
Mistral-7B 20.63 20.96 46.42 60.94 58.80 41.91
+Wiki 20.58 20.80 46.16 60.61 57.40 41.80
+Math 20.56 20.48 46.08 60.77 57.80 41.55
Table4: Performancecomparisonondatasetsforknowledge-intensivereasoningtasks.
Winogrande HellaSwag DROP GSM8K BBH
Llama2-7B 69.37 64.46 32.39 14.83 30.69
+Wiki 70.32 63.67 32.14 12.05 32.08
+Math 68.98 63.54 32.31 13.48 30.82
Llama3-8B 73.95 65.99 45.55 45.72 39.67
+Wiki 73.95 64.71 45.02 44.28 39.01
+Math 74.19 65.15 45.54 45.63 39.92
Mistral 74.19 69.08 46.93 36.30 43.37
+Wiki 74.66 68.21 46.69 36.45 42.69
+Math 73.64 68.11 46.38 36.60 43.09
Table5: Performancecomparisonondatasetsforotherreasoningtasks.
Perplexity Accuracy amples,wefindthefollowingpatternsthatprevent
kNN-LMfromretrievingthecorrecttoken.
LM 255.76 55.80
OBQA
kNN-LM 9.41 95.60
• kNN-LMsstrugglewithmulti-hopreasoning
LM 112.56 23.64
NQ
kNN-LM 8.91 46.40 questions. When the task requires extracting
LM 158.26 25.14
HotpotQA multiplepiecesofsentencesfromthecorpusand
kNN-LM 8.15 49.85
thencombiningtheinformationtoinferthean-
Table 6: Results in an oracle setting where the kNN- swer, kNN-LMs often retrieve tokens that are
LMsalwaysincludethecorrectanswerasoneofthek contextuallyappropriateandrelevanttopartof
nearestneighbors. thequestion,ratherthanthecorrectanswer. As
shown in Table 7, for the multi-hop reasoning
question from HotpotQA, the model needs to
7 Analysis
identify an actor who both starred in Stargate
TheresultsofthisworkshowthatkNN-LMsgen- SG-1andguest-starredinTwinPeaks. Whilethe
erally hurt reasoning of models, despite helping requiredinformationisavailableinWikipedia,it
perplexityandothersimplertasks. Inthissection, isdistributedacrosstwoparagraphs. kNN-LMs
weinvestigatethecauseofthisfurther. retrieveonlytheactorsfromStargateSG-1,fail-
ingtocombineinformationfromtwosourcesto
Qualitative Analysis. We conduct qualitative
performaccuratemulti-hopreasoning.
analysis to understand the failures of kNN-LMs
better. In the qualitative analysis, we inspect ex- • kNN-LMsaresensitivetothesyntaxbutnot
amplesofknowledge-intensiveandmathematical thesemanticsofthequestion. WhilekNN-LM
reasoningdatasetsandshowtheretrievedtokensas retrieves the next token that fits the context, it
wellastheproceedingcontext. Throughtheseex- cannot distinguish subtle semantic differencesHotpotQAExample Label LMPred
WhichAmericancharacteractorwhostarredonthetelevisionseries“StargateSG-1”
DonS.Davis DonS.Davis
(1997–2007)andappearedin“Episode8”of“TwinPeaks”asagueststar?
RetrievedContext Token kNN-LMPred
•AfterthefirstthreeseasonsofStargateSG-1hadbeenfilmedon16mmfilm
(althoughscenesinvolvingvisualeffectshadalwaysbeenshoton35mmfilmfor
Christopher
varioustechnicalreasons),“Nemesis”wasthefirstepisodefilmedentirelyon35mm
film...“Nemesis”wasthelastepisodebeforeactor
•“200”wonthe2007ConstellationAwardforBestOverall2006ScienceFiction
MichaelShanks
FilmorTelevisionScript,andwasnominatedforthe2007HugoAwardforBest
Jack
DramaticPresentation,ShortForm.Theepisodealsomarksthefirsttimeoriginal
SG-1member
• Season one regular cast members included Richard Dean Anderson, Amanda
Michael
Tapping,
Table7: AmultihopreasoningexamplefromHotpotQAwithpredictionsofthestandardLMandkNN-LMs.
NQExample Label LMPred
whoisthelargestsupermarketchainintheuk? Tesco Tesco
Retrievedcontext Token kNN-LMPred
• The majority of stores will open as normal across the UK, however Sainsbury’s advise
shopperstocheckdetailsofwhenyourlocalbranchassomemaycloseearlierthannormal Asda
usingtheonlinestorelocatortool.(Image:Bloomberg)Supermarketgiant
•AlongwithLidl,AldihaseatenawayatthemarketshareoftheBigFoursupermarkets: Tesco Asda
•buyone,getonefree(BOGOF)offershavebeencriticisedforencouragingcustomersto
purchasefooditemsthatareeventuallythrownaway;aspartofitsowncampaignonfood Morris
waste,supermarketretailer
Table8: Aknowledge-intensivereasoningexamplefromNaturalQuestionswithpredictionsofthestandardLM
andkNN-LMs.
betweendifferentwordsinasentence. Asare- asshowninTable10.
sult, when more than one word fits the context,
it may not select the correct answer. Table 8
Is the problem a failure of model weighting?
demonstratesthisissuewithanexamplefromthe
Weinvestigatewhetherdegradedreasoningcapa-
NQdataset. EventhoughAsdaisnotthelargest
bilitiesofkNN-LMsstemfromafailureinchoos-
supermarketintheUK,duetothehighlysimilar
ingagoodweightingλ. Thisexperimentaimsto
contextsof‘supermarketgiant’and‘thelargest
analyze kNN-LMs’ behaviors when λ is optimal
supermarket,kNN-LMsultimatelyassignahigh
forthedownstreamtask. Specifically,wedirectly
probabilitytoAsdaandmakeawrongprediction.
search for λ that maximizes the log probabilities
of a small set of labeled downstream task exam-
• kNN-LMstendtoretrievehigh-frequencyen-
ples. WeconductthisexperimentonOpenbookQA
titiesinthecorpus. Theentitiesareoftenproper
andHotpotQA.Weenumeratethroughretrieving
nouns like person names and locations. If part
k ∈ {16,32,64,128,256,512,1024,2048}neigh-
oftheansweroverlapswiththesehigh-frequency
borsandsettingtemperatureσ ∈ {1,2,5,10}. We
propernouns,kNN-LMswillretrievethemand
retrieve from Wiki. We initialize λ at 0.5, and as
makewrongpredictions,asshowninTable9and
theoptimizationproceeds,wefindthatsmallerλ
Table14.
values correlate with lower loss. Ultimately, we
• kNN-LMs fail at mathematical reasoning arrive at the minimum loss when λ is close to 0.
tasks. Forinstance, intheobjectcountingtask This process suggests that without any interpola-
from the BBH dataset, even though kNN-LM tionofthekNNdistribution,thecorrectlabelsof
understandsthecontextthatitneedstoretrieve the provided demonstrations receive the highest
a number as the next token, it cannot solve the logprobability. Therefore,OpenbookQAandHot-
complex task of first identifying which objects potQAareunlikelytobenefitfromhavingsimple
aremusicalinstrumentsandthencountingthem, kNNaccesstoWiki.HotpotQAExample Label LMPred
Whattypeofplaneisthefourengineheavybomber,firstintroducedin AmericanBoeingB- The B-17 Flying
1938fortheUnitedStatesArmy,whichishangaredatConroeNorth 17FlyingFortress Fortress
HoustonRegionalAirport?
Retrievedcontext Token kNN-LMPred
•AfamoussymbolofthecourageandsacrificesmadebyAmerican
bombercrewsduringWorldWarIIwasrevealedMay16attheNational
17
MuseumoftheU.S.AirForce,Wright-PattersonAirForceBase,Ohio.
ThemeticulouslyrestoredB-
•AstheAvengermadeitswaytothetowerarea,thewingsbeganto TheB-25Mitchell.
25
foldup,amaneuverwhichenabledmoreofitskindtobeloadedsideby
sideintoaircraftcarriers.ThequeenoftheeventwastheB-
•Springishere,sowhynothopaplaneandgrabsomelunch? Even
25
betterifaWorldWarII-eraB-
Table9: ExamplefromHotpotQAshowingtheimpactofhigh-frequencypropernounsinthecorpusonkNN-LMs
predictionsretrievingfromWikipedia.
MathematicalReasoningExample Label LMPred
Ihavethreeviolins,threetrombones,aflute,andfourtrumpets. How
11 11
manymusicalinstrumentsdoIhave?
RetrievedContext Token kNN-LMPred
•Inthisexample,theoptimalroutewouldbe:1->3->2->4->1,with 10
atotalcompletiontimeof
•Howmanydifferentpasswordsarethereforhiswebsitesystem?How 10 10
doesthiscomparetothetotalnumberofstringsoflength
•UsingtheTSP,themostefficientorderinwhichtoschedulethesetasks 14
wouldbe:2->3->1->4->2,withatotalcompletiontimeof
Table10: AmathematicalreasoningexamplefromBBHrequiringobjectcountingwithpredictionsofthestandard
LMandkNN-LMs.
Is the problem a failure of retrieval? We in- 8 Conclusions
vestigatewhetherdegradedreasoningcapabilities
ofkNN-LMsstemfromafailureinretrieval. We We investigate whether the improved perplexity
examine kNN-LMs’ behaviors when retrieval is observed in kNN-LMs models can be translated
into enhanced reasoning capabilities. We con-
perfect. To achieve perfect retrieval, we include
thecorrectansweramongthek nearestneighbors. ductextensiveevaluationacross22datasets. Our
findings indicate that while kNN-LMs improve
Specifically, we construct a datastore for Open-
perplexity and can achieve better performance
bookQA,NQ,andHotpotQA,respectively,includ-
on memory-intensive tasks, they struggle with
ing their train and test examples. We then exam-
reasoning-intensive tasks, showing a disconnect
inebothperplexityandaccuracy. Theresults,pre-
sentedinTable6,indicatethatwhilekNN-LMscan betweenLMabilityandtaskability. Furtherqual-
itativeanalysisrevealsthatevenwhenkNN-LMs
significantlyreducetheperplexity,themodeldoes
producecorrectanswers,theseareoftentheresult
not always derive the correct answer, even when
ofspuriouscorrelationsratherthanactualreason-
thecorrectanswerisexplicitlygivenasoneofthe
k neighbors. Therefore, the failure of reasoning ing. Webelievethisplacesanupperboundonthe
usefulnessoftheseapproachescomparedtoresults
cannotbefullyattributedtothefailureofretrieval.
fromparametricmodels.
However,perfectretrievaldoesimproveLMbya
largemargin,suggestingthatbetterretrievalisben-
Limitations
eficial. Currently,retrievalisperformedbyfinding
similar hidden representations. A training-based
As we are limited by computing budget, we only
approachsuchasRAG(Lewisetal.,2020)hasthe
builddatastoresupto610milliontokens. Itisun-
potentialtoimproveretrievalsubstantially.
likelyalthoughnotimpossiblethatlargerdatastores
built on general web corpus like C4 will lead tobetterreasoningcapabilities. Additionally,weonly Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
experimentwithLLMswithseven-toeight-billion Roth. 2010. Recognizing textual entailment: Ra-
tional,evaluationandapproaches–erratum. Natural
modelparametersasthebasemodels. Thefindings
LanguageEngineering,16(1):105–105.
inthispapermaynotgeneralizetoother,possibly
larger,basemodels. Marie-CatherineDeMarneffe,MandySimons,andJu-
dithTonhauser.2019. Thecommitmentbank: Inves-
Acknowledgements tigatingprojectioninnaturallyoccurringdiscourse.
InproceedingsofSinnundBedeutung, volume23,
This work was supported by NSF IIS-1901030, pages107–124.
NSFCAREER2037519,andtheIARPAHIATUS
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Program.
Kristina Toutanova. 2019. BERT: Pre-training of
deepbidirectionaltransformersforlanguageunder-
standing. InProceedingsofthe2019Conferenceof
References
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
AI@Meta.2024. Llama3modelcard.
nologies,Volume1(LongandShortPapers),pages
4171–4186,Minneapolis,Minnesota.Associationfor
UriAlon,FrankXu,JunxianHe,SudiptaSengupta,Dan
ComputationalLinguistics.
Roth,andGrahamNeubig.2022. Neuro-symbolic
language modeling with automaton-augmented re-
trieval. In International Conference on Machine DheeruDua,YizhongWang,PradeepDasigi,Gabriel
Learning,pages468–485.PMLR. Stanovsky,SameerSingh,andMattGardner.2019.
DROP:Areadingcomprehensionbenchmarkrequir-
Akari Asai, Zexuan Zhong, Danqi Chen, Pang Wei ingdiscretereasoningoverparagraphs. InProceed-
Koh, Luke Zettlemoyer, Hannaneh Hajishirzi, and ingsofthe2019ConferenceoftheNorthAmerican
Wen-tau Yih. 2024. Reliable, adaptable, and at- Chapter of the Association for Computational Lin-
tributable language models with retrieval. arXiv guistics: HumanLanguageTechnologies,Volume1
preprintarXiv:2403.03187. (LongandShortPapers),pages2368–2378.Associa-
tionforComputationalLinguistics.
Parishad BehnamGhader, Santiago Miret, and Siva
Reddy. 2023. Can retriever-augmented language MichaelMGrynbaumandRyanMac.2023. Thetimes
modelsreason?theblamegamebetweentheretriever sues openai and microsoft. The New York Times,
andthelanguagemodel. InFindingsoftheAssoci- pagesB1–B1.
ationforComputationalLinguistics: EMNLP2023,
pages15492–15509.AssociationforComputational KelvinGuu,KentonLee,ZoraTung,PanupongPasu-
Linguistics. pat,andMingweiChang.2020. Retrievalaugmented
languagemodelpre-training. InInternationalconfer-
SebastianBorgeaud,ArthurMensch,JordanHoffmann,
enceonmachinelearning,pages3929–3938.PMLR.
TrevorCai,ElizaRutherford,KatieMillican,George
vandenDriessche, Jean-BaptisteLespiau, Bogdan
FelixHamborg,NormanMeuschke,CorinnaBreitinger,
Damoc,AidanClark,DiegodeLasCasas,Aurelia
andBelaGipp.2017. news-please: Agenericnews
Guy, Jacob Menick, Roman Ring, Tom Hennigan,
crawlerandextractor. InProceedingsofthe15thIn-
SaffronHuang,LorenMaggiore,ChrisJones,Albin
ternationalSymposiumofInformationScience,pages
Cassirer, AndyBrock,MichelaPaganini, Geoffrey
218–223.
Irving, Oriol Vinyals, Simon Osindero, Karen Si-
monyan,JackW.Rae,ErichElsen,andLaurentSifre.
RuiningHeandJulianMcAuley.2016. Upsanddowns:
2022. Improvinglanguagemodelsbyretrievingfrom
Modelingthevisualevolutionoffashiontrendswith
trillionsoftokens. InInternationalConferenceon
one-classcollaborativefiltering. Inproceedingsof
Machine Learning, ICML 2022, 17-23 July 2022,
the25thinternationalconferenceonworldwideweb,
Baltimore,Maryland,USA,volume162,pages2206–
pages507–517.
2240.PMLR.
PeterClark,IsaacCowhey,OrenEtzioni,TusharKhot, DanHendrycks,CollinBurns,StevenBasart,AndyZou,
AshishSabharwal,CarissaSchoenick,andOyvind MantasMazeika,DawnSong,andJacobSteinhardt.
Tafjord. 2018. Think you have solved question 2020. Measuringmassivemultitasklanguageunder-
answering? try arc, the ai2 reasoning challenge. standing. arXivpreprintarXiv:2009.03300.
arXiv:1803.05457v1.
Jordan Hoffmann, Sebastian Borgeaud, Arthur Men-
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, sch, Elena Buchatskaya, Trevor Cai, Eliza Ruther-
MarkChen,HeewooJun,LukaszKaiser,Matthias ford, Diego de Las Casas, Lisa Anne Hendricks,
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Johannes Welbl, Aidan Clark, et al. 2022. Train-
Nakano,etal.2021. Trainingverifierstosolvemath ingcompute-optimallargelanguagemodels. arXiv
wordproblems. arXivpreprintarXiv:2110.14168. preprintarXiv:2203.15556.AriHoltzman,PeterWest,VeredShwartz,YejinChoi, Xing.2023. Retrieval-augmentedgenerationtoim-
andLukeZettlemoyer.2021. Surfaceformcompeti- provemathquestion-answering: Trade-offsbetween
tion:Whythehighestprobabilityanswerisn’talways groundednessandhumanpreference. arXivpreprint
right. InProceedingsofthe2021ConferenceonEm- arXiv:2310.03184.
pirical Methods in Natural Language Processing,
pages 7038–7051. Association for Computational PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
Linguistics. Petroni,VladimirKarpukhin,NamanGoyal,Hein-
richKüttler, MikeLewis, Wen-tauYih, TimRock-
MinqingHuandBingLiu.2004. Miningandsumma- täschel,etal.2020. Retrieval-augmentedgeneration
rizingcustomerreviews. InProceedingsofthetenth forknowledge-intensivenlptasks. AdvancesinNeu-
ACMSIGKDDinternationalconferenceonKnowl- ralInformationProcessingSystems,33:9459–9474.
edgediscoveryanddatamining,pages168–177.
Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Albert Q Jiang, Alexandre Sablayrolles, Arthur Men- DanHuang, AndrewY.Ng, andChristopherPotts.
sch,ChrisBamford,DevendraSinghChaplot,Diego 2011. Learningwordvectorsforsentimentanalysis.
delasCasas,FlorianBressand,GiannaLengyel,Guil- In Proceedings of the 49th Annual Meeting of the
laumeLample,LucileSaulnier,etal.2023. Mistral AssociationforComputationalLinguistics: Human
7b. arXivpreprintarXiv:2310.06825. Language Technologies, pages 142–150, Portland,
Oregon, USA. Association for Computational Lin-
JeffJohnson,MatthijsDouze,andHervéJégou.2019. guistics.
Billion-scale similarity search with GPUs. IEEE
TransactionsonBigData,7(3):535–547. StephenMerity,CaimingXiong,JamesBradbury,and
RichardSocher.2017. Pointersentinelmixturemod-
JaredKaplan,SamMcCandlish,TomHenighan,TomB els. InInternationalConferenceonLearningRepre-
Brown,BenjaminChess,RewonChild,ScottGray, sentations.
AlecRadford,JeffreyWu,andDarioAmodei.2020.
Scaling laws for neural language models. arXiv TodorMihaylov,PeterClark,TusharKhot,andAshish
preprintarXiv:2001.08361. Sabharwal.2018. Canasuitofarmorconductelec-
tricity? anewdatasetforopenbookquestionanswer-
VladimirKarpukhin,BarlasOguz,SewonMin,Patrick ing. InEMNLP.
Lewis,LedellWu,SergeyEdunov,DanqiChen,and
Wen-tauYih.2020. Densepassageretrievalforopen- Sewon Min, Suchin Gururangan, Eric Wallace, Wei-
domainquestionanswering. InProceedingsofthe jia Shi, Hannaneh Hajishirzi, Noah A. Smith, and
2020ConferenceonEmpiricalMethodsinNatural Luke Zettlemoyer. 2024. SILO language models:
LanguageProcessing(EMNLP),pages6769–6781, Isolatinglegalriskinanonparametricdatastore. In
Online.AssociationforComputationalLinguistics. The Twelfth International Conference on Learning
Representations.
UrvashiKhandelwal,AngelaFan,DanJurafsky,Luke
Zettlemoyer,andMikeLewis.2021. Nearestneigh- BoPangandLillianLee.2005. Seeingstars: exploiting
bormachinetranslation. In9thInternationalConfer- classrelationshipsforsentimentcategorizationwith
enceonLearningRepresentations,ICLR2021,Vir- respecttoratingscales. InProceedingsofthe43rd
tualEvent,Austria,May3-7,2021.OpenReview.net. AnnualMeetingonAssociationforComputational
Linguistics,ACL’05,page115–124.Associationfor
UrvashiKhandelwal,OmerLevy,DanJurafsky,Luke ComputationalLinguistics.
Zettlemoyer,andMikeLewis.2020. Generalization
throughmemorization: Nearestneighborlanguage MatthewE.Peters,MarkNeumann,MohitIyyer,Matt
models. In International Conference on Learning Gardner,ChristopherClark,KentonLee,andLuke
Representations. Zettlemoyer.2018. Deepcontextualizedwordrepre-
sentations. InProceedingsofthe2018Conferenceof
JohannesKiesel,MariaMestre,RishabhShukla,Em- theNorthAmericanChapteroftheAssociationfor
manuel Vincent, Payam Adineh, David Corney, ComputationalLinguistics: HumanLanguageTech-
Benno Stein, and Martin Potthast. 2019. Semeval- nologies,Volume1(LongPapers),pages2227–2237,
2019task4: Hyperpartisannewsdetection. InPro- NewOrleans,Louisiana.AssociationforComputa-
ceedingsofthe13thInternationalWorkshoponSe- tionalLinguistics.
manticEvaluation,pages829–839.
KeisukeSakaguchi,RonanLeBras,ChandraBhagavat-
TomKwiatkowski, JennimariaPalomaki, OliviaRed- ula,andYejinChoi.2021. Winogrande: Anadver-
field,MichaelCollins,AnkurParikh,ChrisAlberti, sarialwinogradschemachallengeatscale. Commu-
DanielleEpstein,IlliaPolosukhin,JacobDevlin,Ken- nicationsoftheACM,64(9):99–106.
tonLee,etal.2019. Naturalquestions: abenchmark
forquestionansweringresearch. Transactionsofthe Weijia Shi, Julian Michael, Suchin Gururangan, and
Association for Computational Linguistics, 7:453– LukeZettlemoyer.2022. Nearestneighborzero-shot
466. inference. InProceedingsofthe2022Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing,
ZacharyLevonian,ChengluLi,WangdaZhu,Anoushka pages 3254–3265. Association for Computational
Gade,OwenHenkel,Millie-EllenPostle,andWanli Linguistics.Richard Socher, Alex Perelygin, Jean Wu, Jason Corpus TextSize Tokens
Chuang,ChristopherD.Manning,AndrewNg,and
ChristopherPotts.2013. Recursivedeepmodelsfor Wikitext103 0.5GB 140M
semanticcompositionalityoverasentimenttreebank. Amazon 0.07GB 18M
In Proceedings of the 2013 Conference on Empiri-
CC-NEWS 1.6GB 443M
calMethodsinNaturalLanguageProcessing,pages
IMDB 0.03GB 8M
1631–1642.AssociationforComputationalLinguis-
tics. Total 2.2GB 609M
Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se- Table 11: Statistics of each data source in the Wiki
bastian Gehrmann, Yi Tay, Hyung Won Chung, datastore.
AakankshaChowdhery,QuocVLe,EdHChi,Denny
Zhou,etal.2022. Challengingbig-benchtasksand
whether chain-of-thought can solve them. arXiv A MoreImplementationDetails
preprintarXiv:2210.09261.
Table11presentsthedatasourcesoftheWikidata-
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- store. Table12showshyperparametersweusefor
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
differenttasks.
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale, et al. 2023. Llama 2: Open founda-
B MoreQualitativeAnalysis
tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288.
We explain why retrieving from Math improves
LMs on sentiment analysis. First, we consider a
ShufanWang,YixiaoSong,AndrewDrozdov,Aparna
Garimella, Varun Manjunatha, and Mohit Iyyer. sentiment analysis example in Table 13. In this
2023a. kNN-LMdoesnotimproveopen-endedtext task,givenasentence,amodelisrequiredtopre-
generation. InProceedingsofthe2023Conference
dictwhetherthesentimentexpressedispositiveor
onEmpiricalMethodsinNaturalLanguageProcess-
negative. The sentence in the example expresses
ing,pages15023–15037.AssociationforComputa-
tionalLinguistics. a positive sentiment; however, Llama-2 predicts
thesentimenttobenegative. kNN-LMs,whenre-
ZengzhiWang,RuiXia,andPengfeiLiu.2023b. Gen- trieving from Wiki, fail to find sentiment-related
erativeaiformath: Parti–mathpile: Abillion-token-
tokens, and hence also predict a negative senti-
scale pretraining corpus for math. arXiv preprint
ment. Performing retrieval from Math produced
arXiv:2312.17120.
thecorrectsentiment. However,thisismorecoin-
Kaiyu Yang, Aidan Swope, Alex Gu, Rahul Chala- cidentalratherthanreflectiveofthemodel’scapa-
mala,PeiyangSong,ShixingYu,SaadGodil,Ryan bility, because, although the retrieved tokens dis-
Prenger,andAnimaAnandkumar.2023. LeanDojo:
playapositivesentiment,theretrievedcontextsare
Theoremprovingwithretrieval-augmentedlanguage
models. InNeuralInformationProcessingSystems not relevant to the test example. we observe that
(NeurIPS). sentiment-relatedcontentisubiquitous,regardless
ofthesourceweusetobuildthedatastore. Even
ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,
in math textbooks, we find many sentences that
WilliamCohen,RuslanSalakhutdinov,andChristo-
expresssentiment.
pher D. Manning. 2018. HotpotQA: A dataset for
diverse, explainablemulti-hopquestionanswering.
In Proceedings of the 2018 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
2369–2380.AssociationforComputationalLinguis-
tics.
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali
Farhadi, and Yejin Choi. 2019. HellaSwag: Can
amachinereallyfinishyoursentence? InProceed-
ingsofthe57thAnnualMeetingoftheAssociation
forComputationalLinguistics,pages4791–4800.As-
sociationforComputationalLinguistics.
Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-levelconvolutionalnetworksfortextclassi-
fication. Advancesinneuralinformationprocessing
systems,28.Data λ k τ
Llama2+Wiki 0.2 2048 5.0
Llama3+Wiki 0.1 2048 5.0
Mistral+Wiki 0.1 2048 10.0
Data λ k τ
Llama2+Math 0.2 1600 5.0
Llama3+Math 0.1 2048 3.0
Mistral+Math 0.1 2048 10.0
Table12: HyperparametersinkNN-LM.Top: Hyperpa-
rametersforWikidatastore. Bottom: Hyperparameters
forMathdatastore.SentimentExample Label LMPred
humorous,artsy,andevencute,inanoff-kilter,dark,vaguelydisturbing Positive Negative
way.Thesentencehasatonethatis
RetrievedContext Retrieved kNN-LMPred
Wiki
•meta-commentator,Imhoffgivesusadecidedlymoderndelivery.His bitter
speakingrhythmsarestaccatoandhistone
•Collins,whohasworkedonmorethan100childrenbooksandwon fun Negative
severalawards:histoneis
•isherownnarrator,sothethoughtsandfeelingsofothersareconveyed honest
secondhandorareabsententirely.Hertoneandlanguageareatturns
Math
• preferred term is not “Platonist” but “quasiëmpiricist”, a word Ty- different
moczkolendsasubtly
•... orahorrorfilm(group2,N =29). Thedataarecodedsothat positive
H Positive
higherscoresindicateamore
•thefailureoftheIntermediateValueTheoremisneitherherenorthere good
noranywhereelsetothem.Thisisnotabadnora
Table13: AsentimentanalysisexamplewithpredictionsofthestandardLMandkNN-LMs. Weshowtokens
retrievedfromeachdatastoreandtheirproceedingtokens.
HotpotQAExample Label LMPred
whoisolder,AnnieMortonorTerryRichardson? Terry Terry
Richardson Richardson
Retrievedcontext Token kNN-LMPred
•Andshestillwasn’tdone.Latershetweetedawarningtoallwomen.
“My hard won advice: never get into an elevator alone with [Terry Gilliam
Gilliam.]Terry
• #MeToo https://t.co/jPnFhfB5GQ - Ellen Barkin(@EllenBarkin)
Gilliam TerryGilliam
March17,2018Barkingotanothershotin.Terry
•Ihaven’tpostedaboutChristinaHendricksinawhilebutit’sValen-
tine’sDayandthatmakesmethinkofchocolateandchocolatereminds Hend
meofChristinaHendricks.AndChristina
Table14: AnotherexamplefromHotpotQAexplainstheimpactofhigh-frequencypropernounsinthecorpuson
kNN-LMspredictionsretrievingfromWikipedia.