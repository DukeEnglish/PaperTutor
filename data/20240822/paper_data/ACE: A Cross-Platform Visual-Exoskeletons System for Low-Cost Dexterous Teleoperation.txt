ACE: A Cross-Platform Visual-Exoskeletons System
for Low-Cost Dexterous Teleoperation
ShiqiYang MinghuanLiu YuzheQin RunyuDing JialongLi
XuxinCheng RuihanYang ShaYi XiaolongWang
UCSanDiego
Cross-Platform Teleoperation Different End-Effectors
Mobile Base
Desktop Base
Dual-Arm Humanoid Quadrupeds
Different Robots
Figure 1: An Overview of the Proposed ACE System. The system consists of two bimanual ex-
oskeletonarmsandtwocamerasforhandposetracking. Togetherwithourmodulardesignofthe
base,wecanperformteleoperationacrossawiderangeofendeffectorsandrobotplatforms.
Abstract: Learning from demonstrations has shown to be an effective approach
to robotic manipulation, especially with the recently collected large-scale robot
datawithteleoperationsystems. Buildinganefficientteleoperationsystemacross
diverse robot platforms has become more crucial than ever. However, there is a
notable lack of cost-effective and user-friendly teleoperation systems for differ-
ent end-effectors, e.g., anthropomorphic robot hands and grippers, that can op-
erate across multiple platforms. To address this issue, we develop ACE, a cross-
platformvisual-exoskeletonsystemforlow-costdexterousteleoperation.Oursys-
tem utilizes a hand-facing camera to capture 3D hand poses and an exoskeleton
mountedonaportablebase,enablingaccuratereal-timecaptureofbothfingerand
wrist poses. Compared to previous systems, which often require hardware cus-
tomizationaccordingtodifferentrobots, oursinglesystemcangeneralizetohu-
manoidhands,arm-hands,arm-gripper,andquadruped-grippersystemswithhigh-
precisionteleoperation. Thisenablesimitationlearningforcomplexmanipulation
tasksondiverseplatforms. Webpage: https://ace-teleop.github.io/.
4202
guA
12
]OR.sc[
1v50811.8042:viXra1 Introduction
Inrecentyears,theeffectivenessoftrainingrobotfoundationmodelsusingreal-worldrobotdatahas
led to a significant increase in attention to data collection. Teleoperation has emerged as a crucial
datacollectionmethod,enablingresearcherstodemonstrateandrecordcomplexrobotictasks. Vari-
oussolutions,includingVRsystems[1,2,3],motioncapturesystems[4,5],wearablegloves[6,7],
and low-cost devices [8, 9], have been developed to facilitate teleoperation, each offering unique
advantages in terms of accessibility, precision, and generalizability. As we assess these existing
systems, a critical question arises: What key information must be captured to effectively perform
dexterousmanipulationtasksonawiderangeofrobotplatforms?
Theanswerisquitesimple: accuratehandposesandend-effectorpositions,whichcanbeachieved
withlow-costhardware. WeproposeACE,across-platformvisual-exoskeletonssystemforlow-cost
dexterousteleoperation,asillustratedinFigure1. Forhandposecapture,weutilizealow-costcam-
era combined with a 3D hand pose estimation method [10, 11, 12]. To address the common issue
ofocclusiononvision-basedsystems,ourdesignfeaturesacameramountedontheendeffectorof
theexoskeleton,ensuringitalwaysfollowsthefrontfaceofthehand. Theexoskeletons,whichare
3Dprinted,providepreciseend-effectorpositionsthroughforwardkinematics. Withthis,therobot
hardwaredoesnotneedtomatchthemorphologyoftheteleoperationsystem. Duringteleoperation,
astheoperatormovestheexoskeletonsandtheirhands,wecapturethehandrootend-effectorposi-
tionandhandposeinreal-time. Wethenuseinversekinematicstomaptherobotarmend-effector
with the human hand end-effector position. This allows for effective motion retargeting between
humanhandsandrobothands,enablingprecisecontroloftherobot’sfingers.
Table1: ComparisonofTeleoperationSystems(EE:EndEffector,FK:ForwardKinematics)
TeleopSystem EEType $Cost EETracking CrossPlatform? MobileBase?
ALOHA[8] Parallel-Jaw 20k Joint-matching
✓
Mobile-ALOHA[13] Parallel-Jaw 32k Joint-matching
GELLO[9] Parallel-Jaw 0.6k Joint-matching
✓
AnyTeleop[14] Anthropomorphic ∼0.3k Vision
✓ ✓
DexCap[15] Anthropomorphic 4k HandMocap+Vision
✓ ✓
ACE(Ours) Both 0.6k Vision+FK
Wecompareourteleoperationsystemwithseveralrecentlyproposedsystems,asshowninTable1,
to illustrate our advancement. The ALOHA [8, 13] system provides precise control of bimanual
manipulators,primarilyfocusingonparallel-jawgrippers. Bydirectlymatchingthejointsbetween
the teleoperation system and the robot, ALOHA can achieve precise control of the end-effector.
However, thisadvantagelimitsitsusagetoonlythespecificdesignatedhardware. Incontrast, our
system allows the operation of multiple robot hardware types and offers the flexibility to control
multi-fingerrobothandsinsteadofonlyparallel-jawgrippers.Thisflexibilityenablesdatacollection
on more diverse tasks. Our system can even be adapted to 2-DOF grippers using simplified hand
gestures.TheGELLO[9]systemachievesone-to-onejointmatchingbyusingasmaller-sizedrobot
arm to control the actual robot arm. However, we show in our experiments that this mismatch in
sizemakesithardtocontrolforfinemanipulationtasks. Oursystem,onthecontrary,providesmore
precise control by focusing on transferring the motion of only the end-effectors. AnyTeleop [14]
usescamerastocapturehandposesandperformteleoperationdirectlywiththecameradata. While
this method pushes the boundary of low cost and simplicity in teleoperation hardware, the vision-
based system can only provide limited accuracy in measuring the hand root end-effector poses.
Oursystem,whichemploysanexoskeletonforcapturinghandposes,providesamoreaccurateand
reliablemeasurementofthehandrootend-effector.
Our system leverages the precision of kinematics-based exoskeletons, combined with the afford-
abilityandadaptabilityofvision-basedsystems. Actingasabridgebetweenthesetwoapproaches,
we can obtain accurate hand poses and end-effector positions at a low cost while ensuring cross-
platformcompatibility. Inthispaper,weintroduceourteleoperationsystem,includingthehardware
designandthesoftwaremodulesthatenablecross-platformoperations. Ourexperimentsshowtwo
keyadvantages.First,ourdesignedsystemenablesuserstoquicklyadaptandefficiently,accurately,
2and swiftly complete tasks under various precision and workspace requirements. Second, our im-
itationlearningexperimentsdemonstratedthatoursystemcanefficientlycollecteffectivedataand
completethecorrespondingimitationlearning.
2 RelatedWork
Learningfromhumandemonstrations. Learningfromhumandemonstrationshasemergedasa
widelyadoptedapproachinroboticmanipulation,leveragingtheabilitytoreplicatecomplextasks
by observing human actions. In-the-wild data from human hand movements offers a rich and ac-
cessiblesourceofdemonstrationdataforrobotlearning[2,16,17,18,19,20]. Recentstudieshave
shownthatutilizingteleoperationforrobotcontrolanddatacollectionisbothefficientandtransfer-
able[13,14,9,21,22]. However,collectinglarge-scaledatasetsinreal-worldenvironmentsisoften
time-consuming and resource-intensive [23, 24, 25, 26]. To enhance efficiency and expedite data
collection,itiscrucialtodevelopsystemsthataregeneralizabletoawiderangeofrobotplatforms,
end-effectors,andtasks.
Vision-basedTeleoperation. Teleoperationformanipulationhasalonghistory[27],withcommon
solutions like VR [2, 1, 28, 29, 30, 31], motion capture devices [4, 5], and gloves [6, 7], smart-
phones[32,33],andotherdevices[34,35]. Thosesystemsprovideaccuratetrackingposesforma-
nipulationtasks.However,high-costdevicesarelessaccessible,whichlimitslarge-scaledatacollec-
tion. Incontrast,vision-basedteleoperationisparticularlyadaptableanduser-friendly[36,37,38],
which requires less hardware setup, can be adapted to different body types, and is relatively low-
cost without complex hardware setups. Effective hand-tracking algorithms [10, 11, 12] allow for
thetransferofhumanhandmotionstoanthropomorphicrobothands [39,14,40,38]. Directwrist
tracking and motion transfer allow for cross-platform operations on a wider range of robot plat-
forms[3,18,39,41,42]. However,vision-basedtrackingsystemsaresensitivetoocclusion,which
introducesambiguitiesinthehandposes. Wristposeestimationintheworldcoordinatecanalsobe
inaccurateandnoisy.
Kinematics-based Data Collection. Data collection directly from the robot itself has also been
employed[43]. Recentworksofdevelopingareplicaofarobothaveshownhighefficiencyfordata
collection[44]andteleoperation[8,9]. Thesesystemsmirrorthetargetrobot’skinematicstructure,
enablingaccuratemovementandinteractionreplication. Thecontrollingprocessisstraightforward
withjoint-matching[13,9,45]. Exoskeletonsarealsointuitivesolutionsforhumanoperators, but
normally with a significantly higher cost [46, 47, 48, 49] and do not support hand modeling. Our
workisalsorelatedtorecentlyproposedDexCap[15](Table1)whichutilizesahandmotioncapture
systemwithamobilebase,withmoreexpensivehardware. Itswristtrackingisbasedonreal-time
localization, which is more accurate than pure vision methods but introduces delay. Compared to
DexCap, our system allows cross-platform generalization with enhanced accuracy and flexibility
usingalow-costdesign.
3 SystemDesign
To develop a cross-platform and low-cost dexterous teleoperation system that enables efficient
large-scaledatacollection, wesummarizethedesiderataintothefollowingfiveprinciples: Cross-
platform Compatibility: Ensuring versatility across various robot platforms, such as fixed-based
robotarms,quadrupeds,andhumanoids,whileaccommodatingdifferentend-effectortypes,includ-
inganthropomorphichandsandparallel-jawgrippers. Accuracy: Transferringtheprecisehandand
wrist pose of the operator to actual robot platforms. This enables fine-grained manipulation tasks
and improves the success rate of data collection. Low-cost: Emphasizing affordability to facili-
tate easy prototyping and lower the barrier to large-scale data collection. This encourages the use
ofreadilyavailable,off-the-shelfcomponentsandmaterials, insteadofexpensivecomponentslike
VR headsets or motion tracking systems. User-friendly: Ensuring the system is intuitive to use,
requiring minimal expertise for calibration and operation, and accommodating users of different
heights and weights. We also aim for two types of bases - fixed or mobile - so the user can eas-
ily switch between fixed and mobile tasks. Easy to Manufacture and Maintain: Designing the
3Wrist Pose To End-Effecter Pose
ACE Input
Normal Mode
3
Joint
1 Mapping
Angles
Mirror Mode
Hand Pose To End-Effector Control
Key points Gripper Mode
Mapping
Hand
2
images
Retargeting
Hand Mode
1 Forward Kinematics 2 Hand Detect Algorithm 3 InverseKinematics
Figure2: ArchitectureoftheACETeleoperationSystem. Oursystemreadsthejointanglesfrom
our exoskeleton motors and the hand image to estimate the wrist and hand poses through forward
kinematics and a hand detection algorithm. With different modes of operation, we can perform
teleoperationondifferentend-effectorsandrobotplatforms.
system to be straightforward to manufacture and maintain, with easily replaceable components to
minimizedowntimeandextendoperationallifespan. Thisincludesamodulardesignusingstandard
componentstosupporteasyassembly,disassembly,andreplacement.
AnoverviewofourACEsystemdesignisillustratedinFig.2. Oursystemconsistsofa3D-printed
bimanualexoskeletonandtwohand-facinglow-costwebcamsmountedattheendsoftheexoskele-
ton. Theexoskeleton’sjointpositiontrackingprovidesaccuratewristposebyforwardkinematics,
andthetwocamerasprovideprecisehand-posetracking. Bycombiningthesetwosourcesofinfor-
mation,thesystemenablesreal-timehandposetrackingrelativetotheworldcoordinate.
Afterobtainingtheaccuratehandpose,wemapittotargetrobotposesonvariousrobotplatforms.
Afterthecontrolmapping,wecanteleoperaterobotsandcollectdemonstrationsforimitationlearn-
ing. In experiments, we demonstrate the effectiveness of our teleoperation system on a range of
robotswithvariousend-effectors,includingtheXarmwithAbilityHand,H1withInspireHand,B1
withZ1,Frankawithagripper,andGR-1withagripper.
3.1 HardwareDesign
Dual-basesetup. TheproposedACEsystem,showninFig.3,hastwoarmsandtwotypesofbases:
desktopandmobile. Thisdual-basesetupprovidescross-platformcompatibilityfrommobilerobots
to robot arms. The desktop version provides a stable and precise wrist pose from its stationary
base. Forlong-termteleoperation,theusermayresttheirelbowsontheplatform. Themobilebase
is designed for tasks that need constant movement or continuous adjustment of the field of view.
Specificallysuitableformobileplatformsincludinghumanoidsandquadrupeds.
Servosandcameras. Oursystemfeaturestwoarms,eachwithsevenlinks,sixdegreesoffreedom
(DoF), a wrist, and a camera mount. Each arm is equipped with a UCB2Dynamixel (U2D2) con-
trollerandDYNAMIXELXL330-M288-Tservoswithhigh-resolution12-bitencodersforaccurate
jointpositionreadings,ensuringpreciseend-effectortracking. Thetwo-DoFcameramountallows
foroptimalhandpositioningtoavoidocclusionissuescommoninvision-basedhandtracking.
4Elbow Joint
(3 DOF)
Wrist Joint Mobile Desktop
(2 DOF) Base Base
Base Joint Wrist
(1 DOF) Connectors
Control
Camera Board
Desktop Servo Wrist
Base Joint
Connectors Camera
Mount
Control Links
Board
Components with magnetic connectors
Figure 3: Hardware Components. Left: assembled exoskeleton on a fixed desktop base. Right:
partsforonearm. Weshowtwowristconnectorsandlinksofdifferentsizes.
Magnetic connections. We utilize a modular design with magnetic connections, as illustrated in
Fig.3. Theuseofmagnetsisnotonlyinexpensivebutalsosignificantlyenhancestheuserexperi-
ence. Traditionally,donningexoskeletonequipmentcanbeacomplexprocess. However,ourmag-
neticallymodulardesignallowsuserstoindependentlydonthesystem(thedesktopversion)inless
than30seconds. Additionally,themagneticconnectionsfacilitatequickandeasysizeadjustments.
Thewristsizecanbealteredalmostinstantly,andtheupperandlowerarmlengthadjustmentscanbe
completedinunder2minutes. Thismodulardesignallowseasyintegrationofupdatedcomponents,
enablingefficientupgradestoouropen-sourcesystem.
3.2 PoseEstimationandEnd-EffectorControlMapping
When the user starts collecting demonstrations, we estimate the precise wrist pose and hand key-
points. The wrist pose is determined by reading joint angles from the exoskeleton’s encoders and
calculatingtheposeusingtheforwardkinematicsofthedesignedexoskeletons[50]. Handimages
areprocessedusingMediaPipe[11],alightweight,RGB-basedhanddetectiontoolthatcanoperate
inreal-timeonaCPU,todetectthe21handkeypointsinthewristframe.
After obtaining the wrist and hand pose data, we map human movements to target robot poses
and end-effector control signals across various platforms. To meet the specific needs of different
platforms and tasks, we address three significant challenges in developing the control interface:
workspacemismatch,controlscalevariability,andusabilityconcerns.
Matchingworkspacesizes. First,thevariationinworkspacesizesposesasignificantchallengeon
differentplatforms,particularlyinachievingfullcoverageduringbimanualoperations. Foragiven
platform,userscanspecifytherequiredworkspaceintheconfiguration. Bywearingourdeviceand
moving their arms around, we align the center of the human and robot workspaces and document
thematchingscalebetweenthesetwoworkspaces.
Control scale variability. Second, different tasks and platforms require varying levels of con-
trol precision. For example, when using a scaled replica of the actual robot platform, direct joint-
matchingteleoperationswillresultinerrorsbeingamplifiedwhentransferringthemotiontoalarger
robot arm [9]. Moving the small teleoperation end-effector by a small distance may translate to
much larger movement on the actual robot arm, significantly impacting control accuracy for fine
tasks. Instead,inoursystem,byusinginversekinematicstomaptheend-effectorpositions,wecan
provide a more accurate and intuitive mapping from the teleoperation device to the actual robot.
Considerthe6Drobotend-effectorposex ∈ R6,andthehumanwristposex ∈ R6,wemapx
e h h
tox as
e
x =γ(x −c )+c (1)
e h h t
where γ is the control scale, c is the center of the human workspace, and c is the center of the
h t
taskworkspace. MoredetailedparameterdefinitionsareincludedintheAppendixA.Weshowthat
inourexperiments,thisscaledapproachismoreefficientandadaptabletodifferentworkspacesand
tasksizesthandirectjointmatchingmethods.
5NormalMode on Desktop Base
Dual-Arm+Hands
Mirrormode on Desktop Base
Humanoid+Hands
NormalMode on Mobile Base
Quadruped+Gripper
Figure4: DetailsofCross-PlatformTeleoperation. Thisfigureshowcasesvariouscontrolmodes
forefficientlyteleoperatingdifferentrobots,includingnormal/mirrormodesandhands/grippercon-
figurations.Additionally,itillustratestheapplicationofourDual-basesetupinvariousscenarios.In
theDual-Arm+Handssetup,normalmodewithadesktopbaseisusedtocontrolthexArmwiththe
abilityhand. TheHumanoid+Handssetupemploysmirrormodewithadesktopbasetocontrolthe
robot. IntheQuadrapeds+Gripper setup,therighthandcontrolstherobotinnormalmode,while
thelefthandusessimpleposestomanagethequadruped’smovementusingapre-trainedlow-level
controlpolicyatafixedvelocity. Themobilebaseallowstheoperatortofollowtherobot’smove-
ments,enablingbettercontrol.
Usability. The biggest challenge for cross-platform teleoperation is usability. Cross-platform de-
ployment often involves redundant and labor-intensive calibration processes when switching plat-
forms.Toenhanceusabilityandaccommodatedifferenttasksandrobotplatforms,wehavedifferent
controlmodesasanadditionallayerbeforetransferringtheend-effectorposetotheactualrobot:
• NormalMode: Directtransferend-effectorpositionstotheactualrobot. Theend-effectorposein
this mode xnormal is the same as in Eq. (1), where γ is the ratio between the robot and human
e
workspaceradius.
• MirrorMode: Designedforlargerobots,thismodeallowsuserstooperateface-to-facewiththe
robot.Inthismodexmirror =−γmirror(x −c )+c wheretheend-effectormotionismirrored,
e e h h t
thusmakingitmoreintuitiveduringoperation.
• Bimanual Mode: For bimanual tasks that require high precision, the cameras may collide. We
adjust the scaling factor γ and c so that the left and right hand side workspaces align. In this
t
setting,whenthecameramountsareabouttocollide,therobothandstoucheachother.
Basedondifferenttypesofend-effectors,wealsosupport:
• GripperMode: Tailoredforparalleljawgrippers,thismodeprovidesstraightforwardcontrolfor
taskssuitedtothisend-effectortype. Thedistancebetweenthethumbtipandtheindexfingertip
islinearlymappedtoarangeof0to1.
• HandMode: Thehandandfingertipmotionsareretargetedtotherobothand;detailedprinciples
areprovidedintheAppendixB.
61 4 6 9
2 7
3 5 8 10
Figure5: ExamplesofCross-PlatformTeleoperation. Examples1-3areperformedonthexArm
withabilityhandsetup: 1)stacking,2)servingcoffee,and3)soldering. Examples4-7areexecuted
on the H1 with inspire hand setup: 4) spraying, 5) passing, 6) pipetting, and 7) inserting tennis.
Example8isontheGR-1withagripper, performingabox-packingtask. Example9featuresthe
B1withZ1setup,demonstratingashoppingcart-pushingtask. Example10isontheFrankawitha
gripper,performingataskofpickingupmiscellaneousobjects.
Figure 6: End Effector Accuracy Evaluation. By extending the tape from 20 cm to 40 cm, the
teleoperationend-effectordemonstratesprecisereplicationoftheoperator’smotionwithanaverage
errorofonly3mm.
Aftermappingthewristposestotherobot’scoordinateframe,thejointanglesoftherobotarmcan
beobtainedusinginversekinematics(IK).Differentrobotplatformsmayrequirespecificfilters,PID
parameters,andconstraintstoensuresafety,smoothmovements,andreduceissuesfromsingularity.
The robot hand joints are obtained from human hand poses and mapped through hand motion re-
targeting[14]. Oursystemisdesignedforeasycalibration,incorporatingservoswithabsolutezero
position feedback for one-time calibration without disassembly. The zero position aligns the arm
perfectly when placed flat on a table, and the same arm design is used for both mobile and desk-
top versions, eliminating the need for recalibration when switching bases. We have optimized the
computationalefficiencytoensureahandposetrackingfrequencyofapproximately27Hz,which
can be further improved to 100 Hz with a higher-frequency camera. Integration with the gRPC
pipeline facilitates extension to other platforms such as Vision Pro. These approaches ensure that
ourteleoperationsystemisadaptable,precise,anduser-friendly,addressingtheprimarychallenges
ofdeployingsuchsystemsacrossdiverseroboticplatforms.
7Setup SIM
ACE (Ours) GELLO #1 #2 #3
#1
Figure7: IllustrationoftheTarget-reachingExperiment. WeusexArmasanexample. Theblue
spheresrepresenttheend-effector, andtheredandyellowspheresrepresentthetargetsfortheleft
andrightarms,respectively.Whenatargetissuccessfullyreached,itturnsgreentoindicatesuccess.
WecompareACE(left)withGELLO(right). SIM#1to#3demonstratethecompleteprocessofa
taskbeingcompleted.
Table 2: User Study Evaluation in Simulation. Comparison of ACE with GELLO baseline in
a target-reaching task across varying workspace and target sizes. The results demonstrate ACE’s
superiorperformanceintermsofreachtime,velocity,effectiveratio,andsuccessrate,particularlyin
smallandmediumworkspacescenarios. Eveninalargeworkspace,ACEconsistentlyoutperforms
GELLO,showingitsrobustnessacrossdifferentconditions.
AvgReach AvgReach AvgEE Effective Success
Workspace Target Method
Time(s)↓ Vel(m/s)↑ Vel(m/s)↑ Ratio↑ Rate↑
GELLO 13.6 0.089 0.340 26.2% 47.6%
Small Small
ACE 4.69 0.220 0.360 61.1% 97.1%
GELLO 6.52 0.179 0.395 45.3% 73.8%
Medium Small
ACE 4.54 0.249 0.401 62.1% 91.4%
GELLO 3.65 0.327 0.436 75% 93.8%
Medium Medium
ACE 4.05 0.294 0.438 67.1% 87.5%
GELLO 6.52 0.212 0.491 43.2% 68.7%
Large Large
ACE 5.17 0.264 0.504 52.6% 78.6%
4 Experiments
Wedesignedexperimentstoinvestigatetwokeyaspectsofourproposedteleoperationsystem: pre-
cisionandtransferability. Wedesignedatarget-reachingtasktoshowthatoursystemcanachieve
precise end-effector control, compared to previous joint-matching systems. We show how robots
autonomouslyperformtasksviaimitationlearningtrainedusingthedatacollectedfromoursystem,
andweshowmoreteleoperationexamplesinFig.5.
4.1 EndEffectorAccuracyandEfficiency
Precision evaluation. Similar to other joint matching methods [51, 45, 9], the end-effector pose
obtainedfromthejointencoderishighlyaccurate. Specifically,inoursystem,theaverageforward
kinematicserrorisaround1mm. AsshowninFig.6,weperformteleoperationonameasurement
tape extension task. By extending the tape from 20 cm to 40 cm, we show that the teleoperation
end-effector accurately represents the operator’s motion, with an average error of only 3mm. The
errorspresentedinthisfigurearecumulative,includingbothteleoperationandrobotcontrolerrors,
yettheoverallerrorremainswithinareasonablerange.
Target-reaching evaluation. We compare the agility and precision of our ACE system with the
previousjoint-matchingsystem, specificallyGELLO[9]foritscomparablecostandopen-sourced
implementation. Wedesignedatarget-reachingtasktoevaluatetheperformanceofbothsystemsin
asimulation. Theoperator’sobjectivewastocontroltheend-effectorstoreachrandomlygenerated
target regions. Success was recorded when both end-effectors reached their respective target area
andremainedwithinthetargetregionsforashortduration.
Wesetupfourscenariostoassessteleoperationperformance,withworkspacesandtargetregionsof
small,medium,andlargesizes. Ourevaluationinvolvedsixoperators. Furtherdetailsaboutthetask
8#1 #2 #3 #4 #5
(a)Therobotgraspsthevacuum(#1, #2-Grasp), activatesitbypressingabutton(#3-Activate), usesthe
vacuumtocleanthekeyboard(#4-Clean),andthenreturnsthevacuumtoitsoriginalposition(#5-Place).
#1 #2 #3 #4 #5
(b)Therobotgraspsthecandyjar(#1-Grasp),opensthejarbyremovingthelid(#2-Open),discardsthelid
(#3-ThrowCap),poursoutthecandies(#4-Pour),andfinallydiscardsthejar(#5-ThrowTube).
#1 #2 #3 #4 #5
(c)Therobotgraspstheeraser(#1-Grasp)andthenwipesthewhiteboard(#2-#5-Wipe).
#1 #2 #3 #4 #5
(d)Therobotgraspsthedoll(#1,#3-Grasp)andplacesthedollintothebasket(#2,#4,#5-Place).
#1 #2 #3 #4 #5
(e)Therobotgraspsthetennisball(#1-#3-Grasp)andplacesthetennisballbackintothecontainer(#4,#5-
Place).
#1 #2 #3 #4 #5
(f)H1robotdoingthesameGraspDollstaskasinFig.8d.
Figure 8: Imitation Learning on Different Robots. The first four tasks (a-d) involve imitation
learningusingtheXarmwiththeabilityhand,whilethelasttwotasks(e,f)areperformedusingthe
H1withtheinspirehand.
configurations and operator specifics are provided in Appendix C.3. We evaluate the performance
of the system by the time used to reach the target region, the average reaching speed, the average
end-effector moving speed, and the effective ratio, which is the ratio between the optimal moving
distanceandtheactualmovingdistanceoftheend-effector.
9
draobyeK
muucaV
seidnaC
evreS
draobetihW
epiW
slloD
psarG
sinneT
ni
tuP
slloD
psarGTable3: Imitationlearningevaluation. Thistableevaluatesthesystem’sabilitytocollectdataand
applyittoimitationlearningtasks,followedbyanevaluationoftheperformanceinthesetasks.
DataCollection Imitation
Task Robot Hand
Avg.Time(s) Succ./Trials Steps Succ.Rate
Grasp 1
Activate 0.6
VacuumKeyboard xArm7 Ability 45.6 30/38
Clean 0.6
Place 0.5
Grasp 0.9
Open 0.6
ServeCandies xArm7 Ability 37.6 45/53 ThrowCap 0.5
Pour 0.4
ThrowTube 0.4
Grasp 1
WipeWhiteboard xArm7 Ability 33.5 30/37
Wipe 0.7
Grasp 0.9
GraspDolls xArm7 Ability 11.6 120/123
Place 0.8
Grasp 0.9
PutinTennis H1 Inspire 21.4 25/29
Putin 0.9
Grasp 0.9
GraspDolls H1 Inspire 13.7 62/66
Place 0.9
The result is shown in Table 2. ACE system consistently outperformed GELLO across most sce-
nariosandmetrics,demonstratingshortertimecosts,higherreachingspeeds,highereffectiveratios,
andsuccessrates. BecauseofthecombinationofusingForwardKinematics(FK)forend-effector
tracking,andInverseKinematics(IK),allowsforadaptablemappingfromtheoperatorposetothe
robot pose. Although the direct joint-matching method in GELLO provides accurate control, it is
onlysuitableforaspecificworkspaceandtasksize(mediumsizeasdefinedinourexperiment). For
smallerworkspaces,orfinetasksthatrequireprecisemotion,theamplifiedrobotmotioninGELLO
hasahardtimestabilizingtothegivenposition,resultinginredundantorsub-optimalmotion. Our
system ACE utilizes an adaptable approach that first maps the operator’s natural workspace to the
task’srequiredworkspace,andalsoadjuststhecontrolscaleontherobotplatformtofittherequired
tasks and workspaces. This adaptable approach is only available when we can transfer the scaled
poseswithinversekinematicstosolvetherobotconfigurations. Thisshowsthatourapproachisnot
only more generalizable to different robot platforms and end effectors but also adaptable to tasks
andworkspacesofdifferentscales.
4.2 ImitationLearning
Wedesignsixreal-worldtasksthatrequiremulti-stepdexterousteleoperation,illustratedinFig.8.
Twolonghorizontasks, VacuumKeyboard: 1)graspthevacuum, 2)activatethevacuum, 3)clean
the keyboard, 4) return the vacuum; Serve Candies: 1) grasp the candy tube, 2) open the cap, 3)
throw the cap into the trash bin, 4) pour candies into the box, and 5) throw the tube into the trash
bin. WipeWhiteboard: graspstheeraserandwipesthewhiteboard. GraspDolls: graspsthedolls
one-by-oneandputintothebasket. PutinTennis: graspatennisballandputitintothecontainer.
ForGraspDolls,itrequiresgeneralizationstodifferentobjectsandrobotpositions.Inparticular,we
trainedonninetypesofsmalldollsandtwotypesoflargedollsbuttestedon15typesofsmalldolls
andthreetypesoflargedolls. WecollecteddatawithACEsystemonxArmwithAbilityHandand
H1withInspireHandontheabove-mentionedtasks. Tab.3showsthatwithACE,wecanefficiently
collectalargenumberofdatawithahighsuccessrate.
Withthedatacollectedfromteleoperation,wetraineachpolicywithimitationlearning. Weuse3D
diffusionpolicies[52]forimitationlearningonxArmplatformsandACT[8]onH1.Specifically,for
diffusionpolicy,wedrawpointcloudsindependentlyfromtwocameraviews,andtheproprioception
statesastherobotobservationandtheactionspaceisthetargetposesofthearmwrists,andhands.
10The input for ACT is a single RGB image from a camera mounted at the top of the robot. The
learningresultsforalltasksareshowninTab.3. Wetested10episodesforeachtaskandshowed
thesuccessrateondifferenttasks.
5 Conclusion
Inthispaper,weproposedACE:across-platformvisual-exoskeletonsystemforlow-costdexterous
teleoperation.ACEsystememploysahand-facingcameratocapture3Dhandposesandanexoskele-
ton mounted on either a fixed or a mobile base. This setup accurately captures both the hand root
end-effectorandhandposeinreal-time,enablingcross-platformoperationswithlow-costhardware.
Oursystemdoespresenttwomajorlimitations.Thecameramountpreventsthewearer’shandsfrom
coming together and, additionally, increases the burden of rotational movements due to the added
momentarm. Althoughfunctionallyaddressedbyourscaledcontroller,certainoperationsareless
intuitive.
References
[1] S. Han, B. Liu, R. Cabezas, C. D. Twigg, P. Zhang, J. Petkau, T.-H. Yu, C.-J. Tai, M. Ak-
bay,Z.Wang,etal. Megatrack: monochromeegocentricarticulatedhand-trackingforvirtual
reality. ACMTransactionsonGraphics(ToG),39(4):87–1,2020.
[2] S. P. Arunachalam, S. Silwal, B. Evans, and L. Pinto. Dexterous imitation made easy: A
learning-based framework for efficient dexterous manipulation. In 2023 ieee international
conferenceonroboticsandautomation(icra),pages5954–5961.IEEE,2023.
[3] V. Kumar and E. Todorov. Mujoco haptix: A virtual reality system for hand manipulation.
In 2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids), pages
657–663.IEEE,2015.
[4] Z.Fan,O.Taheri,D.Tzionas,M.Kocabas,M.Kaufmann,M.J.Black,andO.Hilliges.Arctic:
Adatasetfordexterousbimanualhand-objectmanipulation. InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages12943–12954,2023.
[5] O.Taheri,N.Ghorbani,M.J.Black,andD.Tzionas. Grab: Adatasetofwhole-bodyhuman
graspingofobjects. InComputerVision–ECCV2020: 16thEuropeanConference, Glasgow,
UK,August23–28,2020,Proceedings,PartIV16,pages581–600.Springer,2020.
[6] H.Liu, Z.Zhang, X.Xie, Y.Zhu, Y.Liu, Y.Wang, andS.-C.Zhu. High-fidelitygraspingin
virtualrealityusinga glove-basedsystem. In2019internationalconferenceonroboticsand
automation(icra),pages5180–5186.IEEE,2019.
[7] M.Caeiro-Rodr´ıguez,I.Otero-Gonza´lez,F.A.Mikic-Fonte,andM.Llamas-Nistal.Asystem-
aticreviewofcommercialsmartgloves: Currentstatusandapplications. Sensors,21(8):2667,
2021.
[8] T.Z.Zhao, V.Kumar, S.Levine, andC.Finn. Learningfine-grainedbimanualmanipulation
withlow-costhardware. arXivpreprintarXiv:2304.13705,2023.
[9] P. Wu, Y. Shentu, Z. Yi, X. Lin, and P. Abbeel. Gello: A general, low-cost, and intuitive
teleoperationframeworkforrobotmanipulators. arXivpreprintarXiv:2309.13037,2023.
[10] Y. Rong, T. Shiratori, and H. Joo. Frankmocap: Fast monocular 3d hand and body motion
capturebyregressionandintegration. arXivpreprintarXiv:2008.08324,2020.
[11] F. Zhang, V. Bazarevsky, A. Vakunov, A. Tkachenka, G. Sung, C.-L. Chang, and M. Grund-
mann.Mediapipehands:On-devicereal-timehandtracking.arXivpreprintarXiv:2006.10214,
2020.
11[12] T.Ohkawa,K.He,F.Sener,T.Hodan,L.Tran,andC.Keskin. Assemblyhands: Towardsego-
centricactivityunderstandingvia3dhandposeestimation. InProceedingsoftheIEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages12999–13008,2023.
[13] Z.Fu, T.Z.Zhao, andC.Finn. Mobilealoha: Learningbimanualmobilemanipulationwith
low-costwhole-bodyteleoperation. arXivpreprintarXiv:2401.02117,2024.
[14] Y.Qin,W.Yang,B.Huang,K.VanWyk,H.Su,X.Wang,Y.-W.Chao,andD.Fox.Anyteleop:
Ageneralvision-baseddexterousrobotarm-handteleoperationsystem. Robotics:Scienceand
Systems(RSS),2023.
[15] C.Wang,H.Shi,W.Wang,R.Zhang,L.Fei-Fei,andC.K.Liu.Dexcap:Scalableandportable
mocap data collection system for dexterous manipulation. arXiv preprint arXiv:2403.07788,
2024.
[16] K. Shaw, S. Bahl, and D. Pathak. Videodex: Learning dexterity from internet videos. In
ConferenceonRobotLearning,pages654–665.PMLR,2023.
[17] S. Bahl, A. Gupta, and D. Pathak. Human-to-robot imitation in the wild. arXiv preprint
arXiv:2207.09450,2022.
[18] Y.Qin,H.Su,andX.Wang.Fromonehandtomultiplehands:Imitationlearningfordexterous
manipulationfromsingle-camerateleoperation. IEEERoboticsandAutomationLetters,7(4):
10873–10881,2022.
[19] J.Ye,J.Wang,B.Huang,Y.Qin,andX.Wang. Learningcontinuousgraspingfunctionwith
adexteroushandfromhumandemonstrations. IEEERoboticsandAutomationLetters, 8(5):
2882–2889,2023.
[20] H.Bharadhwaj,A.Gupta,V.Kumar,andS.Tulsiani. Towardsgeneralizablezero-shotmanip-
ulationviatranslatinghumaninteractionplans. arXivpreprintarXiv:2312.00775,2023.
[21] J.I.Lipton,A.J.Fay,andD.Rus.Baxter’shomunculus:Virtualrealityspacesforteleoperation
inmanufacturing. IEEERoboticsandAutomationLetters,3(1):179–186,2017.
[22] S.Chen,J.Gao,S.Reddy,G.Berseth,A.D.Dragan,andS.Levine. Asha: Assistiveteleop-
eration via human-in-the-loop reinforcement learning. In 2022 International Conference on
RoboticsandAutomation(ICRA),pages7505–7512.IEEE,2022.
[23] H.R.Walke,K.Black,T.Z.Zhao,Q.Vuong,C.Zheng,P.Hansen-Estruch,A.W.He,V.My-
ers,M.J.Kim,M.Du,etal.Bridgedatav2:Adatasetforrobotlearningatscale.InConference
onRobotLearning,pages1723–1736.PMLR,2023.
[24] H.-S.Fang,H.Fang,Z.Tang,J.Liu,J.Wang,H.Zhu,andC.Lu. Rh20t: Aroboticdatasetfor
learningdiverseskillsinone-shot. arXivpreprintarXiv:2307.00595,2023.
[25] A. Padalkar, A. Pooley, A. Jain, A. Bewley, A. Herzog, A. Irpan, A. Khazatsky, A. Rai,
A. Singh, A. Brohan, et al. Open x-embodiment: Robotic learning datasets and rt-x mod-
els. arXivpreprintarXiv:2310.08864,2023.
[26] A.Brohan,N.Brown,J.Carbajal,Y.Chebotar,J.Dabis,C.Finn,K.Gopalakrishnan,K.Haus-
man,A.Herzog,J.Hsu,etal. Rt-1:Roboticstransformerforreal-worldcontrolatscale. arXiv
preprintarXiv:2212.06817,2022.
[27] G. Niemeyer, C. Preusche, S. Stramigioli, and D. Lee. Telerobotics. Springer handbook of
robotics,pages1085–1108,2016.
[28] T. Zhang, Z. McCarthy, O. Jow, D. Lee, X. Chen, K. Goldberg, and P. Abbeel. Deep imita-
tionlearningforcomplexmanipulationtasksfromvirtualrealityteleoperation. In2018IEEE
internationalconferenceonroboticsandautomation(ICRA),pages5628–5635.IEEE,2018.
12[29] S. P. Arunachalam, I. Gu¨zey, S. Chintala, and L. Pinto. Holo-dex: Teaching dexterity with
immersivemixedreality. In2023IEEEInternationalConferenceonRoboticsandAutomation
(ICRA),pages5962–5969.IEEE,2023.
[30] M. Schwarz, C. Lenz, A. Rochow, M. Schreiber, and S. Behnke. Nimbro avatar: Interactive
immersivetelepresencewithforce-feedbacktelemanipulation.In2021IEEE/RSJInternational
ConferenceonIntelligentRobotsandSystems(IROS),pages5312–5319.IEEE,2021.
[31] X.Cheng,J.Li,S.Yang,G.Yang,andX.Wang. Open-television: Teleoperationwithimmer-
siveactivevisualfeedback. arXivpreprintarXiv:2407.01512,2024.
[32] J.Wong,A.Tung,A.Kurenkov,A.Mandlekar,L.Fei-Fei,S.Savarese,andR.Mart´ın-Mart´ın.
Error-awareimitationlearningfromteleoperationdataformobilemanipulation.InConference
onRobotLearning,pages1367–1378.PMLR,2022.
[33] C.Wang,L.Fan,J.Sun,R.Zhang,L.Fei-Fei,D.Xu,Y.Zhu,andA.Anandkumar.Mimicplay:
Long-horizonimitationlearningbywatchinghumanplay,2023.
[34] C. Chi, S. Feng, Y. Du, Z. Xu, E. Cousineau, B. Burchfiel, and S. Song. Diffusion policy:
Visuomotor policy learning via action diffusion. In Proceedings of Robotics: Science and
Systems(RSS),2023.
[35] Y.Zhu,A.Joshi,P.Stone,andY.Zhu.Viola:Object-centricimitationlearningforvision-based
robotmanipulation. In6thAnnualConferenceonRobotLearning,2022.
[36] C.Theobalt,I.Albrecht,J.Haber,M.Magnor,andH.-P.Seidel. Pitchingabaseball: tracking
high-speedmotionwithmulti-exposureimages.InACMSIGGRAPH2004Papers,pages540–
547.2004.
[37] B.Fang,X.Ma,J.Wang,andF.Sun. Vision-basedposture-consistentteleoperationofrobotic
armusingmulti-stagedeepneuralnetwork. RoboticsandAutonomousSystems,131:103592,
2020.
[38] S. Li, X. Ma, H. Liang, M. Go¨rner, P. Ruppel, B. Fang, F. Sun, and J. Zhang. Vision-based
teleoperationofshadowdexteroushandusingend-to-enddeepneuralnetwork. In2019Inter-
nationalConferenceonRoboticsandAutomation(ICRA),pages416–422.IEEE,2019.
[39] A.Handa,K.VanWyk,W.Yang,J.Liang,Y.-W.Chao,Q.Wan,S.Birchfield,N.Ratliff,and
D.Fox. Dexpilot: Vision-basedteleoperationofdexterousrobotichand-armsystem. In2020
IEEEInternationalConferenceonRoboticsandAutomation(ICRA),pages9164–9170.IEEE,
2020.
[40] S.Li,J.Jiang,P.Ruppel,H.Liang,X.Ma,N.Hendrich,F.Sun,andJ.Zhang. Amobilerobot
hand-armteleoperationsystembyvisionandimu.In2020IEEE/RSJInternationalConference
onIntelligentRobotsandSystems(IROS),pages10900–10906.IEEE,2020.
[41] R. M. Aronson and H. Admoni. Gaze complements control input for goal prediction during
assistedteleoperation. InRoboticsscienceandsystems,2022.
[42] J. Kofman, X. Wu, T. J. Luu, and S. Verma. Teleoperation of a robot manipulator using a
vision-basedhuman-robotinterface. IEEEtransactionsonindustrialelectronics,52(5):1206–
1219,2005.
[43] E.Jang,A.Irpan,M.Khansari,D.Kappler,F.Ebert,C.Lynch,S.Levine,andC.Finn. Bc-z:
Zero-shottaskgeneralizationwithroboticimitationlearning. InConferenceonRobotLearn-
ing,pages991–1002.PMLR,2022.
[44] C.Chi,Z.Xu,C.Pan,E.Cousineau,B.Burchfiel,S.Feng,R.Tedrake,andS.Song. Universal
manipulationinterface: In-the-wildrobotteachingwithoutin-the-wildrobots. arXivpreprint
arXiv:2402.10329,2024.
13[45] H. Fang, H.-S. Fang, Y. Wang, J. Ren, J. Chen, R. Zhang, W. Wang, and C. Lu. Airexo:
Low-cost exoskeletons for learning whole-arm manipulation in the wild. arXiv preprint
arXiv:2309.14975,2023.
[46] A. Toedtheide, X. Chen, H. Sadeghian, A. Naceri, and S. Haddadin. A force-sensitive ex-
oskeletonforteleoperation:Anapplicationinelderlycarerobotics.In2023IEEEInternational
ConferenceonRoboticsandAutomation(ICRA),pages12624–12630.IEEE,2023.
[47] Y.Ishiguro,T.Makabe,Y.Nagamatsu,Y.Kojio,K.Kojima,F.Sugai,Y.Kakiuchi,K.Okada,
andM.Inaba. Bilateralhumanoidteleoperationsystemusingwhole-bodyexoskeletoncockpit
tablis. IEEERoboticsandAutomationLetters,5(4):6419–6426,2020.
[48] H.Lee,J.Kim,andT.Kim.Arobotteachingframeworkforaredundantdualarmmanipulator
withteleoperationfromexoskeletonmotiondata.In2014IEEE-RASInternationalConference
onHumanoidRobots,pages1057–1062.IEEE,2014.
[49] D. Buongiorno, D. Chiaradia, S. Marcheschi, M. Solazzi, and A. Frisoli. Multi-dofs
exoskeleton-basedbilateralteleoperationwiththetime-domainpassivityapproach. Robotica,
37(9):1641–1662,2019.
[50] J.Carpentier,G.Saurel,G.Buondonno,J.Mirabel,F.Lamiraux,O.Stasse,andN.Mansard.
The pinocchio c++ library: A fast and flexible implementation of rigid body dynamics algo-
rithmsandtheiranalyticalderivatives.In2019IEEE/SICEInternationalSymposiumonSystem
Integration(SII),pages614–619,2019.
[51] A..Team,J.Aldaco,T.Armstrong,R.Baruch,J.Bingham,S.Chan,K.Draper,D.Dwibedi,
C. Finn, P. Florence, S. Goodrich, W. Gramlich, T. Hage, A. Herzog, J. Hoech, T. Nguyen,
I. Storz, B. Tabanpour, L. Takayama, J. Tompson, A. Wahid, T. Wahrburg, S. Xu,
S. Yaroshenko, K. Zakka, and T. Z. Zhao. Aloha 2: An enhanced low-cost hardware for
bimanualteleoperation,2024.
[52] Y.Ze,G.Zhang,K.Zhang,C.Hu,M.Wang,andH.Xu. 3ddiffusionpolicy: Generalizable
visuomotorpolicylearningviasimple3drepresentations. InProceedingsofRobotics:Science
andSystems(RSS),2024.
14A End-EffectorControlMappingDetails
With our different modes of operation, we can accurately map the user’s real-world end effector
(EE)center,whichcancomfortablyandfreelydrawspheresinphysicalspace,tothecenterofthe
correspondingtask’sworkspace,whileadjustingthecontrolscale.
Algorithm1MappingtheWorkspace
Require: Robotworkspacecenterrobot center,robotworkspaceradiusrobot radius
Require: Humanmovementdatamax x,max y,max z,min x,min y,min z
Ensure: Mappedhumanworkspacewithinrobotworkspace
1: human center←(maxx+minx,maxy+miny,maxz+minz)
2 2 2
2: human radius ← min(max x − human center.x,max y − human center.y,max z −
human center.z)
3: control scale← robotradius
humanradius
4: offset←robot center−control scale×human center
5: Mapped ee←human ee position×control scale+offset
6: Ensure∥mapped ee−robot center∥<robot radiusforsafety
Algorithm2MapCertainTask
Require: Robotworkspacecenterrobot center,Robotworkspaceradiusrobot radius
Require: Taskcentertask center,Taskcontrolscaletask control scale
Require: Humanmovementdatamax x,max y,max z,min x,min y,min z
Ensure: Mappedhumantaskwithinrobotworkspace
1: human center←(maxx+minx,maxy+miny,maxz+minz)
2 2 2
2: human radius ← min(max x − human center.x,max y − human center.y,max z −
human center.z)
3: control scale←task control scale
4: offset←task center−control scale×human center
5: Mapped ee←human ee position×control scale+offset
6: Ensure∥mapped ee−robot center∥<robot radiusforsafety
Algorithm3MapRotation
Require: Taskrotationrangetask roll range,task pitch range,task yaw range
Require: Human movement data max roll, max pitch, max yaw, min roll, min pitch,
min yaw
1: scale roll← (maxroll−minroll)
taskrollrange
2: scale pitch← (maxpitch−minpitch)
taskpitchrange
3: scale yaw← (maxyaw−minyaw)
taskyawrange
4: offset roll←−scale roll× (maxroll−minroll)
2
5: offset pitch←−scale pitch× (maxpitch−minpitch)
2
6: offset yaw←−scale yaw× (maxyaw−minyaw)
2
7: Mapped roll←human roll×scale roll+offset roll
8: Mapped pitch←human pitch×scale pitch+offset pitch
9: Mapped yaw←human yaw×scale yaw+offset yaw
B HandRetargetingDetails
WemapthehumanhandposedataobtainedfromMediaPipeintojointpositionsoftheteleoperated
robothand. Thisprocessisoftenformulatedasanoptimizationproblem[14],wherethedifference
betweenthekeypointvectorsofthehumanandrobothandisminimized. Theoptimizationcanbe
definedasfollows:
15N
min(cid:88) |αv −f (q )|2+β|q −q |2 (2)
it i t t t−1
qt
i=0
subjectto: q ≤q ≤q
l t u
where q represents the joint positions of the robot hand at time step t, v is the i-th keypoint
t it
vectorforthehumanhandcomputedfromthedetectedfingerkeypoints, f (q )isthei-thforward
i t
kinematics function which takes the robot hand joint positions q as input and computes the i-th
t
keypointvectorfortherobothand,q andq arethelowerandupperlimitsofthejointposition,and
l u
αisascalingfactortoaccountforhandsizedifference. Anadditionalpenaltytermwithweightβ
isincludedtoimprovetemporalsmoothness.
C Target-ReachingTaskDetails
We designed a target-reaching game to test the key performance parameters of both systems in
simulation. AscreenshotofthedesignedgameisshowninFig.7,wheretheonlygoalistocontrol
theend-effectors(alsorepresentedasspheres)toreachtherandomlygeneratedgoals.Whenthegoal
forbotharmsisreachedandtheend-effectorsarekeptinsidethegoalsforanassignedkeeptime,it
isnotedasasuccessandtwonewgoalswillbegeneratedintheworkspace. Wetakeitas“inside”
dependingonthepositionoftheend-effectorandthetargetball,usingthefollowingformula:
1(reached)=∥p −p ∥<=r −r (3)
ee target target ee
whereprepresentsforpositionandrrepresentsforradius,andr > r allthetime. Thegame
target ee
supportsvarioustypesofroboticsarms(withdifferentkinetics),andduringourtest,wechoseXArm
forevaluation.
C.1 Configurations
We construct four different game configurations by varying the workspace, the size of the end-
effector/targetballs,alongthekeeptime. Thefourvariantsaredesignedtoassesstheteleoperation
system’sperformanceunderdifferentconditionsbysimulatingreal-worldrobotictasks. Thesesim-
ulation settings correspond to real-world tasks ranging from highly precise operations like micro-
surgerytolarger-scaletaskssuchashandlinglargeobjects. Specifically,thesesetupsinclude:
The ”Small & Small” setup mimics delicate tasks in confined spaces, while the ”Large & Large”
setup reflects operations requiring speed in a larger workspace. The ”Medium & Small” and
”Medium&Medium”settingsrepresenttasksthatbalanceprecisionandspeed,suchaselectronics
assemblyorgeneralmanufacturingoperations.
These variants differ in terms of workspace size, end-effector/target region size, and duration the
end-effectorsmustremaininthegoalregions. TheirprecisegameparametersareshowninTab.4.
Table4: Thekeyparametersofthefourvariants. Notethattheworkspace,target,andend-effector
areallrepresentedasspheressotheonlyparametersaretheirradius.
ACEControl Workspace Target End-Effector Keep
Workspace Target
Scale Radius(cm) Radius(cm) Sphere(cm) Time(secs)
Small Small 0.5 5 2 1 1
Large Large 6 60 12 6 0.05
Medium Small 1 10 4 2 0.5
Medium Medium 2.5 25 8 4 0.1
C.2 Participants
Weinvite6studentsasourvolunteers,fourofthemaremalesandtwoofthemarefemales. Their
heightrangesfrom165cmto198cm,andtheirweightsvaryfrom55cmto90kg.
16C.3 ExperimentDetails
Playing process. Each participant first plays general range 2 for 5 times, each time lasting 30
seconds. Wehavetwoobjectives. First,toallowuserstofamiliarizethemselveswiththecontroller
through five relatively simple task scenarios. Second, to record the results of these five attempts
toobservethelearnabilityofthesystemThen,participantswillplaygeneral1,fine, andboardfor
once.WetestonlyonceinotherscenariosbecausebothGELLO(thejointcopysystem)andACEare
highlyintuitiveteleoperationsystems. Weaimtoseeifuserscanquicklyadaptwhenencountering
anewscenarioforthefirsttime. Additionally,wewanttoobservetheperformanceofthejointcopy
systemandtheACEsystemintaskscenarioswithvaryingprecisionrequirements.
Grouping. To ensure the fairness of the experiment and the comparability of the results, targets
appearinthesamepositionswithintheidenticalworkspaceacrosstests. Familiaritywiththetesting
simulationcouldalsoaffecttheoutcomes.Therefore,wedividedthesixtestersintotwogroups.One
groupcompletedthefullACEtestbeforetheGELLOtest,whiletheothergroupdidtheopposite.
17