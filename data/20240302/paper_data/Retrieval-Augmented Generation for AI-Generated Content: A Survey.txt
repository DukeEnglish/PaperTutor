1
Retrieval-Augmented Generation for
AI-Generated Content: A Survey
Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng,
Fangcheng Fu, Ling Yang, Wentao Zhang, Bin Cui, Fellow, IEEE
Abstract—ThedevelopmentofArtificialIntelligenceGenerated due to their utilization of novel model algorithms, expan-
Content (AIGC) has been facilitated by advancements in model sive foundation model architectures, and massive high-quality
algorithms, scalable foundation model architectures, and the datasets. Specifically, sequence-to-sequence tasks have transi-
availability of ample high-quality datasets. While AIGC has
tioned from utilizing Long Short-Term Memory (LSTM) [12]
achievedremarkableperformance,itstillfaceschallenges,suchas
the difficulty of maintaining up-to-date and long-tail knowledge, networks to Transformer-based models [13], while image-
the risk of data leakage, and the high costs associated with generation tasks have shifted from Generative Adversarial
training and inference. Retrieval-Augmented Generation (RAG) Networks(GAN)[14]tolatentdiffusionmodels[10].Notably,
has recently emerged as a paradigm to address such challenges.
the architecture of foundation models, initially constituted by
In particular, RAG introduces the information retrieval process,
millions of parameters [15], [16], has now grown to incor-
which enhances AIGC results by retrieving relevant objects
from available data stores, leading to greater accuracy and porate billions of parameters [1], [4]. These advancements
robustness. In this paper, we comprehensively review existing are further bolstered by the availability of rich, high-quality
efforts that integrate RAG technique into AIGC scenarios. We datasets [1], [17], which provide ample training examples to
first classify RAG foundations according to how the retriever
fully optimize model parameters.
augments the generator. We distill the fundamental abstractions
Information retrieval is another pivotal application within
of the augmentation methodologies for various retrievers and
generators. This unified perspective encompasses all RAG sce- the field of computer science. Different from generation,
narios, illuminating advancements and pivotal technologies that retrieval aims to locate relevant existing objects from a vast
helpwithpotentialfutureprogress.Wealsosummarizeadditional pool of resources. The most prevalent application of retrieval
enhancementsmethodsforRAG,facilitatingeffectiveengineering
lies in web search engines, which primarily focus on the task
and implementation of RAG systems. Then from another view,
of document retrieval [18], [19]. In the present era, efficient
we survey on practical applications of RAG across different
modalitiesandtasks,offeringvaluablereferencesforresearchers informationretrievalsystemscanhandledocumentcollections
and practitioners. Furthermore, we introduce the benchmarks ontheorderofbillions[20],[21].Besidesdocuments,retrieval
for RAG, discuss the limitations of current RAG systems, and has also been applied for other modalities [22]–[25].
suggest potential directions for future research. Project Repo:
Despite the remarkable progress made by advanced gen-
https://github.com/hymie122/RAG-Survey.
erative models, AIGC continues to face a number of well-
Index Terms—Retrieval-augmented generation, AI-generated known challenges, including the struggle to maintain up-to-
content, generative models, information retrieval.
date knowledge, the inability to incorporate long-tail knowl-
edge [26], and the risk of leaking private training data [27].
I. INTRODUCTION Retrieval-AugmentedGeneration(RAG)isproposedtoallevi-
ate, if not completely address, the aforementioned challenges
A. Background
through its adaptable data repository. The knowledge stored
RECENT years have witnessed a surge in interest forretrievalcanbeconceptualizedasnon-parametricmemory.
surrounding Artificial Intelligence Generated Content Such a form of memory is easily modifiable, capable of
(AIGC). Various content generation tools have been meticu- accommodating broad long-tail knowledge, and also able to
louslycraftedtoproducediverseobjectsacrossvariousmodal- encode confidential data. In addition, retrieval can also be
ities, such as Large Language Models (LLM) including the employed to reduce the generation costs. For example, RAG
GPTseries[1]–[3]andtheLLAMAseries[4]–[6]fortextsand can reduce the size of large generative models [28], provide
codes, DALL-E [7]–[9] and Stable Diffusion [10] for images, supportforlongcontexts[29],andeliminatecertaingeneration
and Sora [11] for videos. The word “AIGC” emphasizes that steps [30].
the contents are produced by advanced generative models A typical RAG process is shown in Fig. 1: given an input
other than human beings or rule-based approaches. These query,theretrieverlocatesandlooksuprelevantdatasources,
generative models have achieved remarkable performance thentheretrievedresultsinteractwiththegeneratortoenhance
theoverallgenerationprocess.Theretrievalresultscaninteract
•PenghaoZhaoandHailinZhangcontributedequallytothispaper.
with the generation process in different ways: they can serve
• Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng
Geng, Fangcheng Fu, Ling Yang, Wentao Zhang and Bin Cui are with asaugmentedinputtothegenerator[31],[32];theycanjoinat
Peking University (e-mail: penghao.zhao@stu.pku.edu.cn, z.hl@pku.edu.cn, the middle stage of generation as latent representations [33],
yuqinhan@stu.pku.edu.cn, wzr@stu.pku.edu.cn, 1800012997@pku.edu.cn,
[34]; they can contribute to the final generation results in the
ccchengff@pku.edu.cn, yangling0818@163.com, wentao.zhang@pku.edu.cn,
bin.cui@pku.edu.cn). form of logits [35], [36]; they can even influence or omit
4202
beF
92
]VC.sc[
1v37491.2042:viXra2
Fig.1. AgenericRAGarchitecture.Theusers’queries,whichmaybedifferentmodality,serveasinputtoboththeretrieverandthegenerator.Theretriever
searchesforrelevantdatasourcesinstorage,whilethegeneratorinteractswiththeretrievalresultsandultimatelyproducesresultsofvariousmodalities.
certain generation steps [30], [37]. Moreover, built upon the applied.Althoughtextgenerationistypicallyconsideredasthe
typical, foundational RAG process, numerous enhancements mainapplicationofRAG,weemphasizethatthedevelopment
have also been proposed to improve the overall quality. These of RAG in other modalities also began at an early stage and
enhancements encompass methods for specific components as has yielded promising advancements. Certain modalities have
well as optimizations targeting the entire pipeline. arichhistoricalconnectiontotheretrievaltechnique,infusing
RAG with distinctive characteristics. Despite that some sur-
Although the concept of RAG initially emerged in text-
veys on RAG have already been proposed, they mainly focus
to-text generation [32], it has also been adapted to vari-
onpartialaspects,suchasspecificmethodologiesandtasks.In
ous domains, including codes [38]–[40], audios [41], [42],
this paper, our objective is to present a comprehensive survey
images [43]–[45], videos [46], [47], 3D [48], [49], knowl-
to provide a systematic overview of RAG.
edge[50]–[52],andAIforscience[53],[54].Inparticular,the
essentialideaandprocessofRAGarelargelyconsistentacross
modalities.However,itnecessitatesspecificminoradjustments B. Contribution
inaugmentationtechniques,andtheselectionofretrieversand This survey offers a comprehensive overview of RAG, cov-
generators varies depending on the specific modalities and ering foundations, enhancements, applications, benchmarks,
tasks. limitations, and potential future directions. While retrievers
Despite recent rapid growth in research on RAG, a system- and generators exhibit variations across modalities and tasks,
atic review encompassing all foundations, enhancements, and we distill the fundamental abstractions of RAG foundations,
applications is notably absent. The absence of discussion on considering applications as adaptations stemming from these
RAG foundations significantly undermines the practical value abstractions. We aim to offer references and guidelines to
of research in this domain, leaving the potential of RAG not researchers and practitioners, providing valuable insights for
fullyexplored.Whilethemajorityofresearchinterest,particu- advancing RAG methodologies and related applications. In
larlyamongLLMresearchers,centersonquery-basedRAGin summary, we list our contributions as follows:
text-generation tasks, it is essential to acknowledge that other • We conduct a comprehensive review of RAG, and distill
RAG foundation paradigms are also effective techniques with theabstractionsofRAGfoundationsforvariousretrievers
significant potential for usage and further development. The and generators.
lack of an overview on RAG applications causes researchers • WeconcludetheenhancementsonexistingRAGpipeline,
and practitioners to overlook RAG’s progress across multiple elaborating the techniques leveraged to enable more ef-
modalitiesandremainunawareofhowRAGcanbeeffectively fective RAG systems.3
• For various modalities and tasks, we survey existing searches for relevant information; then, the original query and
AIGCmethodsthatincorporateRAGtechniques,exhibit- theretrievalresultsarefedintothegeneratorthroughaspecific
ing how RAG contributes to current generative models. augmentationmethodology;finally,thegeneratorproducesthe
• We discuss the limitations and promising research di- desired outcomes. In Section III-A, we will introduce the
rections of RAG, shedding light on its potential future RAG foundations. In Section III-B, we will introduce further
development. enhancement methods based on a constructed RAG system.
C. Related Work B. Generator
With the advancement of research on RAG, several survey TheremarkableperformanceofgenerativeAIacrossdiverse
papers focusing on RAG have been proposed. Li et al. [55] tasks has ushered in the era of AIGC. Genrative AI, powered
conductedsurveyonRAGfortextgeneration.Sinceitreviews by its robust generative module, has surpassed even the origi-
papers up to 2022, many new advancements of RAG for nal expert systems in terms of effectiveness. Within the entire
AIGC are not included. Asai et al. [56] delivered a tutorial on RAG system, the generation module holds significant impor-
retrieval-based language models, introducing the architectures tance. Different generative models are selected for different
and training paradigms. Gao et al. [57] surveyed RAG for scenarios.Forinstance:transformermodelfortext-to-texttask,
LLMs, especially investigating the enhancements on query- VisualGPT [59] for image-to-text task, Stable Diffusion [10]
based RAG. The above surveys primarily consider RAG for for text-to-image task, and Codex [2] for text-to-code task.
text-related tasks that are facilitated by LLMs, leaving other Basedonmodelstructure,Wecategorizethegeneratorsinto
modalities as potential extensions. However, the concept of 4 main groups: transformer model, LSTM, diffusion model,
RAG emerges across all modalities at an early stage, making and GAN. We will provide a detailed introduction to each
it more suitable for discussion within the broader context category in the following sections.
of the entire AIGC. Zhao et al. [58] proposed a survey
on RAG applications for multiple modalities, but ignoring
Outputs
the discussion on RAG foundations. These surveys either
LossFunction
exclusively focus on a single RAG foundation paradigm or
provide only a brief overview of RAG augmentation method- Transformer x N
LayerNorm
ologies for limited scenarios. Consequently, while existing
researchhasexploredvariousaspectsofRAG,thereremainsa Add
Linear
need for a comprehensive overview that systematically covers FFN
RAG foundations, enhancements, and its applicability across Linear MatMul
differentdomains.Inthispaper,weaimtopresentasystematic
GeLU
overview of RAG that addresses these gaps. Softmax
Linear
Mask (opt.)
D. Roadmap LayerNorm Scale
The rest of the paper is organized as follows. Section II Add
MatMul
elaborates on the preliminary of RAG, introducing retrievers
Attention
and generators. Section III presents the foundations of RAG Q K V
Linear Linear Linear
and further enhancements on RAG. Section IV reviews exist-
ing research on RAG across various applications. Section V
investigates the benchmark frameworks for RAG. Section VI
Embedding
discusses current limitations of RAG and potential future Look-Up
directions. Finally, Section VII concludes this paper.
Inputs
II. PRELIMINARY Fig.2. Architectureofatraditionaltransformermodel.
In this section, we first deliver an overview of the general
1) Transformer Model: The initial transformer was de-
RAG architecture. Subsequently, we delve into the details of
signed to solve problems in the Neural Language Pro-
the generators and retrievers employed in today’s RAG-based
cess (NLP) field, consisting of self attention mechanism, feed
AIGC.
forward network, layer normalization module, and residual
network [60].
A. Overview
As shown in Fig. 2, the input of the transformer is mapped
As shown in Fig. 1, the entire RAG system consists of to a tensor x with a shape of (b, s, h) after the tokenization
in
two core modules: the retriever and the generator. The re- processandembeddingmodel,wherebrepresentsbatchsize,s
triever is responsible for searching relevant information from representssequencelengthandhrepresentshiddendimension.
a constructed data store, and the generator is responsible for Next, the position encoding will be sent to the self attention
producing generated contents. The RAG process unfolds as layer along with this tensor. The input x and the output
in
follows: firstly, the retriever receives the input query and x of the self-attention module will be connected by the
out
…4
residual network and the layer normalization module. Finally, DDIM [92], Rectified Flow [93], Consistency Model [94] and
the output of the ”Add & Norm” module x will be sent to RPG-DiffusionMaster [77].
out
the feed forward network. The entire process can be defined
as follows:
Q=x ∗W +b ,K =x ∗W +b ,V =x ∗W +b ,
in q q in k k in v v
Q∗KT
x =LayerNorm1(Softmax( √ )∗V∗W +b )+x ,
out o o in
h
Fig. 4. Diffusion models smoothly perturb data by adding noise, then
reverse this process to generate new data from noise. Each denoising step
y =LayerNorm2((x ∗W +b )∗W +b )+x .
out 1 1 2 2 out inthereverseprocesstypicallyrequiresestimatingthescorefunction(seethe
illustrativefigureontheright),whichisagradientpointingtothedirections
It should be noted that w ,w ,w ,w are learnable tensors
q k v o ofdatawithhigherlikelihoodandlessnoise,c.f.[62]
with shape (h, h); b ,b ,b ,b are a learnable tensors with
q k v o
shape (h,). Especially, let x be a random variable that follows the
0
data distribution q(x ), and let x be a random variable that
0 t
follows the distribution q(x |x ) after adding noise at time
t 0
step t. Then, DDPM can be formulated as follows:
• ForwardProcessTheforwardprocessperturbsdatawith
asequenceofGaussiannoiseinjections,transformingthe
data distribution q(x ) into a simple prior distribution
Input Output 0
q(x )≈N(0,I). The transition kernel at each time step
T
is given by f z i o
(cid:112)
q(x |x )=N(x ; 1−β x ,β I),
t t−1 t t t−1 t
where β ∈ (0,1) is a hyperparameter. The marginal
t
distribution of x conditioned on x is
t 0
√
q(x |x )=N(x ; α¯ x ,(1−α¯ )I),
Fig.3. ArchitectureofatypicalLSTMblockwithforgetgate. t 0 t t 0 t
2) LSTM: Long Short-Term Memory (LSTM) [61] is a where α t =1−β t and α¯ t
=(cid:81)t
s=0α s.
special Recurrent Neural Network (RNN) model that over- • Reverse Process The reverse process generates new
comes the exploding/vanishing gradient problems of RNN in data samples by reversing the forward process with a
processing long-term dependency information by introducing learnableMarkovchain.Thepriordistributionisp(x T)=
cell state and gate mechanisms. The LSTM model consists N(x T;0,I) and the transition kernel is
of four gates: Input Gate, Forget Gate, Output Gate, and a
p (x |x )=N(x ;µ (x ,t),Σ (x ,t)),
θ t−1 t t−1 θ t θ t
Cell State. These gates update the cell state by controlling the
information flow, enabling the model to remember long-term where θ denotes model parameters, and µ (x ,t) and
θ t
dependent information. Cell State is the core module of the Σ (x ,t)areparameterizedbydeepneuralnetworks.The
θ t
LSTM model which can memorize and maintain information. reverse process starts from sampling x ∼ p(x ) and
T T
TheInputGatedecideswhichinputdatashouldberetainedin iteratively samples x ∼p (x |x ) until t=0.
t−1 θ t−1 t
thecellstate.ForgetGatedetermineswhichcellstateinforma- • Model TrainingForeachsamplex 0 ∼q(x 0),themodel
tion should be discarded to avoid excessive memory. Output training objective is to maximizing the variational lower
Gate determines how the information in the cell state affects bound (VLB) of the log-likelihood of the data x . The
0
thecurrentoutput.Theflowofdataandthecollaborativework simplified form L (x ) is given by
VLB 0
process between components are shown in the Fig. 3.
(cid:34) T (cid:35)
3) Diffusion Model: Diffusion models [62] are a family
E −logp(x
)−(cid:88) logp θ(x t−1|x t)
of deep generative models that can create realistic and di- q(x1:T|x0) T q(x |x )
t t−1
t=1
verse samples of data [63]–[70], such as images [71]–[77],
With simplication and reparameterization trick, the over-
texts [78]–[81], videos [82]–[86], and molecules [87]–[91].
all objective E (cid:2) L (cid:3) can be simplified into the
As shown in Fig. 4, diffusion models work by gradually q(x0) VLB(x0)
final form
adding noise to data until it becomes random, then reversing
the process to generate new data from noise. This process E [λ(t)∥ϵ−ϵ (x ,t)∥]
is based on probabilistic modeling and neural networks.
t∼U[1,T],x0∼q(x0),ϵ∼N(0,I) θ t
Diffusion models mainly have three equivalent formulations: where λ(t) is a positive weighting function, U[1,T] is
denoising diffusion probabilistic models [63]–[65], score- a uniform distribution over the set {1,2,...,T}, and ϵ
θ
based generative models [66], [67], and stochastic differen- is a deep neural network with parameter θ that predicts
tial equations [68], [69], with following improvements like the noise vector ϵ given x and t. Note that, the overall
t
gis hnat gis
hnat
gis5
objective is also equivalent to matching the joint distri- whereIDF istheinversedocumentfrequencyweight,f(q ,D)
i
bution of the reverse process p (x ,x ,...,x ) to that is the number of times that q occurs in the document D, |D|
θ 0 1 T i
of the forward process q(x ,x ,...,x ) by minimizing is the length of D, avgdl is the average document length in
0 1 T
the KL divergence between them. the corpus collection, a and b are tunable parameters.
IDF is computed as:
N −n(q )+0.5
IDF(q )=ln( i +1)
i n(q )+0.5
i
whereN isthenumberofdocuments,andn(q )isthenumber
i
ofdocumentscontainingq .IDF scoreisalsousedinTF-IDF.
i
To enable efficient search, sparse retrieval typically lever-
agesaninvertedindextoorganizedocuments.Concretely,each
term from the query performs a lookup to obtain a list of
Fig.5. ArchitectureofatypicalGenerativeAdversarialNetwork(GAN).
candidate documents, which are subsequently ranked based
on their statistical scores.
4) GAN: Generative Adversarial Networks (GANs) [95]
2) Dense Retriever: Different from sparse retrieval, dense
are highly anticipated deep learning models with amazing
retrieval methods represent queries and keys using dense
capabilities which can simulate and generate realistic images,
embedding vectors, and build approximate nearest neighbor
audio, and other data. Due to its outstanding performance,
(ANN) index to speed up the search. This paradigm can be
GANs have achieved significant achievements in various
appliedtoallmodalities.Fortextdata,recentadvancementsin
fields [96]. The design inspiration of GANs comes from the
pre-trained models, including BERT [15] and RoBERTa [99],
zero-sum game in game theory.
are employed as encoders to encode queries and keys sepa-
As shown in Fig. 5, a typical GAN consists of two main
rately[19],[100]–[103].Similartotext,modelshavebeenpro-
components: a generator and a discriminator. These two parts
posed to encode code data [24], [104], [105], audio data [25],
competewitheachotherthroughadversariallearning,allowing
[106], image data [23], [107], and video data [108], [109].
thegeneratortocontinuouslyimproveitsabilitytogeneratere-
The similarity score between dense representations can be
alisticsamples,whilethediscriminatorcontinuouslyimproves
computed using methods such as cosine, inner product, L2-
its ability to distinguish between true and false samples.
distance.
Duringtraining,denseretrievalusuallyfollowsacontrastive
C. Retriever
learning paradigm, making positive samples more similar and
Retrieval is to identify and obtain information system re- negative samples less similar. Several hard negative tech-
sources that are relevant to an information need. Specifically, niques[100],[110]havebeenproposedtofurtherimprovethe
let’s consider information resources that can be conceptual- modelquality.Duringinference,approximatenearestneighbor
ized as a key-value store {(k ,v )}N , where each key k (ANN) methods are applied for efficient searching. Various
i i i=1 i
corresponds to a value v (often, k and v are identical). indicesaredevelopedtoserveANNsearch,suchastree[111],
i i i
Given a query q, the objective is to search for the top-k [112], locality sensitive hashing [113], neighbor graph in-
mostsimilarkeysusingasimilarityfunctions,andobtainthe dex (e.g., HNSW [114], DiskANN [115], HMANN [116]),
pairedvalues.Basedondifferentsimilarityfunctions,existing the combination of graph index and inverted index (e.g.,
retrieval methods can be categorized into sparse retrieval, SPANN [117]).
dense retrieval, and others. For widely used sparse and dense 3) Others: In addition to sparse retrieval and dense re-
retrieval, the whole process can be divided into two distinct trieval, there are alternative methods for retrieving relevant
phases:inthefirstphase,eachobjectisencodedintoaspecific objects. Instead of calculating representations, some research
representation;andinthesecondphase,anindexisconstructed works directly use the edit distance between natural language
to organize the data source for efficient search. texts [118] or abstract syntax trees (AST) of code snip-
1) Sparse Retriever: Sparse retrieval methods are widely pets [119], [120]. For knowledge graph, entities are linked
used in document retrieval, where the keys are actually doc- with relations, which can be regarded as a pre-built index for
uments to be searched (values are the same documents in retrieval searching. Therefore, RAG methods which involve
this scenario). These methods leverage term matching metrics knowledge graph can use k-hop neighbor search as retrieval
such as TF-IDF [97], query likelihood [98], and BM25 [18], process [121], [122]. Named entity recognition (NER) [123],
whichanalyzewordstatisticsfromtextsandconstructinverted [124] is another way of retrieval, where the input is the query
indices for efficient searching. Among them, BM25 is a hard- and the entites are the keys.
to-beat baseline in industrial-scale web search. For a query q
containing keywords {q i}n i=1, the BM25 score of a document III. METHODS
D is:
In this section, we first introduce the RAG foundations
within the context of AIGC. Subsequently, we outline the
n
s(q,D)=(cid:88)
IDF(q )·
f(q i,D)·(a+1) enhancement methods that further improve the effectiveness
i f(q ,D)+a·(1−b+b· |D| ) of RAG.
i=1 i avgdl6
Fig.6. TaxonomyofRAGfoundations.
A. RAG Foundations and RAG-Sequence differ in their retrieval timings, with the
former retrieving information at each token generation and
Based on how the retriever augments the generator, we
the latter conducting a single retrieval for the entire sequence.
classifytheRAGfoundationparadigmsinto4distinctclasses,
KILT [125] focuses on ensuring information accuracy and
as shown in Fig. 6.
1) Query-based RAG: Query-based RAG is also called reliabilitybyaligningWikipediapageswithspecificsnapshots
prompt augmentation. It integrates the user’s query with in- and pinpointing the most pertinent text ranges through BLEU
sights from documents fetched during the retrieval process, score evaluations. It filters out lower-quality data to maintain
directly into the initial stage of the language model’s input. a high standard of information mapping, offering a variety of
This paradigm stands as a widely adopted approach within retrieval system options like Tf-idf, DPR, RAG, and BLINK
the applications of RAG. Once documents are retrieved, their + flair to support evidence-based predictions or citations ac-
contentismergedwiththeoriginaluserquerytocreateacom- cording to task requirements. SELF-RAG [126] enhances the
positeinputsequence.Thisenhancedsequenceissubsequently accuracy and relevance of responses by integrating a retrieval
fed into a pre-trained language model to generate responses. andcritiquestrategy.Initially,themodelemploysaretrieverto
REALM [31] employs a dual-BERT framework to stream- search for information paragraphs closely related to the input
line knowledge retrieval and integration, marrying pre-trained question. Subsequently, the critique model evaluates these
models with knowledge extractors. The initial BERT module paragraphstodeterminetheirrelevanceandlevelofsupportof
processes the input question alongside documents to facilitate the retrieved text, assessing their impact on the generation of
retrieval, utilizing MIPS for selecting the top-k documents responses. Finally, the generator model constructs responses
with the highest probability and periodically updating the in- based on this information and evaluates the quality of these
dex. The document snippets obtained are then integrated with responses through critique marks.
the query, feeding into the second BERT module to produce Recently, some methods have proposed to implement RAG
multiple outputs that are aggregated into a singular, compre- without modifying the language model architecture, which
hensive response. RAG [32] synergizes pre-trained language is particularly suitable for scenarios where language models
modelswithknowledgeretrievalmechanisms,leveragingDPR are accessed through APIs. REPLUG [127] illustrates this
and BART structures to accomplish retrieval-augmented gen- methodologybytreatingthelanguagemodelasa”blackbox,”
erationtasks.DPRservesastheretrievalcomponent,sourcing utilizingContrievertoseamlesslyincorporaterelevantexternal
pertinent information from vast document databases, while documents into the query. REPLUG LSR, a variant with LM-
BART uses this information for text generation. RAG-Token SupervisedRetrieval,furtherrefinesthisprocessbyoptimizing7
retrieval through language model-supervised insights, aiming enhancingthemodel’scomprehensionabilitiesandthequality
to reduce perplexity scores and improve model performance of the content generated.
by enriching its contextual understanding. RALM [128] uses The FiD [33] technique leverages both BM25 and DPR
the BM25 algorithm for document retrieval and predictive for sourcing supportive paragraphs. It concatenates each re-
reranking to select pertinent documents for input integration. trieved paragraph and its title with the query, processing
In contemporary multimodal application research, integrat- them individually through the encoder. FiD reduces computa-
ingretrievedcontentintoinputshasprovenhighlyeffectivein tional complexity and efficiently utilizes relevant information
enhancing the performance of various tasks. This strategy is to generate answers by fusing information from multiple
applicableacrossseveralkeyfields,includingcodegeneration, retrieved paragraphs in the decoder, rather than processing
audio generation, and Knowledge Base Question Answering each paragraph in the encoder. The application of Fusion-
(KBQA). in-Decoder methodologies transcends the realm of textual
For text-to-code task, APICoder [129] and DocPrompt- content processing, demonstrating substantial potential and
ing [40] demonstrate how effectively integrating retrieved adaptability in processing code, structured knowledge, and
information into language models can improve the accuracy diverse multimodal datasets. Specifically within the code-
and relevance of generated code. In automatic program repair relateddomain,technologiessuchasEDITSUM[138],BASH-
task, CEDAR [130] and InferFix [131] utilize retrieved code EXPLAINER [139], and RetrieveNEdit [140] adopt the FiD
snippets to aid the repair process, enhancing the model’s approach, facilitating integration through encoder-processed
understanding and application of repair strategies by combin- fusion. Re2Com [141] and RACE [141] , among other meth-
ing them with the original input. For code completion task, ods, also feature the design of multiple encoders for different
ReACC [132] employs a prompting mechanism, leveraging types of inputs. In the field of Knowledge Base Question
retrieved code snippets as part of the new input to increase Answering(KBQA),theFiDmethodhasbeenwidelyadopted,
the accuracy and efficiency of code completion. demonstrating significant effectiveness. UniK-QA [142], DE-
CAF [143], SKP [144], KD-CoT [145], and ReSKGC [146]
In the audio generation field, MakeAnAudio [42] leverages
have effectively enhanced the performance of QA systems
retrieval to construct captions of language-free audio, so as to
throughtheapplicationofFusion-in-Decodertechnology.This
mitigate the data sparsity for text-to-audio training.
illustrates that by integrating RAG for KBQA, the efficiency
Recent research in KBQA has shown significant effects of
andaccuracyofQAsystemscanbesignificantlyimproved.In
combining retrieval and language models. Uni-Parser [133],
the field of Science, RetMolRetMol [53]and DeepICL [147]
RNG-KBQA [121], and ECBRF [134] effectively improve
employ the Fusion-in-Decoder strategy, integrating informa-
the performance and accuracy of QA systems by merging
tion at the decoder stage to enhance the relevance and quality
queries and retrieved information into prompts. BLLM aug-
of the generated molecular structures.
mentation [135] represents an innovative attempt at zero-
Retro [34] pioneers the integration of retrieved text via
shot KBQA using black-box large language models. This
”ChunkedCross-Attention,”anovelmechanismthatsegments
method, by directly integrating retrieved information into the
the input sequence into discrete chunks. Each chunk indepen-
model input without the need for additional sample training,
dently executes cross-attention operations, thereby mitigating
demonstrates the great potential of combining retrieval and
computational burdens. This technique enables the model to
languagemodelstoenhancethemodel’sgeneralizationability
selectively retrieve and assimilate distinct documents for var-
in understanding and answering unseen questions.
iedsequencesegments,fosteringdynamicretrievalthroughout
InthescientificdomainofRAGtechnology,GeneGPT[54]
thegenerationprocess.Thisenhancesthemodel’sadaptability
is utilized to address genomics inquiries, whereas Chat-
and enriches the contextual backdrop of generated content. In
Orthopedist[136]aimstoprovidesupportforshareddecision-
the domain of image generation, cross-attention mechanisms
making among adolescents with idiopathic scoliosis. Both ap-
have been widely adopted within RAG frameworks. Methods
proachesenhancetheapplicationeffectivenessandinformation
such as Re-imagen [148], KNN-Diffusion [149], RDM [150]
accuracy of large language models by integrating retrieved
and LAION-RDM & ImageNet-RDM [151] utilize cross-
information into the prompts of these models.
attention to integrate multiple retrieval results, effectively
Inthetaskofimagegeneration,RetrieveGAN[43]enhances
enhancing the overall performance of the models. On the
therelevanceandaccuracyofgeneratedimagesbyintegrating
other hand, Li [152] introduces the ACM, a text-image affine
retrieved information, including selected image patches and
combinationmodule,whichnotablydoesnotemployanyform
their corresponding bounding boxes, into the input stage of
of attention mechanism.
thegenerator.IC-GAN[137]modulatesthespecificconditions
Distinctly, TOME [153] shifts the focus towards compre-
and details of the generated images by concatenating noise
hensive mention encodings, prioritizing the granularity of
vectors with instance features.
mention over mere entity representations. It meticulously
In the field of 3D generation, RetDream [48] initially generatesencodingsforeachentitymentionacrossWikipedia,
utilizesCLIPtoretrieverelevant3Dassets,effectivelymerging populating a repository with approximately 150 million en-
theretrievedcontentwiththeuserinputduringtheinputphase. tries. This repository, encompassing key and value encod-
2) Latent Representation-based RAG: In the framework ings alongside entity IDs, empowers the retrieval of much
of Latent Representation-based RAG, the generative models more fine-grained information. TOME integrates an initial
interactwithlatentrepresentationsofretrievedobjects,thereby transformer block to process input texts, followed by TOME8
blocks with memory attention layers, facilitating the synthesis The kNN-LM [35] model integrates a pre-trained neural
of multifaceted information sources and enhancing inferen- languagemodelwiththek-nearestneighborsearch.Itemploys
tial reasoning capabilities, even for unencountered entities. thepre-trainedmodeltogeneratealistofcandidatewordsand
Memorizing Transformers [29] revolutionize long document theirprobabilitydistribution,whilesimultaneouslyperforming
processingthroughtheintegrationofakNN-augmentedatten- retrieval from a data repository to find the k most relevant
tion mechanism within a Transformer layer. This innovation neighbors based on the current context, thus enhancing the
triggers a kNN search amidst input sequence processing, output of the original language model. The innovation at the
fetching data based on similarities between the sequence and core of this model lies in its ability for dynamic retrieval of
stored key-value pairs, thereby elevating performance without information from a broad text corpus, significantly improving
necessitating complete retraining. This approach not only the accuracy and relevance of its predictions, particularly
bolsters processing efficiency but also broadens the model’s in addressing rare patterns and adapting to various fields.
memory span, enabling self-retrieval from its generated out- He [36] introduces a new framework that is predicated on
puts and fine-tuning for extensive knowledge bases or code performing retrieval operations only when necessary, aimed
repositories. Unlimiformer [154], by embedding a k-nearest at enhancing the inference efficiency of the kNN-LM model
neighbors (kNN) index within a pre-trained encoder-decoder through an adaptive retrieval. This framework accelerates the
transformer framework, pioneers handling inputs of indefinite model’s inference speed by training a retrieval adapter, which
length.StoringhiddenstatesofinputtokensinthekNNindex automatically identifies and eliminates unnecessary retrieval
allows for the efficient retrieval of highly relevant tokens actions in certain scenarios. This method allows the model to
duringdecoding.Thisinnovationextendsthemodel’scapacity dynamically decide on the necessity of retrieval based on the
to manage prolonged sequences. current context, thereby balancing the trade-off between per-
Diverging from prior methods for knowledge, EaE [155] formanceandefficiency,andsubstantiallyincreasinginference
empowers language models to internalize explicit entity speed while maintaining model performance.
knowledge.EaEintroducesanentity-specificparameterization, Unlike previous methods that only merge memories during
optimizing inference efficacy through an entity memory layer the testing time, TRIME [159] achieves memory merging
embedded within the transformer architecture. This layer di- during both training and testing phases, treating in-batch
rectly acquires entity representations from textual data, utiliz- examples as accessible memory. TRIME leverages new data
ingasparseretrievalstrategytofetchthenearestentitiesbased batching and memory construction techniques to effectively
ontheirembeddings,thusrefiningthemodel’scomprehension utilize external memory. TRIME employs BM25 scores to
throughacalculatedaggregationofentity-specificinformation. pack paragraphs with high lexical overlap into the same
In the field of 3D generation, ReMoDiffuse [49] introduces batch, constructing the training memory to further optimize
a semantics-modulated attention mechanism. This technol- model performance. NPM [160] is a non-parametric masked
ogy enhances the accuracy of generating corresponding 3D language model comprised of an encoder and a reference
motions based on textual descriptions. AMD [156] achieves corpus. Unlike traditional models that apply a softmax over a
efficient conversion from text to 3D motion by fusing the finite vocabulary, NPM models a non-parametric distribution
originaldiffusionprocesswiththereferencediffusionprocess. overthecorpus.Theencoder’sroleistomapphrasesfromthe
In the audio domain, Koizumi [41] utilizes a pre-trained corpusintofixed-sizevectors,fillingin[MASK]byretrieving
large-scale language model, incorporating dense features gen- the phrase most similar to the masked position.
erated by VGGish and embedding networks in the atten- Beyond the text domain, other modalities such as code and
tion module to guide the generation of audio captions. Re- imagealsoutilizemethodsthatintegrateretrievedcontentwith
AudioLDM [157] extracts deep features from text and audio language models in the final output stage.
using T5and AudioMAE, andintegrates thesefeatures within For code-to-text conversion task, Rencos [119] generates
theattentionmechanismofitsLatentDiffusionModel(LDM). multiple summary candidates in parallel from the retrieved
In the field of video captioning, R-ConvED [46] employs code. It then normalizes these candidates using edit distance
a convolutional encoder-decoder network architecture, which and calculates the final probability to select the summary out-
processes retrieved video-sentence pairs with the aid of an at- putthatbestmatchestheoriginalcode.Incodesummarization
tentionmechanismtogeneratehiddenstatesandsubsequently task, EDITSUM [138] enhances the quality of summary gen-
produce captions. CARE [158] introduces a concept detector eration by integrating prototype summaries at the probability
as an input to the decoder and embeds concept representa- level. For text-to-code tasks, the kNN-TRANX [161] model
tions within a hybrid attention mechanism. EgoInstructor [47] employs a combination of a confidence network and meta-
employs gated-cross attention to integrate these textual inputs knowledge to merge retrieved code fragments. It utilizes a
with encoded video features, enhancing the relevance and seq2tree structure to generate target code that closely matches
coherence of the generated captions for egocentric video theinputquery,therebyincreasingtheaccuracyandrelevance
content. of code generation.
3) Logit-based RAG: In Logit-based RAG, generative Inimagecaptioningtasks,MA[162]combinesanattention-
models combine retrieval information through logits during based encoder-decoder, using the image encoder to extract
the decoding process. Typically, the logits are summed or visual features to construct the semantic part, and decodes it
combined through models to produce the probability for step- wordbywordwiththeinformationretrieved.MAinterpolates
wise generation. between two distributions generated by the caption decoder9
Fig.7. TaxonomyofRAGEnhancements.
and thememory-augmented module to determinethe distribu- outdated documents, synthesize new data, etc. which can
tion of the next word. effectively improve the performance of the final RAG system.
4) Speculative RAG: Speculative RAG looks for opportu- MakeAnAudio [42] uses captioning and audio-text retrieval
nities to use retrieval instead of generation to save resources to generate caption for language-free audio to mitigate data
and accelerate response speed. REST [30] replaces the small sparsity, and adds random concept audio to improve the
models in speculative decoding [163] with retrieval, so as to original audio.
generate drafts. GPTCache [37] tries to solve the problem 2) Retriever Enhancement: In the RAG system, the pro-
of high latency when using the API of LLMs by building cess of retrieval is crucial. Generally, the better the content
a semantic cache for storing LLM responses. quality, the easier it is to stimulate the ability of LLMs in-
context learning as well as other generators and paradigms.
B. RAG Enhancements The worse the content quality, the more likely it is to cause
model hallucinations. Therefore, in this section, we will
In this section, we will introduce methods to enhance RAG
discuss how to efficiently improve the effectiveness of the
performance. We categorize existing methods into 5 distinct
retrieval process.
groups based on their enhancement targets: input, retriever,
generator, result, and the entire pipeline. a) Recursive Retrieve: Recursive retrieve is the process
1) Input Enhancement: The input refers to the user’s of splitting a query before retrieval, and performing multiple
query, which is initially fed into the retriever. The quality of searchestoretrievemoreandhigherqualitycontent.Jagerman
theinputsignificantlyimpactsthefinaloutcomeoftheretrieval et al. [166] uses Chain-of-Thought(COT) [167] to enable the
stage.Consequently,enhancingtheinputbecomesessential.In model to break queries down gradually and provide more rich
this section, we introduce two methods: query transformation related knowledge. LLMCS [168] applies this technology to
and data augmentation. the conversational system and obtained better retrieval results
a) Query Transformation: Query transformation can by rewriting the conversation record.
enhance the result of retrieval by modifying the input query. b) Chunk Optimization: Chunk optimization technique
Query2doc [164] and HyDE [165] first use query to generate refers to adjusting the size of the chunk to achieve better re-
a pseudo document, and then use this document as a key trieval results. Sentence-window retrieval [169] is an efficient
for retrieval. The advantage of doing so is that the pseudo approach that enhances retrieval by fetching small chunks of
document will contain more rich relevant information, which textandreturningawindowofrelevantsentencessurrounding
helps to retrieve more accurate results. the retrieved segment. This method ensures that the context
b) Data Augmentation: Data augmentation refers to before and after the targeted sentence is included, providing a
improvingthedatainadvancebeforeretrieval,suchasremov- more comprehensive understanding of the retrieved informa-
ing irrelevant information, eliminating ambiguity, updating tion. Auto-merge retrieval is another advanced RAG method10
of LlamaIndex [169] which organizes the document in a tree- a) Prompt Engineering: Technologies in prompt engi-
like structure, with the parent node containing the content of neering [180] that focus on improving the quality of LLMs’
all children nodes. For example, articles and paragraphs, as output, such as Prompt compression, Stepback Prompt [181],
well as paragraphs and sentences, all follow a parent-child Active Prompt [182], Chain of Thought Prompt [167], etc.,
relationship. In the retrieve process, fine-grained search for are all applicable to LLM generators in RAG systems. LLM-
children nodes ultimately returns the parent node, effectively Lingua [183] applies a small model to compresses the overall
providing richer information. lengthofthequerytoacceleratemodelinference,relievingthe
c) FinetuneRetriever: AsacorecomponentintheRAG negative impact of irrelevant information on the model and
system, the retriever plays a crucial role in the entire system alleviating the phenomenon of ”Lost in the Middle” [184].
operation process. A good embedding model can bring se- ReMoDiffuse [49] decomposes complex descriptions into
manticallysimilarcontentclosertogetherinvectorspace.The anatomical text scripts by using ChatGPT. ASAP [185] add
strongertheretriever’sability,themoreusefulinformationcan exemplar tuples to the prompt for better results. An exemplar
be provided for the subsequent generator, thereby improving tuple is composed of the input code, a function definition, the
the effectiveness of the RAG system. Therefore, the ability of resultsofanalyzingthatdefinitionanditsassociatedcomment.
the embedding model [170]–[173] is crucial for the overall CEDAR [130] uses a designed prompt template to organize
effectiveness of the RAG system. code demonstration, query, and natural language instructions
In addition, for embedding models that already have good into a prompt. XRICL [178] utilizes COT technology to add
expressionpower,wecanstillfinetunethemusinghigh-quality translation pairs as an intermediate step in cross linguistic
domain data or task related data to improve their performance semantic parsing and inference. MakeAnAudio [42] is able to
in specific domains or tasks. REPLUG [127] treats LM as a use other modalities as input which can provide much richer
black box and update the retriever model based on the final information for the following process.
results. APICoder [129] finetunes the retriever with python b) Decoding Tuning: Decoding tuning refers to adding
files and api names, signature, description. EDITSUM [138] additional controls during the generator processing, which
finetunestheretrievertodecreasethejaccarddistancebetween can be achieved by adjusting hyperparameters to achieve
summaries after retrieval. SYNCHROMESH [120] adds tree greater diversity, limiting the output vocabulary in some
distance os ASTs in the loss and uses Target Similarity form, and so on. InferFix [131] balances the diversity and
TuningtofinetunetheRetriever.R-ConvED[46]finetunesthe quality of results by adjusting the temperature in decoder.
Retriever with the same data as generator. SYNCHROMESH [120] limits the output vocabulary of the
d) Hybrid Retrieve: Hybrid retrieve refers to the simul- decoder by implementing a completion engine to eliminate
taneous use of multiple types of retrieval methods. RAP- implementation errors. DeepICL [147] controls the random-
Gen [174] and ReACC [132] use both dense retriever and ness of the generation according to an additional temperature
sparse retriever to improve the quality of retrieval. Ren- factor.
cos[119]usessparseretrievertoretrievesimilarcodesnippets c) Finetune Generator: The finetuning of the generator
on syntactic-level and usse dense retriever to retrieve similar can enhance the model’s ability to have more precise domain
code snippets on semantic-level. BASHEXPLAINER [139] knowledgeorbetterfitwiththeretriever.RETRO[34]fixesthe
first uses dense retriever to capture semantic information parametersoftheretrieverandusesthechunkedcrossattention
and then uses sparse retriever to acquire lexical information. mechanism in the generator to combine the content of the
RetDream [48] first retrieves with text and then retrieves with query and retriever. APICoder [129] finetunes the generator
the image embedding. CODEGEN-MONO 350M [186] with a shuffled new file
e) Re-ranking: The Rerank technique refers to reorder- combinedwithAPIinformationandcodeblocks.CARE[158]
ing the retrieved content in order to achieve greater diversity first uses image data, audio data and vedio-text pairs to train
andbetterresults.Re2G[175]appliesare-ranker[176]model encoders and then finetune the decoder (generator) with the
afterthetraditionalretriever.Theeffectofthere-rankermodel target of decreasing caption loss and concept detection loss
is to re-rank retrieved documents, the purpose of which is to together, during which the encoders and the retriever are
reduce the impact of information loss caused by compressing frozen. Animate-A-Story [187] optimizes the video generator
text into vectors on the quality of retrieval. AceCoder [177] with image data, and then finetunes a LoRA [188] adapter
rerank the retrieved programs with a selector. The purpose to capture the appearance details of the given character. Ret-
of introducing the selector is to reduce redundant programs Dream[48]finetunesaLoRAadapter[188]withtherendered
and obtain diverse retrieved programs. XRICL [178] uses a images.
distillation-based exemplar reranker after retrieval. 4) ResultEnhancement: Inmanyscenarios,thefinalresult
f) Meta-data Filtering: Meta-data filtering [179] is of RAG may not achieve the expected effect, and some
another method to help processing retrieved documents which techniques of Result Enhancement can help alleviate this
uses metadata (such as time, purpose, etc.) to filter the re- problem.
trieved documents for better results. a) Rewrite Output: SARGAM [189] modifies the gen-
3) Generator Enhancement: In RAG systems, the quality erated results in code-related task by classifying Deletion
ofthegeneratoroftendeterminesthequalityofthefinaloutput Classifier, Placeholder Classifier and Insertion Classifier with
results. Therefore, the ability of the generator determines the Levenshtein Transformer to better adapt to the actual code
upper limit of the entire RAG system’s effectiveness. context. Ring [190] obtains diversity results by reranking11
candidates based on the average of per token log probabilities A. RAG for Text
producedbythegenerator.CBR-KBQA[52]revisestheresult
In this section, we will introduce some popular work for
by aligning generated relations with those presented in the
text generation using RAG methods.
local neighborhood of the query entity in knowledge graph.
1) Question Answering: Question Answering involves the
5) RAG Pipeline Enhancement:
process of providing responses to posed questions by drawing
a) Adaptive Retrieval: Some studies and practices on
from a vast and comprehensive collection of textual sources.
RAG have shown that retrieval is not always beneficial for
thefinalgeneratedresultsWhentheparameterizedknowledge FID[33]andREALM[31]identifythetopkmostpertinent
of the model itself is sufficient to answer relevant questions, article snippets based on the query and forward each snippet
excessiveretrievalwillcauseresourcewasteandmayincrease along with the question to large language models (LLMs) to
the model’s confusion. Therefore, in this chapter, we will generate k responses. These responses are then synthesized
discuss two types of methods for determining whether to into a final answer. Toutanova et al. [199] substituted the
retrieve, named rule-based and model-based methods. text corpus in REALM with subgraphs from a knowledge
graph, yielding impressive results. Atlas [28] demonstrated
Rule-based: FLARE [191] actively decides whether and
that leveraging Retrieval-Augmented Generation (RAG) to
when to search through the probability in the generation
assist LLMs in open-domain question answering tasks signif-
process.Efficient-KNNLM[36]combinesthegenerationprob-
icantly enhances few-shot learning capabilities. RETRO [34]
ability of KNN-LM [35] and NPM [160] with a hyperpa-
rameter λ to determine the proportion of generation and employs attention mechanisms to integrate the question with
relevant retrieved documents within the model to produce
retrieval. Mallen et al. [192] conducts statistical analysis
the final answer. SKR [196] observed that using RAG does
on questions before generating answers, allowing the model
not invariably benefit Question Answering and thus explored
to directly answer high-frequent questions, and introducing
guidingthemodeltoevaluateitsgraspofpertinentknowledge,
RAG for low-frequent questions. Jiang et al. [193] studies
subsequentlyadaptingitsuseofexternalresourcesforretrieval
Model Uncertainty, Input Uncertainty, and Input Statistics to
enhancement.KAPING [200] enhances the quality of LLM
comprehensively assess the confidence level of the model.
responses byincorporating structured knowledgefrom knowl-
Ultimately, based on the confidence level of the model, a
edgegraphsintotheinputviaconstructedprompts.TOG[201]
decision is made whether to retrieve. Kandpal et al. [194]
introduced an innovative knowledge graph-augmented LLM
assistsindeterminingwhetheraretrievalisneededbystudying
framework, which excels by fostering interactions between
the relationship between the number of relevant documents in
LLMs and the Knowledge Graph and by expanding the in-
thetrainingdatasetandthedegreetowhichthemodelmasters
ferencepathspacewithbeamsearch.Addressingthelong-tail
relevant knowledge.
issue. NPM [160] pioneered the use of nonparametric data
Model-based: Self-RAG [126] uses a trained generator to
distributions in lieu of the softmax layer, enabling models
determine whether to perform a retrieval based on the retrieve
with fewer parameters to perform effectively. Self-RAG [126]
token under different instructions, and evaluates the relevance
improves answer quality by learning to discern when to
and level of support of the retrieved text through the Self-
retrieve, assess the retrieved content’s relevance, and evaluate
Reflection token. Finally, the quality of the final output result
thefinalgeneratedresultsusingfourtypesofreflectivetokens.
is evaluated based on the Critique token. Ren et al. [195]
CL-ReLKT [202] employs a language-generalized encoder to
uses ”Judgment Prompting” to determine whether LLMs can
bridge the gap between question-document pairs across lan-
answer relevant questions and whether their answers are
guages, thus better leveraging multilingual data. CORE [203]
correct or not, thereby assisting in determining the necessity
mitigates language resource disparities by introducing a novel
of a retrieval.SKR [196] uses the abilityof LLMs themselves
dense passage retrieval algorithm and a multilingual autore-
tojudgeinadvancewhethertheycananswerthequestion,and
gressivegenerationmodel.Lastly,EAE[155]enhancesanswer
if they can answer, no retrieval is performed.
quality by retrieving entity embeddings for query entities and
b) Iterative RAG: RepoCoder [197] applies an iterative
integrating these with hidden states for further processing.
retrieval-generation pipeline to better utilize the useful in-
UR-QA [204] found that when encountering unseen prob-
formation scattered in different files in the code completion
lems, retrieving QA pairs has a better final effect; When
tasks. It augments the retrieval query during the i-th iteration
encountering problems that have not been seen before, the
with previously generated code and obtain greater results.
retrieve text chunk performs better. Therefore, it is proposed
ITER-RETGEN [198] synergizes retrieval and generation in
tosimultaneouslyretrieveQApairsandtextchunks,andselect
aniterativemanner.Thecurrentoutputofthegeneratorcanto
the final answer by comparing the calibrated confidences.
someextentreflecttheknowledgeitstilllacks,andtheretrieve
canretrievethemissinginformationascontextualinformation 2) Fact Verification: Fact Verification involves assessing
for the next round, which helps to improve the quality of the the veracity of information, a critical function in disciplines
generated content in the next round. such as Natural Language Processing (NLP), Information Re-
trieval, and Data Mining. In today’s digital era, characterized
by an exponential increase in data, particularly across social
IV. APPLICATIONS
mediaandonlinenewsplatforms,thereisarapidproliferation
In this chapter, we will introduce the popular RAG appli- of unchecked information. Fact verification plays an essential
cations in different fields. role in countering the spread of fake news, deceptive content,12
Fig.8. Taxonomyofmultipleapplicationsinmultimodality.
andrumors,therebypreservingtheintegrityoftheinformation 3) Commonsense Reasoning: Commonsense Reasoning
landscape and ensuring the public’s access to accurate knowl- entailsthecapabilityofmachinestoinferormakedecisionson
edge.Consequently,automatedfactverificationsystemsareof problemsortasksinahuman-likemanner,drawingupontheir
immense importance, with broad applications and significant acquiredexternalknowledgeanditsapplication.However,the
practical value. vast scope of common sense knowledge and the intricacies of
reasoning processes make Commonsense Reasoning a peren-
nially challenging and prominent area of research within the
CONCRETE [205] leverages cross-lingual retrieval mecha-
field of Natural Language Processing (NLP).
nismstotapintoawealthofmultilingualevidence,effectively
bridging the gap in resources for languages that are underrep- KG-BART [206] expands the conceptual landscape by
resented in fact-checking datasets. incorporating intricate interrelations among diverse concepts13
within a knowledge graph. It employs graph attention mech- extraction is to convert the nuanced details embedded within
anisms to aid large language models (LLMs) in crafting text into a structured format, thereby facilitating advanced
morenuancedandlogicallycoherentsentences.Thisapproach analysis, efficient information retrieval, and practical down-
not only improves the models’ generalization capabilities stream applications.
but also significantly bolsters their Commonsense Reasoning R-GQA [214] employs a retrieval-based approach to en-
proficiency. hance the context of a given issue by identifying and utilizing
4) Human-Machine Conversation: Human-Machine Con- the most closely aligned Question-Answer pair from a reposi-
versation encompasses the ability of machines to comprehend tory,therebyenrichingtheinformationavailableforprocessing
natural language and adeptly employ this skill to engage with the current query.
humans seamlessly. This capability represents a significant 7) Summarization: In the realm of Natural Language Pro-
challenge within the realms of Artificial Intelligence and cessing (NLP), Summarization is a task aimed at distilling
Natural Language Processing and offers a broad spectrum of the essential information from lengthy texts and producing
practicalapplications.Assuch,Human-MachineConversation a concise, coherent summary that encapsulates the primary
continues to be a focal point of research for many scholars. themes. Summarization enables users to quickly grasp the
ConceptFlow [207] leverages a commonsense knowledge essenceofatext,therebyconservingtimethatwouldotherwise
graphtostructureconversations,directingtheflowofdialogue be spent on reading extensive material. There are two main
based on attention scores, and propelling the conversation approaches to Summarization: Extractive and Abstractive.
forward. This method achieves commendable results even Extractive Summarization involves the automatic selection
with a substantial reduction in model parameters. Cai et and compilation of key phrases directly from the source
al. [208] reimagines the text generation task as a cloze test text. A key phrase succinctly captures the main themes,
by retrieving and distilling the essence of past conversational content, or perspectives of the text and is typically composed
history, leading to notable outcomes. Komeili et al. [209] of one or several words. The generation of key phrases is
augments dialogue generation quality by harnessing advanced instrumental for understanding, categorizing, retrieving, and
searchenginetechnologiestosourcepertinentcontentfromthe organizing textual information. It is extensively applied in
internet. BlenderBot3 [210] broadens its search horizon, not fields such as search engine optimization, academic research,
only mining relevant internet content but also local dialogue text summarization, and more. This technique refrains from
history,andemploysentityextractionamongothertechniques creating new sentences, instead repurposing segments from
torefinethequalityoftheresultingdialogue.Kimetal.[211] the original text.
improves the caliber of non-English conversations by incor- Abstractive Summarization, on the other hand, entails com-
porating cross-lingual knowledge, effectively addressing the prehending the original text’s meaning and reformulating it
scarcity of non-English datasets and enhancing the quality of into new sentences. This approach can convey the source’s
the generated dialogue. intent more fluidly but poses greater challenges in terms of
5) Neural Machine Translation: NeuralMachineTransla- implementation due to its complexity.
tion (NMT) is the automated process of translating text from RAMKG [215] effectively leverages a comprehensive En-
a source language to a target language. It is a pivotal task glish corpus to bolster the performance of Keyphrase Genera-
in the domain of Natural Language Processing (NLP) and tioninnon-Englishcontexts.Itdoessobyenhancingthealign-
represents a significant objective in the pursuit of Artificial ment of keywords extracted from texts in different languages
Intelligence(AI),boastingconsiderablescientificandpractical thatsharesimilarsubjectmatter.Unlimiformer[154]addresses
significance. the issue of input length constraints in transformer-based
Caietal.[212]proposeaninnovativeapproachthatutilizes models by retrieving and utilizing the top-k most relevant
monolingual corpora alongside multilingual learning tech- hiddenstates,therebyextendingthemodel’scapacitytohandle
niques, challenging the traditional dependency on bilingual longer inputs.
corporainNeuralMachineTranslation.Thisapproachensures
that the retrieval system provides ample information while
B. RAG for Code
simultaneously optimizing both the retrieval mechanism and
the translation model, culminating in impressive performance. Code-related tasks, including code generation, code sum-
KNN-MT [213] executes translation tasks at the token level marization, code auto-completion, automatic program repair,
bycomputingvectorspacedistances.TRIME[159]effectively etc., are always a focus in the field of software engineering.
minimizes the discrepancy between training and inference Retrieval and generation are previously two separate ways
phases by jointly training the retrieval system and the gener- to resolve these tasks. For retrieval, similar code snippets
ation model, thereby enhancing the precision of translations. can be found through similar Abstract Syntax Trees or text
6) Event Extraction: Event Extraction is a specialized edit distances, while natural languages can be found through
task within Natural Language Processing (NLP) that focuses sparse retrieval or dense retrieval. For generation, considering
on pinpointing and extracting instances of particular event that code has a sequential data form, many sequence-to-
types from unstructured textual data. An event is generally sequence models are applied, from LSTM, Transformers, to
characterized by a central action or predicate and the related current decoder-only LLMs. Recent research leverages both
entities, which can include participants, temporal indicators, techniques to achieve better performance, augmenting the
locations, and other relevant attributes. The objective of event generation process with the retrieved results.14
1) Code Generation: The goal of code generation is to based LSTM. There are three encoders for the code input and
transform natural language (NL) descriptions into code im- two retrieval results respectively, and the decoder combines
plementation, which can be seen a process of text-to-code. three probabilities for final generation. Re2Com [220] and
Therefore,LSTMandtransformermodelsarewidelyusedfor EditSum[138]bothretrievesimilarcodeusingsparseretrieval
generator. Whether to use code-specific retrieval or text-based BM25 and generate summary using LSTM. They separately
retrieval depends on the contents to be searched. encode the input, the retrieved code, and the corresponding
Retrieval-based prompt engineering in few-shot learning is summary, then combine the middle representations or prob-
oneofthemostprevalentscenariosofRAGincodegeneration. abilities in the decoder. HGNN [221] instead uses code edit
Few-shotlearning,orsayin-contextlearning,includestraining distance for retrieval, and substitutes the encoders for codes
samples in prompts as the input for sequence-to-sequence withhybridGNNontheirCodePropertyGraphs(CPG)[222].
generative models. Retrieval techniques are adopted to find RACE [141] aims at generating commit message for code
similar training samples to the test input, so that the prompt difference.Itleveragesdenseretrievalforsimilarexamplesand
can be more informative and related. REDCODER [38] re- transformer model for generation. It also uses three encoders
trieves similar NL descriptions using dense retriever Code- for the input, the retrieved code difference, and corresponding
Bert [24], then concatenates the NL texts, their paired codes, commitmessage,thencombinestheresultsbeforefeedinginto
fordownstreamgeneratorPLBART[39].APICoder[129]first thedecoder.BASHEXPLAINER[139]sharesthesimilaridea.
train a Bert-based deep retriever to align the embeddings of Its dense retrieval module is based on CodeBert [24], and
NL descriptions and API documentation; then, it retrieves for generation, the output representations of the input and the
relevant API information to build prompt for the generator similarcodefromCodeBertaredirectlyfusedfortransformer-
CODEGEN-MONO [216]. COCOGEN [217] aims at com- based decoder.
monsense reasoning, which generates code-based reasoning- RAG for in-context learning, which retrieves similar ex-
graphs with Codex [2] given NL inputs; it adds an evaluation amples and build prompt for generation, also works in code
setting of dynamic prompt selection, which actually retrieves summary. REDCODER [38] works for both code generation
relevant examples for prompts. In DocPrompting [40] given and summary, and it replaces the retriever with GraphCode-
an NL intent, the retriver retrieves relevant documentations, Bert [104] for code summary task. ASAP [185] retrieves
then the generator generates codes based on the NL and similar code with BM25, and generates summary with GPT
retrieved documents. It evaluates both sparse retrievers and models.
dense retrievers, and also tries different generators in exper- 3) Code Completion: Code completion can be thought of
iments. CodeT5+ [218] adopts the CodeT5 [105] model for as the coding equivalent of the “next sentence prediction”
both the retriever and generator, leveraging only the encoder task. ReACC [132] follows the few-shot learning paradigm,
partintheretrievalprocess.AceCoder[177]fixestheretriever retrieving similar codes to build prompts for generation. For
to BM25 [18], and tests several LLM generators for code retrieval, it uses hybrid retriever, which combines sparse and
generation. denseretrieval;forgeneration,itusesCodeGPT-adapted[223].
Retrieval results can be applied during the generation pro- RepoCoder [197] steps further to perform iterative retrieval
cess as well. RECODE [118] retrieves similar NL descrip- and generation to bridge the gap between the retrieval context
tions using the edit distance, then extracts n-gram action and the intended completion target. In each iteration, for re-
subtrees from retrieved sentences’ corresponding target code trieval,thecodequeryisaugmentedwithpreviouslygenerated
abstract syntax trees (AST). During LSTM-based generation, code; for generation, the prompt is formed by combining
the patterns of processed subtrees are leveraged to increase the newest retrieved codes with the code query. Other than
the corresponding word probability at each decoding step. combining retrieval results in prompts, the retrieval-and-edit
kNN-TRANX [161] uses seq2tree model BertranX [219] to framework[140]firstretrievessimilartrainingexamplesusing
convertNLtocodeAST.Itconstructsadatastoreforeachcode dense retrieval, then encodes the input and the retrieved result
prefix and NL pair; i.e., for each NL-code pair, the context separately, finally combine them through attention for later
representation of the i-th context is obtained by encoding LSTMdecoder.CoCoMic[224]buildsaprojectcontextgraph
NL and the i-th prefix of code’s AST through the seq2tree for the whole code project, and retrieves top-k neighbors of
model. During generation, at each decoding step the hidden the input source code. It generates representations of both
representationsaresearchedwithinthedatastoretoformanew source code and retrieved contexts, then jointly processes the
probability,whichislatercombinedwiththeseq2treemodel’s embeddings to complete the code.
output using a confidence network. 4) Automatic Program Repair: Buggy code can take a lot
2) Code Summary: The goal of code summary is to ofefforttofix.Automaticprogramrepairleveragesgenerative
transformcodeintonaturallanguage(NL)descriptions,which modelstooutputthecorrectversion.RAGtechinqueiswidely
is a process of code-to-text. Same to code generation, many used for few-shot learning in automatic program repair [130],
sequence-to-sequence models are applied as generator. [131],[174],[189],[190].Amongthem,RING[190]retrieves
In many research works, the retrieval results are processed similarerrormessagesbasedonbothsparseanddensevectors,
by additional encoders. Rencos [119] utilizes two different thenbuildspromptforthegeneratorCodex[2].CEDAR[130]
methods to retrieve similar code snippets, syntactic similarity applies for both assertion generation and program repairs
between abstract syntax trees (AST) and cosine similarity be- tasks; it uses sparse and dense retrieval to search for similar
tweendenserepresentations.Forgenerator,itadoptsattention- codes, then forms prompt for Codex to generate results.15
InferFix [131] crafts a prompt carrying the bug type, location, 2) Audio Captioning: The goal of audio captioning is
relevantsyntaxhierarchies,andsimilarfixesthroughdensere- to generate natural language data with audio data, which is
trieval.ThenitalsousesCodexforgeneration.RAP-Gen[174] basicallyasequence-to-sequencetask.RECAP[229]leverages
also retrieves similar buggy codes and corresponding fixes CLAP [25] to retrieve related captions given audio data. The
through hybrid retriever (including both sparse and dense retrieved captions are then included into the prompt input for
retriever).ItfinetunesCodeT5[105]withthisRAGparadigm. GPT-2model,whichinteractswithaudioembeddingsthrough
SARGAM [189] searches similar buggy code using dense re- crossattention.In[41],denseretriverVGGish[106]isadopted
trieval, generates patches using augmented input, then applies to produce dense embedding of audio data, and GPT-2 is
anothermodeltomodifythefinalresult.Theseresearchworks adopted to generate representations of the retrieved captions
also involve error localization, which is not our focus. which are paired with similar audios. After obtaining the
5) Text-to-SQL and Code-based Semantic Parsing: Se- representations of audios and captions, an extra multi-head
mantic parsing is the task of translating natural language attention block and a linear layer fuses all the information
utterancestounambiguousstructuredmeaningrepresentations, and generates the output. Some research studies transform
where code language is often leveraged to augment this audio modality to text, in order to leverage advancements
process.SQLisnotonlyaprogramminglanguagebutcanalso in LLMs [230]–[232]. They take advantage of deep retrieval
be considered as a structured representation, so we place text- models, aligning the modalities into the same latent space for
to-SQL (a special case of code generation) in this subsection. downstream text generation.
Relatedresearchworksallapplyretrieval-augmentedfew-shot
learning. XRICL [178] focuses on the problem of translating
D. RAG for Image
non-English utterances into SQL queries. It searches and
reranks English utterance using non-English ones by dense 1) Image Generation: RAG enhances generative models
retrieval, then builds prompt for Codex to generate SQL by incorporating an information retrieval system. For image
queries.SYNCHROMESH[120]proposesconstrainedseman- generation [43], [137], [148]–[150], [150]–[152], [233], this
ticdecodingtoenforcerichsyntacticandsemanticconstraints means leveraging retrieved data to produce high-fidelity and
during generation of SQL or other languages. It uses the faithful images, even for rare or unseen entities. Meanwhile,
similarity between abstract syntax trees (AST) to finetune the this approach can also reduce the parameter count and com-
dense retriever S-Bert. During inference, similar NL and SQL putational cost of the generative model.
are retrived to form the prompt of GPT-3. CodeICL [225] RetrieveGAN [43] uses a differentiable retrieval process to
usesPythonforsemanticparsing,andaugmentspromptswith select compatible patches from other images as reference for
a structured domain description for GPT generation. In few- the generation. It adopts the Gumbel-softmax trick to make
shotlearningsetting,itleveragesBM25sparseretrievaltofind the retrieval process differentiable, enabling the end-to-end
similar training examples. training and the optimization of the embedding function. It
6) Others: There are several other code-related tasks that also encourages the selection of mutually compatible patches
adopt RAG paradigm. In [226] for numerical reasoning task, withadditionalobjectivefunctions.RetrieveGANcangenerate
the Chain-of-Thought is replaced with the programs as the realistic and diverse images from scene descriptions, where
intermediate reasoning step, and dense retrieval-based similar the retrieved patches are reasonable and coherent. IC-GAN
examples are augmented in prompt for downstream LLMs. [137] models the data distribution as a mixture of conditional
E&V [227] leverages an LLM-based agent for program static distributions around each training instance. It conditions both
analysis. The agent uses source code retrieval, pseudo-code the generator and the discriminator on instance features,
execution,executionspecificationsverification,andothertools which are obtained from a pre-trained feature extractor. It
to form intermediate results. The retrieval is implemented by also uses the nearest neighbors of the conditioning instance
ASTpatternmatching.StackSpotAI[228]buildsanAIcoding as real samples for the discriminator. IC-GAN can generate
assistant, which incorporates many code-related tasks. It im- realistic and diverse images for both labeled and unlabeled
plements an RAG component, identifying the most relevant datasets, and can transfer to unseen datasets by changing the
pieces of information which serve as the context for GPT conditioninginstances.IC-GANcanalsocontrolthesemantics
generation. andstyleofthegeneratedimagesbyswappingtheclasslabels
ortheinstancefeatures.However,usingtrainingdataitselffor
C. RAG for Audio retrieval potentially limits the generalization capacity.
1) Audio Generation: The goal of audio generation KNN-Diffusion [149] uses large-scale retrieval methods to
is to generate audio with natural language input. Re- train a diffusion-based model without any text data. The
AudioLDM [157] adopts dense retriever CLAP [25] to re- model is conditioned on two inputs: a text or image em-
trieve similar caption-audio pairs given input prompt. The bedding extracted by CLIP, and the k nearest neighbors
generator,latentdiffusionmodelandVAE-baseddecoder,take of the embedding from a large image database. The kNN
the representations of input text and retrieved pairs as input embeddingshelptobridgethegapbetweenthetextandimage
and generate output audio. Make-An-Audio [42] uses dense distributions, and to generate images from different domains
retriever CLAP [25] to augment data, retrieving related audio by simply swapping the database. The model also enables
givennaturallanguagetext.Itthenconstructspseudoprompts text-driven local semantic manipulations without masks, by
for diffusion-based text-to-audio model training. fine-tuning the model to predict the original image from a16
manipulated version. RDM [150] combines a small diffusion network to track coverage information and attention history,
or autoregressive model with a large external image database which helps in avoiding repetitive or incomplete descriptions.
into a semi-parametric model. During training, the model Acopyingmechanismisalsointegrated,allowingtheselection
retrieves a set of nearest neighbors from the database for each of words from retrieved captions to improve the fluency and
training image and conditions the generative model on their informativeness of the generated captions. RA-Transformer
CLIP embeddings. This way, the model learns to compose [44] adopts a kNN memory to retrieve relevant captions from
new scenes based on the retrieved visual content. During an external corpus and augment the generation process. It
inference, the model can generalize to novel domains, tasks, consists of a Transformer-decoder architecture with a kNN-
and conditions by changing the database or the retrieval strat- augmentedattentionlayerthatcombinesmaskedself-attention
egy. Re-imagen [148] retrieved information from an external over the input tokens and cross-attention over the retrieved
multi-modal knowledge base to produce realistic and faithful captions. A learned gate is used to balance the contribution
images, especially for rare or unseen entities. It is based on of the local context and the external memory. For retrieval, it
a cascaded diffusion model that conditions its generation on employsaCLIP-basedvisualencodertoperformapproximate
both the text prompt and the retrieved image-text pairs. It kNN searches in a visual-semantic space. RA-Transformer
also proposed an interleaved classifier-free guidance schedule achieves competitive performance on the COCO dataset and
to balance the alignment between the text and the retrieval demonstrates the effectiveness of retrieval abilities for image
conditions. Re-imagen achieves state-of-the-art performance captioning. EXTRA [236] enhances image captioning by in-
onCOCOandWikiImagesdatasets,andsignificantlyimproves corporating captions retrieved from similar images. It uses
the fidelity of generated images on a new benchmark called a pretrained Vision and Language (V&L) BERT encoder to
EntityDrawBench. X&Fuse [233] is a general approach for jointly process the image and the retrieved captions, creating
conditioning on visual information when generating images a rich cross-modal representation. The decoder then attends
from text. It works by concatenating the conditioned image to both visual and linguistic representations, benefiting from
and the noised image before each attention block in a U-Net the additional textual context. EXTRA shows that retrieving
architecture, and allowing interaction between them via self- a sufficient number of captions (e.g., k=5) indeed improves
attention. Retrieve&Fuse is a special case of X&Fuse, where captioning quality. REVEAL [237] is a retrieval-augmented
theconditionedimageisretrievedfromalargebankofimages visual language model that learns to encode and retrieve
using a text or image index. X&Fuse has several advantages world knowledge from a large-scale memory, using a unified
over alternative methods, such as robustness to spatial differ- encoder and a diverse set of multimodal sources. It consists
ences, no information loss. RPG [77] retrieves representative of four components: the memory, the encoder, the retriever,
images to construct informative in-context examples (i.e., and the generator. For image captioning, REVEAL takes an
image-region pairs), and utilizes multimodal chain-of-thought image as input, retrieves relevant knowledge entries from
reasoning [234] to plan out complementary subregions for the memory, and fuses them with the image features by
compositional text-to-image diffusion. introducinganattentivefusionlayerthatinjectsretrievalscore
2) Image Captioning: Retrieval-augmented Image Cap- into the attention calculation procedure. REVEAL is pre-
tioning is an innovative approach inspired by retrieval- trained on a massive image-text corpus with four knowledge
augmentedlanguagegeneration.Unliketraditionalimagecap- sources: Wikipedia passages and images, web images with
tioning methods that rely solely on the input image, this alt-text captions, knowledge graph triplets, and visual ques-
novel technique usually generates descriptive sentences by tion answering pairs. SMALLCAP [45] generates a caption
leveraging a set of captions retrieved from a datastore in conditioned on an input image and related captions retrieved
addition to the image itself. Memory-augmented (MA) [162] from a datastore of text via image-to-text retrieval. It uses a
exploits explicit knowledge from a memory bank to improve pre-trainedCLIPvisionencoderandGPT-2languagedecoder,
the caption generation. The memory bank is constructed by connected by trainable cross-attention layers. The retrieved
encoding the history context and the target word of each captions are used as a prompt to the decoder, providing a
image-text pair in the training data, i.e., image features and task demonstration tailored to the input image. SMALLCAP
past sentence (key) and target word (value). During inference, differsfrompreviousworkintwomainways,i.e.SMALLCAP
the model queries the memory bank with the current context employsastraightforwardprompt-basedconditioningmethod,
vectorandretrievesthemostsimilarentries.Then,itcomputes wherein retrieved captions are used as a prompt to a language
a distribution over the vocabulary based on the retrieved model.Moreover,SMALLCAPisthefirsttoleverageretrieval
entriesandinterpolatesitwiththeoriginalmodel’sprediction. augmentationfortraining-freedomaintransferandgeneraliza-
The main highlights of MA are that it is non-parametric, tion in image captioning task. The Cross-Modal Retrieval and
compatiblewithanycaptioningmodel,andcanadapttolarger Semantic Refinement (CRSR) method [238] enhances remote
datasets without additional training. RAMP [235] enhances sensingimagecaptioningbyintroducinganovelapproachthat
imageparagraphcaptioningbyincorporatingthebest-retrieved combines cross-modal retrieval with semantic refinement. It
candidate captions through adversarial training. It uses these starts by employing a cross-modal retrieval model to fetch
captions as reference during the training of the discriminator, relevant sentences for each image, using these sentences as
prompting the generator to include informative content from primary semantic information to support the captioning pro-
the retrieved captions into the generated caption. Addition- cess.Torefinethisinformation,asemanticrefinementmodule
ally, RAMP employs a dynamic memory-augmented attention filters out misleading details and emphasizes visually salient17
semanticcontent.Additionally,aTransformerMappernetwork the result from two branches. RetDream [48] targets general
is introduced to expand the representation of image features 3D generation, using retrieved 3D assets to augment the
with learnable queries, capturing more intricate details within process of variational score distillation from 2D diffusion
the images. The integration of refined semantic tokens and models. Given an input query, it retrieves relevant 3D assets
enriched visual features into a cross-modal decoder results in through CLIP, then utilizes the retrieved assets to provide
accurate and contextually rich captions. geometric prior and adapted 2D prior. Concretely, retrieved
assets not only impose an additional velocity on particles
E. RAG for Video for distribution initialization, but also help optimize the 2D
diffusion model through low-rank adaptation.
1) Video Captioning: Video captioning is to describe the
visualcontentwithadescriptiveutterance.R-ConvED[46]in-
troducesretrieval-augmentedmechanismtofacilitatetheword G. RAG for Knowledge
prediction.ItusesDualEncoding[108]forvideo-textretrieval,
Structured knowledge, including knowledge base and
and proposes a convolutional encoder-decoder network for
knowledge graph, is widely used in language tasks. It usually
generation. For a given input video, R-ConvED first retrieves
serves as the retrieval source to augment generation.
top-k relevant sentences and their corresponding video from
1) KnowledgeBaseQuestionAnswering: Knowledgebase
trainingset,thenfeedsthesepairsandtheinputvideointothe
question answering involves leveraging a knowledge base to
generator separately. The obtained decoder hidden states are
identify the correct answer to a question. Many semantic
combined through attention-like read operation, so that the
parsing methods are proposed, which generate logical forms
target word can be predicted using the final representation.
(e.g. SPARQL) given a question.
CARE [158] utilizes visual encoder, audio encoder, and text
ReTraCk [239] links entities using mention detection, and
encoder for frame, audio, and retrieved texts, respectively. It
retrieves schema items using dense retriever Bert. It then
uses CLIP as retriever, and transformer decoder as generator.
generates logical forms by LSTM, incorporating retrieved
The embeddings of the three modalities are combined to aug-
items through knowledge-specific rules. For a given query,
ment the decoder, producing global semantic guidance which
Unseen Entity Handling [51] retrieves topic entities through
attends the input embedding, and local semantic guidance
FreeBase [240], and concatenates the query with the entity
whichattendstheattentionlayer.EgoInstructor[47]generates
for an encoder-decoder to generate SPARQL output. CBR-
captions for first-person view videos. It retrieves relevant
KBQA [52] retrieves relevant questions and corresponding
exocentric videos and corresponding texts via dense retrieval,
logical form answers with roberta-based deep retrieval, then
then encodes the input egocentric video and the retrieved
concatenates the question and the retrieved pairs for encoder-
exocentric videos through a CLIP-based visual encoder and
decoder transformer model. It also revises the final generation
a transformer-decoder-based bottleneck module. Then it gen-
result to align the generated relations with relations present in
erates captions through decoder-based LLM which takes the
the local neighborhood of the query entity in the knowledge
retrieved texts as input and interacts with encoded videos in
graph.GMT-KBQA[50]firstretrievesrelevantentitiesandre-
gated cross-attention layer.
lationsthroughbert-baseddeepretrieval,thenconcatenatesthe
2) Video Generation: Text-to-video generation is to gen-
information for T5 generation. To improve the retrieval result,
erate video given natural language descriptions. Animate-A-
it leverages cross-encoder to rerank the candidates, and uses
Story [187] develops a framework which can generate high-
thesameT5structuretoconductrelationclassificationanden-
quality storytelling videos based on texts. It first separates the
tity dismbiguation. RNG-KBQA [121] enumerates candidate
text into individual plots, and decorates the description using
logical forms in the knowledge graph, then ranks the candi-
LLM. It then retrieves relevant videos for each plot through
dates and concatenates them with query to form the prompt
a dense retriever [109]. It generates videos through a latent
inputtogeneratefinallogicalformthroughaT5model.Based
diffusion model, consisting of two branches: a text encoder
on this idea, TIARA [122] also retrieve entity and schema
CLIP,andastructureencoderwhichtakestheestimateddepth
besides logical forms, while a following work [241] retrieves
of the retrieved videos as structure control.
top-kquestionswithBM25.Uni-Parser[133]retrievesrelevant
entitiesfromknowledgegraphusingmentiondetection,cross-
F. RAG for 3D
encoder ranker, and 2-hop paths extraction. It also considers
1) Text-to-3D: Retrieval can be applied to augment the enumeratingtablesandcolumnsfromdatabases.Onobtaining
generation of 3D contents. ReMoDiffuse [49] aims at gener- the relevant information, it concatenates the top-k primitives
atingmotionsusingdiffusionmodels.Itfirstretrievesrelevant withthequeryandgenerateslogicalformsthroughT5.UniK-
motion entites through CLIP given text input, then leverages QA [142] concatenates the text forms of the components in
the information of the text and the retrieved entities through a a triplet and build document pool for retrieval. For a given
semantic-modulated attention layer. AMD [156] designs two question, it leverages dense retriever for relevant documents,
branchesofmotiondiffusionforfidelityanddiversity.Thefirst then performs fusion-in-decoder technique to incorporate the
branchinputstheoriginalprompttextfordiffusion;thesecond informationforanswergeneration.SKP[144]performssimilar
branch decomposes the input text into anatomical scripts and operations as UniK-QA in inference, but adds a pretraining
retrievesimilarreferencemotionsfordiffusion.Atransformer- stage with a knowledge-aware MLM loss on triplets and
based fusion module is further applied to adaptively balance knowledgeconstrastivelosswithrespecttotheretrieveditems.18
BLLM augmentation [135] uses TIARA as the retrieval for innovativeinteraction-basedretrieval-augmented3Dmolecular
relevant knowledge base elements, then performs in-context diffusionmodeltofacilitatetarget-awaremoleculegeneration.
learningthroughblack-boxLLMsuchasGPT-4forgenerating PromptDiff retrieves a curated set of ligand references, i.e.,
logical forms. ECBRF [134] follows the case-based reasoning those with desired properties such as high binding affinity,
paradigm [242], retrieving similar triplet with dense retriever to steer the diffusion model towards synthesizing ligands
and constructing prompt input for BART or GPT-2 in-context that satisfy design criteria. DeepICL [147] constitutes an
learning. DECAF [143] forms Resource Description Format interaction-focused 3D molecular generative framework with
knowledge base triplets into sentences, then concatenates a specific emphasis on modeling protein-ligand interactions,
sentences with the same head entity into documents. It re- aimed at facilitating a generalizable pocket-constrained ligand
trievesrelevantdocumentsusingBM25sparseretrievalorBert design.UtilizingaVAEarchitecture[251],theencodermodule
denseretrieval,thenleveragesFusion-in-Decodertechniqueto processesprotein-ligandcomplexesintoalatentvector,which
generate logical form and direct answer given each (query, is combined with retrieved prior knowledge from interaction
document) pair as input. It combines the output to obtain the conditions. This combined information guides the sequential,
finalanswer.KD-CoT[145]usesthesamedenseretrieverand atom-wise generation of the ligand structure by the decoder
fusion-in-decoder generator as DECAF. It follows a Chain-of- module, ensuring that ligand atoms are appropriately placed
Thoughtparadigm,iterativelyperformingretrieval,generation, to facilitate the desired interaction with the target.
and verification until the CoT is finished. FC-KBQA [243] 2) Medical Applications: Several recent studies have im-
extracts relevant class, relation, and entity given a question. proved the expressiveness of LLM by retrieving information
For class and relation, it uses BM25 as retriever and a Bert- from biomedical domain-specific databases, thereby augment-
based cross-encoder as re-ranker. For entity, it follows the ing the model’s capabilities to provide valuable guidance for
mention detection paradigm. To compose all the component tasks in the medical field. GeneGPT [54] is a novel method
candidates,itappliesT5modeltogeneratelogicalexpression. in training a LLM to effectively employ the Web API offered
Keqing[244]firstdecomposesacomplextquestionintosimple bytheNationalCenterforBiotechnologyInformation(NCBI)
sub-questions through finetuned LLM, then retrieves similar for addressing genomics inquiries. It enhances the LLM by
sub-question template by dense retriever RoBERTa to extract integrating domain-specific tools, thereby refining its ability
candidateentitiesfromknowledgegraph,andfinallygenerates to access biomedical information through the retrieval of
answer through ChatGPT given relevant entities as context such data from the NCBI via API calls. When tasked with
input. To probe the deep understanding of natural language in GeneTuring tests, GeneGPT instructs Codex [2] to utilize
LLMs with formal languages, a research work [245] explores NCBI Web APIs through in-context learning and an aug-
the capability of formal language understanding and formal menteddecodingalgorithmproficientindetectingandexecut-
languagegeneration.Itleveragesretrievedpairstoperformin- ing API calls. Chat-Orthopedist [136] establishes an external
context learning. For understanding, it uses tree edit distance knowledge base with information on adolescent idiopathic
to retrieve similar logical forms, while for generation, it uses scoliosis (AIS) disease and treatment options, and develops a
BM25 to retrieve similar natural language queries. retrieval-augmentedChatGPTtofeedLLMswithAISdomain
2) Knowledge Graph Completion: Knowledge graph is knowledge, providing accurate and comprehensible responses
consisted of triplets, including head entity, relation, and tail to patient inquiries. Utilizing an external AIS knowledge base
entity. The task of knowledge graph completion is to predict and a dense retriever, Chat-Orthopedist enhances LLMs with
the missing entity in an incomplete triplet. domain-specific knowledge related to scoliosis, avoiding the
ReSKGC [146] linearizes all training triplets into text by issue of “molecular hallucinations”.
concatenation,thenretrievesrelevanttripletsusingBM25,and
generates completed triplet using T5 with fusion-in-decoder.
V. BENCHMARK
Chen et al. [252] proposed an RAG benchmark, which
evaluates RAG from four aspects: Noise Robustness, Neg-
H. RAG for Science
ative Rejection, Information Integration, and Counterfactual
RAG has also emerged as a promising research direction Robustness, respectively. Noise Robustness evaluates whether
for many interdisciplinary applications, such as strengthening LLMscouldextractthenecessaryinformationfromdocuments
molecular generation and guiding medical tasks. containing noisy information. The noisy information is rele-
1) Drug Discovery: The goal of drug discovery is to vant to the input query but useless for answering it. Negative
generate molecules that concurrently fulfill diverse properties. RejectionmeasureswhetherLLMswouldrejecttorespondthe
RetMol [53] incorporates a lightweight retrieval mechanism query when the retrieved content is not enough. Information
into a pre-trained encoder-decoder generative model. This Integration assesses whether LLMs could acquire knowledge
approach adopts the SMILES string [246] representation of andmakeresponsesbyintegratingmultipleretrievedcontents.
molecules along with the ChemFormer model [247] , in- Counterfactual Robustness refers to the ability of LLMs to
volving the retrieval and fusion of exemplar molecules with identify counterfactual errors in the retrieved content.
the input molecule. It also utilizes an iterative refinement Anotherthreebenchmarks,RAGAS[253],ARES[254]and
process to dynamically update both the generated molecules TruLens [255], considers three different aspects: Faithfulness,
and the retrieval database. Targeted at structure-based drug AnswerRelevance,andContextRelevance,respectively.Faith-
design (SBDD) [248], [249], PromptDiff [250] proposes an fulness focuses on the factual errors in the results when the19
correct answers can be inferred from the retrieved contents. these two components encounter challenges. As introduced
Answer Relevance measures whether the generated results in Section III, numerous approaches have been proposed to
actually address the problems (i.e., queries) or not. Context enableeffectiveRAG,andtheseapproacheseitherdisentangle
Relevance judges whether the retrieved contents contain as the retrieval and generation processes or integrate them at an
much knowledge as possible to answer the queries, and as intermediate stage. While the former is more modularized,
little irrelevant information as possible. the latter could potentially benefit from joint training. Till
CRUD-RAG [256] divides all RAG tasks into four cate- not, there lacks a sufficient comparison of different ways of
gories, which are Create, Read, Update, and Delete, respec- interaction across various scenarios.
tively,andalsoevaluateseachcategoryusingtextcontinuation, The tuning of RAG systems is also challenging. A recent
question answering (with single- and multi-document ques- study on the trade-off between attribution and fluency in
tions), hallucination modification, and open-domain multi- prompt-augmentation-styleRAGdemonstratesthatusingtop-k
document summary. retrieval for generation improves attribution, but hurts fluency
inturns[260].ThecountereffectsofdifferentaspectsinRAG,
VI. DISCUSSION such as metric selection and hyper-parameter tuning, remains
unexplored. Therefore, further refinement of RAG systems,
A. Limitations
both in terms of algorithms and deployment, is necessary to
Despite the widespread adoption of RAG in various ap- fully unlock their potentials.
plications, there are indeed some limitations in terms of 4) Long Context Generation: One of the primary chal-
effectiveness and efficiency. In this paper, we summarize the lengesinearlystageRAG,whichleveragespromptaugmenta-
limitations of RAG and deliver in-depth discussion. tion,istheinherentcontextlengthlimitationofthegenerators.
1) Noises in Retrieval Results: Information retrieval can- The research advancements in prompt compression [183] and
not yield perfect results because information loss appears in long-context support [261] have partially mitigated this chal-
representations generated by encoder models. Additionally, lenge,albeitwithaslighttrade-offinaccuracyorcosts.Given
ANN search can also provide approximate results rather than this challenge, a recent notion appears that “long-context
exact ones. Consequently, certain degree of noise is inevitable models like Gemini 1.5 will replace RAG”. Nevertheless, this
in retrieval results, manifesting as irrelevant objects or mis- assertiondoesnotholdtrue—RAGexhibitsgreaterflexibility
leading information, which may cause failure points in RAG in managing dynamic information, encompassing both up-to-
systems [257]. Though the common sense is that increasing date and long-tail knowledge [262]. We believe that RAG
the accuracy of retrieval will contribute to the effectiveness of in the future will take advantage of long context generation
RAG, a recent study surprisingly shows that noisy retrieval to achieve even better performance, rather than simply being
results may conversely help improve the generation qual- weeded out by it.
ity [258]. A possible explanation is that diversity in retrieval
results may also be necessary for prompt construction [259].
B. Potential Future Directions
As a result, the impact of noise in retrieval results remains
uncertain, leading to confusion regarding which metric to Last but not least, we wish to identify a series of possible
employ for retrieval and how to facilitate the interaction directions for the future research and applications of RAG.
between the retriever and the generator. Subsequent research 1) More Advanced Research on RAG Methodologies, En-
on this topic is anticipated to demystify the confusion. hancements, and Applications: A straight-forward research
2) Extra Overhead: While retrieval can help mitigate the direction is to develop more advanced methodologies, en-
costsofgenerationincertaincases[28]–[30],theincorporation hancements, and applications of RAG.
of retrieval sometimes introduces non-negligible overhead. As introduced in Section III-A, existing works have ex-
Considering that RAG is primarily employed to improve the plored various interaction patterns between retrievers and
performance of existing generative models, the inclusion of generators.However,sincetheoptimizationtargetofthesetwo
additionalretrievalandinteractionprocessesleadstoincreased components are distinct, the practical augmentation process
latency. Worse still, when combined with complex enhance- hasalargeimpactonthefinalgenerationresults.Investigation
ment methods, such as recursive retrieval [166] and iterative ofmoreadvancedfoundationsforaugmentationholdspromise
RAG [197], the extra overhead will become even more sig- for fully unleashing the potential of RAG.
nificant. Furthermore, as the scale of retrieval expands, the Based on a constructed RAG system, enhancements are
storage and access complexity associated with data sources helpful to improve the effectiveness of certain components
will also increase. In presence, RAG systems exhibit a trade- or the entire pipeline. Given the inherent complexity of the
off between costs and benefits. Looking ahead, we anticipate system, there exists significant potential for RAG to improve,
further optimization to alleviate the associated overhead. necessitating proper tuning and careful engineering. We look
3) Interaction of Retrieval and Generation: Achieving forward to further experimental analysis and in-depth explo-
seamlessintegrationbetweentheretrievalandgenerationcom- rationthatwillcontributetothedevelopmentofmoreeffective
ponents requires meticulous design and optimization. Given and more robust RAG systems.
that the objectives of the retriever and generator are not As introduced in Section IV, RAG is a general technique
aligned, and that the two models may not share the same that has been applied across diverse modalities and tasks. Yet
latentspace,designingandoptimizingtheinteractionbetween most of existing works straightforwardly integrate external20
knowledge with the specific generation tasks, without thor- S.McCandlish,A.Radford,I.Sutskever,andD.Amodei,“Language
oughlytakingintoaccountthekeycharacteristicsofthetarget models are few-shot learners,” in Advances in Neural Information
Processing Systems 33: Annual Conference on Neural Information
domains. Therefore, for generation tasks that do not fully
Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,
leverage the power of RAG, we are confident that designing virtual,H.Larochelle,M.Ranzato,R.Hadsell,M.Balcan,andH.Lin,
proper RAG system will be beneficial. Eds., 2020. [Online]. Available: https://proceedings.neurips.cc/paper/
2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html
2) Efficient Deployment and Processing: Currently, sev-
[2] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto,
eral deployment solutions of query-based RAG for LLMs J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray,
have been proposed, such as LangChain [263] and LLAMA- R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin,
B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser,
Index [169]. However, for other types of RAG and generation
M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings,
tasks, there lacks a plug-and-play solution. In addition, given M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss,
theextraoverheadintroducedbyretrieval,andconsideringthat A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji,
S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam,
the complexities of both the retriever and generator will con-
V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage,
tinue to grow, achieving efficient processing in RAG remains M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei,
a challenge, necessitating targeted system optimization. S. McCandlish, I. Sutskever, and W. Zaremba, “Evaluating large
languagemodelstrainedoncode,”CoRR,vol.abs/2107.03374,2021.
3) Incorporating Long-tail and Real-time Knowledge:
[Online].Available:https://arxiv.org/abs/2107.03374
While a key motivation of RAG is to harness real-time and [3] OpenAI,“GPT-4technicalreport,”CoRR,vol.abs/2303.08774,2023.
long-tail knowledge, the pipeline for knowledge updating and [Online].Available:https://doi.org/10.48550/arXiv.2303.08774
[4] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M. Lachaux,
expansion remains unexplored. Many existing works make up
T.Lacroix,B.Rozie`re,N.Goyal,E.Hambro,F.Azhar,A.Rodriguez,
the retrieval sources with merely the training data of genera- A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficient
tors, thereby neglecting the dynamic and flexible information foundation language models,” CoRR, vol. abs/2302.13971, 2023.
[Online].Available:https://doi.org/10.48550/arXiv.2302.13971
advantagesthatcouldhavebeenofferedbyretrieval.Asacon-
[5] H. Touvron,L. Martin, K.Stone, P.Albert, A. Almahairi,Y. Babaei,
sequence, designing a useful RAG system with continuously N.Bashlykov,S.Batra,P.Bhargava,S.Bhosale,D.Bikel,L.Blecher,
updated knowledge and/or flexible knowledge sources, along C. Canton-Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes,
J.Fu,W.Fu,B.Fuller,C.Gao,V.Goswami,N.Goyal,A.Hartshorn,
with corresponding system-level optimizations, is a growing
S. Hosseini, R. Hou, H. Inan, M. Kardas, V. Kerkez, M. Khabsa,
research direction. With the capability of utilizing long-tail I.Kloumann,A.Korenev,P.S.Koura,M.Lachaux,T.Lavril,J.Lee,
knowledge, we also expect RAG to leverage personalized D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra,
I.Molybog,Y.Nie,A.Poulton,J.Reizenstein,R.Rungta,K.Saladi,
informationandfeatures,soastoadapttotoday’swebservice.
A. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan,
4) Combined with Other Techniques: In essential, RAG B.Tang,R.Taylor,A.Williams,J.X.Kuan,P.Xu,Z.Yan,I.Zarov,
is orthogonal to other techniques that share the goal of Y.Zhang,A.Fan,M.Kambadur,S.Narang,A.Rodriguez,R.Stojnic,
S.Edunov,andT.Scialom,“Llama2:Openfoundationandfine-tuned
improving AIGC effectiveness, including fine tuning, rein-
chat models,” CoRR, vol. abs/2307.09288, 2023. [Online]. Available:
forcement learning, chain-of-thought, agent-based generation, https://doi.org/10.48550/arXiv.2307.09288
andotherpotentialoptimizations.However,theexplorationof [6] B. Rozie`re, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan,
Y. Adi, J. Liu, T. Remez, J. Rapin, A. Kozhevnikov, I. Evtimov,
simultaneously applying these techniques is still in its early
J. Bitton, M. Bhatt, C. Canton-Ferrer, A. Grattafiori, W. Xiong,
stages, calling for further research to delve into algorithm A. De´fossez, J. Copet, F. Azhar, H. Touvron, L. Martin, N. Usunier,
design and fully leverage their potential. T. Scialom, and G. Synnaeve, “Code llama: Open foundation models
for code,” CoRR, vol. abs/2308.12950, 2023. [Online]. Available:
https://doi.org/10.48550/arXiv.2308.12950
VII. CONCLUSION [7] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford,
M. Chen, and I. Sutskever, “Zero-shot text-to-image generation,”
In this paper, we conduct a thorough and comprehensive in Proceedings of the 38th International Conference on Machine
survey on RAG in the scenarios related to AIGC, with a Learning, ICML 2021, 18-24 July 2021, Virtual Event, ser.
Proceedings of Machine Learning Research, M. Meila and T. Zhang,
particular focus on augmentation foundations, enhancements,
Eds., vol. 139. PMLR, 2021, pp. 8821–8831. [Online]. Available:
and practical applications. We first systematically organize http://proceedings.mlr.press/v139/ramesh21a.html
and summarize the foundation paradigms in RAG, providing [8] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen,
“Hierarchical text-conditional image generation with CLIP latents,”
insights into the interaction between the retriever and the
CoRR, vol. abs/2204.06125, 2022. [Online]. Available: https:
generator. Based on constructed RAG systems, we review the //doi.org/10.48550/arXiv.2204.06125
enhancements that further improve the effectiveness of RAG, [9] J. Betker, G. Goh, L. Jing, T. Brooks, J. Wang, L. Li, L. Ouyang,
J. Zhuang, J. Lee, Y. Guo et al., “Improving image genera-
including the enhancements on input, retriever, generator, and
tion with better captions,” Computer Science. https://cdn. openai.
results. To facilitate researchers across diverse domains, we com/papers/dall-e-3.pdf,vol.2,no.3,p.8,2023.
showcase practical applications of RAG in a range of modal- [10] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer,
“High-resolution image synthesis with latent diffusion models,” in
ities and tasks. Finally, we also present existing benchmarks
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
for RAG, discuss current limitations of RAG, and shed light CVPR 2022, New Orleans, LA, USA, June 18-24, 2022. IEEE,
on promising future directions. 2022, pp. 10674–10685. [Online]. Available: https://doi.org/10.1109/
CVPR52688.2022.01042
[11] OpenAI,“Videogenerationmodelsasworldsimulators,”https://openai.
REFERENCES com/research/video-generation-models-as-world-simulators,2024.
[12] S.HochreiterandJ.Schmidhuber,“Longshort-termmemory,”Neural
[1] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, Comput., vol. 9, no. 8, pp. 1735–1780, 1997. [Online]. Available:
P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, https://doi.org/10.1162/neco.1997.9.8.1735
S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, [13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,
A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is
E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, all you need,” in Advances in Neural Information Processing21
Systems 30: Annual Conference on Neural Information Processing Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada,
Systems 2017, December 4-9, 2017, Long Beach, CA, USA, July9-14,2023,A.Rogers,J.L.Boyd-Graber,andN.Okazaki,Eds.
I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, Association for Computational Linguistics, 2023, pp. 9802–9822.
S. V. N. Vishwanathan, and R. Garnett, Eds., 2017, pp. 5998– [Online].Available:https://doi.org/10.18653/v1/2023.acl-long.546
6008. [Online]. Available: https://proceedings.neurips.cc/paper/2017/ [27] N. Carlini, F. Trame`r, E. Wallace, M. Jagielski, A. Herbert-Voss,
hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html K. Lee, A. Roberts, T. B. Brown, D. Song, U´. Erlingsson, A. Oprea,
[14] I.J.Goodfellow,J.Pouget-Abadie,M.Mirza,B.Xu,D.Warde-Farley, andC.Raffel,“Extractingtrainingdatafromlargelanguagemodels,”
S. Ozair, A. C. Courville, and Y. Bengio, “Generative adversarial in 30th USENIX Security Symposium, USENIX Security 2021,
networks,” Commun. ACM, vol. 63, no. 11, pp. 139–144, 2020. August11-13,2021,M.D.BaileyandR.Greenstadt,Eds. USENIX
[Online].Available:https://doi.org/10.1145/3422622 Association, 2021, pp. 2633–2650. [Online]. Available: https://www.
[15] J.Devlin,M.Chang,K.Lee,andK.Toutanova,“BERT:pre-training usenix.org/conference/usenixsecurity21/presentation/carlini-extracting
of deep bidirectional transformers for language understanding,” in [28] G. Izacard, P. S. H. Lewis, M. Lomeli, L. Hosseini, F. Petroni,
Proceedings of the 2019 Conference of the North American Chapter T. Schick, J. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave,
of the Association for Computational Linguistics: Human Language “Atlas:Few-shotlearningwithretrievalaugmentedlanguagemodels,”
Technologies,NAACL-HLT2019,Minneapolis,MN,USA,June2-7, J. Mach. Learn. Res., vol. 24, pp. 251:1–251:43, 2023. [Online].
2019, Volume 1 (Long and Short Papers), J. Burstein, C. Doran, and Available:http://jmlr.org/papers/v24/23-0037.html
T.Solorio,Eds. AssociationforComputationalLinguistics,2019,pp. [29] Y. Wu, M. N. Rabe, D. Hutchins, and C. Szegedy, “Memorizing
4171–4186.[Online].Available:https://doi.org/10.18653/v1/n19-1423 transformers,” in The Tenth International Conference on Learning
[16] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Representations, ICLR 2022, Virtual Event, April 25-29, 2022.
Y. Zhou, W. Li, and P. J. Liu, “Exploring the limits of OpenReview.net, 2022. [Online]. Available: https://openreview.net/
transfer learning with a unified text-to-text transformer,” J. Mach. forum?id=TrjbxzRcnf-
Learn. Res., vol. 21, pp. 140:1–140:67, 2020. [Online]. Available: [30] Z.He,Z.Zhong,T.Cai,J.D.Lee,andD.He,“REST:retrieval-based
http://jmlr.org/papers/v21/20-074.html speculative decoding,” CoRR, vol. abs/2311.08252, 2023. [Online].
[17] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, Available:https://doi.org/10.48550/arXiv.2311.08252
R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling
[31] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang,
lawsforneurallanguagemodels,”CoRR,vol.abs/2001.08361,2020.
“REALM: retrieval-augmented language model pre-training,”
[Online].Available:https://arxiv.org/abs/2001.08361
CoRR, vol. abs/2002.08909, 2020. [Online]. Available: https:
[18] S. E. Robertson and H. Zaragoza, “The probabilistic relevance
//arxiv.org/abs/2002.08909
framework: BM25 and beyond,” Found. Trends Inf. Retr., vol. 3,
[32] P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin,
no.4,pp.333–389,2009.[Online].Available:https://doi.org/10.1561/
N. Goyal, H. Ku¨ttler, M. Lewis, W. Yih, T. Rockta¨schel, S. Riedel,
1500000019
and D. Kiela, “Retrieval-augmented generation for knowledge-
[19] V. Karpukhin, B. Oguz, S. Min, P. S. H. Lewis, L. Wu, S. Edunov,
intensive NLP tasks,” in Advances in Neural Information Processing
D. Chen, and W. Yih, “Dense passage retrieval for open-domain
Systems 33: Annual Conference on Neural Information Processing
question answering,” in Proceedings of the 2020 Conference on
Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual,
Empirical Methods in Natural Language Processing, EMNLP 2020,
H.Larochelle,M.Ranzato,R.Hadsell,M.Balcan,andH.Lin,Eds.,
Online,November16-20,2020,B.Webber,T.Cohn,Y.He,andY.Liu,
2020. [Online]. Available: https://proceedings.neurips.cc/paper/2020/
Eds. AssociationforComputationalLinguistics,2020,pp.6769–6781.
hash/6b493230205f780e1bc26945df7481e5-Abstract.html
[Online].Available:https://doi.org/10.18653/v1/2020.emnlp-main.550
[33] G.IzacardandE.Grave,“Leveragingpassageretrievalwithgenerative
[20] J. Johnson, M. Douze, and H. Je´gou, “Billion-scale similarity search
models for open domain question answering,” in Proceedings of
with gpus,” IEEE Trans. Big Data, vol. 7, no. 3, pp. 535–547, 2021.
the 16th Conference of the European Chapter of the Association
[Online].Available:https://doi.org/10.1109/TBDATA.2019.2921572
for Computational Linguistics: Main Volume, EACL 2021, Online,
[21] Q. Chen, B. Zhao, H. Wang, M. Li, C. Liu, Z. Li,
April 19 - 23, 2021, P. Merlo, J. Tiedemann, and R. Tsarfaty,
M. Yang, and J. Wang, “SPANN: highly-efficient billion-scale
Eds. AssociationforComputationalLinguistics,2021,pp.874–880.
approximate nearest neighborhood search,” in Advances in Neural
[Online].Available:https://doi.org/10.18653/v1/2021.eacl-main.74
Information Processing Systems 34: Annual Conference on Neural
Information Processing Systems 2021, NeurIPS 2021, December [34] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford,
6-14, 2021, virtual, M. Ranzato, A. Beygelzimer, Y. N. Dauphin, K. Millican, G. van den Driessche, J. Lespiau, B. Damoc, A. Clark,
P. Liang, and J. W. Vaughan, Eds., 2021, pp. 5199–5212. D. de Las Casas, A. Guy, J. Menick, R. Ring, T. Hennigan,
[Online]. Available: https://proceedings.neurips.cc/paper/2021/hash/ S.Huang,L.Maggiore,C.Jones,A.Cassirer,A.Brock,M.Paganini,
299dc35e747eb77177d9cea10a802da2-Abstract.html G. Irving, O. Vinyals, S. Osindero, K. Simonyan, J. W. Rae,
[22] R. Datta, D. Joshi, J. Li, and J. Z. Wang, “Image retrieval: E. Elsen, and L. Sifre, “Improving language models by retrieving
Ideas, influences, and trends of the new age,” ACM Comput. from trillions of tokens,” in International Conference on Machine
Surv., vol. 40, no. 2, pp. 5:1–5:60, 2008. [Online]. Available: Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA,
https://doi.org/10.1145/1348246.1348248 ser. Proceedings of Machine Learning Research, K. Chaudhuri,
[23] A.Radford,J.W.Kim,C.Hallacy,A.Ramesh,G.Goh,S.Agarwal, S. Jegelka, L. Song, C. Szepesva´ri, G. Niu, and S. Sabato,
G.Sastry,A.Askell,P.Mishkin,J.Clarketal.,“Learningtransferable Eds., vol. 162. PMLR, 2022, pp. 2206–2240. [Online]. Available:
visual models from natural language supervision,” in International https://proceedings.mlr.press/v162/borgeaud22a.html
conferenceonmachinelearning. PMLR,2021,pp.8748–8763. [35] U. Khandelwal, O. Levy, D. Jurafsky, L. Zettlemoyer, and
[24] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, M. Lewis, “Generalization through memorization: Nearest neighbor
B. Qin, T. Liu, D. Jiang, and M. Zhou, “Codebert: A pre-trained language models,” in 8th International Conference on Learning
model for programming and natural languages,” in Findings of the Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,
Association for Computational Linguistics: EMNLP 2020, Online 2020. OpenReview.net,2020.[Online].Available:https://openreview.
Event, 16-20 November 2020, ser. Findings of ACL, T. Cohn, net/forum?id=HklBjCEKvH
Y. He, and Y. Liu, Eds., vol. EMNLP 2020. Association for [36] J.He,G.Neubig,andT.Berg-Kirkpatrick,“Efficientnearestneighbor
ComputationalLinguistics,2020,pp.1536–1547.[Online].Available: language models,” in Proceedings of the 2021 Conference on
https://doi.org/10.18653/v1/2020.findings-emnlp.139 Empirical Methods in Natural Language Processing, EMNLP 2021,
[25] Y. Wu, K. Chen, T. Zhang, Y. Hui, T. Berg-Kirkpatrick, and Virtual Event / Punta Cana, Dominican Republic, 7-11 November,
S. Dubnov, “Large-scale contrastive language-audio pretraining with 2021, M. Moens, X. Huang, L. Specia, and S. W. Yih, Eds.
feature fusion and keyword-to-caption augmentation,” in IEEE Association for Computational Linguistics, 2021, pp. 5703–5714.
InternationalConferenceonAcoustics,SpeechandSignalProcessing [Online].Available:https://doi.org/10.18653/v1/2021.emnlp-main.461
ICASSP2023,RhodesIsland,Greece,June4-10,2023. IEEE,2023, [37] zilliztech. (2023) Gptcache. [Online]. Available: https://github.com/
pp. 1–5. [Online]. Available: https://doi.org/10.1109/ICASSP49357. zilliztech/GPTCache
2023.10095969 [38] M.R.Parvez,W.U.Ahmad,S.Chakraborty,B.Ray,andK.Chang,
[26] A.Mallen,A.Asai,V.Zhong,R.Das,D.Khashabi,andH.Hajishirzi, “Retrievalaugmentedcodegenerationandsummarization,”inFindings
“When not to trust language models: Investigating effectiveness of the Association for Computational Linguistics: EMNLP 2021,
of parametric and non-parametric memories,” in Proceedings of Virtual Event / Punta Cana, Dominican Republic, 16-20 November,
the 61st Annual Meeting of the Association for Computational 2021,M.Moens,X.Huang,L.Specia,andS.W.Yih,Eds. Association22
for Computational Linguistics, 2021, pp. 2719–2734. [Online]. [52] R.Das,M.Zaheer,D.Thai,A.Godbole,E.Perez,J.Y.Lee,L.Tan,
Available:https://doi.org/10.18653/v1/2021.findings-emnlp.232 L.Polymenakos,andA.McCallum,“Case-basedreasoningfornatural
[39] W. U. Ahmad, S. Chakraborty, B. Ray, and K. Chang, “Unified pre- language queries over knowledge bases,” in Proceedings of the 2021
trainingforprogramunderstandingandgeneration,”inProceedingsof Conference on Empirical Methods in Natural Language Processing,
the2021ConferenceoftheNorthAmericanChapteroftheAssociation EMNLP2021,VirtualEvent/PuntaCana,DominicanRepublic,7-11
for Computational Linguistics: Human Language Technologies, November,2021,M.Moens,X.Huang,L.Specia,andS.W.Yih,Eds.
NAACL-HLT 2021, Online, June 6-11, 2021, K. Toutanova, Association for Computational Linguistics, 2021, pp. 9594–9611.
A.Rumshisky,L.Zettlemoyer,D.Hakkani-Tu¨r,I.Beltagy,S.Bethard, [Online].Available:https://doi.org/10.18653/v1/2021.emnlp-main.755
R. Cotterell, T. Chakraborty, and Y. Zhou, Eds. Association for [53] Z.Wang,W.Nie,Z.Qiao,C.Xiao,R.Baraniuk,andA.Anandkumar,
ComputationalLinguistics,2021,pp.2655–2668.[Online].Available: “Retrieval-based controllable molecule generation,” in The Eleventh
https://doi.org/10.18653/v1/2021.naacl-main.211 InternationalConferenceonLearningRepresentations,2022.
[40] S.Zhou,U.Alon,F.F.Xu,Z.Jiang,andG.Neubig,“Docprompting: [54] Q. Jin, Y. Yang, Q. Chen, and Z. Lu, “Genegpt: Augmenting large
Generatingcodebyretrievingthedocs,”inTheEleventhInternational languagemodelswithdomaintoolsforimprovedaccesstobiomedical
Conference on Learning Representations, ICLR 2023, Kigali, information,”ArXiv,2023.
Rwanda,May1-5,2023. OpenReview.net,2023.[Online].Available: [55] H. Li, Y. Su, D. Cai, Y. Wang, and L. Liu, “A survey on
https://openreview.net/pdf?id=ZTCxT2t2Ru retrieval-augmented text generation,” CoRR, vol. abs/2202.01110,
[41] Y. Koizumi, Y. Ohishi, D. Niizumi, D. Takeuchi, and M. Yasuda, 2022.[Online].Available:https://arxiv.org/abs/2202.01110
“Audiocaptioningusingpre-trainedlarge-scalelanguagemodelguided [56] A.Asai,S.Min,Z.Zhong,andD.Chen,“Acl2023tutorial:Retrieval-
byaudio-basedsimilarcaptionretrieval,”CoRR,vol.abs/2012.07331, basedlanguagemodelsandapplications,”ACL2023,2023.
2020.[Online].Available:https://arxiv.org/abs/2012.07331 [57] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun,
[42] R. Huang, J. Huang, D. Yang, Y. Ren, L. Liu, M. Li, Z. Ye, J. Liu, Q.Guo,M.Wang,andH.Wang,“Retrieval-augmentedgenerationfor
X. Yin, and Z. Zhao, “Make-an-audio: Text-to-audio generation with largelanguagemodels:Asurvey,”CoRR,vol.abs/2312.10997,2023.
prompt-enhanced diffusion models,” in International Conference on [Online].Available:https://doi.org/10.48550/arXiv.2312.10997
Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, [58] R. Zhao, H. Chen, W. Wang, F. Jiao, D. X. Long, C. Qin, B. Ding,
USA, ser. Proceedings of Machine Learning Research, A. Krause, X.Guo,M.Li,X.Li,andS.Joty,“Retrievingmultimodalinformation
E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, for augmented generation: A survey,” in Findings of the Association
Eds.,vol.202. PMLR,2023,pp.13916–13932.[Online].Available: for Computational Linguistics: EMNLP 2023, Singapore, December
https://proceedings.mlr.press/v202/huang23i.html 6-10,2023,H.Bouamor,J.Pino,andK.Bali,Eds. Associationfor
[43] H.-Y.Tseng,H.-Y.Lee,L.Jiang,M.-H.Yang,andW.Yang,“Retrieve- ComputationalLinguistics,2023,pp.4736–4756.[Online].Available:
gan: Image synthesis via differentiable patch retrieval,” in Computer https://aclanthology.org/2023.findings-emnlp.314
Vision–ECCV2020:16thEuropeanConference,Glasgow,UK,August [59] J. Chen, H. Guo, K. Yi, B. Li, and M. Elhoseiny, “Visualgpt:
23–28,2020,Proceedings,PartVIII16. Springer,2020,pp.242–257. Data-efficient adaptation of pretrained language models for image
[44] S. Sarto, M. Cornia, L. Baraldi, and R. Cucchiara, “Retrieval- captioning,” in IEEE/CVF Conference on Computer Vision and
augmented transformer for image captioning,” in Proceedings of the Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June
19thInternationalConferenceonContent-basedMultimediaIndexing, 18-24, 2022. IEEE, 2022, pp. 18009–18019. [Online]. Available:
2022,pp.1–7. https://doi.org/10.1109/CVPR52688.2022.01750
[45] R.Ramos,B.Martins,D.Elliott,andY.Kementchedjhieva,“Smallcap: [60] Y.Tay,M.Dehghani,D.Bahri,andD.Metzler,“Efficienttransformers:
lightweight image captioning prompted with retrieval augmentation,” A survey,” ACM Comput. Surv., vol. 55, no. 6, pp. 109:1–109:28,
inProceedingsoftheIEEE/CVFConferenceonComputerVisionand 2023.[Online].Available:https://doi.org/10.1145/3530811
PatternRecognition,2023,pp.2840–2849. [61] G. V. Houdt, C. Mosquera, and G. Na´poles, “A review on the
[46] J. Chen, Y. Pan, Y. Li, T. Yao, H. Chao, and T. Mei, long short-term memory model,” Artif. Intell. Rev., vol. 53, no. 8,
“Retrieval augmented convolutional encoder-decoder networks for pp. 5929–5955, 2020. [Online]. Available: https://doi.org/10.1007/
video captioning,” ACM Trans. Multim. Comput. Commun. Appl., s10462-020-09838-1
vol. 19, no. 1s, pp. 48:1–48:24, 2023. [Online]. Available: [62] L. Yang, Z. Zhang, Y. Song, S. Hong, R. Xu, Y. Zhao, W. Zhang,
https://doi.org/10.1145/3539225 B.Cui,andM.-H.Yang,“Diffusionmodels:Acomprehensivesurvey
[47] J. Xu, Y. Huang, J. Hou, G. Chen, Y. Zhang, R. Feng, ofmethodsandapplications,”ACMComputingSurveys,vol.56,no.4,
and W. Xie, “Retrieval-augmented egocentric video captioning,” pp.1–39,2023.
CoRR, vol. abs/2401.00789, 2024. [Online]. Available: https: [63] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli,
//doi.org/10.48550/arXiv.2401.00789 “Deep unsupervised learning using nonequilibrium thermodynamics,”
[48] J. Seo, S. Hong, W. Jang, I. H. Kim, M. Kwak, D. Lee, in International conference on machine learning. PMLR, 2015, pp.
and S. Kim, “Retrieval-augmented score distillation for text-to-3d 2256–2265.
generation,” CoRR, vol. abs/2402.02972, 2024. [Online]. Available: [64] J. Ho, A. Jain, and P. Abbeel, “Denoising diffusion probabilistic
https://doi.org/10.48550/arXiv.2402.02972 models,”Advancesinneuralinformationprocessingsystems,vol.33,
[49] M. Zhang, X. Guo, L. Pan, Z. Cai, F. Hong, H. Li, L. Yang, and pp.6840–6851,2020.
Z. Liu, “Remodiffuse: Retrieval-augmented motion diffusion model,” [65] A. Q. Nichol and P. Dhariwal, “Improved denoising diffusion prob-
in IEEE/CVF International Conference on Computer Vision, ICCV abilistic models,” in International Conference on Machine Learning.
2023, Paris, France, October 1-6, 2023. IEEE, 2023, pp. 364–373. PMLR,2021,pp.8162–8171.
[Online].Available:https://doi.org/10.1109/ICCV51070.2023.00040 [66] Y.SongandS.Ermon,“Generativemodelingbyestimatinggradients
[50] X. Hu, X. Wu, Y. Shu, and Y. Qu, “Logical form generation via of the data distribution,” Advances in neural information processing
multi-task learning for complex question answering over knowledge systems,vol.32,2019.
bases,” in Proceedings of the 29th International Conference on [67] Song, Yang and Ermon, Stefano, “Improved techniques for train-
Computational Linguistics, COLING 2022, Gyeongju, Republic of ing score-based generative models,” Advances in neural information
Korea, October 12-17, 2022, N. Calzolari, C. Huang, H. Kim, processingsystems,vol.33,pp.12438–12448,2020.
J. Pustejovsky, L. Wanner, K. Choi, P. Ryu, H. Chen, L. Donatelli, [68] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon,
H.Ji,S.Kurohashi,P.Paggio,N.Xue,S.Kim,Y.Hahm,Z.He,T.K. and B. Poole, “Score-based generative modeling through stochastic
Lee,E.Santus,F.Bond,andS.Na,Eds. InternationalCommitteeon differentialequations,”arXivpreprintarXiv:2011.13456,2020.
ComputationalLinguistics,2022,pp.1687–1696.[Online].Available: [69] Y. Song, C. Durkan, I. Murray, and S. Ermon, “Maximum likeli-
https://aclanthology.org/2022.coling-1.145 hood training of score-based diffusion models,” Advances in Neural
[51] X. Huang, J. Kim, and B. Zou, “Unseen entity handling in complex InformationProcessingSystems,vol.34,pp.1415–1428,2021.
questionansweringoverknowledgebasevialanguagegeneration,”in [70] L. Yang, H. Qian, Z. Zhang, J. Liu, and B. Cui, “Structure-
Findings of the Association for Computational Linguistics: EMNLP guided adversarial training of diffusion models,” arXiv preprint
2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 arXiv:2402.17563,2024.
November, 2021, M. Moens, X. Huang, L. Specia, and S. W. Yih, [71] X. Zhang, L. Yang, Y. Cai, Z. Yu, J. Xie, Y. Tian, M. Xu, Y. Tang,
Eds. AssociationforComputationalLinguistics,2021,pp.547–557. Y. Yang, and B. Cui, “Realcompo: Dynamic equilibrium between
[Online]. Available: https://doi.org/10.18653/v1/2021.findings-emnlp. realismandcompositionalityimprovestext-to-imagediffusionmodels,”
50 arXivpreprintarXiv:2402.12908,2024.23
[72] R.Rombach,A.Blattmann,D.Lorenz,P.Esser,andB.Ommer,“High- [96] J. Gui, Z. Sun, Y. Wen, D. Tao, and J. Ye, “A review on generative
resolutionimagesynthesiswithlatentdiffusionmodels,”2021. adversarial networks: Algorithms, theory, and applications,” IEEE
[73] A.Ramesh,P.Dhariwal,A.Nichol,C.Chu,andM.Chen,“Hierarchi- Trans. Knowl. Data Eng., vol. 35, no. 4, pp. 3313–3332, 2023.
caltext-conditionalimagegenerationwithcliplatents,”arXivpreprint [Online].Available:https://doi.org/10.1109/TKDE.2021.3130191
arXiv:2204.06125,vol.1,no.2,p.3,2022. [97] S. E. Robertson and S. Walker, “On relevance weights with little
[74] H.Li,Y.Yang,M.Chang,S.Chen,H.Feng,Z.Xu,Q.Li,andY.Chen, relevanceinformation,”inSIGIR’97:Proceedingsofthe20thAnnual
“Srdiff: Single image super-resolution with diffusion probabilistic International ACM SIGIR Conference on Research and Development
models,”Neurocomputing,vol.479,pp.47–59,2022. in Information Retrieval, July 27-31, 1997, Philadelphia, PA, USA,
[75] J.Ho,C.Saharia,W.Chan,D.J.Fleet,M.Norouzi,andT.Salimans, N.J.Belkin,A.D.Narasimhalu,P.Willett,W.R.Hersh,F.Can,and
“Cascaded diffusion models for high fidelity image generation,” The E. M. Voorhees, Eds. ACM, 1997, pp. 16–24. [Online]. Available:
JournalofMachineLearningResearch,vol.23,no.1,pp.2249–2281, https://doi.org/10.1145/258525.258529
2022. [98] J. D. Lafferty and C. Zhai, “Document language models, query
[76] L.Yang,J.Liu,S.Hong,Z.Zhang,Z.Huang,Z.Cai,W.Zhang,and models, and risk minimization for information retrieval,” in SIGIR
B.Cui,“Improvingdiffusion-basedimagesynthesiswithcontextpre- 2001: Proceedings of the 24th Annual International ACM SIGIR
diction,”AdvancesinNeuralInformationProcessingSystems,vol.36, Conference on Research and Development in Information Retrieval,
2024. September 9-13, 2001, New Orleans, Louisiana, USA, W. B. Croft,
[77] L.Yang,Z.Yu,C.Meng,M.Xu,S.Ermon,andB.Cui,“Mastering D. J. Harper, D. H. Kraft, and J. Zobel, Eds. ACM, 2001, pp.
text-to-image diffusion: Recaptioning, planning, and generating with 111–119.[Online].Available:https://doi.org/10.1145/383952.383970
multimodalllms,”arXivpreprintarXiv:2401.11708,2024. [99] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy,
[78] S. Gong, M. Li, J. Feng, Z. Wu, and L. Kong, “Diffuseq: Sequence M. Lewis, L. Zettlemoyer, and V. Stoyanov, “Roberta: A robustly
to sequence text generation with diffusion models,” arXiv preprint optimized BERT pretraining approach,” CoRR, vol. abs/1907.11692,
arXiv:2210.08933,2022. 2019.[Online].Available:http://arxiv.org/abs/1907.11692
[79] X. Li, J. Thickstun, I. Gulrajani, P. S. Liang, and T. B. Hashimoto, [100] L. Xiong, C. Xiong, Y. Li, K. Tang, J. Liu, P. N. Bennett,
“Diffusion-lm improves controllable text generation,” Advances in J. Ahmed, and A. Overwijk, “Approximate nearest neighbor negative
NeuralInformationProcessingSystems,vol.35,pp.4328–4343,2022. contrastive learning for dense text retrieval,” in 9th International
[80] J. Austin, D. D. Johnson, J. Ho, D. Tarlow, and R. Van Den Berg, Conference on Learning Representations, ICLR 2021, Virtual Event,
“Structured denoising diffusion models in discrete state-spaces,” Austria,May3-7,2021. OpenReview.net,2021.[Online].Available:
Advances in Neural Information Processing Systems, vol. 34, pp. https://openreview.net/forum?id=zeFrfgyZln
17981–17993,2021. [101] H. Zhang, Y. Gong, Y. Shen, J. Lv, N. Duan, and W. Chen,
[81] T. Chen, R. Zhang, and G. Hinton, “Analog bits: Generating discrete “Adversarial retriever-ranker for dense text retrieval,” in The Tenth
data using diffusion models with self-conditioning,” arXiv preprint International Conference on Learning Representations, ICLR 2022,
arXiv:2208.04202,2022. Virtual Event, April 25-29, 2022. OpenReview.net, 2022. [Online].
[82] J. Ho, W. Chan, C. Saharia, J. Whang, R. Gao, A. Gritsenko, D. P. Available:https://openreview.net/forum?id=MR7XubKUFB
Kingma, B. Poole, M. Norouzi, D. J. Fleet et al., “Imagen video: [102] Y. Qu, Y. Ding, J. Liu, K. Liu, R. Ren, W. X. Zhao, D. Dong,
Highdefinitionvideogenerationwithdiffusionmodels,”arXivpreprint H. Wu, and H. Wang, “Rocketqa: An optimized training approach
arXiv:2210.02303,2022. to dense passage retrieval for open-domain question answering,”
[83] W. Harvey, S. Naderiparizi, V. Masrani, C. Weilbach, and F. Wood, in Proceedings of the 2021 Conference of the North American
“Flexible diffusion modeling of long videos,” Advances in Neural Chapter of the Association for Computational Linguistics: Human
InformationProcessingSystems,vol.35,pp.27953–27965,2022. Language Technologies, NAACL-HLT 2021, Online, June 6-11,
[84] R.Yang,P.Srivastava,andS.Mandt,“Diffusionprobabilisticmodeling 2021, K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tu¨r,
forvideogeneration,”Entropy,vol.25,no.10,p.1469,2023. I.Beltagy,S.Bethard,R.Cotterell,T.Chakraborty,andY.Zhou,Eds.
[85] M. Zhang, Z. Cai, L. Pan, F. Hong, X. Guo, L. Yang, and Z. Liu, Association for Computational Linguistics, 2021, pp. 5835–5847.
“Motiondiffuse: Text-driven human motion generation with diffu- [Online].Available:https://doi.org/10.18653/v1/2021.naacl-main.466
sion model,” IEEE Transactions on Pattern Analysis and Machine [103] L. Gao and J. Callan, “Condenser: a pre-training architecture for
Intelligence,2024. denseretrieval,”inProceedingsofthe2021ConferenceonEmpirical
[86] L. Yang, Z. Zhang, Z. Yu, J. Liu, M. Xu, S. Ermon, and B. CUI, Methods in Natural Language Processing, EMNLP 2021, Virtual
“Cross-modal contextualized diffusion models for text-guided visual Event / Punta Cana, Dominican Republic, 7-11 November, 2021,
generation and editing,” in International Conference on Learning M.Moens,X.Huang,L.Specia,andS.W.Yih,Eds. Associationfor
Representations,2024. Computational Linguistics, 2021, pp. 981–993. [Online]. Available:
[87] N. Anand and T. Achim, “Protein structure and sequence genera- https://doi.org/10.18653/v1/2021.emnlp-main.75
tion with equivariant denoising diffusion probabilistic models,” arXiv [104] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, S. Liu, L. Zhou,
preprintarXiv:2205.15019,2022. N. Duan, A. Svyatkovskiy, S. Fu, M. Tufano, S. K. Deng, C. B.
[88] M. Xu, L. Yu, Y. Song, C. Shi, S. Ermon, and J. Tang, “Geodiff: Clement, D. Drain, N. Sundaresan, J. Yin, D. Jiang, and M. Zhou,
Ageometricdiffusionmodelformolecularconformationgeneration,” “Graphcodebert: Pre-training code representations with data flow,”
arXivpreprintarXiv:2203.02923,2022. in 9th International Conference on Learning Representations, ICLR
[89] E.Hoogeboom,V.G.Satorras,C.Vignac,andM.Welling,“Equivari- 2021,VirtualEvent,Austria,May3-7,2021. OpenReview.net,2021.
antdiffusionformoleculegenerationin3d,”inInternationalconference [Online].Available:https://openreview.net/forum?id=jLoC4ez43PZ
onmachinelearning. PMLR,2022,pp.8867–8887. [105] Y. Wang, W. Wang, S. R. Joty, and S. C. H. Hoi, “Codet5:
[90] B.Jing,G.Corso,J.Chang,R.Barzilay,andT.Jaakkola,“Torsional Identifier-aware unified pre-trained encoder-decoder models for code
diffusion for molecular conformer generation,” Advances in Neural understandingandgeneration,”inProceedingsofthe2021Conference
InformationProcessingSystems,vol.35,pp.24240–24253,2022. onEmpiricalMethodsinNaturalLanguageProcessing,EMNLP2021,
[91] Z.Huang,L.Yang,X.Zhou,Z.Zhang,W.Zhang,X.Zheng,J.Chen, Virtual Event / Punta Cana, Dominican Republic, 7-11 November,
Y. Wang, B. CUI, and W. Yang, “Protein-ligand interaction prior 2021, M. Moens, X. Huang, L. Specia, and S. W. Yih, Eds.
for binding-aware 3d molecule diffusion models,” in International Association for Computational Linguistics, 2021, pp. 8696–8708.
ConferenceonLearningRepresentations,2024. [Online].Available:https://doi.org/10.18653/v1/2021.emnlp-main.685
[92] J.Song,C.Meng,andS.Ermon,“Denoisingdiffusionimplicitmod- [106] S. Hershey, S. Chaudhuri, D. P. W. Ellis, J. F. Gemmeke, A. Jansen,
els,”arXivpreprintarXiv:2010.02502,2020. R. C. Moore, M. Plakal, D. Platt, R. A. Saurous, B. Seybold,
[93] X. Liu, C. Gong, and Q. Liu, “Flow straight and fast: Learning M. Slaney, R. J. Weiss, and K. W. Wilson, “CNN architectures for
to generate and transfer data with rectified flow,” arXiv preprint large-scaleaudioclassification,”in2017IEEEInternationalConference
arXiv:2209.03003,2022. on Acoustics, Speech and Signal Processing, ICASSP 2017, New
[94] Y.Song,P.Dhariwal,M.Chen,andI.Sutskever,“Consistencymodels,” Orleans, LA, USA, March 5-9, 2017. IEEE, 2017, pp. 131–135.
arXivpreprintarXiv:2303.01469,2023. [Online].Available:https://doi.org/10.1109/ICASSP.2017.7952132
[95] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, [107] X.Yuan,Z.Lin,J.Kuen,J.Zhang,Y.Wang,M.Maire,A.Kale,and
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial net- B. Faieta, “Multimodal contrastive training for visual representation
works,” Communications of the ACM, vol. 63, no. 11, pp. 139–144, learning,” in Proceedings of the IEEE/CVF Conference on Computer
2020. VisionandPatternRecognition,2021,pp.6995–7004.24
[108] J. Dong, X. Li, C. Xu, S. Ji, Y. He, G. Yang, and X. Wang, “Dual ComputationalLinguistics(Volume1:LongPapers),2017,pp.1237–
encoding for zero-example video retrieval,” in IEEE Conference 1247.
on Computer Vision and Pattern Recognition, CVPR 2019, Long [124] X. V. Lin, R. Socher, and C. Xiong, “Bridging textual and tabular
Beach,CA,USA,June16-20,2019. ComputerVisionFoundation/ data for cross-domain text-to-sql semantic parsing,” arXiv preprint
IEEE, 2019, pp. 9346–9355. [Online]. Available: http://openaccess. arXiv:2012.12627,2020.
thecvf.com/content CVPR 2019/html/Dong Dual Encoding for [125] F. Petroni, A. Piktus, A. Fan, P. Lewis, M. Yazdani, N. De Cao,
Zero-Example Video Retrieval CVPR 2019 paper.html J. Thorne, Y. Jernite, V. Karpukhin, J. Maillard et al., “Kilt: a
[109] M. Bain, A. Nagrani, G. Varol, and A. Zisserman, “Frozen benchmarkforknowledgeintensivelanguagetasks,”inProceedingsof
in time: A joint video and image encoder for end-to-end the2021ConferenceoftheNorthAmericanChapteroftheAssociation
retrieval,” in 2021 IEEE/CVF International Conference on Computer forComputationalLinguistics:HumanLanguageTechnologies,2021,
Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, pp.2523–2544.
2021. IEEE, 2021, pp. 1708–1718. [Online]. Available: https: [126] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, “Self-
//doi.org/10.1109/ICCV48922.2021.00175 rag: Learning to retrieve, generate, and critique through self-
[110] J. Zhan, J. Mao, Y. Liu, J. Guo, M. Zhang, and S. Ma, “Optimizing reflection,” CoRR, vol. abs/2310.11511, 2023. [Online]. Available:
dense retrieval model training with hard negatives,” in Proceedings https://doi.org/10.48550/arXiv.2310.11511
of the 44th International ACM SIGIR Conference on Research and [127] W.Shi,S.Min,M.Yasunaga,M.Seo,R.James,M.Lewis,L.Zettle-
DevelopmentinInformationRetrieval,2021,pp.1503–1512. moyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box lan-
[111] J. L. Bentley, “Multidimensional binary search trees used for asso- guagemodels,”arXivpreprintarXiv:2301.12652,2023.
ciative searching,” Communications of the ACM, vol. 18, no. 9, pp. [128] O.Ram,Y.Levine,I.Dalmedigos,D.Muhlgay,A.Shashua,K.Leyton-
509–517,1975. Brown, and Y. Shoham, “In-context retrieval-augmented language
[112] W.Li,C.Feng,D.Lian,Y.Xie,H.Liu,Y.Ge,andE.Chen,“Learning models,”arXivpreprintarXiv:2302.00083,2023.
balanced tree indexes for large-scale vector retrieval,” in Proceedings [129] D. Zan, B. Chen, Z. Lin, B. Guan, Y. Wang, and J. Lou, “When
ofthe29thACMSIGKDDConferenceonKnowledgeDiscoveryand languagemodelmeetsprivatelibrary,”inFindingsoftheAssociation
DataMining,2023,pp.1353–1362. for Computational Linguistics: EMNLP 2022, Abu Dhabi, United
[113] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni, “Locality- ArabEmirates,December7-11,2022,Y.Goldberg,Z.Kozareva,and
sensitive hashing scheme based on p-stable distributions,” in Y. Zhang, Eds. Association for Computational Linguistics, 2022,
Proceedings of the twentieth annual symposium on Computational pp. 277–288. [Online]. Available: https://doi.org/10.18653/v1/2022.
geometry,2004,pp.253–262. findings-emnlp.21
[130] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt
[114] Y. A. Malkov and D. A. Yashunin, “Efficient and robust approx-
selection for code-related few-shot learning,” in 45th IEEE/ACM
imate nearest neighbor search using hierarchical navigable small
International Conference on Software Engineering, ICSE 2023,
world graphs,” IEEE transactions on pattern analysis and machine
Melbourne,Australia,May14-20,2023. IEEE,2023,pp.2450–2462.
intelligence,vol.42,no.4,pp.824–836,2018.
[Online].Available:https://doi.org/10.1109/ICSE48619.2023.00205
[115] S.JayaramSubramanya,F.Devvrit,H.V.Simhadri,R.Krishnawamy,
[131] M. Jin, S. Shahriar, M. Tufano, X. Shi, S. Lu, N. Sundaresan,
andR.Kadekodi,“Diskann:Fastaccuratebillion-pointnearestneigh-
and A. Svyatkovskiy, “Inferfix: End-to-end program repair with
bor search on a single node,” Advances in Neural Information
llms,” in Proceedings of the 31st ACM Joint European Software
ProcessingSystems,vol.32,2019.
Engineering Conference and Symposium on the Foundations of
[116] J. Ren, M. Zhang, and D. Li, “Hm-ann: Efficient billion-point near-
Software Engineering, ESEC/FSE 2023, San Francisco, CA, USA,
est neighbor search on heterogeneous memory,” Advances in Neural
December 3-9, 2023, S. Chandra, K. Blincoe, and P. Tonella,
InformationProcessingSystems,vol.33,pp.10672–10684,2020.
Eds. ACM, 2023, pp. 1646–1656. [Online]. Available: https:
[117] Q. Chen, B. Zhao, H. Wang, M. Li, C. Liu, Z. Li, M. Yang, and
//doi.org/10.1145/3611643.3613892
J. Wang, “Spann: Highly-efficient billion-scale approximate nearest
[132] S. Lu, N. Duan, H. Han, D. Guo, S. Hwang, and A. Svyatkovskiy,
neighborhood search,” Advances in Neural Information Processing
“Reacc: A retrieval-augmented code completion framework,” in
Systems,vol.34,pp.5199–5212,2021.
Proceedings of the 60th Annual Meeting of the Association for
[118] S.A.Hayati,R.Olivier,P.Avvaru,P.Yin,A.Tomasic,andG.Neubig, Computational Linguistics (Volume 1: Long Papers), ACL 2022,
“Retrieval-based neural code generation,” in Proceedings of the 2018 Dublin, Ireland, May 22-27, 2022, S. Muresan, P. Nakov, and
Conference on Empirical Methods in Natural Language Processing, A. Villavicencio, Eds. Association for Computational Linguistics,
Brussels, Belgium, October 31 - November 4, 2018, E. Riloff, 2022,pp.6227–6240.[Online].Available:https://doi.org/10.18653/v1/
D. Chiang, J. Hockenmaier, and J. Tsujii, Eds. Association for 2022.acl-long.431
Computational Linguistics, 2018, pp. 925–930. [Online]. Available: [133] Y. Liu, S. Yavuz, R. Meng, D. Radev, C. Xiong, and Y. Zhou,
https://doi.org/10.18653/v1/d18-1111 “Uni-parser: Unified semantic parser for question answering on
[119] J. Zhang, X. Wang, H. Zhang, H. Sun, and X. Liu, “Retrieval-based knowledgebaseanddatabase,”inProceedingsofthe2022Conference
neural source code summarization,” in ICSE ’20: 42nd International on Empirical Methods in Natural Language Processing, EMNLP
Conference on Software Engineering, Seoul, South Korea, 27 June - 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022,
19July,2020,G.RothermelandD.Bae,Eds. ACM,2020,pp.1385– Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds. Association for
1397.[Online].Available:https://doi.org/10.1145/3377811.3380383 ComputationalLinguistics,2022,pp.8858–8869.[Online].Available:
[120] G. Poesia, A. Polozov, V. Le, A. Tiwari, G. Soares, C. Meek, https://doi.org/10.18653/v1/2022.emnlp-main.605
and S. Gulwani, “Synchromesh: Reliable code generation from [134] Z. Yang, X. Du, E. Cambria, and C. Cardie, “End-to-end case-
pre-trained language models,” in The Tenth International Conference based reasoning for commonsense knowledge base completion,” in
on Learning Representations, ICLR 2022, Virtual Event, April Proceedings of the 17th Conference of the European Chapter of the
25-29, 2022. OpenReview.net, 2022. [Online]. Available: https: Association for Computational Linguistics, EACL 2023, Dubrovnik,
//openreview.net/forum?id=KmtVD97J43e Croatia, May 2-6, 2023, A. Vlachos and I. Augenstein, Eds.
[121] X. Ye, S. Yavuz, K. Hashimoto, Y. Zhou, and C. Xiong, Association for Computational Linguistics, 2023, pp. 3491–3504.
“RNG-KBQA: generation augmented iterative ranking for knowledge [Online].Available:https://doi.org/10.18653/v1/2023.eacl-main.255
base question answering,” in Proceedings of the 60th Annual [135] M. Patidar, A. K. Singh, R. Sawhney, I. Bhattacharya, and
Meeting of the Association for Computational Linguistics (Volume Mausam,“Combiningtransferlearningwithin-contextlearningusing
1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, blackbox llms for zero-shot knowledge base question answering,”
S. Muresan, P. Nakov, and A. Villavicencio, Eds. Association for CoRR, vol. abs/2311.08894, 2023. [Online]. Available: https:
ComputationalLinguistics,2022,pp.6032–6043.[Online].Available: //doi.org/10.48550/arXiv.2311.08894
https://doi.org/10.18653/v1/2022.acl-long.417 [136] W. Shi, Y. Zhuang, Y. Zhu, H. Iwinski, M. Wattenbarger, and M. D.
[122] Y. Shu, Z. Yu, Y. Li, B. F. Karlsson, T. Ma, Y. Qu, and C. Lin, Wang, “Retrieval-augmented large language models for adolescent
“TIARA: multi-grained retrieval for robust question answering over idiopathicscoliosispatientsinshareddecision-making,”inProceedings
large knowledge bases,” CoRR, vol. abs/2210.12925, 2022. [Online]. of the 14th ACM International Conference on Bioinformatics,
Available:https://doi.org/10.48550/arXiv.2210.12925 ComputationalBiology,andHealthInformatics,2023,pp.1–10.
[123] M. Xu, H. Jiang, and S. Watcharawittayakul, “A local detection [137] A.Casanova,M.Careil,J.Verbeek,M.Drozdzal,andA.RomeroSo-
approach for named entity recognition and mention detection,” in riano, “Instance-conditioned gan,” Advances in Neural Information
Proceedings of the 55th Annual Meeting of the Association for ProcessingSystems,vol.34,pp.27517–27529,2021.25
[138] J. Li, Y. Li, G. Li, X. Hu, X. Xia, and Z. Jin, “Editsum: of artistic images with retrieval-augmented diffusion models,” arXiv
A retrieve-and-edit framework for source code summarization,” in preprintarXiv:2207.13038,2022.
36th IEEE/ACM International Conference on Automated Software [152] B. Li, P. H. Torr, and T. Lukasiewicz, “Memory-driven text-to-image
Engineering, ASE 2021, Melbourne, Australia, November 15-19, generation,”arXivpreprintarXiv:2208.07022,2022.
2021. IEEE, 2021, pp. 155–166. [Online]. Available: https: [153] M.deJong,Y.Zemlyanskiy,N.FitzGerald,F.Sha,andW.W.Cohen,
//doi.org/10.1109/ASE51524.2021.9678724 “Mentionmemory:incorporatingtextualknowledgeintotransformers
[139] C. Yu, G. Yang, X. Chen, K. Liu, and Y. Zhou, “Bashexplainer: through entity mention attention,” in International Conference on
Retrieval-augmented bash code comment generation based on fine- LearningRepresentations,2021.
tuned codebert,” in IEEE International Conference on Software [154] A.Bertsch,U.Alon,G.Neubig,andM.R.Gormley,“Unlimiformer:
Maintenance and Evolution, ICSME 2022, Limassol, Cyprus, Long-range transformers with unlimited length input,” CoRR, vol.
October 3-7, 2022. IEEE, 2022, pp. 82–93. [Online]. Available: abs/2305.01625, 2023. [Online]. Available: https://doi.org/10.48550/
https://doi.org/10.1109/ICSME55016.2022.00016 arXiv.2305.01625
[140] T.B.Hashimoto,K.Guu,Y.Oren,andP.Liang,“Aretrieve-and-edit [155] T. Fe´vry, L. B. Soares, N. Fitzgerald, E. Choi, and T. Kwiatkowski,
framework for predicting structured outputs,” in Advances in Neural “Entitiesasexperts:Sparsememoryaccesswithentitysupervision,”in
Information Processing Systems 31: Annual Conference on Neural Proceedingsofthe2020ConferenceonEmpiricalMethodsinNatural
InformationProcessingSystems2018,NeurIPS2018,December3-8, LanguageProcessing(EMNLP),2020,pp.4937–4951.
2018, Montre´al, Canada, S. Bengio, H. M. Wallach, H. Larochelle, [156] B. Jing, Y. Zhang, Z. Song, J. Yu, and W. Yang, “Amd: Anatomical
K.Grauman,N.Cesa-Bianchi,andR.Garnett,Eds.,2018,pp.10073– motiondiffusionwithinterpretablemotiondecompositionandfusion,”
10083.[Online].Available:https://proceedings.neurips.cc/paper/2018/ arXivpreprintarXiv:2312.12763,2023.
hash/cd17d3ce3b64f227987cd92cd701cc58-Abstract.html [157] Y. Yuan, H. Liu, X. Liu, Q. Huang, M. D. Plumbley, and
[141] E. Shi, Y. Wang, W. Tao, L. Du, H. Zhang, S. Han, D. Zhang, and W.Wang,“Retrieval-augmentedtext-to-audiogeneration,”CoRR,vol.
H. Sun, “RACE: retrieval-augmented commit message generation,” abs/2309.08051, 2023. [Online]. Available: https://doi.org/10.48550/
in Proceedings of the 2022 Conference on Empirical Methods in arXiv.2309.08051
Natural Language Processing, EMNLP 2022, Abu Dhabi, United [158] B. Yang, M. Cao, and Y. Zou, “Concept-aware video captioning:
ArabEmirates,December7-11,2022,Y.Goldberg,Z.Kozareva,and Describing videos with effective prior information,” IEEE Trans.
Y. Zhang, Eds. Association for Computational Linguistics, 2022, Image Process., vol. 32, pp. 5366–5378, 2023. [Online]. Available:
pp. 5520–5530. [Online]. Available: https://doi.org/10.18653/v1/2022. https://doi.org/10.1109/TIP.2023.3307969
emnlp-main.372 [159] Z. Zhong, T. Lei, and D. Chen, “Training language models with
[142] B. Oguz, X. Chen, V. Karpukhin, S. Peshterliev, D. Okhonko, memory augmentation,” in Proceedings of the 2022 Conference
M. S. Schlichtkrull, S. Gupta, Y. Mehdad, and S. Yih, “Unik-qa: on Empirical Methods in Natural Language Processing, EMNLP
Unified representations of structured and unstructured knowledge for 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022,
open-domain question answering,” in Findings of the Association Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds. Association for
for Computational Linguistics: NAACL 2022, Seattle, WA, United ComputationalLinguistics,2022,pp.5657–5673.[Online].Available:
States, July 10-15, 2022, M. Carpuat, M. de Marneffe, and https://doi.org/10.18653/v1/2022.emnlp-main.382
I.V.M.Ru´ız,Eds. AssociationforComputationalLinguistics,2022, [160] S. Min, W. Shi, M. Lewis, X. Chen, W. Yih, H. Hajishirzi,
pp. 1535–1546. [Online]. Available: https://doi.org/10.18653/v1/2022. and L. Zettlemoyer, “Nonparametric masked language modeling,” in
findings-naacl.115 FindingsoftheAssociationforComputationalLinguistics:ACL2023,
Toronto,Canada,July9-14,2023,A.Rogers,J.L.Boyd-Graber,and
[143] D. Yu, S. Zhang, P. Ng, H. Zhu, A. H. Li, J. Wang, Y. Hu, W. Y.
N. Okazaki, Eds. Association for Computational Linguistics, 2023,
Wang, Z. Wang, and B. Xiang, “Decaf: Joint decoding of answers
pp. 2097–2118. [Online]. Available: https://doi.org/10.18653/v1/2023.
and logical forms for question answering over knowledge bases,” in
findings-acl.132
The Eleventh International Conference on Learning Representations,
[161] X. Zhang, Y. Zhou, G. Yang, and T. Chen, “Syntax-aware retrieval
ICLR2023,Kigali,Rwanda,May1-5,2023. OpenReview.net,2023.
augmented code generation,” in Findings of the Association for
[Online].Available:https://openreview.net/pdf?id=XHc5zRPxqV9
ComputationalLinguistics:EMNLP2023,Singapore,December6-10,
[144] G. Dong, R. Li, S. Wang, Y. Zhang, Y. Xian, and W. Xu,
2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for
“Bridging the kb-text gap: Leveraging structured knowledge-aware
ComputationalLinguistics,2023,pp.1291–1302.[Online].Available:
pre-trainingforKBQA,”inProceedingsofthe32ndACMInternational
https://aclanthology.org/2023.findings-emnlp.90
ConferenceonInformationandKnowledgeManagement,CIKM2023,
[162] Z.Fei,“Memory-augmentedimagecaptioning,”inProceedingsofthe
Birmingham, United Kingdom, October 21-25, 2023, I. Frommholz,
AAAIConferenceonArtificialIntelligence,vol.35,no.2,2021, pp.
F.Hopfgartner,M.Lee,M.Oakes,M.Lalmas,M.Zhang,andR.L.T.
1317–1324.
Santos, Eds. ACM, 2023, pp. 3854–3859. [Online]. Available:
[163] Y. Leviathan, M. Kalman, and Y. Matias, “Fast inference from
https://doi.org/10.1145/3583780.3615150
transformersviaspeculativedecoding,”inInternationalConferenceon
[145] K. Wang, F. Duan, S. Wang, P. Li, Y. Xian, C. Yin, W. Rong,
Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii,
and Z. Xiong, “Knowledge-driven cot: Exploring faithful reasoning
USA, ser. Proceedings of Machine Learning Research, A. Krause,
in llms for knowledge-intensive question answering,” CoRR, vol.
E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett,
abs/2308.13259, 2023. [Online]. Available: https://doi.org/10.48550/
Eds.,vol.202. PMLR,2023,pp.19274–19286.[Online].Available:
arXiv.2308.13259
https://proceedings.mlr.press/v202/leviathan23a.html
[146] D. Yu and Y. Yang, “Retrieval-enhanced generative model for
[164] L. Wang, N. Yang, and F. Wei, “Query2doc: Query expansion with
large-scale knowledge graph completion,” in Proceedings of the 46th
large language models,” in Proceedings of the 2023 Conference on
International ACM SIGIR Conference on Research and Development
Empirical Methods in Natural Language Processing, EMNLP 2023,
in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27,
Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali,
2023, H. Chen, W. E. Duh, H. Huang, M. P. Kato, J. Mothe, and
Eds. AssociationforComputationalLinguistics,2023,pp.9414–9423.
B. Poblete, Eds. ACM, 2023, pp. 2334–2338. [Online]. Available:
[Online].Available:https://aclanthology.org/2023.emnlp-main.585
https://doi.org/10.1145/3539618.3592052
[165] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense
[147] W. Zhung, H. Kim, and W. Y. Kim, “A protein-ligand interaction- retrievalwithoutrelevancelabels,”inProceedingsofthe61stAnnual
focused3dmoleculargenerativeframeworkforgeneralizablestructure- Meeting of the Association for Computational Linguistics (Volume
baseddrugdesign,”2023. 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023,
[148] W.Chen,H.Hu,C.Saharia,andW.W.Cohen,“Re-imagen:Retrieval- A.Rogers,J.L.Boyd-Graber,andN.Okazaki,Eds. Associationfor
augmentedtext-to-imagegenerator,”arXivpreprintarXiv:2209.14491, ComputationalLinguistics,2023,pp.1762–1777.[Online].Available:
2022. https://doi.org/10.18653/v1/2023.acl-long.99
[149] S.Sheynin,O.Ashual,A.Polyak,U.Singer,O.Gafni,E.Nachmani, [166] R. Jagerman, H. Zhuang, Z. Qin, X. Wang, and M. Bendersky,
and Y. Taigman, “Knn-diffusion: Image generation via large-scale “Query expansion by prompting large language models,” CoRR, vol.
retrieval,”arXivpreprintarXiv:2204.02849,2022. abs/2305.03653, 2023. [Online]. Available: https://doi.org/10.48550/
[150] A. Blattmann, R. Rombach, K. Oktay, J. Mu¨ller, and B. Om- arXiv.2305.03653
mer, “Retrieval-augmented diffusion models,” Advances in Neural [167] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia,
InformationProcessingSystems,vol.35,pp.15309–15324,2022. E. H. Chi, Q. V. Le, and D. Zhou, “Chain-of-thought prompting
[151] R. Rombach, A. Blattmann, and B. Ommer, “Text-guided synthesis elicits reasoning in large language models,” in Advances in26
Neural Information Processing Systems 35: Annual Conference on [186] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou,
Neural Information Processing Systems 2022, NeurIPS 2022, New S. Savarese, and C. Xiong, “A conversational paradigm for program
Orleans, LA, USA, November 28 - December 9, 2022, S. Koyejo, synthesis,” CoRR, vol. abs/2203.13474, 2022. [Online]. Available:
S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds., https://doi.org/10.48550/arXiv.2203.13474
2022.[Online].Available:http://papers.nips.cc/paper files/paper/2022/ [187] Y.He,M.Xia,H.Chen,X.Cun,Y.Gong,J.Xing,Y.Zhang,X.Wang,
hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html C. Weng, Y. Shan, and Q. Chen, “Animate-a-story: Storytelling with
[168] K. Mao, Z. Dou, F. Mo, J. Hou, H. Chen, and H. Qian, “Large retrieval-augmented video generation,” CoRR, vol. abs/2307.06940,
language models know your contextual search intent: A prompting 2023.[Online].Available:https://doi.org/10.48550/arXiv.2307.06940
framework for conversational search,” in Findings of the Association [188] E.J.Hu,Y.Shen,P.Wallis,Z.Allen-Zhu,Y.Li,S.Wang,L.Wang,
for Computational Linguistics: EMNLP 2023, Singapore, December andW.Chen,“Lora:Low-rankadaptationoflargelanguagemodels,”
6-10,2023,H.Bouamor,J.Pino,andK.Bali,Eds. Associationfor in The Tenth International Conference on Learning Representations,
ComputationalLinguistics,2023,pp.1211–1225.[Online].Available: ICLR2022,VirtualEvent,April25-29,2022. OpenReview.net,2022.
https://aclanthology.org/2023.findings-emnlp.86 [Online].Available:https://openreview.net/forum?id=nZeVKeeFYf9
[169] J. Liu, “LlamaIndex,” 11 2022. [Online]. Available: https://github. [189] C. Liu, P. C¸etin, Y. Patodia, S. Chakraborty, Y. Ding, and
com/jerryjliu/llama index B. Ray, “Automated code editing with search-generate-modify,”
[170] S. Xiao, Z. Liu, P. Zhang, and N. Muennighoff, “C-pack: Packaged CoRR, vol. abs/2306.06490, 2023. [Online]. Available: https:
resourcestoadvancegeneralchineseembedding,”2023. //doi.org/10.48550/arXiv.2306.06490
[171] J. Chen, S. Xiao, P. Zhang, K. Luo, D. Lian, and Z. Liu, “Bge m3- [190] H. Joshi, J. P. C. Sa´nchez, S. Gulwani, V. Le, G. Verbruggen,
embedding: Multi-lingual, multi-functionality, multi-granularity text and I. Radicek, “Repair is nearly generation: Multilingual program
embeddingsthroughself-knowledgedistillation,”2023. repair with llms,” in Thirty-Seventh AAAI Conference on Artificial
[172] S.Xiao,Z.Liu,P.Zhang,andX.Xing,“Lm-cocktail:Resilienttuning Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative
oflanguagemodelsviamodelmerging,”2023. Applications of Artificial Intelligence, IAAI 2023, Thirteenth
[173] P. Zhang, S. Xiao, Z. Liu, Z. Dou, and J.-Y. Nie, “Retrieve anything SymposiumonEducationalAdvancesinArtificialIntelligence,EAAI
toaugmentlargelanguagemodels,”2023. 2023, Washington, DC, USA, February 7-14, 2023, B. Williams,
[174] W. Wang, Y. Wang, S. Joty, and S. C. H. Hoi, “Rap-gen: Retrieval- Y. Chen, and J. Neville, Eds. AAAI Press, 2023, pp. 5131–5140.
augmented patch generation with codet5 for automatic program [Online].Available:https://doi.org/10.1609/aaai.v37i4.25642
repair,” in Proceedings of the 31st ACM Joint European Software
[191] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang,
Engineering Conference and Symposium on the Foundations of
J. Callan, and G. Neubig, “Active retrieval augmented generation,”
Software Engineering, ESEC/FSE 2023, San Francisco, CA, USA,
arXivpreprintarXiv:2305.06983,2023.
December 3-9, 2023, S. Chandra, K. Blincoe, and P. Tonella, Eds.
[192] A.Mallen,A.Asai,V.Zhong,R.Das,D.Khashabi,andH.Hajishirzi,
ACM,2023,pp.146–158.[Online].Available:https://doi.org/10.1145/
“When not to trust language models: Investigating effectiveness
3611643.3616256
of parametric and non-parametric memories,” in Proceedings of
[175] M.R.Glass,G.Rossiello,M.F.M.Chowdhury,A.Naik,P.Cai,and
the 61st Annual Meeting of the Association for Computational
A.Gliozzo,“Re2g:Retrieve,rerank,generate,”inProceedingsofthe
Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada,
2022ConferenceoftheNorthAmericanChapteroftheAssociationfor
July9-14,2023,A.Rogers,J.L.Boyd-Graber,andN.Okazaki,Eds.
Computational Linguistics: Human Language Technologies, NAACL
Association for Computational Linguistics, 2023, pp. 9802–9822.
2022, Seattle, WA, United States, July 10-15, 2022, M. Carpuat,
[Online].Available:https://doi.org/10.18653/v1/2023.acl-long.546
M. de Marneffe, and I. V. M. Ru´ız, Eds. Association for
[193] Z. Jiang, J. Araki, H. Ding, and G. Neubig, “How can we know
ComputationalLinguistics,2022,pp.2701–2715.[Online].Available:
Whenlanguagemodelsknow?onthecalibrationoflanguagemodels
https://doi.org/10.18653/v1/2022.naacl-main.194
for question answering,” Trans. Assoc. Comput. Linguistics, vol. 9,
[176] R.F.NogueiraandK.Cho,“Passagere-rankingwithBERT,”CoRR,
pp. 962–977, 2021. [Online]. Available: https://doi.org/10.1162/tacl
vol. abs/1901.04085, 2019. [Online]. Available: http://arxiv.org/abs/
a 00407
1901.04085
[177] J.Li,Y.Zhao,Y.Li,G.Li,andZ.Jin,“Acecoder:Utilizingexisting [194] N. Kandpal, H. Deng, A. Roberts, E. Wallace, and C. Raffel,
code to enhance code generation,” arXiv preprint arXiv:2303.17780, “Large language models struggle to learn long-tail knowledge,”
2023. in International Conference on Machine Learning, ICML 2023,
[178] P.Shi,R.Zhang,H.Bai,andJ.Lin,“XRICL:cross-lingualretrieval- 23-29 July 2023, Honolulu, Hawaii, USA, ser. Proceedings of
augmented in-context learning for cross-lingual text-to-sql semantic Machine Learning Research, A. Krause, E. Brunskill, K. Cho,
parsing,”inFindingsoftheAssociationforComputationalLinguistics: B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202. PMLR,
EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2023, pp. 15696–15707. [Online]. Available: https://proceedings.mlr.
2022,Y.Goldberg,Z.Kozareva,andY.Zhang,Eds. Associationfor press/v202/kandpal23a.html
ComputationalLinguistics,2022,pp.5248–5259.[Online].Available: [195] R. Ren, Y. Wang, Y. Qu, W. X. Zhao, J. Liu, H. Tian,
https://doi.org/10.18653/v1/2022.findings-emnlp.384 H. Wu, J. Wen, and H. Wang, “Investigating the factual knowledge
[179] https://www.pinecone.io. boundary of large language models with retrieval augmentation,”
[180] E. Saravia, “Prompt Engineering Guide,” CoRR, vol. abs/2307.11019, 2023. [Online]. Available: https:
https://github.com/dair-ai/Prompt-Engineering-Guide,122022. //doi.org/10.48550/arXiv.2307.11019
[181] H. S. Zheng, S. Mishra, X. Chen, H. Cheng, E. H. Chi, Q. V. Le, [196] Y. Wang, P. Li, M. Sun, and Y. Liu, “Self-knowledge guided
andD.Zhou,“Takeastepback:Evokingreasoningviaabstractionin retrievalaugmentationforlargelanguagemodels,”inFindingsofthe
large language models,” CoRR, vol. abs/2310.06117, 2023. [Online]. AssociationforComputationalLinguistics:EMNLP2023,Singapore,
Available:https://doi.org/10.48550/arXiv.2310.06117 December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds.
[182] S.Diao,P.Wang,Y.Lin,andT.Zhang,“Activepromptingwithchain- Association for Computational Linguistics, 2023, pp. 10303–10315.
of-thought for large language models,” CoRR, vol. abs/2302.12246, [Online].Available:https://aclanthology.org/2023.findings-emnlp.691
2023.[Online].Available:https://doi.org/10.48550/arXiv.2302.12246 [197] F. Zhang, B. Chen, Y. Zhang, J. Keung, J. Liu, D. Zan,
[183] H. Jiang, Q. Wu, C. Lin, Y. Yang, and L. Qiu, “Llmlingua: Y. Mao, J. Lou, and W. Chen, “Repocoder: Repository-level
Compressing prompts for accelerated inference of large language code completion through iterative retrieval and generation,” in
models,” in Proceedings of the 2023 Conference on Empirical Proceedingsofthe2023ConferenceonEmpiricalMethodsinNatural
Methods in Natural Language Processing, EMNLP 2023, Singapore, Language Processing, EMNLP 2023, Singapore, December 6-10,
December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for
Association for Computational Linguistics, 2023, pp. 13358–13376. ComputationalLinguistics,2023,pp.2471–2484.[Online].Available:
[Online].Available:https://aclanthology.org/2023.emnlp-main.825 https://aclanthology.org/2023.emnlp-main.151
[184] N.F.Liu,K.Lin,J.Hewitt,A.Paranjape,M.Bevilacqua,F.Petroni, [198] Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan, and W. Chen,
and P. Liang, “Lost in the middle: How language models use long “Enhancing retrieval-augmented large language models with iterative
contexts,” CoRR, vol. abs/2307.03172, 2023. [Online]. Available: retrieval-generation synergy,” in Findings of the Association for
https://doi.org/10.48550/arXiv.2307.03172 ComputationalLinguistics:EMNLP2023,Singapore,December6-10,
[185] T.Ahmed,K.S.Pai,P.Devanbu,andE.T.Barr,“Automaticsemantic 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for
augmentation of language model prompts (for code summarization),” ComputationalLinguistics,2023,pp.9248–9274.[Online].Available:
2024. https://aclanthology.org/2023.findings-emnlp.62027
[199] O. Agarwal, H. Ge, S. Shakeri, and R. Al-Rfou, “Knowledge graph Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022,
based synthetic corpus generation for knowledge-enhanced language S. Muresan, P. Nakov, and A. Villavicencio, Eds. Association for
model pre-training,” in Proceedings of the 2021 Conference of ComputationalLinguistics,2022,pp.8460–8478.[Online].Available:
the North American Chapter of the Association for Computational https://doi.org/10.18653/v1/2022.acl-long.579
Linguistics: Human Language Technologies, NAACL-HLT 2021, [210] K. Shuster, J. Xu, M. Komeili, D. Ju, E. M. Smith, S. Roller,
Online,June6-11,2021,K.Toutanova,A.Rumshisky,L.Zettlemoyer, M.Ung,M.Chen,K.Arora,J.Lane,M.Behrooz,W.Ngan,S.Poff,
D. Hakkani-Tu¨r, I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty, N. Goyal, A. Szlam, Y. Boureau, M. Kambadur, and J. Weston,
andY.Zhou,Eds. AssociationforComputationalLinguistics,2021, “Blenderbot3:adeployedconversationalagentthatcontinuallylearns
pp. 3554–3565. [Online]. Available: https://doi.org/10.18653/v1/2021. to responsibly engage,” CoRR, vol. abs/2208.03188, 2022. [Online].
naacl-main.278 Available:https://doi.org/10.48550/arXiv.2208.03188
[200] J. Baek, A. F. Aji, and A. Saffari, “Knowledge-augmented [211] S. Kim, J. Y. Jang, M. Jung, and S. Shin, “A model of
language model prompting for zero-shot knowledge graph question cross-lingual knowledge-grounded response generation for open-
answering,” CoRR, vol. abs/2306.04136, 2023. [Online]. Available: domain dialogue systems,” in Findings of the Association for
https://doi.org/10.48550/arXiv.2306.04136 Computational Linguistics: EMNLP 2021, Virtual Event / Punta
[201] J. Sun, C. Xu, L. Tang, S. Wang, C. Lin, Y. Gong, H. Shum, and Cana, Dominican Republic, 16-20 November, 2021, M. Moens,
J. Guo, “Think-on-graph: Deep and responsible reasoning of large X. Huang, L. Specia, and S. W. Yih, Eds. Association for
language model with knowledge graph,” CoRR, vol. abs/2307.07697, Computational Linguistics, 2021, pp. 352–365. [Online]. Available:
2023.[Online].Available:https://doi.org/10.48550/arXiv.2307.07697 https://doi.org/10.18653/v1/2021.findings-emnlp.33
[202] P. Limkonchotiwat, W. Ponwitayarat, C. Udomcharoenchaikit, [212] D. Cai, Y. Wang, H. Li, W. Lam, and L. Liu, “Neural machine
E. Chuangsuwanich, and S. Nutanong, “Cl-relkt: Cross-lingual translation with monolingual translation memory,” in Proceedings
language knowledge transfer for multilingual retrieval question of the 59th Annual Meeting of the Association for Computational
answering,” in Findings of the Association for Computational Linguistics and the 11th International Joint Conference on Natural
Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15, Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),
2022,M.Carpuat,M.deMarneffe,andI.V.M.Ru´ız,Eds. Association VirtualEvent,August1-6,2021,C.Zong,F.Xia,W.Li,andR.Navigli,
for Computational Linguistics, 2022, pp. 2141–2155. [Online]. Eds. AssociationforComputationalLinguistics,2021,pp.7307–7318.
Available:https://doi.org/10.18653/v1/2022.findings-naacl.165 [Online].Available:https://doi.org/10.18653/v1/2021.acl-long.567
[203] A.Asai,X.Yu,J.Kasai,andH.Hajishirzi,“Onequestionanswering [213] U. Khandelwal, A. Fan, D. Jurafsky, L. Zettlemoyer, and M. Lewis,
modelformanylanguageswithcross-lingualdensepassageretrieval,” “Nearestneighbormachinetranslation,”in9thInternationalConference
in Advances in Neural Information Processing Systems 34: Annual on Learning Representations, ICLR 2021, Virtual Event, Austria,
ConferenceonNeuralInformationProcessingSystems2021,NeurIPS May 3-7, 2021. OpenReview.net, 2021. [Online]. Available:
2021, December 6-14, 2021, virtual, M. Ranzato, A. Beygelzimer, https://openreview.net/forum?id=7wCBOfJ8hJM
Y. N. Dauphin, P. Liang, and J. W. Vaughan, Eds., 2021, pp. [214] X.DuandH.Ji,“Retrieval-augmentedgenerativequestionanswering
7547–7560. [Online]. Available: https://proceedings.neurips.cc/paper/ foreventargumentextraction,”inProceedingsofthe2022Conference
2021/hash/3df07fdae1ab273a967aaa1d355b8bb6-Abstract.html on Empirical Methods in Natural Language Processing, EMNLP
[204] K. Lee, S. Han, S. Hwang, and M. Lee, “When to read documents 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022,
or QA history: On unified and selective open-domain QA,” in Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds. Association for
FindingsoftheAssociationforComputationalLinguistics:ACL2023, ComputationalLinguistics,2022,pp.4649–4666.[Online].Available:
Toronto,Canada,July9-14,2023,A.Rogers,J.L.Boyd-Graber,and https://doi.org/10.18653/v1/2022.emnlp-main.307
N. Okazaki, Eds. Association for Computational Linguistics, 2023, [215] Y.Gao,Q.Yin,Z.Li,R.Meng,T.Zhao,B.Yin,I.King,andM.R.
pp. 6420–6432. [Online]. Available: https://doi.org/10.18653/v1/2023. Lyu, “Retrieval-augmented multilingual keyphrase generation with
findings-acl.401 retriever-generatoriterativetraining,”inFindingsoftheAssociationfor
[205] K. Huang, C. Zhai, and H. Ji, “CONCRETE: improving cross- ComputationalLinguistics:NAACL2022,Seattle,WA,UnitedStates,
lingual fact-checking with cross-lingual retrieval,” in Proceedings July 10-15, 2022, M. Carpuat, M. de Marneffe, and I. V. M. Ru´ız,
of the 29th International Conference on Computational Linguistics, Eds. AssociationforComputationalLinguistics,2022,pp.1233–1246.
COLING 2022, Gyeongju, Republic of Korea, October 12-17, [Online].Available:https://doi.org/10.18653/v1/2022.findings-naacl.92
2022, N. Calzolari, C. Huang, H. Kim, J. Pustejovsky, L. Wanner, [216] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou,
K. Choi, P. Ryu, H. Chen, L. Donatelli, H. Ji, S. Kurohashi, S. Savarese, and C. Xiong, “A conversational paradigm for program
P. Paggio, N. Xue, S. Kim, Y. Hahm, Z. He, T. K. Lee, synthesis,” CoRR, vol. abs/2203.13474, 2022. [Online]. Available:
E. Santus, F. Bond, and S. Na, Eds. International Committee on https://doi.org/10.48550/arXiv.2203.13474
ComputationalLinguistics,2022,pp.1024–1035.[Online].Available: [217] A. Madaan, S. Zhou, U. Alon, Y. Yang, and G. Neubig, “Language
https://aclanthology.org/2022.coling-1.86 models of code are few-shot commonsense learners,” in Proceedings
[206] Y.Liu,Y.Wan,L.He,H.Peng,andP.S.Yu,“KG-BART:knowledge of the 2022 Conference on Empirical Methods in Natural Language
graph-augmented BART for generative commonsense reasoning,” in Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates,
Thirty-FifthAAAIConferenceonArtificialIntelligence,AAAI2021, December7-11,2022,Y.Goldberg,Z.Kozareva,andY.Zhang,Eds.
Thirty-Third Conference on Innovative Applications of Artificial Association for Computational Linguistics, 2022, pp. 1384–1403.
Intelligence, IAAI 2021, The Eleventh Symposium on Educational [Online].Available:https://doi.org/10.18653/v1/2022.emnlp-main.90
Advances in Artificial Intelligence, EAAI 2021, Virtual Event, [218] Y. Wang, H. Le, A. Gotmare, N. D. Q. Bui, J. Li, and S. C. H. Hoi,
February 2-9, 2021. AAAI Press, 2021, pp. 6418–6425. [Online]. “Codet5+: Open code large language models for code understanding
Available:https://doi.org/10.1609/aaai.v35i7.16796 andgeneration,”inProceedingsofthe2023ConferenceonEmpirical
[207] H. Zhang, Z. Liu, C. Xiong, and Z. Liu, “Grounded conversation Methods in Natural Language Processing, EMNLP 2023, Singapore,
generation as guided traverses in commonsense knowledge graphs,” December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds.
in Proceedings of the 58th Annual Meeting of the Association Association for Computational Linguistics, 2023, pp. 1069–1088.
for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, [Online].Available:https://aclanthology.org/2023.emnlp-main.68
D. Jurafsky, J. Chai, N. Schluter, and J. R. Tetreault, Eds. [219] N. Beau and B. Crabbe´, “The impact of lexical and grammatical
Association for Computational Linguistics, 2020, pp. 2031–2043. processing on generating code from natural language,” in Findings
[Online].Available:https://doi.org/10.18653/v1/2020.acl-main.184 oftheAssociationforComputationalLinguistics:ACL2022,Dublin,
[208] D.Cai,Y.Wang,W.Bi,Z.Tu,X.Liu,W.Lam,andS.Shi,“Skeleton- Ireland,May22-27,2022,S.Muresan,P.Nakov,andA.Villavicencio,
to-response: Dialogue generation guided by retrieval memory,” in Eds. AssociationforComputationalLinguistics,2022,pp.2204–2214.
Proceedings of the 2019 Conference of the North American Chapter [Online].Available:https://doi.org/10.18653/v1/2022.findings-acl.173
of the Association for Computational Linguistics: Human Language [220] B. Wei, Y. Li, G. Li, X. Xia, and Z. Jin, “Retrieve and refine:
Technologies,NAACL-HLT2019,Minneapolis,MN,USA,June2-7, Exemplar-based neural comment generation,” in 35th IEEE/ACM
2019, Volume 1 (Long and Short Papers), J. Burstein, C. Doran, and International Conference on Automated Software Engineering, ASE
T.Solorio,Eds. AssociationforComputationalLinguistics,2019,pp. 2020, Melbourne, Australia, September 21-25, 2020. IEEE, 2020,
1219–1228.[Online].Available:https://doi.org/10.18653/v1/n19-1124 pp. 349–360. [Online]. Available: https://doi.org/10.1145/3324884.
[209] M. Komeili, K. Shuster, and J. Weston, “Internet-augmented 3416578
dialogue generation,” in Proceedings of the 60th Annual Meeting [221] S. Liu, Y. Chen, X. Xie, J. K. Siow, and Y. Liu, “Retrieval-
of the Association for Computational Linguistics (Volume 1: augmented generation for code summarization via hybrid GNN,”28
in 9th International Conference on Learning Representations, ICLR Computational Linguistics, 2021, pp. 325–336. [Online]. Available:
2021,VirtualEvent,Austria,May3-7,2021. OpenReview.net,2021. https://doi.org/10.18653/v1/2021.acl-demo.39
[Online].Available:https://openreview.net/forum?id=zv-typ1gPxA [240] K. D. Bollacker, C. Evans, P. K. Paritosh, T. Sturge, and J. Taylor,
[222] F. Yamaguchi, N. Golde, D. Arp, and K. Rieck, “Modeling and “Freebase: a collaboratively created graph database for structuring
discovering vulnerabilities with code property graphs,” in 2014 IEEE humanknowledge,”inProceedingsoftheACMSIGMODInternational
Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, ConferenceonManagementofData,SIGMOD2008,Vancouver,BC,
May 18-21, 2014. IEEE Computer Society, 2014, pp. 590–604. Canada, June 10-12, 2008, J. T. Wang, Ed. ACM, 2008, pp. 1247–
[Online].Available:https://doi.org/10.1109/SP.2014.44 1250.[Online].Available:https://doi.org/10.1145/1376616.1376746
[223] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco, C. B. [241] Y. Shu and Z. Yu, “Data distribution bottlenecks in grounding
Clement, D. Drain, D. Jiang, D. Tang, G. Li, L. Zhou, L. Shou, language models to knowledge bases,” CoRR, vol. abs/2309.08345,
L.Zhou,M.Tufano,M.Gong,M.Zhou,N.Duan,N.Sundaresan,S.K. 2023.[Online].Available:https://doi.org/10.48550/arXiv.2309.08345
Deng,S.Fu,andS.Liu,“Codexglue:Amachinelearningbenchmark [242] D. Leake and D. J. Crandall, “On bringing case-based reasoning
dataset for code understanding and generation,” in Proceedings of methodology to deep learning,” in Case-Based Reasoning Research
the Neural Information Processing Systems Track on Datasets and and Development - 28th International Conference, ICCBR 2020,
Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December Salamanca, Spain, June 8-12, 2020, Proceedings, ser. Lecture
2021, virtual, J. Vanschoren and S. Yeung, Eds., 2021. [Online]. Notes in Computer Science, I. Watson and R. O. Weber, Eds.,
Available: https://datasets-benchmarks-proceedings.neurips.cc/paper/ vol. 12311. Springer, 2020, pp. 343–348. [Online]. Available:
2021/hash/c16a5320fa475530d9583c34fd356ef5-Abstract-round1.html https://doi.org/10.1007/978-3-030-58342-2 22
[224] Y. Ding, Z. Wang, W. U. Ahmad, M. K. Ramanathan, R. Nallapati, [243] L. Zhang, J. Zhang, Y. Wang, S. Cao, X. Huang, C. Li, H. Chen,
P. Bhatia, D. Roth, and B. Xiang, “Cocomic: Code completion and J. Li, “FC-KBQA: A fine-to-coarse composition framework for
by jointly modeling in-file and cross-file context,” CoRR, vol. knowledge base question answering,” in Proceedings of the 61st
abs/2212.10007, 2022. [Online]. Available: https://doi.org/10.48550/ Annual Meeting of the Association for Computational Linguistics
arXiv.2212.10007 (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July
[225] B. Bogin, S. Gupta, P. Clark, and A. Sabharwal, “Leveraging code 9-14, 2023, A. Rogers, J. L. Boyd-Graber, and N. Okazaki, Eds.
to improve in-context learning for semantic parsing,” arXiv preprint Association for Computational Linguistics, 2023, pp. 1002–1017.
arXiv:2311.09519,2023. [Online].Available:https://doi.org/10.18653/v1/2023.acl-long.57
[226] Z.JieandW.Lu,“Leveragingtrainingdatainfew-shotpromptingfor [244] C. Wang, Y. Xu, Z. Peng, C. Zhang, B. Chen, X. Wang, L. Feng,
numericalreasoning,”arXivpreprintarXiv:2305.18170,2023. andB.An,“keqing:knowledge-basedquestionansweringisanature
[227] Y. Hao, W. Chen, Z. Zhou, and W. Cui, “E&v: Prompting large chain-of-thoughtmentorofLLM,”CoRR,vol.abs/2401.00426,2024.
languagemodelstoperformstaticanalysisbypseudo-codeexecution [Online].Available:https://doi.org/10.48550/arXiv.2401.00426
andverification,”arXivpreprintarXiv:2312.08477,2023. [245] J. Liu, S. Cao, J. Shi, T. Zhang, L. Hou, and J. Li, “Probing
[228] G. Pinto, C. de Souza, J. B. Neto, A. de Souza, T. Gotto, and structuredsemanticsunderstandingandgenerationoflanguagemodels
E. Monteiro, “Lessons from building stackspot ai: A contextualized viaquestionanswering,”CoRR,vol.abs/2401.05777,2024.[Online].
aicodingassistant,”2024. Available:https://doi.org/10.48550/arXiv.2401.05777
[229] S. Ghosh, S. Kumar, C. K. R. Evuru, R. Duraiswami, and [246] D.Weininger,“Smiles,achemicallanguageandinformationsystem.1.
D. Manocha, “RECAP: retrieval-augmented audio captioning,” introductiontomethodologyandencodingrules,”JournalofChemical
CoRR, vol. abs/2309.09836, 2023. [Online]. Available: https: InformationandComputerSciences,1988.
//doi.org/10.48550/arXiv.2309.09836 [247] R.Irwin,S.Dimitriadis,J.He,andE.J.Bjerrum,“Chemformer:apre-
[230] B. Elizalde, S. Deshmukh, and H. Wang, “Natural language trained transformer for computational chemistry,” Machine Learning:
supervision for general-purpose audio representations,” CoRR, vol. ScienceandTechnology,2022.
abs/2309.05767, 2023. [Online]. Available: https://doi.org/10.48550/ [248] A. C. Anderson, “The process of structure-based drug design,”
arXiv.2309.05767 Chemistry&biology,vol.10,no.9,pp.787–797,2003.
[231] T. Kouzelis and V. Katsouros, “Weakly-supervised automated audio [249] M.Batool,B.Ahmad,andS.Choi,“Astructure-baseddrugdiscovery
captioning via text only training,” CoRR, vol. abs/2309.12242, 2023. paradigm,”Internationaljournalofmolecularsciences,vol.20,no.11,
[Online].Available:https://doi.org/10.48550/arXiv.2309.12242 p.2783,2019.
[232] S. Deshmukh, B. Elizalde, D. Emmanouilidou, B. Raj, R. Singh, [250] L.Yang,Z.Huang,X.Zhou,M.Xu,W.Zhang,Y.Wang,X.Zheng,
and H. Wang, “Training audio captioning models without audio,” W. Yang, R. O. Dror, S. Hong et al., “Prompt-based 3d molecular
CoRR, vol. abs/2309.07372, 2023. [Online]. Available: https: diffusionmodelsforstructure-baseddrugdesign,”2023.
//doi.org/10.48550/arXiv.2309.07372 [251] D.P.KingmaandM.Welling,“Auto-encodingvariationalbayes,”arXiv
[233] Y. Kirstain, O. Levy, and A. Polyak, “X&fuse: Fusing visual infor- preprintarXiv:1312.6114,2013.
mationintext-to-imagegeneration,”arXivpreprintarXiv:2303.01000, [252] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large
2023. language models in retrieval-augmented generation,” CoRR, vol.
[234] Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis, and A. Smola, abs/2309.01431, 2023. [Online]. Available: https://doi.org/10.48550/
“Multimodal chain-of-thought reasoning in language models,” arXiv arXiv.2309.01431
preprintarXiv:2302.00923,2023. [253] S. ES, J. James, L. E. Anke, and S. Schockaert, “RAGAS:
[235] C. Xu, M. Yang, X. Ao, Y. Shen, R. Xu, and J. Tian, “Retrieval- automated evaluation of retrieval augmented generation,” CoRR, vol.
enhancedadversarialtrainingwithdynamicmemory-augmentedatten- abs/2309.15217, 2023. [Online]. Available: https://doi.org/10.48550/
tionforimageparagraphcaptioning,”Knowledge-BasedSystems,vol. arXiv.2309.15217
214,p.106730,2021. [254] J. Saad-Falcon, O. Khattab, C. Potts, and M. Zaharia, “ARES: an
[236] R. Ramos, D. Elliott, and B. Martins, “Retrieval-augmented image automated evaluation framework for retrieval-augmented generation
captioning,”arXivpreprintarXiv:2302.08268,2023. systems,” CoRR, vol. abs/2311.09476, 2023. [Online]. Available:
[237] Z.Hu,A.Iscen,C.Sun,Z.Wang,K.-W.Chang,Y.Sun,C.Schmid, https://doi.org/10.48550/arXiv.2311.09476
D. A. Ross, and A. Fathi, “Reveal: Retrieval-augmented visual- [255] https://github.com/truera/trulens.
languagepre-trainingwithmulti-sourcemultimodalknowledgemem- [256] Y. Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu,
ory,”inProceedingsoftheIEEE/CVFConferenceonComputerVision H.Liu,T.Xu,andE.Chen,“CRUD-RAG:Acomprehensivechinese
andPatternRecognition,2023,pp.23369–23379. benchmark for retrieval-augmented generation of large language
[238] Z.Li,W.Zhao,X.Du,G.Zhou,andS.Zhang,“Cross-modalretrieval models,” CoRR, vol. abs/2401.17043, 2024. [Online]. Available:
andsemanticrefinementforremotesensingimagecaptioning,”Remote https://doi.org/10.48550/arXiv.2401.17043
Sensing,vol.16,no.1,p.196,2024. [257] S. Barnett, S. Kurniawan, S. Thudumu, Z. Brannelly, and
[239] S. Chen, Q. Liu, Z. Yu, C. Lin, J. Lou, and F. Jiang, “Retrack: M. Abdelrazek, “Seven failure points when engineering a retrieval
A flexible and efficient framework for knowledge base question augmented generation system,” CoRR, vol. abs/2401.05856, 2024.
answering,” in Proceedings of the Joint Conference of the 59th [Online].Available:https://doi.org/10.48550/arXiv.2401.05856
Annual Meeting of the Association for Computational Linguistics [258] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,
and the 11th International Joint Conference on Natural Language Y. Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:
Processing, ACL 2021 - System Demonstrations, Online, August Redefining retrieval for RAG systems,” CoRR, vol. abs/2401.14887,
1-6, 2021, H. Ji, J. C. Park, and R. Xia, Eds. Association for 2024.[Online].Available:https://doi.org/10.48550/arXiv.2401.1488729
[259] L. Qiu, P. Shaw, P. Pasupat, T. Shi, J. Herzig, E. Pitler, F. Sha, and
K.Toutanova,“Evaluatingtheimpactofmodelscaleforcompositional
generalizationinsemanticparsing,”arXivpreprintarXiv:2205.12253,
2022.
[260] R. Aksitov, C. Chang, D. Reitter, S. Shakeri, and Y. Sung,
“Characterizing attribution and fluency tradeoffs for retrieval-
augmentedlargelanguagemodels,”CoRR,vol.abs/2302.05578,2023.
[Online].Available:https://doi.org/10.48550/arXiv.2302.05578
[261] C. Han, Q. Wang, W. Xiong, Y. Chen, H. Ji, and S. Wang, “Lm-
infinite: Simple on-the-fly length generalization for large language
models,” CoRR, vol. abs/2308.16137, 2023. [Online]. Available:
https://doi.org/10.48550/arXiv.2308.16137
[262] S. Jindal, “Did google gemini 1.5 really kill rag?” https://
analyticsindiamag.com/did-google-gemini-1-5-really-kill-rag/,2024.
[263] H. Chase, “Langchain,” https://github.com/langchain-ai/langchain,
2022.