Agent-based MST Construction
Ajay D. Kshemkalyani∗, Manish Kumar†, Anisur Rahaman Molla‡, and Gokarna Sharma§
Abstract
Minimum-weight spanning tree (MST) is one of the fundamental and well-studied problems
in distributed computing. In this paper, we initiate the study of constructing MST using mo-
bile agents (aka robots). Suppose n agents are positioned initially arbitrarily on the nodes of
a connected, undirected, arbitrary, anonymous, port-labeled, weighted n-node, m-edge graph
G of diameter D and maximum degree ∆. The agents relocate themselves autonomously and
computeanMSTofGsuchthatexactlyoneagentpositionsonanodeandtracksinitsmemory
which of its adjacent edges belong to the MST. The objective is to minimize time and memory
requirements. Followingthe literature,weconsiderthe synchronoussetting inwhicheachagent
performs its operations synchronously with others and hence time can be measured in rounds.
We first establish a generic result: if n and ∆ are known a priori and memory per agent is
as much as node memory in the message-passing model (of distributed computing), agents can
simulateanyO(T)-rounddeterministicalgorithmforanyprobleminthemessage-passingmodel
2
to the agent model in O(∆T logn+nlog n) rounds. As a corollary, MST can be constructed
∗ 2 in the agent model in O(max ∆√nlognlog n,∆Dlogn,nlog n ) rounds simulating the cel-
∗ { }
ebrated O(√nlog n+D)-round GKP algorithm for MST in the message-passing model. We
then establish that, without knowing any graphparameter a priori, there exists a deterministic
algorithm to construct MST in the agent model in O(m+nlogn) rounds with O(nlogn) bits
memoryateachagent. Thepresentedalgorithmneedstoovercomehighlynon-trivialchallenges
on how to synchronize agentsin computing MST as they may initially be positioned arbitrarily
onthe graphnodes. The challengeswereovercomebydevelopinga technique ofdispersion with
election which positions n agents at n nodes and elects one agent as a leader, which may be of
independent interest in distributed robotics.
Keywords: Distributedalgorithms,Multi-agentsystems,Mobileagents,Localcommunication,
Minimum Spanning Tree, Leader Election, Time and memory complexity
1 Introduction
Given a connected, weighted, undirected graph G, a minimum-weight spanning tree (MST) (or
simply minimum spanning tree) is a subset of the edges of G that connects all the vertices of G
avoiding any cycles and with the minimum possible total edge weight, i.e., it is a spanning tree
whose sum of edge weights is the minimum. If G has n nodes, then an MST has precisely n 1
−
edges. MST construction is a fundamental problem in graph theory due to its many applications
and there is a vast literature in centralized, parallel, and distributed computing models [2, 5, 6, 7,
9, 10, 11, 12, 16, 19].
∗University of Illinois at Chicago, USA,ajay@uic.edu
†IIT Madras, India, manishsky27@gmail.com
‡ISI Kolkata, India, anisurpm@gmail.com
§Kent State University,USA,gsharma2@kent.edu
1
4202
raM
02
]CD.sc[
1v61731.3042:viXraIn the centralized computing model, many MST construction algorithms exist, e.g. [5, 7, 10,
11, 12]. These algorithms assume that G is known including edge weights and the analysis mostly
concerns time – the number of steps of computation. In the parallel computing model, the focus is
onimprovingtimeusingmultipleprocessors[2,6,19],insteadofasingleprocessorinthecentralized
computing model. Parallel algorithms also assume that G is known including the edge weights.
The (message-passing) distributed computing model (which we simply call the message-passing
model throughout this paper hereafter) lifts the assumption of known G. It only considers that
each node(processor) knows its neighboringprocessors and the weights of the communication links
(edges) connecting it to those neighboring processors. Further, only an O(logn)-size message (the
model) can be sent on each edge in each time step. For computing MST in this model,
CONGEST
as the output, every processor knows which of its adjacent edges belongto MST.MSTconstruction
is an active field of research in the message-passing model. The best known algorithms are [9, 16]
∗
with time complexity O(√nlog n+ D), where D is the diameter of G. Furthermore, the best-
known time lower bound is Ω(√n/logn+ D) [18]. These bounds were achieved considering the
synchronous setting (also ours) in which each processor performs its operations synchronously with
all others.
In this paper, we initiate the study of MST construction using mobile agents (aka robots).
Suppose we are given n agents positioned initially arbitrarily on the nodes of G. Any algorithm
run by agents should output an MST such that (i) each of the n agents is positioned on a different
node of G and (ii) an agent positioned at a node knows which of its adjacent edges are the MST
edges.
The agent model has two major differences with the message-passing model.
I. In the agent model, agents but not the graph nodes are assumed to have memory and pro-
cessing power, whereas the message-passing model assumes each graph node is a processor
having both unrestricted memory and processing power.
II. In the agent model, an agent positioned at a graph node does not have message send/receive
capability to/from an agent positioned at its neighboring node, whereas a processor (at a
node) in the message-passing model has message send/receive capability to/from a processor
positioned at its neighbor node.
Difference II is problematic for the agent model since if an agent (at a node) needs to deliver
a message to its neighbor(s), it has to relocate to that neighbor and there has to be an agent
positioned on that neighbor.
Let us discuss why it is important to study MST in the agent model. First, since the agent
model is different from the message-passing model, it demands new techniques for computation.
Second, theagent modelhasbeengainingsignificant attention recently incomputing. For example,
Pattanayak et al. [17] considered computing Maximal Independent Set (MIS) of G. Chand et al.
[4] considered computing small dominating sets of G. Both of these results assume that graph
parameters (such as n and ∆) are known to agents a priori. Triangle counting by agents is studied
and applied to other problems in Chand et al. [3]. Given these recent developments, MST is a
natural, fundamental problem to investigate in the agent model.
Contributions. Consider an anonymous connected, undirected, arbitrary, weighted n-node, m-
edge graph G of diameter D and maximum degree ∆ with n robots with unique identifiers being
initially positioned arbitrarily on the graph nodes (possibly multiple agents at a node). One might
immediately think of constructing MST in the agent model simulating existing MST algorithms
developed in the message-passing model. We show that this is indeed possible under certain as-
2sumptions by establishing the following general theorem that applies to any problem solved in the
message-passing model.
Theorem1(Simulation). Anydeterministic algorithm foraproblem that takesO(T)rounds in
A ′
the message-passing model can be converted to a deterministic algorithm that takes O(∆T logn+
A
nlog2n) rounds in the agent model, provided that parameters n and ∆ are known a priori and
memory at each agent is as much as the node memory used in the message-passing model.
Plugging in in Theorem 1 the MST algorithm of [9, 16], famously known as GKP algorithm,
∗ A
that takes T = O(√nlog n+D) rounds in the message-passing model, we obtain as a corollary
the MST algorithm ′ that takes O(max ∆√nlognlog∗ n,∆Dlogn,nlog2n ) roundsin theagent
A { }
model.
TheimmediatequestioniswhetheranMSTcanbeconstructedintheagentmodelremovingthe
assumptionof knowngraphparameters (suchas nand∆), andwithaboundonmemory peragent.
We show that this is indeed possible in the agent model. We first establish the following theorem
which concerns with (i) dispersing agents so that graph nodes have an agent each positioned and
(ii) electing an agent at a node as a leader.
Theorem 2 (Dispersion with election). There is a deterministic algorithm in the agent model
for (i) dispersing agents so that a graph node contains one agent and (ii) electing one agent at
a node as a leader, which terminates in O(m) rounds with O(nlogn) bits at each agent, without
agents knowing any graph parameter a priori.
Given a leader and agents dispersed, we establish the following theorem for MST.
Theorem 3 (MST). Given one agent as a leader and n agents positioned on n nodes of G, there
is a deterministic algorithm for constructing MST that takes O(m+nlogn) rounds and O(∆logn)
bits at each agent, without agents knowing any graph parameter a priori.
Compared to the time bound obtained through simulation (Theorem 1), our MST result (The-
∗
orem 3) is better for any graph with m < max ∆√nlog n,∆D,nlogn , even without knowing
{ }
any graph parameter a priori. Additionally, the MST construction time can be compared to the
lower bound of O(max √n/logn+D,n ) rounds in the agent model we prove in which the first
{ }
part comes form the lower bound in the message-passing model and the second part comes from
the lower bound of dispersing n robots to n nodes. Furthermore, the time complexity of our MST
algorithm in the agent model matches that of Prim’s algorithm (using Fibonacci heap) [7]. The
memory of O(nlogn) bits is within O(n) factor from optimal O(logn) bits for solving any problem
in the agent model. Notice that the results in the message-passing model do not explicitly bound
the memory requirement per node. The above results we establish are the first results for MST
in the agent model. The result for dispersion with election (Theorem 2) plays a crucial role in es-
tablishing the MST result (Theorem 3) and hence it may be of independent interest in distributed
robotics.
Challenges and Techniques. The message-passing model allows the nodes (processors) to
send/receive messages to/from their neighbors, i.e., in a single round, a node can send a mes-
sage to all its neighbors and receive messages from all its neighbors. In contrast, in the agent
model, the messages from an agent, if any, that are to be sent to the other agents in the neighbor-
ing nodes have to be delivered by the agent visiting those neighbors. Furthermore, it might be the
case that when the agent reaches that node, the agent at that node may have already moved to
some other node. Therefore, any algorithm in the agent modelneeds to guarantee message delivery
by synchronizing sender and receiver agents to be co-located at a node.
3Additionally, to be able to construct MST of G, each node of G must have an agent positioned
on it, which may not be the case initially since one or more nodes may have possibly multiple
agents positioned and some nodes may have noagent positioned. Surprisingly, even whenthere is a
single agent at each node initially, the agent at a node does not know it. Therefore, irrespective of
whether the nodes have zero, single, or multiple agents initially, we want to reach to configuration
where each node has an agent positioned.
Suppose we have a single agent positioned at a node. The question is the agent from which
node starts MST construction and when. To overcome this challenge, we elect a single agent at
a node as a (global) leader which gets the authority to start MST construction. The remaining
agents do not participate in MST construction until the leader grants them authority to do so.
Although having a leader makes MST construction easier, electing a leader itself turned out to
be a difficult task. Therefore, we elect a leader in two steps. In the first step, the agents compete
to become ‘local leader’. In the second step, the local leaders compete to become a global ‘leader’.
The agent becoming a local leader can immediately run the second step.
On becoming a local leader, each local leader can run the same leader election procedure to
become a global leader. However, in the first step, how an agent competes to become a ‘local
leader’ is different based on whether an agent positioned at a node is alone or not. Additionally an
agent positioned at a node does not know whether the agents positioned at other nodes are alone
(dispersed), all at a single node (rooted), or at multiple nodes (general). This creates a difficulty
for agents on what approach to use in the first step to become local leaders. Therefore, we use
the following idea. For the agents that are initially alone, we ask them to run a singleton election
procedure to check whether the can become local leaders. The singleton election procedure run by
an agent r at a node v visits the neighbors of v (possibly repeatedly). For the agents that are not
v
initially alone, we ask then to run a dispersion with election procedure which serves two purposes:
(i) place an agent each on empty nodesand (i) elect oneagent amongthe initially co-located a local
leader. The singleton election procedure elects an agent r at node v as a local leader if and only
v
if all the neighbors of v have a singleton agent positioned initially. That is, if the procedure finds
at least a neighbor of v is empty or an agent from a dispersion with election procedure positioned,
it will not elect r as a leader. We guarantee that starting from any initial configuration, at least
v
an agent becomes a local leader.
For the dispersed initial cases, only the singleton election procedure runs. For the rooted initial
cases, only the dispersion with election procedure runs. For the general initial cases, the singleton
election and dispersionwith election proceduresrunconcurrently. Once all dispersion with election
procedures finish, there is a guarantee that the n agents disperse to n nodes of G (one per node).
As soon as some agent becomes a local leader, it tries to elect itself as a (global) leader. For
this, it runs a verification procedure to check whether it will be able to traverse all the edges of
G. If the agent is indeed able to traverse all the edges, then it returns to the node (which we call
its home node) and elects itself as a (global) leader. We prove that if an agent elects itself as a
leader, there is no other agent that can satisfy the conditions to be elected as a leader, i.e., the
global leader is unique. This dispersion with election technique may be of independent interest in
distributed robotics.
Since there might be multiple local leaders elected, there might be multiple verification proce-
dures running concurrently. Each verification procedure p has tuple (roundNo ,ID ) such that if
p p
it meets another verification procedure (roundNo ,ID ) then p continues and q stops if p’s tuple
q q
is lexicographically greater than q’s, otherwise q continues and p stops. Here roundNo∗ is a round
number at which the procedure started and ID∗ is the ID of the agent that runs this procedure.
Consider the nodes of the graph where local leaders were positioned (the home nodes) before
they run the verification procedure. While local leaders run the verification procedure, these nodes
4become empty since they are traversing the graph. When some other verification procedure or
dispersion with election procedure encounters an empty node, it needs to confirm whether that
node is in fact empty or it is a home node of some local leader not home at that time. This is
done by asking the local leaders to keep that information about an agent positioned at a neighbor
and the verification procedure to visit the neighbors to see whether such information exists at a
neighbor. We prove that if an empty node is indeed a home node then there exists a neighbor
holding that information. Additionally, we prove that the local leader can return to its home node
whenever needed.
Afteraleaderiselected, wesynchronizeagentstoconstructMST.TheMSTconstructionbegins
with the leader. The leader provides ranking to the agents from 2 to n with it being rank 1. After
ranking, each agent r (at node v) considers itself as a component C and assigns the rank to its
v rv
componentrank(C )itsrankrank(r ),i.e.,rank(C ) rank(r ). Letminimum-weightoutgoing
rv v rv
←
v
edge (MOE) of a node u G be the neighboring edge of u with the minimum weight (ties broken
∈
arbitrarily). The agent r with token (initially the leader) picks the MOE. Let the other end of
u
MOE be node w (with agent r positioned on it) in component C . If rank(C ) < rank(C ),
w rw ru rw
then r forms a merged component Cnew merging C with C and assigns to Cnew the rank
u ru rw ru ru
rank(Cnew) rank(C )1. Notice that the way components are grown, they are always rooted
ru
←
ru
trees. Some parent-child pointer adjustments are done to make sure that the newly formed merged
components (such as Cnew) remain a rooted tree. After merging is done, r passes the token to
ru u
agent r with rank(r ) = rank(r )+1. If rank(C ) < rank(r ), then r simply passes the token
v v u rv v v
to the agent with rank rank(r ) + 1, otherwise r includes the MOE to C as discussed above
v v rv
which forms a merged component and passes the token to the agent with rank rank(r )+1. The
v
process is repeated till the agent r with rank(r ) = n gets the token. After r finishes with its
z z z
process, it passes the token back to the leader, which implies that one phase of MST construction
is finished. We guarantee that at the end of this phase, the number of initial components reduces
to at most half. We further show that repeating this process for O(logn) phases, we have a
single component of MOE edges, giving an MST, since initially we have n single-node components.
Finally, we show that, given a leader and the n robots positioned at n nodes, constructing an MST
takes O(m+nlogn) time and needs memory of O(nlogn) bits per agent. Interestingly, this time
bound is already better than simulating the message-passing algorithm knowing n,∆ in graphs
∗
with number of edges m < max ∆√nlog n,∆D,nlogn .
{ }
Remark on the Memory Requirement of O(nlogn) Bits per Agent in the Proposed
Algorithm: If n and ∆ are known, we can use the dispersion algorithm of Sudo et al. [20] that
finishes in O(nlog2n) rounds or of Kshemkalyani and Sharma [15] that finishes in O(m) rounds.
Both these algorithms need O(logn) bits per agent. The initially singleton agents do nothing until
dispersion is achieved. After that the singleton election procedure can finish in O(∆log2n) rounds
with O(logn) bits per agent. Then finally the local leaders can run leader election procedure
to elect a unique global leader among the local leaders in O(m) rounds with O(logn) bits per
agent. Therefore, the dispersion with election takes O(m) rounds (same as our algorithm) and
memory becomes O(logn) bits per agent (n factor improvement compared to our algorithm). For
the MST construction, a node may need to remember multiple of its neighboring edges as a part
of MST and hence the total memory needed in our algorithm becomes O(∆logn) bits per agent.
Notice that this memory improvement is achieved knowing n and ∆. Our algorithm achieves our
claimed bounds without knowing any graph parameter a priori and there are agent coordination
1However,ifrank(C ru)>rank(C rw),r u simplypassesthetokentothenextagentwithrankrank(r u)+1. When
r w gets thetoken, then r w forms the merged component C rn wew merging C ru with C rw through theMOE connecting
C rw with C ru.
5andsynchronizationchallenges toovercomeasdescribedinchallenges andtechniques. Additionally,
being able to design algorithm without knowing any graph parameter a priori has its own merits
in distributed robotics.
Related Work. There is a vast literature on MST construction in centralized, parallel, and
message-passing models. In the centralized computing model, the first algorithm for MST due
to Bor˚uvka [10] proceeds in stages. In each stage, it identifies a forest F consisting of the MOE
incident to each vertex in G, then forms the graph G = G F as the input to the next step. Each
1
\
stage takes O(m) time and the number of vertices remaining to be processed is reduced by half
in each step. Therefore, this algorithm constructs MST in O(mlogn) time. Prim’s algorithm [7]
grows the MST one edge at a time. The algorithm initially starts from a vertex in G which is
selected arbitrarily. In each step, the MST is augmented with a MOE, say (x,y), such that node x
isalreadyinMSTbutnotnodey. Thisalgorithm finishesintimeO(mlogn)usingbinaryheapand
in time O(m+nlogn) using Fibonacci heap. Kruskal’s algorithm [12] also grows the MST at most
oneedgeat atime. Itpicks thesmallest edge ateach step andaddsitto MSTif itdoesnotcreate a
cycle in the MST constructed so far. This algorithm finishes in O(mlogn)time. Thereverse-delete
algorithm, a reverse of Kruskal’s algorithm [12], finishes in O(mlogn(loglogn)3) time. All these
algorithms are greedy. Later studies focused on improving runtime [5, 11].
In the parallel computing model, with O(n) processors, [2, 6, 19] show that MST can be com-
puted in O(logn) time. In the message-passing model, the GHS algorithm [8] constructs MST in
∗
O(nlogn) time. Time was improved to O(n) in [1] and to O(√nlog n+D) in [9, 16], where D is
the diameter of G. Furthermore, a time lower bound of Ω(√n/logn+D) was given in [18].
Paper Organization. We discuss preliminaries in Section 2 with some immediate lower bounds.
We establish our general simulation result (Theorem 1) in Section 3. We then discuss our approach
to disperse n agents to n graph nodes as well as elect an agent at a node as a leader in Section 4
(Theorem 2) and our MST construction algorithm proving our main contribution (Theorem 3) in
Section 5. Finally, we conclude in Section 6 with a short discussion.
2 Model and Preliminaries
Graph. We consider an anonymous, connected, undirected, port-labeled weighted graph G =
(V,E,w) with V = n and E = m, where V is the set of nodes, E is the set of edges, and w
| | | |
is the weights corresponding to each edge e E. Each node v V has δ ports corresponding
i i i
∈ ∈
to each edge incident to it labeled in [1,...,δ ]. We assume that the weights are (i) positive, i.e.,
i
w(e ) > 0, e E, and (ii) distinct meaning that for two edges e ,e , w(e ) = w(e )2.
i i i j i j
∀ ∈ 6
Agents. The set = r ,r ,...,r of n agents are initially located on the nodes of G. No agent
1 2 n
R { }
can reside on the edges of G, but one or more agents can occupy the same node of G, which we
call co-located agents. The agents take their IDs from the interval [1,nO(1)]. An agent can move
from node v to node u along the edge e . Following the message-passing literature, e.g. [9], we
vu
assume that an agent can traverse an edge in a round, irrespective of its (edge) weight. An agent
that moves from v along the port p is aware of port p when it arrives at u. Additionally, at
vu uv
any node v, it is aware of the weight w(e) of the edge e that connects v to its neighbor u. We
vu
assume that there is no correlation between two port numbers of an edge. Any number of agents
are allowed to move along an edge at any time, that is our model is not congest in terms of how
many agents can traverse an edge at a time. Two agents r ,r can exchange information iff they
i j
are co-located, i.e., they do not have message send/receive capability when they not co-located.
2
This requirement can be removed if thereis a consistent way of breakingties.
6Time Cycle. An active agent r performs the “Communicate-Compute-Move” (CCM) cycle as
i
follows. (i) Communicate: Let r be on node v . For each agent r that is co-located at v ,
i i j i
∈ R
r can observe the memory of r , including its own memory; (ii) Compute: r may perform an
i j i
arbitrary computation using the information observed during the “communicate” portion of that
cycle. This includes determination of a (possibly) port to use to exit v , the information to carry
i
while exiting, and the information to store in the agent(s) r that stays at v ; (iii) Move: r writes
j i i
new information (if any) in the memory of an agent r at v , and exits v using the computed port
j i i
to reach to a neighbor node of v .
i
Agent Activation, Time, and Memory Complexity. In the synchronous setting, every agent
is active in every CCM cycle. Therefore, time is measured in rounds. Memory is measured as the
number of bits stored in persistent memory at each agent.
2.1 Some Lower Bounds
These immediate time and memory lower bounds for constructing MST in the agent model show
the difficulty in obtaining fast time and low memory algorithms. Suppose n agents are positioned
on the nodes of an arbitrary graph G. To construct an MST, n agents need to be dispersed to
n nodes of G. There is a time lower bound of Ω(n) for dispersion. Additionally, since the agent
model is more restrictive compared to the message-passing model, the time lower bound for MST
in the message-passing model [18] directly extends. Therefore, we have the following theorem.
Theorem 4 (Time lower bound). Any algorithm for MST takes Ω(max √n/logn + D,n )
{ }
rounds in the agent model, where D is the diameter of G.
We have the lower boundof Ω(logn)bits at each agent for any deterministic algorithm for MST
in the agent model. The proof is immediate since, from the agent model, n agents must have a
unique ID in the range [1,nO(1)] and we count this memory space for the ID which must survive
across rounds as the space complexity.
Theorem5(Memory lowerbound). Anydeterministic algorithm forMSTonann-nodeanony-
mous G using n agents requires Ω(logn) bits at each agent.
3 Simulating Message-Passing Algorithm in the Agent Model
In this section, we prove Theorem 1 which establishes a time bound of a solution to a problem
in the agent model simulating a deterministic solution to that problem from the message-passing
model. Before we do that, we prove Lemma 6 which is crucial in the proof of Theorem 1.
Lemma 6. Given a dispersion configuration of n agents on a n-node graph G and n and ∆ are
known to the agents, an agent at a node takes at most O(∆logn) rounds to meet all its neighbors.
Proof. Sincen is known and the agent IDs are in the range [1,nO(1)], each agent IDcan beencoded
by c logn = O(logn) bits, for some constant c. If the length of agent ID x < c logn bits, then all
· ·
the c logn xbits precedingthe most significant bit (MSB) are filled with bit 0. Additionally, pad
· −
the least significant bit (LSB) of each agent ID with the bit 1. Each agent r at node v then runs a
v
neighbor probe procedure, knowing ∆, as follows. Start from MSB and end at the padded bit one
by one at the interval of 2∆ rounds. Agent r stays at v for 2∆ rounds when the bit accessed is 0,
v
otherwise (i.e., bit accessed is 1) r visits all the neighbors of v one by one. We know that r can
v v
visit all its neighbors in 2∆ rounds since visiting a neighbor needs 2 rounds. Notice that visiting
7all neighbors does not necessarily mean it visits all the agents positioned on them since they might
again be doing the neighbor probe.
Recall that each agent has a unique ID, therefore, the IDs of two agents r ,r possess at least
v u
one-bit difference in their IDs. This bit difference ensures two neighbors meet each other when
their ID bits differ. Since IDs of all the agents are of length O(logn) bits, the IDs of each of the
neighbors must differ by at least a bit when r visits all its neighbors for O(logn) time. Therefore,
v
each agent meets all of its neighbors in O(∆logn) rounds.
Proof of Theorem 1:
Proof. To simulate an algorithm in the message-passing model to the agent model, n agents need
to disperse to n nodes of G, if they were not already dispersed. The known time complexity of
achieving dispersion configuration, starting from any initial general configuration, is O(nlog2n)
rounds due to Sudo et al. [20]. The algorithm of Sudo et al. [20] is non-terminating meaning
that each agent may not know when the dispersion configuration is achieved since n is not known.
Additionally, if ∆ is not known, a agent may not be able to be co-located with its neighbor agent
to deliver a message. Therefore, knowing n would help to transition from the dispersion procedure
to algorithm simulation procedure. Knowing ∆ would help to prove Lemma 6 which is essential
for the simulation.
Consider memory at each agent the same as it has been used at a node in the message-passing
model, so that, for the received message at the node or agent, both models can perform the
requiredcomputation. We would like to showthat, after O(∆logn)rounds,the agents in theagent
model have the same information as in the nodes in the message-passing model after executing any
deterministic algorithm for a round. The proof is as follows. In any single round of the message-
A
passing model, a node passes the message/information to its all (or fewer) neighbors. To perform
the same operation in the agent model, it is essential that an agent meets all its neighbors and
passes the message based on the algorithm. Since each agent meets all its neighbors in O(∆logn)
roundsas shown inLemma6, aroundin themessage-passing modelcan besimulated inO(∆logn)
roundsin theagent model. Thus,thetotal roundsrequiredto simulate adeterministic algorithm
A
that runs for O(T) rounds in the message passing model is O(∆T logn) rounds in the agent model.
Combiningthetimeboundsfordispersionandthealgorithmsimulation, wehavetheclaimedbound
of O(∆T logn+nlog2n) rounds.
As a corollary, we obtain an algorithm solving MST in the agent model plugging in in Theorem
∗
1 the MST result of [9, 16] (the GKP algorithm) that takes T = O(√nlog n+D) rounds.
Corollary 7. There is a deterministic algorithm for MST in the agent model that takes
O(max ∆√nlognlog∗ n,∆Dlogn,nlog2n ) rounds, when n and ∆ are known to agents a pri-
{ }
ori and memory at each agent is as much as node memory in the message-passing model.
4 Dispersion with Leader Election
In this section, we present our dispersion with election algorithm which, starting from any initial
configuration(dispersed,rooted,orgeneral)ofnagentsinann-nodegraphG,ensuresthefollowing:
• If agents are not initially dispersed, they disperse so that n agents are on n nodes of G.
• One agent among the n agents is elected as a (global) leader.
8Algorithm 1: Leader Election Pseudocode for Agent r
u
Input: A set R of n agents with uniqueIDspositioned initially arbitrarily on thenodes of an n-node,
m-edgeanonymous graph G.
Ensure: An agent in R is elected as a leader with status leader.
States: Initially, each agent r u positioned at node u has r u.status←candidate,r u.init alone←true if
alone at u, r u.init alone←false otherwise, and r u.all edges visited←false. The init alone
variable is neverupdatedfor r u throughout thealgorithm butthe statusvariable can takevalues
∈{non candidate,local leader,leader}and theall edges visited variable can takevalue true.
1 if r u.status=candidate then
2 if r u.init alone=Truethen
3 Singleton Election(r u)
4 if r u.init alone=false then
5 if r u is the minimum ID agent at uthen
6 Dispersion With Election(r u)
7 if r u.status=local leader then
8 if r u became local leader through Dispersion With Election(r u) then
9 Ask theparent node, say w, in the DFS treebuilt while runningDispersion With Election(r u) to
keep theinformation that nodeu is the home nodeof thelocal leader r u.
10 if r u became local leader through Singleton Election(r u) then
11 Inform all neighbors that r u is a local leader.
12 Ask theport-1neighbor, say w, to keep the information that node uis thehome node of thelocal
leader r u.
13 Leader Election(r u)
14 if r u is at the home (or root) node from where Leader Election(r u) started with
r u.all edges visited=true then
15 r u.status←leader
Algorithm 2: Singleton Election(r )
u
1 δ u ← degree of node u.
2 N(r u)← neighbors of agent r u.
3 r u visitsneighbors in N(r u) (in orderof increasing port numbers)onebyone startingfrom and endingat u
4 whiler u.status==candidate do
5 if ∃ neighbor v,δ u >δ v or at least a neighbor agent found belongs to Dispersion With Election() or has
status local leader or ( ∃ neighbor v, δ u =δ v such that r v.ID>r u.ID) then
6 r u.status←non candidate
7 else if ∃ neighbor v, δ u =δ v and v is empty then
8 Neighbor Exploration with Padding(r u)
9 else if ∀ neighbor v, δ v >δ u but ∃ (at least) a neighbor v′ which is empty then
10 r u visits theempty neighbors in theintervalof 2δ v′ rounds starting from and ending at u.
11 if a robot r v′ is found at v′ and r v′ belongs to Dispersion With Election() or has status local leader
then
12 r u.status←non candidate
13 if ∀ neighbor v,δ u <δ v and all neighboring agent were initially singleton and no neighbor has status
local leader and ( ∀ neighbor v, if δ u =δ v then r v.ID<r u.ID) then
14 r u.status←local leader
We start with discussion on the high-level overview of the algorithm, then specific details, and
finally the correctness and complexity proofs on the algorithm guarantees.
9Algorithm 3: Neighbor Exploration with Padding()
1 b← numberof bits in the IDof r u
2 b+2b2 ← numberof bitsin theID of r u after padding a sequenceof ‘10’ bitsb2 times to theLSBin the
original b-bit ID.
3 Starting from MSB and endingon LSB, if the bit is ’1’ visit theN(r u) one by one which finishesin 2δ u
rounds. If bit is ’0’ stay at u for 2δ u rounds.
4 r u explores N(r u) based on padding for 2δ u(b+2b2) rounds
5 if r u meets an agent r v running Algorithm 4 (Dispersion With Election) or Algorithm 6
(Leader Election) or ( ∃ neighbor v, δ u =δ v such that r v.ID>r u.ID) then
6 r u.status←non candidate.
7 if ∃ neighbor v, δ u =δ v and v is empty then
8 r u.status←non candidate.
Algorithm 4: Dispersion With Election(r )
u
1 Run DepthFirst Search (DFS) traversal in forward and backtrack phases. The DFS has ID r u and can be
denoted as DFS(r u). The agents initially co-located with r u movewith r u as a group. In each empty
node, say v, visited, DFS(r u) waits for a round. Ifv is still empty after the(waited) round,DFS(r u)
runstheConfirm Empty()procedure (Algorithm 5) to verify v is in fact empty. If the
Confirm Empty()procedureverifies v empty,DFS(r u) asks the largest ID agent, say r v, in its group to
stayat v settingr v.status←non candidate. DFS(r u) runsuntilr u reachestoa confirmedemptynodew
alone where it can change its status from candidate to local leader setting r u.status←local leader (the
nodew becomes the home nodefor local leader r u). If thehead of DFS(r x) meets thehead of DFS(r y)
at a node w, then thehighest ID agent in thegroup belonging toDFS(r x) staysat w (and becomes
non candidate) if r x >r y, otherwise thehighest ID agent in thegroup belonging to DFS(r y) stays at w
(and becomes non candidate). Both DFS(r x) and DFS(r y) continuetheirtraversal untiltheir respective
headsbecome singleton at empty nodes and theheads elected as local leaders.
2 Remark: There might be a situation in which when Dispersion With Election() finishes for an agent r w
at a node w, the parent node w′ of w in the DFS tree built by r w may be empty (this is because the parent
node happened to be a home node of a local leader r w′ that is currently running Leader Election). In this
case, r w returns to w′ from w and waits there until r w′ returns to w′ . Once r w meets r w′ (at w′ ), r w′
becomes “non-candidate” and stays at w′. r w goes to node w from w′ and becomes a local leader if it finds
no waiting robot at w. If there is a waiting robot at w, r w becomes a ”non-candidate” and the waiting robot
leaves w. This process continues until an waiting robot can become a local leader with the parent node in its
DFS tree non-empty.
Algorithm 5: Confirm Empty()
1 This procedure is to verify whetherthe emptynode, say x,encountered by procedure
Dispersion With Election() (Algorithm 4) or Leader Election() (Algorithm 6) is in fact empty,is the
home nodeof a local leader, or a possible homenode of an agent waiting to become a local leader (see
Line2 of Algorithm 4). This is done as follows. The agent runningthis procedureat an empty nodex
visits theneighbors N(x) of x and collects information on whetherone of the neighbors has the
information that x is the (home) node of a (possible) local leader. Ifno neighbor has theinformation that
x is a (possible) homenode, it is verified that x is empty,otherwise, it is a (possible) homenode.
2 Remark: There may be the case that procedure (Dispersion With Election() or Leader Election()) from
a different agent may reach x while one agent is running this procedure at x. These procedures may simply
wait at x for the ongoing Confirm Empty() procedure to finish.
10Algorithm 6: Leader Election(r )
u
1 Run DFS traversal in forward and backtrack phases as in Dispersion With Election(r u) (Algorithm 4).
TheDFS hasID as a tuple(roundNo u,r u) and it can bedenoted as DFS(roundNo u,r u), where
roundNo u denotes theround at which thisDFS has started. DFS(roundNo u,r u) starts at the home
nodeof r u where it becomes a local leader and ends at the home node(thehome node is also theroot
nodeof DFS(roundNo u,r u)). The goal of DFS(roundNo u,r u) is to see whether it can visit each and
everyedge of G. DFS(roundNo u,r u) keepsa boolean variable alledgevisitedinitially set to False. As
soon as no edge is left to bevisited, allegdgevisitedbecomes Trueand if r u is not on thehome (or root)
nodefrom where DFS(roundNo u,r u) started, it comes back tothat node following theparent pointers.
2 While runningDFS(roundNo u,r u), if r u reaches a node in which it meets an agent running
Dispersion With Election(), DFS(roundNo u,r u) continues. However, if DFS(roundNo u,r u) meets
anotherDFS(roundNo v,r v) at a nodew (not necessarily the head of DFS(roundNo v,r v)),
DFS(roundNo u,r u) continuesif and only if either (i) roundNo u >roundNo v or (ii)
roundNo u =roundNo v but r u >r v, otherwise DFS(roundNo u,r u) stops and DFS(roundNo v,r v)
continues. If DFS(roundNo u,r u) stops, then agent r u follows its parent pointers to reach its its home
(root) node.
3 While runningDFS(roundNo u,r u), Ifr u reaches an empty node, it waits at that node for a round,and if
thenode is still empty after the (waited round),runsprocedure Confirm Empty()as in
Dispersion With Election(r u) (Algorithm 4) to verify whethertheempty node is a home node(of a local
leader). If so, DFS(roundNo u,r u) continues, otherwise DFS(roundNo u,r u) stops and r u returnsto its
home node.
4.1 High-Level Overview of the Algorithm
Initially, a node may have zero, one, or multiple agents. All these agents are “candidates” to
become leader. A candidate needs to first become a “local leader” before becoming a “leader”.
Each candidate that cannot become a “local leader” (also each “local leader” that cannot become
a “leader”) will become a “non candidate”. Lines 2-6 of Algorithm 1 (Leader Election Procedure)
show what procedure an agent runs to contend to become a local leader.
As depicted in Lines 2-3 of Algorithm 1, if an agent is initially alone at a node, then it runs
Algorithm 2 (Singleton Election) to compete to become a local leader. As depicted in Lines 4-6
of Algorithm 1, if an agent is not alone initially and the minimum ID among the co-located, then it
runs Algorithm 4 (Dispersion With Election) to become a local leader. If an agent is successful
in becoming a local leader through either of Algorithm 2 or Algorithm 4, it contends to become a
(global) leader running Algorithm 6 (Leader Election). Algorithm 6 by an agent essentially tries
to verify whether it will be able to traverse all the edges of G. If it is successful in traversing all
the edges, then it declares itself as a leader and we prove that there will be one and only one agent
which will be able to do so, giving us a unique (global) leader.
An agent r runningAlgorithm 2 (Singleton Election) at a nodeu will besuccessful in becom-
u
ing a local leader if and only if all u’s neighbors have initially a single agent positioned on them
and u has the smallest degree compared to the neighboring nodes. Each initially singleton agent
r at node u running Singleton Election visits the neighbors of u one by one which finishes in 2δ
u u
rounds, where δ is the degree of u. If a subsequent visit is needed, then it will take again 2δ
u u
rounds. If not all neighbors have initially singleton agents positioned, the agent gets to know it
cannot become a local leader while running Algorithm 2 (Singleton Election). It then stops the
algorithm and becomes “non candidate”.
An agent r initially at node u running Algorithm 4 (Dispersion With Election) will be suc-
u
cessfulinbecomingalocalleaderifandonlyifithasthesmallestIDamongtheonespositionedwith
it initially at u. As soon as the smallest ID agent becomes a singleton at node w, it declares itself
as a local leader if the parent node in its DFS tree built while running Dispersion With Election
11is non-empty (see Line 2 - Remark in Algorithm 4). If such parent is empty, it waits at that parent
until that local leader is met to decide on whether to become a local leader or a non-candidate.
Algorithm 4 (Dispersion With Election) for an initially non-singleton agent r with α co-located
u
agents is a Depth First Search (DFS) traversal with the goal to visit α 1 other empty nodes
−
of G on which α 1 robots can stay and r becomes a local leader. All other agents initially
u
−
co-located with r at node u stay one by one on the empty nodes of G visited by Algorithm 4
u
(Dispersion With Election) and become “non candidate”.
To make sure that Dispersion With Election meets Singleton Election (if it is running),
Dispersion With Election waits at a node for a round so that if it does not meet agent doing
Singleton Election at the current round, it finds that out in the next round. Singleton Election
stops and the agent becomes non candidate when it knows about Dispersion With Election.
After becoming a local leader (irrespective of whether through procedure Singleton Election
or Dispersion With Election), the local leader agent initiates Algorithm 6 (Leader Election) to
becomeaunique(global)leader. Algorithm 6(Leader Election)isaDFStraversalasinAlgorithm
4 (Dispersion With Election) with the goal to visit all the edges of G. We denote by home node
the node of G on which an agent becomes a “local leader”. To make it easier for other local leaders
or Dispersion With Election to not mistakenly put an agent on the home node of a local leader
(when it is empty since the local leader has left its home node running Algorithm 6), the neighbor
nodes are asked to store the information abouta home node. The agents runningAlgorithms 4 and
6 check the neighbors to confirm whether the visited empty node is in fact a home node of a local
leader (or a node of an agent that is waiting at a parent node to possibly become a local leader, see
Line2ofAlgorithm4). TheconfirmationprocedureisdescribedinAlgorithm5(Confirm Empty).
Ifanemptynodeisahomenode(possiblehomenodeofanagent waitingtopossiblybecomealocal
leader), Algorithms 4 and 6 continue leaving that node empty as is. Otherwise, Algorithm 4 puts
an agent and continues and Algorithm 6 stops as it knows that Dispersion With Election from
at least one agent has not yet finished. This is because since there are n agents and n nodes in G,
no node of G should be empty except the home nodes if all Dispersion With Election procedures
started in the beginning to finish.
There may be the case that while running Algorithm 6, DFS(roundNo ,r ) of local leader r
i i i
may meet DFS(roundNo ,r ) of local leader r . In this case, DFS(roundNo ,r ) continues if
j j j i i
roundNo > roundNo (if same round number, use agent IDs), otherwise DFS(roundNo ,r ). If
i j j j
DFS(roundNo ,r )stops,thenr becomes“non candidate”andreturnstoitshomenodefollowing
j j j
parent pointers in DFS(roundNo ,r ).
j j
4.2 Detailed Description of the Algorithm
We discuss Singleton Election (Algorithm 2), Dispersion With Election (Algorithm 4), and
Leader Election (Algorithm 6) procedures, including how they synchronize even when they meet
the same or different procedure running concurrently by other agents (local leader or candidates)
to decide on when to proceed and when to stop.
Singleton Election (Algorithm 2). Thisprocedureis runby agents thatwereinitially singleton
on a node. They set status candidate and run the Singleton Election algorithm. The agent r at
u
node u visits the δ neighbors of u one by one starting from the minimum ID portto the maximum
u
ID port. Agent r finishes visiting all δ neighbors in 2δ rounds. If r finds there is a neighboring
u u u u
node v such that δ > δ , r becomes non candidate (Lines 5 and 6 of Algorithm 2). If r finds
u v u u
there is at least a neighboring agent settled through Dispersion With Election() or has status
local leader, r cannot become a local leader and hence it does not contend further to become a
u
12local leader, setting status non candidate (Lines 5 and 6 of Algorithm 2).
If all neighbors have an agent positioned that was initially singleton, then r becomes a local
u
leader if u has the smallest degree among the neighbors (Lines 13 and 14 of Algorithm 2). If there
is at least one same degree neighbor, u has to have a higher ID than that same degree neighbor to
become a local leader, otherwise r becomes non candidate (Lines 5 and 6 of Algorithm 2).
u
If not all neighbors have agent positioned and r does not have neighbour of higher degree
u
and does not find any agent belonging to Dispersion With Election or status local leader, then
r explores neighbors after 2δ rounds iff δ < δ , where v is a neighboring node. neighbor
u v u v
∀
v,δ > δ case simply demands visiting the neighbors after 2δ rounds. In 2δ rounds, if there was
v u v v
an agent r at v initially then r will become the non candidate agent after finding the δ < δ
v v u v
(Lines 9-11 of Algorithm 2). Otherwise, if there is no such agent, initially, then the robot at
node v would come from Dispersion With Election. This ensure that there exist a local leader,
therefore, r becomes non candidate with or without finding r after 2δ rounds. For δ = δ ,
u v v v u
we need a guarantee that r meets r if an initially singleton agent r is present at v. This is
u v v
a challenging situation in Algorithm 2 (Singleton Election) which is handled through Algorithm
3 (Neighbor Exploration with Padding) providing a guarantee that r meets r and vice-versa
u v
(Lines 7 and 8 of Algorithm 2).
Algorithm 3 (Neighbor Exploration with Padding) works as follows. Supposean agent r has
u
an ID of b bits; note that b c logn for some constant c > 1. We pad a sequence of ‘10’ bits b2
≤ ·
times to the LSB (least significant bit) of the r ’s ID, i.e.,
u
b 10 10 ... 10 .
|{1z}|{2z} |{ bz2}
Now the ID of b bits becomes the ID of b + 2b2 bits. This padding will be
helpful in making the same degree neighboring agents meet each other. Algorithm 3
(Neighbor Exploration with Padding) ran by agent r starts from its MSB (most significant bit)
u
and ends at LSB. If a bit is 1, then r explores all neighbors which finishes in 2δ rounds, however,
u u
when a bit is 0, it remains at its position for 2δ rounds. We will show that using this padding
u
approach the agents at the same degree neighbors meet each other in O(δ log2n) rounds, a crucial
u
component in Algorithm 2 (Singleton Election).
Dispersion With Election (Algorithm 4). This procedure is run by agents which were not
initiallysingleton. Letubeanodewherer ispositionedanditistheminimumIDagentamongthe
u
co-located (say, group-r ). r is responsible for running Dispersion With Election, others follow
u u
r . Dispersion With Election is essentially a DFS traversal procedure (denoted as DFS(r )) to
u u
visit the nodes of G in forward and backtrack phases [14]. At u, the largest ID agent in group-r
u
settles and it tracks parent and child pointers for the DFS(r ). Each node visited by DFS(r )
u u
may be occupied (has an agent positioned) or empty. If an agent is positioned on a newly visited
node, it writes ID and parent and child pointer information about DFS(r ) and continues. If an
u
empty node, it positions the largest ID agent in group-r and continues. At some point in time,
u
DFS(r ) reaches an empty node such that r is the only agent on it and the parent node of r in
u u u
DFS(r ) is non-empty. r elects itself as a local leader and Dispersion With Election is finished
u u
for r . If r finds the parent node of r in DFS(r ) is empty when becoming singleton, it waits
u u u u
to either become a local leader or non-candidate by going to the parent in DFS(r ) and waiting
u
there until it meets the agent which has this parent node as its home node (Line 2 of Algorithm 4).
While running DFS(r ), we call the node where r is currently positioned the head node of
u u
DFS(r ). DFS(r ) may meet DFS(r ) from another agent r . We differentiate two cases. If the
u u v v
meeting happensat anodew suchthat w is thehead nodeof bothDFS(r ) andDFS(r )and w is
u v
13an empty node, then an agent from DFS(r ) settles if r < r , otherwise an agent from DFS(r )
u u v v
settles at w. Both write their DFS information on the agent positioned on w and continue their
traversal. If w is a non-empty node, they both continue without settling any agent but just write
their DFS information at the agent positioned on w. However, if DFS(r ) meets DFS(r ) at a
u v
node w which is not a head node of DFS(r ) (w is a head node of DFS(r ) since DFS(r ) is
v u u
meeting DFS(r ) at w), then DFS(r ) simply continues writing its DFS information on the agent
v u
positioned at w.
To deal with the situation that DFS(r ) does not miss meeting an agent doing
u
Singleton Election, DFS(r ) waits at every node it visits for a round before exiting. This is
u
enough since an agent doing Singleton Election returns to its node every second round. If the
node is still empty after the (waited) round, it runs Confirm Empty() (Algorithm 5) to verify
whether it is a (possible) home node of a local leader (an agent waiting to become a local leader,
see Remark in Algorithm 4), or indeed an empty node.
Leader Election (Algorithm 6). This procedure is run by agents who become local leaders.
NoticethatanagentmaybecomealocalleaderrunningeitherAlgorithm2(Singleton Election)or
Algorithm 4 (Dispersion With Election). As soon as an agent becomes a local leader, it contends
tobecomeaunique(global)leader. Letr becomesalocalleaderatnodeu(wecalluthehomenode
u
of r ) at round roundNo . It then starts a DFS traversal denoted by tuple DFS(roundNo ,r ),
u u u u
the goal of which is to see whether it can visit all the edges of G and return to u, its home node.
If r can do so, it declares itself as a global leader. While running DFS(roundNo ,r ), it might
u u u
meet DFS(roundNo ,r ). DFS(roundNo ,r ) continues if its ID is lexicographically larger than
v v u u
DFS(roundNo ,r ), otherwise it stops and becomes a non candidate and returns to node u (its
v v
home node). Additionally, DFS(roundNo ,r ) might meet Dispersion With Election and if the
u u
meeting happens at the head node of Dispersion With Election, it stops, otherwise it continues.
Additionally, if DFS(roundNo ,r ) reaches a confirmed empty node (i.e., it is not a empty home
u u
node) then it also stops as it knows that Dispersion With Election from some other initially non-
singleton node is still going on since the node is still empty. This confirmation of empty nodebeing
empty home node or a confirmed empty node is done through Confirm Empty() (Algorithm 5).
4.3 Analysis of the Algorithm
We analyze Algorithm 1 for correctness and its complexity guarantees. We start with
Singleton Election (Algorithm 2).
Lemma 8. In Singleton Election (Algorithm 2) run by agent r at node u, if there is a neighboring
u
agent r positioned on the neighbor node v such that δ = δ and δ ,δ both being the minimum,
v u v u v
r meet r in O(δ log2n) rounds, running Neighbor Exploration with Padding (Algorithm 3).
u v u
Proof. Since agent IDs are from the interval [1,nO(1)], each agent has ID of size c logn for some
≤ ·
constant c. Therefore, for any two agents r ,r , two cases exist for the number of bits on their
u v
IDs: either equal or unequal. Consider the equal case first. If r and r have an equal number of
u v
bits (say, b) then their IDs must be different in at least one bit since IDs are unique, i.e., if one has
bit ’1’ at β-th place from MSB, another must have bit ’0’ at β-th place from MSB. Since an agent
explores neighbors while the bit is ’1’ and stays at its place when the bit is ’0’, r finds r within
u v
2 δ b rounds. Since the bit may be different at the b-th place from MSB, the total time taken
u
· ·
for r to meet r is O(δ logn) rounds.
u v u
Now consider the case of an unequal number of bits. Let r and r , respectively, have b and d
u v
bits in their IDs with b = d. W.l.o.g., b > d, i.e., b = d+c , where d,c 1. Therefore, the total
1 1
6 ≥
14number of bits after padding in the agent r ’s ID is b+2b2. We have that
u
b+2b2 = (d+c )+2(d+c )2 = 2d2+2c2+4 d c +d+c .
1 1 1 · · 1 1
Similarly, thetotal numberofbitsintheagentr after paddingis d+2d2. Therefore, after padding,
v
the difference in the number of bits of the IDs of r and r is
u v
2c2 +4 d c +c .
1 · · 1 1
Since d,c 1, the difference is at least 7 bits in the overall length of the IDs of r and r after
1 u v
≥
padding. Additionally, out of these 7 bits, at least 3 bits are ‘1’s duringwhich agent r can explore
u
the node v with r positioned at node v. What that means is, if r (the smaller ID than r ) stops
v v u
after δ (d+2d2) rounds, then there are at least 3 chances for r to meet r at its node v since r
v u v u
with bit ‘1’ will bevisiting its neighbors and r is at v not moving anymore since it finishedvisiting
v
its neighbors. Therefore, theroundcomplexity becomes O(δ (b+2b2)) = O(δ log2n)rounds,since
u u
b c logn.
≤ ·
Lemma 9. In Lemma 8, O(δ log2n)< O(m).
u
Proof. Noticethatδ = δ andδ istheminimumamongtheneighbordegreesofnodeu. Therefore,
u v u
it must be the case that there are at least δ (δ 1)/2 edges in G. We now relate this to m.
u u
−
We consider two cases and show that in both the cases O(δ log2n) <O(m).
u
• δ (δ 1)/2 O(δ log2n). This implies that δ O(log2n). Which means
u u u u
− ≤ ≤
δ (δ 1)/2 O(log4n)< O(n)< O(m).
u u
− ≤
• δ (δ 1)/2 > O(δ log2n). This implies that m δ (δ 1)/2 > O(δ log2n). Which means
u u u u u u
− ≥ −
O(m) > O(δ log2n).
u
Therefore, in Lemma 8, O(δ log2n)< O(m).
u
Lemma 10. An initially singleton agent r at node u running Singleton Election (Algorithm 2)
u
either becomes a local leader or a non-candidate within O(m) rounds.
Proof. We consider two cases: (A) all δ neighbors of node u where r is positioned have agents
u u
positioned initially, (B) at least 1 neighbor of u was initially empty.
We first consider Case A. We have two sub-cases: (A1) all δ neighbors have a singleton agent
u
initially, (A2) at least a neighbor has multiple agents initially. In Case A1, we prove that r either
u
becomes a local leader or non-candidate in O(δ ulog2n+max v∈N(ru)δ v) rounds. The proof is as
follows. If there is a neighbor node v, such that δ > δ , then r becomes a non-candidate in
u v u
′
2δ rounds. If u is the smallest degree node in N(r ) u and there is a node v N(r ) with
u u u
∪{ } ∈
δ u = δ v′ then either u becomes a local leader or a non-candidate in O(δ ulog2n) rounds (Lemma
′
8). If u is the smallest degree node in u N(r u) and there is no neighbor v with δ
u
= δ v′, then
{ }∪
to become a local leader, it needs to know that the largest degree neighbor, say v, in fact, has an
agent positioned. r gets to know there is an agent r at node v when r finishes visiting all its
u v v
neighbors which takes 2δ rounds. After that r becomes non-candidate (since it knows of u with
v v
δ < δ ) and stays at v. Therefore, combining the times for all the above cases, we have the time
u v
complexity for Case A1 O(δ ulog2n+max v∈N(ru)δ v) rounds.
15In Case A2, r gets to know the neighbor(s) with multiple agents is going to run
u
Dispersion With Election (Algorithm 4) and become a local leader. This information can be
collected by r within 2δ rounds since one agent at the multiplicity neighbor node does not move
u u
during Leader Election Pseudocode (Algorithm 1).
We now consider Case B. We have two sub-cases: (B1) all the neighbors that have agents
positioned are all singleton agents, (B2) at least one neighbor has multiple agents. In Case B1,
r
u
cannot become a local leader in O(δ ulog2n + max v∈N(ru)δ v) rounds if it does not meet any
agent at (at least) a neighbor in those O(δ ulog2n + max v∈N(ru)δ v) rounds. r
u
remains at u as
a candidate until it gets to know of Dispersion With Election or Leader Election and when it
knows of one such procedure, it becomes a non-candidate. Since Dispersion With Election and
Leader Election finish in O(m) time, r becomes a non-candidate in O(m) rounds (Lemmas 12
u
and 17). However, if it meets an agent within O(δ log2n+max δ ) rounds, then that must
u v∈N(ru) v
be from Dispersion With Election since a neighbor was initially empty, and hence r becomes
u
non-candidate in O(δ log2n+max δ ) rounds. In Case B2, r knows it cannot become a
u v∈N(ru) v u
local leader in 2δ round as in Case A2. Therefore, the total time for both cases A and B is O(m)
u
rounds.
Forthedispersedinitialconfigurations,weprovebelowthatatleastoneagentatanode(despite
being singleton initially) becomes a local leader.
Lemma 11. Starting from a dispersed initialconfiguration, at least one agent becomes alocal leader
running Algorithm 2 (Singleton Election).
Proof. LetnodeubethesmallestdegreenodeinG,i.e., δ
u
= min v∈Gδ v. Wehavetwocases: (i)uis
′
theuniquesmallest degreenodeinG, i.e., thereisnoother nodev suchthatδ u =δ v′ (ii)thereisat
′
least a node v G with δ v′ = δ u. We first consider Case (i). Since u is the unique smallest degree
∈
node, r
u
meets all its neighbors in O(δ ulog2n+max v∈N(ru)δ v) rounds (Case A1 in Lemma 10).
Sinceeach neighborofuisofahigherdegreethanu,theyallbecomenon-candidateandr becomes
u
′
a local leader. Now consider Case (ii). We have two sub-cases: (ii.A) u and v are neighbors (ii.B)
′
u and v are not neighbors. In Case (ii.B) r is elected as a local leader as discussed in Case (i).
u
For Case (ii.A), we have from Lemma 8 that r u meets r v′ in O(δ ulog2n) rounds. After that, either
r u or r v′ becomes a non-candidate. If r v′ becomes non-candidate, r u becomes a local leader and we
′′
are done. Otherwise, if r v′ becomes a non-candidate, then it has a neighbor v with δ v′′ = δ v′ = δ u
and r v′′ remains as a candidate to become a local leader. This chain stops at the first node v with
′′′ ∗
the same degree neighbor v such that r v′′′.ID < r v∗.ID > ... > r v′′.ID > r v′.ID > r u.ID and v
∗
becomes a local leader.
We now consider rooted and general initial configurations.
Lemma 12. Dispersion With Election (Algorithm 4) run by an initially non-singleton agent r
u
of minimum ID among the x > 1 co-located agents finishes positioning those co-located agents on
x different nodes of G in O(m) rounds with O(nlogn) bits memory per agent.
Proof. Consider the case of x = n, i.e., there is a single node of G on which all n agent
were co-located initially (rooted initial configuration). Since there is no singleton agent initially,
Singleton Election does not run. We have from Kshemkalyani et al. [14] that the DFS traversal
DFS(r ) run by the minimum ID agent finishes dispersing agents to n nodes (one agent per node)
u
in min(4m 2n+2,4n∆) = 4m 2n+2 = O(m) rounds using O(log(n+∆))= O(logn) bits per
− −
agent, since m n∆ and ∆ n. Now consider the case of ℓ DFSs ran by ℓ minimum ID agents
≤ ≤
from ℓ non-singleton nodes of G with multiple agents positioned. Notice that ℓ n/2. We have
≤
two situations:
16(i) there is no singleton node initially, i.e. n agents are on ℓ non-singleton nodes
(ii) there is at least a singleton node, i.e., n agents are on ℓ non-singleton nodes and at least one
singleton node.
Consider the first situation. Since there is no singleton node initially, Singleton Election does not
run and hence the synchronization is only between Dispersion With Election procedures. A DFS
with x initially co-located agents need to visit x 1 other empty nodes to settle all its co-located
−
agents. When an empty node is visited by a single DFS, then an agent from it settles. If an empty
node is visited by the heads of two or more DFSs, an agent from one DFS settles. Therefore, since
there are ℓ DFSs with n ℓ empty nodes and n ℓ agents to find the empty nodes to settle and in
− −
each empty node visited by one or more DFSs an agent settles, a DFS may need to traverse all the
edges of G to be able to settle all its agents at empty nodes. We know that traversing all the edges
ofGfinishesin4m 2n+2roundssinceeach DFS continues untilitsettles allitsagents. Regarding
−
memory, since each DFS continues until it is able to settle all its agents, an agent positioned at a
node may need to store the information about all the ℓ DFSs. Since ℓ n/2 and for a DFS a node
≤
needs to store O(logn) bits, the total memory needed at an agent is O(nlogn) bits.
Now consider the second situation, i.e., there is at least an agent that runs Singleton Election.
If a DFS visits an empty node, say u, then it has to confirm whether:
(i) it is in fact an empty node,
(ii) a node of agent running Singleton Election,
(iii) a home node of an agent running Leader Election after becoming a local leader through
Singleton Election, or
(iv) a home node of agent running Leader Election after becoming a local leader through
Dispersion With Election.
In the first case, the waiting for a round results u to be empty. The DFS then runs procedure
Confirm Empty() (Algorithm 5) which confirms it to be indeed an empty node. The second case
is confirmed since DFS waits at a node for a round and an agent running Singleton Election
returns to its node every two rounds. For the third case, the head of DFS needs to visit the
port-1 neighbor of u to find out whether it is a home node of the local leader. The fourth case
demands the head of DFS to visit all the neighbors of that node. Therefore, for each empty node u
reached, this confirmation needs at most 2δ +1 rounds, 2δ rounds to visit all neighbors running
u u
Confirm Empty()(Algorithm5),and1roundwaitatubyDFSbeforerunningConfirm Empty()
(Algorithm 5). After a home node (which is empty) is confirmed then that agent running DFS can
store this information for future use. That is, if the agent running the DFS visits u again and finds
it to be empty, it can simply use the stored information to decide whether it is a home node. Since
there are n nodes, total O(nlogn) bits is enough for an agent runningDFS to store this home node
information for future use. Therefore, Dispersion With Election has the additional overhead of
n
at most O(cid:0)P i=1δ i(cid:1)= O(m) due to Confirm Empty (Algorithm 5).
Combining the above costs, Dispersion With Election (Algorithm 4) for each initially non-
singleton agent r finishes in O(m) rounds with memory per agent O(nlogn) bits.
u
Lemma 13. Suppose there were ℓ 1 multiplicity nodes in the initial configuration.
≥
• If ℓ = 1, an initially non-singleton agent r of minimum ID becomes a local leader running
u
Algorithm 4 (Dispersion With Election).
17• If ℓ 2, at least 2 initially non-singleton agents of minimum ID among the x > 1 co-
≥
located agents in their multiplicity respective nodes become local leaders running Algorithm 4
(Dispersion With Election).
Proof. Consider first the case of ℓ = 1. There is a single procedure Dispersion With Election
(Algorithm 4)running. WhenDispersion With Election (Algorithm 4)finishes,let w bethenode
on which the initially non-singleton agent r of minimum ID is positioned. Let T be the DFS tree
u u
′
builtduringDispersion With Election (Algorithm 4). Let w bethe parent nodeof w in T . Note
u
′
that w has the initially non-singleton agent of second minimum ID r w′ is positioned. Therefore,
′
r u can become a local leader writing its home node information at the agent r w′ positioned at w .
Consider now the case of ℓ 2. There will be ℓ instances of Dispersion With Election (Algo-
≥
rithm4)runningpossiblyconcurrently. WhenaDispersion With Election(Algorithm4)instance
′
finishes, let w be the node on which it finishes. Notice that, the initially non-singleton agent r of
minimum ID from that finished instance is positioned on w. Let T r′ be the DFS tree built by agent
′ ′ ′
r while running Dispersion With Election. Let w be the parent node of w in T r′. If w is non-
′′
empty, r can become a local leader writing its home node information at the agent r positioned
u
′
at w . Therefore, if non-empty parent condition in T r′ satisfies for each Dispersion With Election
(Algorithm 4) instance, there will be ℓ local leaders.
′
Suppose non-empty parent condition in T r′ does not satisfy for r. For this to happen, another
′′
instance of Dispersion With Election by some agent r must have previously finished on the
′ ′ ′′ ′ ′ ′
parent node w of r in T r′. and r must have become a local leader at w . For r to find w empty,
′′ ′ ′
r must have now running Leader Election (Algorithm 6). Since w is empty, r cannot write its
′
home node information at w and hence cannot immediately become a local leader.
′ ′ ′′ ′
The agent r now comes to w and waits until r returns to w . During the wait, no other agent
′′′ ′′′ ′
r occupies node w, since when r runs Confirm Empty(), it finds that r which was supposed
′ ′ ′′′
to be at w is waiting at the parent node w of T . r then tries to position itself at a neighbor,
′′ ′′ ′′′ ′
say w , of w. If w is empty, then the parent node in T is w which is empty (since r is waiting
′
at w). This process forms a chain of nodes (i.e., each node in the chain being the parent in the
DFS tree of an agent) such that the first node in the chain is the home node of a local leader and
all other nodes in the chain are the home nodes of the agents waiting (on the predecessor nodes
′
in the chain) to become local leaders. After the local leader returns to w , the waiting agents in
′ ′
the chain go back to their nodes (traversing the child pointers), i.e., r waiting at w goes to w,
′′′ ′′
r waiting at w goes to w , and so on. When a waiting agent r goes to its home node h and
1 1
finds a waiting agent r positioned at h , then r knows that r must have started waiting later in
2 1 1 2
time compared to r . Therefore, r becomes a non-candidate and stays at h . r goes to its home
1 1 1 2
node, say h , and finds an agent r waiting, then r becomes a non-candidate and stays at h , and
2 3 2 2
the process repeats. Otherwise, r knows that it is the last waiting agent in the chain. r becomes
2 2
a local leader at h and writes the home node information at agent r at node h , which is the
2 1 1
parent node in the DFS tree of r . Therefore, at least two initially non-singleton agents become
2
local leaders during Dispersion With Election (Algorithm 4).
Lemma 14. In Lemma 13, each initially non-singleton agent r running
u
Dispersion With Election (Algorithm 4) either becomes a local leader or a non-candidate
within O(m) rounds.
Proof. We have from Lemma 12, agents disperse in O(m) rounds. Therefore, for ℓ = 1 in Lemma
13, an initially non-singleton agent of minimum ID r in the single multiplicity node becomes a
u
local leader in O(m) rounds. For ℓ 2, if non-empty parent condition is satisfied for each of ℓ
≥
initially non-singleton agents of minimum ID in their respective multiplicity nodes, then they all
18become local leaders in O(m) rounds because they do not wait. If non-empty parent condition is
not satisfied, then for each chain of waiting agents, one agent in the parent node in the DFS tree of
the first waiting agent in the chain becomes a local leader in O(m) rounds since it does not wait.
That local leader in the chain running Leader Election (Algorithm 6) must return to its home
node in next O(m) rounds, since it runs a DFS traversal which must finish in O(m) rounds [13].
′
After that if the chain is of length ℓ ℓ then the last waiting agent in the chain reaches its nodein
′ ≤
O(ℓ)roundsandbecomesalocal leader. Otherwaiting robotsinthechainbecomenon-candidates.
′ ′
Since ℓ < ℓ n/2, we have total time O(m+ℓ)= O(m) rounds.
≤
Lemma 15. Consider a currently empty home node u of a local leader agent r running
u
Leader Election (Algorithm 6).
• If r became a local leader through Singleton Election (Algorithm 2), node u will not be
u
occupied by an agent other than r .
u
• If r became a local leader through Dispersion With Election (Algorithm 4), node u may be
u
occupied for a short period by an agent waiting to become a local leader at the neighbor of u
until r returns to u.
u
Proof. We prove prove the first case. Notice that when an agent becomes a local leader at node u
through from Singleton Election (Algorithm 2), then all the neighbors must have an initially non-
singletonagentpositioned. Therefore,whenr becomesalocalleaderatufromSingleton Election
u
(Algorithm 2), then the information that u is a home node is written in port-1 neighbor of u by
r before it initiates Leader Election (Algorithm 6) as that port-1 neighbor is non-empty and not
u
moving. For an agent to settle at u when it finds empty, it has to confirm that it is in fact empty,
i.e., not a home node of another agent. When the agent runs Confirm Empty (Algorithm 5), it
finds that u is in fact a home node. Therefore, no other agent occupies u, the home node of local
leader agent r .
u
We now prove the second case. Notice that when an agent r becomes a local leader at node
u
u through from Dispersion With Election (Algorithm 4), there is no guarantee that all neighbors
of u have agents positioned except the parent node in the DFS tree of r at u. When an agent
u
′′
r finishes its Dispersion With Election (Algorithm 4) instance at the empty-neighbor, say w ,
∗
of u, then r finds that u (the parent node in its DFS tree) empty and has to wait to become
∗
a local leader or non-candidate. r waits at u until r running Leader Election (Algorithm 6)
u
∗ ′′
returns to u. After that r leaves u and enters w at which it becomes either a local leader or
∗
non-candidate.
Lemma 16. Consider a local leader agent r running Leader Election (Algorithm 6). As soon as
u
r realizes it cannot become a (global) leader, it can return to its home node u.
u
Proof. Recall that r runs a DFS traversal DFS(roundNo ,r ) during Leader Election (Algo-
u u u
rithm 6). DFS(roundNo ,r ) builds a DFS tree T with its root node the home node u of r .
u u u
In T, there is a sequence of parent pointers from the current node position (which is the head of
DFS(roundNo ,r )) of r to the root node of T. Since every local leader runs its separate DFS
u u u
traversal and maintains the tree information in each node its DFS visits, r can follow the parent
u
pointers in T until reaching the root node, which is its home node.
Lemma 17. Leader Election (Algorithm 6) elects a unique (global) leader and terminates in O(m)
rounds with O(nlogn) bits at each agent.
19Proof. An agent that is not a local leader does not run Leader Election (Algorithm 6). We
have from Lemmas 11 and 13 that at least one agent becomes a local leader starting from any
initial configuration. Consider an agent r that becomes a local leader at roundNo . It ini-
u u
tiates DFS(roundNo ,r ) at roundNo . Suppose it visits an empty node w at some round
u u u
t > roundNo . We have fromtheproofof Lemma12thatitcan beconfirmedin O(δ )roundsthat
u w
whether w is in fact empty or a home noderunningConfirm Empty (Algorithm 5). If it is empty,
there must be at least one Dispersion With Election still running and an agent will become a
′
local leader in some round t > t, and hence DFS(roundNo ,r ) stops. If DFS(roundNo ,r )
u u u u
does not visit any empty node, then it must visit another DFS(roundNo ,r ). We have that
v v
either DFS(roundNo ,r ) stops or DFS(roundNo ,r ) stops due to this meet but not both.
u u v v
Since the IDs are unique, there is always one and only one DFS(roundNo ,r ) run by local
w w
leader w that wins all the competitions on the DFSs. Therefore, we have a unique leader. Since
Confirm Empty (Algorithm 5) needs to be run for n different nodes at most once with total
n
overhead of O(cid:0)P i=1δ i(cid:1) = O(m) rounds and each DFS takes O(m) rounds, the total time to finish
Leader Election(Algorithm6)afterDispersion With ElectionisO(m)rounds. Tostoreinforma-
tion about Leader Election run by all local leaders, O(nlogn) bits at each agent is sufficient.
We are now ready to prove Theorem 2, the main result of this section.
Proof of Theorem 2:
Proof. The rooted initial configuration is easy since only one Dispersion With Election (Algo-
rithm 4) instance runs until n agents disperse to n nodes and the minimum ID agent running
Dispersion With Election becomes a local leader. It then runs Leader Election (Algorithm 6)
and becomes a global leader. The total time will be O(m) rounds (Lemmas 12 and 17).
In the dispersed initial configuration, only Singleton Election (Algorithm 2) runs. The agents
either become local leaders or non-candidates in O(m) rounds (Lemma 10) and there will be at
least oneagent elected as a local leader (Lemma 11). Leader Election then runsfor the next O(m)
rounds for an agent among local leaders to become a global leader.
For the case of ℓ non-singleton nodes and no singleton node initially, again, ℓ instances of
Dispersion With Election finish in O(m) time electing at least 2 local leaders and they again
synchronize in the lexicographical order of the DFS IDs while runningLeader Election so that one
local leader agent becomes a global leader in next O(m) rounds (Lemmas 12, 14, and 17).
Now the only remaining case is the combination of non-singleton and singleton nodes in the
initial configuration. In this case, Dispersion With Election finishes in O(m) rounds electing at
least one agent as a local leader for any ℓ 1 (Lemmas 13 and 14) and by that time any agent run-
≥
ning Singleton Election either becomes a local leader or gets to know Dispersion With Election
and stops running Singleton Election changing its status to “non candidate”. After that
Leader Election finishes in O(m) rounds electing one agent that becomes a local leader as a global
leader. Therefore, the total runtime is O(m) rounds.
Consider the local leaders (thorough both Singleton Election and Dispersion With Election)
that cannot become a global leader. We have from Lemmas 15 and 16 that they can return to their
home nodes and stay as those nodes as non-candidates. Notice that returning to home nodes takes
O(n) rounds since the agents can traverse parent points on the DFS tree they build while running
Dispersion With Election.
Regarding memory, Dispersion With Election and Leader Election need to run
Confirm Empty() (Algorithm 5) and store the information. Additionally, the ℓ DFSs dur-
ing Dispersion With Election and all local leader DFSs during Leader Election ask nodes to
20keep their information; hence, O(nlogn) bits per agent is needed. All the other variables are of
either O(1) size or O(logn) size and there are only a constant number of them.
5 MST Construction
In this section, we present a deterministic algorithm to construct an MST of the graph G given a
leaderr electedintheprevioussectionanditsDFStreeT builtwhilerunningDFS(roundNo ,r ).
l r l l l
The MST construction finishes in O(m) rounds with O(∆logn) bits of memory at each agent.
Overview of the Algorithm. Starting from any arbitrary initial configuration n agents, when
Algorithm 1 finishes electing a leader, n 1 nodes of G have an agent each positioned with status
−
non candidate and one node has an agent with status leader.
Let r be a leader positioned at node v. We can have two methods for MST construction. The
v
firstmethodistoasktheleaderr tocollect alltheagents atnodev,makingarootedconfiguration.
v
This can be done by revisiting the DFS tree T built by r while running DFS(roundNo ,r ) to
r v v v
l
elect itself as a leader during Algorithm 6 (Leader Election), collecting the agents at node v in
O(n) rounds. After that r can run DFS(r ) as in Algorithm 4 to disperse the agents as well as
v v
assign ranks 1 to n. The leader will have rank 1 and the agent that settles i-th in the DFS order
of empty node visits will have rank i. The second method is to run DFS(r ) to visit all other
v
n 1 agents and assign them rank based on the order they are visited, i.e., the agent visited i-th in
−
the order receives rank i. This can again be done by revisiting the DFS tree T built by r while
r v
l
runningDFS(roundNo ,r ) to elect itself as a leader duringAlgorithm 6(Leader Election). This
v v
revisit finishes in O(n) rounds. We use this second method for MST construction.
As soon as an agent receives its rank, it considers itself as a single component. The leader r
v
at node v (which has rank-1) starts MST construction. r includes the MOE adjacent to v in its
v
componentandpassesatoken (message) totherank-2agent. Thisprocessrunsiteratively untilthe
rank-(n 1) agent passes the token to the rank-n agent. Consequently, the rank-n agent includes
−
in its component the MOE available and passes the token to the rank-1 agent (r ). This whole
v
process of passing token from rank-1 node to rank-n node and back to rank-1 node is one phase.
In the next phase, the minimum rank agent would include the MOE available to its component
and pass the token to the next minimum rank agent, iteratively. In this way, the token reaches
the minimum rank agent from the highest rank agent and this phase is completed. This process is
repeated phase-by-phase until there is a single component left. Eventually, we have an MST of a
single component with n agents. Let us call this algorithm MST Construction. Below, we discuss
the algorithm in detail. A complete pseudocode is given in Algorithm 7.
Our algorithm resembles the MST construction algorithm of Gallager, Humblet, and Spira [8]
with the difference that we start MST construction through ranks already provided to agents,
whereas in [8] all nodes have the same rank. The merging of two same rank components with
rank k in [8] provide a new rank of k +1 for the merged component. In ours, there will be no
same rank components and hence the merged component gets the rank of one of the components
merged. The token is sent in our algorithm in the order of the component ranks to ensure that all
the components can run merging.
Detailed Description of the Algorithm. As discussed earlier, consider that r is the leader
v
positioned at node v. Leader r runs DFS(r ) to visit all the non candidate agents and the i-
v v
th visited agent receives the rank i. The leader position is considered as the first, therefore, the
assigned rank for the leader is 1. Let C be the component of rank-i agent. Initially, C = 1. We
i i
| |
set the rank of component C be be the rank of agent i, i.e., rank(C ) = rank(i). The rank-1 agent
i i
21Algorithm 7: MST Construction
Input: An n-nodeanonymous network with n agents with uniqueIDsplaced on n nodes with an agent r
l
at a nodeelected as a leader (Algorithm 1) with DFS tree T rl built while running
DFS(roundNo,r) (Algorithm 6).
l l
Ensure: MST construction.
1 The leader assumes rank 1. It re-traverses the DFS treeT rl and returns toits home node. While
re-traversingT rl,it providesthedistinct rankfrom therangeof[2,n]totheagentsat n−1othernodesin
orderof visit.
2 Each agent r u considers itself as a component C ru with rank(C ru)←rank(r u).
3 The leader r l generates a token. Let its component beC rl.
4 while|C rl|<n do
5 if r u has the token then
6 if rank(r u)≤rank(C ru) then
7 Agent r u findsthe MOE of theC ru going to anothercomponent C rw connecting r u with r w.
8 if rank(C ru)<rank(C rw) then
9 r w becomes theroot node of C rw by reversing theparent-child pointers from r w up tothe
root nodeof C rw and r u becomes the parent of r w (Figs. 1 and 2). C rw then merges with
C ru giving a new component C rn uew with rank(C rn uew)←rank(C ru).
10 if rank(r u)<n then
11 r u passes thetoken to agent r v with rank(r v)=rank(r u)+1 using T rl.
12 else if rank(r u)>rank(C ru) and rank(r u)<n then
13 r u passes thetoken to agent r v with rank(r v)=rank(r u)+1 using T rl.
14 else if rank(r u)=n then
15 r u passes thetoken to the leader r l (with rank 1) using T rl. This token passing visits the
parentsof r u untilthetoken reaches theroot node of T rl, where theleader is positioned.
(leader) generates a token and performs the following step iteratively. The rank-1 agent checks its
component size C . If C < n, the leader includes the MOE leading to neighbor agent r in C ,
1 1 u 1
| | | |
and assigns rank(C ) rank(C ), where rank(C ) is the rank of the component C that r
1
←
ru ru ru u
belongs to. The MOE is the edge having one endpoint at a node in C (r ’s component) and the
i v
other endpointat a nodein C (r ’s component). Includingthe MOE in a component is component
j u
merging which makes two components a single component. The leader then passes the token to the
next minimumavailable rank agent r , which is token passing. If rank(C ) < rank(r ), r passes
w rw w w
the token to the agent r with rank(r )= rank(r )+1 (without component merging). Otherwise,
x x w
r includes the MOE to its component C and assigns r C ,rank(r) rank(C ) and pass
w rw
∀ ∈
rw
←
rw
the token to the agent r with rank(r ) = rank(r ) + 1 This inclusion of MOE is component
x x w
merging. When this is done for all the agents once and rank-n agent passes the token back to
the leader, a phase is finished. This process repeats and stops after the leader agent (rank-1) has
C = n.
1
| |
Now, we discuss the token passing and merging in detail.
Token Passing: The tokens passed are of two types: (1) token passed by the rank-i
agent to rank-(i + 1) agent (2) token passed by the rank-n agent to rank-1 agent (the leader).
Both token types are passed using the DFS tree T built by the leader agent r while running
r v
l
DFS(roundNo ,r ) (during Algorithm 6). In the first case, the token passing follows the order in
v v
which nodes of G are visited by DFS(roundNo ,r ). In the second case, the token passed by the
v v
rank-n agent follows the parent pointers in T until it reaches the root of T where rank-1 agent
r r
l l
is positioned.
Merging: Suppose agent r with 1 rank(r ) n in component C has the token and
u
≤
u
≤
ru
22r a r y
r r r
u x c
MOE
r v r z r w r e r f r g
r
h
Figure 1: The components C and C before C merges with C due to the MOE connecting
rw ru rw ru
node r C with node r C and rank(C ) < rank(C ) (if rank(C ) < rank(C ), then
u
∈
ru w
∈
rw ru rw rw ru
C merges with C due to the MOE connecting r C with node r C ). Both C and
ru rw w
∈
rw u
∈
ru ru
C are rooted trees with roots r and r , respectively. In the figure, r r denotes r is the
rw a y A
→
B A
parent of r .
B
rank(r ) rank(C ). C isatreeandhasarootnode/agent. Agentr findstheMOEconnected
u
≤
ru ru u
to C (the component it belongs to) as follows. Agent r traverses C and checks the incident
ru u ru
edges of the nodes in C (edges with both endpoints on the nodes in C are not considered) in
ru ru
the ascending order of the (edge) weights. r adds the MOE among the incident edges to C . Let
u ru
the (added) MOE have the other end at a node w that belongs to C . W.l.o.g., let us consider
rw
rank(C ) < rank(C ) (otherwise, r simply passes the token to agent with rank(r )+1). The
ru rw u u
old parent, say r (from the component C ), of r becomes r ’s child. The process of converting
x rw w w
a parent to a child starting from r runs until reaching the root node in C . Each subsequent
w rw
parent now becomes a child and the child becomes a parent, i.e., r becomes the root of C . Since
w rw
MOE is added, r becomes the parent of r . C and C now become a new single component
u w ru rw
Cnew. Since rank(C ) < rank(C ), rank(Cnew) rank(C ), which is communicated to all the
ru ru rw ru
←
ru
agents (nodes) in Cnew. Furthermore, the C ’s component does not go through any transition
ru ru
with respect to parent-child pointers except the fact that r becomes the parent of r . Figs. 1 and
u w
2 illustrate these ideas. Fig. 1 shows components C and C before they merge due to the MOE
ru rw
connecting r with r . Fig. 2 captures the merged component Cnew such that root of the Cnew
u w ru ru
remains unchanged and the pointer changes occurred in the C component during the merging.
rw
The directed edge denotes new parent-child relationships.
Analysis of the Algorithm. We now analyze Algorithm 7 for its correctness and time and
memory complexities. The correctness proof shows that Algorithm 7 indeed constructs a MST.
Lemma 18. Algorithm 7 (MST Construction) generates the MST of G.
Proof. Weprovethis inthreesteps: firstly,Algorithm 7constructs atree; secondly, theconstructed
tree is a spanning tree; finally, the spanning tree is, indeed, a minimum spanning tree. Firstly, we
prove by contradiction that no cycle is generated during Algorithm 7. Let us suppose, there exists
a cycle at any point during the algorithm. Then it implies two components with the same rank
merged at some point, which is a contradiction. Secondly, let us suppose there exist at least two
components at the end of the algorithm. This implies that the leader component (rank-1) did not
merge with the other component and terminated the algorithm, which contradicts the fact that the
algorithm terminates when the leader is connected to n agents altogether.
23r a r y
r r r
u x c
MOE
r v r z r w r e r f r g
r
h
Figure 2: The resulting component Cnew after merging C with C . Component Cnew gets
ru rw ru ru
rank rank(Cnew) rank(C ) since C merged with C to become Cnew due to rank(C ) <
ru
←
ru rw ru ru ru
rank(C ). Two parent-child pointers in C are reversed to keep Cnew a rooted tree.
rw rw ru
∗
Finally, consider that the tree formed by our algorithm is T and the MST is T . Note that
∗
in Algorithm 7, each edge added to the MST tree is by selection of a MOE. If T = T then T is
∗ ∗
minimum spanning tree. If T = T then there exists an edge e T of minimum weight such that
6 ∈
e / T. Therefore, there exists a phase in which e was not considered during component merging
∈ ′
and an edge with higher weight, say e, was considered. But this is contradictory to Algorithm 7
which merges the components with a MOE. Therefore, Algorithm 7 constructs the MST of G.
We now prove time and memory complexities. We start with the following lemma.
Lemma 19. In Algorithm 7 (MST Construction), the leader initiates the merging process at most
O(logn) times.
Proof. Initially, there are n single-node components in Algorithm 7 (Line 2). In each phase (leader
initiating a token until token returns to the leader), each component merges at least once with
another component. Therefore, after every phase, the number of components is reduced by at least
half. Consequently, after O(logn) phases, there remains only a single component of n nodes.
We are now ready to prove Theorem 3, the MST construction result.
Proof of Theorem 3:
Proof. Providing ranks to agents takes O(n) rounds by re-traversing the DFS tree T con-
DFS
structed by DFS(roundNo ,r ) during leader election (Algorithm 6). The while loop performs
u u
two operations - token passing and merging.
In token passing, the token is passed through the edge of the tree T , and an edge is not
DFS
traversed more than twice. Therefore, in a phase, to pass the token from rank-1 agent to rank-n
agent takes O(n) rounds. From rank-n agent the token returns to the leader again in O(n) rounds.
Combining this with Lemma 19, token passing takes O(nlogn) rounds.
In the process of merging, an agent r visits at most three types of edges: i) MOE edges within
u
its component C ii) edges traversed to find MOE iii) reversing the edges from r until the root
ru w
of C when it merges with another component C at r . In the case of i) MOE is the part of the
rw ru w
component C , i.e., a tree. Its traversal finishes in O(C ) rounds. In a phase, the combined size
ru
|
ru|
of all the components is O(n). In case ii) edges that are traversed to find the MOE were either part
24of MOE or not, in case, they become part of MOE they were traversed two times. There are at
most (n 1) such edges throughout the process. On the other hand, if some edges did not become
−
part of the MOE then they were never traversed again. Therefore, there are in total m (n 1)
− −
suchedges. Incaseiii)reversinganedgefromitsmergingpointtotherootcannotbemorethanits
component size. Therefore, reversing of edge for agent r takes O(C ). Combining the time for
u
|
ru|
the cases i) and iii) per phase with O(logn) phases (Lemma 19), we have total runtime O(nlogn)
rounds and for case ii) we have total O(m) rounds throughout the execution. Thus, the overall
round complexity becomes O(m+nlogn).
For memory, rank numbering takes O(logn) bits at each agent to re-traverse the DFS tree
T (constructed during Algorithm 6). Furthermore, each agent stores O(logn) bits to keep the
DFS
account of theID/rank andcomponent rank. Also, there might bea case in which all theneighbors
are part of the MST. Therefore, in the worst case, the highest degree (∆) agent (agent placed at
the highest degree node) keeps the account of all the MST edges and requires O(∆logn) memory.
Hence, the overall memory required by each agent in Algorithm 7 is O(∆logn) bits.
6 Concluding Remarks
We have initiated the study of constructing MST of a graph in the agent model. The considered
agent model poses unique challenges compared to the well-studied message-passing model. We
have developed three results. The first result provides a solution simulating an existing MST
algorithm in the message-passing model to the agent model under some assumptions on known
graph parameters n and ∆ and with memory at each node proportional to the node memory in the
message-passing model. The second result elects a leader in the agent model with agents starting
initially arbitrarily on the graph nodes in O(m) time with O(nlogn) bits at each agents, without
agents knowing any graph parameter a priori. Finally the third result provides a MST solution
given an elected leader in O(m+nlogn) time with O(∆logn) bits at each agent, without agents
knowing any graph parameter a priori. The time complexity of our MST algorithm matches that
of Prim’s algorithm in the centralized computing model. The MST result is made possible by the
highly non-trivialtechnique of electing one agent as auniqueleader which wedeveloped for proving
Theorem 2. This technique may be of independent interest in distributed robotics since having a
leaderallows toprovidesolutionstotheproblemsinwhichsymmetrybreakingisotherwisedifficult.
For future work, it would be interesting to improve the time complexity of our MST solution (and
leader election) to match the lower bound and/or improve the memory complexity to match the
optimal O(logn) bits per agent, without agents knowing graph parameters a priori.
References
[1] Baruch Awerbuch. Optimal distributed algorithms for minimum weight spanning tree, count-
ing, leaderelection andrelated problems(detailed summary). InAlfredV.Aho, editor, STOC,
pages 230–240. ACM, 1987.
[2] David A. Bader and Guojing Cong. Fast shared-memory algorithms for computing the min-
imum spanning forest of sparse graphs. J. Parallel Distributed Comput., 66(11):1366–1378,
2006.
[3] PrabhatKumarChand,ApurbaDas, andAnisurRahamanMolla. Agent-basedtrianglecount-
ing and its applications in anonymous graphs. CoRR, abs/2402.03653, 2024.
25[4] Prabhat Kumar Chand, Anisur Rahaman Molla, and Sumathi Sivasubramaniam. Run for
cover: Dominating set via mobile agents. In ALGOWIN, pages 133–150. Springer, 2023.
[5] Bernard Chazelle. A minimum spanningtree algorithm with inverse-ackermann type complex-
ity. J. ACM, 47(6):1028–1047, 2000.
[6] Ka Wong Chong, Yijie Han, and Tak Wah Lam. Concurrent threads and optimal parallel
minimum spanning trees algorithm. J. ACM, 48(2):297–323, 2001.
[7] Edsger W. Dijkstra. A note on two problems in connexion with graphs. Numerische Mathe-
matik, 1:269–271, 1959.
[8] R. G. Gallager, P. A. Humblet, and P. M. Spira. A distributed algorithm for minimum-weight
spanning trees. ACM Trans. Program. Lang. Syst., 5(1):66–77, jan 1983.
[9] Juan A. Garay, Shay Kutten, and David Peleg. A sub-linear time distributed algorithm
for minimum-weight spanning trees (extended abstract). In FOCS, pages 659–668. IEEE
Computer Society, 1993.
[10] R.L. Graham and Pavol Hell. On the history of the minimum spanning tree problem. Annals
of the History of Computing, 7(1):43–57, 1985.
[11] David R. Karger, Philip N. Klein, and Robert Endre Tarjan. A randomized linear-time algo-
rithm to find minimum spanning trees. J. ACM, 42(2):321–328, 1995.
[12] J. B. Kruskal. On the Shortest Spanning Subtree of a Graph and the Traveling Salesman
Problem. In Proceedings of the American Mathematical Society, 7, 1956.
[13] Ajay D. Kshemkalyani and Faizan Ali. Efficient dispersion of mobile robots on graphs. In
ICDCN, pages 218–227, 2019.
[14] Ajay D. Kshemkalyani, Anisur Rahaman Molla, and Gokarna Sharma. Dispersion of mobile
robots in the global communication model. In ICDCN, pages 12:1–12:10, 2020.
[15] Ajay D.KshemkalyaniandGokarnaSharma. Near-optimal dispersiononarbitraryanonymous
graphs. In25th International Conference on PrinciplesofDistributed Systems, OPODIS,pages
8:1–8:19, 2021.
[16] Shay Kutten and David Peleg. Fast distributed construction of small k-dominating sets and
applications. J. Algorithms, 28(1):40–66, 1998.
[17] Debasish Pattanayak, Subhash Bhagat, Sruti Gan Chaudhuri, and Anisur Rahaman Molla.
Maximal independet set via mobile agents. In ICDCN, pages 74–83. ACM, 2024.
[18] David Peleg and Vitaly Rubinovich. A near-tight lower bound on the time complexity of
distributed minimum-weight spanning tree construction. SIAM J. Comput., 30(5):1427–1442,
2000.
[19] Seth Pettie and Vijaya Ramachandran. A randomized time-work optimal parallel algorithm
for finding a minimum spanning forest. SIAM J. Comput., 31(6):1879–1895, 2002.
[20] Yuichi Sudo,Masahiro Shibata, JunyaNakamura, Yonghwan Kim, and Toshimitsu Masuzawa.
Near-linear time dispersion of mobile agents, 2023.
26