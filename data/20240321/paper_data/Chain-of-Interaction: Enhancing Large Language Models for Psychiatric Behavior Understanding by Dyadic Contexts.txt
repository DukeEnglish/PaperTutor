Chain-of-Interaction: Enhancing Large Language
Models for Psychiatric Behavior Understanding by
Dyadic Contexts
Guangzeng Han∗, Weisi Liu∗, Xiaolei Huang∗, Brian Borsari†‡
∗Department of Computer Science, University of Memphis, Memphis, United States
{ghan,wliu9,xiaolei.huang}@memphis.edu
†Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, United States
brian.borsari@ucsf.edu
‡San Francisco Veterans Affairs Health Care System, San Francisco, United States
Abstract—Automatic coding patient behaviors is essential alternative solution is to build machine learning models to
to support decision making for psychotherapists during the automate coding process in Fig. 1.
motivational interviewing (MI), a collaborative communication
intervention approach to address psychiatric issues, such as
alcohol and drug addiction. While the behavior coding task
I have to quit Change
has rapidly adapted language models to predict patient states drinking. [0.5,0.3,0.2] Talk
duringtheMIsessions,lackingofdomain-specificknowledgeand
overlooking patient-therapist interactions are major challenges Patient Utterance Discriminative Model Logits Prediction
in developing and deploying those models in real practice. To
encounterthosechallenges,weintroducetheChain-of-Interaction Fig. 1. Diagram illustrating automatic behavioral coding methods based on
(CoI) prompting method aiming to contextualize large language discriminativemodels.
models (LLMs) for psychiatric decision support by the dyadic
interactions.TheCoIpromptingapproachsystematicallybreaks Fig. 1 presents current standard process of automatically
down the coding task into three key reasoning steps, extract coding MI sessions that first vectorize patient utterances into
patient engagement, learn therapist question strategies, and neural representations and then feed the representations to
integrates dyadic interactions between patients and therapists.
discriminativeclassifiersforfinalpredictions[5].Forexample,
This approach enables large language models to leverage the
recent studies have developed MI classifiers by recurrent
coding scheme, patient state, and domain knowledge for patient
behavioralcoding.Experimentsonreal-worlddatasetscanprove neural networks (e.g., LSTM or GRU) [6], [7] and BERT [8],
the effectiveness and flexibility of our prompting method with [9] for automatically predicting MISC codes at utterance and
multiplestate-of-the-artLLMsoverexistingpromptingbaselines. session levels, which have achieved promising performance.
We have conducted extensive ablation analysis and demonstrate
However, a major issue of the existing ML classifiers is miss-
the critical role of dyadic interactions in applying LLMs for
psychotherapy behavior understanding.1 ingincorporatingthepsychiatricdomainknowledge,including
IndexTerms—Behavioralcoding,Largelanguagemodels,psy- MISC coding manuals, which guide and train human profes-
chotherapy, motivational interview sionals to annotate patient behaviors. The existing methods
require costly and time-consuming human annotations and
I. INTRODUCTION may not integrate domain-specific knowledge from the MISC
coding schema by only feeding utterances into classifiers for
Motivational interviewing (MI) [1] is defined as “particular
predictions, such as MISC concepts and definitions used by
way of talking with people about change and growth to
humanexpertsinbehavioralcoding.Thus,aconcretequestion
strengthen their own motivation and commitment.” MI can
is: how can we instruct models to annotate MI sessions
facilitate change in behaviors associated with mental health
following the MISC schema like psychiatric professionals?
issues, which are among the most complex health problems
impactingoveronebillionpeopleworldwide[2].TheMotiva- Large language models (LLMs), such as GPT [10], [11]
tional Interviewing Skill Code (MISC) [3] is a coding system and Llama2 [12], has undergone a rapid evolution in recent
that provides comprehensive and structured coding schema years and have demonstrated a significant potential transform
for examining therapist and patient behaviors (utterances) and mentalhealthandpsychotherapyinterventions,suchasdepres-
assessing different aspects of the intervention (e.g., therapist sion detection in social media [13], [14] and psychotherapy
empathy).However,MIsessionassessmentsrequiresignificant chatbot [15]. Effective prompting design for LLMs is the
time commitment, labor costs, and professional training [4], key to achieve precise diagnosis and understanding of patient
which may not meet immediate training or clinical needs. An behaviors. Prompting methods involve how we put together
and format questions or commands for the model to instruct
1Codeavailableathttps://github.com/trust-nlp/CoI-Psychotherapy generating specific responses. For example, prompting meth-
4202
raM
02
]LC.sc[
1v68731.3042:viXraTABLEI
SAMPLESOFMISC-CODEDDATA.THESAMESUB-CODESMAYBEENCODEDASDIFFERENTPATIENTCODESDUETOTHEIRDIFFERENTVALENCE(+/-)
Patientcode Sub-code Description Therapistutterance(Code) Patientutterance
Commitment+ Patientmakesachangingcommitment. Doyouwanttochange?(ClosedQuestion) Iamgoingtostopsmoking.
Ability+ Assessclient’sabilitytochange. You’vebeenthroughalot.(Support) Icandoit.
ChangeTalk
Desire+ Adesiretoalterthetargetbehavior. Iwanttotalkaboutyourmotivation.(Structure) Iwanttoquitdoingdrugs.
Reason+ Reasonsforchangingthebehavior Whataresomereasonsforquitting?(OpenQuestion) I’mkillingmyself.
N/A Reportinginformation. Howoftendoyoudrink?(ClosedQuestion) Usually4-5days.
Follow/Neutral N/A Followtherapist. Doyouhavechildren?(ClosedQuestion) Ihavethreedaughters.
N/A Askquestion. Thesupportgroupmeetsfrom4to5pm.(GiveInformation) Doyouknowwhentheymeets?
Commitment- Patientmakesamaintainingcommitment. Speedingwillcostyouyourlicense.(Warn) IwillneverslowdownwhenIdrive.
Ability- Assessclient’sabilitytochange. Onlyyouknowwhat’sbestforyou.(EmphasizeControl) IcannotstopovereatingevenwhenItry.
SustainTalk
Desire- Adesiretomaintainthebehavior. Ifyougetboredyou’llusedrugs.(Warn) Iwanttokeepgettinghigh.
Reason- Reasonsformaintainingthebehavior. Putyourhealthfirst!(Direct) AtleastIgetrelaxedwhenIdrink.
odslikeChainofThought(CoT)[16],ThreadofThought[17], II. DATA
and Retrieval-Augmented Generation (RAG) [18], [19] can
effectivelysolvecommonsensereasoningtasks––bysplitting Weusedsessionsfromtwoindependentrandomizedclinical
complex questions into several easier and key parts of general trials [23], which conducted MI sessions with 249 university
questions. However, these kinds of prompting techniques do students who had been mandated for alcohol-related infrac-
not consider the dyadic contexts of MI sessions, interactions tions (e.g., possession, vandalism). Each MI session lasts
between patients and therapists. The dyadic interaction be- between45to60minutesandwereaudiorecorded.Toprotect
tween psychotherapists and patients is a natural characteris- user privacy and identities, these recorded sessions were
tic of MI sessions, which is commonly overlooked in the transcribed into text, de-identified, and coded using the Mo-
existing prompt approaches. As the interactive context can tivational Interviewing Skills Code (MISC version 2.0) [24].
providekeyinsightsforaccuratelyinferringpatientbehaviors, MISC encodes patient utterances into three mutually exclu-
the challenges call for new methods to integrate psychiatric siveoverarchingcategories:Follow/Neutral,ChangeTalk,and
knowledge,understanddyadiccontexts,andequipwithstrong Sustain Talk. “Follow/Neutral” encompasses responses where
reasoning capability. the patient aligns with, remains neutral, or seeks information
Toaddressthesespecificchallenges,weproposetheChain- fromthetherapywithoutdirectlyaddressingbehaviorchange;
of-Interaction prompting method aiming to incorporate do- “Change Talk” involves statements indicating an intention to
main knowledge from MISC coding schema and in-session change the behavior; and “Sustain Talk” includes utterances
interactions. It utilizes a series of prompt stages to enhance that suggest maintaining the current behavior. Change lan-
the reasoning abilities of LLMs in the task of coding patient guage can be conceptualized as being on a continuum with
utterance,drawinguponpsychologicaldomainknowledgeand a positive valence indicating Change Talk, a negative valence
the style of interactions between patients and therapists from representingSustainTalk,andaneutralvalencecorresponding
three consecutive stages: Interaction Definition, Involvement to Follow/Neutral.
Assessment, and Valence Analysis. The Interaction Defini- To control data quality, this study did not consider therapy
tion stage aims to help LLMs define the therapist-patient records that had annotation errors or incomplete annotations.
interactions by categorizing the unique MISC codes of each Perrecordingsession,welower-casedutterancesandextracted
utterance.Next,theInvolvementAssessmentevaluatespatient data segments consisting of every ten non-overlapping utter-
engagement by assessing willingness for self-exploration and ances as one data entry, aiming to provide dyadic interactions
emotional expression. Finally, Valence Analysis stage is to between patients and therapists. For each data entry, we
integrate the general sentiment of patient and the clues from utilized the MISC code of the last patient utterance of the
previoustwostages,weexpectLLMscanutilizetheintegrated entry as the ground truth label. This method ensures that
informationtomimicthereasoningprocessofhumanexperts. the model’s focus is on the patient’s most recent utterance,
Weconductextensiveexperimentsondatasetsderivedfrom accurately reflecting their behavioral state at that particular
real-world MI sessions addressing alcohol usage disorder. We moment in the therapy session. We summarize data statistics
examine three prompting baselines and experiment with four inTableIIforrawandprocesseddatatoallowforreplication.
state-of-the-art auto-regressive LLMs, including Llama2 [12],
Falcon[20],Mistral[21],andChatGPT[22].Ourexperiments
TABLEII
demonstratetheeffectivenessoftheChain-of-Interaction(CoI) DATASTATISTICS.LREFERSTOTHEAVERAGENUMBEROFTOKENSPER
prompting method, which can outperform multiple baselines UTTERANCE.UISTHEAVERAGEUTTERANCECOUNTPERTHERAPY
by a large margin. The consistent improvements in Macro-F1
SESSION.
andMicro-F1scorescanindicatethatCoImayenhanceLLMs Utterance ChangeTalk Follow/Neutral SustainTalk L
under data and label imbalance. Furthermore, our ablation 48,529 13,298 29,025 6,026 30.2
study reveals the critical contribution of domain knowledge Session Female Male Therapist U
and dyadic interactions in LLM performance. 249 95 154 14 194.9Interaction Involvement Valence
Definition Assessment Analysis
General sentiment:
What makes Sunday not a The patient's general sentiment
good drinking day for you? Therapist’s behavior: Self-exploration: can be characterized as Neutral.
The therapist is using “Open The patient is engaging in self- Their responses are factual and
Because I have class the next question” and a “Reflection”to exploration by recognizing the focused on practical
day. Usually I have school encourage the patient to explore impact of their choices (not considerations, without strong
work to do on Sundays and I their own behavior and drinking on Sundays due to emotional overtones.
don’t like drinking to
motivations. school work).
interfere with that. Valence type:
The patient’s valence towards
So school is why you are here.
reducing alcohol use appears to
be Positive. While they do not
Yeah, school is definitely Expression of affect : explicitly state a desire to reduce
takes more priority on a Patient’s behavior: The patient expresses affect by alcohol use, the fact that they
Sunday than drinking does. The patient provides "Reasons” showing concernfor their work prioritize school work over
for change. and choosing it over alcohol drinking, indicates a recognition
consumption. of the importance of non-
alcohol-related activities in their
life.
Fig.2. Overviewofthe“Chain-of-Interaction”promptingmethod,weusethreecolorstodenotedifferentstages.
In this study, we utilize the three MISC client language imbueLLMswithanewlevelofunderstandingandanalytical
categories for the auto behavior coding task, and we present depth that parallels professional psychological expertise.
examples of the MISC codes and utterances in Table I. First, the Interaction Definition stage enables the LLMs
The examples show interactive and contextual effects exist learning MI domain knowledge and objectively understand-
between patients and therapists that patient utterances can ing the interaction patterns. Next, the Involvement Assess-
shape therapeutic strategies for interventionists and in turn ment stage inquiries LLMs to examine emotional and self-
theconversationengagementwillimpactonpatientbehaviors. expression clues from the patient utterances to infer the pa-
While past studies [7], [9] have shown concatenating patient tient’sengagementlevel,aimingtobridgecorrelationsbetween
utterance and its previous utterances can improve prediction patient mental states and their behavior outcomes. Finally,
accuracy of the MISC coding task, how the patient-therapist in the Valence Analysis stage, LLMs predict the patient’s
interactionscaninformmodelpredictionsisunderexplored.To utterancevalencebyintegratinginformationaboutthepatient’s
effectively utilize this information, we proposed the Chain- emotionalstateandinteractionpattern.Throughthisstructured
of-Interaction (CoI) prompting, which helps large language approach, we imbue LLMs with a level of understanding and
models in automatically coding motivational interview patient analytical depth that parallels professional psychological ex-
behavior by leveraging the interactions between patients and pertise.MoredetailsabouttheChain-of-Interactionprompting
therapists, as well as the engagement of patients during methods can be found in Fig. 3.
counseling sessions.
A. Interaction Definition
III. THECHAIN-OF-INTERACTIONPROMPTING
Our goal is to equip predictive models with strong reason-
MI efficacy theory [25], [26] suggests that dyadic interac- ing capabilities as human professionals, while concatenating
tions play a critical role in therapist skills, patient behaviors, dyadic interactions and patient utterances as features is the
andoutcomes––guideandinspirethedevelopmentofournew major approach for existing end-to-end MISC classifiers [6],
prompting method. Two aspects of this dyadic interaction are [7], [9], [27], [28]. Unlike the feature integration approach,
linked to MI efficacy. First, there is a technical component humanprofessionalsideallyutilizeMICOstrategiestointeract
in which therapist MI Consistent (MICO) utterances can withpatientsandtheMISCcodingschemacanbeusedtoan-
selectively elicit and strengthen client change language which notatepatientbehaviors,whichisafundamentaldifference.To
is predictive of subsequent behavior change. There is also encounter the wide-existing yet unsolved issue, we introduce
a relational component which incorporates the interpersonal theInteractionDefinitionstage,whichallowsLargeLanguage
aspectsofthetherapistandclientrelationshipsuchasMISpirit Models (LLMs) to understand and interpret the interactive
andempathy.WeproposetheChain-of-Interactionprompting, contexts of therapists and patients by the guidance of MISC
aiming to incorporate the psychological domain knowledge behavior coding schema and definitions.
and the two aspects of therapist-patient interaction to promote We design instructions to guide LLMs understanding inter-
the contextual awareness of large language models in the actions between therapists and patients and mental states of
behavioralcodingtask.Fig.2illustratesourpromptingframe- patientsviatwomajorpartsofpromptmodules,1)definitions
work of Chain-of-Interaction with three continuous stages: 1) of MISC codes and coping with 2) dyadic contexts. The
InteractionDefinition,2)InvolvementAssessment,3)Valence instructional prompts aim to inspire LLMs to capture MI
Analysis. Through this structured prompting approach, we domain knowledge and master the MISC coding schema. ToCode Descriptions [C] Utterance History [X] Prompt Template T + Code Descriptions [C] + Utterance History [X]
Task Definition:Based on the Motivational Interview transcript between a psychotherapist and a patient
with alcohol abuse issues, please identify the patient's valence about changing their behavior (i.e. reducing
alcohol abuse )as either neutral, positive, or negative.
Affirm: Acknowledge Here are the motivational interviewing behavior Code Descriptions [C]
Therapist utterance[1]
admirable behavior or Test Instance: Utterance History[X]
Patient utterance [1]
quality of the patient. Chain-of-Interaction Prompt:Based on the Motivational Interview record, answer the following Chain-of-
…….
…… Interaction questions.
…….
…… Stage1: What are the prime motivation interview behaviors of the doctor and patient?
Therapist utterance[5]
Support: Sympathetic Stage2: How is the involvement of patient in this interview, Specifically does the patient self-explore, and
Patient utterance [5]
behavior. does the patient have any emotional expression?
Stage3: What is the general sentiment of patient language? And What is the patient's valence about reducing
the alcohol use?
Output:
Fig.3. Detailsofthepromptdesignforthe“Chain-of-Interaction”method.
achieve this, we start with feeding LLMs with extracted MI Definitions of stage 1 outputs. We then prompt LLMs to
definitions from MISC coding manuals [1], [24]. After the assess patient engagement through aspects of self-exploration
initial instruction, we then ask LLMs to review a patient and emotional expression. The example in Fig. 2 illustrates
utterance with its dyadic contexts. The process is to enable how the LLM interprets specific methods of self-exploration
LLMs behave like human professionals that apply domain and emotional expression based on the “reason” behavior of
knowledge by their in-context learning ability. We request patients from the first stage.
LLMs to attempt annotating utterances of the dyadic context From the clear interaction patterns obtained in the Interac-
by the MISC therapist MICO categories (e.g. open-ended tion Definition stage to the subjective assessment of engage-
questions, affirmation, reflections) and the patient utterance ment in this stage, LLMs can benefit from domain-specific
subcategories shown in Table I. We illustrate examples of the knowledge and emulate the thinking habits of professionals.
process and prompt examples in Fig. 2 and 3. For example, Furthermore,theemotionalexpressionsidentifiedinthisstage
Fig. 2 shows that LLMs encode the patient and therapist serve as a foundation for the analysis in the final stage.
utterances as “Reason” and “Open question”, respectively,
C. Valence Analysis
which will help LLMs understand patient dynamic mental
states and provide more information for the following stages. In MI, valence reflects the client’s utterances regarding
The stage meets our initial goal by instructing LLMs by changing the target behavior. A positive valence indicates
the behavior coding task, incorporating domain knowledge Change Talk, a negative valence represents Sustain Talk, and
as instructions, and equipping LLMs with domain-specific a neutral valence corresponds to Follow/Neutral. According
reasoning capabilities. to their correspondence, we transform the behavioral coding
task into valence coding task. Valence is a component of
B. Involvement Assessment
sentiment, focusing specifically on the positive-negative axis
MI coding teams objectively code MISC patient behav- of emotional response. Sentiment, however, is a more com-
ior while also subjectively rating the relational aspects of prehensive term that captures the full spectrum of emotional
the session [23] (e.g., engagement). Prior research [29] has states and attitudes, including valence as one of its dimen-
also demonstrated that patients who are highly engaged in sions. Based on this characterization, we propose the Valence
treatment have more Change Talk, and less Sustain Talk, Analysis stage, which aims to help LLMs better perform the
therefore assessing patient engagement will help the model valence coding task through two sub-stages. The first sub-
better understand patient tendencies regrading target behavior. stageinvolvesutilizinggeneralsentimentanalysistoaidLLMs
Toutilizetheseauxiliarysubjectivepathstohelptheobjective in comprehending sentimental states of patients. The second
behavioral coding, we propose the Involvement Assessment one integrates outputs obtained from all three stages to make
stage, which makes LLMs to mimic the rating process of the LLMs to more comprehensively utilize the domain-specific
MI coders by assessing the involvement of patient. knowledge and the interactive contexts.
In this stage, we formulate prompts to remind LLMs In this stage, we start with instructing LLMs to perform
to revisit the original dyadic contexts and the Interaction a generic sentiment analysis based on the original utterances
Definitions (i.e. outputs of Interaction Definition stage), ex- and the emotional expressions obtained from the Involvement
tracting two important cues about engagement from them: Assessment stage. The goal is to allow LLMs to learn more
self-exploration and emotional expression [30], [31]. These about the patient’s sentimental state before reasoning about
prompts aims to guide LLMs to emulate the rating process our final task objective: Valence, through a simpler and more
professionals use when coding MI patient behavior. To aid generalized task. After the sentiment analysis, we finally
in simulating this process, we first require LLMs to consider prompt LLMs to review the outputs obtained through the
not only the original dyadic contexts but also the Interaction three progressive stages, which include the required objectivecriteria in the MISC coding schema, as well as the subjective provides LLMs with a small number of “shots” for tuning,
rating that professionals would refer to when coding, and the including task examples and their corresponding ground truth
sentimental state of the patient’s language. By integrating the outputs. These examples serve as a brief learning guide,
output from these three stages, LLMs not only understood providing LLMs with some context or insight about the
the pattern of interaction between the patient and therapist, nature of the task. However, Few-Shot prompting does not
but also assessed the patient’s level of engagement as well as actively guide the model in breaking down the task into
analyzed the patient’s emotional state. These procedures help multiple reasoning steps. Therefore, for tasks requiring multi-
LLMs to reason and code more rationally about the patient’s step reasoning, such as basic mathematical problems [37] and
Valence by utilizing domain knowledge and patient-therapist the MI behavioral coding in this study, Few-shot prompting
interactions as professional coders do. still struggles to perform well. In contrast, our CoI prompting
reduces the complexity of the behavioral coding task by
IV. EXPERIMENT
breaking it down into three sequential sub-tasks and prompt
To examine the effectiveness of our proposed ‘Chain-of- stages.
Interaction’(CoI)promptingmethod,weconductedacompar- 3) Zero-Shot Chain-of-Thought Prompting: Marking a de-
ative analysis with state-of-the-art baselines and performed a parture from traditional Chain-of-Thought [16], which typi-
detailedablationstudy.Wesetourexperimentalresultsagainst cally relies on hand-crafted, detailed Few-shot examples for
threeestablishedbaselinemethods:Zero-Shotprompting[32], each task, Zero-shot Chain-of-Thought (ZeroCoT) [36] is a
[33], Few-Shot prompting [34], [35], and Zero-Shot Chain template-based prompting method for LLMs. It focuses on
of Thought (ZeroCoT) [36] prompting. In addition, our work sequential reasoning without the need for specific training ex-
includesanablationstudyfocusingontheproposedChain-of- amples. By employing a generalized, one-size-fits-all prompt
Interaction (CoI) method, where we removed each individual suchas“Let’sthinkstepbystep”.ZeroCoTeffectivelyguides
stage within the CoI. By assessing the performance resulting LLMs to decompose various complex tasks into multiple
from the removal of each stage, we measured its contribution reasoning steps. Its robustness has been proven across a wide
to the overall effectiveness. We selected four representative range of applications, from intricate arithmetic and symbolic
auto-regressive LLMs to perform the experiments, including reasoningproblemstootherlogicalreasoningtasks.However,
Llama2-13B-Chat [12], Falcon-7B-Instruct [20], Mistral-7B- MIbehavioralcodingisnotmerelyataskoflogicalreasoning.
Instruct [21], and ChatGPT [22]. We used model-specific It also requires the use of domain-specific knowledge and the
official prompt templates and followed each model’s default characteristics of interactions between patients and therapists
samplingstrategies.OurassessmentemployedMicro-F1score to assist in coding. For this reason, our CoI method, through
togaugeoverallmodelaccuracyandMacro-F1scoretoensure three well-designed prompt stages, breaks the MI behavior
fairnessacrossdifferentclasses,offeringabalancedevaluation coding task down into three sequential sub-tasks based on
of the models’ performance in varied environments. professional guidelines and coding schema, rather than letting
LLMs decompose the task on their own as ZeroCoT. This
A. Baselines
approachaidsLLMsinunderstandingtheinteractionsbetween
To demonstrate the effectiveness of our proposed Chain-of- patients and therapists and simulates the reasoning process of
Interactionpromptingmethod,wecompareitwiththreestate- human coders.
of-the-artpromptingtechniques:1)Zero-ShotPrompting[32],
[33], 2) Few-Shot Prompting [34], [35], 3) Zero-Shot Chain- B. Models
of-Thought (ZeroCoT) Prompting [36].
We performed experiments on four LLMs, namely
1) Zero-Shot Prompting: Zero-shot prompting [32], [33],
Llama2-13B-Chat [12], Falcon-7B-Instruct [20], Mistral-7B-
where LLMs receive only a sample and task description with-
Instruct [21], and ChatGPT [22], which are available by
out corresponding examples or specially designed prompts, OpenAIAPI2orHuggingFace3.Thereasonforselectingthese
may be insufficient for complex and domain-specific tasks.
LLMs over their non-fine-tuned base versions (e.g. Llama2-
ThisapproachreliesentirelyontheLLMs’inherentknowledge
13B-Base, Falcon-7B-Base) is their superior ability to follow
and adaptability, potentially causing it to bypass important
dialogue-style instructions.
reasoningstepsandoverlookcriticalinformationwhenlacking
1) Llama2-13B-Chat: Llama2 [12] is an auto-regressive
necessarycontext.InMIbehavioralcoding,forinstance,Zero-
Transformer model pre-trained on publicly available online
shot prompting might lead to suboptimal performance due to
data. Additionally, it utilizes ghost attention [38] and grouped
the absence of domain knowledge and contextual understand-
queryattentiontoenhanceconsistencyinmulti-turndialogues
ing. In contrast, our CoI can integrate domain knowledge,
and extend its context length, respectively. In this study, we
enablingLLMstopayattentiontounderlyinginformationthat
use the Llama2-Chat variant, which undergoes supervised
are unavailable in the utterances.
fine-tuning followed by reinforcement learning from human
2) Few-Shot Prompting: LLMs have been proven to have
feedback (RLHF) [11], [39], [40], which includes rejection
the capability of in-context learning, which makes Few-Shot
Prompting [34], [35] more effective than Zero-Shot Prompt- 2https://platform.openai.com/docs/guides/gpt/chat-completions-api
ing. Before performing a specific task, Few-Shot prompting 3https://huggingface.co/sampling and proximal policy optimization. While enhancing study[46]demonstratedtheMCQpatternmaynotconsistently
safety, its performance remains competitive with other open- reflectthefinalresponseoutputduetovaryingresponsemodes
source LLMs. ofthemodels.Therefore,weuseregularexpressionstoextract
2) Falcon-7B-Instruct: [41] demonstrated the intrinsic the first output that conforms to the format in the third stage
link between the performance of LLMs and the quality of (ValenceAnalysis).Forexample,ifamodelresponseis:“The
their training data. Consequently, the Falcon-7B-Instruct [20], patient’s valence should be coded as neutral or positive,”
knownforitssuperiorperformance,wastrainedonthemeticu- we extract the first matching token “neutral” as the model
louslycuratedRefinedWeb[41]dataset.Tofurtherenhanceits prediction.Ifthemodelsdonotfollowtheinstructions,leading
efficiencyandreducecomputationaloverhead,Falconemploys to no tokens in the output matching any labels, in this case,
multi-query and flash attention [42] mechanisms, enables it to we randomly select a label. Furthermore, the models we
support sequences up to 2,048 tokens. selectedarealignedtoensuretheiroutputsareconsistentwith
3) Mistral-7B-Instruct: Mistral-7B-Instruct [21], an human professional guidelines. But, this occasionally triggers
instruction-tuned version of the Mistral model checkpoint, the Content Safety Policy when generating content related to
leverages the capabilities of Grouped-Query Attention and psychotherapy. Therefore, we opted to exclude those samples
Sliding Window Attention to expedite inference processes that trigger this policy. These special treatments reduce the
and handle longer sequences. Compared to LLMs with an errors caused by the uncertainty of the generated model and
equivalent number of parameters, Mistral performs better improve the reliability of the research.
in various domains, including Commonsense Reasoning,
Reading Comprehension, and Mathematics.
V. RESULTS
4) ChatGPT: ChatGPT [22] represents an evolution in Due to the data imbalance shown in Table II, we chose
the Generative Pre-trained Transformer (GPT) series, with Micro-averaged F1 and Macro-averaged F1 scores for our
a focus on conversational capabilities. It showcases superior evaluation.Micro-averagedF1assessesoverallaccuracy,while
language understanding and generation abilities, excelling Macro-averaged F1 handles label imbalance by giving equal
in benchmarks like SuperGLUE [43] and HumanEval [44], weight to all classes. These metrics offer a comprehensive
which require deep contextual insight and logical coherence. viewofourChain-of-Interactionapproach’sperformance,both
It also integrates reinforcement learning from human feed- for comparing it against baseline methods and for conducting
back (RLHF) [11], [39], [40], allowing it to generate more an ablation study.
contextuallyappropriateandhuman-likeresponsesindialogue
A. Main Results
scenarios.
Table III presents performance results for different prompt-
C. Sampling Strategy and Experiment Details
ing methods applied to the MI behavioral coding task across
To ensure stable and high-quality output, we adhere to the various large language models (LLMs). The results show that
default sampling strategies specific to each LLM. For Chat- our CoI prompting significantly outperforms the state-of-the-
GPT, we utilize GPT-3.5-Turbo via its ChatCompletion API, artpromptingbaselines.Forexample,ourmethodoutperforms
employingNucleusSampling[45]withtop-pandtemperature the second-best approach, Zero-shot Chain-of-Thought [36],
parameters set to 1. This method known for enhancing output in average performance across four LLMs. Specifically, it
diversity by selecting the next word from a restricted set of showsimprovementsof6.3%inMicro-F1and1.3%inMacro-
highly probable options, thus facilitating more creative and F1 score. This superior performance can be attributed to
varied responses. For all other LLMs, we employ Greedy our method’s strategic breakdown of the behavioral coding
Sampling, a strategy that selects the most probable next task into three key stages that leverage domain knowledge.
word, ensuring deterministic and predictable text generation. By segmenting the task into multiple interactive stages, our
Considering the different context length limitations of various approach facilitates step-by-step reasoning and enables the
LLMs, we established a fair comparison by setting the Few- model to navigate the complexities of the task in a structured
Shot N value to 1, which means providing one example and informed way. This progressive reasoning simulates the
beforeeachsample.Additionally,theFew-shotexampleswere layered understanding that a psychological professional may
randomly chosen from the support set to mitigate the risk of employ, leading to more accurate predictions and a more
data leakage. profound interpretation of patient behaviors.
While different baseline prompting methods exhibit signifi-
D. Answer Extraction
cantperformancevariationsacrossvariousLLMs,ourmethod
Theopen-endednatureoflanguagegenerationmakesitvery consistently achieves state-of-the-art results. For instance, the
challengingtoevaluatetheperformanceofLLMsonclassifica- performance of ZeroCoT may be comparable to our proposed
tion tasks. Two generalized evaluation models are to convert CoI method on LLaMA2 but appears closer to the simpler
the classification task into multiple-choice questions (MCQ) Zero-shot prompting on Falcon, highlighting the performance
and then extract the probability of the first token to select the instability of baseline methods. Few-shot prompting improves
label,andtheotheristoextractthecorrespondinganswerfrom performance over Zero-shot on three LLMs, but its impact
the complete answer based on a regular expression. Previous on ChatGPT may be minimal, possibly suggesting its trainingTABLEIII
MAINRESULTSFORTHEBEHAVIORALCODINGTASK,EXPRESSEDINPERCENTAGES.WEBOLDENTHEBESTPERFORMANCE.
Llama2 Falcon Mistral ChatGPT Average
Methods(%)
Micro-F1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1
Zeroshot 42.7 33.6 40.3 31.0 39.6 30.4 52.0 38.0 43.7 33.3
Fewshot 46.5 33.8 43.9 31.1 47.3 33.6 51.9 38.8 47.4 34.3
ZeroCoT 62.6 33.6 40.4 30.9 44.9 31.5 55.6 41.0 50.9 34.3
CoI 63.5 34.5 53.2 32.6 52.0 34.6 60.2 40.5 57.2 35.6
may already include similar tasks. Despite this instability in thattheintegratedstagesofCoIarecrucialforanuancedtask
baselinemethods,ourapproachstandsoutbyconsistentlyout- like MI behavioral coding.
performing them, demonstrating robustness and adaptability
VI. RELATEDWORK
across different LLMs.
A. Automatic Behavioral Coding
B. Ablation Study
Automatic behavior coding is a critical task to examine
To systematically explore the contribution of each stage the fidelity of MI sessions which, if conducted in real time,
in our Chain-of-Interaction (CoI) method, we conduct a se- can have valuable training and clinical applications. Due to
ries of ablation studies and present the results in Table IV. domain-expertise and time-consuming natures of the task, the
These studies start with a baseline scenario, termed Zeroshot, common strategy is to develop a machine learning classifier
where all CoI stages are omitted. This baseline indicates the to predict and assess patient behaviors in MI sessions, such
performance of models without the benefit of any structured as substance disorder [47], suicide [48], and alcohol addic-
CoI stages. Subsequently, we gradually removed Interaction tion [6]. In recent years, neural models have dominated the
Definition stage (w/o ID), Involvement Assessment stage (w/o automaticbehavioralcodingtaskandshowedtheirsupremacy
IA), and Valence Analysis stage (w/o VA). performance than non-neural approaches, such as linguistic
We summarize our results in Table IV. Removing the features [49] and topic models [4]. Existing studies [6], [50]–
InteractionDefinitionstage(w/oID)leadstoLLMsbeginning [52] develop end-to-end classification pipelines by encoding
their subjective rating process about the patient’s emotional patient utterances into neural feature vectors and utilizing the
expression and self-exploration, without fully understanding vectors for predictions by neural classifiers, such as recurrent
the therapist-patient interaction context by the guidance of neural network (RNN). For example, [6], [7], [53] deployed
MISC behavior coding schema. Compared to the full CoI Long-Short Term Memory (LSTM) or Gated Recurrent Unit
method,Micro-F1andMacro-F1decreaseby8.7%and0.9%, (GRU) to enrich contextual representations and [50], [51]
respectively, which reflect the impact of the loss in initial extended the RNN variants (LSTM and GRU) with attention
insightintothedynamicsoftheinteraction.Whenweexclude mechanisms, which identify salient words and patterns in
the Involvement Assessment stage (w/o IA), the LLMs no utterances. More recent studies [28], [52] have switched to
longer mimic the subjective process used by MI professionals pre-trained language models (e.g., BERT [8]) as the data
toassesspatientinvolvement.Inthissetting,LLMsanalyzethe feature extractor and neural network classifier, which requires
patient’sgeneralsentimentandvalencedirectlyafterreasoning additional fine-tuning steps by the annotated MI corpora.
about the specific patterns of interaction between the patient While the behavioral coding task has achieved promising
andthetherapist.Valencewasanalyzedwithoutthehelpofthe performance, lacking explicit incorporation of domain knowl-
patient’s self-exploration and emotional expression, which are edge is a major issue of the existing methods, which can lead
two key indicators of it. The absence results in a decrease of to unreliable performance comparing to human professionals
7.2% in Micro-F1 and 1.7% in Macro-F1 scores compared and get worse when a large amount of training data is not
to the full method. Finally, skipping the general sentiment available. In this study, we fill the domain knowledge issue,
analysis in the Valence Analysis stage (w/o VA) deprives the propose a new prompt learning approach, and employ LLMs
model of fully indications of the patient’s emotional state. for the automatic coding of motivational interviewing, which
This absence can affect the model’s ability to accurately can enable classification models behave as domain experts
code patient behaviors, as it misses out on initial emotional and learn the domain knowledge required for MISC coding
cues that could influence the overall understanding of the as instructions.
patient’s attitude towards change. In this scenario, the average
B. Large Language Models for Mental Health
performance of the LLMs experiences a 1.5% drop in Micro-
F1anda0.3%dropinMacro-F1comparedtothefullmethod. The field of mental health research is witnessing significant
In conclusion, the full CoI method yields the best results, advancements with the integration of LLMs, as illustrated by
showcasing the method’s effectiveness in leveraging domain a series of pioneering studies [54], [55]. Their comprehensive
knowledge to enable the model to perform detailed reasoning. analysis discusses the potential and limitations of LLMs for
Eachstagecontributestoacompositeunderstanding,whichis mental health, covers technologies ranging from pre-training
reflected in the model performance comparisons, confirming to instruction tuning and prompt tuning.TABLEIV
RESULTSOFTHEABLATIONANALYSIS:UTILIZINGMICRO-F1,MACRO-F1,EXPRESSEDINPERCENTAGES
Llama2 Falcon Mistral ChatGPT Average
Methods(%)
Micro-F1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1
Zeroshot 42.7 33.6 40.3 31.0 39.6 30.4 52.0 38.0 43.7 33.3
w/oID 48.4 33.5 43.1 30.6 50.0 33.9 52.5 40.8 48.5 34.7
w/oIA 54.6 33.5 45.7 31.1 43.4 31.2 56.2 39.9 50.0 33.9
w/oVA 62.9 33.9 51.4 32.7 50.1 33.8 58.5 40.6 55.7 35.3
CoI 63.5 34.5 53.2 32.6 52.0 34.6 60.2 40.5 57.2 35.6
Consistent with their exploratory research, both instruc- strated excellent performance on many tasks, and the prompt-
tion tuned and frozen LLMs have been demonstrated to be ing method is a key factor in their performance. Previous
productive in the Mental health domain. When high-quality prompting methods have enabled LLMs to excel in tasks like
data is available, instruction tuning [56], [57] LLMs tends elementary mathematics and other common sense reasoning,
to significantly improve their ability to perform on relevant but they fall short in domain-specific tasks like coding patient
tasks. For example, ChatCounselor [15] and ChatDoctor [58], behaviorthatrequirespecializedknowledgeandemphasizethe
as consulting chatbots, leverage instruction-tuned open-source dyadic contexts.
LLMs to achieve performance levels comparable to GPT- Toaddressthesespecificchallenges,weproposetheChain-
4 [10], while requiring significantly fewer computational re- of-Interaction prompting method, which aims to leverage do-
sources. And [59] conducted instruction tuning on LLMs main knowledge and patient-therapist interactions to enhance
using real-world psychological Q&A sessions, enabling these reasoninginLLMs.Thismethoddecomposesthetaskofcod-
models to acquire psychological knowledge and enhance ing patient utterances in MI into multiple key reasoning steps
their capability to provide counseling services. In scenarios through three sequential stages. It leverages the interaction
where high-quality data is lacking, existing studies usually characteristics between patients and therapists, allowing the
utilize state-of-the-art LLMs to generate synthetic data for large language model to reason using psychological domain
fine-tuning their LLMs. For instance [13] used ChatGPT knowledge about behavioral coding without further training.
to generate instructions for training open-source LLMs, the Onareal-worlddatasetofmotivationalinterviews,wecom-
instruction-tunedmodelsachievedstate-of-the-artperformance pared our proposed Chain-of-Interaction prompting method
on mental health detection tasks. Although the instruction with three other popular prompting methods using four ad-
tuned LLMs are intuitively more effective than the frozen vanced large language models. The results indicate that our
LLMs,thefrozenLLMswithspecialpromptingmethods[16], method achieves state-of-the-art performance. We also con-
[17], [60], [61] can also perform well with mental health ductedanablationanalysis,andtheexperimentalresultsshow
tasks, such as suicidal risk classification [60] and cognitive that removing any stage of the Chain-of-Interaction leads
distortions detection [61]. Specifically, [60] employed three to a significant decrease in performance, demonstrating the
strategies to assess the performance of LLMs on suicidal effectiveness of each stage.
risk classification, including Zero-shot prompting, Few-shot
prompting and instruction tuning. The results show that both VIII. LIMITATION
prompting and instruction tuning can improve the reasoning Inthisstudy,wefocusonuni-modallargelanguagemodels
ability of LLMs. Moreover, [61] introduced the Diagnosis of that are trained only on text, unlike multi-modal models like
Thought (DoT) prompting framework, which is designed to GPT-4V [10] which can also process audio. This limitation
strategically prompt LLMs to generate diagnosis rationales, means that our models cannot leverage audio features from
withaparticularfocusonthedetectionofcognitivedistortions. therapy recordings that have not been transcribed. Addition-
Likewise, our Chain-of-Interaction method focuses on ally, the sensitive nature of privacy in psychotherapy presents
prompting frozen LLMs. Our approach differs from the ex- significant challenges in obtaining experimental data. There-
isting prompting methods of LLMs for mental health studies, fore, our experiments were only conducted using data from
including Zero Chain-of-Thought [36] and [34], [35]. Our a select group of college students who were enrolled in
approach deconstructs reasoning steps grounded in domain- mandatory alcohol cessation interventions.
specificknowledgeandtheinteractionpatternsbetweenpatient
and therapist, while Zero Chain-of-Thought [36] decomposes IX. ETHICSSTATEMENT
based on general knowledge and the Few-shot [34], [35]
Weaccesstherawdatainaccordancewithdataagreements
method relies on in-context learning without considering do-
and underwent required training. Out of respect for ethical
main knowledge derived from coding schema.
and privacy concerns, we will not release any clinical data
that could be linked to individual patients. Instead, we are
VII. CONCLUSION
dedicated to sharing our code and detailed guidelines to
In this study, we focus on the task of automatic coding facilitatethereplicationofourresults.Ourfocusliesprimarily
of patient utterances during MI sessions. LLMs have demon- on computational methodologies, and we do not engage indirect data collection from human subjects. Furthermore, our [13] K. Yang, T. Zhang, Z. Kuang, Q. Xie, S. Ananiadou, and
institution’s review board has verified that our study does not J. Huang, “Mentallama: Interpretable mental health analysis on
social media with large language models,” 2023. [Online]. Available:
require IRB approval.
https://arxiv.org/abs/2309.13567
[14] S. Ji, T. Zhang, L. Ansari, J. Fu, P. Tiwari, and E. Cambria, “Men-
X. ACKNOWLEDGMENT talBERT: Publicly available pretrained language models for mental
healthcare,” in Proceedings of the Thirteenth Language Resources and
We would like to thank Precious Jones (supported by an
EvaluationConference,N.Calzolari,F.Be´chet,P.Blache,K.Choukri,
NSF REU supplement under IIS-2245920) for her contribu- C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard, J. Mariani,
tions in preprocessing the data errors and extracting coding H.Mazo,J.Odijk,andS.Piperidis,Eds. Marseille,France:European
LanguageResourcesAssociation,Jun.2022,pp.7184–7190.
schema from MI coding manuals. We also appreciate the
[15] J.M.Liu,D.Li,H.Cao,T.Ren,Z.Liao,andJ.Wu,“Chatcounselor:
insightful comments of the ICHI-24 anonymous reviewers. A large language models for mental health support,” 2023. [Online].
Available:https://arxiv.org/abs/2309.15461
REFERENCES [16] J. Wei et al., “Chain-of-thought prompting elicits reasoning in
largelanguagemodels,”inAdvancesinNeuralInformationProcessing
[1] W.R.MillerandS.Rollnick,Motivationalinterviewing:Helpingpeople Systems,S.Koyejo,S.Mohamed,A.Agarwal,D.Belgrave,K.Cho,and
change,3rdedition,ser.Applicationsofmotivationalinterviewing. New A.Oh,Eds.,vol.35. CurranAssociates,Inc.,2022,pp.24824–24837.
York,NY,US:GuilfordPress,2013. [Online]. Available: https://proceedings.neurips.cc/paper files/paper/
[2] M. Freeman, “The world mental health report: transforming mental 2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf
health for all,” World Psychiatry, vol. 21, pp. 391–392, 10 [17] Y. Zhou, X. Geng, T. Shen, C. Tao, G. Long, J.-G. Lou, and J. Shen,
2022. [Online]. Available: https://onlinelibrary.wiley.com/doi/10.1002/ “Thread of thought unraveling chaotic contexts,” 2023. [Online].
wps.21018 Available:https://arxiv.org/abs/2311.08734
[3] T. B. Moyers, T. Martin, J. K. Manuel, and W. R. Miller, “The [18] Y.Zhang,M.Zhu,Y.Gong,andR.Ding,“Optimizingsciencequestion
motivational interviewing treatment integrity (miti) code: Version 2.0,” ranking through model and retrieval-augmented generation,” Interna-
2003. tionalJournalofComputerScienceandInformationTechnology,vol.1,
[4] D. C. Atkins, M. Steyvers, Z. E. Imel, and P. Smyth, “Scaling up no.1,pp.124–130,2023.
the evaluation of psychotherapy: evaluating motivational interviewing [19] Z. Jing, Y. Su, Y. Han, B. Yuan, H. Xu, C. Liu, K. Chen, and
fidelityviastatisticaltextclassification,”ImplementationScience,vol.9, M. Zhang, “When large language models meet vector databases: A
p.49,2014. survey,”2024.[Online].Available:https://arxiv.org/abs/2402.01763
[5] M. Tanana, K. A. Hallgren, Z. E. Imel, D. C. Atkins, and [20] E. Almazrouei et al., “The falcon series of open language models,”
V. Srikumar, “A comparison of natural language processing methods 2023.[Online].Available:https://arxiv.org/abs/2311.16867
for automated coding of motivational interviewing,” Journal of [21] A. Q. Jiang et al., “Mistral 7b,” 2023. [Online]. Available:
Substance Abuse Treatment, vol. 65, pp. 43–50, 2016, motivational https://arxiv.org/abs/2310.06825
Interviewing in Substance Use Treatment. [Online]. Available:
[22] OpenAI, “Chatgpt: Optimizing language models for dialogue,” https:
https://www.sciencedirect.com/science/article/pii/S0740547216000222
//openai.com/blog/chatgpt/,2022,accessed:2023-07-24.
[6] X. Huang, L. Liu, K. Carey, J. Woolley, S. Scherer, and B. Borsari,
[23] B.Borsarietal.,“In-sessionprocessesofbriefmotivationalinterventions
“Modeling temporality of human intentions by domain adaptation,”
intwotrialswithmandatedcollegestudents.”Journalofconsultingand
in Proceedings of the 2018 Conference on Empirical Methods in
clinicalpsychology,vol.83,pp.56–67,22015.
Natural Language Processing, E. Riloff, D. Chiang, J. Hockenmaier,
[24] W. R. Miller, T. B. Moyers, D. Ernst, and P. Amrhein, “Manual for
andJ.Tsujii,Eds. Brussels,Belgium:AssociationforComputational
themotivationalinterviewingskillcode(misc)version2.1,”Substance
Linguistics, Oct.-Nov. 2018, pp. 696–701. [Online]. Available:
Abuse and Addiction (CASAA), University of New Mexico, vol. 8, pp.
https://aclanthology.org/D18-1074
901–4,2008.
[7] J. Cao, M. Tanana, Z. Imel, E. Poitras, D. Atkins, and V. Srikumar,
[25] W. R. Miller and G. S. Rose, “Toward a theory of motivational
“Observingdialogueintherapy:Categorizingandforecastingbehavioral
interviewing.”TheAmericanpsychologist,vol.64,pp.527–37,92009.
codes,”inProceedingsofthe57thAnnualMeetingoftheAssociationfor
[26] M. Magill and K. A. Hallgren, “Mechanisms of behavior change in
Computational Linguistics, A. Korhonen, D. Traum, and L. Ma`rquez,
motivational interviewing: do we understand how mi works?” Current
Eds. Florence, Italy: Association for Computational Linguistics, Jul.
opinioninpsychology,vol.30,pp.1–5,122019.
2019, pp. 5599–5611. [Online]. Available: https://aclanthology.org/
P19-1563 [27] K. Mishra, P. Priya, M. Burja, and A. Ekbal, “e-THERAPIST:
[8] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre- I suggest you to cultivate a mindset of positivity and nurture
trainingofdeepbidirectionaltransformersforlanguageunderstanding,” uplifting thoughts,” in Proceedings of the 2023 Conference on
inProceedingsofthe2019ConferenceoftheNorthAmericanChapter Empirical Methods in Natural Language Processing, H. Bouamor,
of the Association for Computational Linguistics: Human Language J. Pino, and K. Bali, Eds. Singapore: Association for Computational
Technologies,Volume1(LongandShortPapers),J.Burstein,C.Doran, Linguistics, Dec. 2023, pp. 13952–13967. [Online]. Available:
andT.Solorio,Eds. Minneapolis,Minnesota:AssociationforCompu- https://aclanthology.org/2023.emnlp-main.861
tationalLinguistics,Jun.2019,pp.4171–4186. [28] T.Tranetal.,“Multimodalanalysisandassessmentoftherapistempathy
[9] L. Tavabi et al., “Multimodal automatic coding of client behavior in in motivational interviews,” in Proceedings of the 25th International
motivational interviewing,” in Proceedings of the 2020 International ConferenceonMultimodalInteraction,ser.ICMI’23. NewYork,NY,
ConferenceonMultimodalInteraction,ser.ICMI’20. NewYork,NY, USA:AssociationforComputingMachinery,2023,p.406–415.
USA:AssociationforComputingMachinery,2020,p.406–413. [29] A. Gagneur, “Respiratory syncytial virus: Motivational interviewing:
[10] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Apowerfultooltoaddressvaccinehesitancy,”CanadaCommunicable
Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat DiseaseReport,vol.46,no.4,p.93,2020.
et al., “Gpt-4 technical report,” 2023. [Online]. Available: https: [30] S.Rollnick,W.R.Miller,C.C.Butler,andM.S.Aloia,“Motivational
//arxiv.org/abs/2303.08774 interviewinginhealthcare:Helpingpatientschangebehavior,”COPD:
[11] Ouyang et al., “Training language models to follow instructions JournalofChronicObstructivePulmonaryDisease,vol.5,pp.203–203,
with human feedback,” in Advances in Neural Information 12008.
Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, [31] S. A. Cole, D. Sannidhi, Y. T. Jadotte, and A. Rozanski, “Using
D. Belgrave, K. Cho, and A. Oh, Eds., vol. 35. New motivational interviewing and brief action planning for adopting and
Orleans, Louisiana: Curran Associates, Inc., 2022, pp. 27730–27744. maintaining positive health behaviors,” Progress in Cardiovascular
[Online]. Available: https://proceedings.neurips.cc/paper files/paper/ Diseases,vol.77,pp.86–94,2023.
2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf [32] W. Wang, V. W. Zheng, H. Yu, and C. Miao, “A survey of zero-shot
[12] H. Touvron et al., “Llama 2: Open foundation and fine-tuned chat learning:Settings,methods,andapplications,”ACMTrans.Intell.Syst.
models,”2023.[Online].Available:https://arxiv.org/abs/2307.09288 Technol.,vol.10,no.2,jan2019.[33] W. Yin, J. Hay, and D. Roth, “Benchmarking zero-shot text [51] J.Gibson,D.Can,P.G.Georgiou,D.C.Atkins,andS.S.Narayanan,
classification: Datasets, evaluation and entailment approach,” in “Attentionnetworksformodelingbehaviorsinaddictioncounseling,”in
Proceedingsofthe2019ConferenceonEmpiricalMethodsinNatural Interspeech2017,18thAnnualConferenceoftheInternationalSpeech
Language Processing and the 9th International Joint Conference on Communication Association, Stockholm, Sweden, August 20-24, 2017,
Natural Language Processing (EMNLP-IJCNLP), K. Inui, J. Jiang, F.Lacerda,Ed. ISCA,2017,pp.3251–3255.
V. Ng, and X. Wan, Eds. Hong Kong, China: Association for [52] J. Gibson, D. C. Atkins, T. A. Creed, Z. Imel, P. Georgiou, and
Computational Linguistics, Nov. 2019, pp. 3914–3923. [Online]. S. Narayanan, “Multi-label multi-task deep learning for behavioral
Available:https://aclanthology.org/D19-1404 coding,”IEEETransactionsonAffectiveComputing,vol.13,no.1,pp.
[34] T. B. Brown et al., “Language models are few-shot learners,” in 508–518,2022.
Proceedingsofthe34thInternationalConferenceonNeuralInformation [53] K.Singla,Z.Chen,D.Atkins,andS.Narayanan,“Towardsend-2-end
Processing Systems, ser. NIPS’20. Red Hook, NY, USA: Curran learning for predicting behavior codes from spoken utterances in
AssociatesInc.,2020. psychotherapy conversations,” in Proceedings of the 58th Annual
[35] X. Liu et al., “Large language models are few-shot health learners,” MeetingoftheAssociationforComputationalLinguistics,D.Jurafsky,
2023.[Online].Available:https://arxiv.org/abs/2305.15525 J. Chai, N. Schluter, and J. Tetreault, Eds. Online: Association
[36] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large for Computational Linguistics, Jul. 2020, pp. 3797–3803. [Online].
language models are zero-shot reasoners,” 2023. [Online]. Available: Available:https://aclanthology.org/2020.acl-main.351
https://arxiv.org/abs/2205.11916 [54] D. Demszky, D. Yang, D. S. Yeager, C. J. Bryan, M. Clapper,
[37] K. Cobbe et al., “Training verifiers to solve math word problems,” S. Chandhok, J. C. Eichstaedt, C. Hecht, J. Jamieson, M. Johnson,
2021.[Online].Available:https://arxiv.org/abs/2110.14168 M.Jones,D.Krettek-Cobb,L.Lai,N.JonesMitchell,D.C.Ong,C.S.
[38] Y.Baietal.,“Constitutionalai:Harmlessnessfromaifeedback,”2022. Dweck,J.J.Gross,andJ.W.Pennebaker,“Usinglargelanguagemodels
[Online].Available:https://arxiv.org/abs/2212.08073 inpsychology,”NatureReviewsPsychology,vol.2,no.11,pp.688–701,
[39] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and 2023.[Online].Available:https://doi.org/10.1038/s44159-023-00241-5
D. Amodei, “Deep reinforcement learning from human preferences,” [55] T. He et al., “Towards a psychological generalist ai: A survey of
in Advances in Neural Information Processing Systems, I. Guyon, current applications of large language models and future prospects,”
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, 2023.[Online].Available:https://arxiv.org/abs/2312.04578
and R. Garnett, Eds., vol. 30. Curran Associates, Inc., 2017. [56] R.Lou,K.Zhang,andW.Yin,“Acomprehensivesurveyoninstruction
[Online]. Available: https://proceedings.neurips.cc/paper files/paper/ following,”2024.[Online].Available:https://arxiv.org/abs/2303.10475
2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf [57] R. Lou and W. Yin, “Toward zero-shot instruction following,” in
[40] N. Stiennon et al., “Learning to summarize with human Proceedings of the 18th Conference of the European Chapter of the
feedback,” in Advances in Neural Information Processing Systems, AssociationforComputationalLinguistics:StudentResearchWorkshop,
H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, N.Falk,S.Papi,andM.Zhang,Eds. St.Julian’s,Malta:Association
Eds., vol. 33. Curran Associates, Inc., 2020, pp. 3008–3021. for Computational Linguistics, Mar. 2024, pp. 50–60. [Online].
[Online]. Available: https://proceedings.neurips.cc/paper files/paper/ Available:https://aclanthology.org/2024.eacl-srw.5
2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf [58] Y. Li, L. Zihan, K. Zhang, D. Ruilong, S. Jiang, and Y. Zhang,
[41] G.Penedoetal.,“Therefinedwebdatasetforfalconllm:Outperforming “Chatdoctor: A medical chat model fine-tuned on a large language
curated corpora with web data, and web data only,” 2023. [Online]. model meta-ai (llama) using medical domain knowledge,” Cureus,
Available:https://arxiv.org/abs/2306.01116 vol. 15, no. 6, 2023. [Online]. Available: https://www.proquest.com/
[42] T. Dao, D. Fu, S. Ermon, A. Rudra, and C. Re´, “Flashattention: scholarly-journals/chatdoctor-medical-chat-model-fine-tuned-on-large/
Fast and memory-efficient exact attention with io-awareness,” in docview/2844019753/se-2
Advances in Neural Information Processing Systems, S. Koyejo, [59] T. Lai et al., “Psy-llm: Scaling up global mental health psychological
S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, services with ai-based large language models,” 2023. [Online].
Eds., vol. 35. Curran Associates, Inc., 2022, pp. 16344–16359. Available:https://arxiv.org/abs/2307.11991
[Online]. Available: https://proceedings.neurips.cc/paper files/paper/ [60] H. Qi et al., “Supervised learning and large language model
2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf benchmarks on mental health datasets: Cognitive distortions and
[43] A. Wang et al., “Superglue: A stickier benchmark for suicidal risks in chinese social media,” 2023. [Online]. Available:
general-purpose language understanding systems,” in Advances https://arxiv.org/abs/2309.03564
in Neural Information Processing Systems, H. Wallach, [61] Z. Chen, Y. Lu, and W. Wang, “Empowering psychotherapy
H. Larochelle, A. Beygelzimer, F. d'Alche´-Buc, E. Fox, and with large language models: Cognitive distortion detection through
R. Garnett, Eds., vol. 32. Curran Associates, Inc., 2019. diagnosis of thought prompting,” in Findings of the Association
[Online]. Available: https://proceedings.neurips.cc/paper files/paper/ for Computational Linguistics: EMNLP 2023, H. Bouamor, J. Pino,
2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf and K. Bali, Eds. Singapore: Association for Computational
[44] M. Chen et al., “Evaluating large language models trained on code,” Linguistics, Dec. 2023, pp. 4295–4304. [Online]. Available: https:
2021.[Online].Available:https://arxiv.org/abs/2107.03374 //aclanthology.org/2023.findings-emnlp.284
[45] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi, “The curious
case of neural text degeneration,” in International Conference
on Learning Representations, 2020. [Online]. Available: https:
//openreview.net/forum?id=rygGQyrFvH
[46] X. Wang et al., “”my answer is c”: First-token probabilities do
not match text answers in instruction-tuned language models,” 2024.
[Online].Available:https://arxiv.org/abs/2402.14499
[47] B. Xiao, C. Huang, Z. E. Imel, D. C. Atkins, P. Georgiou, and S. S.
Narayanan, “A technology prototype system for rating therapist empa-
thy from audio recordings in addiction counseling,” PeerJ Computer
Science,vol.2,p.e59,42016.
[48] Z. L. Inbar and Elyoseph, “Suicide risk assessments through the eyes
of chatgpt-3.5 versus chatgpt-4: Vignette study,” JMIR Ment Health,
vol.10,p.e51232,92023.
[49] D. Can, P. G. Georgiou, D. C. Atkins, and S. S. Narayanan, “A case
study: detecting counselor reflections in psychotherapy for addictions
using linguistic features,” in Proc. Interspeech 2012, 2012, pp. 2254–
2257.
[50] K. Singla et al., “Using prosodic and lexical information for learning
utterance-levelbehaviorsinpsychotherapy.”Interspeech,vol.2018,pp.
3413–3417,92018.