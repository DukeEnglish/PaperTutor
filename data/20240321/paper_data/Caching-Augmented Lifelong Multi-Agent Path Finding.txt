Caching-Augmented Lifelong Multi-Agent Path Finding
Yimin Tang1∗, Zhenghong Yu2∗, Yi Zheng1, T. K. Satish Kumar1, Jiaoyang Li3, Sven Koenig1
Abstract—Multi-AgentPathFinding(MAPF),whichinvolves MAPF-LNS [9], PIBT [10], and LaCAM [11], have been
finding collision-free paths for multiple robots, is crucial in created and applied in practical environments.
various applications. Lifelong MAPF, where targets are reas-
While many studies focus on developing effective algo-
signedtoagentsassoonastheycompletetheirinitialobjectives,
rithms, there is also interest in enhancing the throughput of
offersamoreaccurateapproximationofreal-worldwarehouse
planning. In this paper, we present a novel mechanism named automatedwarehouseswithintheLifelongMAPFframework
Caching-AugmentedLifelongMAPF(CAL-MAPF),designedto by optimizing warehouse layouts. Prominent approaches
improvetheperformanceofLifelongMAPF.Wehavedeveloped include Fishbone design [12], DSAGE [13], and GGO [14].
a new map grid type called cache for temporary item storage
However, these works mainly focus on static storage design
and replacement and designed a lock mechanism for it to
and do not consider input distributions with specific patterns
improvethestabilityoftheplanningsolution.Thiscachemech-
anism was evaluated using various cache replacement policies that may shift over time. To address this issue, some studies
and a spectrum of input task distributions. We identified three have explored intelligent decision-making strategies [15],
main factors significantly impacting CAL-MAPF performance [16], [17]. Notable examples include the Kiva System and
throughexperimentation:suitableinputtaskdistribution,high various policies like the velocity-based policy [16], and
cache hit rate, and smooth traffic. Overall, CAL-MAPF has
mixed-integer optimization and heuristic methods [18]. Yet,
demonstrated potential for performance improvements in cer-
tain task distributions, maps and agent configurations. these methods are designed for specific warehouse systems,
making it difficult to apply them to different warehouse
I. INTRODUCTION
types. They also require implementing complex rearrange-
Automated warehouses represent a multi-billion-dollar in- ment policies for the entire warehouse storage.
dustryledbycorporationssuchasAmazon,Alibaba,Ocado, In this paper, we present a dynamic cache delivery mech-
and inVia. These facilities deploy hundreds of robots to anism named Caching-Augmented Lifelong MAPF (CAL-
transport goods from one location to another [1]. Planning MAPF), inspired by cache design, a foundational element
collision-free solutions for hundreds of robots is a key com- extensively utilized in computer architecture, databases, and
ponent of these automated warehouses, and it can be sim- various other domains. This cache mechanism is adaptable
plified to a Multi-Agent Path Finding (MAPF) problem [2]. to diverse Lifelong MAPF algorithms, warehouse storage
The MAPF problem requires planning collision-free paths strategies, and incoming task distributions. We have de-
for multiple agents from their start locations to pre-assigned veloped a novel map grid type that allows items to be
target locations in a known environment while minimizing a temporarily stored and replaced. Additionally, we design a
givencostfunction.Manyalgorithmshavebeendevelopedto lock mechanism to enhance the stability of the planning
solvethisproblemoptimallyandboundedsuboptimally,such solution. We have evaluated this cache mechanism using
as Conflict-Based Search (CBS) [3], M∗ [4] and Enhanced different cache replacement policies and a range of input
CBS (ECBS) [5]. task distributions. Through experimentation, we identified
Although MAPF is classified as an NP-hard problem [6], three main factors that significantly impact CAL-MAPF
it still represents a simplistic approximation of actual ware- performance: input task distribution, cache hit rate, and map
house planning. It is the ’one-shot’ version of the real design. Overall, CAL-MAPF has demonstrated potential for
application challenge, where an agent only needs to reach performance improvements in certain task distributions and
one target location and remains stationary until every partic- map and agent configurations.
ipant has arrived at their respective targets. To address this
limitation, an advanced version called Multi-Agent Pickup
II. PROBLEMDEFINITION
and Delivery (MAPD) or Lifelong MAPF [7] has been Lifelong Multi-Agent Path Finding (Lifelong MAPF)
introduced.Thisversionreassignstargetstoagentsoncethey problem presents unique challenges due to the dynamic and
complete their initial objectives, better reflecting continuous unending nature of the tasks. Following the terminology in
operationalscenarios.Variousalgorithms,suchasRHCR[8], the MAPF community, we use agents to refer to robots. Let
I = {1,2,··· ,N} denote a set of N agents. G = (V,E)
∗EqualContribution
represents an undirected graph, where each vertex v ∈ V
1University of Southern California, 3650 McClintock Ave, Los
Angeles, CA 90089 {yimintan,yzheng63}@usc.edu, represents a possible location of an agent in the workspace,
tkskwork@gmail.com, skoenig@usc.edu and each edge e ∈ E is a unit-length edge between two
2ShanghaiTech University, 393 Middle Huaxia Road, Shanghai 201210 vertices that moves an agent from one vertex to the other.
yuzhh1@shanghaitech.edu.cn
Self-loopedgesareallowed,whichrepresent“wait-in-place”
3Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA 15213
jiaoyanl@andrew.cmu.edu actions. Each agent i∈I has a unique startlocation s ∈V.
i
4202
raM
02
]OR.sc[
1v12431.3042:viXra0 1 Next, we will introduce specific assumptions in this paper
2
3
4 5 beyond the standard Lifelong MAPF definition. We assume
6
7 8 each shelf S stores an infinite number of only one unique
9
10
1 11 2 type of item. There will be a total of M different types
13
14
15 of items corresponding to the number of shelves. Each
16
17
1 1 28 9 0 unloading port u k is associated with an independent task
21
22 queue Q . Each task q ∈ Q must be delivered to the
2 23 4 k i k
0123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869702 25 6 unloading port U k.
0
1 We will also involve a new type of map grids: caches.
2
3
4 5 6 These additional vertices, designated as C = {c i|c i ∈ V}
7
8 withpurplecolor,serveasinterimstorageareastostreamline
9
10
1 11 2 thefulfillmentoftasksbyreducingthetraveltimeforagents
13
14
1 15 6 retrieving items. To the best of our knowledge, no previous
17
1 18 9 MAPF works have explored this new cache mechanism,
20
21
2 22 3 so we adopt the following simplifying assumptions: (1)
24
2 25 6 The warehouse is considered to have an unlimited supply
012345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970
Fig. 1: Caching-Augmented Map: (1) Blue grids represent Shelves of items, eliminating worries about stock running out. (2)
S. (2) Purple grids represent Caches C. (3) Green grids represent Agents have infinite capacity for carrying items. However,
unloadingportsU.Theuppermaphasmultipleports,whileasingle
they are limited to transporting one type of item at a time,
port is in the bottom one. In the multi-port map, each unloading
enabling them to move any quantity of that specific item
port has an independent cache area, task queue, and agents. The
cache areas are near the unloading ports within ±2 rows. For the without restriction. (3) Items removed or evicted from the
single-portmap,theportcanutilizeallagentsandallcaches.Given cache are treated as if they vanish immediately.
thatthenumberofcachegridscanaffectthecachehitrate,wealso
tested different numbers of cache grids, ranging from 80 to 16, by
removing cache grids column by column from right to left.
III. RELATEDWORK
A. MAPF
(One-Shot) MAPF, which has been proved an NP-hard
AssumethereisantaskqueueQ=[q ,q ,...].Foreachtask
1 2
problem with optimality [6], has a long history [19]. It
q ∈ Q, q represents a certain item located in a reachable
i i
has inspired a wide range of solutions for its related
vertex in V that at least one agent can find a path to the
challenges. Decoupled strategies, as outlined in [19], [20],
vertex. Each item must be delivered to a vertex in V as
[21], approach the problem by independently planning paths
user specifies. These tasks are generated from a specific
for each agent before integrating these paths. In contrast,
probability distribution to enhance realism.
coupled approaches [22], [23] devise a unified plan for all
We study an online setting in which incoming tasks are
agents simultaneously. There also exist dynamically-coupled
not known in advance. It is assumed that there is a task
methods [3], [24] that consider agents that are planned
assigner(externaltolow-levelMAPFalgorithm)fromwhich
independentlyatfirstandthentogetheronlywhenneededin
agents can request target locations throughout the system’s
ordertoresolveagent-agentconflicts.Amongthese,Conflict-
operation. The task assigner determines the specific target
BasedSearch(CBS)algorithm[3]standsoutasacentralized,
locations for agents based on tasks in Q. In our paper,
optimalsolutionforMAPF,withseveralbounded-suboptimal
this task assigner is considered naive and will return target
variants such as ECBS [5] and EECBS [25]. Some subopti-
location based on the first unfinished task in Q. Each agent
mal MAPF solvers, such as Prioritized Planning (PP) [26],
i∈I startsfromastartlocations ∈V anditstargetlocation
i [19], PBS [27], PIBT [10] and their variant methods [28],
depends on the task assigner. As agents complete their
[29], [11], [30] exhibit better scalability and efficiency.
paths at their assigned goals, they are immediately assigned
new targets, reflecting warehouse operations’ perpetual and
B. Lifelong MAPF
iterativenature.Eachactionofagents,eitherwaitinginplace
ormovingtoanadjacentvertex,takesatimeunit.Anagent’s Compared to the MAPF problem, Lifelong MAPF con-
path, pi = [vi,vi,...,vi ], tracks the sequence of vertices tinuously assigns new target locations to agents once they
0 1 Ti
traversed by agent i from its start to its target. have reached their current targets. It is not necessary for
As shown in Figure 1, we primarily focus on 2D ware- agents to arrive at their targets simultaneously in Lifelong
houselayoutmapsandcategorizeallnon-obstaclemapgrids MAPF. There are mainly three kinds of methods: solving
intothreetypes:bluegridsS ={s |s ∈V}forshelvesthat the problem as a whole [31], using MAPF methods but re-
i i
store items, white grids W ={w |w ∈V} for normal aisle planningallpathsateachspecifiedlengthtimestep[8],[10],
i i
grids, and green grids U ={u |u ∈V} for unloading ports and replanning only when agents reach their current target
i i
where agents deliver items to complete a task. Agents can locations and are assigned new targets [32], [33], [11], [30].
enter S positions only from W positions. Direct transitions Among them, MAPF-LNS [9], [29] and LaCAM [11], [30]
between any two positions in S are not allowed. are the leading methods with high task delivery throughput.Orangearrows: Bluearrows: the task item is already stored in the cache grids. If located,
whenstatus is Whenstatus is
finished notfinished the task assigner will direct agents to retrieve the item
0 from the cache grid and deliver it to the unloading port,
or alternatively, the agent may need to collect the item from
the shelves. Subsequently, the item is stored in a cache grid.
4 1 Oncestored,theagentcantransporttheitemfromthecache
to an unloading port.
However, similar to caching in computer architecture,
there is a risk that other agents could replace an item
in the cache before it being retrieved by assigned agents
3 2 in multi-agent scenarios. This situation could result in a
low-level MAPF algorithm, such as LaCAM, generating
unusual collision-free plans at each timestep, causing agents
Fig. 2: Status 0: If the agent’s task item is not in the cache when to move back and forth between two adjacent grids. Thus,
assigned, it must retrieve the item from a shelf. Status 1: If the
a lock mechanism ensures agents can secure an item after
agent’s task item is in cache when assigned, it should retrieve the
confirming its availability in cache grids.
itemfromthecache.Status 2:Ifatleastonewritablecacheexists
when the agent retrieves the item from the shelf, the agent needs To ensure efficient and synchronized access to cache
to insert the item into cache. Status 3: If no writable cache is locations in the CAL-MAPF framework, we implement a
available when an agent gets the item from the shelf, the agent
cache lock mechanism supported by a state machine. This
goes to the unloading port. Status 4: After retrieving or inserting
approach effectively prevents race conditions during cache
the item from/to the cache, the agent heads to the unloading port.
interactions. The mechanism uses read locks for agents
fetchingitemsandwriteslocksforagentsupdatingthecache,
with the state machine managing transitions to maintain
C. Cache
access order and integrity. Every cache grid will have its
Cache [34] serves as a crucial hardware component de-
independent read lock and write lock. This streamlined
signed to temporarily store data, enhancing the efficiency
system guarantees that agents can safely access and modify
of future request processing. Its main goal is to speed
cache contents, facilitating seamless task execution within
up access to frequently used data, thus minimizing depen-
the dynamic warehouse environment.
dence on slower storage disks. Popular caching policies
include Least Recently Used (LRU) [35] and First-In-First-
A. Cache Lock Mechanism
Out (FIFO) [36], with studies indicating LRU’s superiority
over FIFO [37], [38], [39]. The caching concept is widely 1) Lock Types: The cache lock mechanism is designed
appliedinvariousfields,suchasDatabases[40]andContent aroundtwoprincipallocktypes,facilitatingcontrolledaccess
Delivery Networks (CDN) [41]. to the cache locations: (1) Read Lock (Shared Lock): This
type of lock permits an agent to access a cache location
D. Warehouse Storage Strategy
to retrieve items. Multiple agents can simultaneously hold a
Automated Storage and Retrieval Systems (AS/RS) have read lock on a single cache location as long as no write
attracted attention for their potential to enhance warehouse lock is active on that location. This arrangement ensures
efficiency and reduce operational costs [42], [43]. Various that when agents need to retrieve items from the cache, the
strategies for assigning items to storage locations have been item remains unchanged until all agents have successfully
widelyadoptedandevaluated[43],[44].Therandomstorage retrieved it. (2) Write Lock (Exclusive Lock): An agent
policyallocateseachitemtypetoarandomlychosenstorage is required to secure a write lock prior to inserting an item
location and offers high space utilization [45]. The closest intoacachelocation.Writelocksareexclusive,implyingthat
open location storage policy places the arriving unit of once an agent possesses a write lock on a cache location, no
items in the nearest available storage location, minimizing other agent can acquire either a read lock or another write
the immediate travel distance [46], [47]. The turnover-based lock on that location. This ensures that an agent can insert
storage policy assigns storage locations for each item based an item without impacting other agents.
on their demand frequency [16], [17]. 2) LockAcquisitionandRelease: Themechanismdefines
a protocol for lock acquisition and release: (1) Acquisition:
IV. METHOD
To obtain a read lock, an agent must verify that no write
In this section, we introduce our novel Caching- lock is active on the desired cache location. Conversely, to
AugmentedLifelongMAPF(CAL-MAPF)frameworkalong secure a write lock, an agent must confirm that the target
withacachelockmechanism.Considerawarehousescenario cache location is free from any active read or write locks.
as depicted in Figure 1. When the task assigner encounters (2) Release: Agents release read locks after successfully
a new task requiring completion, the first step typically retrieving the goods. Agents release write locks once they
involves determining which location should be allocated to have updated the cache, making the new items available to
an available agent. The task assigner first checks whether others.The cache lock mechanism ensures that no agent needs Algorithm 3 Cache Operation Functions
to return to shelf when its target location is in cache or 1: function RELEASEALLLOCK(agent)
unloading port, no two agents access the same cache block 2: cacheGrid = findCache(agent.startLoc)
concurrently for writing, and multiple agents may read from 3: cacheGrid.item = agent.task
4: cacheGrid.readLock.remove(agent)
the same cache block concurrently if no write lock is active.
5: cacheGrid.writeLock.remove(agent)
Thisconcurrencycontroliscriticaltopreventraceconditions
6: incoming.remove(taskItemId)
and maintain the cache’s consistency. 7: function CHECK(agent)
8: for cacheGrid in cache.allGrids do
Algorithm 1 CAL-MAPF with One Group Overview 9: noWrite = cacheGrid.writeLock.empty()
Input:MapG,InitialLocationsS =s ,TaskQueueQ,AgentsA 10: hasItem = cacheGrid.item == agent.task
i
11: if noWrite and hasItem then
1: portLoc = getPortLoc(G)
12: cacheGrid.readLock.add(agent.id)
2: for agent in agents do
13: return cacheGrid.loc
3: agent.startLoc = s i 14: return portLoc
4: agent.task = Q.pop()
5: agent.targetLoc = getMapLoc(agent.task) 15: function INSERT(agent)
6: agent.status = 0 16: isInCache = cache.findItem(agent)
17: isIncoming = incoming.find(agent.task)
7: while not Q.empty() do
18: if isInCache or isIncoming then
8: plan = MAPF(agents)
19: return portLoc
9: agents.excute(plan)
10: AgentReleaseLocks(agents, cache) 20: cacheGrid = cache.findEmptyCache()
11: AgentGetLocks(agents, cache) 21: if cacheGrid != -1 then
22: cacheGrid.writeLock.add(agent.id)
23: return cacheGrid.loc
24: candidates = sortByCacheEvitedPolicy(cache.allGrids)
Algorithm 2 Task Assigner Functions 25: for cacheGrid in candidates do
26: if cacheGrid.readLock.empty() then
1: function AGENTRELEASELOCKS(agents, cache)
27: if cacheGrid.writeLock.empty() then
2: for agent in agents do
28: incoming.append(agent.task)
3: agent.startLoc = plan.endLoc[agent]
29: cacheGrid.writeLock.add(agent.id)
4: if agent.targetLoc == agent.startLoc then
30: return cacheGrid.loc
5: if agent.status == 1 or 2 then
31: return portLoc
6: agent.status = 4
7: cache.releaseAllLock(agent)
8: agent.targetLoc = portLoc
9: function AGENTGETLOCKS(agents, cache) B. Algorithm
10: for agent in agents do
As shown in Algorithms 1 to 3, the whole procedure is
11: if agent.status == 0 then
12: if agent.targetLoc == agent.startLoc then mainly based on the task assigner which encounters new
13: targetLoc = cache.insert(agent) tasksanddecideswhatlocationsneedtobevisitedbyagents.
14: CheckTarget(agent, targetLoc, 3, 2) As illustrated in Figure 1, CAL-MAPF could have multiple
15: else
unloading ports and we call each unloading port and cache
16: targetLoc = cache.check(agent)
around the port a group. Each group is independent in task
17: CheckTarget(agent, targetLoc, 0, 1)
queue,cachegridsandagents.Agentsinonegroupcanonly
18: continue
19: if agent.status == 3 then accept tasks from this group and use cache grids of this
20: if agent.targetLoc == agent.startLoc then group. Algorithm 1 illustrates the operation of one group.
21: AgentReachPort(agent) Task assigner uses a state machine to control agent status
22: else
andhowtheytransfertoanotherbasedondifferentsituations.
23: targetLoc = cache.insert(agent)
Whenanyagentreachesitstargetlocation,wemustcheckall
24: CheckTarget(agent, targetLoc, 3, 2)
agents, update their status, and assign new target locations.
25: continue
26: if agent.status == 4 then The state machine is illustrated in Figure 2, and the
27: if agent.targetLoc == agent.startLoc then pseudocodeofAlgorithm1outlineshowanagenttransitions
28: AgentReachPort(agent) through five states while executing the low-level MAPF
29: function AGENTREACHPORT(agent) algorithm for one group. The task assigner monitors and
30: agent.task = Q.pop()
updates the status of agents based on the item’s location,
31: targetLoc = cache.check(agent)
the state of the cache, and the agents’ current status. This
32: CheckTarget(agent, targetLoc, 0, 1)
algorithm ensures the efficient completion of all tasks by
33: function CHECKTARGET(agent, targetLoc, statusa, statusb)
34: if targetLoc == portLoc then orchestrating the agents’ paths and their interactions with
35: agent.status = statusa the cache and unloading port.
36: else In Algorithm 1, we first set the status of each agent to
37: agent.status = statusb
0 and assign them initial target locations (Lines 1-6). Next,
38: agent.targetLoc=targetLoc
we obtain collision-free paths for each agent by invoking a
low-level MAPF algorithm. The plan will be executed until100
80
60
40
20
CAL-MAPF Multi-Port CAL-MAPF Single-Port Baseline Multi-Port Baseline Single-Port
0
Fig. 3: The average frequency of agent wait actions on each map grid with 256 agents. It is evident that CAL-MAPF experiences more
severe traffic congestion compared to the baseline.
at least one agent reaches its target location (Lines 7-9). collision-free paths. Both CAL-MAPF and Lifelong MAPF
Upon arrival, the task assigner updates the lock information, wereimplementedinC++,buildinguponpartsoftheexisting
attempts to assign new target locations to available agents, LaCAM codebase.1 All experiments were conducted on a
and updates the status of all agents based on the current system running Ubuntu 20.04.1, equipped with an AMD
warehouse situation (Lines 10-11). Ryzen 3990X 64-Core CPU and 64GB RAM at 2133 MHz.
Taskassignershouldfirstattempttoreleaselockstoallow
A. Test Settings
other agents the opportunity to access cache grids. Status 1
As shown in Figure 1, we designed a warehouse map
is trying to read a cache grid, and Status 2 is going to write.
(27x71) with caches based on our problem definition. The
Only agents in status 1 and status 2 can hold locks. After
map is adapted from the warehouse map of MAPF bench-
reaching their target location, they must go to the unloading
mark [2]. It includes 1600 shelf grids, a maximum of 80
port to deliver items. So, we verify whether these agents
cachegridsand4unloadingports.WetestedtheCAL-MAPF
have reached their targets before releasing their held locks
in both multi-port and single-port scenarios as depicted in
(Algorithm 2 Lines 1-8).
Figure 1. The multi-port scenario has 4 working groups
Then, we evaluate whether other agents can alter their
of unloading ports and cache grids, each with a maximum
status.ForagentsinStatus0,headingtoshelves,weexamine
of 20 cache grids. The single-port scenario maintains the
if they have reached the shelves and gotten items. We then
same number of total cache grids and agents as the multi-
checkiftheycandoawriteoperationinthecacheandapply
port but only has one unloading port. Each shelf grid
a cache replacement policy to select a cache grid. Thus,
represents a unique kind of item, and we randomly assign
Status 0 may transition either to Status 2 (write to cache) or
an index to each shelf grid. The maximum cache-to-shelf
Status 3 (proceed directly to unloading port) (Algorithm 2
ratio is 5%. We test all scenarios with different cache
Lines 9-14). If they have not yet arrived, we check whether
numbers {16, 32, 48, 64, 80} by deleting some cache grids
they can retrieve an item from the cache, which would
in Figure 1. We have also chosen various total numbers
change their status to 1 (read cache) (Algorithm 2 Lines
of agents, {4,8,16,32,64,128,192,256}. In the multi-port
15-18). We do the same status changes for agents in Status
scenario, each group is allocated an equal number of agents
3 and Status 4 as we describe in Figure 2 (Algorithm 2
{1,2,4,8,16,32,48,64}.
Lines 19-28).
Since we can expect the distribution of the task queue
In Algorithm 3, we detail the process of reading or
could significantly affect the performance of cache design,
inserting(writing)anewitemintocachegridsusingacache
we designed three input task distributions to test CAL-
replacement policy. For the read operation, it is necessary to
MAPF, including: (1) M-K distribution (MK): For any
verify if the item exists in the caches and whether there is
consecutive subarray of length M in task queue Q, there
an existing write lock on the cache grid (Algorithm 3 Lines
are at most K different kinds of items. This distribution is
7-14). For the write operation, we first check whether the
inspired by [37], where LRU has been proven to have a
item is already in the cache area or if another agent plans
bound on cache miss rate and to be better than FIFO. This
to insert the same item into the caches (Algorithm 3 Lines
distribution can also represent that there are only several
15-19). Then, we determine if an available cache exists for
items people purchase daily, and some items may become
inserting the item (Algorithm 3 Lines 20-31).
verypopularatonemoment,replacingthepreviouslypopular
V. EXPERIMENTALRESULTS items. (2) 7:2:1 distribution (Zhang): there are 70% kinds
WeuseLifelongMAPFwithoutcacheasabaseline,which of items with only a 10% appearance probability in the
alignswithourproblemdefinition.Toevaluateperformance,
1TheLaCAMsourcecodeispubliclyaccessibleathttps://github.
we compare CAL-MAPF against Lifelong MAPF, utiliz-
com/Kei18/lacam. Our implementation is available at https://
ing LaCAM as the low-level MAPF solver for generating github.com/HarukiMoriarty/CAL-MAPF.
tnuoC
tiaWLRU FIFO RANDOM NONE
Multi-Port Performance Single-Port Performance Multi-Port Performance Single-Port Performance
20000 20000 5750 65 47.5
17500 56 17500 40 5500 60 5200 44 25 .. 50
15000 5515000 38 5250 5000 40.0
12500 12500 5000 55 4800 37.5
10000 5410000 36 4750 50 4600 35.0
7500 53 7500 4500 4400 32.5
5000 5000 34 45 30.0
2500 52 2500 4250 4200 27.5
0 0 32 4000 40 4000
4 8 16 32 64 128192256 4 8 16 32 64 128192256 16 32 48 64 80 16 32 48 64 80
Number of agents Number of agents Number of caches Number of caches
Fig. 4: Makespan (Bar chart, lower is better) and Cache Hit Rate (Line chart, higher is better). LRU, FIFO and RANDOM represent
CAL-MAPF with different cache replacement policies. NONE represents Lifelong MAPF without cache.
task queue, 20% kinds of items with a 20% probability, numberrises,thecachehitratedecreases:Trafficcongestion
and 10% with a 70% appearance probability [48]. (3) Real makes it hard for agents to complete tasks, and writing to
Data Distribution (RDD): we obtain public warehouse data caches becomes more challenging than reading. This nature
from Kaggle2, build a probability distribution based on item resultsincachesstruggllingtoadaptquicklytothechangesif
frequency of Kaggle data, and generate tasks from this thetaskdistributionshifts.Thissecondpointcanalsoclarify
probability distribution. why CAL-MAPF outperforms the baseline as the number of
We randomly generate Q for all distributions with a total caches increases: enlarging the cache area mitigates traffic
length of 1,000. For the MK distribution, we select M = congestion and enhances the cache hit rate.
200 and K values of {1,20,40,80,120,160}. We allocate In Figure 5 and Figure 6, we present the performance
a total of 10 seconds for the low-level MAPF solver to of CAL-MAPF and the baseline across various task dis-
find a collision-free solution for all 1,000 tasks in Q. We tributions. Figure 5 demonstrates that as the number of
show performance using makespan which is the completion caches increases, CAL-MAPF’s performance improves. In
time when the last task has been accomplished. For CAL- the MK distribution, CAL-MAPF outperforms the baseline
MAPF, we use three different cache replacement policies: in most test settings. For the Real and Zhang distribu-
Least Recently Used (LRU), First-In-First-Out (FIFO), and tions, CAL-MAPF’s performance eventually surpasses the
RANDOM.WeuseNONEtorepresentthebaselinemethod. baseline. However, with a limited number of caches or
with a large number of agents, CAL-MAPF shows poor
B. Performance performance in both cache hit rate and makespan within
Many variables can influence CAL-MAPF performance, the Real and Zhang distributions. One possible reason is
including the number of agents, the number of caches, and that the low hit rate leads to agents requiring longer paths
inputtaskdistributions.AsillustratedinFigure4,increasing to complete a task compared to the baseline. As depicted
thenumberofcachesleadstoimprovementsincachehitrate in Figure 6, the hit rate significantly depends on the input
and makespan performance for both single and multi-port task distribution, and the hit rate also greatly affects the
scenarios. In single-port scenario, the cache hit rate initially final makespan performance. Traffic congestion could also
increases and then decreases as the number of agents grows, contributing to CAL-MAPF’s poor performance in some
whereas it continues to increase in multi-port scenario. It is test settings. Figure 3 illustrates the average frequency of
alsoobservedthatasthenumberofagentsrises,CAL-MAPF agent wait actions on each grid when the number of agents
performance may deteriorate compared to the baseline, even reaches256.ItisevidentthatCAL-MAPFexperiencesmore
though the cache hit rate increases. severe traffic congestion compared to the baseline. This also
Three reasons could contribute to this scenario: (1) CAL- helpsexplainwhy,despiteanot-so-lowcachehitrate,CAL-
MAPF’s makespan performs worse than the baseline with MAPF’s performance falls below the baseline when dealing
too many agents: traffic congestions occur near the cache withalargenumberofagents,suchastheperformancewith
area and unloading port as the number of agents increases. Real and Zhang distributions in Figure 5.
(2)Thecachehitrateinitiallyriseswiththeincreaseinagent Ahighcachehitrateandsmoothtrafficarecrucialforthe
numbers:Weusealockmechanismtomaintainitemsstored performance of CAL-MAPF. To enhance the cache hit rate,
in the cache area. As more agents are involved, the total we can increase the number of caches and agents. However,
number of ongoing tasks increases. Since we use a shared both methods come with their drawbacks. The number of
lockforreadoperationandanexclusivelockforwrite,agents caches is constrained by the space available close to the
havemorechancestogetareadlockratherawritelock.This unloading port. Introducing more agents may lead to severe
leads to an increase in the cache hit rate. (3) As the agent traffic congestion, ultimately causing the hit rate to drop.
Nevertheless, there are potential solutions to mitigate these
2kaggle.com/datasets/felixzhao/productdemandforecasting adverse effects, such as implementing more efficient map
napsekaM etaR
tiH
ehcaCLRU FIFO RANDOM NONE
Goal Generate Type: MK Goal Generate Type: Real Goal Generate Type: Zhang
5600 6500 40 5000 55
5400 55 6000 35 4800 50
5200
50
5000 5500 4600 45
30
4800
45 5000 4400 40
4600 25
4400 35
40 4500 4200
4200 20
30
4000 4000 4000
16 32 48 64 80 16 32 48 64 80 16 32 48 64 80
Number of caches Number of caches Number of caches
36 47
20000 50.5 20000 16000
17500 50.0 17500 34 14000 46
15000 49.5 15000 32 12000 45
12500 49.0 12500 30 10000 44
10000 48.5 10000 8000 43
28
7500 48.0 7500 6000 42
5000 47.5 5000 26 4000 41
2500 47.0 2500 24 2000 40
0 46.5 0 0 39
4 8 16 32 64 128 192 256 4 8 16 32 64 128 192 256 4 8 16 32 64 128 192 256
Number of agents Number of agents Number of agents
Fig. 5: Makespan (Bar chart, lower is better) and Cache Hit Rate (Line chart, higher is better). As the number of caches increases,
CAL-MAPF’sperformanceimproves.IntheMKdistribution,CAL-MAPFoutperformsthebaselineinmosttestsettings.FortheRealand
Zhangdistributions,CAL-MAPF’sperformanceeventuallysurpassesthebaseline.However,withalimitednumberofcachesorwithlarge
number of agents, CAL-MAPF shows poor performance in both cache hit rate and makespan within the Real and Zhang distributions.
Goal Generate Type: MK computer architecture.
LRU FIFO RANDOM NONE
7000 VI. CONCLUSION
90
This work presents a novel mechanism, named Caching-
6000
80 Augmented Lifelong MAPF (CAL-MAPF), designed to im-
5000 70 prove the performance of Lifelong MAPF. We have de-
veloped a new map grid type called cache for temporary
4000 60
itemstorageandreplacement.Additionally,wehavedevised
50
3000 a lock mechanism for caches to improve the stability of
40 the planning solution. This cache mechanism was evaluated
2000
30 using various cache replacement policies and a spectrum
1000 20 of input task distributions. Through experimentation, we
identified three main factors that significantly impact CAL-
0 10
1 20 40 80 120 160 MAPF performance: suitable input task distribution, high
K (M=200)
cache hit rate, and smooth traffic. Overall, CAL-MAPF
Fig. 6: Makespan (Bar chart, lower is better) and Cache Hit Rate
hasdemonstratedpotentialforperformanceimprovementsin
(Line chart, higher is better). The hit rate significantly depends on
certain task distributions and map and agent configurations.
the input task distribution, and the hit rate also greatly affects the
final makespan performance. REFERENCES
[1] P.R.Wurman,R.D’Andrea,andM.Mountz,“Coordinatinghundreds
ofcooperative,autonomousvehiclesinwarehouses,”ArtificialIntelli-
designs [13] and using one-way systems near the cache and gence,vol.29,no.1,pp.9–9,2008.
unloadingports[14].Additionally,aswecurrentlyemploya [2] R.Stern,N.Sturtevant,A.Felner,S.Koenig,H.Ma,T.Walker,J.Li,
D.Atzmon,L.Cohen,T.Kumaretal.,“Multi-agentpathfinding:Defi-
simple task assignment policy, we could implement a more
nitions,variants,andbenchmarks,”inProceedingsoftheInternational
advanced policy with predictive capabilities, leveraging real SymposiumonCombinatorialSearch(SoCS),vol.10,no.1,2019,pp.
warehouse task data to enhance the cache hit rate. The 151–158.
[3] G.Sharon,R.Stern,A.Felner,andN.R.Sturtevant,“Conflict-based
cache replacement policies, such as LRU and FIFO, may be
searchforoptimalmulti-agentpathfinding,”ArtificialIntelligence,vol.
overly simplistic for CAL-MAPF. Incorporating more com- 219,pp.40–66,2015.
plex policies, including learning-based approaches, could [4] G.WagnerandH.Choset,“M*:Acompletemultirobotpathplanning
algorithmwithperformancebounds,”in2011IEEE/RSJinternational
further improve the cache hit rate, especially since CAL-
conferenceonintelligentrobotsandsystems. IEEE,2011,pp.3260–
MAPF allows more planning time then traditional caches in 3267.
napsekaM
napsekaM
napsekaM
etaR
tiH
ehcaC
etaR
tiH
ehcaC
etaR
tiH
ehcaC[5] M. Barer, G. Sharon, R. Stern, and A. Felner, “Suboptimal variants [28] S.-H.Chan,R.Stern,A.Felner,andS.Koenig,“Greedypriority-based
oftheconflict-basedsearchalgorithmforthemulti-agentpathfinding searchforsuboptimalmulti-agentpathfinding,”inProceedingsofthe
problem,”inProceedingsoftheInternationalSymposiumonCombi- International Symposium on Combinatorial Search (SoCS), vol. 16,
natorialSearch(SoCS),2014. no.1,2023,pp.11–19.
[6] J. Yu and S. LaValle, “Structure and intractability of optimal multi- [29] J. Li, Z. Chen, D. Harabor, P. J. Stuckey, and S. Koenig, “Mapf-
robotpathplanningongraphs,”inProceedingsoftheAAAIConference lns2: fast repairing for multi-agent path finding via large neighbor-
onArtificialIntelligence(AAAI),vol.27,no.1,2013,pp.1443–1449. hood search,” in Proceedings of the AAAI Conference on Artificial
[7] H. Ma, J. Li, T. S. Kumar, and S. Koenig, “Lifelong multi-agent Intelligence(AAAI),vol.36,no.9,2022,pp.10256–10265.
pathfindingforonlinepickupanddeliverytasks,”inProceedingsof [30] K.Okumura,“Engineeringlacam∗:Towardsreal-time,large-scale,and
the International Conference on Autonomous Agents and Multiagent near-optimalmulti-agentpathfinding,”arXivpreprint,2023.
Systems(AAMAS),2017,p.837–845. [31] V. Nguyen, P. Obermeier, T. Son, T. Schaub, and W. Yeoh, “Gener-
[8] J.Li,A.Tinka,S.Kiesel,J.W.Durham,T.S.Kumar,andS.Koenig, alized target assignment and path finding using answer set program-
“Lifelong multi-agent path finding in large-scale warehouses,” in ming,” in Proceedings of the International Symposium on Combina-
ProceedingsoftheAAAIConferenceonArtificialIntelligence(AAAI), torialSearch(SoCS),vol.10,no.1,2019,pp.194–195.
vol.35,no.13,2021,pp.11272–11281. [32] M.Cˇáp,J.Vokˇrínek,andA.Kleiner,“Completedecentralizedmethod
[9] J. Li, Z. Chen, D. Harabor, P. J. Stuckey, and S. Koenig, “Anytime for on-line multi-robot trajectory planning in well-formed infrastruc-
multi-agentpathfindingvialargeneighborhoodsearch,”inProceed- tures,”inProceedingsoftheInternationalConferenceonAuto-mated
ings of the International Joint Conference on Artificial Intelligence PlanningandScheduling(ICAPS),vol.25,2015,pp.324–332.
(IJCAI),2021,pp.4127–4135. [33] F. Grenouilleau, W.-J. Van Hoeve, and J. N. Hooker, “A multi-
[10] K. Okumura, M. Machida, X. Défago, and Y. Tamura, “Priority labela*algorithmformulti-agentpathfinding,”inProceedingsofthe
inheritance with backtracking for iterative multi-agent path finding,” International Conference on Auto- mated Planning and Scheduling
ArtificialIntelligence,vol.310,p.103752,2022. (ICAPS),vol.29,2019,pp.181–185.
[11] K. Okumura, “Lacam: Search-based algorithm for quick multi-agent [34] A.W.Burks,H.H.Goldstine,andJ.VonNeumann,“Preliminarydis-
pathfinding,” in Proceedings of the AAAI Conference on Artificial cussionofthelogicaldesignofanelectroniccomputinginstrument,”
Intelligence(AAAI),vol.37,no.10,2023,pp.11655–11662. inTheoriginsofdigitalcomputers:Selectedpapers. Springer,1946,
[12] K. R. Gue and R. D. Meller, “Aisle configurations for unit-load pp.399–413.
warehouses,”IIETransactions,vol.41,no.3,pp.171–182,2009. [35] J. McCabe, “On serial files with relocatable records,” Operations
[13] Y.Zhang,M.C.Fontaine,V.Bhatt,S.Nikolaidis,andJ.Li,“Multi- Research,vol.13,no.4,pp.609–618,1965.
robot coordination and layout design for automated warehousing,” [36] W. F. K. III, “Analysis of paging algorithms,” in in Proceedings of
in Proceedings of the International Joint Conference on Artificial InternationalConferenceonInformationProcessing(IFIP)Congress,
Intelligence(IJCAI),2023,pp.5503–5511. 1971,pp.485–490.
[14] Y.Zhang,H.Jiang,V.Bhatt,S.Nikolaidis,andJ.Li,“Guidancegraph [37] S. Albers, L. M. Favrholdt, and O. Giel, “On paging with locality
optimization for lifelong multi-agent path finding,” arXiv preprint of reference,” in ACM Symposium on Theory of Computing (STOC),
arXiv:2402.01446,2024. 2002,pp.258–267.
[15] C. S. Tang and L. P. Veelenturf, “The strategic role of logistics in [38] A. Dan and D. Towsley, “An approximate analysis of the lru and
the industry 4.0 era,” Transportation Research Part E: Logistics and fifo buffer replacement schemes,” in Proceedings of the 1990 ACM
TransportationReview,vol.129,pp.1–11,2019. SIGMETRICSconferenceonMeasurementandmodelingofcomputer
[16] R.Yuan,S.C.Graves,andT.Cezik,“Velocity-basedstorageassign-
systems,1990,pp.143–152.
mentinsemi-automatedstoragesystems,”ProductionandOperations [39] M. Chrobak and J. Noga, “Lru is better than fifo,” Algorithmica,
Management(POM),vol.28,no.2,pp.354–373,2019. vol.23,pp.180–185,1999.
[40] M.Altınel,C.Bornhövd,S.Krishnamurthy,C.Mohan,H.Pirahesh,
[17] X.Li,G.Hua,A.Huang,J.-B.Sheu,T.Cheng,andF.Huang,“Storage
and B. Reinwald, “Cache tables: Paving the way for an adaptive
assignmentpolicywithawarenessofenergyconsumptioninthekiva
database cache,” in Proceedings 2003 VLDB Conference. Elsevier,
mobilefulfillmentsystem,”TransportationResearchPartE:Logistics
2003,pp.718–729.
andTransportationReview,vol.144,p.102158,2020.
[41] M.Harchol-Balter,T.Leighton,andD.Lewin,“Resourcediscoveryin
[18] F.Weidinger,N.Boysen,andD.Briskorn,“Storageassignmentwith
distributed networks,” in Proceedings of the eighteenth annual ACM
rack-moving mobile robots in KIVA warehouses,” Transportation
symposiumonPrinciplesofdistributedcomputing,1999,pp.229–237.
Science(TS),vol.52,no.6,pp.1479–1495,2018.
[42] J.Gu,M.Goetschalckx,andL.F.McGinnis,“Researchonwarehouse
[19] D.Silver,“Cooperativepathfinding,”inProceedingsoftheAAAICon-
operation:Acomprehensivereview,”EuropeanJournalofOperational
ferenceonArtificialIntelligenceandInteractiveDigitalEntertainment
Research(EJOR),vol.177,no.1,pp.1–21,2007.
(AIIDE),vol.1,no.1,2005,pp.117–122.
[43] K.J.RoodbergenandI.F.A.Vis,“Asurveyofliteratureonautomated
[20] R. J. Luna and K. E. Bekris, “Push and swap: Fast cooperative
storage and retrieval systems,” European Journal of Operational
path-finding with completeness guarantees,” in Proceedings of the
Research(EJOR),vol.194,no.2,pp.343–362,2009.
InternationalJointConferenceonArtificialIntelligence(IJCAI),2011,
[44] K. Azadeh, R. de Koster, and D. Roy, “Robotized and automated
pp.294–300.
warehousesystems:Reviewandrecentdevelopments,”Transportation
[21] K.-H.C.WangandA.Botea,“Fastandmemory-efficientmulti-agent
Science(TS),vol.53,no.4,pp.917–945,2019.
pathfinding,”inProceedingsoftheInternationalConferenceonAuto-
[45] B. C. Park, “An optimal dwell point policy for automated stor-
matedPlanningandScheduling(ICAPS),2008,pp.380–387.
age/retrieval systems with uniformly distributed, rectangular racks,”
[22] T. Standley, “Finding optimal solutions to cooperative pathfinding
Internationaljournalofproductionresearch,vol.39,no.7,pp.1469–
problems,” in Proceedings of the AAAI Conference on Artificial
1480,2001.
Intelligence(AAAI),vol.24,no.1,2010,pp.173–178.
[46] M. Fukunari and C. Malmborg, “A heuristic travel time model for
[23] T. Standley and R. Korf, “Complete algorithms for cooperative
randomstoragesystemsusingclosestopenlocationloaddispatching,”
pathfindingproblems,”inProceedingsoftheInternationalJointCon-
InternationalJournalofProductionResearch,vol.46,no.8,pp.2215–
ferenceonArtificialIntelligence(IJCAI),2011,pp.668–673.
2228,2008.
[24] G.WagnerandH.Choset,“Subdimensionalexpansionformultirobot
[47] J.-P. Gagliardi, J. Renaud, and A. Ruiz, “On storage assignment
pathplanning,”Artificialintelligence,vol.219,pp.1–24,2015.
policiesforunit-loadautomatedstorageandretrievalsystems,”Inter-
[25] J.Li,W.Ruml,andS.Koenig,“Eecbs:Abounded-suboptimalsearch
nationalJournalofProductionResearch,vol.50,no.3,pp.879–892,
formulti-agentpathfinding,”inProceedingsoftheAAAIConference
2012.
on Artificial Intelligence (AAAI), vol. 35, no. 14, 2021, pp. 12353–
[48] Y. Zhang, “Correlated storage assignment strategy to reduce travel
12362.
distance in order picking,” IFAC-PapersOnLine, vol. 49, no. 2, pp.
[26] M. Erdmann and T. Lozano-Perez, “On multiple moving objects,”
30–35,2016.
Algorithmica,vol.2,pp.477–521,1987.
[27] H.Ma,D.Harabor,P.J.Stuckey,J.Li,andS.Koenig,“Searchingwith
consistentprioritizationformulti-agentpathfinding,”inProceedings
of the AAAI Conference on Artificial Intelligence (AAAI), vol. 33,
no.01,2019,pp.7643–7650.