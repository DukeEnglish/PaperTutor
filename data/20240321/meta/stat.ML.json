[
    {
        "title": "An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations",
        "authors": "Charles C. MargossianLoucas Pillaud-VivienLawrence K. Saul",
        "links": "http://arxiv.org/abs/2403.13748v1",
        "entry_id": "http://arxiv.org/abs/2403.13748v1",
        "pdf_url": "http://arxiv.org/pdf/2403.13748v1",
        "summary": "Given an intractable distribution $p$, the problem of variational inference\n(VI) is to compute the best approximation $q$ from some more tractable family\n$\\mathcal{Q}$. Most commonly the approximation is found by minimizing a\nKullback-Leibler (KL) divergence. However, there exist other valid choices of\ndivergences, and when $\\mathcal{Q}$ does not contain~$p$, each divergence\nchampions a different solution. We analyze how the choice of divergence affects\nthe outcome of VI when a Gaussian with a dense covariance matrix is\napproximated by a Gaussian with a diagonal covariance matrix. In this setting\nwe show that different divergences can be \\textit{ordered} by the amount that\ntheir variational approximations misestimate various measures of uncertainty,\nsuch as the variance, precision, and entropy. We also derive an impossibility\ntheorem showing that no two of these measures can be simultaneously matched by\na factorized approximation; hence, the choice of divergence informs which\nmeasure, if any, is correctly estimated. Our analysis covers the KL divergence,\nthe R\\'enyi divergences, and a score-based divergence that compares $\\nabla\\log\np$ and $\\nabla\\log q$. We empirically evaluate whether these orderings hold\nwhen VI is used to approximate non-Gaussian distributions.",
        "updated": "2024-03-20 16:56:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.13748v1"
    },
    {
        "title": "Probabilistic Forecasting with Stochastic Interpolants and Föllmer Processes",
        "authors": "Yifan ChenMark GoldsteinMengjian HuaMichael S. AlbergoNicholas M. BoffiEric Vanden-Eijnden",
        "links": "http://arxiv.org/abs/2403.13724v1",
        "entry_id": "http://arxiv.org/abs/2403.13724v1",
        "pdf_url": "http://arxiv.org/pdf/2403.13724v1",
        "summary": "We propose a framework for probabilistic forecasting of dynamical systems\nbased on generative modeling. Given observations of the system state over time,\nwe formulate the forecasting problem as sampling from the conditional\ndistribution of the future system state given its current state. To this end,\nwe leverage the framework of stochastic interpolants, which facilitates the\nconstruction of a generative model between an arbitrary base distribution and\nthe target. We design a fictitious, non-physical stochastic dynamics that takes\nas initial condition the current system state and produces as output a sample\nfrom the target conditional distribution in finite time and without bias. This\nprocess therefore maps a point mass centered at the current state onto a\nprobabilistic ensemble of forecasts. We prove that the drift coefficient\nentering the stochastic differential equation (SDE) achieving this task is\nnon-singular, and that it can be learned efficiently by square loss regression\nover the time-series data. We show that the drift and the diffusion\ncoefficients of this SDE can be adjusted after training, and that a specific\nchoice that minimizes the impact of the estimation error gives a F\\\"ollmer\nprocess. We highlight the utility of our approach on several complex,\nhigh-dimensional forecasting problems, including stochastically forced\nNavier-Stokes and video prediction on the KTH and CLEVRER datasets.",
        "updated": "2024-03-20 16:33:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.13724v1"
    },
    {
        "title": "Does Differentially Private Synthetic Data Lead to Synthetic Discoveries?",
        "authors": "Ileana Montoya PerezParisa MovahediValtteri NieminenAntti AirolaTapio Pahikkala",
        "links": "http://arxiv.org/abs/2403.13612v1",
        "entry_id": "http://arxiv.org/abs/2403.13612v1",
        "pdf_url": "http://arxiv.org/pdf/2403.13612v1",
        "summary": "Background: Synthetic data has been proposed as a solution for sharing\nanonymized versions of sensitive biomedical datasets. Ideally, synthetic data\nshould preserve the structure and statistical properties of the original data,\nwhile protecting the privacy of the individual subjects. Differential privacy\n(DP) is currently considered the gold standard approach for balancing this\ntrade-off.\n  Objectives: The aim of this study is to evaluate the Mann-Whitney U test on\nDP-synthetic biomedical data in terms of Type I and Type II errors, in order to\nestablish whether statistical hypothesis testing performed on privacy\npreserving synthetic data is likely to lead to loss of test's validity or\ndecreased power.\n  Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated\nfrom real-world data, including a prostate cancer dataset (n=500) and a\ncardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian\ndistributions. Five different DP-synthetic data generation methods are\nevaluated, including two basic DP histogram release methods and MWEM,\nPrivate-PGM, and DP GAN algorithms.\n  Conclusion: Most of the tested DP-synthetic data generation methods showed\ninflated Type I error, especially at privacy budget levels of $\\epsilon\\leq 1$.\nThis result calls for caution when releasing and analyzing DP-synthetic data:\nlow p-values may be obtained in statistical tests simply as a byproduct of the\nnoise added to protect privacy. A DP smoothed histogram-based synthetic data\ngeneration method was shown to produce valid Type I error for all privacy\nlevels tested but required a large original dataset size and a modest privacy\nbudget ($\\epsilon\\geq 5$) in order to have reasonable Type II error levels.",
        "updated": "2024-03-20 14:03:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.13612v1"
    },
    {
        "title": "AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression",
        "authors": "Zelin HeYing SunJingyuan LiuRunze Li",
        "links": "http://arxiv.org/abs/2403.13565v1",
        "entry_id": "http://arxiv.org/abs/2403.13565v1",
        "pdf_url": "http://arxiv.org/pdf/2403.13565v1",
        "summary": "We consider the transfer learning problem in the high dimensional setting,\nwhere the feature dimension is larger than the sample size. To learn\ntransferable information, which may vary across features or the source samples,\nwe propose an adaptive transfer learning method that can detect and aggregate\nthe feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable\nstructures. We achieve this by employing a novel fused-penalty, coupled with\nweights that can adapt according to the transferable structure. To choose the\nweight, we propose a theoretically informed, data-driven procedure, enabling\nF-AdaTrans to selectively fuse the transferable signals with the target while\nfiltering out non-transferable signals, and S-AdaTrans to obtain the optimal\ncombination of information transferred from each source sample. The\nnon-asymptotic rates are established, which recover existing near-minimax\noptimal rates in special cases. The effectiveness of the proposed method is\nvalidated using both synthetic and real data.",
        "updated": "2024-03-20 12:58:46 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.13565v1"
    },
    {
        "title": "Uncertainty quantification for data-driven weather models",
        "authors": "Christopher BülteNina HoratJulian QuintingSebastian Lerch",
        "links": "http://arxiv.org/abs/2403.13458v1",
        "entry_id": "http://arxiv.org/abs/2403.13458v1",
        "pdf_url": "http://arxiv.org/pdf/2403.13458v1",
        "summary": "Artificial intelligence (AI)-based data-driven weather forecasting models\nhave experienced rapid progress over the last years. Recent studies, with\nmodels trained on reanalysis data, achieve impressive results and demonstrate\nsubstantial improvements over state-of-the-art physics-based numerical weather\nprediction models across a range of variables and evaluation metrics. Beyond\nimproved predictions, the main advantages of data-driven weather models are\ntheir substantially lower computational costs and the faster generation of\nforecasts, once a model has been trained. However, most efforts in data-driven\nweather forecasting have been limited to deterministic, point-valued\npredictions, making it impossible to quantify forecast uncertainties, which is\ncrucial in research and for optimal decision making in applications. Our\noverarching aim is to systematically study and compare uncertainty\nquantification methods to generate probabilistic weather forecasts from a\nstate-of-the-art deterministic data-driven weather model, Pangu-Weather.\nSpecifically, we compare approaches for quantifying forecast uncertainty based\non generating ensemble forecasts via perturbations to the initial conditions,\nwith the use of statistical and machine learning methods for post-hoc\nuncertainty quantification. In a case study on medium-range forecasts of\nselected weather variables over Europe, the probabilistic forecasts obtained by\nusing the Pangu-Weather model in concert with uncertainty quantification\nmethods show promising results and provide improvements over ensemble forecasts\nfrom the physics-based ensemble weather model of the European Centre for\nMedium-Range Weather Forecasts for lead times of up to 5 days.",
        "updated": "2024-03-20 10:07:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.13458v1"
    }
]