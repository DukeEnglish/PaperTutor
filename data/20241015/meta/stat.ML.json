[
    {
        "title": "Linear Convergence of Diffusion Models Under the Manifold Hypothesis",
        "authors": "Peter PotaptchikIskander AzangulovGeorge Deligiannidis",
        "links": "http://arxiv.org/abs/2410.09046v1",
        "entry_id": "http://arxiv.org/abs/2410.09046v1",
        "pdf_url": "http://arxiv.org/pdf/2410.09046v1",
        "summary": "Score-matching generative models have proven successful at sampling from\ncomplex high-dimensional data distributions. In many applications, this\ndistribution is believed to concentrate on a much lower $d$-dimensional\nmanifold embedded into $D$-dimensional space; this is known as the manifold\nhypothesis. The current best-known convergence guarantees are either linear in\n$D$ or polynomial (superlinear) in $d$. The latter exploits a novel integration\nscheme for the backward SDE. We take the best of both worlds and show that the\nnumber of steps diffusion models require in order to converge in\nKullback-Leibler~(KL) divergence is linear (up to logarithmic terms) in the\nintrinsic dimension $d$. Moreover, we show that this linear dependency is\nsharp.",
        "updated": "2024-10-11 17:58:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.09046v1"
    },
    {
        "title": "Analyzing Neural Scaling Laws in Two-Layer Networks with Power-Law Data Spectra",
        "authors": "Roman WorschechBernd Rosenow",
        "links": "http://arxiv.org/abs/2410.09005v1",
        "entry_id": "http://arxiv.org/abs/2410.09005v1",
        "pdf_url": "http://arxiv.org/pdf/2410.09005v1",
        "summary": "Neural scaling laws describe how the performance of deep neural networks\nscales with key factors such as training data size, model complexity, and\ntraining time, often following power-law behaviors over multiple orders of\nmagnitude. Despite their empirical observation, the theoretical understanding\nof these scaling laws remains limited. In this work, we employ techniques from\nstatistical mechanics to analyze one-pass stochastic gradient descent within a\nstudent-teacher framework, where both the student and teacher are two-layer\nneural networks. Our study primarily focuses on the generalization error and\nits behavior in response to data covariance matrices that exhibit power-law\nspectra. For linear activation functions, we derive analytical expressions for\nthe generalization error, exploring different learning regimes and identifying\nconditions under which power-law scaling emerges. Additionally, we extend our\nanalysis to non-linear activation functions in the feature learning regime,\ninvestigating how power-law spectra in the data covariance matrix impact\nlearning dynamics. Importantly, we find that the length of the symmetric\nplateau depends on the number of distinct eigenvalues of the data covariance\nmatrix and the number of hidden units, demonstrating how these plateaus behave\nunder various configurations. In addition, our results reveal a transition from\nexponential to power-law convergence in the specialized phase when the data\ncovariance matrix possesses a power-law spectrum. This work contributes to the\ntheoretical understanding of neural scaling laws and provides insights into\noptimizing learning performance in practical scenarios involving complex data\nstructures.",
        "updated": "2024-10-11 17:21:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.09005v1"
    },
    {
        "title": "Hierarchical Universal Value Function Approximators",
        "authors": "Rushiv Arora",
        "links": "http://arxiv.org/abs/2410.08997v1",
        "entry_id": "http://arxiv.org/abs/2410.08997v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08997v1",
        "summary": "There have been key advancements to building universal approximators for\nmulti-goal collections of reinforcement learning value functions -- key\nelements in estimating long-term returns of states in a parameterized manner.\nWe extend this to hierarchical reinforcement learning, using the options\nframework, by introducing hierarchical universal value function approximators\n(H-UVFAs). This allows us to leverage the added benefits of scaling, planning,\nand generalization expected in temporal abstraction settings. We develop\nsupervised and reinforcement learning methods for learning embeddings of the\nstates, goals, options, and actions in the two hierarchical value functions:\n$Q(s, g, o; \\theta)$ and $Q(s, g, o, a; \\theta)$. Finally we demonstrate\ngeneralization of the HUVFAs and show they outperform corresponding UVFAs.",
        "updated": "2024-10-11 17:09:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08997v1"
    },
    {
        "title": "Optimal Downsampling for Imbalanced Classification with Generalized Linear Models",
        "authors": "Yan ChenJose BlanchetKrzysztof DembczynskiLaura Fee NernAaron Flores",
        "links": "http://arxiv.org/abs/2410.08994v1",
        "entry_id": "http://arxiv.org/abs/2410.08994v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08994v1",
        "summary": "Downsampling or under-sampling is a technique that is utilized in the context\nof large and highly imbalanced classification models. We study optimal\ndownsampling for imbalanced classification using generalized linear models\n(GLMs). We propose a pseudo maximum likelihood estimator and study its\nasymptotic normality in the context of increasingly imbalanced populations\nrelative to an increasingly large sample size. We provide theoretical\nguarantees for the introduced estimator. Additionally, we compute the optimal\ndownsampling rate using a criterion that balances statistical accuracy and\ncomputational efficiency. Our numerical experiments, conducted on both\nsynthetic and empirical data, further validate our theoretical results, and\ndemonstrate that the introduced estimator outperforms commonly available\nalternatives.",
        "updated": "2024-10-11 17:08:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08994v1"
    },
    {
        "title": "Online-to-PAC generalization bounds under graph-mixing dependencies",
        "authors": "Baptiste AbélèsEugenio ClericoGergely Neu",
        "links": "http://arxiv.org/abs/2410.08977v1",
        "entry_id": "http://arxiv.org/abs/2410.08977v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08977v1",
        "summary": "Traditional generalization results in statistical learning require a training\ndata set made of independently drawn examples. Most of the recent efforts to\nrelax this independence assumption have considered either purely temporal\n(mixing) dependencies, or graph-dependencies, where non-adjacent vertices\ncorrespond to independent random variables. Both approaches have their own\nlimitations, the former requiring a temporal ordered structure, and the latter\nlacking a way to quantify the strength of inter-dependencies. In this work, we\nbridge these two lines of work by proposing a framework where dependencies\ndecay with graph distance. We derive generalization bounds leveraging the\nonline-to-PAC framework, by deriving a concentration result and introducing an\nonline learning framework incorporating the graph structure. The resulting\nhigh-probability generalization guarantees depend on both the mixing rate and\nthe graph's chromatic number.",
        "updated": "2024-10-11 16:49:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08977v1"
    }
]