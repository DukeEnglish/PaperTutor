©2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other
uses,inanycurrentorfuturemedia,includingreprinting/republishingthismaterialforadvertisingorpromotional
purposes,creatingnewcollectiveworks,forresaleorredistributiontoserversorlists,orreuseofanycopyrighted
component of this work in other works. DOI: https://doi.org/10.1109/MCE.2024.3387019
2023 1
4202
nuJ
81
]GL.sc[
1v26721.6042:viXraUnsupervised explainable
activity prediction in
competitive Nordic Walking
from experimental data
Silvia García-Méndez Javier Vales-Alonso
CommunicationandInformationTechnologiesDepartment,
Francisco de Arriba-Pérez
TechnicalUniversityofCartagena
Francisco J. González-Castaño
InformationTechnologiesGroup,atlanTTic,UniversityofVigo
Abstract—ArtificialIntelligence(AI)hasfoundapplicationinHumanActivityRecognition(HAR)in
competitivesports.Todate,mostMachineLearning(ML)approachesforHARhavereliedonoffline
(batch)training,imposinghighercomputationalandtaggingburdenscomparedtoonlineprocessing
unsupervisedapproaches.Additionally,thedecisionsbehindtraditionalMLpredictorsareopaqueand
requirehumaninterpretation.Inthiswork,weapplyanonlineprocessingunsupervisedclustering
approachbasedonlow-costwearableInertialMeasurementUnits(IMUs).Theoutcomesgeneratedby
thesystemallowfortheautomaticexpansionoflimitedtaggingavailable(e.g.,byreferees)within
thoseclusters,producingpertinentinformationfortheexplainableclassificationstage.Specifically,
ourworkfocusesonachievingautomaticexplainabilityforpredictionsrelatedtoathletes’activities,
distinguishingbetweencorrect,incorrect,andcheatingpracticesinNordicWalking.Theproposed
solutionachievedperformancemetricsofcloseto100%onaverage.
INTRODUCTION for app-based business models, but wearable sensors
AutomaticHumanActivityRecognition(HAR)[1], are preferred for stringent scenarios that require free-
[2] is a field of great interest for sports research. HAR dom of movement [3]–[5], as it is often the case with
isbasedonthepremisethatbodymovementsproduce sports practice [6].
differentiated patterns of signals that can be collected Current methodologies to evaluate sports perfor-
with sensors such as visual recognition and Inertial mance involve predictive techniques based on statisti-
Measurement Units (IMUs). cal methods. Performance in this setting, however, is
Sensors in the literature on sport HAR can be the joint result of a wide variety of factors, including
broadly divided into three groups: (i) portable devices leveloftraining,physicalcondition,andteaminterac-
orwearables(e.g.,gyroscopesandaccelerometers),(ii) tions[7].Morecomplex,intelligent,methodologiesare
environmental sensors (e.g., cameras and GPS), and thereforeneededtocharacterize,beyondperformance,
(iii) sensors integrated into personal terminals (e.g., specificstatesduringthepracticeofsportortopredict
smartphones).Integratedsensorsarepopularandallow certain events that may lead to injuries [8].
These emerging needs have led to the application
of Artificial Intelligence (AI) such as Machine Learn-
2 IEEEConsumerElectronicsMagazine PublishedbytheIEEEConsumerTechnologySociety 2162-2248©2023IEEEing (ML) [9]. Nevertheless, decisions made by tradi- and non-transitional activities. In contrast, Bulbul et
tional ML predictors are opaque and require human al. (2018) [22] recognized six activities: walking,
interpretation of the reasons underlying the decisions. climbing up and down stairs, sitting, standing, and
ThisworkfocusesonexplainableAI(XAI),arelatively lying down. Zainudin et al. (2018) [23] combined
unexplored field in the area of sport. XAI techniques one-versus-all (OVA) models with a self-adaptive al-
are designed to infer the reasons behind prediction gorithm to select features for sports practice analysis.
outcomes1. In this study, we leverage XAI to provide In addition, Bharti et al. (2019) [24] studied different
automatic interpretations and explanations of the dif- body sensor locations on the extremities for activity
ferentiation between correct, incorrect, and cheating recognition.Gil-Martinetal.(2020)[25]applieddeep
practices in a Nordic Walking case study using low- learning models to annotated data to identify move-
cost IMUs. On a more detailed level, we analyze and ments during activity, while Zhu et al. (2020) [26]
leverage the most relevant features of the ML model predicted athlete performance using an SVM model.
to improve explainability. Adoptingadifferentapproach,Rossietal.(2021)[27]
The rest of this paper is organized as follows. studied injury prevention during training, and Webber
ThesectionRELATEDWORKreviewsrelevantworkon & Rojas (2021) [28] fused data from accelerometer
HAR in sports using supervised and unsupervised ML and gyroscope sensors at sensor, feature, and deci-
techniques.Thesection METHODOLOGYdescribesthe sion levels to apply diverse well-known ML models
solution for explainable unsupervised characterization (DT, k-NN, Linear Discriminant Analysis (LDA) and
of Nordic Walking practice. The section EXPERI- SVM). Although the best results were obtained with
MENTALRESULTS presents the experimental data and decision-level fusion, the authors concluded that the
implementationsusedandtheresultsobtained.Finally, computational power and processing times required
thesection CONCLUSIONS providesoveralldiscussion were unacceptable for a practical HAR system. Zeng
and highlights the future scope of research and study. et al. (2021) [29] predicted effort levels during the
execution of physical activities using acceleration and
RELATED WORK angularvelocitysensorsonthearms,waist,andwrists.
Finally,Zhang&Li(2022)[30]usedneuralnetworks
Numerousresearchworksinthefieldofsporthave
andSVMstoanalyzeathletemovementsandtheimpact
analyzed action and movement [9] as well as fitness
of training equipment.
and performance [10]. Many of these studies use
Unsupervised ML techniques [31], which, when
low-cost commercial IMUs, such as accelerometers,
applicable,arehighlyconvenientastheydonotrequire
gyroscopes, and magnetometers. Examples of outputs
manual tagging and can be used to detect practice
measured include basketball movements [11], tennis
patterns. However, a priori, a specific pattern may be
and table tennis strokes [12], and volleyball training
complextoassigntoaspecificstate(i.e.,sportsexecu-
[13].
tion phase). There are few works on unsupervised ML
The more recent ML solutions employ big-data
techniques in sports. Domingo et al. (2018) [32] ap-
and small-data models. Big-data models are typically
pliedSubsequenceTimeSeries(STS)analysisofdom-
deeplearningmodelsduetothelargevolumesofdata
inant arm acceleration data using K-means clustering
involved [14], [15]. However, data volumes in sports
[33],whileGuetal.(2018)[34]proposedtemporarily
trainingscenariosaregenerallysmall,correspondingto
grouping large volumes of unlabeled data into duly
a single individual and even a single training session.
annotated time points. Conversely, Van Kuppevelt et
Unfortunately, supervised approaches have dominated
al. (2019) [35] applied an unsupervised Hidden Semi-
in HAR [16].
Markov Model to automatically segment and cluster
Supervised methodologies for the analysis of
data from wearable acceleration sensors to infer the
sportspracticeincludeDecisionTrees(DT)[17],Sup-
type of activity performed from the clusters detected.
port Vector Machines (SVM) [18], k-nearest neigh-
Finally, Janarthanan et al. (2020) [36] employed an
bors (k-NN) [19], and ensemble methods such as
unsupervised deep learning-assisted reconstructed en-
boosting, bagging, and stacking [20]. Notably, Noor
coderforsportsactivityrecognition,whileSerantoniet
et al. (2017) [21] differentiated between transitional
al. (2022) [37] used a K-means model to differentiate
betweenoverexertionstagesincardiovascularexercise.
1Available at https://doi.org/10.48550/arXiv.2302.05624, March
2024. Nordic Walking involves complex interactions be-
2023 3tweenvariousbodyparts.Whenperformedincorrectly, A generalistic supervised HAR system must be
it increase the risk of injury and reduces training trainedinadvance.Thisisahuge,costly,andlaborious
effectiveness. A typical observable error in Nordic undertaking involving many practitioners. That said,
Walking, for example, is dragging the tips of the there is a finite known set of well-defined practice
poles over the ground [38]. To prevent cheating, in patterns in certain sports, both in training and compe-
NordicWalkingcompetitions,judgespositionedalong titionscenarios.ThisisthecasewithNordicWalking,
the track evaluate whether participants are purposely wherethesewell-definedpatternsincludecorrectprac-
using incorrect techniques, such as when running in- tice, cheating, and, in the case of coaching, incorrect
stead of walking. Some works on automatic activity practices. We demonstrate that it is possible to cluster
monitoring based on integrated pole sensors, heart thesepatternsveryefficiently,toalevelcomparableto
sensors, and GPS data [39], [40] have used static thatseenwithsupervisedsystems.Then,withminimal
formulae, that is, formulae not involving multivariate burden, it is possible to label just some data samples
or intelligent data analysis such as ML. One clear within each cluster. This would be a quite natural
exception is the work by Derungs et al. (2018) [38], processinNordicWalkingcompetitions.Judgescould
which proposed a supervised regression system to easily tag these references during a race by clicking a
detect incorrect practices based on IMUs placed in button when a practitioner passes by their locations.
sevenfixedbodylocations.Wiktorskietal.(2019)[41] Finally, once the labels are propagated within their
employed Dynamic Time Warping (DTW) and a semi- respective clusters, the data could be re-classified for
supervised approach to differentiate between Nordic explainability. It should be noted that the idea of
Walking and other activities. This is the only example this re-classification is not to improve classification
to our knowledge of the application of a, to an extent, performance (since the clustering stage has already
unsupervised technique to this sport. classified the data samples by propagating reference
Finally, and particularly relevant to the scope of labels) but to apply a supervised tree classification
this work, it should be noted that XAI [42], which methodthat,unlikeclustering,isintrinsicallyexplain-
has been applied to a wide range of applications able.Accordingly,weultimatelyachieveclassification
[43], [44], is largely missing in elite sports [45], at no tagging cost and produce useful explainability
with a few exceptions based on strictly offline (batch) information.
supervised solutions. Examples include explainable The base clustering technique, which generates
game-playprediction[46]andcase-basedreasoningto the labels for the explainability classification stage by
recommend training plans to marathon runners using expanding the limited a posteriori tagging available
avisualdashboard[47].Sunetal.(2020)[48]studied within the clusters, achieves up to 97.68% accuracy.
the trade-off between accuracy and transparency in Supervisedlearningisonlyappliedinthisresearchfor
sports analytics. They employed a tree version of a two purposes: (i) as previously explained, to extract
neural network to generate visual (not natural lan- the relevant features for the explainability module
guage) descriptions of ice hockey and soccer practice with minimal labor, and (ii) as a baseline for the
predictions. Finally, Lisca et al. (2021) [49] applied comparisonsintheexperimentalevaluation.Summing
anextremegradientboostingensemblemodelinbatch up, unsupervised clustering enables automatic tagging
modetoobtainsymbolicinsightsintogoalkeeperkine- expansion, a solution to a prevalent challenge in
matics from a single motion sensor. commercial HAR [51]. This feature is subsequently
leveragedtotrainanautomaticallysupervisedclassifier
RESEARCHCONTRIBUTION for explainability purposes at minimal cost.
To the best of our knowledge, the solution is the HAR is of great interest to consumer electronics
firstworkinsportHARthatappliesexplainabilitytech- in sports and health [52]–[54]. Some representative
niques to infer knowledge from unsupervised small- examples of commercial products are Fibaro2, Fitbit3,
dataanalysisinonlineprocessingmode,takingNordic and Mi Band4. The target consumers of a commercial
Walking as a case study. Unlike batch processing, versionofoursystem,ratherthanindividualpractition-
online processing updates model profiling and clas-
sification with each incoming sample [50]. Therefore, 2Availableathttps://www.fibaro.com,March2024.
the system can be easily deployed in the field without 3Availableathttps://www.fitbit.com,March2024.
imposing a manual burden on operators. 4Availableathttps://www.mi.com/global/miband,March2024.
4 IEEEConsumerElectronicsMagazineers, would be group coaches, course organizers, small duringsessions,evenwithinthesameuser.Nospecial
event organizers, and similar. The implementation care was taken when strapping sensors into place
couldbebasedonlow-costconsumerelectronicsusing during the data-gathering process.
smartphonesandcompactaccelerometersasdescribed
in the EXPERIMENTALRESULTS section. DATACALIBRATION,FEATURE
Table 1 provides a brief comparison of our work ENGINEERING,ANALYSIS&SELECTION
with most of the related previous works discussed in Duringthedataprocessingstage,rawdatagathered
this section. by the wearable sensors are merged and filtered to
ensure high-quality classification and explainability
METHODOLOGY results. There are two fundamental data processing
Figure1showstheschemeofthesolution.Itcom- stages: first data calibration, and then, online process-
prisesthe IMUs(withaccelerometers,gyroscopes,and ing feature engineering and analysis & selection.
magnetometers) placed on wrists, ankles, and poles; a
Data calibration. Noise is a major issue
data processing module composed of data calibration,
when working with analogical signals. HAR
feature engineering and analysis & selection stages;
signals are typically filtered using Finite Im-
and an online processing clustering module, whose
pulse Response (FIR) filters [56], [57]. In
outcome is compared with a supervised classification
this work, we apply an averaging FIR filter
baseline. Moreover, the automatically expanded labels
andproduceotherfeaturesusingfoursliding
from the unsupervised clustering module train a su-
windows of different sizes.
pervised classifier for explainability purposes. Finally,
Different window lengths are set at the
the explainability module provides visual and natural
calibration stage by inspecting the sample
language descriptions of the prediction outcome (i.e.,
intervals between successive minima of the
correct, cheating, or incorrect practices).
sensorsignals. Toguaranteethat atleasttwo
minima are captured per sensor, and given
WEARABLESENSORS
the repetitive limb and pole movements in
Three pairs of wearable IMUs are placed
Nordic Walking, the calibration stage lasts
on the left and right sides of the body
for 90 seconds. Let k be the size of the
(P = {left,right}), specifically, on wrists, ankles,
calibration stage in samples. For each sensor
and poles (L = {wrist,ankle,pole}). Each IMU
signal x , we define v as follows
p,a,s,l p,a,s,l
includes tri-axial (A = {x,y,z}) accelerometers (to
(we will avoid the p,a,s,l sub-indices for
capture the modulus and direction of the movement
clarity unless strictly necessary to explain
accelerations), gyroscopes (to capture the axis
the formulae):
rotation speeds), and magnetometers (to capture the
modulus and direction of the magnetic fields) (S =
Let v , v be sample indexes in [1,k−1],
1 2
{accelerometer,gyroscope,magnetometer}),
and V a subset of sample indexes, such
aux
placed as shown in Figure 2. These IMUs gather
that (1):
movement data from the athletes. According to
Edwards et al. (2019) [55], the maximum average
V ={n∈[1,k−1]|
acceleration in human walking is 4.5 g, so the aux
operation range of the wearable sensors must x[n−1]>x[n]<x[n+1]}
cover this with a reasonable excess margin without v =min(V ) (1)
1 aux
compromising sensitivity.
v =min(V \{v })
2 aux 1
The real-time data from the sensors is used as the
v =v −v
input data for the data processing, online processing 2 1
ML clustering, and explainability modules. Of interest That is, v p,a,s,l is approximately the num-
toconsumerelectronicsisthat,eventhoughthesensors ber of samples between the first two local
are positioned in specific locations on the poles and minimadelimitinganx p,a,s,lactivityinterval
the body, precise placement relative to body parts is in the calibration stage. Let V = {v p,a,s,l},
unnecessary. Our tests showed significant linear and |V| = |P|×|A|×|S|×|L|, and let V′ =
angular displacements of the sensors between and {v′,...,v′ }, v′ ≤ v′ ≤ ... ≤ v′
0 |V|−1 0 1 |V|−1
2023 5Table1. ComparisonwithpreviousresearchonintelligentanalysisofNordicWalkingpractice.
Authorship Approach Stream(online)processing Explainability
Moceraetal.(2018)[39] ✗ ✗
Pierleonietal.(2022)[40] Rules&formulas ✗ ✗
Derungsetal.(2018)[38] SupervisedML ✗ ✗
Wiktorskietal.(2019)[41] Semi-supervisedML ✗ ✗
Oursolution UnsupervisedML ✓ ✓
Figure1. NordicWalkingpracticeassessmentscheme.
Figure2. Arrangementofthe IMUs. A)positionsonbodyandpoles, B)wrist IMU, C)ankle IMU, D)pole IMUs,
E)IMUsizeincm.
6 IEEEConsumerElectronicsMagazinebeasequenceofreorderedindexesofV,that Φ({x}) = {x} if x > t , Φ({x}) = ∅
σ
is, ∀v ∈ V, v ∈ V′, in increasing order. otherwise. At any slot n, n ≥ k, by
Then, the four window lengths w Q1, w Q2, considering the online processed standard
w Q3 and w avg for all sensors are defined as deviations of all possible features at
follows (2), where r min and r max are the that moment, the set of selected features
minimum and maximum data rates for all Sw [n] for online processing prediction
p,a,s,l
sensors used: and training update at that slot is composed
ofΦ(σ({avgw [k],...,avgw [n]})),
p,a,s,l p,a,s,l
w Q1 =⌊2r rm ma inx⌉v ⌊′ 1 4|V|⌉ Φ Φ( (σ σ( ({ Qs wtdw p,a,s, [l k[k ],] ., .. .. ,., st Qd ww p,a,s,l[n [n]} ]) )) ),
,
r i,p,a,s,l i,p,a,s,l
w =⌊2 max⌉v′ i = 1,2,3, and Φ(σ({Fw [k],...,
wQ2 =⌊2rr
mm ain
x⌉v⌊ ′2 4|V|⌉
(2)
F pw ,a,s,l[n])).
p,a,s,l
Q3 r
min
⌊3 4|V|⌉
ONLINEPROCESSING
|V|
w =⌊2r max⌉⌊ 1 (cid:88) v′⌉ Incremental profiling is performed at each slot n,
avg r |V| i
min i=0 using the set of features Sw [n]. Incremental clas-
p,a,s,l
Feature engineering. Once the sificationiscomposedofanumberofsteps,described
sliding windows are selected, online below.
processed features can be calculated
ONLINECLUSTERINGANDUNSUPERVISEDTAG-
∀n > max(w ,w ,w ,w ) (to
Q1 Q2 Q3 avg GING
avoid a cold start) for each sensor x
p,a,s,l Unsupervised clustering is based on the K-means
and window size w: average (avgw ),
p,a,s,l method [33]. The results are evaluated using the best
standard deviation (stdw ), quartile
p,a,s,l possible class mapping, that is, by checking the pos-
values (Qw - Qw ) and maximum
1,p,a,s,l 3,p,a,s,l sible matchings between each cluster discovered and
modulus of the components of the Fast
the target categories and selecting the matching that
Fourier Transform (FFT) (Fw ), as
p,a,s,l maximizes classification success. In practice, it can
follows (3):
be assumed a posteriori that the samples taken near
the (few) judges present during a Nordic Walking
∀w ∈{w ,w ,w ,w }, ∀n≥{w,k}
Q1 Q2 Q3 avg competition are correctly tagged. In this work, this
tagging expansion leads to three class labels, c , c ,
0 1
X[n]={x[n−w+1],...,x[n]}. and c 2, corresponding respectively to correct practice,
cheating, and incorrect practice.
Y[n]={y [n],y [n],...,y [n]}|
0 1 w−1
ONLINE PROCESSING SUPERVISED CLASSIFICA-
y [n]≤y [n]≤...≤y [n],
0 1 w−1
TION BASELINE
where∀x∈X[n], x∈Y[n].
Asabaseline,thefollowingMLalgorithmsareapplied,
based on their good performance in HAR problems in
Qw[n]=y [n] the literature [16], [58], [59].
1 ⌊1w⌉
4
Qw 2[n]=y ⌊2w⌉[n] • Gaussian Naive Bayes (GNB) [60], based on a
4
Qw[n]=y [n] Gaussian distribution, for stream-based classifica-
3 ⌊3w⌉
1
(cid:88)w4 tion with the traditional Naive Bayes (NB) model.
avgw[n]=
w
y i[n] • Hoeffding Adaptive Tree Classifier (HATC) [61],
i=0 an online processing single tree-based model with
stdw[n]=σ(X[n])
a branch performance monitoring mechanism.
Fw[n]=|FFT(X[n])| • Adaptive Random Forest Classifier (ARFC) [62],
∞
(3) a stream-based tree ensemble majority voting with
re-sampling and random feature selection using the
Feature analysis & selection.
concept drift mechanism.
Let t > 0 be a configurable threshold,
σ
and Φ a transformation operator such that The accuracy, precision (micro and macro), recall
2023 7(micro and macro), and elapsed time of these algo- EXPERIMENTAL RESULTS
rithms are calculated with the predictive sequential This section describes the experimental data and
(i.e., prequential evaluation) protocol for online pro- wearable sensors used. Then, it outlines the different
cessing learning [63]. sub-problems in the tests, and finally, it presents and
discusses the implementations and results observed
for data calibration, feature engineering, analysis &
EXPLAINABLE UNSUPERVISED RE- selection,onlineprocessingbaselineandunsupervised
CLASSIFICATION classification, and unsupervised explainability.
The explainability module traverses the estimator de-
cisionpathofan ARFC model(alsousedasoneofthe
supervisedclassificationbaselinealgorithms)toextract EXPERIMENTALDATA
the components of features S pw ,a,s,l[n] ∀w,p,a,s,l, The NWGTI and PAMAP2 data sets were used
∀n > n init = max(w Q1, w Q2, w Q3, w avg), to analyze the system’s performance. NWGTI data
which are all relevant for explainability purposes. The were collected from training sessions involving five
reclassification algorithm in this module is trained Nordic walkers under the guidance of Ignacio García
using tags c 0, c 1, and c 2 resulting from the clus- Pérez, regional Nordic Walking coach of the Gali-
tering stage, which are translated to the class refer- cian Mountaineering Federation, Spain. His expertise
ences available by expanding these references inside in technique and competition refereeing enabled the
the corresponding clusters. Therefore, the clustering identification of correct practices and typical cases
stage is explained from an interpretable ML algo- of incorrect practices and cheating, such as keeping
rithm with automatic unsupervised tagging because the poles off the ground and pole dragging. The
the tags are not manually produced. Let S iw ,p,a,s,l[n] PAMAP2 data set5 was used for further evaluation and
be the i-th feature component, i = 1...6, of the 6- comparison purposes. This data set contains data on
dimensionalvectorSw [n]definedfromthemetrics various physical activities, including Nordic Walking,
p,a,s,l
Qw[n],Qw[n],Qw[n],avgw[n],stdw[n] and Fw[n] and was also used by Wiktorski et al. (2019) [41].
1 2 3
in (3), in this same order. Note that, at slot n, a Duetothestreamingimplementation,twotypesof
component will be only defined if its updated stan- data were used in the different sub-problems consid-
dard deviation exceeds threshold t σ (for example, ered: raw data and engineered features from raw data.
Sw [n]=Qw [n] when Qw [n] > t ).
1,p,a,s,l 1,p,a,s,l 1,p,a,s,l σ
Otherwise, it will be left undefined. In the sequel, • 1. Raw data. Up to 54 features were considered at
undefined components are ignored in the calculations. each slot for the NWGTI data set, prior to feature
Once the ARFC trees are obtained for the current engineering. These features directly corresponded
prediction, all the paths leading to the corresponding to the sensor data available at the time (note that
class are traversed. Frequency ξw [n] of subset the sensors produce data at different rates, as de-
i,p,a,s,l
{Sw [n],n >= n } is the number of times scribed below). Forty features were extracted from
i,p,a,s,l init
the tuple (i,w,p,a,s,l) is used as an index in those the PAMAP2 dataset.Notethateachindividualhad
paths, as shown in Algorithm 1. The default feature three wearable IMUs: one on the chest and one
component selected to display on the visual dash- each on the dominant wrist and dominant ankle.
board is S iw ∗∗ ,p∗,a∗,s∗,l∗[n], (i∗,w∗,a∗,p∗,s∗,l∗) = Each IMU included a temperature sensor, two tri-
argmax (ξw [n]), which becomes the axial accelerometers, a tri-axial gyroscope, a tri-
(i,w,a,p,s,l) i,p,a,s,l
first element of the ordered list Γ[n]. The rest of the axial magnetometer, and a heart rate sensor, which
elementsinthislistarecomponents{Sw [n],n> was only activated on the chest.
i,p,a,s,l
n init} ordered in decreasing order of the frequencies • 2.Engineeredfeaturesfromrawdatainthe NWGTI
taken from ξw [n]. and PAMAP2 data sets as described in the section
i,p,a,s,l
Visual content (feature values from six body sen- METHODOLOGY. DATA CALIBRATION, FEATURE
sors, further divided into three axes and four sliding ENGINEERING,ANALYSIS&SELECTION.
windows)andtextualdescriptions(generatedinnatural
language) of athlete performance are shown, together
with predictions of practice type (correct, incorrect,
and cheating). 5Availableathttps://doi.org/10.24432/C5NW2H,March2024.
8 IEEEConsumerElectronicsMagazineAlgorithm 1: Extraction of relevant features
Data: classifier, prediction, sample // Output of the classification model.
Result: Relevant feature components sorted by frequency.
feature_list=[]
for estimator in classifier do
if prediction=estimator.predict(sample) then
node=estimator[0] // Root node. Node structure:
{feature,threshold,left_branch,right_branch,is_terminal_node}.
while node[is_terminal_node]̸=True do
feature=node[feature]
threshold=node[threshold]
if sample[feature]≤threshold then
node=node[left_branch]
else
feature_list.append(feature)
node=node[right_branch]
end
end
end
end
Γ[n]=feature_components_sorted_by_frequency(feature_list)
return Γ[n]
WEARABLESENSORS each burst consisted of 94348 samples distributed as
As illustrated in Figure 2, six wearable IMUs by indicated in Table 2. The number of feature dimen-
Mbientlab6wereusedtocollectthedatafortheNWGTI sions depended on the data type (raw or engineered),
data. These IMUs comprised tri-axial accelerometers, as explained in the section METHODOLOGY. DATA
gyroscopes, and magnetometers, with respective sam- CALIBRATION, FEATURE ENGINEERING, ANALYSIS
pling rates of 12.5, 25, and 10 Hz. Their maximum &SELECTION.
admissible acceleration was 16 g. Our experiments
showed a maximum acceleration excess of 4.75 g,
Table2. DistributionofsamplesintheNWGTIdatasetfrom
which is within a reasonable margin and indicates
databursts(averagevalues).
adequate sensitivity.
Note that the different IMU sensors collected raw Class Numberofsamples
dataatdifferentrates.Inprinciplethus,theassumption Correctpractice 30722
Cheatingpractice 33330
thatallsensorsaresynchronized,implicitinthesection
Incorrectpractice 30296
METHODOLOGY. DATA CALIBRATION, FEATURE EN-
GINEERING, ANALYSIS & SELECTION, did not hold.
The practical approach used to address this issue was
to set “empty” x p,a,s,l[n] entries to NaN values at The sampling rate for the PAMAP2 data set was
any input interrupt, which were ignored by feature 100Hz, except for the heart rate sensor, which was
computations (including online processing variability 9Hz. As previously mentioned, each IMU in this
calculations). case had two tri-axial accelerometers with respective
Raw data from the 54 sensors available were maximum admissible accelerations of 6g and 16g.
producedduring12-minuteaveragebursts.Onaverage, Thus, their sensitivities were also adequate for our
application. Only Nordic walkers who walked for at
least 250 seconds or users who climbed stairs for at
6Availableathttps://www.bosch-sensortec.com/products/motion-
least 150 seconds. This resulted in 43130 samples
sensors/imus/bmi160 and https://mbientlab.com/store/
metamotionrl,March2024. distributed as indicated in Table 3.
2023 9Table 3. Distribution of samples in the PAMAP2 data set w
Q1
= 14 ± 3, w
Q2
= 19 ± 5 and
(averagevalues). w =25±5.
Q3
Featureengineering.IntheNWGTIdataset,
Class Numberofsamples
each engineered data sample had up to 24
NordicWalking 27974
Climbingstairs 15156 features (the six features in Equation (3) for
each of the four sliding windows) per sensor
source, that is 24×54=1296 features, plus
SUB-PROBLEMS
up to 54 additional features directly corre-
Forbaselinedata,weperformedonlineprocessing
sponding to sensor outputs available at that
supervised classifications with prequential evaluation
moment. Therefore, each engineered data
by predicting, testing, and training the model in this
sample had up to 1350 features at each slot.
specific order. In all cases, data were decimated for
For the PAMAP2 data set, 24×40+40=1000
trainingandtesting.Trainingandtestingwereupdated
features in total were used. These resulted
every ten slots for the NWGTI data set and, due to the
from the 40 raw sensor measurements and
higher sampling rate of 100Hz, every 30 slots for the
the 24 engineered features for each of these
PAMAP2 data set.
measurements. Table 4 details the features
• A.Baselinesupervisedclassificationofthesamples engineered per IMU for the two data sets.
of experimental engineered data (in the sequel, by Feature analysis & selection. The
sample we will refer to all or part of the available VarianceThreshold7 function from
features at the corresponding slot). the River8 package was used to calculate
• B. Baseline shuffled supervised classification: the online processed feature variances in the
samples of experimental engineered data of sub- NWGTI data set and select those exceeding
problem A were partitioned into eight randomly t2 σ = 0.24±0.12 in the raw data analysis
shuffledsubsets.Thisemulatesasituationinwhich and t2 = 0.01 ± 0.01 in the engineered
σ
apersonperformscorrectlyorincorrectlyorcheats data scenario. This threshold was tuned as
at different moments compared to sub-problem A the median of the online processed variance
andshowsthattherearenolong-termdependencies of the features by considering the samples
in the data. of a 60-second interval after the calibration
• C. Baseline stressed supervised classification: the stage. In the raw data analysis, at the last
samples in sub-problem B were decimated again slot of the experiment, 27±4 features were
for training and testing. Thus, training and testing selected on average for sub-problems A,
wereappliedwiththe1/100ratio.Thissub-problem B, and C. The most relevant sensors were
stresses online processing supervised classification the accelerometers and the gyroscopes. In
to check its robustness when reducing the propor- the case of engineered data, also at the
tion of annotated data. last slot, 785 ± 69 features, of a total
• D. Unsupervised explainable classification: sample possible 1296 features were selected for sub
clusters from sub-problem A were used for unsu- problems A and D. The average number of
pervised explainable re-classification. features selected for sub-problems B and
C was 789 ± 59. As in the case of raw
DATACALIBRATION,FEATURE data, the most relevant sensors were the
ENGINEERING,ANALYSIS&SELECTION accelerometersandthegyroscopes.Themost
Data calibration. For the NWGTI data relevant engineered feature was F pw ,a,s,l[n].
set, the calibration method in the section In the PAMAP2 data set, the variance thresh-
METHODOLOGY. DATA CALIBRATION, FEA- old was t2 σ = 8.99±3.28 in the raw data
TURE ENGINEERING, ANALYSIS & SELEC- analysis and t2 σ = 5.86±1.58 in the engi-
TION yielded on average w avg =362±58, neereddatascenario.Intherawdataanalysis,
w = 168 ± 0, w = 282 ± 6 and
Q1 Q2
w = 474 ± 87, once the sensors had
Q3 7Available at https://riverml.xyz/0.11.1/api/feature-
been synchronized with NaN padding. For selection/VarianceThreshold,March2024.
the PAMAP2 data set, w
avg
= 362 ± 58, 8Availableathttps://riverml.xyz/0.11.1,March2024.
10 IEEEConsumerElectronicsMagazineonaverage,23±2featureswereselectedfor
subproblemAand23±1forproblemsBand Listing1.HATChyperparameterrangesandselected
C. In the engineered data analysis, the aver- valuesinbold.
agenumberoffeaturesselectedwas526±32 depth = [50, 100, 150]
for sub problems A and D and 525±31 for tiethreshold = [0.5 , 0.05, 0.005]
sub problems B and C. The most important maxsize = [50, 100, 200]
featureswerethoserelatedtoaccelerometers,
magnetometers, and heart rate sensors. As
with the NWGTI data set, the most relevant
Listing2.ARFChyperparameterrangesandselected
engineered feature was Fw [n].
p,a,s,l valuesinbold.
models = [50, 100, 200]
ONLINEPROCESSINGBASELINEAND features = [50, 100, 200]
UNSUPERVISEDCLASSIFICATION lambda = [50, 100, 200]
The online processing supervised classification
baselinealgorithmswereimplementedwiththe GNB9,
HATC10, ARFC11, and K-means12 libraries from the
A,B,andC,forbothrawdataandengineeredfeatures).
River package.
All entries average the corresponding results for the
Listings 1, 2, and 3 respectively show the ranges
usersessionsintheexperiments.Column“prequential
for hyperparameter optimization (selected values in
time”isthetotaltimeneededtoprocessallthesamples
bold font) for the HATC, ARFC, and K-means models
foreachmodelandsub-problem.Itshouldbechecked
(the GNB model has no hyperparameters to tune). The
against the maximum data rate of the sensors, 25 Hz.
ranges and best values were obtained experimentally
In other words, for a method to be feasible in real-
usinganadhocimplementationoftheGridSearch13
time,itsprequentialtimepersamplemustbelessthan
algorithm for data streams. Engineered data for sub-
40 ms (in our worst-case scenario, it is 3 ms, that is
problem A was down-sampled by a factor of 100 306.35s divided by 94348 samples, about 7.5% of
to perform hyperparameter optimization. The selected
the limit value). It should be noted that all methods
hyperparameters for both data sets were the same for
except K-means are used for obtaining baseline data
HATC and ARFC. For K-means, however, the selected
due to their supervised nature, which is impractical
values for halflife (which is related to centroid
for real use. Thus, in light of the results obtained, K-
optimization) varied depending on the data set. For
means is feasible.
PAMAP2, the selected value within the specified se-
First, it is interesting to observe that sub-problem
quencewas0.77(notshown).Recallthatthegoalwith
Awashighlyseparablewhenonlyrawdatawereused.
this model was to discover three clusters for NWGTI
TheslowestmethodwasARFC,butitwasalsofeasible
and two for PAMAP2 (i.e., n_clusters = 3 or 2).
in streaming mode. As expected, the results of sub-
Table 5 reports standard performance measure-
problem B suggestnolong-termdependence.Forsub-
ments by type of experimental data, sub-problem, and
problem C, the outcome was considerably degraded,
model (tags #1, #2, and #3 correspond to correct,
suggesting that, although the approaches seem robust,
cheating, and incorrect practices, respectively) for the
excessive decimation is not conducive to real-time
NWGTI data set. It allows comparison between our
operation on simple hardware since it compromises
unsupervisedsolution(scenarioDwithengineeredfea-
tures)andthesupervisedlearningbaselines(scenarios
9Available at https://riverml.xyz/dev/api/naive-bayes/ Listing3. K-meanshyperparameterrangesandse-
GaussianNB,March2024.
lectedvaluesinbold.
10Available at https://riverml.xyz/0.13.0/api/tree/
halflife = [0.05 , 0.075, 0.1]
HoeffdingAdaptiveTreeClassifier,March2024. nwgti
11Available at https://riverml.xyz/dev/api/ensemble/ halflife pamap2 = [0.02:0.05:0.8]
AdaptiveRandomForestClassifier,March2024. mu = [0.01, 0.1, 1]
12Available at https://riverml.xyz/0.11.1/api/cluster/KMeans, sigma = [0.001 , 1, 10 ]
nwgti pamap2
March2024.
p = [1, 2]
13Available at https://scikit-learn.org/stable/modules/generated/
sklearn.model_selection.GridSearchCV.html,March2024.
2023 11Table4. Rawandengineered(Eng.)featuresper IMU forthetwodatasetsused.
Dataset ID Name Type
1-3 16gaccelerometeraxes
4-6 Gyroscopeaxes Raw
7-9 Magnetometeraxes
NWGTI Qw,Qw,Qw,avgw,stdw andFw forwin-
1 2 3
10-225 dowswQ1,wQ2,wQ3,wavgforeachsensor Eng.
(1-9above)
1-9 Sameasfeatures1-9ofNWGTIdataset
10-12 6gaccelerometeraxes Raw
13 Heartrate
PAMAP2 14 Temperature
Qw,Qw,Qw,avgw,stdw andFw forwin-
1 2 3
15-350 dowswQ1,wQ2,wQ3,wavgforeachsensor Eng.
(1-14above)
performance. Figures 3 and 4 respectively show online changes
The performance gap between the different meth- in accuracy and cross entropy loss curves for scenario
ods was reduced by introducing engineered data. The D (unsupervised learning) with the NWGTI data set.
most relevant result here, highlighting the value of The accuracy was slightly reduced in the last two-
engineered data, was the significant improvement in thirds of the sequence, but it was still very good. To
sub-problem C, regardless of its low computational calculate the cross entropy loss graph we employed
requirements. For this reason, we decided to test the Equation (4), where E is the number of samples, M
practical, unsupervised approach of sub-problem D thenumberofclasses,andhaone-hotencodedvector
using engineered data. As shown in the last row of (in our experiment, as there exist three classes, if the
Table 5, performance was highly satisfactory, assum- samplecorrespondstothesecondclass,thevectorwas
ing each cluster is assigned to the correct class a (0,1,0)),andρ [n]istheprobabilityofpredictingclass
i
posteriori to ensure minimum tagging. It should be i for the n-th sample). The graph showed a slight
noted that, in a competition scenario, it would not be increase in accumulated error, but note that values
necessarytodeterminewhichofthetwodifferentiated lower than 0.5 are satisfactory given the logarithmic
incorrectbehaviorscorrespondstocheatingandwhich term in the crloss function.
to incorrect practice, since the correct practice cluster
couldbeidentifiedfromthefewpointsalongtheroute 1 (cid:88)E (cid:88)M
where the practitioner passes by a judge. Moreover, a crloss=−
E
h j[i]log(ρ j[i]) (4)
coach could differentiate them using training videos a i j
posteriori.
After sub-problem D, with the inclusion of re-
classification for explainability, the prequential pro-
cessingtimeisthesumofthecorrespondingsuccessive
timesofK-meansandARFC,thatis,224.15ms,which
is still feasible for real-time operation.
Table 6 shows the results obtained with the
PAMAP2dataset.Althoughthisdatasetisdesignedfor
activitydifferentiationnotpracticeassessment(tags#1
and#2correspondtoNordicWalkingandstairclimb-
ing,respectively),thegoodperformanceachievedwith
our solution highlights the good quality of the data
collected in NWGTI. The unsupervised model attained Figure3. AccuracycurvefortheNWGTIdataset.
performance metrics above 90% for Nordic Walking
Finally, Table 7 compares our approach with the
prediction, although the GNB classifier was the best
most closely related work in the literature. The au-
model in this case. Elapsed times were considerably
thors, Derungs et al. (2018) [38], computed the same
reduced due to the fewer samples and classes.
evaluationmetricsinthatworkwerecomputed, RMSE
12 IEEEConsumerElectronicsMagazineTable5. Onlineprocessingpracticeassessmentresults, NWGTI dataset.
Data Sce. Model Accuracy Precision Recall Preq.time(s)
Macro #1 #2 #3 Macro #1 #2 #3
GNB 90.99±7.04 91.86 93.27 93.38 88.93 91.15 94.45 90.30 88.71 1.79
A HATC 96.94±1.80 97.19 97.90 95.75 97.92 96.90 98.38 98.84 93.47 3.07
ARFC 99.03±0.55 99.03 99.83 99.65 97.60 99.02 99.28 98.23 99.55 164.68
Raw GNB 79.87±0.71 80.39 79.49 82.73 78.95 79.43 71.19 87.88 79.22 2.05
B HATC 92.98±2.85 92.95 91.85 93.59 93.42 93.05 94.30 93.19 91.65 3.83
ARFC 88.77±4.39 89.00 83.38 91.45 92.16 88.76 91.97 91.06 83.25 306.35
GNB 75.80±2.31 76.14 73.28 82.31 72.84 75.26 65.49 84.75 75.53 1.87
C HATC 71.92±11.63 71.52 67.08 74.89 72.57 71.25 64.50 83.25 66.00 1.50
ARFC 70.46±9.16 71.25 65.62 72.31 75.82 70.24 70.82 77.90 61.98 139.46
GNB 95.39±2.35 95.55 98.15 96.36 92.15 95.42 93.65 95.67 96.94 38.47
A HATC 93.53±7.13 94.64 89.71 97.48 96.74 93.53 99.36 98.02 83.21 58.55
ARFC 99.36±0.31 99.38 99.59 99.21 99.33 99.36 99.91 99.44 98.74 178.02
GNB 93.25±4.55 93.40 89.79 96.23 94.20 93.13 95.17 94.03 90.20 42.56
Eng. B HATC 92.17±2.64 92.34 91.87 94.46 90.68 92.21 93.93 93.10 89.61 83.36
ARFC 98.79±0.90 98.78 98.88 99.20 98.25 98.75 97.87 99.45 98.92 281.89
GNB 92.44±4.77 92.70 88.40 95.48 94.23 92.31 93.46 93.46 90.01 36.69
C HATC 91.05±5.22 91.32 90.56 91.66 91.75 90.89 91.63 93.02 88.01 45.36
ARFC 97.63±0.66 97.58 97.12 98.52 97.09 97.61 97.32 97.54 97.97 117.57
D Clustering 97.68±0.83 97.70 98.37 98.61 96.14 97.74 98.60 95.84 98.78 46.13
Table6. Onlineprocessingpracticeassessmentresults, PAMAP2 dataset.
Data Sce. Model Accuracy Precision Recall Preq.time(s)
Macro #1 #2 Macro #1 #2
GNB 95.69±4.94 95.23 100.00 90.46 96.57 93.14 100.00 0.21
A HATC 82.74±16.80 86.47 100.00 72.94 86.49 72.98 100.00 0.32
ARFC 98.70±0.67 98.25 100.00 96.49 98.98 97.96 100.00 16.90
GNB 93.13±4.71 92.33 95.98 88.67 93.15 93.09 93.21 0.22
Raw B HATC 86.59±6.32 85.96 87.63 84.28 83.89 92.76 75.01 0.41
ARFC 87.08±2.47 88.21 85.68 90.74 83.24 96.23 70.25 24.47
GNB 90.33±4.77 89.76 91.84 87.69 89.10 93.17 85.03 0.19
C HATC 80.04±12.82 83.61 80.81 86.41 74.93 94.79 55.08 0.16
ARFC 70.97±6.65 70.08 72.27 67.89 63.18 89.96 36.40 10.44
GNB 99.00±0.21 98.62 100.00 97.24 99.23 98.46 100.00 3.61
A HATC 91.93±10.43 92.35 100.00 84.69 93.85 87.70 100.00 6.02
ARFC 96.99±0.72 95.98 100.00 91.97 97.69 95.38 100.00 35.11
GNB 99.27±0.28 99.26 99.33 99.18 99.15 99.55 98.75 3.79
Eng. B HATC 95.87±3.40 95.58 96.58 94.57 95.38 97.27 93.50 7.60
ARFC 96.18±2.71 96.00 96.62 95.38 95.64 97.51 93.77 66.65
GNB 97.25±0.60 97.42 97.00 97.83 96.54 98.81 94.27 3.17
C HATC 89.12±11.57 92.50 87.32 97.68 85.40 99.35 71.45 3.21
ARFC 96.59±2.57 96.38 97.26 95.51 96.13 97.54 94.72 22.12
D Clustering 90.46±11.39 93.57 92.26 94.88 87.97 95.53 80.41 3.40
and MAE. The lower error observed with our system Table7. Comparisonwiththemostrelatedwork.
canbeexplainedbythefactthatDerungsetal.(2018)
Approach RMSE MAE
[38] only considered classifiers as regressors and did
ThisworkonNWGTI 0.18 0.03
not use nominal categories, which we used to explore Derungsetal.(2018)[38] 0.43 0.18
strategies such as the ARFC model. Furthermore, they
groupedsensor dataintoindividual strides,preventing
UNSUPERVISEDEXPLAINABILITY
continuous signal analysis. Finally, this comparison
must be understood as a reference since the approach The ARFC algorithm is the basis for explainabil-
ity once trained with the clusters returned by the
inDerungsetal.[38]wassupervised,andourpremise
online processing unsupervised K-means algorithm.
was to avoid that limitation to the greatest possible
It is based on the Hoeffding tree model [62]. The
extent.
explainability module groups the trees from the ARFC
model by predicted categories. Then, the River
2023 13Listing4. Explainabilitytemplates.
#1 The [component list] value<s> of the
[axis] [sensor] within the [windows list]
window<s> and ... define the decision
path.
#2 The component<s> identified
suggest that the value<s> remain
stable in the [sensor] case.
#3 In the case of the [sensor] a
Figure4.CrossentropylosscurvefortheNWGTIdata
change in the [component] in the last
set.
samples and ... produce<s> the
prediction of [correct/cheating/incorrect]
debug_one ARFC method14 is used to extract the practice .
decision paths traversed, whose features are stored in
lists. The lists are then combined, and the frequency
#4 Moreover , a cheating practice was
with which feature components appear is calculated
detected between [start time] and
as explained in the section EXPLAINABLE UNSUPER- [end time]; the last detected sample
VISEDRE-CLASSIFICATION. At this point, the feature
prediction corresponds to [correct/
components are ranked in decreasing order of rele-
cheating/incorrect] practice with
vance. In Figure 5, the most representative feature
[confidence] confidence .
component to that point, corresponding to the z-axis
of the right wrist accelerometer and the w sliding
Q1
window of the Qw component, is displayed. Other
2
feature components can be selected for display using
once. For each instance, template #1 is updated with
the drop box on the dashboard.
the lists of different components and windows across
The dashboard was designed with TEMPLATED15
the decision path corresponding to the selected tuples.
and its charts with Highcharts16. Figure 5 shows an
Template #2 is applied to all nodes along the decision
automatic explanation of a training session of one of
pathinwhichthe’≤’conditionholdsforacomponent
the Nordic Walking practitioners in our experiments.
whose updated standard deviation is less than t . For
σ
The upper part shows the selected sensor as pre-
each node along the tree path, template #3 is updated
viously defined. The real-time graph for the sensor is
whenever a ’>’ condition holds for the sensor and
shownontheleft,wheregreen,purple,andblueiden-
component considered in that node. Finally, template
tify correct, cheating, and incorrect practices, respec-
#4 identifies the cheating interval, if present, and the
tively.Thedescriptionofthelatestpredictioninnatural
current prediction, including its confidence interval.
language,basedonthe ARFC decisionpath,isthetext
The w , w , w , and w windows de-
Q1 Q2 Q3 avg
inthebottomleftcorner,correspondingtothetreepath
termine the time duration under analysis. When the
displayedinthebottomrightcorner.Theextractedin-
featuresinthedecisionpathdisplayedinthedashboard
formationisintroducedintonaturallanguagetemplates
correspond to the w window (as in the example),
Q1
taken from Listing 4 (where ellipses indicate that the
the value changes are recent. Features corresponding
immediatelyprecedingtextisrepeatedasneeded).Our
to the w window, by contrast, are more spaced
Q3
system follows the tree path of the latest prediction
in time. The Qw, Qw, Qw, avgw, stdw, and Fw
and extracts all associated index tuples (a,s). In case 1 2 3
featuresallowfortheinterpretationofextremevalues.
of repetition, an index tuple (a,s) is only considered
Specifically, a value in Qw would indicate that only
1
25% of the samples have lower values. Fw indi-
14Available at https://riverml.xyz/0.14.0/api/tree/
cates a change in the trend of the movement. The
HoeffdingTreeClassifier,March2024.
15Availableathttps://templated.co,March2024. prediction confidence was obtained using the ARFC
16Availableathttps://www.highcharts.com,March2024. predict_proba_one method. This information is
14 IEEEConsumerElectronicsMagazineFigure5. Screenshotofexplainabilitydashboard.
displayedgraphicallyinthetreeinthebottomrightof wearable inertial sensors. These data were then aug-
the image in Figure 5. mented using data engineering techniques to allow
long processing slots. Experimental testing demon-
strated the appropriateness of the unsupervised learn-
CONCLUSIONS
ing approach, as it achieved a classification accuracy
Evaluationofsportandphysicalactivity,including of close to 100% (note that the experimental eval-
aspects such as performance monitoring and injury uation also considered an alternative data set from
prevention, is a major field of application for AI the literature and showed that our data collection was
HAR techniques. ML-based solutions are helpful for notbiasedtowardimprovingperformanceresults).The
differentiatingbetweenwell-definedstateswithinlarge outcome of the unsupervised learning stage (i.e., the
volumes of data collected using inexpensive portable resulting clusters) yields labels at minimal cost for
sensors such as wearables and smartphones. Unsuper- automatic explainable re-classification. By reducing
vised techniques are very interesting in this context thus the need for laborious manual tagging, without
as they can be used in the design of stand-alone compromising interpretability, our work contributes
systems. Nordic Walking HAR, the core application to solving a common need in HAR for consumer
of this research, aligns well with these assumptions, electronics applications.
and can be used to differentiate between correct and Theautomaticexplanationsgeneratedfortheclas-
incorrect techniques and practices that would result in sificationresultsincludetextualandvisualdescriptions
disqualification. This information would be useful for of athletes’ performance as well as intelligible expla-
practitioners, trainers, and competition judges. nationsofthepredictionsmadebytheMLmodels.The
Intheproposedsolution,supervised(baseline)and ultimateobjectiveistopromotetrust,transparency,and
unsupervised models were trained using data from
2023 15acceptance for AI solutions. 5. F.Bozkurt,“AComparativeStudyonClassifying
Automatic explainability has received very little HumanActivitiesUsingClassicalMachineandDeep
attention in sports to date, with solutions focusing on LearningMethods,”Arab.J.Sci.Eng.,vol.47,no.2,
offline supervised approaches. To our knowledge, our pp.1507–1521,2022.
system is the first solution to combine online process- 6. J.W.Navalta,J.Montes,N.G.Bodell,C.D.Aguilar,
ing, explainability, and unsupervised assessment for K.Radzak,J.W.Manning,andM.DeBeliso,
HAR in the field of sport. The flexible positioning of “ReliabilityofTrailWalkingandRunningTasksUsing
the data collection sensors is an additional advantage theStrydPowerMeter,”Int.J.SportsMed.,vol.40,
of our approach. no.8,pp.498–502,2019.
Currently, use of our system is limited to sports 7. E.T.Mohamad,D.J.Armaghani,E.Momeni,A.H.
or training practices with clearly defined patterns or Yazdavar,andM.Ebrahimi,“Rockstrengthestimation:
stages, such as martial arts kata training, boxing bag aPSO-basedBPapproach,”NeuralComput.Appl.,
exercises, certain forms of gymnastics (e.g., rings), vol.30,no.5,pp.1635–1646,2018.
and, as shown in this paper, Nordic Walking. Future 8. S.K.Challa,A.Kumar,andV.B.Semwal,“A
work is needed to extend its application to more multibranchCNN-BiLSTMmodelforhumanactivity
open,“fluid”,sports,suchassoccerandbasketball.In recognitionusingwearablesensordata,”Vis.Comput.,
addition, when applicable, we plan to take advantage p.4095–4109,2021.
of the solution’s modular design to include a rein- 9. E.E.Cust,A.J.Sweeting,K.Ball,andS.Robertson,
forcementlearning modulebased onthehumanin the “Machineanddeeplearningforsport-specific
loop approach. This would allow experts to provide movementrecognition:asystematicreviewofmodel
feedback to continually improve the system and its developmentandperformance,”J.SportsSci.,vol.37,
performance. no.5,pp.568–600,2019.
10. D.BormsandA.Cools,“Upper-ExtremityFunctional
ACKNOWLEDGMENTS PerformanceTests:ReferenceValuesforOverhead
This work was partially supported by Xunta de Athletes,”Int.J.SportsMed.,vol.39,no.6,pp.
GaliciagrantsED481B-2021-118,ED481B-2022-093, 433–441,2018.
andED431C2022/04,Spain.Theauthorsareindebted 11. X.Hu,S.Mo,andX.Qu,“BasketballActivity
toNordicWalkingVigoandMr.IgnacioGarcíaPérez ClassificationBasedonUpperBodyKinematicsand
for their help obtaining representative experimental DynamicTimeWarping,”Int.J.SportsMed.,vol.41,
data for correct, incorrect, and cheating practices. pp.255–263,2020.
12. S.S.Tabrizi,S.Pashazadeh,andV.Javani,“ADeep
LearningApproachforTableTennisForehandStroke
REFERENCES
EvaluationSystemUsinganIMUSensor,”Comput.
1. C.Jobanputra,J.Bavishi,andN.Doshi,“Human Intell.Neurosci.,vol.2021,pp.1–15,2021.
ActivityRecognition:ASurvey,”ProcediaComput.Sci., 13. J.Vales-Alonso,D.Chaves-Diéguez,
vol.155,pp.698–703,2019. P.López-Matencio,J.J.Alcaraz,F.J.Parrado-García,
2. M.Al-Hammadi,G.Muhammad,W.Abdul, andF.J.González-Castaño,“SAETA:ASmart
M.Alsulaiman,andM.S.Hossain,“HandGesture CoachingAssistantforProfessionalVolleyball
RecognitionUsing3D-CNNModel,”IEEEConsum. Training,”IEEETrans.Syst.ManCybern.,vol.45,
Electron.Mag.,vol.9,pp.95–101,2020. no.8,pp.1138–1150,2015.
3. A.Ayman,O.Attalah,andH.Shaban,“AnEfficient 14. L.Lerebourg,D.Saboul,M.Clémençon,andJ.B.
HumanActivityRecognitionFrameworkBasedon Coquart,“PredictionofMarathonPerformanceusing
WearableIMUWristSensors,”inProceedingsofthe ArtificialIntelligence,”Int.J.SportsMed.,pp.352–360,
IEEEInternationalConferenceonImagingSystems 2022.
andTechniques. IEEE,2019,pp.1–5. 15. L.Bai,C.Yeung,C.Efstratiou,andM.Chikomo,
4. S.Abbaspour,F.Fotouhi,A.Sedaghatbaf,H.Fotouhi, “Motion2Vector:unsupervisedlearninginhuman
M.Vahabi,andM.Linden,“AComparativeAnalysisof activityrecognitionusingwrist-sensingdata,”in
HybridDeepLearningModelsforHumanActivity ProceedingsoftheACMInternationalJoint
Recognition,”Sensors,vol.20,no.19,pp.5707–5720, ConferenceonPervasiveandUbiquitousComputing
2020. andProceedingsoftheACMInternationalSymposium
16 IEEEConsumerElectronicsMagazineonWearableComputers. AssociationforComputing AnExampleBasedonInjuryForecastinginSoccer,”
Machinery,2019,pp.537–542. Sports,vol.10,no.1,pp.5–20,2021.
16. J.ShenandH.Fang,“HumanActivityRecognition 28. M.WebberandR.F.Rojas,“HumanActivity
UsingGaussianNaïveBayesAlgorithminSmart RecognitionWithAccelerometerandGyroscope:A
Home,”J.Phys.Conf.Ser.,vol.1631,no.1,pp. DataFusionApproach,”IEEESens.J.,vol.21,no.15,
012059–012064,2020. pp.16979–16989,2021.
17. C.BulacandA.Bulac,“DecisionTrees,”inAdvanced 29. Y.Zeng,C.Wang,C.-C.Chen,W.-P.Xiong,Z.Liu,
SolutionsinPowerSystems:HVDC,FACTS,and Y.-C.Huang,andC.Shen,“SmartDeviceMonitoring
ArtificialIntelligence. Wiley,2016,pp.819–844. SystemBasedonMulti-typeInertialSensorMachine
Learning,”Sens.Mater.,vol.33,no.2,pp.693–714,
18. D.A.PisnerandD.M.Schnyer,“Supportvector
2021.
machine,”inMachineLearning. Elsevier,2020,pp.
30. L.ZhangandN.Li,“Materialanalysisandbigdata
101–121.
monitoringofsportstrainingequipmentbasedon
19. P.CunninghamandS.J.Delany,“k-NearestNeighbour
machinelearningalgorithm,”NeuralComput.Appl.,
Classifiers-ATutorial,”ACMComput.Surv.,vol.54,
vol.34,no.4,pp.2749–2763,2022.
no.6,pp.1–25,2022.
31. J.SutoandS.Oniga,“Efficiencyinvestigationof
20. B.Pavlyshenko,“UsingStackingApproachesfor
artificialneuralnetworksinhumanactivityrecognition,”
MachineLearningModels,”inProceedingsoftheIEEE
J.Ambient.Intell.Humaniz.Comput.,vol.9,no.4,pp.
InternationalConferenceonDataStreamMining&
1049–1060,2018.
Processing. IEEE,2018,pp.255–258.
32. C.Domingo,S.See,andR.Legaspi,“Unsupervised
21. M.H.M.Noor,Z.Salcic,andK.I.Wang,“Adaptive
HabitualActivityDetectioninAccelerometerData,”in
slidingwindowsegmentationforphysicalactivity
MechatronicsandMachineVisioninPractice3,2018,
recognitionusingasingletri-axialaccelerometer,”
pp.253–272.
PervasiveMob.Comput.,vol.38,pp.41–59,2017.
33. K.P.SinagaandM.-S.Yang,“UnsupervisedK-Means
22. E.Bulbul,A.Cetin,andI.A.Dogru,“HumanActivity
ClusteringAlgorithm,”IEEEAccess,vol.8,pp.
RecognitionUsingSmartphones,”inProceedingsof
80716–80727,2020.
theInternationalSymposiumonMultidisciplinary
34. J.Gu,Z.Wang,J.Kuen,L.Ma,A.Shahroudy,
StudiesandInnovativeTechnologies. IEEE,2018,pp.
B.Shuai,T.Liu,X.Wang,G.Wang,J.Cai,and
1–6.
T.Chen,“Recentadvancesinconvolutionalneural
23. M.N.S.Zainudin,M.N.Sulaiman,N.Mustapha,and
networks,”PatternRecognit.,vol.77,pp.354–377,
T.Perumal,“ActivityRecognitionUsingOne-Versus-All
2018.
StrategywithRelief-FandSelf-AdaptiveAlgorithm,”in
35. D.vanKuppevelt,J.Heywood,M.Hamer,S.Sabia,
ProceedingsoftheIEEEConferenceonOpen
E.Fitzsimons,andV.vanHees,“Segmenting
Systems. IEEE,2018,pp.31–36.
accelerometerdatafromdailylifewithunsupervised
24. P.Bharti,D.De,S.Chellappan,andS.K.Das,
machinelearning,”PloONE,vol.14,no.1,pp.
“HuMAn:ComplexActivityRecognitionwith
e0208692–e0208710,2019.
Multi-ModalMulti-PositionalBodySensing,”IEEE
36. R.Janarthanan,S.Doss,andS.Baskar,“Optimized
Trans.Mob.Comput.,vol.18,no.4,pp.857–870,
unsuperviseddeeplearningassistedreconstructed
2019.
coderintheon-nodulewearablesensorforhuman
25. M.Gil-Martín,R.San-Segundo, activityrecognition,”Measurement,vol.164,pp.
F.Fernández-Martínez,andR.deCórdoba,“Human 108050–108060,2020.
activityrecognitionadaptedtothetypeofmovement,” 37. C.Serantoni,G.Zimatore,G.Bianchetti,A.Abeltino,
Comput.Electr.Eng.,vol.88,pp.106822–106835, M.D.Spirito,andG.Maulucci,“Unsupervised
2020. ClusteringofHeartbeatDynamicsAllowsforReal
26. P.ZhuandF.Sun,“SportsAthletes’Performance TimeandPersonalizedImprovementinCardiovascular
PredictionModelBasedonMachineLearning Fitness,”Sensors,vol.22,pp.3974–3969,2022.
Algorithm,”inAdvancesinIntelligentSystemsand 38. A.Derungs,S.Soller,A.Weishaupl,J.Bleuel,
Computing. Springer,2020,vol.1017,pp.498–505. G.Berschin,andO.Amft,“Regression-based,
27. A.Rossi,L.Pappalardo,andP.Cintia,“ANarrative mistake-drivenmovementskillestimationinNordic
ReviewforaMachineLearningApplicationinSports: Walkingusingwearableinertialsensors,”in
2023 17ProceedingsoftheIEEEInternationalConferenceon 49. G.Lisca,C.Prodaniuc,T.Grauschopf,andC.Axenie,
PervasiveComputingandCommunications. IEEE, “LessIsMore:LearningInsightsFromaSingleMotion
2018,pp.1–10. SensorforAccurateandExplainableSoccer
39. F.Mocera,G.Aquilino,andA.Somà,“NordicWalking GoalkeeperKinematics,”IEEESens.J.,vol.21,no.18,
PerformanceAnalysiswithanIntegratedMonitoring pp.20375–20387,2021.
System,”Sensors,vol.18,no.5,pp.1505–1517,2018. 50. S.García-Méndez,F.Leal,B.Malheiro,J.C.
40. P.Pierleoni,S.Raggiunto,S.Marzorati,L.Palma, Burguillo-Rial,B.Veloso,A.E.Chis,and
A.Cucchiarelli,andA.Belli,“ActivityMonitoring H.González–Vélez,“Simulation,modellingand
ThroughWirelessSensorNetworksEmbeddedInto classificationofwikicontributors:Spottingthegood,
SmartSportEquipments:TheNordicWalkingTraining thebad,andtheugly,”Simul.Model.Pract.Theory,
Utility,”IEEESens.J.,vol.22,no.3,pp.2744–2757, vol.120,pp.102616–102628,2022.
2022. 51. H.Bi,M.Perello-Nieto,R.Santos-Rodriguez,and
41. T.WiktorskiandJ.C.-W.Lin,“ApproximateApproach P.Flach,“HumanActivityRecognitionBasedon
toFindingGenericUtilityofSequentialPatterns,”in DynamicActiveLearning,”IEEEJ.Biomed.Health
ProceedingsoftheInternationalConferenceonData Inform.,vol.25,pp.922–934,2021.
MiningWorkshops. IEEE,2019,pp.1029–1034. 52. B.Fu,N.Damer,F.Kirchbuchner,andA.Kuijper,
42. P.Kumar,R.Kumar,M.Aloqaily,andA.K.M.N.Islam, “SensingTechnologyforHumanActivityRecognition:
“ExplainableAIandBlockchainforMetaverse:A AComprehensiveSurvey,”IEEEAccess,vol.8,pp.
Security,andPrivacyPerspective,”IEEEConsum. 83791–83820,2020.
Electron.Mag.,pp.1–7,2023. 53. Z.Meng,M.Zhang,C.Guo,Q.Fan,H.Zhang,N.Gao,
43. F.deArriba-Pérez,S.García-Méndez,F.J. andZ.Zhang,“RecentProgressinSensingand
González-Castaño,andJ.González-González, ComputingTechniquesforHumanActivityRecognition
“Explainablemachinelearningmulti-labelclassification andMotionAnalysis,”Electronics,vol.9,pp.
ofSpanishlegaljudgements,”J.KingSaudUniv. 1357–1375,2020.
Comput.Inf.Sci.,pp.10180–10192,2022. 54. N.Herencsar,“AI-EmpoweredNextGeneration
44. J.González-González,S.García-Méndez, ConsumerInternetofThings,”IEEEConsum.Electron.
F.DeArriba-Pérez,F.J.González-Castaño,and Mag.,vol.12,pp.11–13,2023.
Ó.Barba-Seara,“ExplainableAutomaticIndustrial 55. S.Edwards,S.White,S.Humphreys,R.Robergs,and
CarbonFootprintEstimationFromBankTransaction N.O’Dwyer,“Cautionusingdatafromtriaxial
ClassificationUsingNaturalLanguageProcessing,” accelerometershousedinplayertrackingunitsduring
IEEEAccess,vol.10,pp.126326–126338,2022. running,”J.SportsSci.,vol.37,no.7,pp.810–818,
45. M.Ehatisham-ulHaq,M.N.Malik,M.A.Azam, 2019.
U.Naeem,A.Khalid,andM.A.Ghazanfar,“Identifying 56. S.O.Slim,A.Atia,M.M.A.,andM.-S.M.Mostafa,
UserswithWearableSensorsbasedonActivity “SurveyonHumanActivityRecognitionbasedon
Patterns,”ProcediaComput.Sci.,vol.177,pp.8–15, AccelerationData,”Int.J.Adv.Comput.Sci.Appl.,
2020. vol.10,no.3,pp.84–98,2019.
46. Y.Wang,W.Liu,andX.Liu,“ExplainableAItechniques 57. M.StuartandM.Manic,“DeepLearningShared
withapplicationtoNBAgameplayprediction,” BandpassFiltersforResource-ConstrainedHuman
Neurocomputing,vol.483,pp.59–71,2022. ActivityRecognition,”IEEEAccess,vol.9,pp.
47. C.Feely,B.Caulfield,A.Lawlor,andB.Smyth, 39089–39097,2021.
“ProvidingExplainableRace-TimePredictionsand 58. M.KhannouzandT.Glatard,“ABenchmarkofData
TrainingPlanRecommendationstoMarathon StreamClassificationforHumanActivityRecognition
Runners,”inProceedingsoftheACMConferenceon onConnectedObjects,”Sensors,vol.20,pp.
RecommenderSystems. AssociationforComputing 6486–6502,2020.
Machinery,2020,pp.539–544. 59. D.Chen,S.Yongchareon,E.M.-K.Lai,Q.Z.Sheng,
48. X.Sun,J.Davis,O.Schulte,andG.Liu,“Crackingthe andV.Liesaputra,“LocallyWeighted
BlackBox,”inProceedingsoftheACMSIGKDD Ensemble-Detection-BasedAdaptiveRandomForest
InternationalConferenceonKnowledgeDiscovery& ClassifierforSensor-BasedOnlineActivityRecognition
DataMining. AssociationforComputingMachinery, forMultipleResidents,”IEEEInternetThingJ.,vol.9,
2020,pp.3154–3162. pp.13077–13085,2022.
18 IEEEConsumerElectronicsMagazine60. Q.Xue,Y.Zhu,andJ.Wang,“JointDistribution Javier Vales-Alonso received a degree in telecom-
EstimationandNaïveBayesClassificationUnderLocal municationengineeringfromtheUniversidaddeVigo,
DifferentialPrivacy,”IEEETrans.Emerg.Top.Comput., Spain,in2000,theM.Sc.degreeinmathematicsfrom
vol.9,no.4,pp.2053–2063,2021. the Universidad Nacional de Educación a Distancia,
61. M.Stirling,Y.S.Koh,P.Fournier-Viger,andS.D. Spain, in 2005, and the Ph.D. degree in computer
Ravana,“ConceptDriftDetectorSelectionfor science from the Universidad Politécnica de Carta-
HoeffdingAdaptiveTrees,”inLectureNotesin gena (UPCT), Spain, in 2015, where he is currently
ComputerScience(includingsubseriesLectureNotes a Full Professor with the Department of Information
inArtificialIntelligenceandLectureNotesin and Communication Technologies. He is involved in
Bioinformatics). Springer,2018,vol.11320LNAI,pp. differentresearchtopicsrelatedtomodelingandop-
730–736. timization.
62. H.M.Gomes,A.Bifet,J.Read,J.P.Barddal,
F.Enembreck,B.Pfharinger,G.Holmes,and
T.Abdessalem,“Adaptiverandomforestsforevolving
datastreamclassification,”Mach.Learn.,vol.106,no.
9-10,pp.1469–1495,2017.
63. J.Gama,R.Sebastião,andP.P.Rodrigues,“On
EvaluatingStreamLearningAlgorithms,”Mach.Learn.,
vol.90,no.3,pp.317–346,2013.
Silvia García-Méndez received a Ph.D. in Informa-
tion and Communication Technologies from the Uni-
versityofVigoin2021.Since2015,shehasworked
as a researcher with the Information Technologies
Group at the University of Vigo. She is collaborating
with foreign research centers as part of her post-
doctoral stage. Her research interests include Nat-
ural Language Processing techniques and Machine
Learningalgorithms.
FranciscodeArriba-PérezreceivedaB.S.degreein
telecommunicationtechnologiesengineeringin2013,
an M.S. degree in telecommunication engineering in
2014,andaPh.D.degreein2019fromtheUniversity
of Vigo, Spain. He is currently a researcher in the
Information Technologies Group at the University of
Vigo, Spain. His research includes the development
of Machine Learning solutions for different domains
likefinanceandhealth.
FranciscoJ.González-CastañoreceivedaB.S.de-
greefromtheUniversityofSantiagodeCompostela,
Spain, in 1990 and a Ph.D. degree from the Univer-
sity of Vigo, Spain, in 1998. He is a full professor
at the University of Vigo, Spain, leading the Infor-
mation Technologies Group. He has authored over
120 papers in international journals in the fields of
telecommunications and computer science and has
participated in several relevant national and interna-
tionalprojects.HeholdsthreeU.S.patents.
2023 19