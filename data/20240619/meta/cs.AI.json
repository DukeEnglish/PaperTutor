[
    {
        "title": "Synergizing Foundation Models and Federated Learning: A Survey",
        "authors": "Shenghui LiFanghua YeMeng FangJiaxu ZhaoYun-Hin ChanEdith C. -H. NgaiThiemo Voigt",
        "links": "http://arxiv.org/abs/2406.12844v1",
        "entry_id": "http://arxiv.org/abs/2406.12844v1",
        "pdf_url": "http://arxiv.org/pdf/2406.12844v1",
        "summary": "The recent development of Foundation Models (FMs), represented by large\nlanguage models, vision transformers, and multimodal models, has been making a\nsignificant impact on both academia and industry. Compared with small-scale\nmodels, FMs have a much stronger demand for high-volume data during the\npre-training phase. Although general FMs can be pre-trained on data collected\nfrom open sources such as the Internet, domain-specific FMs need proprietary\ndata, posing a practical challenge regarding the amount of data available due\nto privacy concerns. Federated Learning (FL) is a collaborative learning\nparadigm that breaks the barrier of data availability from different\nparticipants. Therefore, it provides a promising solution to customize and\nadapt FMs to a wide range of domain-specific tasks using distributed datasets\nwhilst preserving privacy. This survey paper discusses the potentials and\nchallenges of synergizing FL and FMs and summarizes core techniques, future\ndirections, and applications. A periodically updated paper collection on FM-FL\nis available at https://github.com/lishenghui/awesome-fm-fl.",
        "updated": "2024-06-18 17:58:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.12844v1"
    },
    {
        "title": "Can Go AIs be adversarially robust?",
        "authors": "Tom TsengEuan McLeanKellin PelrineTony T. WangAdam Gleave",
        "links": "http://arxiv.org/abs/2406.12843v1",
        "entry_id": "http://arxiv.org/abs/2406.12843v1",
        "pdf_url": "http://arxiv.org/pdf/2406.12843v1",
        "summary": "Prior work found that superhuman Go AIs like KataGo can be defeated by simple\nadversarial strategies. In this paper, we study if simple defenses can improve\nKataGo's worst-case performance. We test three natural defenses: adversarial\ntraining on hand-constructed positions, iterated adversarial training, and\nchanging the network architecture. We find that some of these defenses are able\nto protect against previously discovered attacks. Unfortunately, we also find\nthat none of these defenses are able to withstand adaptive attacks. In\nparticular, we are able to train new adversaries that reliably defeat our\ndefended agents by causing them to blunder in ways humans would not. Our\nresults suggest that building robust AI systems is challenging even in narrow\ndomains such as Go. For interactive examples of attacks and a link to our\ncodebase, see https://goattack.far.ai.",
        "updated": "2024-06-18 17:57:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.12843v1"
    },
    {
        "title": "Demystifying Higher-Order Graph Neural Networks",
        "authors": "Maciej BestaFlorian ScheidlLukas GianinazziShachar KlaimanJürgen MüllerTorsten Hoefler",
        "links": "http://arxiv.org/abs/2406.12841v1",
        "entry_id": "http://arxiv.org/abs/2406.12841v1",
        "pdf_url": "http://arxiv.org/pdf/2406.12841v1",
        "summary": "Higher-order graph neural networks (HOGNNs) are an important class of GNN\nmodels that harness polyadic relations between vertices beyond plain edges.\nThey have been used to eliminate issues such as over-smoothing or\nover-squashing, to significantly enhance the accuracy of GNN predictions, to\nimprove the expressiveness of GNN architectures, and for numerous other goals.\nA plethora of HOGNN models have been introduced, and they come with diverse\nneural architectures, and even with different notions of what the\n\"higher-order\" means. This richness makes it very challenging to appropriately\nanalyze and compare HOGNN models, and to decide in what scenario to use\nspecific ones. To alleviate this, we first design an in-depth taxonomy and a\nblueprint for HOGNNs. This facilitates designing models that maximize\nperformance. Then, we use our taxonomy to analyze and compare the available\nHOGNN models. The outcomes of our analysis are synthesized in a set of insights\nthat help to select the most beneficial GNN model in a given scenario, and a\ncomprehensive list of challenges and opportunities for further research into\nmore powerful HOGNNs.",
        "updated": "2024-06-18 17:57:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.12841v1"
    },
    {
        "title": "Influence Maximization via Graph Neural Bandits",
        "authors": "Yuting FengVincent Y. F. TanBogdan Cautis",
        "links": "http://arxiv.org/abs/2406.12835v1",
        "entry_id": "http://arxiv.org/abs/2406.12835v1",
        "pdf_url": "http://arxiv.org/pdf/2406.12835v1",
        "summary": "We consider a ubiquitous scenario in the study of Influence Maximization\n(IM), in which there is limited knowledge about the topology of the diffusion\nnetwork. We set the IM problem in a multi-round diffusion campaign, aiming to\nmaximize the number of distinct users that are influenced. Leveraging the\ncapability of bandit algorithms to effectively balance the objectives of\nexploration and exploitation, as well as the expressivity of neural networks,\nour study explores the application of neural bandit algorithms to the IM\nproblem. We propose the framework IM-GNB (Influence Maximization with Graph\nNeural Bandits), where we provide an estimate of the users' probabilities of\nbeing influenced by influencers (also known as diffusion seeds). This initial\nestimate forms the basis for constructing both an exploitation graph and an\nexploration one. Subsequently, IM-GNB handles the exploration-exploitation\ntradeoff, by selecting seed nodes in real-time using Graph Convolutional\nNetworks (GCN), in which the pre-estimated graphs are employed to refine the\ninfluencers' estimated rewards in each contextual setting. Through extensive\nexperiments on two large real-world datasets, we demonstrate the effectiveness\nof IM-GNB compared with other baseline methods, significantly improving the\nspread outcome of such diffusion campaigns, when the underlying network is\nunknown.",
        "updated": "2024-06-18 17:54:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.12835v1"
    },
    {
        "title": "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation",
        "authors": "Seyedarmin AziziSouvik KunduMassoud Pedram",
        "links": "http://arxiv.org/abs/2406.12832v1",
        "entry_id": "http://arxiv.org/abs/2406.12832v1",
        "pdf_url": "http://arxiv.org/pdf/2406.12832v1",
        "summary": "Low-rank adaptation (LoRA) has become the default approach to fine-tune large\nlanguage models (LLMs) due to its significant reduction in trainable\nparameters. However, trainable parameter demand for LoRA increases with\nincreasing model embedding dimensions, leading to high compute costs.\nAdditionally, its backward updates require storing high-dimensional\nintermediate activations and optimizer states, demanding high peak GPU memory.\nIn this paper, we introduce large model fine-tuning via spectrally decomposed\nlow-dimensional adaptation (LaMDA), a novel approach to fine-tuning large\nlanguage models, which leverages low-dimensional adaptation to achieve\nsignificant reductions in trainable parameters and peak GPU memory footprint.\nLaMDA freezes a first projection matrix (PMA) in the adaptation path while\nintroducing a low-dimensional trainable square matrix, resulting in substantial\nreductions in trainable parameters and peak GPU memory usage. LaMDA gradually\nfreezes a second projection matrix (PMB) during the early fine-tuning stages,\nreducing the compute cost associated with weight updates to enhance parameter\nefficiency further. We also present an enhancement, LaMDA++, incorporating a\n``lite-weight\" adaptive rank allocation for the LoRA path via normalized\nspectrum analysis of pre-trained model weights. We evaluate LaMDA/LaMDA++\nacross various tasks, including natural language understanding with the GLUE\nbenchmark, text summarization, natural language generation, and complex\nreasoning on different LLMs. Results show that LaMDA matches or surpasses the\nperformance of existing alternatives while requiring up to 17.7x fewer\nparameter updates and up to 1.32x lower peak GPU memory usage during\nfine-tuning. Code will be publicly available.",
        "updated": "2024-06-18 17:52:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.12832v1"
    }
]