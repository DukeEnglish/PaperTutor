[
    {
        "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models",
        "authors": "Feng LiRenrui ZhangHao ZhangYuanhan ZhangBo LiWei LiZejun MaChunyuan Li",
        "links": "http://arxiv.org/abs/2407.07895v1",
        "entry_id": "http://arxiv.org/abs/2407.07895v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07895v1",
        "summary": "Visual instruction tuning has made considerable strides in enhancing the\ncapabilities of Large Multimodal Models (LMMs). However, existing open LMMs\nlargely focus on single-image tasks, their applications to multi-image\nscenarios remains less explored. Additionally, prior LMM research separately\ntackles different scenarios, leaving it impossible to generalize cross\nscenarios with new emerging capabilities. To this end, we introduce\nLLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame\n(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To\nenable these capabilities, we regard the interleaved data format as a general\ntemplate and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4\nprimary domains with 14 tasks and 41 datasets. We also curate the\nLLaVA-Interleave Bench to comprehensively evaluate the multi-image performance\nof LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading\nresults in multi-image, video, and 3D benchmarks, while maintaining the\nperformance of single-image tasks. Besides, our model also exhibits several\nemerging capabilities, e.g., transferring tasks across different settings and\nmodalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT",
        "updated": "2024-07-10 17:59:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07895v1"
    },
    {
        "title": "Training on the Test Task Confounds Evaluation and Emergence",
        "authors": "Ricardo Dominguez-OlmedoFlorian E. DornerMoritz Hardt",
        "links": "http://arxiv.org/abs/2407.07890v1",
        "entry_id": "http://arxiv.org/abs/2407.07890v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07890v1",
        "summary": "We study a fundamental problem in the evaluation of large language models\nthat we call training on the test task. Unlike wrongful practices like training\non the test data, leakage, or data contamination, training on the test task is\nnot a malpractice. Rather, the term describes a growing set of techniques to\ninclude task-relevant data in the pretraining stage of a language model. We\ndemonstrate that training on the test task confounds both relative model\nevaluations and claims about emergent capabilities. We argue that the seeming\nsuperiority of one model family over another may be explained by a different\ndegree of training on the test task. To this end, we propose an effective\nmethod to adjust for training on the test task by fine-tuning each model under\ncomparison on the same task-relevant data before evaluation. We then show that\ninstances of emergent behavior largely vanish once we adjust for training on\nthe test task. This also applies to reported instances of emergent behavior\nthat cannot be explained by the choice of evaluation metric. Our work promotes\na new perspective on the evaluation of large language models with broad\nimplications for benchmarking and the study of emergent capabilities.",
        "updated": "2024-07-10 17:57:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07890v1"
    },
    {
        "title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization",
        "authors": "Junkang WuYuexiang XieZhengyi YangJiancan WuJiawei ChenJinyang GaoBolin DingXiang WangXiangnan He",
        "links": "http://arxiv.org/abs/2407.07880v1",
        "entry_id": "http://arxiv.org/abs/2407.07880v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07880v1",
        "summary": "This study addresses the challenge of noise in training datasets for Direct\nPreference Optimization (DPO), a method for aligning Large Language Models\n(LLMs) with human preferences. We categorize noise into pointwise noise, which\nincludes low-quality data points, and pairwise noise, which encompasses\nerroneous data pair associations that affect preference rankings. Utilizing\nDistributionally Robust Optimization (DRO), we enhance DPO's resilience to\nthese types of noise. Our theoretical insights reveal that DPO inherently\nembeds DRO principles, conferring robustness to pointwise noise, with the\nregularization coefficient $\\beta$ playing a critical role in its noise\nresistance. Extending this framework, we introduce Distributionally\nRobustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing\nagainst worst-case pairwise scenarios. The novel hyperparameter $\\beta'$ in Dr.\nDPO allows for fine-tuned control over data pair reliability, providing a\nstrategic balance between exploration and exploitation in noisy training\nenvironments. Empirical evaluations demonstrate that Dr. DPO substantially\nimproves the quality of generated text and response accuracy in preference\ndatasets, showcasing enhanced performance in both noisy and noise-free\nsettings. The code is available at https://github.com/junkangwu/Dr_DPO.",
        "updated": "2024-07-10 17:48:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07880v1"
    },
    {
        "title": "Generative Image as Action Models",
        "authors": "Mohit ShridharYat Long LoStephen James",
        "links": "http://arxiv.org/abs/2407.07875v1",
        "entry_id": "http://arxiv.org/abs/2407.07875v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07875v1",
        "summary": "Image-generation diffusion models have been fine-tuned to unlock new\ncapabilities such as image-editing and novel view synthesis. Can we similarly\nunlock image-generation models for visuomotor control? We present GENIMA, a\nbehavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions'\nas targets on RGB images. These images are fed into a controller that maps the\nvisual targets into a sequence of joint-positions. We study GENIMA on 25\nRLBench and 9 real-world manipulation tasks. We find that, by lifting actions\ninto image-space, internet pre-trained diffusion models can generate policies\nthat outperform state-of-the-art visuomotor approaches, especially in\nrobustness to scene perturbations and generalizing to novel objects. Our method\nis also competitive with 3D agents, despite lacking priors such as depth,\nkeypoints, or motion-planners.",
        "updated": "2024-07-10 17:41:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07875v1"
    },
    {
        "title": "FACTS About Building Retrieval Augmented Generation-based Chatbots",
        "authors": "Rama AkkirajuAnbang XuDeepak BoraTan YuLu AnVishal SethAaditya ShuklaPritam GundechaHridhay MehtaAshwin JhaPrithvi RajAbhinav BalasubramanianMurali MaramGuru MuthusamyShivakesh Reddy AnnepallySidney KnowlesMin DuNick BurnettSean JaviyaAshok MarannanMamta KumariSurbhi JhaEthan DereszenskiAnupam ChakrabortySubhash RanjanAmina TerfaiAnoop SuryaTracey MercerVinodh Kumar ThanigachalamTamar BarSanjana KrishnanSamy KilaruJasmine JaksicNave AlgariciJacob LibermanJoey ConwaySonu NayyarJustin Boitano",
        "links": "http://arxiv.org/abs/2407.07858v1",
        "entry_id": "http://arxiv.org/abs/2407.07858v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07858v1",
        "summary": "Enterprise chatbots, powered by generative AI, are emerging as key\napplications to enhance employee productivity. Retrieval Augmented Generation\n(RAG), Large Language Models (LLMs), and orchestration frameworks like\nLangchain and Llamaindex are crucial for building these chatbots. However,\ncreating effective enterprise chatbots is challenging and requires meticulous\nRAG pipeline engineering. This includes fine-tuning embeddings and LLMs,\nextracting documents from vector databases, rephrasing queries, reranking\nresults, designing prompts, honoring document access controls, providing\nconcise responses, including references, safeguarding personal information, and\nbuilding orchestration agents. We present a framework for building RAG-based\nchatbots based on our experience with three NVIDIA chatbots: for IT/HR\nbenefits, financial earnings, and general content. Our contributions are\nthree-fold: introducing the FACTS framework (Freshness, Architectures, Cost,\nTesting, Security), presenting fifteen RAG pipeline control points, and\nproviding empirical results on accuracy-latency tradeoffs between large and\nsmall LLMs. To the best of our knowledge, this is the first paper of its kind\nthat provides a holistic view of the factors as well as solutions for building\nsecure enterprise-grade chatbots.\"",
        "updated": "2024-07-10 17:20:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07858v1"
    }
]