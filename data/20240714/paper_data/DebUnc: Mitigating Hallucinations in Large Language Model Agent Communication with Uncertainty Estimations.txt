DebUnc: Mitigating Hallucinations in Large Language Model Agent
Communication with Uncertainty Estimations
LukeYoffe AlfonsoAmayuelas WilliamYangWang
UniversityofCalifornia,SantaBarbara
{lukeyoffe, amayuelas}@ucsb.edu, william@cs.ucsb.edu
Abstract Initial Prompt
A food caterer was told to prepare gourmet hot
ToenhanceLargeLanguageModel(LLM)ca-
dogs for 36 guests. While most people would
pabilities, multi-agent debates have been in- only eat one hotdog, he prepared enough for
troduced,wheremultipleLLMsdiscusssolu- half of the guests to be able to have two
tions to a problem over several rounds of de- hotdogs. However, 40 guests showed up, and
everyone wanted a second hotdog. How many
bate. However, LLMs often produce incor-
guests did not get a second hotdog?
rect responses that appear deceptively confi-
dent, which can mislead other agents. This DebUnc: Debate with Uncertainty Metrics
is partly because agents do not express their The answer is 26
confidencelevelsduringstandarddebates. To Confidence: 7
address this, we introduce DebUnc, a multi-
agentdebateframeworkthatusesuncertainty
metricstoassessagentconfidencelevels. We
adaptedtheLLMattentionmechanismtoad-
just token weights based on confidence lev-
els and also explored using textual prompts
toconveyconfidence. Ourevaluationsacross
variousbenchmarksshowthatattention-based The answer is -8 The answer is 4
methodsareparticularlyeffective,andthatas Confidence: 4 Confidence: 4
uncertainty metrics evolve, performance will
Figure 1: Illustration of a three-agent mathematical
continuetoincrease. Thecodeisavailableat
debate. Eachagentusesalargelanguagemodel(LLM)
https://github.com/lukeyoffe/debunc.
togeneratetextresponsesandassessesitsconfidence
1 Introduction usinganuncertaintymetric,highlightedinyellow. The
responsesandconfidenceinformationissharedamong
Large language models (LLMs) have shown im-
theagents,enablingthemtodecidewhomtotrustwhen
pressive performance in various fields, including responsesdiffer. Correctanswersaremarkedingreen,
law, academia, and coding (OpenAI, 2024). To whileincorrectonesareshowninred.
handlemorecomplextasks,LLM-poweredagents
havebeendeveloped. Theseagentsobservetheir
environmentandtakeactions,suchascommunicat- Hallucinations undermine the trustworthiness
ing with other agents, using tools, or performing and utility of LLMs in real-world applications
reasoning(Wuetal.,2023). ThepotentialofLLM (Rawte et al., 2023). For example, an LLM tu-
agentsincreaseswhenmultipleagentscollaborate, tor providing incorrect information could harm a
whichcantakedifferentforms. student’slearning,andanLLMcustomerservice
Oneapproachinvolvesagentsassumingdifferent agentgivingincorrectadvicecouldmisleadacus-
roles,suchasdesigner,programmer,tester,orman- tomer. Infieldslikehealthcareorfinancialservices,
ager,withinasoftwaredevelopmentteamofLLM inaccurate information from an LLM could have
agents (Qian et al., 2024). Alternatively, agents even more severe consequences, ranging from fi-
may all assume the same role, collaborating to nanciallossestohealthrisks. Multi-agentdebates
solveproblemsthroughmulti-agentdebates. This aim to solve this issue by allowing agents to first
canhelpaddressLLM’stendencytogenerateincor- generatediverseanswerstoaproblem,thendiscuss
rectresponses,knownashallucinations(Duetal., eachother’sresponses, andfinallyconvergeona
2023),andisthefocusofthispaper. finalanswer(Liangetal.,2023).
1
4202
luJ
8
]LC.sc[
1v62460.7042:viXraWhile agents often converge on the same fi- 2 RelatedWork
nal solution, it is not always correct, possibly
LargeLanguageModels(LLMs)arecharacterized
duetoflawedcommunicationbetweenagents(Du
bytheiroverconfidenceandpropensitytoalways
etal.,2023). Currently,LLMagentscommunicate
provide a response to user queries. This often re-
throughtext,withoneagentgeneratingananswer
sultsinthegenerationofinaccuratecontent,aphe-
thatisthenincludedinanotheragent’spromptin
nomenonknownashallucination,wherethemod-
the next round. However, LLMs often respond
els produce information that is not supported by
withahighlyconfidenttone,regardlessofwhether
theirtrainingdataorthegiveninput(Liangetal.,
or not their answer is correct. This poses a sig-
2024;Yadkorietal.,2024;Duanetal.,2024;Yao
nificantprobleminmulti-agentsystemsbecausea
etal.,2023;Aichbergeretal.,2024). Addressing
confidentlyincorrectresponsefromoneagentcan
hallucinationsishighlyimportantfordeveloping
mislead the others, eventually leading all agents
trustinLLM-basedsystemsandfacilitatingtheir
toconvergeontheincorrectanswer. Inhumande-
deployment in more real-world applications. As
bates, participants often qualify their statements
a result, there has been a significant increase in
with phrases like "I am sure that..." or "I am not
researchaimedatunderstandingthemechanisms
sure,but...",which,whilenotperfect,helpothers
behindhallucinationsanddevelopingstrategiesto
assessthereliabilityoftheirresponses. Recogniz-
mitigate them (Ji et al., 2023; McDonald et al.,
ingthatLLMshavedifficultyexpressingtheirown
2024;Liuetal.,2023).
confidence, uncertainty metrics have been devel-
opedtoquantifytheiruncertainty.
2.1 UncertaintyinLLMs
Buildingontheseinsights,wepresentDebUnc,a
Somecurrentresearcheffortstomitigatehallucina-
novelmulti-agentdebateframeworkthatenhances
tionsfocusonmeasuringthemodel’suncertainty
multi-agentDebateswithmodelUncertaintymet-
andenhancingtheirself-awareness(Kadavathetal.,
rics. After each debate round, we measure each
2022; Amayuelas et al., 2023; Yin et al., 2023).
agent’suncertaintywithanuncertaintymetric. In
By accurately evaluating their uncertainty, end-
thefollowinground,eachagent’sresponseandun-
users can make more informed decisions about
certaintywillbecommunicatedtoallotheragents.
when to trust the model’s generated output (Lin
Weexplore two methodsfor conveying agentun-
etal.,2022a;Xuetal.,2024). However,accurately
certainty: (1)incorporatingtheuncertaintydirectly
measuringmodeluncertaintyremainsanunsolved
into the textual prompt alongside the agent re-
problem, and ongoing research is exploring new
sponses,asshowninFigure2,and(2)adjustingthe
uncertaintymetrics. Weidentifythreeprimaryap-
LLM’sattentiontowardsagents’responsesbased
proachestothisproblem:
ontheiruncertainty,asdepictedinFigure3. Weex-
Token Probability-Based Uncertainty Met-
tensivelyevaluateDebUncacrossmultipleLLMs,
rics evaluate uncertainty based on the probabili-
benchmarks,anduncertaintymetrics,analyzingthe
tiesassignedtoeachtokengeneratedbythemodel.
results of each uncertainty metric and method of
Hightokenprobabilities(closeto1)indicatestrong
uncertaintycommunication.
modelconfidence,whereaslowertokenprobabili-
Ourkeycontributionsareoutlinedasfollows:
tiessuggestaspreadofprobabilityacrossseveral
• WeintroduceDebUnc,aframeworkthatquan- tokens, signifying uncertainty about the correct
tifies and communicates LLM agent uncer- choice. Prominentmethodsinthiscategoryinclude
taintyinmulti-agentdebates. MeanTokenEntropy,Perplexity(Fomichevaetal.,
• WeadapttheLLMattentionmechanismtoad- 2020),SAR(Duanetal.,2023),RDE(Vazhentsev
justtokenweightsbasedonconfidencelevels et al., 2023), and Claim-Conditioned Probability
andalsoexploretheuseoftextualpromptsto (Fadeevaetal.,2024).
communicateconfidence. LLM-GeneratedUncertaintyMetricsinvolve
• WeevaluateDebUncacrossmultipleLLMs, the model explicitly expressing its uncertainty in
benchmarks,anduncertaintymetrics,andfind itsresponse. Thiscanbeachievedinmultipleways,
thattheattention-scalingmethodconsistently includingbytrainingthemodel. Thiswastheap-
outperformsunmodifieddebates. proachtakenbyLinetal.(2022a),whofine-tuned
• Weofferinsightsintohowperformancewill GPT-3(Brownetal.,2020)toprovideitsanswer
beimpactedasuncertaintymetricsevolve. toaquestionalongwithitsconfidencelevel.
2Alternatively,themodelcanbepromptedtoex- 3 Method
press its uncertainty without prior training. Tian
etal.(2023)foundthatthisapproachcancanout- In human debates, it is often possible to gauge
performtoken-probability-basedmethodswhenap- someone’sexpertiseonasubjectbyobservingthe
pliedtoLLMsfine-tunedwithreinforcementlearn- fluencyoftheirresponses,theirbodylanguage,and
ingfromhumanfeedback(Christianoetal.,2017). othercues. This helps inidentifying whoseargu-
However,Xiongetal.(2023)reportslightlyinferior ments to consider more seriously when there are
performancecomparedtotoken-probability-based conflictingopinions. Ontheotherhand,inmulti-
methodsonGPT-3. agentLLMdebates,agentsfrequentlygeneratein-
Sampling-Based Uncertainty Metrics assess accurateresponsesthatsoundconfident,whichcan
uncertaintybygeneratingmultipleoutputsthrough misleadotheragentsandresultinaconsensuson
sampling, analyzingthedistributionofmeanings anincorrectresponse(Duetal., 2023). Our goal
across the outputs. A consistent meaning across istoadviseagentsonwhichotheragents’opinions
multiplesamplessuggestshighconfidence,while toprioritizebasedontheirconfidencelevels.
variationsindicatelowerconfidence. Thisapproach Our modified debate pipeline, depicted in Fig-
can identify different sequences that convey the ure2,operatesasfollows: ineachroundofdebate,
samemeaning,whichtoken-probability-basedmet- every agent generates a response, and its uncer-
rics do not account for. However, the need for taintyisestimated. Inthenextround,theresponses
multiple generations makes these methods more anduncertaintiesfromeachagentaresharedwith
resource-intensivethantheothersdescribed. Exam- every other agent. We test three uncertainty met-
plesincludeSemanticEntropy(Kuhnetal.,2023), rics and three approaches to communicate agent
LUQ (Zhang et al., 2024), and other metrics that uncertainty.
evaluatemeaningdiversity(Linetal.,2023).
3.1 UncertaintyMetrics
2.2 Multi-AgentDebate
WiththeincreasedaccessibilityofLLMsandim- UncertaintymetricsgaugeanLLM’sconfidencein
provementsintheirinferencetimes,LLMsarebe- its responses; high uncertainty signifies low con-
ing integrated into more complex systems as au- fidence and potential unreliability, while low un-
tonomousagents(Wuetal.,2023;Lietal.,2023; certaintyindicateshighconfidenceandgreaterre-
Hongetal.,2023). Acriticalcomponentofthese liability. These metrics typicaly fall into one or
agent-based systems is the collaboration mecha- moreofthreecategories: TokenProbability-Based,
nism, where models engage in debate with one LLM-Generated, and Sampling-Based methods.
another. These mechanisms are currently being For more information about these categories, re-
studied(Zhangetal.,2023)andhavebeenshownto fertoUncertaintyinLLMs
fostermoredivergentthinking(Liangetal.,2023), In our experiments, we focus on token
enhancereasoningandfactualaccuracy(Duetal., probability-based metrics due to their computa-
2023),andleadtomorereliableevaluations(Chan tionalefficiencyandflexibility. Thesemetricsre-
etal.,2023). Throughdiscussions,theLLMscan quire only a single generation and are effective
refine their outputs, ultimately achieving higher regardlessofthemodel’sabilitytoexpressitsown
levelsofagreementandproducingmorefactually uncertainty. We specifically chose Mean Token
accuratetext(Sunetal.,2024;Fengetal.,2024). Entropy(Fomichevaetal.,2020)foritssimplicity
ReConcile(Chenetal.,2023)exploredtheinte- andTokenSAR(Duanetal.,2023),whichincorpo-
grationofagentconfidenceinmulti-agentdebates, ratesaheuristicrecognizingthatcertaintokenscon-
relying on LLM agents to self-report their confi- tributemoresignificantlytothesequence’smean-
dence, which was communicated to other agents ing than others. We utilize the implementations
throughprompts. Thisledtomarginalperformance fromLM-Polygraph,aframeworkwithimplemen-
improvements due to the confidence estimation. tationsformanystateoftheartuncertaintymetrics
Buildingontheirapproach,weemployuncertainty (Fadeevaetal.,2023). Additionally,toevaluatethe
metrics to estimate agent confidence and explore potentialofmoreadvancedmethodsandtoprepare
bothpromptingandattentionscalingtoconveythis forfutureimprovementsinuncertaintymetrics,we
confidence. Wefoundtheseenhancementstosig- haveincludedathird"oracle"uncertaintymetricin
nificantlyimprovemulti-agentdebateperformance. ouranalysis.
3Agent 1 Agent 2 Agent 3
Answer the following question. Think step by step before answering. <prompt> <prompt>
<question>
Debate Round 1
Large Language Model Uncertainty Metric LLM UM LLM UM
<agent 1 response> <agent 1 confidence> <res> <con> <res> <con>
These are solutions and confidence values from 1 to 10 from other agents: <prompt> <prompt>
One agent solution <agent 2 confidence>: <agent 2 response>
One agent solution <agent 3 confidence>: <agent 3 response>
Debate Round 2+ Based off the opinion of other agents, can you give an updated response?
Do not mention your confidence.
Large Language Model Uncertainty Metric LLM UM LLM UM
<agent 1 response> <agent 1 confidence> <res> <con> <res> <con>
Majority Vote
After Final Round
<final answer>
Figure 2: Illustration of the modified multi-agent debate involving three agents. In the first round, each agent
independentlygeneratesaresponsetothequestion,whichisevaluatedforconfidenceusinganuncertaintymetric.
Thepromptforfollowingroundsincludestheresponsesfromotheragentsinthepreviousround. Sectionsofthe
prompthighlightedingreenareusedonlywiththeConfidenceinPromptmethod. Eachagentretainsaccesstoits
completechathistorythroughoutthedebate. Afterthefinalround,amajorityvotedeterminesthefinalanswer.
3.1.1 MeanTokenEntropy Tocomputeeachtoken’srelevance,RoBERTa-
Mean Token Entropy (Fomicheva et al., 2020) is large (Liu et al., 2019) must be run N times in
the average entropy across all tokens generated, total. Thisismorecomputationallyexpensivethan
withtheentropyofasingletokenX definedas: calculating mean token entropy, but still far less
costlythanmetricsrequiringmultiplegenerations.
(cid:88)
H(X) = − p(x)logp(x)
3.1.3 Oracle
x∈V
Whiletheaforementioneduncertaintymetricsof-
Here,V denotesthevocabularyofthemodel. En-
ferusefulinsightsintoagentuncertainty,theyare
tropyismaximizedwhenp(x)isuniformoverall
notperfect. Tomimicanidealuncertaintymetric,
tokensinthevocabulary,indicatingmaximumun-
wealsoincludean"Oracle"uncertaintymetricin
certainty. Conversely, it is minimized when one
ourevaluation. Thismetricyieldslowuncertainty
token has a probability of 1 and all other tokens
whentheagentiscorrectandhighuncertaintywhen
have a probability of 0, indicating complete cer-
theagentisincorrect. Itisdefinedasfollows:
taintyintheselectedtoken. Thismethodishighly
(cid:40)
computationallyefficient,requiringminimalcom-
0 iftheresponseiscorrect
putationtodeterminetheuncertaintyoncethetext uncertainty =
∞ iftheresponseisincorrect
hasbeengenerated.
Inpractice,using0and∞couldcauseissueswith
3.1.2 TokenSAR
our uncertainty communication methods, so we
TokenSAR (Duan et al., 2023) is defined as the
detailexactlyhowthismetricisappliedinthefol-
weightedaverageofthenegativelogprobabilities
lowingsubsection. Itisalsoimportanttonotethat
foreachgeneratedtoken,wheretheweightsarethe
thismetricrequiresknowledgeofthegroundtruth
relevancescoresofthetokens:
answer, making it impractical for real-world use.
N Instead, it serves to evaluate the effectiveness of
(cid:88)
TokenSAR = −logp(t )R(t )
i i ouruncertaintycommunicationmethodsindepen-
i dentlyoftheperformanceoftheuncertaintymet-
Here,N representsthenumberoftokensgenerated, rics themselves, and allows us to anticipate how
t is the i-th token, and R(t ) is the relevance of improvementsinuncertaintymetricscouldaffect
i i
tokent . debateperformance.
i
4Vanilla Attention …the final answer, in accordance with
other agents' solutions, is 89.
Confidence-Based Weight Modifier Agent 1 Updated Answer
Output = Weights ✕ Values
Normalize
Weights ✕ 3.387 Weights ✕ 6.842 Weights ✕ 3.182
Attention Weights = Softmax(Query ✕ KeysT / √d)
k
Tokens What is 17 + 16 * 3 + 24 ? result is 69.8 result is 89 result is 65
Confidence = 3.387 = 6.842 = 3.182 =
–
1/Uncertainty 1/0.295 1/0.146 1/0.314
Uncertainty – 0.295 0.146 0.314
Context Section Initial Prompt Agent 1 Answer Agent 2 Answer Agent 3 Answer
Figure3: IllustrationoftheAttention-AllmethodfromtheperspectiveofAgent1. Astheseconddebateround
begins, themodel’scontextincludestheinitialpromptandeachagent’sresponses. Agent2providedacorrect
responsewithloweruncertaintythanAgents1and3,whorespondedincorrectly. BecauseAgent2hadalower
uncertainty, the attention weights for tokens constituting Agent 2’s response will be increased, while those for
tokensfromAgent1andAgent3’sresponseswillbedecreased. ThisledAgent1toswitchtothecorrectanswer.
3.2 IncorporatingUncertaintyintoDebate WhenusingtheOracleuncertaintymetric,weset
theconfidenceto1iftheagentwasincorrectand
Aftercomputingtheuncertaintyofeachagent,we
to10iftheagentwascorrect. Thecomputedconfi-
exploremultiplemethodstoincorporatetheseun-
dencescoresarethenincludedinthetextprompt
certaintiesintothefollowingdebateround.
toeachagent,asillustratedinFigure2.
3.2.1 ConfidenceinPrompt
One approach is to include the uncertainties di- 3.2.2 AttentionScaling
rectlyinthetextpromptforthenextdebateround. As an alternative to including confidence levels
Mean Token Entropy and TokenSAR yield non- in the prompt, we can modify the LLM’s token-
negative uncertainties. For Mean Token Entropy, generationprocesstoaccountforeachagent’scon-
therangeofuncertaintiesdependsonthemodel’s fidence. ManyLLMsuseTransformerdecoderlay-
vocabulary size, while for TokenSAR, the maxi- ers that generate an embedding for the last token
mumuncertaintyisunbounded. Therefore,theex- and use this embedding to predict the next token
actuncertaintyvaluesarelessinformativethanthe (Radford et al., 2018). This embedding is deter-
relativedifferencesinuncertaintybetweenagents. minedbytheattentionmechanism,whichcreates
Ratherthanexpressingtheiruncertainty,humans "query,""key,"and"value"vectorsforeachtoken.
often express their confidence on 1 to 10 scale. Thesimilaritybetweenthe"query"vectorofthe
SinceLLMsaretrainedonhumandata,theymay lasttokenandthe"key"vectorofeachtokenisused
exhibitthesamepreference. Asaresult,weconvert tocomputeaweightforeverytoken. Theseweights
the uncertainties into confidence values. Given a arenormalizedwithasoftmaxfunctiontoensure
listofuncertaintiesufornagents,whereu i isthe they sum to 1, and are used to create the output
uncertaintyofagenti,wefirstinvertthemtoobtain embedding,whichistheweightedsumofthevalue
rawconfidencevaluesr. Wethenscalethesevalues vectorsofeachtoken(Vaswanietal.,2017). The
sothattheaverageconfidences i ofallagentsis5. weightofeachtokendeterminesitsinfluenceonthe
Wethenclamptheconfidencelevelstotherange nexttokengenerated. Bymodifyingtheseweights,
of1to10. Finally,weroundtothenearestinteger: wecanadjustthemodel’sfocusoneachtokenin
theinput.
1 Inmulti-agentdebates,thisallowsustoshiftthe
r =
i u model’sfocustowardsmoreconfidentagents. After
i
r 1 each debate round, we will have responses from
i
s = ·(5n−1)+
i (cid:80)n r n everyagent. Inthenextround,eachagent’sprompt
j=1 j
will include these responses. We also compute
c = round(clamp(s ,1,10))
i i
theuncertaintyofeachagentusinganuncertainty
metric.
5Estimator Method MMLU-0 MMLU-5 GSM8k Arithmetic TruthfulQA Avg.
N/A Standard 0.520 0.544 0.512 0.478 0.604 0.532
Entropy Prompt 0.522 0.546 0.536 0.482 0.602 0.538
Attn-Others 0.540 0.566 0.488 0.518 0.608 0.544
Attn-All 0.526 0.570 0.536 0.518 0.604 0.551
TokenSAR Prompt 0.538 0.548 0.504 0.464 0.616 0.534
Attn-Others 0.526 0.560 0.496 0.500 0.626 0.542
Attn-All 0.532 0.552 0.528 0.500 0.610 0.544
Oracle Prompt 0.562 0.560 0.548 0.542 0.626 0.568
Attn-Others 0.606 0.666 0.640 0.654 0.630 0.639
Attn-All 0.618 0.684 0.656 0.732 0.648 0.668
Table1: Accuracycomparisonacrossvariousbenchmarksusingdifferentuncertaintyestimatorsandmethodswith
Mistral-7B.‘MMLU-0’denoteszero-shotperformanceonMMLU,while‘MMLU-5’represents5-shotperformance.
Theotherbenchmarksusedzero-shotprompting. The‘Avg.’ columnshowstheaverageperformanceforalltests.
AftertheLLMcomputesthenormalizedatten- Weexploretwovariantsofattentionscaling:
tionweights,wemultiplytheweightofeverytoken • Attention-Others, where agent i only
fromagentj bytheinverseofagentj’suncertainty rescales attention to other agents’ response
uncertainty when using Mean Token Entropy or tokenst | j ̸= i
j
TokenSAR.WhenusingtheOraclemetric,toavoid • Attention-All, where agent i rescales atten-
divide-by-zeroerrors,wesetthemultiplierto10−5
tion to other agents and itself, illustrated in
if the agent was incorrect and 1 if the agent was Figure3
correct.
Formally,theattentionweightfortokenia i is: 4 ExperimentDesign
(cid:40)
w ·m ifi ∈ t , foranyagentj
a = i j j To evaluate these methods, an open-source LLM
i
w i otherwise isrequired,asimplementingtheattentionscaling
requires modifications to the model source code.
Here, t is the set of token indices from agent
j
Additionally,theuncertaintymetricsusedrelyon
j. Wethennormalizethescaledattentionweights
tokenprobabilities,whichmaynotbereadilyavail-
toensurethatthesumofalltokenweightsequals
able from closed-source models. We performed
1, while leaving the weights of other tokens un-
mostofourexperimentsusingMistral-7B-Instruct-
changed. The final weight f for every token i is
i
v0.2(Jiangetal.,2023),andaddasmallevaluation
calculatedasfollows:
onLlama-3-8B-Instruct(AI@Meta,2024)tover-
 (cid:80)n (cid:80) w ifi ∈ t ,
a · j=1 k∈tj k j ifythattheresultsareapplicabletoothermodels.
f i = i (cid:80)n j=1(cid:80) k∈tja k foranyagentj Tokens were sampled with a temperature of 1 to
a otherwise
i ensure variability in the responses. The methods
Weonlyapplyattentionscalingtotheresponses wereevaluatedonmultiplebenchmarks:
fromthepreviousround. Forinstance,inathree- 1. MMLU(Hendrycksetal.,2021): Adataset
rounddebate,attentionwouldberescaledforthe of multiple-choice questions across various
responses from the first round during the second subjects.
round,andfortheresponsesfromthesecondround 2. GSM8k (Cobbe et al., 2021): A dataset of
duringthethirdround. Inthethirdroundofdebate, free-responsegradeschoolmathproblems.
attention would not be rescaled to the first-round 3. TruthfulQA(Linetal.,2022b): Amultiple-
responses. Additionally,inordertopreventdivide- choicedatasettestingthemodel’ssusceptibil-
by-zero errors during normalization, attention is itytocommonmisconceptions.
not scaled when computing the embeddings for 4. Arithmetic: An randomly generated set of
tokens within the prompt; it is only scaled when arithmeticproblemsintheforma+b·c+d
generatingnewtokens. where0 ≤ a,b,c,d < 30.
6Confidence in Prompt Attention-Others Attention-All
1.5 Trendline: Trendline: Trendline:
m=0.17, R2=0.53 m=0.45, R2=0.55 m=0.59, R2=0.58
1.4
1.3
1.2
1.1
1.0
0.6 0.7 0.8 0.9 1.0 0.6 0.7 0.8 0.9 1.0 0.6 0.7 0.8 0.9 1.0
Uncertainty Metric AUROC Uncertainty Metric AUROC Uncertainty Metric AUROC
Mean Token Entropy TokenSAR Oracle
Figure4: PlotsoftheratioofaccuracyimprovementoverastandarddebateagainsttheuncertaintymetricAUROC.
AhigherAUROCindicatesbettermetricperformance,seeUncertaintyIncorporationMethodsformoredetails.Each
pointrepresentstheresultsononeofthebenchmarks(MMLU-0,MMLU-5,GSM8k,Arithmetic,andTruthfulQA).
Theplotsareorganizedbythemethodofuncertaintyincorporationmethod(astitled)andtheuncertaintymetricused
(color-coded). Thetrendlinesshowthatattention-basedmethods,especiallyAttention-All,leadtomoresubstantial
performancegainsasAUROCincreasescomparedtomethodsthatincorporateconfidencedirectlyintotheprompt.
ForMMLU,wetestedbothzero-shotand5-shot Others, and Attention-All). As a baseline, the
prompting,usingsamplesfromtheoriginalMMLU performance of a standard 3-agent, 3-round de-
repository1. For the remaining benchmarks, we batewithoutanyuncertaintymetricsisalsoshown.
usedonlyzero-shotprompting. Theexactprompts Overall, Attention-All was the top-performing
usedareshowninAppendixC. method, achieving the highest average accuracy
Insteadofevaluatingonthefulldatasets,which acrossallthreeuncertaintymetrics. Itwastheonly
wouldbetooexpensive,wesampled100questions methodthatconsistentlymatchedorexceededthe
from each. We evaluated every combination of performanceofthestandardmulti-agentdebateon
uncertainty metric and uncertainty incorporation allbenchmarks.
methodonthesesamplesfivetimes,andreportthe As shown in Figure 4, Attention-All demon-
averageaccuracyacrossthefiveruns. stratesthemostsignificantaccuracyimprovements
The debates involved three agents and three astheAUROCoftheuncertaintymetricincreases,
rounds, with all agents using the same LLM. In withaslopeof0.59comparedto0.45forAttention-
thefirstround, eachagentansweredthequestion Othersand0.17forConfidenceinPrompt. Theac-
individually. Inthe following rounds, each agent curacyimprovementratiocomparesthemethod’s
was given other agents’ responses, and used this accuracytotheaccuracyobservedinastandardde-
informationtorefinetheiranswers. Afullexample bate. AUROC,theareaunderthereceiveroperating
debateisshowninAppendixA. Thefinalanswer characteristiccurve,representstheprobabilitythat
wasdeterminedbyamajorityvoteafterthethird a correct answer is assigned a lower uncertainty
round. ThisworkflowisillustratedinFigure2. thananincorrectone. Arandomuncertaintymetric
wouldhaveanAUROCof0.5,whileaperfectone
5 Results
wouldhaveanAUROCof1.
Inthissection,wefirstanalyzetheeffectivenessof
each uncertainty incorporation method, and then 5.2 UncertaintyMetrics
analyzetheeffectivenessoftheuncertaintymetrics.
The best-performing uncertainty metric was the
Oraclemetric. MeanTokenEntropyrankednext,
5.1 UncertaintyIncorporationMethods
withdebatesusingitconsistentlyachievinghigher
Table 1 presents a comparison of the results ob-
averageaccuraciesthandebatesusingTokenSAR,
tainedusingdifferentcombinationsofuncertainty
asshowninTable1. MeanTokenEntropyachieved
metrics(MeanTokenEntropy,TokenSAR,andOra-
anaverageAUROCacrossallexperimentsof0.627,
cle)andmethods(ConfidenceinPrompt,Attention-
compared to 0.617 for TokenSAR. Full AUROC
1https://github.com/hendrycks/test resultsareshowninAppendixB.
7
oitaR
tnemevorpmI
ycaruccADistribution of Uncertainties for Correct and Incorrect Responses
Mean Token Entropy TokenSAR
3.0 2.5
Correct Responses Correct Responses
2.5 Mean Correct: 0.256 Mean Correct: 0.251
2.0
Incorrect Responses Incorrect Responses
2.0 Mean Incorrect: 0.324 Mean Incorrect: 0.315
1.5
1.5
1.0
1.0
0.5
0.5
0.0 0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4
Uncertainty Uncertainty
Figure5: Distributionofuncertaintiesforcorrectandincorrectanswersacrossallexperiments,asmeasuredbythe
uncertaintymetricsMeanTokenEntropyandTokenSAR.Generally,correctanswersexhibitloweruncertainties
thanincorrectones,indicatingthatalthoughnotperfect,uncertaintymetricsareusefulfordistinguishingbetween
accurateresponsesandthosewheretheagentmaybehallucinating.
To further analyze the uncertainty metrics and Estimator Method MMLU-0
understandtheirimpact,Figure5presentsthedis-
N/A Standard 0.663
tributionsofuncertaintiesforresponsescontaining
correctanswersversusincorrectanswersacrossall Entropy Prompt 0.650
benchmarks and uncertainty incorporation meth- Attention-Others 0.670
ods. Theleftplotillustratestheuncertaintieswhen Attention-All 0.633
using Mean Token Entropy, while the right plot
Oracle Prompt 0.687
depicts uncertainties when using TokenSAR. As
Attention-Others 0.720
showninTable1,MeanTokenEntropyachieved
Attention-All 0.753
slightly higher accuracy than TokenSAR on av-
erage. Examining the average uncertainties for
Table2: Performancecomparisonofdifferentmethods
correct and incorrect responses, Mean Token En- anduncertaintyestimatorsontheMMLUbenchmark
tropyhasaratioofaveragecorrecttoaveragein- usingzero-shotpromptingandLlama-3astheLLM.
correctof1.264,comparedto1.258forTokenSAR.
This suggests that Mean Token Entropy slightly
6 Conclusion
outperformsTokenSARindifferentiatingbetween
correct and incorrect responses, while also being We present DebUnc, a framework that integrates
lesscomputationallydemanding. However,theper- confidence estimations into multi-agent debates.
formancedifferenceisminimalandpossiblyfalls Thisaddressesthechallengeofdeterminingwhoto
withinthemarginoferror. trustwhenagentspresentdifferentanswers. Incor-
poratingconfidencelevelsintothedebateprovides
5.3 LlamaEvaluation
agentswithamethodtoevaluatethereliabilityof
Finally, Table 2 presents the results of a small- theotheragents. Weuseuncertaintymetricstoesti-
scaletestusingLlama-3-8B-InstructontheMMLU matetheLLM’sconfidencebasedontheprobabil-
benchmarkwithzero-shotprompting. Theresults itydistributiongeneratedforeachtoken. Tocom-
demonstratethatAttention-All,pairedwiththeOr- municateconfidence,weadjustedtheLLMatten-
acle uncertainty metric, consistently delivers the tionmechanismtomodifytokenweightsbasedon
highestperformance. However,performancedrops confidencelevels,andwealsoexploredusingtex-
whenusingMeanTokenEntropyastheuncertainty tualpromptsforthispurpose. Ourfindingsindicate
estimator. While a more extensive evaluation is that adjusting attention is more effective, which
requiredtomakedefinitiveconclusionsaboutDe- showsthatinformationcanbeconveyedtoLLMs
bUnc performance on Llama-3, the consistently throughmethodsbeyondtraditionaltextprompts.
highperformanceofAttention-Allwiththenoise- Attentionscalingcanbeappliedwheneverpartsof
freeOraclemetricindicatesitseffectivenessincon- theinputshouldbeprioritized,andwehopefuture
veyingagentuncertainty. workexploresthisideafurther.
8
ytisneD ytisneD7 Limitations Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Onekeylimitationofthemethodspresentedisthe Neelakantan,PranavShyam,GirishSastry,Amanda
relianceonopen-sourceLLMs,asattentionscaling Askell,etal.2020. Languagemodelsarefew-shot
learners. Advancesinneuralinformationprocessing
requiresmodificationstothemodel’ssourcecode.
systems,33:1877–1901.
Additionally,obtainingtokenprobabilitiescanbe
challengingwithproprietaryLLMs,makingitdif- Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,
Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan
ficulttocomputeuncertainty. Whileopen-source
Liu.2023. Chateval: Towardsbetterllm-basedeval-
LLMssuchasMistral7B(Jiangetal.,2023)and uatorsthroughmulti-agentdebate. ArXivpreprint,
Llama3(AI@Meta,2024)arequitepowerful,they abs/2308.07201.
donotyetmatchtheperformanceofleadingpro-
Justin Chih-Yao Chen, Swarnadeep Saha, and Mohit
prietarymodels. Bansal. 2023. Reconcile: Round-table conference
Inaddition,theattentionscalingmethodissen- improves reasoning via consensus among diverse
llms. arXivpreprintarXiv:2309.13007.
sitivetotheorderofagentresponsesintheprompt.
Forexample,ifagent2’sresponseappearsbefore PaulFChristiano,JanLeike,TomBrown,MiljanMar-
agent3’sresponse,thentheembeddingsfortokens tic, Shane Legg, and Dario Amodei. 2017. Deep
reinforcementlearningfromhumanpreferences. Ad-
from agent 3 will have been influenced by agent
vancesinneuralinformationprocessingsystems,30.
2’sresponse,butnotviceversaduetotheunidirec-
tionalattentionused. Thiscouldallowinformation Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
MarkChen,HeewooJun,LukaszKaiser,Matthias
from agent 2 to leak through, even if we focus
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
entirelyonagent3.
Nakano, Christopher Hesse, and John Schulman.
Lastly, ourexperimentalsetupalwaysusesthe 2021. Training verifiers to solve math word prob-
sameLLMforeachagent,witheachagentbeing lems. Preprint,arXiv:2110.14168.
giventhesamerole. Althoughthisiseffectivefor
Yilun Du, Shuang Li, Antonio Torralba, Joshua B.
multi-agent debates, it may be worthwhile to ex- Tenenbaum, and Igor Mordatch. 2023. Improving
plorecombinationsofdifferentLLMs,suchaspair- factualityandreasoninginlanguagemodelsthrough
multiagentdebate. Preprint,arXiv:2305.14325.
ingsmallerLLMsfine-tunedonspecificdomains
withlargerLLMsthathavebroaderknowledge. Hanyu Duan, Yi Yang, and Kar Yan Tam. 2024. Do
llms know about hallucination? an empirical in-
EthicsStatement vestigation of llm’s hidden states. ArXiv preprint,
abs/2402.09733.
Deploying large language models (LLMs) to the
JinhaoDuan, HaoCheng, ShiqiWang, AlexZavalny,
generalpublicrequiresthemtobetrustworthyand ChenanWang,RenjingXu,BhavyaKailkhura,and
reliable, particularly in high-risk scenarios. This KaidiXu.2023. Shiftingattentiontorelevance: To-
wardstheuncertaintyestimationoflargelanguage
concerngainsmoreimportancewhenLLMsinter-
models. Preprint,arXiv:2307.01379.
actwithinagentframeworks. Weforeseeafuture
whereLLMsinteractwithotherLLMstoachieve Ekaterina Fadeeva, Aleksandr Rubashevskii, Artem
Shelmanov, Sergey Petrakov, Haonan Li, Hamdy
complextasks. Inthiswork,wetakeasteptowards
Mubarak,EvgeniiTsymbalov,GlebKuzmin,Alexan-
achieving reliable communication among agents
der Panchenko, Timothy Baldwin, et al. 2024.
byincorporatinguncertaintyestimations. Fact-checking the output of large language mod-
elsviatoken-leveluncertaintyquantification. ArXiv
preprint,abs/2403.04696.
References
Ekaterina Fadeeva, Roman Vashurin, Akim Tsvigun,
ArtemVazhentsev,SergeyPetrakov,KirillFedyanin,
LukasAichberger,KajetanSchweighofer,MykytaIelan-
Daniil Vasilev, Elizaveta Goncharova, Alexander
skyi, and Sepp Hochreiter. 2024. Semantically di-
Panchenko, Maxim Panov, Timothy Baldwin, and
verselanguagegenerationforuncertaintyestimation
Artem Shelmanov. 2023. Lm-polygraph: Uncer-
inlanguagemodels. ArXivpreprint,abs/2406.04306.
tainty estimation for language models. Preprint,
arXiv:2311.07383.
AI@Meta.2024. Llama3modelcard.
Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan
AlfonsoAmayuelas,LiangmingPan,WenhuChen,and Ding, Vidhisha Balachandran, and Yulia Tsvetkov.
WilliamWang.2023. Knowledgeofknowledge: Ex- 2024. Don’t hallucinate, abstain: Identifying llm
ploringknown-unknownsuncertaintywithlargelan- knowledgegapsviamulti-llmcollaboration. ArXiv
guagemodels. ArXivpreprint,abs/2305.13712. preprint,abs/2402.00367.
9Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, StephanieLin,JacobHilton,andOwainEvans.2022b.
Frédéric Blain, Francisco Guzmán, Mark Fishel, TruthfulQA:Measuringhowmodelsmimichuman
NikolaosAletras,VishravChaudhary,andLuciaSpe- falsehoods. InProceedingsofthe60thAnnualMeet-
cia.2020. Unsupervisedqualityestimationforneural ingoftheAssociationforComputationalLinguistics
machinetranslation. TransactionsoftheAssociation (Volume1: LongPapers),pages3214–3252,Dublin,
forComputationalLinguistics,8:539–555. Ireland.AssociationforComputationalLinguistics.
Dan Hendrycks, Collin Burns, Steven Basart, Andy ZhenLin,ShubhenduTrivedi,andJimengSun.2023.
Zou,MantasMazeika,DawnSong,andJacobStein- Generating with confidence: Uncertainty quantifi-
hardt.2021. Measuringmassivemultitasklanguage cationforblack-boxlargelanguagemodels. ArXiv
understanding. In9thInternationalConferenceon preprint,abs/2305.19187.
LearningRepresentations,ICLR2021,VirtualEvent,
Austria,May3-7,2021.OpenReview.net. FuxiaoLiu,KevinLin,LinjieLi,JianfengWang,Yaser
Yacoob,andLijuanWang.2023. Mitigatinghalluci-
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng nationinlargemulti-modalmodelsviarobustinstruc-
Cheng,JinlinWang,CeyaoZhang,ZiliWang,Steven tiontuning. InTheTwelfthInternationalConference
KaShingYau,ZijuanLin,LiyangZhou,etal.2023. onLearningRepresentations.
Metagpt: Metaprogrammingformulti-agentcollab-
orativeframework. ArXivpreprint,abs/2308.00352. YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Ishii,andPascaleFung.2023. Towardsmitigating
Roberta: A robustly optimized bert pretraining ap-
LLM hallucination via self reflection. In Findings
proach. Preprint,arXiv:1907.11692.
of the Association for Computational Linguistics:
EMNLP2023,pages1827–1843,Singapore.Associ- DanielMcDonald,RachaelPapadopoulos,andLeslie
ationforComputationalLinguistics. Benningfield.2024. Reducingllmhallucinationus-
ingknowledgedistillation: Acasestudywithmistral
AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen-
largeandmmlubenchmark. AuthoreaPreprints.
sch,ChrisBamford,DevendraSinghChaplot,Diego
delasCasas,FlorianBressand,GiannaLengyel,Guil- OpenAI. 2024. Gpt-4 technical report. Preprint,
laumeLample,LucileSaulnier,LélioRenardLavaud,
arXiv:2303.08774.
Marie-AnneLachaux,PierreStock,TevenLeScao,
Thibaut Lavril, Thomas Wang, Timothée Lacroix, ChenQian,WeiLiu,HongzhangLiu,NuoChen,Yufan
andWilliamElSayed.2023. Mistral7b. Preprint, Dang,JiahaoLi,ChengYang,WeizeChen,Yusheng
arXiv:2310.06825. Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu,
and Maosong Sun. 2024. Chatdev: Communica-
SauravKadavath,TomConerly,AmandaAskell,Tom
tive agents for software development. Preprint,
Henighan, Dawn Drain, Ethan Perez, Nicholas
arXiv:2307.07924.
Schiefer,ZacHatfield-Dodds,NovaDasSarma,Eli
Tran-Johnson, et al. 2022. Language models AlecRadford,KarthikNarasimhan,TimSalimans,and
(mostly) know what they know. ArXiv preprint, Ilya Sutskever. 2018. Improving language under-
abs/2207.05221. standingbygenerativepre-training.
LorenzKuhn,YarinGal,andSebastianFarquhar.2023.
VipulaRawte,AmitSheth,andAmitavaDas.2023. A
Semanticuncertainty: Linguisticinvariancesforun-
surveyofhallucinationinlargefoundationmodels.
certaintyestimationinnaturallanguagegeneration.
arXivpreprintarXiv:2309.05922.
ArXivpreprint,abs/2302.09664.
Xiaoxi Sun, Jinpeng Li, Yan Zhong, Dongyan Zhao,
Guohao Li, Hasan Abed Al Kader Hammoud, Hani
and Rui Yan. 2024. Towards detecting llms hallu-
Itani,DmitriiKhizbullin,andBernardGhanem.2023.
cinationviamarkovchain-basedmulti-agentdebate
Camel: Communicative agents for" mind" explo-
framework. arXive-prints,pagesarXiv–2406.
rationoflargescalelanguagemodelsociety.
Katherine Tian, Eric Mitchell, Allan Zhou, Archit
Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang,
Sharma,RafaelRafailov,HuaxiuYao,ChelseaFinn,
YanWang,RuiWang,YujiuYang,ZhaopengTu,and
andChristopherDManning.2023. Justaskforcali-
ShumingShi.2023. Encouragingdivergentthinking
bration: Strategiesforelicitingcalibratedconfidence
inlargelanguagemodelsthroughmulti-agentdebate.
scoresfromlanguagemodelsfine-tunedwithhuman
ArXivpreprint,abs/2305.19118.
feedback. arXivpreprintarXiv:2305.14975.
Yuxin Liang, Zhuoyang Song, Hao Wang, and Jiax-
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
ing Zhang. 2024. Learning to trust your feelings:
Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz
Leveragingself-awarenessinllmsforhallucination
mitigation. ArXivpreprint,abs/2401.15449. Kaiser,andIlliaPolosukhin.2017. Attentionisall
youneed. InAdvancesinNeuralInformationPro-
StephanieLin,JacobHilton,andOwainEvans.2022a. cessingSystems30: AnnualConferenceonNeural
Teaching models to express their uncertainty in InformationProcessingSystems2017,December4-9,
words. 2017,LongBeach,CA,USA,pages5998–6008.
10Artem Vazhentsev, Gleb Kuzmin, Akim Tsvigun,
AlexanderPanchenko,MaximPanov,MikhailBurt-
sev, and Artem Shelmanov. 2023. Hybrid uncer-
taintyquantificationforselectivetextclassification
inambiguoustasks. InProceedingsofthe61stAn-
nualMeetingoftheAssociationforComputational
Linguistics(Volume1: LongPapers),pages11659–
11681,Toronto,Canada.AssociationforComputa-
tionalLinguistics.
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran
Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun
Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan
Awadallah, Ryen W White, Doug Burger, and Chi
Wang. 2023. Autogen: Enabling next-gen llm ap-
plications via multi-agent conversation. Preprint,
arXiv:2308.08155.
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie
Fu, Junxian He, and Bryan Hooi. 2023. Can llms
express their uncertainty? an empirical evaluation
of confidence elicitation in llms. arXiv preprint
arXiv:2306.13063.
Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze
Liu, Xingyao Wang, Yangyi Chen, and Jing Gao.
2024. Sayself: Teaching llms to express confi-
dencewithself-reflectiverationales. ArXivpreprint,
abs/2405.20974.
YasinAbbasiYadkori,IljaKuzborskij,AndrásGyörgy,
and Csaba Szepesvári. 2024. To believe or not to
believeyourllm. ArXivpreprint,abs/2406.02543.
Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan
Ning,andLiYuan.2023. Llmlies: Hallucinations
are not bugs, but features as adversarial examples.
ArXivpreprint,abs/2310.01469.
Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu,
XipengQiu, andXuanjingHuang.2023. Dolarge
languagemodelsknowwhattheydon’tknow? ArXiv
preprint,abs/2305.18153.
CaiqiZhang,FangyuLiu,MarcoBasaldella,andNigel
Collier.2024. Luq: Long-textuncertaintyquantifica-
tionforllms. ArXivpreprint,abs/2403.20279.
JintianZhang, XinXu, andShuminDeng.2023. Ex-
ploring collaboration mechanisms for llm agents:
A social psychology view. ArXiv preprint,
abs/2310.02124.
11A ExampleDebate
Thisisafulldebateonzero-shotMMLUusingMistral-7BastheLLM.ItusestheConfidenceinPrompt
methodforincorporatinguncertaintywiththeOracleuncertaintymetric. Forconciseness,theuserprompts
forrounds2and3use“<agentiresponse>"toreferencetheresponsefromagentiinthepreviousround.
Agent1 Agent2 Agent3
User,Round1
Answerthefollowingmultiplechoicequestion. Thelastlineofyourresponseshouldbeofthefollowingformat: ’Answer:
$LETTER’(withoutquotes)whereLETTERisoneofABCD.Thinkstepbystepbeforeanswering.
Which of these combinations of clinical features is most suggestive of mixed mitral valve disease with a predomi-
nanceofmitralregurgitation?
A.Displacedapexbeat;softfirstheartsound;pan-systolicmurmur;shortmid-diastolicmurmur
B.Irregularly,irregularpulse;displacedapexbeat;ejectionsystolicmurmur;shortmid-diastolicmurmur
C.Displacedapexbeat;normalfirstheartsound;pan-systolicmurmur;longmid-diastolicmurmur
D.Tappingapexbeat;loudfirstheartsound;pan-systolicmurmur;longmid-diastolicmurmur
Assistant,Round1
Basedonthegivenclinicalfeatures, Basedonthegivenclinicalfeatures,the Thecombinationofadisplacedapex
optionC:Displacedapexbeat;normal combinationmostsuggestiveofmixed beat,apan-systolicmurmor,andalong
firstheartsound;pan-systolicmurmur; mitralvalvediseasewitha mid-diastolicmurmurismost
longmid-diastolicmurmurisleast predominanceofmitralregurgitation suggestiveofmitralstenosis.Thus,the
suggestiveofmixedmitralvalve wouldbe: answertothequestionisD.however,
diseasewithapredominanceofmitral wewereaskedforacombinationthatis
regurgitation. C.Displacedapexbeat;normalfirst mostsuggestiveofmixedmitralvalve
heartsound;pan-systolicmurmor;long diseasewithapredominanceofmitral
Thefeaturesmostsuggestiveofmixed mid-diastolicmurmur regurgitation.Withthisinmind,the
mitralvalvediseasewitha correctansweris:C.Displacedapex
predominanceofmitralregurgitation Explanation: beat;normalfirstheartsound;
are: Thepresenceofadisplacedapexbeat pan-systolicmurmur;long
andapan-systolicmurmurpoints mid-diastolicmurmur
1.Displacedapexbeat:Thiscanoccur towardsmitralvalvedisease.However,
duetochronicvolumeoverloador thedurationandtimingofthe Explanation:Mixedmitralvalve
dilatationoftheleftventriclefrom additionaldiastolicmurmurhelps diseasereferstoaconditioninwhich
mitralregurgitation. distinguishtheunderlyingetiology.A bothmitralregurgitationandmitral
2.Softorabsentfirstheartsound:This longmid-diastolicmurmurismore stenosisarepresent.Thepresenceofa
canbeduetothedecreasedforceof suggestiveoffunctionalmitral predominantlyregurgitantjetsuggestsa
mitralvalveclosureduringdiastole. regurgitation,whichisacomponentof moreadvancedstateofthedisease.
3.Pan-systolicmurmur:Thisis mixedmitralvalvediseasewitha Adisplacedapexbeatcanbeseenin
typicallyheardinmitralregurgitation predominanceofmitralregurgitation. conditionsofvolumeoverload,suchas
duetothecontinuousregurgitantjet Therefore,optionCisthecorrect mitralregurgitation,andisless
throughoutthecardiaccycle. answer. commoninmitralstenosis.Anormal
4.Longmid-diastolicmurmur:This firstheartsoundandalong
canoccurduetothecontinuedmitral Answer:C mid-diastolicmurmuraremorelikelyto
regurgitantjetduringdiastole. beheardinmitralregurgitationthan
mitralstenosis,astheyrepresentthe
Therefore,thecorrectansweris: openingandclosingofthemitralvalve
duringdiastole.Therefore,optionC,
A.Displacedapexbeat;softfirstheart withadisplacedapexbeat,normalfirst
sound;pan-systolicmurmur;long heartsound,andalongmid-diastolic
mid-diastolicmurmur murmur,isthemostsuggestiveof
mixedmitralvalvediseasewitha
Answer:A predominanceofmitralregurgitation.
Answer:C.
12Agent1(cont.) Agent2(cont.) Agent3(cont.)
User,Round2
Thesearesolutionsandconfidence Thesearesolutionsandconfidence Thesearesolutionsandconfidence
valuesfrom1to10(highermeansmore valuesfrom1to10(highermeansmore valuesfrom1to10(highermeansmore
confident)totheproblemfromother confident)totheproblemfromother confident)totheproblemfromother
agents: agents: agents:
Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis
1):“‘<agent2response>“‘ 10):“‘<agent1response>“‘ 10):“‘<agent1response>“‘
Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis
1):“‘<agent3response>“‘ 1):“‘<agent3response>“‘ 1):“‘<agent2response>“‘
Basedofftheopinionofotheragents, Basedofftheopinionofotheragents, Basedofftheopinionofotheragents,
canyougiveanupdatedresponse?Do canyougiveanupdatedresponse?Do canyougiveanupdatedresponse?Do
notmentionyourconfidence.Think notmentionyourconfidence.Think notmentionyourconfidence.Think
stepbystepbeforeanswering.Thelast stepbystepbeforeanswering.Thelast stepbystepbeforeanswering.Thelast
lineofyourresponseshouldbeofthe lineofyourresponseshouldbeofthe lineofyourresponseshouldbeofthe
followingformat:’Answer:$LETTER’ followingformat:’Answer:$LETTER’ followingformat:’Answer:$LETTER’
(withoutquotes)whereLETTERisone (withoutquotes)whereLETTERisone (withoutquotes)whereLETTERisone
ofABCD. ofABCD. ofABCD.
Assistant,Round2
Basedontheinformationprovidedby Basedontheclinicalfeaturesprovided Basedonthediscussionsamong
theotheragents,thecombinationmost andtheconsensusofotheragents, differentagents,themostsuggestive
suggestiveofmixedmitralvalve optionC:Displacedapexbeat;normal combinationofclinicalfeaturesfor
diseasewithapredominanceofmitral firstheartsound;pan-systolicmurmur; mixedmitralvalvediseasewitha
regurgitationis: longmid-diastolicmurmuristhemost predominanceofmitralregurgitationis:
suggestiveofmixedmitralvalve
A.Displacedapexbeat;softfirstheart diseasewithapredominanceofmitral A.Displacedapexbeat;softfirstheart
sound;pan-systolicmurmur;long regurgitation. sound;pan-systolicmurmur;long
mid-diastolicmurmur. mid-diastolicmurmur
Answer:C.
Thepresenceofadisplacedapexbeat, Explanation:
softfirstheartsound,andprolonged Mixedmitralvalvediseaseis
pan-systolicmurmurindicatemitral characterizedbytheco-existenceof
valvedisease.Thedurationandtiming mitralstenosisandmitralregurgitation.
ofthediastolicmurmurcanbeusedto Thepresenceofadisplacedapexbeat,
distinguishbetweenmitralstenosisand softfirstheartsound,pan-systolic
mitralregurgitation.Along, murmur,andlongmid-diastolic
holodiastolicmurmurismore murmurcansuggestadiagnosisof
commonlyheardinmitralregurgitation mixedmitralvalvediseasewitha
thanmitralstenosis.Therefore,the predominanceofmitralregurgitation.
presenceofalongmid-diastolic Thedisplacedapexbeatcanoccurdue
murmurwithadisplacedapexbeatand tochronicvolumeoverloadordilatation
softfirstheartsoundsuggestsmixed oftheleftventricle,asseeninmitral
mitralvalvediseasewitha regurgitation.Thesoftorabsentfirst
predominanceofmitralregurgitation. heartsoundcanbeduetothedecreased
forceofmitralvalveclosureinmitral
Answer:A. regurgitation.Thepan-systolicmurmur
istypicallyheardinmitralregurgitation
duetothecontinuousregurgitantjet
throughoutthecardiaccycle.Thelong
mid-diastolicmurmurcanoccurdueto
thecontinuedmitralregurgitantjet
duringdiastole.Therefore,the
combinationoftheseclinicalfindings,
A.Displacedapexbeat;softfirstheart
sound;pan-systolicmurmur;long
mid-diastolicmurmur,ismost
suggestiveofmixedmitralvalve
diseasewithapredominanceofmitral
regurgitation.
Answer:A.
13Agent1(cont.) Agent2(cont.) Agent3(cont.)
User,Round3
Thesearesolutionsandconfidence Thesearesolutionsandconfidence Thesearesolutionsandconfidence
valuesfrom1to10(highermeansmore valuesfrom1to10(highermeansmore valuesfrom1to10(highermeansmore
confident)totheproblemfromother confident)totheproblemfromother confident)totheproblemfromother
agents: agents: agents:
Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis
1):“‘<agent2response>“‘ 10):“‘<agent1response>“‘ 10):“‘<agent1response>“‘
Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis Oneagentsolution(confidencelevelis
10):“‘<agent3response>“‘ 10):“‘<agent3response>“‘ 1):“‘<agent2response>“‘
Basedofftheopinionofotheragents, Basedofftheopinionofotheragents, Basedofftheopinionofotheragents,
canyougiveanupdatedresponse?Do canyougiveanupdatedresponse?Do canyougiveanupdatedresponse?Do
notmentionyourconfidence.Think notmentionyourconfidence.Think notmentionyourconfidence.Think
stepbystepbeforeanswering.Thelast stepbystepbeforeanswering.Thelast stepbystepbeforeanswering.Thelast
lineofyourresponseshouldbeofthe lineofyourresponseshouldbeofthe lineofyourresponseshouldbeofthe
followingformat:’Answer:$LETTER’ followingformat:’Answer:$LETTER’ followingformat:’Answer:$LETTER’
(withoutquotes)whereLETTERisone (withoutquotes)whereLETTERisone (withoutquotes)whereLETTERisone
ofABCD. ofABCD. ofABCD.
Assistant,Round3
Basedonthediscussionsamong Basedontheconsensusofotheragents, Basedontheinformationprovidedby
differentagents,thecombinationof thecombinationmostsuggestiveof variousagentsandtheconsensus
clinicalfeaturesmostsuggestiveof mixedmitralvalvediseasewitha reached,thecombinationofclinical
mixedmitralvalvediseasewitha predominanceofmitralregurgitationis: featuresmostsuggestiveofmixed
predominanceofmitralregurgitationis: A.Displacedapexbeat;softfirstheart mitralvalvediseasewitha
sound;pan-systolicmurmur;long predominanceofmitralregurgitationis:
A.Displacedapexbeat;softfirstheart mid-diastolicmurmur.
sound;pan-systolicmurmur;long A.Displacedapexbeat;softfirstheart
mid-diastolicmurmur. Answer:A. sound;pan-systolicmurmur;long
mid-diastolicmurmur
Explanation:
Mixedmitralvalvediseaseisdefinedas Here’stheexplanation:
thepresenceofbothmitralstenosisand Thepresenceofadisplacedapexbeat
mitralregurgitation.Theclinical andapan-systolicmurmursuggest
presentationofmixedmitralvalve mitralvalvedisease.However,the
diseasecanvarydependingonthe durationandtimingofthediastolic
severityandpredominanceofeach murmurcanhelpdistinguishbetween
component. mitralstenosisandmitralregurgitation.
Mitralregurgitationismorecommonly
Adisplacedapexbeat,softfirstheart associatedwithalong,holodiastolicor
sound,pan-systolicmurmur,andlong mid-diastolicmurmur,whilemitral
mid-diastolicmurmuraremore stenosistypicallyhasashort,
indicativeofmitralregurgitationthan mid-diastolicmurmur.Inthisscenario,
mitralstenosis.Thedisplacedapexbeat thelongmid-diastolicmurmur,along
canresultfromtheincreasedvolume withthedisplacedapexbeatandsoft
loadintheleftventricleduetomitral firstheartsound,makesmixedmitral
regurgitation.Asoftorabsentfirst valvediseasewithapredominanceof
heartsoundmaybeheardinmitral mitralregurgitationthemostlikely
regurgitationduetothedecreasedforce diagnosis.Therefore,theansweris:
ofmitralvalveclosure,whilethe
pan-systolicmurmurandlong Answer:A.
mid-diastolicmurmurarecharacteristic
featuresofmitralregurgitation.
Therefore,thecombinationofthese
clinicalfindings,A.Displacedapex
beat;softfirstheartsound;pan-systolic
murmur;longmid-diastolicmurmur,is
mostsuggestiveofmixedmitralvalve
diseasewithapredominanceofmitral
regurgitation.
Answer:A.
14B FullUncertaintyMetricResults
Estimator Method MMLU-0 MMLU-5 GSM8k Arithmetic TruthfulQA Avg.
Entropy Prompt 0.630 0.637 0.711 0.631 0.585 0.639
Attn-Others 0.628 0.611 0.696 0.598 0.563 0.619
Attn-All 0.647 0.618 0.716 0.573 0.568 0.624
TokenSAR Prompt 0.633 0.612 0.710 0.615 0.566 0.627
Attn-Others 0.622 0.602 0.694 0.600 0.557 0.615
Attn-All 0.621 0.592 0.684 0.591 0.553 0.608
Oracle Prompt 1.000 1.000 1.000 1.000 1.000 1.000
Attn-Others 1.000 1.000 1.000 1.000 1.000 1.000
Attn-All 1.000 1.000 1.000 1.000 1.000 1.000
Table 3: This table displays the uncertainty metric AUROC values for each experiment run with Mistral-7B.
‘MMLU-0’denoteszero-shotpromptingonMMLU,while‘MMLU-5’represents5-shotprompting. Theother
benchmarksusedzero-shotprompting. The‘Avg.’ columnshowstheaverageAUROCforalltests. Bydefinition,
theOraclemetricachievedperfectAUROCscores. Amongtheremainingmetrics,MeanTokenEntropydelivered
slightlybetterperformancethanTokenSARdespitebeingcheapertorun.
15C Prompts
Thetablebelowdisplaysthepromptsusedtofacilitatethedebates. Textingreenisonlyincludedwhen
usingtheConfidenceinPromptmethod,andtextinblueisspecifictoeachdebate.
Benchmark PromptType Prompt
MMLU Initial,0-shot Answerthefollowingmultiplechoicequestion.Thelastlineofyourresponseshould
beofthefollowingformat:’Answer:$LETTER’(withoutquotes)whereLETTERis
oneofABCD.Thinkstepbystepbeforeanswering.
<question>
Initial,5-shot Answerthefollowingmultiplechoicequestion.
Examples:
<5examplequestionsandanswers>
—
YOURTASK
Answer the following question. Think step by step before answering. The
lastlineofyourresponseshouldbeofthefollowingformat: ’Answer: $LETTER’
(withoutquotes)whereLETTERisoneofABCD.
<question>
Debate Thesearesolutionsandconfidencevaluesfrom1to10(highermeansmoreconfident)
totheproblemfromotheragents:
Oneagentsolution(confidencelevelisc):<agentresponse>
Oneagentsolution(confidencelevelisc):<agentresponse>
Based off the opinion of other agents, can you give an updated response? Do
not mention your confidence. Think step by step before answering. The last line
ofyourresponseshouldbeofthefollowingformat: ’Answer: $LETTER’(without
quotes)whereLETTERisoneofABCD.
GSM8k Initial Answerthefollowingmathproblem. Thelastlineofyourresponseshouldbeofthe
followingformat: ’Answer: $INTEGER’(withoutquotes)whereINTEGERisthe
integeranswer.Thinkstepbystepbeforeanswering.
<question>
Debate Thesearesolutionsandconfidencevaluesfrom1to10(highermeansmoreconfident)
totheproblemfromotheragents:
Oneagentsolution(confidencelevelisc):<agentresponse>
Oneagentsolution(confidencelevelisc):<agentresponse>
Based off the opinion of other agents, can you provide an updated response?
Theoriginalproblemis:
<question>
Do not mention your confidence. The last line of your response should be of
thefollowingformat:’Answer:$INTEGER’(withoutquotes)whereINTEGERisthe
integeranswer.
16Benchmark PromptType Prompt
Arithmetic Initial Whatistheresultof<a+b*c+d>?Statethefinalanswerattheendofyourresponse.
Debate Thesearesolutionsandconfidencevaluesfrom1to10(highermeansmoreconfident)
totheproblemfromotheragents:
Oneagentsolution(confidencelevelisc):<agentresponse>
Oneagentsolution(confidencelevelisc):<agentresponse>
Based off the opinion of other agents, can you provide an updated answer?
Donotmentionyourconfidence.Statethefinalanswerattheendofyourresponse.
TruthfulQA Initial Answerthefollowingmultiplechoicequestion:
<question>
Think step by step before answering. The last line of your response should
beofthefollowingformat:’Answer:$LETTER’(withoutquotes)whereLETTERis
oneof<options>.
Debate These are the selections and confidence values from 1 to 10 (higher means more
confident)fromotheragents:
Oneagentsolution(confidencelevelisc):<agentresponse>
Oneagentsolution(confidencelevelisc):<agentresponse>
Can you double check that your response is correct? Do not mention your
confidence.Thelastlineofyourresponseshouldbeofthefollowingformat:’Answer:
$LETTER’(withoutquotes)whereLETTERisoneof<options>.
17