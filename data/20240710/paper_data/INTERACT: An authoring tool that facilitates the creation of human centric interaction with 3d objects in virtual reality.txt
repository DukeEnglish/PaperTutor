INTERACT: An authoring tool that facilitates
the creation of human centric interaction with 3d
∗
objects in virtual reality
Rama Krishnan Gopal Ramasamy Thandapani†
rama.gopal@ls-group.fr
Benjamin Capel†
benjamin.capel@ls-group.fr
Antoine Lasnier† Ioannis Chatzigiannakis‡
antoine.lasnier@ls-group.fr ichatz@diag.uniroma1.it
July 10, 2024
Abstract
A widespread adoption of Virtual, Augmented, and Mixed Reality
(VR/AR/MR), collectively referred to as Extended Reality (XR), has
become a tangible possibility to revolutionize educational and training
scenariosbyofferingimmersive, interactiveexperiences. Inthispaperwe
present INTERACT, an authoring tool for creating advanced 3D physics-
basedIntelligentTutoringSystems(ITS)byindividualdevelopersorsmall-
scale development teams. INTERACT is based on a cutting edge physics
engine allowing realistic interactions such as collision detection and er-
gonomic evaluations. We demonstrate the benefits of INTERACT by de-
veloping a set of training scenarios for a use case of a Laser cutting ma-
chine. Theusecaseillustratesthenumerouspossibilitiessuchascreating
interactionwithobjects,easeofconfiguringascenarioandhowtodesign
the visual effects to the machine.
1 Introduction
Currently, there is a significant surge in interest surrounding Virtual, Aug-
mented, and Mixed Reality (VR/AR/MR), collectively referred to as Extended
Reality(XR)[13,4]. ThewidespreadadoptionofXRinvariousinnovativefields
∗ThispaperwassupportedbytheEuropeanUnion’sHorizonHADEAresearchandinno-
vationprogramundergrantAgreement101092851XR2LEARNproject.
†LSGroup,Paris,France
‡SapienzaUniversityofRome,Rome,Italy
1
4202
luJ
9
]CH.sc[
1v76960.7042:viXrahas become a tangible possibility due to groundbreaking research and continu-
ous advancements of computing power, particularly on mobile devices, as well
as the global expansion of connectivity. With the widespread availability of
powerful mobile devices and continuous wireless internet connectivity, XR ap-
plications can now operate in real-time, on a large scale, and utilize extensive,
up-to-datedata. Furthermore,theexistenceofrobustsoftwarecomponentsthat
offer advanced functionality in accessible, free, and open-source formats allows
individual developers or small-scale development teams to create XR software
with reasonable expectations of business success. XR is no longer confined to
research laboratories or exclusive to established companies with significant in-
vestments in specialized software, hardware, and expert teams. Instead, it can
be pursued as a feasible endeavor.
Emerging XR technologies have the potential to be applied in various fields
with meaningful and beneficial outcomes. Beyond gaming and entertainment,
XR applications in the field of education and training lag significantly behind,
despite a wealth of literature highlighting the advantages of XR technologies in
educational settings [3]. These technologies have been shown to expand knowl-
edge areas, provide active learning experiences instead of passive information
consumption, enhance understanding of complex concepts and subjects, min-
imize distractions during studying, stimulate creativity among students, and
improvelearningefficiency, amongotherbenefits. Unfortunately, thesefeatures
arecurrentlyperceivedasluxuriesaccessibleonlytothosewhocanaffordthem.
Nevertheless, the continuous need for lifelong learning and the demand to up-
skill or reskill large audiences with varying levels of IT literacy, diverse cultural
and educational backgrounds, and different languages will eventually make the
integration of XR technologies in education and training a necessity. For in-
stance, the manufacturing industry is currently grappling with the challenge of
trainingtheglobalworkforceontheemergingindustry4.0and5.0technologies.
Inordertocatertoevolvinglearningscenariosandeducationalandtraining
requirements,thereisagrowingneedforfast-pacedIntelligentTutoringSystems
(ITS)inmoderneducationaltechnologies. SuchITSmustenabletheadaptation
of interactive and virtual experience-based learning activities. It is therefore
crucialtodevelopauthoringtoolstoallowthefast-pacedcreationofITSoffering
support for a wider range of features beyond basic 3D object manipulation and
avatarnavigationinvirtualenvironments. Theyshouldaddressaspectssuchas
ergonomics, advanced physics for object and trajectory tracking, and more. To
achievethis,newauthoringtoolsneedtobedevelopedthatfacilitatethedesign
of three-dimensional spaces, specifically in constrained physical environments
like construction or manufacturing settings. These enablers will enhance the
efficiencyandeffectivenessofcreatingimmersive3Dspacesthatmeetthedesired
objectives in educational and training contexts.
In this work we present an authoring tool delivered as a Unity plugin which
we call INTERACT that can significantly reduce the time needed to develop an
ITS.Thepluginisano-codegenerictoolforcreatingphysics-basedVRtraining
scenarios. INTERACTisbasedonacuttingedgephysicsengineallowingrealistic
interactions such as collision detection and ergonomic evaluations. The plugin
2allows any of its users to create physically realistic VR simulations for multiple
usages such as training for various fields of applications (heavy industry, edu-
cation, energy) from 3D data (CAD or point clouds) that are to be imported
in the authoring tool. We demonstrate how INTERACT can be used in practice
by developing a training application for a laser cutting machine. The resulting
XR application provides a virtual reality training scenario targetting the main-
tenance tasks of a machine. With the application, the user is taught how to
use a laser cutting machine in a step by step process and also validated with a
scoreintheend. Theapplicationalsoillustratesthenumerouspossibilitiessuch
as creating interaction with objects, ease of configuring a scenario and how to
design the visual effects to the machine.
2 Related Work
Various XR-based authoring tools for developing ITS have been proposed in
the relevant literature to study how they can be used to assist in knowledge
creation [1]. Initially authoring tools provided a low-level framework that re-
quiredtheauthortoprovidecode[11]. Morerecenttoolsarestartingtofollowa
low-code approach that make high-fidelity ITS prototyping easier [12]. Most of
theseauthoringtoolsaregenericandareusedtodevelopeproof-of-conceptITS
withamaingoaltointroducecertainfeaturesandstudyhowtheyareperceived
by non-technical designers [12],[8].
Authoringtoolsencompassavarietyofsoftwareproductsthatofferfunction-
alities for composing, editing, assembling, and managing multimedia objects.
These tools have the potential to decrease obstacles and enhance the accessibil-
ity of ITS for both inexperienced and skilled users, as mentioned by Ososky [9].
Murray [7] shares a similar perspective, asserting that apart from tools created
for internal usage by extensively trained specialists, authoring tools, by their
inherent nature, should be user-friendly for a predetermined target audience.
During the past years a limited number of domain-specific authoring tools have
been proposed for the creation of VR-based ITS [10]. For the case of industry
4.0 environments, ARAUM [5], ARTA [6] and WAAT [2] are among the very
few authoring tools available. These tools focus on how to provide guidance of
the industrial procedures that need to be performed by the user.
Incontrasttotheseapproaches,theembeddedphysicsengineallowsINTER-
ACTtoproviderealisticbehaviourofthedifferentcomponentsthatcomprisean
assembly line and thus move beyong simply displaying the instructions. Differ-
ent components such as the cables, frames and lenses can be properly handled
within the XR environment thus providing an immersive learning experience.
Moreover,sinceINTERACTisimplementedasapluginofUnitygameengine,it
can naturally incorporate elements of gamification which can reinforce the ped-
agogical principles of the learning scenarios. Different diffuclty levels, scoring
systems and awards can help in maintain the user’s interest and focus through-
out the learning process.
33 INTERACT
INTERACT is an Unity plugin that allows users to create a human centric in-
teractionwith3dobjectsinvirtualreality. Ithelpstheuserswithlowtechnical
knowledgetoswiftlysetupa3DsceneinUNITY,physicalizeobjectsandgamify
the scenario. The main features are summarized as follows:
• Embedded physics engine: This handles multi-body dynamics, collision
detection,friction,andkinematics,providingrealisticbehaviorforobjects
in a 3D environment.
• Advanced collision detection: This feature allows accurate and efficient
detection of collisions between objects, even when dealing with complex
models. It includes snapping of lenses, closing of a glass door on a steel
frame
• Cables: The software can simulate cables and flexible beams using finite
element analysis, providing realistic representations of these elements in
the 3D environment.This includes the laser arm belt that is simulated as
the laser arm moves.
• Grab: This feature allows users to directly manipulate 3D objects with
their own hands, providing a more natural and intuitive way to interact
with the virtual environment.Though the application is capable of having
interaction from an accessory like Manus gloves, we decided to have the
Grab interaction with the VR controller but the interaction in game will
represent a human hand.
• Scenarization: Thisisamoduledesignedforassemblytraining,whichcan
beusedtocreateandeditcomplexassemblyscenarios. Thisisthemodule
where it helps us to gamify the scenes and create a pedagogical scenario
which is customised to Maintanence procedures in our application.
Initially the user needs to define among the two preconfigured environment:
an empty white laboratory or a factory environment, as shown in Fig. 1a. The
next step is to choose the hardware devices (Display Device, Hand Tracking,
Body Tracking) through which the user will interact in XR environment, as
shown in Fig. 1b.
The next step is the scenarization, where an assembly sequence is provided.
The assembly sequence is a critical part of the manufacturing process, as it
ensures that the product is assembled correctly and efficiently. Usually the
assembly sequences constitute the practical exercises of a training application.
Theuserisrequiredtodefinetheorderinwhichdifferentpartsareputtogether
to form a complete product. This typically involves a series of steps, in which
each part is added to the product in a specific order. INTERACT helps to
create such assembly sequences by visualizing the different parts and how they
fit together.
4(a) Preconfigured environments (b) Hardware devices
Figure 1: Initial steps to create a new ITS
Figure 2: The Scenario Graph used to create an assembly sequence comprised
of multiple steps
In more details, INTERACT provides the Scenario Graph to create a hierar-
chy of steps that create an assembly sequence. The user introduces 3D objects
and indicates how they are connected through Placing Steps. The user can
encode rules to allow the learning scenario to unlock the next steps. For exam-
ple, the assembly of a wheel starts only if the brake disk is in place AND the
boltshavebeenproperlyscrewed. Severaloptionsareavailabletodescribeyour
assembly process in the Scenario window, including time constraints that are
required before proceeding to a subsequent step, or interaction with robots and
actuators, etc. A scenario can also include Events, that is actions that are only
triggeredonspecificconditions. Forexampletounweldoractivateanotherpart
when a keypoint is reached. Fig. 2 provides an example of the scenario graph
and the series of steps that make up the assembly process.
The Scenario manager automatically handles the visual helpers in runtime
(trajectories, ghost, instruction panel). In Simulation (when you switch to the
PLAYmode),thetransitionbetweenstepsisdonewhentheparttoplacereaches
its target. For a detailed presentation of the implemented actions and events
the interested reader is pointed to the dedicated website of INTERACT1.
1https://light-and-shadows.com/documentation/interact/scenarisation/
#welding-and-alignment
54 Laser Cutting Machine: a use case
We use the INTERACT tool to develop an ITS on how to maintain a Trotec
Speedy 400 laser cutting machine. The application aims to bringing together
peopleandmachinesforsafe,quickandeasyaccesstotrainingsatalowcost,re-
gardlessoftrainees’locationandhierarchicalstatus. TheresultingITSprovides
a VR-based simulation for making the interaction with complex and dangerous
machineryeasyandsafe. Itillustratestheauthoringprocessofimmersivetrain-
ing applications using INTERACT from 3D data import to interaction configu-
ration and scenario description.
The application involves several steps to ensure the machine is properly
maintained and continues to operate efficiently. Initially the user enters the
scene where the Trotec Speedy 400 laser cutting machine is located along with
a working table as shown in Fig. 3. The process typically involves turning off
themachineandunmountingvariouscomponents, suchasthemirror, lens, and
nozzle. The user approaches the machine and by following the instructions,
turns off the machine and then unmounts the components indicated, as shown
in Fig. 4a. In the sequel, the user is requested to wip the lens and nozzle with
a fiber cloth as shown in Fig. 4b. The plate is wiped with a sponge, and the
variouscomponentsareremountedandthemachineisturnedbackon. Removal
orparticlesisalsosimulatedintheapplication. Whenthecleaningiscomplete,
the components need to be remounted. Finally, the working table and main
enclosure are then vacuumed to remove any dust or debris.
A differenting aspect of this application is its commitment to user engage-
ment and effective learning. The application incorporates elements of gamifica-
tion, which are carefully aligned with pedagogical principles. The user is pre-
sentedwithmultipledifficultylevels,whichcatertodifferentlevelsofexperience
and expertise. This strategy not only ensures that the content is appropriate
foreachuser,butalsoprovidesasenseofprogressandaccomplishmentasusers
advance through the levels. Furthermore, a scoring system is implemented at
theendofeachsession. Thescoringsystemisbasedonseveralfactors,including
time consumption, accuracy, and the use of hints or skip buttons. This com-
prehensive approach to scoring encourages users to optimize their performance
while offering meaningful feedback.
5 Conclusions and Future Work
INTERACT provides a no-code approach to developing immersive ITS that is
both accessible and safe. By simulating realistic industrial environments and
processes, we are able to expose students and educators to experiences they
mightnototherwisehaveduetolackofrealequipmentorconcernsaboutsafety
risks associated with operating industrial equipment. We demonstrate how IN-
TERACT can be used in practice by developing a ITS that focuses on how to
maintain a Trotec Speedy 400 laser cutting machine. Through this XR appli-
cation, users can gain valuable practical knowledge and skills in maintaining a
6Figure 3: Laboratory with the Trotec Speedy 400 laser cutting machine and a
working table
(a) (b)
Figure 4: Various components of the laser cutting machine unmounted and
cleaned using different tools
7laser cutting machine – experiences that can be safely replicated and iterated,
fostering deep and effective learning.
References
[1] Narges Ashtari, Andrea Bunt, Joanna McGrenere, Michael Nebeling, and
Parmit K. Chilana. Creating augmented and virtual reality applications:
Currentpractices,challenges,andopportunities. InProceedingsofthe2020
CHI Conference on Human Factors in Computing Systems, CHI ’20, page
1–13, New York, NY, USA, 2020. Association for Computing Machinery.
[2] Pierre B´egout, Thierry Duval, S´ebastien Kubicki, Bertrand Charbonnier,
andEmmanuelBricard.Waat: Aworkstationarauthoringtoolforindustry
4.0. InLucioTommasoDePaolisandPatrickBourdot,editors,Augmented
Reality, Virtual Reality, and Computer Graphics, pages 304–320, Cham,
2020. Springer International Publishing.
[3] Ioannis Chatzigiannakis, Georgios Mylonas, Panagiotis Kokkinos, Orestis
Akribopoulos,MariosLogaras,andIreneMavrommati. Implementingmul-
tiplayer pervasive installations based on mobile sensing devices: Field ex-
perience and user evaluation from a public showcase. Journal of Systems
and Software, 84(11):1989–2004, 2011.
[4] Ioannis Chatzigiannakis, Georgios Mylonas, and Andrea Vitaletti. Urban
pervasive applications: Challenges, scenarios and case studies. Computer
Science Review, 5(1):103–118, 2011.
[5] John Ahmet Erkoyuncu, In˜igo Fern´andez del Amo, Michela Dalle Mura,
Rajkumar Roy, and Gino Dini. Improving efficiency of industrial mainte-
nance with context aware adaptive authoring in augmented reality. Cirp
Annals, 66(1):465–468, 2017.
[6] Michele Gattullo, Giulia Wally Scurati, Michele Fiorentino, Antonio Em-
manuele Uva, Francesco Ferrise, and Monica Bordegoni. Towards aug-
mented reality manuals for industry 4.0: A methodology. Robotics and
Computer-Integrated Manufacturing, 56:276–286, 2019.
[7] Tom Murray. Coordinating the complexity of tools, tasks, and users: On
theory-based approaches to authoring tool usability. International Journal
of Artificial Intelligence in Education, 26:37–71, 2016.
[8] Michael Nebeling and Maximilian Speicher. The trouble with augmented
reality/virtualrealityauthoringtools. In 2018 IEEE International Sympo-
sium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct), pages
333–337, 2018.
[9] Scott Ososky. Practical requirements for its authoring tools from a user
experience perspective. In Foundations of Augmented Cognition: Neuroer-
gonomics and Operational Neuroscience: 10th International Conference,
8AC 2016, Held as Part of HCI International 2016, Toronto, ON, Canada,
July 17-22, 2016, Proceedings, Part II 10, pages 55–66. Springer, 2016.
[10] Miriam Saviano, Viktor Malakuczi, and Lorenzo Imbesi. Visor-less xr in
museums. a content management system for immersive installations. In
2023IEEEConferenceonVirtualRealityand3DUserInterfacesAbstracts
and Workshops (VRW), pages 551–556, 2023.
[11] Dieter Schmalstieg, Anton Fuhrmann, Gerd Hesina, Zsolt Szalav´ari,
L. Miguel Encarnac¸˜ao, Michael Gervautz, and Werner Purgathofer. The
StudierstubeAugmentedRealityProject. Presence: TeleoperatorsandVir-
tual Environments, 11(1):33–54, 02 2002.
[12] Lei Zhang and Steve Oney. Flowmatic: An immersive authoring tool for
creating interactive scenes in virtual reality. In Proceedings of the 33rd
AnnualACMSymposiumonUserInterfaceSoftwareandTechnology,UIST
’20, page 342–353, New York, NY, USA, 2020. Association for Computing
Machinery.
[13] ˚Asa Fast-Berglund, Liang Gong, and Dan Li. Testing and validating ex-
tendedreality(xr)technologiesinmanufacturing. ProcediaManufacturing,
25:31–38, 2018. Proceedings of the 8th Swedish Production Symposium
(SPS 2018).
9