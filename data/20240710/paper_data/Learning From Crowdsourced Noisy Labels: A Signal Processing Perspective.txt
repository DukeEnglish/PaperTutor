Learning From Crowdsourced Noisy Labels:
A Signal Processing Perspective
ShahanaIbrahim⋆,PanagiotisA.Traganitis*, XiaoFu,andGeorgiosB.Giannakis
Abstract
Oneoftheprimarycatalystsfuelingadvancesinartificialintelligence(AI)andmachinelearning(ML)is
theavailabilityofmassive,curateddatasets.Acommonlyusedtechniquetocuratesuchmassivedatasets
iscrowdsourcing, wheredataaredispatchedtomultipleannotators. Theannotator-producedlabelsare
thenfusedtoservedownstreamlearningandinferencetasks. Thisannotationprocessoftencreatesnoisy
labelsduetovariousreasons,suchasthelimitedexpertise,orunreliabilityofannotators,amongothers.
Therefore,acoreobjectiveincrowdsourcingistodevelopmethodsthateffectivelymitigatethenegative
impact of such label noise on learning tasks. This feature article introduces advances in learning from
noisy crowdsourced labels. The focus is on key crowdsourcing models and their methodological treat-
ments,fromclassicalstatisticalmodelstorecentdeeplearning-basedapproaches,emphasizinganalytical
insightsandalgorithmicdevelopments. Inparticular,thisarticlereviewstheconnectionsbetweensignal
processing(SP)theoryandmethods,suchasidentifiabilityoftensorandnonnegativematrixfactorization,
andnovel,principledsolutionsoflongstandingchallengesincrowdsourcing—showinghowSPperspec-
tivesdrivetheadvancementsofthisfield.Furthermore,thisarticletouchesuponemergingtopicsthatare
criticalfordevelopingcutting-edgeAI/MLsystems,suchascrowdsourcinginreinforcementlearningwith
humanfeedback(RLHF)anddirectpreferenceoptimization(DPO)thatarekeytechniquesforfine-tuning
largelanguagemodels(LLMs).
1 Introduction
Artificial Intelligence (AI) and machine learning (ML) have made significant strides over the past few
decades, expanding the potential of models and learning algorithms. These advancements have revolu-
tionizednaturallanguageprocessingbyenhancinglanguagegenerationandunderstanding,transformed
computervisionwithsuperiorimagerecognitionandanalysis,andenabledcomplexdecision-makingca-
pabilities. AkeydrivingfactorbehindsuchsuccessesofAI/MListheavailabilityoflarge-scale,accurately
labeled training data. In fact, data annotation has become an indispensable integrating part of the AI in-
dustry.InarecentmarketreportfromGrandViewResearch,itwasstatedthat“theglobaldatacollectionand
labelingmarketsizewasvaluedat$2.22billionin2022,anditisexpectedtoexpandatacompoundannual
growthrateof28.9%from2023to2030”[1].
A prominent data annotation paradigm is crowdsourcing. In crowdsourced data annotation systems,
dataitemsaredispatchedtoagroupofannotatorsforlabeling. Foreachitem,multipleannotatorsprovide
theirindividual,possiblynoisy,annotations. Theseannotationsarethenintegratedtoimprovetheoverall
label accuracy. Leveraging the “wisdom of crowd” in data labeling makes sense, as the label accuracy
providedbyindividualannotatorsissensitivetomanyfactors. Iftheannotatorsarehumanworkers,their
*S.IbrahimandP.A.Traganitiscontributedequally. S.IbrahimiswiththeDepartmentofElectricalandComputerEngineer-
ing,UniversityofCentralFlorida,Orlando,FL32816,UnitedStates. Email: shahana.ibrahim@ucf.edu. P.A.Traganitisiswiththe
DepartmentofElectricalandComputerEngineeringatMichiganStateUniversity, EastLansing, MI48824, UnitedStates. Email:
traganit@msu.edu. X.FuiswiththeSchoolofElectricalEngineeringandComputerScience,OregonStateUniversity,Corvallis,OR
97331,UnitedStates.E-mail:xiao.fu@oregonstate.edu.G.B.GiannakisiswiththeDepartmentofElectricalandComputerEngineer-
ing,UniversityofMinnesota,Minneapolis,MN55455,UnitedStates.Email:georgios@umn.edu.⋆Equalcontribution.
1
4202
luJ
9
]PS.ssee[
1v20960.7042:viXraannotation accuracy is limited by their expertise level, background knowledge, and personal experience;
whentheannotationsaregivenbyautomatedmachineannotators,theaccuracyisaffectedbytheirmodel
expressiveness and the quality/amount of their training data. The idea of systematic crowdsourcing can
bedatedbacktomorethanacenturyago;seetheinsertedbox“CrowdsourcinginHistory”. Overthepast
two decades, many commercial crowdsourcing platforms have become widely used, including notable
onessuchasAmazonMechanicalTurk(AMT)andCrowdFlower[2].Theseplatformswereinstrumentalin
creatingmanyhighlyinfluentialdatasetsinmodernAIhistory.Forexample,theImageNetdataset,thathas
driven significant research advancements in AI, contains approximately 14 million annotations provided
byapproximately25,000AMTannotators. Morerecently,largelanguagemodels(LLMs),suchasChatGPT,
Gemini,andLlama,usedsubstantialamountsofcrowdsourcedlabelsforfine-tuning[3].
BeyondAI,crowdsourcinghasalsoleftsignificantfootprintsinagamutofreal-worldapplicationsinsci-
enceandengineering. PopularcitizenscienceprojectslikeGalaxyZooandeBirdarebyproductsofcrowd-
sourcing,whichprovidedeffectiveandeconomicalsolutionstotheever-lingeringdatascarcityproblemin
lifeandphysicalsciences. Crowdsourcingtechniqueshavealsoshowngreatpromiseinmedicalimaging-
baseddiagnosis,producingreliableresultswithminimalexpertsupervision[4].Inaddition,crowdsourcing
iswidelyutilizedinsensingapplicationsthroughcrowdsensing[5],wherealargegroupofmobileusersor
devicescollectivelysharereal-timedata. Anexampleofcrowdsensingisthecrowd-contributedreal-time
information on road conditions, which is now widely available in applications such as Google Maps and
Waze. Variousdatafusionapplicationsinremotesensingandhealthcarethataggregateinformationfrom
multiplesourcesofvaryingreliabilityalsohavestrongconnectionstocrowdsourcingtechniques[6]. Fur-
thermore,crowdsourcingisconceptuallysimilartoensemblelearningmethods,suchasbagging,boosting,
andstacking,thatcombinemultiplemodelstoimproveoverallpredictiveperformance.
Despite the remarkable achievements of crowdsourcing, the fundamental challenge is that annotator-
provided labels can be substantially noisy, and such noisy labels are detrimental to downstream tasks’
performance. Forexample,indeeplearningsystems,noisylabelscauseoverfittingtonoiseandpoorgen-
eralization. Earlyapproachesforalleviatingthenegativeimpactsofcrowdsourcedlabelnoisefocusedon
improvingthequalityofannotators’responsesduringlabelcollection. Theseapproachesincludevarious
project management-based strategies, such as designing proper labeling workflow, querying proper ex-
perts, enhancing supervision mechanisms, and using effective incentive methods—see [7] and references
therein. However,implementingsuchcomplexqualitycontrolmechanismshasbecomeincreasinglydiffi-
cult and less cost-effective as data volume increases. For massive data annotation tasks faced by modern
crowdsourcing systems, automated annotation integration and label correction algorithms advocated by
themachinelearningcommunityaremuchmorerelevant. Inthisarticle,theterm“crowdsourcing”refers
tothistypeofautomatedsystemsandalgorithms,unlessotherwisespecified.
OurGoal.Inthisfeaturearticle,weaimtoprovideinsightsintokeydevelopmentsoflearningfromcrowd-
sourcednoisylabels. Asonewillsee,designingcrowdsourcingmechanismsandalgorithmspresentsase-
riesofchallengesinproblemdistillation,optimization,andperformancecharacterization. Interestingly—
but not very surprisingly—many design considerations and solutions in crowdsourcing are deeply inter-
twinedwiththeoryandmethodsofsignalprocessing(SP).Weareparticularlyinterestedinviewingcrowd-
sourcing from an SP perspective. Therefore, we will emphasize problem distillation (modeling), learning
criterionformulation, algorithmdesign, andtheoreticaladvancements, ratherthanpresentinganexhaus-
tivesurvey.
CrowdsourcinginHistory. Theterm“crowdsourcing”wasfirstintroducedbybusinessjournalistJeff
Howeinhis2006WiredmagazinearticleontaskoutsourcingtoInternetusers,yettheconcepthasdeep
historicalroots. Oneoftheearliestexamplesofasuccessfulcrowdsourcingprojectisthecompilation
of the Oxford English dictionary back in the nineteenth century, where hundreds of English speak-
ingreaders’effortswereutilizedtocollectwordsandtheirmeanings. Yearslaterin1907,astatistical
perspectivetothisparadigm—“thewisdomofthecrowd”—wasfirstpostulatedbythefamousstatis-
ticianSirFrancisGalton,whenheobservedacrowdatanauctionaccuratelypredictingtheweightof
anoxthroughtheircollectiveguessing. Inthelate1990s,manylarge-scaleannotationprojects,suchas
2TreeBank,FrameNet,andPropBank,begantoemerge,drivenbytheneedforlargeamountsofcurated
data in natural language processing (NLP) tasks. Another notable early effort in crowdsourcing was
pioneered by Luis von Ahn in 2004, who introduced an online game to generate image annotations,
whichsparkedsubstantialinterestinutilizingonlineworkersforlarge-scaleannotationtasks.
Notation. Weusex,x,andX todenotescalar,vector,andmatrix,respectively;both[x] andx(i)referto
i
theithelementofvectorx; [X] orX(i,j)istheelementintheithrowandjthcolumnofX; X(i,:)or
i,j
[X] denotetheithrowofX;X(:,j)or[X] denotethejthcolumnofX;I[A]istheindicatorfunction,
i,: :,j
i.e., I[A] = 1, if the event A occurs, otherwise I[A] = 0; I denotes the identity matrix of size K; ∥x∥
K 2
denotestheℓ norm;∥X∥ and∥X∥ denotetheFrobeniusnormandthespectralnormofX,respectively;
2 F 2
[N] := {1,...,N} is the set of natural numbers from 1 to N; krank(X) denotes the Kruskal rank of the
matrixX;trace(X)denotesthetrace,i.e.,thesumofthediagonalentries,ofmatrixX;◦denotestheouter-
product;Prdenotesprobabilityorprobabilitymassfunction(PMF)orprobabilitydensityfunction(PDF),
andPr(X;θ)denotesadistributionparametrizedbyθ.
2 Problem Settings
Inthissection,weformallydefinetheproblemstatementofcrowdsourcing. Inaddition,weintroducetwo
majorparadigmsofthecrowdsourcingsystemdesign.
2.1 ProblemStatement
As mentioned, crowdsourcing can be used to integrate various types of annotations (e.g., class labels [8],
trafficinformation[9],andbirdcounts);thatis,inprinciple,theannotationsincrowdsourcingcanbeboth
discreteandcontinuousvalues.Nonetheless,forsimplicity,weusecategoricalclasslabelannotationsasthe
primaryworkingexampletointroducecrowdsourcingideasandalgorithms. Consideradatasetconsisting
of N data items, i.e., X := {x }N , where x ∈ RD is the feature vector representing the nth data item.
n n=1 n
AssumethateachdataitembelongstooneofK classes. Let{y }N denotethesetofground-truthlabels,
n n=1
where y ∈ [K], ∀n; i.e., y = k if the data item x belongs to class k. Note that the ground-truth labels
n n n
{y }N areunknown,andM crowdsourcedworkers(annotators)areemployedtolabelthedatasetX,i.e.,
n n=1
togivetheirestimatesof{y n}. Weusey (cid:98)n(m) ∈ [K]todenotethelabelassignedtothenthdataitembythe
mthannotator. Notethattheannotatorsmaybehuman,pre-trainedMLalgorithms,orpredefineddecision
rules. Crowdsourcedlabelsareoftennoisy,whichmeansthatwehavey (cid:98)n(m) ̸=y nformany(m,n)pairs.
2.2 CrowdsourcingSystems: TwoParadigms
The developments of crowdsourcing methods can be roughly classified into two categories, namely,
labelintegrationapproaches(see,e.g.,[8,10–12])andend-to-end(E2E)learningapproaches(e.g.,[13–16]).
The former isolates noisy label correction from downstream tasks, yet the latter directly uses the noisy
labelstotrainsystemsservingforspecifictasks.
Label Integration. Fig. 1 shows the schematics of the first type of crowdsourcing system, where label
integrationisthekeymodule. Thesesystemsconsistoftwostages,wherethelabelintegrationstageisnot
affectedbythesubsequentdownstreamtaskstage. Inthelabelintegrationstage,thelabelsy (cid:98)n(m) ’sarefused
toproduceanestimatedlabely˜ inthehopethaty˜ =y . Oftentimes,thecharacteristicsoftheannotators,
n n n
i.e. “annotatorconfusions”inthefigure,arealsoestimatedintheprocess. Then,theestimatedlabels{y˜ }
n
areusedfortrainingthedownstreammachinelearningsystem,e.g.,traininganeuralnetworkfunctionto
predictground-truthlabels. Thetrainingstagedoesnotneedspecificdesigntohandlemultipleannotators
ornoisylabels.
End-to-End (E2E) Learning. Fig. 2 illustrates a typical E2E crowdsourcing system. This type of systems
considersbothdataandnoisylabelsasinputanddirectlytrainsthelearningsystemsonthetargetdown-
streamtasks. Asthereisnostagebreakdown,thesesystemsarecalledend-to-end(E2E)systems. Whenthe
3Figure 1: The two-stage strategy with label integration and annotator confusion estimation followed by
learningtheground-truthlabelpredictor.
Figure2: TheE2Elearningstrategywithjointestimationoftheground-truthlabelpredictorandtheanno-
tatorconfusions.
targetistotrainaclassifierf :RD →RK,E2Esystemsdesignalossfunctionℓsuchthat
θ
f(cid:98)θ ←argmin ℓ({x n},{y (cid:98)n(m)},θ,η),
θ,η
where η represents additional model parameters according to specific loss designs. The learned f(cid:98)θ is ex-
pected to be a good ground-truth label predictor. For example, denote the ground-truth label posterior
distributionasafunctionf⋆ :RD →RK where
[f⋆(x )] =Pr(y =k|x ), ∀(x ,y ). (1)
n k n n n n
ThegoalofmanyE2Eapproaches(see,e.g.,[13–15])istolearnf(cid:98)θ suchthatf(cid:98)θ ≈f⋆.
Generallyspeaking,labelintegrationapproachescanfeaturemorelightweightandtractablealgorithms,
as they do not require training a learning system f that is usually parameterized by a complex function
θ
class, such as kernels or neural networks. On the other hand, E2E methods often exhibit more appealing
performance, possibly because they naturally exploit information from data features and the underlying
structureofthespecifictasksinajointway.Bothcrowdsourcingapproachescanbeconsideredunsupervised,
4Figure 3: Graphical model of the DS model [8]. The green colored circles indicate observed variables,
whereastheblueoneindicatelatentvariable.
as there are no ground-truth labels available to guide the learning process. The developments in label
integrationandE2Elearningbasedcrowdsourcing,arereviewedinSec.3andSec.4,respectively.
3 Label Integration Approaches
Inthissection,wefocusonapproachesdesignedforthelabelintegrationmoduleinFig.1.
3.1 MajorityVotingandChallenges
Thearguablysimplestapproachforlabelintegrationismajorityvoting(MV),wheretheestimatedlabelfor
eachdataitemistheonevotedbymostannotators,i.e.,
M
(cid:88)
y˜ =argmax I[y(m) =k]. (2)
n (cid:98)n
k
m=1
However, MVisnotalwayseffective, asitimplicitlyassumesequalreliabilityamongallannotators. Fur-
thermore,duetothesignificanttimeandeffortrequired,itisnoteconomicaltoaskallannotatorstolabel
everydataitem. Thismeansthatmanyitemsmaynothavesufficientannotationsthatmeritavotingpro-
cess. Under such circumstances, MV can be far from optimal for label integration [17]. To take unequal
reliability of the annotators into consideration, weighted majority voting (WMV) schemes were proposed.
For example, a non-negative scalar weight w(m) representing the labeling accuracy of annotator m was
consideredin[18]:
M
(cid:88)
y˜ =argmax w(m)I[y(m) =k]. (3)
n (cid:98)n
k
m=1
Nonetheless,accurateweightestimationperseisachallengingtask. Duetothesereasons,MVschemesare
oftenonlyusedasthebasicbaselinesinlabelintegration.
3.2 LabelNoiseModelsinLabelIntegration
A notable milestone in label integration research occurred when the MV approaches were superseded by
probabilisticmodelingapproaches. Byexplicitlymodelingnoisylabelsusingprobabilisticgenerativemod-
els, theseapproachesoftenprovidemorereliablelabelintegrationperformance. Inthissection, weintro-
duceanumberofrepresentativemodelsinthisgenre.
Dawid-Skene (DS) Model. The seminal work of Dawid and Skene introduced one of the most influen-
tialprobabilisticmodelsforcrowdsourcinginthelate1970s[8]. UndertheDawid-Skene(DS)model, the
ground-truth label is a latent discrete random variable, denoted as Y, and each label y ∈ [K] is drawn
n
independentlyfromtherandomvariableY. Theannotator’sresponsesaretheobservedrandomvariables,
5denotedasY(cid:98)(1),...,Y(cid:98)(M)withy (cid:98)n(m) representingthenthrealizationofY(cid:98)(m).ThekeyassumptionoftheDS
modelisthat,giventheground-truthlabel,annotators’responsesareconditionallyindependent;seeFig.3.
Inotherwords,theDSmodelisanaiveBayesmodel.
UndertheDSmodel,thejointprobabilityofalltheannotatorresponsescanbeexpressedasfollows:
K M
(cid:88) (cid:89)
Pr(Y(cid:98)(1) =k 1,...,Y(cid:98)(M) =k M)= Pr(Y(cid:98)(m) =k m|Y =k)Pr(Y =k), (4)
k=1m=1
wherek ,...,k ∈ [K]aretheannotatorresponses, andwehaveusedthelawoftotalprobability, Bayes
1 M
rule, and the conditional independence of annotator responses given the ground-truth label. From the
relationin(4),thefollowingtermsaredefined:
A m(k′,k)≜Pr(Y(cid:98)(m) =k′|Y =k), d(k)≜Pr(Y =k), ∀k,k′ ∈[K], (5)
whereA ∈RK×K iscalledtheconfusionmatrixoftheannotatormandd∈RK isthePMFoftheground-
m
truthlabeldistribution. Asthenamesuggests,theoff-diagonalelementsofA characterizetheprobabil-
m
ities of annotator m making mistakes. An ideal annotator would have A = I. Also note that, as each
m
columnofaconfusionmatrixisaPMF,itholdsthatA ≥0,1⊤A =1⊤,with1denotingtheallonesvec-
m m
torofappropriatedimension. Thus,bothdandcolumnsofA belongtotheso-called(K−1)dimensional
m
probabilitysimplex,∆ ={x∈RK :x≥0,1⊤x=1}.
K
Under the DS model, if the A ’s and d are known, one can construct optimal ground-truth label es-
m
timatorsusingthemaximumaposteriori(MAP)principle, i.e. maximizingtheposteriordistributionofthe
unknownlabel,givenannotatorresponses:
y˜ =arg max Pr(y =k|y(1) =k ,...,y(M) =k )
n n (cid:98)n 1 (cid:98)n M
k∈[K]
=arg max Pr(y(1) =k ,...,y(M) =k |y =k)Pr(y =k)
(cid:98)n 1 (cid:98)n M n n
k∈[K]
K M
(cid:88) (cid:88)
=arg max logd(k)+ I[y(m) =k′]logA (k′,k), (6)
(cid:98)n m
k∈[K]
k′=1m=1
where we have successively used Bayes rule, the properties of the logarithm and the definitions in (5).
Hence,thelabelintegrationproblemundertheDSmodelamountstoestimating{A }anddaccurately.
m
ConnectionstoCommunicationsandInformationTheory. TheDSmodelcanalsobeinterpretedas
single-inputmultiple-output(SIMO)channelfrominformationtheory. Thecommoninputisthesingle
ground-truth label per data item y n, the multiple outputs are the M annotator responses {y (cid:98)n(m)}M m=1,
andtheannotatorconfusionmatricesA ’scanbeassociatedwiththeunknown“channel”character-
m
istics. Asimilarproblemtocrowdsourcingisdecentralizeddetection[19], whereadistributednetwork
of sensors (annotators) observe the same environmental phenomenon, and send their observations
(labels) to a fusion center, and the fusion center has to recover the underlying hypothesis of the en-
vironment. Thekeydifferencebetweendecentralizeddetectionandcrowdsourcingisthatinthefor-
mer case, the fusion center can control the characteristics of both the annotators and the fusion rule.
The crowdsourcing setting with real-valued annotations also bears resemblance to classical problem
ofblindmultichanneldeconvolution[20],wheretheunobservedinputsignalandthechannelcharac-
teristicsareinferredfrommultiplenoisyobservedsignals. Furthermore, thecrowdsourcingproblem
exhibits similarities to the chief executive officer (CEO) problem in information theory [21], where M
agents observe noisy sequences and the CEO aims to recover the ground truth within a communica-
tionconstraint,similartothelabelingcostbudgetincrowdsourcing.
Special Cases of the DS Model. The DS model serves as a foundation for different models that are fre-
quentlyusedintheliterature. Theso-called“one-coin”model[22]isasimplifiedDSmodelthatencodes
6eachannotator’sreliabilitiesusingonlyoneparametersuchthat
(cid:40)
p , k′ =k,
Pr(Y(cid:98)(m) =k′|Y =k)= m
1−pm, k′ ̸=k,
K−1
i.e.,annotatormdeterminestheirresponsewithasinglebiasedcoinflip. Foreachdataitem,theannotator
assigns the correct label with probability p , and gives a wrong label with equal probabilities across the
m
remainingK−1classes. OtherpopularDSmodelvariantsincludethespammer-hammermodel[23]andthe
confusionvectormodel[24].Inthespammer-hammermodel,eachannotatorisa“hammer”withprobability
q,providingcorrectlabels,ora“spammer”withprobability1−q,providingrandomlabels. Theconfusion
vectormodelemploysaparametervectora ∈RK,perannotatorm,tocharacterizetheirreliabilities:
m
(cid:40)
a (k), k′ =k,
Pr(Y(cid:98)(m) =k′|Y =k)= m
1−am(k), k′ ̸=k,
K−1
i.e.,unliketheone-coinmodel,theprobabilitythattheannotatormchoosesthecorrectanswerorawrong
answervariesacrossdifferentclasses.
ThesespecialcasesoftheDSmodeloffersuccinctcharacterizationsofannotatorconfusions. Yet, they
arelessgeneralthantheDSmodel. Nevertheless,thesemodelsoftenadmitmoretractablealgorithmsand
reasonableperformanceguarantees;see,e.g.,[22,23,25].
Extended DS Model: Incorporating Item Difficulties. The DS model introduced in [8] assumes that an-
notator behavior is the same across all data items, i.e., A is the same for all n. Nonetheless, it may be
m
morerealistictoassumethatthedifficultyoflabelingvariesacrossdataitems. Tocapturebothannotator
behavioranditemdifficulty[26]introducedthefollowingmodel:
exp(A (k′,k)+B (k′,k))
Pr(Y(cid:98)(m) =k′|Y =k)=
(cid:80)
exp(m
A
(k′,k)+n
B
(k′,k)),
k′ m n
whereA ∈ RK×K isdefinedasbefore,andB ∈ RK×K isanitem-specificconfusionmatrixthatreflects
m n
item difficulty. Following the same spirit, the one-coin model was also generalized to incorporate item
difficulty;seethegenerativemodeloflabels,abilities,anddifficulties(GLAD)modelin[27].
BayesianModels. Toincorporatepriorinformation,reducethenumberofparameters,andenhancemodel
interpretability, Bayesian models were also introduced on top of the DS model (see, e.g., [16,28]) Using
thefactthatbothdandA (:,k)arePMFs,[28]imposesDirichletpriorsontodandA (:,k)’s,while[16]
m m
assumesaBetapriorfortheconfusionparameters,inthebinaryclassificationcase.
3.3 MethodsforNoiseModelLearning
Undertheaforementionednoisegenerationmodels,labelintegrationboilsdowntolearningthekeymodel
parameters,e.g.,theconfusionmatricesandthepriorprobabilityvectorintheDSmodel.Inthissubsection,
webrieflyreviewsomerepresentativemethodsforlearningthesemodels.
ExpectationMaximization(EM).TheseminalworkbyDawidandSkene[8]soughtamaximum-likelihood
estimator (MLE) of annotator confusion matrices and class priors of the DS model. Collect all ground-
truth labels and annotator responses in Y = {y n} and Y(cid:98) = {y (cid:98)n(m)}, respectively, and all unknown model
parametersinψ ={A ,...,A ,d}. TheMLEofψisgivenby
1 M
N
(cid:88)
ψ(cid:98)=argmax logPr(Y(cid:98);ψ)=argmax logPr(y (cid:98)n(1),...,y (cid:98)n(M);ψ)
ψ ψ n=1
N K M K
(cid:88) (cid:88) (cid:89) (cid:88)
=argmax log d(k) I[y(m) =k′]A (k′,k), (7)
(cid:98)n m
ψ n=1 k=1 m=1k′=1
7where logPr(Y(cid:98);ψ) is the log-likelihood function of observed annotator labels, parametrized by ψ. As di-
rectly optimizing the log-likelihood is often intractable, Dawid and Skene introduced an EM-based algo-
rithmtolearntheDSmodelparameters. TheEMalgorithmistheworkhorseforlearningNaiveBayesand
mixture models. Using the EM algorithm, the log-likelihood function is maximized iteratively, with the
followingstepsperformedateachiteration:
(i)The“Expectation”(E)step: TheE-stepiniterationtisperformedasfollows:
N K
(cid:88)(cid:88)
Q(ψ;ψt)=E Y∼Pr(Y;Y(cid:98),ψt)[logPr(Y(cid:98),Y;ψ)]= q(y
n
=k;ψt)logPr(y (cid:98)n(1),...,y (cid:98)n(M);ψ),
n=1k=1
wherethesuperscripttdenotesiterationindex,andtheexpectationistakenwithrespectto(w.r.t.) thepos-
teriorprobabilityPr(Y;Y(cid:98),ψt)basedonthecurrentestimatesψt = {At,...,At ,dt}. Notethat,Q(ψ;ψt)
1 M
is essentially a lower bound of the log-likelihood. The E-step boils down to estimating q(y = k;ψt) =
n
Pr(y
n
= k|y (cid:98)n(1),...,y (cid:98)n(M),ψt)givenAt m’sanddt. UndertheDSmodelandusingBayesrule,q(y
n
= k;ψt)
admitsasimpleclosedform,i.e.,
(cid:16) (cid:17)
exp logdt(k)+(cid:80)M (cid:80)K logAt (k′,k)I[ym =k′]
m=1 k′=1 m (cid:98)n
q(y n =k;ψt)= (cid:16) (cid:17). (8)
(cid:80)K exp logdt(k′)+(cid:80)M (cid:80)K logAt (k′′,k′)I[ym =k′′]
k′=1 m=1 k′′=1 m (cid:98)n
NotethatthisposteriorhasasimilarformtotheMAPestimatorof(6).
(ii)The“Maximization”(M)step: TheM-steprefinesmodelparametersbymaximizingQ(ψ;ψt),which
alsoadmitsanalyticalupdates:
(cid:80)N q(y =k;ψt)I[ym =k′]
At+1(k′,k)= n=1 n (cid:98)n ,
m (cid:80)K (cid:80)N q(y =k;ψt)I[ym =k′′]
k′′=1 n=1 n (cid:98)n
(cid:80)N q(y =k;ψt)
dt+1(k)= n=1 n .
(cid:80)K (cid:80)N q(y =k′;ψt)
k′=1 n=1 n
TheEMschemecanalsobereadilyadaptedtolearnthespecialcasesoftheDSmodel,i.e.,one-coin,con-
fusion vector, spammer-hammer, and GLAD models as discussed in 3.2. A similar EM strategy is also
employedtolearntheBayesianmodelproposedin[16].
One salient feature of the EM algorithm is its scalability—it enjoys a computational complexity that
is linear in N and M, which is appealing for large-scale crowdsourcing problems. However, it was also
observedthattheEMalgorithmdoesnotconvergewell,iftheinitializationisnotcarefullychosen[11,29],
perhapsduetothenonconvexityoftheMLEloss.
Spectral Methods. One of the notable spectral methods for label integration is the eigendecomposition-
basedapproachproposedin[22]undertheone-coinbinarymodel. Considerthebinaryclassificationprob-
lemwithunobservedground-truthlabelsy ∈ {−1,+1}andtheone-coinmodelparametersp ’s, where
n m
p
m
is the probability that annotator m provides the correct label. Let z n(m) be the correctness indicator of
annotator m on item n; i.e., z n(m) = 1 if annotator m provides the correct label and z n(m) = −1 otherwise.
Then,itcanbeshownthat
(cid:40)
1, w.pp2 +(1−p )2,
z(m)z(m) = m m
n n′ −1, w.p1−p2 −(1−p )2.
m m
Sincey (cid:98)n(m) =z n(m)y nholds,wefurtherobtain:
E(cid:34) (cid:88)M
y (cid:98)n(m)y (cid:98)n(m
′
)(cid:35)
=y ny
n′E(cid:34) (cid:88)M
z n(m)z n(m
′
)(cid:35) =(cid:40) y
Mn
,y n′κ, n n̸= =n n′ ′,
,
(9)
m=1 m=1
8whereκ=(cid:80)M m=1(2p m−1)2. BydefiningtheannotatorresponsematrixU(cid:98) withentriesU(cid:98)(n,m)=y (cid:98)n(m) ,the
relationin(9)canalsobeexpressedas
E[U(cid:98)U(cid:98)⊤]=κyy⊤+(M −κ)I N, (10)
wherey =[y ,...,y ]⊤. Basedontheabove,[22]proposedanintuitivelysimplespectralalgorithmwhere
1 N
theground-truthlabelsyareextractedfromthetopeigenvectoroftheempiricalestimateofE[U(cid:98)U(cid:98)⊤]. Con-
sequently, the annotator confusions p can be inferred from the estimated y. Nonetheless, the approach
requires that the annotator response matrix is fully observed, meaning that all annotators provide labels
foralldataitems. Toaccommodatetheincompletelabelingscenarios,[25]extendedthisstrategybycon-
sideringanannotator-itembinarymatrixalongsidetheannotatorresponsematrixandperformingajoint
singularvaluedecomposition(SVD)operation,stillundertheone-coinmodel.
Moment-Based Approaches: From Tensor Decomposition to Nonnegative Matrix Factorization. The
rank-oneplusdiagonalstructurein(10)isonlyapplicableundertheone-coinmodel.Toidentifytheparam-
etersofthegeneralDSmodel,[10]proposedamomentmatchingapproachthatconsideredthethird-order
momentsoftheannotatorresponsesasfollows:
K
(cid:88)
E[Y(cid:98)(m)◦Y(cid:98)(i)◦Y(cid:98)(j)]= d(k)A m(:,k)◦A i(:,k)◦A j(:,k), ∀m̸=i̸=j, (11)
k=1
where ◦ denotes the outer product (i.e., X = a◦b◦c ⇔ X(m,i,j) = a(m)b(i)c(j)), and Y(cid:98)(m) denotes
the K-dimensional one-hot encoding of the annotator response random variable Y(cid:98)(m), i.e., if Y(cid:98)(m) = k,
then Y(cid:98)(m) = e k, where e
k
∈ RK is a unit vector with [e k]
k
= 1 and zeros elsewhere. In general, the
conditionalindependenceassumptionoftheDSmodelinducestheouterproductexpressionofthehigher-
ordermoments. Toseewhy,considerthesecond-ordermoment
(cid:104) (cid:105)
E[Y(cid:98)(m)◦Y(cid:98)(i)] =Pr(Y(m) =k 1,Y(i) =k 2)
k1,k2
K
(cid:88)
= Pr(Y =k)Pr(Y(m) =k |Y =k)Pr(Y(i) =k |Y =k),
1 2
(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)
k=1
d(k) Am(k1,k) Ai(k2,k)
whichimpliesE[Y(cid:98)(m)◦Y(cid:98)(i)] = (cid:80)K k=1d(k)A m(:,k)◦A i(:,k) = A mdiag(d)A⊤
i
; asimilarderivationholds
forthethird-ordermoments.
Using third-order moments, a coupled tensor factorization (CTD) criterion can be used to identify d and
{A }[10]:
m
M
(cid:88)
minimize ∥T − d,A ,A ,A ∥2 (12)
m,i,j m i j F
{Am},d
m=1
(cid:74) (cid:75)
i>m
j>i
subjecttoA ≥0,1⊤A =1⊤,d≥0,1⊤d=1,
m m
where d,A ,A ,A is the shorthand notation for
(cid:80)K
d(k)A (:,k)◦A (:,k)◦A (:,k), and T is
m i j k=1 m i j m,i,j
(cid:74) (cid:75)
theempiricalversionofE[Y(cid:98)(m)◦Y(cid:98)(i)◦Y(cid:98)(j)]. Theterm“coupled”isduetothefactthatthetensorsT
m,i,j
shareoneortwolatentfactors.Tofurtherregularizetheobjectivefunctionfirst-andsecond-ordermoments
were usedin [10]. Theproblem in(12) is nontrivialto solve. An alternating directionmethod ofmultipliers
(ADMM)-basedoptimizationalgorithmwasemployedin[10]tohandlethiscriterion. Anotherthird-order
moment-based DS learning approach was introduced in [11] that employs an orthogonal tensor decom-
position via a robust power method. Nonetheless, higher-order moments like T in general require a
m,i,j
significantamountofsamples(annotatorlabels)tobeaccuratelyestimated.
9To avoid the sample complexity required for estimating third-order moments, [12,30] proposed using
onlysecond-orderstatistics,leadingtoacouplednonnegativematrixfactorization(CNMF)criterion:
M
minimize
(cid:88) KL(cid:0)
S ||A
diag(d)A⊤(cid:1)
(13)
m,i m i
{Am},d
m=1
i>m
subjecttoA ≥0,1⊤A =1⊤,d≥0,1⊤d=1,
m m
whereS
m,i
istheempiricalestimateofE[Y(cid:98)(m)◦Y(cid:98)(i)],andtheKLdivergencewasusedinthelossdueto
thePMFestimationnature.
The moment-based methods in [10–12,30] come with interesting theoretical support, reminiscent of
signalprocessingresearchontensorandnonnegativematrixfactorization;seealsoSec. 3.5.
Bayesian Methods. Under the Bayesian paradigm, [28] considered the following joint probability under
presumedpriorsofA andd:
m
N M M K
Pr({A m},d,Y|Y(cid:98))∝ (cid:89) d(y n) (cid:89) A m(y (cid:98)n(m),y n)·Pr(d|ν) (cid:89) (cid:88) Pr(A m(:,k)|π k(m)) (14)
n=1 m=1 m=1k=1
whereν,π(m) ∈ RK,∀m,k areDirichletpriorsfordandA (:,k)’s, respectively. Comparedtotheplain-
k m
vanilla DS model learning approaches, Bayesian approaches enjoy more succinct models by treating A
m
anddasrandomquantities. However,thiscomesatthecostofcomputationalintractability; theposterior
in(14)isoftennoteasytoevaluate,asitinvolvesmarginalizationofthisjointprobabilitydistributionover
allparameters. Tocircumventthisissue,samplingtechniquesareoftenadopted.Fromtheposteriorin(14),
inference of unknown parameters, i.e, {A },d,Y, is performed using the Gibbs sampling technique by
m
iterativelysamplingeachparameterfromitsconditionaldensityfunction[28]. OtherBayesianapproaches
includevariationalinferencetechniquesbyapproximatingtheconditionalprobabilitydensitiesusingbelief
propagationandmeanfieldassumptions[31].
Other Methods. Beyond methods based on the DS model and its extensions, there are also numerous
alternativelabelintegrationmethodsthatprovideinterestinginsightsandsimpleimplementations. Some
examplesareintroducedbelow:
Labelintegrationcanbeformulatedasanoptimizationproblemasfollows[32]:
M N
(cid:88) (cid:88)
minimize w dist(y ,y(m)) (15a)
m n (cid:98)n
w,y
m=1 n=1
subjecttoR(w)=1, (15b)
where w = [w ,...,w ]⊤ and y = [y ,...,y ]⊤ are the vector of annotator reliabiliities (similar to the
1 M 1 n
confusion parameter in the one-coin model or the weight values in weighted majority voting) and the
vector of ground-truth labels, respectively. The distance measure dist(y n,y (cid:98)n(m)) captures the deviation
from the ground-truth and the annotator responses, e.g., 0 − 1 loss for the classification case. R(w) is
a regularization term, which ensures that the annotator reliabilities w remain bounded. For example,
m
R(w) =
(cid:80)M
exp(−w ) is employed in [32], rendering the overall optimization problem convex and
m=1 m
allowingittobeeffectivelyhandledusingthemethodofLagrangemultipliers.
A minimax conditional entropy-based label integration was introduced in [24], which considered the
sumoftheentropiesoftheobservedcrowdsourcedlabels. Leta( nm) denotethePMFofthenoisylabely (cid:98)n(m),
i.e., [a( nm)]
k
= Pr(y (cid:98)n(m) = k). Note that this PMF is dependent on the data item index n. Then, following
10Figure 4: Graphical representation of a hidden markov model for the sequentially dependent data. The
greencoloredcirclesindicateobservedvariables,whereastheblueoneindicatelatentvariable.
minimize-maximizeformulationisconsideredin[24]:
M N K
(cid:88) (cid:88)(cid:88)
min max − [a(m)] log[a(m)]
n k n k
y {a( nm)∈∆K}
m=1n=1k=1
M M
(cid:88) (cid:88)
subjectto [a(m)] = I[y(m) =k], ∀n,k,
n k (cid:98)n
m=1 m=1
N N
(cid:88) (cid:88)
I[y =k′][a(m)] = I[y =k′]I[y(m) =k]∀m,k,k′.
n n k n (cid:98)n
n=1 n=1
Here,theparametersa( nm)
arelearnedbymaximizingtheentropyoftheobservations. Simultaneously,the
ground-truth labels y are inferred by minimizing the entropy, ensuring that the observed labels are the
“least random” choice given the ground-truth label. The constraints enforce that the learned PMFs
a( nm)
align with the empirical observations of the annotator responses. Specifically, the first constraint means
thattheentriesofa( nm)
matchtothenumbersofvotesobtainedperclassperdataitemcollectivelyfromall
annotators; thesecondconstraintensuresthatthelearnedparametersofeachannotatormagreewiththe
empiricalestimateoftheconfusionsderivedfromalltheresponsesofthatannotator.
Another notable approach was proposed in [33] that adopted a geometric interpretation to design a
label integration algorithm. To illustrate their idea, consider an M-dimensional indicator vector g for
n,k
eachn∈[N]andk ∈[K],withentriesg n,k(m)=I[y (cid:98)n(m) =k].Then,w⊤g
n,k
correspondstotheaggregated
scoreofweightedmajorityvotingwithw = [w ,...,w ]⊤ denotingthevectorofweightvalues[c.f. (3)].
1 M
Inspired by the notion of maximum margin in multiclass support vector machines (SVMs), the approach
in[33]seeksahyperplanethatseparatesthepointg fromotherpointsg , k ̸= y bythemaximum
n,yn n,k n
margin. Consequently, the annotator-specific weights and the ground-truth labels are learned using the
followingconstrainedoptimizationproblem:
1
minimize ∥w∥2
w,{yn} 2
subjecttow⊤(g −g )≥βI[y ̸=k],∀n,k,
n,yn n,k n
whereβ representsthemaximummarginhyperparameter.
Other interesting developments in crowdsourced label integration include graph-based approaches,
e.g.,themessagepassing-basedalgorithmproposedin[17]anditsmulti-classextensionin[34].
3.4 LabelIntegrationinMoreComplexScenarios
DependentData. Themodelsdiscussedsofarconsiderthatthedatasamplesaredrawni.i.d. fromsome
unknown distribution. However, structured data often arise, e.g., the words in a text and the frames in
11Figure5: GraphicalrepresentationofanextendedDSmodelwithLannotatorgroups. Thegreencolored
circlesindicateobservedvariables,whereastheblueoneindicatelatentvariable.
a video. In these cases, the data samples show temporal dependencies, i.e., x is dependent on x
n n−1
and x . Modeling these dependencies can be useful especially in natural language processing (NLP)-
n+1
related crowdsourcing tasks, such as part-of-speech tagging and named-entity recognition, that have re-
centlygainedmorepopularitywiththeadventoflargelanguagemodels.
While dealing with sequential data, the DS model can be extended using a hidden Markov model
(HMM) [35]. A simple extension involves a one-step, time-homogeneous Markov structure is employed
tomodelthesequenceoflabelsy ,y ,...,y suchthatnthlabeldependsonlyonitsimmediatepredeces-
1 2 n
sor, i.e. Pr(Y |Y ,...,Y ) = Pr(Y |Y )—also see Fig. 4. In addition to annotator confusion matrices
n n−1 1 n n−1
A ’sandthepriorprobabilityvectord,themodelisalsocharacterizedbyaK×KtransitionmatrixT that
m
describesthetransitionsbetweenlabels,i.e.,T(k,k′)=Pr(Y =k|Y =k′). UnderthisDS-HMMmodel,
n n−1
thejointprobabilityoftheobservedcrowdsourcedlabelsY(cid:98)={y (cid:98)n(m)}isgivenby
N M
(cid:88) (cid:89) (cid:89)
Pr(Y(cid:98))= d(k 1) T(k n,k n−1) A m(y (cid:98)n(m),k n), (16)
k n=2 m=1
wherek=[k ,...,k ]⊤ ∈[K]N.
1 N
Toestimatemodelparameters,anEMalgorithm,similartotheoneoutlinedinSec.3.3,canbederived
[35]. Thekeydifferenceisthatthealgorithmincorporatesaforward-backwardalgorithmintheE-stepdue
tothecausalnatureoftheground-truthlabels. TheEMalgorithmcanalsobeinitializedwiththesolutions
obtainedfromthemomentmatchingstrategy,whichisreminiscentofthemethoddescribedin(12). Here,
the moments of annotator responses are characterized including the transition probabilities as well, e.g.,
thesecond-ordermomentsaregivenby
E[Y(cid:98)(m)Y(cid:98)(i)⊤]=A mTdiag(d)A⊤
i
,∀m̸=i. (17)
Once the parameters are estimated, a MAP estimate of the ground-truth labels Y can be obtained via the
Viterbialgorithm.
ABayesianalternativeisintroducedin[36]thatcharacterizesannotatorsasfollows:
C m(k,k′,k′′)=Pr(Y(cid:98)n =k|Y(cid:98)n−1 =k′,Y
n
=k′′′),
whereC isaK ×K ×K-sizedtensorthatincorporatesthelabeldependenciesaswellfortheannotator
m
confusions. Under Dirichlet prior assumptions on the model parameters, the approach maximizes the
posteriorprobabilityandadoptsavariationalBayes-basedalgorithmforinference.
Empirical studies of these approaches [35,36] show that considering the dependencies of the data is
beneficial and the proposed algorithms are much promising than those designed for i.i.d. data—see Tab.
12Table1: Real-dataresultsforthesequentialdata. Tablefrom[35]. Theasterisk∗indicatesthatresultsare
fromasubsetofavailabledata.
Dataset K M N Metric Singlebest MV DS-EM SeqMM SeqMM+EM MV+EM
Precision 0.23 0.22 0.23 0.24 0.25 0.23
POS 12 10 100,676 Recall 0.25 0.23 0.25 0.24 0.26 0.24
F-score 0.23 0.22 0.22 0.23 0.24 0.23
Precision 0.90∗ 0.79 0.77 0.74 0.77 0.75
NER 9 47 78,107 Recall 0.24∗ 0.59 0.66 0.89 0.69 0.66
F-score 0.89∗ 0.68 0.71 0.62 0.72 0.70
Precision 0.94∗ 0.89 0.81 0.75 0.69 0.62
BiomedicalIE 2 120 7,880,254 Recall 0.76∗ 0.45 0.57 0.60 0.68 0.74
F-score 0.84∗ 0.60 0.66 0.67 0.68 0.67
1. Here MV denotes majority voting, DS-EM denotes the EM algorithm by Dawid and Skene, described
in Sec. 3.3. In the table, the methods SeqMM, SeqMM + EM, and MV + EM consider data dependencies.
Specifically,SeqMMdenotesamomentmatchingmethoddesignedfortheDS-HMMmodel,whileSeqMM
+ EM denotes an EM algorithm tailored to the DS-HMM model and initialized with SeqMM. MV + EM
denotestheDS-HMM-basedEMalgorithminitializedwithMV.
Alternativedependencystructurescanalsobeconsidered,e.g.,networkedorgraphdatausingadepen-
dencygraphthatencodesthepairwiserelationsishandledin[35].
DependentAnnotators.RecallthekeyassumptionoftheDSmodel,i.e.,theannotatorresponsesarecondi-
tionallyindependent. Nevertheless,thisassumptionmaynotholdinsomecases. Forinstance,annotators
whounderwentsimilartrainingmayrespondsimilarlytothesametasksorspatiallyclosesensorsthatare
observingthesamephenomenonmaycapturecorrelatedmeasurements. Astheconditionalindependence
nolongerholdsinthesecases,thepreviouslyintroducedmethodsandalgorithmsmayyieldsub-optimal
outcomes,duetomodelmisspecification.
Extendingideasfromthedistributeddetection,[37]introducedavarianttotheDSmodelwheredepen-
dencies are captured by assigning highly correlated or dependent annotators into one group. Assum-
ing that there are L such groups, annotator responses in the ℓth group are conditionally independent
given a latent variable Z(ℓ) ∈ [K], where z n(ℓ) denotes the nth realization of Z(ℓ). In addition, Z 1,...,Z
L
are conditionally independent given the ground-truth label Y, yielding a hierarchy of DS models—see
Fig. 5. Similar to the original DS model, annotator behavior is characterized by confusion matrices w.r.t.
different groups, i.e., if an annotator m belongs to group ℓ, then its confusion matrix A˜ is defined as
m
A˜ m(k′,k) = Pr(Y(cid:98)(m) = k′|Z(ℓ) = k).Thelabelingbehaviorofagroupiscapturedbydefiningaconfusion
matrixΞ(ℓ)suchthatΞ(ℓ)(k′,k)=Pr(Z(ℓ) =k′|Y =k).
Under the described model, [37,38] proposed to estimate A˜ ’s and Ξ(ℓ)’s using a hierarchical algo-
m
rithm. The fist step is to estimate the annotators’ group membership. In the case of binary classification,
theapproachin[37]usedspectralclusteringontothecross-correlationmatrixbetweendifferentannotator
responses in order to assign the annotators to L different groups. This approach was later extended for
K >2classesin[38]. Oncetheannotator’sgroupmembershipisestimated,thefollowingstepcanemploy
anyDSmodellearningalgorithmwithineachgroupℓtoestimatethelatentobservations{z n(ℓ)}N n=1. Using
theestimatedlatentvariablesz n(ℓ) ’s,theunknownground-truthlabels{y n}’scanbeestimated.
Indeed, when annotator dependencies are present, the aforementioned methods show noticeable per-
formancegainscomparedtomethodsthatareagnosticofsaiddependencies.Fig.6showstheclassification
accuracies(i.e.,thepercentageofthedataitemsthatareclassifiedcorrectly)ofvariousmethodsfromasyn-
theticexperiment,forvariousvaluesofN. Themajorityvoting,denotedasMV,andtheEMalgorithm[8],
denotedasDS-EMarecomparedagainsttheircounterpartsthatestimateannotatorgroupingspriortoDS
modelestimation, denotedasGroup-awareMVandGroup-awareDS-EM,respectively. Fromtheresults,
one can note that the “group-aware” algorithms outperform their group-agnostic counterparts. Finally,
notethat,similartodependentdata,alternativedependencystructuresbetweenannotators,encodedina
1368
66
64
62
60
58
56
54
52 DS-EM
MV
50 Group-aware DS-EM
Group-aware MV
48
0 500 1000 1500
N
Figure6: SimulatedtestsonasyntheticdatasetwithK = 3classes,M = 80annotatorsandL = 4groups.
“Group-aware”algorithmsdenotealgorithmsthatestimateannotatorgroupspriortolabelintegration.
knowngraph,wereconsideredin[28].
3.5 PerformanceCharacterizationsofLabelIntegration
A key metric that quantifies the deviation of the corrected labels y˜ ’s from the ground-truth ones y ’s is
n n
givenbytheprobabilityoferror(errorrate)P ,definedasfollows:
e
P =Pr(Y˜ ̸=Y), (18)
e
withY˜ denotingtherandomvariablecorrespondingtothecorrectedlabely˜ . Itwasshownin[10,39]that
n
under the DS model, the error rate P of the MAP rule in (6) decreases exponentially as the number of
e
annotatorsM increases,i.e.,
P ≤αexp(−βM), (19)
e
for some constants α > 0,β > 0. Similar exponential decrease w.r.t. increasing M was reported for the
one-coin,confusionvectormodelsaswellasforthemajorityvotingrule[39]. Thetheoreticalresultsreveal
theimportanceof“crowdwisdom”. Importantly, theseresultsonlyholdwhenthemodelparametersare
known. Thisunderscoresthesignificanceofhavingaccurateparameterestimation. Inthissubsection,we
reviewsomenotabletheoreticaladvancementsinlabelintegration.
Identifiability of Noise Models. If the joint PMF Pr(Y(1),...,Y(M)) is available, the identifiability of
A ,...,A and d under the DS model trivially holds. This is because the naive Bayes model is also a
1 M
CPDmodelwithorderM andrankK. Tobemorespecific,theDSmodelin(4)canbere-writtenas
K
(cid:88)
P = d(k)A (:,k)◦...◦A (:,k), (20)
1 M
k=1
whereP(i ,...,i ) = Pr(Y(1) = i ,...,Y(M) = i ),whichisanMth-orderrank-K tensor. Theessential
1 K 1 K
uniqueness of d and {A } in this tensor model holds under mild conditions; see [40] and the inserted
m
box “Identifiability of CPD and NMF”. Nonetheless, Pr(Y(1),...,Y(M)) is almost impossible to directly
estimate,asitrequiresΩ(KM)colabeledsamplesbyallannotatorstoreachareasonableaccuracy.
Tocircumventthis“curseofdimensionality”,theidentifiabilityoftheDSmodelusingjointdistributions
ofthreeannotatorswasestablishedin[10,11]. Thesesmallerjointdistributionsaremuchmorerealisticto
estimate in practice. In particular, [10] showed that the third-order moment term in (17) is also a rank-K
14
)%(
ycaruccA
noitacifissalCtensorundertheCPDmodel.Therefore,theoptimalsolutionsto(12)revealtheground-truthA ,∀mupto
m
aunifiedpermutationambiguityundermildconditions,e.g.,rank(A )=Kforallm∈[M]asrank(A )=
m m
krank(A ) in this case (see [41] and the inserted box “Identfiiability of CPD and NMF”). Similar results
m
werederivedin[11]usingadifferentmomentconstruction. Theseresultsaresignificant,meaningthatifat
leastthreeannotatorsco-labelasufficientamountofdata(sothatthethird-ordermomentscanbereliably
estimated),thentheDSmodelislikelyidentifiable.
Theworkin[12]arguedthatoneonlyneedssecond-ordermoments(or,jointdistributionsoftwoanno-
tators’outputs)toestablishidentifiabilityoftheDSmodel. Tobespecific,consideracasewherewewish
tofindA anddsuchthatS = A diag(d)A⊤form ∈ Mandi ∈ I,whereM∩I = ∅. Takeasimple
m m,i m i
casewhereM∪I =[M]. Then,thisisequivalentto
   
S , ..., S A
m1,i1 m1,iT m1
 . . . . . . = . . diag(d)[A ,...,A ],
 ., ., .   .  i1 iT
(cid:124) (cid:123)(cid:122) (cid:125)
S , ..., S A
mQ,i1 mQ,iT mQ H
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
X W
whereQ+T = M. FittingtheabovemodelusingaKLdivergencelossleadstoaCNMFformulationlike
thatof(13). AsbothW andH arenonnegative,theidentifiabilityofthesefactorsholdsifbothW andH
satisfytheseparabilityconditionfromtheNMFliterature[42](seetheinsertedbox“IdentifiabilityofCPD
and NMF”). The separability condition holds if K rows of W are close to all K unit vectors. This means
thatthereexist(mutuallynon-exclusive)annotatorsm ,...,m suchthat
1 K
Pr(Y(mk) =k|Y =k)≈1=⇒A mk(k,:)≈e k;
i.e.,annotatorm isanexpertofrecognizingitemsfromclassk,leadingtotheexistenceofaunitvectorin
k
W. Inotherwords, ifthereareK annotators, whoareexpertsofclassk = 1,...,K respectively, thenW
satisfies separability—and the same argument applies to H; see [12,30] for more relaxed conditions and
moreadvancedsettings(e.g.,wherenotallS ’sareobserved).
m,i
BeyondtheDSmodel,identifiabilitywasalsostudiedforothernoisemodels. Asdiscussed,fortheone-
coin model, model identifiability was established by using the uniqueness (up to a scaling ambiguity) of
theprincipleeigenvectorofE[U(cid:98)U(cid:98)⊤][22]—see“SpectralMethods”andEq.(10)inSec.3.3.Whendependent
dataarepresent, theidentifiabilityofboththeconfusionmatricesandtheHMMwereestablishedin[35],
alsousingtensor-basedarguments.
IdentifiabilityofCPDandNMF.Inthecontextofcrowdsourcing,someclassicalresultsfromthesignal
processingliteratureareparticularlyrelevant:
CPD Uniqueness. Let us denote the Mth-order rank-K tensor in (20) using P = d,A ,...,A .
1 M
Notethattheexpressionin(20)isreminiscentofSVDofmatrices.Thatis,A
m
∈RIm×K(cid:74) hasnormalize(cid:75) d
columns,andthetermd(k)isanalogoustothekthsingularvalue.Themodelin(20)isreferredtoasthe
canonicalpolyadicdecomposition(CPD),whichisknowntobeessentiallyuniqueundermildconditions.
Specifically, for any alternative d(cid:101)and A(cid:101)m for m = 1,...,M such that P = d(cid:101),A(cid:101)1,...,A(cid:101)M , it must
(cid:74) (cid:75)
holdthatA
m
=A(cid:101)mΠandd(cid:101)=Πd,undermildconditions. Awidelyusedconditionis
M
(cid:88)
krank(A )≥2K+M −1,
m
m=1
wherekrankdenotestheKruskalrank;see[41].
NMF Uniqueness. Consider a low-rank nonnegative matrix X = WH where W ∈ RM×K and
+
H ∈ RK×N. Then, any nonnegative solution satisfying X = W(cid:99)H(cid:99), W and H has to have the form
+
W(cid:99) = WΠΣandH(cid:99)= Σ−1Π⊤H underreasonableconditions,whereΣisadiagonalmatrixandΠis
15Table2: ClassificationError(%)andRun-time(sec): AMTDatasets;Tableisfrom[12].
TREC Bluebird RTE
Algorithms
(N =19033,M =762,K=2) (N =108,M =39,K=2) (N =800,M =164,K=2)
(%)Error (sec)Time (%)Error (sec)Time (%)Error (sec)Time
CNMF-SPA[12] 31.47 50.68 13.88 0.07 8.75 0.28
CNMF-OPT[12] 29.23 536.89 11.11 1.94 7.12 17.06
CNMF-EM[12] 29.84 53.14 12.03 0.09 7.12 0.32
Spectral-EM[11] 29.58 919.98 12.03 1.97 7.12 6.40
CTD[10] N/A N/A 12.03 2.74 N/A N/A
DS-EM[8] 30.02 3.20 12.03 0.02 7.25 0.07
Minimax-Entropy[26] 30.89 352.36 8.33 3.43 7.50 9.10
SparseSpectralSVD[25] 43.95 1.48 27.77 0.02 9.01 0.03
KOS[17] 51.95 9.98 11.11 0.01 39.75 0.03
SpectralSVD[22] 43.03 11.62 27.77 0.01 49.12 0.03
MV 34.85 N/A 21.29 N/A 10.31 N/A
a permutation matrix. The term Σ can be removed if the column norm and row norm of W and H,
respectively,areknown.AssumethatthereexistindexsetsΛ fori=1,2suchthatW(Λ ,:)=D and
i 1 1
H(:,Λ ) = D , whereD fori = 1,2arefullrankdiagonalmatrices; i.e., bothW andH satisfythe
2 2 i
separabilitycondition. Then, theNMFmodelisessentiallyunique. MorerelaxedconditionsforNMF
uniquenessexist, e.g., thatbothW andH satisfytheso-calledsufficientlyscatteredcondition(SSC).
Thereadersarereferredto[42]foratutorialonNMFidentifiability.
Algorithms - Tractability and Scalability. Establishing identifiability of the noise model is only the first
steptowardssuccessfulmodellearning—asidentifiabilitydoesnotguaranteetheexistenceofatractableor
scalablealgorithm. Somecriteria,e.g.,theCTDandCNMFobjectivesin(12)and(13),respectively,present
NP-hardoptimizationproblems. Theseobjectivesarehandledbystandardnon-convexoptimizationtools.
Although the empirical results of these algorithms are often acceptable, the quality of the solution is not
theoreticallyguaranteed.
Nonetheless,someprogresshasbeenmadetowardsperformance-guaranteedalgorithmdesign. Forex-
ample,theeigen-decompositionbasedmethodfortheone-coinmodeladmitstractablealgorithms,aseigen
problemsaresolvableinpolynomialtime[22]. Ifthepowermethodisused, thecomputationalcomplex-
ity is O(nnz(U(cid:98))) per iteration (where nnz(·) counts the number of nonzero elements), and the algorithm
convergesatanexponentialrate. ForlearningtheDSmodel,similarresultswereshownin[11],wherethe
tensor power method was used. If class experts with Pr(Y(m) = k|Y = k) ≈ 1 exist for every class, [12]
showed that there is a Gram-Schmidt-like NMF algorithm that recovers A(cid:98)m ≈ A mΠ. This second-order
moment matching-based algorithm is also scalable, with a per-iteration complexity of at most O(MK3),
whereK isoftensmall.
Therearealsoanumberofalgorithmsthatare“locallyconvergent”totheparametersoftheDSmodel.
Givensufficientlygoodinitialization,[11]establishedthattheEMalgorithmimprovesthesolutiontowards
the ground-truth confusion matrices. There, the tensor power iterations are combined with the scalable
EMalgorithm(whichtakesO(NMK)flopsperiteration)toprovideanoveralltractablesolution. Asimilar
resultforavariationalinferencealgorithmwasshownin[43]. Againifreasonablyinitialized,[30]showed
thatasymmetricNMFalgorithmthatleverageslightweightProcrustesprojectionconvergesexponentially
totheground-truthDSmodelparameters.
Takeaways. We use some numerical evidence to conclude our discussion of this section. Table 2 shows
theperformanceofaseriesoflabelintegrationmethodsonrealdatasetsannotatedbyAMTworkers. The
annotations are fairly noisy. One can see that majority voting could only correct the labels up to 34.85%,
21.29%and10.31%errorratesfortheTREC,Bluebird,andRTEdatasets,respectively. However,methods
thatlearnannotatorparameters,namely,DS-EM[8],Spectral-EM[11],CNMF[12],andCTD[10]methods,
all improve upon the result of MV by large margins. As we discussed, the EM algorithm enjoys a low
computationalcomplexity. Ifitisinitializedbyareliablealgorithm,e.g.,Spectral-EMandCNMF-EM,the
16Table3: Differentlabelintegrationapproachesandtheircharacteristics
Methods Model-type Method-type Identifiability Tractabiliy Scalability ConditionalIndependence
DS-EM[8] DS EM ✘ ✘ ✓✓✓ ✓✓✓
CNMF-SPA[12] DS Moment-basedFitting ✓✓✓ ✓✓✓ ✓✓✓ ✓✓✓
CNMF-OPT[12] DS Moment-basedFitting ✓✓✓ ✘ ✘ ✓✓✓
SymNMF[30] DS Moment-basedFitting ✓✓✓ ✓✓✓ ✓✓✓ ✓✓✓
CTD[10] DS Moment-basedFitting ✓✓✓ ✘ ✘ ✓✓✓
Spectral-EM[11] DS Moment-basedFitting+EM ✓✓✓ ✓✓✓ ✘ ✓✓✓
Minimax-Entropy[24] ExtendedDS Entropy ✘ ✘ ✘ ✓✓✓
SpectralSVD[22] One-coin SVD ✓✓✓ ✓✓✓ ✓✓✓ ✓✓✓
SparseSpectralSVD One-coin SVD ✓✓✓ ✓✓✓ ✓✓✓ ✓✓✓
GLAD[27] ExtendedOne-coin EM ✘ ✘ ✓✓✓ ✓✓✓
KOS[17] Spammer-hammer Graph-based ✘ ✓✓✓ ✓✓✓ ✓✓✓
IBCC[28] Bayesian-DS MCMC ✘ ✘ ✘ ✓✓✓
OPT-Crowd[32] Weighted-MV Optimization ✘ ✓✓✓ ✓✓✓ ✘
MaxMarginMV[33] Weighted-MV SVM ✘ ✘ ✓✓✓ ✘
VariationalBayes[31] Spammer-hammer VariationalInference ✘ ✘ ✘ ✓✓✓
SeqEM[35] DS-HMM Moment-basedFitting+EM ✘ ✘ ✘ ✓✓✓
BayesSeq[36] ExtendedDS-HMM VariationalInference ✘ ✘ ✘ ✓✓✓
GroupAware-EM[38] Hierarchical-DS SpectralClustering+EM ✘ ✘ ✓✓✓ ✘
EM algorithm often outshines other methods in both accuracy and speed. These results also attest to the
importanceofidentifiabilityguarantees—theCNMFandCTDmethodslearnmoreaccuratelabelsrelative
toothermethods.
Table3presentsasummaryoftheseveralmethodsdiscussedinthissectionalongwiththeircharacter-
istics. Thekeytakeawaysareasfollows: First,identifiabilityofthenoisemodelsisoftenakeyperformance
indicator. Theempiricalevidencestronglysuggeststhatapproacheswithidentifiabilityguaranteesconsis-
tentlyworkwellforlabelintegration. Second,sample(annotatorlabel)complexityisakeyconsideration
when selecting an algorithm in practice. Since collecting more labels incurs extra costs and increases the
annotators’ workload, methods that perform well with fewer annotations are more economical. Third,
methodsneedtobescalableasreal-worldlabelintegrationofteninvolvesalargenumberofdataitemsand
annotators. Hence,itisessentialformethodstoscalegracefullyasbothN andM increase.
4 End-to-End (E2E) Learning from Crowdsourced Labels
Compared to the label integration paradigm, the E2E approaches of Fig. 2 have shown more appealing
performanceovervariousdatasets—seesomenumericalevidenceinFig.7. Thismaybeduetothefactthe
E2Eapproachesdirectlyworkwithdatafeatures. Theyarealsooftenaone-stageapproachthatcanavoid
erroraccumulationandpropagationamongstages.
4.1 E2ELearningviaMaximumLikelihoodandEM
LetusdenoteadatasetwithcrowdsourcedlabelsasD ={x n,{y (cid:98)n(m)}M m=1}N n=1. Undersimilarassumptions
to the DS model, i.e. data items are sampled independently, and annotator responses are conditionally
independent,giventheground-truthlabel,thejointlikelihoodofthedatacanbeexpressedasfollows:
N N K M
(cid:89) (cid:89) (cid:88) (cid:89)
Pr(D)= Pr(x ,y(1),...,y(M))= Pr(y |x ) Pr(y(m)|y ,x ), (21)
n (cid:98)n (cid:98)n n n (cid:98)n n n
i=1 i=1yn=1 i=1
N K M
(cid:89) (cid:88) (cid:89)
= Pr(y |x ) Pr(y(m)|y ). (22)
n n (cid:98)n n
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
i=1yn=1
[f⋆(xn)]k
i=1
Am(y(cid:98)n(m),yn)
Here,(21)usedtheconditionalindependenceofannotators’outputsgiventheground-truthlabel,and(22)
used the assumption that annotator confusion is independent from data items. In the above, f⋆ and A
m
17Figure7: TheperformanceofE2Emethods, GeoCrowdNet[13], TraceReg[15], andCrowdLayer[14]and
thetwostageapproaches(labelcorrectionmethodsCNMF[30],MV,andDS-EM[8]followedbyaneural
network(NNet)classifiertraining)overfourdifferentdatasets.
aredefinedasbefore[cf. (1)and(5)]. Again,theconfusionmatrixA isassumedtobethesameacrossall
m
n,asy (cid:98)n(m) andy nforallnarei.i.d. samples.
The goal of E2E learning is to find Pr(y |x ). Under classification settings, the posterior distribution
n n
maps any data item to a PMF over the class labels 1,...,K. Therefore, let a function f : RD → RK
θ
parametrized by θ to represent the ground-truth label posterior f⋆. Collecting all model parameters in
ψ =(A ,...,A ,θ),wehave
1 M
N K M
(cid:89) (cid:88) (cid:89)
Pr(D;ψ)= [f (x )] A (y(m),y ).
θ n yn m (cid:98)n n
i=1yn=1 i=1
SimilartothelabelintegrationsettinginSec. 3.3,theMLEproblemisformulatedas
ψ(cid:98)=argmax log(Pr(D;ψ)), (23)
ψ
andaswiththelabelintegrationcase,optimizationw.r.t.ψisnottrivial.Totackletheoptimizationproblem
in (23), [14,16] adopted the EM strategy. Specifically, by considering the unobserved ground-truth labels
Y = {y }N as the latent variables, the expected value of the complete log-likelihood log(Pr(D,Y;ψ))
n n=1
underthecurrentestimateofψiscomputedintheE-step:
N K
(cid:88)(cid:88)
Q(ψ;ψt)=E [logPr(D,Y;ψ)]= q(y =k;ψt)logPr(x ,y(1),...,y(M);ψ)
Y∼Pr(Y;D,ψt) n n (cid:98)n (cid:98)n
n=1k=1
withq(y
n
=k;ψt)= Z1[f θt(x n)] k(cid:81)M i=1At m(y (cid:98)n(m),k)andZ beingthenormalizationconstant[cf. (8)].
TheM-stepestimatesψbymaximizingQ(ψ;ψt).Thiscanbedonebyalternatingbetweenthefollowing
updates:
(cid:80)N q(y =k;ψt)I[ym =k′]
At+1(k′,k)= n=1 n (cid:98)n (24a)
m (cid:80)K (cid:80)N q(y =k;ψt)I[ym =k′′]
k′′=1 n=1 n (cid:98)n
θt+1 =argmax Q(θ;(θt,{At+1})). (24b)
m
θ
18This EM formulation is very similar to the one advocated for the DS model in Sec. 3.3, albeit with the
classifier f taking the role of the prior class probabilities d. The EM framework is flexible in terms of
θ
incorporatingvariousf functionclasses. Forbinaryclassification,[16]advocatedforalogisticregression
θ
model,where[f ] = σ(θ⊤x )and[f ] = 1−σ(θ⊤x ),andσ denotesthesigmoidfunction. Asaresult,
θ 1 n θ 2 n
a Newton-Raphson algorithm can be implemented for (24b). Neural networks were used in [14] to serve
as f , where (24b) was updated by back-propagation based stochastic gradient. To deal with sequence-
θ
type data, [44] used a condition random field (CRF) function as the classifier, which uses of the Viterbi
algorithmandthelimited-memoryBroyden–Fletcher–Goldfarb–Shannon(BFGS)algorithmfortheM-step.
A Bayesian method was adopted in [45] that used a Gaussian process to model a binary classifier and
adoptedanexpectationpropagation(EP)-basedalgorithmfortheinferencethatinvolvesEM-likeiterative
steps.
4.2 DeepLearningwith“CrowdLayer”
Among all the functions that can be used as f , deep neural networks (DNNs) naturally attract a lot of
θ
attention, due to their remarkable empirical success in various domains. While [14] showed that EM can
beusedtogetherwithDNNs, theEMframeworkhassomelimitations. First, theEMframeworkisbased
onmulti-classclassification, yetitisnotstraightforwardtoextendittocoverotherproblemsettings, e.g.,
when sequence data is involved—the E-step could quickly become intractable. Second, the derivation of
the EM framework relies on the conditional independence of the annotators, which may not be always a
validassumption,asdiscussedinSec.3.4. Third,thefunctionf needstobetrainedineachM-step,which
θ
maybecomputationallydemanding.
An alternative approach to incorporate DNNs in crowdsourcing was advocated in [14]. Consider the
probabilityofm-thannotators’responsetothedataitemx asfollows:
n
K
(cid:88)
Pr(y(m) =k|x )= Pr(y(m) =k|y =k′)Pr(y =k′|x ), k ∈[K], (25)
(cid:98)n n (cid:98)n n n n
k′=1
where we used the law of total probability and the assumption that annotator responses are instance-
independent,giventhelabely n. UpondefiningaK-dimensionalvectorp( nm) suchthat[p( nm)]
k
≜Pr(y (cid:98)n(m) =
k|x ),Eq.(25)canbeexpressedasfollows:
n
p(m) =A f⋆(x ),∀m,n, (26)
n m n
where[f⋆(x )] = Pr(y = k|x )isasdefinedin(1). Underthismodel, observationscanbeunderstood
n k n n
as realizations of a categorical random variable, i.e. y (cid:98)n(m) ∼ categorical(p( nm)). To estimate A
m
and f⋆, a
commonlyusedcriterioninmachinelearningiscrossentropy(CE),i.e.,
K
(cid:88)
CE(p(m),A f (x ))=− [p(m)] log[A f (x )] ,
(cid:98)n m θ n (cid:98)n k m θ n k
k=1
wherep (cid:98)n(k) = 1ify (cid:98)n(m) = k andp (cid:98)k(k′) = 0fork′ ̸= k,andf
θ
isthelearningfunctionforapproximating
f⋆ asbefore. Inanutshell,CEseeksamodel{A m,f θ(x n)}thatmatchesthe“empiricalPMF”p (cid:98)( nm) . Itcan
beshownthatwhenN → ∞,theminimumofCEisattainedatAf θ(x n) = p( nm) . Collectingallannotator
responses,[14]usedthefollowingcoupledcross-entropyminimizationcriterion(CCEM)[14]:
K
1 (cid:88) (cid:88)
minimize − I[y(m) =k]log[A f (x )] (27)
fθ∈F,{Am∈A} |S|
(m,n)∈Sk=1
(cid:98)n m θ n k
whereS ⊆[M]×[N]istheindexsetofannotator-labeledsamples,F ⊆{f(x)∈RK|f(x)∈∆ , ∀x}isa
K
functionclassparameterizedbyθ,∆ representsthe(K−1)-probabilitysimplex,andAistheconstrained
K
19Figure8: The“crowdlayer”-basedarchitecturefordeeplearning-basedE2Ecrowdsourcing
set of confusion matrices {A ∈ RK×K|A ≥ 0,1⊤A = 1⊤}. In practice, f ∈ F can be approximately
θ
enforcedbyusingasoftmaxlayerasitsoutput. Theconstraintsensurethattheoutputoff andcolumns
θ
ofA m’sarePMFs. Theterm“coupled”referstothefactthattheexpressionsofp( nm) forallmarecoupled
byf (x ).
θ n
Fig.8illustratesthelossfunctionofCCEM.Here,confusionmatricesA ’sactasadditionalannotator-
m
specific layers of the neural network [14], hence this approach is termed crowdlayer. The CCEM type for-
mulation is arguably more versatile in terms of modeling and computation relative to the EM-type E2E
algorithms. First, regularization terms on A and θ can be easily added for various purposes, e.g., in-
m
corporating prior knowledge and enhancing identifiability [13,15]. Second, as we have seen, the CCEM
approach does not require that annotators are conditionally independent (also see details in [13]). Third,
theempiricaldistributionp (cid:98)( nm) needsnotbecategorical,openingdoorsforcontinuousmeasurement-based
problems, e.g., regression. Finally, the crowdlayer architecture can be easily trained via backpropagation
and any gradient decent-based optimization algorithms like Adam, using off-the-shelf deep learning li-
brariessuchasPyTorchandTensorFlow.
4.3 ModelIdentifiabilityunderCCEM
IssuesofmodelidentifiabilityalsoariseintheE2Econtext. UndertheCCEMcriterion,andthegenerative
model y (cid:98)n(m) ∼ categorical(A mf⋆(x n)), it is essential to identify A m’s and the ground-truth f⋆(x n) (i.e.,
Pr(y |x )). Notethatidentifyingf⋆(x )(i.e., toattainf (x ) ≈ f⋆(x ))overalltheseen(training)data
n n n θ n n
{x }N allowsthelearnedmodelf togeneralizeoverunseen(test)dataaswell.Thisturnsouttobenon-
n n=1 θ
trivial.IntheidealcasewhereN →∞,theCCEMcriterionreturnsf(cid:98)θandA(cid:98)msuchthatp( nm) =A(cid:98)mf(cid:98)θ(x n).
Nevertheless, one can easily note that such a relation is highly non-unique since there exists an infinite
numberofnonsingularmatricesQ ∈ RK×K suchthatp( nm) = (A(cid:98)mQ)(Q−1f(cid:98)θ(x n)). However,CCEM-type
approachesseemtoalwayslearnreasonableA andf inpractice. Tounderstandthisphenomenon,[13]
m θ
providedperformancecharacterizationsofCCEM,fromanNMFidentifiabilityviewpoint. Tobespecific,
whenN →∞,theCCEMcriterioncanbeunderstoodasfindingsolutionstofitthefollowingmodel:
 p(1) ... p(1)  A 
1 N 1
   . . . ... . . .   =   . . .   (cid:2) f⋆(x 1) ... f⋆(x N)(cid:3) , (28)
p( 1M) ... p( NM) A M (cid:124) H∈R(cid:123)(cid:122) K×N (cid:125)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
P∈RMK×N W∈RMK×K
20where the factors W and H are both nonnegative per their physical meaning. Clearly, if W and H both
satisfytheseparabilitycondition(orthesufficientlyscatteredcondition(SSC)),asdiscussedin“Identifia-
bilityofCPDandNMF”(alsosee[42]),thefactorizationmodelin(28)isessentiallyunique;i.e.,thereexists
apermutationmatrixΠsuchthat
∥A(cid:98)mΠ−A m∥→0, ∥Π⊤f(cid:98)θ(x)−f⋆(x)∥→0, (29)
when N → ∞. For W, the separability condition still requires the existence of class experts for each of
theK classes. ForH,separabilityimpliestheexistenceofK indices,{n ,...,n } = {1,...,K}suchthat
1 K
f⋆(x ) = e ⇔ Pr(y = k|x ) = 1. Suchpointsx arecalled“anchorpoints”fortheclassesandare
nk k nk nk nk
oftenfoundusefulinnoisylabellearning.
AimingtorelaxtheconditionsononeofW andH,[13]proposedaregularization-basedCCEM.Specif-
ically,aregularizationtermtomaximizethevolumeofH =[f (x ),...,f (x )]wasadded:
θ 1 θ N
minimize L −βlogdet(HH⊤), (30)
CCEM
{Am∈A},fθ∈∆K
whereL isdefinedastheobjectivefunctionin(27)andβ ≥0. Thisformulationleveragesthesimplex
CCEM
volumeminimization-basedstructuredmatrixfactorization[42]toestablishidentifiabilityasshownin(29).
Thisway, the separabilityorSSCconditionimposed ontoW canbe removed. This substantially reduces
theexpertiserequirementfortheannotatorstoestablishidentifiabilityofthemodel.
4.4 OtherE2ECrowdsourcingApproaches
Agreement-BasedModel. Besidestheconfusionmatrix-basedmodelsandformulationsasin(23)and(27),
someothertreatmentsforE2Elearningwerealsointroduced[46]. Theapproachin[46]proposestousean
annotator“aggregator”denotedasg thatmeasuresthe“averageagreement”betweendifferentannotator
ϕ
responses,andismodeledasanaffinemappingfollowedbyaso-calledsoftmaxoperation:
(cid:32) M (cid:33)
(cid:88)
g ({p(m)})=softmax W(m)p(m)+b .
ϕ (cid:98)n (cid:98)n
m=1
Here, ϕ = {W(1),...,W(M),b} and p (cid:98)( nm) denotes the one-hot embedding of the noisy label y (cid:98)n(m) as be-
fore. Notethatf θ(x n)andg ϕ({p (cid:98)( nm)})canbeunderstoodastwolabelpredictorsusingdatafeaturesand
annotator-produced labels as inputs, respectively. The idea in [46] is to maximize the “agreement” (mea-
suredbyf-mutualinformationgain(MIGf))betweenthesetwohypothesesf andg :
θ ϕ
maximizeMIGf(f ,g ;{x },{p(m)}). (31)
θ ϕ n (cid:98)n
θ,ϕ
Inessence,MIGf measurestheagreementbetweenf θ(x n)andg ϕ({p (cid:98)( nm)})averagedoverallthedataitems.
Themeasureofagreementisanf-divergencelossfunction,suchastheKLdivergence. Itwasalsoshown
in[46]thattheobjective(31)findsoptimalsolutions(i.e.,thesolutionsthatextractmaximuminformation
from their inputs to predict the ground-truth) in the asymptotic case, provided there are conditionally
independentexpertannotators.
Instance-dependent Confusion Matrix. Both EM and CCEM based E2E methods assume that A re-
m
mainsidenticalacrossallx [cf. (26)]. Recentworksstudiedcrowdsourcingapproachesunderaninstance-
n
dependentsetting:
p(m) =A (x )f⋆(x ),∀m,n, (32)
n m n n
where A m(x n)’s are instance-dependent annotator confusions with entries [A m(x n)] k,k′ = Pr(y (cid:98)n(m) =
k|y = k′,x ) [cf. (21)]. To estimate the instance-dependent confusion matrices, a common approach
n n
21istousetwolearnablefunctions,i.e., f : RD → RK andAϕ(·) : RD → RK×K (e.g.,neuralnetworks)to
θ m
parameterizef⋆andA (x ),respectively.
m n
E2Elearningofthemodelin(32)wasconsideredin[47],whichextended[15]asfollows:
K M N
1 (cid:88) (cid:88) (cid:88) (cid:88)
minimize − I[y(m) =k]log[Aϕ(x )f (x )] +β trace(Aϕ(x )). (33)
{Aϕ m∈A},fθ∈∆K |S| (m,n)∈Sk=1 (cid:98)n m n θ n k m=1n=1 m n
However, establishing identifiability of the two functions A (·) and f⋆(·) from their product using E2E
m
learningisfundamentallychallenging. Acommonworkaroundistouseamulti-stagestrategy, i.e., first
learningAϕ(·)usingsomepre-selecteddataitemsandthenusingthelearnedAϕ(·)totrainf usinglosses
m m θ
similarto(33). Forinstance,[48]parametrizestheinstance-dependentannotatorconfusionsusingamixed
effectsneuralnetworkmodel(MNN):
[Aϕ(x )] =softmax(B(m)g (x )+C(k)g (x )), (34)
m n :,k ϕ1 n ϕ2 n
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
annotator-specific class-specific
whereg andg aretwoneuralnetworksparameterizedbyϕ andϕ ,respectively. Themodelaimsto
ϕ1 ϕ2 1 2
capture the the annotator-specific and class-specific effects on A (x ). In this work, the first step selects
m n
some “anchor data points” for each class k. The anchor points satisfy Pr(y = k|x) = 1, which means
n
[A m(x n)]
:,k
=Pr(y (cid:98)n(m) =k|x n). Usingsuchselecteddataitems{x s,{y (cid:98)n(m)}}S s=1,theMNNparametersφ=
{ϕ ,ϕ ,{B(m)},{C(k)}} are learned first using a regression approach. The next step involves predicting
1 2
theground-truthlabelsthroughapairwiselikelihoodratiotestusingthelearnedAϕ(·). Thesepredictions
m
arethenusedtotrainf .
θ
4.5 OtherTypesofAnnotations
WhilethediscussionsinSec.3and4focusontheclassificationsettingwheretheannotationsarecategorical,
similarmodelingandalgorithmdesignideascanbeappliedforothertypesaswell.
Regression. Considerthecasewheretheground-truthlabelandthecorrespondingannotationstakecon-
tinuousrealvalues,i.e.,y
n
∈Randy (cid:98)n(m) ∈R. Themostnaiveaggregationschemeisaveraging,i.e.
1 (cid:88)
y˜ = y(m)
n |M | (cid:98)n
n
m∈Mn
withM ⊆ [M]denotingsetofannotatorswhohaveprovidedaresponseforthen-thdataitem. Amore
n
robustalternative,thatisoftenusedinfederatedlearning,isthemedianintegrationrule.
Bothaverageandmediancanberegardedascontinuousextensionsofmajorityvoting. TheDSmodel
canalsobeextendedtocontinuousannotationcases. Forexample,onecanassigncontinuousdistributions
to the ground-truth labels and annotator responses, i.e., y ∼ N(µ ,σ2) where µ ,σ2 are the mean and
n n n n n
variance of the labels, respectively, while the conditional distributions of annotator responses given the
ground-truthlabely
n
= αarey (cid:98)n(m)|y
n
= α ∼ N(α,σ m2 ),withσ m2 beingannotatorspecificvariance[49]. In
theE2Elearning-basedsetting,linearregression,GaussianProcessordeeplearningmodelscanbereadily
employed,withf (x )beingthecontinuousdistributionPr(y |x )[14].
θ n n n
Ranking. Insomecases,annotatorsareaskedtoproviderankingofdataitems. Twotypesofrankingare
often considered, namely, pairwise preference and ordinal ranking. In the pairwise preference case, the
ordinalranksofallthedataitemsaresoughtbycomparingpairs. Givenapairx
n
andx n′,thepreference
ofx n overx n′ isdenotedasx n ≻ x n′. OneofthepopularmodelsforpreferenceisthetheBradley-Terry
(BT)model,inwhichtheprobabilityofx n ≻x n′ ismodeledasfollows:
esn
Pr(x
n
≻x n′)=
esn +es
n′, (35)
22where s for n ∈ [N] is a so-called ranking score for x . In the crowdsourcing setting, each annotator
n n
indicates their preference over x
n
and x n′. That is, if annotator m prefers x
n
over x n′, it is denoted as
x
n
≻
m
x n′. Givenaground-truthpreferencerelationx
n
≻ x n′, annotatorm’scorrectnessandconfusion
probabilitiescanbeexpressedusingw
m
= Pr(x
n
≻
m
x n′|x
n
≻ x n′)and1−w m,respectively. Underthis
model, [50] used the MLE principle to jointly learn w and ranking s . In E2E crowdsourcing, s is ex-
m n n
pressedass =f (x ),wheref :RD →Rlearnsareal-valuedscorefunctionfromthedatafeatures.Note
n θ n θ
thattheBTmodelandsuchfunction-basedscorerepresentationwereusedinLLMfine-tuning,specifically,
by the direct preference optimization (DPO) approach [51]. In the ordinal ranking case, [16] converted the
annotator-provided preference order of the data items into binary labels. This also allows the associated
MLEformulationtobecombinedwithE2Elearningmethod.
SimilarityAnnotations. CrowdsourcedE2Elearningwasalsoformulatedasagraphclusteringproblem.
Inthiscase,theannotatorsareaskedtoindicatethesimilarityoftwodataitems. Thisway,an(incomplete)
N ×N binaryadjacencygraphGisconstructed, whereG(i,j) = 1meansthatx andx areregardedas
i j
“similar” or from the same class and G(i,j) = 0 means otherwise. Similarity-based annotation requires
substantially lower expertise level from the annotators and thus is a promising paradigm for extra-large
scaledataannotation. ThelabelscanbemodeledasBernoullisamplesasfollows:
G(i,j)∼Bernoulli(cid:0) f⋆(x )⊤f⋆(x )(cid:1) , (36)
i j
where f⋆ such that [f⋆] = Pr(y = k|x ) for k = 1,...,K following the same realizability assumption
k n n
before. The term f⋆(x )⊤f⋆(x ) ∈ [0,1] naturally models the similarity of x and x . Let a function f
i j i j θ
be the learner of the ground-truth f⋆ as in the aforementioned E2E approaches, the MLE under (36) is a
logisticregressionobjective(see[52]andsomepredecessors):
minimize (cid:88) (cid:2)I[g =1]log(cid:0) f (x )⊤f (x )(cid:1) +I[g =0]log(cid:0) 1−f (x )⊤f (x )(cid:1)(cid:3) , (37)
ij θ i θ j ij θ i θ j
fθ∈∆K
(i,j)∈Ω
whereΩistheindexsetofannotatedpairs.Theidentifiabilityoff⋆wasestablishedbytreatingthemodelin
(36)asaquantizednonnegativematrixfactorizationproblem.Similarityannotationscanbeeasilyacquired
bythecrowd(despitenoannotator-specificmodelsusedin(36)),andthusthistypeofapproachesareoften
referredtoascrowdclusteringintheliterature.
5 Emerging Topics in crowdsourcing
Asdiscussedintheprevioussections,theresearchincrowdsourcinghasmadeimpressiveprogressinthe
last several decades. Next, we will explore some additional contemporary topics in this domain that are
garneringincreasingattentionfromthemachinelearningcommunity.
5.1 BiasandFairness
Machine learning and statistical learning algorithms are increasingly being applied in areas with signifi-
canthumanandsocietalimpact,suchascreditscoring,loanunderwriting,jobapplications,andthepenal
system. Whilethesealgorithmsoftenachieveoverallgoodperformancefortheunderlyingtask,theycan
alsoperpetuateunfairnessandbiasbydiscriminatingagainstcertainsensitiveattributes,suchasrace,age,
or affiliation. In crowdsourcing, the presence of unfair workers, who provide more inaccurate labels to
the data items belonging to a particular group, can significantly impact the overall system performance
w.r.t. the sensitive attributes. For instance, a recent empirical study [53] observed that the performance
ofthelabelintegrationapproachesincludingmajorityvoting,DSmodel-basedEM,andtheE2Eapproach
Crowdlayer,allareimpactedbythepresenceofunfairannotators. Anapproachtoselectfairworkersfor
labelingtaskswasadvocatedin[54]. Theyproposedanannotatorassignmentsearchalgorithmsuchthat
the overall label integration accuracy is maximized while satisfying certain notions of fairness. Consider
sensitiveattribute-specificconfusionmatrixperannotator,similartotheinstance-dependentconfusionmatrix
23of(32),withentries [A m(Z = z)] k,k′ = Pr(Y(cid:98)(m) = k|Y = k′,Z = z)wherez ∈ {0,1}andZ istherandom
variable denoting the sensitive attribute (e.g., gender). Suppose that s denotes the probability that any
m
dataitemisassignedtomthannotator,regardlessofthesensitiveattribute. Underthissetting,[54]sought
anoptimalannotator-assignmentpolicys=[s ,...,s ]bymaximizingtheexpectedlabelingaccuracy,i.e.,
1 M
(cid:80)
Pr(Z =
z)(cid:80)
Pr(Y =
k)(cid:80)M
s [A (Z = z)] .Nevertheless,confusionmatricesandthe
z∈{0,1} k∈[K] m=1 m m k,k
priorprobabilitiesareassumedtobeestimatedaprioriusingsomelimited“gold”dataitemswithknown
ground-truthlabelsandsensitiveattributes. Inaddition,themaximizationisperformedundercertainfair-
nessconstraintssuchasfalsepositiverateparityonA (Z =z)’sanddiversityconstraintsonstobalance
m
theeffortsacrossmoreannotators.
5.2 AdversarialAttacks
In crowdsourced settings, label noise sometimes stems from undesirable annotator behaviors rather than
unintentional errors. Such undesirable behaviors may be caused by annotators who provide random re-
sponseswithnoeffort(spammers)andthosewhointentionallygiveincorrectresponses(adversaries). In
these cases, identifying and excluding spammers and adversaries is important for performance enhance-
ment. Oneapproachtoidentifyspammersisthroughexaminingannotatorconfusionmatrices. Considera
spammerannotatorm. Then,theentriesofthecorrespondingconfusionmatrixareA m(k′,k)=Pr(y (cid:98)n(m) =
k′|y
n
= k) = Pr(y (cid:98)n(m) = k′|y
n
= k′′) = Pr(y (cid:98)n(m) = k′),∀k,k′′, i.e., the annotator response does not de-
pendontheground-truthlabeloftheitem. Assuch, allcolumnsofA arethesameandrank(A ) = 1.
m m
Basedonthisobservation,[55]deriveda“spammerscore”thatwasthenusedinamodifiedEMalgorithm
to integrate labels and eliminate spammers. Using similar principles, a spectral approach based on the
(cid:104) (cid:105)
second-ordermoments E[Y(cid:98)(m)◦Y(cid:98)(i)] canbeusedtoidentifyspammerspriortolabelaggregation.
Aparticularlychallengingsettinginvolvescolludingadversaries,i.e.,annotatorsthatcooperatetode-
gradetheperformanceofacrowdsourcingsystem. Suchascenariocanbeparticularlydetrimentaltolabel
integrationalgorithmsthatrelyontheconditionalindependencebetweenannotators. Afewrecentworks
have attempted to tackle this issue. A robust rank-one matrix completion method was advocated in [56].
Specifically,therank-oneplusidentitystructure,asgivenby(10)in Sec.3.3,isexploitedassumingthatthe
reliabilitiesoftheadversariesdeviatefromthisstructure. ForthemoregeneralDSmodel,[57]advocated
aspectralmethodthatleveragestheparticularstructureoftheannotatoragreementmatrix. Notethatthe
methods for dependent annotators in 3.4 attempt to unveil the dependencies between annotators. Here,
while there are dependencies between colluding annotators, adversarial crowdsourcing algorithms treat
adversariesas“outliers”,andseektofilterthem.
Whentrainingdeeplearningsystems,effectiveadversarialattackcanberealizedbyaddingdesignated
noisetox . Undersuchcircumstances,[58]introducedanE2Emethod,basedonEM,thatcansimultane-
n
ouslylearnannotatorconfusionmatricesandarobustclassifier.
5.3 ReinforcementLearningwithHumanFeedback
Arecentfieldgainingsignificantattentionisreinforcementlearningwithhumanfeedback(RLHF),particularly
foritsapplicationinfine-tuningLLMs[59]. Inclassicalreinforcementlearning(RL),anagentinteractswith
anenvironmentoverT timesteps. Pertimestep,theenvironmentisatastates andtheagentchoosesan
t
actiona ,andreceivesarewardr .Thenextenvironmentstates isaffectedbythecurrentstates and
t t t+1 t
the agents action a , via a so-called transition probability p(s |s ,a ). The goal of the agent is to learn a
t t+1 t t
policy(i.e.,afunctionmappingstatestoactions)thatwillmaximizetheirrewards. RLhasbeenextensively
studiedandaplethoraofalgorithmsareavailabletotraintheagent.Nevertheless,akeycomponentofRLis
therewardfunction,whosedesignisanon-trivialtask. RLHFcircumventsthetaskofdesigningareward
function a priori; instead of using a pre-defined reward function, a reward model is learned via human
feedback. In RLHF, the agent can issue queries to one or more humans and receive labels in response.
Furthermore,queriescanbespecificactionsandstates,ortrajectoriesτ,whicharesequencesofstatesand
24actions τ = {s ,a ,s ,a ,...}. Typically, feedback is received asynchronously from the main RL agent-
0 0 1 1
environmentinteraction. Humanfeedbackcanbeintheformofclassifyingthequeriesas“good”or“bad”,
oraspreferencesbetweenapairoftrajectories(τ ,τ ). Intheformercase,thelabelintegrationapproaches
1 2
of the previous sections can be utilized to denoise the feedback from multiple human annotators. The
lattercanbetreatedusingpreference-basedlearningasin(35),andinRLHFsettingsx andx′ represent
n n
twotrajectories. Indeed,theBradley-TerrymodelforRLwasrecentlyextendedtothecrowdsourcingcase
in[60]. Allinall,thefieldofRLwithits’multitudeofapplications,presentsexcitingopportunitiestoapply
theprinciplesandideasofcrowdsourcing.
5.4 ConnectionstoActiveLearning,andTransferLearning
5.4.1 Activelearning
MostcrowdsourcingjobssubmittedtoservicessuchasAMT,operatewithinapredeterminedbudget. This
budgetcanbeeasilytranslatedintothetotalnumberofqueriesthatcanbeaskedfromtheannotators.Thus,
efforts that reduce the overall amount of annotator queries, while maintaining classification performance
are well motivated. These goals can be formulated as an active learning problem. Under a classifica-
tionsetup, activelearningiterativelyre-trainsalearnerbygraduallyselectingandaddingsamplestothe
trainingsetineachiteration. Centralcomponentstoanyactivelearningsystemarethemethodthatdata
isselectedtoaugmentthetrainingset,andefficientretrainingoftheclassifierasnewdataarrive. Ifthese
componentsaredesignedproperly,thesamplesneededforlearningtheclassifiercanbedrasticallyreduced
relativetoordinarytrainingprocesses. Dataselectionistypicallyfacilitatedbychoosingdataforwhichthe
currentclassifierismost“uncertain”of.Furthermore, (re-)trainingoff asnewdataarrivecanbefacilitated
via onlineoptimizationmethodssuchasstochasticgradientdescent(SGD).
Tominimizethenumberofqueriestoannotators,whilemaintaininghighclassificationaccuracy,active
learningcanberetooledandincorporatedinthelabelintegrationprocedure. Notably,inadditiontoselect-
ingwhichdatumtoacquirelabelsfor,onemustalsoselectwhichannotatortoquery. Ideally,theannotator
selectedshouldbetheonewiththehighestprobabilityofprovidingthecorrectlabelforagivendatum. As
discussedinSecs.3and4,popularlabelintegrationalgorithmscomputetheposteriorprobabilityforeach
datum Pr(y n|Y(cid:98)) at each iteration. These posteriors can then be used to quantify the “uncertainty” of the
labelintegrationforeachdatapoint,givencurrentlyavailableannotations. Atthesametime,theavailable
estimatesofannotatorconfusionmatricesmaynotbereliableandintroduceadditionaluncertaintyintothe
model. Annotatorscanbeselectedusingthecurrentestimatesofconfusionmatrices. However,oneshould
be careful when selecting which annotator to query, as the “best” annotator based on current parameters
maybesuboptimal.Thus,randomizedexplorationstrategiesmaybebeneficial,especiallywhenonlyafew
labelsareavailable. Afewrecentmethodsutilizeactivelearninginthepurelabelintegration[61]andE2E
cases[45].Inaddition,itcanbenotedthattheannotatorselectionproblemcanbecastasaMulti-armedBan-
dit(MAB)problem,witheachannotatorcorrespondingtoan“arm”or“action”inthebanditsetting[62].
In all these cases, active learning-based sampling of data and annotators outperforms randomly selected
ones,indicatingthesignificanceofactivemethodsincrowdsourcing.
5.4.2 Transferlearning
Anothersetoftechniquesdesignedtodecreasetheamountofannotationsare basedonTransferLearning
(TL).InTL,oneisinterestedintrainingamodelforamachinelearningtaskofinterest, termedthetarget
task. However, the target task does not have enough labeled data available for training. Instead, another
relatedauxiliarytaskhasplentyoflabeleddata.TLseekstotransferknowledgefromtheauxiliarytask,such
thatahigh-performancemodelcanbetrainedforthetargettask. Inthecrowdsourcingsetup, annotators
canberegardedas“vehicles”totransferknowledgeacrosstasks. Indeedaninterestingquestionthatarises
is: “Whichannotatorswouldperformwellona low-resourcetargettask?”. In[63],aprobabilisticmodel
thatcapturesannotatorabilityandtaskspecificparameterswasdevelopedtoestimateannotatorreliability
25across multiple different tasks. When data features are available, [64] advocated for a logistic regression-
basedmodelthatcantransferknowledgeacrossmultipletasks.
6 Conclusions and future directions
Crowdsourcing-based data annotation is pivotal in the AI era. Since crowdsourced annotators are often
unreliable,effectivelyintegratingmultiplenoisylabelstoproduceaccurateannotationsstandsasarguably
themostimportantconsiderationfordesigningandimplementingacrowdsourcingsystem. Inthisfeature
article, we reviewed key milestones in crowdsourcing research, including models, methods, theoretical
advancements and emerging topics. We also reviewed the intimate connections between crowdsourcing
andsignalprocessingtheoryandmethods,suchasNMF,tensordecomposition,distributeddetection,and
optimizationtechniques—showinghowSPperspectivescouldofferprincipleddesignandenhancedper-
formanceforcrowdsourcingsystems.
TogetherwiththeAIboomandthewideadoptionoflarge,complexmodelsthathavehighoverfitting
risks, the relevance of crowdsourced data annotation continues to rise. We highlight several worthwhile
futureresearchdirectionsbelow:
• Understanding of crowdsourcing under realistic and challenging scenarios, such as those involving
instance-dependentlabelnoise,imbalanceddatadistribution,ordynamicandevolvingtasks,isstill
limited. Existingapproacheseitherrequirestringentconditionsorrelyonheuristics. Principledso-
lutionswithperformanceguarantees—suchasmodelidentifiability,generalization,andsamplecom-
plexity—arehighlydesirableinthesecases.
• Crowdsourcingapproachesareakeycomponentofthetrainingandfinetuningfoundationmodels—
see,e.g.,ourintroductiononusingcrowdsourcedlabelstofinetuneLLMsviaRLHFandDPO.These
directionshavejustbeguntobeexplored,andthusmanyresearchquestions,suchasthoseregarding
modelbuilding,methoddesign,andperformancecharacterization,remainwideopen.
• In-depth annotator behavior models, which consider aspects like bias and adversarial tendencies,
have proven beneficial. However, these complex models often involve nontrivial and multi-faceted
designconsiderations, e.g., fairnessmetricseffectiveness, parameterparsimony, andalgorithmscal-
ability. Despite some advancements in the past decade, unified design frameworks and standards
haveyettobeestablished.
• Crowdsourcing offers solutions to a wide range of problems in science and engineering. However,
there remains significant scope for the joint design of crowdsourcing algorithms and specific appli-
cations, such as medical diagnosis, environmental monitoring, and disaster response. This can be
achieved by using cutting-edge models and algorithms tailored to the problem at hand, especially
in light of the emergence of large-scale foundation models. Additionally, the collaboration between
humanandmachineannotators,includingLLMagents,canenhancedataannotation. Theseoppor-
tunities present many unique challenges to be addressed in system design, data and computational
resourcemanagement,andperformancecharacterization.
• The scope of classical applications such as distributed detection, remote calibration, the CEO prob-
lem from information theory, and blind multichannel deconvolution can be broadened via cross-
polinationwithcrowdsourcingmethods. Forinstance,blinddeconvolutioncanbeextendedtonon-
linearsettings,usingideasfromE2Ecrowdsourcing,whereasratedistortionideasfrominformation
theorycanbepotentiallyappliedtostudythecost-performancetradeoffincrowdsourcing. Another
exciting avenues of research include game theoretic approaches in adversarial crowdsourcing and
robustdatafusiontenchniquesthatlearnfromnoisymulti-viewdata.
26Acknowledgments
The work of X. Fu was supported in part by the National Science Foundation (NSF) under Project NSF
IIS-2007836. TheworkofP.TraganitiswassupportedinpartbyNSFgrant2312546.
References
[1] G. V. Research, “Data collection and labeling market size, share & trends analysis report,” https://
www.grandviewresearch.com/industry-analysis/data-collection-labeling-market,2022.
[2] D.VakhariaandM.Lease,“BeyondAMT:Ananalysisofcrowdworkplatforms,”ComputingResearch
Repository,2013.
[3] W.X.Zhao,K.Zhou,J.Li,T.Tang,X.Wang,Y.Houetal.,“Asurveyoflargelanguagemodels,”arXiv:
2303.18223,2023.
[4] J.A.Bogovic,B.Jedynak,R.Rigg,A.Du,B.A.Landman,J.L.Prince,andS.H.Ying,“Approachingex-
pertresultsusingahierarchicalcerebellumparcellationprotocolformultipleinexperthumanraters,”
Neuroimage,vol.64,pp.616–629,Sep.2012.
[5] D.E.Boubiche, M.Imran, A.Maqsood, andM.Shoaib, “Mobilecrowdsensing–taxonomy, applica-
tions,challenges,andsolutions,”ComputersinHumanBehavior,vol.101,pp.352–370,2019.
[6] D.Lahat,T.Adali,andC.Jutten,“Multimodaldatafusion: Anoverviewofmethods,challenges,and
prospects,”ProceedingsoftheIEEE,vol.103,no.9,pp.1449–1477,2015.
[7] N. B. Shah and D. Zhou, “Double or nothing: Multiplicative incentive mechanisms for crowdsourc-
ing,”JournalofMachineLearningResearch,vol.17,no.165,pp.1–52,2016.
[8] A.P.DawidandA.M.Skene,“Maximumlikelihoodestimationofobservererror-ratesusingtheEM
algorithm,”AppliedStatistics,pp.20–28,1979.
[9] Y.Tong,L.Chen,andC.Shahabi,“Spatialcrowdsourcing: Challenges,techniques,andapplications,”
Proc.VLDBEndow.,vol.10,no.12,p.1988–1991,aug2017.
[10] P. A. Traganitis, A. Pages-Zamora, and G. B. Giannakis, “Blind multiclass ensemble classification,”
IEEETrans.SignalProcess.,vol.66,no.18,pp.4737–4752,2018.
[11] Y.Zhang,X.Chen,D.Zhou,andM.I.Jordan,“SpectralmethodsmeetEM:Aprovablyoptimalalgo-
rithmforcrowdsourcing,”inAdvancesinNeuralInformationProcessingSystems,2014,pp.1260–1268.
[12] S.Ibrahim,X.Fu,N.Kargas,andK.Huang,“Crowdsourcingviapairwiseco-occurrences:Identifiabil-
ityandalgorithms,”inAdvancesinNeuralInformationProcessingSystems,vol.32,2019,pp.7847–7857.
[13] S.Ibrahim, T.Nguyen, andX.Fu, “Deeplearningfromcrowdsourcedlabels: Coupledcross-entropy
minimization,identifiability,andregularization,”inProceedingsofInternationalConferenceonLearning
Representations,2023.
[14] F.RodriguesandF.Pereira,“Deeplearningfromcrowds,”ProceedingsoftheAAAIConferenceonArtifi-
cialIntelligence,vol.32,no.1,2018.
[15] R.Tanno,A.Saeedi,S.Sankaranarayanan,D.C.Alexander,andN.Silberman,“Learningfromnoisy
labelsbyregularizedestimationofannotatorconfusion,”IEEEConferenceonComputerVisionandPat-
ternRecognition,pp.11236–11245,2019.
[16] V. C. Raykar, S. Yu, L. H. Zhao, G. H. Valadez, C. Florin, L. Bogoni, and L. Moy, “Learning from
crowds,”JournalofMachineLearningResearch,vol.11,no.Apr,pp.1297–1322,2010.
27[17] D.Karger,S.Oh,andD.Shah,“Iterativelearningforreliablecrowdsourcingsystems,”inAdvancesin
NeuralInformationProcessingSystems,vol.24,2011.
[18] N.LittlestoneandM.K.Warmuth, “Theweightedmajorityalgorithm,” InformationandComputation,
vol.108,no.2,pp.212–261,1994.
[19] J.Tsitsiklis,“Decentralizeddetection,”AdvancedStatisticalSignalProcessing,vol.2,1993.
[20] L. Tong and S. Perreau, “Multichannel blind identification: from subspace to maximum likelihood
methods,”ProceedingsoftheIEEE,vol.86,no.10,pp.1951–1968,1998.
[21] T. Berger, Z. Zhang, and H. Viswanathan, “The CEO problem [Multiterminal Source Coding],” IEEE
Trans.Inf.Theory,vol.42,no.3,pp.887–902,1996.
[22] A.Ghosh,S.Kale,andP.McAfee,“Whomoderatesthemoderators?crowdsourcingabusedetectionin
user-generatedcontent,”inProceedingsoftheACMConferenceonElectronicCommerce,2011,pp.167–176.
[23] D.R.Karger,S.Oh,andD.Shah,“Budget-optimalcrowdsourcingusinglow-rankmatrixapproxima-
tions,”inAnnualAllertonConferenceonCommunication,Control,andComputing,2011,pp.284–291.
[24] D.Zhou,S.Basu,Y.Mao,andJ.Platt,“Learningfromthewisdomofcrowdsbyminimaxentropy,”in
AdvancesinNeuralInformationProcessingSystems,vol.25,2012.
[25] N. Dalvi, A. Dasgupta, R. Kumar, and V. Rastogi, “Aggregating crowdsourced binary ratings,” in
ProceedingsoftheInternationalConferenceonWorldWideWeb,2013,pp.285–294.
[26] D. Zhou, Q. Liu, J. Platt, and C. Meek, “Aggregating ordinal labels from crowds by minimax condi-
tionalentropy,”inProceedingsoftheInternationalConferenceonMachineLearning,2014,pp.262–270.
[27] J.Whitehill,T.-f.Wu,J.Bergsma,J.Movellan,andP.Ruvolo,“Whosevoteshouldcountmore:Optimal
integrationoflabelsfromlabelersofunknownexpertise,”inAdvancesinNeuralInformationProcessing
Systems,vol.22,2009.
[28] H.-C.KimandZ.Ghahramani,“Bayesianclassifiercombination,”inArtificialIntelligenceandStatistics,
2012,pp.619–627.
[29] S. Ibrahim and X. Fu, “Recovering joint probability of discrete random variables from pairwise
marginals,”IEEETrans.SignalProcess.,vol.69,pp.4116–4131,2021.
[30] ——, “Crowdsourcingviaannotatorco-occurrenceimputationandprovablesymmetricnonnegative
matrixfactorization,”inProceedingsoftheInternationalConferenceonMachineLearning,2021,pp.4544–
4554.
[31] Q.Liu,J.Peng,andA.T.Ihler,“Variationalinferenceforcrowdsourcing,”AdvancesinNeuralInforma-
tionProcessingSystems,vol.25,2012.
[32] Q. Li, Y. Li, J. Gao, B. Zhao, W. Fan, and J. Han, “Resolving conflicts in heterogeneous data by truth
discoveryandsourcereliabilityestimation,”inProceedingsoftheACMSIGMODInternationalConference
onManagementofData,2014,p.1187–1198.
[33] T.TianandJ.Zhu,“Max-marginmajorityvotingforlearningfromcrowds,”AdvancesinNeuralInfor-
mationProcessingSystems,vol.28,2015.
[34] D.R.Karger,S.Oh,andD.Shah,“Budget-optimaltaskallocationforreliablecrowdsourcingsystems,”
OperationsResearch,vol.62,no.1,pp.1–24,2014.
[35] P.A.TraganitisandG.B.Giannakis, “Unsupervisedensembleclassificationwithsequentialandnet-
workeddata,”IEEETrans.Knowl.DataEng.,vol.34,no.10,pp.5009–5022,2020.
28[36] E.SimpsonandI.Gurevych,“ABayesianapproachforsequencetaggingwithcrowds,”inProceedings
oftheConferenceonEmpiricalMethodsinNaturalLanguageProcessingandtheInternationalJointConference
onNaturalLanguageProcessing,K.Inui,J.Jiang,V.Ng,andX.Wan,Eds.,2019,pp.1093–1104.
[37] A.Jaffe,E.Fetaya,B.Nadler,T.Jiang,andY.Kluger,“Unsupervisedensemblelearningwithdependent
classifiers,”inArtificialIntelligenceandStatistics,2016,pp.351–360.
[38] P.A.TraganitisandG.B.Giannakis,“Identifyingdependentannotatorsincrowdsourcing,”inAsilomar
ConferenceonSignals,Systems,andComputers,2022,pp.1276–1280.
[39] C.Gao,Y.Lu,andD.Zhou,“Exactexponentinoptimalratesforcrowdsourcing,”inProceedingsofthe
InternationalConferenceonMachineLearning,vol.48,20–22Jun2016,pp.603–611.
[40] N. Kargas, N. D. Sidiropoulos, and X. Fu, “Tensors, learning, and ’Kolmogorov extension’for finite-
alphabetrandomvectors,”IEEETrans.SignalProcess.,vol.66,no.18,pp.4854–4868,2018.
[41] N.Sidiropoulos,L.DeLathauwer,X.Fu,K.Huang,E.Papalexakis,andC.Faloutsos,“Tensordecom-
position for signal processing and machine learning,” IEEE Trans. Signal Process., vol. 65, no. 13, pp.
3551–3582,Jul.2017.
[42] X.Fu,K.Huang,N.D.Sidiropoulos,andW.-K.Ma,“Nonnegativematrixfactorizationforsignaland
data analytics: Identifiability, algorithms, and applications,” IEEE Signal Process. Mag., vol. 36, no. 2,
pp.59–80,March2019.
[43] P.A.TraganitisandG.B.Giannakis,“Bayesiancrowdsourcingwithconstraints,”inMachineLearning
andKnowledgeDiscoveryinDatabases.ResearchTrack,EuropeanConference,ECMLPKDD,2021,pp.543–
559.
[44] F.Rodrigues,F.Pereira,andB.Ribeiro,“Sequencelabelingwithmultipleannotators,”Machinelearning,
vol.95,pp.165–181,2014.
[45] ——,“Gaussianprocessclassificationandactivelearningwithmultipleannotators,”inProceedingsof
theInternationalConferenceonMachineLearning,vol.32,no.2,22–24Jun2014,pp.433–441.
[46] P.Cao,Y.Xu,Y.Kong,andY.Wang,“Max-MIG:Aninformationtheoreticapproachforjointlearning
fromcrowds,”inProceedingsoftheInternationalConferenceonLearningRepresentations,2019.
[47] L. Zhang, R. Tanno, M.-C. Xu, C. Jin, J. Jacob, O. Cicarrelli, F. Barkhof, and D. Alexander, “Disen-
tangling human error from ground truth in segmentation of medical images,” in Advances in Neural
InformationProcessingSystems,vol.33,2020,pp.15750–15762.
[48] H. Guo, B. Wang, and G. Yi, “Label correction of crowdsourced noisy annotations with an instance-
dependentnoisetransitionmodel,”AdvancesinNeuralInformationProcessingSystems,vol.36,pp.347–
386,2023.
[49] J. Ok, S. Oh, Y. Jang, J. Shin, and Y. Yi, “Iterative bayesian learning for crowdsourced regression,” in
Proceedings of the International Conference on Artificial Intelligence and Statistics, vol. 89, 2019, pp. 1486–
1495.
[50] X. Chen, P. N. Bennett, K. Collins-Thompson, and E. Horvitz, “Pairwise ranking aggregation in a
crowdsourcedsetting,”inProceedingsoftheACMInternationalConferenceonWebSearchandDataMining,
2013,p.193–202.
[51] R.Rafailov,A.Sharma,E.Mitchell,C.D.Manning,S.Ermon,andC.Finn,“Directpreferenceoptimiza-
tion: Your language model is secretly a reward model,” in Advances in Neural Information Processing
Systems,vol.36,2023,pp.53728–53741.
29[52] T. Nguyen, S. Ibrahim, and X. Fu, “Deep clustering with incomplete noisy pairwise annotations: A
geometricregularizationapproach,” inInternationalConferenceonMachineLearning, 2023, pp.25980–
26007.
[53] S.Lazier,S.Thirumuruganathan,andH.Anahideh,“Fairnessandbiasintruthdiscoveryalgorithms:
Anexperimentalanalysis,”arXivpreprintarXiv:2304.12573,2023.
[54] N.GoelandB.Faltings,“Crowdsourcingwithfairness,diversityandbudgetconstraints,”inProceed-
ingsofthe2019AAAI/ACMConferenceonAI,Ethics,andSociety,2019,pp.297–304.
[55] V. C. Raykar and S. Yu, “Eliminating spammers and ranking annotators for crowdsourced labeling
tasks,”JournalofMachineLearningResearch,vol.13,no.16,pp.491–518,2012.
[56] Q. Ma and A. Olshevsky, “Adversarial crowdsourcing through robust rank-one matrix completion,”
inAdvancesinNeuralInformationProcessingSystems,vol.33,2020,pp.21841–21852.
[57] P.A.TraganitisandG.B.Giannakis, “Detectingadversariesincrowdsourcing,” inIEEEInternational
ConferenceonDataMining,2021,pp.1373–1378.
[58] P. Chen, H. Sun, Y. Yang, and Z. Chen, “Adversarial learning from crowds,” Proceedings of the AAAI
ConferenceonArtificialIntelligence,vol.36,no.5,pp.5304–5312,2022.
[59] T.Kaufmann,P.Weng,V.Bengs,andE.Hu¨llermeier,“Asurveyofreinforcementlearningfromhuman
feedback,”arXivpreprintarXiv:2312.14925,2023.
[60] D. Chhan, E. Novoseller, and V. J. Lawhern, “Crowd-prefrl: Preference-based reward learning from
crowds,”arXivpreprintarXiv:2401.10941,2024.
[61] P.A.Traganitis,D.Berberidis,andG.B.Giannakis,“Activelearningwithunsupervisedensemblesof
classifiers,” in IEEE International Conference on Acoustics, Speech and Signal Processing, 2020, pp. 3967–
3971.
[62] A.RangiandM.Franceschetti,“Multi-armedbanditalgorithmsforcrowdsourcingsystemswithon-
lineestimationofworkers’ability,”inProceedingsoftheInternationalConferenceonAutonomousAgents
andMultiAgentSystems,2018,p.1345–1352.
[63] K.Mo,E.Zhong,andQ.Yang,“Cross-taskcrowdsourcing,”inProceedingsoftheACMSIGKDDInter-
nationalConferenceonKnowledgeDiscoveryandDataMining,2013,p.677–685.
[64] G.Han, J.Tu, G.Yu, J.Wang, andC.Domeniconi, “Crowdsourcingwithmultiple-sourceknowledge
transfer,”inProceedingsoftheInternationalJointConferenceonArtificialIntelligence,72020,pp.2908–2914.
30