Microsoft cloud-based digitization workflow with
rich metadata acquisition for cultural heritage
objects
Krzysztof Kutt1*, Jakub Gomu(cid:32)lka2, Luiz do Valle Miranda1,
Grzegorz J. Nalepa1
1Jagiellonian Human-Centered AI Lab, Mark Kac Center for Complex
Systems Research, Institute of Applied Computer Science, Faculty of
Physics, Astronomy and Applied Computer Science, Jagiellonian
University, prof. Stanis(cid:32)lawa L(cid:32) ojasiewicza 11, 30-348, Krak´ow, Poland.
2Faculty of Humanities, AGH University of Krakow, Czarnowiejska 36,
30-054, Krak´ow, Poland.
*Corresponding author(s). E-mail(s): krzysztof.kutt@uj.edu.pl;
Contributing authors: jgomulka@agh.edu.pl;
luiz.dovallemiranda@doctoral.uj.edu.pl; gjn@gjn.re;
Abstract
In response to several cultural heritage initiatives at the Jagiellonian Univer-
sity, we have developed a new digitization workflow in collaboration with the
Jagiellonian Library (JL). The solution is based on easy-to-access technological
solutions—Microsoft365cloudwithMSExcelfilesasmetadataacquisitioninter-
faces, Office Script for validation, and MS Sharepoint for storage—that allows
metadata acquisition by domain experts (philologists, historians, philosophers,
librarians, archivists, curators, etc.) regardless of their experience with informa-
tionsystems.Theultimategoalistocreateaknowledgegraphthatdescribesthe
analyzedholdings,linkedtogeneralknowledgebases,aswellastoothercultural
heritagecollections,socarefulattentionispaidtothehighaccuracyofmetadata
and proper links to external sources. The workflow has already been evaluated
in two pilots in the DiHeLib project focused on digitizing the so-called “Berlin
Collection” and in two workshops with international guests, which allowed for
its refinement and confirmation of its correctness and usability for JL. As the
proposedworkflowdoesnotinterferewithexistingsystemsordomainguidelines
regarding digitization and basic metadata collection in a given institution (e.g.,
file type, image quality, use of Dublin Core/MARC-21), but extends them in
1
4202
luJ
9
]LD.sc[
1v27960.7042:viXraordertoenablerichmetadatacollection,notpreviouslypossible,webelievethat
itcouldbeofinteresttoallGLAMs(galleries,libraries,archives,andmuseums).
Keywords:Culturalheritage,Metadata,Knowledgegraphs,GLAM,Digitization,
Spreadsheets,Microsoft365
1 Introduction and motivation
JagiellonianUniversity(JU),theoldestPolishuniversityandoneoftheoldestuniver-
sitiesincontinuousoperationintheworld,holdsinitscollectionsanumberofcultural
heritage objects, including medieval manuscripts, social life documents representing
a wide range of historical periods, memorabilia of former employees and students of
the university, and a collection of authentic relics from the circle of ancient Mediter-
ranean cultures. These collections have attracted greater research interest recently
due to large cultural heritage initiatives at the JU, particularly the so-called flagship
projects(FPs)1 aimedatinterdisciplinaryandinternationalcooperationtoenrichthe
JU’s research ecosystem. Five of the 21 FPs are focused on cultural heritage research,
including digitization, standardization of descriptions, integration of collections, and
more detailed studies of selected items (cf. Sect. 3).
As a team of computer scientists and knowledge engineers, we are actively col-
laborating with these cultural heritage initiatives to assist researchers—philologists,
historians, philosophers, librarians, archivists, curators, etc.—by developing proper
tools for metadata acquisition during the digitization process, which will ultimately
lead to the creation of knowledge base(s) that describe the collections under analysis.
With this in mind, we decided to take advantage of knowledge graphs [10] and
ground the entire solution in the Semantic Web technologies [9] and the linked data
approach [8, 12]. Adopting this approach will allow for the explicit definition of the
meaning of individual metadata, the preservation of a flexible data model that can be
easilyadaptedtotheneedsofindividualcollectionsorresearchobjectives,theefficient
integration of data across disciplines and organizations, and will facilitate future data
processing in automated systems [15].
Duringthedevelopmentofmetadataacquisitiontools,anumberofchallengesand
requirements had to be addressed, among which the most important were the tight
time frame for tool development, the lack of resources to develop dedicated software,
theneedtousetoolsthatareasfamiliarandaccessibleaspossibletodomainexperts,
andthescalabilityofthesolutiontocollectionswithhundredsofthousandsofobjects.
Takingintoaccountallofthese,wedecidedtobasethesolutiononMicrosoft365cloud
and use Microsoft Excel spreadsheets as an interface for metadata collection, Office
Script to facilitate the use of the spreadsheets, Python scripts for initial metadata
validation, and dedicated space in Microsoft Sharepoint for data storage. The whole
solution is complemented by a dedicated workflow based on the developed tools.
1Seehttps://id.uj.edu.pl/enGB/projekty-flagoweformoredetails.
2The original contribution of the paper is the idea of a digitization workflow, based
oneasy-to-accesstechnologicalsolutions(Microsoft365cloud),thatallowsrichmeta-
data acquisition by domain experts regardless of their experience with information
systems. The proposed solution does not interfere with existing systems or domain
guidelines regarding digitization and basic metadata collection in a given institution
(e.g., file type, image quality, use of Dublin Core/MARC-21), but extends them in
ordertoenablerichmetadatacollection,notpreviouslypossible.Therefore,webelieve
thatitcouldbeofinteresttoallGLAMs(galleries,libraries,archives,andmuseums).
WhiletheuseofExcelformetadatacollectionisquitecommon,basingtheentiredig-
itization workflow on Microsoft 365 cloud to the best of our knowledge has not been
described before.
The remainder of the paper is structured as follows. The related work is sum-
marized in Sect. 2. Sect. 3 introduces cultural heritage collections and digitization
projectsatJagiellonianUniversity.Therequirementsfortheentireworkflowarelisted
in Sect. 4. The tools used in the proposed solution are outlined in Sect. 5, while the
actual digitization workflow is described in Sect. 6. Sect. 7 concludes the paper.
2 Related work
Harnessing the power of Semantic Web technology to integrate disparate cultural
heritage(knowledge)basesrequireswell-thought-outsharedvocabulariesorontologies.
These shared resources establish common terminologies and relationships, facilitating
interoperability and enhancing the effectiveness of data exchange and comprehension
among disparate institutions. The two basic vocabularies are MARC-21, traditionally
used in cataloging systems, and Dublin Core, traditionally used in digital libraries.
However,theyonlyallowforabasicdescriptionincludingtitle,author,yearandplace
of creation, or access rights. More detailed metadata requires additional vocabularies
or ontologies. Therefore, similar projects should be evaluated to determine whether
they use vocabularies that can be adapted tothe needs of the institution or collection
under question.
OnesuchprojectistheOntoBelliniLettersontologyoftheBellinianoCivicMuseum
of Catania. Drawing on the main experience in this project, Cristofaro and Spamp-
inato [3] report on the main concepts and relations used to develop the ontology
“concerning the semantic organization of the corpus of Vincenzo Bellini’s correspon-
dence letters” (p. 192). This ontology is inspired by CIDOC CRM, a conceptual
framework and vocabulary for describing the relationships between cultural heritage
objects, events, actors, and their contexts in a structured and interoperable way.
Another project worth mentioning is the attempt at digitization of cultural her-
itage resources in the German state of Brandenburg. Preuss [21] reports on some
challenges of such an undertaking, including the variety of institutions containing rel-
evant collections: 80 archives, 140 libraries, and 150 museums. A significant goal of
such a project is the integration with European-wide portals, including Europeana
andKalliope.Cooperationplaysacrucialroleinaddressingthesechallenges,allowing
thepoolingofresourcesandexpertiseacrossthesediverseinstitutions.Throughcoop-
erative efforts, Brandenburg aims not only to digitize its cultural heritage, but also
3to seamlessly integrate it into larger European frameworks, fostering greater acces-
sibility and appreciation of its rich historical and cultural legacy on a global scale.
Both the targeted portals and the cooperative nature are inspirations for the projects
undertaken currently at the Jagiellonian University.
The presentation of the related project already points out to target platforms for
integration and shared vocabularies that would allow such integration. An instance
of a standard for metadata representation is CIDOC CRM. The widespread use of
CIDOCCRManditsfoundationalroleinthedevelopmentofontologiesforspecificuse
cases within given institutions make it an essential conceptual framework to consider
while developing any cultural heritage-related ontology. The fundamental category in
Voice knowledge acquisition system for the management of cultural heritage 47
CIDOC CRM is event. This event-centric approach offers expressiveness by capturing
the cultural context through human actions, flexibility by allowing for dynamic and
detailedrecords,andprecisionbyenablingtherepresentationofhistoricalprocessesas
documentable units, simplifying time processing and enhancing visualization (cf. [7]).
Fig. 1 shows a graphical example of the representation of a sculpture according to
CIDOC CRM.
E41 Appellation
E31 document
E21 person
La Renommée E55 type
Image.jpg
Pierre Biard has type
sculptor
Is documented in
is identified by
was created by
E22 man-made
object was produced by E E1 v2 e nP troduction E53 Place
Statue took place at
Statue
Paris
consists of
has type
moved
had at most duration
E55 type
E57 material
ssculpture E52 time-Span
bronze
E9 Move
1st quarter of
Paris 17th century
has time-span
moved to moved from
E52 Time-Span
E53 place E53 place
1834
Louvre city hallBordeaux
Fig. 1 ExampleofasculpturemodelinginCIDOC-CRM[2].
A target platform for integration with the data contained in the Jagiellonian
LibraryisKalliope.Kalliopeisanonlinecatalogforpersonalpapers,manuscripts,and
Fig. 3 Example of a sculpture modeling in CIDO4C-CRM.
The evolution from the model defined by the inventory descriptive system to
the CIDOC-CRM ontology is possible by the search for the correspondences be-
tween the fields of the descriptive system, in which the content be considered as
the instance of one of the classes of the CRM ontology.
For the cases, in which this correspondence could not be found because the in-
formation does not exist in the descriptive system, it will be necessary to extract it
from the re-transcribed text, under the condition that the speaker registered it.
Otherwise it will be necessary to enter it during the validation of the information
extracted automatically by the system.
4 Conclusion and perspectives
This paper presents our work on a voice assistant for knowledge acquisition in
the domain of cultural heritage. The originality of our system is the link between
three distinctive research domains such as signal processing, ontology and natural
language processing. We experimented on field voice knowledge acquisition,
“translation” of voice into a text file, the work on text files in order to extract the
relative concepts and relation between them in semiautomatic way. The voice in-
terface provides a considerable help and efficiency for an expert working in thepublishers’archivesthatintegratesmetadatafrominstitutionsallaroundtheGerman-
speakingcountries.Standardizeddatafrompartnerinstitutionscanbemadeavailable
for retrieval in Kalliope given compliance with the Encoded Archival Description
(EAD) format. The EAD is an international XML-based standard for the descrip-
tionandexchangeofarchivaldata.EADpossessesahierarchicalstructureandmakes
it possible to describe the relation between wholes and parts in a collection. EAD
contains elements for persons, families, places, and corporate bodies, these elements
allowreferencestouniqueidentifiersforsuchindividuals.Kalliopeutilizeslinkstothe
Integrated Authority File (Gemeinsame Normdatei, GND) of the German National
Library to identify individuals. Fig. 2 shows an example of data encoded according to
the EAD schema.
Fig. 2 EAD example as presented in the official Kalliope documentation (adapted from https://
kalliope-verbund.info/files/6560c72ae631ecfac4c60d06dde2f57a1b57ceb3.xml).
Finally, another portal with which collaboration is desired is Europeana. It is a
digital cultural platform that integrates resources from more than 3000 institutions
concerningEuropeanculturalheritage.Europeana’smetadatarepresentationisbased
on the native Europeana Data Model (EDM). Three fundamental distinctive classes
in EDM are the provided cultural heritage object (represented as edm:ProvidedCHO),
the digital representation of the object (edm:WebResource), and the aggregation as a
representation of the link between the former and the latter (ore:Aggregation). An
example of an EDM representation of the Mona Lisa painting is presented in Fig. 3.
Besides inspiration on vocabulary as linking targets, similar digital cultural her-
itage projects also show tools for the entry of metadata by domain experts. Kim,
Nakamura,andWatanave[17]presenttwosystemsformanagingmetadatainprojects
related to digital archives: Archivematica and Omeka S. Archivematica is an open-
source digital preservation system designed to automate the process of ingesting,
5Fig. 3 ProvideraggregationwithdescriptivemetadatainEuropeanaDataModel[13].
preserving, and providing access to digital archives. It is specifically tailored for the
long-term preservation of digital materials, including documents, images, audio, and
videofiles,amongothers.OmekaSspecializesinprovidingauser-friendlyplatformfor
creatingandcuratingdigitalexhibitsandcollections.OneofthekeyfeaturesofOmeka
Sisitsflexibilityandextensibility,allowinguserstocustomizemetadataschemasand
data entry forms to suit the unique needs of their projects. Furthermore, Omeka S
facilitates collaborative metadata entry by supporting multi-user access and workflow
management features. This enables domain experts and curatorial teams to collabo-
rate effectively in cataloging and annotating digital materials, ensuring accuracy and
consistency in metadata representation.
Despite the existence of such specialized software for the management of cultural
heritage data, a popular option remains the use of more general Microsoft Excel.
Jan [14] reports on the use of Excel in a case study of the investigation and man-
agement of community heritage resources. Spreadsheets were used to input details
of heritage resources, encompassing site identifiers, titles, spatial representations,
city identifiers, and descriptions. The collected metadata attempted to follow some
interoperable schemas, including CIDOC CRM.
Utilizing Excel spreadsheets for metadata collection offers the benefit of a user-
friendly interface, reducing the learning curve for participants. This advantage is
particularly valuable in projects lacking designated domain experts, where individ-
uals are enlisted on an ad hoc basis for specific tasks as they arise during project
execution. In such scenarios, the familiarity of Excel’s interface enhances efficiency by
enabling quick adaptation and seamless participation, even among those with varied
levels of technical expertise. One way shown by Jan [14] to ensure and enhance the
quality of data entered in spreadsheets is by using Python scripts to extract, validate
and integrate it with other resources such as ontologies, or another type of shared
vocabularies.
Finally,Kovalenko,SerralandBiffl’s[19]discussionoftoolsforontologypopulation
using spreadsheet data already shows some evaluated alternatives to the transforma-
tion of the collected metadata. In a more recent approach, Denisova, Dorodnykh and
Yurin[4]presenttheOntoGentoolforcreatingontologiesbytransformingspreadsheet
6data. Another tool worth mentioning is Owlready, a Python package that provides
convenient manipulation and population of OWL ontologies (cf. [20]).
This brief overview of related projects begins to outline a workflow for managing
digital cultural heritage at Jagiellonian University: domain experts gather metadata
across various fields and input it into Excel spreadsheets. Python scripts are then
employed to both validate the metadata and populate an ontology. This ontology is
designed to be interoperable with Kalliope, Europeana, and CIDOC CRM. Before
delving into the detailed explanation of this workflow in Sect. 4-??, it is valuable to
examine the current cultural heritage landscape at Jagiellonian University.
3 Cultural heritage collections and digitization
landscape at Jagiellonian University
From the point of view of cultural heritage collections, the Jagiellonian Library (JL)
shouldbeconsideredacentralpartoftheJagiellonianUniversity.Althoughitwasnot
founded together with the University in 1364, the Library is a successor to various
university libraries and collections that have existed since the 15th century. For many
years, it also played the role of a national library, the so-called bibliotheca patria [1].
Now,JLholds6,564,628items2 initscollections(notincludingitemsstoredinfaculty
libraries), with many cultural heritage treasures including 11th century documents,
collection of incunabula or Dutch, Italian and French engravings [1].
One of the most notable collections in the holdings of the Jagiellonian Library is
the so-called “Berlin Collection” (affectionately termed “Berlinka” in Polish). It is a
collection of over 500,000 historical documents that, before the end of World War II,
belonged to the Prussian State Library (now State Library of Berlin) but is currently
heldbytheJagiellonianLibrary(foradetailedhistoryofthecollection,see[16]).The
Autograph Collection, a premier segment of the Berlin Collection, is an assembly of
unique manuscript materials from the 15th to the 20th century. It comprises approx-
imately 300,000 autographs, including letters from Martin Luther, Johann Wolfgang
von Goethe, Georg Wilhelm Friedrich Hegel, Heinrich von Kleist, Jacob and Wil-
helm Grimm, Alexander and Wilhelm von Humboldt, Marie Antoinette, and many
other poets, scientists, royals, statesmen, and philosophers. The collection not only
exhibits the activity of particular authors, but also gives insight into the intellectual
exchangesanddevelopmentofculturalandideologicalmovementsinGermanyandin
the whole Europe. The documents within the collection were already organized: they
were divided into units associated with individual persons. Unit shelfmarks, assigned
by Berlin librarians, are the names of these individuals preceded by the designa-
tion“SA,”(Sammlung Autographa)forexample,“SA,Keppler,Johannes”.Thereare
about30,000units withintheAutograph Collection;thesizesofindividualunits vary
greatly;someareextensiveandconsistofhundredsofdocuments,whileotherscontain
only a few, sometimes even just one.
Jagiellonian University’s heritage collections are also spread in many places out-
side the Jagiellonian Library. For example, documents and photos of university staff
2For official numbers, see: https://bj.uj.edu.pl/enGB/about-the-library/
mission-history-and-collections/collections/jagiellonian-university-library-system-holdings-in-numbers.
7and students are kept in the JU Archive, the JU Museum keeps a collection of mem-
orabilia, the mediterranean and prehistoric archaeological collections are kept at the
JU Institute of Archaeology [25]. There are also the photo collection of the Institute
ofArtHistory,theIgnacyJanPaderewskiCenterfortheDocumentationof19th-and
20th-century Polish Music, and many other collections [26].
Most of the aforementioned cultural heritage objects have not yet been digitized.
To illustrate, JL has digitized and made available to the public 830,887 objects.
Considering the special collections alone—that is, excluding collections of books and
periodicals, many of which cannot be digitized due to legal restrictions—comprising
2,296,930objects,thismeansthatmorethan60percentofthecollectionsarestillnot
digitized.
Thesecollectionshaveattractedgreaterresearchinterestrecentlyduetolargecul-
tural heritage initiatives at the JU, particularly the so-called flagship projects (FPs)3
aimed at interdisciplinary and international cooperation to enrich the JU’s research
ecosystem.Fiveofthe21FPsarefocusedonculturalheritageresearch,includingdig-
itization,standardizationofdescriptions,integrationofcollections,andmoredetailed
studies of selected items (cf. Sect. 3).
However, it should be emphasized that significant initiatives for cultural heritage
are currently underway at the Jagiellonian University. The Jagiellonian Center for
DigitalHumanitieshasbeenestablished,and5ofthe21flagshipprojects(seeSect.1)
cover topics related to the digitization of cultural heritage objects:
1. Mare Nostrum Lab (https://mare.id.uj.edu.pl/en GB/) is aimed at the research
related to the cultural heritage of Mediterranean societies.
2. Digital Humanities Lab (https://dhlab.id.uj.edu.pl/en GB/) goal is to provide a
stable and standardized digital editing platform for all JU scholars and students.
3. European Heritage in the Jagiellonian Library: Digital Authoring of the Berlin
Collections (DiHeLib) (https://dihelib.id.uj.edu.pl/en GB/) aims at cataloging,
digitizing, sharing, and conducting research on the Autograph Collection of the
“Berlinka” [23].
4. CulturalHeritageExplorationandRetrievalwithIntelligentSystemsatJagiellonian
University (CHExRISH) will provide a solution for combining a variety of JU col-
lectionsorientedaroundtheuniversity’shistoryinaunifiedinterfacewithSemantic
Web technologies.
5. Critical Heritage Studies Hub (CHSH) (https://crihestu.id.uj.edu.pl/en GB/) is
not aimed at digitization, but among its goals is the creation of thesauri in SKOS
(Simple Knowledge Organization System) format for cultural heritage collections.
Thepresentedculturalheritagelandscapeisaccompaniedbyvarioussystemsused
to store metadata about objects:
1. JL uses the Alma interlibrary catalog (https://katalogi.uj.edu.pl/), which stores
data in MARC 21 format, and the Jagiellonian Digital Library (https://jbc.bj.uj.
edu.pl/) based on the dLibra system, which stores PDFs and metadata in Dublin
Core format.
3Seehttps://id.uj.edu.pl/enGB/projekty-flagoweformoredetails.
82. TheJUMuseumstoresdescriptionsofmanyartifactscollectedbyvariousuniversity
units in the MuzUJ system (https://muzuj.uj.edu.pl/). This metadata is richer
than the basic MARC 21/Dublin Core description, but is not based on shared
vocabularies or ontologies. Currently, the MuzUJ system does not have a public
interface–interestedpersonssendarequesttoMuseumstaff,whoperformsearches
in the system.
3. There are also many other small systems and databases that store information
about individual collections, for example, the photo collection of the Institute of
Art History is presented in http://www.fototeka.ihs.uj.edu.pl/.
4 Objectives and requirements
Our ultimate goal is to create a knowledge base that adheres to FAIR princi-
ples[24],thatislinkedtogeneralknowledgebases—suchasWikidata[5],Geonames4,
and YAGO [22]—as well as to other cultural heritage bases—including the pan-
European Europeana project [6] and bases describing the specific collections, e.g., the
Kalliope catalog5 of approximately 600,000 records from 950 institutions located in
German-speakingcountries—andthatwillenableandfacilitateawiderangeofdigital
humanities research, including tasks done or supported by artificial intelligence tools.
AshighlightedintheIntroduction,theobjectiveoftheworkreportedinthispaper
was to develop tools for metadata acquisition—which as part of further work will be
usedtobuildaknowledgegraph—bydomainexpertsandtocombinethemwithexist-
ing systems and tools (described in Sect. 3) into a unified digitization workflow for
cultural heritage collections. From the very beginning, the Berlin Collection analyzed
intheDiHeLibproject(seeSect.3)waschosenastheplaygroundforthework.There-
fore,ourresearchconcernspracticalchallengesofmassivedigitization(approximately
300,000 documents) of manuscripts of immense historical value for the purpose of a
digital library.
The workflow needed to reach a balance between the two contradictory require-
ments: on one hand, it had to guarantee the high quality of metadata gathered by
the domain experts; on the other, it should allow for relatively quick data collection
andprocessingtoensurethatthedigitizationprocessprogressessmoothlyandcanbe
completed within a reasonable time frame.
The work on the prototypes was done in an iterative manner, allowing the needs,
requirements, and limitations to be determined on an ongoing basis. Among the most
important of these were:
1. Tight time frame for tool development – four months were allocated for this task
in the DiHeLib project,
2. Need for using tools that are as familiar as possible and/or easily accessible to
domain experts – i.e., typical office tools; due to the digital exclusion of some
members of the research team, it was not possible to propose more complex
solutions,
3. Lackofhumanandfinancialresourcesintheprojecttodevelopdedicatedsoftware,
4https://www.geonames.org/.
5https://kalliope-verbund.info/en/.
94. Lack of dedicated infrastructure to operate and maintain the tools,
5. Preference for a web-based solution because domain experts use their private lap-
tops, so we have no control over hardware and software setup, and can only force
them to use a specific web browser.
5 Methods and tools
Taking into account all the goals, requirements, and limitations outlined in Sect. 4,
we decided to use a generic tool such as a spreadsheet and develop a solution in the
Microsoft 365 cloud, which is familiar to JU employees from their daily work. To
reduce the risk of errors and make such a tool easier to use, it was decided to develop
a number of Office Script and Python scripts. The whole is combined into a workflow
(see Sect. 6) that uses the dedicated folder structure in Microsoft Sharepoint. More
specifically, the developed solution consists of the following:
1. The Knowledge Matrix (TKM) – an MS Excel file (see Sect. 5.1),
2. Standard Entries Catalog (SEC) – a set of 4 MS Excel files (see Sect. 5.1),
3. The Mapping system (MAP) – a sheet in TKM file for mapping between specific
pages and actual scans (see Sect. 5.1),
4. Office Script that handles the buttons in TKM and performs initial validation (see
Sect. 5.2),
5. Office Script to assist in adding new SEC records,
6. A set of Python scripts performing more detailed validation of metadata entered
into the TCM and SEC (see Sect. 5.2),
7. A set of documents including: a description of the workflow, instructions for using
TKM and SEC, a file for reporting errors and comments by domain experts.
5.1 Designing TKM, SEC, and MAP
TheExcel-basedformforenteringdocumentmetadataisthekeyDiHeLibdatastruc-
ture. First, it was assumed that each unit (see Sect. 3) would correspond to one file,
in which one of the sheets would be a metric containing the description of a unit as
a whole (see Fig. 4), and the other would be used to collect metadata of individual
documents represented by subsequent rows (see Fig. 5). In turn, columns of the lat-
ter sheet would represent successive fields in the document description. Thus, The
Knowledge Matrix emerged. It was decided that each document would be classified
into one of nine categories, a decision that determines the assignment of a particular
set of fields to it. The list is a slightly modified version of the scheme used for the
Varnhagen Collection [18] and comprises the following categories:
1. Portraits, images, and drawings,
2. Outgoing correspondence,
3. Creative works (literary and other),
4. Personal materials,
5. Historical materials, diplomas,
6. Printed materials and press clippings,
7. Incoming correspondence,
108. Foreign materials (notes about individuals, various letters),
9. Library materials (covers, bookmarks, historical catalog cards).
Fig. 4 Metric sheet of the TKM containing general information of the whole unit (in Polish), i.e.,
the metadata that will be converted to MARC 21 format to create records in library catalog (title,
cardnumber,format,etc).
Some basic fields are ascribed to all document types, e.g., “what is it / docu-
ment title”, while other are associated with particular categories, e.g., “sender” and
“recipient”areassignedtocorrespondence(categories2and7),“issuer”isassignedto
official documents (categories 4 and 5), and “author” to creative works (category 3).
The description fields were further divided into mandatory (as “document number”)
andoptional(as“dateremarks”).Detailedcontentrestrictionswereimposedonsome
of the fields, e.g., “date” field could only accept one of the specified date formats.
The most important from the validation point of view (see Sect. 5.2) is “document
number” filled with a string in format x.y, where x is a digit of encoding document
category of 1 to 9, and y is a sequential number of a document within a unit.
During subsequent iterations, the need for separate acquisition of person- and
place-related metadata appeared. The problem arose from the fact that numerous
individuals (or geographical names) were referred to in the documents under various
different names, stemming from the different spellings of the same surnames in differ-
ent languages or the fact that a person (or institution) might have assumed different
names at different stages of their life. This need led to the creation of the Standard
Entries Catalog. The SEC consists of four Excel files. Two of them are the parts of
the actual catalog, presenting information about persons (see Fig. 6) and locations,
respectively. Only the SEC coordinator is able to enter new data or modify existing
11Fig. 5 Main sheet of the TKM with one row per document in a given unit (in Polish). One can
see the result of the Office Script (errors marked with red color, fields not used in a given category
markedwithgraybackground)andthe“OK?”buttonthattriggersthescript.
entries, while other experts have read-only access. The other two files serve as collec-
tors of proposals from domain experts: they can write suggestions of new entries or
extendingormodifyingtheexistingentriesinbothmainSECfiles.TheTKMrecords
linktospecificSECentriesbyprovidingtheSECIDinadedicatedcolumn.TheSEC
records are linked to external databases by providing URLs (e.g. Geonames URLs for
geographic names).
Finally,whentheTKMfileisfinished,thevalidationscript(seeSect.5.2)extends
it automatically with a MAP sheet designed to store bindings between unit’s card
numbers and their scans. A single page may sometimes require more than just two
scans(oneforitsrecto,anotherforitsversoside).Theremaybeoneormorepaste-in
slips attached to the page that require separate scanning. A telling example of this
problemisoneofthepagesfromAlexandervonHumboldt’sKosmosmanuscriptwhose
scanning produced as many as 14 different files (see pp. 62-75 in [11]). Therefore,
to enable linking particular documents with their scans, a system of mapping card
numbers to scan files—done manually by librarians in a separate MAP sheet—and
mapping units with their documents to specific folder in a folder tree where the files
are stored was introduced.
5.2 Data validation scripts
Dataenteredthroughinterfaces(Excelfiles)mustbeevaluatedtoensurethequalityof
the metadata is as high as possible. Two programs that perform data validation have
been developed for this purpose: 1) on the fly, as they are entered by the researcher
12Fig. 6 SECsheetwithperson-relatedmetadata(inPolish).
into the TKM sheet (via an Office Script), and 2) after the sheet has been filled out
completely – in this case, a full analysis is possible, which is technically impossible to
perform at the Excel online script level (via a set of Python scripts). In both cases,
the syntax of the input data and its completeness are analyzed. Program 2 addition-
ally performs limited semantic validation including, but not limited to: verification
whether the Author’s life span is not greater than 110 years, whether the entered
dates actually existed in the calendar, whether the entered SEC IDs indeed exist in
the SEC and correspond to the specified person/place. Feedback is provided to users
throughappropriatemessagesinadedicatedcolumnAandcellbackgroundcolors(in
Program 1) and in the form of a report in a PDF file (in Program 2).
Both programs were dedicated to data validation, however, during the course of
work, their scope of operation was extended with additional functionalities resulting
from the current needs of the Project:
1. Forcing the process of filling out the TKM (the metric is filled out first, and then
the main sheet);
2. Blocking fields unavailable for a given category of document (e.g., blocking of the
“sender” field for documents in the “Portraits, images, and drawings” category) in
order to facilitate the work of users;
3. Updating the TKM with new columns and fields, performed by Program 1 (e.g.
addingnewfieldsthatwerenotprovidedforearlier;thescriptperformsthischange
without the need for additional user intervention);
4. ValidationofSECentriesbyProgram2(anindependentreportisgenerated,visible
to the SEC coordinator).
13For Program 2, a dedicated virtual server on the JU infrastructure was set up and
configuredtoperformasynchronizationwithSharepointonceaday,runthevalidation
scripts, and perform the synchronization again to propagate the validation reports.
6 Digitization workflow in practice
Data entry and validation are only the initial steps in an overall metadata acquisition
process for digitization integrated with BJ’s procedures. Working closely with JL,
through a series of iterations, existing processes at JL were first identified, and then
a new complete process was developed using Excel input interfaces, the Microsoft
365 cloud, and JL’s existing infrastructure. Importantly, the process was subjected to
practical evaluation through two pilots and two workshops with international guests,
which allowed for its improvement, and confirmation of its correctness and usability
for JL.
Designing, organizing, and implementing the workflow process, and consequently
its implementation in practice, was a major organizational challenge due to three key
factors. Firstly, it included the activities of three different groups of people, partly
working in different places, with different levels of IT competences, using different
IT tools on a daily basis and coming from different work and organizational cul-
tures: domain experts – humanities researchers, computer scientists – researchers,
academicteachers,doctoralstudentsandpractitioners,andlibraryworkers.Addition-
ally, the last of the mentioned groups was also highly differentiated internally. They
included librarians specializing in working with manuscripts, as well as a library sys-
tem administrator, a person specializing in publishing objects in a digital library, a
personoperatingascannerandanITspecialistresponsibleforthelocalnetworkand,
to some extent, servers. Secondly, the workflow was to be fed with different resources
at different times: on the one hand, original manuscripts that require special protec-
tion and security procedures, and on the other hand, two types of digital documents:
Excelfilesfilledwithmetadataandscansofthemanuscripts.Thirdly,theJagiellonian
Library did not have a ready-made tool capable of comprehensively handling such a
workflow. As indicated earlier, it was decided to use the Sharepoint platform offered
in the cloud version of MS Office available to all University employees, but also to a
certain extent the Alma library system and folder structures opened for this purpose
on a dedicated server NAS (Network Attached Storage), as well as a paper register to
control the transfer of original documents.
Tocopewiththesechallenges,itwasdecidedtoadoptaniterativesolution,allow-
ing for gradual solving of problems and getting closer to a production version that
is understandable and acceptable to all stakeholders. The key points were two pilots
carried out in 2023, but due to the complexity of the task, it was assumed that the
firstperiodaftertheimplementationoftheentireprocesswouldalsobetreatedasthe
next stage of development and refinement of the workflow.
Inpractice,itturnedoutthatinthefirstperiodafterimplementation,abundleof
threeparallelpathsofdifferentlengthswasdefactoformed,connectingwitheachother
atspecificpoints(whichispresentedinasimplifiedandsyntheticwayinFig.7).Path
“A” refers to the handling of original manuscripts, the transfer of which is controlled
14B
Downloading
blank forms
A
Introducing
Taking manuscripts
metadata
out of their
storage place
Inspecting,
Conservation
correcting and
assessment and
validating
simple repairs
Creating batches
Transferring selected
C
metadata to ALMA
Transferring
manuscripts for Scanning
scanning
Mapping metadata
files with scans Saving scans in a
Returning
folder structure on
manuscripts to
a NAS server
their storage place
Archiving
metadata files
Fig. 7 Thedigitzationworkflowinpractice.
analogously using paper documentation containing signatures confirming the transfer
and receipt of objects by the people involved. Path “B” is the main axis of the entire
project – it refers to the “life” of Excel files and intended for collecting and storing
(atthisstageoftheproject)metadatadescribingindividualmanuscripts.Thispathis
implementedentirelyinthedigitalenvironmentwithinthestructureoffolderscreated
on a dedicated Sharepoint website. The bundle is completed by path “C”, which
includes activities related to the scanning process and is closely related to both paths
mentioned above.
It was assumed that the entire process would be continuous and systematic, and
that the workload at its individual points would be adjusted so that the flow would
be smooth, and the workload of individual people involved in the process would be
more or less constant. However, it turned out that in practice a different solution was
developed, perhaps more effective from the point of view of using the resources of the
JagiellonianLibrary.Currently,workisperformedpartlyina“batchmode”.Theflow
is paused at the place marked in Fig. 7 as “Creating batches”, a larger number of
finallyacceptedfileswithmetadataarecollectedandonlysucha“batch”isprocessed
further.Itisthenprocessedasoneaction,afterwhichworkinthispartoftheworkflow
15is suspended and waiting for the next “batch”. At the same time, in the first part of
the workflow, which refers to the creation of metadata, work progresses continuously.
Atthisstage,itisnecessarytoperformanalyzesandmakedecisionsregardingthe
direction of further development of the workflow. Should the resources used be opti-
mized in such a way as to achieve the previously assumed continuity of work within
theentireworkflow?Orshouldweadoptahybridsolutioninwhichmetadatacreation
is carried out continuously and the scanning “factory” operates in a cyclical mode
based on periodically processed larger “batches” and the second part of the work-
flow, work organization and resources involved should be adapted to such a solution?
However, such a decision must be made considering the broader context of the Jagiel-
lonianLibrary’soperationanditscurrentandfutureinvolvementinotherdigitization
projects.
7 Conclusions and future work
When joining as a group of knowledge engineers and computer scientists in cultural
heritageinitiativesattheJagiellonianUniversity,wehituponthechallengeofprepar-
ing tools to collect metadata in a short period of time, with very limited human and
financial resources and for a group of domain experts, some of whom are digitally
excluded. It was important to ensure the scalability of the solution to hundreds of
thousands of manuscripts and to take care of the validation of the metadata to be
able to create a functional knowledge graph-based library out of it in the future. To
achieve this, we designed a solution based on Microsoft 365 cloud, using MS Excel
files as data entry interfaces, Office Script scripts for data validation and a dedi-
cated folder structure in MS Sharepoint for file storage, and then together with the
Jagiellonian Library, we formulated a workflow that combines existing systems and
procedures with the proposed tools. The workflow has already been evaluated in two
pilots in the DiHeLib project focused on digitizing the so-called “Berlin Collection”
and in two workshops with international guests, which allowed for its refinement and
confirmation of its correctness and usability for JL.
As future work, we plan to further evaluate the proposed workflow in other cases,
includingtheCulturalHeritageExplorationandRetrievalwithIntelligentSystemsat
Jagiellonian University (CHExRISH) project, where we will be able to examine the
usability of the proposed solution at the JU museum, a different kind of institution
in the GLAM group. We also plan to develop a knowledge graph-based catalog and
related scripts to import metadata stored in Excel files, which is the ultimate goal of
the reported work.
Acknowledgements. We would like to express our gratitude to Remigiusz Sapa—
Director of the Jagiellonian Library—for overseeing all the efforts carried out at the
JL to support the design and validation of the presented workflow, and to all the JL
staff involved in these activities.
Funding. This publication was funded by a flagship project “CHExRISH: Cultural
Heritage Exploration and Retrieval with Intelligent Systems at Jagiellonian Univer-
sity” under the Strategic Programme Excellence Initiative at Jagiellonian University.
The research for this publication has been supported by a grant from the Priority
16Research Area DigiWorld under the Strategic Programme Excellence Initiative at
Jagiellonian University.
Declarations
Conflict of interest. The authors declare that they have no conflict of interest.
Data availability. No datasets were created during this study.
Code availability. All software supporting the workflow (Office Script scripts, a
collection of Python scripts) has been created under the GNU GPL v3.0 license and
is available upon e-mail request sent to the authors of the paper.
References
[1] Bakowska E (2005) The Jagiellonian Library, Cracow: its history and
recent developments. Library Review 54(3):155–165. https://doi.org/10.1108/
00242530510588917
[2] du Chˆateau S, Boulanger D, Mercier-Laurent E (2008) Voice knowledge acquisi-
tion system for the management of cultural heritage. In: Shi Z, Mercier-Laurent
E, Leake D (eds) Intelligent Information Processing IV. Springer US, Boston,
MA, pp 38–49
[3] Cristofaro S, Spampinato D (2021) OntoBelliniLetters: A formal ontology for a
corpus of letters of vincenzo bellini. In: Garoufallou E, Ovalle-Perandones MA
(eds) Metadata and Semantic Research. MTSR 2020. Communications in Com-
puter and Information Science. Springer, Cham, p 192–203, https://doi.org/10.
1007/978-3-030-71903-6 19
[4] Denisova DA, Dorodnykh NO, Yurin AY (2022) Ontology engineering based on
spreadsheet data transformation. In: 2022 Ural-Siberian Conference on Biomedi-
cal Engineering, Radioelectronics and Information Technology (USBEREIT), pp
204–207, https://doi.org/10.1109/USBEREIT56278.2022.9923379
[5] Erxleben F, Gu¨nther M, Kr¨otzsch M, et al (2014) Introducing wikidata to the
linkeddataweb.In:MikaP,TudoracheT,BernsteinA,etal(eds)TheSemantic
Web – ISWC 2014. Springer International Publishing, Cham, pp 50–65
[6] Haslhofer B, Isaac A (2011) data.europeana.eu - the europeana linked open
data pilot. In: DCMI International Conference on Dublin Core and Metadata
Applications, The Hague, The Netherlands, URL http://eprints.cs.univie.ac.at/
2919/
[7] H¨ayrinen A (2008) A template based, event-centric documentation framework.
Paper presented at the 2008 Annual Conference of CIDOC, Athens, September
15 – 18, 2008
17[8] HeathT,BizerC(2011)LinkedData:EvolvingtheWebintoaGlobalDataSpace.
Synthesis Lectures on Data, Semantics, and Knowledge, Springer International
Publishing, Cham, https://doi.org/10.1007/978-3-031-79432-2
[9] Hitzler P (2021) A review of the semantic web field. Commun ACM 64(2):76–83.
https://doi.org/10.1145/3397512, URL https://doi.org/10.1145/3397512
[10] Hogan A, Blomqvist E, Cochez M, et al (2021) Knowledge graphs. ACM
Computing Surveys 54(4):1–37. https://doi.org/10.1145/3447772
[11] von Humboldt A (1845–1858) Kosmos. t. 1 [ca(cid:32)lo´s´c]. https://jbc.bj.uj.edu.pl/
publication/353003
[12] Hyv¨onenE,RantalaH(2019)Knowledge-basedrelationdiscoveryinculturalher-
itage knowledge graphs. In: Proceedings of the Digital Humanities in the Nordic
Countries 4th Conference (DHN 2019)
[13] Isaac A (2013) Europeana data model primer. Tech. rep., Europeana, https://
pro.europeana.eu/page/edm-documentation
[14] Jan JF (2018) Application of open-source software in community her-
itage resources management. ISPRS International Journal of Geo-Information
7(11):426. https://doi.org/10.3390/ijgi7110426
[15] Janowicz K, Van Harmelen F, Hendler JA, et al (2015) Why the data train
needs semantic rails. AI Magazine 36(1):5–14. https://doi.org/10.1609/aimag.
v36i1.2560
[16] Jurkowicz B (2015) The collection of the prussian state library. polish, german,
or european cultural heritage? In: Ziemer K (ed) Memory and Politics of Cul-
tural Heritage in Poland and Germany. Cardinal Stefan Wyszyn´ski University in
Warsaw, Warsaw, p 117–130
[17] Kim B, Nakamura S, Watanave H (2022) Using archivematica and omeka s for
long-term preservation and access of digitized archive materials. In: Tseng YH,
KatsuraiM,NguyenHN(eds)FromBorn-PhysicaltoBorn-Virtual:Augmenting
Intelligence in Digital Libraries. Springer International Publishing, Cham, pp
241–250
[18] Kita-Huber J, Jaglarz M (2022) Re-cataloguing the varnhagen collection. a pro-
posal of a new description scheme and its application to the selected material.
Polish Libraries 10:135–161. https://doi.org/10.36155/PLib.10.00006
[19] KovalenkoO,SerralE,BifflS(2013)Towardsevaluationandcomparisonoftools
for ontology population from spreadsheet data. In: Proceedings of the 9th Inter-
nationalConferenceonSemanticSystems.AssociationforComputingMachinery,
New York, NY, USA, I-SEMANTICS ’13, p 57–64, https://doi.org/10.1145/
182506182.2506190
[20] LamyJB(2017)Owlready:Ontology-orientedprogramminginpythonwithauto-
matic classification and high level constructs for biomedical ontologies. Artificial
Intelligence in Medicine 80:11–28. https://doi.org/10.1016/j.artmed.2017.07.002
[21] Preuss U (2016) Sustainable digitalization of cultural heritage–report on initia-
tivesandprojectsinbrandenburg,germany.Sustainability8(9).https://doi.org/
10.3390/su8090891
[22] Rebele T, Suchanek F, Hoffart J, et al (2016) Yago: A multilingual knowledge
base from wikipedia, wordnet, and geonames. In: Groth P, Simperl E, Gray A,
et al (eds) The Semantic Web – ISWC 2016. Springer International Publishing,
Cham, pp 177–185
[23] Sosnowski R, Tylus P (2023) European treasure in the jagiellonian library. a
flagship project. Polish Libraries 11:235–244. https://doi.org/10.36155/PLib.11.
00008
[24] Wilkinson MD, Dumontier M, Aalbersberg IJ, et al (2016) The FAIR guid-
ing principles for scientific data management and stewardship. Scientific Data
3(1):160018. https://doi.org/10.1038/sdata.2016.18
[25] Wo´zny M, Dzie¸gielewski K (2018) 150 years of the jagiellonian university archae-
ological cabinet. past and present. Recherches Arch´eologique Nouvelle Serie
9:185–208. https://doi.org/10.33547/RechACrac.NS9.07
[26] Zi¸ebaK(2020)UniversitymuseumsandcollectionsontheexampleoftheJagiel-
lonian University. Search for new regulations in the constitution for science.
Muzealnictwo 61:201–207. https://doi.org/10.5604/01.3001.0014.3640
19