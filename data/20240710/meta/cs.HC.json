[
    {
        "title": "Garment suggestion based on comfort extracted from physiological and emotional parameters",
        "authors": "Hyo JungChangMohammad Abu Nasir RakibKamrul H FoysalJo Woon Chong",
        "links": "http://arxiv.org/abs/2407.07040v1",
        "entry_id": "http://arxiv.org/abs/2407.07040v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07040v1",
        "summary": "The purpose of the study was to find the true comfort of the wearer by\nconceptualizing, formulating, and proving the relation between physiological\nand emotional parameters with clothing fit and fabric. A mixed-method research\ndesign was used, and the findings showed that physiological indicators such as\nheart rate are closely linked with user comfort. However, a significant change\nin emotional response indicated a definite relationship between different\nfabric and fit types. The research was conducted to discover the relation\nbetween true comfort parameters and clothing, which is unique to the field. The\nfindings help us understand how fabric types and clothing fit types can affect\nphysiological and emotional responses, providing the consumer with satisfactory\nclothing with the suitable properties needed.",
        "updated": "2024-07-09 17:02:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07040v1"
    },
    {
        "title": "A Framework for Multimodal Medical Image Interaction",
        "authors": "Laura SchützSasan MatinfarGideon SchafrothNavid NavabMerle FairhurstArthur WagnerBenedikt WiestlerUlrich EckNassir Navab",
        "links": "http://arxiv.org/abs/2407.07015v1",
        "entry_id": "http://arxiv.org/abs/2407.07015v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07015v1",
        "summary": "Medical doctors rely on images of the human anatomy, such as magnetic\nresonance imaging (MRI), to localize regions of interest in the patient during\ndiagnosis and treatment. Despite advances in medical imaging technology, the\ninformation conveyance remains unimodal. This visual representation fails to\ncapture the complexity of the real, multisensory interaction with human tissue.\nHowever, perceiving multimodal information about the patient's anatomy and\ndisease in real-time is critical for the success of medical procedures and\npatient outcome. We introduce a Multimodal Medical Image Interaction (MMII)\nframework to allow medical experts a dynamic, audiovisual interaction with\nhuman tissue in three-dimensional space. In a virtual reality environment, the\nuser receives physically informed audiovisual feedback to improve the spatial\nperception of anatomical structures. MMII uses a model-based sonification\napproach to generate sounds derived from the geometry and physical properties\nof tissue, thereby eliminating the need for hand-crafted sound design. Two user\nstudies involving 34 general and nine clinical experts were conducted to\nevaluate the proposed interaction framework's learnability, usability, and\naccuracy. Our results showed excellent learnability of audiovisual\ncorrespondence as the rate of correct associations significantly improved (p <\n0.001) over the course of the study. MMII resulted in superior brain tumor\nlocalization accuracy (p < 0.05) compared to conventional medical image\ninteraction. Our findings substantiate the potential of this novel framework to\nenhance interaction with medical images, for example, during surgical\nprocedures where immediate and precise feedback is needed.",
        "updated": "2024-07-09 16:33:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07015v1"
    },
    {
        "title": "Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects",
        "authors": "Krzysztof KuttJakub GomułkaLuiz do Valle MirandaGrzegorz J. Nalepa",
        "links": "http://arxiv.org/abs/2407.06972v1",
        "entry_id": "http://arxiv.org/abs/2407.06972v1",
        "pdf_url": "http://arxiv.org/pdf/2407.06972v1",
        "summary": "In response to several cultural heritage initiatives at the Jagiellonian\nUniversity, we have developed a new digitization workflow in collaboration with\nthe Jagiellonian Library (JL). The solution is based on easy-to-access\ntechnological solutions -- Microsoft 365 cloud with MS Excel files as metadata\nacquisition interfaces, Office Script for validation, and MS Sharepoint for\nstorage -- that allows metadata acquisition by domain experts (philologists,\nhistorians, philosophers, librarians, archivists, curators, etc.) regardless of\ntheir experience with information systems. The ultimate goal is to create a\nknowledge graph that describes the analyzed holdings, linked to general\nknowledge bases, as well as to other cultural heritage collections, so careful\nattention is paid to the high accuracy of metadata and proper links to external\nsources. The workflow has already been evaluated in two pilots in the DiHeLib\nproject focused on digitizing the so-called \"Berlin Collection\" and in two\nworkshops with international guests, which allowed for its refinement and\nconfirmation of its correctness and usability for JL. As the proposed workflow\ndoes not interfere with existing systems or domain guidelines regarding\ndigitization and basic metadata collection in a given institution (e.g., file\ntype, image quality, use of Dublin Core/MARC-21), but extends them in order to\nenable rich metadata collection, not previously possible, we believe that it\ncould be of interest to all GLAMs (galleries, libraries, archives, and\nmuseums).",
        "updated": "2024-07-09 15:49:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.06972v1"
    },
    {
        "title": "INTERACT: An authoring tool that facilitates the creation of human centric interaction with 3d objects in virtual reality",
        "authors": "Rama Krishnan Gopal Ramasamy ThandapaniBenjamin CapelAntoine LasnierIoannis Chatzigiannakis",
        "links": "http://arxiv.org/abs/2407.06967v1",
        "entry_id": "http://arxiv.org/abs/2407.06967v1",
        "pdf_url": "http://arxiv.org/pdf/2407.06967v1",
        "summary": "A widespread adoption of Virtual, Augmented, and Mixed Reality (VR/AR/MR),\ncollectively referred to as Extended Reality (XR), has become a tangible\npossibility to revolutionize educational and training scenarios by offering\nimmersive, interactive experiences. In this paper we present \\textsf{INTERACT},\nan authoring tool for creating advanced 3D physics-based Intelligent Tutoring\nSystems (ITS) by individual developers or small-scale development teams.\n\\textsf{INTERACT} is based on a cutting edge physics engine allowing realistic\ninteractions such as collision detection and ergonomic evaluations. We\ndemonstrate the benefits of \\textsf{INTERACT} by developing a set of training\nscenarios for a use case of a Laser cutting machine. The use case illustrates\nthe numerous possibilities such as creating interaction with objects, ease of\nconfiguring a scenario and how to design the visual effects to the machine.",
        "updated": "2024-07-09 15:46:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.06967v1"
    },
    {
        "title": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective",
        "authors": "Shahana IbrahimPanagiotis A. TraganitisXiao FuGeorgios B. Giannakis",
        "links": "http://arxiv.org/abs/2407.06902v1",
        "entry_id": "http://arxiv.org/abs/2407.06902v1",
        "pdf_url": "http://arxiv.org/pdf/2407.06902v1",
        "summary": "One of the primary catalysts fueling advances in artificial intelligence (AI)\nand machine learning (ML) is the availability of massive, curated datasets. A\ncommonly used technique to curate such massive datasets is crowdsourcing, where\ndata are dispatched to multiple annotators. The annotator-produced labels are\nthen fused to serve downstream learning and inference tasks. This annotation\nprocess often creates noisy labels due to various reasons, such as the limited\nexpertise, or unreliability of annotators, among others. Therefore, a core\nobjective in crowdsourcing is to develop methods that effectively mitigate the\nnegative impact of such label noise on learning tasks. This feature article\nintroduces advances in learning from noisy crowdsourced labels. The focus is on\nkey crowdsourcing models and their methodological treatments, from classical\nstatistical models to recent deep learning-based approaches, emphasizing\nanalytical insights and algorithmic developments. In particular, this article\nreviews the connections between signal processing (SP) theory and methods, such\nas identifiability of tensor and nonnegative matrix factorization, and novel,\nprincipled solutions of longstanding challenges in crowdsourcing -- showing how\nSP perspectives drive the advancements of this field. Furthermore, this article\ntouches upon emerging topics that are critical for developing cutting-edge\nAI/ML systems, such as crowdsourcing in reinforcement learning with human\nfeedback (RLHF) and direct preference optimization (DPO) that are key\ntechniques for fine-tuning large language models (LLMs).",
        "updated": "2024-07-09 14:34:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.06902v1"
    }
]