[
    {
        "title": "AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning",
        "authors": "Jiaxi CuiWentao ZhangJing TangXudong TongZhenwei ZhangAmieJing WenRongsheng WangPengfei Wu",
        "links": "http://arxiv.org/abs/2407.07094v1",
        "entry_id": "http://arxiv.org/abs/2407.07094v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07094v1",
        "summary": "The pervasive deployment of Large Language Models-LLMs in various sectors\noften neglects the nuanced requirements of individuals and small organizations,\nwho benefit more from models precisely tailored to their specific business\ncontexts rather than those with broadly superior general capabilities. This\nwork introduces \\textbf{AnyTaskTune}, a novel fine-tuning methodology coined as\n\\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on\na diverse array of domain-specific tasks. This method involves a meticulous\nprocess to identify and define targeted sub-tasks within a domain, followed by\nthe creation of specialized enhancement datasets for fine-tuning, thereby\noptimizing task-specific model performance. We conducted comprehensive\nfine-tuning experiments not only in the legal domain for tasks such as keyword\nextraction and sentence prediction but across over twenty different sub-tasks\nderived from the domains of finance, healthcare, law, psychology, consumer\nservices, and human resources. To substantiate our approach and facilitate\ncommunity engagement, we will open-source these bilingual task datasets. Our\nfindings demonstrate that models fine-tuned using the \\textbf{Task-Fine-Tune}\nmethodology not only achieve superior performance on these specific tasks but\nalso significantly outperform models with higher general capabilities in their\nrespective domains. Our work is publicly available at\n\\url{https://github.com/PandaVT/DataTager}.",
        "updated": "2024-07-09 17:59:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07094v1"
    },
    {
        "title": "FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation",
        "authors": "Liqun MaMingjie SunZhiqiang Shen",
        "links": "http://arxiv.org/abs/2407.07093v1",
        "entry_id": "http://arxiv.org/abs/2407.07093v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07093v1",
        "summary": "This work presents a Fully BInarized Large Language Model (FBI-LLM),\ndemonstrating for the first time how to train a large-scale binary language\nmodel from scratch (not the partial binary or ternary LLM like BitNet b1.58) to\nmatch the performance of its full-precision counterparts (e.g., FP16 or BF16)\nin transformer-based LLMs. It achieves this by employing an autoregressive\ndistillation (AD) loss with maintaining equivalent model dimensions (130M,\n1.3B, 7B) and training data volume as regular LLM pretraining, while delivering\ncompetitive results in terms of perplexity and task-specific effectiveness.\nIntriguingly, by analyzing the training trajectory, we find that the pretrained\nweight is not necessary for training binarized LLMs from scratch. This research\nencourages a new computational framework and may facilitate the future design\nof specialized hardware tailored for fully 1-bit LLMs. We make all models,\ncode, and training dataset fully accessible and transparent to support further\nresearch (Code: https://github.com/LiqunMa/FBI-LLM. Model:\nhttps://huggingface.co/LiqunMa/).",
        "updated": "2024-07-09 17:59:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07093v1"
    },
    {
        "title": "V-VIPE: Variational View Invariant Pose Embedding",
        "authors": "Mara LevyAbhinav Shrivastava",
        "links": "http://arxiv.org/abs/2407.07092v1",
        "entry_id": "http://arxiv.org/abs/2407.07092v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07092v1",
        "summary": "Learning to represent three dimensional (3D) human pose given a two\ndimensional (2D) image of a person, is a challenging problem. In order to make\nthe problem less ambiguous it has become common practice to estimate 3D pose in\nthe camera coordinate space. However, this makes the task of comparing two 3D\nposes difficult. In this paper, we address this challenge by separating the\nproblem of estimating 3D pose from 2D images into two steps. We use a\nvariational autoencoder (VAE) to find an embedding that represents 3D poses in\ncanonical coordinate space. We refer to this embedding as variational\nview-invariant pose embedding V-VIPE. Using V-VIPE we can encode 2D and 3D\nposes and use the embedding for downstream tasks, like retrieval and\nclassification. We can estimate 3D poses from these embeddings using the\ndecoder as well as generate unseen 3D poses. The variability of our encoding\nallows it to generalize well to unseen camera views when mapping from 2D space.\nTo the best of our knowledge, V-VIPE is the only representation to offer this\ndiversity of applications. Code and more information can be found at\nhttps://v-vipe.github.io/.",
        "updated": "2024-07-09 17:59:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07092v1"
    },
    {
        "title": "Safe and Reliable Training of Learning-Based Aerospace Controllers",
        "authors": "Udayan MandalGuy AmirHaoze WuIeva DaukantasFletcher Lee NewellUmberto RavaioliBaoluo MengMichael DurlingKerianne HobbsMilan GanaiTobey ShimGuy KatzClark Barrett",
        "links": "http://arxiv.org/abs/2407.07088v1",
        "entry_id": "http://arxiv.org/abs/2407.07088v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07088v1",
        "summary": "In recent years, deep reinforcement learning (DRL) approaches have generated\nhighly successful controllers for a myriad of complex domains. However, the\nopaque nature of these models limits their applicability in aerospace systems\nand safety-critical domains, in which a single mistake can have dire\nconsequences. In this paper, we present novel advancements in both the training\nand verification of DRL controllers, which can help ensure their safe behavior.\nWe showcase a design-for-verification approach utilizing k-induction and\ndemonstrate its use in verifying liveness properties. In addition, we also give\na brief overview of neural Lyapunov Barrier certificates and summarize their\ncapabilities on a case study. Finally, we describe several other novel\nreachability-based approaches which, despite failing to provide guarantees of\ninterest, could be effective for verification of other DRL systems, and could\nbe of further interest to the community.",
        "updated": "2024-07-09 17:58:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07088v1"
    },
    {
        "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
        "authors": "Logan CrossViolet XiangAgam BhatiaDaniel LK YaminsNick Haber",
        "links": "http://arxiv.org/abs/2407.07086v1",
        "entry_id": "http://arxiv.org/abs/2407.07086v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07086v1",
        "summary": "Multi-agent reinforcement learning (MARL) methods struggle with the\nnon-stationarity of multi-agent systems and fail to adaptively learn online\nwhen tested with novel agents. Here, we leverage large language models (LLMs)\nto create an autonomous agent that can handle these challenges. Our agent,\nHypothetical Minds, consists of a cognitively-inspired architecture, featuring\nmodular components for perception, memory, and hierarchical planning over two\nlevels of abstraction. We introduce the Theory of Mind module that scaffolds\nthe high-level planning process by generating hypotheses about other agents'\nstrategies in natural language. It then evaluates and iteratively refines these\nhypotheses by reinforcing hypotheses that make correct predictions about the\nother agents' behavior. Hypothetical Minds significantly improves performance\nover previous LLM-agent and RL baselines on a range of competitive, mixed\nmotive, and collaborative domains in the Melting Pot benchmark, including both\ndyadic and population-based environments. Additionally, comparisons against\nLLM-agent baselines and ablations reveal the importance of hypothesis\nevaluation and refinement for succeeding on complex scenarios.",
        "updated": "2024-07-09 17:57:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07086v1"
    }
]