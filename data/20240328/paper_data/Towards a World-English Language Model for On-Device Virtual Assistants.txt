TOWARDSAWORLD-ENGLISHLANGUAGEMODEL
FORON-DEVICEVIRTUALASSISTANTS
RrichaJalota⊕,⋆ LyanVerwimp† MarkusNussbaum-Thom†
AmrMousa† ArturoArgueta† YoussefOualil†
⊕AppTekGmbH †Apple
ABSTRACT EarlierworksstudyingmultilingualASReitherfocused
NeuralNetworkLanguageModels(NNLMs)forVirtualAs- on the Acoustic Model (AM) in hybrid ASR [3] or on an
sistants(VAs)aregenerallylanguage-,region-,andinsome end-to-end(E2E)ASRarchitecture. MultilingualE2EASR
cases, device-dependent, whichincreasestheefforttoscale models either do not have external LMs [4, 5, 6], or if they
andmaintainthem. CombiningNNLMsforoneormoreof have them, the LMs are often trained on the pooled dataset
thecategoriesisonewaytoimprovescalability. Inthiswork, withoutadditionalenhancements[3].
wecombineregionalvariantsofEnglishtobuilda“WorldEn-
Recently,adaptermoduleshavebecomeapopulararchitec-
glish”NNLMforon-deviceVAs. Inparticular,weinvestigate
tureextensiontoimproveMultilingualAcousticModeling[7]
theapplicationofadapterbottleneckstomodeldialect-specific
and model language-specific traits in end-to-end ASR [8].
characteristicsinourexistingproductionNNLMsandenhance
Adapters are parameter-efficient modeling units consisting
themulti-dialectbaselines. Wefindthatadaptermodulesare
ofadown-projection,followedbyanon-linearityandanup-
more effective in modeling dialects than specializing entire
projection [9, 10]. They are added either after every self-
sub-networks. Basedonthisinsightandleveragingthedesign
attention layer [7] or feed-forward layer [10, 11] in the en-
ofourproductionmodels,weintroduceanewarchitecturefor
coder/decoderblockofTransformer-basedarchitectures,and
World English NNLM that meets the accuracy, latency and usuallyaddaround5%parameterstothemodel. Tothebest
memoryconstraintsofoursingle-dialectmodels.
of our knowledge, Kannan et al. [8] were the first to apply
IndexTerms— NNLM,multi-dialect,multilingual language-specific adapters in a non-attention based RNN-T
framework[12]forMultilingualAcoustic-Modeling.
1. INTRODUCTION Contrarytopreviousworks,weinvestigatetheapplication
ofadaptersandcomparedifferentadaptertrainingschemesin
Inon-deviceVirtualAssistants,itiscommontodeploydistinct twodistinctFeedforwardLMarchitectures,basedontheFixed-
AutomaticSpeechRecognition(ASR)modelsoptimizedfor sizeOrdinally-ForgettingEncoding(FOFE)method[13,1].
eachlanguage,region,anddevice[1]. Thisallowsthemodels WepreferFOFE-basedmodelsovertransformer-basedmod-
tobettercaptureregionaltrendsanddialects,whilemeeting elssincetheyhavebetteraccuracy-latencytrade-offforour
hardwareconstraints. However,maintainingseveralmodelsre- two applications [1]: Speech-to-Text (STT) and Assistant.
quiresalotofeffort,andshippingnewfeaturesrequirestesting Speech-to-Textrequestsaredictatedmessagessuchasnotes
allcombinationsofdeviceandlanguagevariants. Therefore, ande-mails,whileAssistantcoversVArequestsfromvarious
buildingajointmodelforservingallvariantsofalanguage domainssuchasmusic,timer,etc. Inourusecase,thedialect
can improve the scalability of this process by reducing the informationisalreadysetbytheuserandthusknownbefore-
numberofdifferentrecipesthatneedtobemaintained, and hand. Itisusedtotraindialect-specificmodulesandtoenable
alsoreducestheenvironmentalcostoftrainingseveralmodels. theactivationoftherelevantsub-networkduringinference.
Inthiswork,wefocusonthelanguagemodel(LM)compo-
Asopposedtopreviousworks[7,8]thatfocusonmulti-
nentofthehybridASRpipelineandbuildaWorld-English
lingual modeling to improve accuracy on one or more low-
NNLMbycombiningthreedialectsofEnglishthatarespoken
resource languages, in this paper, we aim to build a multi-
intheUSA,UKandIndia,henceforthreferredtoas: en_US,
dialectmodel,whereineachdialectcanbeconsideredhigh-
en_GB,anden_IN.Specifically,wefocusontheLMsthatcan
resourced. Ourcontributionsarethefollowing: (1)weshow
bestoredandusedforASRinferenceondevice. Hence,the
thattheaccuracygainsofadaptersarealsoapplicabletoour
useofmodelsthatdonotfulfillthisrequirement(e.g.,Large
FOFE-basedarchitectures,(2)weconductanin-depthanalysis
LanguageModelslikeGPT-3[2],etc.) isoutofscopeofthis
ontheplacement,trainingstrategiesandvariantsofadapters
paper.
inFOFE-basedNNLMs,and(3)weintroduceanewadapter-
*WorkdonewhiletheauthorwasaninternatApple. based model that leverages the design of our FOFE-based
4202
raM
72
]LC.sc[
1v38781.3042:viXraarchitectures and meets the accuracy, latency and memory isprojectedontoasmallerdimensionk,followedbyanon-
constraintsofon-deviceVAs. linearity (ReLU) and projected back to d dimensions. The
adapter output is then combined with the residual from the
layerprecedingtheadaptermodule.
2. MODELARCHITECTURE
Adapterplacement:Thearchitecturaladditionofadaptersis
First, we briefly describe the existing FOFE-based single-
nottrivial[15],therefore,wefirstinvestigatetheirplacement.
dialectarchitectures. Then,wedefineWorld-Englishbaselines
InMixtureFOFE(seeFig.(1a)),adialect-specificadaptercan
andpresentwaystoenhancethembyaddingadapters,ending
beplacedatvariouspositions: (i)beforetheprojectionlayer,
withtheintroductionofthenewadapter-basedarchitecture.
(ii)ontopofthelasthiddenlayerineachoftheparallelblocks,
(iii)acombinationof(i)and(ii),(iv)aftereachhiddenlayer
2.1. BaselineFOFE-basedNNLMs ineachoftheparallelblocks,and(v): combinationof(iv)and
(i).
TheFOFEmethod[13]uniquelyencodesword-orderinforma-
tionusingarecursiveformulawithaforgettingfactor,thereby
TrainingStrategies:Next,weexaminethreedifferentadapter
enablingafeedforwardneuralnetwork(FNN)tomodellong-
trainingschemes. Adaptersareusuallytrainedinatwo-step
termdependencies. TojointlyhandlebothAssistantandSTT
process[10,11,8,7]. First,abasemodelispre-trainedonthe
applications, [1] extend FOFE-FNNs to two architectures,
combined data from all dialects. In the second step, all the
namely,MixtureFOFEandApplication-Dependent(AD)
modelparametersarefrozen,andtheadapterisadded,which
FOFE. Mixture FOFE, shown in Figure (1a) consists of a
is trained on the dialect-specific data. Since the adapter is
wordembeddinglayer(whichforallarchitecturesisshared
randomlyinitializedtomimicanear-identityfunctionbefore
with the output), followed by a FOFE layer and N parallel
learningthedialect-specificweights,wecallthistrainingsetup
blocks of stacked feedforward layers, one of which acts as
Randomly-InitializedAdapter(RI-A).Inthesecondtrain-
anunsupervisedmixture[1]. Theunsupervisedmixturepro-
ingstrategy,weincludetheadapterinthearchitectureinthe
videsweightstoaverageoutthefeatureslearnedbytheother
firststep(similartothebaselinein[16])andtraintheentire
N −1parallelblocksandthentheaveragedoutputisfedto
network with the multi-dialect data. We call this Adapter-
theprojectionlayer.
Pretraining(PT-A).Inthethirdtrainingscheme,wefine-tune
UnlikeMixtureFOFE,inADFOFE,distinctsub-networks
thepretrainedadapterwithdialect-specificdataandtherefore,
aretrainedforeachapplication-inourcaseAssistantandSTT.
refer to it as Adapter-Finetuning (FT-A). We hypothesize
Eachsub-networkconsistsofastackofLfeedforwardlayers
thatadaptersstartingfrompre-trainedweightswouldconverge
andcarriesitsownprojectionheadandoutputbias. During
fasterandmightperformbetterthanRI-A.
training,theapplication-basedsub-networksarejointlytrained,
while during inference, only the sub-network pertaining to AdapterVariant: Finally, we inspect an adapter variant,
theapplicationremainsactive. Thisgivesasmallermemory namely, Dual adapters (DA) [7] in AD FOFE, which be-
footprinttotheADFOFEmodelandallowsfasterinference. sidesadialect-specificadapteralsocontainsacommondialect
FortheWorld-Englishmodel,weconsiderbothMixtureFOFE adapter(C)tolearnasharedrepresentationofdialects. We
and AD FOFE as our base architectures and investigate the integratedualadaptersinADFOFEbyreducingthenumber
mostoptimalsetup. ofsub-networkstothenumberofapplications. Asshownin
Figure (1c), instead of having a dedicated sub-network for
2.2. World-EnglishNNLMs eachapplicationperdialect,wehaveonlytwosub-networks
(one for each application) and add dual adapters on top of
WefirstestablishthebaselinesforWorld-EnglishNNLMby them,therebyreducingthenumberofparameters.
feedingtheMixtureFOFEandADFOFEmodelswithmulti-
dialectdata(curationexplainedinSection3). Whilethebase- ProposedArchitecture: Itisobservedin[1]thatformono-
lineMixtureFOFEmodeldoesnotchangewiththenumber lingualsetups,althoughADFOFEispreferredforitslower
ofdialects,incaseofADFOFE,thenumberofsub-networks latency, Mixture FOFE is more accurate1. We hypothesize,
increasesbytwowiththeadditionofeachdialect,asshown this higher accuracy might be due to the shared representa-
inFigure(1b). Thismeans,thebaselineWorld-EnglishAD tionofapplicationsinMixtureFOFE.Hence,toenhancethe
FOFE model consists of six sub-networks, with each sub- accuracyofADFOFEwhilepreservingitslowlatency, we
networkmodelinganapplicationinthegivendialect. introduce a novel architecture that combines the AD FOFE
anddualadapterswithMixtureFOFE(seeFigure(1d)).
ExtensionwithAdapters: Followingpreviousworks[14,8]
Following the FOFE layer, we add a block of L feedfor-
thatuseadaptersasanalternativetofine-tuning,weinspectif
ward layers to enable joint learning of applications in all
adapterscanbringsimilaraccuracygainstoourpre-trained
World English baseline models. Similar to [10], we define 1Inthiswork,accuracyreferstoworderrorrate(WER)whileperformance
an adapter as a bottleneck, where the original dimension d referstolatency.(a)Mixture (b)AD (c)AD+DA (d)AD+CAA+DA
Fig.1:FOFE-basedNNLMArchitectures.Thecomponentsinbluedenotefeedforwardlayers.US,GB,INrefertoAmerican,BritishandIndianEnglish.The
abbreviationCinfigures1cand1dreferstotheCommonDialectAdapterandCAAreferstoCommonApplicationAdapter.Figure(1a):MixtureFOFEmodel,
(1b):Multi-dialectADFOFE(AD),(1c):ADFOFEwithDualAdapters(AD+DA)and(1d):ADFOFEwithCAAandDualAdapters(AD+CAA+DA).
threedialects. Thisisfollowedbyapplication-dependentsub- to5and4,respectively. Therestofthehyperparametersfor
networksandaCommonApplicationAdapter(CAA),whichis trainingtheFOFE-basedmodelsarethesameasreportedin
addedinparalleltothesub-networks. Similartothecommon [1].
dialectadapterindual-adapters,CAAwouldfurtherfacilitate ASRSystem: TheASRSystemconsistsofaCNN-acoustic
learningapplication-agnostictraits.Thecombinedoutputfrom model[17]andaFOFE-basedNNLM[1]thatisusedinthe
theapplication-sub-networks,CAAandtheresidualfromthe firstpass.
blockoffeedforwardlayersisdirectedtodual-adapters,placed
atopeachsub-networkformodelingdialects. Thearchitecture Evaluation: Themodelsareevaluatedintermsofaccuracy,
concludes with output from application-specific projection size (measured by the number of parameters to account for
headsandishenceforthreferredas,Application-Dependent memoryconstraints),andon-devicelatency. Weestimatela-
modelwithCommonApplicationAdapterandDualAdapters tencyusingASRProcessingLatency,whichisdefinedasthe
(AD+CAA+DA). time from when the user stops speaking to when the ASR
poststhefinalresult. Bothaverageand95thPercentile(P95)
3. EXPERIMENTALSETUP
resultsarereported,basedonanaverageof3runsondevice.
WeevaluateaccuracyusingWordErrorRate(WER)onthree
Data: Our training data comes from anonymized and ran-
testsets: Assistant(Ast.),Speech-to-Text(STT)andTailEnti-
domly sampled user requests from several domains (media,
ties(T.E.). AssistantandSTTconsistofgeneralVArequests
photos,calendar,etc.) andapplications(AssistantandSTT)
sampledfromtheactualdistribution,therebycontainingthe
ineachofthethreedialects: en_US,en_GB,anden_IN.For
mostfrequent(head-heavy)queries. TailEntitiesisatestset
each dialect, the relevance weights for the data sources are
synthesizedwithText-to-Speech,containingless-frequently
estimatedusingthesametechniqueasdescribedin[1]. Given
occurringquerieswithtailentities. Table1presentsthedevel-
thatallthethreedialectsarehigh-resourced,samplingequal
opmentandtestsetstatistics.
amounts of data for each dialect turned out to be the most
optimalchoiceforourusecase. Split Dialect Ast. STT T.E.
en_US 215,299 285,853 -
dev en_GB 148,814 111,650 -
Training: We train single-dialect NNLMs on 12B words
en_IN 145,795 55,907 -
withthetop100kmostfrequentwordsasvocabulary. Forthe en_US 226,371 292,477 454,159
multi-dialectsetup,wesamplethetrainingdataasexplained test en_GB 155,232 114,103 232,285
en_IN 153,862 54,562 239,852
aboveandsetthetrainingwordsto36Bandvocabsizeto150k.
Thevocabsizeisempiricallychosenonthedevelopmentset Table1:Numberofwordsdevelopmentandtestsets.
suchthatthecoveragewithrespecttothesingle-dialectvocab-
ulariesisgreaterthan75%whilestillachievingmeaningful
WERreductionsandshortertrainingtimes. Forinference,the 4. RESULTS
multi-dialectNNLMisfedintodistinct,dialect-specificASR
systems. Thismeans,excepttheNNLM,allothercomponents AdapterPlacement: WeperformBayesianOptimizationon
of the system are specific to the dialect and remain intact. thedevelopmentsettofindthemostoptimalplacementand
Similar to [1], we set the values of N and L in our models compressiondimensionk(128,96,48)startingfromahiddendimension, d = 768. We observe that adding only a single Proposed Architecture: Finally, we investigate if the pro-
dialect-specificadapterbeforetheprojectionlayer,i.e. place- posedarchitectureimprovesaccuracyoverADFOFEvariants.
ment(i)inSec.2.2,withacompressiondimensionof96(< Asexpected,addingasharedrepresentationforapplications
0.5%moreparameters)ismoreeffectivethanaddingmultiple in AD FOFE (i.e., AD+CAA+DA) relatively improves it on all
adapterstothearchitecture. Thisisincontrasttotheprevious testsetsbyanaverageof1.41%overADandmarginallyover
works[10,11,7,16],whereadaptersareaddedineveryblock AD+DA.Infact,foren_US,AD+CAA+DAalsomarginallyoutper-
oftheencoder/decoder. formstheMixtureFOFEvariantsonheadqueries. However,
Mix+AstillachievesabetterWERacrossmosttestsetsdueto
TrainingStrategies: Wethencomparethethreeadaptertrain-
its larger model size and thus, larger shared representation
ingstrategiesinMixtureFOFEtoverifyifonecouldbepre-
among dialects and applications. Overall, both the multi-
ferred over another. We observe that the results are mixed
dialect models: Mix+A and AD+CAA+DA, improve the single-
andvarywithtestsetsacrossdialects. Onewouldexpectthat
dialectbaselinesonalldialectsbyanaverageof1.41%and
fine-tuningthepre-trainedadapter(FT-A)showsfurtherim-
1.63%onhead-heavytestsets,and5.38%and3.72%ontail
provementsoverPT-AandRI-Aacrossdialects. However,this
entities,respectively. Intermsofaccuracy,Mix+Aisthebest
doesnotholdtrueacrossalltestsets. Sincetheimprovements
choiceforWorld-EnglishNNLM.However,itis45%bigger
fromPT-Aareconsistentacrossalldialectsonanaverage,we
insizethanAD+CAA+DA.
adoptthistrainingstrategyinallexperimentswithadapters
reportedinTable2.
Model Ast.Avg. Ast.P95 STTAvg. STTP95
Mono_150k 334 425 50 185
Adapters in Multilingual FOFE models: In Table 2, we
Mix+A 421 785 74 230
reporttheWERsofthebestperformingmulti-dialectFOFE AD+CAA+DA 359 474 54 182
modelscombinedwithadaptersusingtheoptimalplacement
Table3:LatencyResults(inmilliseconds)onanaverageof3runsondevice.
andtrainingstrategy. Firstly,weobservethatboththemodels,
Mono_150kreferstosingle-dialectADFOFEwith150kvocab.
Mixture(Mix)andAD,alreadyhavegoodaccuracycompared
to the single-dialect baselines (Mono), with Mix outperform- Next, we compare the models Mix+A and AD+CAA+DA in
ing AD in most cases. Adding adapters (Mix+A) gives slight termsoflatencyonen_UStestsets. Asincreasingthevocab
butconsistentimprovementstoMix. However,forAD+A,the sizeresultsinincreasedlatency,tomakethecomparisonmore
resultsaremoremixed,e.g. theaccuracyontailentitiesim- fair,wecompareourmultidialectmodelstosingle-dialectAD
provesby11.6%foren_INwhileforen_GBitdegradesw.r.t. FOFE with 150k vocab size (Mono_150k). Due to random
AD.However,giventhatADmodelsaresmallerandfasterin fluctuations on device, relative changes in latency less than
inference[1],wewanttofurtherbridgetheaccuracygapw.r.t. 10%areconsideredtobeequallyfast. ResultsinTable3show
Mixturemodels. thatforbothapplications,AD+CAA+DAmatchesthelatencyof
Mono_150k. Furthermore,itoutperformsMix+Abyanaverage
Model en_US en_GB en_IN
Model Size Ast. STT T.E. Ast. STT T.E. Ast. STT T.E. of27%onSTTandiseven40%fasteronthetop-5%queries
Mono 111M 3.97 3.47 18.24 5.26 6.16 16.3 6.92 9.62 26.14 fromAssistantthatincurthelargestlatency(P95).
Mix 89M 3.97 3.41 16.84 5.33 6.17 16.29 6.69 9.46 24.01
Mix+A 89M 3.95 3.41 16.83 5.33 6.18 16.27 6.69 9.18 23.99 Insummary,ourproposedarchitecture(AD+CAA+DA)for
AD 54M 4.01 3.43 17.52 5.34 6.28 16.69 7.16 9.57 24.67 World-English NNLM offers a favorable accuracy-latency-
AD+A 55M 3.99 3.41 21.94 5.38 6.33 21.88 7.24 9.64 21.80
AD+DA 45M 3.97 3.42 17.32 5.36 6.21 16.53 6.90 9.54 24.34 memorytrade-off,showcasingitspotentialfordeployment.
AD+CAA+DA 49M 3.93 3.39 17.32 5.35 6.25 16.44 6.90 9.42 24.32
Table2:First-passdecodingresults(WERs)of(i)thebest(MixtureFOFE/AD 5. CONCLUSION
FOFE)single-dialectmodelMono;(ii)Multi-dialectMixtureFOFE(Mix)with
(iii)Pre-trainedAdapter(Mix+A);(iv)Multi-dialectADFOFE(AD)with(v)
WebuildaWorld-EnglishNNLMforanon-deviceASRsys-
Adapter(AD+A),(vi)Dual-Adapter(AD+DA),and(vii)withCommonApplica-
tionAdapter(AD+CAA+DA).Thesecondcolumnshowstheaggregatedmodel tem,startingwiththreehigh-resourcedEnglishdialects. We
sizeacrossdialects.ThebestWERswithinthemodelfamiliesareunderlined, first examine the application of adapters in FOFE-based ar-
whileboldnumbershighlightthebestoverallresult. chitectures. Based on our findings, we introduce a new ar-
chitecture to bridge the accuracy gap between the baseline
AdapterVariants: InAD+A,onlythewordembeddingsben-
MixtureFOFEandADFOFEmodels. Thismodelrelatively
efitfromparametersharingacrossdialectsandapplications.
improves the accuracy of single-dialect baselines by an av-
Thismightbethereasonbehindthemixedresults. Wetryto
erage of 1.63% on head-heavy test sets and 3.72% on tail
overcomethedegradationontailentitiesbyintroducingmore
entitiesacrossdialects. Moreover,itmatchesthelatencyand
sharedparameters. InAD+DA,thenumberofsub-networksis
memoryconstraintsofon-deviceVAs,whichindicatesthatall
reducedtotwo,anddual-adaptersareaddedtocharacterize
single-dialectbaselinescanbereplacedbythissinglemodel.
thedialect-specificanddialect-agnostictraits. Thisnotonly
Inthefuture,theinsightsfromourexperimentalresultswillbe
reducesthemodelsizebyalmost10%butalsorelativelyim-
leveragedtotrulyachieveaWorld-EnglishNNLMspanning
provesthebaselineADmodelbyanaverageof1.18%ontest
alldialects.
setsacrossdialects(seelowerhalfofTable2).6. REFERENCES [9] Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea
Vedaldi,“Learningmultiplevisualdomainswithresidual
[1] MarkusNussbaum-Thom,LyanVerwimp,andYoussef adapters,” Advancesinneuralinformationprocessing
Oualil, “Application-agnosticlanguagemodelingforon- systems,vol.30,2017.
deviceASR,” inProceedingsofthe61stAnnualMeeting
oftheAssociationforComputationalLinguistics(Volume [10] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
5: IndustryTrack),July2023,pp.268–275. BrunaMorrone,QuentinDeLaroussilhe,AndreaGes-
mundo,MonaAttariyan,andSylvainGelly, “Parameter-
[2] TomB.Brown,BenjaminMann,NickRyder,Melanie efficienttransferlearningforNLP,”inInternationalCon-
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind ferenceonMachineLearning(ICML),2019,pp.2790–
Neelakantan, Pranav Shyam, Girish Sastry, Amanda 2799.
Askell,SandhiniAgarwal,ArielHerbert-Voss,Gretchen
[11] Jonas Pfeiffer, Ivan Vulic´, Iryna Gurevych, and Se-
Krueger,TomHenighan,RewonChild,AdityaRamesh,
bastian Ruder, “Mad-x: An adapter-based framework
DanielM.Ziegler,JeffreyWu,ClemensWinter,Christo-
for multi-task cross-lingual transfer,” arXiv preprint
pher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,
arXiv:2005.00052,2020.
Scott Gray, Benjamin Chess, Jack Clark, Christopher
Berner,SamMcCandlish,AlecRadford,IlyaSutskever,
[12] AlexGraves, “Sequencetransductionwithrecurrentneu-
and Dario Amodei, “Language models are few-shot
ralnetworks,” inInternationalConferenceofMachine
learners,” inAdvancesinNeuralInformationProcessing
Learning(ICML)WorkshoponRepresentationLearning,
Systems33: AnnualConferenceonNeuralInformation
2012.
ProcessingSystems2020,NeurIPS2020,December6-12,
2020,virtual,HugoLarochelle,Marc’AurelioRanzato, [13] ShiliangZhang,HuiJiang,MingbinXu,JunfengHou,
RaiaHadsell,Maria-FlorinaBalcan,andHsuan-TienLin, andLi-RongDai, “Thefixed-sizeordinally-forgetting
Eds.,2020. encodingmethodforneuralnetworklanguagemodels,”
inProceedingsofthe53rdAnnualMeetingoftheAssoci-
[3] Hemant Yadav and Sunayana Sitaram, “A survey of ationforComputationalLinguisticsandthe7thInterna-
multilingualmodelsforautomaticspeechrecognition,” tionalJointConferenceonNaturalLanguageProcessing
arXivpreprintarXiv:2202.12576,2022. (Volume2: ShortPapers),2015,pp.495–500.
[4] BoLi,TaraN.Sainath,KheChaiSim,MichielBacchi- [14] Sumanth Doddapaneni, Gowtham Ramesh, Anoop
ani,EugeneWeinstein,PatrickNguyen,ZhifengChen, Kunchukuttan,PratyushKumar,andMiteshMKhapra,
YanghuiWu,andKanishkaRao, “Multi-dialectspeech “APrimeronPretrainedMultilingualLanguageModels,”
recognitionwithasinglesequence-to-sequencemodel,” arXivpreprintarXiv:2107.00676,2021.
inIEEEInternationalConferenceonAcoustics,Speech
andSignalProcessing(ICASSP),2018,pp.4749–4753. [15] Jonas Pfeiffer, Aishwarya Kamath, Andreas Rücklé,
KyunghyunCho,andIrynaGurevych, “AdapterFusion:
[5] VikasJoshi,AmitDas,EricSun,RupeshRMehta,Jinyu Non-destructivetaskcompositionfortransferlearning,”
Li,andYifanGong, “MultipleSoftmaxArchitecturefor inProceedingsofthe16thConferenceoftheEuropean
StreamingMultilingualEnd-to-EndASRSystems,” in ChapteroftheAssociationforComputationalLinguis-
ProceedingsInterspeech,2021,pp.1767–1771. tics: MainVolume,Online,Apr.2021,pp.487–503.
[6] VineelPratap,AnuroopSriram,PadenTomasello,Awni [16] JonasPfeiffer,NamanGoyal,XiVictoriaLin,XianLi,
Hannun,VitaliyLiptchinsky,GabrielSynnaeve,andRo- JamesCross,SebastianRiedel,andMikelArtetxe, “Lift-
nan Collobert, “Massively multilingual asr: 50 lan- ingthecurseofmultilingualitybypre-trainingmodular
guages,1model,1billionparameters,” arXivpreprint transformers,” inProceedingsofthe2022Conferenceof
arXiv:2007.03001,2020. theNorthAmericanChapteroftheAssociationforCom-
putationalLinguistics: HumanLanguageTechnologies,
[7] GentaIndraWinata,GuangsenWang,CaimingXiong,
NAACL 2022, Seattle, WA, United States, July 10-15,
andStevenC.H.Hoi, “Adapt-and-adjust: Overcoming
2022,2022,pp.3479–3495.
thelong-tailproblemofmultilingualspeechrecognition,”
inInterspeech,2020. [17] ZhenHuang,TimNg,LeoLiu,HenryMason,Xiaodan
Zhuang,andDabenLiu, “SNDCNN:Self-normalizing
[8] AnjuliKannan,ArindrimaDatta,TaraNSainath,Eugene
deep CNNs with scaled exponential linear units for
Weinstein,BhuvanaRamabhadran,YonghuiWu,Ankur
speechrecognition,” inIEEEInternationalConference
Bapna, Zhifeng Chen, and Seungji Lee, “Large-scale
onAcoustics,SpeechandSignalProcessing(ICASSP),
multilingualspeechrecognitionwithastreamingend-to-
2020,pp.6854–6858.
endmodel,” inProceedingsInterspeech,2019.