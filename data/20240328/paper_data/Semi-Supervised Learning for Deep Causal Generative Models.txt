Semi-Supervised Learning for
Deep Causal Generative Models
Yasin Ibrahim1, Hermione Warr1, and Konstantinos Kamnitsas1,2,3
1 Department of Engineering Science, University of Oxford, Oxford, UK
{firstname.lastname}@eng.ox.ac.uk
2 Department of Computing, Imperial College London, London, UK
3 School of Computer Science, University of Birmingham, Birmingham, UK
Abstract. Developing models that can answer questions of the form
“How would x change if y had been z?” is fundamental for advancing
medical image analysis. Training causal generative models that address
such counterfactual questions, though, currently requires that all rel-
evant variables have been observed and that corresponding labels are
availableintrainingdata.However,clinicaldatamaynothavecomplete
recordsforallpatientsandstateoftheartcausalgenerativemodelsare
unabletotakefulladvantageofthis.Wethusdevelop,forthefirsttime,
a semi-supervised deep causal generative model that exploits the causal
relationshipsbetweenvariablestomaximisetheuseofallavailabledata.
We explore this in the setting where each sample is either fully labelled
or fully unlabelled, as well as the more clinically realistic case of having
different labels missing for each sample. We leverage techniques from
causal inference to infer missing values and subsequently generate real-
isticcounterfactuals,evenforsampleswithincompletelabels.Codewill
be available at: https://github.com/yi249/ssl-causal
Keywords: Causal Inference · Semi-Supervised · Generative Models
1 Introduction
The deployment of deep learning models to real-world applications faces a va-
riety of challenges [16], with many arguing that this is due to lack of causal
considerations [4,18]. A growing research area is the generation of counterfac-
tuals (CFs), the manifestation of a sample in an alternative world where an
upstreamvariablehasbeenchanged[10,17,21].Suchtechniquesareparticularly
useful in medical image analysis, where models are often hampered by lack of
diversity in training data [5], so methods to generate realistic synthetic samples
from underrepresented classes are critical [13]. Incorporating structural causal
equations into a deep learning framework has been shown to provide a powerful
toolforcounterfactualgeneration[17].Theseideaswereextendedbydeveloping
ahierarchicalVAEstructureforgreaterimagefidelity[7].Thismethodconsists,
however, of a separately trained generative model and structural causal model,
represented by a directed acyclic graph (DAG), and hence, the two components
4202
raM
72
]GL.sc[
1v71781.3042:viXra2 Y. Ibrahim et al.
are unable to leverage information from one another during training. Moreover,
thesemethodsrelyonfullylabelled samples,soareunabletouseadditionaldata
where true values are unavailable for some (or all) variables of the causal graph.
Data with limited labels are ubiquitous, so semi-supervised methods are of par-
ticular interest. A common approach to semi-supervised learning is consistency
regularisation under transformations of the input [1,11,22]. Alongside our gen-
erative model, we present this approach from a causal perspective and demon-
strate how it fits naturally into our framework. Semi-supervised methods also
have a causal motivation [19] due to the principle of independence of cause and
mechanism (ICM) [18], which suggests that possessing information on the effect
(image) alone is beneficial for learning the joint distribution of cause (labels)
and effect. In summary, we make the following contributions:
– Introduce a semi-supervised deep causal generative model,
– Generate and evaluate counterfactuals with missing causal variables,
– Provide a causal perspective on the consistency regularisation technique for
semi-supervised learning,
– InspiredbytheICM,investigatetheperformanceofourmethodwhenparent
variables are missing versus when child variables are missing.
Toillustratethis,wefirstuseasemi-syntheticdatasetbasedonMorpho-MNIST
[6]whichallowsustoexplicitlymeasureperformancegiventheknownunderlying
causal relationships. We then assess our method on the MIMIC-CXR dataset
[9,12] to demonstrate its capabilities on real, more complex, medical data.
2 Background
A (Markovian) Structural Causal Model (SCM) is a 4-tuple [21]:
M=⟨V,U,F,P(U)⟩
where, V = {v ,...,v } is the set of endogenous variables of interest, U =
1 n
{u ,...,u } is the set of exogenous (noise) variables, P(U) is the prior dis-
1 n
tribution over them, and F = {f ,...,f } is a set of functions. Moreover, we
1 n
assumethateachendogenousvariable,x ,isassigneddeterministicallybyitsdi-
i
rectcauses,i.e.itsparentspa ⊆V\{v },andthecorrespondingnoisevariable,
i i
u via the structural assignments,
i
v :=f (pa ,u ). (1)
i i i i
This supersedes conventional Bayesian approaches as it allows for greater con-
trol by explicitly considering the structural relationships between variables. We
achieve this through the do-operation [3], which makes assignments of the formSemi-Supervised Learning for Deep Causal Generative Models 3
do(x = a). This disconnects x from its parents, and we obtain an intervened
i i
distribution over the endogenous variables,
(cid:89)
P(V|do(v =a))= p(v |pa ,v =a).
i j j i
j̸=i
However, such interventions provide only population-level effect estimations [3].
To narrow this down to unit-level and generate counterfactuals for individual
samples, the following procedure is carried out [18]:
1. Abduction: Use the data to update the prior probability on the exogenous
noise p(U) to obtain p(U|V)
2. Action: Perform an intervention do(V = A) to obtain a modified SCM,
denoted by M˜ .
do(V=A)
3. Prediction: Use M˜ to estimate the values of the desired variables.
do(V=A)
3 Methodology
Fig.1:Modeloutline.Green:observed,Grey:latent,Red:predicted,Blue:causal
generative,Yellow:decoding.(left)Training;weusethey predictionsfordecod-
ing unless they are observed, (right) CF generation.
Overview of our method is shown in Fig. 1. Herein, the endogenous variables
consistofimage,x,andvariables,y;denotedbyy∗whenobservedandbyy′when
predicted. Latent variables z =z make up part of the exogenous noise for x,
1:L
modelledusingahierarchicallatentstructureinspiredby[20].Ourmodelextends
their structure with a predictive part that infers the endogenous variables, y,
enabling counterfactual generation in the case of missing labels. For clarity, we
limitderivationstothecasewithasinglecausevariable,y ,andeffectvariable,
C
y , but this can be extended to any finite number of variables with any causal
E
structure.TheELBOlossforfullylabelledsamplesdrawnfromD isS(x,y):
L
(cid:20) (cid:21)
p (x|z,y ,y )p (z)p (y |y )p (y )
logp (x) ≥ E log θ E C θ θ E C θ C
θ qϕ(z|x,yE,yC) q (z|x,y ,y )
ϕ E C
⇒S(x,y):= −L(x,y)−logp (y |y )−logp (y )
θ E C θ C4 Y. Ibrahim et al.
whereL(x,y)istheELBOforaconditionalVAEandp (·)are(Gaussian)priors.
ϕ
For the unlabelled samples, drawn from D , we minimise the loss:
U
U(x):=−E (cid:2)E (L(x,y)−D {q (y |x,y )||p (y )})(cid:3)
qϕ(yE|x) qϕ(yC|x,yE) KL ϕ C E θ C
(2)
+D {q (y |x)||p (y |y )}.
KL ϕ E θ E C
Here, we predict the labels using y′ ∼ q (y|x) and regularise them via the KL-
ϕ
divergencewiththeirrespectivepriorp (y).Whenonly cause y is labelled,
ϕ C
for samples (x,y )∈D , we minimise the loss:
C C
C(x,y ):=−E [L(x,y)]−logp (y )+D {q (y |x)||p (y |y )}. (3)
C qϕ(yE|x) θ C KL ϕ E θ E C
When only effect y is labelled, we minimise the loss:
E
E(x,y ):=−E [L(x,y)+logp (y |y )]+D {q (y |x,y )||p (y )},
E qϕ(yC|x,yE) θ E C KL ϕ C E θ C
for samples (x,y )∈D . In the case of discrete variables, when the true labels,
E E
y∗, are not provided, we supplement these losses by inversely weighting sam-
ples with missing labels by the entropy of the labels predicted by the encoder,
H (y′|x). For example, when y is missing, we multiply the expectation in (3)
ϕ E
by1−H (y′ |x).Weuseentropyhereasanindicatorforpredictiveuncertainty,
ϕ E
to inform us how much to ‘trust’ the predicted label.
Under this construction, the parent predictors, q (y |x) and q (y |x,y ), are
ϕ E ϕ C E
only trained when the parent variables are unobserved. To ensure the model
is able to learn a good representation of y, we include additional classification
terms in the supervised loss [14], giving the total loss to train our model:
(cid:88) (cid:88) (cid:88)
T(x,y):= S(x,y)+ U(x)+ C(x,y )
C
(x,y)∈DL x∈DU (x,yC)∈DC
(4)
(cid:88)
+ E(x,y )−E [logq (y |y ,x)]
E (x,y)∈DL ϕ i <i
(x,yE)∈DE
In the last term, labeled variables y are placed in a topological ordering [8]
i
starting with the root nodes. Thus for all i, the ancestors of y are a subset of
i
y and its descendants are a subset of y . In (2), we see that in the unlabelled
<i >i
case, we require expectations over the labels. For a single discrete label y, this
can be achieved by summing over all possible values of y [14],
(cid:88)
E [f(y,·)]= q (y|x)·f(y,·).
qϕ(y|x) ϕ
y
However,thisquicklybecomescomputationallyexpensiveasthenumberofvari-
ablesorclassesgrows,andisintractableforcontinuousvariables.Weavoidusing
a Monte-Carlo sampler, where taking more samples leads to similar computa-
tional costs. Instead, we propose lowering this variance by beginning training
using only the labelled data. By doing so, predictors q (·|x) reach a sufficiently
ϕ
high accuracy before being used to estimate missing labels for the rest of the
data.Semi-Supervised Learning for Deep Causal Generative Models 5
Counterfactual Regularisation To further improve our model, we turn to a
causal treatment of consistency regularisation [22]. For this, we restrict pertur-
bations of the input image to interventions on the DAG governing the causal
variables. For example, for input image x with variables (y ,y ), we alter ef-
C E
fect variable y via do(y = e˜), to obtain new image x˜ with causal variables
E E
(y˜ ,y˜ ).IftheDAGisobeyed,thecausevariableshouldremaininvarianttothis
C E
perturbation and we can thus impose a loss that penalises divergence between
y and y˜ . In the context of our model, we predict y˜ ∼ q (·|x˜) and minimise
C C C ϕ
D(y ,y˜ ),whereD(·,·)isanappropriatedistancemetric.Ify isunknown,we
C C C
predict its value using y ∼ q (·|x). Suppose instead we alter the cause vari-
C ϕ
able; in this case, the effect should change given the DAG. As such, we predict
y˜ ∼q (·|x˜) and then compute the counterfactual of y under the proposed in-
E ϕ E
tervention on y . When y is unlabelled, we first predict it using y ∼q (·|x).
C E E ϕ
This causal interpretation improves the robustness not only of the generative
component of the model, but also the causal inference elements, p (y |y ).
θ i <i
Counterfactual Generation Oncethegenerativemodelistrained,weusethe
predictivecomponentp(y |y )togeneratecounterfactuals,x˜.Forabductionwe
i <i
requirethestructuralassignments(1)tobeinvertibleinu,soweencodep(y |y )
i <i
as an invertible g (u), u∼p(u), parameterised by the causal parents y [17].
Counterfactual gey n< ei ration can then be expressed as y˜ =g (cid:0) g−1(y )(cid:1)< soi that
i y˜<i y<i i
each counterfactual value can be calculated in sequence. If a label y is missing,
i
weuseourtrainedpredictorq (y |x,y )toimputeit,e.gFig.1(right)forwhen
ϕ i >i
y is unobserved and we intervene on y .
E C
4 Experiments
Fig.2: (a) DAG for Colour MorphoMNIST, d: digit, f: foreground (digit) color,
b: background color, t: thickness, i: intensity. (b) DAG for MIMIC-CXR, s: sex,
a: age, d: disease status, r: race. U: respective exogenous noise variables.
4.1 Causal Analysis on Colour Morpho-MNIST
True causal generative processes for medical imaging data are unknown. There-
fore, to evaluate the causal aspects of our method in depth, we first use data6 Y. Ibrahim et al.
(a) Supervised vs SSL vs Flexible. (b) SSL+Flexible for very few labels.
Fig.3:ColourMorpho-MNIST:Accuracyofdo(d=k)onrandomtestimagesfor
uniformlyrandomk ∈{0,...,9}\dwheredisthedigitoftheoriginalimage.For
SSL, the x-axis represents to the number of fully labelled samples; for Flexible
it represents the number of labels for each variable across all the samples. For
SSL+Flexibleweuse600randomlyallocatedlabelsforeachvariableinaddition
to the number of fully labelled samples denoted by the x-axis.
adapted from Morpho-MNIST (60k training, 10k test samples) [6], considering
the thickness (t) and intensity (i) of each digit. We increase the complexity of
the causal structure by colouring the foreground (f) and background (b), with
eachcolourdrawnfromadistributionconditionalonthedigit(d),asinFig.2a.
Counterfactual Effectiveness As baseline, we use the state of the art super-
visedmethodforcounterfactualimagegeneration[7]trainedonlyonthelabelled
samplesofeachexperiment.Wecomparethisagainstourmethodforalabelled-
unlabelledsplit(SSLinfigures)andforlabelsmissingrandomlyforeachvariable
(Flexible). We measure the effectiveness [15] of our counterfactual generations
by abducting and intervening on test images with random interventions before
usingclassifiersorregressors,q(·|x),trainedindependentlyonuncorrelateddata,
to measure how well the desired change has been captured.
Table 1: Colour Morpho-MNIST: Log likelihoods of the child variables. Colour
log likelihoods ∈(−∞, 2.239], intensity log likelihoods ∈(−∞, −1.336].
Model Labelled MAE p (f) p (b) p (i,t) q(f|x˜) q(b|x˜) q(i,t|x˜)
θ θ θ
1000 3.91 -1.46 -1.49 -38.21 -1.01 -1.17 -32.98
Supervised 5000 3.84 -1.31 -1.38 -21.38 -0.63 -0.93 -28.44
60,000 3.75 1.20 1.24 -5.55 1.17 1.18 -14.42
1000 3.85 1.05 1.10 -14.26 0.81 1.08 -26.02
SSL
5000 3.83 1.10 1.12 -7.40 1.01 1.19 -22.39
1000 3.86 1.11 1.13 -17.93 0.77 1.15 -28.20
Flexible
5000 3.84 1.14 1.16 -13.98 1.07 1.10 -19.56
Fig. 3a highlights the improvement by our method over the purely supervised
approach.Evenwhenonly1000samples(∼1.67%)arelabelled,weachievenear
perfect effectiveness for changed digit counterfactuals. This holds both when
the data is split into distinct labelled-unlabelled sets and when these labels areSemi-Supervised Learning for Deep Causal Generative Models 7
missing randomly. Moreover, in Fig. 3b, counterfactual regularisation improves
performance for very low labelled sample sizes by an average of ∼2.2%. Table 1
demonstrates how the causal relationships are learned significantly better using
ourmethod,withregardstoboththedistributionsinferredfromtheDAG,p (·),
θ
and the manifestations of these changes in the counterfactual image, q(·|x˜).
Independence of Cause and Mechanism Inspired by insights on the ICM
[19],weanalysehowourmethodperformsinthespecificcasesofthecausevari-
able missing and the effect present, and vice-versa, by varying the number of
thicknessandintensitylabelswhilekeepingtheothers.Table2(left)showsthat
the settings with greater proportions of intensity (effect) labels tend to produce
better joint distributions, supporting the ICM hypothesis [19]. This is signifi-
cant for domains with limited labelled data such as healthcare, as it suggests
that,givenanidentifiedcause-effectrelationshipandlimitedcapabilitytoobtain
labels, focusing on labelling the effect should provide improved performance.
Table2:(left)Causeandmechanismexperiment.(right)MIMIC-CXRinterven-
tions: rows are 10%, 20%, 30% labelled, all with counterfactual regularisation.
do(t) do(i) Disease(↑) Age(↓) Sex(↑) Race(↑)
i t Sup.SSLFlex.Sup.SSLFlex.Sup.SSLFlex.Sup.SSLFlex.
labelslabelspθ(i,t)(↑)q(i,t|x˜)(↑)||t−t˜||1(↓)||i−˜i||1(↓) do(d)0 0. .5 55 70 0. .6 684 00 .. 762 02 10 9. .9 21 19 7. .1
6
1 17 7. .3
6
0 0. .9 95 40 0. .9 93
3
0 0. .9 93 20 0. .7 71 40 0. .6 71
7
0 0. .6 75
3
300 2700 -19.31 -29.40 0.094 0.320 0.680.750.7717.618.016.920.980.98 0.970.770.80 0.81
0.870.87 0.8816.516.017.5 0.900.94 0.930.720.72 0.74
600 2400 -16.77 -26.99 0.098 0.288 do(a)0.870.94 0.9217.915.315.00.940.94 0.950.710.78 0.77
1200 1800 -18.80 -21.16 0.114 0.231 0.900.98 0.9716.812.512.9 0.980.98 0.980.780.78 0.78
1500 1500 -15.28 -27.08 0.108 0.191 0.840.87 0.8618.719.5 17.2 0.690.740.760.690.67 0.68
do(s)0.860.94 0.9516.517.6 17.7 0.730.810.800.690.75 0.71
1800 1200 -21.05 -20.09 0.110 0.123 0.890.93 0.9016.215.9 16.4 0.780.890.890.770.78 0.77
2400 600 -16.59 -19.97 0.117 0.106 0.840.87 0.8719.320.6 18.7 0.960.94 0.940.460.490.51
2700 300 -14.72 -17.74 0.112 0.092 do(r)0.880.88 0.8717.417.6 17.9 0.950.95 0.960.500.610.60
0.930.92 0.9217.316.3 17.0 0.980.98 0.990.550.670.69
4.2 Counterfactuals for Medical Imaging Data
To evaluate our method on medical imaging data, we apply it to the MIMIC-
CXR dataset (50k training, 20k test samples) [9,12]. We assume the casual
structure used in [7] with variables disease (d), age (a), sex (s), race (r), with
the only non-independence being that a causes d (Fig. 2b). For disease, we use
the presence of pleural effusion as a binary variable and we train models using
10%, 20%, 30%, 40% and 50% of the total labels for each of the three mod-
els (Supervised, SSL, Flexible). As the causal structure is simpler, we measure
performance by intervening on each variable separately before measuring the
accuracy via the ROCAUC for the discrete variables, and the MAE for age.
FromthecellsonthediagonalofTable2(right),weseethatourmethodtendsto
improve upon the supervised approach with regards to implementing interven-
tions. The other cells are essentially a measure of reconstruction quality, since8 Y. Ibrahim et al.
Fig.4:(a)CFRegularisationonMIMIC-CXR.(b)MIMIC-CXRCFsfrommodel
trained on 40% labels. From top-left: (1) original: white, healthy, 20-year-old
male,(2)do(age=90),(3)do(diseased),(4)do(asian),(5)do(female),(6)do(all).
they involve evaluating variables that have not been intervened on. As such,
the closeness of these values for the various models suggests that the achieved
counterfactualgenerationgainsareprimarilyduetodifferencesinthecausalin-
ferencecomponent.Thisindicatesthatitwouldbefruitfultofocusfutureefforts
on improving this section of the model. This holds for both SSL and Flexible,
demonstratingthatpractitionersimplementingourapproachneednotprioritise
achievingfulllabellingforanygivensampleovercollectingasmanylabelsaspos-
sible, bolstering the usability of the model. Fig. 4a demonstrates the increased
interventional accuracy provided by counterfactual regularisation. Moreover, as
shown in Figure 4b, our model is able to exhibit clear visual changes for the
various counterfactuals, indicating the numerical results are not due to minute
changesundetectabletothehumaneye[2].Tobuilduponthis,oneavenueoffu-
tureresearchwouldbetousethisapproachtogenerateadditionaltrainingdata
forunderrepresentedpopulationsinmedicaldatasetsandevaluatehowthisaids
downstream tasks.
5 Conclusion
This study introduces a semi supervised deep causal generative model to enable
trainingoncausaldatawithmissinglabelsinmedicalimaging.Experimentsona
colouredMorpho-MNISTdataset,wherethewholegenerativeprocessisknown,
along with experiments on real clinical data from MIMIC-CXR, demonstrate
that our approach uses unlabelled and partially labelled data effectively and
improvesoverthestateoftheartfullysupervisedcausalgenerativemodels.The
key practical contribution of this work is that it enables training causal models
onclinicaldatabaseswherepatientdatamayhavemissinglabels,whichprevious
modelscouldnotuse,relaxingoneofthemainrequirementsfortrainingacausal
model. A limitation of our work is that we assume the DAG structure is known
apriori.Hence,ifthisismisspecified,therearenoguaranteesonthecorrectness
of the generated counterfactuals. A possible next step could thus be to explore
cases with limited information on the DAG structure of the causal variables.Semi-Supervised Learning for Deep Causal Generative Models 9
6 Acknowledgements
Yasin Ibrahim is supported by the EPSRC Centre for Doctoral Training in
Health Data Science (EP/S02428X/1). The authors also acknowledge the use
of the University of Oxford Advanced Research Computing (ARC) facility in
carrying out this work (http://dx.doi.org/10.5281/zenodo.22558).
References
1. Bachman, P., Alsharif, O., Precup, D.: Learning with pseudo-ensembles. ArXiv
abs/1412.4864 (2014) 2
2. Banerjee, I., Bhimireddy, A.R., Burns, J.L., Celi, L.A., Chen, L.C., Correa, R.,
Dullerud,N.,Ghassemi,M.,Huang,S.C.,Kuo,P.C.,Lungren,M.P.,Palmer,L.J.,
Price,B.,Purkayastha,S.,Pyrros,A.,Oakden-Rayner,L.,Okechukwu,C.,Seyyed-
Kalantari, L., Trivedi, H., Wang, R., Zaiman, Z., Zhang, H., Gichoya, J.W.: Ai
recognition of patient race in medical imaging: a modelling study. The Lancet.
Digital health 4, e406 – e414 (2021) 8
3. Bareinboim, E., Correa, J.D., Ibeling, D., Icard, T.F.: On pearl’s hierarchy and
thefoundationsofcausalinference.ProbabilisticandCausalInference(2022) 2,3
4. Bengio,Y.,Courville,A.C.,Vincent,P.:Representationlearning:Areviewandnew
perspectives.IEEETransactionsonPatternAnalysisandMachineIntelligence35,
1798–1828 (2012) 1
5. CoelhodeCastro,D.,Walker,I.,Glocker,B.:Causalitymattersinmedicalimaging.
Nature Communications 11 (12 2020) 1
6. Castro, D.C., Tan, J., Kainz, B., Konukoglu, E., Glocker, B.: Morpho-MNIST:
Quantitative assessment and diagnostics for representation learning. Journal of
Machine Learning Research 20(178) (2019) 2, 6
7. De Sousa Ribeiro, F., Xia, T., Monteiro, M., Pawlowski, N., Glocker, B.: High
fidelity image counterfactuals with probabilistic causal models. In: Proceedings of
the 40th International Conference on Machine Learning. Proceedings of Machine
Learning Research, vol. 202, pp. 7390–7425 (07 2023) 1, 6, 7
8. Gagrani,M.,Rainone,C.,Yang,Y.,Teague,H.,Jeon,W.,Hoof,H.V.,Zeng,W.W.,
Zappi, P., Lott, C., Bondesan, R.: Neural topological ordering for computation
graphs (2022) 4
9. Goldberger,A.L.,Amaral,L.A.N.,Glass,L.,Hausdorff,J.M.,Ivanov,P.C.,Mark,
R.G., Mietus, J.E., Moody, G.B., Peng, C.K., Stanley, H.E.: Physionet: Compo-
nents of a new research resource for complex physiologic signals”. circu-lation vol
(2000) 2, 7
10. Hess, K., Melnychuk, V., Frauen, D., Feuerriegel, S.: Bayesian neural controlled
differentialequationsfortreatmenteffectestimation.In:TheTwelfthInternational
Conference on Learning Representations (2024) 1
11. Hu, W., Miyato, T., Tokui, S., Matsumoto, E., Sugiyama, M.: Learning discrete
representationsviainformationmaximizingself-augmentedtraining.ArXiv(2017)
2
12. Johnson,A.E.W.,Pollard,T.J.,Berkowitz,S.J.,Greenbaum,N.R.,Lungren,M.P.,
yingDeng,C.,Mark,R.G.,Horng,S.:Mimic-cxr,ade-identifiedpubliclyavailable
database of chest radiographs with free-text reports. Scientific Data 6 (2019) 2, 7
13. Jones, C., Castro, D.C., Ribeiro, F.D.S., Oktay, O., McCradden, M., Glocker, B.:
Nofairlunch:Acausalperspectiveondatasetbiasinmachinelearningformedical
imaging (2023) 110 Y. Ibrahim et al.
14. Kingma,D.P.,Rezende,D.J.,Mohamed,S.,Welling,M.:Semi-supervisedlearning
with deep generative models 4
15. Monteiro,M.,Ribeiro,F.D.S.,Pawlowski,N.,Castro,D.C.,Glocker,B.:Measuring
axiomatic soundness of counterfactual image models (2023) 6
16. Paleyes, A., Urma, R.G., Lawrence, N.D.: Challenges in deploying machine learn-
ing: A survey of case studies. ACM Computing Surveys 55, 1 – 29 (2020) 1
17. Pawlowski, N., Castro, D.C., Glocker, B.: Deep structural causal models for
tractable counterfactual inference. In: Advances in Neural Information Process-
ing Systems (2020) 1, 5
18. Peters, J., Janzing, D., Scho¨lkopf, B.: Elements of Causal Inference: Foundations
and Learning Algorithms. Adaptive Computation and Machine Learning, MIT
Press (2017) 1, 2, 3
19. Scho¨lkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., Mooij, J.: On
causal and anticausal learning. Proceedings of the 29th International Conference
on Machine Learning, ICML 2012 2 (06 2012) 2, 7
20. Sønderby, C.K., Raiko, T., Maaløe, L., Sønderby, S.K., Winther, O.: Ladder vari-
ational autoencoders 3
21. Xia,K.,Lee,K.Z.,Bengio,Y.,Bareinboim,E.:Thecausal-neuralconnection:Ex-
pressiveness,learnability,andinference.In:NeuralInformationProcessingSystems
(2021) 1, 2
22. Xie, Q., Dai, Z., Hovy, E.H., Luong, M.T., Le, Q.V.: Unsupervised data augmen-
tation for consistency training. arXiv: Learning (2019) 2, 5