Usage-Specific Survival Modeling Based on
Operational Data and Neural Networks
OlovHolmer∗MattiasKrysander∗ErikFrisk∗
∗DepartmentofElectricalEngineering,Linko¨pingUniversity,SE-58183
Linko¨ping,Sweden,(e-mail:name.lastname@liu.se).
Abstract:Accuratepredictionsofwhenacomponentwillfailarecrucialwhenplanningmaintenance,and
bymodelingthedistributionofthesefailuretimes,survivalmodelshaveshowntobeparticularlyuseful
inthiscontext.Duetothecomplexbehaviorofdegradation,describingthisdistributionisoftenacomplex
problemanddata-drivenmethodsareoftenpreferred.Inthispaper,amethodologytodevelopdata-driven
usage-specificsurvivalmodelsthatpredictthedistributionoftheremaininglifeofacomponentbased
on its usage history is presented. The methodology is based on conventional neural network-based
survival models that are trained using data that is continuously gathered and stored at specific times,
calledsnapshots.Animportantpropertyofthistypeoftrainingdataisthatitcancontainmorethanone
snapshotfromaspecificindividualwhichresultsinthatstandardmaximumlikelihoodtrainingcannot
bedirectlyappliedsincethedataisnotindependent.However,thepapersshowthatifthedataisina
specificformatwhereallsnapshottimesarethesameforallindividuals,calledhomogeneouslysampled,
maximumlikelihoodtrainingcanbeappliedandproducedesirableresults.Inmanycases,thedataisnot
homogeneouslysampledandinthiscase,itisproposedtoresamplethedatatomakeithomogeneously
sampled.Howdenselythedatasetissampledturnsouttobeanimportantparameter;itshouldbechosen
largeenoughtoproducegoodresults,butthisalsoincreasesthesizeofthedatasetwhichmakestraining
slow.Toreducethenumberofsamplesneededduringtraining,thepaperalsoproposesatechniqueto,
insteadofresamplingthedatasetoncebeforethetrainingstarts,randomlyresamplethedatasetatthestart
ofeachepochduringthetraining.Theproposedmethodologyisevaluatedonbothasimulateddataset
andanexperimentaldatasetofstarterbatteryfailures.Theresultsshowthatifthedataishomogeneously
sampledthemethodologyworksasintendedandproducesaccuratesurvivalmodels.Theresultsalso
showthatrandomlyresamplingthedatasetoneachepochisaneffectivewaytoreducethesizeofthe
trainingdataandatthesameimprovetheperformanceoftheresultingmodel.
Keywords:Data-driven;Machinelearning;Survivalanalysis;Time-to-eventmodeling
1. INTRODUCTION specific age. Dhada et al. (2023) used a similar approach but
includedusagedatafromgatheredatmultipletimesduringthe
components’lifetime;however,predictionsweredonebasedon
Inmanyapplications,maintenancecostsmakeupasignificant aspecifictimeandthereforeonlyonepredictionpercomponent
portionofasystem’stotalcost.Toavoidunnecessarymainte- wasmade.InLietal.(2022)theageofthecomponentatthe
nanceitisthereforeofinteresttodeterminetheremaininguseful timeofpredictionwasincludedasinputtothemodelmakingit
lifeofthecomponentsothatmaintenancecanbeplannedaslate possibletousethemodelatanyage.However,whiletheresults
aspossible.Inmanycases,thedegradationisnotadeterministic fromthiswrokeareimpressive,thedatausedtotrainthemodel
processandpredictingexactlywhenacomponentwillfailisnot containsmultipledatapointsfromthesameindividualsandis
possible,makingastatisticaldescriptionmoreuseful.Survival thereforenotindependent,makingstandardtrainingtechniques
modelsprovidesuchadescriptionbypredictingtheprobability notdirectlyapplicable,anditisnotdiscussedwhythemethod
thatthecomponentwillsurvivelongerthanaspecifictime.Due worksorifitwillworkinotherapplications.
to the complex behavior of system degradation, such models
In conclusion, a more general definition of a usage-specific
areoftendifficulttofind,andthereforedata-drivenmethodsare
survivalfunctionthatconsidersoperationaldatagatheredduring
attractive.
anytimeintervalismissing;aswellasamethodologytotrain
While other methods like random survival forests (Ishwaran thesetypesofmodelswhenthereismorethanoneobservation
etal.,2008)exist,neuralnetwork-basedsurvivalmodelshave from each individual. The aim of this paper is therefore to
beenshowntoperformparticularlywell,andmultiplemodels addressthesetwoproblems.
havebeenproposedforthis,seeforexampleBrownetal.(1997),
Biganzolietal.(1998),KvammeandBorgan(2021),andChing 2. SURVIVALMODELING
et al. (2018). However, these models are defined in a more
generalsetting,andtousethemforpredictingtheremaininglife
SurvivalmodelsdescribethedistributionofthefailuretimeT,
ofacomponentisnotalwaysclear.
oftenconditionedonanexplanatoryvariableX.Theyareoften
How a component is used often affects its useful life, and it specifiedusingthesurvivalfunction,definedas
is therefore of interest to base the predictions on operational (cid:90) ∞
data gathered as the component is used. Since degradation is S(t;x)=P(T >t|X =x)= f(τ;x)dτ (1)
often accumulative, the period during which the operational t
data is gathered can greatly affect the predictions. In Holmer where f is the corresponding failure probability density. In
et al. (2023) this was solved by only considering operational general,therearemanydensityfunctionsf suchthat(1)holds,
datauptoaspecificageofthecomponent,whichmeansthat andthepair(S,f)isthusneededtospecifyasurvivalmodel;
the resulting model can only be used for predictions at this however,inmostcases,thisisamoretheoreticalproblem,and
4202
raM
72
]GL.sc[
1v93781.3042:viXrawewillinmostcasesonlyusethesurvivalfunctionS tospecify Inthiswork,theenergy-basedapproachinHolmeretal.(2023)
amodel. is used. In this approach, a continuous survival function is
definedbyspecifyingthedensityfunctionofT as
2.1 SurvivalDataandCensoring e−Eθ(t;x) (cid:90) ∞
f(t;x)= , Z(x)= e−Eθ(t;x)dt (6)
Z(x)
Ingeneral,notallindividualsaremonitoreduptothetimethey 0
failsince,forexample,theexperimentendsorbecauseofsome
wheretheenergyE θ(t;x)istakenastheoutputfromaneural
otherunconsideredfailureinthesystem.Thismeansthatthe
network, parameterized by θ; and the normalization constant
datacontainsright-censoringandthedatafromN individualsis Z(x) is evaluated numerically, for details on this see Holmer
etal.(2023).Thesurvivalfunctionisthencalculatedas
ontheform
D ={(τ i,δ i,x i)}N
i=1
(2)
Sˆ
(t;x)=1−(cid:90) t
f(τ;x)dτ
=1−(cid:90) t e−Eθ(τ;x)
dτ (7)
θ
where τ is the recorded time, δ is the indicator (δ = 1 for Z(x)
i i i 0 0
a failure, and δ = 0 for a censoring), and x is the covariate
i i where, again, the integral is evaluated numerically. Since the
vectorofindividuali.
energyE (t;x)isspecifiedbyaneuralnetwork,thismodelcan
θ
essentiallybecomeasexpressiveasdesired;however,thiscomes
2.2 Likelihood atthecostofthetwonumericalintegrations.
A likelihood function is defined based on a statistical model 3. USAGE-SPECIFICSURVIVALMODELINGBASEDON
describingthedistributionofthedata.Sincethemodelinour OPERATIONALDATA
caseonlydescribesthedistributionofasingleobservationitcan
notbeuseddirectlytodefinealikelihoodfunction.However,by Wewillnowconsidertheproblemofpredictingthedistribution
assumingthattheobservationsareindependentthemodelfor of the failure time given the available operational data up to
thecompletedatasetfactorsintoaproductofthemodelforeach a specific age. The main difference compared with Section 2
observation.Aconsequenceofthisisthatthelikelihoodfunction isthattheexplanatoryvariablesnowarebasedonaggregated
itself can be written as a product of the likelihood of each system usage, which varies over time, and the main topic of
observation.Thismeansthatinthiscasedefiningalikelihood thesectionistodefinetheusage-specificsurvivalfunctionand
functionbasedonindependentobservationsisstraightforward, developandtrainthesetypeofmodels.
aslongasthelikelihoodofasingleobservationisknown.
3.1 OperationalDataandSnapshots
Given a survival model parameterized by θ, with survival
function S and density f , the likelihood of the observation
θ θ
(τ,δ,x)canbedefinedas Inmanycases,howasystemisusedgreatlyaffectsthelifetime
ofthesystem,andinformationaboutthisisusefulforpredicting
(cid:26)
L(θ |(τ,δ,x))=
f θ(τ,x), δ =1
. (3)
when the system will fail. In this work, we assume that a
S (τ,x), δ =0 snapshot x(t ) with information about how the system has
θ 0
beenuseduptoaget isavailable.Thesnapshotx(t )could
Assumingthattheobservationsfromeachindividualareinde- 0 0
essentiallycontainanyinformationabouthowthesystemhas
pendent,thelikelihoodofthedataset(2)factorsinto
been used, and the only requirement is that it can be used as
(cid:89) (cid:89)
L(θ |(τ,δ,x))= f (τ ,δ ,x ) S (τ ,δ ,x ). aninputtoaneuralnetwork.Inpractice,however,atrade-off
θ i i i θ i i i
between the amount of information stored in x(t ) and the
i:δi=1 i:δi=0
amount of storage needed to store it must be
don0
e. For this
(4)
reason,weinthisworkmainlyconsidersnapshotsontheform
Inpractice,theproductaboveisnumericallydifficulttowork
withandinsteadthelog-likelihoodisused,definedas (cid:90) t0
x(t )= g(y(t))dt (8)
(cid:88) 0
l(θ |(τ,δ,x))= logf θ(τ i,δ i,x i) 0
i:δi=1
. (5)
where y(t) denote the available measurements and control
(cid:88) signals at time t, and g is a function specifying how y(t) is
+ logS (τ ,δ ,x )
θ i i i aggregated.
i:δi=0
A simple example of a function g is g(y) = y which can
be interpreted as accumulated usage; for example, if y is the
2.3 Neural Network-Based Survival Models and Maximum
velocity of a truck then x(t ) would in this case be the total
LikelihoodTraining 0
mileageuptoaget .Anotherexampleis
0
(cid:26)
1, y ≤y
Thedependenciesontheexplanatoryvariablesareoftencomplex g(y)= thres (9)
makingdata-drivenmethodsforpredictingthesurvivalfunction 0, y >y thres
attractive,andinparticularNeuralnetwork-basedapproaches
wherey isathreshold.Inthiscase,x(t )isthetimespent
havebeenshowntoperformwell.From(5)itfollowsthatifa thres 0
withy(t)≥y which,forexample,canbeusedtomeasure
networkparameterizedbyθcanprovidethedensityf andthe thres
θ theamountoftimethepowerproducedbyanenginehasbeen
survivalfunctionS (alongwiththeirgradients),gradient-based
θ aboveaspecificthreshold.Byusingmorethanonethreshold
learningcanbeappliedtomaximizethelog-likelihood.Inthis
ahistogramofhowthecomponenthasbeenusedcanalsobe
context,foreachsample(τ ,δ ,x )thepair(τ ,δ )canbeseen
i i i i i created; most of the features in the dataset in Section 6 are
asthetargetandx thefeatures.
i createdinthisway.
Animportantpartofneuralnetwork-basedsurvivalmodeling
Often data is continuously gathered and stored during the
is to ensure that the pair (S ,f ) defines a proper survival
θ θ systems’ lifetime, and consequently the available data from
model; that is, the relation between S and f in (1) holds,
and f (t,x) ≥ 0. There are several waθ ys to dθ o this, see for eachindividualisasequenceofsnapshots(x(tss))M where
θ i i=1
exampleBrownetal.(1997),Biganzolietal.(1998)Kvamme tss < tss < ··· < tss aretheM timeswhendatawasstored.
1 2 M
andBorgan(2021),Voronovetal.(2020),Chingetal.(2018), However,whenmakingaprediction,onlyonesnapshotisused.
orLietal.(2022). Itisofcourselikelythatusingbyusingasequenceofsnapshotswould resultin better predictions;however, with thenotation the different snapshots. This means that the usual motivation
usedinthisworkx(tss)shouldthenbethatsequence. forthelikelihoodtofactordoesnothold,andcannotbeused
i
toshowthatL˜ isaproperlikelihood.Infact,thereisnothing
3.2 Usage-SpecificSurvivalFunction thatsuggeststhatL˜ isaproperlikelihood,andaswillbeseenin
Section5,itiseasytofindcaseswhereitisnot.Atthesametime,
Asnapshotx(t )describeshowaspecificindividualhasbeen byassumingthatitcanbeusedasaproperlikelihooditis,as
0
used up age t . By interpreting x(t ) as an observation of a willbeshownlater,possibletoextendthemaximum-likelihood
0 0
trainingdescribedinSection2.3tothiscaseinastraightforward
randomvariableX(t ),describingthedistributionoftheusage
0
in a population, the usage-specific survival function can be way.WethereforecallL˜ aquasi-likelihoodandinSection4we
definedas willinvestigateunderwhatcircumstancesitcansubstituteasa
likelihood.
S(t;t ,x)=P (T >t|X(t )=x), (10)
0 0
i.e.,theprobabilityofthefailurehappeningafterttimeunits, Sinceobservationsfromtwodifferentindividualsareassumed
giventheoperationaldatax(=x(t ))ataget . independent, together with the assumption that the quasi-
0 0
likelihoodbehaveslikeaproperlikelihood,itfollowsnaturally
Operational data often contain direct measurements from the
thatthequasi-likelihoodconsideringthecompletedataset(18)
consideredcomponentand,consequently,thereisanimplicit
ofN individualsfactorsinto
implicationthatT >t ,sinceotherwisemeasurementsfromage
0 N
t 0wouldnotbepossible.Ifthisisthecase,itismoreappropriate L˜(θ |D)=(cid:89) L˜(cid:16) θ |τ ,δ ,(cid:8)(cid:0) x(tss),tss(cid:1)(cid:9)Mi (cid:17) . (16)
toconsidertheusage-specificsurvivalfunctiondescribingthe i i i,j i,j j=1
remaininglifeofthecomponent i=1
Sr(t;t ,x)=P (T >t+t |T >t ,X(t )=x). (11)
0 0 0 0
4. MAXIMUMQUASI-LIKELIHOODTRAINING
However, to make the notation simpler, we will focus on
presenting a methodology for predicting total life, and later
in Section 4.5 show how to extend it to predicting remaining Bycomparingthelikelihoodofasinglesnapshot(14)withthe
life. likelihoodintheconventionalcase(5),itcanbeseenthatthey
are essentially the same if we in the snapshot case consider
the pair (x (t ),t ) as the covariate x in the conventional
3.3 SurvivalDataIncludingOperationalData i i,j i,j
case. This means that, by considering each snapshot from all
individualsasasingleobservation,correspondstothedataset
As in the conventional case in Section 2.1, the data from a
specificindividualcontainarecordedtimeτ andanindicatorδ D˜ =∪N (cid:8)(cid:0) τ ,δ ,(cid:0) x(tss),tss(cid:1)(cid:1)(cid:9)Mi
i=1 i i i,j i,j j=1
indicatingifitwasafailureorcensoring.However,insteadofa
(s
ix
nin d(g
t ivs
il se id)c
)
uo
M
i
a=v l1a ir
f
ii
r
sa ot te
m
hev rte eic
m
ft oo
e
rr
s
ex
t os
1, nsw
t<
he en
t
fo
s
2
ow
s
rm<ha ·v ·e ·a <se tq
s
Mu se .n Tc he eo df as ta am frp ole ms  
(cid:0)
τ(cid:0) τ ,1 δ,δ ,1 (cid:0), x(cid:0) x (1 ts(
. .
.
sts 1s ,1) ), ,t ts 1 ss s,1(cid:1)(cid:1)
(cid:1)(cid:1)
 ,
(17)
w ah pe or pe uM lati ioi nst
ohD fei Nn=
u im
n(cid:16) dbτ iei v,
r
iδ doi uf, a(cid:8)
s
ln(cid:0) sax
tp
hi s( ehts i do,s aj ts) ta, ft
r
ios i s,s mj o(cid:1) n(cid:9)
in
tM j hd= ei i1 v(cid:17)
fi od ru
mali,and(1 fo2 r) = (cid:0)
τ
,(cid:0)1 δτ 2,1 ,δ (cid:0)2 x,(cid:0)1 x (2 ts1 (
.
. .
st,M s 2s ,11 ), )t ,s 21 ts ,, s1M s(cid:1)1(cid:1) (cid:1)(cid:1)
D
=(cid:110)(cid:16)
τ ,δ
,(cid:8)(cid:0)
x
(tss),tss(cid:1)(cid:9)Mi (cid:17)(cid:111)N
. (13) maximizing the
quN asi-N likeliN hooN d,M (1N
6)
foN r, tM hN
e dataset D is the
i i i i,j i,j j=1 i=1 same as maximizing the conventional likelihood (4) for the
Animportantdifferencecomparedtotheconventionalcaseis
datasetD˜.Consequently,ausage-specificsurvivalmodelcan
thatthedatacontainsM snapshotsfromsubjecti,andtherefore be trained using maximum-likelihood training described in
i
M different predictions can be made, one for each time tss. Section2.3bysimplyusingthedatasetD˜.
i i,j
Thisisespeciallyimportantwhenitcomestodeterminingthe
This means that in principle any method for training conven-
likelihood.
tionalsurvivalmodelscanbeusedfortrainingusage-specific
survival models. However, it remains to show under what
3.4 Likelihood circumstancesmaximizingthequasi-likelihoodgivesthedesired
result.
In the case of a single snapshot (τ ,δ ,(x(tss),tss)) from
i i i i
individuali,thelikelihoodcanbedefinedsimilarlyasbeforeas 4.1 AnExampleWheretheQuasi-LikelihoodisInappropriate
(cid:26) f (τ ;tss,x ), δ =1
L(θ |τ i,δ i,(x(ts is),ts is))= Sθ (τi ;ti ss,xi ), δ =0. (14) Wewillheregiveanillustrativeexamplewhenmaximizingthe
θ i i i quasi-likelihoodfailstogiveadesirableresult.
Basedonthis,itistemptingtoassumethatthelikelihoodinthe
casewhenthereismorethanonesnapshotfromanindividual InFig.1anillustrativeexampleofdatafromthreeindividuals
canbedefinedastheproductofthelikelihoodbasedonasingle is shown. As can be seen, the accumulative usage is quite
snapshotas similarwhichindicatesthattheindividualsareusedsimilarly,
and therefore predictions about their failure times should be
L˜(cid:16) θ |τ ,δ ,(cid:8)(cid:0) x(tss),tss(cid:1)(cid:9)Mi (cid:17) similar. For example, when considering predictions based on
i i i,j i,j j=1 usageuptoaget = 1,theaccumulativeusageisaround1for
=
(cid:89)Mi
L(cid:0)
θ |τ ,δ
,(cid:0) x(tss),tss(cid:1)(cid:1)
, (15)
a rell asi on nd aiv bi ld eu ca ol ns c, la un sd ionsin wc oe ult dhe befa ti hl au tre afti am ilue rs ea sr oe m2 e, ti2 m.5 e, ba en td we3 ena
i i i,j i,j
2and3time-unitsislikelyforanindividualthatisusedinthis
j=1
way.
andwouldbemotivatedifthedataineachfactorwereindepen-
dent.However,thisisclearlynotthecasesinceallcontainτ However, when looking at the snapshots, it can be seen that
i
andδ ,andinmostcases,therearealsodependenciesbetween the blue individual has 5 snapshots around age t = 1, while
ithe others only have 1. This means that if a model is trained 4.3 HomogeneousResamplingofaDataset
usingthis data,the failure timeof theblue individual will be
overrepresentedandmostlikelytheresultingmodelwillpredict Ifadatasetisnothomogeneouslysampleditisnaturaltotryto
failuretimescloserto2timeunits. transformitintoahomogeneouslysampleddataset,andoneway
todothisistosimplyresamplethedatasetasdescribedbelow.
3
When the snapshots are based on the accumulative data (8),
x(t)isacontinuousfunctionandbyinterpolatingthesnapshots
2 fromindividualianestimatexˆ (t)ofx (t)isobtainedforall i i
times t between thefirst and lastsnapshot. Whilethe type of
interpolationschemetouseprobablydependsonthesituation,
1
wehaveinthisworkusedlinearinterpolation.
0 By defining a sampling grid G = {g 1,g 2,...,g M}, and
resampling each individual on G, a dataset that is by design
0.0 0.5 1.0 1.5 2.0 2.5 3.0
homogeneouslysampledisobtained.However,itisnotalways
t
possible to resample all individuals on each point in G since
interpolationcanonlybedonebetweenthefirstandlastsnapshot,
Fig.1.Anillustrativeexampleshowingtheaccumulativeusage
and G might contain points outside this interval. Instead, by
x(t)forthreeindividual.Includedarealsotheirrespective
lettingI betheindexofallsamplingpointsg ∈Gonwhich
failure times marked by crosses, and times from which i k
individualicanberesampledon,theresampleddatasetcanbe
snapshotsareavailablemarkedwithcircles.
written
Dˆ(G)=(cid:8)(cid:0)
τ ,δ ,{(xˆ (g ),g )}
(cid:1)(cid:9)N
. (20)
Sinceallindividualshavethesamenumberofsnapshotsintotal, i i i k k k∈Ii i=1
itcanalsobeconcludedthattheprobleminthisexampleishow Bycomparingwith(19)weseethatif,forallindividuals,I =
i
thesnapshottimesaredistributedandnothowmanythereare {1,2,...,M }withM asin(19),thenDˆ(G)ishomogeneously
fromeachindividual. i i
sampled.
The condition that I = {1,2,...,M } has two implications:
i i
4.2 HomogeneouslySampledDatasets Thefirstisthatallindividualsmusthaveasnapshotfromatime
beforethefirstsamplingpointinG,sothat1∈I .Thesecondis
i
Aconclusionthatcanbemadefromthepreviousexampleisthat thatallindividualshaveasnapshotfromatimelaterthaneither
foranytimet
0
≥0thenumberofsnapshotsfromatimeclose thelastsamplingpointinG(correspondingtoallM ithesame
tot ,saybetweent −∆tandt +∆tforsome∆t,should andequaltoM),orthelastsamplingpointinGthatissmaller
0 0 0
besimilarforallindividuals,otherwisethepredictionswillbe thanthefailuretimeoftheindividual(correspondingtowhen
biasedtowardsindividualswithmoresnapshotsaroundt 0. M i dependsonthefailuretimein(19)).Inpractice,however,
wehavefoundthatitisoftenenoughthatmostindividualscan
Bytakingtheargumentabovetotheextreme,andsayingthat besampleduniformlyontheselectedgrid.
foranyt ≥ 0and∆t > 0thenumberofsnapshotsbetween
0
t −∆tandt +∆tshouldbethesamefromallindividuals
0 0 4.4 EpochwiseRandomResampling
wegetthefollowingrequirement:ifindividualihasasnapshot
fromtimetthensomustindividualj,sinceotherwise,subjecti
wouldhavemoresnapshotsaroundtimetforsome∆t>0.It ConsideragridGofsizeM points.IfM issmall,itislikely
followsthatthedatafromanyindividualmustcontainasnapshot that the resulting model will only be accurate for predictions
fromtimetandthatthedatamustbeontheform basedonsnapshotsfromtimesaroundthepointsinG,which
can be interpreted as a type of overfitting to the points in G.
(cid:110)(cid:16) (cid:17)(cid:111)N
D = τ ,δ ,{(x (tss),tss)}M (18) Ontheotherhand,ifM islarge,thedatasetwillbecomelarge
i i i k k k=1
i=1 makingthetrainingslow.Acompromisemustthereforebemade
forsomesequenceofsnapshottimes(tss)M . whenchoosingG.
k k=1
AsdiscussedinSection3.2,itisoftennotpossibleordesirable Awaytocircumventthiscompromiseistouseasmallergrid,
tohavesnapshotsfromtimesaftertheindividualhasfailed,and butineachepochchangethegrid.Thatis,inepochnusethe
thereforeitmightbenecessarytorelaxtheconditionslightly grid
(cid:110) (cid:111)
andsaythatthenumberofsnapshotsfromallindividualsthat G = g(n) ,g(n) ,...,g(n) . (21)
havenotfailedbeforetimet +∆tshouldhavethesamenumber n 1 2 M
0
ofsnapshotsbetweent 0−∆tandt 0+∆t.Thisresultsinthat Inthisway,byusingdifferentG nineachepoch,theresulting
all individuals do not need to have a snapshot from all t for model will not be overfitted for a particular grid; at the same
k
k =1,2,...,M,butitisenoughthattheyhavesnapshotsfrom time,thesizeofthedatasetwillbekeptsmall.
alltimessmallerthantheirfailuretime,i.e.foralltss <τ .
k i GeneratingG canofcoursebedoneinmanyways.Totraina
n
Basedonthediscussionsabovewedefinethefollowing. modelthatcanbeusedforpredictionsbasedonsnapshotsfrom
Definition1.(homogeneouslysampled). A dataset (18) is ho-
timesbetweents ms inandts ms ax,weproposetogeneratethegrid
mogeneouslysampledifthereisasequencetss <tss <···< pointsas
ts Ms ofsnapshottimessuchthat
1 2
g(n) =tss +
ts ms ax−ts ms
inu(n) (22)
k min M k
(cid:110)(cid:16) (cid:17)(cid:111)N
D = τ i,δ i,{(x i(ts ks),ts ks)}M k=i 1
i=1
(19) whereu( kn) areindependentanduniformlydistributedbetween
zeroandone.
where either all M are the same (and equal to M) or M =
i i
max{k ∈{1,2,...,M}:tss ≤τ }.
k i 4.5 TrainingforRemaining-LifePredictions
This definition aims to specify when a dataset is suitable for
maximumquasi-likelihoodtraining;withthemotivationthatif Sofarwehaveonlydiscussedhowtotrainamodeltopredictthe
itisnot,theproblemsdiscussedinSection4.1mightarise. totallifeofthecomponent,andnottopredicttheremaininglife.
)t(xHowever,thisissimplydonebyrealizingthatwhenconsidering 5.3 ResamplingtheDataset
themodelSr in(11)fortheremaininglife,thelikelihood14for
asinglesnapshotbecomes
The fact that there is a discontinuity in S(t;x,t ) at t =
(cid:26) fr(τ −t ;t ,x ), δ =1 0 makes it difficult to train a network to produc0 e accu0 rate
L(θ |τ i,δ i,(x(t i),t i))= Sθ θr(τi i−ti i;ti i,xi i), δ =0. p tsr sedict =ion 0s .1aro isun pd utt 0 on= the0. pF reo dr ict th ii os nre tia mso en,
t
a
.
Slo iw nce er mlim osi tt
(23) min 0
individuals tend to fail before one time unit an upper limit
whereτ −t istheremaininglifeatthetimeofthesnapshot.
i i tss = 1 is also used. This means that only snapshot times
Thismeansthatbysimplyexchangingτ forτ −t whencre- max
i i i,j betweenthesetwolimitsneedtobeconsidered.
atingthedataset(17)andapplyingmaximumquasi-likelihood
training,amodelfortheremaininglifeistrained. Bothfixedresamplingandepochwiseresamplingwereusedto
trainmodels.Forfixedresamplinganequidistantgridbetween
tss andtss wasusedandforepochwiserandomresampling
5. ASIMULATEDEXAMPLE min max
thesamplingin(22)wasusedwithtss andtss asthelimits.
min max
In this section, a simulated dataset is used as an example
wherethepropertiesofmaximumquasi-likelihoodtrainingare
investigated. 5.4 TrainingandNetworkArchitecture
We consider a system whose usage U is constant over time,
but varies among individuals as U ∼ Uniform(1,5). For a During training, the dataset was first split into two separate
datasets, one for training and one for validation; 85 % of the
specific usage U = u, the failure times are modeled using a
individualswereusedfortrainingandtherestforvalidation,note
Weibulldistributionwithshapeparameterk =2anduasscale
thatthesplitwasdonebasedonindividualssothatsnapshots
parameter,givingthesurvivalfunction
fromthesameindividualisnotpresentinboththetrainingand
S(t;u)=P(T >t|U =u)=e−(ut)2 (24) validationdata.Eachmodelwastrainedfor200epochsusingthe
Adamoptimizer;however,thestateofthemodelontheepoch
Tomodeltheoperationaldataforagivenusageu,theaccumu-
withthelowestvalidationlosswasusedintheend.
lativeusage
(cid:90) t It was found that a small network with only two layers of 32
x(t)= udτ =ut (25) neurons each is sufficiently expressible for this type of data.
0 Dropout was also evaluated, but it was found that it did not
isused.Thismeansthattheoperationaldataofthepopulationis improve the result. 15 different learning rates between 10−2
describedby
and 0.25 following a geometric progression were evaluated.
X(t)=Ut∼Uniform(t,5t). (26) Sincetherearestochasticelementsinthetraining40different
randomlygeneratedrepresentationsofeachdatasetwereevalu-
atedandthelearningratethatperformedbestonaveragewas
5.1 DatasetGeneration
selected.
TosimulateapopulationofN individuals,foreachiausage To evaluate the models a separate dataset for testing of 500
u is generated from Uniform(1,5) and a failure time is then individualswasutilized.All40modelsforeachrepresentation
i
generated from the distribution in (24). Right-censoring is ofthedatasetwereevaluatedandthemeanofthelosswasnoted.
introducedbygeneratingacensoringtimefromaUniform(0,3)
distribution,andifthefailuretimeislargerthanthecensoring
timetheindividualiscensored.Sincex i(t)islinearintforall 5.5 Results
individuals,onlyonesnapshotfromthetimeoffailureisneeded
sincex (t)canbereconstructedfromthiswhenthedatasetis
i
resampled. Fig.2theresultfromtrainingmodelsondatasetswithavarying
number of individuals, different numbers of samples in the
resampling,andforbothfixedsamplingandepochwiserandom
5.2 TrueUsage-SpecificSurvivalFunction
resampling.Hereitcanbeseenthatincreasingthenumberof
samples (reducing the sampling time) improves the result, at
Abenefitofthisexampleisthatthetrueusage-specificsurvival leastuntilsomepoint.Thisholdsbothforfixedresamplingand
functioncanbedetermined.Fort >0itbecomes epochwiseresampling;however,epochwiseresamplingisless
0
sensitivetothenumberofsamplesandalwaysperformsbetter
S(t;x,t )=P (T >t|X(t )=x)=P (T >t|t U =x)
0 0 0 thanfixedresamplingforthesameamountofdata.Itcanalso
=P
(cid:18)
T >t|U =
tx(cid:19) =S(cid:18)
t;
tx(cid:19) =e−(cid:0)
t tx
0(cid:1)2
b ree suse lte wn hth ica hti in nc dr ie ca as ti en sg ct oh ne sin su tem nb cye .rofindividualsimprovesthe
0 0
(27)
InFig.2alldataishomogeneouslysampledand,asdiscussed
and above, the results are as expected. In Fig. 3 an example of
Sr(t;x,t 0)= S(t+t 0;x,t 0) =e−(cid:0) t tx 0(cid:1)2 +x2 . (28) m iso sd he ol ws ntr .a Tin he ed go rn eed nat la inetha int i ts hin so fit gh uo rm eo cg oe mn ee sou fs roly msa mm op dl ee ld s
S(t 0;x,t 0) trained on a dataset consisting of the union of two datasets
Fort = 0,ontheotherhand,x (t ) = 0andnoinformation both of size 500 individuals and equidistantly sampled, but
0 i 0
abouttheindividualisprovided,instead,wehave oneofthemhasbeensampled10timesmoredensely.Ascan
be seen, the performance of the models trained on the mixed
S(t;x=0,t 0 =0)=P (T >t|X(0)=0) datasetsisclosertotheperformanceofthemodelstrainedonthe
(cid:90) 5 1 (29) homogeneouslysampleddatafrom500individuals,eventhough
= P (T >t|U =u) du thetotalnumberofindividualsinthisdatais1000individuals.
5−1
1 Alogicalexplanationforthisisthatsincethe500individuals
i.e.thepopulationaverage(whichdoesnothaveaconvenient thataresampledwithhigherfrequencyareover-representedin
expression). This also means that there is a discontinuity in thedata,thepredictionsfromtheresultingmodelwillbesimilar
S(t;x,t )att =0. toamodeltrainedonthedatafromthese500individuals.
0 00.32 0.26
N=500, homogeneous
0.30 0.25 N=1000, homogeneous
N=1000, mixed
0.28 0.24
0.26
0.23
0.24
0.22
0.22
0.21
103 104 105
0.0 0.2 0.4 0.6 0.8
Total size of training data
Mean sampling time ( g)
0.32 Fig. 3. Results from models trained using homogeneously
sampleddatasetsaswellasthemixeddatasetcontaining
N=250
twodifferentsamplingdensities.
0.30 N=500
hasspentindifferentintervals.Formoreinformationaboutthe
N=1000
0.28 datasetseeHolmeretal.(2023);Voronov(2020).
Fixed grid
6.2 Training
0.26 Epochwise
Thedatasetwasfirstsplitintothreepartsintheconventional
0.24
way:70%fortraining,15%forvalidation,and15%fortesting.
Tomakesurethatdatafromaspecificvehicleonlyendsupin
0.22 oneofthedatasetsthesplitwasdonebasedonthenumberof
vehiclesinthedatasets.
103 104
ThesametrainingasdescribedinSection5.4wasusedforthis
Mean total size of training data datasetaswell,butwithahyperparametersearchoverlearning
rate,numberofnodesperlayer,andamountofdropout,based
onthesearchspacesinTable1.
Fig. 2. Results from models trained on datasets of three
different sizes, for different numbers of samples in the
Parameter Searchspace
resampling, and for both fixed sampling and epochwise
random resampling. The results are shown both as a Learningrate {0.001,0.00215,0.00464,0.01,0.0215,0.0464,0.1}
Nodesperlayer {64,128,256}
function of the sampling time (distance between two
Dropout {0%,10%,25%,50%}
samplesinthesamplinggrid),andtotalsizeofthetraining
data;sinceforepochwiseresampling,thegridvariesthe Table1.Searchspacesusedinthehyperparameter
meanisusedinbothcases.Thetestlossisthemeanloss search.
forthe40modelsevaluatedonthetestsetasdescribedin
Section5.4
Intotal7differentmodelsweretrained.Thefirsttwomodelsare
6. STARTERBATTERYFAILUREDATA modelstrainedforaspecificpredictiontimeofonerespective
twoyears,whicharetrainedusingasinglesnapshotfromthat
In this section, an experimental dataset consisting of starter time from each vehicle; this means that the training data for
batteryfailuretimes,fromafleetofaround25,000vehicles,is thesemodelsareindependentandtheconventionalmaximum
usedtoevaluatethemethodologyonexperimentaldata. likelihoodtrainingcanbeused.Thenextthreemodelsareall
basedonresampledversionsofthedatasetwithvaryingnumbers
of samples in the resampling; all were equidistantly sampled
6.1 DescriptionoftheDataset between0.5and2.5years,andthenumberofsampleswas4,
5,and12.Thelastmodelwastrainedusingtheoriginaldataset
Thedatasethasacensoringrateof74%,meaningthatafailure withoutanyresampling,butonlyusingsnapshotsfromtimes
wasonlyobservedfor26%ofthevehicles.Thesnapshotsinthis between0.5and2.5years.
datasetconsistofoperationaldatathatisaggregatedovertime
inthevehicles’controlunitsandstoredduringspecifictimes 6.3 Evaluation
during the vehicles’ lifetime, for example when the vehicle
visitsaworkshop.Thefrequencyofwhichdataisstoredfora
Toevaluatethemodelsthreedifferentresampledversionsofthe
specificvehicleisfairlyconstantovertime,butvariesgreatly
testsetwereevaluatedusingtwodifferentmetrics.
fromvehicletovehicle;fromafewsnapshotsperyeartoone
snapshotperweek. Two of the test sets were created by resampling the original
test set to only include data from one year and two years,
The information in each snapshot is based on various signals
respectively;andathirddatasetwascreatedbyresamplingthe
availableinthevehicles’controlsystemselectedbyexpertstobe
datasetusing15randomsamplesbasedon(22).
informativeforpredictingbatteryfailures;forexample,mileage,
engineload,andnumberofenginestarts.Mostofthesignals Asanevaluationmetricthequasi-log-likelihoodwasused,which
arestoredashistogramsindicatingtheamountoftimethesignal forthetestsetsresampledonasingletimebecomesaproper
ssol
tseT
ssol
tseT
ssol
tseTlikelihood.Asanadditionalevaluationmetric,theBrierscore Dhada,M.,Parlikad,A.K.,Steinert,O.,andLindgren,T.(2023).
wasused,whichisdefinedforthedataset(17)as Weibullrecurrentneuralnetworksforfailureprognosisusing
J BS(t)=
(cid:80)M1
i M
(cid:88)N (cid:88)Mi
(cid:32)I
{τi>t}(1−S G(t (; tts
i
),s j,xi(ts i,s j)))2
Hoh
3
lm0is 1t eo
1
rg ,–r O3a
0
.m
,2
F4d
.
ra ist ka ,. EN .e ,u ar na dl KC ro ym sap nu dt ein r,g Man .d (2A 02p 3p )li .c Ea nti eo rn gs y, -3 b5 as(4 ed),
i=1 i i=1j=1 survivalmodelsforpredictivemaintenance. InProceedings
I (cid:33) ofIFACWorldCongress,Yokohama,Japan.
+
{τi>t,δi=1}S(t;ts i,s j,xi(ts i,s j))2
(30) Ishwaran,H.,Kogalur,U.B.,Blackstone,E.H.,andLauer,M.S.
G(τ i) (2008). Random survival forests. The Annals of Applied
Statistics,2(3),841–860.
whereGistheKapplan-Meierestimateofthecensoringdistri-
Kvamme,H.andBorgan,Ø.(2021). Continuousanddiscrete-
bution.SincetheBrierscoreisafunctionoftime,theresultsare
timesurvivalpredictionwithneuralnetworks. LifetimeData
presentedintermsoftheintegratedBrierscoredefinedas
Analysis,27(4),710–736.
1 (cid:90) maxiτi Li,X.,Krivtsov,V.,andArora,K.(2022). Attention-baseddeep
J IBS = J fBS(t) (31) survivalmodelfortimeseriesdata. ReliabilityEngineering
max τ
i i 0 &SystemSafety,217,108033.
whichisevaluatednumerically.
Voronov,S.(2020). MachineLearningModelsforPredictive
Maintenance. Ph.D.thesis,Linko¨pingUniversityElectronic
6.4 Results Press.
Voronov, S., Krysander, M., and Frisk, E. (2020). Predictive
Thissectioncontainspossiblysensitivedataandwillbemade maintenanceoflead-acidbatterieswithsparsevehicleopera-
availableinthefinalversion. tionaldata. InternationalJournalofPrognosticsandHealth
Management,11(1).
7. CONCLUSION
This paper proposes a methodology for defining and training
data-driven usage-specific survival models based on continu-
ously gathered operational data. The models can be used to
predict the remaining life of a component based on its usage
historyandassuchfitwellintomanypredictivemaintenance
applications.
Themethodologyisbasedonconventionalneuralnetwork-based
survivalmodelsthataretrainedusingdatathatiscontinuously
gathered and stored at specific times, called snapshots. The
fact that the data can contain more than one snapshot from a
specificindividualmeansthatthestandardmaximumlikelihood
training can not be directly applied since the data is not
independent.However,thepapersshowthatifthedataisina
specificformatwhereallsnapshottimesarefromthesametime
forallindividuals,calledhomogeneouslysampled,maximum
likelihoodtrainingcanbeappliedandproducedesirableresults.
In many cases, the data is not homogeneously sampled and
in this case, it is proposed to resample the data to make it
homogeneously sampled. The results from applying this to a
datasetofstarterbatteryfailuresindicatethatthisisapromising
approach. However, the results also show that the number of
samples that the dataset is resampled with is an important
parameter;itshouldbechosenlargeenoughtoproducegood
results, but this also increases the size of the dataset which
makestrainingslow.Toreducethenumberofsamplesneeded
to produce good results it is also proposed that, instead of
resamplingthedatasetoncebeforethetrainingstarts,randomly
resamplethedatasetatthestartofeachepochduringthetraining.
Randomly resampling the dataset on each epoch is shown to
greatly reduce the number of samples needed to produce the
sameresultsasthatobtainedfromonlyresamplingthedataset
once.
REFERENCES
Biganzoli,E.,Boracchi,P.,Mariani,L.,andMarubini,E.(1998).
Feed forward neural networks for the analysis of censored
survivaldata:Apartiallogisticregressionapproach. Statistics
inMedicine,17(10),1169–1186.
Brown, S., Branford, A., and Moran, W. (1997). On the use
ofartificialneuralnetworksfortheanalysisofsurvivaldata.
IEEETransactionsonNeuralNetworks,8(5),1071–1077.
Ching,T.,Zhu,X.,andGarmire,L.X.(2018). Cox-nnet:An
artificialneuralnetworkmethodforprognosispredictionof
high-throughputomicsdata. PLOSComputationalBiology,
14(4),e1006076.