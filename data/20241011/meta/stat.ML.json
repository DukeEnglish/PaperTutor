[
    {
        "title": "One Initialization to Rule them All: Fine-tuning via Explained Variance Adaptation",
        "authors": "Fabian PaischerLukas HauzenbergerThomas SchmiedBenedikt AlkinMarc Peter DeisenrothSepp Hochreiter",
        "links": "http://arxiv.org/abs/2410.07170v1",
        "entry_id": "http://arxiv.org/abs/2410.07170v1",
        "pdf_url": "http://arxiv.org/pdf/2410.07170v1",
        "summary": "Foundation models (FMs) are pre-trained on large-scale datasets and then\nfine-tuned on a downstream task for a specific application. The most successful\nand most commonly used fine-tuning method is to update the pre-trained weights\nvia a low-rank adaptation (LoRA). LoRA introduces new weight matrices that are\nusually initialized at random with a uniform rank distribution across model\nweights. Recent works focus on weight-driven initialization or learning of\nadaptive ranks during training. Both approaches have only been investigated in\nisolation, resulting in slow convergence or a uniform rank distribution, in\nturn leading to sub-optimal performance. We propose to enhance LoRA by\ninitializing the new weights in a data-driven manner by computing singular\nvalue decomposition on minibatches of activation vectors. Then, we initialize\nthe LoRA matrices with the obtained right-singular vectors and re-distribute\nranks among all weight matrices to explain the maximal amount of variance and\ncontinue the standard LoRA fine-tuning procedure. This results in our new\nmethod Explained Variance Adaptation (EVA). We apply EVA to a variety of\nfine-tuning tasks ranging from language generation and understanding to image\nclassification and reinforcement learning. EVA exhibits faster convergence than\ncompetitors and attains the highest average score across a multitude of tasks\nper domain.",
        "updated": "2024-10-09 17:59:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.07170v1"
    },
    {
        "title": "Collusion Detection with Graph Neural Networks",
        "authors": "Lucas GomesJannis KueckMara MattesMartin SpindlerAlexey Zaytsev",
        "links": "http://arxiv.org/abs/2410.07091v1",
        "entry_id": "http://arxiv.org/abs/2410.07091v1",
        "pdf_url": "http://arxiv.org/pdf/2410.07091v1",
        "summary": "Collusion is a complex phenomenon in which companies secretly collaborate to\nengage in fraudulent practices. This paper presents an innovative methodology\nfor detecting and predicting collusion patterns in different national markets\nusing neural networks (NNs) and graph neural networks (GNNs). GNNs are\nparticularly well suited to this task because they can exploit the inherent\nnetwork structures present in collusion and many other economic problems. Our\napproach consists of two phases: In Phase I, we develop and train models on\nindividual market datasets from Japan, the United States, two regions in\nSwitzerland, Italy, and Brazil, focusing on predicting collusion in single\nmarkets. In Phase II, we extend the models' applicability through zero-shot\nlearning, employing a transfer learning approach that can detect collusion in\nmarkets in which training data is unavailable. This phase also incorporates\nout-of-distribution (OOD) generalization to evaluate the models' performance on\nunseen datasets from other countries and regions. In our empirical study, we\nshow that GNNs outperform NNs in detecting complex collusive patterns. This\nresearch contributes to the ongoing discourse on preventing collusion and\noptimizing detection methodologies, providing valuable guidance on the use of\nNNs and GNNs in economic applications to enhance market fairness and economic\nwelfare.",
        "updated": "2024-10-09 17:31:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.07091v1"
    },
    {
        "title": "Do Contemporary CATE Models Capture Real-World Heterogeneity? Findings from a Large-Scale Benchmark",
        "authors": "Haining YuYizhou Sun",
        "links": "http://arxiv.org/abs/2410.07021v1",
        "entry_id": "http://arxiv.org/abs/2410.07021v1",
        "pdf_url": "http://arxiv.org/pdf/2410.07021v1",
        "summary": "We present unexpected findings from a large-scale benchmark study evaluating\nConditional Average Treatment Effect (CATE) estimation algorithms. By running\n16 modern CATE models across 43,200 datasets, we find that: (a) 62\\% of CATE\nestimates have a higher Mean Squared Error (MSE) than a trivial zero-effect\npredictor, rendering them ineffective; (b) in datasets with at least one useful\nCATE estimate, 80\\% still have higher MSE than a constant-effect model; and (c)\nOrthogonality-based models outperform other models only 30\\% of the time,\ndespite widespread optimism about their performance. These findings expose\nsignificant limitations in current CATE models and suggest ample opportunities\nfor further research.\n  Our findings stem from a novel application of \\textit{observational\nsampling}, originally developed to evaluate Average Treatment Effect (ATE)\nestimates from observational methods with experiment data. To adapt\nobservational sampling for CATE evaluation, we introduce a statistical\nparameter, $Q$, equal to MSE minus a constant and preserves the ranking of\nmodels by their MSE. We then derive a family of sample statistics, collectively\ncalled $\\hat{Q}$, that can be computed from real-world data. We prove that\n$\\hat{Q}$ is a consistent estimator of $Q$ under mild technical conditions.\nWhen used in observational sampling, $\\hat{Q}$ is unbiased and asymptotically\nselects the model with the smallest MSE. To ensure the benchmark reflects\nreal-world heterogeneity, we handpick datasets where outcomes come from field\nrather than simulation. By combining the new observational sampling method, new\nstatistics, and real-world datasets, the benchmark provides a unique\nperspective on CATE estimator performance and uncover gaps in capturing\nreal-world heterogeneity.",
        "updated": "2024-10-09 16:04:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.07021v1"
    },
    {
        "title": "Optimizing Estimators of Squared Calibration Errors in Classification",
        "authors": "Sebastian G. GruberFrancis Bach",
        "links": "http://arxiv.org/abs/2410.07014v1",
        "entry_id": "http://arxiv.org/abs/2410.07014v1",
        "pdf_url": "http://arxiv.org/pdf/2410.07014v1",
        "summary": "In this work, we propose a mean-squared error-based risk that enables the\ncomparison and optimization of estimators of squared calibration errors in\npractical settings. Improving the calibration of classifiers is crucial for\nenhancing the trustworthiness and interpretability of machine learning models,\nespecially in sensitive decision-making scenarios. Although various calibration\n(error) estimators exist in the current literature, there is a lack of guidance\non selecting the appropriate estimator and tuning its hyperparameters. By\nleveraging the bilinear structure of squared calibration errors, we reformulate\ncalibration estimation as a regression problem with independent and identically\ndistributed (i.i.d.) input pairs. This reformulation allows us to quantify the\nperformance of different estimators even for the most challenging calibration\ncriterion, known as canonical calibration. Our approach advocates for a\ntraining-validation-testing pipeline when estimating a calibration error on an\nevaluation dataset. We demonstrate the effectiveness of our pipeline by\noptimizing existing calibration estimators and comparing them with novel kernel\nridge regression-based estimators on standard image classification tasks.",
        "updated": "2024-10-09 15:58:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.07014v1"
    },
    {
        "title": "Efficient Distribution Matching of Representations via Noise-Injected Deep InfoMax",
        "authors": "Ivan ButakovAlexander SememenkoAlexander TolmachevAndrey GladkovMarina MunkhoevaAlexey Frolov",
        "links": "http://arxiv.org/abs/2410.06993v1",
        "entry_id": "http://arxiv.org/abs/2410.06993v1",
        "pdf_url": "http://arxiv.org/pdf/2410.06993v1",
        "summary": "Deep InfoMax (DIM) is a well-established method for self-supervised\nrepresentation learning (SSRL) based on maximization of the mutual information\nbetween the input and the output of a deep neural network encoder. Despite the\nDIM and contrastive SSRL in general being well-explored, the task of learning\nrepresentations conforming to a specific distribution (i.e., distribution\nmatching, DM) is still under-addressed. Motivated by the importance of DM to\nseveral downstream tasks (including generative modeling, disentanglement,\noutliers detection and other), we enhance DIM to enable automatic matching of\nlearned representations to a selected prior distribution. To achieve this, we\npropose injecting an independent noise into the normalized outputs of the\nencoder, while keeping the same InfoMax training objective. We show that such\nmodification allows for learning uniformly and normally distributed\nrepresentations, as well as representations of other absolutely continuous\ndistributions. Our approach is tested on various downstream tasks. The results\nindicate a moderate trade-off between the performance on the downstream tasks\nand quality of DM.",
        "updated": "2024-10-09 15:40:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.06993v1"
    }
]