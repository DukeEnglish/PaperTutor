[
    {
        "title": "Thing2Reality: Transforming 2D Content into Conditioned Multiviews and 3D Gaussian Objects for XR Communication",
        "authors": "Erzhen HuMingyi LiJungtaek HongXun QianAlex OlwalDavid KimSeongkook HeoRuofei Du",
        "links": "http://arxiv.org/abs/2410.07119v1",
        "entry_id": "http://arxiv.org/abs/2410.07119v1",
        "pdf_url": "http://arxiv.org/pdf/2410.07119v1",
        "summary": "During remote communication, participants often share both digital and\nphysical content, such as product designs, digital assets, and environments, to\nenhance mutual understanding. Recent advances in augmented communication have\nfacilitated users to swiftly create and share digital 2D copies of physical\nobjects from video feeds into a shared space. However, conventional 2D\nrepresentations of digital objects restricts users' ability to spatially\nreference items in a shared immersive environment. To address this, we propose\nThing2Reality, an Extended Reality (XR) communication platform that enhances\nspontaneous discussions of both digital and physical items during remote\nsessions. With Thing2Reality, users can quickly materialize ideas or physical\nobjects in immersive environments and share them as conditioned multiview\nrenderings or 3D Gaussians. Thing2Reality enables users to interact with remote\nobjects or discuss concepts in a collaborative manner. Our user study revealed\nthat the ability to interact with and manipulate 3D representations of objects\nsignificantly enhances the efficiency of discussions, with the potential to\naugment discussion of 2D artifacts.",
        "updated": "2024-10-09 17:49:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.07119v1"
    },
    {
        "title": "Robots in the Middle: Evaluating LLMs in Dispute Resolution",
        "authors": "Jinzhe TanHannes WestermannNikhil Reddy PottanigariJaromír ŠavelkaSébastien MeeùsMia GodetKarim Benyekhlef",
        "links": "http://arxiv.org/abs/2410.07053v1",
        "entry_id": "http://arxiv.org/abs/2410.07053v1",
        "pdf_url": "http://arxiv.org/pdf/2410.07053v1",
        "summary": "Mediation is a dispute resolution method featuring a neutral third-party\n(mediator) who intervenes to help the individuals resolve their dispute. In\nthis paper, we investigate to which extent large language models (LLMs) are\nable to act as mediators. We investigate whether LLMs are able to analyze\ndispute conversations, select suitable intervention types, and generate\nappropriate intervention messages. Using a novel, manually created dataset of\n50 dispute scenarios, we conduct a blind evaluation comparing LLMs with human\nannotators across several key metrics. Overall, the LLMs showed strong\nperformance, even outperforming our human annotators across dimensions.\nSpecifically, in 62% of the cases, the LLMs chose intervention types that were\nrated as better than or equivalent to those chosen by humans. Moreover, in 84%\nof the cases, the intervention messages generated by the LLMs were rated as\nbetter than or equal to the intervention messages written by humans. LLMs\nlikewise performed favourably on metrics such as impartiality, understanding\nand contextualization. Our results demonstrate the potential of integrating AI\nin online dispute resolution (ODR) platforms.",
        "updated": "2024-10-09 16:51:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.07053v1"
    },
    {
        "title": "Diamond of Thought: A Design Thinking-Based Framework for LLMs in Wearable Design",
        "authors": "Qiyang MiaoJiang XuZhihao SongChengrui WangYu Cui",
        "links": "http://arxiv.org/abs/2410.06972v1",
        "entry_id": "http://arxiv.org/abs/2410.06972v1",
        "pdf_url": "http://arxiv.org/pdf/2410.06972v1",
        "summary": "Wearable design is an interdisciplinary field that balances technological\ninnovation, human factors, and human-computer interactions. Despite\ncontributions from various disciplines, many projects lack stable\ninterdisciplinary teams, which often leads to design failures. Large language\nmodels (LLMs) integrate diverse information and generate innovative solutions,\nmaking them a valuable tool for enhancing design processes. Thus, we have\nexplored the use of LLMs in wearable design by combining design-thinking\nprinciples with LLM capabilities. We have developed the \"Diamond of Thought\"\nframework and analysed 1,603 prototypes and 1,129 products from a body-centric\nperspective to create a comprehensive database. We employed retrieval-augmented\ngeneration to input database details into the LLMs, ensuring applicability to\nwearable design challenges and integration of embodied cognition into the\nprocess. Our LLM-based methodology for wearables has been experimentally\nvalidated, demonstrating the potential of LLMs for the advancement of design\npractices. This study offers new tools and methods for future wearable designs.",
        "updated": "2024-10-09 15:10:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.06972v1"
    },
    {
        "title": "Digital Dotted Lines: Design and Evaluation of a Prototype for Digitally Signing Documents Using Identity Wallets",
        "authors": "Yorick LastJorrit GeelsHanna Schraffenberger",
        "links": "http://dx.doi.org/10.1145/3613905.3650977",
        "entry_id": "http://arxiv.org/abs/2410.06857v1",
        "pdf_url": "http://arxiv.org/pdf/2410.06857v1",
        "summary": "Documents are largely stored and shared digitally. Yet, digital documents are\nstill commonly signed using (copies of) handwritten signatures, which are\nsensitive to fraud. Though secure, cryptography-based signature solutions\nexist, they are hardly used due to usability issues. This paper proposes to use\ndigital identity wallets for securely and intuitively signing digital documents\nwith verified personal data. Using expert feedback, we implemented this vision\nin an interactive prototype. The prototype was assessed in a moderated\nusability test (N = 15) and a subsequent unmoderated remote usability test (N =\n99). While participants generally expressed satisfaction with the system, they\nalso misunderstood how to interpret the signature information displayed by the\nprototype. Specifically, signed documents were also trusted when the document\nwas signed with irrelevant personal data of the signer. We conclude that such\nunwarranted trust forms a threat to usable digital signatures and requires\nattention by the usable security community.",
        "updated": "2024-10-09 13:20:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.06857v1"
    },
    {
        "title": "Focal Surface Holographic Light Transport using Learned Spatially Adaptive Convolutions",
        "authors": "Chuanjun ZhengYicheng ZhanLiang ShiOzan CakmakciKaan Akşit",
        "links": "http://arxiv.org/abs/2410.06854v1",
        "entry_id": "http://arxiv.org/abs/2410.06854v1",
        "pdf_url": "http://arxiv.org/pdf/2410.06854v1",
        "summary": "Computer-Generated Holography (CGH) is a set of algorithmic methods for\nidentifying holograms that reconstruct Three-Dimensi-onal (3D) scenes in\nholographic displays. CGH algorithms decompose 3D scenes into multiplanes at\ndifferent depth levels and rely on simulations of light that propagated from a\nsource plane to a targeted plane. Thus, for n planes, CGH typically optimizes\nholograms using n plane-to-plane light transport simulations, leading to major\ntime and computational demands. Our work replaces multiple planes with a focal\nsurface and introduces a learned light transport model that could propagate a\nlight field from a source plane to the focal surface in a single inference. Our\nlearned light transport model leverages spatially adaptive convolution to\nachieve depth-varying propagation demanded by targeted focal surfaces. The\nproposed model reduces the hologram optimization process up to 1.5x, which\ncontributes to hologram dataset generation and the training of future learned\nCGH models.",
        "updated": "2024-10-09 13:17:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.06854v1"
    }
]