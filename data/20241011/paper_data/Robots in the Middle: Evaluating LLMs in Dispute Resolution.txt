September2024
Robots in the Middle:
Evaluating LLMs in Dispute Resolution
JinzheTAN a,1,HannesWESTERMANNb,NikhilReddyPOTTANIGARIc,
Jarom´ırSˇAVELKAd,Se´bastienMEEU`Sa,e,MiaGODETa,and
KarimBENYEKHLEFa,
aCyberjusticeLaboratory,UniversityofMontreal,Canada
bMaastrichtLawandTechLab,MaastrichtUniversity,Netherlands
cMila-QuebecAIInstitute,UniversityofMontreal,Canada
dSchoolofComputerScience,CarnegieMellonUniversity,UnitedStates
eFacultyofLawandCriminology,Universite´ LibredeBruxelles,Belgium
Abstract.Mediationisadisputeresolutionmethodfeaturinganeutralthird-party
(mediator)whointervenestohelptheindividualsresolvetheirdispute.Inthispa-
per,weinvestigatetowhichextentlargelanguagemodels(LLMs)areabletoact
asmediators.WeinvestigatewhetherLLMsareabletoanalyzedisputeconversa-
tions,selectsuitableinterventiontypes,andgenerateappropriateinterventionmes-
sages.Usinganovel,manuallycreateddatasetof50disputescenarios,wecon-
ductablindevaluationcomparingLLMswithhumanannotatorsacrossseveralkey
metrics.Overall,theLLMsshowedstrongperformance,evenoutperformingour
humanannotatorsacrossdimensions.Specifically,in62%ofthecases,theLLMs
choseinterventiontypesthatwereratedasbetterthanorequivalenttothosechosen
byhumans.Moreover,in84%ofthecases,theinterventionmessagesgeneratedby
theLLMswereratedasbetterthanorequaltotheinterventionmessageswritten
byhumans.LLMslikewiseperformedfavourablyonmetricssuchasimpartiality,
understandingandcontextualization.Ourresultsdemonstratethepotentialofinte-
gratingAIinonlinedisputeresolution(ODR)platforms.
Keywords.
largelanguagemodels,artificialintelligence,onlinedisputeresolution,accessto
justice,ai&law,chatgpt
1. Introduction
Intermediaries (for example, mediators, arbitrators, or conciliators) can play an impor-
tantroleinfacilitatingdisputeresolution.Whenadiscussionturnsemotionallycharged,
communicationbreaksdown,orthedisputereachesadeadlock,intermediariescaninter-
venewithinformationtohelpcalmemotions,clarifyfacts,identifythekeyissuesinthe
dispute,andmakeproposalsforsettlement,therebypromotingthesatisfactoryprogress
ofdisputeresolution.
Ofcourse,theinvolvementofsuchintermediariesislimitedtoareaswherethevalue
forthedisputeishigherthanthecostoftheintermediary.Further,insomeareas,there
1CorrespondingAuthor:JinzheTan,UniversityofMontreal,jinzhe.tan@umontreal.ca.
4202
tcO
9
]CH.sc[
1v35070.0142:viXraSeptember2024
maysimplynotbeasufficientnumberoftrainedfacilitatorstocoverallofthedisputes
[5].Supportingmediationthroughtechnologicaltoolsisthusapromisingavenueofin-
creasingthescalabilityoffacilitateddisputeresolution,andenablingitsuseinnewcon-
texts.
The recent advancements in large language models (LLMs) have opened the door
totheuseofAItoassistintermediariesinunderstandingdisputescenarios,offeringAI-
suggested interventions, and even AI automated interventions [26]. However, the com-
plex, interactive and interpersonal nature of dispute resolution sets a high bar for such
tasks[15].Intermediariesneedanuancedskillset,includingcontextualunderstanding,
emotionperception,andtheabilitytoproposebalanced,contextuallyappropriatesolu-
tions.WhileLLMshavedemonstratedconsiderablecapabilitiesindiscretetasks(suchas
contextualawarenessandlanguageunderstanding),theirperformanceinmorecomplex,
integratedtasksremainsunder-explored.
To investigate the performance of large language models (LLMs) like GPT-4o in
dispute resolution tasks, we analyzed their abilities in selecting intervention types and
generatinginterventionmessagesbasedondisputescenariosfromanovelcorpusof50
hypotheticaldisputes.Basedonthesedisputes,weinvestigatethreeresearchquestions:
RQ1 To what extent can LLMs select appropriate intervention types given a dispute
scenario?
RQ2 HowdoLLMscomparetohumansindraftinginterventionmessages?
RQ3 TowhatdegreearemessagesgeneratedbyLLMssafeandfreeofhallucinations?
2. RelatedWork
Theuseofcomputationalmethodstofacilitatedisputeresolutionisalong-standingtopic
in the field of Legal Informatics, such as in the ICANS system, where the parties can
choose their preferences through a mathematical mechanism and gradually reach an
agreement with the assistance of the system [24]. Using a similar idea, Family winner
uses a game-theoretic approach that allows users to split up and resolve disputes using
repeated offers [2,28,3]. Other approaches include indicating potential court outcome
rangesto alignthe expectationsof theparties[6,27,22,4]). Theseapproaches havelaid
thegroundworkforapplyingtechnologytothemediationprocess.
Inrecentyears,withadvancesinnaturallanguageprocessing(NLP),discussionsand
attempts to use language models to facilitate dispute resolution have emerged [15,16].
For example, Branting et al. use the example of Utah’s ODR system to analyse how
languagemodelscanbeusedtoanalysethestagesofadisputeandprovidefacilitators
withrecommendationsbasedonstandardtextmessage[5].
TheevolutionofLLMmarksasignificantshiftfromearlierdomain-specificmodels.
LLMshaveachievedsignificantperformanceintermsoftheirfoundationalcapabilities
[1],contrarytoconventionalmodelsthatarespecifictoparticulardomains.LLMsexcel
in tasks such as, e.g., language understanding and generation [7], sentiment analysis
[29], and reasoning [11]. These foundational capabilities allow LLMs to be adapted to
various domains through techniques such as fine-tuning or prompt engineering. This
flexibility has already led to diverse applications in the legal field, including providing
legal information [23,25], acting in fiduciary roles [18], conducting empirical research
[10],analyzinglegaltextdata[20,21],anddevelopinglegalexpertsystems[12].September2024
The main direction of our exploration in this paper is how well LLMs such as
GPT-4o perform in selecting intervention types and generating intervention messages,
ratherthanexpectingtodeploythemdirectlyinpracticalapplications.
3. ProposedFramework
WeusetheLLMediatorframeworkpresentedin[26]tosetupadisputescenarioinvolv-
ingtwodisputingpartiesandamediator.Thepartiescancommunicatewitheachother
throughtextmessages,andthemediatorcaninterveneinthedisputethroughintervention
messages in order to assist the disputants in reaching a resolution. In the LLMediator
framework,thisfunctionalitycanbeperformedbyahuman,byahumanassistedbyan
LLM,andpotentiallyinafullyautomatedfashion[26].Inthispaper,weinvestigatehow
human-writtenmessagescomparetothosegeneratedbyLLMs.
Figure1. AscreenshotfromtheLLMediator,showingadisputepriortothemediator’sintervention.
Figure 1 shows a screenshot of a dispute. At this point, the mediator may decide
that it is time to intervene, in order to help the disputants find an amicable solution. In
intervening,themediatorneedstoperformtwoimportantsteps:
Step 1 - Decide intervention type. Depending on the state of the discussion, the
mediatormaywanttoincludedifferenttypesofinterventionsinthemessagestheysend.
Forexample,theymaywanttocalmdownthediscussion,encourageexchangesofinfor-
mationorhelpthepartiesevaluatetheiralternatives.Weadoptedalistoftypesofpossi-
bleinterventionsfrom[13],ascanbeseenintable3.Decidingonthetypeofintervention
requiresanunderstandingofthedisputecontextandempathytowardstheparties.
Step 2 - Draft the intervention message. The mediator has to decide which spe-
cificwordstousetoperformthetypeofinterventiontheyhavechosen.Clearlyandem-
pathicallycommunicatingtheseideasisimportanttohelpthepartiesachievetheirgoals,
whileavoidingmistakesandambiguities.
Thesestepsneedtobecarriedoutimplicitlybythemediatorinterveninginadispute.
We chose to adopt them as a framework to compare the messages created by human
annotatorsandLLMs.Bysplittingtheprocessintothesetwosteps,wecancomparethe
performance of the two across multiple steps, giving us a deeper understanding of the
difference.September2024
4. ExperimentalDesign
Communicationsbetweenpartiesduringdisputesofteninvolvesensitiveandprivatein-
formation leading to a scarcity of accessible data on dispute scenarios. Therefore, we
manuallyconstructedadatasetcomprising50disputescenariosforourexperiments(sec-
tion 4.1). Afterwards, human mediators and LLMs intervened in the dispute scenarios
(sections4.2&4.3),followingthesameinstructions,andbothwereassessedinablind
evaluationfortheirperformanceinthesamescenarios(section4.4).
4.1. Constructingdisputes
The 50 dispute scenarios we created followed the same structure, with each scenario
consistingoftwodialoguesbetweenPartyAandPartyB,thusfeaturingatotaloffour
textual messages. In order to ensure a diverse set of disputes, we wrote disputes with
varyingcharacteristics,asdescribedinTable1.
Type Explanation Example
Emotional Thepartieshavestrongemotional Apersonaskstheirneighbourtokeeptheirdogs
expressionsintheconversation. quiet,resultinginanescalatingconversationwith
threats.
Complex Thedisputehasahighdegreeof Apersonasksaninsurancecompanytopayfor
complexityandthefactsofwhat acaraccident,resultinginadiscussionoflegal
happenedaredifficulttoclarify. andtechnicalnuances.
Confusion Thepartiesareconfused,leading Acustomerandmerchantdisagreeonthedetails
todifficultiesincommunication. ofanundeliveredorder,leadingtorepeatedre-
questsformoreinformation.
Impossible The dispute features strong dis- Acustomerrequestsalaptoptoberepaired,but
agreements, resulting in a dead- themanufacturerarguesthatthedamageiscause
lock. bytheuser,refusingthewarranty.
Evidential The dispute centers around con- Onepartyinsiststhatanagreementregardinga
flictingevidenceorclaims. computersalewasreached,whiletheotherdis-
agrees.
Table1. Descriptionofdisputecharacteristics
Afterreviewingthedisputescenarios,wefoundthattheywerediversebothinterms
ofcommunicationstyleandlegalareas,coveringareassuchasparceldelivery,landprop-
ertyrightsdisputes,noisecomplaints,andsoon.Thisdiversitycontributestohelpingus
performrobustevaluationsoftheinterventions.
4.2. Humaninterventions
Aftercreatingthedisputescenarios,wemanuallycreatedinterventionsforthedisputes.
We randomly assigned our annotators (all of whom are co-authors on this paper, with
varying legal knowledge) to the disputes. For each dispute, we asked the annotators to
performthestepsdescribedaboveinsection3.First,wethusaskedthemtoselectfrom
onetothreeoftheinterventiontypesdescribedintable3.Second,weaskedtheannota-
torstodraftinterventionmessagesbasedonthechoseninterventiontypes.Forcoherence
withtheLLMwrittenmessages,weaskedthemediatorstomaintainaone-to-onecorre-
spondencebetweenthechoseninterventiontypesandthegeneratedmessage,bywriting
1-2 sentences for each intervention type to construct their message. Table 2 shows an
exampleofchoseninterventiontypesandresultingmessagesbyhumansandLLMs.September2024
Disputesummary Interventiontypeschosen Interventions
Party A asks Party Human:4.Promoteaproductive Human:Let’snotinsulteachotherordown-
B to delete their levelofemotionalexpression,13. play anyone’s feelings. B, you must delete
picture from social Propose solutions that meet the thepicture,sincekeepingitwithoutA’scon-
media. B refuses fundamental interests of all par- sentisillegal.
and makes fun of ties.(preferred)
A.
LLM:2.Helpthepartiesunder- LLM: Let’s ensure the conversation is re-
stand each other’s views, 3. Let spectful.Here’saproposition:PartyB,how
the parties know that their con- aboutpostinganimagethatbothofyoufind
cerns are understood, 9. Encour- humorousandenjoyableinstead?Thisway,
ageflexibilityandcreativity PartyAwon’tfeelembarrassedandbothof
youcanhavefun.(preferred)
Table2. Exampleofselectedinterventiontypesandwritteninterventions,bothbyhumanandLLM.Here,the
evaluatorpreferredthehumanchoiceofinterventiontypes,buttheLLM-generatedinterventionmessage.
4.3. LLMInterventions
ForLLMs,wefollowedthesameprocessasforhumaninterventions,offirstusingthe
LLMtochooseaninterventiontype,andthengeneratinganinterventionmessagebased
onchoseninterventiontypes.Weusedthegpt-4o-2024-05-13modelviatheopenai
python Python library2, which was the state-of-the-art model at the time of the experi-
ment.Duringtheexperiment,weusedthedefaultparameters.
Step1-Decideinterventiontype.First,weaskedthemodeltoselectbetweenone
and three intervention types to respond to a provided dispute. We used the mediator’s
guidegivenonthewebsiteofDepartmentofJusticeofCanada[13]tocreatetheprompt,
whichcoversthedisputedconversationandthe13typesofinterventions(seetable3).
Step2-Generateinterventionmessage.Wethenprovidedhuman-selected inter-
vention types as inputs to the models and asked them to write intervention messages
basedontheinterventiontypes.TheLLMwasalsoaskedtomaintainthecorrespondence
betweentheinterventiontypesandthetext(seesection4.2andtable2).
Wealwaysusetheinterventiontypeschosenbythehumanannotatorinordertobe
able to compare the quality of the written intervention. Thus, we are able to compare
LLMstohumansontwotasks:choosingthecorrectinterventiontypes,andgenerating
an intervention message based on chosen intervention types. Our choice of using the
human messages does not imply that we considered the intervention types selected by
thehumanstobesuperiortothoseselectedbytheLLMs—infact,intheevaluation,we
foundthattheevaluatorsoftenpreferredtheinterventiontypesselectedbytheLLMs.
4.4. Evaluation
E1-Evaluationofinterventiontypes.Afterobtainingthetypesofinterventionchosen
byhumansandLLMsbasedonthedisputescenariosaccordingtotheprocessdescribed
inSection4.3,weconductedablindevaluationonthechoiceoftype.Weaskedevalua-
torstocomparethetwointerventiontypechoicesafterreadingthedisputescenarioand
tojudgewhichchoicetheythoughtwassuperiorona5pointLikertscale.
2Github: OpenAI Python Library. Available at: https://github.com/openai/openai-python [Ac-
cessed2024-08-26]September2024
No. InterventionTypes
1 Encourageexchangesofinformation
2 Helpthepartiesunderstandeachother’sviews
3 Letthepartiesknowthattheirconcernsareunderstood
4 Promoteaproductivelevelofemotionalexpression
5 Layoutthedifferencesinperceptionsandinterests
6 Identifyandnarrowissues
7 Helppartiesrealisticallyevaluatealternativestosettlement
8 Suggestthatthepartiestakebreakswhennegotiationsreachanimpasse
9 Encourageflexibilityandcreativity
10 Shiftthefocusfrompasttofuture
11 Shiftthefocusfromoneofblametoacreativeexchangebetweentheparties
12 Holdcaucuseswitheachdisputantifthereisdeadlockoraproblem
13 Proposesolutionsthatmeetthefundamentalinterestsofallparties
Table3. Listofinterventiontypestofacilitatemediationfrom[13]
Although there are multiple reasonable intervention type choices for each dispute
scenario,someoptionsmaybemoresuitabledependingonthecontext.Forexample,if
thepartiesuseimpolitelanguageorexpressstrongemotions,selectinginterventiontype
No.4,‘Promoteaproductivelevelofemotionalexpression,’wouldbemoreappropriate.
Insituationswherenegotiationsaredeadlocked,choosinginterventiontypeNo.8,‘Sug-
gestthatthepartiestakebreakswhennegotiationsreachanimpasse,’orNo.12,‘Hold
caucuseswitheachdisputantifthereisdeadlockoraproblem,’wouldbemorefitting.
E2-Evaluationofinterventionmessages.Afterward,weassignedanotherevalu-
atortoeach dispute.Weaskedthem toassess(ina blindfashion)whichof thetwoin-
terventionmessagestheypreferred.Theevaluatorsfirstprovidedtheiroverallpreference
using a 5 point Likert scale, and wrote comments motivating their choice. Then, they
compared the messages in terms of specific rubric items, including understanding and
contextualization, neutrality and impartiality, empathy awareness, and resolution qual-
ity.Aftercompletingtheevaluationbasedonthesecriteria,theevaluatorswereaskedto
writeadditionalnoteshighlightinganynoteworthypoints.
E3 - Safety evaluation of LLM interventions. Finally, we conducted safety and
qualitychecksofthemessagesgeneratedbytheLLMs.Weassessedwhetherthemodel
hallucinatedandwhethertherewereanysafetyissueswiththegeneratedmessages.
5. Results
5.1. E1-Evaluationofinterventiontypes
Table 4 shows the results of the blind evaluation. We found that evaluators generally
preferredtheinterventiontypeschosenbyLLMs.However,therewereinstanceswhen
these choices showed strong variance. Figure 2 shows the distribution of interventions
chosenbyhumans,comparedtothosesuggestedbyLLMs.September2024
Description Numberofresponses
LLMissignificantlybetterthanHuman 11
LLMisslightlybetterthanHuman 11
LLMandhumanareaboutthesame 9
HumanisslightlybetterthanLLM 14
HumanissignificantlybetterthanLLM 5
Table 4. We used a 5 point Likert scale to compare human evaluators’ preferences for LLM and human-
selectedinterventiontypes.
Figure2. FrequencyofInterventionTypesChosenbyLLMandHuman
5.2. E2-Evaluationofinterventionmessages
Figure 3 shows the blind evaluation preference of the evaluators on the different axes
between the human and LLM-generated messages. As we can see, there was a strong
preferenceforthemessageswrittenbytheLLMs,acrossthedifferentcategories.
Intermsofoverallevaluation,84%ofevaluatorsbelievedthattheinterventionmes-
sagesgeneratedbyLLMswereeithersuperiororequivalenttothosecreatedbyhuman
mediators,withLLMssignificantlyorslightlyoutperforminghumansin60%ofcases.
Further,theLLM-generatedmessageswerescoredasequaltoorbetterthanthehuman
messagesinbetween80%and96%ofthecasesinallcategories(seefigure3).
5.3. E3-SafetyevaluationofLLM-generatedintervention
After manually checking all the LLM-generated messages, we did not find the appear-
ance of harmful messages and hallucinations in the scenario of this experiment. How-
ever,thisresultdoesnotguaranteethattheLLMwillalwaysbesafeinlarger-scaleex-
periments or real-world applications, it simply indicates that no such phenomena were
detectedinthisparticularexperimentalscenario.September2024
Figure3. ThebarchartshowsthedistributionofresponsesevaluatingtheperformanceofLLMscomparedto
humansacrossthefivemetricsweset.
6. Discussion
6.1. RQ1-TowhatextentcanLLMscomprehenddisputescenariosandselect
appropriateinterventiontypes?
Table4showsthatourhumanevaluatorspreferredtheinterventiontypeschosenbythe
LLMsin22cases,wereambivalentin9cases,andpreferredthehuman-chosentypesin
19 cases. Overall, this is a strong result suggesting viability of LLMs on this complex
task,requiringthenuancedunderstandingofadisputeandempathytodeterminewhich
steps to take next. At the same time, it should be noted that the evaluators were not
expert mediators, and that the task of determining which specific intervention type is
appropriatemaybesubjective(seesection7).
Figure2showsthedistributionofinterventiontypeschosenbyhumansandLLMs.
Here, differing patterns are revealed. The top three types of interventions chosen by
the LLMs are helping the parties to understand each other’s views, the encouragement
of exchanging information and the helping of parties to evaluate alternatives (2,1,7).
The human annotators, on the other hand, preferred the encouragement of exchanging
information, the promotion of a productive level of expression, and helping the parties
understandeachothersviews(1,4,2).
Thesepreferencesmayrevealadifferentunderstandingofwhatisimportantinme-
diation.Atthesametime,priorworkhasshownthatLLMsmaybeaffectedbytheorder
ofpresentedoptions[19].ThismaypartiallyexplainwhytheLLMsseemtopreferthe
early items in the list, although a similar preference also seems present for the human
mediators.
6.2. RQ2-HowdoLLMscomparetohumansindraftinginterventionmessages?
Our experiment shows that LLMs can perform at a level comparable to or even better
thanourhumanannotators.TheLLM-generatedmessageswereratedhigherorequalto
thehuman-writtenonesin84%ofthescenarios.Whilecertaincaveatsapply(seesectionSeptember2024
7),theseresultshighlighttheimpressivecapabilityofLLMsindraftingappropriatein-
terventionmessages.Variousreasonsweregivenastowhytheevaluatorspreferredthe
messageswrittenbytheLLM.
First,theevaluatorsoftenfoundthemessageswrittenbytheLLMtobemoresmooth
andclearthanthehuman-writtenones.ThegeneraltoneusedbyLLMs,involvingfre-
quentmessagessuchas“Icompletelyunderstand”or“Itseemslikethereareproblems,”
seemstoworkwellinamediationenvironment,andmayhavecontributedtohighscores.
Second, while LLMs are known to frequently “hallucinate” information [9,8], in
ourcasethehumansmoreoftenmisunderstoodthedisputeorwereconfusedaboutthe
party intentions or factual occurrences. This could be due to factors such as fatigue,
emotional bias, or a misunderstanding of the role of the mediator. In contrast, LLMs
demonstrated consistent and coherent interventions across multiple cases, with fewer
instancesofjudgmenterrors.
Third,wefoundthatourhumanannotatorswouldoftenproposeveryspecificsolu-
tions or even indicate fault, which received a lower rating as it may not be appropriate
fortheroleofthemediator.
Overall, while it is important to highlight the caveat of none of the annotators and
evaluatorshavingexperienceinmediation,itseemslikethemessagesgeneratedbythe
LLMscapturethedisputewell,useanappropriatetone,areclearanddonotoverreach,
makingthemcomparefavourablytothemessageswrittenbyourhumanannotators.
6.3. RQ3-TowhatdegreearemessagesgeneratedbyLLMssafeandfreeof
hallucinations?
We did not notice any unsafe messages or hallucinated information in the generated
messages.Whilethisofcoursedoesnotruleoutsuchissues,itisnonethelessapromising
result for the use of LLMs in a dispute resolution context. The approach discussed in
[26],wherethegeneratedmessagesareprovidedtoahumanmediatorbeforebeingsent
totheparties,couldfurthermitigatesuchconcerns.
6.4. Ontheuseofgold-standarddata
Using human-generated answers as Ground Truth (‘gold standard’) is a very common
practiceinmachinelearningresearch,whichhelpsuscreatebenchmarksforevaluating
the performance of algorithms or models. Here, we took a different approach, instead
askingto comparehuman-generated messagestoLLM-generated ones,thereby notas-
suming that the human data can serve as a reliable gold standard. With good reason -
lookingattheresults,theLLMgeneratedmessageswereconsistentlyratedhigherthan
themessageswrittenbythehumans.
However,theresultsalsorevealthegeneraldifficultyofevaluatingtheperformance
ofmodelsthatcanperformcomplex,nuancedtaskswithoutgivingobviouslywrongan-
swers.NoneofthemessageswrittenbytheLLMcontainedanyhallucinationsorother
obviousdefects,whichmakestheoverallassessmentdifficultandsubjective.Perhaps,as
discussedin[17],itismoreusefultoseetheannotationsassurveysofindividualviews,
ratherthanasingle“truth”,whenitcomestobespokeandnuancedlegaltasks.Regard-
less,thescienceofevaluatinglargelanguagemodelsonlegaltasksisinitsinfancy,and
wehopethatthispapercancontributesomeinsightstothisimportantissue.September2024
7. Limitations
In this work, we used a structured evaluation method to compare the performance of
LLMs to humans. While the results are promising, there are some important caveats.
First, the process of selecting an intervention type and then being bound to it may not
correspondtohowmediatorsapproachdraftingmessagesinreality.Likewise,thedraft-
ing of messages in blocks organized by intervention types may also impose artificial
limitationsonthetypesofinterventionsthatcanbewritten.
Second, our disputes and messages were drafted and evaluated by people without
specifictraininginmediation,andnoneofwhomarenativeEnglishspeakers.Thismay
give an advantage to the LLMs. While it seems like the ability of the LLM to select
interventiontypesandwritemessagesisfavourabletothatofaveragepeople,thispaper
cannottellusabouthowtrainedmediatorswouldapproachtheseissues.
Third, as touched upon in section 6.4, it may not be possible to assess which in-
tervention type or message is “better” without observing real-world outcomes, leading
to a subjective assessment. For example, it is possible that grammar mistakes and our
expectations of the tone of the mediation message played an exaggerated role in our
comparisonofthemessages,whichmaynotmakeabigdifferenceinarealcontext.
Fourth,ourexperimentaldesignassumesthattherearealways4messages,andthat
themediatorshouldintervenenext.Itdoesnotincludethemessagesaftertheinterven-
tion,ortheimportantchoiceonwhentointervene(c.f.[5]),
WhilethesechoicesweremadetoenabletheassessmentofLLMsinmediation,they
also somewhat limit the general applicability of the results. Future work should focus
on evaluating such tools in real-world contexts, and involve expert mediators, in order
to achieve a higher “construct validity,” i.e., be more closely aligned with real-world
outcomes(c.f.[14]).
8. Conclusion&FutureWork
In this study, we demonstrated that large language models possess significant poten-
tial in mediating disputes, performing on par or even surpassing our human annotators
inselectingappropriateinterventiontypesandcraftingeffectiveinterventionmessages.
ThesefindingssuggestthatLLMscouldplayapivotalroleinenhancingonlinedispute
resolutionplatformsbyprovidingscalableandcost-effectivemediationservices.
OurresearchcontributestothegrowingbodyofknowledgeonAIapplicationsinlaw
anddisputeresolution,highlightingthecapabilitiesofLLMsinunderstandingcomplex
humaninteractionsandrespondingwithempathyandneutrality.Thisadvancementcould
significantlyimproveaccesstojustice,particularlyincaseswheretraditionalmediation
isinaccessibleduetocostoravailabilityconstraints.
Futureworkshouldincorporatemulti-modaldatatobettersimulatereal-worldme-
diation scenarios, and conduct pilot studies within actual ODR systems to assess prac-
tical effectiveness. By continuing to refine these technologies, we move closer to a fu-
turewhereAInotonlysupportsbutenhancesthehumancapacityfordisputeresolution,
contributingtoamoreaccessibleandefficientjusticesystem.September2024
References
[1] Achiam,J.,Adler,S.,Agarwal,S.,Ahmad,L.,Akkaya,I.,Aleman,F.L.,Almeida,D.,Altenschmidt,J.,
Altman,S.,Anadkat,S.,etal.:GPT-4technicalreport.arXivpreprintarXiv:2303.08774(2023)
[2] Bellucci,E.,Zeleznikow,J.:Representationsofdecision-makingsupportinnegotiation.Journalofde-
cisionsystems10(3-4),449–479(2001)
[3] Bellucci,E.,Zeleznikow,J.:Developingnegotiationdecisionsupportsystemsthatsupportmediators:a
casestudyofthefamilywinnersystem.ArtificialIntelligenceandLaw13,233–271(2005)
[4] Benyekhlef,K.,Zhu,J.:Intelligenceartificielleetjustice:justicepre´dictive,conflitsdebasseintensite´
etdonne´esmassives.Intelligence30(3)(2018)
[5] Branting,K.,McLeod,S.,Howell,S.,Weiss,B.,Profitt,B.,Tanner,J.,Gross,I.,Shin,D.:Acomputa-
tionalmodeloffacilitationinonlinedisputeresolution.ArtificialIntelligenceandLaw31(3),465–490
(2023)
[6] Carneiro,D.,Novais,P.,Andrade,F.,Zeleznikow,J.,Neves,J.:Onlinedisputeresolution:anartificial
intelligenceperspective.ArtificialIntelligenceReview41,211–240(2014)
[7] Chen,X.,Ye,J.,Zu,C.,Xu,N.,Zheng,R.,Peng,M.,Zhou,J.,Gui,T.,Zhang,Q.,Huang,X.:Howro-
bustisgpt-3.5topredecessors?acomprehensivestudyonlanguageunderstandingtasks.arXivpreprint
arXiv:2303.00293(2023)
[8] Dahl,M.,Magesh,V.,Suzgun,M.,Ho,D.E.:Largelegalfictions:Profilinglegalhallucinationsinlarge
languagemodels.JournalofLegalAnalysis16(1),64–93(2024)
[9] Das,S.,Saha,S.,Srihari,R.K.:Divingdeepintomodesoffacthallucinationsindialoguesystems.arXiv
preprintarXiv:2301.04449(2023)
[10] Dra´pal,J.,Westermann,H.,Savelka,J.:Usinglargelanguagemodelstosupportthematicanalysisin
empiricallegalstudies.arXivpreprintarXiv:2310.18729(2023)
[11] Huang, J., Chang, K.C.C.: Towards reasoning in large language models: A survey. arXiv preprint
arXiv:2212.10403(2022)
[12] Janatian,S.,Westermann,H.,Tan,J.,Savelka,J.,Benyekhlef,K.:Fromtexttostructure:Usinglargelan-
guagemodelstosupportthedevelopmentoflegalexpertsystems.In:LegalKnowledgeandInformation
Systems,pp.167–176.IOSPress(2023)
[13] DepartmentofJustice,C.:DisputeResolutionReferenceGuide:PracticeModule2.DisputeResolu-
tionSeries,DepartmentofJustice,Canada(jan2007),https://www.justice.gc.ca/eng/rp-pr/
csj-sjc/dprs-sprd/res/drrg-mrrc/04.html,lastModified:August25,2022
[14] Kapoor,S.,Henderson,P.,Narayanan,A.:Promisesandpitfallsofartificialintelligenceforlegalappli-
cations.arXivpreprintarXiv:2402.01656(2024)
[15] Larson,D.A.:Artificialintelligence:Robots,avatars,andthedemiseofthehumanmediator.OhioSt.J.
onDisp.Resol.25, 105(2010)
[16] Larson,D.A.:Brother,canyouspareadime-technologycanreducedisputeresolutioncostswhentimes
aretoughandimproveoutcomes.Nev.LJ11, 523(2010)
[17] Ma,M.,Waldon,B.,Nyarko,J.:Conceptualquestionsindevelopingexpert-annotateddata.In:Pro-
ceedingsoftheNineteenthInternationalConferenceonArtificialIntelligenceandLaw.pp.427–431
(2023)
[18] Nay,J.J.:Largelanguagemodelsasfiduciaries:acasestudytowardrobustlycommunicatingwitharti-
ficialintelligencethroughlegalstandards.arXivpreprintarXiv:2301.10095(2023)
[19] Pezeshkpour,P.,Hruschka,E.:Largelanguagemodelssensitivitytotheorderofoptionsinmultiple-
choicequestions(2023),https://arxiv.org/abs/2308.11483
[20] Savelka,J.,Ashley,K.D.,Gray,M.A.,Westermann,H.,Xu,H.:CanGPT-4supportanalysisoftextual
dataintasksrequiringhighlyspecializeddomainexpertise?ASAIL’23:6thWorkshoponAutomated
SemanticAnalysisofInformationinLegalText(2023)
[21] Savelka,J.,Ashley,K.D.,Gray,M.A.,Westermann,H.,Xu,H.:Explaininglegalconceptswithaug-
mentedlargelanguagemodels(GPT-4).arXivpreprintarXiv:2306.09525(2023)
[22] Susskind,R.:Onlinecourtsandthefutureofjustice.OxfordUniversityPress(2019)
[23] Tan,J.,Westermann,H.,Benyekhlef,K.:ChatGPTasanartificiallawyer?ArtificialIntelligencefor
AccesstoJustice(AI4AJ2023)(2023)
[24] Thiessen,E.M.:ICANS:Aninteractivecomputer-assistedmultipartynegotiationsupportsystem.Cor-
nellUniversity(1993)
[25] Westermann,H.,Meeu`s,S.,Godet,M.,Troussel,A.C.,Tan,J.,Savelka,J.,Benyekhlef,K.:Bridging
thegap:Mappinglaypersonnarrativestolegalissueswithlanguagemodels.In:ASAIL@ICAIL.pp.September2024
37–48(2023)
[26] Westermann,H.,Savelka,J.,Benyekhlef,K.:LLMediator:GPT-4assistedonlinedisputeresolution.
ArtificialIntelligenceforAccesstoJustice(AI4AJ2023)(2023)
[27] Zeleznikow,J.:Canartificialintelligenceandonlinedisputeresolutionenhanceefficiencyandeffective-
nessincourts.In:IJCA.vol.8,p.30.HeinOnline(2016)
[28] Zeleznikow,J.,Bellucci,E.:Familywinner:integratinggametheoryandheuristicstoprovidenegoti-
ationsupport.In:Proceedingsofsixteenthinternationalconferenceonlegalknowledgebasedsystem.
pp.21–30.IOSPublicationsAmsterdam(2003)
[29] Zhang,W.,Deng,Y.,Liu,B.,Pan,S.J.,Bing,L.:Sentimentanalysisintheeraoflargelanguagemodels:
Arealitycheck.arXivpreprintarXiv:2305.15005(2023)