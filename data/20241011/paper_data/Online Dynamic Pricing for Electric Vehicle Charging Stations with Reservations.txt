Online Dynamic Pricing for Electric Vehicle
Charging Stations with Reservations
∗† ∗ ∗ ∗
Jan Mrkos , Anton´ın Komenda, David Fiedler, and Jiˇr´ı Vokˇr´ınek
October 10, 2024
Abstract
The transition to electric vehicles (EVs), coupled with the rise of
renewable energy sources, will significantly impact the electric grid.
Unlike conventional fuel sources, electricity for EVs is constrained by
grid capacity, price fluctuations, and long EV charging times, requiring
new pricing solutions to manage demand and supply. This paper
proposes a model for online dynamic pricing of reserved EV charging
services, including reservation, parking, and charging as a bundled
service priced as a whole. Our approach focuses on the individual
charging station operator, employing a stochastic demand model and
online dynamic pricing based on expected demand. The proposed
model uses a Markov Decision Process (MDP) formulation to optimize
sequential pricing decisions for charging session requests. A key contri-
bution is the novel definition and quantification of discretization error
introduced by the discretization of the Poisson process for use in the
MDP. The model’s viability is demonstrated with a heuristic solution
method based on Monte-Carlo tree search, offering a viable path for
real-world application.
1 Introduction
The mass electrification of personal transportation, concurrent with the
introduction of green energy resources, will significantly impact the electric
∗FacultyofElectricalEngineeringCzechTechnicalUniversityinPrague,Karlovona´mˇest´ı
13, Prague 2, 121 35
†Corresponding author, mrkosja1@fel.cvut.cz
1
4202
tcO
7
]AM.sc[
1v83550.0142:viXragrid. Most likely, these changes will mean that drivers will need to adapt to a
new way of using their soon-to-be electric vehicles. Unlike gasoline and diesel,
electricity is not as easily stored in the charging location. Therefore, charging
electric vehicles is subject to grid constraints and varying prices of electricity.
To make the allocation of the charging capacity more efficient, it is
reasonable to price the charging of EVs dynamically. This way, the price
signals coming from the energy markets and grid operators can propagate
to the EV users. Additionally, dynamic pricing can help charging station
(CS) operators maximize revenue and reduce congestion by responding to the
changing demand for charging.
The benefits of dynamic pricing of EV charging are clear when applied to,
e.g., overnight charging at home. However, when it comes to traveling long
distances, EV charging is already more complicated than refueling a gasoline
car and takes a lot more planning. Adding price uncertainty to the mix could
make planning and travel even more difficult.
However, if EV charging could be reserved ahead of time, then the price
could be fixed at the time of reservation. This way, the driver could plan
the whole trip and know the exact cost of charging. This is the idea behind
the dynamic pricing model we propose in this paper. This type of dynami-
cally priced, reserved EV charging session is not common in the EV pricing
literature.
There are three things that set this work apart from the previous works:
First, the product we consider is charging session reservations, which include
the energy delivered to the EV, time spent at the charging station, and the
parking spot. While other works often make use of some form of reserva-
tions [1]–[4], they are often a byproduct of a top-down allocation scheme that
assigns charging slots to EV drivers.
Second, the pricing of these products happens online and is fully dynamic;
the price of each requested reservation can be different, reflecting the current
state of the charging station, the parameters of the request, and the expected
future demand for charging. Many previous works are a lot more conservative
in the variability and complexity of pricing [2], [5]–[7], either because their
product is different, such as “charged kWh,” or because of the computational
complexity of optimizing such pricing.
Finally, we focus on revenue maximization for the seller, operator of a
single charging location. This point of view has become more popular in
recent years [6], [8] as many realized that the transition to and sustainability
of electric mobility is not feasible without profitable EV charging stations.
2Pricing of EV Charging
Surveys: [8], [9]
Centralized Decentralized
Global view Local view
Game theory Simulation More complex Different type
This work
[1]–[4], [10], [11] study [12] CS models [7], [13] of pricing [6]
Figure 1: Structure of the literature survey.
Arguably, focusing on a single location is limiting, and many works explore
the problem on a much larger scale. However, limiting our focus makes the
complexity raised by the first two points manageable.
To summarize, in this paper, we present a model of dynamic pricing of
electric vehicle charging that relies on the full reservation of the charging ser-
vice, including the parking, and prices this service as a complete product. We
consider fully dynamic pricing that reflects the charging requests’ parameters,
the charging stations’ state, and expected future demand. We optimize this
pricing to maximize revenue for the charging station operator.
We do this by explicitly formulating a discrete, finite-horizon Markov
Decision Process (MDP) of the dynamic pricing problem in Section 3, where
we model the demand as a mix of Poisson processes. Since discretization of
the Poisson process introduces an error to the model, we derive this error
in Section 4 to make sure our model is theoretically sound. To validate
the feasibility of our approach, we develop a heuristic solution method for
dynamic pricing based on Monte-Carlo tree search (MCTS) in Section 5, and
we use it to solve a number of generated problem instances, comparing its
performance to a number of baselines in Section 6.
32 Literature review
Pricing of EV charging is an active research topic, with many papers tackling
the problem from different points of view. We provide an overview of the
structure of our literature survey in Figure 1.
The works on the pricing of EV charging are commonly divided between
centralized and decentralized approaches, as is also the case in the surveys
[8], [9]. A centralized approach collects all the inputs with a central authority
who then makes and distributes decisions. On the other hand, the decentral-
ized approach allows the participants to make decisions independently. As
centralization is practically problematic in the context of public EV charging,
many works, ours included, focus on decentralized approaches.
One branch of decentralized research takes a “global” view of the EV
charging ecosystem, modeling both EV drivers and CSs individually in their
interactions in the transportation network. The second branch of research,
which includes this work as well, focuses on the “local” viewpoint of a single
actor in the ecosystem, such as the charging station, without the ambition of
optimizing some ecosystem-wide criteria.
The first segment of papers that take the “global” view uses a game
theoretical approach to the problem of EV charging. In [2]–[4], [10], [11],
the allocation arises as part of iterative negotiation between the charging
stations and the EV drivers. Price changes are used as signals to influence
the decisions of the drivers and to guarantee some useful properties, such as
individual rationality [2], [3] or incentive compatibility and preservation of
privacy [2]. While these approaches do not rely on a central authority to make
decisions, they require a widespread consensus on the rules and protocols
of the system. An additional drawback of this approach is that it requires
many iterations of negotiation between drivers and the CSs. This can be
addressed by having agents in the form of, e.g., smartphone applications
perform the negotiation on drivers’ behalf. Overall, these approaches are
often not practically scalable, as the required consensus between CS owners
and EV drivers is difficult to achieve.
Other works that take the “global” view of electromobility look at the
EV drivers and CSs individually without applying game theoretical concepts.
For example, Seyedyazdi, Mohammadi, and Farjah [12] proposes a selection
algorithm for EV drivers to choose the best charging station based on the
trip price travel time, as well as a pricing algorithm that considers previously
reserved pricing requests and day-ahead pricing of electricity. The proposed
4algorithmsarethenallowedtointeractinasimulation. Simulationresultsshow
that the proposed solution improves upon the selected baselines. However, the
work suffers from the same coordinational weaknesses as the game-theoretical
approaches; it assumes all the EV drivers and CSs are all using the proposed
algorithms.
2.1 Local view of pricing
We follow the “local” branch of research, focusing on an individual charging
station or charging station operator and their pricing strategy. Here, the
EV drivers’ needs are abstracted into a much simpler model, usually a
stochastic demand model. This approach is useful when the charging stations
are modeled in greater detail or when the interactions are more complex.
Representatives of this approach are, for example, Zhang, You, and Cai
[13] and Abdalrahman and Zhuang [7], who propose a model of pricing EV
charging that considers different charging speeds and prices them differently.
Within the local focus on the charging stations point of view, we are
interested in reservations and the form that the dynamic pricing of these
reservations has.
2.1.1 Reservations
Reservations are not common in the EV charging industry. However, for
example, charging station operator EVgo [14] has recently introduced a
reservation system for their charging stations. Reservation systems are useful
for CS operators as they can better plan the utilization of their resources.
For EV drivers, reservations reduce uncertainty about their trips.
In the “local” literature on EV charging, reservations are not particularly
common either. They are present implicitly or explicitly in the auction-like
mechanisms that result in the allocation of the charging capacity, such as
[1], [3], [10]. Other works assume a less organized EV ecosystem and model
reservations explicitly, such as [6], [15]. Fang, Lu, Hong, et al. [6] is of most
interest to us as it studies the pricing of a single CS that offers reservations,
and the pricing responds to previously reserved demand.
52.1.2 Dynamic pricing
Dynamic pricing is a relatively common feature of papers on EV charging,
as illustrated in the survey [9]. However, there are big differences between
the dynamic pricing schemes. First, different works price different products.
Second, dynamic pricing can mean different things in different papers. Some
works apply dynamic pricing to the electricity price [13]. In that case, the
common choice of pricing is extending the smart-grid concept of time-of-use
pricing to EV charging [16], which works by setting different prices per kWh
for different time intervals, usually well ahead of time. Other works apply
dynamic pricing to the per-minute fee, which is viewed as an improvement
over the current state of charging per kWh as it incentivizes drivers to
disconnect when their vehicle is sufficiently charged [17]. Others don’t look
at the charging and instead focus on the pricing of parking reservations, e.g.,
Fang, Lu, Hong, et al. [6] and Lei and Ouyang [18].
2.2 Contributions
In this work, we focus on the full reservations (following the taxonomy
proposed in Basmadjian, Kirpes, Mrkos, et al. [19]), and we price these
reservations as a complete product, including the delivered electricity and
the parking spot. De-facto full reservations are common with papers that
take the global view of EV pricing and result in allocations. Our approach is
most similar to Boateng, Si, Xia, et al. [1], who let drivers reserve charging
stations before their arrival at the charging location and proposes a dynamic
pricing scheme to manage demand. However, Boateng, Si, Xia, et al. [1]
focuses on autonomous vehicles and takes the global view of the problem,
with both customers and service provider constantly adjusting their strategies
to maximize their individual utilities.
In the pricing, our work is most similar to Fang, Lu, Hong, et al. [6], who
take the local approach to pricing. In this work, the pricing is also dynamic
in the sense that the price changes in 1-hour timesteps based on demand.
The price updates are broadcast to all potential customers. In contrast, our
protocol has the customers request charging reservations, and the station
responds with a price.
The main contributions of this work are:
1. MDP-based model of online dynamic pricing of reserved EV charging
service that includes the parking spot and delivered charge and that is
6based on available charging capacity and expected customer demand,
modeled as a possibly time-dependent Poisson process,
2. Definition of a novel error metric that quantifies the error introduced
by the discretization of the Poisson process in the MDP model,
3. Scalable heuristic solution method for the model based on Monte-Carlo
tree search for pricing of the EV charging service reservations.
While reservations reduce uncertainty for both the EV drivers and the CS
operators, they also introduce a new layer of complexity and reduce flexibility
for the EV drivers. However, this complexity can be reduced by the use of
driver assistant technologies, such as smartphone apps, to make reservations
on behalf of the drivers. For example, routing algorithms for EVs can plan
whole trips, including the charging stops, and let the driver select the best
tradeoff between the trip time and the cost [20]. Reservations are a natural
extension of this approach.
3 MDP model for dynamic pricing
In our work, the pricing of EV charging is a question of sequential pricing
decisions for incoming charging reservation requests. As such, MDP is a
natural model for the problem. MDP is model of choice for other dynamic
pricing works, especially when combined with reinforcement learning [7],
[12], [21]. In these works, the state space is constructed with as many state
variables as possible, and the pricing policy is learned from the data. However,
we systematically avoid the use of reinforcement learning in our work due to
the large computing requirements to train the model and the currently low
availability of representative data to train the model on. Instead, we focus on
a concise model of the problem and a scalable heuristic solution method.
Lastly, the demand model in our work uses a Poisson process to model
the arrival of the charging requests. This is a relatively common choice in
the literature on dynamic pricing of EV charging, used by [6], [12], [13]. By
applying the Poisson process to our discrete-time model of online dynamic
pricing, we introduce a discretization error. This error is described and
quantified in Section 4.
7Products
1 2 3 4 5 6
1 1 1 1 3
2 1 1 1 1 3
3 1 1 1 3
Request
time
arrivals
b = 3 b = 6b = 2b = 8 b = 6b = 5b = 9
& budgets 1 2 3 4 5 6 7
Pricing
actions a = 2 a = 5a = 5a = 8 a = 6a = 8a = 6
1 2 3 4 5 6 7
3 2 2 2 1 0 0 0
Resources3 3 3 3 2 1 1 0
3 3 2 2 1 1 1 0
(cid:80)
r = 2 r = 5r = 0r = 8 r = 6r = 0r = 6 r = 27
1 2 3 4 5 3 7 i i
Rewards
Figure 2: Illustration of the online dynamic pricing of EV charging. The
charging products being priced are vertical columns in the resource matrix
on top. For example, product [1,1,0] represents consecutive charging in
the first time slot (resource) and second time slot out of the three. In the
EV charging problem, we assume each product contains every resource (the
charging slot capacity in a time interval) only once and that products contain
only consecutive time intervals (i.e., there is no product [1,0,1]). Below the
matrix, the request arrivals and budgets show customers requesting different
products at different times and their budgets (b to b ). The next line below
1 7
shows pricing actions a to a taken by the seller. When a customer accepts
1 7
the price (i.e., when b ≥ a , shown as green ✓), the seller accumulates a
i i
reward r , and his resource capacity is reduced by the product requirements,
i
this is shown on the two bottom lines.
8
secruoseR
yticapac
laitinI3.1 Pricing Problem Description
In this work, dynamic pricing of EV charging involves setting optimal or
near-optimal prices online for different charging products as customer requests
for these products arrive, one after another. Seller, the CS operator, combines
his resources, the charging capacity of a set of charging stations, into products
offered to customers, such as half-day charging of an EV. In our case, the
product is a charging session, and the different resources it consists of are
charging capacities in different time slots.
Although the demand for these products is unknown beforehand, the seller
has historical data about customer request arrivals and a model of customer
responses to changing prices. The seller’s goal is to price each arriving product
request in a way that maximizes its objective function, considering demand
uncertainty. The objective function can be maximizing either revenue or
efficiency, such as for CS operated by public utilities. This optimization
occurs over a finite time horizon, after which the resources can no longer be
sold.
Here, we give a minimalist formal description of the pricing problem by
considering first the supply side that puts constraints on the seller and the
demand side that prompts the seller’s actions. The description is illustrated
by Figure 2.
The supply side of the problem is formed by a set of n resources that can
be combined into m products available for sale. Each product is represented
by a vector p ∈ Nn, elements of which prescribe the number of individual
0
resourcesusedintheproduct. Theavailabilityoftheseproductsisconstrained
by the initial capacity of the resources c ∈ Nn and the lengths of selling
0
periods of different resources T ∈ R+ that determine the time after which
each resource and product, it is part of, can no longer be sold.
The demand side of the problem is modeled by a non-homogeneous,
compound Poisson counting process N(τ), τ ∈ (0,max(T)) that models
the arrivals of requests for different products in time and distributions of
finite internal customer valuations for different products, {β |p ∈ P}. The
p
customers accept the offered price for the requested product if it is below
their internal valuation. Otherwise, they reject the offer and leave the system.
Realized demand takes the form of a sequence of timestamped product
requests (pair (p,τ)) associated with hidden customer valuations of products,
b ∼ β :
i p
i
d = ((p ,τ ,b ),(p ,τ ,b ),...) (1)
1 1 1 2 2 2
9The service provider needs to process these requests individually as they
arrive. The protocol for a single interaction between the seller and customers
is following:
1. An ith customer requests product p from the seller at time τ .
i i
2. If the request is feasible, that is, if τ ≤ T and the resource capac-
i p
i
ity is greater than the products resource requirements, c ≥ p in all
i
components, then the seller proposes price a ∈ A ⊂ R to the customer.
Otherwise, the seller rejects the request (equivalent to proposing an
infinite price for the product).
3. The customer compares the price a against their internal valuation of
the product b , and if a ≤ b , then the customer pays the price and buys
i i
the product. Otherwise, the customer rejects the price a and leaves the
system.
Crucially, the seller does not know the values of the customer’s valuations b .
i
Each customer requests a single product and leaves the system after accepting
or rejecting the offered price.
3.2 MDP Model
Having described the dynamic pricing problem, we will now develop the MDP
model to determine the pricing policy π. The pricing policy is a mapping that
assigns price a to the product-time pair (p,τ) combined with the currently
available and planned future capacity c of the seller’s resources.
In our MDP, defined as a 5-tuple (S,T ,R,A,s ), the seller starts in some
0
initial state s ∈ S. Each state captures the current timestep, what product
0
is being requested, and how many resources are currently available. The
seller offers a price a ∈ A for the requested product, taking an action that
results in a transition to a new state s′ ∈ S. However, the transition is not
deterministic because it is unknown whether the customer will accept or reject
the price and what the next product request will be. By fitting the random
demand process N(τ) and distributions of the customer internal valuations
{β |p ∈ P} to the historical data, we can estimate the transition probability
p
T (s′|a,s), which determines the likelihood of reaching state s′ when taking
action a in the state s. The transition between states also generates rewards
for the seller, determined by the function R(s,a,s′).
10Figure 3: Illustration of the MDP states for the dynamic pricing of EV
charging. Unlike Figure 2, this figure illustrates the expiration of resources
after their selling period ends (grey in the capacity and product vectors).
The blue squares represent the MDP states. At timestep t, the capacity of
the charging station is expressed by the capacity vector c . Elements of the
t
vector represent available charging capacity in corresponding timeslots (time
ranges in the green square). Possible charging session reservation requests
arriving since the previous timestep is expressed by the vector p , with ones
t
representing the requested timeslots. Based on the three state variables
c ,t,p , the pricing policy provides an action a, the price for charging, that
t t
the user either accepts (the first two states at the bottom) or rejects (the state
on the right). The state then transitions into the next timestep (details of the
transition function are illustrated by Figure 4). The accepted charging request
leads to reduced capacity values. The next charging session reservation is
entered into the new state. Note that the timesteps must have much finer
resolution than the charging timeslots. The gray color shows past information
regarding the charging capacity and session vectors c and p , respectively.
t t
11s = (c,p)
t
a
action acti
o
n
a′
p acc(p,a) = 1−F βp(a) ··· . .
.
p
acc
−
p 1
− p
←
c c′ acc
c′ ← c
p req(p′) = λ p′/h . .
.
p′) p
preq(
p′
preq(
p′′
← )
←
p p′′
s = (c′,p′) ··· s = (c′,p′′)
t+1 t+1
Figure 4: The structure of the transition function T . Given state s , the
t
probability of getting to the next state s is given by multiplying the
t+1
probabilities along the edges. States are the decision nodes (in red), and
chance states are in blue and contain the definition of the probability used
along the edge.
123.2.1 State Space
TheMDPstate space S consistsofstatess = (c,t,p)(wealsousethenotation
s = (c,p)). That is, the state is defined by the supply of all the resources c
t
at time step t and the product p being requested by some customer at time
step t. By discretizing the selling period (0,max(T)) into k time steps, we
make sure the state space is finite.
While continuous-time MDP formulation [22] is possible, it complicates
the description of the problem, making it less intuitive and the solution more
complex. The arrival time of customer product requests is continuous; the
service provider can’t influence these arrival times. However, they arrive as
discrete events. Additionally, in pricing problems we are interested in, we
assume that customer product requests arriving at similar times will mostly
exhibit similar types of behavior. That is to say that we expect demand
to depend on time in a piecewise continuous fashion with a finite number
of discontinuities, where the discretization can be made to match these
discontinuities. Additionally, as discussed in Section 4, the discretization only
needs to be fine enough to ensure that the probability of multiple requests
arriving in a single timestep remains low.
The time step t increases by one with every transition, so s = (c,p) is
t
always followed by some s = (c′,p).
t+1
3.2.2 Action Space
The MDP action space A ⊂ R is a set of possible prices that the seller can
offer customers. This set can principally be continuous, but we assume the
prices to form a finite set for our experiments.
Similarly, as with continuous time, our model could accommodate for
continuous action spaces [23]. Doing so could improve the sellers’ objectives,
as the proposed prices could get closer to the internal customer’s product
valuation b. Most current service providers1 selling directly to customers,
however, offer discrete service prices. Therefore, it seems to be a natural
simplification in our case as well. Furthermore, where possible, we compare
1Recent exception in the context of dynamic pricing in network revenue management
is Lufthansa, which introduced continuous pricing in 2020 [24]. The reasons service
providers use discrete prices in dynamic pricing are part technical (systems in airline
revenue management have historically used discrete prices), part psychological/marketing
to simplify customer choices.
13our heuristic solution to optimal baselines only applicable to finite action
spaces.
One special price is the infinite price a = ∞, which effectively forms the
reject action since no customer will have infinite funds. This action is used
when the seller lacks the resources to provide the requested product.
3.2.3 Reward Function
The MDP reward function R(s ,a,s ) determines the reward obtained by
t t+1
transitioning from s to s by taking action a. If the seller’s goal is revenue
t t+1
maximization, the reward is the price offered for the product. The reward
has the value of the action a if the customer accepts the offered price a and 0
otherwise. Formally:
(cid:40)
a, if b > a
R(s ,a,s ) =
t t+1
0, otherwise
Here, a on the right-hand side of the equation is the value of the action a.
b > a means that the customers budget b is greater than the price a, meaning
customer accepts the price. Note that a successful sale implies capacity is
reduced between s = (c,p) and s from c to c−p in s , which brings us
t t+1 t+1
to the definition of the transition function.
3.2.4 Transition Function
The transition function T (s ,a,s ) is the most complex component of the
t t+1
MDP model. It determines the state s the system develops into from
t+1
state s when the service provider takes action a. The transition function T
t
is determined by two factors: the customer arrival processes D(t) and the
distributions of customer internal valuations {β |p ∈ P}. The structure of
p
the transition function and how it combines these two components is shown
in Figure 4.
In some state s = (c,p) (the root of the tree in Figure 4), the seller
t
picks a price a for product p requested by a customer with a hidden internal
valuation of the product. Since the customer accepts the offered price only if
his internal valuation (modeled by a random variable X ∼ β of the product
p
p) is greater than the offered price a, the probability of a customer accepting
the offered price is given by the complementary cumulative density function
14F of β as
βp p
p (p,a) = P(X > a) = 1−F (a) (2)
acc βp
This is shown in the second level of the tree in Figure 4. The budget
distribution β could also be time-dependent, but we assume it is not for
p
simplicity.
Independently of whether the product p is sold at time step t in Figure 4,
some product p′ could be requested at time step t+1. The demand model
D(t) that determines the probability of a product request at time step t is
derived from the compound Poisson counting process N(τ) with rate λ.
The choice of the Poisson process to model arrival is a natural consequence
of the so-called memoryless property that assumes that, at any point, the
time until the next customer request does not depend on how much time has
passed since the last customer request. Fortunately, this assumption holds
in many pricing problems, since the assumed customer populations are large
and customers act independently. For this reason, as well as its simplicity
and useful properties, the Poisson process is a popular choice for modeling
customer arrivals.
In our case, N(τ) counts the arrival of a request for any product, and is
created by merging independent, product-specific Poisson counting processes
N (τ) with rates λ into a single combined process.
p p
For the sake of explanation and without the loss of generality, we assume
these processes are homogenous, i.e., the intensity λ does not depend on time.
Thus, the intensity of each product subprocess is λ and is constant, and
p
(cid:80)
from the properties of the Poisson process, we have λ = λ.
p∈P p
However, in our MDP definition, we discretize the selling period (0,T)
into k intervals, the timesteps2. Assuming for now that each timestep in the
discretization has constant length T, we approximate the Poisson process
k
with a discrete demand process D(t), t ∈ {1,2,3,...,k}. D(t) gives the
probability of product arrivals in each timestep. However, it allows for at
most one product to be requested at any timestep. D(t) is a multi-class
extension of the Bernoulli process with |P|+1 possible outcomes, with +1
for no (empty) product request arriving in a timestep. The probabilities of
2Timesteps are not to be confused with the timeslots that form the resources used in
the charging products, and that can have coarser discretization.
15the different products at timestep t in D(t) are chosen in the following way:
(cid:40)
λp, p ∈ P
p (p,t) = k (3)
req 1−(cid:80) (λj), p = ∅
j∈P k
See Section 4 for details on how the discrete demand process with product
request probabilities chosen this way behaves concerning the compound
Poisson process N(τ) and what is the quality of this approximation.
We consider the approximation of N(τ) by D(t) to be acceptable for
a given number of timesteps k and the expected number of requests λT
under one condition. D(t) can generate at most 1 request in any interval of
the discretization. In contrast, N(τ) can generate any positive number of
requests in any interval. Thus, for D(t) to approximate N(τ) well, we want
the expected number of requests assigned to different intervals between D(t)
and N(τ) to be low. Specifically, we want to pick k so that the error term
Err2(k,λ) is small. In the next section, we explain what we mean by Err and
λ 2
justify this approximation.
4 Properties of the Demand Approximation
in the MDP Model
Here, we formalize the definition of the discrete demand process used in our
MDP model and quantify how well it approximates the assumed Poisson
demand process.
4.1 Convergence of the Discrete Demand Process
In this section, we will assume that the selling period (0,T) is a unit interval
(0,1), which is without a loss of generality through simple rescaling of the
timeline. Next, let us describe the Poisson demand process obtained by
combining the Poisson sub-processes for each product. We assume there is a
Poisson counting process N (τ) for each product p ∈ P, defined by the rate
p
λ , generating arrival times of requests for that specific product. From the
p
convenient properties of Poisson processes, the arrival times of all product
requests can be considered as coming from a single compound Poisson process
(cid:80)
N(τ) with intensity λ = λ . The compound Poisson process generates
p∈P p
arrivals of requests for any product.
16However, since we discretize the time into k timesteps, we have to approx-
imate the arrivals generated by the Poisson process by the discrete Bernoulli
process. The Bernoulli process is a sequence of Bernoulli trials, defined by
the number of trials k and the probability of arrival of any request in a single
trial p. The approximation is based on the fact that the Poisson process is
a limit of a sequence of Bernoulli processes created by keeping the product
kp = λ constant and taking k → +∞.
We can reconstruct the arrival process for individual products by assigning
product indices to the arrivals according to the probabilities λ1, λ2,..., λm.
λ λ λ
Arrival in the Bernoulli process can then be assigned a product type by
sampling a discrete distribution with probabilities λ1, λ2,..., λm, one for each
λ λ λ
product. We refer to the resulting object as discrete demand process with
m+1 outcomes, where m outcomes correspond to the m possible products
and m+1 outcome corresponds to no request being made. We call this process
the discrete demand process Dk(t) in k time steps and demand intensities
λ
λ = [λ ,...,λ ].
1 m
Proposition 1. For given λ = [λ ,...,λ ], let Dk(t) be a discrete demand
1 m λ
process with k steps, k ≥
(cid:80)m
λ , and m + 1 distinct possible values with
i=1 i
outcomes i ∈ {1,...,m,∅} occurring with probability:
(cid:40)
λi, i ∈ {1,...,m}
p = k
i 1−(cid:80)m λi, i = ∅
i=1 k
Then, the sequence of the discrete demand processes Dk(t) converges with
λ
k → +∞ to the compound Poisson process with arrival intensity λ =
(cid:80)m
λ
i=1 i
and discrete jump size distribution with probabilities λ1, λ2,..., λm.
λ λ λ
Proof. Consider the discrete demand process for a single product, which is a
Bernoulli process Bk(t,p ) with k steps and probability of success p = λ /k.
i i i
This is a sequence of k i.i.d. binary random variables with the probability of
success p . We know that with k → +∞, the sequence Bk(t,λ /k) converges
i i
to a Poisson process with intensity λ . Combining the m Poisson processes
i
with λ ,i ∈ {1,...,m} gives a Poisson process with intensity λ =
(cid:80)m
λ
i i=1 i
with the required jump size distribution by the properties of combined Poisson
processes.
Then, the issue is whether these individual Bernoulli processes combine
into the required discrete demand process Dk(t) and whether this process
λ
converges to the same Poisson process as the combination of their limits.
17We show this using two Bernoulli processes consisting of i.i.d. random
variables X and Y , i ≤ k. The success probability in the first process is p
i i 1
and p in the second process. These two processes can be combined into a
2
new Bernoulli process with success probability p = p +p , and a random
1 2
variable Z that determines the success class in the combined process with
class probabilities p1, p2. However, unlike in the case of the Poisson process,
p p
the arrival classes are no longer independent since success in X implies failure
j
in Y . For separate processes, the event {X = 1,Y = 1} for some j has
j j j
probability p p . Nevertheless, since we have p = λ1,p = λ2, the probability
1 2 1 k 2 k
is P(X = 1,Y = 1) = λ1λ2. Since P(X = 1,Y = 1) goes to 0 with 1
j j k2 j j k2
while p and p go to 0 with 1, the sequence of combined Bernoulli schemes
1 2 k
approaches the desired Poisson process in the limit k → +∞.
To summarize, we use a discrete demand process in the MDP model. The
demand process consists of k die-rolls with m+1 sided unbalanced die. Each
die roll corresponds to a random arrival of a product request in some timestep.
The m sides of the die correspond to the different product requests made in
different timesteps, and the m + 1 side represents no request done by the
customer in the given step. The proposition means that the demand process
defined this way approximates the assumed naturally occurring Poisson arrival
processes that generate arrivals of m different products on a real timeline.
4.2 Approximation Quality
The approximation quality depends on the value of k that represents the
number of timesteps the continuous selling period (0,1) is split into. However,
the discrete demand process with the probability of any arrival p = (cid:80)m λi
i=1 k
is defined so that the expected number of requests in k steps, which has
binomial distribution and expected value E(Bin(k,p)) = pk, exactly matches
the expected number of arrivals from the Poisson process, E(Pois(λ)) = λ,
in the (0,1) interval. Therefore, the Poisson and the approximating discrete
processes do not differ in this metric.
Thus, the approximation error is more nuanced. By definition, the discrete
demand process allows only for 0 or 1 arrival in every timestep. However, the
Poisson process can generate more than one arrival in any real interval. This
means that the discrete demand model systematically underestimates the
probability of more than one arrival (by effectively setting this probability to
0) while simultaneously overestimating the probability of exactly one arrival
18Figure 5: Visualization of the error term Err (k,λ) (left) and the rela-
2
tive error Err2(k,λ) (right) for different values of k and λ. Err is defined
λ 2
in Proposition 2 and represents the number of ignored events caused by
the discretization of the Poisson process. With the number of timesteps k
approaching 0, the number of ignored events approaches the expected number
of events λ. The relative error term Err2(k,λ) (Equation (10)) represents the
λ
number of ignored events relative to the expected number of events.
19in every timestep of the discretization. This over- and under-estimation can
be understood from the distribution of the number of arrivals in an interval
of length 1/k in the Poisson process. We will denote this random variable X
and note that it is Poisson distributed3:
(λ)je−λ/k
P(X = j) = k
j!
We get the approximation error through Taylor expansion of this term for
different values of j corresponding to the probabilities of 0,1 and 2 or more
arrivals:
λ λ
P(X = 0) = e−λ/k = 1− +o( )
k k
λ λ λ
P(X = 1) = ( )e−λ/k = +o( )
k k k
λ
P(X > 1) = o( )
k
Therefore, the approximation error in one timestep is in o(λ) and gets
k
smaller with k increasing. However, we want to ensure not only that the
error in one timestep is small but also that the accumulated error over all
timesteps is acceptable.
To this end, we define two error metrics. Err is the expected number of
1
intervals in the discrete demand process where the Poisson process would have
more than one arrival. That is, the expected value of a Binomial distribution
Bin(p,k) with p being the probability of 2 or more arrivals from the Poisson
process in an interval of length λ.
k
However, Err only gives an expected number of intervals where we have
1
a problem with more than one arrival, not the number of arrivals ignored
by the discrete demand process, which could be higher. For this reason,
we define Err , which gives the expected number of arrivals missed in all
2
3Unfortunately, the terminology here is historically misleading. In the discrete case, we
have a sequence of Bernoulli distributed random variables (sequence of coin tosses), which
is called a Bernoulli process. The process’s number of successes (heads) is distributed
according to a Binomial distribution. However, in the continuous case, we have a sequence
of exponentially distributed random variables that form a Poisson process, and the number
of arrivals in the process that is Poisson distributed.
20timesteps caused by ignoring additional (over one) arrivals in every timestep.
By symmetry argument from E(Pois(λ)) = E(Bin(k, λ)), this is also the
k
expected number of timesteps with one arrival added by the discrete demand
process over the Poisson process. Err is formally given as:
2
Err = Err (k,λ)E [X −1|X > 1]
2 1 Pois(λ/k)
where X ∼ Pois(λ) is the Poisson distributed random variable that describes
k
the number of arrivals in an interval of length 1. E[X −1|X > 1] is then the
k
expected number of arrivals over one, conditional on more than one arrival.
The following proposition gives formulas for these two kinds of errors.
Proposition 2. Let Dk(t) be a Bernoulli demand process that converges to a
λ
Poisson process with intensity λ on a unit interval when the discretization of
time into k timesteps is refined in the limit k → +∞.
Then, the expected number of timesteps in which the Poisson process will
register more than one arrival is
Err (k,λ) = k −(k +λ)e−λ/k (4)
1
The expected number of arrivals over one, summed across all timesteps, is
Err (k,λ) = λe−λ/k +(λ−k)(1−e−λ/k) (5)
2
Proof. Equation (4) is easily seen from the definition. The expected value of
Bin(p,k) is kp, substituting the probability of two or more events in Poisson
as p = 1−P(X = 0)−P(X = 1) = 1−e−λ/k − λe−λ/k and simplifying the
k
expressions immediately provides the result.
To show Equation (5), we need to express the conditional expectation
E [X −1|X > 1]
Pois(λ/k)
of a Poisson distributed random variable X ∼ Pois(λ):
k
21+∞
(cid:88)
E[X −1|X > 1] = jP(X −1 = j|X > 1) (6)
j=0
+∞
(cid:88) P(X −1 = j ∧X > 1)
= j (7)
P(X > 1)
j=0
+∞
1 (cid:88)
= (j −1)P(X = j) (8)
1−P(X = 0)−P(X = 1)
j=2
(λ −λe−λ/k)−(1−e−λ/k −λe−λ/k)
= k (9)
1−e−λ/k −λe−λ/k
We use the fact that
E(cid:2) Pois(λ)(cid:3)
= λ. We get the desired term by multiplying
k k
the last line by Err1 and simplifying.
In Proposition 1, we show that the discrete demand process converges to
the Poisson process when refining the discretization of time. However, it does
not tell us about the quality of the approximation for a given k. Proposition 2
explicitly quantifies the two kinds of errors in the approximation in terms of
the number of timesteps k and the expected number of requests λ. Since the
error depends on the expected number of requests λ, in experiments, we will
use the relative error
Err (k,λ)
2
(10)
λ
to quantify the quality of the approximation. The interpretation of this
relative error is number of missed additional requests per expected request. As
mentioned above, in the discrete model, these requests are not actually missed;
they show up as “hallucinated” additional requests at different timesteps.
5 Dynamic Pricing Algorithm Using MCTS
This section describes the method we use to derive the dynamic pricing
policies. Our solution method of choice for large-scale problems is MCTS.
Unlike tabular methods, such as Value Iteration (VI) or policy iteration,
MCTS does not need to enumerate the whole state space. Instead, it looks
for the best action from the current state and expands only to states that the
22Algorithm 1 Dynamic pricing MCTS algorithm for MDPs. Based on [25],
[26].
1: procedure MCTS(state;c,d ,n )
max iter
2: n ← 0
3: while n < n do
iter
4: n ← n+1
5: s ← state
0
6: r ← 0
0
7: d ← 0
8: for i = 1 to d do ▷ Selection-Expansion loop to max. tree
max
depth d
max
9: if s not encountered yet then ▷ Expansion
10: n ← 0
s
11: for a ∈ A do
12: n ← 0
s,a
13: q ← 0
s,a
14: d ← i
15: if ∃a ∈ A s.t. n = 0 then ▷ Avoids undefined operation on
s,a
line 18
16: a ← a
i
17: else
(cid:113)
18: a ← argmax q −c ln(ns) ▷ Selection (using UCB1)
i a∈A s,a ns,a
19: s′ ← T (s′|a ,s) ▷ Sample execution of action a in s
i
20: r ← r +R(s,a ,s′) ▷ Cumulative reward received up to it-
i i−1 i
eration i
21: s ← s
i
22: s ← s′
23: if s terminal or n = 0 then
s,ai
24: break
25: r ← r +rollout(s) ▷ Value estimation
d d−1
26: for i = 1 to d do ▷ Backpropagation
27: q ←
nsi,aiqsi,ai+(r d−ri−1)
▷ Average q with reward from lev-
si,ai nsi,ai+1 s,a
els below
28: n ← n +1
si si
29: n ← n +1
si,ai si,ai
30: return argmax q
a∈A s0,a
23Algorithm 2 Rollout algorithm used in Algorithm 1
1: procedure Rollout(state = (c,t,p))
2: s ← state
3: r ← 0
4: while s is not terminal do
5: a′ ← select random action from A
6: s′ = (c′,t′,p′) ← T (s′|a ,s) ▷ sample result of action a′ in s
i
7: r ← r+R(s,a′,s′)
8: ∆t ← sample inter-arrival time distribution of demand at timestep
t
9: p′ ← sample product request at t+∆t
10: s ← (c′,t+∆t,p′)
11: return r
system is likely to develop into. However, unlike VI, for every state, MCTS
only approximates best actions. MCTS improves its approximations of best
action with the number of iterations.
Nonetheless, it can be stopped anytime to provide currently the best
approximation of optimal action. These properties make it a helpful method-
ology in dynamic pricing. With MCTS, we can quickly apply changes in
the environment to the solver. Even in large systems, the price offer can
be generated quickly enough for a reasonable customer response time. To
the best of our knowledge, this is the first attempt to solve the EV charging
dynamic pricing problem using MDP and MCTS.
In our MCTS implementation, we use the popular Upper Confidence-
bound for Trees (UCT) variant of MCTS [25], [27], [28] that treats each
node as a bandit problem and uses the upper confidence bound formula to
make the exploration-exploitation trade-off. We split the presentation of the
algorithm into two parts. The first part covers the the selection and expansion
of tree nodes that form the tree policy and backpropagation. This part of the
algorithm is shown in Algorithm 1. The second part of the algorithm is the
rollout policy, which is shown in Algorithm 2.
5.1 Tree Policy and Backpropagation
The input of Algorithm 1 is the current state for which we seek to estimate the
best action a. The algorithm has three parameters, the exploration constant
24c, the number of iterations n , and the tree depth limit d .
iter max
The input state corresponds to a tree’s root from which the MCTS
algorithm builds the search tree. Each tree node corresponds to a state s of
the MDP, and for each node, we keep track of how many times was the given
node visited, n , how many times was action a used in given state, n and a
s s,a
running average of the q-value of each state-action pair, q . These values
s,a
are iteratively updated during the run of the algorithm.
Each iteration of the MCTS algorithm works in 4 stages: selection, ex-
pansion, value estimation, and backpropagation. The existing tree nodes are
first traversed in the Selection step (Lines 8-24). Each tree node selects an
action using the UCB formula (Line 18). The exploration constant c sets the
appropriate exploration-exploitation trade-off between selecting actions with
high q-value averages and actions that were not yet tried often. The node
to transition to is determined by sampling the MDP transition function T
for the outcome of action a in the state s (Line 19)4. If the resulting state
has already initialized tree node variable n , the same process is repeated
s
from this node. This process is repeated for d iterations or until a node
max
corresponding to a terminal state is reached or until a state that does not yet
have a corresponding tree node is encountered.
When a previously unseen state is encountered, the tree is Expanded with
a new node corresponding to this state (Line 9). Additionally, the stat-action
counters and q-values are initialized for this node for all possible a ∈ A.
However, for the freshly expanded node, the exploration term in the UCB
formula on Line 18 has an undefined value. Therefore, if there is an untried
action in some state s, we first try any unused action a with n = 0 (Line
s,a
16). Additionally, when we encounter an untried action, we terminate the
selection-expansion stage, even if the tree depth limit has not been reached yet
(Line 23). As a result, our MCTS implementation proceeds in a breadth-first
manner.
During the selection phase of the algorithm, the cumulative reward col-
lected up to ith iteration is recorded (Line 20). The estimated value of the
newly explored state-action pair q is then calculated in the Value estimation
s,a
stage of the iteration using the rollout (Line 25).
4The description of the algorithm may lead one to expect that during the selection
phase of the algorithm, each selection leads to a new state and one level lower in the tree.
This is not necessarily true for all MDPs since the transition from state s in ith step in
the selection loop can result in a state encountered in some previous step. However, this
cannot happen in our finite-horizon MDP as it includes timestep as a state variable.
25The fourth stage of the MCTS iteration is the backpropagation (Lines 26).
Here, the cumulative rewards are used to update the average q-value of the
node on the ith level of the tree, q . The value is updated with r −ri−1,
si,ai d
all reward collected below the ith level in the tree, including the reward from
the rollout. The update is done by averaging the previous update values with
the new value (Line 27).
Thefourstages(selection—expansion—valueestimation—backpropagation)
are repeated as many times as allowed. Finally, when the main loop termi-
nates, the algorithm estimates the best action based on the q-value of actions
in the tree’s root (Line 30).
5.2 Rollout Policy
Algorithm 2 presents the second part of the MCTS algorithm, the rollout.
It is applied from state-action pairs that were used for the first time in the
tree policy. The rollout approximates the reward of the selected action by
quickly reaching the terminal state. In our experiments, we use the uniformly
random rollout policy that applies random actions until a terminal state in
the MDP is reached.
Because we use the Poisson process (Bernoulli processes after discretiza-
tion) as the customer arrival process, we can speed up the rollout by sampling
the time to the next arrival from the inter-arrival distribution. It has a geo-
metric distribution in the discretization (Line 8 in Algorithm 2). Therefore,
we can arrive at the terminal state in fewer steps. In the rollout, we simu-
late actions without storing their resulting states until reaching a terminal
state. When the terminal state is reached, the rollout terminates immediately,
returning the accumulated reward.
5.2.1 Implementation
OurimplementationisbasedontheMCTSimplementationinthePOMDPs.jl[26]
library that uses recursion when traversing the tree, unlike the description in
Algorithm 1. We provide the unrolled iterative description for clarity.
The implementation we use reuses the constructed decision tree between
the steps of the “real” MDP that happen outside of the MCTS algorithm,
improving the convergence speed. In our experiments, we build the tree to
the maximum depth d = 3 with the exploration constant set to c = 1.
max
The number of iterations is capped at n = 800. We find that these low
iter
26numbers are sufficient for sufficiently good performance in our experiments
and result in a reasonable computation time.
6 Experiments and Results
We compare our MCTS pricing solution against multiple baselines on arti-
ficially generated problem instances modeled on a real-life charging station
dataset provided by a local German charging station operator.
The main goal of the experiments is to demonstrate the viability of the
MCTS dynamic pricing algorithm for EV charging. To show this, we run a
number of simulations with problem instances created using different problem
parameters and compare the average performance of the MCTS algorithm
with the baseline methods.
6.1 Problem Instances
Table 1: Overview of the problem instance parameters.
Instance property Structure Parameters
Fixed parameters
Request length [h] Exponential distribution θ = 3
Request start time [h] Normal distribution µ = 12, σ = 3
Customer budget [1/h] Normal distribution µ = 1, σ = 0.5
Instance duration [h] 00:00 to 23:59
Varied parameters
Request arrivals [#/24h] Discretized Poisson proc. 6 to 288
Timeslot length [h] discrete value range 15min to 12h
Timestep length [h] discrete value range 2min to 1.5h
While the generated instances are simple, the approach is flexible, and it
can accommodate much more complicated inputs. We use basic distributions
with parameters fitted to our EV charging dataset. The user budgets are
sampled from the user budget distribution for the given charging session
27length. As we did not have any data on user budgets, the choice of pa-
rameters is arbitrary. We set the charging session start times to follow the
normal distribution and the charging session length to follow the exponential
distribution. We set both distributions to be independent. While this is
not true in practice, it is sufficient to showcase our method and make the
definition of the instances simpler.
The request arrival times are obtained from a discretized homogeneous
Poisson process, as described in Section 4. Time-variable Poisson demand
process intensity that appears in the real world would be handled by a simple
transformation of the timeline, resulting in discrete variable-length timesteps,
which lead to a constant probability of request arrival in the discretized arrival
process. Therefore, using a homogenous Poisson demand process is without
the loss of generality. Where available, we set their parameters based on the
data analysis of our dataset; these values are collected in Table 1.
Each problem instance has a form of a charging request sequence, as
shown by Equation (1). Each pricing method, including the baseline methods
described below, then prices the requests in the order they come in. The
accumulated reward is averaged across 100 simulated runs to measure the
performance of each method for comparison with other methods.
6.2 Baseline Methods
Because of the difficulties of evaluating the dynamic pricing policies, we
evaluate our proposed MCTS solution against three baseline methods: flat
rate, MDP-optimal VI, and Oracle pricing methods. The flat rate represents
the lower bound on the revenue we might expect from a dynamic pricing
solution. The VI baseline returns an optimal pricing policy and represents the
best possible pricing method for the MDP model. Finally, the Oracle policy
represents the unachievable upper bound on dynamic pricing performance.
Oracle provides the best possible allocation by assuming the CS operator
has a perfect knowledge of future requests and EV users’ budgets, which is
unrealistic in real-world use cases.
6.2.1 Flatrate
This baseline provides a lower bound for our MCTS pricing method and a
reference for showing how much improvement dynamic pricing could bring.
28The Flatrate baseline is a single flat price per minute of charging that is used
for all charging requests.
The flat price is determined from a set of “training” pricing problem
instances that take the form of sequences shown in Equation (1). In each each
problem instance, we evaluate every possible flat-rate price that corresponds
to an action in the MDP, and measure the resulting revenue. The price that
maximizes the average revenue across all training sequences is then used as
the flat-rate price in the testing simulation runs. This pricing method still
uses reservations and the reservations are allocated in in sequence, resulting
in first-requested, first-reserved allocation.
6.2.2 Value Iteration (VI)
Our second baseline pricing method is the optimal MDP policy generated by
a VI algorithm [29]. VI is a simple yet accurate method for solving MDPs
that converges to an optimal policy for any initialization. The advantage of
VI is that it quickly converges to a complete near-optimal pricing policy at
the cost of enumerating the whole state space in memory.
Based on the structure of our MDP state, the state-space size of our
MDP model is kcn2n, where k is the number of timesteps, n is the number
0
of charging timeslots and c is the initial charging capacity. If we limit the
0
reservations to contain only the contiguous timeslots, as we do, the state-space
size reduces to kcnn(n+1)/2. This gives VI an exponential space complexity
0
in the number of timeslots. Thus, it does not scale well to larger problem
instances. Therefore, we use VI only to obtain optimal policies on smaller
problem instances to validate the heuristic approach of MCTS.
Note that there are other exact solution methods for MDP problems than
VI, such as policy iteration or linear programming. All these methods can
provide the same optimal pricing policy as VI. However, just like VI, all these
methods require enumeration of the whole state space. Our choice of VI is,
therefore, arbitrary in this sense.
Since VI gives optimal pricing policy, we use it to benchmark the per-
formance of our MCTS approach, which, since it is heuristic, is expected to
provide worse results. How much worse is the question we want to answer by
comparing the performance of the two methods on small-enough instances
that VI can solve.
296.2.3 Oracle
Finally, we compare our MCTS-based pricing method against the Oracle
baseline strategy. It’s important to note that the Oracle strategy, while used
for benchmarking, isn’t practically applicable due to its nature. Unlike other
pricing strategies, Oracle relies on having prior knowledge of the entire request
sequence and the budgets of EV users to determine prices.
Usingthisknowledge, Oraclemaximizestheoptimizationmetrictoprovide
a theoretical upper bound on the revenue and resource usage achievable by
any pricing-based allocation strategy. It works for large and small problem
instances; therefore, we can use it to track the performance of MCTS across
a wide range of problem sizes.
The Oracle pricing solution is obtained from a linear program. For kth
sequence of charging requests d with requests indexed by i, the optimum
k
revenue is the result of a simple binary integer program:
(cid:88)
maximize x ⌊b ⌋ , subject to: (11)
i i A
i∈{1...|d |}
k
(cid:88)
x pj ≤ cj j = 1,...,|R| (12)
i i 0
i∈{1...|d |}
k
x ∈ {0,1} i = 1,...,|d |.
i k
where, x are the binary decision variables that determine which requests from
i
d are accepted by the CS operator. In the objective function (Equation (11)),
k
the term ⌊b ⌋ = max a denotes the fact that the budget values in
i A a∈A,a ≤bi
the sequence d are mapped to the closest lower values in the action space A.
k
Conditions (Equation (12)) mean that the accepted charging sessions have to
use fewer resources than the initial supply c .
0
6.3 Results
We evaluate the proposed MCTS pricing method in the experiments against
the baselines described in Section 6. First, we analyze the performance of the
MCTS algorithm in a set of small instances to select the best hyperparameters.
Then, we compare the performance of the MCTS algorithm with the Flatrate,
VI, and Oracle baselines in a set of different instances, ranging from instances
with a small state space where VI can still generate results to instances with
a larger state space.
3031
.secnatsni
001
morf
degareva
era
seulaV
.stnemirepxe
eht
fo
stluser
detceleS
:2
elbaT
ecnatsnI
.gvA
fo
.mun
egarevA
.mun
.gvA
petsemiT
tolsemiT
]h[
noitazilitU
]1[
euneveR
dohteM
]s[
emitnuR
stseuqer
detpecca
stseuqer
fo
]nim[.neL
.muN
]nim[.neL
.muN
200.0
16.8
89.81
85.35
54.76
00.51
69
063
4
200.0
28.41
76.63
87.15
13.46
05.7
291
081
8
200.0
41.02
59.94
27.15
66.26
00.5
882
021
21
elcarO
300.0
18.92
82.67
95.05
19.75
05.2
675
06
42
500.0
37.53
68.29
94.05
85.55
76.1
468
04
63
700.0
13.54
69.321
25.94
76.15
38.0
8271
02
27
100.0
47.7
89.81
27.84
33.93
00.51
69
063
4
100.0
61.31
76.63
25.74
63.83
05.7
291
081
8
100.0
53.71
59.94
69.54
41.04
00.5
882
021
21
etartalF
200.0
57.52
82.67
70.44
94.83
05.2
675
06
42
300.0
19.03
68.29
28.34
72.83
76.1
468
04
63
800.0
48.34
69.321
69.14
46.63
38.0
8271
02
27
764.1
51.7
89.81
84.54
10.44
00.51
69
063
4
210.5
10.21
76.63
58.44
17.34
05.7
291
081
8
509.01
21.61
59.94
22.54
51.34
00.5
882
021
21
STCM
314.93
95.32
82.67
02.44
86.04
05.2
675
06
42
755.39
68.72
68.29
31.44
99.93
76.1
468
04
63
714.054
57.83
69.321
57.24
15.83
38.0
8271
02
27
200.0
11.4
00.9
44.94
81.84
00.03
84
027
2
200.0
61.5
49.31
84.24
88.34
00.02
27
084
3
IV
200.0
60.7
89.81
67.44
32.64
00.51
69
063
4depth=1 depth=3 depth=8 depth=15 depth=50
23
] 22
1
[
e
u
n
e 21
v
e
r
n
a 20
e
M
19
Exploration const.: 0.5 1.0 3.0 6.0 10.0
18
251251251 251251251 251251251 251251251 251251251
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 k 0 0 k 0 0 k 0 0 k 0 0 k
0 0 0 0 0
log of # of MCTS iterations
Figure 6: Figure showing the performance of the MCTS algorithm on the
same problem instance with varied hyperparameters. The plots show means
from 100 different request sequences.
6.3.1 MCTS Hyperparameter Grid Search
The MCTS algorithm (Algorithm 1) has three parameters, the number of
iterations n , the exploration constant c, and the tree depth limit d . To
iter max
determine its hyperparameters, we use a modestly sized instance with 12
timeslots and 96 timesteps, three charging stations, and expected 24 charging
requests.
We perform a full grid search with discretized sequences of these parame-
ters. The results of the grid search are shown in Figure 6. The results are
averaged from 100 sampled request sequences. The main takeaway from the
grid search is that the number of iterations has the most significant impact
on the performance of the algorithm. The exploration constant and the tree
depth limit have a much smaller impact. However, the number of iterations
and the tree depth have the highest impact on the computation time, as seen
in Figure 7. Therefore, in the following experiments, we set the number of
32Depth 1 3 8 15 50
10
5
]
s
[ 2
e
m
1
ti
n
u 5
r
e
c
n 2
a
t
s
n 0.1
i
f
o 5
g
o
l
2
0.01
5 100 2 5 1000 2 5 10k
log of # of MCTS iterations per action
Figure 7: Figure showing the runtime of the MCTS algorithm on the
same problem instance with varied hyperparameters and exploration constant
fixed at 0.3. Changing the exploration constant has a negligible effect on the
resulting runtime. The plots show means from 100 different request sequences.
33Oracle Flatrate MCTS VI
1
]
1
[ 0.9
e
u
n
e
v
re 0.8
d
e
z
ali
m
0.7
r
o
N
0.6
0 2 4 6 8 10 12
Timeslot length [h]
Figure 8: Performance of the evaluated methods when refining the dis-
cretization of the charging resources (and reducing timeslot length) in the
24 hour charging window with fixed expected charging demand (24 hours of
charging). VI runs out of memory for a timeslot shorter than 6 hours. The
demand process discretization error is kept constant by increasing the number
of timesteps.
iterations to n = 10000, the tree depth to d = 10, and the exploration
iter max
constant to c = 3.
6.3.2 Varying Timeslot Length
In the next experiments, we evaluate the performance of the MCTS algorithm
againsttheFlatrate, VI,andOraclebaselinesinasetofinstanceswithvarying
timeslot and timestep lengths to demonstrate the scalability of our approach.
The problem instance again models a charging station with three chargers in
a 24 hour day and expected demand for 24 hours of charging. The number
of charging timeslots is varied from 2 timeslots, each 12h, to 240 timeslots
at 15min each. The number of timesteps in each instance is then calculated
34100
80
]
1
[
e 60
u
n
e
v
e
R
40
20
Oracle Flatrate MCTS VI
Figure 9: Violin plot showing the performance of the MCTS algorithm
compared to the Flatrate, VI, and Oracle baselines in small instances. The
vertical axis is the mean revenue averaged over 100 instances. The Oracle
baseline provides a theoretical bound on the best achievable performance.
35Oracle Flatrate MCTS
80
70
60
]
1
[
e
u
n 50
e
v
e
R
40
30
20
50 100 150 200 250
Expected number of charging requests [1]
Figure 10: Performance of the evaluated methods when increasing demand.
Numberoftimeslotsisfixedat24. VIdoesnotrunfortheseprobleminstances
due to memory constraints.
36Oracle
MCTS
Flatrate
6 8 10 12 14 16 18 20 22 24 6 8 10 12 14 16 18 20 22 24
Figure 11: Allocation of the charging requests in a single instance of the
problem. The left-hand side (blue) is all the charging requests in the instance.
The right-hand side shows the allocation of the requests by the different
methods, with the revenue from each request illustrated by the proportion
of the darker color. The horizontal axis is the time of the day; the vertical
axis is the charging station. The row also roughly corresponds to the order of
request arrivals, that is, the later the charging request was made, the higher
it is in the figure.
using Equation (10) to make the relative discretization error constant at 0.06
missed charging requests per one expected request. Therefore, the number
of timesteps varies between 16 timesteps at 1.5h each to 768 approximately
2min timesteps.
Detailed results are shown in Table 2, the table shows averages from
100 instances. For VI, we show all results, for the rest of the methods, we
show results for instances with timeslots of lentgh 20min and its multiples.
Figure 8 shows the performance of the evaluated methods, averaged from 100
runs, normalized to the oracle baseline. The optimal VI baseline runs out
of memory for more than 4 resources. Performance of all methods improves
with as timeslot length decreases. The Flatrate baseline performs the worst,
as expected. The MCTS algorithm keeps close to the performance of the VI
baseline and outperforms the Flatrate baseline.
Forthe100instanceswith6htimeslots, wealsogiveasenseofthevariance
of the results in Figure 9, which shows that the MCTS algorithm, stochastic
by nature, does not significantly increases the variance of the results over the
other baselines.
376.3.3 Varying Expected Demand
For the second experiment, we fix the timeslot length at 1h, and we vary the
expected number of requests. The results of this experiment are presented
in Figure 10. As can be expected, the revenue of all the pricing methods
increases with increasing demand, and the gap between MCTS and Flatrate
grows with demand. The VI baseline does not run in these instances.
The number of expected requests directly influences the error caused by
the discretization of the demand process (see Equation (10)). Therefore, to
control the error, we have to vary the number of timesteps in this experiment.
We calculate the number of timesteps and their length to keep the relative
error constant again at 0.06 ignored charging requests per one expected
request. This results in 192 timesteps at 7.5min each for the instances with
the smallest demand, and 1920 timesteps, each 45s, for the instances with
the highest number of expected requests.
6.3.4 Focusing on Single Instance
The mechanism by which the MCTS and Oracle baseline outperform the
Flatrate is illustrated in Figure 11. The figure shows the allocation of the
charging requests in a single instance of the problem with a timeslot length
of one hour. In this high-demand instance, all pricing strategies allocate
almost all of the available capacity (3 charging stations). However, the MCTS
algorithm and the Oracle baseline manage to extract more revenue either
from the same requests or from requests that the Flatrate baseline does not
allocate as it runs out of capacity earlier.
7 Conclusions
In conclusion, we have described an MDP based model for dynamic pricing
of reserved EV charging service, a type of charging service that is not well-
studied in the literature, but which could be an important part of the future
EV charging infrastructure as more EVs get on roads. This charging service
allows the CS operator to maximize his revenue while providing a guaranteed
charging service to EV drivers who plan their trips in advance.
We model the customer demand as a Poisson process, a common choice
in the literature. However, to apply that to the MDP model, we need to
discretize the process into discrete steps. We show that the discretization
38introduces error and that this error can be controlled by increasing the number
of timesteps, as we describe in the experiments. But this also increases the
computational complexity of the problem. By quantifying this error, we
can control the tradeoff between the approximation error and computational
complexity, offering a practical tool for future researchers working on similar
models.
To solve our MDP model, we propose an MCTS heuristic algorithm
that optimizes the pricing decisions. We show that this pricing algorithm
outperforms the Flatrate baseline, and is competitive with the optimal VI
baseline in instances where this baseline is available. We also show that this
MCTS algorithm is scalable to larger instances and that its performance does
not deteriorate with regard to the globally optimal Oracle baseline.
For the future work, we see two main directions. First, we do not fit
the model to the real-world data, but rather use the data to generate the
problem instances. If appropriate training data becomes available, we can fit
the demand model to the data and evaluate the performance of the pricing
algorithm on the real-world data. This will allow us to verify the impact of
the discretization error on the performance of the pricing algorithm. Second,
we would like to validate the approach of dynamic pricing of the reserved
charging services in combination with the multi-criterial optimization of the
driver trips [30]. Joining the two techniques in a multi-agent simulation, such
as in [31], would allow us to evaluate the impact of our pricing scheme on the
drivers as well as the CS operator.
8 Acknowledgments
ThisworkwassupportedbytheprojectofCTUno. SGS/22/168/OHK3/3T/13,
“Decision-making in large, dynamic multi-agent scenarios 2”.
References
[1] G. O. Boateng, H. Si, H. Xia, et al., “Automated Valet Parking and
Charging: A Dynamic Pricing and Reservation-Based Framework Lever-
aging Multi-Agent Reinforcement Learning,” IEEE Transactions on
Intelligent Vehicles, pp. 1–18, 2024, issn: 2379-8904. doi: 10.1109/TIV.
392024.3421524. [Online]. Available: https://ieeexplore.ieee.org/
abstract/document/10582308 (visited on 08/09/2024).
[2] J. Zhang, S. Li, and C. Wang, “Range-Constrained and Stable Fed-
erated Charging Scheme for Electricity Vehicles,” IEEE Transactions
on Intelligent Transportation Systems, pp. 1–11, 2024, issn: 1558-0016.
doi: 10.1109/TITS.2024.3435001. [Online]. Available: https://
ieeexplore.ieee.org/document/10623910 (visited on 08/08/2024).
[3] J. Gao, T. Wong, C. Wang, and J. Y. Yu, “A Price-Based Iterative
Double Auction for Charger Sharing Markets,” IEEE Transactions
on Intelligent Transportation Systems, vol. 23, no. 6, pp. 5116–5127,
Jun. 2022, issn: 1558-0016. doi: 10.1109/TITS.2020.3047984. [On-
line]. Available: https://ieeexplore.ieee.org/document/9325919
(visited on 08/09/2024).
[4] L. Hou, J. Yan, C. Wang, and L. Ge, “A Simultaneous Multi-Round
Auction Design for Scheduling Multiple Charges of Battery Electric
VehiclesonHighways,”IEEE Transactions on Intelligent Transportation
Systems, vol. 23, no. 7, pp. 8024–8036, Jul. 2022, issn: 1558-0016.
doi: 10.1109/TITS.2021.3075202. [Online]. Available: https://
ieeexplore.ieee.org/document/9424480 (visited on 08/08/2024).
[5] C. Yao, S. Chen, M. Salazar, and Z. Yang, “Joint Routing and Charging
Problem of Electric Vehicles With Incentive-Aware Customers Con-
sidering Spatio-Temporal Charging Prices,” IEEE Transactions on
Intelligent Transportation Systems, vol. 24, no. 11, pp. 12215–12226,
Nov. 2023, issn: 1558-0016. doi: 10.1109/TITS.2023.3286952. [On-
line]. Available: https://ieeexplore.ieee.org/document/10164169
(visited on 08/09/2024).
[6] C. Fang, H. Lu, Y. Hong, S. Liu, and J. Chang, “Dynamic Pricing for
Electric Vehicle Extreme Fast Charging,” IEEE Transactions on Intel-
ligent Transportation Systems, vol. 22, no. 1, pp. 531–541, Jan. 2021,
issn: 1558-0016. doi: 10.1109/TITS.2020.2983385. [Online]. Avail-
able: https://ieeexplore.ieee.org/document/9057557 (visited on
08/08/2024).
[7] A. Abdalrahman and W. Zhuang, “Dynamic Pricing for Differenti-
ated PEV Charging Services Using Deep Reinforcement Learning,”
IEEE Transactions on Intelligent Transportation Systems, vol. 23,
no. 2, pp. 1415–1427, Feb. 2022, issn: 1558-0016. doi: 10.1109/TITS.
402020.3025832. [Online]. Available: https://ieeexplore.ieee.org/
document/9210540 (visited on 08/09/2024).
[8] P. V. Dahiwale, Z. H. Rather, and I. Mitra, “A Comprehensive Review
of Smart Charging Strategies for Electric Vehicles and Way Forward,”
IEEE Transactions on Intelligent Transportation Systems, pp. 1–21,
2024, issn: 1558-0016. doi: 10.1109/TITS.2024.3365581. [Online].
Available: https://ieeexplore.ieee.org/document/10457989 (vis-
ited on 08/08/2024).
[9] E. S. Rigas, S. D. Ramchurn, and N. Bassiliades, “Managing Elec-
tric Vehicles in the Smart Grid Using Artificial Intelligence: A Sur-
vey,” IEEE Transactions on Intelligent Transportation Systems, vol. 16,
no. 4, pp. 1619–1635, Aug. 2015, issn: 1558-0016. doi: 10.1109/TITS.
2014.2376873. [Online]. Available: https://ieeexplore.ieee.org/
document/7000557 (visited on 08/08/2024).
[10] Y. Yu, C. Su, X. Tang, et al., “Hierarchical Game for Networked Electric
VehiclePublicChargingUnderTime-BasedBillingModel,”IEEE Trans-
actions on Intelligent Transportation Systems,vol.22,no.1,pp.518–530,
Jan. 2021, issn: 1558-0016. doi: 10.1109/TITS.2020.2994192. [On-
line]. Available: https://ieeexplore.ieee.org/document/9102356
(visited on 08/08/2024).
[11] L. Hou, C. Wang, and J. Yan, “Bidding for Preferred Timing: An
Auction Design for Electric Vehicle Charging Station Scheduling,”
IEEE Transactions on Intelligent Transportation Systems, vol. 21,
no. 8, pp. 3332–3343, Aug. 2020, issn: 1558-0016. doi: 10.1109/
TITS.2019.2926336. [Online]. Available: https://ieeexplore.ieee.
org/document/8759942 (visited on 08/08/2024).
[12] M. Seyedyazdi, M. Mohammadi, and E. Farjah, “A Combined Driver-
Station Interactive Algorithm for a Maximum Mutual Interest in Charg-
ing Market,” IEEE Transactions on Intelligent Transportation Systems,
vol. 21, no. 6, pp. 2534–2544, Jun. 2020, issn: 1558-0016. doi: 10.1109/
TITS.2019.2919934. [Online]. Available: https://ieeexplore.ieee.
org/document/8736505 (visited on 08/09/2024).
[13] Y. Zhang, P. You, and L. Cai, “Optimal Charging Scheduling by Pricing
for EV Charging Station With Dual Charging Modes,” IEEE Transac-
tions on Intelligent Transportation Systems,vol.20,no.9,pp.3386–3396,
41Sep. 2019, issn: 1558-0016. doi: 10.1109/TITS.2018.2876287. [On-
line]. Available: https://ieeexplore.ieee.org/document/8520744
(visited on 08/09/2024).
[14] S. Edelstein. “Do EV fast-charging reservations make sense? EVgo
thinks so,” Green Car Reports. (Jun. 2, 2021), [Online]. Available:
https://www.greencarreports.com/news/1132440_do-ev-fast-
charging-reservations-make-sense-evgo-thinks-so (visited on
08/28/2024).
[15] N. Kumar, R. Chaudhry, O. Kaiwartya, and N. Kumar, “ChaseMe:
A Heuristic Scheme for Electric Vehicles Mobility Management on
Charging Stations in a Smart City Scenario,” IEEE Transactions on
Intelligent Transportation Systems, vol. 23, no. 9, pp. 16048–16058,
Sep. 2022, issn: 1558-0016. doi: 10.1109/TITS.2022.3147685. [On-
line]. Available: https://ieeexplore.ieee.org/document/9762651
(visited on 08/08/2024).
[16] W. Wu, Y. Lin, R. Liu, et al., “Online EV Charge Scheduling Based
on Time-of-Use Pricing and Peak Load Minimization: Properties and
Efficient Algorithms,” IEEE Transactions on Intelligent Transportation
Systems, vol. 23, no. 1, pp. 572–586, Jan. 2022, issn: 1558-0016. doi: 10.
1109/TITS.2020.3014088. [Online]. Available: https://ieeexplore.
ieee.org/document/9185026 (visited on 08/09/2024).
[17] A. Bakhtiari, A. U. Zaman Patwary, F. Ciari, A. Moeini, and A. Haje-
brahimi, “A Comparative Analysis of Time-Based and Hybrid Pricing
Models for Electric Vehicle Charging,” Procedia Computer Science,
The 15th International Conference on Ambient Systems, Networks
and Technologies Networks (ANT) / The 7th International Confer-
ence on Emerging Data and Industry 4.0 (EDI40), April 23-25, 2024,
Hasselt University, Belgium, vol. 238, pp. 757–762, Jan. 1, 2024, issn:
1877-0509. doi: 10.1016/j.procs.2024.06.088. [Online]. Avail-
able: https://www.sciencedirect.com/science/article/pii/
S1877050924013243 (visited on 10/02/2024).
[18] C. Lei and Y. Ouyang, “Dynamic pricing and reservation for intelligent
urbanparkingmanagement,”Transportation Research Part C: Emerging
Technologies, vol. 77, pp. 226–244, Apr. 1, 2017, issn: 0968-090X. doi:
10.1016/j.trc.2017.01.016. [Online]. Available: https://www.
42sciencedirect.com/science/article/pii/S0968090X17300232
(visited on 08/09/2024).
[19] R. Basmadjian, B. Kirpes, J. Mrkos, M. Cuchy´, and S. Rastegar, “An
Interoperable Reservation System for Public Electric Vehicle Charg-
ing Stations: A Case Study in Germany,” in Proceedings of the 1st
ACM International Workshop on Technology Enablers and Innovative
Applications for Smart Cities and Communities, ser. TESCA’19, New
York, NY, USA: Association for Computing Machinery, Nov. 13, 2019,
pp. 22–29, isbn: 978-1-4503-7015-8. doi: 10.1145/3364544.3364825.
[Online]. Available: https://doi.org/10.1145/3364544.3364825
(visited on 02/10/2020).
[20] M. Cuchy´, J. Vokˇr´ınek, and M. Jakob, “Multi-Objective Electric Ve-
hicle Route and Charging Planning with Contraction Hierarchies,”
Proceedings of the International Conference on Automated Planning
and Scheduling, vol. 34, pp. 114–122, May 30, 2024, issn: 2334-0843.
doi: 10.1609/icaps.v34i1.31467. [Online]. Available: https://
ojs.aaai.org/index.php/ICAPS/article/view/31467 (visited on
08/29/2024).
[21] Z. Zhang, Y. Wan, J. Qin, W. Fu, and Y. Kang, “A Deep RL-Based
Algorithm for Coordinated Charging of Electric Vehicles,” IEEE Trans-
actions on Intelligent Transportation Systems,vol.23,no.10,pp.18774–
18784, Oct. 2022, issn: 1558-0016. doi: 10.1109/TITS.2022.3170000.
[Online]. Available: https://ieeexplore.ieee.org/document/
9766186 (visited on 08/09/2024).
[22] X. Guo and O. Herna´ndez-Lerma, “Continuous-Time Markov Decision
Processes,” in Continuous-Time Markov Decision Processes: Theory
and Applications, ser. Stochastic Modelling and Applied Probability,
X. Guo and O. Hern´andez-Lerma, Eds., Berlin, Heidelberg: Springer,
2009, pp. 9–18, isbn: 978-3-642-02547-1. doi: 10.1007/978-3-642-
02547-1_2. [Online]. Available: https://doi.org/10.1007/978-3-
642-02547-1_2 (visited on 03/09/2023).
[23] J. Lee, W. Jeon, G.-H. Kim, and K.-E. Kim, “Monte-Carlo Tree Search
in Continuous Action Spaces with Value Gradients,” Proceedings of the
AAAI Conference on Artificial Intelligence, vol. 34, no. 04, pp. 4561–
4568, 04 Apr. 3, 2020, issn: 2374-3468. doi: 10.1609/aaai.v34i04.
435885. [Online]. Available: https://ojs.aaai.org/index.php/AAAI/
article/view/5885 (visited on 03/09/2023).
[24] Continous Pricing, Lufthansa Group, Oct. 2020. [Online]. Available:
https://www.lufthansaexperts.com/shared/files/lufthansa/
public/mcms/folder_102/folder_3212/folder_4994/file_
148593.pdf.
[25] Mausam and A. Kolobov, Planning with Markov Decision Processes:
An AI Perspective. Dec. 18, 2016. [Online]. Available: https://www.
microsoft.com/en-us/research/publication/planning-markov-
decision-processes-ai-perspective/ (visited on 11/06/2019).
[26] M.Egorov,Z.N.Sunberg,E.Balaban,et al.,“POMDPs.jl:Aframework
for sequential decision making under uncertainty,” Journal of Machine
Learning Research, vol. 18, no. 26, pp. 1–5, 2017. [Online]. Available:
http://jmlr.org/papers/v18/16-300.html.
[27] P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-time Analysis of the
Multiarmed Bandit Problem,” Machine Learning, vol. 47, no. 2, pp. 235–
256, May 1, 2002, issn: 1573-0565. doi: 10.1023/A:1013689704352.
[Online]. Available: https://doi.org/10.1023/A:1013689704352
(visited on 12/05/2022).
[28] R. Coulom, “Efficient selectivity and backup operators in Monte-Carlo
tree search,” in International Conference on Computers and Games,
Springer, 2006, pp. 72–83.
[29] S. Russell and P. Norvig, Artificial Intelligence: A Modern Approach,
Thirdedition.PrenticeHall,1995.[Online].Available:http://cumincad.
scix.net/cgi-bin/works/Show?1bb0.
[30] M. Cuchy`, J. Vokˇr´ınek, and M. Jakob, “Multi-Objective Electric Ve-
hicle Route and Charging Planning with Contraction Hierarchies,”
in Proceedings of the International Conference on Automated Plan-
ning and Scheduling, vol. 34, 2024, pp. 114–122. [Online]. Available:
https://ojs.aaai.org/index.php/ICAPS/article/view/31467
(visited on 08/29/2024).
[31] R. Basmadjian, B. Kirpes, J. Mrkos, and M. Cuchy´, “A Reference
Architecture for Interoperable Reservation Systems in Electric Vehicle
Charging,” Smart Cities, vol. 3, no. 4, pp. 1405–1428, 4 Dec. 2020.
44doi: 10.3390/smartcities3040067. [Online]. Available: https://
www.mdpi.com/2624-6511/3/4/67 (visited on 11/22/2020).
45