Focal Surface Holographic Light Transport using Learned
Spatially Adaptive Convolutions
ChuanjunZheng YichengZhan LiangShi OzanCakmakci KaanAkşit∗
UniversityCollege UniversityCollege MassachusettsInsti- Google UniversityCollege
London London tuteofTechnology USA London
UnitedKingdom UnitedKingdom USA UnitedKingdom
ABSTRACT simulationsandactualhardware.Ei-
Computer-GeneratedHolography(CGH)isasetofalgorithmic therlearnedorconventional,simulat-
methodsforidentifyinghologramsthatreconstructThree-Dimensi- inglightpropagationamongmulti-
onal(3D)scenesinholographicdisplays.CGHalgorithmsdecom- pleplanesina3Dvolumeiscomputa-
pose3Dscenesintomultiplanesatdifferentdepthlevelsandrely tionallydemanding,asa3Dvolume
onsimulationsoflightthatpropagatedfromasourceplanetoa isrepresentedwithmultipleplanes
targetedplane.Thus,for𝑛planes,CGHtypicallyoptimizesholo- andeachplanerequiresaseparate
gramsusing𝑛plane-to-planelighttransportsimulations,leading calculationoflightpropagationtore-
tomajortimeandcomputationaldemands.Ourworkreplacesmul- constructthetargetimage.
tiple planes with a focal surface and introduces a learned light Ourworkintroducesalearnedfo-
transportmodelthatcouldpropagatealightfieldfromasource calsurfacelightpropagationmodel
planetothefocalsurfaceinasingleinference.Ourlearnedlight thatcouldhelpfreelightsimulations
transportmodelleveragesspatiallyadaptiveconvolutiontoachieve fromplanedependence.Specifically,
depth-varyingpropagationdemandedbytargetedfocalsurfaces. our model can propagate a phase-
Theproposedmodelreducesthehologramoptimizationprocess only hologram represented with a
upto1.5x,whichcontributestohologramdatasetgenerationand planetoatargetedfocalsurface,see
thetrainingoffuturelearnedCGHmodels. Fig.1.Inourmodel,weextractSpa-
tially Varying (SV) depth features
CCSCONCEPTS ofafocalsurfacebylearningaset
ofSVkernels.Inaddition,ourmodel
•Hardware Emergingopticalandphotonictechnologies;
→ combinestheseSVlearnedkernels
• Human-centered computing Displays and imagers; •
→ withSpatiallyInvariant(SI)kernels
Computingmethodologies Computergraphics.
→ usingaSpatiallyAdaptiveConvolu-
Figure 1: Conventional
tion(SAC).Thus,effectivelycaptur-
KEYWORDS LightTransportVS.Proposed
ingSVandSIfeaturesoflightpropa- Focal Surface Light Trans-
Computer-GeneratedHolography,LightTransport,Optimization, gationoverafocalsurface.Ourwork port.(Source image: Tobi 87,
SpatiallyAdaptiveConvolutions,ConvolutionalNeuralNetworks makesthefollowingcontributions: Link:WikimediaCommons)
Learnedfocalsurfacelighttransportmodel.Byuniquely
1 INTRODUCTION •
leveragingSACforCGH,weintroduceanewlearnedlighttrans-
Computer-GeneratedHolography(CGH)isafamilyofalgorithmic portmodel.Ourmodelidentifiesamappingfromaphase-only
methodsusedtogenerateholographicinterferencepatterns.Identi- hologramrepresentedoveraplanetoatargetedfocalsurface.
fyingtheseinterferencepatternsusinglearned[Shietal.2022]and Focal surface-based hologram optimization. To evaluate
•
optimization[Kavaklıetal.2023a]CGHmethodsrequireconven- itspracticality,weutilizeourmodelfora3Dphase-onlyholo-
tionalsimulationsoflightpropagationfromplane-to-plane[Mat- gram optimization application. Compared with conventional
sushima and Shimobaba 2009; Shen and Wang 2006]. Recently, lightpropagationbasedhologramoptimizationmethods[Kavaklı
learnedproxymethods[Choietal.2021;Kavaklıetal.2022]have etal.2023a,b],ourapproachacceleratestheoptimizationpro-
been proposed to replace conventional light propagation meth- cessupto1.5x,leadingtospeedupbenefitsinhologramdataset
ods[MatsushimaandShimobaba2009;ShenandWang2006].As generationandtrainingfuturelearnedCGHmodels.
theselearnedproxymethodsforlightpropagationaretrainedus- ExperimentalValidation.Weevaluateourmethodinsimu-
•
ingcamera-in-the-loopstrategies,theyareabletocaptureimper- lationforvariouspropagationdistancesandvalidatetheresult
fectionsofopticalhardware,closingthegapbetweentheoretical usingabench-topon-axisholographicdisplayprototype.
∗denotescorrespondingauthor
2 FOCALSURFACELIGHTTRANSPORT
WeintroducetheSAC,amodifiedconvolutionstructureforencod-
This work is licensed under a Creative Commons
“Attribution-NonCommercial-NoDerivatives4.0Interna- ingSVfeatures.LeveragingtheSAC,ourworkenablesthelearned
tional”license. focalsurfacelighttransportnetwork.
4202
tcO
9
]RG.sc[
1v45860.0142:viXraChuanjunZheng,YichengZhan,LiangShi,OzanCakmakci,andKaanAkşit
Figure2:Ourproposedlearnedfocalsurfacelighttransportmodel.TheprocessstartswithaninputhologramHandafocal
s thu erf Sa pce atD iat lo lyg Aen de ar pa tt ie vesp Mat oi da ull ly ev (a Sr Ay Min )g toke ar cn he il es ve[V fi o] c, aw lh se ur re fa𝑖 c= e0 l, ig1, h2 t,3 tri an nd si pca ot re ts .It nhe thin ed Se Ax Mo ,f Vsc 0a ,Vle 𝑗s ,. VT 𝑙h ,Vo 𝑧se rek pe rr en se el ns ta kre eru nti el li sze ud sein
d
3 3 3 3
atdifferentspatiallocations,where0,𝑗,𝑙,and𝑧indicatespecificpositions.(Sourceimage:Tobi87,Link:WikimediaCommons)
2.1 SpatiallyAdaptiveConvolution Initially,theSVkernelV R1 ×ℎ ×𝑤 ×𝑐˜ ×𝑘 ×𝑘 isintroduced,theout-
∈
vS ota lund tia or nd aC lNon ev uo rl au lti No en t. wG oi rv ken (Ca Nn Nin ),p wut hf ee ra etu 𝑐˜r ,e ℎ˜I˜ ,a∈ nR d𝑐 𝑤˜ ˜×ℎ r˜ × ep𝑤˜ rein sea ntC to hn e- p tiu at llc yh Aan dn ae pl ti is vese (t St Ao )1 kto err ne ed lu Acet ∈he Rn 𝑐ˆu ×m ℎ ×b 𝑤er ×o 𝑐˜ ×f 𝑘p ×ar 𝑘am ise ct oer ms. pT uh tee dSp ba y-
multiplyingtheWandV,whichdefinedas:
numberofchannels,height,andwidthoftheinputI˜(inourcase,
𝑐˜=3,𝑤˜ =1080,ℎ˜=1920),thediscreteconvolutionbasedonaSI A 𝑐,𝑥,𝑦,𝑐 ′,𝑥 ′,𝑦 ′ =V 1,𝑥,𝑦,𝑐 ′,𝑥 ′,𝑦 ′ W 𝑐,𝑐 ′,𝑥 ′,𝑦 ′ , (2)
[ ] [ ]∗ [ ]
kernelW
∈R𝑐ˆ ×𝑐˜ ×𝑘 ×𝑘
isdefinedas: where1 ≤𝑐 ≤𝑐ˆ,1 ≤𝑐 ′ ≤𝑐˜,1 ≤𝑥 ≤ℎand1 ≤𝑦 ≤𝑤.Eq.2en-
hancestheoutputchannelcapacityinVwhilemaintainingspatially
I [(cid:32)𝑐 (cid:32)(cid:32)(cid:32),𝑥, (cid:32)(cid:32)𝑦 (cid:32)(cid:32)]= W (cid:32)(cid:32)(cid:32)(cid:32)[(cid:32)(cid:32)𝑐 (cid:32)(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)𝑐 (cid:32)′,𝑥 (cid:32)(cid:32)(cid:32)′(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)𝑦 (cid:32)(cid:32)(cid:32)(cid:32)′(cid:32)]I˜ [(cid:32)(cid:32)𝑐 (cid:32)(cid:32)(cid:32)′(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)𝑥 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)+(cid:32)(cid:32)(cid:32)𝑥 ′, (cid:32)(cid:32)(cid:32)𝑦 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)+(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)𝑦 (cid:32)(cid:32)(cid:32)(cid:32)′(cid:32)], (1) variant.BothVandWcanbeeitherpre-definedorlearned,making
𝑐,𝑥,𝑦 thenetworkcontent-adaptive.ByusingA,theSACisdefinedas:
′∑︁′ ′
output SIKernel input
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125) I [𝑐,𝑥,𝑦 ]= A (cid:32)(cid:32)[(cid:32)(cid:32)𝑐 (cid:32)(cid:32)(cid:32)(cid:32), (cid:32)(cid:32)𝑥 (cid:32)(cid:32)(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)𝑦 (cid:32)(cid:32),𝑐 ′(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)𝑥 (cid:32)(cid:32)(cid:32)(cid:32)′(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)𝑦 (cid:32)(cid:32)(cid:32)(cid:32)′(cid:32)]I˜ [𝑐 ′,𝑥 +𝑥 ′,𝑦 +𝑦 ′ ]. (3)
where𝑐˜and𝑐ˆindicatethenumberofinputandoutputchannels. 𝑐 ′, ∑︁𝑥 ′,𝑦 ′
SAKernel
Theindicessatisfy1 𝑐 ′ 𝑐˜and1 𝑐 𝑐ˆ.Thepair 𝑥 ′,𝑦 ′
belongstothesetΩ 𝑘≤ ,whi≤ chspecifies≤ a𝑘 ≤ 𝑘convolution( alwin) - SACretainsboththedim(cid:124)ensiona(cid:123)l(cid:122)cohere(cid:125)nceoftheSIkernelinCNN
( ) × andisspatiallyvariantatthesametime.NotethatwhenWbecomes
dow.Thesummationoperationactsonallinputchannels,which
anall-onetensor,Eq.3isequivalenttotheSVconvolutioninCNN.
impliesthateachinputchannelcontributestoeveryoutputchannel.
AccordingtoEq.(1),thisoperationischaracterizedbyakernelthat 2.2 LearnedFocalSurfaceLightTransport
isspatiallysharedandcontent-independent.Learning-basedlight
WefirstgenerateSVkernelstoencodedepth-varyingfeaturesof
transportmodelscoulduseEq.(1)asabasicoperation.However,it
thefocalsurface,whicharelaterusedinSACforfocalsurfacelight
ischallengingforthismethodtoprojectahologramontoafocal
transport.Fortheschematicfigureofoursystem,pleaseseeFig.2.
surface.Aseachpixelonthehologramplanemaycorrespondtoa
SpatiallyVaryingKernelGeneration. AsshowninFig.2,theSV
differentdepthonthefocalsurface,whichmakestheSIkernela
s 2u 01b 9-o ],p it nim clual dc inh goi fc oe cuto sic na gp otu rr oe us t-p oa ft -i fa ol cly usva er ffy ei cn tg sdfe ua etu tore ds e[ pS tu he vt ara il -. k foe cr an le sl ug re fan ce era Dtion Rm
1
×o 1d ×u ℎle ×𝑤tak ases int ph ue th s.o Wlo egr aa dm opH ted∈ tR he1 × a3 r× chℎ i× te𝑤 cta un rd
e
∈
ance.Atypicalsolutionistoemployalargenumberofparameters inRSGUNet[Huangetal.2018]forSVkernelgenerationmodule.
forfeatureencoding,resultinginanincreasedmemoryfootprint. Theoutputofeachdecoderlayerisintegratedwithfeaturemaps
Alternatively,wecouldconsiderusingSVconvolution[Suetal. fromdifferentlayersintheencoders.Thencombinedfeatureswill
2 p0 o1 r9 a; teZ sh te wn oge nt ea wl. d2 i0 m21 e] n. sT ioh ne sS ℎV ,𝑤ker inn te olV
SI∈
keR r𝑐ˆ n× eℎ l,× w𝑤 × h𝑐 e˜ × re𝑘 × ℎ𝑘 ai nn dco 𝑤r- b oe fSfe Vd kin ert no eS lp sat Via 𝑖ll ,y wV ha er ry ein Vg 𝑖Fea Rtu 𝑛r ×e 𝑐˜𝑖( ×S 𝑘V ×F 𝑘) ,m 𝑖o =du 0l ,e 1,t 2o ,l 3ea rern fera ss te ot
[ ] ∈
indicateheight,andwidthoftheoutputfeature.However,relying differentscalelevels,𝑐˜𝑖 denotestheinputchannel,𝑘isthekernel
ℎ 𝑤
solely on SV kernels may increase model capacity due to extra size,and𝑛 = 2𝑖
×
2𝑖 isthenumberofkernels.TheSVFmodule
parameters,particularlywhenℎand𝑤 arelarge.Thesealternative containsconvolutionlayersandaveragepoolinglayers.Tomitigate
designsalldemandextranetworkcapacity. artifacts,wemodifytheglobalfeaturemodulein[Huangetal.2018]
toanattentionblockandapplyitatthebottleneckoftheU-Net.
SpatiallyAdaptiveConvolutionOperation. Toaddresstheseprob-
lems,weproposetheSAC.Ourmethodreducesthenetworkpa- FocalSurfaceLightTransport. WeleveragethegeneratedSVkernels
rametersbymultiplyingtheSVkernelwiththestandardSIkernel. tobuildourlighttransportmodulebasedonRSGUNet[Huangetal.FocalSurfaceHolographicLightTransportusingLearnedSpatiallyAdaptiveConvolutions
0mm Infocus Outoffocus Infocus 10mm Infocus Outoffocus Infocus
Figure3:Visualcomparisonofsimulatinglighttransportedontoafocalsurface(specifiedinthefirstrowofeachcase)at0mm
and10mmpropagationdistances.ThegroundtruthisobtainedviaASM[MatsushimaandShimobaba2009].Bothfocusedand
defocusedregionsindicatepoorperformanceoftheU-Netmodel.(Sourceimage:MattH.Wade,Link:WikimediaCommons)
2018].ThemoduletakesthehologramHasinputwithoutrequiring lighttransportmodelwithourfocal-surface-basedmodel:
depth,asthedepthfeatureofthefocalsurfaceisinherentlyencoded Hˆ argmin 𝐹 H,D ,𝑠R . (5)
withinthelearnedSVkernels.TointegratetheSVfeaturesinto ← H L( ( ) )
theencoder,weproposeaSpatiallyAdaptiveModule(SAM)based Inthiscase,thehologramoptimizationproblemissimplified.Our
onSAC.AsshowninFig2,wefirstreplacetheSIkernelWtoan approachsimultaneouslyoptimizesholograminthreecolorpri-
all-onestensorinEq.(2),whichignorestheSIkernelsandonly mariesandmaintainsphase-onlyatthesametime.
considerstheSVkernelstocapturetheoriginalSVinformation.
3 EVALUATIONANDDISCUSSION
Inparallel,weintroducetheSIkernelsbacktoEq.(2)asalearn-
ingparameterandmultiplywiththeSVkernelsforbetterdiverse We generate the focal surface light transport dataset based on
featureextraction.Thesefeaturesfromthetwooperationswillbe previous work [Kavaklı et al. 2023a,b] at the resolution 1920
×
concatenatedtoformtheoutputofSAM.Finally,theglobalfeature 1080. See Section 1 of the supplementary material for more de-
moduleandthedecoderwillprocesstheoutputtogeneratethe tails. We use Adam optimizer 𝛽1 = 0.9,𝛽2 = 0.999,𝛼𝑑𝑒𝑐𝑎𝑦 =
(
reconstructionatthegivenfocalsurfacedenotedasR. 0.5𝑎𝑓𝑡𝑒𝑟 50𝑒𝑝𝑜𝑐ℎ𝑠 .Themodelistrainedfor500epochs,with
Lossfunction. Weemploythe𝐿2normtoquantifythediscrepancy
aninitialLearningR) ate(LR)of2 ×10−4.Allexperimentsarecon-
ductedonasingleNVIDIAV10016GGPU.
between the reconstruction R and the target image R′. Both R
andR′arefocalsurfacedependedimagereconstructions.SinceR Evaluation. Toassesstheimagequality,weutilizemetricsincluding
containsbothfocusanddefocusregions[Kavaklıetal.2023a],we PeakSignal-to-noiseRatio(PSNR),StructuralSimilarity(SSIM),and
utilizeabinarymaskMthathighlightsonlythefocuspartsofthe PerceptualSimilarityMetric(LPIPS)[Zhangetal.2018].First,we
image.Thelossfunctionforthereconstructiononasinglefocal
assessthequalityoflightsimulationonafocalsurface.Asshown
surface 𝐷 isdefinedas:
L inTbl.1,ourmodeloutperformsU-Net[Ronnebergeretal.2015]
L𝐷 =𝛼 0M ∥R −R′ ∥22 +𝛼 1(1 −M )∥R −R′ ∥22, (4) across all metrics. Fig. 3 shows that our model preserves more
high-frequency content than U-Net, providing finer details and
where𝛼0and𝛼1representweights(𝛼0=1and𝛼1=0.5).
sharperedges,closertothegroundtruth. Second,weutilizeour
2.3 OptimizingHologramswithFocalSurfaces
Table1:Evaluationofvariouslighttransportmodelsonour
Recently,learning-basedmethodshavebeenproposedtosolve3D dataset.Thespeedistestedbysimulatinganall-in-focus,
hologramgenerationtasks[Choietal.2021;Shietal.2022].How- full-color3Dimagewithsixdepthplanes.Notethathigher
ever,theideal3Dhologramfortheholographicdisplayhasnotyet
PSNR/SSIMandlowerParams/Speedindicatebetterperfor-
beenpreciselydefined[Kimetal.2024].Optimization-basedholo-
mance,denotedby and inthetables.
gramgenerationmethods[Kavaklıetal.2023a,b]couldpotentially ↑ ↓
helpidentifytheideal3Dhologramandgeneratehologramdatasets
PSNR(dB) SSIM Params Speed
forlearning-basedapproaches.Typically,optimizationmethodsare Methods ↑ ↑ Stage ↓ ↓
0mm/10mm 0mm/10mm (M) (s)
basedonthemultiplanerepresentation,whereafull-colorholo- ASM(GT)[Matsushima
- - Two - 0.4559
gramissynthesizedbymakinguseofthephasepatternsofthethree andShimobaba2009]
colorprimaries.Followingpreviouswork[Kavaklıetal.2023b], U-Net[Ronneberger
29.662/30.112 0.8015/0.7760 Single 7.7760 0.0565
eachsingle-colorphasepatternisobtainedby: etal.2015]
Ours 36.016/34.279 0.9128/0.8470 Single 7.4446 0.0471
3
Hˆ𝑝 argmin 𝑒𝑖H𝑝 K𝑝2,𝑠R𝑝 , (1) modelfora3Dphase-onlyhologramoptimizationapplicationunder
← Hp 𝑝 ∑︁=1L (cid:16)(cid:12) ⊗ (cid:12) (cid:17) 0𝑚𝑚propagationdistance.Optimizinghologramswithsixtarget
(cid:12) (cid:12)
where𝑝denotestheindexofacolorprimary,H𝑝 istheSLMphase, planesusingAngularSpectrumMethod(ASM)[Matsushimaand
Hˆ𝑝 istheoptimizedSLMphase,K𝑝 isthewavelength-dependent Shimobaba2009]isdenotedasASM6,whileOurs4andOurs6
lighttransportkernel[MatsushimaandShimobaba2009],R𝑝 isthe representoptimizinghologramsusingourmodelwithfourand
targetimageintensity,𝑠 isanintensityscalingfactor(𝑠 = 1by sixfocalsurfaces,respectively.Allhologramsarereconstructed
default), denotesconvolution.Wesubstitutetheconventional usingASMforperformanceassessment.AsshowninFig.4and
⊗
hturTdnuorG
sruO
teN-UChuanjunZheng,YichengZhan,LiangShi,OzanCakmakci,andKaanAkşit
Ours6 ASM6
Rearfocus Frontfocus Rearfocus Frontfocus
Outoffocus Outoffocus Infocus Infocus Infocus Outoffocus Outoffocus Outoffocus Infocus Infocus Infocus Outoffocus
Figure4:VisualcomparisononsimulatedhologramsoptimizedusingASM6andOurs6under0mmpropagationdistance.All
hologramsarereconstructedusingASMforevaluation.(Sourceimage:JaimiePhillips,Link:WikimediaCommons)
Table2:ComparisonofimagequalityforthesceneinFig.4 comparedtozerodistance 0𝑚𝑚 .SeeSection3inthesupplemen-
amongASM6,Ours6,andOurs4acrossdifferentiterations tarymaterialformorecom( pariso) ns.Futureimprovementscould
at0mmpropagationdistance.NotethathigherPSNR/SSIM includeusingafactorizedlargerkernelforlong-distancepropaga-
andlowerLPIPS/Speed indicatebetterperformance. tion.Inaddition,ourmodelfocusesondepth-varyingpropagation
↑ ↓
withina3Dvolume,moreinvestigationisneededfordepth-varying
ASM6 /Ours6 Iteration propagationoftheentirevolumeusingconditionalnetworks.
/Ours4 50 100 200
Speed(s) 42.580/30.182/20.869 84.626/61.460/39.792 171.49/119.02/77.878 ACKNOWLEDGMENTS
↓
PSNR(dB) 27.377/27.501/26.088 27.795/27.598/26.905 27.801/27.625/26.928
SSIM ↑ 0.7100/0.6868/0.6142 0.7193/0.6933/0.6753 0.7195/0.6890/0.6767 Theauthorsthankreviewersfortheirvaluablefeedback;Louise
↑
LPIPS 0.3971/0.4747/0.5431 0.3894/0.4687/0.4707 0.3889/0.4787/0.4689 L.Xieforherfeedbackonthemanuscript;ZiyangChenandDoğa
↓
Yılmazfortheirdiscussionsandassistance.WealsothankNorth-
Tbl.2,Ours6achievescomparableresultswithabout70%ofthe easternUniversityforcomputingresourcesforearlyexperiments.
optimizationtimecomparedtoASM6.ActualcapturesofOurs6
REFERENCES
andASM6inFig.5demonstratethecapabilityofourmodelfor
generating3Dholograms.Formoredetailsonthedisplayprototype SuyeonChoi,ManuGopakumar,YifanPeng,JonghyunKim,andGordonWetzstein.
2021.Neural3dholography:Learningaccuratewavepropagationmodelsfor3d
andcomparisons,seeSections2and3insupplementarymaterial. holographicvirtualandaugmentedrealitydisplays.ACMTransactionsonGraphics
(TOG)40,6(2021),1–12.
JieHuang,PengfeiZhu,MingruiGeng,JiewenRan,XingguangZhou,ChenXing,
PengfeiWan,andXiangyangJi.2018.Rangescalingglobalu-netforperceptual
imageenhancementonmobiledevices.InProceedingsoftheEuropeanconference
oncomputervision(ECCV)workshops.0–0.
KorayKavaklı,YutaItoh,HakanUrey,andKaanAkşit.2023a.Realisticdefocusblur
formultiplanecomputer-generatedholography.In2023IEEEConferenceVirtual
Realityand3DUserInterfaces(VR).IEEE,418–426.
Ours6 ASM6 KorayKavaklı,LiangShi,HakanUrey,WojciechMatusik,andKaanAkşit.2023b.
Multi-colorHologramsImproveBrightnessinHolographicDisplays.InSIGGRAPH
Figure 5: Comparing experimental captures of ASM 6
Asia2023ConferencePapers.1–11.
andOurs6under0mmpropagationdistances.(Sourceimage KorayKavaklı,HakanUrey,andKaanAkşit.2022.Learnedholographiclighttransport.
:JaimiePhillips,Link:WikimediaCommons) AppliedOptics61,5(2022),B50–B55.
DongyeonKim,Seung-WooNam,SuyeonChoi,Jong-MoSeo,GordonWetzstein,and
YoonchanJeong.2024. HolographicParallaxImproves3DPerceptualRealism.
ComputationalComplexityAnalysis. First,weassessthecomputa-
arXivpreprintarXiv:2404.11810(2024).
tionalcomplexityofsimulatingafull-color,all-in-focus3Dimage KyojiMatsushimaandTomoyoshiShimobaba.2009.Band-limitedangularspectrum
acrosssixdepthplanes.AsshowninTbl.1,conventionalASM- methodfornumericalsimulationoffree-spacepropagationinfarandnearfields.
Opticsexpress17,22(2009),19662–19673.
basedmodel[MatsushimaandShimobaba2009]requireseighteen OlafRonneberger,PhilippFischer,andThomasBrox.2015. U-net:Convolutional
forwardpassestosimulateafull-color,all-in-focus3Dimagewith networksforbiomedicalimagesegmentation.InMedicalimagecomputingand
computer-assistedintervention–MICCAI2015.Springer,234–241.
sixdepthplanes.Incontrast,ourmodelsimulatesthethreecolor-
FabinShenandAnboWang.2006.Fast-Fourier-transformbasednumericalintegration
primaryimagessimultaneouslyontoafocalsurfacewithasingle methodfortheRayleigh-Sommerfelddiffractionformula.Appliedoptics45,6(2006),
forwardpass,reducingsimulationtimeby10xandachievingbetter 1102–1110.
LiangShi,BeichenLi,andWojciechMatusik.2022.End-to-endlearningof3dphase-
image quality with fewer parameters compared to U-Net [Ron-
onlyhologramsforholographicdisplay.Light:Science&Applications11,1(2022),
nebergeretal.2015].Second,weevaluatehologramoptimization. 247.
In Tbl. 2, using four focal surfaces (Ours 4) to approximate six HangSu,VarunJampani,DeqingSun,OrazioGallo,ErikLearned-Miller,andJanKautz.
2019.Pixel-adaptiveconvolutionalneuralnetworks.InProceedingsoftheIEEE/CVF
planesforfocusanddefocusguidance,speedingupoptimization ConferenceonComputerVisionandPatternRecognition.11166–11175.
byupto2x.Increasingthenumberoffocalsurfacestosix(Ours6) RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang.2018.The
unreasonableeffectivenessofdeepfeaturesasaperceptualmetric.InProceedings
achievescomparableresultswithabouta1.5xspeedup.
oftheIEEEconferenceoncomputervisionandpatternrecognition.
ChuanjunZheng,DamingShi,andYukunLiu.2021. Windowingdecomposition
LimitationsandFutureWorks. AsshowninFig.3,theperformance
convolutionalneuralnetworkforimageenhancement.InProceedingsofthe29th
of our model degrades at a long propagation distance 10𝑚𝑚 ACMInternationalConferenceonMultimedia.424–432.
( )
                                                                                                                                           Focal Surface Holographic Light Transport using Learned
Spatially Adaptive Convolutions
CHUANJUN ZHENG,UniversityCollegeLondon,UnitedKingdom
YICHENG ZHAN,UniversityCollegeLondon,UnitedKingdom
LIANG SHI,MassachusettsInstituteofTechnology,UnitedStatesofAmerica
OZAN CAKMAKCI,Google,UnitedStatesofAmerica
KAAN AKŞIT∗,UniversityCollegeLondon,UnitedKingdom
Fig.1. Basedonpreviousworks[Kavaklıetal.2023a],weoptimizethehologramgivenanimageandits
correspondingdepthmap.ThehologramisreconstructedonsixdepthplanesusingASM.Subsequently,
wegeneratethefocalsurfacebyrandomlyassigningdifferentdepthvaluestothein-focusregions.Inthe
in-focusrestorationmodule,wesegmentthe3Dreconstructionsbasedonfocalsurfacesandmergetheminto
atargetimage,withamaskindicatingthefocusedareas.(Sourceimage:Tobi87,Link:WikimediaCommons)
1 DATASETGENERATION
WestartwithanRGBimageanditscorrespondingdepthmaptooptimizethehologramH,following
methodsfrompreviouswork[Kavaklıetal.2023a].Theoptimizationiscarriedoutwithtwodifferent
propagationdistances(0𝑚𝑚and10𝑚𝑚)attheresolution1920 1080.Forbothcases,wereducethe
×
iterationcountstointroducenoiseintothehologram,whichisbeneficialforthemodeltolearnthe
high-frequencyinformation.Theoptimizedhologramisthenpropagatedontosixdistinctdepth
planes,producingsixreconstructions.Next,wegeneratethefocalsurfaceDbyrandomlyassigning
different depth values to the focused regions on these six depth planes. These depth values are
selectedfromauniformdistributionrepresentingsixdistinctdepthvalues.AsshowninFig.1,the
focalsurfaceisthenprocessedbytheIn-focusRestorationmodule,whichweextractthefocused
anddefocusedregionsfromthe3DreconstructionsandcombinethemintoasingletargetimageR
withthecorrespondingmaskM.Forthedataset,weuse300RGBimagesasthetrainingsetand
another100imagesforthetestset.ForeachRGBimage,wegeneratefivearbitraryfocalsurfaces,
resultingin1500trainingcasesand500testingcases.
2 DISPLAYPROTOTYPE
Webuildanon-axisholographicdisplayprototype
usingaphase-onlySpatialLightModulator(SLM)
with Fisba ReadyBeam Lasers (420, 520, and 638
nm). The SLM is aJasper Display SLM Research
kit (2400 by 4094 pixels and 3.74µm pixel pitch).
WebroughtopticalcomponentsfromThorlabsto
augmentourholographicdisplayprototype.
Fig.2. Animageofourholographicdisplayprototype
∗denotescorrespondingauthor
1Zheng,C.etal.
3 VISUALRESULTS
0mm 10mm
Ours6 ASM6 Ours6 ASM6
Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus
Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus
Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus
Fig.3. VisualcomparisononsimulationsbetweenASM6andOurs6atsixdepthplanesunder0mmand10
mmpropagationdistances.(Sourceimage:MartinKníže,Link:WikimediaCommons)
Ours6 ASM6
Fig.4. ComparingexperimentalcapturesofASM6andOurs6under0mmpropagationdistance.(Source
image:MartinKníže,Link:WikimediaCommons)
2
      
sucoFtnorF-snoitalumiS
sucoFdiM-snoitalumiS
sucoFraeR-snoitalumiS
                                                                                    