Already Moderate Population Sizes Provably Yield
Strong Robustness to Noise
Denis Antipov
Optimisation and Logistics,
School of Computer and Mathematical Sciences,
The University of Adelaide
Adelaide, Australia
Benjamin Doerr Alexandra Ivanova
Laboratoire d’Informatique (LIX), HSE University, Skoltech
CNRS, E´ cole Polytechnique, Moscow, Russia,
Institut Polytechnique de Paris
Palaiseau, France
April 3, 2024
Abstract
Experienceshowsthattypicalevolutionaryalgorithmscancopewellwithstochas-
ticdisturbancessuchasnoisyfunctionevaluations. Inthisfirstmathematicalruntime
analysis of the (1+λ) and (1,λ) evolutionary algorithms in the presence of prior bit-
wise noise, we show that both algorithms can tolerate constant noise probabilities
without increasing the asymptotic runtime on the OneMax benchmark. For this, a
population size λ suffices that is at least logarithmic in the problem size n. The
only previous result in this direction regarded the less realistic one-bit noise model,
required a population size super-linear in the problem size, and proved a runtime
guarantee roughly cubic in the noiseless runtime for the OneMax benchmark. Our
significantly stronger resultsarebased on thenovel proofargumentthatthenoiseless
offspring can be seen as a biased uniform crossover between the parent and the noisy
offspring. We are optimistic that the technical lemmas resulting from this insight
will find applications also in future mathematical runtime analyses of evolutionary
algorithms.
1
4202
rpA
2
]EN.sc[
1v09020.4042:viXra1 Introduction
Themathematicalruntimeanalysishasaccompaniedandsupportedthedesignandanalysis
of evolutionary algorithms (EAs) for more than 30 years. It has led to a deeper under-
standing of many important aspects of evolutionary computation [NW10, AD11, Jan13,
ZYQ19, DN20].
While this area has also studied how EAs cope with noise, that is, a stochastically
disturbed access to the true problem instance, the rigorous understanding of this aspect of
evolutionary computation is rather limited. Most previous works regard simple algorithms
like the (1+1) EA and show that these, without particular adjustments, can stand a
moderate level of noise, but usually not more than one noisy fitness evaluation every
roughly n/log(n) iterations for problems with bit-string representation of length n.
Some works have shown that larger population sizes improve the robustness to noise,
but these still do not show a very satisfying picture. For example, in the work closest
to ours, Gießen and Ko¨tzing [GK16] showed that the (1+λ) EA can stand random one-
bit prior noise with arbitrary rate q [0,1] when optimizing the OneMax benchmark.
∈
However, their result requires a relatively large population size of at least λ = Ω(1nlogn)
q
and then gives a runtime guarantee of O(1n2λ) fitness evaluations, significantly above the
q
guarantee O(max nλloglogλ,nlogn ) for the noiseless setting [DK15]. We also note that
{ logλ }
both the required population size and the runtime guarantee contain a factor of 1, that is,
q
they become worse for lower noise rates. This counter-intuitive dependence on the noise
intensity together with the weak runtime guarantee of order at least n3logn suggest that
this problem is not yet fully understood, and this is why we undertake a new attempt to
analyze how the (1+λ) EA solves the OneMax problem in the presence of noise.
As a main result, we prove that the (1+λ) EA with any population size λ Cln(n),
≥
C a suitable constant, can optimize the OneMax problem in the presence of bit-wise prior
noise with up to constant noise probability per iteration, in asymptotically the same time
aswhen no noise ispresent. We notethat we regarda different noise model thanin [GK16],
namely independent bit-wise prior noise. This model is generally regarded as more realistic
because thetrue andthe noisy fitness candeviate by arbitraryamounts. There isno reason
to believe that the (1+λ) EA should suffer less from noise in this noise model. In fact,
we are convinced that results analogous to ours hold in the one-bit noise model regarded
in [GK16], and that such results can be proven with a variant of our general proof method.
We do not conduct these proofs since, as often in runtime analyses, the precise proofs rely
on the details of the particular algorithm, objective function, and noise model. For that
reason, even though our general approach seems to apply also to one-bit noise, the proofs
would differ in many small details. We therefore leave this task for future work.
This result is the first tight analysis of a standard population-based EA in the presence
ofnoiseinastandardmodel (infact, itisthefirst analysisofthe(1+λ) EAinthepresence
of bit-wise noise). Our result shows that already moderate population sizes can yield an
enormous robustness. We note that for λ = Θ(logn), our runtime guarantee is O(nlogn),
that is, the same as for the simple (1+1) EA in the noiseless setting. Hence the larger
2population size used here to obtain robustness does not lead to an increase in the runtime.
We also recall the general lower bound of Ω(nlogn) valid for all unary unbiased black-box
algorithm [LW12], which shows that our O(nlogn) bound is asymptotically tight and that
a better performance is not possible in the realm of mutation-based unbiased evolutionary
algorithms.
We extend our analysis to the non-elitist (1,λ) EA and show the same results for this
algorithm. In the noisefree setting, the (1+λ) EA and the (1,λ) EA are known to have a
similar performance when the population size is at least logarithmic, basically because the
(1,λ) EA becomes near-elitist since with high probability at least one offspring is equal
to the parent. That this similarity of the two algorithms extends to noisy settings was, a
priori, not obvious. We note that this is the first runtime analysis of the (1,λ) EA in the
presence of prior noise.
Our results are based on a novel proof argument, namely that the noiseless offspring
can beseen asa biased crossover between the parent andthe noisy offspring. This allows to
obtain probabilistic information on the offspring given the parent and the noisy offspring.
Note that the noisy offspring is visible to the algorithm (and thus in a sense also to our
proofs) via its fitness, whereas the non-noisy offspring is not visible, but is of course what
really counts for the further run of the algorithm. We refer to Sections 4 and 5 for more
details.
Overall, our work gives two main insights, namely (1) that using EAs with at least a
moderate population size can lead to a strong robustness against noise, and this without
performance losses even when compared with using the optimal population size in the
noiseless setting, and (2) that such processes can be analyzed with mathematical means,
in particular, with the tools we developed to gain from the noisy offspring probabilistic
information on the noiseless offspring.
We complement our theoretical analysis with a small experimental study, aiming at
answering two questionswhich ourasymptoticruntimeanalysisnaturallycouldnotanswer.
We observe that, as predicted by theoretical considerations in the noisefree case, also in the
noisy setting there is no significant performance difference between the (1+λ) EA and the
(1,λ) EA. Also, we show that the asymptotic runtime advantage of the (1+λ) EA over
the (1+1) EA at constant noise rates is clearly visible already for moderate population
sizes.
This work is organized as follows. In Section 2, we review the most relevant previous
works. We describe the benchmark, noise model, and algorithms in Section 3. Our main
technical tool, the analysis of the relation between parent, true offspring, and noisy off-
spring, is developed in Section 4. We use this tool in Section 5 to conduct the runtime
analyses leading to the main results of this work. Our experimental study can be found in
Section 6. The paper ends with a short conclusion and outlook.
32 Related Works
One of the most recent and detailed overviews of mathematical analyses of evolutionary
algorithms in noisy environments can be found in the recent paper [LQ24]. We refer the
reader to this work and discuss now only the results most relevant to ours.
For the (1+1) EA, several results show that it can tolerate a small amount of noise,
but becomes highly inefficient for larger noise rates. In [GK16], it was shown that on
OneMax with either prior bit-wise noise flipping each bit with probability q or one-
n
bit noise flipping exactly one random bit with probability q, the (1+1) EA keeps its
O(nlog(n)) runtime from the noiseless setting when q = O(1). For q = O(log(n)), the run-
n n
time is still polynomial, but for q =
ω(log(n))
the runtime is super-polynomial. That is, the
n
(1+1) EA can cope with noise only if it happens at most, on average, every Θ( n ) iter-
log(n)
ations. A similar effect was observed on LeadingOnes and made very precise in [Sud21],
where for the same noise models for all q 1 a runtime of order n2exp(Θ(min qn2,n ))
≤ 2 { }
was shown. Hence here already from q = 1/n2 on the performance drops rapidly with
increasing noise rate.
Posterior additive Gaussian noise was studied in [GK16, QYT+18]. In [GK16] the au-
thors showed that the (1+1) EA can solve OneMax and LeadingOnes in its noiseless
time when the variance σ2 of the Gaussian distribution is at most 1 and 1 , respec-
4log(n) 12en2
tively. In [QYT+18] it was shown that for large variance, namely 1 and n2, respectively,
the runtime on these problems is exponential.
A more general approach based on estimating the probability that the noise inverts
the comparison of two individuals was used in [DNDD+18]. This led to a polynomial
runtime guarantee on OneMax for every noise model for which the probability to invert a
comparison via noise is at most
cln(n)
for some constant c. Also, this approach allowed to
n
maketheresults of[GK16]moreprecise, amongothers, giving thattheO(nlog(n)) runtime
bound remains valid up to q = c′log(log(n))/n with c′ a constant specified in [DNDD+18].
It is also worth mentioning the papers [QYT+18, QBJT19, QBY+21], which showed
that resampling an individual sufficiently often can help to determine its true fitness. This
can make the (1+1) EA robust to noise, but often requires large (more than n3) numbers
of samples. This strategy, however, does not work on LeadingOnes with high-rate prior
noise. Additionally, in [DS19] it was shown that using a median instead of the mean of the
samples can significantly reduce the number of resamplings necessary to yield a reasonable
performance, e.g., to Θ(log(n)) if the noise is not too strong.
For population-based EAs there are considerably fewer results. In [GK16] it was
shown that for the (1+λ) EA and the (µ+1) EA, the population sizes µ =
Ω(log(n))
and
q
λ = Ω(1nlog(n)) can lead to polynomial runtimes on OneMax with one-bit noise occur-
q
ring with probability q. The runtimes in this case are O(µnlog(n)) for the (µ+1) EA,
mildly above its O(µn) noisefree runtime guarantee [Wit06], and O(1n2λ) for the
q
(1+λ) EA, significantly above its noisefree runtime guarantee of O(nλlogloglogλ) [DK15].
loglogλ
This result definitely suggests that the larger populations, in particular, larger parent pop-
4ulations, can be beneficial to cope with noise. However, these results counter-intuitively
require larger population sizes to cope with smaller noise rates.
Another result for population-based EAs was obtained in [QBY+21], where the authors
considered a symmetric noise model. The authorsshowed that with logarithmicpopulation
sizes both the (1+λ) EA and the (µ+1) EA have an O˜(n) runtime on OneMax, and
also that smaller population sizes for the (1+λ) EA lead to exponential runtimes. The
downside of this result is that the symmetric noise model is quite artificial. In particular,
for the (µ+1) EA it implies that if we have a single individual with best fitness, it is
removed from the population only if the noise affects all individuals in the population
(which is very unlikely when µ is at least logarithmic). For the (1+λ) EA it implies that
we lose fitness only when all Θ(λ) copies of the current individual are affected by the noise,
which isalso unlikely forlogarithmicor largervalues ofλ. Withthese particular properties,
these results appear hard to extend to the more common noise models.
In [DNDD+18] the authors write that the (1+λ) EA can optimize OneMax under a
one-bit noise in O(nlog(n)) runtime, if λ = Θ(log(np)), where p is the probability that
the noise flips a bit. However, this result is only described informally, there is no theorem
stating it, nor a proof or a proof sketch.
The study of non-elitist algorithms in the presence of noise is confined to the three
works [DL15, LQ24, LQ23]. In [DL15], it is shown that a non-elitist EA constructing the
next population by λ times independently selecting two parents and taking the mutant of
the better one into the next population, is very robust to prior noise with up to constant
noise rates, keeping its noisefree runtime apart from a loglogn factor. Besides many other
results, this result was sharpened and extended to more general noise models in [LQ24],
however, to the best of our understanding only for mutation rate below 1/n. That paper,
as well as the subsequent work [LQ23], also give results for the symmetric noise model,
but as discussed above, we are not optimistic that such results can be extended to more
realistic noise models.
Other slightly less relevant results include studies of ant colony optimizers
(ACO) [FKKS16], estimation of distribution algorithms such as the cGA [FKKS17] and
the UMDA [LN21], and voting algorithms [RA19] in the presence of noise. For an ACO
with a fitness-proportional update it was shown in [FKKS16] that with a small evaporation
factor ρ = O( 1 ) this algorithm can solve OneMax in O(n2log(n)/ρ) time for both
n3log(n)
Gaussian or 1-bit noise with any noise rate (note that this runtime is of order larger than
n5). For the cGA on OneMax with Gaussian noise with variance σ2 it was shown that
with population size K = ω(σ√nlog(n)) the optimum is found in O(Kσ2√nlog(Kn))
time [FKKS17]. With an automated choice of the algorithm parameter K, the runtime
stemming from the optimal choice of K can be obtained [ZD23], and this without knowing
in advance the noise variance σ2. In [LN21], the UMDA was studied on LeadingOnes
with a one-bit noise with rate less than one. It was shown that with parameters µ and λ
which are at least logarithmic in n, the runtime is O(nλlog(λ)+n2). The voting algorithm
was studied on OneMax with Gaussian noise, and it was shown that if the noise rate σ2
is at least 3n, then the optimum is correctly found after O(σ2log(n)) samples.
8
5Frozen noise models, where noise is applied to the objective function once before the
algorithm is run, were studied in [FKNR22, JLS23]. The main result is that RLS, the
(1 + 1) EA, and the (1 + λ) EA are not efficient on those rugged landscapes, but the
compact genetic algorithm and the (1,λ) EA are.
Noisy optimization has also been studied for multi-objective EAs [DDHW23, DOSS23],
but the very different population dynamics render it difficult to compare these results with
the single-objective setting.
3 Preliminaries
3.1 OneMax with Bit-wise Noise
OneMax is one of the most common benchmark functions used in theoretical studies of
EAs. It returns the number of one-bits in its argument, which is formally defined by
n
OneMax(x) = x
i
i=1
X
for all x 0,1 n. Despite its simplicity, this benchmark has had an enormous impact on
∈ { }
the field. It was the basis of the first mathematical runtime analyses at all [Mu¨h92, Rud97,
DJW02], the first analyses of EAs in the presence of noise and dynamic changes [Dro02,
Dro04], the first analyses of population-based algorithms [JJW05, Wit06, AD21], or the
first analyses of estimation-of-distribution algorithms and ant-colony optimizers [Dro05,
Gut08, NW09]. These works triggered the development of many analysis methods that
are used regularly since then. The study of how EAs optimize OneMax also led to the
discovery of many new algorithmic ideas, e.g., various ways to dynamically adjust the
parameters of an EA [LS11, DDE15, DWY21].
In this paper we study the optimization of OneMax under bit-wise prior noise. In
this noise model, we do not learn the correct fitness of x, but the fitness of some bit string
obtained from x by flipping each bit independently with probability q. We call q the noise
n n
rate. In this paper we consider q = O(1), so that the noise rate is at most O(1), which
n
means that we might have a constant probability that the noise occurs and we learn a
possibly wrong fitness value.
3.2 The (1 + λ) EA and the (1,λ) EA
The two most simple EAs with a non-trivial offspring population are the (1+λ) EA and
(1,λ) EA. Both algorithms work according to the following scheme. They keep a bit-string
x, which is called the current individual and which is initialized with a random bit string.
Then in each iteration they create λ individuals, independently, by applying standard bit
mutation with rate χ to the current individual x (that is, each bit in a copy of x is flipped
n
with probability χ independently from other bits). A best of these offspring is selected as
n
the mutation winner y. Then the only difference in two algorithm occurs. The (1+λ) EA
6Algorithm 1: The (1,λ) EA and the (1+λ) EA maximizing a function f :
0,1 n R.
{ } →
1 Initialization: Sample x 0,1 n uniformly at random and evaluate f(x);
∈ { }
2 Optimization: for t = 1,2,3,... do
3 for i = 1,...,λ do
4 y(i) copy of x;
←
5 Flip each bit in y(i) with probability χ;
n
6 evaluate f(y(i));
7 end
8 y argmax f(y(i)) i [λ] ;
← { | ∈ }
9 if running (1,λ) EA then x y;
←
10 if running (1+λ) EA and f(y) f(x) then x y;
≥ ←
11 end
compares y with x and if y is not worse, then it replaces x in the next iteration. Otherwise
x stays the same. In the (1,λ) EA we use a non-elitist selection, and y always replaces
x, even if it is worse. In this paper we use the standard assumption that χ = Θ(1), since
smaller mutation rates usually reduce the optimization speed and larger rates can lead to
an exponential runtime even on monotone functions [DJS+13]. The pseudocodes of the
(1,λ) EA and the (1+λ) EA are shown in Algorithm 1, where the only difference between
them is in lines 9 and 10.
In the context of noisy optimization, it is important to note that for the (1+λ) EA
we re-compute the fitness of the current individual in each iteration and do not reuse the
value computed previously. This allows to correct the situation that we have a current
individual for which we believe its fitness to be significantly higher (due to a noisy fitness
evaluation in the past). In such a situation the EA may get stuck for a long time, simply
because all offspring appear to be worse than this parent. That this problem is real and
can be seen, e.g., by comparing the results of [ST12] (without reevaluations) and [DHK12]
(with reevaluations).
To take into account the specifics of noisy optimization, we use the following point of
view and notation when we consider an iteration of the (1+λ) EA or the (1,λ) EA. We
denote the λ offspring of x created via standard bit mutation by x(i) (for i [1..λ]). Then
∈
when we apply noise to each of λ individuals independently, we obtain λ noisy individuals
x˜(i), where for each i [1..λ] individual x˜(i) is obtained from x(i). When we talk about an
∈
arbitraryoffspringanditsnoisyversion, wedenotethembyx′ andx˜′ correspondingly. After
creating noisy offspring we evaluate their OneMax values and we choose an individual y˜
from the λ noisy ones with the best fitness value (the ties are broken uniformly at random)
as the mutation winner and we denote its non-noisy parent by y. Then for the (1+λ) EA
we also apply noise to x before we compare it with y˜, and thus we get a noisy individual
x˜ which competes with y˜.
73.3 Drift Analysis
Drift analysis is a rapidly developing set of tools which are widely used in the analysis of
random search heuristics. They help to transform easy-to-obtain information about the
expected progress into bounds on the expected runtime. In this paper we use the following
variable drift theorem, which was first introduced in [MRC09, Joh10]. We use its simplified
version for processes over integer values from [DDY20].
Theorem 1 (Theorem 6 in [DDY20]). Let (X t) t∈N be a sequence of random variables in
[0..n] and let T be the random variable that denotes the earliest point in time t 0 such
≥
that X = 0. Suppose that there exists a monotonically increasing function h : [1..n] R+
t 7→ 0
such that
E[X X X ] h(X )
t t+1 t t
− | ≥
holds for all t < T (as an inequality of random variables). Then
X0
1
E[T X ] .
0
| ≤ h(i)
i=1
X
3.4 Auxiliary Tools
The following lemmas introduce several tools which will be useful in our proofs.
Lemma 2 (Lemma 1.4.9 in [Doe20]). For all n N and k [1..n], we have
∈ ∈
n n k
.
k ≥ k
(cid:18) (cid:19)
(cid:16) (cid:17)
Lemma 3 (Inequality 3.6.2 in [VM12]). If n and x are real numbers such that 0 x n
≤ ≤
and n > 0, then
x n x2
1 e−x .
− n ≥ − 2n
(cid:16) (cid:17)
Lemma 4 (Lemma 1 in [ADK22]). For all x [0,1] and λ > 0 we have
∈
1
1 (1 x)λ min 1,λx .
− − ≥ 2 { }
4 Offspring Distribution
In this section we discuss the relationship between the parent individual x, its offspring x′
obtained via standard bit mutation, and the individual x˜′ obtained from the offspring via
bit-wise noise.
We start with the distribution of x˜′, when we have no information about the true
offspring x′. Each bit of the noisy offspring x˜′ is different from the bit in the same position
8Table 1: Distribution of a bit value in the offspring x′ given the observed value in the noisy
offspring x˜′.
Event A Event B Pr[A B] Approximate Value
|
x′ = x x˜′ = x
(1− nχ)(1− nq)
1 qχ O 1
i i i i (1−χ n)(1− nq)+ nqχ 2 − n2 − n3
x′ = x x˜′ = x (1−χ n) nq q (1 o((cid:0) 1))(cid:1)
i i i 6 i (1−χ)q+χ(1−q) q+χ ±
n n n n
χq
x′ = x x˜′ = x n2 qχ +O 1
i 6 i i i (1−χ n)(1− nq)+ nqχ 2 n2 n3
x′ = x x˜′ = x (1− nq) nχ χ (1 (cid:0) o(1(cid:1) ))
i 6 i i 6 i (1−χ)q+χ(1−q) q+χ ±
n n n n
in x, if and only if either it was flipped by the mutation, but not by the noise, or it was
flipped by the noise, but not by the mutation. The probability of this event is
χ q q χ χ q χq 1 2qχ
1 + 1 = + 2 = χ+q .
n − n n − n n n − · n2 n − n
(cid:18) (cid:19)
(cid:16) (cid:17) (cid:16) (cid:17)
Since this event is independent for all bits, x˜′ is distributed in the same way as if it was
created from x via standard bit mutation with rate r, where r = χ+q 2qχ. Since in this
n − n
paper we assume χ = Θ(1) and q = O(1), we have r = Θ(1) as well.
When we know the parent x and also the noisy offspring x˜′, we can estimate the
distribution of the noiseless offspring x′, which is an intermediate step when we get x˜′ from
x. The following lemma shows how the bit values in x′ are distributed when we know those
bit values in x and x˜′. Since, naturally, these estimates depend not on the particular bit
value in x, but only on whether the corresponding bits agree or differ with this value, we
also formulate our result in this symmetric fashion.
Lemma 5. Consider an arbitrary bit position i. The distribution of this bit value x′ in x′,
i
conditional on the values of this bit in x and x˜′, are as shown in Table 1.
Proof. We start with the first row of Table 1, that is, we compute Pr[x′ = x x˜′ = x ].
i i | i i
By the definition of conditional probabilities we have
Pr[x′ = x = x˜′]
Pr[x′ = x x˜′ = x ] = i i i .
i i | i i Pr[x = x˜′]
i i
The bit in position i has the same values in all three individuals only if it has not been
flipped, neither by mutation, nor by noise. The probability of this event is (1 χ)(1 q).
− n − n
This bit is equal in the parent x and in the noisy offspring x˜′ when we either have not
flipped it at all, or we flipped it twice. The probability of this event is (1 χ)(1 q)+ qχ.
− n − n n2
Thus, we have
91 χ 1 q
Pr[x′ = x x˜′ = x ] = − n − n
i i | i i 1 χ 1 q + qχ
(cid:0) − n (cid:1)(cid:0) − n (cid:1)n2
qχ
qχ 1
= 1
n2 (cid:0) (cid:1)(cid:0)
= 1
(cid:1)
− 1 χ 1 q + qχ − n2 · 1 O 1
− n − n n2 − n
qχ 1
= 1 (cid:0) O(cid:1)(cid:0) .(cid:1) (cid:0) (cid:0) (cid:1)(cid:1)
− n2 − n3
(cid:18) (cid:19)
To prove the second row of Table 1, we use similar arguments to show that the event
x = x′ = x˜′ happens only if we flip this bit by noise, but do not flip it by mutation. The
i i 6 i
probability of this is (1 χ)q. We have x = x˜′,when we flip the i-th bit only once, the
− n n i 6 i
probability of which is (1 χ)q +(1 q)χ. Hence, we have
− n n − n n
Pr[x′ = x = x˜′] 1 χ q
Pr[x′ = x x˜′ = x ] = i i 6 i = − n n
i i | i 6 i Pr[x = x˜′] 1 χ q + χ 1 q
i 6 i − n(cid:0) n n(cid:1) − n
q q q +χ q
= = (cid:0)= (cid:1) (1 (cid:0)o(1)), (cid:1)
1−q q +χ · q +χ o(1) q+χ ±
q +χ n
1−χ ±
n
(cid:16) (cid:17)
since χ = Θ(1) and q = O(1).
By regarding complementary events, we obtain the remaining two rows of Table 1:
Pr[x′ = x x˜′ = x ] = 1 Pr[x′ = x x˜′ = x ]
i 6 i | i i − i i | i i
χq
qχ 1 qχ 1
=
n2
= 1+O = +O ,
1 χ 1 q + qχ n2 n n2 n3
− n − n n2 (cid:18) (cid:18) (cid:19)(cid:19) (cid:18) (cid:19)
Pr[x′ = x x˜′ = x ] = 1 Pr[x′ = x x˜′ = x ]
i 6 (cid:0) i | (cid:1)i(cid:0) 6 i (cid:1) − i i | i 6 i
χ
= (1 o(1)).
q +χ ±
Lemma 5 can be interpreted in the way that given x and x˜′, the true offspring x′
is, asymptotically, a biased crossover between x and x˜′, taking bit values from x with
probability q and from x˜′ otherwise. Indeed, if x and x˜′ agree in a bit value, then with
q+χ
high probability x′ also has this value in this bit (the first and the third lines of Table 1).
Where x and x˜′ differ, the offspring x′ takes the value from x with probability q o(1),
q+χ ±
see the second line of Table 1, and otherwise from x˜′.
By linearity of expectation, this observation can be lifted to distances, which is what
we do in the following lemma. It implies, in particular, that if we observe some progress
towards some target solution with respect to the noisy offspring, then a constant fraction
of this progress is real, that is, witnessed by the true offspring. This insight will be the
central tool in our later analyses. We are optimistic that it will be useful in other runtime
analyses of EAs in the presence of noise as well.
10A B C D
x : 11...1 11...1 00...0 00...0
z : 11...1 00...0 11...1 00...0
Figure 1: Illustration of the four groups of bits in the proof of Lemma 6.
Lemma 6. Consider some arbitrary, but fixed parent x. Let d( ) denote the Hamming
·
distance to some arbitrary point x∗ in the search space. Then for any bit string z we have
E[d(x) d(x′) x˜′ = z]
− |
χ qχ 1
(d(x) d(z)) (1 o(1)) O .
≥ − · q +χ · ± − n − n2
(cid:18) (cid:19)
Proof. W.l.o.g. we assume that x∗ is the all-ones bit string1, thus d( ) stands for the
·
number of zero-bits in its argument. Consider some arbitrary z. We divide the bits into
four groups depending on their values in x and z as illustrated in Figure 1. Let A be the
number of bits which are both ones in x and z, let B be the number of bits which are
ones in x and zeros in z, let C be the number of bits which are zeros in x and ones in
z, and let D be the number of bits with are both zeros in x and z. Note that in each of
these four groups the number of zero-bits in x′ follows a binomial distribution, with success
probability as given in Table 1. We denote the precise probabilities from rows 3 and 4 of
Table 1 by p and p respectively (the ones in column Pr[A B]). Then the probabilities
3 4
|
from rows 1 and 2 are (1 p ) an (1 p ) respectively. Hence, for any arbitrary z we have
3 4
− −
E[d(x′) x˜′ = z] = p A+p B +(1 p )C +(1 p )D
3 4 4 3
| − −
= D +C +p (A D)+p (B C)
3 4
− −
qχ 1 χ
= (D +C)+(A D) +O +(B C) (1 o(1))
− n2 n3 − q +χ ±
(cid:18) (cid:18) (cid:19)(cid:19)
qχ 1 χ
d(x)+n +O +(d(z) d(x)) (1 o(1))
≤ n2 n3 − q +χ ±
(cid:18) (cid:18) (cid:19)(cid:19)
qχ 1 χ
= d(x)+ +O +(d(z) d(x)) (1 o(1)),
n n2 − q +χ ±
(cid:18) (cid:19)
since C + D = d(x), A D n, and B C = d(z) d(x). By moving d(x) to the left
− ≤ − −
hand side and multiplying both sides by 1, we finish the proof.
−
1
To generalize this proof for an arbitrary bit string
x∗
, it is sufficient to replace “one-bits” with “bits
whichhavethe samevalue
inx∗
”and“zero-bits”with “bitswhichhaveadifferentvalue
inx∗
”. We avoid
doing so to improve the readability of the proof.
115 Runtime Analysis
We use the results from Section 4 to estimate upper bounds on the runtime of the
(1+λ) EA and the (1,λ) EA. The main result of this section is the following theorem.
Theorem 7. Consider a run of the (1,λ) EA or the (1+λ) EA with mutation rate χ
n
where χ = Θ(1) on the OneMax problem with bit-wise noise with rate q where q = O(1).
n
If the population size λ is at least Cln(n) for some constant C depending on χ and q, then
the expected number E[T ] of fitness evaluations until the optimum is sampled is
F
loglog(λ)
O nlog(n)+nλ .
log(λ)
(cid:18) (cid:19)
To prove Theorem 7, we use the variable drift theorem (Theorem 1). The process
we apply it to is {d t }t∈N 0, which is the distance of the current individual (of either the
(1,λ) EA or the (1+λ) EA) to the optimum after iteration t. Since we consider the
OneMax function, d is equal to the number of zero-bits in that individual.
t
To bound the drift of d , we study what happens in one iteration of the two considered
t
algorithms. We use the notation defined in Section 3.2, and additionally we denote the
individuals accepted as the parent for the next iteration by x for the (1,λ) EA and
com
by x for the (1+λ) EA. Note that x is always equal to y (the winning offspring),
plus com
while x can be either y or x, depending on their noisy comparison. We also denote the
plus
˜
distances to the optimum from different individuals as follows. By d and d we denote the
distance to the optimum from the parent x and the noisy parent x˜, respectively. By d
y
˜
and d we denote the distance to the optimum from the mutation winner y and its noisy
y
version y˜, respectively. By d and d we denote distances from next generation parents
com plus
x and x to the optimum, respectively.
com plus
With this notation the drift in one iteration is defined as
∆com(d) := E[d d ] for the (1,λ) EA, and
com
−
∆plus(d) := E[d d ] for the (1+λ) EA.
plus
−
We estimate these drifts in the following lemma.
Lemma 8. Let
d
∆+(d) := Pr[d˜ d i], and
y
≤ −
i=1
X
n−d
∆−(d) := Pr[d˜ d+j].
y
≥
j=1
X
Then the drift of the current individual x towards the optimum in one iteration is at least
χ qχ 1
∆com(d) (1 o(1)) ∆+(d) ∆−(d) O (1)
≥ − q +χ − − n − n2
(cid:18) (cid:19)
(cid:0) (cid:1)
12for the (1,λ) EA, and it is at least
χ
∆plus(d) (1 o(1)) (1 o(1))e−q∆+(d) ∆−(d)
≥ − q+χ − −
(2)
qχ 1 (cid:0) (cid:1)
O
− n − n2
(cid:18) (cid:19)
for the (1+λ) EA.
Before we prove this lemma we note that ∆+(d) and ∆−(d) are the positive and the
˜
negative components of the drift of y˜ from x respectively, since we have E[d d ] =
y
−
∆+(d) ∆−(d).
−
Proof. In this proof we consider a fixed parent individual x, and therefore d is also fixed
(that is, it is not a random variable). For the (1,λ) EA we have x = y, hence we have
com
∆com(d) = E[d d ] = E[d d ]
com y
− −
= Pr[y˜= Y]E[d d y˜= Y].
y
− |
Y∈{0,1}n
X
For any bit string z 0,1 n we denote the distance to the optimum by d . Then by
z
∈ { }
Lemma 6 we have
∆com(d)
χ qχ 1
Pr[y˜= z] (d d ) (1 o(1)) O
z
≥ − q +χ ± − n − n2
z∈{0,1}n (cid:18) (cid:18) (cid:19)(cid:19)
X
χ qχ 1
= (1 o(1)) Pr[y˜= z](d d ) O
z
 − q+χ − − n − n2
z∈{0,1}n (cid:18) (cid:19)
X
 χ qχ 1 
˜
= (1 o(1)) E[d d ] O .
y
− q+χ − − n − n2
(cid:18) (cid:19)
Noting that E[d d˜ ] = ∆+(d) ∆−(d) by the definition of ∆+(d) and ∆−(d) completes
y
− −
the proof of eq. (1).
Estimating drift for the (1+λ) EA requires more effort, since we are not guaranteed
that x = y. This happens if and only if y˜ appears no worse than x˜ (the individual we
plus
obtain from x via noise). Consequently, we have
d d = (d d )I d˜ d˜ , (3)
plus y y
− − ≥
h i
where all random variables are over the joint probability space of noise on x, noise on
I
offspring and the mutation, [ ] is an indicator random variable, and eq. (3) is an identity
·
13of random variables functions. Therefore, by the law of total probability, the drift for the
(1+λ) EA is
∆plus(d) = E[d d ] = E (d d )I d˜ d˜
plus y y
− − ≥
h h ii
˜ ˜
= Pr[y˜= z] Pr d d y˜= z
y
· ≥ |
z∈ X{0,1}n (cid:18) h i
˜ ˜ ˜ ˜
E d d y˜= z,d d +Pr d < d y˜= z 0 .
y y y
· − | ≥ | ·
(cid:19)
h i h i
˜ ˜
Note that when we fix x and y˜, then event d d depends only on the noise which
y
≥
affects x˜. This noise does not affect any offspring of x, hence the random variable d d
y
˜ ˜ −
conditioned on y˜= z is independent of d d , which together with Lemma 6 implies that
y
≥
˜ ˜
E d d y˜= z,d d = E[d d y˜= z]
y y y
− | ≥ − |
h iχ qχ 1
(1 o(1)) (d d ) O .
z
≥ ± q+χ − − n − n2
(cid:18) (cid:19)
Hence, we have
χ
∆plus(d) (1 o(1))
≥ − q+χ
˜ ˜
Pr[y˜= z]Pr[d d y˜= z](d d )
y z
· ≥ | − (4)
z∈{0,1}n
X
qχ 1
O .
− n − n2
(cid:18) (cid:19)
˜ ˜
When d > d, we estimate the conditional probability Pr[d d y˜ = z] by one.
z y
≥ |
Otherwise, if d < d, this probability is at least the probability that x˜ = x, that is, that
z
the noise has not flipped any bit in x when we compared it with y˜. This probability is
(1 q)n = (1 o(1))e−q. With this observation, similar to the (1,λ) EA, we can rewrite
− n −
the sum above as follows
˜ ˜
Pr[y˜= z]Pr[d d y˜= z](d d )
y z
≥ | −
z∈{0,1}n
X
d n−d
(1
o(1))e−qiPr[d˜
= d i]
jPr[d˜
= d+j]
y y
≥ − − −
i=1 j=1
X X
= (1 o(1))e−q∆+(d) ∆−(d).
− −
Putting this into eq. (4) completes the proof of eq. (2).
Above we obtained a weaker drift estimate for the (1+λ) EA than the (1,λ) EA. This
is counter-intuitive – one would feel that the (1+λ) EA should profit to some extent
14from the property that the current-best solution is participating in the selection of the
next parent. The reason for our weaker bound in the estimate following eq. 4, where
we pessimistically estimated that inferior mutation winners y are always accepted, but
superior ones only when the parent is not subject to noise. We feel that this cannot be
avoided in the general case (note that Lemma 8 is valid in general and is not specific for
the optimization of OneMax). We are sure that when exploiting properties of OneMax,
stronger bounds could be shown. We refrain from this both because we like our general,
problem-independent approach and because all we can gain are constant factors, which are
generally ignored in an asymptotic analysis as ours (note that we lose constant factors and
lower order terms in the later part of the analysis anyway).
In the following lemmas we show estimates for ∆+(d) and ∆−(d), which naturally
are specific to the OneMax problem. Lemmas 9-11 estimate the positive component of
the drift for different distances. We note that implicitly these results exist in the proofs
in [DK15], but distilling them from there is rather complicated.
Lemma 9 (Positive drift, large distance). If λ = ω(1) then for any distance d n we
≥ lnλ
have Pr[d d˜ lnλ ] 1 and the positive component of the drift is at least
− y ≥ ⌊2lnlnλ⌋ ≥ 4
1 lnλ
∆+(d) .
≥ 4 2lnlnλ
(cid:22) (cid:23)
Proof. Let x′ be some arbitrary offspring and let x˜′ be the same offspring after noise.
˜
Denote the distances from them to the optimum by d x′ and d x′ correspondingly. Let also
p i = Pr[d − d˜ x′ ≥ i] ≥ Pr[d − d˜ x′ = i] ≥ d i nr i 1 − nr n−i , since each noisy offspring is
distributed as if it was created via standard bit mutation with rate r where r = χ+q 2qχ.
(cid:0) (cid:1)(cid:0) (cid:1) (cid:0) (cid:1) n − n
Then we compute
d r ⌊ lnλ ⌋ r n−⌊ lnλ ⌋
2lnlnλ 2lnlnλ
p 1
⌊ 2ll nn lλ nλ⌋ ≥ lnλ n − n
(cid:18)⌊2lnlnλ⌋(cid:19)
(cid:16) (cid:17) (cid:16) (cid:17)
⌊
lnλ
⌋
d 2lnlnλ r ⌊ lnλ ⌋ r n
2lnlnλ
1
≥ lnλ n − n
!
⌊2lnlnλ⌋
(cid:16) (cid:17) (cid:16) (cid:17)
⌊
lnλ
⌋
dr 2lnlnλ r2
e−r ,
≥ lnλ n! − 2n
⌊2lnlnλ⌋ (cid:18) (cid:19)
where transition to the second line follows from Lemma 2 and the next transition follows
from Lemma 3. When n is large enough, the last term is close to e−r, thus we can bound
it from below with e−2r. Hence, recalling that we consider the case when d n , we have
≥ lnλ
lnλ dr lnλ
p exp ln ln 2r
⌊ 2ll nn lλ nλ⌋ ≥ 2lnlnλ n − 2lnlnλ −
(cid:18) (cid:18) (cid:19) (cid:19)
lnλ r
exp ln lnlnλ+ln(2lnlnλ)
≥ 2lnlnλ lnλ −
(cid:18) (cid:18)
152lnlnλ
2r
− · lnλ
(cid:19)(cid:19)
Since ln(2lnln(λ)) = ω(1) and lnr and 2r 2lnlnλ are both O(1), when n is large enough,
· lnλ
we have
lnλ 1
p exp ( 2lnlnλ) = e−lnλ = .
⌊ 2ll nn lλ nλ⌋ ≥ 2lnlnλ · − λ
(cid:18) (cid:19)
The probability that at least one of the λ individuals is by lnλ closer to the optimum
⌊2lnlnλ⌋
than x is therefore at least (1 1)λ 1. Hence, we have
− λ ≥ 4
lnλ 1 lnλ
∆+(d) p .
≥ ⌊ 2ll nn lλ nλ⌋ 2lnlnλ ≥ 4 2lnlnλ
(cid:22) (cid:23) (cid:22) (cid:23)
The next lemma covers the case when d [n, n ].
∈ λ lnλ
Lemma 10 (Positive drift, medium distance). For d [n, n ] we have Pr[d d˜
∈ λ lnλ − y ≥
1] r (1 o(1)) and the positive drift is at least ∆+(d) r (1 o(1)) = Θ(1), where
≥ λer − ≥ 2er −
r = q +χ 2qχ.
− n
˜
Proof. Similar to Lemma 9, let p 1 = Pr[d d x′ 1]. Then we have
− ≥
dr r n−1 dr 1 r
p 1 = o(1) (1 o(1))
1 ≥ n − n n er − ≥ λer −
(cid:18) (cid:19)
(cid:16) (cid:17)
by Lemma 3. The probability that the noisy mutation winner is better than the current
individual is the probability that at least one of the noisy offspring is better. Hence, we
have
∆+(d) 1 Pr d d˜ 1 1 (1 p )λ
y 1
≥ · − ≥ ≥ − −
1 h ir
min(1,λp ) (1 o(1))
≥ 2 1 ≥ 2er −
by Lemma 4 and since r 1 for all r. Since r = Θ(1), this lower bound is also Θ(1).
er ≤
Finally, we estimate the positive drift then d n.
≤ λ
Lemma 11 (Positive drift, small distance). For d n we have Pr[d d˜ 1] r (1
≤ λ − y ≥ ≥ λer −
o(1)) and the positive drift is at least ∆+(d) λdr (1 o(1)).
≥ 2ner −
˜
Proof. Similar to Lemma 9 and Lemma 10, let p 1 = Pr[d d x′ 1]. Then we have
− ≥
dr r n−1 dr
p 1 = (1 o(1)).
1 ≥ n − n ner −
(cid:16) (cid:17)
Therefore, similar to the proof of Lemma 10, by Lemma 4 we have
1 λdr
∆+(d) min(1,λp ) (1 o(1))
≥ 2 1 ≥ 2ner −
due to λd 1 and r 1.
n ≤ er ≤
16We proceed with bounding the negative component of the drift. A similar estimate
for this negative part of the drift of the (1,λ) EA on the noiseless OneMax was shown
in [RS14]. However, there this drift was bounded with a constant, which is not enough in
our situation, so we give a stronger bound.
Lemma 12 (Negative drift). If λ > Cln(n) for some sufficiently large constant C which
depends on r, then for all d [1..n] we have ∆−(d) 1.
∈ ≤ n
˜ ˜
Proof. If d is at least d, then for all λ offspring x˜ their d is at least d. Then we have
y
n−d n−d
λ
˜ ˜
Pr[d d j] = Pr[d d j] .
y
− ≥ − ≥
Xj=1 Xj=1(cid:16) (cid:17)
Let p := Pr[d d˜ j]. Since p is at most the probability that at least one 1-bit in x is
j 1
− ≥
flipped, we have p 1 1 r n−d 1 e−r+o(1) (the last inequality is by Lemma 3).
1 ≤ − − n ≤ −
Hence,
(cid:0) (cid:1)
1
pλ 1 e−r +o(1) λ
1 ≤ − ≤ n2
(cid:0) (cid:1)
for λ Clnn with C = 2 . For all j N we have p p , and therefore
≥
−ln(1−e−r+o(1))
∈
j
≤
1
pλ 1 . Consequently,
j ≤ n2
n−d n−d
λ n d 1
∆−(d) = Pr[d d˜ j] = pλ − .
− ≥ j ≤ n2 ≤ n
Xj=1(cid:16) (cid:17) Xj=1
With Lemma 8 and and with estimates given in Lemmas 9-12 we are now in position
to prove our main result, Theorem 7.
Proof of Theorem 7. Let h+(d) be the lower bound on∆+(d) derived in Lemmas 9-11, that
t
is,
1 lnλ if d > n ,
4 2lnlnλ lnn
∆+(d) h+(d) := r (1 o(1)) if d n, n , (5)
≥  2e(cid:4)r − (cid:5) ∈ λ lnλ
  λdr (1 o(1)) if d n.
2ner − ≤(cid:3)λ (cid:3)
Note that this is a monotonically inc reasing function in d. Let also h−(d) be the upper
bound on ∆−(d) from Lemma 12, that is,
1
∆−(d) h−(d) := ,
≤ n
for which we require λ to be at least Cln(n), where C is the constant from Lemma 12.
Using Lemma 8, we define lower bounds on the drift of two algorithms, that are,
17∆com(d) hcom(d)
≥
χ qχ 1
:= (1 o(1)) h+(d) h−(d) O ,
− q+χ − − n − n2
(cid:18) (cid:19)
∆plus(d) hplus(d) (cid:0) (cid:1)
≥
χ qχ
:= (1 o(1)) (1 o(1))e−qh+(d) h−(d)
− q+χ − − − n
1 (cid:0) (cid:1)
O .
− n2
(cid:18) (cid:19)
We now aim at showing that the first term (the one containing h+(d)) is dominant in
both hcom(d) and hplus(d) for all values of d. For this we note that by Lemmas 9-11, we
have h+(d) = ω(1). By Lemma 12 we have h−(d) = O(1) = o(h+(d)). By the constraints
n n
χ = Θ(1) and q = O(1) we also have χ = Θ(1) and qχ = O(1) = o(h+(d)), and
q+χ n n
e−q = Θ(1). Therefore, the expressions for the lower bounds on the drift are simplified as
follows.
χ
hcom(d) = (1 o(1)) h+(d)
− q+χ
χe−q
hplus(d) = (1 o(1)) h+(d).
− q+χ
Let Tcom and Tplus be the number of iterations until the (1,λ) EA and the (1+λ) EA
I I
(respectively) find the optimal solution and accept it as x for the first time, that is, the
minimum t when we have d = 0. Then by the variable drift theorem (Theorem 1) we have
t
n 1 (1+o(1))(q+χ)eq n 1
E[Tplus] = , and
I ≤ hplus(d) χ h+(d)
d=1 d=1
X X
n n
1 (1+o(1))(q +χ) 1
E[Tcom] = .
I ≤ hcom(d) χ h+(d)
d=1 d=1
X X
By eq. (5), we have
n 1 n 8 ⌊ lnn λ⌋ 2er ⌊n λ⌋ 2ner
+ +
h+(d) ≤ lnλ 2 r λdr
d=1 d=⌊ n ⌋+1 lnlnλ − d=⌊n⌋+1 d=1
X Xlnλ Xλ X
9lnlnλ n 2er 2ner n
n + + ln +1
≤ · lnλ lnλ · r λr λ
nloglogλ n (cid:16) n (cid:17)n
= O +O +O log
logλ logλ λ λ
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:16) (cid:17)
18n n λloglogλ
= O log + .
λ λ logλ
(cid:18) (cid:18) (cid:19)(cid:19)
Hence, we have
n n λloglogλ
E[Tplus],E[Tcom] = O log + .
I I λ λ logλ
(cid:18) (cid:18) (cid:19)(cid:19)
Since in each iteration of the (1,λ) EA we make λ fitness evaluations and in each
iteration of the (1+λ) EA we make λ+1 = Θ(λ) fitness evaluations, the expected number
of fitness evaluations until we find the optimum is at most
n λloglogλ
E[Tplus],E[Tcom] = O nlog +n .
F F λ logλ
(cid:18) (cid:19)
We also note that for all λ =
O(log(n)loglog(n))
the first term of the upper bound in
logloglog(n)
Theorem 7 is dominating, hence the expected runtime is O(nlog(n)), that is, the same as
in the noiseless case.
6 Experiments
In this section we describe the results of our empirical study, the goal of which is to give a
better understanding of the noisy optimization process and to answer some questions for
which our theoretical analysis was not detailed enough.
When we estimated the drift of the (1+λ) EA in Lemma 8, we pessimistically assumed
that the elitism of this algorithm can be only harmful. Namely, in our proofs, the com-
parison with the parent does not save us from decreasing the fitness (since the parent’s
fitness might be decreased by the noise) and it might prevent us from increasing fitness
(since the parent’s fitness might be increased by the noise). This pessimistic view eased
the proof without harming the asymptotic order of magnitude of the runtime, so it was
fully appropriate for the theoretical analysis. Still, it raises the question which of the two
algorithms is better when looking at the precise runtime rather than its asymptotics. To
understand this question, we ran the (1+λ) EA and the (1,λ) EA on OneMax with
problem sizes n = 26,27,...,214 , with 100 repetitions for each value of n. We used a
{ }
strong noise with q = 1 to maximize its effect, standard bit mutation with χ = 1, and we
chose λ = Cln(n) with C = 14, since for the chosen values of q and χ this C would
⌈ ⌉
satisfy the assumptions of Lemma 12. The mean runtimes of these runs and their standard
deviations are shown in the plot in Figure 2. For better visual comparison, we normalize
both runtimes by nln(n), which is our upper bound on their asymptotical runtime and
the well-known lower bound for all unary unbiased black-box algorithms [LW12]. In the
plot we see that for all problem sizes the difference between the mean runtimes of two
algorithms is very small compared to the standard deviations of their runtimes. Therefore,
we conclude that in practice for this population size the elitism does not slow down the
1914
12
10
(1+λ) EA, λ = 14 lnn
⌊ · ⌋
8 (1,λ) EA, λ = 14 lnn
⌊ · ⌋
26 27 28 29 210 211 212 213 214
Problem size n
Figure 2: Mean runtimes (number of fitness evaluations, normalized by nlnn) and their
standard deviations over 100 runs of the (1+λ) EA and the (1,λ) EA on OneMax with
noise rates q = 1 with varying problem size n.
algorithm by more than some lower order terms (but neither can speed it up). We note
that this is well-known for the noisefree setting, simply because with high probability some
offspring equals the parent, so removing the parent in the (1,λ) EA has no negative effect.
For the noisy setting, as our proof shows, this is less obvious.
We also compare the (1+λ) EA with λ = ln(n) and the (1+1) EA on OneMax
⌊ ⌋
in the presence of bit-wise noise with small but constant value of q = 0.01. Ours and
the previous theoretical works showed that in this setting the asymptotic runtime of the
(1+λ) EA is much better, but the question is if this translates to significant runtime
differences already for common problem sizes. Our results, depicted in Figure 3, show
that the difference between the algorithms is notable already on the smallest problem size
n = 26. We also note that since we use a logarithmic scale for both axes, the convex plot
of the (1+1) EA indicates that its runtime is super-polynomial in problem size n, which
lines up with the theoretical results in [GK16].
7 Conclusion
In this work, we have proven that boththe (1+λ) EA and(1,λ) EA with at least logarith-
micpopulationsizes areveryrobusttonoise, thatis, withuptoconstant noiseprobabilities
they optimize the OneMax benchmark in asymptotically the same time as if no noise was
present. This significantly improves the state of the art for the (1+λ) EA, considerably
reducing both the required population size and the runtime guarantee, and this is the first
such result for the (1,λ) EA.
The reason for this progress is the general observation that the noisefree offspring can
beseen asabiased uniformcrossover between theparent andthenoisy offspring. Fromthis
we proved that the true progress is at least a constant fraction of the noisy progress. The
20
nnln/
emitnuR(1+λ) EA, λ = ln(n)
107 ⌊ ⌋
(1+1) EA
106
105
104
103
26 27 28 29 210
Problem size n
Figure 3: Mean runtimes (number of fitness evaluations) and their standard deviations
over 100 runs of the (1+λ) EA and the (1+1) EA on OneMax with noise rates q = 0.01
with varying problem size n.
latter can be analyzed with known methods because the noisy offspring, asymptotically,
has the distribution of an offspring obtained from bit-wise mutation with a rate that is
the sum of the mutation and the noise rate. We are optimistic that this or analogous
arguments will find applications in future runtime analyses again.
Next steps to continue this line of research could include the first analysis of the
(µ,λ) EA [AD21] in the presence of noise or an analysis of the algorithms studied in
this work on the LeadingOnes benchmark, which generally is more affected by noise.
Acknowledgements
This research benefited from the support of the FMJH Program Gaspard Monge for op-
timization and operations research and their interactions with data science. It was also
supported by Australian Research Council through grants DP190103894and FT200100536
References
[AD11] Anne Auger and Benjamin Doerr, editors. Theory of Randomized Search
Heuristics. World Scientific Publishing, 2011.
[AD21] Denis Antipov and Benjamin Doerr. A tight runtime analysis for the
(µ+λ) EA. Algorithmica, 83:1054–1095, 2021.
[ADK22] Denis Antipov, Benjamin Doerr, and Vitalii Karavaev. A rigorous runtime
analysis of the (1+(λ,λ)) GA on jump functions. Algorithmica, 84:1573–
1602, 2022.
21
emitnuR[DDE15] Benjamin Doerr, Carola Doerr, and Franziska Ebel. From black-box com-
plexity to designing new genetic algorithms. Theoretical Computer Science,
567:87–104, 2015.
[DDHW23] Matthieu Dinot, Benjamin Doerr, Ulysse Hennebelle, and Sebastian Will.
Runtime analyses of multi-objective evolutionary algorithms in the presence
of noise. In International Joint Conference on Artificial Intelligence, IJCAI
2023, pages 5549–5557. ijcai.org, 2023.
[DDY20] Benjamin Doerr, Carola Doerr, and Jing Yang. Optimal parameter choices
via precise black-box analysis. Theoretical Computer Science, 801:1–34, 2020.
[DHK12] Benjamin Doerr, Ashish Ranjan Hota, and Timo Ko¨tzing. Ants easily solve
stochastic shortest path problems. In Genetic and Evolutionary Computation
Conference, GECCO 2012, pages 17–24. ACM, 2012.
[DJS+13] Benjamin Doerr, Thomas Jansen, Dirk Sudholt, Carola Winzen, and Chris-
tineZarges. Mutationratemattersevenwhenoptimizingmonotonefunctions.
Evolutionary Computation, 21:1–21, 2013.
[DJW02] Stefan Droste, Thomas Jansen, and Ingo Wegener. On the analysis of the
(1+1) evolutionary algorithm. Theoretical Computer Science, 276:51–81,
2002.
[DK15] Benjamin Doerr and Marvin Ku¨nnemann. Optimizing linear functions with
the(1+λ)evolutionaryalgorithm—different asymptoticruntimesfordifferent
instances. Theoretical Computer Science, 561:3–23, 2015.
[DL15] Duc-Cuong Dang and Per Kristian Lehre. Simplified runtime analysis of esti-
mation of distribution algorithms. In Genetic and Evolutionary Computation
Conference, GECCO 2015, pages 513–518. ACM, 2015.
[DN20] Benjamin Doerr and Frank Neumann, editors. Theory
of Evolutionary Computation—Recent Developments in Dis-
crete Optimization. Springer, 2020. Also available at
http://www.lix.polytechnique.fr/Labo/Benjamin.Doerr/doerr_neumann_book.html
[DNDD+18] Rapha¨el Dang-Nhu, Thibault Dardinier, Benjamin Doerr, Gautier Izacard,
and Dorian Nogneng. A new analysis method for evolutionary optimization
of dynamic and noisy objective functions. In Genetic and Evolutionary Com-
putation Conference, GECCO 2018, pages 1467–1474. ACM, 2018.
[Doe20] Benjamin Doerr. Probabilistic tools for the analysis of randomized op-
timization heuristics. In Benjamin Doerr and Frank Neumann, ed-
itors, Theory of Evolutionary Computation: Recent Developments in
Discrete Optimization, pages 1–87. Springer, 2020. Also available at
https://arxiv.org/abs/1801.06733.
22[DOSS23] Duc-Cuong Dang, Andre Opris, Bahare Salehi, and Dirk Sudholt. Analysing
the robustness of NSGA-II under noise. In Genetic and Evolutionary Com-
putation Conference, GECCO 2023, pages 642–651. ACM, 2023.
[Dro02] StefanDroste. Analysis of the(1+1)EAfor adynamically changing OneMax-
variant. In Congress on Evolutionary Computation, CEC 2002, pages 55–60.
IEEE, 2002.
[Dro04] Stefan Droste. Analysis of the (1+1) EA for a noisy OneMax. In Genetic
and Evolutionary Computation Conference, GECCO 2004, pages 1088–1099.
Springer, 2004.
[Dro05] Stefan Droste. Not all linear functions are equally difficult for the compact
genetic algorithm. In Genetic and Evolutionary Computation Conference,
GECCO 2005, pages 679–686. ACM, 2005.
[DS19] BenjaminDoerrandAndrew M. Sutton. When resampling tocopewithnoise,
usemedian, not mean. InGenetic and Evolutionary Computation Conference,
GECCO 2019, pages 242–248. ACM, 2019.
[DWY21] Benjamin Doerr, Carsten Witt, and Jing Yang. Runtime analysis for self-
adaptive mutation rates. Algorithmica, 83:1012–1053, 2021.
[FKKS16] Tobias Friedrich, Timo Ko¨tzing, Martin S. Krejca, and Andrew M. Sutton.
Robustness of ant colony optimization to noise. Evolutionary Computation,
24:237–254, 2016.
[FKKS17] Tobias Friedrich, Timo Ko¨tzing, Martin S. Krejca, and Andrew M. Sutton.
The compact genetic algorithm is efficient under extreme Gaussian noise.
IEEE Transactions on Evolutionary Computation, 21:477–490, 2017.
[FKNR22] Tobias Friedrich, Timo Ko¨tzing, Frank Neumann, and Aishwarya Radhakr-
ishnan. Theoretical study of optimizing rugged landscapes with the cGA. In
Parallel Problem Solving from Nature, PPSN 2022, Part II, pages 586–599.
Springer, 2022.
[GK16] Christian Gießen and Timo Ko¨tzing. Robustness of populations in stochastic
environments. Algorithmica, 75:462–489, 2016.
[Gut08] Walter J. Gutjahr. First steps to the runtime complexity analysis of ant
colony optimization. Computers & Operations Research, 35:2711–2727, 2008.
[Jan13] Thomas Jansen. Analyzing Evolutionary Algorithms – The Computer Science
Perspective. Springer, 2013.
23[JJW05] Thomas Jansen, Kenneth A. De Jong, and Ingo Wegener. On the choice of
the offspring population size in evolutionary algorithms. Evolutionary Com-
putation, 13:413–440, 2005.
[JLS23] Joost Jorritsma, Johannes Lengler, and Dirk Sudholt. Comma selection out-
performsplusselectiononOneMaxwithrandomlyplantedoptima. InGenetic
and Evolutionary Computation Conference, GECCO 2023, pages 1602–1610.
ACM, 2023.
[Joh10] Daniel Johannsen. Random Combinatorial Structures and Randomized Search
Heuristics. PhD thesis, Universit¨at des Saarlandes, 2010.
[LN21] Per Kristian Lehre and Phan Trung Hai Nguyen. Runtime analyses of
the population-based univariate estimation of distribution algorithms on
LeadingOnes. Algorithmica, 83:3238–3280, 2021.
[LQ23] Per Kristian Lehre and Xiaoyu Qin. Self-adaptation can improve the noise-
tolerance of evolutionary algorithms. In Foundations of Genetic Algorithms,
FOGA 2023, pages 105–116. ACM, 2023.
[LQ24] Per Kristian Lehre and Xiaoyu Qin. More precise runtime analyses of
non-elitist evolutionary algorithms in uncertain environments. Algorithmica,
86:396–441, 2024.
[LS11] J¨org La¨ssig and Dirk Sudholt. Adaptive population models for offspring pop-
ulations and parallel evolutionary algorithms. In Foundations of Genetic Al-
gorithms, FOGA 2011, pages 181–192. ACM, 2011.
[LW12] Per KristianLehreandCarsten Witt. Black-box search by unbiased variation.
Algorithmica, 64:623–642, 2012.
[MRC09] Boris Mitavskiy, JonathanE. Rowe, andChris Cannings. Theoretical analysis
of local search strategies to optimize network communication subject to pre-
serving the total number of links. International Journal on Intelligent Com-
puting and Cybernetics, 2:243–284, 2009.
[Mu¨h92] Heinz Mu¨hlenbein. How genetic algorithms really work: mutation and hill-
climbing. In Parallel Problem Solving from Nature, PPSN 1992, pages 15–26.
Elsevier, 1992.
[NW09] Frank Neumann and Carsten Witt. Runtime analysis of a simple ant colony
optimization algorithm. Algorithmica, 54:243–255, 2009.
[NW10] Frank Neumann and Carsten Witt. Bioinspired Computation in Combi-
natorial Optimization – Algorithms and Their Computational Complexity.
Springer, 2010.
24[QBJT19] Chao Qian, Chao Bian, Wu Jiang, andKe Tang. Running time analysis of the
(1+1)-EA for OneMax and LeadingOnes under bit-wise noise. Algorithmica,
81:749–795, 2019.
[QBY+21] Chao Qian, Chao Bian, Yang Yu, Ke Tang, and Xin Yao. Analysis of noisy
evolutionary optimization when sampling fails. Algorithmica, 83:940–975,
2021.
[QYT+18] Chao Qian, Yang Yu, Ke Tang, Yaochu Jin, Xin Yao, and Zhi-Hua Zhou. On
the effectiveness of sampling for evolutionary optimization in noisy environ-
ments. Evolutionary Computation, 26:237–267, 2018.
[RA19] Jonathan E. Rowe and Aishwaryaprajna. The benefits and limitations of
voting mechanisms in evolutionary optimisation. In Foundations of Genetic
Algorithms, FOGA 2019, pages 34–42. ACM, 2019.
[RS14] Jonathan E. Rowe and Dirk Sudholt. The choice of the offspring popula-
tion size in the (1,λ) evolutionary algorithm. Theoretical Computer Science,
545:20–38, 2014.
[Rud97] Gu¨nter Rudolph. Convergence Properties of Evolutionary Algorithms. Verlag
Dr. Kovaˇc, 1997.
[ST12] Dirk Sudholt and Christian Thyssen. A simple ant colony optimizer for
stochastic shortest path problems. Algorithmica, 64:643–672, 2012.
[Sud21] Dirk Sudholt. Analysing the robustness of evolutionary algorithms to noise:
refined runtime bounds and an example where noise is beneficial. Algorith-
mica, 83:976–1011, 2021.
[VM12] Petar M. Vasi´c and Dragoslav S. Mitrinovi´c. Analytic Inequalities.
Grundlehren der mathematischen Wissenschaften. Springer Berlin Heidel-
berg, 2012.
[Wit06] Carsten Witt. Runtime analysis of the (µ + 1) EA on simple pseudo-Boolean
functions. Evolutionary Computation, 14:65–86, 2006.
[ZD23] Weijie Zheng and Benjamin Doerr. From understanding genetic drift to a
smart-restart mechanism for estimation-of-distribution algorithms. Journal
of Machine Learning Research, 24:1–40, 2023.
[ZYQ19] Zhi-Hua Zhou, Yang Yu, and Chao Qian. Evolutionary Learning: Advances
in Theories and Algorithms. Springer, 2019.
25