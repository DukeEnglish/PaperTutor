The Effects of Group Sanctions on Participation and Toxicity:
Quasi-experimental Evidence from the Fediverse
Carl Colglazier∗, Nathan TeBlunthuis†, Aaron Shaw∗
∗Northwestern University
†University of Michigan
Abstract—Online communities often overlap and coexist, de- Serverspre-defederation Serverspost-defederation
spite incongruent norms and approaches to content moder-
ation. When communities diverge, decentralized and feder-
atedcommunitiesmaypursuegroup-levelsanctions,including
defederation (disconnection) to block communication between
Accountspre-defederation Accountspre-defederation
members of specific communities. We investigate the effects
of defederation in the context of the Fediverse, a set of
decentralized,interconnectedsocialnetworkswithindependent
governance.MastodonandPleroma,themostpopularsoftware
powering the Fediverse, allow administrators on one server
to defederate from another. We use a difference-in-differences
approachandmatchedcontrolstoestimatetheeffectsofdefed-
eration events on participation and message toxicity among Figure 1: Illustration of how defederation disconnects two
affected members of the blocked and blocking servers. We servers and thereby disconnects the subnetworks of people
find that defederation causes a drop in activity for accounts usingeachserver.Thetoprowshowsthenetworkofservers
on the blocked servers, but not on the blocking servers. Also, before (left) and after (right) defederation. The bottom row
we find no evidence of an effect of defederation on message shows the corresponding networks of users. On the left, an
toxicity. edgeconnectsauserononeserverwithauseronadifferent
server.Defederation(right)disconnectsthemsotheycanno
Introduction longer exchange messages.
Content moderation in response to toxic and anti-social
behaviorispervasiveinsocialmedia.Ingeneral,moderation such as when a sub-community restricts contributions from
interventions strive to balance the value of wide and active members of another sub-community. These decentralized
user bases with the threats posed by conflicts and hate group-level sanctions are distinct in that the targeted sub-
speech (Gillespie, 2018). Websites that host user-generated community remains part of the larger network. To our
content and sub-communities apply many kinds of policies knowledge, the effects of such sanctions remain unexplored
and interventions. However, when norms diverge across empirically.
interconnected, independent communities in the absence of To investigate the effects of decentralized group-level
a single (corporate or not) parent or owner, governance and sanctions, we analyze defederation events in the Fediverse,
moderation pose acute challenges. a decentralized social media system which consists of in-
A growing empirical literature has investigated social dependently managed servers that host individual accounts
media content moderation and governance. Moderation ac- and pass messages using shared protocols. Communication
tions most frequently target individual posts and accounts, between servers can happen only when the administrators
but other group-level sanctions affect entire communities of both servers permit it. Server administrators can revoke
or websites. For example, Reddit has banned subreddits such permission by “defederating” from (blocking all in-
and Discord has blocked servers, reducing the prevalence teractions with) specific servers. Defederation is one of the
of unwanted behavior within and sometimes beyond the few tools administrators in a decentralized system have to
targetedgroups(Chandrasekharanetal.,2017,2022;Ribeiro protect against bad actors or enforce norms from beyond
et al., 2021, 2023; Russo et al., 2023; Zhang and Zhu, their own servers. While many defederation events on the
2011). Most prior work on group-level sanctions focuses Fediverse occur between servers with no known interaction
on sanctions applied by central actors such as commercial history, many also come in response to norm violations and
social media platform staff. However, autonomous com- toxic interactions across server boundaries with a history of
munity administrators can also enact group-level sanctions previous interactions. Defederations that cutoff cross-server
4202
rpA
2
]IS.sc[
1v90120.4042:viXrainteractionsprovideanopportunitytoidentifytheeffectsof effectivepolicymaking,design,andanalysisofsocialmedia
thesegroupsanctions onaccounts mostlikelytobedirectly governance especially difficult.
affected. Largecorporateplatformsandautonomouscommunities
We collect data from 214 defederation events between alike must grapple with incongruent norms about online
January 1, 2021 to August 31, 2022 that involved 275 behavior and the appropriate role of the above governance
servers and 661 accounts which had previously communi- components. For instance, today’s regulatory assemblage
cated across subsequently defederated inter-server connec- governing social media departs from earlier eras charac-
tions.Usingacombinationofnon-parametricandparametric terized by utopian notions of freedom of expression on
methods, we estimate the effects of defederation on two the “electronic frontier” (Kaye, 2019). Whether governance
outcomes:postingactivityandtoxicpostingbehavioramong interventions are understood as “censorship” or “content
affectedaccounts.Wefindanasymmetricimpactonposting moderation” depends not only on one’s perspective, but
activity: Accounts on blocked servers reduce their activity, also the on their origin within the institutional hierarchy
but not accounts on blocking servers. By contrast, we find (MyersWest,2018).Atthehighestlevel,state-ledinterven-
that defederation has no effects on post toxicity on either tionspreventaccesstosites,domains,services,IPblocks,or
the blocked or blocking servers. protocols(King,Pan,andRoberts,2013).Similarly,network
These findings suggest that defederation, although a service providers and other intermediaries also engage in
common group-level sanction on the Fediverse, has mixed blocks or website takedowns justified by terms of service
effectiveness: Despite the risks of severing communication violations or legal risks (Vu, Hutchings, and Anderson,
channels, communities implementing group-level sanctions 2023; Ribeiro et al., 2023; Han, Kumar, and Durumeric,
do not lose activity. This implies that defederation may 2022). Lower in the hierarchy, owners and administrators
avoid some of the costs associated with other moderation of specific sites or platforms set their own policies and
techniques such as account requirements or group sanc- can enforce them through sanctions applied to individuals
tions like geographic blocks (Hill and Shaw, 2021; Zhang as well as whole (sub-)communities (Jhaver et al., 2021;
and Zhu, 2011). Although defederation reduces activity by Chandrasekharanetal.,2022;Ribeiroetal.,2021).Devolv-
blocked accounts, we did not find evidence that it made ingpolicysettingandenforcementtoincreasinglylow-level
their posts less toxic. This suggests that defederation may actors poses a trade-off. Low-level governance can institute
not improve adherence to broadly held norms. Our study local norms and advance a community’s specific goals,
contributes to knowledge of content moderation on social but may lack the necessary means to prevent important
media in that it (1) describes defederation, a novel form categories of harm.
of group-level sanction as instantiated on the Fediverse, A growing literature in the social and computational
(2) derives hypotheses regarding the effects of defederation sciences evaluates the empirical effects of specific content
from prior literature, (3) creates a novel dataset of defeder- moderation and governance techniques at various institu-
ation events, (4) conducts a quasi-experimental analyses to tional levels. Previously studied techniques include deplat-
quantify effects of defederation on parties affected on the forming, quarantines, censorship and geographic blocks,
blockedandblockingserversand(5)findsthatdefederation banning, account requirements, and pre-publication filter-
has asymmetric effects on activity and no measurable effect ing (Ribeiro et al., 2023; Chandrasekharan et al., 2022;
on toxicity. King, Pan, and Roberts, 2013; Ribeiro et al., 2021; Zhang
and Zhu, 2011; Hill and Shaw, 2021; Tran et al., 2022).
In general, this prior work finds that barriers to specific
Background
kinds of contributions from specific kinds of actors cause
immediate decreases in the targeted activity among the
Social media content moderation and governance targetedaccounts.Asexamples,requiringaccountsonwikis
decreased the quantity of low-quality contributions (Hill
Challenges of decentralized governance and content and Shaw, 2021); mainland China’s block of Chinese lan-
moderation in networked communication systems are ubiq- guageWikipediadecreasedcontributionsfromeditorsinside
uitous. Threats to public safety, trust, and health resulting and outside of China (Zhang and Zhu, 2011), and pre-
from toxicity, misinformation, and incivility online are now publicationmoderationincreasedqualitycontributions(Tran
widely perceived and addressed by various content modera- et al., 2022).
tion and governance tools (Gruzd, Soares, and Mai, 2023). Some governance interventions spill-over or have indi-
National and supra-national governments impose disparate rect effects (intended or not) beyond their immediate tar-
legal regimes such as the GDPR in Europe or the DCMA gets. Banning hateful communities on Reddit, for example,
in the United States. Simultaneously, corporate platforms reducedspeechcharacteristicofthebannedcommunitiesby
employmanystrategies,fromalgorithmicfilterstouserand boththeactiveparticipantsinthosecommunitiesandwithin
content monitoring systems, to monitor and shape content the other communities they participated in following the
visibility. Leaders of communities such as subreddits and ban (Chandrasekharan et al., 2022). However, when Reddit
Facebook groups institute their own rules and norms and banned two toxic communities, they subsequently reorga-
seek to hold community participants to them (Gillespie, nized on other platforms where they experienced declining
2018). Interdependence among these components makes activity and one had increasing radicalization and toxicity(Ribeiroetal.,2021).Banningwholesub-communitiesmay level of adoption across servers to be useful. The overall
also create spillovers of antisocial and toxic behavior when result is that the user experience in a federated communi-
the former members of banned communities migrate their cation network can vary enormously depending on how one
activities elsewhere (Ribeiro et al., 2021, 2023). connects to it.
The majority of prior work in this area has identified This variability extends to governance. No server can
effects of governance and moderation interventions on the directlydictatetherulesordecisionsofanother.Theadmin-
largest “mainstream” social media platforms such as Face- istrators of each server hold complete autonomous control
book, Twitter, or Twitch (Jhaver et al., 2021; Mitts, Pishar- over their internal affairs. In choosing which server to
ody,andShapiro,2022;Seering,Kraut,andDabbish,2017). connect to the network through, individuals also choose
A few have focused on more decentralized or autonomous a governance regime (intentionally or not). If unsatisfied
community environments like subreddits or independently with one regime, they can (at least in theory) move to
managed wikis (Chandrasekharan et al., 2022; Hill and anotherandtaketheirdataandsocialtieswiththem.Among
Shaw, 2021). Many of the interventions studied include dissatisfied members of a community, the opportunity for
group-level sanctions such as political blocks and censor- “exit” may be especially easy when it costs little time or
ship events affecting whole geographic regions (Zhang and effort to join another subnetwork (Frey and Sumner, 2019;
Zhu, 2011), as well as decisions and enforcement actions Frey and Schneider, 2021). Individuals wishing to behave
by “local” administrators or moderators (Srinivasan et al., anti-socially—toharass,troll,ormakeoffensiveposts—may
2019). Several more recent studies have considered alterna- select a server that allows them to do so. Other servers
tive social media sites, such as alt-right communities Voat, within a federated social media network must address this
Parler,orGab,oftenwithaneyetowardsunderstandinghow to protect their own users.
interventions on mainstream platforms may have impacted Governanceinfederatedcommunicationnetworksisnot
participation in less regulated environments (Ribeiro et al., limited to servers’ authority over individuals: servers also
2023; Stocking et al., 2022). The current project expands implement sanctions against each other. If one server hosts
this literature by analyzing the effects of a previously un- anti-social behavior, other servers can implement a server-
studiedgroup-levelsanctioninadecentralizedandfederated level intervention. Such interventions, for instance group-
social media network. level bans or blocks, also happen among semi-autonomous
communities within platforms or more centralized environ-
Governance and moderation in federated commu- ments like Reddit, Wikipedia, and multiplayer video game
nication networks servers.Yet,toourknowledge,priorworkongovernancein
social media has not analyzed the effects of these sorts of
The architectures of federated communication systems group-level interventions. Doing so offers a valuable oppor-
createdistinctopportunitiesandobstaclestogovernanceand tunity to expand the empirical knowledge in this domain.
moderation. Federated communication networks, such as
email, are defined by independently operated servers which
The effects of community-level defederation as a
let users pass messages both within and across servers.
group sanction
Protocol-based interoperability underpins this design and
affords cross-server communication. The resulting server-
Servers in a federated network can enact sanctions
levelautonomymayalsoofferbenefitsintermsofscalability
against other servers in several ways, all of which regulate
and resilience. For instance, new servers may join or leave
interactionsamongtheirusers.Forexample,serversmayfil-
the network without coordinating with other servers. Such
ter, limit or slow the propagation of messages from another
decentralized and complex systems of communication tend
serverthroughtheirsubnetwork.Ofthepossibleapproaches,
to possess a scale-free structure with superior robustness
defederation—which completely blocks all communication
to the failure of single nodes over other classes of large,
acrossserverboundaries—isthemostextreme.Defederation
complex graphs (Albert, Jeong, and Baraba´si, 2000).
is widely used when server administrators determine that
Scalabilityandresilienceareparticularlyimportantqual-
another server is causing problems to such a degree that
ities for communication networks, where the value of the
managing continued interactions is not worth the trouble.
networkisoftenasuperlinearfunctionofitssize(VanHove,
Forexample,emailspamfiltersoftenincluderulesblocking
2016). Expanding a communication network can produce
all messages originating from a given email domain or
collective benefits to members driven by both the increased
server.
space of potential connections (connectivity) as well as the
increased opportunities for pooled information (communal- Basedonpriorcontentmoderationresearchandthechar-
ity)(Fulketal.,1996).Federatednetworksalsoofferprofuse acteristics of defederation as a specific type of governance
opportunities for decentralized action, including modular intervention in decentralized social media, we pursue the
extensions and localized content and norms (Datta et al., following research questions:
2010). 1) How does defederation impact the activity levels for
Atthesametime,thedecentralizedstructureoffederated affected accounts on (a) the defederated instance
networksalsomakesitdifficulttocentrallycontrolorapply (blocked server); and (b) the defederating instance
uniformity. Technical features typically require a sufficient (blocking server)?2) How does defederation impact toxic posting behavior
among the affected accounts on either (a) the blocked Blocked Blocking
or (b) blocking servers?
When one Fediverse server blocks another, the blocked
server no long propagates messages to the blocking server. 200
This reduces the size of the audience that can be reached
fromtheblockedserverandtherebymaydecreasetheutility
100
of posting on that server. As with interventions studied in
priorresearchsuchasbans,quarantines,anddeplatforming,
0
weexpectthatdefederationreducesactivityamongaffected
1 1 1 2 2
2 2 2 2 2
accounts on the blocked servers. 0 0 0 0 0
2 2 2 2 2
Thelikelyconsequencesofdefederationfortheblocking Apr Jul Oct Jan Apr
server are less clear. Disconnecting from the blocked server
decreases the potential audience of the blocking server’s
Figure 2: The y-axis shows the cumulative number of
users.Asaresult,individualswholosevaluableconnections
blockedandblockingaccountsincludedinouranalysisover
might have fewer reasons to use the network. On the other
our study period.
hand, server administrators who initiate defederation likely
have an informed rationale. They may anticipate the costs
andbenefitsofdefederationbyobservingmessagesbetween
toxic posting behavior in the Fediverse. We collected lon-
their server and the servers they consider blocking. Perhaps
gitudinal trace data from 7,445 publicly listed defederation
more importantly, some volunteer administrators struggle
events and about 104 million public posts that occurred in
to effectively protect their users from anti-social behavior.
the Fediverse on either the Mastodon or Pleroma networks
By enacting defederation, administrators demonstrate com-
between April 2, 2021 and May 31, 2022. Using this data,
petence in server governance, eliciting increased trust and
we analyze activity of user accounts (for RQ1) and the
commitment from members of their communities. If users
toxicity of their messages (for RQ2) on the blocking and
tend to value such competence more than their connections
blocked servers impacted by these events in comparison
to the blocked server then defederation is unlikely to de-
to matched control accounts. We apply a difference-in-
crease their activity and could even increase it.
differences approach and present both non-parametric and
Similarly,itisunclearhowdefederationwillaffecttoxic
parametric estimates of the effects of defederation.
posting behavior. Some past studies of deplatforming have
foundthattoxicityincreasesaftersomedeplatformingevents
Empirical Setting
(Ali et al., 2021; Buntain et al., 2023; Chandrasekharan
et al., 2017). Such increases may happen when group-level
The Fediverse is a decentralized social network com-
sanctionsprovokeblowbackorrevoltsagainsttheimposition
prised of many servers which each institute their own rules,
of sanctions in the form of non-compliance with sanctions
policies,andmoderationpractices.Eachaccountconnectsto
orincreasinganti-socialbehavior(Heckathorn,1988).How-
thenetworkthroughahomeserverandcansendandreceive
ever, other studies have found that group-level sanctions
postsfromaccountsbothwithinandoutsidethehomeserver
decrease or do not change toxicity (Jhaver et al., 2021;
via the ActivityPub protocol. Mastodon and Pleroma are
Chandrasekharan et al., 2022).
twopopular,interoperableActivityPub-basedmicroblogging
Therefore,weanticipatethatdefederationwillhavelim-
systems with overlapping but distinct features.
itedornegligibleeffectsontoxicpostingbehavior.Accounts
Fediverse administrators have nearly complete control
onblockedserversmaynotreceiveanyindicationoftherea-
over their servers, from choosing and configuring software
sons for the intervention. While server administrators may
to setting rules. However, administrators only have direct
choose to publicize their defederation decisions, no mecha-
control over their own server. Although users of one server
nismpropagatesthedecisionstotheusersoftargetedservers
can report rule-breaking posts by another server’s accounts,
(muchlesstheuserswhosebehaviormayhavetriggeredthe
only the administrator of an account’s home server can
blockinthefirstplace).Usersontheblockingsererwhohad
sanction the user, such as by removing the post or send-
interactedacrosstheseveredconnectionlikewiseexperience
ing a warning. Consequently, when two servers come into
no other direct effects and retain access to the rest of their
conflict, administrators must either use persuasion, ignore
communication networks. In the absence of more targeted
the problem, or block or filter the other server.
or focused information about the reasons behind the block,
Defederation is the process of severing ties between
we do not expect it to impact toxic behavior substantially.
serverstorestrictinteractions,typicallyduetodifferencesin
policies, norms, or content. Administrators are responsible
Data, Measures, and Methods
fordefederationdecisions,andtheycanchoosetodefederate
fromspecificservers.Defederationhelpsmaintaintheauton-
Wepursueanobservational,quasi-experimentalresearch omyofserversandallowsthemtoadheretotheirownvalues
designtoidentifyeffectsofdefederationontheactivityand andrules.IndividualswithaccountsonFediverseserversdo
stnuocca
fo
.muNTerm Description
Fediverse Agroupofindependentlyoperatedsocialmediaserverswhichinteroperatewithsharedprotocols.
Defederation Aserver-to-serverblockbetweenserversinafederatedsystem.
Mastodon ThemostpopularandwidelyusedsoftwareontheFediverse.
Pleroma AlightweightFediversesoftwarewithanAPIsimilartoMastodonandanalternativefeatureset.
Serveradministrator ApersonorgroupwhocontrolsthetechnicalinfrastructureandconfigurationofaFediverseserver.
Groupsanction Amoderationactionagainstagroup,notanindividual.
TABLE 1: Glossary of key terms.
not tend to receive direct notifications about defederation records each day and infer the date that defederation oc-
events,thoughtheymayeitherseeanannouncementbytheir curred by the day a server first appears in the list. We
server administrator. On Mastodon, defederations delete exclude 472 defederation events where we do not know
records of the defederated server, meaning that affected the exact date of defederation because we are missing a
accounts lose followers from the defederated server and no dailysnapshotoftherecord.Weonlyanalyzeddefederation
longer follow accounts on the defederated server. events where the public record persisted at least 92 days
aftertheinitialevent,excluding1,347thatdidnot.Accounts
are affected by a defederation event if they had previously
sent a reply to an account on the blocked or blocking
server.Weexcludedaccountsthatmayhavebeenaffectedby
defederation events we dropped due to missing data issues.
Ouranalysisisdesignedtoidentifytheeffectsofdefed-
eration accounting for trends in activity and toxicity before
and after defederation events (defined below). We therefore
analyze data from the 91 days prior to and following each
defederation event (dropping the day of the defederation
itself). The outcomes of interest are quantities and qualities
of posting activity, so we exclude inactive accounts by
dropping those that posted fewer than 10 times in the 91
daysbeforeadefederationeventinvolvingtheirhomeserver.
Wealsoincludeonlyaccountsthatpostedatleastonceprior
to the 91 day period and at least once in the final 45 days
of this period.
Figure 3: A screenshot shows a cross-server interaction on Someserversexperiencemultipledefederationevents.In
Mastodon. Note that the account name of the replying user order to avoid potential confounding of our estimates from
indicates their home server (@user@server). multiple exposures to defederation, we exclude accounts
thatexperienceddefederationeventsonmultipledays.After
dropping some additional accounts in the matching process
Data Collection (described below), the resulting dataset includes 258 ac-
counts whose 71 home servers were defederated and 150
We first identify a list of Fediverse servers involved in accountswhose52homeserversdefederatedanotherserver.
defederation by compiling a set of known servers which This included a total of 214 defederation events.
federatewithotherserversonthelist,startingwiththesetof
serversonmastodon.social1.Wetheniterativelyaddservers
Measures
with peer connections to members of this set using an API
feature which discloses server-to-server connections. This
We construct measures within the analytic window for
approach identified 11,025 servers and 7,445 defederation
all accounts and servers involved in defederations. We also
records. We collected data from these servers by running
aggregate our measures over 7 day periods (weeks).
a script daily. The script uses publicly available and docu-
Defederation events: We observe defederation events
mented REST APIs provided by Mastodon and Pleroma to
viatherecordsoffederationpoliciespublishedbyMastodon
collect timelines of posts. We collected approximately 104
andPleromaserverswithintheFediversesystemswestudy.
million posts in total. The post data allows us to identify
We collected data on 440 blocking servers and 1,136
accounts that engaged in cross-server interaction because
blocked servers. We record the timestamp of each defed-
usernames indicate the home server.
eration event, which we use to construct a timeline of
Weidentifydefederationfromthepublicrecordsservers
defederation events.
publish of which other servers they block. We check these
Activity:TheresponsevariableofouranalysisforRQ1
1.https://mastodon.social/ is the posting activity of user accounts affected by defed-eration events. We measure activity as the number of posts how they engage with the wider Fediverse through posting
an account makes each week. replies to external servers. We match on the following
Toxic behavior: RQ2 investigates the impact of defed- variables: total number of account posts, the number of
eration on toxic posting behavior. We measure post toxicity posts in the 45 days prior to treatment (“post count (45)”),
using the Perspective API model for toxicity, which uses the number of replies sent, the number of other servers
machinelearningtopredictifapostisa”rude,disrespectful, engaged with replies, and the number of active accounts
or unreasonable comment that is likely to make someone on their home server. We applied a log transformation to
leaveadiscussion”(Jigsaw,2021).Foreachpost,themodel eachofthese(highlyskewedcount)variables.Weconstruct
outputs a score ranging from 0–1 corresponding to the all matching measures over weeks during the 91 days prior
estimated probability that the post contains toxic speech. to the defederation event experienced by the treated user in
For each account, we aggregated their toxicity during each question.
weekbytakingthemeantoxicityscorefortheirpostsduring We use coarsened exact matching (Iacus, King, and
that window. Porro, 2012) with Sturges’ rule to determine the number of
Blocked user accounts: Defederation is a directional bins for all variables except the number of active accounts
action from one server to another and may not be recipro- on the server, for which we used four bins to be less strict.
cated. In our research questions, we estimate the effects of We used one-to-one matching, selecting the closest match
user accounts being blocked from cross-server interactions according to Mahalanobis distance and discarded accounts
in a defederation event. We assign accounts to the blocked for which there was not a sufficiently good match (139
treatment group if (1) their home server was defederated for the blocked accounts; 63 for the blocking accounts).
(blocked) by another server (the blocking server), (2) they Accounts that were treated were not eligible to be matched
replied to an account on the blocking server in the 91 days controls.
before defederation, and to ensure the account is active at We denote the resulting matched control groups as C ,
0
the time of treatment, (3) they post at least once in the last the control group for blocked server users U , and C , the
0 1
45 days prior to defederation . For clarity we refer to the control group for blocking server users U . The blocked
1
blocked treatment group as U 0 below. accounts had 258 matched units from 397 potential units;
Blocking user accounts: In our research questions, we the blocking accounts had 150 from 213 potential units.
are also interested in effects of defederation on the block- Figure 4 shows the covariate balance using standardized
ing servers’ accounts. We assign accounts on the blocking mean differences before and after matching across these
servertotheblockingtreatmentgroup(U 1)iftheymeetthe groups.
parallel conditions to those described above for the blocked
treatment group.
Time: As noted above, we aggregate our measures over Adjusted Unadjusted
7 day periods. We therefore measure (time) as the number
of such weekly periods before/after the defederation event Blocked Blocking
affecting the account in question excluding the day defed-
Server accts.
eration occurred.
Replies
Analytic Plan Post count (45)
Post count
We pursue an identification strategy to estimate the Domains
effects of defederation events. For both sets of outcomes— Date
activity levels and toxic posts—we visualize time series,
−3 −2 −1 0 1 −3 −2 −1 0 1
conduct non-parametric statistical tests, and perform re-
gression analysis using difference-in-differences (DiD) es- Standardized Mean Differences
timators that infer the effects of the treatment on treated
Figure 4: A covariate balance plot shows the standard-
accounts from both blocked and blocking servers against a
ized mean difference between treatment and control groups
setofmatchedcontrols.Weusecoarsenedexactmatchingto
for each measure used in our matching procedure before
construct this synthetic control group of accounts that are
(unadjusted) and after (adjusted) matching. Our procedure
similar to the accounts impacted by defederation (treated
effectively found a group of matched controls similar to the
accounts).
treated accounts along these measures.
Constructing Matched Control Groups
All of our analyses depend on comparing user accounts Analysis
that experienced defederation events with similar accounts
thatdidnot.Thegoalofstatisticalmatchingistoreducebias Ouranalysisproceedsinthreeparts:descriptivecompar-
and account for potential confounders. In this case, we use ison and visualization; non-parametric tests; and difference-
observable, pre-treatment attributes of accounts that capture in-differences estimation.Descriptive comparison and visualization:. We cal-
culate descriptive and summary statistics for all measures
across the treated and control groups. We also visualize y ∼NegBinomial(µ ,ϕ)
i,t i,t
posting activity before and after defederation, plotting the
µ =β +ζ +β I(i∈U )
i,t 0 i 1 k
number of weekly posts made by the median user account
+β I(t>T)+β t+β I(t>T)·t
in each of our four study groups (U , U , C , C ) in the 12 2 3 4
0 1 0 1
weeks prior to and following defederation with 95% confi- +β 5I(i∈U k)·I(t>T)+β 6I(i∈U k)·t
denceintervalsbasedonorderstatistics.Boththedescriptive +β I(t>T)·I(i∈U )·t
7 k
analysis and the visualization justify and complement our
non-parametric and difference-in-differences analyses. Where y is the activity of user account i in week t.
i,t
T indicates the time of defederation, U is the treatment
Non-parametric tests:. We first compare changes in k
group (U is the set of blocked accounts and U is the
activity level and median post toxicity before and after 0 1
set of blocking accounts), I is the indicator function equal
defederation using a non-parametric Wilcoxon signed-rank
to 1 when its parameter is true and 0 if not, and ζ is
test, which returns a W test statistic representing the sum i
the random intercept for user account i. Our parameter of
of the ranks of the positive differences between paired
interest is β , the coefficient for post-treatment membership
observation and a p-value which compares to the null hy- 5
inthetreatmentgroup,fortestingwhetheractivityincreases
pothesis that the changes between the two groups are zero.
(β > 0) or decreases (β < 0) upon defederation. The
This test is robust to outliers, independent of distributional 5 5
model’s other terms are intercepts and trends pre-treatment
assumptions, and assigns equal weight to each user account
(β ,β ) and post-treatment (β ,β ,β ) and membership in
irrespectiveoftheiractivitylevels.Fortoxicityinparticular, 0 3 2 4 6
the treatment group (β ).3
this non-parametric approach reduces threats of bias due to 1
the opaque machine learning systems that create the values Model for toxicity:. Our measure for toxicity is
reportedfromthePerspectiveAPI.Weconductthistestover calculatedatthepostlevel,leadingtoseveralkeydifferences
all user accounts in both the blocked and blocking groups. inhowwemodelthisoutcome.Insteadofaggregatingthisat
the account level, which would obscure variation, we use a
Difference-in-differences(DiD)estimation:.Ourpri-
multi-level model with random slopes for group to estimate
mary analysis estimates the causal effect of defederation on
the effects of defederation as an account-level treatment on
the blocked accounts (U ) and the blocking accounts (U )
0 1 post-level toxicity. We use beta regression for our analysis
using a difference-in-differences (DiD) framework. DiD
oftoxicitybecausethePerspectiveAPIscoresareonarange
systematically quantifies the changes in a treatment group
between0and1andaredesignedtoquantifytheprobability
(i.e., blocked accounts; U ) following an intervention (i.e.,
0 that a comment is toxic. Our model of toxicity is thus:
a defederation event) relative to changes in a control group
(i.e.,accountsmatchedtoblockedaccounts;C ).Itdoesthis
0
by modeling temporal trends for each group (treatment; U
i y ∼Beta(µ ,ϕ)
andcontrol;U )beforeandafterthedefederationaswellas k,i,t i,t
i
group-dependent discontinuous “jumps” at the moment of µ i,t =K 0+ζ i+η 0(i∈U k)+η 1(i∈/ U k)
intervention. η =β +β I(t>T)+β t+β I(t>T)·t
0 0 1 2 3
Our DiD estimates support causal inferences under sev- η =β +β I(t>T)+β t+β I(t>T)·t
1 4 5 6 7
eral assumptions: The matching procedure should result
in control groups of accounts that were not affected by where y is the toxicity of a given post k by account i
k,i,t
defederation, but were just as likely to have been affected in week t, K is the overall intercept, ζ are the random
0 i
as the accounts that were, the two groups’ trends in the intercepts for each account, η are random effects for the
0
outcome variables should be parallel prior to treatment, and treatment group and η are random effects for the matched
1
thetrendsshouldbelinear.Ifso,thenthedifferencebetween control group.
the jumps of the two groups quantifies a “local average
treatmenteffect” (LATE).2 Weincluderandominterceptsin
Results
our model to account for variability between subjects. We
fit versions of this model for both outcomes and types of
server (blocked and blocking) using the brms R package. Figure 5 summarizes our dependent variables across the
treatment and matched control groups during the pre- and
Model for activity:. Activity, the number of posts
post-treatmentperiods.Below,wepresentresultsforthetwo
anaccountmakesperweek,isanover-dispersedcountvari-
outcomes—activity and toxicity—separately.
able. We therefore use a negative binomial model formally
represented as:
3.We note that the β6 and β7 coefficients model the group-specific
trends before and after treatment. If these are both 0, this would provide
evidencesupportingtheparalleltrendsassumptionofourDiDmodels.As
2.Wesaylocalaveragetreatmenteffectbecausetheestimateappliesin showninTable3,the95%credibleintervalsforbothcoefficientscontain
specifictimesandplacesthatmaynotgeneralizetoothercontexts. 0,suggestingtheassumptionisreasonable.Post count (log) Blocked
30
20
Control (pre) 10
0.0 2.5 5.0 7.5 0
Control (post)
Toxicity Treatment (pre) Blocking
30
Treatment (post)
20
10
0.0 0.2 0.4 0
−10 −5 0 5 10
Weeks since treatment
Figure 5: Box and whisker plots visualize the distributions
of our dependent variables within the blocked and blocking
groups of user accounts and their matched controls before Control Treatment
and after defederation. The lines correspond to the median,
the boxes to the inter-quartile range (IQR), the whiskers to
the range of the data within 1.5 * IQR, and the dots to data Figure6:Visualizationofactivityamongblockedandblock-
points outside the range of the whiskers. ing user accounts shows an asymmetric change in activity
following defederation. An account with a median post
count on the blocked server declines in activity much more
Effects on Activity rapidly following defederation compared to matched con-
trols while an account with a median post count on the
Research question 1 asks how defederation affected blocking server declines similarly to matched controls.
activity among user accounts whose home server either
blocked (blocking group) or was blocked by (blocked Group median W p
group) another server. Our visualization of the time series
U0 -135.5 41197.5 0.000
of affected accounts compared to matched controls, non- C0 -18.0 35762.0 0.143
parametric tests, and difference-in-differences analysis all U1 -54.5 12413.0 0.122
indicate that blocked group users decreased their activity C1 -53.5 12520.0 0.091
followingdefederationwhilechangesamongblockinggroup
∆0 -39.0 39927.0 0.000
users were minor or noisy.
∆1 3.0 10645.5 0.421
Before defederation, the trends and weekly median ac- TABLE 2: Non-parametric tests for differences in activity
tivity levels remained comparable for accounts on both the before and after defederation events (summed across all
blocked and blocking servers. Although all groups reduced weeks)findameasurabledecreaseinpostingactivityforthe
activity somewhat after defederation, Figure 6 shows the accounts on blocked servers compared to matched controls
activity levels on the blocked servers quickly diverged from but no such change for accounts on blocking servers.
theirmatchedcontrolsafterdefederation.Forinstance,while
the median post count for treated accounts on blocked
servers (U ) was 18.5 posts one week before defederation, trols. By contrast, among the user accounts on the blocking
0
this dropped to 13 posts one week after defederation. Com- servers, we observe very similar post-defederation activity
parethistotheanalogousmedianpostcountamongmatched decreasesforthetreatmentandmatchedcontrolaccountson
controls which was 20.5 posts per week both before and the blocking server with a decrease in the median of 54.5
afterdefederation.Incontrast,themedianpostcountamong posts (10.7%) by treated accounts compared to 53.5 post
treatedaccountsonblockingservers(U )was17intheweek (11.1%) by the the matched controls. In sum, we observe
1
before and 13 in the week after defederation compared to asymmetric effects of defederation: activity decreases for
15 and 13 for the matched controls (C ). affected accounts on blocked servers, but not on blocking
1
servers.
Non-parametric tests:. This strong response among the
treatedaccountsontheblockedservers(U )alsoappearsin DiD Analysis:. Our DiD results corroborate the same pat-
0
thenon-parametrictestbasedonpostcountssummedforall tern:decreasedactivityamongusersontheblockedservers,
weeks and shown in Table 2. Prior to defederation, median andnochangeamongusersontheblockingservers.Table3
activity among blocked accounts and matched controls was shows the regression results for both models. Figure 7 plots
similar, yet following treatment, activity for the treated the modeled activity levels of a median account in each
blocked accounts decreased by a median of 135.5 posts group along with the corresponding 95% credible intervals
(21.9%) compared to 18 posts (9.5%) for the matched con- quantifying uncertainty in the model’s parameter estimates.
tnuoc
tsop
naideMUseraccountsonthetheblockedservers(U )decreasetheir
0 Blocked
activity compared to matched controls (β =−0.24;SE = 0.2
5
0.07).Forauseraccountwithmedianpre-treatmentactivity
levels on the blocked server, this corresponds to a reduction 0.1
from 24.9 posts per week immediately before treatment to
19.6 posts per week immediately after treatment (a 21.4% 0.0
reduction),comparedto22.8postsperweekafter treatment
for its matched control. Blocking
0.2
Consistentwithourotherresultsforuseraccountsonthe
blocking server, the 95% credible interval for the effect of
0.1
defederation on activity by accounts on the blocking server
(U ) contains 0 (β =−0.08;SE =0.08).
1 5 0.0
−10 −5 0 5 10
Weeks since treatment
Blocked
3.0 Control Treatment
2.5
Figure 8: Median toxicity among accounts which posted
Blocking each week for blocked and blocking user accounts. The
median toxicity remained flat for all groups.
3.0
2.5 Non-parametric tests. Table 4 summarizes aggregate
changes in anti-social behavior (toxicity) after defederation
−10 −5 0 5 10 for all groups. Anti-social behavior by user accounts on
Weeks since treatment blocked servers decreases slightly. For example, the median
toxicity score for posts from these accounts declined by
0.005, but we lack sufficient statistical power to distinguish
Control Treatment
this from the null hypothesis that there was no difference
in changes between treatment and control groups on the
Figure 7: A marginal effects plot visualizes results from
blocked server (p=0.072). We do not observe even such a
our difference-in-differences analysis of account activity by
small change in toxicity among posts from accounts on the
week. We observe a discontinuous activity decrease among
blocking server.
accounts ontheblockedserverthatexceedsanydecreasein
the matched controls, but no corresponding change among
DiD Analysis. Again, the results of the DiD analysis for
accountsontheblockingserver.Thebandsare95%credible
toxicitytellasimilarstorytothedatavisualizationandnon-
intervalsthataccountforuncertaintyinparameterestimates.
parametric tests. Our models estimate that toxicity levels of
posts from affected accounts on both blocked and blocking
servers do not change following defederation events. Full
Effects on Anti-Social Behavior regression results are in Table 5. We find no evidence for
any significant changes in post toxicity among accounts on
Wenowpresentresultsforoursecondresearchquestion either blocked or blocking servers.
ontheeffectsofdefederationonthetoxicityofpostsbyuser
accounts on the blocked and blocking servers. Our three Discussion
analyses: visualization of the time-series of affected ac-
counts compared to matched controls, non-parametric tests, We investigated defederation, a group-level sanction
and difference-in-differences analysis are in agreement that whereadministratorsoftheblockingserverdisconnectcom-
defederationdidnotresultinastatisticallydetectablechange munication channels between users of their server and the
in toxicity for affected accounts on either server. blocked server. Although one of few actions by which lead-
The median toxicity plotted in Figure 8 remained at ers in such networks can protect their community’s servers
consistent levels for accounts which posted on a given from trolls, harassers, and objectionable content from other
week for both treatment and matched control groups on servers, defederation’s consequences are poorly understood.
both the blocked and blocking servers. The trends remained Therefore, in a quasi-experimental study, we estimate the
similar before defederation between the treatment and con- effects of defederation on the activity and toxicity of users
trol groups for accounts on both the blocked and blocking on both the blocking and blocked servers who had sent
servers. or received messages across server boundaries. Our results
)gol(
tnuoc
tsoP
yticixot
naideMBlocked Blocking
Term Estimate Stderror 2.5% 97.5% Estimate Stderror 2.5% 97.5%
β0 (Intercept) 3.216 0.086 3.049 3.380 2.901 0.118 2.684 3.121
β1 Group -0.024 0.116 -0.255 0.198 0.023 0.177 -0.290 0.367
β2 Treatment -0.089 0.045 -0.178 0.002 -0.080 0.060 -0.201 0.034
β3 Time 0.006 0.004 -0.002 0.015 -0.002 0.006 -0.014 0.009
β4 Treatment:Time -0.026 0.006 -0.038 -0.014 -0.027 0.008 -0.042 -0.010
β5 Group:Treatment -0.241 0.065 -0.367 -0.116 -0.084 0.082 -0.247 0.072
β6 Group:Time -0.007 0.006 -0.020 0.004 0.006 0.008 -0.010 0.021
β7 Group:Treatment:Time -0.015 0.009 -0.031 0.002 0.009 0.011 -0.013 0.032
TABLE3:Difference-in-differencesanalysisofactivitylevelforuseraccountswhoseserverwasdefederated(blockedgroup)
or whose server defederated another (blocking group). The 95% credible interval negative coefficient for membership in the
blocked group post-defederation (β ) is less than 0, indicating that activity by accounts in this group decreased more than
5
accounts in the matched control group. We do not draw such a conclusion about members of the blocking server because
the corresponding credible interval contains 0.
Group median W p to undesirable behavior on other servers without negative
impacts on activity by affected user accounts on their own
U0 -0.006 17746 0.538
C0 0.004 14000 0.950 server.
U1 -0.008 6514 0.619
Although sanctions are typically intended to promote
C1 0.001 5546 0.873
normative compliance, group-level sanctions in some prior
∆0 -0.005 17161 0.072
∆1 0.000 6414 0.305 empirical studies have been met with increases in anti-
socialbehaviororrebelliousnon-compliance(Mitts,Pishar-
TABLE4:Non-parametricdifference-in-differencesforme-
ody, and Shapiro, 2022; Ribeiro et al., 2021; Russo et al.,
dianposttoxicitybeforeandafterde-federationevents.The
2023). Therefore, we investigated defederation’s effects on
W test statistic represents the sum of the ranks of the
toxicity in research question 2. If defederation causes an
positivedifferencesbetweenpairedobservationswhilethep-
increaseinanti-socialbehavior,wewouldexpectanincrease
valuecomparestothealternativehypothesisthatthechanges
in toxicity on the blocked server. If defederation causes
are zero.
non-compliance, we would expect toxicity on the blocking
server to increase. However, we do not find evidence of
either of these adverse indirect outcomes. In this sense,
providethefirstevidenceconcerningtheimpactsofdefeder- defederation appears similar to individual and collective
ation in Fediverse communication networks. This evidence sanctionsanalyzedinpriorstudiessuchasaccountbanning,
can inform governance decisions among Fediverse server quarantine, and sub-community removal (Chandrasekharan
administrators and moderators and the design of future etal.,2022,2017;Jhaveretal.,2021).Someofthesegroup-
decentralized social media networks. levelsanctionshaveevenimprovedcompliancewithwidely-
Research question 1a asked how defederation changed held norms (Chandrasekharan et al., 2017). If defederation
posting activity by affected users on the blocked server. also does so then we would expect affected users on the
We find that losing communication channels to users on blocked server to become less toxic. Yet we observe no
the blocking server causes users on the blocked server who such effect.
hadusedsuchchannelstodecreasetheiractivity.Thishelps Among the various kinds of content moderation and
us understand defederation’s potential as an intervention governance interventions available to social media systems
against undesirable behavior. Not only does it protect the administrators, server defederation may be among the more
blocking server’s users from the blocked server, it may de- extreme group sanctions. However, our analysis suggests
creasetheblockedserver’svalue.Defederationmaycausea that it may also provide administrators with an effective re-
userontheblockedservertolosevaluedaudiences,sources sponse to undesirable behavior that does not undermine the
of content, or interpersonal connections and therefore to activityofaffecteduseraccountsontheserverimplementing
become less active. the block. User accounts affected by defederation events
If this positive effect of defederation results from lost cancontinuetocommunicatewithothersontheirrespective
connections,defederationmightalsohaveanegativeconse- serversaswellasotherserverswherefederatedinteractions
quence: Users of the blocking server may decrease their remain permitted. The disconnection from the network is
activity for the same reason. However, our results for nottotalandcanrespectthelocalnormsthatoperateamong
research question 1b, which inquired into defederation’s distinct sub-components of the larger network. We believe
consequences on posting activity by affected users on the this is a design feature of federated systems that distin-
blockingserver,shownomeasurableeffect.Theseasymmet- guishes them from other kinds of content moderation and
ric effects of defederation on posting activity suggest that governance systems in social media environments. Other,
administrators may find defederation an effective response more centralized, platforms may wish to experiment withBlocked Blocking
Group Term Estimate Stderror 2.5% 97.5% Estimate Stderror 2.5% 97.5%
Treatment β0 (Intercept) -0.143 0.438 -1.197 0.763 -0.042 0.284 -0.754 0.518
β1 Treatment 0.002 0.006 -0.009 0.018 -0.001 0.010 -0.020 0.017
β2 Time 0.001 0.001 0.000 0.002 0.001 0.001 -0.001 0.003
β3 Treatment:Time -0.002 0.001 -0.004 0.000 -0.001 0.002 -0.004 0.003
Control β4 (Intercept) 0.136 0.436 -0.907 1.044 0.048 0.283 -0.613 0.649
β5 Treatment 0.000 0.006 -0.016 0.011 0.004 0.009 -0.014 0.024
β6 Time 0.001 0.001 0.000 0.002 0.003 0.001 0.001 0.005
β7 Treatment:Time -0.005 0.001 -0.007 -0.003 -0.006 0.002 -0.009 -0.002
TABLE 5: Beta regression coefficients drawn from the posterior of the parametric toxicity DiD model for user accounts
whose server was defederated (blocked group) or whose server defederated another (blocking group). For all groups, the
95% credible intervals for a change in toxicity levels after treatment (β , β ) contain 0.
1 5
similar features as doing so may advance user trust and would happen on both sides of a defederation event. In
safety without undermining activity. addition,defederationmightaffectformsofbehaviorbeyond
That said, further research is needed to support recom- toxicity that future research may investigate such as topics
mendations about defederation’s overall benefits and lim- of post or the extent to which they elicit replies or boosts
itations in decentralized social media systems. Such re- (analogous to retweets).
search should uncover the mechanisms that drive the ob- In terms of the analysis, our study incorporated several
served changes in activity levels and toxic behaviors, such critical assumptions and focused on the effects of defedera-
as changes in user motivations or migration to alternative tion events within a relatively narrow timeframe. Matching
servers or communication channels. Future work should entails an assumption that selection into treatment or con-
also investigate how defederation events are perceived and trol occurred due to observable variables incorporated into
experienced by the people operating affected accounts on the matching process. A quasi-experimental difference-in-
bothblockedandblockingservers.Inaddition,insightsinto differences analysis similarly assumes parallel trends and
the reasons behind administrator decisions to implement comparability across units conditional only on “as-if” ran-
defederation blocks as well as the timing of such changes dom exposure to the treatment in question. For example,
wouldenrichthefindingsreportedhere.Asnotedabove,the possible advanced announcements of defederation events
defederation events in our study did not occur at random may drive changes in user behavior prior to defederation it-
and were likely undertaken with some awareness of the self.Whilewetriedtosupportsuchassumptionsempirically,
various actors involved. For these reasons, we encourage they may not hold uniformly, and in addition, the effects of
caution around the generalizability of our findings beyond defederation on user behavior might change over time as
the specific context of our study. users adapt to new norms and technologies. Additional and
Additional limitations of the study relate to the con- longer duration analyses could address these concerns and
straintsaroundourdatacollection,measurement,andanaly- shed light on the long-term consequences of defederation
sisstrategies.First,ourdatacollectionwaslimitedtopublic events.
status posts, which do not fully capture user interactions
within the Fediverse. Private posts and direct messages, Conclusion
which are not accessible through the APIs we used, might
exhibit different patterns in response to defederation events. In this study, we investigated the effects of defederation
Inaddition,someserverschoosenottopublishdefederation events on the activity levels and toxic posting behavior of
information. If the effects of defederation emerge anywhere accounts in the Fediverse. The results indicate that such
otherthanpublicposts,ouranalysiscouldnotcapturethem. events produce asymmetric effects on activity for affected
Our analysis also relied on the Perspective API to ana- accountsonblockedserversversusthoseonblockingservers
lyzethecontentofpostsbyquantifyingtheirtoxicity.While with no increase in toxicity for any groups. The results also
this tool provides a useful proxy, its accuracy may vary highlight the potential of decentralized social networks and
across languages and contexts and its errors may affect theiruniquemechanisms,suchasdefederation,inproviding
our statistical results (TeBlunthuis, Hase, and Chan, 2023). communities with tools to manage content moderation and
Moreover, it is conceivable that the contexts for which Per- other aspects of online interactions. Future research could
spectivedesigneddepartfromtheFediversesosubstantially explore the causes or reasons behind defederation events,
thatPerspectivefailstodetectformsofmisbehavioraffected the long-term consequences of defederation, as well as the
by defederation. Future research could explore alternative mechanisms by which defederation produces (asymmetric)
methodsforassessingcontentqualityandtoxicity.Although effects. By continuing to study the Fediverse and its affor-
language models like those utilized in the Perspective API dances, we can better understand how to foster healthy on-
have significant limitations, we believe that these are likely linecommunitiesandeffectivecontentmoderationstrategies
to be time invariant, at least in the short-run. That is, they in a decentralized environment.Acknowledgements Han,C.;Kumar,D.;andDurumeric,Z.2022. OntheInfras-
tructureProvidersThatSupportMisinformationWebsites.
The authors would like to thank Ceren Budak and the ProceedingsoftheInternationalAAAIConferenceonWeb
Community Data Science Collective. Support for this work and Social Media, 16: 287–298.
wasprovidedbytheU.S.NationalScienceFoundation(IIS- Heckathorn, D. D. 1988. Collective Sanctions and the Cre-
191020, IIS-1908850). Additionally, Dr. TeBlunthuis was ation of Prisoner’s Dilemma Norms. American Journal
partially supported by NSF grant IIS-1815875. of Sociology, 94(3): 535–562.
Hill, B. M.; and Shaw, A. 2021. The Hidden Costs of
References Requiring Accounts: Quasi-experimental Evidence from
Peer Production. Communication Research, 48(6): 771–
Albert, R.; Jeong, H.; and Baraba´si, A.-L. 2000. Error 795.
and Attack Tolerance of Complex Networks. Nature, Iacus,S.M.;King,G.;andPorro,G.2012. CausalInference
406(6794): 378–382. without Balance Checking: Coarsened Exact Matching.
Ali,S.;Saeed,M.H.;Aldreabi,E.;Blackburn,J.;DeCristo- Political Analysis, 20(1): 1–24.
faro, E.; Zannettou, S.; and Stringhini, G. 2021. Under- Jhaver, S.; Boylston, C.; Yang, D.; and Bruckman, A. 2021.
standingtheEffectofDeplatformingonSocialNetworks. Evaluating the Effectiveness of Deplatforming as a Mod-
InProceedingsofthe13thACMWebScienceConference eration Strategy on Twitter. Proceedings of the ACM on
2021, WebSci ’21, 187–195. New York, NY, USA: As- Human-ComputerInteraction,5(CSCW2):381:1–381:30.
sociation for Computing Machinery. ISBN 978-1-4503- Jigsaw. 2021. Perspective API.
8330-1. https://www.perspectiveapi.com/.
Buntain, C.; Innes, M.; Mitts, T.; and Shapiro, J. 2023. Kaye,D.2019. SpeechPolice:TheGlobalStruggletoGov-
Cross-Platform Reactions to the Post-January 6 Deplat- ern the Internet. New York: Columbia Global Reports.
forming. Journal of Quantitative Description: Digital ISBN 978-0-9997454-8-9.
Media, 3. King,G.;Pan,J.;andRoberts,M.E.2013. HowCensorship
Chandrasekharan,E.;Jhaver,S.;Bruckman,A.;andGilbert, in China Allows Government Criticism but Silences Col-
E. 2022. Quarantined! Examining the Effects of lective Expression. American Political Science Review,
a Community-Wide Moderation Intervention on Red- 107(2).
dit. ACM Transactions on Computer-Human Interaction, Mitts, T.; Pisharody, N.; and Shapiro, J. 2022. Removal of
29(4): 29:1–29:26. Anti-Vaccine Content Impacts Social Media Discourse.
Chandrasekharan, E.; Pavalanathan, U.; Srinivasan, A.; In 14th ACM Web Science Conference 2022, 319–326.
Glynn,A.;Eisenstein,J.;andGilbert,E.2017. YouCan’t Barcelona Spain: ACM. ISBN 978-1-4503-9191-7.
Stay Here: The Efficacy of Reddit’s 2015 Ban Examined MyersWest,S.2018.Censored,Suspended,Shadowbanned:
through Hate Speech. Proc. ACM Hum.-Comput. Inter- User Interpretations of Content Moderation on Social
act., 1(CSCW): 31:1–31:22. Media Platforms. New Media & Society, 20(11): 4366–
Datta, A.; Buchegger, S.; Vu, L.-H.; Strufe, T.; and Rzadca, 4383.
K. 2010. Decentralized Online Social Networks. In Ribeiro,M.H.;Hosseinmardi,H.;West,R.;andWatts,D.J.
Furht, B., ed., Handbook of Social Network Technologies 2023. Deplatforming Did Not Decrease Parler Users’
andApplications,349–378.NewYork,NY:SpringerUS. Activity on Fringe Social Media. PNAS Nexus, 2(3):
ISBN 978-1-4419-7142-5. pgad035.
Frey, S.; and Schneider, N. 2021. Effective Voice: Beyond Ribeiro, M. H.; Jhaver, S.; Zannettou, S.; Blackburn, J.;
Exit and Affect in Online Communities. New Media & Stringhini, G.; De Cristofaro, E.; and West, R. 2021. Do
Society, 14614448211044025. Platform Migrations Compromise Content Moderation?
Frey, S.; and Sumner, R. W. 2019. Emergence of Integrated Evidencefromr/The donaldandr/Incels. Proceedingsof
InstitutionsinaLargePopulationofSelf-GoverningCom- the ACM on Human-Computer Interaction, 5(CSCW2):
munities. PLOS ONE, 14(7): e0216335. 316:1–316:24.
Fulk, J.; Flanagin, A. J.; Kalman, M. E.; Monge, P. R.; and Russo, G.; Verginer, L.; Ribeiro, M. H.; and Casiraghi,
Ryan, T. 1996. Connective and Communal Public Goods G. 2023. Spillover of Antisocial Behavior from Fringe
in Interactive Communication Systems. Communication Platforms: The Unintended Consequences of Community
Theory, 6(1): 60–87. Banning. Proceedings of the International AAAI Confer-
Gillespie, T. 2018. Custodians of the Internet: Platforms, ence on Web and Social Media, 17: 742–753.
Content Moderation, and the Hidden Decisions That Seering, J.; Kraut, R.; and Dabbish, L. 2017. Shaping Pro
Shape Social Media. New Haven: Yale University Press. andAnti-SocialBehavioronTwitchThroughModeration
ISBN 978-0-300-17313-0. and Example-Setting. In Proceedings of the 2017 ACM
Gruzd,A.;Soares,F.B.;andMai,P.2023. TrustandSafety Conference on Computer Supported Cooperative Work
onSocialMedia:UnderstandingtheImpactofAnti-Social and Social Computing, CSCW ’17, 111–125. New York,
BehaviorandMisinformationonContentModerationand NY, USA: ACM. ISBN 978-1-4503-4335-0.
Platform Governance. Social Media + Society, 9(3): Srinivasan, K. B.; Danescu-Niculescu-Mizil, C.; Lee, L.;
20563051231196878. and Tan, C. 2019. Content Removal as a ModerationStrategy:ComplianceandOtherOutcomesintheChange-
myviewCommunity. ProceedingsoftheACMonHuman-
Computer Interaction, 3(CSCW): 163:1–163:21.
Stocking, G.; Mitchell, A.; Matsa, K. E.; Widjaya, R.; Ju-
rkowitz,M.;Ghosh,S.;Smith,A.;Naseer,S.;andAubin,
C. S. 2022. The Role of Alternative Social Media in the
News and Information Environment. Technical report,
Pew Research Center, Washington D.C.
TeBlunthuis, N.; Hase, V.; and Chan, C.-H. 2023. Misclas-
sification in Automated Content Analysis Causes Bias in
Regression.CanWeFixIt?YesWeCan! Communication
Methods and Measures, 18(1).
Tran, C.; Champion, K.; Hill, B. M.; and Greenstadt, R.
2022. The Risks, Benefits, and Consequences of Prepub-
lication Moderation: Evidence from 17 Wikipedia Lan-
guage Editions. Proceedings of the ACM on Human-
Computer Interaction, 6: 1–25.
Van Hove, L. 2016. Testing Metcalfe’s Law: Pitfalls and
Possibilities. Information Economics and Policy, 37: 67–
76.
Vu, A. V.; Hutchings, A.; and Anderson, R. 2023. No
Easy Way Out: The Effectiveness of Deplatforming an
Extremist Forum to Suppress Hate and Harassment.
arxiv:2304.07037.
Zhang, X. M.; and Zhu, F. 2011. Group Size and Incen-
tives to Contribute: A Natural Experiment at Chinese
Wikipedia. American Economic Review, 101(4): 1601–
1615.