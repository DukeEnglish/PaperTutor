REMATCH: Robust and Efficient Matching of Local Knowledge Graphs
to Improve Structural and Semantic Similarity
ZoherKachwala, JisunAn, HaewoonKwak, FilippoMenczer
ObservatoryonSocialMedia
IndianaUniversity
zkachwal@iu.edu, {jisun.an, haewoon}@acm.org
Abstract
Knowledgegraphsplayapivotalroleinvari-
ousapplications, suchasquestion-answering
and fact-checking. Abstract Meaning Repre-
sentation(AMR)representstextasknowledge
graphs. Evaluatingthequalityofthesegraphs
Figure1: AMRforthesentence: “Hedidnotcutthe
involves matching them structurally to each
applewithaknife.” ColorsindicateAMRcomponents:
otherandsemanticallytothesourcetext. Ex-
instances(blue),relations(red),constants(teal),andat-
istingAMRmetricsareinefficientandstruggle
tributes(orange). Theinstancecut-01isaverbframe
to capture semantic similarity. We also lack
thatusesARG0,ARG1andinsttoexpresstheverb’s
asystematicevaluationbenchmarkforassess-
agent(he),patient(apple),andinstrument(knife),
ingstructuralsimilaritybetweenAMRgraphs.
respectively. The attribute polarity expresses the
Toovercometheselimitations,weintroducea
negationoftheverbthroughtheconstant-.
novelAMRsimilaritymetric,rematch,along-
sideanewevaluationforstructuralsimilarity
calledRARE.Amongstate-of-the-artmetrics,
therelationshipsbetweenconceptsandtheirroles
rematchrankssecondinstructuralsimilarity;
andfirstinsemanticsimilarityby1–5percent- in a sentence. They have been applied to a vari-
age points on the STS-B and SICK-R bench- ety of natural language processing tasks, includ-
marks. Rematchisalsofivetimesfasterthan ing summarization and question answering (Liu
thenextmostefficientmetric.1
etal.,2015;HardyandVlachos,2018;Bonialetal.,
2020;MitraandBaral,2016). Recentworkhasalso
1 Introduction
shown that AMRs can reduce hallucinations and
Knowledgegraphsprovideapowerfulframework improveperformanceinfactualsummarizationand
formulti-hopreasoningtasks,suchasquestionan- textclassificationtasks(Ribeiroetal.,2022;Shou
sweringandfact-checking(Yasunagaetal.,2021; etal.,2022).
VedulaandParthasarathy,2021). Evenforclosed- However, evaluating the quality of knowledge
domain tasks like long-form question answering graphslikeAMRshingescriticallyontheability
and multi-document summarization, knowledge toaccuratelymeasuresimilarity. Thisassessment
graphs derived from individual documents — re- mustconsideradualperspective. Firstly,thesimi-
ferredtoaslocalknowledgegraphs—exhibitsupe- laritybetweentwoAMRsshouldreflectstructural
riorperformancecomparedtoplaintext(Fanetal., consistency, guaranteeing that the similarity be-
2019). Thishighlightsthesignificanceofautomati- tweentwoAMRsalignswiththesimilarityoftheir
callyparsedknowledgegraphsinbothlarge-scale structuralconnections. Secondly,AMRsshouldex-
andfine-grainedstructuredreasoningapplications. hibitsemanticconsistency,ensuringthatthesimi-
The Abstract Meaning Representation (AMR) laritybetweentwoAMRsalignswiththesimilarity
framework leverages acyclic, directed, labeled ofthetextsfromwhichtheyarederived. Therefore,
graphstorepresentsemanticmeaning(knowledge) aneffectiveAMRsimilaritymetricmustsuccess-
extracted from text (Banarescu et al., 2013). As fullyaccountforbothstructuralandsemanticsimi-
illustratedintheexampleofFig.1,AMRscapture larity,allwhileovercomingtheresource-intensive
natureofmatchinglabeledgraphs.
1OurcodeforrematchandRAREispubliclyavailableat:
https://github.com/osome-iu/Rematch-RARE CurrentAMRsimilaritymetricsfallshortinsev-
4202
rpA
2
]LC.sc[
1v62120.4042:viXraeral key areas. Firstly, their computational effi- 3. Relations represent the connections between
ciencyhindersthecomparisonoflargeAMRsex- instances. In Fig. 1, the instance cut-01 has
tractedfromdocuments(Naseemetal.,2022). Sec- threeoutgoingrelations: ARG0,ARG1,andinst.
ondly,thesemetricsstruggletoaccuratelycapture ThesecomefromPropBank’scut-01frameand
thesemanticsimilarityoftheunderlyingtextfrom link to the agent (he), the patient (apple), and
which AMRs are derived (Leung et al., 2022a). theinstrument(knife),respectively.
Additionally,whilerecenteffortslikeBAMBOO
(Opitzetal.,2021)haveevaluatedmetricsonAMR 2.2 AMRSimilarity
transformations,westilllackalarge-scalebench- Graphisomorphismisatesttodeterminewhether
marktosystematicallyevaluatetheabilityofAMR twographsarestructurallyequivalent. Theclass-
metricstocapturestructuralsimilarity. wiseisomorphismtestingwithlimitedbacktrack-
Our work introduces a structural AMR bench- ing(CISC)algorithmefficientlyidentifiesisomor-
mark called Randomized AMRs with Rewired phic relationships in labeled graphs (Hsieh et al.,
Edges(RARE)andproposesrematch,anoveland 2006), such as AMRs. But a pair of AMRs may
efficientAMRsimilaritymetricthatcapturesboth not have the same number of nodes, which vio-
structural and semantic similarity. Compared to lates a key assumption of graph isomorphism. A
the state of the art, rematch trails the best simi- more appropriate approach is subgraph isomor-
laritymetriconRAREby1percentagepointand phism,whichdetermineswhetherasmallergraph
ranksfirstontheSTS-B(Agirreetal.,2016)and isisomorphictoasubgraphofalargergraph. Sub-
SICK-R(Marellietal.,2014)benchmarksby1–5 graphsofdirectedacyclicgraphs,likeAMRs,can
percentage points. Additionally, rematch is five be enumerated in polynomial time (Peng et al.,
timesfasterthanthenextmostefficientmetric. 2018), enablingefficientapplicationoftheCISC
testtoeachpairofsmallerAMRandlargerAMR
2 Background
subgraphs. However, even if two AMRs are not
2.1 AbstractMeaningRepresentations subgraph-isomorphic,theymaystillexhibitsimi-
laritiesinmeaningandstructure. Next,wedescribe
AbstractMeaningRepresentation(AMR)isastruc-
variousexistingapproachestomeasurethesimilar-
tural,explicitlanguagemodelthatutilizesdirected,
itybetweenAMRgraphs.
labeledgraphstocapturethesemanticsoftext(Ba-
narescuetal.,2013). AMRisdesignedtobeinde-
2.3 AMRSimilarityMetrics
pendentofsurfacesyntax,ensuringthatsentences
2.3.1 Smatch
with equivalent meanings are represented by the
samegraph. AnAMRcomprisesthreefundamen- Smatch is a prominent tool for evaluating AMR
talcomponents: instances,attributes,andrelations. parsers(CaiandKnight,2013). ItestablishesAMR
alignment by generating a one-to-one node map-
1. Instancesarethecoresemanticconcepts. Struc- ping, considering node and edge labels. To effi-
turally,theyarerepresentedbynodesinthegraph. ciently explore this vast mapping space, smatch
AMRs have two types of instances. One utilizes employsahill-climbingheuristic.
PropBank (Palmer et al., 2005), a dictionary of
2.3.2 S2match
frames that map verbs and adjectives. The other
comprises entities. Considering the sentence in Similar to smatch, s2match (Opitz et al., 2020)
Fig.1,“Hedidnotcuttheapplewithaknife,”the also establishes a node alignment between two
AMRcontainsaPropBankinstancecut-01and AMRs. However, instead of relying on AMR la-
threeentityinstances: he,appleandknife. bels, s2match utilizes GloVe word embeddings
(Pennington et al., 2014). To address the exten-
2. Attributescapturedetailsaboutinstances,such sive search space, it uses the same hill-climbing
as names, numbers, and dates. These values are heuristicadoptedbysmatch.
representedasconstantnodes. Structurally,anat-
tributeisidentifiedinthegraphastheedgefrom 2.3.3 Sembleu
aninstancenodetoaconstantnode. Forexample, Sembleugeneratespath-basedn-gramsfromAMRs
inFig.1,theattributepolarity isspecifiedfor by leveraging node and edge labels (Song and
theinstancecut-01,where-istheconstantthat Gildea, 2019). The final similarity score for an
representsthenegationoftheverb. AMRpairisdeterminedbycalculatingtheBLEUFigure2:Anexampleofrematch’ssimilaritycalculationforapairofAMRs.AfterAMRsareparsedfromsentences,
rematchhasatwo-stepprocesstocalculatesimilarity. First,setsofmotifsaregenerated. Second,thetwosetsare
usedtocalculatetheJaccardsimilarity(intersectingmotifsshownincolor).
score(Papinenietal.,2002)betweentheirn-grams. thesenodegroupscanbelarge.
Byavoidingaone-to-onenodealignment,Sembleu Graphfeaturesconstructedusinganorderedcon-
efficientlybypassestheissueofexploringalarge catenation of edge-node bi-grams are utilized in
searchspace. both isomorphism tests like the CISC and ker-
nels like Weisfeiler-Leman (Shervashidze et al.,
2.3.4 WLK
2011). This approach is effective: it consistently
TheWeisfeiler-LemanKernel(WLK)andWasser- producessmallernodegroupscomparedtothose
steinWeisfeiler-LemanKernel(WWLK)forAMRs based solely on node labels. Matching between
also utilize graph features for computing similar- twographsissignificantlyacceleratedasaresult.
ity(Opitzetal.,2021). WLK firstconstructsnode Inspired by this idea of exploiting graph fea-
featuresbyrecursivelyaggregatingAMRnodeand turesforefficiency,rematchcomputesthesimilar-
edgelabels. Thenitgeneratesafrequency-based ity between two AMRs by analyzing the overlap
featurevectorforeachAMRandcalculatesasimi- ofsemanticallyrichfeatures,whichwecallmotifs.
larityscore usingtheirinnerproduct. WWLK ex- UnliketheorderedgraphpartitionsusedbyCISC
tendsWLK withfeaturesbasedonaggregatednode andWeisfeiler-LemanKernel,whichrelyonnode
embeddings(GloVE)insteadofnodelabels. Since andedgelabels,AMRmotifsareunorderedgraph
WWLKisasupervisedmetric,wedonotconsider partitionsthatleverageAMRinstances,attributes,
itinourevaluation. andrelations. Thisapproachallowsrematchtocap-
turemeaningacrossthreesemanticlevels: specific
3 Methods facts (attributes), main concepts (instances), and
therelationshipsamongconcepts(relations). Fig.2
Inthiswork,weproposerematch,anAMRsimilar-
illustratesrematchthroughanexample. Next,we
itymetricthataimstocaptureboththestructural
delveintothethreeordersofsemanticmotifsthat
andsemanticoverlapbetweentwoAMRs.
weuseforrematch. Weextractthesemotifsusing
Astraightforwardapproachtomatchtwolabeled
thePythonpackagePenman(Goodman,2020).
graphsinvolvesidentifyingthealignmentbetween
node labels. However, labeled graphs often con- 1. Attributemotifsarepairsofattributesandcon-
tain duplicate labels, necessitating an exhaustive stants associated with AMR instance nodes. For
explorationofallone-to-onecombinationsamong thebottomAMRinFig.2,talk-01hasattribute
nodeswithinthesamelabelgrouptodeterminethe motif(polarity -),indicatinganegation. The
optimal match. The resulting matching complex- firstnamehastheattributemotif(op1"Helen")
ityhingesonthesizeofnodegroupswithshared andthesecondnamehas(op1"Maya"),identi-
labels. This is why algorithms like smatch and fyingthenamevalues. Theremaininginstancesdo
s2match do not scale well to large AMRs, where nothaveanyattributes.2. InstancemotifsleverageVerbatlas,aresource similarity, and BAMBOO (Opitz et al., 2021), a
that maps PropBank frames to more generalized hybrid benchmark that modifies AMR semantics
frames (Di Fabio et al., 2019). If an instance in through structural transformations. Additionally,
the AMR corresponds to a Verbatlas frame, the weassesstheefficiencyofrematch.
latterisusedinstead. Otherwise,theoriginalProp-
Bank instanceisretained. Forexample,inFig.2, 4.1 StructuralSimilarity(RARE)
talk-01isreplacedbythemoregeneralizedVer- GiventhatAMRsaregraphicalrepresentationsof
batlas frame speak. The generation of instance text,anAMRsimilaritymetricshouldbesensitive
motifsfollowstwoapproaches. Ifaninstancelacks tostructuralvariationsbetweenAMRs,evenifits
associatedattributes,theinstanceitselfservesasits labelsremainunchanged.
motif. However,ifattributesarepresent,instance SincethereisnoestablishedevaluationofAMR
motifsareconstructedbycombiningtheinstance metricsonstructuralsimilarity,wehavedeveloped
with each of its attribute motifs. For the bottom anewbenchmarkdatasetcalledRandomizedAMRs
AMR in Fig. 2, the instance motif for talk-01 withRewiredEdges(RARE).RAREconsistsofEn-
is (speak (polarity -)), indicating a nega- glishAMRpairswithsimilarityscoresthatreflect
tion of the verb. For the two person instances thestructuraldifferencesbetweenthem.
and the politics instance, the instances them- In the construction of RARE, we adopt an it-
selvesbecometheirmotifs,namely(person)and
erative randomization technique commonly used
(politics). Finally,theinstancemotifsforthe for graph rewiring. This involves repeatedly se-
twonameinstancesare(name(op1"Helen"))
lectingarandompairofdirectededgesandswap-
and(name(op1"Maya"))respectively,identify-
pingeithertheirsourceortargetnodestoestablish
ingthenamesintheconversation. newconnections. Thiswayeachnode’sin-degree
andout-degreearepreserved. Inapplyingthisap-
3. Relation motifs are constructed for relation
proachtoAMRs,weswaparandompairofedges
edges in an AMR graph. Each relation motif
betweeneitherattributesorrelations. Thisallows
comprises three elements: an instance motif of
us to quantify the structural changes made to the
the source instance, the relation label, and an in-
AMRthroughthenumberofswappededges.
stance motif of the target instance. A relation
RARE does not add or remove edges as these
can have multiple relation motifs, one for each
modifications would amount to adding or remov-
uniquecombinationofsourceandtargetinstance
inginformation. Systematicedgeinsertionordele-
motifs. For the bottom AMR in Fig. 2, the re-
lation motifs for ARG0, ARG1 and ARG2 are: tionwouldalsointroduceadditionalcomplications,
((speak (polarity -)) ARG0 person), indi- suchashavingtodecidethesetofedgesthatcould
be added or removed while keeping the network
catingapersonisthespeakeroftheconversation;
((speak(polarity -))ARG1politics),in- connected. Byswappingedgesalone,weguaran-
teethattheAMRsbeingcomparedhavethesame
dicating that the topic of conversation is politics;
and ((speak (polarity -)) ARG2 person), informationintermsofsize,density,andconnec-
tivity.
indicatingthatapersonistherecipientofthecon-
versation. Forthetwonamerelations,themotifs Wegenerateaspectrumofmodifiedgraphsfrom
are: ((person) name (op1 "Helen"))), iden- an original AMR, ranging from the unchanged
graphtoonewherealledgesarerewired,subject
tifying "Helen" as the name of one person; and
((person) name (op1 "Maya")), identifying to some constraints that preserve the integrity of
AMRs:
"Maya"asthenameoftheotherperson.
EachAMRisrepresentedbytheunionofitsin-
1. Structural Constraints. AMRs are acyclic,
stance,relation,andattributemotifs. Therematch
connectedgraphsthatallownomultiedges(more
scorebetweentwoAMRsisdeterminedbycalculat-
than one edge between the same pair of nodes).
ingtheJaccardsimilaritybetweentheirrespective
To preserve these properties during the rewiring
motifsets,asillustratedinFig.2.
process, pairs of swapped edges must maintain
theseconstraintsinthemodifiedAMR.
4 Evaluation
Weevaluatetheeffectivenessofrematchonthree 2. SemanticConstraints. Theseconstraintsrelate
typesofsimilarity: structuralsimilarity,semantic toswappingattributesandrelations:(a) Attributes have an inherent connection with 4.2 SemanticSimilarity
constants in AMRs. Hence, while rewiring
AfundamentaltenetofAMRsisthatiftwopieces
a pair of attribute edges, only the source in-
oftextaresemanticallyrelated, theircorrespond-
stancenodeshouldbeswapped. Thisrestric-
ing AMRs should exhibit a degree of similarity.
tionensuresthattheassociationbetweenthe
ButametriccoulddeemtwoAMRssimilareven
attribute and its corresponding constant re-
whentheirtextualsourceshaveverydifferentmean-
mainsintact. Forexample,theconstantnode
ings. As an example, for two completely unre-
-shouldremainassociatedsolelywiththeat-
latedsentences“Spanishbullsgoreseventodeath”
tributeedgepolarity.
and“ObamaqueriesTurnbulloverChinaportdeal,”
(b) Relations in AMRs connect two instances. smatchassignsanon-zeroscoreduetothesimilar-
Whenrewiringapairofrelationedges,only ityintheirargumentstructure(Leungetal.,2022b).
the target instance node should be swapped. Toteaseoutsuchshortcomings,weevaluateeach
Thisrestrictionmaintainstheassociationbe- AMRsimilaritymetricbyconsideringmanypairs
tweentherelation’ssourceinstanceandthere- ofsentences. Foreachpair,wecomparethesimi-
lationitself. Forexample,PropBankinstances laritygeneratedbythemetricforthecorresponding
haveapredefinedsetofrelationswithwhich AMRstoaground-truthsimilarityscorebetween
they can be associated. The instance node thesentencesgeneratedbyhumanannotations.
talk-01canonlybeassociatedwithedges
We utilize two standard sentence similarity
ARG0,ARG1,andARG2.
benchmarks for English: STS-B (Agirre et al.,
2016) and SICK-R (Marelli et al., 2014). To ac-
Each pair of AMRs, consisting of an origi- count for variations in AMR parsing accuracy,
nal AMR G with E edges and its corresponding we employ four different AMR parsers: spring
rewiredAMRG′ withE′ swappededges,isanno- (Bevilacquaetal.,2021),amrbart(Baietal.,2022),
tatedwiththefollowingsimilarityscore: structbart(Drozdovetal.,2022),andthemaximum
Bayessmatchensemble(Leeetal.,2022).
|E|−|E′| Given a set of sentence pairs and correspond-
similarity(G,G′) = (1)
|E| ingAMRpairs,weevaluateasimilaritymetricby
computing the Spearman correlation between its
scoresfortheAMRpairsandthehuman-annotated
TogeneratetheRAREbenchmark,welicensed
similarity values for the sentence pairs. We refer
theEnglishAMRAnnotation3.0(Knight,Kevin
to this as the semantic consistency of the metric.
et al., 2020) containing 59,255 human-created
Notethatsemanticconsistencycanbeusedtoeval-
AMRs. Usingtheprocessdescribedabove,weget
uateanysimilaritymethodforsentences,notonly
563,143rewiredAMRpairsannotatedwithsimi-
AMR-basedones. Forbothstructuralandsemantic
larity scores per Eq. 1. Since the original AMR
consistency,weuseSpearmanratherthanPearson
Annotation 3.0 corpus has an unusual training-
correlationbecausewedonotassumethatthesim-
development-testingsplit,wemerge,shuffle,and
ilarityvaluesarenormallydistributed.
re-split AMR3.0 into training (47,404), develop-
ment (5,925), and test (5,926) sets to get an 80-
4.3 HybridSimilarity(BAMBOO)
10-10splitratiothatismoreconsistentwithstan-
dard benchmarks. The resulting RARE training- In addition to the structural and semantic consis-
development-test sizes are 450,067, 56,358, and tencydiscussedearlier,weevaluatetherobustness
56,718,respectively. Thecreationoftrainingand of AMR metrics using the Benchmark for AMR
development splits could facilitate the future de- MetricsBasedonOvertObjectives,orBAMBOO
velopment of supervised AMR metrics. For the (Opitzetal.,2021). BAMBOOassessestheability
currentevaluation,AMRstructuralsimilaritymet- ofAMRsimilaritymetricstocapturesemanticsim-
ricsareevaluatedontheRAREtestsplit. ilaritybetweenEnglishsentenceswhilemodifying
We evaluate a similarity metric by computing thestructureofthecorrespondingAMRs.
the Spearman correlation between its scores and BAMBOO incorporates three types of graph
thegroundtruthvaluesfromEq.1,acrossasetof modifications: synonym replacement, reification,
pairsoforiginalandmodifiedAMRs. Wereferto androleconfusion. Considertheexamplesentence
thisasthestructuralconsistencyofthemetric. “He lives in the attic,” represented by an AMRwhere the node live-01 connects to nodes he AMRMetric RARE
andatticviatheedgesARG0andlocation,
smatch 96.57
respectively. Synonym replacement swaps Prop- s2match 94.11
Bankinstanceswithequivalentterms. Intheexam- sembleu 94.83
ple,live-01mightbereplacedbyreside-01.
WLK 90.39
Reification transforms a relation into a new in- rematch 95.32
stance. Intheexample,thelocationedgemight
bereplacedbyanewnodebe-located-at-91
Table1: StructuralconsistencyofdifferentAMRsimi-
connectedtolive-01andatticvianewARG1 laritymetricsontheRAREtestsplit.
and ARG2 edges, respectively. Finally, role con-
fusion swaps relation roles. In the example, the
5 Results
relationslocationandARG0mightbeswapped
suchthatthemodifiedAMRwouldrepresentthe
5.1 StructuralConsistency
sentence “The attic lives in him.” BAMBOO ap-
pliesthesemodificationstotheoriginaltrain,test Table1reportsonthestructuralconsistencyofthe
anddevsplitsoftheSTS-B,SICK-R,andPARA AMR similarity metrics on the RARE test split.
(DolanandBrockett,2005)datasets. Wecanseethatsmatchperformsthebest,followed
GivenasetofmodifiedAMRpairs,BAMBOO closelybyrematch,sembleuands2match. Thesub-
evaluatesanAMRmetricbytheSpearmancorrela- parperformanceofWLK canbeattributedtotheir
tion2 betweenitsscoresandthesimilaritybetween relianceonfeaturesusingallofanode’sneighbors.
thecorrespondingsentencepairs. Wecallthishy- Thisapproachresultsinchangestonodefeatures
bridconsistencyofthemetric. regardless of the number of modified neighbors,
failing to capture the nuances of neighborhood
4.4 Efficiency changes.
Asdiscussedearlier,thecomputationalcomplexity
5.2 SemanticConsistency
associated with node alignment is a crucial chal-
lengeforcomparingAMRs. Toaddressthisissue, Table2reportsonthesemanticconsistencyofthe
weevaluatethesearchspacesexploredbyvarious similaritymetricsfordifferentAMRparsers. Re-
metricsandtherequiredruntime. match outperforms all other metrics by 1–5 per-
WeestablisharealistictestbedusingtheAMR centagepoints,acrossallparsersandbenchmarks.
Annotation3.0onceagain. Forthisevaluation,we Thembseandamrbartparsersperformbestforthe
randomlysampled500,000pairsfromthe(cid:0)59,255(cid:1)
STS-BandSICK-Rdatasets,respectively.
2
possible AMR combinations. For each pair of So far we have focused on methods that use
AMRs(G 1,G 2),thesearchspacesfornodealign- AMRstocalculatethesemanticsimilaritybetween
mentalgorithmslikesmatchands2matchis sentences. Table3reportsontheevaluationofalter-
nativesimilaritymethodsonthesamebenchmarks.
(cid:89)
search(G 1,G 2) = |M G2(n i)| (2) LikeAMR-basedmethods,thesearealsounsuper-
ni∈G1 vised(nottrainedspecifically)fortextualsemantic
similarity. AMRoutperformssomerepresentations
where M (n ) denotes the set of matching can-
G2 i likeGloVeandRoBERTabutlagsbehindthestate-
didatesinG fornoden . Forfeature-basedalgo-
2 i of-the-artmethodSimCSE(Gaoetal.,2022).
rithms,likesembleu,WLK,andrematch,werecord
thesearchspaceusing
5.3 HybridConsistency
search(G ,G ) = |F(G )|·|F(G )| (3) Table4reportsonthehybridconsistencyofAMR
1 2 1 2
similarity metrics on the four different tests of
where F(G) denotes the feature set for graph G. BAMBOO, across three different datasets. The
ForeachpairofAMRs,wealsorecordtheruntime. results vary considerably across graph modifica-
tionsanddatasets;noneofthemethodsisaclear
2TheoriginalformulationofBAMBOO(Opitzetal.,2021) winner. Rematchachievesbestresultsinthreeout
usedPearsoncorrelation.HereweuseSpearmanbecause,as
oftwelvetestsandlagsslightlybehinds2matchon
forstructuralandsemanticconsistency,wedonotassumethat
thesimilarityvaluesarenormallydistributed. average.STS-B SICK-R
spring amrbart sbart mbse spring amrbart sbart mbse
smatch 53.84 54.67 54.73 55.16 58.69 58.89 58.70 57.84
s2match 56.60 57.15 57.54 57.64 58.09 58.56 58.42 57.58
sembleu n/a 58.62 58.17 58.95 60.15 60.61 59.62 59.57
WLK 63.18 64.60 64.33 65.37 63.09 63.33 63.07 62.59
rematch 64.93 65.88 65.06 66.52 67.03 67.72 67.10 67.34
Table2: SemanticconsistencyofAMRsimilaritymetricsandAMRparsersonthetestsplitsofSTS-BandSICK-R
datasets. Bestresultsarehighlightedinbold. SembleufailstoparsesomeoftheAMRsgeneratedbyspring.
SimilarityMethods STS-B SICK-R We leave the efficiency comparison against non-
GloVe(avg.) 58.02 53.76 AMR similarity methods like GloVe, RoBERTa
RoBERTa(first-lastavg.) 58.55 61.63 andSimCSEasfuturework.
AMR(rematch) 66.52 67.72
5.5 AblationStudy
SimCSE-RoBERTa 80.22 68.56
Toassesstheimpactofthethreetypesofrematch
Table3: Comparisonofsimilaritymethods(AMRand motifs — attribute, instance, and relation — on
non-AMR)onsemanticconsistencyforthetestsplitsof structural and semantic similarity, let us conduct
STS-BandSICK-Rdatasets.
anablationstudy,inwhichweremoveoneormore
types of motifs at a time. The results are pre-
sented in Table 5. Instance motifs have the most
5.4 Efficiency
significantinfluenceonsemanticsimilarity,partic-
Fig.3showsthesearchspacesexploredbyAMR ularlywhencombinedwithrelationmotifs. Con-
metricsforincreasingvaluesofN,theaveragesize versely,relationmotifsexertthestrongestinfluence
of each pair of AMRs. The size of each AMR on structural similarity, especially when comple-
is determined by the sum of the number of in- mentedbyinstancemotifs.
stances,attributes,andrelations. Approachesthat To evaluate the overall effectiveness of motifs,
findnodealignmentbetweenAMRs,likesmatch wealsoassesstheperformanceofrematchthrough
ands2match,exploresearchspacesthatgrowex- theuseofAMRlabelsalone. ForthebottomAMR
ponentiallywithN. Feature-basedmethods, like in Fig. 2, the label set is {talk-01, person,
sembleu, WLK, and rematch, in contrast, explore politics, name, ARG0, ARG1, ARG2, name,
significantlysmallerspaces. -,"Helen","Maya",polarity,op1}. Note
Fig.3alsoshowstheruntimesforincreasingN. that person, name, and op1 appear only once
Byusingahill-climbingheuristic,node-alignment in the set. Similar to rematch motifs, we calcu-
metrics effectively overcome the exponentially latetheJaccardsimilaritybetweentwoAMRlabel
growingsearchspaces. However,theyaresignifi- sets. AsshowninTable5,thedeclineinstructural
cantlylessefficientcomparedtofeature-basedmet- consistencywhenusingAMRlabelsissubstantial,
rics. For large values of N, smatch and s2match giventheabsenceofstructuralinformationinthe
displayanapproximatelyquadratictimecomplex- labelsets. Incontrast,thedeclineinsemanticcon-
ity. Sembleu,WLK,andrematch,ontheotherhand, sistencyisrelativelymodest,indicatingthatAMR
demonstratealinearcomplexity. labelsplayasignificantroleincapturingsemantics.
In terms of absolute runtime on the test bed,
5.6 ErrorAnalysis
rematchisthefastestmetric,witharuntimeof51
seconds. This is five times faster than sembleu, On structural consistency, we find that rematch
which took 275 seconds. Smatch, s2match, and underperformswhenRAREswapsattributeedges
WLK trailed further behind, requiring 927, 7718, connected to instance nodes with many relations.
and315seconds. Allmetricsexecutedthetestbed While the change might seem minor (a single
onasingle2.25GHzcore. Rematch,sembleu,and swapped edge), the nested motif structure of re-
smatchneeded0.2GBofRAM,whereass2match matchamplifiesthedifference: mismatchesinat-
andWLK required2GBand30GB,respectively. tributemotifsextendtoinstancemotifsandallcon-Main Reification SynonymReplace RoleConfusion Avg.
STS-B SICK-R PARA STS-B SICK-R PARA STS-B SICK-R PARA STS-B SICK-R PARA
smatch 53.01 57.65 40.96 53.02 59.74 40.08 51.76 55.42 39.60 54.03 75.20 24.78 50.44
s2match 55.87 57.38 41.92 55.41 59.46 40.78 54.86 56.12 40.59 48.23 73.89 26.19 50.89
sembleu 57.02 58.76 31.95 54.73 59.92 31.92 53.42 54.66 27.95 45.69 66.74 21.36 47.01
WLK 63.68 62.32 35.18 61.31 63.03 35.65 57.90 56.60 31.43 44.72 66.39 17.46 49.64
rematch 64.72 66.54 34.88 63.49 62.55 35.82 59.75 61.54 32.70 42.38 67.28 15.37 50.59
Table4: HybridconsistencyofAMRsimilaritymetricsonthetestsplitoftheBAMBOObenchmark,forthethree
kindsofmodifications,nomodification(main)andtheoverallaverage. Thebestresultsarehighlightedinbold.
Figure3: Averagesearchspace(left)andruntime(right)onarandomsampleof500kpairsfromAMRAnnotation
3.0. N denotestheaveragesizeofeachAMRpair.Theinsetzoomsinonsembleu,WLK,andrematch,whichcannot
bedistinguishedinthelog-linearplot. ThelinesontheruntimeplotindicateapproximatefitsforN >101.5,which
onthelog-logscalerepresentpolynomialtimecomplexity. Theslopesindicatethattheruntimescalesquadratically
forsmatchO(N2.25)andlinearlyforrematchO(N).
RARE STS-B SICK-R AMR associates an imperative attribute with
rematch 95.01 73.95 71.01 theverbwork-01. Thisfeatureismissinginthe
secondsentence. Consequently,rematchgenerates
−attribute −00.85 −00.40 −00.09
differentinstanceandrelationmotifs,resultingina
−instance +00.08 −06.34 −07.12
lowersimilarityscorecomparedtotheground-truth
−relation −62.30 +01.15 −01.41
similarity.
−attribute,instance +01.18 −16.78 −07.32
−attribute,relation −62.55 +00.93 −01.92 Moreoften,thenestedmotifgenerationgrants
−instance,relation −95.87 −37.90 −62.32 rematch an advantage in semantic consistency
labels −72.89 −08.08 −07.30 tasks: it allows rematch to handle negation more
effectively compared to other metrics. For exam-
Table5: Ablationstudyofdifferentmotifsonstructural ple, the sentences “You should do it” and “You
(RARE) and semantic (STS-B, SICK-R) consistency. should never do it” have a lower similarity score
Dev splits of RARE and STS-B, and the trial split of inrematchduetothepresenceofthenegative(-)
SICK-Rwereused. Thembseandamrbartparserswere polarity attribute.
usedforSTS-BandSICK-R,respectively.
6 Conclusion
nectedrelationmotifs,leadingtoasignificantdis- This paper introduces rematch, a novel and effi-
crepancyintheoverallsimilarityscore. cient metric for AMR similarity. Rematch lever-
The nested nature of rematch can also some- agessemanticAMRmotifstooutperformexisting
times underestimate semantic similarity. For in- metricsinbothsemanticconsistencyandcomputa-
stance,considerthesentences“Workintoitslowly” tionalefficiency. Additionally,wepresentRARE,
and“Youworkonitslowly.” Thefirstsentence’s a new benchmark designed to evaluate the struc-turalconsistencyofAMRmetrics. UsingRARE, acknowledge the Lilly Endowment for computa-
wedemonstratethestrongsensitivityofrematchto tionalsupportthroughtheIndianaUniversityPer-
structuralchangesinAMRs. vasiveTechnologyInstitute.
AMR matching was originally introduced to
evaluateandenhanceAMRparsers. Throughim-
References
proved matching, metrics like rematch improve
parsing,whichindirectlybenefitsdownstreamuses EnekoAgirre,CarmenBanea,DanielCer,MonaDiab,
ofAMRs. ButrematchshowsthatAMRsencode Aitor Gonzalez-Agirre, Rada Mihalcea, German
Rigau, and Janyce Wiebe. 2016. SemEval-2016
richer semantics than previously assumed. Thus,
Task 1: Semantic Textual Similarity, Monolingual
improved AMR matching also directly benefits
andCross-LingualEvaluation. InProceedingsofthe
downstreamapplications,likesemantictextualsim- 10thInternationalWorkshoponSemanticEvaluation
ilarity. (SemEval-2016),pages497–511,SanDiego,Califor-
Future research should explore the full poten- nia.AssociationforComputationalLinguistics.
tialofAMRsfornaturallanguageunderstanding.
Xuefeng Bai, Yulong Chen, and Yue Zhang. 2022.
Natural Language Inference (NLI) is a prime ex- GraphPre-trainingforAMRParsingandGeneration.
ample, where AMR-based systems have already In Proceedings of the 60th Annual Meeting of the
AssociationforComputationalLinguistics(Volume
shownpromise(Opitzetal.,2023). Anevenmore
1: LongPapers),pages6001–6015,Dublin,Ireland.
intriguingdirectionwouldbetodevelopmethods
AssociationforComputationalLinguistics.
thatperformNLIsolelythroughAMRmatching,
capitalizingontherichstructureandsemanticsen- Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
codedwithinAMRs.
Knight,PhilippKoehn,MarthaPalmer,andNathan
Schneider.2013. AbstractMeaningRepresentation
7 Limitations
forSembanking. InProceedingsofthe7thLinguistic
AnnotationWorkshopandInteroperabilitywithDis-
Current AMR metrics, including rematch, have
course,pages178–186,Sofia,Bulgaria.Association
limitationsfordownstreamtaskslikesemantictex-
forComputationalLinguistics.
tual similarity. One key issue is their inability to
capture similarity between words. This can lead Michele Bevilacqua, Rexhina Blloshmi, and Roberto
Navigli. 2021. One SPRING to Rule Them Both:
metricslikerematchtomisclassifytwosentences
Symmetric AMR Semantic Parsing and Genera-
withdifferentwordingsbutequivalentmeaningas tion without a Complex Pipeline. Proceedings
dissimilar. S2matchattemptstoaddressthislimita- of the AAAI Conference on Artificial Intelligence,
tionbyusingwordembeddingsfornodealignment, 35(14):12564–12573. Number: 14.
but our analysis shows that this approach offers
Claire Bonial, Lucia Donatelli, Mitchell Abrams,
minimalimprovementinsemanticconsistencyata StephanieM.Lukin,StephenTratz,MatthewMarge,
highcomputationalcost. Recently,thislimitation Ron Artstein, David Traum, and Clare Voss. 2020.
was addressed by a novel self-supervised metric Dialogue-AMR: Abstract Meaning Representation
for Dialogue. In Proceedings of the Twelfth Lan-
called AMRSim (Shou and Lin, 2023). It trains
guageResourcesandEvaluationConference,pages
Siamese BERT models on flattened silver AMR
684–695,Marseille,France.EuropeanLanguageRe-
pairs generated from one million sentences sam- sourcesAssociation.
pledfromWikipedia.
ShuCaiandKevinKnight.2013. Smatch:anevaluation
Anotherlimitationofrematchisthatitusesmo-
metricforsemanticfeaturestructures. InProceed-
tifs associated with single edges (paths of length ingsofthe51stAnnualMeetingoftheAssociation
one). Whilethisapproachworkswellforshort-text forComputationalLinguistics(Volume2: ShortPa-
semanticsimilarity,itmightnotcapturethemore pers),pages748–752,Sofia,Bulgaria.Association
forComputationalLinguistics.
complexsemanticspresentinAMRsderivedfrom
longerdocuments. Inotherwords,rematchmight AndreaDiFabio,SimoneConia,andRobertoNavigli.
struggletocomparethemeaningoflongertexts. 2019. VerbAtlas:aNovelLarge-ScaleVerbalSeman-
tic Resource and Its Application to Semantic Role
Acknowledgements. WethankRamónFernan- Labeling. InProceedingsofthe2019Conferenceon
dez Astudillo for helpful discussions. This work EmpiricalMethodsinNaturalLanguageProcessing
andthe9thInternationalJointConferenceonNatu-
wassupportedinpartbytheNSFthroughanNRT
ralLanguageProcessing(EMNLP-IJCNLP),pages
Fellowship (grant 1735095), the Knight Founda-
627–637,HongKong,China.AssociationforCom-
tion,andCraigNewmarkPhilanthropies. Wealso putationalLinguistics.William B. Dolan and Chris Brockett. 2005. Auto- WaiChingLeung,ShiraWein,andNathanSchneider.
maticallyConstructingaCorpusofSententialPara- 2022b. Semanticsimilarityasawindowintovector-
phrases. InProceedingsoftheThirdInternational andgraph-basedmetrics. InProceedingsofthe2nd
WorkshoponParaphrasing(IWP2005). Workshop on Natural Language Generation, Eval-
uation, and Metrics (GEM), pages 106–115, Abu
AndrewDrozdov,JiaweiZhou,RaduFlorian,Andrew
Dhabi,UnitedArabEmirates(Hybrid).Association
McCallum, Tahira Naseem, Yoon Kim, and Ra-
forComputationalLinguistics.
monFernandezAstudillo.2022. InducingandUs-
ingAlignmentsforTransition-basedAMRParsing.
Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman
ArXiv:2205.01464[cs].
Sadeh,andNoahA.Smith.2015. TowardAbstrac-
tiveSummarizationUsingSemanticRepresentations.
Angela Fan, Claire Gardent, Chloé Braud, and An-
InProceedingsofthe2015ConferenceoftheNorth
toineBordes.2019. UsingLocalKnowledgeGraph
AmericanChapteroftheAssociationforComputa-
Construction to Scale Seq2Seq Models to Multi-
tionalLinguistics: HumanLanguageTechnologies,
DocumentInputs. InProceedingsofthe2019Confer-
pages1077–1086,Denver,Colorado.Associationfor
enceonEmpiricalMethodsinNaturalLanguagePro-
ComputationalLinguistics.
cessingandthe9thInternationalJointConference
onNaturalLanguageProcessing(EMNLP-IJCNLP),
MarcoMarelli,StefanoMenini,MarcoBaroni,Luisa
pages4186–4196,HongKong,China.Association
Bentivogli, Raffaella Bernardi, and Roberto Zam-
forComputationalLinguistics.
parelli. 2014. A SICK cure for the evaluation of
Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2022. compositional distributional semantic models. In
SimCSE:SimpleContrastiveLearningofSentence ProceedingsoftheNinthInternationalConference
Embeddings. ArXiv:2104.08821[cs]. onLanguageResourcesandEvaluation(LREC’14),
pages216–223,Reykjavik,Iceland.EuropeanLan-
MichaelWayneGoodman.2020. Penman: AnOpen-
guageResourcesAssociation(ELRA).
SourceLibraryandToolforAMRGraphs. InPro-
ceedingsofthe58thAnnualMeetingoftheAssocia-
ArindamMitraandChittaBaral.2016. Addressinga
tionforComputationalLinguistics: SystemDemon-
QuestionAnsweringChallengebyCombiningSta-
strations, pages 312–319, Online. Association for
tistical Methods with Inductive Rule Learning and
ComputationalLinguistics.
Reasoning. ProceedingsoftheAAAIConferenceon
ArtificialIntelligence,30(1). Number: 1.
HardyHardyandAndreasVlachos.2018. GuidedNeu-
ralLanguageGenerationforAbstractiveSummariza-
TahiraNaseem,AustinBlodgett,SadhanaKumaravel,
tionusingAbstractMeaningRepresentation. InPro-
Tim O’Gorman, Young-Suk Lee, Jeffrey Flanigan,
ceedingsofthe2018ConferenceonEmpiricalMeth-
RamónAstudillo,RaduFlorian,SalimRoukos,and
odsinNaturalLanguageProcessing,pages768–773,
NathanSchneider.2022. DocAMR:Multi-sentence
Brussels, Belgium. Association for Computational
AMRrepresentationandevaluation. InProceedings
Linguistics.
ofthe2022ConferenceoftheNorthAmericanChap-
Shu-Ming Hsieh, Chiun-Chieh Hsu, and Li-Fu Hsu. teroftheAssociationforComputationalLinguistics:
2006. Efficient Method to Perform Isomorphism HumanLanguageTechnologies,pages3496–3505,
Testing of Labeled Graphs. In Computational Sci- Seattle,UnitedStates.AssociationforComputational
ence and Its Applications - ICCSA 2006, Lecture Linguistics.
NotesinComputerScience,pages422–431,Berlin,
Heidelberg.Springer. Juri Opitz, Angel Daza, and Anette Frank. 2021.
Weisfeiler-Leman in the Bamboo: Novel AMR
Knight,Kevin,Badarau,Bianca,Baranescu,Laura,Bo-
Graph Metrics and a Benchmark for AMR Graph
nial, Claire, Griffitt, Kira, Hermjakob, Ulf, Marcu,
Similarity. TransactionsoftheAssociationforCom-
Daniel, O’Gorman, Tim, Palmer, Martha, Schnei-
putationalLinguistics,9:1425–1441.
der,Nathan,andBardocz,Madalina.2020. Abstract
MeaningRepresentation(AMR)AnnotationRelease
JuriOpitz,LetitiaParcalabescu,andAnetteFrank.2020.
3.0. LDCCatalogNo.LDC2020T02.
AMRSimilarityMetricsfromPrinciples. Transac-
tionsoftheAssociationforComputationalLinguis-
Young-Suk Lee, Ramon Fernandez Astudillo,
tics,8:522–538. Place: Cambridge,MAPublisher:
Thanh Lam Hoang, Tahira Naseem, Radu Flo-
MITPress.
rian, and Salim Roukos. 2022. Maximum Bayes
Smatch Ensemble Distillation for AMR Parsing.
JuriOpitz,ShiraWein,JuliusSteen,AnetteFrank,and
ArXiv:2112.07790[cs].
NathanSchneider.2023. AMR4NLI:Interpretable
WaiChingLeung,ShiraWein,andNathanSchneider. and robust NLI measures from semantic graphs.
2022a. SemanticSimilarityasaWindowintoVector- ArXiv:2306.00936[cs].
andGraph-BasedMetrics. InProceedingsofthe2nd
Workshop on Natural Language Generation, Eval- Martha Palmer, Daniel Gildea, and Paul Kingsbury.
uation, and Metrics (GEM), pages 106–115, Abu 2005. The Proposition Bank: An Annotated Cor-
Dhabi,UnitedArabEmirates(Hybrid).Association pusofSemanticRoles. ComputationalLinguistics,
forComputationalLinguistics. 31(1):71–106.KishorePapineni,SalimRoukos,ToddWard,andWei-
JingZhu.2002. BLEU:amethodforautomaticeval-
uationofmachinetranslation. InProceedingsofthe
40th Annual Meeting on Association for Computa-
tionalLinguistics, ACL’02, pages311–318, USA.
AssociationforComputationalLinguistics.
Yisu Peng, Yuxiang Jiang, and Predrag Radivojac.
2018. Enumeratingconsistentsub-graphsofdirected
acyclicgraphs: aninsightintobiomedicalontologies.
Bioinformatics,34(13):i313–i322.
Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. GloVe: Global Vectors for Word
Representation. InProceedingsofthe2014Confer-
enceonEmpiricalMethodsinNaturalLanguagePro-
cessing (EMNLP), pages 1532–1543, Doha, Qatar.
AssociationforComputationalLinguistics.
LeonardoF.R.Ribeiro,MengwenLiu,IrynaGurevych,
MarkusDreyer,andMohitBansal.2022. FactGraph:
EvaluatingFactualityinSummarizationwithSeman-
ticGraphRepresentations. ArXiv:2204.06508[cs].
Nino Shervashidze, Pascal Schweitzer, Erik Jan van
Leeuwen,KurtMehlhorn,andKarstenM.Borgwardt.
2011. Weisfeiler-LehmanGraphKernels. TheJour-
nalofMachineLearningResearch,12(null):2539–
2561.
ZiyiShou,YuxinJiang,andFangzhenLin.2022. AMR-
DA:DataaugmentationbyAbstractMeaningRep-
resentation. InFindingsoftheAssociationforCom-
putationalLinguistics: ACL2022,pages3082–3098,
Dublin,Ireland.AssociationforComputationalLin-
guistics.
Ziyi Shou and Fangzhen Lin. 2023. Evaluate AMR
graphsimilarityviaself-supervisedlearning. InPro-
ceedingsofthe61stAnnualMeetingoftheAssocia-
tionforComputationalLinguistics(Volume1: Long
Papers),pages16112–16123,Toronto,Canada.As-
sociationforComputationalLinguistics.
LinfengSongandDanielGildea.2019. SemBleu: A
RobustMetricforAMRParsingEvaluation. InPro-
ceedings of the 57th Annual Meeting of the Asso-
ciationforComputationalLinguistics,pages4547–
4552,Florence,Italy.AssociationforComputational
Linguistics.
Nikhita Vedula and Srinivasan Parthasarathy. 2021.
FACE-KEG:FactCheckingExplainedusingKnowl-
edgEGraphs. InProceedingsofthe14thACMInter-
nationalConferenceonWebSearchandDataMining,
WSDM’21,pages526–534,NewYork,NY,USA.
AssociationforComputingMachinery.
Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut,
Percy Liang, and Jure Leskovec. 2021. QA-GNN:
ReasoningwithLanguageModelsandKnowledge
GraphsforQuestionAnswering. InProceedingsof
the2021ConferenceoftheNorthAmericanChapter
oftheAssociationforComputationalLinguistics:Hu-
manLanguageTechnologies,pages535–546,Online.
AssociationforComputationalLinguistics.