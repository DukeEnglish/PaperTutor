Exploring Automated Distractor Generation for
Math Multiple-choice Questions via Large Language Models
WanyongFeng1˚,JaewookLee1˚,HunterMcNichols1˚,AlexanderScarlatos1˚,
DigorySmith2,SimonWoodhead2,NancyOteroOrnelas3,AndrewLan1
UniversityofMassachusettsAmherst1,Eedi2,StanfordUniversity3
{wanyongfeng,ajscarlatos,jaewooklee,wmcnichols,andrewlan}@umass.edu
{digory.smith,simon.woodhead}@eedi.co.uk
nancy.otero.o@gmail.com
Abstract knowledgeoftheskillstestedintheMCQtoaccu-
ratelyidentifythekeyasthecorrectanswer,orii)
Multiple-choicequestions(MCQs)areubiqui-
holdmisconceptionsthatresultinselectingaspe-
tousinalmostalllevelsofeducationsincethey
cificdistractorasthecorrectanswer. WhileMCQs
areeasytoadminister,grade,andareareliable
offermanyadvantagesforstudentknowledgeeval-
formatinassessmentsandpractices.Oneofthe
mostimportantaspectsofMCQsisthedistrac- uation,manuallycraftinghigh-qualityMCQsisa
tors,i.e.,incorrectoptionsthataredesignedto demandingandlabor-intensiveprocess(Kellyetal.,
targetcommonerrorsormisconceptionsamong 2013). Specifically,high-qualitydistractorsshould
realstudents. Todate,thetaskofcraftinghigh- beplausibleenoughtomisleadstudentsandnotso
qualitydistractorslargelyremainsalaborand
evidentlyincorrecttobeidentifiedeasily.
time-intensiveprocessforteachersandlearning
Prior work on automatic distractor generation
contentdesigners,whichhaslimitedscalability.
primarilyfocusesonlanguagelearningandreading
In this work, we study the task of automated
comprehension tasks, where distractors are used
distractor generation in the domain of math
MCQsandexploreawidevarietyoflargelan- toassessstudents’comprehensionofagiventext
guagemodel(LLM)-basedapproaches, from or article. Early works use a ranking approach
in-contextlearningtofine-tuning. Weconduct based on semantic similarity and word colloca-
extensiveexperimentsusingareal-worldmath tioninformationorapre-definedontologytopro-
MCQdatasetandfindthatalthoughLLMscan
ducedistractors(Susantietal.,2018;Stasaskiand
generatesomemathematicallyvaliddistractors,
Hearst,2017;Alsubaitetal.,2014). Morerecent
theyarelessadeptatanticipatingcommoner-
worksuseencoder-decodermodelswithattention
rorsormisconceptionsamongrealstudents.
mechanismsfordistractorgeneration,resultingin
1 Introduction longer and higher-quality distractors (Qiu et al.,
2020; Shuai et al., 2023; Xie et al., 2021; Gao
Multiple-choicequestions(MCQs)arewidelyused
etal.,2019). Additionally,severalrecentworksuse
to evaluate student knowledge because they en-
pre-trainedlargelanguagemodels(LLMs)suchas
ablequickandaccurateadministrationandgrading.
BERTandT5fordistractorgenerationinthecon-
MCQs are reliable because they are designed to
textofSwedishreadingandClozetest(Kalpakchi
measure specific learning objectives consistently
and Boye, 2021; Chiang et al., 2022; Rodriguez-
(Nitko,1996;Airasian,2001;KubiszynandBorich,
Torrealbaetal.,2022). OtherworkspromptLLMs
2016). MCQsareconstructedinaspecificformat.
suchasChatGPTandGPT-4togeneratedistrac-
See Figure 1 for an example. The stem refers to
tors, either by providing detailed instructions or
the statement on the problem setup and context,
in-contextexamplesintheirprompts,forcomputer
followedbyaquestionthatneedstobeanswered.
sciencecoursequizquestionsandquestionstesting
Amongtheoptions,thecorrectonecanbereferred
languagemasteryorfactualknowledge(Tranetal.,
toasthekey,whileincorrectonescanbereferred
2023;Bitewetal.,2023).
toasdistractors. Asthenameimplies,distractors
However, there is limited work on automatic
inMCQsaretypicallyformulatedtoalignwiththe
distractor generation for math MCQs. This prob-
commonerrorsstudentswouldmakeormisconcep-
lemismorechallengingthangeneratingdistractors
tionsstudentswouldexhibit. Thesedistractorsare
for reading comprehension tasks because plausi-
chosenbecausestudentseitheri)lackthenecessary
bledistractorsarenotnecessarilycontainedorcan
*Theseauthorscontributedequallytothiswork. be inferred from the passage. A model for math
4202
rpA
2
]LC.sc[
1v42120.4042:viXraFigure1: DifferentpartsofmathMCQsandtheterminologyweuse,illustratedwithanexample.
MCQdistractorgenerationshouldhavesomemath 2 TaskandApproaches
problem-solvingcapabilityandmoreimportantly,
In this section, we first formally define relevant
anunderstandingofthecommonerrorsormiscon-
mathematicalnotationinMCQsandtheautomated
ceptions among real students. Existing works ei-
distractorgenerationtask. WethendetailtheLLM-
theruseconstraintlogicprogramming(Tomásand
basedapproachesandbaselinesthatweexplore.
Leal,2013)ormanuallyconstructedrules(Prakash
etal.,2023)togeneratedistractors. However,these 2.1 TaskDefinition
works only applies to math MCQs generated by
We define an MCQ Q as a set of textual compo-
templates. Theworkin(Daveetal.,2021)explores
nents,i.e.,Q “ ts,k,e ,D,Fu.* EachMCQcon-
k
generatingdistractorsusinganeuralnetwork. How-
tains a stem s, a key k, an (optional) explanation
ever, their approach is training a math problem
of the key e , and a set of distractors D; each of
k
solvermodelandtreatingtheincorrectoutputsas
which has an (optional) corresponding feedback
distractors,whichcannotcapturecommonerrors
messagef whichisshowntoastudentuponselect-
i
ormisconceptionsamongrealstudents.
ing a distractor d P D. All of these components
i
1.1 Contributions are sequences of words and math symbols (e.g.,
s “ tw ,...,w u where L is the length of the
In this work, we investigate the task of automat- 1 L
sequences). Similarto(Qiuetal.,2020),wefor-
ically generating plausible distractors for math
mulatethetaskofdistractorgenerationaslearning
MCQsusingLLMs. Ourcontributionsinclude:
afunctiongdisthatoutputsasetofdistractorsDˆ for
• Weexploreavarietyofapproachestothistask, anMCQgiventhequestionstemand(optionally)
includingin-contextlearning,fine-tuning,and keyanditsexplanation,i.e.,
chain-of-thought prompting, together with
gdisps,k,e q Ñ Dˆ. (1)
rule-andsampling-basedbaselines. k
• Weconductextensivequantitativeandquali- Our goal is to generate distractors that students
tativeexperimentsonareal-worlddatasetof withinsufficientknowledgeonskillsrequiredfor
mathMCQs. Wefindthatthemosteffective the MCQ or specific misconceptions will select.
approachisin-contextlearning,wherewese- Thisway,theMCQcanbetterdistinguishbetween
lectafewexampleMCQsasinputtotheLLM, studentsthatmasteralltherequiredskillsandthose
whichcanserveasabaselineforfuturework. whodonot. Below,wedetailvariousLLM-based
distractorgenerationapproachesandseveralbase-
• Weconductahumanevaluationandfindthat linesthatweexplore.
although the LLM-generated distractors are Wenotethatinthiswork,westudytheproblem
closetothehuman-authoredonesintermsof ofgeneratingasetofdistractorsDˆ givenasingle
mathematical validity, they do not necessar-
*In this paper, we do not consider MCQs that contain
ilyreflectcommonerrorsormisconceptions
diagramsorimages;extendingourworktomulti-modalMCQ
amongrealstudents. contentisleftforfuturework.Figure2: OverviewofthekNNapproachillustratedwithamathMCQon“compoundpercentagedecrease”.
questionstem. Thissettingisdifferentfromapos- tions that are feasible to the target MCQ, which
siblealternativesettingwherewegeneratedistrac- may help the LLM to generate plausible distrac-
torsone-by-one,eachcorrespondingtoacommon tors. Eventhoughtextualsimilaritymaynotbean
errorormisconceptionamongrealstudents. The appropriaterepresentationformathematicalerrors,
latterisapplicabletotherelatedproblemoffeed- thesein-contextexamplesshouldatleastinformthe
backgeneration(Priharetal.,2023),whichinves- LLM on distractor formatting (Chen et al., 2023;
tigatesthetaskofgeneratingafeedbackmessage Lyu et al., 2023). We use ChatGPT in this ap-
f foradistractord . Providingfeedbackmessages proach for its proficiency in understanding tasks
i i
to students who select distractors can help them anddeliveringstrongperformancewhenprovided
identify their errorsor misconceptions and guide within-contextexamples.
themtowardsthecorrectanswer,whichmayexpe-
The second approach is chain-of-thought
dite their learning process. In this work, we only
prompting (CoT) (Wei et al., 2022). We provide
treat the feedback message as an additional rea-
the LLM with the question stem and (optionally)
soningpathwaytohelpLLMsgenerateplausible
keyanditsexplanationanddetailedguidelineson
distractorsanddonotstudythequalityoffeedback
distractorgenerationasinputandaskittofirstgen-
messages,whichweleaveforfuturework.
eratepotentialerroneousstepsastudentmaytake,
followed by an incorrect answer as the distractor.
2.2 Approaches
Thisapproachoperatesinazero-shotmannerand
The first approach is in-context learning or few-
requiresnoaccesstoanyrealMCQdata. Therefore,
shotprompting,i.e., theLLMisexpectedtogen-
theperformancedependssolelyontheLLM’sabil-
erate desired outputs for a new task by learning
ityinmathematicalreasoningandanticipatingcom-
fromthegivenexamples(Brownetal.,2020). To
monerrorsormisconceptionsamongrealstudents.
selectexamples,weselectthek-nearestneighbor
Giventhedemandingnatureofthisapproach,we
(kNN)MCQsfromareal-worldmathMCQdataset,
useastrongbaseLLMGPT-4(OpenAI,2023).
whichwedetailinSection3.1,tothetargetMCQ.
ThethirdapproachisLLMfine-tuning(FT)to
Afterconductingtestswithvariousvaluesofk,we
help pre-trained LLMs to adapt to the distractor
findthatthisapproachachievesthebestdistractor
generationtask. Weusethereal-worldmathMCQ
generation performance when k “ 3. To deter-
datasettofine-tunetheLLMintheformatofEq.1,
minesimilarity,wecalculatethecosinesimilarity
i.e., outputting all distractors given the question
between vectorized textual encodings of MCQs.
stemand(optionally)keyanditsexplanationasin-
Specifically, we use the pre-trained SBERT en-
put. WeuseChatGPT(gpt-3.5-turbo-1106)(Ope-
coder MPNet (Reimers and Gurevych, 2019) to
nAI,2022),thelargestbaseLLMthatcanbefine-
calculatethetextualencodingofthequestionstem
tuned,inthisapproach.
and(optionally)keyanditsexplanation. Figure2
provides a visual representation of this approach. Thefourthapproachisarule-based(RB)base-
TheintuitionforthisapproachisthatMCQswith line, which can be used to generate different ver-
similar question stems may have distractors that sions of the same MCQ with different numerical
correspondtosimilarstudenterrorsormisconcep- values. Weemphasizethatinmanyreal-worlded-ucational platforms, content creators do not use distribution, i.e., the proportion of students who
rules to design distractors. In practice, not a lot selected each option. The option selection distri-
ofMCQsarecreatedfromtemplatesandonlydif- butioniscomputedonanaverageof4000student
ferbynumericalvaluesornamedentitiesintheir responses, with more than 900 student responses
questionstems. Therefore,weapproximatelyfol- available in over 75% of the MCQs. We divide
low the baseline approach in (Dave et al., 2021) thedatasetintotwosubsets,namelyatrainingset
andmanuallyconstruct444distincterrorexplana- and a test set, using an 80 : 20 ratio. We use the
tions,suchas“confusesfactorandmultiples”for trainingsettoselectMCQsasin-contextexamples
question-distractor pairs that correspond to com- orfine-tuneLLMsandthetestsetforevaluation.
monerrorsormisconceptionsamongrealstudents.
3.2 EvaluationMetrics
Thisprocessisextremelytime-consumingandre-
quiressignificantmanualeffort. Wethenprovide Our main evaluation metric is a set of alignment-
the LLM with the question stem and (optionally) based metrics, which quantifies the extent to
keyanditsexplanationandapooloferrorexplana- which the LLM-generated distractors align with
tionsthatarefeasibleundertheMCQ’stopic(i.e., the human-authored ones. We denote the LLM-
fractions,rounding,etc.),andaskLLMtoselect3 generated distractors as Dˆ where |Dˆ | “ N. We
relevantonesandgeneratethecorrespondingdis- utilize 3 measures for this evaluation, two binary
tractors. We use GPT-4 in this approach for the and one continuous. The binary metrics are Ex-
samereasonasCoT. actmatchh e,i.e.,whetherallLLM-generateddis-
The fifth approach is an improved version of tractorsmatchhuman-authoredones*,andPartial
the sampling-based (SB) baseline in (Dave et al., matchh p,i.e.,whetheratleastoneLLM-generated
2021). This approach fine-tunes a base LLM on distractor matches human-authored ones. These
MCQanswering,i.e.,outputtingthekeygiventhe measuresareformallydefinedas
question stem as input. Then, we randomly sam- #
pleupto20outputanswersfromthetrainedLLM h pD,Dˆ q “ 1 @dˆ i P Dˆ : dˆ i “ d i
e
givenaquestionstemasinputandchoose3distinct 0 otherwise.
incorrectonesasdistractors. Thisapproachimplic-
itlyassumesthatLLMsmakesimilarerrorsasreal and
#
students. We use ChatGPT in this approach for
1 Ddˆ P Dˆ : dˆ “ d
thesamereasonasFT. h pD,Dˆ q “ i i i
p
0 otherwise
3 Experiments
Wealsouseacontinuousmeasureintherange
Inthissection,wedetailthespecificsofourdataset, r0,1sthatwecallProportionalmatchh ,i.e.,the
n
theevaluationmetrics,theexperimentalsetup,and portion of LLM-generated distractors that match
reportresultsfromaseriesofquantitative,qualita- human-authoredones,definedas
tiveexperiments,andhumanevaluation. ř
1
h pD,Dˆ q “ i“1 i:dˆ i“di
3.1 Dataset n
N
Our dataset consists of 1.4K MCQs from Eedi’s
where1denotesanindicatorfunction. Wereport
content repository*, and all MCQs are written in
allmetricsbyaveragingacrossallMCQsinthetest
English. Eachquestionhas1keyand3distractors
set and scale the values of metrics by a factor of
designedaccordingto commonerrorsormiscon-
100intopercentages.
ceptions among real students. The questions are
Additionally, we experiment with a non-
sourced from thebroad mathematical topic titled
standard,distribution-based metric,whichtriesto
“Number”withsubtopicsincluding“BasicArith-
predicthowoftenadistractorisselectedbyrealstu-
metic”, “Fractions”, and“RoundingandEstimat-
dents. Thismetricismotivatedbytheobservation
ing”. Thequestionsareprimarilytargetedtowards
(SeeSection3.5foradetailedqualitativeanalysis)
studentsagedbetween10to13. EachMCQalso
thathuman-authoreddistractorsaresometimesnot
hassomeadditionalmetadata,e.g.,the“topic”on3
plausibleorcomplete: forsomeMCQs,theremay
differentgranularitylevelsandtheoptionselection
*We use the exact string match criterion to align LLM-
*https://eedi.com/home generateddistractorswithhuman-authoredones.only be one highly common error or misconcep- Approach Exact Partial Proportional
tion among real students, so teachers often have
kNN 10.95 73.85 38.52
to come up with a few placeholders that will be
CoT 4.24 65.02 30.39
selectedbyalmostnoone,whileforotherMCQs,
RB 4.95 57.95 27.21
there may be numerous plausible distractors that
FT 2.83 57.95 25.32
cannot all be included. Therefore, our goal is to
SB 0.00 10.25 3.65
usethepercentagesofstudentswhoselectedeach
optiontotrainamodelthatpredictshowfeasiblea
Table1: Resultsondistractorgenerationonalignment-
distractoris. Sincewecannotreachhighpredictive
basedmetrics,wherein-contextlearningwithkNNex-
accuracyontherealdatasetwehave,werelegate
ampleselectionoutperformsotherapproaches.
thedetailsonthismetricandexperimentalresults
totheSupplementaryMaterialSectionA.
Furthermore,weexperimentwithametricthat ilar to the target MCQ often contain distractors
evaluates the quality of LLM-generated distrac- that correspond to plausible errors or misconcep-
torsindirectly: weaskGPT-4toanswerMCQsin tionsamongrealstudentsforbothMCQs. There-
thetestsetundertwoscenarios: oneusingLLM- fore,theLLMcangeneratedistractorsthatmatch
generated distractors and the other using human- thehuman-authoredonesbysimplyreplicatingthe
authoredones. Wethencalculateandcomparethe styleofthein-contextexamples. Thisapproachis
solverates. WefoundthatLLM-generateddistrac- especiallyeffectiveforMCQsthathavehighlysim-
torsusingkNN,thebest-performingmethodunder ilarstructuresanddifferinonlynumericalvalues.
alignment-basedmetrics,aremoredifficult(71% TheadvantageofCoToverFTreflectsthestrong
solverate)thanthehuman-authoredones(72.5%). mathematical reasoning capability of GPT-4,
ThisresultimpliesthattheLLM-generateddistrac- which results in a performance gap that not even
torsarenotplaceholders,whichwouldmakeitvery fine-tuningChatGPTonhuman-authoreddistrac-
easyforGPT-4toselectthekey. However,solve tors can make up. Instead of acting as an oracle,
ratecannotbeusedtoevaluatetherealqualityof RB underperforms this expectation and does not
distractorsandwhethertheyreflectcommonerrors evenoutperformCoT,despiterequiringsignificant
ormisconceptionsamongrealstudents. human expertise and effort. This result is likely
duetothefactthatdespiteextensiveeffortinlabel-
3.3 ExperimentalSetup
ingerrorexplanations,wecannotcomeupwitha
ForallapproachesexceptSB,weuseauniformfor- comprehensivelistofthem;asaresult,manytarget
mattorepresentthetargetMCQ.Thisformatcom- MCQsarenotmatchedwitherrorexplanationsfor
prisesaconcatenationof3elements: thequestion GPT-4 to select from. Overall, we observe that
stem, key, and its explanation. We use this struc- GPT-4 can often generate mathematically valid
turesinceitencapsulatesthemostcomprehensive distractorsbutisunawareofwhaterrorsormiscon-
information about the target MCQ. Furthermore, ceptionsarecommonamongrealstudents. There-
basedonCoT,weinstructtheLLMtofirstgenerate fore,CoTandRBdonotperformaswellaskNN.
feedback message and then the distractor, which Amongalltheapproachesweexplore,SBhasby
intendstosimulateareasoningpathway,providing far the worst performance. This result is not sur-
a scaffold that guides the subsequent generation prisingsincewhenwetrainLLMstoanswermath
of plausibledistractors. Weuse greedy decoding MCQscorrectly,thegeneratedincorrectanswers
and a maximum output length of 350 tokens for areeitheronlymarginallydifferentthanthekeyor
distractorgeneration. Additionalhyperparameters completelyunrelatedtothequestionstem. There-
and model detailsare in Supplementary Material fore,thedistractorsgeneratedbythisapproachlack
SectionB.WealsoprovideourpromptsforCoT, coherentreasoningandfailtocapturecommoner-
RB,andkNNinTables 9, 10,and 11respectively. rorsormisconceptionsamongrealstudents.
3.4 ResultsandDiscussion 3.4.1 AblationStudy
Table1showstheresultsondistractorgeneration In this ablation study, we investigate the impact
forthe5approachesweexplore. Overall,kNNout- of different configurations of kNN on its perfor-
performs the other approaches. This result is not manceandsummarizetheseresultsinthefirstpart
surprising since examples that are textually sim- ofTable2. WeexplorehowdifferentwaysofusingApproach Exact Partial Proportional LLM Approach Exact Partial Proportional
kNNall 10.95 73.85 38.52 kNN 8.83 71.73 38.52
GPT-4 CoT 4.24 65.02 30.39
kNNkey 11.66 69.96 37.57
RB 4.95 57.95 27.21
kNNnone 9.54 67.84 35.81
kNN 10.95 73.85 38.52
Random 2.12 54.77 23.56
ChatGPT CoT 1.06 48.41 21.67
Promptkey 8.48 66.43 34.04
RB 1.77 50.53 23.09
Promptnone 3.89 44.52 21.20
FT 2.83 57.95 25.32
kNNall 3.18 58.30 26.38
␣T kNN 1.77 31.10 13.90
FTgpt3.5 2.83 57.95 25.32 Mistral CoT 0.0 8.83 3.65
FTmistral 1.77 52.30 22.50 RB 0.0 18.37 7.07
FT 1.77 52.30 22.50
RBselect 4.95 57.95 27.21
RBrandom 1.06 53.00 23.20 Table 3: Results on kNN, CoT, RB, and FT on
alignment-based metrics with different base LLMs:
Table2: Resultsonablationstudyonalignment-based
GPT-4,ChatGPT,andMistral.
metricswithdifferentsettingsofkNN,FT,andRB.
alsoexploretheimpactofnotallowingMCQswith
differentpartsoftheMCQinthetextualencoder
thesametopictobeselectedasexamplesonkNN’s
fornearestneighborsearchcouldaffectkNN’sper- performance (kNNall ). We see that doing so re-
␣T
formance. Weexperimentwith3differentsettings: sultsinahugeperformancedrop-offfromkNNall.
usingjustthequestionstem(kNNnone);usingthe
Thisresultsuggeststhatmosterrorsormisconcep-
question stem and key (kNNkey); and using the
tions behind distractors are topic-specific and do
question stem, key, and its explanation (kNNall),
notgeneralizeacrosstopics.
whichisthebestperformingsetting. Forcompar-
Next, we investigate the impact of different
ison, we also experiment with a simple random
base LLMson FT’s performance and summarize
heuristic (Random) that chooses examples from
these results in the second part of Table 2. We
thetrainingsetrandomlywithoutanyspecificcri-
compareChatGPTagainstMistral-7B(Jiang
teria. We see that although using only the ques-
et al., 2023), which is one of the biggest open-
tion stem captures the math skill covered by an
sourcedgenerativeLLMs(FTmistral). Weseethat
MCQandhelpskNNfindexamplesthathavethe
ChatGPT outperforms Mistral-7B on all 3
same format as the target MCQ, adding the key
alignment-basedmetrics. Thisresultsuggeststhat
and explanation helps kNN find better examples
larger models that are better at mathematical rea-
that use similar problem-solving strategies to the
soning are more likely to generate plausible dis-
targetMCQ.Wealsoexplorehowdifferentprompt
tractors. Wealsoinvestigatetheimpactofdifferent
formats could affect kNN’s performance. We ex-
error selection approaches on RB’s performance
perimentwith3differentpromptformats. Thebest-
performingsetting(kNNall)includesthequestion and summarize these results in the third part of
Table2. WeexperimentwithavariantofRBthat
stem,key,andexplanationforboththetargetMCQ
randomlyselectserrorexplanationsunderthesame
andthein-contextexamples. Thein-contextexam-
math topic (RBrandom) instead of asking GPT-4
plesalsocontainfeedbackonthedistractors,and
to select 3 relevant ones (RBselect). We see that
weasktheLLMtogeneratethefeedback,followed
askingtheLLMtoselecterrorexplanationsoutper-
bythedistractor. The othersettingsarenottoin-
forms selecting error explanations randomly, but
clude feedback messages for the distractors and
the explanation for the key (Promptkey), and not notbyasignificantmargincomparedtootherabla-
includingthekeyeither(Promptnone). Weseethat tions. ThisresultsuggeststhateventhoughLLMs
cangeneratemanymathematicallyvaliddistractors,
includingthekeysignificantlyimproveskNN’sper-
theirabilitytorecognizewhicherrorexplanations
formanceandaskingtheLLMtogeneratefeedback
arepopularamongstudentsislimited.
followedbythedistractorfurtherimprovesperfor-
mance. Thisresultagainreinforcestheimportance Furthermore, we investigate the impact of dif-
ofmathproblem-solvingstrategiesandCoTreason- ferentbaseLLMsonallapproaches’performance
ingonthedistractorgenerationperformance. We exceptSBandsummarizetheseresultsinTable3.We compare 3 base LLMs: GPT-4 *, ChatGPT, Target
andMistral. WeseethatkNNoutperformsCoT
Quesitonstem:whichmultipliercanbeusedtofindthe
and RB across all base LLMs. This result sug- valueafteranamounthasdecreasedinvalueby8%for
4years?
gests that kNN is a promising approach since in-
Explanation: Asitsisadecrease,weneed100%-8%
contextexamplesprovidevaluableinformationto
whichis92%whichisthesameas0.92. Wethenuse
the LLM on the nature and format of the distrac-
thenumberofyearsasthepowerof4.
tor generation task. We see that GPT-4 signifi- Answer:ˆ0.924
cantlyoutperformsChatGPT,whichsignificantly
Example1
outperforms Mistral on CoT and RB. This re-
Quesitonstem:whichmultipliercanbeusedtofindthe
sultsuggeststhat,amongthe3baseLLMsevalu-
valueafteranamounthasdecreasedinvalueby5%for
ated,GPT-4possessesthemostrobustmathemat- 5years?
ical reasoning capability, followed by ChatGPT, Explanation: Asitsisadecrease,weneed100%-5%
which possesses a better mathematical reasoning whichis95%whichisthesameas0.95. Wethenuse
thenumberofyearsasthepowerof5.
capabilitythanMistral. WeseethatFTachieves
Answer:ˆ0.955
betterperformancethankNNwithMistral. This
resultsuggeststhatthepre-trainedMistralini- Example2
tiallylacksmathematicalreasoningcapability,and Quesitonstem: thevalueofalaptopthatinitiallycost
$1100,declinesinvalueby15%ayear.ifyouwanted
the fine-tuning process significantly enhances its
tocalculatethevalueofthetabletattheendof6years,
mathematicalreasoningcapability. whatnumberwouldreplacethesquare?1100ˆ˝6
Explanation: Asthevaluedecreasesby15%,wehave
3.5 QualitativeAnalysis 100%-15%=85%=0.85asthemultiplier.
Answer:0.85
Wenowqualitativelyinvestigatethedistractorsgen-
eratedbythebestapproach,kNN,toextractsome Example3
insightsonthedistractorgenerationtaskandhow Quesitonstem:acardepreciatesinvalueby15%each
to improve performance. We group the 283 total year.ifacarwasboughtfor$3500,whichofthefollow-
ingcalculationswouldfindthenewvalueofthecarafter
MCQsin thetestsetinto 4categories, according
3years?
to the number of LLM-generated distractors that
Explanation:Themultiplieris1-0.15=0.85,andaswe
matchthehuman-authoredones,from0to3. areusingcompoundinterest,weraisethistothepower
of3.
ForthegroupwhereallLLM-generateddistrac-
Answer:3500ˆ0.853
tors match thehuman-authored ones (3 outof 3),
wefindthat,inallbut2ofthe28suchcases,there
Table4: Threein-contextlearningexamplesretrieved
is an in-context example that is very similar to
bykNN; weseethatExample1isverysimilartothe
the target MCQ, with the only difference being
targetMCQ,exceptfordifferentnumericalvalues.
differentnumericalvaluesornamedentities. See
Table 4 for an example. However, this situation
LLM-generated distractors are plausible, and the
sometimes appears in other groups too, which is
human-authoredonesarenotsuperiortotheLLM-
perhapssurprisingsinceitimpliesthatthepresence
generated distractors. See Table 5 for an exam-
ofanear-identicalin-contextexamplealoneisnot
ple. While this observation is entirely subjec-
sufficientforanLLMtogenerateplausibledistrac-
tive,ithighlightsthatalignment-basedmetricsmay
tors. Weinvestigatefurtherintosuchcasesandfind
notbeanappropriatemetrictomeasurethequal-
thatevenfortwoMCQswithnear-identicalques-
ityofLLM-generateddistractorsbecausehuman-
tionstem,theirsetsofdistractorsandtheerrorsor
authoredonesmaynotbenaturallyoptimal. This
misconceptionsunderlyingeachdistractormaydif-
observation is also part of our motivation in de-
fereventhoughbothareplausible. Thissituation
velopingdistribution-based metricstopredicthow
occurswhentherearemorethan3plausibleerrors
likelyaLLM-generateddistractorwillbeselected
ormisconceptionsgivenaquestionstem.
byrealstudentswithinsufficientknowledge. More-
ForthegroupwherenoneoftheLLM-generated
over, since many LLM-generated distractors are
distractors match the human-authored ones, we
plausible even if they are not the same as the
randomly select 20 of the 78 cases to analyze.
human-authored ones, there is promise in using
We find that in 14 of the 20 cases (70%), the
automateddistractorgenerationforteachersupport
*Asofnow,Openaidoesnotallowfine-tuneGPT-4. duringthegenerationofMCQs.QuestionStem QWK AverageRatings
Craig and Isaac share some fruit. Isaac gets
LLM Human LLM Human
three-quartersofthefruit. Inwhatratiodothey
Validity 0.34 0.23 3.28 3.99˚
sharethefruit? (Isaac’spartsecond)
Plausibility 0.54 0.54 2.68 3.72˚
Key
1: 3 Table7: QWKandaverageratingsamonghumaneval-
uatorsonLLM-generatedandhuman-authoreddistrac-
LLM-generatedDistractors
tors for validity and plausibility. Under a Student’s
3 : 1 3 : 4 4 : 1 t-test,humanevaluatorspreferhuman-authoreddistrac-
torswithstatisticalsignificance(pă0.05˚).
Human-authoredDistractors
1 : 4 1 : 2 4 : 3
opingthedistribution-basedmetric.
Table5: ExampleofLLM-generateddistractorsthatare
mathematically valid and plausible but do not match 3.6 HumanEvaluation
human-authoredones.
Weconductahumanevaluationtoassessthequal-
ityofLLM-generateddistractors. Thisevaluation
QuestionStem is motivatedby observationsfrom the qualitative
Convert0.6toafractioninitssimplestform. analysis that the generated distractors are often
plausibleeventhoughtheymaybedifferentfrom
Key
human-authoredones.
3
5
3.6.1 EvaluationDesign
LLM-generatedDistractors
6 5 6 Werecruit2graduatestudentswhohaveexperience
10 3 5
teaching math or related topics as human evalua-
Human-authoredDistractors
tors. They are presented with the same set of 20
6 60 1
10 100 6 MCQs that are randomly sampled from the test
set,eachaccompaniedbyamixtureof4or6dis-
Table6: ExampleofLLM-generateddistractorswhere
theplausibleone, 6 matchesthehuman-authoredones, tractors. Toensureabalancedassessment,halfof
10
whiletherestofhuman-authoredonsareplaceholders. theseareLLM-generateddistractors,whilethere-
In this case, 6 is selected by 28% of students while maining are human-authored ones. To eliminate
10
otherdistractorsarerarelybeingselected. any potential ordering bias, the sequence of the
distractorsisrandomizedforeachquestion. They
are asked to rate the distractors on two aspects:
Finally, for the group where 1 or 2 LLM-
mathematical validity (validity) and plausibility
generated distractors match the human-authored
formiddleschoolmathstudents(plausibility). Va-
ones,weexaminewhichhuman-authoreddistrac-
lidity measures the degree of a distractor that is
tor(s)aregenerated. Wefindthatinmanycases,the
relevanttothequestionstemandcanbetangibly
human-authored distractors that match the LLM-
reachedbysomeincorrectreasoning. Plausibility
generated ones seem to reflect common errors or
measureshowlikelyadistractoristobeselected
misconceptionsamongrealstudents,whiletheoth-
byrealstudents. Eachaspectisscoredonascale
ersdonot. SeeTable6foranexample. Thisobser-
from 1 to 5, with 1 being the lowest: a distractor
vationisfurthersupportedbyselectionsmadeby
that is irrelevant to the question stem or one that
realstudents,wherethedistractorsthatcorrespond
no real students would select, while 5 being the
to the common errors or misconceptions are se-
highest: a distractor that is highly relevant to the
lectedbymorestudentsin44of108(40.7%)cases
question stem or one that is highly likely to trick
and46of63(73%)casesfor1and2matches,re-
realstudentswithinsufficientmathknowledgeinto
spectively,whiletherestarerarelybeingselected.
selectingit. Additionalevaluationsetupdetailsare
This result suggests that many MCQs have 1 or
inSupplementaryMaterialSectionC.
2highlyplausibledistractorswhiletheothersare
placeholders. Again,usinghuman-authoredones 3.6.2 EvaluationResultandDiscussion
asthegroundtruthonalignment-basedmetricsis Table7showstheinter-rateragreement,measured
not ideal, which justifies our motivation in devel- usingquadraticweightedKappa(QWK)(BrennerandKliebsch,1996)andtheaverageratingacross QuestionStem
?
2humanevaluatorsforbothLLM-generatedand Solvethisproblem: 3 216 “?
human-authoreddistractors. TheQWKscoresindi-
LLM-generatedfeedbackmessage
cateafairtomoderatelevelofagreementbetween
Ithinkyouhavemultipliedby3. Thequestion
twohumanevaluatorsregardingboththevalidity
isaskingforthecuberoot.
andplausibilityaspectsofdistractors. Thisobser-
vation suggests that measuring the quality of dis- LLM-generateddistractor
tractorsbasedontheirvalidityandplausibilityis 648
consistentatcertainlevelandcanbeusedinfuture
LLM-generatedfeedbackmessage
assessmentsofdistractors. WeconductaStudent’s
I think you have written the digits as a new
t-test(Semenick,1990)tocomparetheratingsfor
number. The question is asking for the cube
LLM-generated and human-authored distractors
root.
and find that in both aspects, there is a statisti-
callysignificantdifference(p ă 0.05). Thisresult LLM-generateddistractor
showsthathumanevaluatorsthinkhuman-authored 2163
distractorsarebetterthanLLM-generateddistrac-
torsinbothaspects. Furthermore,weobservethat Table8:ExamplesofLLM-generateddistractors,which,
fromapurelymathematicalperspective,seemvalidas
the gap between LLM-generated distractors and
theerrorssuggestmisunderstandingsofthecuberoot
human-authoredonesismuchbiggerforplausibil-
operationaseithermultiplyingby3orappendinga3to
ity than validity. This observation indicates that
theoriginalnumber. However,thesetwodistractorsdo
LLMs exhibit a higher proficiency in generating noteffectivelyreflectthecommonerrorsormisconcep-
mathematicallyvaliddistractorscomparedtoantic- tionsamongrealstudents.
ipatingcommonerrorsormisconceptionsamong
real students. See Table 8 for an example. This
approachesthatarecloselyalignedwitherrorsor
result is not surprising since LLMs, which have
misconceptionsamongrealstudentsforin-context
notbeenextensivelytrainedonerroneousanswers
example selection. Furthermore, we aim to ex-
provided by real students, may struggle to antici-
plorethegenerationofdistractors,eachofwhich
patethevariouswaysinwhichstudentsareprone
corresponds to a specific error or misconception,
tomakingerrorsorstudentmisconceptions. There-
aswellasthegenerationofhigh-qualityfeedback
fore,thereisstillconsiderableroomforimprove-
messagesforeachdistractor.
mentforLLMsintheircapacitytoanticipateerrors
ormisconceptionsamongrealstudents.
5 Acknowledgements
4 ConclusionsandFutureWork The authors thank Schmidt Futures and the NSF
(undergrants2118706&2237676)forsupporting
Inthispaper,weexploreautomateddistractorgen- thiswork.
erationformathmultiple-choicequestionsvialarge
language models. We conduct experiments on a
real-worldmathMCQdatasetandfindthatthein-
context learning-based approach kNN, achieves
the best performance when compared to other
approaches such as fine-tuning, chain-of-thought
prompting, and various baselines. We also con-
ducthumanevaluationandobservethatLLMsare
capableofgeneratingmathematicallyvaliddistrac-
tors but are not fully aware of common errors or
misconceptions among real students. Our initial
explorationofthistaskopensupmanyavenuesfor
future work. For example, we need to further re-
finethedistribution-basedmetricsthatpredictthe
percentageofstudentswhoselecteachdistractor.
We also need to develop modified text encodingLimitations Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Being the attempt at the task of generating plau- Neelakantan,PranavShyam,GirishSastry,Amanda
sibledistractorsformathMCQsusingLLMs,we Askell,etal.2020. Languagemodelsarefew-shot
learners. Advancesinneuralinformationprocessing
findseverallimitationsinourcurrentsetup. First,
systems,33:1877–1901.
wefindthatsomehuman-authoreddistractorsare
merely placeholders that do not reflect common YulinChen,NingDing,XiaobinWang,ShengdingHu,
errorsormisconceptionsamongrealstudents,and Hai-TaoZheng,ZhiyuanLiu,andPengjunXie.2023.
Exploringlotterypromptsforpre-trainedlanguage
usingthemasin-contextdemonstrationsmaylead
models. arXivpreprintarXiv:2305.19500.
tothegenerateddistractorsalsonotreflectingcom-
monerrorsormisconceptionsamongrealstudents. Shang-Hsuan Chiang, Ssu-Cheng Wang, and Yao-
Second,thealignment-based metricsmaynotac- ChungFan.2022. Cdgp: Automaticclozedistractor
generationbasedonpre-trainedlanguagemodel. In
curately measure the quality of LLM-generated
FindingsoftheAssociationforComputationalLin-
distractorsbecausesomeMCQsmayhaveonly1
guistics: EMNLP2022,pages5835–5840.
or 2 plausible distractors and some MCQs have
more than 3 plausible distractors. Third, we ac- PaulFChristiano,JanLeike,TomBrown,MiljanMar-
tic, Shane Legg, and Dario Amodei. 2017. Deep
knowledgethatourhumanevaluationsamplesize
reinforcementlearningfromhumanpreferences. Ad-
issmall,andshouldideallybeincreasedforfuture vancesinneuralinformationprocessingsystems,30.
studiesinordertoreceivemoreaccurateresults.
NeisargDave,RileyBakes,BartonPursel,andCLee
EthicalConsiderations Giles. 2021. Math multiple choice question solv-
ing and distractor generation with attentional gru
networks. International Educational Data Mining
The focus of our work is to automatically gen-
Society.
erate plausible distractors for math MCQs using
LLM.ByautomatingpartoftheMCQgeneration, Yifan Gao, Lidong Bing, Piji Li, Irwin King, and
weaimtosaveeducatorsandteachersfromtime- Michael R Lyu. 2019. Generating distractors for
readingcomprehensionquestions fromrealexami-
consuming MCQ generation and allow them to
nations. InProceedingsoftheAAAIConferenceon
dedicate more effort to teaching and student en-
ArtificialIntelligence,volume33,pages6423–6430.
gagement. Basedonouranalysisonthegenerated
distractors,weacknowledgethatnoteverydistrac- Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
torgeneratedbyourworkisplausible. Therefore,
and Weizhu Chen. 2021. Lora: Low-rank adap-
westronglyadvisethatourworkshouldbeadopted
tation of large language models. arXiv preprint
asanauxiliarytoolinthegenerationofMCQs. All arXiv:2106.09685.
automaticallygenerateddistractorsshouldundergo
Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
acarefulreviewbyeducatorsandteachersbefore
sch,ChrisBamford,DevendraSinghChaplot,Diego
beingutilizedinrealtestsforstudents.
delasCasas,FlorianBressand,GiannaLengyel,Guil-
laumeLample,LucileSaulnier,etal.2023. Mistral
7b. arXivpreprintarXiv:2310.06825.
References
DmytroKalpakchiandJohanBoye.2021. Bert-based
PeterAirasian.2001. Classroomassessment: Concepts distractor generation for swedish reading compre-
andapplications. McGraw-Hill,Ohio,USA. hensionquestionsusingasmall-scaledataset. arXiv
preprintarXiv:2108.03973.
Tahani Alsubait, Bijan Parsia, and Uli Sattler. 2014.
Generating multiple choice questions from ontolo- KimKelly, NeilHeffernan, SidneyD’Mello, Namais
gies: Lessonslearnt. InOWLED,pages73–84.Cite- Jeffrey,andAmberC.Strain.2013. Addingteacher-
seer. createdmotivationalvideotoanits. InProceedings
of26thFloridaArtificialIntelligenceResearchSoci-
SemereKirosBitew,JohannesDeleu,ChrisDevelder, etyConference,pages503–508.
and Thomas Demeester. 2023. Distractor genera-
tion for multiple-choice questions with predictive Tom Kubiszyn and Gary Borich. 2016. Educational
promptingandlargelanguagemodels. arXivpreprint testingandmeasurement. JohnWiley&Sons,New
arXiv:2307.16338. Jersey,USA.
HermannBrennerandUlrikeKliebsch.1996. Depen- XinxiLyu,SewonMin,IzBeltagy,LukeZettlemoyer,
denceofweightedkappacoefficientsonthenumber and Hannaneh Hajishirzi. 2023. Z-ICL: Zero-shot
ofcategories. Epidemiology,pages199–202. in-contextlearningwithpseudo-demonstrations. InProceedings of the 61st Annual Meeting of the As- Ana Paula Tomás and José Paulo Leal. 2013. Auto-
sociationforComputationalLinguistics(Volume1: matic generation and delivery of multiple-choice
LongPapers),pages2304–2317. math quizzes. In Principles and Practice of Con-
straintProgramming: 19thInternationalConference,
Anthony J. Nitko. 1996. Educational assessment of CP2013,Uppsala,Sweden,September16-20,2013.
students. Prentice-Hall,Iowa,USA. Proceedings19,pages848–863.Springer.
OpenAI.2022. Introducingchatgpt. Andrew Tran, Kenneth Angelikas, Egi Rama, Chiku
Okechukwu,DavidHSmithIV,andStephenMac-
OpenAI.2023. Gpt-4technicalreport.
Neil.2023. Generatingmultiplechoicequestionsfor
computingcoursesusinglargelanguagemodels.
FabianPedregosa,GaëlVaroquaux,AlexandreGram-
fort,VincentMichel,BertrandThirion,OlivierGrisel,
PauliVirtanen,RalfGommers,TravisEOliphant,Matt
MathieuBlondel,PeterPrettenhofer,RonWeiss,Vin-
Haberland, Tyler Reddy, David Cournapeau, Ev-
cent Dubourg, et al. 2011. Scikit-learn: Machine
geni Burovski, Pearu Peterson, Warren Weckesser,
learninginpython. theJournalofmachineLearning
JonathanBright,etal.2020. Scipy1.0: fundamental
research,12:2825–2830.
algorithmsforscientificcomputinginpython. Na-
VijayPrakash,KartikayAgrawal,andSyaamantakDas. turemethods,17(3):261–272.
2023. Q-genius:Agptbasedmodifiedmcqgenerator
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
foridentifyinglearnerdeficiency. InInternational
Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le,
Conference on Artificial Intelligence in Education,
andDennyZhou. 2022. Chain-of-thoughtprompt-
pages632–638.Springer.
ing elicits reasoning in large language models.
Ethan Prihar, Morgan Lee, Mia Hopman, Adam Tau- abs/2201.11903.
man Kalai, Sofia Vempala, Allison Wang, Gabriel
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Wickline, Aly Murray, and Neil Heffernan. 2023.
Chaumond,ClementDelangue,AnthonyMoi,Pier-
Comparingdifferentapproachestogeneratingmathe-
ricCistac,TimRault,RémiLouf,MorganFuntow-
maticsexplanationsusinglargelanguagemodels. In
icz,JoeDavison,SamShleifer,PatrickvonPlaten,
InternationalConferenceonArtificialIntelligencein
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Education,pages290–295.Springer.
Teven Le Scao, Sylvain Gugger, Mariama Drame,
ZhaopengQiu,XianWu,andWeiFan.2020. Automatic QuentinLhoest,andAlexanderM.Rush.2019. Hug-
distractorgenerationformultiplechoicequestionsin gingface’stransformers: State-of-the-artnaturallan-
standardtests. arXivpreprintarXiv:2011.13100. guageprocessing. abs/1910.03771.
NilsReimersandIrynaGurevych.2019. Sentence-bert: Jiayuan Xie, Ningxin Peng, Yi Cai, Tao Wang, and
Sentenceembeddingsusingsiamesebert-networks. QingbaoHuang.2021. Diversedistractorgeneration
InProceedingsofthe2019ConferenceonEmpirical forconstructinghigh-qualitymultiplechoiceques-
MethodsinNaturalLanguageProcessing.Associa- tions. IEEE/ACM Transactions on Audio, Speech,
tionforComputationalLinguistics. andLanguageProcessing,30:280–291.
RicardoRodriguez-Torrealba,EvaGarcia-Lopez,and
Antonio Garcia-Cabot. 2022. End-to-end genera-
tionofmultiple-choicequestionsusingtext-to-text
transfer transformer models. Expert Systems with
Applications,208:118258.
DougSemenick.1990. Testsandmeasurements: Thet-
test. Strength&ConditioningJournal,12(1):36–37.
PengjuShuai, LiLi, SishunLiu, andJunShen.2023.
Qdg: A unified model for automatic question-
distractor pairs generation. Applied Intelligence,
53(7):8275–8285.
KatherineStasaskiandMartiAHearst.2017. Multiple
choicequestiongenerationutilizinganontology. In
Proceedingsofthe12thWorkshoponInnovativeUse
ofNLPforBuildingEducationalApplications,pages
303–312.
YuniSusanti,TakenobuTokunaga,HitoshiNishikawa,
andHiroyukiObari.2018. Automaticdistractorgen-
erationformultiple-choiceenglishvocabularyques-
tions. Researchandpracticeintechnologyenhanced
learning,13:1–16.Supplementary Material optimizerfor10epochswithalearningrateof3e-
5, a batch size of 16, accumulate gradients for 4
A Distributionrankingmetric batches. Themodelconvergesonthevalidationset
after6epochs. TheGPUweusetotrainthemodel
SinceourqualitativeanalysisinSection3.5found is NVIDIA RTX A6000. The training process
that human-authored distractors are sometimes iscompletedin10hours. Whenevaluatedonthe
unplausible or incomplete, using them as the testset,therankingmodelcorrectlyidentifiesthe
groundtruthisnotideal. Therefore,weexplorea preferred distractor 61.60% of the time (random
distribution-basedmetrictoevaluatethequalityof guessingcorrespondsto50%accuracy). Thisaccu-
LLM-generateddistractors,basedononeintuition: racyislowoverallbuthighonsubsetsofdistractor
gooddistractorsareonesthatarelikelygoingtobe pairswhosestudentselectionpercentagesdifferby
selectedbymanyrealstudents. Therefore,ourgoal a large margin: on pairs with a larger than 20%
istotrainamodelthatcanpredicttheportionofstu- margin,whichaccountsfor6%ofpairs,theaccu-
dentsthatselecteachoptioninanMCQ.However, racyjumpsto74.47%. Thisresultisnotsurprising
duetothehighlynoisynatureofthisdistribution, sincetheselectionpercentagedataisverynoisy.
weopttotrainamodelthatpredictsthemoreoften Using this trained model, we can evaluate the
selecteddistractoramongapair,givenaquestion qualityofLLM-generateddistractors: wecompare
stem,whichissimilartothepairwisepreferencere- allpossiblehead-to-headmatchupsbetweengen-
wardmodelinreinforcementlearningfromhuman erated distractors and human-authored ones, and
feedback(RLHF)(Christianoetal.,2017). After recordtheportionoftimesthatthegenerateddis-
training such a model, we can use it to compare tractorsarepreferredbytherankingmodel. Ifthe
generated distractors to human-authored ones in two distractors are the same then we record a tie.
head-to-headmatchups,givingusaproxyforhow Incaseswherethegenerateddistractorsareinvalid
goodanLLMisintermsofgeneratingdistractors or repeated, we treat them as null and record a
thatarelikelytobeselectedbystudents. win for the human-authored ones. Formally, we
Formally, we train an LLM-based model defineapreferencescoreas
r pd ,d ,s,k,e q Ñ td ,d u, where ϕ denotes
ϕ 1 2 k 1 2 ÿN ÿ3 ÿ3
thesetofmodelparameters. Wetrainthismodel
s “
1 rpiq pdˆpiq,dpiq
q
byfirstconstructingadatasetofallpairsofhuman- 18N ϕ a b
i“1a“1b“1
authored distractors for each MCQ and include
`p1´rpiq pdpiq,dˆpiqqq,
bothordersof`ea˘chpairtoavoidorderingbias,re- $ ϕ b a
sultinginNˆ 3 2 ˆ2totalpairs,whereN denotes ’ ’ ’ ’0.5 d 1 “ d 2
&
thenumberofMCQs. Eachpairisassociatedwith
1 d isnull
a seb lein ca tery d- bv yalu me od rela sb te ul di en nd ti sc ,a wtin hg icw hh we eth ce ar nd c1 ao lr cud l2 ati es r
ϕpiq
pd 1,d 2q “ ’ ’ ’ ’ %0
d2
1 isnull ,
p otherwise
from the student response records in our dataset.
Wethenusethisdatasettofine-tuneanLLMina p “ 1 ,
textgenerationtask,wheretheLLMreceivesthe
r ϕpd1,d2,spiq,kpiq,ep kiqq“d1
question and distractor information in its prompt wheredˆ aregenerateddistractors. Thisscorehasa
and outputs its preference. We show our prompt rangeofr0,1swherehighervaluesindicateLLM-
forthistaskinTable12. generated distractors are likely to be selected by
We use the same train/test split as the morestudentsthanthehuman-authoredones. We
distractor generation experiments, and reserve foundthatkNNscores0.46onthetestset,which
20% of the train split for validation after indicatesthatthedistractorsitgeneratesarealmost
each epoch and early stopping. We fine-tune asplausibletostudentsashuman-authoredones.
the mistralai/Mistral-7B-v0.1 model, Weemphasizethatthisevaluationmetricshould
which contains 7 billion parameters, from Hug- onlybeconsideredexploratoryduetoseveralobvi-
gingFace(Wolfetal.,2019)usingLoRA(Huetal., ouslimitations. First,studentoptionselectionper-
2021) with adaptors on the q_proj, k_proj, centagescreatenoisylabelsfortherankingmodel,
v_proj, and o_proj matrices, set r “ 32, limiting its accuracy. Second, using the overall
α “ 16, dropout “ 0.05, and use 8-bit quan- selection percentages also ignores the individual
tization. We train the model using the AdamW learningcontextofeachstudentsincestudentswithdifferentknowledgelevelsmayhavedifferentten-
denciesamongMCQoptions. Therefore,weleave
amorethoroughtreatmentofthedistribution-based
metrictofuturework.
B HyperparametersandImplementation
Details
For fine-tune (FT) approach, We fine-tune
2 large language models. We fine-tune the
mistralai/Mistral-7B-Instruct-v0.2
model, which is the latest Mistral model and
contains7billionparameters,fromHuggingFace
using LoRA with adaptors on the q_proj,
k_proj, v_proj, and o_proj matrices, set
r “ 32, α “ 16, dropout “ 0.05, and use 8-bit
quantization. We use 20% of the training set
for validation. We train the model using the
AdamW optimizer with weightdecay “ 0.0
and gradientclip “ 1.0 for 8 epochs with a
learning rate of 8e-5, a batch size of 16, and
accumulatedgradientsfor4batches. Theselection
oftheaforementionedhyperparametersisguided
by exploratory evaluations and no substantial
hyper-parametersearchisconducted. TheGPUwe
use to train the model is NVIDIA RTX A6000.
The training process is completed in 2 hours and
55 minutes. We fine-tune the ChatGPT model
using the first 200 data points from the training
set. WetrainthemodelusingtheOpenAI’sdefault
fine-tuningsettings,whichwefindtoprovidethe
best performance via OpenAI API. The training
process is completed in 20 minutes. We use
the scikit-learn (Pedregosa et al., 2011)
implementation to calculate QWK, and use the
scipy (Virtanen et al., 2020) implementation
to calculate Student’s t-test. For prompting
GPT-4andChatGPTusingOpenAIAPI,weuse
temperature “ 0, max_tokens “ 350, top_p “ 1
as our setup for greedy decoding. All our experi-
mentsareimplementedinPythonorPytorchcode,
and We note that all software employed in this
workisopen-source,orthelicenseisunspecified.
C HumanEvaluationDetails
Inthiswork,weobtainedapprovalfromtheethics
reviewboardforhumanevaluation. Weshowthe
evaluationinstructionstohumanevaluatorsinTa-
ble 13. Wedonotprovideanycompensationfor
humanevaluatorsbecausetheirparticipationisen-
tirely voluntary and we appreciate their contribu-
tiontothiswork.D PromptFormat
WeprovidethepromptsforCoT,RB,andkNNintheworkbelow. Weuseăątoindicatethatavariable
isfilledindynamically.
Prompt You are given the following math question along with the correct
answerandexplanation. Pleaseusethefollowingtemplatetogive3
alternative incorrect answers to be used as multiple-choice options
in a multiple-choice exam. Prior to the incorrect answer, provide
feedbacktobedisplayedtothestudentasanexplanationofwhythat
isnotthecorrectanswer.
[Template]
Distractor1Feedback:
Distractor1:
Distractor2Feedback:
Distractor2:
Distractor3Feedback:
Distractor3:
Question: <question>
Explanation: <explanation>
Answer: <answer>
Table9: CoTpromptformat
Prompt You are given the following math question along with the correct
answer,explanation,andalistoferrors. Pleasefollowthetemplate
to first select 3 most likely errors for this question and use the se-
lected errors to generate 3 alternative incorrect answers to be used
as multiple-choice options in a multiple-choice exam. Prior to the
incorrectanswer,providefeedbacktobedisplayedtothestudentas
an explanation of why that is not the correct answer. If the list of
errorsisnotgiven,generate3errorsinsteadanddonotcontainany
explanationinthe3incorrectanswer.
[Template]
Error1:
Error2:
Error3:
Distractor1Feedback:
Distractor1:
Distractor2Feedback:
Distractor2:
Distractor3Feedback:
Distractor3:
Question: <question>
Explanation: <explanation>
Answer: <answer>
Errorlist: <errorlist>
Table10: RBpromptformatPrompt Question: <in-contextquestion>
Explanation: <in-contextexplanation>
Answer: <in-contextanswer>
Distractor1Feedback: <in-contextdistractor1feedback>
Distractor1:<in-contextdistractor1>
Distractor2Feedback: <in-contextdistractor2feedback>
Distractor2:<in-contextdistractor2>
Distractor3Feedback:<in-contextdistractor3feedback>
Distractor3:<in-contextdistractor3>
[stop]
Question: <targetquestion>
Explanation: <targetexplanation>
Answer: <targetanswer>
Table11: kNNpromptformat,inpractice,weuse3in-contextexamplesE RankingMetricExamples
Prompt Ateacherassignsthefollowingmathmultiplechoicequestiontoa
classofmiddleschoolstudents.
Question: 3 of50“ 6 of˝
5 10
CorrectAnswer: 50
Solution: 3/5and6/10areequivalent,so3/5of50isthesameas6/10
of50.
Hereare2incorrectoptionsthatsomestudentschoose:
OptionA:30
OptionB:18
Whichincorrectoptionarethestudentsmorelikelytopick?
Output PreferredAnswer: A
Table12: Examplepromptandoutputfortherankingmodelusedinthedistributionrankingmetric.
F Instruction
Youaregivenacsvfile. Eachrowcorrespondstoaquestionstemandadistractor.
Your job is to rate the distractor on two aspects: mathematical validity and plausibility for middle
schoolmathstudents.
Mathematicalvaliditymeasureswhetheradistractorisrelevanttothequestionstemandcanbetangibly
reachedbysomeincorrectreasoning. Mathematicalvalidityisscoredonascalefrom1to5,where1
indicatesadistractorthatisirrelevanttothequestionstem,and5indicatesadistractorthatishighly
relevanttothequestionstem.
Plausibilitymeasureshowlikelyadistractoristobeselectedbymiddleschoolstudentslearningmath.
Plausibilityisscoredonascalefrom1to5,where1indicatesthatnostudentwouldselectitand5
indicatesthatthedistractorishighlylikelytotrickstudentswithinsufficientmathskillsintoselecting
it.
pleaseusenumbersonmactoratedistractorsandgive1and1forbothmetricifthedistractoristhe
correctanswer.
Yourratingswillbeusedtoquantitativelymeasuresandanalyzesthequalityofdistractorsonvalidity
andplausibility.
Table13: InstructionforHumanEvaluation